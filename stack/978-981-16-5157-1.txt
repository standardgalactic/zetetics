Advances in Intelligent Systems and Computing 1408
Subarna Shakya
Valentina Emilia Balas
Sinchai Kamolphiwong
Ke-Lin Du   Editors
Sentimental 
Analysis 
and Deep 
Learning
Proceedings of ICSADL 2021

Advances in Intelligent Systems and Computing
Volume 1408
Series Editor
Janusz Kacprzyk, Systems Research Institute, Polish Academy of Sciences,
Warsaw, Poland
Advisory Editors
Nikhil R. Pal, Indian Statistical Institute, Kolkata, India
Rafael Bello Perez, Faculty of Mathematics, Physics and Computing,
Universidad Central de Las Villas, Santa Clara, Cuba
Emilio S. Corchado, University of Salamanca, Salamanca, Spain
Hani Hagras, School of Computer Science and Electronic Engineering,
University of Essex, Colchester, UK
László T. Kóczy, Department of Automation, Széchenyi István University,
Gyor, Hungary
Vladik Kreinovich, Department of Computer Science, University of Texas
at El Paso, El Paso, TX, USA
Chin-Teng Lin, Department of Electrical Engineering, National Chiao
Tung University, Hsinchu, Taiwan
Jie Lu, Faculty of Engineering and Information Technology,
University of Technology Sydney, Sydney, NSW, Australia
Patricia Melin, Graduate Program of Computer Science, Tijuana Institute
of Technology, Tijuana, Mexico
Nadia Nedjah, Department of Electronics Engineering, University of Rio de Janeiro,
Rio de Janeiro, Brazil
Ngoc Thanh Nguyen
, Faculty of Computer Science and Management,
Wrocław University of Technology, Wrocław, Poland
Jun Wang, Department of Mechanical and Automation Engineering,
The Chinese University of Hong Kong, Shatin, Hong Kong

The series “Advances in Intelligent Systems and Computing” contains publications
on theory, applications, and design methods of Intelligent Systems and Intelligent
Computing. Virtually all disciplines such as engineering, natural sciences, computer
and information science, ICT, economics, business, e-commerce, environment,
healthcare, life science are covered. The list of topics spans all the areas of modern
intelligent systems and computing such as: computational intelligence, soft comput-
ing including neural networks, fuzzy systems, evolutionary computing and the fusion
of these paradigms, social intelligence, ambient intelligence, computational neuro-
science, artiﬁcial life, virtual worlds and society, cognitive science and systems,
Perception and Vision, DNA and immune based systems, self-organizing and
adaptive systems, e-Learning and teaching, human-centered and human-centric
computing, recommender systems, intelligent control, robotics and mechatronics
including human-machine teaming, knowledge-based paradigms, learning para-
digms, machine ethics, intelligent data analysis, knowledge management, intelligent
agents, intelligent decision making and support, intelligent network security, trust
management, interactive entertainment, Web intelligence and multimedia.
The publications within “Advances in Intelligent Systems and Computing” are
primarily proceedings of important conferences, symposia and congresses. They
cover signiﬁcant recent developments in the ﬁeld, both of a foundational and
applicable character. An important characteristic feature of the series is the short
publication time and world-wide distribution. This permits a rapid and broad
dissemination of research results.
Indexed by DBLP, INSPEC, WTI Frankfurt eG, zbMATH, Japanese Science and
Technology Agency (JST).
All books published in the series are submitted for consideration in Web of Science.
More information about this series at http://www.springer.com/series/11156

Subarna Shakya · Valentina Emilia Balas ·
Sinchai Kamolphiwong · Ke-Lin Du
Editors
Sentimental Analysis
and Deep Learning
Proceedings of ICSADL 2021

Editors
Subarna Shakya
Institute of Engineering
Tribhuvan University, Pulchowk Campus
Lalitpur, Nepal
Sinchai Kamolphiwong
Songkla University
Songkhla, Thailand
Valentina Emilia Balas
Intelligent Systems Research Centre
Aurel Vlaicu University of Arad
Arad, Romania
Ke-Lin Du
Department of Electrical and Computer
Engineering
Concordia University
Montreal, QC, Canada
ISSN 2194-5357
ISSN 2194-5365 (electronic)
Advances in Intelligent Systems and Computing
ISBN 978-981-16-5156-4
ISBN 978-981-16-5157-1 (eBook)
https://doi.org/10.1007/978-981-16-5157-1
© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature
Singapore Pte Ltd. 2022
This work is subject to copyright. All rights are solely and exclusively licensed by the Publisher, whether
the whole or part of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse
of illustrations, recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and
transmission or information storage and retrieval, electronic adaptation, computer software, or by similar
or dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this book
are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or
the editors give a warranty, expressed or implied, with respect to the material contained herein or for any
errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional
claims in published maps and institutional afﬁliations.
This Springer imprint is published by the registered company Springer Nature Singapore Pte Ltd.
The registered company address is: 152 Beach Road, #21-01/04 Gateway East, Singapore 189721,
Singapore

We, the organizers, dedicate this ICSADL
2021 proceeding to the worldwide community
of artiﬁcial intelligence, information and
communication technologies (ICT)
researchers. We also dedicate this proceeding
to the authors and editorial team of the
conference, who have highly discussed about
the solutions to problems that exist in the
international research community.

Preface
On behalf of the ICSADL 2021 International Program Committee and Organizing
Committee, it is my pleasure to welcome you to the International Conference on
Sentimental Analysis and Deep Learning (ICSADL 2021) hosted by the Institute of
Engineering, Tribhuvan University and Songkla University, Thailand, on June 18–
19, 2021. This conference has served as an interactive platform for the academic and
industrial communities to address current and future challenges in intelligent infor-
mation systems and computing technologies. This conference has invited the contri-
butions about the state-of-the-art technologies and the implementation of advances in
the artiﬁcial intelligence-driven information systems and computational intelligence
models.
Amidst, the COVID-19 pandemic, the conference has become a very successful
event with different academic sessions, which cover the latest advances in intelligent
information systems. The sessions have been designed to enhance understanding on
how to autonomously connect people and process the big data resources obtained
fromdifferentpartsoftheworld.Thiswillcoverchallenges,suchasdesignforservice
and understanding the intelligent implications of information systems. Additionally,
the attendees have gained excessive research knowledge from keynotes which are
delivered by academics and industrialists, who represent different sectors. Also, the
presenters have offered interactive sessions in a range of topics ranging from current
research requirements to technical solutions.
These proceedings will furnish the ongoing research works from different parts
of the world with a convincing implementation of sentiment analysis, deep learning,
and data analytics models. I also trust that this proceeding will be an impetus to
stimulate further study and research in all these areas.
I thank all authors and participants for their contribution.
vii

viii
Preface
I hope that all the authors and other interested readers would technically beneﬁt
from the proceedings, and also, it stimulates their research knowledge.
Technical Program Chairs—ICSADL 2021
Dr. Subarna Shakya
Professor, Department of Electronics
and Computer Engineering, Institute
of Engineering
Tribhuvan University, Pulchowk
Campus
Lalitpur, Nepal
Dr. Valentina Emilia Balas
Head of the Intelligent Systems
Research Centre
Aurel Vlaicu University of Arad
Arad, Romania
Dr. Sinchai Kamolphiwong
Dean, Songkla University
Songkhla, Thailand
Dr. Ke-Lin Du
Afﬁliated Associate Professor,
Department of Electrical and Computer
Engineering
Concordia University
Montreal, QC, Canada

Acknowledgments
We would like to thank our institution, Tribhuvan University, for supporting this
event. We also acknowledge all participants, who have actively participated in the
conference activities and utilized the opportunity to learn from one another.
We acknowledge the distinguished speaker of the conference: Dr. Manu Malek
for the acceptance to deliver a keynote talk on the respective ﬁelds of expertise. Also,
we like to acknowledge the internal and external referees and the advisory committee
members for their continual effort for the selection of papers by strictly following
the international peer review standards.
We would like to thank the technical program chairs, guest editors, conference
organizing committee, session organizers for their valuable assistance. A special
thanks to the editorial members of Springer for the acceptance and inclusion of the
conference proceedings.
Special thanks and appreciation are extended to the academic and non-academic
faculty for their efforts in organizing the conference despite the current pandemic
situation all across the globe.
As organizers, we would like to convey our heartfelt gratitude to all delegates
for their cutting-edge research, as well as the session chairs for curating high-level
presentations into harmonic sessions.
Thanks to all participants, who have contributed to the success of ICSADL 2021.
ix

Contents
Analysis of Healthcare Industry Using Machine Learning
Approach: A Case Study in Bengaluru Region . . . . . . . . . . . . . . . . . . . . . .
1
Poornima Taranath, Sweta Das, and S. Gowrishankar
Dynamic Document Localization for Efﬁcient Mining . . . . . . . . . . . . . . . .
15
P. Sijin and H. N. Champa
SentiSeries: A Trilogy of Customer Reviews, Sentiment Analysis
and Time Series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
Aishwarya Asesh
Video Summarization Using Fully Convolutional Residual
Dense Network . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
47
Anil Singh Parihar, Ritvik Mittal, Himanshu, and Prashuk Jain
An Efﬁcient Deep Learning Approach for Detecting Pneumonia
Using the Convolutional Neural Network . . . . . . . . . . . . . . . . . . . . . . . . . . .
59
Anik Kumar Saha and Md. Muhaimenur Rahman
QMCDS: Quantum Memory for Cloud Data Storage . . . . . . . . . . . . . . . .
69
Ankit Sharma, Indra Kumar Sahu, and Manisha J. Nene
A Study Towards Bangla Fake News Detection Using Machine
Learning and Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
79
Elias Hossain, Md. Nadim Kaysar, Abu Zahid Md. Jalal Uddin Joy,
Md. Mizanur Rahman, and Wahidur Rahman
A Deep Learning Approach to Analyze the Propagation
of Pandemic in America . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
97
Paola G. Vinueza-Naranjo, Angel F. Vinueza-Naranjo,
and Hieda A. Nascimento-Silva
xi

xii
Contents
Graph Convolution-Based Joint Learning of Rumor
with Content, User Credibility, Propagation Context,
and Cognitive as Well as Emotion Signals . . . . . . . . . . . . . . . . . . . . . . . . . . .
113
Prajna Nagaraj and Bhaskarjyoti Das
Deep Learning-Based Real-Time Object Classiﬁcation
and Recognition Using Supervised Learning Approach . . . . . . . . . . . . . . .
129
J. Harikrishna, Ch. Rupa, and R. Gireesh
Single-Channel Speech Enhancement in Modulation Domain
Using Particle Swarm Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
141
Kalpana Ghorpade and Arti Khaparde
Pneumonia and Diabetic Retinopathy Detection Using Deep
Learning Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
155
Meera Ghaskadvi, Sakshi Khochare, Rozebud Gonsalves,
and Prajakta Dhamanskar
Design of IoT-Based Improved Multimodal Ant Colony
Optimızation (MM-ACO) Algorithm for Real-Time Applications . . . . .
177
Mohammed Khalid Kaleem,Kassahun Azezew,andSmegnew Asemie
An Interview Transcriber Using Natural Language Processing . . . . . . . .
185
G. R. Deeba Lakshmi, Jayavrinda Vrindavanam, Anshika Shukla,
and Rahul
Plagiarism Detection for Source Codes and Texts . . . . . . . . . . . . . . . . . . . .
199
Syed Yasmeen, Munjuluri Prathyusha, Malisetty Rajeswari,
Padmanabhuni Srujana, and K. Ashesh
Investigation of Kinetic Energy Harvesting from Human Body
Motion Activities Using Free/Impact Electromagnetic Generator . . . . . .
209
Athern Aloysius, M. K. A. Ahamed Khan, Wei Hong Lim,
Manicam Ramaswamy, Sridevi, Deisy, Abdul Qayyum,
Chun Kit Ang, and Kalaiselvi Aramugam
Automated Determination of Critical Temperature . . . . . . . . . . . . . . . . . .
223
Abhishek Deshpande, Jatin Pardhi, and Gokul Bisen
ANN-based Hybridization Approach for Detection of Cardiac
Disease . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
237
N. Shwetha, N. Gangadhar, Mahesh B. Neelagar, and K. C. Shilpa
The Implementation of Enhanced K-Strange Points Clustering
Method in Classifying Undergraduate Thesis Titles . . . . . . . . . . . . . . . . . .
255
Malcolm Andrew Madeira and Teslin Jacob
Spam Email Detection Using Machine Learning and Neural
Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
275
Manoj Sethi, Sumesha Chandra, Vinayak Chaudhary, and Yash Dahiya

Contents
xiii
Online Appointment Management System in Hospitals Using
Distributed Resource Allocation Algorithm . . . . . . . . . . . . . . . . . . . . . . . . .
291
B. Jency A. Jebamani, R. Murugeswari, and P. Nagaraj
BeFit—A Real-Time Workout Analyzer . . . . . . . . . . . . . . . . . . . . . . . . . . . .
303
Richard Joseph, Manoj Ayyappan, Tanvi Shetty, Gurudatt Gaonkar,
and Aashish Nagpal
Analysis of Car Damage for Personal Auto Claim Using CNN
. . . . . . . .
319
Jagadevi N. Kalshetty, B. A. Hrithik Devaiah, K. Rakshith,
Ken Koshy, and N. Advait
On the Analysis Problem of the Attribute-Based Access Control
Model HGABAC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
331
Anh Truong
The Freshness of Food Detection Using IoT and Machine
Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
347
Snehal Chalke, Sowmya Ganesan, Krishna Gajera, Pooja Reshim,
and Nita Patil
Prediction of Signal Drop Due to Rain at User Cellular Signal
Reception . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
357
D. Lohith Bhargav, D. Achish, G. Yashwanth, N. Pavan Kalyan,
and K. Ashesh
Wavelet Decomposition Methodology for Improved Retinal
Blood Vessel Segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
369
Udayini Dikkala, Kezia Joseph Mosiganti, and Mukil Alagirisamy
Exploring the Performance of Ensemble Machine Learning
Classiﬁers for Sentiment Analysis of COVID-19 Tweets . . . . . . . . . . . . . .
383
Md. Mahbubar Rahman and Muhammad Nazrul Islam
Implementation of Bayesian Network Model (BN Trust Model)
for IoT Routing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
397
Sridhar Manda, N. Nalini, and A. Arun Kumar
Bioinformatics: The Importance of Data Mining Techniques . . . . . . . . . .
411
Md. Nasﬁkur R. Khan, Shatabdee Bala, Sarmila Yesmin,
and Mohammad Zoynul Abedin
Comparative Analysis of Different Deep Learning Techniques
for Relation Extraction from Biomedıcal Literature . . . . . . . . . . . . . . . . .
423
M. Saranya, T. V. Geetha, and R. Arockia Xavier Annie
Classiﬁcation of the Suicide-Related Text Data Using Passive
Aggressive Classiﬁer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
439
B. V. Kiranmayee, Chalumuru Suresh, and S. SreeRakshak

xiv
Contents
Covid-19 Data Analysis to Predict the Level of Hospitalization . . . . . . . .
451
Advet Jadhav, Maheshwari Satpute, Utkarsh Rai,
Apeksha Wadibhasme, and Usha Verma
Analysis the Accuracy of Rice Grains Quality Using Neural
Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
465
S. Menaka and K. Sashi Rekha
Smart Food Fare Canteen: Automation of Bills and Serving . . . . . . . . . .
475
Radha Mothukuri, S. Hrushikesava Raju, S. Adinarayna,
Vijaya Chandra Jadala, Saiyed Faiayaz Waris, and G. Subba Rao
Activation Functions Instituted Clustering for Automated
Generation of Programming Code Contracts . . . . . . . . . . . . . . . . . . . . . . . .
487
S. V. Gayetri Devi and T. Nalini
Voice Signal-Based COVID-19 Detection Using Ensemble
Neural Network . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
501
A. V. Akshaya and Meril Cyriac
A Performance Metrics Estimation of Spade, Preﬁx Span, Fast,
and Lapin Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
515
T. M. Veeragangadhara Swamy and N. Vani
Prediction and Classiﬁcation of Cardiac Arrhythmia . . . . . . . . . . . . . . . .
527
Aashuli Gupta, Arnob Banerjee, Disha Babaria, Kunal Lotlikar,
and Hema Raut
Impact of Variation of Temperature on PEM Fuel Cell-Based
Power Converters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
539
M. Malathi, Usha Surendra, and N. Latha
Qgen: An Automatic Question Paper Generator . . . . . . . . . . . . . . . . . . . . .
555
Ajil Paul, Amal Sabu, Beema Abdulkader, Priya George,
and Sneha Sreedevi
Fundamental Frequency Extraction of Noisy Speech Using
Exponent Enhancement in Weighted Autocorrelation . . . . . . . . . . . . . . . .
565
Md. Saifur Rahman and Nargis Parvin
Solar-Powered Multipurpose Agro-Utility System . . . . . . . . . . . . . . . . . . .
577
Vipin Bondre, Surabhi Pawar, Shatakshi Dixit, Shefali Thoolkar,
and Trupti Tale
A Performance Analysis of Supervised Machine Learning
Techniques for COVID-19 and Happiness Report Dataset . . . . . . . . . . . .
591
Syed Abu Farooq and Selvanayaki Kolandapalayam Shanmugam
Predicting Telecom Customer’s Switch Over Intentions Using
Machine Learning Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
603
S. N. Vivek Raj and S. Prithiviraj Pallava Rayer

Contents
xv
Detect CLAMAV Virus Signatures Using Restricted Features . . . . . . . . .
615
Reshma Sri Sai Mangipudi, J. Pranitha, G. Sai Varsha,
and B. Indira Priyadarshini
A Review of Mesh Generation in ANUGA . . . . . . . . . . . . . . . . . . . . . . . . . .
625
Shreya Kendhe, Aditi Limkar, Sakshi Doshi,
T. S. Murugesh Prabhu, Girishchandra R. Yendargaye,
Y. S. Ingle, and N. F. Shaikh
Modeling and Analysis of Tsunami Wave Propagation
Characteristics in the Coast of Bay of Bengal . . . . . . . . . . . . . . . . . . . . . . . .
637
M. Yasmin Regina and E. Syed Mohamed
An Android Application for University-Based Academic
Solution for Crisis Situation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
653
Md. Nasﬁkur R. Khan, Asif Khan Shakir, Shantunu Shakhwat Nadi,
and Mohammad Zoynul Abedin
Never Underestimate Substitution Cipher with Diffusion . . . . . . . . . . . . .
665
Md Rasid Ali and Dipanwita Roy Chowdhury
Kannada Sentiment Analysis Using Vectorization and Machine
Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
677
M. E. Sunil and S. Vinay
Human Activity Recognition Using 1D Convolutional Neural
Network . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
691
Khushboo Banjarey, Satya Prakash Sahu,
and Deepak Kumar Dewangan
Language and Era Prediction of Digitized Indian Manuscripts
Using Convolutional Neural Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
703
Anukriti Garg, Laghima Tiwari, Tejsvi Juj, S. Indu, and N. Jayanthi
Continuous Chain Fibonacci: Knowledge Management System
with Chatbot . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
719
S. Pradeep Kumar, R. Murugeswari, and P. Nagaraj
Management of IoT Devices Security Using
Blockchain—A Review . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
735
Gaurav Pattewar, Nachiket Mahamuni, Hrishikesh Nikam,
Omkar Loka, and Rachana Patil
Role of the Procedures of Deep Learning for Higher Proﬁtability
in the Agriculture Sector . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
745
Amit Verma
Retinal Encryption Using Snnipet Pixel XOR with Huffman
Sequential Encoding for Privacy Augmentation . . . . . . . . . . . . . . . . . . . . .
757
L. Poongothai, K. Sharmila, C. Shanthi, R. Devi, and R. Anitha

xvi
Contents
Automatic Text Summarization Using Deep Learning
and Reinforcement Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
769
Jency Thomas, Amrutha Sreeraj, Ayswarya Sreeraj,
Megha Mary Varghese, and Thomas Kuriakose
An Analysis and Application of HRMS Tools in Industries
. . . . . . . . . . .
779
M. R Dileep, A. V Navaneeth, B. M Chaitra, and Ajit Danti
Resource Allocation and Power Management in Cloud Servers
Using Deep Reinforcement Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
789
Sushil Shakya and Subarna Shakya
System for Analyzing Crime News by Mining Live Data Streams
with Preserving Data Privacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
799
Rahul Patil, Pramod D. Patil, Sayali Kanase, Nikita Bhegade,
Vaishnavi Chavan, and Shreyas Kashetwar
Webpage Portal for Crowd Sourcing on Food Waste Management . . . .
813
C. S. Manikandababu, M. Jagadeeswari, R. Priyanka, S. Preethi,
V. Rithika, and J. Ravin Kumar
Extensive Analysis of Global Presidents’ Speeches Using Natural
Language . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
829
S. Nivash, E. N. Ganesh, K. Harisudha, and S. Sreeram
Photo-Realistic Virtual Try-On with Enhanced Warping Module . . . . . .
851
Antony Alisha, C. V Amaldev, D. A Aysha Dilna, Sebastian Subin,
N. G Resmi, and G Sreenu
Convolutional Neural Networks Hyperparameters Optimization
Using Sine Cosine Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
863
Nebojsa Bacanin, Miodrag Zivkovic, Mohamed Salb,
Ivana Strumberger, and Amit Chhabra
A Novel Approach to Detect Low Quality Deepfake Videos . . . . . . . . . . .
879
Neeraj Guhagarkar, Sanjana Desai, Swanand Vaishampayan,
and Ashwini Save
Epileptic Seizure Detection Using Deep Bidirectional Long
Short-Term Memory Network . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
893
Mahima Thakur, U. Snekhalatha, M. Naveed Shaﬁ,
Saumya Raj Gupta, Sourabh Ranjan Roy, and S. Vineetha
Disease Detection in Crop Management Using Ensemble
Machine Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
907
J. Vakula Rani, Aishwarya Jakka, and Hamsini Kanuru
SVM, CNN and VGG16 Classiﬁers of Artiﬁcial Intelligence
Used for the Detection of Diseases of Rice Crop: A Review
. . . . . . . . . . .
917
Amit Verma

Contents
xvii
Smart Dark Pattern Detection: Making Aware of Misleading
Patterns Through the Intended App . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
933
S. Hrushikesava Raju, Saiyed Faiayaz Waris, S. Adinarayna,
Vijaya Chandra Jadala, and G. Subba Rao
Use of a Recurrent Neural Network to Identify Spammers
on Twitter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
949
Rahul A. Patil and Chetana C. Chaudhari
Computer-Aided Diagnosis of Pancreatic Ductal
Adenocarcinoma Using Machine Learning Techniques . . . . . . . . . . . . . . .
959
H. S. Saraswathi, Mohamed Raﬁ, K. G. Manjunath,
and Channa Krishna Raju
Application of Data Mining Technique for Retail Industry . . . . . . . . . . . .
973
Pradnya Abhay Muley
Online System for Identifying Need of Machine Maintenance
by Mining Data Streams and Handling Concept Drifts . . . . . . . . . . . . . . .
983
Rahul Patil, Pramod Patil, Aditya Ghongade, Adriel Dsa,
Parth Lokhande, and Harsh Munot
Hybrid Model for Sentiment Analysis Based on Both Text
and Audio Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
993
D. E. Tolstoukhov, D. P. Egorov, Y. V. Verina, and O. V. Kravchenko
Salesforce Vaccine for Real-Time Service in Cloud . . . . . . . . . . . . . . . . . . .
1003
Monika Mehra, Pradeep Jha, Himanshu Arora, Khushboo Verma,
and Himalaya Singh
Prediction of Inborn Talents Using Fingerprint Analysis . . . . . . . . . . . . .
1009
Maitreyi Pitale, Riya Kale, Manasi Khamkar, and Ujwala Ravale
Author Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1027

Editors and Contributors
About the Editors
Prof. Dr. Subarna Shakya is currently Professor of Computer Engineering, Depart-
ment of Electronics and Computer Engineering, Central Campus, Institute of Engi-
neering, Pulchowk, Tribhuvan University, Coordinator (IOE), LEADER Project
(Links in Europe and Asia for engineering, eDucation, Enterprise and Research
exchanges), Erasmus Mundus. He received M.Sc. and Ph.D. degrees in Computer
Engineering from the Lviv Polytechnic National University, Ukraine, 1996 and 2000,
respectively.Hisresearchareaincludese-governmentsystems,computersystemsand
simulation, distributed and cloud computing, software engineering and information
systems, computer architecture, information security for e-government, multimedia
systems.
Dr. Valentina Emilia Balas is currently Full Professor at “Aurel Vlaicu” University
of Arad, Romania. She is Author of more than 300 research papers. Her research
interests are in intelligent systems, fuzzy control, soft computing. She is Editor-in
Chief to International Journal of Advanced Intelligence Paradigms (IJAIP) and to
IJCSE. He is Member of EUSFLAT, ACM and a SM IEEE, Member in TC-EC and
TC-FS (IEEE CIS), TC-SC (IEEE SMCS), Joint Secretary FIM.
Dr. Sinchai Kamolphiwong is Director of CNR (Centre for Network Research),
Prince of Songkla University, Department of Computer Engineering, Songkhla, Thai-
land. He had completed his Ph.D. in the University of New South Wales, Australia.
He has secured awards and research grants in reputed organization. His research
interest includes computer networks, tele-medicine and real-time communications.
Dr. Ke-Lin Du is Research scientist at Center for Signal Processing and Communi-
cations, Department of Electrical and Computer Engineering, Concordia University,
since 2001, where he became Afﬁliate Associate Professor in 2011. His research
area includes signal processing, wireless communications and soft computing.
xix

xx
Editors and Contributors
Contributors
Beema Abdulkader Department of Computer Science & Engineering, Muthoot
Institute of Technology and Science, Ernakulam, India
Mohammad Zoynul Abedin Department
of
Finance
and
Banking,
Hajee
Mohammad Danesh Science and Technology University, Dinajpur, Bangladesh
D. Achish Department of Computer Science and Engineering, Koneru Lakshmaiah
Education Foundation, Vaddeswaram, Guntur, India
S. Adinarayna Department of CSE, Raghu Institute of Technology, Visakhap-
atnam, Andhra Pradesh, India
N. Advait Nitte Meenakshi Institute of Technology, Bengaluru, India
A. V. Akshaya LBS Institute of Technology for Women, Kerala, India
Mukil Alagirisamy Lincoln University College, Petaling Jaya, Selangor, Malaysia
Md Rasid Ali Indian Institute of Technology Kharagpur, Kharagpur, India
Antony Alisha Department of Computer Science and Engineering, Muthoot Insti-
tute of Technology and Science, Kochi, kerala, India
Athern Aloysius UCSI University, Cheras, Malaysia
C. V Amaldev Department of Computer Science and Engineering, Muthoot Insti-
tute of Technology and Science, Kochi, kerala, India
Chun Kit Ang UCSI University, Cheras, Malaysia
R. Anitha Department
of
Computer
Science,
S.T.E.T
Women’s
College
(Autonomous), Thiruvarur, India
R. Arockia Xavier Annie Computer Science and Engineering, CEG, Anna Univer-
sity, Chennai, Tamil Nadu, India
Kalaiselvi Aramugam UCSI University, Cheras, Malaysia
Himanshu Arora Department of CSE, Arya College of Engineering & Research
Centre, Jaipur, Rajasthan, India
Smegnew Asemie School of Computing and Informatics, Mizan Tepi University,
Tepi, Ethiopia
Aishwarya Asesh Adobe, Lehi, USA
K. Ashesh Department of Computer Science and Engineering, Koneru Lakshmaiah
Education Foundation, Vaddeswaram, Guntur, India
D. A Aysha Dilna Department of Computer Science and Engineering, Muthoot
Institute of Technology and Science, Kochi, kerala, India

Editors and Contributors
xxi
Manoj Ayyappan Department of Computer Engineering VESIT, Mumbai, India
Kassahun Azezew School of Computing and Informatics, Mizan Tepi University,
Tepi, Ethiopia
Disha Babaria Department Electronics and Telecommunication, SIES, Graduate
School of Technology, University of Mumbai, Navi Mumbai, India
Nebojsa Bacanin Singidunum University, Belgrade, Serbia
Shatabdee Bala Department of Computer Science and Engineering, Dhaka,
Bangladesh
Arnob Banerjee Department Electronics and Telecommunication, SIES, Graduate
School of Technology, University of Mumbai, Navi Mumbai, India
Khushboo Banjarey Department of Information Technology, National Institute of
Technology, Raipur, India
D. Lohith Bhargav Department of Computer Science and Engineering, Koneru
Lakshmaiah Education Foundation, Vaddeswaram, Guntur, India
Nikita Bhegade Pimpri Chinchwad College Of Engineering, Pune, India
Gokul Bisen Visvesvaraya National Institute of Technology, Nagpur, India
Vipin Bondre Yeshwantrao Chavan College of Engineering, Nagpur, MH, India
B. M Chaitra Master of Computer Applications, Nitte Meenakshi Institute of
Technology, Bengaluru, Karnataka, India
Snehal Chalke BE EXTC SIES GST, Mumbai, India
H. N. Champa University Visvesvaraya College of Engineering, Bangalore
University, Bengaluru, Karnataka, India
Sumesha Chandra Department of Computer Science, Delhi Technological Univer-
sity, New Delhi, India
Chetana C. Chaudhari Department of Computer Engineering, PCCOE, Pune,
Maharashtra, India
Vinayak Chaudhary Department of Computer Science, Delhi Technological
University, New Delhi, India
Vaishnavi Chavan Pimpri Chinchwad College Of Engineering, Pune, India
Amit Chhabra Guru Nanak Dev University, Amritsar, Punjab, India
Meril Cyriac LBS Institute of Technology for Women, Kerala, India
Yash Dahiya Department of Computer Science, Delhi Technological University,
New Delhi, India

xxii
Editors and Contributors
Ajit Danti Department of Computer Science and Engineering, Christ Deemed to
be University, Bengaluru, India
Bhaskarjyoti Das PES University, Bengaluru, Karnataka, India
Sweta Das Department of Computer Science & Engineering, Dr. Ambedkar Insti-
tute of Technology, Bengaluru, Karnataka, India
G. R. Deeba Lakshmi Faculty, Department of ECE, Nitte Meenakshi Institute of
Technology, Bangalore, India
Deisy Thiagarajar College of Engineering, Madurai, India
Sanjana Desai Computer Engineering Department, VIVA Institite of Technology,
Mumbai, India
Abhishek Deshpande Visvesvaraya National Institute of Technology, Nagpur,
India
R. Devi Department of Computer Science, VISTAS, Chennai, India
S. V. Gayetri Devi Department of Computer Science and Engineering, Bharath
Institute of Higher Education and Research, Chennai, India
Deepak Kumar Dewangan Department of Information Technology, National
Institute of Technology, Raipur, India
Prajakta Dhamanskar Fr. Conceicao Rodrigues College of Engineering, Bandra
West, Mumbai, India
Udayini Dikkala Lincoln University College, Petaling Jaya, Selangor, Malaysia
M. R Dileep Master of Computer Applications, Nitte Meenakshi Institute of
Technology, Bengaluru, Karnataka, India
Shatakshi Dixit Yeshwantrao Chavan College of Engineering, Nagpur, MH, India
Sakshi Doshi Department of Computer Engineering, Modern Education Society’s
College of Engineering, Pune, India
Adriel Dsa Department of Computer Engineering, Pimpri Chinchwad College of
Engineering, Pune, India
D. P. Egorov Kotel’nikov Institute of Radioengineering and Electronics of Russian
Academy of Sciences, Moscow, Russian Federation
Syed Abu Farooq Concordia University Chicago, Chicago, Illinois, USA
Krishna Gajera BE EXTC SIES GST, Mumbai, India
Sowmya Ganesan BE EXTC SIES GST, Mumbai, India
E. N. Ganesh Department of Electronics and Communication Engineering, Vels
Institute of Science, Technology & Advanced Studies, Chennai, India

Editors and Contributors
xxiii
N. Gangadhar Department of ME, Dr. Ambedkar Institute of Technology, Banga-
lore, Karnataka, India
Gurudatt Gaonkar Department of Computer Engineering VESIT, Mumbai, India
Anukriti Garg Department of Electronics and Communication Engineering, Delhi
Technological University, Delhi, New Delhi, India
T. V. Geetha UGC-BSR Faculty Fellow, Computer Science and Engineering, CEG,
Anna University, Chennai, Tamil Nadu, India
Priya George Department of Computer Science & Engineering, Muthoot Institute
of Technology and Science, Ernakulam, India
Meera Ghaskadvi Fr. Conceicao Rodrigues College of Engineering, Bandra West,
Mumbai, India
Aditya Ghongade Department of Computer Engineering, Pimpri Chinchwad
College of Engineering, Pune, India
Kalpana Ghorpade MKSSS’sCumminsCollegeofEngineeringforWomen,Pune,
Maharashtra, India
R. Gireesh Department of Computer Science, Vijayawada, Andhra Pradesh, India
Rozebud Gonsalves Fr. Conceicao Rodrigues College of Engineering, Bandra
West, Mumbai, India
S. Gowrishankar Department of Computer Science & Engineering, Dr. Ambedkar
Institute of Technology, Bengaluru, Karnataka, India
Neeraj Guhagarkar Computer Engineering Department, VIVA Institite of Tech-
nology, Mumbai, India
Aashuli Gupta Department Electronics and Telecommunication, SIES, Graduate
School of Technology, University of Mumbai, Navi Mumbai, India
Saumya Raj Gupta Department of Electronics and Communication Engineering,
Faculty of Engineering and Technology, SRM Institute of Science and Technology,
Chennai, Kattankulathur, India
J. Harikrishna Department of Computer Science, Vijayawada, Andhra Pradesh,
India
K. Harisudha SRM Institute of Science and Technology, Kattankulathur, Tamil
Nadu, India
Himanshu Department of Computer Science and Engineering, Delhi Technological
University, Delhi, India
Elias Hossain Department of Software Engineering, Daffodil International Univer-
sity, Dhaka, Bangladesh
B. A. Hrithik Devaiah Nitte Meenakshi Institute of Technology, Bengaluru, India

xxiv
Editors and Contributors
S. Indu Department of Electronics and Communication Engineering, Delhi Tech-
nological University, Delhi, New Delhi, India
Y. S. Ingle Department of Computer Engineering, Modern Education Society’s
College of Engineering, Pune, India
Muhammad Nazrul Islam Department of Computer Science and Engineering,
Military Institute of Science and Technology, Dhaka, Bangladesh
Teslin Jacob Goa College of Engineering, Farmagudi, Ponda, Goa, India
Vijaya Chandra Jadala Department of Computer Science and Engineering,
Koneru Lakshmaiah Education Foundation, Vaddeswaram, Guntur, Andhra Pradesh,
India
Advet Jadhav School of Electrical Engineering, MIT Academy of Engineering,
Pune, India
M. Jagadeeswari Department of Electronics and Communication Engineering, Sri
Ramakrishna Engineering College, Coimbatore, Tamil Nadu, India
Prashuk Jain Department of Computer Science and Engineering, Delhi Techno-
logical University, Delhi, India
Aishwarya Jakka University of Pittsburgh, Pittsburgh, PA, USA
Abu Zahid Md. Jalal Uddin Joy Department of Software Engineering, Daffodil
International University, Dhaka, Bangladesh
N. Jayanthi Department of Electronics and Communication Engineering, Delhi
Technological University, Delhi, New Delhi, India
B. Jency A. Jebamani Kalasalingam Academy of Research and Education, Srivil-
liputtur, Virudhunagar, Tamilnadu, India
Pradeep Jha Department of CSE, Arya College of Engineering & Research Centre,
Jaipur, Rajasthan, India
Richard Joseph Department of Computer Engineering VESIT, Mumbai, India
Tejsvi Juj Department of Electronics and Communication Engineering, Delhi
Technological University, Delhi, New Delhi, India
Riya Kale Department of Computer Engineering, SIES Graduate School of Tech-
nology, Mumbai, India
Mohammed Khalid Kaleem School of Computing and Informatics, Mizan Tepi
University, Tepi, Ethiopia
Jagadevi N. Kalshetty Nitte Meenakshi Institute of Technology, Bengaluru, India
N. Pavan Kalyan Department of Computer Science and Engineering, Koneru
Lakshmaiah Education Foundation, Vaddeswaram, Guntur, India

Editors and Contributors
xxv
Sayali Kanase Pimpri Chinchwad College Of Engineering, Pune, India
Hamsini Kanuru Mahatma Gandhi Institute of Technology, Hyderabad, India
Shreyas Kashetwar Pimpri Chinchwad College Of Engineering, Pune, India
Shreya Kendhe Department
of
Computer
Engineering,
Modern
Education
Society’s College of Engineering, Pune, India
Manasi Khamkar Department of Computer Engineering, SIES Graduate School
of Technology, Mumbai, India
M. K. A. Ahamed Khan UCSI University, Cheras, Malaysia
Md. Nasﬁkur R. Khan Automation, Application and Biomedical Based Technical
(AABTech) Lab, Dhaka, Bangladesh;
Department of Electrical and Electronic Engineering, Independent University,
Dhaka, Bangladesh
Arti Khaparde Dr. Vishwanath Karad MIT World Peace University, Pune, Maha-
rashtra, India
Sakshi Khochare Fr. Conceicao Rodrigues College of Engineering, Bandra West,
Mumbai, India
B. V. Kiranmayee Computer Science Department, VNR VJIET, Hyderabad, India
Ken Koshy Nitte Meenakshi Institute of Technology, Bengaluru, India
O. V. Kravchenko Bauman Moscow State Technical University, Moscow, Russian
Federation;
Federal Research Center “Computer Science and Control” of RAS, Moscow, Russian
Federation
A. Arun Kumar Professor, Department of Computer Science & Engineering,
Balaji Institute of Technology and Science, Warangal, India
J. Ravin Kumar CG VAK Software & Exports Ltd, Coimbatore, Tamil Nadu, India
S. Pradeep Kumar Kalasalingam Academy of Research and Education, Virudhu-
nagar, Tamil Nadu, India
Thomas Kuriakose Department of Computer Science and Engineering, Muthoot
Institute of Technology and Science, Kochi, India
N. Latha Department of Electrical and Electronics Engineering, REVA University,
Bengaluru, Mysuru, India
Wei Hong Lim UCSI University, Cheras, Malaysia
Aditi Limkar Department of Computer Engineering, Modern Education Society’s
College of Engineering, Pune, India

xxvi
Editors and Contributors
Omkar Loka Department of Computer Engineering, Pimpri Chinchwad College
of Engineering, Pune, India
Parth Lokhande Department of Computer Engineering, Pimpri Chinchwad
College of Engineering, Pune, India
Kunal Lotlikar Department Electronics and Telecommunication, SIES, Graduate
School of Technology, University of Mumbai, Navi Mumbai, India
Malcolm Andrew Madeira Goa College of Engineering, Farmagudi, Ponda, Goa,
India
Nachiket Mahamuni Department of Computer Engineering, Pimpri Chinchwad
College of Engineering, Pune, India
M. Malathi Department of Electrical and Electronics Engineering, NIE Institute of
Technology, Mysuru, India
Sridhar Manda Assistant Professor, Balaji Institute of Technology and Science,
Narsampet, Warangal, Telangana, India
Reshma Sri Sai Mangipudi Department of ECE, Matrusri Engineering College,
Hyderabad, Saidabad, India
C. S. Manikandababu Department of Electronics and Communication Engi-
neering, Sri Ramakrishna Engineering College, Coimbatore, Tamil Nadu, India
K. G. Manjunath Department of CS&E, Jain Institute of Technology, Davanagere,
India
Monika Mehra Department of CSE, Arya College of Engineering & Research
Centre, Jaipur, Rajasthan, India
S. Menaka Department of Computer Science and Engineering, SRM Institute of
Science and Technology, Chennai, India
Ritvik Mittal Department of Computer Science and Engineering, Delhi Techno-
logical University, Delhi, India
Md. Mizanur Rahman Department of Computer Science and Engineering,
Rajshahi University of Engineering and Technology, Rajshahi, Bangladesh
E. Syed Mohamed Department of Computer Science and Engineering, B. S. Abdur
Rahman Crescent Institute of Science and Technology, Chennai, India
Kezia Joseph Mosiganti Stanley College of Engineering and Technology for
Women, Abids, Hyderabad, India
Radha Mothukuri Department of Computer Science and Engineering, Koneru
Lakshmaiah Education Foundation, Guntur, Andhra Pradesh, India
Md. Muhaimenur Rahman Department of Computer Science & Engineering,
Jahangirnagar University, Dhaka, Bangladesh

Editors and Contributors
xxvii
Pradnya Abhay Muley PES Modern College of Engineering, Pune, India
Harsh Munot Department of Computer Engineering, Pimpri Chinchwad College
of Engineering, Pune, India
R. Murugeswari Kalasalingam Academy of Research and Education, Srivil-
liputtur, Virudhunagar, Tamilnadu, India
Shantunu Shakhwat Nadi Automation, Application and Biomedical Based Tech-
nical (AABTech) Lab, Dhaka, Bangladesh;
Department of Electrical and Electronic Engineering, Independent University,
Dhaka, Bangladesh
Md. Nadim Kaysar Department of Computer Science & Engineering, World
University of Bangladesh, Dhaka, Bangladesh
P. Nagaraj Kalasalingam Academy of Research and Education, Srivilliputtur,
Virudhunagar, Tamilnadu, India
Prajna Nagaraj PES University, Bengaluru, Karnataka, India
Aashish Nagpal Department of Computer Engineering VESIT, Mumbai, India
N. Nalini Professor, Department of Computer Science and Engineering, Nitte
Meenakshi Institute of Technology, Govindapura, Gollahalli, Yelahanka, Bangalore,
India;
Department of Computer Science and Engineering, Dr. M.G.R. Educational and
Research Institute, Chennai, India
Hieda A. Nascimento-Silva Faculty of Engineering, Telecommunication, Federal
University of Pará, Belem, Brazil
A. V Navaneeth Master of Computer Applications, Nitte Meenakshi Institute of
Technology, Bengaluru, Karnataka, India
Mahesh B. Neelagar Department of VLSI Design and Embedded Systems, VTU,
Belagavi, Karnataka, India
Manisha J. Nene Department of Computer Science & Engineering, Defense Insti-
tute of Advanced Technology, Pune, Maharashtra, India
Hrishikesh Nikam Department of Computer Engineering, Pimpri Chinchwad
College of Engineering, Pune, India
S. Nivash Department of Electronics and Communication Engineering, Vels Insti-
tute of Science, Technology & Advanced Studies, Chennai, India
Jatin Pardhi Visvesvaraya National Institute of Technology, Nagpur, India
Anil Singh Parihar Department of Computer Science and Engineering, Delhi
Technological University, Delhi, India

xxviii
Editors and Contributors
Nargis Parvin Bangladesh Army International University of Science and Tech-
nology, Cumilla, Bangladesh
Nita Patil BE EXTC SIES GST, Mumbai, India
Pramod Patil Department of Computer Engineering, Dr. D. Y. Patil Institute of
Technology, Pune, India
Pramod D. Patil Dr. D.Y. Patil Institute of Technology, Pimpri, Pune, India
Rachana Patil Department of Computer Engineering, Pimpri Chinchwad College
of Engineering, Pune, India
Rahul Patil Department of Computer Engineering, Pimpri Chinchwad College of
Engineering, Pune, India
Rahul A. Patil Department of Computer Engineering, PCCOE, Pune, Maharashtra,
India
Gaurav Pattewar Department of Computer Engineering, Pimpri Chinchwad
College of Engineering, Pune, India
Ajil Paul Department of Computer Science & Engineering, Muthoot Institute of
Technology and Science, Ernakulam, India
Surabhi Pawar Yeshwantrao Chavan College of Engineering, Nagpur, MH, India
Maitreyi Pitale Department of Computer Engineering, SIES Graduate School of
Technology, Mumbai, India
L. Poongothai Department of Computer Science, Dr. MGR Janaki College for
Women, Chennai, India
T. S. Murugesh Prabhu Centre for Development of Advanced Computing (C-
DAC), Pune, India
J. Pranitha Department of ECE, Matrusri Engineering College, Hyderabad, Said-
abad, India
Munjuluri Prathyusha Department of Computer Science and Engineering Koneru
Lakshmaiah Education Foundation, Vaddeswaram, Guntur, India
S. Preethi Department of Electronics and Communication Engineering, Sri
Ramakrishna Engineering College, Coimbatore, Tamil Nadu, India
B. Indira Priyadarshini Department of ECE, Matrusri Engineering College,
Hyderabad, Saidabad, India
R. Priyanka Department of Electronics and Communication Engineering, Sri
Ramakrishna Engineering College, Coimbatore, Tamil Nadu, India
Abdul Qayyum UMR CNRS 6285 LabSTICC, ENIB, Brest, France

Editors and Contributors
xxix
Mohamed RaﬁDepartment of CS&E, Jain Institute of Technology, Davanagere,
India
Md. Mahbubar Rahman Department of Computer Science and Engineering,
Military Institute of Science and Technology, Dhaka, Bangladesh
Md. Saifur Rahman Comilla University, Cumilla, Bangladesh
Rahul Department of ECE, Nitte Meenakshi Institute of Technology, Bangalore,
India
Utkarsh Rai School of Computer Engineering & Technology, MIT Academy of
Engineering, Pune, India
S. N. Vivek Raj KCT Business School, Kumaraguru College of Technology, Coim-
batore, India
Malisetty Rajeswari Department of Computer Science and Engineering Koneru
Lakshmaiah Education Foundation, Vaddeswaram, Guntur, India
Channa Krishna Raju Departmant of CS&E, UBDT College of Engineering,
Davanagere, India
S. Hrushikesava Raju Department of Computer Science and Engineering, Koneru
Lakshmaiah Education Foundation, Vaddeswaram, Guntur, Andhra Pradesh, India
K. Rakshith Nitte Meenakshi Institute of Technology, Bengaluru, India
Manicam Ramaswamy UCSI University, Cheras, Malaysia
J. Vakula Rani Department of MCA, CMR Institute of Technology, Bengaluru,
India
G. Subba Rao Department of Computer Science and Engineering, Koneru Laksh-
maiah Education Foundation, Vaddeswaram, Guntur, Andhra Pradesh, India
Hema Raut Department Electronics and Telecommunication, SIES, Graduate
School of Technology, University of Mumbai, Navi Mumbai, India
Ujwala Ravale Department of Computer Engineering, SIES Graduate School of
Technology, Mumbai, India
S. Prithiviraj Pallava Rayer KCT Business School, Kumaraguru College of Tech-
nology, Coimbatore, India
M. Yasmin Regina Department of Civil Engineering, B. S. Abdur Rahman Cres-
cent Institute of Science and Technology, Chennai, India
K. Sashi Rekha Department of Computer Science and Engineering, Saveetha
School of Engineering, Saveetha Institute of Medical and Technical Sciences,
Chennai, India
Pooja Reshim BE EXTC SIES GST, Mumbai, India

xxx
Editors and Contributors
N. G Resmi Department of Computer Science and Engineering, Muthoot Institute
of Technology and Science, Kochi, kerala, India
V. Rithika Department of Electronics and Communication Engineering, Sri
Ramakrishna Engineering College, Coimbatore, Tamil Nadu, India
Dipanwita Roy Chowdhury Indian
Institute
of
Technology
Kharagpur,
Kharagpur, India
Sourabh Ranjan Roy Department of Electronics and Communication Engi-
neering, Faculty of Engineering and Technology, SRM Institute of Science and
Technology, Chennai, Kattankulathur, India
Ch. Rupa Department of Computer Science and Engineering, VR Siddhartha
Engineering College, Vijayawada, Andhra Pradesh, India
Amal Sabu Department of Computer Science & Engineering, Muthoot Institute of
Technology and Science, Ernakulam, India
Anik Kumar Saha Department of Computer Science & Engineering, Bangladesh
University of Business and Technology, Dhaka, Bangladesh
Indra Kumar Sahu Department of Computer Science & Engineering, Defense
Institute of Advanced Technology, Pune, Maharashtra, India
Satya Prakash Sahu Department of Information Technology, National Institute of
Technology, Raipur, India
Mohamed Salb Singidunum University, Belgrade, Serbia
M. Saranya Computer Science and Engineering, CEG, Anna University, Chennai,
Tamil Nadu, India
H. S. Saraswathi Department of CS&E, Jain Institute of Technology, Davanagere,
India
Maheshwari Satpute School of Electrical Engineering, MIT Academy of Engi-
neering, Pune, India
Ashwini Save Computer Engineering Department, VIVA Institite of Technology,
Mumbai, India
Manoj Sethi Department of Computer Science, Delhi Technological University,
New Delhi, India
M. Naveed ShaﬁDepartment of Electronics and Communication Engineering,
Faculty of Engineering and Technology, SRM Institute of Science and Technology,
Chennai, Kattankulathur, India
N. F. Shaikh Department of Computer Engineering, Modern Education Society’s
College of Engineering, Pune, India

Editors and Contributors
xxxi
Asif Khan Shakir Department of Software Engineering, Daffodil International
University, Dhaka, Bangladesh
Subarna Shakya Institute of Engineering, Tribhuvan University, Lalitpur, Nepal
Sushil Shakya Institute of Engineering, Tribhuvan University, Lalitpur, Nepal
Selvanayaki Kolandapalayam Shanmugam Concordia
University
Chicago,
Chicago, Illinois, USA
C. Shanthi Department of Computer Science, VISTAS, Chennai, India
Ankit Sharma Department of Computer Science & Engineering, Defense Institute
of Advanced Technology, Pune, Maharashtra, India
K. Sharmila Department of Computer Science, VISTAS, Chennai, India
Tanvi Shetty Department of Computer Engineering VESIT, Mumbai, India
K. C. Shilpa Department of ECE, Dr. Ambedkar Institute of Technology, Banga-
lore, Karnataka, India
Anshika Shukla Department of ECE, Nitte Meenakshi Institute of Technology,
Bangalore, India
N. Shwetha Department of ECE, Dr. Ambedkar Institute of Technology, Bangalore,
Karnataka, India
P. Sijin University Visvesvaraya College of Engineering, Bangalore University,
Bengaluru, Karnataka, India
Himalaya Singh Department of CSE, Arya College of Engineering & Research
Centre, Jaipur, Rajasthan, India
U. Snekhalatha Department of Biomedical Engineering, Faculty of Engineering
andTechnology,SRMInstituteofScienceandTechnology,Chennai,Kattankulathur,
India
Sneha Sreedevi Department of Computer Science & Engineering, Muthoot Insti-
tute of Technology and Science, Ernakulam, India
G Sreenu Department of Computer Science and Engineering, Muthoot Institute of
Technology and Science, Kochi, kerala, India
Amrutha Sreeraj Department of Computer Science and Engineering, Muthoot
Institute of Technology and Science, Kochi, India
Ayswarya Sreeraj Department of Computer Science and Engineering, Muthoot
Institute of Technology and Science, Kochi, India
S. Sreeram Master of Engineering Electrical and Computer Engineering in Data
Science, Carleton University, Ontario, ON, Canada
Sridevi Thiagarajar College of Engineering, Madurai, India

xxxii
Editors and Contributors
Padmanabhuni Srujana Department of Computer Science and Engineering
Koneru Lakshmaiah Education Foundation, Vaddeswaram, Guntur, India
Ivana Strumberger Singidunum University, Belgrade, Serbia
Sebastian Subin Department of Computer Science and Engineering, Muthoot
Institute of Technology and Science, Kochi, kerala, India
M. E. Sunil Computer Science and Engineering, PESITM, Shivamogga, India
Usha Surendra Department of Electrical and Electronics Engineering, Christ
(Deemed to be University), Bengaluru, Mysuru, India
Chalumuru Suresh Computer Science Department, VNR VJIET, Hyderabad,
India
T. M. Veeragangadhara Swamy Department of CSE, RYMEC, V.T.U, Ballari,
Karnataka, India
Trupti Tale Yeshwantrao Chavan College of Engineering, Nagpur, MH, India
Poornima Taranath Department of Computer Science & Engineering, Dr.
Ambedkar Institute of Technology, Bengaluru, Karnataka, India
Mahima Thakur Department of Electronics and Communication Engineering,
Faculty of Engineering and Technology, SRM Institute of Science and Technology,
Chennai, Kattankulathur, India
Jency Thomas Department of Computer Science and Engineering, Muthoot Insti-
tute of Technology and Science, Kochi, India
Shefali Thoolkar Yeshwantrao Chavan College of Engineering, Nagpur, MH, India
Laghima Tiwari Department of Electronics and Communication Engineering,
Delhi Technological University, Delhi, New Delhi, India
D. E. Tolstoukhov OTPBank, Moscow, Russian Federation;
Bauman Moscow State Technical University, Moscow, Russian Federation
Anh Truong Ho Chi Minh City University of Technology—VNU-HCM, Ho Chi
Minh, Vietnam
Swanand Vaishampayan Computer Engineering Department, VIVA Institite of
Technology, Mumbai, India
N. Vani Department of CSE, RYMEC, V.T.U, Ballari, Karnataka, India
Megha Mary Varghese Department of Computer Science and Engineering,
Muthoot Institute of Technology and Science, Kochi, India
G. Sai Varsha Department of ECE, Matrusri Engineering College, Hyderabad,
Saidabad, India

Editors and Contributors
xxxiii
Y. V. Verina Bauman Moscow State Technical University, Moscow, Russian Feder-
ation
Amit Verma UniversityCentreforResearchandDevelopment,ChandigarhUniver-
sity, Mohali, Punjab, India
Khushboo Verma Department of CSE, Arya College of Engineering & Research
Centre, Jaipur, Rajasthan, India
Usha Verma School of Electrical Engineering, MIT Academy of Engineering,
Pune, India
S. Vinay Information Science and Engineering, PESCE, Mandya, India
S. Vineetha Department of Electronics and Communication Engineering, Faculty
of Engineering and Technology, SRM Institute of Science and Technology, Chennai,
Kattankulathur, India
Angel F. Vinueza-Naranjo Faculty of Engineering, Telecommunication, Pontiﬁcia
Universidad Católica del Ecuador, Quito, Ecuador;
Faculty of Engineering, Information Technology and Communication, Universidad
Nacional de Chimborazo, Riobamba, Ecuador
Jayavrinda Vrindavanam Faculty, Department of ECE, Nitte Meenakshi Institute
of Technology, Bangalore, India
Apeksha Wadibhasme School of Electrical Engineering, MIT Academy of Engi-
neering, Pune, India
Wahidur Rahman Department of Computer Science & Engineering, Mawlana
Bhashani Science and Technology University, Santosh, Bangladesh
Saiyed Faiayaz Waris Department of CSE, Vignan’s Foundation for Science,
Technology and Research, Vadlamudi, Guntur, Andhra Pradesh, India
G. Yashwanth Department of Computer Science and Engineering, Koneru Laksh-
maiah Education Foundation, Vaddeswaram, Guntur, India
Syed Yasmeen Department of Computer Science and Engineering Koneru Laksh-
maiah Education Foundation, Vaddeswaram, Guntur, India
Girishchandra R. Yendargaye Centre for Development of Advanced Computing
(C-DAC), Pune, India
Sarmila Yesmin Automation, Application and Biomedical Based Technical
(AABTech) Lab, Dhaka, Bangladesh;
Chittagong Medical College, Chittagong, Bangladesh
Miodrag Zivkovic Singidunum University, Belgrade, Serbia

Analysis of Healthcare Industry Using
Machine Learning Approach: A Case
Study in Bengaluru Region
Poornima Taranath, Sweta Das, and S. Gowrishankar
Abstract The huge collection of data under the domain of health informatics has
always been of crucial importance in giving insights into human health and its
sundry causes. With technology rising day after day, this data can be visualized
under different lights which are depicted in the following paper. Data analysis is the
answer to the challenges of the healthcare industry because of the plasticity offered
in implementing its techniques in various frameworks and technologies. A notion
about Machine learning and its association with big data has also been discussed
here. The Machine learning techniques have always made analysis better; with a
similar analogy, the paper gives a glimpse of ameliorating the patient’s lives who are
looking for healthcare facilities in the Bengaluru region.
Keywords Data analysis · Big data · Machine learning · Web scraping ·
Healthcare
1
Introduction
Big data in our present time can be viewed as voluminous data, with ever surging
increase in variety and velocity which can be used to address various problems we
could not be able to tackle before. It all started in the 1970s when the relational
database was being developed and used often for storage. When potential clients
discerned the value of the human footprint on the internet, many open source frame-
works like Hadoop, NoSQL later Spark were introduced to the market to capture
the data generated and utilize them in innumerable ways [1]. In the coming years
of machines, Internet of Things (IoT) will also be the largest contributor to the data
collected [2]. Data mining is also a popular technique for determining hidden patterns
based on different perspectives to categorize them into handy information [3]. It also
narrows down the systematic relationships between the variables and how they can
be manipulated. A major feature of data mining is predictive data mining i.e., is
P. Taranath · S. Das · S. Gowrishankar (B)
Department of Computer Science & Engineering, Dr. Ambedkar Institute of Technology,
Bengaluru, Karnataka 560056, India
e-mail: gowrishankarnath@acm.org
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_1
1

2
P. Taranath et al.
the prediction or to identify models that can predict the response of our interest.
Machine learning stands in tandem with the above technologies used for prediction
and analysis of Big Data [4]. Machines look for patterns in the data we provide either
based on observations or experiences, learning from those without being explicitly
programmed. Supervised, unsupervised, and reinforcement learning algorithms are
the methods of machine learning [5]. Amalgamating all the slices of technologies as
said above, we can have an immense amount of growth in strategies and development
in the area of healthcare.
The rest of the paper is organized as follows. Section two presents a literature
survey, the challenges involved during data acquisition are discussed in section three,
the various stages involved in successfully carrying out this project are described in
discussed in section four, the results are provided in the ﬁfth section and we ﬁnally
conclude the paper.
2
Literature Survey
In India, healthcare has always been under a grievance, mistreated with a lack of
resources and knowledge. In the last few decades, we have seen exponential advance-
ments in artiﬁcial intelligence and their application in deep learning [6], convoluted
neural networks and many more [7]. This rise in ease of access to the betterment
of systems has given a tremendous push in India to explore comprehensive medical
devices and treatments. Visualizing and analyzing scans and images is of high impor-
tance where deep learning can make a signiﬁcant impact. They have been applied to
MRI [8], ultrasound [9, 10], X-ray [11] and many more modalities Machine learning
for prediction of diseases based on user questions [12], diabetes and identifying
brain disorders [13] and cancer cells [14] are the current growth pyramids in the
health informatics arena. Multi-sensor fusion approaches [15] are being developed
for assistive medical technology. With an increase in IoT models, capturing values
from medical devices has paved the path for real-time analysis [16]. Other methods
like risk prediction algorithms [17] are also in the surge, especially in cancer detection
[18] and prognosis research ﬁeld. Coming over to the other topics like sentimental
and prediction analysis it has been reported that more than 7,000 papers have been
published on the subject since 2004 making it one of the fastest growing research
topics. The sentimental analysis also called opinion mining sometimes., is a way of
extracting attitudes from a text [19]. In 2002, a paper by Bang et al. titled “Thumbs
up? Sentiment Classiﬁcation using Machine Learning Techniques” [20] showed that
machinelearningpredictionoutperformedhumanpredictioninmoviereviews.Social
media platforms are presently used to get raw truth about anything as in the format
of reviews. Tumasjan et al. describe a way where they concluded the election poll
results using around 100,000 tweets which also showed that 40% of the tweets about
politics were only by the 4% of the users. Other technologies are being used and

Analysis of Healthcare Industry Using Machine Learning …
3
developed in tandem with the above techniques of machine learning, big data anal-
ysis, and deep learning [21]. Big data is used for summarizing the inputs, while the
latter is greatly used under NLP for analyzing the attributes and attitudes in the texts.
3
Challenges Faced During Data Acquisition
Collecting data from the internet according to our requirements is no easy task due
to the ample amount of non-standardized data availability [22]. Data preparation
and data reduction are the two components in this section. While data preparation is
focused on gathering useful information that is not out-of-bound or unrelated, data
reduction is about aggregating similar results from amorphous datasets to smaller
reliable clusters. The three domains that can provide us healthcare data are Patient’s
clinical data on web platforms and in hospitals, Trail data for research and develop-
ment, and government authorized datasets. This is the ﬁrst and foremost crucial step
in our project as it contains feature selection. This is the initial exploratory phase
where we ﬁnalize our predictors from the other candidate predictors. The data scraped
are from the websites that offer the patients reviews, comments, their worries, and
the relevance of their problems with the other patients on the platform. These all
diverse data are to be trimmed and suited according to our use cases. The presence of
invalid and blank errors in the data gathered is a common challenge in the analysis
platform but there are a few libraries such as NLTK that offer to take the burden
of giving individual attention for removal of verbs, prepositions, and also some of
our customized words. Health care is a sensitive matter which is often kept private
by patients hence this obliges us to gather information subjected to both legal and
ethical standards [23].
4
Methodology
The system implemented in the following paper consists mainly of two sections: web
scraping and data analysis. The data for analysis are obtained through sources cited
in the above section. Many equations, methods, and algorithms are applied to the data
according to our requirement using Python language with Jupyter Notebook as the
execution environment. The obtained results are further analyzed and stored in our
local environment. In Fig. 1, we depict the various stages of our project. It all begins
with understanding the challenges and requirements of the healthcare industry.

4
P. Taranath et al.
Fig. 1 Various stages of the
project
4.1
Web Scraping
The Web scraping is a technique used to extract desired information out of websites.
In our project, we have used Python’s BeautifulSoup library to extract and store
the obtained data in a JSON ﬁle. BeautifulSoup extracts data in HTML and XML
format, thus making it easier to break the code and get the regions of the ﬁle where the
desired data resides. The website used in our following project to gather healthcare
data is mouthshut.com, furthermore, Twitter API’S has also been used to scrape
tweets related to all hospitals in the region. Using the access tokens provided by the
Twitter platform we can obtain the tweets based on a search keyword along with
the region’s latitude and longitudinal extent value. The datasets contain reviews of
patients, their ratings, and opinions about the hospitals that are located in various
regions of Bengaluru. These datasets are in a raw format and must be cleansed to
perform analysis which is described in the below topics.

Analysis of Healthcare Industry Using Machine Learning …
5
4.2
Statistical Analysis
Python’s Pandas library provides a data structure called DataFrame which is used to
store the 2-D tabular format data scraped from the web. Other tools provided by the
Pandas library help us perform simple statistical analysis on the datasets. Libraries
likeNumpy,Matplotlib,Seaborn,Cufﬂinks,andPlotlyareusedfordatavisualization.
Questions like the most popular hospital in Bengaluru based on the number of patient
reviews per hospitals, the standard deviations of the ratings given to the hospital, the
most common words used by patients in their opinions about the hospital can be
answered. The correlations between the reviews and their corresponding ratings can
also be deduced using the above method.
4.3
Natural Language Processing
Natural Language Processing (NLP) can also be called linguistics science. As the
name suggests, in this technique we draw inference out of the natural language
that we use in text and speech. Machines learn and predict the usage of languages as
humans would, like to suggest search phrases based on keyword entry, autocomplete,
spellcheck, and many more. One of the most popular NLP techniques in current
business is the WordCloud which is often done using the NLTK and Scikit library.
WordCloud is an image that displays the frequency of words present in the collection
of texts. The more the frequency the bigger space the word occupies in the image. The
collection of words, phrases are cleansed using stopwords to remove the unwanted
prepositions and conjunctions, then WordCloud can be plotted using Matplotlib or
any other visual library. In our WordCloud, the image shows the word distribution
on the scraped healthcare data. The outlook of a hospital can be inferred by creating
a WordCloud on the review texts.
4.4
Sentimental Analysis
Sentimental Analysis is a method of determining the sentiment of a given text. It
is the most common text classiﬁer. Using this method, we can determine whether a
patient’s opinion is positive, negative, or neutral. This helps us in understanding the
overalloutlookofthehospital.WeﬁrstproceedwithcleaningthetextusingNLPtech-
nique. The SentimentAnalyzer() function expresses in numeric the positive, negative
and neutral ratios of the reviews. Tools like Doc2Vec provided by NLP are used to
convert the opinions into vectors thus enabling us to ﬁnd the similarities among
the opinions. Term Frequency Inverse Distribution Frequency (TF-IDF) is used to
classify features of utmost importance and display them. Density plots between the

6
P. Taranath et al.
positive and negative feedbacks are plotted for the hospitals. Random Forest Clas-
siﬁer, a Machine Learning algorithm is used to predict the positivity and negativity
of a review once we are done with training our model with the datasets. A Receiver
Operating Characteristic and a Precision-Recall curve for the above approach are
also plotted to check the validity of the model. Multinomial Naive Bayes, also a
Machine Learning algorithm for text categorization is used to predict the ratings of
an opinion. A confusion matrix is generated to check the righteousness of this model.
5
Results and Discussion
Data that is obtained from websites and social networks are prepared for analytics.
The data preparation methods include cleaning, transforming, and validating the
data. Natural Language Processing tools are used to lemmatize, tokenize and clean
the datasets. Now, this data is analyzed for deriving business related information and
knowledge that helps numerous patients in making good choices. This information
is displayed in the form of reports and charts. Therefore, it becomes a necessity to
incorporate data visualization tools and libraries. Matplotlib, Seaborn, and Plotly are
the most common libraries that are used in this project for visualization. Apart from
this, Machine Learning algorithms like Random Forest Classiﬁer and Multinomial
Naive Bayes are employed to perform sentiment analysis. The results of our analysis
are depicted and discussed further in detail.
The user shall get to know the most frequently used 20 English words in the
patients’ or customers’ reviews under the section hospital in a particular location
(Fig. 2). The opinions of the patients’ are subjected to NLP tools that reduce the
Fig. 2 Top 20 most frequent words

Analysis of Healthcare Industry Using Machine Learning …
7
opinions to contain only the most important words that are used by the patients to
describe hospitals. The same is plotted.
The number of reviews given by the patients to each hospital in the Bengaluru
region is shown in Fig. 3. This links us to the most popular and most visited hospital
in the region and can be used for further analysis as shown below.
The relation and variation between the good and bad reviews for a hospital are
given in Fig. 4. Based on the words in the comments and the sentiment scores, it can
be classiﬁed as either good or bad.
The relationship associated with the review length and review ratings is shown in
Fig. 5.
In Fig. 6, the heatmap graphical representation of the correlation between Figs. 3,
and 4 is depicted.
Fig. 3 Review count for the
ﬁrst 20 hospitals

8
P. Taranath et al.
Fig. 4 Good versus bad reviews
Fig. 5 Relation between text length and review ratings
Fig. 6 Correlation HEATMAP

Analysis of Healthcare Industry Using Machine Learning …
9
Fig. 7 WordCloud to depict
the pain and grievances of
the patients
In Fig. 7, the words with the higher frequency are shown in bigger font sizes while
the words with lower frequency are given in smaller font sizes based on its presence
in the data collected. It depicts the pain and grievances or satisfaction of the patients.
The standard deviation of the average of the review ratings given by patients for
each hospital is shown in Fig. 8.
The Area Under the Curve (AUC) and Average Precision (AP) shown in Fig. 9,
indicates the skill of our model trained using Random Forest Classiﬁer.
As seen in Fig. 10, the output value predicts whether the given review falls towards
the good or as a bad review spectrum based on the resultant number, between 1 and
5 where 1 is the lowest rating. This prediction is based on the Multinomial Naive
Bayes algorithm.
The ROC curve (Fig. 11) that is obtained by implementing Random Forest Clas-
siﬁer, shows the false alarm rate (false positive rate) versus the hit rate (false negative
rate) between the threshold of 0.0 and 1.0.
6
Conclusion
The paper presented the application of predictive and sentimental analysis in the
recent trend under the hospital domain. With terms like Big data, machine learning,
and data analysis being in the current trend there would be no surprise in the growth
of capital, new techniques, and technologies in the advent years. Evolving machine
learning algorithms that can compute better analysis with the least resource usage are
the desired path for the future. With increasing population and so with its patient’s

10
P. Taranath et al.
Fig. 8 Standard deviation of
the review ratings
data it is crucial to advance in medical analytics. Algorithms capable of overt results
on the ever diverse clinical data that can include and provide reliable insights on
diagnosis, predictions, medications, and symptoms are a promising answer to the
upcoming challenges in the healthcare industry. Pharmaceuticals, health insurance
industries, and hospitals collaborating with each other are essential for ameliorating
the patients and caregivers live as they can offer to provide their services as a package
to the end customers. The scope of future work for this project can be done in
different directions. We can build a platform that gives a deduction on any hospitals
in the country or the world for the end user, in order to achieve the above said
objectives, we need more collection of data and more analytical work on them.
The challenges addressed in the paper and the technical challenges that appear as
an obstacle for improvement, are to be looked on. Moreover, this ﬁeld has a huge
potential in affecting the daily lives of humans hence it has to be made sure it serves
its said purpose and is not misused.

Analysis of Healthcare Industry Using Machine Learning …
11
Fig. 9 Precision-recall curve
Fig. 10 Predicting a review as either good or bad
Fig. 11 Receiver operating characteristic curve

12
P. Taranath et al.
Acknowledgments The third author would like to acknowledge that this research work was
supported in part by the VGST grant of Govt. of Karnataka, India, under the RGS/F scheme.
References
1. Benlachmi, Y., & Hasnaoui, M. L. (2020). Big data and Spark: Comparison with Hadoop.
In 2020 Fourth World Conference on Smart Trends in Systems, Security and Sustainability
(WorldS4) (pp. 811–817).
2. Alkhabbas, F., Spalazzese, R., Cerioli, M., Leotta, M., & Reggio, G. (2020). On the deployment
of IoT systems: An ındustrial survey. In 2020 IEEE International Conference on Software
Architecture Companion (ICSA-C) (pp. 17–24).
3. Li, Y. (2020). Practice of machine learning algorithm in data mining ﬁeld. In 2020 International
Conference on Advance in Ambient Computing and Intelligence (ICAACI) (pp. 56–59).
4. Gupta, R. (2020). A survey on machine learning approaches and ıts techniques. In 2020 IEEE
InternationalStudents’ConferenceonElectrical,ElectronicsandComputerScience(SCEECS)
(pp. 1–6).
5. Ferdous, M., Debnath, J., & Chakraborty, N. R. (2020). Machine learning algorithms in health-
care: A literature survey. In 2020 11th International Conference on Computing, Communication
and Networking Technologies (ICCCNT) (pp. 1–6).
6. Srivastava, S., Soman, S., Rai, A., & Srivastava, P. K. (2017). Deep learning for health
ınformatics: Recent trends and future directions. In International Conference on Advances
in Computing, Communications and Informatics (ICACCI), Udupi, India, September 13–17
(pp. 1665–1670).
7. Nithya, I. (2017). Predictive analytics in healthcare using machine learning tools and tech-
niques. In IEEE International Conference on Intelligent Computing and Control Systems,
Madurai, India, June 15–16 (pp. 492–499).
8. Golkov, A. D., Sperl, J. I., Menzel, M. I., Czisch, M., Samann, P., Brox, T., & Cremers, D.
(2016, May). q-space deep learning Twelvefold shorter and model-free diffusion MRI scans.
IEEE Transactions on Medical ˙Imaging, 35(5), 1344–1351.
9. Huynh, B., Drukker, K., & Giger, M. (2016). Computer-aided diagnosis of breast ultrasound
images using transfer learning from deep convolutional neural networks. International Journal
of Medical Physics and Practice, 43(6), 3705–3705.
10. Zamﬁr, M., Florian, V., Stanciu, A., Neagu, G., Preda, S., & Militaru, G. (2016). Towards a
platform for prototyping ˙IoT health monitoring services. Springer International Conference on
Exploring Services Science, Lecture Notes in Business Information Processing, 247, 522–533.
11. Mancini, A., Frontoni, E., & Zingaretti, P. (2015). Embedded multisensor system for safe
point-to-point navigation of impaired users. IEEE Transactions on Intelligent Transportation
Systems, 16(6), 3543–3555.
12. Travé-Massuyèsab, L. (2014). Bridging control and artiﬁcial intelligence theories for diagnosis:
A survey. Elsevier Engineering Applications of Artiﬁcial Intelligence, 27(27), 1–16.
13. Sirinukunwattana, K., Raza, S. E. A., Tsang, Y.-W., Snead, D. R., Cree, I. A., & Rajpoot, N.
M. (2016). Locality sensitive deep learning for detection and classiﬁcation of nuclei in routine
colon cancer histology images. IEEE Transactions on Medical Imaging, 35(5), 1196–1206.
14. Basole, R. C., Braunstein, M. L., & Sun, J. (2015). Data and analytics challenges for a learning
healthcare system. ACM Journal of Data and Information Quality (JDIQ), 6, 1–4.
15. Nie, L., Wang, M., Zhang, L., Yan, S., Zhang, B., & Chua, T.-S. (2016). Disease inference
from health-related questions via sparse deep learning. IEEE Transactions on Knowledge and
Data Engineering, 27(8), 2107–2119.
16. Pavel, M., Jimision, H. B. et al. (2015). Behavioral ınformatics and computational modeling
in support of proactive health management and care. IEEE Transactions on Biomedical
Engineering, 62(12), 2763–2775.

Analysis of Healthcare Industry Using Machine Learning …
13
17. Das, J., Gayvert, K. M., Yu, H. (2014). Predicting cancer prognosis using functional genomics
data sets. Cancer Informatics, 13(5), 85–88.
18. Liu, B. (2010). Handbook chapter: Sentiment analysis and subjectivity. Handbook of natural
language processing. In Handbook of natural language processing. Taylor and Francis.
19. Pang, B., Lee, L., & Vaithyanathan, S. (2002). Thumbs up? Sentiment classiﬁcation using
machine learning techniques. In Conference on Empirical Methods in Natural Language
Processing, (pp. 79–86).
20. Tumasjan, A., Sprenger, T. O., Sandner, P. G., & Welpe, I. M. (2010). Predicting elections with
twitter: What 140 characters reveal about political sentiment. Fourth International ICWSM,
10(1), 178–185.
21. Holzinger, A. (2016). Machine learning for health informatics. In Machine learning for health
ınformatics, lecture notes in artiﬁcial ıntelligence (pp. 1–24). Springer International Publishing.
22. Drukker, C. A. (2014). Optimized outcome prediction in breast cancer by combining the 70-
gene signature with clinical risk prediction algorithms. Springer Journal of Breast cancer
research and treatment, 145(3), 697–705.
23. Anavi, Y., Kogan, I., Gelbart, E., Geva, O., & Greenspan, H. (2016). Visualizing and enhancing
a deep learning framework using patients age and gender for chest x-ray image retrieval. In
SPIE Medical ımaging. International Society for Optics and Photonics.

Dynamic Document Localization for
Efﬁcient Mining
P. Sijin
and H. N. Champa
Abstract Annotation is the process of adding notes about an entity such as docu-
ments, attributes, data repositories and data spaces to make them more visible and
expressive. In probabilistic data models, it is used for generating values for attributes
which could be used for generating a range of queries which are matched with a
database schema. The proposed fuzzy document localization model (FDLM) lists out
the top-k attributes by deriving a monotone fuzzy rank function based on query value
Qval and content value Cval. The newly arrived documents are processed with the
annotated documents which are conditionally modeled with ground truth attributes in
a dynamic document categorization process. The semantic matches of attributes are
identiﬁed by a pre-processed conceptualization framework this in turn increases the
cardinality of result set. The system is biased with a biasing parameter β in order to
maintain a balance with workload-based query value and database-oriented content
value to set a selection bound over the range of accurate and approximate matches.
Keywords Conﬁdent segment · Query value · Content value · Data space ·
Annotation · Workload
1
Introduction
Annotated documents are used to generate attribute values which are of user inter-
est. It can be classiﬁed into un-typed keyword annotation (Cyclone wind = 85),
attribute value pairs (Cyclone wind, 85), pre-determined schema with potential
ﬁelds ((Cyclone wind, 85), (Cyclone type = ‘tropical’), (depression date = Nov
30) ...., (damage = ‘unknown’)), pre-determined schema with basic annotation ﬁelds
((Cyclone wind, 85), (depression date = Nov 30), (damage = ‘unknown’)). Many
systems do not have attribute-value pair combinations so the ﬁrst two methods are
not always feasible. Numerous ﬁelds may occur in a pre-determined schema. So
P. Sijin (B) · H. N. Champa
University Visvesvaraya College of Engineering, Bangalore University,
Bengaluru, Karnataka, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_2
15

16
P. Sijin and H. N. Champa
analysis and querying are cumbersome in third approach. Fourth approach uses a
limited set of attributes and shows feasible performance. But it is lagging in answer-
ing approximate querying and achieving query conceptualization.
Many attribute insertion softwares are existing which would use an adaptive
attribute insertion form to collect user concerned attributes about a document. A
form is such a simple initiative query interface which determines the usefulness and
availability of data in a database. Form interface design requires careful analysis of
data content and user interests over the query. Since form is a set of query agent to
the complex database hierarchy it should be optimal and diversed to answer areas of
potential interest in a repository called workloads. The form set should be expres-
sive with a wide range of queries and within the limit of constrained-based interface
complexity. Form generation process is either static or dynamic. CGI Scripts, Cold
Fusion, Active Server Pages (ASP) are used for dynamic script generation process. In
automated E-form development process an XML DTD can use with supporting soft-
ware tools for validation, navigation, multilingualism and calculation [1–3]. Before
preparing an insertion form for an unstructured document or for documents which
are vague or short in nature the system should be careful about the global and local
context of the document and its fuzzy relation with the application domain [4, 5].
Figure1 gives the pictorial representation of an unstructured document which
gives the information about the tropical cyclone Burevi which made landfall in India
and Sri Lanka recently. It is a cumbersome work for Information Retrieval (IR) and
Database Querying (DB) to work on such ﬁles. The modern Query modeling systems
use DB approach enriched with powerful query languages such as XPath and XQuery
and IR approaches to eliminate unwanted structures in the query [6–8]. It is difﬁcult
for a query analyzing system to fetch out the information from Fig.1 due to informal
writing style, limited length and abbreviated sentences which require smoothing
method to get the likely hood predicates for the queries [9, 10]. The document in
Fig. 1 An informal document about cyclone Burevi

Dynamic Document Localization for Efﬁcient Mining
17
Fig. 2 Proper annotation for
the document about cyclone
Burevi
Fig.1. contains the important attributes ((Cyclone wind, 85), (depression date = Nov
30), (damage = ‘unknown’) which are prepossessed for ‘Burevi’ by domain experts
but the document is undetected or not properly classiﬁed due to the ambiguity arise
in global and local context of document during search. In order to avoid this problem
proper annotation forms such as descriptive, summarized, or evaluated values can
be used to express the intent of the queries. Figure2 lists out the proper annotation
for Fig.1 which is used for metadata generation for Fig.1 document. Annotation
improves the quality of search and can fetch out most relevant documents for a
query. In a dynamic environment, annotation helps to categorize a new document to
the desired topic by probabilistic modeling of query with annotated documents in
a workload environment. The following queries are beneﬁted from the annotation
speciﬁed in Fig.2.
Q1: Cyclone name= “Burevi” AND type = “tropical”.
Q2: Cyclone Category = 1.
Q3: Cyclone name = “Burevi” AND date “4 Dec to 8 Dec”.
Whenever a new document is uploaded to the data repository the proposed FDLM
model uses Bayes and Bernoulli methods to analyze it and identify the important
attributes. These attributes are used to represent the documents and generate basic
fuzzy attributes for the original attributes and attributes having high probability to
divert the documents to a database schema or a data space for achieving semantic
integration to produce top-k attributes. A monotonically increasing function is used to
combine Qval and Cval to produce ﬁnal values for attributes and hence the documents
can categorize accordingly.
2
Literature Review
Machine learning (ML) is a method of data analysis which enables a system to
learn from data using algorithms, artiﬁcial intelligence tools, learned prototypes
and efﬁcient data representation methods [11, 12]. Data mining is the process of
formulating rules and associations to localize the desired patterns by applying ML
and various data models [13–17] with data summarization methods [18–20]. The
ML evaluated data is used in industrial line to produce products and parts having
high throughput, low cost and more reliability [21–24].
Query forms are used to represent the schema of queries which are related to the
attribute, value names in a database. The schema can be prepared either from database
or from query workload. It is possible to model the dependencies in a workload
environmentwithminimumeffortbyreducingthenumberofqueryoptimumattribute
list [25, 26]. Form generation process is either static or dynamic.

18
P. Sijin and H. N. Champa
The existing automated information extraction algorithms are facing problems
when the documents do not have targeted information, or percentage of relevant
information is less. In such situations they have to perform unnecessary computation
and to met with false positives [27–29]. The proposed approach used a pre-processed
fuzzy conceptualization model (FCM) to generate semantic alternatives for basic
attributes [10, 30, 31].
In language models, a new word is predicted by looking at m predecessors words
and interpolated the n-gram model with a unigram model in a linear fashion and
probabilistic dependencies between the predecessors can also identiﬁed [32]. The
FDLM is probabilistic in nature and it achieves forecaster evidences from multiple
sources on conditional basis followed by a normal distribution.
According to [33–36] combining the attribute grade by using a monotonic aggre-
gation function the grade for each object can calculate. In such a scenario each object
has multiple grades corresponding to attributes and attributes maintain a sorted list to
show its association with various accessing points. The FDLM used optimal sorted
algorithm called Fuzzy threshold algorithm to sort out attribute grades [37, 38].
3
Methodology
The proposed Query-Content Inference model achieves an outlier score for attributes
in order to become part of an annotation framework by following Bayer’s and
Bernoulli strategies. The model took the query and contents to an information of
need called workload and formed an abstract annotation model. Table1 lists out the
notations used in this paper.
The pre-determined schema with basic annotation as mentioned in Introduction
part is used for document annotation. There are four documents and their corre-
sponding annotations are given in Table2. The document doc5 is newly added to the
database. The selected attributes are city and relief. Table3 lists out the information
need called workload.
3.1
Probabilistic Model for Query-Workload
The query value for an attribute A j is calculated as the likely hood of fetching A j
in the given workload WL as given in (1). The fuzzy set of attribute A j is given as
Afs j where j is in the range of 0-k. The members of set Afs j is represented with a
variable fuzzyval j.
Qval =
P(A j/WL)
1 −P(A j/WL)
(1)
where

Dynamic Document Localization for Efﬁcient Mining
19
Table 1 Notations used
Notation
Meaning
Ai
Attributes in annotated data of WL∪R
A j
Attributes in Ai where A j ⊆Ai
WL
Workload
R
Repository
doc
Documents
doct
Document text for D
doca
Document annotation for D
docresult
Complete and optimal annotation for doc
w
Words in document
Rankv
Ranking Function
DBA
Database
DBA j
Database document annotated with A j
DBA j,w
Database document annotated with A j that
contains word w
Qval
Query value
Cval
Content value
WLA j
Workload document contains A j
fuzzyval j
The FCM values of semantically related
attributes of A j
Table 2 Documents and their corresponding annotations
Document ID
Content
Annotation
doc1
Cyclone Burevi depression
ﬁfty mph
Cyclone: Burevi,depression
speed: 50 mph
doc2
Damaged food crops Tamil
Nadu
Reported Damage: food crops,
City: TN
doc3
Water ﬂood Jafna DM, Sri
Lanka
Relief: water ﬂood area: Jafna
DM,
School: Jafna DM City: Sri
Lanka
doc4
Flood affected Sri Lanka
relief: Flood City: Sri Lanka
doc5
Result of ﬂood at Tamil Nadu
DM

20
P. Sijin and H. N. Champa
Table 3 Information need
Query
State: Puducherry, area: Tamil Nadu South DM
Area: Vavuniya District, City: Sri Lanka
Area: Jaffna High School, relief: water
School: Open, school: Jaffna DM
State: Puducherry, damage: 5000 displaced
Area: Northern province area, relief: water
P(A j/WL) = WLA j + 1
WL + 1
The fuzzy set Afs j contains the FCM values for all semantically matched values of
A j and it is calculated as
Qvali = fuzzyval j ∗
P(A j/WL)
1 −P(A j/WL)
(2)
Query value for attribute ‘City’ is calculated as
WLA j + 1
WL + 1
= 1 + 1
6 + 1 = 2
7 = 0.29
Qval,City =
0.29
1 −0.29 = 0.29
0.71 = 0.40
Suppose FCM (City, Town, 0.9) shows the attribute ‘City’ is related to attribute
‘Town’ in the given domain with an effective coefﬁcient value of 0.9, so Qval,Town is
calculatedasfuzzyvalj ∗Qval = 0.9 ∗0.40 = 0.36.Thisapproachwillproducemore
number of attributes and is used for query approximation.
Similarly Query value for attribute ‘relief’ is calculated as
WLA j + 1
WL + 1
= 2 + 1
6 + 1 = 3
7 = 0.42
Qval,relief =
0.43
1 −0.43 = 0.43
0.57 = 0.75

Dynamic Document Localization for Efﬁcient Mining
21
3.2
Probabilistic Model for Content-Workload
The probability of observed co-occurrence of an attribute to each word in the doc-
ument provides the content value of document for the given word and is given in
(3).
Cval = w∈doct P
 w
A j

(3)
where
P
 w
A j

=
DBA j,w + 1
DBA j + DB + 1
The content value for attribute ‘City’ with term ‘ﬂood’ in the newly arrived document
is calculated as
P
ﬂood
City

=
DBA j,w + 1
DBA j + DB + 1 =
2 + 1
3 + 4 + 1 = 3
8 = 0.375.
Similarly with other words the content value is calculated as result = 0.25, Tamil
Nadu = 0.25, DM = 0.25). The probability of observed non co-occurrence of an
attribute to each word in the document provides the content value of document for
the given word and is given in (4).
P

w
A j

=
DBA j, w + 1
DBA j + DB + 1
(4)
The content value for negated attribute City with term ‘ﬂood’ in the newly arrived
document is calculated as
P
 f lood
City

=
DBA j, w + 1
DBA j + DB + 1
=
0 + 1
1 + 4 + 1 = 1
6 = 0.17
Similarly with other words the negated content value is calculated as result = 0.17,
Tamil Nadu = 0.17, DM = 0.17). The overall content value for City is given as
Cval,City =
w∋doct P

w
A j

w∋doct P

w
A j
 = 0.375 ∗0.25 ∗0.25 ∗0.25
0.17 ∗0.17 ∗0.17 ∗0.17 = 7.59.
(5)
Similarly the overall content value for relief is given as
Cval,relief =
w∋doct P

w
A j

w∋doct P

w
A j
 = 0.42 ∗0.28 ∗0.14 ∗0.28
0.14 ∗0.14 ∗0.28 ∗0.14 = 6.
(6)

22
P. Sijin and H. N. Champa
The overall content value for ‘Town’ a semantic match for ‘City’ is given as
Cfuzzyval,Town = 7.59 ∗0.9 = 6.831.
The overall content value for ‘Supplies’ a semantic match for ‘relief’ is given as
Cfuzzyval,Supplies = 6 ∗0.85 = 5.1.
A ranking function is used calculate the total score for an attribute. The ranking
function is a fuzzy monotone function and is given as
Rankval = Qval ⊗Cval
(7)
According to (7) the RankCity = 0.4 ∗7.59 = 3.03 and Rankrelief = .75 ∗6 = 4.5.
Similarly for the fuzzy terms RankTown = 0.36 ∗6.83 = 2.45 and RankSupply =
0.63 ∗5.1 = 3.21.
3.3
Bernoulli Model for Rank Calculation
According to this model, each forecaster provides an independent view of annotation.
SupposeattributeAj presentinadocumentandavariablewithdistributionbisdeﬁned
to model the occurrence of the event of speciﬁed attribute present in the document
as a Bernoulli experiment and is given in (8).
b
 A j
WL, doct, Pr

= β1.bw + β2.bd
(8)
where the query value bw is calculated as same as (1) and content value bd is calcu-
lated from (3) with modiﬁcations and is given in (9).
bd(A j) = P(A j).w∋doct P
 w
A j

(9)
P(A j) = DBA j + 1
DB + 1
(10)
From (3), (9) and (10) the content values obtained for City is 0.004 and relief is
0.002. According to (8) the Bernoulli rank for attributes are given as
b
City
WL , doct, Pr

= β ∗0.28 + (1 −β) ∗0.004

Dynamic Document Localization for Efﬁcient Mining
23
b
relief
WL , doct, Pr

= β ∗0.43 + (1 −β) ∗0.002
when the β exceeds 0.6 the attribute relief and it’s fuzzy attributes are getting higher
rank.
4
Fuzzy Threshold Algorithms
It is clear from the previous section that whenever a new document arises it is anno-
tated and allowed to process with query workload to obtain query value. The content
value is measured as the ratio of probabilities of co-occurred to not co-occurred
attribute-words pairs. A fuzzy monotone function with or without forecaster evi-
dences is used to combine them. FDLM uses a pipe-lined approach for document
localization and hence it needs conﬁdent or seed attributes as input to proceed for efﬁ-
ciency concerns. The proposed fuzzy threshold algorithm deﬁnes a threshold function
τ to combine Qval and Cval and continuously adding new attributes to result set and
is given below in Algorithm 1. This rich set is using for document categorization.
Algorithm 1 reads the attributes from annotated form of the query and prepares a
result set of attributes and its pre-processed fuzzy set. Workload-based query value
and database orient content values are calculated to rank the attributes. The same
process is repeated for their respective fuzzy terms. The order of rank can change by
adjusting β in FDLM system. If the attribute rank is more than threshold value τ then
these attributes are used for further processing which is pipe-lined with processing
of the old top values in the result set. This process continues with upcoming more
and more conﬁdent segments.
Algorithm 1: Fuzzy threshold algorithm to calculate result set instance
Data: The search query and the annotated keywords or attributes, workload and word
corpus.
Result: The result set Resulti for a particular instance of time period.
initialization;
1. Choose the attributes Aj from annotated forms where j=0-n
identify its fuzzy set.
2. Calculate Qval as given in (2)
3. Calculate Cval as given in (3)
4. Setup a set called Resulti as given in (8)
5. Identify the best range of Aj by setting β.
6. If a new attribute Ak for which Ak ≥τ
return Resulti
7. else go to step 1.

24
P. Sijin and H. N. Champa
5
Experimental Analysis
The proposed model produces the best set of attributes which can use for document
annotation. The proposed pipeline approach performs the annotation and also local-
izes the newly arrived documents by running a fuzzy-oriented algorithm based on
QV and CV. In experimental analysis, the effect of precision and recall over the
dataset with different query suggestions are identiﬁed. The role of biasing parame-
ter β on Bernoulli model is iterated over CNET and Amazon datasets. Finally, the
effect of size of training dataset is studied for approximate and actual matches. Two
datasets are used for experimental analysis namely CNET and Amazon. The CNET
corpus consists of 4840 electronic product reviews obtained from CNET. It contains
different kinds of products like cameras, video games, television, audio sets, and
alarm clocks. The Amazon Products corpus consists of 19,700 documents down-
loaded from Amazon. It also included electronic products, books, and other items
which are sell at Amazon.
5.1
Effect of Attribute Suggestion to Determine Precision
and Recall
The quality of suggested attributes for a document could be measured with the ground
truth attribute set. The precision and recall metrics is used to reﬂects the effect. The
content value-based approach and Fuzzy Document Localization Approach show
comparatively good results since the former works on document workload and the
later consider semantic matches on query workload. Figures3 and 4 show results for
CNET and Figs.5 and 6 show results for Amazon datasets.
Fig. 3 Precision for CNET
dataset

Dynamic Document Localization for Efﬁcient Mining
25
Fig. 4 Recall for CNET dataset
Fig. 5 Precision for Amazon dataset
Fig. 6 Recall for Amazon dataset

26
P. Sijin and H. N. Champa
Fig. 7 Effect of beta in
CNET
Fig. 8 Effect of beta in
Amazon
5.2
Effect of Biasing Coefﬁcient for Determining Attribute
Matches
In Bernoulli strategy β, the biasing coefﬁcient is used to stabilize the number of
partial and full attribute matches. In FDLM along with ground truth attributes the
fuzzy set is used which in turn increase the optimum result set size and is shown for
CNET in Fig.7 and Amazon in Fig.8.
5.3
Effect of Database Size for Determining Precision
The precision increases when the training size increases. The CV approach com-
pletely depends on database the effect is high. Similarly in FDLM the approximate
and semantic matches are more and hence precision increases Fig.9 shows this for
CNET and Fig.10 shows this for Amazon.

Dynamic Document Localization for Efﬁcient Mining
27
Fig. 9 Effect of data size in CNET
Fig. 10 Effect of data size in Amazon
6
Conclusion
The proposed Fuzzy document localization model ranked the attributes and produced
the best set of attributes which could be used for document annotation. The annotated
documents are very expressive and visible to user. The FCM-based fuzzy set provides
an exclusive attribute set which are relevant and semantically matched to the ground
truth attributes. The proposed fuzzy evaluation function combines workload-based
query values with data content values to produce top-k attributes which could be used
for further query suggestions. The pre-processed fuzzy set can easily added to the

28
P. Sijin and H. N. Champa
given model and could produce range of values biased with a biasing parameter called
β. The fuzzy threshold algorithm is used to put a limit on conﬁdent input segments
and achieves parallelism in computation. In order to avoid additional computation
over head if any the fuzzy set with very effective assessment coefﬁcient values with
selected attributes are used. FDLM offers a data annotation platform for other query
search services to work on. The system can effectively change the order of selection
by adjusting β in some favored cases. Even though annotation is efﬁcient in usage it
induces some extra communication overhead which can avoid by incorporating fully
automated prepossessed datasets and services.
References
1. Helm, D. J., & Thompson, B. W. (2001). An approach for totally dynamic forms processing in
web-based applications. In ICEIS (pp. 974–977).
2. Tornqvist, N. C., & Johnson, A. M. (1999). XML and Objects-the Future of the E-forms on
the Web (pp. 303–308).
3. Jeffery, S. R., Franklin, M. J., & Halevy, A. Y. (2008). Pay-as-you-go user feedback for datas-
pace systems (pp. 847–860).
4. Li, C., Sun, A., Weng, J., & He, Q. (2015). Tweet segmentation and its application to named
entity recognition. IEEE Transactions on Knowledge and Data Engineering, 27(2), 558–570.
5. Yu, Z., Wang, H., Lin, X., & Wang, M. (2016). Understanding short texts through semantic
enrichment and hashing. IEEE Transactions on Knowledge and Data Engineering, 28(2), 566–
579.
6. Schmidt, A., Kersten, M., & Windhouwer, M. (2001). Querying XML documents made easy:
Nearest concept queries (pp. 321–329).
7. Fuhr, N., & Grosjohann, K. (2001). XIRQL: A query language for information retrieval in
XML documents (pp. 172–180).
8. Schutze, H., Manning, C. D., & Raghavan, P. (2008). Introduction to information retrieval, 39.
9. Chen, S. F., & Goodman, J. (1999). An empirical study of smoothing techniques for language
modeling. Computer Speech Language, 13(4), 359–394.
10. Ruiz, E. J., Hristidis, V., & Ipeirotis, P. G. (2014). Facilitating document annotation using
content and querying value. IEEE Transactions on Knowledge and Data Engineering, 26(2),
336–349.
11. Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efﬁcient estimation of word represen-
tations in vector space. Cornell University Library.
12. Sijin, P., Champa, H., & Venugopal, K. (2017). A survey on intent-based diversiﬁcation for
fuzzy keyword search. International Journal of Computer Science and Information Technolo-
gies, 8(6), 602–618.
13. Liu, J., & Yan, D. (2016). Answering approximate queries over XML data. IEEE Transactions
on Fuzzy Systems, 24(2), 288–305.
14. Li, J., Liu, C., & Yu, J. X. (2015). Context-based diversiﬁcation for keyword queries over XML
data. IEEE Transactions on Knowledge and Data Engineering, 27(3), 660–672.
15. Wang,L.(2017).Heterogeneousdataandbigdataanalytics.AutomaticControlandInformation
Sciences, 3(1), 8–15.
16. Chiang, I. J., Liu, C. C. H., Tsai, Y. H., & Kumar, A. (2015). Discovering latent semantics in web
documents using fuzzy clustering. IEEE Transactions on Fuzzy Systems, 23(6), 2122–2134.
17. Sestakova, E., & Janousek, J. (2018). Automata approach to XML data indexing. Information,
9(1), 12.

Dynamic Document Localization for Efﬁcient Mining
29
18. Dou, Z., Jiang, Z., Hu, S., Wen, J.-R., & Song, R. (2016). Automatically mining facets for
queries from their search results. IEEE Transactions on Knowledge and Data Engineering,
28(2), 385–397.
19. Zhao, R., & Mao, K. (2017). Fuzzy bag-of-words model for document representation. IEEE
Transactions on Fuzzy Systems.
20. Kusner, M., Sun, Y., Kolkin, N., & Weinberger, K. (2015). From word embeddings to document
distances (pp. 957–966).
21. Liu, J., Wang, K., & Fung, B. C. (2016). Mining high utility patterns in one phase without
generating candidates. IEEE Transactions on Knowledge and Data Engineering, 28(5), 1245–
1257.
22. Tseng, V. S., Wu, C.-W., Fournier-Viger, P., & Philip, S. Y. (2016). Efﬁcient algorithms for
mining top-k high utility itemsets. IEEE Transactions on Knowledge and Data Engineering,
28(1), 54–67.
23. Suma, V., & Hills, S. M. (2020). Data mining based prediction of demand in Indian market for
refurbished electronics. Journal of Soft Computing Paradigm (JSCP), 2(03), 153–159.
24. Raj, J. S. (2020). Machine learning implementation in cognitive radio networks with game-
theory technique. Journal: IRO Journal on Sustainable Wireless Systems, 2020(2), 68–75.
25. Koshti, S., Sen, A., & Jadhav, V. (2017). Dynamic Query Forms (DQF) using ranking models
for database queries (pp. 365–370).
26. Jayapandian, M., & Jagadish, H. (2008). Automated Creation of a Forms-based Database Query
Interface. Proceedings of the VLDB Endowment, 1(1), 695–709.
27. Jain, A., & Ipeirotis, P. G. (2009). A quality-aware optimizer for information extraction. ACM
Transactions on Database Systems, 34(1), 1–48.
28. Rahm, E., & Bernstein, P. A. (2001). A Survey of Approaches to Automatic Schema Matching.
the VLDB Journal, 10(4), 334–350.
29. Ponte, J. M., & Croft, W. B. (1998). A language modeling approach to information retrieval
(pp. 275–281).
30. Sijin, P., & Champa, H. (2020). Fuzzy conceptualization model for document representation.
In IEEE International Conference on Electronics, 2020, Computing and Communication Tech-
nologies (pp. 1–4).
31. Cohen, W. W., Ravikumar, P., Fienberg, S. E., et al. (2003). A comparison of string distance
metrics for. Name-Matching Tasks, 2003, 73–78.
32. Ney, H., Essen, U., & Kneser, R. (1994). On structuring probabilistic dependences in stochastic
language modelling. Computer Speech and Language, 8(1), 1–38.
33. Fagin, R., Lotem, A., & Naor, M. (2003). Optimal aggregation algorithms for middleware.
Journal of Computer and System Sciences, 66(4), 614–656.
34. Fagin, R. (1999). Combining fuzzy information from multiple systems. Journal of Computer
and System Sciences, 58(1), 83–99.
35. Zadeh, L. A. (1965). Fuzzy Sets. Information and Control, 8(3), 338–353.
36. Dong, X. L., Halevy, A., & Yu, C. (2009). Data integration with uncertainty. The VLDB Journal,
18(2), 469–500.
37. Clemen, R. T., & Winkler, R. L. (1990). Unanimity and compromise among probability fore-
casters. Management Science, 36(7), 767–779.
38. Chang, K. C.-C., & Hwang, S.-w. (2002). Minimal probing: Supporting expensive predicates
for top-k queries (pp. 346–357).

SentiSeries: A Trilogy of Customer
Reviews, Sentiment Analysis and Time
Series
Aishwarya Asesh
Abstract The customer rating is a great source of user feedback knowledge. Despite
the large number of reviews on online retailing, one knows very little on how con-
sumers feel about the goods and services provided by retail companies. The focus of
this research is on analyzing sentiment in reviews aligned with the time series analysis
that unveils quite interesting and decisive insights. The trends in user behavior, count
frequency and sentiments are used to decipher polarity shift. Ensemble of different
methods is used for time series analysis, sentiment analysis, and subject modeling.
Time series segmentation helps in differentiating critical time points that contribute
to major shifts in sentiment patterns. The study of timesteps leading up to and after
these crucial moments using a subject modeling technique help in proper analysis and
prediction of user behavior in a ceaseless manner. The research deepens the knowl-
edge of online retailing consumer behavior and yields valuable strategic lessons for
optimizing online retailing service deliverables. Finally, an in-depth investigation
establishes ﬁrst in the domain metrics such as sentiment velocity and acceleration
for sentiment monitoring. The ﬁndings presented here are to date the best in the
literature.
Keywords Sentiment analysis · Time series · Topic modeling · Sentiment
velocity · Sentiment acceleration · Sentiment monitoring · Customer reviews
1
Introduction
Understanding consumers varied preferences and intents is critical for any retailer to
adaptively optimize their product or service [1]. Iterating and improving on feedback
has been demonstrated by a number of successes. One of the recent studies [2] found
that properly segmenting users by user review content and working on recommen-
dations can improve customer retention by nearly 35%; and upside the conversion
rate by more than 25%.
A. Asesh (B)
Adobe, Lehi, USA
e-mail: asesh@adobe.com
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_3
31

32
A. Asesh
Real-world reviews have varying levels of decision words and express different
feelings that makes behavior modeling difﬁcult. Although their intentions are not
directly visible to the systems, they are distinct. Various activity signals have been
investigated, with varying degrees of success in extracting knowledge about users
recommendations. A broad body of work has been done to investigate opinionated
text data in order to better explain users focus [3, 4]. To determine the embedded
consumer intents, the distribution of terms and their emotion polarities can be statis-
tically modeled together. Device-logged behavior info, such as opinion ratings and
outcome clicks, provide clear supervision for inferring users latent biases but with
the multitude of data available it becomes really difﬁcult to understand individual
request and work on iteration [5].
Sentiment analysis is acoreNatural LanguageProcessing(NLP) taskthat attempts
to detect the polarity of a text. It is one of the most often used, straightforward, and
practical useful technique in NLP. Its aim is to anticipate how a piece of article,
usually a sentence or a summary, will be received. One can use sentiment analysis to
distinguish between positive and negative emotions, effectively turning the challenge
into a binary classiﬁcation problem. Almost everything available today in the digital
world are often given a star rating, which indicates the degree to which a product or
piece of work is either good or bad or is there a possibility or intention of instituting
modiﬁcations if necessary.
This challenge is often regarded as one of the simplest in NLP since simple
Machine Learning (ML) strategies can provide solid baselines [6], sometimes out-
performing far more complex approaches [7]. In its most basic form, this task can
be thought of as a binary classiﬁcation of positive and negative sentiment. How-
ever, there are many obstacles to overcome in order to achieve the highest level of
accuracy. Beyond basic bag of words methods that miss word order detail, it’s not
clear how to represent variable length texts. Advanced ML methods such as recur-
rent neural networks and their variants [7, 8] can be used, but it is unclear if they
provide a major advantage over plain bag-of-words and bag-of-ngram techniques [7,
9]. Complementary models favor the ensemble the most, so using a diverse range
of techniques is ideal. The vast majority of models presented in the literature are
discriminative in nature, with parameters optimized speciﬁcally for classiﬁcation.
People may use digital content to debate issues and disseminate their views. The
amount of textual data available from digital content is massive. The method of eval-
uating sentiment must be streamlined in order to obtain insight into the “overall”
view on speciﬁc products. For many industries, opinion analysis is becoming an
increasingly signiﬁcant area of research. If a corporation can ﬁgure out what cus-
tomers think about its goods, it can take steps to change them or satisfy a disgruntled
client. For sentiment analysis, many of the algorithms, including Naive Bayes and
Maximum Entropy, take a probabilistic approach to solving the problem. The use of
a Support Vector Machine (SVM) is another popular way. The trained model can be
used to differentiate between positive and negative reviews for a new product launch
and some critical metrics such as sentiment acceleration and velocity can be studied
to ﬁnd meaningful insights.

SentiSeries: A Trilogy of Customer Reviews, Sentiment …
33
2
Literature Review
The need to hear what others have to say is just as ancient as verbal conversation
itself. Leaders have often been interested in their subordinates views, either to brace
for criticism or to boost their popularity. There are examples of attempting to identify
internal opposition dating back to Ancient Greece [10]. The year 2001 appears to
mark the beginning of widespread understanding of the study issues that sentiment
analysis and opinion mining pose, according to ‘Opinion Mining and Sentiment
Analysis’ [9]. As a result of the recent boom of science, the ﬁeld is progressing at
a breakneck pace. Data from other contexts, such as movie reviews [11] and blog
posts [12], were included in most of the earlier work in the ﬁeld. The difﬁculties of
classifying Twitter data have only recently drawn researchers [13–15].
Theexplorationofopinion-richtextualcontentstoconsiderusersdecision-making
process has received a lot of attention [4, 16, 17]. To distinguish sentiment polarity
in text results, previous studies used both lexicon-based [18] and learning-based [19]
solutions. Later, using subject modeling techniques, ﬁner-grained models were cre-
ated to forecast users detailed aspect-level views and expectations [20, 21]. Modeling
user-generated text data has advanced to the point where personalized recommen-
dation and retrieval are now possible. For an explainable suggestion [22] merged
phrase-level sentiment analysis with matrix factorization. Authors in [23] showed
how user-generated content can be mined and integrated into a demand estimation
model to create a modern product search engine ranking method.
Sentiment analysis is a very speciﬁc type of text classiﬁcation problem in machine
learning that involves a series of training records X1, . . . , X N, where each record is
labeled with a class value selected from a set of k distinct discrete values indexed by
1, . . . , k. The training data is used to construct a classiﬁcation model that connects
the underlying record features to one of the class labels. The class labels assigned to
the documents in sentiment analysis denote the mood or viewpoint expressed in the
document. Opinion mining, which is the method of gathering sentiment on a certain
subject in order to obtain insights into public opinion on that topic, is closely related
to sentiment analysis.
Naive Bayes, Maximum Entropy and SVM classiﬁers have been used in a lot of
previousstudies.TheNaiveBayesclassiﬁercalculatestheprobabilitythatanexample
in the test set belongs in a given class based on the occurrences of features in the
training set. Since there is no iterative mechanism, this approach has the advantage
of linear time preparation, but it assumes that all characteristics are distinct, which
is not the case in natural language. SVM classiﬁers take a different approach to
the problem than Maximum Entropy and Naive Bayes, which are also probabilistic
approaches to the problem. SVM classiﬁers aim to segment the data space using
linear or non-linear delineations between the various classiﬁers [24].
One of the most critical facets of any text classiﬁcation is determining how to
represent a document and how to pick symbolic elements. A bag-of-words is a
collection of strings with no clear order that is often used to describe a document.
There are several well-established methods for choosing attributes, such as document

34
A. Asesh
frequency, which essentially refers to the amount of documents in which a word
appears at least once. Document frequency also eliminates the need for class labels
when selecting functions. There are several others methods for choosing attributes,
including the Gini Index, Information Gain, and the chi2-statistic [24]. Here in the
aforementioned research experiments are made using Logistic Regression, decision
trees and SVM; Logistic Regression is chosen due to the best accuracy among other
techniques.
Although a large number of research works are present for time series analysis as
well. The relationship mapping of predicted sentiment analysis classiﬁcation to time
series data and recommendation of sentiment monitoring is not that common. Let us
examine how the two ﬁeld of studies overlap to form an amalgam of knowledge.
3
Theory of Dynamic Sentiment Tracking
3.1
Natural Language Processing—Sentiment Analysis
Let us examine some of the state-of-the-art models used for sentiment analysis.
Generative Models A distribution over the input is described by a generative
model. One may use Bayes rule to predict which class a test sample belongs to
after training a generative model for each class. More formally, given a dataset
of pairs {x(i), y(i)}i=1,...,N where x(i) is the i-th document in the training set,
y(i) ∈{−1, +1} is the corresponding label and N is the number of training samples,
two models are trained: p+(x|y = +1) for {x(i) subject to y(i) = +1} and p−(x|y =
−1) for {x subject to y = −1}. Then, given an input x at test time, the ratio is
computed (derived from Bayes rule): r = p+(x|y = +1)/p−(x|y = −1) × p(y =
+1)/p(y = −1). If r > 1, then x is assigned to the positive class, otherwise to the
negative class. The most common form for distribution choice is the n-gram, a count-
based non-parametric method to compute p(x(i)
k |x(i)
k−1, x(i)
k−2, . . . , x(i)
k−N+1), where x(i)
k
is the k-th word in the i-th document. For likelihood of a text Markov assumption can
be used which involves simply multiplying the n-gram probabilities over all words
in the text:

p(x(i)) = K
k=1 p(x(i)
k |x(i)
k−1, x(i)
k−2, . . . , x(i)
k−N+1).

Logistic Regression and Naive Bayes A multinomial Logistic Regression model
is used. A single completely connected layer with a softmax is used for the output
module. The loss function is always negative log loss. As shown, a two-group multi-
nomial Logistic Regression model is reduced to a simple binary Logistic Regression
with cross-entropy loss. The two softmax units’ contributions can be summarized as
follows (with assumption that each unit’s bias b is integrated into each theta with a
1 dummy multiplier in x):

SentiSeries: A Trilogy of Customer Reviews, Sentiment …
35
hθ(x) =
1
exp(θ(1)⊤x) + exp(θ(2)⊤x)
exp(θ(1)⊤x)
exp(θ(2)⊤x)

By dividing the numerators and denominators of the two vector components by
exp(θ(1)⊤x):
hθ(x) =
1
exp(θ(1)⊤x)
exp(θ(1)⊤x) + exp(θ(2)⊤x)
exp(θ(1)⊤x)
 exp(θ(1)⊤x)
exp(θ(1)⊤x)
exp(θ(2)⊤x)
exp(θ(1)⊤x)

=
1
exp(θ(1)⊤x −θ(1)⊤x) + exp(θ(2)⊤x −θ(1)⊤x)
exp(θ(1)⊤x −θ(1)⊤x)
exp(θ(2)⊤x −θ(1)⊤x)

=
1
exp(0⊤x) + exp((θ(2) −θ(1))⊤x)

exp(0⊤x)
exp(θ(2) −θ(1))⊤x)

=

1
1+exp((θ(2)−θ(1))⊤x)
exp((θ(2)−θ(1))⊤x)
1+exp((θ(2)−θ(1))⊤x)

=

1
1+exp((θ(2)−θ(1))⊤x)
1 −
1
1+exp((θ(2)−θ(1))⊤x)

Replacing θ(1) −θ(2) in the expression with a single parameter vector θ′, the soft-
max regression will predict the probability of one of the labels as
1
1+exp(−(θ′)⊤x), and
the probability of the other label as 1 −
1
1+exp(−(θ′)⊤x). This establishes equivalency
to the binary Logistic Regression, with the difference that θ′ is overparameterized as
θ(1) −θ(2). More iteration of the train step can help in getting good performance of
the model.
The loss function takes the dot product of the target y_ with the log of the softmax
output y:
y(i)
1 −y(i)

1
1+exp((θ(1)−θ(2))⊤x)
exp((θ(1)−θ(2))⊤x)
1+exp((θ(1)−θ(2))⊤x)

In binary Logistic Regression, this is precisely the same as the cross-entropy loss
function. Grid search is performed, attempting several values of the regularization
coefﬁcient of the L2 penalty of the θ(2), θ(1) parameters (or the weights of our single
layer fully connected softmax network), and noting where the descent algorithm
performance on the validation set begins to deteriorate, indicating that grid search can
be capped to the last used value that demonstrated improvement. The regularization
coefﬁcient was set to 0.0085. Learning curves of the Logistic Regression model can
be observed in Fig.1.
The vectorized softmax output for either class is:
=

1
1+exp((θ(2)−θ(1))⊤x)
1 −
1
1+exp((θ(2)−θ(1))⊤x)


36
A. Asesh
Fig. 1 Training and
validation accuracy for
logistic regression model
The class with the argmax probability is chosen similar to binary classiﬁcation
problem. This is the same as choosing y = 1 if,
1
1 + exp((θ(2) −θ(1))⊤x) > 0.5 ⇐⇒(θ(2) −θ(1))x > 0
.
Bringing the bias term included in the θ’s
(θ(2) −θ(1))x + (b(2) −b(1)) > 0
= (b(2) −b(1)) + (θ(2)
1
−θ(1)
1 )x1 + (θ(2)
2
−θ(1)
2 )x2 + . . . + (θ(2)
k
−θ(1)
k )xk > 0
Fortheaboveexpressionθ0 + θ1I1(x) + θ2I2(x) + . . . + θk Ik(x) > threshold,indi-
vidual Ii(x) shows wordexistenceai fromthevocabularyinthetext at review x (value
is 0 or 1). The vocabulary’s size is k (the total number of unique words in the training
set from both the positive and negative classes). θ0 shows the difference in the bias of
the terms (b(2) −b(1)). Coefﬁcient θi of individual Ii(x) are respectively (θ(2)
i
−θ(1)
i
)
in the expression above. In other words, the weight connecting the negative class’s
output unit (1) to the input unit xi is subtracted from the weight connecting the pos-
itive class’s output unit (2) to the input unit xi. Here θi represents the polarity of
the ith keyword. If the ith keyword is strongly negative, θi is strongly negative, and
vice-versa.
When using Naive Bayes to characterize a sample analysis, the argmax of the
conditional probability of each class (1 = positive or 0 = negative) conditioned
on the sample review is chosen. This is the same as choosing y = 1 if,
P(class = 1|a1, . . . , an)
P(class = 0|a1, . . . , an) > 1

SentiSeries: A Trilogy of Customer Reviews, Sentiment …
37
If log is added to either side of the inequality:
log(P(class = 1|a1, . . . , an)) −log(P(class = 0|a1, . . . , an)) > 0
Expanding the equations
	
i

log(P(ai|class = 1))

+ log(P(class = 1)) −log(P(ai, . . . , an))
−	
i

log( (P(ai=1|class=0))
count(class=0) )

−log(P(class = 0)) −(−log(P(ai, . . . , an))) > 0
= log

 P(class = 1)
P(class = 0)

+

i

log(P(ai|class = 1)) −log(P(ai|class = 0))

> 0
If the expression θ0 + θ1I1(x) + θ2I2(x) + . . . + θk Ik(x) > threshold shows the
label of a single sample text block, the bias term θ0 is the log of the ratio of prior
probability of the positive class to the negative class. The vocabulary’s size (the
total number of unique words in the training set from both the positive and negative
classes) is k. Individual Ii is a binary 0 or 1 value showing the existence of the ith
keyword from the vocabulary in the sample text. The respective coefﬁcient θi is the
log odds observation point for the word ai. θi should depict the polarity value of the
ith word. The bias of one mark versus another is represented by the log odds value
for the term.
Each θi corresponds to the polarity value either positive or negative of the ith word
in the training set text sample. Here in this research 100 greatest (most positive) θs
are chosen, which means θs of the words with the strongest polarity for the positive
label of reviews are selected.
3.2
Time Series Characteristics
A univariate time series is a set of measurements taken at random intervals of one
dimension. Such data need not be Independent and Identically Distributed (IID).
Objectives of Time Series Analysis It can be used to describe the main charac-
teristics of every time series pattern. Discuss and derive how the past inﬂuences the
future or how two time series “interact” in this piece. As a monitor standard, use time
series to know decision points such as measures of the quality of a manufactured
component.
Model Types and Considerations There are two fundamental types: Autore-
gressive Integrated Moving Average (ARIMA) models relate time series values to
previous values and historical forecast errors. Unit time indexes as x-variables in
standard regression models.

38
A. Asesh
Basic insights that the time series can provide:
• Trend: The overall evolution in dimensions is referred to as a trend.
• Seasonality: Seasonality refers to activity that occurs on a regular basis that is
dependent on calendar cycles such as seasons, thirds, months, weeks, and so on.
• Outliers: Outliers are data that differs from the original or has been manipulated
in some way.
• Long-run Cycle: Long-run Cycle are recurring behavior that is unrelated to sea-
sonality.
• Constant Variance: Variance that does not change is known as constant variance.
• Abrupt Changes: Signiﬁcant disturbances in sequence or variation, among other
factors, are referred to as abrupt changes.
Autoregressive Models: Autocorrelation and Partial Autocorrelation Let us
consider {yt}n
t=1 be a time series indexed by t. The values of a time series are regressed
on previous values in an autoregressive model. For example, a one-order or ﬁrst order
autoregression AR(1):
yt = β0 + β1yt−1 + ϵt
two order or a second-order autoregression AR(2):
yt = β0 + β1yt−1 + β2yt−2 + ϵt.
kth-order autoregression AR(k) is represented by:
yt = (β0, β1, . . . , βn, 1) (1, yt−1, . . . , βt−n, ϵt)T .
Generally the errors ϵt
iid∼N(0, σ 2
ϵ ) and independent of y. Choosing the order for a
time series can be done using two methods:
1. Autocorrelation Function (ACF) and
2. Partial Autocorrelation Function (PACF).
The correlation coefﬁcient between two values in a time series, expressed as:
Corr(yt, yt+k) = rk = ck
c0
where
ck = 1
n
n−k

t=1
(yt −¯y)(yt+k −¯y)
is the ACF. The covariance formula, is used to show a linear relationship between
two variables. This is the covariance (or linear relationship) of lagged values in this
situation. The lag is given by k in this case.
This is one approach. This approach takes into account the impact of other lags
on yt. The second approach eliminates the impact of the other lags in the middle:
Here the PACF is given by

SentiSeries: A Trilogy of Customer Reviews, Sentiment …
39
fk =

r1 = Corr(yt, y0)
if k = 1;
Corr(yt −yt−1
t
, y0 −yk−1
0
) if k ≥2 .
Generally, this has the effect of representing the linear correlation in between yt and
yt+k but ceasing the linear dependence of lags in between t and t + k, namely ti such
that t < ti < t + k. This may also be thought of as removing the projection of yt on
the linear subspace spanned by yt+1, . . . , yt+k−1.
Decomposition can be used to further simplify the situation by analyzing some
pattern activity within our initial time sequence.
Decomposition and Higher Order Trends The decomposition of a time series
involves:
• overall trend, mt
• seasonality, st, and
• error, ϵt
yt = mt + st + ϵt.
Typical prediction begins with a linear ﬁlter estimate of the aggregate trend. A
moving average determined by the size of a “window” is an example of this:
ˆmt =
a

k=−a

1
1 + 2a

yt+k.
To get a sense of a positive overall theme, play around with the window height. Then,
if that’s done, we can calculate the seasonality based on what’s left:
ˆst = yt −ˆmt.
This ˆst is dependent on the window height. To correct a single st, we can take the
average of the window sized seasonality ﬁgures. Then we have a method to quantify
the error:
ϵt = xt −ˆmt −ˆst.
Another way to make time series model more complex is to use quadratic patterns
by taking into account not only linear time factors t, but also higher order factors
and interactions like t2, t3, and so on.
4
Dataset
Book reviews and scores are present in the dataset. The information was gathered
from goodreads.com,1 where users public shelves were scraped, allowing everyone
1 https://sites.google.com/eng.ucsd.edu/ucsdbookgraph/home.

40
A. Asesh
to see them without signing in. The user and review IDs have been deleted from the
database. Despite the fact that most terms are dependent on the novels, are obscure,
or are commonplace, some of the words still express clear emotions about the book
in question. For example, a sample phrase from a positive review that expresses a
positive opinion, where the noteworthy keyword is ‘fun’, is ‘This is the most exciting
book of the season.’; ‘Didn’t they read the weak dialogue, the cheezy lines?’ is an
excerpt from a scathing critique, where the keywords are ‘evil’ and perhaps ‘cheezy.’
It’s worth remembering that the word ‘cheezy’ is pronounced incorrectly, making
semantic comprehension challenging. Other shortcomings include semantic key-
word analyzes inability to handle language structures including sentence negation,
sarcasm, and the terseness or tone of a phrase. However, even with simple keyword
identiﬁcation, there is still a lot of information needed for determining a study’s
polarity. After the sentiment analysis model is trained using Logistic Regression, the
model is used to classify positive or negative sentiments on newly launched product
data. The data is double blind encrypted, for privacy reasons.
5
Results and Discussions
The data shows that Naive Bayes and Logistic Regression both use some of the
same terminology in their top 100 terms. For example, the adjectives ‘outstanding,’
‘terriﬁc’, and ‘wonderfully’ are all very upbeat. Both contain chaotic expressions,
such as ‘even’, which ranks third in Logistic Regression and ‘gattaca’, which ranks
ﬁfth in Naive Bayes. Since positive reviews are longer than negative reviews, a term
like ‘even’ could appear in more positive reviews, which could be explained by the
training data bias. In Table 1, one can see the accuracy values for sentiment analysis
models using different techniques.
Naive Bayes continues to pick keywords with a stronger positive emotion in its
top 100 more frequently than Logistic Regression, for example, ‘uplifting’ ,‘melan-
choly’, ‘lovingly’ and ‘masterfully’ are all picked by Naive Bayes but not by Logistic
Regression. For Naive Bayes, there are more adjectives and adverbs. One can see
terms that are not as descriptive at the top of the list in Logistic Regression; others
are nouns, and some can be used as emphasis or complimenting words with a better
explanation.
Table 1 Performance of individual models for sentiment analysis
Sentiment analysis methods
Accuracy (%)
Support Vector Machine (SVM)
86.5
Decision tree
78.6
Logistic regression
88.73

SentiSeries: A Trilogy of Customer Reviews, Sentiment …
41
Fig. 2 Comparison of positive and negative reviews over time
For instance, the terms ‘life’ , ‘most’, ‘particularly’, ‘real’, ‘all’, ‘together’ and
‘many’ are all speciﬁc to the top 100 for Logistic Regression. The inconsistencies in
the models may perhaps clarify these trends.
Using the trained model, when experimentation was carried out on a new product,
in Fig.2 one can observe the number of negative and positive reviews over a time
period of 1372days. The graph shows that product started gaining high popularity
at around 175th and 200th day of launch and then again had a major positive review
season around 500days from launch. The negative reviews continued in a similar
manner. Firms give out free samples before unveiling a new product to seed the
market. One of the important things is to ﬁnd the best seeding goals, such as early
adopters, social hubs, or randomly selected users, while taking into account the
possibility of negative word-of-mouth (WOM). If that is the case, one can argue that
seeding early adopters yields the most advantage and business penetration, led by
social hubs and unknown customers.
Figure3 is a comparison of two products; product 1 (a highly stable product
in the market) and product 2 (a newly launched product). Using topic modeling
on the two products data, one can ﬁnd that how people react to certain situational
change and what changes might be needed for product to sell again. One major
comparison here using sentiment monitoring is positive sentiment acceleration rate
versus negative sentiment acceleration rate. This ratio can highly help a ﬁrm in
establishing a anomalous pattern in customer behavior due to some issue in product
service or rising competition. Further investigation can be made using sentiment
velocity ratio.
Many ﬁrms already have shorter product life cycles, necessitating more accurate
forecasting of demand for newly launched goods. They will use these predictions to
help them make business decisions including acquisition and inventory management.
As observed in Fig.4, a time series is decomposed focusing mainly on seasonal and

42
A. Asesh
Fig. 3 Comparison of positive reviews for 2 products
Fig. 4 Trend and seasonal effect for positive review of a product
trend component. The trend of a product demand can be highly important insight for
deciding the launch season. These are the trend for a product X (example a humidiﬁer)
whose sales varies according to demand and need. Thus a ﬁrm can do market research
based on other popular products in the category before a launch. Since these decisions
are based on projections, a thorough sales forecasting strategy is essential to avoid
problems at or shortly after the product launch. Stock-outs or overstock conditions
can occur as a result of poor forecasting, which has a signiﬁcant impact on the
company’s performance and can also reduce customer loyalty and market share.

SentiSeries: A Trilogy of Customer Reviews, Sentiment …
43
Each feature’s weight is determined separately in Naive Bayes, depending on
how well it correlates with the mark. As a result, if any of the features are dependent
on each other and often occur together (especially if the feature space is large), the
prediction may overestimate their inﬂuence in the entire sample space since the step
includes multiplying probability values of two or more highly correlated features that
really represent a single feature, and it is assumed that these features could encumber
each other. As a result, one can see a lot of similar adjectives and adverbs chosen,
as well as pairings like (‘masterfully’ and ‘weaves’ which can appear together in
the text, but aren’t generally the most reﬂective of the entire sample room. It’s not
necessarily the case that the analysis would have words like ‘masterfully’ or ‘weaves’.
In Logistic Regression, on the other hand, all of the weights are combined such that
the linear decision function is high for positive classes and low for negative classes.
As a result, Logistic Regression could be able to loosen the Naive Bayes assumption
and compensate for associated features by lowering their weighting.
Finally, Logistic Regression has lower theta values than Naive Bayes. This may
be attributed to the fact that Naive Bayes matches feature weights separately, while
Logistic Regression allows for feature similarities and thus sets weights to be smaller
when combined with regularization.
6
Conclusions and Future Work
In the domains of time series and emotion analysis, there is a lot of space for advance-
ment. Only simple techniques were used for pre-processing, such as excluding 28
stopwords, words with a text frequency less than one, and normalizing words, emoti-
cons. These simple pre-processing and feature selection methods generated satisfac-
tory results when used in combination with a Maximum Entropy classiﬁer. In case
of complicated word text, further research should be performed in the future.
Any phrases in the analysis may also be used to suggest mood modiﬁers (e.g.,
#sarcasm) or even raw emotion (e.g., #yay). For certain emotion analysis functions,
DiMSUM (Detecting Minimal Semantic Units and their Meanings) may be used
[25]. Though it may be impossible to remember word deﬁnitions for proper nouns,
particularly with the use of hashtags, classiﬁcation accuracy can be improved by
using modiﬁers and hashtags with raw emotion. Simple words have meaning at
the sentence level, while hashtags have meaning at the message level as well. For
training and testing, further annotated feedback with hashtags would be needed.
CamelCase is often used to create multi-word tags (e.g., #SorryNotSorry). During
function discovery, it may be worthwhile and try to decompose CamelCase hashtags
into its component words.
Almost every author has written several reviews. A more advanced classiﬁer could
detect a user’s proclivity for expressing a single emotion through all of their feedback.
In addition, such reviewers can be treated with a particular emotion on a daily basis.
For example, reviews of popular author books and general topics are more likely to be
positive, while reviews of political books are more likely to be mixed. The addition

44
A. Asesh
of a temporal element, in which people’s perspectives, and therefore emotions in
reviews, change over time, could pose a problem for this method. When public’s
opinion of an individual changes, so does the mood.
Many other implementations of bag-of-words capture word order by creating fea-
tures made up of bi-grams, which are sequences of words. The addition of bi-gram
support expands the number of features available, making planning more challeng-
ing. This description also applies to n-grams, which are n-letter strings. When used
correctly, an SVM outperforms a Maximum Entropy solution.
Acknowledgements All that I am, or ever hope to be, I owe to my angel mother.
References
1. Wang, W., Feng, F., He, X., Nie, L., & Chua, T.-S. (2021). Denoising implicit feedback for
recommendation. In Proceedings of the 14th ACM International Conference on Web Search
and Data Mining (pp. 373–381).
2. Raﬁeian, O., & Yoganarasimhan, H. (2021). Targeting and privacy in mobile advertising. Mar-
keting Science, 40(2), 193–218.
3. Hong, M., & Wang, H. (2021). Research on customer opinion summarization using topic
mining and deep neural network. Mathematics and Computers in Simulation, 185, 88–114.
4. Kumar,R.S.,Devaraj,A.F.S.,Rajeswari,M.,Julie,E.G.,Robinson,Y.H.,&Shanmuganathan,
V. (2021). Exploration of sentiment analysis and legitimate artistry for opinion mining. Multi-
media Tools and Applications, 1–16.
5. Wang, X., & Kadıo˘glu, S. (2021). Modeling uncertainty to improve personalized recommenda-
tions via Bayesian deep learning. International Journal of Data Science and Analytics, 1–11.
6. Wang, S. I., & Manning, C. D. (2012). Baselines and bigrams: Simple, good sentiment and topic
classiﬁcation. In Proceedings of the 50th Annual Meeting of the Association for Computational
Linguistics (Vol. 2: Short Papers, pp. 90–94).
7. Socher, R., Pennington, J., Huang, E. H., Ng, A. Y., & Manning, C. D. (2011). Semi-supervised
recursive autoencoders for predicting sentiment distributions. In Proceedings of the 2011 Con-
ference On Empirical Methods in Natural Language Processing (pp. 151–161).
8. Mikolov, T., Martin, K., Burget, L., Cernocky, J., & Khudanpur, S. (2010). Recurrent neural net-
work based language model. In INTERSPEECH, 11th Annual Conference of the International
Speech Communication Association (pp. 1045–1048).
9. Bakshi, R. K., Kaur, N., Kaur, R., & Kaur, G. (2016). Opinion mining and sentiment analysis.
In 2016 3rd International Conference on Computing for Sustainable Global Development
(INDIACom) (pp. 452–455). IEEE.
10. Richmond, J. A. (1998). Spies in ancient Greece. Greece & Rome, 45(1), 1–18.
11. Pang, B., Lee, L., & Vaithyanathan, S. (2002). Thumbs up? Sentiment classiﬁcation using
machine learning techniques. arXiv preprint cs/0205070.
12. Melville, P., Gryc, W., & Lawrence, R. D. (2009). Sentiment analysis of blogs by combining
lexical knowledge with text classiﬁcation. In Proceedings of the 15th ACM SIGKDD Interna-
tional Conference on Knowledge Discovery and Data Mining (pp. 1275–1284).
13. Si, J., Mukherjee, A., Liu, B., Li, Q., Li, H., & Deng, X. (2013). Exploiting topic based twitter
sentiment for stock prediction. In Proceedings of the 51st Annual Meeting of the Association
for Computational Linguistics (Vol. 2: Short Papers, pp. 24–29).
14. Barbosa, L., & Feng, J. (2010). Robust sentiment detection on twitter from biased and noisy
data. In Coling 2010: Posters (pp. 36–44).

SentiSeries: A Trilogy of Customer Reviews, Sentiment …
45
15. Gokulakrishnan, B., Priyanthan, P., Ragavan, T., Prasath, N., & Perera, A. (2012). In Inter-
national Conference on Advances in ICT for Emerging Regions (ICTer2012) (pp. 182–188).
IEEE.
16. Liu, B. (2012). Sentiment analysis and opinion mining. Synthesis Lectures on Human Language
Technologies, 5(1), 1–167.
17. Varghese, R., & Jayasree, M. (2013). A survey on sentiment analysis and opinion mining.
International Journal of Research in Engineering and Technology, 2(11), 312–317.
18. Hu, M., & Liu, B. (2004). Mining and summarizing customer reviews. In Proceedings of the
Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (pp.
168–177).
19. Pang, B., & Lee, L. (2005). Seeing stars: Exploiting class relationships for sentiment catego-
rization with respect to rating scales. arXiv preprint cs/0506075.
20. Titov, I., & McDonald, R. (2008). A joint model of text and aspect ratings for sentiment
summarization. In Proceedings of ACL-08: HLT (pp. 308–316).
21. Wang, H., Lu, Y., & Zhai, X. (2011). Latent aspect rating analysis without aspect keyword
supervision. In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining (pp. 618–626).
22. Zhang, Y., Lai, G., Zhang, M., Zhang, Y., Liu, Y., & Ma, S. (2014). Explicit factor models
for explainable recommendation based on phrase-level sentiment analysis. In Proceedings of
the 37th International ACM SIGIR Conference on Research and Development in Information
Retrieval (pp. 83–92).
23. Ghose, A., Ipeirotis, P. G., & Li, B. (2012). Designing ranking systems for hotels on travel
search engines by mining user-generated and crowdsourced content. Marketing Science, 31(3),
493–520.
24. Tang, X., Yao, H., Sun, Y., Aggarwal, C., Mitra, P., & Wang, S. (2020). In Proceedings of the
AAAI Conference on Artiﬁcial Intelligence (Vol. 34, No. 04, pp. 5956–5963).
25. Asesh, A. (2020). Computational semantics: How to solve the suspense of supersense. In 2020
IEEE Third International Conference on Artiﬁcial Intelligence and Knowledge Engineering
(AIKE) (pp. 120–125). IEEE.

Video Summarization Using Fully
Convolutional Residual Dense Network
Anil Singh Parihar, Ritvik Mittal, Himanshu, and Prashuk Jain
Abstract Video summarization is a keenly intellective video compression technique
to select a subset of keyframes or keyshots which are combined to represent shorter
and compendious summary of the original input video without losing the contex-
tual semantics of the same. Previous work has shown that extracting rich contextual
information from the input video frames is imperative for generating summary that
is closer to human interpretation of the original input video. However, recent convo-
lutional architectures were unable to account for the same. In this paper, we institute
a novel relation between image super resolution and video summarization and intro-
duce a novel architecture by adapting residual dense network (RDN), which fully
exploits both local and global structural context. Experimental results indicate that
introducing a modiﬁed RDN (SUM-RDN) unit signiﬁcantly improves the perfor-
mance over standard convolutional networks.
Keywords Video · Summarization · Residual · Dense · Convolutional · Deep
learning
1
Introduction
In recent years with the exponential growth in population and reduction in the cost to
capture videos, the volume of video content has risen drastically. Video has become
one of the most essential sources of visual knowledge. It is not possible for a single
human being to go over the video uploaded on a platform like youtube in just an hour.
According to WordStream.com, “72h of video are uploaded on youtube every 60s.”
“Every second, a million minutes (17,000h) of video content will cross global IP
networks by 2024,” according to Cisco. The creation of computer vision techniques
that can allow enormous video data to be browsed efﬁciently is therefore becoming
increasingly important. Video summarization has arisen in particular as a propitious
A. S. Parihar · R. Mittal (B) · Himanshu · P. Jain
Department of Computer Science and Engineering, Delhi Technological University,
Shahbad Daulatpur, Main Bawana Road, Delhi 110042, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_4
47

48
A. S. Parihar et al.
way to help to analyse the overwhelming volume of video content. The purpose
of video summary is to construct a short video from the original given input video
without losing the essential features of the video. In several real-world applications,
video summarization can be helpful. For instance, in video surveillance, scrolling
through several hours of videos recorded by surveillance cameras is boring and time-
consuming for humans. It would signiﬁcantly minimize the human efforts required
for video monitoring, if we can provide a brief video summary that extracts the
necessary data from a long video. Video summarization will also provide a better
user interface for video exploration, extraction and analysis as shorter videos are
more economical to store, watch and analyse.
Inourwork,westudyvideosummarizationasakeyframesubsetselectionproblem
in which we have to train our model so as to select such frames which capture the
most deﬁning features of the input video. This problem can also be formulated as
sequential frame labeling task in which each frame is provided with a binary label
indicating whether it is in the summary subset.
In recent years, convolutional neural network (CNN) based models [1–4] have
achievedgreatsuccessinvideosummarization.However,mostCNNbasedmodelsdo
not fully exploit the temporal hierarchical features extracted from each convolutional
layer due to loss of locality across the convolutions, thereby achieving relatively
low performance. Furthermore, it is essential for a model for video summarization
to capture long-range complex temporal dependencies among the video frames as
indicated through previous empirical work. Model proposed in [5, 6] solves the
problem using recurrent neural networks. However, recurrence based models are
relatively slow as they process one frame at a time either left to right or right to left in a
sequentialmannergeneratingabinarylabelforeachframeandareincapableoftaking
full advantage of GPU parallelization. The current state-of-the-art [7, 8] introduces
attention mechanism which captures the long-range dependencies remarkably but
do not take into account the temporal nature of the task which can lead to degraded
performance on some of the tasks.
In this paper, we took inspiration from [1, 9, 10] and introduced fully convo-
lutional residual dense network (FCRDN) for the purpose of video summarization
which uses summary residual dense network (SUM-RDN) as depicted in Fig.1 for
context extraction and fully convolutional sequential network (SUM-FCN) [1] for
frame level mapping to binary outputs. RDN [9] has been used for the task of image
super resolution through which visually pleasing high-resolution image is generated
from a low-resolution degraded image. RDN completely utilizes hierarchical features
from all the convolutional layers which was not achieved by most of the CNN based
models. Being fully convolutional, it fully utilizes GPU capacity. RDN networks con-
sist of building blocks called residual dense blocks (RDB), which contains densely
connected convolutional layers with additional network structure for local feature
fusion (LFF) and local residual learning (LRL). RDB also incorporates contiguous
memory mechanism as all the layers in one RDB have direct access to the output of
the previous RDB. LFF helps to preserve the information by fusing the output from
various convolutional layers in the current RDB and the output of preceding RDB,
thereby extraction local dense hierarchical features. LRL further improves the rep-

Video Summarization Using Fully Convolutional Residual …
49
Fig. 1 Formation of SUM-RDB from residual and dense blocks
resentational ability of the RDB unit which enhances the overall performance of the
model. RDN also perform global feature fusion (GFF) and global residual learning
(GRL) to preserve the global hierarchical features.
Our insight is that residual dense network can be modiﬁed and applied for the task
of video summarization. Our SUM-RDN extracts hierarchical features among the
frames of the input video. Furthermore, the contiguous memory mechanism helps in
capturing long-range complex temporal dependencies among the frames of the input
video. SUM-FCN [1] then generates frame level binary labels for the summary.
Summarizing our work, we have three major contributions:
1. We establish a novel connection between two apparently different domains of
image super resolution and video summarization.
2. We are the ﬁrst to use RDB for video summarization and propose a novel archi-
tecture by adapting the residual dense network (RDN) for our task.
3. We report higher evaluation results over the standard SUM-FCN [1] network
underlining the effectiveness of our SUM-RDB network.
2
Related Work
Through video summarization, short highly informative representations of input
videos are generated. These representations can be of various forms such as sto-
ryboards [1, 5, 7, 8, 11], montages [12, 13] and time-lapses [14, 15]. Our work

50
A. S. Parihar et al.
adapts the storyboard representation in which certain keyframes [5, 16] or keyshots
[5] are chosen to form the summary video. Keyframes based summary also called
static summary is a set of representative individual frames from the input video,
whereas keyshots summary also known as dynamic summary is a set of shots from
the input video where a single shot is a group of consecutive frames in the video time-
line. Speciﬁcally, our work uses keyframes to form the video summaries highlighting
a temporal order.
Before deep learning, low level features such as color histograms, motion vector,
image alignment, etc. were used to represent a particular frame of the video. On
these representations, various distance metrics were applied to quantify the simi-
larity between frames and interestingness of a particular frame or a set of frames.
Based on these heuristics, certain frames were selected to be a part of summary as
in [17–19]. Majority of such approaches have been unsupervised leading to forma-
tion of clusters of similar frames. Recent advancements [1, 5, 7, 8] have explored
video summarization as a supervised problem where the goal of a model is to identify
keyframes by leaning the semantics of how users understand the task of summarizing
a video. Ground truth or user annotated summaries corresponding to each video form
the training data for such approaches. Our work follows on these supervised meth-
ods. Supervised methods have traditionally outperformed the previous unsupervised
work indicating that learning high level semantics of how users select summaries is
essential.
Various deep learning models have been adapted for the video summarization
problem. Zhang et al. [5] leverage the sequential nature of recurrent networks to
account for the temporal structure and capture long range context from the video.
RNNs recursively aggregate the context to produce output labels. Zhang et al. [5]
propose a bi-directional LSTM network. One LSTM is used for learning context in
the forward direction, while one is used for the backward direction. Learning both
the directions produces better results. Mahasseni et al. [11] learn a keyframe selector
LSTM by using variational autoencoder to generate corresponding summary which
is then fed to confuse the LSTM discriminator in an adversarial setting against the
input video.
LSTM networks form a natural choice for a sequential task like video summariza-
tion but are computationally very expensive because of sequential processing. More
recently, attention networks [7, 8] form the recent state-of-the-art for our task. Ji et
al. [7] propose an attention based encoder decoder network where the encoder is a
Bi-LSTM network, and the decoder is an attention based LSTM network. Attention
mechanism provides attention weights associated with individual encoder hidden
states. Decoder output at a single instance can learn to combine different hidden
units through these weights resulting in rich structural knowledge instead of using
a single hidden vector as in case of LSTMs. This network is also notorious to train
due to LSTMs. Fajtl et al. [8] are based on evaluating a soft, global attention layer to
evaluate a context vector using attention weights. Context vector along with residual
sum is then used for frame level score regression. Attention networks do not inher-
ently give regard to the temporal structure of the video and consider all the frames
as equivalent which leads to ignorance of local context.

Video Summarization Using Fully Convolutional Residual …
51
Rochan et al. [1] proposed a fully convolutional sequence network (SUM-FCN)
for video summarization on the argument that convolutions can also capture long
range dependencies and adapted this property for video summarization. Fully end-
to-end convolutions also allow for faster learning. However, SUM-FCN can not fully
capture the global context. The stacked convolutions lead to local and hence global
information loss due to diminishing resolution of the neighborhood. Through our
work, we try to better account for both the local and global context. Along similar
lines as [9], we propose a fully convolutional residual dense architecture (FCRDN)
forvideokeyframesummarizationandpresentourresultsontwobenchmarkdatasets.
Our work is the ﬁrst to use residual dense network for video summarization.
3
Our Approach
In this section, we ﬁrst present the problem description (Sect. 3.1). We then present
our architecture and elaborate its major components (Sect. 3.2).
3.1
Problem Description
Two types of frame level outputs have been identiﬁed from previous work. (1) Hard
{0, 1} Binary labels; (2) Soft (0, 1) frame level importance scores. Binary outputs also
called hard outputs directly indicate whether a particular frame is part of the summary
or not. These labels could be keyframe or keyshot where keyframes are a subset of
discontinuous frames, whereas keyshots are a subset of shots of continuous frames.
Frame level importance scores also referred to as soft outputs determine the likeliness
of selecting that frame in the video summary. User annotations for popular datasets
are available in these two forms and following [5], and it is possible to interchange
between these two. In our approach, we use binary frame level mappings or hard
scores.
Let an input video be represented by T which is the number of frames in the input
video. Each frame is represented by a feature vector based on some preprocessing.
For our work, following [1], we pass each frame through the pre-trained GoogleNet
and take the output from the pool5 layer. GoogleNet provides rich features as it has
been trained on a huge collection of images. Let the feature vector has K dimensions
and Vi be the feature vector corresponding to the ith frame. Then, the input video
consists of FV = {V1, V2, . . . , Vi, . . . , VT }. User annotated summaries have {0,1}
assigned to each frame. Frames labeled with 1 form the summary. Our goal is to
learn semantics of how the users summarize a video through supervised training and
then predict binary labels for every frame of the input video.

52
A. S. Parihar et al.
Fig. 2 Fully convolutional residual dense network
3.2
Fully Convolutional Residual Dense Network
Our work is inspired from the ability of RDN [9, 10] to extract contextual knowledge
with regard to image super resolution. Image super resolution inherently requires
local and global contextual knowledge from the low-resolution space to be preserved
for upscaling. Our intuition and precious work suggest that contextual knowledge
across the video timeline is critically important for generating a summary which is
highly representative of the video itself. Hence, RDN can be exploited for gathering
richer hierarchical features and gain better structural knowledge of the entire video by
enhancing the local features and then aggregating them for effective global context.
Aparticularresidualdenseblockin[9]usesconvolutionfunctionoverthe2dimen-
sions of the input image. Videos follow a temporal ordering, and hence, we modify
the residual dense block to take convolutions over the single-temporal dimension of
the video. 1D convolutions over the temporal range and the dense architecture help
in extracting the local context, whereas the residual nature of the network preserves
the information for a rich global context. These rich features are then fed to a fully
convolutional sequence network (SUM-FCN) [1] for frame level mapping to binary
outputs as in Fig.2. SUM-FCN is a fully convolutional network with an architecture
similar to an encoder decoder network. The encoder part consists of stack of con-
volution layers for hierarchical feature formation, whereas decoder part is a stack
of deconvolution layers to up-scale the temporal range for frame level mapping.
We name our entire architecture as Fully Convolutional Residual Dense Network
(FCRDN). This section further describes the major components of our architecture
in greater detail.
FCRDN: We adapt the RDB introduced in [9], for video summarization and name
the structure SUM-RDB. We stack a number of SUM-RDBs together to form SUM-
RDN. The inputs to our network are of dimensions 1 × T × K. These features are
ﬁrst enhanced by passing through the SUM-RDN and then fed to the fully convolution
encoder decoder (SUM-FCN). FV are the GoogleNet feature vectors which are fed
to the SUM-RDN. FNF are the rich features obtained as output from the SUM-RDN.
FNF form the input to SUM-FCN [1] which produces frame level binary labels (Y ,)
where a binary label 1 indicates that a particular frame is in the summary. Abstractly,
our model can be represented by following two equations.

Video Summarization Using Fully Convolutional Residual …
53
FNF = HSUM−RDN(FV )
(1)
Y , = HSUM-FCN(FN F)
(2)
where Hmodel(x) is a composite transformation applied by model on input x.
Before RDN, two convolutional layers applied on FV form the shallow features
F−1 and F0. F−1 is also used in global residual learning. F0 is the input to the SUM-
RDB blocks. For nth block out of total N blocks, the output is given by the recurrence
relation:
Fn = HSUM-RDB,n(Fn−1)
(3)
For the ﬁnal output of SUM-RDN (FNF), previously extracted local hierarchical
features (all Fd) are densely combined following global feature fusion (GFF) and
global residual learning (GRL). This is represented as
FNF = HGlobal(F−1, F0, F1, . . . , Fn, . . . , FN)
(4)
These rich features are fed to SUM-FCN for binary predictions as in Eq. 2.
Global feature fusion (GFF) is realized by taking all the feature maps generated by
RDBs, concatenating them and then applying 1*1 convolution on it to get the desired
shape of the output. A 3 * 3 convolution is applied on this feature map to further
extract the context for global residual learning (GRL). This mechanism of GFF helps
in extracting and fusing the hierarchical context from RDBs in a global way to gain
better temporal structure among the video frames. The operation in equation form
can be represented as
FGF = C3∗3(C1∗1(Hconc(F1, . . . , Fn, . . . , FN)))
(5)
where Fn is the feature map from nth RDB, C3∗3 and C1∗1 represent convolution
operation and Hconc represents concatenation function.
Global residual learning (GRL) is realized by making a skip connection to add the
output from global feature fusion (FGF) with feature map from ﬁrst convolution layer
(F−1). This mechanism helps in propagating the feature learned from shallow layer
to encourage feature reuse and control vanishing gradient problem. The operation in
equation form can be represented as
FDF = FGF + F−1
(6)
SUM-RDB: RDN consists of densely connected convolutional layers, local fea-
ture fusion (LFF) and local residual learning (LRL) which contributes toward pre-
serving the preceding information and making a contiguous memory pass throughout
the model. In [9], the input to RDB is the feature extracted from two convolutional
layer that takes the original low-resolution image of dimensions k × l with 3 RGB
channels, where k and l are image height and width. The dimensions of the con-
volution in RDB are chosen in such a way that the output has same dimensions

54
A. S. Parihar et al.
Fig. 3 SUM-RDB: Modiﬁed RDB for video summarization
as the input feature vector. Unlike RDB, our SUM-RDB takes the input with the
dimensions 1 × T × K, where T represents the number of frames and K represents
the dimensions of the feature vector for each frame. We apply 1 × 1 convolution
after concatenating features vector generated by each convolutional layer and the
preceding SUM-RDB so that we get the output vector of the same dimensions as the
input.
Figure3 shows the architecture of our SUM-RDB. We use temporal convolu-
tions in SUM-RDB, unlike RDB which used spacial convolution. Each convolution
operation is followed by ReLU for nonlinearity.
Local feature fusion (LFF) is realized by concatenating the feature map from each
temporal convolution layer in SUM-RDB and output of the previous SUM-RDB. The
operation in equation form can be represented as
Fn,LF = H n
LFF([Fn−1, Fn,1, ..., Fn,c, ..., Fn,C])
(7)
where H n
LFF represents the 1 * 1 convolution to get the desired dimensions of the
output. Since we are using low number of temporal convolution operation in a single
SUM-RDB, LFF helps to extract local context from current and preceding SUM-
RDB. Local residual learning (LRL) is realized in SUM-RDB by introducing a skip
connection that combines the output of the previous SUM-RDB and the output of
LFF of the current SUM-RDB. This helps to recover temporal information from
shallower stage for video summarization. The operation in equation form can be
represented as
Fn = Fn−1 + Fn,LF
(8)
SUM-FCN: This is the same model used by [1] for generating frame level binary
labels. We use SUM-FCN 8 in our work. The model is fully convolutional similar to
preceding SUM-RDN unit and consists of temporal elements like 1D convolutions,
1D pooling and 1D deconvolution layers. It is adeptly interpreted as an encoder
decoder network where the stack of 1D convolutional layers forms the encoder and
a stack of 1D deconvolutional layers forms the decoder as depicted. The encoder
extracts contextual long term dependencies, whereas the decoder upscales the con-
voluted temporal dimension for outputting frame wise 0/1 mappings.

Video Summarization Using Fully Convolutional Residual …
55
As the model is fully convolutional, there are no restrictions on the input video
length. For a densely connected neural network, we would have to explicitly specify
the dimensions for producing frame level output mappings. Also, since a single-
convolutional operation is not sequential, the model fully utilizes GPU paralleliza-
tion. Features generated by SUM-RDN FN F are inputs to SUM-FCN and it produces
0/1 labels as outputs. This is represented by Eq. 2.
4
Results
In this section, we ﬁrst present the datasets. We then introduce evaluation metrics
and compare our results with vanilla SUM-FCN[1] and other video summarization
techniques.
4.1
Datasets
Supervised training requires user generated summaries of training videos. TVSum
[20] and SumMe [21] are two annotated datasets which contain videos summarized
by multiple users. These datasets are the benchmark for testing video summarization
models. TVSum has 50 videos with categories ranging across news, documentaries,
etc., and video length 1–5 min. It provides user generated summaries as frame level
importance values. SumMe dataset has 25 videos of various events across holidays,
sports, etc., ranging from 1.5 to 6.5min in length. User generated summaries are key
shot based (set of frame intervals). OVP open video project) [17, 22] dataset has
50 videos covering genres such as historical, educational, etc. These are 1–4 min in
length. The YouTube [17] dataset contains 39 videos distributed among news, sports,
commercials, etc. These are 1–10 min in length. Both OVP and YouTube dataset
provide multiple user summaries as keyframes. Since different datasets provide user
annotated summaries in different formats, we follow [5] for pre-processing data for
training of supervised models and evaluation.
4.2
Result
We follow the commonly used evaluation metric [5] and use F-Scores for quantitative
comparison. It is most commonly used metric across the work we have considered
and hence provide for fair analysis. F score is based on precision (P) and recall (R).
Given G as ground truth summary and M as machine generated summary:
P = G ∩M/ |M|
R = G ∩M/ |G|
(9)

56
A. S. Parihar et al.
Table 1 F score comparison with vanilla SUM-FCN [1]
Model
SumMe
TvSum
Rochan et al. [1]
51.1
59.2
FCRDN (ours)
50.26
61.87
Table 2 F score comparisons with various video summarization models
Model
SumMe
TvSum
Zhang et al. [5]
42.9
59.6
Mahasseni et al. [11]
43.6
61.2
Rochan et al. [1]
51.1
59.2
Ji et al. [7]
46.1
61.8
Fajtl et al. [8]
51.1
62.4
FCRDN (ours)
50.26
61.87
where |.| indicates summary length. F-Score is computed as:
F = (2P ∗R)/(P + R) ∗100%
(10)
F scores on augmented [5] setting of the datasets where training is performed on
augmentation of OVP, YouTube, X1, 80% of X2 and testing on 20% of X2 are
given. X1 and X2 being TVSum and SumMe interchangeably. Table1 compares our
approach with the standard SUM-FCN. Our SUM-RDB unit signiﬁcantly improves
the performance of vanilla SUM-FCN. Table2 compares our approach with other
video summarization approaches. We outperform most of the methods on both the
SumMe and TVSum datasets. The scores are taken directly from the corresponding
work. Our low score in comparison with the state-of-the-art attention model [8] is
due to less powerful SUM-FCN. We hypothesize using our SUM-RDN features in
accordance with the current state-of-the-art, we can achieve favorable outcomes. A
key observation from the results is our model performs well on both SumMe and
TVSum datasets. This is particularly interesting as videos differ in length across the
two datasets. Fine results verify the ability of our SUM-RDN to extract both local
and global context equally well. Local context is specially important in summarizing
long videos.
5
Conclusion
We have adapted residual dense blocks (RDBs) for the task of video summariza-
tion. We established a novel relation between image super resolution and video
summarization and presented that both of these domains excel on rich contextual
features. Further, we have introduced a novel architecture which we call FCRDN for

Video Summarization Using Fully Convolutional Residual …
57
summarizing videos. Our model outperforms the standard convolutional model. It
also delivers competitive performance on popular benchmark datasets. Being fully
convolutional, it allows for optimal GPU utilization as compared to LSTM based
approaches. We emphasize that our SUM-RDN unit can be used in accordance with
other video summarization models as well. Similar to adapting RDBs, we believe
that other super resolution techniques can be adapted for video summarization. In
future work, we look forward to utilize our SUM-RDN unit with other video sum-
marization models and aim to explore other research domains for new inspiration
toward video summarization.
References
1. Rochan, M., Ye, L., & Wang, Y. (2018). Video summarization using fully convolutional
sequence networks. In ECCV.
2. Nair, M. S., & Mohan, J. (2019). Video summarization using convolutional neural network and
random forest classiﬁer. In TENCON 2019 - 2019 IEEE Region 10 Conference (TENCON),
Kochi, India (pp. 476–480). https://doi.org/10.1109/TENCON.2019.8929724
3. Rochan, M., & Wang, Y. (2019). Video summarization by learning from unpaired data. In 2019
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2019 (pp.
7894–7903).
4. Elfeki, M., & Borji, A. (2019). Video summarization via actionness ranking. In IEEE Winter
Conference on Applications of Computer Vision (WACV), Waikoloa Village, HI, USA, January
7–11, 2019, Jan 2019 (pp. 754–763).
5. Zhang, K., Chao, W. L., Sha, F., & Grauman, K. (2016). Video summarization with long
short-term memory. In ECCV.
6. Zhao, B., Li, X., & Lu, X. (2017). Hierarchical recurrent neural network for video summariza-
tion. In Proceedings of the 2017 ACM on Multimedia Conference (MM ’17) (pp. 863–871),
New York, NY. ACM.
7. Ji, Z., Xiong, K., Pang, Y., & Li, X. (2017). Video summarization with attention-based encoder-
decoder networks. arXiv preprint arXiv:1708.09545
8. Fajtl, J., Sokeh, H. S., Argyriou, V., Monekosso, D., & Remagnino, P. (2018). Summarizing
videos with attention. In ACCVW.
9. Zhang, Y., Tian, Y., Kong, Y., Zhong, B., & Fu, Y. (2018). Residual dense network for image
super-resolution. In 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition,
Salt Lake City, UT (pp. 2472–2481). https://doi.org/10.1109/CVPR.2018.00262
10. Huang, G., Liu, Z., Weinberger, K. Q., & van der Maaten, L. (2017). Densely connected
convolutional networks. In CVPR.
11. Mahasseni, B., Lam, M., & Todorovic, S. (2017). Unsupervised video summarization with
adversarial LSTM networks. In CVPR.
12. Kang, H. W., & Chen, X. Q. (2006). Space-time video montage. In IEEE Conference on
Computer Vision and Pattern Recognition.
13. Sun, M., Farhadi, A., Taskar, B., & Seitz, S. (2014). Salient montages from unconstrained
videos. In European Conference on Computer Vision.
14. Kopf, J., Cohen, M. F., & Szeliski, R. (2014). First-person hyper-lapse videos. ACM Transac-
tions on Graphics, 33(4), 78.
15. Poleg, Y., Halperin, T., Arora, C., & Peleg, S. (2015). Egosampling: Fast-forward and stereo
for egocentric videos. In IEEE Conference on Computer Vision and Pattern Recognition.
16. Gong, B., Chao, W. L., Grauman, K., & Sha, F. (2014). Diverse sequential subset selection for
supervised video summarization. In Advances in neural information processing systems.

58
A. S. Parihar et al.
17. De Avila, S. E. F., Lopes, A. P. B., da Luz, A., & de Albuquerque Araujo, A. (2011). VSUMM:
A mechanism designed to produce static video summaries and a novel evaluation method.
Pattern Recognition Letters, 32(1), 56–68.
18. Khosla, A., Hamid, R., Lin, C. J., & Sundaresan, N. (2013). Large-scale video summarization
using web-image priors. In CVPR.
19. Ngo, C. W., Ma, Y. F., & Zhang, H. J. (2003). Automatic video summarization by graph
modeling.
20. Song, Y., Vallmitjana, J., Stent, A., & Jaimes, A. (2015). TVSUM: Summarizing web videos
using titles. In CVPR.
21. Gygli, M., Grabner, H., Riemenschneider, H., & Van Gool, L. (2014). Creating summaries
from user videos. In ECCV.
22. Open video project. http://www.open-video.org/

An Efﬁcient Deep Learning Approach
for Detecting Pneumonia Using
the Convolutional Neural Network
Anik Kumar Saha and Md. Muhaimenur Rahman
Abstract In recent years, Pneumonia has emerged as one of the greatest threats to
humanity worldwide, particularly in developing countries around Asia and Africa.
This malignant disease is responsible for a considerable number of deaths each
year. Therefore, it is vital to detect Pneumonia without making any delay to prevent
untimely deaths. The World Health Organization has reported that at least 4 million
premature deaths happen yearly due to illnesses related to domiciliary air contam-
ination, which includes Pneumonia. An adept radiologist usually diagnoses Pneu-
monia patients by analyzing chest X-ray images. However, depending on radiol-
ogists alone may block the diagnosis process because the detection of diseases
analyzing chest X-ray images demands human assistance, expertise, and resources. In
such cases, a Computer-Aided Diagnosis (CAD) system can play a signiﬁcant role
in detecting patients with Pneumonia automatically, which requires less time and
human effort. This paper has suggested a modiﬁed deep learning approach adopting
the convolutional neural network (CNN) model to train sample chest X-ray images
and extract features from them to predict the presence of Pneumonia. Our proposed
model performs better during the experimentation and achieves 89% exactness which
is relatively better than existing deep learning-based clinical image classiﬁcation
algorithms.
Keywords Pneumonia · Image classiﬁcation · Data augmentation · Data
preprocessing · Convolution neural network · Chest X-ray · Feature extraction
1
Introduction
The danger of Pneumonia is enormous for some countries, particularly where people
are deprived of fundamental human rights and spend their lives in extreme poverty.
A. K. Saha (B)
Department of Computer Science & Engineering, Bangladesh University of Business and
Technology, Dhaka, Bangladesh
Md. Muhaimenur Rahman
Department of Computer Science & Engineering, Jahangirnagar University, Dhaka, Bangladesh
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_5
59

60
A. K. Saha and Md. Muhaimenur Rahman
They are unable to take advanced treatment due to a lack of education and modern
medical facilities. According to World Health Organization (WHO), as many as 3.8
million untimely deaths are being accounted for each year due to household-related
contamination, whereas 27% of people are died caused by Pneumonia [1]. Moreover,
about 150 million people, particularly children under 5, are reportedly being affected
byPneumoniaannually[2].Thiscomplicationmaybecomemoreacuteintheabsence
ofphysiciansandclinicalstaffinsuchasituation.Accordingtoasurveyon57African
countries, there is a shortage of more than 2.3 million specialist doctors and medical
personnel [3, 4]. However, an exact and timely diagnosis can be essential for the
large population living in this part of the world.
Although numerous neural network architectures are regularly being developed
to diagnose diseases, expert radiologists identify patients with Pneumonia through
manual analysis of their chest x-ray images. It requires a lot of time to deal with
this process, demanding a vast amount of specialists and an increasing number of
organizations to step forward. An unusual yet straightforward model is introduced
to overcome this adversity for performing optimal classiﬁcation tasks employing
the deep learning-based convolutional neural network. This examination proposes
a modiﬁed CNN architecture that can train sample images and recognize the pres-
ence of Pneumonia germs in a human body. The proposed model may regularly
attenuate the unwavering challenges of quality and reliability while working with a
medical image repository. We have adopted a new strategy that does not depend on
traditional handcrafted techniques or transfer learning approaches to accomplish a
greater validation rate. We have established a CNN architecture that extracts features
of selected chest X-ray images and analyzes them in different segregated layers to
predict positive and negative Pneumonia.
It appears that the deep learning-based CNN framework has become one of the
most commonly used algorithms by researchers for the classiﬁcation of images in
recent years. Some examples of the most favored and widely recognized clinical data
classiﬁcation models are U-Net [5], SegNet [6], and CardiacNet [7].
2
Literature Review
The deep learning-based image classiﬁcation task has caught a growing interest in
recent years. Many researchers have continuously been experimenting to uncover the
research intricacies involved in the medical image classiﬁcation process. Kermany
et al. [8] proposed an intelligent diagnosis tool employing a deep-based transfer
learning approach by analyzing chest X-ray images that could predict retinal disease
and pediatric Pneumonia patients. His proposed framework utilized a dataset of
optical coherence tomography images and a set of chest X-ray images during the
training process. Antin et al. [9] constructed an algorithm that uses “a 121-layer
Convolutional Neural Network to classify chest x-ray images assembled from the
NHIS dataset to identify Pneumonia patients”. Rajpurkar et al. [10] have used an
algorithm called Chex Net, which can detect 14 types of viruses. Park et al. [11]

An Efﬁcient Deep Learning Approach for Detecting …
61
developed “a Gabor ﬁlter-based algorithm to detect rib reduction on abnormal tissue
by scanning the X-ray images”. Ragab [12] built a computer-aided diagnosis system
to detect fatal tumors utilizing the deep learning approach and image segmentation
methodologies by analyzing mammography images. Livieris et al. [13] proposed
a novel weighted voting system based on a semi-supervised learning algorithm to
detect lung abnormalities by analyzing a dataset of X-ray images. Choudhari et al.
[14] proposed an algorithm that was able to identify skin cancer using the convo-
lution neural network. Omar and Babalık [15] proposed an efﬁcient algorithm to
detect positive and negative Pneumonia using the convolution neural network. The
researchers observed that their suggested architecture could accomplish a greater
exactness rate of 87.5 than state-of-the-art deep learning-based algorithms. Abiyev
et al. [16] developed a deep neural network to detect chest diseases where the success
rate of the backpack system is more than 99.19%. Naranjo-Torres et al. [17] designed
a CNN-based model that can detect fruits by scrutinizing images of different fruits.
Han et al. [18] developed an image processing system to help robots classifying
underwater images. Alazab et al. [19] constructed a CNN-inspired novel technique
for diagnosing COVID-19 from original datasets. Chakraborty et al. [20] established
“a Convolutional Neural Network (CNN) model to diagnose Pneumonia from a chest
X-ray dataset, which can be used in real-world applications to treat Pneumonia”.
The dropout regularization strategy was used in the model to minimize the overﬁt-
ting problem. Rahman et al. [21] worked with various types of machine learning
technology with the implementation of convolutional neural network. Shubho et al.
[22] analyzed the performance of NB Tree, REP Tree, and Random Tree classiﬁers
against the German credit dataset to detect real-world fraud transactions. Rahman
and Basak [23] uses ﬁve different types of algorithms where random forest works
better than others.
3
Material and Methods
We conducted the entire experiment in a detailed way to assess our proposed CNN
model’s efﬁciency. The required image dataset was carefully picked from the Kaggle
platform [24]. This study used Keras open-source neural network library integrated
with the TensorFlow backend to construct and train the proposed CNN architecture.
We experimented with the help of a Lenovo laptop ﬁtted with an Intel Core i5–5200
CPU, a 64-bit operating system, 8 GB RAM, and the CUDA Toolkit 9.0. To compile
this model, we used Python version 3.7.
3.1
Dataset
The collected dataset was separated into training, testing, and validation folders.
These folders were further split into two new directories known as pneumonia (P)

62
A. K. Saha and Md. Muhaimenur Rahman
Table 1 Entire dataset
Chest X-Ray Image
Training data
Testing data
Pneumonia
3875
390
Normal
1241
231
Total
5216
624
Fig. 1 Sample chest X-ray image dataset without pneumonia
Fig. 2 Sample chest X-ray image dataset with pneumonia
and normal (N). The dataset includes 5840 chest X-ray images assembled from the
previously admitted patients aged between 1 to 5 years during their regular medical
check-ups. The National Institutes of Health (NIH) has recognized the dataset taken
from the Guangzhou Women’s Medical Center in Guangzhou, China. We modi-
ﬁed the original dataset to balance the percentage of several types of data allocated
to training and validation sets. Thus, the whole dataset was only split up into a
training and validation set. Table 1 shows the overview of the dataset we used for
the experiment (Figs. 1 and 2).
3.2
Preprocessing and Data Augmentation
Data preprocessing is a phase that involves transforming the raw data before putting
it into the proposed CNN architecture during the training. At the time of collecting
various data from different origins, it is accumulated in raw form. Since raw data
cannot be analyzed during the training process, preprocessing of the collected data
is necessary to make them usable. As part of preprocessing, we deployed various
data augmentation algorithms to enhance sample images’ size and quality. These
processes are required to deal with the overﬁtting problem of data as well as improve
the generalization capability of the model.
At ﬁrst, we used the rescale operation, which is responsible for reducing and
magnifying images during the augmentation period. Then, the rotation operation is
utilized to rotate the image samples by 40° during the training. The sample images

An Efﬁcient Deep Learning Approach for Detecting …
63
were horizontally translated by 0.2%. We also applied the vertical translation of
the collected images by 0.2%. The other operation in the data augmentation process
includes shear range, zoom range, and horizontal ﬂip. The data augmentation process
applies different operations on sample data to increase the model’s validation and
classiﬁcation accuracy.
3.3
Proposed Model
Figure 3 represents the general outline of the suggested CNN model trained to classify
the sample image dataset. The proposed convolution neural network architecture is
divided into several layers, which are also known as dense layers. Feature extractors
and classiﬁers are two of the most responsible features of our proposed CNN model.
The Softmax activation function was employed in the model as a classiﬁer. The
suggested CNN model comprises several layers, such as Convolution layers, various
classiﬁcation layers, and max-pooling layers.
Here, the feature extractors layer comprises of conv3 × 3, 16; conv3 × 3, 32;
conv3 × 3, 64; conv3 × 3, 128, max-pooling layers of size 2 × 2, and a RELU as
an activation function between them.
The result obtained from the max-pooling and convolution operations is accumu-
lated in 2D planes, also known as feature maps. We received 163 × 163 × 16, 79 ×
79 × 32, 37 × 37 × 64, 16 × 16 × 128, 3 × 3 × 128 sizes feature maps from the
convolution operations, whereas 81 × 81 × 16, 39 × 39 × 32, 18 × 18 × 64, 8 × 8
× 128, 3 × 3 × 128 feature maps collected from the pooling operations.
In contrast, the input image was 165 × 165 × 3 in size. The Classiﬁer Softmax
Activation Function is placed at the distant regions of the suggested neural network
model. It is also known as an ANN model that is often referred to as the squashing
function due to having several dense layers.
The Softmax activation function also takes feature vectors to carry out any calcula-
tions involved in the classiﬁcation process like other classiﬁers. Thus, after ﬁnishing
the feature extraction process, the obtained output is further transformed into the
Fig. 3 The outline of the proposed model

64
A. K. Saha and Md. Muhaimenur Rahman
Fig. 4 The parameters of the proposed model
1D feature extractor planes for the classiﬁer known as the ﬂattening process. The
convolution operation’s result is generalized into a feature vector plane required for
the ﬁnal classiﬁcation process. Furthermore, the classiﬁcation layer comprises a ﬂat-
tening layer, 2 thick layers of 512 and 1, a dropout size of 0.2, RELU activator, and a
Softmax activation function, which can be utilized in the images’ ﬁnal classiﬁcation
task (Fig. 4).
4
Result Analysis
We carried out the same experiment multiple times every 3 hour to calculate the
accuracy and efﬁcacy of the architecture. The parameter and hyper parameters of
the proposed model were adjusted to get relatively higher performance during the

An Efﬁcient Deep Learning Approach for Detecting …
65
training process. While obtaining different results from different test cases, the most
valid outcome was taken into consideration. The total epoch number was 3, whereas
the dropout was set to 0.2. Figures 5 and 6 illustrate the graphical views of the
proposed model’s performance derived during the dataset training (Table 2; Fig. 7).
The experimental result shows our proposed CNN architecture’s efﬁciency, which
performed much better than the existing contemporary deep learning algorithms for
medical image classiﬁcation tasks. Based on the experimental result, our proposed
Fig. 5 Training accuracy
Fig. 6 Training loss

66
A. K. Saha and Md. Muhaimenur Rahman
Table 2 Result comparison
Algorithm
Accuracy (%)
SMO
76.76
C4.5
74.83
3NN
74.51
Voting
76.12
WvEnSL3
83.49
CNN Model
87.65
Proposed CNN Model
89.00
Fig. 7 Result comparison graph
model acquired an accuracy of 89%, which is comparatively higher than the sophisti-
cated supervised methodologies such as SMO [25], C4.5 [26], 3NN [27], WvEnSL3
[13], and CNN [18]. SMO, C4.5, 3NN, etc., are known as the most established and
recognized deep learning algorithms to carry out object detection tasks.
5
Discussion
In this research, we collected a total of 5840 sample chest X-ray images from the
Guangzhou Women’s Medical Center in Guangzhou, China. The algorithm begins
with data preprocessing by employing various data augmentation techniques to
enhance classiﬁcation and validation accuracy. After manual annotation, we trained
the model utilizing the Keras deep learning open-source library having TensorFlow
backend. The convolutional layer extends a set of ﬁxed size learnable kernels to

An Efﬁcient Deep Learning Approach for Detecting …
67
the input images for generating 2D planes called feature maps. These maps contain
the extracted features of the pixel values. At the later stage, the max-pooling layer
performs various operations on the feature maps to down sample the input features
and reduce the computational complexity. Then, the fully connected layer accepts
the previous layers’ output and converts them into a 1D feature vector. Finally, a
Softmax activation function analyzes feature vectors to classify and predict positive
and negative Pneumonia. Overall, the system obtained an accuracy of 89%, which
is relatively high compared to the existing models.
6
Conclusion
Thedeeplearning-basedCNNmodelisregardedasthemostrecognizedalgorithmfor
analyzing clinical image data [28]. In this paper, we tried to demonstrate an efﬁcient
way of detecting Pneumonia by analyzing a set of chest X-ray image datasets. The
recommended CNN model was built from scratch, which performed more accurately
and accomplished better exactness during the training than other existing machine
learning algorithms. In the future, we will try to expand this research work by clas-
sifying X-ray images affected by lung cancer. In recent years, the classiﬁcation task
of X-ray images containing lung cancer poses an increasing cause of concern for
scientists worldwide. We are optimistic that our next approach will play a signiﬁcant
role in dealing with that complication.
References
1. World Health Organization. (2018). Household air pollution and health [Fact Sheet]. WHO.
http://www.who.int/newa-room/fact-sheets/detail/household-air-pollution-and-health.
2. Rudan, I., Tomaskovic, L., Boschi-Pinto, C., & Campbell, H. (2004). Global estimate of
the incidence of clinical Pneumonia among children under ﬁve years of age. World Health
Organization, 82, 85–903.
3. Narasimhan, V., Brown, H., Pablos-Mendez, A., et al. (2004). Responding to the global human
resources crisis. Lancet, 363(9419), 1469–1472.
4. Naicker, S., Plange-Rhule, J., Tutt, R. C., Eastwood, J. B. (2009). Shortage of healthcare
workers in developing countries. Africa Ethnicity & Disease, 19, 60.
5. Ronneberger, O., Fischer, P., Brox, T. (2015). U-Net: Convolutional networks for biomedical
image segmentation. In: Navab, N., Hornegger, J., Wells, W., Frangi, A. (eds) Medical Image
Computing and Computer-Assisted Intervention – MICCAI 2015. MICCAI 2015. Lecture
Notes in Computer Science, vol 9351. Springer, Cham.
6. Badrinarayanan, V., Kendall, A., & Copolla, R. (2015). Segnet: Deep convolutional encoder-
decoder architecture for image segmentation.
7. Mortazi, A., Karim, R., Rhode, K., Burt, J., & Bagci, U. (2017). Cardiacnet.: Segmentation of
left atrium and proximal pulmonary veins from MRI using multi-view CNN. In M. Descoteaux,
L.Maier-Hein,A.Franz,P.Jannin,D.Collins,&S.Duchesne(Eds.),MedicalImageComputing
and Computer-Assisted Intervention, MICCAI 2017. Springer.
8. Kermany, D. S., Goldbaum, M., Cai, W., et al. (2018). Identifying medical diagnoses and
treatable diseases by image-based deep learning. Cell, 172(5), 1122–1131.

68
A. K. Saha and Md. Muhaimenur Rahman
9. Antin, B., Joshua, K., & Martayan, E. (2017). Detecting Pneumonia in chest X-Rays with
supervised learning. Semanticscholar.org.
10. Rajpurkar, P., Irvin, J., Zhu, K., et al. (2017). Chexnet: Radiologist-level Pneumonia detection
on chest x-rays with deep learning. arXiv preprint arXiv: 1711.05225.
11. Park, M., Jin, J. S., & Wilson, L. S. (2004). Detection of abnormal texture in chest X-rays
with reduction of ribs. In Proceedings of the Pan-Sydney area workshop on Visual information
processing.
12. Ragab, D. A., Sharkas, M., Marshall, S., & Ren, J. (2019). Breast cancer detection using deep
convolutional neural networks and support vector machines. Peer, 7, e6201.
13. Livieris, I., Kanavos, A., Tampakas, V., et al. (2019). A weighted voting ensemble self-labeled
algorithm for the detection of lung abnormalities from X-rays. Algorithms, 12(3), 64.
14. Choudhari, S., & Seema, B. (2014). Artiﬁcial neural network for skin cancer detection. Inter-
national Journal of Emerging Trends & Technology in Computer Science (IJETTCS), 3(5),
147–153.
15. Omar, H. S., & Babalık, A. (2019). Detection of pneumonia from X-ray ımages using
convolutional neural network (p. 183). Proceedings Book.
16. Abiyev, R. H., & Ma’aitah, M. K. S. (2018). Deep convolutional neural networks for chest
diseases detection. Journal of Healthcare Engineering, 2018.
17. Naranjo-Torres, J., Mora, M., Hernández-García, R., Barrientos, R. J., et al. (2020). A review
of convolutional neural network applied to fruit image processing. Applied Sciences, 10(10),
3443.
18. Han, F., Yao, J., Zhu, H., & Wang, C. (2020). Underwater ımage processing and object detection
based on deep CNN method. Journal of Sensors, 2020.
19. Alazab, M., Shalaginov, A., Mesleh, A., et al. (2020). COVID-19 prediction and detection
using deep learning. International Journal of Computer Information Systems and Industrial
Management Applications, 12, 168–181.
20. Chakraborty, S., Aich, S., Sim, J. S., & Kim, H. C. (2019). Detection of Pneumonia from chest
x-rays using a convolutional neural network architecture. International Conference on Future
of Information and Communication Engineering, 11(1), 98–102.
21. Rahman, M. M., Faruque Shamim, M. O., & Ismail, S. (2018). An analysis of Bangladesh one
day ınternational cricket data: A machine learning approach. In 2018 International Conference
on Innovations in Science, Engineering and Technology (ICISET).
22. Shubho, S. A., Razib, M. R. H., Rudro, N. K., Saha, A. K., Khan, M. S. U., & Ahmed, S.
(2019). Performance analysis of NB Tree, REP tree and random tree classiﬁers for credit card
fraud data. ˙In 2019 22nd International Conference on Computer and Information Technology
(ICCIT).
23. Rahman, M. M., & Basak, S. (2021). Identifying user authentication and most frequently used
region based on mouse movement data: A machine learning approach. In 2021 IEEE 11th
Annual Computing and Communication Workshop and Conference (CCWC).
24. National Institutes of Health chest X-Ray Dataset. https://www.kaggle.com/nih-chest-xrays/
datasets. Accessed August 30, 2020.
25. Platt, J. (1998). Advances in kernel methods—Support vector learning. MIT Press.
26. Quinlan, J. (1993). C4.5: Programs for machine learning. Morgan Kaufmann.
27. Aha, D. (1997). Lazy learning. Kluwer Academic Publishers.
28. Yamashita, R., Nishio, M., Togashi, K., et al. (2018). Convolutional neural networks: An
overview and application in radiology. Insights Into Imaging, 9(4), 611–629.

QMCDS: Quantum Memory for Cloud
Data Storage
Ankit Sharma, Indra Kumar Sahu, and Manisha J. Nene
Abstract Cloud computing is emerging as a very prominent and promising tech-
nology with its unique characteristics like low cost, scalability, elasticity, and on
demand services. On the other hand, quantum computing is also gaining increasing
research attention due to its enormous computational power. The future will soon
be deﬁned by the combined capabilities of both technologies. The challenges of
cloud computing like threats to conﬁdentiality, integrity, authentication, availability,
and authorization are deteriorating day by day. The cloud Storage as a Service also
suffers from such threats and challenges. Due to the rapid advancements in crypt-
analytical methodologies and techniques, existing solutions to secure cloud storage
based on traditional cryptography techniques will no longer be viable. Henceforth,
this research work proposes a Quantum Memory for Cloud Data Storage (QMCDS)
as a solution after performing a detailed analysis on the difﬁculties and limitations in
cloudstorage.TheproposedsolutionisbasedonQubitsandthesameisalsodiscussed
here. The proposed research work is an effort to pave way towards developing solu-
tions by keeping quantum computing at center in the cloud quantum computing
technology.
Keywords Cloud computing · Quantum computing · Entanglement · QMCDS ·
No-cloning theorem · Hadamard gate · Quantum memory
1
Introduction
Cloud computing has emerged as one of the most promising network-based tech-
nologies to share calculations and resources without considering their location [1].
Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a
Service (SaaS) is the available various service models, which are associated with
essential characteristics like on-demand self-service, resource pooling, rapid elas-
ticity, low cost, and pay per use [2]. Huge data storage capacity, tremendous scalable
A. Sharma (B) · I. K. Sahu · M. J. Nene
Department of Computer Science & Engineering, Defense Institute of Advanced Technology,
Pune, Maharashtra, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_6
69

70
A. Sharma et al.
performance, and maintenance of large number of services have made it a dominating
technology.
Quantum computing with tremendous computing power is considered as another
eminent technology to exponentially solve the most difﬁcult problems [3]. The tradi-
tional cryptographic systems, which are used for encryption, may no longer be safe.
The combined capabilities of cloud and quantum computing are going to be the future
of this ﬁeld.
Cloud computing also offers Storage as a Service for its users. Google Drive,
Jio Cloud, Microsoft OneDrive, and Dropbox offer limited free storage services
while IBM cloud storage, Apple iCloud, SpiderOak One, and CertainSafe Deposite
Box are commercially used by leveraging paid data storage for individual users,
enterprises, and organizations. The stored data in cloud servers is secured using
traditional encryption technologies which are considered to be very safe at present.
But, with upcoming advancements in cryptanalytical methods and techniques, espe-
cially by using quantum computing, they will not withstand much longer. There
are serious threats to cloud storage data with regards to conﬁdentiality, integrity,
authentication, availability, and authorization. So, there is a need to devise some
methods/schemes/protocols that can sustain against such odds and attacks in post
quantum era.
From rigorous studies and tremendous research work, Quantum Memory for
Cloud Data Storage (QMCDS) solution is proposed for keeping the data safe in
cloud servers. The proposed QMCDS is capable of withstanding most attacks on
cloud storage and mitigate the threats based on classical techniques.
The rest of the paper is organized into six sections. The second section is for
literature survey, third for describing prelims, fourth for problem statement. The ﬁfth
section gives out proposed solutions to the storage problem. Sixth section presents
experiments and observations, followed by last section with conclusion and future
scope.
2
Literature Survey
2.1
Related Work
CloudcomputingoffersvariousbeneﬁtsforboththeusersandCSP.Usersgetservices
at low cost, on demand, pay per use, and irrespective of geographical limitations.
Data storage is the service to users at their convenience and having adequate secu-
rity. Lot of research work has been carried out in this discipline. Apart from clas-
sical techniques, lattice cryptography-based solutions for ensuring conﬁdentiality,
integrity, and other security and privacy parameters have been proposed. Identity
based Integrity Veriﬁcation (IBIV) protocol for integrity [4], Study of Lattice based
FHE for cloud data security [5] and Lattice based access control for protecting user

QMCDS: Quantum Memory for Cloud Data Storage
71
data in cloud environments with hybrid security [6] are some of the works on this
ﬁeld based on lattice cryptography.
Quantum-based techniques have been proposed for securing data at storage and
during transit. A single quantum cannot be cloned [7], Quantum copying: Beyond the
no-cloningtheorem[8],ClassicalNo-CloningTheorem[9],no-cloningtheorem[10],
entanglement measurement inﬂuencing various quantum applications [11], quantum
communication protocol to preserve the qubits for future reference [12], qubit OTP
with biometrics [13] and dual factor authentication using qubit OTP [14] are some of
the quantum-based research works that paved the way to enhance and utilize security
and privacy parameters for various applications including cloud security.
2.2
Contributions
This paper presents a Quantum Memory for Cloud Data Storage (QMCDS) solution
to utilize Qubits for securing cloud data storage. This solution is tested by using IBM
Q Experience and the results are also explained. The solution enhances security by
using inherent quantum characteristics.
3
Preliminaries
Before exploring the QMCDS solution, familiarization with few preliminaries is
given in succeeding parts [15, 16].
3.1
Qubit
• In Qubit representation state 0 or |0 > and state 1 or |1 > is represented by a 2-by-1
matrix as follow:
|0⟩=
 1
0

|1⟩=
0
1

• For Multi Qubits |00 >, |01 >, |10 > and |11 > value can be found by taking tensor
product (represented by ⊗) as shown below
• For example, value of |00 > can be found as

72
A. Sharma et al.
|00⟩=
 1
0

⊗
 1
0

=
⎛
⎜⎜⎝
1
0
0
0
⎞
⎟⎟⎠
Similarly,
|01⟩=
⎛
⎜⎜⎝
0
1
0
0
⎞
⎟⎟⎠, |10 > =
⎛
⎜⎜⎝
0
0
1
0
⎞
⎟⎟⎠, |11 >=
⎛
⎜⎜⎝
0
0
0
1
⎞
⎟⎟⎠
3.2
Representation of Quantum Gates
• NOT gate for quantum operations can be represented as:
NOT =
0 1
1 0

This matrix can perform operation of a NOT gate, that is it can ﬂip Qubit |0 > to
|1 > and vice versa.
Similarly, matrices for operation of OR, AND gate for quantum operations can
be represented as:
OR =
 1 0 0 0
0 1 1 1

AND =
 1 1 1 0
0 0 0 1

• OR and AND operation is two qubit operations performed on |00 >, |01 >, |10 > ,
and |11 >.
• Controlled-NOT gate can be represented as:
CNOT =
⎛
⎜⎜⎝
1 0 0 0
0 1 0 0
0 0 0 1
0 0 1 0
⎞
⎟⎟⎠
• Toffoli or CCNOT (control control NOT) gate can be represented as:

QMCDS: Quantum Memory for Cloud Data Storage
73
Toffoli gate =
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝
1 0 0 0 0 0 0 0
0 1 0 0 0 0 0 0
0 0 1 0 0 0 0 0
0 0 0 1 0 0 0 0
0 0 0 0 1 0 0 0
0 0 0 0 0 1 0 0
0 0 0 0 0 0 0 1
0 0 0 0 0 0 1 0
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠
Toffoli gate is a universal gate and it can be utilized to represent other gates.
• Hadamard gate
H=
1/
√
2 1/
√
2
1/
√
2 −1/
√
2

Hadamard gate can be utilized to put qubits into a superposition state.
• Fredkin or Cswap (controlled swap) gate
Fredkin gate =
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝
1 0 0 0 0 0 0 0
0 1 0 0 0 0 0 0
0 0 1 0 0 0 0 0
0 0 0 1 0 0 0 0
0 0 0 0 1 0 0 0
0 0 0 0 0 0 1 0
0 0 0 0 0 1 0 0
0 0 0 0 0 0 0 1
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠
• Phase gates
Y =
0 −i
i 0

, X =
0 1
1 0

Z =
 1 0
0 −1

, T =
 1 0
0 i

• Matrix X, Y and Z are also called Pauli’s matrices wherein Pauli X matrix is also
NOT gate implementing phase change of π.

74
A. Sharma et al.
3.3
Bloch Sphere
The geometrical representation of Bloch sphere helps to understand unitary quantum
operations of a unit length [16].
4
Proposed Solution
Traditional cryptographic solutions are considered to be vulnerable to analyzing
advanced cyber and quantum attacks. Various existing techniques like RSA based
encryptions, digital signatures, hashing techniques, etc. are utilized for security and
privacy applications, where cryptography will be based on number theory or hard
problem of factorization. Such problems will no longer remain as hard problems as
they could be solved or broken in polynomial time by using quantum computing.
Henceforth, there is a need to ﬁnd a solution in quantum domain for cloud data,
especially in the post quantum era.
With quantum memory having qubits for storing information in it, this solution
has been proposed. For quantum memory-based techniques, it is pertinent to store
and measure the values of qubits at various states. In quantum mechanics, operations
on qubits are inﬂuenced by wave function collapse [17], No-cloning theorem [7]
and reversible operations [18]. These properties pose challenges to measure or copy
quantum state stored in memory and also puts restriction to only utilize the reversible
operations.
There is a solution through ‘No-cloning theorem’, which states that it is impossible
to make exact copies of the quantum state and if the copy of quantum state is made
then it will either be same or orthogonal [7–10, 19].
In bloch sphere |0 > and |1 > are orthogonal. Which can be veriﬁed by taking their
scalar product as:
|0 > =
 1
0

,
|1 > =
0
1

,
and their scalar product |0 > . |1
> =
(10).
 0
1

=
(1 × 0 + 0 × 1) +
(0 × 0 + 0 × 1) = 0.
Similarly, |X+ >, |X−> and |Y + >, |Y −> are orthogonal states.
Necessary and sufﬁcient condition for entangled qubit in two systems to be cloned
by sequential access was given by Masato Koashi and Nobuyuki Imoto [20]. On
similar lines, we design a circuit in quantum machine which is as shown in Fig. 1a
for experiment, we take 3 qubit system in which the value of qubit q0, q1, and q2 is
to be cloned to qubit q3, q4, and q5 respectively. Quantum function operating on q0
is represented by NOT gate followed by Hadamard gate . The qubits q1 and q2 have

QMCDS: Quantum Memory for Cloud Data Storage
75
Fig. 1 Quantum circuit for cloning
quantum operations represented by Hadamard gate. After quantum operation, the
qubits q0, q1, q2 are entangled with q3, q4, q5 respectively with the help of CNOT
gate.
5
Experiments and Observation
The experiments were conducted on IBM quantum machine [21], where circuits were
run on both quantum machines and quantum simulators. However, results discussed
are of the quantum simulator as it has less error rate.
In Fig. 1 qubits q0, q1, and q2 are put on entangled state with q3, q4, and q5
respectively. In results, from Fig. 2, it can be seen that, the entangled qubit pairs
q0–q3, q1–q4, q2–q5 both qubits have same value either 0 or 1 as per the applied
quantum operation.
In quantum memory, there is a requirement to copy the data or to carry out read
operations for more than one time. As per wave collapse theorem [17] quantum state
would collapse after a measurement is made on the quantum state, hence if quantum
Fig. 2 Results obtained after running quantum circuit for cloning

76
A. Sharma et al.
Fig. 3 Quantum circuit for cloning after measurement
Fig. 4 Results obtained after executing quantum circuit for cloning after measurement
state is copied before a measurement is made then the copied state can be utilized
for future use.
Figure3showsthecircuitdiagraminwhichqubitq0,q1,q2areclonedtoq3,q4,q5
respectively as was done in Fig. 1. Read/measurement operation is carried out on q0,
q1, q2 which results in collapse of qubit state to 0 (represented by measurement and
reset operator). Qubit q3, q4, q5 are entangled with qubit q0, q1, q2 respectively after
measurement is carried out on q0, q1, q2. This entanglement results in restoration of
state of qubits q0, q1, q2 the state it was prior to the measurement as seen in Fig. 4
(can also be compared with Fig. 2).
6
Conclusion and Future Scope
Cloud computing and quantum computing are set to be getting established as the
future of computing environment having combined capabilities of tremendous calcu-
lation power; shared, distributed, and on-demand computing resources. The proposed
QMCDS solution is a step towards realizing the same. It is apparent from the exper-
iments carried out that cloning qubits with entanglement and utilization to main-
tain and store data and other information in qubit states is possible. While carrying
out implementation, it requires sequential operation such that every time before a

QMCDS: Quantum Memory for Cloud Data Storage
77
measurement is made on the qubit, its state is to be cloned with entanglement to
some other qubit. After measurement, the cloned state is to be cloned/ copied back
to the original qubit under required conditions. It is required so that stored data on
cloud can be accessed multiple times by user as per the user’s choice and in a secure
manner maintaining all the security and privacy parameters.
The Quantum Memory discussed for QMCDS can further be utilized for multiple
reads of quantum memories required to perform accessing the data multiple times and
thus, can be deployed in cloud environment. Such deployment in cloud environment
will enhance the security of cloud due to inherent quantum properties.
The future work may be taken to enable multiple measurements at same instance
andfurtherenhancesecuritybyemployingquantumlockstodisableanyunauthorized
access of data through operations on qubits envisaging Cloud Quantum Computing
for the most secure environment for individual users, organizations, and enterprises.
Acknowledgments The authors would like to extend gratitude to the IBM quantum machines team
and the many anonymous reviewers for their valuable guidance and genuine feedbacks. We would
like to record our thanks to colleagues at Defense Institute of Advanced Technology, Pune for their
constant motivation and technical support.
References
1. Subramanian, N., & Jeyaraj, A. (2018). Recent security challenges in cloud computing.
Computers & Electrical Engineering, 71, 28–42.
2. Mell, P., & Grance, T. (2011). The NIST deﬁnition of cloud computing.
3. Calefﬁ, M., Cacciapuoti, A. S., & Bianchi, G. (2018, September). Quantum Internet: From
communication to distributed computing! In Proceedings of the 5th ACM International
Conference on Nanoscale Computing and Communication (pp. 1–4).
4. Sahu, I. K., & Nene, M. J. (2021, February). Identity-Based Integrity Veriﬁcation (IBIV)
protocol for cloud data storage. In 2021 International Conference on Advances in Electrical,
Computing, Communication and Sustainable Technologies (ICAECT) (pp. 1–6). IEEE.
5. Dadheech, A. (2017). Study of lattice based FHE for cloud data security. International Journal
of Advanced Research in Computer Science, 8(7).
6. Saravanan, N., & Umamakeswari, A. (2021). Lattice based access control for protecting user
data in cloud environments with hybrid security. Computers & Security, 100, 102074.
7. Wootters,W.K.,&Zurek,W.H.(1982).Asinglequantumcannotbecloned.Nature,299(5886),
802–803. https://doi.org/10.1038/299802a0
8. Lindblad, G. (1999). Letters in Mathematical Physics, 47(2), 189–196. https://doi.org/10.1023/
a:1007581027660
9. Bužek, V., & Hillery, M. (1996). Quantum copying: Beyond the no-cloning theorem. Physical
Review A, 54(3), 1844–1852. https://doi.org/10.1103/physreva.54.1844
10. Daffertshofer, A., Plastino, A. R., & Plastino, A. (2002). Classical no-cloning theorem. Physical
Review Letters, 88(21). https://doi.org/10.1103/physrevlett.88.210601
11. Gupta, M., & Nene, M. J. (2020, December). Quantum computing: An entanglement measure-
ment. In 2020 IEEE International Conference on Advent Trends in Multidisciplinary Research
and Innovation (ICATMRI) (pp. 1–6). IEEE.
12. Nema, P., & Nene, M. J. (2020, December). Pauli matrix based quantum communication
protocol. In 2020 IEEE International Conference on Advent Trends in Multidisciplinary
Research and Innovation (ICATMRI) (pp. 1–6). IEEE.

78
A. Sharma et al.
13. Sharma, M. K., & Nene, M. J. (2019, October). Quantum one time password with biometrics.
In International Conference on Innovative Data Communication Technologies and Application
(pp. 312–318). Springer.
14. Sharma, M. K., & Nene, M. J. (2020). Dual factor third–party biometric—based authentication
scheme using quantum one time passwords. Security and Privacy, 3(6), e129.
15. Yanofsky, N. S., & Mannucci, M. A. (2008). Quantum computing for computer scientists.
Cambridge University Press.
16. Boyer, M., Liss, R., & Mor, T. (2017). Geometry of entanglement in the Bloch sphere. Physical
Review A, 95(3). https://doi.org/10.1103/physreva.95.032308
17. Bassi, A., Lochan, K., Satin, S., Singh, T. P., & Ulbricht, H. (2013). Models of wave-function
collapse, underlying theories, and experimental tests. Reviews of Modern Physics, 85(2), 471–
527. https://doi.org/10.1103/revmodphys.85.471
18. Brandão, F. G. S. L., & Gour, G. (2015). Reversible framework for quantum resource theories.
Physical Review Letters, 115(7).
19. Wootters, W. K., & Zurek, W. H. (2009). The no-cloning theorem. Physics Today, 62(2), 76–77.
20. Koashi, M., & Imoto, N. (1998). No-cloning theorem of entangled states. Physical Review
Letters, 81(19), 4264–4267. https://doi.org/10.1103/physrevlett.81.4264
21. IBM Quantum experience (online). https://quantum-computing.ibm.com

A Study Towards Bangla Fake News
Detection Using Machine Learning
and Deep Learning
Elias Hossain, Md. Nadim Kaysar, Abu Zahid Md. Jalal Uddin Joy,
Md. Mizanur Rahman, and Wahidur Rahman
Abstract Verifying Bangla Fake news is challenging, especially if there are many
updates from various sources such as social media or online news portals. This study
aims to identify the Bangla fake news article; therefore, our Corpus is trained with
57,000 Bangla news items related to trustworthiness and counterfeit. In this study,
95% and 94% accuracy were found by applying K-fold cross validation on top of Bi-
LSTM with Glove and FastText model. At the time, the research is also experimented
with the state-of-the-art technique like Gated Recurrent Unit (GRU) and found the
accuracy 77%. In sharp contrast, we tracked out the accuracy of 96% utilizing the
Bi-LSTM which identically indicates our proposed model. A comparative study on
existing work has been utilized in this research. Again, some experimental analysis
based on the FEM is shown elaborately in this research. However, the proposed
system can be adjustable in real-time news classiﬁcation of Bangla Fake news.
Keywords Bangla fake news · Text classiﬁcation · Machine learning · Random
forest · LSTM · Bi-LSTM · CNN · Glove · Fasttext · Gated Recurrent Unit (GRU)
E. Hossain · A. Z. Md. Jalal Uddin Joy
Department of Software Engineering, Daffodil International University, Dhaka, Bangladesh
Md. Nadim Kaysar
Department of Computer Science & Engineering, World University of Bangladesh, Dhaka,
Bangladesh
Md. Mizanur Rahman
Department of Computer Science and Engineering, Rajshahi University of Engineering and
Technology, Rajshahi, Bangladesh
Wahidur Rahman (B)
Department of Computer Science & Engineering, Mawlana Bhashani Science and Technology
University, Santosh, Bangladesh
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_7
79

80
E. Hossain et al.
1
Introduction
The world today is rich with data and information on news and events. Due to modern
communication technology, people today have easy access to information. This also
means data is also produced in large amounts by millions who have access to the
internet, especially social media. Access to data is not a problem, but it is dangerous
when these data include fake news or stories that spread worldwide. This fake news
can cause misunderstanding and even political tension and it has immoral impression
on personal and social life. A recent report illustrates, about one in three citizens in
the United States, Spain, Germany, United Kingdom, Argentina, and South Korea
claim they have seen untrue or deceiving data on social media related to COVID-19
[1].
Impact of fake news is producing devastation worldwide. In 2012, several Pagoda
was torched in Bangladesh after an image showed a derogatory picture of the Quran.
The image was tagged with a Buddhist youth but was not responsible for the photo in
any way. Many rumors spread because of this image even though the image’s identity
could not be veriﬁed [2]. In 2019, a false rumor circulated online about the Padma
Bridge authorities sacriﬁcing humans’ lives at the construction site. This rumor then
leads to suspicion of random individuals being child kidnappers [3]. In Bangladesh,
the 2012 Ramu incident is a standard example where almost 25 thousand people
joined in abolishing the Buddhist temples on the source of a Facebook post from a
fake account [4].
Fortunately, there are websites to tackle fake news, But these websites are not able
to sufﬁciently respond to many fake news incidents. There are some computational
approaches used to isolate fake news, which is destructive for our daily life. Nowa-
days, we found lots of research work in English Languages. As of now, more than
341 million people in the world communicate with Bangla Language. But there is no
resource to detect fake news written in the Bangla language. The aim of this work is
to develop a solution to ﬁght against misinformation. This study also aims to create
an AI-based effective system to identify fraud news articles by applying Traditional
Machine Learning and Deep Learning algorithms. Through our proposed solution,
we can easily classify inaccurate Bangla news. Our contribution can be summarized
as follows:
• We have presented a comparative analysis based on numerous feature extraction
approach with traditional machine learning and deep learning.
• We develop a classiﬁcation system to detect fake news written in the Bangla
language. Additionally, we have implemented different type’s pre-trained model
in this problem.
• We have shown a separate text preprocessing pipeline for each approach, which
will positively impact the research community.

A Study Towards Bangla Fake News Detection Using Machine …
81
The manuscript is classiﬁed into ﬁve sections. Section two presents the back-
ground study of previous contributions. Section three shows the proposed method-
ology and working principles. Section four illustrates the results with proper
discussion. Finally, section ﬁve depicts the conclusion of this manuscript.
2
Related Works
The author of paper [5] proposed the multinomial Naïve Bayes model to detect
Malicious Bangla Text Content by using social networks. The proposed research
recognizes spam based on the extremity of each sentence related to it, and accuracy
was found 82.44% [6]. Was tried to detect hateful speech in Public Facebook Pages
for the Bengali Language. The authors developed a machine learning-based model,
but they could not achieve satisfactory accuracy. So a neural network-based Gated
Recurrent Unit (GRU) model was considered. The accuracy of the GRU was 70%
[7]. Conducted research for the Automatic Detection of Satire on Bangla Documents.
Convolutional Neural Network (CNN) was used for this model and obtained 96.4%
accuracy [8]. Used a Deep Convolution Nets approach to categories the Bangla
Documents programmatically. Word2vec was utilized for feature extraction, and
they proposed a “DCNN” deep learning-related neural network, whose accuracy
was 94% [9]. Proposed Bangla word embedding and its application of Bangla text
classiﬁcation. The Skip n-gram method was applied for word embedding with various
dimensions and Support Vector Machine (SVM) [10]. Showed Boosting on Stylo-
metric and Word Vector Features method to identify fake news with 95% accuracy
[11]. Demonstrated their work by using Convolutional Neural Network (CNN) for
the detection of fake news. The study was conducted on the English dataset, and
the performance score stood at 98% [12]. Classiﬁed fake news by using the LSTM
approach. The authors used different dens layers and various percentages of ﬁlters
using the Conv1D layer. Glove pre-trained word embedding to ﬁnd out fraud news
[13]. Researched detecting fake news on Social Media Networks. Fake news was
classiﬁed by applying various types of traditional machine learning algorithms [14].
Explained tensor decomposition-based deep neural network for improving fake news
detection. A deepFake method was proposed by applying the BuzzFeed and Poli-
tiFact dataset. In [15] research proposed a CNN based ﬂood management system,
which predicts available space of the tank using IOT sensors data [16]. Conducted
with traditional machine learning approach with imbalance data and they are used
numerous types of techniques resolve imbalanced data problem.
Reviewing the above study shows that not enough research has been accomplished
onvastdatasets.Somedrawbackscanbefoundintheabovestudymentioned.Authors
[5] acknowledges they do not have sufﬁcient Corpus for their work. The authors [6]
detect hateful speech from Public Facebook Pages for the Bengali Language over
5126 Bengali comments; they have only experimented through traditional machine
learning algorithms. Still, the amount of datasets is comparatively less.

82
E. Hossain et al.
In our proposed research, we have applied deep learning and machine learning
algorithms for classifying fake news reports in the context of Bangla language.
Various features have been generated for the conventional approach, such as unigram
and bigram. This is the most extensive dataset in Bangla, with a volume of 57,000
as far as we know and handling such a massive dataset is exceptionally challenging.
We have shown a separate text preprocessing pipeline for each approach, which will
positively impact the research community. While not enormous research has been
done on top of Bangla, it will serve as a Benchmark for those who desire to work
with Bangla News Classiﬁcation.
3
Proposed Research Methodology (PRM)
In this proposed study, several traditional machine learning and deep learning algo-
rithms are tested in terms of Bangla misleading news identiﬁcation from news reports.
The Proposed Research Methodology (PRM) is divided into four segments: Experi-
mental Setup, Data Preparation Pipeline (DPP), Features Extraction Methods (FEM),
and Algorithm Selection Procedure (ASP).
By looking at Fig. 1, it can be observed that the proposed research architecture
diagram is classiﬁed into several phases, and each stage completes an individual task.
More importantly, text preprocessing is completed in the ﬁrst stage using pre-trained
and non pre-trained models; then, the model is fed into the machine learning and deep
learning algorithms; afterwards, the model evaluation is accomplished, moving to
architecture embodiment eventually, the documents are being classiﬁed. The details
sequence and consequences are visualized in Fig. 1.
BEGIN 
END
Step 1: Data read from CSV file 
Step 2: Data pre-processing 
Step 3: Feature Extract:   
            if(Machine Learning Based Feature Extract): 
                Use TF-IDF|| Bag of Words || Word2Vec method 
           else:  
                Use One hot encoding || Glove/fastText pre-trained 
Step 4: Model Selection: 
            If(Machine Learning based algorithm): 
                Use DTC || RF ||SVM ||NB||GB||LR||KNN 
            Else: 
                 Use LSTM || CNN|| Bi-LSTM|| GRU 
Step 5: Output of the model.        
Psedo code.1. Working flow of propose approach. 

A Study Towards Bangla Fake News Detection Using Machine …
83
Fig. 1 Architecture diagram of the proposed research
3.1
Experimental Setup
In this section, we have described our research dataset based on the Bangla news arti-
cles. The proposed research dataset contains 57,000 news articles that were collected
from various news portals of Bangladesh. We have collected the dataset from [4].
Table 1 shows the dataset description.
3.2
Data Preparation Pipeline (DPP)
Data preparation is an essential part of applying every machine learning algorithm,
and while working on text data, the corpus needs to be cleaned to apply the machine
learning algorithm [17]. Data Preparation concludes with data preprocessing. Text
preprocessing recommends stops words, punctuation, phrases that do not carry much
weight in context to the text, etc.

84
E. Hossain et al.
Table 1 News description
Feature
Authentic
Fake
Domain
jagonews24.com
channeldhaka.news
Publication Time
2018-09-19 22:00:27
2019-02-22T14:50:20+00:00
Category
National
Technology
Headline
Article
Label
1
0
Noise Filtering & Text Normalization. The noises have been ﬁltered from
the text corpus of this research, such as removing constant features, drop-
ping
duplicate
data,
dropping
identical
columns,
removing
null
values,
applying regular expressions, and removing stop words. Bangla is still now
as a low resource has not yet developed a large corpus like NLTK, but
some stop words are found in the case of Bengali text data, for example,
and so on. We have removed stop words through BLTK Library [18]. Stem-
ming programs are known as stemming or stemmers. An algorithm reduces the
words “chocolates”, “chocolatey”, “choco” to the foundation word, “chocolate”
and “retrieval”, “retrieved”, “retrieves” cut back to the stem “retrieve”. We have
endeavored for Stemming through the BLTK library [18].
3.3
Features Extraction Methods (FEM)
In this section, Feature extraction approaches are described and has been classiﬁed
into Non Pre-trained Model Intuition (NPMI) and Pre-trained Model Intuition (PMI).
Non Pre-trained Model Intuition (NPMI)
Term Frequency (TF)—Inverse Document Frequency (IDF). In Natural
Language Processing, various features extraction techniques can be found to extract
features for the text document; for instance, Bag-of-Words (BOW), Term Frequency-
Inverse Document (TF-IDF), Count Vectorizer, etc. [19]. TF (Term Frequency),
which measures how frequently terms occurred in a document. On the other hand,
Inverse Document Frequency (IDF) is a score of words in a full document. Another
signiﬁcant parameter of the TF-IDF feature extraction approach is N-gram that is a
sequence of N tokens or words [20]. We can write the equation of TF-IDF as follows:
TF: tf(w, d) = log(1 + f (w, d)), IDF: tf(w, D) = log

N
f (w, D)

(1)

A Study Towards Bangla Fake News Detection Using Machine …
85
TF IDF:tf - idf(w, d, D) = tf(w, d) ∗tf(w, D)
(2)
Over here, w is a word, and d is a document. F(w,d) is a frequency of the word
in a document-the inverse document frequency (IDF) of the word across a set of
documents. Here N is the number of documents and f (w,d) is a number of the
document containing the corpus word. Multiplying these two numbers results in the
TF-IDF score of a word in the document.
Pre-trained Model Intuition (PMI)
Word2Vec. Word2Vec is a superﬁcial word embedding model proposed by [21].
This is to say that Word2Vec describes word embedding with two-layer shallow
neural networks. It has several conveniences over the bag-of-words and the TF-IDF
approach, which takes on the semantic meaning of the document’s different words.
Nonetheless, two types of architecture can be found inside CBOW (Continuous
Bag-of-Words) and skip-gram model [22] thus, we proposed a skip-gram model and
skip-gram uses word information to predict its neighbour word, which is deﬁned as:
1
T
T

t=1

−c≤j≤c, j̸=0
log p(ωt+ j|ωt
(3)
In the above equation, c denoted as a training context (c become a function of the
center word ωt). The besic formula of skip-gram by using the softmax function:
p(wO|wI) =
exp

vT
wOvwI

W
w=1 exp

v′T
w vwI

(4)
where ϑω is input and ϑ
′
ω is the output of the vector representation of ω. W is the
number of words in the vocabulary. The cost computing ∇log(ωo|ωi) is proportional
to W, so that formula is impractical.
3.4
Algorithm Selection Procedure (ASP)
In our proposed research, we have experimented through the Supervised Machine
Learning Algorithm and Deep Learning Algorithm. We have classiﬁed this section
into two phases: the Machine Learning Model (MLM) and Neural Network Model
(NNM).
Machine Learning Model (MLM). In this section, six classiﬁcation algorithms
were applied, such as Decision Tree Classiﬁer, Random Forest Classiﬁer (RF), K
Nearest Neighbor (KNN), Multinomial Naïve Bayes, Gradient Boosting, Support
Vector Machine (SVM), and Logistic Regression. After experimenting, we observed

86
E. Hossain et al.
thattheDecisionTreeClassiﬁer(DTC)andRandomForestClassiﬁer(RF)performed
well, so the DTC is described in this section.
Decision Tree Classiﬁer (DTC). Decision Tree Classiﬁer (DTC) is a prior classiﬁca-
tion algorithm for text and data mining [23]. DTC is used effectively for classiﬁcation
invariousﬁelds[24].Theprimaryconceptismakingatreethatsupportedtheattribute
for categorized data points. However, the biggest challenge of a DTC is that attribute
or feature might be at the parents’ level and that one ought to be at the kid level. An
applied math modeling [25] addressed feature choice within the tree to solve this
downside. For a training set comprising p positive and n negative:
H

p
n + p ,
n
n + p

= −
p
n + p log2
p
n + p −
n
n + p log2
n
n + p
(5)
Choose K in the attribute with the unique value, the training set E divides into
the preﬁxes of {E1, E2, . . . , Ek} The expected entropy (EH) will remain after the
attempt in the attribute (branches i = 1, 2, . . . , k) including:
EH(A) =
K

i=1
pi + ni
p + n H

pi
ni + pi
,
ni
ni + pi

(6)
Information gain (I) or decrease in entropy for this trait is:
A(I) = H

p
n + p ,
n
n + p

−EH(A)
(7)
Select the property with the most prominent information gain as a parent’s hub.
Neural Network Model (NNM). This section explains Convolutional Neural
Networks (CNN), Long short term memory (LSTM), and Bidirectional LSTM (BI-
LSTM) that have been experimented with for classifying the text documents in this
research.
Convolutional Neural Network (CNN). The basic functionality of a convolution
neural network is similar to that of the animal brain’s visual cortex. Convolution
Neural Networks perform well in text classiﬁcation tasks. The criteria for text clas-
siﬁcation are identical to those for image classiﬁcation, except that instead of pixel
values, we have a matrix of word vectors. Convolutional Neural Networks (CNN) is
one of the most popular algorithms for machine learning. The CNN illustrates fruit-
fulness to classify the short and long text [26]. So we examined categorizing Bangla
as Fake news with the help of CNN. CNN’s hidden layers usually contain convolu-
tional layers, pooling layers, fully connected layers, and generalization layers [27].
Here, embedding represents every word numeric vector, and the embedding creates a
data table where each row of that table representing the embedding of a word. Every
embedding have some parameters like voc-size and embedding-dim. Here voc_size

A Study Towards Bangla Fake News Detection Using Machine …
87
represent the number of unique words in a document and embedding-dim, describing
the number of dimensions of each term [11].
Convolutional Layer. This is the ﬁrst layer and one of the primary components of
a Convolutional Neural Network (CNNs). They take as input the raw pixel values of
the training image and extract features from them. This layer ensures that pixels are
spatially related by learning image features from small squares of input data [28].
Mathematically, we can deﬁne as a combination of two functions “f ” and “g” as:
( f ∗g)(i) =
m

j=1
g( j). f

i −j + m
2
	
(8)
Pooling Layer. Another essential concept of convoluted neural networks is pooling,
recognized as a form of non-linear down-sampling. Pooling performs to extract the
Particular Value (Max/Average Value) from the speciﬁed portion (n × n) of the
matrix. In this architecture, the max-pooling layers combine the output from the
convolutional layers. All results from the convolutional layers are concentrated and
conveyed to the following level of the convolutional layer [29].
Fully Connected Layer. The fully connected layer is also known as the dense layer.
Each neuron receives input from its predecessor neuron, and it is densely connected.
The output calculates by optimizing the loss with the result obtained by weight
initiation with each neuron [30]. Suppose we have an input layer where the inputs
are ×1, ×2, and ×3 and a hidden layer H1. The weight initialization of each neuron
is y1, y2, and y3. After adding bias, we can see the output following:
Y =
n

i=1
wi ∗xi + wn ∗xn · · · + bias
(9)
Twotypesofpropagationcanbeusedtoreduceerrors,suchasforwardpropagation
and backward propagation. When considered multiple hidden layers, in that case, the
error usually reduces through the backpropagation. In backpropagation, derivatives
are complete by chain rules [31].
Dropout. The Dropout, which helps avoid overﬁtting, randomly sets input units
to 0 with a frequency of rate at each stage during training time. It should be noted
that the Dropout is only active when training is set to True, which means that no
values are lowered during inference when using the model.
Activation Function. We have considered the ReLu as an activation function for our
CNN architecture. The foremost advantage of the ReLu function is that it eliminates
the negative rate from an activation map by labeling them zero in a network. The
vanishing gradient problem is solved efﬁciently through this function [31].

88
E. Hossain et al.
Long Short Term Memory (LSTM). Having the capability to catch up with the
sequential information, the LSTM is usually widely used for text classiﬁcation-
related issues. In particular, by collecting sequential information from both direc-
tions in texts, Bidirectional LSTM (Bi-LSTM) has demonstrated impressive efﬁ-
ciency. Besides, when used with Bi-LSTM, the attention mechanism has been noticed
as a potential pooling technique for classiﬁcation tasks. In this research, we have
experimented through Bidirectional LSTM (Bi-LSTM) model that is close to focus
on top [32]. However, the following architecture that has been used in Bi-LSTM:
Inputcontainsvocabularysize,embedding_vector_features,andinputshape,Spatial-
Dropout1D layer with value 0.4, Bidirectional with 356 LSTM units, Dropout with
value 0.2 to avoid overﬁtting, A dense layer with 2 neurons with softmax activation
function.
4
Result and Analysis
This section consists of the two-phase, to illustrate, Performance Analysis (PA),
Comparative Analysis (CA). The PA is further subdivided into two-part, for instance,
Consequence of the Model (CM) and Model Evaluation Report (MER).
4.1
Performance Analysis (PA)
This section mainly analyzes the performance obtained through the classiﬁcation
algorithms of machine learning. However, two approaches are described in this
section: the performance of the traditional machine learning algorithm and the deep
learning algorithm. Our research found that Deep Learning algorithms play a vital
role in Text classiﬁcation rather than Traditional Machine Learning Algorithms.
Consequence of the Model (CM). As we have mentioned earlier, this study has
experimented through the seven classiﬁcation algorithms, so the precision, recall,
and f 1-score of the algorithms are shown in Table 2. In Tables 3 and 4 where the
precision has been written “P” and the same way the recall is “R” and the F1-
Score is “F1”. We are present number of TP, TN, FP, and FN by confusion matrix.
Tables 2, 3 and 4 shows the Classiﬁcation report of the traditional approach and Deep
Learning-based approach. Equations (10), (11), (12), and (13) show the formula for
ﬁnding precision, recall, F-1 score, and accuracy. We obtained higher accuracy in
the random forest (ensemble learning), which is 89% accuracy. Furthermore, On the
other hand, DTC, KNN, NB, GB, SVM, and LR are give 86%, 78%, 67%, 73%, 88%,
and 73% accuracy with Uni-gram. Table 1 describes the same traditional algorithm
with Bi-gram approach and got maximum 78% validity from Random Forest (RF).
Besides, others algorithm are performance not so well. The word2vec method used
in Table 3 and got 83% accuracy in RF. Our Neural network model has shown

A Study Towards Bangla Fake News Detection Using Machine …
89
Table 2 Classiﬁcation report for TF-IDF (Uni-gram and Bi-gram) approach
Algorithm
Approach
Authentic
Fake
P
R
F1
P
R
F1
DTC
TF-IDF
(Uni-gram)
0.88
0.83
0.86
0.84
0.89
0.86
RF
0.91
0.87
0.89
0.87
0.91
0.89
KNN
0.93
0.51
0.66
0.66
0.96
0.78
NB
0.67
0.67
0.67
0.67
0.67
0.67
GB
0.75
0.66
0.70
0.69
0.78
0.73
SVM
0.96
0.77
0.86
0.81
0.97
0.88
LR
0.73
0.71
0.72
0.72
0.74
0.73
DTC
TF-IDF
(Bi-gram)
0.88
0.59
0.71
0.69
0.92
0.79
RF
0.90
0.61
0.73
0.70
0.93
0.80
KNN
0.90
0.47
0.62
0.64
0.94
0.76
NB
0.84
0.53
0.65
0.66
0.90
0.76
GB
0.84
0.21
0.33
0.55
0.96
0.70
SVM
0.93
0.54
0.68
0.67
0.96
0.79
LR
0.84
0.58
0.68
0.68
0.89
0.77
Table 3 Classiﬁcation report for Word2Vec approach
Algorithm
Authentic
Fake
P
R
F1
P
R
F1
DTC
0.81
0.80
0.81
0.80
0.82
0.81
RF
0.84
0.80
0.83
0.82
0.84
0.83
KNN
0.84
0.75
0.79
0.77
0.86
0.81
NB
0.56
0.52
0.54
0.54
0.59
0.56
GB
0.61
0.63
0.62
0.61
0.59
0.60
SVM
0.57
0.34
0.43
0.53
0.74
0.62
LR
0.56
0.53
0.54
0.55
0.57
0.56
outstanding performance, and two pre-trained models are also used to improve the
accuracy in Table 4. In the LSTM experiment, we got accuracy of 96%. On the other
hand, we conduct Bi-LSTM with validity of 96%. Here, CNN and GRU models are
implemented with 95% and 78% accuracy, and the CNN model of authentic news
F1 score is 96%, and Fake F1 score is 95%. Moreover, we have conducted the glove
and Fasttext pre-trained model with Bi-LSTM, and the accuracy was 95% and 94%.
precision =
TP
TP + FP
(10)

90
E. Hossain et al.
Table 4 Classiﬁcation report of Deep Learning algorithms (based on the features extraction
approach)
Algorithm’s
Feature
extraction
Authentic
Fake
P
R
F1
P
R
F1
LSTM
One hot
encoding
0.93
0.99
0.96
0.99
0.93
0.96
Bi-LSTM
One hot
encoding
0.93
0.99
0.96
0.99
0.93
0.96
CNN
One hot
encoding
0.93
0.99
0.96
0.98
0.93
0.95
GRU
One hot
encoding
0.76
0.82
0.79
0.80
0.74
0.77
Bi-LSTM with
Glove
Glove
0.93
0.98
0.95
0.97
0.93
0.95
Bi-LSTM with
Fasttext
FastText
0.93
0.96
0.94
0.96
0.92
0.94
recall =
TP
TP + FN
(11)
F1 = 2 · precision . recall
precision + recall
(12)
accuracy =
TP + TN
TP + TN + FP + FN
(13)
Model Evaluation Report (MER). Another approach is to decide how good the
performance of different classiﬁcation models is the ROC-AUC curve. Figures 2 and
3 show the ROC-AUC curve on top of Bi-LSTM with Glove and Fasttext pre-trained
model. We have used K = 5 to cross validation. Here, K = 1 fold is test data and K =
2, K = 3, K = 4 and K = 5 fold data are training data. ROC-AUC mean value of every
fold Glove pre-trained model is 99%.On the other hand, ROC-AUC mean value of
Fasttext pre-trained model 98%. This study has been applied to the ROC-AUC curve
on top of the Bi-LSTM with Glove FastText model. The blue line in Figs. 2 and 3 is
ROC, and the space below this ROC is AUC. The higher the value of ROC close to
the value 1.0 in blue marked region refers to the signiﬁcance of the trained model.
Nevertheless, Cross validation details sequence and a clear visualization are shown
in Figs. 2 and 3, respectively. On the other hand, the confusion matrix, accuracy
assessment, and loss measurement approaches are shown in Figs. 4, 5, 6, and 7,
respectively.

A Study Towards Bangla Fake News Detection Using Machine …
91
Fig. 2 ROC Curve for
Bi-LSTM using Glove
Fig. 3 ROC Curve for
Bi-LSTM using fastText
4.2
Comparative Analysis (CA)
This section discusses Comparative Analysis (CA). This research has been compared
with the top four research papers that accomplished on Bangla News Classiﬁcation.
Table 5 shows a comparison between recent publications with the proposed study.
Articles in Table 5 with higher accuracy than the proposed research are called “yes”;

92
E. Hossain et al.
Fig. 4 Confusion matrix of
Bi-LSTM with Glove
Fig. 5 Confusion matrix of
Bi-LSTM with fastText
thus, papers with a lower accuracy refer to “no.” If the previous study’s accuracy
equivalent to with the proposed research, they are mentioned “equal.”
5
Conclusions and Future Work
FakenewscontentsnotonlyappearinEnglishlanguagebutalsoseeminother’snative
languages. This research proposed a Machine Learning and Deep Learning approach
with different features extraction pipelines that will place signiﬁcant benchmarks in
the ﬁeld of Bangla fake news classiﬁcation. The previous contributors had experi-
enced a higher accuracy on a limited dataset, but this work had been utilized a dataset

A Study Towards Bangla Fake News Detection Using Machine …
93
Fig. 6 Accuracy Measurement of Bi-LSTM
Fig. 7 Loss Mesurment of Bi-LSTM
Table 5 Comparison table
Paper’s
Feature
extraction
Algorithm
Accuracy (%) Match with
proposed
accuracy
(Yes/No/Equal)
[4]
MNB
Count Vectorizer, TF-IDF
82.44
No
[5]
GRU
TF-IDF
70.10
No
[6]
CNN
Word2Vec, TF-IDF
96
Equal
[8]
SVM
Word2Vec
91
No
Our proposed
model
Bi-LSTM One hot encoding
96

94
E. Hossain et al.
containing 57 thousand online articles. This research has tracked out the accuracy
of 96% by using the Bi-LSTM model. By experimenting with machine learning and
deep learning algorithms, the proposed model has experienced better performance
with the deep learning models compared to the traditional machine learning algo-
rithms. This paper also ensures a comparative study among existing works on Bangla
fake news detection strategy. Though the proposed work has found improved perfor-
mance, it has experienced some limitations. First of all, Bangla language is still a very
low resource language compared to the others existing languages. Secondly, there
is no sufﬁcient library like NLTK to work with Bangla language. Finally, more and
more data preprocessing are required to boost up the accuracy level of the proposed
model. In the future, we will come up with a solution to crack these limitations to
ﬁnd the enhanced results in Bangla fake news detection and classiﬁcation. However,
the objective of this research is achieved and the proposed model can be practicable
in real life Bangla fake news recognition.
References
1. Nielsen, R. K., et al. (2020). Navigating the ‘infodemic’: How people in six countries access
and rate news and information about coronavirus. Reuters Institute.
2. Star, T. D. (2012). A hazy picture appears.
3. Star, T. D. (2019). Mobs beat ﬁve dead for ‘kidnapping’.
4. Hossain, M. Z., et al. (2020). BanFakeNews: A dataset for detecting fake news in bangla. arXiv
preprint arxiv.org/abs/2004.08789
5. Islam, T., Latif, S., & Ahmed, N. (2019). Using social networks to detect malicious bangla
text content. ˙In 2019 1st International Conference on Advances in Science, Engineering and
Robotics Technology (ICASERT). IEEE.
6. Ishmam, A. M., & Sharmin, S. (2019). Hateful speech detection in public Facebook pages for
the Bengali language. ˙In 2019 18th IEEE International Conference On Machine Learning And
Applications (ICMLA). IEEE.
7. Sharma, A. S., Mridul, M. A., & Islam, M. S. (2019). Automatic detection of satire in bangla
documents: A cnn approach based on hybrid feature extraction model. ˙In 2019 International
Conference on Bangla Speech and Language Processing (ICBSLP). IEEE.
8. Hossain, M. R., & Hoque, M. M. (2019). Automatic bengali document categorization based on
deep convolution nets. Emerging Research in Computing, Information, Communication and
Applications (pp. 513–525). Springer.
9. Ahmad, A., & Amin, M. R. (2016). Bengali word embeddings and it’s application in solving
document classiﬁcation problem. ˙In 2016 19th International Conference on Computer and
Information Technology (ICCIT). IEEE.
10. Reddy, H., et al. (2020). Text-mining-based fake news detection using ensemble methods.
International Journal of Automation and Computing, 1–12.
11. Kaliyar, R. K., et al. (2020). FNDNet–a deep convolutional neural network for fake news
detection. Cognitive Systems Research, 61, 32–44.
12. Agarwal, A., et al. (2020). Fake news detection using a blend of neural networks: An application
of deep learning. SN Computer Science, 1(3), 1–9.
13. Aldwairi, M., & Alwahedi, A. (2018). Detecting fake news in social media networks. Procedia
Computer Science, 141, 215–222.
14. Kaliyar, R. K., Goswami, A., & Narang, P. (2021). DeepFakE: Improving fake news detection
using tensor decomposition-based deep neural network. The Journal of Supercomputing, 77(2),
1015–1037.

A Study Towards Bangla Fake News Detection Using Machine …
95
15. Smys, S., Basar, A., & Wang, H. (2020). CNN based ﬂood management system with IoT
sensors and cloud data. Journal of Artiﬁcial Intelligence, 2(04), 194–200.
16. Chakrabarty, N., & Biswas, S. (2020). Navo Minority Over-sampling Technique (NMOTe): A
consistent performance booster on imbalanced datasets. Journal of Electronics, 2(02), 96–136.
17. Kalra, V., & Aggarwal, R. (2017). Importance of text data preprocessing & ımplementation in
RapidMiner. ˙In ICITKM.
18. Hossain, S. (2012). BLTK: The Bengali natural language processing toolkit.
19. Waykole, R. N., & Thakare, A. D. (2018). A review of feature extraction methods for text
classiﬁcation. International Journal of Advanced Research and Development, 5(04).
20. Shah, F. P., & Patel, V. (2016). A review on feature selection and feature extraction for text clas-
siﬁcation. ˙In 2016 ˙International Conference on Wireless Communications, Signal Processing
and Networking (WiSPNET). IEEE.
21. Mikolov, T., et al. (2013). Efﬁcient estimation of word representations in vector space. arXiv
preprint arXiv:1301.3781
22. Naili, M., Chaibi, A. H., & Ghezala, H. H. B. (2017). Comparative study of word embedding
methods in topic segmentation. Procedia computer science, 112, 340–349.
23. Morgan, J. N., & Sonquist, J. A. (1963). Problems in the analysis of survey data, and a proposal.
Journal of the American Statistical Association, 58(302), 415–434.
24. Anyanwu Matthew, N., & Shiva Sajjan, G. Comparative analysis of serial decision tree
classiﬁcation algorithms. Issue.
25. De Mántaras, R. L. (1991). A distance-based attribute selection measure for decision tree
induction. Machine Learning, 6(1), 81–92.
26. Shrestha, P., et al. (2017). Convolutional neural networks for authorship attribution of short
texts. In Proceedings of the 15th Conference of the European Chapter of the Association for
Computational Linguistics (Vol. 2, Short Papers).
27. PAI, A. (2020). https://www.analyticsvidhya.com/blog/2020/01/ﬁrst-text-classiﬁcation-in-pyt
orch/
28. Zhong, B., et al. (2019). Convolutional neural network: Deep learning-based classiﬁcation of
building quality problems. Advanced Engineering Informatics, 40, 46–57.
29. Shang, L., et al. (2020). Sentiment analysis of ﬁlm reviews based on CNN-BLSTM-Attention.
Journal of Physics: Conference Series.
30. Rakhlin, A. (2016). Convolutional neural networks for sentence classiﬁcation. GitHub.
31. Bengio, Y., Courville, A., & Vincent, P. (2013). Representation learning: A review and new
perspectives. IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(8), 1798–
1828.
32. Zhou, P., et al. (2016). Attention-based bidirectional long short-term memory networks for
relation classiﬁcation. ˙In Proceedings of the 54th Annual Meeting of the Association for
Computational Linguistics (Vol. 2: Short papers).

A Deep Learning Approach to Analyze
the Propagation of Pandemic in America
Paola G. Vinueza-Naranjo, Angel F. Vinueza-Naranjo,
and Hieda A. Nascimento-Silva
Abstract The new Coronavirus Disease 2019 (COVID-19) opened new and signif-
icant challenges for the research community. Deep learning (DL) models could be
used to extract important information from continuously generated data to detect and
predict the COVID-19 epidemic growth by continuously monitoring it. Together with
the next-generation fog computing (FC) framework, the strategies could be designed
to help and manage the spread of the virus in a speciﬁc region effectively. Inspired
by future Internet technologies, we propose an algorithm that applies a mathematical
model using DL to predict and analyze the growth and spread of the COVID-19 in
America. We also proposed an FC platform to predict real-time data gathered from
patients in America’s geographical location. The DL-based prediction technique to
be utilized in remote Fog Nodes (FNs) to make a more accurate prediction in human
networks. Finally, we delineate some research opportunities, as well as preparation
bases for practical applications. The simulation results conﬁrm the model’s efﬁciency
and precision in America and the countries most affected by the epidemic. The pro-
posed model could help the related governments apply needful actions to control the
spread of the pandemic.
Keywords Deep learning (DL) · Fog computing (FC) · Internet of Thing (IoT) ·
Pandemic · COVID-19 · Epidemic control
P. G. Vinueza-Naranjo (B)
Faculty of Engineering, Information Technology and Communication, Universidad Nacional de
Chimborazo, Riobamba, Ecuador
e-mail: paolag.vinueza@unach.edu.ec
A. F. Vinueza-Naranjo
Faculty of Engineering, Telecommunication, Pontiﬁcia Universidad Católica del Ecuador, Quito,
Ecuador
e-mail: angelfvn@unach.edu.ec
H. A. Nascimento-Silva
Faculty of Engineering, Telecommunication, Federal University of Pará, Belem, Brazil
e-mail: hieda@ufpa.br
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_8
97

98
P. G. Vinueza-Naranjo et al.
1
Introduction
The novel coronavirus disease 2019, also designated as COVID-19 caused by a
new severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has practi-
cally spread to every corner of the Earth in a short period unfolding not only into
a severe global public health crisis but also social and economic crisis. The out-
break of COVID-19 was ﬁrst detected in Wuhan, China in December 2019 which
was subsequently declared as a pandemic on March 11, 2020, by WHO. Similar
to severe acute respiratory syndrome coronavirus (SARS-CoV) and Middle East
respiratory syndrome coronavirus (MERS-CoV), SARS-CoV-2 causes severe lung
damage leading to viral pneumonia and acute respiratory distress syndrome (ARDS)
in some patients [1, 2]. Several clinical studies have suggested that the cardiovascu-
lar, brain, kidney, liver and immune systems are also crippled due to SARS- CoV-2,
leading to morbidity and mortality at an unprecedented rate worldwide.
In America, the ﬁrst case of evident SARS-CoV-2 transmission emerged on Jan-
uary 21, 2020. The spread was rapid and on February 26, 2020, the ﬁrst case was
reported in South America in São Paulo, Brazil. Until April 2021, the virus has
infected over 133 million people worldwide and every country and territory in North
and Latin America, and the Caribbean has been affected by the pandemic. Until late
March 2021, United States reported the highest number of COVID-19 cases crossing
the 30 million mark, whereas Brazil stood second with more than 13 million con-
ﬁrmed cases. The current statistics have ranked United States as the 12th worst with
COVID-19 cumulative mortality rates of all countries, whereas Peru has reported
the highest COVID-19 death rate in Latin America [3]. This dangerous surge of
COVID-19 continues in the year 2021 and the situation of the pandemic is frightful
in multiple countries in South America where the infection rates are spiking putting
immense pressure on the health systems [4]. The COVID-19 datasets are currently
being collected and released from different sources such as: European Centre for
Disease Prevention and Control (ECDC) [3], World Health Organization (WHO)
[5], Center for Systems Science and Engineering (CSSE) at Johns Hopkins Univer-
sity [6] and others. Some of the recent ﬁndings on the prediction of COVID 19 cases
and the comparison with the proposed work are presented in Table1.
COVID-19 outbreak has resulted in one of the most devastating health debacles
around the globe and ending this crisis will require not only further advances in treat-
ment, prevention strategies and dedicated vaccination programmes but also unprece-
dented efforts from various research communities including the use of emerging tech-
nologies to bridge its gap with the various healthcare systems for future prevention
and intervention. Technological solutions like Deep Learning [7], Cloud Computing,
Fog Computing and the use of artiﬁcial intelligence (AI) [8] and machine learning
can revolutionize the COVID-19 healthcare response by designing strategies and
policies to manage its spread by providing a comprehensive and complete model
to track the disease and predict its growth. Our research is a step towards using the
Fog Computing (FC) architecture in the Deep Learning (DL) model to predict and
understand the COVID-19 spread pattern in America in an effort of revolutionizing
the COVID-19 healthcare response.

A Deep Learning Approach to Analyze the Propagation …
99
Table 1 Comparison of existing works on COVID-19 prediction methodologies with the proposed
work
References
Learning algorithm
Data source
Accuracy
Proposed of
algorithm
Kırba¸s et al. [9]
– Autoregressive
Integrated Moving
Average (ARIMA)
– Nonlinear
Autoregression
Neural Network
(NARNN)
– Long Short Term
Memory (LSTM)
ECDC
MAPE values of
LSTM model are
better than the other
models
An analysis and
comparison were
made to model and
predict the
cumulative conﬁrmed
cases and the total
increase rate of the
countries. LSTM
outperforms other
models
Linardatos et al. [10]
– Autoregressive
Integrated Moving
Average (ARIMA)
– Holt-Winters
Additive Model
(HWAAS)
– TBAT
– Facebook’s Prophet
– Deep AR
KAGGLE
ARIMA and TBAT
outperformed other
models in forecasting
the pandemic
The population of
each country has
been considered, to
predict future
conﬁrmed cases,
death and recovered
from COVID-19
Hawas [11]
– Recurrent Neural
Network (RNN)
CSSE
60.17% accuracy
To predict one month
ahead conﬁrmed
cases and to take
preventive measures
Car et al. [12]
– Multilayer
Perceptron (MLP)
– Artiﬁcial Neural
Network (ANN)
CSSE
Accuracy for
conﬁrmed cases
(0.986R2 Value)
To predict the spread
of pandemic
world-wide
Ogundokun et al. [13] Linear regression
model
NCDC
95% conﬁdence
interval
To predict the
COVID-19 conﬁrmed
cases in Nigeria
1.1
The Goal of the Paper and Its Contributions
In this article, we present the evaluation results of the outbreak of coronavirus disease
in America. Also, to give a clear vision of the dynamics of the epidemic’s spread
to provide governments and ministries of health with a real-time estimation of the
magnitude (peak) in which the epidemic is developing. As a result, in this way, the
governments and ministries of health can effectively face and control this epidemic.
Motivated by this, we propose an FC architecture with a DL model under the FC
platform, which can be executed in real-time (continuously) in the fog data centres
for a more accurate prediction and understanding of the COVID- 19 spread pattern
in America. Speciﬁcally, our model helps us to accurately predict the number of
COVID-19 cases (daily cases-deaths-recovery). Dataset (Data Source) was collected
from the European Center for Disease Control and Prevention (ECDC) [3] (Github
repository), Center for Systems Science and Engineering (CSSE), Johns Hopkins

100
P. G. Vinueza-Naranjo et al.
University (JHU). Dong et al. [6] and WHO [5]. Below, we summarize our main
contributions as follows:
• We generate a new three-tiered architecture that presents the computation and
communication connections between the Internet of Thing (IoT) users, FNs and
remote cloud;
• The DL model that we have proposed DL model to predict the epidemic spread in
heterogeneous populations in each country of America;
• We use Deep Neural Network (DNN) prediction model to analyze the system
behaviour and shape our proposed strategy for learning the model;
• Finally, we use a real dataset obtained from [3] to assess our solution’s precision
and applicability.
1.2
Organization
We organize the paper as follows. The following Sect.2 explains our proposed archi-
tecture. Section3 gives details of our proposed model. In Sect.4, we present the algo-
rithm proposed. Followed by the experimental evaluation, details of the simulation’s
conﬁguration, and metrics, the results are presented in Sect.5. Further discussion is
made in Sect.6 highlighting the limitations of the model. Finally, Sect.7 gives the
conclusions and discusses the prospects for future work.
2
The Architecture of the Framework
Figure1showsthesketchoftheconsideredscenario.Itreferstonetworkedcomputing
Fog architecture to three-tier for the distributed wireless and wired IoT devices. It is
speciﬁcally composed of:
• Several wireless heterogeneous devices, like sensors, laptops, PCs, tablets, access
points, mobile, etc., are spatially distributed. We call them things that could operate
at the edge of the network and shape the IoT Layer as the bottom tier in Fig.1.
• A set of spatially distributed and interconnected FNs are located in each country.
Each FN’s role is to attend near to the devices by providing on-demand computing
andnetworkingresources.EachFNactsasasmall-sizedatacentre.Hence,itcovers
small computing and processing space on its physical servers interconnected by
Ethernet-type switches. The FNs process locally the delay-sensitive demands,
whiletheFNsmayforwardmoredelay-tolerantrequeststoremote(morepowerful)
Cloud nodes. FNs’ set makes up the Fog Layer as the middle tier in Fig.1.
• The third tier includes a set of remote Clouds, including Cloud Data Center (CDC).
Remote clouds are nodes in the cloud, which form the Cloud Layer in the archi-
tecture; they serve the delay-tolerant computing requests achieving from a set of
FNs, they act as a portal to users and providers of remote services.

A Deep Learning Approach to Analyze the Propagation …
101
Fig. 1 Architecture of the proposed framework. MC:=Monitored Country; SMC:=Server Manager
Country; PMI:=Patient Monitored Isolation
In this architecture, an IoT device can ofﬂoad the most computationally intensive
tasks in the considered scenario to the servicing FN. Hence, each IoT device in Fig.1
can support:
• Things such as sensors that are located as infotainment devices on a patient or
connected to the mobile/PC/laptop device of a patient can continuously measure
the patient’s vital signs including heart rate, body temperature, blood pressure,
pulse rate, fail detection and respiration rate–vital signs help in detecting or mon-
itoring COVID-19. The readings taken by public and private hospitals, homes
(patient monitored for isolation or patient monitored isolation (PMI)), clinics,
etc., are initially captured and processed at the edge by personal agents hosted
on the accompanying things (laptops, pcs and smartphones) to detect possible
abnormalities;
• WeimplementThing-to-FogandFog-to-Thing(T2F/F2T)communicationthrough
end-to-end UDP-TCP/IP transport-layer in the Fog layer two-way connections.
They rely on emerging wireless technology single-hop short-range Bluetooth, Zig-
Bee, or WiFi-based wireless transmission links. It is showed in Fig.1 (the green
rays) [14].
• We assign each Fog Node (FN) in the Monitored Country (MC) to collect and mon-
itor the data within its FN area. The FN is in charge of sending the aggregated data
periodically to the corresponding higher-level agent Server Manager Country
(SMC) having the responsibility of combining the received data to detect possi-
ble threats within its country of coverage. Communication between fog is via a
mid-range wireless backbone that operates broadband transmission technologies,
such as IEEE 802.11a/g/n, LTE or WiMax. It helps maintain reliable connections
(TCP/IP) from fog to fog of high performance (see Fig.1 of the blue-ray). For this
purpose, multi-antenna technologies would be used [15]. FNs and SMCs can gen-

102
P. G. Vinueza-Naranjo et al.
erally be implemented on any distributed computing platform. Besides, FC allows
the extension of the framework to support the proactive system in real-time to warn
the population of possible threats, pandemics, or infectious diseases, make quick
decisions, and guide the people to safe places. According to our interpretations,
each country could contain multiple infected areas, so it is essential to group the
FNs with updated information on the epidemic or infection in the same country.
• Cloud-to-Fog is interconnected by a backbone wide area network (WAN), and
the communication is implemented through TCP/IP connections. Moreover, it
may contain multi-hop which relies on 3G/4G long-range cellular transmission
technologies [16]. It will depend on the considered application scenario. The
CDC oversees FNs’ distribution within the country and redistributes them again
when necessary to create concentrated information regions. The CDC has global
knowledge about the whole monitored environment to operate. The latency issues
between SMCs and CDC are marginal to the work of the CDC. The cloud platform
handles growing or diminishing resources and provides powerful resources that
support the overall framework’s scalability.
3
Proposed SIR Model
In this part, we explain the susceptible, infectious or recovered (SIR) model that we
have taken as a reference. The SIR model is one of the epidemiological models; it
calculates the theoretical number of people infected with a contagious disease within
a closed population over time. This model categorizes individuals in the population as
belonging to several different compartments, representing their health status about
infection. The SIR model uses a time series that is updated daily, and the input
data are the proportions of the infected and eliminated cases (recovered and dead).
Therefore, in our study, America’s input data have been collected from January 21,
2020, to June 8, 2020. The dynamics of an epidemic are analyzed as the transfer rates
between compartments. Being one of the most fundamental compartmental models,
the SIR model forms a large part of infectious diseases modelling [17]. The more
people are infected, the more people also recover or die. Within the model of the
evolution of the epidemic outbreak, people are divided into different classes that
come to be the basic compartments that are Susceptible—Infected—Recovered or
SIR (in which S, I and R represent the three compartments). The individuals who
make up the population can be in any of the mentioned three compartments. Infected
cases are currently conﬁrmed cases; eliminated cases are recovered and deceased
cases. Therefore, we have
• Susceptible: Individuals are not infected but are likely to become infected. If they
were to become infected, these individuals would become part of the infected
cases.
• Infected: Individuals are infected (disease), and they could transmit it to suscep-
tible individuals. After a whilst, they will move on to the removed cases.

A Deep Learning Approach to Analyze the Propagation …
103
• Removed: The individuals may or may not have been infected with the disease,
and they may also recover from the infection and may have a natural immunity to
re-infection or have died.
We use t as the time duration to represent the independent variable of this model.
According to [17, 18], the exchange rates of the compartments can be expressed as
dS
dt = −E × F
P
× S,
(1)
dF
dt = E × F
P
× S −θ × F,
(2)
dR
dt = θ × F,
(3)
where P is the total number of the population. Cases are collected daily to apply
the SIR model. S(t) is the number of susceptible people in the t-th day. F(t) is the
number of infected people in t-th day. R(t) is the number of people recovered on
t-th day. E represents the expected number of people an infected person infects per
t-th day. D is the number of days that an infected person has the disease and can
spread it. θ is the proportion of infected people who recover per t-th day (θ = 1/D)
and R0 is the total number of people infected by an infected person (R0 = E/θ).
In this model, we consider the equations as “directions” that indicate the popu-
lation’s conﬁguration for the next day. For example, if we assume that k people are
infected, we can only recover θ percent, so the number of people who will recover
the next day can be calculated as θ × k. This behaviour will inﬂuence the remaining
equations and make the problem sophisticated. We draw the transitions from one
compartment to another in Fig.2. R0, basic breeding number, indicates the trans-
missibility of a virus within a particular population. In a susceptible population, this
represents the average number of new infections generated by an infected person.
In the time-dependent R0, we implement a simple change as follows. We apply a
strict lockdown on the L day, which pushes R0 to 0.9. In the equations, we do not
use R0 but E, as we know from the above that R0 = E/θ. Therefore, E = R0 × θ.
Formally, we deﬁne the function def R0(t) : where return 5.0 i f t < L else 0.9.
Also, we deﬁne another function for β that calls this function: def E(t) : where
return R0(t) × E.
As a result, the overall disease spreading will be enormously raised after a few. The
value of R0 probably never “jumps” from one value to another value. Conversely,
it can continuously change or ﬂuctuates. It happens if social distancing measures
Fig. 2 SIR model

104
P. G. Vinueza-Naranjo et al.
Fig. 3 DNN-based prediction learning (COVID-19)—Prediction process
are loosened and then tightened again. We should emphasize that we can choose
any function for R0; however, I only can present one common choice to model the
initial impact of social distancing based on a logistic function. Therefore, the logistic
function can be achieved as
R0(t) = R0start −R0end
1 + e−k(−x+x0) + R0end,
(4)
where R0start and R0end are the values of R0 on the ﬁrst and the last day. While x0 is
the x−value of the inﬂection point (i.e. the date of the steepest decline in R0 which
could be considered as the main “lockdown” date). Moreover, the decline rate of R0
depends on the value of the variable k.
4
Proposed Algorithm
A simple ﬁrst analysis to get an idea of outbreaks’ dynamics is creating iterative
time lag maps. In this section, we present our idea, which investigates the relation-
ship between a population of PD and SD at the time-day (D + AD) and some
characteristics of the selected countries (it is for each country of America). Hence,
the simplest case is to build maps daily (t = 1). In which we create two groups of
maps as follows. First, PD, associated with the country area (A) and the population of
cumulative conﬁrmed infected people (C), recover people (RC) and deaths reported
cases (DC) for each country of America. We observe that F = C −(RC + DC),
being the total number of infected people such that we considered neither recoveries
nor deaths. Second, SD, associated with multiple hospitals (H), number of airports
(A), migration rate (MR) and the elderly population (EP) of the cumulative cases
of conﬁrmed infected persons (C), cases of recovered persons (RC) and reported
cases deaths (DC) for each of the countries that make up America. We summarize
the proposed method in the Algorithm 1.
In Algorithm 1, N is the number of countries, D is a sequence of days from the
ﬁrst case in America, C refers to the number of cases for each day in D, DC stands
for the number of deaths for each day in D, RC indicates the number of recovered
cases for each day in D), A speciﬁes the area of each N, P is population of each
N), EP is elderly population of each N, REP is the rate of the elderly population of
each N), H is the number of the hospital of each N), AS is the number of airports of

A Deep Learning Approach to Analyze the Propagation …
105
Algorithm 1 Prediction of COVID-19 in America
Input: N, D, C, DC, RC, A, P, EP, REP, H, AS, MR
Output: PDA
1: NDB
2: for t = 1 to D do
3:
for t = 1 to N do PD ←{D; C; DC; RC; NC; A}
4: SD ←{P; H; AS; MR; EP; REP}
5:
end for
6: end for
7: NDB ←PD, SD
Creation of new database with primary and secondary parameters
8: Matlab ←NDB
9: for t=1 to D do
10:
Prediction Process
11: end for
12: return NDB
each N, and MR is the migration rate of each N. Moreover, the above algorithm’s
output is the predicted database Covid-19 in America; PDA. This algorithm tries to
predict the database based on the various days and their variation per day.
5
Performance Evaluation
This section details the gathered real dataset, followed by the explanation of the
compared metrics, simulation testbed, tested scenarios and results.
Dataset (Data Source) Data was collected from the European Center for Dis-
ease Control and Prevention (ECDC) [3] (Github repository), Center for Systems
Science and Engineering (CSSE), Johns Hopkins University (JHU). Dong et al. [6]
and WHO [5]. In this study, the data analyzed corresponds from January 21, 2020,
to June 8, 2020.
Simulation Metrics COVID-19 is expanding exponentially. According to previ-
ous evaluations of the COVID-19 virus pandemic (originating from SARS-CoV-1),
it has been shown that the data corresponding to the new cases tend to a large number
of outliers (whether or not they continue a standard distribution) over time, such as
Gaussian or Exponential [19, 20]. Recent studies from the Singapore University of
Technology and Design (SUTD) (Data-Driven Innovation Laboratory), used the SIR
model for the regression curves [17] and implemented the Gaussian distribution to
estimate the number of cases concerning the time. DL models are designed for a pre-
diction of new cases and an end date for this pandemic. So we propose a framework
to implement these models in fog data centres, as shown in Fig.1, to provide fail-safe
computing and rapid data analysis. In a fog-based environment, hospitals (govern-
ment health facilities) and clinics (private health centres) send data continuously of
positive patients to the Ministry of Health of each country in America. Population
density, median and median age (number of > 55years (% of the population)), num-

106
P. G. Vinueza-Naranjo et al.
ber of airports, net migration rate and health facilities (number of hospitals) will also
be integrated so that the predictions are more accurate. We conduct our simulations
on a virtual machine (VM) corporate three Azure B1s single-core with 1 GB RAM,
extra SSD storage, and equipped with 64-bit Microsoft Windows Server 2016 OS.
Simulation Scenarios In this paper, we test our DL method over the real dataset.
We gathered the data from June 21, 2020—the ﬁrst day that start pandemic in
America—tillJune8,2020.Untilthistime,thenumberofconﬁrmedcasesis3407874,
deaths cases are 186220, and recovered cases are 160200. Also, we predict the data
up to September 13, 2020.
5.1
Results
Our study is based on the SIR model and R0 method. Furthermore, we included the
sensitivity analysis to ﬁnd the essential features. We examined our model predictions
root-mean-square error (RMSE) on the validation data to evaluate the method. We
summarize the tested scenarios below:
Validity of the SIR model In this scenario, Table2 illustrates the results achieved
of applying the SIR model in the dataset and lists the error of ﬁtting the (numerical)
solution of Eqs. (1), (2), (3), giving an RMSE accuracy of 98.8–99.5%.
Table 2 The comparison results in the epidemic phase’s growth rate between active, death and
recovered cases
Details
Active cases
Death cases
Recovered cases
Estimated epidemic
size (cases)
6493840
267478
3571340
Estimated epidemic
rate (1/day)
0.0424
0.0518
5.180270e-02
Estimated initial state
(cases)
156042
9634
55087
Estimated initial
doubling time (day)
16.3
13.4
13.4
Estimated duration of
fast growth phase
(day)
94
77
77
Estimated end of
transition phase
01-Sep-2020
24-Jul-2020
01-Sep-2020
Epidemic phase
4/5
4/5
3/5
Fast growth
Slow growth
Fast growth
Deceleration phase
Transition phase
Deceleration phase
RMSE
1.19e+05
7.23e+03
8.75e+04
Adjusted R-Squared
0.995
0.992
0.988

A Deep Learning Approach to Analyze the Propagation …
107
(a) Number of active cases
(b) Rate of active cases
Fig. 4 The results of scenario one for a is the number of an active case, and b is the rate of active
cases of prediction on validation data
Scenario 1: In this scenario, the aim is to predicate the active COVID-19 cases.
Figure4, presents the predicated results comparing with the actual values, using the
network optimized for America. It is noted that the loss curve is iterative lowering
during training. We trained and tested our network on America dataset. The RMSE
error is 1.19e+05, with an accuracy of 99.5% for long term predictions in America.
Our algorithm’s predictions are shown in Fig.4a with a solid red line. It shows that
our algorithm was able to capture the dynamics of the transmission with minimum
loss. In Figs.4a, we can say that America witnessed growth since March 12, 2020,
after almost two months of the ﬁrst conﬁrmed case in America. The current phase
of the epidemic in America is expected to continue until September 01, 2020 (see
Table2).
Scenario 2: In this scenario, the aim is to predicate the death of COVID-19 cases.
Figure5, present the predicated results comparing with the actual values, using the
network optimized for America. It is noted that the loss curve is iterative lowering
during training. We trained and tested our network on America dataset. The RMSE
error is 7.23e+03, with an accuracy of 99.2% for long term predictions in America.
Our algorithm’s predictions are shown in Fig.5a with a solid red line. It shows that
our algorithm was able to capture the dynamics of the transmission with minimum
loss.
In Fig.5a, we can say that America witnessed growth since March 05, 2020, after
one week of the ﬁrst conﬁrmed death case in America. The current phase of the
epidemic in America is expected to continue until July 24, 2020 (see Table2).
Scenario3: Inthis scenario, theaimis topredicatetherecoveredCOVID-19cases.
Figure6, present the predicated results comparing with the actual values, using the
network optimized for America. It is noted that the loss curve is iterative lowering
during training. We trained and tested our network on America dataset. The RMSE
erroris8.75e+04withanaccuracyof98.8%forlongtermpredictionsinAmerica.The
predictions of our algorithm are shown in Fig.6a with a solid red line. It shows that
our algorithm was able to capture the dynamics of the transmission with minimum
loss. In Fig.6a, we can say that America witnessed growth since February 09, 2020,
after one month of the ﬁrst conﬁrmed recovered case in America. The current phase
of the epidemic in America is expected to continue until September 01, 2020 (see
Table2).

108
P. G. Vinueza-Naranjo et al.
(a) Number of death cases
(b) Rate of death cases
Fig. 5 The results of scenario 2 for a is the number of death case, and b is the rate of death cases
of prediction on validation data
(a) Number of recovered cases
(b) Rate of recovered cases
Fig. 6 The results of scenario 3 for a is the number of recovered case, and b is the rate of recovered
cases of prediction on validation data
(a) # of active cases
(b) Rate of death cases
(c) # of recovered cases
Fig. 7 The results of scenario 4 for a is the number of active cases; b is the number of death
cases and c is the number of recovered cases of prediction on validation data of the 5 most affected
countries in America
Scenario 4: In this scenario, the aim is to give more details on the prediction per
country in America, and we selected the top 5 highest predicated cases comparing
to the actual rates, which are reported in Fig.7. The RMSE error of active cases is
1.01e+05 with an accuracy of 99.58%, for death cases is 4.41e+03 with an accuracy
of 99.7% and for recovered cases is 3.02e+03 with the accuracy of 99.9%, for long
term predictions in the 5 most infected countries of America.
Scenario 5: In this scenario, the aim is to give details about the error rates (%)
of our proposed method. In Table3, the dataset is sorted from the last date (08-June-
2020) of our scenarios (Figs.4, 5 and 6) Focusing on this table, it shows the latest
data collected from the different ofﬁcial sources (WHO, ECDC, and CSSE). We have
compared our algorithm 16days later to verify that our algorithm works, giving an
error percentage of between (0.9 to 2.5)%, getting an accuracy of minimum 97.5%
to 99.1%.

A Deep Learning Approach to Analyze the Propagation …
109
Table 3 Error rates (%) of our proposed method to prediction compared with WHO, ECDC and
CSSE datasets
Date
WHO
ECDC
CSSE
Prediction
Error rate (%)
8/06/2020
c: 3309781
c: 3367726
c: 3420760
c: 3410198
c: 1.5
d: 181743
d: 184078
d: 186161
d: 182320
d: 1.1
10/06/2020
c: 3413477
c: 3487699
c: 3564333
c: 3471248
c: 1.6
d: 185801
d: 189270
d: 192900
d: 188327
d: 1.4
12/06/2020
c: 3558739
c: 3638857
c: 3712321
c: 3660317
c: 1.6
d: 192882
d: 196039
d: 198959
d: 195036
d: 1.2
14/06/2020
c: 3709658
c: 3788003
c: 3847618
c: 3789311
c: 1.2
d: 199190
d: 201844
d: 203723
d: 202352
d: 0.9
16/06/2020
c: 3839334
c: 3907122
c: 3986999
c: 3971245
c: 1.8
d: 200485
d: 205555
d: 208954
d: 210029
d: 2.5
18/06/2020
c: 4012874
c: 4048808
c: 4170662
c: 4190141
c: 2.8
d: 208926
d: 210780
d: 215793
d: 215135
d: 1.8
20/06/2020
c: 4158906
c: 4224280
c: 4372986
c: 4292197
c: 2.2
d: 215844
d: 217650
d: 221787
d: 221074
d: 1.4
22/06/2020
c: 4367230
c: 4381198
c: 4516638
c: 4421113
c: 1.4
d: 221816
d: 223456
d: 226768
d: 227099
d: 1.4
24/06/2020
c: 4503410
c: 4544332
c: 4712916
c: 4581312
c: 1.8
d: 226436
d: 228799
d. 233727
d: 233014
d: 1.7
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
13/09/2020
–
–
–
c: 6493840
–
d: 267478
The dataset is sorted by date (from the last day the prediction was made to 16days later to verify
that our algorithm works. c cases, d deaths)
6
Discussion
This section summarizes the beneﬁts and limitations of the proposed approach and
some future integrations. This work has several beneﬁts. First, since the predicated
model is located on the fog node connected to the PMI and patient sensors, it can
help the medical team how and where to plan their monitoring and operate the
related therapeutic actions. It also allows the PMI team to better understand the
spread of infection in the region and efﬁciently apply medical expertise and other
important measures to limit its spread in highly affected regions in America. Second,
the generated DL model could help the data analyst to remodel the same behaviour
in another area using similar features.

110
P. G. Vinueza-Naranjo et al.
Following are the limitations that the authors would like to highlight. First, the
work does not consider the anomaly behaviour in the gathered data, making the model
generation inaccurate. Second, since the paper proposes a localized DL model when
the volume of the affected people and their symptoms will be changed, the model
cannot update itself based on newly added features. Indeed, it takes some time to
retrain and retest the new features. To cope with this issue, we can design some solu-
tions. First, we can exploit 5G technology to enhance the generated architecture’s
coverage reported in Fig.1. 5G can help our model to form better, gather data and
increase the DL model’s learning phase’s converging speed. Second, we could inte-
grate our model by the new intelligent transportation system to help the DL model
be federated on various FNs scattered in the region and speed up the learning and
testing with the new mitigated record (affected case) in America.
7
Conclusion and Future Research
The article highlights the accelerated growth and spread of COVID-19 in some of the
most affected countries in America and how the mathematical model (e.g. SRI and
DL) in Fog and Cloud computing could helps improve COVID-19 prediction. We
show that our algorithm is capable of making predictions with a minimum percentage
of error. The Gaussian reference model indicates a holistic optimistic picture of the
COVID-19 scenario.
Combining 5G technology with the Internet of Everything (IoE) and FC plat-
form will create a room to propose Fog of Everything’s future platform. Since the
FC paradigm is propagated, by design, networks, and computing resources through-
out the wireless access network, it would support delay-sensitive, computational-
intensive data transmission applications. To add processing solutions for real-time
data, and in this way, create robust frameworks in conjunction with the use of moving
edge computing techniques.
References
1. Kevadiya, B. D., Machhi, J., Herskovitz, J., Oleynikov, M. D., Blomberg, W. R., Bajwa, N.,
Soni, D., Das, S., Hasan, M., Patel, M., et al. (2021). Diagnostics for SARS-COV-2 infections.
Nature Materials, pp. 1–13.
2. Schurink, B., Roos, E., Radonic, T., Barbe, E., Bouman, C. S. C., de Boer, H. H., de Bree, G. J.,
Bulle, E. B., Aronica, E. M., Florquin, S., et al. (2020). Viral presence and immunopathology
in patients with lethal covid-19: A prospective autopsy cohort study. The Lancet Microbe, 1(7),
e290–e299.
3. ECDC. European Centre for Disease Prevention and Control. Coronavirus disease 2019
(COVID-19) situation reports. Accessed April 25, 2020.
4. Koh, H. K., Geller, A. C., & VanderWeele, T. J. (2021). Deaths from covid-19. JAMA, 325(2),
133–134.

A Deep Learning Approach to Analyze the Propagation …
111
5. WHO. World Health Organization. (2020). Coronavirus disease 2019 (COVID-19) situation
reports. Accessed April 25.
6. Dong, E., Hongru, D., & Gardner, L. (2020). An interactive web-based dashboard to track
covid-19 in real time. The Lancet Infectious Diseases.
7. Chen, J. I. Z., & Smys, S. (2020). Social multimedia security and suspicious activity detection
in SDN using hybrid deep learning technique. Journal of Information Technology, 2(02), 108–
115.
8. Smys, S., Basar, A., & Wang, H. (2020). Artiﬁcial neural network based power management
for smart street lighting systems. Journal of Artiﬁcial Intelligence, 2(01), 42–52.
9. Kırba¸s, ˙I, Sözen, A., Tuncer, A. D., & Kazancıo˘glu, F. (2020). Comparative analysis and
forecasting of covid-19 cases in various European countries with ARIMA, NARNN and LSTM
approaches. Chaos, Solitons & Fractals, 138, 110015.
10. Papastefanopoulos, V., Linardatos, P., & Kotsiantis, S. (2020). Covid-19: A comparison of time
series methods to forecast percentage of active cases per population. Applied Sciences, 10(11),
3880.
11. Hawas, M. (2020). Generated time-series prediction data of covid-19 s daily infections in Brazil
by using recurrent neural networks. Data in Brief, 32, 106175.
12. Car, Z., Baressi Šegota, S., An -deli´c, N., Lorencin, I., & Mrzljak, V. (2020). Modeling the
spread of covid-19 infection using a multilayer perceptron. Computational and Mathematical
Methods in Medicine, 2020.
13. Ogundokun, R. O., Lukman, A. F., Kibria, G. B. M., Awotunde, J. B., & Aladeitan, B. B. (2020).
Predictive modelling of covid-19 conﬁrmed cases in Nigeria. Infectious Disease Modelling, 5,
543–548.
14. Vinueza, P. G., Naranjo, Z. P., Shojafar, M., Conti, M., & Buyya, R. (2019). FOCAN: A fog-
supported smart city network architecture for management of applications in the internet of
everything environments. Journal of Parallel and Distributed Computing, 132, 274–283.
15. Baccarelli, E., & Biagi, M. (2004). Power-allocation policy and optimized design of multiple-
antenna systems with imperfect channel estimation. IEEE Transactions on Vehicular Technol-
ogy, 53(1), 136–145.
16. Shojafar, M., Cordeschi, N., Amendola, D., & Baccarelli, E. (2015). Energy-saving adaptive
computingandtrafﬁcengineeringforreal-time-servicedatacenters.In2015IEEEInternational
Conference on Communication Workshop (ICCW) (pp. 1800–1806). IEEE.
17. Kermack, W. O., & McKendrick, A. G. (1927). A contribution to the mathematical theory
of epidemics. Proceedings of the Royal Society of London. Series A, Containing Papers of a
Mathematical and Physical Character, 115(772), 700–721.
18. Harko, T., Lobo, F. S. N., & Mak, M. K. (2014). Exact analytical solutions of the susceptible-
infected-recovered (SIR) epidemic model and of the SIR model with equal death and birth
rates. Applied Mathematics and Computation, 236, 184–194.
19. Bai, Y., & Jin, Z. (2005). Prediction of SARS epidemic by BP neural networks with online
prediction strategy. Chaos, Solitons & Fractals, 26(2), 559–569.
20. Wang, W., & Ruan, S. (2004). Simulating the SARS outbreak in Beijing with limited data.
Journal of Theoretical Biology, 227(3), 369–379.

Graph Convolution-Based Joint
Learning of Rumor with Content, User
Credibility, Propagation Context, and
Cognitive as Well as Emotion Signals
Prajna Nagaraj
and Bhaskarjyoti Das
Abstract To limit its harmful effect of rumor on social media, an ability to detect
rumor is important as refuting a false rumor with true news can then follow. Rumor
detection task necessitates joint learning as factors such as credibility of the user,
propagation and dispersion context on the social graph, and rumor content are equally
signiﬁcant. A bidirectional graph convolution-based approach is a feasible imple-
mentation of joint learning strategy. Moreover, rumor mongers use emotions and
cognitive words actively. Though emotion has been used in disinformation research,
cognitive aspects have been mostly neglected. This work improves the joint learning
approach for rumor detection by using cognitive and emotion features.
Keywords Rumor detection · Graph convolution · Bidirectional graph
convolution · BERT · Node classiﬁcation · Cognition · Emotion · User
credibility · Propagation context · Twitter
1
Introduction
With social media becoming increasingly popular, it is possible that information
posted by any user on the network grasps the attention of almost a billion users,
within a few seconds. Since there are no ofﬁcial restrictions on the content of what
is being posted on these social media platforms, there tends to be a lot of unveriﬁed
information online, also known as rumors. Fake news and rumor are close cousins. A
rumor is breaking news that is not yet veriﬁed and has no malicious intention behind
it. Fake news, on the other hand, is news that is intentionally false with a malicious
design behind it.
The rumor detection problem is deﬁned as follows: A rumor ri is deﬁned as a set
of n pieces of related messages M = m1, m2, . . . , mn where m1 is the source post
that initiated the chain. Hence, ri is very similar to a tree structure with a root and
Supported by PES University.
P. Nagaraj (B) · B. Das
PES University, 100 Feet Ring Road, Banashankari Stage III, Bengaluru, Karnataka 560085, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_9
113

114
P. Nagaraj and B. Das
multiple branches. For each message mi, it has content, such as text and image. Each
message mi is associated with a user who posted it having a set of attributes. Given
a rumor ri with its message set M and user set U, the rumor detection task aims to
determine whether this message is true or false. Sometimes we can have an additional
label, i.e., unveriﬁed. Detecting this message as rumor or not is rumor detection task
and whether the rumor is true or false is rumor veracity classiﬁcation task. A rumor
dataset R will typically consist many such rumor conversations ri.
Marten et al. [31] investigated the correlation between emotion and believing
fake news. The study conﬁrmed that people who engage in more reasons and are less
emotional will be less likely to believe fake news. Russo [44] worked on sadness
and fear as two primary emotion features of fake news spreaders. A socio-pragmatic
analysis study [21] conﬁrms the same fact, i.e., fake news somehow comes across as
a good story that touches the emotional chords of the recipients and readers tend to
accept them as true because it makes them feel good. A study [39] of emotional appeal
of fake news suggests that the fake news titles are substantially more negative and text
body has more negative emotions such as disgust and anger. It is also observed that
credible users are conservative, and they usually do not indulge in rumor mongering.
In this work, the problem of rumor detection is addressed in a joint learning
approach where a bidirectional graph convolution network along with text content,
user credibility features, and emotions are utilized.
2
Existing Work
2.1
Rumor Detection and Veracity Classiﬁcation
Rumor detection and rumor veracity classiﬁcation have witnessed active research
ever since social media became the medium to spread rumor. The existing approaches
can be classiﬁed into several categories of which the most recent being graph deep
learning-based approach (this work also adopts the same):
1. Content-based approach: This approach assumes that rumors have a different
textual styles compared to non-rumor. Early research used feature engineering
with traditional machine learning models and later on deep learning models were
employed. Text features were either based on attributes (sentiment, subjectivity,
uncertainty expressed by question marks, tentative terms in text, diversity of con-
tent such as number of unique words.) or derived from syntax (POS tag showing
tense, lexicon derived features, negation words, etc.). Also, a deep contextual
model [47] of the content is required as the source tweet along with the reply
tweets capture more information. Some researchers concatenated statistical and
content features of image and video with the textual features for multimodal rumor
detection. Both the original poster of the rumor and those who refute question or
support the same have some stance toward the rumor topic. Many researchers who
have adopted the content-based route have framed rumor detection as multitask

Graph Convolution-Based Joint Learning of Rumor …
115
learning [20, 22, 29] with stance detection being the auxiliary task or sometimes
as a hierarchical or hybrid learning [17, 18] problem.
2. User-based approach: User credibility [7, 27] is usually determined by certain
proxy features that can be obtained from social media platforms, i.e., registration
age, number of followers, posts, number of likes, veriﬁed or not, listed in public
directory or not, etc.
3. Social graph-based approach and other approaches: There were few attempts
using alternative means, i.e., using social graph characteristics [26], anomaly-
based approach [36] as a rumor tree is kind of anomalous compared to other
conversationtrees,usingoptimizationalgorithmslikeparticleswarmoptimization
[23] in classiﬁers on rumor content, rumor detection using reinforcement learning
[54], etc. However, none of these approaches have become mainstream.
4. Propagation-based approach that helps in joint learning: A rumor tree can be
visualized as a subgraph of the social graph. A very successful rumor ﬂows far
and wide. Hence, propagation (depth) and dispersion (width) are two important
characteristics of such rumor trees. Researchers tried various attempts to capture
this characteristics, i.e., conditional random ﬁeld [55] or LSTM-based model that
assumes a time-based sequential context, treeLSTM [24, 30] model that tries to
capture the propagation tree and very recently graph neural network [50] models
that this work also adopts. An algorithm such as graph convolution network [10,
19] additionally can provide node embedding that can capture the tweet–tweet
graph in addition to the node attributes capturing the attributes of the tweet and
the user tweeting the tweet. From that perspective, this approach is a convenient
implementation of the joint learning approach when none of the content, user, or
propagation network alone may be sufﬁcient for a rumor detection task. Hence, the
work described here adopts this model and enhances this with cognitive–emotive
footprints to further enhance the performance.
2.2
Emotion Research and Application of Emotion in Fake
News and Rumor Research
Emotion can be an important component in textual semantics and has remained a
popular research area for at least a decade. However, it has its own set of challenges.
The main challenges are the lack of sufﬁcient labeled datasets, different types of
annotations in existing datasets, overlapping nature of different types of emotion,
and incomplete emotion information in any single modality like text, audio, or video.
The existing datasets used in various researches also reﬂect the issue of different
emotion labels and resulting diverse annotation methods. The two popular emotion
categorization methodologies are Ekman’s basic emotion [12] and Plutchik’s [41]
emotion wheel. While Ekman deﬁnes six basic emotions, Plutchik identiﬁed eight
basic emotions (grouped into four pairs of opposing emotions) while introducing the
ideaof other subtypes bycombinationof thesebasicemotions withdifferent intensity.

116
P. Nagaraj and B. Das
Apart from different types of discrete emotion labels followed by different datasets
[3, 45, 49], some datasets [35, 42, 43] are annotated with emotion intensity. So,
emotion recognition from this perspective is not only a classiﬁcation problem but is
also a regression problem. The other dominant approach can be called a knowledge-
based approach that relies on building a lexicon [9, 33, 46] for each emotion type or
subtypes. There are corpus [4, 34] which adopt both lexicon and intensity annotation.
Due to the fuzzy nature of boundaries between different emotion types, the other
approach is to model emotion as a set of continuous values in multiple dimensions
such as pleasure, arousal, violence, and dominance. Hence, there are emotion corpus
that adopts this dimensional vector-based approach. There are recent datasets [6, 32]
that adopt dimensional approach with lexicon or discrete emotion labels. Recently
with advent of neural learning, emotion embedding has been proved effective. The
Emo2vec [52], emoji2vec [11], and deepmoji [14] are most mention worthy in this
category.
In fake news detection task, Zhang et al. [53] elaborately mined both publisher
and commenters’ sentiments to come up with an emotion vector that consists of three
parts, i.e., publisher emotion, commenters’ emotion, and emotion gap that consists of
mean gap and maximum gap. Guo et al. [16] analyzed the datasets and noticed anger,
sadness, and doubt more in published fake news and the word analysis (exaggerated
and inﬂammatory words) revealed the same. They expected users’ social emotion
to fake news to have more negative emotions in their reactions. Hence, both pub-
lisher and social emotion will be largely negative. Finally emotion at word level and
sentence level along with text embedding is combined to come up with the emotion
enhanced text embedding at both publisher and reader. These two types of vectors
are then used together in the ﬁnal fake news classiﬁcation.
Kwon et al. [25] analyzed rumor datasets to identify prominent features, i.e., peri-
odic spikes as temporal characteristics, network parameters of the diffusion networks,
and emotion features such as LIWC [40]. Chen et al. [8] used feature concatenation
of sentiment embedding with character embedding of Cantonese tweets. Endang
Pamungkas et al. [38] in SemEval task for rumor stance classiﬁcation used emotion
lexicons as features. Ajao et al. [2] used lexicon-based ratio of positive and negative
emotion words as a feature in the embedding of rumor tweets.
2.3
Cognitive Signals in Disinformation Research
Some researchers [15, 51] have used topic distribution along with content embedding
for little more discriminatory power of the model. But topics alone may not be enough
as real and fake news will be somewhat similar in these aspects especially for the
case when fake news essentially tells true news differently. An alternative approach
to topical signals can be the cognitive words as emotion and cognition are closely
related. However, disinformation research has not utilized cognitive signals as much.
Oh et al. [37] analyzed the tweets during 2008 Mumbai attack between anxiety and

Graph Convolution-Based Joint Learning of Rumor …
117
rumor by looking at the words that were used. Abulaish et al. [1] built on this approach
using a graph theoretic implementation starting with seed words.
Cognition is the ability to perceive, process, store, and retrieve information lead-
ing to decision making and responses containing certain emotions. Cognition may
lead to emotion and emotion may lead to cognition. So, the cognitive footprints that
lead to emotions, can possibly be used in emotion detection. An example of a cogni-
tive process can be “discrepancy,” and it can be captured by verbs such as “should,”
“could,” “would” and in cases, it may lead to an affective state such as negative
emotion expressed by word the “worthless.” A lexicon-based sentiment detection
strategy would focus on ﬁnding the word “hate” whereas a strategy based on cog-
nitive footprint of negative emotion may look for “should”, “would,” “could.” An
investigation by Wang et al. [48] shows that bigram as a feature does better than most
other features in emotion detection task. One can suspect that this works because of
the effective capturing of the cognitive aspects. Hence, an alternative strategy can
be to adopt a lexicon-based strategy that looks for both. The work described in this
paper also adopts this strategy.
The linguistic inquiry and word count (LIWC) that has been [40] extensively
used in sentiment analysis in text also captures some cognitive aspects apart from
emotion. For each of this category, LIWC has a list of English word or stem and
the tool manually searches for the occurrence of the same. Empath[13] is a similar
tool built using vector space model. This can analyze text over around 200 topics
including emotional categories like those covered by LIWC. In that sense, Empath is
broader than LIWC and it can capture topical as well as cognitive signals and certain
types of emotion. This work uses topical, emotive, and cognitive signals as captured
by Empath [13].
3
Dataset
In this work, two available rumor datasets [30], i.e., Twitter15 and Twitter16 as
shown in Table1 are used. Each dataset has tweets categorized into four labels:
Table 1 Dataset
Dataset
Type
Twitter15
Twitter16
Number of rumor
1084
599
Number of non-rumor
369
199
Total before oversampling
1453
798
Number of rumor
1084
599
Number of non-rumor
1084
599
Total after oversampling
2168
1198

118
P. Nagaraj and B. Das
“true,” “false,” “unveriﬁed,” “non-rumor." Few augmentations were made to this
dataset:
1. Derived 1453 tweets from Twitter15 and 798 tweets from Twitter16 that were
effectively mapped (from the original 1490 in Twitter15 and 808 in Twitter16 )
to user information.
2. Only two labels were considered for experimentation.
(a) “rumor” tweets that were composed of labels: “true”, “false”
(b) “non-rumor” tweets that were composed of labels: “non-rumor”
(c) The label “unveriﬁed” was discarded as they could be either “rumor” or
“non-rumor.” Predictability results degraded in the experimentation where
“unveriﬁed” tweets were included.
3. The “non-rumor” tweets were oversampled to balance the dataset.
4. Using Twitter API, Twitter user features collected were:
(a) favorites-count: The number of tweets the user has “liked” since the account
was created.
(b) followers-count: The number of accounts following the user.
(c) friends-count: The number of accounts the user follows.
(d) listed-count: The number of public lists the user is a member of.
(e) statuses-count:The number of tweets and retweets done by the user.
(f) veriﬁed (Boolean): Mentions if the user is veriﬁed (true) or not (false).
The above dataset was subjected to some preprocessing such as normalization
of text, lower casing, replacing Twitter handles (@userhandle) into word “user,”
replacing urls into the word “url,” removal of non-alphanumeric characters. The
hashtag, emoji, and emoticons were converted into appropriate text.
4
Analysis of Cognitive and Emotion Patterns in Rumor
and Non-rumor
An additional dataset PHEME [22] along with the Twitter15 and Twitter16 datasets
was investigated for difference in cognitive and emotional footprints in rumor versus
non-rumor. The PHEME dataset is unbalanced, i.e., many more non-rumor samples
compared to rumor samples. Hence, for the sake of analysis, sampling is done so
that overall dataset is balanced for analysis.
Empath comes with 200 prebuilt categories and out of those 194 unique were
used without normalization. Based on frequency, top 20 most prevalent categories in
Twitter15, Twitter16, and PHEME dataset were identiﬁed for both rumor and non-
rumor categories. Subsequently, the comparative analysis was carried out as shown
in Figs. 1, 2, 3, and 4.
The ﬁndings are as follows:

Graph Convolution-Based Joint Learning of Rumor …
119
Fig. 1 Empath analysis of Twitter15-16 rumor
1. In Twitter15 and Twitter16 rumor, we can see higher frequencies in categories
like “breaking,” “crime,” “death,” “dispute,” “injury,” “kill,” “prison,” “violence,”
“war,” “weapon” along with “negative emotion.” These words in themselves tend
to carry a negative connotation that may ignite negative emotions that are usually
used to rile and agitate people leading to spreading of such tweets.
2. In Twitter15 and Twitter16 non-rumor, we can see higher frequencies in categories
like “celebration,” “children,” “sports,” “government,” “leader,” “party,” “work”
along with “negative emotion.” These words are less instigative and may help us
lead to the conclusion that emotions and feelings linked with the aggressive and
more negative qualities that are usually associated with rumor tweets does impact
the spread of rumor versus non-rumor tweets.
3. In the PHEME dataset, both rumor and non-rumor data have comparatively high
frequencies for “crime,” “kill,” “negative emotion,” “war,” “weapon,” and “terror-

120
P. Nagaraj and B. Das
Fig. 2 Empath analysis of Twitter15-16 non-rumor
ism.” But what can be observed is that “positive emotion” category is picked up
in non-rumor dataset and has not been picked up in the rumor dataset. Again like
in Twitter non-rumor, PHEME non-rumor has comparatively higher frequency
for “air travel” and “traveling” compared to PHEME rumor data, i.e., categories
that are less instigative than in rumor dataset.
Essentially the analysis conﬁrms the expectation that rumor and non-rumor vary
in terms of emotion footprints and cognitive words that can lead to negative emotion.
Rumordatasethasinstigativewords,cognitiveverbs,andisnegativeemotionbearing.

Graph Convolution-Based Joint Learning of Rumor …
121
Fig. 3 Empath analysis of PHEME rumor
5
Methodology
Rumor propagates from the source to other users who react to it on social media
platformlikeTwitter.Thisformsapropagationstructureandtypicallyusesanexisting
relationship chain like follower relationship. Rumor spreads not only far but also
wide. A graph convolution network (GCN) algorithm with its aggregate and update
operations is well-suited to capture the propagation characteristics into the node
embedding when done in a source to children direction. When we go up from the
children nodes to the source node, it captures the dispersion that the rumor goes
through. The same GCN algorithm when used in the reverse direction will be able
to capture the dispersion property. A ﬁnal embedding, as shown in Fig. 5, combines
the embedding derived from both to capture both propagation and dispersion [5].

122
P. Nagaraj and B. Das
Fig. 4 Empath analysis of PHEME non-rumor
Fig. 5 Algorithm ﬂow

Graph Convolution-Based Joint Learning of Rumor …
123
Fig. 6 Sample rumor tree and preprocessing with various features
The work done here extends this approach. Also, just like conversational stance, a
reply to a rumor tweet is better understandable when it is examined along with the
source tweet. So, if a rumor tree ri is visualized as subgraph of a graph of R, the text
attribute of a node should be the vector representation of the concatenated text of the
source and the reply tweet.
In this work, overall a joint learning methodology is used, i.e., user credibility
features, content-based features, cognitive and emotion features along with the prop-
agation context are considered for rumor detection. This is illustrated in Fig. 6. The
words in bold are those that carry emotive and cognitive signals. Graph convolution
is used for implementing joint learning. Top-down graph convolution and bidirec-
tional graph convolution have been investigated with different types of feature sets.
The features derived from text content were using term frequency, inverse document
frequency (TF-IDF) and transformer-based RoBERTa model [28] that generate an
embedding vector for each tweet. In this, last four hidden embedding layers were
concatenated and their mean was used for each source tweet and response tweet. For
RoBERTa, base model (1 layer = 768 features and last 4 layers = 3072 features) and
large model (1 layer = 1024 features and last 4 layers = 4096 features) have been
experimented with. Same model conﬁguration is used for all baselines (2 labels,
twofold cross-validation, 64 hidden features, 50 epochs with early stopping, drop
rate: 0.2, optimizer: Adam, and learning rate: 0.0005).

124
P. Nagaraj and B. Das
6
Results and Analysis
Table2 lists the results obtained with various feature sets as deﬁned in Table3 where
TD is top-down graph convolution and BI is bidirectional graph convolution. The
train-test split details are listed in Table4. From the results, the followings can be
concluded :
1. Adding Empath-based cognitive features showed jump in performance in three
out of four cases.
2. Transformer-based content features perform better than count-based TF-IDF
features. In general, transformer-based features with Empath-based cognitive–
emotive features and user credibility features took the top slots.
3. The combination strategy of content feature, cognitive features, and user credi-
bility features works better even on a small dataset like Twitter15 and Twitter16.
4. Across the two datasets and four baselines, bidirectional GCN did not always
beat the top-down GCN. We can conclude that the result depends on the extent
of dispersion a particular conversation tree possesses.
Table 2 Results
Results
Baseline
Model
Dataset
Accuracy
F1 R
F1 NR
1
TD GCN
Twitter15
0.9512
0.9211
0.9667
1
TD GCN
Twitter16
0.9437
0.8889
0.9697
1
BI GCN
Twitter15
0.9160
0.8603
0.9254
1
BI GCN
Twitter16
0.8750
0.7836
0.8940
2
TD GCN
Twitter15
0.9590
0.9453
0.9755
2
TD GCN
Twitter16
0.9062
0.8541
0.9303
2
BI GCN
Twitter15
0.9824
0.9730
0.9828
2
BI GCN
Twitter16
0.8750
0.7895
0.9102
3
TD GCN
Twitter15
0.9680
0.9665
0.9693
3
TD GCN
Twitter16
0.9412
0.9397
0.9426
3
BI GCN
Twitter15
0.9661
0.9660
0.9658
3
BI GCN
Twitter16
0.9706
0.9700
0.9711
4
TD GCN
Twitter15
0.9517
0.9505
0.9524
4
TD GCN
Twitter16
0.9790
0.9785
0.9794
4
BI GCN
Twitter15
0.9624
0.9611
0.9632
4
BI GCN
Twitter16
0.9622
0.9618
0.9627
5
TD GCN
Twitter15
0.9728
0.9727
0.9729
5
TD GCN
Twitter16
0.9747
0.9740
0.9754
5
BI GCN
Twitter15
0.9693
0.9684
0.9696
5
BI GCN
Twitter16
0.9538
0.9524
0.9551

Graph Convolution-Based Joint Learning of Rumor …
125
Table 3 Feature sets for different baselines
Feature sets
Baseline
Details
Baseline 1
5000 TF-IDF features
Baseline 2
5000 TF-IDF features + Empath features(194)
Baseline 3
5000 TF-IDF features + Empath features(194)
+ User features (6)
Baseline 4
RoBERTa embedding BASE (768), four layers
(3072) + Empath (194) + User features (6)
Baseline 5
RoBERTa embedding LARGE (1024), four
layers (4096) + Empath (194) + User features
(6)
Table 4 Train-test split details
Train test split 9:1
Dataset
Train
Test
Total
Twitter15
1952
216
2168
Twitter16
1080
118
1198
7
Conclusion and Future Work
Disinformation such as rumor comes as a tree that captures the propagation context.
While there is a time sequence in it, capturing the semantics of this tree purely by
sequence-based deep learning approach is somewhat limited in capturing the width
and depth of it. While utility of graph convolution as a mechanism of capturing prop-
agation and dispersion aspect has been investigated in very recent researches, this
work additionally investigates the effect of combining user credibility information
and cognitive-emotional footprints into the feature mix. This work also successfully
validates the hypothesis that having cognitive–emotive features contribute to higher
performance. Additionally this work also shows that the transformer-based text fea-
tures are more effective than the count-based TF-IDF features for disinformation
detection task due to the lack of large sample size.
As a next step, we plan to investigate further usage of cognitive words vis-a-vis
emotion signifying words by the disinformation spreaders and the efﬁcacy of cog-
nitive features in other areas of disinformation research. In this work so far, only
emotive and cognitive knowledge are used and the approach is based on lexicons.
We plan to incorporate a joint approach of emotion embedding along with the cur-
rently employed knowledge-based approach. We also plan to extend this work by
investigating with a much larger dataset.

126
P. Nagaraj and B. Das
References
1. Abulaish, M., Kumari, N., Fazil, M., & Singh, B. (2019). A graph-theoretic embedding-based
approach for rumor detection in twitter. In IEEE/WIC/ACM International Conference on Web
Intelligence (pp. 466–470).
2. Ajao, O., Bhowmik, D., & Zargari, S. (2019). Sentiment aware fake news detection on online
social networks. In ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech
and Signal Processing (ICASSP) (pp. 2507–2511). IEEE.
3. Alm, C. O., Roth, D., & Sproat, R. (2005). Emotions from text: Machine learning for text-
based emotion prediction. In Proceedings of Human Language Technology Conference and
Conference on Empirical Methods in Natural Language Processing (pp. 579–586).
4. Araque, O., Gatti, L., Staiano, J., & Guerini, M. (2019). Depechemood++: A bilingual emo-
tion lexicon built through simple yet powerful techniques. IEEE Transactions on Affective
Computing.
5. Bian, T., Xiao, X., Xu, T., Zhao, P., Huang, W., Rong, Y., & Huang, J. (2020). Rumor detection
on social media with bi-directional graph convolutional networks. Proceedings of the AAAI
Conference on Artiﬁcial Intelligence, 34, 549–556.
6. Busso, C., Bulut, M., Lee, C. C., Kazemzadeh, A., Mower, E., Kim, S., et al. (2008). IEMOCAP:
Interactive emotional dyadic motion capture database. Language Resources and Evaluation,
42(4), 335–359.
7. Castillo, C., Mendoza, M., & Poblete, B. (2011). Information credibility on twitter. In Pro-
ceedings of the 20th International Conference on World Wide Web (pp. 675–684).
8. Chen, X., Ke, L., Lu, Z., Su, H., & Wang, H. (2020). A novel hybrid model for Cantonese
rumor detection on twitter. Applied Sciences, 10(20), 7093.
9. De Albornoz, J. C., Plaza, L., & Gervás, P. (2012). Sentisense: An easily scalable concept-based
affective lexicon for sentiment analysis. In LREC (vol. 12, pp. 3562–3567). Citeseer.
10. Dong, M., Zheng, B., Quoc Viet Hung, N., Su, H., & Li, G. (2019). Multiple rumor source
detection with graph convolutional networks. In Proceedings of the 28th ACM International
Conference on Information and Knowledge Management (pp. 569–578).
11. Eisner, B., Rocktäschel, T., Augenstein, I., Bošnjak, M., & Riedel, S. (2016). Emoji2vec:
Learning emoji representations from their description. arXiv preprint arXiv:1609.08359
12. Ekman, P. (1992). An argument for basic emotions. Cognition & Emotion, 6(3–4), 169–200.
13. Fast, E., Chen, B., & Bernstein, M. S. (2016). Empath: Understanding topic signals in large-
scale text. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems
(pp. 4647–4657).
14. Felbo, B., Mislove, A., Søgaard, A., Rahwan, I., & Lehmann, S. (2017). Using millions of
emoji occurrences to learn any-domain representations for detecting sentiment, emotion and
sarcasm. arXiv preprint arXiv:1708.00524
15. Gautam, A., Masud, S., et al. (2021). Fake news detection system using XLNet model with
topic distributions: Constraint@ aaai2021 shared task. arXiv preprint arXiv:2101.11425
16. Guo, C., Cao, J., Zhang, X., Shu, K., & Yu, M. (2019). Exploiting emotions for fake news
detection on social media. arXiv preprint arXiv:1903.01728
17. Hamidian, S., & Diab, M. (2019). GWU NLP at semeval-2019 task 7: Hybrid pipeline for
rumour veracity and stance classiﬁcation on social media. In Proceedings of the 13th Interna-
tional Workshop on Semantic Evaluation (pp. 1115–1119).
18. Hamidian, S., & Diab, M. T. (2019). Rumor detection and classiﬁcation for twitter data. arXiv
preprint arXiv:1912.08926
19. Huang, Q., Zhou, C., Wu, J., Wang, M., & Wang, B. (2019). Deep structure learning for rumor
detection on twitter. In 2019 International Joint Conference on Neural Networks (IJCNN)
(pp. 1–8). IEEE.
20. Islam, M. R., Muthiah, S., & Ramakrishnan, N. (2019). RumorSleuth: Joint detection of rumor
veracity and user stance. In 2019 IEEE/ACM International Conference on Advances in Social
Networks Analysis and Mining (ASONAM) (pp. 131–136). IEEE.

Graph Convolution-Based Joint Learning of Rumor …
127
21. Juez, L. A., & Mackenzie, J. L. (2019). Emotion, lies, and “bullshit” in journalistic discourse:
The case of fake news. Ibérica: Revista de la Asociación Europea de Lenguas para Fines
Especíﬁcos (AELFE), 38, 17–50.
22. Kochkina, E., Liakata, M., & Zubiaga, A. (2018). All-in-one: Multi-task learning for rumour
veriﬁcation. arXiv preprint arXiv:1806.03713
23. Kumar, A., Sangwan, S. R., & Nayyar, A. (2019). Rumour veracity detection on twitter using
particle swarm optimized shallow classiﬁers. Multimedia Tools and Applications, 78(17),
24083–24101.
24. Kumar, S., & Carley, K. M. (2019). Tree LSTMS with convolution units to predict stance and
rumor veracity in social media conversations. In Proceedings of the 57th Annual Meeting of
the Association for Computational Linguistics (pp. 5047–5058).
25. Kwon, S., Cha, M., Jung, K., Chen, W., & Wang, Y. (2013). Prominent features of rumor
propagation in online social media. In 2013 IEEE 13th International Conference on Data
Mining (pp. 1103–1108). IEEE.
26. Lathiya, S., Dhobi, J., Zubiaga, A., Liakata, M., & Procter, R. (2020). Birds of a feather check
together: Leveraging homophily for sequential rumour detection. Online Social Networks and
Media, 19, 100097.
27. Li, Q., Zhang, Q., & Si, L. (2019). Rumor detection by exploiting user credibility information,
attention and multi-task learning. In Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics (pp. 1173–1179).
28. Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., &
Stoyanov, V. (2019). Roberta: A robustly optimized Bert pretraining approach. arXiv preprint
arXiv:1907.11692
29. Ma, J., Gao, W., & Wong, K. F. (2018). Detect rumor and stance jointly by neural multi-task
learning. Companion Proceedings of the the Web Conference, 2018, 585–593.
30. Ma, J., Gao, W., & Wong, K. F. (2018). Rumor detection on twitter with tree-structured recursive
neural networks. Association for Computational Linguistics.
31. Martel, C., Pennycook, G., & Rand, D. G. (2020). Reliance on emotion promotes belief in fake
news. Cognitive Research: Principles and Implications, 5(1), 1–20.
32. Mohammad, S. (2018). Obtaining reliable human ratings of valence, arousal, and dominance
for 20,000 english words. In Proceedings of the 56th Annual Meeting of the Association for
Computational Linguistics (Vol. 1: Long Papers, pp. 174–184)
33. Mohammad, S., & Turney, P. (2010). Emotions evoked by common words and phrases: Using
mechanicalturktocreateanemotionlexicon.InProceedingsoftheNAACLHLT2010Workshop
on Computational Approaches to Analysis and Generation of Emotion in Text (pp. 26–34).
34. Mohammad, S. M. (2017). Word affect intensities. arXiv preprint arXiv:1704.08798
35. Mohammad, S. M., & Bravo-Marquez, F. (2017). WASSA-2017 shared task on emotion inten-
sity. arXiv preprint arXiv:1708.03700
36. Nguyen, T. T. (2019). Graph-based rumour detection for social media. Technical Report
37. Oh, O., Agrawal, M., Rao, H. R., & Dalziel, G. (2010). Anxiety and rumor: Exploratory analysis
of twitter posts during the Mumbai terrorist attack. The Political and Social Impact of Rumor,
S. Rajaratnam School of International Studies, Nanyang Technological University, Singapore.
38. Pamungkas, E. W., Basile, V., & Patti, V. (2019). Stance classiﬁcation for rumour anal-
ysis in twitter: Exploiting affective information and conversation structure. arXiv preprint
arXiv:1901.01911
39. Paschen, J. (2019). Investigating the emotional appeal of fake news using artiﬁcial intelligence
and human contributions. Journal of Product & Brand Management.
40. Pennebaker, J. W., Mehl, M. R., & Niederhoffer, K. G. (2003). Psychological aspects of natural
language use: Our words, our selves. Annual Review of Psychology, 54(1), 547–577.
41. Plutchik, R. (2001). The nature of emotions: Human emotions have deep evolutionary roots,
a fact that may explain their complexity and provide tools for clinical practice. American
Scientist, 89(4), 344–350.
42. Quan, C., & Ren, F. (2010). A blog emotion corpus for emotional expression analysis in
Chinese. Computer Speech & Language, 24(4), 726–749.

128
P. Nagaraj and B. Das
43. Quan, C., & Ren, F. (2010). Sentence emotion analysis and recognition based on emotion words
using ren-cecps. International Journal of Advanced Intelligence, 2(1), 105–117.
44. Russo, I. (2020). Sadness and fear: Classiﬁcation of fake news spreaders’ content on twitter.
In CLEF.
45. Strapparava, C., & Mihalcea, R. (2007). Semeval-2007 task 14: Affective text. In Proceedings
of the Fourth International Workshop on Semantic Evaluations (SemEval-2007) (pp. 70–74).
46. Strapparava, C., Valitutti, A., et al. (2004). Wordnet affect: An affective extension of wordnet.
In LREC (Vol. 4, p. 40). Citeseer.
47. Veyseh, A. P. B., Thai, M. T., Nguyen, T. H., & Dou, D. (2019). Rumor detection in social
networks via deep contextual modeling. In Proceedings of the 2019 IEEE/ACM International
Conference on Advances in Social Networks Analysis and Mining (pp. 113–120).
48. Wang, S. I., & Manning, C. D. (2012). Baselines and bigrams: Simple, good sentiment and topic
classiﬁcation. In Proceedings of the 50th Annual Meeting of the Association for Computational
Linguistics (Vol. 2: Short Papers, pp. 90–94).
49. Wang, Z., Li, S., Wu, F., Sun, Q., & Zhou, G. (2018). Overview of NLPCC 2018 shared task
1: Emotion detection in code-switching text. In CCF International Conference on Natural
Language Processing and Chinese Computing (pp. 429–433). Springer.
50. Wu, Z., Pi, D., Chen, J., Xie, M., & Cao, J. (2020). Rumor detection based on propagation graph
neural network with attention mechanism. Expert Systems with Applications, 158, 113595.
51. Xu, K., Wang, F., Wang, H., & Yang, B. (2019). Detecting fake news over online social media
via domain reputations and content understanding. Tsinghua Science and Technology, 25(1),
20–27.
52. Xu, P., Madotto, A., Wu, C. S., Park, J. H., & Fung, P. (2018). Emo2vec: Learning generalized
emotion representation by multi-task training. arXiv preprint arXiv:1809.04505
53. Zhang, X., Cao, J., Li, X., Sheng, Q., Zhong, L., & Shu, K. (2019). Mining dual emotion for
fake news detection. arXiv e-prints pp. arXiv–1903
54. Zhou, K., Shu, C., Li, B., & Lau, J. H. (2019). Early rumour detection. In Proceedings of
the 2019 Conference of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies (Vol. 1, Long and Short Papers, pp. 1614–1623).
55. Zubiaga, A., Liakata, M., & Procter, R. (2017). Exploiting context for rumour detection in
social media. In International Conference on Social Informatics (pp. 109–123). Springer.

Deep Learning-Based Real-Time Object
Classiﬁcation and Recognition Using
Supervised Learning Approach
J. Harikrishna, Ch. Rupa, and R. Gireesh
Abstract Due to the rapid technological advancements in recent years, humans
have gained the ability to design and implement the knowledge into machines and it
also allows them to perform various functions such as autonomous thinking ability,
understanding skills, and problem-solving. Moreover, machine learning [ML] plays
an important role in developing the image-processing models and application. In real-
time applications, the labels of objects may be unfamiliar to those who are unaware
of them, or there may be several identical objects but are labeled differently. In this
paper, the approach that would be useful to detect and classify various objects is
presented with a trial study by utilizing various datasets. This method can be used
to improve accuracy in ﬁnding the classiﬁcation of similar objects. In the process
of classifying real-time objects, this system uses a supervised learning technique,
where various datasets are trained and compared with the queried object. Here, the
Support Vector Machine (SVM) algorithm is utilized for performing analysis and
decision making in object classiﬁcation domain. The result of this project is to read
the given objects with the help of computer vision and allowing the machine to
perform the prediction or classiﬁcation for the given object. More than 800 images
obtained from standard datasets of trained labeled classes are implemented in our
application to classify the objects.
Keywords Machine learning · Real-time object detection · Classifying objects ·
Labeled data · Supervised learning · Support vector machine (SVM) · Computer
vision
J. Harikrishna (B) · R. Gireesh
Department of Computer Science, Vijayawada, Andhra Pradesh, India
Ch. Rupa (B)
Department of Computer Science and Engineering, VR Siddhartha Engineering College,
Vijayawada, Andhra Pradesh, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_10
129

130
J. Harikrishna et al.
1
Introduction
In today’s modern world, computer vision is implemented in various applications to
meet the requirements such as identifying and categorizing the objects, predicting
similar objects that are available in the market, identifying the script present in the
image and their translation to plain text or into an audio, obtaining more information
with the help of image search and so on. Image processing helps in analysis of
various objects and helps to obtain detailed information. In current world, there are
many ﬁelds such as healthcare, remote sensing, color processing, pattern recognition,
and robot vision, where there is a need for image classiﬁcation. Aerial surveillance
with the help of drones and helicopters are the latest trends, where they are using
image classiﬁcation technologies to identify a targeted object from a large amount of
objects in a single survey. Classiﬁcation of objects based on contour and appearance
is a challenging task to obtain high accurate results [1, 2]. The primary objective is to
train different dataset models based on supervised learning and as a result working
on this issue will improve the result accuracy.
Currently, deep learning, machine learning and data mining are the benchmark
mechanisms that are utilized to process the data for analytics. Generally, supervised
learning technologies were classiﬁed into two types such as regression and classiﬁca-
tion. Regression has been utilized to ﬁt the data according to the proposed application.
The main aim of the regression is to model the relationship among the features and
target component. Classiﬁcation has been utilized to separate the data. For example,
text and image classiﬁcation problems are considered as the examples of classiﬁ-
cation. The main objective of these problems is the prediction of class label for an
assigned piece of text. Sentiment analysis is an example of a real-time application of
text classiﬁcation, wherein it predicts the sentiment of a text like a product review or
tweet. The well-known applications of supervised learning are bioinformatics, cyber
crime analytics [3], satellite data analysis [4], etc.
The main objective of the proposed application is to provide a classiﬁcation of
an object in order to serve the users in its own way with the help of supervised
learning, where a set of trained data labels are provided and a queried object can be
classiﬁed based on the available data. This approach for developing an application
will overcome the drawback, where there is a need of Internet to classify the image.
Since the image sets are deﬁned in our application database, there is no need for
Internet connectivity to perform actions and also it can be operated in any remote
areas.
An application-based service is required for a simple classiﬁcation process. This
application architecture will provide readily vision system that makes application
modules to share and exchange information [5]. In our project, a very simple method-
ology has been developed in framing the architecture of image classiﬁcation with
the help of Support Vector Machine (SVM) [6]. Object detection is an approach
to ﬁnd the class of the queried image. Classiﬁcation plays a vital role in machine-
based learning [7–9]. The proposed application has used supervised learning, which
is considered as an efﬁcient way in solving the real-time challenges. In supervised

Deep Learning-Based Real-Time Object Classiﬁcation …
131
classiﬁcation, the human professional decides the output classiﬁcation of the objects
with the help of model objects with known classes. These known objects are known
as training sets. This works as a main strength to provide a platform, where the object
classiﬁcation has been performed instantly in any remote area without any need of
Internet connectivity.
The subsequent part of the paper is systematized in the following way. Section 2
discusses the related research works, Sect. 3 describes about the proposed approach
and Sect. 4 deals with performance analysis and results.
2
Literature Survey
Browatzki et al. [1] have described it with the help of new sensor technology, where
the image processing has become available for a variety of new applications. This
system can be applicable on both two—dimensional and three—dimensional infor-
mation. The fundamental drawback of this technique is that only a small number of
data models are trained. Wang et al. [2] have described about the real-world applica-
tions of human centered computing based on multiple cameras. This study proposes
an architecture for training data models and processing object categorization based
on the available information. Udendhran et al. [4] states that the computer vision has
increased its capability. This is achieved with the help of high performance proces-
sors and integrated deep learning algorithm. With the help of latest smart devices,
which are handy such as cameras, smartphones, tablets, this project may not require
the high processor capabilities but it performs desired actions.
Longsheng et al. [5] designed a methodology to detect each fruit even if they
are clustered in a straight line. In our project, the comparison of two class objects is
done based on the linear SVM and as a result this research work identiﬁes the nearest
points of the class that belong to the same input image.
Tzotsos et al. [7] described Support Vector Machine as a superior method espe-
cially for supervised classiﬁcation and was a found to be a best machine learning
algorithm. The main drawback was this algorithm was developed in C++ language
where current devices such as smartphones, tablets and other cameras do not support
to extract this ﬁle extension. The main objective if this research work is to train
the classiﬁer and perform actions to validate the queried object without using the
Internet. There are no sensors required to scan the object in three-dimensional space,
and a simple two-dimensional image of an object can be used to obtain an accurate
classiﬁcation result. Reyad et al. [10] have described computer vision and Internet of
Things (IoT); a very effective GPU is implemented to make the analysis faster. This
approach can be utilized in the devices, where high complex actions are required to
be performed such as devices to be constructed for surgeries. This can lead to higher
costs to construct the devices. The developed application doesn’t need any high GPU
performance as it only deals with object prediction.

132
J. Harikrishna et al.
Table 1 Summary of related work
Scheme
Features
Mining performance
Robustness
Imperceptibility
Quality
[12]
Low
Partial
Moderate
High
[13]
Moderate
High
High
Low
[14]
Moderate
High
High
Low
[15]
High
Low
Low
Low
[16]
High
Moderate
Moderate
High
[17]
High
Low
Moderate
High
Proposed
High
High
Moderate
High
Cervantes et al. [11] mentioned in his work that enormous research works have
been made on SVM in the recent years. These SVM algorithms are the dominant
and tough classiﬁcation that serves numerous grounds of application. The SVM
algorithm helps in the classiﬁcation and regression of huge datasets. The SVM trends
are different from one application to other based on the user requirements (Table 1).
3
Proposed System
In order to identify and classify the given object, this method should undergo different
procedures, which collects different data models and organizing them to their respec-
tive labeled class, training the models, generating the trained ﬁles, integration of the
trained dataset to our application and classify the object by using Support Vector
Machine [SVM] algorithm [18–20] as shown in Fig. 1
SVM is used for both regression and classiﬁcation. It is often preferred for the
utilization in classiﬁcation issues due to the algorithm that works on the limits of
making linear decisions to categorize multiple classes. In the SVM methodology,
inherently it has binary classiﬁcation function. A binary classiﬁer of SVM is trained
for a pair of classes [21]. To combine the outcomes or results, It has been decided to
employavotingfeature.Theproposedsystemclassiﬁestheobjectsbyconsideringthe
real-time images. These mechanisms are preferable to process the security analytics,
which is considered as one of major applications [22]. The step-by-step process of
the proposed approach is shown as follows.
Proposed approach stages: object classiﬁcation
1
Since our application is based on supervised
learning, it gathers a variety of object images
to train. A sample of random object images is
shown in Fig. 2
(continued)

Deep Learning-Based Real-Time Object Classiﬁcation …
133
(continued)
Proposed approach stages: object classiﬁcation
2
In this stage 2, all the images of a particular
labeled class are required to be assigned into
a single model class. A sample of random
object class ﬁle is shown in Fig. 3
3
In this stage, different class models are
trained for classiﬁcation with the help of
python language
4
Now, the trained model ﬁles (e.g., class
labels.txt ﬁle, Image database ﬁle) are
generated
5
In this stage 5, the desired application
development platform such as android studio
or python is selected to integrate the trained
model ﬁle to your application
6
At this phase, the object images and their
respective class labels are predeﬁned in the
proposed application and are stored in the
application memory
7
When the object image query is given as
input, the application starts mapping the
input ﬁle with our predeﬁned trained class
sets. To compare the queried image with the
available data sets we use Support Vector
Machine algorithm which is explained below
8
At this phase, all the class points are checked
with our input and the decision is made by
the device to predict the given object
9
At this ﬁnal step the classiﬁcation of the
object is displayed as an output
Support Vector Machine (SVM):
The aim of this algorithm is to create a best decision boundary line between the
available classes and helps in classiﬁcation of the object with a high accuracy rate.
The functionality of SVM is more effective when there are clear margins among
the classes as separation. It works more effectively when the number of dimensions
is more than the number of available samples. Relatively SVM has more memory
efﬁcient mechanism [4, 6, 23–25]. The functioning of SVM is as shown here.
a.
Divide the available data into certain classes based on the object category.
b.
Read the object image as input and compare it with available image database
classes.
c.
The object classes are to be divided based on the linear straight line; this straight
line is called as hyperplane or decision boundary.

134
J. Harikrishna et al.
Output
Collecting random 
data models
Assigning data into a 
single model classes
Training data model 
set (using python)
Generate 
trained 
model files
Image
Database
Integrating trained model files 
with our application by using 
android studio or python
Class Labels
Query Image
Classification by using SVM
Fig. 1 Proposed system architecture
d.
Now calculate the closest points of classes that are near to the hyperplane. These
closest lines to hyperplane are called as support vectors
e.
Calculate the maximum points that are available to hyperplane and assign the
class label to the object classiﬁcation.

Deep Learning-Based Real-Time Object Classiﬁcation …
135
Fig. 2 Set of random real-time object images a Pen object b USB drive
Fig. 3 Sample data collection of a labeled class “pen”
In the SVM graph shown above, class 1 points are denoted with circle shape and
class 2 points are denoted with triangle shape. The points of class 2 lies more on the
support vector S2 than the points of class 1 on support vector S1. So in this case,
the label of class 2 will be classiﬁed. This application will directly lead the user to
browse the images of any format and can apply the action based on the user interest.
Figure 2 shows the sample of random object images, which are considered in the
proposed system.
Where Fig. 2a depicts the set of real-time object positions (Pen) that have been
examined for performing classiﬁcation by using the SVM methodology. Figure 2b
depicts various positions of the real-time object (USB drive). Figure 3 shows the
information about sample data collection on which the proposed mechanism has
been applied. A SVM classiﬁcation approach is used for performing classiﬁcation
and assigning a class label by identifying them appropriately.

136
J. Harikrishna et al.
Fig. 4 Classiﬁcation of real-time objects
4
Results and Analysis
Figure 4 shows the result of the proposed object classiﬁcation method. This method
is experimented on more than 300 objects obtained from various datasets such as
Kaggle, live data records and Google site images. The proposed application provides
an accurate result in the process of predicting the object as shown in Fig. 4 by
considering the water bottle image. The proposed application has been implemented
by using Python, Google API software on 62-bit processor with 8 GB RAM system.
Performance analysis of the proposed method is described in the next section. The
results indicate the ability of the proposed method to detect the selected objects
effectively. The detection rate is more than 97%, by considering the object area.
4.1
Performance Analysis [15–19]
The performance of the proposed system is evaluated by considering the following
characteristics.

Deep Learning-Based Real-Time Object Classiﬁcation …
137
1.
Accuracy: It calculates the total percentage of accuracy of the ﬁndings. The
higher the percentage value, the better the performance of proposed application.
Accuracy is calculated by adding Total positives (TP) and Total negatives (TN)
divided by Total elements (T).
Accuracy = TP + TN/T
2.
Precision: This indicates the probability by pairing the truths in order to identify
the nearest object from the available datasets. It is the most important model to
evaluate the classiﬁcation. It provides the top most prioritized results.
Precision = TP/TP + FN
where FN is false negative.
3.
Speciﬁcity: This parameter is used to analyze the objects and identify the
targeted object in an image. It is measured with the below formula
S = TN/FP + TN
Below are the tables and graphs that represent SVM analysis and also the classes
are compared. Table 2 deals with the analysis of results by using SVM and also
the probability of comparing the classes respectively.
Figures 5 and 6 illustrate graphical representations of several metrics such as
accuracy, precision, speciﬁcity of SVM, and probability comparison of labeled
classes.
Table 2 Probability of
comparing classes for
classifying water bottle
Labeled class
Probability
Water Jug
0.03
Water bottle
0.89
Jar
0.08
Fig. 5 Graphical
representation of SVM
analysis
97
98.6
98
96
97
98
99
Accuracy
Precision
Specificity
SVM analysis

138
J. Harikrishna et al.
Fig. 6 Graphical
representation of comparing
classes
0
0.2
0.4
0.6
0.8
1
Water Jug
Water 
boƩle
Jar
Probability analysis of 
comparing classes
5
Conclusion and Future Work
The proposed application has collected different image sets and assigned them to
their respective class labels. Later, the proposed research work has trained the datasets
and integrated with the proposed application. By using the Support Vector Machine
algorithm, this research work gains the ability to compare the queried image with the
objects that are available in the application database and classify the given image. The
proposed object classiﬁcation application is quick and accurate in the performance.
The scanning can be one to one image and many to many images. The future work
of this paper can be done on GIFs by using Convolution neural networks [CNN] and
the efﬁciency for calculating the time can be improved simultaneously.
References
1. Browatzki, B., Fischer, J., & Graf, B. (2011). “Going into depth Evaluating 2D and 3D cues for
object classiﬁcation on a new, large-scale object dataset”. International conference on computer
vision workshop IEEE.
2. Wang, G., Tao, L., Di, H., Ye, X., & Shi, Y. (2012). A scalable distributed architecture for
intelligent vision system. IEEE Transactions, 8(1), 91–99.
3. Rupa, Ch., Thippa Reddy, G., Abidi, M. H., & Alahmari, A. (2020). “Computational system to
classify cyber crime offenses using machine learning”. Journal of Sustainability, 12(10), 1–15.
4. Udendhran, R., Suresh, A. (2020). “Enhancing image processing architecture using deep
learning for embedded vision systems”, (Vol. 76). Elsevier.
5. Rupa, Ch. (2019). Extended statistical analysis on multimedia concealed data detections.
Ingénierie des Systèmes d’Information, 24(2), 161–165.
6. .Fu, L., Tola, E., & Li, R. (2019). “A novel image processing algorithm to separate linearly
clustered kiwi fruits”. Science Direct, 183.
7. Argialas, T. (2008). “Support vector machine classiﬁcation for object—Based image analysis”.
Springer.
8. Rupa, Ch., & Sumanth, T. (2019). “Integrity checking of physical currency with pattern
matching: Coping with few data and the training sample order”. International Journal of
Institution of Engineers, 100(3). Springer IEI.
9. Polonio, D., Tavella, F., & Zanella, M. (2018). “An android application for automatic image
classiﬁcation”. LNICST, 233.

Deep Learning-Based Real-Time Object Classiﬁcation …
139
10. Reyad, O., & Amin, M. (2019). “An effective deep convolutional neural network for visual
image classiﬁcation”. (Vol. 921). Springer.
11. Cervantes, J., Garcia, F., Rodríguez-Mazahua, L., (2020). “A comprehensive survey on support
vector machine classiﬁcation: Application, challenges and trends”. Science Direct, 408.
12. Dubey, S. R., Pulabaigari, V., & Basha, S. H. (2020). “Impact of fully connected layers on
performance of convolutional neural networks for image classiﬁcation”. Science Direct, 378.
13. Tammy, J., Gradus, J. L. (2020). “Supervised machine learning: A brief primer”. Science Direct,
51.
14. Ch, R. (2016). A novel approach in security using gyration slab with watermarking technique.
Springer IEI, 97(3), 273–279.
15. Akbari, V., et al. (2017). “Iceberg detection in open water and sea ice using C-band radar
polarimetry”. IEEE conference geosciences and remote sensing symposium.
16. Widyantara, O., et al. (2016). “Image enhancement using morphological contrast enhance-
ment for video based image analysis”. IEEE international conference on data and software
engineering (ICoDSE), (pp. 1–6).
17. Rupa, Ch., Raveendra Babu, P., Rangarao, R. (2018, 14–16 June). “Object based open sea
icebergs identiﬁcation using transformation techniques”. IEEE international conference on
intelligent computing and control systems. Madhurai.
18. Mazur, A. K., et al. (2017). An object-based SAR image iceberg detection algorithm applied
to the Amundsen Sea. Journal of Remote sensing of Environment, Elsevier, 189, 67–83.
19. Rupa,Ch.,&Devi.(2019,19–21January).“PrivacyandprotectionofmedicalimagesROIusing
SPLSB and bit-plane based watermarking”. ACM international conference on cryptography,
security and privacy 2019. University of Malaya.
20. Tao, D., Doulgeris, A. P., & Brekke, C. (2016). A segmentation-based CFAR detection algo-
rithm using truncated statistics. IEEE Transactions on Geoscience and Remote Sensing, 54(5),
2887–3289.
21. Fan, W., Zhou, F., Tao, M., Bai, X., Shi, X., & Xu, H. (2017). “An automatic ship detection
method for PolSAR data based on K-Wishart distribution”. IEEE Journal Selected Topics
Applications Earth Observe. Remote Sensing, 10(6), 2725–2737.
22. Rupa, Ch. (2017). A secure information framework with APRQ properties. Springer IEI, 98(4),
359–364.
23. Hameed, M. A., Hassaballah, M., Aly, S., & Awadi, A. I. (2019, 17 December). “An adap-
tive image steganography method based on histogram of oriented gradient and PVD-LSB
techniques”. IEEE.
24. Duraipandian, M. (2020). Adaptive algorithms for signature wavelet recognition in the musical
sounds. Journal of Soft Computing Paradigm (JSCP), 2(02), 120–129.
25. Manoharan, S. (2020). Population based meta heuristics algorithm for performance improve-
ment of feed forward neural network. Journal of Soft Computing Paradigm (JSCP), 2(01),
36–46.

Single-Channel Speech Enhancement
in Modulation Domain Using Particle
Swarm Optimization
Kalpana Ghorpade and Arti Khaparde
Abstract Background noise affects speech quality and intelligibility degrading the
performance of speech-operated systems. Speech enhancement can improve the
quality of noisy speech. Modulation domain spectral subtraction for separate real
and imaginary spectra improves speech intelligibility without having musical noise
in enhanced speech. In this paper, we suggest using particle swarm optimization-
based noise estimation for single-channel speech enhancement. Particle swarm opti-
mization algorithm ﬁnds the most optimum value of noise present in input speech.
We investigate the suitability of this algorithm for noise estimation in the modula-
tion domain by comparing the perceptual estimate of speech quality (PESQ) of the
enhanced speech with the results of various other algorithms. The proposed algo-
rithm converges fast while giving an optimal solution. We get improvement in PESQ
and segmental SNR values. The musical noise is reduced in enhanced speech.
Keywords Speech enhancement · Spectral subtraction · Modulation domain real
imaginary spectral subtraction · Particle swarm optimization (PSO) · Noise
estimation
1
Introduction
Speech signals get contaminated by background noise making them less intelligible.
In speech-operated systems, degraded speech affects the performance of the system.
The noise generated by vehicles, co-speakers, fans, air ducts gets added to the speech
signal. In the real environment, complete noise cancellation is not possible as it is
difﬁcult to track varying noise types and characteristics that change with time [1].
But reducing additive noise is possible to make speech more intelligible and to
K. Ghorpade (B)
MKSSS’s Cummins College of Engineering for Women, Pune, Maharashtra, India
e-mail: kalpana.joshi@cumminscollege.in
A. Khaparde
Dr. Vishwanath Karad MIT World Peace University, Pune, Maharashtra, India
e-mail: arti.khaparde@mitwpu.edu.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_12
141

142
K. Ghorpade and A. Khaparde
enhance the efﬁciency of speech-dependent applications. This is done by speech
enhancement systems. Speech enhancement has gained a lot of research interest. For
single-channel speech enhancement systems, enhancing speech is quite challenging
as there is no reference for noise. A variety of speech enhancement algorithms are
available which improve the quality of speech [2, 3]. Spectral subtraction is the
simple speech enhancement method suggested by Boll [4, 5]. The main drawback
of this method is the annoying musical noise. To reduce it, Boll suggested to ﬂoor
the negative spectral component values of spectral subtraction result to the minimum
of the adjacent frames [2]. Berouti et al. suggested subtracting an overestimate of
the noise power spectrum to prevent the resultant spectral components from going
below a preset minimum value [2]. In spectral subtraction, the speech-noise cross
term is assumed to be zero which is not zero for low-SNR cases. Also, while recon-
structing the enhanced speech spectrum, the noisy speech phase is used along with
the enhanced magnitude spectrum. For low SNR signals, the phase angles of noisy
speech and clean speech differ [2]. To reduce musical noise, Zadeh ﬁrst suggested the
modulation frequency domain as the transform of time series of acoustic frequency
[6]. Later, it was proposed that the ﬁrst STFT of the time domain noisy speech as
the acoustic spectrum and the second STFT of the time series at a particular acoustic
frequency as the modulation spectrum at that frequency [7]. The strength of the modu-
lation domain as compared to the acoustic domain is evaluated for spectral subtrac-
tion in [8]. In [9], the effect of cross term, noisy phase angle is analysed on speech
enhancement. To reduce their effect, it is suggested to use the modulation domain real
imaginary spectral subtraction (MRISS). In [10–12], various techniques of speech
enhancement are implemented in the modulation domain which give better perfor-
mance results compared to time domain or frequency domain methods. Researchers
have used swarm-based algorithms for speech enhancement due to the simplicity and
optimality of these algorithms. In [13–15], variants of particle swarm optimization
(PSO) and the combination of PSO with other heuristic algorithms are implemented
for dual-channel speech enhancement. Single-channel speech enhancement is imple-
mented in [16] by using a combination of minimum mean square error and PSO
(MMSEPSO). In this paper, we propose noise estimation using particle swarm opti-
mization for single-channel speech enhancement in the modulation domain. With
the use of PSO, we ﬁnd the optimized estimate of noise present in speech. There is a
signiﬁcant reduction in musical noise with the increase in objective measure values.
The rest of the paper is organized as follows. Section 2 gives a brief description of
spectral subtraction, modulation domain spectral subtraction and modulation domain
real imaginary spectral subtraction. Section 3 provides an introduction of the stan-
dard particle swarm optimization (PSO) algorithm, Sect. 4 describes the proposed
method of noise estimation using PSO for modulation domain spectral subtraction,
in Sect. 5 experimental results are demonstrated, and Sect. 6 gives the conclusion.

Single-Channel Speech Enhancement in Modulation Domain …
143
2
Spectral Subtraction
Spectral subtraction is a widely used speech enhancement method. If y(n) is the
noise corrupted signal composed of the clean speech signal x(n) and the additive
noise signal d(n) such that
y(n) = x(n) + d(n)
(1)
The spectral subtraction is given as
 ˆX (ω)
 =|Y(ω)| −
 ˆD(ω)
 if|Y(ω)| >
 ˆD(ω)

= 0
else
(2)
where
 ˆD(ω)
 is the estimate of the magnitude noise spectrum made during non-
speech activity, |Y(ω)| is the noisy speech magnitude spectrum,
 ˆX (ω)
 is the magni-
tude spectrum of enhanced speech. Equation (2) describes the spectral subtraction
method which can be also extended in the power spectral domain as in Eq. (3).
 ˆX (ω)

2
= |Y(ω)|2 −
 ˆD(ω)

2
(3)
Due to non-linear processing of the negative values in spectral subtraction as
in equation (2), tones of frequencies that change randomly occur in the enhanced
speech. This is termed musical noise [2]. To reduce the effect of musical noise,
Berouti et al. suggested subtracting an overestimate of noise power spectrum from
the power spectrum of noisy speech [2].
|En(n, k)|2 = |Y(n, k)|2 −α
D′(n, k)
2
if |Y(n, k)|2 > (α + β)
D′(n, k)
2
= β
D′(n, k)
2
otherwise
⎫
⎪⎪⎬
⎪⎪⎭
(4)
where |En(n, k)|2 is the power spectrum of enhanced speech, |Y(n, k)|2 is the power
spectrum of noisy speech, and
D′(n, k)
2 is the power spectrum of estimated noise,
α (greater than or equal to 1) is the over subtraction factor, β (lying in between 0 and
1) is the spectral ﬂoor which controls the amount of residual noise [2].

144
K. Ghorpade and A. Khaparde
2.1
Modulation Domain Spectral Subtraction
To overcome the problem of musical noise, modulation domain spectral subtraction
is suggested in the literature. Modulation domain spectral subtraction is discussed in
[8]. The following ﬂowchart gives steps for modulation domain spectral subtraction.
input noisy speech y(n)
Framing and windowing
First FFT,Y(n, )
, Get magnitude spectrum 
in each frequency bin |Y( ,n)|
Second FFT,
get magnitude 
spectrum  
Do framing and windowing in each frequency bin
Follow equation(5) to carry out spectral subtraction
Here, the ﬁrst STFT (frequency index = η) converts time-domain speech short
frames to frequency domain called as acoustic frequency domain. Second FFT
(frequency index = m) is carried out to perform modulation domain spectral subtrac-
tion where k is a time index. Equation (5) gives the modulation domain spectral
subtraction. U can be equal to 1 or 2 depending on if we go for magnitude spectral
subtraction or power spectral subtraction.
|En(η, k, m)| =

|Z(η, k, m)|ϒ −α
D′(η, k, m)
ϒ 1
ϒ
if |Z(η, k, m)|ϒ −α
D′(η, k, m)
ϒ ≥β
D′(η, k, m)
ϒ
=

β
D′(η, k, m)
ϒ1/ϒ
otherwise
⎫
⎪⎪⎪⎪⎬
⎪⎪⎪⎪⎭
(5)
where D′(η, k, m) is the noise estimate in the modulation domain, α is the over
subtraction factor and β the spectral ﬂoor [2]. Here, cross term error effect is present
in the acoustic frequency domain and also in the modulation frequency domain.
Also, noisy speech phase spectrum is used along with enhanced magnitude spectrum
while converting speech frames from acoustic frequency domain to time domain.
Modulation domain real imaginary spectral subtraction (MRISS): to reduce the effect
of cross term and noisy phase angle, the modulation domain real imaginary spectral
subtraction (MRISS) method is suggested in [9]. In this method, ﬁrst STFT gives the
conversion of noisy speech frames from the time domain to the acoustic frequency
domain. The acoustic spectrum is separated into real and imaginary spectra. This

Single-Channel Speech Enhancement in Modulation Domain …
145
avoids cross term error effect in the acoustic frequency domain. To convert acoustic
frequency domain frames into the modulation frequency domain, samples in each
frequency bin of real and imaginary noisy speech spectra are framed separately and
windowed. Then, the second FFT is carried out. Equation (6) depicts the conversion
of the acoustic domain real spectrum at frequency k to the modulation frequency
domain. A similar process is done at each frequency for imaginary spectra also.
ZR(k, m, r) =
M −1
	
n=0
YR(n, k)v(m −g)e−j2πnr/M
(6)
Here, r is the modulation frequency index (r = 0 to M −1), k is the acoustic
frequency index, m is the time index, M is the window length, g is the window shift.
Noise estimated by any noise estimation algorithm is also converted into the modu-
lation domain. Equation (7) is followed for spectral subtraction in the modulation
frequency domain for the real modulation spectrum. |MR(k, m, r)| is the estimated
noise real magnitude spectrum in the modulation domain.
Z′
R(k, m, r)
 = |ZR(k, m, r)| −α(m)|MR(k, m, r)|
if |ZR(k, m, r)| > (α(m) + β)|MR(k, m, r)|
= β|MR(k, m, r)| otherwise
⎫
⎪⎬
⎪⎭
(7)
where α(m) = 2 −

 3
20

SNR(m).
α(m) controls the amount of noise subtraction, β is the spectral ﬂoor. Modi-
ﬁed magnitude
Z′
R(k, m, r)
 along with noisy phase gives enhanced modulation
spectra Z′
R(k, m, r). Similarly,
Z′
I(k, m, r)
 along with corresponding noisy phase
gives Z′
I(k, m, r). Here, for conversion into the modulation domain, the complex
acoustic frequency spectrum’s real and imaginary spectra are used instead of using
magnitudes. The cross-term effect will be present only in the modulation domain.
Also, while converting the acoustic frequency spectrum back to the time domain, it
is not required to use noisy speech phase angles.
3
Standard Particle Swarm Optimization
Evolutionary algorithms can give a satisfactory solution to practical multimodal
problems. The main advantages of the evolutionary algorithms are: (1) these opti-
mization algorithms are independent of system structure, and (2) they only use objec-
tive function information [17, 18]. Particle swarm optimization (PSO) was originally
introduced by Eberhart and Kennedy in 1995 [17]. In a swarm-based algorithm, local
interactions between particles (agents) provide a global result that permits the system
to solve the problem without using any central controller [19]. In population-based
heuristic algorithms, exploration and exploitation are the two important aspects.

146
K. Ghorpade and A. Khaparde
Exploration is the ability to broaden the search space, whereas exploitation is the
ability to locate the optima surrounding a promising answer. A heuristic search
algorithm traverses the search space to uncover novel solutions in ﬁrst iterations.
As iterations pass, exploitation becomes more prevalent, and the algorithm tunes
itself to semi-optimal locations [19]. In PSO, each individual candidate solution can
be depicted as a particle moving through the problem hyperspace in real number
space [17, 18]. Each individual’s information is based on their personal experience
(the decisions they have taken thus far and the success of each decision) as well as
knowledge of the performance of other individuals in their area. Vector CurrentPo-
sition gives the position of a particle and Velocity gives the velocity of the particle.
CurrentPosition(t) indicates particle position in tth iteration.
CurrentPosition(t) = CurrentPosition(t −1) + Velocity(t)
(8)
Velocity(t) = W*Velocity (t −1) + C1 ∗(R1 ∗(LocalBestPosition −CurrentPosition))
+ C2 ∗(R2 ∗(GlobalBestPosition −CurrentPosition))
(9)
where C1, C2 are the positive numbers and R1, R2 are random numbers with
uniform distribution in the range of [0,1]. The velocity update equation (9) has three
components (1) referred to as inertia, it models the tendency of the particle to continue
in the same direction it has been traveling (2) linear attraction towards the best
position ever found by the given particle: LocalBestPosition (whose corresponding
ﬁtness value is called the particle’s best: pbest) scaled by a random weight, (3) linear
attraction towards the best position found by any particle: GlobalBestPosition (whose
corresponding ﬁtness value is called global best: gbest), scaled by another random
weight. In each iteration, the ﬁtness function is evaluated for every particle. The steps
involved in the standard PSO algorithm are.
Initialise the swarm, get velocity = W* CurrentPosition
*Evaluate the ObjectiveFunction of each particle, update gbest, pbest, 
LocalBestPosition, GlobalBestPosition
Find velocity by (9), update particle position by (8) for the next iteration.
$ update ObjectiveFunction of the new individuals, update gbest, pbest
Repeat * to $ until the given threshold is reached, GlobalBest of swarm 
Initialise PSO parameters- N, Nvars, C1, C2, upper bound, lower bound

Single-Channel Speech Enhancement in Modulation Domain …
147
4
Proposed Noise Estimation Using PSO
Here, we propose PSO to estimate noise in speech for modulation domain spectral
subtraction. The particles of PSO are nothing but the (noise) magnitudes of a real
and imaginary acoustic frequency spectrum of noise. Every particle corresponds to
1024 coefﬁcients (noise magnitudes at acoustic frequencies) corresponding to the
position of the particles which are initialized by the PSO algorithm at the start. The
ﬁrst 512 values for every particle correspond to coefﬁcients of real acoustic frequency
spectrum N_R (n, k), and the next 512 values correspond to coefﬁcients of imaginary
acoustic frequency spectrum N_I (n, k). Thus at every acoustic frequency, there is
one coefﬁcient in real and one in the imaginary spectrum. Such 30 particles are
initialized in the algorithm. Thus, the swarm size of PSO is 30 × 1024. (30 particles
each having 1024 coefﬁcients, i.e. each particle’s position has 1024 coefﬁcients)
Table 1 gives the parameter setting of PSO for the proposed algorithm. For each
particle, at each frequency k of N_R (n, k) and N_I (n, k), 144-point FFT is taken to
get the modulation domain noise spectrum. M_R-I (k, m, r) gives modulation domain
noise spectrum where k is the acoustic frequency index, m is the time index and r
is the modulation domain frequency index. We used modulation domain spectral
subtraction as mentioned in [9]. Steps in section modulation domain real imaginary
spectral subtraction (MRISS) are followed to convert time domain noisy speech
signal to real and imaginary spectra in the modulation domain. The noisy speech
signal in the time domain is framed and windowed by the hamming window.
MR−I(k, m, r) =
M −1
	
n=0
(NR(n, k)NI(n, k))e−j2πnr/M
(10)
Table 2 gives frame and FFT size for converting the time domain speech to the
modulation domain.
As mentioned in [9], while getting spectra in the modulation domain, we consid-
ered real and imaginary spectra in the acoustic frequency domain separately. For
conversion into the modulation domain, components in each acoustic frequency
bin are again windowed by the hamming window. As frameshift in time domain
frames is 2.5 ms; therefore, the time gap between two samples of modulation domain
frame which are the samples in the consecutive acoustic domain frames at the single
Table 1 Parameters for PSO
Parameter
Value selected
Population size N
Nvars
Max no. of iterations
C1, C2
Inertia W
Upper bound
Lower bound
30
1024
100
2.05
0.9 at start, 0.4 at end
0.35
−5 × 10−5

148
K. Ghorpade and A. Khaparde
Table 2 Frame and FFT size for modulation domain
Frame size for time-domain speech
25 ms with 2.5 ms shift
FFT size for converting time-domain speech to acoustic
frequency domain
512 point
Frame size for conversion into modulation domain
120 ms with frameshift of 15 ms
Second FFT size
144 point
Number of acoustic domain frames per modulation frame
48
frequency is also 2.5 ms. So, the sampling frequency in the modulation domain is
the reciprocal of this interval, i.e. 400 Hz. Due to this, there are 48 acoustic domain
frames (i.e. 48 components from a given frequency bin) per modulation domain
frame. The modulation domain magnitude spectrum is modiﬁed by using equation
(7) for spectral subtraction in the modulation domain.
Objective Function
PSO optimizes the particle positions such that the objective function value will be
maximum in this algorithm. Modulation domain spectral SNR is the objective func-
tion here. PSO modiﬁes the noise magnitudes (particle positions) such that the objec-
tive function value is maximum. The following equations give objective function
calculation. For a given acoustic frequency, for a real modulation domain spectrum,
if |ZR(k, m, r)| is the magnitude of one sample in the frame and |MR−I(k, m, r)| is
the magnitude of noise at that frequency then SNR for the modulation domain frame
is estimated as in (11 and 12)
SNR_R(k, m, 1) = 10 ∗log
 M −1
r=0 |ZR(k, m, r)|2
M −1
r=0 |MR−I(k, m, r)|2

(11)
SNR_I(k, m, 1) = 10 ∗log
 M −1
r=0 |ZI(k, m, r)|2
M −1
r=0 |MR−I(k, m, r)|2

(12)
In this way at each acoustic frequency, for every modulation frame, SNR is esti-
mated for the real and imaginary spectrum in the modulation domain. Frame SNR
s of the imaginary spectrum are named (SNR_I). Equations (13 and 14) give the
average of frame SNR of all modulation frames of a single acoustic frequency in the
real and imaginary spectrum. Equation (15) gives the average of snr_R and snr_I
for a single acoustic frequency. The average of SNR s for all acoustic frequencies is
calculated which is the objective function, given by (16). If there are Q modulation
domain frames of single acoustic frequency for real and imaginary then.
snr_R = 1
Q ∗
Q
	
m=1
SNR_R(m, 1)
(13)

Single-Channel Speech Enhancement in Modulation Domain …
149
snr_I = 1
Q ∗
Q
	
m=1
SNR_I(m, 1)
(14)
AvSNR =
1
2

∗(snr_R + snr_I)
(15)
SNR =
 1
N

∗AvSNR = Objective Function
(16)
The algorithm tries to maximize the objective function value by optimizing the
value of noise at each frequency. The optimization of SNR values in turn decides
the value of α for each frame in Eq. (7) by which we get the enhanced magnitude
spectrum as the output of spectral subtraction. In every iteration, the algorithm ﬁnds
particles with the maximum objective function value. The stopping criterion is based
on the threshold value set for the objective function. Here, we kept 8 as the threshold
value. The particle whose objective function value is greater than or equal to the
set value becomes the best particle. It gives the most optimized noise estimate in
the acoustic domain. The corresponding modulation domain magnitudes for the best
particle are used for the spectral subtraction in Eq. (7). IFFT of these two spectra
along with overlap-add gives acoustic domain spectra En′
R(n, k) and En′
I(n, k). These
two spectra are combined, and then by taking IFFT along with overlap-add, we obtain
a time-domain enhanced speech signal.
5
Results
To simulate the proposed method, we used MATLAB2019b. Noisy speech data is
taken from the NOIZEUS database which comprises thirty IEEE sentences produced
by three male and three female speakers corrupted by eight different real-world noises
atdifferentSNR[20].Fivesentencesbymaleandﬁvebyfemalespeakerswithbabble,
car and exhibition noise having overall SNR of 0 dB, 5 dB, 10 dB and 15 dB are given
as the input to the algorithm. Total 120 sentences (10*3*4) are used to evaluate the
objective measures. Perceptual estimation of speech quality (PESQ) and segmental
SNR are estimated in each case. Comparison of output PESQ of the proposed algo-
rithm is done with PESQ result of [16] for MMSE, bnmf, MMSEPSO and result of
Log-MMSE. Table 3 gives a comparison of output PESQ for the above-mentioned
algorithms. Fig. 1 shows convergence of PSO, Figs. 2 and 3 show comparison of
PESQ values for various algorithms for babble and car noise. The proposed method
gives a better value of output PESQ for all noise types and all input SNR levels. It
gives convergence to the set value of the objective function within 3–5 iterations.

150
K. Ghorpade and A. Khaparde
Table 3 Comparison of output PESQ for various algorithms
Babble noise
method
0 dB
5 dB
10 dB
15 dB
bnmf
MMSE
MMSEPSO
Log MMSE
proposed method
1.70
1.72
1.75
1.8630
2.2216
2
2
1.895
2.2065
2.7922
2.25
2.3
2.45
2.5973
3.0271
2.4
2.375
2.70
2.8675
3.0351
Car noise
bnmf
MMSE
MMSE-PSO
Log MMSE
proposed method
1.625
1.6
1.75
1.9221
2.4413
1.85
2.15
2.13
2.3394
2.6855
2.20
1.9
2.25
2.7090
2.9155
2.375
2.4
2.75
2.8956
2.9685
Exhibition noise
bnmf
MMSE
MMSE-PSO
Log MMSE
proposed method
1.3
1.31
1.75
1.6712
2.525
1.9
1.7
1.95
2.1703
2.675
2.2
2.1
2.4
2.5334
2.775
2.4
2.25
2.75
2.9012
2.98
Fig. 1 Convergence of the proposed algorithm
Fig. 2 Output PESQ for babble noise

Single-Channel Speech Enhancement in Modulation Domain …
151
Fig. 3 Output PESQ for car noise
Pseudocode of the Proposed Algorithm

152
K. Ghorpade and A. Khaparde
6
Conclusion
PSO can be suitably used for noise estimation in the modulation domain. Results
show that the use of PSO gives improved PESQ for babble, car and exhibition noise.
We got 34.5% increase in PESQ for 0 dB babble noise. The percentage increase in
PESQ is more for female speakers compared to male speakers in the case of 5 dB
and 10 dB input SNR. Segmental SNR is improved except for the 15 dB noise level.
Musical noise is reduced in the enhanced speech. PSO gives convergence to the set
objective function value in 3–5 iterations. This shows that PSO can provide good
optimization of noise estimation for a single-channel speech enhancement system.
References
1. Kondaz, A. M. (2004). Digital speech coding for low bit rate communication systems, 2 Edn.
Wiley.
2. Loizou P. C. (2013). Speech enhancement: Theory and practice, 2 Edn. CRC Press.
3. Hu, Y., & Loizou, P. C. (2006). Subjective comparison of speech enhancement algorithms,
Department of Electrical Engineering, University of Texas at Dallas Richardson, Texas. 1-
4244-0469-X/06 IEEE.
4. Boll, S. (1979). Suppression of acoustic noise in speech using spectral subtraction. IEEE
Transactions on acoustics, speech, and signal processing, 27(2), 113–120.
5. Berouti et al. (1979). Ehancement of speech corrupted by acoustic noise, acoustics, speech,
and signal processing. IEEE international conference on ICASSP 79, (Vol. 4, pp. 208–211).
6. Zadeh. (1950). Frequency analysis of variable networks.” IRE, 38, 291–299.
7. Atlas. (2003). Modulation spectral transforms: application to speech separation and modiﬁca-
tion. University of Washington.
8. Paliwal, K., Wójcicki, K., & Schwerin, B. (2010). Single-channel speech enhancement using
spectral subtraction in the short-time modulation domain. Speech Communication, 52(5), 450–
475.
9. Zang, Y. (2012). Modulation domain processing and speech phase spectrum in speech enhance-
ment. A dissertation presented to the faculty of the graduate school at the University of
Missouri-Columbia.
10. Wang, Y. (2015). Speech enhancement in the modulation domain Ph.D. thesis. Imperial College
London.
11. Dionelis, N., & Brookes, M. (2017). Modulation domain speech enhancement using Kalman
Filter with a Bayesian update of speech and noise in the log spectral domain, 978-1-5090-
5925-6/IEEE.
12. Wang, Y., & Brookes, M. (2018). Model-based speech enhancement in the modulation domain
IEEE/ACM transaction on audio. Speech and Language Processing, 26(3).
13. Prajna, K., Rao, S. B., & Reddy, K. V. V. S. (2014). A new dual channel speech enhancement
approach based on accelerated particle swarm optimization (APSO) I.J. Intelligent Systems
and Applications.
14. Prajna, K., Rao, S. B., Reddy, K. V. V. S., & Maheswari, R. U. (2015). A new approach to
dual channel speech enhancement based on hybrid PSOGSA. International Journal Speech
Technology, 18, 45–56.
15. Geravanchizadeh, M., & Osgouei, S. G. (2015). A new shufﬂed sub-swarm particle swarm
optimization algorithm for speech enhancement. Journal of Advances in Computer Engineering
and Technology, 1(1).

Single-Channel Speech Enhancement in Modulation Domain …
153
16. Selvi, R., Suresh, G. R. (2015). Hybridization of spectral ﬁltering with particle swarm
optimization for speech signal enhancement. International Journal of Speech Technology.
17. Kennedy, J., & Eberhart, R. (1995). Particle swarm optimization. In Proceedings of the IEEE
international conference on neural networks, (Vol. 4, pp. 1942–1948).
18. Shi, Y., & Eberhart, R. (1999). Empirical study of particle swarm optimization. Proceedings
of the IEEE congress on evolutionary computation, (CEC), (pp. 1945–1950).
19. Esmat, R., Hossein, N.-P., & Saeid, S. (2009). GSA: A gravitational search algorithm.
Information Sciences, 179, 2232–2248.
20. Hu, Y., & Loizou, P. (2007). Subjective evaluation and comparison of speech enhancement
algorithms. Speech Communication, 49, 588–601.

Pneumonia and Diabetic Retinopathy
Detection Using Deep Learning
Algorithm
Meera Ghaskadvi, Sakshi Khochare, Rozebud Gonsalves,
and Prajakta Dhamanskar
Abstract Diseases knock on a man’s door when he least expects it. One such disease
is Pneumonia. It occurs due to the inefﬁciency of lungs and can lead to major health
threats in not just young adults but also children if not detected timely. Diabetic
Retinopathy, a disease commonly seen in diabetic patients can be lethal and make a
person lose their eyesight. To diagnose these diseases timely, the amalgamation of
health with technology is inevitable. With the medical circle of our country being
consistently under a great deal of pressure particularly in these difﬁcult times of
the pandemic, we have made a one-stop site that can test the presence of different
illnesses like diabetic retinopathy and pneumonia by using a deep learning algorithm
called convolutional neural networks. We wish to limit the endeavors and the human
contact needed in the whole cycle of getting oneself tested so that the presence of
illnesses can be tested from the comfort of your home, without investing cash and
energy, and by staying away from human touch and hence keeping yourself safe from
the covid-19 infection. We have taken CT Scan images as input and have obtained
high accuracy, recall, and precision values. We have obtained an accuracy of 90.06%
and 92.88% for Pneumonia and Diabetic Retinopathy respectively. Thus we have
successfully created a one-stop website that can be used by healthcare professionals
as well as organizations.
Keywords Diabetic retinopathy · Pneumonia · Deep learning · Convolutional
neural networks · CT scans · Overﬁtting · Precision · F1 score · Recall · Feature
extraction · Feature importance
1
Introduction
Our Advancements in medicines are the demand of the day and it is required to
combine medicine with technology for further growth. Due to the unprecedented
circumstances faced by the entire world due to the pandemic, there is tremendous
pressure on doctors, hospitals, and medical staff. As “contactless” aims to become the
M. Ghaskadvi (B) · S. Khochare · R. Gonsalves · P. Dhamanskar
Fr. Conceicao Rodrigues College of Engineering, Bandra West, Mumbai, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_13
155

156
M. Ghaskadvi et al.
new normal, the patients are scared to go to hospitals and get themselves diagnosed
with a speciﬁc disease. The process is prone to error and doctors, in general, are
very busy, even busier due to the pandemic. All these limitations encountered can
be solved with the help of our project. We have come up with a solution where
the patients can take a couple of tests from the comfort of their homes for free of
cost, and know what ailment they have without having to step a foot out of their
houses, thereby reducing the stress on the medical ﬁeld. The aim is to develop a
system that successfully identiﬁes whether a person has a disease or not and to print
a full body report of those diseases using Deep Learning Algorithms. Currently,
our system can be used for the diagnosis of two distinct types of disease, that is
Pneumonia (Lung disease) and Diabetic Retinopathy. The problem with Pneumonia
is that it is not easily discovered in early stages. An early diagnosis of the subtle
symptoms can increase the chances of survival of the patient. Similarly, Diabetic
Retinopathy that causes blindness in the eyes of a diabetic patient occurring due to
high sugar levels can be avoided if the symptoms are diagnosed at an early stage.
We subsequently propose a framework that will anticipate sicknesses at a beginning
phase, consequently improving the odds of endurance or getting completely treated.
The program will at that point continue to print the full body report and immediately
the individual knows the inﬁrmities that he/she is experiencing.
2
Related Work
This research [1] focuses on multilayer perceptron neural networks (MLPNN) to
determine the presence of diabetic retinopathy in the eyes by using various features
of the pictures of the retina of the human eye. The dataset images used here were
taken from Kuopio University Hospital and have a total of 130 images. 20 of them
are normal (healthy) and what’s more, 110 pictures contain indications of diabetic
retinopathy (unusual). Unmistakable highlights of pictures of the retina like 64-point
DCT, alongside 9 measurable factual boundaries are extricated from retinal pictures
and utilized as contributions to the classiﬁers. In this exploration, best outcomes
were acquired when 10% models were utilized for cross validation (CV), and 90%
for training neural networks.
This research [2] aims to provide a model to do all lesion occurrences of
contrasting classiﬁcation in one go. The experiment results of this research show
that the methods used here can improve performances of lesion detection to a great
extent over the previous methods used (Faster RCNN and FPN). The analysts here
built up their own naming instruments, which is effectively put in to stamp the limit
box and classiﬁcation of lesion instances in a picture. This dataset contains 5198
images with a resolution of 2136 × 3216 covering all ﬁve severity stages. Small
lesion detection in large medical images is an ordinary complication in the image
processing sector; therefore, these ﬁndings can automatically identify a lesion region,
thus improving the accuracy of the doctor’s diagnosis and efﬁciency.

Pneumonia and Diabetic Retinopathy Detection Using …
157
There are four phases of diabetic retinopathy that this research [3] speaks about:
mild non proliferative retinopathy, moderate non proliferative retinopathy, severe
non proliferative retinopathy, and proliferative diabetic retinopathy. It is possible that
doctors can make an incorrect diagnosis since all four stages have speciﬁc charac-
teristics. This research says 56% of new cases can be reduced with proper diagnosis
and treatment. The dataset used here was taken from Kaggle diabetic retinopathy
challenge 2015 and is the largest dataset available to the audience that consists of
35,126 fundus images. On the local dataset, ensembling with TTA performed some-
what worse than without it, however, ensembling with TTA performed better on the
testing dataset. The ensemble in TTA showed consistent ranking (58 and 54 of 2943)
on validation and testing datasets respectively.
The aim here [4] is to construct a design that can examine the seriousness of
diabetic retinopathy in a fundus picture. Various datasets are used in this research
that includes the standard diabetic retinopathy dataset, digital retinal images, Kaggle
diabetic retinopathy dataset among others. For image processing and to classify
them, deep convolutional neural networks were used. The steps were data collection,
data annotation, data pre-processing, data augmentation, model setup and evaluation,
model deployment, and clinical evaluation. Among the models evaluated, inception-
V3 achieved the highest accuracy of 88.35%
In this paper [5], the researchers talk about ﬁve stages of Diabetic Retinopathy; 0,
1, 2, 3, 4. From normal images, the doctors cannot speciﬁcally tell the phases; each
phase has its own particular properties. The dataset in this research is taken from
Kaggle 4th APTOS 2019 blindness detection. The images in this dataset provide a
color fundus image of diabetic retinopathy. VGG16 is utilized without ImageNet and
QWK and Dense Net is utilized with ImageNet and QWK. VGG16 gives less preci-
sion and Dense Net (with ImageNet) gives better precision comparatively. Hence, the
research compares these two constructions- VGG16 and Dense Net and the accuracy
of VGG16 is 73.26% and that of Dense Net is 96.11%.
This research’s [6] fundamental aim is to improve medical proﬁciency in places
where radiotherapists are not easily available. Early diagnosis of pneumonia is the
principal aspect of this research, so adverse consequences (even death) are avoided.
Different pre-prepared CNN models alongside distinct classiﬁers were noticed, and
based on measurable outcomes DenseNet-169 was chosen for the component separa-
tion stage and SVM for the grouping stage. The dataset utilized is the ChestXray-14
which is likewise freely accessible on Kaggle and consists of 30,085 pictures from
patients. Each picture is marked with at least one out of the 14 distinctive thoracic
sicknesses.
The research [7] here uses deep neural networks on the basis of the approach
involving TL for the automatic detection of types of lung diseases that are, COVID-
19 pneumonia, non COVID-19 viral pneumonia, bacterial pneumonia. All the models
were based on two binary classes and multi classes. Accuracy, sensitivity, speciﬁcity
were the aspects on which the models are evaluated in this research. A limitation

158
M. Ghaskadvi et al.
of this paper is that the authors used a considerably smaller dataset of COVID-19
pneumonia and hence it is difﬁcult to assume that the result applies to all classes
of people. The amount of CT scan images available on the internet for COVID-19
pneumonia and non COVID-19 viral pneumonia are very less. The researchers used
153 images from GitHub, 219 images from Kaggle, 1341 normal, and 4274 infected
images from Kaggle.
The proposed work [8] does a relative study of traditional deep learning based
neural networks. The designed Convolutional Neural Network (CNN), Competi-
tive Neural Network (CpNN), and Backpropagation Neural Network (BPNN) are
trained using chest pictures carrying various types of ailments. A number of combi-
nations of different parameters and iterations were carried out throughout this work
and comparisons were made between the models and also with the previous work.
The analysis of the network’s efﬁciency was done on the basis of various factors
like recognition rates, computation time, generalization power, and accuracy. It was
observed that CNN outperformed the other networks with higher recognition rates.
The results of CNN were also further juxtaposed with advanced deep learning models
like GIST, VGG16, and VGG19 which were also proved to have lower generalization
capabilities and accuracy.
This research [9] aims to determine an architecture that will help CAD, whose
purpose is to assist radiologists in medical image interpretations, to improve diag-
nostic accuracy. This paper implements two architectures, Deep Residual Network
and Mask Regional CNN, which can prove to be helpful in the development of CAD.
The performance of each network was observed using confusion matrices. Both the
networks resulted in a huge contrast graph between the Speciﬁcity and Sensitivity
calculated through the confusion matrices. This gap suggests that the dataset is unbal-
anced and the network will tend to predict the data in the negative class. Despite
these shortcomings, the residual network proved to show better performance than
the masked RCNN.
This paper [10] provides exhaustive research of deep learning approaches that
could be applied on various types of datasets consisting of CT scans of lungs
containing pneumonia. The proposed work aims to achieve better accuracy than the
previous works which used customized VGG16, yielding an accuracy of 96.2% and
93.6%, with the help of modiﬁcations. Initially, Chest Xnet produced good results in
detecting various diseases but was eventually outstripped by CNN which gave better
accuracy. From the later methods proposed it was concluded that VGG16 gave the
best accuracy. It was also noted that using various image pre-processing techniques
could help signiﬁcantly improve the speed and exactness of this network.

Pneumonia and Diabetic Retinopathy Detection Using …
159
Paper
Title
Publication details
Objective of the paper
Algorithms used
Accuracy
Future scope and
limitations
Bhatkar and Kharat [1] Finding the presence
of diabetic
retinopathy in retinal
images using MLP
classiﬁer
Amol Prataprao
Bhatkar,
Dr. G. U. Kharat
This paper focuses on
the MLPNN classiﬁer
is inaugurated to
characterize retinal
pictures as typical and
atypical
Multilayer perceptron
neural networks
100%
The image’s dispersion
doesn’t relate to any
regular population.
Pictures were caught
with not many 50° ﬁeld
of-view advanced
fundus cameras with
obscure camera settings
and contained an
obscure measure of
noise and differences in
optics
Chen et al. [2]
Mini lesions
detection on diabetic
retinopathy images
via large scale CNN
features
Qilei Chen, Xinzi
Sun, Ning Zhang,
Yu Cao, Benyuan
Liu Published in
2019
This paper analyzes the
lesion-vs-image
precisely and proposes
a huge feature pyramid
network (LFPN) to not
waste picture details
for mini lesion instance
detection
Huge size feature
pyramid network
–
Recall is still inﬂated
even with the IoU ratio
threshold climbs to 0.6
(continued)

160
M. Ghaskadvi et al.
(continued)
Paper
Title
Publication details
Objective of the paper
Algorithms used
Accuracy
Future scope and
limitations
Tymchenok et al. [3]
Deep learning
approach to diabetic
retinopathy
detection
Borys Tymchenko,
Philip Marchenko
and Dmitry
Spodarets
This paper proposes
the multi-task learning
approach to detect
diabetic retinopathy. It
uses three decoders
each trained to solve its
task based on features
extracted with CNN
backbone
EfﬁcientNet-B4,
EfﬁcientNet-B5, SE-
ResNeXt50
81%
The future work can
extend this method with
the computation of
SHAPE for the entire
ensemble, not just for a
speciﬁc network, and
with more exact
hyperparameter
optimization. Plus, we
can do tests utilizing pre
trained encoders on
others associated with
eye diseases
undertakings
Gao et al. [4]
Diagnosis of
diabetic retinopathy
using deep neural
networks
Zhentao Gao, Jie Li,
Jixiang Guo,
Yuanyuan Chen,
Zhang Yi, Jie Zhong
This paper aims to
fabricate a model that
can review the
seriousness of DR in a
given fundus picture
RESnet -18, ResNet
101, VGG-19,
Inception -V3,V4
88%
In the future, data from
greater equipment will
be incorporated, and a
more extensive pilot
study will be
dispatched. The
gathered information
will be additionally
used to improve the
exactness of the models
(continued)

Pneumonia and Diabetic Retinopathy Detection Using …
161
(continued)
Paper
Title
Publication details
Objective of the paper
Algorithms used
Accuracy
Future scope and
limitations
Mishra et al. [5]
Diabetic retinopathy
detection using deep
learning
Supriya Mishra,
Seema Hanchate,
Zia Saquib
The papers aim was to
develop a skeleton for
automatic detection of
DR
VGG16,
DenseNet121
96%
Not mentioned
Varshni et al. [6]
Pneumonia detection
using CNN based
feature extraction
Dimpy Varshni,
Karthik Thakral,
Lucky Agarwal,
Rahul Nijhawan,
Ankush Mittal
Assessment of the
performance of various
variations of
pre-prepared CNN
models followed by
various classiﬁers for
ordering abnormal and
typical chest X-Rays
ResNet, DenseNet,
VGG, SVM kernel
80%
Aims to give the
dominating
pre-prepared CNN
model and classiﬁer for
future work in the
comparative research
space
Ibrahim et al. [7]
Pneumonia
classiﬁcation using
deep learning from
chest X-ray images
during COVID-19
Abdullahi Umar
Ibrahim, Mehmet
Ozsoz Sertan Serte,
Fadi Al-Turjman,
Polycarp
Shizawaliyi Yakoi
This paper shows the
use of a deep neural
network depending on
the TL approach for
automatic detection of
COVID-19 pneumonia,
non-COVID-19 viral
pneumonia, and
bacterial pneumonia
AlexNet
94%
In the coming times, we
wish to get more
datasets and train the
images using deep
neural networks such as
pretrained GoogleNet
and ResNet thereby
combining CNN models
with support vector
machine (SVM) and
support vector
regression (SVR)
(continued)

162
M. Ghaskadvi et al.
(continued)
Paper
Title
Publication details
Objective of the paper
Algorithms used
Accuracy
Future scope and
limitations
Abiyev and Ma’aitah
[8]
Deep convolutional
neural networks for
chest diseases
detection
Rahib H. Abiyev
and Mohammad
Khaleel Sallam
Ma’aitah
Here, our goal is to
train both conventional
and deep networks
using the same chest
X-ray dataset and
drawing conclusions
based on it
Backpropagation
neural network
(BPNN),
convolutional neural
network (CNN),
competitive neural
network (CpNN)
92%
Not mentioned
Al Mubarok et al. [9]
Pneumonia
detection with deep
convolutional
architecture
Abdullah Faqih Al
Mubarok,
Dominique Jeffrey,
Ahmad Habbie
Thias
This paper aims to
know the performance
of two widely known
deep convolutional
architecture: residual
network and
mask-RCNN in
classifying and
detecting pneumonia
Residual network and
mask-RCNN
85%
In the coming future,
we could enhance the
performance with the
help of hyper parameter
tuning. Using complex
network structures and
augmenting the
unbalanced dataset may
also be possible in the
future so that we can get
the best architecture for
the pneumonia CAD
system
(continued)

Pneumonia and Diabetic Retinopathy Detection Using …
163
(continued)
Paper
Title
Publication details
Objective of the paper
Algorithms used
Accuracy
Future scope and
limitations
Tilve et al. [10]
Pneumonia
detection using deep
learning approaches
Ashitosh Tilve,
Shrameet Nayak,
Saurabh Vernekar,
Dhanashi Turi,
Pratiksha R.
Shetgaonkar,
Shailendra Aswale
In this survey, we also
tried to familiarize
ourselves with the
different image
pre-processing
methods apply to
transform raw X-ray
images into regular
formats to analyze
machine learning
techniques
VGG16, CNN
96%
It can happen that a
disease can be found
even when it is not
present due to the
existence of some
different ailment and
this issue of wrong
disease detection has to
be solved. We will solve
this issue by making a
model for similar
disease pneumonia and
using a more accurate
dataset
Yadav et al. [11]
Diabetic retinopathy
detection using feed
forward neural
network
Jayant Yadav,
Manish Sharma,
Vikas Saxena
This paper deals with
this issue with
computer vision to
detect this disease and
automate this
procedure using a
neural network thereby
giving results to many
patients in a stipulated
time
OpenCV and
Tensorﬂow
75%
Exactness can be
ampliﬁed using highly
up to date methods
(continued)

164
M. Ghaskadvi et al.
(continued)
Paper
Title
Publication details
Objective of the paper
Algorithms used
Accuracy
Future scope and
limitations
Smys et al. [12]
Survey on neural
network
architectures with
deep learning
Smys, S., Joy Iong
Zong Chen, and
Subarna Shakya
This survey majorly
gives an insight on
deep learning through
the analysis of its
architectures and its
characteristics along
with its drawbacks.
Also, this research
work analyzes recent
trends in deep learning
through various
literature to explore the
present evolution in
deep learning models
Various deep learning
algorithms
–
Future research could
be introducing hybrid
architectures in CNN
for enhancing
performance

Pneumonia and Diabetic Retinopathy Detection Using …
165
3
Research Gap
At ﬁrst, while managing both the sicknesses, the exactness was coming to 60% and
70% separately. At that point, we changed the ages of Lungs to 10 and of Diabetic
Retinopathy to 12 which gave the exactness of 80% and 85% for Lungs and Diabetic
Retinopathy separately. We at that point performed different techniques for precision
increment, for example, Image cleaning, Recalling, Vertical Zipping, Reducing the
quantity of layers, and diminishing the quantity of components in the secret layers.
By doing this our exactness effectively expanded to 90.6% for Lung’s illnesses and
92.88% for Diabetic Retinopathy.
4
Problem Deﬁnition
Our project detects the presence of two diseases in our body using Deep Learning
Algorithms. We have used Convolutional Neural Networks (CNN) thereby having
image data in the form of CT Scans for both Liver and Diabetic Retinopathy. We
expect a binary answer either in the form of a person having a disease or not having
one, thus having only two output classes. We then print a full body report with all
the details of the disease and further actions to be taken.
5
Methodology
5.1
Algorithm Used- Convolutional Neural Networks
We have made use of convolutional neural networks (CNN) in both Diabetic
Retinopathy and Pneumonia. A CNN is a deep learning algorithm suitable for prob-
lems with image datasets. It takes images as input to the algorithm and highlights
several important aspects of the image. CNN is an artiﬁcial neural network in which
the association pattern between its neurons is similar to the structure and operation
of the animal visual cortex of the brain. The role of CNN is to process an image in
such a way that the image is reduced in a form and important conclusions are drawn
out of it (Fig. 1).
A computer understands an image using numbers. So, we divide the entire image
into grids and assign the value of 1 to places where the picture is detected and −1
where it is not detected. The ﬁlters are formed and the input image is compared with
the already existing dataset of images.
There are 4 major layers in the architecture of CNN- convolutional, pooling, Relu,
and fully connected layer.

166
M. Ghaskadvi et al.
Fig. 1 Architecture of convolutional neural networks
• Convolutional layer: In this layer, the mathematical operation of convolution is
performed between the image given as input and a ﬁlter of a size MxM. It creates
a provincial ﬁeld and shrinks it into the size mentioned. The dot product is taken
between the ﬁlter and the parts of the input image. Because feature extraction
happens in this layer, it is also called the feature extraction layer. The result of
executing these layers is that the image details are arranged into scenes.
The following are the steps to a convolutional layer
Step 1: Here the features of the images are lined up
Step 2: Each image is multiplied by the feature pixel
Step 3: Addition
Step 4: Divide by the total pixels that are present in the feature.
From the output, we obtain details about the corners and edges. It is called a
feature map that is given as input to the next layer.
• Pooling layer: The primary goal of this layer is to decrease the size of the map
so that the processing of the image becomes lighter. It reduces the information
generated in the convolutional layer, keeping only those particular features that are
completely essential. This layer takes the largest element from the feature map
about which we have seen in the Convolutional layer. It is a crossover linking
the Convolutional layer and the fully connected layer. There are various types of
Pooling layers namely: Max Pooling, Average Pooling, Global Pooling.
• Relu layer: Rectiﬁed Linear Unit transformation function triggers a node if the
input is above a certain threshold. We eliminate non positive values from the
ﬁltered images and reinstate it with zeros. This is done to avoid getting zeros
after the addition. According to math, it is formulated as y = max (0, x). As we
can see that the equation is very simple and least complicated, the model takes
lesser fractions to run and thus Relu is one of the most widely used activation
functions. There is a minor issue that tags alongside Relu called the dying relu
where all negative values output zero. This problem can be solved by using other
Relu alternatives like Leaky Relu and ELU or by lowering learning rates.

Pneumonia and Diabetic Retinopathy Detection Using …
167
Fig. 2 Neural network with the fully connected layer
• Fully connected layer: It is the ultimate layer where the stratiﬁcation actually
occurs. Filtered and contracted input images are taken and are transformed into a
single unit. It comprises weights and biases. It is used to connect neurons between
twodifferentlayers.Italsocompressestheimageintoasinglecolumnvector.After
the convolutional layer, this stands second in time consumption. Learning the non
linear combinations happens here (Fig. 2).
5.2
Data Pre-processing
The inputs are stored in a directory that is then split into training and testing data
with a ratio of 20% and 80% respectively.
5.3
Model Information
Lungs: Size of the image after resizing is 150*150 (height and width). The ﬁrst layer
of convolution has 16 ﬁlters and a kernel size of (3,3). The next layer has 32 ﬁlters
and a kernel size of (3,3). The third convolutional layer has 64 ﬁlters and a kernel
size of (3,3). To ﬂatten the features to a vector, a Pooling layer of dimensions (2,2) is
used. The activation function used at the output is the Sigmoid Algorithm to classify
whether or not a person has pneumonia or not.
Diabetic Retinopathy: The size of the image after resizing: 224*224 (height and
width). The ﬁrst convolutional layer has 8 ﬁlters and a kernel size of (3,3). The second
convolutional layer has 16 ﬁlters and a kernel size of (3,3). The third layer has 32
ﬁlters and a kernel size of (4,4). To ﬂatten the features to a vector, a Pooling layer of

168
M. Ghaskadvi et al.
dimensions (2,2) is used. The activation function used at the output is the SoftMax
Algorithm to classify whether or not a person has pneumonia or not.
Samples used:
1.
Lungs:
Training data: 5126
Testing data: 624
2.
Diabetic Retinopathy:
Training data: 2562
Testing data: 548.
5.4
Datasets Used
The CNN architecture has been applied on two distinct datasets of ailments, Pneu-
monia and Diabetic Retinopathy. Both the datasets are image based, consisting of
scans of the area of interest.
5.4.1
Pneumonia
The dataset used for the Pneumonia detection model was published by Daniel
Kermany, Kang Zhang and Michael Goldblum in 2018. The latest version of this
dataset was extracted from Kaggle. This repository of data is divided into 3 direc-
tories of training data, testing data and validation data respectively, each containing
subfolders of each image category (Pneumonia/Normal). The dataset consists of
5856 CT scans, all in JPEG format each, out of which 1583 images were labeled
as normal and 4273 were labeled as infected with pneumonia. The scans were thor-
oughly scanned and graded by experts before being used for analysis and all low
quality and unreadable scans were discarded (Figs. 3 and 4).
Fig. 3 CT scan of normal
lungs

Pneumonia and Diabetic Retinopathy Detection Using …
169
Fig. 4 CT scan of affected
lungs
5.4.2
Diabetic Retinopathy
For the detection of Diabetic Retinopathy, the dataset used was downloaded from
Kaggle which was originally published by Asia Paciﬁc Tele-Ophthalmology Society
(APTOS). The dataset was perfectly balanced, consisting of 3660 retinal scan images
outofwhich1,805werelabeledwithnoDRand1855werelabeledwithDR.Theorig-
inal dataset was divided into 5 classes based on the severity of diabetic retinopathy,
which was combined for the aim of this work. The images were found to be in PNG
format. A Gaussian ﬁlter was applied to the images for enhancements of the features
and was resized to 224 × 224 pixels so that it could be readily used for the analysis
(Figs. 5 and 6).
Fig. 5 Eyes not affected by
diabetic retinopathy

170
M. Ghaskadvi et al.
Fig. 6 Eyes affected by
diabetic retinopathy
6
Results
6.1
Screenshots of Results
Descriptionof Figs.7and8:Thisﬁgureshowsagraphbetweenthenumberofepochs
and the accuracy of the research. Accuracy is highly dependent on the epochs. Taking
a large number of epochs might result in overﬁtting of the model. We have taken
the epochs to be 10 in Pneumonia and 12 in Diabetic Retinopathy. This graph is
very important to tell us about overﬁtting in the model. If the blue and the yellow
lines in the graph do not go along the same direction then it is a classic example of
overﬁtting. In our model, there is no such problem of overﬁtting as both the graphs
are along the same line.
Description for Figs. 9, 10, 11 and 12: The results table shows the various images
that are given as input on our website. These images are CT scans of lungs and
diabetic retinopathy for the respective diseases.
Fig. 7 Pneumonia model performance with respect to epochs

Pneumonia and Diabetic Retinopathy Detection Using …
171
Fig. 8 Diabetic retinopathy model performance with respect to epochs
Fig. 9 Pneumonia prediction—the patient does not have lung disease

172
M. Ghaskadvi et al.
Fig. 10 Pneumonia prediction—the patient has lung disease
Result Table
Accuracy = (TP + TN)/(TP + FP + TN + FN)
Precision = (TP)/(TP + FP)
Recall = (TP)/(TP + FN)
F1 score = (2TP)/(2TP + FP + FN)
where TP = True Positive, TN = True Negative, FP = False Positive, and FN =
False Negative.
A very big difference between scores (more than 20%) indicates overﬁtting. That
is not the case here. A well balanced and high value of all of the terms mentioned
above makes a model a reliable model.

Pneumonia and Diabetic Retinopathy Detection Using …
173
Fig. 11 Diabetic retinopathy detection—the patient doesn’t have lung disease
7
Conclusion
Adeeplearninghealthbaseddetectoriscreatedwhichdistinguisheswellbeingrelated
inﬁrmities and sicknesses and accordingly prints a full body report. We are preparing
a total site made for the patients containing two diseases at the moment. The dataset
consists of 5856 CT scans for pneumonia and 3660 retinal scan images for diabetic
retinopathy. For lunges, we received an accuracy of 90.06%, a precision of 87.61%,
recall of 97.43%, and F1 score of 92.45%; on the other hand, for diabetic retinopathy,
we received an accuracy of 92.88%, precision of 92.88%, recall of 91%, and F1 score
of 92.88%. For both diseases, we have used convolutional neural networks as the
algorithm to predict the disease as this algorithm works best with image data. We
are successfully predicting whether a person has a disease or not and the accuracies
are high enough to depend on. This framework will save time, exertion, and money
for a great deal of patients and viably give an idea to the patient about their health
status particularly during covid times where the whole medical industry is under a
ton of stress and with our research we aim to conglomerate the ﬁeld of Medicine
with Technology.

174
M. Ghaskadvi et al.
Fig. 12 Diabetic retinopathy detection—the patient has lung disease
Table 1 Model performance for different image sizes
Disease
Total
cases
Total correct
identiﬁcations
Test
accuracy
(%)
Precision
(%)
Recall
(%)
F1 score
(%)
Lungs
624
562
90.06
87.61
97.43
92.45
Diabetic
retinopathy
562
550
92.88
92.88
91
92.88
8
Future Scope
Alongside diabetic retinopathy and pneumonia, the framework can be improved by
including different ailments for all body parts like diabetes, kidney, heart infections,
and so forth in this way expanding the extent of the framework. Besides, versatile
use of the framework would empower users to get to it on their mobiles as android or
iOS applications. We can likewise make this framework accessible without internet
connection so users won’t require internet access to beneﬁt from this. We can add a
guest’s query module where guests can post their inquiries which can be replied to

Pneumonia and Diabetic Retinopathy Detection Using …
175
by medical services experts. We can add a chatbot where unprescribed medications
for not severe diseases like cold, cough can be recommended by the bot on the site.
We can add a personal consultation module where patients can book appointments
with Specialists if they possess a risk of these diseases. An OCR based module can
be introduced into the framework, which will scan the reports for the attributes and
save the difﬁculty of manual information.
References
1. Bhatkar, A. P., & Dr. Kharat, G. U. (2015). “Detection of diabetic retinopathy in retinal images
using MLP classiﬁers”. IEEE international symposium on nanoelectronic and information
system.
2. Chen, Q., Sun, X., Zang, N., Cao, Y., & Liu, B. (2019, November 19). “Mini lesions detection
on diabetic retinopathy images via large scale CNN features”. arXiv.
3. Tymchenok, B., Marchenko, P., & Spodarets, D. (2020, March 3). “Deep learning approach
to diabetic retinopathy detection”. arXiv.
4. Gao, Z., Li, J., Guo, J., Chen, Y., Yi, Z., & Zhong, J. (2018, December 19). “Diagnosis of
diabetic retinopathy using deep neural networks”. IEEE Access.
5. Mishra, S., Hanchate, S., & Saquib, Z. (2020). “Diabetic retinopathy detection using deep
learning”. International conference on smart technologies in computing, electrical and
electronics.
6. Varshni, D., Thakral, K., Agarwal, L., Nijhawan, R., & Mittal, A. (2019). “Pneumonia detection
using CNN based feature extraction”. IEEE explore.
7. Ibrahim, A. U., Ozsoz, M., Serte, S., Al Turjman, F., & Yakoi, P. S. (2021, January 4).
“Pneumonia classiﬁcation using deep learning from chest X ray images during COVID-19”.
Springer.
8. Abiyev, R. H., & Ma’aitah, M. K. S. (2018). “Deep convolutional neural networks for chest
disease detection.” Hindawi Journal of healthcare and Engineering.
9. Al Mubarok, A. F., Dominique Jeffery A. M., & Thias, A. H. (2019). “Pneumonia detection
with deep convolutional architecture”. IEEE.
10. Tilve, A., Nayak, S., Vernekar, S., Turi, D., Shetgonkar, P. R. & Aswale, S. (2020). “Pneumonia
detection using deep learning approaches”. International conference on emerging trends in
information technology and engineering.
11. Yadav, J., Sharma, M., Saxena, V. (2017, August 10–12). “Diabetic retinopathy detection using
feedforward neural network”. International conference on contemporary computing (IC3).
Noida, India
12. Smys, S., Chen, J. I. Z., & Shakya, S. “Survey on neural network architectures with deep
learning”. Journal of Soft Computing Paradigm (JSCP), 2.

Design of IoT-Based Improved
Multimodal Ant Colony Optimızation
(MM-ACO) Algorithm for Real-Time
Applications
Mohammed Khalid Kaleem, Kassahun Azezew, and Smegnew Asemie
Abstract In this paper, the design of IoT-based improved multimodal ant colony
optimization (MM-ACO) algorithm for real-time applications is implemented. The
main intent of multimodal ant colony optimization (MM-ACO) algorithm is to give
good solution for ﬁnding an optimal traversal path. In this, ﬁrst, data is initialized;
next, map is loaded and destination is selected. By using IoT, the location is updated.
Now,multimodalantcolonyoptimization(MM-ACO)algorithmwillgivetransversal
path using obtained data. By using this data, trafﬁc intensity is calculated. After calcu-
lation of intensity, the position is updated globally. By using Python, the entire system
is designed. Hence, from this, it can be observed that the accuracy and efﬁciency of
this algorithm is high compared to ant colony optimization (ACO) algorithm.
Keywords Ant colony optimization (ACO) · Multimodal ant colony optimization
(MM-ACO) · Internet of Things (IOT) · Intelligent transportation system ·
Connected vehicles · Swarm ıntelligence · Ant colony optimization · Dynamic
decision-making · Decentralized management
1
Introduction
The Internet of Things (IoT) is a computing idea that portrays the possibility of
regular actual items being associated with the web and provides the options to recog-
nize themselves to different gadgets for communication of information. In simple
terms, IoT is a system which associates the actual world with the computerized
world. Applications in the IoT are broad. This philosophy can be applied toward any
genuine situation wherein data can be gathered, experiences can be accumulated,
and suggestions can be made to take care of issues.
The Internet of Things is an advancement which includes detecting and preparing
information for applications and administration improvements. Present generation
explores center around shipping, examining, and putting away IoT information to
the cloud stage [1]. However, with the fast development of IoT gadgets which
M. K. Kaleem (B) · K. Azezew · S. Asemie
School of Computing and Informatics, Mizan Tepi University, Tepi, Ethiopia
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_15
177

178
M. K. Kaleem et al.
produce a lot of information ordinarily, there is profoundly alluring for enhancing
IoT information measures utilizing disseminated and decentralized administration.
The Internet of Things (IoT) is a system which is incorporated and extensive
use of the new age of data innovation. It plays major role in present generation
based on the facts of society and economy. In IoT, wireless sensor networks play
innovative role to establish and empower the data very quickly. IoT will enable the
data processing in very fast way and effective way [2]. Hence, the IoT systems will
take care the issues of powerful properties, inadequate data, and restricted calculation
capacities by using the artiﬁcial bee colony (ABC), SI-based calculations, ant colony
optimization (ACO), and particle swarm optimization (PSO) [3].
Basically, various utilizations of SI in IoT measures have been presented like
associated vehicles, information directing, and distributed computing of informa-
tion advancement [4]. SI-based calculation is introduced in this paper which centers
around applying SI-based calculation for transportation from the executives in IoT
framework. Especially, this proposes another model for the present generation,
where dependent on the offering data to one another, vehicles can consequently
and adaptively track down the best ways to objections.
Figure 1 shows an outline of transportation framework dependent on cutting-edge
vehicular innovations in which the associations of actual elements can be addressed
in digital substances [5]. Internet access is available to associate the vehicles from
the vehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V) and vehicle-to-base
station (V2B) and vehicle-to-sensor (V2S) [6].
In such manner, the target of this examination is associated with vehicles based on
the type of assistance and transportation. The executives depended on nature-roused
smart advances. Especially, a novel methodology of transportation where executives
Fig. 1 Overview of cyber physical architecture of smart transportation

Design of IoT-Based Improved Multimodal Ant Colony …
179
utilizing the idea of ACO and SI-based calculation is empowering associated vehicles
to settle on singular choices for passing a speciﬁc territory.
Against the background where the Internet grows quickly and clients interest
for different Internet administrations will take off, in Internet scale, application
and economies of scale have given stimulus to the rise of distributed computing
and another registering model. Distributed computing assembles a lot of dissi-
pated information in the server through the Internet, and afterward, distributed
computing specialist organizations supply ﬁguring, access, programming, and
different administrations.
Adequately, appropriating and booking a lot of information in the server farm
apply a huge impact on the exhibition of the distributed computing climate and
the genuine ﬁnancial advantages of providers. Exploration has shown that various
calculations utilized in distributed computing can rapidly ﬁnish large information
activity and acquire the ideal arrangement of enormous information that determines
these calculations which have issues of being single, ﬂuctuating, and simple to fall
into nearby ideal arrangements.
To advance the current circumstance, this paper proposes ideas from two view-
points. Concerning quick preparing of distributed computing, it utilizes the MapRe-
duce strategy to understand the quick examination of huge information. Concerning
benchmark understanding of huge information, this paper utilizes molecule swarm
streamlining to improve the calculation, along these lines empowering enormous
information to get the worldwide ideal arrangement.
With the development of advancement in the correspondences and control inno-
vations for ITS, makers and scientists begin to consider how to make vehicles can
“think,” work, and offer information together in endeavors of discovering an answer.
Consequently, SI turns into a promising procedure in which vehicles can go about
as an aggregate multitude is a framework.
Among approaches in SI, ACO has become a system for taking care of the shortest
path problem (SPP). Fundamentally, ACO is a class of streamlining calculations
which models the various activities. Especially, by setting down the phenomenon,
they will illuminate with one another to discover the assets while investigating their
current circumstance. Motivated by the conduct of genuine sources, in software
engineering, fake subterranean insects have been proposed to record their positions
and the nature of their answers.
In this manner, promising ways can be found with diminishing the computational
issues, particularly, in complex framework. In ITS, the vehicle issues are exploited
by using ant colony optimization (ACO), and this will explore the issues obtained
from the system. In present generation, trafﬁc streams are recorded based on the
vehicle advancements. However, they are mainly two types of vehicles which are
exploited; they are V2V and V2I. This will ascertain the advancement of vehicle
communication. To improve the stream of trafﬁc, ACO is used based on PSO. This
will empower the activity of decentralized framework. Hence, it will adjust the trafﬁc
stream dynamically effective.

180
M. K. Kaleem et al.
2
Existing System
Swarm intelligence (SI) are complex terms which are supported by decentralized
management in IoT systems. The equal advancement of AI at the edge empowers
programming based man-made brainpower into the actual world, which gives
constant enhancement and computational knowledge for associated objects at a
framework level. In such manner, edge investigation for decentralized administration
turns into a rising examination pattern in IoT these days. However, IoT frameworks
are mind boggling and dynamic conditions which need decentralized control. Swarm
intelligence is planning hideous quantities of individual innovation elements to coop-
erate. It is a major idea in IT that has been valuable and intriguing, just as somewhat
undermining, all through the advancement of present day mechanical advancement.
In such manner, using of SI-based calculations in IoT can improve the informa-
tion preparing regarding productivity and time utilization. In particular, keen appli-
cations, for example, associated vehicles and keen energy are obtained by utilizing
SI-based calculations which have been presented. Speciﬁcally, gaining high-volume
IoT information and enhancing IoT information preparing can improve the shopper
experience of IoT applications and administrations.
Associated vehicle for intelligent transportation system, recently, progressed that
vehicle advances will empower vehicles to convey and team up with others (e.g., V2V
and V2I) in their inner and outer conditions. This idea is required to be the vital factor
for the advancement of state of transportation. Ongoing explores center around the
idea of associated vehicles to give different uses of brilliant trafﬁc administrations.
Figure 2 portrays the interaction of associated vehicles when they cross a given
region. Basically, when vehicles show up the space, they will stack the guide to get
data for passing the region. Especially, maps are sectioned into different ways which
Fig. 2 Existing system

Design of IoT-Based Improved Multimodal Ant Colony …
181
address for the dynamic trafﬁc stream. In such manner, the calculation of trafﬁc
force and best courses are freely decided as opposed to considering the entire street
organization.
3
Proposed Algorithm
Fig. 3 shows the proposed algorithm. In this, ﬁrst, data is initialized; next map is
loaded and destination is selected. By using IoT, the location is updated. In applied
arithmetic, multimodal enhancement manages improvement errands that include
discovering all or the majority of the different arrangements of an issue, instead
of a solitary best arrangement. In multimodal ant colony optimization algorithm, a
few states of ants participate in discovering great answers for an advancement issue.
At certain time steps, the settlements trade data about great arrangements. In the event
that the measure of traded data is not too enormous, then the MM-ACO algorithm
can be effortlessly parallelized in a characteristic manner by setting the settlements
on various processors.
Hence, the multimodal ant colony optimization (MM-ACO) algorithm will give
transversal path using obtained data. By using this data, trafﬁc intensity is calculated.
After calculation of intensity, the position is updated globally.
Fig. 3 Proposed algorithm

182
M. K. Kaleem et al.
(1)
When a vehicle moves into a speciﬁc territory, it will guide the data and store
in a portioned information structure dependent on V2I correspondence. At that
point, objective is controlled (by driver) for moving and gives the different
vehicle hubs which are nearby to the message (neighborhood update) (Steps
1, 2, 3, 4, and 5 in Fig. 3).
(2)
When the vehicle went through an intersection hub (e.g., crossing point) (Step
6 in Fig. 3), it sends demand messages to different vehicles for computing the
trafﬁc force dependent on V2V interchanges (Step 7 in Fig. 3).
(3)
For the selection of destination in this examination, we expect that the asso-
ciated vehicle will settle on the choice for pushing the dependent on the best
estimation of viability computation (Step 6 in Fig. 3).
(4)
The interaction rehashes until the associated vehicle arrives at the objective
(Step 7 in Fig. 3). In particular, Alg. 2 shows the harsh sketch for settling on
thechoiceofassociatedvehiclesineverydivision.Atthepointwhenthevehicle
leaves the territory, it will send a worldwide update message for refreshing the
phenomena which is dependent on V2I correspondence.
For accessing the viability of the proposed approach, this ﬁgures out the vehicles
for passing a speciﬁc region. With respect to address Q3, we consider three run of
the system situations in transportation; the executives frameworks which include:
• Single Intersection: the situation including various ways empowers vehicles to
settle on the choice for moving at a given intersection hub.
• Intersection with Multiple Lanes: the situation is sent with various paths in a way,
for stressing the upside which is associated with vehicles by offering data to one
another for continuous information handling.
• Multiple Intersections: the situation with various intersection hubs access the
presentation of our methodology as far as the huge size of the street organization.
Fig. 4 shows the comparison of accuracy of ACO and MM-ACO. Compared to
ACO, MM-ACO will improve the accuracy of the system in very effective way.
Fig. 4 Comparison of accuracy

Design of IoT-Based Improved Multimodal Ant Colony …
183
Accuracy is improved by taking ﬁve samples of multi-agents. Every multi-agent
performs its operation in very effective way.
Fig. 5 shows the comparison of energy consumption of ACO and MM-ACO.
Compared to ACO, MM-ACO will reduce the energy consumption of the system in
very effective way.
Fig. 6 shows the comparison of lifetime network of ACO and MM-ACO.
Compared to ACO, the MM-ACO increases the life time of the system in very
effective way.
Fig. 5 Comparison of energy consumption
Fig. 6 Comparison of life time of network

184
M. K. Kaleem et al.
4
Conclusion
Hence, in this paper, the design of IoT-based improved multimodal ant colony opti-
mization (MM-ACO) algorithm for real-time applications was implemented. The
accuracy, efﬁciency, and network life of ACO and MM-ACO are observed from
results. It can be concluded that the MM-ACO gives good solution for the system in
real-time applications.
References
1. He, W., Yan, G., & Xu, L. D. (2014, May). Developing vehicular data cloud services in the iot
environment. IEEE Transactions on Industrial Informatics, 10(2):1587–1595.
2. Tsai, C.-W., Lai, C.-F., & Vasilakos, A. V. (2014, November). Future internet of things: open
issues and challenges. Wireless Networks, 20(8):2201–2217.
3. Zedadra, O., Guerrieri, A., Jouandeau, N., Spezzano, G., Seridi, H., & Fortino, G. (2018).
Swarm intelligence-based algorithms within iot-based systems: A review. Journal of Parallel
and Distributed Computing., 122, 173–187.
4. Fangchun, Y., Shangguang, W., Jinglin, L., Zhihan, L., & Qibo, S. (2014, November). An
overview of internet of vehicles. China Communications, 11(10):1–15.
5. Maglaras, L. A., Al-Bayatti, A. H., He, Y., Wagner, I., & Janicke, H. (2016, February). Social
internet of vehicles for smart cities. Journal of Sensor and Actuator Networks, 5(1):3.
6. Lu,N.,Cheng,N.,Zhang,N.,Shen,X.,&Mark,J.W.(May2014).Connectedvehicles:Solutions
and challenges. IEEE Internet of Things Journal, 1(4):289–299.
7. Abul, B. (2020). Sensor cloud based architecture with efﬁcient data computation and security
implantation for internet of things application. Journal of ISMAC, 2(02), 96–105.
8. Middendord, M., Reischle, F., & Schmeck, H. (2002). Multi colony ant algorithms. Journal of
Heuristics, 8, 305–320. https://doi.org/10.1023/A:1015057701750

An Interview Transcriber Using Natural
Language Processing
G. R. Deeba Lakshmi, Jayavrinda Vrindavanam, Anshika Shukla,
and Rahul
Abstract During the challenging times of COVID 19, major shifts in the learning
and interaction process have been observed especially in the ﬁeld of education and
platforms of wider interactions like seminars. Online medium has been emerging as
the order of the day. In this context, this paper looks at a new challenge that is being
faced by various institutions while carrying out the interview process or interactions
online or on a telephone. The recruiter might miss certain points when evaluating a
candidate or sometimes the ﬁner details of an interview are lost in communication,
the interviewer might also not be able to recall the details of a particular interviewee
at a later point in time. These are some of the challenges that would ultimately reduce
the effectiveness of an interview process. We are developing a platform that extracts
all the essential information delivered by the person who is being interviewed from
the data received by the candidate during the process. The paper makes use of Natural
Language Processing (NLP) to extract the key information from an interaction by
extracting certain features or important key points by making suitable algorithms
with the help of language dependencies. The paper also dealt with the outcome of
the interview in the sense that, whether the candidate got selected or not based on
her/his answers and how similar they are with the data provided by the company
which clearly puts forward what they are looking for in an employee.
Keywords Natural language processing (NLP) · Bag of words (Bow) · Term
frequency (TF) · Inverse-term frequency (ITF) · Parts of speech (POS) tag ·
Dependencies · Word2Vec · Computer vision (CV)
G. R. Deeba Lakshmi (B) · J. Vrindavanam
Faculty, Department of ECE, Nitte Meenakshi Institute of Technology, Bangalore, India
e-mail: deebalakshmi.gr@nmit.ac.in
J. Vrindavanam
e-mail: jayavrinda.v@nmit.ac.in
A. Shukla · Rahul
Department of ECE, Nitte Meenakshi Institute of Technology, Bangalore, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_16
185

186
G. R. Deeba Lakshmi et al.
1
Introduction
Though the research in the domain of Natural Language Processing (NLP) goes back
to the 1950s with the very ﬁrst Turing test, we have observed that it did not receive
focus until recently. By the late 1980s, there was a revolution in natural language
processing with the introduction of new machine learning algorithms, more compu-
tational power, and lesser dependence on various theories of linguistics. In this paper,
we are focusing on extracting important features from textual data, which is a major
ﬁeld of research in NLP. The earlier approach towards transcribing interviews was
manual and a person had to sit down and listen to an interview and write everything
down making sure nothing was missed. With the advancement in NLP, we are now
able to make our systems carry out this process more efﬁciently. This paper could
be considered as the initial step towards a task speciﬁc and elaborate approach for
information extraction which then goes through further analysis, and then ﬁnally
arrive at the results. The ﬁrst step in the NLP is to understand various Parts of Speech
(POS) [1]. There are 8 different POS in the English language: noun, pronoun, verb,
adjective, adverb, preposition, conjunction, and intersection. The POS determines
how a speciﬁc word helps in giving meaning to a sentence, for example; take the
word “address.” In the sentence, “You shall address the teachers”, the word address
is used as a verb. Whereas, in the sentence, “What is your address?” it is used as
a noun. Another example that could be taken for better understanding, the word
“notice”. In the sentence, “Did you notice that car?”, the word notice is used as a
verb whereas in the sentence “The notice is put up on the bulletin word” the word
notice is used as a noun. This shows that the POS tag of a word is signiﬁcant when
it comes to understanding the meaning of a sentence because before extracting a
sentence, understanding it is a crucial job that the transcriber must perform. The
other aspect we need to keep in mind is, when it comes to POS tags, they alone are
not sufﬁcient to help the listener to grasp the meaning of the sentence. Further, to
analyze whether the candidate is ﬁt for the company or not, we have made use of
Natural Language Toolkit (NLTK) and perform textual similarity, which helps us in
comparing whether the mindset of the candidate matches with the company. After
proper evaluation, a decision is made whether he or she would be selected or not.
During this process, the notable point is, the dataset used was developed by us, such
that it consisted of questions asked to the candidate and the answers of the candi-
date, with this we included a predeﬁned company dataset which consisted of answers
deemed acceptable by the company for the questions asked to the candidate. This
worked well for our small-scale research with limited data on the subject.
2
Literature Review
We began our research by looking up ideas and information regarding a transcriber.
Startingfromthefactthattranscribingofinterviewsforinformationwasinitiallydone
manually and still continues to the case in some places, which has made to create a

An Interview Transcriber Using Natural Language Processing
187
transcriber which could scrape out the essential information. With the aid of textual
similarity, we could even predict the outcome of the interview, which predicted if
a candidate got rejected or selected. Researching further into the linguistic realms
of this paper, we came across Stanford’s Typed Dependencies Manual [1], which
was designed to provide a simple description of the grammatical relationships in a
sentence. It gave us a broad idea about the grammatical technicalities that we need
to keep in mind while processing natural language. Techniques like Bag of Words
(BoW) and Term Frequency & Inverse Documents Frequency (TF-IDF) which are
used as word embedding techniques were understood by going through the works of
Zang [2] and Bafna and team [3] respectively. They have used arithmetic equations
to formulate the occurrence and importance of certain words. They also explained
how these values affect when we take up tasks like textual similarity, etc. where we
could get faulty values if these occurrences are not tuned. The paper by Mikolov [4],
showed how the word to vector is an efﬁcient approach when we create word vectors
and extract information by words but also it would have contextual correctness in
it which is not present in TF-IDF or Bow. To have an understanding of the imple-
mentation on a valid dataset we took the general debates dataset from Kaggel [5].
Another factor that plays a major role when it comes to setting up similarity between
two word sequences is dimensionality, Bengio’s paper dealt with this factor as the
testing word sequence would deﬁnitely be different from training word sequence
hence to ﬁght this by learning a distributed representation of words which informs
about the presence of the number of semantically close sentences [6]. Parida’s paper
dealing with keyphrase extraction helped us in understanding the problem better,
in the paper various keyphrase extraction technologies were elaborated [7]. Sara-
vana Kumar’s paper gave us insight on how decision making is carried out in an
Artiﬁcial Intelligence (AI) environment [8]. Ghahramani’s came to a conclusion
that proper aggregation of weights generated by carefully selected basic weighting
methods improves retrieval of the relevant documents with respect to the user’s
needs [9]. The extraction module presented in Siva’s paper explores implicit struc-
tures of the web page class to extract the information efﬁciently and helps in building
further understanding towards information extraction [10]. Chiu’s paper on co-verbal
gestures talked about how gestures play an important part in a face to face conversa-
tion, taking into account the conceptual content in utterances, physical properties of
speech signals, and the physical properties of the gestures themselves [11].
3
Proposed System Methodology
The proposed system consists of the stages which are shown in Fig. 1. As a ﬁrst
step, the system is fed with our candidate’s data. On this data, we have performed
information extraction. After extraction, we performed textual similarity with the
company data. Then, we get the numeric value for the similarity that we compute
between the candidates and company interview data. We compare our value (in %)

188
G. R. Deeba Lakshmi et al.
Fig. 1 Block diagram of the proposed system
with the threshold cut off percentage set by the company. Finally, the decision is
made whether the candidate is selected or not. This is what the model would be
doing overall and would give us the desired results.
4
Information Extraction
What information is to us might not be important to someone else, and getting
that selective information can be tiresome and time consuming in this era of endless
plethora of textual data and information. So being able to get our required information
inaccordancewithourintentionscomesunderinformationextraction.Understanding
the speciﬁc relationship between words, entities, and the meaning of a sentence in
its correct sense is important in this phase. It is our view that an automated way of
extracting information from a long and elaborate textual collection of data is quite
beneﬁcial [12]. The ﬂow chart of information extraction is provided in Fig. 2 to have
a better understanding.
4.1
Approaches to Extract Information
Extracting Information Based on Keywords
When we are extracting information, we start by applying simple rules, similar to the
keywords. For example, in a dataset which contains 100 speeches made by politicians
and we only wanted to extract the ones given by the president, we use the keyword
“President” to get the information we want. In this paper, such an approach is being
used for extracting simple information such as the name of the candidate or qualiﬁ-
cation with the help of various POS pattern formations [1] which we developed with

An Interview Transcriber Using Natural Language Processing
189
Fig. 2 Flow chart of information extraction
the objective of understanding the entity dependency in sentences keeping in mind
POS. When we went through the data that we created as well as the debates data we
saw similar patterns repeating in sentences.
For example, the most common patterns were [noun-auxiliary-proper noun],
[noun-preposition-noun], [verb-preposition-proper noun], [noun–verb–noun], etc.
which has helped us in extracting information such as name, previous occupations,
expertise, etc. For instance, let us look at the sentence below:
My name is Tanya, I have a degree in Arts. Previously, I was working with
Facebook, and the role being, manager of the content creation team.
• Name (noun) + is (auxiliary) + Tanya (proper noun)
• Degree (noun) + in (preposition) + Arts (proper noun)
• Working (verb) + with (preposition) + Facebook (proper noun)
• Role (noun) + being (verb) + manager (noun).
Byobservingtheabovementionedapproachwewereabletoextracttheunderlined
sentence fragments from our datasets as well.

190
G. R. Deeba Lakshmi et al.
Extraction of Information Based on Similar Pool of Words
We at times notice a variety of similar words that mean almost the same is used to
deliver the same meaning in a sentence. In this extraction process, what we do is we
group similar words and run our dataset through it to extract all the sentences which
have those words and might be useful. For example, in a job interview when asked
about the candidate’s strength, we might look for words like “strength,” “strong,”
“strong,” “proﬁcient,” “strong suit,”, etc. [7].
As wecanseeinFig. 2, weacquiredtherequiredcandidatedataset. Wepre-process
the dataset to make it useful for our further exploration and extracting information at
the same time. Information extraction is performed according to keywords present in
POS patterns [1]. If the keyword that we are using to extract information is present
in the corpus, we are delivered what we need. Else the process halts. This process
can be repeated for as many keywords as we want to extract the entire information.
5
Textual Similarity
When two pieces of texts are quite close to each other then we say such texts show
resemblance and similarity. This similarity is classiﬁed into two categories, lexical
similarity, and semantic similarity [10]. Lexical similarity at times is referred to as
surface closeness, which means it does not consider the actual meaning of the words
entered and just focuses on the word similarity. For example, sentence one: “The park
has a beautiful swing,” sentence two: “The trees present in the park are beautiful.”
In these sentences, there are 3 words which overlap. Not much attention is given to
meaning or context. Since word-to-word similarity is not enough, we must also look
for contextual similarity as well, in order to capture more of the semantics. Before
computing the similarity, we break a text into a relevant group of related words. If
we consider the above example again, we can observe that even though the words
overlap, the meanings of the two sentences are completely different.
5.1
Approaches for Text Pre-processing
Before feeding our textual dataset to our machine learning algorithms pre-processing
of text is required so as to accelerate the processing by ﬁltering out redundant and
useless data.
Bag of Words (BoW)
Bag of words is a kind of word embedding and is often described as a way of
extracting features from text for using them in various models and representing them
in vector format, with different machine learning algorithms [2].
For example, let us take 2 sentences:

An Interview Transcriber Using Natural Language Processing
191
Table 1 Bag of words vector table
Example
No
The
Water
In
The
Is
Very
Clean
Appears
To
Be
Blue
L
1
1
1
1
1
1
1
1
1
0
0
0
0
8
2
1
1
0
0
0
0
0
0
1
1
1
1
6
L: Length of the sentence
Vector of sentence 1: [1 1 1 1 1 1 1 1 0 0 0 0]
Vector of sentence 2: [1 1 0 0 0 0 0 0 1 1 1 1]
1.
The water ﬂowing in the river is very clean.
2.
The water appears to be very blue.
As we can see here, we have successfully represented the words as a bag of words
(a string of numbers). With addition of new words, the vector size increases and
therefore the length of the vector also increases which is one of the drawbacks of
BoW.
Term Frequency-Inverse Document Frequency (TF-IDF)
Term Frequency
Term frequency is simply deﬁned as the number of times a certain term appears in a
document [3].
Given by the formula:
t ft,d =
nt,d
Number of terms in the document
(1)
where, t is the term, d is the document and n is the number of times the term t appears
in document d. Therefore, each document and term would have its own TF value.
Inverse Document Frequency (IDF)
Inverse Document Frequency is simply a measure of how important a term is [3].
Given by the formula:
id ft = log
number of documents
number of documents with term′t′
(2)
TF-IDF Score
We can compute the TF-IDF score now since we have TF and IDF expressions
separately. Words with a higher score are more important compared to words with
lower scores [3].
Given by the formula:
(t f _id f )t,d = t ft,d ∗id ft
(3)

192
G. R. Deeba Lakshmi et al.
As we can observe from Fig. 3, we start by importing the required libraries needed
to perform our textual similarity task. We preprocess the dataset using BoW and TF-
IDF, to make it useful for our further exploration and extracting information at the
same time. Similarity query operation is performed on the pre-processed dataset.
Percentage similarity is delivered as the output. We take the average and check if the
average is greater than or less than the predeﬁned average value set by the company
(which can vary according to the need). If greater, the candidate is selected, otherwise,
he/she is rejected.
Fig. 3 Flow chart of textual similarity

An Interview Transcriber Using Natural Language Processing
193
6
Observed Results
With these information extraction techniques, we were able to extract the desired
speciﬁc information that we needed. We used two different approaches towards
extraction and obtained the desired information out.
6.1
Extracting Information Using Keywords
In Fig. 4, we used the keyword “branch,” thus our program scanned the entire corpus
and put forward the speciﬁc information.
6.2
Extracting Information Based on Similar Pool of Words
Over here we have a similar pool of words that would help us in extracting the
information about the “strength” of the candidate.
Now we move towards the textual similarity part.
Fig. 4 Information extracted
Fig. 5 Information extracted
using similar pool of words

194
G. R. Deeba Lakshmi et al.
Fig. 6 Extracted statement by identifying similar words in the corpus
Fig. 7 Similarity probabilities
Fig. 8 Average computed
We were able to ﬁnd the similarity between the query document (i.e., candidates’
dataset) and the corpus (i.e., company dataset) as shown in Fig. 6.
We ﬁnd the average similarity to take a decision whether the candidate is selected
or not as shown in Figs. 7 and 8.
At last, we pass our ﬁnal judgment by setting up a cut off value below which the
company would reject the candidate. For result purposes we took 60% as the cut off
could vary as per need [8].
So, the ﬁnal output is as shown in Fig. 9 below.
The tabulated results of the ﬁnal evaluations and a comparative analysis on our
two sets of datasets are formulated below.
Similarly, we performed the same operations of our other dataset (Dataset 2).
Fig. 9 Final outcome

An Interview Transcriber Using Natural Language Processing
195
Table 2 Final results of the
evaluation process
Technique Used
Dataset
Results
Candidate’s
status
BoW & TF-IDF
Dataset 1
46%
Rejected
BoW & TF-IDF
Dataset 2
67%
Selected
Word2Vec
Dataset 1&2
Inconsistent
NA
7
Work Embeddings for Future Deeper Approaches Like
Word2Vec
Word embeddings are representations for text which are learned, if two words have
similar meaning then they may have similar representations as well. Each and
every word is represented with real valued vectors in a predeﬁned vector space.
For example, the words “sister” and “brother” have the similar meaning minus the
gender so their word embeddings would be quite similar [4].
7.1
Word2Vec
It is an advanced word embedding technique developed by Google in 2013. It is an
effective method for efﬁciently learning standalone word embeddings from a text
corpus.
It made the neural network-based training of the embeddings more efﬁcient and
is considered the standard for developing pre-trained word embedding models.1
In the 2013 word2vec paper, they proposed two types of word2vec approaches
both involving neural networks, CBOW & Skip Gram model [4].
Common Bag of Words (CBOW)
In this model, we try to predict a target word with the help of the words around
that word (context words). In the neural network, we give the context word as input
which can be paired in a window of two or more words and in the output, we get our
desired target word predicted [4].
Example:
Sentence: “I love to make pizza for dinner” Over here, “pizza”: target word & “to
make,” “for dinner”: context word with a window size of 2.
1 Due to small datasets, we were getting inconsistent results with Word2Vec for the respective
similarity task.

196
G. R. Deeba Lakshmi et al.
Skip Gram Model
This works in just the opposite manner of the CBOW, here instead of giving context
words as input we give our target word as input and we receive our context words as
the output with SoftMax applied in the output layer [4].
8
Conclusion and Future Scope
The approach introduced in the paper was found to be enhancing our understanding
towards NLP. The paper has introduced an innovative approach that has the potential
for further improvement. The approach followed in this paper is able to successfully
extract information from the datasets that we created with the POS dependency
approach and with the help of various word embedding techniques like BoW and
TF-IDF we were able to compare similarities that were present in the two datasets.
Further, with a small python program, we just calculated the averaged-out percentage
which would tell us whether a candidate is selected or not.
NLP and the approach being introduced also opens up major areas for futher
research. During this study, we were unable to ﬁnd a public dataset for our task,
which has made us create our own dataset to test our techniques which worked
well for its capacity. Having large and more diverse datasets would help in further
improvements of this technique. On the other hand, a huge amount of structured
data is required for algorithms like word2vec, Glove, etc. to work properly and to
display desired results, we tried formulating them for better results but ended up with
inconsistent and highly unreliable outputs. So, in future, we would like to exploit the
dataset even further and get on par with it by training our models on the above stated
algorithms and techniques and work a seamless solution for this.
With the aid of CV (Computer Vision) and advanced machine learning we could
further add interactive features like facial features and gestures capturing [11] that
wouldtellusabouttheattitudeandbehavioralpatternsofthecandidate.Inconclusion,
we were able to implement a small-scale version of the big picture which has opened
doors for us to dwell in deep and bring it to further perfection in the near future.
References
1. Stanford Dependencies Manual https://nlp.stanford.edu/links/statnlp.html
2. Zhang, Y., Jin, R., & Zhou, Z. H. (2010). Understanding bag-of-words model: A statistical
framework. International Journal Machinery Learning and Cyber. 1, 43–52.
3. Bafna, P., Pramod, D., & Vaidya, A. (2016). Document clustering: TF-IDF approach.
International conference on electrical, electronics, and optimization techniques (ICEEOT),
(pp. 61–66). ICEEOT.
4. Mikolov, T., Yih, W., & Zweig, G. (2013). Linguistic regularities in continuous space word
representations. In: NAACL-HLT: Proceedings of North American chapter of the association
for computational linguistics: Human language technologies, (pp. 746–751).

An Interview Transcriber Using Natural Language Processing
197
5. UN General Debates www.kaggel.com
6. Bengio, Y., Ducharme, R., Vincent, P., & Jauvin, C. (2003). A neural probabilistic language
model. Journal of Machine Learning Research, 3, 1137–1155.
7. Parida, U., Nayak, M., & Nayak, A. K. (2021). Insight into diverse keyphrase extraction tech-
niques from text documents. In: D. Mishra, R. Buyya, P. Mohapatra, & S. Patnaik (Eds.)
Intelligent and cloud computing, (Vol. 194). Smart Innovation, Systems and Technologies.
Springer, Singapore.
8. Saravana Kumar, N. M. (2019). Implementation of artiﬁcial intelligence in imparting education
and evaluating student performance. Journal of Artiﬁcial Intelligence, 1(1), 1–9.
9. Ghahramani, F., Tahayori, H., & Visconti, A. (2021). Effects of central tendency measures on
term weighting in textual information retrieval. Soft Computer, 25, 7341–7378.
10. de Morais Sampaio Silva, T., de Freitas, F. L. G., Cobra Teske, R., & Bittencourt, G. (2004).
Semantic information generation from classiﬁcation and information extraction. In: N. Koch,
P. Fraternali, & M. Wirsing (Eds.) Web engineering. ICWE 2004. Lecture notes in computer
science, (Vol. 3140). Springer, Berlin, Heidelberg.
11. Chiu, C. C., Morency, L. P., & Marsella, S. (2015). Predicting co-verbal gestures: A deep and
temporal modeling approach. In: W. P. Brinkman, J. Broekens, & D. Heylen (Eds.) Intelligent
virtual agents. IVA 2015. Lecture notes in computer science, (Vol. 9238). Springer, Cham.
12. Taran, M. O., Revunkov, G. I., & Gapanyuk, Y. E. (2020). The text fragment extraction
module of the hybrid intelligent information system for analysis of judicial practice of arbi-
tration courts. In: B. Kryzhanovsky, W. Dunin-Barkowski, V. Redko, & Y. Tiumentsev (Eds.)
Advances in neural computation, machine learning, and cognitive research IV, (Vol. 925).
NEUROINFORMATICS 2020. Studies in Computational Intelligence. Springer, Cham.

Plagiarism Detection for Source Codes
and Texts
Syed Yasmeen, Munjuluri Prathyusha, Malisetty Rajeswari,
Padmanabhuni Srujana, and K. Ashesh
Abstract Everything is online. We exist in the age of internet. It has become an
important part of our life that we cannot imagine our life without it. We use internet
forvariousdifferentneedsfromsendingmessages,calling,sharingpicturestoacquire
skills online. It is serving as a source of information, entertainment and has made
online shopping easy. It has made our life very convenient. But people now tend to
spend more and more time on it without doing any actual work. And it saves our
time too. Besides every big or small detail is available on the internet. In this age
of internet, one tends to use easy methods to do his work, assignments, projects,
speeches, presentations instead of putting in efforts from their side. Technology has
been developing from letters to mails, books to pdfs and blackboards to screens.
Since everything is online, there is a high chance of stealing or copying someone
else’s work and this is called plagiarism. Plagiarism is the practice of copying other’s
work or ideas. Plagiarism has become disseminated in online. It happens due to lazi-
ness, last minute panic, desire to get good grades, fear of failing, lack of conﬁdence.
Plagiarism is popular in computer language coding programs, projects and docu-
mentation/research papers. Plagiarism is being done with or without knowledge.
Sometimes it is very difﬁcult to check if you are plagiarizing when you paraphrase
someone’s ideas as your own. Plagiarism does not allow an individual to develop their
writing skills, nor does it serve the purpose of the assignments. Plagiarism prevents
you from shaping your own ideas and opinions on a topic.
Keywords Data importing · Flask · Nltk · Cosine similarity · Ngrams · Lcs ·
Percentage calculation · Plagiarism detection · Html · Css
S. Yasmeen (B) · M. Prathyusha · M. Rajeswari · P. Srujana · K. Ashesh
Department of Computer Science and Engineering Koneru Lakshmaiah Education Foundation,
Vaddeswaram, Guntur, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_17
199

200
S. Yasmeen et al.
1
Introduction
Plagiarism detection is very useful in the online ﬁeld. Since everything is revolving
around online texts, documents etc., there is a high chance of copying other’s work.
It is very easy to steal or copy someone’s work in online. So many people tend to
copy/steal. If everyone continues to steal the work instead dong on their own there
will be no value to the original work/content. So, there is a high end necessary to
identify which is original work and copied work. It is very difﬁcult to identify the
original work and copied work manually because of massive ﬁles and data and also
there are different types of stealing work which cannot be found in a general way of
detection.
Plagiarism is stealing or copying someone else’s work and calling it their own.
It can be done with or without knowledge. Plagiarism is done by stealing the work
entirely or partially. There are various kinds of plagiarism.
Generally speaking, there are four kinds of plagiarism namely:
1.
Direct Plagiarism: It is that plagiarism when you deliberately copy word to word
without any changes, attributions or quotations. The most common example
for this type of plagiarism is copying of essays from internet for assignment
purposes.
2.
Self-Plagiarism: It happens when someone submits his own previous works or
part of it without permission again. It also applies to submitting same work in
different situations.
3.
Mosaic Plagiarism: The basic meaning of mosaic is putting together small
pieces. This kind of plagiarism is when someone takes up phrases and words
from original work or reframing the sentences and keeping the structure and
meaning of it same as original one.
4.
Accidental Plagiarism: This kind of plagiarism occurs in an unintentional way.
It happens when someone unintentionally paraphrases a source with the use of
similar kind of words.
Here our basic idea of the project is to detect plagiarism in texts as well as in the
source codes of various programming languages.
2
Objectives
1.
Study and explore required concepts and review the literature survey on
detection of plagiarism.
2.
Examine the usage of plagiarism in real world. Designing a website exclusively
for selecting the type of ﬁle and upload the ﬁle into it for plagiarism detection.
3.
Studying various layered approaches exploring algorithms which helps to detect
plagiarism to predict plagiarism.

Plagiarism Detection for Source Codes and Texts
201
3
Literature Review
Plagiarismis theactionof copyingothers works without their consent. It is considered
as academic dishonesty. In academics it is a serious ethical offense. Plagiarism is not
punished by law, but rather by institutions.
Many plagiarism detection tools and algorithms are now available to help limit
the issues. Many of these is the product of scholarly studies rather than commercial
endeavors. Some current tools are based on algorithms that can handle all types of
submissions, including plain text, structured text, and audio podcasts, by converting
them to plain text and then applying the well-known Winnowing algorithm to look
for similarities with other texts locally or globally. For sentence comparison, other
natural language-based techniques were used. Using a natural language algorithm,
each pair of sentences is given a similarity score and a common score. The affectivity
of discovering plagiarized text can be increased by using sentence-based comparison.
There are two types of plagiarism detection systems:
1.
Plagiarism in Documents is number one.
2.
Source code plagiarized.
Plagiarism detection software is divided into two categories:
1.
Resources that can be accessed through the internet.
2.
Instruments that can be used on their own.
Existing Tools
1.
Web-enabled plagiarism detection tools: A web-enabled plagiarism detector
is an online platform which takes text or documents as input and checks or
compares with various papers published online and shows the amount of content
plagiarized in the form of percentages and generates a report at the end for the
reference.
2.
Standalone plagiarism detection tools: Standalone tools are some plagiarism
detection software’s that can be installed and run-in individual PC’s unlike
online plagiarism websites and used for checking plagiarism in the given input
documents or texts. It performs a large number of searches on the internet using
articles to ﬁnd matches between sentences. As a result, the device must be linked
to the internet in order for these resources to work.
Text Document Plagiarism Detection
The existing features of document plagiarism detection techniques are developed
using similarity technique. Most of these tools are web-enabled tools. These tools
support input of various languages documents and returns the output in the form of
a report. It is a web-based platform. The main users of this platform are teachers,
instructors, or students. The input ﬁle format can be in the form of word document’s
or plain text.

202
S. Yasmeen et al.
Since it is a web-based platform when a word document or text is given as input,
this platform compares the document with many available documents in web. Plagia-
rism is detected in text documents using various factors such as average length of
line, total size of ﬁle, number of commas used in each line.
Source Code Plagiarism Detection
Copying or reproducing the same source code without providing due credit to the
original source code author is known as source code plagiarism. This involves
adapting work in a minimal or moderate way, or repurposing original code fragments
as your own.
It can be done in two types:
i.
Lexical Change.
ii.
Structural Change.
i.
Lexical Change:
The simplest form of shift is lexical. They can be accomplished by making a few
basic changes to the master code. There is no need to know how to code in this case.
ii.
Structural Change:
For systemic changes, programming expertise is needed. Changing iterations, condi-
tional statements, and statement order, as well as changing procedural calls within
the body of the process and vice versa, converting procedure to work and vice versa,
and adding statements that will not affect the code’s output, are all examples of struc-
tural changes. The plagiarism detector employs advanced algorithms to detect any
code overlaps between candidates’ submissions. Code cloned from publicly acces-
sible sources on the internet. Code that can be duplicated by modifying the names
of variables, formats, and so on.
As we had gone through numerous research papers, we found some other
algorithms which were used to detect plagiarism.
String Matching technique: In this method plagiarism is detected by matching
character by character. String matching is not limited to only character matching.
This method can also use n-Gram and hashing block of the character to match the text.
Before performing n-Gram and hashing the text is pre-processed using tokenization,
stop word removal, stemming then hashing with Rabin-Karp algorithm.
AST (Abstract Syntax Tree): This algorithm detects plagiarism by the process
of generating hash values and comparing them. AST-CC (Code Compare) algorithm
also eliminates the potential errors of some arithmetic operations such as subtraction,
division, modulo arithmetic and so on. This works effectively because of storage form
of AST.
SPDS (Structure Plagiarism Detection System): To analyse the behaviour of
the function, the Dynamic Slicing technique is used, which combines combinatorial
decision coverage to produce valid inputs. The results are then translated to a software
dependency graph, which is used to quantify the behavioural part’s similarity. Then,
usingthecosinesimilarityandwinnowingalgorithms,thesimilaritybetweenvariable

Plagiarism Detection for Source Codes and Texts
203
and statement is determined. Finally, depending on the case, the weight of each
similarity is changed by the user or determined by the systems.
After going through all the research papers, we had found that there were very less
plagiarism detection systems which were detecting both the source code plagiarism
and text plagiarism. To detect the percentage of plagiarism separate algorithms were
used for source codes and texts. Based on that, this paper tries to combine and improve
the algorithms and apply the same to both the source code and the text plagiarism.
We have also made the plagiarism detection system such that it does not restrict the
user to choose only from a single language of source code.
4
Proposed Work
A.
Front End
The basic idea for the implementation is make user friendly web application in
which one can easily check plagiarism. The web application is developed using
hypertext mark-up language, cascade style sheets, java script and java server pages.
The backend is connected through oracle express edition and python using ﬂask. It
consists of login and sign- up pages. A person needs to login through this application,
if he does have an account, he can always sign up through register page. After
logging in one can select if he wants to check plagiarism in text or source codes.
There are various validations which are performed through java script like validating
password so it contains minimum eight characters and similarly validating whether
the password and retype password are same or not.
B.
Back End
1.
Connecting the local host with python environment: We have to connect
to the web with python so as to import the data entered in the webpage
and apply the techniques and algorithms in python language and ﬁnd
plagiarism.
We do so by importing ﬂask from command prompt. We need to have
anaconda python beforehand for this.
2.
Creation of HTML web pages: We have created login and registration
pages using html, jsp. After the user logs in the web application, he/she can
enter the source codes or texts for which he/she needs to check plagiarism.
Our web application is not a language speciﬁc one. So the user can enter
the source code of whichever language he wishes.
3.
Importing packages in python like ﬂask, math, nltk: Flask is used for
developing web applications by python. We connect front end web pages
by this package. Math package is used to for performing mathematical
operations. By using NLTK (Natural Language Toolkit) we can perform
operations like Tokenization, Stemming, Lemmatization, Punctuation,
Character count, word count.

204
S. Yasmeen et al.
4.
Importing the data entered in the webpage to python environment:
Twoﬁeldsofdatawhichweregivenasaninputinthewebpageareimported
to the python environment so as to perform various techniques and apply
algorithms to ﬁnd plagiarism between the data.
5.
Comparing the data using various techniques and algorithms:
• Cosine Similarity:
Cosine similarity is used to measure the similarity. By measuring cosine
angle between texts, we can ﬁnd whether the texts are similar to each
other or not.
• Number of Characters:
Number of characters are counted in the data and compared and
percentage is calculated.
• Number of Times Each Character is repeated:
The percentage is determined by calculating the number of times each
character is replicated, including special characters.
• Number of Times Each Word Is Repeated:
The percentage is determined by calculating the number of times each
character is replicated, including special characters.
• Longest Common Sub Sequence (LCS):
This approach compares the semantic similarity of two codes, one
from the plaintiff and the other from the suspicious code, using the
LCS dynamic programming algorithm, with simple blocks as sequence
components, by attempting more than one direction, and combining the
code similarity scores from LCS to model program semantics similarity.
• N-Grams:
Text N-grams are commonly used in text mining and natural language
processing. They’re essentially a set of co- occurring terms within a
given window, and when computing the n- grams, you usually advance
one word. By employing this process. We can compare n-grams much
better and efﬁciently using the n-gram overlap method than we can
using single word matching.
6.
Comparing the data using various techniques and algorithms: For every
technique percentage of plagiarism is calculated and average is taken from the
ﬁve techniques mentioned above and the ﬁnal output is rendered to the webpage.
7.
Rendering the output i.e., the percentage of plagiarism to the webpage:
After calculating the percentage the output is rendered into the webpage.
5
Experimental Analysis
There are two modules respectively. The ﬁrst one is plagiarism in texts. The appli-
cation was tested using various inputs and displaying the output as the percentage of
plagiarism in the second document as compared to the ﬁrst one.

Plagiarism Detection for Source Codes and Texts
205
The algorithm used here is cosine similarity. It is implemented by calculating the
cosine angle. It is measured using the following formula:
similarity(A, B) =
A · B
∥A∥× ∥B∥=
n
i=1 Ai × Bi
n
i=1 A2
i ×
n
i=1 B2
i
It calculates the similarity by creation of two lists, which are the similar words
in the given texts and ﬁnding the similarity using the above formula. The algorithm
can be used irrespective of the size of the text.
The ﬁrst input is as follows:
The second text input is as follows:
Both the texts were compared using the application and it turned out that the
second text was 84.42% plagiarized when compare to ﬁrst one. The second module
is plagiarism in the source codes. In this module various algorithms are used. Some
of them are as number of characters, number of each character repetition, longest
common subsequence and using nltk, tokenization, stemming, lemmatization and
n-grams are used. The source plagiarism is also test using various inputs.
So, the First input is as follows:
The second input is as follows:

206
S. Yasmeen et al.
Here the two source codes depict the logic to reverse a number. When the two of
the source codes were compare it was found that the second code when compared to
the ﬁrst was 78.54% plagiarized.
Flow-Chart
6
Result and Discussion
Here the algorithm to detect the source code plagiarism and text plagiarism is
combinedly developed using methods like cosine similarity, character count, key
word count, repetition of characters, longest common subsequence of words and N-
grams. We can ﬁnd the amount of plagiarism done in two texts by comparing them
and calculating the amount of percentage using cosine similarity algorithm in given
input texts and for source code the plagiarism check is done by taking the output of
given average of character count including special character, word count and total
number of character count including space. Since, a code consists of special char-
acters and different functions and variables. So, when two texts are given as input
these texts will be compared and after considering all these factors the amount of
plagiarism done in both the texts is calculated and percentage is displayed at the end.

Plagiarism Detection for Source Codes and Texts
207
7
Conclusion
Plagiarism is considered as academic dishonesty. Even though it is not a crime to
copy others works but it can constitute copyright infringement.
In academics it is a serious ethical offense. Plagiarism is not punished by law, but
rather by institutions.
Education institutions can pose penalties or suspensions on authors who plagia-
rized the works and published them without their permission. Plagiarism is described
as taking someone else’s work and passing it off as your own, or copying words or
ideas from someone without permission or license.
Many plagiarism detection tools and algorithms are now available to help limit the
issues. All these were a result of academic research than for commercial purposes.
Here the methodology used is cosine similarity, which is also used in real time to
check for plagiarism in various ﬁelds.
Also,forsourcecodesusingtokenization,stemmingandlemmatizationtheproject
is implemented using python and ﬂask as connection between the server and python
script.
Machine learning has played a vital role in real life for plagiarism detection.
Acknowledgements Our thanks to Mr. K. Ashesh, Associate Professor, for guiding us throughout
the project and teaching us the relevant methodologies and helping us understand the needed
concepts. And thanks to Mr. Vege Hari Kiran (Head of the Department) sir for providing us with
the required facilities and for the guidance.
References
1. Al Jarrah, A., Alsmadi, I., & Za’atreh, Z. Plagiarism detection based on studying correlation
between author, title and content.
2. Saini, A., Bahl, A., Kumari, S., & Singh, M. ∥(2016, January). Plagiarism checker: text mining.
https://doi.org/10.5120/ijca2016907833
3. Kenechukwu, A. (2018, October). Word processing and plagiarism in technical writing.
4. Elhoseny, M., Osman, L., Zaher, M., Shehab, A. A new model for detecting similarity in Arabic
documents, in AG 2018. https://doi.org/10.1007/978-3-319-64861-3_46
5. Higgins, J. R., Lin, F.-C., & Evans, J. P. (2016). Plagiarism in submitted manuscripts: incidence,
characteristics and optimization of screening—case study in a major specialty medical journal.
In Higgins et al. Research integrity and peer review, (Vol. 1, p. 13). https://doi.org/10.1186/
s41073-016-0021-8
6. Verco, K. L., & Wise, M. J. (1996, August). Software for detecting suspected plagiarism:
Comparing structure and attribute—Counting systems. https://doi.org/10.1145/369585.369598
7. Abid, M., Usman, M., & Ashraf, M. W. (2017, November 4). Plagiarism detection process
using data mining techniques. https://doi.org/10.3991/ijes..v5i4.7869
8. Shakhovska, N., & Shvorob, I. (2015, November 12). The Method for detecting plagiarism in
a collection of documents. https://doi.org/10.1109/STC-CSIT.2015.7325453
9. Raﬁeian, S., & Braani Dastjerdi, A. “Plagiarism checker for Persian (PCP) texts using hash-
based tree representative ﬁngerprinting”. https://doi.org/10.5829/idosi.JAIDM.2016.04.02.01

208
S. Yasmeen et al.
10. Patil, S. S. & Yeole, H. (2019, February). “Overview of Plagiarism checkers and Plagiarism
detection tools: A study”.
11. Pupovac, V., Bilic-Zulle, L., & Petrovecki, M. (2008, December). “On academic plagiarism in
Europe. An analytical approach based on four studies”. https://doi.org/10.7238/d.v0i10.507
12. Parwita, W. G. S. & Wijaya, N. S. W. “String matching based plagiarism detection for document
in Bahasa Indonesia”.
13. Zhao, J., Xia, K., Fu, Y., Cui, B. “An AST-based code plagiarism detection algorithm”.
14. Kuo, J.-Y., Cheng, H.-K., & Wang, P.-F. “Program Plagiarism detection with dynamic
structure”.
15. Wan, H., Liu, K., & Gao, X. “Token-based approach for real-time Plagiarism detection in
digital”. Designs.
16. Vandana “A comparative study of Plagiarism detection software”.

Investigation of Kinetic Energy
Harvesting from Human Body Motion
Activities Using Free/Impact
Electromagnetic Generator
Athern Aloysius, M. K. A. Ahamed Khan, Wei Hong Lim,
Manicam Ramaswamy, Sridevi, Deisy, Abdul Qayyum, Chun Kit Ang,
and Kalaiselvi Aramugam
Abstract The main purpose of this research is to harvest energy by free/impact
motion generator (FIMG) with human body motion by using micro-electromagnetic
vibration. To have the best efﬁciency and energy harvesting, harvesters are used to
create energy using insole sensors, Micro-electromagnetic generators and servomo-
tors can be used to obtain the output and it should be tested with the actual human
body movements. Understanding the biomechanics of a human body and the location
of harvesting the energy can be determined by studying the gait of a human body. It
also has an effective performance output with low frequency—large amplitude vibra-
tions. Energy harvested from the movement of human body is converted to electrical
energy by using micro-electromagnetic sensor. The body location this sensor will
be ﬁtted for harvesting the energy are the angle, upper leg, wrist. The energy that is
harvested by doing daily activity is as people intentionally do movement in the body
either by walking, fast walking, and jogging.
Keywords Generator · Qualisys · Harvesting · Voltage booster · Energy ·
Biomechanics
1
Introduction
At this modern and digitalized era, every individual is equipped with smartphones,
electronic gadgets, and also with any wearable gadgets. All these gadgets are inspired
to have long lasting, self-rechargeable, and long power durability. However, all smart
gadgetsandbattery-poweredequipmentarerequiredtobepoweredwithconventional
A. Aloysius · M. K. A. A. Khan (B) · W. H. Lim · M. Ramaswamy · C. K. Ang · K. Aramugam
UCSI University, No. 1 Jalan Menara Gading, UCSI Heights, 56000 Cheras, Malaysia
e-mail: mohamedkhan@ucsiuniversity.edu.my
Sridevi · Deisy
Thiagarajar College of Engineering, Madurai, India
A. Qayyum
UMR CNRS 6285 LabSTICC, ENIB, 29238 Brest, France
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_18
209

210
A. Aloysius et al.
charger that requires time to charged batteries to be used for a certain amount of
time until need to be recharged. For more long-lasting batteries, weight factor and
charging time has to be taken into consideration in order to utilize the particular
gadget or electronic device [1, 2]. As powered gadgets such as power banks are in
general be moderately power eager, a compromise between battery limit and size has
administered the life expectancy, measurements, and abilities for battery gadgets.
2
Literature Review
Studies and research show that computer generation has been progressing very fast
over the last two decades, but it is also stating that the battery technology does
not keep up with the speed that computer technology has been progressing. Even
though energy source has been increased by capacity over the years, it seems to
slow down the progress for portable electronics to gain in a wider market. It is
proven that the computer capabilities have outrun the battery development. In the
matter, more battery appliances could be improved by keeping up with the pace of
the computer technology. For instance, the cost of battery replacement prohibits a
wider deployment of wireless sensor networks. As a result, the demand for energy
sources will be increased. As a solution, energy harvesting can be an option to solve
the demand. The data are investigated in 3 different natural gaits speeds which are
walking with a speed of 80 m/min, fast walking with 110 m/min, and jogging with
160 m/min [3, 4].
The research was including from investigating for harvesting energy by body
heat, respiration, blood pressure, and other activity such as exercising, typing, and
also walking. Therefore, in this project, walking at 3 different speeds is analyzed to
harvest energy from the human body [5].
Besides that, biomechanical motion analysis harvesting from walking at the joints
was examined by Niu et al. The study shows that per cycle will produce an evaluation
of 1 Hz gait cycle in 2 steps of movement made [6]. From the elbow, knee, and ankle
have a potential for energy harvesting. Li et al. has shown that using a knee brace
that harnessed energy only when the limbs decelerated produces an output close to
5 W [7, 8] (Fig. 1).
Qualisys motion capture company offers many features in the software that is
provided by the ﬁrm to be selected according to the purpose of research or study.
In this project, the objective of this project is to harvest kinetic energy from the
movement of human body in different types of motion. The system that will be
acquired to get the data are Qualisys Track Manager, MATLAB, LabVIEW and
the Qualisys trade markers [9, 10]. Qualisys offers the framework to be viewed by
skeleton solving, 3D video overlay, and Automatic Identiﬁcation Markers [11, 12].
As for the Qualisys Track Manager, it integrates with the 3D motion camera whereby
allows research of human motion of biomechanics in real time streaming of rigid
body data or high-quality skeletal data. The system allows users to perform 2D, 3D,
and 6D of capture of data in real time with minimal latency [13, 14] (Fig. 2).

Investigation of Kinetic Energy Harvesting from Human Body …
211
Fig. 1 Energy generated from human body
Fig. 2 Qualisys skeleton
view
Advantages of Qualisys framework software are the data of tracking can be
retrieved in either 2D, 3D, and 6D. Besides that, it has high-speed real time streaming.
The recovery down time is only 4 ms. It can be integrated with markers identiﬁcation
with Qualisys camera detection of the skeleton view.
Human body gait is determined when the speed is mainly dependent on the stride
length or stride frequency. Stride frequency is the leg movement speed while stride
frequency is the total distance covered by a certain number of strides. The frequency
and amplitude attached to the leg can be increased with respect to increasing the
stride length. By increasing the stride length, the speed of walking will eventually
increase, and the amount of harvested energy will be increased too by allowing
more displacement on the harvesters. The values of stride and energy harvested are
proportional to each other. Regarding hip harvesting during walking, the amount
of input vibration is mainly dependent on the number of steps taken. The hip and
the output of the energy harvested are directionally promotional to each other. The
frequency ratio between the hip harvesting is 2:1 at walking speed (Fig. 3).

212
A. Aloysius et al.
Fig. 3 Available power at walking speed of 80 m/min
3
Methodology
Harvesting energy from human motion using electromagnetic generators, the hip
part of the body will be chosen for this experimental study. Once all this sensor and
generators have been ﬁtted on a human body, the study will be done on the treadmill
with 3 different operation speed of 80 m/min walking, 110 m/min fast walking and
160 m/min running or jogging. The results will be seen in the simulation software to
detect and analyze the best place to ﬁx the generator on the human body for maximum
harvesting of energy from all 3 different speeds.
3.1
Storage of Harvested Energy
For storage purposes of the harvested energy, a prototype circuit will be created to
collect, store, and convert the energy harvested. For storage purposes, rechargeable
batteries will be used to store the harvested energy with charging circuits design for
this experiment.
Method of harvesting and achieving the objective of this experiment is by selecting
ten different volunteers with different body mass indexes (BMI) to analyze the hip
gait cycle and gait pattern of a human body during different speeds of motion. BMI
is calculated by the body mass in kilograms over the total height of the volunteers
(Atchka, 2015). The normal BMI of a normal human is ranged within 18.5–25 kg/m2.
Any BMI of individuals above 25–29.99 kg/m2 is categories under the overweight
while individuals 30 kg/m2 and above falls is categories under the obese category.
Figures 4 and 5 represents the different body shapes with respect to the BMI cate-
gories and classes. In order of selecting the volunteers, BMI values with a range
of 18–30 kg/m2 with the aim of covering as much data of the different result with
different range of individuals.

Investigation of Kinetic Energy Harvesting from Human Body …
213
Fig. 4 Obesity and BMI index
The design of the belt is done using 3D modulation software using solid work to
be placed on the hip during any motion is made by a human body. The mechanical
magnetic generator is attached on the belt with coil windings and magnets that has
north and south pole the end of the tube. Voltage is generated when the ﬂux is cut
by the stoppers in the tube. Since the electrical output from the generator requires
rectifying with the circuit for a smoothing capacitor was connected to the generator
to convert its output to DC form. The DC output was then connected to a charging
circuit to make use of the generated energy in charging and powering DC devices.
3.2
The Designed Structure of Biomechanical Hip Energy
Harvester
In the process of designing and building the prototype, one of the most important
points to be taken into consideration is raising the efﬁciency of harvesting the energy
from the Mechanical design that is comfortable to be worn in any circumstances and
light in weight. The design is too then checked with the Qualisys software with the
help of the markers to determine the most effective point of the components to be
placed for harvesting the energy. Previous research has been harvested from the join
of the hip using piezoelectric sensors that are placed below the hip part that works
on pressure to be applied that generates the output of the energy harvested, As for
this experimental research, energy will be harvested using a generator that will be
created from the nature of electromagnetic ﬁeld that is placed at the design of the
belt (Figs. 6 and 7).
The circuit above is designed to increase the voltage harvested using an ideal
switching mosfet with a PID controller to increase the voltage to charge the battery

214
A. Aloysius et al.
Fig. 5 Flowchart of harvesting the energy
Fig. 6 Hip harvesting prototype

Investigation of Kinetic Energy Harvesting from Human Body …
215
Fig. 7 Voltage booster circuit
and store the energy harvested. The voltage input was set to 2 V and the output
of the designed circuit produces about 5 V output. Depending on the output of the
generators, the circuit is able to give a higher output for the storage and the charging
system.
The regulator output voltage can be utilized to charge the battery. The voltage
boost circuit is utilized to support the voltage between 3 and 5 V appropriate
to charge the battery-powered battery 12 V as essential voltage storage. As the
progression numbers are expanded the voltage harvested additionally will increase
(Fig. 8, Table 1).
The prototype of the harvester is designed length of 2.5 cm in length and 8 mm
in diameter. The prototype is placed above the femur bone which is also the upper
thigh bone of the hip area for harvesting. (Femur Shaft, 2018) As the study is done
using the markers with the Qualisys software, the most movement is done by the
hips are both sides of the femur bone head. To maximize energy harvested and most
efﬁcient part to be chosen for harvesting is the part that makes the most movement
done by the biomechanics of a human body (Riemer, 2011). Integrating the Qualisys
software using the markers placed all around the hip, the most strength of stress is
also resulting on the femur bone head which will be the best place for harvesting the
energy from the hip circumference (Fig. 9).
4
Results and Discussion
4.1
Hip Joint Gait Cycle
The result collected by Qualisys motion camera system from all the volunteers is
subject to different speeds performing the activity with different angular motions

216
A. Aloysius et al.
Fig. 8 Harvester electromagnetic concept
Table 1 Model parameter
and measurement
Parameter
Value
Unit
Housing length
21
mm
Magnet tube length
20
mm
Coil length
5
mm
Magnet length
13.5
mm
Moving mass M1
1.55
g
Moving mass M1
0.53
g
Moving mass SMH
1.53
g
Volume of SMH
0.835
cm3
Volume of CMH
0.893
cm3
and the velocity of the subject moving. The gait pattern on the hip was collected in
both situations where the subject was performing the motion and stationery while
wearing the harvester attached to the volunteer (Fig. 10).
4.2
Positioning the Angle of Harvester
In this experiment, the harvester is a coil magnet that creates electromagnetic force
when the magnet moves freely up and downwards. A study is done on the linear

Investigation of Kinetic Energy Harvesting from Human Body …
217
Fig. 9 Femur bone location for harvesting
Fig. 10 Average hip joint angle gait cycle
displacement and the angle of the most output of the harvested energy. Human
walking gait is performed with different speeds to get the best angle of the harvester
to be placed.
Experimental results show that the best angle to be placed by the generators is
within 30°–45° for the magnet to move freely inside the design prototype. When
the magnet is placed at 90° upwards, there is no generation at slow walk and very
minimum generation at fast walk or running. Therefore, the position of the best
harvesting degree is obtained within 30°–45° (Fig. 11).

218
A. Aloysius et al.
Fig. 11 Position of
electromagnetic generator
4.3
Hip Joint Gait Harvesting at Walking Speed 80 M/Min
Figure 12 shows the linear displacement result of linear velocity and BMI in respect
to males and females. The angular velocity is found by dividing the values between
the maximum and minimum of the linear displacement between the range of every
cycle of step and motion made during harvesting. The output values upon harvesting
are then tabulated and represented in an excel format as showing in Figure 13. The
graph too shows that the velocity of a person with lowest BMI has the highest velocity
produced compared to the highest BMI value. The linear velocity produced by males
andfemaleswithalmostasimilarBMIproducessimilaroutputofthevelocity(Fig.14
and Tables 2, 3, 4).
Fig. 12 Graph output at speed of 80 m/min

Investigation of Kinetic Energy Harvesting from Human Body …
219
1.82 1.93 2.46 2.61 2.1 
2.8 2.24 2.1 1.64 2.27 
3.5 
3.4 
3 
2.9 
3.4 
2.7 
3.2 
3.5 
4 
3 
1
2
3
4
5
6
7
8
9
10
BMI(x10)
voltage output(V)
Fig. 13 Graph output at speed of 110 m/min
1.82 1.93 2.45 2.1 2.8 2.8 2.24 2.1 1.64 2.27 
4 
4.2 3.5 3.5 
4 
3.5 3.8 4.1 4.3 3.6 
1
2
3
4
5
6
7
8
9
10
11
BMI
Voltage Output
Fig. 14 Graph output at speed of harvesting 160 m/min
Table 2 Harvesting at speed 80 m/min
Subject
Age
Gender
BMI
Linear velocity (m/m)
Voltage generated (V)
1
25
M
18.2
62
3.20
2
23
M
19.3
48
3.10
3
21
M
24.55
51
2.60
4
24
M
26.1
36
2.50
5
22
M
21
52
3.00
6
21
F
28
35
2.30
7
20
F
22.4
48
2.80
8
23
F
21
47
3.00
9
27
F
16.4
65
3.50
10
21
F
22.68
48
2.80
5
Conclusion
In conclusion, the hip energy harvesting output in creating the gait pattern of the hip
is more linear and smoother as the speed of motion is increased. The design of the
harvester can be worn at any circumstances for harvesting. The harvesting prototype

220
A. Aloysius et al.
Table 3 Harvesting at speed 110 m/min
Subject
Age
Gender
BMI
Linear velocity (m/m)
Voltage generated (V)
1
25
M
18.2
45
3.50
2
23
M
19.3
34
3.40
3
21
M
24.55
38
3.00
4
24
M
26.1
40
2.90
5
22
M
21
25
3.40
6
21
F
28
40
2.70
7
20
F
22.4
30
3.20
8
23
F
21
39
3.50
9
27
F
16.4
51
4.00
10
21
F
22.68
39
3.00
Table 4 Harvesting at speed 160 m/min
Subject
Age
Gender
BMI
Linear velocity (m/m)
Voltage generated (V)
1
25
M
18.2
49
4
2
23
M
19.3
34
4.2
3
21
M
24.55
37.5
3.5
4
24
M
26.1
27.9
3.5
5
22
M
21
40.5
4
6
21
F
28
27
3.5
7
20
F
22.4
37.5
3.8
8
23
F
21
37.7
4.1
9
27
F
16.4
50
4.3
10
21
F
22.68
39
3.6
has experimented with 3 different speeds of motion of 8, 110, and 160 m/min with
same gradient of pavement. In the result section, it is seen that the voltage of the most
harvested is by the most emf produced by the generated in proportion to the highest
speed of motion. The generator tends to boost up and store the harvested energy at
a faster rate of 160 m/min.
Besides that, the BMI factor also is considered for harvesting energy. The lower
BMI tends to give a better output compared to the higher BMI. The duration of
motion by the human also contributed to the amount of energy harvested. Lastly,
the linear velocity is calculated by the movement of the magnet inside the tube. The
velocity is also proportional to the hip gait harvesting where the linear velocity will
create more emf and more voltage in a prescribed time.
Acknowledgments I would like to express my gratitude to the supervisor, Dr. Mohamed Khan
Afthab Ahamed Khan, and UCSI University, for the continuous support, guidance, and comments
throughout the time span of this project.

Investigation of Kinetic Energy Harvesting from Human Body …
221
References
1. tchka. (2015, January 15). Size and prejudice. Retrieved from Fierce Fatties: https://ﬁercefat
ties.wordpress.com/2015/01/23/size-and-prejudice/
2. Choi, Y.-M. (2017, July 12). Energies. Retrieved from Wearable Biomechanical Energy: www.
mdpi.com
3. Dai, D. (2014). Hip-mounted electromagnetic generator to harvest energy from human motion.
Retrieved from HEP frontier online: https://academic.hep.com.cn/ﬁe/CN/https://doi.org/10.
1007/s11708-014-0301-2
4. Femur Shaft. (2018, May 1). Retrieved from Orthoinfo: https://orthoinfo.aaos.org/en/diseases--
conditions/femur-shaft-fractures-broken-thighbone/
5. Nedunchalian, I., Elamvazuthi, N., Parasuraman, S., Ahamed Khan, M.K.A. (2017, September
19–21). Biomechanical energy harvesting from human lower extremity gait: A comparative
analysis. IEEE ROMA2017. IEEE Xplorer, Scopus indexed. https://doi.org/10.1109/ROMA.
2017.8231741
6. Gupta, P. (2019, April 3). How does a MOSFET work? Retrieved from Learn Engineering:
https://learnengineering.org/how-does-a-mosfet-work.html
7. Peterson, I. (2021). Qualisis. Retrieved from Qualisys Track Manager (QTM).
8. Lange, H. E. (2020, October 22). IOP science. Retrieved from A piezoelectric energy harvesting
concept for an energy-autonomous instrumented total hip replacement: https://iopscience.iop.
org/article/https://doi.org/10.1088/1361-665X/abba6e
9. Houng, H.O.C., Sarah, S., Parasuraman, S., Ahamed Khan, M.K.A., Elamvazhuthi. (2013).
International symposium on medical and rehabilitation robotics and instrumentation,
December 2–4. ‘Energy harvesting from human locomotion: Gait analysis, design and state of
art. (2014). Published in Procedia Computer Science, Elsevier, 42, 327–335.
10. Hesmondjeet Oon Chee Houng, Dr. Parasuraman, M.K.A.Ahamed khan (2013, December 13).
IEEE conference INDICON, IIT Bombay India, paper titled ‘Energy harvesting from human
locomotion ‘indexed in IEEE proceedings (pp. 1–6). IEEE Conference publications. https://
doi.org/10.1109/INDCON
11. Lin, J. H. (2015, May 15). Researchgate. Retrieved from Accuracy of the Microsoft KinectTM
for measuring gait parameters during treadmill walking: https://www.researchgate.net/public
ation/276299527_Accuracy_of_the_Microsoft_KinectTM_for_measuring_gait_parameters_
during_treadmill_walking
12. Liu, Z. (2020, December 23). Overview of human walking induced energy harvesting tech-
nologies and its possibility for walking robotics. Retrieved from energies: https://www.mdpi.
com/1996-1073/13/1/86/htm
13. Mars. (2020). World’s ﬁrst fully integrated wireless pressure sensor insole. Retrieved from
MARsystem: https://www.mar-systems.co.uk/
14. Pancharoen, K. (2017, October). Hip implant energy harvester (p. 219). Retrieved from Hip
Implant Energy Harvester.

Automated Determination of Critical
Temperature
Abhishek Deshpande, Jatin Pardhi, and Gokul Bisen
Abstract We used a dataset consisting of 77 physical and chemical properties of
18,974 chemical compounds to develop 3 machine learning models using the algo-
rithms Multiple Linear Regression, Lasso Regression, and SVM regression respec-
tively for prediction of critical temperatures of chemical compounds. We achieved
an accuracy of 84.61% for models using Multiple Linear Regression, and Lasso
Regression algorithms and 63.47% for model using SVM Regression. Based on
these models we predicted the temperature at which a chemical compound will be
superconducting. We also discussed the major properties that determine the critical
temperature of a chemical compound.
Keywords Machine learning · Multiple linear regression · Lasso regression ·
SVM regression · Prediction · Critical temperature · Accuracy · Superconducting
1
Introduction
Superconductors are substances which exhibit zero electrical resistance at very low
temperatures (close to absolute zero). Most of the superconductors are metals and
metalloids. Mercury was the ﬁrst metal observed to show superconducting property,
discovered in 1911 by “Dutch physicist Heike Kamerlingh Onnes” here mercury
was cooled down to 4 K. After the discovery of mercury this ﬁeld got attention from
scientists all over the world and later many other different forms of superconductor
were discovered which includes Type 2 superconductors discovered in the 1930s. But
in 1986 Johannes Bednorz and Karl Muller made a discovery which brought a revolu-
tionary change in the ﬁeld of superconductors. Before this theory, the understanding
was that when a certain material is cooled near absolute zero it starts behaving as
a superconductor. But Karl Muller and Johannes Bednorz found that certain mate-
rials started behaving as superconductors at approx 40 ◦Kwhen they are mixed with
oxides (copper, lanthanum, and barium). Superconductors have the property to allow
ﬂow of current through it without any resistance, this type of current ﬂowing through
A. Deshpande (B) · J. Pardhi · G. Bisen
Visvesvaraya National Institute of Technology, Nagpur, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_19
223

224
A. Deshpande et al.
the conductor is known as super current. The temperature below which a conductor
starts behaving as a superconductor is known as critical temperature. The critical
temperature is represented by T c. It is not possible to convert all materials into
superconductors, but those materials that get properties of superconductors have
their own respective value of critical temperature T c [1].
Superconductors are divided into two types based on their room temperature
behavior:
Type I superconductor:
Type I superconductors include material which behave as conductors at room temper-
ature.Whenthismaterialgetscooledbelowcriticaltemperaturethemolecularmotion
inside the material gets reduced and the ﬂow of current can move unhindered.
Type 2 superconductor:
This category includes materials which are not particularly good conductors at room
temperature. This material also gets superconductive properties after cooling below
a certain critical temperature but in this type, the change is the transition to a super-
conductor state is more gradual than the ﬁrst type. Type 2 superconductors mostly
contain metals and alloys [1].
1.1
Critical Temperature
The temperature below which any material gains the superconductive properties that
temperature is known as critical temperature. Critical temperature is represented by
the T c. Different materials have their own different critical temperatures. Supercon-
ductors have a critical temperature range from 20 K to below 1 K. Example-Solid
mercury has a critical temperature at 4.2 K. The highest critical temperature found for
conventional superconductors till 2015 is 203 K for H2S. At low temperature (around
critical temperature) the energy of interaction between electrons becomes very weak
and the pair between them can be easily broken with the help of thermal energy. This
is the reason why materials behave as superconductors at low temperatures [2].
1.2
Machine Learning Algorithms
1.2.1
Linear Regression
Linear Regression algorithm gives us the linear relation between two variables by
applying the linear equation to the given/observed data. This Algorithm gives us the
relation between two variables (one supposed to be independent and other dependent
variable). Example: The weight of any human being is linearly proportional to its
height. If height increases the weight increases. This is how we can predict one’s

Automated Determination of Critical Temperature
225
weight from their given height using linear regression. It is not necessary that one
variable has to be dependent on another variable, but there has to be some relationship
between two variables. We use scatter plot to imply the strength relation between
variables. If there is no relation between two variables then the scatter plot will not
show any increasing/decreasing pattern [3].
The linear regression equation is of form:
Y = a + bX
From the above equation, we can see X is independent of any constraint (inde-
pendent variable), whereas Y is dependent on X so Y is a dependent variable. X is
plotted along X-axis and Y is plotted along the Y-axis. b is slope and a is intercept.
a = [(y)

x2
−(x)(xy)]
[n(x2) −(x)2]
(1)
b = [n(xy) −(x)(y)]
[n(x2) −(x2)]
(2)
Types of Linear Regression:
Simple Linear Regression:
In simple linear regression, we ﬁnd relation between 1 independent variable and
corresponding dependent variable.
Y = β0 + β1X + ε
Here Y is a dependent variable, β0 and β1 are unknown constants which represent
Y intercept and slope respectively and ε (Epsilon) represent error term (Fig. 1).
Example: We can predict the marks of students based on their hours of study. Here,
the hours of study are independent variable and marks are dependent variables. Here
we can use a simple regression model to predict the marks of a student.
Multiple Linear Regression:
In Multiple linear regression, we try to ﬁnd the relation between two or more
independent variables (Input) and one dependent variable (Output).
1.2.2
LASSO Regression
LASSO stands for “Least Absolute Shrinkage and Selection Operator”. LASSO is
another variation of linear regression; it is a shrinkage and selection method for linear
regression. We use LASSO regression when there are a large number of predictor

226
A. Deshpande et al.
Fig. 1 Simple linear regression
variables. The selection and shrinkage approach reduces the value of incorrectly
estimated coefﬁcients [4].
1.2.3
SVM Regression
SVM stands for Support Vector Machine. It is used for classiﬁcation as well as
for regression. SVM is mainly preferred in classiﬁcation problems. This algorithm
creates a hyperplane/line which separates data into classes and reduces the error
probability. SVM works well in unstructured data. Example. “Text and data”. This
regression model is based on the geometric properties of given data [3].
1.3
Dataset
The dataset is an Excel ﬁle that consists of 76 physical and chemical properties
of 18,974 chemical compounds along with their respective critical temperatures in
the 77th column. The penultimate and the ultimate column consists of the molec-
ular formula of the compounds and their respective critical temperatures. Thermal
conductivity, atomic radius, valence, electron afﬁnity, and atomic mass are the
properties that contribute far more to the model’s precision.
The below histogram shows classiﬁcation of chemical compounds in the dataset
based on the range of Critical temperature (Fig. 2).

Automated Determination of Critical Temperature
227
Fig. 2 Classiﬁcation of compounds on the basis of critical temperature range
2
Literature Survey
We did extensive research and survey about critical temperature and the different
methods that have been followed for its quick and simulated determination. To gain
some preliminary to advanced knowledge regarding critical temperature we referred
to Fedors et al. [5], Ginzberg et al. [6], Tu et al. [7] reading these we got an idea
regarding the factors or properties responsible to determine the critical temperature
of a material. This helped us in involving the relevant features in the dataset that we
used. Further, we moved towards understanding of the Machine learning and Deep
Learning approaches that have been followed by earlier researchers in determination
of critical temperature. Le et al. [8] followed a neural network approach for devel-
oping such a model. Although they achieved decent enough results with this, they
used a dataset with less features than of ours as the application of neural networks on
a large dataset requires a highly sophisticated system that can handle the load. Stanev
et al. [9] and Xie et al. [10] deployed machine learning algorithms for this task and
used datasets with a large number of data entities and a large number of features but
achieved a high RMSE and MSE for their models. Horide et al. [11] developed a
machinelearningsearchmodeltodeterminematerialswithahighcriticaltemperature
by including only the data for those materials which are suspected to have a critical
temperature. De Gruyter et al. [12] presented an interesting approach to predict crit-
ical temperature of iron doped superconductors using machine learning algorithms.
Our model is most inﬂuenced by the work of Hamidieh et al. [13] and Roter et al.
[14]. The machine learning models developed by both of these researchers use the
same dataset that includes 35 most relevant features that are suspected to inﬂuence
the critical temperature of a material. Li et al. [15] used a highly accurate but compli-
cated approach by using Atomic vectors and Deep Learning for the determination
of critical temperature. His model achieved high accuracy as he used a sophisticated
and expensive system for implementation.

228
A. Deshpande et al.
From the above discussion, we can see that most of the researchers have used
smaller datasets in order to achieve high accuracy and those who have used a larger
dataset have taken into account less features or have used Deep learning approach
which can only be implemented in certain sophisticated systems. Hence, we have
developed a method for a cost-effective determination of critical temperature by using
a large dataset (18,974 chemical compounds, 76 properties) without compromising
on accuracy.
3
Methodology
3.1
Algorithm Followed for Developing the Models
1.
Import libraries
numpy, pandas, matplotlib, sklearn
2.
Import and read the csv dataset.
3.
Display the dataset and check for null values, duplicate values, and inconsistent
data.
4.
If such data is found, eliminate or replace the data.
5.
Deﬁne features to X (independent variable) and Y (dependent variable).
6.
Split the data into train and test sets.
7.
Instantiate the Regression object or deﬁne the model.
LinearRegression()
Lasso(Normalize = True)
SVR()
1.
Train the model.
2.
Predict the critical temperature for testing data.
3.
Find Accuracy and error for the model.
3.2
Data Preprocessing
The dataset was preprocessed before being used in the Machine Learning models.
The data preprocessing involved the following steps:
1.
Eliminating or replacing the missing values
2.
Eliminating or replacing the duplicate values
3.
Replacing the inconsistent data
4.
Removing the irrelevant data ﬁelds.

Automated Determination of Critical Temperature
229
3.3
Working of the Models
3.3.1
Multiple Linear Regression
The Multiple Linear Regression algorithm develops a relation between the indepen-
dent variables, i.e., the 76 physical and chemical properties and the Critical Temper-
ature of the chemical compound by ﬁtting the 76 independent variables in the linear
equation:
Y = β0 + β1x1 + β2x2 + · · · + β76x76 + ϵ
(3)
where, β0= intercept
β1,β2, …, β76= coefﬁcients
β1x1, β2x2, …, β76x76= independent variables
ε= Error.
The model then takes the best combination of the independent variables that
inﬂuence the dependent variable the most and forms a hyperplane using the linear
equation. A hyperplane is a best-ﬁt line for data in three or more dimensions. The
Critical temperature for the rest of the data is then obtained from the y-coordinates
of the independent variables (×1, ×2, …) on the hyperplane. Figure 3 is a pictorial
representation of the hyperplane with two independent variables and one dependent
variable.
Fig. 3 Hyperplane with two
independent variables and
one dependent variable

230
A. Deshpande et al.
3.3.2
Lasso Regression
Lasso Regression algorithm is a mere extension of Linear Regression with some
normalization in order to enhance the prediction accuracy of the model. Just like
Multiple Linear Regression algorithm, Lasso Regression algorithm also develops a
relation between the independent variables, i.e., the 76 physical and chemical prop-
erties and the Critical Temperature of the chemical compound. The only thing that
it does different from Multiple Linear Regression algorithm is it uses the shrinkage
technique, i.e., in our case graphically, it brings the mappings of Critical Tempera-
ture w.r.t the independent variables (76 physical and chemical properties) closer and
towards the center in order to develop such a hyperplane that gives more precise and
accurate predictions for the test data. It uses the following mathematical equation to
implement this technique:
Least - Squares + λ ∗(Sum of the absolute value of the magnitude of coefﬁcients)
n
i=1(yi −

j
xi jβ j)
2 + λ
p
j=1
β j

(4)
where,
• λ—amount of shrinkage.
• If λ is equal to 0 all independent variables are taken into account and the Lasso
Regression model becomes equivalent to a linear regression model where only
the residual sum of squares is taken into account to build the model.
• If λ = ∞no variable is taken into account, i.e., it eliminates more and more
variables.
• λ ↑, bias ↑.
• λ ↓, variance ↑.
We have used Lasso Regression as our dataset consists of a large number of
features. Lasso Regression technique is best suited for handling such kinds of data
(Fig. 4).
3.3.3
SVM Regression
Support Vector Regression (SVR) algorithm creates a mapping between the prop-
erties of the chemical compounds and their respective Critical Temperatures. SVR
develops a hyperplane such that it contains the maximum mappings. The next thing
that SVR algorithm does is it creates decision boundaries at a distance of ‘ε’ from
the hyperplane.
For, e.g., If the equation of hyperplane is, Ax + b = 0.
Then, equation of decision boundaries: Ax + b = ε, Ax + b = −ε.

Automated Determination of Critical Temperature
231
Fig. 4 Graphical representation of derivation of least-squares
The value of ‘ε’ is chosen by the algorithm such that all the mappings that are
closest to the hyperplane fall inside the decision boundary. Further, the algorithm uses
only those mappings/points in developing the ﬁnal regression plane which falls inside
the decision boundaries [10]. This plane is then used for the prediction of Critical
temperatures of the test data. The mappings that fall inside decision boundaries are
also called Support vectors (Fig. 5).
Fig. 5 Graphical representation of SVR

232
A. Deshpande et al.
Although after we got the results, we realized that the properties of the chemical
compounds and the critical temperature have a linear relationship we didn’t know
that initially. Hence, we used SVR as SVR also works well for non-linear regression.
3.4
Model Training
Model Training is deﬁned as the process to train a Machine Learning algorithm on a
dataset. The sample output data and the related sets of input data that have an effect
on the output make up the dataset. The training model is used to process the input
data through the algorithm in order to compare the processed output to the sample
output. The model is modiﬁed based on the results of this correlation. The model’s
accuracy majorly depends on the accuracy of the dataset. We trained and tested the
models in the Google Colab environment. We used 80% of the data from the dataset
to train the models. We used this data to train and test 3 models with 3 different
Machine Learning algorithms.
(1)
Multiple Linear Regression
(2)
Lasso Regression
(3)
SVM (Support Vector Machine) Regression.
3.5
Model Testing
After training the models on 80% data of the dataset they were made to predict the
independent variable (Critical Temperature) for the rest 20% of the data on the basis
of the knowledge that they acquired from training. These predicted values were then
compared with the corresponding values from testing data as a part of the Model
Testing process.
3.6
Model Performance Determination
We used 4 metrics for model performance determination:
1.
Adjusted R-squared
2.
MSE (Mean Squared Error)
3.
RMSE (Root Mean Squared Error)
4.
MAE (Mean Absolute Error).
R-Squared—The proportion of variance in the outcome that is described by the
predictor variables is known as R-squared (R2). The squared correlation between

Automated Determination of Critical Temperature
233
the observed outcome values and the model’s estimated values is referred to as R-
Squared in multiple regression models. The higher the R-squared value, the more
precise the model.
Adjusted R-Squared—Adjusted r-square is a modiﬁed form of r-square whose
value increases if new predictors tend to improve model’s performance and decrease
if new predictors do not improve performance as expected (Figs. 6 and 7).
Mathematically,
ˆyi is the corresponding point for yi on the Regression line.
R-Squared:
R2 = 1 −SSres
SStotal
(5)
Adjusted R-Squared:
R2
adj = 1 −[(1 −R2)(n −1)
n −k −1
]
(6)
k—number of regressors, n—sample size.
Fig. 6 Graph for R-squared
Fig. 7 Adjusted R-squared
graph

234
A. Deshpande et al.
Mean Squared Error—The difference between the actual and predicted values
retrieved by squared the average difference over the data set is given by MSE (Mean
Squared Error).
MSE = 1
N
N
i=1(yi −∩y)2
(7)
∩y= Predicted value of y.
Root Mean Squared Error—The error rate by the square root of Mean Squared
Error is called RMSE (Root Mean Squared Error).
RMSE =
√
MSE
(8)
Mean Absolute Error—The difference between the original and predicted values
extracted by averaging the absolute difference over the data set is represented by
Mean absolute error.
MAE = 1
N
N
i=1|yi −∩y|
(9)
4
Results and Discussion
The following image shows a scatter plot between the Actual critical temperature of
the test data and the Predicted Critical temperature that we obtained using matplotlib
library.
From the Fig. 8 it is clear that although we weren’t able to achieve 100% accuracy
in predicting the Critical Temperatures of chemical compounds, we got most of the
predictions close to the actual values. In the graph, all the points seem to be clustered
around the imaginary x = y line. Thus, our main objective of predicting Critical
Temperatures for chemical compounds was fulﬁlled to a great extent.
To achieve this objective, we made use of 3 Machine Learning algorithms out
of which 2 were the most effective and accurate. The accuracies and Mean Squared
errors for these algorithms are mentioned in the Table 1.
The results in the Table 1 suggest that Multiple Linear Regression and Lasso
Regression algorithms achieved higher accuracy and less error than SVM regression.
Hence, these two algorithms are more suited to handle this type of data.
Although we have achieved a high accuracy using machine learning models, we
had limitations on the usage of the system. We weren’t able to use better and sophis-
ticated systems which could handle bigger datasets and apply even more advanced
algorithms, so this is not a full proof method. Thus, more research needs to be done on
such types of models which are more sophisticated and can be applied on even bigger
datasets in order to obtain even higher accuracy. Future research should concentrate

Automated Determination of Critical Temperature
235
Fig. 8 Scatter plot between the actual critical temperature of the test data and the predicted critical
temperature
Table 1 Accuracies and errors for all the models
No
Machine learning
algorithm used
MSE (mean
squared error)
RMSE (root
mean squared
error)
MAE (mean
absolute error)
Adjusted
R-squared * 100
(Accuracy %)
1
Multiple linear
regression
68.052
8.25
4.41
84.61
2
Lasso regression
68.052
8.25
4.41
84.61
3
SVM (support
vector machine)
regression
101.04
10.05
7.11
63.47
on possible compounds for use as a new superconductor. It would be advantageous
to provide preliminary input to assess the correctness and efﬁciency of alternative
compounds before committing to expensive and time-consuming experiments in the
real world.
5
Conclusion
Material data science, especially superconductor exploration, is still in the initial
phases of machine learning adaptation. While the number of single-use applica-
tions is increasing, more intelligent models are yet to emerge. We developed a new
computational method for estimating the critical temperature of chemical compounds
using a Machine Learning approach in this paper. Our ﬁndings are consistent with
previous critical temperature predictive model research. These preliminary ﬁndings

236
A. Deshpande et al.
show that machine learning algorithms can be used to provide persuasive and useful
evidence for understanding superconductivity physics. This discovery is promising,
and it should be studied further with other advanced predictive models, which could
eventually lead to the discovery of new superconductors in the future.
References
1. https://irds.ieee.org/topics/semiconductor-materials
2. Critical Temperature and Pressure, https://www.chem.purdue.edu/gchelp/liquids/critical.html
3. A blog about data science and machine learning, https://www.datatechnotes.com/2019/01/svr-
example-in-python.html
4. Introduction to Lasso Regression; Statology.
5. Fedors, R. F. (1982). A relationship between chemical structure and the critical temperature.
Chemical Engineering Communications, 16(1–6), 149–151. https://doi.org/10.1080/009864
48208911092
6. Ginzberg, V. L, & Kirzhnits, D. A. High-Temperature superconductivity.
7. Tu, C.-H. (1995). Group-contribution estimation of critical temperature with only chemical
structure. Chemical Engineering Science, 50(22), 3515–3520. ISSN 0009-2509, https://doi.
org/10.1016/0009-2509(95)00191-7.
8. Le, T. D., Noumeir, R., Quach, H. L., Kim, J. H., & Kim, H. M. (2020, June). Critical temper-
ature prediction for a superconductor: A variational bayesian neural network approach. IEEE
Transactions on Applied Superconductivity, 30(4), 1–5, Art no. 8600105. https://doi.org/10.
1109/TASC.2020.2971456.
9. Stanev, V., Oses, C., Kusne, A. G. et al. (2018). Machine learning modeling of supercon-
ducting critical temperature. npj Computing Materials, 4, 29. https://doi.org/10.1038/s41524-
018-0085-8.
10. Xie, S. R., Stewart, G. R., Hamlin, J. J., Hirschfeld, P. J., Hennig, R. G. (2019, November 18).
Functional form of the superconducting critical temperature from machine learning. Physical
Review B, 100, 174513.
11. Matsumoto, K., & Horide, T. (2019). An acceleration search method of higher Tc supercon-
ductors by a machine learning algorithm. Applied Physics Express, 12, 073003.
12. Gruyter, D. (2021, February 19). Predicting doped Fe-based superconductor critical temper-
ature from structural and topological parameters using machine learning. https://doi.org/10.
1515/ijmr-2020-7986
13. Hamidieh, K. (2018). A data-driven statistical model for predicting the critical temperature of
a superconductor. Computational Materials Science, 154, 346–354. ISSN 0927-0256, https://
doi.org/10.1016/j.commatsci.2018.07.052. https://www.sciencedirect.com/science/article/pii/
S0927025618304877
14. Roter, B., & Dordevic, S. V. (2020). Predicting new superconductors and their critical tempera-
tures using machine learning. Physica C: Superconductivity and its Applications, 575, 1353689.
ISSN 0921-4534, https://doi.org/10.1016/j.physc.2020.1353689. https://www.sciencedirect.
com/science/article/pii/S0921453420301374
15. Li, S., Dan, Y., Li, X., Hu, T., Dong, R., Cao, Z., & Hu, J. (2020). Critical temperature prediction
of superconductors based on atomic vectors and deep learning. Symmetry, 12(2), 262. https://
doi.org/10.3390/sym12020262

ANN-based Hybridization Approach
for Detection of Cardiac Disease
N. Shwetha, N. Gangadhar, Mahesh B. Neelagar, and K. C. Shilpa
Abstract Cardiac diseases are one of the high-risk low-detection diseases as they
are lethal as well as silent. It affects the human lives without any earlier symptoms,
by making it more deadly than other types of illnesses. The majority of the world’s
population are unaware that they are suffering from heart disease; hence, it greatly
increases the death rate. Lack of early detection of heart disease is one of the most
signiﬁcant research gaps that needs to be addressed to in the ﬁeld of medical research,
which cannot be done more accurately. Since manual prediction of any sort of heart
disease is hardly accurate, it is highly essential to incorporate a hybrid approach
wherein the automation technology is also leveraged to assist in the accurate detection
of heart disorders. This can be achieved by introducing the hybrid neural network
genetic algorithm (HNNGA). This novel approach aims to develop and incorporate
a support system for medical practitioners. Furthermore, this paper describes the
utilization of the proposed system to predict a heart disease. Also, this is purely
based on neural network architecture and genetic algorithm along with the learning
algorithm.
Keywords Neural network architecture · Genetic algorithm · Heart disease
prediction · Hybrid approach
N. Shwetha (B)
Department of ECE, Dr. Ambedkar Institute of Technology, Bangalore, Karnataka 560056, India
N. Gangadhar
Department of ME, Dr. Ambedkar Institute of Technology, Bangalore, Karnataka 560056, India
M. B. Neelagar
Department of VLSI Design and Embedded Systems, VTU, Belagavi, Karnataka 590018, India
K. C. Shilpa
Department of ECE, Dr. Ambedkar Institute of Technology, Bangalore, Karnataka 560056, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_20
237

238
N. Shwetha et al.
1
Introduction
Based on the information delivered by the World Health Organization (WHO), heart
disease and stroke kill 17 million people each year, making them the leading cause
of mortality and disability in the world [1]. “No matter what propels there are in
high-innovation medication, the basic message is that any signiﬁcant decrease in
passing and inability from coronary illness and stroke will come principally from
prevention, not simply ﬁx. We accept that early cardiovascular physical assessment
(screening) will turn into a central component of any avoidance program. Dr. Judith
Mackay, co-creator of the WHO Atlas of Coronary Illness and Stroke [1, 2], made
the following statement. The phrase “coronary illness” encompasses a wide range
of conditions that affect the human heart. In the year 2007, coronary illness was
one of the signiﬁcant reasons for the loss of human lives in the US, Canada, Wales,
and England, which kills one individual for every 34 s in the US. Coronary illness,
cardiovascular ailment, and cardiomyopathy are a portion of the classiﬁcation of
heart sicknesses. The expression “cardiovascular infection” combines a wide scope
of conditions, which inﬂuence the heart and the related veins and the way, where the
blood is being drawn off and circled, however, out the human body. All sort so of
cardiovascular ailment (CVD) brings about extreme disease, incapacity, and passing.
The development inside the heart conduits, narrowing them, and coronary corridors
brings about the diminished blood and oxygen ﬂexibly to the heart prompting the
coronary illness. Myocardial areas of dead tissue and angina pectoris broadly known
as a cardiovascular failures and chest torment separately are guzzled in the CHD. A
blood coagulation inside the coronary course, bringing about the blockage, brings
about an unexpected respiratory failure. At the point when the blood got by the heart
is deﬁcient, it ascends to chest torments [3–7].
Figure 1 shows the input and output layers describing the artiﬁcial neural network
where the input layer is a passive node, whereas the hidden and output layers are
Input Side                                      Hidden Side                       Output Side
Fig. 1 Architecture of neural networks

ANN-based Hybridization Approach for Detection of Cardiac Disease
239
active nodes. The training of the neural network is done by means of error correction
learning. Purpose of learning is modiﬁcation of weights so to ensure minimum errors.
1.1
Feedforward Networks (FFN)
FFANNs conﬁnes the signs to go in a unidirectional one manner only, i.e., from
contribution to yield. There are no input (circles), for example, the yield of any layer
does not inﬂuence that equivalent layer. Feedforward ANNs will in general be direct
systems which partner contributions with output. They are widely used to perceive
patters. This sort of association on occasion alluded to as base up or top-down way
to deal with structure.
1.2
Feedback Networks
Feedback networks have signals going in either directions by joining loops in the
system. Input systems are incredible and can be amazingly confounded. These
systems are in unique state; their “states” are ceaselessly changing until they acquire
a harmony. They stay at the balance point until the information changes and another
harmony should be found [8].
1.3
ANN Learning
Learningisanongoingcyclewhereintheframeworkreactingtotheecologicalbound-
aries rearranges without anyone else so that it becomes in functioning in the world.
ANN learning can be considered as an exceptional instance of machine learning.
Slope descent-type rules are generally utilized by a large portion of the scientists
and application clients, and it comes to the minima of hyper surface characterized
by error function and genetic calculations are likewise used to prepare ANN.
2
Literature Review
Different papers in the programmed choice framework area were contemplated. The
authors examine the neural network (NN) that has been working on information
ranging from a self-applied poll to confer a choice framework intended to search
out high-danger people in a signiﬁcant population. Multi-layered perception (MLP)
was prepared to connect with different peril variables to recognize coronary illness
(CI). It describes an alteration of weight esteems to the design of the neural system

240
N. Shwetha et al.
wherein an additional layer of neurons is included at the information and allocated
a less error-giving loads. It presents potential understanding about the loads of these
neurons and shows how they can be utilized as a determination measures for which
inquiries to use as data sources. The strategy is looked at opposite to other measurable
techniques that will assist it with understanding the upsides of current methodology.
We proceed to exhibit the framework’s capacity for identifying both the suggestive
and asymptomatic patients by utilizing the neural system preparing techniques [1].
The authors of [2] discusses, about the CVD, are the lead reason for death in
today’s industrialized world. In today’s world, the available resources to extemporize
the analysis and the treatment are profoundly developed. The one strategy used to
observe is the heart rate variability records from the electrocardiogram for more
than 24 h. These HRV values lie in between the two R peak of continuous QRS
and RR intervals. There are versatile ﬁlters used to improve the clamor signals from
the solid case from the skin surface. It is additionally named as artifacts. At last,
power spectrum density (PSD) is registered, sifting the values in the three groups
that portray are very low frequencies (VLF), HRV are high frequencies (HF) and low
frequencies (LF). The model incorporates inﬂuences from the recurring space and
the time.
The authors of [9] talk about the utilization of consolidated neural systems with
fuzzy logic frameworks, and this hybrid technique is quite unpredictable to compre-
hend. This permits the evaluation and portrayal of HRV and identiﬁes the patients
with respect to low and high probability who are going through a heart issue. The
preparation method, its parameters, and details of the application have been devel-
oped to understand about the cause of the cardiovascular issue. The outcomes propose
that this sort of hybrid network is reasonable for the recognizable proof of patients
with variations of high to low cardiovascular risk. The re-enactment condition can be
measured as an integral asset for the improvement strategies in biomedical designing
for the cardiology [9].
The grouping framework for cardiovascular arrhythmia forms the standard 12
lead ECG recording data using a generalized feedforward neural network classi-
ﬁer. As seen, the GFNN classiﬁer is prepared, by utilizing static back proliferation
calculation to order arrhythmia cases into ordinary and strange classes where it is
considered as risk-free arrangement. In this examination, basically, keen on creating
high-certain arrhythmia arrangement results to be material in symptomatic-choice
helping systems. In arrhythmia investigation, it is unavoidable that some trait estima-
tions of an individual would be absent. Consequently, these missing qualities were
supplanted by the nearest section estimation of the class. This method is smarter
to keep away from the human mistake; systems models are prepared and tried for
UCI ECG arrhythmia informational collection dependent on the data sources. The
information is gathered from all out 452 patient cases, and the outcomes shown in
this paper are that up to 82.35% testing order precision can be obtained [10].
Further, examining about a novel technique called as reference model method-
ology of neural systems has been proposed. The investigation of the new method-
ology is to contemplate a neural system model regarding other related models, so

ANN-based Hybridization Approach for Detection of Cardiac Disease
241
that different approaches can be aggressively utilized for the improved methodology
of structure requirements [8].
The authors of [11, 12] present another neural system prototype, which is called
constrained smallest-norm neural network (CSII NN), to know the basis pursuit
(BP)[I] 121 [9]. Joining the high goal with the quick usage, the CSII NN-BP will be
extremely encouraging for online time-recurrence investigation of different sorts of
non-ﬁxed signs including clinical information, for example, ECG, EEG, and EGG,
and so forth., with high caliber.
The conversation about the design of intelligent system by using gradient descent
algorithm, here, soft computing tools like artiﬁcial neural network (ANN) and resort
to utilize conjugate gradient (CG) technique serves to train the ANN. The study offers
CG-based ANN preparing calculation utilized in plan of an intelligent framework.
To perform better, a large portion of the current variations of CG is applied for the
said purpose [13].
The investigation about artiﬁcial neural network is difﬁcult to pick the best calcu-
lation for a given assignment or dataset, despite the fact that huge numbers of the
calculations are accessible in usage of existing apparatuses. In this work, the picked
set of calculations are tried with a couple of dataset values and tried commonly for
various beginning arrangements of loads and various quantities of hidden neurons
while saving one concealed layer for all the feedforward artiﬁcial neural networks
[14].
The further conversation is tied in with learning. Notwithstanding, a signiﬁcant
issue in this ﬁeld is that typically no target esteems is accessible to ﬁt an element
learningcapacitytoartiﬁcialneuralnetworksisanadequatelyadaptableapparatusfor
work estimate to have the option to maintain a strategic distance from this issue. It was
exhibited how the error capacity of an ANN could be altered, so it worked exclusively
with target rather than target esteems. We determine the balanced principles for
back and forth through systems with arbitrary department and incorporate viable
contemplation that must be considered to apply contrast-based adapting system. On
each of the three benchmark datasets, we use straight SVMs prepared on naturally
learned ANN features outperform RBF part SVMs prepared on the raw information.
This can be accomplished in an element space with up to just a tenth of measurements
of the quantity of unique information measurements. We ﬁnish up our work with two
examinations on separation-based ANN preparing in two further ﬁelds: information
perception and exception detection [12].
3
Problem Formulation
Choice emotionally supportive networks are accessible for foreseeing the presence
or non-appearance of a heart alignment. Poor diagnosis conclusion and poor clin-
ical choices prompt death. Likewise, all clinicians are not similarly reasonable in
foreseeing the coronary illness in which determination happens to be an imperative
job. On account of coronary illness, “time is valuable,” legitimate analysis at the

242
N. Shwetha et al.
opportune time maintains a strategic distance from mortality. The framework helps
the cardiologist to conclude up to a choice, while people may make mistake complex
data. Intelligent system is quickly assuming a pivotal job in medication and medical
services area for all intents and improvises the quality of the sensitive patient care and
to extemporize the nature of the delicate patient health. The requirement for a target
technique for assessing such frameworks is generally recognized. In the documented
of medication and medical services, where well-being is crucial, this is signiﬁcant if
procedures, for example, clinical master frameworks and neural frameworks are to
be generally accepted by all in clinical practice.
4
Proposed System
Analysisofcoronaryillnessassumesasigniﬁcantjobincertiﬁablewherethemajority
of individuals of both genders of any age are inﬂuenced a great deal. Coronary illness
would make more serious threat to individuals who should be analyzed more efﬁ-
ciently. It is judicious to analyze the coronary illness right off the bat so as to guarantee
early treatment so as to evade further well-being complexities. The principle quality
of this speciﬁc examination work is to fuse the framework which can foresee the
heart issues in a mechanized manner at the soonest with expanded precision. This
is accomplished in this examination work by presenting the hybrid neural network
genetic algorithm (HNNGA) which can foresee the coronary illness event quickly
and precisely [15]. The performance of proposed strategy regarding exact analysis of
coronary illness is achieved by improving the underlying weight updating of neural
system which is ﬁnished by presenting the hereditary calculation. The hereditary
calculation can pick the best weight regards for the concealed layers of neural frame-
work. The taking care of stream of the proposed research procedure is shown up in
the going with Fig. 2. The acquired dataset is ﬁrst normalized before applying the
Fig. 2 Proposed model

ANN-based Hybridization Approach for Detection of Cardiac Disease
243
calculation. By then, arranged hybrid neural network genetic algorithm (HNNGA)
is applied to the normalized dataset. The display of the proposed computation is
dissected.
5
Algorithms
5.1
Artiﬁcial Neural Network (ANN)
The artiﬁcial neural systems are computational standards dependent on numerical
models that, dissimilar to conventional ﬁguring, have a structure and activity that
takes after that of the well-evolved creature cerebrum. Artiﬁcial neural network or
neural systems are also called as the connectionist frameworks or equal conveyed
frameworks or multipurpose frameworks; subsequently, they are made by an arrange-
ment out of interconnected preparing components that work in equal. Neural systems
are being useful to expand huge number of real-time issues. Their essential preferred
position is that they can take care of issues that are excessively perplexing for regular
innovations; issues that do not have an algorithmic arrangement or for which an
algorithmic arrangement are too mind boggling to be in any way characterized. In
algorithmic methodology, the system follows a portion of computation so as to tackle
a problem. But if the speciﬁc advances that the system needs to follow are known,
the system cannot take care of the subject. That restricts the perilous thinking ability
of regular system to issues that are of now comprehended, and the system frame-
work administrator realizes how to illuminate. By and large, neural systems are
appropriate for issues that individuals are acceptable at understanding, yet for which
computers for the most part are deﬁnitely not. These issues incorporate example
acknowledgment and determining—which requires the acknowledgment of patterns
in information. In the event of neural system, for loose sources of information, the
system can recover the ideal result or the information that is nearest to the ideal
information. Thinking about the effectiveness of neural systems in numerous places
[16–19].
The block diagram depicted in Fig. 3 describes the purpose of learning in modiﬁ-
cation of weights so as to reduce the error. Weights, in order to be modiﬁed, require
some kind of mathematical guarantee which will be provided by a mathematical
tool called gradient. The maximum rate of increment for the scalar function gives
direction, in which magnitude would be achieved, as error has to decrease with the
maximum rate; hence, change has to be done in opposite direction of gradient oper-
ator. The range should be zero and one. If it is less than zero, rather than having
the change in opposite direction of gradient, it will have the change in direction of
gradient, the result, rather than decreasing, will increase. Hence, it must be greater
than zero. If it is greater than one, the guarantee of gradient will not be maintained
where as the result leads to oscillation. In order to overcome these criteria, it must

244
N. Shwetha et al.
Fig. 3 Block diagram design of ANN architecture
be less than one. Optimal value of learning constant depends upon the application
[20–23].
5.2
Gradient Descent Algorithm
This is also called as an optimization algorithm. Where in order to ﬁnd a local min
of a function using gradient descent, it is required to take some steps comparative to
the negative of the gradient of the function at the current point. It is also termed as
“steepest descent algorithm” [11]. While training ANN using gradient descent rule,
it gets stuck at times, because of local minima.
Here,  is a mathematical operator. When this is applied to a scalar function, result
will be a vector quantity which will have both magnitude and direction. Magnitude
will provide maximum rate of increment, and direction gives in which direction this
magnitude can be achieved. Reason for learning is to discover ideal arrangement of
loads to make error equivalent to zero. On the off chance that we take inclination of
negative work, the modiﬁcation should be negative of the slope. Figure 4 portrays
the inclination descent calculation, where at ﬁrst, the preparation information will
be arbitrary on the grounds so as to keep the information zero. The irregular loads
are given to ANN algorithm, and the yield will be given to the descent estimation

ANN-based Hybridization Approach for Detection of Cardiac Disease
245
Fig. 4 Gradient descent algorithm
dependent on which the errors have been determined so as to limit the errors and
the change of weights taken place. The weight adjustment is taken and is discussed
brieﬂy in the derivation [24].
5.3
Genetic Algorithm
John Holland developed the ﬁrst basic ideas on genetic algorithms that are basically
utilized as search and streamlining strategies. Genetic algorithms depend on the
knowledge of regular determination. As seen, the properties of an organism are
resolved. John Holland created that essential thoughts on genetic calculations are
basically utilized as search and improvement strategies. Given a huge arrangement
space, one might want to choose the point which advances an article work while
as yet satisfying a lot of requirements. Genetic calculations depend on its qualities.
Genetic calculations work on the particular string portrayal. They accompanying
three essential operators are applied as: one will be reproductive, the second will be
the crossover, and the third will be mutation. The propagation cycle makes another
age, beginning from a current age; strings are recreated with a likelihood separate to
their wellness esteem.

246
N. Shwetha et al.
Fig. 5 below represents the ﬂowchart of genetic algorithm. The genetic algorithm
works as follows: It initially creates a random population by uniform distribution.
Here, the purpose is ﬁnding the best solution for the problem. A maximum of 50%
of hidden nodes can go for crossover and randomly select how many nodes among
those in which one can decide which node to select randomly. Apply the mutation
Fig. 5 Flowchart of genetic algorithm

ANN-based Hybridization Approach for Detection of Cardiac Disease
247
to each and every offspring by adding the Gaussian distribution randomly. Process
will be repeated to create the same size of the parent population of the offspring
population in order to obtain the ﬁtness value by passing these weights to the neural
network.
5.3.1
Tournament Selection
Figure 6 describes the tournament selection in the working principle of genetic algo-
rithm. It is applied with challenger population equal to 20%. The algorithm sorts out
the tournament selection score and picks up the best half samples of the population
to deﬁne the next generation. Once the process gets terminated (from the last gener-
ation to next generation), the best solution is taken as the ﬁnal solution. From the
mating pool obtained, the algorithm selects two parents at random and applies the
GA operators such as crossover and mutation for hidden weights and output weights
by selecting row/column randomly. The newly obtained member of the population is
called child. This process repeats till the number of children produced is equal to the
original population size. A new generation is formed once the number of children
obtained by us equals to the total population. The process repeats till the parents have
95% of some ﬁtness value.
6
Error Back Propagation (EBP)
The principle points of interest of the enactment work in ANN alleged sigmoid
function are that it has an extremely basic subordinate, learning ̸= memorization. The
capacity to learn by models makes ANN entirely adaptable and amazing. The target
of EBP is to utilize errors to alter loads so that mistake are gradually reduced. The
ability to speed up EBP algorithm can be momentum method by dynamic learning
rate alterations and a predisposition node at input.
7
Machine Learning Network
There are a few reasons why genetic algorithm for preparing neural systems can
be useful to utilize. With respects exclusively to the issue of weight (and incli-
nation) determination for systems with ﬁxed networks, hereditary calculations are
especially acceptable at effectively looking through huge and complex spaces to
discover almost worldwide optima. As the multifaceted nature of the pursuit space
increments, genetic calculations present an undeniably appealing option in contrast
to slope-based strategies, for example, back engendering. Over-simpliﬁcation is the
second preferred position of genetic calculations. With just minor changes to the
calculation, genetic calculations can be utilized to prepare all various assortments of

248
N. Shwetha et al.
Fig. 6 Tournament selection
systems so as to build up a choice steady framework. Administered back proliferation
learning calculation or genetic calculation is utilized to prepare the ANN engineering.
To improve learning and speed, force and predisposition will be applied. By and large,
node predispositions are permitted to be altered during preparing, however, can be
set to speciﬁc incentive at the hour of system instatement. To help abstain from

ANN-based Hybridization Approach for Detection of Cardiac Disease
249
sinking into a nearby, an energy rate permits the system to conceivably skid through
neighborhood minima.
8
Beneﬁts of Genetic Algorithm in Neural Network
There are a few reasons why genetic algorithm for preparing neural systems can
be useful to utilize. With respects exclusively to the issue of weight (and incli-
nation) determination for systems with ﬁxed networks, hereditary calculations are
especially acceptable at effectively looking through huge and complex spaces to
discover almost worldwide optima. As the multifaceted nature of the pursuit space
increments, genetic calculations present an undeniably appealing option in contrast
to slope-based strategies, for example, back engendering. Over-simpliﬁcation is the
second preferred position of genetic calculations. With just minor changes to the
calculation, genetic calculations can be utilized to prepare all various assortments of
systems so as to build up a choice steady framework. Administered back proliferation
learning calculation or genetic calculation is utilized to prepare the ANN engineering.
To improve learning and speed, force and predisposition will be applied. By and large,
node predispositions are permitted to be altered during preparing, however, can be
set to speciﬁc incentive at the hour of system instatement. To help abstain from
sinking into a nearby, an energy rate permits the system to conceivably skid through
neighborhood minima.
9
Tests and Results
The input selection contains a total of 13 parameters as per the UCI repository as per
the experts who had already built the dataset.
Figure 7 shows the overall module which is created as GUI menu. The button
list has been arranged for the sequential output. Heart training data are the initial
stage where the input data are obtained and normalized into zero and one. The tested
data have been taken to test over trained data to ﬁnd the learning is complete or not.
Initially, gradient learning is taken for the learning performance.
In order to switch the operation in the saturation mode, one has to normalize
the datasets. Figure 8 shows the training dataset with target, while Fig. 8 shows the
normalized training dataset with target. Here, the rows represent patients who are
considered for dataset, i.e., (patient 1, patient 2, etc.…), while the columns represent
the parameters of individual patients, i.e., age in year, sex (one = male; zero =
female), chest pain-type (one = typical-type one angina; two = typical-type angina;
three = non-angina pain; four = asymptomatic),fasting blood sugar (one represents
>120 mg/dl; zero represents <120 mg/dl), rest ECG-resting electrographic results
(zero = normal;value1:one having ST-T wave abnormality; value two = showing
probable or deﬁnite left ventricular hypertrophy), exang—exercise-induced angina

250
N. Shwetha et al.
Fig.7 Over all GUI modules
Fig. 8 Normalized training dataset with target

ANN-based Hybridization Approach for Detection of Cardiac Disease
251
Fig. 9 Test dataset with target
Fig. 10 Normalized test dataset with target
(one = yes; zero = no), slope—the slope of the peak exercise ST segment (one
= unsloping; two = ﬂat; three = down sloping), CA—number of major vessels
colored by ﬂuoroscopy (value zero to three), thal (three = normal; six = ﬁxed defect;
seven = reversible defect), trest blood pressure (in Hg/mm upon hospital admission),
serum cholesterol (mg/dl), thalach—extreme heart rate achieved, and old peak—ST
depression induced by exercise.
Figure 9—test dataset with target; Fig. 10—normalized test dataset with target.
10
Conclusion and Future Scope
ANN architecture and genetic algorithm are discussed in detail. There exists no
standard procedure for prediction of the heart disease. A survey of literature of

252
N. Shwetha et al.
various reset mechanism known till date has to be carried out. These studies help in
conﬁrmation of the disease at least. Patients need not face problems of ambiguity
and inaccurate decision. Presently, neural network weight modiﬁcation is done by
using gradient descent and genetic algorithms and by applying for different patients
of using 13 parameters as dataset. It can, thus, be checked out for each training and
test data. Both the algorithms are used for performance analysis. The future actions
would be on the expert system design with implementation; a medical diagnosis
dataset can be designed according to the requirements for the module.
References
1. Shen, Z., Dept. of Electr. Eng., Brunel Univ., Uxbridge, UK, Clarke, M., Jones, R., & Alberta,
T. (1993). A neural network approach to the detection of coronary artery disease.Computers in
cardiology 1993, Proceedings (pp. 221–224).
2. Bushra, M., Electronic Engineering Sir Syed University of Engineering & Technology, Karachi,
Pakistan Khan, Tahmina, & Ali, Z. A. (2006). Cardiac sudden death risk detection using
hybrid neuronal-fuzzy networks. Electrical and electronics engineering, 2006 3rd international
conference on, 6–8 September 2006 (pp 1–4).
3. Image of a Neuron form website http://transductions.net/2010/02/04/313/neurons/
4. Baluja, S., & Davies, S. (1997). Using optimal dependency-trees for combinatorial optimiza-
tion: Learning the structure of the search space. In Proceedings of 14th international conference
machine learning (pp. 30–38). San Mateo, CA: Morgan Kaufmann.
5. De Jong, K. A. (1975). An analysis of the behavior of a class of genetic adaptive systems.
Ph.D. dissertation, University of Michigan, Ann Arbor.; Deb, K., & Goldberg, D. E. (1993)
Analyzingdeceptionintrapfunctions.InL.D.Whitley(Ed.),Foundationsofgeneticalgorithms
2 (pp. 93–108). San Mateo, CA: Morgan Kaufmann.
6. De Bonet J. S., Isbell, C., & Viola, P. (1997). MIMIC: Finding optima by estimating probability
densities. In M. C. Ozer, M. I. Jordan, & T. Petsche (Eds.), Advances in neural information
processing systems (Vol. 9, p. 424). Cambridge, MA: MIT Press.
7. Eshelman, L. J., & Schaffer, J. D. (1993). Crossover’s niche. In S. Forrest (Ed.), Proceedings
of the 5th international conference genetic algorithms (pp. 9–14). San Mateo, CA: Morgan
Kaufmann; [9] Goldberg, D. E. (1987). Simple genetic algorithms and the minimal, deceptive
problem. In L. Davis (Ed.), Genetic algorithms and simulated annealing (pp. 74–88). San
Mateo, CA: Morgan Kaufmann.
8. Kumaravel, N., Coll. of Eng., Anna Univ., Madras, India, Sridhar, K.S., & Nithiyanandam,
N. (2011). Artiﬁcial neural network based cardiac arrhythmia disease diagnosis. Process
automation, control and computing (PACC), 2011 international conference on 20–22 July
2011 (pp. 1–6).
9. Jadhav, S. M., Dept. of Inf. Technol., Dr. Babasaheb Ambedkar Technol. Univ., Lonere, India,
Nalbalwar, S. L., & Ghatol, A. A. (2008). Data fusion for heart diseases classiﬁcation using
multi-layer feed forward neural network. Computer engineering & systems, 2008. ICCES 2008
international conference on 25–27 November 2008 (pp. 67–70).
10. Jadhav, S. M., Dept. of Inf. Technol., Dr. Babasaheb Ambedkar Technol. Univ., Lonere, India,
Nalbalwar, S. L., & Ghatol, A. A. (2010). Generalized feed forward neural network based
cardiac arrhythmia classiﬁcation from ECG signal data. Advanced Information Management
and Service (IMS), 2010 6th International Conference on November 30 2010–December 2
2010 (pp. 351–356).
11. Yu, X., Inst. of Oceanol, Chinese Academy of Sci Beijing China, Gong, D., Shuen, X., Li, S.,
& Xu, Y. (2003). Comparisons of a combined wavelet and a combined principal component

ANN-based Hybridization Approach for Detection of Cardiac Disease
253
analysis classiﬁcation model for BCG signal analysis.Robotics, intelligent systems and signal
processing, 2003, proceedings 2003 IEEE international conference on 8–13 October 2003
(pp. 160–165).
12. Wang, Z. S., Xia, K. S., Li, W. H., He, Z. Y., Chen, J. D. Z. **Department of Radio Engineering,
Southeast Universiq, Nanjing, P. R. China *Department of Mathematics, Nanjing University of
Post & Telecommunications, Nanjing, P. R., China* *Institute for Healthcare Research, Baptist
Medical Center, Oklahoma City, Oklahoma, USA. A neural network solver for basis pursuit
and its applications to time-frequency analysis of biomedical signals.
13. Valavanis, I. K., School of Electrical and Computer Engineering, National Technical Univer-
sity of Athens, 9 heroon Polytechneiou Str, 15780 Zographou, Geece, Mougiakakou, S. G.,
Grimaldi, K. A., & Nikita, K. S. (2008) Analysis of postprandial lipemia as a cardiovascular
disease risk factor using genetic and clinical information: An artiﬁcial neural network perspec-
tive. Engineering in Medince and Biology Society 2008. EMBS 2008. 30th Annual International
IEEE EMBSConference vancouver,BritishColumbia (pp.4609–4612).Canada,August 20–24.
14. Qiao, H., Member, IEEE, Peng, J., Xu, Z.-B., & Zhang, B. (2003, December). A reference
model approach to stability analysis of neural networks. IEEE Transactions on Systems, Man,
and Cybernetics—Part B: Cybernetics, 33(6), 925–933.
15. Harik, G., Cantú-Paz, E., Goldberg, D. E., & Miller, B. (1997). The gambler’s ruin problem,
genetic algorithms, and the sizing of populations. In T. Back (Ed.), Proceedings 4th
international conference evolutionary computation (pp. 7–12) Piscataway, NJ: IEEE Press.
16. Harik, G. (1999) Linkage learning via probabilistic modeling in the ECGA, Univ. Illinois,
Urbana-Champaign, IlliGAL Rep. 99010.; [12] Hertz, J., Krogh, A., & Palmer, G. (1993)
Introduction to the theory of neural computation. Reading, MA: Addison-Wesley.
17. Höhfeld, M., & Rudolph, G. (1997). Toward a theory of population-based incremental learning.
InBack(Ed.),Proceedingsofthe4thinternationalconferenceevolutionarycomputation(pp.1–
5). Piscataway, NJ: IEEE Press.
18. Shyu, M. L., Chen, S. C., Sarinnapakorn, K., & Chang, L. (2003). A novel anomaly detection
scheme based on principal component classiﬁer. InProceedings of the IEEE foundations and
new directions of data mining workshop (pp. 172–179).
19. Ryan, J., Lin, M., & Miikkulainen, R. (2003). Intrusion detection with neural networks.
Advances in neural information processing systems (Vol. 10). Springer.
20. Shwetha, N., & Priyatham, M. (2020). Performance Analysis of self adaptive equalizers using
EPLMS algorithm. In 2020 Fourth international conference on I-SMAC (IoT in social, mobile,
analytics and cloud) (I-SMAC), Palladam, India (pp. 872–876). https://doi.org/10.1109/I-SMA
C49090.2020.9243512
21. Shwetha, N., & Priyatham, M. (2021). Convergence analysis of self-adaptive equalizers using
evolutionary programming (EP) and least mean square (LMS). In V. Bindhu, J. M. R. S. Tavares,
A. A. A. Boulogeorgos, & C. Vuppalapati (Eds.), International conference on communication,
computing and electronics systems. Lecture notes in electrical engineering (Vol. 733). Springer,
Singapore. https://doi.org/10.1007/978-981-33-4909-4_48
22. Shwetha, N., & Priyatham, M. (2021). Performance analysis of self adaptive equalizers using
nature inspired algorithm. In S. Smys, V. E. Balas, K. A. Kamel, P. Lafata (Eds.), Inventive
computation and information technologies. Lecture notes in networks and systems (Vol. 173).
Springer, Singapore. https://doi.org/10.1007/978-981-33-4305-4_37
23. Shwetha, N., Priyatham, M., & Gangadhar, N. (2021). Adaptive ﬁlter equalizer optimiza-
tion using hybrid approach. International Journal of Advanced Research in Engineering and
Technology, 12(1), 473–483.
24. Chen, Y. H., Abraham, A., & Yang, B. (2007). Hybrid ﬂexible neural-tree-based intrusion
detection systems. International Journal of Intelligent Systems, 22(4), 337–352.

The Implementation of Enhanced
K-Strange Points Clustering Method in
Classifying Undergraduate Thesis Titles
Malcolm Andrew Madeira
and Teslin Jacob
Abstract Clustering deals with the grouping together of data items which are sim-
ilar amongst themselves and differ to a greater extent in terms of proximity to items
of other groups. The problem is that in most institutions, undergraduate thesis titles
are not grouped based on similarity and it is time-consuming for research students
to search for a thesis report based on similarity or research papers which have simi-
lar topics since the titles are just stored sequentially in the database. The low score
of Silhouette coefﬁcient using k-means as a clustering algorithm on text clustering
motivated to exploit the potentiality of the Enhanced K-Strange points clustering
algorithm to obtain better results. The objective of this paper is to group the under-
graduate thesis titles using the Enhanced K-Strange points clustering algorithm. The
Silhouette coefﬁcient is used to test the cluster quality. The result of the research is
a method that can process the titles of the undergraduate thesis and group them into
different groups using a clustering technique.
Keywords Enhanced K-Strange points clustering · Text clustering · K-means ·
Silhouette coefﬁcient · Euclidean distance measure · Tokenization · Stemming
1
Introduction
In today’s scenario, undergraduate thesis titles in an institute or university are stored
sequentially or according to their branch, but students usually undertake thesis that
may fall into another branch or domain, increasing the burden on research students
to efﬁciently search for a thesis title as per their requirement and research interest.
M. A. Madeira (B) · T. Jacob
Goa College of Engineering, Farmagudi, Ponda, Goa, India
e-mail: teslinjacob@gec.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_21
255

256
M. A. Madeira and T. Jacob
Another problem found at Goa Engineering colleges is that the automatic thesis
title clustering process has never been carried out. All these years, the thesis titles
were just stored as per the students branch of study and not as per the domain of the
thesis.
As a result, the thesis titles data was only there with the librarian project coor-
dinator in excel ﬁle format. If those thesis titles of undergraduates were classiﬁed,
it could potentially increase the efﬁciency of students to do research of their choice
without any hindrance by referring to the classiﬁed thesis.
Oneof themethods inmanagingdocument is text mining. Thescopeof text mining
involves clustering the dataset, classiﬁcation, dimension reduction, topic modelling
and similarity computing [9]. The major issues in text clustering are feature selec-
tion, unknown class labels, the weighting scheme, similarity or dissimilarity measure,
sparsity of document term matrix, huge number of outliers [1]. An algorithm is pro-
posed to overcome the shortcomings of k-means algorithm using two stages splitting
and merging for increasing its efﬁciency [12]. In k-means selection of centroid are
performed based on ﬁtness function paradigm of genetic algorithm [14]. “Bisecting
K-Means algorithm” gives better performance, when huge data is used [11]. Text
clustering algorithm uses a model called vector space [3].
1.1
Motivation
The use of K-Means clustering method in classifying thesis titles was shown wherein
the silhouette coefﬁcient was used for testing cluster quality and a low score of silhou-
ette coefﬁcient 0.5674 was shown if used K-Means as the clustering algorithm [16].
Clustering using the classical K-Means algorithm results in obtaining ﬁnal ﬁxed
points called ﬁnal means around which all the points in the dataset are clustered. This
suggests that if the ﬁnal unchanging means are calculated ﬁrst, then the task only
comes down to only assigning the remaining data points into appropriate clusters,
an algorithm called “K-Strange points clustering method” was proposed where in K
number of points from the dataset equalling the number of clusters required which
are farthest from each other based on the Euclidean distance parameter, the leftover
points in the dataset are assigned to clusters formed by these K-Strange points [7].
An enhancement was proposed to the above-mentioned algorithm by correcting
the location of the third strange point by placing it almost maximally and equally
spaced both from kmin, kmax, and this results in more accurate clusters [6].
From the existed problem and potentiality of Enhanced K-Strange points cluster-
ing algorithm to categorize textual data. It is expected that this research can classify
undergraduate thesis titles into their appropriate clusters.

The Implementation of Enhanced K-Strange Points …
257
Fig. 1 Kmin of the dataset
2
Illustration of Enhanced K-Strange Points Clustering
Algorithm
The K-Strange points clustering algorithm has been improved to ﬁnd strange points
that are maximally separated from one another, as well as to address the impact on
the running time of selecting the two farthest points from the dataset.
Instead of selecting two points which are at maximum distance from each other by
using the Euclidean distances between all the points in the dataset from each other,
this algorithm ﬁrst ﬁnds the minimum of the dataset.
This point is called as kmin and represents the ﬁrst of the K-Strange points as
shown in Fig.1.
The algorithm then locates a point which is farthest from Kmin which named as
Kmax and can be seen in Fig.2.
These two steps eliminate the need to identify the two strange points by computing
the Euclidean distances between all points in the dataset from each other, removing
the strong inﬂuence on the clustering method’s running time, which was O(n2), by
ﬁrst ﬁnding the minimum and then identifying the point that is farthest from the
minimum, thus reducing the need to discover the two strange points by computing
the Euclidean distances between all points in the dataset from each other.
This is likely to improve the algorithm’s performance signiﬁcantly since ﬁnding
the minimum data point requires only one pass of the dataset, which can be done in
O(n) time for n points in the dataset, and ﬁnding the second strange point, which is
farthest from Kmin, also requires only one pass of the dataset, which can be done in
O(n) time for n points in the dataset.
The enhanced algorithm then locates a third data item that is further separated
from the two strange data elements discovered in the previous steps. If the third
strange element, as shown in Fig.3, is closer to Kmin, then Eq. (3), is used to correct

258
M. A. Madeira and T. Jacob
Fig. 2 Kmin and Kmax of the
dataset
Fig. 3 Kstr closer to Kmin
than to Kmax
the position of the potential third strange data item by ﬁnding a central element
between the third strange element and Kmax and referring to this central element as
the ﬁnal third strang point which is farthest from kmin and kmax.
If, as shown in Fig.4, the third strange point is closer to Kmax, the position of the
potential third strange element is corrected using Eq. (4) by ﬁnding a central element
between the third strange element and Kmin and referring to this central element as
the ﬁnal third strange (farthest) point [5, 6].
The three strange points can be depicted as shown in Fig.5 by doing the above.
If K = 3 clusters are required number of clusters, the three clusters can be formed
by assigning the remaining elements to clusters made up of these three enhanced
strange points, as shown in Fig.6 [6].

The Implementation of Enhanced K-Strange Points …
259
Fig. 4 Kstr closer to Kmax
than to Kmin
Fig. 5 K = 3 strange points
3
Research Method
3.1
Research Data
Research data is used in this research was data of undergraduate thesis titles of Goa
College of Engineering containing 250 records.

260
M. A. Madeira and T. Jacob
Fig. 6 K = 3 strange points
3.2
Text Mining
Text mining incorporates traditional data mining algorithm such as clustering and
classiﬁcation. Text mining is repeated process involving analysis repetition by using
different setting and excluding partial requirement for better result. This step’s out-
come can be a form of document collection, multi-terms topic list, or rules to solve
classiﬁcation problem [4].
Figure 7 shows the steps involved in text mining.
Fig. 7 General ﬂow diagram of proposed methodology

The Implementation of Enhanced K-Strange Points …
261
3.2.1
Data Collection
The ﬁrst step in text mining is collection of the required textual data that is needed
to explore the required information from the textual data.
3.2.2
Pre-Processing
Preparing the dataset collected to be ready for application of the intended clustering
algorithm.
1. Tokenization and stop word removal
2. Stemming
3. TF-IDF.
• Tokenization is the method of separating a volume of text into tokens. The token
collection is used as input for additional processing such as ﬁltering or text mining.
Tokenization has applications in both linguistics (as a form of text subdivision) and
computer science (as a component of lexical analysis) [13]. Stop words, which are
words, extracted out of natural language data before or during processing. While
stop words typically correspond to a language’s most familiar words, there is no
standard set of stop words used by processing tools, to help phrase quest, some
tools speciﬁcally prevent deleting these stop phrases.
• The method of reducing words to their word stem, nucleus, or root form, which
is usually a written word form, is called as stemming. The stem does not have
to match to the word’s morphological origin; it is generally enough that related
words should map to the same stem in most cases, even though the stem isn’t a
true root in and of itself.
• Tf-idf stands for “term frequency–inverse document frequency” and is a numerical
metric that determines the signiﬁcance of a word is to a corpus text [15]. In infor-
mation processing and text mining, it is widely used as a criterion. The number of
times a term appears in the paper increases the tf-idf value, but is counterbalanced
by the frequency of a word in a documents, which helps to compensate for the
fact that certain words are used more often than others in general. State that the
term/word count is explained with Eq. (1) [8].
t f -id f (ti, dj) = t f (ti, dj) ∗log(N/(ti))
(1)
where
t f -id f (ti, dj) = word/term count towards document dj
t f (ti, dj) = number of times word/term ti appears in document dj
N = Number of documents in total
N(ti) = number of documents with word/term ti in it.

262
M. A. Madeira and T. Jacob
3.3
Enhanced K-Strange Points Clustering Algorithm
Input: The number of required cluster K = T and database containing n objects
D=D1, D2,…Dn
Output: Group of K clusters.
Step 1: Find Kmin, the Minimum of dataset.
Step 2: Find a Point Kmax, which is at maximum distance from Kmin.
Step 3: Locate a third point S which is farthest from Kmin and Kmax.
Step 4:
if(D(Kmin, S) == D(Kmax, S))
Kstr = S
(2)
else if(D(Kmin, S) < D(Kmax, S))
Kstr = Kstrprv + Xm
|Kmax −Kstrprv|
(K −1)

(3)
else if(D(Kmin, S) > D(Kmax, S))
Kstr = Kmin + Xm
Kstrprv −Kmin

(K −1)

(4)
where
K = Total number of clusters
Xm ranges from 1, 2, 3 . . . K −2 i.e.
Xm = X1, X2, X3 . . . Xk−2
For e.g. if K=5, Xm = 5 −2 = 3 so we have
X1 = 1 = with the ﬁrst rectiﬁed value of S
X2 = 2 = with the second rectiﬁed value of S
X3 = 3 = with the third rectiﬁed value of S
Kstrprv = Uncorrected values of S
Kstr
= Corrected values of S
Step 5: Repeat the above procedure until we locate K-Strange points.
Step 6: Assign the remaining Points in the dataset into clusters formed by these non
collinear K-Strange points [6].
The distance measurement that is used in the above algorithm is the Euclidean
distance [2].

The Implementation of Enhanced K-Strange Points …
263
Fig. 8 Illustration of Silhouette coefﬁcient testing
3.4
Silhouette Coefﬁcient Testing
Silhouette coefﬁcient is used to ﬁnd out the cluster quality and strength, how good
an object is placed in a cluster [10]. Score of Silhouette coefﬁcient is shown in Eq.
(5)
S(i) =
(b(i) −a(i))
max {a(i), b(i)}
(5)
where
S(i) = value of silhouette validity with object i
a(i) = average distance between objects i with all objects in the same cluster (intra-
cluster)
b(i) = average distance between objects i with all objects in the nearest cluster
(nearest cluster)
max = maximum
where in Fig. 8,
a = average intra-cluster distance, i.e. the average distance between each point within
a cluster.
b= average inter-cluster distance, i.e. the average distance between all clusters.
The silhouette coefﬁcient value is between −1 and 1.
1: Indicates that clusters are well separated and distinct from one another.
0: Indicates that clusters are unrelated, or that the distance between clusters is not
signiﬁcant.
−1: Clusters have been allocated incorrectly.

264
M. A. Madeira and T. Jacob
Table 1 Data
Term
T1
T2
T3
T4
T5
Firm
0
5
0
0
0
India
7
0
0
0
0
Plai
0
0
2
1
0
Foreign
2
5
0
0
0
Year
2
2
3
2
0
Win
0
0
1
4
1
Slam
0
0
2
1
0
First
1
0
1
5
0
Tax
0
0
0
0
9
Howard
0
0
0
0
5
4
Mathematical Illustration
We have 5 documents thesis titles to be clustered which are given below after per-
forming Tokenization, Stop word removal and stemming.
1. T1: India, foreign, year, ﬁrst
2. T2: ﬁrm, foreign, year
3. T3: plai, year, win, slam, ﬁrst
4. T4: plai, year, win, slam, ﬁrst
5. T5: win, tax, howard.
The number of times the word is present in each document given in Table 1.
After performing Min-Max normalization on the data table to normalize the data
from Table 1, the result is shown ion Table 2.
Now, calculation of Tf-idf of the normalized data, the result is shown in Table 3
(Table 4).
Thedocumentvectorsaregivenasinputtotheclusteringalgorithm,i.e.“Enhanced
K-Strange points clustering algorithm”.
4.1
Step I: Finding the Minimum of the Dataset (Kmin)
Using Euclidean distance measure the minimum from the dataset is calculated from
the origin.
The minimum distance from the origin is 2.4619, and kmin value is (0, 2.321, 0,
0.7346, 0, 0, 0, 0.367, 0, 0).

The Implementation of Enhanced K-Strange Points …
265
Table 2 Normalized data
Term
T1
T2
T3
T4
T5
Firm
0
1
0
0
0
India
1
0
0
0
0
Plai
0
0
1’
0.5
0
Foreign
0.4
1
0
0
0
Year
0
2
1
0
0
Win
0
0
0.25
1
0.25
Slam
0
0
1
0.5
0
First
0.2
0
0.2
1
0
Tax
0
0
0
0
1
Howard
0
0
0
0
1
Table 3 Tf-idf data matrix
Term
TFI
DF
D/DF
IDF
Weights = TFI * IDF
T1
T2
T3
T4
T5
t1
t2
t3
t4
t5
From
0
1
0
0
0
1
5/1
2.2319
0
2.231
0
0
0
India
1
0
0
0
0
1
5/1
2.2319
2.231
0
0
0
0
Plai
0
0
1
0.5
0
1.5
5/1.5
1.7369
0
0
1.7369
0.8684
0
Foreign 0.4
1
0
0
0
1.4
5/1.4
1.8365
0.7346
1.836
0
0
0
Year
0
0
1
0
0
1
5/1
2.2319
0
0
2.3219
0
0
Win
0
0
0.25
1
0.25
1.5
5/1.5
1.7369
0
0
0.4342
1.7369
0.434
Slam
0
0
1
0.5
0
1.5
5/1.5
1.7369
0
0
1.7369
0.8684
0
First
0.2
0
0.2
1
0
1.4
5/1.4
1.8365
0.367
0
0.3673
1.8365
0
Tax
0
0
0
0
1
1
5/1
2.2319
0
0
0
0
2.3219
Howard 0
0
0
0
1
1
5/1
2.2319
0
0
0
0
2.3219
Table 4 Document titles vectors
Term
Firm
India
Plai
Foreign Year
Win
Slam
First
Tax
Howard
t1
0
2.321
0
0.7346
0
0
0
0.367
0
0
t2
2.321
0
0
1.836
0
0
0
0
0
0
t3
0
0
1.736
0
2.321
0.4342
1.7369
0.3673
0
0
t4
0
0
0.8684
0
0
1.7369
0.8684
1.8365
0
0
t5
0
0
0
0
0
0
0
0.434
2.3219
2.3219

266
M. A. Madeira and T. Jacob
4.2
Step II: Finding the Maximum of the Dataset (Kmax)
Using Euclidean distance measure the maximum from the dataset is calculated from
the kmin value.
The maximum distance from the minimum (kmin) is 4.1872, and kmax value is (0,
0, 1.736, 0, 2.321, 0.4342, 1.7369, 0.3673, 0, 0).
4.3
Step III: Finding the Third Strange Point
Equation (6) is made use of to calculate the third strange point, where max = 4.1872
and Kmin = (0, 2.321, 0, 0.7346, 0, 0, 0, 0.367, 0, 0)
Kmax= (0, 0, 1.736, 0, 2.321, 0.4342, 1.7369, 0.3673, 0, 0)
Distance = Max + dist(Kmin, datapoint) + dist(Kmax, datapoint)
(6)
The maximum distance farthest from kmin and kmax is 13.0075 and the K-Strange
= (0, 0, 0, 0, 0, 0, 0, 0.434, 2.3219, 2.3219).
4.4
Step IV: Correcting the K-Strange Point
To make sure that the third strange point is maximally further from kmin and kmax it
is tested as follows,
f 1 = dist(Kmin, S) = dist(Kmin, 5) = 4.0882
f 2 = dist(Kmax, S) = dist(Kmax, 5) = 4.7321
Since f 1 < f 2 , using the Eq. (3), the Kstrange data point value is rectiﬁed
where
K = Total number of clusters =3
Since K = 3, Xm = 3 −2 = 1 so we have
X1 = 1 = with the ﬁrst rectiﬁed value of S
Kstrprv = Uncorrected values of S
Kstr = Corrected values of S.
After compoutation, the corrected value is Kstr =(0, 0, 0.868, 0, 1.1605, 0.2171,
0.86845, 0.46735, 3.48285, 3.48285).

The Implementation of Enhanced K-Strange Points …
267
4.5
Step V: Assigning Points to Respective Clusters
We know that Kmin = (0, 2.321, 0, 0.7346, 0, 0, 0, 0.367, 0, 0)
Kmax= (0, 0, 1.736, 0, 2.321, 0.4342, 1.7369, 0.3673, 0, 0)
Kstrange = (0, 0, 0, 0, 0, 0, 0, 0.434, 2.3219, 2.3219).
Using Euclidean distance measures the remaining data points are grouped into
their respective clusters. The titles T1 and T2 are grouped as C1 cluster, T3 and T4
are grouped as C2 cluster and T5 as C3 clsuter.
5
Result and Discussion
In this research, data obtained from the library is processed through text mining
phases.
5.1
Collect Data
Collect data is carried out by collecting data. The data was obtained from library
coordinator of undergraduate thesis, and the data obtained is saved in excel format.
To process the document, the data is inputted to system. The dataset in excel format is
showninFig.9,andthedatasetisloadedinJupiternotebookusingpandasdata-frame;
the loaded dataset is shown in Fig. 10. The data which is loaded has a serial number
denoted as no., Identiﬁcation number denoted as ID, type of the paper denoted as
Type, thesis title denoted as Titles and year of publication denoted as Year in the
header of the dataset loaded.
Fig. 9 Dataset of thesis titles in excel format

268
M. A. Madeira and T. Jacob
Fig. 10 Process of load data
Fig. 11 Titles extracted from the loaded dataset
5.2
Text Parsing
The process of text parsing is divided into two which are tokenization and stemming.
Selecting only the titles from the dataset and converting to lowercase and removing
punctuations before tokenization and titles are stored in python list, and this result is
shown in Fig.11.
Tokenization is used to break the titles from the dataset into words. Tokenization is
performed using NLTK library, after tokenization, stemming is done. For stemming
process, the Porter stemmer algorithm is used which is inbuilt in NKTK library, the
pseudo-code is shown in Listing 21.1.
Listing 21.1 Tokenization and Stemming process
import nltk import string from nltk .stem. porter import
PorterStemmer
def tokenize(text ):
tokens = nltk .word_tokenize(text)
stems = []
for item in tokens:
temp=PorterStemmer().stem(item)
stems.append(temp)
return stems
The result of tokenization and stemming is shown in Fig. 12.

The Implementation of Enhanced K-Strange Points …
269
Fig. 12 Outcome of tokenization and stemming
5.3
The Process of Document Clustering
The tokenization and stemming results are given for document clustering but before
clustering, document from the pre-processing result will be used to construct TF-IDF
matrix, from “Scikit-learn”, library the TﬁdfVectorizer is used to construct the TF-
IDF matrix, for the tokenizer, the tokenizer function shown in the listing 1.1, is given
and the stop words speciﬁes the language used as in this case its English language
and the norm speciﬁes the distance measure used, in this case its l2 norm, which is
Euclidean distance measure, the use_idf is set as true, and the list of titles is passed
to the vec.ﬁt_transform(titles) function, this process gives a TF-IDF matrix which is
at the end is converted to array format for furtherprocessing.
Listing 21.2 TF-IDF matrix generation process
from sklearn . feature_extraction . text import TfidfVectorizer vec =
TfidfVectorizer(tokenizer=tokenize ,
stop_words=’english’ ,
norm=’l2’ ,
use_idf=True)
matrix = vec. fit_transform( titles ) df =
pd.DataFrame(matrix. toarray() , columns=vec.get_feature_names())
Then the Enhanced K-Strange points clustering algorithm will be carried out. In
clustering process, the value k = 3, i.e. the no. of clusters.
Step 1. Check if it is possible to create given k amount of clusters based on dataset
content’s length.
Step 2. Calculate given datapoints’ dimensions.
Step 3. Find minimum and maximum k-strange points. Assign them as centroids.

270
M. A. Madeira and T. Jacob
Step 4. Find remaining (k −2) k-strange points and adjust their coordinates accord-
ing to the algorithm. Assign k-strange point as an additional centroid. Aux-
iliary: Create a copy of dataset to remove points that are already found and
assigned as additional centroids in order to prevent a point being found twice.
Step 5. Create an array of dataset’s shape of cluster IDs. Fill it with corresponding
IDs based on the distances between established k-strange points.
Listing 21.3 Enhanced K-Strange points clustering pseudo-code
cluster(k, dataset ):
’’’ Step 1 ’’’
if len(dataset) < k:
raise QuantityError( ’Can\ ’ t create given amount of clusters! Too few datapoints . ’)
’’’ Step 2 ’’’
dimension = len(dataset[0])
’’’ Step 3 ’’’
k_min = find_k_min(dataset , dimension)
k_max_distance_value, k_max = find_k_max(k_min, dataset)
centroids = [k_min, k_max]
’’’ Step 4 ’’’
confined_dataset = dataset .copy()
for point in range(0, k −2):
# find additional k−strange candidate point
# dist = max+dist (Kmin,datapoint)+(Kmax,datapoint)
candidate_index , candidate = find_k_str_candidate(k_min, k_max, k_max_distance_value, confined_dataset)
# remove k−strange candidate point from temporal dataset copy
confined_dataset = np. delete(dataset , candidate_index , 0)
# adjust k−strange candidate point’s coordinates
k_str = correct_coordinates(k, k_min, k_max, candidate , dimension)
dataset[candidate_index] = k_str
# assign k−strange point as additional centroid
centroids .append(k_str)
’’’ Step 5 ’’’
clusters = np.empty(len(dataset) , dtype=int )
if len(centroids) == 3:
for i in range (0, len(dataset )):
if (euclidean_distance(k_min, dataset[ i ]) <= euclidean_distance(k_max, dataset[ i ])) and (
euclidean_distance(k_min, dataset[ i ]) <= euclidean_distance(k_str , dataset[ i ])):
clusters[ i ] = 0
if (euclidean_distance(k_str , dataset[ i ]) <= euclidean_distance(k_min, dataset[ i ])) and (
euclidean_distance(k_str , dataset[ i ]) <= euclidean_distance(k_max, dataset[ i ])):
clusters[ i ] = 1
if (euclidean_distance(k_max, dataset[ i ]) <= euclidean_distance(k_min, dataset[ i ])) and (
euclidean_distance(k_max, dataset[ i ]) <= euclidean_distance(k_str , dataset[ i ])):
clusters[ i ] = 2
return centroids , clusters
The clustering result is shown in Fig. 13.
In the clustering result, the thesis titles are classiﬁed into 3 clusters, i.e. 0, 1 and
2. Against each thesis title, the corresponding cluster number is denoted in which
the thesis title is classiﬁed.

The Implementation of Enhanced K-Strange Points …
271
Fig. 13 Clustering result
Fig. 14 Silhouette coefﬁcient using “Enhanced K-Strange points clustering method”
5.4
Testing
After the thesis, titles are classiﬁed using the “Enhanced K-Strange points clustering
method”,theclustersaretestedforclusterqualityusingSilhouetteCoefﬁcienttesting.
An inbuilt function from “Scikit-learn”, library is used for Silhouette coefﬁcient test-
ing. The “metrics.silhouette_score(matrix, labels, metric=‘euclidean’)” takes input
parameters as, the TF-IDF matrix, the cluster labels and the distance matrix, here
Euclidean distance measure is used, and it returns the Silhouette coefﬁcient value.
In Fig.14, the Silhouette coefﬁcient using “Enhanced K-Strange points clustering
method”. The result of Silhouette Coefﬁcient is 0.9631 …with a total of three clusters.
Similarly, the dataset was also tested using K-Means clustering algorithm, in
Fig.15 the Silhouette coefﬁcient using “K-Means clustering algorithm”, the result
of Silhouette coefﬁcient is 0.0677 …with a total of three clusters.
The result using “Enhanced K-Strange points clustering method” is relatively
high. From analysis, the lower distribution of thesis titles makes the testing score
become high. The high testing score suggests that these clusters are well isolated

272
M. A. Madeira and T. Jacob
Fig. 15 Silhouette coefﬁcient using “K-Means clustering algorithm”
Table 5 Comparison of Silhouette coefﬁcient and running time of algorithm
Algorithm
Silhouette coefﬁcient
Running time of algorithm
(ms)
K-means clustering algorithm
0.0677
26
Enhanced K-Strange points
clustering algorithm
0.9631
6
from each other when used with Enhanced K-Strange points clustering method to
cluster the thesis titles as compared to using K-Means clustering algorithm.
From Table 5, it is evident that the “Enhanced K-Strange points clustering algo-
rithm” outperforms the K-Means clustering algorithm in the domain of text cluster-
ing.
6
Conclusion
This paper implements the “Enhanced K-Strange points clustering method” on text
clustering domain.
Based on the result of the research on the implementation of text mining on
undergraduate thesis, the Silhouette coefﬁcient is 0.9631 and compared to K-Means
clustering algorithm the Silhouette coefﬁcient is 0.06778.
Since the true cluster labels are uncertain and not known, evaluation was per-
formed using the Silhouette Coefﬁcient which gave a higher coefﬁcient for Enhanced
K-Strange points clustering algorithm compared to K-Means, and this signiﬁes that
the clusters formed by “Enhanced K-Strange points clustering method” are well
separated from each other.
The running time of “Enhanced K-Strange points clustering method” is 6 ms, and
the running time of K-Means clustering algorithm is 26 ms. Although the K-Means
clustering algorithm executes faster than the K-Strange points clustering algorithm, it
is considerably slower than the K-Strange points clustering algorithm as it is evident
from Table 5.
Therefore, it can be concluded that using Enhanced K-Strange points clustering
algorithm when applied in the domain of text clustering, it gives efﬁcient clusters as
shown in this paper where the cluster quality is relatively high and running time of

The Implementation of Enhanced K-Strange Points …
273
the algorithm is much less using the “Enhanced K-Strange points clustering method”
as compared to K-Means clustering method.
This research only focuses on a particular textual dataset of 250 records, which
is a demerit, in future scope and studies, the Enhanced K-Strange points clustering
method needs to be tested for a larger dataset containing more than 250 records and
needs to be tested for Silhouette coefﬁcient and running time of the algorithm.
Acknowledgements Iwouldliketotakethisopportunitytoexpressmyprofoundgratitudeanddeep
regard to my Prof. Teslin Jacob, Computer Engineering Department, Goa College of Engineering,
for his guidance and valuable feedback and constant encouragement.
References
1. Afzali, M., & Kumar, S. (2019). Text document clustering: Issues and challenges. In 2019 inter-
national conference on machine learning, big data, cloud and parallel computing (COMITCon)
(pp. 263–268). IEEE.
2. Alfakih, A. Y., Khandani, A., & Wolkowicz, H. (1999). Solving Euclidean distance matrix
completion problems via semideﬁnite programming. Computational Optimization and Appli-
cations, 12(1), 13–30.
3. Beil, F., Ester, M., & Xu, X. (2002). Frequent term-based text clustering. In Proceedings of the
eighth ACM SIGKDD international conference on Knowledge discovery and data mining (pp.
436–442).
4. Chakraborty, G., Pagolu, M., & Garla, S. (2014). Text mining and analysis: Practical methods,
examples, and case studies using SAS. SAS Institute.
5. Johnson, T., & Lobo, J. Z. (2012). Collinear clustering algorithm in lower dimensions. IOSR
Journal of Computer Engineering, 6(5), 08–11.
6. Johnson, T., & Singh, S. K. (2015). Enhanced k strange points clustering algorithm. In 2015
international conference on emerging information technology and engineering solutions (pp.
32–37). IEEE.
7. Johnson, T., & Singh, S. K. (2015). K-strange points clustering algorithm. In Computational
intelligence in data mining(Vol. 1, pp. 415–425). Springer.
8. Kao, A., & Poteet, S. R. (2007). Natural language processing and text mining. Springer Science
& Business Media.
9. Kobayashi, V. B., Mol, S. T., Berkers, H. A., Kismihók, G., & Den Hartog, D. N. (2018). Text
mining in organizational research. Organizational Research Methods, 21(3), 733–765.
10. Plattel, C. (2014). Distributed and incremental clustering using shared nearest neighbours.
Master’s thesis.
11. Rohilla, V., Kumar, M. S. S., Chakraborty, S., & Singh, M. S. (2019). Data clustering using
bisecting k-means. In 2019 international conference on computing, communication, and intel-
ligent systems (ICCCIS) (pp. 80–83).
12. Rong, Y., et al. (2020). Staged text clustering algorithm based on k-means and hierarchical
agglomeration clustering. In IEEE international conference on artiﬁcial intelligence and com-
puter applications (ICAICA) (pp. 124–127). IEEE.
13. Schütze, H., Manning, C. D., & Raghavan, P. (2008). Introduction to information retrieval
(Vol. 39). Cambridge University Press Cambridge.
14. Sen, A., Pandey, M., & Chakravarty, K. (2020). Random centroid selection for k-means cluster-
ing: A proposed algorithm for improving clustering results. In 2020 international conference
on computer science, engineering and applications (ICCSEA) (pp. 1–4).

274
M. A. Madeira and T. Jacob
15. Vijayarani, S., Ilamathi, M. J., Nithya, M., et al. (2015). Preprocessing techniques for text
mining—An overview. International Journal of Computer Science & Communication Net-
works, 5(1), 7–16.
16. Zahrotun, L., Putri, N. H., & Khusna, A. N. (2018). The implementation of k-means clustering
method in classifying undergraduate thesis titles. In 2018 12th international conference on
telecommunication systems, services, and applications (TSSA) (pp. 1–4). IEEE.

Spam Email Detection Using Machine
Learning and Neural Networks
Manoj Sethi, Sumesha Chandra, Vinayak Chaudhary, and Yash Dahiya
Abstract Spam emails are junk emails which are unrequested deceptive emails
sent or forwarded to any person or a company which may contain malware and
has access to conﬁdential information of any individual. A lot of research work has
been done in this area of spam detection which is limited to some speciﬁc domains.
Machine learning is generally used to classify whether an email is valid (ham) or
unwanted (spam). Two feature sets are introduced namely stopwords and word count
to determine an email is spam or ham on the basis of textual information and ﬁelds of
an email ﬁle. The entire process involves the comparison of two different feature sets
on Multinomial Naïve Bayes, Logistic Regression, Linear Support Vector Machine,
and Artiﬁcial Neural Network Algorithms to determine a more reliable method for
spam detection. For this purpose, we use benchmark datasets as well as real time
evaluation to experimentally evaluate the proposed work. Detection of a spam email
on basis of content, malware, and sender’s information can reduce the threat to user’s
conﬁdential information to a great extent.
Keywords Email spam detection · Machine learning · Neural networks · Naive
Bayes · Support vector classiﬁer · Logistic regression · Spam · Email
1
Introduction
Technology has become a vital part of life in today’s time. With each passing day,
the use of the internet increases exponentially, and with it, the use of email for the
purpose of exchanging information and communicating has also increased, it has
become second nature to most people. While emails are necessary for everyone, they
also come with unnecessary, undesirable bulk mails, which are also called Spam
Mails [1]. Anyone with access to the internet can receive spam on their devices.
Most spam emails divert people’s attention away from genuine and important emails
M. Sethi · S. Chandra · V. Chaudhary (B) · Y. Dahiya
Department of Computer Science, Delhi Technological University, New Delhi, India
M. Sethi
e-mail: manojsethi@dce.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_22
275

276
M. Sethi et al.
and direct them towards detrimental situations. Spam emails are capable of ﬁlling up
inboxes or storage capacities, deteriorating the speed of the internet to a great extent.
These emails have the capability of corrupting one’s system by smuggling viruses
into it or steal useful information and scam gullible people. The identiﬁcation of
spam emails is a very tedious task and can get frustrating sometimes.
While spam detection can be done manually, ﬁltering out a large number of spam
emails can take very long and waste a lot of time. Hence, the need for spam detection
software has become the need of the hour. To solve this problem, various spam
detection techniques are used now. The most common technique for spam detection
is the utilization of Naive Bayesian method and feature sets that assess the presence
of spam keywords. The main purpose is to demonstrate an alternative scheme, with
the use of Neural Network (NN) [2] classiﬁcation system that utilizes a collection
of emails sent by several users, is one of the objectives of this research. One other
purpose is the development of spam detection with the help of Artiﬁcial Neural
Networks, resulting in almost 98.8% accuracy.
2
Literature Review
Email:
Electronic mail (email) is a messaging system that electronically transmits messages
across computer networks. Anyone is free to use email services through Gmail,
Yahoo, or people can even register with an Internet Service Provider (ISPs) and be
provided with an email account. Only an internet connection is required, otherwise
being a free service.
Spam:
There is an unprecedented growth in multimedia content with social network prolif-
eration [3]. The ever growing, vibrant pool of data leads to several challenges in
gaining useful insights due to the object oriented and content driven nature of social
media. Private and sensitive user data are available in social networks along with
their multimedia content [4]. This is the reason for identity and personal informa-
tion thefts. Bulk mails that are unnecessary and undesirable that can be classiﬁed as
Spam Mails. These spam emails hold the power to corrupt one’s system by ﬁlling up
inboxes, degrading the speed of their internet connection.
Spam Detection:
Many spam detection techniques are being used now-a-days. The methods use ﬁlters
that can prevent emails from causing any harm to the user. The contributions and
their weakness have been identiﬁed [5].
There are several methods that are accessible to spam, for example, location of
sender, its contents, checking IP address or space names [6]. Spammers use reﬁned

Spam Email Detection Using Machine Learning and Neural Networks
277
Table 1 Spam categories
Categories
Descriptions
Health
The spam of fake medications
Promotional products
The spam of fake fashion items like
clothes bags and watches
Adult content
The spam of adult content of
pornography and prostitution
Finance and marketing
The spam of stock kiting, tax
solutions, and loan packages
Phishing
The spam of phishing or fraud
variations to avoid spam identiﬁcation. Few measures connected with spam iden-
tiﬁcation are; Blacklist and white-list, Machine learning approaches, Naïve Bayes,
Support Vector Machine, Neural Network Classiﬁcation [7].
A mobile system was proposed by Mahmoud et al. [8] with the motive of blocking
and identifying spam SMS. In their work, they attempted to protect smartphones by
ﬁltering SMS spam that contains abbreviations and idioms. The system was based
on the Artiﬁcial Immune System (AIS) and Naïve Bayesian (NB) algorithm. By the
use of the Naive Bayes algorithm, the messages are classiﬁed based on their features.
It used an SMS dataset with 1324 messages. Results from this system gave detection
rate 82%, 6% positive rate, and 91% accuracy (Table 1).
An approach using random forest algorithm approach is proposed by Akinyelu
and Adewumi [9] in order to identify phishing or spam emails. It used 200 emails.
The main motto of research was to reduce features and increase efﬁciency/accuracy.
Accuracy of up to 99.7% with a minimal amount of 0.06% false positives is achieved
by the proposed algorithm.
The research only covered the classiﬁcation aspect without considering vital
information which can affect the results, especially, in case of limited text in the
email.
Yüksel et al. [8] aimed to resolve the problem of spam by inhibiting the spam
emails from being spread within the email systems. To achieve this, they propose a
cloud base system, which involves the identiﬁcation of spam emails using analytics
and machine learning algorithms like support vector machines and decision trees.
The results of the tests show that the SVM leads to higher accuracy of up to 97.6%
and a false-positive rate of 2.33%. The decision tree attains a lower accuracy of
82.6% and a false-positive rate of 17.3%. Results reveal that the increase in spam
emails is affected by the no. of received emails. Lee et al. [10] proposed an optimal
technique for spam detection.

278
M. Sethi et al.
2.1
Existing System
2.1.1
Non Machine Based Learning
Numerous early anti-spam methods [11] belong to the present category; a few speci-
mens for this can be usage of blacklisted spammers, whitelists of certain sources, or a
corpus of man-made terms, like “make wealthy”. Nevertheless, there is a possibility
that static lists like these might be employed by spammers, like altering or spooﬁng
the domain or the address of the sender. Now spammers have mastered the art of
avoiding or bypassing terms on purpose or avoiding ﬁlters of spam. This has made
constant manual alterations a necessity, and there is a high danger of screening out
genuine messages. According to estimates given by the British Computers Society,
an imperfect anti-spam technology could cost as high as 5 million operating hours
in a year for users to verify.
Heuristics Beneﬁts: Mail ﬁlters that are Heuristic are considered straightforward,
tremendously accurate, and powerful for regulative speech.
Limitations: Mail ﬁlters that are Heuristic do not possess intelligent learning
capacity (not suited for new SPAM features); they let manager interference for 2
modiﬁcations, in the sequence that rule alterations or the set guidelines have to be
updated irregularly, furthermore, when sensitivity increases for inﬂated rates of false
positives.
Beneﬁts: Some of the high beneﬁts include support of collision hash functions
at high resistance and production of low levels of false positives in signature mail
ﬁlters.
Limitations: The signature mail ﬁlters do not hold practicality of intelligent
learning (in the case of latest SPAM emails hazards are not acknowledged), allows
user to refresh the SPAM hash list or from a delivery server, the list is regularly
fetched and upon updating, the pre-known SPAM emails are not determined by the
ﬁltering system. Altered pre-know SPAM emails give rise to a hash that is separate
from the already-existing ﬁltering system hash. After this, the upgraded SPAM email
goes through the ﬁltering system.
Beneﬁts of Blacklists: Blacklist ﬁltering or white-listing are considered fast, simple
and uncomplicated to implement.
Limitations: A sender’s email address can be easily spoofed. This happens to be
one of the biggest drawbacks in terms of blacklisting or white-listing ﬁltering.
Trafﬁc Analysis Beneﬁts: For trafﬁc analysis, mail ﬁltering is deemed sophisticated
in comparison. This procedure, however, suggests improved and fast mail ﬁltering
as compared to genuine email content analysis as they evaluate only SMTP logs.
Limitations: Absence of polished learning skills in spam ﬁlter of mail analysis
(new SPAM features are not answered). At this point, determining the email trafﬁc
specifying attributes that are most appropriate for an exact email trafﬁc collection is
not achievable [2].

Spam Email Detection Using Machine Learning and Neural Networks
279
2.1.2
Machine Based Learning
Targeting standard technologies, Machine Learning approaches transcribe the
acquired output of the messages dynamically and then further create reliable models.
Hence, we can be more additional, interminable, and distinguished to deal with spam-
mers. Many Machine Learning procedures have been used, including spam ﬁltering
[12].
Bayesian Beneﬁts: Bayesian mail ﬁlters make use of Intelligent Modeling (in
Machine Learning) and better ﬁltering that content analysis is targeted on. This allows
email users to make changes to the SPAM form received by the users. Reliability
can, hence, be found in the Bayesian mail ﬁlters.
Limitations: Bayesian ﬁlters compose single word tokens. Value of consecutive
termsisgenerallynotrecognizedbyﬁltersthatarerepresentedasspammerﬁlters.The
term “special offer” in the contents of emails can be considered as an example. Also,
each term is evaluated independently. Other phrases and various terms can be found
usually within SPAM emails. If terms like these are unknown, a restriction is created
in the performance of the ﬁltering for identiﬁcation of the aforementioned SPAM
emails. However, there are other algorithms that are already available which help in
the evaluation of permutations of single words, words at intervals, and successive
words as well.
Gray Listing Beneﬁts: Gray listings make detection of SPAM emails fast, simple
andeffective.Theformatofstandardmailprotocolisusedhere.Hence,implementing
external hardware or software packages is not required. It provides a secure method
of keeping SPAM emails under control and also rejecting (removing) messages that
are on spamming sites. Prevention of spamming server zombie computers is seen to
be successful by the system.
Limitations: Even though Gray listings seem effective, they cannot be accepted
as a thorough anti-SPAM [11] remedy. This can prove to be a major inconvenience
for emails that require a prompt response. A situation that ﬁts here can be a request
from a website for user feedback via email so that the user can ﬁnish their domain
registrations. One other limitation that can be observed here is if an email is not
received by the source within its waiting time, then the session of the email ends,
resulting in the source mail server getting blocked by the receiver mail server [2].
Due to the increase in the number of email users, the amount of spam emails has
also risen in number in the past years. It has now become even more challenging
to handle a wide range of emails for data mining and machine learning. Therefore,
many researchers have executed comparative studies to see various classiﬁcation
algorithm’s performances and their results in classifying emails accurately with the
help of a number of performance metrics. Hence, it is important to ﬁnd an algorithm
that gives the best possible outcome for any particular metric for correct classiﬁcation
of emails and spam or ham.

280
M. Sethi et al.
3
Proposed Methodology
The dataset is taken from SpamAssassin [13], 2500 non-spam messages belong
to easy_ham and they should be easily differentiated from spam. Instead of using
sophisticated and hybrid models, this study relies on relatively simple classiﬁcation
algorithms to solve this problem like Logistic Regression, Naive Bayes, and Support
Vector Machine. The concept of Neural Networks is also used to select the best
activation function for spam detection.
The dataset is in the form of HTML ﬁles which are converted into plaintext during
text preprocessing. This paper has used two feature sets to ﬁnd the most optimal
feature set and respective models.
In order to perform efﬁcient operations, Compressed Sparse Row (CSR) is used
to feed data to models. Hence, the data is converted into a compressed sparse row
matrix format for modeling.
A perfect (or best) model should be the one that reduces underﬁtting or overﬁtting.
There are three practices for identiﬁcation. They are datasets splitting, cross valida-
tion, and bootstrap. In the proposed work to prevent underﬁtting and overﬁtting, the
modeling results will be evaluated ﬁrst through a tenfold cross validation score, and
then evaluated by evaluation metrics of classiﬁcation (Fig. 1).
Data from Spam Assassin 
Stop words removal, stemming, 
normalization of plaintext 
Stemming and punctuation removal 
Form a vocabulary with most 
frequent words count 
Compute tf-idf statistic and convert 
into a compressed sparse matrix 
Partition dataset in 20-80 ratio of 
training and testing samples
Parse Email to Plain Text 
10 cross fold validation 
Fig. 1 Flow chart for methodology

Spam Email Detection Using Machine Learning and Neural Networks
281
Fig. 2 Data set ﬁles record
3.1
Data Set Reading and Inspection
The Data set has been taken from Spam Assassin [13]. It consists of nearly 5000 email
ﬁles. These emails taken from Spam Assassin are used so that models can be created
that can distinguish between spam and ham (non-spam) emails. The email data
consists of either spam or hams. Spams, aka junk emails, are unsolicited messages
sent in bulk by email. Hams are non-spams expected by email recipients. Data is read
and inspected according to the existing kernel method. Each ﬁle in the data source
represents an email message (Fig. 2).
All emails can be read by the python email package.
Emails are in Html format and can be seen clearly in Fig. 3 and contains 2 ﬁelds
namely header and message ﬁeld along with message contents. The python package
grants us the ability to read the emails in the dataset. All emails can be read by the
python email package.
3.2
Text Preprocessing
In this section, the email structure will be extracted and the content of the emails will
be converted to plain text for the text analysis. This is executed through the following
functions on the existing kernel as shown below:
• Get Structure of Emails
This function is used to differentiate structures of lines/words in emails (Fig. 4).
Fig. 3 Email ﬁle from dataset

282
M. Sethi et al.
Fig. 4 ‘Get structure of
emails’ function ﬂow
In the following algorithm, email python package is used to read email and a
parser is used to identify the structure of a particular email. This is done to get pure
text content from dataset.
This Function returns an output as mentioned in Fig. 5. Such that structural
visualization can be done on the input and possible plain content can be extracted
later.
• HTML to Plain Text
This Function is used to get plain text emails as some email ﬁles in the dataset are
read in HTML format with HTML tags present which need to be removed as we
work on plain content (Fig. 6).
• Emails to Plain Texts
This function is a driver of all the functions and works as depicted in the ﬁgure
below. It is the ﬁnal function which calls the above functions to return the emails in
the dataset to plain text emails with their content (Fig. 7).
Fig. 5 Structure of ham and spam emails

Spam Email Detection Using Machine Learning and Neural Networks
283
(a)
(b)
Fig. 6 a Conversion to plain text. b Html ﬁle
Fig. 7 Emails to plain texts’ function ﬂow
3.3
Feature Sets and Vectorization
Feature extraction and selection methods have been facilitated by python’s sklearn
and NLTK library. Two feature sets were prepared for the modeling task:
• The feature set 1—Stopwords with N-gram and Term Frequency Inverse Docu-
ment Frequency (tf-idf).
• The feature set 2—Most Frequent Word Count with Count Vectorization.
Feature Set 1
Its motive of creation was to explore the text structure of the plain content and
exploit the contextual features. For this feature selection, the use of methods like

284
M. Sethi et al.
Fig. 8 Feature selection methodology
simple stopwords and n-grams and then term frequency like tf-idf weighting has
been done.
wi, j = t f i, j × log
 N
d f i

where, tf i,j is number of occurrences of i in j, df i is number of documents containing
i and N is total number of documents.
N-grams are permutations of word combinations. They help in providing context
to the text by combining nearby words and making a single feature out of them
(Fig. 8).
Feature Set 2
It is created by converting a string to a list of words then using the word index
increasing the count of them. It is based on counting the most frequently occurring
words from the email content (Fig. 9).
The extracted features are ﬁrst converted into vectors and then into a compressed
sparse row (CSR) matrix and then they are fed into different classiﬁers such as Naive
Bayes, Logistic Regression, Linear SVM, and Artiﬁcial Neural Network with the
help of a pipeline for faster efﬁciency.
Fig. 9 Feature selection methodology

Spam Email Detection Using Machine Learning and Neural Networks
285
3.4
Pipeline and Modeling
A pipeline is created so it’s easy to compare different models and feed data to them
with their feature set. The models being used and metrics to compare them are shown
as below:
• Naive Bayes
The Naive Bayes algorithm for multinomial distributed data or Multinomial Naive
Bayes Algorithm is one of the classic naive Bayes variants which is used for text
classiﬁcation (preferably where the data are typically represented as word vector
counts or tf-idf vectors in practice) [14].
• Logistic Regression
The logistic regression model uses the logistic function to squeeze the output of
a linear equation between 0 and 1. The logistic function is deﬁned as:
logistic(η) =
1
1 + exp(−η)
Dependent variables are incorporated in the Logistic Regression [15] techniques
that denote binary values (0 or 1, true or false, yes or no), implying that the results
can only be in two forms.
• Support Vector Machine
Support Vector Machine or SVM is one of the foremost in style Supervised
Learning algorithms [16], that is employed for Classiﬁcation similarly as Regres-
sion issues. However, primarily, it’s used for Classiﬁcation issues in Machine
Learning.
The goal of the SVM rule in the research is to make the simplest line or call
boundary that may segregate n-dimensional space into categories (ham or spam)
in order that we will simply place the new information within the correct class
within the future. This best call boundary is termed a hyperplane [17].
• Neural Network
The neural network used is an MLPClassiﬁer. The multilayer perceptron (MLP)
is a feedforward artiﬁcial neural network model that maps sets of input data onto
a set of appropriate outputs. The nodes of the layers are neurons using nonlinear
activationfunctionsforclassiﬁcation,andtheactivationfunctionusedintheneural
network is tanh activation function [18].
The MLP consists of two hidden layers with one input layer and one output layer.
And each layer is fully connected to the following one. The nodes present in the
hidden layers are 6 and 2 (h1 layer has 6 nodes while h2 layer has 2 nodes). Weight
biasing and hyper tuning parameters of the neural network is done with sklearn
help to provide better efﬁciency and performance (Fig. 10).
The evaluation criteria are simply based on the following evaluation metrics:

286
M. Sethi et al.
Fig. 10 Neural network
design
• Accuracy
• Precision
• Recall
• F1 score.
These four factors comprehend the performance of a model with the feature set.
Using these Numbers with Cross Validation Scores we can ﬁnd the best performance
model.
4
Results
In the Fig. 11a, b, it is shown how different models perform with these respective
metrics. The results show that in feature set 1, Neural Network has the best perfor-
mance on this dataset in the model, while SVM having a slightly better performance
than logistic regression classiﬁer. The same can be perceived from the Table 2 scores.
As shown in Table 3 it can be seen that still artiﬁcial neural network has the
highest detection rate of whether a ﬁle is a spam or ham. Also as shown by recall
and F-Score it can be seen that the Neural Network out-performs every other model.
However, these results were seen in on the dataset comparatively smaller than real
world emails and the emails were relatively easier to identify due to them being of
easy-ham category. If the model is trained with a more diverse dataset with emails
from various different domains, obtaining a much more robust and accurate classiﬁer
is not too far-fetched.

Spam Email Detection Using Machine Learning and Neural Networks
287
(a)
(b)
Fig. 11 a Graphs of Evaluation metrics: accuracy; Precision. b Graphs of Evaluation metrics:
recall; F-score
5
Conclusion
The importance of email spam detection has grown in recent years, due to the rise
in the number of spam emails and the ever increasing issues that come with it.
Differentiating spam emails from required ones is a task that is crucial. This research
presents numerous machine learning methods such as Logistic Regression, Support
Vector Machine, Naive Bayes, and Neural Network to help in detection of spam
emails. Neural Network is the machine learning technique that provides the highest
accuracy; nonetheless, this research makes use of a very basic feature extraction
technique that extracts features to give out the highest outcome. While the results
show extremely high accuracy, an even more advanced feature extraction algorithm,
one that is able to perform sentiment analysis, can be used here to improve its feature
selection, providing an in-depth means of analysis of emails. One other concern is
that while every other content of the emails is analyzed by the model, the imagery and
other attachments are left untouched. Using computer vision techniques to extract
information from images and documents in the email can also add to the feature
extraction process, hence improving analysis [19].
One of the most signiﬁcant observations that have been in recent research is that
real world data is preferred wherever possible. In order to protect its customers’

288
M. Sethi et al.
Table 2 Feature set 1 outputs
Feature
Model_name
cv_score_mean
cv_score_std
Accuracy
Precision
Recall
F1
0
stopword + n-gram + td-idf
NB-multinomial
0.9222
0.0162
0.9394
0.9877
0.63
0.7730
1
stopword + n-gram + td-idf
LR
0.8849
0.0094
0.8903
0.9933
0.33
0.4962
2
stopword + n-gram + td-idf
SVM
0.9509
0.0153
0.9591
0.9877
0.75
0.8571
3
stopword + n-gram + td-idf
NN
0.9828
0.0085
0.9869
0.9366
0.98
0.9608

Spam Email Detection Using Machine Learning and Neural Networks
289
Table 3 Feature set 2 outputs
Feature
Model_name
cv_score_mean
cv_score_std
Accuracy
Precision
Recall
F1
0
Word
count
NB-multinomial
0.9803
0.0073
0.9787
0.9579
0.61
0.9333
1
Word
count
LR
0.9861
0.0086
0.9885
0.9933
0.93
0.9637
2
Word
count
SVM
0.9795
0.0095
0.9853
0.9505
0.96
0.9552
3
Word
count
NN
0.9873
0.0078
0.9902
0.9608
0.98
0.9703
private information, many email service providing companies do not prefer to
disclose their data on various certiﬁed spam emails, leading to scarcely available real
world data on emails. There has been an indication of poor performance of models
that have been trained on artiﬁcial or synthetic data when applied to real world prob-
lems [20], which can cause spam detection accuracy to deteriorate as compared to
theoretical results; however, using unsupervised machine learning methods can help
eradicate this issue as well as provide equally good results while also saving uptime.
An alternative method can be to use adaptive learning with data acquired by the
model during its working and hence using more real world data.
As shown in Fig. 4, all the models based on the Feature Set 2 ‘most-frequent-
word-count’ have a higher Accuracy and F1 score as compared to those based on the
Feature Set 1 ‘stopwords + n-gram + tf-idf’. If the use case is to introduce a beta
version of an email spam detector like no-spam in the inbox. In this case, the model:
Neural Network with tanh activation function and the Feature Set 1 ‘stopwords +
n-gram + tf-idf’ serves this purpose. According to the graphs in Fig. 4, if the use case
is to introduce an email spam detector to reduce bad user experience in searching
for important emails from junk mailboxes and ﬁltering spam from the inbox. In this
case, Neural Network with a feature set 2—‘most frequent word count’ gives a better
user experience in general. The future work includes testing the model with various
standard datasets.
In terms of individual feature sets, in Feature Set 1 ‘stopwords + n-grams +
tf-idf’, Neural Network performs the best, giving the highest accuracy among all
machine learning techniques, whereas the lowest accuracy is achieved by Logistic
Regression. However, in Feature Set 2 ‘most-frequent-word-count’ Logistic Regres-
sion is not the lowest performer, the least accuracy is achieved by Naive Bayes and
the best accuracy is attained by Neural Network. Although it can be seen that as a
whole, the same techniques perform better in Feature Set 2 rather than Feature Set 1,
showing a noticeable difference between the two for each machine learning method.
This research proposes that the outcome that is obtained should be compared with
additional spam datasets from various sources. Also, more classiﬁcation and feature
algorithms should be analyzed with email spam dataset.

290
M. Sethi et al.
References
1. Mohammed, M. A., Mostafa, S. A., & Obaid, O. I. An anti-spam detection model for emails
of multi-natural language.
2. Mallampati, D., & Hegde, N. P. (2020). A machine learning based email spam classiﬁcation
framework model. IJITEE, ISSN, 9(4), 2278–3075.
3. Cormack, G. V. (2006). Email spam ﬁltering: A systematic review. Foundations and Trends®
in Information Retrieval, 1(4), 335–455.
4. Chen, J. I. Z., & Smys, S. (2020). Social multimedia security and suspicious activity detection in
SDN using hybrid deep learning technique. Journal of Information Technology, 2(02), 108–115.
5. Siponen, M., & Stucke, C. (2006). Effective anti-spam strategies in companies: An international
study. In Proceedings of the 39th Annual Hawaii international conference on system sciences
(HICSS’06).
6. Mallampati, D., Chandra Shekar, K., & Ravikanth, K. Supervised machine learning classiﬁer
for email spam ﬁltering, © Springer Nature Singapore Pte Ltd. 2019 and Engineering. https://
doi.org/10.1007/978-981-13-7082-341.
7. Gupta, H., Jamal, M. S., Madisetty, S., & Desarkar, M. S. (2018, January). A framework for
real-time spam detection in Twitter. In 2018 10th international conference on communication
systems & networks (COMSNETS) (pp. 380–383).
8. Mahmoud, T. M., & Mahfouz, A. M. (2012). SMS spam ﬁltering technique based on artiﬁcial
immune system. International Journal of Computer Science Issues (IJCSI), 9(2), 589.
9. Akinyelu, A. A., & Adewumi, A. O. (2014). Classiﬁcation of phishing email using random
forest machine learning technique. Journal of Applied Mathematics.
10. Yüksel, A. S., Cankaya, S. F., & Üncü, ˙I. S. (2017). Design of a machine learning based
predictive analytics system for spam problem. Acta Physica Polonica, A., 132(3); Goodman,
J. (2004, July). IP Addresses in Email Clients. CEAS.
11. Androutsopoulos, J. Koutsias, K. Chandrinos and C. D. Spyropoulos, “An experimental
comparison of naive Bayesian and keyword-based anti-spam ﬁltering with personal email
messages,” Computation and Language, pp. 160–167, 2000.
12. Huang, L., Jia, J., Ingram, E., & Peng, W. Enhancing the naive bayes spam ﬁlter through
intelligent text modiﬁcation detection. In 2018 17th IEEE international conference on trust,
security and privacy in computing and communications.
13. Apache. (2019). “open-source Apache SpamAssassin Dataset”, https://spamassassin.apache.
org/old/publiccorpus/
14. Vinodhini, M., Prithvi, D., Balaji, S. (2020, March). Spam detection framework using ML
algorithm. IJRTE, 8(6). ISSN: 2277-3878.
15. Brownlee, J. (2016, April 1). Logistic regression for machine learning. The Machine Learning
Mastery. https://machinelearningmastery.com/logistic-regression-for-machine-learning/
16. Zavvar, M., Rezaei, M., & Garavand, S. (2016) Email spam detection using combination
of particle swarm optimization and artiﬁcial neural network and support vector machine.
International Journal of Model Education and Computer Science 68–74.
17. Gandhi, R. (2018, June 7). Support vector machine. The Machine Learning Mastery. https://
towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algori
thms-934a444fca47
18. Smys, S., Basar, A., & Wang, H. (2020). Artiﬁcial neural network based power management
for smart street lighting systems. Journal of Artiﬁcial Intelligence, 2(01), 42–52.
19. Li, X. M., & Kim, U. M. (2012, June). A hierarchical framework for content-based image spam
ﬁltering. In 8th international conference on information science and digital content technology
(ICIDT) (pp. 149–155). Jeju.
20. Mukherjee, A., Venkataraman, V., Liu, B., & Glance, N. S. (2013). What yelp fake review ﬁlter
might be doing? In ICWSM.

Online Appointment Management
System in Hospitals Using Distributed
Resource Allocation Algorithm
B. Jency A. Jebamani, R. Murugeswari, and P. Nagaraj
Abstract Every day, people all around the world strive to make their lives more
comfortable through technological advancements. Nobody anticipates wasting their
time, effort, and money by waiting in line at a counter especially during their hospital
visits. Henceforth, this paper proposed web development as a solution for the patients
to schedule hospital appointments online, with doctors approving them based on their
availability. The developed system aims to regulate the knowledge of patients based
on doctor availability, hospital and specialist schedules, and patient appointment.
The proposed system has been designed within the ASP to automate the day-to-day
activities in a hospital like room activities, admission of latest patient, doctor visits.
The proposed distributed resource allocation algorithm aims to search the availability
ofnearbyhospitalstomakeanappointment.Similarly,oncetheuserhasregisteredfor
an appointment and if the appointment has been accepted by the appropriate doctor,
the user will receive a conﬁrmation email. The proposed model has used Visual
Studio.NET 2008 environment, ASP.NET for frontend processing, and MS-SQL
SERVER 2008 for backend processing.
Keywords Healthcare · Mobile responsive website · Status tracking · Location ·
ASP · Distributed resource
B. J. A. Jebamani (B) · R. Murugeswari · P. Nagaraj
Kalasalingam Academy of Research and Education, Anand Nagar, Krishnankoil, Srivilliputtur,
Virudhunagar, Tamilnadu 626126, India
R. Murugeswari
e-mail: r.murugeswari@klu.ac.in
P. Nagaraj
e-mail: nagaraj.p@klu.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_23
291

292
B. J. A. Jebamani et al.
1
Introduction
People nowadays have a strong interest in technological advancements in order to
make their lives easier. At the same time, technology is becoming an integral part of
our everyday lives. As a result, the researchers strive to integrate emerging technolo-
gies with real-time applications in order to make our lives easier. In this perspec-
tive, the proposed research work has developed an online appointment management
system for hospitals. In today’s world, people are not ready to go to the hospital
and wait in a queue for consulting the doctors. This research work has developed a
website to digitally handle patient appointment scheduling for hospitals.
The online appointment scheduling system reduces time, energy, and cost. The
developed website for hospital appointment booking can arrange an appointment in
one click irrespective of their location. Without requiring any human labor, patient
databases may be simply kept and maintained for a long period.
2
Literature Survey
Xiao et al. [1] proposed an online appointment ﬁxing website for the diagnosis of the
patients like radiotherapy, nuclear medicine, etc. The author has used the nonlinear
integer programming model for scheduling the appointment for patients based on
their available dates. This method was developed in West China Hospital (WCH) for
the convenience of the patients without wasting time, energy, and effort. Liang et al.
[2] comparing the intelligent appointment system with a normal ofﬂine appointment
system. The author has used the First Come First Serve (FCFS) simplest scheduling
algorithm for their patient’s appointment by checking the availability of doctors. At
the same time, the author has compared the matching degree of doctors and patients
for their appointment and also helps them to ﬁnd the right doctor for their health
checkups. Aburayya et al. [3] proposed the hybrid appointment system for health-
care in Dubai. The author used Variable Neighborhood Descent Algorithm (VNDA).
It is mainly used for primary health centers. Liu et al. [4] proposed the system for
outpatient appointment system. The author used Latent Dirichlet Allocation (LDA)
topic model for scheduling the outpatient. This may improve the service of the
hospital. But they have that system only for outpatients. Li et al. [5] proposed the
cloud-based health care system by using the greedy-based heuristic algorithm. By this
the patients can receive their treatment methods online it may reduce their cost and
time. This plays as a bridge for community and tertiary hospitals. In that, the author
faced that planning and scheduling are the main problems in for the cloud-based
system. Khalid et al. [6] developed a mobile application that has a web appointment
booking system. the web appointment booking system is an Associate in Nursing
on-the-go appointment booking system that helps patients schedule a brieﬁng with
their most popular doctor. the most plan of this work is to produce ease and luxury to
patients and it conjointly resolves the issues that the patients face whereas creating a

Online Appointment Management System in Hospitals …
293
brieﬁng. This application is used for only patient appointment booking. Kumar et al.
[7] developed a web-based application for appointment booking where patients can
book their appointment for the concerned doctors. Doctors can log in by their user-
name and password. Once the doctor saw the patient’s appointment, they approve
their appointment. Akinode et al. [8] focused on developing a system to reinforce
the efﬁciency and quality of delivering an internet-based appointment system to cut
back waiting time. throughout this paper, a patient appointment and programming
system is meant to exploit Angular JS for the frontend, Ajax substructure for holding
client-server requests, and Sqlite3 and MYSQL for the backend. Odeh et al. [9]
developed the mobile application “Mwa3edk” to feature new ideas for the tactic
of getting appointments with doctors in hospitals and medical clinics by transfer-
ring the manual appointment registration into a digital online registration process.
This method connects users with a large number of hospitals and clinics around the
UAE, allowing us to ﬁnd doctors in a variety of places and schedule appointments
that are convenient for us. Furthermore, users may explain their symptoms, and the
device will provide recommendations based on what they have drawn. This may
allow users to skip a stage, where they must make an appointment. Cola et al. [10]
proposed a solution for the online technologies to handle the doctor appointment.
If the doctor and patient decide, they have a video consult rather than a traditional
visit to the doctor’s workplace. The appointments have created support on time slots
interval available in an exceeding day. These time slots are outlined by the doctor or
a delegated person. Video appointments are created within a web browser; no further
package is required. Bensbih et al. [11] describe the aspects of online appointment
scheduling for external specialization doctors in the Moroccan using a qualitative
approach analysis. Bensbih et al. [12] proposed the online appointment system for
patients to book their appointments on free dates and at the same time, it is used in one
hospital or clinic. Khan et al. [13] developed an android application for appointment
booking for patients. It is a customizable and user-friendly application but in this
application, we can’t able to locate the hospitals or clinics. Nazia et al. [14] focused
on the detailed study of online appointment scheduling systems with architecture
and merits, which may help the patients or not.
According to a review of the literature, they can all develop a website for a primary
health center or a single hospital or clinic. However, our study recommended adding
several hospital numbers to a single website with full data of the hospitals, as well as
physicians, who work in the hospitals along with the map location of the hospitals.
Patientscanbookappointmentontheirfreedates.Oncetheappointmentwasaccepted
by the doctor, automatically the acceptance mail is sent to the patient with full details
of their appointment booking.
3
Proposed System
Any hospital can use the developed online appointment management system to
replace their traditional paper-based system. The new technology will be used
to manage patient data. Doctor accessibility, speciﬁc list schedules, and patient

294
B. J. A. Jebamani et al.
Fig. 1 Architecture diagram of a website
invoices are considerable parameters. These service square measures can be provided
in an associate degree economical, value-effective manner, to reduce the time and
resources presently required for performing such tasks. This process is converting
the user-oriented input into the computer-based format. The goal of designing input
data is to make data entry as easy as possible and free from errors.
Figure 1 describes the architecture of the website. In the database, doctors
searchingforappointmentacceptance,patientquery,andresendqueryarecompletely
encrypted. Only the administrator with perfect authentication can gain access to all
records. At the same time, appointments of the patients are scheduled automatically
and the overall database of the website is enrolled in the SQL management server,
where the entered data will be stored in the database and also the user can also easily
edit and store the data in the database.
3.1
Module Description
There are some modules for the appointment book. These modules help us to collect
data from the patients and store them in the database. Further, by using these modules,
admin can monitor the receptionist’s activities and patient’s record requests and
security key generation for records. The proposed model includes the following
modules:
• Admin Module
• Patient Module
• Doctor Module
• Appointment Module
• Reporting Module.

Online Appointment Management System in Hospitals …
295
3.1.1
Admin Module
Admin will add the information about hospital, patients, and doctors. Admin also
has the access to modify the information. Also, the proposed model will look out
for the patient and it will also plan appointments for doctors via the appointment
module. Also, different roles are assigned to various staff members, similar to how
front-desk hospital employees may arrange or schedule appointments. Admin may
also look at physicians’ and patients’ information, as well as doctor and appointment
information. A patient may also be issued a walk-in appointment or be issued a
previously scheduled appointment.
3.1.2
Patient Module
The patient module can have the choice to look at the patient history/report, doctor
history, etc. The report will comprise the prescribed medications. Hospital visit wise
reports can also be viewed by a doctor simply before checking any patient. This
module is solely accessible to doctor and admin. Also, the choice is provided to print
reports like visit reports, medication history reports, etc.
3.1.3
Doctor Module
The doctor can also check the schedule and meet the patients. The doctor can also
save the information associated with the patient’s ill health, history of the patient,
the affected organ will also be noted. Separate choices are provided for saving this
information. The doctor can also read the patient-connected visit information within
the variety of a report. The doctor will bring down medications and the choices are
supplied with the same medications. The doctor is supplied with the choice to save
the dietary information if available.
3.1.4
Appointment Module
This module will allow admin and front-desk staff to view appointments using a
doctor login. It will allow to take pre-booked appointments as well as walk-in visits.
There will also be an option to select the doctor for whom the appointment must be
reserved or allotted for walk-in appointments. The option to cancel or change sched-
uled appointments, such as changing the assigned doctor or altering the appointment
date is also available.

296
B. J. A. Jebamani et al.
3.1.5
Reporting Module
The reporting module was designed to provide a feature-rich and user-friendly
websiteformanagingreportspresentwithinAdmin.Inaddition,thereportingmodule
provides ﬂexibility and extensibility in this project. Admin also provided an option to
generate the user report, order report, and request report. All the reports will provide
an overview of the project details.
3.2
Distributed Resource Allocation Algorithm
In distributed systems, resource allocation is based on the search resource. For
example, if the patient requires information on a local hospital in a speciﬁc region.
This method helps to locate the proper source of information from the category
section provided for patients. It returns the hospitals in a given city that fall into the
categories of specialized, general, and child specialists.
Step 1: D0<- Generate M individuals (the initial population) at random.
Step 2: Dsel-1<- Repeat steps of 3–5 for 1 = 1, 2, until the stopping criteria are
met.
Step 3: select N ≤M individuals from Dl-1 according to the selection method.
Step 4: pl(x) = p(x|Dsel-1)<- Estimate the probability distribution of an individual
being among the selected individuals.
Step 5: Dl<- Sample M individual (the new population) from pl(x).
3.3
Data Flow
This explains the data ﬂow at the admin level and user level.
3.3.1
Admin Level
In the admin module, they can access the doctor and patient registration. Once the
patient login to the website, admin collects their data and stores it into the database
for future use.
3.3.2
User Level
In the user module, once they login they gain the ability to search the particular
hospital or doctor. If people wish to travel to a child specialist hospital in Madurai,
for example, they just search the district and select child specialists in the category
area, which displays all of the -child specialist hospitals in Madurai.

Online Appointment Management System in Hospitals …
297
4
Experimental Result
The software requirements are Visual Studio.NET 2008, MS-SQL SERVER 2008
for backend, ASP.NET for frontend. There are some options to add hospitals and
doctors’ details on the website.
Figure 2 shows the registration for the hospital. It includes the hospital name,
address, city, landmark, a specialist doctor in which category, contact number, and
their email. id.
Figure 3 shows the number of hospitals that are added to the website for appoint-
ment booking. For any review, the view option helps to see the full details of
hospital or delete certain hospital data if not required. Using the distributed resource
algorithm, it can search the nearby hospitals and enter the category of doctors.
Select the city you want and the doctor category you want, such as cardiology,
orthopedics, neurology, and so on, as illustrated in Fig. 4.
Fig. 2 Hospital registration
Fig. 3 View hospital

298
B. J. A. Jebamani et al.
Fig. 4 Searching the concerned doctor
Figure 5 depicts the results of a search for specialists in Madurai. On the same
page, you may change the city and category without going back.
Figure 6 shows that the concerned hospital may be searched by categories such
as specialist, child specialist, and general at the same time by utilizing search
Fig. 5 Searched result

Online Appointment Management System in Hospitals …
299
Fig. 6 Searching of hospital
hospital option. The search result displays the hospital’s address, phone number,
email address, and landmark.
The add hospital option’s location is instantly updated in the view map section
if the hospital name is provided correctly, as shown in Fig. 7. When you click the
see map button in the hospital’s detail page, you’ll be sent to a Google map with the
hospital’s location.
The appointment of the patients planned in the admin module is shown in Fig. 8,
along with the status of the appointment (accepted or rejected).
Fig. 7 Map location of the hospital

300
B. J. A. Jebamani et al.
Fig. 8 Patient’s appointment
5
Conclusion
The primary goal of this article is to develop a web-based solution for hospital
appointment booking. In one click, the distributed resource algorithm looks for his
or her appointment registration at a nearby hospital. The proposed model gains the
ability to add the greater number of districts, hospitals, and doctor’s proﬁles in this
one website, where Google map is also integrated, So once the hospital names were
entered correctly, the location of the hospital was added in the user search and it is
also user-friendly. Future development will include adding an online pharmaceutical
website to the patient’s prescription and allowing them to simply purchase their
medication.
References
1. Xiao, Q., Luo, L., Zhao, S. Z., Ran, X. B., & Feng, Y. B. (2018). Online appointment scheduling
for a nuclear medicine department in a Chinese hospital. Computational and mathematical
methods in medicine.
2. Liang, Y., & Zhao, L. (2019). Intelligent hospital appointment system based on health data
bank. Procedia Computer Science, 159, 1880–1889.
3. Aburayya, A., Al Marzouqi, A., Al Ayadeh, I., Albqaeen, A., & Mubarak, S. (2020).
Evolving a hybrid appointment system for patient scheduling in primary healthcare centres
in Dubai: Perceptions of patients and healthcare provider. International Journal on Emerging
Technologies, 11(2), 251–260.
4. Liu,T.,Ma,Y.,&Yang,X.(2018,October).Servicequalityimprovementofhospitalreservation
system based on text sentiment analysis. In 2018 9th International Conference on Information
Technology in Medicine and Education (ITME) (pp. 289–293). IEEE.
5. Li, Y., Wang, H., Li, Y., & Li, L. (2019). Patient assignment scheduling in a cloud healthcare
system based on petri net and greedy-based heuristic. Enterprise Information Systems, 13(4),
515–533.

Online Appointment Management System in Hospitals …
301
6. Khalid, M., Singh, S., Singh, K., Jeevitha, J., & Anand, P. (2018). Medicus: A doctor
appointment bookingsystem. International Journal of ComputingandTechnology,5(4),48–52.
7. Kumar, S., Kiran, J., kumar, V., Saranya, G., & Ramalakshmi (2019). Effective Online Medical
Appointment System. International Journal of Scientiﬁc & Technology Research, 8, 803–805.
8. Akinode,J.L.,&Oloruntoba,S.A.(2017).Designandimplementationofapatientappointment
and scheduling system. Department of Computer Science, Federal Polytechnic Ilaro Nigeria.
9. Odeh, A., Abdelhadi, R., & Odeh, H. (2019, December). Medical patient appointments
management using smart software system in UAE. In 2019 International Arab Conference
on Information Technology (ACIT) (pp. 97–101). IEEE.
10. Cola, C., & Valean, H. (2015, November). E-health appointment solution, a web-based
approach. In 2015 E-Health and Bioengineering Conference (EHB) (pp. 1–4). IEEE.
11. Bensbih, S., Bouksour, O., Souadka, A., Majbar, M. A., & Rifai, S. (2020). Esupply chain
management in healthcare: Facilitating Factors and Challenges. International Journal of
Management, 11(9).
12. Bensbih, S., Bouksour, O., & Rifai, S. (2019, April). On line appointment systems in a patient
centric strategy: a qualitative approach in a case study for hospitals in Morocco. In 2019
6th International Conference on Control, Decision and Information Technologies (CoDIT)
(pp. 1735–1739). IEEE.
13. Khan, M. N. R., Mashuk, A. K. E. H., Durdana, W. F., Alam, M., Roy, R., & Razzak, M.
A. (2019, July). ‘Doctor Who?’-A Customizable Android Application for Integrated Health
Care. In 2019 10th International Conference on Computing, Communication and Networking
Technologies (ICCCNT) (pp. 1–6). IEEE.
14. Nazia, S., & Ekta, S. (2014). Online appointment scheduling system for hospitals–an analytical
study. International Journal of Innovative Research in Science, Engineering and Technology,
4(1), 21–27.

BeFit—A Real-Time Workout Analyzer
Richard Joseph, Manoj Ayyappan, Tanvi Shetty, Gurudatt Gaonkar,
and Aashish Nagpal
Abstract Maintaining one’s physical ﬁtness is of utmost importance. Exercising
regularly is very important as it helps improve the quality of life. However, incorrect
posture during exercises may lead to severe long-term injuries such as back pain,
Tendinitis or even hamstring strains. Hence, this application BeFit is proposed that
analyzes the posture of the user performing a particular workout by comparing their
workout to the reference image or video provided by the system. The system will
analyze the angles between the limbs of the body and compare it to the reference
video or image using the Cosine rule. After synchronizing user and reference image
or video the system gives a green skeleton if the user posture is correct and a red
skeleton if the user posture is incorrect. This model has been achieved using the
PoseNet library on Tensorﬂow. The maximum score that the PoseNet model achieves
ranges from 0.92874 to 0.98325 for all the key points. With the help of this model,
ﬁtness enthusiasts can perform a particular workout accurately at the comfort of their
home without getting injured and with proper guidance.
Keywords Pose detection · Pose estimation · PoseNet · Yoga pose analysis ·
Workout analysis · PoseNet workout analysis · Cosine rule · Skeleton matching
R. Joseph · M. Ayyappan (B) · T. Shetty · G. Gaonkar · A. Nagpal
Department of Computer Engineering VESIT, Mumbai, India
e-mail: 2018.manoj.ayyappan@ves.ac.in
R. Joseph
e-mail: richard.joseph@ves.ac.in
T. Shetty
e-mail: 2018.tanvi.shetty@ves.ac.in
G. Gaonkar
e-mail: 2018.gurudatt.gaonkar@ves.ac.in
A. Nagpal
e-mail: 2018.aashish.nagpal@ves.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_24
303

304
R. Joseph et al.
1
Introduction
Exercising regularly improves well-being and reduces the risk of obesity, diabetes,
and hypertension. To maintain overall health and build strength, the Centers for
Disease Control and Prevention (CDC) recommends adults to strength train at least
twice a week. However, it is difﬁcult to remain consistent and workout regularly.
AccordingtoaresearchconductedbyMintel64%ofIndiansdonotexerciseregularly.
The research also revealed lack of time for exercising as the top barrier with almost a
third (31%) of consumers saying that they don’t have time to exercise. They further
revealed that most Indians tend to choose very basic forms of exercise. About 67%
of Indians who exercise typically do brisk walking The reason for choosing very
basic forms of exercise is the fact that exercises involving gyms and ﬁtness classes
tend to be more expensive. While the 36% that do exercise regularly often end up
causing injuries such as back pain, muscle pulls, and so on due to improper posture
[1] (Fig. 1).
Maintaining correct posture while working out is very important. Incorrect posture
while exercising can lead to long-term injuries such as spine curvature, Tendinitis,
hamstring strains, etc. Apart from injuries, desired results will not be achieved by
people if they continue following poor form during their workout.
Inordertotacklewiththisproblem,auser-friendlysystemcalledBeFitisproposed
that will analyze the posture of a person performing a particular workout session and
comparing it to a reference video or picture and offering suggestions to improve it if
necessary, at the comfort at your own home. The user only requires an android device
with a good camera or a computer with a webcam capable of streaming their workout,
in order to use this application. Using PoseNet on Tensorﬂow, the reference picture
or video will be preprocessed and would compare the limb movements from the
reference video to that of the user and hence detect if the user’s posture is incorrect
Fig. 1 Left image depicts improper posture while right image depicts the correct posture [2]

BeFit—A Real-Time Workout Analyzer
305
or not. This system uses Convolutional Neural Network (CNN) ML algorithm to
identify key points on the user’s body [3, 4].
The paper is organized into three major sections where ﬁrst the methodology
of the system is explained and how they apply to the proposed solution, secondly
the complete system overview is discussed. Finally, the future scope and conclu-
sion follow where the outcome and future possibilities of the proposed method are
discussed.
2
Related Work
Very few applications have been produced related to this topic. But developers have
produced applications which can calculate the accuracy of a workout by using pose
estimation and Deep learning. Most of the applications are formed on Yoga positions.
1.
Amit et al. [3] developed a system—Real-time Indoor Workout Analysis
Using Machine Learning & Computer Vision. Their system analyzes the angle
between limb pairs to detect errors and provide corrective action to the user [3].
They have used techniques for time series data alignment like DTW (Dynamic
Time Warping) along with optical ﬂow tracking using OpenCV to synchro-
nize user/reference videos. Based on the threshold deviation calculated from
the angle between the limbs their system has been able to detect the errors in
user’s activity, i.e., their posture very effectively.
2.
Yadav et al. [4] generated a system—Real-time Yoga recognition using deep
learning. Their proposed system is a hybrid of convolutional neural network
(CNN) and long short-term memory (LSTM) for Yoga pose estimation on
real-time videos. The system has achieved a test accuracy of 99.04% on single
frames and 99.38% accuracy after polling of predictions on 45 frames of the
videos however their system is restricted only to Yoga poses.
3.
Kumar and Sinha [5] created a system—Yoga Pose Detection and Classiﬁca-
tion Using Deep Learning. Their system takes the video input from the user
ﬁrst and then the pose of the user is compared with the pose of the expert and the
difference in angles of various body joints is calculated. Based on this differ-
ence of angles feedback is provided to the user so that he/she can improve the
pose. They have used the PoseNet model to extract the angles between limbs
and have used CNN and LSTM models to compare the angles between limbs.
Their system has achieved 82.84% accuracy using this technique.
4.
Markolefas et al. [6] developed a system—Virtual Video Synthesis for Person-
alized Training. Their system has a camera recording the video of the trainee
during the exercise, which is presented in contrast to the instructor’s video
on the device screen live on the conference call. The accuracy of the trainee’s
workout will be detected live while working out, by comparing the trainee’s and
instructor’s video feed. They have achieved these using techniques including

306
R. Joseph et al.
an initial background reconstruction method followed by a selective updating
scheme.
5.
Borkar et al. [7] Match Pose—A System for Comparing Poses. Their research
focuses on comparing reference video to real-time video in general. They have
proposed a system which presents a simple method to compare users’ real-time
pose with any selected pose. For real-time pose estimation, their system also
uses PoseNet. Their algorithm allows users to check if their pose has been
imitated successfully.
6.
Mehta et al. [8] XNect: Real-time Multi-Person 3D Motion Capture with a
Single RGB Camera—The system works on 30 fps using a RGB camera in
real time to approach multi-person 3D motion. The system starts with a convo-
lutional neural network (CNN) which estimates 2D and 3D pose features and
determines the identity assignments for visible joints. The second stage of the
system uses another CNN considering occlusion to determine the features. In
the ﬁnal stage, space-time skeletal model ﬁtting is applied to the predicted 2D
and 3D pose per subject to further deal with the 2D and 3D pose, and enforce
temporal coherence.
7.
Ding et al. [9] Human posture recognition based on multiple features and rule
learning—Thesystemusesa219dimensionalvectorforcalculatingtheangular
and distance-based features of joints and spatial location of joints The system
makes use of RIPPER rule learning Classiﬁcation algorithm. The system does
not use any traditional CNN approach and is capable of classifying various
algorithms.
8.
Vyas [10] Pose Estimation and Action recognition in sports and ﬁtness. The
goal of their system is to compare two computer vision models. They have
used two approaches: silhouette model and pose estimation. They have created
models using pose estimation techniques and silhouette models to compare
between the two and ﬁnd out the model which gives best accuracy. The dataset
they have used is PennAction dataset for squat exercise action recognition.
Their best model was able to achieve 79% accuracy.
9.
Xiong et al. [11] Robust vision-based workout analysis using diversiﬁed deep
latent variable model. Their main goal is to develop a 3D pose estimation
model which will give more accuracy as to the traditional 2D pose estimation
models. Their proposed system uses a deep latent variable model to estimate
3D skeletons from videos and images. To further improve the model, they have
integrated diversity-encouraging prior to their deep latent variable model.
10.
Cao et al. [12] Real-time Multi-Person 2D Pose Estimation using Part Afﬁnity
Fields—They proposed a system which uses Part Afﬁnity Fields [PAFs]. The
model uses a bottom-up approach which gives high accuracy. It simultaneously
detects and associates part afﬁnity joints and conﬁdence maps. Conﬁdence
maps are used to detect different parts whereas Part afﬁnity decides different
numbers of people and hence the model supports multi-pose detection along
with CNN.
11.
Rishan et al. [13]—Inﬁnity Yoga Tutor: Yoga Posture Detection and Correction
System—The system works in real-time by taking user’s mobile camera taking

BeFit—A Real-Time Workout Analyzer
307
input at the rate of 30fps. The poses are estimated by using Open Pose which
identiﬁes 25 key points on the human body. Further it uses LSTM, CNN and
SoftMax regression algorithms to predict the pose.
12.
Chao et al. [14] Forecasting Human Dynamics from Static Images—They
proposed a 3D Pose Forecasting Network which works on single RGB images
as input. The system makes advances on pose estimation and sequence
prediction in 2D and represents it into 3D space.
13.
Park et al. [15] 3D Human Pose estimation using Convolutional Neural
Networks with 2D pose estimation. The goal of this research is to create an
effective 3D pose estimation model using CNNs. They have achieved this with
two ideas, and ﬁrst they added 2D pose information to estimate a 3D pose from
an image by concatenating 2D pose estimation results with the features from
an image. For the second technique. In the model, they have combined infor-
mation on relative positions with respect to multiple joints instead of just one
root joint.
14.
Fani et al. [16]. Hockey action recognition via integrated stacked hourglass
network—Their system recognizes the actions performed by a hockey player,
i.e., actions performed in a Hockey game. It contains three layers of Action
Recognition Hourglass Network (ARHN). The ﬁrst layer is used for pose
estimation, second for transforming latent features to a common frame of
reference, and the ﬁnal layer for recognizing the action of the Hockey player.
15.
Sawant [17] Human activity recognition with OpenPose and long short-term
memoryonreal-timeimages.Inthisresearchpaper,theyhavecreatedasystem-
atic method of pose estimation using OpenPose and long short-term memory
networks. In their system the OpenPose detects body parts like hands, face,
legs, etc. and the output of the body features is split into sub-sequence called
windows using a sliding window approach. Then they have used long short-
term memory networks to efﬁciently learn the key points features and return
an activity class. The system can detect real-time human activities.
3
Methodology Adopted
The use case diagram below represents the action of the application in the order of
their occurrence. The model is dependent on a pre-trained model by Tensorﬂow.js.
The PoseNet model is pre-trained to estimate the pose of a Person and determine the
position of speciﬁc key body parts with high accuracy. The model which is trained
on the output of PoseNet determines the accuracy and correctness of the Person’s
posture (Fig. 2).
Tensorﬂow.js is a primitive JavaScript library which does not provide much func-
tionality and ﬂexibility to use all its functions. So, the model works with the ml5.js
library which is an extension of Tensorﬂow.js with more functions. This in conjunc-
tion with p5.js was used to implement the pose detection in the web browser. This
model works on all major browsers and it has been tested on Google Chrome, Mozilla

308
R. Joseph et al.
Fig. 2 Use case diagram displaying the working of our system
Firefox and Microsoft Edge browsers. The PoseNet model was included from the
ml5.js library.
The user ﬁrst needs to give permission to the website to access the camera in order
for this to work. PoseNet receives input as video from the webcam of the device and
gives an array as output. This array consists of all the x and y coordinates of the key
points of the body along with the conﬁdence scores of all the points. This is called
the skeleton. It also has a key points array and an overall conﬁdence score. All the
major key points received as output are shown in Fig. 3.
3.1
Working of PoseNet Model
The PoseNet library [18] provides an interface that takes a processed image from
the webcam and gives as output the user’s key body parts. The method runs the
TensorFlow.js interpreter on a processed RGB bitmap and returns a Person object
[19].
There exists a Person class which holds all the locations of the key body parts
and the associated conﬁdence scores [19]. It contains conﬁdence scores for each
individual key point as well as one score for the whole body which is basically the
average of all the conﬁdence scores of each key point. The conﬁdence score indicates
the probability of a key point which could exist in that location. Every key point is
associated with the position of a body part along with its conﬁdence score. Down
below is a list of all the deﬁned key points (Table 1).

BeFit—A Real-Time Workout Analyzer
309
Fig. 3 A PoseNet estimation
of the body Skeleton
Table 1 A list of all deﬁned
key points [20]
ID
Part
0
Nose
1
Left eye
2
Right eye
3
Left ear
4
Right ear
5
Left shoulder
6
Right shoulder
7
Left elbow
8
Right elbow
9
Left wrist
10
Right wrist
11
Left hip
12
Right hip
13
Left nee
14
Right nee
15
Left ankle
16
Right ankle

310
R. Joseph et al.
Fig. 4 Working of PoseNet model [21]
The model captures the input from the camera and outputs the image with key
points drawn on it. The image data from capers is converted to ARGB_888 format
and Bitmap is created to hold the pixel from RGB and the image is resized and sent
to the model. The model gets Person object from PoseNet library and scales Bitmap
to screen size to draw it on canvas. It uses key points obtained from person object to
draw on canvas [21] (Fig. 4).
3.2
Comparison Analysis
There is another human pose estimation algorithm which is widely used—OpenPose.
OpenPose is an open-source human pose estimation library. It detects the human body
key points, facial expression and positions, hand and foot key point extraction. The
OpenPose model gives 15, 18 and 25 key descriptors for a human body. It can run
22 FPS on a system with Nvidia GTX 1080 Ti, on the same device PoseNet gives 10
FPS [22].
The Performance for OpenPose is comparatively better than PoseNet, but Open-
Pose requires a High-powered GPU and is immensely heavy software for mobile
devices compared to PoseNet, PoseNet is Lightweight software and can run on low
powered GPU devices like mobile phones.
To test performances of both PoseNet and OpenPose on mobile devices, we used
a system with Nvidia GTX 285, which is equivalent to GPUs which are being used in
an average mobile device. We Processed a 5 s video with both OpenPose and PoseNet
on our system, OpenPose took 1 min and 11 s to process the video, Compared to
PoseNet which took only 12 s to process the same video.

BeFit—A Real-Time Workout Analyzer
311
Fig. 5 PoseNet drawing
user’s skeleton
As this application is designed for Mobile devices as well, we went with the
PoseNet library for our system.
3.3
Detecting User’s Pose
Two instances of PoseNet are used in the sketch.js ﬁle.
1.
PoseNet1 is the instance which is used for detecting the key points from the
user’s webcam video feed.
2.
PoseNet2 is the instance which is used for detecting the key points from the
reference image that will be given as input.
We have made a canvas of 640 × 850 and on top is the output from the webcam
video feed and in the bottom half, the reference image is placed.
The PoseNet1 detects all the key points from the webcam video feed and gives an
array and a skeleton. Then the lines are plotted connecting all the key points except
the points on the face. The facial key points were not necessary for the system and
hence it is ignored (Fig. 5).
The ﬁnal skeleton is imposed on the video feed in red color on the top half of the
canvas. This skeleton will only be visible if there is a pose detected by the PoseNet
model and the score is greater than 0.2.
3.4
Getting Pose from Yoga/Gym Workout Selected
The PoseNet2 uses the method on the image and detects all the key points from the
reference image that have been provided. The method is important as it is a still image
and the model needs to work only once and does not have to refresh continuously.

312
R. Joseph et al.
Fig. 6 PoseNet on single
image
In this skeleton too, the facial key points are ignored as they contribute very little
to the working of the project. Now this skeleton is white and scaled appropriately
and positioned in the middle of the video feed in the top portion of the canvas.
This will be a guiding tool for the user to align him/her with the desired/correct
pose (Fig. 6).
3.5
Comparing the Skeletons
(1)
Superimposition
One of the ways to compare the skeletons could be to superimpose them but we have
to also keep in mind that all people have different bodies. Some people have shorter
arms, some might have longer legs and so on. So, this method will become a very
challenging task. Also, there will arise another problem that the orientation of these
skeletons has to be matched as well. If the user’s webcam is tilted, the skeletons
would not superimpose correctly, and the system would give wrong results even
if the user is performing the correct workout. Solving this problem by correcting
the orientation would result in more strain on the computing end. This would not
be suitable for the system as it aims to work on low end devices with minimum
computing power. Hence, to solve this problem, instead of actually comparing the
lengths or the coordinates of the key points, comparison of the angles between the
limbs is done [7] (Fig. 7).

BeFit—A Real-Time Workout Analyzer
313
Fig. 7 Angle between limbs [23]
2)
The Cosine Rule
For example, to calculate the shoulder angle, the coordinates of shoulder, elbow and
hip are taken from the skeleton. These points form an imaginary triangle with the
shoulder point as the middle angle. In this way the all the angles between the joints
are calculated and compared. The primary reason why the cosine rule is used is that
it is the only trigonometric formula which gives the angle given 2 sides of a triangle.
It is very easy to calculate the angle and has minimal load or strain on the processor.
For a system which runs on lightweight hardware, this is a prime priority.
The angle is calculated using a formula-
Cos B = (a2 + b2 −c2)/2ac
(1)
where a, b and c are the side lengths and B is the angle to be calculated.
For comparison, the difference between the angle from the reference image and
the angle from the webcam feed is taken. If the absolute value of the difference is
less than 5, the user’s skeleton would turn green in color from red. In this way, the
user can comprehend whether the pose he/she is doing is correct or not (Fig. 8).
3.6
Data Stream Handling
The reference images/videos that have been used for the gym/yoga poses are fetched
from the database and uploaded to the P5 editor. It is then displayed on the screen

314
R. Joseph et al.
Fig. 8 The Cosine rule [24]
based on the workout that has been selected. The user webcam feed is processed and
analyzed in real time in order to achieve the user skeleton. The user data is streamed
directly and processed with the PoseNet model and the skeleton is drawn over the
webcam feed in the canvas of the user’s screen.
4
Final Implementation
The ﬁnal implementation of this project was done using the P5 editor which is avail-
able online for free. Everything is displayed on a canvas which is created according
to the screen size of a standard laptop or mobile device. On the left half of the
screen, the webcam feed is drawn and on the right half, the chosen Gym/Yoga pose
image/video is drawn. The webcam feed is inverted as it is easier to comprehend
mirror images for our brain to follow. The chosen pose is scanned and a white color
skeleton is drawn over the webcam feed. The user’s skeleton is drawn in red/green
color according to the angles calculated. If the user performs the pose correctly, the
skeleton turns green, and the user gets notiﬁed about the same else it is red in color
if the user performs an incorrect pose. Both of the cases are tested and are shown in
Fig. 9.
5
Advantages
• PoseNet works well on lightweight devices such as mobile phones/browsers,
whereas OpenPose requires a GPU powered machine/system.
• On analysis, PoseNet gives accuracy at par with OpenPose, hence using PoseNet
makes the system available on lightweight devices.
• The system deals with multiple step workouts/poses depending on users progress,
i.e., the referenced gym/yoga pose will move to the next step only after the user
has accomplished accuracy in the initial steps which allows users to get a good

BeFit—A Real-Time Workout Analyzer
315
Fig. 9 Actual working of system
grip on their health and will ensure they have executed their particular exercise in
a correct manner.
6
Future Scope
1.
The proposed model right now has a limited number of workouts, the dataset
can be extended by adding more gym workouts and yoga poses to cater to a
larger audience of all ages.
2.
This system can be made more personalized for each user by analyzing the user
data and recommending workouts or videos accordingly.
3.
The system can be further enhanced by integrating a voice recognition system
which will be helpful to play or pause a particular video.

316
R. Joseph et al.
Fig. 10 Accuracy calculated under different conditions
7
Results
The system is taking both image and video as references and both yoga and gym
workout have been incorporated in this model. Therefore, our model is unique
compared to the previously created models. The model achieves acceptable results
in detecting and denoting various joint positions such as shoulders, elbows, hips,
and knee. However, detection of ankles scores poorly and no facial features have
been detected as depicted by (Fig. 9). The model’s ability to track real-time joint
movements is relatively high. The maximum score that the PoseNet model achieves
ranges from 0.92874 to 0.98325 for all the key points.
Testing the model in best, good and bad lighting conditions was necessary as the
room is not always brightly lit. The results say that the model performs satisfac-
torily in good lighting conditions, and it is highly accurate in best lighting condi-
tions. However, the accuracy score suffers in bad lighting conditions and is not
recommended for this model.
An interesting pattern was observed that the accuracy scores of the body parts
became poor going from top to bottom. The body parts which are higher like the
elbows and the shoulders have the highest accuracy, but ankles and knees have a
relatively lower accuracy. This problem does not affect the model in any big way and
the estimation is correct most of the time (Fig. 10).
8
Conclusion
In this paper, we have presented a system for monitoring user workout with help
of a reference video and image. The user will be able to perform exercises with
correct posture as the system will detect and compare the user posture skeleton

BeFit—A Real-Time Workout Analyzer
317
with the reference skeleton and thus provide the user with real-time feedback if
they are having incorrect alignment while performing the workout. Using PoseNet
libraries the model has been achieved. Using this method, the key points are plotted
successfully and a skeleton is created to detect the posture. The goal is to make this
system accessible to all age groups. Hence, our real-time indoor workout analyzer
provides users with professional yoga and gym trainers within their arms reach and
makes their lives simpler.
References
1. Times of India. “64 per cent Indians don’t exercise: Study—Times of India.” The Times of
India, July 3, 2019. https://timesoﬁndia.indiatimes.com/life-style/health-ﬁtness/health-news/
64-per-cent-indians-dont-exercise-study/articleshow/70038656.cms
2. CSCS, Andrew Heffernan. “7 common exercises you’re doing wrong-and how to ﬁx them.”
Openﬁt, August 29, 2020. www.openﬁt.com/common-exercises-wrong-strength
3. Nagarkoti, A., Teotia, R., Mahale, A., & Das, P. (2019). Realtime indoor workout analysis
using machine learning & Computer vision. Conference proceedings: ... Annual International
Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in
Medicine and Biology Society (pp. 1440–1443). https://doi.org/10.1109/EMBC.2019.8856547
4. Yadav, S., Singh, A., Gupta, A., & Raheja, J. (2019). Real-time yoga recognition using deep
learning. Neural Computing and Applications, 31. https://doi.org/10.1007/s00521-019. https://
doi.org/10.1007/s00521-019-04232-7.
5. Kumar, D., & Sinha, A. (2020). Yoga pose detection and classiﬁcation using deep learning.
International Journal of Scientiﬁc Research in Computer Science Engineering and Information
Technology. https://doi.org/10.32628/CSEIT206623
6. Markolefas, F., Moirogiorgou, K., Giakos, G., & Zervakis, M. (2018). Virtual video synthesis
for personalized training (pp. 1–6). https://doi.org/10.1109/IST.2018.8577097
7. Borkar, P. K., Pulinthitha, M. M., & Mrs. Pansare, A. (2019). Match pose—A system for
comparing poses, International Journal of Engineering Research & Technology (IJERT),
08(10) (2019, October).
8. Mehta, D., Sotnychenko, O., Mueller, F., Xu, W., Elgharib, M., Fua, P., Seidel, H.-P., Rhodin,
H., Pons-Moll, G., & Theobalt, C. (2020, July). XNect: Real-time multi-person 3D motion
capture with a single RGB camera. ACM Transactions on Graphics 39. 4, 82, 17 pages. https://
doi.org/10.1145/3386569.3392410
9. Ding, W., Hu, B., Liu, H., et al. (2020). Human posture recognition based on multiple features
and rule learning. International Journal of Machine Learning and Cybernetics, 11, 2529–2540.
https://doi.org/10.1007/s13042-020-01138-y
10. Vyas,P.(2019).“Poseestimationandactionrecognitioninsportsandﬁtness”Master’sProjects.
695. https://doi.org/10.31979/etd.w8ug-4v5c
11. H. Xiong, S. Berkovsky, Sharan R. V., Liu S., & Coiera, E. (2020) “Robust vision-based
workout analysis using diversiﬁed deep latent variable model,” 2020 42nd Annual International
Conference of the IEEE Engineering in Medicine & Biology Society (EMBC) (pp. 2155–2158).
https://doi.org/10.1109/EMBC44109.2020.9175454
12. Cao, Z., Simon, T., Wei, S., & Sheikh, Y. (2017). Realtime multi-person 2D pose estima-
tion using part afﬁnity ﬁelds. IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), 2017, 1302–1310. https://doi.org/10.1109/CVPR.2017.143
13. Rishan, F., de Silva, B., Alawathugoda, S., Nijabdeen, S., Rupasinghe, L., & Liyanapathirana,
C. (2020) “Inﬁnity yoga tutor: Yoga posture detection and correction system.” 2020 5th Inter-
national Conference on Information Technology Research (ICITR) (pp. 1–6). https://doi.org/
10.1109/ICITR51448.2020.9310832

318
R. Joseph et al.
14. Chao, Y.-W., Yang, J., Price, B., Cohen, S., & Deng, J. (2017). Forecasting human dynamics
from static images (pp. 3643–3651). https://doi.org/10.1109/CVPR.2017.388
15. Park, S., Hwang, J., & Kwak, N. (2016). 3D Human pose estimation using convolutional neural
networks with 2D pose information. https://doi.org/10.1007/978-3-319-49409-8_15
16. Fani, M., Neher, H., Clausi, D. A., Wong, A., & Zelek, J. (2017). Hockey action recognition
via integrated stacked hourglass network. IEEE Conference on Computer Vision and Pattern
Recognition Workshops (CVPRW), 2017, 85–93. https://doi.org/10.1109/CVPRW.2017.17
17. Sawant, C. (2020, January 2). Human activity recognition with openpose and Long Short-
Term Memory on real time images. EasyChair Home Page. https://easychair.org/publications/
preprint/gmWL
18. Posenet Library. https://github.com/tensorﬂow/tfjs-models/tree/master/posenet
19. Tensorﬂow Blog, “Real-time Human Pose Estimation in the Browser with TensorFlow.js,”
https://medium.com/tensorﬂow/real-time-human-pose-estimation-in-the-browser-with-tensor
ﬂow-js-7dd0bc881cd5
20. Description of 17 key-points detected by PoseNet, Tensorﬂow Blog
21. Track Human Poses in Real-Time on Android with TensorFlow Lite. The Tensor-
Flow Blog, https://blog.tensorﬂow.org/2019/08/track-human-poses-in-real-time-on-android-
tensorﬂow-lite.html
22. Hidalgo, G., Sheikh, Y., Kitani, K., Bansal, A., Sanabria R., Xiang, D., Li, X., & Idrees, H.,
(2019). OpenPose: Whole-body pose estimation.
23. Brown, V. (2021). The bike ﬁt with Todd—Part two. Nicholas Brown. https://nichollasbrown.
wordpress.com/2020/05/26/the-bike-ﬁt-with-todd-part-two/
24. Sin and Cosine rules objectives: Calculate missing sides and angles is non-right angles triangles.
(2021). Ppt Download. https://slideplayer.com/slide/6955412/

Analysis of Car Damage for Personal
Auto Claim Using CNN
Jagadevi N. Kalshetty
, B. A. Hrithik Devaiah
, K. Rakshith
,
Ken Koshy
, and N. Advait
Abstract In the world of vehicle insurance and rental industries, detecting damages
on vehicles is one of the most important activities. These damages are identiﬁed and
inspected by the drivers and insurance companies to determine the suitable monetary
compensation, and by vehicle rental companies to assign the responsibility to guilty
customers.Sincethecurrentsystemistimeconsuming,whereintheinspectorshaveto
manually inspect the damages before appraising, this identiﬁcation can be performed
by object recognition systems. The intricacy of these systems rests in the image
feature determination and extraction techniques. A more novel approach to detecting
the severity of damage and predicting the repair costs is using 2D image recognition.
This way, the driver would not have to wait for the appraisal of insurance companies
to determine the rough estimate of cost of repairs. After a picture is uploaded to the
framework, the picture is then processed and the vehicular damage is identiﬁed. The
image is then classiﬁed into relevant damage severity classes. Afterward, the damage
severity that is detected in the image, is then mapped to the approximate cost values.
Then ﬁnally, the user is presented with a report of the vehicular damage severity
classiﬁcation as well as an average expense cost report from which the vehicle can
then be recuperated from the damages.
Keywords CNN · Deep learning · Image classiﬁcation · Image recognition ·
Machine learning
1
Introduction
Thousands of motor accidents take place around the world every day [1]. After
an accident, the driver wastes a lot of time trying to get the vehicle damage costs
estimated. In the world of vehicle insurance and rental industries, detecting these
damages is one of the most important activities. These damages are identiﬁed and
inspected by the drivers and insurance companies to determine the suitable monetary
J. N. Kalshetty (B) · B. A. Hrithik Devaiah · K. Rakshith · K. Koshy · N. Advait
Nitte Meenakshi Institute of Technology, Bengaluru 560064, India
e-mail: jagadevi.n.kalshetty@nmit.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_25
319

320
J. N. Kalshetty et al.
compensation, and by vehicle rental organizations to allocate out the responsibility
to liable clients. Regularly, the driver or the protection policyholder contacts the
insurance agency after a mishap and stands by waiting for the relevant personnel
to arrive. The current system is time consuming, wherein the inspectors follow a
traditional approach by manually inspecting the damages before appraising. Also,
the inspectors can sometimes omit minor damages in haste or by being partial to
some parties. Recognition of such minor damages is important in scenarios where
the drivers frequently change, such as in a vehicle rental service.
2
Literature Survey
Over the last few years, there have been innumerable works presented based on
the implementation of an automated vehicle damage detection system to counter
the current conventional technique, wherein the insurance inspectors have to spend
time assessing damages, which causes a lot of delay in the appraisal calculation for
personal auto claims. Thus, a lot of researchers have paid attention to this problem at
an industrial scale as well over the years. A number of solutions have been proposed
in literature by using AI based on deep learning to improve the effectiveness of the
proposed system.
In spite of the fact that comparative applications for this exploration issue exist,
no arrangement with all aforementioned features exist. The expense cost just as the
damage severity forecast are the key highlight features of this proposed study [2].
Highlights like the client advance just as the heads (vehicle insurance agencies and
vehicle rental organizations) having the option to refresh the grouping of severities
and the everchanging cost rules to coordinate with the organization arrangements are
additionally a signiﬁcant point which is wanted by the possible clients, however, they
will be executed shortly in future. The current system ﬁgures the kind of damage, the
severity grouping, and the expense cost according to the damage, just considering the
kind of vehicle [1, 3]. In this manner, the damage cost expectation which is given by
the system isn’t explicitly speciﬁc to a solitary vehicle. The novel contributions of our
proposed system are an included severity classiﬁcation, a report generation system
which would facilitate the further conversation between user and insurance provider,
and a helpdesk chatbot that helps with user queries. To ameliorate the precision of the
expense cost and to make it more impossible to miss even a solitary vehicle, the make,
model, and the year of production can be thought of. Furthermore, as a progression of
the inner activities of the application, the programmed identiﬁcation of the previously
mentioned subtleties, vehicle make, model and the year of production can be added.
Furthermore, the chatbot functionality can be improved with voice recognition and
additional supported languages. By adding the aforementioned progressions, the
prescribed methodology is expected to be more dependable and exact.

Analysis of Car Damage for Personal Auto Claim Using CNN
321
3
Design
The following ﬂowchart shown in Fig. 1 illustrates the design of the proposed system.
In this project, the user submits the picture to the system. The picture goes through
the ﬁrst gate which checks if the image is that of a car or not. If the picture is correct
then it moves to the next gate which checks if the car is damaged or not. If either of
the gates fails, the user is prompted to upload another picture. Once both gates are
passed, the image passes through two more gates- location of damage and severity of
damage. The damage can be located on the front, side, and rear of the car. Similarly,
the damage severity can range from minor, moderate, and severe. Based on the
approximate prices of the corresponding damaged car parts and damage severity, an
estimate of the repair costs is generated as a report.
Fig. 1 Flow of activity in
the system

322
J. N. Kalshetty et al.
4
Proposed Method
The machine learning process can be divided into 5 basic steps, Firstly, Data collec-
tion—in this stage, the data is collected from various sources using different methods.
Normally a lot of information is needed to be gathered for preparing the model. Data
preparation—The next step is important as the collected data is cleaned, classiﬁed,
augmented, etc. to prepare it for the model. This allows for a good quality of data.
Choosing a model—Various models exist serving various purposes with varying
degrees of accuracy, trainability, and speed. Choosing the appropriate model for the
required job is necessary. Training the model—The model is trained using training
data collected as well as prepared in the ﬁrst two steps. The model is tuned if needed
and evaluated for accuracy. Deploying the model—The model is ﬁnally ready to be
tested on the testing data.
The architecture of the proposed system is as demonstrated in Fig. 2. The user
uploads the picture to the site. We utilize a web app framework created for Python.
It helps us build lightweight web applications as it keeps the core of the apps very
simple. The image is then sent to the TensorFlow platform where an inference request
is sent. The term deduction alludes to the way toward executing a TensorFlow Lite
model on-device to make predictions based on input information. We have multiple
models each performing a speciﬁc task. These serve as the inference endpoints. The
tasks are Car Validation, Damage Presence, Damage Location, and ﬁnally Damage
Severity.
The Convolutional Neural Network (ConvNets or CNNs) is a sort of neural
network utilized for performing image recognition and classiﬁcation (Fig. 3). CNN
image classiﬁcation takes a picture, processes it, and classiﬁes it under certain cate-
gories like car, bus, train, etc. Computers consider pictures to be arrays of pixels and
the size relies upon the picture resolution. In light of the picture resolution, the height,
Fig. 2 System architecture diagram

Analysis of Car Damage for Personal Auto Claim Using CNN
323
Fig. 3 Convolutional Neural Network Architecture
width, and depth are resolved. Actually, deep learning CNN models are prepared
and tested by passing each picture through a progression of convolution layers with
ﬁlters (Kernels), pooling fully connected layers (FC), and applying Softmax function
which arranges identiﬁed object vector(s) into a probability distribution that sums to
1 [1, 4].
Image classiﬁcation involves extracting features from the image to detect patterns
in the data. Using a normal neural network, or even basic machine learning classi-
ﬁcation models for image classiﬁcation would become very expensive in terms of
computation as the trainable parameters become huge. CNNs are very effective in
reducing the number of parameters without losing the quality of models. Images
have high dimensionality (as each pixel is considered as a feature) which suits the
above described abilities of CNNs. CNNs allows us to not worry about what ﬁlters
to use for feature extraction. Instead, CNNs automatically extract features, some
not even visible to humans, thus reducing the complexity of training. CNNs are
trained to identify the edges of objects in any image. We use CNN for each of the
four gates- car validation, damage validation, location detection, severity detection.
Since each gate is performing image classiﬁcation but with different features, we
use the same algorithm, i.e., VGG-16. The algorithm essentially involves feature
extraction for features like outline, shapes, colors, etc., and then using those features
for identifying patterns on the images.
These models of the proposed system run on the VGG-16 architecture for image
classiﬁcation. VGG-16 is a Convolutional Neural Network model accomplishing
92.7% top-5 test accuracy in ImageNet, a dataset utilized for visual identiﬁcation
research containing more than 14 million pictures across 1000 classes. The Kernel
size is 3 × 3 and the pool size is 2 × 2 for every one of the layers. The information
given to the vgg 16 model is 224 × 224 × 3 pixels pictures. This is then shipped off
to the following two convolution layers with each being 224 × 224 × 64 sizes, this
picture is then shipped off to a pooling layer where the width as well as the height of

324
J. N. Kalshetty et al.
the picture is decreased to 112 × 112 × 64. The picture at that point goes through
two conv128 layers with 112 × 112 × 128 size, after that the picture goes into a
pooling layer which further lessens the stature and width of the picture to 56 × 56 ×
128. Further, there are three conv256 layers with each 56 × 56 × 256 size, after that
again a pooling layer diminishes the size of the picture to 28 × 28 × 256. Further
that point there are three more conv512 layers with each 28 × 28 × 512 size, after
which another pooling layer lessens the picture size to 14 × 14 × 512. Furthermore,
there are three conv512 layers with each 14 × 14 × 521 layers, trailed by one more
pooling layer resized to 7 × 7 × 521. This is then trailed by two dense or completely
associated layers with each having 4090 nodes. Ultimately there is a last dense yield
layer (softmax) with 1000 nodes which produces yield by applying softmax function
as actuation to the net information coming from the past layer [5].
For images of damaged cars, we need to collect them from the web. Web Scraping
is a method to accumulate data automatically from an online source, generally from
a website. Selenium is an open-source web-based automation tool. It is primarily
used for web app testing in the industry, but it can also be used for web scraping.
Using selenium, the images of damaged cars were downloaded from the internet.
For images of undamaged cars, we use The Stanford Cars dataset. It is a huge dataset
containing 16 thousand images of 196 classes of cars. We need a small sample of
images from this dataset.
Data pre-processing consists of the following steps. Firstly, we have Image Clas-
siﬁcation where the images are classiﬁed into different classes like damage location
(front, rear, and side), severity (minor, moderate, and severe). The next step is Image
Resizing-Neural networks operate on inputs of the same size, requiring the resizing
of all input images to a ﬁxed size before feeding them into the CNN. Larger ﬁxed
sizes require lesser shrinking, which translates to lesser deformation of patterns,
details, and features of the images. And lastly, we have Data Augmentation where
the images are augmented to inﬂate the dataset size by ﬂipping, changing brightness.
5
Results and Simulation
The following ﬁgures show the working of the proposed system. Figures 4, 5 and 6
show the results page with the uploaded image, the validation gates passed, and the
options to upload another image, generate report, and chat with chatbot. Figures 7
and 8 show the working of the report generation. Figures 9 and 10 show the working
of the chatbot. In the ﬁrst gate (car validation gate), the model achieves an accuracy
of 87%. Secondly, in the damage validation gate, the model achieves an accuracy
of 85%. Finally, for the third gate (damage location gate) and fourth gate (damage
severity gate), the models achieve accuracies of 75% and 69% respectively. These
numbers are achieved at around 50 epochs. As we get more data, we can train the
model further, thus increasing accuracy.

Analysis of Car Damage for Personal Auto Claim Using CNN
325
Fig. 4 Gate 1 car validation check
Fig. 5 Gate 2 damage validation check
As you can see in Fig. 4, an image of a lion is uploaded, and the car validation
model correctly identiﬁes that this is not an image of a car. The user has to then
reupload the correct image.
In this scenario Fig. 5, the user has uploaded an image of a car and has passed the
car validation. The damage validation model, however, has not detected any damage

326
J. N. Kalshetty et al.
Fig. 6 Gate 3 and Gate 4 location and severity
in the car. The image failed to pass the second validation gate and thus, a reupload
of the correct image is required.
Here in Fig. 6, the user has uploaded the correct image of a car and has passed both
validation gates. The third and fourth gates which are responsible for identifying the
location and the severity respectively have shown the correct results. As the damage
in this car is on the side, the insurance covers only the window and the door. So, our
insurance summary provides an estimate of the cost of repairs for the parts. Similarly,
if the location is front or rear, the insurance summary provides the corresponding
costs for the parts such as bumper, trunk, bonnet, and windshield.
As seen in Figs. 7 and 8, the Print Document button generates a report of the
results with a screenshot of the page and saves the ﬁle locally. Additionally, the
report is also sent by mail to the user after which the user can use it to initiate further
insurance processing.
The chatbot is implemented as seen below. On clicking the button, the user is
redirected to the most popular instant messaging app.
In Fig. 9, we see that the chatbot offers the user multiple queries to ask on the
user’s request of “help”.
Figure 10 shows that the chatbot also provides features like recommending
Insurance sites and plans and providing parts and prices of the car, etc.

Analysis of Car Damage for Personal Auto Claim Using CNN
327
Fig. 7 Report is saved locally on the user’s system
Fig. 8 Report is also sent to registered email
6
Conclusion
By using this system, the damages can be identiﬁed immediately without having to
deal with in-person inspection. This will decrease the waiting period for response
from the insurance company. It will also decrease the workload of the inspection

328
J. N. Kalshetty et al.
Fig. 9 KHAR chatbot in use
Fig. 10 More queries
personnel as everything is done by the system, including uploading pictures of the
damages, assessing damages, calculating estimate of repair costs, and providing a
summarized report of the overall assessment. The appraisal calculation time can be
reduced as all damages are classiﬁed into relevant severity and are assigned respective
costs based on vehicle make and type, etc. Human error can be reduced as the system

Analysis of Car Damage for Personal Auto Claim Using CNN
329
keeps improving over time. As more pictures are uploaded over time, the model
is trained more and keeps increasing its accuracy. Working with deep learning and
image processing helps us to understand the vast potential of this technology.
References
1. Singh, R., Ayyar, M. P., Sri Pavan, T. V., Gosain, S., & Shah, R. R. (2019). Automating car
insurance claims using deep learning techniques. In 2019 IEEE Fifth International Conference
on Multimedia Big Data (BigMM), Singapore, Singapore.
2. Zhang, Q., Chang, X., & Bian, S. B. (2020). Vehicle-damage-detection segmentation algorithm
based on improved mask RCNN. IEEE Access, 8, 6997–7004.
3. Patil, K., Kulkarni, M., Sriraman, A., & Karande, S. (2017) Deep learning based car
damage classiﬁcation. In 2017 16th IEEE International Conference on Machine Learning
and Applications (ICMLA), Cancun.
4. Dhieb, N., Ghazzai, H., Besbes, H., & Massoud, Y. (2019). A very deep transfer learning
model for vehicle damage detection and localization. In 2019 31st International Conference
on Microelectronics (ICM), Cairo, Egypt.
5. Qassim, H., Verma, A., & Feinzimer, D. (2018). Compressed residual-VGG16 CNN model for
big data places image recognition. In 2018 IEEE 8th Annual Computing and Communication
Workshop and Conference (CCWC), Las Vegas.
6. Waqas, U., Akram, N., Kim, S., Lee, D., & Jeon, J. (2020). Vehicle damage classiﬁcation and
fraudulent image detection including moiré effect using deep learning. In 2020 IEEE Canadian
Conference on Electrical and Computer Engineering (CCECE), London, ON, Canada.
7. Zhu, X., Liu, S., Zhang, P., & Duan, Y. (2019). A uniﬁed framework of intelligent vehicle
damage assessment based on computer vision technology. In 2019 IEEE 2nd International
Conference on Automation, Electronics and Electrical Engineering (AUTEEE), Shenyang,
China.
8. Koch, M., Wang, H., & Bäck, T. (2018). Machine learning for predicting the damaged parts of
a low speed vehicle crash. In 2018 Thirteenth International Conference on Digital Information
Management (ICDIM), Berlin, Germany.
9. Ak¸sehır, Z. D., Oruç, Y., Elıbol, A., Akleylek, S., & Kili, E. (2018). On the analysis of work
accidents data by using data preprocessing and statistical techniques. In 2018 2nd Interna-
tional Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT), Ankara,
Turkey.
10. Sharma, S., & Bhagat, A. (2016). Data preprocessing algorithm for web structure mining. In
2016 Fifth International Conference on Eco-friendly Computing and Communication Systems
(ICECCS), Bhopal, India.
11. Jony, R. I., Mohammed, N., Habib, A., Momen, S., & Rony, R. I. (2015). An evaluation of data
processing solutions considering preprocessing and “special” features. In 2015 11th Interna-
tional Conference on Signal-Image Technology & Internet-Based Systems (SITIS), Bangkok,
Thailand.
12. A comprehensive guide to convolutional neural networks. https://towardsdatascience.com/a-
comprehensive-guide-to-convolutional-neural-networksthe-eli5-way-3bd2b1164a53
13. VGG16—convolutional network for classiﬁcation and detection. https://neurohive.io/en/pop
ular-networks/vgg16
14. Basics of image classiﬁcation techniques in machine learning. https://iq.opengenus.org/basics-
of-machine-learning-image-classiﬁcation-techniques/amp/

On the Analysis Problem
of the Attribute-Based Access Control
Model HGABAC
Anh Truong
Abstract Due to the limitations of the role-based access control (RBAC) model, the
attribute-based access control (ABAC) model is being researched and promised to
become a dominant access model in the near future. Similar to RBAC, the security
analysis problem, i.e., the problem to analyze the policy to verify if there is any
security issue in the policy is one of the crucial problems in ABAC. In this paper, we
consider the security analysis problem in a recent proposed implementation of ABAC
model, namely HGABAC and its administration model GURAG. We investigate the
backward procedure proposed and assemble this procedure to build the analysis
technique for HGABAC and GURAG policies. We also implement the technique and
perform some experiments to show the scalability of the proposed technique.
Keywords Security analysis · Access control · Attribute-based access control ·
Role-based access control · Model checking
1
Introduction
Access control [1] is a process of verifying restricted access to the system resources
thatdetermineswhethertheresourcehasbeengrantedordenied.Discretionaryaccess
control (DAC), mandatory access control (MAC) arrived in the early 1970s [1, 2].
However, the shortcomings of MAC and DAC led to the establishment and devel-
opment of role-based access control (RBAC) [3–6]. RBAC is widely used today
by most access control systems. However, the demand for building more complex
and restricted access models has encouraged researchers to head to new invented
models. Attribute-based access control (ABAC) [7] has been proposed and studied
thoughtfully, along with the limitation of RBAC [8], Attribute-based access control
(ABAC) becomes a promising access control model shortly. However, a method-
ology to analyze the ABAC model’s security policies is necessary but has not been
thoroughly studied.
A. Truong (B)
Ho Chi Minh City University of Technology—VNU-HCM, Ho Chi Minh, Vietnam
e-mail: anhtt@hcmut.edu.vn
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_26
331

332
A. Truong
In the ABAC model, users can access resources in the system within their
scope of authority. User permissions are managed through attributes. Assigning
and/or revoking attribute values to/from users are equivalent to adding or removing
user rights in the system. Such assigning and revoking actions are performed by
admins. In large systems, there are often numerous different admins. Therefore, an
administrative model for the ABAC model is needed to manage the actions of admins.
The administrative model for the ABAC model is used to manage decentralized
policy. As the number of users in the system is large and the policies become more
complex, the process of decentralization can make the system vulnerable to security.
For example, in a university system, consider the combination of two administrative
actions (may be executed by different admins) in a policy that (i) assign attribute
value TA to a user who has already attribute value student and (ii) assign attribute
value teacher to a user who has attribute value TA. The execution of action (i) and
then followed by action (ii) may raise a security problem, e.g., a user has attribute
value student and also has the attribute value teacher. This could cause a student in
the system to access sensitive teacher resources such as exam papers. With similar
vulnerabilities, sensitive information could be leaked or illegally modiﬁed. These
errors are caused by the administrative actions, and they may be accidentally or
intentionally combined to cause the system to fall into an unsafe state.
To be able to check the system for the presence of security issues or not, it is
necessary to build an automatic analysis technique that can check for the presence
of security vulnerability in all possible cases that could happen. In this paper, we
consider the security analysis problem in a recent proposed implementation of ABAC
model, namely HGABAC and its administration model GURAG. We investigate the
backward procedure proposed in [9–15] and assemble this procedure to build the
analysis technique for HGABAC and GURAG policies. We use ﬁrst-order logic
to represent all the components of the ABAC policy and investigate the backward
procedure proposed to analyze the security policies automatically to ﬁnd out if the
system’s policies could lead to security vulnerability. We implement our technique
using a model checking tool named MCMT (the implementation of the backward
procedure) and also perform experiments to show the scalability of the technique.
The paper is organized as follows: Sect. 2 brieﬂy introduces the HGABAC model
and the administration model GURAG. We also specify the security analysis problem
for the models in Sect. 2. Section 3 presents our technique to automatically analyze
the GURAG model. Section 4 shows the experimental results. Finally, Sect. 5 gives
some conclusions and future works.

On the Analysis Problem of the Attribute-Based Access Control …
333
2
HGABAC: An ABAC Model and Its Administrative
Model GRUAG
ABAC has been developed in many different directions. Several models have been
introduced, of which the ABACα model introduced in 2012 becomes the basis devel-
opment for other models [7]. The hierarchical group and attribute-based access
control (HGABAC) [7] is one of the models developed from the ABACα model.
This is a highly advanced ABAC model. This model eliminates many disadvantages
of the previous ABAC models and could be soon deployed in reality.
HGABAC description. In HGABAC, the entities of the model are users, objects,
and subjects. Objects are resources of the system (ﬁles, applications, etc.). Users
access objects via subjects. Subjects are created by users (processes, sections) when
they interact with the system. A subject owns attributes of the user that created it,
which can vary over time but never exceed the set of attributes of the user created it.
Subjects and users have the same set of attributes, while objects have a separate set
of attributes reﬂecting their characteristics. Operations are the system’s operations
(read, write) that are performed by subjects on objects. The attributes are the sets of
values. The conceptual model HGABAC is illustrated in Fig. 1.
HGABAC formalization. In this section, we formalize the components of
HGABAC.
Let U, S, O, Au, Ao, OP be the ﬁnite set of users, subjects, objects, attributes of
user, attributes of objects, and operations, respectively. UA, OA be the ﬁnite set of
user attribute and object attribute functions, respectively. We have UA ⊆U × Au
and OA ⊆O × Ao.
Authorization Function. For each op ∈OP, Authorizationop (s:S, o:O) is deﬁned
as the following policy language, returning true or false using ABNF syntax [7]. True
means that the subject s can get access to object o:
Fig. 1 Conceptual model of HGABAC [7]

334
A. Truong
Au_func = exp [ bool_op Au_func]  | exp
exp = term op term
| [ “NOT” ] bool_var
| [ “NOT” ] “(”Au_func “)”
term = const | att_name
bool_var = boolean | att_name
op = “>” | “=” | “<=” | “! =” | “ ”
bool_op = “˅” | “˄” 
att_name = user_att_name | object_att_name| 
admin_att_name
user_att_name = “user.” att_name 
object_att_name = “object.” att_name 
admin_att_name = “admin.” att_name 
const = atomic | set
boolean = “TRUE” | “FALSE”
set = “{” “}” | “{” setval “}”
setval = atomic | atomic “,” setval
atomic = int | float | string | “NULL”
Where user_att_name, admin_att_name are the attribute names of users and
admins in the UA set, object_att_value is the attribute name of the objects in the
OA set. int, ﬂoat, string are values with corresponding data types int, ﬂoat, string.
For example, let consider the following authorization functions:
Authorizationread(s : S, o : O) = s.UserType ∈o.ReaderType
∧s.Faculty ∈{Medical,Physical}
∧s.Age > 18
This function returns true iff (i) the values of the attribute UserType of subject s
are included in the set of values of the attribute ReaderType of object o; and (ii) the
values of the attribute faculty of s must be medical and/or physical (means that the
subject s works for medical or physical faculty); and (iii) the age of s is more than
18.
Let consider an example of HGABAC system as follows:
– U = S = {Alice, Bob, Shan}
– Au = {UserType, Location, Faculty} where the range of each attribute is UserType
= {student, teacher, tutor assistant};Location = {Paris, New York, London}; and
Faculty = {Chemistry, Medical, Physical}
– O = {O1, O2}
– Ao = [ReaderType, Location} where the range of each attribute is ReaderType
= {student, teacher} and Location = {Paris, New York}
Given an HGABAC policy as follows (UA and OA):

On the Analysis Problem of the Attribute-Based Access Control …
335
User
UserType
Location
Faculty
Alice
Student
Paris
Chemistry
Bob
Teacher
NewYork
Medical
Shan
Tutor assistant
London
Physical
Object
ReaderType
Location
O1
Student
Paris
O2
Teacher
NewYork
We will have (Alice, UserType.Student) ∈UA; (Bob, UserType.Teacher) ∈UA;
(Alice, Location.Paris) ∈UA. Similarly, (O1, ReaderType.Student) ∈OA; (O1,
Location.Paris) ∈OA; …
Let consider op ∈OP = {read}. An authorization function for read operation can
be described as follows:
Authorizationread(s : S, O1 : O) ≡s.UserType ∈O1.ReaderType ∧s.Location = O1.Location
Assume that user Alice requests to read the object O1 (see Fig. 2): the conditions
s.UserType ∈O1.ReaderType and s.Location = O1.Location are satisﬁed, so Alice
is allowed to read o1.
A subject s is allowed to access object o if and only if Authorization(s,o) is
evaluated to true. Since the subject can always receive attributes from the user or the
entire attributes of the user, thus in the following, we will only analyze the attributes
of the user without analyzing the attributes of each subject. We assume if the user
has enough attributes to perform administrative action on the object, then that user
can also create a qualiﬁed subject to perform an action on the object (i.e., the set of
users is the same as the set of subjects).
Fig. 2 Example of access request

336
A. Truong
The Administrative Model GURAG: This model has been proposed in order to
provide administrative actions for controlling HGABAC policy. GURAG adminis-
trative model has three sub-models: UAA sub-model, UGAA sub-model, UGA sub-
model. The UAA sub-model deals with the addition or deletion of values to attributes
of users. The UGAA sub-model controls the addition and deletion of attributes to user
groups while the UGA sub-model controls the assignment of users to user groups, as
well as the removal of a user from a user group. As argued above, we do not consider
the user group in the analysis of the policies. Thus, for the GURAG administrative
model, we only take care of administrative actions in the UAA sub-model while
leaving the UGAA sub-model and UGA sub-model as the future works.
• User Attribute Assignment sub-model (UAA).
The UAA model deals with modifying the attribute value of users, e.g., add or
delete values to attributes of a user. The two administrative actions in this sub-model
are formalized as follows:
Can_Add_att/Can_delete_att
({admin_role}, {user_attribute_set}, {target_attribute_set}) .
Where admin_role is the role of the administrator who will execute this action;
sincetheGURAG modelusestheRABCmodelasabasemodeltomanagetheadmins,
thus admins must have the role (admin_role) in the administrative actions. In the
ABAC model, we can treat a role as an attribute. As you will see in our analysis
technique, we consider an admin is also a user who owns attributes (and role is an
attribute of admin); this can help us in expanding the GURAG model easily and
ﬂexibly in the future. user_attribute_set is the user’s conditional set that
requires a user to have some values on some attributes. target_attribute_set
is the set of attributes and their values that the user will be assigned to or deleted
after executing the action.
Letconsiderwhenanadministrativeaction Can_Add_att/Can_delete_att
can be executed:
– Condition 1: There exists an admin that satisﬁes the admin_role conditions, i.e.,
the admin must assume the admin_role. In this case, we say that the administrative
action is enabled and ready to be executed.
– Condition 2: If there is a user in the system that has an attribute set satisfying
user_attribute_set (e.g., the values of its attributes include the values deﬁned in
user_attribute_set), then we say that the user satisﬁes the user’s condition of the
administrative action.
With the condition 2 is satisﬁed and the administrative action is enabled, the admin
now can execute the administrative action on the user and then the corresponding
attribute set of the user will be assigned/deleted to the target_attribute_set.
We now consider an example:
Can_Add_att
(DeptAdmin,
{UserType.Tutor_assitant},
{User-
Type.Teacher}).

On the Analysis Problem of the Attribute-Based Access Control …
337
This administrative action will be enabled if there exists an admin whose role is
DeptAdmin (condition 1). The condition 2 will be satisﬁed if there is a user u so
that the value of the attribute UserType is Tutor_assistant. If the two conditions are
satisﬁed, the admin can execute this action on user u that would lead to a state in
which the value Teacher is added to the attribute UserType of user u (e.g., the relation
UA is changed to a new relation UA’ where UA’ = UA U (u.UserType.Teacher)).
Similarly, consider the action:
Can_delete_att (DeptAdmin, {UserType.(Tutor_assitant, Student)}, {User-
Type. Tutor_assitant}).
This action requires an admin whose role is DeptAdmin to become enabled (condi-
tion 1). The condition 2 will be satisﬁed if there is a user u so that the values of the
attribute UserType is Tutor_assistant and Student (i.e., the user is a student and also
a tutor assistant). If the two conditions are satisﬁed, the admin can execute this
action on user u that generates a state in which the value Tutor_assitant is deleted
from the set value of the attribute UserType of user u (UA →UA’ where UA’ =
UA\(u.UserType. Tutor_assitant)).
The Security Analysis problem of the GURAGmodel. The objective of this
paper is to ﬁnd out if the system has security vulnerability. This means that after
executing some administrative actions, if a user can obtain some speciﬁc values for
their attributes and based on this, he can get access to sensitive resources and leads
the system to danger. In this case, we say that the system is unsafe (or security
vulnerability) because there exist users who can get access to sensitive resources
through administrative actions although following the security requirement of the
system, the users are not allowed to do so.
Sensitive resources can only be accessed through legal users who own certain
attribute values. Thus the purpose is to ﬁnd out if there exists an illegal user (beside
the legal users above) possessing the attribute values through the application of
administrative actions. If yes, the system is unsafe. For example, given a user who
has the attribute UserType with value is Student; through applying some certain
administrative actions, the user possesses also the value Teacher for UserType. Thus,
the user has both types Student and Teacher at the same time. Then the user can
access sensitive resources of the teacher although he is a Student and not allowed
to get the access. We call the attribute value set {Student, Teacher} as the goal (that
we want to verify if the goal can be reached). The problem that veriﬁes if a goal
can be reached or not in a GURAG system is called the security analysis problem of
GURAG.
In order to answer the security analysis problem, we need to analyze the given
GURAG. To do so, one of the simple algorithms is that: we collect all the administra-
tive actions that the system has. Subsequently, we analyze each action by executing
it. When an administrative action is performed, the system is transitioned into a new
state (we can say that the initial system is the initial state) and we need to check if
the goal is satisﬁed in the new state or not. If yes, we return the answer “Yes” for
the security analysis problem (i.e., the system is unsafe). Otherwise, we continue to
select actions and perform them to get other states and check again the goal and so

338
A. Truong
Fig. 3 Forward algorithm for the analysis of the GURAG system
on… Intuitively, this is a time-consuming process. Figure 3 illustrates this forward
algorithm to analyze the system.
3
Automated Analysis Technique for GURAG System
In this section, we propose an analysis technique to analyze the GURAG system.
Intuitively, we can assemble the forward algorithm mentioned above into the anal-
ysis technique. However, in the following, we investigate the backward reachability
algorithm proposed in [14] and adapt this algorithm into our analysis technique. The
reason to do this is that: (i) instead of checking from the initial state, the backward
reachability algorithm starts checking from the goal, so, it will limit all the explored
states that does not satisfy the goal; (ii) we can inherit the tool MCMT that imple-
ments the backward reachability algorithm and so, we can adapt some heuristics
introduced in MCMT in order to alleviate the state explosion problem, a well-known
problem in the analysis of transition-based systems like GURAG system, and thus,
speed up the analysis.
MCMT [10] attempts to solve reachability problems for a certain class of inﬁnite
state transition systems whose state variables are arrays that can be seen as func-
tions mapping indexes to elements. Such transition systems can be used as suitable
abstractions of parameterized protocols, sequential programs manipulating arrays,
etc. The main idea underlying MCMT is to use a backward reachability algorithm that
repeatedly computes pre-images of the set of goal states, which is usually obtained
by complementing a certain safety property that the system should satisfy. The set
of backward reachable states of the system is obtained by taking the union of such
pre-images (states K1 and K2 as in Fig. 4, backward reachability algorithm). At
each iteration of the procedure, the algorithm checks whether the intersection with
the initial set of states (the initial system) is non-empty or not. If yes, it will report
the unsafety of the system, i.e., there exists a (ﬁnite) sequence of transitions that
leads the system from an initial state to one satisfying the goal. Otherwise, the algo-
rithm checks if the set of backward reachable states is contained in the set computed

On the Analysis Problem of the Attribute-Based Access Control …
339
Fig. 4 Forward and backward reachability algorithm
at the previous iteration (ﬁx-point test) or not; if yes, it reports the safety of the
system, i.e., no (ﬁnite) sequence of transitions leads the system from an initial state
to one satisfying the goal; otherwise, the algorithm continues with next iterations.
The peculiarity of MCMT is that sets of states and transitions are represented by
ﬁrst-order formulae so that the computation of pre-images boils down to logical
manipulations and the safety and ﬁx-point tests are reduced to satisﬁability checks
of ﬁrst-order formulae. The resulting satisﬁability problems are efﬁciently solved by
state-of-the-art tools, called Satisﬁability Modulo Theories (SMT) solvers.
We will adapt MCMT to the context of solving the security analysis problem
of GURAG. In general, we investigate the backward reachability algorithm imple-
mented in MCMT to analyze the GURAG policies. To do this, we need to implement
an module that translates all components of GURAG policies such as goal, attributes,
administrative actions, … to the language of MCMT (Note that MCMT language is
based on ﬁrst-order logic (FOL) representation; thus, we will represent the compo-
nentsofGURAG policiesasFOLformulaandthentransformtheformulaintoMCMT
language).
Attributes are represented in MCMT as tuples deﬁned of type uat{false, false…-
false}. When a user is added to a certain attribute value, the corresponding value of
the attribute will be set to true. For example, a user is assigned to the attribute value
b1 (i.e., the attribute b of the user will be assigned to value 1), then the attribute b of
the user will be as follows: b {true, false, false, …, false}.
Then, we have to represent the initial state and the goal state of GURAG policies
in the MCMT language. For simplicity, we assume that the initial state is the state
in which all attributes of users and admins are not assigned to any value (however,
our module even works with the initial states in which some attributes are already
assigned). The goal state is a set of attribute values of the user. If a user has all of these
attribute values enabled, the system will be unsafe. For example, a goal specifying
that “students are not allowed to access object O(readerType: teacher)” means that
a user owning the attribute value student and teacher at the same time will cause
the system to be unsafe. For this, we represent the goal as Goal: {student, teacher}.
Generally, a goal can be:
Goal = {attribute_value1, attribute_value2, . . . attribute_valuen}

340
A. Truong
Such goal can be written in the ﬁrst-order logic as follows:
∃u. (u, attribute_value1) ∈UA ∧(u, attribute_value2) ∈UA ∧(u,
attribute_value3) ∈UA ∧…∧(u, attribute_valuen) ∈UA ∧.
This ﬁrst-order logic formula returns true iff in the current state of the system,
there exists a user u who has the set of tuple attribute values including all the tuples
attribute_value1, attribute_value2, …, attribute_valuen. For example: let consider a
goal = {a2, b1, d5}, this goal is satisﬁed if there exists a user u so that (i) the attribute
a of u is set to value 2, and (ii) the attribute b of u is set to value 1, and (iii) the attribute
d of u is set to value 5.
Actions in GURAG include three main parts: admin role, user condition set, and
target set. MCMT can only assign one target per action. So we have to split the target
set into individual targets. For example, let consider the following actions:
Can_Add_att (DeptAdmin, {UserType.Tutor_assitant}, {UserType.Teacher,
UserType.Secretary}).
The target set is {UserType.Teacher, UserType.Secretary} and thus will be splitted
into two targets {UserType.Teacher} and {UserType.Secretary}. The original action
will be separated into two actions with the conditions of admin and user are
maintained as follows:
Action 1: Can_Add_att (DeptAdmin, {UserType.Tutor_assitant}, {User-
Type.Teacher}).
and.
Action 2: Can_Add_att (DeptAdmin, {UserType.Tutor_assitant}, {User-
Type.Secretary}).
In the following, for simplicity, we use a, b, c, … to denote the attributes and
numbers 1, 2, 3, … to denote the value of attributes. The administrative actions in
GURAG will be generalized as following formation:
Can_Add_att/Can_delete_att ad_role_value, user_attribute_value1,
user_attribute_value2, …, user_attribute_valuen; target_value
Where ad_role_valueistheroleoftheadminwhoexecutestheadministrative
action.
user_attribute_value1,user_attribute_value2, …,
user_attribute_valuen is the set of conditions for a certain user who
will be affected by the action. target_value is an attribute value that the user
will be added or deleted according to can_add or can_del action. For example:
Can_Add_att a1 , b1 , c3 ; b3
Can_delete_att a2 , true ; c1
Notethat“true”meansthattheconditionisalwaystrueandwedonotneedtocheck
this condition. The Can_Add_att action requires an admin whose role attribute
value must be 1 in order to be enabled (i.e., admin condition a1). If there exists certain
user u so that (i) the attribute b of u has value 1, and (ii) the attribute c of u has value

On the Analysis Problem of the Attribute-Based Access Control …
341
3 (i.e., user condition b1, c3), then the admin can execute the Can_Add_att
action on the user u. After execution of the action, the attribute b of user u will be
added to value 3 (target attribute b3). Similarly, the Can_delete_att requires
an admin whose role attribute value must be 2 in order to be enabled (i.e., admin
condition a2). The user condition true means that any user u can be affected by this
action. After execution of the action, the attribute c of certain user u will be revoked
from the value 3 (target attribute c1: this means that if the user u has attribute c
with value 1, after executing the Can_delete_att, the attribute c of the user u
no longer has value 1).
Given a Can_Add_att administrative action:
Can_Add_att
ad_role_value,u_att_value1,
u_att_value2,…,
u_att_valuen;target_value
This action can be expressed in ﬁrst-order logic as follows:
∃ua, u. (ua, ad_role_value) ∈UA .
∧(u, u_att_value1) ∈UA ∧(u, u_att_value2) ∈UA.
∧… ∧(u, u_att_valuen) ∈UA.
⇔UA’ = UA ∨(u, target_value).
Similarly,
Can_Delete_att
ad_role_value,u_att_value1,
u_att_value2,…,
u_att_valuen;target_value
can be expressed in ﬁrst-order logic as follows:
∃ua, u. (ua, ad_role_value) ∈UA.
∧(u, u_att_value1) ∈UA ∧(u, u_att_value2) ∈UA.
∧… ∧(u, u_att_value3) ∈UA.
⇔UA’ = UA \ (u, target_value) .
For
example,
the
action
Can_Add_att a1, b2, b3; c1 will
be
expressed:
∃ua, u. (ua, a1) ∈UA ∧(u, b2) ∈UA ∧(u, b3) ∈UA.
⇔UA’ = UA ∨(u, c1) .
And the action Can_Delete_att a2, b1, c1; d5 will be expressed:
∃ua, u. (ua, a2) ∈UA ∧(u, b1) ∈UA ∧(u, c1) ∈UA.
⇔UA’ = UA \ (u, d5) .
After we represent all components of GURAG policies using MCMT language,
we now will invoke the backward reachability algorithm implemented in MCMC to
analyze the GURAG policies. For simplicity, we describe the underlying process of
the backward reachability algorithm by using the following example:
Let consider a GURAG security analysis problem as follows: the goal is {b1} and
the following administrative actions:
Can_Add_att true , true ; a1 (1)

342
A. Truong
Can_Add_att a1 , c1 ; b1 (2)
Can_Add_att a1 , b1 ; b2 (3)
Can_Add_att a1 , true ; c1 (4)
Note that we assume that the initial state is the state in which all attributes of users
and admins are not assigned to any value. The process of backward reachability
algorithm will work as follows: First, since the goal is b1, so, the algorithm will
select all actions that can target the goal, e.g., action (2) will be selected because its
target value is b1. Then, in order to be enabled, the action (2) requires an admin with
attribute value a1. Moreover, it also requires a user u with attribute value c1: (i) To
obtain a1, the algorithm continues to select all actions in which the target value is a1.
Then, the action (1) is selected and the algorithm will analyze it: the admin condition
and user condition of the action (1) are true, thus, action (1) can be executed at any
time without any condition (e.g., do not require admin and user attributes are assigned
to some values). This means that the action (1) can be executed at the initial state.
Then, the algorithm stops the process that analyze a1. (ii) For a user u with attribute
value c1, the algorithm selects all actions in which the target value is c1. Then, the
action (4) is selected and analyzed: this action requires an admin with attribute value
a1 and does not require any condition for the user u (note that the user condition is
true). Clearly, an admin with attribute value a1 can be obtained by using the process
in (i). Then, the algorithm also stops the process analyzing c1. Now, the algorithm
returns “unsafe” for this security analysis problem and outputs a sequence of actions
(1) →(4) →(2) that leads the system from the initial state to the goal.
4
Evaluation
In this section, we show the evaluation we conducted in order to evaluate the effec-
tiveness of our technique. To the best of our knowledge, some recent researches
[16] have introduced some novel ideas to analyze the ABAC systems but there is no
available implemented analysis technique up to now. Thus, we cannot conduct exper-
iments that compare our analysis technique with the similar ones (we will leave this
as our future works when there are some available analysis techniques for ABAC).
We implement the translation module in Python and use the implemented model
checker MCMT as our backward reachability analysis technique.
We also generate a set of test cases to use for the analysis of the GURAG model
based on the real test cases for the RBAC model collected from hospitals and univer-
sities [13]. Because the set of admins and the set of users must be separated [8], thus,
we will generate the two sets of administrative actions: one for admin and one for
normal user. The RBAC model test cases are a set of test cases that use roles. The
GURAG model uses the RBAC model to manage admins. So we remain the actions
in the RBAC test cases as administrative actions for the admin. We then add random
actions that are administrative actions on the user. We denote the admin attribute
role as “a” in an administrative action. User attributes will be denoted with the next

On the Analysis Problem of the Attribute-Based Access Control …
343
Table 1 Experimental results with Test suite 1
#
Max value of
admin role
Number of user
attributes
Max value of
each attribute
Number of
actions
Average time
(sec)
1
5
2
5
15
0.53
2
10
3
10
15
0.67
3
15
5
10
30
2.62
4
20
7
15
40
3.70
5
25
10
25
60
7.89
6
30
15
30
70
11.20
7
35
20
50
100
12.45
letters b, c, d … For example, an administrative action for affecting admins would
look like:
Can_Add_att a1, a2, a3; a4
where an admin whose role attribute value is a1 could assign the role attribute
value a4 to an admin who owns the role value attributes a2 and a3 at the same time.
Similarly, an administrative action for a user would look like:
Can_Add_att a2, b1, c1, d5; c2
where an admin whose role attribute value is a2 can assign the attribute value c2
to a normal user that owns attributes value b1, c1, and d5 at the same time.
For each test case, we run ten times with different goals and measure the average
time taken for the veriﬁcation process. All experiments were performed on an Intel
Core i7 CPU with 4 GB Ram running Ubuntu 12.04 LTS 32 bit.
In Table 1, we report the running time of our proposed technique on Test suite 1
that includes seven general test cases. Second column shows the maximum value of
the admin role. The third column indicates the number of user attributes for each test
case while the maximum value of each attribute is reported in Column 4. Column
5 shows the number of actions of each test case and Column 6 reports the average
running time of our techniques on the test cases. According to the result, our analysis
technique seems to be scalable since the running times are acceptable. The running
times for the “complex” test cases (that parameters are similar to the real system)
are around seconds.
In Table 2, we report the experiment result when we select a test case in which:
the maximum value of admin role is set to 10; the maximum value of user attribute
is 20; and the number of actions is set to 100. Then we increase the number of user
attributes and run our analysis technique to see how the number of user attributes
affects the analysis time. Column 2 shows the number of user attributes and Column
3 reports the average running time for each test case. According to the experiment, it
seems that the running time increases “linearity” when the number of user attributes
increases (Table 3).

344
A. Truong
Table 2 Experimental results
with Test suite 2
#
Number of user attributes
Average run-time (sec)
1
2
0.60
2
3
1.68
3
5
3.87
4
7
6.76
5
10
10.83
6
15
11.28
7
20
13.69
Table 3 Experimental results
with Test suite 3
#
Number of actions
Average run-time (sec)
1
30
3.22
2
50
2.68
3
70
0.83
4
100
310.33
5
150
154.12
6
200
59.19
7
250
146.72
8
300
457.10
In the third experiment, we report the experiment result when we select a test case
in which: the maximum value of admin role is set to 10; the number of user attributes
is 7; and the maximum value of user attribute is 10. We run our proposed analysis
technique with the number of actions increasing to see how such a number affects
the analysis time. Column 2 shows the number of actions and Column 3 reports the
average running time for each test case. According to the experiment, the number of
actions affects much to the analysis time. One reason to explain this is that the well-
known state space explosion problem happens when the number of actions explodes.
Thus, some heuristics that try to alleviate the problem need to be considered and we
leave this as our future work.
5
Conclusions
In this paper, we have proposed a technique using the SMT-based model checker
approach to solve the security analysis problem in HGABAC and GURAG system.
The main idea is to investigate the backward reachability algorithm implemented in
MCMT to analyze the GURAG policies. To do this, we implement an module that
translates all components of GURAG policies such as goal, attributes, administra-
tive actions, … to the language of MCMT and then adapt the backward reachability

On the Analysis Problem of the Attribute-Based Access Control …
345
algorithm t the analysis process. We also perform some experiments to show the
scalability of our proposed technique on some test cases. We also describe the effec-
tiveness of some factors such as number of user attributes and number of actions on
the analysis time.
Analysis time is an important factor in evaluating the efﬁciency of the analysis
technique. As shown above, the model checking-based analysis technique may be
affected by the well-known state space explosion problem. Therefore, alleviating
such problem is one of the next future works we need to conduct. The main idea is to
design some heuristics that try to reduce the state space explored during the analysis.
Besides, considering the security analysis problem on the other two sub-models of
GURAG (i.e., UGAA and UGA sub-models) are also research directions for our
future work.
Acknowledgements This research is funded by Ho Chi Minh City University of technology -
VNU-HCM under grant number T-KHMT-2019-70
References
1. National Computer Security Center (NCSC). (1987). A guide to understanding discretionary
access control in trusted system, Report NSCD-TG-003 Version1, 30 September 1987.
2. Osborn, S. (1997). Mandatory access control and role-based access control revisited. In
Proceedinds of the 2nd ACM Workshop on Role-Based Access Control, RBAC 1997 (pp. 31–40).
ACM.
3. Samarati, P., & Vimercati, S. (2000). Access control policies, models, and mechanisms. In
FOSAD: International School on Foundations of Security Analysis and Design (pp. 137–196).
4. Sandhu, R. S., Coyne, E. J., Feinstein, H. I., & Youman, C. (1996). Role-based access control
models. IEEE Computer, 38–47.
5. Ferraiolo, D., & Kuhn, R. (1992). Role-based access control. In 15th National Computer
Security Conference (pp. 554–563).
6. Sandhu, R., & Ferraiolo, D., & Kuhn, R. (2000). TheNISTmodel for role-based access control:
Toward a uniﬁed standard. In 5th ACM Workshop Role-Based Access Control (pp. 47–63).
7. Gupta(B), M., & Sandhu, R. (2016). The GURAG administrative model for user and group
attribute assignment.
8. Sandhu, R., Bhamidipati, V., & Munawer, Q. (1999). The ARBAC97 model for role-based
administration of roles. ACM Transactions on Information and System Security (TISSEC),
105–135.
9. Ranise, S., & Truong, A. (2014). Alessandro Armando: Scalable and precise automated anal-
ysis of administrative temporal role-based access control. In Proceedings of the 19th ACM
Symposium on Access Control Models and Technologies (pp 103–114) ACM.
10. Ghilardi, S., & Ranise, S. (2010).MCMT a model checker modulo theories. In Proceedings of
IJCAR’10, LNCS.
11. Ghilardi, S. (2010). Ranise: Backward reachability of array-based systems by SMT solving
termination and invariant synthesis. Logical Methods in Computer Science, 1–48.
12. Dinh, K., & Truong, A. (2019). Automated security analysis of authorization policies with
contextual information. In Transactions on large-scale data- and knowledge-centered systems
XLI (pp. 107–139). Springer.
13. Silvio, A., & Truong, A. (2014). Armando: SACMAT 14 Proceedings of the 19th ACM
Symposium on Access Control Models and Technologies (pp. 103–114).

346
A. Truong
14. Ranise, S. (2013). Symbolic backward reachability with effectively propositional logic.
Applications to security policy analysis. FMSD, 24–45.
15. Truong, A. (2019). Adventures in the Analysis of Access Control Policies. In The Proceedings
of FDSE 2019: Future Data and Security Engineering (pp. 467–482). Springer.

The Freshness of Food Detection Using
IoT and Machine Learning
Snehal Chalke, Sowmya Ganesan, Krishna Gajera, Pooja Reshim,
and Nita Patil
Abstract The Internet of things (IoT) describes the network of physical objects
that are embedded with sensors, software, and other technologies for the purpose of
connecting and exchanging data with other devices and systems over the Internet.
Technologies like Internet of things connect anything at anytime and anywhere. This
paper essentially deals with the turn up technologies alongside the Internet of things.
In this we have used NodeMCU as a microcontroller and programmed the sensors
like MQ4 sensor, MQ9 sensor, DHT11 sensor with it. If the food which comes in
contact with the sensors is spoilt, then the buzzer will get activated and the LCD will
display whether the food is healthy or not. Hence, the output is sent to the well-known
ThingSpeak platform, and the consumers will be alerted.
Keywords Food safety · IoT · ML · NodeMCU · Arduino IDE · Food detection ·
ThingSpeak
1
Introduction
For freshness and quality of food elements, measurements of parameters like gas
level, moisture, and humidity are important. Freshness describes the presence and
absence of deterioration. The detection of freshness of food has become an important
routine in the ﬁelds of food industry. It makes major contribution to the quality of
food. Food products are healthy or not, this prediction is made using the following
standards as:
(1)
If food is attacked by germs or say microorganisms, the oxygen level is to be
lower than it normally is.
(2)
Many vegetables and fruits (banana, apple) release methane gas when they are
spoilt or over-ripened.
We have used MQ4 and MQ9 sensors to examine the quality of food for avoiding
and reducing ill health. It determines like household food items such as vegetables,
S. Chalke (B) · S. Ganesan · K. Gajera · P. Reshim · N. Patil
BE EXTC SIES GST, Mumbai, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_27
347

348
S. Chalke et al.
fruits, dairy products, and meat. The unhealthy food items are going unexplored to
the consumers. Mostly the process of checking food quality is done by person sitting
across conveyor belt. Hence, to examine the freshness and quality of food automated
process is brought. Hence, the main advantage is it reduces the manual manpower.
One of the physical environments is food. For maintaining good health, vitality,
and well-being of an individual, hygienic food is must. Food can also transmit
diseases during any procedure from producer to consumer, so proper precautions
must be taken. When ethylene reacts with oxygen from the air the ripening process
of banana occurs. With increase in time, these gases also increase. Quality of food
is not always ensured.
2
Literature Survey
Another approach [1] is based on examining the food whether the food is healthy or
not. The drawback of this approach is by capturing food only outer part is detected.
A sensor is determined by an MIT team which determines unhealthy meat items, but
it will show incorrect output, as it only determines a certain gas.
To get a result, we are taking collective results of oxygen and methane sensors
and not relying on one sensor. By using this, we can get an actual output. We can
increase interoperability and application by combining IoT and machine learning.
Recently done research [2] combines a continuous monitoring system through a food
supply chain. This research helps in determination of the accuracy of the prediction
of shelf life of a self-learning model and to estimate the enhancement of the current
supply chain. With a focus on the enhancement of a real-time self-learning model
that differs from previous research, taking into account active data of measurements
on the product level throughout the entire supply chain.
Paper [3] is for freshness of food detection using various sensors such as electrical
and biosensors. An intelligent system is made, which detects quality of food, various
foods such as fruits and meat. Whether the food is consumable or not, the sensors
(gas, moisture), selection of hydrogen ion concentration device ensures the quality
of food whether the food is healthy or not. Hence, an application is made to fulﬁll
this need.
This paper [4] is about the categorization of bacteria in different food. The main
aim of this paper is to develop a system to detect the gas with speciﬁc gas sensors
which will determine three standard types of bacteria. Categorization is done if a
particular bacterium is available in before cooking phase as well as in after cooking
phase.
In this paper [5], the parameters like oxygen and carbonic acid gas accumulation
are observed, which is applied for quality of food management. The freshness of the
food depends on the concentrations of oxygen and carbon dioxide gas. For obser-
vation of gases, we are using this system, and it is connected with radio-frequency
identiﬁcation (RFID) tag. RFID system is easier to supervise. For the calculation of
freshness of vegetables, this combined system is used.

The Freshness of Food Detection Using IoT and Machine Learning
349
3
Methodology
See Figs. 1, 2, and 3.
We have used three sensors. Relay is used to switch the sensors. DHT11 sensor
is the digital sensor, so we have connected to any pin, and for this, we do not need
to use any extra circuit. LCD is used, and it has 16 pins; we cannot directly connect
to NodeMCU because it does not have that much pins, so for this we have one
converter, named I2C converter; this converter is added to the LCD inter-integrated
circuit technology (I2C). It has only 4 wires: Vcc, Gnd, Clk, and Data.
MQ4 and MQ9 sensors have 6 pins: A, A’, B, B’ (for sensing elements) and h h’
(for heaters). Heaters require more power, i.e., more current; therefore, we have to
connect 5 V power supply. In our project, we have used SMPS.
Hence, we have used double pole single throw (DPST) relay by default MQ4 is
connected to analog input, and when we want to measure MQ9, then relay will be
operated, and MQ9 is connected to analog input. So this is our design using only one
analog. We have to measure two analog sensors. Therefore, DHT11 sensor which
will sense humidity and temperature, MQ4 which will sense methane gas, and MQ9
for oxygen gas are connected to NodeMCU.
Sensor will sense the data and will display the output on LCD that the food is
spoilt or not and, respectively, their sensor values. So if MQ4 < 270 and MQ9 < 190,
the food is not spoilt otherwise it is spoilt. The buzzer will be ON if the food is spoilt.
Then this data is stored in cloud using ThingSpeak platform. We are using machine
learning algorithm to compare the results we get in IoT and ML. Our project aims
to detect food spoilage using appropriate sensors monitoring gases released by food
items, and we are going to implement machine learning algorithm to predict whether
food is spoilt or not. The detection of a food item is spoilt or not can be decided using
below theories:
(1)
If food is attacked by germs or say microorganisms, the oxygen level is to be
lower than it normally is.
Fig. 1 Block diagram of spoilt food detection system

350
S. Chalke et al.
Fig. 2 Flowchart
(2)
Many vegetables and fruits (banana, apple) release methane gases when they
are spoilt.
Methane sensor, oxygen sensor, temperature and humidity sensors are the sensors
used. Values will be given to logistic regression which is machine learning for
predicting whether given sample of food is spoilt or not.
We are using microcontroller as practical application of IoT to store data, and it
also encounters spoilt food items and rings a buzzer when food spoilage is detected.
This data is then sent to cloud platform so that authority can monitor the quality

The Freshness of Food Detection Using IoT and Machine Learning
351
Fig. 3 Circuit diagram
of food items, frequency of food spoilages in a day. This will increase competition
among retailers to sell more healthy food and safe food for consumers.
3.1
Components Required
1.
MQ 4, MQ 9, DHT 11 Sensor
2.
ESP8266 NodeMCU
3.
Relay
4.
I2C 1602 Serial LCD
5.
Buzzer
6.
Diode.
3.2
Result
See Figs. 4, 5, 6, 7, 8, and 9.
3.3
Machine Learning Algorithms
• Machine learning is a branch of artiﬁcial intelligence based on the idea that
systems can learn from data, identify patterns, and make decisions with minimal
human intervention. To enhance the productivity, we have used ML as another
approach. Input values which we received from sensors in real time will be used
in the machine learning algorithm.

352
S. Chalke et al.
Fig. 4 Implementation of components
Fig. 5 Sensor values on
LCD screen
Fig. 6 Final output
• We have collected samples of spoilt/not spoilt food items, oxygen and methane
concentrations as well as environmental conditions for each sample which will
be used to train machine learning algorithms.
• Logistic regression: Logistic regression is the machine learning algorithm used
to obtain odds ratio in the presence of more than one explanatory variable. In
our project, output classes are binary: ‘Spoilt’, ‘Not Spoilt’. Hence, for different
days, we need to obtain the probability of being spoilt. Performance of logistic

The Freshness of Food Detection Using IoT and Machine Learning
353
Fig. 7 These are the images of the temperature readings stored in ThingSpeak Web page
Fig. 8 These are the images of the fruit freshness readings stored in ThingSpeak Web page
regression is best regarding mean-squared error and percentage accuracy than
other classiﬁcation algorithms, so it is chosen.

354
S. Chalke et al.
Snapshot of Machine Learning Output.
Fig. 9 These are the images of the machine learning readings stored in ThingSpeak Web page

The Freshness of Food Detection Using IoT and Machine Learning
355
3.4
Cloud Platform Integration
We have used the popular cloud platforms like ThingSpeak which is an IoT platform
to store and recover all the data one place. So, from this we can get the set of data from
which we can examine the peak time duration when food is getting spoilt mostly,
number of spoilt food items which are separated successfully, and probability of the
food getting spoilt if it is brought from a certain vendor. Hence, by using ThingSpeak
cloud platform, we can store substantial amount of data related to food items and
can be viewed on the Web page from anywhere as a practical application of IoT.
4
Future Scope and Applications
Further design can be modiﬁed by increasing size of conveyor belt so that it is possible
to perform quality inspection of large food products and increasing accuracy of the
system so that it can differentiate between artiﬁcial from original food. As we are
using the DHT11 temperature sensor, using that sensor we can predict the shelf life
of the given food.
• For the retail stores, we can implement our system inside the shelves and
containers and also below the weighing machine.
• For the food industry, we can place our system across the conveyor belt as in the
industries large number of foods is processed along the conveyor belt.
• For the household use, we can implement our system inside the refrigerators.
5
Conclusion
It is very necessary to implement safe food handling practices and procedures at
every stage of food to avoid food borne diseases. Food products may encounter any
number of health hazards during their journey through the supply chain; hence, it is
needed to monitor freshness or quality of food time to time.
In our work, information fusion was implemented using NodeMCU, which yields
goodresultsinvariousworkingenvironments.Informationfusionreducestheamount
of storage space as well as increases the computational power considerably.
This project can be used to automate the food industry by using simple combina-
tion of sensors, Internet of things, and machine learning. It will also encourage food
manufacturers to sell and purchase healthy food by keeping records of food samples
at every stage. We can also create competition to sell more healthy food among
retailers. Hence, spoilt food samples can also be removed efﬁciently by reducing
manpower.

356
S. Chalke et al.
References
1. Chen, J. I. Z., & Yeh, L.-T. (2020). Analysis of the impact of mechanical deformation on
strawberries harvested from the farm. Journal: Journal of ISMAC (3), 166–172.
2. Hebbar, N. (2020). Freshness of food detection using ml and IoT. In International Conference
on Emerging Trends in Information Technology and Engineering (ic-ETITE).
3. Jain, S. A., & Bharadwaj, A. (2020). Characterizing WDT subsystem of a Wi-Fi controller in
an Automobile based on MIPS32 CPU platform across PVT. Journal of Ubiquitous Computing
and Communication Technologies (UCCT), 2(04), 187–196.
4. Mustafa, F., & Andreescu, S. (2018). Chemical and biological sensors for food-quality
monitoring and smart. Philosophical Transactions of the Royal Society A, London, A247,
529–551.
5. Alcéo R. G. A. (2016). Temperatures and shelf-life duration in the strawberry supply chain.
Universidade de Lisboa.

Prediction of Signal Drop Due to Rain
at User Cellular Signal Reception
D. Lohith Bhargav, D. Achish, G. Yashwanth, N. Pavan Kalyan,
and K. Ashesh
Abstract The availability of signal to users is the most difﬁcult aspect of communi-
cation, yet massive changes in the environment result in signal loss. Also, the signal
loss will result in reduced availability of signal receptions, and, in extreme cases,
there will be a full signal loss without establishing any communication with the rest
of the world. This paper discusses about the prediction of cellular signal loss due to
rainfall. The cellular signals are affected by some factors like temperature, rain, fog,
wind, etc. When a radio signal travels through rain, it may be reﬂected, refracted or
dispersed, causing the signal to diverge or stop communication. As this is considered
as the most common case for cellular communications, it necessitates the need to
predict the signal loss/drop due to rain and also to visualize signal loss in a variety
of circumstances. Henceforth, to predict the future signal loss, this research work
has developed an algorithm by using machine learning (ML) techniques, which can
predict the signal loss in different rainfall conditions. After the prediction of signal
loss, the proposed model analyses the resulting data by which we can infer some
improvement techniques for attaining better cellular signal receptions at the user
end.
Keywords Availability · Signal · Receptions · Loss · Predication · Rainfall · Drop
1
Introduction
The mobile signal that travels from one device to another device by the operator
helps in establishing communication from one point to another with reduced latency.
The signal strength is set according to the area and their availability, and also the
signal strength may vary according to the population and number of usages. Also,
the signal strength may vary due to the materials utilized and also the size of that
material. Nowadays, the signal speed is also getting increased due to an increase
in new generations; this new generation needs a strong signal strength and low
D. L. Bhargav · D. Achish · G. Yashwanth (B) · N. P. Kalyan · K. Ashesh
Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation,
Vaddeswaram, Guntur, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_28
357

358
D. L. Bhargav et al.
latency that helps in establishing a seamless communication. There will be some
areas that contain fewer signals due to different scenarios, where signal drop due to
environmental changes like rain, humidity, fog, etc., can be detected.
Factors Affect the Cellular Signals
1.
Rain: When raindrops are larger, the cellular signals will be scattered, and it
weakens the cell signal more than any other weather conditions.
2.
Fog and Clouds: Just like rain but smaller droplets. Fog also seriously scatters
the signal but is not considered as a huge factor.
3.
Snow: Ice crystals are less dense than liquid water, in snowfall form, so they do
not have nearly the same effect on signal propagation. Also, very heavy snow
may still refract radio waves and reduce the signal strength.
4.
Hail: Depending on the size and density of hail, ice is less dense than water and
hail is not as thick as rain, so it slightly refracts the cell signal.
5.
Lightning: A huge charge of a lightning bolt can cause electrical interference,
and it can damage the equipment like antennas and other transmission resources.
6.
Wind: Only wind will not affect the radio signals. But the condition associated
with it can cause damage to the exposed cell towers, power lines, etc.
7.
Bodies of Water: Radio signals travelling across bodies of water and ice water
temperatures can create surface inversions, which result in a delay in reception.
8.
Tress: A heavy dense forest with a combination of trees and water results in
reﬂecting and absorbing radio signals.
9.
Physical Obstructions: The presence of physical objects causes limitation on
receptionbecausethesignalsarepresentinthelineofsight.Amountain/building
with heavy metal/vehicles causes interference with the signals, even when it
travels for a short distance.
Effect of Rain on Cellular Signals:
The effect of the signal is determined by the rain that contains varying size of droplets,
the raindrop size and the distance between the raindrops; light rain absorbs the signal,
whilst medium and heavy rain scatters it. At most times, the radio signals that travel
from the tower to the user’s device will be consistent, but when the environment
changes, there may be a signal loss that disrupts the seamless communication. The
high-frequency signal used by phones does not travel well through water because
water conducts electricity, where it reﬂects radio waves and water vapour absorbs
the energy of radio signal to turn it into heat and also the same phenomenon is used
in microwaves. We can observe a drop in signal strength, the signals are calculated in
Dbm,andwegetvaluesforsometimebywhichwecanturnthevaluesintoagraphical
representation. Certainly, we can know the efﬁciency of signal and drop/loss of signal
through which we can analyse the data and after data cleaning, which eliminates the
unusable data so that data gets more useful and the data will be in comma-separated
values (CSV) format to predict the data. Also to perform data visualization, we
consider many data to ﬁnd the next value.

Prediction of Signal Drop Due to Rain at User Cellular …
359
Fig. 1 Signal strength
Rain Concentration:
The rain concentration determines the different categories of rain like light rain
and heavy rain. Usually, it is determined by calculating the distance between two
raindrops.
Light Rain: If the distance between the two raindrops is more, then it is considered
as light rain, and it can cause low attenuation.
Heavy Rain: If the distance between the two raindrops is less, then it is considered
as heavy rain, and it can cause high attenuation.
Signal Strength:
• Signal strength can range from −30 to −110 dbm.
• The closer number to 0 is considered as the strongest signal.
• Signal strength greater than −85 dbm is considered as usable signal (Fig. 1).
Possible Ways to Enhance Signal Reception:
Some strategies can help us enhance signal reception, but we need to know where
to utilize them and under what conditions they may be used. If we can forecast all
future situations, we will be able to choose which methods to employ in order to
improve the reception.
1.
Using Boosters: A booster antenna is used for achieving reliable connection
from a nearest cellular tower.
2.
Using Repeaters: If the reception was weak within a structure but excellent
outside, the signals were lost due to physical things such as metals. We can
employ cellular repeaters in these situations to extend the range of your cellular
networks for achieving greater indoor coverage.
3.
Expansion to a Short Range: Due to the rain, the signals have not reached the
destination areas, where we need to extend the network availability to a small
range. In this kind of situation, the signal strength can be increased by increasing
the power to generate the signal that gets transmitted to the destination. For every
+3db, the power to generate that signal is twice the required energy.
4.
Expansion to a Long Range: Due to the unexpected heavy rainfall, the towers
are damaged and not in working condition, because of this, the whole commu-
nication at that place was stopped. In this case, we can increase the range of the

360
D. L. Bhargav et al.
network availability by increasing the energy required to generate a signal that
is four times the normal energy, where this signal can reach double the distance
than normal signal availability range.
Importance of Data set:
Data sets in the real world are used to calculate the difference between two values,
which helps in gathering the data, and it can also be used for representation. Many
algorithms are available to know about the signal loss, but no predictive measures
are taken by an operator due to the climatic changes but we try to collect the data
from different sources and also different data sources are analysed to understand the
scenario, we should remove some unnecessary and listless values, and we need to
train a data set for prediction of future values. So further, we take a testing data set
to predict value especially after the completion of training data phase. The trained
data is also compared with the test data set for analysing the accuracy, and also there
may be a different scenario because of static values or constant changes in climatic
change, we test different data sets and compare them, then we receive correct values
by which we can decrease signal loss or signal drop, and we also evaluate data in
graphical form for achieving a better understanding on efﬁciency.
2
Motivation
Technology has ruined patience in every facet of life in today’s fast-paced world,
and every demand must be fulﬁlled as soon as possible. However, this tendency
of communication has existed for a long time, and researchers could continue to
look for developing better and faster communication technologies.
Different communication technologies are used by the network operators. If the
network operator was not providing the customer requirements like network avail-
ability, data speed, etc., then there will be a chance of losing the customer support.
A network operator has a signal loss perception at user signal reception. They inves-
tigated the situation and discovered that it was increased by environmental changes.
As a result, the operator requests a detailed report on the situation as well as solutions
to the issues.
3
Methodology
The ﬁrst thing to do is clean the data set to ensure its accuracy and completeness, so
that we can generate excellent predictions.
The working process of data cleaning includes the following:
• Data auditing
• Workﬂow speciﬁcation

Prediction of Signal Drop Due to Rain at User Cellular …
361
• Workﬂow execution
• Post-processing and controlling
• Parsing
• Data transformation
• Duplicate elimination
• Statistical methods.
The second thing to work on is data visualization, which represents the data set
in graphs to obtain a better understanding, summarization and analysis. The data
visualization model used for this project is scatter plot (also called a scatterplot,
scatter graph, scatter chart, scattergram, scatter diagram), which is a type of plot
diagram using Cartesian coordinates to display the values for typically two variables
in a set of data.
Prediction Algorithm: To predict the values using a data set.
Support vector machine [SVM] is a supervised algorithm, which is used to predict
any kind of values based on the existing values. A support vector machine (SVM)
is used to analyse the data by using regression analysis. SVM is a robust prediction
method that has been used to predict the data, wherein this method can calculate short
data sets but it can handle complex values. Also, SVM functions more efﬁciently
when compared to linear classiﬁcation by using the Kernel trick, and it is used for
classiﬁcation, regression and outlier detection. When there is only clean data, SVM
performs pretty well when compared to other methodologies. Unlike other regres-
sion models, SVM minimizes the error between real-world values and predicted
values. For large data sets, SVM is used, also it provides faster implementation when
compared to other regression models, and it depends only on the subset of the training
data because the cost function does not consider samples, whose prediction is close
to the target. Also, based on our resources, this is considered as the best suitable
model to predict the signal drop based on the available data set.
The advantages of support vector machines are as follows:
• Effective in high-dimensional spaces.
• Effective in cases, where the number of dimensions is greater than the number of
samples.
• It uses a subset of training points in the decision function, so it is also considered
as memory efﬁcient.
Support Vector Machine Algorithm:
1.
Import the packages.
2.
Read the data set.
3.
Split the column, which is going to be predicted.
4.
Create a variable and assign how many days you should take to predict.
5.
Create the independent data set.
6.
Convert the data frame into a NumPy array.
7.
Create the dependent data set.
8.
Convert the data frame into a NumPy array.

362
D. L. Bhargav et al.
9.
Split the data into 80% training and 20% testing.
10.
Create and train the support vector machine [SVM].
11.
Print the predictions for the next n minutes.
4
Literature Survey
Base Paper 1: Effect of Rainfall on Cellular Signal Strength: A study on the variation
of RSSI at user end of smartphone during rainfall.
Overview: The change of climatic conditions and the rainfall can cause a signal loss,
so in this we can use signal strength Android application programming interface
which is also known as APIs that can help in reduction lo signal loss, by using both
received signal strength indicator (RSSI) and roaming options, it helps to ensure
fast strong connections. Users of RSSI always experience a strong signal to their
access point usage of fast roaming to speed the security connections when you use
wireless application protocol (WPA2) enterprise security. Electromagnetic signals
get reduced when there is rainfall, rainfall absorbs the signal when there is a low rain
and scattered when there is medium or heavy rain, and more the raindrops, there will
be more signal loss. Due to the air, the shape of the raindrop gets changed. So, when
there is air, the angles of the raindrop change and then the values get changed. There
may be variations between microwave links and end-users, we can ﬁnd differences
in transmission power. Now we can ﬁnd the signal strength in a smartphone because
there are more sensors involved that detect the signal range, and signal strength can
give us accurate values. The measurement has been taken at a period so that the values
will be static and can calculate accurately, in this experimentation, we found there
is a signal loss due to the inefﬁciency in RSSI that shows the quality of a network
signal.
Base Paper 2: Determination of the Effect of Rain on Cellular Signal Receptions.
Overview: We must take different scenarios or different conditions to collect the
data. We must collect a huge amount of data to make predictions as accurate as
possible. In a rainfall scenario, there will be both absorption and signal scattering, in
light rain there will be absorption, whereas in medium and heavy rain the signal gets
scattered. In this, they have taken the limited area to ensure there will be no physical
objects or any objects, so the calculation gets as simple as possible. The radio signals
are affected by the scattering and absorption of rainfall, and this experimentation
refers to different patterns that affect the cellular network signal. The effect of the
signal is more when there is heavy rain, and light rain does not affect much due to
the frequency from the operator. There will be an increase in signal strength during
medium or heavy rain so there will be no signal drop when there is no rain or light
rain, and the speciﬁc time when there is heavy rain should be predicted. There is a
collection of data in three different conditions, the duplicate data has been removed
from the data set, and the data set is used for further process.

Prediction of Signal Drop Due to Rain at User Cellular …
363
Base Paper 3: A Study on the effect of Temperature on Cellular Signal Strength
Quality.
Overview: The world relates to wireless connections which are connected through
smartphones, and there are many sensors in smartphones by which we can see the
frequency of the signal. The weather is measured by a gauging instrument by which
we can observe the change in temperature or climate. The world is moving towards
effective communication, so to calculate the signal strength we use signal strength
Android API for measurement the signal in real time, some end-users by seeing the
readings of the RSSI user get an understanding of the drop of signal in different
atmospheric conditions. The signal condition depends upon the radio channel and
links. The higher the temperature, the signal strength may be disturbed, and the
readings were taken from the RSSI which can be seen in the smartphone which
contains data of different time intervals. Transmitters are used to provide the much
gain in ampliﬁers that gives a boost in thermal effect on CMOS transmitters.
Base Paper 4: Determination of the Inﬂuence of Wind on Received Cellular Signal
in a Heavy Vegetation Environment.
Overview: The signal gets affected by four major issues that include reﬂection,
diffraction, obstruction and scattering, and there may be some distractions such as
buildings,wallsandtrees.Thedifferentclimaticconditionsarerainfall,fog,humidity,
etc. The air contains water molecules which add weights that increase pressure when
a signal gets on its way. When the signal is sent through a wind, the signal gets
scattered into multiple directions, and it may lose to the end-user or get attached to
another signal. The experimental data set is taken in a limited time which helps in
taking static values to calculate and ﬁnd the signal loss or the drop of the signal. The
data set has been taken average to know the mean predicted value.
Base Paper 5: Effect of Rainfall on Link Quality in an Outdoor Forest Deployment.
Overview: There is more number of wireless communication, and there are sensors
that are interacting with cellular signals. The data is sent at a bulk state where the
data will be hundreds of kilobytes which transfers from user to operator and from
operator to end-user; this huge data should be shared as the shortest path possible
that gives efﬁciency; if the data is not transferred, the data again gets retransmitted;
this experimentation was done outdoors which contains various obstacles that affect
signal. They ﬁxed the location to the forest environment so that the area will be static
and the temperature near the forest keeps changing, and the experimentation has
been done on limited time which tells us the exact usage drop of the signal at given
time.

364
D. L. Bhargav et al.
5
Result and Analysis
After predictions, here are the outputs, as mentioned before in the introduction that
any signal less than or near to −100 dBm is not useful and it cannot establish
communication. So, −100 dbm is considered as extreme condition. At a near point
time, the condition is reported and sent to the network operator. So, they can increase
the signal and improve the availability of signals.
1.
Signal loss due to no rain (Figs. 2 and 3)
2.
Signal loss due to light rain (Figs. 4 and 5)
3.
Signal loss due to heavy rain (Figs. 6 and 7).
Fig. 2 No rain. Predicted values range in no rain conditions: −81 to −91 dbm
Fig. 3 No rain and found no conditions of loss of signal
Fig. 4 Light rain. Predicted values range in light rain conditions: −78 to −100 dbm

Prediction of Signal Drop Due to Rain at User Cellular …
365
Fig. 5 Light rain and found two conditions of loss of signal at times −42, 44 min
Fig. 6 Heavy rain. Predicted values range in heavy rain conditions: −78 to −100 dbm
Fig. 7 Heavy rain and found two conditions of loss of signal at times −32, 35, 37, 42 and 45 min
Performance Analysis:
We have collected the signal strength for using the signal strength feature in mobile
(which is standard in every mobile).
In mobile device, we can ﬁnd this in Settings > About Phone > Status > SIM
Status > Signal Strength.
From the collected data, we predicted the signal strength and compared it with
the actual measured signal strength from collected data.
After calculating the cumulative performance based on the predicted values and
actual values, we got a range between 81.80 and 92.27% accuracy. The performance
testing is based upon no. of predicted values and no. of values taken to predict.

366
D. L. Bhargav et al.
6
Conclusion
By using the support vector machine algorithm, the future loss of signals can be
predicted based on the clean data set. Using the predicted data, we can estimate
when the signal was lost and at what time it was lost, based on how much signal loss
the operator is experiencing and the availability of the region, and we can utilize any
of the mentioned enhancement approaches depending on the circumstance. Also, the
details will be sent to the network operator to perform the required tasks to increase
the signal strength.
7
Future Scope
• Rain is not the only factor affecting the signal and nature; it can sometimes be
very unpredictable. In that case, any predicting models will not work using past
data.
• For utmost accurate results, time series algorithms are used for attaining better
and best nearest values.
• It can make a model, where present and past data in signal loss has been collected
continuously and the future loss of signal can be predicted; therefore, it will be
compared with real-world reading to ﬁnd the accuracy.
• Work on signal loss prediction with respect to temperature or any other factors
that affect the signal.
• Work on a prediction model to estimate the signal loss with all the factors that
could affect the transferring signals.
Acknowledgements Our thanks to Mr. K. Ashesh, Associate Professor, for guiding us throughout
the project and teaching us the relevant methodologies and helping us understand the needed
concepts. And thanks to Mr. Vege Hari Kiran (Head of the Department) sir for providing us with
the required facilities and guidance.
References
1. Alor, M. O., Abonyi, D., & Okafor, P. U. (2015). Determination of the effect of rain
on cellular signal receptions. https://www.researchgate.net/publication/333603272_Determina
tion_Of_The_Effect_Of_Rain_On_Cellular_Signal_Receptions.
2. Alor, M. O., Abonyi, D., & Okafor, P. U. (2015). Determination of the inﬂuence of wind on
received cellular signal in a heavy vegetation environment. https://www.researchgate.net/pub
lication/333603535_Determination_Of_The_Influence_Of_Wind_On_Received_Cellular_S
ignal_In_A_Heavy_Vegetation_Environment.
3. Markham, A., Trigoni, N., & Ellwood, S. (2010). Effect of rainfall on link quality in an outdoor
forest deployment. https://ieeexplore.ieee.org/document/5741509.

Prediction of Signal Drop Due to Rain at User Cellular …
367
4. Fong, B., Rapajic, P. B., Fong, A. C. M., & Hong, G. Y. (2003). Polarization of received signals
for wideband wireless communications in a heavy rainfall region. https://ieeexplore.ieee.org/
document/1159879.
5. Hendrantoro, G., Bultitude, R. J. C., & Falconer, D. D. (2002). Use of cell-site diversity in
millimeter-wave ﬁxed cellular systems to combat the effects of rain attenuation. https://ieeexp
lore.ieee.org/document/995519.
6. Sabu, S., Renimol, S., Abhiram, D., & Premlet, B. (2017). Effect of rainfall on cellular signal
strength: A study on the variation of RSSI at user end of smartphone during rainfall. https://
ieeexplore.ieee.org/document/8070024.
7. Sabu, S., Renimol, S., Abhiram, D., & Premlet, B. (2017). A study on the effect of temperature
on cellular signal strength quality. https://www.researchgate.net/publication/320652473_A_s
tudy_on_the_effect_of_temperature_on_cellular_signal_strength_quality.
8. Beritelli, F., Capizzi, G., Sciuto, G. L., Napoli, C., Scaglione, F. (2018). Rainfall estimation
based on the intensity of the received signal in a LTE/4Gmobile terminal by using a probabilistic
neural network. https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8365880.
9. Radio signal path loss. https://www.electronics-notes.com/articles/antennas-propagation/pro
pagation-overview/radio-signal-path-loss.php.
10. Support vector machine — introduction to machine learning algorithms. https://towardsda
tascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a44
4fca47.
11. Support vector machine algorithm. https://www.javatpoint.com/machine-learning-support-vec
tor-machine-algorithm.
12. How weather affects your cell signal. https://www.outsideonline.com/2186591/how-weather-
affects-your-phones-signal#:~:text=Rain,more%20than%20any%20other%20weather.

Wavelet Decomposition Methodology
for Improved Retinal Blood Vessel
Segmentation
Udayini Dikkala, Kezia Joseph Mosiganti, and Mukil Alagirisamy
Abstract Retinal image analysis requires extensive research, especially in the
proper detection of the blood vessels as the condition of these vessels helps the
ophthalmologist to identify certain underlying eye diseases. An approach based on
wavelet transforms, whose invariant moment features help in improved detection of
the vasculature, is proposed. This transform is a multiresolution approach that can
provide the ﬂexibility to work with a certain set of frequencies for quality improve-
ment in image analysis. In addition, there is a reduction in the speckle noise and an
enhancement in the edge detection. The quality is improved by considering the spec-
tral characteristics of the noise as opposed to its statistical properties. The mother
wavelet used is Daubechies db2 or D4. This method is evaluated on the publicly
available DRIVE database as a benchmark. This database consists of non-mydriatic
retinal fundus images. The accuracy obtained through this process is about 88%
with a speciﬁcity of close to 98% in the vasculature detection. A pre- and subsequent
processing methodology is used for the segmentation outputs enhancement.
Keywords Daubechies · Multiresolution · Retinal image analysis · Segmentation ·
Wavelet transform
1
Introduction
The multiresolution approach through wavelet decomposition with optimal basis
selection [1–3] has been an area of focus in image coding, fractal analysis and texture
discriminationsincethelasttwodecades.Inthelastfewyears,theapproachisfocused
on mainly medical image analysis in modalities (e.g., ultrasound, magnetic resonance
U. Dikkala (B) · M. Alagirisamy
Lincoln University College, Petaling Jaya, Selangor, Malaysia
M. Alagirisamy
e-mail: mukil.a@lincoln.edu.my
K. J. Mosiganti
Stanley College of Engineering and Technology for Women, Abids, Hyderabad, India
e-mail: keziajoseph@stanley.edu.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_29
369

370
U. Dikkala et al.
imaging (MRI) and computed tomography angiogram) both for compression and
enhancement, especially for clinical study and non-invasive treatment. In particular,
the application of analysis based on wavelets in the areas of retinal image analysis
includes visualization and information analysis. It is observed that this approach
provides an opportunity to work with a few of the spectral components at a time and
reduce the noise that is normally seen in the higher frequencies. The theory has been
applied in many realms of applications due to its ﬂexibility. This methodology may
be combined with adaptive thresholding, mathematical morphology [4] and super-
vised training algorithms to obtain an improvement in the image of the vasculature
structure.
The anomalies associated with the vasculature structure of the retina reﬂect the
health of the individual. The assessment that is carried out by the ophthalmologists
in the initial visits may not show these anomalies, even though it is inevitably time-
consuming. Research is being undertaken to provide a more accurate analysis of the
image through automated means prior to the visit to the specialist [5]. Changes in
the retinal blood vasculature might be observed due to the medical condition of the
patient. The blood vessels are connected by various layers [6] of cells as shown in
Fig. 1.
Examples of the conditions that may lead to the changes in the vessel structure
include a certain retinal condition that leads to the generation of very ﬁne capillary
vessels from the thinner vessels. Neovascularization results in an abnormal growth
in the width of the blood vessels. Small changes in the structure of the blood vessels
may be seen prior to the onset of hypertension. The blood vessels are tortuous [7]
in nature due to which it is sometimes difﬁcult to identify them as separate entities
during the segmentation process, as is seen in Fig. 2. This leads to a crucial indicator
of a disease being missed.
Retinal ganglion cell
Bipolar cell
Amacrine cell
Horizontal cell
Rod 
Cone
Retinal vessel
Superficial 
RETINAL VESSELS
Intermediate 
Deep 
Fig. 1 Retinal blood vessels on the inner surface of the retina [6]

Wavelet Decomposition Methodology for Improved Retinal …
371
Fig. 2 Fundus images with
tortuous retinal blood vessels
a Mild b Severe
The solution to the above problems lies in the precise extraction of the vessel tree,
measurement of the changes observed in the vessels and, then, consecutively judging
the patient’s medical condition.
The approach of wavelet decomposition is extended to the segmentation of retinal
blood vessels whose shape is non-uniform and dependent on the pressure of the ﬂow
of blood in it. This creates a complexity in determining the blood vasculature structure
and modeling it to identify any abnormalities related to retinal eye diseases. Various
approaches are observed to trace a dynamic model that would mimic the change in
the shape of these blood vessels [8]. Also, the noise in fundus images is assumed to
have additive and zero-mean, constant-variance Gaussian [9] properties.
The wavelet transform is orthogonal and helps in noise removal in the images and
theeliminationofoutlierswithanefﬁcientandcompactrepresentationofthefeatures.
This transform is applied over the entire region, and its coefﬁcients are extracted
from the different scales. Low-pass ﬁltering is generally performed to obtain the
approximation coefﬁcients for preprocessing as they contain better-deﬁned features
in comparison with the detailed coefﬁcients of the wavelet transform. One of the
key reasons for this is that the use of high-pass ﬁlters may result in the removal of
textural information in the radiological images.
2
Inferences from the Literature Review
In order to overcome the problem of not being able to effectively obtain the retinal
blood vessel segmentation, a number of studies based on different wavelet transforms
have been conducted. Retinal images obtained from non-mydriatic camera were used
to develop a methodology based on the segmentation for the blood vessel image
processing. The various methods used include wavelet analysis, adaptive threshold
procedures, morphology-based techniques and supervised classiﬁer probabilities.
Diabetes results in the changes in the vasculature, which in turn assist in identi-
fying and measuring the changes in the diameter of the blood vessel. Features were
extracted from the pixel feature space obtained from the decomposition of the struc-
ture using Morlet transforms with reduced dimensionality. Morphological operation
was utilized as a post-processing technique to obtain continuous vessel contours [10].

372
U. Dikkala et al.
Focus is laid on detecting micro-aneurysms by utilizing the Haar wavelet, the
biorthogonal wavelet with a factor of 5/3 and the Daubechies four-tap orthogonal
wavelet [6]. Relative homogeneity is a parameter considered to extract textural
features through discrete wavelet transform to obtain sensitivity of 85.4% and a
speciﬁcity of 79% [11]. A two-dimensional Gabor wavelet followed by a sharp-
ening ﬁlter is used to enhance the image [12]. Higher-frequency components are
decomposed further, and the statistical metrics are measured. Classiﬁcation is done
through leave-one-out cross-validation method and support vector machine [13].
Hard exudates are detected using Haar transform followed by K-nearest neighbor
classiﬁer[14].Acorrectionintheunevennessintheilluminationisconductedthrough
a homomorphic ﬁlter, after which a super Gaussian band-pass ﬁlter in the discrete
cosine transform context is employed. Otsu’s global method is used in the ﬁnal stage
after which exudates are extracted and also to segment the blood vessels [15]. The
discrete wavelet transform is used in combination with the Coye algorithm to be
used for the segmentation process after applying the appropriate Gamma correction
[16]. Modern concepts related to the use of deep convolutional neural network and
a hybrid method based on combining decision tree and artiﬁcial neural network [17,
18] for overcoming the inverse problem are used for the selection of hyperparameters
and for classiﬁcation.
The efﬁciency of wavelet analysis in various forms in image processing will vary
with the family of wavelets used and the level to which the signal is decomposed.
The techniques include the expansion of the functions into a set of bases functions
of varying properties, Haar wavelet transform being the best-ﬁt wavelet form with
high compact support. The challenge of obtaining the precise measurements of the
physical structure of the blood vessels with the existing methods still exists.
3
Method Proposed
The objective of this work is to obtain a denoised and well-segmented retinal
blood vessel structure through wavelet decomposition methodology. The approach
proposed here employs a preprocessing technique to denoise the fundus image [19].
Then the wavelet transform is used to segment the vasculature structure, using
Daubechies-2 family of wavelets. A comparison is made with the best-ﬁt family
of Haar wavelets. Haar wavelet is the simplest and basic wavelet function which is
orthogonal to its own dilations and translations. It is not a continuous function, and
the Fourier transform decreases gradually as an inverse of the frequency.
The use of Haar wavelet results in an ineffective localization of the frequency
components. On the other hand, Daubechies wavelet is an orthonormal wavelet and
compactly supported. This family of wavelets is used for the purpose of segmentation
of the retinal blood vessels. It is used with a small support (in this case, Daubechies
db2 or D4) to separate the relevant features after using the same wavelet for denoising
the image. The larger is the support for the wavelets, the more difﬁcult is the process
of identifying the narrowly distanced features. This may result in coefﬁcients which

Wavelet Decomposition Methodology for Improved Retinal …
373
Data: Fundus image
Procedure: Parameters to quantify the methodology
begin
Initialization: 1. Resize image for efficient calculations
2. improve quality of image through use of Luminance plane
Gray scale image obtained
Contrast Stretching
3. Denoise using wavelet transform with level independent thresholding
4. Segmentation through wavelet transform
5. Feature comparison
Contrast enhancement of image
Average filtering to remove background of image
Difference obtained 
Local thresholding  
Binary image obtained
Remove isolated points through Mathematical Morphology
6. Calculate metrics
end; 
Fig. 3 Framework for the wavelet transform segmentation algorithm
cannot distinguish the individual features. Also, Haar wavelet is used to detect abrupt
changes in the image, while the other wavelet types are used to smoothen the image
edges and for texture analysis.
A framework is developed to extract the retinal blood vessels as efﬁciently as
possible and is explained through an algorithm in Fig. 3. In the proposed method,
Daubechies wavelet is used initially for denoising purposes and in a later stage for
segmentation. Its process is shown in Fig. 4.
Features are extracted from the denoised image, and the relevant metrics are
calculated.
3.1
Data Acquisition
A publicly available database of retinal images, Digital Retinal Images for Vessel
Extraction (DRIVE), was used for the current research. Two sets of 20 images each,
with one for test and the other for training purposes are included in this data set, with
a number of images representing normal and abnormal conditions with different ages
of the subjects [20]. The camera used is a digital Canon CR5 non-mydriatic 3CCD
camera with a 45° ﬁeld of perspective. Data is stored as a 24-bit data for each image
is in JPEG format. The images are each of a size 768 × 584 pixels, with ﬁeld of
view (FOV) with a diameter of about 540 pixels. The manual segmentation of each
of these images in the database is provided by experts as ground truth images. Two
observers segmented 14 and 6 images, respectively, in the training set, while two
observers segmented the test images twice. The result was two sets of test images,

374
U. Dikkala et al.
Pre-processing
Segmentation
Wavelet 
Decomposition
Feature Extraction 
and Comparison
Evaluation Metrics
Gray scale image; 
Removal of noise
Spatial to wavelet domain 
transformation at 2 levels
Sensitivity, Selectivity and 
Accuracy
Vein structure and ground truth 
image
Cross-section of blood 
vessel profiling
Fig. 4 Schematic ﬂow of the technique
A and B. A binary mask is provided with delineated ﬁeld of view (FOV) for each of
the images. A sample normal and abnormal fundus image is shown in Fig. 5.
Fig. 5 Sample images from retinal database DRIVE database. Source DRIVE database a Healthy
(01.tif), b Scar seen in fovea (08.tif), c Background retinopathy (26.tif)

Wavelet Decomposition Methodology for Improved Retinal …
375
The STARE database is also used extensively in research and is publicly available.
This database consists of a set of 81 fundus photograph with 31 normal and 50
abnormal images, with 24 bits per pixel. A fundus camera Topcon TRBV50 is used
to obtain images with a resolution of 605X700 with a 35° FOV.
Preprocessing. There are number of factors affecting the retinal fundus images,
especially noise, non-uniform illumination and, also, weak contrast. The input is
converted into a grayscale image. To obtain a better result of segmentation, at the
minimal, noise is ﬁltered through the process of wavelet transform and adaptive
thresholding.
Wavelet Decomposition. The discrete wavelet transform can be non-decimated as
seen in maximal overlap DWT (MODWT) or decimated as seen in multiresolution
analysis (MRA). As the non-decimated wavelet function does not include down
samples, it is shift invariant, and more coefﬁcients are generated in comparison with
the decimated wavelet function. The wavelet transform considers a domain which
is a combination of spatial and scaling domains, and it restricts the signal energy
within this region. The elementary constituents of the image are represented across
a number of scales [21] and are useful in the analysis (time–frequency) of non-
stationary signals and to characterize the singularity points obtained. The analysis
process involves the hierarchical decomposition of the image into approximate and
detailed coefﬁcients. The mother wavelet function undergoes dilation, a shift and
ﬁnally convolution with the input data to obtain the ﬁnal output. At every level,
low and high frequencies of the signal are obtained, which results in the resolution
reduced to half indicating the decrease in number of samples retained to half to
represent the entire signal. The approximation coefﬁcients are obtained at the jth
level in the four different components through 2D discrete wavelet transform.
The operation of discrete wavelet transform [2, 21] on an (M X N) image f (x, y)
can be represented by Eqs. (1) and (2), respectively, below.
Wϕ( j0, m, n) =
1
√
M N
M−1

x=0
N−1

y=0
f (x, y)ϕ j0,m,n(x, y)
(1)
W i
γ ( j, m, n) =
1
√
M N
M−1

x=0
N−1

y=0
f (x, y)γ i
j.m,n(x, y), i = {H, V, D}
(2)
with j0 representing the initial scale, the approximate coefﬁcients at j0 being repre-
sented by W ϕ(j0, m, n), for j ≥j0, addition of the detailed coefﬁcients (horizontal ‘H’,
vertical ‘V’ and diagonal ‘D’) as W i
y( j, m, n). The approximation coefﬁcients are
concentrated in the inner details of the image, the detail coefﬁcients are concentrated
along the horizontal, vertical and diagonal directions, and the activity at the edges
of the image is captured. Daubechies wavelet function is applied to the images of
interest, and corresponding functions (scaling and wavelet) are shown in Fig. 6.
The level of decomposition chosen is 2, as there is a wide deviation between
the original and the approximated images for levels after 3, and hence, the results

376
U. Dikkala et al.
Fig. 6 a Scaling and b Wavelet functions of Daubechies wavelet
obtained are not signiﬁcant. For a wavelet with n number of vanishing moments, the
minimum size of the discrete ﬁlter is 2n. The coefﬁcients related to n = 2 are listed
in Table 1.
Feature Extraction. For denoising the grayscale image, a linear-independent
noise estimate is used with soft thresholding on the wavelet coefﬁcients to preserve
the response of the image. The scale value of 2 or 3 generates an output with minimal
noise. Features are extracted from the denoised image through Daubechies wavelets,
and the relevant metrics are calculated.
Post-processing. A few discontinuities in the line segments representing the
retinal blood vessels may exist in the resultant images. Also, as a result of any patho-
logical condition, there might appear a few isolated points. To overcome these short-
comings, morphological operations are performed to obtain a continuous vasculature
structure. The output of each of the steps is presented in Fig. 7.
Table 1 Coefﬁcients for Daubechies wavelets with two vanishing points [19]
n
LoD
HiD
LoR
HiR
0
−0.129409523
−0.482962913
0.482962913
−0.129409523
1
0.224143868
0.836516304
0.836516304
−0.224143868
2
0.836516304
−0.224143868
0.224143868
0.836516304
3
0.482962913
−0.129409523
−0.129409523
−0.482962913
(a)
(b)
(c)
Fig. 7 Output of each step. a Original image b Noisy image c Reconstructed image after applying
Daubechies with a scale of 2 or a tap of 4

Wavelet Decomposition Methodology for Improved Retinal …
377
4
Results of the Simulation
The results of wavelet transform method used for the segmentation of the fundus
images from the DRIVE database are observed, and it is seen that there is an improve-
mentintheacutance.Acutanceisanimportantparameterwhichrepresentsthemagni-
tude of the derivative of the image brightness in relation to space in which the image
is observed. An improvement in the speciﬁcity is observed due to this positive change
in the acutance.
A few samples of the results of the simulation are listed in Table 2. The list
includes images of retina, unaffected and affected by disease. Upon comparison
with the ground truth or manually segmented annotations, it is observed that the
Table 2 Subset of results of the simulation of the proposed system
No.
Original
Annotated Image
Result
1
2
3
4
5

378
U. Dikkala et al.
method, when applied to the images of affected eye, will result in a segmentation
which produces artifacts of the diseased areas through the vein structure. This method
needs to be improvised to produce more prominent vasculature structure. However,
the method implemented produces the structure of the wider veins, the branching
veins and the connectivity between them.
4.1
Performance Metrics
The output obtained is evaluated based on certain metrics that would deﬁne the
quality of the output obtained. Some of the common measurement parameters are
identiﬁed, and their values are mathematically calculated by the formulae in Table
3. Here, TP represents True Positive which is given as number of pixels identiﬁed
as part of a vessel both manually and through the implementation of the algorithm;
similarly, TN is deﬁned as True Negative for the number of pixels identiﬁed as
non-vessel both manually and through the implementation of the algorithm. Along
the same lines, FP represents False Positive as the number of pixels for the wrong
detection of non-vessels as part of a vessel when the algorithm is implemented.
Finally, FN represents False Negative with the failure of the algorithm to detect the
pixels belonging to vasculature. The metrics obtained from the above parameters are
sensitivity, speciﬁcity and accuracy, which can be deﬁned as the capability of the
proposed algorithm in the correct detection of blood vessels, the capability of the
given algorithm in the proper detection of the non-blood vessels and the ratio of the
total number of correctly identiﬁed pixels to the number of pixels in the image ﬁeld
of view, respectively.
A summary of various wavelet transforms applied to the fundus images by
different authors and the results obtained in terms of performance metrics are shown
in Table 4. A comparison is made with the proposed method to show the results
obtained during the experimentation.
As observed from Table 4, the proposed method results in speciﬁcity and accuracy
of approximately 98% and 88%, respectively, in comparison with the other methods
using wavelet transform for segmentation. The Daubechies transform is simpler to
utilize for this purpose.
Table 3 Performance
metrics deﬁned
Metric
Formula/mathematical
expression
Sensitivity (True Positive
Ratio (TPR))
TP/(TP + FN)
Speciﬁcity (1-False Positive
Ratio (FPR))
TN/(TN + FP)
Accuracy
(TP + TN)/(TP + FN + TN +
FP)

Wavelet Decomposition Methodology for Improved Retinal …
379
Table 4 Comparison of results of previous methods with the method proposed
S. No
Author name
[references]
Speciﬁcity (Sp) %
Accuracy (Acc) %
1
Manual evaluator
97.23
94.70
2
Quellec et al. [10]
96.18
–
3
Khademi and Krishnan
[11]
79.00
82.20
4
Lahmiri [13]
–
79.33 improvement in classiﬁcation
5
Rokade and Manza [14]
1
6
Dasha and Senapati [16]
99.05
96.61
7
Proposed
97.68
87.77
Table 5 Metrics comparison
for DRIVE image analysis
Sample image No
Speciﬁcity
Accuracy
1
0.9745
0.8904
2
0.9539
0.8761
3
0.9509
0.8725
4
0.9534
0.8691
5
0.9850
0.9103
5
Setup Used and Relevant Discussions
Validation of the proposed method is conducted on the aforementioned research-
friendly DRIVE database in which there are 33 retinal images of healthy subjects
and seven with lesion problems. Intel-i7 CPU at 2.2 GHz speed with 4 GB RAM
is used to perform these image processing functions. MATLAB 2019a was used for
the data visualization purposes.
The measurement of the metrics for ﬁve randomly selected images from the
DRIVE database is tabulated in Table 5, for a clear comparison of accuracy and
speciﬁcity of the images.
The average of the readings for the images in the DRIVE database shows values
close to the ones obtained by the previously utilized wavelet transforms by other
authors.
6
Conclusion and Future Scope
The focus of the research work is denoising and segmentation using wavelet trans-
forms. As per the analysis performed, it is seen that for all the images in the DRIVE
database, the mean square error, the accuracy and the speciﬁcity are comparable to the
other methods utilized, with a simpler transform. Daubechies db2 or D4 produced

380
U. Dikkala et al.
smaller MSE, higher accuracy and better speciﬁcity compared to the basic Haar
transform with level 2. Only a small improvement in the PSNR is observed.
Work can be extended to other mother wavelets and also, ﬁne-tuning the current
process to enhance the performance metrics of the system. This will be based on the
detection of the thinner and smaller retinal blood vessels. The authors are working
toward extending this research further.
Acknowledgements The authors are thankful to the support team for the implementation of this
research work within the prescribed time and utilization of the resources in the systems laboratory.
References
1. Mallat, S. G. (1989). A theory for multiresolution signal decomposition: The wavelet
representation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 11(7),
674–693.
2. Lee, D. T. L., & Yamamoto, A. (1994). Wavelet analysis: Theory and applications. Hewlett-
Packard Journal, 44–52.
3. Zhuang, Y., & Baras, J. S. (1994). Optimal wavelet basis selection for signal representation.
SPIE Defense, Security, and Sensing, 2242(301), Wavelet Applications, 200–211.
4. Dikkala, U., Joseph, M. K., & Alagirisamy, M. (2021). A comprehensive analysis of morpho-
logical process dependent retinal blood vessel segmentation. In International Conference on
Computing, Communication, and Intelligent Systems (ICCCIS), pp. 510–516.
5. Srinidhi, C. L., Aparna, P., & Rajan, J. (2017). Recent advancements in retinal vessel
segmentation. Journal of Medical Systems, 41(4), 70.
6. Santiago, A. R., Boia, R., Aires, I. D., Ambbrósio, A. F., & Fernandes, R. (2018). Sweet stress:
Coping with vascular dysfunctionin in diabetic retinopathy. Frontiers in Physiology, 9(820),
1–14.
7. Retina Vitreous Resource Center, http://louisvillediabeticeyedoctor.com
8. Cornforth, D. J., Jelinek, H. J., Leandro, J. J. G., Soares, J. V. B., Cesar, R. M., Cree, M. J.,
et al. (2005). Development of retinal blood vessel segmentation methodology using wavelet
transforms for assessment of diabetic retinopathy. Complexity International, 11, 50–61.
9. Ben Abdallah, M., Malek, J., Tourki, R., Monreal, J. E., & Krissian, K. (2013). Automatic
estimation of the noise model in fundus images. In 10th International Multi-Conferences on
Systems, Signals & Devices, pp. 1–5.
10. Quellec, Q., Lamard, M., Josselim, P. M., Cazuguel, G., Cochener, B., & Roux, C. (2006).
Detection of lesions in retina photographs based on the wavelet transform. In International
Conference of the IEEE Engineering in Medicine and Biology Society, pp. 2618–2621.
11. Khademi, A., & Krishnan, S. (2007). Shift-invariant discrete wavelet transform analysis for
retinal image classiﬁcation. Medical & Biological Engineering & Computing, 45(12), 1211–
1222.
12. Akram, M. U., Atzaz, A., Aneeque, S. F., & Khan, S. A. (2009). Blood vessel enhance-
ment and segmentation using wavelet transform. In International Conference on Digital Image
Processing, IEEE Computer Society, Washington, pp. 34–38.
13. Lahmiri, S. (2013). Features extraction from high frequency domain for retinal digital images
classiﬁcation. Journal of Advances in Information Technology, 4, 194–198.
14. Rokade, P. M., & Manza, R. R. (2015). Automatic detection of hard exudates in retinal
images using Haar wavelet transform. International Journal of Application or Innovation in
Engineering and Management, 4, 402–410.

Wavelet Decomposition Methodology for Improved Retinal …
381
15. Lara-Rodriguez, L. D., & Serrano, G. U. (2016). Exudates and blood vessel segmentation in
eye fundus images using the Fourier and cosine discrete transforms. Computation y Sistemas,
20(4), 697–708.
16. Dasha, S., & Senapati, M. R. (2020). Enhancing detection of retinal blood vessels by combined
approach of DWT, Tyler Coye and Gamma correction. Biomedicsl Signal Proessing and
Control, 57, 1–12.
17. Vijayakumar, T. (2020). Posed inverse problem rectiﬁcation using novel deep convolutional
neural network. Journal of Innovative Image Processing (JIIP), 2(03), 121–127.
18. Kumar, T. S. (2020). Data mining based marketing decision support system using hybrid
machine learning algorithm. Journal of Artiﬁcial Intelligence, 2(03), 185–193.
19. Tyler, C. (2015). A novel retinal blood vessel segmentation algorithm for fundus images.
MATLAB Central File Exchange.
20. Fraz, M. M., Remagnino, P., Hoppe, A., et al. (2012). Blood vessel segmentation methodologies
in retinal images—a survey. Computer Methods and Programs in Biomedicine, 108(1), 407–
433.
21. Daubechies, I. Ten lectures on wavelets. In Proceedings of CMBS-NSF Regional Conference
Series in Applied Mathematics. Doi: https://doi.org/10.1137/1.9781611970104

Exploring the Performance of Ensemble
Machine Learning Classiﬁers for
Sentiment Analysis of COVID-19 Tweets
Md. Mahbubar Rahman
and Muhammad Nazrul Islam
Abstract Since the beginning of the global COVID-19 pandemic, measuring public
opinion has been considered as one of the most critical issues for decision-makers to
ﬁght against the pandemic, such as implementing a national lockdown, introducing
quarantine procedure, providing health services, and the like. During the COVID-19
pandemic, decision-makers in several countries around the world made a number
of critical decisions focused on public opinion to combat coronavirus. In the ﬁeld
of natural language processing, sentiment analysis has emerged for mining public
opinion, while machine learning (ML) algorithms are very common for analyzing
sentiment. In this research, approximately 12 thousand tweets from United Kingdom
(UK) were rigorously annotated by three independent reviewers, and based on the
labeled tweets, three different ensemble ML models were proposed to classify the
tweet data into three sentiment labels: positive, negative, and neutral. The study found
that stacking classiﬁer (SC) showed the highest F1-score (83.5%), followed by the
voting classiﬁer (VC) (83.3%) and bagging classiﬁer (BC) (83.2%).
Keywords COVID-19 · Machine learning · Tweet · Sentiment analysis · Natural
language processing · Ensemble algorithms
1
Introduction
Nowadays, several social media are producing huge amounts of text data that develop
a strong interest in data processing to discover the latent meaning of the data in a wider
context. Due to the public availability and transparency of Twitter data, these data
can be used to explore new ways in the ﬁeld of natural language processing (NLP)
and data mining like sentiment analysis [1]. Sentiment analysis extracts subjective
Md. M. Rahman (B) · M. N. Islam
Department of Computer Science and Engineering, Military Institute of Science and Technology,
Mirpur Cantonment, Dhaka 1216, Bangladesh
e-mail: mahbub@mist.ac.bd
M. N. Islam
e-mail: nazrul@cse.mist.ac.bd
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_30
383

384
Md. M. Rahman and M. N. Islam
information, viewpoint, or polarity expressed in sentences or paragraphs. Sentiment
analysis of social media data like Twitter can play a powerful tool to extract insights
from raw data and enables real-time monitoring and decision-making capabilities to
ﬁght against the COVID-19 pandemic.
The current COVID-19 pandemic creates unprecedented situations in our soci-
ety, and many countries have taken appropriate measures like isolation, quarantine,
lockdown or social distancing, etc., taking into account the expressed concerns by
the mass people in social media [2–4]. However, people of various nationalities and
cultures have different ways of voicing their feelings and opinions on a given sub-
ject. For example, people of one country can respond more emotionally than people
in another country, regardless of whether the subject is health, politics, sports, or
entertainment.
Machine learning (ML) algorithms make intelligent predictions based on a set
of data [5, 6]. ML algorithms gain insight from known data points and can predict
the class labels of unknown data points, thus ML algorithms are colossally being
used in the ﬁeld of health informatics [7–11], forecasting pandemic [2, 12], predict-
ing autism [13], etc. Similarly, several studies have been carried out on sentiment
analysis of Twitter data using ML algorithms. For example, Villavicencio et al. [14]
conducted a study in Philippine on sentiment analysis of COVID-19 vaccination-
related tweets using Naïve Bayes classiﬁer and found 81.77% accuracy. The study
considered 11,974 manually labeled tweets for the classiﬁer to test the accuracy. In
another study, Khan et al. [15] performed sentiment scoring of 50,000 COVID-19-
related tweets using Naïve Bayes classiﬁer and found 19% positive and 70% negative
tweets. Deep learning-based classiﬁers were used in [16] to classify 600 COVID-19-
related tweets into different sentiment labels. The study used hybrid heterogeneous
support vector machine (H-SVM), recurrent neural network (RNN), and support vec-
tor machine (SVM) as the classiﬁcation algorithms where H-SVM showed highest
precision (86%), recall (69%), and F1-score (77%) compared to other two models.
Gupta et al. [17] measured Twitter users’ perception on potential ability of weather to
affect SARS-CoV-2 transmission. The study was carried out by ﬁltering the relevant
tweets (n =28,555) using 11 different ML algorithms and then classify the annotated
tweets (n =2442) into different sentiment labels. The study estimated that 40.4%
tweets indicate uncertainty about weather’s impact, 33.5% indicate no effect, and
26.1% indicate some effect on SARS-CoV-2 transmission from the relevant tweet
dataset. COVID-19-related topic identiﬁcations from Twitter data were performed in
[18–20]throughlatentDirichletallocation(LDA)modelingtoassistdecision-makers
and healthcare organizations in assessing and responding to the requirements of the
people. The performance evaluation of various machine learning classiﬁers showed
in [21] on an annotated dataset of 7528 COVID-19 tweets. The study used automatic
annotation on the collected tweets and found 93% accuracy on their dataset. How-
ever, these existing studies showed that ML algorithms were extensively used for
sentiment analysis and classiﬁcation of the COVID-19 tweets. Again, none of the
studies have been conducted with an explicit focus to explore ensemble ML models
for sentiment analysis due to COVID-19 pandemic.

Exploring the Performance of Ensemble Machine Learning Classiﬁers …
385
In relation to existing studies, this research focuses on the sentiment analysis of
COVID-19-related Twitter data using ensemble machine learning algorithms. The
study explores the performance of voting classiﬁer, bagging classiﬁer, and stacking
classiﬁer for user sentiment analysis of COVID-19 tweets from the United King-
dom (UK). The article is structured as follows. The next section presents the study
methodology for sentiment analysis of COVID-19 tweets. Section3 provides an in-
depth analysis and discussion on the results of different ML models. The ﬁnal section
concludes the article and highlights the limitations.
2
Research Method
The methodological overview of sentiment analysis process is shown in Fig.1. The
COVID-19-related tweets data were extracted from Twitter in data acquisition step,
then extracted dataset was preprocessed followed by data labeling. After the data
labeling, data oversampling was performed followed by data embedding using Uni-
versal Sentence Encoder (USE). Then the embedded data were feed into the ensemble
ML models for training and classiﬁcation purpose. The following subsections brieﬂy
discuss these steps of sentiment analysis.
Fig. 1 Methodological
overview of sentiment
analysis

386
Md. M. Rahman and M. N. Islam
2.1
Data Acquisition
The coronavirus-related geo-tagged English tweets were collected from Twitter,
which was sent from the UK and posted on Twitter between January 1, 2020 and
December 31, 2020. The mentioned country, UK, was selected because the country
affected by the COVID-19 since late January 2020 and one of the highly infected
countries during the pandemic timeline [22]. A set of predeﬁned, widely used sci-
entiﬁc and news media terms relating to the novel coronavirus, like “COVID-19,”
“coronavirus,” “lockdown,” “isolation,” “quarantine,” “pandemic,” and “2020-nCov”
were used to collect tweets. The dataset contains 11,960 tweets with 9,81,005 unique
words where maximum occurred word is COVID-19. The sample tweets with manual
labeled sentiment is presented in Table1.
Table 1 Sample tweets with manually labeled sentiment
Tweet
Sentiment
I have concerns about some of the #vaccines
being developed to deal with #COVID19,
mainly because I think they are not safe
Negative
The online retail sector is busier than ever since
the outbreak of #COVID19
Neutral
It is important to keep washing your hands
every time you return home to kill any virus
#COVID19
Positive
AstraZeneca’s eagerly awaited COVID-19
vaccine passes large test, but conﬁrmation
needed
Neutral
You can be young and healthy and still get
along with nasty illnesses with #COVID19
Negative
While #Lockdown restrictions are
easing#Coronavirus is still active
Negative
A terrifying virus designed to subjugate
humanity. The only hope is a vaccine but that is
uncertain
Negative
Look after yourself. Eat and drink wisely.
#COVID19
Positive
Coronavirus-infected cells sprout ﬁlaments that
may spread the virus #COVID19
Negative
The global pandemic is bringing health
inequalities into sharp focus
Neutral

Exploring the Performance of Ensemble Machine Learning Classiﬁers …
387
2.2
Data Preprocessing
The data preprocessing steps are responsible for performing the necessary data trans-
formation and cleaning on the collected dataset to make the raw dataset in a useful
and efﬁcient format for the ML algorithms. The preprocessing step includes the con-
version of tweets to lowercase characters, removing username, URL, punctuation,
links, tabs, HTML contents, and spaces. The stop words like “a,” “an,” and “the”
are removed as they carry little meaning in a sentence. As the study is conducted on
English tweets, identiﬁcation of non-English tweets performed using the language
ﬁeld in the tweet’s metadata and removed them from the considered dataset.
2.3
Data Labeling
Data labeling step involves the manual annotation of the preprocessed individual
tweets. Three independent annotators were given the unlabeled Twitter data to pre-
pare a labeled dataset for ML models. Two authors of this article participated as
independent annotators where third annotator experienced in sentiment analysis and
machine learning algorithms participated voluntarily. The objective of using three
individual annotators is to take the unbiased sentiment of the annotators and to
minimize the noise and inaccuracies in labeling. The annotators labeled the tweets
into three classes according to sentiments expressed/observed in the tweets: posi-
tive, negative, and neutral. The annotation measured from three different annotators
was combined through a majority vote to get an average opinion. We also calcu-
lated the human–human agreement for labeling the tweet. Some accepted inter-rater
reliability techniques [23, 24] were used to ﬁnd out the inter-annotator agreement
coefﬁcient. For this, ﬁrstly, percent of agreement is applied on inter-annotators’
labels and found 85% average agreement. Again, the inter-annotator agreement was
evaluated by Fleiss’ kappa and Krippendorf’s alpha [25]. The average inter-rater
agreement coefﬁcient values of Krippendorf’s alpha and Fleiss kappa were 83% and
81%, respectively. Since the inter-rater agreement coefﬁcient values over 80% is well
acceptable [26], the coefﬁcient values found through different inter-rater reliability
technique show that the annotation process was consistent and reliable.
2.4
Data Oversampling
In the train dataset, class imbalance [27] problem was exist as the quantity of positive,
negative, and neutral tweets was not same (see Fig.2a). The class distribution of the
labeled tweets showed that a number of negative tweets are higher than positive and
neutral, whereas a number of positive tweets are larger than neutral. After splitting
the data into train and test sets, an adaptive synthetic (ADASYN) sampling method

388
Md. M. Rahman and M. N. Islam
Fig. 2 Sentiment count of all the labeled tweets: a before sampling and b after sampling
was applied to have similar number of instances for all the three classes of both
train as well as test sets. The basic concept behind ADASYN is to use a weighted
distribution for different minority class examples based on learning difﬁculty [28].
This oversampling method produces more synthetic data of minority class examples
that have more difﬁculty in learning by the classiﬁers. The class distribution of
the tweets after applying the oversampling method to remove the class imbalance
problem is presented in Fig.2b.
2.5
Data Embedding
Data embedding step is responsible for making suitable machine readable format of
data from raw dataset. A machine does not understand the semantics of the text as
well as the machine learning models cannot process text data, thus it is essential to
convert these textual data into numerical data. Some popular sentence embedding
techniques available in NLP are Doc2Vec [29], SentenceBERT [30], and Univer-
sal Sentence Encoder (USE) [31]. In this research, USE is adopted that encodes
the text into high-dimensional vectors. This simple and efﬁcient model outperforms
over other pretrained word embedding models. The pretrained Universal Sentence
Encoder (USE) is publicly available in TensorFlow-hub.1 The preprocessed tweet
data as discussed above were converted to the numeric vector using the Universal
Sentence Encoder (USE). Then, these numeric vectors were fed into different super-
vised machine learning models to determine the sentiment and classiﬁed into the
different sentiment class labels named positive, negative, and neutral.
1 https://www.tensorﬂow.org/hub.

Exploring the Performance of Ensemble Machine Learning Classiﬁers …
389
2.6
Developing and Analyzing ML Models
Three different ML models were developed using the preprocessed tweets. The ML
models were trained using the train dataset, while the performance of the models
was evaluated using both the train and test dataset. The ML models are analyzed in
detail in the later subsection.
3
Analyzing Machine Learning Models
This section brieﬂy discusses the exploration of different ML ensemble algorithms
for the classiﬁcation of the user sentiment to different labels (positive, negative, and
neutral). Python programming language and the scikit-learn [32] library were used
for developing and analyzing the ML models. A random train-test split of 80-20 was
applied on the manually labeled dataset. Thus, 80% of data were considered as train
data, whereas 20% of data were considered as the test data. The hyperparameters,
which can be used to control the learning process of the algorithms, were tuned
using the grid search tuning method [33] for ﬁnding out the appropriate hyperpa-
rameters for the applied models. The performance of the algorithms was analyzed
based on precision, recall, and F1-score. Again, receiver operating characteristics
(ROC) curves are a type of curve that shows the relationship between speciﬁcity
and sensitivity for each potential classiﬁcation threshold by plotting the true positive
rate against the false-positive rate. Furthermore, the region under the ROC curve
(AUC) for a model indicates how effective a model is for classiﬁcation. Thus, for
evaluating the models, ROC curves and confusion matrices were generated. The next
subsections brieﬂy analyze the applied ML models.
3.1
Voting Classiﬁer
The voting classiﬁer is ensemble ML models that is used for classiﬁcation based
on the highest probability of a class from different baseline models [34]. It uses a
simple aggregation approach that predicts the probability of a class and passed it into
the classiﬁers and then the voting classiﬁer predicts the output based on the highest
probability of the chosen class as output. In this study, hard voting, also known as
majority voting, was done among decision tree (DT), support vector classiﬁer (SVC),
and logistic regression (LR), to get the ﬁnal predicted labels. The precision, recall,
and F1-score for the VC model on the training dataset were 98.9%, 99.5%, and
99.3%, respectively, whereas the value of precision, recall, and F1-score for the test
dataset were 83.8%, 83.4%, and 83.3%, respectively (see Table2). The ROC curve
on training data showed that the micro- and macroaverage of the area under the curve
(AUC) were 100 and 99%, whereas the micro- and macroaverage ROC for the test
data were 88% for both cases (see Fig.3).

390
Md. M. Rahman and M. N. Islam
Table 2 Performance measures for the developed models
Proposed
model
Train dataset
Test dataset
Precision
Recall
F1-score
Precision
Recall
F1-score
Voting
classiﬁer
(VC)
0.989
0.995
0.993
0.838
0.834
0.833
Bagging
classiﬁer
(BC)
0.980
0.989
0.986
0.846
0.833
0.832
Stacking
classiﬁer
(SC)
0.982
0.989
0.985
0.847
0.836
0.835
Train Data
Test Data
Fig. 3 ROC curves for voting classiﬁer
3.2
Bagging Classiﬁer
Bagging is simple and popular ensemble ML meta-algorithm that is designed to
improve the stability and accuracy perspective in solving classiﬁcation and regression
problems [35, 36]. The method works with bootstrapping [37] several copies of the
input training set and then training separate models to reduce variance thus helps to
avoid overﬁtting problems. It is considered as a model averaging approach where
several predictors are used and then the outputs from the predictive models are
applied to a voting scheme for better classiﬁcation. In this study, SVC with 10 trees
was used as the base estimator for training the BC model. On the training dataset,
the precision, recall, and F1-score for the bagging classiﬁer were 98%, 98.9%, and
98.6%, respectively, while the precision, recall, and F1-score for the test dataset were
84.6%, 83.3%, and 83.2%, respectively (see Table2). The micro- and macroaverage
of the AUC for the train ROC curve were 99%, while the micro- and macroaverage
AUC for the test ROC curve were 88% and 87%, respectively (see Fig.4).

Exploring the Performance of Ensemble Machine Learning Classiﬁers …
391
Train Data
Test Data
Fig. 4 ROC curves for bagging classiﬁer
3.3
Stacking Classiﬁer
Stacking is a methodology that uses a meta-classiﬁer to merge several classiﬁcation
models [38]. Individual classiﬁcation models are trained using the entire training
set, and the meta-classiﬁer is then ﬁtted using the outputs (meta-features) of the
ensemble’s individual classiﬁcation models. The architecture of the proposed SC
model consists of two layers. The ﬁrst layer of the SC model was made up of above-
mentioned VC and BC model, while the second layer was made up of a logistic
regression model. The verdicts are derived from two separate models for each of
the observations/tests in the dataset. The second layer LR model used the verdicts
obtained from these algorithms as input features. Then, based on the input features,
the second layer model provided the ﬁnal verdict. The SC model’s precision, recall,
and F1-score were 98.2%, 98.9%, and 98.5%, respectively, on the training set, while
the precision, recall, and F1-score for the test dataset were 84.7%, 83.6%, and 83.5%,
respectively. As a result, the SC model achieved the highest results in the training as
well as test set (see Table2). The micro- and macroaverage of the AUC for the train
ROC curve were 100%, while the micro- and macroaverage of the ROC for the test
ROC curve were 88% (see Fig.5).
Train Data
Test Data
Fig. 5 ROC curves for stacking classiﬁer

392
Md. M. Rahman and M. N. Islam
3.4
Comparative Analysis
Applying each of the algorithms to the dataset led to different performances based
on precision, recall, and F1-score values (see Fig.6). The SC model achieved the
highest precision (84.7%), recall (83.6%), and F1-score (83.5%) compared to other
two models from the test dataset (see Table2). For the test dataset, the VC model
providesthesecondbestperformanceintermsofF1-score(83.3%)andrecall(83.4%)
values compared to BC model where F1-score and recall values were 83.2% and
83.3%, respectively. Again, in terms of precision values, BC model achieved 84.6%
which is slightly higher than VC model (83.3%).
Fortrainingdataset,VCmodelachievedhighestprecision(98.9%),recall(99.5%),
and F1-score (99.3%) compared to other two models. However, the precision, recall,
and F1-score values of all three models for training dataset are 98% and above (see
Table2).
The ROC curve for train and test dataset is presented in Figs.3, 4, and 5. The micro-
and macroaverage values of the AUC for the train dataset are 99% and above for all
three models (see Figs.3, 4, and 5). The VC and SC model achieved 88% micro- and
Fig. 6 Performance of the algorithms in: a train data, b test data

Exploring the Performance of Ensemble Machine Learning Classiﬁers …
393
Train Data
Test Data
(a)
Train Data
Test Data
(b)
Train Data
Test Data
(c)
Fig. 7 Confusion matrices for developed models: a VC, b BC, and c SC
macroaverage value of the AUC for the test dataset whether the BC model achieved
microaverage value of 88% and macroaverage value of 87%, respectively.
A summary of the predicted results of the tweet sentiment is also expressed by
confusion matrices shown in Fig.7 where each entry of the matrix denotes the number
of predictions madebythemodel whereit classiﬁedthelabels correctlyor incorrectly.
From the sum of the diagonal entries of the confusion matrices of VC and BC
models, 2990 tweet data (positive, negative, and neutral) for both of the models
were correctly classiﬁed out of 3588 test data (see Fig.7a, b). Again, the SC model
correctly classiﬁed highest number (3001) of tweet data that outperform over the
other two models (see Fig.7c). The applied models also showed over 98% accuracy
on classiﬁcation of the tweets for the train dataset.

394
Md. M. Rahman and M. N. Islam
4
Conclusions
This research aimed at sentiment analysis of COVID-19 tweet data through ensem-
ble ML models to classify tweets into positive, negative, and neutral sentiment. The
proposed SC classiﬁer showed the highest F1-score of 83.5%, while VC and BC
model shown very promising results, which indicates that ensemble ML models can
be used for sentiment analysis. The ensemble ML models outperformed over some
existing studies. For example, in [14], the authors used Naïve Bayes classiﬁer and
found 81.77% accuracy. In another study [16], the authors applied SVM, RNN, and
H-SVM ML models and found recall and F1-score (69%) and (77%), respectively.
However, for text embedding, Universal Serial Encoder (USE) is employed to make
the trainable input data for the ML models. Future studies may focus on trying differ-
ent encoders, such as BERT, Word2vec for text embedding to ﬁnd the best suitable
encoding for the classiﬁers to get better outcomes. Again, the study considered only
11,960 tweet data for training and testing of ML models which may be increased to
a bigger sample size to get more accurate results.
References
1. Chong,W.Y.,Selvaretnam,B.,&Soon,L.K.(2014).Naturallanguageprocessingforsentiment
analysis: An exploratory analysis on tweets. In 2014 4th international conference on artiﬁcial
intelligence with applications in engineering and technology (pp. 212–217). IEEE.
2. Islam, M. N., & Islam, A. N. (2020). A systematic review of the digital interventions for ﬁghting
covid-19: The Bangladesh perspective. IEEE Access, 8, 114078–114087.
3. Islam, M. N., Inan, T. T., & Islam, A. N. (2020). Covid-19 and the Rohingya refugees in
Bangladesh: The challenges and recommendations. Asia Paciﬁc Journal of Public Health,
32(5), 283–284.
4. Laato, S., Islam, A. N., Islam, M. N., & Whelan, E. (2020). What drives unveriﬁed information
sharing and cyberchondria during the covid-19 pandemic? European Journal of Information
Systems, 29(3), 288–305.
5. Islam, M. N., Inan, T. T., Raﬁ, S., Akter, S. S., Sarker, I. H., & Islam, A. N. (2021). A systematic
review on the use of AI and ML for ﬁghting the covid-19 pandemic. IEEE Transactions on
Artiﬁcial Intelligence.
6. Nichols, J. A., Chan, H. W. H., & Baker, M. A. (2019). Machine learning: Applications of
artiﬁcial intelligence to imaging and diagnosis. Biophysical Reviews, 11(1), 111–118.
7. Islam, M. N., Mahmud, T., Khan, N. I., Mustaﬁna, S. N., & Islam, A. N. (2020). Exploring
machine learning algorithms to ﬁnd the best features for predicting modes of childbirth. IEEE
Access.
8. Khan, N. I., Mahmud, T., Islam, M. N., & Mustaﬁna, S. N. (2020). Prediction of cesarean
childbirth using ensemble machine learning methods. In Proceedings of the 22nd international
conference on information integration and web-based applications & services (pp. 331–339).
9. Aishwarja, A. I., Eva, N. J., Mushtary, S., Tasnim, Z., Khan, N. I., & Islam, M. N. (2020).
Exploring the machine learning algorithms to ﬁnd the best features for predicting the breast
cancer and its recurrence. In International conference on intelligent computing & optimization
(pp. 546–558). Springer.
10. Khan, N. S., Muaz, M. H., Kabir, A., & Islam, M. N. (2017). Diabetes predicting mhealth
application using machine learning. In 2017 IEEE international WIE conference on electrical
and computer engineering (WIECON-ECE) (pp. 237–240). IEEE.

Exploring the Performance of Ensemble Machine Learning Classiﬁers …
395
11. Dhaya, R. (2020). Deep net model for detection of covid-19 using radiographs based on ROC
analysis. Journal of Innovative Image Processing (JIIP), 2(03), 135–140.
12. Zaman, A., Islam, M. N., Zaki, T., & Hossain, M. S. (2020). Ict intervention in the containment
of the pandemic spread of covid-19: An exploratory study. arXiv:2004.09888
13. Omar, K. S., Mondal, P., Khan, N. S., Rizvi, M. R. K., & Islam, M. N. (2019). A machine
learning approach to predict autism spectrum disorder. In 2019 international conference on
electrical, computer and communication engineering (ECCE) (pp. 1–6). IEEE.
14. Villavicencio, C., Macrohon, J. J., Inbaraj, X. A., Jeng, J. H., & Hsieh, J. G. (2021). Twitter
sentiment analysis towards covid-19 vaccines in the philippines using naïve bayes. Information,
12(5), 204.
15. Khan, R., Shrivastava, P., Kapoor, A., Tiwari, A., & Mittal, A. (2020). Social media analysis
with AI: Sentiment analysis techniques for the analysis of twitter covid-19 data. Journal of
Critical Review, 7(9), 2761–2774.
16. Kaur, H., Ahsaan, S. U., Alankar, B., & Chang, V. (2021). A proposed sentiment analysis deep
learning algorithm for analyzing covid-19 tweets. In Information Systems Frontiers (pp. 1–13).
17. Gupta, M., Bansal, A., Jain, B., Rochelle, J., Oak, A., & Jalali, M. S. (2021). Whether the
weather will help us weather the covid-19 pandemic: Using machine learning to measure
twitter users’ perceptions. International Journal of Medical Informatics, 145, 104340.
18. Garcia, K., & Berton, L. (2021). Topic detection and sentiment analysis in twitter content
related to covid-19 from Brazil and the USA. Applied Soft Computing, 101, 107057.
19. de Melo, T., & Figueiredo, C. M. (2021). Comparing news articles and tweets about covid-19 in
Brazil: Sentiment analysis and topic modeling approach. JMIR Public Health and Surveillance,
7(2), e24585.
20. Abd-Alrazaq, A., Alhuwail, D., Househ, M., Hamdi, M., & Shah, Z. Top concerns of tweeters
during the covid-19 pandemic: A surveillance study.
21. Rustam, F., Khalid, M., Aslam, W., Rupapara, V., Mehmood, A., & Choi, G. S. (2021). A
performance comparison of supervised machine learning models for covid-19 tweets sentiment
analysis. Plos One, 16(2), e0245909.
22. Anderson, R. M., Hollingsworth, T. D., Baggaley, R. F., Maddren, R., & Vegvari, C. (2020).
Covid-19 spread in the UK: The end of the beginning? The Lancet, 396(10251), 587–590.
23. Armstrong, D., Gosling, A., Weinman, J., & Marteau, T. (1997). The place of inter-rater relia-
bility in qualitative research: An empirical study. Sociology, 31(3), 597–606.
24. Gwet, K. L. (2008). Computing inter-rater reliability and its variance in the presence of high
agreement. British Journal of Mathematical and Statistical Psychology, 61(1), 29–48.
25. Artstein, R., & Poesio, M. (2008). Inter-coder agreement for computational linguistics. Com-
putational Linguistics, 34(4), 555–596.
26. Hays, R. D., & Revicki, D. (2005). Reliability and validity (including responsiveness). Assess-
ing Quality of Life in Clinical Trials, 2, 25–39.
27. Japkowicz, N., & Stephen, S. (2002). The class imbalance problem: A systematic study. Intel-
ligent Data Analysis, 6(5), 429–449.
28. He, H., Bai, Y., Garcia, E. A., & Li, S. (2008). Adasyn: Adaptive synthetic sampling approach
for imbalanced learning. In 2008 IEEE international joint conference on neural networks (IEEE
world congress on computational intelligence) (pp. 1322–1328). IEEE.
29. Dai, A. M., Olah, C., & Le, Q. V. (2015). Document embedding with paragraph vectors.
arXiv:1507.07998
30. Reimers, N., & Gurevych, I. (2019). Sentence-bert: Sentence embeddings using siamese bert-
networks. arXiv:1908.10084
31. Cer, D., Yang, Y., Kong, S. Y., Hua, N., Limtiaco, N., John, R. S., Constant, N., Guajardo-
Céspedes, M., Yuan, S., Tar, C., et al. (2018). Universal sentence encoder. arXiv:1803.11175
32. Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M.,
Prettenhofer, P., Weiss, R., Dubourg, V., et al. (2011). Scikit-learn: Machine learning in python.
The Journal of Machine Learning Research, 12, 2825–2830.
33. Ghawi, R., & Pfeffer, J. (2019). Efﬁcient hyperparameter tuning with grid search for text
categorization using knn approach with bm25 similarity. Open Computer Science, 9(1), 160–
180.

396
Md. M. Rahman and M. N. Islam
34. Ruta, D., & Gabrys, B. (2005). Classiﬁer selection for majority voting. Information Fusion,
6(1), 63–81.
35. Breiman, L. (1996). Bagging predictors. Machine Learning, 24(2), 123–140.
36. Bühlmann, P., Yu, B., et al. (2002). Analyzing bagging. The Annals of Statistics, 30(4), 927–
961.
37. Efron, B., & Tibshirani, R. J. (1994). An introduction to the bootstrap. CRC Press.
38. Džeroski, S., & Ženko, B. (2004). Is combining classiﬁers with stacking better than selecting
the best one? Machine Learning, 54(3), 255–273.

Implementation of Bayesian Network
Model (BN Trust Model) for IoT Routing
Sridhar Manda, N. Nalini, and A. Arun Kumar
Abstract In this paper, we are talking about the proposed Bayesian Network Trust
Model (BN Trust Model). In attention to the developing issue of security of the
Internet of Things, we present, from a quantiﬁable choice perspective, a novel
methodology for trust-based access control utilizing Bayesian Network Model. We
build up a trust model, BN Trust Model, which depicts a trust level for distinguishing
proof organization in IoT. BN Trust Model is being actualized to record access control
on trouble conditions where characters are not known in progress. A judgment will
be favored dependent on standard parameters and be determined utilizing Bayesian
choice rules. To evaluate a trust model, we play out an arithmetical investigation
and reproduce it utilizing NS2 apparatus to look at control use. The activity result
shows that the Bayesian choice hypothesis technique for BN Trust Model backings
adaptability, and it is energy production as a creating number of devices and not
inﬂuencing the working and execution work Model. BN Trust Model contrasted and
different directing conventions of AODV, DSR, DSDV in the situation of two param-
eters parcel misfortune and Throughput. Result investigation shows that the proposed
BN trust model gives better exactness thought about previous routing calculations.
Keywords IoT · BN Trust Model · Trust · AODV · DSR · DSDV · NS2
S. Manda (B)
Assistant Professor, Balaji Institute of Technology and Science, Narsampet, Warangal, Telangana,
India 506 331
N. Nalini
Professor, Department of Computer Science and Engineering, Nitte Meenakshi Institute of
Technology, Govindapura, Gollahalli, Yelahanka, Bangalore 560064, India
A. A. Kumar
Professor, Department of Computer Science & Engineering, Balaji Institute of Technology and
Science, Warangal, India 506 331
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_31
397

398
S. Manda et al.
1
Introductıon
The Internet of Things (IoT) is a rising international Internet-based data design
facilitating the exchange of knowledge and services. Varied devices are being created
with net capabilities and sensors designed into them in contrast to other networks
like P2P and WSN, ton is a complicated network characterized by heterogeneous
interconnection, intelligent perception, and multiple ﬁeld applications. In IoT [1]
environment surround different kinds of computing devices, that are billions, vary
in size and their ability to speak with one another. However, the protection threat is
growing chop-chop because of its gap. Ancient security ways, as an example, access
management, are not any longer ﬁtted to handling security problems in ton due to
centralized security management and poor measurability. IoT setting is characterized
by extremely dynamic nodes property and network topologies because of the ever-
changing of the wireless channel, mobility, and restricted power, that causes a node
to die out. Sadly, each new technological development sometimes comes with a
brand new set of security threats. the protection threats of the ton are broad and
doubtless devastating, thus it wants an answer to handle security threats during a
dynamic setting like ton network Trust management is to be projected to handle
security problems in an IoT setting. Trust is that the chance forecast of AN entity
to a different entity’s speciﬁc behavior. Trust management is predicated on a uniﬁed
mechanism and native management of trust relationships. Trust mechanisms will
traumatize changeable security conditions and customized security requests.
1.1
Trust System
Trust and name management plans became a key call tool in net things. This helps
verify that nodes in net objects should be wont to forward packets to different nodes,
or to just accept data or services from different nodes. This call provides security
from the IoT for things from internal attacks wherever cryptography security doesn’t
work. The conﬁguration of a passionate mobile network of nodes for routing and
information sharing has been helpful. This implies minimum efforts to put together
the system. Trust is crucial as a result of it helps in decision-making. Trust helps
verify UN agency trusts routing packets, in addition to services like ﬁle downloads
and ﬁle sharing. A node that ignores packets, delays package redirection, doesn’t
offer the requested ﬁle, or doesn’t share information, is taken into account malicious
and less assured with each of those behaviors. The foremost reliable node will show
such behavior if it will some priority actions. During this case, the sure computing
engine reduces trust and therefore the most reliable node is known as a malicious
node. During this case, the afﬁliation is created through a less honest contract, or
an afﬁliation path cannot be found. To avoid this drawback, think about the state of
the node once calculative the trust, thus there’s no extra drop by the trust values.
Conﬁdence calculation schemes are typically the victim of false praise and false

Implementation of Bayesian Network Model (BN Trust Model) …
399
criticism that ends up in false trustiness that ends in unreliable ways that. Often, the
node denies that it praises the opposite node or criticizes it incorrectly [2].
On the IoT of things, there’s no centralized management authority. The terribly
dynamic nature of the network doesn’t enable you to use predeﬁned static security
strategies to direct packets from one node to a different. You would like the node
to stay different packets to handle. This kind of open network cannot be subject to
any security policy determined by the knowledge owner [3]. Cryptology security
mechanisms won’t offer conﬁdentiality of communications and contract documents
against packet drop, delayed packet attack, or pulse attack, and can’t assist in quali-
fying services. Trust and name systems became the key call support tools for choosing
a routing node and services.
Trust between a user and her agent(s)
When a (personal) agent may be a human user, there could also be cases wherever
the agent doesn’t act because the user expects. The extent to that the user trusts her
agent determines the way to delegate her functions to the agent [4].
Trust in commission supplier
Measure whether or not your service supplier will offer reliable services. Quality of
service is that the main concern during this case.
Trust in references
1.
References discuss with agents UN agency create recommendations or share
their trust value live whether or not the agent will create reliable recommen-
dations. Stress on similarities in preferences and strategies of judgment issues
between 2 purchasers. The IoT of similar the 2 factors, the IoT of assured they’re
in creating recommendations.
2.
It is vital for the agent to develop conﬁdence in different agents as references
within the redistributed system, as a result of once the agent is unsure of the
dependability of the service supplier, he will solely raise recommendations
from those few agents UN agency trust him instead of raising an outsized
variety of agents, that doesn’t facilitate the agent to induce an IoT of reliable
recommendations solely, however, saves time and Communications prices.
2
Proposed System Model of IoT Using BN
We gift a trust model [5] to handle access management during a ton setting. AN objec-
tive approach to the matter of trust management in applied mathematics decision-
making is bestowed underneath uncertainty. The problem is typically called the
organization of systems. Most projected solutions to handle security problems are
to use a judgment approach. We have a tendency to create predictions to see the
uncertainty regarding access management using applied mathematics strategies and
chance. Our projected approach uses Thomas Bayes call rules that supported previous

400
S. Manda et al.
Fig. 1 System model
expectations found by applying the scientiﬁc illation technique. The matter is devel-
oped during an applied mathematics call theory format, and therefore the general
resolution technique is made public.
To start with, trust in the IoT-based framework [6] in Fig. 1 to the character of the
individual’spersonality,whilethetrustinthepartconsidersadeviceorarticles.Along
these lines, the trust of the executive’s cooperation in IoT is a type of correspondence
starting with one device then onto the next with or without human mediation. When
all is said in done, the IoT comprises system modules, sensors, and players. Each
IoT device interfaces and offers assets with another IoT device. On the off chance
that the IoT needs to demand an asset from another device, it makes a validation
procedure for access control in conventional security. In the trust strategy, the IoT
device acquires access control by surveying its condition, for instance, the protected
system and an individual from the conﬁded in organize space. Despite the fact that the
IoT device comprises numerous modules, we expect that it is a unit. Each solicitation
will be ﬁgured out how to an IoT sensor or administrator by the IoT framework with
the goal that we can disentangle our multifaceted nature of the IoT issue.

Implementation of Bayesian Network Model (BN Trust Model) …
401
2.1
Bayesıan Networks (BN)
A Bayesian system (BN) [7] is a graphical structure to speak to probabilistic rela-
tions between an enormous number of properties (or factors) and to make prob-
abilistic derivation with those properties. The graphical idea of Bayesian systems
gives an exceptionally natural comprehension of the connections between high-
lights. For instance, the Bayesian system can speak to potential connections among
infections and manifestations. Given the side effects, the system can be utilized
to ascertain the odds of getting various maladies. Bayesian systems are utilized to
show learning in organic chemistry and biophysics (quality administrative systems,
protein structure, and quality articulation investigation), drug, report grouping, data
recovery, picture preparing, information coordination, choice emotionally supportive
networks, designing, games, and laws. Yehuda Pearl [8] detailed the expression
“Bayes Networks” to stress three perspectives:
1.
The regularly abstract nature of info data.
2.
Trust in the adjustment of Bayes as a reason for refreshing data.
3.
Recognize sensible and clear thinking.
There are numerous introductions accessible for information investigation,
including rule rules, choice trees, and counterfeit neural systems; there are
numerous procedures for information examination, for example, thickness estima-
tion, reviewing, relapse and conglomeration. Along these lines, what do Bayes
Networks they are?
1.
Bayesian systems can undoubtedly deal with inadequate informational indexes.
For instance, consider the issue of characterization or relapse where two infor-
mative factors or info factors are ﬁrmly related. This isn’t an issue for standard
regulated learning strategies, as long as all sources of info are estimated for each
situation. Be that as it may, in the event that one of the information sources isn’t
watched, most models will deliver an off-base forecast, since they don’t encode
conditions between the info variable. Bayesian systems offer a characteristic
method to encode such conditions.
2.
Bayesian systems help during the time spent ﬁnding out about causal connec-
tions. Finding out about causal connections is signiﬁcant for at any rate two
reasons. The procedure is valuable when we attempt to all the more likely
comprehend the issue zone, for instance, during the examination of exploratory
information. What’s more, realizing causal connections enables us to make
forecasts of mediations. For instance, a showcasing examiner should check
whether it merits expanding or not demonstrating a speciﬁc advertisement to
build item deals. To respond to this inquiry, the examiner needs to decide if the
advertisement is motivation to expand deals and to what degree.
3.
Bayesian Networks with Bayesian factual methods encourage the blend of
learning and ﬁeld information. Any individual who has played out a certiﬁable
investigation knows Prior information or signiﬁcance of the area, particularly
when the information is uncommon or costly. The truth of the matter is that

402
S. Manda et al.
some exchanging frameworks (for example master frameworks) can be worked
without earlier learning; this is the only declaration of the intensity of earlier
information. Bayesian systems have causal ramiﬁcations that make codiﬁcation
of causal learning especially clear and direct. What’s more, Bayesian systems
symbolize the intensity of causal associations with probabilities. Along these
lines, learning and past information can be joined with very much considered
systems for Bayesian measurements.
2.2
Algorıthm for Baysıan Netoworks
1.
Input: Dataset D; Variable set V = (V1, V2, . . . . . . ., VN); node ordering P
2.
Output: A directed Acyclic Graph G.
3.
Construct the moral graph Gm = (V, Em) from the Data set D.
4.
Decompose the moral graph Gm
into its maximal prime sub graph
Gm
1 , Gm
2 , . . . .., Gm
k .
5.
ForeachsubgraphGm
l (l = 1, 2, . . . ., k)ofGm,calltok2algorithmwiththelocal
node ordering of Gm
l to construct a directed acyclic graph Gl(l = 1, 2, . . . ., k).
6.
Combine G1, G2, . . . . . . , Gk into directed graph G = (V, K) where
7.
V = V(G1)∪V(G2)∪. . . . . . ..∪V(Gk)andE = E(G1)∪E(G2)∪. . . ., ∪E(Gk)
8.
Output: A directed Acyclic Graph G.
The relationship between parent and child between the nodes in the Bayes network
indicates the causal direction between the corresponding variables, that is, the vari-
able represented by the sub node is causally dependent on those represented by their
parents. Each node corresponds to the states of the random variable it represents and
the probability that the node will be in a given state given the state of its parents
(conditional probability). In the Bayesian event model, the boundary between two
potential dependency events between events appears, i.e., e1 →e2 indicates that the
probability of event e2 is conditional on event probability e1. In general, for events
A and B, where A depends on B, provided thatP(B) ̸= 0
P(A|B) = P(A)P(B|A)
P(B)
In many cases, event B is constant (P(B) = 1), and we would like to think about
its observed effect, on the probability of other possible events. In such a case, the
preceding expression is ﬁxed, the probability of the given B directory is ﬁxed and
we want to calculate probability A based on how the B directory is organized on our
previous (historical) knowledge about probability A.

Implementation of Bayesian Network Model (BN Trust Model) …
403
3
Constructıon of Bayesıan Network
There are two different ways to make a Bayesian system: manual creation or
programmed creation (called “learning”) from databases. The two strategies have
points of interest and weaknesses.
Manual development
The Bayesian manual advancement incorporates earlier master information of the
essential area. The initial step is to develop a guided wave graph, trailed by a subse-
quent advance to assess the conveyance of contingent likelihood in every node.
Guided ring chart: The development of the ring-focused diagram starts by recog-
nizing the signiﬁcant nodes (irregular factors) and the auxiliary reliance between
them [9]. All factors ought not to be watched; truth be told, some irregular factors
may distinguish undisclosed sums accepted to inﬂuence the watched outcomes. Infor-
mation, fundamental factors, and parameters are consistently spoken to as nodes in
the chart. Be that as it may, the conveyance of the fundamental restrictive likeli-
hood must be known or possibly assumed (for instance, typical circulation). The
hypothesis of virtualization depends on the supposition that every obscure amount
is arbitrary factors, so it is normal to incorporate parameters, for example, nodes in
the diagram, just as all the fundamental factors and detectable sums.
Programmed learning
In contrast to manual development, programmed learning doesn’t require partic-
ular information of the essential space. Bayes systems can be consequently gained
straightforwardly from databases utilizing experience-based calculations, regularly
incorporated into the suitable program. In any case, the detriment is that programmed
development forces more necessities on the information. Most robotization calcu-
lations don’t require missing information in the informational index, which is
frequently a solid suspicion by and by. In the event that the information is absent
in the informational collection, it must be imported, determined, or evaluated from
other sources [10]. Moreover, there must be adequate information to meet the calcu-
lation’s prerequisites for dependable appraisals of restrictive likelihood circulations.
For manual development, it is accepted that contingent likelihood dispersions are as
of now known. Mechanized learning includes the formation of system structures and
the estimation of restrictive likelihood dispersions.
Genie environment
The Genie programming is the program which is free and can be downloaded from
http://genie.sis.pit.edu. Genie for PC is planned with the essential Windows working
framework. The outcome is to be comparable to Fig. 2.
To indicate node properties, double-tap the chose node. A window ought to show
up as in Fig. 3. On the General tab, you can determine a name and a node ID. On
the Identiﬁcation tab, you can indicate the circulation of contingent likelihood on
this node. Utilizing the Thunder symbol, or the Network →Update choice promptly

404
S. Manda et al.
Fig. 2 Genie environment
Fig. 3 ˙Import ODBC data
identiﬁes the conveyance of the past likelihood. When the proof is gotten, the accom-
panying probabilities are recalculated by tapping on the relating condition of the
node.
For robotized learning, you should bring the fundamental database into the
program utilizing File →Open Data File … or on the other hand File →Import
ODBC Data … Can choose the favored calculation in the Network →calcula-
tion alternative. Extra highlights of the Genie bundle incorporate, for instance,
affectability examination, which delineates the power of the impact or ascertains
the likelihood of complete proof.

Implementation of Bayesian Network Model (BN Trust Model) …
405
4
Resutls and Dıscussıons
GFB represents packets transferred without loss due to attacks and vice versa. BFB
represents the loss of packets due to routing attacks. Hence, the throughput and
packet loss due to routing attacks are compared in the following tables. In Table 1,
the packet loss in BN with TRM on a no attack environment is shown. In Table 2, the
packet loss on BN with TRM and secured BN with TRM on a simple injection attack
is shown. Similarly, the throughput in BN with TRM on a no attack environment is
shown in Table 3, and the packet loss on BN with TRM and secured BN with TRM on
a simple injection attack is shown in Tables 4 and 5 will show the comparison of cost
between various algorithms. The graphs on the following page show the performance
Table 1 Packet loss on non-attack environment in BN Trust Model
No of nodes
No of packet loss
BN Trust Model
DSDV
DSR
AODV
100
4
6
8
10
200
7
9
11
13
300
10
12
15
16
400
18
22
26
27
500
38
42
50
52
1000
78
82
102
107
Table 2 Packet loss on simple injection attack in BN Trust Model
No of nodes
No of packet loss
BN Trust Model
DSDV
DSR
AODV
100
6
7
8
9
200
9
10
11
12
300
13
15
17
19
400
19
23
24
25
500
39
45
49
53
Table 3 Throughput in BN Trust Model on no attack environment
No of nodes
Throughput in Kbps
BN Trust Model
DSDV
DSR
AODV
100
35.5
34.5
32.5
29
200
38.3
37
34
32
300
47.2
42.7
42
38.5
400
61.3
57
53.5
48.5
500
79
74.5
69
65

406
S. Manda et al.
Table 4 Throughput on simple injection attack in BN Trust Model
No of nodes
Throughput (Kbps) in simple attack mode
BN Trust Model
DSDV
DSR
AODV
100
35
29
24
19
200
42
35
27
22
300
52
43
38
33
400
65
55
49
44
500
83
69
65
57
Table 5 Comparison of transmission cost in BN Trust Model
No of ﬂows
Transmission cost (in ms)
BN Trust Model
DSDV
DSR
AODV
10
22
23
24
25
20
47
64
63
67
50
112
165
166
167
100
225
275
276
278
of the proposed routing protocols with respect to different transmissions [11, 12]
range of the node. The proposed Bayesian Network Trust Model (BN Trust Model)
performance is calculated based on the Bad Forward Behavior (BFB) and the Good
forward behavior (GFB), and the Security Trust (ST). GFB and BFB are two limits
based on productivity.
Figure 4, shows that the result of the recommended research work of the BN Trust
Model in the situation of packet loss is compared with different algorithms of DSDV,
DSR, and AODV without attacking the Environment. With the study of the chart,
we can tell when the number of nodes is improved, and packet loss is reduced in the
proposed BN Trust Model compared with existed algorithms. The Number of Nodes
taken in the X-axis and the number of Packet loss taken in the Y-axis.
Figure 5 The Number of Nodes used in the X-axis and the number of Packet loss
used in the Y-axis. By examining the chart, we can determine when the number of
nodes is maximized, and packet loss minimized in the proposed BN Trust Model
0
50
100
150
100
200
300
400
500
1000
No of Packet Loss
No of Nodes
BN Trust Model
DSDV
DSR
AODV
Fig. 4 No. of nodes versus No. of packet loss

Implementation of Bayesian Network Model (BN Trust Model) …
407
0
20
40
60
100
200
300
400
500
No of Packet loss
No of Nodes
BN Trust Model
DSDV
DSR
AODV
Fig. 5 No of nodes versus No. of packet loss in attack mode
0
50
100
100
200
300
400
500
Throughput
No of Nodes
BN Trust Model
DSDV
DSR
AODV
Fig. 6 No. of nodes versus throughput in normal mode
compared to existing algorithms it shows that the result of recommended research
work of the BN Trust Model in the situation of packet loss is compared with different
algorithms of DSR, and AODV, DSDV in the sample attacking mode
Figure 6 The x-axis shows the Number of Nodes and the Y-axis represents
throughput in kbps. With this analysis, we can get an idea that when the number of
nodes is increased, and illustrate that the outcome of the Proposed BN Trust Model’s
Throughput [13] is considered and compared with various previous algorithms of
DSR, and AODV, DSDV is normal without attacking the environment. Throughput
in the proposed BN Trust Model is improved compared with the previous models
Figure 7 Throughput in the proposed BN Trust Model is increased compared
with the current algorithms and shows that the outcomes of the Proposed BN Trust
Model’s Throughput are calculated and compared with other previous algorithms of
AODV, DSDV, and DSR and in the simple attacking scenario. The x-axis shows the
Number of Nodes, and Y-axis represents Throughput. With this examination of the
above chart, we can ﬁnalize when the number of nodes is maximized
As in Fig. 8, the transmission cost of the proposed BN Trust model is determined
and contrasted and the present calculation. In the diagram, the X pivot speaks to the
0
50
100
100
200
300
400
500
ThroughPut
No of Nodes
BN Trust Model
DSDV
DSR
AODV
Fig. 7 Number of nodes versus throughput (kbps) in simple attacking mode

408
S. Manda et al.
0
100
200
300
BN Trust Model
DSDV
DSR
AODV
Transmission 
Cost
No of Flows
10
20
50
100
Fig. 8 Graph between numbers of ﬂows versus transmission cost (in ms)
number of ﬂows and the Y node speaks to the transmission cost. Through Graph
examination, we can see when the quantity of ﬂows increments and the expense of
transport is decreased contrasted with the existing algorithms.
5
Conclusion
In this paper, the proposed Bayesian Network Trust model (BN Trust Model) demon-
strated to be the best direction in the IoT condition of customary steering strategies.
In this manner, the proposed BN Trust model turns into a signiﬁcant research theme
for IoT. The proposed BN Trust model contrasts and circumstances without assault
and straightforward infusion assault. The exhibition of the veriﬁed BN trust model
is determined in two parameters: (1) packet loss and (2) Throughput. The packet
loss shows BFB behavior, and represents the GFB performance from the investiga-
tion of results and execution, he reasoned that the proposed BN Trust model gives a
superior outcome and improves the exhibition of the BN Trust model in both packet
misfortune and Throughput contrasted with past calculations. Finally, the expense of
transportation is diminished when processed and contrasted with existing methods.
In the Future, we can modify the algorithm which gives the best performance by
adding or modifying the parameters of the BN trust model.
References
1. Ying, B., & Nayak, A. (2019). Fair and social-aware message forwarding method in
opportunistic social networks, (pp. 720–723).
2. Manda, S., & Nalini, N. (2018). Trust mechanism in IoT routing. In: 2018 Second International
Conference on Intelligent Computing and Control Systems (ICICCS), Madurai, India, pp. 230–
234. https://doi.org/10.1109/ICCONS.2018.8662982, IEEE Xplore: 11 March 2019.
3. Manda, S., & Nalini, N. (2018). Denial-of-service or ﬂooding attack in ıot routing. International
Journal of Pure and Applied Mathematics” Scopus (Free Journal), 118(19), 29–42.
4. Manda, S., & Nalini, N. (2018). A study on trust based routing protocols in ınternet of things.
InternationalJournalofPureandAppliedMathematics”Scopus((FreeJournal),118(162018),
91–104.
5. Mishra, P. M. (2014). Internet of Things and Bayesian Networks. Available from http://www.
analyticbridge.com/proﬁles/blogs/internet-of-things-andbayesian-networks

Implementation of Bayesian Network Model (BN Trust Model) …
409
6. Wunder, G. (2016). RECiP: Wireless channel reciprocity restoration method for varying
transmission power, 1–5.
7. Karakostas, B. (2016). Event prediction in an IoT environment using naïve Bayesianmodels,
12–17.
8. Heckerman, D. (1995). A Tutorial on learning with bayesian networks. Microsoft Research
Report MSR-TR-95-06.
9. Ashton, K. (2009). That “Internet of Things” thing. RFID Journal, 4986.
10. Huang, Z., & Hsu, J. Y. (2014). Co-locating services in IoT systems tominimize the
communication energy cost, 47–57.
11. Chen, D., & Tang, X. (2018). Energy-efﬁcient secure transmission design for the ınternet of
things with an untrusted relay, 11862–11870.
12. Hu, J., & Yang, N. (2018). Secure transmission design with feedback compression for the
ınternet of things, 1580–1593.
13. Enciso, ˙I., & Galan, M. (2013). Assessment of throughput performance under NS2 in mobile
ad hoc networks (MANETs), (pp. 338–343).

Bioinformatics: The Importance of Data
Mining Techniques
Md. Nasﬁkur R. Khan, Shatabdee Bala, Sarmila Yesmin,
and Mohammad Zoynul Abedin
Abstract Data mining is a persuasive method that can be applied to bioinformatics
research. The study of biological information such as protein, DNA and RNA is
known as bioinformatics. Data mining errands/procedures include characterizations,
aspiration, bunching, correlation, irregularity acknowledgement, backslide and case
taking after. Data mining can be used to ﬁnd critical afﬁliations, chained instances
and bioinformatics intellectual database information. Apart from exceptional enun-
ciation, qualitative analysis of co-disease, detailed patient detecting identiﬁcation
and protein structure speciﬁcation and drug transparency, the social event of expense
and protein conﬁguration is more than one traditional repetitive representation that
has listed data mining as an affordable approach for bioinformatics. In this paper,
we are presenting the role of data mining techniques in Bioinformatics.
Keywords Bioinformatics · Classiﬁcation · Clustering · Data mining · Genes ·
Proteins
Md. N. R. Khan (B)
Department of Electrical and Electronic Engineering, Independent University, Dhaka, Bangladesh
e-mail: mnrkhan@iub.edu.bd
Md. N. R. Khan · S. Yesmin
Automation, Application and Biomedical Based Technical (AABTech) Lab, Dhaka, Bangladesh
S. Bala
Department of Computer Science and Engineering, Gono Bishwabidyalay, Dhaka, Bangladesh
S. Yesmin
Chittagong Medical College, Chittagong, Bangladesh
M. Z. Abedin
Department of Finance and Banking, Hajee Mohammad Danesh Science and Technology
University, Dinajpur, Bangladesh
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_32
411

412
Md. N. R. Khan et al.
1
Introduction
Bioinformatics is the integration of research, mathematics, bits of experience, medi-
cations, information development and computer software development. Bioinfor-
matics is the mastery of removing, repairing and breaking down massive amounts of
natural information, for example, DNA, RNA and Proteins and so on. Late innovative
transformation allows researchers to transmit huge volumes of data from estimates
of DNA information set, action course on proteins, information on the protein struc-
ture set, phénotype information set, genomic information collection set, for instance
[1–3]. As depicted in Fig. 1, bioinformatics has the unimaginable potential of investi-
gation in various areas such as the genome, proteomics, drug discovery and enhance-
ment, protein structure, cell science, nuclear showing, efﬁciency verbalization and
many more [2].
One can investigate and focus on critical cases in quality verbalization, organize
protein structure, quality number, standard ID, diagnosing various types of ailments
(infection, for example) for which values are expressed and so on. Data Mining
enables the analysis of bioinformatics data and it is critical to prepare to acknowledge
conﬁrmation, course of action, desire and inherent organization recognition [4–6]. In
this day and age, data is the foundation for anything whether it is properly analyzed
and isolated.
Figure 2 demonstrates the various forms of bioinformatics mining data available.
Information mining techniques can be effective for interpreting the association, situ-
ation and record dissemination from bioinformatics datasets. The aim of mining
techniques is to tunnel or “mine” information from massive amounts of data. Infor-
mation mining techniques ﬁnd the crucial event, gathered up data open from an
Fig. 1 Examining the
domain of bioinformatics

Bioinformatics: The Importance of Data Mining Techniques
413
Fig. 2 Types of
bioinformatics data
insightful array. Data mining procedures are effectively linked in different ﬁelds,
including retail, e-business, supporting, therapeutic administrations, research and so
on. Bioinformatics is a popular speciality in this ﬁeld of Biology.
Overall, the area that is using an enriched plan of action of data is the leading
contender for data mining. As a result, there is a tremendous opportunity to re-
establish the connection between data mining strategies and bioinformatics [7–9]. In
bioinformatics, there are numerous challenges such as protein arrangement, consis-
tency, etc., as well as the interaction between co-sicknesses. Data mining techniques
are adaptable to overcome these challenges and have involved new encounters in
extracting data and cases in a traditional database. Manufacturer resources, a subset
of statistics mining systems in bioinformatics, are discussed in this article. The
remainder of this article is structured as follows. Section two demonstrated the
drawbacks associated with the ﬁeld of bioinformatics. The undeniable data mining
assignment in bioinformatics is discussed in section three. In section four, the use of
statistics mining in infection gauge is discussed and section ﬁve concludes the article
by illustrating the future scopes.
2
Bioinformatics Challenges
The normal database is a massive amount of sloppy data evolution that causes
both opportunities and challenges for data revelation. Bioinformatics is used in
the nucleotide sequence, protein sequence and macromolecular sequence. Previ-
ously, a bioinformatics challenge was the creation and maintenance of data sets to
store unique information such as DNA, nucleotide, protein development and group-
ings. Recent developments in genomic and other subatomic investigation progresses,
as well as advancements in knowledge development, have combined to provide a

414
Md. N. R. Khan et al.
massive amount of evidence associated with subatomic research and computational
science [10]. The following characteristics are assessed at the level of bioinformatics:
• DNA, RNA and protein progressions are associated and analyzed
• DNA progressions provide evidence of gene recognition
• Microarray observations and understanding of consistency auditory stimulation
• The formation of phylogenetic trees to examine transformative connections
• Estimation and characterization of protein structure
• Subatomic docking and molecular arrangement.
Along with these, some noteworthy troubles are open in the bioinformatics ﬁeld
are:
1.
How to secure the enlightening collection to investigate a point of see?
2.
How to gather and disentangle evidence from various common sources when a
dataset is heterogeneous, such as images, content, cells, etc.?
3.
What are the best ways to classify and recognize distinctive data?
4.
How can gadgets be improved that allow data to be examined and integrated?
5.
How to use natural data and devices to examine and disentangle the speciﬁc
systems to ﬁnd and attain untouched natural visions?
Data mining techniques assist in the retrieval of substantial data from large
databases compiled from natural data and other relevant life sciences areas in order
to illustrate medicine and neuroscience [10–13]. These instructional documents are
potentially accessible to creative work. A lot of amazing function instructive collec-
tions are GenBank, Protein Information Bank and so on. Information mining tech-
niques are organized to comprehend the imparted needs in the ﬁeld of bioinformatics.
With the substantial advancement in ordinary data, records mining or KDD (Knowl-
edge Discovery in Databases) would expect to play an excellent role in analyzing
records and addressing advancing issues and inconveniences in bioinformatics [14].
3
Data Mining Techniques in Bioinformatics
Data mining is a technique for selecting notable cases, alliances and designs by
mining massive amounts of data from diverse data sources. Data mining is deﬁned as
Knowledge Disclosure in Databases (KDD) because it is used to assess the possibility
of subtle data from databases. KDD incorporates various indicators of success, for
example, data selection, data preprocessing, data modify, design/relationship seeking
for category data analysis and once more evaluation and perhaps the interpretation of
the illustrations to focus on the alternative that identiﬁes as data. Figure 3 illustrates
the orientation of KDD.
Data mining techniques allow for the reliable storing of data in a single location
that is usable in a variety of formats such as substance, images and so on. Without
using any data mining techniques, sensitive data or features are selected. Data prepro-
cessing is a data mining method that is used to transform raw data into a suitable

Bioinformatics: The Importance of Data Mining Techniques
415
Fig. 3 The ﬂowchart of database (KDD)
Fig. 4 Workﬂow of data
mining
form. Data preprocessing includes data inspection, data modiﬁcation and feature
extraction.
Data cleaning involves both misplaced and uproarious qualities. Data modiﬁcation
involves standardization, quality assurance, discretization and so forth, while data
reduction includes computational complexity reduction, dimensionality reduction
and data high—resolution form selection. Following preprocessing, data is ready for
extraction framework and data concentration [12].
As depicted in Fig. 4, there are various data mining endeavours such as organize,
gathering, interaction, irregularity detection, aspire, following an example and back-
slide. There are several computations and methods available for such a task. These
estimations focus on offering a balanced exposure to usage statistics. Data mining
techniques are considered valuable in the ﬁeld of bioinformatics due to the fact that
these tend to be effective in terms of effectiveness evolving and generating a degree
of standard statistics [13].
3.1
Classiﬁcation
The aggregation is perhaps one of the well-known data mining activities that assign
items in accordance to trigger instruction inspection. This is contingent on a system-
atic perception of where the objective instruction description is currently identiﬁed.
The course of action’s fundamental capability is to effectively ﬁnd out the speciﬁc

416
Md. N. R. Khan et al.
message designation for each selected feature highlight. For example, a conﬁgura-
tion showcase will predict and recognize cancer instruction content, if the condition
is favourable or detrimental, whether there is an occurrence of bony illness and so
on.
To establish an approach to content illustrates, as a major aspect, the programme’s
arranging is guided. During the planning process, demonstrate has taken inside the
data highlight and their contrasting objective path using computation. This movement
is also known as the test advancement procedure.
Following the effective preparation of the demonstration, the next step is to coor-
dinate the demonstration’s endeavour. Integrate constructions are accomplished by
arranging with the standard route label to recounted benchmark engaging label in
a spectrum of analyzing data. The favourable evidence for a depiction showcase is
usually divided into two instructive records: one for assembling the demonstration
(also known as the display outline step) and the other for intending the depiction.
The accuracy of the ﬁltering out such a phase establishes the classiﬁer’s standard
presentation. The prediction is the compilation of erroneous data for a terrestrial
insight [15].
Decision Tree, SVM, Random Forest, KNN and Naïve Bayes are some of the most
common for the measurement of characteristics of the exhibit framework. The calcu-
lation of KNN, Decision Tree and SVM are not used equally in the e-business, but
in bioinformatics extension, for customer behaviour and constancy. Quality inter-
pretation, protein structure ﬁgure is a few signiﬁcant characteristic examinations
conducted by intervention research methods for data mining. The procedure provides
a wide range of information for incidence indicators of attributes, protein function,
inherent coordination and so on and is primarily used in systems and computation
studies [16].
Classiﬁcation techniques distinguish massive natural databases in search of
a convincing set of circumstances, expectations and possible outcomes. Protein
structure analysis, production classiﬁcation, disrupting implementation framework
that focuses on genomic evidence, identiﬁable validation of function articulation,
protein-protein interactions, etc.—are examples of this type of analysis.
3.2
Clustering
Data mining focuses on unhindered identiﬁcation in circumstances where the refer-
ence check is uncertain. It is used to classify data clusters in such a way that each
cluster has the most ﬁrmly initiated data. Clustering is similar to sorting, but the
distinction is that the collection of data is based on their similarities. Distance-
based clustering, dynamic clustering, self-sorting out maps, fuzzy clumping, map
clustering, fragment clustering and graphics clustering are all useful clustering
methodologies for bioinformatics investigations. K-Mean (separate based) and Gaus-
sian Blend Models (GMMs), Hidden Markov Models (HMM) and Expectation-
Maximization (EM) are a few examples of notable clustering equations used in

Bioinformatics: The Importance of Data Mining Techniques
417
bioinformatics research. For characteristic gathering, on the other hand, Generalized
Estimating Equations (GEE) are used [14].
Clustering is widely linked in microarray testing to disrupt the constrictions of
assignment searching, where the intended practice label is often undisclosed at the
period the experiment starts. For example, assume a researcher needs to see how
disease in a particular tissue or disorder inﬂuences the level of eloquence or cognition
shifts between various groups. Top-notch articulation is the process of incorporating
scientiﬁc evidence into the association of a signiﬁcant commodity component such
as protein or RNA. To form and restore biological entity cells, attributes are the
basics of distinctive residue in living organisms. To handle in function for non-
uniform instances, schematic representation of action consistency articulative data
is interconnected to evaluate brief mitigation strategies.
The main goal of collaborative approaches is to reduce the number of features
to those that can be expressed dynamically through experiments. GeneXPress is a
discernment and examination mechanism that can assess the adequacy of any clus-
tering process for a reconﬁguration of high-quality inputs and categories. Further-
more, clustering can be used to effectively distort cloud accessibility and disclose
strategies. In the end, collecting standard data would be essential for analyzing the
data and establishing stable connections between the various elements. One of the
most popular clustering applications is Genetics Calculation. In data analysis of
quality articulation, truthful clustering, lucrative compilation and neural network
clustering procedures are very efﬁcient [16].
3.3
Association
Afﬁliation is a fact-mining project that looks into the probability of variables in a
data set co-occurring. Apriori is a contemporary way of ﬁguring that is crucial in
determining measuring in current datasets and establishing membership laws. The
Association Rule is important when looking at retail holder or trade results and it is
commonly used in Characteristic Canister Evaluation (CCE). CCE is the analysis of
market trade databases in order to see if conditions differ among the various items
that consumers purchase at different times. Furthermore, in clinical bioinformatics,
it is more likely to expect related co-disease from one tainting. Apriori prediction
has provided the ﬁndings of looking forward to the co-diseases in diabetic patients
by extracting an exclusive insightful series of control.
The majority of diabetic patients’ results have shown that they are more likely to
have brain strokes and cardiovascular setbacks in the future. The link that makes the
decisions is primarily helpful in detecting co-morbidity in clinical data analysis, bio-
clinical works, protein potential outcomes, outline data, key reversal and distortion
disclosure in the arrangement, client connection with charge or Payment gateway
trading ofﬁcials and so on [17].

418
Md. N. R. Khan et al.
3.3.1
Medical Data Analysis
Data mining can assist specialists in resolving patient issues. Mining Alliance Rules
aids in identifying co-events with afﬂictions handed on by a chronic that has used the
clinical treatment department. The demonstration, which is run by the association,
supports in detecting the possibility of such illnesses in the vicinity of such diseases.
Clinical data is an analysis for determining the contaminations that have formed a
coalition to run the programme. It is possible to anticipate the possibility of emerging
infection by considering the steps that arrange the illness and its side effects using
alliance make the decisions. In these sections, the main ailment may be detected and
thwarted. Far too many drugs used for multiple diseases can be revived by taking the
same drug with a particular mixture of illnesses. Open access, Twitter and Facebook
will also be used to collect information for the clinical review.
3.3.2
Protein Sequences
Protein is an essential piece of every residing organism. Protein is constructing
squares of diverse Amino acids strengthened by peptide bonds. To put it another
way, amino acids bind folds together in a perplexing way, giving each protein an
amazing 3-D structure. The misfolded form may also be caused by mild misman-
agement within the imploding alliance. This misfolded form is the driving factor
behind neurodegenerative symptoms such as Alzheimer’s, Parkinson’s and Sickle
cell disease.
Since amino acids are the building blocks of protein, courting a few of the most
important amino acids and detecting evidence in their cases is critical. Perceiving
the times of the amino acids is important from now on for communicating protein-
relatedherbalillnesses.TheAprioricalculationisalsowidelyusedtoﬁndunremitting
commodity set age by the use of association function, which is essential for effective
informatics [14].
3.4
Outlier Detection
Characteristics transparency helps to explain predictive plans that do not suit the
predicted behaviour. The key element is publications that might be substantially
different, sublime, or contrary in terms of additional data. During this slicing half-
year,thebioinformaticsstatisticsspiltminingﬁeldhasrevealedafundamentalideaby
inquiries around great directions. The peculiarity is the obvious main example, which
is unable to include a consistent, almost instructive list. Uncommon case conspicuous
veriﬁcation is a way of resolving identiﬁable discrepancies in the statistics base.
ODR-ioVFDT is associated with bioinformatics peddling statistics allowing plans for
ﬁnding and measuring the details of environments inventions of the function content
and may assist with diagnosing and resolving the complication even more effectively.

Bioinformatics: The Importance of Data Mining Techniques
419
Outlierextraordinaryconﬁrmationisusefulfordetectingunusualreactionstocutting-
edge medical solutions [18].
Data collection can be utilized when the nature of properties is straight out and
on the off chance that nature of quality is ceaseless, backslide show is connected.
A few critical classiﬁcation algorithms are decision tree, Naïve Bayes, SVM, KNN
and so forward and backslide show depends on straight and key backslide. Backslide
utilized transcendently as a sort of planning and illustrating to see the chance of a
particular given variable inside the locate of distinctive components. The amazing
target of backsliding is to examine the particular association between components.
Backslide is also oftentimes utilized in bioinformatics to expect the surrender
estimation of a natural interaction for a particular common system beneath a deﬁnite
situation. The signiﬁcant aspect of the coordinate backslide show is to choose the
backslide loads apportioned to each quality. Coordinate backslide moves forward the
component assurance for quality choice subordinate on their uniqueness level from
the run of the process quality verbalization backslide line [19].
3.5
Tracking Patterns and Prediction
The vital portion of data mining strategies is ﬁguring out how to see plans in enlight-
ening collections. Data mining, as scientiﬁc understanding, endeavours to discover
unfaltering, modern, proﬁtable and noteworthy cases in tremendous volumes of data
that analyze the concealed illustrations within the quality verbalization microarray
data for down-to-earth proteomics and genomics. Bunching, course of action reve-
lation, an association run the show and so forward can be connected to recognize the
illustrations in data that discover the properties of the data, removed data and cases
that are surveyed and a short time later afﬁrmed as data.
Want is the maximum facts mining strategy, given that it is far used to heighten
such data thereafter on. In bioinformatics, you possibly can foresee from DNA get-
collectively and Amino detrimental strategy. With the fact-mining technique, one
can anticipate its cap potential depending on the main likeness which could provide
assistance to predict which debris or medicines can properly bind to the protein.
Normally surely top importance for orchestrating drugs [1–19].
4
Utilization of Bioinformatics and Data Mining in Disease
Prediction
Data burrowing gives innovative devices to clinical applications for powerful sick-
nesses and besides makes a difference with recognizing the organism and analyzing
the pharmaceutical obstacle plan. Data mining assignments in bioinformatics are
proﬁtable in a couple of disorder arrangements and ﬁgures. Alliance examination is

420
Md. N. R. Khan et al.
maybe the foremost standard examination measure in data mining. Data mining can
be critical within the consider of malady transmission and ailment examination to
ﬁgure the case of afﬂictions and track the scenes. It tends to be utilized to see the
clinical data to assess the capability of prosperity programmes and organize people
in threat of emerging therapeutic conditions. Bioinformatics applications are utilized
to an examination of whole quality verbalization proﬁles to recognize the ailment at
a genome level and pose unused hypotheses about particular threatening counting
the act of course of action, upkeep and improvement of tumours.
Protein development and cooperation are big for anticipating proteins’ molecular
limits that give desires to constructing infection systems and developing modern
remedies outrageous to stop the infection. Specialists with facts mining devices and
strategies are developing their conﬁrmation in illness need and region [1].
Ideally,dataminingerrandwillhaverelentlessportionsthatpassonbioinformatics
into a more created ﬁeld and offers a useful procedure for building correct choices
in completely different regions, counting sickness investigation desire.
5
Future Scopes
Bioinformatics is generating new gene editing and synthetic biology advances that
are reshaping the future health and medicine market, thanks to current technological
advancements such as IoT, cloud, artiﬁcial learning, deep learning and data mining.
Provide new schemes and techniques for diagnosing infectious diseases, defending
against bioterrorism and managing disease outbreaks. Understanding the structure
of genomes and how they act in viral replication and cell entry is important for
developing successful vaccine and drug strategies for modern diseases like Covid
19.
Subatomic investigators and clinical experts will be screened and bolstered by
bioinformatics in order to maximize the advantages of computational science. There
is a push to incorporate bioinformatics’ capabilities into the foundation in order to
contribute to research in serious illnesses, such as evidence and medication reports,
to prevent pain and spread in the future.
6
Conclusion
Data mining and the advancement of data ﬁnding tools is a feature of dynamic
bioinformatics technology. The possible tools used in modern biotechnology include
data mining techniques like classiﬁcation, correlation, cluster, regression and predic-
tion. Bioinformatics research is so comprehensive that the properties of biolog-
ical databases encounter many challenges. Data mining methods are important for
solvingbioinformaticschallengesintermsofefﬁciencyandprecision.Thatiswhythe

Bioinformatics: The Importance of Data Mining Techniques
421
importance of bioinformatics data mining techniques is unavoidable. Data mining
techniques also can effectively perform tasks such as gene classiﬁcation, protein
sequence analysis and estimation, genome annotation and drug discovery.
References
1. Singh, P., & Singh, N. (2021). Role of data mining techniques in bioinformatics. International
Journal of Applied Research in Bioinformatics (IJARB), 11(1), 51–60.
2. Lin, E., & Lane, H. Y. (2017). Machine learning and systems genomics approaches for multi-
omics data. Biomark Research, 5, 2.
3. Friedman, J., Hastie, T., & Tibshirani, R. (2010). Regularization paths for generalized linear
models via coordinate descent. Journal of Statistical Software, 33(1), 1–22. PMID: 20808728;
PMCID: PMC2929880.
4. Zou, H., & Hastie, T. (2005). Regularization and variable selection via the elastic net. Journal
of the Royal Statistical Society. Series B (Statistical Methodology), 67(2), 301–320.
5. Huang, L.-C., et al. (2009). A comparison of classiﬁcation methods for predicting Chronic
Fatigue Syndrome based on genetic data. Journal of Translational Medicine, 7(81), 22. https://
doi.org/10.1186/1479-5876-7-81
6. Lin, E., Chen, P. S., Lee, I. H., Chang, H. H., Gean, P., Yang, Y. K., & Lu, R. (2010).
Modeling short-term antidepressant responsiveness with artiﬁcial neural networks. Open
Access Bioinformatics, 2, 55–60.
7. Kim, W., Kim, K. S., Lee, J. E., Noh, D. Y., Kim, S. W., Jung, Y. S., Park, M. Y., & Park,
R. W. (2012). Development of novel breast cancer recurrence prediction model using support
vector machine. Journal of Breast Cancer, 15(2), 230–238. https://doi.org/10.4048/jbc.2012.
15.2.230 Epub 2012 Jun 28.
8. Tseng, C. J., Lu, C. J., Chang, C. C., et al. (2014). Application of machine learning to predict the
recurrence-proneness for cervical cancer. Neural Computing and Applications, 24, 1311–1316.
9. Chang, S. W., & Merican, A. F. (2013). Oral cancer prognosis based on clinic pathologic and
genomic markers using a hybrid of feature selection and machine learning methods. BMC
Bioinformatics, 14, 170.
10. Ritchie, M., & Holzinger, E. (2015). Li, R, Methods of integrating data to uncover genotype-
phenotype interactions. Nature Reviews Genetics, 16, 85–97.
11. Kim, D., Li, R., Dudek, S. M., & Ritchie, M. D. (2013). ATHENA: Identifying interac-
tions between different levels of genomic data associated with cancer clinical outcomes using
grammatical evolution neural network. BioData Mining, 6, 23.
12. Mankoo, P. K., Shen, R., Schultz, N., Levine, D. A., & Sander, C. (2011). Time to recurrence
and survival in serous ovarian tumors predicted from integrated genomic proﬁles. PLoS One,
6(11), e24709. https://doi.org/10.1371/journal.pone.0024709
13. Holzinger, E. R., Dudek, S. M., Frase, A. T., Pendergrass, S. A., & Ritchie, M. D.
(2014). ATHENA: The analysis tool for heritable and environmental network associations.
Bioinformatics, 30, 698–705.
14. Bah, S. Y., Morang’a, C. M., Kengne-Ouafo, J. A., Amenga-Etego, L., & Awandare, G. A.
(2018). Highlights on the application of genomics and bioinformatics in the ﬁght against
infectious diseases: Challenges and opportunities in Africa. Frontiers in Genetics, 27(9), 575.
15. Stilou, S., Bamidis, P. D., Maglaveras, N., & Pappas, C. (2001). Mining association rules from
clinical databases: An intelligent diagnostic process in healthcare. Studies in Health Technology
and Informatics, 84(Pt 2), 1399–1403. PMID: 11604957.
16. Liu, C., Zhou, Q., Li, Y., Garner, L. V., Watkins, S. P., Carter, L. J., Smoot, J., Gregg, A. C.,
Daniels, A. D., Jervey, S., & Albaiu, D. (2020). Research and development on therapeutic
agents and vaccines for COVID-19 and related human coronavirus diseases. ACS Central
Science, 6(3), 315–331.

422
Md. N. R. Khan et al.
17. Wahl, S., Vogt, S., Stückler, F., Krumsiek, J., Bartel, J., Kacprowski, T., et al. (2015). Multiomic
signature ofbodyweight change: Resultsfroma population-basedcohort study. BMC Medicine,
13, 48.
18. Rahman Khan, M. N., Yesmin, S., Aktar, M., Quader Chowdhury, K. B., Labeeb, K., & Abedin,
M. Z. (2021) Techniques for Multi-Omics Data Incorporating Machine Learning and System
Genomics. In: 2021 6th International Conference on Communication and Electronics Systems
(ICCES), pp. 1524–1528. https://doi.org/10.1109/ICCES51350.2021.9489222.
19. David, S. K., Saeb, A. T., Raﬁullah, M., & Rubeaan, K. (2019). Classiﬁcation techniques and
data mining tools used in medical bioinformatics. In: Strydom, S. K., & Strydom, M. (Eds.)
Big data governance and perspectives in knowledge management (pp. 105–126). IGI Global.
https://doi.org/10.4018/978-1-5225-7077-6.ch005

Comparative Analysis of Different Deep
Learning Techniques for Relation
Extraction from Biomedıcal Literature
M. Saranya, T. V. Geetha, and R. Arockia Xavier Annie
Abstract Developing an automated system for extracting the hidden relation
from unstructured text is very challenging and demanded task. In manufacturing
unhurt drugs, identifying new candidates for existing drugs (drug repurposing) and
improving the system of health care, the relation extraction plays the major role in
the ﬁeld of biomedicine. Generally, relation extraction is designed as a classiﬁca-
tion problem which is the subtask of information extraction. Due to the unavail-
ability of common annotated corpus for all types of biomedical relations and the
existence of imbalanced class problems, the classiﬁcation method is not suitable,
and it reduces the classiﬁer’s performance. Therefore, we introduced deep learning
models with existing corpora of different types of biomedical relations to solve the
above-mentioned issues. Before designing deep learning models, k-means SMOTE
is passed down to equalize the dataset which is the recent oversampling method.
Six distinct features are extracted from the sentences, and the embedding of those
features are fed into deep learning models. From these features, the dependency-
based word sequence (context) and dependency-based relation sequence (context)
contribute more in the accuracy of the system. Using this technique, we extracted
three types of associations called drug-drug, drug-disease, and drug-side effect. The
results which we obtained represent that training the model with balanced dataset
produces better result than imbalanced dataset.
Keywords Relation extraction · Class imbalance · Deep learning models ·
Embedding · The shortest dependency path · Dependency-based word sequence ·
Dependency-based relation sequence
M. Saranya (B) · R. A. X. Annie
Computer Science and Engineering, CEG, Anna University, Chennai, Tamil Nadu, India
T. V. Geetha
UGC-BSR Faculty Fellow, Computer Science and Engineering, CEG, Anna University, Chennai,
Tamil Nadu, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_33
423

424
M. Saranya et al.
1
Introduction
One of the great challenges in our digital world is manipulating the enormous amount
of heterogeneous often wavering structured data and unorganized text data [1]. With
the exponential growth of biomedical-related articles or publications on the Internet,
it is increasingly difﬁcult to ﬁnd the knowledge submerged in it. The complexity
and scale of the data in the biomedical domain are the motivation toward mining the
heterogeneous data from unstructured text. Manual effort to transform the unstruc-
tured text into structured is a laborious process [1]. Hence, an automated method
or technique is needed to extract the information behind it. The determination of
biomedical relation extraction from the text has acquired a great concentration in the
modern times; on account of this awareness, it allows the different types of inter-
actions that appear among the biomedical entities. Adverse drug event is a critical
problem in the health care system. In the US, patients especially older patients are
taking more than ﬁve drugs at a time. This is the situation where there is high chance
of interaction between drugs. Adults in the US aged over 60 are prescribed more
than 5 drugs at a time of about 36.1% [2].
Drug-drug interaction (DDI) is a type of biomedical relation where interaction
between two drugs will occur and that causes side effects in the form of positives and
negatives on the patient [3]. DDI, which is the subset of ADE, is also an important
factor contributing toward adverse drug effects (ADE). In most of the countries, there
are more deaths per year due to adverse drug effects, and it increases the clinical
care system investment [4]. Hence, to improve the clinical care system, the relation
between drug-drug and drug-side effects is identiﬁed from the scientiﬁc literature. It
is also very important to differentiate the drug-disease treatment relations occurred
in the documents when the adverse drug effects are identiﬁed from the articles. So,
extraction of three types of biomedical relations such as drug-drug, drug-disease,
and adverse drug effects is handled in this paper.
For DDI, DrugBank [5] and Stockley’s drug interactions [6] have been developed
to determine the relations from the structured data. But, these data are having limited
access and cannot be directly accessed like relational database. Since the rapid growth
in the scientiﬁc articles, many relations remain hidden in unstructured biomedical
texts. Thus, the automated method is needed to extract the relation from unstructured
texts. Relation extraction task in NLP is very typical. There are many rule-based and
machine learning-based algorithms are available to extract the relation. Currently,
deep learning methods have been achieving state-of-the-art results in solving Natural
Language Processing problems [7]. Deep learning models are very powerful than the
traditional model, because the model learn the required features by its own. In this
work, we are comparing different types of deep learning techniques with cross-corpus
training incorporating more features like word context, entity position, concept-type,
part-of-speech tagging, Chunk tag, and the shortest dependency path. Before passing
the inputs to the deep learning models, the features must be represented as embedding
using different embedding methods with respect to the different types of features.
Here,wehaveusedSMOTEandk-meansSMOTE[8]tomaketheinstancesbalanced.

Comparative Analysis of Different Deep Learning Techniques …
425
Because in most of the relation classiﬁcation problem, datasets do not contain the
same number of instances in each classes, and it also degrades the performance of
the classiﬁer. Hence, we used random oversampling algorithm which is mentioned
earlier to resolve the class imbalance problem before training the model.
2
Related Work
Internet is permeated with lot of biomedical data in both structured and unstructured
forms [9]. Even though structured data are available, that are not updated properly,
and they are far from the current availability of information. More and more rela-
tions are hidden in the biomedical text, and that should be identiﬁed or extracted
from it. One of the main tasks of Natural Language Processing (NLP) is information
extraction from the plain unstructured text; these extracted information can be clearly
understood by machine or a program [9]. In previous years, with the help of super-
vised algorithm called feature-based and kernel based-methods, the relation has been
extracted. For these above methods, feature vector have to be created for training the
model [10]. For developing the feature vector, vector itself requires more additional
steps including named entity recognition (NER), type of relation, relation extraction,
event extraction, etc. [10]. Generally, supervised learning algorithm requires more
training dataset for its classiﬁcation. Traditional methods need more man power to
generate the feature vector, and also, it is very time-consuming process and expen-
sive [7]. Sometimes, these hand-annotated datasets are not enough to extract the
relevant information [11]. This is the situation where an automated feature engi-
neering method called deep learning comes into picture for relation extraction. Deep
neural network (DNN) learns the necessary features automatically, and it produces
the good attainment in relation extraction [12].
One of the powerful deep learning method called Convolutional Neural Network
(CNN) is initially works well for image processing domain and it is extended to NLP
problems in current years [12]. There is a lot of relations and concepts present in
the biomedical text and the clinical records. He et al. [12] used deep learning model
to extract prosperous and absolute features to classify these relations which produce
good results also. To migrate the issues (sparse, higher dimension, and varying
length vectors) of traditional representation of features, famous concept called word
embedding has been employed. This approach can be followed by many of the deep
learning-based approaches in NLP tasks. Because, this word embedding approach
[13] represents the features in dense, low-dimension of ﬁxed length. In NER [14],
relation extraction problem word embedding has been used very successively. After,
there are many experiments have been done on different embedding for choosing
which is producing better results in NLP by Ghannay et al. [15]. Comparatively,
dependency-based embedding works better than others.
Class imbalance problem is the major drawback of biomedical relation extraction
in which the data samples are not uniformly distributed across the different classes.
This is the problem where the number of sample in one class is higher (majority) than

426
M. Saranya et al.
number of samples in another class (minority). Due to the presence of uneven class
distribution of the samples or dataset, most of the state-of-the-art methods are not
predicting the samples to the correct class in classiﬁcation [8]. And, also the model
which have been developed during the training may be over ﬁtting or erroneous model
which is not able to achieve better result [8]. Thus, the above class imbalance problem
can be rectiﬁed by applying frequently used techniques called oversampling and
undersampling. SMOTE and k-means SMOTE are an oversampling methods which
will generate the new instances for the minority class rather than simply duplicating
the available instances. The input to the model is the feature embedding vector
obtained using the six features, namely word context, entity position, concept-type,
part-of-speech tagging, parse tree, and the shortest dependency path.
3
Biomedical Relation Extraction
Generally, there are two categories in biomedical relation extraction task (i) binary
relation extraction and (ii) multi-class binary extraction. Binary relation extraction
checks whether the entity pair has semantic relation or not, i.e., whether the given
pair has true relation or false relation. But, multi-class relation extraction detects
the semantic relation as well as type of relation also. For example, DDI relation
extraction has four types as follows advice, effect, int, and mechanism. Thus, the
relation extraction task is considered to be the main goal of the biomedical relation
extraction [16] (Fig. 1).
Fig. 1 System architecture

Comparative Analysis of Different Deep Learning Techniques …
427
3.1
Preprocessing
The annotated corpus is available in different format like .CSV and.XML. These
dataset are needed to be changed in the appropriate format by removing unnecessary
information before giving as an input to train the model. In preprocessing stage,
sentence splitting and entity extraction are done. Then, the splitted sentences are
converted into tokens by using GENIA tagger [17]. Generally, in biomedical docu-
ments (datasets), more numerical values are presented in the form of integer and
ﬂoat. Suppose all the numerical values are considered as such in the document, the
vocabulary size gets increased. To avoid this, numerical values are changed into
uniform format.
3.2
Representation Learning
In order to perform any machine learning task, representation learning or feature
learning is founded to be the most appropriate representation, and it plays a major
role in algorithm’s performance also. [13]. It becomes more important to represent
the unstructured data like text in such a way that is meaningful to any of the model
or algorithm. Here, the representation of each word in the input sentence will be the
concatenation of different feature embedding, and these concatenated feature vector
embedding of the sentences are passed as an input to the deep learning models. (1)
Word context, (2) POS tag, (3) Chunk tag, (4) positions (p1,p2), (5) type of word,
and (6) the shortest dependency path (SDP) are identiﬁed as beneﬁcial features for
relation extraction or classiﬁcation. Embedding vector of each word is obtained by
using the most familiar model called Skip gram model [13].
Each feature is brieﬂy described below:
1.
Word Context (f 1): Exact word appeared in the sentence.
2.
POS (f 2): Using GENIA tagger, the parts-of-speech tag of examined word is
identiﬁed.
3.
Chunk (f 3): Here, also GENIA tagger is used to identify the Chunk tag of each
word in the sentences.
4.
Positions (P1, P2) (f 4): Identifying the distance between the current word and
the entity1 and entity 2, respectively.
5.
Word Type (T) (f 5): Identifying the type of word. For example, it would be
BI tags for the entities and other for rest words following the BIO tagging
convention.
6.
The Shortest Dependency Path (f 6):
Sentence:
Fixed drug eruption is associated with many drugs, but this is the ﬁrst
such report with omeprazole.
The main claiming of the relation extraction is deﬁnite identiﬁcation and classiﬁ-
cation relation for the complicated sentences. The dataset does not contain uniform

428
M. Saranya et al.
Fig. 2 Dependency tree and the shortest dependency path
length and clauses. Sometimes, the sentences may have more than 150 words. The
help of lexical and syntactic features of sentences alone is not enough to detect the
relation very accurately. Thus, the emergence of the shortest dependency path to use
in Natural Language Processing tasks is suggested by few studies which are giving
very useful syntactic features for relation extraction. To increase the usage of the
SDP, we split it into dependency word sequence and dependency relation sequence
[18] (Fig. 2).
3.3
Embedding Layer
The above ﬁve features, namely word-context, POS, Chunk, positions, type of word,
are concatenated into single feature embedding for each word in the sentences, and
it is represented as wi. The equation of the same is given below.
wi = f i
1 + f i
2 + f i
3 + f i
4 + f i
5
(1)
f ii is the i-th feature embedding of the i-th word in the sentence. The size of the
vector wi is the addition of all feature’s vector size. And, it could be written as wi
e R(n1+n2+···+n5), and ni is the vector size of the i-th feature. The relation extraction

Comparative Analysis of Different Deep Learning Techniques …
429
Fig. 3 Illustration of deep learning model for biomedical relation extraction
system using different deep learning methods is illustrated in Fig. 3. Embedding of
the sentences are represented in Eq. 1. Likewise, for the dependency word sequence,
embedding also depicted as di = f 1i + f 2i + f 3i + f 4i + f 5i. For a relation rk in
the dependency relation sequence {r1, r2,…rm}, the dependency relation sequence
embedding is obtained based on the relation rk and the word2vec model.
3.4
SMOTE
Before training the model, the uneven distribution of feature vector has to be
addressedproperly.SMOTEistheoversamplingtechniquetocreatethenewsynthetic
instances from the minority class.

430
M. Saranya et al.
for each minor class sample do 
m)
r) among the training samples 
find difference between considered sample and nearest neighbour sample (d = m −r)
consider any one of the minor class sample (
find nearest neighbour using KNN algorithm (
choose random no between 0 and 1 (i) 
calculate m * d + i which is synthetic minor sample 
end for
The above explained algorithm will generate new synthetic samples with the help
of less number of minor class samples to solve imbalanced dataset problem. The
imbalanced datasets will be given as input to this algorithm. Choose any xi which
belongs to Smin (minor class sample). By using KNN, it will ﬁnd the new neighbor in
minor class samples. Finally, new samples are generated to eliminate the imbalanced
dataset problem.
3.5
k-means SMOTE
Even though SMOTE algorithm eliminates the problem of overﬁtting occured by
random over sampling method, it also has some issues with noise and imbalanced
data [19]. Because, this algorithm is not able to carry out the decision boundary.
So that, the samples which are actually far from the outline are oversampled as
close to the outline with equal likelihood. Though SMOTE has some weakness, it
has been used broadly due to its simplicity. To improve and reduce the noise and
imbalanced data, there are many techniques that have been tried with SMOTE like
CURE-SMOTE uses hierarchical clustering and self-organizing map oversampling
(SOMO) [19] . Finally, cluster-based SMOTE called k-means SMOTE has been
used to reduce the noise as well as between and within class imbalance into some
extent [19]. This will cluster the minority classes before applying SMOTE instead
of choosing the minority sample in random way. Cluster method will group same
likelihood samples in one cluster, so that the decision boundary problem get ﬁxed
here. Steps followed in the k-means SMOTE are given below,
Step 1: Clustering: Using k-means, cluster the entire input space.
Step 2: Filtering: Distribute the number of samples to generate across clusters: Filter
out clusters which have a high number of majority class samples.
Step 3: Oversampling: Using SMOTE, oversample each ﬁltered cluster [Step 2].

Comparative Analysis of Different Deep Learning Techniques …
431
3.6
Deep Learning Models
3.6.1
Convolutional Neural Network
Based on the ﬁlters or window size of different length, the signiﬁcant features have
been extracted from by the CNN. The embedding of the sentences of same length is
given as input to the CNN model for training. The probability value of each relation is
obtained as an output of this model in the form of vector of size equal to the number of
relation types (in this work, no. of relation including negative type is seven) by doing
some operations on different layers called convolution layer, max pooling layer, and
fully connected layer. Figure 4 illustrates the relation extraction task from text.
Convolution layer:
To get the local feature from the entire sentences, it is extracted by applying convo-
lution which is the heart component of the CNN. Convolution represents different
ﬁlters of different size [20]. Wi is the concatenated feature embedding for the i-th
word in the sentence.
The feature vectors for the sentence of length n are f 1, f 2, … f n. In Fig. 4, the
length used by the ﬁlter (d) is 3 and activation function used here is rectiﬁed linear
unit (ReLU). The output of each convolution (hidden layer) hi is calculated as below
Eq. 2
Fig. 4 Convolutional neural
network model

432
M. Saranya et al.
hi = f (w · Wi:i+d−1 + b)
(2)
where i = 1,2,3…n −d + 1.
Here, w—weight vector, b—bias term →learning parameters, and f —ReLU
function.
·—dot product, n–No. of words in the sentence, and d—ﬁlter size.
Max pooling layer:
Output of the convolution layer will give only the local features of varying length.
Usage of max pooling is to extract the necessary features, i.e., global features from
the sentences for relation extraction. Applying different ﬁlters of varying length is
used to extract the global features of the sentence [12]. The output of max pooling
is given as below
Z =

cmax
1
, cmax
2
, . . . cmax
t

(3)
where ckmax = max(cj1, cj2, …cjn −d + 1).
Fully connected layer:
Overﬁtting of the model can be avoided by using dropout function and regularization
technique on the output of the max pooling layer. After, it is passed down to the fully
connected layer. To reduce the loss of the i-th sentence, soft-max classiﬁer is used,
and it is depicted in Eq. 4. Soft-max classiﬁer is also used to detect the type of the
relation.
Li = log
ezi
yi

∀j ezi
j
(4)
yi—correct relation of i-th instance or sentence.
3.6.2
Long Short-Term Memory (LSTM)
Drawback of CNN model is not suitable for the relation extraction among the longest
sentences, i.e., block of text because it has long-term dependencies problem. Some-
times, the dataset may contain the longest sentences also, and it is not efﬁcient to
remember the dependencies among the words in the sentences. The solution to the
above problem is LSTM which is the special type of recurrent neural network. LSTM
will rectify the long-term dependencies by remembering it for longer time. The term
called cell state is the main key of the LSTM. LSTM has the capability to add or
remove the information to the cell state, and it is regulated keenly by the gates.
Figure 5 illustrates the basic steps of LSTM.

Comparative Analysis of Different Deep Learning Techniques …
433
Fig. 5 Long short-term memory
Initial step is deciding which information should be throwing away from the cell
state, and it is done by sigmoid layer called forget gate layer. For example, when the
new subject is arrived, the previous subject’s pronoun should be erased from the cell
state. The output of the layer is “0” means completely remove the information or “1”
means completely have this information.
ft = sigmoid

W f ·

ht−1, xt

+ b f

(5)
where Wf , bf —learning parameters of forget gate layer (weight matrix, bias term).
Next step is deciding what information to be stored in the cell state, and it is
done by sigmoid layer and tanh layer. Sigmoid layer establishes which values to be
updated (it), and tanh layer generates the new candidate values (Ct’).
it = sigmoid

Wi ·

ht−1, xt

+ bi

(6)
C′
t = tan h

Wc ·

ht−1, xt

+ bc

(7)
Next step is to combine the values generated by Eqs. 6 and 7 and update the values
of previous cell state (Ct −1) to the new cell sate (Ct) by multiplying previous cell
state Ct −1 by f t for erasing the old values. Then, for deciding up to how far the
values to be updated, it is given by

it ∗C′
t

Ct = Ct−1 ∗ft + it ∗C′
t
(8)
After updating the values of the cell state, ﬁnally, decide what values are sent
output. The output values are ﬁltered version of the cell state values. First, sigmoid
layer is done to decide whether the part of the cell state values are sent output. The

434
M. Saranya et al.
cell state values are passed to tanh, and this could be multiplied by the output of the
sigmoid layer to choose what values can be output.
outputt = sigmoid

Woutput ·

ht−1, xt

+ boutput

(9)
hiddent = tan h (Ct) ∗outputt
(10)
By the above equations from 5 to 10, it is used to identify the information to be
stored for a long time or the information to be erased. In previous RNN models, there
is no facility for vanishing gradients which was a vast problem, and this may cause
the layers not to learn much.
3.6.3
Bidirectional Long Short-Term Memory (Bi-LSTM)
Using bidirectional LSTMs, you feed the learning algorithm with the original data
once from beginning to the end and once from end to beginning. There are debates,
here, but it usually learns faster than one-directional approach although it depends
on the task. For maximizing the learning rate of the algorithm, feed the input from
start to the end and from the end to the start by using Bi-LSTM model. This learns
the features faster than the unidirectional approach (Fig. 6).
Fig. 6 Bi-LSTM model

Comparative Analysis of Different Deep Learning Techniques …
435
4
Result and Analysis
Precision, recall, and F-measure are the mostly used evaluation metrics in relation
extraction from the biomedical text. F-measure is the correct metric to measure the
overall performance by combining precision and recall. The formulae for the above
metrics are as follows:
Precision =
True Positive
True Positive + False Positive, Recall =
True Positive
True Positive + False Negative
F-measure = 2 ∗Precision ∗Recall
Precision + Recall
4.1
Datasets
Here, different deep learning techniques have been evaluated using DDI extrac-
tion challenge 2013 dataset [17], ADE corpus [21], and EU-ADR corpus [20]
for extracting the relation between drug-drug, drug-side effects, and drug-disease,
respectively. DDI corpus has MEDLINE abstracts and DrugBank documents of count
233 and 792, respectively. And also, it has four types of relations called (i) mecha-
nism, (ii) advice, (iii) int, and (iv) effect. ADE corpus consists of 2972 MEDLINE
sentences which are the case reports of different patients. These sentences are anno-
tated with drug, dosage, and side effects. Totally 20,967 sentences can be generated in
which 4272 sentences are positive and 16,695 sentences are negative. Likewise, EU-
ADR corpus is also annotated with drug, gene, and disease entities. From these,
only drug-disease annotated sentences are considered. Table 1 contains detailed
description of the dataset.
Table 1 Dataset description
Relation type
Positive instances
Negative instances
DDI mechanism
1625
28,554
DDI advice
2069
DDI int
1050
DDI effect
284
Adverse drug effect
4272
16,695
Drug disease
162
68
Total
9462
45,317

436
M. Saranya et al.
4.2
Comparison of Deep Learning Model
Bi-LSTM model produces the good result for all the datasets than the other deep
learning techniques.
4.3
SMOTE and k-means SMOTE
The proportion of positive and negative samples distinctly for drug-drug, drug-side
effect, and drug-disease is 1:5.7, 1:3.9, and 1:2.4, respectively. Approximately, posi-
tive and negative samples proportion in total is 1:4.8. The ratio between the drug-
disease relation and the drug-side effect relation is 1:26.3. The imbalance exhibits
in the datasets are eliminated by using different oversampling techniques called
SMOTE and k-means SMOTE. Though there are different varieties of SMOTE, k-
means SMOTE gives better result compared to it. Table 2 represents the performance
of different deep learning models on different datasets with and without sampling
techniques. Table 3 shows that every model is performing better when the dataset is
balanced using k-means SMOTE algorithm. Even though EU-ADR corpus is highly
imbalanced, it achieves better F-measure of 8.1% compared to other corpora.
Table 2 Performance of different deep learning techniques
Learning model
Corpora
Precision
Recall
F-measure
CNN
ADE
0.774
0.761
0.767
DDI DrugBank
0.764
0.752
0.758
DDI Medline
0.771
0.762
0.766
EU-ADR
0.759
0.714
0.736
LSTM
ADE
0.817
0.754
0.784
DDI DrugBank
0.807
0.761
0.783
DDI Medline
0.792
0.788
0.790
EU-ADR
0.781
0.731
0.755
Bi-LSTM
ADE
0.828
0.772
0.799
DDI DrugBank
0.825
0.784
0.804
DDI Medline
0.821
0.762
0.790
EU-ADR
0.804
0.763
0.783

Comparative Analysis of Different Deep Learning Techniques …
437
Table 3 Performance of SMOTE and k-means SMOTE
Learning models
Corpora
F-measure
(without balancing
F-measure (with
SMOTE
F-measure (with
k-means SMOTE
CNN
ADE
0.588
0.705
0.767
DDI DrugBank
0.608
0.676
0.758
DDI Medline
0.601
0.674
0.766
EU-ADR
0.579
0.622
0.736
LSTM
ADE
0.622
0.716
0.784
DDI DrugBank
0.629
0.763
0.783
DDI Medline
0.616
0.682
0.790
EU-ADR
0.597
0.665
0.755
Bi-LSTM
ADE
0.652
0.736
0.781
DDI DrugBank
0.621
0.712
0.784
DDI Medline
0.624
0.718
0.790
EU-ADR
0.616
0.702
0.783
5
Conclusion and Future Work
The initial step in the mining of the valuable information buried in the literature or
biomedical texts is the biomedical relation extraction which is very crucial and essen-
tial also. Each and every deep learning model has its own advantages for extracting
the relation. In this study, we compared different deep learning techniques wt the
hep different types of features. SDP attains more priority in extracting the relation
from literature with k-means SMOTE and cross-corpus training as well. With this
comparison, we found that the Bi-LSTM model has performed well compared to
other two methods due to its advantage. Our future idea is to develop the relation
extraction model for the inter-sentence as it is main limitation of the current work,
which is very challenging task.
References
1. Nagaraj, K., Sharvani, G. S., & Sridhar, A. (2018). Emerging trend of big data analytics in
bioinformatics: A literature review. International Journal of Bioinformatics Research and
Applications, 14(1–2), 144–205.
2. Qato, D. M., Wilder, J., Schumm, L. P., Gillet, V., & Alexander, G. C. (2016). Changes in
prescription and over-the-counter medication and dietary supplement use among older adults
in the United States, 2005 vs 2011. JAMA Internal Medicine, 176(4), 473–482.
3. Sutherland, J. J., Daly, T. M., Liu, X., Goldstein, K., Johnston, J. A., & Ryan, T. P. (2015).
Co-prescription trends in a large cohort of subjects predict substantial drug-drug interactions.
PLoS ONE, 10(3), e0118991.
4. Giardina, C., et al. (2018). Adverse drug reactions in hospitalized patients: Results of the
FORWARD (facilitation of reporting in hospital ward) study. Frontiers in Pharmacology, 9,
350.

438
M. Saranya et al.
5. Wishart, D., Djoumbou, Y., Guo, A. C., Lo, E., Marcu, A., Grant, J., Sajed, T., Johnson, D.,
Li, C., Sayeeda, Z., Assempour, N., Iynkkaran, I., Liu, Y., Maciejewski, A., Gale, N., Wilson,
A., Chin, L., Cummings, R., Le, D., & Wilson, M. (2017). DrugBank 5.0: A major update to
the DrugBank database for 2018. Nucleic Acids Research, 46.
6. https://www.wlv.ac.uk/lib/resources/databases-a-z/databases/stockleys-drug-interactions.php
7. Sharma, R. D., Tripathi, S., Sahu, S. K., Mittal, S., & Anand, A. (2016). Predicting online
doctor ratings from user reviews using convolutional neural networks. International Journal
of Machine Learning and Computing, 6(2), 149.
8. Chawla, N. V., Bowyer, K. W., Hall, L. O., & Kegelmeyer, W. P. (2002). SMOTE: Synthetic
minorityover-samplingtechnique.TheJournalofArtiﬁcialIntelligenceResearch,16,321–357.
9. Kumar, S. (2017). A survey of deep learning methods for relation extraction. arXiv:1705.036
45v1 [cs.CL].
10. Mintz, M., Bills, S., Snow, R., & Jurafsky, D. (2009). Distant supervision for relation extraction
without labeled data. In Proceedings of the joint conference of the 47th annual meeting of the
ACL and the 4th international joint conference on natural language processing of the AFNLP,
ACL (Vol. 2, pp. 1003–1011).
11. Liu, S., Tang, B., Chen, Q., & Wang, X. (2016). Drug-drug interaction extraction via
convolutional neural networks. Computational and Mathematical Methods in Medicine.
12. He, B., Guan, Y., & Dai, R. (2019). Classifying medical relations in clinical text via
convolutional neural networks. Artiﬁcial Intelligence in Medicine, 93, 43–49.
13. Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Distributed represen-
tations of words and phrases and their compositionality. In Advances in neural information
processing systems (pp. 3111–3119).
14. Habibi, M., Weber, L., Neves, M., Wiegandt, D. L., & Leser, U. (2017). Deep learning with word
embeddings improves biomedical named entity recognition. Bioinformatics, 33(14), i37–i48.
15. Ghannay, S., Favre, B., Esteve, Y., & Camelin, N. (2016). Word embedding evaluation and
combination. In: LREC (pp. 300–305).
16. Segura-Bedmar, I., Martínez, P., & Zazo, M. H. (2013). Semeval-2013 task 9: Extraction of drug
drug interactions from biomedical texts (ddiextraction 2013). In Second joint conference on
lexical and computational semantics (* SEM) (Vol. 2): Proceedings of the seventh international
workshop on semantic evaluation (SemEval 2013), (Vol. 2, pp. 341–350).
17. Gurulingappa, H., Rajput, A. M., Roberts, A., Fluck, J., Hofmann-Apitius, M., & Toldo, L.
(2012). Development of a benchmark corpus to support the automatic extraction of drug-related
adverse effects from medical case reports. Journal of Biomedical Informatics, 45(5), 885–892.
18. Zhang, Y., Lin, H., Yang, Z., Wang, J., Zhang, S., Sun, Y., & Yang, L. (2018). A Hybrid model
based on neural networks for biomedical relation extraction. Journal of Biomedical Informatics,
81, 83–92.
19. Last, F., Douzas, G., & Bacao, F. (2017). Oversampling for imbalanced LearningBased on
K-means and SMOTE. arXiv:1711.00837v2 [cs.LG]
20. Collobert, R., & Weston, J. (2008). A uniﬁed architecture for natural language processing: Deep
neural networks with multitask learning. In Proceedings of the 25th international conference
on Machine learning, ACM (pp. 160–167).
21. Van Mulligen, E. M., et al. (2012). The EU-ADR corpus: Annotated drugs, diseases, targets,
and their relationships. Journal of Biomedical Informatics, 45(5), 879–884.

Classiﬁcation of the Suicide-Related Text
Data Using Passive Aggressive Classiﬁer
B. V. Kiranmayee, Chalumuru Suresh, and S. SreeRakshak
Abstract As technological advancements have been increasing in day-to-day life,
most people are relying on Internet usage where they are using social media platforms
to convey their status through their respective proﬁles. As social media made a
big boom on the planet, most people use these applications to share their views
in many ways like text, images or videos, etc., with which a huge amount of data
gets generated. From the data related to their posts, it is been observed that most
people are not able to get rid of their mental stress. As the report of WHO (World
Health Organization) shows that suicides are the second-largest global pandemic,
our objective is to analyze the text within the suicide notes posted on Twitter (one
among the social media platforms). Text classiﬁcation is been done on the data, and
we have many machine learning algorithms, neural networks, regression techniques,
etc., Like the large stream of data is been generated to get better results, we use
passive aggressive classiﬁer (PAC) algorithm. Along with PAC, we use SVM, Naive
Bayes, random forest, and decision tree and have a comparative study. Since we
considered the labeled textual dataset, we apply the above models on the dataset and
classify and show the result as “Suicidal” or “Non-Suicidal.”
Keywords Text classiﬁcation · SVM · Random forest · Naïve Bayes · Decision
tree · Sklearn · Passive aggressive classiﬁer · Suicide-related
1
Introduction
According to the WHO (World Health Organization) statistics, every year close to
800 000 people take their own life, and also there are many more people who attempt
suicide. Attempting suicide will not only affect the individuals but also affects their
B. V. Kiranmayee · C. Suresh · S. SreeRakshak (B)
Computer Science Department, VNR VJIET, Hyderabad, India
B. V. Kiranmayee
e-mail: kiranmayee_bv@vnrvjiet.in
C. Suresh
e-mail: suresh_ch@vnrvjiet.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_34
439

440
B. V. Kiranmayee et al.
families and the society nearby. Many suicide cases are getting registered every year,
and according to the survey, the number is getting increased year by year. Of the
people who attempt suicide, most of them are of the age group of 15–29 years.
Suicide cases do not only occur in high-income countries, as a study done in 2016
over 79% of suicide cases are registered in middle and low-income countries.
In a study, it has been stated that most of the suicide cases are registered in
rural agricultural areas in low- and middle-income countries due to pesticide self-
poisoning, hanging, and ﬁrearms. We can have the option to stop this global pandemic
by having more awareness projects and need to make individuals think about the
situation what occurs after a suicide in any of the house and their people. Suicide
is considered as one of the top priorities by WHO. The ﬁrst WHO World Suicide
Report “Preventing suicide: a global imperative,” published in 2014, aims to increase
the awareness of suicide and suicide attempts. WHO also takes steps to reduce the
rate of suicide cases and to strengthening its member countries by taking necessary
policies. By 2020, WHO wanted to reduce the suicide rate by 10% which is been
considered in the act of Mental Health Action Plan 2013.
2
Literature Survey
Shivam et al. [1] mentioned in their work regarding text classiﬁcation on the suicide-
related textual dataset. Initially, we need to know how the text data is classiﬁed and
what are the steps to do to classify the textual data. We can ﬁnd that most of the text
classiﬁcation proceeds with the standard method of collecting dataset, preparation
of dataset, feature engineering, training the model using respective techniques, and
then ﬁnd different machine learning algorithms of certain classiﬁer techniques to
classify the data. Konstantina et al. [2] mentioned in his work as many machine
learning algorithms are used in classifying the data [2] it might be of any kind of
data like text, image, etc. Ismiguzel et al. [3] explain to us that the classiﬁcation of
text can be done using various techniques, and we can also apply logistic regression
[3]. After the dataset is prepared, logistic regression is been applied to the dataset,
but we cannot achieve highly accurate results which can result in false predictions
and false classiﬁcation of data. Emma et al. [4] show us in the recent day’s usage
of electronic gadgets rapidly increased which resulted in the generation of high data
like images, moving clips, textual, symbolic, etc., much text data is been generated
on social media platforms since we can have a sentimental data is generated highly
using the data [5, 6].
Text data plays a prominent role in sentimental analysis. Text categorization can
also be done using various machine learning algorithms like SVM. It is much harder
to achieve a sentimental analysis than the classiﬁcation. Li et al. [8] showed us
using the machine learning algorithms, multi-task learning [7, 8] can be done on the
dataset, so that we can have good results than using single algorithms with single
labeled or multi-labeled dataset. Meanwhile, Fabrizio et al. [9] speak about machine
learning that can also be used to automate [9] the process of classiﬁcation, so that no

Classiﬁcation of the Suicide-Related Text Data Using Passive …
441
manpower is required and get a good result in lesser time. This can be helpful when
we have a streamline of data that is generated continuously in no time. Jadzia et al.
[10] worked on a model named ID3 algorithm, and a new model is been developed
named PRISM algorithm which gives better results than the previous models and the
comparison of data is been done in this paper between 5 different models.
Theodore and Haddi [4, 14] paper shows us the comparison between machine
learning models and neural networks. Here, we can also see that neural networks
can also be used in text classiﬁcation. SVM, radial basis function (RBF), and back-
propagation techniques are used here, and these can also be applied in ﬁnancial
forecasting [4]. Xia et al. proposed a work using the granular computing [6] method
the text data can be split into small components named granules, and each granule
is been evaluated and generates a granule network where each granule is interlinked
with other and the required network is considered to get the result. As we have seen
many techniques and strategies are applied to achieve text classiﬁcation, we propose
a linear model named passive aggressive algorithm to get the results. We can learn
about our proposed model [13] in detail and with regular examples. We can also have
a detailed explanation of algorithms, and a video made by Lavrenko [14] helps us to
understand the concept easily.
3
Proposed System
Textual data is collected which is related to the suicide cases from Twitter into a single
dataset, and it is used to classify the data using different models. Many of the machine
learning algorithms and other classiﬁcation techniques are been used and achieved
good results. Many other techniques are also implemented for text classiﬁcation by
other authors like logistic regression, other machine learning classiﬁers like SVM,
random forest, Naïve Bayes, decision tree, and KNN classiﬁer. Neural networks can
also be used. But these models cannot give accurate results for the huge stream of
data.
To overcome the drawbacks of the existing models in the proposed system, we
have used the linear classiﬁer named “passive aggressive model” which gives us
more accurate results than the previously used models with better results and high
accuracy. A comparative study is been done with the other four different models
(multinomial Naïve Bayes, decision tree, support vector classiﬁer, and random forest)
in the proposed system off them passive aggressive model shows us the high accuracy
with better results. Classiﬁcation of the data is been using a Web application that
runs in the local server.
We have used the Django framework to run the application in the server, which
generates the link to run on local host in a Web browser. Here, our application works
if and only if the server is run in the background. As the classiﬁcation of the training
data is been done, the remaining data will be validated. Then, we can be able to
test the model by entering the text in the checkbox of the model page in the Web
application. New input to the model can also be given to the model other than the

442
B. V. Kiranmayee et al.
data in the dataset which is collected. Our model is the advanced techniques of the
neural network called perceptron classiﬁer which can classify the dataset and can
achieve better results.
In the proposed system, we have a dataset containing textual information gathered
from Twitter. From this platform, only the tweets related to suicide are collected.
Initially, after the dataset is collected, we need to preprocess the data to overcome
the issues like empty spaces and other pointers. Then, feature engineering is been
done like vectorization and transformation (all the data into a single structure). Now
we can see all the data in the same format with similar speciﬁcations, and then data
fragmentation is been done i.e., data is divided into training and testing along with
this some data is also separated for validation.
The model will be trained using the data which is been divided, then it gives the
result after the model is been trained, and the validation phase is been done where
we check the accuracy of the particular algorithm. Data left for the validation will be
given as input to the trained model, and then it validates the data and gives the result
and accuracy of the model. If we get good accuracy results, we can use the model
in real-time applications. From Fig. 1, we can see that the remaining 20% of testing
data is been done using some validated machine learning algorithms and compare
the results and the model with highly accurate results can be used.
Firstly, when the text data is collected from the social media platforms like Twitter,
we need to identify the text which is much related to the suicidal context. Our main
aim is to ﬁnd an elegant model which shows us highly accurate results by classifying
the text from social media. Though there are many models which are implemented,
we have implemented the model which gives better results than the existing models.
Fig. 1 Text classiﬁcation using passive aggressive classiﬁer

Classiﬁcation of the Suicide-Related Text Data Using Passive …
443
In the ﬁrst phase, the textual dataset is been collected which is the collection of the
Twitter data. After the dataset is collected, we have to check the dataset whether the
data is of suicidal context, and then, we need to upload the dataset to the model/system
where it is to be processed.
In the second phase, preprocessing of the collected data is been done by uploading
the dataset to the system before classiﬁcation, i.e., we have to clean the dataset into
a single format which makes the model process easily. Vectorization of the data is
to be done, and then, the entire dataset will be divided into three parts i.e., training,
testing, and validation. From the entire dataset, 70–80% of the dataset is divided
into training data by which the developed model is getting trained along with the
labels attached to it. After the training is been done, 5–10% is set into validation data,
i.e., here the trained model validates its process; in this phase, we can also ﬁnd the
accuracy of the model; in this phase, higher the accuracy, higher the testing result.
In the end, the remaining 15–20% of the data is testing data where we test the model
with this data and check the output with the expected result.
In the third phase, classiﬁcation of the data is been done after we preprocess
the data. We can use multiple classiﬁers or a single classiﬁer. If we have a single
classiﬁer, we will get only one result. If we have multiple classiﬁers, we have to
check the preprocessed data with the multiple models and can be able to verify the
accuracy of the models over the dataset.
In the fourth phase, after the classiﬁcation of the data is been done, we need to
check and analyze the result of the model which is been used. If we use multiple
models, we have to verify the results of each model separately and then consider the
model which gives us highly accurate results. And a graph analysis is also been done
between the models.
Passive Aggressive Algorithm: Passive aggressive algorithms are to some degree
like a perceptron model, as in they do not need a learning rate. Nonetheless, they do
incorporate a regularization boundary.
An awesome illustration of this is to distinguish counterfeit information on a
social media site like Twitter, where new information is being added each second.
To powerfully peruse information from Twitter consistently, the information would
be enormous, and utilizing an online-learning algorithm would be ideal (Fig. 2).
Algorithm
• Passive: If the prediction is correct, keep the model and do not make any changes,
i.e., the data in the example is not enough to cause any changes in the model.
If dTw > 1, then it is OK. Output classiﬁed is correct.
• Aggressive: If the prediction is incorrect, make changes to the model, i.e., some
change to the model may correct it.
If dTw < 1, then we have to classify it again using new weight (wnew). Output
classiﬁed is incorrect (Fig. 3)
dTw have Loss (L) short of y

444
B. V. Kiranmayee et al.
Fig. 2 Algorithm of passive aggressive classiﬁer [14]
Fig. 3 Passive aggressive classiﬁer
dTwnew = dT(w + yLd)
= dTw + yLdTd
= dTw + yL
= y
4
Experimental Results
The implemented system mainly focuses on achieving the best results and better
performance than the existing models. As text data is collected from the social media
platforms as a dataset. The text data in the dataset is preprocessed to classify the text

Classiﬁcation of the Suicide-Related Text Data Using Passive …
445
data. After preprocessing, the dataset is divided into training and testing where the
model will be trained along with the labels which we give in the dataset. After training
is done, the remaining data is validated to check the accuracy of the models. Hence,
we use ﬁve different models to the same dataset, and all the accuracies are stored
and compared. Our implemented model (passive aggressive classiﬁer) tests the data
and gives us results as suicidal text or non-suicidal text.
We have implemented the current system in a Windows environment with
mentioned software. Django framework to run the application on the server, Tinkter
is used to create user interface, sklearn library of python.
Detailed process to build the system:
1.
Collect the dataset which consists of the suicidal data.
2.
Start preprocessing of the data and vectorize it to a normal form.
3.
Divide the dataset into training, validation, and testing parts to apply a model
and train the model.
4.
Now all the models used are trained using the training data along with the labels
in the dataset.
5.
Then, the models get validated using the validation data and check the accuracy
of the model.
6.
After the validation is been done, we have to test the validated models to check
the results.
7.
Results are generated and compared with the labels in the dataset.
8.
The models with high accuracy give accurate results. Here, the proposed system
passive aggressive classiﬁer model generates high accuracy and accurate results.
Below we can see the homepage of our application where we can see the results
and accuracy of different algorithms by clicking on them. Also, we have a graph that
shows a bar graph of the accuracies of each algorithm used (Fig. 4).
Fig. 4 Application homepage

446
B. V. Kiranmayee et al.
Fig. 5 Enter the text data to test
When we select the passive aggressive algorithms, it shows a text box where we
can enter the text and check the result (Fig. 5).
Based on the classiﬁcation results, the text we added to the textbox is classiﬁed
as either a “suicide tweet” or “not a suicide tweet” (Fig. 6).
We estimated the results of the implemented model based on evaluation metrics
that were more popular known to calculate the accuracy of the machine learning
classiﬁcation problem.
We can see the accuracy of our proposed system and also the result generated by
testing the data (Fig. 7).
Estimated when we click on the graph on the homepage, it shows the bar graph
which includes algorithms used on X-axis and the accuracy on the Y-axis. A compar-
ative study is been done among the ﬁve algorithms that includes passive aggressive
classiﬁer, decision tree, random forest, Naïve Bayes, and SVM. We can see the graph
showing the accuracies of all the models (Fig. 8).
Fig. 6 Result

Classiﬁcation of the Suicide-Related Text Data Using Passive …
447
Fig. 7 Accuracy of passive aggressive classiﬁer
Accuracy
Algorithms
Fig. 8 Bar graph showing the accuracies
5
Conclusion
Our model can be used by the one who wants to know the category of the suicide-
related tweet or text which have been posted on the social media platform. In this
project, we have processed the dataset based on the labels given, and we can classify
the text data. We have used ﬁve algorithms in our application, and each algorithm
gave us different accuracy values by which we can state which algorithm produces
highly accurate results.
The implemented model generates results with high accuracy than the other algo-
rithms which we can see in the bar graph which is depicted. When compared with
other algorithms, our proposed model can generate a result with an accuracy of 95%.
As a result, using our proposed model when text input is given in the text ﬁeld, it
shows the related output and is able to classify our dataset. However, the implemented
model can classify the text data of the dataset.
References
1. Shivam (2018) What happen in text classiﬁcation. https://www.analyticsvidhya.com/blog/
2018/04/a-comprehensive-guide-to-understand-and-implement-text-classiﬁcation-in-python/

448
B. V. Kiranmayee et al.
2. Kourou, K., Exarchos, T. P., Exarchos, K. P., Karamouzis, M. V., & Fotiadis, D. I. (2015).
Machine learning applications in cancer prognosis and prediction. Computational and
Structural Biotechnology Journal, 13, 8–17. ISSN 2001-0370.
3. Apply text classiﬁcation using Logistic regression.https://medium.com/analytics-vidhya/app
lying-text-classiﬁcation-using-logistic-regression-a-comparison-between-bow-and-tf-idf-1f1
ed1b83640
4. Haddi, E., Liu, X., & Shi, Y. (2013) The role of text pre-processing in sentiment analysis.
Procedia Computer Science, 17, 26–32. ISSN 1877-0509.
5. Murphy, K. P. (2012). Machine learning a probabilistic perspective. A text book. The MIT
Press.
6. Zhang, X., Yin, Y., & Yu, H. (2007). An application on text classiﬁcation based on granular
computing. Communications of the IIMA, 7(2), Article 1.
7. Vasundhara, S., Kiranmayee, B. V., Suresh, C. (2019, May). Machine learning approach for
breast cancer prediction. International Journal of Recent Technology and Engineering (IJRTE),
8(1).
8. Liu, H., Cocea, M., & Ding, W. (2018). Multi-task learning for intelligent data processing in
granular computing context. Granular Computing, 3, 257–273.
9. Sebastiani, F. (2002, March). Machine learning in automated text categorization. ACM
Computing Surveys, 34(1), 1–47.
10. Cendrowska,J.(1987).PRISM:Analgorithmforinducingmodularrules.InternationalJournal
of Man-Machine Studies, 27(4), 349–370. ISSN 0020-7373.
11. Murphy, K. P. (2012). Machine learning: a probabilistic perspective. Murphy, K. P. p. cm.—
(Adaptive computation and machine learning series) Includes bibliographical references and
index. ISBN 978-0-262-01802-9 (hardcover: alk. paper) 1. Machine learning. 2. Probabilities.
I. Title. Q325.5.M87 2012 006.3’1—dc23 2012004558.
12. Kolli, K., & Suresh, C. (2018). Prototype for analytic procedures in bio-ınformatics data
evaluation. International Journal of Pure and Applied Mathematics, 118(20), 839–851.
13. Liu,H.,Cocea,M.,Mohasseb,A.,&Bader,M.(2017).Transformationofdiscriminative single-
task classiﬁcation into generative multi-task classiﬁcation in machine learning context. In 9th
International Conference on Advanced Computational Intelligence, ICACI 2017 (pp. 66–73).
14. What actually happen in PAC algorithm. https://www.youtube.com/watch?v=TJU8Nf
DdqNQ&t=3s
15. Ince, H., & Trafalis, T., Trafalis, T. (2008). Short term forecasting with support vector machines
and application to stock price prediction. International Journal of General Systems, 37(6),
677–687. https://doi.org/10.1080/03081070601068595
16. Liu, Y., Bi, J.-W., & Fan, Z.-P. (2017). Multi-class sentiment classiﬁcation: The experi-
mental comparisons of feature selection and machine learning algorithms. Expert Systems
With Applications, 80. https://doi.org/10.1016/j.eswa.2017.03.042.
17. Suresh, C., Kamakshaiah, K., Thatavarti, S., Kumar, P. S., & Ramasubbareddy, S. (2019,
November). Accurate and tımely predıctıon of rıce crop dısease by means of machıne learnıng
algorıthms. International Journal of Advanced Science and Technology, 28(13), 662–671.
18. Bhavana, A. K., Suresh, C., Kiranmayee, B. V., & Kumar, K. S. (2020, February). Prediction
of epidemic outbreaks in speciﬁc region using machine learning. International Journal of
Innovative Technology and Exploring Engineering (IJITEE), 9(4).
19. Suresh, C., Ravikanth, M., Srivani, B., & Satish, T. (2021). Cognitive IoT-based smart
ﬁtness diagnosis and recommendation system using a three-dimensional CNN with hier-
archical particle swarm optimization. Print ISBN: 978-3-030-52623-8, Electronic ISBN:
978-3-030-52624-5, Copyright Year: 2021.
20. Begum, S., Satish, T., Suresh, C., Bhavani, T. & Ramasubbareddy, S. (2021). Predicting type
of lung cancer by using K-MLR algorithm. https://doi.org/10.1007/978-981-15-5400-1_39
21. Maneesha, A., Suresh, C., & Kiranmayee, B. V. (2021). Prediction of rice plant diseases based
on soil and weather conditions. In C. K. Mai, B. V. Kiranmayee, M. N. Favorskaya, S. C.
Satapathy, K. S. Raju (Eds.), Proceedings of international conference on advances in computer
engineering and communication systems learning and analytics in intelligent systems (Vol. 20).
Springer, Singapore.

Classiﬁcation of the Suicide-Related Text Data Using Passive …
449
22. Suresh, C., Chandrakiran, C., Prashanth, K., Sagar, K. V., & Priyanka, K. (2020). “Mobile
medical card”—An android application for medical data maintenance. In 2020 Second Interna-
tional Conference on Inventive Research in Computing Applications (ICIRCA) (pp. 143–149).
Coimbatore, India, 2020. https://doi.org/10.1109/ICIRCA48905.2020.9183307
23. Suresh, C., Kiranmayee, B. V., Mujahed, S., Kanth, K., & Ramesh, R. (2019). Image processing
based on emotive and perfomance mangement system, 431–435. https://doi.org/10.1109/
ICECA.2019.8821932

Covid-19 Data Analysis to Predict
the Level of Hospitalization
Advet Jadhav, Maheshwari Satpute, Utkarsh Rai, Apeksha Wadibhasme,
and Usha Verma
Abstract The spread of Coronavirus has resulted in a global pandemic. It has caused
a heavy burden on medical facilities world over. The analysis of Covid-19 data
presented in the paper may help the medical experts to categorize the patient into
four levels of hospitalization based on their age, symptoms, and any previous medical
history. Different prediction analysis algorithms are implemented, and results are
presented to verify the accuracy of the implemented methods. Naive Bayes algorithm
is found useful to categorize the patients with highest accuracy and R square score. Its
results are compared with some of the traditional machine learning techniques such
as K-nearest neighbor algorithm (KNN), random forest algorithm, support vector
machine (SVM). Along with accuracy, the dataset is trained and tested with different
proportionate 60–40, 70–30, 80–20, and 90–10. The highest accuracy achieved is
95% and R square score as 94% with 80–20 ratio of training and testing dataset. The
end result reveals that the presented algorithm is an accurate machine learning model
to predict the level of hospitalization for the infected patient. A Web page is also
designed to give access to common people, so that the dependency on other agencies
and delaying the progress of the diagnosis can be reduced.
Keywords Covid-19 · Data analysis · Naive Bayes algorithm · K-nearest neighbor
algorithm · Random forest algorithm · Support vector machine · Machine learning
A. Jadhav (B) · M. Satpute · A. Wadibhasme · U. Verma
School of Electrical Engineering, MIT Academy of Engineering, Pune, India
e-mail: advetjadhav@mitaoe.ac.in
M. Satpute
e-mail: mgsatpute@mitaoe.ac.in
A. Wadibhasme
e-mail: avwadibhasme@mitaoe.ac.in
U. Verma
e-mail: uyverma@etx.maepune.ac.in
U. Rai
School of Computer Engineering & Technology, MIT Academy of Engineering, Pune, India
e-mail: urrai@mitaoe.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_35
451

452
A. Jadhav et al.
1
Introduction
Covid-19 is an infectious disease which was reported ﬁrst in Wuhan city, Hubei
Provinces of China. SARS Coronavirus-2 has never been identiﬁed in people as it
is a new virus family. The virus is transmitted through small respiratory drops by
coughing or when people interact with each other in closeness [1].
The deaths due to Covid-19 may also be due to other complications. Tracking
total death toll can provide information [2] if an excess number of deaths are being
recorded even when Covid-19 mortality may be not counted properly. The detection
of Coronavirus disease remains a huge challenge. As of March 12, 2021 the Covid-19
pandemic has 1,13,08,646 conﬁrmed cases with around 1,58,343 conﬁrmed deceased
in India [3]. Various danger factors of disease progression requiring hospitalization
have been taken into account, but medical decision-making remains challenge [3].
In order to analyze the Covid-19 data, data analysis techniques shall be used.
One of such techniques is machine learning. Machine learning allows computers to
learn themselves without human intervention [4]. There are mainly two categories
of ML: Supervised and unsupervised. Supervised ML technique is designed to learn
from examples. The machine will predict output based on the previous experience,
whereas unsupervised machine learning allows the model to work on its own to
predict the results [5].
In this paper, an analysis of Covid-19 data of patients is presented using Naïve
Bayes ML algorithm which further classiﬁes the patients into the four levels of
hospitalization based on their symptoms, age, and medical history. It will further
help to predict the level of hospitalization, and the medical resources can be utilized
in effective way for those who are critical patients. Webpage is created for the use of
doctors and patient. In this webpage, patients have to input their age, medical history,
and symptoms, so they can result of their infection with accuracy.
2
Literature Review
Several researchers have been adding to the areas of forecasting of current pandemic
situation. But less are working for analysis of their symptoms or medical history.
Remuzzi A. and Remuzzi G. have discussed the severe impact that causes Coron-
avirus and its rapid spread in Italy [6]. A predictive model was built to understand
the patient’s case better, and this may further help the medical institutions to take
better decisions.
Hall I. et al. also studied about the inﬂuenza virus called H5N1 which was seen in
birds and has predicted the use of regression analysis during this time of pandemic. In
similar study, scientists have validated different models to predict the spread of cases
in Hubei Province [7]. The data used here is from National Health Commission of
China to view predictions for every ﬁve days from day one up to ﬁfteenth day. Their

Covid-19 Data Analysis to Predict the Level of Hospitalization
453
model has shown that the containment procedures being used in China are bringing
down the spread of virus, and the pandemic has decreased a bit.
Furqan Rustam et al. have developed a model using supervised machine learning
for future forecasting of Covid-19 cases. They are predicting the number of future
patients affected by Covid-19. The forecasting is done based on the number of
recently infected cases [8], number of demises, and recoveries. Learning models
such as LR, SVM, ES, and LASSO have been used for the forecasting. On the other
side, Bastos et al. have developed a prediction model using South American data
from the dates of February 25–March 30, 2020. It was built around parameter of
social distancing. The results indicate that social distancing will reduce the spread of
infection [9]. However, if social distancing is not implemented properly, the infection
spread will start gain.
Akib Mohi Ud Din Khanday et al. have proposed a model for the prediction of
Covid-19 cases. The prediction is done based on the age, gender, death rate hospital-
ization, and symptoms of patients [10]. The regression approaches for analysis are
trained and tested on real time data using the data given for the corresponding.
Another model is implemented by Dehning et al. which is Bayesian inference
with epidemiological parameters to observe the time dependency of the increase of
new contagious infection of Covid-19 in Germany [11]. Authors have claimed that
the model is fully functional and can be adapted by any region in the world.
Liu et al. have presented a new method that takes into account the estimation of
decease from mechanical models along with traces of machine learning algorithms
to forecast spread of Covid-19 in the various regions of China [12].
Based on aforementioned literature, it is seen that there are multitude methods
to predict the spread of Covid-19. Most of the work is in the area of predicting the
number of cases, and fewer researchers have focused on development of machine
learning algorithms for other aspects of Covid-19 pandemic like hospitalization level
and optimize the use of medical resources. Here in this paper, a data analysis using
machine learning algorithm ‘Naïve Bayes’ is presented based on other factors which
furtherclassifythepatientsinthefourcategoriesofhospitalizationwiththemaximum
accuracy. Some of the limitations of the above-mentioned models are their model is
not forecasting the spread considering the age groups they should specify that which
age group will be more infected. Another drawback is that their model is not that
much accurate due to less amount of data.
3
Machine Learning Algorithm
In the proposed work, different machine learning classiﬁcation algorithms are
implemented to compare the results of Naïve Bayes algorithm. They are:
Supportvectormachine.Thisalgorithmisasupervisedalgorithmwhichusesclassi-
ﬁcation techniques. SVM divides data into different classes by creating a hyperplane,
and support vectors are the data points which are nearest to the hyperplane [13].

454
A. Jadhav et al.
Decision tree. It is a graphical representation for getting all possible decision based
on given problem. Decision tree consists of two nodes: decision node and leaf node.
Decision nodes are used in making decision and have multiple number of branches,
whereas leaf nodes are the output nodes of those decision nodes [13].
K-nearest neighbor (KNN). KNN algorithm is a supervised ML algorithm which
we can use for both regression and classiﬁcation. It considers the similarity in new
case and the available case and places the new case in the class which is most similar
in the available cases. All the available data is stored by the algorithm. Based on the
similarity, a new data point is classiﬁed [4].
Naive Bayes classiﬁcation. It is a classiﬁcation algorithm for two or more classes. It
is basedonBayes theoremwiththenaiveassumptionthat thefeatures areindependent
of each other. For understating of the use of Bayes theorem in our work, let us take
a feature vector.
X = (x1, x2, x3, . . . , xn) and a class variable C k in our model, we have 15 feature
vectors so, n = 15, and we have 4 classes so, k = 4. Using the Bayes Theorem, the
probability of class C occurring can be calculated by (1) as
P(Ck|X) = P(X|Ck)P(Ck)
(1)
where P(C|X) denotes posterior probability of class C for given predictor (features),
P(X|C) denotes likelihood of the data X given C, P(C) denotes probability of class
C, and P(X) represents prior probability of predictor.
In Naïve Bayes classiﬁer, the likelihood is calculated as in (2).
P{(X|Ck)} = P(x1 . . . , xn|Ck)
= P(x1|x2 . . . , xn, Ck) . . . P(xn−1|xn, Ck)P(xn|Ck)
(2)
In Naïve Bayes classiﬁer, the posterior probability is calculated as in (3).
P(Ck|X) = P(X|Ck)P(Ck)
P(X)
(3)
By conditional independence, we have (4)
P(C|x1, . . . , xn) = P(x1|C)P(x2|C) . . . P(xn|C)P(C)
P(x1)P(x2) . . . P(xn)
(4)
which can also be expressed as shown in (5)
P(C|x1, . . . , xn) =
P(C)n
i=1P(xi|C)
P(x1)P(x2) . . . P(xn)
(5)
and the joint model can be expressed as in (6)

Covid-19 Data Analysis to Predict the Level of Hospitalization
455
P(C|x1, . . . , xn)αP(C)n
i=1P(xi|C)
(6)
where α represents proportionality.
In this work, probability is calculated for all four classes by considering all input
parameters. So, the class with highest probability will be the outcome.
As compared to other methods, Naïve Bayes does not require much training data,
and it is highly scalable. Three main types of Naive Bayes classiﬁer is Gaussian,
multinomial, and Bernoulli. Naive Bayes follows normal distribution and it supports
continuous data. Bernoulli Naive Bayes is used for discrete data, and it works on
Bernoulli distribution. Multinomial Naive Bayes is also suitable for the classiﬁca-
tion with discrete features. In this work, we have used multinomial Naive Bayes
because it is used for classiﬁcation with discrete features. As compared to Bernoulli
Naive Bayes, multinomial Naive Bayes is easier technique when we have binary or
categorical inputs in the dataset [14].
4
Methodology
This algorithm works quickly and can save a lot of time. Naive Bayes is suitable
for solving multiclass prediction problems. If its assumption of the independence
of features holds true, it can perform better than other models and requires much
less training data. Naive Bayes is better suited for categorical input variables. We
have used Naive Bayes because due to its assumption of independence and high
performance in solving multiclass problems [15].
The proposed work consists of ﬁve modules. First module is data collection,
whereas second is reﬁning of data. Both are equally important as without the proper
data collection and correct extraction of the required data, no algorithm can give
good results. In next module of classiﬁcation, the Naïve Bayes algorithm is used, and
its results are compared with the other traditional techniques of ML. Performance
analysis is presented in the fourth module with different proportion of Training–
Testing dataset. In last module webpage is created for user interface with algorithm.
4.1
Covid-19 Data Analysis Model Using Naïve Bayes
The complete model of Covid-19 data analysis based on Naïve Bayes machine
learning algorithm to predict the level of hospitalization is presented in Fig. 1.

456
A. Jadhav et al.
Positive 
Negative 
Data Collection
Data Refining-
1. Age of patient
2. Symptoms
3. Medical History
Naïve Bayes Classifier
Covid-19
Status
i.
Home Quarantine
ii.
Hospitalization
iii. Hospitalization with 
oxygen Support
Home Quarantine
Fig. 1 Covid-19 data analysis model for categorization of hospitalization levels
4.1.1
Module 1—Data Collection
A dummy dataset of patients is created, regardless of age, who had tested positive
and negative for Covid-19. This included all Covid patients whether they were hospi-
talized or not. In this dataset, the previous medical history and symptoms of patients
are included based on which the proposed model works.
4.1.2
Module 2—Data Reﬁning
The data reﬁning is done manually on the dataset. After reﬁning, the input parameters
consist of 15 attributes namely age, medical history, headache, muscle pains, loss of
smell, cough, chest pain, sore throat, fever, hoarseness, diarrhea, shortness of breath,
fatigue, and abdominal pain. Four main diseases which are heart disease, diabetes,
respiratory disease, and blood pressure are considered in medical history which can
affect the health of patient suffering from Covid. Patients are divided into ﬁve groups
of age which are: below 15, between 15 and 30, between 30 and 45, between 45 and
60, and above 60. The patients were classiﬁed into four classes: negative but home
quarantine, positive and home quarantine, positive and hospitalization, and positive
and hospitalization with no oxygen support.

Covid-19 Data Analysis to Predict the Level of Hospitalization
457
4.1.3
Module 3—Classiﬁcation
Naïve Bayes algorithm is used for classiﬁcation purpose. The algorithm is imple-
mented to classify the patients into four levels of hospitalization. The four level of
hospitalization are negative but home quarantine, positive but home quarantine, posi-
tive and hospitalization, and positive and hospitalization with oxygen support. The
same dataset is also classiﬁed using other traditional ML algorithms to validate the
accuracy of Naïve Bayes algorithm. They are: K-nearest neighbor (KNN), support
vector machine (SVM), and random forest. After comparing, it is found that Naïve
Bayes is giving highest accuracy.
4.1.4
Module 4—Performance Analysis
The ﬁrst performance measure used is Accuracy. To calculate the accuracy, ﬁrst
confusion matrix is determined. This matrix compares the actual values with the
values which are predicted by the model. This analysis is carried out with different
combination of training and testing data to get to know with which the highest
accuracy is achieved. Training data is utilized to train the model, and testing data
is used to test the model whether it works correctly [4]. The performance of Naïve
Bayes algorithm is compared along with different classiﬁcation algorithms. The
Naïve Bayes algorithm provides greater accuracy.
The second performance measure used is R squared score. It is the proportion of
variance of the dependent variable which is predictable from independent variables.
To calculate the R2, the average actual values are subtracted from each actual values
after that the results are squared, and the results are added. After that, the ﬁrst sum
of errors is divided by the second sum, and the results are subtracted from one.
The performance of Naïve Bayes algorithm is compared with different classiﬁcation
algorithms. The Naïve Bayes algorithm provides greater R2. This can be expressed
as shown in (7):
R2 = Variance of model
Total Variance
(7)
4.1.5
Model 5—Webpage Design
After the completion of machine learning model, webpage is created. ‘ﬂask’ tool is
used for integrating our machine model to Web application. Further it is rendered
to the html template to ﬂask, so that it will allow users to input parameters and get
accurate result of their level of hospitalization.

458
A. Jadhav et al.
4.2
Algorithm
The ﬂow of the model is presented by the following algorithm:
Step 1—Import libraries. The Libraries which are used include pandas, numpy,
matplotlib.pyplot, seaborn, sklearn.metrics.
Step 2—Read the dataset.
Step 3—Create the frequency table for each input parameter. 15 input parameters
were taken.
Step 4—Calculate the count of each class for each input parameter.
Step 5—Factorize the data to convert it into numerical form.
Step 6—Split the data into training and testing ratio. Training—80% and testing
20%.
Step 7—Apply Naïve Bayes algorithm to calculate the probability of each class
using the (2).
Step 8—Calculate the confusion matrix by using testing samples.
Step 9—Calculate the accuracy of the model by using confusion matrix.
5
Implementation and Results
5.1
System Speciﬁcation and Dataset
The system used for implementation has the conﬁguration of 8 GB RAM with 2.3
GHZ processors. Jupyter notebook software and Scikit learning tool is used for
performing the classiﬁcation of patients into four different levels. The dataset of
100 patients is used, in which input parameters are age, symptoms, and previous
medical history of patients [16]. Out of 100 patients, there were 14 patients having
age between 0 and 15, 16 patients having age between 15 and 30, 18 patients having
age between 30 and 45, 20 patients having age between 45 and 60, and 32 patients
having age above 60. Figure 2 represents patients in different age groups having
different diseases. It can be observed that most of the patients with age above 60
are having the medical history of disease like diabetes, heart, respiratory, and blood
pressure. Therefore, there may be more probability to hospitalize these patients.
5.2
Results and Discussion
Depending on the said input parameters, the outcome of Naive Bayes algorithm into
the four classes of hospitalization is based on the highest probability among four. The
four levels are negative, positive but home quarantine, positive and hospitalization,
andpositiveandhospitalizationwithoxygensupport.Figure3showsthe%ofpatients
having different level of hospitalization.

Covid-19 Data Analysis to Predict the Level of Hospitalization
459
Fig. 2 Number of patients having different diseases
Fig. 3 Categorization of
patients into 4 levels
Out of 100 patients, 15 patients were negative, 24 patients were positive and
home quarantined, 21 patients were positive and hospitalized, and 40 patients were
positive and hospitalized with oxygen support. The symptoms which are considered
include headache, muscle pains, loss of smell, cough, chest pain, sore throat, fever,
hoarseness, diarrhea, shortness of breath, fatigue, and abdominal pain.
5.3
Performance Analysis
The proposed work evaluated based on two parameter—accuracy and r squared score.
As Naive Bayes algorithm is based on probability, a case of patient is explained here
for more clarity.
Probability calculation—To show the calculation of probability, a case one patient
is considered who is having following symptoms and diseases:
Age is above 50, medical history is having heart disease, symptoms having
headache, cough, loss of smell, sore throat, fever, chest pain, shortness of breath,

460
A. Jadhav et al.
and abdominal pain. The probability for all four classes in this case is calculated
using Eq. (1).
P (Negative) = 0.02
P(Positive Home quarantine) = 0.04
P(Positive Hospitalization) = 0.13
P(Hospitalization with Oxygen Support) = 0.82
Hence, the patient is positive and needs hospitalization with oxygen support.
Accuracy (%)
The dataset is split into training 80% and testing 20% ratio. The dataset of 100
patients is taken, and out of them 80 samples are trained, and 20 samples are tested.
Out of the 20 samples, 19 sample were tested correctly.
To calculate the accuracy, the confusion matrix is obtained as presented in Table
1. Accuracy is calculated as:
= (Sum of diagonal elements/Total no. of samples) ∗100
= ((1 + 9 + 4 + 5)/20) ∗100 = 95%
The accuracy of the model using Naïve Bayes algorithm is 95% for 80–20 ratio
of training and testing data.
The classiﬁcation outcome of Naïve Bayes algorithm is compared with other ML
algorithm by performing training, testing, and classifying the same dataset which is
used for Naïve Bayes. The initial dataset is separated into training and testing subsets
which reduces the possibility of overﬁtting. All the algorithms are implemented with
four different proportions of training and testing sets which are 80–20, 70–30, and
60–40. Table 2 provides a comparative analysis of accuracy of all the classiﬁcation
machine learning methods which are used for performing this task with different
training and testing set. Figure 4 shows the comparison of classiﬁcation algorithm
accuracy rate with respect to training and testing ratio taken.
It can be depicted from both Table 2 and Fig. 4 that Naive Bayes algorithm gives
best result as compared to all other algorithms by giving 95% accuracy when training
and testing dataset is in the ratio of 80:20. Support vector machine has also given
better results by giving 90% accuracy, but we have not chosen SVM because it will
Table 1 Confusıon matrıx of testing data
N HQ Hos
P HQ
P
P Hos Os
N HQ
1
2
0
1
P HQ
0
9
0
0
P Hos
0
0
4
0
Pos Os
0
0
3
3

Covid-19 Data Analysis to Predict the Level of Hospitalization
461
Table 2 Comparative analysis for different proportion of training and testing dataset
Machine learning algorithm
Accuracy with different training and testing ratio
90–10 (%)
80–20 (%)
70–30 (%)
60–40 (%)
Naive Bayes
80
95
92
89
Decision tree
75
85
80
78
K-nearest neighbors
77
88
85
80
Support vector machine
75
90
88
80
Fig. 4 Accuracy analysis with different training and testing ratio
underperform in some cases where the count of features for each data point is greater
than the count of training data samples.
In the ﬁrst stage, 60% of the data is used for training, but it showed less accuracy
in comparison with the case where 80% of the data is used for training. Therefore,
when more proportion of data is provided to train these algorithms, the chances
of enhancement in the performance of these algorithms are increased. As there are
many challenges in facing the deadly virus, this work can help the community to
know the severity of disease by identifying the level of hospitalization and take
actions accordingly.
R square score
It can be depicted from Table 3 that Naive Bayes algorithm gives best result as
compared to all other algorithms by giving 94.8 value of R2 score with 80:20 ratio
of training and testing dataset.
Therefore, when more proportion of data is provided to train these algorithms,
the chances of enhancement in the performance of these algorithms are increased.
In terms of both accuracy and r square of score and as there are many challenges in
facing the deadly virus, this work can help the community to know the severity of
disease by identifying the level of hospitalization and take actions accordingly.

462
A. Jadhav et al.
Table 3 Comparative analysis for different proportion of training and testing dataset
Machine learning algorithm
R2 with different training and testing ratio
90–10
80–20
70–30
60–40
Naive Bayes
90
94.8
91
85.8
Decision tree
73.4
83.2
78.2
76.4
K-nearest neighbors
75.2
85.4
80.2
78.5
Support vector machine
73.6
88.3
85.6
79.4
Fig. 5 Webpage user interface a one case of patient with various input, b result of level of
hospitalization
5.4
Webpage Design for User Interface
The webpage which we have created is shown in Fig. 5. In that we are taking the inputs
from the users. The user have to insert their age, medical history, and symptoms, and
after pressing the check button, their level of hospitalization will be displayed on the
screen.
6
Conclusion
Initially, when Covid-19 virus was identiﬁed and its severity was understood, the
medical society was having major role in treating the huge number of patients as the
rate of spread of virus was very high. To optimize the use of medical resources, it
is advisable to refer those patients who are having minor symptoms and no medical

Covid-19 Data Analysis to Predict the Level of Hospitalization
463
history, can be home quarantine. The proposed work is the one step in this direction
to use the medical resources effectively. The developed Web site will help the users
to check their level of hospitalization and take further actions.
The analysis presented in this paper concludes toward the best results in terms of
accuracy and R2 score using Naive Bayes algorithm as compared to other machine
learning algorithm. Also the best training to testing ratio is found to be 80:20 in all
cases. As common people are able to access our Web site and get results rather than
depending on other agencies and delaying the progress of the diagnosis. Time is of
essence in solving the Covid problem once infected. Further, the performance of this
model can be improved by increasing the volume of data used. Also, depending of
the symptoms for those who are classiﬁed for hospitalization, further work may be
proposed to predict the drugs to treat the patients.
Acknowledgements It gives an immense pleasure to acknowledge the support provided by the
institute MIT Academy of Engineering for implementation for the proposed work.
References
1. D, L. (2021, March 14). Coronavirus disease 2019. Retrieved from www.wikipedia.org: https://
en.wikipedia.org/wiki/COVID-19
2. Rabbat, P. D. (n.d.). Coronavirus disease (COVID-19) pandemic. Retrieved from www.
who.com: https://www.who.int/emergencies/diseases/novel-coronavirus-2019/who-director-
general-s-special-envoys-on-covid-19-preparedness-and-response
3. Research., M. F. (n.d.). Our Covid-19 patients and visiter guidline,and trusted health details.
Retrieved from https://www.mayoclinic.org: https://www.mayoclinic.org/diseases-conditions
4. Srivastava, A., Saini, S., & Gupta, D. (2019). Comparison of various machine learning tech-
niques and ıts uses in different ﬁelds. In 2019 3rd International conference on electronics,
communication and aerospace technology (ICECA) (pp. 81–86). Coimbatore, India.
5. Hesiodus. (2020, December 12). Supervised and unsupervised learning. www.geeksforgeek
s.org. [Online]. Reterived from https://www.geeksforgeeks.org/supervised-unsupervised-lea
rning/
6. Remuzzi,A.,&Remuzzi,G.(2020).COVID-19,andItaly:Whatnext?TheLancet,395(10231),
1225–1228.
7. Hall, I., Gani, R., Hughes, H., & Leach, S. (2007). Real-time epidemic forecasting for pandemic
inﬂuenza. Epidemiology and Infection, 135(3), 372–385. https://doi.org/10.1017/S09502688
06007084
8. Rustam, F., Reshi, A. A., Mehmood, A., Ullah, S., On, B. W., Aslam, W., & Choi, G. S. (2020).
COVID-19 future forecasting using supervised machine learning models.
9. Bastos, S. B., & Cajueiro, D. O. (2020). Modeling and forecasting the Covid-19 pandemic in
Brazil. arXiv preprint arXiv:2003.14288
10. Khanday, A. M. U. D., Rabani, S. T., Khan, Q. R., Rouf1, N., & Din, M. M. U. (2020). Machine
learning based approaches for detecting COVID-19 using clinical text data. International
Journal of Information and Technology.
11. Dehning, J., Zierenberg, J., Spitzner, F. P., Wibral, M., Neto, J. P., Wilczek, M., & Priesemann,
V. (2020). Inferring COVID-19 spreading rates and potential change points for case number
forecasts. arXiv preprint arXiv:2004.01105

464
A. Jadhav et al.
12. Liu, D., Clemente, L., Poirier, C., Ding, X., Chinazzi, M., Davis, J. T., Vespignani, A., &
Santillana, M. (2020). A machine learning methodology for real-time forecasting of the 2019-
2020 COVID-19 outbreak using Internet searches, news alerts, and estimates from mechanistic
models. arXiv preprint arXiv:2004.04019
13. Shafri, H. Z. M., & Ramle, F. S. H (2009). A comparison of support vector machine and
decision tree classiﬁcations using satellite data of Langkawi Island. www.scialert.net, [Online].
Reterived from https://scialert.net/fulltext/?doi=itj.2009.64.70
14. Qin, Z. (2006). Naive Bayes classiﬁcation given probability estimation trees. In 2006 5th Inter-
national conference on machine learning and applications (ICMLA’06) (pp. 34–42). Orlando,
FL.
15. Roosa, K., Lee, Y., Luo, R., Kirpich, A., Rothenberg, R., Hyman, J. M., Yan, P., & Chowell, G.
(2020). Real-time forecasts of the COVID-19 epidemic in China from February 5th to February
24th. Infectious Disease Modelling, 5, 256–263.
16. Perc, M., Gorišek Miksi´c, N., Slavinec, M., & Stožer, A. (2020). Forecasting COVID-19.
Frontiers in Physics, 8(127), 1–5.

Analysis the Accuracy of Rice Grains
Quality Using Neural Networks
S. Menaka and K. Sashi Rekha
Abstract Rice is the real sustenance source in southern India. It is the staple food
for more than 80% of population around the globe. Many styles of paddy crop
are cultivated and exported. Detecting the defected grains and distinguishing rice
variety are essential in rice ﬁne analysis. An automated machine can be used for
identifying rice grain type, and digital imaging is identiﬁed as a sustainable method
to abstract the capabilities from rice grains in a contact-free manner. Image pre-
processing techniques, ﬁltering, segmentation and aspect detection are performed on
the acquired image. The morphological capabilities, which might be extracted from
the image, are in the form of light-emitting diode (LED) display by using machine
learning technique. In neural network through the texture, size and colour of the rice
grains, the image will be processed, the outcome was compared with the existing
multilayer perceptron (MLP) and support vector machine (SVM), and a matching
pattern is used along with extracted images to produce the high accuracy and high-
quality rice grain. The proposed backpropagation algorithm using feedforward neural
network approach appears to have better accuracy of about 98.4% when compared
with SVM, which have 92% accuracy for analysing the rice grain quality.
Keywords Neural network · Multilayer perception · Feedforward NN · Machine
vision device · Radial basis features · Backpropagation
1
Introduction
One of the most signiﬁcant functions in device perception is analysing high-quality
rice. Some researchers believe that an object’s shape contains more information than
its features, resulting in a bigger colouring difference between related items. It cannot
S. Menaka
Department of Computer Science and Engineering, SRM Institute of Science and Technology,
Ramapuram, Chennai, India
K. S. Rekha (B)
Department of Computer Science and Engineering, Saveetha School of Engineering, Saveetha
Institute of Medical and Technical Sciences, Chennai, India
e-mail: sashirekhak.sse@saveetha.com
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_36
465

466
S. Menaka and K. S. Rekha
guarantee a ﬂawless result. However, it can discover problems with rice consistency,
such as the rice veracity technique, which affects rice seed samples. The foremost
purpose of this method is to propose a new for managing adequate rice and to analyse
the ﬁne rice quality, which could moderate the desired effort, value and time. The
rice quality plays a crucial role within the production of agronomic and horticultural
crops, and so the identiﬁcation of the rice type plays a vital role. Image processing
is an enormous and superior technological location, where crucial trends have been
made in the lives of farmers.
2
Literature Survey
For the estimation and categorization of rice grains, it is completely relied upon the
two bodily and organic properties. The ﬁrst-rate valuation is executed by locating
the boundary and length factors through its measures. The average fee capabilities
are also taken into consideration, and they are implemented in MATLAB.
(1)
The image processing algorithm was implemented over the sample grains
through MATLAB. The class of the ﬁrst rate of rice grain is totally built based
on its colour, shape and size [1]. The accuracy and end result are divided into
good, awful and medium by using neural network classiﬁers.
(2)
An automated technique is used for ﬁguring out special form of rice seeds by
using system vision and detection machine, which includes inspector system
and an image processing unit. A backpropagation neural network was used to
satisfactorily identify the rice seed. This device has become sufﬁcient to offer
an inspection on rice seeds, which is primarily based on the look trends of
seeds.
(3)
The exceptional evaluation and the rice seed quality were analysed through
the naked eye. They also recognized the diverse varieties. In the current years,
effort has also been made to broaden machine vision [1] system (MVS) for
business application, which has been increased substantially and attributable
to the availability of the low-fee electronic contraptions and processing hard-
ware. The advancement in PC technologies using digital image processing
applications has showed the way for reading the exceptional of food material.
Rice is considered as the foremost crop for the growing country. The employ-
ment of a software machine to extract rice information is more quick, accurate,
convenient, non-toxic and non-destructive, and so the result achieved is more
accurate. An algorithm can be developed to analyse the exceptional results
alongside the accuracy obtained from the given samples. Soft computing tech-
niques are initiated in grading of Krishna Kamod rice with the support of digital
image processing which checks the appearance of rice grains. The feedforward
neural network techniques are applied to ﬁnd the high degree of quality. The
long seeds and small seeds as well as unknown seed quality are found by the
trained multilayer feedforward neural networks.

Analysis the Accuracy of Rice Grains Quality Using Neural …
467
(4)
Clustering analysis is mainly used in the data mining zone. The K-means
algorithm mainly depends upon clustering centre and its local best possible.
The hybrid optimization algorithm [2] and clustering algorithm are used to ﬁnd
the optimal cluster centre.
(5)
The optimization set of rules is stimulated with the aid of using the breeding
procedure of the three-line hybrid rice. The self-procedure and hybridiza-
tion are the evolutionary method used in swarm seeks procedure. They are
mixed with the ability to convergence and velocity calculation, which can be
concerned as a whole.
(6)
The machine vision device is used for performing grain classiﬁcation. The rice
can be distinguished and analysed based on its RGB histogram, edge detection
and shade model. It aids to discover the clarity of rice grains [3] primarily
based on its features consisting of shape and colour.
(7)
The answer for ﬁrst-rate grading and evaluation of Indian Basmati rice (Oryza
Sativa) ranges with [4] the usage of ML and prescient and digital Processing.
It calculates the size of Oryza Sativa (L) also with detection of chalky and
damaged rice with progressed accuracy as compared with human inspectors.
(8)
The normalization of food grains with the impact of orientation is completed
with the usage of image warping technique with proper scaling [5]. The back-
propagation neural community primarily is advanced to pick out the unusual
grain types. The colouration and grain skins will be obtainable to the neural
networks for training reason that identiﬁes the unknown grain type.
(9)
The exclusive models have been advanced for both the character characteristic
set and for the combined characteristic sets. The type of accuracy is given by
the way of textural capabilities than morphological and colour functions. Thus,
neural network architecture has a tendency to produce distinct accuracies for
special function sets.
The existing approaches discussed above show the analysis of rice grains that are
evaluated with different parameters for analysing different variety of rice in different
locations. In the proposed system, the quality is analysed with the morphological
features of rice grains, where the texture, size and shape are evaluated with the help
of backpropagation algorithm using feedforward neural network approach. From this
approach, the accuracy is measured as 98.4%, which is more accurate than SVM with
92% accuracy.
3
Size and Appearance
Rice grain varieties include differences in appearance, size and the quality also
varieties as seen in the table below:

468
S. Menaka and K. S. Rekha
Characteristics features
Kar rice
Kuruvai rice
Navarai
Late thaladi
Variety
Adt-43
Adt-45
Adt-36
Adt-36
Grain lib rate
2.18
2.98
3.1
3.1
Grain type
Medium slender
Medium slender
Medium
Medium
Habit
Semi dwarf
Semi dwarf, erect
Erect
Erect
Length
5.46
8.00
7.8
7.8
Breadth
1.94
2.16
2.5
2.5
Thickness
1.63
1.97
2
2
A rice grain seed contains the following:
• Protein (4.98%)
• Lipids (0.99%)
• Starch (93.9%).
4
Architectural Diagram
An automated evaluation method is implemented to increase the ﬁrst rate of rice
granules. The high class of rice seed granules trials intend to take part is decided
with the assist of symmetrical talents. A version of exquisite grade attempting out
and identity is constructed that is primarily based mostly on look abilities which
encompass area, two-axis dimensions, part fraction, colour texture and shadeation
escorted by generation of mainframe picture processing and neural network (NN).
The shadeation and diagnosis talents are provided to the neural networks for working
out various purposes, which is then used to understand the unknown rice granules
types and it is excellent. This future technique offers excellent consequences in
evaluation of rice quality. Machine learning is a part of a broader circle of studying
Fig. 1 Rice grain structure

Analysis the Accuracy of Rice Grains Quality Using Neural …
469
Fig. 2 Architecture diagram
methods based totally on learning statistics representation, in place of task-speciﬁc
algorithms. Learning may be supervised, supervised or unsupervised (Fig. 2).
However, this method introduces a number of privateers and efﬁciency chal-
lenges, as the cloud operator can carry out secondary inferences on the available
statistics. Recently, advances in facet processing have paved the way for more efﬁ-
cient, and private, information processing at the supply for easy tasks and lighter
models, although they continue to be a challenge for larger and greater complex
models.
5
Multilayer Perceptron
Artiﬁcial neural network (ANN) kinds and its miles are used for classiﬁcation
purpose. It is one sort of supervised learning. MLP includes three layers: an initial
layer, a middle layer and a result layer. It makes use of the backpropagation algo-
rithm for classiﬁcation of milled rice samples. It is also called a feedforward method
because in this all the facts are passed handiest in the forward guidelines through
the nodes. It calculates neurons weight through its activation characteristic meaning
a linear function calculates the burden of the inputs to the output. In MLP, a few
neurons may be nonlinear. The activation feature includes two commonplace func-
tions. The ﬁrst one is hyperbolic tangent levels from −1 to at least one, and other

470
S. Menaka and K. S. Rekha
Fig. 3 Classiﬁer methods
one is logistic characteristic ranges from 0 to 1. Each node in a single layer connects
with the burden of the alternative nodes within that layer (Fig. 3).
The initial layers are visible layers. Each node is taken as a neuron. In this, the
inputs are passed through the subsequent layer. Initial layer, a middle layer and output
layer is connected with one another. Middle layers are known as invisible layer. The
input is passed through the middle layer and that offers yield fee without delay to
the output result layer.
6
Support Vector Machine
Support vector implement is oneof thesupervisedlearningmodels that is usedfor two
purposes:theyareclassiﬁcationandregression,butoftenusedinclassproblems.Here
the sample is represented as points. The surest boundary is also known as hyper-plane.
And the hyper-aircraft for two units in a vector space are obtained independently that
is based totally on the probabilistic distribution of schooling vectors in the set. Hyper-
plane locates boundary which is a way far from the nearest vectors to the boundary
in units. The vectors positioned near the boundary are called help vectors. Suppose
if area is not linear, at that factor hyper-plane cannot be used to distinguish. The
kernel characteristic is used to resolve the ones problems. Kernel trick is one of the
processes to remedy nonlinear solvable problems. This technique is based totally
on the internal product of input facts and with the deﬁnition of the proper kernel
function (Fig. 4).
The kernel feature enables to carry out the operations in input area as a substitute
than excessive dimensional feature area. Kernel functions are known as a class of
algorithms used for sample analysis. Four kernel functions are there. They are poly-
nomial, normalized polynomial, radial basis feature (RBF) and familiar Pearson VII.

Analysis the Accuracy of Rice Grains Quality Using Neural …
471
Fig. 4 Hyper-margin SVM
The polynomial kernel characteristic is used to symbolize the similarity of vectors
in characteristic space [6]. The normalized polynomial gives better consequences in
comparison with polynomial kernel. RBF is used in numerous kernelized studying
algorithms. Universal Pearson VII is successful to function a generic opportunity to
the common linear, polynomial and RBF kernel functions.
7
Working Model
A feedforward synthetic neural network called a multilayer perceptron (MLP) is a
type of feedforward NN. There are at least three sections of nodes in an MLP [7]: an
initial layer, a middle layer and a result layer. Each node, with the exception of the
input nodes, has unpredictable function of a neuron. For practising, MLP employs a
supervised mastering technique known as again propagation.
MLP is distinguished from a linear perceptron by its many layers and nonlinear
activation. It can say the difference between facts that are not linearly separable. (1)
Feature of activation: [5] if all neurons in a neural networks have a linear charac-
teristic, that maps the weighted inputs to each neuron’s output, then linear algebra
shows that a two-layer input–output layout can be reduced from any number of layers
A few neurons in MLPs use a nonlinear activation mechanism that was developed for
the frequency of behavioural neurons activity abilities or ﬁring. The most common
activation abilities are sigmoid, and they are identiﬁed by the ﬁrst as a hyperbolic
tangent, which has a value between −1 and 1. The logistic function, on the other
hand, is similar in form but has a number of values from 0 to 1. The i-th node’s
(neuron’s) output is shown here, and i is the weighted sum of the enter connections.
The rectiﬁer and gentle plus functions were suggested as potential response features.

472
S. Menaka and K. S. Rekha
Fig. 5 Comparative diagram
8
Computing SVM Classiﬁer
The SVM (soft-margin) classiﬁer is achieved by calculating a type expression. We
concentrate on the SVM because, as previously reported, selecting a slight enough
price straightaway is classiﬁable response data. The conventional form, whichever
includes falling the situation to a symmetric optimization problems [8], is high-
lighted below. Further recent techniques, such as coordinate descent and sub-gradient
descent, can then be addressed.
(1)
Primitive: Reducing the amount of tasks you have to do.
(2)
In the following way, it mayhap treated as a speciﬁc reﬁnement problem with
deviating independent task (Fig. 5).
The main focus is to analyse the visual characteristics of rice seed photographs,
such as shape, colour and texture. It is possible to apply distinct category models to
the use of these capabilities. This study found that image processing techniques can
be used in combination with classiﬁcation techniques such as MLP, linear regression,
SVM and Bayesian culture to classify rice seeds in mixed samples [9]. Some of the
methods which use basic features demonstrated adequate functionality and form
accuracy; on average, they achieved 90.27% and 90.54%, respectively. Other types
of features may be used to enhance performance, as well as further research into
category models. It attempted to concentrate on the fundamental problems of rice
grain industry for the purpose to determine the quality of rice grains, as well as the
associated paintings of researchers to get rid of the hassle associated with ﬁrst-rate
analysis of rice grains.
9
Conclusion
The primary objective of this paper is to survey different ANN methods that are
utilized in the characterization of rice quality. Quality is signiﬁcant in estimating the
evaluation of rice grains. Along these lines, it needs to screen the rice quality and
track down the appropriate method to perform rice quality characterization. The most

Analysis the Accuracy of Rice Grains Quality Using Neural …
473
grouping procedure dependent on the connected works is neural network. Results of
the past investigation have achieved 92% accuracy by utilizing ANN strategy. The
precision consequence of utilizing FFNN procedure as more tasteful is 98%, which
is the best exhibition contrasted with other ANN classiﬁers. Various analysts have
utilized diverse component to gauge the quality. Image preparation will be done to
obtain an exact outcome. To help in improving the exhibitions, SVM shows the most
noteworthy precision by consuming less time. For enormous data set, MLP has been
demonstrated as the best classiﬁer and KNN is not reasonable for working with huge
data set. For analysing the rice grain quality, the proposed backpropagation algorithm
using feedforward neural network approach appears to have better accuracy of 98.4%
when compared with SVM of 92% accuracy.
10
Future Work
The future work can be too precise for the results of the non-uniform enlightenment
and observe top hat transformation on rice grains, and as a result various parameters
will be calculated for the ﬁrst-rate evaluation of Indian Basmati rice grains and
classiﬁed them into normal, small and long rice seeds. Different rice grain varieties
of huge data set with limited parameters can be used to perform better quality analysis
of rice grain.
References
1. Devi, T. G., Neelamegam, P., & Sudha, S. (2017). Machine vision based quality analysis of rice
grains. Published 2017 Computer Science. In 2017 IEEE international conference on power,
control, signals and instrumentation engineering (ICPCSI).
2. Ye, Z., Ma, L., & Chen, H. (2016). A hybrid rice optimization algorithm. In The 11th
international conference on computer science and education (ICCSE) (pp. 169–174).
3. Herath, H. M. K. K. M. B, & de Mel W. R. E., Department of Mechanical Engineering. (2016).
Rice grains classiﬁcation using image processing technics (pp. 1–6). The open university of
Sri Lanka.
4. Birla, R., & Chauhan, A. P. S. (2015). An efﬁcient method for quality analysis of rice using
machine vision system. Electronics and Communication Engineering Department. Journal of
advances in Information Technology (Vol. 6, No. 3, pp. 140–145).
5. Shantaiya, S., & Ansari, U. (2010). Identiﬁcation of food grains and its quality using pattern
classiﬁcation. Special issue of IJCCT 2010 for international conference [ICCT-2010] (Vol. 2,
Issue 2, 3, 4, pp. 70–74).
6. Mohanraj, S., Narenthiran, B., Manivannan, S., & Murugan, R. A. (2021, February). Classiﬁ-
cation of rice grains based on quality using probabilistic neural network. In Materials, design,
and manufacturing for sustainable environment (pp. 867–886).
7. Avudaiappan, T., Sangamithra, S., Roselin, A. S., Farhana, S. S., & Visalakshi, K. M. (2019,
March). Analysing rice seed quality using machine learning algorithms. SSRG International
Journal of Computer Science and Engineering (SSRG—IJCSE)—Special Issue ICRTCRET.

474
S. Menaka and K. S. Rekha
8. Bao, J. S., Wu, Y. R., Hu, B., Wu, P., Cui, H. R., & Shu, Q. Y. (2002). QTL for rice grain quality
based on a DH population derived from parents with similar apparent amylose content 128,
317–324.
9. Asif, M. J., Shahbaz, T., Rizvi, S. T. H., & Iqbal, S. (2019). Rice grain identiﬁcation and quality
analysis using image processing based on principal component analysis. In 2018 International
symposium on recent advances in electrical engineering (RAEE).
10. Shatadal, P. (2003). An identifying damaged soybeans by color image analysis. Applied
Engineering in Agriculture, 19, 65–69.
11. Abdullah, M. Z., Fathinul-Syahir, A. S., & MohdAzemi, B. M. N. (2005). Automated inspection
system for color and shape grading of star fruit (Averrhoacarambola L.) using machine vision
sensor. Transactions of the Institute of Measurement and Control, 27(2), 65–87.
12. Kanungo, T., Mount, D. M., Netanyahu, N. S., et al. (2002). An efﬁcient K-means clustering
algorithm: analysis and implementation. IEEE Transactions on Pattern Analysis & Machine
Intelligence, 24(7), 881–892.
13. Mahale, B., & Korde, S. (2015). Rice quality analysis using image processing techniques. In
International conference for convergence for technology-2014, IEEE.
14. Adu-Kwartenga, E., Ellisb, W. O., Odurob, I., & Manful, J. T. (2003, October). Rice grain
quality: A comparison of local varieties with new varieties under study in Ghana, 14(7),
507–514.
15. Armstrong, B. G., Aldred, G. P, Armstrong, T. A., Blakeney, A. B., & Lewin, L. G. (2005).
Measuring rice grain dimensions with an image analyser. Institute of Food and Crop Science,
University of Ballarat, Ballarat, VIC, 3353.
16. Danying, W., Xiufu, Z., Zhiwei, Z., Neng, C., Jie, M., Qing, Y., Jianli, Y., & Xiyuan, L. (2005,
January 01). Correlation analysis of rice grain quality characteristic. Zuo wu xue bao, 31(8),
1086.
17. Singh, K. R., & Chaudhury, S. (2020). A cascade network for the classiﬁcation of rice grain
based on single rice kernel. Complex & Intelligent Systems, 6, 321–334.
18. Komal, Sethi, G. K., & Bawa, R. K. (2020). Feature based qualitative classiﬁcation of rice
varieties: A review. Journal of Scientiﬁc Research, 64(2).
19. Aukkapinyo, K., Sawangwong, S., Pooyoi, P & Kusakunniran, W. (2020). Localization and
classiﬁcation of rice-grain images. International Journal of Automation and Computing, 17,
233–246.
20. Mohan, D., & Raj, M. G. (2020),Quality analysis of rice grains using ANN and SV. Journal
of critical reviews, 7(1). ISSN 2394-5125
21. Hamzah, A. S., & Mohamed, A. (2020, December). Classiﬁcation of white rice grain quality
using ANN: A review. In IAES international journal of artiﬁcial intelligence (IJ-AI) (Vol. 9,
No. 4, pp. 600–608).
22. Yao, Q., Chen, J., Guan, Z., Sun, C., & Zhu, Z. (2009, May). Inspection of rice appearance
quality using machine vision. In 2009 WRI Global Congress on Intelligent Systems (Vol. 4,
pp. 274–279). https://doi.org/IEEE.

Smart Food Fare Canteen: Automation
of Bills and Serving
Radha Mothukuri, S. Hrushikesava Raju, S. Adinarayna,
Vijaya Chandra Jadala, Saiyed Faiayaz Waris, and G. Subba Rao
Abstract Nowadays, technology is upgrading and advancing in multi-folded ways
and dimensions. The real time application considered is the canteen bill system. In
the traditional system, the user will take a static bill for the kind of food that may be
needed to feed on the bill counter. This leads to many users would experience odd
kind of issues such as few may waste the food because that is not tasty, few users may
not consume more food because of their potentiality, and few may take more than
they deserve. In such cases, in order to set right, the situation that prefers a token for
the trail to check up the food is tasty with a certain 10% of fare of that speciﬁc food.
Manual billing is avoided, and automatic billing is accounted for using debit cards
or QR codes through authorized payment gateway apps. Each item in the canteen
is assigned a certain price and a scanner and QR code for it; the user has to choose
which items to eat after the trail of food items is over. This way avoids wastage of
bills that protects trees indirectly and also saves the environment. This automated
billing and efﬁcient catering of quality food and its items would be the demanding
in the business in the future. In this way, two sections are there in which one is trial
session, and the other is real food court session. Both are separated sessions but
connected.
Keywords Trial session · Real court session · Scanner · QR code · Effective
catering and automated billing
R. Mothukuri · S. H. Raju (B) · V. C. Jadala · G. S. Rao
Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation,
Green Fields, Vaddeswaram, Guntur, Andhra Pradesh, India
S. Adinarayna
Department of CSE, Raghu Institute of Technology, Visakhapatnam, Andhra Pradesh, India
S. F. Waris
Department of CSE, Vignan’s Foundation for Science, Technology and Research, Vadlamudi,
Guntur, Andhra Pradesh, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_37
475

476
R. Mothukuri et al.
1
Introduction
Nowadays, there are many ways the people are facing billing issues for their food
to take up in the hotels, canteens, and any billing section. This billing is not only
for canteen but also to be customized for other sections. The manual billing system
or semi-automatic billing system would lead to human interference in most of the
aspects such as time incurred in taking billing for getting certain items from the shop
or store, papers would be wasted that indirectly causing global warming, printing the
bills also leads to cartridge or toner wastage, and the cost is more when these activities
are involved. In the latter case such as semi-automated process billing where human
efforts are involved to some extent, it uses concept of manual billing to some extent.
When compared to the existing approach, the proposed system consists of totally
automated billing that eliminates many manual activities that cause the environment
resources not to be diluted and preserve the resources of the environment. The activ-
ities automated in this case are such as QR codes are generated for each bill made,
and such codes are useful in getting required items from the shop or the store. The
printing bills on the paper, requirements of the paper rolls, requirement of toners,
and maintenance cost are all to be reduced to the extent possible, and even they are
made zero in the automated process.
The activities of the proposed system are provided as follows:
(1)
The shop or the store has the latest stood with just price markers along with
QR code.
(2)
Generation of unique QR code to each user per item.
(3)
Each item at front has a scanner that would read the QR codes obtained from
the last payment.
(4)
AftersuccessfulveriﬁcationofQRcodes,thequeueofthatitemwoulddispense
or release the items.
(5)
Repeat the process for each user (Steps 3 and 4 are integrated as a master code
that could be read by the scanner that dispenses the selected items from the
counter).
(6)
Finally, these amounts are all summed in order to know total amount earned
on each day.
The payments and queue of dispensing the items are automated using novel hybrid
approach where two or three approaches are combined in order to accomplish the
given task. The steps speciﬁed for the proposed system are performed in sequence.
This system is not preferred to the canteen or shop or the store or any seller shop
in order to eliminate the human interference. This kind of approach is a revolution
in the technology in the modern days. The main beneﬁt of this automation is to
reduce the cost cutting to the shop or storekeeper. This system requires that the shop
merchant would get awareness on the technology and updates over the technology.
Any educated user would feel comfortable in the usage of the technology. Other more
advantage is the shop merchant would concentrate on their other activities instead
of spending all time over the items billing and items delivery.

Smart Food Fare Canteen: Automation of Bills and Serving
477
2
Literature Review
In this, the approaches that are working on billing and dispensing of the items are
discussed along with their limitations and disadvantages.
In the view of source speciﬁed in [1], there are many readymade software that are
developed according to the restaurant-type and its serving capacity. With the source
demonstrated in [2], this is a readymade site that caters many needs of the restau-
rant, billing, servicing, etc. It is multi-folded categorized application that meets user
requirements. In the source given in [3], this is a predeﬁned site that caters many
operations such as recipe managing, prevents employee fraud, kitchen management,
and table orders. In the regard of source mentioned in [4], this is a site which avoids
wastage of inventory and pilferage, works on multiple outlets and controls such
outlets through this site, and encourages the customers feedback on delivery. In the
respect of demonstration provided in [5], there are many kinds in its community
where buffet, food courts, cocktail dinners, etc. are with the aim of reducing the
human service efforts and increasing the self-disciplines. In the regard of the source
given in [6], the restaurant provides the ordered food with servers may or may not
be provided and may not provide additional food instantly that means only whatever
foodissuppliedthatistobeadjusted,whereascateringprovidesfreshfoodandinstant
food if there is shortage with human facilities. In the regard of the source speciﬁed
in [7], the best practices such as integrating the inventory management with POS
for recipe cost and menu engineering take the inventory, leverage smart forecasting
tools, and analyze reports based on inventory and accounting are all demonstrated
with their purpose and theme-oriented terminology. In the perspective of [8], many
principles such as analyzing the employee theft, point of sale, yearly inventory,
employee training, and POS user access permissions are discussed, and their beneﬁt
is also demonstrated. In the regard of [9] and [10], former indicates the manual
demonstration about kinds of foods to prepare, marketing, quality, safety, and many
others in relation with Japan and the USA, and latter indicates the manual description
about quality control, checking out the procedures, closing a table, alcohol awareness,
and many others regarding the restaurant management training and soft templates. In
the regard of [11], the latent factor collaborative ﬁltering optimization is performed
on two matrices such as user features and business features that result errors in the
multiplication of these for gathering user ratings about the restaurant systems. The
regularization is added in order to avoid model overﬁtting. In the view of source
speciﬁed in [12], the enhanced NLP is used to read out the reviews given about the
restaurants on selected features; when user searches for speciﬁc features, the highly
rated hotels are returned for analysis and further proceedings. In the descriptions of
[13] and [14], this model demonstrates about searching of restaurants and produces
the results that consist of restaurants along with food famous in that using collabora-
tive machine learning techniques such as KMM, slope one, and multiclass SVMs. In
the view of [15] and [16], the former speciﬁes that the hybrid approach considered
is a combination of naive Bayes and support vector machines and outputs the results
based on speciﬁc features such as taste, reputation, ratings, reviews, and service, and

478
R. Mothukuri et al.
latter speciﬁed that the algorithms used in this study are compared based on mean
squared error and mean absolute error in evaluating the performances. In the view
of resources demonstrated in [17] and [18], the former describes that the Yelp users
will search for restaurant and would get results based on ratings and reviews about
famous foods in each restaurant. With these details, any individual could commu-
nicate among the groups for speedy decision to order the speciﬁc foods according
to their choice, and latter demonstrates that the recommendations are done based
on guest-type as well as preferences using collaborative ﬁltering technique. The
attributes such as precision, recall, and F-score are the approaches that are compared
based on accuracy and response times. In the regard of [19] and [20], the former
denotes the social data taken from the Facebook and the Yelp help to analyze the
restaurants using the machine learning approaches such as naive Bayes and KNN and
produce the results with 93% accuracy, and latter denotes searching in online became
a demanding task among the users. In the sources mentioned in [21], the demonstra-
tion is on usage of Internet of technology and sensors, and their interaction in order
to communicate and generate automatic reports as per the application.
In the regard of information mentioned in [22], the present pandemic is to be
restricted using the digital mask that reports the virus in the environment that the
user is currently staying. The mask designed will provide statistics about the objects
in the present environment. With respect to source speciﬁed in [23], the IoT is used
in detecting the location and automatically takes its currency and converts that into
the user’s currency. This user ﬂexibility is provided in this context.
As per the study mentioned in [24], the IoT is used in the power banks and portable
devices in order to exchange charging power in the user-friendly atmosphere. The
customized way of charging is done through the designed app and IoT technology.
With respect to the description given in [25], the IoT is used in communicating the
weighted objects falling to the other devices in order to catch it and send it gently to
the ground using automated net.
As the information of [26], the IoT is used in the industries where level of gas is
monitored and detects the leakage if any such is identiﬁed during the passage of gas
over the pipes that are placed from the source to destination. This detection avoids
harmful incidents over the people.
With respect to the source speciﬁed in [27], the IoT is useful over the users in such
a way that users’ health bulletin to be monitored and provides a guide to maintain the
ﬁtness based on food diet. With the view of source mentioned in [28], the IoT and
GSM are used in determining the popular places when a user wants to make a trip
in the world. The guidance is to be provided about the top places and ranked places
in those cities along with route map.
As per the source demonstrated in [29], the GSM and IoT are used to monitor
the garbage bins and alert the nearest municipal ofﬁce in order to clear it which
avoids wastage of visiting many times of that bin. In the regard of [30], any intrusion
is detected in the IoT-based internet environment in the homes, which should be
alerted and avoid future inconveniences.
In the aspect of description given in [31], the detection of premature bosom irreg-
ularity in the images related to especially personal health care systems is discussed,

Smart Food Fare Canteen: Automation of Bills and Serving
479
and the role modality is explored in processing the system. With regard of demonstra-
tion of information in [32], the human effort is maximum minimized and increases
automation through the app based on IoT devices and checks the eyesight remotely.
The signiﬁcance of IoT is clearly depicted and would be useful in making the
proposed system. Regarding the demonstration of [33], It uses Raspberry Pi in
designing the smart meter where how much of electricity is consuming for the usage
is tracked and management of this lively is monitored. In the principal aspect of [34],
the support of new technologies that are based on effective platforms is nowadays a
challenging task. The success of the business depends on this adoption of supporting
new technologies and new designs.
To search for restaurants according to their choice in the available sites, reduces
time and efforts in knowing the required ﬁelds. The sources mentioned in cited
references are describing about manuals, training the staff, software, and based on
rating and reviews. But, we are discussing about the restaurant systems where billing
is taken as prior task and that should be automated which in turn makes rest of
services are also automated in dispensing the selected items based on user choice
during the payment done.
3
Proposed Approach
In this, two modules are identiﬁed which are payment through distributed item cards
with QR codes and dispensing items when master code which is integrated form of
independent item codes when it is read by scanner. In this, priority queues concept is
used in which items are added to one master QR code in order to avoid maintenance
of lot of codes and machine learning technique such as random forest is used in order
dispense the right items from the group of items.
In Fig. 1, there are two modules such as integration of QR codes into one
master code using priority queue per user and dispense of items using random forest
approach. The use-cases of former case are unique UPI per user, items could scanned
and generates a QR code for such item, adding such items QR codes into one master
cod using priority queue, That generated master code to be scanned at dispense
counter that will have separate use-cases such as dispensing of items accordingly
through dispenser, later the items count is to be reduced after each dispense, pops
up the message when user selects any particular item which is not available in the
dispenser, and generates EOD report about money earned, and statistics of items
sold.
The pseudo procedures of these two modules are deﬁned as follows:
Pseudo_Procedure
Prority
Queue_addition_items_codes(items[],
QR
codes[],mater_code[],UPI[]):
Input: UPI[], items[], QR codes[].
Output: Master code per user, cost of items purchased.
Step 1: Import in-built module priority queue and call its methods whenever
appropriate.

480
R. Mothukuri et al.
Fig.1 ER diagram of smart restaurant automation of billing
Step 2: Should use any of UPI apps where user has valid UPI name.
Step 3: Scan the QR codes of items that are to be required. Here, call addition of
items in a priority queue.
function addition(item):
              pq.insert(item);        // where item is add to priority queue instance pq. 
Step 4: All the QR codes of one UPI are added in order to get user cost and
generate master code for that user.
function Generation_Master_code_cum_cost(QR Codes[]):
Mcode= “ “
 
sum=0 
 
for i=0 to n                    // where n is number of items                 
 
 
sum=sum+Currency(QRCodes[i])    // billing per user 
 
 
Mcode=Mcode+QRCodes[i] 
 
return Mcode 
The pseudo procedure for random forest which is a classiﬁcation technique for
dispensing the items from the dispenser:

Smart Food Fare Canteen: Automation of Bills and Serving
481
Pseudo_Procedure Random_Forest_Dispensor(MCode, item1Count, item2Count,
………, itemNCount):
Input: Mcode per user, items counts.
Output: Dispensing of items and Report generation.
Step 1: For the ﬁrst user, the scanner (reader) of dispenser would scan the MCode
and feed what items are to be dispensed.
function Checking_dispense(Mcode):
for each Mcode, there are many QR codes that were integrated that reﬂect items
count.
call Random_Forest(dataset[][], MCodes[])
for 1 to n:
if(item1<=item1count): 
item1count--; 
else if(item2<=item2count): 
 
item2count--; 
.
.
else if(itemN-1<=itemN-1count): 
 
itemN-1count--; 
else: 
 
itemNcount--; 
Step 2: For second user, the Step 1 is performed till last user.
Step 3: Generate a report where each user detail is mentioned along with billing.
for user1 to userN:
Call Checking_dispense(Mcode[user1])          // where user1 is like 1, user2 is like 2, and ….. userN is N.
Step 4: EOD report is to be generated and produced for further analysis.
The working philosophy of random forest is described as follows:
Pseudo_Procedure Random Forest(Dataset[][])
Aim: It is invented by Tin Kam Ho, and it considers the multiple decision trees, average the
outcome of such trees, and output the higher accuracy in determining the class label for the
attribute
Input: Dataset
Output: Class label for each tuple
• Selection of random k data points in the dataset
• Build up decision trees for associated selected data points
• Choose the number N for the decision trees to build up
• Repeat ﬁrst and second points
• For each new data point, assign the class that obtained from majority of voting
The working of random forest algorithm is illustrated in the following diagram
(Fig. 2):

482
R. Mothukuri et al.
Fig. 2 Theme of random
forest approach
Fig. 3 Flowchart of smart
restaurant automation of
billing
The ﬂowchart of smart restaurant automation of billing is deﬁned as follows
(Fig. 3):
4
Results
In this, the expected windows that describe the ﬂow of events are to be interacted one
after the other which would demonstrate the beginning to the closing of the scenario.
At the last, the performance of proposed approach and traditional and semi-traditional
approaches are illustrated through a graph.
The ﬂow of events is depicted in the following diagram where billing to be done
automatically in the sense of digital transactions is encouraged with safety measures
(Fig. 4).

Smart Food Fare Canteen: Automation of Bills and Serving
483
Fig. 4 Flow of events screens in time order in the proposed system
The interaction of signiﬁcant screens in the process of smart restaurant billing
system is as follows:
From Fig. 5, the efﬁcient online sites were used in generation of QR codes for
each person’s bill and are automated for payment. The three approaches taken as
study and their performance toward automatic billing are noted and are depicted in
the following graph (Table 1):
The following are the graphs depicted based on performance and accuracy are
(Fig. 6):
Fig. 5 Signiﬁcant screens that are to be interacted in the ﬂow of processing the proposed system

484
R. Mothukuri et al.
Table 1 Characteristics of approaches that are under analysis
Approach
Performance status
Traditional
Poor and time taking, and human support is required
Semi-traditional
Moderate and some process is automatic and some part is human driven
Proposed system
Expected less time and fully automatic, and accuracy is more
Performance of approaches under analysis
Performance of approaches under accuracy
Fig. 6 Graphs based on performance and accuracy
5
Conclusion
In this, the smart service for billing is automated in terms of reading the items’ QR
codes, as well as dispensing through the master code details. The concept of priority
queues is useful in determining the master code by integrating the selected items
of a speciﬁc user and random forest approach for determining the appropriate items
from the forest of items according to the user’s master code. The use-cases for these
two modules are demonstrated in the ER diagram and are demonstrated through the
appropriate pseudocodes. The performance of the proposed system for automation
of the billing in the smart restaurant case study is speciﬁed in the results. Hence, the
human efforts are all mostly minimized as well as statistics of the everyday report is
generated automatically once the working hours are over.
References
1. Best restaurant billing software in 2021. https://www.softwaresuggest.com/restaurant-billing-
software
2. Ease your business with Windows POS Software. https://justbilling.in/
3. Restaurant billing software for smarter food outlets. https://slickpos.com/features/restaurant-
billing-software/
4. Simplify restaurant operations with restaurant POS software. https://www.gofrugal.com/restau
rant/restaurant-pos-software
5. Mealey, L. (2018, October). Restaurant catering food service guide. https://www.thebalanc
esmb.com/restaurant-catering-events-2888392

Smart Food Fare Canteen: Automation of Bills and Serving
485
6. Catering service vs. restaurant catering: Which is best for you? http://brownbrotherscatering.
com/catering-service-vs-restaurant-catering-which-is-best-for-you/
7. Hannon, H. 4 Restaurant inventory management tips and best practices. https://www.restauran
t365.com/blog/4-restaurant-inventory-management-tips-and-best-practices/
8. 9 Techniques for successful restaurant inventory management. https://www.glimpsecorp.com/
restaurant-inventory-management/
9. Operations Standards Manual (Restaurant case). (2015, March). https://www.jetro.go.jp/ext_
images/en/reports/survey/pdf/2015_03_biz4.pdf
10. Restaurant training manual templates. https://www.restaurantowner.com/public/Restaurant-
Training-Manual-Templates.cfm
11. Theo Jeremiah, How to Build a Restaurant Recommendation System Using Latent Factor
Collaborative Filtering. (2019, November). https://towardsdatascience.com/how-to-build-a-res
taurant-recommendation-system-using-latent-factor-collaborative-ﬁltering-ffe08dd57dca/
12. Gomathi, R. M., Ajitha, P., Krishna, G. H. S., & Pranay, I. H. (2019, October). Restaurant
recommendation system for user preference and services based on rating and amenities. In
ICCIDS. https://doi.org/10.1109/ICCIDS.2019.8862048
13. Jiang, R. (2015). A customized real time restaurant recommendation system. https://etda.librar
ies.psu.edu/ﬁles/ﬁnal_submissions/8189
14. Lavanya, B. M., Kumar, K. K., Kayanath, H. S., & Bai, D. P. (2020, May). A machine learning
model for recommending restaurants based on user ratings. International Journal of Recent
Technology and Engineering (IJRTE), 9(1). ISSN: 2277-3878.
15. Jeyabharathi, J., Loheswaran, K., Ramaiah, V. S., & Kumaravel, T. (2020). Restaurant recom-
mendation system using support vector machine and Naive Bayes classiﬁer machine learning
algorithms. International Journal of Future Generation Communication and Networking,
13(4), 3710–3714.
16. Sawant, S., & Pai, G. Yelp food recommendation system. http://cs229.stanford.edu/proj2013/
SawantPai-YelpFoodRecommendationSystem.pdf
17. A preference-based restaurant recommendation system for individuals and groups. https://
www.cs.cornell.edu/~rahmtin/Files/YelpClassProject.pdf
18. Ramzan, B., Bajwa, I. S., Jamil, N., Amin, R. U., Ramzan, S., Mirza, F., & Sarwar, N. (2019).
An intelligent data analysis for recommendation systems using machine learning. https://doi.
org/10.1155/2019/5941096
19. Joshi, S., Dubey, J. Restaurant recommendation system based on novel approach using k-means
and Naïve Bayes classiﬁers. In AISC (Vol. 1112). https://link.springer.com/chapter/10.1007%
2F978-981-15-2188-1_48
20. Cao,F.F.(2018,May).Eat-smart: Arestaurant recommendationwebapplicationusingmachine
learning and yelp dataset. https://scholarworks.calstate.edu/downloads/nv9356056?locale=en
21. Raju, S. H., Ramani, B. L., Warris, S. F., Kavitha, S., & Dorababu, S. (2020, October). Smart eye
testing. Springer, ISCDA-2020. https://link.springer.com/chapter/10.1007/978-981-33-6176-
8_19
22. Tumuluru, P., Raju, S. H., Baba, C. H. M. H. S., Dorababu, S., & Venkateswarlu, B. ECO
friendly mask guide for corona prevention eco friendly mask guide for corona prevention. In
IOP conference series materials science and engineering (Vol. 981, No. 2). https://doi.org/10.
1088/1757-899X/981/2/022047
23. Baba, C. H. M. H. S., Raju, S. H., Santhi, M. V. B. T., Dorababu, S., & Waris, S. F. International
currency translator using IoT for shopping. In IOP Conference series materials science and
engineering (Vol. 981, No. 4). https://doi.org/10.1088/1757-899X/981/4/042014
24. Sunanda, N., Raju, S. H., Waris, S. F., & Koulagaji, A. Smart instant charging of power banks.
In IOP conference series materials science and engineering (Vol. 981, No. 2). https://doi.org/
10.1088/1757-899X/981/2/022066
25. Mothukuri, R., Raju, S. H., Dorababu, S., & Waris, S. F. Smart catcher of weighted objects. In
IOP conference series materials science and engineering (Vol. 981, No. 2). https://doi.org/10.
1088/1757-899X/981/2/022002

486
R. Mothukuri et al.
26. Kavitha, M., Raju, S. H., Waris, S. F., & Koulagaji, A. Smart gas monitoring system for home
and industries. In IOP conference series materials science and engineering (Vol. 981, No. 2).
https://doi.org/10.1088/1757-899X/981/2/022003
27. Raju, S. H., Burra, L. R., Waris, S. F., & Kavitha S. IoT as a health guide tool. In IOP confer-
ence series, materials science and engineering (Vol. 981, No. 4). https://doi.org/10.1088/1757-
899X/981/4/042015
28. Raju, S. H., Burra, L. R., Koujalagi, A., & Waris, S. F. Tourism enhancer app: User-friendliness
of a map with relevant features. In IOP conference series, materials science and engineering
(Vol. 981, No. 2). https://doi.org/10.1088/1757-899X/981/2/022067
29. Kavitha, M., Srinivasulu, S., Savitri, K., Afroze, P. S., Akhil, P., Sai, V., & Asrith, S.
(2019). Garbage bin monitoring and management system using GSM. International Journal
of Innovative Technology and Exploring Engineering, 8(7), 2632–2636.
30. Kavitha, M., Anvesh, K., Kumar, P. A., & Sravani, P. (2019). IoT based home intrusion detection
system. International Journal of Recent Technology and Engineering, 7(6), 694–698.
31. Kavitha, M., Krishna, P. V., & Saritha, V. (2019). Role of imaging modality in premature detec-
tion of bosom irregularity in internet of things and personalized healthcare systems (pp. 81–92).
Springer, Singapore.
32. Raju, S. H., Burra, L. R., Waris, S. F., Kavitha, S., & Dorababu, S. (2021) Smart eye testing. In
Advances in intelligent systems and computing, 2021, ISCDA 2020, 1312 AISC (pp. 173–181).
https://doi.org/10.1007/978-981-33-6176-8_19
33. Bhalaji, N., (2020, March). EL DAPP–An electricity meter tracking decentralized application.
Journal of Electronics, 2(01), 49–71. https://doi.org/10.36548/jei.2020.1.006
34. Dube, T., Van Eck, R., & Zuva, T. (2020, December). Review of technology adoption models
and theories to measure readiness and acceptable use of technology in a business organization.
Journal of Information Technology, 2(04), 207–212. https://doi.org/10.36548/jitdw.2020.4.003

Activation Functions Instituted
Clustering for Automated Generation
of Programming Code Contracts
S. V. Gayetri Devi and T. Nalini
Abstract Several object-oriented analysis methods require constraints in form of
programming constraints to reﬂect rules for extensive veriﬁcation of concurrent soft-
ware with higher degree of polymorphism and inheritance relationships. To address
the need of software veriﬁcation in time-restrained environment, the proposed work
builds such contracts in an automated way with minimal involvement by developers.
The behavioral and structural information of concurrent Java software is extracted
to derive the behavioral dependency measure as constraints in form of a decision
tree and thereafter transform them as automated code contracts. Then, optimiza-
tion of derived contracts is performed with modiﬁed particle swarm optimization
algorithm to identify the viable contracts. In order to validate the effectiveness of
swarmoptimizationincontractsgeneration,enhancedk-meansclusteringwithneural
networks-associated activation functions, namely tangent hyperbolic and variants of
rectiﬁed linear units, is applied on contracts derived from behavioral dependency
measure, forming deﬁned clusters of similar contracts, and results of both methods
are compared. The results obtained show the efﬁciency of contracts generated by both
optimization and clustering techniques. The work also compares the performances
of the applied clustering algorithms to assess the correctness of contracts generation
by each clustering. The ﬁndings indicated the tangent hyperbolic function guided
k-means clustering accurately and grouped the programming contracts with efﬁcient
time and memory resources usage.
Keywords Contracts prioritization · K-means clustering · Activation function ·
Swarm optimization · Classiﬁer
S. V. G. Devi (B)
Department of Computer Science and Engineering, Bharath Institute of Higher Education and
Research, Chennai, India
T. Nalini
Department of Computer Science and Engineering, Dr. M.G.R. Educational and Research
Institute, Chennai, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_38
487

488
S. V. G. Devi and T. Nalini
1
Introduction
The essential tasks during software products development comprise of the activi-
ties of veriﬁcation and validation [1]. Veriﬁcation endeavors to deliver the conﬁ-
dence that the software is in agreement with the software obligations, regulating the
developmental concerns, comprehensiveness, and function as per the requirements.
Validation formulates on software diligence at each level of development.
Veriﬁcation involves dynamic and static analyses. Static analysis scrutinizes all
potential execution paths as well as variable values of the source code without the
application being executed with the ability to identify errors that may not manifest
even after software release. Dynamic analysis tests and evaluates the application
code at runtime and discovers threading and memory vulnerabilities that cannot be
uncovered by static analysis. Tools implementing both the analyses complement
one another for an exhaustive analysis to ensure quality of software and lowered
development outlays.
Contracts in a broad spectrum represent an essential foundation for formal
program veriﬁcation, or they can be utilized to assist in testing or debugging process.
In the case of testing, contracts are the base to specify the objective to which the soft-
ware program is desired to adhere. With regards to debugging, they are employed to
regulate the inclusion of probes within the software. The probes represent the runtime
checks performed on the contracts validity. The concept of establishing programming
contracts, thus, aids in program veriﬁcation and validation.
Inobject-orientedprogramming,contractsdetailtherelationshipamongasupplier
class as well as a client class, expressed as (i) preconditions, (ii) postconditions on
functions or methods, and (iii) invariants on classes. The contracts drafted signify the
predicates that detail a condition with reference to the data attributes in a class that
the class members must maintain. They are different from the assert statement in Java
language, in the way, that an assert statement indicates a construct that programmers
use to check that assertions stay unviolated, whereas contracts are formal constraints
on the software’s behavior, stating important application-related properties in an
unambiguous way.
Software keeps evolving either to improve functionality or to rectify software
defects bugs. Certain classes of object-oriented software are more susceptible to
changes when compared with others. Prediction of such change-proneness is bene-
ﬁcial for several reasons. It helps developers to emphasize on pre-emptive activities
such as testing, inspections, and peer-reviews, enabling them efﬁcient utilization of
their resources and deliver subsequent higher quality software products in a timely
approach. In spite of increased usage of complex polymorphism and inheritance rela-
tionships and in several object-oriented software applications, there is less stress on
verifying the dynamic behavior of the software. We can obtain a better veriﬁcation
model by measuring the behavioral characteristics of the software and draft them as
programming contracts. The behavioral dependency is attained using the structural
information of the classes present and the relationships among them, along with

Activation Functions Instituted Clustering for Automated …
489
behavioral information in terms of messages passed between objects. The program-
ming contracts are validated using varied formal analysis tools to conﬁrm if funda-
mental conditions of the software speciﬁcations are veriﬁed upon method calls and
if postconditions are satisﬁed once an operation is concluded [1].
Resources and time constraints impact software veriﬁcation activities; hence, opti-
mizing the contracts generated is crucial in the development of a software without
affecting costs for maintenance. At present, programming contracts are being manu-
ally written by programmers which is time-consuming as well as laborious [2, 3].
The proposed work intents to automate the contracts derivation process by extracting
the behavior dependency measure automatically from source code and transforming
them as contracts subsequently. Also, the generated contracts must be optimized
such that neither coverage of software veriﬁcation nor fault identiﬁcation capability
is degraded. The proposed work attains this objective with the application of particle
swarm optimization (PSO) algorithm during contracts derivation [4]. The accuracy
of the optimization can be validated by exercising data mining techniques [2, 5, 6]
with clustering algorithms on the behavior dependencies while transforming them
as contracts. The paper proposes the identiﬁcation of such clusters of programming
contracts that are similar using an appropriate distance measure (Euclidean) with
an enhanced form of k-means clustering algorithm, which is instituted with activa-
tion functions of neural networks such as tangent hyperbolic (TanH) and variants of
rectiﬁed linear units (ReLU). The derived contracts using clustering are compared
with those obtained with PSO algorithm to ascertain the accuracy. Also, the variants
of clustering algorithms with different activations functions applied in the paper are
compared with each other to establish the correctness of contracts generation with
each variant.
2
Related Works
Several authors have presented different strategies for the usage of activation
functions in relevant generalization problems.
Wang et al. [7] proposed a method to handle the difﬁculties in learning a two-
layered ReLU neural network in a binary classiﬁcation background, wherein the
data is linearly distinguishable, and a hinge loss yardstick is assumed. An original
stochastic gradient descent (SGD) method to train any one-hidden-layered ReLU for
global optimality attainment regardless of inﬁnite several unscrupulous local maxima
and minima, as well as saddle points in common, is presented in the paper. Gener-
alization guarantees emphasize a key dissimilarity between dependable learning of
a ReLU network and leaky ReLU network on the lines of model complexity. A
scope to generalize the new noise injection designing to SGD for multiple-layered
ReLU networks, and reﬂecting different loss function and generalizations to multiple
kernel-oriented approaches, is identiﬁed. The SGD algorithm, thus, escapes local
minima as well as saddle points to train efﬁciently any two-layered ReLU network
to achieve global optimality. Evidences pertaining to theoretical as well as empirical

490
S. V. G. Devi and T. Nalini
are attained that support the noise injection during training neural networks to escape
bad local minima as well as saddle points. Optimal training of ReLU networks with
novel SGD and tight generalization error bounds is accomplished.
Li et al. [8] conducted a sequence of experiments on certain datasets by modifying
ReLu activation function into the weighted sum of ReLU TanH activation function.
It is observed that TanH function output enhances the values activated by ReLU units
and lowers the values which are actually shortened by ReLU units. The prospects to
enhance the precision of ResNet as well as inception by a greater margin with two
parameters alone included at each convolutional layer are is observed.
Banerjee et al. [9] presented the data-driven model that led learning of general-
ization problem for distinct output ReLU activation function to a multiple output
variant on the basis of multiple-phased ReLU with the activation function-speciﬁc
parameters. The multi-phase ReLU introduced and studied in the paper, thus, was a
variant of the regular single-output ReLU function, derived by the generalization of
the regular function into a parameterized variant with multi-output. The parameters
expressing the activation function are learned with a data-driven paradigm by the loss
function optimization with regular back propagation. Compared to other activation
functions, ReLU is a non-saturated function with a quicker convergence ability. The
experimental outcomes are reported with MNIST dataset applying a two-layered
network demonstrating the accuracy of the multiple-phased ReLU across the typical
one-output ReLU. The work showed good results with multi-output activation with
reduced overﬁtting. Further scope to apply the activation function with challenging
datasets and deeper neural networks is acknowledged.
Kimura [10] presented a new clustering technique implemented using a feed-
forward neural network, and the method has three segments: Encoder that maps
records to the clusters, decoder that maps clusters to the respective exemplars, and a
loss function to calculate positional proximity between the records as well as exem-
plars. In order to speed up the clustering, an enhanced activation function is used
in the encoder migrating a soft-max function continuously into a max function. The
presented work built the total of clusters as the number of exclusive one-hot encoding
vectors acquired as an outcome. The method is consistent with deep learning neural
networks, and additionally, the presence of local minima of loss function and their
association to clusters are studied.
The prevailing conventional contracts selection methods are based on their utility
with regards to software quality, but in reality, the selection procedure has several
real-timelimitations.Asanexample,variedcontractsmightconsumedifferentexecu-
tion time, and the defects revealed by these assertions possess mixed severity. The
effectiveness of the contracts’ prioritization is, thus, dependent on the concrete time
required for prioritization as well as veriﬁcation with respect to input speciﬁcations.
Activation functions impact the ability of the neural networks to converge as well as
the convergence speed. Also, activation functions aid in normalizing the output of
any input in the range between 0 to 1 or 1 to −1. This paves the way for evolving
efﬁcient clustering and classiﬁcation methods with activation functions instituted
method to select the contracts relevant to the problem under study.

Activation Functions Instituted Clustering for Automated …
491
3
Methodology for Optimization and Ranking
of Programming Contracts
The main objective of the proposed work is to generate software programming
contracts (also implied to as assertions) in an automated way [11–16] with minimal
manual intervention and at the same time optimize the generation process. Particle
swarm optimization is used to optimize the generation of code contracts by having
the contracts derived only for the source ﬁles comprising of decision list with valid
programming conditions (contracts) to be veriﬁed against input speciﬁcations. In
order to verify the results obtained by optimization, the decision lists of the Java
source ﬁles are clustered to ascertain the feasibility of contracts. The method involves
analogous contracts grouped as clusters by applying clustering algorithms subse-
quently [17]. Clustering divides the set of “n” programming contracts (observations)
into “m” distinct groups (clusters). The number of groups is pre-assigned to be 2, in
the proposed method, one each for “feasible” and “non-feasible” contract clusters,
respectively. K-means clustering, with its good performance and straightforward-
ness, is utilized in the work to initialize the cluster centroids (centers) values and
accomplish the clustering. The basic notion behind k-means clustering is unsuper-
vised machine learning. In order to achieve a global minimum during the grouping
of contracts, a comprehensive search exploration is required for larger number of
contracts which is not possible nearly; hence, activation functions are used to speed
up the exploratory task. Selection of appropriate preliminary centroids is the chief
part of k-means where it is obligatory to position the initial cluster centroids ideally
as close as possible to the optimal centroids preferably.
The algorithmic steps of the adapted k-mean clustering in determining the centroid
with activation functions are presented in Fig. 1 as follows.
Activation functions aid in computing the centroids and lessen the number of
clustering iterations and computation time. The contracts are clustered through acti-
vation functions, namely rectiﬁed linear unit (ReLU), leaky ReLU, smooth ReLU,
Fig. 1 Basic steps for contracts to clusters assignment

492
S. V. G. Devi and T. Nalini
and tangent hyperbolic function (TanH) in the modiﬁed form of k-means clustering.
ReLU function is a linear function which is simpler to train, attaining relatively better
performances. The function yields the input value right away as output if it is posi-
tive and zero when otherwise. The leaky ReLU reworks on the ReLU function to let
smaller negative values while the input is lesser than zero [5, 18]. TanH function is
a nonlinear activation function that enables the neural nodes to learn complex data
patterns [8].
The objective function of the clustering is given as follows in Eq. (1):
J =
k

j=1
n

i=1
xi
( j)
−−activationFunction

c j

||2
(1)
where J is the objective or ﬁtness function of clustering algorithm, k is the pre-
assigned number of clusters, n is the number of contracts, xi is the contract i, and
||xi(j)—activationFunction(cj)||2 is the distance function. Here, activationFunction
can be ReLU/leaky ReLU/smooth ReLU/TanH functions instituted during centroid
computation.
The overall scheme for extracting contracts and then apply activation function-
based (TanH/ReLU/smooth ReLU/leaky ReLU) k-means clustering algorithm is
furnished in Fig. 2 as indicated below.
To summarize the clustering method, the number of clusters k, in the work, is
at ﬁrst ﬁxed as 2 with each cluster representing infeasible (non-feasible) as well as
feasible contracts. The spacing between the contracts and the respective centroid of
a cluster is computed by the Euclidean distance between two contracts [19, 20]. The
centroid is apprised by calculating the mean of all contracts within the linked cluster.
Subsequently, the contracts grouping to the equivalent clusters is reiterated consistent
to the altered clusters’ centroid until ﬁnding the termination decisive factor. The
resulting contracts from clustering is compared with the decision lists of contracts
attained after contracts generation through an enhanced particle swarm optimization
[21] in order to conﬁrm the accuracy of clustering.
4
Results and Discussion
To optimize the generation of programming contracts, so that, veriﬁcation and valida-
tion activities can be carried out on the software under test under time and resource-
restricted testing environments, and a modiﬁed form of particle swarm optimization
algorithm (PSO) is implemented by constructing the ﬁtness function of the algorithm
which on evaluation considers only the source ﬁles that have non-empty decision lists
with valid programming conditions (contracts) in effect, thus, generating optimized

Activation Functions Instituted Clustering for Automated …
493
Fig. 2 Optimized and clustered automated contracts development
contracts only from those ﬁles. The modiﬁed PSO algorithm explores the valid deci-
sion lists of programming rules of every source ﬁle and then converts them into a
J48 decision tree of automated code contracts [21].
In order to substantiate and verify the effectiveness of the contracts optimization
using modiﬁed PSO, the contracts of the decision lists that are generated after static–
dynamic analyses of the source code ﬁles are clustered as feasible and non-feasible
ones. Hence, this clustering aspect forms the primary objective of this paper. As part

494
S. V. G. Devi and T. Nalini
Table 1 Contracts clustering with activation functions instituted
Source ﬁle name
Contracts
per
source
ﬁle
Assignment of source ﬁle contracts in “feasible”
(F)/“non-feasible” (NF) cluster
k-means
k-TanH
means
k-ReLU
means
k-Leaky
ReLU
means
k-Smooth
ReLU
means
EmployeeServlet.java
27
NF
F
F
F
F
MainControllerServlet.java 33
NF
F
F
F
F
Now.java
3
F
F
NF
NF
NF
ContextListener.java
2
F
F
NF
NF
NF
BankDB.java
8
F
F
NF
NF
NF
of contracts clustering stage while evolving a tool for verifying multithreaded Java
software [21], the basic k-means clustering and the four activation function (tangent
hyperbolic, ReLU, leaky ReLU, smooth ReLU)-driven k-means clustering methods
are implemented as ﬁve sub-segments for clustering the contracts generated from
behavior dependency measure computed in an automated way.
The clustering implementation is developed as Java web application (versioning
1.8) with Eclipse platform and Windows 10 OS. The source code under test is obtain-
able at GitHub: https://github.com/nardevar/Banking. The purpose of the clustering
is, therefore, to maintain minimal spacing among the contracts inside a cluster and at
the same time, spacing among the “feasible” and “non-feasible” clusters being larger.
Table 1 shows the number of contracts clustered as feasible (F) and non-feasible (NF)
after feasibility assessment using the various clustering methods.
The proposed work considers 26 Java input ﬁles for contracts generation. Behavior
dependency measure in terms of 12 depending and 3 dependent classes was identi-
ﬁed. This information is extracted to identify the classes that are sensitive to code
changes, if any, thereby enabling predicting change-proneness as versions of soft-
ware increases due to introduction of new features or bugs being ﬁxed. The automated
contracts are derived by transforming the conditions in each source ﬁle as constraints
in form of a decision tree.
Out of 26 ﬁles considered, 5 source ﬁles, namely EmployeeServlet.java, Main-
ControllerServlet.java, Now.java, ContextListener.java, and BankDB.java, contain
valid behavior dependency relationship among the relevant classes present in those
ﬁles and are, hence, grouped in two clusters (feasible and non-feasible) using simple
k-means clustering as well as activation functions-exercised clustering algorithms.
Based on the manual analysis of the behavior dependency measure derived from the
26 source code ﬁles as well as the decision list extracted from the tree, only 14 out
of 26 ﬁles have decision lists with conditions, out of which only the 5 source ﬁles,
listed in Table 1, have both behavior dependent classes and valid constraints existing;
hence, contracts are extracted only from these 5 ﬁles, and rest of 9 out of 14 ﬁles are
discarded.
Out of the ﬁve clustering methods presented, only k-TanH means clustering algo-
rithm proposed correctly clusters the contracts in “feasible” group based on the

Activation Functions Instituted Clustering for Automated …
495
described manual analyses of behavior dependency measure as well as extracted
decision lists of constraints. Other clustering methods incorrectly group the contracts
irrespective of whether valid behavior dependent classes and conditions exist in the
source ﬁles. The clustering of the contracts of each of the 5 Java ﬁles using the
presented clustering methods is illustrated in Table 1.
The cluster visualization of the automated contracts generated and tabulated in
Table 1, using the simple k-means clustering, and activation functions-exercised
clustering algorithms, namely k-TanH means, k-ReLU means, k-leaky ReLU means,
and k-smooth ReLU means, are portrayed in the following Figs. 3, 4, 5, 6, and 7,
respectively.
The clustered contracts tabulated in Table 1 using presented clustering methods
can be veriﬁed with the results of PSO algorithm applied on the behavior dependency
measure extracted from the source ﬁles as conditions in decision tree representation.
The PSO generated optimized contracts from 5 valid source ﬁles containing valid
conditions to evaluate for software veriﬁcation and is in agreement with the k-TanH
means clustering algorithm. The correctness of the modiﬁed PSO optimization was
also veriﬁed through manual analysis of behavioral dependency among Java classes
to ascertain presence of valid class dependencies in the source ﬁles as well as valid
decision list of conditions existing.
The processing time, memory as well as CPU consumption for the clustering
algorithms considered are presented in Table 2 and Fig. 8 as follows.
By comparing, the cluster formation results of k-means clustering without any
activation function and the activation function included in the clustering techniques,
namely clustering, isolate the contracts appropriately by accurately reviewing the
feasibility of contracts on the basis of behavioral dependencies which are converted
into contracts in due course. This can be evident in the source ﬁles Employ-
eeServlet.java and MainControllerServlet.java, for example, where k-means clus-
tering incorrectly clusters the 27 and 33 contracts from the both the ﬁles, respectively,
Fig. 3 Cluster visualization of contracts for k-means clustering

496
S. V. G. Devi and T. Nalini
Fig. 4 Cluster visualization of contracts for k-TanH means clustering
Fig. 5 Cluster visualization of contracts for k-ReLU means clustering

Activation Functions Instituted Clustering for Automated …
497
Fig. 6 Cluster visualization of contracts for k-leaky ReLU means clustering
Fig. 7 Cluster visualization of contracts for k-smooth ReLU means clustering

498
S. V. G. Devi and T. Nalini
Table 2 Time, CPU, and
memory consumption for
clustering algorithms
Clustering
algorithm
Time
(in
milliseconds)
CPU usage
(in %)
Memory usage
(in %)
K-means
1175
44.31
64.03
K-TanH
means
1037
36.52
63.3
K-ReLU
means
1062
36.55
62.91
K-leaky
ReLU means
1052
37.86
62.63
K-smooth
ReLU means
1041
38.64
63.07
Fig. 8 Time, memory, and CPU consumption analysis of clustering algorithms
as infeasible in spite of viable behavioral dependences in existence between them
along with valid conditions and so should basically be considered as being feasible.
Similarly, the ﬁle Now.java has valid conditions to be veriﬁed for conformance with
input speciﬁcations, but the algorithms k-ReLU means, k-leaky ReLU means, and
k-smooth ReLU means incorrectly cluster them as infeasible. To summarize, from
the clustering outcomes, it is indicated that only k-TanH means algorithm correctly
clusters the contracts of all the source ﬁles taken for the experiment.

Activation Functions Instituted Clustering for Automated …
499
5
Conclusions
The presented paper constructs feasible contracts with computational efﬁciency by
appropriately modifying k-means clustering using activation functions like Rectiﬁer
Linear Unit (ReLU) variants and Tangent Hyperbolic (TanH). Some concluding
observations from the investigation are given below.
• The programming contracts are clustered in two clusters “feasible” and “non-
feasible.”
• Tangent hyperbolic function-based k-means clustering (k-TanH means) achieves
clustering outputs of 5 source ﬁles consisting of decision lists of contracts grouped
under “feasible” cluster. As compared to the presented clustering methods in
the work, k-TanH means clustering is the optimum clustering method to accu-
rately group the contracts based on presence of valid speciﬁcations constraints
and behavior dependency measure analysis. The method is in accordance with
contracts generation outputs obtained using enhanced PSO algorithm [21] (Fig. 5).
• Experimental measurements of the parameters—time, memory, and CPU utiliza-
tionforclusteringusingdifferentactivationfunctionsarealsoestablished.K-TanH
means clustering attained better performances in terms of the parameters values
obtained.
Future prospect of research essential in this course encompasses of classifying
the clustered contracts to acquire exactness of isolation by constituting a classiﬁca-
tion model for feasible as well as infeasible clusters distinctly. As a further work,
the proﬁciency of the classiﬁcation can be justiﬁed with prevailing metaheuristic
optimization methods to conclusively fortify the software veriﬁcation.
References
1. Monteiro, P, Machado, R. J., & Kazman, R. (2009). Inception of software validation and
veriﬁcation practices within CMMI Level 2. In 2009—For the fourth ınternational conference
on software engineering advances (pp. 536–541). Porto. https://doi.org/10.1109/ICSEA.200
9.84
2. Fausett, L. V. (2004). Fundamentals of neural networks: Architectures, algorithms and
applications.
3. Dias, R. J., et al. (2017). Verifying concurrent programs using contracts. In 2017 IEEE ınterna-
tional conference on software testing, veriﬁcation and validation (ICST) (pp. 196–206). https://
doi.org/10.1109/ICST.2017.25
4. Gayetri, S. V., & Nalini, T. (2021). Optimizing automated programming contracts with modiﬁed
ant colony optimization. Indian Journal of Computer Science and Engineering, 12, 226–238.
https://doi.org/10.21817/indjcse/2021/v12i1/211201252
5. Parhi, R., & Nowak, R. D. (2020). The role of neural network activation functions. IEEE Signal
Processing Letters, 27, 1779–1783. https://doi.org/10.1109/LSP.2020.3027517
6. Pang, Y, Xue, X., & Namin, A. S. (2017). A clustering-based test case classiﬁcation technique
for enhancing regression testing. Journal of Software, 12, 153–164. https://doi.org/10.17706/
jsw.12.3.153-164

500
S. V. G. Devi and T. Nalini
7. Wang, G., Giannakis, G. B., & Chen, J. (2019, May 1). Learning ReLU networks on linearly
separable data: Algorithm, optimality, and generalization. In IEEE Transactions on Signal
Processing (Vol. 67, No. 9, pp. 2357–2370). https://doi.org/10.1109/TSP.2019.2904921
8. Li, X. Hu, Z., & Huang, X. (2020). Combine Relu with Tanh. In 2020 IEEE 4th information
technology, networking, electronic and automation control conference (ITNEC) (pp. 51–55).
Chongqing, China. https://doi.org/10.1109/ITNEC48623.2020.9084659
9. Banerjee, C., Mukherjee, T., & Pasiliao, E. (2020). The multi-phase ReLU activation function.
In Proceedings of the 2020 ACM Southeast Conference (ACM SE’20) (pp. 239–242) Associ-
ation for Computing Machinery, New York, NY, USA. https://doi.org/10.1145/3374135.338
5313
10. Kimura,M.(2018).AutoClustering:Afeed-forwardneuralnetworkbasedclusteringalgorithm.
In 2018 IEEE ınternational conference on data mining workshops (ICDMW) (pp. 659–666).
Singapore, Singapore. https://doi.org/10.1109/ICDMW.2018.00102
11. Devi, S. V. G., & Nalini, C. (2019, July). A systematic judgment to automated programming
contracts generation. International Journal of Recent Technology and Engineering (IJRTE),
8(2). ISSN: 2277-3878.
12. Devi, S. G., Chidambaram. N., & Narayanan, K. (2018). An efﬁcient software veriﬁcation using
multi-layered software veriﬁcation tool. International Journal of Engineering & Technology,
7, 454. https://doi.org/10.14419/ijet.v7i2.21.12465
13. Devi, S. V. G., & Nalini, C. (2020). Prioritized automated generation of contracts with modiﬁed
swarm optimization. International Journal of Advanced Science and Technology, 29(8s), 2432–
2439. Retrieved from http://sersc.org/journals/index.php/IJAST/article/view/14731
14. Devi, S. V. G., & Nalini, C. (2020). Enhanced K-means clustering algorithm for feasi-
bility assessment of ACC. In 2020 Second ınternational conference on ınventive research in
computing applications (ICIRCA) (pp. 340–345). Coimbatore, India. https://doi.org/10.1109/
ICIRCA48905.2020.9182934
15. Devi S. V. G., & Nalini C. (2021). Classifying automated programming contracts using TanH2
decision tree classiﬁer. In J. S. Raj, A. M. Iliyasu, R. Bestak, Z. A. Baig (Eds.), Innovative
data communication technologies and application. Lecture notes on data engineering and
communications technologies (Vol. 59). Springer, Singapore. https://doi.org/10.1007/978-981-
15-9651-3_60
16. Devi, S. V. G., & Nalini, C. (2020). Performance analysis of K-means clustering based hyper-
bolic tangent ınstituted classiﬁcation of automated coding contracts. In 2020 3rd Interna-
tional conference on intelligent sustainable systems (ICISS) (pp. 489–497). Thoothukudi, India.
https://doi.org/10.1109/ICISS49785.2020.9315994
17. Devi, S. V. G., & Nalini, T. (2021). Performance of activation function based clustering of auto-
mated software coding contracts. International Journal of Grid and Distributed Computing,
14(1), 757–768.
18. Stursa, D, & Dolezel, P. (2019). Comparison of ReLU and linear saturated activation functions
in neural network for universal approximation. In 2019 22nd International Conference on
Process Control (PC19) (pp. 146–151). Strbske Pleso, Slovakia. https://doi.org/10.1109/PC.
2019.8815057
19. Volkovich, Z., Toledano-Kitai, D., & Weber, G. (2013). Self-learning K-means clustering: A
global optimization approach. Journal of Global Optimization, 56, 219–232. https://doi.org/
10.1007/s10898-012-9854-y
20. Devi, S. V. G., & Nalini, C. (2021). Prioritizing automated programming contracts using K-
means clustering. Wutan Huatan Jisuan Jishu, XVI(VI), JUNE/2020.
21. Devi, S. V. G., & Nalini, C. (2020). Optimization of automated software contracts gener-
ation by modiﬁed particle swarm optimization. International Journal of Future Generation
Communication and Networking, 13(1), 629–637.

Voice Signal-Based COVID-19 Detection
Using Ensemble Neural Network
A. V. Akshaya and Meril Cyriac
Abstract A rapid and affordable methods of COVID-19 testing are necessary to
reduce increasing rate of infection and to prevent hospitals and medical facilities from
overcrowding. This study demonstrates that different cough audio samples, breath
audio samples, etc., are recorded and collected through smartphones from different
places in the world that can be used to develop a method that predicts COVID-19
infection accurately based on artiﬁcial intelligence algorithm. Artiﬁcial Intelligence
algorithms are used as one of the powerful tools for a preliminary detection of
COVID-19 status of a person and have been developed to accurately predict COVID-
19 infection from smartphone-based cough sounds. A large variety of COVID-19
cough recording audio datasets have been collected by various source and used
to train and develop machine learning models for COVID-19 detection. Different
compression formats are used for recordings. The system uses a combined effect
of three algorithms integrated in as ensemble architecture model. The model is also
pretrained with a larger dataset using cough/non-cough labels and techniques, such
as noise augmentation, audio segmentation, and time and frequency masking, which
are applied. The model can be implemented using different respiratory audio sample
ﬁles collected from various source to create a cough analysis-based machine learning
(ML) solution for COVID-19 detection. After training, the performance is evaluated
by plotting area under curve which results in 0.71 and then predicting the COVID-19.
Keywords Convolution neural network · Long short-term memory ·
Convolutional recurrent neural network · Recurrent neural network · Ensemble
neural network · Mel frequency cepstral coefﬁcient · Mel spectrogram · Artiﬁcial
intelligence
1
Introduction
In the widespread testing and isolation of individuals who are infected with COVID-
19, it is necessary to control spreading rates, and the healthcare resources were
ﬂooded with cases still increasing, and vaccine approval and distribution still delay-
A. V. Akshaya (B) · M. Cyriac
LBS Institute of Technology for Women, Kerala, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_39
501

502
A. V. Akshaya and M. Cyriac
ing, a method of accessible and affordable testing is critical to limit the pandemic.
Present approaches of COVID-19 detection require the person to visit testing centers.
Also, the limited number of testing centers and the centers are ﬂooded with peoples.
With smartphone and Internet usage in most of the countries, these devices are an
ideal platform for a widespread low-cost collection of respiratory audio recordings
and for implementing audio-based COVID-19 testing.
The main challenging factor in medical ﬁeld is diagnosing a patient having severe
acute respiratory syndrome which is through a direct contact only, that result in
spreading virus in the air. Not only that the insufﬁcient test center, absence of low
cost also makes this research more relevant. Rudraraju et al. [1] proposed a traditional
standard clinical test procedure named as spirometry test for detection of respiratory
problems, and it is expensive and not available in the rural area. So, the goal of this
research is to access a real-time voice-based detection of respiratory disease like
COVID-19 through artiﬁcial intelligence in a very low cost and which could be able
to access anyone with a low risk.
Meng et al. [2], Thomas et al. [3], and Gonzalez-Lopez et al. [4] say that the sound
generated from respiratory system reveals some important information of the lungs.
Processing this sound signal through artiﬁcial intelligence-based real-time automated
speech processing system results in diagnosis of severe acute respiratory syndrome
like asthma, pneumonia, bronchitis, COVID-19, asthma, etc. Through this research,
it will be helpful for avoiding the traditional method of painful and time-consuming
approach. To enable this research, a large-scale, crowdsource data was collected from
a healthy and non-healthy patient. The studies show that the human voice consists of
6300 parameters, and based on these parameters, feature extraction and classiﬁcation
are done through an ensemble neural model. Ensemble neural model consists of a
strong and efﬁcient algorithm like convolutional neural network (CNN), long short-
term memory (LSTM), and convolutional recurrent neural network (CRNN).
Recent studies show that there are so many methods for extracting features and
classiﬁcation, but the main problem seen in that is the accuracy is less and there is no
prediction stage. Roneel et al. [5] proposed different techniques for the preprocessing
of the cough signals. Vinayak et al. [6], Pablo et al. [7], Luis et al. [8], and Basu et
al. [9] in these papers show the relevant feature and classiﬁer for cough signals.
Dinh et al.[10], Vinayak et al.[11], and Wani et al. [12] provide a theoretical study of
application of artiﬁcial intelligence and big data of machine learning-based algorithm
on speech and image processing related to COVID-19.
This research is based on the real-time automated testing of COVID-19 in a low
cost with low risk and which could able to access anyone in the world. From this,
it may leads to another thought that it is possible to predict any respiratory disease
through speech signal with small modiﬁcation in the algorithm. In other side, this
research opens the wide application behind in speech processing and which make
useful to researches later. This research may also be helpful for detecting other
respiratory diseases like pneumonia, asthma, etc.
The rest of this paper is organized as follows: Sect.2 provides the detailed method-
ology along with the elementary parts and architecture of the system. Section3 rep-
resent the test result of the model.

Voice Signal-Based COVID-19 Detection …
503
2
Methodology
2.1
Data Collection
This research made use of worldwide data collected with the help of github and
other cloud storage. The audio data of coughing, breathing, and vowels are collected.
The dataset used here consist of 2000 voice samples and their general information’s
including name, gender, age, and questions related to symptoms like fever, dry cough,
wet cough, etc.
The procedure for recording is to place mobile 15cm distance from the patient
in silent environment. Then, step 1 breathe in and out from mouth as deeply for
ﬁve times, step 2 record cough three times, step 3 last one is read the vowel sounds
“a,” “e,” “o.” This voice samples consist of a non-speech and speech sounds of
respiratory syndrome. After recording the voice, the required portion of the audio
can be extracted from the original sample, then it is converted into WAV format
at a sampling frequency of 44,100 samples per sec. These data are uploaded and
shared through github and other cloud platform. Then, later the positive and negative
COVID-19 samples can be divided into training set and testing set.
The dataset used here are ﬁrst one is shallow, deep, and heavy sound of breathing
audio sample, coughing audio sample, and vowel sounds; second one is meta data
information of the patients of their current and preexisting health condition; and third
one is set of algorithms of different speech pronunciation from different countries.
2.2
Audio Data Assessment
The audio data collected is in the time domain and contains several features which are
hidden in it. The data parameter like audio frequency, audio intensity, audio pattern,
and other feature of the audio like amplitude, bit, sampling rate, power, etc., has to
be extracted, so that the data can be visualized and can be processed further.
The cough can be segmented into explosive phase, intermediate cough sound, and
voiced phase. The dry cough has no mucus, and the lower energy is observed in the
intermediate phase. The wet cough was typically produced by foreign bodies that
cause swelling and secretion in lower airways, and it contains mucus. More energy
is observed at the intermediate phase (Fig. 1).
powerdry = Total power in dry cough
Total power in wet cough
(1)
powerwet = Total power in wet cough
Total power in dry cough
(2)

504
A. V. Akshaya and M. Cyriac
Fig. 1 Block diagram
2.3
Audio Data Preprocessing
The collected data may contains of weak and noisy data. This might results to mispre-
diction and improper classiﬁcation during the training phase. The audio parameters
can be boosted for speciﬁed requirement. This processing is called as audio pre-
processing. So, the audio data has to be boosted by varying the audio parameters
like different frequency ranges, intensity, pattern, power, etc., based on the speciﬁc
application. For solving this problem,
Step1-Pre-emphasis
Here, the high-frequency components have been increased with respect to low
frequency component, it is also useful for strengthening the signal, and it increases
the higher frequency component present in the signal, improves signal-to-noise ratio,
and balances the frequency spectrum.
The ﬁrst-order ﬁlter of a pre-emphasis ﬁlter of a signal x is represented as
y(t) = x(t) −αx(t −1)
(3)
where α is 0.97 or 0.95.
Step 2-Framing
Generally, the speech processing is done in trance level and frame level. Trance
level means that the processing is done on the entire sentence of the sample size.
Frame level means that the entire speech is split into small parts and applied algorithm
on each duration and takes result. So, here after, pre-emphasis of the signal is split
into short time frames in required parts. Because the collected voice samples like
cough, breath, and speech are non-stationary sound signals, so their frequency range
varies change entire time, but in case of very short period, the frequency of a signal
are seen to be stationary.

Voice Signal-Based COVID-19 Detection …
505
The number of samples in short period can be expressed as
number of sample size = duration ∗sampling frequency
(4)
Step3-Windowing
After slicing the signals into frames, the window function is applied to the signal.
Window function is used to remove the abrupt changes in the signal. Blackman
window, hamming window, hanning window, estimate window, etc., are some of the
examples of window function. The most used window function is hamming window
where the window length is seen to be same as that of frame. After applying the
window function, the signal is seen to be smoothened, and it will reduce the spectral
leakage.
w(n) = 0.54 −0.46cos( 2πn
N −1)
(5)
where 0≤n ≤(N −1), N is the window length.
Step4-Fourier Transform and Power Spectrum
Short-time Fourier transform /Frequency spectrum can be calculated using each
frame with N point FFT . Then, power spectrum is calculated as
p = |FFT(xi)|2
N
(6)
2.4
Feature Extraction
The main relevant features that extracted from the sound samples are.
2.4.1
Mel Frequency Cepstral Coefﬁcient (MFCC)
It models the human voice characteristics and deﬁnes the spectral envelop overall
shape, and usually it consists of 10–20 small set of features. In this, the cough signal is
usually transformed into the perceptual frequency, which can simulate for processing
auditory better. For that after preprocessing and calculating the Fourier transform,
then calculating the spectral energy at each frame of the Mel frequencies is followed
by taking the log of the energy at each of the Mel frequency and the discreate cosine
transform of the list of Mel powers.
Mel( f ) = 259log(1 +
f
700)
(7)

506
A. V. Akshaya and M. Cyriac
Fig. 2 Mel spectrogram
2.4.2
Mel Spectrogram
Mel spectrogram is a visual representation of different energy levels of a signal, or
in other words, it represents the signal strength over time at different frequencies
present on a particular waveform. Figure2 represents the Mel Spectrogram. The Mel
spectrogram can be calculated by
a. Calculating the frequency spectrum using short-term Fourier transform (STFT).
b. Compute the power of the spectrum.
c. Then, ﬁlter banks is computed by applying triangular ﬁlters on a Mel scale.
d. The ﬁlter bank is applied to the signal spectrum.
2.4.3
Other Feature
Spectral roll, for example, measures frequency where high frequency tends to zero
decline and also measures spectrum shape, while chroma feature describes the simi-
larities between audio pieces. That is, it measures how much energy is present in the
signal for each pitch class C, D, …, and zero crossing rate will be considered within
a segment of sample and measure the number of zero crossing that is taken.
2.5
Labels
The meta data information of a patients including csv ﬁle is named as labels. The
collected information’s include age, gender, age, country, and preexisting and current
health condition of a patient.
Table 1 shows the labels where Y denote as yes, and N denoted as no by comparing
this information with the collected sounds which help us to increase the prediction
accuracy level.

Voice Signal-Based COVID-19 Detection …
507
Table 1 Labels
id
id1
id2
id3
id4
State
India
India
US
India
Gender
Female
Male
Male
Female
Age
26
44
33
60
Smoking
N
Y
N
N
Fever
Y
Y
Y
N
Cold
Y
Y
Y
N
Diabetes
N
N
N
Y
Asthma
N
N
N
Y
Ischemic heart
disease
N
N
N
N
Breathing
difﬁculties
N
Y
N
Y
Sore throat
Y
Y
Y
N
Muscle pain
Y
Y
Y
N
Loss of smell and
taste
N
Y
Y
N
Chronic lung
disease
Y
Y
Y
N
Pneumonia
N
N
N
N
Status of COVID
test
Y
Y
N
N
2.6
Ensemble Neural Network
Ensemble neural network is network which combines strong or weak algorithms
together and predicts a weighted output. It has a good performance and higher predic-
tive performance, i.e., ﬁnal accuracy is better than the individual model performance.
It has two techniques boosting and bagging which make the system performance bet-
ter. The bagging decreases the variance in the prediction and boosting increase the
performance level of the system. Ensemble neural model learns several Wodzinsk et
al. [13], Wirths and Bayer [14] combine their output and produce the ﬁnal predic-
tion. The model here used is long short-term memory (LSTM), convolutional neural
network (CNN), and convolutional recurrent neural network (CRNN).
Recurrent neural network (RNN) is top performance model architecture for the
sequential data. The main strength of RNN is the capability to memorize the result
of previous computation and use that information in the current computation. The
issues of RNN like short term memory, vanishing gradient problem is solved by long
short-term memory. Model 1 is evaluated using LSTM algorithm, they are long-term
dependencies having different operations, and the mechanism used here is called as
gate. Following are steps of LSTM.

508
A. V. Akshaya and M. Cyriac
The ﬁrst step of LSTM is to identify the information that are not required from the
sample data and then throw away that information from the cell state. The decision
is made by the forget gate.
ft = σ[w f (h(t −1), x(t)) + b f
(8)
w f is the weight, h(t−1) is the output from the previous time step, xt is the new input,
and b( f ) is the bias In second step, they decide regarding the information storing in
the cell state. In this step, it has both sigmoid layer and tanh layer.
it = σ[wi(h(t −1)xt) + b f ]
(9)
Ct = tanh[(h(t −1), xt) + b f ]
(10)
Next state is to update the cell state to new state. After that, run sigmoid layer which
decide what part of the cell state we are going to output
The Model 2 layer is evaluated using Zhang et al. [15]. Convolutional neural net-
work (convnet) is a category of neural network. It is a type of feedforward neural
architecture. It does not memorize the past result. It has the following layers like
convolution layer, rectiﬁed linear unit (ReLU) layer, pooling layer, and fully con-
Fig. 3 Ensemble neural
network

Voice Signal-Based COVID-19 Detection …
509
nected layer. Convolution layer will extract features from the input samples, then the
negative values are replaced by zero. Then, the rectiﬁed output is passed through a
pooling layer which reduce the dimensionality problem, and the ﬁnal layer is a fully
connected layer which will shrink or ﬁlter the previous resultant.
The Model 3 layer is evaluated using convolutional recurrent neural network
(CRNN). It is the combination of CNN and RNN. In this, the convolution layer is
generally for feature extraction, i.e., feature maps is obtained through convolution
layer. Then pooling Process is followed by convolution layer (Fig. 3).
3
Test and Discussion
The data of breathing, coughing and vowel audio sample are collected through a
GitHublinkpage(https://github.com/avakshaya1996/COVID19Data.git). It consists
of 1200 patient’s audio and meta data information. Multiple tests were conducted
on the developed system with various audio data. As the datasets are a mixture
of compressed and uncompressed ﬁles and the compression downgrades the audio
quality, a decrease in performance was expected.
Table 2 shows the audio features where each row of that extracted audio features
like MFCC, Mel spectrogram, zero crossing rate, spectral roll off, etc., of each audio
ﬁles in the dataset. Several features are thus extracted and are used for training
process. After extracting the features of the audio from the training data, now the next
step is to test the data for evaluating their performance. By observing the performance
of the model when training increases, gradually their accuracy is increased. Figure4
shows the ﬁrst training step, and in this, they are not learning perfectly, and this
results in curve passing through the reference line it is worthless. Figure5 shows the
second training phase, and in this, they are learning better than the training 1 and the
accuracyisalsoincreased,whichleadstogoodperformance.Figure6showsexcellent
area under curve (AUC) of 0.71, which correlates with the fact that the samples are
noisy compared to the others but also shows promise in extremely noisy samples.
During the ﬁrst few tests, the sample audio was ﬁltered using different ﬁlters, and
an effective ﬁlter algorithm was selected. During the test, multiple models were ﬁrst
created during the train phase and tested the samples for accuracy. When the required
accuracy was obtained, then best models were saved in the system and excluded all
other models. Using the best models created, the accuracy curve was plotted with the
true positive and false positive. As evaluation metrics, we used both accuracy and
the area under the receiver operating characteristics curve (ROC) Curve (AUC). As
the data is unbalanced, we believe that AUC would be a better presentation of how
the model is working.
After the training process, the system was tested with positive and negative sam-
ples. Then, accuracy of the prediction was calculated and veriﬁed the prediction
result. Figures4, 5, and 6 illustrate the ROC curves of results, which further conﬁrms
that our model generalizes to different datasets.

510
A. V. Akshaya and M. Cyriac
Table 2 Labels
0
1
2
3
4
5
6
7
8
9
…
0
−87.028
−87.028
−87.028
−87.028
−87.028
−87.028
−87.028
−87.028
−87.028
…
1
−7.525
−7.41
−10.349
−14.588
−17.028
−15.602
−17.780
−18.137
−19.849
…
2
−87.028
−87.028
−87.028
−87.026
−87.028
−15.602
−17.780
−18.137
−19.849
…
3
−8.409
−16.163
−20.357
−22.281
−20.357
−25.602
−27.780
−28.137
−29.849
…
4
−40.940
−44.948
−44.990
−45.786
−44.990
45.530
−45.968
−45.102
−40.111
…
5
−87.028
−87.028
−87.028
−−87.665
−87.028
−87.026
−87.026
−87.028
−87.028
…
6
−−87.028
−87.028
−87.028
−87.028
−87.028
85.530
−85.968
−285.107
−80.934
…
7
−47.342
−47.195
−47.658
−49.032
−87.028
45.530
−25.968
−25.102
−20.999
…
8
−7.525
−7.525
−14.588
15.026
−14.588
5.530
−25.968
−25.10
−20.921
...
9
−14.588
−14.588
−14.588
−−14.588
−14.588
15.530
−15.968
−15.101
−10.932
…
10
−46.097
−45.987
−−45.098
−46.031
−45.098
45.530
−45.968
−45.102
−40.943
…

Voice Signal-Based COVID-19 Detection …
511
Fig. 4 Training 1
Fig. 5 Training 2
Fig. 6 Training 3

512
A. V. Akshaya and M. Cyriac
4
Conclusion
A new and relevant approach using audio data features, the ensemble deep learn-
ing model, was implemented and is successful in identifying COVID-19 positive
patients. The algorithm for detection maintains its performance on external and clin-
ical datasets which were collected using slightly different noisy environments that
were less than ideal and at different stages of infection. This demonstration gives cre-
dence to the hypothesis that COVID-19 can be reliably detected from cough sounds,
as the virus signature appears to generalize. Test results obtained from the system
demonstrated the effectiveness of the prediction.
References
1. Rudraraju, G., Palreddy, S., Mamidgi, B., Sripada, N. R., Sai, Y. P., Vodnala, N. K., & Haranath,
S. P. (2020). Cough sound analysis and objective correlation with spirometry and clinical
diagnosis. Elsevier Inform. In Med.
2. Meng, F., Shi, Y., Wang, N., Cai, M., & Luo, Z. (2020). Detection of respiratory sounds based
on wavelet coefﬁcients and machine learning. IEEE Access, 8, 155710–155720.
3. Acharya, J., & Basu, A. (2020). Deep neural network for respiratory sound classiﬁcation in
wearable devices enabled by patient speciﬁc model tuning. IEEE Transactions on Biomedical
Circuits and Systems, 14(3), 535–544.
4. Gonzalez-Lopez,J.A.,Gomez-Alanis,A.,MartínDoñas,J.M.,Pérez-Córdoba,J.L.,&Gomez,
A. M. (2020). Silent speech interfaces for speech restoration: A review. IEEE Transactions of
Biomedical Engineering, 8(3), 995–1021.
5. Srivastava, A., Bhateja, V., Shankar, A., & Taquee, A. (2020). On analysis of suitable wavelet
family for processing of cough signals. In Frontiers in intelligent computing: Theory and
applications.
6. Sharan, R. V., Abeyratne, U. R., Swarnkar, V. R., & Porter, P. (2018). Automatic croup diagnosis
using cough sound recognition. IEEE Transactions on Biomedical Engineering, 66(2), 485–
495.
7. Monge-Álvarez, J., Hoyos-Barceló, C., Lesso, P., & Casaseca-De-La-Higuera, P. (2018).
Robust detection of audio-cough events using local hu moments. IEEE Journal of Biomed-
ical and Health Informatics, 6(2), 910–920.
8. Pham, Q. V., Nguyen, D. C., Huynh-The, T., Hwang, W. J., & Pathirana, P. N. (2020). Artiﬁcial
intelligence (AI) and big data for coronavirus (COVID-19) pandemic: A survey on the state-
of-the-arts. IEEE Access, 77(3), 366–372.
9. Monge-Álvarez, J., Hoyos-Barcelo, C., San-José-Revuelta, L. M., & Casaseca-De-La-Higuera,
P. (2018). A machine hearing system for robust cough detection based on a high-level repre-
sentation of band-speciﬁc audio features. IEEE Journal of Biomedical and Health Informatics,
8(4), 430–439.
10. Sun, L., Zou, B., Fu, S., Chen, J., & Wang, F. (2019). Speech emotion recognition based on
DNN-Decision Tree SVM Model. In Elsevier on speech communication.
11. Swarnkar, Vinayak, Abeyratne, Udantha R., Chang, Anne B., Amrulloh, Yusuf A., Setyati,
Amalia, & Triasih, Rina. (2013). Automatic identiﬁcation of wet and dry cough in pediatric
patients with respiratory diseases. Annals of Biomedical Engineering, 41(5), 1016–1028.
12. Wani, T. M., Gunawan, T. S., Qadri, S. A. A., Mansor, H., Kartiwi, M. & Ismail, N. (2020).
Speech emotion recognition using convolution neural networks and deep stride convolutional
neural networks. In 6th International Conference on Wireless and Telematics (ICWT) (pp. 1–6).

Voice Signal-Based COVID-19 Detection …
513
13. Wodzinski, M., Skalski, A., Hemmerling, D., Orozco-Arroyave, J. R., & Nöth, E. (2019). Deep
learning approach to Parkinson’s disease detection using voice recordings and convolutional
neural network dedicated to image classiﬁcation. In 41st Annual International Conference of
the IEEE Engineering in Medicine and Biology Society (EMBC) (pp. 717–720).
14. Wirths, O., & Bayer, T. (2018). Motor impairment in alzheimer’s disease and transgenic
alzheimer’s disease mouse models. Genes Brain and Behavior, 7(2), 1–5.
15. Zhang, S., Zhang, S., Huang, T., & Gao, W. (2018). Speech emotion recognition using deep
convolutional neural network and discriminant temporal pyramid matching. IEEE Transactions
on Multimedia, 20(6), 1576–1590.

A Performance Metrics Estimation
of Spade, Preﬁx Span, Fast, and Lapin
Algorithms
T. M. Veeragangadhara Swamy and N. Vani
Abstract Sequential pattern mining extracts the core of patterns from a wide number
of social media platforms, including Google, Yahoo, Amazon, Flipkart, and others. In
different applications such as DNA analysis, stock market, intrusion detection, and so
on, sequential pattern algorithms are extremely beneﬁcial in extracting the intelligent
patterns. The performance mestrics estimation of Preﬁx Span, SPADE and LAPIN
and FAST algorithms is calculated. For real-time applications of DNA analysis, stock
market analysis, user behavior prediction, and online business expansion, the best
algorithm should be selected. FAST and LAPIN algortihms deliver best performance,
when correlated with other algorithms. FAST performance is better at sparse dataset
and LAPIN outperforms better at dense dataset.
Keywords Preﬁx Span · Spade · GSP · Fast · Lapin
1
Introduction
Sequential pattern mining is mainly focused on predicting future interest. The utiliza-
tion of sequential algorithms in many real-time practices such as decision support,
disease prediction, fraud detection, learning status analysis, ıntrusion detection, stock
market analysis, web log analysis, and customer shopping analysis. Sequential algo-
rithms are performing better predictions on stock market analysis based on the shares
invested on particular company is proﬁtable or loss. Disease predictions are identiﬁed
based on symptoms in patients. The web log analysis is used to check personalization
of user logs and future request predictions are also performed. Sequential algorithms
are more effective at detecting fraudulent activities in the bank transactions carried
out by users. Learning status analysis means students learning on online education
examinations are performed on correctness of predicted request. The are several algo-
rithms on sequential pattern mining such as GSP, Preﬁx Span and SPADE, FAST,
and LAPIN algorithm works on extraction of pattern from sequence database and
predicting future interested patterns which on several real-time applications.
T. M. V. Swamy · N. Vani (B)
Department of CSE, RYMEC, V.T.U, Ballari, Karnataka, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_40
515

516
T. M. V. Swamy and N. Vani
2
Literature Survey
The abundant discrete number of constraints are considered in FAST algorithm
[1]. The closed sequences and generator sequences are investigated on frequent
sequences. It examines constraints based on equivalence class. The MFC-IC is
investigated for memory efﬁciency; time efﬁciency of results is examined. The web
personalization [2] records user interest based on frequent inputs given by user. It
uses Markov models, clustering, and association rule mining.
The comparative analysis of sequential pattern mining algorithm is performed
by using Apriori techniques [3]. The traversing sequential pattern tree by using
breadth-ﬁrst traversal and depth ﬁrst traversal to record backtracking process for path
reference information. The intrusion detection [4] performs securing information by
using timestamp. The proposed model of intrusion detection in the network by using
candidate generation of Apriori algorithm for securing information.
The Apriori-based algorithms [5] are GSP, SPADE, and SPAM algorithms. The
pattern growth algorithms are Free Span and Preﬁx Span algorithms. The Apriori
algorithm requires joining and pruning technique and generate-test methods are used.
The main property of Apriori is breadth-ﬁrst search algorithm. MR-Preﬁx Span
[6] reduces size of the database by merging process of smaller elements. Hadoop
platform is used to perform experiments on improving efﬁciency.
The constraint-based Apriori [7] algorithm introduces intra-event and inter-event
constraint. This algorithm proposed event-wise and sequence-wise Apriori property
and efﬁciency for long sequential patterns. The linear technique of GSP [8] algorithm
works on iterative approach requires ‘n’ number of iteration on ‘n’ database. The
huge number of candidate sequences are generated for large database and requires
more number of scans. The time complexity and space complexity are more in GSP
algorithm when correlated with Preﬁx Span and SADE algorithm.
The pattern growth algorithm [9] uses tree structure for representing node using
depth ﬁrst search algorithm. The partitioning of search space represents database
is partitioned into smaller pieces and mining is performed in parallel, and projected
databases are generated simultaneously. The projected tree implemented to traversing
tree and search for pattern based on depth and breadth-ﬁrst traversal. The pruning of
candidate sequences is performed at early stage which less than minimums support
threshold is eliminated so memory efﬁciency is improved.
3
Sequential Pattern Mining
Sequential pattern mining is most applicable for online business transactions for
expansion of business for world wide. Customer behavior interest must be recorded
for business improvement such as Amazon, Flipkart, Zomato, Facebook, and Twitter.
The algorithms of sequential pattern mining is SPADE, Preﬁx Span, FAST, and

A Performance Metrics Estimation of Spade, Preﬁx Span, Fast …
517
LAPIN. The best performance of algorithm is estimated and increased performance
is evaluated and recorded and applied for real-time applications.
3.1
PREF˙IXSPAN
Preﬁx Span mines all patterns in the database and completely removes concepts of
candidate sequence generation. It is efﬁcient processing and reduces size of database
in projected sequence. The Preﬁx Span [6] scanning database identiﬁes Length-1
sequential pattern, Length-2 sequential pattern, and Length-K sequential patten.
The working process of Preﬁx Span:
Step 1: In Length-1 Sequential Pattern, It partitions projected database and
identiﬁes preﬁx as ﬁrst letter in pattern as Length-1 sequence.
Step 2: The postﬁx of projected database is scanned and adapts length-1 patterns
and second letter of sequence are identiﬁed as preﬁx. The process is executed and
repeated so on until end of the database is reached.
Step 3: No candidate sequences are used. Only projected database is adopted.
The parameters of Preﬁx Span algorithm are:
1.
β is sequential pattern.
2.
l is length of sequential pattern.
3.
S| β is α is projected database.
4.
If β ̸= < > , it is sequence database β.
The previous algorithm has several drawback which leads to several complexity
while implementing algorithm in real-time applications.
a.
Large Number of Candidate Sequences:
Apriori-like algorithm includes concept of permutation and combinations of an
itemset in sequence. The list of sequences from the database.
< β1, β2, β3, . . . .. . . . . . . . . . . . . β1000 >
Total Number of Sequences = n ∗n + n ∗(n −1)
2
For the ﬁrst scan of database < β1, β2 >
< β1, β2 > . . . . . . . . . . . . . . . . . . . . . . . . < β1, β1000 >
< β1, β1 >< β2, β2 > . . . . . . . . . . . . . . . . . . . . . . . . < β2, β1000 >
b.
Huge number of multiple database scans:
For large database, it requires multiple database scans for each candidate sequence.

518
T. M. V. Swamy and N. Vani
{(α1 α2 α3) (α1 α2 α3) (α1 α2 α3) (α1 α2 α3) (α1 α2 α3)} requires ten times
same scan.
c.
Complexity in mining large patterns in sequential pattern:
For every candidate sequence generates short pattern and on growing for large
sequential pattern.
For example: the length of the ﬁrst sequence is 1000.
Table 1 describes about database input for Preﬁx Span algorithm with SID repre-
sents Sequence ID. The EID represents Element ID. The patterns considered are
(RT),(PQR)(PQT)(PQ) recorded based on request sent by user.
In this algorithm, the database is considered as projected database and preﬁx
pattern is identiﬁed as ﬁrst item in the sequence with related to postﬁx sequences
(Table 2).
There are two types of projected database:
(i)
Level-by-level projection
(ii)
Bi-level projection
(iii)
Pointer is pointing to SQ1 and offset represents projection to position 2.
Loop Holes of Preﬁx Span:
Table 1 Database 1 for Preﬁx Span
SID
Time(EID)
Items
1
20, 15, 10, 30, 50
(RT) (PQR) (PQT) (PQ)
2
10, 30
(RT) (PQ)
3
50
(QR) (RT)
4
10, 15, 30, 50
(PQR) (PR) (RT)
Table 2 Preﬁx Span algorithm
Prefıx Span algorithm
Input: Sequence dataset (SD)
Output: Frequent Pattern(FP), Number of sequences(Ns),Time Efﬁciency (TE)
Parameters: Count, SeqSet, Start_Time(ST) = 0, End_Time(ET) = 0, Pattern_Count(PC),
CurPreﬁxes, CurFreqPreﬁxes, ProjectedDB, Min_Sup, Frequent_Count(FC),
Frequent_Pattern(FP), Sequence (S1)
Step 1: Initially set count = 0
Step 2: Find Length-1 Frequent Preﬁxes
Step 3: Check Cur_Preﬁxes > Min_Sup
Step 4: Store SeqSet, Preﬁx in ProjectedDB
Step 5: Compare Elements of S1 and S2
Step 6: Find Preﬁxes from ProjectedDB and Preﬁxes
Step 7: if Found then FP to ProjectedDB
Step 8:Repeat this process until end of SD reached
Step 9:Print FP, TE, Ns

A Performance Metrics Estimation of Spade, Preﬁx Span, Fast …
519
• It scans complete level of database when it considers large database. It requires
more time for processing.
• Time complexity and space complexity is considered as more when database is
large.
• Projected database is considered only preﬁx of database scan for each and every
item in the database and postﬁx subsequences is not considered in this algorithm.
3.2
SPADE
The fast discovery algorithm is SPADE algorithm using hash tree structure performs
only three database scans using temporal join operation. This algorithm was invented
by JAKI in 1998. The SPADE(Sequential Pattern Discovery using Equivalence
Classes) (Table 3).
SPADE has following characteristics:
a.
Temporal operation of joining for Id-List.
b.
Hash tree structure is reduced complexity.
c.
It performs equivalence classes dividing original problem into subproblem.
Spade works on three database scans:
a.
Frequent 1-Sequence
b.
Frequent 2-Sequence
c.
Frequent 3-Sequence.
Table 3 SPADE algorithm
SPADE algorithm
Input: Sequence dataset (SD)
Output: Frequent Pattern(FP), Number of sequences(Ns),Time Efﬁciency (TE)
Parameters: START_TIME(ST) = 0, END_TIME(ET) = 0, MINIMUM_SUPPORT _VALUE
(Min_Sup), Frequent_Pattern(FP), IDList = 0, Itemset
Step 1: Initially set PC = 0,TE = 0 and F1 = 0,F2 = 0
Step 2: Find F1—Frequent Length Sequence
Step 3: Find F2—Frequent Length Sequence
Step 4: Calculate Equivalence Class(EC)
Step 5:Calculate Length-1 Candidate Sequence
Step 6: if Cur_Seq > Min-Sup
Step 7: Store FP in Vertical Database
Step 8: Calculate Length-2 Candidate Sequence
Step 8: Performs Temporal Join Operation
Step 9: Repeat this process until end of SD reached
Step 10: Find FP, NS, TE

520
T. M. V. Swamy and N. Vani
Table 4 Database for
SPADE algorithm
SID
Time
Items
1
10
R S
1
15
P Q R
1
20
P Q T
1
25
P R S T
2
15
P Q T
2
20
T U
4
10
S U V
4
20
Q T
4
25
P U V
SPADE reduces database scan by minimizing I/O cost [10]. It is considered as fast
pattern ﬁnder in sequential pattern mining. Spade utilizes vertical database represen-
tation format. For huge number of databases and ﬁnding frequent sequences requires
itemset big(0 (Pn)) for length n.
Features of SPADE algorithm are:
1.
Vertical id-list
2.
Lattice-theoretical approach
3.
Decomposition of problem.
Let us consider sequence SQ1 and SQ2 where SQ1 contains attributes of itemset
IS = {si1,si2,si3……sim}. A sequence P and sequence Q are considered. If the event
Pi and Qi. Pi is the subsequece of another sequence Qi denoted Pi ≤Qi. The only
ﬁnding frequent subsequences f(Pi) < f(Qi) (Table 4).
Loop Holes and drawbacks of existing algorithm are:
a.
Minimizing input and output problem.
b.
Data skew impacts on performance.
c.
Data structure of internal makes complex.
Outﬂaws of these problems can be solved in SPADE algorithm. Spade divides
search space into smaller pieces and runs independently in main memory. It
adapts depth-ﬁrst search and breadth-ﬁrst search. It reduces cost in search schemes
efﬁciency.
3.3
FAST Algorithm
FAST (FAST Sequence Mining Based on Sparse Id-List) is faster in execution when
correlated with Preﬁx Span and SPADE algorithms (Tables 5 and 6).
The FAST algorithm [1] initially assigns start time and end time and pattern count
set to zero. The threshold maximum support value is inserted by user and ﬁnding
itemset extension and sequence extension.

A Performance Metrics Estimation of Spade, Preﬁx Span, Fast …
521
Table 5 Sequence database
of FAST algorithm
SID
Sequence
1
{{a,b,c},{c},{d},{e},{f}}
2
{{a},{b},{c}}
3
{{c},{d},{e}}
Table 6 FAST algorithm
FAST algorithm:
Input: Sequence dataset (SD)
Output: Efﬁciency of space and Time
Parameters: ST = 0, ET = 0, PC, IE(Item
extension),SE(Sequence extension),SuppTH(Support
Threshold)
Step 1: Initially set ST = 0, ET = 0 and PC = 0
Step 2: Calculation OF IE and SE
Step 3: Find FP on ST & ET
Step 4: Find PC, MEFF, SEFF
Step 5:Calculate Suppth
Step 6: Display FP
3.4
LAP˙IN Algorithm
LAPINalgorithmisoneofsequentialpatternminingidentifyingLAstPositionInduc-
tion (LAST) takes last position to search for pattern and compares with ﬁrst element
(Table 7).
In Lapin algorithm, key value position is calculated as last position where frequent
(K + 1) pattern length by performing appending operation. Lapin greatly minimizes
search space during ﬁnding sequential patterns. ST and ET are start time and end
time of algorithm is required estimate time efﬁciency and space efﬁciency (Table 8).
Table 7 LAPIN database
Customer ID
Customer sequence
10
a(abc)bc(d)
20
b(bcd)ac(bd)
30
c(bc)ab(cd)
40
d(bc)(ab)(ad)

522
T. M. V. Swamy and N. Vani
Table 8 LAPIN algorithm
LAPIN algorithm:
Input: Sequence DataBase
Output: Total Time, Frequent Sequence, Maximum memory used
Parameters: ST = 0, ET = 0, PC = 0, Maximum_support_value, Position = 0,
Sequence_Extension (Seq_E) = 0,ItemSet Extension(IT_E) = 0
Step 1:Estimation of FD Scan
Step 2: Record Counts Min_sup, largest item
Step 3: Calculates SD Scan
Step 4: Find Seq_E & IT_E
Step 5: BackTracking process is investigated
Step 6: Find Min_Sup
Step 7: Calculate THD Scan
Step 8:Forward tracking estimation
Step 9: Display IT_E, Seq_E, PC
4
Comparative Analysis
4.1
Comparative Analysis of SPADE, Prefıx Span, FAST
and LAPIN
The comparative analysis [3] of Preﬁx Span and SPADE algorithm is described on
Table 9. The Preﬁx growth projection is implemented in Preﬁx Span. The database
vertical projection is implemented on Preﬁx Span but in SPADE horizontal database
scan. The pruning of candidate sequences is performed on both Preﬁx Span and
SPADE at early stage to improve space efﬁciency. The depth ﬁrst search is performed
on SPADE for tree projection process. The breadth-ﬁrst search performed on Preﬁx
Span algorithm.
Table 9 Comparative study
on GSP, SPADE and Preﬁx
Span
Categories
Spade
Preﬁx Span
Statically database
Yes
Yes
Preﬁx growth
Yes
Bottom-up search
Yes
Top-down search
Yes
Regular expression constraint
Yes
BFS-based approach
Yes
DFS-based approach
Yes
Yes
Candidate sequence pruning
Yes
Yes
DataBase MultiScan
Yes
Yes
Database vertical projection
Yes

A Performance Metrics Estimation of Spade, Preﬁx Span, Fast …
523
Table 10 Comparative analysis based on pattern growth approach
Sl. no.
Approach
Techniques
FAST
LAPIN
1
Pattern growth
Candidate sequence
Yes
Yes
2
Search space
Yes
Yes
3
Tree projection
Yes
Yes
4
Depth ﬁrst search
Yes
Yes
5
Sufﬁx growth
No
No
6
Sampling compression
No
No
7
Preﬁx growth
No
Yes
8
Memory
Yes
Yes
4.2
Comparative Analysis of FAST and LAPIN Algorithms
(See Table 10).
5
Results
The implementation of sequential algorithm is done with software of python spyder
3.7. The experiments conducted on sequential pattern mining algorithms regarding
time complexity of SPADE, Preﬁx Span, FAST, and LAPIN algorithms to identify
best algorithm for sequential pattern mining for future predictions of behavior users.
The four DATASET remains same for all four algorithms but results various based
on performance of the algorithm.
The Preﬁx Span algorithm identiﬁes sequences of patterns are 86 with time
complexity us 0.120555 when compared to SPADE algorithm time complexity
recorded is 0.330757. The performance of Preﬁx Span is greatly increased when
correlated with SPADE algorithm (Tables 11 and 12; Fig. 1).
The SPADE algorithm time complexity various based on number of sequences
pattern found is investigated. the DATASET 1 identiﬁes sequences of pattern recog-
nized is 86 with time complexity recorded is 0.330757 and DATASET 2 records time
complexity recorded is 0.124488 (Fig. 2; Table 13).
Table 11 Preﬁx Span time
complexıty
Preﬁx Span total time complexity
Dataset
Sequences
Time complexity
Dataset 1
86
0.120555
Dataset 2
30
0.005835
Dataset 3
53
0.004604
Dataset 4
35
0.003180

524
T. M. V. Swamy and N. Vani
Table 12 SPADE tıme
complexity
SPADE total time complexity
Dataset
Sequences
Time complexity
Dataset 1
86
0.330757
Dataset 2
30
0.124488
Dataset 3
53
0.037398
Dataset 4
35
0.035727
Fig. 1 Graph of Preﬁx Span
time complexity
Fig. 2 Graph of SPADE
time complexıty
Table 13 FAST and LAPIN
time complexıty
FAST and LAPIN time consumption
Minimum support (%)
LAPIN (ms)
FAST (ms)
Min_Sup:20
35
0.054
Min_Sup = 50
20
0.025
Min_Sup = 70
15
0.020

A Performance Metrics Estimation of Spade, Preﬁx Span, Fast …
525
Fig. 3 Graph of FAST and
LAPIN time complexity
The FAST and LAPIN algorithms time complexity is recorded with Min_Sup
(Minimum support threshold) with values of 20% of LAPIN algorithm records 35 ms
and FAST algorithm records 0.054 ms recorded. The FAST algorithm is fastest
algorithm when compared to SPADE, Preﬁx Span, and LAPIN algorithms (Fig. 3).
6
Conclusion
Sequential pattern mining investigates patterns which are most commonly frequent
occurred patterns are recorded. The existing algorithms are GSP, Preﬁx Span
using candidate sequence generation and estimation of minimum support value
and maximum support value threshold to ﬁnd pattern greater min_sup threshold is
recorded. The memory space and time complexity constraint are observed in earlier
algorithms and joining, and pruning techniques are used so it is time consuming tech-
nique. The FAST algorithm is faster in execution and suitable for sparse dataset. The
LAPIN algorithm is suitable for dense dataset. The algorithm performance greatly
differs with size of database and complexity varies based on length of dataset.
References
1. Duong, H., Truong, T., & Tran, A. (2019.) Fast generation of sequential pattern with item
constraints from concise representation. Springer Open. Journal of Big Data. https://doi.org/
10.1186/s40537-019-0200-9
2. Doddegowda, B. J., Raju, G. T., & Manvi, S. K. S. (2016, May 20–21). Extraction of behavioral
patterns from preprocessed web usage data for web personalization. In IEEE ınternational
conference on recent trends ın electronics ınformation communication technology.
3. Parikh, M., Chaudhari, B., & Chand, C. (2013). A comparative study of sequential pattern
mining algorithms. International Journal of Application or Innovation in Engineering &
Management (IJAIEM), 2(2). ISSN 2319 – 4847.

526
T. M. V. Swamy and N. Vani
4. Reshamwala, A., & Mahajan, S. (2012, October). Prediction of DoS attack sequences. In
International conference on communication, ınformation and computing technology (ICCICT-
2012) (pp. 18–20). Mumbai.
5. Slimani, T., & Lazzez, A. (2013). Sequentıal mining: Patterns and algorıthms analysıs.
International Journal of Computer and Electronics Research, 2(5).
6. Yong-Qing, W., Dong, L., & Lin-Shan, D. (2012). Distributed PreﬁxSpan algorithm based on
MapReduce. In International symposium on information technology in medicine and education.
7. Gonen, Y., Gal-Oz, N., Yahalom, R., & Gudes, E. (2010). CAMLS: A constraint based
Apriori algorithm for mining long sequences. In Proceedings of database systems for advanced
applications, 15th international conference.
8. SPMF: A sequential pattern mining framework. http://www.philippe-fournier-viger.com/spmf
9. Srikant, R., et al. Data mining: Concepts and techniques mining sequence patterns in
transactional databases. http://www.cs.nyu.edu/courses/spring08/G22.3033-003/8timeseries.
ppt
10. Zaki, M. J. (2001). SPADE: An efﬁcient algorithm for mining frequent sequences. Journal
Machine Learning, 42(1–2), 31–60.
11. Swamy, T. M. V., & Raju, G. T. (2015). A novel prefetching technique through frequent
sequential patterns from web usage data. COMPUSOFT, An ˙International Journal of Advanced
Computer Technology, 4(6), Volume-IV, Issue-4.
12. Doddegowda, B. J., Swamy T. M. V., & Raju, G. T. (2013) Preprocessing of web usage
data for web personalization and prefetching applications. International Journal of Advanced
Computing, 46(3). ISSN: 2051-0845.
13. Chand, C., Thakkar, A., & Ganatra, A. (2012). Sequential pattern mining: Survey and current
research challenges. International Journal of Soft Computing and Engineering (IJSCE), 2(1).
ISSN: 22312307.
14. Zhong, X.-Y. (2011). The research and application of web log mining based on the platform
Weka. Procedia Engineering, 15, 4073–4078.
15. Srikant, R., & Agarwal, R. (1996). Mining sequential patterns: Generalizations and perfor-
mance improvements. In Proceedings of the 5th international conference on EDT: Advances
in database technology (pp. 3–17).
16. Mahajan,S.,Reshamwala,A.,Sharma,N.,Vineet,D.,Sharma,A.,&Shah,P.(2012).Prediction
of Yahoo! music sequences on user’s musical taste. In International conference on advances
in information technology (pp. 6–9). Bangkok, Thailand. https://doi.org/10.3850/978-981-07-
2683-6AIT-102
17. Pei,J.,Han,J.,Mortazavi-Asl,B.,Wang,J.,Pinto,H.,Chen,Q.,Dayal,U.,&Hsu,M.-C.(2004).
Mining sequential patterns by pattern-growth: The PreﬁxSpan approach. IEEE Transactions
on Knowledge and Data Engineering, 16(10).
18. Srivastava, J., Cooley, R., Deshpande, M., & Tan, P.-N. (2000). Web usage mining: Discover
and applications of usage patterns from web data. ACM SIGKDD Explorations, 1(2), 12–23.
19. Agrawal, R., & Srikant, R. Mining sequential patterns. In Proceedings of International
conference on data engineering (pp. 3–14).

Prediction and Classiﬁcation of Cardiac
Arrhythmia
Aashuli Gupta, Arnob Banerjee, Disha Babaria, Kunal Lotlikar,
and Hema Raut
Abstract Due to advancement of new edge medical technologies, many methods
have been applied to solve medical issues including machine learning approach.
Cardiac Arrhythmia is one of the common diseases which can be solved using various
machine learning approaches. There are many approaches which have already been
introduced to classify arrhythmia and abnormality detection. This paper has a solu-
tion, introduces supervised and unsupervised models in which supervised models
generate a good classiﬁcation result. However, in this paper, we have also introduced
a deep neural network classiﬁer and used for prediction of arrhythmia if present
based on some predeﬁned value. In this paper, we have also connected it to the user
interface to which the native users can check the level of arrhythmia.
Keywords Arrhythmia · ECG · Classiﬁcation · Prediction · Deep neural network ·
CNN · DBN · SVM · Decision tree · Logistic regression · MATLAB
1
Introduction
Cardiac Arrhythmia refers to the condition which causes the heart to beat irregu-
larly, either too slowly or too quickly. ECG, also known as Electro-Cardiography
detects if the patient is suffering from arrhythmia. Electrodes are attached to the skin
A. Gupta (B) · A. Banerjee · D. Babaria · K. Lotlikar · H. Raut
Department Electronics and Telecommunication, SIES, Graduate School of Technology,
University of Mumbai, Navi Mumbai, India
e-mail: aashuli.gupta17@siesgst.ac.in
A. Banerjee
e-mail: arnob.banerjee17@siesgst.ac.in
D. Babaria
e-mail: disha.ramesh17@siesgst.ac.in
K. Lotlikar
e-mail: lotlikar.kunal17@siesgst.ac.in
H. Raut
e-mail: hema.raut@siesgst.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_41
527

528
A. Gupta et al.
which is used to take the reading of the patient’s heart activities. The ECG signal
is an important part of the medical profession which helps us to detect the level
of arrhythmia and how dangerous it is. The interpretation of the data is tough and
cant be decoded by a normal person and always requires a medical expert, so here
we are using Machine learning to read the data set (ECG) and detect the abnormal
condition. It helps to do the work faster and more efﬁciently. The content dataset
is taken from the UCI database. Pre-preparing and standardization steps have been
done before prediction and characterization of cardiovascular arrhythmia. In this
paper, we have used deep neural network techniques to classify and predict data as
per guided medical standards.
1.1
Need of Project
These days people are infected by various cardiovascular diseases. Heart illnesses
are one among those that inﬂuence a huge population. Stress is also a reason for
many individual’s heart failures. This undesirable cardiovascular failure and abrupt
passing can be stopped by early recognition and ideal treatment of arrhythmia which
will reduce heart attack in people and also prevent the loss of life. Arrhythmia is
a state of heart where there is irregular beating of the heart causing it to go fast,
slow or unstable. There are different types of arrhythmia from dangerous to normal,
in which Atrial and Ventricular Fibrillation and ﬂutters are dangerous to humans.
These abnormal beating of the heart can be easily identiﬁed at the right time using
proper health monitoring machines which use machine learning and First-aid can be
given to them with proper treatment treating it. This is how machine learning plays
an important role.
1.2
Objectives
The main objective of the project is to detect whether the patient suffers from Cardiac
Arrhythmia by checking its heart beat and the irregularity that is seen in it. It predicts
the discovered patterns and the predicted data using machine learning and helps to
solve health problems. For disease and syndrome prediction they can act as a good
model.
2
Literature Survey
We studied and went through the following research paper listed below to get more
knowledge and proper understanding about the implementation of our project.
Amplitude difference is investigated using random forest. The difference in
features obtained after adding the amplitude difference in the MIT-BIH database

Prediction and Classiﬁcation of Cardiac Arrhythmia
529
recorded growth from 98.51 to 98.68%. to signify the growth the Wilcoxon signed
rank test was extensively employed and after the experiment. It was determined that
addition of amplitude difference helps. The database contains 48 half-hours record-
ings from the ECG leads. So based on this our classiﬁers are trained and tested and
add the difference in the amplitude received. There are many features that include
PQ, QR, and RS amplitude. The study was to check the difference between the data
after the amplitude differences are added to the classiﬁer. QRS duration and RR
interval are added. The new data with the amplitude difference of P, Q, R, and S are
added. After the addition of new data and using random forest, the difference was
not much but increased from 98.51 to 98.68% [1].
ECG signal is nothing but a pulse reading of the heart which can be used to detect
and predict cardiac diseases. By using the SVM (Support Vector Machine) the ﬁrst
step is to detect if the patient is sound or abnormal then for the second step the
disease is classiﬁed into the type of disease the patient might be suffering from. A
basic timing is set and then the model is trained accordingly to differentiate the time
between a normal person and a diseased person. The data is referred from BIOPAC
data acquisition and has used 70 subject’s data. The classiﬁcation accuracy of this
model is 84.6% and is helpful for early diagnosis of the growing heart condition and
so it can be treated before any complications [2].
To obtain the accuracy of DBN on cardiac disorders, the DBN is used in multistage
mode for classiﬁcation which can also be called Multistage DBN. DBN gives 94.15%
accuracy, 92.64% sensitivity and 93.38% selectivity. In this study, the database which
is used is ADB for arrhythmia classiﬁcation. To explain DBN clearly, it is made up of
two stages. The ﬁrst stage being the pre-training of the neural network using greedy
layer wise unsupervised learning. For the second stage, whatever classiﬁcation we
got in the ﬁrst stage, those classiﬁcations are increased by the supervised ﬁne-tuning
within the Contrastive Divergence method [3].
Detection and prediction methods are used for cardiac arrhythmia. Clustering
and regression algorithms are used for this detection. For clustering Density-Based
Spatial Clustering of applications with noise (DBSCAN) is used and for regression
analysis, Multiclass logistic regression is used. When clustering is done, the clusters
obtained are forwarded to the multiclass logistic regression. When these two things
are done, we can be sure as to what type of cardiac arrhythmia it is. This entire system
has given accuracy of 80% overall. In the training phase, both DBSCAN and logistic
regression are used. The dataset is grouped into many clusters by DBSCAN, in which
each cluster will have instances that belong to more than one class. This clustering
method is more efﬁcient in ﬁnding clusters therefore it is used over other clustering
techniques. Logistic regression is applied which will create threshold values for each
cluster. Using Euclidean distance, we check for, the test data belongs to which of
the low-density clusters, and the cluster which is nearest is then selected, in the
Testing phase. After the nearest cluster is selected, the threshold values are checked
to conﬁrm the class where the probability is more than the test tuple is categorized
to that class [4].
The RNN algorithm has been used for identifying normal and abnormal heart beat
in ECG automatically. The ECG signals from the MIT-BIH database are directly

530
A. Gupta et al.
implemented without any pre-processing of data. Binary classiﬁcation has been used
in this paper. The success of heart beat classiﬁcation is carried out by accuracy,
sensitivity, and speciﬁcity [5].
For classiﬁcation purposes, a Three layer feedback-propagation neural network is
used. Results show the Normal beat detection with the other ﬁve types of arrhythmia
beats which are found by giving balanced input to the classiﬁer for training. Same
number of patterns are taken from each class by the input of the training network [6].
Cardiac Arrhythmia is classiﬁed by using the Deep Neural Network. From the
ECG signal, four features are extracted to classify. The feature extracted is Renyi
entropy and is used to classify into types namely arrhythmia and sinus rhythm by
the DNN [7].
To identify different types of cardiovascular disease using deep learning methods
(CNN and MLP) a diagnosis system is developed. These algorithms get implemented
on ECG signals. Multilayer perceptron uses four hidden layers which give accuracy
of 88.7% and CNN uses four convolution layers which give 83.5% accuracy [8].
Raw ECG time-series data with the ECG spectrogram is used as an input to the
CNN. Speciﬁcally, as an input, the ECG time-series is used as an input to the CNN
in the ﬁrst method. For the second method, Time-frequency domain metrics are
used which are converted from the ECG signals and are given to the CNN. In the
time-frequency domain there are hidden features present of the ECG signal [9].
Hybrid Model is proposed in the research work which is developed using a combi-
nation of decision trees and artiﬁcial neural network models. This section gives math-
ematical formulas for the proposed hybrid algorithm. Hybrid models are examined
based on the criteria such as internal pressure, criteria, targets, and external pressures.
This is done so that each category is assessed against the proposed algorithm and
then compared with hidden Markov and SVM based on the decision support system
[10].
Sentiment Analysis is performed by using lexicon-based approach, machine
learning-basedapproach.Inthispaper,abasicinformationunitispresentedtoprovide
a scope of classiﬁcation addicted to positive or negative class at Document level.
SVM, Logistic Regression, Naive Bayes, and Natural Language Processing are used
as machine learning algorithms [11].
Two classiﬁers are used which are Naive Bayes classiﬁers which are based on
probabilistic methods and SVM which is used to recognize patterns and separates in
a dataset. This research paper provides better accuracy than the previous sound-based
dataset, which had noise in it [12].
Our approach in classiﬁcation of the type of arrhythmia is done in this system with
a high accuracy where a combination of classiﬁcation and pre-processing techniques
are used with the implementation of Deep Belief Network (DBN).

Prediction and Classiﬁcation of Cardiac Arrhythmia
531
3
Proposed Model
Any Machine Learning model principally requires a bunch of information to prepare
or test the model. The information needed for forecast is gathered from UCI ML
repository for preparing the dataset. The rundown of boundaries that areincluded
is (age, status, weight, sex, pulse, ECG) which are considered as the contribution
for the preparation informational collection and the testing dataset. The input data
set reads and performs pre-processing for some exploratory data in which it needs
to performs analysis like data quality check like null and missing values which are
further replaced by the mean value or are ﬁltered out from the dataset for improving
the prediction.
After pre-processing the features selection and extraction method which is used
as the datasets typically contain huge number of measurements yield an order which
isn’t precise particularly in the multiclassiﬁcation of the features. A feature selection
wrapper technique is used for extracting important attributes from the dataset and
sci-kit python libraries are also used.
Further, the standardized information is partitioned into two sections for example
70% of the data is for training purposes and 30% for testing purposes. Train/Test is
a method to measure the accuracy of the model. The general principle is to train an
algorithm on a large number of datasets to predict arrhythmia.
Now, we are using different Machine Learning classiﬁers for predicting
arrhythmia. A classiﬁer will help us in ordering data automatically or categorizes
data into one or more of a set of “classes”. The normalized data will be fed into
different classiﬁers. Each of the normalized data is used in all of the classiﬁers. The
classiﬁers used in the model are as follows:
A.
Supervised Learning
Supervised learning works on a labeled dataset in which each input vector has
a corresponding target vector and can be used to evaluate accuracy on training
data (Fig. 1).
1.
Logistic Regression
Logistic regression produces the result in binary form which is used to predict
the outcome of a dependent variable. It has many advantages such as features
that can be dependent. It is an improvement of linear regression used to classify
data. The model having the largest number dedicated to it will be chosen and
classify the given (test data) which further gives the ﬁnal output.
Itisusedtodifferentiatebetweendatabydrawingalinebetweenthemseparating
them from each other. It is similar to linear regression but here the line used
to differentiate the data is the sigmoidal line. The negative data coming on the
graph is converted from zero to one. Logistic regression act both as binary
classiﬁer and multiclass classiﬁer in multi class classiﬁer.
There is a lot of data that can be classiﬁed using the same logic of binary
classiﬁcation. Where the data that has to be classiﬁed is referred against the
entire data set. This process is continued for all the data and a separate model is

532
A. Gupta et al.
Fig. 1 Workﬂow Diagram
formed where they are added to one. Their average is below one and the addition
of the average of all the data is equal to one.
2.
Decision Tree
It is a Graphical representation of possible solutions to a decision based on
certain conditions. A decision tree employs a structure of nodes and branches.
The depth of node is the minimum number of steps required to reach the node
from the root. Eventually, a ﬁnal point is reached and then the prediction is made.
Decision trees can handle both numerical and categorical variables. Overﬁtting
is the main disadvantage of decision trees.
In this algorithm, ﬁrst, a data set is taken. Suppose this data set is D with ‘m’
rows and ‘d’ columns. Now some part of the same data is taken where Row
Sampling (RS) for rows and Feature Sampling (FS) for columns is done. This
small part of the data is given to a decision tree (Dt) and it gets trained on this
small data. Similarly, many such decision trees (Dt’s) can be used.

Prediction and Classiﬁcation of Cardiac Arrhythmia
533
For testing, all of these decision trees (Dt’s) that we have used are bootstrapped
and a majority vote is considered for classiﬁcation. For example, if Dt1 →1,
Dt2 →1, Dt3 →0, Dt4 →1, Dt5 →0, then the majority vote is 1. So, 1 is
considered.
The two main features of decision trees are Low Bias and High Variance.
Low Bias →When we use a decision tree to its complete depth, it will get
properly trained for our training data set. So, the training error is very less.
High Variance →Whenever we get our new test data, these decision trees (Dt’s)
are prone to give a large amount of variance.
In short, whenever we are creating our decision tree (Dt) to its complete depth,
it leads to something called overﬁtting which becomes a problem.
3.
Support Vector Machine (SVM)
SVM is a supervised machine learning algorithm which is used for two-group
classiﬁcation problems. It works relatively well when there is a clear margin of
separation between classes. Also, SVM is effective in cases where the number
of dimensions is greater than the number of samples.
In this algorithm, we have ﬁrst loaded the data set and then have split it into
training and testing data. An SVM classiﬁer is created which improves the
complexity of the classiﬁer using a linear kernel. Then we train the model using
a training dataset and then the system will predict the response for the test dataset
and from this we will evaluate the accuracy.
B.
Unsupervised Learning
An unsupervised learning input vector has no target vector associated with it and no
supervision is involved. Input vectors of similar types are grouped together. In this
process, the neural networks are used for prediction and classiﬁcation which gives
better performance.
DBN can be viewed as a stack of RBMs where the hidden layer of one RBM is
the visible layer of the one above it. A DBN is trained as follows: a) the ﬁrst RBM
is trained to reconstruct its input as accurately as possible. b) The hidden layer of
the ﬁrst RBM is treated as the visible layer for the second and the second RBM is
trained using the output from the ﬁrst RBM. c) This process is repeated until every
layer in the network is trained. DBN only needs a small labeled dataset instead of a
whole dataset to ﬁnish training and ﬁne-tune the net with supervised learning.
Once ﬁtting the model, we will compare the score and check the confusion matrix.
In the wake of ﬁtting every one of the classiﬁers, best performing models will be
chosen as applicant models for Arrhythmia prediction and classiﬁcation. The result
of this candidate model will be displayed with the score of confusion matrix.

534
A. Gupta et al.
4
Implementation and Results
A.
Supervised and Unsupervised model
For implementation, project, and better result purposes we found a dataset of csv
ﬁle, which is further pre-processed into mean values, and wrapper feature is applied.
After this, we used a google collaboratory to implement our supervised learning
ML program. We have used Logistic Regression, Decision Tree, and Support Vector
Machine.
After pre-processing and cleaning the data, we train and test them according to
these supervised learning classiﬁers we got the accuracy for Logistic Regression as
57.52%, Decision Tree as 95%, and SVM as 71.43%.
Below is the tabular representation to make it more understandable. The table will
have following columns:
Classiﬁers: Classiﬁers are the models which are used to train and test the data.
Accuracy: It is deﬁned as the percentage of accurate prediction for the test data.
Precision: It conveys that out of total positive results that is predicted by the model
what is the percentage of actual positive results.
Recall: It is calculated by dividing the total number of true positive data to the total
number of actual positive data. For example, out of all patients having arrhythmia,
what fraction did we correctly detect as having arrhythmia.
F1 Score: It is the combination of precision and recall. Its value lies between 0
and 1. The more the value is nearer to 1, the better and accurate the model will be.
The values needed to calculate F1 score, Recall, Precision we get from Confusion
Matrix. It is a table that is regularly used to depict the exhibition of an arrangement
model (or “classiﬁer”) on a bunch of test information for which the true values are
known.
Further, the dataset is utilized in unsupervised learning DBN utilizing MATLAB.
The neural networks tool compartment gives calculations, pre-prepared models, and
applications to create, train, imagine neural networks. A Training dataset is used
for training the data on some stipulated output. After 542 iterations it reaches the
optimum gradient value. Various parameters are checked from the toolbox after
generating data. Utilizing MATLAB with Deep Learning Toolbox which empowers
to conﬁgure, prepare and deploy DBN.
The MATLAB program was utilized for information handling and characteriza-
tion. The presentation of classiﬁer has been resolved by following measures:
Senstivity = T P/(T P + F N) ∗100(%)
Speci f icity = T N/(T N + F P) ∗100(%)
Accuracy = (T P + T N)/(T P + F P + T N + F N) ∗100(%)

Prediction and Classiﬁcation of Cardiac Arrhythmia
535
It is of the form,
Positive (1)
Negative (0)
Positive (1)
TP
FP
Negative (0)
FN
TN
After training and testing of the models, we concluded that unsupervised learning
models give better accuracy when compared to supervised learning algorithms. So,
unsupervised learning models were interfaced with the GUI (Fig. 2).
B.
User Interface
Flutter is an open-source UI programming Development unit which is made by
Google. It is written in Dart language. It further executes shudder’s center libraries,
document and network I/O, accessibility support.
Features of ﬂutter are—free and open-source framework, can run on different
platforms, changes can be made instantaneously using hot reload, allows accessible
native features and SDKs, Minimal code and it offers widgets which are capable of
developing speciﬁc designs.
Fig. 2 Confusion matrix

536
A. Gupta et al.
Fig. 3 User interface
In the project, Flutter server is used in the Backend side for hosting web portals and
apps, integrating Machine Learning code. Flutter enables a smoother and seamless
scrolling experience while using the app and web framework and also reduces the
time for testing which predicts and classiﬁes the arrhythmia accurately (Fig. 3).
5
Conclusion
In this paper, we examined a modernized model for foreseeing and arranging the
information of cardiovascular arrhythmia. Subsequent to having thought from the
unsupervised models, a profound learning-based model is proposed to anticipate the
arrhythmia.
The investigation demonstrated that even the fundamental calculations on ﬁelds
like AI and Machine Learning may track down a nice result on such basic issues
of dangerous illness. Appropriately, the delayed consequences of this assessment

Prediction and Classiﬁcation of Cardiac Arrhythmia
537
Table 1 Comparison of supervised learning classiﬁers
Classiﬁers
Accuracy (%)
Precision
Recall
F1-Score
Logistic Regression
57.52
0.48
0.58
0.51
Decision Tree
95
0.96
0.96
0.96
SVM
71.43
0.70
0.71
0.70
propose considerably more, that frameworks like this may come to a lot of helpful
and be viably used to deal with this basic issue.
Cardiac Arrhythmia may be a serious problem if not taken proper treatment on
time and not being aware of the depth of the disease. It successfully recognized the
arrhythmia by Neural networks process. It is an efﬁcient and fast process and also
it is very easy to maintain. The dataset in this assessment is depended upon to be
used for courses of action which use AI based measurable estimations, for instance,
Logistic Regression (LR), Decision Tree, SVM, and Deep Belief Network (DBN).
The Flutter based website makes interfacing extremely user friendly. It also directs
the user to easily access disease prediction, at the earliest. In the future, the efﬁciency
and accuracy of the prototype can be enhanced to a certain level, and also connected
to ECG Device for predicting the disease as well as prove to be extremely helpful in
medical applications.
Acknowledgments Authors wish to communicate a profound feeling of appreciation and gratitude
to the Internal Guide, Prof. Hema Raut for her direction, help, and useful suggestions, which helped
in completing the project work successfully. This experience of work led them to self-development
and exposure to the ﬁeld knowledge.
References
1. Lee, S., Kang, K., & Park, J. (2015). Arrhythmia detection using amplitude difference features
based on random forest. IEEE.
2. Tabassum, T., & Islam, M. (2016).An approach of cardiac disease prediction by analyzing
ECG signal. IEEE.
3. Altan, G., Allahverdi, N., & Kutlu, Y. (2018).A multistage deep learning algorithm for detecting
arrhythmia. IEEE.
4. Mol, P., Suresh, A., & Suresh, G. (2017). Prediction of cardiac arrhythmia type using clustering
and regression approach (P-CACRA). IEEE.
5. Singh, S., Pandey, S. K., Pawar, U., & Janghel, R. R. (2018). Classiﬁcation of ECG arrhythmia
using recurrent neural networks. In International Conference on Computational Intelligence
and Data Science, Elsevier.
6. Dash, S. K., & Rao, G. S. (2016).Robust multiclass ECG arrhythmia detection using balanced
trained neural network. © IEEE.
7. Paul, T., Chakraborty, A., & Kundu, S. (2018).Hybrid shallow and deep learned feature mixture
model for arrhythmia classiﬁcation. IEEE.
8. Savalia, S., & Emamian, V. (2018).Cardiac arrhythmia classiﬁcation by multi-layer perceptron
and convolution neural networks.

538
A. Gupta et al.
9. ¸Sen, S. Y., & Özkurt, N. (2020). ECG arrhythmia classiﬁcation by using convolutional
neural network and spectrogram. In 2019 Innovations in Intelligent Systems and Applications
Conference (ASYU), IEEE Xplore: January 2, 2020.
10. Kumar, T. S. (2020). Data mining based marketing decision support system using hybrid
machine learning algorithm. Journal of Artiﬁcial Intelligence, 2(3), 185–193.
11. Mitra, A. (2020). Sentiment analysis using machine learning approaches (Lexicon based on
movie review dataset). Journal of Ubiquitous Computing and Communication Technologies
(UCCT), 2(3), 145–152.
12. Chen, J. I. Z., & Hengjinda, P. (2021). Early prediction of coronary artery disease (CAD) by
machine learning method-a comparative study. Journal of Artiﬁcial Intelligence, 3(1), 17–33.

Impact of Variation of Temperature
on PEM Fuel Cell-Based Power
Converters
M. Malathi, Usha Surendra, and N. Latha
Abstract In renewable energy-based systems, converters and fuel cells play an
essential role. One of the main sources of power for portable applications and stan-
dalone applications is fuel cells. Among various fuel cells types so far, PEMFC
(Proton Exchange Membrane Fuel Cell) is an important fuel cell having characteris-
tics like fast response, low operating temperature, high power/mass ratio, low noise,
little emission or no emission and stable operation. Variation of temperature affects
fuel cell systems performance. The paper aims at modelling PEMFC, different types
of power converters and impact of temperature variation. Simulation of PEM fuel
cell-based energy system with different power converters for the variation of oper-
ating temperature is performed using MATLAB Simulink and results are tabulated
and discussed.
Keywords Fuel cells · PEMFC · Power converters · MATLAB simulink ·
Renewable energy-based systems
1
Introduction
Economic growth and development of human beings mainly depend on clean, safe,
low cost and reliable energy supply. In couple more years, conventional energy
sources like fossil fuels will be exhausted which affects economic growth of human
beings. Hence renewable energy sources play a vital role in energy power generation.
Fuel cells are most popular green energy applications as they provide uninterruptible
M. Malathi (B)
Department of Electrical and Electronics Engineering, NIE Institute of Technology, Mysuru, India
U. Surendra
Department of Electrical and Electronics Engineering, Christ (Deemed to be University),
Bengaluru, Mysuru, India
e-mail: usha.surendra@christuniversity.in
N. Latha
Department of Electrical and Electronics Engineering, REVA University, Bengaluru, Mysuru,
India
e-mail: latha.n@reva.edu.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_42
539

540
M. Malathi et al.
power supply throughout all the seasons. As hydrogen fuel cells have less noise
and high power quality, their beneﬁts are more. They are more suitable for mobile
applications, hospitals and IT centres. Consequence of the use of fuel cells in the
system is clean and efﬁcient energy conversions. The features of fuel cells are listed
below (1) A Fuel Cell possess high density of energy, (2) A Fuel cell is around
40–60%, (3) When fuel cell is used in the system nearly zero gas emission, (4)For a
low frequency ripple current, fuel cell internal losses is more, (5) A single fuel cell
produces the output which is around 0.7 V so to increase the output voltage they are
connected in series, (6) For high output currents, the dynamic performance of a fuel
cell is poor, with “dropping of output voltage and slow response” [1]. Because of
high power density and less operating temperature is the more suitable for vehicle
applications [2]. In portable applications, because of “fuel cells more efﬁciency and
less emission” form them agreeable selection for energy sources [3]. Adopting power
electronics in fuel cell systems make possible to use fuel cell in many applications.
Fuel cells are popularly known as the “microchip of the hydrogen age”. PEMFC
is an electrochemical cell which produces electricity by using oxygen and hydrogen.
Converter transfers energy properly from fuel cells to loads. The “Proton Exchange
MembraneFuelCell(PEMFC)”isestimatedasimportantremedyforexistingecolog-
ical issues, as it produces “almost zero emission, operate at low temperature and
respond quickly as load changes [4]”. Because of “low noise, quick startup, robust-
ness, high efﬁciency, low operating temperature PEMFC are suitable for stationary
and transportation applications [5]. Since fuel cell provides low voltage output char-
acteristic, there is a need for “high step-up DC-DC converter” in Fuel Cell-based
Energy System. Increase in load decreases the fuel cells output voltage.
Section 2 gives explanation about power converters applications in fuel cell-based
energy systems, Sect. 3 mentions about Modelling of power Converters, Sect. 4
indicates about Modelling of PEMFC, Sect. 5 about Simulation results, Conclusion
and future scope have been discussed in Sect. 6.
2
Power Converters Applications in Fuel Cell-Based
Energy System
Fuel cells are the most popular green energy source among all other types, as they
provide clean and continuous supply throughout the year [3]. But, “energy produced
by fuel cell has low voltage output characteristic”, therefore there is a need of using
converters in fuel cell-based energy system. Because of drawbacks of fuel cells such
as less voltage, poor current densities and unreliable power, DC-DC converter plays
an important role in fuel cell-based energy systems [6] (Fig. 1).
Typically, under loaded conditions, a single fuel cell can supply approximately
0.3–0.5 V [7]. These limitations can be overcome by using a DC converter along with
the fuel cell. To meet the operative conditions of fuel cell-based energy systems,
different topologies are developed either as a “DC-DC converter or a DC-AC

Impact of Variation of Temperature on PEM Fuel Cell-Based Power Converters
541
PEMFC
O2
H2
DC-DC 
CONVERTER
LOAD
Fig. 1 PEMFC connected to DC-DC converter
inverter”. Depending on either the load is “AC or DC”, there will be a direct conver-
sion of voltage of fuel cell to an AC voltage. For low power fuel cells, it is stated
that “by maintaining input current ripple below 2% of nominal input current DC-DC
boost converter gives regulated output voltage level”. Boost converter topology is
more suitable than Buck topology for applications of low voltage fuel cells [7].
3
Modelling of Power Converters
3.1
Boost Converter Modelling
This converter is used to boost the input voltage. Sometimes known as “Step Up
Converter”. The function of diode and MOSFET will be a complement to each other
during the switching process, i.e. at a given interval of time when diode is OFF,
MOSFET is ON and when MOSFET is off, diode is off.
In Fig. 2, diagram possess storage elements such as capacitor and inductor. The
inductor voltage and capacitor equations are given below [8]
VL = L dil
dt
(1)
ic = C dVc
dt
(2)
During the switching process, i.e.
Fig. 2 Boost converter
circuit diagram

542
M. Malathi et al.
Case (i) When MOSFET is in “ON” condition
V s = VL
(3)
Case (ii) When MOSFET is in “OFF” condition
−Vout + Vs = VL
(4)
Inductor current is given by the equation
iL = 1
L ∫VLdt
(5)
The current through capacitor can be obtained by the equation
iC = iL −iR
(6)
VC =

icdt 1
C
(7)
Boost converter duty cycle is given by
1 −VS
V0
= D
(8)
3.2
Buck Converter Modelling
A buck converter is a converter which steps down the source voltage. Sometimes
known as “Step-Down Converter”. The circuit modelling possesses two energy
storage elements of inductor and capacitor in buck converter, where voltage across
the inductor V L and current across the capacitor ic are shown in Fig. 3.
VL = L dil
dt
(9)
Fig. 3 Circuit diagram of
buck converter

Impact of Variation of Temperature on PEM Fuel Cell-Based Power Converters
543
ic = C dVc
dt
(10)
During the switching process, i.e.
Case (i) When MOSFET is in “ON” condition
−Vout + Vs = VL
(11)
Case (ii) When MOSFET is in “OFF” condition
VL = Vs
(12)
iC = iL −iR
(13)
Vc = 1
c ∫icdt
(14)
Duty cycle of Buck converter is given by
D = V0
VS
(15)
3.3
Buck Boost Converter Modelling
In Buck boost converter output voltage is either more than or less than the input
voltage [9] (Fig. 4).
The energy in an inductor is given by:
E = LI 2
L
1
2
(16)
Fig. 4 Circuit diagram of
buck converter

544
M. Malathi et al.
V 0
Vi =
−D
1 −D
(17)
4
Modelling of PEMFC
To design stack of fuel cell, PEMFC characteristics is very essential and its equations
are given below.
Ecell = ENernst −Vact −Vohmic −Vcon
(18)
where
ENernst = 1.229 −8.5 × 10−4 × (T −298.15)
+ 4.3085 × 10−5 × T × (ln PH2 + 0.5 ln PO2)
(19)
Vact = −[ξ1 + ξ2T + ξ3T ln(CO2) + ξ4T ln(I)]
(20)
where
CO2 = PO2/5.08 × 106 × exp(−498/T )
(21)
Vohmic = I(Rm + Rc)
(22)
where
Rm = rm Xl/A
(23)
where
rm = 181.6[1 + 0.03 I
A + 0.062
 T
303
2 I
A
2.5

λ −0.634 −3
 I
A

exp[4.18
 T−303
303

]
(24)
Vcon = −Bln

1 −
J
J max

(25)
I
A = J
(26)
A stack voltage with n cells are given by the equation

Impact of Variation of Temperature on PEM Fuel Cell-Based Power Converters
545
Table 1 Parameters for
“PEMFC”
Parameter
Description
n
Number of cells in a stack
T
Temperature of stack/K
A
Activation area/cm2
l
Membrane thickness/μm
PH2
Pressure of hydrogen/atm
PO2
Pressure of oxygen/atm
B
Coefﬁcient for computing Vcon
λ
Membrane moisture content
ξ1, ξ2, ξ3, ξ4
Curve ﬁtting parameter
CO2
Concentration of oxygen at cathode (mol/cm3)
Estack = nEcell
(27)
Output power is given by the equation
Pstack = EstackI
(28)
The efﬁciency is
η =
Ecell
ENernst
(29)
From the above equations it is clear that, with increase in temperature, activation
voltage loss decreases due to which there is increase in stack voltage. Because of
increase in stack voltage, there is increase in power and its efﬁciency (Table 1).
5
Simulation Results
Modelling of PEMFC, Boost and Buck converters are simulated in Simulink and
results are tabulated.
5.1
Circuit Model Graphical Computational Implementation
of Boost Converter in Simulink Platform
The following parameters are used to simulate the Boost converter: input voltage =
45 V, C = 400μF, R = 4 and L = 76.8μH.

546
M. Malathi et al.
Figure 5 shows that for the input voltage 45 V and using the given parameters the
output voltage is 74 V which is found satisfactory when compared with theoretical
calculation (Fig. 6).
Fig. 5 Graphical implementation of boost converter
Fig. 6 Voltage graph of boost converter

Impact of Variation of Temperature on PEM Fuel Cell-Based Power Converters
547
Fig. 7 Graphical implementation of buck converter
Fig. 8 Voltage graph of buck converter
5.2
Circuit Model Implementation of Buck Converter
in Simulink Platform
Buck converter system was simulated using the following parameters: input voltage
= 60 V, C = 3 × 10–6, R = 1 and L = 50 × 10−6 H (Figs. 7 and 8).
5.3
Circuit Model Computational Implementation of Buck
Boost Converter in Simulink Platform
Simulation is done by using the below parameters: input voltage = 45 V, C = 400
μF, R = 4 and L = 76.8 μH (Fig. 9).

548
M. Malathi et al.
Fig. 9 Graphical implementation of fuel cell buck boost converter
Fig. 10 Voltage graph of buck boost converter when D < 0.5
Figures 10 and 11 shows that for the input voltage 60 V and using the given
parameters the output voltage is 24.87 when Duty Cycle D = 0.3 and the output
voltage is 83.68 V when D = 0.6 which is found satisfactory when compared with
theoretical calculation.
5.4
Circuit Model Implementation of PEMFC in Simulink
Platform
PEMFC model was simulated using Simulink and results are shown below (Figs. 12
and 13).

Impact of Variation of Temperature on PEM Fuel Cell-Based Power Converters
549
Fig. 11 Voltage graph of buck boost converter when D > 0.5
Fig. 12 Graphical implementation of PEMFC
Fig. 13 Voltage graph of PEMFC

550
M. Malathi et al.
Fig. 14 Graphical implementation for PEMFC based boost converter
Fig. 15 Temperature effect
on DC-DC fuel cell boost
converter
5.5
Circuit Model for Variation of Temperature on PEMFC
Based Boost Converter
See Figs. 14 and 15.
5.6
Circuit Model for Variation of Temperature on PEMFC
Based Buck Converter
See Figs. 16 and 17.
5.7
Circuit Model for Variation of Temperature on PEMFC
Based Buck Boost Converter
In Figs. 15, 17, 18 and 19 it is clear that when the temperature on Fuel cell’s DC-DC
power converters increases the output voltage increases.

Impact of Variation of Temperature on PEM Fuel Cell-Based Power Converters
551
Fig. 16 Graphical implementation for PEMFC based buck converter
Fig. 17 Temperature effect on DC-DC fuel cell boost converter
Fig. 18 Graphical implementation for PEMFC based buck boost converter
6
Conclusion and Future Scope
The use of various topologies in DC-DC converters has been made possible to use
non-conventional energy in different applications. For PEMFC applications, dc to dc

552
M. Malathi et al.
Fig. 19 Voltage versus
temperature graph for
DC-DC fuel cell buck boost
converter
conversion is always used in order to accomplish huge step-up ratio, small ripple of
input current. In case if ripple of input current is present, it may escort unacceptable
hysteresis power losses within the fuel cell stacks [6]. Above simulation results
clearly shows that the output voltage increases with increasing in temperature which
in turn results in cell membrane dehydration [10]. In PEMFC at high temperature,
“decrease in proton conductivity and membrane dehydration” are crucial obstacles.
Consequence of membrane dehydration is “cracking, loss of mechanical stability
and shrinking” [11]. From the above simulation results, it is clear that when there is
undesirable, unexpected variation in input parameters, there is undesirable change
in the output. Hence to overcome the problems different controller techniques can
be used which will improve the system performance [12].
Acknowledgements We thank Visvesvaraya Technological University, JnanaSangama, Belagavi,
Karnataka, India-590018 for the support given for this proposed research work.
References
1. Daud, W. R. W. (2017). PEM fuel cell system control: A review. Renewable Energy, 113, pp
620–638.
2. Benchouia, N. E., et al. (2015). An adaptive fuzzy logic controller (AFLC) for PEMFC fuel
cell. International Journal of Hydrogen Energy, 40(39), pp 13806–13819.
3. Lai, J.-S., et al. (2017). Fuel cell power systems and applications. IEEE, 105(11)
4. Runben, D. U., et al. (2019). DC/DC modeling and current harmonic analysis in fuel cell
hybrid power system. SAE International.
5. Derbeli, M., et al. (2017). Control of proton exchange membrane fuel cell (PEMFC) Power
system using PI controller. IEEE 2017
6. http://www.eere.energy.gov/hydrogenandfuel cells.
7. Shyammohan, et al. (2018). Comparative study of DC-DC converter topologies for fuel
cells.International Journal of Engineering Research in Electrical and Electronic Engineering
(IJEREEE), 4(2).

Impact of Variation of Temperature on PEM Fuel Cell-Based Power Converters
553
8. Vishwanatha, V., et al. (2017). A complete mathematical modeling, simulation and computa-
tional implementation of boost converter via MATLAB/SIMULINK. International Journal of
Pure and Applied Mathematics, 114 (10), 407–419.
9. Shringi, S. (2019). Comparative study of Cuk, Zeta, Buck-Boost, Boost, Buck Converter in a
standalone PV system. IJERT, 8(9). ISSN: 2278-0181.
10. Wu, Z., et al. (2019). Dynamic modeling and operation strategy of an NG-fueled SOFC-
WGS-TSA-PEMFC hybrid energy conversion system for fuel cell vehicle by using
MATLAB/SIMULINK. Energy Volume, 175, 567–579.
11. Al-Hadeethi, F. (2017). Improving the performance of PEM fuel cell-proton exchange
membrane fuel cell. 2017 - books.google.com.
12. Javaid, U. (2020). Operational efﬁciency improvement of PEM fuel cell—a sliding mode based
modern control approach. IEEE Access, 8.

Qgen: An Automatic Question Paper
Generator
Ajil Paul, Amal Sabu, Beema Abdulkader, Priya George, and Sneha Sreedevi
Abstract Education is a process of gaining knowledge and is important for all as
it plays a vital role in shaping the life of a student. The knowledge that we gain
through education is evaluated through examinations that the teachers conduct peri-
odically. Performance in an examination is an indication of a student’s proﬁciency in
a particular subject. Courses of an educational curriculum are deﬁned with learning
objectives. Question papers consist of questions belonging to different cognitive
levels. Generation of a quality question paper is essential as performance in it can
inﬂuence the career decisions the students take in their life. It is difﬁcult for the
teachers to maintain the same level of complexity across the set of question papers
that are generated. In this paper, we present a model where the questions are tagged
automatically to their respective cognitive levels. It also helps in creating different
sets of question papers containing unique questions and also provides a pictorial
representation of the percentage of various cognitive levels present in the question
paper. The pictorial representation helps the evaluation panel to have an overview of
the distribution of cognitive levels in the question paper.
Keywords Cognitive level · Bloom’s taxonomy · Question paper · Tagging · Word
embedding · LSTM · Pictorial representation
1
Introduction
Examinations play a crucial role in a student’s life. The performance of a student
in an exam inﬂuences the major decisions they take in their life. Thus generating
a good quality question paper is an essential part of any educational curriculum.
Teachers generate a variety of question papers and the lack of experienced teachers
further makes this process even worse. A good question paper is a proper blend
A. Paul · A. Sabu · B. Abdulkader · P. George (B) · S. Sreedevi
Department of Computer Science & Engineering, Muthoot Institute of Technology and Science,
Ernakulam, India
S. Sreedevi
e-mail: snehas@mgits.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_43
555

556
A. Paul et al.
Table 1 Analysis of each cognitive level of bloom’s taxonomy [1]
Level
Anticipated achievement
Example of question
Knowledge
Able to recite, remember previously
learned concept
List two reference parameters in the
sethour function
Comprehension
Construct meaning. Interpret
information in your own words
Brieﬂy compare the performance of a
binary tree to a linked list
Application
To apply previous knowledge in a
new scenario
Write C++ statement to declare a
variable of type musicType name
MyTune
Analysis
Breakdown a concept or architecture
of a system into its smaller parts
If the program received the value 2 3 4
5 as an input. What are the values for
time, hours, minutes after statements
in lines 19 and 20 are executed
Synthesis
Putting elements together to form a
new whole
Write the deﬁnition of the function
OutputTime if the statements from
lines 22 to 34 were to be performed in
function
Evaluation
Judging the value of ideas and
justifying any stand or opinions
Explain brieﬂy how the mechanisms
differ in Java for passing primitive and
nonprimitive types as parameters to
methods
of easy and challenging questions. The question paper should be aligned with the
learning objectives of each course. It is also important to have a perfect distribution
of questions according to cognitive levels. It is a difﬁcult process for the teachers to
select a random set of questions from the pool of available question banks in order to
set a question paper for the examination process. At the same time, the teacher also
needs to maintain the correct proportion of the different cognitive levels as per the
university guidelines. Manual generation of multiple sets of question papers takes
more effort and puts more stress on people as its quality is purely dependent on the
individual’s expertise. So considering these difﬁculties we have proposed a solution
that generates a question paper automatically using user-entered speciﬁcations.
There are six different cognitive levels according to Bloom’s taxonomy. They are
knowledge, comprehension, application, analysis, synthesis, evaluation (Table 1).
2
Related Works
Assessment made by conducting a written test is a traditional process but it is
a universal evaluation process in almost all academic institutes today. Therefore,
students should follow the question with the subject they have learned in order to
achieve the results they have learned. However, the technique of writing questions is
a very demanding task for the teacher [2].

Qgen: An Automatic Question Paper Generator
557
A literature survey was conducted in order to understand the need for automatic
generation of the question paper. It was found that the proposed solution deals with
selecting questions from a pre-tagged repository for the generation of question paper
[3]. A deep understanding of the various levels in Bloom’s taxonomy was gained
throughthepaper[4].Asperthepaper[1],arule-basedapproachwasusedwhereonly
the keywords were matched to classify questions to their appropriate cognitive levels.
The relevance of POS tagging in Bloom’s taxonomy classiﬁcation was understood
through the paper [5, 6]. According to [7], the NLTK tagger has considerable accu-
racy in assigning appropriate POS tags to words. Based on [8], a Recurrent Neural
Network (RNN) is a feed-forward neural network whose input depends on the output
of the previous computation. But although they have some attractive qualities, RNNs
failed to train very long sequences due to vanishing gradient problems. According to
[9] LSTM, an advanced form of RNN was found that resolved the vanishing gradient
problem in RNN. It performs much better than conventional RNN. A comparative
study of LSTM and GRU is done and it was found that LSTM gives more accuracy
and F-measure than GRU in the case of large datasets and GRU is more suitable for
smaller datasets [10]. It is a really difﬁcult and tedious task for teachers to manually
tag the questions to their corresponding cognitive levels. The quality of the question
paper generated depends entirely on the experience and expertise of teachers. The
shortage of experienced teachers further complicates the issue. Hence it is a neces-
sity to have a system where the questions are tagged automatically to their respective
cognitive levels. In addition to that, several sets of question papers containing unique
questions can also be generated along with a visualization that shows the percentage
of various cognitive levels in the question paper.
3
Design
3.1
System Architecture
Step 1: Users register by ﬁlling the necessary details and then sign into their account
(Fig. 1).
Step 2: Questions along with their modules are entered by the user.
Step 3: Questions are classiﬁed to their appropriate cognitive levels and are stored
in the database.
Step 4: Database thus stores questions, the modules they belong to, and their
corresponding cognitive levels.
Step 5: The user can enter the speciﬁcations of the question paper which are to be
generated such as the module-wise percentage, cognitive level percentage, number
of sets, number of sections, total marks of individual sections, range of marks in each
section.

558
A. Paul et al.
Fig. 1 Proposed system architecture
Step 6: Questions are queried from the database based on all the conditions spec-
iﬁed and different sets of question papers are generated. The sets of question papers
generated do not contain any repetitive questions.
Step 7: A pictorial representation of the percentage of various cognitive levels
present in each question paper is produced.
3.2
Question Classiﬁcation
Question classiﬁcation module is a module that deals with automatically analyzing
a question and then assigning it to a set of pre-deﬁned cognitive levels based on
Bloom’s taxonomy. This module often consists of the preprocessing phase, word
embedding, and classiﬁer stage (Fig. 2).
• Preprocessing
Preprocessing is the process of preparing the text for classiﬁcation. It transforms text
to a more suitable form so that the algorithms can perform better.
Each question has to go through a series of steps such as normalization, tokeniza-
tion, POS tagging, and lemmatization. In normalization, unwanted data such as
punctuation marks,non-English characters, etc. are removed. Stop words can also
be removed in this stage. After performing normalization, the result is given to the

Qgen: An Automatic Question Paper Generator
559
Fig. 2 Architecture of question classiﬁcation module
tokenization stage. Here the question is split into individual words based on whites-
paces [9]. The resulting form is called tokens. Then the tokens are passed to the POS
tagging stage where the words are assigned with their appropriate POS tags. The
output is given to the lemmatization stage where the sufﬁxes are removed and return
the base or the dictionary form of the word.
• Word Embedding
Word embedding is one of the most popular representations of document vocabu-
lary. It is the vector representation of a particular word. The Word embed format
usually attempts to map the world using a dictionary in vector. Word2Vec is one
of the most popular ways to learn embedding. It is an algorithm that accepts the
text corpus as inserting and issuing a vector representation on each word [10]. One
of the beneﬁts of this approach is that it is possible to learn efﬁciently for words
with high-quality embedding. It is not a single algorithm but a combination of two
strategies—CBOW (Continuous Wallet) and the Skip-gram model. Both of these
techniques study weights that serve as word representations.
The output of the preprocessing phase is served as an input to the word embedding
stage. Words with similar meanings will be represented in the same manner in the
vector space. These words are the vector representations of ﬂoating-point numbers.
Finally, the vectorized words are then given to the classiﬁer.

560
A. Paul et al.
Fig. 3 The idea of LSTM [12]
• LSTM Classiﬁer
LSTM is an advanced form of RNN as it overcomes the vanishing gradient problem
in RNN [11]. Unlike standard feedforward neural networks, LSTM has feedback
connections. It can not only process single data points but also entire sequences of
data. It processes data passing on information as it propagates forward. Operations
within LSTM cells allow it to keep or forget information. The information in an
LSTM cell is regulated using three different gates, a forget gate, an input gate, and
an output gate. Forget gate is used to keep the information from the previous steps,
the input gate determines which information should be added from the current step
and the output gate is used to determine the next hidden state (Fig. 3).
Each term T i is ﬁrst converted to a compatible vector xi input using the Word2Vec
model and installation in each LSTM. Each time j, the output in W of the hidden
layer Hj will be distributed back to the hidden layer with the following insert xj + 1
in the next location of time j + 1. Finally, the ﬁnal output Wn will be placed in the
output layer.
Here the LSTM model classiﬁes questions to their appropriate cognitive levels
such as knowledge, comprehension, application, analysis, synthesis, evaluation.
3.3
Pictorial Representation
A pictorial graph representation that depicts the contribution of different cognitive
levels in a question paper can also be generated. It can be represented as either a
bar graph or a pie chart. This can be done using the chart.js library. Chart.js is a

Qgen: An Automatic Question Paper Generator
561
Javascript library used for including animated and interactive graphs. This helps the
question paper review committee to get an overview of the different cognitive levels
and their distribution in a question paper.
4
˙Implementation
WehaveusedYahyaetal.(2012)dataset.Itconsistsof600questions.Questionsalong
with their corresponding cognitive levels are present in the dataset. The different
cognitive levels present in the dataset are knowledge, comprehension, application,
analysis, synthesis, evaluation.
There are several things to do in the model training phase. First, the questions are
passed to the preprocessing stage. The output is given to the word2vec and each word
in the question is converted to its corresponding vector of ﬂoating-point numbers.
After that, we padded the input questions so that they are all of the same lengths for
modeling. The model will learn that zero values used for padding do not contain any
information. Same length vectors are required to perform computation in Keras but
they are not of the same length in terms of content.
We need to split the data into train/test. 70% of the questions of Yahya et al.
(2012) dataset are used for training and the remaining 30% for testing. After these
steps, we pass the output to the LSTM model. The ﬁrst layer is the Embedded layer
that uses 32 length vectors to represent each word. The next layer is the LSTM
layer with 100 memory units. Finally, we use a Dense output layer with a single
neuron as it is a classiﬁcation problem and a softmax activation function to make
multiple level predictions. The predictions are different cognitive levels such as
knowledge, comprehension, application, analysis, synthesis, and evaluation. Cate-
gorical_crossentropy in Keras is used as the loss function. ADAM algorithm is used
for optimization, as it is the best optimization algorithm.
In addition to that, we passed the output obtained after preprocessing to the GRU
model. It is a standard RNN which uses an update gate and reset gate. Basically,
these are two vectors that decide what information should be passed to the output.
The specialty about them is that they can be trained to keep information from long
ago, without washing it through time or removing information that is irrelevant to
the prediction.
5
Results
GRU model gives an accuracy of 86% for training and an accuracy of 82% for testing.
It gives a loss of 0.1992. The LSTM model gives an accuracy of 87% for training
and an accuracy of 85% for testing. It gives a loss of 0.1127 (Figs. 4 and 5).
It is found out that, for the available datasets, LSTM gives comparatively better
accuracy.

562
A. Paul et al.
Fig. 4 Output accuracy of LSTM Model
Fig. 5 Output loss of LSTM model
6
Conclusion
Existing systems mainly prefer rule-based approaches for classifying questions to
their appropriate cognitive levels. Some of them use pre-tagged repositories to
generate question papers. These approaches will only result in a great workload
for teachers as most of the work is done manually and also the result may not be

Qgen: An Automatic Question Paper Generator
563
that accurate. The result can be improved if the meaning of the question is also
considered.
Our proposed solution is a web application that automatically generates question
papers with several features like user-entered speciﬁcation. It sets questions auto-
matically based on these speciﬁcations. The meaning of the question is also taken
into consideration. The model also helps in creating different sets of question papers
containing unique questions. We have also considered the importance of pictorial
representation of the percentage of various cognitive levels present in the question
paper. It reduces the burden of generating multiple question papers with unique
questions for the teachers and also reduces the consumption of their valuable time.
7
Discussions and Future Scope
It is really time-consuming for teachers to manually tag each question to their appro-
priate cognitive level and our model simpliﬁes this problem. Even though our model
is well functioning, there is still scope for more enhancements that can make it
more useful. Question repositories can be shared among teachers having similar
domains of expertise. Thus they can easily prepare different sets of question papers
as they have access to a sufﬁcient number of questions. There also arises a difﬁculty
in mapping questions with mathematical equations to their appropriate cognitive
levels. Innovative methods can be incorporated to solve such issues.
References
1. Haris, S. S., & Omar, N. (2012). A rule-based approach in Bloom’s Taxonomy question
classiﬁcation through natural language processing. In 2012 7th International Conference on
Computing and Convergence Technology (ICCCT) (pp. 410–414).
2. Gangar, F. K., Gori, H. G., & Dalvi, A. (2017). Automatic question paper generator system.
International Journal of Computer Applications, 166, 42–47.
3. Nalawade, G., & Ramesh, R. (2016). Automatic generation of question paper from user entered
speciﬁcations using a semantically tagged question repository. In 2016 IEEE Eighth Interna-
tional Conference on Technology for Education (T4E) (pp. 148–151), Mumbai. https://doi.org/
10.1109/T4E.2016.038.
4. Ilango Sivaraman, S., & Krishna, D. (2015). Bloom’s taxonomy—application in exam papers
assessment. International Journal Of Multidisciplinary Sciences and Engineering, 6(9).
5. von Konsky, B., Zheng, L., Parkin, E., Huband, S., & Gibson, D. (2018). Parts of speech in
bloom’s taxonomy classiﬁcation.
6. Kanakaraddi, S. G., & Nandyal, S. S. (2018). Survey on parts of speech tagger techniques. In
2018 International Conference on Current Trends towards Converging Technologies (ICCTCT)
(pp. 1–6). https://doi.org/10.1109/ICCTCT.2018.8550884.
7. Tian, Y., & Lo, D. (2015). A comparative study on the effectiveness of part-of-speech tagging
techniques on bug reports. In 2015 IEEE 22nd International Conference on Software Analysis,
Evolution, and Reengineering (SANER). https://doi.org/10.1109/SANER.2015.7081879.

564
A. Paul et al.
8. Sutskever, I., Martens, J., & Hinton, G. E. (2011). Generating text with recurrent neural
networks. In Proceedings of the 28th International Conference on Machine Learning
(ICML-11) (pp. 1017–1024).
9. Wang, Y. (2017). A new concept using LSTM neural networks for dynamic system identiﬁca-
tion. In 2017 American Control Conference (ACC) (pp. 5324–5329). https://doi.org/10.23919/
ACC.2017.7963782.
10. Yang, S. (2020). LSTM and GRU neural network performance comparison study. In
International workshop on electronic communication and artiﬁcial ıntelligence (IWECAI).
11. Mohammed, M., & Omar, N. (2020). Question classiﬁcation based on Bloom’s taxonomy
cognitive domain using modiﬁed TF-IDF and word2vec. PLosONE, 15(3):e0230442. https://
doi.org/10.1371/journal.pone.0230442.
12. Wang, J., Liu, T., Luo, X., & Wang, L. (2018). An LSTM approach to short text sentiment
classiﬁcation with word embeddings. ROCLING.

Fundamental Frequency Extraction
of Noisy Speech Using Exponent
Enhancement in Weighted
Autocorrelation
Md. Saifur Rahman and Nargis Parvin
Abstract This research proposes a powerful method for extracting fundamental
frequencies from speech in noisy environments that is more successful for speech
processing applications. This work discusses a noise-resistant method for funda-
mental frequency extraction based on an exponent augmentation in the weighted
autocorrelation function. To demonstrate the greater accuracy for fundamental fre-
quency extraction, we focus on the exponent of the magnitude difference function.
According to experimental results, proposed approach’s presentation in noisy situ-
ations provides an unequaled presentation compared to the conventional technique
when an appropriate exponent is used.
Keywords Fundamental frequency · Weighted autocorrelation function ·
Autocorrelation · Magnitude difference function · Exponent
1
Introduction
Vibration of vocal cord produces the fundamental frequency of speech. This trade-
mark is particularly well suited to speech processing domains for example speech
analysis-synthesis, speech coding, speech enhancement, and speaker identiﬁcation
in speech signals. These frameworks are essentially inﬂuenced by the extraction
exactness of fundamental frequency. A large portion of the fundamental frequency
extraction strategies is primarily found on the time domain approach, frequency
domain approach and the both domains approach. They are performed productively
with clean speech [1, 2].
Md. S. Rahman (B)
Comilla University, Cumilla, Bangladesh
e-mail: saifurice@cou.ac.bd
N. Parvin
Bangladesh Army International University of Science and Technology, Cumilla Cantonment,
Cumilla, Bangladesh
e-mail: nargis@baiust.edu.bd
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_44
565

566
Md. S. Rahman and N. Parvin
Fundamental frequency extraction is a challenge, when speech signals are pol-
luted by noise. In noisy environment, the noisy speech cannot maintain the periodic
structure. Therefore, it is more hard to extract the more accurate pitch peak. The auto-
correlation function (ACF) [3] and average magnitude difference function (AMDF)
[4] are two of the most commonly used fundamental frequency extraction methods
which show adequacy against noise. The ACF utilizes similar arrangement of input
samples of a signal, which correlates with itself by its moved postponement. On the
other hand, AMDF shows the contrast between original input speech and its post-
poned variant, which presents the almost similar behavior of ACF. In [5], correntropy
is created by using the properties to the ACF, and a transformation function is con-
sidered for protecting the qualities of the periodicity in a signal, which is profoundly
viable for basic fundamental frequency extraction. Correntropy likewise utilizes the
higher order statistics to upgrade the goal of fundamental frequency extraction.
In [6], weighted autocorrelation function (WAF) is carried out which depends
on ACF and weighted by the inverse of AMDF. The major fundamental frequency
extraction precision of WAF is superior to that of the regular ACF, where weighting
reinforces are featured to upgrade the more exact peak in highly noisy environment.
Generally, the exhibition of the ACF-based fundamental frequency extraction strate-
gies is debased with the inﬂuence of vocal tract properties.
For lessening the vocal tract impact from speech signal, the cepstrum (CEP)
technique [7] shows the great inclination in frequency domain. The fundamental
frequency is recovered in CEP by using the Fourier transform of the logarithmic
spectrum in a signal. Resulting in that the CEP strategy diminishes the vocal tract
attributes. When the CEP is exposed to clear speech, it performs well; however,
when it is exposed to noise, it performs poorly. Improved versions of the problem
are addressed in [8], which is represented as MCEP. CEP based techniques do not
perform well absolutely in noisy environments, because the noisy speech harmonics
are inﬂuenced to the clean speech harmonics in the frequency domain.
Recently, two state-of-the-art approaches have been addressed [9, 10]. In [9],
PEFAC strategy is created, where a pitch assessment channel is used to decrease the
impact of commotion attributes. Bringing about that the smooth force range is gotten.
PEFAC also use the amplitude compression approach to improve noise robustness.
BaNa [10], on the other hand, takes into account noisy speech peaks and picks the
ﬁrst ﬁve spectral peaks in the speech signal’s amplitude spectrum. To explore the
harmonic peaks and extract the pitch from the candidates, BaNa employed a hybrid
pitch detection algorithm that calculated harmonic ratios.
We suggest an updated weighted function in this paper, using ACF and an expo-
nent enhancement of the magnitude difference function in the WAF for fundamental
frequency extraction. In the magnitude difference function, an appropriate value of
the exponent is used to take out the noise impact, just as to acquire the accurate time
period in noisy conditions. As a result, the updated weighted function is proposed
to improve the extraction accuracy. In noisy environments, this approach likewise
emphasizes the true peak, while suppressing the noise effect.
The rest of this paper is divided into the following manner. Proposed method-
ology is described in Sect.2. The trial condition and preliminary experiments for

Fundamental Frequency Extraction of Noisy Speech Using Exponent …
567
the proposed technique are shown in Sect.3. After that we analyze the exhibition
of the proposed technique with that of the conventional methods by the exploratory
outcomes. Finally, in Sect.4, we bring this paper to a close.
2
Proposed Method
Let, s(n) and v(n) denote the clean speech signal and noise, respectively. Then, the
noisy speech signal, y(n) is deﬁned as
y(n) = s(n) + v(n).
(1)
The WAF [6] deﬁned as the product of the ACF and the inverse of the AMDF. These
are represented as numerator and denominator part, respectively, in WAF. In the
proposed method, we keep the properties of ACF and focus on the modiﬁcation of
the power of AMDF in the WAF.
The proposed function is given by
ρ(ζ) =
R(ζ)
A(ζ) + δ
(2)
To avoid division by zero, use a tiny positive constant δ. The two functions in the
right-hand side, R(ζ) and A(ζ), are calculated as,
R(ζ) = 1
M
M−1−ζ

n=0
y(n)y(n + ζ)
(3)
A(ζ) = 1
M
M−1−ζ

n=0
|y(n) −y(n + ζ)|P,
(4)
respectively, where M is the length of the frame, P represented as power factor, and ζ
is the lag number from 0 to M −1. The ACF calculates the fundamental time period
based on the location of the second highest peak in relation to the highest peak (at
ζ = 0). For P = 1 case, A(ζ) in (4) corresponds to the AMDF [4], which is expected
to have a strong minimum value, when y(n) is similar with y(n + ζ). on the other
hand, to estimate the fundamental time period, the AMDF technique calculates the
second minimum location.
Figure1 shows the waveform of AMDF of the speech signal at different levels of
SNRs. From Fig.1, we see that the notch points are not so accurate in low SNR cases
of white noise addition. Background noise has a signiﬁcant impact on the magnitude
of AMDF’s global minimum. As a result, the extraction error increases signiﬁcantly.

568
Md. S. Rahman and N. Parvin
0
20
40
-5dB
0
20
40
0dB
0
20
40
Amplitude
5dB
0
20
40
10dB
0
50
100
150
200
250
300
350
400
450
500
0
50
100
150
200
250
300
350
400
450
500
0
50
100
150
200
250
300
350
400
450
500
0
50
100
150
200
250
300
350
400
450
500
0
50
100
150
200
250
300
350
400
450
500
0
20
40
20dB
True fundamental frequency
Fig. 1 Behavior of waveform of AMDF for different values of SNR
Figure2 shows the waveform calculated by the P-th power of AMDF, A(ζ), of a
voiced frame of speech in white noise. Using the exponential process of magnitude
difference signal in (4) expands the range of the input signal, and makes sufﬁcient
difference between the speech and the noise. As a result, the accuracy and consistency
of fundamental frequency extraction can be improved. In Fig.2, we observe that the
second minimum location is more accurate to extract the fundamental time period
by the increases of the power factor P. From the above observations, we realize that
the extraction accuracy is improved by adjusting the power factor P according to the
noise type and intensity, which is a common idea with that in [11, 12].
The ACF, which is the numerator part of the proposed function, is ﬁrst computed.
We compute the power of magnitude difference function in the denominator and add
δ to prevent division overﬂow. We take the best appropriate power factor P from
preliminary testing as the denominator. ρ(ζ) in (2) is expected to enhance the real
peak, while suppressing false peaks and noise components.

Fundamental Frequency Extraction of Noisy Speech Using Exponent …
569
0
500
1000
P=0
0
50
100
P=1
0
2
4
Amplitude
P=3
0
0.2
0.4
P=5
0
0.05
P=7
Max notch=True fundamental frequency
Max notch
True fundamental frequency
0
50
100
150
200
250
300
350
400
450
500
0
50
100
150
200
250
300
350
400
450
500
0
50
100
150
200
250
300
350
400
450
500
0
50
100
150
200
250
300
350
400
450
500
0
50
100
150
200
250
300
350
400
450
500
Fig. 2 Behavior of waveform of AMDF for different values of P
3
Experimental Results and Discussion
Experiments were conducted using speech signals recorded at a rate of 10 [kHz]
and spoken by four Japanese male and female speakers. The speech materials are
11 [s] long sentences derived from NTT Advanced Technology Corporation’s NTT
database[13].WeusetheKEELE[14]database,whichcontainstenEnglish-speaking
speakers. Ten speakers’ speeches are approximately 6 [m] in duration. The speech
signals were analyzed at a rate of 16 [kHz]. The experiments were carried out by
adding white Gaussian noise to the speech signals. The SNR was set to −5, 0, 5, 10,
15, 20 [dB], with the following trial conditions:
• Except for PEFAC and BaNa, frame length is 51.2 [ms].
• The frame shift is 10.0 [ms];
• Rectangular is the window function.;
• The band limitation of LPF is 3.4 [kHz];
• Except for PEFAC and BaNa, DFT (IDFT) length is 1024 points for the NTT
database and 2048 points for the KEELE database.

570
Md. S. Rahman and N. Parvin
Based on Rabiner’s approach [2], the following error parameter er(m) was used
to evaluate fundamental frequency extraction accuracy.
er(m) = F1(m) −F2(m),
f or
m = 1, 2, . . . , k
(5)
where k denotes the number of frames in the utterance, and F1(m) and F2(m) denote
the fundamental frequency derived from noisy speech and the true fundamental fre-
quency at the mth frame, respectively. As a result, in (5), er(m) denotes an extraction
error. We identiﬁed the error as gross pitch error (GPE) if |er(m)| > 10[%] from
the ground true fundamental frequency. For the extraction of the fundamental fre-
quency, we only looked at voiced sections of sentences. To obtain the fundamental
frequency, search range of fmax = 50 [Hz] and fmin = 400 [Hz] is used, which most
of the people provides the same range.
3.1
Preliminary Experiments
Setting the better power factor per measure of noise is important for the proposed
method. Then, in order to decide the best coefﬁcient of power, we perform the
fundamental trials. In this work, we extract the fundamental frequency by using just
the denominator component, just the numerator part, or both. The precision of the
proposed technique relies upon the difference in the parameter per measure of the
noise. Here, we select the worth of power coefﬁcients from 1 to 7, which is more exact
with the measure of noise. In the event that the power factor of denominator part is
1, it shows the conduct as AMDF. Figures3 and 4 show the connection between the
power factor of denominator part and the average GPE for male speakers and female
speakers, respectively. Exhibition of the average GPE relies upon the power factor of
each part. For male speakers in Fig.3, the power factor P with the value of 5 shows
the better extraction exactness at the low SNR levels aside from the high SNR level
from 0 [dB] to 20 [dB]. At the high SNR level, the power factor P = 2 gives lower
blunder rate than different upsides of P. Likewise, the average GPE rate of the value
of power factor from 4 to 7 is practically comparative at −5 [dB]. Figure4 shows
a wonderful improvement of average GPE when the power factor P increments. As
per the test result, it very well may be seen that the average GPE diminishes with the
increments of power factor P in almost all low SNR levels in both speakers.
3.2
Performance Comparison
Figures5, 6, 7, and 8 show the average GPE results of male and female speeches
with white noise in NTT and KEELE databases, respectively. NTT database has no
ground truth fundamental frequency. On the other hand, in the KEELE database,

Fundamental Frequency Extraction of Noisy Speech Using Exponent …
571
-5
0
5
10
15
20
SNR [dB]
0
10
20
30
40
50
Average GPE (%)
P=1
P=2
P=3
P=4
P=5
P=6
P=7
Fig. 3 Connection among P and average GPE at various SNRs for male speakers
-5
0
5
10
15
20
SNR [dB]
0
10
20
30
40
50
Average GPE (%)
P=1
P=2
P=3
P=4
P=5
P=6
P=7
Fig. 4 Connection among P and average GPE at various SNRs for female speakers

572
Md. S. Rahman and N. Parvin
-5
0
5
10
15
20
SNR [dB]
0
10
20
30
40
50
Average GPE (%)
WAF
PEFAC
BaNa
PROP
Fig. 5 Average GPE of proposed method with conventional methods at white noise in NTT database
(male speakers)
-5
0
5
10
15
20
SNR [dB]
0
10
20
30
40
50
Average GPE (%)
WAF
PEFAC
BaNa
PROP
Fig. 6 Average GPE of proposed method with conventional methods at white noise in NTT database
(female speakers)

Fundamental Frequency Extraction of Noisy Speech Using Exponent …
573
-5
0
5
10
15
20
SNR [dB]
0
10
20
30
40
50
Average GPE (%)
WAF
PEFAC
BaNa
PROP
Fig. 7 Average GPE of proposed method with conventional methods at white noise in KEELE
database (male speakers)
-5
0
5
10
15
20
SNR [dB]
0
10
20
30
40
50
Average GPE (%)
WAF
PEFAC
BaNa
PROP
Fig. 8 Average GPE of proposed method with conventional methods at white noise in KEELE
database (female speakers)

574
Md. S. Rahman and N. Parvin
at each frame, the fundamental frequency’s ground truth information is supplied.
In the proposed method, we used the optimal value of power factor P = 5 from
the preliminary experiments, because the error rate is decreased by the increases of
the power factor. The proposed method is compared to the conventional methods of
PEFAC [9], BaNa [10], and WAF [6] in white noise.
With the exception of the frame length, DFT(IDFT) points, window function
of PEFAC, and BaNa, the experimental of traditional approaches are unaltered in
proposed technique. For PEFAC, we employed the Hamming window function with
a frame length of 90 [ms] as suggested in [9]. The DFT (IDFT) points were 213,
and the source code used them. PEFAC source code was taken from [15]. For the
BaNa, we employed the Hanning window function with a frame length of 60 [ms].
According to the theory in [10], the DFT (IDFT) points were 216. The BaNa source
code was taken from [16].
From Fig.5, it is evident that at every SNR setting, the proposed method’s per-
formance has the smallest average GPE [%] rate among the other three approaches.
In Fig.6, it is observable that the average GPE [%] of the proposed method is signif-
icantly superior to the PEFAC and WAF methods over all SNR cases, except for the
SNR level of −5 [dB] in BaNa. BaNa performs marginally better than the proposed
technique at low SNR (−5 [dB]) for female speech. At low SNRs, the noise peaks
have a signiﬁcant impact on the true peak. As a result, peak extraction becomes more
difﬁcult. In this case, BaNa gains an advantage by selecting the ﬁrst ﬁve spectral
peaks. After that fundamental frequency is extracted accurately by depending on a
post-processing on the noisy speech spectrum.
In this part, we utilized the KEELE database for approving the exhibition of
the proposed method in noisy environment. Figures7 and 8 show the average GPE
rate for male and female speakers, separately. However, ground truth values of the
fundamental frequency for KEELE data set are given from the laryngograph signals.
We looked at the ground truth values and discovered a few discrepancies. Along these
lines, the ground truth values are not all that precise. This shows up in the resulting
GPE rates at high SNR (20 [dB]).
Figure7 indicates an almost similar tendency for all methods to be compared with
Fig.5. Figure8 is also similar with Fig.6 from a performance comparison aspect. For
each speaker, the factor P has a major effect on the success of the proposed technique.
If we consider P = 1 in (4), the proposed method behaves as like the WAF.
4
Conclusion
A noise-resistant fundamental frequency extraction method based on WAF is pro-
posed in this paper. The proposed method is satisfactory for fundamental frequency
extraction of speech signals in noisy environments, as evidenced by lower GPEs
in experiments. The performance of the proposed method is powerful by using the
ACF in the numerator part and by changing the power factor of magnitude difference
signal.

Fundamental Frequency Extraction of Noisy Speech Using Exponent …
575
References
1. Hess, W. (1983). Pitch determination of speech signals. Springer.
2. Rabiner, L. R., Cheng, M. J., Rosenberg, A. E., & McGonegal, C. A. (1976). A comparative
performance study of several pitch detection algorithms. IEEE Transactions on Acoustics,
Speech, and Signal Processing, 24(5), 339–417.
3. Rabiner, L. R. (1977). On the use of autocorrelation analysis for pitch detection. IEEE Trans-
actions on Acoustics, Speech, and Signal Processing, 25(1), 24–33.
4. Ross, M. J., et al. (1974). Average magnitude difference function pitch extractor. IEEE Trans-
actions on Acoustics, Speech, and Signal Processing, 22(5), 353–362.
5. Xu, J. W., & Principle, J. C. (2008). A pitch detector based on a generalized correlation function.
IEEE Transactions on Audio, Speech, and Language Processing, 16(8), 1420–1432.
6. Shimamura, T., & Kobayashi, H. (2001). Weighted autocorrelation for pitch extraction of noisy
speech. IEEE Transactions on Speech and Audio Processing, 9(7), 727–730.
7. Noll, A. M. (1967). Cepstrum pitch determination. The Journal of the Acoustical Society of
America, 41(2), 293–309.
8. Kobayashi, H., & Shimamura, T. (1998). A modiﬁed cepstrum method for pitch extraction.
In Proceedings of IEEE Asia-Pacifc International Conference on Circuits and Systems Micro-
electronics and Integrating Systems (APCCAS).
9. Gonzalez, S., & Brookes, M. (2014). PEFAC–A pitch estimation algorithm robust to high
levels of noise. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 22(2),
518–530.
10. Yang, N., Ba, H., Cai, W., Demirkol, I., & Heinzelman, W. (2014). BaNa: A noise resilient
fundamental frequency detection algorithm for speech and music. IEEE/ACM Transactions on
Audio, Speech, and Language Processing, 22(12), 1833–1848.
11. Motegi, S., & Shimamura, T. (2012). Extended fundamental frequency extraction using expo-
nentiated amplitude spectrum with band-limitation. International Journal of Computer and
Electrical Engineering, 4(4), 507–510.
12. Narita, M., & Shimamura, T. (2011) Exponentiated enhancement for fundamental frequency
extraction of noisy speech. IEEE International Symposium on Signal Process. and Information
Technology (pp. 342–346).
13. 20 Countries Language Database. (1988). NTT Advanced Technology Corporation, Japan.
14. Plante, F., Meyer, G., & Ainsworth, W. (1995). A fundamental frequency extraction reference
database. In Proceedings of Eurospeech (pp. 837–840).
15. Brookes, M. Voicebox toolkit [Online]. Available, www.ee.ic.ac.uk/hp/staff/dmb/voicebox/
voicebox.html.
16. Wcng, wireless communication networking group, [Online]. Available www.ece.rochester.edu/
projects/wcng/code.html.

Solar-Powered Multipurpose
Agro-Utility System
Vipin Bondre, Surabhi Pawar, Shatakshi Dixit, Shefali Thoolkar,
and Trupti Tale
Abstract Agriculture and farming have seen numerous modiﬁcations in recent
decades, with a special focus on technological improvements. For around 58% of
India’s population, agriculture is their primary source of income. As a result, the agri-
cultural industry needs change new ideas and their application in order to improve.
Drilling, sowing, pesticide spraying, and cutting are four important farming processes
that are addressed in this paper using a smart machine that is monitored via an RF-
based remote system. The iron plow tool is connected to the machine’s tool holder and
used to loosen the soil. Only one row of seeds is sowed and plowed at a time. Solar-
powered pesticide spraying produces no pollution. The top-mounted solar panel can
be tilted to the desired angle in relation to the sun. The major goal of this project is
to create the machine at a reasonable cost for farmers in order to boost crop yield
and quality while also optimizing human labor. In our work, we have presented
comparative analysis of proposed system with other existing system.
Keywords Agriculture · Solar · Automated system · Arduino UNO
1
Introduction
Agriculture is one of India’s most important occupations. Agriculture is extremely
important to the Indian economy. Over the last few decades, India’s agriculture has
grown at a rapid pace. Despite the fact that much work has been done in this subject,
it is critical to discover and implement new ideas. Unfortunately, these concepts are
not being fully implemented in the real world. This is because of the high expense,
and it is difﬁcult for individuals who live in remote areas. A multipurpose agriculture
machine, often known as a farming machine, is a basic and important machine used in
agriculture to maximize yields. The traditional method of plowing and seed planting
is a time-consuming process, and as a result, there is a manpower shortage. As
a result, many farmers in India rely on bullocks, horses, and he-buffalo for their
farming operations. In comparison with other countries in the world, this will not
V. Bondre (B) · S. Pawar · S. Dixit · S. Thoolkar · T. Tale
Yeshwantrao Chavan College of Engineering, Nagpur, MH, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_45
577

578
V. Bondre et al.
sufﬁcetomeettheenergyneedsofagriculture.Asaresult,agriculturecropproduction
procedures have been postponed in order to solve these challenges.
We believe that human and animal efforts can be substituted by advanced tech-
nology that is both cost-effective and time-efﬁcient for small-scale farmers. As a
result, a multipurpose agricultural machine has been built to meet all of these needs
while also solving the labor problem. Seed sowing and hole drilling for plantation,
solar-powered insecticides and pesticides sprayer, wireless operation utilizing RF
remote control, weed remover, and crop cutter are among the ﬁve tasks performed
by the multifunction farming equipment. Everything in our system will be controlled
remotely. The procedure will be carried out row by row, one row at a time. Our system
will handle the entire operation, including hole drilling, seed sowing, insecticide and
pesticide spraying, weed eradication, and crop cutting.
2
Problem Statements
In the current situation, most countries lack sufﬁcient skilled labor, particularly in
the agricultural sector, which has negative impact on emerging countries’ growth.
As a result, it is the moment to automate the sector in order to solve this problem.
It is critical to create and build an agricultural machine that can conduct many
operations concurrently in the ﬁeld of agriculture in order to reduce human efforts
in tedious job.
To create a smart, efﬁcient decision support system/machine that uses wireless
sensors and an automated method to manage different agriculture process-related
tasks and deliver meaningful information about the farm ﬁeld to the farmer, reducing
the usage of human labor, lowering overall costs, and producing more efﬁcient crops.
3
Literature Survey
Seeding and fertilization using automated robot: Using the above-mentioned
concept,amachineeffectivelyplantsandfertilizesenormousamountsoflandwithout
the need for human interaction. The technology used in this project is a hybrid of
robotics and artiﬁcial intelligence. As a country with an agriculturist economy, India
would beneﬁt signiﬁcantly from an invention that relieves small and large-scale
farmers of an additional load [1].
Smart sensors-based monitoring system for agriculture: It has been utilized
to boost plant output by monitoring environmental elements and giving farmers with
the appropriate information. The suggested method is primarily designed to beneﬁt
farmers. The advantages of a wireless sensor network over a wired one include the
ability to put it in any sort of setting for monitoring, as well as its ﬂexibility and
robustness [2].

Solar-Powered Multipurpose Agro-Utility System
579
The role of agricultural mechanization in the economic development for
small-scale farms In Adamawa State: It has been used to increase plant produc-
tivity by monitoring environmental factors and providing farmers with the necessary
information. The strategy proposed is primarily intended to aid farmers. The ability
to place a wireless sensor network in any type of monitoring situation, as well as its
ﬂexibility and robustness, are all beneﬁts of a wireless sensor network over a wired
one [3].
In agriculture system, IoT should be considered differently and should have
different approach in production of various crops. To overcome the problem the
authors presented the IoT-based system to monitor the crops at larger scale by
gathering environmental information [4].
In next paper, author deals with the constant discharge of pesticide. The mechan-
ical sprayer device is used with solar power DC batteries to store natural energy.
Once the sufﬁcient level of batteries were used, it starts spraying the pesticide. The
solar energy stored in the battery is used to operate the motor of the sprayer [5].
Currently in India former used conventional method for the crop cutting. The
conventional method for crop cutting is as manually cutting using labor but this
method is lengthy and time-consuming. In their analysis of speciﬁc ﬁeld crop cutter
machine for small height crop. To analysis cutting roller and horizontal cutting blade
by using Pro-e and anises software [6].
The autonomous robot is more efﬁcient in spraying the crop ﬁelds as compared
to manual traditional spraying. It is also hazardous in some health-related diseases.
Thus this particular fully equipped robot is set to spray the ﬁeld without any health
issues in green house [7].
The effectiveness of an automatic irrigation system is measured by comparing
plant growth to that of manually irrigated plants. Shoot, root, and total fresh and dry
weights are all growth parameters. The results revealed that the automatic irrigation
system performed well over time. As assessed by the performance of plants in terms
of photosynthesis rates, it’s a manual one [8].
The Internet of Things (IoT) is revolutionizing agriculture and empowering
farmers to confront the immense difﬁculties they face. Agriculture is being addressed
by new innovative IoT applications that improve the quality, quantity, sustainability,
and cost-effectiveness of agricultural output [9].
Recent advances in technologies that form the foundation of the Internet of Things,
such as Radio Frequency Identiﬁcation (RFID), wireless sensor networks, and cloud
computing addressing “things” on a shared network, as well as Cloud-based appli-
cations are those that run on a computer that is connected to the Internet. In the same
way, several works are presented that incorporate one or more of the IoT technologies
[10].
Digital farming is the use of modern technologies such as sensors, robotics, and
data analysis to automate tasks that were previously labor-intensive. This study exam-
ines some of the most recent advances in agricultural robots, focusing on autonomous
weed management, ﬁeld scouting, and harvesting [11].
Robotic systems have been introduced to the agricultural industry as a result of
the advancement of contemporary technology, which serves to boost productivity

580
V. Bondre et al.
and efﬁciency. Several studies have been carried out to increase the capabilities of
robots in assisting agricultural operations, leading to the development of autonomous
agricultural robots [12].
4
Objectives
• To minimize the amount of manpower necessary while simultaneously improving
crop quality and quantity.
• To minimize the amount of time spent on different agricultural tasks such as
drilling, planting, pesticide spraying, and so on.
• To decrease seed and fertilizer waste to a considerable extent, hence preventing
any contamination.
• Using solar power to save electricity and power used in these operations, lowering
total costs.
• Using RF technology and a remote control system, make this system function
without requiring line of sight.
• Reducing operating costs by adopting more innovative methods.
5
Methodology
I.
Seed Sowing/Hole Drilling
Spreading the seeds over the soil, separating seed germination, and putting the seeds
into the soil are the three primary phases in planting the seed. The two latter stages
take longer and need more effort to complete. It must be examined since it is a source
of concern. As a result, the goal was to design and manufacture a less cost, unique
attachment for the machine that could be employed quickly.
Basic Components:
The following components are used to build a seed sowing machine:
• Direct Current Motors (DC Motors): These are utilized in the model to drive the
front wheels, which then drive the distributer.
• Hoppers: They hold the seeds that will be planted in the soil. The higher the
capacity, the fewer frequently the hopper must be reﬁlled during the operation.
• Seed Distributor: It is made up of ﬂuted rollers that are operated by the rear wheel
through a belt and pulley system.
• Cultivator: The cultivator’s job is to tilt the soil to the proper depth so that the
seed may be distributed by the distributer mechanism.
• Belt and pulley drive: The machine uses a belt and pulley drive to transmit power
from the engine to the wheels, as well as drive the seed distributer (Fig. 1).
II.
Solar-Powered Insecticide Sprayer

Solar-Powered Multipurpose Agro-Utility System
581
Fig. 1 Schematic of seed sowing machine
Solar panels turn the sun’s rays into energy by stimulating electrons in silicon cells
using photons of light from the sun. This electricity may then be utilized to charge a
battery with renewable energy (Figs. 2 and 3).
III.
Wireless Operation-RF Remote Control
The major goal of this project is to develop a new system that uses RF technology
to manage many appliances. One of the most signiﬁcant advantages of an RF-based
remote control is that it may effectively operate appliances without the need for line
of sight within its designated range.
The transmitter is made up of two main parts: an encoder IC HT12E and an RF
transmitter module. The encoder IC has four ports, which are utilized to operate the
appliances through four input buttons.
On the receiver side, there is a decoder IC HT12D as well as an RF reception
module. When you push a button, the matching output port becomes active, which
activates the relay and controls the action.
Fig. 2 Block diagram of spraying system

582
V. Bondre et al.
Fig. 3 Design of solar
mounted pesticide spraying
mechanism
The HT 12E and HT 12D are encoder and decoder integrated circuits with a wide
range of applications in switching and wireless operation. This Rx/ Tx module has
four dedicated ports, one for each encoder and decoder, which are conﬁgurable as
input and output channels. Each of the input switches is set to operate a matching
relay, which is linked to a load (Figs. 4 and 5).
IV.
Weed Removal
Fig. 4 RF transmitter and receiver

Solar-Powered Multipurpose Agro-Utility System
583
Fig. 5 Transmitter block diagram
Weed control is one of the most time-consuming aspects of the farming process.
Manual weeding is inefﬁcient due to labor expenses, time, and tedium. The main
goal of the project is to create a basic weed cutter.
V.
Crop Cutting
In India, there are two types of crop cutters: manual (traditional) and mechanical
(mechanized). Crop cutting is a crucial stage in the agricultural industry. Currently,
the Indian former utilized the traditional way of crop cutting, which is physical work,
but this approach is quite time-consuming. Crop cutting will be less expensive if an
automated crop cutter is designed.
6
Components
1.
HT 12E and HT 12D IC’s
The HT12E IC can only be used in conjunction with the HT12D IC. Together,
these two ICs comprise an Encoder and Decoder pair. It’s a pair of 12-bit
encoders and decoders. However, an encoder IC should not connect with another
decoder IC, hence an Encoder and Decoder IC pair will share an 8-bit data
address.

584
V. Bondre et al.
2.
Arduino UNO
The Arduino Uno is a microcontroller board based on the Microchip
ATmega328P microprocessor that is open-source. The board has digital and
analog input/output (I/O) pins that may be used to connect to expansion boards
(shields) and other circuits.
3.
Relay
A relay is a switch that is controlled by electricity. A collection of input terminals
for a single or many control signals, as well as a set of functioning contact
terminals,makeupthedevice.Theswitchcanhaveanynumberofconnectionsin
anycontactform,includingmakeconnections,breakcontacts,andcombinations
of the two.
4.
Solar panels
Solar energy is undoubtedly the cleanest and most dependable renewable energy
source today. Solar-powered photovoltaic (PV) panels use photons of light from
the sun to excite electrons in silicon cells, converting sunlight into energy.
5.
Battery
Electrical energy is typically converted from mechanical energy, solar energy,
and chemical energy in the contemporary period. The term "battery" refers to a
device that turns chemical energy into electrical energy.
6.
Pump
A pump is a device that uses mechanical motion to transport ﬂuids. Pumps use
energy to do mechanical work by pushing ﬂuid through a device.
7.
Chassis frame
It is made up of a structure on which the various components are mounted. A
chassis frame is a component of a machine that includes the frame (on which
everything is mounted). A machine’s chassis is one of its most important compo-
nents. It is the portion of the machine that holds both the body and the head.
The chassis structure holds parts such as wheels, motors, hoppers, and spraying
systems.
8.
Digging tool
A digging tool device, sometimes known as a drill bit, consists of a rod with an
angled hook that drills the earth as the machine travels ahead. The mechanism
consists of a drill tool and its machine, and in this project, we are plowing the
ﬁeld with the machine’s forward push.
9.
Fertilizer tank
It is located between the batteries and the motors on the back of the chassis.
It’s attached to the machine’s praying mechanism and may hold either water or
insecticides.

Solar-Powered Multipurpose Agro-Utility System
585
7
Working
We use the IC HT12E for communications. The HT12E IC can only be used in
conjunction with the HT12D IC. RF or IR pairs are frequently employed with these
ICs.
Together, these two ICs comprise an Encoder and Decoder pair. They’re 12-bit
encoders/decoders, which means they can send and receive 12-bit data. However,
an encoder IC should not connect with another decoder IC, hence an Encoder and
Decoder IC pair will share an 8-bit data address. So, of the 12-bits, eight will be used
to set the address and the remaining four will be utilized to transfer data. We can
make 16 different sorts of combinations with 4-bit data (24 = 16) (Fig. 6).
The IC’s operational voltage ranges from 2.4 to 12 V, although the Vcc pin, which
is pin number 18, is usually powered by +5V and the grounded at pin number 9.
To engage transmission, pull the Transmission Enable pin (pin 14), which is linked
to ground. The IC requires an oscillator to decode data, therefore we connected the
OSC1 and OSC2 at pin 15 and 16 with a 750k resistor to activate it.
The pins A0 to A7 are used to set the 4-bit data that is provided to the pins AD8
to AD11, as well as an 8-bit address. It is critical that the encoder and decoder have
the same address in order to communicate with one another.
The Dout pin, which is pin number 17, may be used to extract the encoded 12-
bit data. This data is delivered to the HT12D decoding IC for decoding; it can be
delivered directly over a wire or over a wireless media (Fig. 7).
The HT12D’s job is to decode the 12-bit signal sent by the input pin. It is quite
simple to make this IC operate because it has an in-built oscillator. The IC is driven
Fig. 6 Transmitter

586
V. Bondre et al.
Fig. 7 Receiver
by a 5V supply at pin 18 and grounded at pin 9. The IC will need an oscillator to
decode data.
To invoke it, we linked the OSC1 and OSC2 at pins 15 and 16 with a 33K resistor.
Pins D8 to D11 may be used to acquire the 4-bit data received, while pins A0 to A7
may be used to create an 8-bit address. It is critical that the Decoder and Encoder
have the same address.
The decoded signal received from the receiver from pins D8 to D11 is fed into
the Arduino’s input pins D2 to D5, and the Arduino’s output is obtained from pins
D8 to D13 (Fig. 8).
8
Results and Discussion
Our results were obtained on manual, semi-automated and our fully automated
system. We have done comparative analysis of our proposed system with existing
manual system. Then we have done performance analysis with our system and
existing various semi-automated tools in market. In spite of this, we have also relative
comparative study on direct power and solar power system. The ﬁnal comparative
evaluation report is then presented on our proposed system and its effectiveness as
compare to all the existing available systems. These results were analyzed on survey
and we carried out with other existing system and evaluated our result by obtaining
statistical data.

Solar-Powered Multipurpose Agro-Utility System
587
Fig. 8 Arduino UNO
Power Consumption: As shown in Fig. 9, we have the analysis shows our system
is more compatible as compared to the various existing system. The power consump-
tion is very less as our system directly work on solar power batteries. In traditional
system, it required direct power from the power supply and it also consumes more
power. Its power consumption is 9% only in terms of batteries.
Labor: The labor requirement as per our proposed system is very less and it
required less time with more efﬁciency. If we compared our system with existing
system, our system required less man power per hector. It is up to two labor and
its constant for every hector, whereas in other system, it keeps on increasing per
hector. For manual and semi-automated system, it is keep on increasing as the land
is increased in per hector. It obtained evaluation is shown in Fig. 10.
Fig. 9 Power consumption per hector

588
V. Bondre et al.
Fig. 10 Labor per hector
Time: The other major performance parameter in our system is time stamp for
wheat crop. The time required in our system is comparatively very less as compared
to manual and semi-automated system. It requires less hours in time as compared
to traditional existing system. It analysis is shown in Fig. 11, where we can say our
system is less time-consuming and increases efﬁciency.
Overall Performance: The overall combined performance of the system is ﬁnally
evaluated using existing and our proposed system. The comparative analysis yields
that our proposed system performs well in every aspect and its productivity is measur-
ably increased as compared to other two systems. This performance rate evaluation
is shown in Fig. 12. The performance rate of our proposed system is more.
Conclusion: The technology we propose is hybrid agricultural system that will
run on solar power. It will be a semi-automated system with some changes and
advancements in comparison with current system. This technology will totally auto-
mate all aspects of agricultural ﬁeld operations and will run on solar power. In terms
of seeding, undesirable grass removal, and power independence, this system will
Fig. 11 Time per hector

Solar-Powered Multipurpose Agro-Utility System
589
Fig. 12 Performance rate per Hector
be more efﬁcient and trustworthy for farmers. On a bigger scale, the system will
boost crop quality and yield in future. Thus, our results show improved results when
compared with other existing system. In future, this work can be extended with
various new technology which will give high performance result and may increase
the crop production.
References
1. Lee, M., Hwang, J., & Yoe, H. (2013). Agricultural production system based on IoT. In
2013 IEEE 16th International Conference on Computational Science and Engineering (CSE)
(pp. 833–837). IEEE.
2. Chavan, R., Hussain, M., Mahadeokar, S., Nichat, S., & Devasagayam, D. (2015). Design
and construction of solar powered agricultural pesticide sprayer. International Journal of
Innovations & Advancement in Computer Science, 4(4).
3. Avatade, P. G., Deshmukh, P. V., Sakhare, A. M., Shinde, A. J., Patil, J. M. (2013). Android
based appliances control system. International Journal of Emerging Technology and Advanced
Engineering, 3(12), 681–683.
4. Chavan, P. B., Patil, D. K., Dhondg, D. S. (2015). Design and development of manually operated
reaper. Journal of Mechanical and Civil Engineering (IOSR-JMCE), 12(3) Ver. I, 15–22. ISSN:
2278-1684, p-ISSN: 2320-334X
5. Celen, I. H., Onler, E., & Kilic A. E. (2015). Design of an autonomous agricultural robot to
navigate between rows. In International Conference of Electrical, Automation and Mechanical
Engineering (EAME 2015), © 2015: Atlantis Press.
6. Bakker, T., van Asselt, K., Bontsema, J., Muller, J., & van Straten, G. (2010). Systematic design
of an autonomous platform for robotic weeding. Journal of Terramechanics, 47, 63–73.
7. Sammons, P.J., Furukawa, T., & Bulgin, A. (2005). Autonomous pesticide spraying robot for
use in a green-house. In Proceedings of the Australasian Conference on Robotics & Automation,
Australia.
8. Boutraa, T., Akhkha, A., Alshuaibi, A., & Atta, R. Evaluation of the effectiveness of an auto-
mated irrigation system using wheat crops. In Agriculture And Biology Journal of North
America. ISSN Print: 2151-7517, ISSN Online: 2151-7525, https://doi.org/10.5251/abjna.
2011.2.1.80.88.

590
V. Bondre et al.
9. Satish, T., Bhavani, T., & Begum, S. (2017). Agriculture productivity enhancement system
using IOT. International Journal of Theoretical and Applied Mechanics, 12(3), pp 543–554.
ISSN 0973-6085.
10. Tzounis, A., Katsoulas, N., Bartzanas, T., & Kittas, C. (2017). Internet of Things in agriculture,
recent advances and future challenges. In Article in Biosystems Engineering. https://doi.org/
10.1016/j.biosystemseng.2017.09.007.
11. Shamshiri, R. R., Weltzien, C., Hameed, I. A., Yule, I. A., Grift, T. E., Balasundram, S. K.,
Pitonakova, L., Ahmad, D., & Chowdhary, G. (2018). Research and development in agricultural
robotics: A perspective of digital farming. International Journal of Agricultural and Biological
Engineering.
12. Rahmadian, R., & Widyartono, M. (2020). Autonomous robotic in agriculture: a review. In 2020
Third International Conference on Vocational Education and Electrical Engineering (ICVEE).
IEEE, October 3–4 2020.

A Performance Analysis of Supervised
Machine Learning Techniques
for COVID-19 and Happiness Report
Dataset
Syed Abu Farooq and Selvanayaki Kolandapalayam Shanmugam
Abstract Researchers and scientists from all over the world have been working to
ﬁnd the cure for the severe acute respiratory disease, coronavirus, since the start of
an epidemic in Wuhan, China. Governments all over the world are taking unprece-
dented measures to slow the spread of the coronavirus disease 2019 pandemic, which
is caused by the serious acute respiratory syndrome (SARS-CoV-2). Many policies,
such as school closings and population conﬁnement, impose signiﬁcant and notice-
able costs on society. This report focuses to analyze the data in which we have merged
two datasets, happiness report dataset which shows the data that how much citi-
zens have freedom. The second dataset considered here is COVID-19 dataset which
has conﬁrmed cases grouped by different countries. This system applies different
machine learning algorithms which includes linear regression, logistics regression,
support vector machine (SVM), Naive Bayes (NB), and K-nearest neighbor (KNN),
and their performance metrics are analyzed. Based on the experimental results and
discussion, the best algorithm is identiﬁed and concluded in the study.
Keywords Epidemic · Freedom · Regression · Machine learning · Conﬁnement
1
Introduction
In Wuhan, Hubei Province, China, a serious respiratory illness was recently observed.
SincetheﬁrstpatientwasadmittedtothehospitalonDecember12,2019,atleast1975
cases had been reported as of January 25, 2020. The outbreak may have been linked
to a ﬁshing market in Wuhan, according to epidemiological studies. Governments
all over the world are taking unprecedented measures to slow the spread of the
coronavirus disease 2019 pandemic, which is caused by serious acute respiratory
syndrome (SARS-CoV-2). Many policies, such as school closings and population
conﬁnement, impose signiﬁcant and noticeable costs on society. The paper highlights
the data which have been merged with two datasets one is the happiness report
which shows the data that how much citizens have freedom and the second is a
S. A. Farooq (B) · S. K. Shanmugam
Concordia University Chicago, River Forest, Chicago, Illinois, USA
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_46
591

592
S. A. Farooq and S. K. Shanmugam
COVID-19datasetwhichhasconﬁrmedcasesgroupedbythecountrythatwillhelpus
identify whether more freedom given by countries resulted in more COVID-19 cases
or having more conservative and stricter policies helped having a smaller number
of cases [1–4]. As per the data gathered in the report, there is an implementation
of machine learning algorithms and analyzes their accuracy which includes SVM,
linear regression, logistics regression, Naive Bayes, and KNN in order to predict the
future number of cases. The major policies implemented globally includes closing
of educational institutes, banning on large public gatherings, mask compulsory, and
maintaining social distancing [5]. The frequent spread of COVID-19 changed the way
of living both in private and public manner. However, these policies also inﬂuenced
the mental health of the people and a drastic change noticed on the economy all
around the globe, as a result of this people are reluctant to follow the government
guidelines [6]. The pandemic not only effected the health of the people, but it also
created problem in personal relationships with partner and parents with children.
Researchers found that COVID-19 hitting people mental health in various ways
and found a signiﬁcant reason to make person stressed and depressed [7]. ˙In this
document, we studied and found that government policies in the time of COVID-
19 plays an important factor to impact happiness report globally. Further, it has
been studied by using algorithms of machine learning that global happiness factor
inﬂuences the multiplication of COVID-19 cases.
2
Literature Review
The world was hit by a life-threatening pandemic on the 12th of December 2019
named coronavirus disease (COVID-19). Researchers found that this deadliest
disease is caused by severe acute respiratory syndrome coronavirus 2; it is also
known as (SARS-CoV-2). Past studies showed that the ﬁrst outbreak of this virus
started from a local Sea Market located in the city of China named Wuhan. The
most common symptoms of COVID-19 are fever, dry cough, and in acute condi-
tion difﬁculty in breathing which leads to death. Furthermore, researchers found that
people with old age and people with chronic diseases are more affected and died.
Scientists found that there are different methods to test and diagnose the disease such
as RT-PCR and Serological Test. However, studies showed that this COVID-19 has
pneumonia-like symptoms and assume that it is originally transmitted from bats to
humans.
Research scholars found that the disease is associated with the respiratory disease
while researching a patient who was admitted to Central Hospital of Wuhan. Symp-
toms shown on the patient were closely studied and found that COVID-19 is an
acute type of respiratory disease that damages the lungs. Since the disease caused
by SARS-CoV-2 has broken out, scientists and researchers all over the world are
engaged in ﬁnding the cure of this disease along with ﬁnding and implementing
solutions to slow down the spread of this highly contagious disease.

A Performance Analysis of Supervised Machine …
593
The governments of almost every country around the world joined to implement
rules which slowed down the spread of disease. Anti-contagion policies can help to
stop or break the chain to spread the disease frequently. Studies showed that coun-
tries have implemented rules like mandatory wearing masks. Some countries even
penalized if somebody was found not wearing the mask. Some countries included
closing schools and public places to reduce the interaction of people to people. Many
countries implemented a strict lockdown that is restricting people at their homes or
country. However, it has been found that the execution of these anti-contagion poli-
cies and rules showed a signiﬁcant impact in slowing down the spread of disease. On
the other hand, these strategies hit the economy of the country and people suffered
a lot [1–4].
A method known as well-being found by the researcher explain that people all
around the world want to live long and healthy [8]. Several researches are conducted
to ﬁnd the cure of this deadly disease COVID-19. However, even after a year of the
outbreak of COVID-19, it is not yet treatable but researchers found that implementa-
tion of policies can signiﬁcantly lower the number of infections. On the other hand,
the stricter government policies showed ﬂuctuation in human emotions which leads
to stress and depression [9]. Many researchers implemented and discovered different
ways to measure emotions and study the impact of emotions on human health due
to COVID-19 [10]. In order to overcome the emotional imbalance of people, WHO
and world happiness report clariﬁes that to slow down the spread of infection is to
maintain physical distance and not the social distant. People got themselves socially
distant which created a sense of loneliness and unhappiness [11]. All the government
policies were applied for the safety of human life in the time of pandemic. On the
contrary, psychologist researchers found that it is impacting the mental health of the
people high class studies performed to ﬁnd the result of lockdown on human mental
health [12].
Further, on the basis of upgraded researches, government policies were revised
to lower the impact of strict government policies on mental well-being of a person
[13]. Moreover, researchers and scientists are ﬁnding solutions to provide accurate
and most recent datasets to policymakers. So, they can make better policies and rules
to slow down the spread of the virus. As the economy of the world was hit badly
due to strict anti-contagion policies, scholars are continuously working to ﬁnd better
ways and revised policies which should tackle not only the spreading of disease, but
also should not damage the economy of any country plus maintain the mental well-
being of a person. The new and revised strategies are more targeted and speciﬁed
like shutting down the part of the country which has been more affected instead of
closing the whole country [14]. During the period of pandemic in the year 2020, it
has been noticed that life expectancy in USA has decreased. The infection multiplies
frequently and spread all over the world within couple of days [15]. Past researches
showed that social distancing plays an important part in the spread of disease. The
symptoms of the disease are similar to seasonal inﬂuenza but past researches showed
that COVID-19 is not like seasonal inﬂuenza [16].

594
S. A. Farooq and S. K. Shanmugam
3
Proposed System
In machine learning, the algorithm is classiﬁed as supervised and unsupervised
learning algorithm.
One of the supervised learning technique is classiﬁcation. In our system, different
classiﬁcation algorithms are used. They are
• Linear regression
• Logistic regression
• K- nearest neighbor
• Support vector machine
• Naive Bayes.

A Performance Analysis of Supervised Machine …
595
In this system, the dataset is preprocessed, and the model is constructed using
different algorithms given above, and the predicated result is attained. In this system,
two datasets, COVID-19 data and world happiness report are combined and aimed
to predict based on features like freedom of choice, health life expectancy, and other
social features which countries have higher number of cases. The model is trained
according to this dataset, and then in future, when system gets those parameters, it
can predict whether this country is at risk or no risk in terms of COVID-19 spread. In
classiﬁcation algorithm, it will classify country as risk or no risk and algorithm like
regression we will predict expected number cases based on future days. Then, perfor-
mance of the algorithm is calculated by considering the performance metrics. The
performance metrics are considered based on the components of accuracy, confusion
matrix, etc.
4
Experimental Results and Discussion
4.1
Data Visualization
The data visualization for different categories like maximum infection rate and by
GDP capita and social rate, freedom of choices for different countries, max infection
rate by healthy life expectancy (Figs. 1, 2, 3, 4, 5, 6, 7 and 8).
4.2
Data Preprocessing
In this system, two datasets, COVID-19 data and World happiness report are
combined and aimed to predict based on features like freedom of choice, health life
expectancy, and other social features which countries have higher number of cases.
In COVID-19 dataset preprocess, the columns of “Lat” and “Long” are removed
because they are not needed at this point of time. Then the infection count country

596
S. A. Farooq and S. K. Shanmugam
Fig. 1 Max infection rate
country wise
Fig. 2 Max infection rate by
country date wise
Fig. 3 Country wise
data—freedom of chioces
Fig. 4 Max infection rate
for GDP capita

A Performance Analysis of Supervised Machine …
597
Fig. 5 Max infection rate by
social rate
Fig. 6 Max infection rate by
health life expcetancy
Fig. 7 Scatter matrix
Fig. 8 Covid-19 data
countrywise
wise is summed using group by. So, the preprocessed dataset has max infection
rate country wise. In Happiness reports Dataset Preprocessing, few columns, like
“Overall rank,” “Score,” “Generocity,” “Perceptions of corruption” which are not
required are removed. Then index on country is set and helps to join our dataset

598
S. A. Farooq and S. K. Shanmugam
with preprocessed data. In the end, inner join of two data frames by country is made,
which gives combined data that shows the country its max infection rate and its
freedom of choices, health expectations, and another social parameter that identiﬁes
their happiness. At last, a new column, “iﬁsRisk” is created which shows whether
the country is at risk or no risk is created.
4.3
Machine Learning Algorithms
Linear Regression
In statistics, linear regression is a linear approach to modeling the relationship
between a scalar response and one or more explanatory variables (also known as
dependent and independent variables).
The details of the MSE and accuracy for linear regression are given below.
S. No.
Algorithm
Mean absolute error
Mean squared error
Accuracy
1
Linear regression
1,398,193.557592338
2,022,186,321,883.8347
65.21
Logistic Regression
Logistic regression is a statistical model that in its basic form uses a logistic function
to model a binary dependent variable, although many more complex extensions
exist. In regression analysis, logistic regression (or logit regression) is estimating the
parameters of a logistic model (a form of binary regression).

A Performance Analysis of Supervised Machine …
599
Naive Bayes
In statistics, Naive Bayes classiﬁers are a family of simple “probabilistic classiﬁers”
based on applying Bayes’ theorem with strong independence assumptions between
the features. They are among the simplest Bayesian network models but coupled
with kernel density estimation, and they can achieve higher accuracy levels
KNN
The K-nearest neighbors (KNN) algorithm is a simple, supervised machine learning
algorithm that can be used to solve both classiﬁcation and regression problems.
It is easy to implement and understand but has a major drawback of becoming
signiﬁcantly slow as the size of that data in use grows.
Support Vector Machine
In machine learning, support vector machines are supervised learning models with
associated learning algorithms that analyze data for classiﬁcation and regression
analysis.
The performance metrics of logistic regression, K-nearest neighbor, Naive Bayes,
and support vector machines are calculated and given below:
S. No.
Algorithm
Accuracy report
1
Logistic regression
0.9767441860465116
2
KNN
0.9767441860465116
3
Naive Bayes
0.9767441860465116
4
Support vector machine
0.9767441860465116

600
S. A. Farooq and S. K. Shanmugam
S. No 
Algorithm 
Label 
Precision 
Recall 
1 
Logistic Regression  Metrics 
0
1
0.96
1.00 
1.00 
0.95 
2 
KNN 
0
1
0.96 
1.00 
1.00
0.95 
3 
Naive Bayes 
0
1
0.96 
1.00 
1.00
0.95 
4 
Support Vector Machine 
0
1
0.95 
0.94 
0.91 
0.97 
Given experimental results classiﬁcation algorithm will work best on my dataset,
I would recommend SVM as it has enhanced grid search functionality to ﬁnd optimal
hyperparameters of the model which results in the most accurate predictions.
5
Conclusion
In this work, different machine learning algorithms are applied on the COVID-19
dataset and happiness report dataset and analysed. The tables above show the perfor-
mance metrics for the algorithms and could recommend that SVM is an adaptable
techniques for this combined dataset as it enhanced the grid functionality to ﬁnd
optimal hyperparameters of the model which results in the most accurate predic-
tions. In future, other machine learning algorithms like decision tree, random forest,
principal component analysis, etc., can be used to analyze the best efﬁcient algorithm
in depth.
References
1. Wu, F., Zhao, S., Yu, B., Chen, Y. M., Wang, W., Song, Z. G., Hu, Y., Tao, Z. W., Tian, J. H.,
Pei, Y. Y., & Yuan, M. L. (2020). A new coronavirus associated with human respiratory disease
in China. Nature, 579(7798), 265–269.
2. Zhou, P., Yang, X. L., Wang, X. G., Hu, B., Zhang, L., Zhang, W., Si, H. R., Zhu, Y., Li, B.,
Huang, C. L., & Chen, H. D. (2020). A pneumonia outbreak associated with a new coronavirus
of probable bat origin. Nature, 579(7798), 270–273.

A Performance Analysis of Supervised Machine …
601
3. Cheng, C., Barceló, J., Hartnett, A. S., Kubinec, R., & Messerschmidt, L. (2020). COVID-
19 government response event dataset (CoronaNet v. 1.0). Nature Human Behaviour, 4(7),
756–768.
4. Hsiang, S., Allen, D., Annan-Phan, S., Bell, K., Bolliger, I., Chong, T., Druckenmiller, H.,
Huang, L.Y., Hultgren, A., Krasovich, E., Lau, P., & Wu, T. (2020). The effect of large-scale
anti-contagion policies on the COVID-19 pandemic. Nature, 584(7820), 262–267.
5. Hale, T., Petherick, A., Phillips, T., & Webster, S. (2020). Variation in government responses
to COVID-19. Blavatnik school of government working paper, 31, 2020–11.
6. Fetzer, T. R., Witte, M., Hensel, L., Jachimowicz, J., Haushofer, J., Ivchenko, A., Caria, S.,
Reutskaja, E., Roth, C. P., Fiorin, S., & Gómez, M. (2020). Global behaviors and perceptions at
the onset of the COVID-19 Pandemic (No. w27082). National Bureau of Economic Research.
7. Banks, J., Fancourt, D., & Xu, X. (2021). Mental health and the COVID-19 pandemic. In J.
Helliwell, R. Layar, J. D. Sachs, J. E. De Neve (Eds.),World happiness report. sustainable
development solutions network (pp. 109–130).
8. Layard, R., & Oparina, E. (2021). World happiness report: Living long and living well. LSE
Business Review.
9. Kleinberg, B., van der Vegt, I., & Mozes, M. (2020). Measuring emotions in the covid-19 real
world worry dataset. arXiv preprint arXiv:2004.04225.
10. Abdul-Mageed, M., & Ungar, L. (2017). EmoNet: Fine-grained emotion detection with gated
recurrent neural networks. In Proceedings of the 55th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers) (pp. 718–728). Vancouver, CA.
11. Okabe-Miyamoto, K., & Lyubomirsky, S. (2021). Social connection and well-being during
COVID-19. World Happiness Report 2021 (p. 131).
12. Aknin, L., De Neve, J. E., Dunn, E., Fancourt, D., Goldberg, E., Helliwell, J., Jones, S. P.,
Karam, E., Layard, R., Lyubomirsky, S., & Rzepa, A. (2021). A review and response to the
early mental health and neurological consequences of the COVID-19 pandemic.
13. Duffy, B., & Allington, D. (2020). The accepting, the suffering and the resisting: the different
reactions to life under lockdown. King’s College London.
14. Frijters, P., Clark, A., Krekel, C., & Layard, R. (2020). A happy choice: Wellbeing as the goal of
government. Behavioural Public Policy, 4(2), 126–165. https://doi.org/10.1017/bpp.2019.39
15. Andrasfay, T., & Goldman, N. (2021). Reductions in 2020 US life expectancy due to COVID-
19 and the disproportionate impact on the Black and Latino populations. Proceedings of the
National Academy of Sciences, 118(5).
16. Koziol, J. A. (2021). Lessons from the past: Comparison of the disease burden of the ınﬂuenza
A (H1N1) pandemic 2009–10 and seasonal ınﬂuenza 2010–2019 in the United States.

Predicting Telecom Customer’s Switch
Over Intentions Using Machine Learning
Algorithms
S. N. Vivek Raj and S. Prithiviraj Pallava Rayer
Abstract Customer Churn is one of the major issues affecting the global telecom
sector and Indian Telecom industry is not an exemption. TRAI (Telecom Regulatory
Authority of India) has regulated the sector by introducing MNP (mobile number
portability), by which the customer can easily switch over to other telecom operators
without changing their mobile numbers. This research work has been carried out
among subscribers using telecom networks to ﬁnd out the factors that inﬂuence
the subscriber’s intent to switch over to another network. Data has been collected
from 458 telecom users using convenience sampling and structured questionnaires.
Machine Learning Algorithms have been used to predict the customer switch over
intent and identify the important features affecting the customer intent to switch over
to a new operator. Among various algorithms that are used in the study for predicting
customer switch over intentions, Logistic Regression performed relatively better with
high accuracy. From the results of logistic regression, it is found that marital status,
no of years that a customer is using the current mobile operator, Network Quality,
Tariff, and advertisements have a signiﬁcant impact on the customer switch over
intentions.
Keywords Machine learning · Logistic regression · Feature Selection · Customer
churn · Decision tree · Classiﬁcation · Prediction · Telecom
1
Introduction
Customer Churn analysis is one of the important applications of Machine Learning
and predictive models have been widely used to classify which customers are likely to
churn. With the help of this insight, organizations can formulate strategies and tactical
plans to reduce the customer churn in their organization and can focus more on a
customerwhowillnotchurnhenceturningthemintomoreloyalcustomers.Customer
Churn analysis helps organizations to carry out targeted marketing activities and
S. N. V. Raj (B) · S. P. P. Rayer
KCT Business School, Kumaraguru College of Technology, Coimbatore, India
e-mail: vivek@kctbs.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_47
603

604
S. N. V. Raj and S. P. P. Rayer
saves a lot of promotion budget by not marketing to customers who are in a high
probability to switch over to another organization or a product. Organizations with the
help of churn analytics can better retain the customers which in turn affects the overall
proﬁtability.Usinginsightsfromcustomerchurnanalytics,organizationscanconduct
promotional activities like free streaming services, loyalty beneﬁts programs to better
satisfy the intended customers. There have been instances where organizations using
analytics able to reduce the customer churn to a great extent and in one such instance
a fortune 500 telecom organization is able to attain a 50% decrease in customer
churn with the support of customer lifetime modeling [1]. Telecom industry globally
is affected by increasing rate of customer churn [2] and Indian Telecom sector is
one of those which is affected by high customer churn rate which is attributed to
lower cost of changeover [3]. Telecom Regulatory Authority of India which is the
governing body of telecom sector in India has introduced a policy called Mobile
Number Portability using which the customers can change their telecom service
with very minimal switch over cost and in addition to that he or she can retain the
same mobile number [4]. We consider that this is one of the fueling reasons for
customers to switch over to other telecom operators very easily. Entry of Reliance
Jio in September 2016 had a huge impact on pricing and subscriber distribution in
India [5]. To Face Rivalry and Endure Smaller Operators were acquired and Larger
Operators Like Vodafone and Idea Merged. The Telecom Operators now are forced to
operate on low tariff plans, and they provide additional add-on beneﬁts to customers
like free OTT subscriptions to make sure they do not churn and switch over to
other operators. Considering the industry scenario, the study was conducted during
Covid-19 Lockdown period where most of the organizations have switched to remote
working and have mandated the employees to work from home and educational
institutions including schools and colleges started to conduct online classes. Because
of this many employees have started to used Telecom networks for connecting to
internet and many citizens started to use OTT due to spending time at home isolating
themselves. Even the Students are forced to use smartphone and other gadgets for
online study. Our Study Conducted during the Covid-19 pandemic time focuses
on understanding and analyzing the factors that impact the customer intention to
switchover to new telecom operator. The Data for the study was collected using a
structured questionnaire and a total of 458 telecom users in India responded to the
survey in the month of July 2020. Popular Machine Learning Algorithm Logistic
Regression was deployed to unearth the important features impacting the customer’s
intent to switch over to a new network. Other Machine Learning Algorithms like
Decision tree and Discriminant analysis have also been used to classify the customer
who is showing intent and not showing intent to switch over based on the feature set
and the best algorithm is selected based on measures like accuracy. Of the Chosen
Machine Learning Algorithms, Logistic Regression performed better in terms of
overall accuracy. Logistic Regression inferences revealed that features like marital
status, no of years customers are using the current mobile operators, Network Quality,
Tariff, and Advertisements have an impact on customer switchover.

Predicting Telecom Customer’s Switch Over Intentions …
605
2
Review of Literature
Global Telecom Sector is projected to have a Compound Annual Growth Rate of
14.3% from 2018 to 2023 and it is imperative that the increasing need to reduce
customer churn is one of the compelling factors that will drive the growth of Global
Telecom Industry [6]. There has been substantial research work that has been carried
to understand the customer churn process and the factors affecting customer churn.
Some of the prominent research works in customer churn are discussed subsequently.
A study was conducted to assess the repetition of customer churn during customer
second lifetime, it is found from the research that customer churn behavior during
First Lifetime and Second Lifetime are practically different and marketing commu-
nication can elongate customer Second Lifetime in an organization [7]. Internet
Broadband Service Providers must insist on value added services and addons like
Wi-Fi Mesh network systems to provide better quality of services to the subscribers
hence reducing the threat of customer churn [8]. Customer proﬁling based on past
transactions can use critical input to understand the customer churn process and this
methodology can be used to detect customer churn in telecom sector [9]. There is
another signiﬁcant study that contributes to the body of knowledge by realizing the
importance of two constructs, i.e., corporate image, cost of switching, and its effect
on customer loyalty [10]. A Multivariate survival model with cure rate has also been
implemented in the past on a customer churn dataset and the model is found to be of
a good ﬁt for the data and the model was able to identify customer non-churning frac-
tions [11]. In another interesting ﬁeld study experiment, it was found that by being
proactively advising customers to move to reduced cost plan, customer churn was
found to increase rather than decreasing and one of the reasons being the proactive
campaign reduced customer inertia to change schemes [12]. A Noteworthy Research
was conducted as a ﬁeld study experiment to evaluate the effect of pricing structure
on customer retention, and it was concluded from the study that two part pricing tariff
results in decline of annual customer retention by a substantial percentage compared
to pay per use tariff [13]. While majority of the studies focused on reducing customer
churn over rate, one of the path breaking studies explored another dimension by
letting customer conglomeration in incentive redemption behavior thus accounting
for enhancements in customer churn management [14]. Telecom Sector Globally
has been researched frequently for customer churn and one such research on churn
analysis in telecom sector revealed the impacts of customer satisfaction, calcula-
tive commitment, and prior churn on retention of customers [15]. Another such
research with special reference to the Indian telecom sector reveals that network,
tariff, advertising, technology, reward, and other outside factors affects the churn
behavior of Indian telecom subscribers [4]. A Comparative study was conducted
to assess the performance of simple and boosted machine learning algorithms in
predicting customer churn with a public telecom dataset, and the results proved
that boosted machine learning algorithms performed better compared to the simple
machine learning algorithms [16] and another such research work has also recom-
mended boosting for churn prediction compared to a single learner, results of this

606
S. N. V. Raj and S. P. P. Rayer
research also uncovered that boosted learners provide a great division of churn data
[17]. Bagging algorithms capability on predicting customer churn were also been
highly researched and in one such research it was observed from the experiments that
Improved Balanced Random Forest Algorithm which merges sampling methods with
cost sensitive learning performed better in terms of accuracy compared to Random
Forest Algorithm [18]. Apart from Boosting and Bagging Machine Learning Algo-
rithms, Deep Learning Algorithms like Artiﬁcial Neural Networks have also been
used to predict customer churn and even two neural network methods have been
combined to provide better accuracy [19].
As seen from the reviews of the previous studies, some of the studies apply
structural equation modeling to analyze the effect of constructs on customer churn.
Similarly, some of the studies seem to be conducted on secondary datasets containing
customer data. This research is different in the sense it deploys the popular machine
learning algorithms to identify the features impacting the customer churn and the
study is conducted based on the primary data collected from the respondents during
covid-19 pandemic and hence reﬂects the attitude of the customers towards customer
churn during this time.
3
Research Methodology
The study was conducted by following the popular data mining research model
CRISP-DM. The Data was collected from the telecom customers by circulating a
google form to collect the intentions of customers for switching over to a new telecom
operator. The questionnaire was structured comprising of 55 questions consisting of
demographic variables and predictor variables. First Step in CRISP-DM approach
is business understanding, so to understand the variables impacting customer switch
over intentions extensive review of literature is conducted and the signiﬁcant features
are identiﬁed. The Independent Variables which are selected for the study area as
Network Quality, Tariff, Internet, Customer Service, Network Service during Trav-
eling, Trust, Loyalty, Offers, and discounts, Brand association and advertisements.
The dependent variable used for the study is customer switch over intention which
is a binary categorical variable code as ‘Intent’ and ‘No intent’.
After Data Collection is and Data is cleansed, and missing data is removed from
the study. A total of 458 respondents’ data is taken for the ﬁnal analysis. Then
the Collected data is analyzed using three popular machine learning algorithms, i.e.,
Logistic Regression, Decision Tree, and Discriminant Analysis. The Models are built
around the training data and the results are validated using 10-fold cross validation
method. Finally, the Validated models are deployed to predict the customer’s turn
over intention.
The study was started ﬁrst week of June 2020 and was completed in the end of
July 2020.

Predicting Telecom Customer’s Switch Over Intentions …
607
4
Data Analysıs
The main objective of this research is to understand the customer churn process
and ﬁnding out the signiﬁcant factors impacting the customer’s intent to switch
over to a new Telecom operator. Primary Source of Data Collection has been used
in the study. An online survey has been conducted to collect customer’s switch
over intention with help of structured questions. For this purpose, a classical and
well documented Machine learning algorithm logistic regression is deployed. Binary
Logistic Regression is used since the dependent variable for the research is coded as
binary, i.e., customers are showing intent or not showing intent for switching over to
a new operator [20]. Forward Stepwise Regression using Likelihood Ratio has been
used as a feature selection methodology. The Results of the study are discussed as
follows.
The ﬁrst step involves creating dummy variables for the categorical variables. As
a rule of thumb m-1 dummy variables are created for the categorical variables with
m categories (Table 1).
The Dummy Variables thus created above are used in lieu of categorical variables.
Thus, using the methodology of dummy variable encoding we can use the categorical
variables in the logistic regression equation. Similarly, the Dependent Variable which
is binary has been encoded as given in Table 2. Intent to Switch over is coded as ‘0’
and No intent is coded 1.
The Classiﬁcation Table of the Stepwise Logistic Regression is given in the
Table 3. The Classiﬁcation accuracy of the logistic classiﬁer increased progressively
from step 1 to step 5. In the Last Step, i.e., Step 5, the model has an overall accuracy
Table 1 Categorıcal varıables codıng
Options
Frequency
Parameter coding
Marital status
Married
49
1.000
Unmarried
409
0.000
Type of connection
Post-paid
86
1.000
Prepaid
372
0.000
Do all family members use same connection?
No
196
1.000
Yes
262
0.000
Do you travel frequently?
No
189
1.000
Yes
269
0.000
Awareness about mobile number portability
No
188
1.000
Yes
270
0.000
Switched from other network priorly?
No
217
1.000
Yes
241
0.000
Gender
Female
294
1.000
Male
164
0.000

608
S. N. V. Raj and S. P. P. Rayer
Table 2 Dependent variable
encoding
Original value
Internal value
˙Intent
0
No intent
1
of 73.4% which is a good indicator of the model’s performance. The model correctly
predicts 96.7% of cases as having the intent to switch over which is again a very
good indicator considering our study focuses more on the switch churn intention.
The Model did not perform comparatively better in predicting cases which are having
no intent to switch over and hence there is a scope for improvement in this aspect.
The First Step started with an accuracy of 72.1% and no cases have been correctly
classiﬁed for the class ‘ no intent ‘. The Stepwise regression ended in Step.5 as the
algorithm found out that no more improvements can be made in the model accuracy
by adding new features to the ﬁnal model.
The main aim of feature selection is to eliminate the independent variables which
are not having a signiﬁcant impact on the target variables and to include only the
signiﬁcant variables in the ﬁnal model. Stepwise Forward Logistic Regression has
been employed in this research where we start with an intercept only model and we
keep on adding the signiﬁcant variables till no further improvements in the model are
possible. Table 4 explains the results of the stepwise forward regression. The Forward
Logistic Regression algorithm has proceeded from step 1 to step 5 adding signiﬁcant
Table 3 Classiﬁcation table—stepwise logistic regression
Observed
Predicted
Intent to switch
Percentage correct
˙Intent
No intent
Step 1
Intent to switch
Intent
330
0
100.0
No intent
128
0
0.0
Overall percentage
72.1
Step 2
Intent to switch
Intent
329
1
99.7
No intent
127
1
0.8
Overall percentage
72.1
Step 3
Intent to switch
Intent
321
9
97.3
No intent
117
11
8.6
Overall percentage
72.5
Step 4
Intent to switch
Intent
316
14
95.8
No intent
115
13
10.2
Overall percentage
71.8
Step 5
Intent to switch
Intent
319
11
96.7
No intent
111
17
13.3
Overall percentage
73.4

Predicting Telecom Customer’s Switch Over Intentions …
609
Table 4 Variables in the equation— Logistic regression
Variables
B
S.E
Wald
df
Sig
Exp(B)
Step 1a
Marital Status (1)
−1.114 0.449 6.155
1
0.013 0.328
Constant
−0.855 0.108 62.650 1
0.000 0.425
Step 2b
Marital Status (1)
−1.139 0.451 6.376
1
0.012 0.320
advertisement
−0.345 0.138 6.287
1
0.012 0.708
Constant
0.420
0.516 0.664
1
0.415 1.522
Step 3c
Marital Status (1)
−1.034 0.454 5.187
1
0.023 0.356
Network
0.572
0.176 10.489 1
0.001 1.771
advertisement
−0.632 0.166 14.486 1
0.000 0.532
Constant
−0.713 0.633 1.268
1
0.260 0.490
Step 4d
Marital Status (1)
−1.316 0.480 7.512
1
0.006 0.268
Number of years customer is using the
current sim
0.105
0.040 7.057
1
0.008 1.111
Network
0.643
0.180 12.705 1
0.000 1.901
advertisement
−0.649 0.168 15.002 1
0.000 0.522
Constant
−1.349 0.682 3.912
1
0.048 0.259
Step 5e
Marital Status (1)
−1.235 0.481 6.589
1
0.010 0.291
Number of years customer is using the
current sim
0.104
0.040 6.838
1
0.009 1.110
Network
0.874
0.211 17.241 1
0.000 2.397
Network Tariff
−0.493 0.213 5.347
1
0.021 0.611
advertisement
−0.527 0.176 8.982
1
0.003 0.590
Constant
−0.889 0.712 1.560
1
0.212 0.411
variables in each step. In Step 1 the algorithm had only one independent variable
Marital Status (1). The ﬁnal Step and ﬁnal model, i.e., Step 5 explains the signiﬁcant
factors impacting the churn decision and it can be ascertained that the variables
namely marital status, no of years customers are using the current telecom sim,
Network Quality, Tariff, and Advertisements are the signiﬁcant variables impacting
the customers intent to switch over to a new network.
Next, we proceed to analyze the customer churn intention using Decision Tree
Algorithm. We have deployed Decision Tree with CHAID (Chi-Square Auto-
matic Interaction Detector) mechanism with tenfold cross validation. The resultant
Decision tree is given in Fig. 1.
The Fig. 1 explains how the decision tree has been built for classifying the
customer’s intent to switch over to a new telecom operator. The independent vari-
ables which are found to be signiﬁcant in impacting the customers switch over intent
are advertisement, network, and Service (Table 5).
While coming to the performance of the algorithm in classifying the records, the
overall accuracy is 72.3%, i.e., the algorithm can correctly classify 72.3% of cases.

610
S. N. V. Raj and S. P. P. Rayer
Fig.1 Decision tree algorithm for predicting customer churn intention
Table 5 Classiﬁcation
table—Decision tree
Observed
Predicted
Intent
No intent
Percent correct (%)
Intent
294
36
89.1
No intent
91
37
28.9
Overall percentage
84.1%
15.9%
72.3

Predicting Telecom Customer’s Switch Over Intentions …
611
Similarly, the algorithm classiﬁes 89.1% of customers having the intent to switch over
correctly. The algorithm performed better in comparison to the logistic regression in
the following aspect since the decision tree algorithm correctly predicted 28.9% cases
with no intent to switch over whereas logistic regression predicted only 13.3% in this
class. Next Algorithm which is used for predicting the customer’s intent to churn is
discriminant analysis and it is multivariate analysis technique. One of the limitations
of discriminant analysis compared to the other two methods is that independent
variables in Discriminant analysis can be only continuous data and hence we may
miss the statistical power of some of the categorical variables.
Table 6. shows the Wilk’s Lambda of the discriminant function and discriminant
function which is used to predict the dependent variable is signiﬁcant. Table 6 also
gives the value of chi-square statistic to assess the wilk’s lambdas signiﬁcance. Since
the P value is less than 0.01, we can conclude that the discriminant function well
describes the group membership, but Wilks Lambda is closer to 1, which is not a
good indicator since it may denote that the groups are overlapping (Table 7).
The Results of the Discriminant Analysis seem to go along the Logistics Regres-
sion. The Variables Network Quality, Tariff, Advertisement, and Number of Years
that a customer is using the current sim are chosen as the signiﬁcant variables
impacting the customer switch over intent.
Table 8 explains the classiﬁcation results of the discriminant analysis. The Label
‘Original’ denotes the count of classes found in the actual data. The Actual frequen-
cies denote 330 instances have been coded as intent and 128 instances have been
coded as no intent. The Predicted Group Membership denote the predictions of the
groups made by discriminant analysis. 67.3% of the cases have been correctly clas-
siﬁed as intent, similarly, 53.9% of the cases have been correctly classiﬁed as no
intent. Overall, the Discriminant Analysis algorithm correctly classiﬁes 63.5% of
cases correctly and it falls behind both Logistic Regression and Decision Tree.
Table 6 Wilks’ Lambda
Test of function(s)
Wilks’ lambda
Chi-square
df
Sig
1
0.937
29.595
4
0.000
Table 7 Classiﬁcation function coefﬁcients discriminant analysis
Variables
Switch group
Intent
No Intent
Number of years customer is using the current sim
0.837
0.915
Network Quality
3.268
4.181
Tariff
4.106
3.567
Advertisement
3.218
2.670
(Constant)
−22.238
−22.086

612
S. N. V. Raj and S. P. P. Rayer
Table 8 Classiﬁcation results—Discriminant analysis
Switch group
Predicted group membership
Total
Intent
No intent
Original
Count
Intent
222
108
330
No Intent
59
69
128
Percentage
Intent
67.3
32.7
100.0
No Intent
46.1
53.9
100.0
a63.5% of original grouped cases correctly classiﬁed
5
Comparıson of Results
The Table 9 explains the comparison of performance of the three machine learning
algorithms used in this research. Both Logistic Regression and Decision Tree
performed better in comparison to the Discriminant Analysis the main reason being
discriminant analysis is not able to include the categorical variables as the predic-
tors in the model. The variables Network Quality and advertisements are selected as
signiﬁcant variables in all three machine learning algorithms. Hence the above vari-
ables are considered to have high impact on customer switch over intention. Tariff
and no. of years a customer is using his current telecom operator have been judged
signiﬁcant by two of the models.
The Table clearly explains that the Logistic Regression and Decision Tree results
are similar in terms of accuracy. The Table also gives us an overall picture of the
signiﬁcant features which has an impact over the target variable. By Focusing on the
features affecting the customer switch over intentions, it is possible for the organi-
zations to provide data driven interventions to decrease the switch over propensity
among the customers.
Table 9 Comparison of results
Sl.no Algorithm
Accuracy (%) Features ıdentiﬁed
1
Logistic regression
73.4
Marital status, number of years customer is using
the current operator, network quality, tariff and
advertisements
2
Decision Tree
72.3
Advertisement, network quality, and service
3
Discriminant analysis 63.5
Network quality, tariff, advertisement and
number of years customer is using the current
operator

Predicting Telecom Customer’s Switch Over Intentions …
613
6
Conclusion
The study was carried out for analyzing the factors impacting the customer churn
intention during covid-19 pandemic time in India, ie, from June to July 2020. This
was critical because many organizations switched to work from home model and
mobile network plays a crucial for staying connected and working from home. Simi-
larly, educational institutions adopted online teaching to face the pandemic situ-
ation. As expected, the machine learning algorithms used in the research, i.e., the
logistic regression, Decision Tree, and Discriminant analysis were able to identify the
signiﬁcant variables affecting the customer switchover intention. Logistic regression
and Decision tree performed better compared to the Discriminant analysis. Logistic
regression classiﬁed 73.4% of customer switch over intentions correctly followed by
Decision tree which is able to classify 72.3% of customer switch over intentions.
7
Future Work and Limitations
The current study incorporated only three popular machine learning algorithms, i.e.,
Logistic Regression, Decision Tree and Discriminant analysis to predict the intent
of the customer to switch over to a new telecom operator. Further research can
be carried out with a more exhaustive list of machine learning algorithms which
may entail bagging, boosting, and deep learning algorithms. The study can also be
carried out to predict customer switch over intention using a hybrid machine learning
algorithm and the results can be compared. The current research work focuses on
the customer switch over intent, one of the possible enhancements possible is that
instead of predicting the customer switch over intentions, actual customer churn can
be predicted to give better insights about the customer churn process.
References
1. Quantzig. (2020a). Fortune 500 telecom company reduces customer churn with the
help of customer lifetime value modeling. Bus Wire Engligh, Feb, 2020. [Online].
Available:
http://search.ebscohost.com/login.aspx?direct=true&db=bwh&AN=bizwire.bw5
454736&site=ehost-live.
2. Quantzig. (2020b). Analytics experts at quantzig analyze the ımpact of ıncreasing churn
rates in telecom | submit RFP for comprehensive ınsights. Bus Wire Engligh, Jul, 2020.
[Online]. Available: http://search.ebscohost.com/login.aspx?direct=true&db=bwh&AN=biz
wire.bw10187429&site=ehost-live.
3. Singh, S., & Sirohi, N. J. (2015). Mobile number portability: It’s ımpact on consumer and
service providers. BVIMR Manage Edge, 8(1), 92–104, Jan, 2015.
4. Chadha, S. K., & Bhandari, N. (2014). Determinants of customer switching towards mobile
number portability. Paradigm, 18(2), 199–219. https://doi.org/10.1177/0971890714558708
5. Mazumdar, R. (2019). Reliance jio becomes India’s top telecom services provider.
Bloomberg.com, p. N.PAG-N.PAG, Jul, 2019.

614
S. N. V. Raj and S. P. P. Rayer
6. Research and Markets. (2019). ‘$6 Billion telecom analytics market—Global forecast to 2023:
Need to reduce churn and retain customers to drive the growth of the market—ResearchAnd-
Markets.com. Bus Wire Engligh, Mar, 2019. [Online]. Available: http://search.ebscohost.com/
login.aspx?direct=true&db=bwh&AN=bizwire.c88507142&site=ehost-live.
7. Kumar, V., Leszkıewıcz, A., & Herbst, A. (2018). Are you back for good or still shopping
around? Investigating customers’ repeat churn behavior. Journal of Marketing Research JMR,
55(2), 208–225, Apr, 2018.
8. PR Newswire. (2016). Broadband service providers need to ınvest in home Wi-Fi solu-
tions or run risk of customer churn. ABI-Research-Wiﬁ-Sol, Jun, 2016. [Online]. Avail-
able: http://search.ebscohost.com/login.aspx?direct=true&db=bwh&AN=201606291124PR.
NEWS.USPR.NY36448&site=ehost-live.
9. Qian, Z., Jiang, W., & Tsui, K.-L. (2006). Churn detection via customer proﬁle modelling.
International Journal of Production Research, 44(14), 2913–2933. https://doi.org/10.1080/
00207540600632240
10. Kaur, H., & Soch, H. (2012). Validating antecedents of customer loyalty for Indian cell phone
users. Vikalpa: The Journal for Decision Makers, 37(4), 47–62. https://doi.org/10.1177/025
6090920120404
11. Cancho, V. G., Dey, D. K., & Louzada, F. (2016). Uniﬁed multivariate survival model with
a surviving fraction: An application to a Brazilian customer churn data. Journal of Applied
Statistics, 43(3), 572–584. https://doi.org/10.1080/02664763.2015.1071341
12. Ascarza,E.,Iyengar,R.,&Schleicher,M.(2016).Theperilsofproactivechurnpreventionusing
plan recommendations: Evidence from a ﬁeld experiment. Journal of Marketing Research,
53(1), 46–60. https://doi.org/10.1509/jmr.13.0483
13. Iyengar, R., Jedidi, K., Essegaier, S., & Danaher, P. J. (2011). The impact of tariff structure
on customer retention, usage, and proﬁtability of access services. Marketing Science, 30(5),
820–836. https://doi.org/10.1287/mksc.1110.0655
14. Tamaddoni, A., Stakhovych, S., & Ewing, M. (2017). The impact of personalised incentives on
the proﬁtability of customer retention campaigns. Journal of marketing management., 1–21,
Mar, 2017. https://doi.org/10.1080/0267257X.2017.1295094.
15. Gustafsson, A., Johnson, M. D., & Roos, I. (2005). The effects of customer satisfaction, rela-
tionship commitment dimensions, and triggers on customer retention. Journal of Marketing,
69(4), 210–218. https://doi.org/10.1509/jmkg.2005.69.4.210
16. Vafeiadis,T.,Diamantaras,K.I.,Sarigiannidis,G.,&Chatzisavvas,KCh.(2015).Acomparison
of machine learning techniques for customer churn prediction. Simulation Modelling Practice
and Theory, 55, 1–9. https://doi.org/10.1016/j.simpat.2015.03.003
17. Lu, N., Lin, H., Lu, J., & Zhang, G. (2014). A customer churn prediction model in telecom
industry using boosting. IEEE Transactions on Industrial Informatics, 10(2), 1659–1665.
https://doi.org/10.1109/TII.2012.2224355
18. Xie, Y., Li, X., Ngai, E. W. T., & Ying, W. (2009). Customer churn prediction using improved
balanced random forests. Expert Systems with Applications, 36(3), 5445–5449. https://doi.org/
10.1016/j.eswa.2008.06.121
19. Tsai, C.-F., & Lu, Y.-H. (2009). Customer churn prediction by hybrid neural networks. Expert
Systems with Applications, 36(10), 12547–12553. https://doi.org/10.1016/j.eswa.2009.05.032
20. Vohra, J., & Soni, P. (2015). Logit modelling of food shopping behaviour of children in retail
stores. Management Research Review, 38(8), 840–854. https://doi.org/10.1108/MRR-03-2014-
0061

Detect CLAMAV Virus Signatures Using
Restricted Features
Reshma Sri Sai Mangipudi, J. Pranitha, G. Sai Varsha,
and B. Indira Priyadarshini
Abstract Since most of the devices work on Internet today, there is a need to provide
network security and monitor for malicious ﬁles continuously. In this paper, we are
showing interest to design a mono chip hardware identiﬁer to scan the virus using
information reduction methods. This process depends on the Clam AV virus infor-
mation database, which has 88.91 K strings and 9.59 K elongated hex type signatures
with constricted systematic declaration (regex) properties. The byte-related compar-
ison problem is shifted to a token-related matching process. A regex design having
single or multiple sections may be further divided into a larger number of non-trivial
tokens. Generally, a token is related to single or only with few regexes. The input
byte information is changed into a token model using decided hardware parts, where
the tokens are much less when compared with the number of bytes.
Keywords Network intrusion detection · String matching · Regular expression ·
Virus detection · Memory-based designs · Finite state machine
1
Introduction
With the large spread existence of device hacks, the virus combined with prolifera-
tion of Internet and networking applications has enlarged the necessity for network
shielding. Present network security requirements, on the other hand, necessitate more
effective review, comprehension usage of data. A topic related to security risks and
issues becomes more common on a daily basis. Virus and worm intonations, spam,
forged sender emails, harmful or unwanted information are all becoming increas-
ingly irritating and causing a plethora of issues. As a result, future generation ﬁre-
walls should have deep packet examination ability to defend against different types
of attacks related to viruses. Those systems examine the packet header, evaluate
R. S. S. Mangipudi (B) · J. Pranitha · G. S. Varsha · B. I. Priyadarshini
Department of ECE, Matrusri Engineering College, Hyderabad, Saidabad, India
B. I. Priyadarshini
e-mail: priyadarshini@matrusri.edu.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_48
615

616
R. S. S. Mangipudi et al.
the packet payload using pattern matching techniques, and determine the impor-
tance of the packet structure related to payload material. Deep packet inspection is
performed by Network Intrusion Detection Systems (NIDS). They search for trends
in the payload of packets that might imply security threats. At wire speeds, however,
matching each and every incoming byte information against thousands of pattern
characters is a difﬁcult job. String matching accounts for 31% of overall processing,
according to CLAM AntiVirus (AV) measurements [1]; in the part of Web meticulous
trafﬁc, the percentage rises up to 80%. So, matching a string can be considered as a
part of the most calculating parts of a NIDS and in this paper, we are concentrating
on payload matching. Different types of processes or combinations of methods have
been explained and used in general purpose processors (GPP) for matching a string in
faster way by using CLAM AV open-source NIDS rule-set. However, the intervention
identiﬁcation systems working in GPP can only serve up to a few hundreds of Mbps
output. Therefore, searching for hardware-related solutions is possible to increase
the performance higher than a few hundred Mbps. Until now, few ASIC-based proﬁt-
oriented products have been designed. These systems can support to generate high
output in the account of relatively expensive result. On the other hand, FPGA-related
systems provide higher ﬂexibility and greater output than compare with ASICs
performance. FPGA (Field Programmable Gate Array) related platforms can utilize
the fact that the NIDS rules change approximately and also it uses redesign to reduce
the cost of the designing process. In addition, they can make use of correspondence
in order to get effective output. Some designs have been suggested for FPGA-related
NIDS, using systematic expressions like NFAs/DFAs (Non-deterministic and Deter-
ministic Finite Automata), discrete comparators, and approximate ﬁltering tech-
niques. In orderly, the performance results of FPGA systems are promising and
showing that FPGAs can be used to support the increasing necessity of a network
security. FPGAs are ﬂexible, reconﬁgurable, provide hardware speed, hence more
suitable for designing such type of systems. On the other hand, there are some issues
that could be encountered. Large designs are harder to formulate and hard to operate
at huge frequency. Also matching more number of patterns occupies a greater area
making it critical to share the logic.
2
Literature Survey
D. Pao, X. Wang, X. Wang, C. Cao and Y. Zhu introduced a memory-efﬁcient string
searching method in [2]. The proposed Quick Sampling and Veriﬁcation (QSV)
approach is based on veriﬁcation of the varying length sufﬁx segment and fast
sampling of data segments. The scalability of the QSV approach is excellent. Only
static strings are handled by the method introduced in this paper. Regular expres-
sion matching is widely acknowledged to be a more difﬁcult issue, particularly
when aiming for speed, hardware performance, scalability and versatility. Author
has proposed a cost-effective method of the processing rate and implementing the
entire system on a single computer in [3]. If we are interested in identifying network

Detect CLAMAV Virus Signatures Using Restricted Features
617
rush in our daily life, we’ll need hardware accelerators. As a result, a new circuit
design that can send more input data per cycle is in demand. As a result, this approach
is only applicable to static strings. Standard expression matching has become even
more complicated as the count of regular information present in the virus database has
increased gradually. A pattern should be able to be handled by the targeted method.
In [4], Other than by seeing the virus information as a data array, they suggested
that the pattern be viewed as a set of tokens, with each and every token corresponding
to a data segment and the input byte stream is converted into a token branch. The
token branch will then be processed by the detection engine to see if any virus present
information can be detected. The system’s drawback is that it can only handle 84 k
strings and 3.2 k multi-segment patterns.
The authors proposed the P-AC pipelined method for circuit design of the Aho
Cora sick algorithm in [5]. However, the research is limited to DFA (Deterministic
Finite Automaton), where any given input can only transit from one state to the next
through one direction. As a result, if the given input length is long, searching and
matching the entire data takes a long time. The above authors proposed a memory-
related design to implement a NFA in order to improve the accessing of general
expression matching for signature-related violation detection in [6]. The author has
raised a concept to get out from the state explosion problem in the DFA method by
implementing NFA, but regular expression matching is restricted to only 80 k strings.
T. N. Thinh, T. T. Hieu, H. Ishii and S. Tomiyama introduced an FPGA-based virus
signature matching architecture in [7]. The Bloom and Bloomier ﬁlter approaches are
used in this framework, which can accommodate both simple and regular expression
virus signatures. Experiments on the Clam AV signature database show that the
device can accommodate 1Gbps throughput and is more robust in terms of on-chip
memory density than previous approaches. This design is mostly memory-based,
and it can be easily modiﬁed to include new virus signatures. The machine is a part
of a high-quality system which comprises both circuitry and programming code.
Using the techniques described above, they implemented a new DFA-based packet
scanner in [8]. Our implementation outperforms a widely used DFA-based scanner
by a factor of 12–42, according to their experimental ﬁndings utilizing real-world
trafﬁc and trends. Our DFA-based packet scanner outperforms the state-of-the-art
NFA-based implementation by 50–700 times.
According to [9] studies, parallel queries to Bloom ﬁlters are typically imple-
mented in hardware for performance, but sequential queries can also be imple-
mented efﬁciently in software. They built an approach in [10] that works on a
special purpose design that executes novel string relating algorithms that have been
separately designed to use in our project. They explained how the problem can be
overcome by breaking down the vast storage device of strings into several small
state diagrams, which searches for a sub-part of the laws and bits of every law. We
demonstrate that by carefully co-designing and optimizing their design with a new
string-matching technique, we can create a new system that can be 10 more times
effective than the current approaches.
In [11], for example, larger-scale string matching, an efﬁcient memory and ﬂex-
ible methodology is used. String design matching in NIDSs necessitates extremely

618
R. S. S. Mangipudi et al.
high performance to align network jam content against an already deﬁned database
of string designs. In this sector, a lot of work has been done. They suggest a method
for preprocessing a database without increasing the number of patterns called “leaf-
attaching.”Anytreesearchdatastructurecanbeusedtosearchtheresultingcollection
of post-processed patterns. They also present a pipelined binary search tree-based
measurable, high output, efﬁcient memory design for large-scale string matching
(MASM). The memory efﬁciency of the proposed algorithm and architecture is 0.56.
as well as 1.32 As a result, their style lends itself well to larger dictionaries. For the
new CLAMAV and Snort databases, designing processes on a 45 nm ASIC tech-
nology and a FPGA computer show that their architecture achieves 24 and 3.2 Gbps
respectively.
The deep packet inspection idea plays an essential role in network security appli-
cations where regular expressions are used in detecting patterns. Various methods of
string matching have been considered over years and slightly enhanced versions in
terms of memory usage in DFA have been discussed in [12]. Currently, exact strings
are being replaced by regular expressions to depict patterns in most popular software
tools such as Snort, Clam AV as they could provide a standard database for studies
as explained in [13].
3
Existing Techniques
In existing works, they proposed an efﬁcient memory and ASCII methodology for
matching the string on FPGAs. Here high throughput is achieved using FSM-based
binary search tree algorithm. Also, they used on-chip RAM to store the patterns.
In previous techniques for matching a mono variable string, there are three
different ideas for the implementation of circuitry in the AC instructions, memory
cost and electronic elements used in designing processes, speed of accessing and
pattern formation. To shown differences between circuitry design can be set up in
the comprehension, the circuit designing process along with storage device type
designing process. Huge analogy is used in FPGA circuit designing, where we need to
match a string method modeled as a non-deterministic ﬁnite automata to discriminate
the count of boundary of a transition. Convergence in the state realignment diagrams
is pointed to unaccompanied data register and also state realignment is performed
by actual circuits that attaches the data bits presented in the register relating with the
instant states and the upcoming states of transformation borders.
In the existing state transformation, the number of states is 6, this will take up more
area due to this more time is taken to do the transitions and delay is also increased
(Fig. 1). This operation is done for only one pattern or virus, so when we consider
more number of patterns, it could increase the time and delay also increases, this can
be overcome in our proposed system.

Detect CLAMAV Virus Signatures Using Restricted Features
619
Fig. 1 Existing state transformation circuit
4
Proposed System
In this work, we introduced the efﬁcient hardware VLSI architectures to detect the
complex NIDS patterns based on the information reduction methodology. Here we
pre-process the input data bytes to change the byte-related comparison problem to a
token-based-related problem. The input data branch is changed into a token branch
using devoted core units which can perform operations like parallel computations
for high throughput rate. A NIDS pattern containing one or more segments will be
divided into multiple non-trivial tokens. Finally, the token branch is expressed by an
NFA-related aggregation unit to detect the virus to be found.
In the proposed block diagram Fig. 2, a selected input pattern is given to the
SRAM cell; the input patterns work on the commands that are generated by the
SRAM controller. When the function is done in the SRAM the output of that function
is stored in the memory, this output which is stored in the memory is given to the
FSM. In the FSM the state transition occurs. In case of NFA system, it requires
more number of state machines (FSM) and so, if we have more number of FSMs
the area increases, delay increases and therefore speed decreases. Due to that, in the
proposed system the state transitions are reduced to fewer numbers, i.e., to 3 states,
Fig. 2 Proposed NIDS
architecture

620
R. S. S. Mangipudi et al.
Fig. 3 Modiﬁed state
transition diagram
so that delay will be reduced due to the less space or area, the modiﬁed state ﬁgure
is observed in Fig. 3. The output of the state transitions is stored in the memory and
comparators compare that with the existing virus databases and it is given to the
payload validity checker.
The memory we used in this system is the SRAM memory, due to its reliability, and
its lower power consumption compared to DRAM. In the proposed system instead
of doing bit by bit operation, we are going to do the same for decimal numbers or the
tokens, so that the number of states can be reduced. Each and every state diagram is
going to perform its operation parallelly so that the speed of operation will increase.
In this process, we take input patterns and client patterns. Each and every bit is
performed by each state that is at so, s1, s2. Here we can see the PMV, Pattern Match
Variable is going to be asserted as either 0 or 1. If it is 1, virus is present, that is
pattern matches occurs. If it is zero, no viruses are present.
5
Implementation
Unlike the earlier systems that process single byte per cycle, the proposed system has
been devised with a new design that processes more bytes of input data bits per one
clock cycle. This enhances the throughput as a straightforward parallel processing
technique is used. The throughput rate is considerably increased by allowing page-
enabled parallel processing (PEPP) as presented in Fig. 4. In Asynchronous circuits,
handshaking protocol is used for time reference. In synchronous circuits, the clock
will be used for time reference.
With this proposed approach, the main limitation is the occurrence of synchroniza-
tion errors in synchronous circuits. The three cases of synchronization mismatches
include mismatch during ASCII encoding, mismatch during string-matching conver-
sion and mismatches between the pages. In order to overcome this limitation, PLL
(Phase Locked Loop) clock technique may be used. A highly reconﬁgurable clock
divider will be used here. By using this model, a single source clock can be used for
multi-rate clock domains.
Here in this study, ﬁve pages with various operating clocks are implemented
based on a single source clock by using RECONFIGURABLE CLOCK DIVIDER.
And phase signals will be successfully matched with PLL. The source clock will be
divided into the required range in order to cope up with the variable rate browsing
of the users from various geographical locations such as 2G, 3G, 4G speeds and

Detect CLAMAV Virus Signatures Using Restricted Features
621
Fig. 4 Page-enabled parallel
processing
this divided clock will be matched with the global clock. For every positive clock of
match PAGE data will be read out and matched with the input stream.
6
Results
Patternmatchingisimplementedusingtheproposedmemory-basedarchitecture.The
results of the power, throughput, registers, look-up tables are analyzed and compared.
The parameters of the existing system were also taken as reference values in the same
way to compare with proposed design. The optimizing results for the page-enabled
parallel implementation given with XILINX ISE 14.7 showed the efﬁciency of the
approach. Here the input intrusions are partitioned into pages. The simulation results
are observed as shown in the ﬁgure.
1.
Simulation of Pattern matching (Fig. 5)
2.
Simulation of control inputs (Fig. 6)
3.
Simulation of text inputs and clocks (Fig. 7).
The synthesis report has been generated after implementation and the comparison
results of the proposed system with the existing systems are shown in Table 1.
7
Conclusions and Future Work
Signature-based virus identiﬁcation is a computation exhaustive task, in particular
for the detection of virus patterns that contain regular expression (regex) features.
Our work is concerned with the design of application speciﬁc hardware to increase
the speed of the matching of an input data stream against the set of embedded virus

622
R. S. S. Mangipudi et al.
Fig. 5 Simulation results of pattern matching
Fig. 6 Simulation results of control inputs
Fig. 7 Simulation results of text inputs and clocks

Detect CLAMAV Virus Signatures Using Restricted Features
623
Table 1 Comparability
results
Parameter
Existing
Proposed
Throughput
144 MHz
176 MHz
Power
1.4 Watts
0.070 Watts
LUTs
858
541
Slice registers
810
655
No. of instances
683
156
Block Ram
76
10
signatures. The device processes the input data stream in single pass and identiﬁes
if any embedded virus structure can be identiﬁed.
The functionality proposed in the hash table-based DFA-based parallel string
comparison method with minimized memory utilities for virus databases is veri-
ﬁed. The efﬁcient memory architectures were proposed for matching a string which
can decrease the ﬁnal memory prerequisites. Accounting for the decreased memory
prerequisites for the ﬁnal rule sets, it is concluded that the explained matching
methodology is useful for decreasing the total prerequisites of memory for parallel
string comparable engines. Ultimately, this design is useful in the applications and
devices where speed and memory are of major concern.
The future scope of this project should focus on proving the memory efﬁciency
of modiﬁed FSM with shared memory for different patterns. Also, bit wise parallel
string matching can be performed and its efﬁciency over previous methods should be
compared. On the whole, the throughput rate and accuracy level of proposed methods
with real-time implementation have to be proved.
References
1. ClamAV anti-virus system, http://www.clamav.net.
2. Pao, D., Wang, X., Wang, X., Cao, C., & Zhu, Y. (2011). String searching engine for virus
scanning. IEEE Transactions on Computers, 60, 1596–1609.
3. Pao, D., & Wang, X. (2012). Multi-stride string searching for high-speed content inspection.
The Computer Journal, 55, 1216–1231.
4. Wang, X., Or, N. L., Lu, Z., & Pao, D. (2015). Hardware accelerator to detect multi-segment
virus patterns. The Computer Journal.
5. Pao, D., Lin, W., Liu, B. (2008). Pipelined architecture for multi-string matching. IEEE
Computer Architecture Letters, 7, 33–36.
6. Pao, D., Or, N. L., & Cheung, R. C. C. (2013). A memory-based NFA regular expression match
engine for signature-based intrusion detection. Computer Communications, 36, 1255–1267.
7. Thinh,T.N.,Hieu,T.T.,Ishii,H.,&Tomiyama,S.(2014).Memory-efﬁcientsignaturematching
for ClamAV on FPGA. In IEEE international conference communications and electronics (pp
358–363).
8. Babu Karuppiah, A., & Rajaram, S. (2011). Deterministic ﬁnite automata for pattern matching
in FPGA for intrusion detection. In 2011 international conference on computer, communication
and electrical technology (ICCCET) (pp. 167–170).

624
R. S. S. Mangipudi et al.
9. Lin, P.-C., Lin, Y.-D., Lee, T.-H., & Lai, Y.-C. (2008). Using string matching for deep packet
inspection. IEEE Computer, 41(4), 23–28.
10. Rashid, M., Imran, M., & Jafri, A. R. (2020). Exploration of hardware architectures for
string matching algorithms in network intrusion detection systems. Association for Computing
Machinery. Article 3, 1–7.
11. Tan, L., Brotherton, B., & Sherwood, T. (2006). Bit-split string-matching engines for intrusion
detection and prevention. ACM Translations Architecture and Code Optimization, 3(1), 3–34.
12. Liu, T., Yang, Y., Liu, Y., Sun, Y., & Guo, L. (2011). An efﬁcient regular expressions
compression algorithm from a new perspective. In 2011 Proceedings IEEE INFOCOM (pp
2129–2137).
13. Asystematicreviewofscalablehardwarearchitecturesforpatternmatchinginnetworksecurity.
Computers & Electrical Engineering, 92, 2021.
14. Parallel combining different approaches to multi-pattern matching for Fpga-based security
systems 5(1), 2020.
15. Sadredini, E., Rahimi, R., Lenjani, M., Stan, M., & Skadron, K. (2020). Impala: Algo-
rithm/architecture Co-design for in-memory multi-stride pattern matching. In 2020 IEEE
international symposium on high performance computer architecture (HPCA).
16. Roesch, M. (1999). Snort—lightweight intrusion detection for networks. In Proceedings of the
13th USENIX conference on system administration (pp. 229–238).

A Review of Mesh Generation in ANUGA
Shreya Kendhe, Aditi Limkar, Sakshi Doshi, T. S. Murugesh Prabhu,
Girishchandra R. Yendargaye, Y. S. Ingle, and N. F. Shaikh
Abstract ANUGA is a freely available inundation software developed by the
Australian National University (ANU) and Geoscience Australia (GA). It is a tool
used for 2D hydrodynamic modeling of realistic ﬂow problems such as tsunamis,
ﬂoods, storm surges, or dam breaks and can be used to simulate their effects on the
environment. It is based on a ﬁnite volume method used for solving the shallow water
wave equation. It makes use of a mesh of triangular cells to represent the area of
study. The mesh is generated following the properties of Delaunay triangulation. This
paper discusses the methods of mesh generation used by ANUGA, the importance
of an accurate and optimal mesh for a good prediction and proposes a new method
of mesh generation.
Keywords ANUGA · Mesh generation · Delaunay triangulation · 2D
Hydrodynamic model · Voronoi tessellation · Domain
1
Introduction
Every year, natural disasters claim millions of lives and cause enormous economic
losses. Hydrological disasters are among the most frequent and most destructive
natural disasters worldwide. An accurate, reliable, and timely forecast can be instru-
mental in minimizing the damage to a great extent. These forecasts are achieved
using various numerical models that can predict the depth, velocity, and arrival time
of water.
Numerous softwares are used for predicting hydrological disasters and for
understanding the consequences of their impact on the environment and commu-
nity. ANUGA is one such software. It is an open-source software developed by
Roberts et al. [1]. Most components of the software are written in Python and its
S. Kendhe (B) · A. Limkar · S. Doshi · Y. S. Ingle · N. F. Shaikh
Department of Computer Engineering, Modern Education Society’s College of Engineering,
Pune, India
T. S. M. Prabhu · G. R. Yendargaye
Centre for Development of Advanced Computing (C-DAC), Pune, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_49
625

626
S. Kendhe et al.
computationally intensive part, the mesh generator engine makes use of Triangle.
Triangle is a C program for 2-D mesh generation and construction of Delaunay
triangulations, constrained Delaunay triangulations, and Voronoi diagrams written
by Shewchuk [2]. This combination of python and C ensures that the software is
ﬂexible yet robust and efﬁcient. To interact with ANUGA, users are required to write
Python programs that are dependent upon the numerous functions already available
in ANUGA.
In ANUGA, the study area or the region in which the prediction is to be conducted
is known as the domain. This domain is represented with the help of a mesh of
triangular cells. The mesh is generated using Triangle [3], the built-in mesh generator.
By solving the governing shallow water wave equation [4] within each cell of the
mesh, properties such as depth or height of the ﬂuid and its horizontal momentum
are observed and stored over a deﬁned period to predict the ﬂuid ﬂow.
The accuracy of predictions relies on the quality of the mesh representation of the
domain and hence the mesh must be accurate. Flood information generated by the
model is valuable when it is computed in advance and warn people of the impending
disaster. The computational load goes up with higher mesh quality and hence it is
necessary to keep optimum mesh quality. The working of ANUGA, current methods
of mesh generation, a new method for mesh generation and the importance of an
accurate and optimal mesh for a good and timely prediction are discussed in the
sections that follow.
2
How ANUGA Works
To interact with ANUGA, users are required to write Python programs that are
dependent upon the numerous functions already available in ANUGA. Using these
programs, the user can specify different parameters such as depth and time-varying
functions or change the bed level [1].
Theprogramisusedtoperformthefollowingsteps:Itestablishesthedomainbased
on the user’s speciﬁcation and sets up a mesh of triangular cells for it. Parameters
governing the mode operation of the model such as the destination of where the
output ﬁle is to be stored are set. The input of various quantities describing physical
measurements is taken. This includes the elevation of different points in the domain.
Boundaryconditionsfordifferenttypesofboundariessuchasreﬂective,transmissive,
Dirichlet, or time are set according to the user input. The evolution of the model is
carried out through a series of time steps. A results ﬁle that can be viewed is generated
as an output.
These programs can be used for parallel computation as well. ANUGA supports
parallel programming with MPI. It makes use of pypar as an interface between
MPI and Python. OPENMPI and MPICH2 are supported by pypar [5]. Parallel
computation results in high performance for a low price and allows system scalability.

A Review of Mesh Generation in ANUGA
627
3
Mesh Generation
Mesh generation is the process of dividing large, complex, and continuous areas into
simpler and smaller elements known as cells. Mesh generation is used in practical
simulation such as ﬁnite element analysis because we can perform numeric opera-
tions on simple geometric ﬁgures like triangles rather than performing it directly on
complicated geometric areas.
In practical simulations, continuum elements are commonly used. For the repre-
sentation of complex continuum elements, unstructured meshes with triangular cells
are generally used. This is because any random or unpredictable complex area can be
ﬁlled ﬂexibly with unregulated meshes of triangular elements. The process of mesh
generationcanbecarriedoutmanually.Manualmeshgenerationisextremelytedious,
time-consuming, and prone to error. Thus, it needs to be automated. Several tech-
niques can be used to automate mesh generation such as the Advancing front Method,
Delaunay Triangulation, and the Sweep Line method. The Delaunay Triangulation
method is the most widely used.
A.
Delaunay Triangulation
Delaunay triangulation is one of the most popular triangular mesh generation algo-
rithms as it generates the optimal number of triangles with easy implementation
details. Voronoi tessellation and Delaunay triangulation are duals of each other. The
properties of Voronoi tessellation and Delaunay triangulation lay the base for mesh
generation based on the Delaunay method [6].
If there are ‘p’ points in a plane, the Voronoi tessellation splits up the area into
regions. The boundaries of these regions are at right angles with the lines connecting
the points such that each region includes only one of the p points. The collection of
all the Voronoi regions is together known as the Voronoi diagram of that point set.
According to the Delaunay criterion, the circumcircle of any triangle in the trian-
gulation should not contain any node of the triangulation, then it is considered an
effective triangulation. The circumcenter of this triangle is called a Voronoi vertex.
A commonly used algorithm used for Delaunay triangulation is Bowyer Watson’s
algorithm. It uses the following approach.
• Find a triangle called the super triangle containing all the points in the domain.
• Select a point and look for triangles whose circumcircle contains the selected
point.
• Connect its edges to the selected point to make a set of new triangles, keeping
only those that follow the Delaunay criterion.
• Repeat the above procedure until all the given points are covered.
• Delete all the triangles consisting of the vertices of the super triangle to obtain
the result.
For a three-dimensional domain, instead of a super triangle and circumcircle, a
super tetrahedron is used to enclose all the given points and a circum-sphere to check
if the new point is to be deleted or inserted in the polyhedron [3] (Fig. 1).

628
S. Kendhe et al.
Fig. 1 Delaunay
triangulation of four points
with their circumcircles
Although this algorithm provides the basis of triangular mesh generation, this
mesh needs to be further reﬁned so that the triangles formed are not too linear, i.e.,
the minimum angle is not too small and the maximum angle is not too large. Thus,
for further reﬁnement, Ruppert’s Delaunay reﬁnement [2] algorithm is widely used.
B.
Ruppert’s Delaunay Reﬁnement Algorithm
Ruppert’s reﬁnement algorithm for 2-D mesh generation is the guarantees the mesh-
ﬁrst algorithm that guarantees the mesh to be satisfactory in practice [2]. It is a better-
ment of Chew’s Reﬁnement algorithm. Chew’s Reﬁnement algorithm produces a
uniform mesh, but Ruppert’s algorithm allows the concentration and size of triangles
to change and adapt to smaller distances [7]. This reduces the number of triangles as
compared to Chew’s method. Ruppert’s reﬁnement algorithm [2] can be summarized
as follows.
• The input vertices are triangulated using Delaunay’s rules.
• A segment with input vertices in its diametral circle is found and its midpoint is
inserted into the triangulation. The diametral circle of a segment is the unique
smallest circle that surrounds it.
• The circumcenter of a poor-quality triangle is then inserted into the triangulation
if it does not lie in the diametral circle of some segment.
• If it does, the segment which has been encroached is further split into two
subsegments.
• These operations are repeated until no segment encroaches, i.e., there are no
poor-quality triangles.
• All triangles formed are the required triangulations (Fig. 2).

A Review of Mesh Generation in ANUGA
629
Fig. 2 Splitting of segments
in Ruppert’s reﬁnement
algorithm

630
S. Kendhe et al.
4
Mesh Generation in ANUGA
ANUGA is a collection of classes and functions which can be called to aid the process
of construction of a 2D hydrodynamic model represented by a triangular mesh. The
model is used to simulate water movement following the various boundary conditions
that have been applied to the model domain. In ANUGA, the mesh is generated using
the built-in mesh generator called Triangle which is a C program for two-dimensional
mesh generation and construction of Delaunay triangulations, constrained Delaunay
triangulations, and Voronoi diagrams [3].
The process of mesh generation in ANUGA takes place in several steps. Initially,
the user gives the input from the python script. The input is in the form of a planar
straight-line graph (PSLG) or bounding points depending upon the domain func-
tion (create_domain _from_region or rect_cross_domian) being used. The domain
creation is done by the abstract_2D_ﬁnite_volumes [8] module. Then, this domain
is passed to the mesh engine for mesh generation within the speciﬁed domain.
The mesh is generated by the Mesh class in the pmesh.mesh module. ANUGA
starts from the boundary points and gradually works its way inwards. It gener-
ates the internal points such that they abide by the rules of Delaunay triangulation
mentioned in the earlier section to form the entire mesh. The user can also make a
few changes to the mesh manually such as adding holes in the polygonal boundary
or adding points or segments in the mesh using add_hole_from_polygon [1] and
add_points_and_segments [1] functions of the mesh class.
Once the mesh is ready, the algorithm then starts simulating for the amount of time
speciﬁed by the user in the given code. Meanwhile information such as computational
step time, run time is displayed by ANUGA on the terminal.
Once the simulation is complete, ANUGA writes the output of these models in
speciﬁed ﬁles such as a.sww ﬁle, a.tsh ﬁle, or a.csv ﬁle. Modules such as geospa-
tial_data can be used over here. One can also export the mesh ﬁle with the help of
the export_mesh_ﬁle function [1].
C.
A simple example
Figure 3 is an image of a mesh generated by ANUGA as viewed in GIS software. The
domain is rectangular and very simple. It has been created by the rect_cross_domain
function of the ANUGA library. The mesh generated is highly regular. It can be
observed that the size of all the triangles generated is the same and vertex points are
spaced at regular intervals. This method generates a mesh for rectangular areas and
is thus not useful for real-life problems due to the irregular shape of river basins or
watersheds for which the mesh generation is to be used.
D.
A realistic example
Figure 4 is an image of the mesh generated by ANUGA as viewed in GIS
software. The domain has complex geometry. It has been created by the
create_domain_from_regions function of the ANUGA library. The mesh generated
is highly irregular. It can be observed that the size of all the triangles generated

A Review of Mesh Generation in ANUGA
631
Fig. 3 Mesh generated using the rect_cross_domain function
Fig. 4 Mesh generated using the create_domain_from_regions function
varies to a large extent and vertex points are randomly spaced. This irregular method
is currently used for mesh generation. This method takes two inputs.
1.
Outer Boundary or the Domain of the region
2.
Maximum Resolution (Area) of the triangles forming the mesh.

632
S. Kendhe et al.
The interior points are generated automatically by the mesh generator such that
the triangles generated are non-intersecting and in accordance with Delaunay’s
triangulation. In this method, the mesh that is generated is completely random in
nature.
As the internal points generated are randomly distributed, the size of the triangles
being generated varies. As a result, there can be many triangles in a small area and
all of them will pick up the same elevation data leading to repeated values. These
triangles are completely unnecessary and increase the computation time and cost.
On the other hand, there may be no complete triangle in some over a large area
and hence the elevation of that area will not be picked up at all and the mesh will
not be able to adapt to varying slopes, thus resulting in an inaccurately represented
surface and inaccurate predictions.
5
Proposed Regular Mesh
The regular mesh is generated in such a way that the entire domain is divided into
identical squares. Each square is then divided into two right-angled triangles by
joining the diagonals of the square to obtain the required triangulation. The optimum
number of triangles required for the triangulation can be found out by dividing the
maximum resolution used in the irregular method by two.
For example, an area of interest represented by a terrain data of 30 m × 30 m.
Assuming the maximum resolution for the triangles to be formed with the irregular
method is 30 * 30 m. Hence, triangles will not have an area above 900 sq m. Now, in
order to calculate the optimal resolution for the triangles in the regular method, we
divide 900 by 2 which gives us 450 sq m. The division by two is done because the
identical squares are divided into two triangles.
In the formation of regular mesh the area or the maximum resolution of the
triangle formed inside the mesh need not be explicitly speciﬁed as all the triangles
will be of the same area. Instead, these triangles will be formed on the basis of the
regular interior points present. Doing so will not only ensure that elevation at all the
points is considered and the surface is represented accurately resulting in an accurate
prediction but also ensure that the number of triangles generated is optimum resulting
in a reduced computation time (Fig. 5).
6
Comparison Between Irregular Mesh Generated
by ANUGA and Proposed Regular Mesh
The formation of mesh in the irregular method is simpler as compared to the proposed
regular mesh method. But, the irregular method is less accurate than the regular

A Review of Mesh Generation in ANUGA
633
Fig. 5 Mesh generated by the proposed mesh method
Table 1 Comparison
between irregular and regular
mesh
Type of mesh
Number of triangles
Difference
Irregular
3,52,286
94,524
Regular
2,57,762
one. The proposed regular method is optimal, reducing the time, cost and space of
computation.
To compare the regular and irregular methods, let us consider an area of 90 sq km.
The current irregular mesh generation method would generate 3,25,286 triangles
and for the same area, the regular right angle mesh method would generate 2,57,762
triangles. The proposed regular mesh generation method reduces the number of
triangles being generated by approximately 27% as compared to the irregular method
(Table 1).
7
Importance of Mesh Representation
In real-life scenarios of modeling of hydrological disasters, the study area is
extremely large, and simulating the water ﬂow over it is a time and resource-intensive
task. It could take multiple hours or sometimes even a few days. As computation is

634
S. Kendhe et al.
carried out for every unit in the mesh, the time and resources required for simulation
are directly proportional to the number of triangular cells forming the mesh. The
more the number of triangles, the greater the time and resources. Hence an optimum
number of triangles must be present. But, in reducing the number of triangles, the
accuracy of the mesh representation cannot be compromised. The study area often
has varied relief and the mesh must be able to represent the elevation of different
points in the study area well as the accuracy of the prediction depends on how well
the features of the study area are represented. Hence both, the optimality and the
accuracy of the mesh representation of the study area are extremely vital for a timely
and accurate prediction.
8
Conclusion
ANUGA is a tool used for 2D hydrodynamic modeling of realistic ﬂow problems. It
makes use of a built-in mesh generator to represent the area of study in the form of
triangular cells. Mesh generation is an integral part of the entire prediction process
and an optimal and accurate mesh representation is the key to a timely and accurate
prediction. In the irregular method of mesh generation, the distribution of mesh trian-
gles is completely random, which does not adapt to varying slopes and other param-
eters that govern the ﬂow of water. Also, this method does not generate an optimum
number of mesh triangles. So a new method for mesh generation is proposed. The
proposed method makes use of regular triangles. This method ensures that the mesh
generated is accurate and optimal. For an area of 90 sq m., the number of triangles
generated by the regular method reduces by approximately 27% as compared to the
irregular method.
References
1. Roberts, S., Nielsen, O., Gray, D., & Sexton, J. (2015). ANUGA user manual commonwealth of
Australia (Geoscience Australia) and the Australian National University.
2. Shewchuk, J. R. (2002). Delaunay reﬁnement algorithms for triangular mesh generation.
Computational Geometry, 22(1–3), 21–74, ISSN 0925-7721.
3. Shewchuk, J. R. (1996). Triangle: Engineering a 2D quality mesh generator and Delaunay
triangulator. In M. C. Lin, & D. Manocha (Eds.), Applied computational geometry towards
geometric engineering. WACG 1996. Lecture notes in computer science (Vol. 1148). Springer.
4. Mungkasi, S., & Roberts, S. G. (2011). A ﬁnite volume method for shallow water ﬂows on
triangular computational grids. In 2011 international conference on advanced computer science
and information systems (pp. 79–84).
5. Mungkasi, S., Darmawan, J. B. B. (2015). Fast and efﬁcient parallel computations using a cluster
of workstations to simulate ﬂood ﬂows. In R. Intan, C. H. Chi, H. Palit, & L. Santoso (Eds.),
Intelligence in the era of big data. ICSIIT 2015. Communications in computer and information
science (Vol. 516). Springer.
6. Lee, D. T., & Schachter, B. J. (1980). Two algorithms for constructing a Delaunay triangulation.
International Journal of Computer and Information Sciences, 9, 219–242.

A Review of Mesh Generation in ANUGA
635
7. Ruppert, J. (1994). A delaunay reﬁnement algorithm for quality 2-dimensional mesh generation.
8. Vandrie, R., & Rigby, E. H. (2008). ANUGA—A new free & open source hydrodynamic model.

Modeling and Analysis of Tsunami Wave
Propagation Characteristics in the Coast
of Bay of Bengal
M. Yasmin Regina and E. Syed Mohamed
Abstract Tsunami is one of the most destructive and unpredictable forces of nature.
Modeling is useful for predicting the tsunami wave properties and prevent the
mankind from great losses in real time. In this paper, the propagation phase of tsunami
is modeled and calculated tsunami characteristics are analyzed. Tsunamis are the
nonlinear, linear frequency dispersion and shallow water waves which depends only
on the ocean water depth. This analytical research is based on the boussinesq approx-
imation because of the nonlinearity and dispersive phenomena for the homogeneous
ocean with the variable bottom. Tsunami wave parameters are calculated for the zone
between West coast of northern Sumatra, Indonesia (95.85 E, 3.316 N) and Marina
Beach, Chennai, Tamil Nadu, India (13.04375 N and 80.28542 E) for 9.1 magnitude
of thrust fault earthquake. The wave height and travel time are validated and veriﬁed
with the observed data. Minimum travel time to reach the coast of Tamil Nadu is
calculated as 2 h 21 min 54 s by the depth averaged technique. Using this technique,
the tsunami characteristics analyzed for the other areas like Paradip, Devananpatnam,
Velanganni presented in the Bay of Bengal coast.
Keywords Wave propagation · Boussinesq approximation · Nonlinearity ·
Shallow water waves · Solitary wave theory · Travel time of tsunami
1
Introduction
Tsunami is one of the nature’s imperceptible phenomena. It is essential to forecast
the tsunami characteristics, travel time, propagating direction and the area where the
tsunamiisgoingtohitforprotectingthelivesandpropertiesfromthemassivedestruc-
tion. Advancement in mathematics and computing technologies helpful in prediction
M. Y. Regina (B)
Department of Civil Engineering, B. S. Abdur Rahman Crescent Institute of Science and
Technology, Chennai, India
E. S. Mohamed
Department of Computer Science and Engineering, B. S. Abdur Rahman Crescent Institute of
Science and Technology, Chennai, India
e-mail: syedmohamed@crescent.education
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_50
637

638
M. Y. Regina and E. S. Mohamed
of these catastrophic wave behaviors. Tsunami is a series of wave with a long wave-
length and long wave period. Sudden and abrupt movement ocean bed deformation
due to earthquake generates tsunami. Apart from seismic activity, there are many
other factors responsible for tsunami like landslides, volcanic activity and rarely
meteorite strike. These gigantic waves are probably one of the most powerful and
most destructive forces of nature [1]. On December 26, 2004, the severely affected the
surrounding coast of Indian Ocean. Nearly 2, 27, 800 people were killed in 14 coun-
tries due to this tsunami. Therefore the modeling of tsunami propagation becomes
more important to avoid the destruction due to this natural phenomenon. Three stages
of tsunami are (i) Generation, (ii) Propagation, (iii) Run up. Generation of tsunami
depends on the earthquake parameter or the source parameter responsible for the
tsunami. After that, the wave propagation and ampliﬁcation based on water depth is
happened. The tsunami propagates orthogonal to the rupture direction, one towards
the shore (local tsunami) and another towards the deep ocean (Trans ocean tsunami)
[2]. When the tsunami reaches the coastline, it started run into land called run-up [3].
Large magnitude of earthquakes, abrupt displacement of the seaﬂoor along a fault or
thrust, creates a void. To ﬁll this void, seawater from all sides rushes in with terriﬁc
speed, colliding and then turning back in the form of sea waves that may travel with
a speed as high as 900 km/hr. Their wavelength is very large 100–200 km but their
amplitude is very small merely 1–2 m in the high seas. As they reach shallow coast
their speed diminishes to 50 km/hr in 20 m as deep water and the amplitude increases
so the wave may rise to a height more than 15 m even up to 30 m. The destruction
due to this can be colossal in magnitude [4].
Modeling of tsunami wave propagation is done by different equations such as
shallow water equation [5], Boussinesq equation [6] and Navier–Stokes equation [7].
When the wave like tsunami propagates large distance so the dispersion is the main
phenomenon that is necessary to be considered in modeling. Tsunami propagates
with varying wavelength and speed depends on varying depth of ocean [6, 8].
In this paper, the characteristics of tsunami wave calculated and analyzed analyt-
ically by using boussinesq approximation and solitary wave theory. The propagation
phase of tsunami wave and their characteristics were analyzed and explained in a
detail manner. The selected zone is divided into small grids. Tsunami celerity, wave
period, wavelength, amplitude, travel time and pressure of wave are calculated and
their relationship analyzed.
2
Methods
2.1
Selection of Zone for Modeling
Modeling carried out for the December 26, 2004 tsunami. The zone selected for
modeling is shown in Fig. 1 as a rectangular section which is obtained from U.
S. Geological Survey [9]. Location of epicenter and Chennai, Marina Beach are as

Modeling and Analysis of Tsunami Wave Propagation …
639
Fig. 1 Selected zone for modeling (95.85 E, 3.316 N and 13.04375 N and 80.28542 E) [9]
follows 3.316 N, 95.85 E and 13.04375 N, 80.28542 E. In this zone, no disturbance
in the ocean and it is considered as a homogeneous condition. Ocean bathymetry
and coastal topography are the important parameter in modeling of tsunami wave
propagation. Bathymetry of ocean and topography data are collected from General
Bathymetric Charts of the Oceans (GEBCO) [10].
2.2
Generation of Tsunami
Tsunami generation depends on the earthquake parameter. Earthquake parameters
responsible for tsunami generation are Magnitude of earthquake, Type of fault,
Depth of earthquake, Area of fault, Depth of water at the rupture area, Location
of earthquake, Height of deformation and Energy released by the earthquake.
In this study, the selected zone [95.85 E, 3.316 N and 13.0403 N and 80.28 E] for
modeling is considered as a homogeneous ocean because there is no disturbances
in between the selected location. 95.85 E, 3.316 N is a location of epicenter (West
coast of northern Sumatra, Indonesia) and 13.0403 N and 80.28 E is a destination

640
M. Y. Regina and E. S. Mohamed
(Marina Beach, Tamil Nadu, India) where tsunami height and travel time measured
for reaching that point.
Ocean bathymetry and coastal topography are the important parameter in
modeling of tsunami wave propagation. Bathymetry of ocean data is collected
from GEBCO [10]. December 26, 2004 tsunami earthquake parameter are collected
from National Oceanic Atmospheric Administration (NOAA) [11]
and this is
recorded as the most dangerous tsunami in the history. The fault parameters such as
length, width, depth, dip slip and strike angles were obtained from cahyadi (2014)
and tsunami generation parameters are given in Table 1.
Water upliftment due to the 9.1 magnitude shallow earthquake of 15 m depth
is plotted below. It shows water level uplifted above mean sea level for time of
one second. Volume of water uplifted during the earthquake is one of the important
parameter in tsunami modeling which describes the strength of tsunami and the
location of earthquake (deep water earthquake or shallow water earthquake) which
determine how big the tsunami will be happened. The energy released by the rock
during earthquake transferred to the water. The above are responsible for the tsunami
initiation.
Theseabottomdeformationduetoearthquakeisdenotedasξ(x, y, t)andη(x, y, t)
is the free surface of water.
Initial condition of ocean before the earthquake,
z(x, y, t) = 0 = ξ(x, y, t) at time t = 0
z(x, y, t) = η(x, y, t) = 0 at time t = 0
z(x, y, t) = −h(x, y, t) at t = 0
⎫
⎬
⎭
(1)
Table 1 Tsunami parameters
for December 26, 2004 [12]
1
Source
West coast of northern Sumatra,
Indonesia
2
Longitude
95.854 E
3
Latitude
3.316 N
4
Magnitude
9.1 to 9.3
5
Type of fault
Thrust fault
6
Focal depth
30 km
7
Fault length
1200 km
8
Fault width
90 km
9
Fault depth
15 km
10
Energy released
1 × 1017 J
11
Dip
12o
12
Slip
90o
13
Strike
323o
14
Rupture speed
2.8 km/s
15
Height of tsunami
15 to 30 m

Modeling and Analysis of Tsunami Wave Propagation …
641
The vertical velocity is zero at the sea bed. Before earthquake, the water move-
ment is not occurred at the bottom. Once the tsunami generated, the water particle
movement occur up to the sea bed that is the wave of translation started. The amount
of water displaced by the earthquake is moving outwards till it reaches the shore or
inland. This will increase the global sea level in a small level. Overall rising global
sea level is 0.1 mm because of the 2004 tsunami [12].
Ocean condition after earthquake,
z(x, y, t) = −h(x, y, t) + ξ(x, y, t) at t > 0
z(x, y, t) = η(x, y, t) at t > 0

(2)
2.3
Propagation of Tsunami
Tsunami is a shallow water waves where the wavelength (λ) is greater than the water
depth (h), water particles displacement occurs up to the seabed. Their characteristics
are similar to solitary waves. These waves are propagting in an elliptical orbit because
the entire domain will be considered as a shallow water depth once the tsunami
initiated [13]. It is a nonlinear and dispersive wave. It has different wavelengths
travel with different phase speed and the phenomenon called frequency dispersion
which can be obtained by boussinesq approximation. Wave celerity depends only
on water depth. In shallow water, due to the disruption of ocean bottom reduces the
water particle velocity and it doesn’t return to their original position.
Consider ‘’ is the domain in three dimensional which represents the ocean where
the tsunami wave is propagating. The domain is divided into multiple sub-domains as
a control volume. Assumptions for the modeling are following, (i) water is ideal and
incompressible, (ii) water is said to be irrotational, (iii) Surface tension is neglected,
(iv) Seabed is rigid and Impermeable, (v) Potential ﬂow theory is applicable, (vi)
Pressure at the free surface is uniform and constant, (vii) Vertical velocity at the
sea bed is zero. Boussinesq approximation is applied for water waves in shallow
water condition with dispersive nature and the nonlinearity of the equation can be
expressed using Ursell number and the equation is given below,
∂2η
∂t2 −gh∂2η
∂x2 −gh ∂2
∂x2
3
2
η2
h + 1
3h2 ∂2η
∂x2

= 0
(3)
For solitary waves, the Ursell number UR > 450, η
H = 1. Wave characteristics
only depend on wave height (H) and water depth (d) and independent on wavelength
(L) and wave period (T).
The following governing equations are satisﬁed in each control volume and inter-
polate the values to get values at the control surface, the generating force of tsunami

642
M. Y. Regina and E. S. Mohamed
is an earthquake, volcanic eruption, etc. But the restoring force of tsunami is gravity.
So the other force surface tension, viscous forces are eliminated. Coriolis force is
considered because it has some inﬂuence in the wave amplitude but not much differ-
ence in the travel time [14]. If the source width of tsunami generation increases, the
Coriolis Effect will increase [15].
Governing Equations: Each control volume satisﬁes the Continuity equation. It
maintains the conservative property.
Conservation of mass is given by,
∂η
∂t = ∂
∂x[(η + h)u] + ∂
∂y[(η + h)u] = 0
(4)
Conservation of Momentum: Conservation of momentum in x, y direction as
follows
∂u
∂t + u∂u
∂x + v∂u
∂y −f v + g ∂η
∂x = 0
(5)
∂v
∂t + u∂v
∂x + v∂v
∂y −fu + g ∂η
∂y = 0
(6)
where f = coriolis parameter = 2Sinϕ,  = angular velocity of earth’s rotation =
0.73 × 10–4 s−1,  = latitude.
Boundary conditions: At the surface, the vertical velocity is independent on x, y
direction,
Dη
Dt = ∂η
∂t + v.∇η = w
where, z = η(x, y, t)
(7)
Based on the Kinematic bottom boundary condition, the vertical velocity (w) is
zero at the sea bed, z = −h(x, y)
u. ∇(z + h(x, y)) = 0
(8)
Based on the dynamic free surface boundary condition, the pressure at the free
surface is zero, i.e., P = 0 at z = η. The following equation is applicable when the
height of wave (H) is very small compared to water depth (d) and wavelength (L)
and it is valid for H/d < 1, H/L < 1
η = 1
g · ∂φ
∂t
at z = 0
(9)
Tsunami waves are shallow water waves and potential wave ﬂow which satisﬁes
the Laplace equation in the region,

Modeling and Analysis of Tsunami Wave Propagation …
643
∇2φ = 0
(10)
Velocity potential φ is given by,
φ = −gH T
4π
cos h
 2π
L (H + z)
	
cos h

 2π
L H

sin(kx −ωt)
(11)
where H = Wave height, T = Wave period, z = Water depth, L = Wavelength, k =
Wave number (2π/L), ω = Wave frequency (2π/T), x = Distance, t = Time and g
= Acceleration due to gravity.
Displacement of the sea surface height is η (x, y, t), Mean sea level is denoted
by ‘z’, bottom topography is denoted by –h (x, y), the velocity throughout the ﬂuid
domain is u (x, y, z, t) and the velocity of a ﬂuid parcel in x, y, z direction is u, v, w.
u = ∂ϕ
∂x ; w = ∂ϕ
∂z
(12)
The amplitude of tsunami (η) is derived based on the solitary wave theory and it
increases with shallower water depth. The wave enters into the shallow depth, the
wavelength and wave celerity reduces with increasing ampliﬁcation of tsunami and
the equation of tsunami amplitude (η) is given below,
η(x, y) = H. sec2 h

3
4 · H
d3 (x −ct)
(13)
where H = wave height of tsunami (crest to trough), d = depth of water, c = celerity
of the tsunami wave, t = time and x = space coordinate.
Wave height can be calculated using the Green’s law as follows,
H1 =
Do
D1
 1
4
· Ho
(14)
where H = tsunami wave height, D = water depth, Subscript ‘0’ represents deep
water and subscript ‘1’ represents shallow water.
Pressure and the wave height relation which is important for tsunami warning
system is,
η = N(P + ρgz)
ρgK
(15)
where η = tsunami amplitude, P = pressure, ρ = density of ocean, seawater density
at 20 °C is 1.024 g/cm3. K = pressure response factor, 1/cosh kd, k = wave number
(2π/L), d = water depth, z = water depth, g = acceleration due to gravity and N is

644
M. Y. Regina and E. S. Mohamed
a constant. If N > 1, the wave is long period wave, N < 1 = short period wave and
N = 1 means linear wave.
Tsunami waves are similar to solitary waves. The variables wave celerity, wave
height and pressure of the water particle depends on the wave height, water depth
in x, y direction. These solitary waves have long wavelength and long wave period.
These waves have sharp crest and no trough. The celerity of the wave (C) depends on
the depth of water (d) and wave height (H). Local speed of propagation of tsunami
in any direction is given below. The phase celerity (Cp) and group celerity (Cg) are
equal.
Cp = Cg =

gh(x, y)
(16)
According to Russell’s empirical formula, the celerity will be
C =

g(d + H)
(17)
where d = water depth, H = tsunami height above msl and g = acceleration due to
gravity.
Using boussinesq equation, the linear frequency dispersion characteristics of
equation gives the phase speed of wave (C) which relate the wave number (k) is,
C2 = gh

1 −1
3k2h2

(18)
kh < 2π/7 equivalent to wavelengths λ longer than 7 times the water depth for fairly
long waves. K = wave number, h = tsunami wave height and g = acceleration due
to gravity.
Travel time of tsunami is calculated by dividing the selected zone into grids. The
grids are divided and equally spaced in the interval of 1°. Each and every grids the
depth is averaged based on that the parameters such as tsunami amplitude, wave-
length, water pressure, speed and travel time of the tsunami are calculated for each
and every grid by using the above-mentioned equation analytically approach. From
the observed value [16], initiation time of tsunami is 06.29 am and the ﬁrst wave
reached the coast of Tamil Nadu at 08.50 am, travel time of tsunami to reach Tamil
Nadu was 2 h 21 min. Tsunami reached Chennai coast at 09.06 am.
3
Results and Discussion
The selected region is divided into grids of equally spaced intervals. The tsunami
wave parameter is calculated for each and every point of grids. The below ﬁgure
shows the fault boundary of Sumatra. The points A, B, C, D, E, F, G, H, I, J, K and
L are taken from the fault boundary and these are assumed as the wave initiation

Modeling and Analysis of Tsunami Wave Propagation …
645
Table 2 Time taken for rupture to reach the initiation points
Tsunami
waves
Initiation points
Distance
between
points (km)
Total
distance
(x in km)
Time taken to reach for rupture
between points (t = x/v)
longitude
(°E)
Latitude
(°N)
t in
seconds
t in
minutes
t in hours
A
95
2.5
0
0
0
0
0
B
94
3
124.2
124.2
44.357
0.7392
0.01232
C
93.2
4
142.3
266.5
95.178
1.586
0.02643
D
92.9
5
116.1
382.6
136.642
2.277
0.03795
E
92.8
6
111.7
494.3
176.535
2.942
0.04903
F
92.5
7
116
610.3
217.964
3.632
0.06054
G
92.2
8
116
726.3
259.392
4.323
0.07205
H
91.8
9
119.6
845.9
302.107
5.035
0.08391
I
91.5
10
116
961.9
343.535
5.725
0.09542
J
91.6
11
111.7
1073.6
383.428
6.390
0.10650
K
91.7
12
111.7
1185.3
423.321
7.055
0.11758
L
91.8
13
111.7
1297
463.214
7.720
0.12867
points. Rupture velocity (v) is 2.5 m/s. The time taken to reach these points are given
in Table 2.
From the observed value [16], initiation time of tsunami is 06.29 am and the ﬁrst
wave reached the coast of Tamil Nadu at 08.50 am, travel time of tsunami to reach
Tamil Nadu was 2 h 21 min. Tsunami reached Chennai coast at 09.06 am (Fig. 2).
Once the tsunami started, the wave characteristics are derived using the above
equation. From the observed parameter, assume the wave height in the deep ocean
was 60 cm. The wave height (H) and tsunami amplitude (η) for a solitary wave
approximation is η/H = 1. The wave height for the various depths are calculated
using Eq. (3). Assume the tsunami wave period in the deep ocean is 24 min and
amplitude of tsunami is 60 cm. The wave height increases and the wave celerity
decreases at the shallower region. At the depth of 18 m, the wave speed reduces to
47.838 km/hr and the wave height at that point is 2.388 m are calculated by this
modeling.
Figures 3 and 4 show the amplitude increases and wave celerity reduces with
propagation of wave from deep to shallower depth. The celerity of the tsunami
depends only on the water depth. The wave celerity and wavelength are larger in
Deep Ocean which diminishes with shallower depth. Friction at the sea bed reduces
the wave speed and subsequently wavelength reduces due to this drag force. If the
wavelength reduces then the large amount of energy tries to accumulated in the small
length which cause the steepens or increases the wave height. The maximum wave
celerity at the deep ocean is calculated as 750–800 km/hr by using Eq. (17). The
celerity of tsunami wave at the coast (80.28542 E, 13.04375 N), 25.21285 km/hr is
calculated.

646
M. Y. Regina and E. S. Mohamed
Fig. 2 Sumatra fault boundary with initiation points (Tectonics observatory)
0
1
2
3
0
500
1000
1500
2000
2500
3000
3500
4000
Amplitude (m)
water depth (m)
Relaonship between Tsunami amplitude and 
Water depth
η= 2.388 m
Fig. 3 Relationship between tsunami amplitude and wave height

Modeling and Analysis of Tsunami Wave Propagation …
647
0
100
200
300
400
500
600
700
800
0
500
1000
1500
2000
2500
3000
3500
4000
Wave celerity (km/hr)
water depth (m)
Wave celerity vs water depth 
C = 25.21285 km/hr
D = 5 m
Location: 80.2852E, 13.04375N
Fig. 4 Relationship between wave celerity and water depth
If the condition of wavelength is greater than 7 times the wave height is satisﬁed
thenthetsunamiwaveisalongwave.Theaboveconditionisprovedinthedeepocean.
If this condition is not satisﬁed, i.e., λ < 7H, so the wave might break in this place
and due to this massive breaking wave or a ridge reaches the shore, The calculated
results by using Eq. (18) shows that the above condition is satisﬁed in the deep ocean
and not satisﬁed very shallower depth nearby the shore so it concluded the massive
breaking wave might reaches the shore which veriﬁed by the tsunami reaches the
Marina Beach as massive ﬂooding on December 26, 2004. The calculation showed
that the range of 160–18 m depth of water, the wave breaking occurs, the calculated
wave height is 1.38–2.39 m between this region.
The wave started to curl when it reaches the nearby shore. It shows that the wave
reaches the coast as a massive ﬂooding. At the time of tsunami in Marina Beach,
the tsunami reached as a massive ﬂooding. So it satisﬁes the real time parameter.
Figure 5 the tsunami reach the shore as a ﬂooding [17].
Pressure and wave height relationship is an important parameter in the tsunami
early warning system. A DART buoy measures the very small level differences in the
pressure of seawater. Using Eq. (12), the following parameters calculated. Tsunamis
are long period waves in the open ocean when it reaches the shallower coast the
period of wave are going to reduces at 18 m depth of water the period of waves were
small or short period waves which is similar to the results obtained by Eq. (18) so,
the tsunami break down before it reaches the coastline in Chennai coast.
Figure6shows that thereis verylittledifferences intheamplitudeof tsunami while
the wave traveling in the deep ocean. The amplitude of tsunami increases when it
entered into the very shallower coast. Nearby the shore only the amplitude increases
quickly. Tsunami amplitude started to increase in the very shallow water. In the deep
ocean, the amplitude ranges from 0.6–0.8 m. After this enter into the shallow coast,
tsunami amplitude increasing rapidly. For Chennai, Marina Beach which calculated
as 2.388 m. Observed wave height at Marina Beach, Chennai, Tamil Nadu was 2.23 m
[11].

648
M. Y. Regina and E. S. Mohamed
Fig. 5 Tsunami reached as a massive ﬂooding in Marina Beach [17]
0
1
2
3
1002 751 501 250 117 101
86
70
54
39
23
7.9
Amplitude of tsunami (m)
Distance from shore (km)
Tsunami Propagation distance Vs 
Amplitude
Amplitude
of tsunami
η= 2.388m
Fig. 6 Relationship between Tsunami amplitude and wave propagation distance
Travel time of tsunami is calculated by dividing the domain into grids. The nodes
where the wave passes through to reach the destination are deﬁned. The times taken
to reach the nodes are calculated using wave speed and distance between the nodes.
For every grids, the depth is taken as average depth, the celerity and the tsunami
amplitude values calculated for ever grids. In this study, nearly 12 waves are taken
from various initiation points at the rupture length. The path of various tsunami waves
initiated from various points is found and the travel times to reach the location of
Marina Beach, Tamil Nadu, India are identiﬁed. Rupture velocity is 2.5 km/s, total
rupture length is 1200 km and the observed earthquake duration 8 min. Travel time
is calculated using the above data, the tsunami initiated points are chosen at the plate
boundary of rupture area in the Sumatra.

Modeling and Analysis of Tsunami Wave Propagation …
649
Figures 7 shows the travel time of tsunami from various initiation points which
located at the rupture to Chennai, Tamil Nadu, India. From this study, the ﬁrst wave
reached Chennai at 2 h 21 min 54 s of travel time. The observed initiation time 06.29
am, then it will reach at 08.50.54 am. It matches the observed arrival time of tsunami
in Tamil Nadu coast [16]. Travel time of tsunami to reach the destination of Marina
Beach, Chennai was given in Table 3.
3.43 3.23
3.2
2.88 2.77 2.66 2.53 2.45 2.37 2.36 2.36 2.39
0
1
2
3
4
Travel me (hrs)
Travelling distances of various waves (km)
Travel me of tsunami for waves from diﬀerent 
iniaon point
First wave reach at 2.36 hrs
(2 hrs 21mins  54secs )
Fig. 7 Travel time of tsunami waves initiated from various points at the rupture area
Table 3 Travel time of tsunami
Tsunami
waves
initiated
points
Distance
between
location of
rupture
Time for
rupture
Initiation time
Distance
from
source to
Chennai
(km)
Total travel time
Seconds
Minutes
Seconds
Hr.
Min.
Sec.
A
0
0
0
1
1999
3
25
53
B
125.2
50.08
0
50
1876
3
14
12
C
266.5
106.6
1
46
1739
3
12
16
D
382.6
153.04
2
33
1648
2
52
58
E
494.3
197.72
3
17
1579
2
46
30
F
610.3
244.12
4
4
1496
2
39
57
G
726.3
290.52
4
50
1418
2
32
14
H
845.9
338.36
5
38
1334
2
27
12
I
961.9
384.76
6
24
1268
2
22
38
J
1073.6
429.44
7
9
1251
2
21
54
K
1185.3
474.12
7
54
1244
2
22
11
L
1297
518.8
8
38
1247
2
24
59

650
M. Y. Regina and E. S. Mohamed
Fig. 8 Travel time of tsunami to reach the coast of Bay of Bengal
Figure 8 shows the travel time of tsunami to reach various locations in the coast of
Bay of Bengal. It shows the observed and calculated travel time of tsunami to reach
each locations. The little differences comes between observed and calculated value.
This will be rectiﬁed in our future work.
4
Limitations
The propagation phase of the tsunami is only discussed here. Generating parameter
doesn’t consider here. Tsunami initiation and propagation depend on the genera-
tion phenomenon. Energy transfer is responsible for the tsunami to propagate large
distances. In this study, the energy of the wave is not considered. High energy
waves travel slowly and these are the main factors for the second wave of tsunami
which makes major destruction. The height of water upliftment or volume of water
upliftment is also an important parameter for tsunami initiation and its propagation.
These parameters not discussed here. The modeling is done by analytical method.
Numerical techniques are useful in getting more accuracy values of the tsunami
parameters.

Modeling and Analysis of Tsunami Wave Propagation …
651
5
Conclusion
In this study, mathematical modeling of tsunami wave propagation using boussi-
nesq equation gives a better result of tsunami propagation modeling because of
considering the nonlinearity and dispersion behavior. Tsunami wave characteristics
value obtained in this model is veriﬁed with the observed parameter of the tsunami
happened on December 26, 2004. At the coast, the speed of tsunami reduces to
25.21 km/hr, tsunami amplitude is 2.388 m at 18 m water depth and the travel time of
ﬁrst tsunami wave reach Marina Beach 2 h 21 min 54 s are calculated by using this
modeling. From this study, speed of tsunami in the deep ocean is 694 km/hr and in the
shallow coast at 5 m depth which reduces to 25 km/hr. Amplitude of tsunami at the
coast is 2.388 m and nearby the shore tsunami started to curl (λ < 7H), so it reaches
the coast as massive ﬂooding. The values obtained using this modeling veriﬁed with
the observed parameter. The parameters calculated in this study matches with the
observed parameter.
In the further research work, the modeling work will be done by using numerical
techniques with Boussinesq approximation and solitary wave theory. The generation
and propagation phase will be modeled and the important parameters such as height
of water gradient, energy transfer by generating mechanism and the detailed analysis
of tsunami parameters will be done in future.
Acknowledgements We would like to thank this research paperwork has been supported by DST-
SERB project ref. no. CRG/2018/002022/MS in the project title on ‘CELLULAR AUTOMATA
MODEL FOR PROPAGATION OF TSUNAMI WAVE’.
References
1. Yasmin Regina, M., & Syed Mohamed, E. (2020). Study on Analytical modeling of tsunami
wave propagation (pp. 479–484). In Intelligent systems and computer technology. IOS press.
https://doi.org/10.3233/APC200188.
2. Syed Mohamed, E., & Rajasekaran, S. (2012). Tsunami wave propagation models based on
two-dimensional cellular automata. International Journal of Computer Applications, 0975,
8887 57– No. 20, November 2012.SU.
3. Valdiya, K. S., Environmental Geology, book.
4. International handbook of Earthquake engineering and seismology.
5. Altaie, H., & Dreyfuss, P. (2018). Numerical solutions for 2D depth-averaged shallow water
equations. International Mathematical Forum, 13(2), 79–90.
6. Ataie-Ashtiani, B., & NajaﬁJilani, A. (2007). A higher-order Boussinesq-type model with
moving bottom boundary: Applications to submarine landslide tsunami waves. International
Journal for Numerical Methods in Fluids, 53, 1019–1048, https://doi.org/10.1002/ﬂd.1354.
7. Kozelkov, A., Efremov, V., Kurkin, A., Pelinovsky, E., Tarasova, N., & Strelets, D. (2017).
Three-dimensional numerical simulation of tsunami waves based on the Navier-Stokes
equations. Journal of Tsunami Society International, Science of Tsunami Hazards, 36(4).
8. Jawad, A. J. M., Petkovic, M. D., Laketa, P., & Biswas, A. (2013). Dynamics of shallow water
waves with Boussinesq equation. Scientia Iranica B, 20(1), 179–184. https://doi.org/10.1016/
j.scient.2012.12.011

652
M. Y. Regina and E. S. Mohamed
9. https://www.usgs.gov/centers/pcmsc/science/tsunami-generation-2004-m91-sumatra-and
aman-earthquake?qt-science_center_objects=0#qtscience_center_objects.
10. GEBCO website: https://download.gebco.net/#.
11. The information on Tsunami events and runups can be downloaded from the following link:
https://www.ngdc.noaa.gov/hazard/tsu.shtml.
12. Cahyadi, M. N. (2014). Comparison of coseismic ionospheric disturbance waveforms revisited:
strike-slip, normal, and reverse fault earthquake. Geoid, 10(01), 104–110.
13. Yuvaraj, V., Rajasekaran, S., & Mohamed, E. S. (2017). An alternative analytical model for
propagation of tsunami waves. International Journal of Pure and Applied Mathematics, 113(6),
29–37.
14. Dao, M. H., & Tkalich, P. (2007). Tsunami propagation modeling—A sensitivity study. Natural
Hazards and Earth System Sciences, 7, 741–754.
15. Kirby, J. T., Shi, F., Tehranirad, B., Harris, J. C., & Grilli, S. T. (2013). Dispersive tsunami
waves in the ocean: Model equations and sensitivity to dispersion and Coriolis effects. Ocean
Modelling, 62, 39–55. https://doi.org/10.1016/j.ocemod.2012.11.009
16. Sheth, A., Sanyal, S., Jaiswal, A., & Gandhi, P. (2006). Effects of the December 2004 Indian
Ocean Tsunami on the Indian Mainland. Earthquake Spectra, 22(S3), S435–S473.
17. https://timesoﬁndia.indiatimes.com/event/2004-Indian-Ocean-tsunami/articleshow/550711
72.cms.

An Android Application
for University-Based Academic Solution
for Crisis Situation
Md. Nasﬁkur R. Khan, Asif Khan Shakir, Shantunu Shakhwat Nadi,
and Mohammad Zoynul Abedin
Abstract In this paper, we design an Android application-based framework for a
university-based academic solution for a crisis period. Nowadays people feel more
comfortable using an Android phone for their regular day-to-day activities. Besides,
during crisis moments, when people need to stay home for a longer period, smart-
phones are turning into the main source of entertainment, information, communica-
tion resource and many more. Considering the impact of this Android technology
on university going students, we have designed and constructed an Android appli-
cation named ‘Study-Mate’. By using this application, students can ﬁnd registra-
tion and course information, lecture notes, faculty information, and research infor-
mation, updated results from outside the campus, pay their registration bills and
can contact their faculty members directly by saving both faculty and student’s
proﬁle on the application. On the other hand, faculty members can use it for online
attendance, updating course materials, lecture notes and information related to the
course and university. Lastly, it also provides the opportunity to conduct short classes
online and students can attend them by the use of the internet. The outcome shows
that the application is very promising considering the other available platforms in
Bangladesh.
Keywords Android application · Internet · Online platform · Mobile phone
Md. N. R. Khan (B) · S. S. Nadi
Automation, Application and Biomedical Based Technical (AABTech) Lab, Dhaka, Bangladesh
e-mail: mnrkhan@iub.edu.bd
Department of Electrical and Electronic Engineering, Independent University, Dhaka, Bangladesh
A. K. Shakir
Department of Software Engineering, Daffodil International University, Dhaka, Bangladesh
M. Z. Abedin
Department of Finance and Banking, Hajee Mohammad Danesh Science and Technology
University, Dinajpur, Bangladesh
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_51
653

654
Md. N. R. Khan et al.
1
Introduction
In the twenty-ﬁrst century, the internet and advancing technology have seen many
backlashes for its misuse. Sadly, its good aspects are being overlooked. The connec-
tivity among users and the plethora of information that it provides us at the click
of a button is incredible. But the media and entertainment industry has overshad-
owed all the positive ways that progressing technology is improving our lives. Tech-
nology has advanced so much that handheld devices, like smartphones and tablets,
have enabled people to seek information whenever and wherever they may need
it. A large part of students uses this aspect of sharing information through a more
accessible and user-friendly medium to know more about what they are studying.
Academic students receive notiﬁcation or important announcements through emails
or social media, such as Facebook, for their course information and materials. But
as we know, they are not the right platform nor do they create the right atmosphere
for school bodies to interact with their scholars/pupils [1]. Additionally, instead of
integrating students to our aged methods of information sharing where students have
to be present on the university campus to look for important announcements hung up
on notice boards or going to the ofﬁcial websites that may have a confusing interface
due to a greater number of schools using the same page to share their information,
we can reshape our method to achieve the goal of swift information sharing through
Android application. For a student, an Android application becomes a step easier
to access and obtain information. Such Android applications are already in place in
other well-known Universities, such as Harvard University, and have proven to be
beneﬁcial. Repeatedly logging into an account can also be tedious and frustrating.
Having an app that remembers your Login information securely makes the whole
process of accessing the University database much simpler and swift. This Android
platform will also enable faculty members to give quicker instructions, guidance,
and announcement for the students. The sudden surge in the speed and accessibility
of transmitting data wirelessly to handheld devices do play a huge role in why using
such a medium can be helpful. Researchers have aimed to develop and provide a
generalized solution to monitor various works that are carried out by a college for
automation of various tasks. They provided up to date information on the system
which improved the efﬁciency of university record management and decrease the
room between students and college [2]. Another application provided a general-
ized solution to monitor the various works that were carried out by a construction
company at different geological points. By using a Web Service, the data was stored
in the remote database. This mobile application requires Wi-Fi technology to reach
a remote database. Although several sections of this application can be browsed
without the internet as it has storage facilities for saving data through ﬁre-base data
storage system. Another application also allows lecturers to take the attendance of
students via smartphones. First of all, lecturers need to log in to the phone applica-
tion, get connected with the server and take attendance using a Smartphone. After
taking the attendance through mobile, lecturers need to send the updated list to the
server using the internet. Additionally, this app also gives the lecturers the ﬂexibility

An Android Application for University-Based Academic Solution …
655
to edit the attendance by logging on to their proﬁle. It allows the students to see their
attendance as well as curriculum information.
Lastly, the application also helps the faculties to run live classes with the help
of Google live classrooms, which will help during any crisis, relate to the society
or environment. With all these are in mind, an Android-based application has been
developed, where the students and faculty members can use this application with
their university Login ID. At ﬁrst, a student will choose their school, then their
department. Under the department, they can select “Course”, “Faculty”, “Research”,
“Publication”, or “Result”. They will have access to a simple interface that will
guide them through the Course Updates, Faculty details, Research groups, and their
information, and semester results. Currently, the university Android application is
being developed for mobile but broadening its reach for IOS and other OS devices is a
future goal for this application. Due to this application taking the user to the webpage
of the selected option, it requires a network connection and a Google account to be
full of use.
2
Taxonomy of Research
The process starts with an Interface of login and new user registration option, which
helps to login to any existing account or opening a new account, along with that,
it allows user to gain access to this application. Figure 1a and b show the interface
of the user’s login procedure. The next step leads to the user’s proﬁle with four
different options. The ﬁrst option is followed by a layout of different schools, in
which the user gets the opportunity to select a school and a speciﬁc department.
After selecting the speciﬁc department, it allows the user to get into another layout
of the list including the course detail, faculty information, research updates, and
Fig. 1 a User’s login and
b Preliminary interface with
school information of
Independent University,
Bangladesh

656
Md. N. R. Khan et al.
publications. By selecting a speciﬁc option, the user gets the opportunity to view the
details of that section [3].
Figure 2a and b demonstrate the interface of the School of Engineering and
Computer Science and the interface of the Electrical and Electronic Engineering
department’s proﬁle. After getting into the proﬁle of a speciﬁc department, the user
gets the opportunity to select the tab s/he wants to browse. Figure 3a and b show
the interfaces of courses and faculty tabs, which help the users to get the updated
information of the courses and faculty members. The proﬁles of two faculty members
have been mentioned in Fig. 4.
Lastly, the Android application also has the opportunity to check grades and take
attendance. In Fig. 4, an interface of the grades of a student has been shown. The
overall working procedure is described through a ﬂowchart as shown in Fig. 5.
Fig. 2 a Interface of
different departments of the
school of engineering and
computer science b Various
information of EEE
department
Fig. 3 a Courses
information and b Faculty
list of EEE department of
IUB

An Android Application for University-Based Academic Solution …
657
Fig. 4 a, b Proﬁles of two distinguished professors of the EEE department of IUB (with permission)
and c grade of a speciﬁc semester of a student
Fig. 5 Block diagram for the working procedure of the application for school-based information

658
Md. N. R. Khan et al.
Through this application, students can get their necessary materials like a soft
copy of books, lecture notes, sample questions, etc. for their study purposes. They
canalsocloselyseetheirfacultymembers’educationalbackgroundandtheirresearch
ﬁeld through links that are provided over there. For an emergency, students can send
emails to their speciﬁc course instructor and the email of the instructor is provided on
their proﬁle by clicking on MORE DETAILS options as shown in Fig. 4a, b. Besides
this application also provides the opportunity to conduct online classes and students
can join in and attendance automatically will be counted.
3
Case Study
As an attempt to implement our “Study-Mate” project, we performed experiments,
on ﬁfty-two users, from diverse backgrounds, which help us to achieve our goal to
establish the application for all kinds of users by providing a simple solution to their
academic problem. The following leads to their introduction.
3.1
Participant Type One
This category belongs to the 15 ﬁrst-year students, who just have started their under-
grad in 6 different private universities in Dhaka. Most of them are from small town
to Dhaka, have shifted recently and their knowledge of Android phones is minimum.
3.2
Participant Types Two
6 different senior faculties of the Electrical and Electronic Engineering department
of Independent University, Bangladesh. They have been requested to provide their
response to the application. All of them have completed their higher studies from
distinguished universities in North America. Some of them are conducting classes
in rooms without computer facilities and that is why they need to take attendance
manually through the time-consuming paper. They also have a better understanding
of Android phones and similar applications. Besides, during the current unstable
situation for the COVID-19, they need to perform classes online.
3.3
Participant Type Three
13 sophomores of different universities are typecast in this category. Most of these
students are studying in the BBA department BBA. Every day they travel a lot to

An Android Application for University-Based Academic Solution …
659
attend their classes because all of them live far away from their university campuses.
Especially they miss classes at 8:00 AM due to trafﬁc jams. They have adequate
knowledge of Android devices and applications.
3.4
Participant Type Four
This group pertains to 12 graduate engineering students, who got admitted to a
particular university to complete their post-graduation. They are also doing jobs to
support their family. Due to job purposes, they couldn’t attend all of their classes.
They are experts in using an Android device and its application.
3.5
Participant Type Five
6 different age female post-graduate students, who are mostly working as housewives
have belonged to that category. Most of them are studying from home and through
distance learning, they are trying to complete their course works and exams. Most
of them rarely use android-based applications.
4
Experiments
Step by step methods has been followed to check the experiences of ﬁve different
participants. Kind of support they got from the Android application on regular uses
for university purposes. The procedures were as follows:
First of all, hand over the Android device to the participants especially those
who are very less familiar with Android applications. Priorities were given to them
at the beginning for providing adequate training to get used to Android devices.
After four sessions with Android devices, we let them use the application to adapt
to it. Secondly, aid was given to the ones who are facing difﬁculty to start up the
application. After providing them with assistance all the participants were able to
install and use the application without any external help [4–6]. Next thing is to let
them open, run, customize according to their preference and create their proﬁle. To
ﬁnd out how they are using the application according to their comfort zone. But if still,
they face problem difﬁculty in using the application, we sort it out on whichever part
of the application they are unable to operate. So, they can use it properly. Our ﬁnal
targetistojudgeespeciallyaftersolvingtheirproblemregardingtheapplication.How
effortlessly and smoothly they are using the application for their university purposes.
We have learned that the implementation of this application, through which a student
can keep records and get their study materials [7–9].

660
Md. N. R. Khan et al.
5
Results
From this evaluation of the system, all the participants were given the device to
use the application for the same time duration. Although the time might vary due
to participants having different adaptability and knowledge with application. The
overall outcome of the experiment on the participants can be summarized as follows:
The ﬁrst group of participants could read but their knowledge of Android application
is very minimum. So, initially, they had a hard time adjusting themselves to the
application. They found it quite complicated in the beginning session. However, they
improved continuously session by session. By the ﬁnal two sessions (9 sessions) most
of them run the application effortlessly and were positive about using the Android
application. Although participants types two are familiar with Android devices, they
lead a busy life to attend sessions. However, most of them attended overall eight
sessions in total and run the application smoothly by the end of these sessions.
They seem interested to use the application regularly for their professional life in
universities [10–13]. The third type of participants have adequate knowledge of
Android and the application than the previous two types of participants and used most
oftheoptionswithoutanyexternalsupport.Forthem,ﬁvesessionswereenoughtoget
complete use of all the options of the application. Participants type four was a group
of very quick learners and had experiences using an Android device. It took only
four sessions for them to know the complete use of this application. They were very
positive about using this application which helps them a lot to get their study material
and lecture notes. Participant’s type ﬁve has completely different experiences in the
beginning with the application. All of them took extra sessions (on an average total
of eleven sessions) to open and run the application. But later they become more
engaged with it and zeal with most of the features. Overall, we tried to capture all
relevant information based on ratings, which have been summarized in Table 1.
In short, it is understood that all ﬁve types of participants were comfortable with
the application and they utilized the application effectively without any external
help by the end of eleven sessions as Android devices are very accessible making
it easy for the participants to adapt to the app. Besides, all four student-participants
groups were also very impressed with the fact that such an app might lead them to
save more time and effort to collect more study information and course materials
along with the beneﬁt of visiting the faculty member’s proﬁle and availability. The
proposed app was well appreciated by participant type two, who is currently working
as a faculty member in the EEE department of Independent University Bangladesh.
Additionally, most of them want to involve in the development of this application and
work to enhance the usability of the application in the future. Lastly, we studied the
android applications designed for and by other universities in Bangladesh and listed
out the features of all these applications, then compared those with the Study-Mate
android application. Table 2 has shown the results.

An Android Application for University-Based Academic Solution …
661
Table 1 Participants response
Participants
Previous experience
Ratings based on usability (Out of 5)
L
U
C
I
O
Type one
The participant has little
experience and knowledge on
Android device but this kind of
application is unknown to him
3
5
5
4
4.25
Type two
This participant has some
experience and familiarity with
the Android device but not used
to with these kinds of
applications
4
4
5
3
4.25
Type three
This user got better knowledge
than the previous two
participants. He has little idea of
these types of applications
3
5
4
4
4
Type four
This particular user is a quick
learner and also had a lot of
experience in using an Android
device. He knows how to
operate many other Android
applications
3
4
4
5
4
Type ﬁve
The user is almost new in terms
of handling the Android device.
So, her ability is the least
among the other
5
3
5
5
4.5
Table 2 List of android applications of universities in Bangladesh and their features
Name of apps
Features
A
Rg
P
At
N
D
Cd
On
As
F
s
R
Co
Study-Mate
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✕
BUET
✓
✕
✕
✕
✓
✕
✕
✕
✕
✓
✕
✕
✓
Bangladesh University
✓
✕
✕
✕
✓
✕
✕
✕
✕
✓
✕
✓
✓
University of Dhaka
✓
✕
✕
✕
✓
✕
✕
✕
✕
✓
✓
✓
✓
UTUians, Ucam
✓
✓
✓
✓
✓
✓
✓
✕
✕
✓
✕
✓
✓
AIUB Portal
✕
✕
✕
✓
✕
✕
✓
✕
✕
✕
✓
✓
✕
EWU NB
✕
✕
✕
✕
✓
✕
✕
✕
✕
✓
✕
✕
✓
BRACU Mobile
✕
✕
✕
✓
✕
✕
✓
✕
✕
✓
✓
✓
✕
NSU NB
✕
✕
✕
✕
✓
✕
✕
✕
✕
✕
✕
✕
✕
DIU—S. Student
✕
✕
✕
✕
✓
✓
✓
✕
✕
✕
✓
✓
✕
Aust-Hub
✕
✕
✕
✕
✕
✕
✓
✕
✕
✕
✕
✕
✕
A = Admission, Rg = Registration, P = Payment, At = Attendance, N = Notice Board, D
= Database, C = Course Details, O = Online Classes, As = Assignment Submission, F =
Faculties/Department, S = Student Proﬁle, R = Results, C = Career

662
Md. N. R. Khan et al.
6
Conclusion
An integrated solution of the university management system for students and faculty
members has been developed by using an Android application, which includes admis-
sion, registration, course materials, course information, faculty details, research
updates, publications, news and course grading information for student users with
a university-provided student identiﬁcation number. The app also includes online
attendance, news, information, course update facilities, and online class conduction
opportunity for faculty members by using individual proﬁles. Finding the faculty
member’s appointment gets easier than ever as this app will allow users to contact
the faculty directly through email. Besides this application is synchronized with
university websites and allows the user to directly get information from there. The
overall performance of this proposed Android application is quite positive with a
few sections to be updated in the future. A major update would be to allow students
to register and withdraw from different courses directly through the application.
However, by considering all these points and other available applications of different
universities, it can be said that Study-Mate is an improved and useful source for
students and faculties of Bangladesh to collaborate with the university-based educa-
tion procedure, speciﬁcally, the online class conduction opportunity will provide the
students and faculties with the luxury and comfort to attend and conduct classes
respectively from any sorts of situation, from anywhere in the world.
References
1. Tawheed, P., Shahin, F. B., Mashuk, A. E. H., Al Zabir, K., Poddar, G., Roy, R., & Khan, M. N.
R. (2017). Contemplation and challenges of mobile learning implementation. In Proceedings
of 14th global engineering and technology conference (p. 63). BIAM Foundation, December
29–30, 2017.
2. Oliveira, E. G. D., Oliveira, M. S. F. D., Neto, N. R., Soldati, F. D. P., & Nassur, T. L. C.
(2020). Development and evaluation of a mobile educational application to support teaching of
management of process in Operating Systems. In 2020 IEEE 20th international conference on
advanced learning technologies (ICALT), 2020 (pp. 19–21). https://doi.org/10.1109/ICALT4
9669.2020.00012.
3. Utesch, M. C., Faizan, N. D., Krcmar, H., & Heininger, R. (2020). Pic2Program—An Educa-
tional android application teaching computational thinking. IEEE Global Engineering Educa-
tion Conference (EDUCON), 2020, 1493–1502. https://doi.org/10.1109/EDUCON45650.
2020.9125087
4. Khan, M. N. R., Khan, M. R., Mashuk, A. K. E. H., Sunny, F. I., Farhan, S. K. A., Shukhon, R.
N. S. (2020). An android application to calculate the average chemical presence in food items.
In: Dawn, S., Balas, V., Esposito, A., Gope, S. (eds) Intelligent techniques and applications in
science and technology. ICIMSAT 2019. Learning and Analytics in Intelligent Systems, vol 12.
Springer, Cham. https://doi.org/10.1007/978-3-030-42363-6_16
5. Jahan, N., Ghani, T., Rasheduzzaman, M., Marzan, Y., Ridoy, S. H., & Khan, M. M. (2021).
Design and feasibility analysis of NSUGT a machine learning-based mobile application for
education. In 2021 IEEE 11th annual computing and communication workshop and conference
(CCWC), 2021 (pp. 0926–0929). https://doi.org/10.1109/CCWC51732.2021.9376040.

An Android Application for University-Based Academic Solution …
663
6. Konuk, M. S., Akku¸s, N., & Yerden, A. U. (2020). Development and application of android
based mobile optical test reading system. Innovations in Intelligent Systems and Applications
Conference (ASYU), 2020, 1–6. https://doi.org/10.1109/ASYU50717.2020.9259807
7. J.R. Corbeil and M.E. Valdes-Corbeil, “Are You Ready for Android Learning”, Educause
Quarterly, pp. 51–58, No. 2, 2016.
8. Khan, M. N. R., Sonet, H. H., Yasmin, F., Yesmin, S., Sarker, F., & Mamun, K. A. (2017). ‘Bolte
chai’—An Android application for verbally challenged children. In 2017 4th international
conference on advances in electrical engineering (ICAEE), 2017, pp. 541–545. https://doi.
org/10.1109/ICAEE.2017.8255415.
9. Diaz, J., Osorio, A., Harari, I., Amadeo, P., & Schiavoni, A. (2020). Mi Universidad mobile
application: an accessible door to educative services of the University. In 2020 15th Iberian
conference on information systems and technologies (CISTI), 2020 (pp. 1–6). https://doi.org/
10.23919/CISTI49556.2020.9140988.
10. Song, F. (2020). Mobile learning system of ideological and political education in universities
based on android. 2020 12th international conference on measuring technology and mecha-
tronics automation (ICMTMA), 2020 (pp. 750–754). https://doi.org/10.1109/ICMTMA50254.
2020.00163.
11. Khan, M. N. R., Mashuk, A. K. E. H., Durdana, W. F., Alam, M., Roy, R., & Razzak, M.
A. (2019). ‘Doctor Who?’ A customizable android application for integrated health care. In
201910thinternationalconferenceoncomputing,communicationandnetworkingtechnologies
(ICCCNT), 2019 (pp. 1–6). https://doi.org/10.1109/ICCCNT45670.2019.8944501.
12. Jianhong, L., & Xinyue, W. (2020). Design of mobile learning platform based on android. In
2020 15th international conference on computer science & education (ICCSE), 2020 (pp. 257–
261). https://doi.org/10.1109/ICCSE49874.2020.9201659.
13. Khan, M. N. R., Shahin, F. B., Sunny, F. I., Khan, M. R., Haque Mashuk, A. K. E., & Al
Mamun, K. A. (2019). An innovative and augmentative android application for enhancing
mediated communication of verbally disabled people. In 2019 10th international conference
on computing, communication and networking technologies (ICCCNT), 2019 (pp. 1–5). https://
doi.org/10.1109/ICCCNT45670.2019.8944655.

Never Underestimate Substitution
Cipher with Diffusion
Md Rasid Ali and Dipanwita Roy Chowdhury
Abstract This work investigates whether a modiﬁed substitution cipher can have
any cryptographic importance in today’s scenario. A classical substitution cipher is
a confusion-only cipher. Due to the absence of a proper diffusion mechanism, this
cipher is vulnerable to frequency attacks. We propose a block cipher model based on
the substitution cipher in which we introduce a diffusion mechanism and multiple
encryption rounds. The key indirectly used in the encipherment process is supplied
to a deterministic random bit generator to shufﬂe a look-up table (LUT) using a
uniform shufﬂing algorithm randomly. After studying the cryptographic properties
of randomly generated LUTs, we perform a case study of an imaginary block cipher
assumed to have a diffusion function equipped with a perfect diffusion property.
Though, a randomly generated permutation may possess weaker cryptographic prop-
erties with a high probability. From the investigation, we ﬁnd that with a robust
diffusion mechanism, the proposed modiﬁed substitution cipher can have sufﬁcient
potentiality against several popularly known attacks.
Keywords Substitution cipher · Pseudo random permutation · Diffusion · Degree
of completeness
1
Introduction
A substitution cipher is developed and used way before the modern computer era.
This cipher is one of the earliest forms of cryptography and is usually implemented
with pen-paper or some mechanical devices. A substitution cipher does not come
in comparison with the security point of view to a modern cipher. The majority of
modern symmetric ciphers use the concept of substitution cipher as one of the pri-
mary building blocks. Substitution Permutation Network (SPN) and Feistel network
are two symmetric cipher design structures employed by most modern symmetric
ciphers. AES (SPN) and DES (Feistel network) are two modern ciphers that perform
Md R. Ali (B) · D. Roy Chowdhury
Indian Institute of Technology Kharagpur, Kharagpur, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_52
665

666
Md R. Ali and D. Roy Chowdhury
the substitution and diffusion (in each round) operations iteratively on the plaintext
some ﬁxed number of times and results in the ciphertext.
The substitution operation in symmetric ciphers introduces confusion to the
cipher. Confusion is an operation that obscures the relationship between the key
and the ciphertext and makes each ciphertext bit dependent on many key bits.
There exist several design principles for achieving confusion. 8-bit invertible S-
box is used by 3D [21], Rijndael [14], ITUbee [15], which involves two operations.
One afﬁne transformation of GF(2) and inverse function in GF(28) is used where
the zero is mapped to itself. Two different 8-bit S-boxes are used in ARIA [17]. Both
S-boxes consist of different afﬁne transformations, though the same inverse function
y = x−1 is used. Similarly, four 8-bit S-boxes are used in Camellia [1]. Whirlpool [4]
and Crypton [18] use 8-bit S-boxes, which are made of three 4-bit S-boxes. For
ANUBIS [5], and CLEFIA [31] though the initial S-box design choice was a random
S-box, ﬁnally, two types of 8-bit S-boxes are selected. The ﬁrst one is an inverse func-
tion in GF(28), and the second one is made of two 4-bit S-boxes. For TWIS [25]
and DES, the input and output lengths of the S-box are not the same. LED [12],
PRESENT [7], Piccolo [30], TWINE [32], RECTANGLE [34], and MIBS [13] for
optimizing hardware resources use single 4-bit S-boxes, though, this decision com-
promised securities to more number of rounds. To balance the security criteria and
hardware resources, LBlock [33], Midori [2], Serpent [6], and mCrypton [19] use
multiple 4-bit S-boxes. Nyberg [22] in his theoretical work shows that the AES S-box
resists statistical attacks by achieving the highest possible nonlinearity. For the same
reason, many ciphers have accepted the same AES S-box. Ciphers achieve the confu-
sion from a publicly known function with higher nonlinearity and algebraic degrees,
substitution box. To withstand statistical attacks [26], the authors of GOST [11],
Twoﬁsh [28], PRINTcipher [16], and REDOC II [8] use key-dependent S-boxes.
However, these ciphers never gained popularity, as the generation of key-dependent
S-box on-the-go is an expensive operation.
The main pitfall of substitution cipher is that it is a confusion-only cipher. The
absence of diffusion restricts the plaintext from diffusing over the ciphertext, and
plaintext properties also remained on the ciphertext. This phenomenon makes the
frequency attack and other types of attacks possible.
In this work, we introduce the perfect diffusion property to a substitution cipher
with multiple encryption rounds and see how relevant it is in today’s scenario. We use
aDeterministicRandomBit Generator (DRBG) [3] andauniformshufﬂingalgorithm
like Fisher-Yates [10] to randomly shufﬂe a look-up-table (LUT). The shared secret
symmetric key is fed to the DRBG as an entropy source. In the literature, we came
across many ciphers that use key-dependent S-boxes. Generally, in a key-dependent
S-box, it is checked whether the generated S-box satisﬁes speciﬁc cryptographic
criteria or not. However, in our work, we go for the random S-box/ LUT that is
achieved from a DRBG. After studying the cryptographic properties of such LUT’s,
we analyze how well this modiﬁed substitution cipher can resist relevant popularly
known attacks.
The rest of the paper is organized as follows. Section2 presents a brief description
of various substitution ciphers and their analysis. In Sect.3, we describe the proposed

Never Underestimate Substitution Cipher with Diffusion
667
modiﬁed substitution cipher. Sections 3.1 and 3.2 elaborate on the generation of LUT
and the shufﬂing of LUT, respectively. Section4 elaborates on the perfect diffusion
property. Section5 portrays the cryptographic properties of the randomly generated
LUT. In Sect.6, we investigate a case study. Finally, Sect.7 concludes the paper.
2
Substitution Cipher
In this section, we brieﬂy discuss the substitution ciphers. It is a classical method
of encryption in which units of plaintext are replaced with ciphertext. Based on
the length of the units, the substitution cipher is classiﬁed into two types, mono-
alphabetic and poly-alphabetic substitution ciphers.
2.1
Mono-alphabetic Substitution Cipher
If the cipher operates on a single letter, it is termed as mono-alphabetic, here the unit
length is 1. Let us assume, M be the set of all strings of length t over an alphabet A
of q symbols. Let K be the set of all permutations on the set A. Now, for each e ∈K
an encryption transformation Ee:
Ee(m) = (e(m1)e(m2) . . . e(mt)) = c1c2, . . . , ct = c,
Where the message m ∈M and m = (m1m2, . . . , mt). Each symbol in m sub-
stituted according to some ﬁxed permutation rule e. For decryption operation on
c = c1c2, . . . , ct compute the inverse permutation d = e−1:
Dd(c) = (d(c1)d(c2), . . . , d(ct)) = m1m2, . . . , mt = m.
Ee is called mono-alphabetic substitution cipher.
2.2
Poly-alphabetic Substitution Cipher
In a poly-alphabetic substitution cipher, the unit length is more than one. Let us
assume the unit length t over an alphabet A where the key space is a ordered set of t
permutations on the set A. The encryption on a message m ∈M m = (m1m2, . . . , mt)
under the key e = (p1, p2, . . . , pt) is given by,
Ee(m) = (p1(m1)p2(m2), . . . , pt(mt)) = c1c2, . . . , ct = c,
the decryption key of e = (p1, p2, . . . , pt) is d = (p−1
1 , p−1
2 , . . . , p−1
t ), and
Dd(c) = (p−1
1 (c1)(c2), . . . , p−1
t (ct)) = m1, . . . , mt = m

668
Md R. Ali and D. Roy Chowdhury
2.2.1
Analysis of the Ciphers
In the above substitution ciphers, a random alphabet e(m) or random block of alphabet
p(m) substitutes another unrelated alphabet m or block of alphabet in the plaintext.
Due to the absence of a proper diffusion mechanism, all the fundamental properties
of plaintext remain in the ciphertext, which makes frequency attack possible. With
current computation power and with sufﬁcient data, substitution cipher can be broken
instantly. Diffusion is the property that dissipates the statistical redundancy of the
plaintext in the cipher-text [29]. That is, the non-uniformity of alphabets in the
plaintext is re-distributed to the non-uniformity of a large structure of ciphertext,
which is very hard to detect. It is expected to have a strict avalanche criterion that is
if i-th bit in m ∈M is ﬂipped then j-th bit of c may ﬂipped with probability half.
3
Proposed Model
This section describes the proposed model. Both communicating parties agree with
a secret seed. Using a DRBG, the LUT and LUT −1 are generated at respective ends
as shown in Fig.1. The plaintext is taken as input, then the substitution and diffusion
operations are performed iteratively by some ﬁxed number of rounds, which ﬁnally
results in the ciphertext (Fig.2). Below are some points relevant for the proposed
model,
• In the proposed model, the key is not directly used in the encipherment process; it
is only used to generate the LUT (Sect. 3.1).
• The diffusion function that we use is a completefunction that is each output bit of
a round is dependent on every input bit.
• When a l-bit permutation is generated using a k-bit key as entropy, if the key
is selected uniformly at random, the process is analogous to choosing one of 2k
potential permutations uniformly at random out of all permutations (2l!).
Fig. 1 Sender and receiver
key agreement
DRBG
k bit shared seed
Alice
2k
⇓
LUT
⇓
E(m,lut)
D(c,LUT)
DRBG
Bob
⇓
LUT −1
⇓
D(c,LUT−1)
E(m,LUT−1)

Never Underestimate Substitution Cipher with Diffusion
669
Fig. 2 Encryption algorithm
LUT
Plaintext
Substitution
Dif fusion
Ciphertext
• An implementation of the proposed cipher must integrate some mechanism to
break each round’s self-similarity.
• Larger LUT may possess better cryptographic properties but comes with more
cost (LUT generation, storage to store LUT). While designing a cipher, the
designer needs to balance the security, cost, and performance.
• The number of encryption rounds (nround) should be chosen after studying various
attack models carefully. Which again depends on the selected LUT size.
Algorithm 1 Encryption algorithm
1: procedure EncAlgorithm(plaintext,key)
2: //state is a placeholder which gets N-bit plaintext, divided in l-bit word (N = l||l||...||l)
3: //nround is number of encryption rounds
4: //GenerateLUT return l-bit permutation with key as entropy
5: //Substitution replace each l-bit words from LUT
6: //Diffusion operation (Dc = 1) diffuses the state
7:
state ←paintext
8:
LUT ←GenerateLUT(key, l)
9:
for i ∈(0, ..., nround −1) do
10:
state = Substitution(state, LUT)
11:
state = Diffusion(state)
12:
end for
13:
return state
3.1
Generation of LUT
In the proposed cipher, the lut (substitution table) is secret and acts as a key. Initially,
take an array that contains the elements [0, 1, . . . , 2l −1], where l is the length
of each LUT element in bits. Now, perform a random permutation on the array
elements. If the LUT contains 2l elements, the number of possible rearrangements
is 2l!. In our proposed case, as we are using a DRBG with a secret k-bit key as an
entropy source, the possible number of different LUT is 2k. The LUT generation is
a one-time pre-processing task.

670
Md R. Ali and D. Roy Chowdhury
3.2
Shufﬂing of LUT
We use the well-known Fisher-Yates shufﬂing [10] algorithm to shufﬂe the LUT.
This method shufﬂes in linear time as shown in Algorithm 1 and also provides a
uniformly shufﬂed LUT that results in 2l! possible rearrangements for a l bit LUT.
Though in our proposed scenario, a maximum of 2k possible LUTs can occur.
Algorithm 2 Shufﬂing algorithm
1: procedure FisherYatesShufflingAlgorithm(LUT,l)
2: //LUT is an array, containing [0, 1, .., 2l −1]
3: //rand(p,q) returns a random number betw p to q
4:
n←2l
5:
for i ∈(0, ..., n −2) do
6:
j = rand(i, n −1)
7:
swap(LUT[i], LUT[j])
8:
end for
9:
return LUT
3.2.1
Proof of Uniform Shufﬂe
Assuming the part of the list, {a0, . . . , ai−1} is already shufﬂed. Now, randomly
select an element aj from {ai, . . . , an−1} and replace it with ai. The probability of
occurring an element at position zero is 1
n and (n−1)
n
is the probability to land at
any of the remaining 1, . . . , n −1 positions. Now, we can assume that place zero
is uniformly shufﬂed.
1
(n−1). (n−1)
n
is the probability of being one of a remaining
elements at position one. As, the probability that the element is placed at position
one is
1
(n−1) and not placed at position zero is (n−1)
n
. The probability of an element at
position i is calculated using mathematical induction,
(n −1)
(n)
· (n −2)
(n −1) · (n −3)
(n −2) · · ·
(n −i)
(n −i −1) ·
1
(n −i) = 1
n
So, we observe that the Fisher-Yates method is a uniform shufﬂing algorithm from
the algorithm and its analysis.
4
Perfect Diffusion
In his work [29], Shannon mentioned the term diffusion to indicate the quantitative
spreading of information. The inﬂuence of input bits on output bits of an (n, m)-
function is called the diffusion property. The degree of completeness (Dc) is an

Never Underestimate Substitution Cipher with Diffusion
671
instinctive way to measure the diffusion of a vectorial boolean function as mentioned
in NESSIE [20, 27] project. A boolean function with Dc = 1 is a complete function
with perfect diffusion property. Some form of cryptographic attacks is executed by
ﬁnding the effect of input bits on a particular output bit/ bits. If every output bit does
not depend on all the input bits, some potential attacks may exist (i.e., algebraic
attack). An attacker may form some polynomial equations on the output bits and
solve them to gain an advantage.
Degree of completeness [27] The degree of completeness for an (n, m)-function
F = (f1, f2, . . . , fm) is deﬁned as
Dc(F) = 1 −|{(i, j)|ai,j = 0, 1 ≤i ≤n, 1 ≤j ≤m}
mn
(1)
Here,ai,j = |{x ∈Fn
2|fj(x) ⊕fj(x ⊕ei) = 1}|, i = 1, . . . , n, j = 1, . . . , m.Foran(n,m)-
function F, it is certain that 0 ≤Dc(F) ≤1. Dc(F) is the mean value of all the D(fi)’s,
where, i = 1, 2, . . . , m. When F is a complete function and Dc(F) = 1, the following
two measures are instinctual,
Dax
c (F) = max1≤i≤m{Dc(fi)}, Dmin
c
(F) = min1≤i≤m{Dc(fi)}
(2)
It is clear that for a vectorial boolean function Dmin
c
is the strongest measure
of completeness, as, Dmin
c
(F) ≤Dc(F) ≤Dmax
c
(F), and Dmin
c
(F) = 1 if and only if
Dc(F) = 1. Two construction of (n, n) functions with perfect diffusion properties are
(1) Almost balanced (n, n) function and (2) Rotation symmetric (n, n) function; both
of them being complete function completely diffuses in every encryption round.
5
Properties of the Random LUT
Substitution boxes play an essential role in obscuring the relationship between
key and ciphertext. Today, popularly known block ciphers generally use a pub-
licly known S-box with superior cryptographic properties (high nonlinearity, high
algebraic degree, should satisfy strict avalanche criterion). A randomly generated
LUT shall be less potent than a known S-box with a high probability, though it can
resist [26] several cryptographic attacks. This section studies the expected values of
several cryptographic properties of a randomly generated LUT.
5.1
Expected Differential Characteristics
Differential cryptanalysis is a chosen plaintext attack based on following the differ-
ence propagation known as characteristics. A given characteristic is obtained from
a table known as Difference Distribution Table (DDT), which is enriched analyzing

672
Md R. Ali and D. Roy Chowdhury
the substitution box. A randomly shufﬂed substitution box (LUT) is used in the pro-
posed model, which is generated using the random seed as an entropy source. The
complexity of differential cryptanalysis depends on the larger value of the DDT. In
his theoretical study, O’connor [24] shows that the highest probability of differential
characteristics in a non-trivial case is expected to be at most 2m
2m for a uniformly
random m-bit bijective mapping.
5.2
Expected Linear Characteristics
Linear cryptanalysis is one of the most signiﬁcant known plaintext attacks on a block
cipher. This attack is checked whether there is any probabilistic linear relationship
after substitutions are performed in the last round between a portion of plaintext bits
and a subset of bits. After certain rounds, the number of active bundles is combined
to the largest value of the Linear Approximation Table (LAT) to determine the com-
plexity of a cipher’s linear cryptanalysis. We use the results from [23] to calculate
the expected maximum value of LAT. Let us assume π : Zl
2 →Zl
2 is a random per-
mutation and λ(π) is the linearity of π. E(λ(π, 2k)) denote the expected number of
entries in LAT of size 2k. E(λ(π, 2k)) in Eq.3 tends to zero as a function of k we
are likely to obtain an upper bound on λ(π).
E(λ(π, 2k)) = 2 × (2l −1)2 × (2l−1!)2
2l!
×

2l−1
2l−2 + k
2
(3)
6
Case Study
This section assumes an imaginary block cipher with block length 128 bits divided
into 8-bit words (16 words in total), the key length 128 bits, and the LUT is of length
l=8 (l-bit permutation). After providing the 128 bit key as entropy to a DRBG,
the LUT is generated. The incorporated diffusion mechanism in the cipher is opti-
mal (Dc = 1) one. Each of the 16 words of the block is substituted using the values
from random LUT.
Using the results from [24], we can conclude that in a non-trivial case, the highest
probability of differential characteristics for a uniform random 8-bit bijective map-
ping is 2−4. As our test block cipher has Dc = 1, each output bit of a round depends
on every input bit. Likewise, each of the 16 words is expected to be active. So, using
the results from [9] the expected number of active words/ bundles after the ﬁrst round
is 17. Again, using the Four-Round Propagation Theorem from [9], we can say the
expected bundle weight is 289. Due to the high number of active bundle weights, one
has an upper bound of the probability for any 4-round differential characteristic of
2−1156. It is evident that randomly generated LUT may have weaker cryptographic

Never Underestimate Substitution Cipher with Diffusion
673
properties with high probability. However, if we exclude the cost of construction of
a function with perfect diffusion property, a cipher can have sufﬁcient potentiality
against differential cryptanalysis despite using a random LUT. The resistance of the
cipher against differential cryptanalysis makes it potential against boomerang types
of attacks.
Similarly, from Eq.3, it is clear that if E[A(λ, 2k)] is tending rapidly to zero as
a function of k, then, we are likely to obtain a useful bound on π(λ). Using Eq.3,
the value of k is obtained as 19 for an 8-bit random permutation. This expected
value is not marvelous, but it is possible to show adequate security against linear
cryptanalysis; again, this is due to the use of complete function for diffusion.
The ciphers that use identical substitution-diffusion operations in every round are
generally vulnerable to attacks like slide and invariant subspace. Section3 describes
that the proposed model’s actual implementation must blend some mechanism to
break the round similarity. Breaking the self-similarity of rounds ensures that the
cipher is resistant against slide/ invariant subspace types of attacks.
7
Conclusions
In this paper, we perform an analytical study of the substitution cipher to miti-
gate its deﬁciencies. We propose a block cipher model modifying the substitution
cipher by introducing a diffusion mechanism and several iterative rounds. In every
round, substitution and diffusion operations are performed. The random substitution
table (LUT) is a permutation generated using a DRBG and a uniform shufﬂing algo-
rithm feeding the symmetric key as an entropy source to the DRBG. We perform a
case study by assuming an imaginary block cipher, performing rudimentary analy-
sis, and ﬁnding that the cipher is immune to several statistical attacks. To the best of
our knowledge, this is the only of its kind where a classical cipher’s weaknesses are
mitigated by introducing several modiﬁcations. We strongly encourage the rigorous
analysis of the proposed model.
References
1. Aoki, K., Ichikawa, T., Kanda, M. , Matsui, M., Moriai, S., Nakajima, J., & Tokita, T. (2000).
Camellia: A 128-bit block cipher suitable for multiple platforms–design and analysis. In Inter-
national Workshop on Selected Areas in Cryptography (pp. 39–56). Springer.
2. Banik, S., Bogdanov, Isobe, T., Shibutani, K., Hiwatari, H., Akishita, T., & Regazzoni, F.
(2015). Midori: A block cipher for low energy. In International Conference on the Theory and
Application of Cryptology and Information Security (pp. 411–436). Springer.
3. Barker, E., Feldman, L., & Witte, G. (2015). Recommendation for random number genera-
tion using deterministic random bit generators, tech. rep., National Institute of Standards and
Technology.
4. Barreto, P., Rijmen, V., et al. (2000). The whirlpool hashing function. In First open NESSIE
Workshop (Vol. 12, p. 14). Leuven, Belgium.

674
Md R. Ali and D. Roy Chowdhury
5. Barreto, P. S. (2000). The anubis block cipher. NESSIE.
6. Biham, E., Anderson, R., & Knudsen, L. (1998). Serpent: A new block cipher proposal. In
International Workshop on Fast Software Encryption (pp. 222–238). Springer.
7. Bogdanov,A.,Knudsen,L.R.,Leander,G.,Paar,C.,Poschmann,A.,Robshaw,M.J.,Seurin,Y.,
& Vikkelsoe, C. (2007). Present: An ultra-lightweight block cipher. In International Workshop
on Cryptographic Hardware and Embedded Systems (pp. 450–466). Springer.
8. Cusick, T. W., & Wood, M. C. (1990). The redoc ii cryptosystem. In Conference on the Theory
and Application of Cryptography (pp. 546–563). Springer.
9. Daemen, J., & Rijmen, V. (2001). The wide trail design strategy. In IMA International Confer-
ence on Cryptography and Coding (pp. 222–238). Springer.
10. Fisher, R. A., & Yates, F. (1953). Statistical tables for biological, agricultural and medical
research. Hafner Publishing Company.
11. GOST, G. S. (1989). 28147–89. Government Committee of the USSR for Standards: Crypto-
graphic protection for data processing systems.
12. Guo, J., Peyrin, T., Poschmann, A., & Robshaw, M. (2011). The led block cipher. In Interna-
tional Workshop on Cryptographic Hardware and Embedded Systems (pp. 326–341). Springer.
13. Izadi, M., Sadeghiyan, B., Sadeghian, S. S., & Khanooki, H. A. (2009). Mibs: A new lightweight
block cipher. In International Conference on Cryptology and Network Security (pp. 334–348).
Springer.
14. Joan, D., & Vincent, R. (2002). The design of rijndael: Aes-the advanced encryption standard.
In Information Security and Cryptography: Springer.
15. Karakoç, F., Demirci, H., & Harmancı, A. E. (2013). Itubee: A software oriented lightweight
block cipher. In International Workshop on Lightweight Cryptography for Security and Privacy
(pp. 16–27). Springer.
16. Knudsen, L., Leander, G., Poschmann, A., Robshaw, M. J. (2010). Printcipher: a block cipher
for ic-printing. In International Workshop on Cryptographic Hardware and Embedded Systems
(pp. 16–32). Springer.
17. Kwon, D., Kim, J., Park, S., Sung, S. H., Sohn, Y., Song, J. H., Yeom, Y., Yoon, E.-J., Lee,
S., Lee, J., et al. (2003). New block cipher: Aria. In International Conference on Information
Security and Cryptology (pp. 432–445). Springer.
18. Lim, C. H. (1998). Crypton: A new 128-bit block cipher. NIsT AEs Proposal.
19. Lim, C. H., & Korkishko, T. (2005). mcrypton–a lightweight block cipher for security of low-
cost rﬁd tags and sensors. In International Workshop on Information Security Applications
(pp. 243–258). Springer.
20. Liu, J., Mesnager, S., & Chen, L. (2015). On the diffusion property of iterated functions. In
IMA International Conference on Cryptography and Coding (pp. 239–253). Springer.
21. Nakahara, J. (2008). 3d: A three-dimensional block cipher. In International Conference on
Cryptology and Network Security (pp. 252–267). Springer.
22. Nyberg, K. (1993). Differentially uniform mappings for cryptography. In Workshop on the
Theory and Application of of Cryptographic Techniques (pp. 55–64). Springer.
23. O’Connor, L. (1994). Properties of linear approximation tables. In International Workshop on
Fast Software Encryption (pp. 131–136). Springer.
24. O’connor, L. (1995). On the distribution of characteristics in bijective mappings. Journal of
Cryptology, 8, 67–86.
25. Ojha, S. K., Kumar, N., Jain, K., et al. (2009). Twis–a lightweight block cipher. In International
Conference on Information Systems Security (pp. 280–291). Springer.
26. Pradeep, L., & Bhattacharjya, A. (2013). Random key and key dependent s-box generation for
aes cipher to overcome known attacks. In International Symposium on Security in Computing
and Communication (pp. 63–69). Springer.
27. Preneel, B., Bosselaers, A., Preneel, B., Bosselaers, A., Rijmen, V., Stern, J., Murphy, S.,
Van Rompay, B., Granboulan, L., Biham, E., et al. (2000) Comments by the nessie project on
the aes ﬁnalists.
28. Schneier, B., Kelsey, J., Whiting, D., Wagner, D., Hall, C., & Ferguson, N. (1998). Two sh: A
128-bit block cipher. AES submission.

Never Underestimate Substitution Cipher with Diffusion
675
29. Shannon, C. E. (1949). Communication theory of secrecy systems. The Bell system technical
journal, 28, 656–715.
30. Shibutani, K., Isobe, T., Hiwatari, H., Mitsuda, A., Akishita, T., & Shirai, T. (2011). Piccolo:
an ultra-lightweight blockcipher. In International Workshop on Cryptographic Hardware and
Embedded Systems (pp. 342–357). Springer.
31. Shirai, T., Shibutani, K., Akishita, T., Moriai, S., & Iwata, T. (2007). The 128-bit blockcipher
cleﬁa. In International Workshop on Fast Software Encryption (pp. 181–195). Springer.
32. Suzaki,T.,Minematsu,K.,Morioka,S.,&Kobayashi,E.(2011).Twine:Alightweight,versatile
block cipher. In ECRYPT Workshop on Lightweight Cryptography (Vol. 2011).
33. Wu, W., & Zhang, L. (2011). Lblock: A lightweight block cipher. In International Conference
on Applied Cryptography and Network Security (pp. 327–344). Springer.
34. Zhang, W., Bao, Z., Lin, D., Rijmen, V., Yang, B., & Verbauwhede, I. (2015). Rectangle: A
bit-slice lightweight block cipher suitable for multiple platforms. Science China Information
Sciences, 58, 1–15.

Kannada Sentiment Analysis Using
Vectorization and Machine Learning
M. E. Sunil and S. Vinay
Abstract The sentiment analysis (SA) also known as opinion mining (OM) is a
new arena in text mining and NLP ﬁeld. We are presenting a method to analyze the
IMDB movie reviews translated to Kannada using Google translator along with other
reviews collected from various creditable sites like Vijayakarnataka, Gadgetloka,
and ﬁlmibeats. In sentiment analysis, many research has been carried out on English
text. Methods and resources of English may not produce good results for other
languages. In this paper, we are analyzing around 50,034 of reviews with positive and
negativelabels.Ourensembleclassiﬁcationtechniqueusingvariousvectorizationhas
achieved the accuracy of 89%.
Keywords Sentiment analysis · Stop words elimination · Word vector · Kannada
sentiments · Tokenization · Term frequency
1
Introduction
Opinion mining (sentimental analysis) is the new way of knowing the people’s feel-
ings from texts written by the users. There is much valuable information available
online in the form of textual reviews, which plays a predominant role in decision
process. For example, he/she will decide which movie he/she wants to watch based
on valuable reviews posted by others. Hence, how to mine reviews which are posted
by local language has become an important issue in NLP, machine learning and
web mining. Natural language processing (NLP) is multidisciplinary ﬁeld. It draws
on results from artiﬁcial intelligence, linguistics, and computer science. These days
computer acts very smart, useful manner, and they can understand, analyze, and
derive the meaning of the human language using natural language processing [1].
Sentimental analysis, speech recognition, named entity recognition; translation,
relationship extraction, automatic summarization, and topic segmentation tasks can
M. E. Sunil (B)
Computer Science and Engineering, PESITM, Shivamogga, India
S. Vinay
Information Science and Engineering, PESCE, Mandya, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_53
677

678
M. E. Sunil and S. Vinay
be performed by the developers in an organized and structure knowledge by utilizing
the natural language processing [2]. NLP also helps us to analyze the textual state-
ments and enables the interaction of human and computer in real-world applications
like relationship extraction, stemming, topic extraction, named entity recognition,
and more. It allows the computer to understand how human beings speak.
Sentiment analysis is the computerized process that allows machines to iden-
tify and extract sentiments associated within the text, such as tweets, emails, movie
reviews, reviews on products, responses from various surveys, etc. We can differ-
entiate poor- and high-quality content using available technologies with sentimental
analysis. We may ﬁnd the reason why a movie has more positive feedback than
negative feedback.
Research in sentimental analysis now pay attention to social media data such as
Facebook, IMBD, Twitter, Amazon, Flipkart, Goibio, Quiker, etc., along with senti-
ments generated from local or regional variations of a language (Linguistic geog-
raphy) such as Chinese, Arabic, Spanish, and Indian languages like Hindi, Kannada,
Tamil, Telugu, Marti, Bengali, etc. The textual sentiments generated from regional
languages require the different methods be tailored to serve the rising demand.
Furthermore, performing analysis of sentiments or reviews written in a local language
is a challenging task.
Inthispaper,wehaveappliedvariousvectorizationmethodstoanalyzethereviews
written in Kannada language. This method comprises of machine learning and deep
learningapproaches.Theproposedmethodconsistsoffollowingﬁvemaincategories.
(1)
Data crawling (Data collection)
(2)
Pre-processing technique
(3)
Feature extraction technique
(4)
Vectorization
(5)
Evaluation.
Also, we have analyzed accuracy of the approach used and evaluated the
performance of the various deep learning and machine learning techniques.
2
Background
In this section, related to the proposed system, we have reviewed the existing work.
The goal of sentiment analysis is to know the feelings of a reviewer with respect to
some topic or subject. The attitude may be naïve evaluation or judgment, experience
or emotional state expressed in the form of speech or text.

Kannada Sentiment Analysis Using Vectorization and Machine …
679
2.1
Sentiment Analysis in Different Languages
F. Sa˘glam, H. Sever, and B. Genç have developed the sentiment lexicon for online
news media written in Turkish Language [3]. In this work, large database consists of
Turkish news pages that were extracted from GDELT database and obtained roots
of the words present in these texts using Zemberek framework. They obtained the
new lexicon as SWNetTR-PLUS by enhancing the existing 10,000 unique words
SWNetTR lexicon. Finally performed the Chi-Squared statistical test to evaluate the
performance of the model. As a result, SWNetTR-PLUS polarity lexicon gives the
better accuracy compared to SWNetTR.
S. Smetanin and M. Komarov used the convolutional neural networks to analyze
the product reviews written in Russian language [4]. In this work, inputs for the model
were pre-trained vectors of Word2Vec model, and the training dataset was collected
from e-commerce sites in Russia. They have used 90 k reviews during the training
stage along with two separate CNN models. Emoticons pre-processing techniques of
Ekphasis toolkit and emoticons without any pattern extraction characters of regular
sequence and, ﬁnally, evaluated the effectiveness of FastText, Word2Vec, and glove
techniques.
K. S. Sabra, R. N. Zantout, and et. al have developed the model to generate
sentiment lexicons using semi-supervised learning for the Arabic language [5]. Using
English WordNet, they have assigned the sentiment scores to words, and evaluation
of the lexicon classiﬁcation was carried out on the opinion corpus for Arabic (OCA).
Finally, evaluated the lexicon with multiple classiﬁers was produced the average
F-measure of 65% with improvement.
2.2
Indian Language Sentiment Analysis
We can observe that researchers are contributing to Indian languages continually,
and Bandopadhya and Amitava Das have done a great work in Hindi and Bengali.
They developed the SentiwordNet for Bengali language [6]. In this process, they
used the English-Bengali Dictionary and lexical transfer technique to each word in
English SentiWordNet and which resulted the 35,805 Bengali entries. The task of
emotion tagging for Bengali words has carried out by Das and Bandopadhya [7]. In
this work, they classiﬁed the high, low, and general types of intensities for sentence
and emotion classes like anger, fear disgust, sad, happy, and surprise level annotation
in Ekmans.

680
M. E. Sunil and S. Vinay
2.3
Kannada Language Sentiment Analysis
Yashawini Hegde and S. K Padma analyzed sentiments of mobile product reviews
written in Kannada using random forest ensemble. In this work, they determined
the polarity of sentiment as positive and negative and also achieved the performance
accuracy about 72% in multi-class Kannada sentiment classiﬁcation [8].
K. M. Anil Kumar, N. Rajasimha, and et al. analyzed user sentiments from
Kannada web documents [9]. Some methods under semantic and ML approaches
are used to identify the users’ sentiments. In this experiment, they have used the text
corpus of Kannada consists of 182 positive and 105 negative reviews as a dataset
for algorithms. In semantic methods, sentence based, Neagtor-Window, and Baseline
were performed well, and under machine learning approaches, Na¨ıve Bayes method
performs the best.
Rohini et al. [10] carried out work on domain-based sentiment analysis in
Kannada. They used the reviews of speciﬁc movies in regional language for domain-
based sentiment analysis and also drawn the comparison study between machine
translation in English and direct Kannada dataset.
Reddy and Sharoff [11] developed a Kannada cross-language POS tagger by
exploiting the resources of Telugu. They also developed the morphological analyzer
(including lemmatization) and large corpora for Kannada. Results from the exper-
iment conducted are highly encouraging toward building cross-language tools for
Kannada using Telugu.
Prathibha and Padma [12] developed morphological analyzer. Structure of given
word is identiﬁed and analyzed with the help of this tool, and also, we can obtain
the grammatical and morphological information of the given word. The model
for morphological analyzer has consisted of two modules, namely morphological
stemmer and morphological analyzer. In their work, they have used three databases
like verb-sufﬁx table, category-code table, and verb-root monolingual dictionary.
3
Methodology
In India, we can see large number of people who communicate in their local
languages. But some of these languages have non-efﬁcient or minimal linguistic
resources. For example, if we consider south Indian languages, Kannada is rela-
tively resource poor compared to Tamil, Malayalam, and Telugu which is also
poor compared to Hindi. In Indian languages, high similarities in morphology
and syntactic behavior exists. Kannada and Telugu exhibit some similarities in
morphology. But during the machine translation, certain words in Kannada can
produce ambiguous text, which can produce the unacceptable results. We may get
better results by performing the sentimental analysis in regional language compared
to Machine Translated English Language.

Kannada Sentiment Analysis Using Vectorization and Machine …
681
The proposed system is included ﬁve steps which are data collection, pre-
processing, pre-processing technique, feature-extraction, hybrid-classiﬁcation algo-
rithm, and evaluation.
3.1
Data Collection
The dataset was created by translating IMDB movie reviews to Kannada language
using Google translator, and we have also included other movie reviews from various
creditable sites like Vijaya Karnataka, Gadgetloka, Filmibeats, and from survey form.
Around 50,034 reviews with positive and negative labels used as the input for the
model. Example of positive and negative dataset is shown below.
Kannada Positive Review
English Positive Review
This is the best movie I have seen in the last 5 years. Of course, this is in line with masterpieces
such as The Platoon, Apocalypse Now, The Doors, The Dog’s Heart (Russian movie). It’s a
good movie, there are a lot of things I want to say about this ﬁlm, but I’m not very good in
English. But I’m sure, those of you who have seen the movie understand me
Machine Transilaration Positive Review
Kal.eda 5 vars.agal.alli n¯anu n¯od.ida atyuttama citra idu. Khan.d.itav¯agi, idu di plat.¯un,
ap¯oky¯alips nau, di d. ¯ors, di d. ¯ags h¯art. (ras.yan calanacitra) nantaha m¯erukr.tigal.ondige
ond¯e s¯alinalliruttade., Idu ol.l.eya citra, ¯ı citrada bagge n¯anu h¯el.alu bayasuva
bahal.as.t.u vis.ayagal.ive, ¯adare n¯anu Englishnalli as.t.ondu uttamav¯agilla. ¯Adare
nanage khacitav¯agide, nim’malliruvavaru, calanacitravannu n¯od.idavaru nannannu
artham¯ad.ikol.l.utt¯are. Ol.l.eyad¯agali.

682
M. E. Sunil and S. Vinay
Kannada Negative Review
English Negative Review
The ﬁrst question that popped into my mind after watching the movie was whether
it was a cartoon. After reading a few comments about the Doc Savage character and
the comic series, I know this movie is not a cartoon. Seems like a typical story. But
it comes across as unrealistic and is ridiculous. The end-ﬁght shows that the worst
presentation of Sahasa art I has ever seen. This ﬁlm could be a bad example for low
budget ﬁlmmakers.
Machine Transilaration Negative Review
Calanacitravannu n¯od.ida nantara nanna manas’sinalli udbhavisida modala pra´sne
idu vya˙ngya citrave embudu. D. ¯ak s¯av¯ej p¯atra mattu k¯amik saran.iya bagge
kelavu k¯amen.t.gal.annu ¯odida nantara, ¯ı citravu vya˙ngyada citravalla endu nanage
til.idide. Vi´sis.t.a katheyante t¯oruttade. ¯Adare idu av¯astavika r¯ıtiyalli baruttade mattu
adu h¯asy¯aspadav¯agide. Antima-h¯or¯at.avu n¯anu n¯od.ida sah¯asa kalegal.a ket.t.a pras-
tutiyannu t¯orisuttade. Kad.ime bajet. calanacitra vin’y¯asakarige ¯ı citravu ket.t.a
ud¯aharan.ey¯agirabahudu.
3.2
Pre-processing Technique
Pre-processing involves various data cleaning and correction process. In which the
set of words that do not give any meaning (stop words) for the text are eliminated
and cleaning the data may reduce the noise of dataset. Pre-processing may help the
classiﬁer to improve the performance and speed of classiﬁcation process.
• Standardization: Data collected from various source is not in the required form.
Standardization is a process of converting the raw data into standard data. Here
we have stored the data in excel from with headers
Kn_review, Label, non_stop_review, processed_review
• Stop Words Elimination: Stop words are the partition of natural language. These
words are not being the part of sentimental process and less important to analysts
and which make the text heavier. So, we have to remove stop words from a text

Kannada Sentiment Analysis Using Vectorization and Machine …
683
Fig. 1 Dataset
and dimensionality of term space may reduce. The most common words in text
documents are articles, prepositions, and pro-nouns, etc. Around 374 stop words
are identiﬁed in Kannada and were removed from the data and stored under the
header non_stop_review.
• Removal-of-Punctuation: All the punctuation marks are removed from all the
text-snippets (instances or documents) from the dataset (corpus)
• Tokenization: It is the process of splitting the ﬁle content into smaller parts is
also called as tokens. In this study, we have applied NLTK word_tokenize method
and will be added to ﬁle under the header processed_review. The sample dataset
is shown in Fig. 1.
3.3
Feature Extraction Technique
Vectorization is the process of representing the words in numerical form. In natural
language processing, corresponding vector of real numbers for the words or phrases
from vocabulary is represented as word vectorization or word embeddings. Vectoriza-
tion helps in word predictions, compute similar words, word similarities/semantics.
Different types of vectorization methods are.
• Binary term frequency (BTF)
• Count vectorizer
• Normalized term frequency
• Tf-idf vectorizer
• Hashing vectorizer
• Word2Vec.

684
M. E. Sunil and S. Vinay
Fig. 2 Binary term frequency
From the literature, we have observed that most of the techniques were used
in various publications, but majority of them used Tf-idf with machine learning
algorithms. As a result, we used the same for carrying out feature extraction for the
data.
Binary Term Frequency (BTF): If term does not exist in the document, it uses 0
to represent and 1 in other case. If the term presented more than one time, then also
the value will be 1. The results of BTF are shown in Fig. 2.
English Translated
This is the best movie I have seen in the last 5 years. But I am sure, those of you who have
seen the movie understand me. Be good, those who have seen the movie understand me
Tf-idf: Tf-idf stands for term frequency and inverse document frequency of statis-
tical methods. Both the methods can use various ways for determining the exact
values.Theseareusedasweightingfactorintextmining,incaseofthetermfrequency
tf (t, d) we will count the number of times each word appeared in the document.
The inverse document frequency is a measure of how much information the word
provides, i.e., prepositions are commonly appeared in the document compared to
rarely appeared sentimental word. Hence, idf diminishes the words that occur very

Kannada Sentiment Analysis Using Vectorization and Machine …
685
Fig. 3 Tf-idf
frequently and rise the weight of words that occur rarely across all documents. The
results of Tf-idf have been shown in Fig. 3.
Term Frequency
• Bag of words term frequency
• The more frequent a term is, the higher the TF.
Inverse Document Frequency
• Number of documents in the corpus represented by N
• Number of documents in corpus with term t represented by Nt
idf (t) = log([1 + N])
(1 + Nt)
Tf-idf is the product of term frequency and inverse document frequency
TfIdf = tf ∗idf (t, d)
Another technique we are using here for the deep learning method is fast text
which is a derivative of Word2Vec. Word2vec is pre-trained Google dataset consist
of group of models used to produce word embeddings.
FastText is a library for efﬁcient learning of word representation and text classiﬁ-
cation open-source library released by Facebook research group- FAIR [13]. FasText
has ability to recognize more than 170 languages, and it can also produce bag of
words in words representation. Indeed, vectors of substrings of characters contained
in text are used to generate the fast text word vectors even for misspelled words or
concatenation of words.

686
M. E. Sunil and S. Vinay
3.4
Hybrid-Classiﬁcation Algorithm
The classiﬁcation algorithm we used is an ensemble technique of combing two
machine learning algorithms and two CNN-LSTM models. The machine learning
algorithm we are using here are Naïve-Bayes and logistic regression [14].
Deep learning is the sub-branch of machine learning that uses multiple layers
instead of single layer to progressively extract higher level features from the raw
input. The deep learning model used here is a combination of LSTM and CNN
models.
3.5
Evaluation
Experiments are carried out to evaluate the working performance of the proposed
method. Initially, dataset is divided into two sets: training data and testing data.
Classiﬁer is trained using almost ¾ of the data, and rest is used for testing, and we
have built the classiﬁcation model using a certain classiﬁcation algorithm and the
same for the deep learning model. After that, the testing data was used to test the
model, and the predicted instances are compared with the original ones, and the
accuracy is calculated based on the number of correctly classiﬁed samples; with this,
we also calculated the precision, recall and other parameters.
4
Experimental Results
We have read the dataset which is of csv format and listing the stop words list which
is stored as a text ﬁle. Then the stop words are removed from the dataset, and then,
the data is split into training and test data. Then, the y attribute is label encoded, and
the data (articles) is converted into vectors using the Tf-idf and word vectors. The
vector data is fed to classiﬁcation algorithm where the data is ﬁtted, and then the test
data will be predicted using the same classiﬁcation algorithm. We have used the two
methods for analysis; Later, the accuracy is calculated using the prediction of the
data. The detailed process has shown below.
Step 1: Read the Stop words list.
Step 2: Remove the Stop words from the dataset.
Step 3: Find the non-converted eng-kan words in the corpus. Remove the
duplicates in it and store it in a list.
Step 4: Split the data into Train and Test set.
Step 5: Create Tf-idf transformer for the dataset and ﬁt it to produce the vectors.
Step 6: Fit the Tf-idf vectors to naïve-Bayes and logistic regression algorithms.
Step 7: Create word vectors from fast text pre-trained word net for Kannada.

Kannada Sentiment Analysis Using Vectorization and Machine …
687
Table 1 Dataset
Label
Count
Positive
25,270
Negative
24,764
Table 2 Result of different
algorithms
Algorithm
Accuracy
Precision
Recall
2 CNN-LSTM (with GRU)
88.72
88
89
Naïve bayes
88.6
85
88
Logistic regression
88.3
89
88
Combined model
89.1
89
89
Step 8: Fit the word vectors to 2 CNN-LSTM deep learning models for different
layer layout.
Step 9: Create a list of average prediction values between the 2 CNN-LSTM
models.
Step 10: Create a list of major prediction values between the 2-machine learning.
Models and the combined CNN-LSTM Model.
Step 11: Create a Classiﬁcation Matrix Containing all the Results.
4.1
Result Analysis
A total 50,034 rows reviews shown in Table 1 consisting of labels positive and
negative were fed to the model consisting of a hybrid combination of 4 models
where 2 are LSTM and 2 are machine learning-based models as discussed. The deep
learning models on average give 88.72% accuracy, and the combined model gives
89.1% accuracy as shown in the Table 2; Figs. 4 and 5.
5
Conclusion
Sentiment analysis for Kannada reviews involves the identiﬁcation of the label either
positive or negative in the document. This involves the process of collection of the
data,pre-processingtheobtaineddata,and,ﬁnally,trainingthehybridmodelbasedon
the processed data, and once the model is trained, it is ready to predict the sentiment
of the review. The whole of the available data is split into test and training data.
Training data comprises of about 3/4th of the overall data, and the remaining is split
into test data. The hybrid model used here gives the best accuracy for our selected
data. This experiment can be extended to various other classiﬁers. Furthermore, the
accuracy of the model can be further enhanced with the addition of even more data.

688
M. E. Sunil and S. Vinay
Fig. 4 Accuracy of algorithms
Fig. 5 Precision of algorithms
References
1. Wang,D.,Su,J.,&Yu,H.(2020).Featureextractionandanalysisofnaturallanguageprocessing
for deep learning english language. IEEE Access, 8, 46335–46345. https://doi.org/10.1109/
ACCESS.2020.2974101
2. Ghani, N. A., Hamid, S., Hashem, I. A. T., & Ahmed, E. (2019) Social media big data analytics:
A survey. Computers in Human Behavior, 101, 417–428. ISSN 0747–5632.

Kannada Sentiment Analysis Using Vectorization and Machine …
689
3. Sa˘glam, F., Sever, H., & Genç, B. (2016). Developing Turkish sentiment lexicon for senti-
ment analysis using online news media. In 2016 IEEE/ACS 13th international conference
of computer systems and applications (AICCSA) (pp. 1–5). https://doi.org/10.1109/AICCSA.
2016.7945670.
4. Smetanin, S., & Komarov, M. (2019). Sentiment analysis of product reviews in Russian using
convolutional neural networks. In 2019 IEEE 21st conference on business informatics (CBI)
(pp 482–486). https://doi.org/10.1109/CBI.2019.00062.
5. Sabra, K. S., Zantout, R. N., Abed, M. A. E., & Hamandi, L. (2017). Sentiment analysis:
Arabic sentiment lexicons. Sensors Networks Smart and Emerging Technologies (SENSET),
2017, 1–4. https://doi.org/10.1109/SENSET.2017.8125054
6. Das, A., & Bandyopadhyay, S. (2010). SentiWordNet for Bangla.
7. Das, D., & Bandyopadhyay, S. (2010) Labeling emotion in bengali blog corpus a ﬁne grained
tagging at sentence level. In Proceedings of the eighth workshop on Asian language resouces
(pp. 47–55). Coling 2010 Organizing Committee, August 2010.
8. Hegde, Y., & Padma, S. K. (2017). Sentiment analysis using random forest ensemble for mobile
product reviews in Kannada. In 2017 IEEE 7th international advance computing conference
(IACC) (pp. 777–782).
9. Anil Kumar, K. M., Rajasimha, N., Reddy, M., Rajanarayana, A., & Nadgir, K. (2015). Analysis
of users’ sentiments from Kannada web documents. Procedia Computer Science, 54, 247–256.
10. Rohini, V., Thomas, M., & Latha, C. (2016). Domain based sentiment analysis in Regional
Language- Kannada. International Journal of Engineering Research & Technology (IJERT),
4(22).
11. Reddy, S., & Sharoff, S. (2011). Cross language POS taggers (and other Tools) for Indian
languages: An experiment with Kannada using Telugu resources. In Proceedings of the 5th
international joint conference on natural language processing (pp. 11–19), November 8–12,
2011.
12. Padma, M. C., & Prathibha, R. J. (2014). Development of morphological stemmer, analyzer
and generator for Kannada nouns. In Emerging research in electronics, computer science and
technology (pp. 713–723).
13. Xu, J., & Du, Q. (2019). A deep Investigation into fastText. In 2019 IEEE 21st interna-
tional conference on high performance computing and communications; IEEE 17th inter-
national conference on smart city; IEEE 5th International conference on data science and
systems (HPCC/SmartCity/DSS) (pp. 1714–1719). https://doi.org/10.1109/HPCC/SmartCity/
DSS.2019.00234.
14. Han, J., Pei, J. & Kamber, M. (2011). Data mining: concepts and techniques. Elsevier.

Human Activity Recognition Using 1D
Convolutional Neural Network
Khushboo Banjarey, Satya Prakash Sahu, and Deepak Kumar Dewangan
Abstract Humans are more oriented toward innovative research objectives to recog-
nize objects and understand the environment, evaluating time series and forecasting
outcomes patterns due to rapid artiﬁcial intelligence (AI) advances. Human activity
recognition (HAR) is a domain that targets on recognizing, interpreting, and eval-
uating human movement behavior. HAR has signiﬁcantly beneﬁtted from deep
learning. Despite its immense potential, deep learning models face signiﬁcant chal-
lenges, such as the need for a large dataset for training in the real world. On
the other hand, the current study needs to be improved to distinguish static and
dynamic behavior with more remarkable achievements. Our main goal is to use one-
dimensional convolutional neural network (1D CNN) to create a system that can
identify movements such as sitting, standing, walking, sleeping, reading, and tilting,
and also we are trying to reduce the time optimization for training the neural network.
Human–computer interaction (HCI) mechanization is becoming more in demand for
recording behaviors using sensors like gyroscope and accelerometer, and HAR can
be done with sensors, images, smartphones, or clips. This paper introduces a tech-
nique that employs a 1D CNN to expecting human behavior that is based totally on
the dataset given, and we have got ﬁnished 90.73% accuracy.
Keywords Artiﬁcial intelligence · Human activity recognition · Deep learning ·
Computer vision · 1D CNN · Human–computer interaction
K. Banjarey (B) · S. P. Sahu · D. K. Dewangan
Department of Information Technology, National Institute of Technology, Raipur, India
S. P. Sahu
e-mail: spsahu.it@nitrr.ac.in
D. K. Dewangan
e-mail: dkdewangan.phd2018.it@nitrr.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_54
691

692
K. Banjarey et al.
1
Introduction
Human activity recognition has become a not unusual area of study in recent years.
The essential types of HAR research are motion identiﬁcation based totally on
virtual video pictures and sensor facts. The computer imaginative and prescient-
based system is regularly utilized in captured video records—primarily based HAR
for detection and popularity, and it in particular uses exterior cameras to screen
customers, lowering its outreach approach. Sensor—primarily based HAR, but on
the other aspect, is generally worn and might song customers in a whole lot more
open environments.
In medical diagnosis, HAR will be extremely helpful. HAR may also be used
to keep track of the everyday activities of senior citizens. HAR can be used to
keep track of crime statistics. The smart home can be created by recognizing daily
activities. One may identify dangerous driving behaviors and help to make travel
safer. Military behavior can be detected using HAR. By analyzing motion data that
is captured by multiple sensors, HAR hopes to navigate patterns of human physical
activity. HAR has a extensive range of possible applications, ranging from human
activity monitoring (e.g., fall identiﬁcation and health protection) to human activity
awareness (Fig. 1).
A plunging-based model is presented in this paper. 1D CNN is proposed, in which
human behaviors are recognized using input data generated during model training.
In general, the HAR model starts with gathering data and ends with identifying the
current operation. HAR principles are used in various applications or ﬁelds, including
health care, child care, and other ﬁelds where tracking human behavior is necessary.
Its primary goal is to observe and analyze human behavior in order to understand
current affairs successfully. In the process of tracking a patient’s health status, child
care, protection, home care, and surveillance procedures, it was historically done
Fig. 1 Human activity recognition [1]

Human Activity Recognition Using 1D Convolutional Neural Network
693
by human operators. When it comes to tracking human behavioral patterns with the
aid of human operators, there may be issues such as preconceived notions, biased
approaches, implicit bias, or bad judgment, all of which can affect the efﬁciency of
behavioral pattern recognition. A primary challenge is to achieve high activity recog-
nition accuracy while minimizing computational costs. To address this problem,
the HAR community is starting to use deep learning to replace well-established
identiﬁcation methodologies that rely on manual feature extraction. However, func-
tion extraction is being used in a variety of image processing [2–9] areas, and
in recent years, computer vision and prescience-based image processing [10, 11]
as well as supervised learning with convolutional neural networks (CNNs) have
seen widespread use in intelligent applications [12–14]. Picture processing [15–17],
physician-diagnosing, speech recognition, and natural language processing are only
a few areas where deep learning has recently been used. It has been utilized to solve
a variety of actual problems since then. For the human activity recognition mission,
we employ a one-dimensional convolutional neural network (1D-CNN). Convolu-
tional neural network models [9, 18] are created to classify the images, and the
system gains an understanding of an internal impression of a two-dimensional input
through feature learning. This same method can recognize human behavior from one-
dimensional data sequences, such as acceleration and gyroscopic data. The system
gains a knowledge how to extract attributes from observation sequences and how to
plot internal features to variant types of activity.
1D CNN will recognize whether a person is standing, walking, jumping, and so
on, based on the input data [19]. Two dimensions are present in this data. Time
steps are the ﬁrst component, followed by acceleration values in three axes. CNN
beneﬁts from learning features from the raw time series analysis, eliminating a need
for the experience and expertise to develop activation functions. In principle, the
system should acquire an underlying structure of the time series analysis and produce
comparable results to machines conﬁgured on a variant of the datasets with based
features.
2
Related Works
HAR applications have been the subject of much research in recent years, with
many suggested methods. Early studies primarily used decision trees, SVMs, Naive
Bayes classiﬁers, and shallow traditional models to classify data collected by sensors,
especially after developing the HAR [20–22] public-domain benchmark and several
recognition methods. The K-nearest neighbors algorithm had found to be better than
other previous algorithms in various recognition tasks, but there was need of many
features in order to construct the classiﬁer [23]. To resolve the complications of prior
KNN algorithm related to the computation, the cluster-based KNN algorithm [24]
was introduced. Support vector machine (SVM) [25], which handles outliers better
than KNN, mainly when there are prominent features and limited training data, is
another excellent algorithm that has produced excellent results.

694
K. Banjarey et al.
Deep neural networks (DNNs) are better than other methods for measuring
complex input transformations [26, 27]. DNNs such as convolutional and recur-
rent layers are used in the wearable HAR domain. Signals from wearable sensor
were observed to extract features using convolution layers, then dense layers are
used to unify the features in order to provide a probabilistic distribution for different
human activities. A “deep residual-bidirectional LSTM network” [28] was created
to enhance learning ability of the model. However, the time needed to achieve the
best precision makes it unsuitable for real-time applications, even though it has good
accuracy early in training, making it convenient for HAR tasks. Hybrid networks
were introduced to extract features automatically by combining convolutional layers
with LSTM and classifying them with only a few parameters [29]. A model which
can combine both attribute extraction and categorization in one time learning entity
employing CNN has been suggested, in contrast to previous research that used
manual ﬁltering features. It has been claimed that hybrid machine learning systems,
which merge the strengths of two non-identical model forms, produce better results
than a single system. Using F1-score and accuracy, the author proposed a deep
“Conv-LSTM” network [30] that performed better than previous methods. Unlike
LSTM approaches, one-dimensional CNN (1D CNN) for this task was implemented
with two-stage learning models and used divided and conquer-based classiﬁcation
learning merged with test data-sharpening [21, 31]. Since pace is vital in these
kinds of packages, the writer proposed a “fast and strong deep convolutional neural
community structure (FR-DCNN)” [31] for this task the usage of a cellphone, which
progressed overall execution and multiplied sensor unprocessed records details by
using combining a group of sign processing algorithms and a signal selection module.
A time series is described through Ismail et al. [32] as an ordered set of real values
with a length identical to the variety of actual values T. He goes on to explain a
dataset as a list of pairs (xi, yi), in which xi is a time series and yi is the mark or
magniﬁcence that corresponds to it. The dataset has then categorized the use of a
version that maps the distance of possible inputs xi to a possibility distribution over
the elegance variable values yi, which is the cornerstone of any TSC device learning
model. Since HAR is a TSC challenge, a selection of deep and non-deep studying
tactics was proposed. To call some, there is the multiclass SVM proposed by Anguita
et al. [33], LSTM [34], and CNN [32, 35].
3
Proposed Methodology
We have applied 1D CNN for HAR. The advantage of using CNNs for sequence
classiﬁcation is how they can understand directly from the raw time series analysis,
requiring no subject matter expertise to develop feature vectors manually. HAR has
been carried out in following steps:

Human Activity Recognition Using 1D Convolutional Neural Network
695
3.1
Dataset Collection
We have used the HAR dataset from UCI HAR, which includes 30 subjects having
a waist-mounted smartphone with embedded inertial sensors when conducting
everyday activities. It was conducted with a group of 30 volunteers aged 19 to 48.
Walking, going-upstairs, going-downstairs, sitting, standing, and laying were the six
activities performed by each person while wearing a smartphone around their waist.
We have used this dataset because the triaxial acceleration from the accelerometer
and the approximated body acceleration are given for each record in this dataset—
the gyroscope’s three-dimensional angular velocity. Time and frequency domain
variables are included in this 561-feature vector. Its classiﬁcation is a recreational
activity—a unique identiﬁer for the experimenter.
3.2
Data Preprocessing
The facts are ﬁrst normalized to ﬁt the proposed model’s facts layout. After that, the
mark is encoded once more to convert the word labels to the numeric type.
3.3
Data Training
We divided the dataset into instructions: education statistics and trying out records.
In our dataset, the training to investigate records ratio is 7:3.
3.4
Applied Model
CNN makes use of a convolution operation to combine several processing layers, uses
many components in parallel, and makes use of the shape of the organic frightened
system. 1D CNN is used due to the fact the dataset incorporates time series records
from an accelerometer sensor. With the input layer holding the x-axis, y-axis, and
z-axis time intervals, the data is reshaped. The input layer is preceded through the
convolution layer and the max pooling layer for attribute extraction, after which the
dense layer for categorization (Fig. 2).
We have modiﬁed the 1D CNN model [36] architecture in order to reduce the
training time. In the structure of our 1D CNN model, we have included three convo-
lutional layers, one dropout layer, max pooling layer; one ﬂattens layer, two dense
layers, and one output layer. As the method maintains, the output on the input layer
is implemented because they enter at the very ﬁrst convolution layer until the ﬁnal
convolution layer. The employed activation feature in all convolution layers makes

696
K. Banjarey et al.
Fig. 2 Architecture of our 1D CNN model
use of the rectiﬁcation linear unit (ReLU). The dropout layer is used to avoid overﬁt-
ting and to speed up the learning process by deleting nodes that are no longer useful.
The utilized dropout value is 0.5. The pooling layer used on the CNN version is max
pooling to reduce the feature map dimensions and the whole wide variety of nodes
thereby speeding up the computing process.
The next step is to ﬂatten the pooled featured map that has been obtained. The
entire pooling feature map matrix is transformed into a single column, which is then
supplied to the neural network for processing. To put it another way, we combine all
of the pixel data into a single line and connect it to the ﬁnal layer. The dense layer is
a neural network layer that is connected deeply, because of this every neuron inside
the dense layer gets enter from all neurons of its previous layer. The dense layer
is determined to be the maximum commonly used layer within the fashions. Dense
layers also apply operations like rotation, scaling, and translation on the vector. Dense
layer does the operation at the input and return the output. The function of dense is
to add connected layers. The applied activation is softmax, with classiﬁcation results
as the output.

Human Activity Recognition Using 1D Convolutional Neural Network
697
3.5
Fit and Evaluate Model
Now that the statistics has been loaded into memory and is prepared to be modeled,
we are able to outline, in shape, and compare a 1D CNN model. We must ﬁrst provide
an explanation for the CNN version with the Keras deep learning library. A three-
dimensional input is crucial for the version. There are 128-fold steps in whenever
series window, and nine variables or functions are included in each step, precisely
how the statistics was loaded. The model’s performance can be a vector with six
factors containing the probability in a given window of each of the six-behavior
paperwork. We can extract those measurements’ input and output from the given
schooling information set while becoming the model.
As visible, the version will encompass 1D CNN layers, a regularization dropout
layer, and a pooling layer. CNN layers are commonly divided into lessons to provide
the version a truthful threat of mastering capabilities from the enter facts. The dropout
layer is intended to slow down the mastering system, resulting in a higher ﬁnal
version. CNNs are clean to apprehend. The pooling layer reduces the discovered
features to 1/4 in their unique length, maintaining most effective the maximum vital
aspects. Post-CNN and pooling, the discovered functions are ﬂattened right into a
lengthy vector and surpassed via a wholly connected layer before being anticipated
by the output layer. The fully linked layer is supposed to buffer between the found-out
capabilities and the output, permitting the discovered capabilities to be interpreted
before making a prediction. For this model, we are able to use a regular sixty-four
parallel feature map conﬁguration and a kernel size of 3. The kernel size is the wide
variety of enter time steps taken into consideration when they enter collection is
studied or processed into the characteristic maps. The characteristic maps represent
the quantity of instances the input is processed or interpreted.
We are exploring a multimagniﬁcence-type hassle, we will optimize the network
with the speciﬁc move-entropy loss function, the use of the Adam version of
stochastic gradient descent. The version can be appropriate for a predetermined
variety of epochs. In this situation, ten samples are used with a batch size of 32 and
32 windows of statistics exposed to the model before the weights are modiﬁed. After
becoming the model, it is checked on the take a look at dataset, and the accuracy of
the ﬁt model is again.
4
Result
We have applied 1D CNN on processed data taken from UCI HAR dataset in order
to predict human activity and achieved 90.73% accuracy.

698
K. Banjarey et al.
Table 1. Performance
comparison
S. no.
Method
Accuracy
1
Deep CNN + statistical feature [37]
95.13%
2
CNN [38]
94.66%
3
Rps with CNN [39]
90.1%
4
CNN [40]
92.22%
5
CNN + stat.features [41]
90.42%
6
LSTM + CNN [42]
95.75%
7
1D CNN (our model)
90.73%
4.1
Performance Comparison with Previous Research Work
Many researches have been worked on HAR and achieved remarkable result with
their proposed models. Table 1 shows the comparison of our achieved accuracy with
previous works.
4.2
Discussion and Future Scope
Both smartphone and wearable sensor technologies are widespread in HAR research,
according to our ﬁndings. The pose-based technique, on the other hand, was not as
popular in the beginning, presumably due to the limitations of scenery and human
movements in 3D space. Another restriction that necessitates advanced machining
is recognizing and removing humans from picture sequences. As a result, real-
time HAR systems can obtain superior outcomes when massive amounts of data
are analyzed at once. There is no precise sign or statistic that suggests wearable
sensors that are superior than smartphone sensors or vice versa in a universal setting.
Depending on the subject and the intended usage, both sensors are predicted to
have beneﬁts and disadvantages. As a result, before deploying any HAR technology,
researchers and developers must ﬁrst choose the subjects and how they will be used.
We observed that, despite having better results, vision-based approach has not been
very popular among the three in the last two centuries due to its limitations. However,
in the years ahead, as technology advances, machines with high computing capabili-
ties will become more readily available, capable of processing large amounts of data
in less time, vision-based solution will become a great choice for HAR [43].
4.3
Challenges in HAR
Data collection: If data is to be obtained via sensors, the user must wear many
sensors, and sensor placement is a concern because it impacts the results.

Human Activity Recognition Using 1D Convolutional Neural Network
699
Severalpersons:Whensensorsareimplantedinthehomeenvironment,numerous
individuals may be present, making it challenging to map the actions of numerous
occupants.
Time complexity and accuracy: Various classiﬁcation algorithms result in
varying levels of temporal complexity and precision. It is widely noticed that when a
classiﬁcation system’s computational complexity is low, it has lower accuracy than
system with high accuracy but low computational complexity.
Real-time data: Many of the results were estimated using conventional datasets,
which may differ when using a real-time dataset.
Various action: If the people perform various activities at the same time,
recognition for the action will be tough.
5
Conclusion
In this paper, we advise a 1D CNN approach to human hobby recognition that reasons
to decorate interest popularity efﬁciency by leveraging a CNN network’s robustness
in feature extraction. This look centered on the guidance, trying out, and assessment
of a selection of physical games. This CNN version will robotically research the crit-
ical features from input (raw) information to make correct predictions. New datasets
or ﬁlms can be used, and the identical version can be used to adopt them easily and
affordably. For a UCI HAR dataset, the accuracy became 90.73%. We will retain to
reﬁne this device for future work and punctiliously testing it with various hyperpa-
rameter, which includes gaining knowledge of rate, batch size, and regularization,
and others in future paintings. We want to test this system on numerous datasets to
apply too many more challenging functions to clear up other deep-getting-to-know
and HAR problems. For the UCI dataset and different open-supply datasets, we will
evaluate the effects of this method on the modern.
References
1. Concone, F., Gaglio, S., Lo Re, G., & Morana, M. (2017). Smartphone data analysis for human
activity recognition. In Lecture Notes in Computer Science (including subseries Lecture Notes
in Artiﬁcial Intelligence and Lecture Notes in Bioinformatics (Vol. 10640, pp. 58–71). LNAI.
https://doi.org/10.1007/978-3-319-70169-1_5.
2. Dewangan, D. K., & Rathore, Y. (2011). Image quality costing of compressed image using full
reference method. International Journal of Technology, 1(2), 68–71.
3. Pandey, P., Dewangan, K. K., & Dewangan, D. K. (2017). Enhancing the quality of satel-
lite images by preprocessing and contrast enhancement. In: 2017 international conference on
communication and signal processing (ICCSP) (pp. 0056–0060). IEEE.
4. Ali, U., Dewangan, K. K., & Dewangan, D. K. (2018). Distributed denial of service attack
detection using ant bee colony and artiﬁcial neural network in cloud computing. In Nature
inspired computing (pp. 165–175). Springer.

700
K. Banjarey et al.
5. Bhattacharya, N., Dewangan, D. K., & Dewangan, K. K. (2018). An efﬁcacious matching
of ﬁnger knuckle print ımages using gabor feature. In ICT based ınnovations (pp. 153–162).
Springer.
6. Pandey, P., Dewangan, K. K., & Dewangan, D. K. (2017). Enhancing the quality of satel-
lite images using fuzzy inference system. In 2017 ınternational conference on energy,
communication, data analytics and soft computing (ICECDS) (pp. 3087–3092). IEEE.
7. Pandey, P., Dewangan, K. K., & Dewangan, D. K. (2017). Satellite image enhancement tech-
niques—a comparative study. In 2017 ınternational conference on energy, communication,
data analytics and soft computing (ICECDS) (pp. 597–602). IEEE.
8. Dewangan, D. K., & Rathore, Y. (2011). Image quality estimation of ımages using full reference
and no reference method. International Journal of Advanced Research in Computer Science,
2(5).
9. Sahu, S. P., Dewangan, D. K., Agrawal, A., & Priyanka, T. S. (2021). Trafﬁc light cycle control
using deep reinforcement technique. In 2021 ınternational conference on artiﬁcial ıntelligence
and smart systems (ICAIS) (pp. 697–702). IEEE.
10. Dewangan, D. K., & Sahu, S. P. (2021). Driving behavior analysis of ıntelligent vehicle system
for lane detection using vision-sensor. ˙In IEEE sensors journal (vol. 21, no. 5, pp. 6367–6375),
March 1, 2021. https://doi.org/10.1109/JSEN.2020.3037340.
11. Dewangan, D. K., & Sahu, S. P. (2020). Real-time object tracking for ıntelligent vehicle. In
2020 ﬁrst ınternational conference on power, control and computing technologies (ICPC2T)
(pp. 134–138). IEEE.
12. Dewangan, D. K., & Sahu, S. P. (2021). Deep learning-based speed bump detection model
for ıntelligent vehicle system using raspberry Pi. ˙In IEEE sensors journal (Vol. 21, no. 3,
pp. 3570–3578). February 1, 2021. https://doi.org/10.1109/JSEN.2020.3027097.
13. Dewangan, D. K., & Sahu, S. P. (2021). RCNet: Road classiﬁcation convolutional neural
networks for intelligent vehicle system. Intelligent Service Robotics, 14, 199–214. https://doi.
org/10.1007/s11370-020-00343-6
14. Dewangan, D. K., & Sahu, S. P. (2021). PotNet: Pothole detection for autonomous vehicle
system using convolutional neural network. Electronics Letters, 57, 53–56. https://doi.org/10.
1049/ell2.12062
15. Dewangan, D. K., & Sahu, S. P. (2021). Predictive control strategy for driving of ıntelligent
vehicle system against the parking slots. In 2021 5th ınternational conference on ıntelligent
computing and control systems (ICICCS) (pp. 10–13). IEEE.
16. Banjarey, K., Sahu, S. P., & Dewangan, D. K. (2021). A survey on human activity recognition
using sensors and deep learning methods. In 2021 5th ınternational conference on computing
methodologies and communication (ICCMC) (pp. 1610–1617). IEEE.
17. Dewangan, D. K., & Sahu, S. P. (2021). Road detection using semantic segmentation-
based convolutional neural network for ıntelligent vehicle system. In Data engineering and
communication technology (pp. 629–637). Springer.
18. Pardhi, P., Yadav, K., Shrivastav, S., Sahu, S. P., & Dewangan, D. K. (2021). Vehicle
motion prediction for autonomous navigation system using 3 dimensional convolutional neural
network.In20215thınternationalconferenceoncomputingmethodologiesandcommunication
(ICCMC) (pp. 1322–1329). IEEE.
19. Ragab, M. G., Abdulkadir, S. J., & Aziz, N. (2020). Random search one dimensional CNN for
human activity recognition. International Conference on Computational Intelligence (ICCI),
2020, 86–91. https://doi.org/10.1109/ICCI51257.2020.9247810
20. Jalloul, N., Poree, F., Viardot, G., L’Hostis, P., & Car-rault, G. (2017). Activity recognition
using complex network analysis. IEEE Journal of Biomedical and Health ˙Informatics, 22(4),
989–1000.
21. Gupta, P., & Dallas, T. (2014). Feature selection and activity recognition system using a single
triaxial accelerometer. IEEE Transactions on Biomedical Engineering, 61(6), 1780–1786.
22. Fullerton, E., Heller, B., & Munoz-Organero, M. (2017). Recognizing human activity in free-
living using multiple body-worn accelerometers. IEEE Sensors Journal, 17(16), 5290–5297.

Human Activity Recognition Using 1D Convolutional Neural Network
701
23. Hu, Y., Li, Z., Li, G., Yuan, P., Yang, C., & Song, R. (2016). Development of sensory-
motor fusion-based manipulation and grasping control for a robotic hand-eye system. IEEE
Transactions on Systems, Man, and Cybernetics: Systems, 47(7), 1169–1180.
24. Jobanputra, C., Bavishi, J., & Doshi, N. (2019). Human activity recognition: A survey. Procedia
Computer Science, 155, 698–703.
25. Sunkad, Z. A. et al. (2016). Feature selection and hyperparameter optimization of svm for
human activity recognition. ˙In 2016 3rd ınternational conference on soft computing and
machine ıntelligence (ISCMI) (pp. 104–109). IEEE.
26. LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436–444.
27. Abdulkadir, S. J., Yong, S.-P., & Zakaria, N. (2016). Hybrid neural network model for metocean
data analysis. Journal of Informatics and Mathematical Sciences, 8(4), 245–251.
28. Zhao, Y., Yang, R., Chevalier, G., Xu, X., & Zhang, Z. (2018). Deep residual bidir-lstm for
human activity recognition using wearable sensors. Mathematical Problems in Engineering,
2018.
29. Xia, K., Huang, J., & Wang, H. (2020). Lstm-cnn architecture for human activity recognition.
IEEE Access, 8, 56855–56866.
30. Ord´o˜nez, F. J., & Roggen, D. (2016). Deep convolutional and lstm recurrent neural networks
for multimodal wearable activity recognition. Sensors, 16(1), 115
31. Qi, W., Su, H., Yang, C., Ferrigno, G., De Momi, E., & Aliverti, A. (2019). A fast and robust
deep convolutional neural networks for complex human activity recognition using smartphone.
Sensors, 19(17), 3731.
32. Ismail Fawaz, H., Forestier, G., Weber, J., Idoumghar, L., & Muller, P. -A. (2018). Transfer
learning for time series classiﬁcation. In: IEEE ınternational conference on big data (pp. 1367–
1376).
33. Anguita, D., Ghio, A., Oneto, L., Parra, X., & Reyes-Ortiz, J. L. (2013). A public domain dataset
for human activity recognition using smartphones. In Proceding of the European symposium
on artiﬁcial neural networks, computational ıntelligence and machine learning (pp. 24–26).
Bruges. April, 2013.
34. Eyobu, S. O., & Han, D. S. (2018). Feature representation and data augmentation for human
activity classiﬁcation based on wearable IMU sensor data using a deep LSTM neural network.
Sensors, 18, 2892.
35. Rueda, F. M., Grzeszick, R., Fink, G. A., Feldhorst, S., & Hompel, M. (2018). Convolutional
neural networks for human activity recognition using body-worn sensors. Informatics, 5(2),
26.
36. Kusuma, W. A., Minarno, A. E., & Wibowo, M. S. (2020). Triaxial accelerometer-based human
activity recognition using 1D convolution neural network. International Workshop on Big Data
and Information Security (IWBIS), 2020, 53–58. https://doi.org/10.1109/IWBIS50925.2020.
9255581
37. Almaslukh, B., Al Muhtadi, J., & Artoli, A. M. (2018). A robust convolutional neural network
for online smartphone-based human activity recognition. Journal of Intelligent & Fuzzy
Systems, 35(2), 1609–1620.
38. Jeong, C. Y., & Kim, M. (2019). An energy-efﬁcient method for human activity recognition
with segment-level change detection and deep learning. Sensors (Switzerland), 19(17), 4–11.
39. Garcia-Ceja, E., Uddin, M. Z., & Torresen, J. (2018). Classiﬁcation of recurrence plots’ distance
matrices with a convolutional neural network for activity recognition. Procedia Computer
Science, 130, 157–163.
40. Avilés-Cruz,C.,Ferreyra-Ramírez,A.,Zúñiga-López,A.,&Villegas-Cortéz,J.(2019).Coarse-
ﬁneconvolutionaldeep-learningstrategyforhumanactivityrecognition.Sensors(Switzerland),
19(7).
41. Shakya, S. R., Zhang, C., & Zhou, Z. (2018). Comparative study of machine learning and deep
learning architecture for human activity recognition using accelerometer data. International
Journal of Machine Learning and Computing, 8(6), 577–582.
42. Ignatov, A. (2018). Real-time human activity recognition from accelerometer data using
Convolutional Neural Networks. Applied Soft Computing Journal, 62, 915–922.

702
K. Banjarey et al.
43. Gupta, A., Gupta, K., Gupta, K., & Gupta, K. (2020). A survey on human activity recogni-
tion and classiﬁcation. International Conference on Communication and Signal Processing
(ICCSP), 2020, 0915–0919. https://doi.org/10.1109/ICCSP48568.2020.9182416
44. Cho, H., & Yoon, S. M. (2018). Divide and conquer-based 1d cnn human activity recognition
using test data sharpening. Sensors, 18(4), 1055.

Language and Era Prediction
of Digitized Indian Manuscripts Using
Convolutional Neural Networks
Anukriti Garg, Laghima Tiwari, Tejsvi Juj, S. Indu, and N. Jayanthi
Abstract With an increasing number of Indian manuscripts being digitized, the
subject of their era prediction is readdressed to interpret the socio-economic fabric
of different periods. This paper describes a novel approach to estimate the era of
Indian manuscripts from their scanned images using convolutional neural networks
(CNN). The method primarily uses image processing to harness visual features from
small image patches and classiﬁes them based on the difference in writing styles in
terms of strokes and letter formation. We follow a two-step approach of language
prediction followed by a separate era prediction model for each language to achieve
optimal results. For this paper, we restrict consideration to six Indian language
manuscripts written between the sixteenth and twentieth centuries. Conclusively,
our model outperforms other well-known architectures and gave over 90% and 80%
accuracy on the training and validation data, respectively.
Keywords Convolutional neural network · Era prediction · Indian manuscripts ·
Language prediction
1
Introduction
Historical ﬁndings trace their way to various sources such as archeological sites,
manuscripts, artifacts, and oral transmission. In this paper, we narrow down our
focus area to handwritten manuscripts. An abundance of historical material is avail-
able for studying the rich culture and heritage of India [1]. These documents were
created as a necessary part of some activity—administrative, social, religious, or
commercial. This increases the importance of accurate determination of the era they
A. Garg (B) · L. Tiwari · T. Juj · S. Indu · N. Jayanthi
Department of Electronics and Communication Engineering, Delhi Technological University,
Delhi, New Delhi 110042, India
S. Indu
e-mail: s.indu@dce.ac.in
N. Jayanthi
e-mail: njayanthi@dce.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_55
703

704
A. Garg et al.
Fig. 1 Red boxes show change in writing style of Devanagari diacritic from 16th to nineteenth
century
belong to Numerous techniques have been employed for dating including chemical
and physical methods [2]. All these methods, however, pose a major challenge to
the preservation of manuscripts, especially during handling and storage due to their
fragile nature. This has been overcome by their digital preservation, thus generating
a prospect of using image processing and deep learning for dating purposes.
In this paper, we employ a novel approach to estimate the era of Indian manuscripts
from their scanned images using convolutional neural network (CNN). We restrict
our consideration to six Indian language manuscripts, namely Bengali, Hindi, Prakrit,
Punjabi, Sanskrit, and Tamil written between the sixteenth and twentieth centuries.
Note that our proposed model is not conﬁned to the particular dataset we have used
in this paper and should be suitable to other datasets as well.
We adopt a novel two-step approach based on deep learning, a language predic-
tion model followed by a separate era prediction model for each language. Such a
grouping provides a coherent basis of distinction by focusing on character sets of a
particular language. Additionally, it provides a holistic view of the input manuscript
and enables its extension to other languages. Our model accurately predicts the era
based on the visual differences in writing style [1, 3–6] without knowing its textual
content. We assume that the writing style in a particular language will change over a
century as shown in Fig. 1 [4]. While this has been previously modeled as a basis of
classiﬁcation, we consider the rich diversity of Indian manuscripts by taking multiple
languages into account. To increase the validation, we compare our method against
other well-known architectures [4, 6].
The remainder of the paper is organized as follows. Section 2 comprises of liter-
ature review. Sect. 3 consists of the problem statement. In Section 4, we describe
our proposed methodology. Sections 5 and 6 showcases analyses of the result and
comparison with existing architectures. Lastly, Sect. 7 concludes the paper.
2
Literature Review
The importance of manuscripts in understanding the past is immense. Although
ample work has been done to predict either language or era, negligible work has
been carried out to simultaneously predict both. Here, we provide a brief review of
the previous studies in the ﬁeld of language and era prediction of manuscripts.

Language and Era Prediction of Digitized Indian Manuscripts …
705
2.1
Language Prediction
Deep learning methods using CNN were used to recognize hand-written Tamil char-
acters in [7] and Hindi and Telugu language in [8]. Kesiman et al. [9] focused
on decoding palm-leaf manuscripts from Southeast Asia through word detection
and translation. CNN was used to extract visual features whereas recurrent neural
network-long short-term memory (RNN-LSTM) was used for word recognition and
translation. In [2], a patch-based system was used for language identiﬁcation. We
also train CNN for language identiﬁcation, however, the focus is on visual features
like strokes and edges instead of actual characters written.
2.2
Era Prediction
We have come across three major approaches for era dating: (1) Chemical dating
methods [10] (2) Feature vector-based methods [3, 11–13], and (3) Convolutional
neural network methods [1, 4–6, 14]. In [10], chemical dating methods were studied
to determine the elemental composition of historical paper samples. In our model, we
focus on digitized versions of manuscripts to safeguard the fragile ancient documents.
References [3, 11–13] used feature vector-based methods for era prediction.
Most of these proposed models were curated for European and Middle East Asian
[11] languages. Sparse feature-based and handwriting feature-based methods were
adopted for dating Arabic manuscripts in [11]. Herein, the size of the image was
increased to improve accuracy that led to a surge in computational cost. Grapheme-
based features, K contour, and K stroke fragments were used for dating in [3, 12].
Bannigidad and Gudada [13] proposed a system to benchmark Kannada manuscripts
through image enhancement, Histogram of Oriented Gradient (HOG) descriptors, K
nearest neighbors (KNN), and support vector machine (SVM) classiﬁers. The feature
vector-based methods described above were unable to harness global features rather
focused only on local features. To resolve this, we have trained a state-of-the-art
CNN model which can identify the differences in writing style.
References [1, 4–6, 14] used CNN to estimate the time-period of manuscripts.
In [1], a CNN model was used to index digitized manuscripts. While this is one of
the few works addressing Indian manuscripts, it does not take into account the input
features rather merely clusters images with similar appearances together. Text model,
image model, and a combined model based on CNN and optical character recognition
(OCR) were designed to estimate the publication date of printed documents in [14].
Herein, OCR integration increased the complexity of the model, moreover, hand-
written documents may not give good results with OCR. [4, 5] propose several pre
trained architectures based on ImageNet dataset, like GoogletNet, AlexNet, ResNet,
and Inception networks for historical document analysis. Wilkinson [6] used a modi-
ﬁed GoogleNet that replaced the ﬁnal classiﬁcation by a single neuron layer for

706
A. Garg et al.
Table 1 Analysis of previous works on era prediction of historical manuscripts
Contribution
Proposed method
Language(s) considered
Accuracy (%)
Feature-extraction
methods for historical
manuscript dating based
on writing style
development [12]
Grapheme based
feature extraction
Aramaic script
60.6
Age-type identiﬁcation
and recognition of
historical Kannada
handwritten document
images using HOG
feature descriptors [13]
HOG feature
descriptors with K-NN
and SVM classiﬁers
Kannada
96.70
Publication date
estimation for printed
historical documents
using CNN’s [14]
Image model and text
model using CNN
combined with OCR
English
86.7
Deep learning based
approach for historical
manuscript dating [4]
Pre-trained Alex net,
google net, etc. using
image net
Medieval Dutch
71.6
A comprehensive study
of image net pre-training
for historical document
image analysis [5]
Pre-trained google net
using image net
Japanese, Latin
37.9
regression. The accuracy of these methods is questionable due to fundamentally
different natures of the datasets. Table 1 shows an analysis of some of the techniques
described above.
3
Problem Statement
The past decade has seen substantial growth in the dating of manuscripts. Despite
that, there are still certain untouched areas and challenges that need to be addressed:
(1) Although a considerable amount of work has been carried out for dating of
European and Middle East Asian [11] language manuscripts, not so much for Indian
languages. (2) Dating algorithms have been proposed for manuscripts belonging to
only one or two languages till now [2, 4–8]. We focus on the prediction of the era of six
Indian language manuscripts. (3) Most of the work has been done to predict only one
of the two characteristics of manuscripts, either language or era. (4) The majority of
previous studies utilize feature vector-based methods for dating which focus only on
local features [3, 11–13]. (5) Even when CNN-based methods are adopted, they face
problems such as increased computational cost [11], unconcentrated text patches,
and higher accuracy only when tested on the training dataset taken into account [1].
(6) Limited availability of data for training purposes is another major concern. (7)

Language and Era Prediction of Digitized Indian Manuscripts …
707
Poor quality images with unreadable text pose a major challenge. (8) Validation of
the proposed model to increase its reliability is an important aspect while dating.
We have acknowledged all the above-stated problems by providing a state-of-the-
art method using CNN to predict the era of Indian manuscripts.
4
Methodology
The proposed methodology consists of two parts: language prediction model and
era prediction model. As a ﬁrst step, we pass the input image through a language
prediction model. For each of the available languages within our dataset, a separate
era prediction model has been trained to extract the difference in writing styles.
This enables us to classify digitized manuscripts into different eras. In this section,
we provide a detailed account of the dataset used, image preprocessing steps, data
augmentation, language prediction model, and era prediction model.
4.1
Dataset
Dataset forms the backbone of our proposed model. We have collected an authentic
set of scanned images of Indian manuscripts from various sources: (1) Central
Library—Delhi Technological University (2) Collection of Indic Manuscripts, Penn
Libraries—University of Pennsylvania [15] (3) websites providing an open and
usable database of Indian manuscripts as part of the initiative by the Government of
India.
The dataset is divided based on languages and eras. In this paper, we have conﬁned
our research to six Indian language manuscripts, namely Bengali, Hindi, Prakrit,
Punjabi, Sanskrit, and Tamil. These manuscripts were written between the sixteenth
and twentieth centuries. We have uniformly chosen a total of 2223 images from each
of the classes to form the training set. The rest of the 456 images are used as the test
set. Table 2 shows the numbers of scanned images over the key eras and languages.
4.2
Image Pre-processing
The poor image quality of manuscripts poses a major challenge. To resolve this,
we follow certain image preprocessing steps as showcased in Fig. 2: (1) Conver-
sion to grayscale (2) Image binarization, and (3) Image de-noising. In contrast to
other models where image pre-processing is hand-engineered and has higher compu-
tational cost [11], we follow an approach that is less time-consuming and more
accurate.

708
A. Garg et al.
Table 2 Number of images in each era over six languages in the dataset
Languages
Sixteenth
century
Seventeenth
century
Eighteenth
century
Nineteenth
century
Twentieth
century
Total
Bengali
–
–
133
133
–
266
Hindi
–
–
95
102
–
197
Prakrit
140
100
100
100
–
440
Punjabi
–
264
250
–
–
514
Sanskrit
101
100
100
100
102
503
Tamil
249
260
250
–
–
759
Total
490
724
928
435
102
2679
Fig. 2 The three steps of image pre-processing
1.
Conversion to grayscale: An RGB image is ﬁrst converted into a grayscale
image. We use the average method for conversion. For each pixel, we take the
average of the red, green, and blue pixel values to get the desired grayscale
value: (R + G + B)/3.
2.
Image binarization: We use Otsu’s thresholding algorithm [16], to determine
the global threshold for the input image. It is calculated using the following
equation:
σ 2
w(t) = w1(t)σ 2
1 (t) + w2(t)σ 2
2 (t)
(1)
Here,w1(t)andw2(t)aretheprobabilitiesofthetwoclassesdividedbythreshold,
t whose value lies between 0 and 255. We obtain the auto threshold value as
127.
3.
Image de-noising: We use the median ﬁltering algorithm to get rid of the noise.
It scans the entire image using a 10 * 10 matrix. The value of the pixel causing
deviation is replaced by the median of the pixel values inside the same matrix.
4.3
Data Augmentation
We use a novel data augmentation approach and solve the problem of limited data.
We divide the input image into 9 parts each of size 256 * 256 * 1 px before passing
it to the network for training. This resolves many issues. (1) It divides the image

Language and Era Prediction of Digitized Indian Manuscripts …
709
Fig. 3 Final processed and
augmented image from a
sample manuscript
in such a manner that the small text patches are clearly visible. This brings out the
individual letters into focus. (2) It allows the generation of abundant data for training.
(3) It decreases the computational cost, since we do not have to increase the size of
images to increase accuracy [11]. Figure 3 shows the division of an input image into
9 equal parts.
4.4
Convolution Neural Network Models
CNN has gathered immense popularity in image processing applications due to its
ability to learn complex relations. In this paper, we propose two architectures, a
language prediction model followed by an individual era prediction model for each
language. Figure 4 shows the pipeline of the proposed system. The two step approach
introduces novelty into our proposed method while benchmarking historical docu-
ments. Such division based on language helps the network to concentrate on certain
widely used patterns. To facilitate the working of our model, we also make use of
concentrated text patches from the manuscript using image enhancement followed
Fig. 4 Pipeline architecture of the proposed algorithm

710
A. Garg et al.
by a novel data augmentation approach. This also helps to resolve the issue of
degraded or torn corners, commonly observed in certain manuscripts and attain a
useful segregation between the white background and the black handwritten text
pixels.
The architecture consists of convolutional layers, Maxpool layers, fully connected
layers, and a Softmax layer. We choose gradually decreasing ﬁlter sizes moving
deeper into the network to focus on the intricate elements of the input. We use Adam
Optimizer[17]tocalculateindividuallearningratesforeachparameterinthenetwork
using bias correction estimators. The ﬁrst and second moments of the loss g for the
network are used to calculate the bias correction estimators mi and vi, initialized to
0. β1 and β2 are the hyper parameters with values 0.9 and 0.999, respectively.
mi = (β1mi−1 + (1 −β1)g)/

1 −βi
1

(2)
vi =

β2vi−1 + (1 −β2)g2
/

1 −βi
2

(3)
wi = wi−1 −ηmi/
√vi + ε

, η : stepsize
(4)
The last convolutional layer transforms into a one-dimensional feature vector.
The vectors go through a series of fully connected layers with the Relu activation
function. The output from the last fully connected layer goes to a Softmax layer.
The Softmax layer has units equal to the number of output classes n. The predicted
class probabilities from the Softmax function si are compared with the actual class
label ti to calculate the cross-entropy loss L [18]. Cross entropy uses the logarithmic
function to yield a small loss for close predictions but a high loss for deviations.
L(Cross entropy) = −ti log(si), i = 1 −n
for n
classes
(5)
Starting with 25 epochs and a batch size of 10, three hyperparameter callbacks
are applied to prevent overﬁtting during. (1) Save the best weights and biases based
on testing accuracy. (2) Reduce the learning rate when no signiﬁcant improvement
occurs over successive iterations. (3) Stop the training once the model begins to
overﬁt.
Language Prediction Model. While other works focus on identifying the char-
acters from the image available, we focus on the stroke formation of the characters
written on the image to classify its language. The visual features of commonly used
characters across a language can be used to make distinctions instead of actually
identifying them. The model consists of three convolutional layers with kernel sizes
5 * 5, 3 * 3, and 1 * 1. A max pooling layer of 3 * 3 or 2 * 2 kernel follows each convo-
lutional layer. A dropout layer of probability 0.5 is present after the last pooling layer.
The convolutional layer decomposes into two fully connected layers with 128 and
64 nodes each. The Softmax layer uses six neurons, one for each language. Figure 5
shows the detailed architecture. The weight gradient computations indicate that char-
acter pixels are the features which contribute most while predicting the output class.

Language and Era Prediction of Digitized Indian Manuscripts …
711
252*252*32                 124*124*64                62*62*64                           128     64 nodes                     
256*256*1                         126*126*32 
62*62*64                  31*31*64
Convolution     (3*3)      Convolution   (2*2)    Convolution   (2*2)                       
                           (5*5)     Maxpool        (3*3)       Maxpool       (1*1)     Maxpool         Fully Connected 
Segregation of background and identifying 
handwritten text 
Identifying characters from the manuscript to 
make predictions about the language 
Fig. 5 Architecture of language prediction model
The initial three layers are responsible for segregation of background and identifying
handwritten text. The computations become increasing complex as we go deeper into
the network. The later layers identify the common strokes and patterns of characters
in a particular language to make the ﬁnal prediction.
Era Prediction Model. Once the language is successfully identiﬁed, manuscripts
of aparticular languagearegroupedtogether. Amongthis grouping, theeraprediction
model harnesses the differences in stroke formation of diacritics belonging to a
similar language. We propose a language-based grouping to extend our model to
include different languages with respect to the availability of a suitable dataset. If
such a distinction is not made, the model does not learn anything fruitful, instead it
only overﬁts on the dataset available [1]. Figure 6 shows the detailed architecture
of the model. The model consists of four convolutional layers of ﬁlter sizes 7 * 7,
5 * 5, 3 * 3 & 1 * 1. Max pooling layers of sizes 3 * 3 and 2 * 2 follow each
convolutional layer. The last convolutional layer decomposes into two FC layers
with 256 nodes each with a dropout of probability 0.5. The number of Softmax units
for Bengali, Hindi, Prakrit, Punjabi, Sanskrit, and Tamil models are 2, 2, 4, 2, 5, and
3, respectively. The weight gradient computations indicate that the stroke formations
are the features which contribute the most while predicting the output class. While
the initial layers perform the task of differentiating the background and handwritten
text in the input manuscript, the further layers perform more complex computations.
The last layers are responsible to identify the variations in writing style over a period
to completely benchmark the manuscript by predicting its era.

712
A. Garg et al.
256*256*1                  62*62*32 
9*9*64                  3*3*96              1*1*128
Convolution  (3*3)  Convolution  (3*3)  Convolution (2*2)  Convolution (2*2)  
              (7*7)     Maxpool    (5*5)     Maxpool    (3*3)    Maxpool    (1*1)   Maxpool   Fully Connected 
    (Stride: 2)                (Stride: 3)               (Stride: 1)               (Stride: 1) 
Segregation of background and identifying 
handwritten text 
Identifying variations in writing styles to make 
predictions about the era 
Fig. 6 Architecture of era prediction model
5
Results
The proposed methodology is tested for six Indian languages. Each image is divided
into nine parts to train the model on concentrated text patches. For the purpose of
testing, predictions are made on each part of the manuscript, and the ﬁnal language
and era are decided on the basis of majority polling. We train, test, and validate our
model on Google Colab to use a fast GPU for processing image data. Out of the
available images in each class, we use 70% images for training and remaining 20%
images for testing. 10% images are used for validation purposes to make predictions
on unseen manuscripts, as described later.
Weusefourmetricstoanalyzetheperformanceofourmodels:accuracy,precision,
recall, and f 1 score. Accuracy is the most commonly used metric for evaluation.
Precision is the accuracy of labeling images, whereas recall is proportional to the
number of positive samples detected. F1 score obtains a balance between precision
and recall.
Precision = Truepositive/

Truepositive + Falsepositive

(6)
Recall = Truepositive/

Truepositive + Falsenegative

(7)
F1 score = 2 ∗(Precision ∗Recall)/ (Precision + Recall)
(8)
The overall performance of the model consisting of n output classes is evaluated
through the calculation of macro or average precision, recall, and f 1 score given by:

Language and Era Prediction of Digitized Indian Manuscripts …
713
Table 3 Precision, recall and F1 score for proposed language prediction model
Metric
Bengali
Hindi
Prakrit
Punjabi
Sanskrit
Tamil
Precision
96
84
83
80
82
84
Recall
85
94
80
94
80
95
F1 score
90
89
80
86
80
89
Fig. 7 Normalized
confusion matrix for
proposed language
prediction model
Macro X =

Xi/n, i = 1 −n, X : precision, recall, f 1 score
(9)
The following sections present the training and testing results of language and era
prediction models followed by validation of the proposed architecture.
5.1
Language Prediction Model
We achieve 95% training and 85% testing accuracy. Table 3 shows precision, recall,
and f 1 score values for individual languages. Figure 7 represents a normalized
confusion for the model.
5.2
Era Prediction Model
We train six different era prediction models for each language. Table 4 shows the
trainingandtestingaccuracies.Table5showsprecision,recall,andf 1scorevaluesfor
individual eras in each language. Figure 8 represents normalized confusion matrices.

714
A. Garg et al.
Table 4 Training and testing accuracies of six era prediction models (%)
Metric
Bengali
Hindi
Prakrit
Punjabi
Sanskrit
Tamil
Training acc
95
84
83
85
82
84
Testing acc
85
94
80
94
80
95
Table 5 Precision, recall, and F1 score for proposed era prediction model (%)
Language
Metric
Sixteenth
century
Seventeenth
century
Eighteenth
century
Nineteenth
century
Twentieth
century
Bengali
Precision
–
–
80
90
–
Recall
92
80
F1 score
82
80
Hindi
Precision
–
–
100
100
–
Recall
100
100
F1 score
100
100
Prakrit
Precision
99
89
80
97
–
Recall
93
86
88
87
F1 score
96
87
80
91
Punjabi
Precision
–
99
99
–
–
Recall
99
98
F1 score
98
99
Sanskrit
Precision
88
87
85
99
100
Recall
94
88
85
98
92
F1 score
91
88
85
99
95
Tamil
Precision
95
99
99
–
–
Recall
95
98
96
F1 score
97
99
97
5.3
Validation
In this section, we perform era prediction on an unseen manuscript and compare
our method with other state-of-the-art architectures to increase the validity of the
proposed methodology.
Era prediction on an unseen manuscript. An unseen manuscript is ﬁrst divided
into nine parts and individual era prediction is made on each part of the input image.
The ﬁnal result of the model is the era that dominates, that is, occurs in the majority.
Figure 9 shows the era prediction made on each of the nine parts of an unseen
manuscript. The manuscript is identiﬁed as written in Punjabi language. The era of
eight of nine parts is identiﬁed as seventeenth century which is also the ﬁnal predicted
era. Herein, the predicted era is the same as the actual era, thus corroborating the
working of our model.

Language and Era Prediction of Digitized Indian Manuscripts …
715
Fig. 8 Normalized confusion matrices for six era prediction models
Fig. 9 Era prediction on an unseen manuscript

716
A. Garg et al.
Fig. 10 Comparison of proposed model with other state of art architectures (%)
Comparison with other state-of-the-art architectures. We compare our state-
of-the-art model with AlexNet [4] and GoogleNet [6] architectures as shown in
Fig. 10. We use the pre trained models on the ImageNet dataset to benchmark
manuscripts present in our dataset. Both architectures have performance metrics
below 65%, whereas our model outperforms [4] and [6] with above 80% values
across all classes.
6
Discussion
The primary objective of this research was to propose an algorithm to accurately
benchmark Indian manuscripts on the basis of their era. For accurate classiﬁcation,
it is imperative to have a language and era prediction model with minimal error.
We observe decent performances across all classes which is further veriﬁed through
the normalized confusion matrices of the models. Thus, we can conclude that our
proposed methodology successfully benchmarks manuscripts irrespective of their
language or era. The same system can be extended to other languages as well.
The performance metrics indicate that the model can work well in case of class
imbalancesaswell.Theprecision,recall,andf 1scoresneedtobeconsideredtogether
with the accuracy measures to rightfully evaluate the model. With all values above
80%, we can establish that not one category out of true positives or negatives and
false positives or negatives dominate in the result. Thus, the obtained weights and
biases are robust to any changes in the dataset.
We compare the validity of our approach with other pre-trained convnets. We use
the AlexNet and GoogleNet architectures as studied in [4] and [6] to make predictions
on our dataset. The approach described does not take into account the language of
the manuscript, which might be unknown initially. Taking into account the language
becomes imperative in case of Indian manuscripts due to their rich diversity. We
use the ImageNet pretrained weights and biases in both the networks. Results in
Fig. 10 indicate that both the networks have performance metrics below 65%. Our
model clearly outperforms the GoogleNet and AlexNet pretrained convnets. In this

Language and Era Prediction of Digitized Indian Manuscripts …
717
discussion we explore the underlying reasons behind the same. Lower performance
metrics indicate the convnets have been trained on a fundamentally different dataset
than the one being considered for our aim. These networks require tweaking and need
to be trained from scratch. We address this problem through our method and train the
proposed convnet from scratch. We use decreasing ﬁlter sizes and hyperparameter
callbacks throughout to achieve the best results. Other architectures, when trained
from scratch can prove to be computationally expensive due to the huge volumes. We
look into a computationally efﬁcient and accurate approach to address the problem.
7
Conclusion
We developed a deep learning approach to predict the era of manuscripts written in
six different Indian languages based on the difference in writing style. We adopted
a pipeline structure consisting of language prediction followed by era prediction for
our model. We have employed various image preprocessing methods and a novel
data augmentation technique to enhance the quality and quantity of the images.
We obtained over 90% accuracy on training and over 80% accuracy on validation
across all the available languages and eras. We also compared our model with other
pretrained convnets [4, 6] and observed low performance metrics, with all values
below 65%. For future work, we are interested in adding support for even more
languages depending upon the availability of the dataset. We are also interested in
reducing the size of classes from centuries to shorter periods. The same concept can
be further developed to detect whether the given document is an original or a replica
made in a later time period. We also intend to apply codebook learning to the model
to increase its computational efﬁciency and achieve wider applications.
Acknowledgements We are sincerely thankful to Prof. Santanu Chaudhury, Director, Indian
Institue of Technology, Jodhpur for his valuable suggestions throughout the course of this research
project.
References
1. Kaur, A., Raj, A., Jayanthi, N., & Indu, S. (2020). Algorithm for manuscript grouping indicative
of time period, region and language. IJAST, 29(7), 11805–11824.
2. Rusinol, M., Aldavert, D., Toledo, R., & Llados, J. (2015). Efﬁcient segmentation-free keyword
spotting in historical document collections. Pattern Recognition, 48(2), 545–555.
3. He, S. (2017). Beyond OCR: Handwritten manuscript attribute understanding (pp. 69–87).
University of Groningen, Netherlands.
4. Hamid, A., Bibi, M., Moetesum, M., & Siddiqi, I. (2019). Deep learning based approach
for historical manuscript dating. In 2019 international conference on document analysis and
recognition (pp. 967–972). IEEE Press.

718
A. Garg et al.
5. Studer, L., Alberti, M., Pondenkandath, V., Goktepe, P., Kolonko, T., Fischer, A., Liwicki, M.,
& Ingold, R. (2019). A comprehensive study of imagenet pre-training for historical document
image analysis. axXiv preprint, arXiv: 1905.09113v1
6. Wilkinson, T. (2019). Learning based word search and visualisation for historical manuscript
images (pp. 63–69). Acta Universitatis Upsaliensis, Uppsala
7. Kavitha, B. R., & Srimathi, C., Benchmarking on ofﬂine Handwritten Tamil Character Recog-
nition using convolutional neural networks. Journal of King Saud University—Computer and
Information Sciences (in press).
8. Sujatha, P., & Bhaskari, D. L. (2019). Telugu and Hindi script recognition using deep learning
techniques. IJITEE, 8(11), 2278–3075.
9. Kesiman, M. W. A., Valy, D., Burie, J.-C., Paulus, E., Suryani, M., Hadi, S., Verleysen, M.,
Chhun, S., & Ogier, J.-M. (2018). Benchmarking of document image analysis tasks for palm
leaf manuscripts from Southeast Asia. Journal of Imaging, 4(2), 101–127.
10. Dzinavatonga, K., Medupe, T. R., Prinsloo, L. C., & Ebenso, E. E. (2013). Energy dispersive X-
ray ﬂuorescence analysis of pre and post-1850 historical documents obtained from the National
Library of South Africa. Asian Journal of Chemistry, 25(16), 9384–9386.
11. Adam, K., Baig, A., Al-Madeed, S., Bouridane, A., & El-Menshawy. (2018). KERTAS: Dataset
for automatic dating of ancient Arabic manuscripts. IJDAR, 21, 283–290.
12. Dhali, M. A., Jansen, C. N., Wit, J. W. D., & Schomaker, L. (2020). Feature-extraction methods
for historical manuscript dating based on writing style development. Pattern Recognition
Letters, 131, 413–420.
13. Bannigidad, P., & Gudada, C. (2019). Age-type identiﬁcation and recognition of historical
kannada handwritten document images using hog feature descriptors. Advances in intelli-
gent systems and computing. In Iyer, B., Nalbalwar, S., & Pathak, N. (eds.), Computing,
communication and signal processing (Vol. 810, pp. 1001–1010). Springer, Singapore.
14. Li, Y., Genzel, D., Fujii, Y., & Popat, A. C. (2015). Publication date estimation for printed histor-
ical documents using convolutional neural networks. In Proceedings of the 3rd international
workshop on historical document imaging and processing (pp. 99–106). ACM Press.
15. Penn in Hand: Selected Manuscripts. http://dla.library.upenn.edu/dla/medren/index.html. Last
accessed January 16, 2021.
16. Otsu, N. (1979). A threshold selection method from gray-level histograms. IEEE Transactions
on Systems, Man, and Cybernetics, 9(1), 62–66.
17. Kingma, D., & Ba, J. (2017). Adam: A method for stochastic optimization. In 3rd international
conference for learning representations. arXiv: 1412.6980
18. Zhang, Z., & Sabuncu, M. (2018). Generalized cross entropy loss for training deep neural
networks with noisy labels. axXiv preprint, arXiv: 1805.07836v4

Continuous Chain Fibonacci: Knowledge
Management System with Chatbot
S. Pradeep Kumar, R. Murugeswari, and P. Nagaraj
Abstract Knowledge Management is a big deal when it comes to Organizations.
There will be some general information that needs to be known by all the employees.
The normal process of gaining information happens usually through communication.
There will be lots of redundancy and misleading information. The main objective
of this project is to reduce or eliminate the time of discussion to the person with
knowledge within the same organization. The development of the Frequently Asked
Questions (FAQ) chatbot helps to maintain the record of questions and answers,
whenever a user approaches this bot with queries it provides the user with existing
similar questions using Continuous Chain Fibonacci Algorithm. This algorithm is
speciﬁcally designed for predicting the user’s expected question from the database
with minimal complexity and requirements. If the user couldn’t ﬁnd the query, he/she
can post that query directly to the people with higher echelon or to a certain team
within the organization to get the expected response. Everything will be stored to
save time for someone who is looking for the same information.
Keywords Chatbot · Continuous chain ﬁbonacci · Knowledge management ·
Organizations
1
Introduction
Knowledge Management is essentially about getting the right knowledge to the right
person at the right time. There are several applications speciﬁcally built for Knowl-
edge Management and Learning Management System. The main objective of such
S. P. Kumar (B) · R. Murugeswari · P. Nagaraj
Kalasalingam Academy of Research and Education, Anand Nagar, Srivilliputtur, Krishnankoil,
Virudhunagar, Tamil Nadu 626126, India
e-mail: 9919104001@klu.ac.in
R. Murugeswari
e-mail: r.murugeswari@klu.ac.in
P. Nagaraj
e-mail: nagaraj.p@klu.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_56
719

720
S. P. Kumar et al.
applications is to reduce the time consumption for the new employees who enter
a company or keep the existing employees up to date with the pieces of informa-
tion. The base objective of these tools is to feed the pieces of information without
consuming much human resource and time.
Frequently Asked Question (FAQ) is a part of the Knowledge Management
System. Every Organization Maintains records of past events and trouble shouting
methods in document form [1]. If someone seeks particular information, he/she
have to go through such a document to get enlightened. To reduce the trafﬁc and
time, the FAQ forum has become a mandatory system for every Organization. Every
organization will have its unique platform to maintain these records. A chatbot is a
type of software that can automate conversations and interact with people through
messaging platforms. There are two objective-based categories in chatbots. One is
Intelligence-based and the other is Task focused.
Intelligence-based chatbots aim to communicate or do a task more in a smart
way. There are several types of research and projects are being done in this area. The
intelligence of the bots has been scaled in several ways to compete with others. The
popular scale used to compare these bots are using the sensibleness and speciﬁcity in
communication. The present intelligent chatbot is a Mena chatbot that is created by
google developers, which scores almost close to Human Intelligence. Also, Gener-
ative Pre-trained Transformer 3 (GPT-3) created by Open AI, is the largest artiﬁcial
neural network ever created. It is trained around 570 GB of text information gathered
by crawling the internet.
Task Focused chatbots are very popular, mostly exist in the form of an Assistant
chatbot. These bots are created to do speciﬁc tasks. These have been evolved with
speech to text and text to speech as front end, which makes it more convenient for
the user to interact with the bot.
Continuous Chain Fibonacci is an algorithm created to run efﬁciently behind the
bot to pick up and provide the similar question that the user is seeking. This algorithm
was inspired by the basic function of the human brain that is Expectation. This algo-
rithm is a truncated version of tree-structured nodes and it uses Fibonacci to emulate
the full-sized tree structure and it also supports prioritizing the questions based on
the user’s expectation with a certain question. Fibonacci emulates the momentum of
expectation which is expected to be similar to human decision making.
In this project, a Task Focused chatbot is used to assist with Frequently Asked
Questions. Whenever a user has any doubt within the organization, the user can freely
post his/her query to this chatbot. If the bot ﬁnds a similar question in its database,
it provides suggestions. In case if the user is not satisﬁed with the suggestions, the
user can post that question to the respective person or to a certain team in the same
organization to get a response from them. Every data will be stored to support the
one who seeks the same information.

Continuous Chain Fibonacci: Knowledge Management …
721
2
Related Works
Frequently Asked Question is a necessary feature when comes to administration and
e-commerce that has live chat for customer services. Several algorithms could be
used for FAQs Chatbot, it can use the Neural Network Algorithms direct integration
for best performance. For example, Recurrent Neural Network (RNN) in the form of
Long Short-term Memory (LSTM) for text classiﬁcation. The experimental results
have shown that chatbot could recognize 86.36% of the questions and answer with
93.2% accuracy [2, 3].
Most of the Researches has been done in the educational area, like Colleges and
Universities.ManyUniversitiesprovidee-learningforsupportingclassesfavoringthe
construction of Internet-mediated Knowledge [1]. Not only in the educational insti-
tutions, even in companies the freshers need to be enlightened with the knowledge
before working on companies’ environment. The internship program is organized for
this purpose. The use of a chatterbot in that situation helps a lot in improving knowl-
edge [4]. A Chatbot is a good choice to support a dynamic Q&A system. It should
be human-friendly and must radiate a certain personality of it to the user to keep the
conversation simple. Fewer typing and more clicking is the major improvement in
user experience and user interface part [5]. Research done by Sumikawa et al. [6],
has proved that time-based Q&A needs speciﬁc handling methods, these types of
questions are categorized as temporal questions. Certain questions have a limited
time of validity. Handling such questions requires more intelligence [7]. The use
of Natural Language Understanding (NLU) to classify the type of questions might
help to classify such questions. But still handling such a question is difﬁcult because
several possibilities of actions require unique handling methods [8].
In current lexical and semantic feature representations, previous studies often used
a word embedding method or deep learning method to represent semantic features of
a text [9]. Even though there is an existing Chatbot like ELIZA and ALICE, which is
designed to respond directly with random choices. Latent Semantic Analysis (LSA)
is a better choice in classifying the questions more accurately [10].
Artiﬁcial Intelligent Markup Language (AIML) is a widely used framework in
XML text format that constitutes the knowledge base of a conversational agent. This
gives the behavior for a conversational agent based on the stimulus-response model.
It uses an interpreter, which is in charge of analyzing the message from the user and
ﬁnding the right response from its knowledge base [10, 11].
Most of the requirements for FAQ Chatbot are similar, the concept of re-using
it for different areas is appreciated. FLOSS FAQ chatbot [12] project developed in
Portuguese to an e-government service in Brazil. It comprises the chatbot distribution
service. Sequence to Sequence algorithm for Conversational AI Chatbot proposed
by Palasundram et al. [13] is almost equivalent to the algorithm I have proposed in
this paper.

722
S. P. Kumar et al.
3
Proposed System
3.1
Cliq Platform
Cliq is an Organizational Team Communication platform developed by Zoho, which
almost has every feature that an organization might need. They also have a custom
ex- tension developing platform which is free to every user who has an account.
These extensions provide a vast number of features and possible integrations. There
are several predeveloped extensions in their marketplace you can use for your
organization.
Chatbots can also be developed easily using this platform. They use their
programing language called Deluge. Which is almost used everywhere in Zoho
products to develop extensions. With that programming language, you can create
your chatbot easily without a problem. They also provide a database and several
functionalities that can be integrated into your custom chatbot.
With the help of that platform, I have developed a Chatbot named ‘FAQ?’. The
reason why I have developed the bot in Cliq is that it comes with all the other features
that an organization might need.
3.2
About FAQ Bot
FAQ bot is aimed to store Intra Organizational queries and deliver them to the respec-
tive person who needs them. The basic functionality of this bot is to guess what the
user is seeking and provide the required information. If the user is not satisﬁed with
the suggestions provided by the bot, he/she can post that query to the respective
person, to the team, or broadcast to the entire organization. Anyone who received the
query can follow it or can respond to the query. Every response will get forwarded
to all the followers and the query posted person as a message.
As the data increases this bot’s usability increases too. This Bot Gets the full
ﬂexible team chats to feature from the Cliq platform. The Teams, mentioning, broad-
casting messages, and so on. More to that it allows to create of buttons within
messages for better UI. Figure 1 shows the basic UI of FAQ? Bot.
3.3
Posting a Query
Whenever a user has a question, he/she can post it to this bot by saying ‘post question’
to the FAQ bot. It will request you back, asking you to enter the question as shown
in Fig. 2. After you enter the question, the bot will provide you with a maximum of
3 similar existing questions if exists as shown in Fig. 3. Else the bot will prompt to
choose the receivers. There will be three options to choose from: Teams, Speciﬁc

Continuous Chain Fibonacci: Knowledge Management …
723
Fig. 1 Basic UI of FAQ? chatbot developed in cliq Integration and bot development platform
Users, and Broadcast. Users can proceed with any one of these options as shown in
Fig. 4.
After posting the question, all the recipients will receive a question card in their
FAQ bot with two buttons Answer and Follow as shown in Fig. 5. The user who
received this card can respond to the question or he/she can follow it to receive

724
S. P. Kumar et al.
Fig. 2 FAQ? Bot requests the user to enter his/her query
responses from other users for that particular question. The user who follows the
question will also get the existing responses if available.
3.4
Responding to the Query
Every user who received the question can respond to it. The bot will provide a text
ﬁeld when the answer button is clicked. The user can enter his known response for
the question in it and post it as shown in Fig. 6. Every response will get forwarded to
all the followers and the question posted person in a message card as shown in Fig. 7.
Every response card will contain a Thumbs Up and Thumbs Down emoji button to
store the likes and dislikes of the responses which will help rank the answers in order.
Only the question posted person will receive the answer card with a close discus-
sion button. When the discussion is closed no one can respond to the question
anymore.
3.5
Other Functions
This Bot can also bring up the trending questions in Organization. The user can view
all his/her questions at any time also every contribution he/she made by responding to
queries. The user can also view his/her posted question for status using the ‘My ques-
tions’ Command and his/her contribution to an organization in the form of responses
to questions using the ‘My Contributions’ command. All these functionalities can be
triggered just using a message or the bot action feature in Cliq. Figure 8 shows the
bot action menu of FAQ? Bot.

Continuous Chain Fibonacci: Knowledge Management …
725
Fig. 3 FAQ? The bot provides suggestions for similar questions

726
S. P. Kumar et al.
Fig. 4 FAQ? Bot requests the user to enter his/her choice on recipients
Fig. 5 The question card was received by all the receipts
4
Proposed Algorithm
Continuous Chain Fibonacci Algorithm was designed speciﬁcally for this FAQ
chatbot to ﬁnd similar questions in the existing database and provide them as a
suggestion to the user. This is the core of the FAQ bot to ﬁnd the user expected query.
This algorithm was inspired by Neural Networks and the functionality of the
human brain. The base structure of this algorithm was in a growing tree format. At
ﬁrst, each word in the given sentence is segmented word by word and every word
will get connected to create a tree structure with intermediate nodes.
There will to a dot in front and the end of the sentence to identify the starting and
ending of the sentence. For every n number of words, there will be:
Number of nodes in tree = (n + 1) (n + 2)/2.
From Fig. 9, Since creating such several nodes might be meaningful in a fully
automated response generating bot. In my case, there is no need for a such number

Continuous Chain Fibonacci: Knowledge Management …
727
Fig. 6 FAQ? Bot prompts the user to enter the response for the question
Fig. 7 The answer card is delivered to all the followers and the question posted person in this
format

728
S. P. Kumar et al.
Fig. 8 Bot action menu in FAQ? bot
Fig. 9 Tree-structured node
formation for a sentence,
segmented by words
of nodes as I am not going to map all the nodes to the respective response. Instead,
every node will just be mapped to its questions itself. Also, to reduce the number of
nodes, one-fourth of the nodes are removed and their weights are calculated using a
formula.
From Fig. 10, The weightage follows the number structure of summation of the
number sequence. To make the structure more meaningful the weights should be
incremented in a meaningful manner. That’s where I have introduced Fibonacci. For
each continuous chain, there will be an increment in the Fibonacci number, that
indicates the weightage of the node as shown in Fig. 11.
Before entering into the algorithm the sentence should be cleaned by removing
special characters. The sentence should be segmented word by word and stored in a
string list. The string list should be appended with dots on both ends to highlight the
start and end of the sentence.
The Continuous Chain Fibonacci Algorithm calculates and returns the question
numbers with the most relevant question order as output. The following Flowchart
gives a detailed explanation and ﬂow of the algorithm (Fig. 12).
At ﬁrst, the database to store the node details should be in a structure. The columns
are ID—unique node id, QID—unique question id, LEFT—to store the left word of
the current node, RIGHT—to store the right word of the current node, EXPECT—to
store the id of the next node in the chain.

Continuous Chain Fibonacci: Knowledge Management …
729
Fig. 10 Truncated tree form
to reduce the size but
maintains its functionality
Fig. 11 Continuous chain
ﬁbonacci structure

730
S. P. Kumar et al.
Fig. 12 Flow diagram for continuous chain ﬁbonacci algorithm
• F_LoM(L, R) fetches a list of maps from the database, each map in the list contains
a single record from the database.
• C_N(H, RM) contains node function returns a Boolean value if existing nodes in
Hold’s (H) expected node is in record map (RM) or not.
• U_H(HM, RM) updates the hold_map in H list and increments the Fibonacci
value using the following formula: next_ﬁb = round(ﬁb*(1 + √5)/2).
• I_H(H, RM) this function inserts a new map into the H list in the required format
and initiates the Fibonacci value with 2.

Continuous Chain Fibonacci: Knowledge Management …
731
• U_Q_ID(H, Q_ID) this function removes all the broken chains from the H list
and updates their question id with the total Fibonacci in the Q_ID dictionary.
The following pseudo-code explains Continuous Chain Fibonacci Algorithm:
VAR S_Q: Segmented question in clean format; 
VAR L: Left word; 
VAR R: Right word; 
VAR H: List of maps hold the current nodes and live chains; 
VAR R_QID: Dictionary with question id as key and summed Fibonacci as value; 
VAR  
FOR EACH word IN S_Q: 
 
L=R; R=word; 
 
FOR EACH record_map IN F_LoM(L, R): 
 
 
IF(C_N(H, record_map.id)): 
 
 
 
U_H(H, record_map); 
 
 
ELSE 
 
 
 
I_H(H,record_map); 
 
U_Q_ID(H,Q_ID); 
U_Q_ID(H,Q_ID); 
Sort(Q_ID); 
5
Results
The Continuous Chain Algorithm will ﬁnd similar questions based on the weight
of continuous possible chains that could ﬁnd in other questions. This gives several
possible outputs. Since a question possibly might have several segmented small

732
S. P. Kumar et al.
chains, summing it all might surpass the weight of other questions even if it has a
single ling chain with the highest Fibonacci.
Here are some sample questions to demonstrate the Continuous Chain Fibonacci
Algorithm’s choice on ﬁnding similar questions:
(a)
I recently read Stanford course notes on Convolutional Networks for Semantic
Segmentation by Jonathan Long, Evan Shelhamer, Trevor Darrell. I don’t
understand what de convolutional layers do or how they work.
(b)
Is it known why convolutional neural networks always end up learning increas-
ingly sophisticated features as we go up the layers? What caused them to create
such a stack of features and would this also be true for other types of deep neural
networks?
(c)
I understand the advantages of dying ReLU, which is avoiding dead neurons
during back propagation. However, I am not able to understand why is ReLU
used as an activation function if its output is linear?
(d)
I have built my model. Now I want to draw the network architecture diagram
for a research paper. How to draw a Deep neural network architecture diagram?
(e)
When writing a research paper or making a presentation about a topic that is
aboutneuralnetworks,oneusuallyvisualizesthenetworkarchitecturediagram.
What is a simple way for good visualization in common network architecture?
For the following I have some sample questions and the Fibonacci calculations:
1.
Referring to the Stanford course notes on Convolutional Neural Networks for
Visual Recognition, what is the dying ReLU problem in neural networks?
1:{“questionId”:"a”,"ﬁbonacciValue”:10}.
3:{“questionId”:"e”,"ﬁbonacciValue”:6}.
2:{“questionId”:"b”,"ﬁbonacciValue”:10}.
2.
Convolutional neural networks (CNN) have ﬁrst been developed for image clas-
siﬁcation purposes, is it possible to develop a successful application of CNN or
any other types of deep neural networks for non-image data?
1:{“questionId”:"b”,"ﬁbonacciValue”:22}.
2:{“questionId”:"e”,"ﬁbonacciValue”:4}.
3:{“questionId”:"d”,"ﬁbonacciValue”:2}.
3.
I am preparing a presentation about neural networks. Is there any tool that one
can use to draw the neural network architecture diagram for research papers to
give it a good visualization?
1:{“questionId”:"d”,"ﬁbonacciValue”:25}.
2:{“questionId”:"e”,"ﬁbonacciValue”:15}.
3:{“questionId”:"c”,"ﬁbonacciValue”:4}}.
From the above examples, it is clear that this algorithm’s way of prioritizing is
unique and more relevant.

Continuous Chain Fibonacci: Knowledge Management …
733
6
Conclusion
This paper ﬁrst presents a chatbot’s help in Knowledge Management System for an
organization. The bot I have developed in this project is named ‘FAQ?’. This bot
fulﬁlls its job by maintaining a good connection between employees to assist with
their queries. The Organization might get beneﬁted by using this bot to assist their
employees without approaching someone or dealing with queries personally. There
will be a huge increase in productivity because this bot acts as a manual for every
user. This bot could also be used in universities to increase collaboration.
By using the Continuous Chain Fibonacci algorithm, the data will never need to
seek for external application support to fetch similar questions. Since this algorithm
is inspired by a neural network. There are several possible future improvements.
Several possible applications might get supported by this algorithm. Improving this
algorithm by including the answers to get mapped directly from the question may
help the user to get the expected speciﬁc answer itself. The same algorithm could
be used to work with characters instead of words to provide even more relevant
suggestions.
References
1. Neto, M. A. J., & Fernandes, M. A. (2019). Chatbot and conversational analysis to promote
collaborative learning in distance education. In 2019 IEEE 19th International Conference
on Advanced Learning Technologies (ICALT). Published. https://doi.org/10.1109/icalt.2019.
00102
2. Lee, K., Jo, J., Kim, J., & Kang, Y. (2019). Can chatbots help reduce the workload of adminis-
trative ofﬁcers?—Implementing and deploying FAQ chatbot service in a university. Commu-
nications in Computer and Information Science, 348–354. https://doi.org/10.1007/978-3-030-
23522-2_45
3. Muangkammuen, P., Intiruk, N., & Saikaew, K. R. (2018). Automated Thai-FAQ Chatbot
using RNN-LSTM. 2018 22nd International Computer Science and Engineering Conference
(ICSEC). Published. https://doi.org/10.1109/icsec.2018.8712781
4. Ch’ng, S. I., Yeong, L. S., & Ang, X. Y. (2019). Preliminary ﬁndings of using chat-bots as a
course FAQ tool. 2019 IEEE Conference on E-Learning, E-Management & E-Services (IC3e).
Published. https://doi.org/10.1109/ic3e47558.2019.8971786
5. Sethi, F. (2020). FAQ (Frequently Asked Question) chatbot for conversation. Published. https://
doi.org/10.26438/ijcse/v8i10.710
6. Sumikawa, Y., Fujiyoshi, M., Hatakeyama, H., & Nagai, M. (2019). Supporting creation of
FAQ dataset for E-learning chatbot. Intelligent Decision Technologies, 2019, 3–13. https://doi.
org/10.1007/978-981-13-8311-3_1
7. Pérez, J. Q., Daradoumis, T., & Puig, J. M. M. (2020). Rediscovering the use of chatbots in
education: A systematic literature review. Computer Applications in Engineering Education,
28(6), 1549–1565. https://doi.org/10.1002/cae.22326
8. Zubani, M., Sigalini, L., Serina, I., & Gerevini, A. E. (2020). Evaluating different natural
language understanding services in a real business case for the Italian language. Procedia
Computer Science, 176, 995–1004. https://doi.org/10.1016/j.procs.2020.09.095
9. Su, M. H., Wu, C. H., Huang, K. Y., & Lin, W. H. (2019). Response selection and automatic
message-response expansion in retrieval-based QA systems using semantic dependency pair

734
S. P. Kumar et al.
model. ACM Transactions on Asian and Low-Resource Language Information Processing,
18(1), 1–24. https://doi.org/10.1145/3229184
10. Ranoliya, B. R., Raghuwanshi, N., & Singh, S. (2017). Chatbot for university-related FAQs. In
2017 International Conference on Advances in Computing, Communications, and Informatics
(ICACCI). Published. https://doi.org/10.1109/icacci.2017.8126057
11. Mikic-Fonte, F. A., Llamas-Nistal, M., & Caeiro-Rodriguez, M. (2018). Using a chatterbot as
a FAQ assistant in a course about computers architecture. In 2018 IEEE Frontiers in Education
Conference (FIE). Published. https://doi.org/10.1109/ﬁe.2018.8659174
12. de Lacerda, A. R. T., & Aguiar, C. S. R. (2019). FLOSS FAQ chatbot project reuse. In Proceed-
ings of the 15th International Symposium on Open Collaboration. Published. https://doi.org/
10.1145/3306446.3340823
13. Palasundram, K., Mohd Sharef, N., Nasharuddin, N. A., Kasmiran, K. A., & Azman, A. (2019).
Sequence to sequence model performance for education chatbot. International Journal of
Emerging Technologies in Learning (IJET), 14(24), 56. https://doi.org/10.3991/ijet.v14i24.
12187

Management of IoT Devices Security
Using Blockchain—A Review
Gaurav Pattewar, Nachiket Mahamuni, Hrishikesh Nikam, Omkar Loka,
and Rachana Patil
Abstract Internet of things (IoT) refers to a network where the devices included in
that network are connected with each other through a common medium, in this case,
the Internet, in order to share or exchange data with other devices in the network. The
paper concentrates on Management of Security of these devices in the IoT network
along with their maintenance, accessibility, etc. The main problems faced are data
leakage, data alteration/modiﬁcation, access to private data or important transactions,
data loss, etc. This review paper refers to various ways to improve the existing IoT
system with the use of different consensus algorithms and techniques. It also covers
the security and data privacy of systems like smart homes and smart cities through
modiﬁed blockchain systems.
Keywords Security · IoT · Blockchain · Data privacy · Consensus algorithm ·
Smart contracts · Hyper ledger fabric · Ethereum
1
Introduction
Along the time, there has been a huge amount of advancement in technologies,
embedded systems, real-time information has taken place resulting in a Modern
Era where different devices/objects are connected with each other over the internet.
G. Pattewar (B) · N. Mahamuni · H. Nikam · O. Loka · R. Patil
Department of Computer Engineering, Pimpri Chinchwad College of Engineering, Pune 411044,
India
e-mail: gaurav.pattewar18@pccoepune.org
N. Mahamuni
e-mail: nachiket.mahamuni18@pccoepune.org
H. Nikam
e-mail: hrishikesh.nikam18@pccoepune.org
O. Loka
e-mail: omkar.loka18@pccoepune.org
R. Patil
e-mail: rachana.patil@pccoepune.org
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_57
735

736
G. Pattewar et al.
Fig. 1 Working of a IoT device in the IoT network
The invention of microcontrollers and microprocessors/microcomputer chips and the
superﬁcial wireless network technology made it easy to connect different devices
irrespective of their shape, size, area of installation/use, etc., making them smarter
than ever. This system can work without the interference of a human being. This
advancement is bringing the physical as well as the digital world together [1, 2].
The Internet of Things is enabled due to combined working of existing ﬁelds like
the embedded system, control system, automation services (smart homes and cities,
industry). The IoT includes systems like home security systems, home appliances,
automation in irrigation, etc. These systems can be controlled remotely by other
devices which have one or more common ﬁelds to the system. There is involvement
of IoT in the healthcare system too making it more efﬁcient and organized. Along
with the increased use of IoT devices in different sectors, the cyber-attacks are on
rise [3, 4]. Addressing these cyber security threats [5] is one of the biggest challenges
in IoT networks. The Working of an IoT device like collecting data, storage of data
on cloud systems, processing of data, and its application in the IoT network is shown
in the below mentioned Fig. 1.
In the ﬁrst stage, the sensors/devices collect data from the environment. Then
the data collected by sensors is sent to the cloud storage with the help of WIFI,
Bluetooth, etc. In the third stage, the data is processed/analyzed and stored in the
cloud database for further use. The processed data from cloud storage is used in
end-user applications.
1.1
History of Internet of Things (IoT)
The idea of making existing systems smarter and better by adding sensors or other
objects and intelligence to the basic devices was discussed around the 1980s. The
ﬁrst implementation of IoT was in a Coca-Cola vending machine at Carnegie Mellon

Management of IoT Devices Security Using Blockchain—A Review
737
University in 1982. It was the ﬁrst ARPANET connected device. The vending
machine was able to check its inventory/stock as well as the temperature of newly
loaded drinks. The term ‘Internet of Things’ was deﬁned by Kevin Ashton. He
mentioned that, for computers to manage all individual tasks, Radio Frequency
Identiﬁcation (RFID) is a requisite to IoT.
At that time, the processors or chips used in the systems were much more expen-
sive as well as bulkier. There were no proper means for the devices to communicate
with each other. The inter connectivity of devices over a large geographical area was
possible only when the processors/chips were modiﬁed and were available at afford-
able cost. As Kevin Ashton mentioned, RFID tags along with broadband internet
and wireless networks made it possible for the devices to establish a connection with
each other. The acquisition of IPv6 among other things increased the chances to scale
IoT on a larger scale.
2
Features of Blockchain
Decentralization—In the centralized transaction, every transaction is corroborated
with the centralized third-party. This causes increase in cost and affects the perfor-
mance at the center point. In decentralized processing third-party is not needed, so
it increases the performance.
Perseverance—After the validation of the transaction record by a miner node, the
copy of that record is distributed across the network and is not deleted from the
blockchain network.
Anonymity—In blockchain, a node uses a public key to collaborate with the network
which gives the address of the node in the blockchain along with the secured data
privacy.
Security—In the blockchain network, public-key cryptography is used for securing
the network. It has public key and private key. Generation of such keys is based on
cryptographic algorithms which are based on way functions. For effective security,
rivate-key is kept private and public key can be distributed openly.
Strong Backend—If any failure occurs then each distributed node maintains a copy
of the whole database in the backend.
More Efﬁciency—Transaction does not contain a third-party along with low-trust
conditions, time required to verify a transaction is less and hence it increases
efﬁciency.
Transparency—The public blockchain is open/viewable to all the participants.
Though the transactions are immutable.
Smart Contract—There are deﬁned rules in smart contracts. Ethereum supports
different languages to write contracts like solidity.

738
G. Pattewar et al.
3
Related Work
To know which technique or algorithms work efﬁciently with blockchain in order to
improve security along with other parameters like maintenance, performance, etc. of
the IoT devices, we did study the different methods/modiﬁcations on the basis of its
Contribution, Advantages, and Shortcomings. The results of the survey on the basis
of above mentioned criteria is explained in (Table 1).
From the analysis and review of existing schemes described in Table 1. It is
observed that some of the attacks like the eclipse and sybil attacks have been proved
difﬁcult to handle. To overcome these issues, we are currently working on devel-
opment of a blockchain based solution for maintaining the security of IOT device’s
data.
4
Challenges Faced by IoT Devices Security
Data Privacy—Due to the centralized system of the device, the data collected is
accessible to attack by compromising the nodes of the system. That’s why the attacker
can get the data without any authorized access.
Data Integrity—Attackers can access the data in the centralized system which may
result in alteration or modiﬁcation of data by the attacker.
Centralized Entity—Third-party controlled and stored data may lead to issues
regarding security and privacy.
Trusted Data Origin—The origin of data in the network is not known to anyone,
hence the data can be tampered during transfer of data.
Access Control—It is difﬁcult to describe in an IoT network that data can be accessed
by nodes and can execute different functions.
Single Points of Failure—Central authority stores and veriﬁes all the data of the
network but in case the central point breaks down, the whole network gets. disturbed.
Unauthorized use of Personal Data—Sensors and chips are part of the IOT devices
which collect the information and send it with the help of the internet. Central
database stores collected information. Firms can use this data which causes an effect
on data privacy.

Management of IoT Devices Security Using Blockchain—A Review
739
Table 1 Comparative analysis of existing schemes
References
Year
Blockchain platform
Contribution
Advantages
Shortcomings
Dorri et al. [1]
2017
Novel framework
Blockchain security along
with privacy can occur with
the use of hierarchical form
and distributed trust
Authentication process of
outgoing transactions
increased
Energy consumed by miner
is more
Singh et al. [2]
2019
Ethereum, proof-of-authority,
proof-of-work
Storage capacity and
computational power
increases
Increase performance along
with reduced power
consumption
Another decentralized
solution can be used
Lee et al. [6]
2020
Ethereum platform
Stores only necessary
information
Increases conﬁdentiality,
integrity, and authentication
of the heterogeneous IoT and
centralized gateways
It has an additional
computation
complexity
Nadiya et al. [7]
2019
Ethereum, blockchain, smart
contract
With the help of hash function
along with encryption
algorithm increases the
strength of the IOT devices
Hash function’s avalanche
effect is greater than 50%
System cannot be developed
using hash Conﬁguration
Lunardi et al. [8]
2019
Appendable-block blockchain
framework, consensus
algorithms
An improved system with
appendable-block blockchain
that supports various
consensus algorithms to
overcome existing issues
Various attacks are tackled
with improved performance
along with adoption to
different IoT scenarios
System will be vulnerable
against eclipse and sybil
attacks
Kanhere et al. [9]
2020
Smart cities and homes, supply
chains, vehicular network
A several layer model of
blockchain along with
different network architectures
and consensus algorithms
Higher dependability, higher
availability, better security
and communication
Issues inherited due to P2P
networks
(continued)

740
G. Pattewar et al.
Table 1 (continued)
References
Year
Blockchain platform
Contribution
Advantages
Shortcomings
de Arruda et al. [10]
2020
A gateway having hierarchical
peer to peer architecture is
proposed
A hierarchical peer to peer
gateway based architecture is
added to appendable-block
blockchain along with PBFT
and POW algorithms
Higher data integrity and
privacy
Over a largely distributed
area, it provides less
security and latency
Alharby et al. [11]
2020
Smart cities, smart buildings,
appendable-block blockchain
Context-based consensus, a
modiﬁed consensus
mechanism for blockchain
Latency is reduced and
throughput of transaction
insertions increases
Complex to implement
Loia et al. [12]
2016
Smart grids, demand response,
Smart Governance
Implementation of services
that can have interaction with
the environment
Combination of the IoT
platform with the other
autonomous and intelligent
systems are used for
providing smart and
widespread applications
Privacy rights of citizens in
the area which can be solved
Garrocho et al. [13]
2021
Smart city, smart contract
API Gateways are added in
order to provide better
authentication and
identiﬁcation
Provide real-time
management information
protection against DDOS
attack
Communication problems
occurred due to the
occurrence of UDP protocol
Yetis et al. [14, 15]
2019
Cryptographic hash algorithm,
secure communication, smart
home
Authorization system is being
set up using the distributed
node structure of the
blockchain system and blocks
are kept in these nodes.
Vigenere cipher encryption is
used
The message
transfer/communication
between the nodes is
encrypted which results in
better security as it maintains
data privacy
UDP protocol is used
instead of IP protocol which
is unsafe
(continued)

Management of IoT Devices Security Using Blockchain—A Review
741
Table 1 (continued)
References
Year
Blockchain platform
Contribution
Advantages
Shortcomings
He et al. [16]
2016
Hyperledger Fabric, smart
contracts
A web based-prototype along
with blockchain is used to
validate the authentication,
identiﬁcation process
Security against a single point
of failure. Veriﬁes ﬁrmware
update authority and provides
security against potential
cyber-attacks
The grammar and compiler
should work properly,
otherwise, the system won’t
give the expected results
Dang et al. [17]
2018
Smart contracts
Smart home based IoT
Blockchain (SHIB). The
proposed architecture has
three types of smart contracts
that are ACC, RC, and JC
The proposed system
provides data privacy, trust
access control, and high
scalability
This system is only for those
parties who agreed the smart
contract with the smart
home owner
Ding et al. [18]
2019
Consortium blockchain
We proposed a novel
attribute-based access control
scheme for IoT systems
The proposed scheme could
effectively resist multiple
attacks, avoid single point of
failure as well as data
tampering
Computational overhead of
transaction increases
Fakhri et al. [19]
2018
Ethereum with smart contract
The proposed system includes
blockchain with
communication protocol
MQTT
Smart contracts help to store
and retrieve data faster, while
the communication protocol
MQTT secures
communication between two
devices more efﬁciently
Avalanche effects due to
simultaneous attacks should
be considered

742
G. Pattewar et al.
5
Conclusion
In this review, we surveyed different methods/modiﬁcations of the blockchain plat-
form to improve the existing system which provides better security, data integrity,
maintenance, performance, etc. This paper emphasizes the issues faced by IoT
network devices and the proposed solution to tackle the threats and problems faced
by devices of IoT. The different techniques like appendable-block blockchain along
with different consensus algorithms, cryptographic hash algorithms, API gateways
with hierarchical peer to peer architectures, etc. are mentioned in this survey paper.
There were some problems faced while implementation of the proposed system like
implementation is expensive. Also, transition from existing structure to new structure
is a bit difﬁcult. Above mentioned techniques have been proved signiﬁcant against
IoT devices threats for, e.g., ﬁshing attacks, bribery attacks, unauthorized access, data
integrity, etc. Also, they help to improve the performance of the system along with
its maintenance and less power/energy consumption. The drawbacks are that some
of the attacks like the eclipse and sybil attacks have been proved difﬁcult to tackle.
Also, some issues inherited due to the P2P network are to be taken into consideration.
References
1. Dorri, A., Kanhere, S. S., Jurdak, R., & Gauravaram, P. (2017). March. Blockchain for IoT
security and privacy: The case study of a smart home. In 2017 IEEE International conference
on pervasive computing and communications workshops (PerCom workshops) (pp. 618–623).
IEEE.
2. Singh, P. K., Singh, R., Nandi, S. K., & Nandi, S. (2019). June. Managing smart home appli-
ances with proof of authority and blockchain. In International conference on innovations for
community services (pp. 221–232). Springer, Cham.
3. Patil, R. Y., & Devane, S. R. (2019). Network forensic investigation protocol to identify true
origin of cyber crime. Journal of King Saud University-Computer and Information Sciences.
4. Yogesh, P. R., & Devane, S. R. (2018, July). Primordial ﬁngerprinting techniques from the
perspectiveofdigitalforensicrequirements.In20189thinternationalconferenceoncomputing,
communication and networking technologies (ICCCNT) (pp. 1–6). IEEE.
5. Patil, R. Y., & Devane, S. R. (2017, October). Unmasking of source identity, a step beyond in
cyber forensic. In Proceedings of the 10th international conference on security of information
and networks (pp. 157–164).
6. Lee, Y., Rathore, S., Park, J. H., & Park, J. H. (2020). A blockchain-based smart home gateway
architecture for preventing data forgery. Human-centric Computing and Information Sciences,
10(1), 1–14.
7. Nadiya, U., Rizqyawan, M. I., & Mahnedra, O. (2019). November. Blockchain-based secure
data storage for door lock system. In 2019 4th International Conference on Information
Technology, Information Systems and Electrical Engineering (ICITISEE) (pp. 140–144). IEEE.
8. Lunardi, R. C., Michelin, R. A., Neu, C. V., Nunes, H. C., Zorzo, A. F., & Kanhere, S. S. (2019,
November). Impact of consensus on appendable-block blockchain for IoT. In Proceedings of
the 16th EAI international conference on mobile and ubiquitous systems: Computing (pp. 228–
237). networking and services
9. Zorzo, A. F., Nunes, H. C., Lunardi, R. C., Michelin, R. A. & Kanhere, S. S. (2018,
October). Dependable IoT using blockchain-based technology. In 2018 Eighth Latin-American
Symposium on Dependable Computing (LADC) (pp. 1–9). IEEE.

Management of IoT Devices Security Using Blockchain—A Review
743
10. de Arruda, E. H., Lunardi, R. C., Nunes, H. C., Zorzo, A. F. & Michelin, R. A. (2020,
May). Appendable-block blockchain evaluation over geographically-distributed IoT networks.
In 2020 IEEE International Black Sea Conference on Communications and Networking
(BlackSeaCom) (pp. 1–6). IEEE.
11. Lunardi, R. C., Alharby, M., Nunes, H. C., Zorzo, A. F., Dong, C. & Van Moorsel, A.
(2020, November). Context-based consensus for appendable-block blockchains. In 2020 IEEE
International Conference on Blockchain (Blockchain) (pp. 401–408). IEEE.
12. Arasteh, H., Hosseinnezhad, V., Loia, V., Tommasetti, A., Troisi, O., Shaﬁe-khah, M. & Siano,
P. (2016, June). Iot-based smart cities: A survey. In 2016 IEEE 16th International Conference
on Environment and Electrical Engineering (EEEIC) (pp. 1–6). IEEE.
13. Ferreira, C. M. S., Garrocho, C. T. B., Oliveira, R. A. R., Silva, J. S., & Cavalcanti, C. F. M.
D. C. (2021). IoT Registration and authentication in smart city applications with blockchain.
Sensors, 21(4), 1323.
14. Yetis, R. & Sahingoz, O. K. (2019, April). Blockchain based secure communication for IoT
devices in smart cities. In 2019 7th International Istanbul Smart Grids and Cities Congress
and Fair (ICSG) (pp. 134–138). IEEE.
15. Patil,R.Y.,&Devane,S.R.(2020).Hashtree-baseddeviceﬁngerprintingtechniquefornetwork
forensic investigation. In Advances in Electrical and Computer Technologies (pp. 201–209).
Springer, Singapore.
16. He, X., Gamble, R. & Papa, M. (2019, October). A smart contract grammar to protect IoT
ﬁrmwareupdatesusinghyperledgerFabric.In2019IEEE10thAnnualInformationTechnology,
Electronics and Mobile Communication Conference (IEMCON) (pp. 0034–0042). IEEE.
17. Dang, T. L. N. & Nguyen, M. S. (2018, November). An approach to data privacy in smart home
using blockchain technology. In 2018 International Conference on Advanced Computing and
Applications (ACOMP) (pp. 58–64). IEEE.
18. Ding, S., Cao, J., Li, C., Fan, K., & Li, H. (2019). A novel attribute-based access control scheme
using blockchain for IoT. IEEE Access, 7, 38431–38441.
19. Fakhri, D. & Mutijarsa, K. (2018, October). Secure IoT communication using blockchain tech-
nology. In 2018 International Symposium on Electronics and Smart Devices (ISESD) (pp. 1–6).
IEEE.

Role of the Procedures of Deep Learning
for Higher Proﬁtability
in the Agriculture Sector
Amit Verma
Abstract Utilization of the techniques of Artiﬁcial Intelligence has been obvious
for the agriculture sector. The division faces various difﬁculties so as to boost its yield
including ill-advised soil treatment, malady and nuisance pervasion, large informa-
tion necessities, low yield, and information gap among ranchers and innovation. The
primary idea of AI in agribusiness is its adaptability, superior, exactness, and cost-
viability. The paper represents a survey of the uses of AI and deep learning in crop the
board. An uncommon spotlight is laid on the quality and constraints of the utilization
of four procedures (CALEX, FARMSYS, ANN, and Demeter system) and the route
in using the methods of AI for higher proﬁtability.
Keywords Agribusiness · Calex · Farmsys · Neural networks · Demeter system ·
Artiﬁcial intelligence · Deep learning classiﬁers
1
Introduction
Accomplishing greatest harvest yield at least expense is one of the objectives of
agrarian creation. Early recognition and the board of issues related to crop yield
pointers can assist increment with returning and ensuing beneﬁt [1].
Farming is the principle uphold and the signiﬁcant segment for the economy of
India. The creation of agronomy is excessively low. As the interest in food is devel-
oping exponentially, the specialists, examiners, ranchers, researchers, and govern-
ment attempt to put further exertion and systems to increment horticultural creation
to oblige the requirements [2, 3]. The target of horticultural creation is to accomplish
greatest harvest yield. Introductory revelation and the board of entanglements like
harvest yield can help intensify return and resulting beneﬁts. On the off chance that
local climate designs are affected, enormous scope climate occasions can substan-
tially affect crop creation. Yield directors can utilize forecasts to limit harm in basic
A. Verma (B)
University Centre for Research and Development, Chandigarh University, Gharuan, Mohali,
Punjab 140413, India
e-mail: amit.e9679@cumail.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_58
745

746
A. Verma
conditions. Moreover, these gauges could be utilized to utilize the harvest ﬁgure if
the potential for good states of development exists [4].
Rural synthetic substances have a danger to impede individuals’ wellbeing, which
could bring about the disturbance of biological systems. Consequently, it ought to be
fundamental to utilize cultivating strategies, which can limit the utilization of such
synthetic compounds, just as advancements for climate protection. It ought to be
imperative to analyze the plant conditions in utilizing the earth amicable creation
innovation [5].
Exactnesscultivatingproducesinformationwhich,becauseoftheirsortandunpre-
dictability, couldn’t be proﬁciently dissected by conventional strategies. Harvest the
board customarily has been founded predominantly on the experience of the rancher
for his ﬁeld. However, later with ranch motorization, the immediate association of
the rancher with the ﬁeld was lost and the executives depended on yield and soil
mean properties [6].
Today, work is the biggest cost factor of a cutting edge nursery holding. Over
30% of the complete creation costs are spent on compensation for the cultivator
and his representatives [7, 8]. Clearly, to adapt to immersing market requests and
expanding rivalry, the producer is searching for approaches to improve the general
proﬁciency of the creation cycle. Improving the productivity of human work or in
any event, lessening the measure of human work is a main point of contention today.
Physical work in a nursery is requesting, particularly under poor climatic conditions.
The positions accessible are not esteemed and the proﬁt is low. In this way, it is
turning out to be increasingly harder to acquire satisfactory staff. These are reasons
why effectively numerous years back, research was centered on the computerization
of the dreariest and dull undertakings in agricultural yield creation, both inside and
outside nurseries [9].
The agribusiness part is going through a change driven by new advancements,
which appears to be encouraging as it will empower this essential area to move
to the following degree of homestead efﬁciency and beneﬁt [10]. Accuracy Agri-
culture, which comprises of applying inputs (what is required) when and where is
required, has become the third rush of the cutting edge horticulture upheaval (the ﬁrst
was motorization and the second the green insurgency with its hereditary alteration
[11]), and these days, it is being upgraded with an expansion of ranch information
frameworks because of the accessibility of bigger measures of information [12].
The last motivation behind this paper is to exhibit how to settle the choices of
advanced farming based on information which can be prompt accessibily today for
the manageable and gainful incitation to support the individuals for minimizing the
damages to climate [13, 14]. So as to assess how present day horticulture can help
in a reasonable dynamic cycle, this article returns to the principle steps of a data put
together farming and centers with respect to information the board frameworks by
auditing ongoing applications identiﬁed with each essential advance, from informa-
tion obtaining in crop ﬁelds to the execution of errands with variable rate hardware
[12].
This paper chronicles basic concept of CALEX, FARMSYS, ANN, and Demeter
system which includes the capabilities, characteristics, classiﬁcation, architecture,

Role of the Procedures of Deep Learning for Higher …
747
and the applications of the agricultural perspectives globally. Further, it provides
the knowledge for the representation, issues, searching mechanism, and future
projections of the four procedures.
2
Procedures of Deep Learning Used for Comparisons
2.1
CALEX
The target of the CALEX venture is to build up a universally useful shell program that,
when combined with space explicit program modules, gives a product bundle that can
be utilized by cultivators, bug control guides, specialists, and different administrators
for generally speaking farming administration choice help.
The two basic subprograms of the CALEX are the execution and the smart system,
and the modules which are domain speciﬁc. The ﬁrst part which comprises its execu-
tion and the system is written in C, while the domain speciﬁc modules of the venture
are in C, Pascal, or FORTRAN. The crucial part of the CALEX pack comprises
the executive, the scheduler, and the expert system. The databases and the territory
unequivocal modules are added to the fundamental CALEX system to shape an abso-
lute execution. The ﬁeld archives and atmosphere records are made by CALEX as
of late depicted [10].
The CALEX framework, a microcomputer based coordinated master choice
emotionally supportive network for horticultural administration. The program, which
is actualized related to space explicit modules, comprises of the three basic and
separate subprograms: the schedules, the executive, and the shell of the system. The
executive ﬁlls in as the essential interface to the client, to models, and to the plate.
The scheduler produces a succession of the executive’s exercises by more than once
initiating the master framework. The expert system shell settles on the real adminis-
tration choices. The CALEX bundle is mainly independent of the domain which can
be utilized with any ware and makes it platform independent. Beginning improve-
ment of program has zeroed in on the advancement of the bundle of modules for the
cotton of California and another bundle mainly for the peaches. This paper depicts
the engineering of the fundamental CALEX program. The highlights of the CALEX
bundle are represented with brief portrayals of a portion of the item’s explicit usage.
Full depictions of product explicit executions will be given somewhere else [15].
One of the chief elements of the CALEX program is to furnish the client with a
timetable of future administration exercises (for example, water system, exploring
for bothers, preparation, and so forth) A signiﬁcant disadvantage of the underlying
adaptation, as depicted by Plant (1989), was that it didn’t have an adequately ground-
breaking instrument for taking care of the booking of in-season item the executives
[7, 16, 17]. In the ﬁrst framework, every action’s information base was basically
stacked and prepared in arrangement. It was perceived that in planning exercises,
it was conceivable to freely plan two contradictory activities for that exact day. For

748
A. Verma
instance, a water system may be planned for the exact day as a stroll through the
ﬁeld to scout for bug bugs. To determine this, higher need exercises were handled
before lower need ones to guarantee that the higher need exercises would ‘win’ any
contentions [10].
2.2
FARMSYS
FARMSYS, an incorporated apparatus the board choice emotionally supportive
network, was planned and created in the PROLOG. The FARMSYS comprises
of the four parts which are: the operational simulator, the system which is info
manager, the analyses which are required for results, and the system for estimation
of the yield which is actualized under solitary climate, along these lines prompting
their consistent coordination [18]. They utilize a typical pool of information bases
to play out their assignments. The item arranged portrayal of homestead informa-
tion in PROLOG helped in catching heuristics, for example, ranchers’ inclinations
and needs for various ﬁelds, editing designs, activity types, and administrator farm
vehicle executes mixes fundamental for planning ﬁeld tasks [19, 20]. FARMSYS at
present suggests changes in ranch hardware and work assets dependent on special-
ized contemplations. A ﬁnancial investigation of these adjustments regarding starting
venture, activity and upkeep cost, and added returns or misfortunes because of
practicality of the inﬂuenced tasks would additionally improve the nature of these
suggestions [21].
The methodology of utilizing pre-created model outcomes for assessing yield of
the crop and ranch creation for various ﬁelds is a useful other option. In any case,
the model linkage act as the fundamental parts of the FARMSYS, and intuitively
execution for every particular circumstance made by operational simulator would
additionally upgrade the nature of the forecasts [22].
FARMSYS expects that all ranch assets are solely accessible for crop creation
[23]. A measure that parcels the accessible assets among animal and yield creation
would make FARMSYS a more adaptable instrument for the ranches, particularly
little scope undertakings and resource cultivating in creating nations that have animal
creation as a basic segment of their cultivating frameworks [24].
The involvement in FARMSYS shows that the methodology of letting the group
of specialists assess and the decision support system integrated within the model
evaluation is a doable and feasible technique for making a decision about the nature
of such frameworks [25].
PROLOG is one of the most broadly utilized AI dialects for master frameworks
and furthermore gives a climate to composing applications in an article situated way.
As of late, endeavors have additionally been made to create reproduction projects,
and recreation and article arranged programming dialects utilizing PROLOG as a
base language [22].
The PROLOG program is an assortment of realities and rules (information base)
about the framework. These realities and rules are collected in two head parts of

Role of the Procedures of Deep Learning for Higher …
749
the program code: speciﬁcally, predicates and conditions. Predicates are undiffer-
entiated from subroutines, and provisos are like requires a subroutine with explicit
contention esteems in a procedural language [26]. From this assortment, PROLOG
infers answers for the inquiries and accomplishes its objective, additionally a part of
the PROLOG program, via looking through the provisions for those that are valid. Its
abilities in emblematic preparing, list control, and recursion encourage taking care
of heuristics, notwithstanding quantitative and procedural calculations important to
recreate the framework’s conduct [21].
Other than a climate for consistent incorporation of master frameworks and recre-
ation, Turbo PROLOG (c), utilized in this task, gives a helpful programming climate
and grants composing the code in normal language-like sentences. It additionally
allows incorporating the last program in the conﬁguration of an executable record
which can be dispersed to clients with no requirement for a run-time adaptation of
the PROLOG language [22].
2.3
ANN
The artiﬁcial neural network is a forecast procedure that is utilized to foresee non-
straight connections from info gave. They depend on organic neural cycles of a crea-
ture’smind[27].NeuralNetwork,toanticipatetheyieldrequirespreparing,whenever
it is prepared it can foresee the harvest yield which contains designs regardless of
whether the past info incorporates any blunder. Neural Network is known for giving
precise outcomes regardless of whether the info gave is unpredictable, multivariate,
and nonlinear and afterward, the yield is removed. Artiﬁcial neural network (ANN)
has an assortment of utilizations like discourse acknowledgment, PC vision, char-
acter acknowledgment, signature check acknowledgment, human face acknowledg-
ment [28]. ANN comprises of three unique squares Network Topology, Weights or
Learning, Activation Functions. Organization Topology contains two sorts of orga-
nization—Feed forward and Feed-back. Feed forward layer comprises of various
layers which are associated with one another through hubs, there is no circle, and
sign is passed distinctly one way from contribution to yield. It comprises two sorts
of organization, single layer feed forward organization and multi-layer feed forward
organization. Input networks include various layers which are associated through
hubs however the organization contains circles where the sign streams in the two
ways [29]. It is additionally partitioned into three sort’s intermittent organizations,
network which is fully connected, and the jordan network. These hubs have various
loads, In the Learning technique, on the off chance that the ideal yield isn’t deter-
mined, at that point, the heaviness of these hubs is adjusted. These hubs are known
as neurons. It comprises 3 distinct kinds of learning as supervised, unsupervised, and
reinforcement learning. Enactment capacities are utilized to get the exact yield [4].
In programming designing and the related ﬁelds, counterfeit neural organizations
are the models that are computational that are animated by animal central tangible
frameworks (explicitly the brain) that are good for AI and model afﬁrmation [30].

750
A. Verma
Fig. 1 Connections and the
layers of feed forward and
back-propagation ANN
These are typically presented as structures of the “neurons” which are interconnected
and can enlist regards from commitments by dealing with information through the
association. Like other AI methodologies, neural associations have been used to
fathom a wide grouping of endeavors that are hard to comprehend using regular rule
based programming, including PC vision and talk afﬁrmation [31].
In artiﬁcial neural network, the word network recommends the connection
between neurons in the various layers of each structure. A model framework has
three layers. The main layer has neurons used for input nodes, which can send infor-
mation by strategies for neurotransmitters to the layer of neurons placed at second
position, and accordingly through more neural relationship with the yield neurons
placed at third layer. Additional astounding structures can have number of layers of
neurons with some having layers expandation of the information neurons and yield
neurons. The neural afﬁliations store limits called “loads” that control the information
in the counts.
The feed forward back spread neural organization shows in Fig. 1. The layers
used in the classiﬁcation process are used for the classiﬁcation process of the images
used for disease detection. This neural organization design is extremely mainstream,
since it very well may be applied to various errands.
The term initially used, “feed forward” illustrates that how the neural organiza-
tion cycles and evaluates the designs. In the term feed forward neural organization,
forward association of the neurons is applied. Each layer in the neural organization
contains lower layer associations using the contribution of the concealed layer, and
there is no back association of the layers.
The articulation “back proliferation” depicts how this sort of neural association
is readied. Back causing is a kind of oversaw getting ready. While using a regulated
getting ready strategy, the association must be outﬁtted with both model sources of
info and predicted yields. The predicted crop yields are contemplated against the
information collected for the genuine crop yields. Using the predicted yields, the
back expansion getting ready ﬁguring by then takes a decided error and changes the
heaps of the various layers backward from the yield layer to the information layer.
The back engendering and feed forward ﬁguring’s are oftentimes used together;
regardless, this is by no means whatsoever, essential. It would be entirely sensible to

Role of the Procedures of Deep Learning for Higher …
751
make a neural association that uses the feed forward ﬁguring to choose its yield and
doesn’t use the back expansion planning count. Likewise, if you choose to make a
neural association that uses back spread getting ready strategies, you are not generally
limited to a feed forward computation to choose the yield of the neural association.
Disregarding the way that such cases are more surprising than the feed forward back
spread neural association [4].
2.4
Demeter System
Demeter system is controlled by speed paddling machine, furnished with a couple
of camcorders and a worldwide situating sensor for route. Demeter is equipped for
arranging collecting tasks for a whole ﬁeld, and afterward executing its arrange-
ment by cutting harvest columns, going to cut progressive lines, repositioning in the
ﬁeld by the machine itself, and recognizing startling deterrents. In August of 1997,
the Demeter framework self-sufﬁciently collected 100 sections of land of hay in a
constant run (barring stops for refueling). During 1998, the Demeter framework has
collected more than 120 sections of land of yield, cutting in both Sudan and horse
feed ﬁelds.
Agrarian reaping is an alluring territory for mechanization for a few reasons.
Human execution is a key constraint in the productivity of reaping: for example,
collectors have been planned which can work at higher paces than the current norm
of 4 miles 60 min, yet people experience difﬁculty managing the machines decisively
at these paces for extensive stretches of time. Moreover, the specialized impediments
to computerization are less denying than in numerous different territories: the speed
of gathering machines is low, snags are unprecedented, the climate is organized, and
the errand itself is amazingly tedious [32].
Demeter has two route frameworks, one camera-put together and one based with
respect to a global positioning system (GPS). There are a few reasons why the
utilization of two separate route frameworks is alluring. Every route framework has
a few exceptional points of interest: the camera framework can be utilized without
a from the earlier guide of the territory and can serve as a snag locator, while the
GPS framework is better at keeping situating mistakes from gathering inconclusively.
Furthermore, the two frameworks have very extraordinary disappointment modes,
thus most disappointments will leave at any rate one of the frameworks working
effectively. For instance, GPS is liable to multi-way issues and blocked satellites,
while the vision framework will in general experience difﬁculty with helpless lighting
conditions and inadequate harvest. As the route frameworks become all the more
ﬁrmly incorporated, later on, abusing the reciprocal idea of the two will give a critical
increment in by and large strength of the reaping activity [33].
The position-based route framework utilizes the posture information from the
machine regulator to direct the machine in the ﬁeld along arranged ways. The posture
information is combined from a differential GPS, wheel encoder (dead-retribution),
and gyro framework sensors. The camera framework for controlling the gatherer

752
A. Verma
Table 1 Comparison of the classiﬁers used for the different approaches of disease detection
CALEX
FARMSYS
ANN
Demeter system
Strength
Formulates the
guidelines of
scheduling for the
management of the
activities of the
harvested crop
Eliminates less
utilized farm
devices from the
farm
Predicts the yield
of the crop in an
efﬁcient and with
accuracy
Harvest the crop
up to the limit of
40 hectares
Weakness
Takes much time
Speciﬁc to the
location
Limited to the
weather only as a
factor for crop
yield
Expensive: fuel
used by the
technique is in
large amount
comprises three between subordinate modules: a yield line tracker, a ﬁnish of-line
locator, and a deterrent ﬁnder. The calculation for following the harvest line furnishes
the ﬁnish of-column locator with data describing the distinction among cut and
whole yield. The ﬁnish of-line indicator at that point demonstrations to compel
the preparation of harvest line tracker. All together for the observation modules to
accurately work, a picture pre-processor recognizes and rectiﬁes for picture twisting
brought about by shadows.
The accomplishment of the Demeter venture exhibits that monetarily practical
computerized gathering is actually achievable soon. Likewise, with most robotiza-
tion, power to disappointment and minimal effort will be the keys to moving the inno-
vation into the commercial center. By utilizing two correlative direction frameworks
made of parts accessible off-the-rack, we have made an enormous stride towards the
ideal of a really reasonable mechanized reaping machine.
3
Comparison of CALEX, FARMSYS, ANN and Demeter
System
The main objective of the study is to compare the classiﬁers which use the techniques
of AI, machine learning, and deep learning for plant disease detection using the
image classiﬁcation approaches. Table 1 shows the strengths and the weaknesses of
the classiﬁers used for the comparison.
4
Conclusion
Overall people are depended upon to show up at in excess of over nine billion by the
end of 2050 which requires an extension in agrarian creation approximately of 70% to
fulﬁll the intrigue. Pretty much 10% of the extended creation may begin from ground

Role of the Procedures of Deep Learning for Higher …
753
which is unused and using the current creation fortifying the rest can be fulﬁlled.
For this remarkable condition, the use of the latest mechanical responses to make
developing more successful remains one unprecedented need. Present frameworks
to uplift rustic creation require high fuel wellsprings of information and market
demands high bore food [34]. Advanced mechanics and self-sufﬁcient frameworks
(RAS) are set to change worldwide ventures.
The study describes the weaknesses and strengths of the four methods analyzed
in the paper. The CALEX classiﬁers formulates the guidelines of scheduling for
the management of the activities of the harvested crop and take more time for the
classiﬁcation process whereas FARMSYS is speciﬁc to the location. ANN predicts
the yield of the crop in an efﬁcient and with accuracy and Demeter system is much
more expensive.
These advances discussed in the paper have incredible sway on enormous areas of
the economy with generally low proﬁtability, for example, agro (food creation from
the ranch to the retail rack).
References
1. Papageorgiou, E. I., Markinos, A. T., & Gemtos, T. A. (2011). Fuzzy cognitive map based
approach for predicting yield in cotton crop production as a basis for decision support system
in precision agriculture application. Applied Soft Computing Journal, 11(4), 3643–3657.
2. Simonyan, K., & Zisserman, A. (2015). Very deep convolutional networks for large-scale
image recognition. In 3rd International conference on learning representations, ICLR 2015—
Conference Track Proceedings, (pp. 1–14).
3. Venugoban, K., & Ramanan, A. (2014). Image classiﬁcation of paddy ﬁeld insect pests using
gradient-based features. International Journal of Machine Learning and Computing, March
2015, 1–5.
4. Lurstwut, B., & Pornpanomchai, C. (2017). Image analysis based on color, shape and texture
for rice seed (Oryza sativa L.) germination evaluation. Agriculture and Natural Resources,
51(5), 383–389.
5. Anitha, P., & Chakravarthy, T. (2018). Agricultural crop yield prediction using artiﬁcial
neural network with feed forward algorithm. International Journal of Computer Sciences and
Engineering, 6(11), 178–181.
6. Plant, R. E. (1989). An artiﬁcial intelligence based method for scheduling crop management
actions. Agricultural Systems, 31(1), 127–155.
7. Xiao, M., Ma, Y., Feng, Z., Deng, Z., Hou, S., Shu, L., & Lu, Z. X. (2018). Rice blast recognition
based on principal component analysis and neural network. Computers and Electronics in
Agriculture, 154(April), 482–490.
8. Shrivastava, V. K., Pradhan, M. K., Minz, S., Thakur, M. P. (2019). Rice plant disease clas-
siﬁcation using transfer learning of deep convolution neural network. International Archives
of Photogrammetry Remote Sensing & Spatial. Information Sciences—ISPRS Archives, 42,
631–635.
9. Hanzlík, P., Kožíšek, F., & Pavlíˇcek, J. (2015). Design of intelligent decision support systems
in agriculture. International Journal of Mathematics and Computers in Simulation, 9(August
2018), 113–118.
10. Plant, R. E. (1989). An integrated expert decision support system for agricultural management.
Agricultural Systems, 29(1), 49–66.

754
A. Verma
11. Grandgirard, J., Poinsot, D., Krespi, L., Nénon, J. P., & Cortesero, A. M. (2002). Costs of
secondary parasitism in the facultative hyperparasitoid Pachycrepoideus dubius: Does host
size matter? Entomologia Experimentalis et Applicata, 103(3), 239–248.
12. Yang, C. C., Prasher, S. O., Landry, J. A., & Ramaswamy, H. S. (2003). Development of
a herbicide application map using artiﬁcial neural networks and fuzzy logic. Agricultural
Systems, 76(2), 561–574.
13. Rahman, C. R., Arko, P. S., Ali, M. E., Iqbal Khan, M. A., Apon, S. H., Nowrin, F., Wasif,
A. (2020). Identiﬁcation and recognition of rice diseases and pests using convolutional neural
networks, Bio systems Engineering, 194, 112–120.
14. Milosevic, N. (2020). Introduction to convolutional neural networks, Introduction to convolu-
tional neural networks, 1–31.
15. Plant, R. E., Horrocks, R. D., Grimes, D. W., & Zelinski, L. J. (1992). CALEX/Cotton: An
integrated expert system application for irrigation scheduling. Transactions of ASAE, 35(6),
1833–1838. https://doi.org/10.13031/2013.28803
16. Zhang, S., Li, X., Zong, M., Zhu, X., & Cheng, D. (2017). Learning k for kNN classiﬁcation.
ACM Transactions on Intelligent Systems and Technology, 8(3).
17. Yao, Q., te Chen, G., Wang, Z., Zhang, C., jun Yang, B., Tang, J. (2017). Automated detection
andidentiﬁcationofwhite-backedplanthoppersinpaddyﬁeldsusingimageprocessing. Journal
of Integrative Agriculture, 16 1547–1557.
18. Pinki, F. T., Khatun, N., & Islam, S. M. M. (2018). Content based paddy leaf disease recogni-
tion and remedy prediction using support vector machine. In 20th international conference of
computer and information technology, ICCIT 2017, 2018-January, (pp. 1–5).
19. Rautaray, S. S., Pandey, M., Gourisaria, M. K., & Sharma, R. (2020). Paddy crop disease
prediction—A transfer learning technique. International Journal of Recent Technology and
Engineering, 8(6), 1490–1495.
20. Singh, G., Mishra, A., & Sagar, D. (2013). 3 1,2,3, 1, 3–6.
21. Lal, H., Jones, J. W., Peart, R. M., & Shoup, W. D. (1992). FARMSYS-A whole-farm machinery
management decision support system. Agricultural Systems, 38(3), 257–273.
22. Lal, H., Jones, J. W., Peart, R. M., & Shoup, W. D (1992), January. “FARMSYS—A whole-
farm machinery management decision support system,” Agricultural. Systems, 38(3), 257–273.
https://doi.org/10.1016/0308-521X(92)90069-Z.
23. Phadikar, S. (2012). Classiﬁcation of rice leaf diseases based on morphological changes.
International Journal of Information and Electronics Engineering, 2(3), 460–463.
24. Naeem, M., Iqbal, M., Parveen, N., Abbas, Q., Rehman, A., & Sad, M. (2016). An over view
of bakanae disease of rice. & Environmental Science, 16(2), 270–277.
25. Patrício, D. I., & Rieder, R. (2018). Computer vision and artiﬁcial intelligence in precision
agriculture for grain crops: A systematic review. Computers and Electronics in Agriculture,
153(April), 69–81.
26. Murase, H. (2000). Artiﬁcial intelligence in agriculture. Computers and Electronics in
Agriculture, 29(1–2), 1–2.
27. Ji, B., Sun, Y., Yang, S., & Wan, J. (2007). Artiﬁcial neural networks for rice yield prediction
in mountainous regions. Journal of Agricultural Science, 145(3), 249–261.
28. Zhai, Z., Martínez, J. F., Beltran, V., & Martínez, N. L. (2020). Decision support systems for
agriculture 4.0: Survey and challenges. Computers and Electronics in Agriculture, 170(August
2019), 105256.
29. Saiz-Rubio, V., & Rovira-Más, F. (2020). From smart farming towards agriculture 5.0: A review
on crop data management. Agronomy, 10(2).
30. Mir, S., Qasim, M., Arfaty, Y., Mubarak, T., Bhat, A. Z., Bhat, J., Bangroo, S. A., & Soﬁ, T.
(2015). Decision support systems in a global agricultural perspective-a comprehensive review.
International Journal of Agriculture Sciences, 7(1), 403–415.
31. Dai, X., Huo, Z., & Wang, H. (2011). Simulation for response of crop yield to soil moisture
and salinity with artiﬁcial neural network. Field Crops Research, 121(3), 441–449.
32. Priyanka, T., Soni, P., & Malathy, C. (2019). Agricultural crop yield prediction using artiﬁcial
intelligence and satellite imagery Teresa. Eurasian Journal of Analytical Chemistry, 13(SP),
6–12.

Role of the Procedures of Deep Learning for Higher …
755
33. Song, H., & He, Y. (2005). Crop nutrition diagnosis expert system based on artiﬁcial
neural networks. In Proceedings—3rd international conference on information technology
and applications, ICITA 2005, I, (pp. 357–362).
34. Mukherjee, M., Pal, T., & Samanta, D. (2012). Damaged paddy leaf detection using image
processing. Journal of Global Research in Computer Science, 3(10), 2010–2013.
35. Ezziane, Z. (2006). Applications of artiﬁcial intelligence in bioinformatics: A review. Expert
Systems with Applications, 30(1), 2–10.
36. Patidar, S., Pandey, A., Shirish, B. A., & Sriram, A. (2020). Rice plant disease detection and
classiﬁcation using deep residual learning. In Communications in Computer and Information
Science, 1240 CCIS (pp. 278–293).
37. Prajapati, H. B., Shah, J. P., & Dabhi, V. K. (2017). Detection and classiﬁcation of rice plant
diseases. Intelligent Decision Technologies, 11(3), 357–373.
38. Rahman, C. R., Arko, P. S., Ali, M. E., Iqbal Khan, M. A., Apon, S. H., Nowrin, F., & Wasif,
A. (2020). Identiﬁcation and recognition of rice diseases and pests using convolutional neural
networks. Biosystems Engineering, 194(December), 112–120.
39. Rajmohan, R., Pajany, M., Rajesh, R., Raman, D. R., & Prabu, U. (2018). Smart paddy crop
disease identiﬁcation and management using deep convolution neural network and SVM
classiﬁer. International Journal of Pure and Applied Mathematics, 118(15 Special Issue),
255–264.
40. Ramesh, S., & Vydeki, D. (2020). Recognition and classiﬁcation of paddy leaf diseases using
optimized deep neural network with Jaya algorithm. Information Processing in Agriculture,
7(2), 249–260.
41. Shrivastava, V. K., Pradhan, M. K., Minz, S., & Thakur, M. P. (2019). Rice plant disease
classiﬁcationusingtransferlearningofdeepconvolutionneuralnetwork.InternationalArchives
of the Photogrammetry, Remote Sensing and Spatial Information Sciences—ISPRS Archives,
42(3/W6), 631–635.
42. Sladojevic, S., Arsenovic, M., Anderla, A., Culibrk, D., & Stefanovic, D. (2016). Deep neural
networks based recognition of plant diseases by leaf image classiﬁcation. Computational
Intelligence and Neuroscience, 2016.
43. Suresha, M., Shreekanth, K. N., & Thirumalesh, B. V. (2017). Recognition of diseases in paddy
leaves using knn classiﬁer. In 2017 2nd international conference for convergence in technology,
I2CT 2017-January, 663–666.
44. Verma, T., & Dubey, S. (2019). Fuzzy-ﬁltered neural network for rice disease diagnosis using
image analysis. International Journal of Innovative Technology and Exploring Engineering,
8(8 Special Issue 3), 437–446.
45. Yao, Q., Chen, G. te., Wang, Z., Zhang, C., Yang, B., jun., & Tang, J. (2017). Automated detec-
tion and identiﬁcation of white-backed planthoppers in paddy ﬁelds using image processing.
Journal of Integrative Agriculture, 16(7), 1547–1557.
46. Singh, A. K., & Raja, B. S. (2015). Classiﬁcation of rice disease using digital image processing
and Svm classiﬁer, International Journal of Electrical and Electronic Engineeing ISSN, 07,
294–299.
47. Pinki,F.T.,Khatun,N.,Islam,S.M.M.(2017)Contentbasedpaddyleafdiseaserecognitionand
remedy prediction using support vector machine. In 20th International Conference Computer
Information Technololy ICCIT. 2018-January (2018), 1–5.
48. Sethy, P. K., Negi, B., Barpanda, N. K., Behera, S. K., Rath, A. K. (2018) Measurement of
disease severity of rice crop using machine learning and computational intelligence, Springer
Briefs in Applied Sciences Technology, 1–11.

Retinal Encryption Using Snnipet Pixel
XOR with Huffman Sequential Encoding
for Privacy Augmentation
L. Poongothai, K. Sharmila, C. Shanthi, R. Devi, and R. Anitha
Abstract The escalated utilization of digital platforms in recent times using digital
platforms, web applications and multimedia ﬁles such as pictures, audio, and video
data have triggered the demand for faster mechanisms with resilient working method-
ologies. Unauthenticated breaches have become a common problem and therefore
require access audits frequently. To achieve impeccable security, encryption is a solu-
tion rendered for inimitable and mitigated infringement of data from unauthorized
users. The increase in Personal Health Records (PHR) and Electronic Health Records
(EHR) has been under constant scrutiny for their data breach. The previous indaga-
tion pertaining to encryption have been focused primarily on data to a large extent,
and although image encryption has entailed several features in the past, this paper
pivots on the encryption of an individual’s retina. This study is aimed at improving
security of biometric modalities taken from a patient for further diagnosis and protec-
tion in terms of standardized and lossless data protection. The methodology of retinal
encryption is thus implemented by using the fragmented compartment-based XOR
encryptionmethodalongwiththesequentialHuffmancodingmethod.Thesymmetric
key encryption method thus enhances the content concealment of the image for the
respective owner and their sub-assigned authorized users. The simulation for this
study is performed in MATLAB, and the results are successfully procured. MATLAB
and the results are procured successfully.
L. Poongothai (B)
Department of Computer Science, Dr. MGR Janaki College for Women, Chennai, India
K. Sharmila · C. Shanthi · R. Devi
Department of Computer Science, VISTAS, Chennai, India
e-mail: sharmila.scs@velsuniv.ac.in
C. Shanthi
e-mail: shanthi.scs@velsuniv.ac.in
R. Devi
e-mail: devi.scs@velsuniv.ac.in
R. Anitha
Department of Computer Science, S.T.E.T Women’s College (Autonomous), Sundarakkottai,
Mannargudi, Thiruvarur, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_59
757

758
L. Poongothai et al.
Keywords Neighborhood pixel analysis · Huffman encoding ·
Exclusive-OR(XOR) · Fundus image · Encryption · Decryption
1
Introduction
Encryption has garnered a lot of ﬂake in recent times, this is extensively due to the
high number of privacy breaches and data pilferages that have eroded the security
mechanisms to a great extent. Image encryption is a domain in which the cognizance
of information security with algorithmic protection of digital images has been intro-
duced. The intrinsic features of images along with its various characteristics pose
structural changes of images to that of text. The complexity associated with the tradi-
tional encryption methods has been quite elaborate and has been used as vulnerabil-
ities to breach gargantuan data globally. Image Encryption is a panacea for personal
health record protection and is widely used as a technique to cipher an image through
random generation of secret accesses. Many image encryption algorithms are selec-
tive and work speciﬁcally for a segmented portion of an image, however, it is impor-
tant that the chosen protection method satisﬁes the general rubrics for encryption.
The purpose of simulation the selective encryption method is to compress the entailed
chosen data for encryption while ensuring the protection of the certain degree that
may be mandated. However, the problem with selective encryption modes are its
scope of performance and data privation. The exploration of various technological
advancements in the ﬁeld of medicine and modern analysis has played a prominent
role in the various diagnostic modes of treatment for medically detrimental indi-
viduals. Nonetheless, with the various boons of technical upliftment, the cons such
as unauthorized data access, and vulnerable digital content with respect to patient
details and records seem to be precariously unsafe [1]. In order to maintain privacy
and hold databases to be non-vulnerable, cryptography is used more frequently to
metamorphosethepixeleddatausingvariousencryptionmethods.AdvancedEncryp-
tion Standard (AES), Data Encryption Standard (DES), Rivest, Shamir and Adleman
(RSA) [2] are a few commonly used algorithmic approaches that may be intricate in
computing, as well as in hardware execution. Since networking is more often used,
the channeling of digital pixeled data over web applications has created multifar-
ious risks. Nevertheless, due to the transparent apportion of networks, the reliability
of the graphical and other digital data is compromised during transmission. While
this communication has become a quotidian lifestyle in individualistic and corporate
world, the resilience and robustness toward ruptures and malicious content are neces-
sitated to be augmented. Pixels of images and graphical data involving secret codes
from army or security ﬁrms should be proffered with the appropriate encryption
algorithm and image stitching techniques. Encryption is thus entailed as a method
of obligatory would like in various ﬁelds like social media, life science, and military
scope of use, however, each image to be communicated or digitally transferred into

Retinal Encryption Using Snnipet Pixel XOR with Huffman …
759
chunks, encrypted, and sent to the receiver. Thereby effectuating the pixeled infor-
mation to be burdensome for the trespassers to ingress and procure the ﬁrst image [3,
4]. The encryption methods and algorithms vary from simple spatial domain tech-
niques to additional complicated and reliable frequency domains. Although there
have been are many challenges regarding the privation of content during encryption,
uniform globality, customized application of algorithms along with their scalability,
this work discusses the potential mode of encrypting the biometric modality in an
efﬁcacious manner. The paper is structured with Sect. 2 exposition the prevailing
methodology, the projected study is explicated in Sects. 3 and 4 delineates on the
results, and therefore the ﬁnal section provides a compendium of the work with the
longer term implementation to be done.
2
Existing Methodology
This section pivots on the various empirical studies by various researchers in the
domain of image encryption. The pixeled encryption approach relies largely on the
chaotic representation of connecting pixels together and is explored through many
simulation methods. Image encryption is perceived as a pixel value-metamorphosis
method. Swifter transmission methods and algorithmic approaches have been initi-
ated with the purpose of contriving non-lagged and protected modes of operation.
Nonetheless, most users prefer encryption-based algorithmic methods that deﬁne the
security of images in a more appropriate manner from unauthorized hackers. The
crypting mechanism makes the pixeled data to be loaded and read to a relatively
increased degree of complexity [5]. Hence, the possibility of man-in-the-middle
attack,hackeroreavesdroppertoprocuretheoriginalcontent,andmisusethecommu-
nication channeling is likely near to impossible. Thus, the end-to-end transmission
of the graphical content over the network is more secure by encrypting the images
[6, 7]. The Ceaser cipher or Vigenere cipher techniques are the most conventional
modes of crypting, but when considering the encryption of images, they are less
adequately used. A more appropriate procedure of encryption relative to images is,
therefore, best suited with the Blowﬁsh algorithm, randomized connectivity through
Chaoticmaps and Genetic algorithms [8].
Sakthidasan et al. delineated a novel method of encrypting images which detailed
the use of three dynamic chaotic models that helped a user to edit the pixel positions.
The three methods were Lorenz, Chen, and LU chaotic system, which was singularly
utilized to generate randomness of encryption in the pixels and to obtain the encrypted
image. This randomness initiated the challenge of unauthorized access to obtain the
original content with facileness and established protection [2].
Fu et al. elaborated on a symmetric color image encryption methodology with
permutation-diffusion framework. The three-color element of images are mingled
with the Arnold cat map in the initial phase of permutation in order to mitigate the
axial relationship between adjacent pixels [9].

760
L. Poongothai et al.
Manoj and Manjula et al. [3] emphasized a technique during which the pixeled
information of a graphical object is placed into the AES secret writing to accumulate
the encrypted image. The output of secret writing therefore obtained is employed
as input to AES decipherment to retrack, and decipher the encrypted image to the
initial image. This paper used a twelve8-bit AES for image secret writing and deci-
pherment that was then synthesized and simulated on the FPGA family of Spartan-6
(XC6SLX25) victimization Xilinx ISE 12.4 tool in terribly high-speed computer
circuit Hardware Description Language (VHDL).
Younes et al. [4] introduced a block-based transformation algorithmic rule victim-
ization the mixture of image transformation and a widely known secret writing and
decipherment algorithmic rule particularly Blowﬁsh.
Reddy et al. [10] explicated the close study of RSA and NTRU (“non trivial
ring units” or “nth-degree truncated polynomial ring units” or “Number Theory
Research Units”) algorithms for graphical objects as input. The simulation outcome
was evaluated and compared to agnize the appropriate model best suited for corporate
architectural working.
The transfer of data and images through network will cause a problem of security.
The problem of size by transferring the data and the image through network is also
found. Also if the size increases then the efﬁciency of the network will decrease.
The previous indagation pertaining to encryption has been focused primarily on data
to a large extent, and although image encryption has entailed several features in the
past, this paper pivots on the encryption of an individual’s retina and also to increase
efﬁciency of the existing system. By using this method the ﬁnal image obtained at
the receiver end will be secure compared to previous methods like sending through
plain format and also increase security and pixel edge protection in the image after
encryption. ˙In this work, XOR is combined with Huffman is used to increase security.
3
Proposed Method
For the purpose of exploring the crypted mechanism of operation on digital images,
the initial process is to scrutinize the simulation disparities between image and text
data [5]. The text data is encrypted keeping in mind the length of the data while
metamorphosing, wherein the process of decryption must hold the full length of the
data without any loss of content. However, this form of encryption is challenging
with large amount of data involved. The mode of crypting images does not entail this
criterion as well. The cipher pixels can be encrypted and decrypted with a few pixels
that can be added or subtracted while holding a similar amount of data as compared
to the original image. Most commonly, the pixels are represented in a 2D array. While
focusing on the data storage of images, the data storage repository may have to be
large, therefore image compression is considered as a potent remedy that parallelly

Retinal Encryption Using Snnipet Pixel XOR with Huffman …
761
Fig. 1 Proposed methodology
reduces the storage space and the transmission time [5]. This paper ensures the
encryption of the image using snippet-pixel XOR with the Huffman encode-decode
of the secret key is explicitly implemented. The below diagram clearly delineates the
proposed technique used (Fig. 1).
The snippet-pixel XOR technique acts as a non-volatile mode of image encryp-
tion [18]. The XOR operation is quite easily implemented. However, the mode of
segmenting the image is quite complex. This study incorporates the 3 × 3 snippet-
pixel encryption mode to perform the full encryption of the image. The key generation
is implemented by bit amalgamation of the randomized probabilistic occurrences of
the values from the biometric modality used. The code dictionary of the Huffman
encoding mechanism distinctly aligns with an N-by-2 cell array, with the original
signal wave converted to a binary form. The initial column holds the possible repre-
sentations, and the second column holds the possible permutations of the encoding
signal wave.
3.1
Exclusive-OR (XOR)
Table 1 shows how the XOR operation transforms individual bits. Let A be a bit
from the plain text message, and B be a bit from the key. The ⊕column shows the
resulting bit.
If A wants to transmit a secret message to B, it uses the message’s bit sequence
(the plain text) and a bit sequence known only to A and B—the key. To encrypt,
A uses XOR to mix the plain text with the key bit by bit. A and B must utilize a
unique set of secret, randomly generated bits for each message they exchange. A
and B share a signiﬁcantly smaller amount of secret bits in a stream cypher and
utilize them to produce a long, difﬁcult-to-guess sequence of bits. A cryptographic
procedure is used by the stream cypher to construct that long sequence from a small,
shared secret. This generated sequence is then merged with the message using XOR.
Table 1 Shows how the
XOR operation transforms
individual bits
A
B
⊕
0
0
0
0
1
1
1
0
1
1
1
0

762
L. Poongothai et al.
3.2
Algorithm
1.
Analyze images in wavelet interactive tool.
2.
Perform the preprocessing for denoising, and true color dimensional equality
for enhanced compression mechanism to be implemented.
3.
Level-wise thresholding with sym wavelet with cascading global thresholding
combined with Huffman coding is implemented for enhanced results.
Symlet Wavelets: symN.
The symN wavelets are also known as Daubechies’ least-asymmetric wavelets.
The symlets are more symmetric than the extremal phase wavelets. In symN,
N is the number of vanishing moments. These ﬁlters are also referred to in the
literature by the number of ﬁlter taps, which is 2 N.
4.
The GBL_MMC_H global Compression with the Bit-Per-Pixel ratio set to 0.51
is chosen.
5.
Once the image is compressed, perform key generation using bit-level XOR
method and to perform pixel-wise compression, and key generation is effectu-
ated.
6.
The decryption adopts the reverse method.
4
Simulation Results
The simulation results in MATLAB are illustrated below. The true color image of
the biometric retinal modality obtained from fundus photography is used for the
encryption process. This study is more apt for ensuring the privacy of the patients
enrolled for any diagnosis or research study is protected according to the framed
ethical rubrics. The below ﬁgure is the stepwise procedure executed in the MATLAB
GUI environment (Figs. 2, 3, 4, 5 and 6).
The retinal modality taken for this study is a true color image of 558 × 481 sized,
unit 8 class image with a bit depth of 24 indicating the possible range of colors the
image holds. The original retinal image is encoded through randomized pixel values

Retinal Encryption Using Snnipet Pixel XOR with Huffman …
763
Fig. 2 Wavelet interactive Tool
Fig. 3 Preprocessing
that are XOR’ed to generate an encrypted image (Randomized pixel values ⊕Secret
key). The same procedure is followed where the reverse is executed to decode the
encryption done on the image.

764
L. Poongothai et al.
Fig. 4 GBL_MMC_H global Compression
5
Conclusion and Future Work
In this work, the design and implementation of an encryption algorithm that provides
both high security and performance were presented. This study has helped in stim-
ulating and augmenting the protection mechanism for images. This is speciﬁcally
analogized keeping in mind the ethical framework which is most of the time breached
by intermediaries. This indagation has helped in potentially dissecting the combi-
nation of secret key and Huffman coding for patients to conveniently encrypt
and decrypt their modality images before transmitting them over a network. This

Retinal Encryption Using Snnipet Pixel XOR with Huffman …
765
Fig. 5 Procured simulation
symmetric key encryption mechanism also renders better performance in terms of
security and helps users to execute this technique with relative ease. The future work
for this study is to incorporate the use of Afﬁne transform along with RGB pixel
transformation and shufﬂing technique. This could help in higher level of encryption
when a user opts to encrypt a true color image of varying red, green and blue pixels,
potentially mitigating the vulnerability exposures that may crop in while the binary
wave is chosen in the Huffman encryption method.

766
L. Poongothai et al.
 
Fig. 6 Key generation for encryption
References
1. Dai, Y., & Wang, X. (2012). Medical image encryption based on a composition of logistic
maps and chebyshev maps. In Proccedings of International Conference on Information and
Automation (lClA) (pp. 210–214).
2. Stallings, W. (2003). Cryptography and network security (3rd ed.). Prentice Hall.
3. Manoj, B., & Harihar M. N. (2012, June). Image encryption and decryption using AES. Inter-
national Journal of Engineering and Advanced Technology (IJEAT) ISSN, 1(5), 2249–8958.
4. Sinha, A., & Singh, K. (2003). A technique for image encryption using digital signature. Optics
Communications, 218(4–6), 229–234.
5. Amalarethinam, D. I. G. (2015). Image encryption and decryption in public key cryptography
based on MR. International Conference on Computing and Communications Technologies
(ICCCT’15).
6. Reddy, C. S., Sowjanya, C., Praveena, P., & Symmetric, P. S. L. P. A. Key algorithm using
randomized prime numbers. International Journal of Scientiﬁc and Research Publications.
7. Stallings, W. (2017). Cryptography and network security. In Principles and Practice (pp. 92–
95). Upper Saddle River.
8. Rogers, A., & Loly, P. (2004, November). The inertial properties of squares and cubes (pp. 1–3).
9. Schneier, B. (2007). Applied cryptography: Protocols, algorithms, and source code in C. In
Wiley; Stamp, M. (2011). Information security: Principles and practice. Wiley

Retinal Encryption Using Snnipet Pixel XOR with Huffman …
767
10. Reddy, N., Nayak, R., & Baboo, S. (2012, August). Analysis and performance characteristics
of cryptosystem using image ﬁles. International Journal of Computer Applications, 51(22),
0975–8887.
11. Pﬂeeger, C. P., & Pﬂeeger, S. L. (2002). Security in computing. In Prentice hall professional
technical reference 6. Kahate, A. (2013). Cryptography and network security. Tata McGraw-
Hill Education.
12. Karim, M. Z., & Akter, N. (2011, October). Optimum Partition Parameter of Divide-And-
Conquer Algorithm for solving closestPairProblem. International Journal of Computer Science
& Information Technology (IJCSIT), 3(5).
13. Schenier, B. (1996). Applied cryptography. John Wiley & Sons Inc.
14. Singh, A., & Dhanda, N. (2015, March–April). DIP using image encryption and XOR operation
afﬁne transform. IOSR Journal of Computer Engineering (IOSR-JCE), 17(2), 07–15. e-ISSN:
2278–0661.

Automatic Text Summarization Using
Deep Learning and Reinforcement
Learning
Jency Thomas, Amrutha Sreeraj, Ayswarya Sreeraj, Megha Mary Varghese,
and Thomas Kuriakose
Abstract Choosing relevant information from a giant source of data available online
is a difﬁcult and challenging task. Automatic summarization can address this chal-
lenge. Summarization is the task of condensing a chunk of text to a shorter version,
which reduces the size of the initial text and simultaneously preserves the meaning
of content. This model proposes automatic text summarization based on the rein-
forcement learning method and uses a deep learning network to estimate Q value.
Here, we use rouge to analyze the performance of our model. ROUGE is used for
evaluating automatic text summarization. The three phases of the project are text
processing, text formation, and text evaluation. In text processing, select a set of
sentences using latent semantic analysis and form a summary using reinforcement
and deep Q network. And then, the summary is evaluated using rouge.
Keywords Reinforcement learning · Deep learning network · Latent semantic
analysis · Rouge
1
Introduction
In this new era, where tremendous data is obtainable on the net, it is most important
to supply the improved mechanism to extract the information quickly and most with
efﬁciency. It is troublesome for people, in general, to manually extract the summary
of an outsized document of text. So automatic text summarization is required.
Types of summaries can be user-focused, topic-focused, or query-focused, i.e.,
matter of summary should match to a particular user or group of users, or else,
they could be generic. Currently, many models have been made for both abstractive
summarization and extractive summarization approaches. Extractive summarization
approaches try to choose keywords, sentences, or paragraphs from source documents,
J. Thomas · A. Sreeraj (B) · A. Sreeraj · M. M. Varghese · T. Kuriakose
Department of Computer Science and Engineering, Muthoot Institute of Technology and Science,
varikoli, puthencruz p.o, Kochi 682308, India
J. Thomas
e-mail: jencythomas@mgits.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_60
769

770
J. Thomas et al.
whereas abstractive approaches try to summarize the overall contents of the docu-
ments to provide a meaningful summary. They can take the form of an extract, i.e., an
abstract or a summary consisting fully of the same material but not all copied from
the input. Impressed by extractive summarization approaches based on traditional
reinforcement learning and deep neural networks, we develop a deep reinforcement
learning framework for extractive summarization tasks by using a deep Q Network
(DQN).
Our project consists of three phases:
• Text processing: This phase will initially preprocess the actual document and
apply latent semantic analysis to select a set of sentences.
• Text formation or summarization: And also will apply reinforcement learning and
DQN for text summarization.
• Text Evaluation: We evaluate the summary obtained using rouge.
The text to be summarized is given as input to the system. The LSA module
would create an extractive summary of the input and is taken as the partial summary.
Partial summary is then passed to the input layer of the deep Q Network. The human
reference summary is also given as the input to DQN. We implement rouge algorithm
to evaluate the partial summary in comparison with the human reference summary
as it gets modiﬁed, and reward is calculated based on the rouge output.
2
Literature Survey
Kherwa and Bansal [1] conducted a study using latent semantic analysis to ﬁnd the
correlation of terms in a data set consisting of research papers of various applica-
tions of natural language processing. They employed singular value decomposition,
which has been employed in a variety of ﬁelds such as information retrieval, natural
language processing, and so on. This experiment shows the power of latent semantic
analysis, and they have compared the results with simple vector space of terms and
documents. They concluded that a latent semantic algorithm with optimal number of
dimension reduction using singular value decomposition provides us query results
that are semantically correlated in a corpus.
Gong and Liu [2] proposed two text summarization techniques. The ﬁrst method
is ‘relevance measure’ that ranks sentence relevance, while the second method uses
the LSA method that identiﬁes the semantic relationship between terms and docu-
ments. The author described sentence selection algorithms for summarization in this
article. For experimental testing, a two-month database of CNN Worldview news
programs was developed, and the effectiveness of the two summaries was tested
by comparing machine-generated summaries with manual summaries made by three
independent users. Despite the fact that the two summarizers had completely different
methodologies, their performance scores were extremely similar.
Christian et al. [3] described an automated text summary developed with the TF-
IDF algorithm and compared it to various other online sources of automatic text

Automatic Text Summarization Using Deep Learning …
771
summarizer. This approach follows extractive summarization. This paper explains
about different steps involved in summarization using this approach the F-Measure
as the standard comparison value was used. The results of this study produce 67%
accuracy with samples of the top three data compared to other online summaries.
Serve them to produce better summary results than any other online summary.
Lin [4] discusses the rouge evaluation approach and how to calculate it. It calcu-
lates the recall value based on the overlapping between the reference summary and
candidate summary The paper also explains multiple references and the evalua-
tion method. Rouge-W (Weighted Longest Common Subsequence): It considers the
spatial relations in the strings. Rouge-L (Longest Common Subsequence) another
kind of matrix available in the rouge package is explained, and it is used as a string
matching algorithm. Automatic evaluation approaches like rouge and BLEU has been
compared [5]. To validate the approaches, they used manual evaluation approach.
The recall approach in rouge is preferred more than the precision approach in BLEU.
Saziyabegum and Sajja [6] also did some research on ways to evaluate summa-
rization techniques. It is also difﬁcult to analyze automatic summaries. The chal-
lenges of summarizing are also explained. Summary test methods—Both internal
and external: are described in detail. This paper concludes with some suggestions
for future indicators for summary analysis.
Esmaeilzadeh and Peh [7] investigated abstractive text summarization using
a variety of models, including LSTM-encoder-decoder with attention, pointer-
generator networks, coverage techniques, and transformers, before using their text
summarization model as a feature extractor in a false news detection job.
In this work, they mainly focused on abstractive text summarization which is
considered to be a more robust approach compared to extractive summarization and
focused in exploring recent advancements in the natural language models. In this
work, they not only summarize the document which is given as input in which the
output is a combination of a few sentences that summarize the entire document which
is actually meaningful but also they use the summarization model as a feature building
module for fake news detection and news headlines. Rouge is used as the evaluation
metric which compares the system summary against a reference. Precision and recall
would be calculated to evaluate the summarized text.
Manning and Hewitt [8] conducted a study using self-supervised learning to ﬁnd
the correlation of terms in a dataset consisting of research papers of various natural
language processing applications. They conducted their survey on self-supervised
artiﬁcial neural networks like BERT and many other language model. They studied
large artiﬁcial neural networks which are trained through self-supervision in which
the model tries to ﬁnd an unknown word in a given context by prediction.
They have demonstrated that modern deep contextual language models learn
major aspects of human language hierarchical structure without any direct super-
vision. They have also demonstrated BERT (Bidirectional Encoder Representations
from Transformers) which is a self-supervised artiﬁcial neural network on word
prediction tasks (Tables 1, 2, 3, and 4).

772
J. Thomas et al.
Table 1 Comparison of literature survey
Method
Category
Dataset
Advantages
Disadvantages
Accuracy
(%)
Latent
semantic
analysis
Text
summarization
Articles
related to
applications
of NLP
Easy to
implement and
helps to ﬁnd
relationships
between terms
It cannot
handle words
with many
multiple
meanings
effectively
70
Tf-IDF
Text
summarization
Three
different
documents
are used and
these are
descriptive
text
powerful method
to understand
how important
the word is.
Better summary
produced than
online
summarizers
Query-based
sentences
Not much
accurate
Very slow for
large
vocabularies
Redundancy in
summary
67
Rouge
Text evaluation
DUC 2001,
2002, 2003
ROUGE-2,
ROUGE-L,
ROUGE-W, and
ROUGE-S
works well in
single-document
summarization
tasks
ROUGE-1,
ROUGE-L,
ROUGE-W,
ROUGE-SU4,
and
ROUGE-SU9
is good for
evaluating
short
summaries
–
Abstractive
summarization
Text
summarization
It generates new
text which is
meaningful
(more human)
and not verbose
Abstractive
summarization
is difﬁcult to
implement
–
Table 2 Term-document
matrix
Terms
Document/Sentences
1
2
3
Cat
1
1
0
Child
1
1
1
Garden
0
1
1
Took
0
1
0
Talk
1
0
0
Went
0
0
1

Automatic Text Summarization Using Deep Learning …
773
Table 3 Term frequency
matrix
Terms
Document/Sentences
1
2
3
Cat
1.584963
1.584963
0.000000
Child
1.000000
1.000000
1.000000
Garden
0.000000
1.584963
1.584963
Took
0.000000
2.584963
0.000000
Walk
2.584963
0.000000
0.000000
Went
0.000000
0.000000
2.584963
Table 4 VT matrix
Concepts
Sentences
1
2
3
1
0.460
0.707
0.536
2
−0.758
0.037
0.651
3
Design
3.1
Architecture
Automatic text summarization is a system that converts a large piece of text or
document into smaller versions by retaining the meaning of the original text. In
this work, we apply the deep Q Networks (DQN)-based model to automatic text
summarization tasks as shown in Fig. 1. In the case of a summary of a text, the
state means an incomplete partial summary that can be completed and the action
means the addition or deletion of a sentence from this summary. By using the RL
method in summarizing the text, two parameters should be predeﬁned. The length
of the summary is one parameter. The other parameter is the reward for the partial
summary. The reward is calculated by the evaluation of the current state (partial
summary). Rouge is a package used to compare the machine-generated summary
with that of the reference summary, and it calculates the accuracy (score).
Fig. 1 Architecture

774
J. Thomas et al.
3.2
Latent Semantic Analysis
Text processing is the ﬁrst stage of the project. In this, we apply latent semantic
analysis for selecting a set of sentences. Before applying LSA, we have to preprocess
the corpus for removing unwanted words from the actual document.
The different processing steps are:
• Tokenization: Tokenization is the process of dividing documents into tokens or
terms. For example, consider the sentence, ‘Hello World.’ This word results in
two tokens, Hello world.
• Stop word removal: Stop words are words like prepositions, conjunctions, articles
like a, an, the, when, but, etc. These words are removed from the document.
• Stemming: Process of reducing a term to its root word. For example, words like
’retrieved, ’,’retrieves’ can be reduced to the word ’retrieve.’
Consider the the below text as input:
‘The child walked the cat. The child took the cat to the garden. The child went to
the garden.’
It consists of 3 sentences and 19 terms initially. Now preprocess the document.
The main terms obtained are cat, child, garden, took, walk, and went.
After the pre-processing stage, we apply LSA. The latent semantic analysis ﬁnds
hidden relationships in documents for better understanding the relationship between
terms (each word in the document) and documents in the data set. LSA follows three
main steps. Each step is discussed with the above example.
1.
Create a term-document matrix in which each row stands for a keyword or term
and column represents the document or sentences in which the keyword appears.
Each cell in the matrix represents how many times a particular term occured in
that document or sentence.
2.
Convert the term frequencies in a term-document matrix using TF-IDF (Term
Frequency-Inverse Document Frequency) weighting schema. It tells how signif-
icant a term is to a document in its corpus. This stage is applied to each and
every cell in the matrix. This step helps to reduce the impact of the most
commonly used words. Term frequency (TF) and inverse document frequency
(IDF) combined together is known as TF-IDF.
Wi j = tfi j ∗idfi
where tfij is term frequency and idfi is the inverse document frequency of term i.
TF(i) = (Number of times term t appears in a document j)/(Total number of terms
in the document)
idfi = log2(N/dfi)

Automatic Text Summarization Using Deep Learning …
775
where N is the total number of sentences or documents and dfi is document frequency
of term i.
3.
Do singular value decomposition (SVD) on the matrix obtained. It decomposes
the matrix ‘C’ into orthogonal elements representing both types and texts. It
can be represented as:
C = UV T
where in C is an m × n matrix, U is an (m × r) orthonormal matrix (left singular
vector), isan(m ×n)non-negativediagonalmatrix,andV isan(r ×n)orthonormal
matrix. r is the rank of the matrix and it should be less than or equal to min (m, n).
It reduces the dimensionality of the term frequency matrix obtained. The main
aim in text processing is to select a set of statements. Therefore, we apply sentence
selection algorithms proposed by Gong and Liu [2] in the matrix obtained from SVD.
For sentence selection, the Gong Liu summarization algorithm uses a V T matrix. The
rows and columns of the V T matrix denote concepts got from SVD and sentences of
the input matrix, respectively. The ﬁrst row displays the most important concept or
term, and the order of the row reﬂects the importance of the concepts. The cells of
this matrix provide details of how a sentence relates to a given concept. The sentence
that is more related to the concept will be having higher cell value.
Consider r = 2.
In the Gong Liu summarization algorithm, the ﬁrst concept is selected, selecting
a sentence that is most closely related to that concept. After that the second concept
is chosen, and the same step is taken. This repetition of choosing a concept and the
sentence that is closely related to that concept is carried on until a predetermined
number of sentences are extracted. The sentences obtained from this are provided to
the deep Q Network.
From the above table, it is clear that sentence two has the highest value, and
therefore, it gets extracted.
Output: The child took the cat to the garden.
3.3
Deep Q Network
Deep Q networks can solve problems from wide scenarios by combining reinforce-
ment learning and deep neural networks. The process of deep Q-Learning creates an
optimal policy in which the working agent tries to maximize the reward in the long
run. Q-Learning is calculating the Q value for deciding an action in a state under the
policy function.
Q-Learning depends on a Q-function. The Q network is based on a policy function
based on which the system measures the expected reward or value of the discount
factor obtained from the state by taking action at ﬁrst and modifying the policy
function. We deﬁne the optimal Q-function as the policy function in which all the

776
J. Thomas et al.
Fig. 2 Deep Q network
states have the maximum return and taking action and following the optimal policy
then. Q value or q factor is a measure to evaluate the summary. As inputs, i.e., the
nodes in the layer of deep learning will contain the keywords, which are extracted at
the preprocessing phase.
As shown in Fig. 2, the partial summary (state) and the human summary are
provided as the inputs to the DQN with random weights. Compare the two summaries
using rouge and based on the rouge value calculate the reward. Executing a series
of actions will result in the maximum total reward. The Q value of a particular state
refers to the sum of reward obtained by taking an action in that state and the Q value
of the obtained state.
Q(s, a) = r(s, a) +  max Q

s′, a

Q(s, a) →Q(s′, a) + Q

s′′, a

. . . ′′Q

S′′..n, a

3.4
Rouge
Rouge recall oriented understudy for gisting evaluation is an evaluation method
which is used to compare the summary against the human summary.
Rouge-N. It calculates the number of parallel ‘n-grams’ between our model-
generated summary and a human summary, n-gram means grouping of words. A 1-g
(unigram) would consist of a single word, whereas 2-g (bigram) would consist of 2
consecutive words. Similarly, 3-g (trigram) would consist of 3 consecutive words.
AfterdecidingwhichN touse—thenextstepistocalculaterougerecallandprecision.
Rouge uses the method of recall to decide how accurate the candidate summary is
when evaluated against a human or reference summary. The recall in rouge gives us a
measure of how much part of the human generated summary is the system summary
covering.
Recall = No: of n-grams found in model/No: of n-grams in reference.
A system summary may be very long if it captures all words from a human gener-
ated summary. If so, many of the words in the system summary would be pointless,
and it results in making the summary unnecessarily long and wordy. Precision metric

Automatic Text Summarization Using Deep Learning …
777
can be used to avoid this. In terms of precision, we will be able to know how much
of the system summary is admissible or required.
Precision = No: of n-grams found in model and reference/No: of n-grams in
model.
The output of the LSA will be given to the Q network, and corresponding Q
values are obtained. Using the rouge algorithm, we will be deﬁning the threshold
value. Further summarization is not required when our system reaches this threshold
value. Rouge automatically measures the summary by comparing it to a reference
summary based on n-grams.
Rouge = No. of Overlapping Words/Total No. of words.
In reference summary rouge is very interpretable. A good candidate translation
will only use recall for the evaluation purpose. And for comparing, it is always better
to use one of the possible reference summaries from the reference pool.
4
Experiment
4.1
Dataset
Dataset required is obtained from Kaggle and is used in the training process of the
deep Q network. The dataset obtained contains 4450 ﬁles which include the news arti-
cles and their extractive summaries. Dataset genre includes business, entertainment,
sports, politics, and tech. 70% of the dataset has been used for training purposes, and
the rest has been taken for testing and validation.
5
Discussion and Conclusion
Existing models for text summarization are not very accurate and also there is a
possibility to occur the same sentences multiple times. Compared with other classi-
ﬁer models, our text summarization approach is based on reinforcement learning and
deep Q networks. The growing growth of the Internet has made a huge amount of
information available. It is troublesome for humans to summarize giant amounts of
text. So automatic text summarization is necessary. There are various ways of summa-
rizing the text. In this study, we attempt to train Q network effectively using deep Q
network for developing an automatic document summarizer based on reinforcement
learning. Rouge can be used to evaluate the accuracy of the summarized text in which
a document is given as input. The real-world applications of text summarization
can be document summarization, news and articles summarization, review systems,
recommendation systems, social media monitoring, survey responses systems. The
summarization model will help a large community of people to determine essential
ideas and consolidate essential details. It also helps in focusing on crucial topics

778
J. Thomas et al.
and words worth noticing and remembering in a paper. The model contains research
papers on artiﬁcial text summarization and diverse language methods. Our model
promises to summarize the text even if it only uses simple features.
References
1. Kherwa, P., & Bensal, P. (2017). Latent semantic analysis: An approach to understand semantic
of text. In IEEE conference publication (pp. 870–874).
2. Gong, Y., & Liu, X. (2001). Generic text summarization using relevance measure and latent
semantic analysis. In SIGIR conference on research and development in ınformation retrieval.
3. Christian, H., et al. (2016, December). Single document automatic text summarization using
term frequency-ınverse document frequency (TF-IDF). ComTech: Com-puter, Mathematics and
Engineering Applications, 7.
4. Lin, C. Y. (2004). ROUGE: A package for automatic evaluation of summaries.
5. Nenkova, A. (2006). Summarization evaluation for text and speech: Issues and approaches.
6. Liu, F. L., Yang (2008). Correlation between ROUGE and human evaluation of extractivemeet-
ingsummaries, pp. 201–204. https://doi.org/10.3115/1557690.1557747
7. Anand, D., & Wagh, R. (2018). Effective deep learning approaches for summarization of legal
texts. Journal of King Saud University—Computer and Information Sciences.
8. Esmaeilzadeh, S., & Peh, G. X. (2020). Neural abstractive text summarization and fake news
detection. IEEE.

An Analysis and Application of HRMS
Tools in Industries
M. R Dileep, A. V Navaneeth, B. M Chaitra, and Ajit Danti
Abstract HRMS tools are the application that helps any organization to set up an
environment that helps them to easily view their employees, their activities, and
other work-related jobs. This application is available to everyone where a user can
register into the application with the required details and access to the credentials.
The admin then can add the employees of their organization and give them roles and
responsibilities. The admin can also give updated responsibilities to HR who can then
make the required changes. The HR is responsible for recruiting the employees and
also he can add upon the employees into the organization. The employees can look
up their inbox, dashboard, recruit, personal details on the application. They can also
get a help and support system which they can contact if there are any requirements.
They can edit their proﬁle anytime, can search for any requirements, and can get news
feed from the organization. These are some of the functionalities of the application.
Apart from that they can also view their salary slips, can apply for a leave application,
and so on. With the advancement in the development of computers, HRMS tools are
developed in such a way that humans can interact with it. The recent developments in
the ﬁeld of computer science especially in the ﬁeld of Artiﬁcial Intelligence(AI) have
opened wide doors for the development of efﬁcient HRMS tools thereby reducing
human efforts. In this paper, an analysis has been made between the HRMS tools
developed with AI and HRMS tools without AI and based on the suitability the
applications of these HRMS tools are drawn.
Keywords Artiﬁcial intelligence · Feature engineering · MongoDB · Sybase ·
Navigation
M. R. Dileep · A. V. Navaneeth (B) · B. M. Chaitra
Master of Computer Applications, Nitte Meenakshi Institute of Technology, Yelahanka,
Bengaluru, Karnataka, India
A. Danti
Department of Computer Science and Engineering, Christ Deemed to be University, Bengaluru,
India
e-mail: ajit.danti@christuniversity.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_61
779

780
M. R. Dileep et al.
1
Introduction
HRMS is an application that makes the organization ﬂow easy. This gives the admin
and HR to easily monitor the work of the employees. Also, the employees can check
their status, can view or edit their proﬁles, can look upon other fellow mates, can
apply for a leave application, and can look upon their salary slips, and so on. Since an
organization is a body of people, their acquisition, development of skills, motivation
for higher levels of attainment, as well as ensuring maintenance of their level of
commitment is all signiﬁcant activities. These activities fall under the domain of
HRMS. The primary objective of HRMS is to ensure the availability of the right
people for the right jobs, so as the organizational goals are achieved effectively.
Data’s/Files/Records of every employee are securely kept from this system which is
developed to lessen the slow process in retrieving the ﬁles of employees. The HR can
also recruit employees and also can make posters on the sites so that all can view it.
The employees can easily monitor their roles and responsibilities which are updated
by the HR or the admin. This application can make the organization more productive
by easy monitoring of the employees and their work.
In most of the HRMS related activities, human interaction is preferred the most.
But when the work load is increased in the HRMS systems the performance and
quality of the output may get decreased, since many of the activities in HRMS
tools are associated with human employees to be operated manually. In such cases,
the availability of some automated tools in the areas of high workload may reduce
the inaccuracies in providing the outputs. In HRMS applications, it is difﬁcult to
develop automated tools for all the activities because of various reasons. But at the
same time, there are some areas in HRMS tools for which efﬁcient automated tools
can be developed.
In this paper, an attempt has been made for providing some automated tools at
various stages of HRMS activities, and analysis of these activities for developing
automated tools.
2
Literature Survey
The current systems used in various ﬁelds are based on manual record systems
such as an excel sheet or Google sheet. It provides the data storage properly, except
everything would be manual. Manual Email, follow-ups which are repetitive tasks of
HR of the organization could be tedious work. It might end up sending emails to the
same person and miss another one. So this is always been a problem. When it comes
to employee details, it takes so much processing time with high rate of inaccurate
results. This kind of system is hard to maintain as the data grows exponentially since
it is a tedious job to track how many employees would be recruited on a daily basis,
or how many of them would be left as well as terminated.

An Analysis and Application of HRMS Tools in Industries
781
Aydo˘gan and Cemil [1], has made a research on Recent advances and appli-
cations in LC-HRMS for food and plant natural products: a critical review which
demonstrates the usage of the HRMS tool. Alygizakis et al. [2], has demonstrated
Untargeted time-pattern analysis of LC-HRMS data to detect spills and compounds
with high ﬂuctuation in inﬂuent wastewater. Chaker et al. [3], has made a survey on
transformation from Metabolomics to HRMS-Based Exposomics and Adapting Peak
Picking and Developing Scoring for MS1 Suspect Screening. Di Ottavio et al. [4],
has studied UHPLC-HRMS-based metabolomics and chemoinformatics approach
to chemically distinguish ‘super foods’ from a variety of plant-based foods which
dawn some useful results. Hemmer et al. [5] conducted a comparison of three untar-
geteddataprocessingmethodsforanalyzingLC-HRMSmetabolomicsdata.Hohrenk
et al. [6] conducted a thorough investigation into the use of chemometric methods
to improve data mining and prioritization in LC-HRMS for non-target screening of
organic micropollutants in complicated water matrices. Hrbek et al. [7] described a
technique for authenticating milk and milk-based items using direct analysis in real
time ionization–high resolution mass spectrometry (DART–HRMS).
Ivanisevic et al. [8] conducted a survey by naming from samples to metabolic
insights: Uncovering biologically relevant information in LC-HRMS metabolomics
data. Kirwan [9] created two approaches to nuclear chemical plant human reliability
management:HRMSandJHEDI.Liuetal.[10]conductedastudyonHRMSmethods
for non-target ﬁnding and characterization of poly—and per-ﬂuoroalkyl substances
(PFASs) in environmental and human samples. Matos et al. [11] used Integrated
UPLC-HRMS, Chemometric Tools, and Metabolomic Analysis of Forage Palm
(Opuntia spp. and Nopalea spp.) to identify Biomarkers Associated with Carmine
Cochineal (Dactylopius opuntia) Susceptibility. Ranjan et al. [12] conducted a thor-
ough examination of data mining strategies for enhanced decision making in human
resource management systems. Ramanathan et al. [13] conducted research on the
paradigm change in drug discovery bioanalysis from SRM to HRMS. Righetti et al.
[14] presented recent advancements and potential challenges in modiﬁed myco-
toxin analysis and explained why HRMS has become a vital instrument in food
contamination research. Zahn et al. [15] conducted a thorough investigation into
locating a needle in a haystack–analyte-driven methods and strategies for informa-
tion extraction and chemical prioritization from environmental (chromatography)
HRMS non-target screening data.
The study which is made in this paper depicts the possibility of building automated
tools in some areas of the HRMS tools based on suitability by considering business
oriented factors and performance issues. However, the paper also gives some general
ideas of building automated tools with combination of technologies thereby making
an attempt for good deliverables.

782
M. R. Dileep et al.
3
Proposed Methodology
The proposed system has everything automated except a mouse click. A system has
been built, that would help HR of any organization to do their complex manual task
easily on a great UI in a simple manner. It also makes the HR easily monitor the work
ﬂow if the employers and the employees can edit or update their records or proﬁle
on the application, can apply for a leave application, can get their salary slips, can
easily search anything which is needed, can look upon the news feeds and so on.
This makes the entire process easy by recording the ﬁles in a single applica-
tion and retrieves them. The HR or the admin can also add new users, can recruit
employees, can make different news feeds in the organization so that the employees
can easily monitor the new record, and can also share them with their social media
accounts. These major activities are done automated using AI systems. The proposed
methodology has been explained in Fig. 1.
In the proposed methodology, a scenario associated with the HRMS tool is consid-
ered where a set of activities for recruitments, training, reward, assigning tasks, etc.
are performed. From this scenario, certain activities are identiﬁed for the develop-
ment of the automated tool. The activities, methods, algorithms used for developing
the automated tool are explained in the Proposed Algorithm section.
Fig. 1 Flowchart representing the proposed methodology

An Analysis and Application of HRMS Tools in Industries
783
4
Proposed Algorithm
The proposed methodology has been summarized as an algorithm as shown below.
Step 1: Data Preparation—The process of Data Preparation involves 3 phases.
• Phase-1: Data collection—The ﬁrst phase involves the activities such as articu-
lating the problem, deﬁnition of the structure of the data which is required and
combining different sources to collect the necessary data.
• Phase-2: Data Preprocessing—This phase involves the extraction of the accurate
data required for further processing by applying ﬁlter over the data gathered. The
techniques which are involved in this process are such as cleaning, sampling, and
formatting.
• Phase-3: Data Transformation—This phase involves certain activities which
give the relationship between different attributes of the data and establish a rela-
tionship between the data. In order to get relationships and mapping between
the data certain techniques such as scaling, decomposition and aggregation are
employed. These 3 Phases are represented as in Fig. 2.
Step 2: Analysis of Data by HR
In the second step, the prime focus is to analyze the data based on certain constraints.
The analysis of the data can be usually done by the HR team, whereas suitable bots
can be developed in this stage for getting the work done with increased speed.
Step 3: Data Access, Update, Manipulation, and Deletion of Data
Effective data accessing tools can be employed in the process for easy and fast access
for manipulation of the data. Modern database systems such as MongoDB, Sybase,
etc. are examples at this stage.
Step 4: Generation of Reports
Reports can be generated at different stages of the process and this report can be in
various formats. Suitable Android Apps can be developed and can be employed at
this stage.
Fig. 2 Data preparation
process

784
M. R. Dileep et al.
Fig. 3 Menu with additional
options
5
Experimental Results
This application gives the user to create an environment for their organization and
add the users. Users can also easily search anything on the navigation bars. Users
can check the news feeds on the navigation bars and get the help support system if
there is any difﬁculty. Fig. 3 represents the structure of a navigation bar and shows
the navigation bar with other options.
6
Conclusion
It is clear from the experiment that the application will help every organization to
set up their own environment so that users can get all the details of their employees
just by a mouse click. The client or the user can visit the site and register themselves
into the application by providing their information with the company name. Then
the client gets their credentials and becomes the admin of their organization. Then
admin can add upon the member for their organization and assign the roles and
responsibilities for them. The admin can make or give roles to the other members.
The admin has access to all the roles. HR can give the roles and responsibilities to the
employees. There is a priority meter which is handled by the admin and only admin
can change the access for the others. The HR and the admin can change the access
of the employees. The employee can edit their proﬁle and HR and the accountant is
responsible for the leave applications and the salary statements. The employees can
view their salary statements. The HR is responsible to recruit new employees and
make them a part of the organization. HR can also send in the invite link for others
to join the application. Then the new employee will get the credentials and can be a
part of the organization. This will entirely reduce the manpower of the organization
and also help in keeping track of the employees in their organization.
Along with the said activities, some additional activities are made automated
based on the environments and requirements. The task includes Data Collection,
Data Analysis, Data Accessing, and representation of output in various forms. It is

An Analysis and Application of HRMS Tools in Industries
785
also noted that in existing HRMS tools, that not all the activities are automated as
these activities need human interference. This paper reﬂects a new approach towards
development of novel methods of HRMS tools.
7
Future Scope
7.1
Bulk Emailing
Whereas previously users would write and send individual emails, users now put
Close’s bulk emailing functionality to good use. Users use it in conjunction with
Smart Views and email templates, meaning users can simply click on a Smart View
and then bulk email a pre-deﬁned template to that whole segment. It really allows us
to ramp up our process.
7.2
Email Template for Leave and Salary Slips
Work would be started with salary slips. The way that the employees could easily
work on the organization is by knowing their salary slips every month and then gets
their leave applications approved without moving around the organization to get
approval.
7.3
Proﬁle Data from LinkedIn
This template would make the work of HR, even more, easier by posting up blogs
or comments on the site by inviting or encouraging new members coming up to give
interviews to the organization. This way the HR can recruit many employees to the
organization.
7.4
Data Compression
This is a feature that the end-user does not really see, but it is something the user can
feel. Passing the compressed data when the server and client communicate increases
the performance of the system as well as, reduces the bandwidth.

786
M. R. Dileep et al.
7.5
Automatic SMTP Connection
For email services, the application limits the user to use only Gmail for email integra-
tion. Once ready with automatic SMTP recognition and connection it can allow users
to use whichever email service user wants. This is very important since allowing only
Gmail decreases our potential user, who uses other email services for their business.
References
1. Aydo˘gan, C. (2020). Recent advances and applications in LC-HRMS for food and plant natural
products: A critical review. Analytical and Bioanalytical Chemistry, 412(9), 1973–1991.
2. Alygizakis, N. A., Gago-Ferrero, P., Hollender, J., & Thomaidis, N. S. (2019). Untargeted
time-pattern analysis of LC-HRMS data to detect spills and compounds with high ﬂuctuation
in inﬂuent waste water. Journal of Hazardous Materials, 361, 19–29.
3. Chaker, J., Gilles, E., Léger, T., Jégou, B., & Arthur, D. (2020). From metabolomics to HRMS-
Based exposomics: Adapting peak picking and developing scoring for MS1 suspect screening.
Analytical Chemistry.
4. Di Ottavio, F., Gauglitz, J. M., Ernst, M., Panitchpakdi, M. W., Fanti, F., Compagnone, D.,
Dorrestein, P. C. & Sergi, M. (2020). A UHPLC-HRMS based metabolomics and chemoinfor-
matics approach to chemically distinguish ‘super foods’ from a variety of plant-based foods.
Food chemistry, 313, 126071.
5. Hemmer, S., Manier, S. K., Fischmann, S., Westphal, F., Wagmann, L., & Meyer, M. R.
(2020). Comparison of three untargeted data processing workﬂows for evaluating LC-HRMS
metabolomics data. Metabolites, 10(9), 378.
6. Hohrenk, L. L., Vosough, M., & Schmidt, T. C. (2019). Implementation of chemometric tools
to improve data mining and prioritization in LC-HRMS for nontarget screening of organic
micropollutants in complex water matrixes. Analytical Chemistry, 91(14), 9213–9220.
7. Hrbek, V., Vaclavik, L., Elich, O., & Hajslova, J. (2014). Authentication of milk and milk-based
foods by direct analysis in real time ionization–high resolution mass spectrometry (DART–
HRMS) technique: A critical assessment. Food Control, 36(1), 138–145.
8. Ivanisevic, J., & Want, E. J. (2019). From samples to insights into metabolism: uncovering
biologically relevant information in LC-HRMS metabolomics data. Metabolites, 9(12), 308.
9. Kirwan, B. (1997). The development of a nuclear chemical plant human reliability management
approach: HRMS and JHEDI. Reliability Engineering & System Safety, 56(2), 107–133.
10. Liu, Y., D’Agostino, L. A., Qu, G., Jiang, G., & Martin, J. W. (2019). High-resolution
mass spectrometry (HRMS) methods for nontarget discovery and characterization of poly-
and per-ﬂuoroalkyl substances (PFASs) in environmental and human samples. TrAC Trends in
Analytical Chemistry, 121, 115420.
11. Matos, T. K. B., Guedes, J. A. C., Alves Filho, E. G., Luz, L. R., Lopes, G. S., do Nascimento,
R. F., & João A. de Sousa et al. (2021). Integrated UPLC-HRMS, chemometric tools, and
metabolomic analysis of forage palm (Opuntia spp. and Nopalea spp.) to deﬁne biomarkers
associated with non-susceptibility to carmine cochineal (Dactylopius opuntiae).
12. Ranjan, J., Goyal, D. P., & Ahson, S. I. (2008). Data mining techniques for better decisions in
human resource management systems. International Journal of Business Information Systems
3, 5, 464–481.
13. Ramanathan, R., Jemal, M., Ramagiri, S., Xia, Y. Q., Humpreys, W. G., Olah, T., & Korfmacher
W. A. (2011). It is time for a paradigm shift in drug discovery bioanalysis: from SRM to HRMS.
Journal of mass spectrometry 46(6), 595–601.

An Analysis and Application of HRMS Tools in Industries
787
14. Righetti, L., Paglia, G., Galaverna, G., & Dall’Asta, C. (2016). Recent advances and future
challenges in modiﬁed mycotoxin analysis: why HRMS has become a key instrument in food
contaminant research. Toxins 8(12), 361.
15. Zahn, D., & Frömel, T. (2020). Finding a needle in a haystack–analyte-driven tools and
techniques for information extraction and prioritization of chemicals from environmental
(chromatography-) HRMS non-target screening data. Current Opinion in Environmental
Science & Health.

Resource Allocation and Power
Management in Cloud Servers Using
Deep Reinforcement Learning
Sushil Shakya
and Subarna Shakya
Abstract Resource allocation and power management have become challenging
tasks in cloud computing. Since workloads change over time, dynamic cloud resource
allocation and power management solutions are needed, that can intrinsically adapt
to the demand of the resources. This paper demonstrates the use of deep reinforce-
ment learning algorithms for the task dispatching and power management in the
simulated Alibaba cluster environment with the goal of achieving better power and
latency management than traditional task scheduling algorithms. In this paper, we
propose a hierarchical RL model for resource allocation and power management
which obtains better results in terms of latency as well as power usage, than tradi-
tional task scheduling.
Keywords Dynamic resource management · Reinforcement learning · Cloud
computing · Task scheduling
1
Introduction
Today, the cloud computing has become analogous to modern computing itself,
where everything is a service that can connect and combine with other services
to meet an endless number of application needs. More and more companies are
shifting their businesses into the cloud, and thus, it has completely changed the
way businesses operate and build applications. One of the main reasons behind the
popularity of cloud computing is the advancement of virtualization technology which
enables resources indatacenters tobesharedinon-demandbasis. Incloudcomputing,
resource allocation and power management for these virtual machines are two of the
major concerns. Although cloud computing systems have been helping businesses
to increase their revenue, the overgrowing dependency on the cloud computing has
created a worldwide growth in energy consumption and has negatively impacted the
environment in terms of carbon footprints. Datacenter electricity consumption was
S. Shakya (B) · S. Shakya
Institute of Engineering, Tribhuvan University, Lalitpur, Nepal
URL: http://www.pcampus.edu.np/
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_62
789

790
S. Shakya and S. Shakya
projected to reach about 140 billion kWh per year by 2020, which costs $13 billion
annually in electricity bills [1].
Resource allocation and power management using the conventional optimiza-
tion algorithm is one of the possible approaches, and many research works have
shown promising results [2, 3]. But these algorithms cannot dynamically adapt to
the time-varying workloads and require manual tuning. Since time-varying workload
is intrinsic in cloud computing, cloud resource allocation and power management
needs to be performed in online adaptive manner. Thus, an optimal dynamic resource
allocation and power management policy is required to minimize latency and power
consumption in the cloud computing systems. Designing the dynamic resource allo-
cation and power management policy can be modeled as a Markov decision process
(MDP). Reinforcement learning (RL) has proven an effective solution for solving
such dynamic optimization problems. RL approaches are ideal for cloud comput-
ing system as it does not require any prior modeling of transition matrix, workload,
or power/performance of the underlying system [4]. The primary goal here is to
reduce explicit human instructions in the management of complex computing sys-
tems. Although traditional RL algorithms are good at operating in dynamic envi-
ronments, these algorithms face a challenge because of the large state and action
spaces of cloud computing systems, making conventional RL approach ineffective
[5]. Deep reinforcement learning algorithms have proven to be successful at handling
complicated control problems with high-dimensional state and action space and even
surpassed human performance in playing Atari games [6] and Go games. Note Go
is the computationally most complex game that humans have ever created.
A hierarchical approach for solving the resource allocation and power manage-
ment problem has been proposed in [4]. Using the hierarchical RL models, the
authors were able to achieve signiﬁcant improvement in the power consumption of
cloud computing resources but the latency was still higher than the baseline approach
such as round-robin. Building upon the idea of hierarchical RL models, an improved
version has been proposed in this paper. Experiment results using Alibaba cluster
traces [7] show that the proposed version of the hierarchical RL model achieves better
performance than the baselines in terms of power consumption as well as latency.
2
Related Work
In [1], it has been projected that the annual electricity consumption of datacenters in
the USA would be around 140 billion kilowatt hours (kWh) by the year 2020 which
would cost roughly 3 billion US dollars. Researchers have been trying to come
up with better optimization algorithms to improve the resource allocation and task
scheduling problem which would eventually lead to better power management. An
algorithm called “Fast and Energy-Aware Resource Provisioning and Task Schedul-
ing” (FERPTS) has been proposed to optimize the task run time and also ensure
low energy consumption in the cloud systems, and the authors were able to achieve
upto 79.94% run time savings compared to baseline [8]. But such algorithms cannot

Resource Allocation and Power Management in Cloud Servers …
791
automatically adapt to the dynamic cloud environment, so researchers have been
trying to use machine learning algorithms to come up with self-adjusting dynamic
algorithm.
Deep learning has made it possible to train an end-to-end machine learning model
without the necessity of cherry-picked input features. A lot of deep reinforcement
learning algorithms have been proposed and shown their effectiveness in the ﬁeld
of game playing by defeating human players. Deep Q-Network (DQN) was one of
the ﬁrst successful deep reinforcement learnings that were able to achieve state-of-
the-art results and even beat human performance in a number of Atari games [6, 9].
Recently, this algorithm has also been able to achieve better performance in resource
scheduling and task allocation problem beating the performance of FERPTS by a sig-
niﬁcant margin [10]. Researchers have been trying to use deep RL algorithm in case
of resource allocation and power management for cloud computing. A hierarchical
RL approach has been used in [4] where the authors have shown that a hierarchical
framework with a global tier for virtual machine (VM) resource allocation to the
servers and a local tier for distributed power management of local servers achieves
better power management performance than round-robin and greedy task scheduling
algorithms. In an example, cloud service provider (CSP) setup with 5000 servers and
200,000 tasks, the DRL-Cloud [10] achieved 218% energy cost efﬁciency improve-
ment and 144% runtime reduction while maintaining lower reject rate on average but
it suffered from latency issues in case of smaller server clusters and tasks. Even for
a CSP setup with 500 servers, with 50,000 tasks, the DRL cloud had 480% higher
runtime than round-robin. Based on the results of [10], the approach does not seem
suitable for the cloud datacenters with servers less than 2000. Not all datacenters
contain such a large number of servers. Building upon the idea from [4] and [10],
we have proposed a hierarchical model with round-robin in the global tier and RL
model in the local tier which is suitable for small datacenters.
3
Methodology
Cloud service providers are continuously looking for better solutions to optimize the
power consumption and improve the task execution latency by applying state-of-the-
artresourceprovisioningandtaskschedulingalgorithms.Thesealgorithmshavebeen
successful to a certain limit. But the major issue is that these algorithms cannot adapt
to the changes in the cloud computing environment and also do not always provide
the optimal solution. Deep RL algorithms have been shown to be very effective in
handling optimization problems in such dynamic environment. The methodology of
the proposed solution has been described in the following subsections.

792
S. Shakya and S. Shakya
3.1
Data Collection and Analysis
It is well known that the deep learning algorithms are very data demanding, and the
overall performance of the deep learning models eventually depends on the amount
of data available. Alibaba has released its cluster workload traces under Alibaba
Cluster Trace Program, which is smaller in size and easier to work with. Researchers
have been using this dataset for the purpose of server workload experimentation. A
trimmed down version of this dataset containing the logs for 100K server tasks is
easily available, and this dataset is sufﬁcient enough to carry out the experiments of
this project. The Alibaba cluster dataset is composed of the following ﬁve comma-
separated value (CSV) ﬁles.
• batch instance
• batch task
• container usage
• machine meta
• machine usage
Out of these available data batch task contain the logs of the tasks that actually ran
on the Alibaba cluster machines and machine meta contains the meta information
of these cluster machines. These are the only data of interest for the experiments of
this project. The schema for batch task and machine meta are shown in Tables1
and 2, respectively.
3.2
Implementation
The problem of optimizing power consumption and task execution can be modeled
as a Markov decision process (MDP), and thus, RL algorithms can be applied to
solve it. RL algorithms can adapt to a dynamic cloud computing environment, so no
external manual input is ever required. An experimental setup of the cloud cluster
environment is shown in Fig.1. The whole setup is similar to that of [4]. It consists
Table 1 Schema for batch task csv ﬁle
Field
Comment
task_name
Unique within a job
instance_num
Number of instances
job_name
Job name
task_type
Task type
status
Task status
start_time
Start time of the task
end_time
End of time the task
plan_cpu
Number of cpu needed by the task, 100 is 1 core
plan_mem
Normalized memory size, [0, 100]

Resource Allocation and Power Management in Cloud Servers …
793
Table 2 Schema for machine meta csv ﬁle
Field
Comment
machine_id
Uid of machine
time_stamp
Time stamp, in second
failure_domain_1
One level of container failure domain
failure_domain_2
Another level of container failure domain
cpu_num
Number of cpu on a machine
mem_size
Normalized memory size. [0, 100]
status
Status of a machine
Fig. 1 Cluster environment
of N servers that have R types of resources related to framework for cloud resource
distribution and power management. A server can be in an active mode or sleep mode
for power saving. The CPU and memory are the basic types of server resources that
are dealt with here. Whenever a new task comes in, the global model is responsible
for selecting the machine to which to send this task. The task is then forwarded to
that particular machine. A machine here consists of CPU, memory, a local model, a
workload predictor and running and pending tasks. Depending on the current state
of the machine, the local model decides to either run this new task of place it in the
pending queue and process it later. The working of the global model, local model,
and workload predictor will be discussed next.
3.2.1
Global Model
Let us take a look on why there is a need of making smart decisions inside these
machines from the CPU resource consumption point of view. An example of task
execution on a machine is shown in Fig.2. Let us assume tasks 1, 2, and 3 arrive at a
particular machine M1 at time t1, t2, and t3 and ﬁnish at t4, t5 and t6, respectively. Let
us say at time 0, M1 is in active mode. When tasks 1 and 2 arrive, there are plenty
resources, so their requirements are fulﬁlled immediately. When task 3 arrives, it has
to wait until the task 1 is ﬁnished and the waiting time is t4 −t3. Therefore, the latency
of task 3 is t6 −t3, which is longer than the task duration. To reduce the task latency,
the global model should not overload servers. Thus, a smart scheduling scheme is

794
S. Shakya and S. Shakya
Fig. 2 Task execution
example on an active
machine [4]
very important for automatically assigning the tasks to machines and distributing
resources in each machine. The former is carried out by the global model.
3.2.2
Local Model
When a task is assigned to a machine in sleep mode, it takes Ton time to switch the
machine into the active mode and Toff time to switch the machine back to sleep mode.
The power consumed by a machine in sleep model is assumed to be zero, and the
power consumed by a machine at time t in the active mode is a function of the CPU
utilization [11] as given in Eq.1.
P(xt) = P(0%) + (P(100%) −P(0%))(2xt −x1.4
t
)
(1)
where xt is the CPU usage of the machine at time t, P(0%) is the power consumption
of the machines in the idle mode, and P(100%) is the power consumption of the
machine in full load. Usually, the power consumption of the machine during the sleep
to active switch is higher than P(0%) [11, 12].
To better understand how the power consumption can be efﬁciently managed, let
us take a look at Fig.3. At time 0, the machine is in the sleep mode, task 1 and task 2
arrive at t1, t3, respectively, and consume 50% and 70% CPU resources, respectively.
When task 1 arrives, the machine switches from sleep mode to active mode and starts
serving task 1 from t1 + Ton to t2. At this point, the machine needs to make a decision
of whether to go back to sleep or stay idle waiting for next task to arrive. In case of
ad-hoc technique shown in Fig.3a, the machine goes to sleep which takes Toff time,
so when task 2 arrives at time t3, the machine has to switch on again before serving
the task. Thus, the execution of task 2 starts only at t2 + Toff + Ton and completes
at time t4. But in case of dynamic power management (DPM) shown in Fig. 3b, the
machine does not immediately goes to sleep and instead waits for Ttimeout in idle
mode. Within that timeout period, task 2 arrives and the machine can immediately
switch to active mode and start processing this task and complete it at time t′
4 which
is less than t4. So clearly, the dynamic power management (DPM) technique helps to
improve the task latency and also to reduce the overall power consumption because:

Resource Allocation and Power Management in Cloud Servers …
795
Fig. 3 Effectiveness of smart power management in a machine [4]
P(idle) < P(active to sleep) + P(sleep to active)
(2)
The dynamic power management is carried out by the local model which is shared
across all the machines. A question that may arise now is how do we set the timeout
values for the machines, that is where the workload predictor comes in.
3.2.3
Workload Predictor
A workload predictor is an important part of the DPM framework that is responsible
for getting the predictions of the future workloads. The prediction along with the
current information such as the number of pending tasks in the queue is fed to the
local model and serve as the current state of the machine for selecting corresponding
actions and learning in the observation domain of the machine. A long short-term

796
S. Shakya and S. Shakya
memory (LSTM) network has been used as workload predictor in this project but
any other recurrent neural network (RNN) variant can also be tried out. With the
accurate prediction and the current information of the machine under management,
the local model has to select the most appropriate actions (timeout values) to help
reduce the power consumption of the machine as well as the task latency.
3.2.4
Training Procedure
Training RL algorithms directly on the cloud cluster environment can be difﬁcult
as these suffer from the convergence issues. A lot of hyperparameter tuning would
be required and it becomes very time-consuming as well. Instead, the algorithms
can ﬁrst be experimented on the OpenAI Gym environments [13] to obtain a good
set of hyperparameter values as the starting point for the cloud cluster environment
training. The training procedure consists of the following two steps:
1. Train RL algorithms on the CartPole environment and ﬁnd the best performing
hyperparamter setting
2. Use the hyperparameter from step 1 as the starting point to train the algorithms
on the Alibaba cloud cluster environment.
A popular RL policy optimization algorithm called asynchronous actor–critic
algorithm (A2C) is used to train both global and local models. The pseudocode for
A2C algorithm is reported in Algorithm 1.
Algorithm 1 N-step Advantage Actor–Critic
Start with policy model πθ and value model Vω
repeat:
Generate an episode S0, A0,r0, . . . , ST −1, AT −1,rT −1 following πθ(·)
for t from T −1 to 0:
Vend = 0 if (t + N ≥T ) else Vω(st+N)
Rt = γN Vend + N−1
k=0 γk (rt+k if (t + k < T ) else 0)
L(θ) = 1
T
T −1
i=0 (Rt −Vω(St)) log πθ(At|St)
L(ω) = 1
T
T −1
i=0 (Rt −Vω(St))2
Optimize πθ using ∇L(θ)
Optimize Vω using ∇L(ω)
The main objective while training RL algorithms on Alibaba cloud cluster envi-
ronment is to obtain a better power usage than the baseline approaches such as greedy
and round-robin approach without sacriﬁcing much on the task latency. It should be
noted at this point that the task latency and power usage in the cloud servers aren’t of
exact equal importance and the importance ratio can vary for different cloud clusters.
The experiment results have been discussed in Sect.4.

Resource Allocation and Power Management in Cloud Servers …
797
(a) Power Usage graph
(b) Latency graph
Fig. 4 Experiment results (servers = 30, tasks = 10,000)
4
Results
Alibaba cluster trace data [7] is used to train and compare the performance of the
hierarchical RL models [4] to that of round-robin algorithms. RL models are trained
using A2C algorithm. Hierarchical RL models are better than baseline algorithms
in terms of power usage but suffer from huge latency issues. As a solution to this,
two modiﬁed hierarchical models have been proposed where the global RL model is
replaced with greedy algorithm and round-robin algorithm keeping the local model
same. These modiﬁed hierarchical approaches obtain overall better performance
compared to other approaches. The results of the experiment run on 10,000 tasks of
Alibaba cluster trace dataset on 30 servers are shown in Fig.4.
The experiment results graph clearly shows that the vanilla hierarchical model suf-
fers from huge latency problem even though it shows a positive improvement toward
power consumption. The latency issue arises due to the fact that the two RL models
used for hierarchical setup take some processing time while deciding for the server
selection. The two modiﬁed hierarchical models bring this time down by replacing
the global model with round-robin and greedy algorithm which are comparatively
faster. The effect can be clearly observed from the graphs for round_robin_rl and
greedy_rl.
5
Conclusion
In this paper, a reinforcement learning-based hierarchical framework [4] has been
implemented to tackle the resource distribution and power management issues in
the domain of cloud computing systems. This is a simple framework with two main
models: global model for better task dispatching and local model for better power
management.Boththesemodelsarebasedondeepreinforcementlearningalgorithms

798
S. Shakya and S. Shakya
which make them highly scalable and as well as reduce the online computational
complexity. A local model is supported by a LSTM-based workload predictor which
provides the prediction about the future workloads and helps the local model decide
ontheappropriatemachinetimeoutvalues.Ontheperformanceside,hierarchicalRL-
based approach reduces power usage by around 30% when compared to round-robin
but the model suffers from severe latency issues. As a solution to this problem, two
modiﬁed hierarchical solutions variants have been proposed that uses round-robin
and greedy algorithms as their global tier keeping the RL-based local tier. The results
show that these modiﬁed hierarchical solutions have better latency than the vanilla
hierarchical approach of [4] without sacriﬁcing much on the power improvement.
References
1. Delforge, P. (2014). America’s data centers consuming and wasting growing amounts of energy.
Natural Resource Defence Council.
2. Liu, X., Qin, Z., & Gao, Y. (2019). Resource allocation for edge computing in IOT networks via
reinforcement learning. In ICC 2019-2019 IEEE international conference on communications
(ICC) (pp. 1–6). IEEE.
3. Tesauro, G., et al. (2005). Online resource allocation using decompositional reinforcement
learning. AAAI, 5, 886–891.
4. Liu, N., Li, Z., Xu, J., Xu, Z., Lin, S., Qiu, Q., Tang, J., & Wang, Y. (2017). A hierarchical frame-
work of cloud resource allocation and power management using deep reinforcement learning.
In 2017 IEEE 37th international conference on distributed computing systems (ICDCS) (pp.
372–382). IEEE.
5. Fundamentals of Reinforcement Learning. Retrieved on March, 01, 2021 from https://www.
coursera.org/learn/fundamentals-of-reinforcement-learning/home/welcome
6. Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., & Riedmiller,
M. (2013). Playing atari with deep reinforcement learning. arXiv:1312.5602
7. Alibaba Cluster Workload Traces. Retrieved on December 20, 2020, from https://github.com/
alibaba/clustered
8. Li, H., Li, J., Yao, W., Nazarian, S., Lin, X., & Wang, Y. (2017). Fast and energy-aware resource
provisioning and task scheduling for cloud systems. In 2017 18th international symposium on
quality electronic design (ISQED) (pp. 174–179). IEEE.
9. Alpha Go. Retrieved on March, 01, 2021 from https://deepmind.com/research
10. Cheng, M., Li, J., & Nazarian, S. (2018). Drl-cloud: Deep reinforcement learning-based
resource provisioning and task scheduling for cloud service providers. In 2018 23rd Asia
and South Paciﬁc Design Automation Conference (ASP-DAC) (pp. 129–134). IEEE.
11. Fan, X., Weber, W. D., & Barroso, L. A. (2007). Power provisioning for a warehouse-sized
computer. ACM SIGARCH Computer Architecture News, 35(2), 13–23.
12. Meisner, D., Gold, B. T., & Wenisch, T. F. (2009). Powernap: Eliminating server idle power.
ACM SIGARCH Computer Architecture News, 37(1), 205–216.
13. OpenAI Gym. Retrieved on March, 02, 2021 from https://gym.openai.com/

System for Analyzing Crime News
by Mining Live Data Streams
with Preserving Data Privacy
Rahul Patil, Pramod D. Patil, Sayali Kanase, Nikita Bhegade,
Vaishnavi Chavan, and Shreyas Kashetwar
Abstract Data stream mining is an emerging ﬁeld of data science. It is a process of
extraction of knowledge from streaming data using incremental algorithms. Mining
streamingdatacomeswithdifferentchallenges[3]likeconceptdrift,handlingincom-
plete and delayed information, skewness of data, and privacy preservation. Privacy of
streaming data should be maintained during the process of its mining and processing
to protect sensitive information from attackers and also to preserve user-sensitive
personal data that is vulnerable to malicious purposes. In this paper, we proposed a
system for mining crime news data streams along with privacy preservation of sensi-
tive data using K-anonymization and Apache Spark. The knowledge gained through
the process of mining streaming data is visualized in the form of real-time updating
charts which provides the end-user with useful insights about current crime rates and
statistics in the popular cities of India.
Keywords Data stream mining · Privacy preservation · Apache Spark ·
K-anonymization · Quasi-identiﬁer · Multithreading
R. Patil (B) · S. Kanase · N. Bhegade · V. Chavan · S. Kashetwar
Pimpri Chinchwad College Of Engineering, Pune, India
S. Kanase
e-mail: sayali.kanase17@pccoepune.org
N. Bhegade
e-mail: nikita.bhegade17@pccoepune.org
V. Chavan
e-mail: vaishnavi.chavan17@pccoepune.org
S. Kashetwar
e-mail: shreyas.kashetwar17@pccoepune.org
P. D. Patil
Dr. D.Y. Patil Institute of Technology, Pimpri, Pune, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_63
799

800
R. Patil et al.
1
Introduction
Nowadays, the mining of data streams is an emerging area in the ﬁeld of data science
and knowledge engineering owing to the spurge in applications requiring mining of
real-timestreamingdata.Streamingdataischaracterizedbyanever-endingdatasurge
that has no deﬁnite beginning or end, providing a persistent feed of data that can be
harnessed for various uses without the need to store or download it. The data sources
are widespread and can range from e-commerce purchases, social media feeds, real-
time stock trades, Web site activity, IoT devices [1], transactions, to server log ﬁles,
etc. The prime factors that come into consideration while handling streaming data
are velocity, variety, and volume [2]. Data needs to be analyzed while in motion,
and it thus gives rise to the need to tackle many challenges according to the need of
the application. The challenges are related to concept drift [8] getting induced in the
incoming data stream, memory management issues, dealing with complex queries
that are in a continuous format, multilevel or multi-dimensional processing, handling
incomplete or delayed information, and many others that arise during different stages
of mining data streams [3]. One such challenge is preserving the privacy of user-
sensitive or vulnerable data which is present in this real-time streaming data.
Privacy preservation is a crucial process in mining streaming data. The methods
for preserving privacy are ever-demanding for secured and reliable processing [4,
5] and analysis of data streams. Vulnerable data needs to be masked during stream
processing to prevent any kind of malicious use on it. While mining streaming data
that contains crime-related information and statistics, the privacy preservation of
user’s personal details is of utmost importance. The streaming data collected from
online sources encompasses the information of users posting it on various platforms.
Names of the individuals need to be masked or hidden from the analysts or other end-
users who are processing the real-time data and also during the stage of visualization
to preserve privacy of sensitive data and avoid its misuse in any form.
In this paper, we have proposed a system for mining crime-related streaming
data and its visualization with preserving the privacy of sensitive information. In this
system,streamingdataisextractedfromTwitterandnewsWebsites.NewTwitterdata
arrives every second, whereas news data gets updated every day. Twitter streaming
data is extracted using Twitter API and Python tweepy library. News streaming data
is extracted from news Web sites using Web scraping.
After extraction of data, preprocessing is done on it. Preprocessing includes
removal of null values, deletion of unwanted data, etc. Processing of streaming
data took place at runtime. The proposed system uses Apache Spark for processing
of Twitter data and for privacy preservation K-anonymization algorithm is used.
To achieve a fast processing speed, multithreading is used. Multithreading helps to
achieve the desired execution pace while dealing with data that has been extracted
from news Web sites that generate a tremendous amount of streaming data. The
paper proposes system architecture and also implementational details of our proposed
system. The outcome of the implementation of the proposed system is to attain valu-
able and meaningful insights that provides the end-users a dashboard for viewing

System for Analyzing Crime News by Mining Live Data Streams …
801
and analyzing real-time crime statistics. The various forms of visualizations provided
depict the crime rates in particular cities, correlation between types of crime and their
rates, and also real-time popular crime topics which are being reported on various
online platforms. These insights will prove to be very supportive for crime analysts
working for various crime branches and also for the common people to keep in touch
and be aware of the crime statistics in their respective cities.
The remainder of the paper proceeds as follows. Section 2 presents the overall
system ﬂow of our proposed system elaborating the components and architectural
details. The two process ﬂows owing to the selected streaming data sources are
described in this section which processes the streaming data. Section 3 describes
the process of extracting data from crime news related data sources for the proposed
system. Section 4 summarizes the preprocessing steps that were carried out after data
extraction in order to attain the desired data format needed for further processing.
Section 5 presents K-anonymization as the privacy preservation technique used
in the proposed system for masking user-sensitive data attributes throughout its
processing and visualization without affecting the performance of the process of
mining. Sections 6 and 7 present the part of knowledge extraction and data visual-
ization as a form of result. Further, Sect. 8 discusses the limitations of the proposed
system. Finally, Sect. 9 concludes the paper.
2
System Flow
The complete system ﬂow is divided into two parts twitter streaming module and the
news streaming module. Figure 1 represents the detailed ﬂow of the system.
2.1
Twitter Streaming Module
The Twitter streaming module deals with the streaming twitter data along with K-
anonymization and Apache Spark. It is represented as 1-2-3-4-5-6.
• Step 1—In step 1, application will send an HTTP request for the real-time chart
on Twitter data. Real-time charts consist of the most popular hashtags regarding
different categories of crimes sexual assault, cheating, ﬁnancial fraud, smuggling,
and murder.
• Step 2—In step 2, Twitter streaming module will fetch the data using Twitter
streaming API and tweepy library of Python. During the fetching process, the
ﬁlter function is applied to get only relevant information of tweepy library Python.
• Step 3—After fetching data from Twitter, anonymization is performed on it in
such a way that data will not be identiﬁable using less than k entries.

802
R. Patil et al.
Fig. 1 Proposed system ﬂow
• Step 4—Anonymized data is passed to Apache Spark for further processing.
Apache Spark will create a spark session in which streaming data will get
processed using streaming data frame and SQL commands.
• Step 5—After processing, we will get data with popular crime hashtags, and
their count which will update every new entry. Processed data will go to Flask
for visualization where we used ChartJs javascript library for plotting streaming
data.
2.2
News Streaming Module
The news streaming module will deal with streaming news data from news Web
sites which will get updated every day. City VS Crime Rates and Type Of Crime VS
Crime Rates graphs are plotted on streaming news data. The ﬂow of the module is
represented using A-B-C-D-E-6.
• Step 1—The application will send a request for two graphs to the news streaming
module.
• Step 2—The news streaming module will fetch the data from news Web sites
using Web scraping. For Web scraping, a beautiful soup Python library is used.

System for Analyzing Crime News by Mining Live Data Streams …
803
For handling and fetching data, multithreading is used to reduce the load on
machines.
• Step 3—In this step, the data will be anonymized and processed in a structured
format. The format contains information about crime news, the city of the crime,
and name of the author of the news.
• Step 4—In this step, anonymized and processed data will get pushed to the
machine learning unit. The machine learning unit identiﬁes the type of crime
depending upon the crime news. It uses natural language processing. Here, we
used different machine learning libraries like Tﬁdfvectorizer which is used for
mining frequent patterns from data, MultinomialNB naive Bayes for classiﬁca-
tion of news to different categories of crime. The above process is incremental.
Every time it will learn from the latest data.
• Step 5—After classifying the news, data will go to the visualization, where ChartJs
will visualize data in the form of a pie chart and bar chart.
3
Data Extraction
Data extraction in data stream mining is the process wherein we retrieve data from
various sources that provide real-time streaming data for further processing. The
sources are also known as data stream generators. The task here is to catch or collect
the data from these generators and ingest them in a proper structure in the system, so
that it can be efﬁciently consumed by the ingestion module for further processing.
For our proposed system, we have two prime data sources: Twitter tweets via Twitter
streaming API and streaming news data from news Web sites. Both the data sources
are extracted, transformed, and loaded into Apache Spark for further processing.
3.1
Twitter Streaming API
The ﬁrst data stream generator chosen for the proposed system is real-time tweets
data obtained from Twitter streaming API. It allows us to fetch the streaming data
by connecting to Twitter using authenticated API endpoints. It does not work like
the conventional batch data process that requires multiple and repeated requests by
the client application. Rather it operates in a manner that will enable the developers
to instantiate a single connection between the application and the API allowing
us to have a continuous connection throughout the process. This nature of Twitter
Streaming API is very suitable for the requirements of the proposed system as the
system deals with processing real-time streaming data. Batch connection is not in
accordance with the handling of streaming data. By this process, the throughput
achieved is also high that is desired for the system.

804
R. Patil et al.
Twitter streaming API authentication module contains consumer key, consumer
secret key, access token, and access secret key. This is a part of the OAuth authoriza-
tion process of connecting to the Twitter data stream securely and in an authenticated
manner [15]. The basic process of consuming streaming data via Twitter Streaming
API is as follows:
• Conﬁguration of the data stream.
• Connecting to the API provided for developer access.
• Consumption of the data as it is being delivered to the connection endpoint
established.
• Reconnecting to the Twitter API when the process is disconnected or is broken in
between.
Python Tweepy library [16] is used along with Twitter streaming API to extract
the tweets. As the programming language used while developing the application is
Python, the Tweepy library proves to be very helpful as it is open-sourced and also
hostedbyGithub.Thismakesitreadilyavailableforuse,andPythoncanthuscommu-
nicate with the Twitter platform while using its API. Tweepy provides different func-
tionalities like ﬁltering tweets related to a particular subject, location, language, etc.
The crime news data stream mining application uses the track option of the ﬁlter
function [17] to extract tweets on speciﬁc topics.
3.2
News Web sites
The second streaming data source chosen for the proposed system is real-time news
data streams generated from news Web sites that will provide us with the required
streaming data that contains crime related reports and news. This stream generator
processes in a different manner and pertains to an altogether different behavior as
compared to the Twitter tweets from Twitter streaming API. This data source is
usuallyupdatedonhourlyordailybasiswhichisincontrasttoTwittertweetsupdating
every second. Thus, to handle this data source, a different process is carried out to
avoid the distortion in the outcome of the system which is elaborated in Sect. 2 of
the paper.
The application extracts the data using Web scraping as it is the most efﬁcient and
convenientwayofaccessingdataontheInternet.ForWebscraping,thebeautifulsoup
Python package is used. This enables us to access the datasets provided by the news
Web sites posting crime-related reports and news daily. Beautiful soup can extract
the data from markup languages like HTML, XML, etc. To get the URL of the Web
site, urllib2 python function is used. After getting the HTML page using urllib2, the
parse tree is created using a beautiful soup library for parsed pages from which data
can be extracted daily. Through this process of Web scraping, we are extracting only
the speciﬁc elements from the source code by providing some custom ﬁlters that will
ﬁlter out desired crime-related information for further processing and visualization.

System for Analyzing Crime News by Mining Live Data Streams …
805
4
Preprocessing
After extracting the real-time streaming data from the sources discussed, its prepro-
cessing is carried out. The data transformation also involves ﬁltering the relevant
data as per the needs of our application. As our proposed system aims to mine
crime-related streaming data, data is reﬁned and ﬁltered [13]. The other operations
involved in preprocessing are discarding the null values, removal of unnecessary
data, and ﬁltering out the data for further processing. Data preprocessing is being
carried out on streaming data itself.
5
Privacy Preservation
The challenge of preserving privacy while mining data streams is one the prime
challenges to look out for along with others. The related work [5–7] describes how
various approaches have been suggested or implemented while dealing with applica-
tions that handle private data while mining it. The system extracts data from various
sources which contain sensitive information like user location, user id, name, etc. To
protect this information from outside attackers during mining and processing, visu-
alization of data is important. Hence, the proposed system uses the K-anonymization
technique for privacy preservation [11].
K-anonymization is a technique used to prevent privacy attacks such that an
individual record is non-identiﬁable from at least k-1 records. Generalization and
suppression are two main processes of this technique. Generalization is a technique,
which replaces an original record with a less speciﬁc or more generalized value,
while suppression involves discarding data [12, 14].
The proposed system uses K-anonymization for anonymizing user id, the user
name from the Twitter stream, and the author name from the news stream. Every
incoming tweet and news are anonymized using basic Python operations on data,
so that it cannot be re-identiﬁed. After anonymization, data goes for processing and
visualization through HTTP requests.
In the proposed system, anonymized stream accuracy during prediction is equal
to the non-anonymized stream accuracy. Figure 2 shows the accuracy of Multino-
mialNB before applying K-anonymization that is equal to 88.49557522123894%,
whereas Fig. 3 shows the accuracy after applying K-anonymization that is also
equal to 88.49557522123894%. Hence, we can conclude that the K-anonymization
algorithm does not produce any noise or distortion in the data.

806
R. Patil et al.
Fig. 2 Accuracy before K-anonymization
Fig. 3 Accuracy after K-anonymization
6
Knowledge Extraction
Knowledge extraction from streaming data is the process of extracting relevant infor-
mation from rapid data records. The proposed system extracts the knowledge from
anonymized twitter and news data streams. For extracting knowledge from Twitter
streams, it uses Apache Spark [9]. And for news streams, it uses Tﬁdfvectorizer and
some machine learning algorithms.
Apache Spark is an open-source framework used for analyzing and processing
data. The proposed system creates a spark session, and it takes an input of an
anonymized Twitter stream. Then, it processes the stream and pushes the stream
into a spark streaming data frame [18]. After that, SQL queries applied to each
stream [19]. SQL query identiﬁes a hashtag along with its count. The streaming data
frame will contain two rows, a hashtag, and a hashtag count. The hashtag with the
highest count would be considered a trending crime hashtag. And depending upon
it, we can calculate awareness of the crime. Then, the data frame gets converted to

System for Analyzing Crime News by Mining Live Data Streams …
807
Python data frames. Python data frames go to a Flask where it gets visualized in
the form of a real-time graph. For every new entry of a data frame, a graph gets
updated [10].
Extraction of knowledge from news streams is a lengthy process; therefore,
to reduce the load on the machine, multithreading is used. Multithreading is the
process of concurrently running multiple threads for multiple tasks or subtasks. In
this process, for every city, a new thread is created. Along with multithreading, Tﬁd-
fvectorizer is used. Tﬁdfvectorizer is a Python library used for feature extraction. It
extracts the features for every type of crime. It works on the principle of identifying
the token from the news depending on the frequency weightage of the token. The
proposed system handles the speciﬁc type of crimes like sexual assault, ﬁnancial
fraud, cheating, smuggling, and murder. After identiﬁcation of features, Multinomi-
alNB naive Bayes algorithm is used for classifying the news into a particular type
of crime. MultinomialNB is commonly used for NLP. It works on the principle that
each record being classiﬁed is irrelevant to any other feature. To use MultinomialNB,
sklearn python library is imported.
7
Data Visualization
Data visualization is a phase in which all the streaming data is shown in a graphical
format. This phase is an output phase of the system and also the ﬁnal stage. The
system performs different steps such as extraction of the streaming data from both
the prime data sources, preprocessing for achieving clean data and to make it ready for
applying K-anonymization as the privacy preservation technique, sending it ahead
for processing in Apache Spark and machine learning unit. Now the ﬁnal step is
the visualization of the outcome for analysis.
The role of visualization is very essential in data mining or data stream mining
as the user needs an overview of the outcome, it helps to discover some interesting
patterns achieved from processing the data and also for valuable insights. The user
also needs to examine and analyze the predictions and statistics. The proposed system
represents three graphs on the dashboard as follows.
City VS Crime Rate: This graph is plotted using news streams from news Web
sites. Graph updates on a daily basis. This graph is a bar graph. It helps us to analyze
which city is a crime hotspot in real time for criminal activities being reported. As
and when the crimes are disclosed and broadcasted over the Internet, they are fetched
from the news Web sites, and it takes into consideration particular cities which are
selected for the analysis (Fig. 4).
Type of Crime VS Crime Rate: The graph is plotted using news streams. This
graph is a pie chart. Here, the principal focus is on the various types of crimes selected
for analysis instead of cities. The types of crime selected for this analysis are sexual
assault, murder, robbery, ﬁnancial fraud, smuggling, and cheating. For the pie chart,
the processed real-time news data stream is taken and utilized to plot the pie chart
based on the above-mentioned crime types and their individual statistics. The pie

808
R. Patil et al.
Fig. 4 Chart displaying a bar chart for city versus crime rates
chart is dynamic in nature and keeps refreshing as and when it receives updates from
the processed data from Apache Spark (Fig. 5).
Real-Time Trending Crime Topic: The real-time graph on twitter data gets
updated on every new entry of tweet. This is a line graph. It shows the count of
popular crime hashtags and its count (Fig. 6).
8
Limitations of the System
The system takes the input for streaming data and processes the data at runtime
without storing it. Therefore, the system takes some time to produce the result. As
discussed earlier, the system is devoted to the privacy preservation of data streams.
But data stream mining also has some other challenges like skewness of data and
delayed information. So, it is one of the limitations of the system.

System for Analyzing Crime News by Mining Live Data Streams …
809
Fig. 5 Chart displaying a pie chart for type of crime vs crime rates
9
Conclusion and Future Work
In this paper, we proposed a system for crime data stream mining along with privacy
preservation. Privacy preservation ensures the conﬁdentiality of the user-sensitive
data attributes while its processing is being carried out and also during the visualiza-
tion of results. It is achieved using the K-anonymization algorithm which anonymizes
or masks speciﬁc data values from the stream of data. Processing of data streams is
done using Apache Spark and multithreading. Our main contribution is developing
a system such that streaming data processing is done in real time and without the
need of storing it in any storage system or database. Moreover, in the implementa-
tion of this system, we have presented different graphs on streaming data as results
or outcomes. The visualization part depicts these results in the form of charts and
graphs using Chart.js which was presented in the frontend created using the Python
Flask framework.
Currently, the system is working only on Twitter data and news stream data.
Therefore, future work concerns more about the ingestion of different types of crime
and to reduce the compilation time.

810
R. Patil et al.
Fig. 6 Line graph showing real-time popular crime topic on streaming data from twitter platform
References
1. Nandi, A., Xhafa, F., Subirats, L., & Fort, S. (2020). A survey on multimodal data stream
mining for e-learner’s emotion recognition. International Conference on Omni-layer Intelligent
Systems (COINS), 2020, 1–6.
2. Reddy, P. P., & Sriram, K. (2021). A research study on the privacy preserving data mining
algorithms and the trend of stream data mining. International Journal of Engineering Research
& Technology (IJERT), 10(02).
3. Mehmood, E., & Anees, T. (2020). Challenges and solutions for processing real-time big data
stream: a systematic literature review. IEEE Access, 8, 119123–119143.
4. Perova, I., ova, B. Y., Miroshnychenko, N., & Bodyanskiy, Y. (2020). Information technology
for medical data stream mining. 2020 IEEE 15th international conference on advanced trends
in radioelectronics, telecommunications and computer engineering (TCSET) (pp. 93–97).
5. Segarra, C., Muntan´e, E., Lemay, M., Schiavoni, V., & Gonzalo, R. D. (2019). Secure stream
processing for medical data. In 2019 41st Annual International Conference of the IEEE
Engineering in Medicine and Biology Society (EMBC).
6. Navqvi, S., Endervy, S., Williams, L., Asif, W., Rajarajan, M., Potlog, C., & Florea, M. (2019).
Privacy-preserving social media forensic analysis for preventive policing of online activities.
2019 10th IFIP International Conference on New Technologies, Mobility and Security (NTMS),
IEEE.
7. Wang, J., Deng, X., & Li, X. X. (2018). Two privacy-preserving approaches for publishing
transactional data stream. In 2018 IEEE Translations and content mining.

System for Analyzing Crime News by Mining Live Data Streams …
811
8. Rutkowski, L., et al. (2020). Basic concepts of data stream mining. Stream data mining: algo-
rithms and their probabilistic properties, studies in big data 56. Springer Nature Switzerland
AG.
9. Evgenyevich, G. M., Valerievich, B. A., & Alekseevna, B. M. (2018). Using apache spark to
collect analytics from the streaming data processing application logs. 2018 7th Mediterranean
Conference on Embedded Computing (MECO), 1–4.
10. Sirisakdiwan, T., Nupairoj, N. (2019). Spark framework for real-time analytic of multiple
heterogeneous data streams. In 2019 2nd international conference on communication engi-
neering, and technology.
11. Sopaoglu, U., & Abul, O. (2017). A top-down k-anonymization implementation for apache
spark. IEEE international conference on big data (Big Data), 2017, 4513–4521.
12. Mohamed, M. A., Nagi, M. H., Ghanem, S. M. (2016). A clustering approach for anonymizing
distributed data streams. 978–1–5090–3267–9/16. IEEE.
13. Lal, D. K., & Suman, U. (2019). Towards comparison of real time stream processing engines.
IEEE conference on information and communication technology, 2019, 1–5.
14. Tortikar,P.(1970,January01).K-Anonymizationimplementationusingapachespark.Available
online https://library.ndsu.edu/ir/handle/10365/29524
15. Z_ai. (2020, April 01). Downloading data from twitter using the streaming API, medium.
Available online https://medium.com/@z_ai/downloading-data-from-twitter-using-the-stream
ing-api-3ac6766ba96c
16. Roesslein, J. Streaming with tweepy, tweepy 3.5.0 documentation. Available online https://docs.
tweepy.org/en/v3.5.0/streaming_how_to.html
17. Shousha, H. M. (2017, May 24). Apache spark streaming tutorial: ıdentifying trending twitter
hashtags, toptal engineering blog. Available online https://www.toptal.com/apache/apache-
spark-streaming-twitter.
18. DataFlair, Spark Streaming Tutorial for Beginners, DataFlair. (2018, November 21). Available
Online https://data-ﬂair.training/blogs/apache-spark-streaming-tutorial/
19. Bhadani, N. (2021, March 02) Apache spark structured streaming - ﬁrst streaming example (1
of 6), medium. Available online https://medium.com/expedia-group-tech/apache-spark-struct
ured-streaming-ﬁrst-streaming-example-1-of-6-e8f3219748ef

Webpage Portal for Crowd Sourcing
on Food Waste Management
C. S. Manikandababu, M. Jagadeeswari, R. Priyanka, S. Preethi, V. Rithika,
and J. Ravin Kumar
Abstract This paper represents a Web portal for crowd resourcing on food waste
management where the leftover food is donated to the needy and to people who
lack or suffer from food. The need for donation is due to the wastage of food. In this
present scenario, wastage of food is on large quantity in many places like restaurants,
weddings, social functions, college canteens, and many other social events. Some
people donate food manually by visiting some organizations. In order to reduce the
issue of food wastage, there are Web sites that have taken efforts to help people
donate food through online mode. This system provides a new approach where left-
over food is donated to needy people or organizations, for both governmental and
non-governmental people. The system is an effective means of donating food to
organizations, orphanages, etc., over the Internet. This has a potential for avoiding
the wastage of food. Using the Internet mode for donating food is mainly helpful
to the NGO organizations where they can raise the request for food. So, the donors
from the hotels and marriages can donate food to the wanted people by seeing the
request given on the Web site. It provides information that provides motivation to
come up with a successful application, thereby describing existing donation system
C. S. Manikandababu · M. Jagadeeswari · R. Priyanka (B) · S. Preethi · V. Rithika
Department of Electronics and Communication Engineering, Sri Ramakrishna Engineering
College, Coimbatore, Tamil Nadu, India
e-mail: priyanka.1702138@srec.ac.in
C. S. Manikandababu
e-mail: manikandababu.shelvaraju@srec.ac.in
M. Jagadeeswari
e-mail: hod-ece@srec.ac.in
S. Preethi
e-mail: preethi.1702135@srec.ac.in
V. Rithika
e-mail: rithika.1702148@srec.ac.in
J. R. Kumar
CG VAK Software & Exports Ltd, Mettupalayam Rd, Kuppakonam Pudur, Coimbatore, Tamil
Nadu, India
e-mail: ravin@cgvakindia.com
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_64
813

814
C. S. Manikandababu et al.
that works for the betterment of the society. A new donation request will be created
on the portal, and once the request is accepted, then the food request from food donor
to food receiver is processed and updated on the webpage.
Keywords SQL database · Visual studio · ASP.Net · Donor · Finder
1
Introduction
According to a recent survey, 1.3 billion food is wasted globally and one-third of it
is leftover food. This leftover food comes from restaurants, private functions like
marriages, etc. There are many NGO organizations and needy people suffering
without food, wherein the food from restaurants, marriages, and some social events
are been wasted deliberately. To overcome this food wastage, we can perform some
food donation process. In the initial stage, the food donation process was done manu-
ally. To make this process even more convenient and easy, online Web sites have taken
in charge for donating the food to the NGO organizations and to people who suffer
from hunger. This project focusses on developing a Web application portal where
the user could register themselves as a donor or a ﬁnder. The donors are mainly the
people from restaurants and caterers of the marriages. If the food gets wasted in their
place and are ready to donate them to the needy or NGO organizations, they can
register their details on this Web site. The ﬁnders are mainly the NGO organizations
that can be both governmental and non-governmental. The ﬁnders can register their
details saying the amount of food required for their organizations. By doing so, the
donors will be able to see the request given by the ﬁnders and can satisfy their needs
accordingly. The Web site will have all the details of both the ﬁnder and donor who
have all registered which can help in communicating between the donor and the
ﬁnder. This communication process might help the donors to donate the food to the
correct person without any confusion. The Web site also talks about the allocation
process where it contains allocated and not allocated details, whether the donor is
allocated to the correct ﬁnder. The Web application enables the donors to notify
the amount of leftover food, locality, and the time period of perishability, whereas
the ﬁnders register themselves the quantity of the required food. These details get
stored in the admin’s database. As per the requirements, the users can take away the
food. Thus, the portal displays the donor and the ﬁnder details at both ends. Once
the allocation process is done, the information about the request is pulled out of the
database, and every time new and new records will be updated. The Website is very
much helpful and useful in reducing the wastage of food and also satisﬁes the hunger
of the need.

Webpage Portal for Crowd Sourcing on Food Waste Management
815
2
Literature Review
India has the most malnourished and hungry population in the world. The survey
states 15.2% of our population is malnourished, 194.6 million folks go hungry every
day, 30.7% of children below 5 years of age are under-weight, 58% of children are
stunted by 2 years ago, 1 in 4 kids is undernourished due to poverty, 3000 kids in
India die daily from poor diet concerned illness, 24% of under 5 deaths in India
are due hunger, and 30% of neonatal deaths are in India. Mainly in India, there is
a loss of 1.4 billion tons of food each year. To overcome this food wastage, they
started to donate the food. The paper “Availability of food for NGO through Mobile
Application: Food For All” [1] is an Android application that is developed on Android
studio software using Java and xml. The application consists of the donor and the
volunteer of an NGO as main components. The donor and NGO can register/login
into the system. The system notiﬁes the ﬁnder about the donor details, and there
is a need for a third party vendor for delivery purposes. The NGO can check the
availability of food, and the donor can enter the availability of food. In this system,
a restaurant or company or institutes either waste tons of food daily or they have to
search for any charity which needs the food. The paper, “Food Wastage Reduction
Through Donation” [2] gives a detailed overview about leftover food donation. This
involves the efforts of calling various charities or NGO’s to contact them manually.
The paper “Sustainable Development: Drivers of Consumer Food” [3] gives the idea
for a food donation network. ˙It has presented an impact on the society through this
medium is known. This paper indicates the statistics of food wastage in restaurants,
private functions, and many other events. The paper “A Webportal for Medicine
Distribution among Poverty-stricken People” [4] also gives us an insight on the food
donation process. The disadvantage in this paper is that there is no other way than the
Android application. That means the system does not allow other operating systems
to view or donate the food as the user’s browser does not support the version of
the application. So the entire system cannot be viewed by all the person. The paper
“Design an Information Management System for a Pharmacy” [6] gives an overlook
of the design of a Web portal for donation purposes.
3
Proposed System
The main purpose of the project is to satisfy the food wastage through a donation
process where leftover food is donated to needy people, orphanages, poor people, or
NGOs over the Internet (Fig. 1).
The application consists of following modules:
1.
Administrator
2.
User registration and login
3.
Database creation
4.
Donation of the excess/leftover food

816
C. S. Manikandababu et al.
Fig. 1 Project ﬂow
5.
Claiming the excess food
6.
Allocation of a ﬁnder to a donor.
4
Module Description
4.1
Administration
In this module, the admin is given all the access to view all the user information.
The admin manages all the master information in the database like ﬁnder and donor
details. Admin could change the design, layout, and properties of the Web application
when necessary. Admin is also responsible for managing fake data of NGOs and
updating them in the database.
4.2
User Registration and Login
The portal allows users to register either as a donor or a ﬁnder. Once successfully
registered, the details get stored in the database. Then, the user could login as a ﬁnder
or a donor. NGOs, orphanages, and a group of people from a particular locality or
individuals could register in this Web portal. A ﬁnder can give details like name,
email, contact, name of organization if applicable, location, quantity of the food
required, and time. While a donor gives details like name, contact, email, number

Webpage Portal for Crowd Sourcing on Food Waste Management
817
of people the food could be served, time perishability of food, and location details.
This information gets stored in the admin database.
4.3
Database Creation
A database allows us to store the information related to a speciﬁc topic in the most
organized way. It helps to summarize the information of the stored data. Finally,
the information of the user gets stored in the database. SQL server database helps
in storing the details of the ﬁnder and donor. Once a successful donation process is
completed, the details get automatically pulled out of the ﬁnder table, and hence, the
database is updated.
4.4
Donation of Excess or Leftover Food
The excess food or leftover food from restaurants or any private functions like
marriages could be donated using this portal. After the registration process, the user
having excess food could login as a donor and give the required details. These details
are stored in the database and displayed at the ﬁnder end in the form of a table. A
view request page displays the ﬁnders who requested food. Finder details are also
displayed in the form of a table at the donor end.
4.5
Claiming the Excess Food
As the ﬁnder is able to view the donor details, in the not allocated page, the ﬁnder
could claim the donor according to their requirement. This action is initiated by
clicking the take button. Once the ﬁnder claims a donor, the status gets updated in
the database, and the not allocated table does not have the donor details who are
assigned to a particular ﬁnder. In this way, a ﬁnder could claim for food.
4.6
Allocation of Finder to a Donor
When the ﬁnder claims for food, the donor gets assigned to the requested ﬁnder. After
a successful donation, the database at the server-end gets a ‘taken’ status. Similarly,
all the donation process takes place, and a large amount of food wastage could be
avoided. The application is developed using HTML, CSS for front-end design, and
SQL database for server-end, and C# for back-end (Fig. 2).

818
C. S. Manikandababu et al.
Fig. 2 Block diagram
5
Methodology
5.1
Web Application Creation
STEP 1: The ﬁrst step is to create a new project in Visual Studio.
STEP 2: Customize your webpage with HTML and CSS for frontend design. C#
code is used for back-end interface.
STEP 2: Select ASP.net core Web application, providing a name and a directory for
the project which indicates the path of the project.
STEP 3: Choose the Web location for the created ﬁle. This indicates whether the
project has to be stored in https or ftp format. This project is built with the https
extension.
STEP 4: Select the.NET core version and Web API. By selecting controller from
solution explorer, we could add the controller method get() which deﬁnes the main
method for the Web API.
STEP 5: Web API URL is deﬁned, and it is copied to the get() method. Now the
project could be deployed on the Web.
5.2
Database Creation
STEP 1: Creating an empty database project in Visual Studio. Select SQL server
database project under Add > New Project.
STEP 2: Adding the essential credentials in the created database. This includes user
information like name, contact, and other user details.

Webpage Portal for Crowd Sourcing on Food Waste Management
819
STEP 3: Conﬁguring the database in SQL server. Import the database schema from
the existing database. Selecting the import option prompts with three options: Data-
tier application, database, and script. Database option is chosen. Then import settings
have to be set.
STEP 4: Authentication of the created database. After importing, we can see the
table’s views and stored procedures in our project window.
STEP 5: Connecting the Web site with the database through C# code. The created
database in the SQL server could be deployed in our Web application by providing
a connection.
5.3
Deploying in Web Server
STEP 1: The www root folder is the root for the Web site. The site contents like
HTML, CSS ﬁles, and library ﬁles are present in this folder
STEP 2: Conﬁguration of the Web site is done in appsettings.json
STEP 3: Privacy policy connections are established in IISExpress window
STEP 4: The project is built as a solution explorer window and published in Web
Server(IIS)
STEP 5: The deployment setting is chosen and the required setting is conﬁgured.
6
Results
The above ﬁgure is the homepage of the Web site. This page includes the options for
ﬁnder/donor login database which includes donor and ﬁnder details (Fig. 3).
Fig. 4 indicates the user registration. The user could register and login either as a
ﬁnder or donor.
Figures. 5 and 6 indicate the login page of ﬁnder and donor, respectively.
Figures 7 and 8 denote the database which is displayed in the Web site. The donor
database is displayed at the ﬁnder end and vice versa.
The ﬁnder request option in the menu as indicated in Fig. 9 provides access to the
donor database for the ﬁnders. This helps the ﬁnder to select the donor as per their
requirement (Figs. 10, 11 and 12) (Table 1).
Under the not allocated menu, the view request page is present that helps in
assigning a donor to a particular ﬁnder. Once the take option in this page is selected,
a donor is allocated to a ﬁnder. After successful donation, the database gets updated
automatically.

820
C. S. Manikandababu et al.
Fig. 3 Home page
Fig. 4 User registration
In the view donor menu, view donation page is present, wherein the details of
donation between the donor and ﬁnder are shown. It also shows the status whether
the ﬁnder has taken the food from the donor or not.
Additional page like about us menu is also present where it talks about the use of
donating wasted food to the needy and poor people.
7
Conclusion
On a daily basis, hundreds and thousands of tons of food get wasted, while the
needy and poor people suffer without food. To stop this issue, a mobile application
is developed, wherein the wasted food can be donated to needy people and NGO
organizations. The main aim of the product is to reduce the wastage of food and make

Webpage Portal for Crowd Sourcing on Food Waste Management
821
Fig. 5 Finder login
Fig. 6 Donor login
it beneﬁcial for people who suffer without food. This Web site is more convenient
for people to use and is very much beneﬁcial to the society. When there is wastage of
food, people can use this Web site telling the NGO organizations that they are ready to
donate and satisfy the hunger of the poor. We can also make this application feasible
and available for more NGO’s, orphanages, old age houses, and other organizations.
The advantage of this Web site includes food wastage prevention at hotels, prevention
of hunger for orphans and needy people, easy accessibility, and mobility of food on
request. The disadvantage of our Web site is the absence of live location tracking.
This feature could be included in the future scope of this project.

822
C. S. Manikandababu et al.
Fig. 7 Finder database
Fig. 8 Donor database
8
Future Scope
In the future, we can display live donation information where people can track the
location of food coming. By doing so, if there is any trouble in sending the food to
the organization, the donation process can be replaced by another donor such that
the hunger of the needy people is satisﬁed.

Webpage Portal for Crowd Sourcing on Food Waste Management
823
Fig. 9 Finder request
Fig. 10 View request

824
C. S. Manikandababu et al.
Fig. 11 View donation
Fig. 12 About us

Webpage Portal for Crowd Sourcing on Food Waste Management
825
Table 1 Database for ﬁnder
S. No.
Name of organization
Contact number
Address
1
Imayam social welfare
association
098659 44910
119/2, Lakshmipuram,
Ganapathy
2
Anbu public charitable
trust
0422 233 0190
59, Kannappa Nagar, 5th Street,
Rathinapuri, Coimbatore,
641027
3
Coodu Organisation
0422 231 6178
15-A, Kongu Nagar East„ Trichy
Road„ Ramanathapuram,
Coimbatore, Tamil Nadu 641045
4
Iragugal coimbatore ofﬁce
088447 17793
Peelamedu, Poonga Nagar, Civil
Aerodrome Post, Coimbatore,
Tamil Nadu 641014
5
Nizhal maiyam
Giri Nagar, Kuppakonam Pudur,
Coimbatore, Tamil Nadu 641030
6
Aishwariam ngo
0422 264 5101
Nggo Colony, Thudiyalur, Tamil
Nadu 641022
7
Satyagraha foundation of India
099429 92060
23, Vilankuruchi Rd, Phase Ii,
Cheran Ma Nagar, Coimbatore,
Tamil Nadu 641035
8
Sigaram foundation
098945 44778
Skc Building,
19–209894544778, Sigaram, 3rd
Floor, Mill Rd, Coimbatore,
Tamil Nadu 641001
9
Osai
0422 437 2457
70-A, Raju Naidu St, Sivananda
Colony, Tatabad, Coimbatore,
Tamil Nadu 641012
10
Let’s thank foundation
095666 55936
18, Rangaswamy Road,
Sukrawar Pettai, R S Puram
West, Coimbatore, Tamil Nadu
641002
11
Coimbatore multipurpose social
service society
094431 39152
Bishop’s House, Coimbatore,
Tamil Nadu 641001
12
Iconn—indigenous community
organization for natives and
nature—ngo
072008 20022
Ma - 190, 1st Block, Ganapathy
Maa Nagar, Coimbatore, Tamil
Nadu 641006
13
Sanjeevani health care trust
106, W Ponnurangam Rd, R S
Puram West, Coimbatore, Tamil
Nadu 641002
14
AA coimbatore miracle group
098430 09115
St. John De Britto Church,
Anaikatti Rd, Vincent Colony, R
S Puram West, Coimbatore,
Tamil Nadu
15
Rhythem social service society
for women
Nirmala College Campus, Red
Fields, Po, Coimbatore, Tamil
Nadu 641018
(continued)

826
C. S. Manikandababu et al.
Table 1 (continued)
S. No.
Name of organization
Contact number
Address
16
Esree foundation
No. 22, 4th Cross Rd, Saibaba
Colony, Kuppakonam Pudur,
Coimbatore, Tamil Nadu 641038
17
Family care
098940 58041
110, Prp Krishna Garden,
Peelamedu, Coimbatore, Tamil
Nadu 641004
18
Swachh coimbatore
093641 23123
Vivekananda Road Ramnagar
Landmark:Opposite To
Corporation Girls Higher
Secondary School, Coimbatore,
Tamil Nadu 641009
19
Dot foundation
072000 40874
Saravana Nagar, Tvs Nagar,
Coimbatore -641025 25,
Velnivas, Subramaniam Rd, R S
Puram West, Coimbatore, Tamil
20
Youth helping hands
097903 76745
No:16, Papammal Complex,
Lakshmipuram, [Near Textool
Bridge], Ganapathy, Coimbatore,
Tamil Nadu 641006
References
1. Panchal, V., Kuchekar, K., Tambe, S. (2020, Mar). Availability of food for NGO through
mobile application: food for all. International Research Journal of Engineering and Technology
(IRJET) e-ISSN: 2395–0056 07(03). www.irjet.net p-ISSN: 2395–0072.
2. Jethwa, D., Agrawal, A., Kulkarni, R., Raut, L. (2018, March). Food wastage reduction through
donation. 2018 International Journal of Recent Trends in Engineering and Research, 04(03),
[ISSN: 2455–1457].
3. Wasti., Chang, H. H. (2019). Sustainable development: Drivers of consumer food (2nd). Asia
conference on energy and environment engineering-ACEEE. IEEE.
4. Dhaka, B., Islam, M. N., Zavin, A., Srabanti, S., Ferdous, C. N., Suha, S. A., Afroze, L., &
Shawon, N., Refath, N. S. (2017, December). A webportal for medicine distribution among
poverty-strickenpeople.2017IEEEregion10humanitariantechnologyconference(R10-HTC),
21–23.
5. Masrom, S., Rahman, A. S. A., Azahar, F. N., & Omar, N. (2018). Food for you (F4U) mobile
charity application. International Journal of Recent Trends in Engineering and Research,
7(2018).
6. Zangana, H. M. (2018, October). Design an information management system for a phar-
macy. 2018 International Journal of Advanced Research in Computer and Communication
Engineering, 7(10).
7. Talati, N., Surve, O., Shah, J., & Kyal, K. (2017). Food donation portal. 2017 IJSRD—Inter-
national Journal for Scientiﬁc Research & Development, 4(11).
8. Elavarasan, M. S., & Nesakumar, C. D. (2019, October). Food wastage reduction mobile
application. 2019 International Journal of Computer Science and Mobile Computing, 8(10).
9. Manikandan1, J., & Kumar, N. (2020, March). Food waste reduction through donation. 2020,
International Research Journal of Engineering and Technology (IRJET), (07).

Webpage Portal for Crowd Sourcing on Food Waste Management
827
10. Mandal, K., Jadhav, S., & Lakhani, K. (2016, April). Food wastage reduction through donation
using modern technological approach: Helping hands. 2016, International Research Journal
of Advanced Research in Computer Engineering and Technology (IJARCET).
11. Freeda1, R. A., & Ahamed2, M. S. S. (2018, April). Mobile application for excess food donation
and analysis. 2018, International Journal Of Innovation Research In Science Engineering &
technology(IJIESET).
12. Rajendrakumar, S., More, A. N., & Hatture, S. (2021). Online medicine donation portal.
International Journal of Advance Research, Ideas and Innovations in Technology, 7(1).
13. Akshayapatra. https://www.akshayapatra.org/
14. Donate for food-for leprosy patients. https://www.leprosymission.in
15. Feeding America. https://www.feedingAmerica.org

Extensive Analysis of Global Presidents’
Speeches Using Natural Language
S. Nivash, E. N. Ganesh, K. Harisudha, and S. Sreeram
Abstract Over the last many years, sentiment analysis has evolved. A substantial
part of the work rotates around the examination of textual feelings utilizing the tools
of text mining. In any case, audio sentiment analysis is still coming to the present
stage to investigate network gatherings. The following article proposes to use Natural
Language Processing (NLP) to identify the effect of presidential speeches across the
world from 1970 to 2019 on the public’s mood, with positive and negative state-
ments presented. This paper includes an analysis of different speeches for sentiment
analysis in real time given by Global Presidents (positive and negative opinion) by
implementing different classiﬁcation techniques to predict the accuracy. Naïve Bayes
performed well without overﬁtting and underﬁtting with an accuracy of 86%.
Keywords Sentiment analysis · State union addresses · Natural language
processing (NLP) · Random forest (RF) · Naïve Bayes (NB)
1
Introduction
Elections make a major commitment to governing democracy. Since the full group of
competent residents in a direct democracy is impractical in the most recent civiliza-
tions, a suggested style of government in which policy decisions are decided directly,
voting governments must be carried out by agents [1]. Elections allow individuals
to select and hold pioneers in ofﬁce responsible for their exhibition. However, by
expecting pioneers to submit to regular and intermittent decisions, the opportunity
S. Nivash · E. N. Ganesh (B)
Department of Electronics and Communication Engineering, Vels Institute of Science,
Technology & Advanced Studies, Chennai, India
K. Harisudha
SRM Institute of Science and Technology, Kattankulathur, Tamil Nadu, India
e-mail: harisudk@srmist.edu.in
S. Sreeram
Master of Engineering Electrical and Computer Engineering in Data Science, Carleton University,
Ontario, ON, Canada
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_65
829

830
S. Nivash et al.
of managing them helps to address the issue of administrative advances and adds to
the continuing of the government’s primary rule [1]. Elections reinforce the political
network’s health and validity. Like public events perceiving necessary encounters,
races associate inhabitants to each other and thus insist on the country’s reasonability.
Accordingly, races help to encourage social and political coordination. Decisions
give residents political training and guarantee the responsiveness of majority rule
governments to the desire of individuals [2]. Prediction is exceptionally signiﬁcant,
and it is fundamental to science to see whether emotional reality coordinates with
the objective world. Yet, it is not generally a jubilee show game. Individuals have
been asking some of the time to foresee Kate Middleton’s various stuff that way. It
is not generally the thought, isn’t that so? [3]. US elections are unsurprising for a
couple of reasons. There are masses of surveying information: there are traditional
cross country surveys and, not at all like in the UK, surveys for every individual
state. “If we would have just had public survey information, we’d, in any case, have
had Obama ahead, yet with considerably less certainty.” We’d have made them win
signiﬁcantly a point rather than 2.5 focuses [Article from New York Times].
Natural language processing is amazing because it helps machines communicate
with people by speaking with people in their language and scales other tasks related
to language [4]. For example, NLP causes it doable for machines to comprehend
the substance and interpret it, measure assessment, and sort out which parts are
critical. The current machines shock us by investigating more data-dependent on
language than individuals, without weariness and in a predictable, unbiased way
[4]. Considering the astonishing proportion of unstructured data that is made every
day, from political decision shows to online media tweets, computerization will be
fundamental to separate substance and discourse data gainfully [5]. NLP is important
as it helps ﬁx linguistic obscurity and provides considerable numerical structure to
the data for certain downstream applications, for example, voice recognition or data
analysis [6].
Sentiment analysis is the best approach to recognize the tone and feelings commu-
nicated through-composed or spoken online correspondence, otherwise called senti-
ment mining or emotional AI [6]. Sentiment analysis performs information mining,
forms the outcomes, separates popular assessments of the content, and reaches essen-
tial resolutions. Sentiment analysis is the investigation of individuals’ feelings or
mentalities toward an occasion, discussion on subjects, or all in all. Predilection
analysis is utilized in different areas. Here, it is used to handle President Speech’s
effect on their State Union addresses to the public each year [6]. For a machine to
comprehend the President’s speech’s impact on the people, it has to realize what is
spoken, so actualize a web scraping framework to peruse the substance of addresses
through URL and perform predilection analysis on to the information collected from
earlierprocedures.UnderstandingtheimpactofthePresident’sspeechonthepublicis
useful under many instances. For example, let the computers know and predict before
the election which candidate will have a better chance of winning will be based on
candidate speeches on the public. It can suggest the user the usage of unique words,
word count, sentence length, etc. The specialist’s afﬁliation has tackled changing
sound materials, such as tunes, news, political speeches, and text content. With the

Extensive Analysis of Global Presidents’ Speeches Using …
831
advancement in technology, audio speeches are converted to text and are available
online. In [6], a methodology is used to read and interpret the speeches from a Web
source by using web scraping tools like the request and beautiful soup package from
the Python library. Natural language processing tools to perform tokenization, stem-
ming, lemmatization, and negation handling on the obtained data after web scrapping
the speeches from URL source are adopted. In order to understand what the presi-
dents were saying and what inﬂuences people in general, feeling is also incorporated
with the speech signal, which enables the engine to understand.
The background and related work of sentiment analysis is discussed in segment-II.
Segment-IIIcontainsaclariﬁcationabouttheproposedframework.Segment-IVdeals
with insights concerning the exploratory arrangement and Segment-V talks about
the different results obtained. The conclusion drawn from this project is explained
in Segment-VIII.
2
Related Work and Background
Various writing reviews are committed to growing new devices and advances for
nostalgic investigation for sentimental analysis. Sentiment analysis perceives the
sentiment communicated in a text and afterward looks at it to ﬁnd whether the
speech conveys positive or negative feelings. By and large, work on the investigation
of sentiment done on Naïve Bayes, decision tree, support vector machine, and ridge
classiﬁers [1–3]. Mostafa et al. [4] worked on each ﬁle’s information and named as
theoretical and target, and afterward, old-style AI methodologies are put in for the
emotional parts with the objective that the extremity classiﬁer overlooks the super-
ﬂuous or misdirecting terms. Since social events and denoting the in-arrangement is
repetitiveatthesentencelevel,thisprocedureisnothingyethardtotest.Toperforman
assumption analysis, they have utilized the accompanying strategies—Naïve Bayes,
linear support vector machines, and VADER [5]. What is more, a correlation is made
to locate a proﬁcient calculation for their motivation.
In paper [6], they did a sentiment analysis on the data taken from Twitter. They
utilized the cutting-edge unigram model as a benchmark and detailed a general addi-
tion of over 4% for two grouping errands: a parallel, negative versus positive, and a 3-
way plus versus minus versus unbiased. They introduced an exhaustive plan of inves-
tigations for both these undertakings on truly explained data that is an uncommon
illustration of a surge of tweets. Sentiment analyzer [7] works by removing notions
about a given subject. Assumption analysis contains a point explicit component term
extraction, feeling extraction, and relationship by relationship investigation Evalua-
tion analysis uses two semantic evaluation resources: the concluding dictionary and
the opinion plan bases. It reviews good and negative words and tries to evaluate the
scale−5 to +5.
Natural language processing (NLP) has, as of late, increased a lot of considera-
tion for speaking to and dissecting human language computationally. It has spread its

832
S. Nivash et al.
applications in different ﬁelds, such as machine interpretation, email spam recogni-
tion, data extraction, synopsis, clinical, question replying, etc. [8]. Right now recog-
nizes four stages by talking about various stages of NLP and parts of natural language
generation (NLG) trailed by introducing the history and development of NLP, best
in class raising the different uses of NLP and current patterns and difﬁculties.
In this paper [9], they present many new methodologies for text portrayal for
programmed grouping of Arabic printed records. These methodologies depend on
consolidating the notable bag-of-words (BOW) and the bag-of-concepts (BOC) text
portrayal plots and using Wikipedia as an information base. The proposed portrayals
are utilized to produce a vector space model, which thus is taken care of into a
classiﬁertoorderanassortmentofArabictextualarchives.ThreedistinctiveAI-based
classiﬁers have been used in this work. The display of proposed content depiction
models is surveyed conversely using a standard BOW contrive and a thought based
arrangement, similarly starting late uncovered near substance portrayal plots that
rely upon expanding the traditional BOW with the BOC.
Late advances in machines and innovation brought about an ever-expanding set
of records. The need is to characterize the arrangement of archives as indicated by
the sort. For dynamics, it is useful to lay associated papers together. Interdisciplinary
research analysts gain shops on several topics.
Grouping the vaults as per the issue is a genuine need to dissect the research papers.
In this paper [10], experiments are taken a stab at various authentic and counterfeit
datasets, such as NEWS 20, Reuters, messages, and investigative reports on changed
points. Term frequency-inverse document frequency calculation is utilized alongside
ﬂuffy K-implies and various leveled estimates. At ﬁrst, the trial is being completed
on a small dataset and implemented the bunch analysis. The best calculation is
applied to the all-inclusive dataset. Alongside the related records’ various bunch,
the silhouette coefﬁcient, entropy, and F-measure pattern are introduced to show
calculation conduct for every data set. In the paper [11], they suggested a sentiment
classiﬁcation model. Client surveys into good and negative audits using the ensemble
machine learning method. The proposed model is done using WEKA too, which
has certain limitations. For word removal, they are using uni-gram, bi-gram, and tri-
gramtechniques.Thisapproachprovidesgreateraccuracyanddiversiﬁedsentimental
polarity.
In this paper [12], the author represented nouns as sentimental words, which
positively impacted sentiment detection. Some words have duel sentiment based on
their application; mostly, those words are a noun. Yet, the accuracy is less compared
to other machine learning approaches. There needs to be some improvement done
on the dual sentimental analysis to increase the model’s performance.
In this paper [13], they have built a system that analyses sentiments based on
historical data to forecast prices over a future selling period and then use the dynamic
pricing model to increase revenue. Here, the raw data from tweets are converted into
JSON format, and parsing of data is done at ease, making the prepossessing much
efﬁcient. The scoring mechanism developed in the model and the generated time
series cannot predict sentiments of the matched tweets.

Extensive Analysis of Global Presidents’ Speeches Using …
833
In this paper [14], they have used the techniques and methods to perform sentiment
analysis: RNN algorithm and NLP. To improve the model’s competence, power, and
accuracy, they have introduced the Stanford library. Google Translate is being used
here to remove the linguistic issues. There is a major drawback with the Google
Translate; the accuracy with which the translator algorithm works is seemingly low,
and it needs some improvement. Moreover, there would be a delay in the process,
which might affect the model’s overall performance.
This paper [15] created an evaluation process based on weighted sentiment
analysis of product comment material in order to evaluate the dependability of e-
commerce items from a subject point of view more correctly and effectively. In this
process, they assessed the sentimental worth and usefulness of a certain set of e-
commerce goods for each comment. The large user data lower the performance and
index parameters of neural networks. There is still a need to enhance the computation
techniques utilized here. Picture comments are not examined and identiﬁed here in
the calculation of dependability. The reliability evaluation of the product with fewer
words is less accurate.
In this study, [16] they investigated the review text sentiment analysis for online
video utilizing big data analysis to estimate the user’s favorite video type based on the
algorithm reference value. This algorithm will help analyze the user’s favorite genres
and suggest videos based on the data analyzed. But the downside is that few more
parameters need to be considered, like impressions, trafﬁc sources for impressions,
views from impressions, and watch time from appearances to efﬁciently predict
the user-desired videos. This approach is currently implemented in the YouTube
algorithm. Sentiment polarity categorization, a fundamental problem in predilec-
tion analysis, is addressed in the paper [17]. The data is taken from Amazon.com
product reviews. Sentiment polarity classiﬁcation and POS tagger are implemented
to improve the performance. More innovative and efﬁcient machine learning tech-
niques are used instead of this model to overcome the performance issues faced with
opinion mining based on the POS taggers.
The two models for the categorization of short texts (i.e., sentimental context
Term model, C. sentimental context Topic model) were created in the study [18]
by incorporating emotional contexts. The results suggest that the feeling context
contributes to the categorization of feelings. This model has proved its performance
in a lesser number of data, but the topic-based models will get affected by the number
of selected topics.
In this paper [19], the sentimental analysis is calculated by collecting data from
ﬁve companies, i.e., Oracle, Microsoft, Google, Apple, and Facebook, in the form of
tweets and the user comments from the largest community of investors and traders
website, Stock twits. Here, the author fed the sentimental score with market values to
an artiﬁcial neural network, Levenberg-Marquardt algorithm, and used mean square
error to calculate errors and to predict the future market values. The use of an artiﬁcial
neuralnetworkistheprimaryadvantageofthispaper.Basedonthenumberofneurons
used, the efﬁciency varies. But I highly doubt this approach’s precision for a wide
variety of data, which would be its major disadvantage.

834
S. Nivash et al.
In this paper [20], the author takes a probabilistic approach in machine learning
techniques by using the Naïve Bayes classiﬁer for the amazon product review dataset
to improve the analysis’s overall performance. The major advantage of the classiﬁer
is that it is mainly based on the prior and posterior probability. The word occurrence
is mainly considered for this method. The accuracy of 89% still can be improved by
doing proper preprocessing and adding various datasets.
To anticipate the organization’s future extremity in this paper [21], they have
utilized the KNN calculation to store all the accessible cases and classify the new
instances dependent on the likeness measures. This approach’s main advantage is
the categorization for that they have used non-probabilistic binary linear classiﬁer—
SVM algorithm. For sentimental analysis, they have used tweets to classify positive
and negative words. All three of these results can be used by the investor to get the
accurate result about the next day’s trends before buying or selling its stocks. The
disadvantage is using three more parameters, which must be separately analyzed for
the market prediction.
To calculate the sentimental analysis in this paper [22], they have used Twitter
as an input data and used the Stanford core NLP, which provides a set of natural
language analysis tools to predict the sentimental value. The main disadvantage is
the lack of preprocessing and the limitation of the Stanford library.
In this paper [23], they have proposed a new word sentimental similarity calcula-
tionmethodtocomputeaword’ssentimentalvaluewiththemodiﬁedHowNetknowl-
edge, based on existing primitives, which is combined with transductive learning
for judgment words sentimental orientation, which is the main advantage. The
performance of this model is far superior to that of SVM and traditional semantic
comprehension.
To identify eight kinds of sentiment like joy, love, sorrow, disgust, surprise,
anxiety, anger, hate for the Chinese language reviews, in this paper [24], they have
used a sentimental agent identiﬁcation based on the Chinese corny sentence dictio-
nary. The sentence dictionary consists of sentence patterns that can be used to calcu-
late the conversations’ consistency and easily get rid of the sentences without senti-
ment. The model depends upon the texture of the sentimental sentence pattern that
needs improvement.
In this paper [25], they use the traditional classiﬁer Naïve Bayes classiﬁer to get
a set of positive, negative, and neutral sentences used for feedback. The clustering
operation is then done with positive and negative feedback. It determines the general
themes such as meal quality, atmosphere and service that received comments. K-
means clustering is thus used here.
With this strategy [26], Twitter tweets are continually downloaded and transmitted
to the Flume sink through the streaming API. The tweets are collected using the ﬂume
of Apache from Twitter depending on the user’s keywords. The tweets relating to
the IPL have been collected to ﬁnd the public and their ratings on IPL players and
their matches. The hashtag analysis, which classiﬁes the themes of the tweet, takes
place here in the continuation of emotional analysis. It also optimizes tweets and
maximizes the visibility of certain terms. Followed by count analysis, the analyst
learns what the individual could do on Twitter.

Extensive Analysis of Global Presidents’ Speeches Using …
835
In this paper [27], they have used a simple approach and used Twitter tweets and
comparing with ﬁles containing a dictionary of positive and negative words. The
sentiment score is calculated by considering the positive and negative words used
in the tweets, and these calculations can be used to do the sentimental analysis. But
there is a major drawback where the sarcastic conversations cannot be identiﬁed.
Electoral results can be predicted by analyzing social media feeds. In this paper
[28], they are using the concept of a decision tree to show the output with the help of
tree and nodes. It is a simple classiﬁer that helps in text mining. Naive Bayer’s is also
used here, and the results are compared between the decision tree and the Naïve Bayes
classiﬁer. Quite often, for visual image recognition CNN is used. It won’t be suitable
for analyzing the words because most online comments are short texts and always
have character limitations. The word embedding created by uncontrolled pretraining
with word-level embedding is highly dimensioned and sparsely represented. Unlike
the information in the RGB picture, the neighboring point in the word vector has no
signiﬁcant association [29, 30].
3
Problem Identiﬁcation
From the literature survey, it is evident that all the papers solely focus on opinion
mining, but not on the sentimental analysis of multiple feature classiﬁcation, which
targets the real-time issue faced when classifying president speeches. A speech might
have thousands of paragraphs in a real-time scenario, and a public mood might
have different opinions about each sentence. The overview of the project has been
explained in the below diagram.
Moreover, from all these papers, it is evident that the datasets used are from social
media sites like Twitter, Facebook, and e-commerce sites like Amazon. NLP models
are implemented on these datasets to ﬁnd the statistical opinion analysis of a speciﬁc
feature. But here, it is implemented to sentimental model for real-time president
speech data from the state union addresses and analyze based on the same.
4
Proposed Solution
The main scope of this project is to develop an efﬁcient sentimental analysis using the
NLP algorithm. The type of data set chosen here is from online resources like Wiki
source and Kaggle. The proposed solution uses Python NLTK as the main library, in
whichdifferentspeechesonthedatasetareanalyzed(positiveandnegativeemotions).
Then, we are going to use the classiﬁer like Naïve Bayes, AdaBoost, and random
forest. Once the model has been developed from the dataset, we will efﬁciently
strategize and plan speeches based on sentiment, it assigns for a speech. The block
diagram of the proposed methodology is shown in Fig. 1.

836
S. Nivash et al.
Fig. 1 Block diagram of the proposed methodology
5
Scientiﬁc Reasons
To improve the performance and create a highly efﬁcient model to do sentimental
analysis for real-time president speech data by using machine learning approaches,
which improves our machine learning results by combining several classiﬁers? We
are utilizing this technique in our predictive model to diminish differences.
The different classiﬁers such as random forest tree, AdaBoost, and naïve Bayes
algorithm are used to efﬁciently mitigate the feature classiﬁcation. Here for two
feature classiﬁcations, Naïve Bayes can go for multiple feature classiﬁcation.
Random forest tree is more suitable. Here we are going to experiment with both
classiﬁers and compare the efﬁciency to choose our ideal model. These classiﬁers
help in determining the speech sentiments given by Presidents (positive and negative

Extensive Analysis of Global Presidents’ Speeches Using …
837
Fig. 2 NLP methods in
sentiment analysis
opinion). To implement this feature, we are ﬁrst doing the text classiﬁcation (posi-
tive and negative words) using the NLTK library, a widely used Python library. The
diagram in Fig. 2 shows the steps involved in sentimental analysis.
5.1
Datasets
The dataset chosen for this project is from online resources through Kaggle, wiki
source, and Miller Center. President’s speeches on State Union Addresses and Annual
messages dataset describe the President’s speech from 1970 to 2019. On undergoing
through different speeches in the dataset, it is found that the speech’s tone was
different and that each speech’s length varied too. The opinions on various speeches
will be interesting to calculate on such datasets. Once data is cleaned and processed
using natural language processing techniques. First, sentiment analysis is applied
to predict the impact of positive or negative sentiment on our speeches and then
evaluated using classiﬁers. The bag of words and TF-IDF is used to predict the
accuracy.

838
S. Nivash et al.
6
Experiments and Methodologies
This part will examine the supervised ML calculations, which we are utilized in this
paper. This paper will use three ML calculations: random forest, Naive Bayes, and
AdaBoost.
(i)
Naïve Bayes:
In Naïve Bayes, all the info credits are thought to be autonomous of one another.
Bayes Theorem is the idea of the Naïve Bayes classiﬁer. They are called independent
Bayes or straightforward Bayes. For instance, a natural product can be named an
orange only because it is round, orange, and 8 cm in measurement. The classiﬁer
considers the highlights like circle shape, shading, and size freely before anticipating
it as orange. Gullible Bayes is regarded as straightforward, simple, and utilized in
the vast informational collection.
The least troublesome arrangements are by and large the huge ones, and naïve
Bayes is among them. Despite the phenomenal advances of machine learning in the
most re-penny years, it has exhibited to not only be fundamental yet furthermore
snappy, precise, and dependable. It has been utilized generally for some reasons.
Yet, it functions admirably with problems with natural language processing (NLP).
Naïve Bayes is a gathering of probabilistic algorithms that uses the probability theory
and Bayes theorem to foresee a book tag (like a digit of information or a customer
review). These are probabilistic, which means estimating each tag’s probability for
a given content, and a short time later yields the label with the essential one. How
they get these probabilities is by using Bayes theorem, which portrays the likelihood
of an element, considering primary data on conditions related to that feature.
(ii)
Random Forest:
Random forest is an ensemble supervised classiﬁer, which makes various or distinc-
tive choice trees, and toward the end it coordinates them to get more steady and exact
expectations. For preparing information, N irregular backwoods select N arbitrarily
created information with the adequate substitution of preparing the report. In the
wake of making a few trees, it makes pre-word usage to locate the ideal arrangement
by the larger part casting a ballot.
(iii)
AdaBoost
AdaBoost is an iterative algorithm that at every cycle extricates a powerless classiﬁer
from the arrangement of frail classiﬁers, and weight is being assigned to the clas-
siﬁer as indicated by its importance. The boosting procedure has pulled in a ton of
consideration among specialists to legitimize its outstanding performance in practice
and its relative immunity to overﬁtting.

Extensive Analysis of Global Presidents’ Speeches Using …
839
7
Architecture
The high-level architecture diagram of the project is given in Fig. 1.
(a) Design and Implementation
In this project, the dataset is taken from an online resource such as Miller and
Wikisource, which contains the URL links for President State of Union Addresses
and Annual messages.
A.
Data Preparation
There are four feature variables available in the dataset; if the data is imbalanced,
it can be balanced by adding a dataset. It is also the stage of data cleaning. We
use a library called “urllib request” to open the URL link. Beautiful soup, which
is supported by python 3.x, is used for web scraping. It is an HTML/XML parser
used to read and navigate through the URL’s contents. Once we have the content,
we tokenize the paragraph and store it in a corpus. We do cleaning, stemming, and
lemmatization/lemma for each word in the corpus, which are NLP steps. We use a
library called “regular expression” for substituting and replacing the data to remove
unwanted words when web scraped. We then perform stop word removal.
B.
Text processing
Text processing is the main step in toward the sentimental analysis. It converts the
text into the more readable form of data so that the machine learning algorithm could
perform better. The NLP techniques is achieved by using the NLTK python library.
There are speciﬁc NLP techniques we are using in this project. They are explained
below.
(i)
Tokenization:
Given a character succession and a characterized archive unit, Tokenization might be
characterized as the way toward breaking it up into pieces, called tokens, which may
be simultaneously discarding certain characters, for example, punctuation. These
tokens are regularly approximately alluded to as terms or words, yet it is time-critical
to make a type-token distinction. We use the Punkt sentence tokenizer from the NLTK
library. This tokenizer separates a corpus into a rundown of sentences. Utilizing a
solo calculation to construct a model for shortened form words, collocations, and
words that start sentences. It must prepare on a vast assortment of explicit content in
the objective language before it very well may be utilized. The NLTK information
bundle incorporates a preprocessed Punkt tokenizer for English.
(ii)
Stop Words Removal:
To improve the model and to expand the processing time, it is essential to expel the
stop words like “the,” “an,” “a,” wherein it takes additional memory space during
the procedure. Removing stop words are not a ﬁrm standard or fast rule in NLP. It

840
S. Nivash et al.
relies on the undertaking that we are dealing with. For errands like content grouping,
where the content is to be arranged into various classes, stop words are expelled
or barred from the given content to be given to those words that characterize the
content’s signiﬁcance. On evacuating stop words, dataset size reductions, and an
opportunity to prepare the model additionally diminishes. Removing stop words
can conceivably help improve the performance as there are less and just signiﬁcant
tokens left. Accordingly, it could expand order exactness. Indeed, Web search tools
like Google remove stop words for quick and essential recovery of information from
the database.
(iii)
Stemming:
For syntactic reasons, documents will use different kinds of words, for instance,
form, ﬁgures out, and orchestrating. Likewise, there are gatherings of derivationally
related words with similar ramiﬁcations. Both stemming and lemmatization aim to
reduce harmful structures and sometimes derivationally related word to an average
base structure. For instance: am, are, is can be decreased to base structure “be.”
Vehicle, vehicles, cars, vehicles’ can be diminished to base structure “vehicle.” The
consequence of this text planning will be something like the kid’s vehicles are various
tones brings about: the kid vehicle is diverse tone.
Regardless, the two words contrast in their ﬂavor. Stemming ordinarily insinuates
an unpleasant heuristic method that hacks off the pieces of the deals the desire to
achieve this target precisely, and as often as possible, fuses the removal of deriva-
tional appends. The popular measurement for stemming English, experimentally
successful, is given in Porter’s calculation (Porter, 1980). The total estimate is exor-
bitantly long and confounded here; notwithstanding, we will show its general nature.
Porter’s estimation contains ﬁve times of word diminishes, applied progressively.
Inside each stage, there are various shows to pick rules, such as determining the
norm from every standard assembly used to the longest postﬁx.
(iv)
Lemmatization:
Lemmatization, generally speaking, implies doing things ﬁttingly with the use of
a language and morphological examination of words, commonly aiming to oust
inﬂectional endings only and to re-establish the base or word reference sort of a word,
which is known as the lemma. At whatever point went looking with the symbolic
saw, stemming may restore. At the same time, lemmatization would try to return
either watch or saw subordinate upon whether the token’s use was as an activity
word or a thing. They may be distinguished between the two in derivative terms,
but lemmatization usually occurs in various types of lemma inﬂections. A further
module of the reference method periodically prepares to stop or to lemmatize and
there are several ﬁelds, both business and free-source.
C. Review Analysis
A list of positive and negative words in a text ﬁle is collected, and compare our
tokenize words with the list of words and count the number of positive and negative

Extensive Analysis of Global Presidents’ Speeches Using …
841
words. Each speech will have numerous amounts of positive and negative words. It
is essential to identify the count of positive and negative words to correctly classify
a speech that will have a positive or negative impact. Based on overall negative word
usage in all speeches, we will try to set a threshold for negative words used to classify
them as negative impact speech.
WordNet
WordNet is the lexical database, for example, word reference for the English
language, explicitly intended for natural language processing. Synset is a distinctive
sort of straightforward interface available in NLTK to investigate WordNet words.
Synset examples are the groupings of synonymous words that express a similar idea.
A portion of the words have just a single Synset, and some have a few.
D. Sentiment Polarity
After all the text processing, one needs to ﬁnd the sentimental polarity of the review
data. To determine the amount of positive and negative reviews in the dataset, for this
purpose, we are using the Python Vader library. If needed, further POS tagging can be
done, which improves accuracy. VADER (Valence Aware Dictionary and Sentiment
Reasoner) is a vocabulary and rule-based supposition examination apparatus that is
explicitly receptive to slants communicated in web-based social networking. VADER
utilizes a blend of A supposition dictionary is a rundown of lexical highlights (e.g.,
words), commonly marked by their semantic direction as either positive or negative.
VADER does not just tell about the positive and negative score yet; also, it enlightens
us regarding how positive or negative a supposition is.
E. Bag of Words
The bag-of -words (BoW) is a computation which checks the frequency with which a
word appears in a record. This is a count. This is a count. These word controls allow
us to think about archives and to quantify their similarities for applications such as
query, categorization of documents and subject modelling. On the off chance that
the new sentences contain new words, at that point, our jargonize would increment,
and, in this manner, the length of the vectors would increment as well. Moreover, the
vectors would likewise contain a huge number, accordingly, bringing about a meager
lattice (which is the thing that we might want to keep away from). We are holding
no data on the sentences’ language structure or requesting the words in the content.
F. TF-IDF
Term-frequency inverse document frequency (TF-IDF) is another approach to pass
judgment about an article by the words it contains. Words weigh with TF-IDF – TF-
IDF estimations are relevant rather than a recurrent one. This means that TF-IDF
scores for the full dataset are substituted for word checks. In the ﬁrst place, TF-IDF
measures the circumstances in which words are recorded (that is, “term recurrence”).
But since terms like “and” or “the” often appear in all records, for instance, they have
to be effectively restricted. This is the reverse section of the repetition report. The
more records a term appears, the less important is the term as an indication for any

842
S. Nivash et al.
archive to be separated, i.e., is expected to leave just the regular and unmistakable
words as markers. Each word’s TF-IDF pertinence is a standardized information
position that likewise signiﬁes one.
Bag-of-words makes many vectors containing word events in the record (audits),
while the TF-IDF model has data on the more important words and the less signiﬁcant
ones. BOW vectors are anything but difﬁcult to decipher. Nonetheless, TF-IDF, for
the most part, performs better in AI models.
G. Classiﬁcation
(1) Once all the pre-processing has been done, the vectorized words are split into
training data and testing data. The python library can achieve its Scikit learn. Then
Split data is used for training the model using Naïve Bayes and random forest clas-
siﬁers. Once the classiﬁcation has been done with the training dataset and with
testing data and then compare each classiﬁer’s accuracy and ﬁnally choose the best
performance model. The ROC and precision–recall curves are plotted.
In Fig. 3a, the sentiment scores of every president speech is listed which is used
for calculating the accuracy and the total number of speeches of president is shown
in Fig. 3b. The usage of words in all speeches indicates that 50% of the president’s
speeches range from 4800 to 10,000 words shown in Fig. 5 and can also see some
outliers and extreme data. Figures 7 and 8 supports Fig. 5 showing the number of
speeches by each party vs. party (Figs. 4, 5 and 6).
The plot 5 gives an idea to the upcoming President on the average number of
words used in a speech by previous presidents. The longest and shortest speech of
one President is shown in Fig. 5, and the box plot of words is shown in Fig. 6.
Figures 4, 5, 6 and 8, are all for better understanding and visualization purposes of
President Speeches.
Fig. 3 a Sentiment scores of every president speech b Total number of speeches of President

Extensive Analysis of Global Presidents’ Speeches Using …
843
Fig. 4 Words usage by each
party
Fig. 5 Longest and shortest
speech

844
S. Nivash et al.
Fig. 6 Box plot of words
Fig. 7 Number of speeches by each party
Fig. 8 Speech sentence length by Democrat and Republic party

Extensive Analysis of Global Presidents’ Speeches Using …
845
Fig. 9 ROC curve—NB
Fig. 10 Precision-recall
curve-NB
Word clouds are fun to use as a visual aid with blog posts to underscore the
keywords you’re focusing on. The public will see the bigger, intense words and
comprehend their signiﬁcance to speech (Figs. 9 and 10).
Furthermore, word mists are extraordinary for speakers to ensure you’re concen-
trating on the correct words in their addresses. The speech sentence length by
Democratic and Republic party is compared in Fig. 7.
In the present, where we’re experiencing information over-burden (even though
this doesn’t mean better or more profound bits of knowledge), organizations may
have heaps of client input gathered. However, it’s yet challenging for simple people
to investigate it physically with such a mistake or inclination. As a rule, organizations
with the best aims end up in an experiences vacuum. You realize you need bits of
knowledge to educate your dynamic. Also, you know that you are deﬁcient with
regards to them. Yet, you do not have the foggiest idea of how best to get them.
Sentiment analysis in Fig. 3 gives answers to what the most signiﬁcant issues are.
Since assumption examination can be mechanized, choices can be made dependent

846
S. Nivash et al.
Fig. 11 ROC
curve—random forest
Table 1 Performance metrics
comparison of classiﬁers
Performance
metrics
Naïve Bayes
Random forest
AdaBoost
Accuracy (%)
86
94
90
Precision
0.86
0.95
0.91
Recall
0.87
0.95
0.90
F-Score
0.86
0.95
0.90
on a lot of information instead of an understandable instinct that is not in every case
right.
Figures 9, 11, and 13 show the Receiver operating curve (ROC) for Naïve Bayes,
random forest and AdaBoost classiﬁer. The experimental results are shown in Table
1. The precision recall curve for all the three classiﬁers are shown in Figs. 10, 12,
and 14. The performance metrics such as accuracy, precision, recall, and F-score
is compared in Table 1. Random forest outperforms Naïve Bayes and AdaBoost
classiﬁer by 8% and 4%.
8
Conclusion
This work presents a generalized model that takes a website link that contains a
speech of a particular president and studies the content by automatically extracting
thespeechcontentinthewebsiteandstoresthespeechinacorpus.Rightnow,wehave
proposed a basic framework to do the previously mentioned task. The framework
functions admirably with the misleadingly created dataset. We are chipping away
at gathering a bigger dataset and expanding the versatility of the framework. Naïve
Bayes ends up being increasingly successful and beats random forest and AdaBoost.

Extensive Analysis of Global Presidents’ Speeches Using …
847
Fig. 12 Precision curve-RF
Fig. 13 ROC
curve—AdaBoost
Fig. 14 Precision
curve—AdaBoost

848
S. Nivash et al.
Both random forest and AdaBoost get overﬁt. It is common in these algorithms to
get overﬁt. It must be adjusted in tree size to reduce overﬁtting.
Overﬁtting is a shown mistake when a capability ﬁts too ﬁrmly into a limited
arrangement of information emphasis. Most overﬁtting the model appears to clarify
the speciﬁc features of the information examined by a model that is too confusing.
Hence, Naïve Bayes for natural language processing is advisable because, under
Naïve Bayes, we get 86% accuracy and do not see any overﬁtting or underﬁtting.
In contrast, for AdaBoost of 90% accuracy and random forest of 94% accuracy, we
ﬁnd the model to overﬁt. Also, one must always remember the most straightforward
model will yield the best result. Even though the framework is precise in fathoming
the speakers’ sentiment in speech data, it endures a few defects. At the moment, the
framework may be discussed by two speakers and only one speaker should speak at
a certain period in the debate. It cannot understand whether two people are talking
all the time. The future work would solve these difﬁculties and make the system
more precise and versatile. When we can predict outcomes of sentiment for election
speeches of elected presidents, if the same algorithm is applied for speeches of
presidential debate or speeches of incumbents, we can predict elections’ outcome.
References
1. Pang, B., & Lee, L. (2004). A sentimental education: Sentiment analysis using subjectivity
summarization based on minimum cuts. In Proceedings of the 42nd ACL (pp. 271–278).
2. Pang, B., & Lee, L. (2005). Seeing stars: Exploiting class relationships for sentiment catego-
rization concerning rating scales. In proceedings of the 43rd annual meeting on association for
computational linguistics (pp. 115–124). https://doi.org/10.3115/1219840.1219855
3. Pang, B., Lee, L., & Vaithyanathan, S. (2002). Thumbs up? Sentiment classiﬁcation using
machine learning techniques. In Proceedings of the ACL-02 conference on empirical methods
in natural language processing (Vol. 10, pp. 79–86). https://doi.org/10.3115/1118693.1118704
4. Shaikh, M., Prendinger, H., & Mitsuru, I. (2007). Assessing sentiment of text by semantic
dependency and contextual valence analysis. Affective Computing and Intelligent Interaction,
191–202.
5. Walker, W., Lamere, P., Kwok, P., Raj, B., & Singh, R., Gouvea (2004). Sphinx-4: A
ﬂexible open-source framework for speech recognition. SMLI TR2004-0811 c 2004 SUN
MICROSYSTEMS INC.
6. Hutto, C. J., & Gilbert, E. (2014). Vader: A parsimonious rule-based model for sentiment
analysis of social media text. Published in ICWSM 2014.
7. Yi, J., Nasukawa, T., Bunescu, R., & Niblack, W. (2003, November). Sentiment analyzer:
Extracting sentiments about a given topic using natural language processing techniques. In
Third IEEE international conference on data mining, 2003. ICDM 2003 (pp. 427–434). IEEE.
https://doi.org/10.1109/ICDM.2003.1250949
8. Khurana1, D., Koli, A., Khatter, K., & Singh, S. (2017). Department of Computer Science
and Engineering (2017) Natural Language Processing: State of The Art, Current Trends and
Challenges, publication- 319164243.
9. Alahmadi, A., Joorabchi, A., & Mahdi, A. E. (2014). Combining bag-of-words and bag-
of-concepts representations for Arabic text classiﬁcation. In 25th IET Irish signals and
systems conference 2014 and 2014 China-Ireland international conference on information
and communications technologies (ISSC 2014/CIICT 2014). https://doi.org/10.1049/cp.2014.
0711

Extensive Analysis of Global Presidents’ Speeches Using …
849
10. Bafna, P., Pramod, D., & Vaidya, A. (2016). Document clustering: TF-IDF approach. In Inter-
national conference on electrical, electronics, and optimization techniques (ICEEOT). https://
doi.org/10.1109/ICEEOT.2016.7754750
11. Alrehili, A., & Albalawi, K. (2019). Sentiment analysis of customer reviews using ensemble
method. In International conference on computer and information sciences (ICCIS). https://
doi.org/10.1109/ICCISci.2019.8716454
12. Chaki, P. K., Hossain, I., Chanda, P. R., & Anirban, S. (2017). An aspect of sentiment anal-
ysis: Sentimental noun with dual sentimental words analysis. INSPEC Accession Number:
18075945. https://doi.org/10.1109/CTCEEC.2017.8455159
13. Zhao, L. (2019). A dynamic pricing mechanism model based on sentiments analysis. In Inter-
national conference on intelligent transportation, big data and smart city (ICITBS).https://doi.
org/10.1109/ICITBS.2019.00155
14. Mahajan, D., & Chaudhary, D. K. (2018). Sentiment anlysis using RNN and Google trans-
lator. In 8th International conference on cloud computing, data science and engineering
(Conﬂuence). https://doi.org/10.1109/CONFLUENCE.2018.8442924
15. Zhang, X., Xie, G., Li, D., & Kang, R. (2018). Reliability evaluation based on sentiment
analysis of online comment. In 12th International conference on reliability, maintainability,
and safety (ICRMS), 2018. https://doi.org/10.1109/ICRMS.2018.00026
16. Liu, Z., Yang, N., & Cao, S. (2016). Sentiment-analysis of review text for micro-video. In
2nd IEEE International conference on computer and communications, 2016. https://doi.org/
10.1109/CompComm.2016.7924756
17. Pankaj, P. P., & Muskan, N. S. (2019). Sentiment analysis on customer feedback data: Amazon
product reviews. In international conference on machine learning, big data, cloud and parallel
computing (Com-IT-Con), India. https://doi.org/10.1109/COMITCon.2019.8862258
18. Zheng, W., Xu, Z., Rao, Y., Xie, H., Wang, F. L., & Kwan, R. (2017). Sentiment classiﬁcation
of short text using sentimental context. In International conference on behavioral, economic,
social-cultural computing. https://doi.org/10.1109/BESC.2017.8256405
19. Khatri, S. K., & Srivastava, A. (2016). Using sentimental analysis in prediction of stock
market investment. INSPEC Accession Number: 16544223. https://doi.org/10.1109/ICRITO.
2016.7785019
20. Surya Prabha, P. M., & Subbulakshmi, B. (2019). Sentimental analysis using Naive Bayes
classiﬁer. In International conference on vision towards emerging trends in communication
and networking (ViTECoN). https://doi.org/10.1109/ViTECoN.2019.8899618
21. Khatri, S. K., & Srivatsava, A. (2016). Capital market forecasting by using sentimental analysis.
In 2nd International conference on next generation computing technologies (NGCT), 2016.
https://doi.org/10.1109/NGCT.2016.7877381
22. Kisan, H. S., Kisan, H. A., & Suresh, A. P. (2016). Collective intelligence and sentimental
analysis of twitter data by using StandfordNLP libraries with Software as a Service (SaaS).
https://doi.org/10.1109/ICCIC.2016.7919697
23. Wen, B., Duan, S., Rao, B., & Dai, W. (2015). Research on word sentimental classiﬁcation based
on transductive learning. In 2015 8th International symposium on computational intelligence
and design (ISCID) 2015. https://doi.org/10.1109/ISCID.2015.244
24. Liu, D., Quan C., Fujiren, P. (2008). Sentiment and sentimental agent identiﬁcation based on
sentimental sentence dictionary. In International conference on natural language processing
and knowledge engineering, 2008. https://doi.org/10.1109/NLPKE.2008.4906802
25. Patil, A., Upadhyay, N. S., Bheda, K., & Sawant, R. (2019). Restaurant’s feedback analysis
system using sentimental analysis and data mining techniques. In International conference on
current trends towards converging technologies (ICCTCT) (Vol. 21, No. 17).
26. Kavitha, G., Save, B., & Imtiaz, N. (2018). Discovering public opinions by performing senti-
mental analysis on real-time twitter data. In International conference on circuits and systems in
digital enterprise technology (ICCSDET). https://doi.org/10.1109/ICCSDET.2018.8821105
27. Arora, T. B. Saxena, S. (2017). Sentimental analysis using fuzzy and Naive Bayes. In
International conference on computing methodologies and communication (ICCMC).

850
S. Nivash et al.
28. Gigi, N., & Kaur, A. (2018). Sentimental analysis on social feeds to predict the elections. In
ﬁrst international conference on secure cyber computing and communication (ICSCCC), 2018.
https://doi.org/10.1109/ICSCCC.2018.8703347
29. Kuresan, H., Samiappan, D., Ghosh, S., & Gupta, A. (2021). Early diagnosis of Parkinson’s
disease based on non-motor symptoms: A descriptive and factor analysis. Journal of Ambient
Intelligence and Humanized Computing. 1–15. https://doi.org/10.1007/s12652-021-02944-0
30. Masunda, S. et al. (2019, January). Fusion of WPT and MFCC feature extraction in Parkinson’s
disease diagnosis (pp. 363–372).

Photo-Realistic Virtual Try-On
with Enhanced Warping Module
Antony Alisha, C. V Amaldev, D. A Aysha Dilna, Sebastian Subin,
N. G Resmi, and G Sreenu
Abstract An image-based virtual try-on system focuses on virtually transferring a
clothing item to a given person. In most of the approaches, garment transfer on a
target image involves human parsing with pose estimation generating warped cloth,
followed by an inpainting module. The generated output depends on the attributes
of the ﬁnal and intermediate stages. In our paper, we organized a relative study of
methods adopted on different existing stages to bring up a better solution. We conduct
our studies with reference to a state-of-the-art try-on model named adaptive content
generating and preserving network (ACGPN). ACGPN transfers reference cloth to
the target person and gives photo-realistic try-on results but fails when there is large
dissimilarity in reference person image and cloth image which arises due to errors
in the warping module. We propose an improved ACGPN model, with a key-points
based warping module to improve the result.
Keywords ACGPN · Pose estimation · Human parsing · Key-points based
warping module
1
Introduction
In today’s pandemic situation, online shopping has gained a boom, and product
manufacturers and distributors are coming forward with various ways to market and
sell their products in the most proﬁtable way. Textile owners ﬁnd it hard to sell off
their items since they are hesitant to buy more clothes without trying them. Virtual try-
on offers customers a virtual clothing experience by helping them visualize how the
fabric would suit them. It transfers an image of a clothing item onto the corresponding
A. Alisha · C. V. Amaldev · D. A. Aysha Dilna · S. Subin (B) · N. G. Resmi · G. Sreenu
Department of Computer Science and Engineering, Muthoot Institute of Technology and Science,
Kochi, kerala, India
N. G. Resmi
e-mail: resming@mgits.ac.in
G. Sreenu
e-mail: sreenug@mgits.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_66
851

852
A. Alisha et al.
region of the person’s image. This has become a much-preferred application in the
e-commerce and fashion industry due to its convenience and the huge variety of
selections provided by the online stores. It helps the end-users to visualize themselves
in different outﬁts and thus making shopping much easier. People are more interested
in internet buying these days and virtual try-on enhances their shopping by providing
them a more personalized experience.
However, generating photo-realistic images through the proper and efﬁcient
rendering of a 3D cloth model on a human body, considering, human poses and self
occlusions, is challenging. Therefore, 2D clothing models are favoured as compared
to3Dmodels.2Dclothingmodelsusethegeneratedconfrontationnetworkforhuman
posture evaluation and analysis. Speciﬁc body parts and position of the body parts
are identiﬁed, and generative adversarial network (GAN) generates a warped image
of the clothing which is then applied to the image.
In this work, studies are conducted with reference to ACGPN model [1]. The
ﬁrst stage of ACGPN is a semantic layout generator that determines which region of
reference person needs to be generated. In ACGPN, the warped image is generated by
a spatial transformer network (STN) and applying thin-plate spline (TPS) transform.
The warping stage may produce incorrect results as it is solely based on the output
of the semantic generation module (SGM). In the proposed method, a key-points
detection strategy to effectively warp the cloth image based on the predicted key-
points of the reference person image is used. Key-points of the cloth image are
detected ﬁrst and are used to predict key-points on the semantic mask of the person,
and the warped image is obtained by employing a TPS transformer with key-points
as control points.
The remaining sections of the paper are organized as follows: Sect. 2 summarizes
our ﬁndings through literature surveys that were conducted, Sect. 3 explains in detail
about the proposed system, Sect. 4 contains results and discussions, and Sect. 5
discusses conclusion and future scope.
2
Literature Survey
Motivated by the rapid development of image synthesis, a virtual try-on network
called ACGPN is proposed in Zuo et al. [1] to solve the issues in recent try-on
networks. The image-based visual testing that aims to transfer the target clothing to
a reference person has received much attention in recent years. ACGPN predicts the
semantic format of the input image decides if its image content must be created or
protected by the planned semantics design, prompting a photo-realistic trial. Mainly,
it has three modules, a semantic layout generation module that utilizes semantic divi-
sion of the reference outline to foresee the ideal semantics format after the try-on, a
clothes warping module which distorts clothing images as per the generated semantic
layout, and an inpainting module for content fusion that integrates all information to
adaptively and responsively produce every semantic part in the human body. All the
generators in the semantic generation module and content fusion module have the

Photo-Realistic Virtual Try-On with Enhanced Warping Module
853
same structure. In contrast with the current strategies, ACGPN produces much better
results than others. The non-target body composition can manage different scenarios
in a ﬂexible manner in try-on tasks.
Yuying Ge et al. [2] present a virtual image test to match an image of a piece of
clothing with an image of a person. This method produces highly realistic images
without manual analysis. It regards the fake images obtained through the analyzer-
based method as “teacher knowledge,” which can be corrected by considering the
actual “teacher knowledge” extracted from images of real people.
Davis et al. [3] present a virtual try-on network (VITON) without the use of 3D
data. VITON transfers the desired garment over a person’s corresponding region
using a rough strategy. The appearance of the clothes strongly depends on the body
shapes and therefore how to transfer the target mode element depends on the location
of the different body parts and body shape. This framework generates a synthesized
image with the target clothing over-posed on that same person in the same pose. It
also improves the underlying obscured dressing zone with a reﬁnement network. The
network is framed to ﬁgure out how much detail to use from the objective article
of clothing and where to apply to the individual to incorporate a photograph with
a reasonable image in which the objective item normally twists with clear visual
patterns. It uses a human parser to extract the RGB channels of the person’s facial
and hair areas to inject identity information during the generation of new images.
Rosin et al. [4] propose CP-VTON+ (clothing shape and texture preserving
VITON) which performs better than VITON both qualitatively and quantitatively.
VITON works well for mono-coloured dresses with short sleeved and up to the front
poses, but not for the case with rich textured or long sleeves or a varied human pose.
In CP-VTON+, ﬁrst the wrong fashion agnostic human representation is corrected
and then the issues in warping networks. This model produces good quality images
but fails to produce results with complicated shapes.
Torr et al. [5] propose a two-phase cloth interactive transformer (CIT) for virtual
try-on tasks, the ﬁrst of its kind to use transformers. CIT can model an interactive
relation between the clothing and input person image which is ignored by a vast
majority of the current techniques. First phase uses a transformer-based matching
block that can demonstrate worldwide connections through the cross-modular trans-
former encoder. So the warped clothing becomes more appropriate and natural. It
can also ﬁt the person’s pose and shape more accurately. The second stage uses a
transformer-based reasoning block that establishes a mutual interactive dependence
to strengthen the signiﬁcant regions in the input data.
Choi et al. [6] propose a method called VITON-HD that successfully synthesized
1024 × 768 virtual try-on images which could overcome the limitation of the low
resolution of synthesized images due to the misalignment between the warped cloth
and the person’s body. It could also generate high-quality body parts and maintain
the texture sharpness of the clothes. The clothing-agnostic person representation uses
both the pose map and the segmentation map of the person to eliminate the clothing
information in the input image. Then, deform the dress image roughly aligned to the
input human body. After deforming the dress image, the alignment-aware segment
(ALIAS) normalization removes misleading information in the misleading area.

854
A. Alisha et al.
Then, the ALIAS generator maintains the clothing details by ﬁlling the misaligned
area with the clothing texture.
Neuberger et al. [7] introduce an outﬁt-viton (O-VITON) that empowers an
improved virtual try-on experience where the client can pick numerous articles
of clothing to be composited together into a practical looking outﬁt. The training
stage requires an enormous arrangement of single pictures of individuals wearing
different articles of clothing without 3D data. It combines pictures of different pieces
of clothing formed into a solitary, coherent outﬁt. It arranges a ﬁrm outﬁt from
numerous pictures of dressed human models, whilst ﬁtting the outﬁt to the body
shape and posture of the query individual. This algorithm precisely incorporates ﬁne
articles of clothing highlights like surfaces, logos and weaving utilizing an online
advancement plot that iteratively adjusts the synthesized image.
Yu et al. [8] present a virtual try-on network called VTNFP, which arranges
photo-realistic images given the pictures of a dressed person and objective clothing.
VTNFP follows a three-stage plan procedure, ﬁrst producing warped clothing trailed
by generating a body segmentation map of the individual wearing the objective
attire and ﬁnishing with a try-on synthesis module to combine all data for the last
picture combination. A critical advancement of VTNFP is the body segmentation
map prediction module, which gives basic data to manage picture blend in areas
where body parts and garments cross and is exceptionally gainful for preventing
foggy pictures and preserving dress and body part subtleties.
Rajetal.[9]introduceaswapnet,aframeworktoconveyclothesthroughtheimage
of a person in any position, shape or clothes. Clothing information is transferred
between two images describing a person in any position or shape which requires
jointly determining the posture, shape and clothing of the human body. Since it
is difﬁcult to obtain image pairs showing the same clothing on different bodies,
the method generates training pairs from the same image through extended data.
The latest method of clothing extraction and transfer involves three-dimensional
reconstruction of the human body and the estimation of predetermined tissue model
parameters.
Mir et al. [10] introduced an approach to switch textures of garb pictures (the
front and back) to 3-d clothes worn on pinnacle SMPL (skinned multi-person linear
Model), in actual time. Pairs of pictures are computed with aligned 3-d clothes with
the use of a custom non-inﬂexible 3-d to 2D registration approach. Using those pairs,
dense correspondences from garment photo silhouettes to a 2D-UV map of a 3-d
garment ﬂoor are examined, absolutely ignoring texture, which helps to generalize
to the huge variety of net pictures.
Toshev et al. [11] mention a strategy for human posture assessment based on
DNNs (deep neural network). The posture assessment is formed as a DNN-based
relapse issue towards body joints. DeepPose reﬁnes the coarse posture to improve
assessment utilizing a course of regressors. At the point when joints are anticipated
in DeepPose fell regressors, pictures are edited around that joint to take care of for
the following stage. This permits the resulting regressors to learn highlights for better
scales since a higher goal picture directs them to better exactness.

Photo-Realistic Virtual Try-On with Enhanced Warping Module
855
Simon et al. [12] propose a method to connect human body parts using part
afﬁnity ﬁelds (PAFs). This is mainly used to achieve a bottom-up multi-person pose
estimation model. This model identiﬁes the difﬁculties faced in ﬁnding individual
body joints involving a number of people in the image, the interaction between
them, irregular scale for each individual, etc. Using part conﬁdence maps, each joint
is determined, and the location and orientation of body parts are determined by PAF.
Li et al. [13] put forward an approach called self-correction for human parsing
(SCHP). Starting from a model prepared with incorrect explanations, a consistently
learning scheduler induces more dependable pseudo masks by iteratively amassing
the current learned model with the previous ideal one in an online way.
Lu et al. [14] suggest parsing R-CNN for instance-level human analysis, consid-
ering situations and different appearances, like human part division, thick posture
assessment, human-object connections and so forth. Models need to recognize
diverse human occasions in the picture board and learn rich highlights to address
the subtleties of each case. Parsing R-CNN is very adaptable and productive, which
is appropriate to numerous issues in human occasion investigation.
Girshick et al. [15] present a ﬂexible framework for object instance segmentation.
This approach called Mask R-CNN generates a segmentation mask for each instance
by detecting objects in an image. It adds a branch to predict an object mask in parallel
with the current branch to recognize bounding boxes. Mask R-CNN is an extension
of faster R-CNN. For every region of interest (RoI), mask R-CNN outputs a binary
map. Table 1 illustrates the comparison in the literature survey.
3
Photo-Realistic Virtual Try-On with Enhanced Warping
Module
3.1
Overview of Architecture
Figure 1 illustrates the proposed architecture which is an enhancement to the ACGPN
model.
The ACGPN model consists of four modules namely, semantic layout generator,
cloth warping module, non-target body part composition and content fusion module.
Similarly, the method discussed here contains four modules with a modiﬁcation to the
warping module that would enhance the result. The warping module of the proposed
system uses key-points on the cloth as well as the predicted body part mask to obtain
the warped cloth image.

856
A. Alisha et al.
Table 1 Summary of
literature survey
Method
Task
Dataset
Accuracy
ACGPN [1]
Virtual try-on
VITON
78.3
PF-AFN [2]
Virtual try-on
VITON
64.27
VITON [3]
Virtual try-on
VITON
77.2
CP-VTON +
[4]
Virtual try-on
CP-VTON +
84.25
CIT [5]
Virtual try-on
VITON
84.5
VITON-HD [6]
Virtual try-on
VITON
84.4
Outﬁt-VITON
[7]
Virtual try-on
O-VITON
76
VTNFP [8]
Virtual try-on
VITON
67.87
Swapnet [9]
Virtual try-on
FASHION IQ
83
PIX2SURF [10]
Virtual try-on
VITON
66
Deeppose [11]
Pose estimation
FLIC
69
PAF [12]
Pose estimation
COCO
70.7
SCHP [13]
Segmentation
LIP
59.36
Parsing R-CNN
14]
Segmentation
COCO
64.1
Mask R-CNN
[15]
Segmentation
COCO
71.4
Fig. 1 Proposed architecture with enhancement to ACGPN [1]
3.2
Algorithm
1.
Use SOTA (State-of-the-art) pose estimator [12] to detect 18 pose key-points in
the person image.

Photo-Realistic Virtual Try-On with Enhanced Warping Module
857
2.
Use SCHP [13] model to obtain parsing results. Reassign labels to obtain 14
class labels. Arms and torso region are fused together.
3.
Use Retinanet object detection to detect the type of cloth and Mask R-CNN to
detect key-points.
4.
Pass output of steps 1 and 2 to the semantic layout generator. It contains two
conditional GANs—G1 predicts the target body parts mask and G2 predicts the
target cloth mask [1].
5.
Pass the output of step 3 and target body mask from step 4 to the KPN (Kernel
Prediction Network) module to predict the key-points in the body mask.
6.
Pass the output of step 5 and cloth image to the warping module to obtain the
warped cloth image.
7.
Pass the warped cloth image to the CFM (content fusion module) which is
identical to the one in ACGPN [1] method to generate the try-on result.
3.3
Pose Estimator and Parser
The person image represented as a pose map, segmentation mask and cloth image
together comprise the input to the semantic layout generator. A prior pose estimator
called Openpose [12] is employed to generate the pose map in a Json format. The
method detects 18 key-points in the body and is a common pose estimator in most
of the try-on tasks. A content fusion module state-of-the-art human parser [13] is
used to obtain clothing segmentation of the reference image. The “self-correction
for human parsing” algorithm trained on the LIP dataset predicts 20 class labels of
the reference image. The insigniﬁcant class labels are reassigned to convert it to a 14
channel representation. The arms and torso regions are fused together to form input
to the semantic layout generator.
3.4
Semantic Layout Generator
The semantic layout generator used in our method is similar to the one in the original
ACGPN paper. The semantic layout generator follows a two stage strategy. At the
ﬁrst stage, the parser generator GAN G1 generates the target body mask based on
the fused parsing map, the pose heatmap and the cloth image. In the second stage the
pose map, the target mask and the cloth image are combined to generate synthesized
cloth mask by GAN G2. In both stages of the SGM, a conditional GAN is used. The
loss functions used are similar to those adopted in the original ACGPN paper.

858
A. Alisha et al.
3.5
Enhanced Warping Module
An enhanced warping module is a key feature of the proposed method. The warping
module aims to ﬁt the cloth on the target body according to the deformations caused
by the pose, whilst preserving the texture as well as text in the cloth. The warping
module of ACGPN is similar to those in VITON [3] and in CP-VTON [16] but
the geometric matching is obtained by a second-order difference constraint on the
network [1]. The warping module of ACGPN takes the cloth mask generated by the
SGM and also the target cloth image and by applying the TPS [17] transform after
STN [18] to generate the warped cloth image. The warped image is transformed by
learned parameters in STN and by applying the second-order difference constraint.
The warped image may contain artefacts due to the complex poses and the nature of
clothes. The main reason behind this is the warping module which is solely based
on the cloth mask generated by the SGM.
Here, a warping module that takes into account not only the generated mask but
also the predicted key-points on the reference person and cloth image is used. This
method uses a state-of-the-art key-points detector [15] to detect key-points in the
body. The mask R-CNN network [15] trained on Deepfashion 2 [19] dataset detects
key-points in the body.
3.6
Key-Points Detection
In our work, 3 types of clothes are considered: long sleeve, short sleeve and vest.
Retinanet object detection is employed to detect the 3 kinds of clothes. For detecting
key-points in the image, the mask R-CNN network is employed. There are 25, 33
and 15 key-points of short sleep top, long sleep top and vest, respectively, that are
deﬁned in the DeepFashion2 [19] dataset. The detected key-points are used to predict
the key-points of the reference person image and also to ﬁnd parameters in the TPS
network.
3.7
Key-Points Prediction Network (KPN)
The method proposed in KP-VTON [20] is used to predict the key-points in the
segmentation mask generated by SGM. The key-points prediction network comprises
a sequence of convolutional layers that serve as feature extractors. The network
predicts 256 parameters of the semantic mask generated by the SGM. The feature
extractor which extracts features from key-points of target clothes is a fully connected
layer whose output size is 256 [20]. The product of two branches is passed through
a fully connected layer to predict 66, 50 and 30 key-points for long sleeve top,
short sleeve top and vest, respectively. The warping of target cloth is performed by

Photo-Realistic Virtual Try-On with Enhanced Warping Module
859
matching between the predicted key-points on the segmentation mask and key-points
on the target cloth image. The warping is performed by using two algorithms TPS
and IMLS (image deformation using moving least squares) [21]. The warping control
points for each type of image is speciﬁed as:
• {2 to 7, 12 to 20, 25} for short sleeve,
• {2 to 7, 16 to 24,33} for long sleeve and
• {2 to 15} for vest.
For warping of key-points related to hand region IMLS [9] algorithm is applied.
• {8 to 11, 21 to 24} for short sleeve
• {8 to 15, 25 to 32} for long sleeve.
3.8
Content Fusion Module (CFM)
The ﬁnal try-on module used here is similar to the content fusion module of ACGPN.
It consists of two modules namely non-target body part composition and mask
inpainting module. In the non-target body part composition module, the mask of
the clothing area from the reference person is taken and combined with the semantic
layout to get the mask of the region that has to be generated. Combining the result
with the remaining mask and complement of the target cloth mask, the semantic
layout of the target image is obtained. From the original user image, the region to
be preserved is obtained by combining it with the complemented cloth mask. The
inpainting module generates a photo-realistic try-on a result by using a conditional
GAN. The warped cloth image, composite mask and preserved body region are given
as input to the GAN G3 to obtain the target image. Conditional GAN is used for fusing
and inpainting the given inputs to the target image.
4
Results and Discussions
In our method, a pre-trained open pose model is used for pose estimation, and the
model is trained on the COCO dataset which detects 18 key-points in the body.
Figure 2 shows the key-points detected by open pose for a reference person image.
For human parsing, the method “self-correction for human parsing’ discussed
earlier is employed to obtain the result and also referred to the ofﬁcial github repo
for implementation details. We used schp model pretrained on LIP dataset to obtain
parsing result. Reassignment of the class labels was performed to convert it to 14
class labels to ﬁt our application. Figure 3 illustrates the segmentation mask by the
original SCHP method and after reassigning to 14 class labels as used in our system.
In this paper, the warping module which was proposed in the KP-VTON paper is
utilized along with modiﬁcations to key-points detection. KP-VTON uses CPN [22]
for key-points detection. Mask R-CNN is used for this purpose. For comparative
studies, the image dataset shown in that paper was taken and performed warping

860
A. Alisha et al.
Fig. 2 Key-points detected by pose estimator
Fig. 3 Results obtained by SCHP
using ACGPN’s warping module and observed better results for KP-VTON. Figure 4
illustrates results obtained by the warping module of ACGPN and KP-VTON which
shows the superiority of the latter method. ACGPN performed well with images
where the warping is performed for the cloth of the same type, i. e. ﬁtting short
sleeve on the short sleeve but, whilst ﬁtting long sleeve dress on short sleeves, the
warping module gives greater artefacts. For inpainting, ACGPN’s method is more
superior, and hence the same was chosen for the proposed system.
The entire network is trained on VITON dataset. The dataset contains 16,253
pairs of images of a person and a clothing item. The dataset is split into 11,380 for
training and 4873 for testing. SOTA pose estimator and parser are used to obtain
the pose map and segmentation mask as mentioned above. Retinanet object detector
detects the type of clothes and mask R-CNN predicts key-points. These models are
trained on Deepfashion2 dataset as VITON does not provide key-points for cloth
images. The KPN module is trained for 20 epochs and the warping module for 20
epochs. Batch size for the training setup is 8. The training is done on Google Colab.

Photo-Realistic Virtual Try-On with Enhanced Warping Module
861
Fig. 4 Comparison of warping results by ACGPN and KP-VTON
Due to GPU limitation, ETA for the training process is shown as 16 days. Hence,
the training phase for obtaining the ﬁnal model is in progress, and the experiments
and research done so far show that the ﬁnal results will be better than the original
ACGPN method.
5
Conclusion and Future Scope
In this paper, a virtual try-on network that can virtually transfer clothing images to
a targeted person’s image is presented. It is an enhancement of the ACGPN method
with a change in the warping module. The warping pipeline of the proposed method
follows detection of key-points in the cloth, followed by KPN network and then
applying TPS transform to obtain warped cloth image.
The proposed architecture would bring outstanding results in terms of various
benchmarks. The practical implementation work is in an unfolding stage. The major
challenges to such a kind of project are return due to poor ﬁt, causing the e-commerce
players huge loss. This also becomes a disappointing experience for the customers
if he/she has to yet again wait for another few days. Not only the sizing but also
the actual fall, drape and look of the garment remains another matter of concern in
online shopping.

862
A. Alisha et al.
References
1. Han, Y., Zhang, R., Guo, X., Liu, W., Zuo, W., & Luo, P. (2020). Towards photo-realistic virtual
try-on by adaptively generating↔preserving image content. In IEEE conference on computer
vision and pattern recognition.
2. Ge, Y., Song, Y., Zhang, R., Ge, C., Liu, W., & Luo, P. (2021). Parser-free virtual try-on via
distilling appearance ﬂows. CVPR.
3. Han, X., Wu, Z., Wu, Z., Yu, R., & Davis, L. S. (2018). VITON: An image-based virtual try-on
network. In IEEE conference on computer vision and pattern recognition.
4. Minar, M. R., Tuan, T. T., Ahn, H., Rosin, P. L., & Lai, Y. K. (2020). CP-VTON+: Clothing
shape and texture preserving image-based virtual try-on. In IEEE conference on computer
vision and pattern recognition.
5. Ren, R., Tang, H., Meng, F., Ding, R., Shao, L., Torr, P. H. S., & Sebe, N. (2021). Cloth
interactive transformer for virtual try-on. arXiv preprint arXiv:2104.05519.
6. Choi, S., Park, S., Lee, M., & Choo, J. (2021). VITON-HD: High-resolution virtual try-on via
misalignment-aware normalization. In CVPR.
7. Neuberger, A., Borenstein, E., Hilleli, B., Oks, E., & Alpert, S. (2020). Image based virtual
try-on network from unpaired data. In CVPR.
8. Yu, R., Wang, X., & Xie, X. (2019). VTNFP: An image-based virtual try-on network with body
and clothing feature preservation. In ICCV computer vision foundation.
9. Raj, A., Sangkloy, P., Chang, H., Hays, J., Ceylan, D., & Lu, J. (2018). SwapNet: Image based
garment transfer. ECCV computer vision foundation.
10. Mir, A., Alldieck, T., Pons-Moll, G. (2020). Learning to transfer texture from clothing images
to 3d humans. In CVPR.
11. Toshev, A., & Szegedy, C. (2014). Deep pose: human pose estimation via deep neural networks.
In IEEE conference on computer vision and pattern recognition.
12. Cao, Z., Simon, T., Wei, X. E., & Sheikh, Y. (2017). Realtime multi person 2d pose estimation
using partafﬁnity ﬁelds. In IEEE conference on computer vision and pattern recognition.
13. Li, P., Xu, Y., Wei1, Y., & Yang, Y. (2019). Self-Correction for Human Parsing. In IEEE
conference on computer vision and pattern recognition.
14. Yang, L., Song, Q., Wang, Z., & Jiang, M. (2019). Parsing R-CNN for Instance-Level Human
Analysis. In IEEE conference on computer vision and pattern recognition.
15. He, K., Gkioxari, G., Dollar, P., & Girshick, R (2017). Mask R-CNN. In International
conference on computer vision.
16. Wang, B., Zheng, H., Liang, X., Chen, Y., Lin, L., & Yang, M. (2018). Toward characteristic-
preserving image-based virtual try-on network. ECCV.
17. Duchon, J. (1977). Splines minimizing rotation-invariant semi norms in sobolev spaces.
Constructive theory of functions of several variables.
18. Jaderberg, M., Simonyan, K., & Zisserman, A. (2015). Spatial transformer networks. Advances
in neural information processing systems.
19. Ge, Y., Zhang, R., Wang, X., & Luo, P. (2019). Deep fashion 2: a versatile benchmark for
detection,poseestimation,segmentationandre-identiﬁcationofclothingimages.InProceeding
of the IEEE conference on computer vision and pattern recognition (pp. 5337–5344).
20. Pham, D. L., Nguyen, N. T., & Chung S. T. (2020). Key-points-based 2D virtual try-on network
system. Journal of Korea Multimedia Society.
21. Schaefer, S., McPhail, T., & Warren, J. (2006). Image deformation using moving least squares.
ACM Transactions on Graphics, 25(3), 533–540.
22. Chen, Y., Wang, Z., Peng, Y., Zhang, Z., Yu, G., & Sun, J. (2018). Cascaded pyramid network
for multi-person pose estimation. In Proceeding of the IEEE conference on computer vision
and pattern recognition.

Convolutional Neural Networks
Hyperparameters Optimization Using
Sine Cosine Algorithm
Nebojsa Bacanin
, Miodrag Zivkovic
, Mohamed Salb
,
Ivana Strumberger
, and Amit Chhabra
Abstract The most challenging task in the machine learning domain is optimizing
the hyperparameters in convolutional neural networks. This task is representative
of NP-hard problems, and consequently, it is not possible to solve it by applying
standard deterministic approaches in an acceptable amount of time. Additionally,
convolutional neural networks’ hyperparameters must be optimized for each partic-
ular problem, as there is no solution that ﬁts all possible applications. Swarm intel-
ligence metaheuristics have been established as efﬁcient optimizers, and this paper
proposes the enhanced sine cosine algorithm to address the task of hyperparame-
ters optimization. The experiments conducted in this research were executed with
the CIFAR-10 benchmark dataset. The experimental results were analyzed and val-
idated against other proven metaheuristics approaches, and it can be concluded that
the presented enhanced sine cosine approach outperformed other methods included
in this research.
Keywords Machine learning · Swarm intelligence · NP hardness · Convolutional
neural networks · Neuroevolution · Sine and cosine algorithm · Optimization
N. Bacanin (B) · M. Zivkovic · M. Salb · I. Strumberger
Singidunum University, Danijelova 32, Belgrade 11000, Serbia
e-mail: nbacanin@singidunum.ac.rs
M. Zivkovic
e-mail: mzivkovic@singidunum.ac.rs
M. Salb
e-mail: mohamed.salb.16@singimail.rs
I. Strumberger
e-mail: istrumberger@singidunum.ac.rs
A. Chhabra
Guru Nanak Dev University, Amritsar, Punjab, India
e-mail: amit.cse@gndu.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_67
863

864
N. Bacanin et al.
1
Introduction
Machine learning or ML refers to the computer systems and programs that learn from
a speciﬁc task to evolve and enhance their performance, in the absence of additional
programming. Machine learning relies on human involvement to learn (datasets with
labelsarerequired),somachinelearningcanunderstandthevariationsbetweeninputs
data, which is also known as supervised learning. Another important area is deep
learning, a subset of the wider domain of machine learning, and can also use labels
with datasets to instruct the system, but it does not always need a labeled dataset to
train itself and evolve, because deep learning can use unsupervised learning. A deep
learning algorithm will demand more data to increase its accuracy, while a machine
learning algorithm will use fewer data due to the underlying data structure.
Deep learning consists of several “layers” of basic processing units that are joined
in a network so that the system’s input is transmitted into each one in turn just like
the human brain which is known as the most compound, nonlinear, and parallel
system capable of executing tasks much quicker than any computer, such as the
recognition of different patterns, awareness, and control of movement. Additionally,
other features, including the learning capability, the memorizing and generalizing
abilities, have contributed to the development of the algorithmic models of compound
neural systems inspired by biology, also known as artiﬁcial neural networks (ANNs)
[24].
ANNs have frequently been applied in a variety of areas over the last two decades,
including classiﬁcation, prediction problems, regression, pattern recognition, signal
processing, and robotics. Based on the input data given to it, ANNs must calculate
the best weight and bias for each node in the network which is known as the training
process, so it can generate accurate output data. As a result, the training process
for artiﬁcial neural networks strongly impacts the network performance. But using
ANNs alone is not enough due to the number of parameters that ANNs might contain
with it for solving complex problems. This problem can be addressed by utilizing the
convolutional neural networks (CNNs) that can be utilized to decrease the number
of parameters in ANNs.
Convolutional neural networks also known as (CNNs, or ConvNets) are a sub-
set of deep learning models that have been utilized with great success to address a
broad spectrum of different digital image processing tasks and shown exceptional
performance on that matter. CNNs have many uses like image recognition, image
classiﬁcation, face recognition, eye movement analysis, detecting different anoma-
lies, discovering the hidden drugs, natural language processing, assessment of the
potential health hazards and age biological markers, object tracking, and many other
applications [19–22].
CNNs have recently become a very popular area even though the work in this
ﬁeld started primarily a few decades ago. It is all started in 1959, when Hubel and
Wiesel [12] published their work, which was one of the most important publications
in this ﬁeld. They carried out a variety of studies in order to better understand how
neurons in the visual cortex function. Their experiments have revealed that the brain’s

Convolutional Neural Networks Hyperparameters Optimization …
865
main visual cortex is organized hierarchically with a combination of the elementary
and compound neurons and that visual processing always begins with elementary
structures of the observed environment, like oriented edges, and that complex higher-
order neurons receive input from the elementary neurons found in lower levels.
After about a decade time in 1980, a researcher with the name Fukushima created
neocognitron [11], that was the ﬁrst practical model of an artiﬁcial neural network.
This neocognitron had the same core logical structure of simple and compound cells
just like the one revealed by Hubel and Wiesel. Fukushima constructed a hierarchical
structure of different layers of simple cells (known as S-cells) and complex cells
(known as C-cells), where those cells have similar properties to the ones in the
brain’s visual cortex. The simple cells with modiﬁable parameters, and on the other
hand, the complex cells performed pooling on the top of them. After few years, in
1989, LeCun applied backpropagation mechanism to the neocognitron, achieving a
one percent rate of errors and a nine percent rate of rejections on zip codes [16].
A decade later, by employing an error gradient-based learning algorithm, LeCun
further enhanced the model. Therefore, LeChen method became the basis of modern
computer vision.
Alex Krizhevsky presented in 2012 the ﬁrst deep convolutional network, known as
AlexNet [15]. It obtained remarkable performances, and this success revolutionized
the computer vision domain. The uses of technologies such as graphical process-
ing units (GPUs), ReLU activation function, data augmentation, and the dropout
regularization technique were also the reason behind the success of AlexNet.
Building CNNs involves a number of conﬁgurations that are independent of the
data and must be manually tuned by the machine learning experts. Hyperparame-
ters are factors in the network conﬁguration and the CNNs trained network. The
hyperparameter optimization problem often includes determining a range of hyper-
parameters that produces an accurate model in a considerable amount of time. The
best manual conﬁguration outputs are then modeled and applied in CNNs. Even so,
various datasets actually require different models or hyperparameter combinations,
which can be time-consuming and unpleasant.
OneofthegreatestchallengesforCNNsistodeﬁneasuitablenetworkstructurefor
a particular problem requires tuning hyperparameters in order to increase the solution
accuracy. This particular task is very time-consuming and necessitates signiﬁcant
work and of course expert people in this ﬁeld. As the search space for the solution is
too large and it is not possible to try all the possible solutions for such a problem in
a polynomial time, that is why such a problem is considered to be NP-hard problem,
and cannot be solved using usual algorithms. The metaheuristics algorithms such as
swarm intelligence algorithms can be utilized to counter the NP-hard problem and
obtain a solution that might not be the exact one but it will be close enough to the
desired result.

866
N. Bacanin et al.
1.1
Optimizing the Hyperparameters of Convolutional
Neural Networks
Convolutional neural networks just like any natural networks contain several layers
to help the CNNs in the training process to gain the best possible accuracy for the
provided input. These layers are deﬁned as follows: convolutional, pooling, and dense
layers, respectively.
The ﬁrst layer in the network receives the images on its inputs and convolves them
by using ﬁlters and then applies the activation function to the output. By using this
pattern, low-level features are removed from the image, and the output result of this
layer acts as the input for the subsequent layer, with each following layer extracting
even more sophisticated high-level features. Afterward, the pooling layer is employed
for down-sampling and can be either maximum or average pooling. Finally, the CNN
structure contains a single or several ﬂattened dense layers, and the last layer at the
end has the task to classify the image. Many optimizers have been proposed in the
recent literature, including stochastic gradient descent, adagrad, rmsprop, adadelta,
adamax, momentum, and Adam [10, 34] in the weight learning process, to optimize
the loss function during network training.
In case that the training and the testing accuracy differ signiﬁcantly, the CNN will
be incapable of predicting any new inputs, and this situation is known as overﬁtting
and can be avoided by using different regularization techniques, for example, L1
and L2 regularization methods, drop connect, batch normalization, dropout, data
augmentation, and early stopping.
The activation function executed over the convolved output is used to map the set
of inputs to a nonlinear output. The sigmoid, tanh, and rectiﬁed linear unit (ReLU)
are three of the most commonly used transfer functions. The most common choice
of the transfer function selection is ReLU, that can be mathematically denoted as
f (x) = max(x, 0).
The following describes the execution in the convolutional layer and the process
of applying the activation function:
z[l]
i, j,k = a(w[l]
k x[l]
i, j + b[l]
k )
(1)
Where z[l]
i, j,k represents the activation map, and wk is the kth ﬁlter, xi, j refers to the
input at the i, j location, and the bias term is represented by b. And the superscript
l indicates the lth layer, and ﬁnally, the activation function is denoted as a(.)
An adequate structure is required to build CNNs, and this structure in return
needs suitable variables which are known as hyperparameters. These hyperparame-
ters include the quantity of convolutional layers and kernels in every convolutional
layer, kernel size in every convolutional layer, pooling size (if the pooling exist)
after every convolutional layer, number of dense layers, activation function, number
of neurons, connectivity pattern, dropout rate, weight regularization, learning rate,
batch size, and learning rule. Since there is no general law for determining the best
network structure for a given problem, it is required to establish a new design for

Convolutional Neural Networks Hyperparameters Optimization …
867
each particular problem and this issue is identiﬁed by the modern publications as the
hyperparameter optimization task.
Many researchers have attempted to create a system that can generate, train, and
validate various CNN architectures to obtain the one that is the most suited for
a speciﬁc role using metaheuristics methods [31]. This led to neuroevolution [5],
which is the method of automatically ﬁnding the right CNN structures for a given
task using metaheuristics algorithms.
1.2
Objectives
The goal of the research performed in this manuscript is to use an enhanced sine
cosine algorithm (SCA) to boost the process of automatic learning of the efﬁcient
architectural structure and the best possible combination of the hyperparameters of
the CNN without human interaction. This process is very time-consuming when done
manually, it has to be performed for each particular problem instance as there is no
general solution, and at the end, it is mostly based on the trials and errors.
1.3
Structure of the Paper
The rest of this document is organized in the following order. Section2 dives into
related works from the CNNs area that are present in many of the recent computer sci-
ence publications and a brief overview of the swarm intelligence approaches together
with hands-on implementations, after that Sect.3 describes systematically the pro-
posed method. Section4 explains the studies that were carried out and provides the
experimental results. At the end, Sect.5 delivers the conclusion and proposes future
studies.
2
Overview of Convolutional Neural Network and Related
Work
Convolutional neural networks have exhibited exceptional performance in a highly
challenging learning process. CNNs have established to be especially effective in
processing signals and time series of various types, as well as image, audio, and
video processing. The implementation of effective signal preprocessing and feature
selection systems to generate sufﬁcient structures capable of the classiﬁcation chal-
lenge is a fundamental part of the solution to these problems. After all, because of
their capability for automatic extraction of the useful features, CNNs have resulted

868
N. Bacanin et al.
that the preprocessing is redundant in many applications where it was previously a
necessary and required part of the classiﬁcation task.
Metaheuristic algorithms start with random solutions to the training loop and
enhance the solution over time to minimize error. The beneﬁt of such algorithms is
that they are very effective at avoiding local optimizations. In the training phase of
ANNs, metaheuristic algorithms were used, and it was proposed that these algorithms
outperformed the gradient-based algorithm when the problem was more complicated
and multidimensional. The simulation of creatures that act intelligently in the form
of swarms is known as swarm intelligence. Swarm intelligence algorithms are the
most common metaheuristic algorithm used to solve many NP-hard problems. There
are many swarm intelligence algorithms that been developed by researchers over the
years worldwide, and some of the most famous representatives involve ant colony
optimization (ACO) [9],particle swarm optimization (PSO) [14], artiﬁcial bee colony
(ABC) [13], and bat algorithm (BA) [33]. Swarm intelligence approaches were used
in solving different problems from the various application domains, including cloud
computing [3, 6, 8], wireless sensor networks [4, 35, 37, 39], predicting number of
COVID-19 cases [36, 38], machine learning [17], classiﬁcation of brain tumor MRI
images [7], and global optimization problems [27].
Some of these swarm intelligence algorithms have been applied successfully to
tackle the CNNs hyperparameters problems such as using the recent tree growth
approach to optimize the hyperparameters [25]. The proposed framework’s robust-
ness, performance, and solution quality were tested on the MNIST dataset. A com-
parison to other algorithms showed that the suggested structures show respectable
results in this ﬁeld.
Using the ﬁreﬂy algorithm to build the architecture of CNNs [26]. The research
presented in this paper is concerned with the optimization of CNNs hyperparameters,
which determine the network’s architecture and structure. The MNIST dataset was
utilized to validate the quality, robustness, and performances of the architecture
suggested in this paper. The obtained experimental results demonstrated that the
suggested structure performs well in this domain.
An automated system for optimizing hyperparameters and designing structures
was used in [2], through applying an improved metaheuristic algorithm. Firstly, they
suggest modiﬁed versions of the tree growth and ﬁreﬂy algorithms, which are then
tested and evaluated on the standard set of unconstrained benchmarks. Following that,
the improved algorithms are used to build the network. The ﬁndings were checked
against the MNIST dataset, and a comparison with other outstanding approaches
evaluated on the same issue was executed. The experimental ﬁndings indicate that
all proposed improved methods outperformed the other algorithms in terms of clas-
siﬁcation accuracy and computational resource use.
Hybridized monarch butterﬂy optimization algorithm to designing CNNs archi-
tecture for speciﬁc image classiﬁcation tasks [1]. The suggested hybrid approach
was initially evaluated on a set of standard unconstrained benchmarks before being
modiﬁed for a CNN design problem and then evaluated against other optimization
algorithms. The results demonstrated that their method achieved higher classiﬁcation
accuracy.

Convolutional Neural Networks Hyperparameters Optimization …
869
3
Proposed Method
The sine cosine algorithm (SCA) method was developed by Mirjalli [18], by propos-
ing a mathematical model that utilizes the sine and cosine functions. Multiple random
and adaptable variables are also incorporated into this method to highlight the explo-
ration and exploitation of the search space at various optimization stages. It has been
proven that the SCA is capable of successfully exploring various areas of a search
space and yet avoiding local optimums while converging in the direction of the global
optimum and exploiting promising areas of an inquiry space.
An optimization algorithm in the exploration phase abruptly blends the random
solutions into the collection of solutions with a high degree of randomness to identify
the potentially interesting areas of the search space. Even so, there are incremental
shifts in the random solutions during the exploitation process, and random deviations
are much lower than during the exploration phase.
The position updating equations for the exploration and exploitation phase are as
follows:
Xt+1
i
= Xt
i + r1 · sin(r2) · |r3Pt
i −Xt
i|
(2)
Xt+1
i
= Xt
i + r1 · cos(r2) · |r3Pt
i −Xt
i|
(3)
where Xt
i represents the current solution position in the ith dimension at tth iteration,
r1, r2, and r3 represent three random numbers between 0 and 1, and Pt
i represents the
position of the ith dimension, also || to show that the absolute value (positive value)
will be used only of r3Pt
i −Xt
i.
These two equations are incorporated as shown here:
Xt+1
i
=

Xt
i + r1 · sin(r2) · |r3Pt
i −Xt
i|,
r4 < 0.5
Xt
i + r1 · cos(r2) · |r3Pt
i −Xt
i|,
r4 ≥0.5
(4)
where r4 represents a random number between 0 and 1.
As can be seen from Eq. (4), the SCA is using four main parameters, and these
parameters are responsible for either the position or the destination. As a result, the
search process is able to strike a balance between solutions for successful coordina-
tion toward the best solution. The cyclic nature of sine and cosine functions ensures
that the area deﬁned between two observed solutions is exploited. The solutions have
the capability to search beyond the area between their corresponding destinations in
order to explore the search space. This is accomplished by adjustments of the ranges
of the sine and cosine functions. To guarantee that the search area has been explored,
the range modiﬁcations of sine and cosine necessitate the use of solutions to update
their locations out of the borders of the space between each solution. Randomness is
also obtained by identifying a number randomly for r2 in Eq. (4), which is a number
between 0 and 2π.
In order for the SCA to obtain the equilibrium among the exploration phase and
the exploitation phase, the following equation is used:

870
N. Bacanin et al.
r1 = a −t a
T
(5)
where a represents a constant value, T represents the maximum number of rounds,
and ﬁnally t marks the current round.
However, by performing tests of original SCA with basic CEC unconstrained
benchmarks, it was observed that exploration of the metaheuristics can be enhanced.
In the earlier phases of the algorithm’s run, the original SCA can become stuck in the
suboptimal parts of the search space, due to lack of exploration power. This drawback
will result in the degradation of the solutions’ quality. To overcome this, a simple
exploration mechanism is introduced in basic SCA as follows: in every round, the
worst solution from the population is replaced by the random individual inside the
limits of the search space by using the expression:
X j
rnd = L j + φ · (U j −L j),
(6)
where X j
rnd is jth component of the newly generated random solution, phi is the
value derived from the uniform distribution, and U J and L j are upper and lower
boundaries of j-th parameter, respectively. The implemented modiﬁcations increase
the computational complexity of the proposed algorithm in comparison to the basic
version; however, the improvements in the performances of the proposed method
over the original SCA justify this.
The proposed improved SCA metaheuristics is named enhanced SCA (eSCA).
Pseudocode is shown in Algorithm 1.
Algorithm 1 Pseudocode of proposed eSCA
Initialization. Generation of the starting random population of N individuals X within the boundaries of the search
space and calculation of its ﬁtness.
Initialize the maximal number of iterations T.
do
for all X in the generated population do
Evaluate utilizing the ﬁtness function.
if f (X) better than f (P) then
Update the position of the best solution so far (P = X∗).
end if
end for
Update r1 parameter using Eq. (5).
Update r2,r3, and r4 parameters.
Update the positions of search agents using Eq. (4).
Replace worst solution with random one using Eq. (6)
while (t < T)
return P the best solution found.

Convolutional Neural Networks Hyperparameters Optimization …
871
Table 1 Details of CIFAR-10 dataset
Training samples
60,000
Test samples
10,000
Number of classes
10
Input image size (height × width × input
channels)
28 × 28 × 1
Images
Colored
4
Experimental Setup and Analysis
Designing the architecture and hyperparameters of CNNs requires a lot of time
and effort from researchers. Therefore, creating an automated approach is a very
important process, so people with less experience in this domain can create the best
possible CNN model for their needs. In this paper, random but at the same time
guided eSCA was used to create the best possible structure of CNN. The guided
part of the algorithm is the optimization process because it depends of the human
presence from the start to determine the search region. In the conducted experiments,
the eSCA was tested with the (CIFAR-10 dataset) of colored images. The description
of the datasets can be found in Table1. Also, the obtained results have been evaluated
together with other well-known algorithms. It should be noted that for the purpose
of this research, basic SCA as well as the improved one (eSCA) were adapted for
CNN design.
The eSCA-CNN model has been developed in Python environment by using well-
known keras machine learning library and preprocessing tools from the scikit-learn.
Simulations are conducted on 6× GPU NVidia 1080 with 8GB of memory.
The hyperparameters’ scopes used to optimize the conﬁgurations are manually
set as shown in Table2, and individual motion is driven by eSCA parameters that are
shown in Table3.
To begin, it can be seen that the eSCA improves the population of potential CNN
conﬁgurationsandineachiterationenhancesefﬁciency.Intheend,itachievesthebest
possible setup. The algorithm ﬁnds the best solution in the observed search domain
and a prescribed amount of rounds. Based on the computational time and resources
availability, the conﬁguration search space and the maximal number of rounds were
expanded. Further, the average accuracy achieved on CIFAR-10 benchmark dataset
for 20 independent algorithm’s runs is shown, as well as the ﬁndings achieved using
other modern approaches.
According to hyperparameters’ shown in Table2, each eSCA individua (solution)
from population is encoded as integer array length of 43. The ﬁrst three components
are used to encode nC, nP, and nF, respectively, while the remaining components
encode hyperparameters’ values within each convolutional, pooling, and dense lay-
ers.

872
N. Bacanin et al.
Table 2 Range of hyperparameters for designing the CNN structure
Layers
Hyperparameter
Scope
Minimum value
Maximum value
Convolution
1. Convolutional layer
count (nC)
1
5
Pooling
2. Pooling layer count
(nP)
1
5
Fully connected
3. Fully connected
layer count (nF)
1
5
1. Filter count (c_nf)
1
64
2. Filter size (c_fs)
(odd)
1
13
3. Padding pixels
(c_pp)
0 (valid)
1 (same) p = c_fs−1
2
4. Stride size (c_ss)
(<c_fs)
1
5
Pooling
5. Filter size
(p_fs)(odd)
1
13
6. Stride size (p_ss)
1
5
7. Padding pixels
(p_pp) (<p_fs)
0 (valid)
1 (same) p = p_fs−1
2
8. Neuron count (op)
1
1024
Table 3 eSCA parameter set with the corresponding values
Parameter
Value
Number of solution in population
5
Number of iterations
5
Social coefﬁcient (c1)
2
Cognitive coefﬁcient (c2)
2
Table4 displays the mean number of parameters that can be trained in a single
CNN model for the CIFAR-10 dataset, as well as the overall number of CNNs
evaluated in one isolated run, which is determined by the number of individuals and
the number of rounds. It also displays the average time of execution for the observed
CNN model and the achieved validation accuracy after executing all phases of this
stochastic eSCA-CNN method. It is needed to highlight that all runs take 128 mini-
batch size, dropout rate of 20%, and ReLU activation function. Feature set generated
by the CNN is utilized for image classiﬁcation in softmax layer.
The convergence of an isolated run of eSCA-CNN that achieved the median
accuracy out of 20 runs was observed, and the random CNNs for 25 rounds were
also included, where 25 CNNs were modiﬁed after every step and the best accuracy
is point out after every round. After a few iterations of the possible solution, the

Convolutional Neural Networks Hyperparameters Optimization …
873
Table 4 Values of the parameters for a singular independent execution of the eSCA-CNN with
median accuracy achieved through 20 independent runs of eSCA-CNN
Dataset
Values of parameters
Average amount
of trainable
parameters in one
CNN model
Total CNNs
evaluations for
this independent
run
Average
execution time of
one CNN model
(s)
Achieved
validation
accuracy (%)
CIFAR-10 dataset 416,356
750
212,168
93,33
solution begins to converge. The structure of the mentioned algorithm’s convergence
is analyzed, and the algorithm’s execution is terminated once the solution stabilizes.
The ﬁndings show that the suggested structure of individuals of swarm effectively
searches the CNN hyperparameters and increases the efﬁciency for the CIFAR-
10 dataset. The eSCA-driven search will be able to explore larger portion of the
search space and ﬁnd even better solutions. The ﬁndings presented here are from
one isolated algorithm’s run, and they display the averages of ﬁtness values achieved
in twenty independent eSCA-CNN runs. Every run begins with a new collection
of hyperparameters that are generated randomly. For a fair comparison of results,
the randomly generated CNNs have been initialized by the same arbitrary set of
hyperparameters as the eSCA-CNN model shown here.
It is needed to point out that the searching process is not driven by eSCA, and
the 25 steps were performed using randomly generated CNNs. 25 CNNs have been
generated in every step, and the best candidate among the 25 CNNs is recorded. A
total of 625 CNNs were generated randomly, and the outcomes show that eSCA-
driven CNN search is a structured method that contributes to higher results than
random CNN model search. The downside of using eSCA-CNN is that it takes
more computing energy than random selection, but in return it can have higher
efﬁciency than the default conﬁguration environment, it decreases human effort and
eliminates conﬁgurations that perform poorly. The experimental setup for eSCA-
CNN and randomly generated CNNs is the same.
In Table 5, the outputs obtained from eSCA generated CNN models were com-
pared with those obtained from randomly generated CNN models and also with the
results for the basic SCA-CNN and the MPSO-CNN. The results for the MPSO-CNN
were taken from [23]. For the CIFAR-10 dataset, the average and best accuracy of
eSCA optimized CNNs outperform randomly generated CNNs and other approaches.
The directed approach works better than the totally randomized approach. It searches
for the best CNN conﬁguration automatically, which is a hard job for the people with
less knowledge in this ﬁeld. The proposed eSCA-CNN approach achieved the aver-
age accuracy about 3% better than the MPSO-CNN, and almost 18% better results
than the SCA-CNN. Furthermore, eSCA-CNN approach delivered almost 5% better
best accuracy result than the referenced MPSO-CNN.
Anautomaticselectionandoptimizationprocessexistsalongsideotherestablished
methods. Table2 shows the solution space for CNN parameters. The experiment is

874
N. Bacanin et al.
Table 5 Evaluation of the results achieved by SCA optimized CNN models and randomly generated
CNN models (20 runs)
CIFAR-10 dataset
Average accuracy (%)
Best accuracy (%)
Randomly generated CNN
42.81
58.49
SCA optimized CNN
73.55
81.34
eSCA optimized CNN
90.53
94.29
MPSO optimized CNN
87.34
89.56
Table 6 Simulation results of the obtained average accuracy
CIFAR-10 dataset
Average accuracy (%)
eSCA-CNN
90.53
SCA-CNN
73.55
CGP-CNN (ResSet) [28]
94.02
CGP-CNN (ConvSet) [28]
93.25
ReLU-CNN [30]
88.8
ReNet [29]
87.65
MPSO-CNN [23]
87.34
PSO-CNN [32]
80.15
Alexnet [32]
77.75
Fig. 1 Comparative analysis
of average accuracy achieved
by different approaches
preformed twenty times, while the average accuracy achieved is shown in Table6.The
eSCA-CNN with CIFAR-10 dataset has an overall accuracy of 90.53, which is higher
than all other metaheurics approaches included in the research, and comparable to
the results achieved with state of the art CGP-CNNs (ResSet and ConvSet). The
eSCA-CNN approach obtained signiﬁcantly better results than the basic SCA-CNN
and PSO-CNN and outperformed the referred MPSO-CNN by approximately 3%.
To better visualize the obtained results, bar plot of the accuracy achieved by different
approaches included in the comparative analysis is presented in Fig.1.

Convolutional Neural Networks Hyperparameters Optimization …
875
Convergence speed graphs comparison between SCA-CNN and proposed eSCA-
CNN for one randomly chosen run is shown in Fig.2. It can be clearly seen that the
eSCA-CNN converges much faster than the original SCA-CNN approach.
To provide an easier visual comparison between the original SCA and proposed
eSCA adapted for CNN design, we have generated swarm plots of both methods,
where every point denotes the position of the best solution in terms of accuracy in
one of totally conducted 20 runs. Swarm plot comparison is shown in Fig.3.
From the presented swarm plot, the distribution of best solutions within 20 runs
can be easily seen, where the superiority of proposed eSCA-CNN over SCA-CNN
is emphasized.
Fig. 2 Comparison of
converging speed graphs
among SCA-CNN and
eSCA-CNN in one run
Fig. 3 Swarm plot
comparison between
SCA-CNN and eSCA-CNN

876
N. Bacanin et al.
5
Conclusion
This paper presents a novel technique to the CNN hyperparameter optimization by
utilizing the eSCA metaheuristics as an optimizer. The goal of the paper was to reduce
the effort in determining the proper architecture and the hyperparameters, as the CNN
must be trained for each particular problem instance individually. The proposed
eSCA-CNN approach has obtained promising results in achieving a more effective
CNN structure. The experiments executed over the CIFAR-10 dataset conﬁrmed
that the eSCA-CNN can be successfully applied in the automation of the selection
process of appropriate CNN structure, without human supervision. Future work in
this domain will focus on enhancing and applying other metaheuristics approaches
to the CNN hyperparameter optimization task. The proposed SCA approach will
be validated on additional datasets as well. Additionally, the SCA approach will be
applied in other application domains as well, including the wireless sensor networks
and cloud computing.
References
1. Bacanin, N., Bezdan, T., Tuba, E., Strumberger, I., & Tuba, M. (2020). Monarch butterﬂy
optimization based convolutional neural network design. Mathematics, 8(6), 936.
2. Bacanin, N., Bezdan, T., Tuba, E., Strumberger, I., & Tuba, M. (2020). Optimizing convolu-
tional neural network hyperparameters by enhanced swarm intelligence metaheuristics. Algo-
rithms, 13(3), 67.
3. Bacanin, N., Bezdan, T., Tuba, E., Strumberger, I., Tuba, M., & Zivkovic, M. (2019). Task
scheduling in cloud computing environment by grey wolf optimizer. In 2019 27th telecommu-
nications forum (TELFOR) (pp. 1–4). IEEE.
4. Bacanin, N., Tuba, E., Zivkovic, M., Strumberger, I., & Tuba, M. (2019). Whale optimization
algorithm with exploratory move for wireless sensor networks localization. In International
conference on hybrid intelligent systems (pp. 328–338). Springer.
5. Baldominos, A., Saez, Y., & Isasi, P. (2018). Evolutionary convolutional neural networks: An
application to handwriting recognition. Neurocomputing, 283, 38–52.
6. Bezdan, T., Zivkovic, M., Antonijevic, M., Zivkovic, T., & Bacanin, N. (2020). Enhanced
ﬂower pollination algorithm for task scheduling in cloud computing environment. In Machine
learning for predictive analysis (pp. 163–171). Springer.
7. Bezdan, T., Zivkovic, M., Tuba, E., Strumberger, I., Bacanin, N., & Tuba, M. (2020). Glioma
brain tumor grade classiﬁcation from MRI using convolutional neural networks designed
by modiﬁed fa. In International conference on intelligent and fuzzy systems (pp. 955–963).
Springer.
8. Bezdan, T., Zivkovic, M., Tuba, E., Strumberger, I., Bacanin, N., & Tuba, M. (2020). Multi-
objective task scheduling in cloud computing environment by hybridized bat algorithm. In
International conference on intelligent and fuzzy systems (pp. 718–725). Springer.
9. Dorigo, M., Birattari, M., & Stutzle, T. (2006). Ant colony optimization. IEEE Computational
Intelligence Magazine, 1(4), 28–39.
10. Duchi, J., Hazan, E., & Singer, Y. (2011, July). Adaptive subgradient methods for online
learning and stochastic optimization. Journal of Machine Learning and Research, 12(null),
2121–2159.
11. Fukushima, K. (1980). A self-organizing neural network model for a mechanism of pattern
recognition unaffected by shift in position. Biological Cybernet, 36, 193–202.

Convolutional Neural Networks Hyperparameters Optimization …
877
12. Hubel, D. H., & Wiesel, T. N. (1959). Receptive ﬁelds of single neurons in the cat’s striate
cortex. The Journal of Physiology, 148(3), 574–591.
13. Karaboga, D., & Basturk, B. (2008). On the performance of artiﬁcial bee colony (ABC) algo-
rithm. Applied Soft Computing, 8(1), 687–697.
14. Kennedy, J., & Eberhart, R. (1995). Particle swarm optimization. In Proceedings of ICNN’95-
international conference on neural networks (Vol. 4, pp. 1942–1948). IEEE.
15. Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). Imagenet classiﬁcation with deep convo-
lutional neural networks. Advances in Neural Information Processing Systems, 25, 1097–1105.
16. LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11), 2278–2324.
17. Milosevic, S., Bezdan, T., Zivkovic, M., Bacanin, N., Strumberger, I., & Tuba, M. (2021).
Feed-forward neural network training by hybrid bat algorithm. In Modelling and development
of intelligent systems: 7th international conference, MDIS 2020. Sibiu, Romania, October
22–24, 2020, Revised Selected Papers 7 (pp. 52–66). Springer International Publishing.
18. Mirjalili, S. (2016). SCA: A sine cosine algorithm for solving optimization problems.
Knowledge-Based Systems, 96, 120–133.
19. Pyrkov, T. V., Slipensky, K., Barg, M., Kondrashin, A., Zhurov, B., Zenin, A., et al. (2018).
Extracting biological age from biomedical data via deep learning: Too much of a good thing?
Scientiﬁc Reports, 8(1), 1–11.
20. Ranganathan, G. (2020). Real life human movement realization in multimodal group com-
munication using depth map information and machine learning. Journal of Innovative Image
Processing (JIIP), 2(02), 93–101.
21. Ren, H., Xu, B., Wang, Y., Yi, C., Huang, C., Kou, X., Xing, T., Yang, M., Tong, J., & Zhang,
Q. (2019). Time-series anomaly detection service at microsoft. In Proceedings of the 25th ACM
SIGKDD international conference on knowledge discovery & data mining (pp. 3009–3017).
22. Samide, A., Stoean, C., & Stoean, R. (2019). Surface study of inhibitor ﬁlms formed by
polyvinyl alcohol and silver nanoparticles on stainless steel in hydrochloric acid solution using
convolutional neural networks. Applied Surface Science, 475, 1–5.
23. Singh, P., Chaudhury, S., & Panigrahi, B. K. (2021). Hybrid MPSO-CNN: Multi-level particle
swarm optimized hyperparameters of convolutional neural network. Swarm and Evolutionary
Computation, 63, 100863.
24. Smys, S., Chen, J. I. Z., & Shakya, S. (2020). Survey on neural network architectures with
deep learning. Journal of Soft Computing Paradigm (JSCP), 2(03), 186–194.
25. Strumberger, I., Tuba, E., Bacanin, N., Jovanovic, R., & Tuba, M. (2019). Convolutional neural
network architecture design by the tree growth algorithm framework. In 2019 International
Joint Conference on Neural Networks (IJCNN) (pp. 1–8). IEEE.
26. Strumberger, I., Tuba, E., Bacanin, N., Zivkovic, M., Beko, M., & Tuba, M. (2019). Designing
convolutional neural network architecture by the ﬁreﬂy algorithm. In 2019 International Young
Engineers Forum (YEF-ECE) (pp. 59–65). IEEE.
27. Strumberger, I., Tuba, E., Zivkovic, M., Bacanin, N., Beko, M., & Tuba, M. (2019). Dynamic
search tree growth algorithm for global optimization. In Doctoral conference on computing,
electrical and industrial systems (pp. 143–153). Springer.
28. Suganuma, M., Shirakawa, S., & Nagao, T. (2017). A genetic programming approach to design-
ing convolutional neural network architectures. In Proceedings of the genetic and evolutionary
computation conference (pp. 497–504).
29. Visin, F., Kastner, K., Cho, K., Matteucci, M., Courville, A., Bengio, Y.: Renet: A recurrent
neural network based alternative to convolutional networks. arXiv preprint arXiv:1505.00393
(2015)
30. Xu, B., Wang, N., Chen, T., Li, M.: Empirical evaluation of rectiﬁed activations in convolutional
network. arXiv preprint arXiv:1505.00853 (2015)
31. Yamaguchi, K., Sakamoto, K., Akabane, T., & Fujimoto, Y. (1990). A neural network for
speaker-independent isolated word recognition. In First international conference on spoken
language processing.

878
N. Bacanin et al.
32. Yamasaki, T., Honma, T., & Aizawa, K. (2017). Efﬁcient optimization of convolutional neural
networks using particle swarm optimization. In 2017 IEEE third international conference on
multimedia big data (BigMM) (pp. 70–73). IEEE.
33. Yang, X. S. (2010). A new metaheuristic bat-inspired algorithm. In Nature inspired cooperative
strategies for optimization (NICSO 2010) (pp. 65–74). Springer.
34. Zeiler, M. D. (2012). Adadelta: An adaptive learning rate method. arXiv:1212.5701
35. Zivkovic, M., Bacanin, N., Tuba, E., Strumberger, I., Bezdan, T., & Tuba, M. (2020). Wire-
less sensor networks life time optimization based on the improved ﬁreﬂy algorithm. In 2020
International Wireless Communications and Mobile Computing (IWCMC) (pp. 1176–1181).
IEEE.
36. Zivkovic, M., Bacanin, N., Venkatachalam, K., Nayyar, A., Djordjevic, A., Strumberger, I., &
Al-Turjman, F. (2021). Covid-19 cases prediction by using hybrid machine learning and beetle
antennae search approach. Sustainable Cities and Society, 66, 102669.
37. Zivkovic,M.,Bacanin,N.,Zivkovic,T.,Strumberger,I.,Tuba,E.,&Tuba,M.(2020).Enhanced
grey wolf algorithm for energy efﬁcient wireless sensor networks. In 2020 zooming innovation
in consumer technologies conference (ZINC) (pp. 87–92). IEEE.
38. Zivkovic, M., Venkatachalam, K., Bacanin, N., Djordjevic, A., Antonijevic, M., Strumberger,
I., & Rashid, T. A. (2021). Hybrid genetic algorithm and machine learning method for covid-
19 cases prediction. In Proceedings of international conference on sustainable expert systems:
ICSES 2020 (Vol. 176, p. 169). Springer.
39. Zivkovic, M., Zivkovic, T., Venkatachalam, K., & Bacanin, N. (2021). Enhanced dragonﬂy
algorithm adapted for wireless sensor network lifetime optimization. In Data intelligence and
cognitive informatics (pp. 803–817). Springer.

A Novel Approach to Detect Low Quality
Deepfake Videos
Neeraj Guhagarkar, Sanjana Desai, Swanand Vaishampayan,
and Ashwini Save
Abstract Exceptional improvements in the domain of Deep Learning (DL) have
resulted in the surge of highly realistic Artiﬁcial Intelligence (AI) generated fraud-
ulent videos, generally known as Deepfakes. Although this technology has inﬁnite
useful applications, there are also notable concerns about the drawbacks of the same.
The generation of false videos about public ﬁgures such as politicians or actors to
despoil their character and to trick the public is one such application. So there is an
urgent need to develop a system that would detect and mitigate the negative impact
of these AI-generated videos on society. High quality Deepfake videos were easily
detected by the previously created models. But the efﬁciency of the system would
gradually decline when tested for low quality videos. The videos that are transferred
through various social media sites are of low quality, so the detection of such videos
becomes challenging. So, in this system using the concept of super resolution along
with Convolutional Neural Network (CNN) and Long Short Term Memory (LSTM),
detection of the low quality Deepfakes is carried out. In this, the concept super reso-
lution increases the quality of videos and then the CNN architecture with the help
of LSTM will classify the videos as Deepfake or not by considering the given facial
features. For this project, the proposed framework was used on the FaceForensics++
dataset. This system has thus aimed to develop a model that detects such low quality
Deepfake videos with better accuracy.
Keywords Deepfake · Deep learning · Super resolution · CNN · LSTM · Softmax
function
N. Guhagarkar · S. Desai · S. Vaishampayan (B) · A. Save
Computer Engineering Department, VIVA Institite of Technology, Mumbai, India
A. Save
e-mail: ashwini-save@viva-technology.org
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_68
879

880
N. Guhagarkar et al.
Abbreviations
CNN
Convolutional Neural Network
DL
Deep Learning
GAN
Generative Adversarial Network
SVM
Support Vector Machine
PSNR
Peak Signal-to-Noise Ratio
SSIM
Structural Similartity Index
1
Introduction
Noteworthy advancements in the ﬁeld of DL have led to the rise of Deepfake videos.
Manipulated videos that are created with the help of advanced artiﬁcial intelligence,
whose overall quality and sound appear to be real, are known as Deepfakes. By aid of
DL architectures such as Generative Adversarial Network (GANs) and autoencoders
and a considerable amount of footage of a target subject, anyone can create such
convincing Deepfake videos [1]. There are 3 major types of Deepfake videos, i.e.,
(a) Head Puppetry, (b) Face-swapping, and (c) Lip-syncing [2]. This technique can
be used to cause potential harm to society. For instance, Rana Ayyub, an Indian
journalist had become the victim of a wicked Deepfake plot. A false pornographic
content that showed her in it was shared on social media platforms such as Twitter
and WhatsApp. Therefore, there is an instant need to develop a system that would
identify such Deepfake videos.
The use of social media has increased enormously, especially during this covid-
19 era. Sharing of Deepfake videos through social media platforms has increased
alarmingly. To tackle this problem, Facebook recently undertook a competition at
international level. Since the Deepfake videos that are passed through the social
media platform can cause huge harm, it becomes necessary to detect such videos for
the welfare of society.
To fulﬁll the need of ﬁnding a solution for the detection of Deepfake videos, the
proposed system was built using the concept of super resolution along with CNN
and LSTM with far better accuracy than the previous models. The proposed system
uses the concept of super resolution which helps to enhance the quality of the videos
[3–6] and later the concept of CNN is employed to extract the features at the frame
level of the facial region and ﬁnally using LSTM the classiﬁcation of whether a video
is faked or not is detected. Dataset used is FaceForensics++. The work presented by
Rossler et al. [7] is considered as base paper and baseline accuracy as 81% for low
quality videos.
Proposed system architecture can be broken down into three stages. For ﬁrst stage,
i.e., super resolution, ESRGAN has been used. For second stage, i.e., for feature

A Novel Approach to Detect Low Quality Deepfake Videos
881
extraction, CNN Resnext50 has been used. And ﬁnally for third stage, LSTM along
withsoftmaxfunctiongivesustheoutputofthesystem,i.e.,therequiredclassiﬁcation
of videos. In the following sections, it is discussed that how this system outperforms
other models in terms of accuracy.
2
Related Work
To resolve the issue of detection of Deepfakes videos, numerous models have been
implemented over the past few years by researchers using diverse Machine Learning
techniques like Support Vector Machine (SVM) [8–11], DL techniques like CNN
[3, 12, 13], CNN with SVM [2], CNN with LSTM [1, 13–17] and Recurrent Neural
Network (RNN) [18]. Various approaches such as considering the changes in the
background color [10], exposing inconsistent head poses [8], were also considered
for detection. Although many systems have been developed based on Deep learning
techniques when these models were tested on low quality Deepfake videos their
accuracy decreased. They gave better results only for the detection of high quality
Deepfakes.
Lyu [2] has thoroughly studied different methods for generating Deepfakes such
as (a) head Puppetry, (b) face-swapping, (c) Lip-syncing, etc. The author found
that the area of audio Deepfakes has more scope for research and limitations of
these techniques are the inability to produce accurate details of the faces, quality of
Deepfake Datasets, social media laundering, etc.
Younus et al. [15] compared the most popular Deepfake detection techniques.
Backgroundcomparison,temporalpatternanalysis,eyeblinking,andposeestimation
are few of these techniques. This survey report aided in understanding the various
Deepfake detection algorithms now in use, as well as how additional features could
be discovered to aid in the detection of Deepfakes more effectively.
Aneja et al. [19] have introduced Deep Distribution Transfer (DDT) which is
based on zero and few-shot transfer learning. When dataset was transferred to Face-
Forensics++ from Dessa dataset, accuracy increased by 4.88% and 8.38% for zero
shot and few shot transfer respectively.
2.1
Support Vector Machine(SVM)
Yang et al. [8] have proposed a model to detect Deepfake using inconsistent head
poses. Algorithms used in the previous models used to create the face of various
persons without changing the original expressions hence creating mismatched facial
landmarks. Therefore, when these videos were created using Deepfake techniques,
often the landmark position of faked faces differed from real faces while superim-
posing the fake faces in place of real ones. Researchers noted the divergence between
the two vectors created using cosine distances of the head orientation of real as well

882
N. Guhagarkar et al.
as Deepfake videos. This difference between the two vector values can be used to
classify the videos. Implemented system extracts 68 facial remarks and uses the DLib
package for the detection of the face. OpenFace2 model is used in this to create 3D
facial model and then the difference between them is being calculated. The proposed
system uses UADFV dataset. Radial Basis Function (RBF) kernels are used to train
SVM classiﬁer. Area Under ROC (AUROC) of 0.89 is accomplished on the UADFV
dataset by the SVM classiﬁer. How the Deepfakes were generated by entwining
a synthesized face area into the primary image, and how the 3D pose estimation
was used for detecting synthesized videos, was one of the important point that was
inferred from this paper.
McCloskey et al. [10] have proposed a method that makes use of saturation cues to
detect Deepfakes. Images can be recognized as GAN-generated imagery or camera
imagery, with the help of saturation cues. Two kinds of GAN-generated imagery can
be detected with the help of this cue. It is observed that HDR, camera pictures
usually have areas of saturation under-exposure. Generator normalization steps
usually suppress the regularity of saturated pixels and pixels which are non-exposed.
This is the hypothesis which has been explained in this research. Researchers recom-
mended the use of GAN image detector by which the frequency of saturated and
non-exposed pixels can be calculated. These are trained with the help of MATLAB’s
ﬁtcsvm function and features are classiﬁed by SVM.
Kharbat et al. [11] proposed utilizing SVM regression to detect Deepfake movies.
Their strategy trains AI classiﬁers to detect fraudulent videos using feature points
derived from the videos. HOG, ORB, BRISK, KAZE, SURF, and FAST are the
different feature point extraction algorithms determined by them. Using the HOG
feature point extraction approach, 95% accuracy was achieved. The above-mentioned
system aids in the discovery of a feature detection alternative. Because feature detec-
tion is such an important component of the project, this study recommends that the
standard algorithms mentioned above can also be employed for feature detection.
The basic logistic regression model for detection was proposed by Matern et al.
[20]. This research demonstrates how the manipulation occurs in the generated faces
and the Deepfake. They present algorithms for detecting faces that have been totally
produced. They show this through a variety of visual cues that focus on the eyes,
dentition, and face shapes. Faces have the most pronounced specular reﬂection in
the eyes. The neural network employing the combined feature vector achieves the
best performance, with an AUC of 0.851. This is a good sign that the eye and tooth
features are meaningful, and that the results aren’t due to discrepancies in the genuine
and false class photographs.
2.2
Convolutional Neural Network(CNN)
To take advantage of possible inter-frame differences, the technique of ﬂow ﬁelds that
are optical has been proposed by Amerini et al. [21]. CNN classiﬁers further learn
from this clue. Between the spectator and scene, there is movement to extract this

A Novel Approach to Detect Low Quality Deepfake Videos
883
optical ﬂow ﬁeld, which is computed on two frames in a row. To calculate the optical
ﬂow ﬁelds, one frame from the real video and the other from the Deepfake is used.
The vectors surrounding the chin were smooth for the edited videos whereas there
was more noise in the original sequence. They have used Faceforensics++ dataset.
720, 120, and 120 videos for training, validation and testing respectively were used
from the dataset. VGG16 and ResNet50 neural networks were used. VGG16 network
gave the detection accuracy of 81.61% for Face2Face videos whereas ResNet50
gave detection accuracy of 75.46%. The idea of inter-frame dissimilarities is the
main quality of this paper, unlike other techniques which rely only on intra-frame
inconsistencies and how to overcome them using the optical ﬂow based CNN method.
Zhou et al. [9] have presented a survey paper. Extreme posture, lighting, minimal
resolution, and small sizes are all obstacles for face detection systems. This paper
states that most of the systems are trained only on high-resolution images therefore
they perform badly when they are tested on surveillance systems because of low
resolution. The authors have used HoG-SVM and R-CNN and S3FD algorithms on
low-resolution images. The dataset used is FDDB. When the parameters such as
blur, noise, or contrast levels were changed and algorithms were tested, it was found
that the performance of the given models degraded. The conclusion was, both the
algorithms HoG-SVM and R-CNN-S3FD perform very badly when they are tested
on low-resolution images. This paper provides insights that care must be taken as
R-CNN and S3FD performs very badly for face detection of low-resolution images.
The care must be taken for noise and contrast level because these factors can also
affect the accuracy of the algorithms.
Using a DL Approach, Malolan et al. [22] established a method to detect these
Deepfake clips. They used a database of extracted faces from the FaceForensics++
Dataset to train a CNN architecture. They’ve also put the model through its paces
using Explainable AI approaches like Layer-Wise Relevance Propagation (LRP)
and Local Interpretable Model-Agnostic Explanations (LIME) to provide crisp
visualizations of the model’s target regions.
2.3
CNN with Long Short Term Memory (LSTM)
Yadav et al. [1] have elaborated the Deepfake techniques that are used along with
how it can create manipulated faces with high accuracy. The GANs contain two
entwined neural networks, called generator and discriminator. The fraudulent images
are synthesized from the given dataset by the generator. On the other hand, discrimi-
nator neural networks assess the images which are synthesized by the generator and
check its authenticity. Deepfakes are harmful because of cases like individual char-
acter defamation and assassination, spreading fake news, a threat to law enforcement
agencies. Blinking of eyes can be considered as one of a feature for detecting Deep-
fakes. The necessity of large datasets, training, and swapping is time-consuming,
alike faces and skin tones of personalities, etc. are few limitations for making Deep-
fake.RecurrentneuralnetworkscanalsobeusedtodetectDeepfake.Thecombination

884
N. Guhagarkar et al.
of CNN and LSTM helps to efﬁciently identify variations present in frames which are
useful for Deepfake detection. On Face2Face dataset, Meso-4 and Mesoinception-4
models have 95% and 98% accuracies respectively.
Guera et al. [16] have illustrated how Deepfake videos are produced and how they
can be detected using CNN and LSTM. GAN’s are used for better quality Deepfake
videos. The decoder of the target image is used for the swapping of faces with the
target image, and for the generation process, the encoder of the original image is
used. Many different techniques were used by them to accurately detect Deepfake
videos and concluded that the best accuracy was attained when the video was split
into 80 frames per second along with a combination of CNN and LSTM. Maximum
accuracy of around 97.1% was obtained. But the accuracy which was acquired was
on a set of high-resolution images. The above paper also explains in great detail how
the Deepfake videos are generated.
For a human being, detecting Deepfakes is not an easy task; this is being stated
by Rossler et al. [7]. Including a human baseline, this paper also provides the bench-
mark for facial manipulation detection under random compression. CNN model was
used to detect all these Deepfakes. They have used a total of 7 methods to detect the
various Deepfake videos of various qualities. One such method was the Steganalysis
method which used the handcrafted feature and the SVM classiﬁer. Provided input
to this model was a 128 × 128 cropped facial region. It was observed that detec-
tion of raw images was good but when it came to low quality videos its accuracy
decreased. Initially, a constrained convolution layer is used. Then, two convolu-
tion layers and two max pooling layers are used, which are followed by three fully
connected layers. 81% was the highest accuracy for the low quality videos using
Xception net algorithm.
ThesystembasedonthecombinationofCNNandLSTMforclassifyingthevideos
asfakeororiginalwasproposedbyRanjanetal.[23].Transferlearningwasemployed
by the authors to improve the accuracy of their system. This is also something to keep
in mind, as transfer learning has the potential to drastically improve the Deepfake
detection system’s accuracy. The DFD model, with an accuracy of 70.57% on the
custom test set from the single dataset train models, was the top performer.
To explore spatial and temporal at the same time, Chen et al. [14] have proposed
FSSPOTTER. The authors have used a VGG16 architecture with LSTM and have
achieved accuracies which are better than XcpetionNet by 2.2%, 5.4%, 4.4%,
2.0% for UADFV, Celeb-DF, DeepfakeTIMIT HQ and DeepfakeTIMIT LQ datasets
respectively.
2.4
Super Resolution
Jagdale et al. [3] introduced a revolutionary super resolution algorithm called NA-
VSR. The algorithm reads the low-resolution videos and converts them into high-
resolution videos. It ﬁrst reads the low-resolution video and converts it into frames.

A Novel Approach to Detect Low Quality Deepfake Videos
885
To resolve the issue of undesired noise, the median ﬁlter is used. The bicubic interpo-
lation technique is used to boost the image’s pixel density. Then Bicubic transforma-
tion and image enhancement are done for mainly resolution enhancement. After these
steps,thedesignmetriciscomputed.Theimagequalityisdeterminedusingtheoutput
peak signal-to-noise ratio (PSNR) and structural similarity index method (SSIM).
For NA-VSR the parameters PSNR and SSIM were computed and compared with
earlier approaches. NA-VSR yeilds improved PSNR values than bicubic, SRCNN,
and ASDS, by 7.84 dB, 6.92 dB, and 7.42 dB, respectively.
Yamanaka et al. [12] have proposed a system which has exceptionally low compu-
tational cost than other super resolution methods. It achieves a PSNR/SSIM value
of 33.05/0.9126 on Set14 dataset which is better than computationally expensive
methods like SRCNN, DRCN, VDSR, etc.
Many super resolution algorithms have a major drawback, i.e., low performance
for videos with facial changes. To tackle this challenge, Yu et al. [5] have incorporated
global tracking and local alignment steps along with super resolution algorithm. The
authors evaluated the method on ten clips of ten people and obtained a PSNR of 26.62,
which was much higher than the 20.62 obtained using merely the global tracking
technique. This approach is helpful for doing super resolution of videos with facial
expression changes.
3
Research Gap
After going through the recent research work of various researchers meticulously, it
was found out that the current Deepfake detection systems gave far better accuracies
for the high quality Deepfake videos. When same systems were tested for classiﬁca-
tion of low quality videos, the current models failed to classify the Deepfake videos
with higher accuracies. The main reason behind that was failure of CNN algorithms
to extract the important features from videos having lo resolution. The Deepfake
videos which are passed through social media platforms are of main concern. These
videos are low quality videos. Therefore, accurate detection of Deepfake videos
passed through social media using current models is not possible. Proposed model
aims to bridge this current gap.
4
Proposed System
4.1
Deepfake Detection Model
For detection of Deepfake videos, proposed model uses combination of super reso-
lution along with CNN and LSTM. The Enhanced Super Resolution Generative
Adversarial Network (ESRGAN) architecture [24] is used to enhance the low quality

886
N. Guhagarkar et al.
Fig. 1 Overall Architecture of System
videos. CNN is implemented for essential features extraction at frame level. CNN
is best option because frame level extraction can be done using CNN’s automatic
feature extractor. For model to give precise results, feature extraction step is most
essential and vital. CNN must extract the features precisely at the frame level. After
this, the results of CNN are passed to LSTM and at the end after applying softmax
function, we get the required classiﬁcation of videos as Deepfaked or genuine.
Figure 1 shows the overall architecture of the system which is further divided into
two parts, i.e., (a) super resolution and (b) CNN–LSTM model. The video from the
FaceForensics++ dataset is used as input for the ESRGAN super resolution model.
In this the extraction of frame from the video input is carried out. After the super
resolution of the video, it is passed to the CNN and LSTM model for the feature
extraction and the classiﬁcation purpose and then ﬁnally we get the output whether
the video is Deepfaked or not.
4.2
Super Resolution Architecture
First, the ESRGAN architecture [24] is used for the super resolution purpose, in
which the low-resolution videos are converted into frames and are further passed
through various convolution layers and 23 dense blocks of the Generator Network
of ESRGAN. Each dense block contains 5 convolution layers and Leaky Relu as an
activation function. As the neural network is very deep skip connections are used to
resolve the issue of vanishsing gradients. After the dense blocks, convolution layers
and upsampling is carried out on these frames and the high-resolution videos are
obtained. First the VGA quality videos are passed as input and after super resolution,
we get the Full HD quality videos as output (Fig. 2).
4.3
Preprocessing Stage
After the videos are super resolved, before passing these videos directly to CNN
Resnext50 model, preprocessing of these videos takes place. In this, ﬁrst the videos
are again broken down into frames, to be precise 40 frames per seconds. To reduce
the overhead of computational complexity, only ﬁrst 150 frames are selected and
then face cropping will be performed. As FaceForensics++ dataset only consists of
face cropped Deepfake videos, it is essential that CNN model accurately extract the

A Novel Approach to Detect Low Quality Deepfake Videos
887
Fig. 2 Super resolution architecture [24]
features of facial area. Therefore step of facial cropping is pivot in preprocessing
stage. Then corrupted frames will be removed from the sequence as they can affect
the training stage.
4.4
CNN Architecture
Preprossed frames are passed to CNN Resnext50 model for frame level extraction.
Resnext50 is pre-trained model which can be imported using pytorch library. It
consists of ﬁve Convolution layers. Input size for ﬁrst layer is 112 × 112. After the
ﬁrst layer max pooling of 3 × 3 is applied. Subsequent layers have been applied the
activation function Relu. After the 5th layer, the image size of 7 × 7 is obtained. The
Resnext50 architecture is used to extract the most important features from the input
data. After the feature extraction for the classiﬁcation purpose, the softmax is used
along with LSTM.
4.5
LSTM
The main reason behind using the LSTM along with CNN is that it has memory unit.
When the Deepfake videos are generated, they are generated at frame level. Autoen-
coder does not know values of brightness, contrast of the previously formed frame.

888
N. Guhagarkar et al.
Fig. 3 CNN and LSTM architecture
So, when the Deepfake video is broken down into frames, at frame level the vector
values of brightness, facial orientation, etc., differ from one another. This is where
LSTMworksatitsbest.UsingLSTMwecomparethetwovectorvaluesofsubsequent
frames, if the variance is above the threshold value, the video may be Deepfaked.
After comparing all such 150 frames, softmax function gives a probabilistic value
which accurately detects the Deepfaked or real videos (Fig. 3).
5
Dataset
FaceForensics++ dataset [7] was used on the proposed model. The dataset consists
of 2000 videos, from which after the preprocessing stage, the corrupted videos were
removed. After removing corrupted videos, total 1967 videos were used. All the
videos were of VGA quality. The dataset was split into ratio of 80:20 for the purpose
of training and testing respectively.
5.1
Training and Testing
For training 1573 videos were used, out of which 778 were real and 795 were fake
videos. And testing was done on 394 videos out of which 213 were real and 181
were fake videos. Training was done in batches taking random videos. Each batch

A Novel Approach to Detect Low Quality Deepfake Videos
889
Table 1 Results and analysis table
Sr.No.
Deepfake detection techniques
Technique
Hardware details
Dataset
Accuracy
1
CNN
(XceptionNet) and
LSTM [7] (2019)
–
FaceForensics++
81% (Low quality)
2
Super resolution,
CNN and LSTM
(Proposed System)
System: Core i5 and
above
Hard Disk: 500 GB
Monitor: Color
Monitor
RAM: 8 GB and More
Graphic Card: GTX
1050 Ti and above
FaceForensics++
94.16%
(Low quality)
contained 400 videos and the number of epochs was set to 20. To calculate the
accuracy, a confusion matrix was created on the test dataset. The true positive and
true negative values were 170 and 201 respectively, and false positive rate was 11
while false negative rate was 12.
The overall accuracy was calculated by (TP + TN)/Total. Model gave an overall
accuracy of 94.16%.
6
Results and Analysis
The purpose of proposed system is to detect whether the video that is passed through
social media is Deepfaked or real achieving the accuracy of 94.16% on FaceForen-
sics++ dataset. For comparison, the proposed model was compared to the model
proposed by Rossler et al. [7], which is displayed in the table below for the low
quality video.
AsshowninTable1,thedescribedmodelwiththeFaceForensics++datasetdetects
low quality Deepfake with an accuracy of 94.16%, which is higher than the accuracy
of 81% [7].
7
Conclusion
The system that has been proposed is based on DL to detect if the video is Deepfaked
or not. As per the found research gap, a model to detect the Deepfake videos of low
quality has been devised. Model uses super resolution with CNN and LSTM. Super
resolution enhances the quality of low quality videos. The current Deepfake detection
systems gave lower accuracies when used on low quality videos, because CNN
fails to extract the features from low quality frames correctly. By using ESRGAN

890
N. Guhagarkar et al.
super resolution, the quality of low quality videos was enhanced thus, proposed
system was able to rectify the issue pertaining to current Deepfake detection models.
Preprocessing stage helped to clean the corrupted videos as well as it generated facial
cropped videos for better feature extraction. Also cropping the facial region from
videos reduces the computational cost. For CNN extraction stage, proposed system
used Resnext50 architecture. After feature extraction, LSTM was used. LSTM can
store the vector values from each frame which can be further used to compare the
vector values of subsequent frames. After comparing all of the frames of videos, a
probabilistic value was achieved that was used to identify the videos as Deepfaked
or real. After training and testing, the accuracy of the system was found out to be
94.16% which was greater than the baseline accuracy of 81%.
8
Future Work
The proposed system focuses on detection of the low quality Deepfake videos which
are generated by face-swapping. Deepfake detection of low quality Deepfake videos
generated by other manipulation techniques can also be undertaken in coming years.
In future, researchers can also try using different super resolution algorithms like
ESRGAN+ , TecoGAN, MSG-CapsGAN, etc. Apart from that, Audio Deepfake
detection systems can also be incorporated with the current models which only
focuses on visual aspects.
Acknowledgements We are grateful to Dr. Tatwadarshi Nagarhalli of the Computer Engineering
Department for his continual guidance, support, and insightful recommendations. We were able to
deliver this work thanks to his prompt instruction and encouragement.
References
1. Yadav, D., & Salmani, S. Deepfake: A survey on facial forgery technique using generative
adversarial network. Proceedings of the ınternational conference on ıntelligent computingand
control systems (ICICCS 2019). IEEE Xplore Part Number: CFP19K34-ART; ISBN: 978-1-
5386-8113-8.
2. Lyu, S. Deepfake detection: Current challenges and next steps. 2020 IEEE ınternational
conference on multimedia & expo workshops(ICMEW).
3. Jagdale, R., & Shah, S. A novel algorithm for video super-resolution. Proceedings of ICTIS
2018, ınformation and communication technology for ıntelligent systems (Vol. 1, pp.533–544).
4. Tao, X., Gao, H., Liao, R., Wang, J., & Jia, J. Detail-revealing Deep Video Super-resolution.
2017 IEEE ınternational conference on computer vision (ICCV).
5. Yu, J., & Bhanu, B. (2018) Super-resolution of facial ımages in video with expression changes.
IEEE 5th conference on advanced video and signal based surveillance.
6. Dong, C., Loy, C. C., He, K., & Tang, X. Image super-resolution using deep convolutional
networks. IEEE Transaction on Pattern Analysis and Machine Intelligence (2016).

A Novel Approach to Detect Low Quality Deepfake Videos
891
7. Rossler, A., Cozzolino, D., Verdoliva, L., Riess, C., Thies, J., & Nießner, M. (2019) Face-
Forensics++: Learning to detect manipulated facial ımages. Proceedings of the IEEE/CVF
ınternational conference on computer vision (ICCV) (pp. 1–11).
8. Yang, X., Li, Y., & Lyu, S. Exposing deep fakes using ınconsistent head poses. ICASSP 2019—
2019 IEEE ınternational conference on acoustics, speech and signal processing (ICASSP).
9. Zhou, Y., Liu, D., Huang, T. Survey of face detection on low-quality ımages. 2018 13th IEEE
ınternational conference on automatic face and gesture recognition.
10. McCloskey, S., & Albright, M. Detectıng gan-generated ımagery usıng saturatıon cues. 2019
IEEE.
11. Kharbat, F. F., Elamsy, T., Mahmoud, A., & Rami. Image feature detectors for deepfake video
detection. IEEE 2019.
12. Yamanaka, J., Kuwashima, S., & Kurita, T. Fast and accurate ımage super resolution by deep
CNN with skip connection and network in network. (Springer 2017).
13. Luo,M.,Xiao,Y.,&Zhou.Y.Multi-scalefacedetectionbasedonconvolutionalneuralnetwork.
IEEE 2018.
14. Chen, P., Liu, J., Liang, T., Zhou, G., Gao, H., Dai1, J., & Han, J. Fsspotter: Spotting
face-swapped video by spatial and temporal clues. 2020 IEEE ınternational conference on
multimedia and expo (ICME).
15. Younus, M. A., & Hasan, T. M. Abbreviated view of deepfake videos detection techniques. 2020
6th ınternational engineering conference “sustainable technology and development” (IEC).
16. Guera, D., & Delp, E. J. Deepfake video detection using recurrent neuralnetworks. 2018 15th
IEEE ınternational conference on advanced video and signalbased surveillance (AVSS).
17. Jafar, M. T., Ababneh, M., Al-Zoube, M., & Elhassan, A. Digital forensics and analysis of
deepfake videos. (IEEE 2020).
18. Akandeh, A., & Salem, F. M. Slim LSTM NETWORKS: LSTM 6 and LSTM C6. 2019 IEEE.
19. Aneja, S., & Nießner, M. Generalized zero and few-shot transfer for facial forgery detection.
arXiv:2006.11863v1 [cs.CV] 2020.
20. Matern, F., Riess, C., & Stamminger, M., & Friedrich-Alexander. Exploiting visual artifacts to
expose deep fakes and face. 2019 IEEE Winter Application of Computer Vision Workshop.
21. Amerini, I., Galteri, L., Caldelli, R., & Del Bimbo, A. Deepfake video detection through optical
ﬂow based CNN. 2019 IEEE/CVF ınternational conference on computer vision workshop
(ICCVW).
22. Malolan B, Parekh, A., & Kazi, F. Explainable Deep-Fake Detection Using Visual Inter-
pretability Methods, 2020 3rd International conference on ınformation and computer tech-
nologies (ICICT).
23. Ranjan, P., Patil, S., & Kazi, F. Improved generalizability of deep-fakes detectionusing transfer
learning based CNN framework. (IEEE 2020).
24. Wang, X., & Yu, K., et al. ESRGAN: Enhanced super-resolution generative adversarial
networks. unpublished.

Epileptic Seizure Detection Using Deep
Bidirectional Long Short-Term Memory
Network
Mahima Thakur, U. Snekhalatha, M. Naveed Shaﬁ, Saumya Raj Gupta,
Sourabh Ranjan Roy, and S. Vineetha
Abstract An epileptic seizure is a disruption of the electrical signals in our brain.
An encephalogram (EEG) is widely accepted test that assists with the diagnosis
of epileptic seizures. Critical changes in frequency in EEG signals are observed in
patients experiencing such seizures. This study focuses on analyzing such signal
activities and classifying these high frequency signals observed in seizures from
those of healthy ones. A densely connected Bidirectional Long Short-Term Memory
(BiLSTM) is proposed for feature extraction and classiﬁcation of EEG signals.
BiLSTM has proven to be powerful in analyzing text-embedded sequences from both
directions (i.e., left and right), providing accurate results. The experimental ﬁndings
revealed that the proposed scheme obtained a satisfactory classiﬁcation accuracy
of 97–99%, indicating that it could be a helpful tool for adaptable diagnosis and
treatment of epileptics in the real world.
Keywords Bidirectional long short-term memory · Epileptic seizures · Time series
data · Encephalogram (EEG)
1
Introduction
Epilepsy is a neurological disorder characterized by epileptic seizures [1, 2], which
are episodes of vigorous shaking. Each shaking episode can last from brief to long
periods and it can result in physical injuries. The topic of epileptic seizures has been
deeply analyzed since the 1970s. In epilepsy, seizures tend to recur without warning
or any immediate underlying cause; for this reason, people with epilepsy experience
varying degrees of discomfort in their social life due to their condition [3]. Since
M. Thakur · M. N. Shaﬁ· S. R. Gupta · S. R. Roy · S. Vineetha
Department of Electronics and Communication Engineering, Faculty of Engineering and
Technology, SRM Institute of Science and Technology, Chennai, Kattankulathur 603203, India
e-mail: mt3178@srmist.edu.in
U. Snekhalatha (B)
Department of Biomedical Engineering, Faculty of Engineering and Technology,
SRM Institute of Science and Technology, Chennai, Kattankulathur 603203, India
e-mail: snehalau@srmist.edu.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_69
893

894
M. Thakur et al.
Table 1 A descriptive
impression of the dataset
Set
Recording setup
Case
Category
A
Surface-EEG
Eyes open
Healthy
B
Surface-EEG
Eyes close
Healthy
C
Intracranial-EEG
Interictal
Epileptic
D
Intracranial-EEG
Interictal
Epileptic
E
Intracranial-EEG
Seizure
Epileptic seizure
epileptic seizures arise inside the brain, the most common tests that specialist use
in order to diagnose epilepsy are the electroencephalogram (EEG) and the magnetic
resonance imaging (MRI). Tests involving recordings of EEG are used in order to
look for the causes of epilepsy and to observe the brain activity during seizures to
ﬁnd patterns that make it predictable [4, 5]. In the last few years, machine learning
techniqueshavebeenlargelyappliedalsotothemedicalﬁeld.Manymachinelearning
start-ups are intensively working on healthcare solutions that could potentially help
doctors to diagnose illness, make patients’ lives much easier or offer information
able to save lives Machine learning models in general have been heavily used just
in recent years and are continuing to grow can be identiﬁed in the technological
development: only starting from the new millennium we dispose of machines that
have the computational power that is needed for these type of techniques. The focus of
this study is on the problem of seizure prediction, of which we are going to analyze the
different cases in order to have a clearer and more complete idea of the deep learning
models potentialities on epileptic seizures data. The seizure prediction problem can
be treated as a classiﬁcation problem, whose aim is to predict a class associated with
eachsample.Basedonthisidea,amodelwithbaselayersofBidirectionalLongShort-
Term Memory (BiLSTM) network structure is used to analyze the text-embedded
sequence data of EEG signals of the popularly used Bonn dataset, developed in
Germany. A tabular description of the dataset is shown below. Each section of the
dataset incorporates to 20% of the whole dataset (Table 1).
2
Related Works
Seizure classiﬁcation and prediction by deep learning and machine learning methods
have been in pursuit by researches since the last ten years. Recent studies related to
seizure classiﬁcation have been discussed in this section.
Zhang et al. [6] employed an empirical mode decomposition method to extract the
interictal and epileptic EEG signals into multiple eigenmode function, and the corre-
lation coefﬁcient variable features, then combined it with SVM machine learning
model for classiﬁcation. Lu et al. [7] classiﬁed epileptic EEG using two benchmark
datasets, exploiting deep convolutional neural networks with residual connections.
[8] used both linear and non-linear machine learning classiﬁers to detect epileptic

Epileptic Seizure Detection Using Deep Bidirectional …
895
seizure activity by ﬁrst pre-processing the EEG data using discrete wavelet trans-
form (DWT) and arithmetic coding to detect epileptic seizure from normal healthy
signals. Mehla et al. [9] used Fourier analysis to decompose the EEG signals and
then classiﬁcation using SVM (Support Vector Machine).
[6] utilized convolutional neural networks to detect time-invariant features of the
EEG signals then, passed it through fully connected layers and ﬁnally classiﬁed
using softmax function. George et al. [10], took the TUH-Corpus EEG database and
distinguished the features using Tunable-Q wavelet transform (TQWT) then ﬁnally
feeding the data into artiﬁcial neural networks.
3
Dataset Description
The data adopted for this study is procured from Department of Epileptology at
University of Bonn, Germany (Andrzejak et al.). This is an EEG time series dataset
where the sample data were registered by the test taken of epilepsy patients. This
dataset has ﬁve sections (A–E). Each section has 100 text ﬁles. Each of these text
ﬁles has 4096 component samples of the EEG series (based on time) in ASCII format
code. The EEG signals were documented with a 128-channel system ampliﬁer. All
the ﬁve sets of signals were received the same way for this dataset. Using a special
Analog to Digital Converter (ADC), this data was transformed to digital format. With
a sampling rate of 173.61 Hz, the data was then continuously taped on a disk. A ﬁlter
of range 0.53–40 Hz was used for ﬁnally processing the dataset. Each segment signal
taken in the sets (A–E) had 100 channels with EEG section of 23.6 (in seconds) of
duration. The A and B sets were features of healthy person. Set A represented the
eyes-open state while set B were those of eyes-closed (both set of a healthy person).
The other three segments (C, D, and E) were related to the epileptic condition of
the brain activity. Five patients that were suffering from epileptic conditions were
taken into account. The sets C and D comprised of seizure free activities. Only Set E
incorporated the seizure episodes. For this study, only the distinguishing of seizure
episodes from the non-seizure episodes were taken for assessment and test for our
model. Discriminating the differed features of Set E from Set A, B, C, D were taken
for check. After a detailed analysis, it was observed that only the seizure class dataset
(Set E), had a signiﬁcantly high frequency from the other classes (Fig. 1).

896
M. Thakur et al.
Fig. 1 Sample comparison of recordings of Set A (healthy person) vs Set E (person with seizure
episodes)
4
Methodology
4.1
Initial Data Pre-processing
Considering a time portion of T + 1 discrete time steps in an EEG: the portion is
be characterized by a sequence of features [xt, xt+1, xt+2, …, xt+T], one for each time
step t, representing the signals amplitude in that instant.
The information vector (input data) of the EEG samples are transformed into a
binary format via the one-hot encoding technique This is a common useful approach
for converting categorical features into a format that can be used as an input to a
deep learning model. Two-dimensional and three-dimensional arrays are converted
for proper investigation as class categories. This means seizure data is labeled as 1
while the non-seizure data are labeled as 0.
In order to overcome the need of manually crafted feature extraction, scien-
tists have proposed Neural Network-based approaches for the task of detection
and classiﬁcation, as these types of models are able to learn efﬁciently unsuper-
vised aspects and features from the data. Sergeeva et al. [11] suggested a Recur-
rent Neural Network-based method that utilizes unsupervised word-embeddings and
character-level word-embeddings with pre-computed syntactic features as inputs.
A preview of the intuitions which led to using bidirectional LSTM model for usage
is given below:
Recurrent Neural Network: The recurrent neural network (RNN) is a deep neural
network used largely for sequential data processing [12]. A guided graph is set up by
the connection links of the neurons. RNN uses its own internal state to process the

Epileptic Seizure Detection Using Deep Bidirectional …
897
input data sequences, which makes it widely successful for NLP (Natural Language
Processing) based work. Each of the output is evaluated by carrying out the same task
function over each sample of the series data repeat mode. This way, the performance
gets evaluated based on all the previous evaluations.
Long Short-Term Memory Network: Based on RNN model structure, Long short-
termmemorynetwork(LSTM)deepneuralnetwork,whereforgetgatesareemployed
to eradicate the exploding or vanishing gradient problem. LSTM sufﬁciently allows
error back propagation through a ﬁnite number of time measures. A typical LSTM
unit cell has the three type gates, i.e., input gate, output gate, and a forget gate.
Depending on the open and close functions at the gates, the unit cell establishes when
the information should be retained and when the units should enter the information.
Given below are the explained equations:
ft = σg

W f xt + G f ht−1 + b f

(1)
it = σg(Wixt + Giht−1 + bi)
(2)
ot = σg(Woxt + Goht−1 + bo)
(3)
Ct = tanh(Wcxt + Gcht−1 + bc)
(4)
where the weights (Wf , Wi, Wo, and Wc) as input matrices for the hidden layer of
the three gates of the input cell, the Gf , Gi, Go, and Gc are the weight matrices that
connect the last previous cell output to the three gates as well as the input cell. The
four biases are bf , bi, bo and bc. The gate activation function, σg, and tanh refers to
the hyperbolic tangent function. Based on the results of four above equations, at each
time ‘i’ iteration t, the cell output state, Ct, and the layer output, ht, can be calculated
as follows:
Ct = ft ∗Ct−1 + it ∗Ct
(5)
ht = ot ∗tanh(Ct)
(6)
The ﬁnal output of the LSTM unit cell comes out in terms of yt.
Bidirectional Long Short-Term Memory Network: The principle behind the bidi-
rectional LSTM model is to assess the input data in both directions (that of left and
right) and train the base model. This method captures the complicated and multi-
variate patterns seen in longitudinal electronic health record data and continuously
recorded physiological signals, which are often used in acute condition estimation,
classiﬁcation, and phenotype analysis. The developed model (Fig. 2) using Bidirec-

898
M. Thakur et al.
Fig. 2 A diagrammatic intuition of the steps performed
tional LSTM leverages the inherent long and short-term developments and associ-
ated intuitions of the text-based documentation of the EEG signals of each of the ﬁve
states.
yt = σ

⃗dt,
←
d
t

(7)
When the bidirectional layer produces the classiﬁed output, say in terms of yt in
the above equation (for each state), σ function is used to combine the two output
classiﬁed sequences.
Since a bidirectional LSTM examines both left and right content given in terms
of
←
d (in above equation), it outperforms unidirectional deep neural architectures in
such type of predictions.
4.2
Two-Layer Stacked-Bidirectional LSTM
enlargethispage-12ptResultant FeatureExtractionProcess:Atwo-layer layeredbidi-
rectional LSTM architecture was developed to process time series EEG data based
on relevant analysis with different number of layers. As the dataset is composed
of text ﬁles with 4096 component samples, after including the index, a reshaped
input vector of (4097, 1) was passed to the network for feature extraction analysis.
Then, to obtain knowledge about the earlier stages of a time series, the input data
is given to the hidden layers in the forward direction. To recognize analyzed infor-
mation, units of hidden layers are placed in the higher hierarchies of the conﬁgured
architecture. Standard activation parameters of ‘tanh’ of the keras library in python
for the processing of the ﬁrst two main bidirectional layers. Here, the very efﬁcient
activation layer of ‘relu’ was taken. The model is then slightly extended with an
additional dense layer (also known as fully connected layer) after the Bidirectional
LSTM layers. Then, the outputs of the ﬁnal dense layer were concatenated using
a ‘softmax’ activation to determine the class attribution, which was namely either
seizure or non-seizure (Table 2).
Relu activation: In the secondary dense layer with 56 neurons, activation relu was
used. The equation for this activation function is given below:

Epileptic Seizure Detection Using Deep Bidirectional …
899
Table 2 Proposed two-layer stacked-LSTM model description
Layer name
Nodes/dropout rate
Output shape
Parameters
Activation function
Bidirectional
128
(None, 4097, 256)
133,120
Tanh
Dropout
0.25
(None, 4097, 256)
0
None
Bidirectional
128
(None, 256)
394,240
Tanh
Dropout
0.25
(None, 256)
0
None
Dense
56
(None, 56)
14,392
Relu
Dropout
0.35
(None, 56)
0
None
Final dense
2
(None, 2)
114
Softmax
frelu

hi,k

= max

0, hi,k

.
(8)
Here hi,k denotes the given input to the function and maximum positive value
reached. If the value of the function turns negative, it returns zero and for a postive
value it remits that value back.
Softmax function: Final dense layer has two 2 neurons which derives the output.
This resultant is calculated by using the softmax activation function
fSoftmax(xi) =
exp(xi)

j exp

x j

(9)
where x is the input vector, exp(xi) and exp

x j

are the exponential function of the
input vector and output vector, respectively (Fig. 3).
Categorical cross-entropy (CCE): A standard loss function used to compile the
train the model for solve classiﬁcation tasks. The CCE loss function seeks to maxi-
mize the log-likelihood of the N-sample training set, where h(i) is the index-score of
the true class for sample i:
LossCCE = −1
N
N

i=1
log
exp(wT
y j h(i))
K
k=1 exp(wT
k h(i))
(10)
5
Results and Discussion
Figure 4 shows accuracy and loss of the model over time based on same parameter-
epochs. The model quickly reaches a high accuracy of 97% and loss of 0.2092, within
a minimum number 25 epochs.

900
M. Thakur et al.
Fig. 3 Model ﬂow structure
This section further entails the statistical benchmarks utilized to assess the robustness
of the model:

Epileptic Seizure Detection Using Deep Bidirectional …
901
Fig. 4 a Training vs Validation accuracy b Training vs Validation model loss with the stacked-
bidirectional LSTM model
5.1
Confusion Matrix
We use a systematic analysis focused on different metric parameters to evaluate the
reliability of our proposed architecture. In the confusion matrix given in Fig. 5, the
matrix comprises classes epileptic seizure-(zero) and healthy-(one) where:
• True positives (TP): It indicates how many times the model correctly classiﬁes
which were actual healthy classes.
• False Positives (FP): It indicates how many times the model incorrectly classiﬁes
epileptic seizure patients as healthy persons.
• True Negatives (TN): It indicates how many times the model correctly classiﬁes
epileptic seizure patients.
• False Negatives (FN): It indicates how many times the model incorrectly classiﬁes
healthy persons as epileptic seizure patient.
Fig. 5 Confusion matrix for
the model where (0) is
Epileptic Seizure, (1) is
Healthy class

902
M. Thakur et al.
Table 3 Statistical results of the proposed model
Class attribute
Precision
Recall/sensitivity
F1-score
Overall accuracy
AUC
Healthy
0.99
0.98
0.98
0.97
0.98
Epileptic seizure
0.85
0.92
0.88
0.98
5.2
Statistical Parameters Observation
Precision: A statistical metric that measures how many optimistic results were accu-
rate. It is determined by dividing the cumulative count of true positives and false
positives by the number of true positives (Table 3).
Precision =
True Positives
(True Positives + False Positives)
(11)
Recall/Sensitivity: A statistical metric that measures how many accurate positive
predictions were made out of all possible positive predictions. It is determined by
dividing the total count of true positives and false negatives by the total value of true
positives (e.g., it is the true positive rate).
Recall/Sensitivity =
True Positives
(True Positives + False Negatives)
(12)
F1-score: A harmonic average of statistical measure of Precision and Recall, and
it provides a more accurate estimate of wrongly graded cases than the Accuracy
Metric.
F1 Score = (2 × Precision × Recall)/(Precision + Recall)
(13)
A precision recall curve (PR Curve) is a graphical analysis of the Precision
and Recall (on y-axis and x-axis, respectively) for various probability thresholds.
A horizontal line on the plot representing a no-skill classiﬁer would have a precision
proportional to the number of positive examples in the dataset. This would be 0.5 for
a balanced dataset. The PR curve is an effective diagnostic for imbalanced binary
classiﬁcation models since it focuses on the minority class.
5.3
ROC Area Under Curve (AUC) Score
While the ROC Curve is a valuable diagnostic tool, comparing the curves of two or
more classiﬁers may be challenging. The area under the curve, on the other hand,
can be used to calculate a single score for a classiﬁer model that is extended to all

Epileptic Seizure Detection Using Deep Bidirectional …
903
Fig. 6 ROC-AUC Curve of
classes (0) epileptic seizure
vs class (1) healthy patients
threshold values. The ﬁeld under the curve, or AUC, of the ROC is a representation
of this. For a perfect classiﬁer, the score is a number between 0.0 and 1.0 (Fig. 6).
5.4
Model Predictions
Figures given below depict how the model correctly classiﬁes instance measures
(in frequency) of EEG values of healthy people and people with epileptic seizure
episodes. The drafted signal values are expressed in graphs with the ground truth
class and model predicted output class observed with the percentage value of the
precision with which it stands (Fig. 7).
A closely related method of Golmohammadi et al. [13] investigated two LSTM
architectures with three and four layers, with a softmax classiﬁer, and found good
results. For similar feature extraction process, a 3-layered LSTM deep network is
deployed in [14]. The sigmoid classiﬁcation algorithm in the network’s last layer,
obtained 96.82% accuracy. Another experiment illustrates using two LSTM and GRU
model layers [15]. With a layer that functions to reshape, four layers of LSTM/GRU
with the activator, and one layer of Fully Connected (FC) with sigmoid activator
made up the LSTM, GRU model structure. In yet another study, Yao et al. [12]
used one layer of Fully Connected (FC) with sigmoid activator to get the greatest
accuracy out of 10 varied and improved Independently Recurrent Neural Network
with an accuracy 88.75%. The model used in this study uses a simple bidirectional
LSTM and brings an efﬁcient accuracy of 97% in just 25 epochs.

904
M. Thakur et al.
Fig. 7 Performance evaluation ﬁgures—a, b, c and d represent EEG signals of normal vs epileptic
seizure patients with different frequency ranges
6
Conclusion and Future Scope
Since epilepsy is now a progressive neurological condition, researchers continue to
look at different models for automated diagnosis. Various attempts in the past have
been made using Convolutional Neural Networks and Long Short-Term Memory
networks have been used to analyze the signal values using spectrogram visual anal-
ysis and sequence text-based detection for epileptic cases. The focus of this study
was to establish the usage of bidirectional LSTM model for the classiﬁcation of

Epileptic Seizure Detection Using Deep Bidirectional …
905
epileptic EEG. After deeply analyzing the Bonn EEG Dataset from Germany and
using optimal parameters for the model, it obtained an accuracy of range 97–99%
in the validation and test set. Although the seizure episodes comprised of only 20%
(a minority class) of the given dataset, the model was able to correctly predict such
episodes with ﬁne precision. Our future works include working to ﬁne-tune our model
more to implement to get similar accurate results on MIT-CHB scalp EEG dataset.
References
1. Chang, B. S., & Lowenstein, D. H. (2003, September). Epilepsy. The New England Journal of
Medicine, 349(13), 1257–1266, PMID: 14507951. https://doi.org/10.1056/NEJMra022308
2. Fisher, R. S., et al. (2014). Ilae ofﬁcial report: A practical clinical deﬁnition of epilepsy.
Epilepsia, 55(4), 475–482. https://doi.org/10.1111/epi.12550 PMID: 24730690.
3. Andrzejak, R., Lehnertz, K., Mormann, F., Rieke, C., David, P., & Elger, C. (2002). Indica-
tions of nonlinear deterministic and ﬁnite-dimensional structures in time series of brain elec-
trical activity: Dependence on recording region and brain state. Physical review. E, Statistical,
nonlinear, and soft matter physics, 64, 061907. https://doi.org/10.1103/PhysRevE.64.061907
4. Glory, H. A., Vigneswaran, C., Jagtap, S. S., et al. (2021). AHW-BGOA-DNN: A novel deep
learning model for epileptic seizure detection. Neural Computing and Applications, 33, 6065–
6093. https://doi.org/10.1007/s00521-020-05384-7
5. Srivastava, N., Hinton, G., Krizhevsky, A., et al. (2014). Dropout: A simple way to prevent
neural networks from overﬁtting. Journal of Machine Learning Research, 15, 1929–1958.
https://doi.org/10.1214/12-AOS1000
6. Zhang, Z., Li, Z., Ma, T., & Zhao, J. (2021). EEG signal classiﬁcation method based on
improved empirical mode decomposition and SVM. Journal of Physics: Conference Series,
1846, 012054.https://doi.org/10.1088/1742-6596/1846/1/012054
7. Lu, D., & Triesch, J. (2019). Residual Deep Convolutional Neural Network for EEG Signal
Classiﬁcation in Epilepsy. ArXiv, abs/1903.08100.
8. Amin, H. U., Yusoff, M. Z., & Ahmad, R. F. (2019). A novel approach based on wavelet analysis
and arithmetic coding for automated detection and diagnosis of epileptic seizure in EEG signals
using machine learning techniques. Biomedical Signal Processing and Control.https://doi.org/
10.1016/j.bspc.2019.101707
9. Mehla, V. K., Singhal, A., Singh, P., & Pachori, R. B. (2021). An efﬁcient method for identiﬁ-
cation of epileptic seizures from EEG signals using Fourier analysis. Physical and Engineering
Sciences in Medicine, 44(2), 443–456. https://doi.org/10.1007/s13246-021-00995-3.
10. George, T. S., Subathra, M. S. P, Sairamya, N. J., Susmitha, L., & Premkumar, M. (2020).
Classiﬁcation of epileptic EEG signals using PSO based artiﬁcial neural network and tunable-
Q wavelet transform. Biocybernetics and Biomedical Engineering, 40. https://doi.org/10.1016/
j.bbe.2020.02.001
11. Sergeeva, E., Zhu, H., Prinsen, P., & Tahmasebi, A. (2019). Negation scope detection in clinical
notes and scientiﬁc abstracts: A feature-enriched LSTM-based approach. AMIA Joint Summits
on Translational Science proceedings. AMIA Joint Summits on Translational Science, 2019,
212–221. https://europepmc.org/articles/PMC6568093
12. Yao, X., Cheng, Q., & Zhang, G.-Q. (2019). Automated classiﬁcation of seizures against
nonseizures: A deep learning approach.
13. Golmohammadi, M., Ziyabari, S., Shah, V., de Diego, S. L. Obeid, I., & Picone, J. (2017).
Deep architectures for automated seizure detection in scalp eegs. arXiv preprint arXiv:1712.
09776
14. Chen, X., Ji, J., Ji, T., & Li, P. (2018). Cost-sensitive deep active learning for epileptic seizure
detection. 226–235. https://doi.org/10.1145/3233547.3233566; Kumar, V., Singhal, A., Singh,

906
M. Thakur et al.
P., & Pachori, R. (2021). An efﬁcient method for identiﬁcation of epileptic seizures from EEG
signals using Fourier analysis. Physical and Engineering Sciences in Medicine. https://doi.org/
10.1007/s13246-021-00995-3.
15. Fukumori, K., Thu Nguyen, H. T., Yoshida, N., & Tanaka, T. (2019). Fully data-driven convolu-
tional ﬁlters with deep learning models for epileptic spike detection. ICASSP 2019—2019 IEEE
International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 2772–
2776), IET Digital Library. https://doi.org/10.1109/ICASSP.2019.8682196.119-124, https://
doi.org/10.1049/ccs.2020.0011

Disease Detection in Crop Management
Using Ensemble Machine Learning
J. Vakula Rani, Aishwarya Jakka, and Hamsini Kanuru
Abstract Agriculture is the backbone of a country’s economy and is one of the
major sources of economic growth. In India, majority of rural population depends on
farming for livelihood. Farmers play an important role to meet the ever-increasing
demands by maintaining the quantity and quality of the produce. The plant disease
is one of the factors which affect the productivity of the crop. Early detection of
plant diseases could signiﬁcantly save the crop from damage and, help the farmers
reduce the risk and maximize the proﬁts. Hence, automatic plant disease detection
is important to prevent the spread of the disease and reduce the damage. This study
aims to review a methodology for the analysis and detection of plant diseases using
image processing methods and ensemble machine learning techniques. The exper-
imental results show that the ensemble classiﬁers have better prediction accuracy
when compared to the other baseline classiﬁers.
Keywords Ensemble machine learning · Crop management · Produce · Crop
quality · Disease detection · Image processing · Baseline classiﬁers
1
Introduction
Agricultural Sustainability is very important to ensure and meet the ever-increasing
food needs for current or future generations [1]. By 2050, it is estimated that global
food production must be ampliﬁed by 60–110% to feed about 9 billion of the popu-
lation. Therefore, a strategic move from the recent enhanced farming yield model to
a more sustainable model is necessary. The agricultural sector is one of the broadest
J. V. Rani (B)
Department of MCA, CMR Institute of Technology, Bengaluru, India
e-mail: vakula.r@cmrit.ac.in
A. Jakka
University of Pittsburgh, Pittsburgh, PA, USA
e-mail: Aishwaryajakka@pitt.edu
H. Kanuru
Mahatma Gandhi Institute of Technology, Hyderabad, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_70
907

908
J. V. Rani et al.
economic sectors of the global economy. Agricultural crop production is an exclusive
business that depends on various climatic and ﬁnancial factors. Farming primarily
relies on weather, irrigation, soil, cultivation, nourishments, atmospheric tempera-
ture, rainfall, and pesticide/weeds. For the supply chain operation of companies, the
past crop yield information is vital to understand the trend of past activities and for
root cause analysis. The prediction of crop production and risk management support
these businesses to plan their supply chain decisions. Two factors supportive in deci-
sion making for agriculturalists and the government are (a) It supports the forecast.
It reduces the risk with the help of the historical crop yield record. (b) It assists
the government in decision making regarding crop protection and insurance policies
and strategies for supply chain activities. In traditional farming, people assume that
the conditions like moisture, soil, nutrient, and weed, and so on for all crops were
uniform. These assumptions often led to overdose or underdose of pesticides, irri-
gation, fertilizers, and other treatments. The use of Information Technology allowed
precision agriculture by bringing information from numerous sources to make better
crop production related decisions [2].
The primary objective of Machine learning is making machines learn automati-
cally without human intervention. The learning process starts with data, then looks for
patterns and makes optimal decisions in the future. It deals with computer programs
learning through experience, and a system fed with training input data makes changes
in its parameters and adjusts itself to give the desired output.
1.1
Machine Learning in Agriculture
Machine Learning techniques in agricultural systems at various production levels will
beneﬁt the farmers for efﬁciently managing their crops. This system mainly consists
of four phases: (a) Planning or Preparation Phase (b) Production Phase (c) Processing
Phase and (d) Transportation or Distribution Phase. First, the Planning or Preparation
Phase deals with the farm preconditions such as soil properties, irrigation, and crop
data. Next, the Production Phase deals with prediction systems like weather predic-
tion, disease detection, harvesting of the crop, etc. After the Production phase comes
to the Processing Phase that deals with Demand Management, Produce planning,
quality management, etc. Last, The Transportation or Distribution Phase deals with
Inventory management, Retail management, Transport management, Cold storage
management, and Consumer Analytics. Time Series based forecast models will be
well suited to monitor and predict the weather data. It helps the farmers to make
decisions based on the optimal conditions to cultivate the crops. Some of the appli-
cations of machine learning algorithms used in the prediction of crop management
are presented in Table 1.
This paper is prepared into 5 sections. 1 and 2 briefs the introduction and related
work. 3 and 4 sections describe the methodology, results, and its interpretation. The
conclusion and future work are presented in the last section.

Disease Detection in Crop Management Using Ensemble …
909
Table 1 Applications of ML in crop management
ML
algorithm
Description
Bayesian network
This classiﬁer calculates the class conditional probability and
prior probability and classiﬁes it into output classes using
Bayes Theorem. [3]. Model is used to forecast the quality of
the crop and weed extraction using weather data collected
from sensors. This is the best algorithm to optimize the event
triggers depends on sensor data and is supported by a
cloud-based decision support system. The irrigation schedule
depends on soil moisture and weather forecast
Linear and Multiple regression
A predictive technique uses input and output variables as a
mathematical equation to express their relationship [2]. This
model was used to predict the crop yield using Historical data.
The rainfall, farming area, and fertilizers, and crop production
as parameters for prediction
Logistic regression
Air temperature and moisture, carbon dioxide concentration
levels, soil moisture, and wetness of the leaf were used to
model and predict the safety and risk-free farm area for crop
yield [2]
Apriori algorithm
To ﬁnd the relationships between lemon and vegetables’
yield, atmospheric moisture, temperature, and soil wetness.
Association rules were used. Linear regression to model was
used to predict the appropriate temperature, soil moistness,
and humidity for the excellent crop yield [4]
Support Vector Machine (SVM)
The algorithm classiﬁes and deﬁnes multidimensional
boundaries by separating data points into output classes using
a boundary detection algorithm [4, 5] and using digital image
processing techniques to measure the amount of produce on a
branch. The produce is categorized into ripe fruits, not ripe
fruits, and fruits ignored for maturation. The number of fruits
in a branch approximated weight and the percentage of
maturation are critical parameters for yield production. This
method can be used for the prediction of the rice growth stage
Naives Bayes algorithm60
For crop disease detection and forecasting, historical data and
real-time data were used to model the system [6]. The
temperature, humidity, pressure, pH-value, nitrogen, soil, and
moisture parameters were used to monitor crop quality and
disease detection
Ensemble learning
Ensemble algorithms such as bagging leverage the crowd’s
knowledge by aggregating the ﬁnal output from several
models’ predictions [7]
2
Related Work
Wolfert et al. [1] presented the review on ML applications in crop management such
as yield-prediction, disease detection, weed-detection. They discussed ML and AI
based decision support system and how it helps the farmers to make precise decisions

910
J. V. Rani et al.
by guiding them through each decision stage and presenting the probability of various
outcomes resulting from different choices. Kamilaris et al. [8] explored big-data
applications in food and agriculture ﬁeld and presented the effects and interactions
among various players and the extent of beneﬁciaries. Steve Sonka et al. P. R. Rothe
and R. V. Kshirsagar [9] studied identiﬁcation of Cotton leaf disease using pattern
recognition techniques. They applied HU moments and active counter models to
identifying global attributes and infected areas on the leaf. BPNN classiﬁer was used
to handle the multiclass problem and achieved 85.52% accuracy. Mekonnen et al. [10]
used Bayesian network Model to forecast the quality of the crop and weed extraction
usingweatherdatacollectedfromsensors.Thisalgorithmoptimizestheeventtriggers
depends on sensor data and is supported by a cloud-based decision support system.
The irrigation schedule depends on soil moisture and weather forecast. Huang et al.
[4]workedonLinearandMultipleregressiontopredictthecropyieldusingHistorical
data. It had rainfall, farming area, and fertilizers, and crop production as parameters
for prediction. Air temperature and moisture, carbon dioxide concentration levels,
soil moisture, and wetness of the leaf were used to model and predict the safety and
risk-free farm area for crop yield. Su et al. [11] studied digital image processing
techniques to measure the amount of produce on a branch using Support Vector
Machine. Further, the produce is categorized into ripe fruits, not ripe fruits, and fruits
ignored for maturation. The number of fruits in a branch approximated weight and the
percentage of maturation are critical parameters for yield production. This method
can be used for the prediction of the rice growth stage. Wani et al. [12] studied the
crop disease detection and forecasting, historical data, and real-time data were used
to model the system. The temperature, humidity, pressure, pH-value, nitrogen, soil,
and moisture parameters were used to monitor crop quality and disease detection.
Korkut et al. [5] made use of DIP and ML approaches for automatic leaf disease
detection. Early detection can avoid unnecessary pesticides and could reduce costs.
They implemented deep learning techniques for extracting the features and achieved
94% accuracy. Sharma et al. [7] presented an SLR (Systematic-Literature-Review)
on use of ML in agricultural sector and provided insights about the present status of
ML applications and agricultural practices to improve the yield and quality of the
crops.
3
Disease Detection—Methodology
This work mainly focuses to identify the disease either from the plants or leaves with
an aim to achieve better accuracy. Ensemble bagging and boosting machine learning
techniques are implemented. Ensemble classiﬁers improve the prediction accuracy
by constructing a learning model from a linear combination of simpler base learners.
As each trained ensemble denotes a single hypothesis, ensemble of classiﬁers enables
hybridization of hypotheses from different base learners. This results in improved
performance when compared with the single model.

Disease Detection in Crop Management Using Ensemble …
911
3.1
Dataset Description
Cotton plant leaf image dataset is used for this study and is sourced from Kaggle. The
images are labeled into four categories, plant healthy, leaf healthy, plant infected, and
leaf infected images. Dataset comprises 1713 images which belong to four classes.
The feature vector size was (1713, 532). The image dataset was randomly split into
80% train data and 20% test data. Thus, approximately 1370 images were used for
the model training, while the remaining 343 images were kept for testing the model
performance. The diseased images are of leaves infected by fungal, bacterial, and
pest. The dataset image dimensions are 500 × 500 pixels, resolution 96 dpi, and bot
depth is 24. Figure 1a, b shows random samples of diseased plant and leaf images,
and Fig. 1c, d shows random samples of healthy plant and leaf images.
The spot of disease can be easily identiﬁed with the help of the infected area of the
leaf using image processing techniques. RGB is the most popular color space whose
color component is represented as a tuple (Red, Green, Blue). The dataset images are
in the form of BGR (Blue-Green-Red) and required to be converted into RGB to use
OpenCV image processing library. RGB image represents only color intensity, and it
cannot be used to separate color luminance from color information. Hu’s Saturation
Value (HSV) is used to separate image luminance from the color information. Next,
separate the image from the background by setting the background pixels to black
and the foreground pixels to white using region-based image segmentation. Based
on the color threshold range and convert the color range to grey scale using binary
Fig. 1 a Diseased Leaf sample b Diseased Plant samples c Healthy Leaf sample d Healthy plant
sample

912
J. V. Rani et al.
mask where 1 indicates the values within the threshold range, and 0 indicates the
value outside the range. Impose the binary mask on the top of the original image
which keeps every pixel in the given image if the corresponding value in the mask is.
It is observed that the resultant image has white stripes. This is overcome by adding
a second mask and combine both. Figure 2(a–e) shows (a) BGR image sample,
(b) RGB image sample, (c) HSV image sample, (d) image sample after ﬁrst mask,
(e) image sample after second mask.
Global features are extracted from the image using three feature descriptors shape,
texture, and color. Hue Moments are used to characterize the shape of an object in an
image. It performs the distribution of the number of pixels for each quantized bin and
is deﬁned for each component to get outline. The Haralick texture feature extraction
method is used to measure the perceived texture of an image. Texture tells about the
spatial arrangement of intensities in an image. Texture analysis describes the image
qualities such as rough, smooth, silky, or bumpy as a function of the spatial variation
in pixel intensities. Color histogram is used to represent the color distribution, type,
and the number of pixels in each type of color in the image. The extracted features
are stacked and encoded in numeric format for modeling. Now, the data is ready for
modeling. The vectorized data is randomly split into 80% train data and 20% test
data. Feature scaling is used to standardize the independent features of dataset and
bring them into a ﬁxed range for analysis. Then, the images are saved as HDF5 ﬁle
format to handle large heterogeneous complex data.
Machine learning models—K Nearest Neighbors (KNN), Decision Tree (DT), and
Ensemble models -Random Forest (RF), Bagging (Bagg), Extra Tree (ET), XGBoost
(XGB), ADA Boost (ADAB), and Gradient Boost (GradB) techniques were used to
for the experiment.
4
Results and Discussion
The KNN, DT, RF, Bagg, XGB, ADAB, and GradB models were implemented,
10 K-fold cross validation was done, and analyzed the performance.
Model performance analysis was made based on the prediction of incorrectly and
correctly classiﬁed instances and described by Confusion Matrix [13]. Accuracy is
measured as the ratio between correctly predicted instances to total instances. The
F1-Score metric tells about the goodness of the model and is the harmonic mean
between precision and recall. The classiﬁcation accuracy and F1-scores of the ML
algorithms are presented in the Table 2. Accuracy of ML algorithms is represented
by Box and shown in Fig. 3. The prediction accuracy of XGBoost, Random Forest
and ADA Boost are 98.18%, 97.33% and 97.18% respectively. It is observed that the
accuracy is enhanced by ensemble models when compared with base models.
Confusion matrix of KNN, and DT Tree Classiﬁer on cotton disease data set are
presented in Fig. 4. Here, the dark color boxes represent the model that predicts the
correct number of samples of respective classes from class-0 to class-3 (Fig. 5).

Disease Detection in Crop Management Using Ensemble …
913
Fig. 2 a BGR image sample, b RGB image sample, c HSV image sample, d image sample after
ﬁrst mask, e image sample after second mask
Table 2 Performance metrics
Technique
F1-score %
Accuracy %
KNN
89
90.54
DT
94
94.96
RF
93
97.33
Bagg
96
96.16
ET
96
97.25
XGB
97
98.18
ADAB
96
97.18
GradB
94
95.45
AUC-ROC curve is one of the gold standard metrics for model selection. It is a
probability curve for classiﬁcation and speciﬁes how good the model is to differ-
entiate the given classes, in terms of predicted probability. Curve is drawn between
FPR (False-Positive-Rate) and TPR (True-Positive-Rate). Receiver Operating Char-
acteristic (ROC) curve for binary classiﬁcation is presented in 4a. OneVSRest (OvR)
heuristic method is used to plot one class against the rest to convert multiclass to

914
J. V. Rani et al.
Fig. 3 Accuracy comparison of ML algorithm
(a) KNN                                                                  (b) DT
Fig. 4 a, b: Confusion Matrix generated by the models
binary class. AUC-ROC curves of RF Model are presented in Fig. 4b. Area under
the ROC cure for class-0, class-1, class-2, and class-3 VS Rest are 99%, 98%, 96%,
and 99% respectively.
5
Conclusion
With the ever-growing population, there is an increasing demand for food, hence it is
required to be a shift from the traditional agricultural methods. The use of Machine
Learning could bring in a more modern and sustainable approach to crop cultivation
which could improve crop yield. The use of machine learning algorithms for disease
detection improves agricultural productivity, efﬁciency, and monitoring harvest time.

Disease Detection in Crop Management Using Ensemble …
915
Fig.5 AUC-ROC curves of ML Model a) Random Forest (RF)
It is observed that Ensemble methods in machine learning give better performance
and accurate predictions when compared with base models. This work can be further
extended by applying ML in a smart crop management application in the agriculture
ecosystem.
References
1. Wolfert, S., Ge, L., Verdouw, C., & Bogaardt, M.-J. (2017). Big data in smart farming—A
review. Agricultural Systems, 153, 69–80.
2. H. Geli, L., & Prihodko, J. (2019, August). Climate adaptive smart systems for future
agricultural and rangeland production: College of agricultural [White Paper] (pp. 13).
3. Tantalaki, N., Souravlas, S., & Roumeliotis, M. (2019). Data-driven decision making in preci-
sion agriculture: The rise of big data in agricultural systems. Journal of Agricultural & Food
Information, 20(4), 344–380.
4. Huang, G.-B., Zhou, H., Ding, X., & Zhang, R. (2011). Extreme learning machine for regression
and multiclass Classiﬁcation. IEEE Transactions on Systems (pp. 513–529).
5. Deepalakshmi, P., Nagarajan, K., & Sumathi, K. (2019). Guided analytics platform for southern
region of Tamilnadu farmer fraternity. International Journal of Engineering and Advanced
Technology (IJEAT), 9, 5512–559.
6. Liakos, K. G., Busato, P., Moshou, D., Pearson, S., & Bochtis, D. (2018). Machine learning in
agriculture: A review. Sensors (Switzerland), 18(8), 1–29.
7. Sharma, R., Kamble, S., Gunasekaran, A., & Kumar, A. (2020). A systematic literature
review on machine learning applications for sustainable agriculture supply chain performance.
Computers & Operations Research, 119.
8. Kamilaris, A., Kartakoullis, A., Francesc, X., & Boldú, P., (2017). A review on the practice of
big data analysis in agriculture. Computers and Electronics in Agriculture, 143, 23–37.
9. Sonka, S., & Souravlas, S. (2014). Big data and the Ag sector: More than lots of numbers.
International Food and Agribusiness Management Review, 17(1).

916
J. V. Rani et al.
10. Mekonnen, Y., Namuduri, S., Burton, L., Sarwat, A., & Bhansali, S. (2020). Review—Machine
learning techniques in wireless sensor network based precision agriculture. Journal of the
Electrochemical Society, 167, 037522.
11. Su, Y. X., Huan, et.al. (2017) Support vector machine-based open crop model (sbocm): Case
of rice production in china. Saudi Journal of Biological Sciences, 24(3), 537–547
12. Wani, H., & Ashtankar, N. (2017). An appropriate model predicting pest/diseases of crops using
machine learning algorithms. IEEE 4th International Conference on Advanced Computing and
Communication Systems (ICACCS) (pp. 1–4).
13. Jakka, A., & Vakula Rani, J. (2019). Performance evaluation of machine learning models for
diabetes prediction. International Journal of Innovative Technology and Exploring Engineering
(IJITEE), 8, 1976–1980.

SVM, CNN and VGG16 Classiﬁers
of Artiﬁcial Intelligence Used
for the Detection of Diseases of Rice
Crop: A Review
Amit Verma
Abstract The production of grains plays a vital role for the economy of any country.
Smart methods are required that accurately helps to increase the efﬁciency of the
grain production. The use the techniques of the tools of artiﬁcial intelligence, deep
learningandimageprocessingarehighlightedinthispaper.Theseproceduresachieve
especially compelling results for the revelation of diseases using the photos of leaves,
seedsorreapﬁeld.Inthisspecialcircumstance,theworkpresentsareviewthatcenters
around precision agriculture for the high formation of quite possibly the main reap in
the world: RICE. In this paper, the classiﬁers SVM, CNN and VGG16 which utilizes
the methods of Artiﬁcial Intelligence utilized for crop illness location, seedlings
wellbeing, and grain quality are reviewed.
Keywords Artiﬁcial intelligence · Support vector machine · Convolutional neural
networks · Deep learning
1
Introduction
Cultivating is the bedrock of acceptability of any country’s economy. It has a key
effect in long stretch money-related turn of events and helper change [1]. According
to Food and Agriculture Organization (FAO) of UN, by 2050 the populace will
have expanded by 2 billion [2]. Conventional strategies which are utilized for the
executives of the yield sicknesses are extremely testing to perform. Though, the
crucial difﬁculty is the arrangement of these conventional strategies. The inadequate
spots are orchestrated to get ready people with the central quality and experience for
effectively execution of these strategies. Other difﬁculty is the time required to ﬁnish
these evaluations, which hinders quickly unique and enormous degree appraisal [3].
Rice crop is one of the essential collects on the planet and after wheat is acknowl-
edged as a central yield. For the economy of the immature country and for ranchers
the Rice is fundamental staple food and, the economy and ranchers are especially
A. Verma (B)
University Centre for Research and Development, Chandigarh University, Gharuan, Mohali,
Punjab 140413, India
e-mail: amit.e9679@cumail.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_71
917

918
A. Verma
relying on the Rice crop yield. The harvest yield is exceptionally inﬂuenced by
the negative effect of any sort. The harvest yield is inﬂuenced by the effect of a
mechanical damage, healthy need, genetically mess, climatic conditions, etc. Rather
than that, the difﬁcult issue is afﬂiction causing by macrobes and microorganisms.
Ailments remain a huge explanation behind return setback and lower beneﬁts in rice
crop creation. Ailments and vermin bugs yearly abatements the harvest yield by 8–
10%. Creation costs are furthermore extended by the use of compound and social
procedures for sickness control [4]. Exhaustively, Rice is farmed on the land with
about 66 mha with a yearly production of 745.17 mt of rice crop yield and ordinary
productivity by 4.48 t/ha as per FAO. It is evaluated that by 2025 880 mt of unfor-
giving rice ought to be conveyed with an enlargement of about 70% to satisfy the
growing masses essential as proposed by Lampe in 1995. In the nation like India,
complete locale of about 42.41 mha goes under the improvement of Rice during the
time of 2013 with yearly formation of 104.40 mt of paddy crop and 3.59 t/ha was the
typical proﬁciency of the harvest yield. It has been evaluated that continually 2021,
India needs to make 113.3 mt rice to fulﬁll the extending food need of the country.
Higher rice yield must be procured through improved cultivars and composed collect
and water system leader’s progressions. Huge restrictions for the afﬁrmation of better
returns of rice crop are its weakness to frightening little creature bugs, diseases and
abiotic stresses. In any case, the diseases achieved by parasites, minuscule living
beings, contaminations and nematodes are completely serious risks to help higher
creation and yield strength [5]. Experts have watched 10–15% ordinary yield setback
considering 10 critical infections of rice. Thusly, it is basic to recognize the ailments
of rice ideal for ensuring a down-to-earth formation of rice. Starting at now, when a
rice sickness scene happens some spot, rice illness specialists of different agribusi-
ness research centers or agriculture specialists visit the spot, and offer direction to
the farmers. In various domains, there are not acceptable rice afﬂiction professionals
stood out from the number of farmers. There is a staggering prerequisite for modiﬁed
rice disease acknowledgment using viably available devices in provincial zones [6].
Acknowledgements of paddy ﬁeld creepy-crawly vermin are testing on the
grounds that the bug nuisances are exceptionally explained, they display a serious
extent of intra-bother variety in size and shading, and some bug bugs are hard to
recognize outwardly, notwithstanding unmistakable dorsal designing. The measures
that are taken manually for the detection of the different diseases for the rice crops
can be very complex and requires considerable efﬁcient aptitude for the detection
process. This whole process of detection the diseases is even more complex when
there is presence of the pest insect and the analyst has to perceive the process from
the still images. The image of the pest insects which is taken using various prospec-
tive, jumbled foundation may change the whole process, for example, turn, clamor,
etc. So, the images of the insect pest that have taken will be extraordinary. In this
way, the improvement of a robotized framework for paddy ﬁeld creepy-crawly bother
distinguishing proof is of extraordinary hugeness. PC vision methods have incredible
importanceontheprogrammeddistinguishingproofofthepicturesofbugbothers[5].
Generally, the paddy crop farmers and agriculturists physically recognize the infec-
tion by using personal experience and further treating the distinguished ailments. The

SVM, CNN and VGG16 Classiﬁers of Artiﬁcial Intelligence …
919
use of manual experience for distinguishing the proof of sickness there is possibility
for mistakes. Anyway, in customary strategies time multifaceted nature is high and
it is difﬁcult, as it is difﬁcult to precisely recognize the illness and gauge its tainted
territory in serving huge size of cultivating [4].
It is very important for the crop yield that the disease and the pest insects will be
detected timely. For this purpose, there is requirement of technology and using the
technology the issues can be solved more precisely and accurately.
2
Classiﬁers Used for Automation Approaches
Distinctive new strategies are pointing toward the improvement of ailment and
nuisance location that assists with expanding the amount and nature of the yields
for the ranchers and the agriculturists. In farming ﬁeld, the Artiﬁcial Intelligence
(AI) machines and innovation have an extraordinary potential to give the data with
respect to the nature of soil, when to plant, where to shower herbicide, and where
there is most extreme likelihood of having the irritation pervasion. The AI Techniques
are utilized all-inclusive which helps the ranchers in improving the proﬁciency for
checking of yield wellbeing and utilized for illness the executives for pretty much
every crop. AI methods are utilized for making and creating savvy machines which
are utilized for crop the board with higher precision than human can do [7]. Agricul-
turists are embracing the methods of Artiﬁcial Intelligence and Machine Learning for
expanding the effectiveness of the harvest the executives which incorporate discovery
and restoring the yields from different sicknesses and nuisance creepy crawlies. The
wise frameworks are good to go to turn out to be most utilized methods in coming
days which reacts to the various circumstances which depend on learning and builds
the proﬁciency to handle these sorts circumstances [2]. As the innovation incre-
ments and there is simplicity of utilizing the innovation, the people have pushed
our restriction of the reasoning cycle and attempt to trade our typical cerebrum with
a fake one. This procedure with examination delivered a completely unique ﬁeld
Artiﬁcial Intelligence. It is the strategy by which a human can make an Artiﬁcial
Machines. Simulated intelligence utilizes the previous learning and ready to execute
the thoughts of the board dependent on these learnings [8]. The advances of Artiﬁcial
Intelligence, Machine Learning, Computer Vision, Satellite Imaging and Advance-
ment in Analytics are new time advances and are best condition for the production
of an environment required for brilliant cultivating. These innovations are expansion
to accomplish high normal harvest yield and the better value control for ranchers.
The discovery and relieving of rice sicknesses and irritation bug should be possible
in three phases which incorporates the pre-handling and division stage, highlight
extraction of the various maladies or bug bugs, and acknowledgment of the kind of
infection or bug creepy crawlies. These frameworks which are utilized as shrewd
frameworks for usage of the acknowledgment steps must have high identiﬁcation
and grouping precision. There are numerous methods with various effectiveness and

920
A. Verma
exactness which are utilized for the recognition motivations behind paddy sicknesses
and irritation creepy crawlies [9].
The main classiﬁers which are used for the automation process of detecting and
managing the Rice crop are: SVM (Support Vector Machine), CNN (Convolutional
Neural Network) and VGG16.
2.1
Support Vector Machine
Support Vector Machine or SVM used for the classiﬁcation or regression challenges
is a supervised machine learning algorithm. However, it is used mostly used in the
problems of classiﬁcation. In the SVM algorithm, the classiﬁcation is done by ﬁnding
the hyperplane is processed which can be used to differentiate the two classes by
plotting of each data is done in the n-dimensional space. The differentiation of the
classes is done very well using the SVM algorithm. In the ﬁgure, the classiﬁcation
of two classes is shown by using hyperplane (Fig. 1).
For the grouping and the relapse issues, the calculation with Support Vector
Machine is one out of the most mainstream utilized devices which are utilizing
the Machine Learning procedures. The calculation is proposed by Vapnik and Cher-
vonekis which depends on factual learning structure or VC hypothesis. SVM is one
of the most vigorous expectation techniques created at AT & T Bell Laboratories by
Vapnik with partners. SVM utilized as a classiﬁer is non-direct classiﬁer which can
organize the features into two classes. By introducing a hyperplane, the part vectors
were separated into various determined classes. Essential objective of SVM is to
achieve most outrageous detachment between the hyperplane and as far as possible
to avoid the misclassiﬁcation of the vectors into various class. The component vectors
whichareaccessibleatedgeofaclassandsubjecttowhichthehyperplanedetachment
is picked called as a help vector [10].
Fig. 1 Classiﬁcation of two
classes shown using
hyperplane

SVM, CNN and VGG16 Classiﬁers of Artiﬁcial Intelligence …
921
2.2
Convolutional Neural Network
The term Deep Learning or Deep Neural Network insinuates the Artiﬁcial Neural
Networks with different layers. All through the ongoing couple of decades, it has been
seen as one of the most essential resources and has gotten especially notable in the
composition as it can manage a massive proportion of data. The most notable signif-
icant neural system is the Convolutional Neural Network (CNN). It takes the said
name from activity of numerical linearity from the grids called convolution. Convo-
lutional Neural Network or CNN have different kinds of layers; which incorporates
convolutional, non-linearity, pooling and completely associated. There is distinc-
tion between these layers, convolutional and completely associated have limits and,
pooling and non-linearity don’t have any limits [11, 12]. The CNN has a fabulous
introduction in AI issues. Astoundingly the applications that oversee picture data, for
instance, greatest picture game plan instructive record (Image Net), PC vision, and
in like manner language planning (NLP) and the results achieved were amazingly
shocking. Convolutional Neural Network has vital results over the earlier decade in a
collection of ﬁelds related to structure afﬁrmation; from picture taking care of to voice
afﬁrmation [13, 14]. The most proﬁtable piece of CNNs is lessening the number of
limits in ANN. This achievement has instigated the two pros and designers to advance
toward greater models to handle complex tasks, which was unreasonable with excel-
lent ANNs. The hugest assumption about issues that are appreciated by CNN should
not have features which are spatially destitute. All things considered, for example,
in a face acknowledgment application, we don’t need to concentrate on where the
appearances are arranged in the photos. The primary concern is to remember them
paying little notice to their circumstance in the given pictures. Another critical piece
of CNN is to get hypothetical features when data multiplies toward the more signif-
icant layers. For example, in picture portrayal, the edge might be recognized in the
chief layers, and a short time later the less troublesome shapes in the ensuing layers,
and subsequently the more raised level features [15] (Fig. 2).
The above ﬁgure shows the basic concept behind the CNN in which the input is
taken as image and from the input to the output, the input image is processed through
different layers of the model [16, 17]. After the full processing of the input image
Fig. 2 Layers used in CNN for image identiﬁcation

922
A. Verma
the ﬁnal output is obtained which gives the result based on the classiﬁcations done
by the different layers of the model [18, 19].
Deep CNN designing is a featured strategy expected for signiﬁcant learning
of picture features. It contains a layer-based convolutional-deconvolutional model
expected for profound learning of picture features with Symmetric Skip Connections
(SSC) between turning convolutional-deconvolutional layers [13, 20]. The Continual
direct and non-straight limits involve the profound CNN. The straight capacities are
unequivocally conveyed by convolution undertakings and the non-direct capacity
imparts the ﬂighty exercises. The convolution layer understands the close-by prop-
erty of the paddy crop pictures, and starts complex part depictions of paddy ailments.
The more profound the model transforms into, the more imperative the impression
of pictures [21].
2.3
VGG 16
In Oxford University Visual Geometry Group Lab in 2014 a paper was presented
by two scientists named as Andrew Zisserman and Karen Simonyan and based on
the presented paper by the scientists a model named VGG 16 was proposed. The
VGG 16 model takes the ﬁrst and second spot on the above classiﬁcations in 2014
ILSVRC challenge [22–24]. The model accomplishes an accuracy of 92.7%, which
is among top ﬁve test exactness on the dataset of ImageNet which contains places of
1000 classes with almost 14 million images (Fig. 3) [25].
Fig. 3 VGG architecture used for image processing

SVM, CNN and VGG16 Classiﬁers of Artiﬁcial Intelligence …
923
The characterization of the network is done by its simplistic manner, in which
3 × 3 convolutional layers are stacked on top of one another in increasing manner.
Max pooling is used for reducing the volume size.
3
Methodology
The paper presents a review to identify the work which is related to the use of artiﬁcial
intelligence, neural networks and computer vision techniques for the management
which includes detection of the diseases and pest insects of rice. The review is based
on the approaches used for the identiﬁcation, detection of the rice disease using
techniques of artiﬁcial intelligence.
During development of harvest, the promptest and exact ﬁnding of the rice plant
afﬂictions ready to diminish the damage, and return in better insurance condition for
harvest and yield of yield. Phadikar et al. (2012) developed a mechanized structure
to mastermind the sicknesses like leaf earthy colored spot and the leaf impact of rice
plant subordinate upon the progressions of the morphological investigation of the
plants brought because of the contaminations. Classiﬁers reliant on Baye’s theory and
Support Vector Machines (SVMs) are applied to infected pictures for the portrayal
and the show which are examined. Circulation of the spiral of the shade from the
center to the spot at the limit pictures used as features to orchestrate the disorders by
Baye’s and SVM Classiﬁer. Just about, 500 instances of each data classes are utilized
to test the system. At the essential degree of portrayal (for instance uninfected leaf or
a sick leaf), it has been found that accomplishment rate is around 92% for uninfected
leaf, 96.4% for leafs with earthy colored spot and 84% for the leafs with impact.
In the work, a motorized structure has been delivered for perceiving two particular
kinds of maladies in rice crop. In the essential stage, gathering of the uninfected and
the ailing leaves are done, which relies upon the number of tops in the histogram.
Miss course of action may happen as a result of shadow effect and concealing turning
of developing leaves. In the resulting level Baye’s classiﬁer and SVM are applied
to amass the illnesses of the leaves. Time intricacy of the Bayes’ classiﬁer is O(N
× D2) where regarding the O(D × N2) of Support Vector Machine, where the part
of the element vector is D and the quantity of preparing tests is N. Since number of
tests normally much greater than the component of the element vector, thusly the
proposed system is time capable diverge from SVM. The system has been endorsed
using 1000 test spot pictures of polluted leaves of the rice crop accumulated from the
ﬁeld, which gives precision of 79.5% for Baye’s and 68.1% for SVM classiﬁer-based
structure independently [26].
Singh et al. (2015) proposed system is an approach to manage perceive by and
large happening ailment in rice plant speciﬁcally Leaf sway using Support Vector
Machine classiﬁer (SVM). With the progressing progress in picture getting ready
and structure afﬁrmation procedures, it is possible to develop an independent system
for infection plan in crops. The work is restricted inside the rice ailments just and

924
A. Verma
considered the most notable ailment in the district of North India, explicitly Leaf
Blast.Thepaperhasbeenisolatedintoﬁveterritories.FragmentIoverseessecuringof
pictures, Section II contains Image Pre-Preparing, Section III depicts about division
of Image, Section IV oversees Feature assurance and Feature extraction, Section V
portrays about SVM classiﬁer used for illness plan and Section VI include Result
assessment lastly end. The photos were taken from information base of International
Rice Research Institute. Division measure is ﬁnished using bunching calculation
K-mean and the polluted piece of leaf got. The surface component vectors which
were taken out from the divided pictures were given as classiﬁer’s info. The Support
Vector Machine can organize all maladies all the more exactly (82%) diverged from
various classiﬁers and neural system [27].
Chung et al. (2016) proposed a system to arrange seeds which are three-week-old
and debased with Bakanae disease. Polluted plants can yield void panicles or pass on,
achieving lost grain yield. The contamination happens practically sometimes when
dirtied seeds are used. At the point when the seeds are debased, the microorganism
Fusarium fujikuroi spreads in the ﬁeld. Thusly, corrupted plants must be screened at
early developmental stages. The photos of polluted and control seedlings were picked
up using ﬂatbed scanners to quantify their morphological and concealing qualities.
Backing vector machine (SVM) classiﬁers were delivered for perceiving the sullied
and strong seedlings. An inherited estimation was used for picking fundamental
qualities and ideal model limits for the SVM classiﬁers. The methodology proposed
in the paper perceived tainted and strong seedlings with an exactness of 87.9% and
a positive perceptive assessment of 91.8% [6].
Watching the amount of bug irritations is a fundamental section in pheromone-
based vermin the board systems. In this paper, Ding et al. (2016) propose a computeri-
zation recognition pipeline reliant on profound learning for recognizing and remem-
bering disturbances for pictures taken inside ﬁeld traps. The work prone to apply
top tier profound learning techniques to bug area and counting, suitably removing
the human from the hover to achieve a completely computerized, progressing bug
checking system. Applied to a dataset of business codling moth, the procedure shows
promising execution both emotionally and quantitatively. Stood out from past under-
takings at bug recognizable proof, this strategy uses no vermin express structuring
which engages it to conform to various species and conditions with unimportant
human effort. It is sensible to utilization on equivalent hardware and subsequently
prepared for sending in settings where constant execution is required. Abstract
and quantitative examinations display the sufﬁciency of the proposed strategy on
a codling moth dataset. Stood out from a large portion of past work, the proposed
strategy relies more upon data, and less on human data [28].
Prajapati et al. (2017) present a model system for recognizable proof and gathering
of rice crop sicknesses which relies upon the photos of corrupted rice plants. This
article tries for applying the thoughts of Machine Learning and Image Processing to
deal with the issue of the naturally location and gathering of diseases in the rice crop
ﬁeld, which is one of the noteworthy sustenance in India. On any plant, sicknesses
are achieved by microorganisms, creatures, and contamination [29–31]. This model
system is made after bare essential test examination of various techniques used in

SVM, CNN and VGG16 Classiﬁers of Artiﬁcial Intelligence …
925
picture taking care of undertakings. The work considers three rice plant infections to
be explicit Bacterial leaf curse, Brown spot, and Leaf muck. The photos of spoiled
rice plants had taken using a serious camera from a rice ﬁeld [32, 33]. At that
point tentatively they survey four methodology of establishment ejection and three
techniques for division. For engaging the exact extraction of features, they propose
centroid dealing with based K-infers gathering for division of disease package from
a leaf picture. They have improved the yield of K-suggests gathering by ousting
green pixels in the ailment separate. They separate various features under three
classes: concealing, shape, and surface. For multi-class portrayal they are utilizing
Support Vector Machine (SVM) and achieve 93.3% accuracy on planning dataset
and 73.3% precision on the test dataset and similarly perform 5 and 10-cover cross-
endorsements, for which the exactness achieved is 83.80 and 88.57%, independently
[34].
The paper by Pinki et al. (2017) proposed a system which is computerized in
nature for discovering three standard sicknesses of rice leaves: Leaf Blast, Brown
Spot and Bacterial Light Blight and pesticides just as fertilizers are instructed by the
earnestness concerning the contaminations. K-implies grouping strategy is used for
the conﬁnement of the impacted part from paddy leaf picture. To orchestrate these
sicknesses visual substance, for example, surface of leaves, concealing in leaves and
states of leaves are used for featuring measure. The sicknesses present in the rice
leaves are arranged by the classiﬁer Support Vector Machine. After the afﬁrmation,
the technique for relieving the ailment is proposed which helps people and agricul-
turists related to cultivation to take important activities against the contaminations.
The structure has two guidelines and organizes: The Training stage (Some infection
impacted paddy leaf pictures are used to set up the SVM) and The Testing Phase (Test
pictures are gotten by camera from the paddy ﬁeld. The request picture is dealt with
and features of this image are isolated using comparative techniques of the readiness
stage [35–37]. By then a segment vector is made for question picture. A segment
vector sent totheclassiﬁer for seeingthepaddyleaf diseases). This proposedstructure
has concentrated on seeing the paddy leaf contaminations which causes the farmers
to take an authentic assessment and extends the formation of paddy. The structure
shows generous result with an accuracy of 92.06% than some current methods [38].
An outline of the people densities of planthoppers present in the rice crop which is
criticaltodecidingdecisionsandviablemeasures[39,40].Regularmanualinspecting
of planthoppers presents in rice crop is monotonous, depleting, and dynamic. A
three-layer revelation procedure was proposed by Yao et al. (2017) to recognize and
perceive WBPH (white-upheld planthoppers) and their developmental stages using
picture handling. In the underlying two acknowledgment layers, they are utilizing a
classiﬁer named as AdaBoost classiﬁer which was set up on a histogram of orches-
trated slope features and a help vector machine classiﬁer which was set up on Local
Binary Pattern Highlights and Gabor to perceive White-Backed Planthoppers and
clears the contaminating impacts [41, 42]. The work achieved a distinguishing proof
pace of around 86% and a sham area pace of 10%. In the third acknowledgment
layer, a Support Vector Machine classiﬁer that was set up on the features of HOG
was used to recognize the particular developmental periods of the White-Backed

926
A. Verma
Planthoppers, and achieved a conspicuous conﬁrmation pace of 73%, a fake ID pace
of 23%, and a 6% fake area rate for the photos without planthoppers [43, 44]. The
new three-layer area system generally took generally 8 s to recognize and perceive
the planthoppers in a solitary rice picture. This amazingly truncated the survey time
in the paddy ﬁelds. As such, the method is conceivable and fruitful for the ID of
different developmental stages on rice plants planthoppers [45].
Rajmohan et al. (2018), presented a Sensor-based Mobile App framework for
precision agribusiness which outﬁts agriculturists with critical information about the
paddy yield and its condition. Our structure intends to make improvement progres-
sively productive as the agriculturist can pick better showed choices and along these
lines additional time and assets [46, 47]. The proposed Smart Paddy Pest Manage-
ment model is based on sensor compose intertwined to a ﬂexible application. The
methodology of the proposed framework incorporates two modules:
1.
Identiﬁcation of malady inﬂuencing the harvest.
2.
Management of malady which incorporates healing measure for infection.
Distinguishing proof of the infection is connected to perceiving what kind of
sullying is occurred in the paddy crop. Ailment Management is connected to choosing
the eventual outcome of contamination unmistakable veriﬁcation which are implied
to the farmer through versatile application [48]. Among the 200 sickly pictures,
number of really perceived pictures that have manifestations for Blast illness, Brown
spot malady, Bacterial leaf curse (BLB), Sheath scourge, bogus muck, Root tie
nematode and White tip contaminated recognized were only 175 under various
arrangement. The revelation accomplishment rate for considered paddy crop afﬂic-
tion impacted pictures is 87.50% [49]. The proposed framework which incorporates
Deep CNN and SVM classiﬁer is differentiated and the previous system which was
realized by joining k-implies and ﬂuffy rationale classiﬁer and KNN and SVM classi-
ﬁer.Itisfoundthattheproposedapproachhasbeendemonstratedtoachieveimproved
game plan [50].
3.1
Comparison
S. No.
References
Year
Technique
used for
disease
detection
Target
Used for
Accuracy %
1
S. Phadikar et al.
(2012)
Bayes’ and
SVM
Classiﬁer
Leaves
2 diseases
Baye’s—79%
SVM—68%
2
Amit et al.
(2015)
SVM
Leaves
1 disease
Achieves
accuracy of 82%
(continued)

SVM, CNN and VGG16 Classiﬁers of Artiﬁcial Intelligence …
927
(continued)
S. No.
References
Year
Technique
used for
disease
detection
Target
Used for
Accuracy %
3
Chung et al.
(2016)
SVM
Seedlings
1 disease
Accuracy—88%
and positive
predictive
value—92%
4
W. Ding et al.
(2016)
CNN
Insect
Pests
Not speciﬁc
to pest
The method
depends on data
and less on
knowledge
5
Yang Lu et al.
(2017)
CNN
Leaves
10 diseases
Using the
cross-validation
strategy for
tenfold, the
proposed model
achieves an
accuracy of 96%
6
B. Prajapati et al.
(2017)
SVM
Leaves
3 diseases
Training Dataset
Accuracy—93%,
and Accuracy
over test
dataset—73%
7
Farhana et al.
(2018)
SVM
Leaves
3 diseases
Average
Accuracy—92%
8
Yao Qing et al.
(2017)
AdaBoost
classiﬁer and
SVM
Paddy
ﬁelds
Density of
white-backed
planthoppers
Detection
rate—86% and
False Detection
rate—10%
9
R. Rajmohan et al.
(2018)
Deep CNN
and SVM
classiﬁer
Leaves
7 diseases
Detection
success rate for
considered paddy
crop disease
affected images
is 87%
10
P. K. Sethy et al.
(2018)
Fuzzy logic
and machine
vision tool
and SVM
Leaves
4 diseases
Estimated with
an accuracy of
86%
11
Vimal et al.
(2019)
SVM and
CNN
Leaves
4 diseases
Accuracy—91%
12
Rafeed et al.
2019
Stacked-CNN
and VGG16
Leaves
9 diseases
Accuracy—99%
(continued)

928
A. Verma
(continued)
S. No.
References
Year
Technique
used for
disease
detection
Target
Used for
Accuracy %
13
Wan-jie et al.
(2019)
CNN, SVM,
LBPH and
Haar-WT
Leaves
1 disease
CNN—96%
CNN +
SVM—96%
LBPH +
SVM—83%
Haar-WT +
SVM—84%
14
S. Rautaray et al.
(2020)
Architecture
of VGG-16 of
transfer
learning
Leaves
6 diseases
Accuracy of 90%
achieved
4
Conclusion
PCvisionstructuresarecurrentlycommonlyusedindifferentsectionsofhorticultural
creation and modern food creation. As rice plant illnesses can make a major measure
of misfortune in the agribusiness space, these systems can be used for identiﬁcation
of different sicknesses of rice crop all the more proﬁciently. Through these systems
are sufﬁciently proﬁcient to mechanize persevering tasks, in a non-hazardous way,
making adequate data for future examination. It was discovered that there are holes
to be satisﬁed with the improvement of clever gadgets that utilization PC vision and
man-made reasoning for mechanization of errands in the rice crop ﬁeld. PC vision
and AI procedures are a lot of fundamental to watch the power of illness. As the
open eye perception may result in helpless precision and it might shift individual to
individual. Finally, we point that this audit would present varying applications of the
classiﬁers SVM, CNN and VGG 16 and procedures of AI, picture and video taking
care of to move more examiners to apply them for dealing with agrarian issues at
present open.
References
1. Shrivastava, V. K., Pradhan, M. K., Minz, S., & Thakur, M. P. (2019). Rice plant disease
classiﬁcationusingtransferlearningofdeepconvolutionneuralnetwork.InternationalArchives
of the Photogrammetry, Remote Sensing and Spatial Information Sciences—ISPRS Archives,
42(3/W6), 631–635.
2. Simonyan, K., & Zisserman, A. (2015). Very deep convolutional networks for large-scale image
recognition.3rdinternationalconferenceonlearningrepresentations,ICLR2015—Conference
Track Proceedings, 1–14.

SVM, CNN and VGG16 Classiﬁers of Artiﬁcial Intelligence …
929
3. Ramesh, S., & Vydeki, D. (2020). Recognition and classiﬁcation of paddy leaf diseases using
optimized deep neural network with Jaya algorithm. Information Processing in Agriculture,
7(2), 249–260.
4. Albawi, S., Mohammed, T. A., & Al-Zawi, S. (2018, April). Understanding of a convolutional
neural network. Proceedings of 2017 international conference on engineering and technology,
ICET 2017, 2018-January (pp. 1–6).
5. Atole, R. R., & Park, D. (2018). A multiclass deep convolutional neural network classiﬁer
for detection of common rice plant anomalies. International Journal of Advanced Computer
Science and Applications, 9(1), 67–70.
6. Chung, C. L., Huang, K. J., Chen, S. Y., Lai, M. H., Chen, Y. C., & Kuo, Y. F. (2016). Detecting
Bakanae disease in rice seedlings by machine vision. Computers and Electronics in Agriculture,
121, 404–411.
7. Singh, G., Mishra, A., & Sagar, D. (2013). 3 1,2,3. 1, 3–6.
8. Rautaray, S. S., Pandey, M., Gourisaria, M. K., & Sharma, R. (2020). Paddy crop disease
prediction—A transfer learning technique. International Journal of Recent Technology and
Engineering, 8(6), 1490–1495.
9. Lu, Y., Yi, S., Zeng, N., Liu, Y., & Zhang, Y. (2017, July). Identiﬁcation of rice diseases using
deep convolutional neural networks. Neurocomputing, 267, 378–384.
10. Bashyal, B. M. (2018). Etiology of an emerging disease: Bakanae of rice. Indian
Phytopathology, 71(4), 485–494.
11. Murase, H. (2000). Artiﬁcial intelligence in agriculture. Computers and Electronics in
Agriculture, 29(1–2), 1–2.
12. Naeem, M., Iqbal, M., Parveen, N., Abbas, Q., Rehman, A., & Sad, M. (2016). An over view
of Bakanae disease of rice. American-Eurasian Journal of Agriculture and Environmental
Science, 16(2), 270–277.
13. Mukherjee, M., Pal, T., & Samanta, D. (2012). Damaged paddy leaf detection using image
processing. Journal of Global Research in Computer Science, 3(10), 2010–2013.
14. Patidar, S., Pandey, A., Shirish, B. A., & Sriram, A. (2020). Rice plant disease detection and
classiﬁcation using deep residual learning. Communications in Computer and Information
Science, 1240 CCIS, 278–293.
15. Verma, T., & Dubey, S. (2019). Fuzzy-ﬁltered neural network for rice disease diagnosis using
image analysis. International Journal of Innovative Technology and Exploring Engineering,
8(8 Special Issue 3), 437–446.
16. Pinki, F. T., Khatun, N., & Islam, S. M. M. (2018, January). Content based paddy leaf disease
recognition and remedy prediction using support vector machine. 20th international conference
of computer and information technology, ICCIT 2017, 1–5.
17. Rahman, C. R., Arko, P. S., Ali, M. E., Iqbal Khan, M. A., Apon, S. H., Nowrin, F., & Wasif, A.
(2020, December). Identiﬁcation and recognition of rice diseases and pests using convolutional
neural networks. Biosystems Engineering, 194, 112–120.
18. Patrício,D.I.,&Rieder,R.(2018,April).Computervisionandartiﬁcialintelligenceinprecision
agriculture for grain crops: A systematic review. Computers and Electronics in Agriculture,
153, 69–81.
19. Sladojevic, S., Arsenovic, M., Anderla, A., Culibrk, D., & Stefanovic, D. (2016). Deep neural
networks based recognition of plant diseases by leaf image classiﬁcation. Computational
Intelligence and Neuroscience, 2016.
20. Lurstwut, B., & Pornpanomchai, C. (2017). Image analysis based on color, shape and texture
for rice seed (Oryza sativa L.) germination evaluation. Agriculture and Natural Resources,
51(5), 383–389.
21. Khandelwal, P., Maharaj, R. T., Khandelwal, P. M., & Chavhan, H. (2019, September). Artiﬁcial
intelligence in agriculture: An emerging era of research article. Researchgate, 01, 01–08.
22. Venugoban, K., & Ramanan, A. (2014). Image classiﬁcation of paddy ﬁeld insect pests using
gradient-based features. International Journal of Machine Learning and Computing, March
2015, 1–5.

930
A. Verma
23. Xiao, M., Ma, Y., Feng, Z., Deng, Z., Hou, S., Shu, L., & Lu, Z. X. (2018, April). Rice
blast recognition based on principal component analysis and neural network. Computers and
Electronics in Agriculture, 154, 482–490.
24. Zhang, S., Li, X., Zong, M., Zhu, X., & Cheng, D. (2017). Learning k for kNN Classiﬁcation.
ACM Transactions on Intelligent Systems and Technology, 8(3).
25. Yao, Q., Chen, G. T., Wang, Z., Zhang, C., Yang, B. J., & Tang, J. (2017). Automated detection
andidentiﬁcationofwhite-backedplanthoppersinpaddyﬁeldsusingimageprocessing. Journal
of Integrative Agriculture, 16(7), 1547–1557.
26. Phadikar, S. (2012). Classiﬁcation of rice leaf diseases based on morphological changes.
International Journal of Information and Electronics Engineering, 2(3), 460–463.
27. Singh, A. K., & Raja, B. S. (2015). Classiﬁcation of rice disease using digital ımage processing
and svm classiﬁer, International Journal of Electrical and Electronics Engineers ISSN, 07,
294–299.
28. Ding, W., & Taylor, G. (2016). Automatic moth detection from trap images for pest
management. Computers and Electronics in Agriculture, 123, 17–28.
29. Joshi, A. A., & Jadhav, B. D. (2017). Monitoring and controlling rice diseases using Image
processing techniques. International Conference on Computing, Analytics and Security Trends,
CAST, 2016, 471–476.
30. Kumar Singh, A., & Raja, Bs. (2015). Classiﬁcation of rice disease using digital image
processing and SVM classiﬁer. International Journal of Electrical and Electronics Engineers
ISSN, 07(01), 294–299.
31. Kumar, P., Negi, B., & Bhoi, N. (2017). Detection of healthy and defected diseased leaf of rice
crop using K-means clustering technique. International Journal of Computer Applications,
157(1), 24–27.
32. Jha, K., Doshi, A., Patel, P., & Shah, M. (2019). A comprehensive review on automation in
agriculture using artiﬁcial intelligence. Artiﬁcial Intelligence in Agriculture, 2, 1–12.
33. Li, D., Wang, R., Xie, C., Liu, L., Zhang, J., Li, R., Wang, F., Zhou, M., & Liu, W. (2020). A
recognitionmethodforriceplantdiseasesandpestsvideodetectionbasedondeepconvolutional
neural network. Sensors (Switzerland), 20(3).
34. Prajapati, H. B., Shah, J. P., & Dabhi, V. K. (2017). Detection and classiﬁcation of rice plant
diseases. Intelligent Decision Technologies, 11(3), 357–373.
35. Gayathri Devi, T., & Neelamegam, P. (2019). Image processing-based rice plant leaves diseases
in Thanjavur, Tamilnadu. Cluster Computing, 22, 13415–13428.
36. Gupta, A. K., Solanki, I. S., Bashyal, B. M., Singh, Y., & Srivastava, K. (2015). Bakanae of
rice—An emerging disease in Asia. Journal of Animal and Plant Sciences, 25(6), 1499–1514.
37. Gurumoorthy, S., Rao, B. N. K., & Gao, X. Z. (2018, January). Cognitive science and arti-
ﬁcial intelligence: Advances and applications. Cognitive Science and Artiﬁcial Intelligence:
Advances and Applications, 1+.
38. Pinki, F. T., Khatun, N., & Islam, S. M. M. (2018, January). Content based paddy leaf disease
recognition and remedy prediction using support vector machine. 2017 20th International
Conference of Computer and Information Technology ICCIT 2017, , 1–5.
39. Eli-Chukwu, N. C. (2019). Applications of artiﬁcial intelligence in agriculture: A review.
Engineering Technology & Applied Science Research, 9(4), 4377–4383.
40. Islam, R., & Raﬁqul, M. (2015). An image processing technique to calculate percentage of
disease affected pixels of paddy leaf. International Journal of Computer Applications, 123(12),
28–34.
41. Shrivastava, V. K., Pradhan, M. K., Minz, S., & Thakur, M. P. (2019). Rice plant disease
classiﬁcationusingtransferlearningofdeepconvolutionneuralnetwork.InternationalArchives
of the Photogrammetry, Remote Sensing & Spatial Information Sciences—ISPRS Arch., 42,
631–635.
42. Rahman, C. R., Arko, P. S., Ali, M. E., Iqbal Khan, M. A., Apon, S. H., Nowrin, F., & Wasif,
A. (2020). Identiﬁcation and recognition of rice diseases and pests using convolutional neural
networks. Biosystems Engineering, 194, 112–120.

SVM, CNN and VGG16 Classiﬁers of Artiﬁcial Intelligence …
931
43. Sethy, P. K., Negi, B., Barpanda, N. K., Behera, S. K., & Rath, A. K. (2018). Measure-
ment of disease severity of rice crop using machine learning and computational intelligence.
SpringerBriefs Applied Science and Technology, 1–11.
44. Milosevic, N. (2020). Introduction to convolutional neural networks. 1–31.
45. Q. Yao, Chen, G. T., Wang, Z., Zhang, C., Yang, B. J., & Tang, J. (2017). Automated detection
andidentiﬁcationofwhite-backedplanthoppersinpaddyﬁeldsusingimageprocessing. Journal
of Integrative Agriculture, 16 1547–1557.
46. Bhar, L. M., Ramasubramanian, V., Arora, A., Marwaha, S., & Parsad, R. (2019). Era of
artiﬁcial intelligence: Prospects for Indian agriculture. Indian Farming, 3(69), 10–13.
47. Bhattacharjee, A., Kr, S., Soni, B., Verma, G., & Gao, X. Z. (Eds.) (2020). Machine learning,
image processing, network security and data sciences.
48. Chatterjee, A., & Das, A. (2020, January). Intelligence Enabled Research. 1109 (pp. 107–112).
49. Ahmed, K., Shahidi, T. R., Irfanul Alam, S. M., & Momen, S. (2019). Rice leaf disease detection
using machine learning techniques. 2019 international conference on sustainable technologies
for industry 4.0, STI 2019, May 2020 (pp.1–5).
50. Rajmohan, R., Pajany, M., Rajesh, R., Raman, D. R., & Prabu, U. (2018). Smart paddy
crop disease identiﬁcation and management using deep convolution neural network and svm
classiﬁer. International Journal of Pure and Applied Mathematics, 118 (15 Special Issue),
255–264.
51. Liang, W.-J, Zhang, H., Zhang, G. F., & Cao, H. X. (2019). Rice blast disease recognition using
a deep convolutional neural network. Scientiﬁc Reports, 9(1), 1–10.
52. Liu, Z., Gao, J., Yang, G., Zhang, H., & He, Y. (2016, March). Localization and classiﬁcation
of paddy ﬁeld pests using a saliency map and deep convolutional neural network. Scientiﬁc
Reports, 6.
53. Suresha, M., Shreekanth, K. N., & Thirumalesh, B. V. (2017, January). Recognition of diseases
in paddy leaves using knn classiﬁer. 2017 2nd international conference for convergence in
technology, I2CT 2017, 663–666.

Smart Dark Pattern Detection: Making
Aware of Misleading Patterns Through
the Intended App
S. Hrushikesava Raju, Saiyed Faiayaz Waris, S. Adinarayna,
Vijaya Chandra Jadala, and G. Subba Rao
Abstract The signiﬁcance of dark patterns is to deceive consumers when they are
exploring the internet. There were social networking sites such as LinkedIn, Face-
book, and others, where users discovered dark patterns whose goal was to steal users’
personal information or get them to click on advertisements. Dark patterns are created
by using the domains such as UI/UX. Although, there many kinds in which they trap
the users’ attention to focus though the advertisements on the websites where users
can be trapped and may lose their money. There are a few security concerns that
are required to detect the dark patterns through smart dark pattern detection. The
intended theme proposed in this case is designing the application through which
browsing could be done where any dark pattern advertisement is identiﬁed that
could be alerted through a dialog box. For detection, a novel dark pattern detection
approach is designed and considered as in-built application activity. The performance
and accuracy are the main factors that judge the intended theme is designed as per
the expectations.
Keywords Dark patterns · Application · Detection · Prevent misleading · IoT ·
Report generation
1
Introduction
Originally, the advertisements in websites would be one way of attracting the users
in clicking and leads to different behavior. This would lead to purchase some prod-
ucts or some activity that would beneﬁt the intended company income. This term
S. H. Raju (B) · V. C. Jadala · G. S. Rao
Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation,
Green Fields, Vaddeswaram, Guntur, India
S. F. Waris
Department of CSE, Vignan’s Foundation for Science, Technology and Research, Vadlamudi,
Guntur, India
S. Adinarayna
Department of CSE, Raghu Institute of Technology, Visakhapatnam, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_72
933

934
S. H. Raju et al.
is introduced by Harry Brignull who used in his Ph.D. thesis “cognitive science”
in 2010. There are many kinds of dark patterns that are listed and demonstrated
in the following table. According to originator, the dark patterns are listed in the
darkpaterns.org website (Table 1).
There is a sequence of activities to place in order to grab the users for reaching
the companies turnover and targets (Fig. 1):
The steps to be taken up for achieving the intended theme are provided as below:
(1)
Open the app designed with loaded signatures; it is customized to add new
signature or remove outdated signature also.
(2)
Open the website in the app for stopping the clicking and alerting such
advertisement is a dark pattern.
(3)
Once detected needs to provide prevention or blocking such advertisements so
that end user might experience normal usage but not unintended experience.
(4)
At last, a report is alerted or posted to authorized users.
Table 1 List of dark patterns that demonstrate how to behave
Kind of dark pattern
Description and its impact
Bait and switch
It resulted in unforeseen manner when user is about to do action
in desired manner. It provides value to the content and expects a
return. Example: It allows UX pin to get eBooks for an exchange
email address
Disguised ads
These are part of regular content, getting attention of user to
click. Example: The dafont.com site consists of alphabets,
misleads to click it. The main download is much smaller and less
visible than ZipMac, which has nothing to do
Forced continuity
It allows initially as free service (trial) and start charging after
trial period is completed. Example: Coursera is a global learning
platform that confuses the new users about the subscription
Friend spam
It asks for user email or social media permissions under false
believeness for their targets to achieve. Example: LinkedIn
where lawsuit cause ﬁne
Hidden costs
It involves a series of steps, where the last step shows
unexpected amount in which product price plus other amenities
like tax and other components are included. Example: Showing
speciﬁc amount in advertisement but shows more different
amount at the checkout
Misdirection
It targets to speciﬁc place but won’t notice something else is
happening. Example: Skype software update leads to two other
applications like Bing search engine as well as MSN as home
page
(continued)

Smart Dark Pattern Detection: Making Aware of Misleading …
935
Table 1 (continued)
Kind of dark pattern
Description and its impact
Price comparison prevention
It leads to not making informed decisions by the retailer and
makes hard for user to compare one item price with other item.
Example: LinkedIn gives free trail and never disclose its
premium subscription charges
Privacy Zuckering
It is found on Facebook where grabs the user attention over
certain things and returns their information publicly available
than speciﬁcally intended. Example: The zappier.com posts in
two modes in which one shows English form that everyone
understood it, and other is ﬁlled with legal jargon without
reading it
Roach motel
It throws the user into certain situation that won’t allow getting
out from that place. Example: Times of India in which once job
alerts are registered but won’t have a way to stop alerting
messages from the job portal
Sneak into basket
It expects purchase of one thing, but additional item is also
added during the purchasing journey automatically. Example:
GoDaddy site shows speciﬁc amount for three sites, but ﬁnal
amount includes privacy subscription also which is not meant in
the purchasing
Trick questions
It makes a tricky sentence that asks for one thing but intends to
do other thing. Example: Sky is responsible for products and
services that you like unless you click on opt-out
Big picture effects
It allows give a statement in the view of future or parallel factor
details but not focusing on small details. Example: Information
wielded against democracy during Trump contested in elections,
false news boosted clicks and helps to win trump
Fig. 1 Sequence of activities in the process of experiencing the dark patterns

936
S. H. Raju et al.
2
Literature Review
As per information provided by many resources, certain studies are to be mentioned
in order to create awareness of dark patterns and how to identify such patterns is a
signiﬁcant task.
With regard of demonstration provided in [1, 2], there are ways to exploit the
shoppers or users to attract and involve to do different behavior through their tricky
logics. Although there are bans on these in certain countries, but still many social
media sites are randomly involved these without their interference. Also, it describes
how to attract the persons in making decisions based on their jobs to be done (JTBD).
With regard of article mentioned in [3], the review of dark patterns are demonstrated,
various ways of dark patterns are explained, how to identify such patterns also spec-
iﬁed and this source act like a guide to the dark patterns. The need of dark patterns
is to make money based on the companies turn over and targets. With respect to the
demonstration of [4], this is a motivational study for the researchers where a lot of
products, a lot of websites are engaged the dark patterns whose aim is to grab the
users to do different behavioral mannerisms. Based on the nature of patterns, those
are classiﬁed into a few categories. The purpose and details of many dark patterns are
explored in this article. In regard of the information given in [5], the tricks that these
dark patterns will do is to be alerted early to the users. There are certain functions to be
known such as program analysis and few machine learning approaches are helpful in
determining the dark patterns. With regard to the data provided in [6], this is a survey
made on the dark patterns which aim to mislead the user to do something, also catego-
rize those into speciﬁc types and explored such patterns. In addition, the percentage
of users, who are aware of these patterns, was questioned, as well as the percentage
of users who are not aware of these patterns. With regard to source mentioned in
[7], the main objective is to perform three things like susceptibility, making victims,
and their impact on the users. There is a correlation factor, which determines the
type of pattern and its impact; the users depicted as victims are discussed. As per
the demonstration of study in [8], the nearby spatial devices that people would use
would experience the same dark patterns. This kind of proxemic (social) interactions
determines the root cause of having the dark sides and provides the solutions that
would minimize the dangers. With the respect to information of [9], there are types
of dark patterns, where the classiﬁed groups fall under categories labeled as pres-
sure, force, obstacles, sneaking, and deception. These categories would be further
decomposed into other services. As per the rationality of mentioned information in
[10], this also demonstrates the variety of dark patterns, their behavior over the users
and also provided the ways of stopping such patterns with the initiated steps. As
per study mentioned in [11], differences were listed between the common behavior
of UX-based dark patterns and AI and machine learning-based algorithms, which
are shown in the below diagram. The signiﬁcant difference is that the former allows
changing the behavior, which is impossible to know you are tricked, and the latter
helps to mislead the work as well as the outrage as tricked (Fig. 2).

Smart Dark Pattern Detection: Making Aware of Misleading …
937
Fig. 2 Difference in activities based on AI and machine based versus UX based

938
S. H. Raju et al.
With regard of source mentioned in [12], the book demonstrates various laws
and legal constructs against deceptive constructs over digital sites with respect to
Harvard journal of law and technology, Vol. 34. In the aspect of source mentioned in
[13], the dark patterns include varying designs based on platform they are available,
wherein the policies are based on technical, political, and security settings and are
demonstrated accordingly. In the view of mentioned information in [14], there are
speciﬁc machine learning classiﬁers that are proposed in order to determine the kind
of pattern which is not only dark pattern, may be of anti-pattern or other type. As per
the study of [15], this shows many statistical analysis on the various kinds of dark
patterns in terms of frequency, when they deceptive, etc. There are scenarios where
certain countries imposed a ﬁne against the some social running sites because of their
carelessness towards grabbing the users to perform misleading behavior. These laws
and ﬁnes are imposed by European legislative digital forum authority. With regard
to [16], the impact of dark patterns are analyzed, their unintended task would trick
the users, and also proposed techniques to minimize such patterns. They are also
reviewed in a systematical manner. With the aim to use patterns, the source given
in [17], the objective is to check come text is in large portion of data where it is
there within it or not using indexOf() which is also called onetime look indexing
method. It also allows many patterns at a time and report the statistics about the
patterns against the given text. With regard of information in [18], the novel tree
structure is built up for the incremental database, and helps to identify the popular
patterns in those databases. As per the description from [19], the crucial criterion
is applied over the temporal databases to determine the regularity in the patterns
with respect to various applications such as stock market, market basket, etc. In the
aspect of [20], all the complaints about the crime are registered in the law ofﬁce
after the violation of the law is identiﬁed by the police or by the automatic violation
design. With the view of mentioned information from [21], the household human
patterns are evaluated based on data mining techniques such as clustering, analysis
of energy utilization changes. As per the demonstration of [22], the apriori algorithm
is used in the infection-oriented health environment in early detection of diseases.
This could be made scalable using map reduce technique. The unusual data set can
be identiﬁed and could be removed. As per the source mentioned in [23], the sliding
window is used where leaves old transactions and includes new transactions. The
novel approach applied is used to determine positive and negative patterns from the
vertical format of the database and it won’t require to scan multiple times and also
not to construct trees. With regard to the information given in [24], the advancement
of mining over various application-oriented web sites in order to extract the frequent
and popular patterns. The limitations of FP-Growth are avoided by mining web usage
patterns for regular patterns.
As per the information speciﬁed in [25], the detection of islanding is done by
SVM-based approach and determines required locations using distributed generation
system. As per the source mentioned in [26], the detection of patterns over the ZNO
structures while loss of insertion in the SAW mixtures is done. With regard to the
information in [27], the image in the video is decomposed in order to capture the
license number using consecutive ANPR and RNPR frame works. As per the article

Smart Dark Pattern Detection: Making Aware of Misleading …
939
description given in [28], the efﬁciency is achieved by storing the frequent item sets
whose support count is same as earlier conventional approach count in a coalesce
matrix as a binary content. With regard to information in [29], the FP-growth and
apriori are applied in order to ﬁnd the regular patterns in multi-dimensional database.
It uses the extra time and also lazy pruning method. In the aspect of source mentioned
in [30], the difference between the center pixel and its neighbors are estimated and
are iterated based on the proposed different approaches for patterns on the required
applications. As per the demonstration of [31], the local edge detection versus the
same method with respect to the color feature would be extracted and compared
based on evaluation measures considered. With regard of description given in [32],
discovering the patterns using novel pattern discovery models is to be developed over
the text databases and are minimized the drawbacks associated with the existing data
mining techniques. With regard of demonstration of [33], the video is monitored
and color codes are assigned based on the activity behavior. Hence, the detection
of activities and color is marked on the progress bar. As per the source mentioned
in [34], the detection of animals crossing, speed breaker, and making alerts while
moving on the road. This guide helps to the driver in making a safe journey. As per
role mentioned in [35], objects are tracked when they have more weight satisfying the
cut off; those objects are spotted and are caught using IOT. In the view of description
mentioned in [36], the speciﬁc objects are tracked and reports are generated about
those scenarios.
Any article discussed above are useful for determining the patterns using data
mining techniques, machine learning technique and deep learning approaches.
Hence, the signiﬁcance is taken upon the methodology that could detect the patterns.
3
Proposed Work
In this, the modules identiﬁed are designing the app, identifying the dark patterns
by the app, displaying an icon over the misleading advertisements and alerting. The
designing the app involves sequence of steps like loading the webpage, scanning
the source code of the web page, Based on advertisement and its intension is to be
identiﬁed and adds the alert icon over the misleading advertisement. In this manner, it
leads to making aware of these misleading patterns. The objective of this system is to
alert the user because most of users who are browsing the websites are unintentionally
trapped and involved in such traps. Hence, the ER diagram of detection of dark
patterns through the app is demonstrated, as well as pseudo procedures of the modules
are demonstrated.
The ER diagram of smart dark pattern detection consist of modules where each
module’s functionality is achieved in terms of activities. In this, module is speciﬁed
in a rectangle and activities are speciﬁed in terms of use cases speciﬁed in ovals
(Fig. 3).

940
S. H. Raju et al.
Fig. 3 ER diagram of smart dark patterns detection and reporting
The intended app speciﬁes its inherent activities that include analyzing the loaded
web page using predeﬁned and efﬁcient extraction tool and reporting about the iden-
tiﬁed patterns in that web page as a statistical guide to the end-user. The objective
of this theme is to make aware of any user about the dark patterns and try to alert
openly in a virtual page which is similar to actual page but with alerted tags.
The pseudo procedure for smart dark patterns is deﬁned as below:
Pseudo_Procedure
SDP_Notiﬁcation_app
(website,
alertdialog[],
parser
_darkpatterns):
Step 1: open the app, register ﬁrst, and then login
Step 2: load the webpage, open that page in virtual crawler
Step 3: Call Analysis_page_source_code(code, detecting_signatures_Darkpatt[])
Step 4: Call alert and report (output_of_Step3)
The
pseudo
procedure
for
Analysis_page_source_code(code,
detecting
_signatures_darkpatt[]) is deﬁned as below:
Pseudo_procedure
Analysis_page_source_code(code,
detecting_signatures
_darkpatt[]):
Step 1: Read the any tag having money as assignment to the value attribute or
shopping address as anchor tag value or social address as value for anchor tag or
as link (or) settimer() method (or) bind() method

Smart Dark Pattern Detection: Making Aware of Misleading …
941
Step 2: If the part_code contains settimer() method (or) bind() method,
alert(“It is a tricky question—May be one of Confrishaping or Scarcity or
CountDowns or Nagging or SocialProof”)
Step 3: else if part_code contains negative force behavior like NO, Go Back or
deactivate account or traping for money
alert(“It is Force Continuity or Force Enrollment”)
Step 4: else if part_code contains Not revealing costs or Checking the membership
to close
alert(“It is Roach model or preselection or Hidden Information or Click-Fatigue”)
Step 5: else if part_code contains Sports direct magazine or extra products adding
into the basket
alert(“It is Sneak into basket or Hidden Subscription or Hidden Costs”)
Step 6: else if part_code contains membership status or ﬂashy visual elements or
record abnormal behavior or advertisement that allows to control
alert(“It is Trick Question or Misdirection or Bait and Switch or Disguised Ads”)
return output_Analysis_page_source_code that consist of detected patterns and
its type in a record
ThePseudoprocedureofalertandreport(output_Analysis_page_source_code[][])
is given below:
Step 1: Store the output_Analysis_page_source_code entity in dictionary form
Step 2: Find the length of output_Analysis_page_source_code
Step 3: For ﬁrst entity to last entity based on Step2 where I is loop variable
repeat
Create a Warning dialog for detected output_Analysis_page_source_code[i]
set the type detected from the output_Analysis _page_source_code(code,
detecting_signatures_darkpatt[])
until last entity is reached
Step 4: Records the click activity over the dark patterns
Step 5: Sends a report to the authorized user through the mail.
In the above-mentioned pseudo codes, where app is one module where authen-
tication is checked and opening and accessing the web page securely, the second
module analysis_web_page_darkpatterns in which built-in parser is used to identify
certain keyword texts, social media or shopping address parts, bifurcates such tags
into appropriate dark patterns, and those category of patterns are tracked in a record,
and the third module is alert, and report would track of such patterns, and such
patterns are tagged with dialog windows and would send a report to the concerned
mail (Fig. 4).
The below is the ﬂow chart of Smart dark pattern detection.

942
S. H. Raju et al.
Fig. 4 Flowchart of smart dark patterns detection
4
Results
The expected sequence of screens of this intended objective of the proposed system
is deﬁned as follows (Fig. 5):
In case of Fig. 6, a report on this page is prepared and alerted as well as posted to
the concerned mail (Fig. 7).
In case of Fig. 8, a report on this page is prepared and alerted as well as posted to
the concerned mail (Fig. 9).
The below are few snaps of the dark patterns to make aware of misleading the
user when they are browsing (Fig. 10):
The accuracy of SDP app is almost cent percentage compared to many existing
approaches in detecting variety of dark patterns which would mislead the user
behavior (Fig. 11):
Fig. 5 Sequence of activities in the initial stage of SDP app

Smart Dark Pattern Detection: Making Aware of Misleading …
943
Fig. 6 Identiﬁcation of monetary dark pattern in the gaming
Fig. 7 Report w.r.to Fig. 6
In the Fig. 9, the traditional approach reads the dark patterns by theoretical aware-
ness or softcopy of the practicing such patterns by training, the existing apps would
detect but not making aware of such advertisement which possess the dark patterns,
and the proposed objective SDP app makes the opened website in a virtual page and
tags if any such dark patterns are detected along with its type so that the user would
be in alert in clicking them.
5
Conclusion
The estimated objective of this research work is to alert the user by making aware
of the kind of dark pattern in the web page that the users utilize. The alerts would
be tagged in a virtual webpage when opened and in-built web page parser is used

944
S. H. Raju et al.
Fig. 8 Identiﬁcation of Roach Motel in the Digest Magazine
Fig. 9 Report outputted from Fig. 8
Fig. 10 Few example snaps of dark patterns

Smart Dark Pattern Detection: Making Aware of Misleading …
945
Fig. 11 Accuracy of detecting the dark patterns against the approaches vs. SDP App
to detect such patterns by tags or the keywords, also separate boundaries within
the web page with addresses related to social media or shopping, etc. This is a
way of informing the dark patterns so that user would be cautious. Although it is
alerted in a virtual page of an opened page in the designed app, the user activities
on these advertisements, which possess behavior of dark patterns are recorded, such
recorded activities are stored in a separate ﬁle and is communicated to the concerned
mail for future analysis. The accuracy is appreciable when compared to the existing
approaches. The advantages of intended ideology are detecting by loading the same
page in virtual page, making aware of dialogs for each predicted advertisement and
avoid internet users to be far from those advertisements. The accessing of the page is
fast because the page has been opened virtually. If any new signatures are discovered,
they must be added to the current list for further processing.
References
1. Wintermeier, N. (2020, June). Dark Patterns Examples in eCommerce: What they are & why
to avoid them. https://blog.crobox.com/article/dark-patterns
2. Wintermeier, N. (2021, March). Decision science & JBTD for personalization. https://blog.cro
box.com/article/decision-science-ebook
3. Maier, M., & Harr, R. Dark design patterns: An end-user perspective. Human Technology,
16(2), 170–199. https://doi.org/10.17011/ht/urn.202008245641
4. Mathur, A., et al. (2019, September). Dark Patterns at scale: Findings from a crawl of 11K
shopping Websites, 3, No. CSCW, Article 81. https://arxiv.org/pdf/1907.07032.pdf
5. Chen, C. (2019). Dark-pattern Web Detector. https://supervisorconnect.it.monash.edu/pro
jects/honours/dark-pattern-web-detector
6. di Geronimo, L., et al. (2020, April) UI dark patterns and where to ﬁnd them: A study on mobile
applications and user perception. CHI ‘20: Proceedings of the 2020 CHI conference on human
factors in computing systems (pp. 1–14), https://doi.org/10.1145/3313831.3376600

946
S. H. Raju et al.
7. Aditi, M., & Bhoot, et al. (2020, November) Towards the identiﬁcation of dark patterns: An
analysis based on end-user reactions. IndiaHCI 2020: IndiaHCI ‘20: Proceedings of the 11th
Indian conference on human-computer interaction (pp. 24–33), https://doi.org/10.1145/342
9290.3429293
8. Greenberg, S., et al. (2014, June). Dark patterns in proxemic interactions: a critical perspective.
DIS ‘14: Proceedings of the 2014 conference on designing interactive systems (pp. 523–532).
https://doi.org/10.1145/2598510.2598541
9. Dark pattern detection project. https://dapde.de/en/dark-patterns-en/types-and-examples-en/
10. Dark Patterns: A New Scientiﬁc Look at UX Deception. https://www.fyresite.com/dark-pat
terns-a-new-scientiﬁc-look-at-ux-deception/
11. Kinnaird, Z. (2020, October). Dark patterns powered by machine learning: An intel-
ligent combination. https://uxdesign.cc/dark-patterns-powered-by-machine-learning-an-intell
igent-combination-f2804ed028ce
12. Willis, L. E. (2020). Deception by design. Harvard Journal of Law & Technology, 34, Number
1 Fall. https://jolt.law.harvard.edu/assets/articlePDFs/v34/3.-Willis-Images-In-Color.pdf
13. Sinders, C. (2020, May). Dark patterns and design policy. https://points.datasociety.net/dark-
patterns-and-design-policy-75d1a71fbda5
14. Nord, R., & Kurtz, Z. (2020, March). Using machine learning to detect design patterns. https://
insights.sei.cmu.edu/blog/using-machine-learning-to-detect-design-patterns/
15. Caruso, F. (2019, November). Dark patterns: born to mislead. https://www.europeandatajou
rnalism.eu/eng/News/Data-news/Dark-patterns-born-to-mislead
16. Cara, C. (2020, January). Dark patterns in the media: A systematic review. https://www.resear
chgate.net/publication/341105338_DARK_PATTERNS_IN_THE_MEDIA_A_SYSTEMA
TIC_REVIEW
17. Raju, S. H., & Rao, M. N. (2016). Pattern matching using data preprocessing with the
help of one time look indexing method. International Journal of Pharmacy and Technology,
8(3), 18395–18407, ISSN: 0975–766X, http://www.ijptonline.com/wp-content/uploads/2016/
10/18395-18407.pdf
18. Kumar, G. V., Sreedevi, M., Bhargav, K., & Krishna, P. M. (2018). Incremental mining
of popular patterns from transactional databases. International Journal of Engineering and
Technology (UAE), 7, 636–641.
19. Kumar, G. V., Sravya, S. V., & Satish, G. (2018). Mining high utility regular patterns in
transactional database, International Journal of Engineering and Technology (UAE), 7, 900–
902.
20. Kumar, G. V., Sreedevi, M., Krishna, G. V., & Ram, N. S. (2018). Regular frequent crime
pattern mining on crime datasets. International Journal of Engineering and Technology (UAE),
7, 972–975.
21. Akhila, G., Madhubhavana, N., Ramareddy, N. V., Hurshitha, M., & Ravinder, N. (2018). A
survey on health prediction using human activity patterns through smart devices. International
Journal of Engineering and Technology (UAE), 7(1), 226–229.
22. Bisoyi, S. S., Mishra, P., & Mishra, S. (2018). Extracting global exceptional frequent pattern
from distributed data sources: A MapReduce approach. Journal of Advanced Research in
Dynamical and Control Systems, 10(2 Special Issue), 1460–1467.
23. Kumar, N. V. S. P., & Rao, K. R. (2018). A sliding window approach to mine negative and
positive regular patterns in incremental databases using vertical data format. International
Journal of Engineering and Technology (UAE), 7(3.27 Special Issue 27), 621–626.
24. Nallamala, S. H., Pathuri, S. K., & Koneru, S. V. (2018). An appraisal on recurrent pattern
analysis algorithm from the net monitor records. International Journal of Engineering and
Technology (UAE), 7, 542–545.
25. Rao, G. S., & Rao, G. K. (2018). SVM based pattern recognised islanding detection approach in
a multiple distributed generation system. International Journal of Engineering and Technology
(UAE), 7(1), 228–231. https://doi.org/10.14419/ijet.v7i1.9559
26. Santosh, G. S. K., Kumar, K. M., Kumar, K. P. M. S., Sai, K. B., Sravani, P., & Shanmukh,
G. (2018). Investigation of insertion loss in SAW delay line with periodically-patterned ZnO
structure. Journal of Advanced Research in Dynamical and Control Systems, 10(2), 541–546.

Smart Dark Pattern Detection: Making Aware of Misleading …
947
27. Rani, C. M. S., Dheeraj, K., Reddy, P. S. V., & Satyasai, K. (2018). Image segmentation
for pattern recognition in surveillance. International Journal of Engineering and Advanced
Technology, 7(3), 45–49.
28. Sireesha, M., Vemuru, S., & Rao, S. N. T. (2018). Coalesce based binary table: An enhanced
algorithm for mining frequent patterns. International Journal of Engineering and Technology
(UAE), 7(1.5 Special Issue 5), 51–55.
29. Sreedevi, M., Harika, V., Anilkumar, N., & Sai Thriveni, G. (2018). Regular pattern mining
on multidimensional databases. International Journal of Engineering and Technology (UAE),
7(2), 61–63. https://doi.org/10.14419/ijet.v7i2.20.11752
30. Sucharitha, G., & Senapati, R. K. (2018). Local extreme edge binary patterns for face recog-
nition and image retrieval. Journal of Advanced Research in Dynamical and Control Systems,
10, 644–654.
31. Sucharitha, G., & Senapati, R. K. (2018). Local quantized edge binary patterns for colour
texture image retrieval. Journal of Theoretical and Applied Information Technology, 96(2),
291–303.
32. Changala, R., & Rajeswara Rao, D. (2017). A survey on development of pattern evolving model
for discovery of patterns in text mining using data mining techniques. Journal of Theoretical
and Applied Information Technology, 95(16), 3974–3981.
33. Raju, S. H., Rao, M. N., Sudheer, N., & Kavitharani, P. Quick identiﬁcation of speciﬁc activity
by processing of large-size videos using advanced spotter. International Journal of Engineering
& Technology (UAE), ISSN: 2227–524X. https://doi.org/10.14419/ijet.v7i2.32.15712
34. Raju, S. H., Dr Rao, M. N. Dr Sudheer, N., & Dr Kavitharani, P. Visual safe road travel app over
google maps about the trafﬁc and external conditions. International Journal of Engineering &
Technology (UAE), ISSN: 2227–524X, https://doi.org/10.14419/ijet.v7i2.32.15697
35. Mothukuri, R., Raju, S. H., Dorababu, S. & Waris, S. F. Smart catcher of weighted objects
smart catcher of weighted objects. IOP Conference Series Materials Science and Engineering,
981(2). https://doi.org/10.1088/1757-899X/981/2/022002
36. Lalitha, V. L., Raju, S. H., Sonti, V. K., & Mohan, V. M. (2021). Customized smart object
detection: Statistics of detected objects using IoT. International Conference on Artiﬁcial Intel-
ligence and Smart Systems (ICAIS), 2021, 1397–1405. https://doi.org/10.1109/ICAIS50930.
2021.9395913

Use of a Recurrent Neural Network to
Identify Spammers on Twitter
Rahul A. Patil and Chetana C. Chaudhari
Abstract A great many individuals all throughout the planet are engaged with infor-
mal communication locales. Client encounters with such systems administration
media, like twitter, have huge and regularly undesirable consequences forever. Spam-
mers have become an objective for the dispersal of huge quantities of unimportant and
destructive data from the main informal communication locales. Twitter is among the
most lavish weblogs administrations ever and is normally used to post nonsensical
spam. Counterfeit clients give clients spontaneous tweets to embrace projects or sites
that sway genuine clients, yet additionally stop the utilization of assets. Moreover,
the potential has expanded to broaden clients with invalid data by means of wrong
personalities, bringing about vindictive material. Spammers and phony client and
phony tweets have as of late been distinguished on Twitter and turned into a per-
tinent examination ﬁeld in online organizations. The techniques used to recognize
Twitter spammers were recommended in this paper. Besides, Twitter’s spam sepa-
rating techniques are ordered dependent on their recognition capacity bogus data, a
URL, and pattern spam. Because of 12–9 capacities, including 6 as of late character-
ized capacities and 2 recently characterized capacities, two PC checked arrangements
have been found to separate among clients and spammers in a constant dataset.
Keywords Classiﬁcation · Social network sites · Spammers detection · Machine
learning · Social networks security
1
Introduction
Web network sites like Instagram, Facebook, and Twitter become unmistakable as of
late just as some online interpersonal interaction organizations. Individuals invest a
great deal of energy with online social network (OSN) befriending individuals they
know or like. The expanded interest in Web-based media permits clients to gather
plentiful information and client information. Also, the focal point of spammers is
R. A. Patil (B) · C. C. Chaudhari
Department of Computer Engineering, PCCOE, Pune, Maharashtra 411044, India
e-mail: rahul.patil@pccoepune.org
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_73
949

950
R. A. Patil and C. C. Chaudhari
drawing on a lot of information accessible on these pages. Twitter has immediately
ﬁlled in prevalence as a wellspring of continuous client information. Twitter is an
OSN that permits clients to share anything from news to perspectives to states of
mind. There are a few discussions on various issues, including ﬁnancial aspects,
current undertakings, and signiﬁcant occasions. On the off chance that a client posts
anything, they are promptly moved to their devotees to broaden the information on
a far bigger scope. The development of OSNs has built up the need of think about
and break the acts of clients during on the Web get-togethers. Numerous individuals
with little data on the OSNs can be deluded by fraudsters absent a lot of exertion.
There is additionally an interest in battling and controlling individuals who just use
OSNs for exposure and spamming different reports thusly.
Analysts have as of late been drawn by spam acknowledgment on person to person
communication locales. Spam recognition is a difﬁcult task to guard interpersonal
organization security, and spams are fundamental in OSN areas, which are utilized to
shield clients from different types of malignant attacks. These unsafe developments
by spammers really cause the organization to fall massively. Twitter spammers have
different points, like the spread of invalid, phony, and uncontrolled data. Spammers
accomplish their destructive objections with advertisements and various strategies
where they store different mail records and afterward send spam messages indis-
criminately to communicate their propensities. The principal customers recognized
as non-spammers are grieved by these activities. Moreover, the reputation of the OSN
stages is additionally diminished. It is then fundamental to system a spammer spot
plan to neutralize their insidious activities with helpful endeavors.
For the scholarly community and the business world to ﬁnd stored thoughts and
ﬁgure designs on Twitter, the capacity to arrange signiﬁcant data is signiﬁcant.
Nonetheless, on Twitter, spam delivers a great deal of commotion. To powerfully
follow spam, analysts utilized calculations for machine learning to order spam dis-
covery. Spam recognition is a difﬁcult task to guard interpersonal organization secu-
rity, and spams are fundamental in OSN areas, which are utilized to shield clients
from different types of malignant attacks. Indeed, it is more reasonable to arrange a
tweet broadcast as opposed to Twitter client as a spamming or non-spamming.
2
Related Work
Writing study is the main advance in any sort of exploration. Before begin creating,
we need to examine the past papers of our space which we are working and based
on investigation. They would anticipate or supply the impediment and continue to
work utilizing practice tests as a guide. We quickly review the associated studies
with spam detection and their various approaches in this section.
Sirivianos et al. [1] describe the SybilRank, a compelling and productive phony
record deduction conspire, which permits OSNs to rank records as indicated by their
apparent probability of being phony. It chips away at the separated information with
the organization so it recognizes, check and eliminate the fake records.

Use of a Recurrent Neural Network to Identify Spammers on Twitter
951
Kruegel et al. [2] describe that, in any case, when a nectar account is not really
answered, it allows us to distinguish spam proﬁles. The erratic behavior of a client
database being discovered, and a pattern is designed based upon it to identify spam-
mers.
Song et al.[3] state that a spam separating technique for interpersonal organiza-
tions utilizing connection data among clients that is availability as the highlights is
difﬁcult to control by spammers and compelling to group spammers.
Caverlee et al. [4] state that system dissects how spammers who target inter-
personal interaction locales work for collecting the information regarding to the
spamming movement, the logic made an enormous course of action of “proﬁles” on
three gigantic person to person communication destinations.
According to Nathan Aston et al. [5], during the execution highlight decrease, we
had the option of building an input layer and a classiﬁer based on calculations that
are reasonable in the climate stream. The author proposes foster strategies in which
the twitter concept is resolved quickly and precisely for a large scale.
Thomas et al. [6] state that “Suspended accounts in retrospect: An analysis of Twit-
ter spam” practices the spammers by investigating the tweets on twitter that are reply
by delayed clients everything considered. An arising spamming-as-a-administration
that incorporates respectable and not-so-trustworthy offshoot programs, advertise-
ment that depends on Twitter account merchants.
Ma et al. [7] state that “Design and evaluation of a real-time URL spam ﬁltering”
administration constant framework for separating trick, URLs for malicious Web
sites because they are reported to the site administrations. Ruler’s design sums up to
various sites administrations is focused by URL spam, exact grouping relies on a
close comprehension of fake crusades manhandling a help.
Lin et al. [8] state that “Social spam guard: A data mining based spam detec-
tion system for social media networks” is independently gathering fake exercises
in informal organization by observing monitors for socializing with famous client
bases. Presenting both picture and text content highlights and informal community
highlights to demonstrate spam exercises. Grouping calculation to deal with enor-
mous scope information. Presenting an adaptable dynamic learning way to deal with
distinguish present fake with restricted user endeavors, and Perform online analysis
that how to identify spams continuously.
Ghosh et al. [9] state that “Understanding and combating link farming in the
Twitter social network” the motors ranking sites/site pages dependent on diagram
measurements, for example, for getting the highest pagerank, the high degree assists
of PageRank. To follow the Connection on twitter cultivating for identifying Spam-
mers on different clients and endeavor to follow back.
Benevenuto et al. [10] describe the “Detecting tip spam in location-based social
networks” in the mainstream the LBSN framework that is brazilian is recognize by tip
spam speciﬁcally Annotator. The view of named assortment that follow by annotator
just as crept data about clients and areas, we recognized various characteristics spam
is recognize from non-spam tips.
Boshmaf et al. [12] state that “Thwarting fake osn accounts by predicting their
victims”, in this, author ventures out and proposes to fuse forecasts about casualties

952
R. A. Patil and C. C. Chaudhari
of obscure fakes into the work processes of existing protection components. In par-
ticular, they researched how such a mix could prompt more vigorous phony record
protection systems.
3
Proposed System
In this framework, interaction of spamming tweet recognition utilizing ML tech-
niques. Prior to grouping, a classiﬁer that contains the information construction
ought to be prepared includes the tweets that have already been categorized. Follow-
ing that, characterization model acquires the information construction of preparation
information, it very well may be utilized to anticipate another approaching tweet. The
entire cycle comprises of 2 stages: to learn and characterizing. Highlights tweets is
separated and organized as just a vector. For example spamming and non-spamming
is getting by means of different methodologies. Highlights and class name is joined
as case for preparing.
The preparing tweet would further able to be addressed by a couple existing
component vector, that addresses a tweet, and normal outcome, setting the vector
preparation. The equipment is the passage into the computer study calculation, and
the plan of grouping is constructed after the learning stage. During the classiﬁcation
process, tweets secured by time are marked with a qualiﬁed characterizing model.
The set preparation is contribution of ML technique, grouping model is worked on
wake of preparing measure. In the grouping cycle, convenient caught tweets will be
marked by the prepared characterization model.
3.1
Proposed System Beneﬁts
• Extraction of 12–14 features (content, metadata, interaction) and their classiﬁca-
tion as Tag and URL dependent features.
• Framework carries out a technique which will utilize spot channel instrument to
identify if the message is abuse.
• Platform that performs the use can also be facilitated online for its utilization and
the information will be put away and gotten from worker.
• User with greatest number of abuse can be obstructed from the platform.
• Execution appraisal done on dataset by using TPR, FPR, precision, recall, and
F-measure.

Use of a Recurrent Neural Network to Identify Spammers on Twitter
953
3.2
Proposed System Architecture
A proposed system of this work is as shown in Fig.1, and we are going to explain
the details of the proposed system as follows.
1. Feature Extraction: Extraction of 10–12 highlights and classiﬁcations as tag-based
highlights andURLbasedhighlights. Client-basedhighlights wereseparatedfrom
the JSON object client, for example, account_age, which can be determined by
utilizing the assortment date short the record made information. Other client based
highlights, as no_of adherents, no_of followings, number of user favourites, num-
ber of lists, and number of tweets, can be straightforwardly parsed from the JSON
structure. Tweet-based highlights incorporates no_retweets, number of hashtags,
number of usermentions, number of urls, number of chars, and number of digits.
While number of chars and number of digits needs a little ﬁguring, i.e., checking
them from the tweet text, others can likewise be directly extricated.
2. Feature Statistics: Framework assess the spam observation execution on dataset
by utilizing machine learning techniques.
3. Tweet Processing: Using ML techniques, framework evaluates the spam acknowl-
edgment execution on dataset
4. Spam tweet detection on ML based: This comprises of Naive Bayes, and spam-
ming tweets are fundamentally utilized for separate and furthermore utilized in
text characterization. Naive Bayes classiﬁers work by associating the utilization
of tokens (normally words, or here and there different things), with spam and non-
spam tweets and afterward utilizing Bayes’ hypothesis to compute a likelihood
that a tweets is or is not spam.
Fig. 1 Proposed system architecture

954
R. A. Patil and C. C. Chaudhari
3.3
Algorithm
3.3.1
Recurrent Neural Network (RNN)
As seen in Fig.2 [11], let our entry x for an RNN be a sequence with a T, x =
x1, x2, . . . , xT length and a feature vector for each xt object (Fig. 2).
At time t in Eqs. (1) and (2), the new ht that is hidden layer status and yt is the
output layer status can be determined using the previous hidden level status ht −1,
ht = σh(whxt + Uhht −1 + bh)
(1)
yt = σy(wyht + by)
(2)
In which, wh and wy refer, respectively, to weight matrices from input to hidden
and to hidden output, Uh is the matrix of recurring weights between the layer unseen
and themselves at two adjacent timescales, bh and by are biases.
At each step, the input is spread by default, followed by a learning law. The
back ties lead to background units still having a copy of the previous hidden units
(since they propagate over the connections before the educational rule is applied).
The network will then sustain a state and execute tasks such as sequence estimation
beyond the potential for conventional multilayer awareness.
Equation (3) is for determining the present situation:
ht =

(ht −1, xt)
(3)
wheres,
ht = present state ht −1 = Last state xt = state of the input. Equation (4) is for
applying Activations functions:
ht = activation(whhht −1 + wxhxt)
(4)
where, whh = Weight-at-recurrent-neuron wxh = Weight-at-input-neuron.
Fig. 2 Recurrent neural
network [11]

Use of a Recurrent Neural Network to Identify Spammers on Twitter
955
Output Eq. (5) formula:
yt = wh yht
(5)
where, yt = Output wh y = The output layer’s mass.
4
Results and Discussion
1. Positives and Negatives: Assume that t for tweet and S for the class of spam. In
that t is in to S or not, that is determined by the classiﬁer’s output. True positives
(TP), false positives (FP), true negatives (TN), and false negatives (FN) are all
widely accepted variables that affect a classiﬁer’s performance. These parameters
were just as follows:
• The tweets TP of S class are accurately named having a place with class S.
• The tweets FP is not having a place with S class inaccurately named having a
place with class S.
• The TN tweets are not having a place with S class effectively named not having
a place with S class.
• The FN tweets of S class are erroneously named not having a place with S
class.
We likewise use conditions (6) and (7) to ascertain the true-positive-rate (TPR)
and false-positive-rate (FPR) to survey the capacity to distinguish spam.
• TPR is called as the proportion of spam tweets accurately named spam to the all
out number of spam tweets, and it tends to be determined utilizing the equation
TPR = TP/(TP + FN)
(6)
• The ratio of nonspam tweets wrongly categorized as the class S is spam to the
overall count of tweets that are nonspam is called as the FPR.
FPR = FP/(FP + FN)
(7)
2. Precision, recall, and F-measure: By using precision equation (8), recall equation
(9), and F-measure equation (10), evaluate the performance of per class.
• Precision is called as the proportion of tweets classiﬁed as a S class versus those
classiﬁed as S class. It can be calculated using the formula
Precision = TP/(TP + FP)
(8)
• The proportion of the tweets accurately named having a place with class S to
the complete number of clients in class S is depicted as recall (otherwise called
identiﬁcation rate in the recognition situation).

956
R. A. Patil and C. C. Chaudhari
Table 1 Online results
Parameters
Percentages (%)
TPR
84.6
FPR
77.8
Precision
61.1
Recall
84.6
F-measure
71.0
Accuracy
90.0
Fig. 3 Online dataset results
Recall = TP/(TP + FN)
(9)
• F-measure is a blend of exactness and review, it is a broadly receive metric to
assess per class execution, and it tends to be determined
F-measure = (2 * Precision * Recall)/(Precision + Recall)
(10)
As a result, as given in Table 1 Owing to the drop in precision, the F-measure, is a
mixture of precision and recall low signiﬁcantly. We are trying to ﬁnd the online
dataset accuracy and that is quite difﬁcult to ﬁnd it. So the accuracy for online
data is 90%. Table 1 shows the real-time dataset that is online dataset results, and
Fig.3 shows the online streaming dataset result and that data are refered from
twitter real time data (Fig. 3).

Use of a Recurrent Neural Network to Identify Spammers on Twitter
957
5
Conclusion
This paper took a glance at the methodologies for recognizing Twitter spammers.
Moreover Twitter has given a scientiﬁc categorization of spam location strategies,
which is ordered as wrong substance discovery, URL-based spam identiﬁcation,
spam recognition, and client detecting procedures. The methodologies introduced
were looked at based on an assortment of qualities, including customer attributes,
material qualities, attributes, structure, and time. Besides, the methodologies were
corresponded with the referenced objectives and datasets. The introduced investiga-
tion will assist analysts with solidifying attention to best in class Twitter techniques
for spam distinguishing proof.
References
1. Cao, Q., Sirivianos, M., Yang, X., & Pregueiro, T. (2012). Aiding the detection of fake accounts
in large scale social online services. In: Proceedings symposium network systems and design
implementation (NSDI) (pp. 197–210).
2. Stringhini, G., Kruegel, C., & Vigna, G. (2010). Detecting spammers on social networks. In
Proceedings of 26th annual computer security applications conference (pp. 1–9).
3. Song, J., Lee, S., & Kim, J. (2011). Spam ﬁltering in Twitter using sender receiver relationship.
In Proceedings 14th international conference recent advanced intrusion detection (pp. 301–
317).
4. Lee, K., Caverlee, J., & Webb, S. (2010). Uncovering social spammers: Social honeypots +
machine learning. In Proceedings 33rd international ACM SIGIR conference research and
development information retrieval (pp. 435–442).
5. Aston, N., Liddle, J., & Hu, W. (2014). Twitter sentiment in data streams with perceptron.
Journal of Computer and Communications, 2(11).
6. Thomas, K., Grier, C., Song, D., & Paxson, V. (2011). Suspended accounts in retrospect: An
analysis of Twitter spam. In Proceedings ACM SIGCOMM conference of internet measure (pp.
243–258).
7. Thomas, K., Grier, C., Ma, J., Paxson, V., & Song, D. (2011). Design and evaluation of a
real-time URL spam ﬁltering service. In Proceedings of IEEE symposium security privacy (pp.
447–462).
8. Jin, X., Lin, C. X., Luo, J., & Han, J. (2011). Socialspamguard: A data mining based spam
detection system for social media networks. PVLDB, 4(12), 1458–1461.
9. Ghosh, S., Viswanath, B., Kooti, F., & Sharma, N. K. (2012). Understanding and combating
link farming in the Twitter social network. In Proceedings of 21st international conference
world wide web (pp. 61–70).
10. Costa, H., Benevenuto, F., & Merschmann, L. H. C. (2013). Detecting tip spam in location-
based social networks. In Proceedings of 28th annual ACM symposium in applied computing
(pp. 724–729).
11. https://ai.stackexchange.com/questions/12042/what-is-a-recurrentneural-network
12. Boshmaf, Y., Ripeanu, M., Beznosov, K., & Santos-Neto, E. (2015). Proceedings of“Thwarting
fake OSN accounts by predicting their victims (pp. 81–89). AISec.: Denver.

Computer-Aided Diagnosis of Pancreatic
Ductal Adenocarcinoma Using Machine
Learning Techniques
H. S. Saraswathi, Mohamed Raﬁ, K. G. Manjunath,
and Channa Krishna Raju
Abstract Pancreatic ductal adenocarcinoma (PDAC) is one of the most assailing
diseases. The occurrence rate is increasing everyday, and at the same time, the
mortality rate is also increasing. The survival rate for 5 years is less than 10%. The
majority of the patients are lately diagnosed. Most PDAC cases are asymptomatic in
the early stages. To reduce the death rate and enhance the survival rate, early iden-
tiﬁcation of the disease is highly essential. National Cancer Institute predicts that
the pancreatic cancer is expected to become the world’s second-deadliest disease
by 2030. The identiﬁcation of high-risk patients who might beneﬁt from screening
for pre-malignant conditions such as pancreatic intraepithelial neoplasia, intraductal
papillary mucinous neoplasms, and mucinous cystic neoplasms is critical, but an
accepmiR-217 screening test has yet to be identiﬁed. Diagnosing the PDAC in the
early stages plays a vital role in decreasing the mortality rate. Machine learning and
deep learning techniques are now being used in different sectors including health
care. As a result, this research work offers a summary of the available biomarker
approaches that are used for early detection of PDAC, as well as our proposed work
in this area. The proposed system develops a novel urine-based biomarkers along
with LVYE1 (Lymphatic Vessel), Trefoil factor1(TFF1), and Reg family proteins
such as REG1A and REG1B to improve the sensitivity and speciﬁcity in diagnosing
the PDAC in stages I-II.
Keywords Pancreatic ductal adenocarcinoma · Machine learning · Deep learning
CA19-9 · Risk score · New onset diabetes · LVYE1 · REG1A · REG1B · TFF1 ·
CEA · ctDNA · miRNA · Biomarkers · IPMN
H. S. Saraswathi (B) · M. Raﬁ· K. G. Manjunath
Department of CS&E, Jain Institute of Technology, Davanagere, India
e-mail: saraswathi@jitd.in
C. K. Raju
Departmant of CS&E, UBDT College of Engineering, Davanagere, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_74
959

960
H. S. Saraswathi et al.
1
Introduction
Pancreatic cancer—pancreatic ductal adenocarcinoma is an aggressive disease.
According to the National Cancer Institute (NCI), the PDAC becomes the second
deadliest disease by 2030 in the USA [1]. 80–85% of the cases are diagnosed in
the later stages because of the asymptomatic nature of the disease. So, PDAC is
very difﬁcult to diagnose in the initial stages of the disease. The diagnosis of PDAC
in the early stages plays a vital role in the next treatment. The researchers are still
working on this problem but have not received fruitful results. Efﬁcacy and outcome
of PDAC treatment are in large part decided by the degree of ailment on the time
of prognosis. Surgical resection followed via adjuvant chemotherapy is the simplest
possibly curative therapy available, yet only 10–20% of PDAC sufferers present with
resectable PDAC degrees, even as the residual 80–90% display regionally advanced,
non-resectable degrees or—in most of the people—distant metastases [2] (Fig. 1).
The pancreas is a spongy organ that has been located deep within the abdomen.
It is approximately 6 inches long. The pancreas aids in the digestion of food as well
as the control of blood sugar levels. The head of the organ, which is linked to the
duodenum, is the widest section of the organ. The tail is near the spleen on the left
side. We refer to the area between the head and the tail as the neck or body of the
pancreas. Exocrine and Endocrine glands are found in the pancreas. Exocrine glands
produce digesting enzymes, while endocrine glands release hormones into the blood-
stream. Exocrine tissue makes up the majority of the pancreas. Pancreatic disorders
canrangefromminor ailments likeacutepancreatitis tolife-threateningdisorders like
pancreatic cancer. The inﬂammation of the pancreas is known as pancreatitis. Intra-
ductal Pappilary Neoplasm, PainIN, and MCN are all precancerous diseases, which
could or could not result in cancer. Pancreatic ductal adenocarcinoma (PDAC) is the
pancreatic cancer which is a prevalent type of cancer that affects the pancreas.
Pain and weight loss are the most prevalent symptoms of PDAC, while jaun-
dice is the most common clinical marker. Weakness/fatigue, loss of appetite, weight
loss, abdominal discomfort, dark urine, jaundice, nausea, back pain, diarrhea, and
vomiting are all common signs and symptoms in people with PDAC, according to one
study. However, we are unable to diagnose the condition based on these symptoms.
As a result, a method for diagnosing the disease is required.
Fig. 1 Anatomy of the
pancreas—human body

Computer-Aided Diagnosis of Pancreatic Ductal Adenocarcinoma …
961
Fig. 2 Survival rate v/s
diagnosis stage
The CA19-9 is the only serum recommended to be used as a biomarker by the
FDA [3]. But currently, this is used for the disease progression monitoring purpose
after the treatment, but not for the diagnosis of the disease by most clinicians. The
sensitivity and speciﬁcity of CA19-9 are less than 80% in both sensitivity and speci-
ﬁcity rates. Some studies work on invasive methods and some others on non-invasive
or minimally invasive methods such as blood, urine, and pancreatic juice to diag-
nose the disease. Achieving high sensitivity and speciﬁcity for PDAC through non-
invasive methods yields difﬁculties in differentiating benign, malignant, or chronic
pancreatitis. Machine learning and deep learning are the two subﬁelds of artiﬁcial
intelligence that aim in building a machine capable of performing cognitive functions
through training and testing phases (Fig. 2).
According to a survey conducted between 2004 and 2012, the survival percentage
for patients diagnosed in the early stages of the disease, such as Stage IA and IB, is
up to 80%. Patients identiﬁed in Stages IIB, IIA, and III, IV, on the other hand, have
a survival rate of fewer than 20%. As a result, it is critical to diagnose the condition
in its early stages.
˙In the current era, machine learning technologies entered into almost all the ﬁelds
to solve the problems, as such the healthcare environment. Much of the research work
reveals the efﬁcient disease diagnosis by using computer vision and data analysis
approaches (Fig. 3).
A histogram depicts the steady rise of articles that incorporate machine learning to
predict cancer risk, recurrence, and outcome. The information has been gathered by
conducting keyword searches in PubMed, CiteSeer, Google Scholar, Science Citation
Index, and other internet database. Each bar reﬂects the total number of papers
published over the course of two years. ˙In this view, the existing work carried out on
the diagnosis of pancreatic cancer in the early stages with the help of biomarkers, and
a machine learning approaches are summarized. ˙It helps us to design and develop a
novel approach to diagnose the disease in the near future.

962
H. S. Saraswathi et al.
Fig. 3 Number of published
papers on machine learning
methods in the area of cancer
diagnosis. Source Cancer
Informatics 2006: 2
2
Existing Diagnostic Markers for the Early Detection
Pancreatic Ductal Adenocarcinoma
2.1
Different Approaches in the Early Diagnosis
of Pancreatic Ductal Adenocarcinoma Using Various
Biomarkers
The biomarkers are the biological markers or substances which can measure in the
blood, urine, tissue, and pancreatic juice. These may be the proteins of a body. CA19-
9, HGF, CA125, CA15-3, CEA, TP53, PIK3CA, BRAF, KRAS, EGFR, and NRAS
markers are investigated for the early diagnosis of PDAC. But, only CA19-9 is the
approved biomarker. Because of the lack of required sensitivity and speciﬁcity, we
cannot rely on CA19-9 alone. So, novel biomarkers need to be investigated further.
CA19-9.
The elevated levels of Carbohydrate antigen19-9 indicate the disease, but these
levels may also be elevated for liver cancer, colorectal cancer, and chronic pancre-
atitis for some patients [4]. But in some individuals, the presence of the disease is not
indicated by the elevated levels of CA19-9. So, the performance of this biomarker
in diagnosing PDAC in the initial stages is not appropriate with sensitivity and
speciﬁcity.
Sensitivity determines the proportion of actual positive cases which got predicted
correctly.
Sensitivity =
TP
TP + FN ∗100(1)
Speciﬁcity determines the proportion of actual negative cases which got predicted
correctly.

Computer-Aided Diagnosis of Pancreatic Ductal Adenocarcinoma …
963
Speciﬁcity =
TN
TN + FP ∗100(2)
To improve the sensitivity and speciﬁcity of a system, CA19-9 can be used with
other biomarkers. The normal value of CA19-9 is 0-37u/ml [5].
Authors of [6] state that CA19-9 of 35 ng/ml in serum were 52% and 88%,
respectively, for detecting invasive IPMN [6]. The CA19-9 was reached to sensitivity
with NLR > 2.5:35.3%, CAR > 0.03:31.8%, CEA > 5, CA19-9 > 37, and NLR:58.5%.
Speciﬁcity with NLR > 2.5:87%, CAR > 0.03:82.8%, CEA > 5, CA19-9 > 37,
and NLR: 58.5% [7] this concludes the least sensitivity. Authors of [7] state that
serum CA19-9 on the surgically resected intraductal papillary mucinous neoplasm
IPMN-invasive versus non-invasive achieved sensitivity 74% and speciﬁcity 85.9%
for elevated levels for 37 u/ml [6]. Authors of [8] state serum CA19-9 on HGD and
invasive IPMN on surgical pathology achieved a sensitivity of 34.2% and speciﬁcity
of 92.4% for elevated CA19-9. CA19-9 alone given the least sensitivity compared
to speciﬁcity. The CA19-9 protein biomarker is used along with TSP-1 and got an
AUC of 0.86 to identify PDAC samples [8].
In Table 1, several miRNAs are compared to CA19-9 in terms of sensitivity and
speciﬁcity for the early diagnosis of PDAC, and it was discovered that the miR panel
miR-16, miR-196a, and miR-1290 perform better in terms of sensitivity. CA19-9, on
the other hand, performs better in terms of speciﬁcity. CA19-9 cannot be used alone
to diagnose PDAC in its early stages according to the study.
Table 1 Diagnostic performance of CA19-9 and ncRNAs in pancreatic ductal adenocarcinoma
Biomarkers
Source
Number of cases
AUC
Sensitivity
Speciﬁcity
miR panel
miR-16
miR-196a
versus
CA19-9
Plasma
140 PDAC 68 Controls
0.89
versus
0.90
87%
versus
81%
73%
versus
100%
miR-1290
versus
CA19-9
Serum
41 PDAC
19 controls
0.96
versus
0.86
88%
versus
71%
84%
versus
90%
miR panel
(miR-885-5p, 22-3p,
642b-3p)
versus
CA19-9
Plasma
11 PDAC
11 controls
0.97
versus
unclear
91%
versus
73%
91%
versus
100%
miR-483-3p
miR-21
versus
CA19-9
Plasma
32 PDAC
30 controls
0.74
versus
0.86
undeﬁned
undeﬁned
miR-1290
versus
CA19-9
Plasma
267 PDAC
167 controls
0.73
versus
0.91
56.3%
versus
85%
89.5%
versus
95.9%

964
H. S. Saraswathi et al.
For the diagnosis of PDAC, the Cyst ﬂuid method is analyzed with CEA for
different levels of units in Table 2. They discovered that CEA > 200 ng/ml has
superior sensitivity than speciﬁcity. Due to a deﬁciency of the enzyme necessary,
about 5–10% of persons are unable to produce CA19-9. CA19-9 is a blood test used
to assess patients following surgery. Even after combining CA19-9 with MUC5AC,
MUC16, CEA, CEMIP, and PC-594, they were able to achieve a sensitivity of 70%.
The CA19-9 + THBS2 at sensitivity of 68% and speciﬁcity 95% for elevated
levels of CA19-9 for > 37u/ml [7]. These studies suggest the usage of CA19-9 with
other markers to improve the performance. The Circulating ncRNA’s as diagnostic
Table 2 Cyst ﬂuid approach in the early diagnosis of pancreatic ductal adenocarcinoma using
various biomarkers
Approach
Biomarkers in the
current clinical
practice
Sensitivity
Speciﬁcity
Description
Cyst ﬂuid approach
(normal serum level
is 30 to 110U/L)
CEA
Glycoprotein on
the cell
75%
83.6%
CEA > 192 ng/ml
90%
71%
CEA > 200 ng/ml
47%
40%
CEA > 200 ng/ml
52.4%
42.3%
CEA > 200 ng/ml
63%
88%
CEA > 200 ng/ml
Cyst ﬂuid approach
for IPMN
(normal serum level
is <30u/ml)
CA19-9
(carbohydrate
antigen 19-9)
74%
85.9%
In the serum of 85%
of PDAC patients,
this glycoprotein is
increased
About 5–10% of
people are unable
to generate CA19-9
due to a lack of the
enzyme required.
CA19-9 is used to
evaluate patients
after surgery
40%
89%
34.2%
92.4%
60%
75%
In Meta analysis:
52% and 89% for detecting
invasive IPMN
Cyst ﬂuid approach
CA199 +
MUC5AC +
MUC16
67–80%
98%
–
CA19-9 + CEA
70%
90%
–
CA19-9 + CEMIP
NA
NA
Differentiates
PDAC from healthy
group
CA19-9 + PC-594
NA
NA
Good compared to
CA19-9 alone
CA19-9 + CEMIP
+ C4BPA +
IGFBP2 +
IGFBP3
unclear
unclear
Differentiates
PDAC from healthy
groups
good compared to
CA19-9 alone

Computer-Aided Diagnosis of Pancreatic Ductal Adenocarcinoma …
965
biomarkers of PDAC. But miRNA’s have similar sensitivity compared to CA19-9,
but unfavorable speciﬁcity in diagnosing PDAC compared to CA19-9. Circulating
tumor DNA acts as a biomarker for the diagnosis of PDAC, CA19-9, was used
with THBS2[Thrombospondin-2] is a disulﬁde-linked homotrimer glycoprotein that
mediates cell to cell and cell to matrix interactions [9]. The C-statistics of 0.87 in
a combination of CA19-9 with THBS2. The absence of Lewis antigen is not able
to detect the PDAC with CA19-9 [10]. Mutations in the KRAS oncogene identiﬁed
in about 90% of the PDAC cases [4]. CEA a glycoprotein on the cell surface of
the mucin-producing epithelium. CEA can be used to differentiate mucinous from
nonmucinous PCL [9] (Table 3).
The investigators worked with CTC, KRAS, and ctDNA in liquid biopsy in Table
4. The detection rate for these biomarkers is 75% and 50%, respectively. As a result,
they decided to combine KRAS with CA19-9 to increase the performance even
further, and they got a 98% sensitivity but only a 77% speciﬁcity.
˙In Table 5, the some authors worked on body ﬂuids approach to solve the problem.
The body ﬂuids includes saliva, urine, stool, and pancreatic juice. Among these,
Table 3 Noncoding RNA’s approach in the early diagnosis of pancreatic ductal adenocarcinoma
using various biomarkers
Approach
Investigated biomarkers
Findings
Noncoding RNA’s
miRNA
miRNA is studied PDAC with serum,
plasma, pancreatic juice, stool, urine,
saliva
Tested more than 700 miRNA’s but
result not superior to CA19-9
miRAN486-5P, miR-198
Good in distinguishing PDAC from
healthy compared to ca19-9
miR-143, miR-145, miR-146,
miR-148, miR-150, miR-155,
miR-196a, miR-196b
Upregulated in PDAC
miR-216, miR-217
Downregulated in PDAC
Noncoding RNA acts as potential
biomarkers in urine, blood, stool
Table 4 Liquid biopsy approach in the early diagnosis of pancreatic ductal adenocarcinoma using
various biomarkers
Approach
Investigated biomarkers
Findings
Liquid biopsy
Circulating tumor cells (CTC)
Circulating tumor cells enter the blood
stream in all stages of PDAC
KRAS [Kirten Sat Sarcoma]
Detected rate is 75%. But standardized
large-scale validation is required
Circulating tumor DNA (ctDNA)
Detected rate is 50% for early stages of
PDAC
Ca19-9 + KRAS
Sensitivity 98% and speciﬁcity 77%

966
H. S. Saraswathi et al.
Table 5 Body ﬂuids approach in the early diagnosis of pancreatic ductal adenocarcinoma using
various biomarkers
Approach
Investigated biomarkers
Findings
Body ﬂuids—
Saliva, urine, stool, pancreatic
juice
Saliva—miRNA
Because of the strong blood
ﬂow in salivary glands, saliva
includes the same particles as
serum
Urine-REG1A, REG1B, TFF1,
LYVE1109, NGAL108,
miRNA
Used for PDAC
differentiation from healthy
group in an easy way
Stool, pancreatic juice-miR-21,
miR-155, miR216
But endoscopy is needed
urine approach is highly non-invasive, easy sample collection. Many markers are
overexpressed in PDAC patients compared to healthy controls. But still with these
biomarkers such as REG1A, REG1B, TFF1, LYVE1109, NGAL108, miRNA the
sensitivity ans speciﬁcity is not maintained above 90%.
3
Proposed Work
3.1
Introduction
By 2030, the PDAC is anticipated to be the second-deadliest illness in the USA [1].
The pancreas is deep inside the body, and hence, tumors are not detected during
physical examination. To detect the disease in the later stages ends in a compli-
cated scenario because the disease will become metastasis disease. The treatment
may not be helpful, so it leads to an increase in mortality. The pancreatic cancer
symptoms are very vague. The screening tests are available for breast cancer called
mammography and colon cancer called colonoscopy. But pancreatic cancer has no
screening test for early detection. To make the resection fruitful, it is necessary to
diagnose the disease in the early stages, thereby the survival rate can increase in the
future. ˙In this view, we are planning to build an artiﬁcial intelligence machine to
diagnose PDAC with the help of a urine-based non-invasive method using a panel
of biomarkers such as LYVE1, REG1A, REG1B, and TFF1 [11], and with a new
novel biomarker. Many researchers involved in the development of early diagnosis
of pancreatic cancer with panel of biomarkers using machine learning techniques.
One such machine learning method is support vector machine (SVM). To ﬁnd the
best REOs, researchers employed a feature selection methodology called minimum
redundancy maximum relevance. The results of multiple classiﬁcation methods for
distinguishing PDAC and its neighboring normal tissues from non-PDAC tissues
were then compared. For discovering early PDAC diagnostic biomarkers, the support
vector machine technique is the best [12].

Computer-Aided Diagnosis of Pancreatic Ductal Adenocarcinoma …
967
3.2
Challenges and Possibilities of Early Detection
of Pancreatic Cancer
Challenges: The rapid progression of pancreatic cancer, which can evolve from a
small undetectable malignant tumor to a metastatic disease in a matter of months, is
one of the many obstacles facing early identiﬁcation of pancreatic cancer. Between
stage I and stage IV disease, an average of 1.3 years passes. The pancreas veins drain
straight into the liver, causing a large number of neoplastic cells to disseminate into
the liver. As a result, the chances of detecting PDAC early are limited. The distinc-
tion of high-grade precursor lesions from low-grade intraductal papillary mucinous
neoplasm, chronic pancreatitis, is the second key hurdle. For the presence of lesions
that may not turn into cancer, excision of the pancreas may be necessary.
Possibilities: Despite the many problems that early detection of pancreatic cancer
poses, we now have several options for diagnosing pancreatic cancer in its early
stages. To begin, mucinous cystic neoplasms and intraductal papillary mucinous
neoplasms are precancerous lesions that may be discovered and treated using today’s
machine learning, deep learning, and imaging technology. The ability to identify
precursor lesions is crucial. Second, targeted genome events (BRCA2 mutations) can
be used to identify high-risk groups. Thirdly, we can learn about changes in gene,
microRNA, and protein expression that are linked to pancreatic cancer development.
Fourth, in recent years, high-risk groups such as new-onset diabetes, obesity, chronic
pancreatitis, cigarette smoking, and the existence of precursor lesions have been
identiﬁed, which aids in the detection of pancreatic cancer [2]. As a result of these
possibilities, we are hopeful that early diagnosis of the disease will be beneﬁcial in
the near future.
3.3
Research Design Process
Because the screening approach cannot be used to all people due to cost, it is required
to identify the pancreatic cancer high-risk group. The high-risk group may have
a high probability of having pancreatic cancer. New-onset diabetes is a harbinger
symptom for PDAC, and it is been discovered that 1 in one hundred humans of new-
onset diabetic sufferers PDAC has been detected. ˙In the current studies work, it is
been proved that new-onset diabetes may be the early symptom of PDAC. Recent
years from the retrospective study, it exposed that new-onset diabetes is a high-
risk factor for PDAC in the next three years [5, 13]. We are using this chance and
expertise to screen high-risk populations for early detection of pancreatic cancer.
Other factors such as age >50, gender, weight loss, changes in blood sugar level,
jaundice, and abdominal discomfort are associated with new-onset diabetes. Use the
unconventional biomarkers to screen the high-risk group and to are expecting PDAC,
the positive instances are applied to image modality which includes MRI, CT to verify
the PDAC using Machine Learning and deep learning techniques (Fig. 4).

968
H. S. Saraswathi et al.
Fig. 4 Flowchart to apply
biomarker and image
modality testing in screening
program
3.4
Proposed Methodology
The proposed system consists of ﬁve stages. The data set will be collected from the
pancreatic cancer research network, USA. ˙It has 590 patients’ text data based on
the urine test to diagnose PDAC. Preprocessing, such as missing value management,
preparing an analyzable data collection, and using imperfect, imbalanced medical
data to construct a prediction model for illness diagnosis. Text feature extraction that
extracts textual content data is an extraction to symbolize a textual content message,
it’s miles the premise of a massive quantity of textual content processing. The simple
unit of the feature is referred to as textual content capabilities. Selecting a set of
capabilities from a few powerful approaches to lessen the size of feature space, the
reason of this manner is referred to as feature extraction (Fig. 5).
During feature extraction, uncorrelated or superﬂuous features could be removed.
As a records preprocessing method, feature extraction can higher enhance the accu-
racy of the studying set of rules and shorten the time. Selection from the docu-
ment element can reﬂect the data at the content material words, and the calculation
of weight is referred to as the textual content feature extraction. Common tech-
niques of textual content feature extraction consist of ﬁltration, fusion, mapping,
and clustering method. A form of those techniques, along with logistic regression,
most cancer studies have used artiﬁcial neural networks (ANNs), Bayesian networks
(BNs), support vector machines (SVMs), and decision trees (DTs) to develop predic-
tive models, resulting in powerful and accurate decision making. ˙In the last stage,

Computer-Aided Diagnosis of Pancreatic Ductal Adenocarcinoma …
969
Fig. 5 Proposed system
the biomarker is identiﬁed by analyzing the text data, and the identiﬁed urine-based
biomarker is used for the development of a machine learning risk score model for
the diagnosis of PDAC in the initial stages.
We are looking for efﬁcient urine-based biomarkers which can be overexpressed
in patients of Stage I, II when compared to healthy controls. We take up microRNAs
(miRNAs) along with LYVE1, REG1A, REG1B, and TFF1. Because of their link
to tumor progression, miRNAs are gaining a lot of interest. At least half of the
abnormally expressed miRNAs in tumors play crucial roles as post-transcriptional
regulators, acting oncogenic or tumor suppressive by binding directly to their target
messenger RNAs. Identifying miRNAs that are differently expressed in malignant
versus normal tissues can be done using a variety of ways. It is necessary to establish
the expression proﬁles of miRNAs in urine samples from patients with PDAC, CP,
and healthy people. We show that urine miRNA levels can distinguish not only
between healthy and ill people, but also between early and late stage cancers. Using
the same samples and an independent urine sample cohort, we need to successfully
validate four differentially expressed miRNAs, showing their potential diagnostic
value at an early stage of disease. After large-scale validation, seamless translation
of these miRNAs into the clinical context as an RT-PCR-based urine test for early
detection could have a major impact on the prognosis and survival of pancreatic
cancer patients.
A sophisticated network of lymphatic vessels and nodes collects interstitial ﬂuids
for hydration maintenance and immunological monitoring, resulting in pancre-
atic lymphatic outﬂow. When disorders like pancreatitis or neoplasm strike, the
lymphatic system plays a critical part in the body’s defences against inﬂammation

970
H. S. Saraswathi et al.
and malignancy. ˙It is found that genes such as LVYE1 (Lymphatic Vessel), Trefoil
factor1(TFF1), Reg family proteins REG1A, and REG1B are overexpressed in PDAC
stage I and stage II patients when compared to healthy controls. We expect sensitivity
and speciﬁcity above 90% with miRNAs- miR-30e, miR-143, miR-204, miR-223,
LVYE1, REG1A, REG1B, and CA19-9 through urine specimen in the diagnosis of
PDAC in the early stages.
3.5
Results and Discussion
The goal of our planned research is to develop a biomarker panel for diagnosing
PDAC in its early phases—Stage I and Stage II. The identiﬁed biomarker is applied
forthehigh-riskpopulationsuchasnew-onsetdiabetes,obesity,jaundice,andchronic
pancreatitis. The data set contains 600 urine samples of PDAC and healthy controls.
The logistic regression model is to be developed to diagnose the disease based on the
risk score calculation. The analysis of the model is done in different ways. Firstly, the
candidate biomarker is analyzed individually for sensitivity, speciﬁcity, and ROC.
Secondly, all biomarkers in a panel combined to analyze sensitivity, speciﬁcity, and
ROC. Thirdly, CA19-9 is applied to identify its performance. Fourthly, a panel of
biomarkers is combined with CA19-9 to analyze the model. Lastly, compare all the
different analyses to conclude the best biomarkers. The positive cases from the model
are enrolled for conﬁrmation through image modality techniques. The model result
is to be compared with the actual diagnosis.
˙In our proposed work, we compare PDAC samples with healthy samples and
expect higher areas under the receiver operating characteristic curves (AUCs) in
training and validation phases. Then compare PDAC stage I, II with stage III, IV
to achieve higher areas under the receiver operating characteristic curves (AUCs) in
trainingandvalidationphases.Themodelsensitivityandspeciﬁcityaretobeachieved
above 90% with miRNAs—miR-30e, miR-143, miR-204, miR-223, KRAS, LVYE1,
REG1A, REG1B, and CA19-9 through urine specimen in the diagnosis of PDAC in
the early stages. The proposed work in diagnosing the PDAC is to be carried out with
urine-based biomarkers for the speciﬁed data set with 600 samples. The diagnosing
PDAC using image modality is left to future work.
4
Conclusion
Early detection of PDAC the usage of urine-primarily based totally biomarkers ought
to offer a solution and future instructions for PDAC screening packages to diag-
nose the disorder with inside the early stages. Simultaneous measurement of various
urine-primarily based totally biomarkers blended collectively may also have extra
potentiality in diagnosing the PDAC with excessive accuracy while in comparison
to individual usage. Furthermore, the usage of a multimarker panel composed of the

Computer-Aided Diagnosis of Pancreatic Ductal Adenocarcinoma …
971
glycoproteins with CA19-9, in addition to different scientiﬁc tactics which include
imaging, ought to enhance the power of a single marker. We developed a six-protein
biomarker panel that will identify patients with early stage pancreatic cancer in urine
samples.
References
1. Kenner, B. J., Chari, S. T., & Maitra, A. Early detection of pancreatic cancer-a deﬁned future
using lessons from other cancers. Pancreas, 45(8), 1073–1079.
2. Gillen, S., Schuster, T., Meyer Zum Buschenfelde, C., Friess, H., & Kleeff, J. (2010). Preop-
erative/neoadjuvant therapy in pancreatic cancer: a systematic review and meta-analysis of
response and resection percentages. PLoS Medicine, 7(4), e1000267.
3. Llop, E., Guerrero, P. E., & Duran, A. (2018). Glycoprotien biomarkers for the detection of
panctreatic ductal adenocarcinoma. World Gastroenterology, 24(24), 2537–2554.
4. Marker, A. V., Carrara, S., & Jamieson, N. B. (2015). Cyst ﬂuid biomarkers for intraductal
papillary mucinous neoplasms of the pancreas: a critical review from the international expert
meeting on pancreatic branch-duct-intraductal papillary mucinous neoplasms. Journal of the
American College of Surgeons, 220, 243–253.
5. Pergolini, I., Jager, C., & Safak, O. (2021). Diabetes and weight loss are associated with malig-
nancies in patients with ıntraductal papillary mucinous neoplasms. Clinical Gastroenterology
and Hepatology, 19, 171–179.
6. Fritz, S., Hackert, T., & Hinz, U. (2011). Role of Serum carbohydrate antigen 19-9 and
acrcinoembryonic antigen in distinguishing between benign and invasive intraductal papillary
mucinous neoplasm of the pancreas. British Journal of Surgery, 98, 104–110.
7. Hata, T., & Mizuma, M. (2019). Diagnostic and prognostic impact of neutrophil-to-lymphocyte
ratio for intraductal papillary mucinous neoplasms of the pancreas with highgrade dysplasia
and associated invasive carcinoma. Pancreas, 48, 99–106.
8. Kim, J. R., Jang, J. Y., & Kang, M. J.(2015). Clinical implication of serum carcinoembryonic
antigen and carbohydrate antigen 19-9 for prediction of malignancy in intraductal papillary
mucinous neoplasm of pancreas. Journal of Hepato-Biliary-Pancreatic Sciences, 22, 699–707.
9. Jenkison, C., Elliott, V. L., Evans, A., & Oldﬁeld, L. (2016). Decreased serum Throbospondin-1
levels in pancreatic cancer patients upto 24 months prior to clinical diagnosis, association with
diabetes millitus. Clinical Cancer Research, 22(7), 1734–1743.
10. Singhi, A. D., McGranth, K., & Brand, RE. (2018). Preoperative next-generation sequencing
of pancreatic cyst ﬂuid is highly accurate in cyst classiﬁcation and detection of advanced
neoplasia. Gut, 2131–2141.
11. Radon, T. P., Massat, N. J., & Jones, R. (2015). Identiﬁcation of a three-biomarker panel in
urine for early detection of pancreatic adenocarcinoma. Clinical Cancer Research, 21(15).
12. Zhang., Z.-M., & Wang, J.-S. (2020). Early diagnosis of pancreatic ductal adenocarcinoma
by combining relative expression orderings with machine-learning method. PMC, PMCID:
PMC7593596.
13. Huang, B. Z., & Pandol, S. J. (2020). New-onset diabetes, longitudinal trends in metabolic
markers, and risk of pancreati cancer in a heterogeneous population. Clinical gastroenterology
and Hepatology, 18, 1812–1821.
14. Brugge, W. R., Lauwers, G. Y., & Sahani, D., et al. (2004). Cystic neoplasms of the pancreas.
New England Journal of Medicine, 351, 1218–1226.
15. Wang, W., Zhang, L., & Chen, L. (2015). Clinical Implication of serum carcinoembryonic
antigen 19-9 for prediction of malignancy and invasiveness in intraductal papillary mucinous
neoplasm of pancreas. Journal of Hepato-Biliary-Pancreatic Sciences, 3, 43–50.

972
H. S. Saraswathi et al.
16. Kong,B.,&Friess,H.(2020).BloodbasedcirculatingRNAsaspreventive,diagnostic,prognstic
and druggable biomarkers for pancreatic ductal adenocarcinoma. Springer nature swizerland
AG.

Application of Data Mining Technique
for Retail Industry
Pradnya Abhay Muley
Abstract This research work presents an implementation of a hybrid model for
consumer segmentation in online shopping business support and decision-making
by employing an unsupervised learning algorithm and Fuzzy C-means approach. In
this research, the customers are sub-divided into distinct segments by using the cluster
analysismethod.Itwillgathertheinformationaboutcomponentscores,clustermodel
and similarities among the customers and suggests a way for grouping them. In
speciﬁc, the proposed model has used K-means clustering, which is a type of unsu-
pervised learning method. The procedure aims to classify a given dataset through a
certain number of clusters (assuming k clusters) ﬁxed a priori.
Keywords Clustering · K-means · Fuzzy C-means · Segmentation · Online
shopping · Retail industry · Customer segmentation
1
Introduction
At present, the enhancement in several Internet users leads to a signiﬁcant impact on
online retailing business. As stated above, retail industries are classiﬁed as organized
or unorganized retail industries, but in both the service delivery plays a critical role
in customer satisfaction.
• In order to enhance retail business proﬁts while increasing customer satisfac-
tion, retail organizations must ﬁrst understand the needs of their customers. The
retail business may increase the market turnover by having a good grasp of the
customer’s needs.
• To improve the market turnover of the organization, the customer segmentation
process should be improved, which means that the segmentation or partition of
customers should be done in different ways.
P. A. Muley (B)
PES Modern College of Engineering, Pune, India
e-mail: pradnya.muley@moderncoe.edu.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_75
973

974
P. A. Muley
Customersegmentedcompaniesoperatewiththefactthateachandeverycustomer
is unique, and if appropriate marketing service is provided to their needs, the
marketing efﬁciency can be improved. Some people have their opinion that customer
segmentation can only be done by performing a practical understanding, which will
be time-consuming, and there is also a chance for human errors. With the utilization
of data mining technique, the different group of customers are segmented based on
several factors. The existing data mining approaches use mathematical formulations
for segmentation, but still it exhibits some challenges, which lead to the requirement
for developing an efﬁcient data mining approach for performing customer segmen-
tation in online retail business. Through the development of effective data mining
technique for customer segmentation, the online retail industry can achieve a high
rate of business turnover with an increased customer satisfaction level.
2
Research Objective
The main objective of this research work is to improve the performance of retail
marketing system by using some efﬁcient techniques. The objectives of this research
study are:
1.
To identify various factors that would inﬂuence online customer shopping using
data mining technique.
2.
To develop a hybrid model using SOM unsupervised learning and fuzzy C-
means (adaptive resonance theory) technique.
3.
To implement the proposed model for segmenting customers in online retail
shopping by using the standard cross industry process (CRISP) methodology.
4.
To validate the proposed model with the traditional two-stage k-means algo-
rithm.
5.
To study the factors that affect the organized retail sector’s growth.
6.
To research and compare the different factors, which are inﬂuencing customer
purchasing behaviour from an unorganized retail outlet or a structured retail
outlet in India.
7.
To recognize the selected retail point during shopping.
8.
To identify the importance of retailers in India and its conﬁnes.
2.1
Literature Review
Background. Most of the papers surveyed here are related to retail marketing by
incorporating the clustering algorithm, fuzzy logic method, CRM, association rule
mining,marketsegmentationmethod,machinelearning,frequentitemsetminingand
sentimental analysis of product review techniques. Here, most of the techniques are
studied and analysed the function and processing of the methods in retail marketing.
Traditional retail marketing has undoubtedly performed a major economic function

Application of Data Mining Technique for Retail Industry
975
and an important source for employment. But, as a consequence, it suffers from
enormous shortfalls. These types of problems are currently faced by the Indian orga-
nization or retail industry, which are hampering the Indian retail industry’s complete
potential. All of the conventional research work contains both advantages and disad-
vantages. But most of the work contains drawbacks such as, less efﬁciency, lack of
accurate result, less segmentation process and high processing time. To overcome
these drawbacks, the efﬁciency of the system will be improved in the future. So,
in future, the research work concentrates on developing an appropriate data mining
model for performing customer segmentation in online retail industry. By getting a
clear understanding of customer requirement, the retail industry can gain the ability
to serve in a better way for customers, and also, their marketing efﬁciency will also
be increased (Table 1).
2.2
Proposed Methodology
This research has implemented a system using Fuzzy c-means and SOM towards
market as well as a customer segmentation in the online market. The proposed
researchapproachisbasedonthesegmentationtheoryfromtheaspectofthebusiness;
it is considered as clustering/classiﬁcation theory.
2.3
Implementation Process Flow
In this research work, the overall work ﬂow is described in below steps. Initially, the
customer data are collected, and these gathered data are pre-processed to remove the
unwanted data which are present in collected data. Then, the clustering technique
is used to cluster the pre-processed data to extract the required pattern. Finally, the
experiment results are compared with some other metrics.
Step 1: Customer data
Step 2: Data pre-processing
Step 3: Clustering Extract the pattern
Step 4: Customer identiﬁcation
Data proﬁling & cluster results analysis.
Independent variables considered for the customer segmentation such as Finan-
cial Bond (FB), Reference Group (RG), Merchandise Attractiveness (MA), Product
Related Factors (PRT), Service Related Factors (SF), Integrated Marketing Commu-
nication (IMC), Recommendations (RCOM), In-store/Online browsing (IOB), Posi-
tive Emotions (PE), Negative Emotions (NGE), Urge to Buy (UB), Internet distrust
(ID), Internet offers (IOF), Internet self-inefﬁcacy (ISIE), Internet logistical issues
(ILI), Internet enjoyment and Convenience (IEC) and Dependent variable considered
for the customer segmentation as factors affecting purchase intention (FAPI).

976
P. A. Muley
Table 1 Study and analysis of previous work
Sr. No.
Authors
Method
Results
Limitation
1
Gupta and
Pathak (2014)
Machine learning,
data mining and
statistical methods
The error rate is
reduced, and much
better price range,
which is appropriate
for both customer
and organization, is
being determined
The results of the
work-in-progress not
completed entirely
2
Raju et al.
(2014)
DM with CRM
Analysed the data
and captured the
information is used
throughout the
organization to
support
decision-making
Doesn’t focus on the
decision-making
process. This will
reap the immense
beneﬁt and derive
considerable
competitive
advantage to
withstand
competition
3
Surendren and
Bhuvaneswari
(2014)
Association rules
mining
Based on the study,
63% of users avoid
post-purchase
dissonance and 11%
of users avoid
pre-purchase
dissonance
Need to focus
towards classifying
users based on
cognitive dissonance
with the machine
learning method
4
Cervellon et al.
[1]
Reviewed the
inﬂuence of
consumer shopping
orientations
Highlight the
importance of
responsible retail
practices and ethical
assortments in
consumers’ choice of
online formats while
local product
orientation inﬂuences
the selection of city
stores and
marketplaces
The results might be
limited to the
particular domain of
grocery shopping;
cross-channel
free-riding is a very
limited behaviour in
the domain of
grocery shopping
5
Chelmis et al.
[2]
Data clustering
approach
This method was
generable to
large-scale,
real-world scenarios
without making any
assumptions about
the data
As no ground truth
for clusters is
available in this
dataset, choosing
appropriate seeds
becomes even more
complicated
(continued)

Application of Data Mining Technique for Retail Industry
977
Table 1 (continued)
Sr. No.
Authors
Method
Results
Limitation
6
Mittal and
Jhamb (2016)
Reviewed the
shoppers’ patronage
of a shopping mall in
the Indian context
The spending power
of Indian consumers
coupled with the
substantial
investments in
shopping centres
makes this study
critical for retail
practitioners,
academics and
researchers
Need to
accommodate local
tastes and
preferences still be
critical particularly in
the
store, brand and
product level
7
Ariyawansa
and Aponso
(2016)
Association rules
mining
ARM is to ﬁnd out
association rules that
satisfy the predeﬁned
minimum support
and conﬁdence from
a given database
To generate
association rules
from those large item
sets with the
constraints of
minimal conﬁdence
In this study the researcher has used K-means clustering which is type of
unsupervised learning method.
3
Data Collection and Analysis
To achieve the research objectives and address the research question, this thesis anal-
yses the secondary data collection methods (Saunders et al., 2009). The information
taken from academic articles, books and reports were used as secondary data. These
data have been updated and recorded frequently once the response received. The
results have been organized in the Microsoft Excel spread sheet with the code sheet
that has been developed to analyse the data of the survey results. Based on altitudinal
score, the data are organized as distinct rows and columns.
Based on the item, the respondents are selected based on criteria from 1 to 5
(i.e., 1 = Strongly Disagree, 2 = Disagree, 3 = Neutral, 4 = Agree, 5 = Strongly
Agree). Based on these factors, the questionnaire has been framed. The created the
Google form for an online survey. This survey is conducted to identify the factor
inﬂuencing impulse buying behaviour among shoppers. A sample size of 550 have
been considered for the whole analysis process. After data collection the analysis
have been done using SPSS software (ANOVA and k-means cluster analysis). The
analysis and modelling of the segmentation process are based on the customers of
online retail sector. It was required to map the proﬁle of the target customers in
terms of lifestyle, attitudes and perceptions. Further, the validity of the results will
also be done using analysis of variance (ANOVA) and MATLAB software to ensure,
whether the clusters are similar or different.

978
P. A. Muley
4
Results and Discussion
Figure 1 represents the cluster analysis of proposed work. From this, the respondents
are categorized based on age and their income level.
The cluster size is depicted in Fig. 2. It comprises three groups of data, each with
a distinct data size. From the ﬁgure, the cluster 1 contains 25.1% of data, cluster
2 have 34.4% of data, and cluster 3 includes 40.5% of data. From that, the cluster
1 is considered as small size of cluster, and it contains 138 data. The cluster 3 is
considered as largest size of cluster, and it includes 223 data. The ratio of cluster size
from largest cluster to smallest cluster is 1.62.
4.1
Cluster Analysis
Figure 3a, b represents the cluster analysis and cluster assignments. In Fig. 3a, the
x-axis measures the length in cm, and y-axis measures the width in cm. Here, the
multiple input data are collected to create a single cluster. Figure 3b displays the
cluster 1, cluster 2 and centroids. Here, the cluster 1 is marked in red cluster, cluster
2 marked in blue colour, and the centroids are represented in cross section (X) in
black colour.
The research work concludes that the elements such as a ﬁnancial bond, product-
related features, in-store browsing are found to affect impulse buying after moder-
ating demographic variables while the factors such as merchandise attractiveness and
recommendations were found to inﬂuence an in-store purchase. This study concluded
that the external factors did the predispose impulse and urged to buy after control-
ling the demographical variables and consumer buying behaviour in the online and
in-store shopping mode.
5
Conclusion and Future Work
The proposed research work has developed a computing-based framework, which
has automatically extracted the outputs to the retail sector to leverage a quick and fast
decision-makingprocess.Theexperimentalresultshavecalculatedthecharacteristics
of the cluster and cluster brands of a speciﬁc group of people. Based on the behaviour,
the data have been mined via clustering or grouping the customer details. This kind of
data is beneﬁcial for holding on to the good customers and, furthermore, characterizes
the same user in a cluster and classiﬁes potential responses for targeted marketing.
As a result, this study has assisted merchants in investing the correct sector by
allowing them to invest prudently. Through the segmentation process, the retailers
can maximize the opportunities for up-selling by holding the most signiﬁcant and

Application of Data Mining Technique for Retail Industry
979
Fig. 1 Cluster analysis

980
P. A. Muley
Fig. 2 Cluster sizes
Fig. 3 a Cluster analysis b Cluster assignments
important clients just to recognize new business prospects by successfully speaking
with the correct target group. Consequently, this will expand a lead to proﬁtability
and maximizes the marketing expenditures.

Application of Data Mining Technique for Retail Industry
981
The ﬁndings of the proposed research work give some different experiences to
specialists in the light of certain restrictions. The investigation is restricted to buyers
in Maharashtra. In this way, the examination does not cover other potential clients in
different territory of India. By joining the potential different clients in the investiga-
tion, this will improve the generalizability of the consequent research. Besides, the
investigation received a quantitative strategy where survey technique was embraced
to gather the information from the customers. If we include the subjective strategy,
will get more data with respect to the goal.
Due to the limits of this research work, three suggestions are recommended for
the future research for the purpose of developing the study of the customer online
shopping behaviour towards products. The study needs to be conducted in other states
of India. Secondly, the study conducted a quantitative methodology. Besides, it is
recommended that to conduct a qualitative method, so that gets in-depth information
about impulse buying behaviour in an online shopping environment. So, the future
study should examine the relationship between online behaviour and ofﬂine shopping
behaviour.
References
1. Cervellon, M. C., Sylvie, J., & Ngobo, P. V. (2015). Shopping orientations as antecedents to
channelchoiceintheFrenchgrocerymultichannellandscape.JournalofRetailingandConsumer
Services, 27(1), 31–51.
2. Chelmis, C., Kolte, J., & Prasanna, V. K. (2015). Big data analytics for demand response:
Clustering over space and time. 2015 IEEE ınternational conference on big data (Big Data)
(pp. 2223–2232), October 2015. IEEE.

Online System for Identifying Need
of Machine Maintenance by Mining Data
Streams and Handling Concept Drifts
Rahul Patil, Pramod Patil, Aditya Ghongade, Adriel Dsa, Parth Lokhande,
and Harsh Munot
Abstract Data streams represent an ongoing stream of data, in many forms, coming
from different sources. In real time data often comes in streams and is changing over
time. Concept drift in supervised learning means that the data is going through a
change. While solving predictive maintenance tasks on the streaming data, tradi-
tional models, trained on historical data, may become invalid, when such change
occurs. Hence, the learning models need to adapt to changes very quick and accu-
rately. Adaptive ensemble models are used for classiﬁcation on data streams. In
this paper, we implemented the modiﬁcations of the adaptive bagging methods,
which uses internal class-weighting schemes for the model adaptation. Implemented
models were evaluated on manually created data streams with ensemble methods
and analyzed performance evaluation of different classiﬁers. This performance is
greatly differed than the traditional model and hence handles the drift in much more
effective way.
Keywords Data stream mining · Concept drift · Ensemble learning · Preventive
maintenance · OEE analysis · Online bagging · Scikit-multiﬂow
1
Introduction
Mining of streaming data is growing on a large scale and is a large topic of research.
This mining of streaming data is very useful for different types of analysis, study,
report generation and future predictions regarding a large system. The accuracy of
streaming data also needs to be preserved in applications dealing with user sensitive
or vulnerable data. The ever increasing need for maintaining systems has arisen, but
not many methods are available to predict failure of a particular system which is the
biggest motivation behind the system. The real time processing and analysis of this
R. Patil · A. Ghongade (B) · A. Dsa · P. Lokhande · H. Munot
Department of Computer Engineering, Pimpri Chinchwad College of Engineering, Pune, India
P. Patil
Department of Computer Engineering, Dr. D. Y. Patil Institute of Technology, Pune, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_76
983

984
R. Patil et al.
streaming data by considering various parameters will help analysts to study it and
thereby take necessary actions.
A lot of work has been done in the ﬁeld of Static Data Mining, but nowadays
the frequency of dynamically occurring data has increased due to advancement in
technology. This dynamically occurring data has not been explored as much as the
statically occurring data has been explored. There are various challenges in handling
dynamically occurring data like concept drift [1], skewness, privacy preservation,
handling delayed and incomplete data, etc. In this paper, we will be seeing what
concept drift is? How to overcome it? And how does it affect the performance of the
system?
In today’s era, manpower is less and everything is dependent on machines.
Machines are used on a large scale and malfunctions tend to occur because of the
heavy usage on an everyday basis and so maintenance is required. If we knew when
malfunctions would take place, we would do maintenance at the ﬁrst stop before the
malfunction. This would save a lot of time, money and effort.
Preventive maintenance basically is the systematic and the proper routine mainte-
nance of the machine and in order to keep it running and prevent it from unexpected
machine failure. It is used to know and prevent the breakdown of machines and will be
performed on all machines which will prevent age related failure too. Then, we have
the mandatory and non-mandatory tasks. Mandatory should be done as soon as the
machine is due and will often include safety checks. Non-mandatory can be delayed
without failure or performance reduction. The exact need of preventive maintenance
will vary depending on the machine, and the operation it is performing.
In this paper, we have proposed a system which creates a stream and induces drift
manually in it, and then handles it using ensemble method drift detection algorithms.
Ensemble learning is a supervised machine learning method [2, 3]. We have used
scikit-multiﬂow [4], a machine learning library for streaming data in Python. In
Sect. 2, the ﬂow of the proposed system is provided. In Sect. 3, results are provided
after applying the ensemble methods on the dataset mentioned in Sect. 2. In Sect. 4,
conclusions are made for the paper. The main objective of the paper is to check the
impact of concept drift on the data and how it affects the performance and how it can
be handled.
2
Proposed System
2.1
Dataset
The dataset which is used is production data. This dataset contains various different
features on which the analysis would be carried out. The data has certain ﬁelds like
Circuit Id which represents the Id of the particular circuit. Another ﬁeld in this data is
the timestamp explaining when the record was inserted into the database. Then, the
shift Id which gives the speciﬁc shift in which the reading was taken. Now coming

Online System for Identifying Need of Machine Maintenance …
985
on to the main attributes which we would be working on, total batches produced at
that instance of time. Rejected batches are the batches which have been rejected for
that instance of time. The last attribute in the dataset is the efﬁciency of the particular
circuit which would be the good batches produced by that speciﬁc circuit are above
75% than the total batches produced.
2.2
Stream Application
The data used in this application is in static form meaning the data is of ﬁxed size.
To make this data into streaming data, a program in python is written which extracts
the circuit id, current date and time, the shift id and also the total batches produced
and rejected and is that particular circuit efﬁcient or nor depending on the previous
two ﬁelds. The data which is then generated from this application is then inserted
into a MYSQL database. A timer is also induced in this application to let the data
become streaming data. This timer appends data every 8 s into the stream.
2.3
Concept Drift
While working with a continuous stream of data, the data may get noisy sometimes,
i.e., the properties of the target variable, which the model is trying to predict, may
change over time. Such data is called drift and may hinder the performance of the
system. Some real world applications of such data are as follows [5]:
• Trafﬁc monitoring, where trafﬁc may vary over time,
• Weather forecast where climate change and other natural anomalies can affect the
ﬁnal prognosis,
• Systems for tracking individuals’ interests, such as personalized ads, where people
can gradually change interests.
A concept in “concept drift” refers to the hidden relationship between inputs and
output variables [1]. Different types of drifts may include: A gradual change over
time, a recurring change, a sudden or abrupt change.
Desired properties to handle concept drift are: Adapt to concept drift as soon as
possible, distinguish noise from change and adapt to it, recognizing and reacting to
recurring contexts, adapting with limited resources, i.e., time and money. If concept
drift is not handled properly it may lead to false analysis or predictions which may
affect the efﬁciency of the program resulting in inaccurate results. Hence, to avoid
such a problem, we need to use algorithms which adapt to such changes and may
increase the performance of the system. In our dataset, we had no such drift but to
check what happens if drift arrives, how it affects performance, how to handle it? We
induced concept drift into our dataset by adding some negative values in between
the data which in general resulted in recurring concept drift.

986
R. Patil et al.
2.4
Detecting Concept Drift
To detect concept drift in data, adaptive windowing (AdWin) concept [6, 7] provided
by scikit-multiﬂow [4] was used in the system. ADWIN (Adaptive Windowing) is
a ﬂexible slide algorithm for ﬁnding changes, and keeping updated statistics about
data distribution. ADWIN allows unplanned algorithms for drift data, to withstand
this situation. A common idea is to keep statistics from a variable size window, while
detecting the drift concept. It uses sliding windows of size-adjusted windows online
based on the rate of change observed from the data in these windows. The algorithm
strongly enlarges a window (W) when there is no visible change in context, and
reduces it when a change is detected. If the total value of the difference between the
two currencies exceeds the limit previously described, the change is immediately
available and all data prior to that period is discarded. The algorithm attempts to ﬁnd
two small windows of different sizes. When that happens, it concludes that the corre-
sponding expected values are different, which means that the old part of the window
is based on a different data allocation than the real one, and therefore reduced. The
maximum length of the window is mathematically consistent with the assumption
that there is no change in the normal value within the window. Additionally, adwin
provides substantial guarantees of its performance, in the form of restrictions on the
number of false proﬁts and false objections.
2.5
Handling Concept Drift
As mentioned in Sect. 2.3, the properties of the system to handle drift, to adapt to it,
how this drift affects the performance of the system, actually, we cannot completely
remove the drift, instead we can adapt to it using an algorithm which eventually
results in an increase in the performance of the system.
Boosting and bagging are classical ensemble methods used to improve the perfor-
mance of single classiﬁers. They obtain superior performance by increasing the
accuracy. Bagging splits, the datasets into various classiﬁers, i.e., divides it into new
training sets. The output of all these classiﬁers is used for voting and then we get an
ensemble classiﬁer. Ensemble learning algorithms work by combining the outputs
of multiple base learners. The objective is to improve the performance of individual
classiﬁers by training multiple base classiﬁers on different datasets (subsets of the
original dataset) and combining the results. Averaging the outputs of several clas-
siﬁers helps reduce the bias in the classiﬁcation error [8]. Adaptive bagging was
successfully used in the classiﬁcation of the imbalanced data streams [9]. Moreover,
by adapting scalable technologies, online bagging ensembles were successfully used
to tackle big data [8].
As our data was in streams, there was no limit to it hence considered as a big data
and online bagging (OzaBagging) [9] considered to be the best option to improve
the performance. The advantage of these methods is that they can be used not only

Online System for Identifying Need of Machine Maintenance …
987
for processing data streams but also for static data when there is a lack of memory
and computing capacity for the processing in a single iteration as evaluation and
possibly update of the models on relatively small data sets is less demanding for
computing performance [5]. We used KNN as our base estimator as it has low bias
which will give good performance for classiﬁcation problems. OzaBagging [9] is a
bagging technique where there is no training dataset like bagging but here there are
a stream of samples and here our classiﬁer will train each arriving sample K times,
which is drawn by the Poisson distribution. The Poisson distribution here helps to
predict the probability of certain events from happening when you know how often
the event has occurred. It will also give us the probability of a given number of events
happening in a ﬁxed interval of time [4].
2.6
OEE Analysis
Overall equipment effectiveness (OEE) is a standard for measuring manufacturing
productivity. By analyzing with OEE analysis and also identifying the underlying
losses, one can gain useful insights on how to increase or improve the manufacturing
productivity [10].
OEE analysis is calculated by taking into consideration three factors which are
availability, performance and quality. OEE analysis can also identify the underlying
potential losses and also gives insights on how to minimize them. OEE has some
advantages as follows: 1. OEE can increase the equipment uptime by reducing its
downtime and maintenance costs. 2. OEE can reduce machinery cost by analyzing
the actual performance of the equipment and suggest changes accordingly. 3. The
most important advantage of OEE is that one can easily visualize the performance
of the equipment [10].
According to [11], there are 3 categories of losses which cause the performance of
the equipment to drastically reduce. The three categories are (1) availability loss, (2)
performance loss and (3) quality loss. These losses are further classiﬁed into 6 losses
namely equipment failure and setup and adjustments which come under availability
loss, idling and minor stops and reduced speed come under performance loss and
ﬁnally process defect and reduced yield falls under quality loss.
The OEE can be calculated based on these three factors (1) availability, (2)
performance and (3) quality. OEE value is calculated using the below formula:
OEE (%) = Availability × Performance × Quality × 100%
(1)
Availability takes into account for how long the equipment is available than the
calculated available time. Availability can be calculated using the below formula:
Availability = Operating time loading time × 100%
(2)

988
R. Patil et al.
Performance of the equipment is basically the calculated maximum speed the
equipmentshouldwork(theoretical)onandtheactualspeedtheequipmentisworking
on. Performance can be calculated using the below formula:
Performance = Tot.of prod. (processes amount)
× ideal (theoretical) cycle time operation time × 100%
(3)
Quality of the equipment means taking into account how many products need not
meet the quality standards. Quality can be calculated by using the below formula:
Quality = Net produced (processes amount)
−defect amount Net produced (processes amount) × 100%
2.7
Data Visualization
Data visualization is a tool of data literacy: “Data visualization is the graphical
representation of information and data. By using visual elements like charts, graphs
and maps, data visualization tools provide an accessible way to see and understand
trends, outliers and patterns in data” (https://www.tableau.com 2019, online) [12].
Datavisualizationistheprocessoftranslatinginformationintoavisualrepresentation
such as graphs and interactive dashboard which make it easy to gain insights from.
The main motive behind data visualization is to identify patterns, trends and outliers
in data sets. Tableau is a powerful data visualization tool used to analyze and visualize
data. It helps in simplifying data in a very easily understandable visual form. Tableau
helps to visualize data in such a way that it can be understood by anyone [12].
Data analysis and visualization are very fast and easy with Tableau and also the
visualizations created are in the form of interactive dashboards and worksheets.
3
Results
While experimenting the ﬁrst series (Table 1), we compared the performance of
the system with drift and without drift and found how the drift abruptly affects the
system’s performance.
Table 1 Accuracy of model
with and without drift
With drift
Without drift
Accuracy
78.30
89.54

Online System for Identifying Need of Machine Maintenance …
989
We also found the changes in the data, i.e., drift occurred using the ADWIN
algorithm [6, 7]. We found that there were changes in the data at particular indices.
Now after using Ozabagging [9] on the data, we found the system gave a performance
of 97% which is pretty good rather than Online Boosting which gave about 64%.
While experimenting with data visualization, we used tableau [12] which contains
different ﬁelds as follows.
3.1
OEE Dashboard
Figure 1 gives the overview of the analysis done on the dataset. This dashboard
contains various charts like bubble chart and bar charts. The bubble chart lets the
user know the OEE of the circuits in particular states by using various shades of
colors.
The OEE by month chart shows OEE of various circuits in the particular month
hence gives the user a brief about the performance over the year. Similar to the OEE
by month, the dashboard also shows availability by month, performance by month
and also quality by month.
3.2
Availability Dashboard
Figure 2 explains in detail the availability of circuits. This dashboard contains a
bar chart which shows the availability of the circuits by states. Another bar graph
shows downtime occurred with respect to centers and the other shows downtime with
respect to center type. As this dashboard is interactive, just by clicking on the center
Fig. 1 OEE dashboard

990
R. Patil et al.
Fig. 2 Availability dashboard
the center type chart modiﬁes with respect to the center clicked. This dashboard
shows the highest number of downtimes occurred due to a speciﬁc problem.
3.3
Performance Dashboard
Figure 3 explains in detail the performance of circuits. This dashboard contains a bar
chart which shows the performance of the circuits by states. Another bar graph shows
the comparison of performance which is theoretically calculated and the practical
performance achieved. The next bar graph shows the percentage difference of the
Fig. 3 Performance dashboard

Online System for Identifying Need of Machine Maintenance …
991
Fig. 4 Quality dashboard
performance from the earlier bar graph, and lets the user know in which state they
should concentrate more on.
3.4
Quality Dashboard
Figure 4 explains in detail the quality aspect of the circuits. This dashboard contains
a bar chart which shows the quality of the circuits by states. Other bar graph shows
the comparison of quality which is theoretically calculated and the practical quality
achieved. The next bar graph shows the percentage difference of the quality from
the earlier bar graph, and lets the user know in which state they should concentrate
more on.
4
Limitations of the System
The system takes input from sensors which are real time based which come in a
stream and hence as a time interval. As this data is stored in the database and then
accessed, hence it takes time to produce the results needed. Due to the earlier problem
it also takes time to analyze data in tableau which is done in real time. As this system
is dedicated to handle concept drift, hence it does not deal with other challenges
in data stream mining such as skewness in data, delayed information, etc. So these
challenges are one of the limitations of this system.

992
R. Patil et al.
5
Conclusion and Future Work
In this paper, we have proposed a system for identifying machine maintenance and
handling concept drift. Concept drift deals with the underlying change in data. This
concept drift is detected using Adwin algorithm and is handled using oza bagging
technique which gave us performance of 97%. The data is processed using a python
application which also generates and converts static data into streaming data. We have
also visualized this data and presented it with different graphs. This data visualization
is done by using Tableau, and it contains various different graphs which depict the
availability, performance and quality. The main idea of our system is to save a lot of
time and money when a machine failure occurs by preventing it by detecting as soon
as there is a fault.
At present, the system handles concept drift as a data stream mining challenge,
and the machine maintenance analysis is done using OEE. The future work concerns
more about handling different challenges faced during data stream mining and
also analyzing the data using different techniques tile total effective equipment
performance (TEEP).
References
1. Minku, L. L., & Yao, X. (2012, April). DDD: A new ensemble approach for dealing with
concept drift. IEEE transactions on knowledge and data engineering, 24(4), 619–633.
2. Polikar, R. (2012). Ensemble learning, Ensemble machine learning (pp. 1–34). Springer.
3. Lin, C.-C., Deng, D.-J., Kuo, C.-H., & Chen, L. (2019). Concept drift detection and adaption
in big imbalance industrial IoT data using an ensemble learning method of ofﬂine classiﬁers.
IEEE Access, 7, 56198–56207.
4. scikit-multiﬂow. https://scikit-multiflow.github.io/
5. Sarnovsky, M., & Marcinko, J. (2021). Adaptive bagging methods for classiﬁcation of data
streams with concept drift. Acta Polytechnica Hungarica, 18, 47–63. https://doi.org/10.12700/
APH.18.3.2021.3.3
6. Bifet, A. (2010). Adaptive stream mining: Pattern learning and mining from evolving data
streams. Frontiers in Artiﬁcial Intelligence and Applications, 207.
7. Bifet, A., & Gavaldà, R. (2007). Learning from time-changing data with adaptive windowing.
Proceedings of the seventh SIAM international conference on data mining (pp. 443–448).
8. Wang, B., & Pineau, J. (2016). Online bagging and boosting for imbalanced data streams.
IEEE Transactions on Knowledge and Data Engineering, 28(12), 3353–3366, https://doi.org/
10.1109/tkde.2016. 2609424. https://doi.org/10.1109/tkde.2016.2609424
9. Oza, N. C., Russell, S. (2001). Online bagging and boosting. Proceedings of the eighth inter-
national workshop on artiﬁcial intelligence and statistics (AISTATS’01, pp. 105112–105112).
Morgan Kaufmann.
10. OEE. https://www.oee.com/
11. Pomorski, T. (1997). Managing overall equipment effectiveness [OEE] to optimize factory
performance. 1997 IEEE international symposium on semiconductor manufacturing confer-
ence proceedings (pp. 33–36).
12. Tableau. https://www.tableau.com

Hybrid Model for Sentiment Analysis
Based on Both Text and Audio Data
D. E. Tolstoukhov, D. P. Egorov
, Y. V. Verina, and O. V. Kravchenko
Abstract A model for positive/negative sentiment analysis of phone conversa-
tions audio data is considered. Over six thousand features are retrieved employing
opensmile Python library, afterward the most signiﬁcant features are selected.
Sentiment analysis of the related text data of conversations is also carried out. An
attempt to combine features retrieved from audio and text is performed to increase the
quality of binary sentiment classiﬁcation. Practically acceptable results are obtained.
An original algorithm is developed and implemented, which includes data prepro-
cessing, model training, and veriﬁcation. A research software package has been
developed to solve the problem of bank scoring.
Keywords Machine learning · Logistic regression · Sentiment analysis ·
Multimodal sentiment · Fusion of models · Hybrid sentiment model
D. E. Tolstoukhov (B)
OTPBank, Leningradskoe highway, 16A, bldg. 2, Moscow 125171, Russian Federation
e-mail: d.tolstoukhov@otpbank.ru
D. E. Tolstoukhov · Y. V. Verina · O. V. Kravchenko
Bauman Moscow State Technical University, ul. Baumanskaya 2-ya, 5/1, Moscow, Russian
Federation
e-mail: verinayav@student.bmstu.ru
O. V. Kravchenko
e-mail: ok@bmstu.ru
D. P. Egorov
Kotel’nikov Institute of Radioengineering and Electronics of Russian Academy of Sciences,
Moscow 125009, Russian Federation
O. V. Kravchenko
Federal Research Center “Computer Science and Control” of RAS, Vavilova st., 40, Moscow
119333, Russian Federation
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_77
993

994
D. E. Tolstoukhov et al.
1
Introduction
A problem of recognition of emotions from speech and text was considered in [1].
On the other hand, the transfer learning model allows detecting some emotions
such as anger, disgust, fear, happiness, and sadness applying to dynamically detect
emotions from live videos. Transfer learning is an approach to utilize knowledge
achieved from the other problems to the problem at hand. A framework of transfer
learning that contains a priori trained effective information is introduced in [2]. That
aspect supports to overall task and provides some beneﬁts to reduce the number
of training epochs as well. An unsupervised sentiment classiﬁcation system that
proceeds phrases and polarity using fuzzy logic is also proposed in [3]. Sentiment
analysis of conversation is still an active area of research. There are currently no
reference solutions that can perform that type of sentiment analysis. An interactive
long short-term memory network that estimates tonality and measure of speakers
is developed in [4]. This paper explores how to use a classical machine learning
algorithm for sentiment analysis (binary classiﬁcation) of communication between
people by texts and volumes and get good quality by a classical algorithm. ˙In this
task, one audio track corresponds to one transcript in the text form. Training data
consists of 200 speech recordings and 200 texts (which are audio decryption). Test
data are 50 audio recordings and 50 texts. We show the result of sentiment analysis
by texts and audios and, in the ﬁnal, show the result of the hybrid algorithm.
2
Sentiment Analysis
2.1
Motivation
Sentiment analysis is a class of methods of content analysis in computational lin-
guistics, designed for automated use in text and sound. A brief comparison among
the existed methods in literature is introduced in Table1. One may highlight several
points from this Table1. As a rule, researchers consider data of only one nature, for
example, text or audio. The main classiﬁcation algorithm nowadays is neural net-
works. The quality in sense of accuracy in some metrics does not exceed 90%. The
number of sound features does not exceed 2000.
The major goal is to develop and implement a sentiment analysis algorithm, by
means, the classical algorithms of machine learning that have the result on the same
level of accuracy as shows neural networks on test data (performance evaluation
metric F1). To conduct that idea all steps such as data preparation, building models,
simulations, etc. were performed in Python (scikit-learn and opensmile libraries
[12]). The logistic regression [13] model (1) is used as classiﬁer
f (x) =
1
1 + exp (−wx),
(1)

Hybrid Model for Sentiment Analysis Based …
995
Table 1 Comprehansive analysis of the multimodel sentiment analysis publications
Model
Data
Features
No. of features
Classiﬁer
Quality
Refs.
R-CNN/fast R-CNN
Image/audio
MFCC/poistion
–
R-CNN/fast R-CNN
∼86%
[5]
Conv-LSTM
Text
N-gramms
200-dimensional
vocabulary
CNN&LSTM
∼89%
[6]
Multimodal
sentiment analysis
Text/audio
MFCC/Word2Vec
300 text/13-65-130
audio
SVM/DNN/GMM
∼78%
[7]
Fusion of mel and
gammatone/deep
C-RNN
Audio
MFCC/M-
GFCC/GFCC
36 (GFCC ﬂter)
Deep C-RNN
∼80%
[8]
ResNet/UB-
BiLSTM
Audio
MFCC
matrix 256 × 3
CNN/LSTM
∼69%
[9]
Acoustic and lexical
sentiment analysis
Text/audio
openSMILE
features/ n-gram
text/cepstral
988
openSMILE/1450
cepstral
DNN
∼85%
[10]
Sentiment analysis
using relative
prosody features
Audio
MFCC
–
SVM/GMM
∼83%
[11]

996
D. E. Tolstoukhov et al.
Table 2 Result on test data
Solver
Precision
Recall
F1-score
Support
Class 0
0.86
0.76
0.81
25
Class 1
0.79
0.88
0.83
25
Accuracy
–
–
0.82
50
Macro avg
0.82
0.82
0.82
50
Weighted avg 0.82
0.82
0.82
50
Table 3 Confusion matrix
Positive
Negative
Positive
19
6
Negative
3
22
where w is a vector of weight features and x are features. For each class (text
and sound), models consist of different stages but using one approach for signiﬁ-
cant model parameters determination. This approach is RandomizedSearchCV. Each
model ﬁt by RandomizedSearchCV on train data. In the result, selected model param-
eters for the different stages give the best result of the model in test data. In ﬁnal, the
model is ﬁt on train data with these parameters, and a ﬁtted model is applied to test
data. In turn, logistic regression return not only predicted target. It also returns the
probability of assigning an object to each class. In the present work, we have a deal
with these probabilities.
2.2
Sentiment Analysis by Text
Model consists of three stages. The ﬁrst stage is count vectorizer application with
handpicked parameters min_df=1, ngram_range=(1,2), max_df=0.9 and
Russian stop words. The second stage is TF–IDF. The third is logistic regression
with the following chosen parameters solver=sag, max_iter=150, C=0.4.
In ﬁnal, model is ﬁt on train data [14] with mentioned parameters, and ﬁtted model
is applied to test data, see Tables2, 3 and Fig.1.
2.3
Sentiment Analysis by Sound
Features were retrieved from sound using the opensmile library, for example,
audspec_lengthL1norm_sma_range, mfcc_sma_de_peakRangeRel
and so one. The total number of variables was 6343. Features that are correlated

Hybrid Model for Sentiment Analysis Based …
997
Fig. 1 AUC metric by text
Table 4 Result on test data [16]
Solver
Precision
Recall
F1-score
Support
Class 0
0.83
0.80
0.82
25
Class 1
0.81
0.84
0.82
25
Accuracy
–
–
0.82
50
Macro avg
0.82
0.82
0.82
50
Weighted avg 0.82
0.82
0.82
50
Table 5 Confusion matrix
Positive
Negative
Positive
20
5
Negative
3
21
more than 0.9 (in terms of Pearson correlation coefﬁcient [15]) were dropped.
After dropping highly correlated features, their total number was 3700. Model con-
sists of two stages. The ﬁrst stage is standard scaling. The second stage is logistic
regression with the following parameters solver=liblinear, penalty=l1,
max_iter=100 and C=0.4. In ﬁnal, model is ﬁt on train data with chosen param-
eters and ﬁtted model is applied to test data, see Tables4, 5 and Fig.2.

998
D. E. Tolstoukhov et al.
Fig. 2 AUC metric by sound
2.4
Hybrid Sentiment Analysis Model
Fusion strategy is about a simple idea to employ a linear combination [17] to merge
probabilities achieved from data of different types of text and audio. Both models
return a pair of probabilities of object’s attribution to classes “0” and “1.” The ﬁrst
model trained on text returns probabilities pm1(0), pm1(1). The second one returns
pm2(0) and pm2(1). Thus, to assign an object to a class, the following empirical
solution can be introduced
 ph(0) = αpm1(0) + (1 −α)pm2(0),
ph(1) = αpm1(1) + (1 −α)pm2(1).
(2)
where ph is a ﬁnal probability of hybrid model, α ∈[0, 1] is a coefﬁcient of cali-
bration. This relation (2) calibrates probability by each segments (text and sound)
for each classes 0 or 1 and return ﬁnal calibration probability by each class on each
object. If the extreme values of the probabilities in (0, 1) substitute interval and
the extreme values of the α parameter, then ph probability will take values from
0 to 1. For ﬁnding α coefﬁcient, a special cross-validation procedure (by text and
sound) is implemented, which returns predict probabilities by test block (test block
is part of train data on which the classiﬁer was not trained). Further, an optimized
procedure is developed, which operates with output probabilities returned from the
cross-validation procedure.
Logic of optimizing procedure is below.
1. Values from cross-validation (by text and sound) procedure are supplied to the
input (predict probabilities by test block).

Hybrid Model for Sentiment Analysis Based …
999
Table 6 Confusion matrix on test data
Positive
Negative
Positive
23
0
Negative
2
25
2. Final probabilities by test block are compiled from the previous item with the
help of p probability function, where α coefﬁcient is set from 0 to 1 with step
equal to 0.01 for each class 0 or 1.
3. F-metrics are formed by each test block.
4. In the output, we have data frames (as much, as test block in cross-validation)
with α coefﬁcient and F-metrics (100 strings in a data frame, because of 100
different values α coefﬁcient).
5. Sort each data frame by F-metrics and save only α coefﬁcient values with F-
metrics greater than 0.9 by each test block.
6. At ﬁrst, α coefﬁcient is averaged by each test block to get a new α coefﬁcient.
Secondly, the new α coefﬁcient is averaged by data frames to get the optimal α
coefﬁcient.
7. Finally, optimal α coefﬁcient is achieved.
In the present simulation, an optimal value of α coefﬁcient equals 0.2. Further,
p probability with optimal α coefﬁcient is used on test data. The general approach
contains several steps. Each ﬁtting model (by text and sound) is applied to each test
data (text and sound). We get the probability of assignment to each class for each
object from sound and text. Further, the probability of assigning an object to class
0 and class 1 is calibrated by p probability [14], and we get the ﬁnal probability of
assigning an object to class 0 and class 1. In the ﬁnal, two probabilities are compared:
if the probability of class 0 greater than the probability of class 1, then object refers
to class 0. In Table6, the confusion matrix is presented. Final F1-score equals 0.96.
3
Conclusions
Sentiment classiﬁcation is one of the most interesting and important problems in data
science. Emotion recognition has the stable development of artiﬁcial intelligence
technology. And emotion mining plays a key role in human–computer interaction.
The textual sentiment analysis has also attracted a lot of attention. Nowadays, deep
learning is often used to solve such problems. Perhaps the biggest disadvantages here
are a huge amount of marked-up data needed to train and difﬁculties in interpreting
the models. Although deep learning algorithms are successful and there are large
computing resources at our disposal, which were not available earlier, it still seems
that a lot of attention should be paid also to classical methods and the ability of the
most informative and signiﬁcant feature retrieval. The classical machine learning

1000
D. E. Tolstoukhov et al.
approach has been applied to sentiment analysis both on text and audio data in the
present paper. The hybrid model with mentioned calibration improves the resulting
F1-score by around 10% rather than sentiment analysis of text and sentiment analysis
of sound independently.
The relevance of this work is due to the importance of the task of determining
tonality in the modern world. The reasons are as follows: the number of ways of
communication has increased and to anticipate the wishes of the client, companies
need to catch changes in the behavior of their clients.
In the present work, results of different classiﬁcation algorithms, algorithm by
texts, algorithm by audio, and union algorithm are given. As seen that union algorithm
has the best separating ability (96% in F1-metrics) compared with the algorithm by
text and by audio ﬁles, also given a table with results from different articles.
Outour results illustrate a possible way how to get good quality (in a range from 90
to 100% by F1-metrics) without neural networks. This approach is the most simple
compared to neural networks and has a good interpretation of the result.
Further development of the present approach will research more relevant and
consistent databases. Also, an additional possible point for research, for example, is
the development in-house framework for tonality analysis.
References
1. Linqin, C., Yaxin, H., Jiangong D., & Sitong Z. (2019). Audio–textual emotion recognition
based on improved neural networks. Mathematical Problems in Engineering, 2593036.
2. Devamanyu, H., Soujanya, P., Roger, Z., & Rada, M. (2021). Conversational transfer learning
for emotion recognition. Information Fusion, 65, 1–12.
3. Srishti, V., & Seba, S. (2021). Highlighting keyphrases using senti-scoring and fuzzy entropy
for unsupervised sentiment analysis. Expert Systems With Applications, 169, 1–12.
4. Yazhou, Z., Prayag, T., Dawei, S., Xiaoliu, M., Panpan, W., Xiang, L., & Hari, M. P. (2021).
Learning interaction dynamics with an interactive LSTM for conversational sentiment analysis.
Neural Networks, 133, 40–56.
5. Tsai, M., & Huang, J. (2021). Sentiment analysis of pets using deep learning technologies in
artiﬁcial intelligence of things system. PPR: PPR301546, 1–16.
6. Ghorbani, M., Bahaghighat, M., Xin, Q., & Ozen, F. (2020). ConvLSTMConv network: A deep
learning approach for sentiment analysis in cloud computing. Journal of Cloud Computing,
9(16), 1–12.
7. Abburi, H., Prasath, R., Shrivastava, M., & Gangashetty, S. V. (2016). Multimodal sentiment
analysis using deep neural networks. In Proceeding of the 4th international conference on
mining intelligence and knowledge exploration (pp. 13–19).
8. Kumaran, U., Rammohan, S. R., Nagarajan, S. M., & Prathik, A. (2021). Fusion of MEL and
gammatone frequency cepstral coefﬁcients for speech emotion recognition using deep C-RNN.
International Journal of Speech Technology, 24, 303–314.
9. Luo, Z., Xu, H., & Chen, F. (2018). Audio sentiment analysis by heterogeneous signal features
learned from utterance-based parallel neural network. EasyChair Preprint No., 668, 1–18.
10. Li, B., Dimitriadis, D., & Stolcke, A. (2019, May). Acoustic and lexical sentiment analysis
for customer service calls. In Proceeding of the IEEE international conference on acoustics,
speech and signal processing (ICASSP) (pp. 5876–5880).
11. Abburi, H., Alluri, K. N. R. K. R., Vuppala, A. K., Shrivastava, M., & Gangashetty, S. V. (2017)
Proceeding of the tenth international conference on contemporary computing (IC3) (pp. 1–5).

Hybrid Model for Sentiment Analysis Based …
1001
12. Sklearn logistic regression documentation. Retrieved on May 30, 2021, from https://scikit-
learn.org/stable/modules/classes.html
13. James, G., Witten, D., Hastie, T., & Tibshirani, R. (2014). An introduction to statistical learning.
14. Russian open speech to text. Retrieved on May 30, 2021, from https://azure.microsoft.com/
en-us/services/open-datasets/catalog/open-speech-to-text/
15. Hastie, T., Tibshirani, R., & Friedman, J. (2009). The elements of statistical learning.
16. Audio feature extraction opensmile. Retrieved on May 30, 2021, from https://www.audeering.
com/opensmile/
17. Vogt, C. C., & Cottrel, G. W. (1999). Fusion via a linear combination of scores. Information
Retrieval, 1, 151–173.

Salesforce Vaccine for Real-Time Service
in Cloud
Monika Mehra, Pradeep Jha, Himanshu Arora, Khushboo Verma,
and Himalaya Singh
Abstract This article analyses Salesforce’s cloud-based vaccine management
platform based on its working procedure and advantages. The most difﬁcult task
is to manufacture a large number of vaccinations and disseminate them to humans.
The Salesforce platform is very beneﬁcial to distribute that vaccination, and also,
it manages the scheduling, dosage, and registration in a very efﬁcient and simple
manner. Moreover, the platform manages the collection and veriﬁcation of cases,
and also, it prepares a report based on the health status.
Keywords Customer relationship management (CRM) · Salesforce · Vaccine ·
Cloud · Health · Biomedical
1
Introduction
Machines with low power and frequency were launched in the biomedical system
to obtain a long battery life [1]. The portable biomedical system works on system
to achieving the low cut-off frequency and low power consumption and low area
requirement necessitates resolving this challenge [2]. When we consider the cloud
system, it is ideal for overcoming the problems of low power, frequency, and extended
battery life of devices. Since, we can ﬁx all of these issues with the assistance of the
cloud and Salesforce.com is the ﬁnest CRM given by the Salesforce Company. It is
software as a service [SaaS] software that helps us to manage sales and after-sales
services. It assists in learning from our business and manages all the ﬁrm’s activities
on a single platform with minimal time and effort. Salesforce offers a variety of clouds
to manage various tasks. Sales Cloud, Service Cloud, Marketing Cloud, and other
clouds are examples of the existing cloud platforms. Vaccine Cloud is a new product
available on the market. The Vaccine Cloud helps us to manage the distribution
process of vaccines across the country, and it also helps to obtain knowledge about
the health status of an individual. It explains which platform is appropriate for your
company and how to combine it with Salesforce to achieve the best outcomes [3].
M. Mehra · P. Jha · H. Arora · K. Verma (B) · H. Singh
Department of CSE, Arya College of Engineering & Research Centre, Jaipur, Rajasthan, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_78
1003

1004
M. Mehra et al.
We have a procedure on the Vaccine Cloud to manage our whole vaccine distribu-
tion program. It provides a step-by-step method to implement a management system
that will assist in vaccination distribution across the country. Salesforce offers a
variety of services to help in the implementation of vaccination cloud system. The
usercanchooseanyplatformthattheyarecomfortablewithandfollowstheprocedure
to implement the best system to assist the world’s health status.
Government
Vaccination campaigns are becoming more complex and the government requires
data to conduct them more efﬁciently. Vaccine Cloud helps them to:
• Track their goals.
• Data visualization.
• Track vaccination distribution.
1.1
Healthcare Organizations
Healthcare providers need this cloud to manage the patients and heal them. They
need an effective system to manage their work in a very smooth and effective way.
Vaccine Cloud allows them to:
• Train their team and make them professional.
• Trace doses of vaccine.
• Scale efforts without delay.
• Helps to manage campaigns and mass reach out.
• To establish better communication.
• Organize efforts on different sites.
1.2
Business Organizations
Business organizations need to enhance their working model. They must establish
safeguards not only for their employees but also for their consumers to:
• Support Salesforce’s workplace command centre in order to help them to return
to the workplace safely.
• Digitize ﬁtness credentials.
• Maintain case and gathering of data.
• Perform secured contract tracing.

Salesforce Vaccine for Real-Time Service in Cloud
1005
1.3
Non-proﬁt Organization
We need precision to ﬁgure out how many vaccinations are required and where they
are needed. Salesforce.com and the experience cloud can be effortlessly integrated
with the non-proﬁt cloud to help:
• Single portal for international organization.
• Financially modernized in real-time.
• Supply teams with vaccines and access reporting.
• Centralized cloud to store information.
2
How to Implement the Right Solution for Vaccine
Management System
2.1
Preparation
Now start by making the units of government leaders, health leaders, partners they
will be the key to capture the perspectives and building faith. After that, you need
to decide which cloud platform ﬁts to the goals and gives you the ﬂexibility to
meet requirements and speed up the process. Our platform should be clear to learn
and deploy the cloud-based data management process. As we know, cloud-based
platforms can be implemented in days and weeks while others take months and
years. It gives us the sights of data in visualized form like dashboards and reports,
which helps to take required action in a particular circumstance [4] (Fig. 1).
The major drawback of the existing system is security, so the right platform should
be utilized. Also, the existing platform can also be easily integrated to the proposed
salesforce system to enhance its efﬁciency.
2.2
Awareness and Outreach
The trust on the Vaccine Cloud can be enhanced if the preparedness is not getting
out of hand. After developing the model, it will become ready to engage with people
across the country. The developed model should communicate with people across a
variety of channels, and it will also require a team of representatives to answer all of
the inquiries made by the common people. For this, the model should be connected
with the people via various channels like SMS, Email, website, social media, etc.
to build trust and make sure that no questions can remain unanswered. Vaccine
management will insist the organizations to move quickly and inform people about
every single piece of information in order to gain their trust [5]. The selected cloud
management platform should have the capability to send automated emails at the

1006
M. Mehra et al.
Fig. 1 Implementation of
vaccine management system
right time and also to the right place, and it also develops the capability to scale
according to the user speciﬁcation.
2.3
Administration
With a technology platform, it will include full data with a 360° view to deliver a fast
vaccination process. The developers should communicate to each constituent at the
right time and right place and manage each dose of vaccine, which should be provided
at the right time to customers. The outreach of the platform should be to everyone
even if they do not have access to smartphones or even the internet [6]. It should also
be understandable and also the developed webpage should be multi-lingual so that
people from different regions/states can understand it. The users should completely
understand the process. Also, if the person is not able to opt in for that campaign,
make sure that they have received an alternative method to become a part of that
program.
Doses of COVID-19 may be limited at the initial stage but the platform helps
you to determine the need for doses. It necessitates the need to maintain a stock-
pile of supplies as safety measures. Also, the developers should also verify whether
the facilities are following the safety protocols. The developed platform should be
capable to grow according to the need of doses even when the number of appoint-
ments increases. It should be quick to respond in order to obtain a real-time stock
information.

Salesforce Vaccine for Real-Time Service in Cloud
1007
2.4
Program Monitoring and Community Safety
As many people are getting immunized, it is very essential to monitor the previous
periods. This will help a lot to do research on that data and it will help you to
solve the problems and the outcomes of vaccines. It helps you to build trust in your
constitution [7]. The model can easily identify the vaccine need and how many people
are getting vaccinated. Now the particular organization can also closely monitor how
the vaccines behaving to the people and what are the effects of that vaccine on
humans. The organization can read this data in a visualized form by using reports
and dashboards.
Reopening schools and colleges create challenges in establishing mass immu-
nization campaigns. An advanced technology will be required to make sure that
everyone is safe by verifying each and every individual. Helping organizations to
reopen require different digital tools to track the health status of every individual.
Access to services will not only depend on the applications but it should also be
available to everyone. For example, if a person wants to know about their COVID
report, it should be available to him/her without entering any email or logging into
any application [8].
2.5
Wrap Up
Managing one of the largest public health programs requires speed and scalability.
Using a single technology platform can help you manage all aspects of information,
and it will be quickly enough to scale according to the vaccine availability [9].
Distributing information to the people will highly help to gain trust and increase the
number of people, who get vaccinated by making the program successful (Fig. 2).
Fig. 2 Process of vaccine distribution

1008
M. Mehra et al.
3
Conclusion
From the proposed research work, it is concluded that Salesforce is gaining promi-
nence as technology improves at a rapid pace. Salesforce just introduced Vaccine
Cloud to assist companies in managing the vaccination process and gathering data
in real-time to discover answers to the existing real-time challenges. The proposed
Vaccine Cloud also helps to display the data. It provides solutions, which are not only
software-dependent but it also makes people who do not have access to the internet
to remain as a part of the program. It helps you to manage a large number of people,
who get vaccinated, and it also tells you the required vaccination count. It helps to
communicate with people via any means of the channel in order to reach out to every
person and also to check the health status of every individual. Therefore, this paper
has completely studied how the vaccination cloud provides the best services to make
every individual healthier and safer.
References
1. Soni, G. K., Singh, H., Arora, H., & Soni, A. (2020) Ultra low power CMOS low pass ﬁlter for
biomedical ECG/EEG application. In IEEE 2020 fourth international conference on inventive
systems and control (ICISC) (pp. 558–561).
2. Soni, G. K., & Arora, H. (2020). Low power CMOS low transconductance OTA for electrocar-
diogram applications. In Recent trends in communication and intelligent systems, algorithms
for intelligent systems (pp. 63–69).
3. Manchar, A., & Chouhan, A. (2017). Salesforce CRM: A new way of managing customer rela-
tionship in cloud environment. In 2017 Second international conference on electrical, computer
and communication technologies (ICECCT).
4. Gupta, H., & Vincent, P. M. D. R. (2017). A centralized system to support health care in India
using cloud. In 2017 International conference on intelligent computing, instrumentation and
control technologies (ICICICT).
5. Karaﬁllakis, E., et al. (2021, February 8). Methods for Social Media Monitoring Related to
Vaccination: Systematic Scoping Review. JMIR Public Health and Surveillance, 7(2), e17149.
6. Areﬁn, M. S., Survoi, T. H., Snigdha, N. N., Mridha, M. F., & Adnan, M. A. (2017, December).
Smart healthcare system for underdeveloped countries. In IEEE International conference on
telecommunications and photonics (ICTP).
7. Rahmat, S. N, Jamal, A., Alkawaz, M. H., & Sangaran, M. (2019). Parental reminder and planner
for children vaccination. In 2019 IEEE 9th international conference on system engineering and
technology (ICSET) (pp. 144–149).
8. Fernandes, S. M., & Coutinho, C. (2017). Key performance indicators for improving a CRM
implementation. In 2017 International conference on engineering, technology and innovation
(ICE/ITMC).
9. Numnark, S., Ingsriswang, S. & Wichadakul, D. (2014). VaccineWatch: A monitoring system
of vaccine messages from social media data. In 2014 8th International conference on systems
biology (ISB).

Prediction of Inborn Talents Using
Fingerprint Analysis
Maitreyi Pitale, Riya Kale, Manasi Khamkar, and Ujwala Ravale
Abstract Dermatoglyphics multiple intelligence test is a scientiﬁc study of
ﬁngerprint and rigid skin patterns found on your ﬁngers. With the help of this test,
complete brain analysis in a unique, adaptive, instinctive, and responsive way can
be done by classiﬁcation of the patterns and ridges on a person’s ﬁngerprint tips.
DMIT works by scanning the ﬁngerprint and manually counting the ridges on the
ﬁngerprints of each individual and then calculating the percentage of brain domi-
nance, learning styles, lobe percentage, and ridge count. This technique is a tradi-
tional method of taking a DMIT test, which requires human assistance for manual
calculations and demands using scientiﬁc approaches. The proposed system aims
to technically generate the DMIT report of 13 pages for each dominant pattern
detected in seconds using minutiae extraction, singularity detection using Poincare
index, contour counting, and pattern recognition using CNN. This helps in amelio-
rating the situation by making better career decisions using the report generated by
the application. Hence, taking this concept on a broader level using technological
compensation.
Keywords DMIT—Dermatoglyphics multiple intelligence test ·
CNN—Convolutional neural network · Minutiae extraction · Ridge count
M. Pitale · R. Kale · M. Khamkar · U. Ravale (B)
Department of Computer Engineering, SIES Graduate School of Technology, Mumbai, India
e-mail: ujwala.ravale@siesgst.ac.in
M. Pitale
e-mail: maitreyi.pitale17@siesgst.ac.in
R. Kale
e-mail: riya.kale17@siesgst.ac.in
M. Khamkar
e-mail: manasi.arun17@siesgst.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1_79
1009

1010
M. Pitale et al.
1
Introduction
Fingerprints are distinct patterns made on the tips of ﬁngers, toes, and palms due
to crests and troughs on the epidermal tissue. No two individuals have been found
with the same ﬁngerprint even identical biological twins have unique ﬁngerprints.
Even one individual does not have the same pattern on two ﬁngers. These qualities
of the ﬁngerprints make it the globally used identiﬁcation system. They are used
in biometric security systems, crime scene investigations, detecting drug usage, and
many more. There are mainly three ﬁngerprint patterns [1] found in human beings.
The loop pattern is the one, in which the ridges circle back toward themselves,
forming a loop. The whorl pattern is the one in which the ridges form a whirlpool-
like pattern on the tips of the ﬁngers. This pattern constitutes about 35% of the
population. The last pattern is the arch pattern forms a wavy pattern with one delta.
One other use of the ﬁngerprint, though not widely known, is its use in getting
a basic understanding of the human thought process and brain development and
dominance. The technique developed was by Dr. Howard Gardner. Popularly known
as DMIT [1] or dermatoglyphics multiple intelligence tests helps in understanding
the lobes of the brain and its usages vary widely for all individuals.
Every child is unique in his or her way, be it the learning abilities or their response
to natural stimuli. Parents struggle every day to ﬁnd out what their child inclines,
ultimately putting a lot of pressure on the child to overachieve. On the other hand,
knowing the personality of the child, how their child should be approached in difﬁcult
situations, and knowing their area of interest could help both parties.
Another way to get a hazy picture of the person’s nature is by the multiple intelli-
gence test. These have a series of MCQ questions that you have to answer honestly.
At the end of the test, the system generates a report showing the nine bits of intel-
ligence (musical, bodily kinesthetics, interpersonal, verbal-linguistic, naturalistic,
intrapersonal, and visual-spatial) and a bar graph showing which is your strong suit.
Although there is no way in which you can guarantee the result as you have no idea
what algorithm is running at the back or if you did or did not answer the questions
honestly.
Similarly, the basis is the open-source psychometric report which gives the same
result based on a set of 36 statements which you have to rate in the range of most and
less likely to do. Out of the three, DMIT has proven to be the most efﬁcient method
but the problem with this system is that it is time-consuming, and calculations and
analysis in this DMIT process are done manually. Hence, our system is looking
forward to leveraging this hand-operated system into an automated system where
the application does all the calculations in seconds.

Prediction of Inborn Talents Using Fingerprint Analysis
1011
2
Related Work
There have been quite a few studies and exploration in the dermatoglyphics depart-
ment. Many researchers have found interrelations between ﬁngerprints and the
psychological behavior of a human being.
In2008,Mil’shteinetal.[2]proposedtwonewalgorithmsnamelyLineScanAlgo-
rithm (LSA) and Spaced Frequency Transformation Algorithm (SFTA) to compare
and recognize full and partial ﬁngerprint, respectively. The SFTA uses a two-
dimensional Fourier transform to convert the image into a frequency domain. Then
each pixel is compared by the computer with a certain threshold value ﬁxed. If it is
surpassed, a match is found otherwise rejected. The LSA ﬁrst crops out the unnec-
essary portions of the image. Then correlation curves are found in the rows which
are similar for the same images. It was concluded that LSA had a greater accuracy
as it worked on partial images.
In 2012, Agarwal et al. [3] concluded after an extensive study of ﬁngerprints
obtained from the northern parts of India that there is a correlation between ﬁngerprint
patterns and personality. This correlation can be used as an instrument totally to the
person to a speciﬁc type of counseling. Data was collected from all the ten ﬁngers
using the ink technique and the chi-square test with a level of signiﬁcance less than
0.5 was used to compare it.
In 2017, Dholiya et al. [4] in their paper specifying the dermatoglyphics multiple
intelligence tests stated the ATD angle also has a signiﬁcant role to play in deducing
the person’s response to learning stimuli. Fingerprint patterns are in the control of
additive alleles, inherited from parent to offspring. The DMIT report may suggest
several talents but no talent can be perfected without training in the ﬁeld.
In 2019, Gupta et al. [5] studied the correlation between blood type, ﬁngerprint,
and personality. They stated that American doctors in their study speciﬁed a deﬁ-
nite correlation between human personality and their ﬁngerprints because when the
human fetus had no brain, he had no ﬁngerprints. In 2019, Nguyen and Nguyen [6]
used a combination of support vector machines, random forest, and machine learning
algorithms to predict the ﬁngerprint type.
In 2019, Srivastava et al. [7] used histogram equalization, Fourier transforms, and
image binarization for ﬁngerprint picture improvement. After improving the picture,
the next task was minutiae extraction which was done by edge diminishing and
minutia checking. The edge diminishing each ridge of the ﬁngerprint was diminished
to one-pixel length for accurate minutiae extraction.
3
Dataset
Our process begins with acquiring a large-scale dataset of customized ﬁngerprints
from varied resources. The need of our project was to ﬁnd ﬁngerprint data with a
clearer insight into its ridges, bifurcations, and visibly identiﬁed patterns. We have

1012
M. Pitale et al.
used the Sokoto Coventry Fingerprint Dataset [8], consisting of 6000 ﬁngerprints
from 600 African subjects, from which only 600 ﬁngerprints were used for training
purposes as the remaining were distorted and unclear; hence, we had to discard them.
The Institute of Educational Counseling and NLP—a unit of the Guru Founda-
tion—provided us with a dataset of 2100 ﬁngerprints of 70 individuals. Among the
dataset of 2700 ﬁngerprints, we have used 1500 ﬁngerprints as our system requires
clear images. Our dataset consists of two parts—training set and validation set. There-
fore, we have taken 1200 ﬁngerprints for the training part and 300 ﬁngerprints for
the validation part. Further, we have classiﬁed the training and validation sets into
three patterns—arches, loops, and whorls—to train the CNN model.
4
Proposed System
Our approach begins with dividing the obtained dataset into arches, loops, and whorls
for the training and validation purpose. Once the dataset is trained, the main objective
here is to provide an efﬁcient and smart CNN model to predict the class of pre-
processed ﬁngerprint images. It classiﬁes the ﬁngerprint and provides the dominant
ﬁngerprint pattern accurately. Our second objective is to ascertain the singularities
(coreanddelta)bytakingintoaccounteveryminutiafeatureusingminutiaeextraction
and singularity detection algorithms. Core to delta image is cropped and stored in
the backend, where the contour counting is done. Ridge count is then mapped to
relative formulae to calculate the ridge percentage, total ridge count, and brain lobe
dominance. Since there is no such pre-existing application, this system will be useful
in reaching a wider area.
4.1
Pattern Recognition Using CNN
The ﬁrst goal of our system is to recognize the appropriate ﬁngerprint pattern from
whichwecanidentifythedominantﬁngerprint,forwhichweuseaconvolutionneural
network [9]. A basic CNN model is made up of one or multiple pairs of convolution
and pooling layers (alternated one after other) which ultimately provides a perfectly
connected neural network. These two layers mimic the character of the complex
and simple cells in the mammalian visual cortex. The classic architecture of the
convolution network is shown in Fig. 1 [9].
A CNN architecture is used to ﬁnd the pattern—arches, loops, and whorls, of
the ﬁngerprint. Each node obtained in the output layer correlates with one character
class. After training the CNN, parameters of the fully connected layer remain to
draw out the ﬁnal feature vector which is fed to the BPR classiﬁer. The CNN-based
feature extractor which is inconsequential to the number of character classes can
be very compact. The pattern recognition is incorporated on all the ten ﬁngerprints

Prediction of Inborn Talents Using Fingerprint Analysis
1013
Fig. 1 A typical convolutional neural network
Fig. 2 Model for prediction of ﬁngerprint pattern
and the one which is found the maximum number of times is the dominant ﬁnger-
print pattern of that individual, which is crucial in mapping the personality of that
person (Fig. 2).
4.2
Minutiae Extraction and Singularity Detection
After the successful identiﬁcation of the dominant pattern, our next aim to process
the raw ﬁngerprints into skeletonized images to detect the core and delta singularity
for each ﬁngerprint. The procedure of minutiae extraction method [10] is as follows:
1.
Grayscale transformation—The gray color is the color in which all RGB values
are of equal intensity, and hence, we have to provide only a single intensity value
for each color. The grayscale algorithm transforms the raw image in which the
only colors are shades of gray. By doing this transformation, less information
is to be provided for each pixel by performing this transformation, and less
information is needed for each pixel, which is ample for the majority of tasks
and eliminates the need for complex and difﬁcult-to-process-colored images.
2.
Image normalization—It is a well-known image enhancement technique that is
used to improve the contrast in an image. This system is used in this project
to standardize the intensity values obtained from an image by modifying the
range of gray-level values resulting in their extension in a required direction

1014
M. Pitale et al.
and ameliorate the variance of the image quality. Normalization is pivotal in the
case of noisy ﬁngerprint for better image outcome and to decrease the variance
of the gray-level amount alongside the ridges to ease the processing steps in the
subsequent image
3.
Segmentation—Segmentation is needed to remove the image’s edges and areas
that are too noisy. That is reached by estimating acceptable gray levels. The
image is divided into sub-blocks of (W * W) sizes for this reason, with the
variance calculated for each block. The root of the variance of each block is
then associated with a threshold T, and if the obtained value is less than the
threshold, the resulting block is called the image’s context and will be removed
from further processing. It is possible to reduce the size of a valuable part of
the ﬁngerprint and get the most out of the biometric data by using this step.
The picture is smoothed using the “Open” and “Close” morphological opens.
The “OPEN” operation is used to expand images and delete background noise
peaks, while the “CLOSE” operation is used to shrink images and remove tiny
cavities.
4.
Orientation—A variety of methods for estimating the orientation area of ﬁnger-
print images have been offered by viewing the image as an oriented texture. The
main steps for calculating dominant direction are as follows (Fig. 3) [10]:
A variety of methods for estimating the orientation area of ﬁngerprint images
have been offered by viewing the image as an oriented texture. The main steps
for calculating dominant direction are as follows: Given a normalized image,
N. the main steps for calculating prevailing direction are as follows:
(1)
Cut it into w * w (8 * 8) square blocks.
(2)
For each pixel, compute gradients (i, j) x ∂and (i, j) y ∂. Simple Sobel
operators are gradient operators.
(3)
Using the following, estimate the local orientation of each block centered
at pixel (i, j).
5.
Frequency map and Gabor ﬁlter—A frequency block is determined. To build
the Gabor ﬁlter, we need the local estimate of the frequency map in addition to
the directional map. The image’s frequency map is composed of calculating the
local frequency of the streaks in each pixel (Figs. 4 and 5) [11].
Fig. 3 Dominant directions
calculation a The original
ﬁngerprint image. b The
ﬁngerprint image’s
orientation ﬁeld

Prediction of Inborn Talents Using Fingerprint Analysis
1015
Fig. 4 Local direction in the
vicinity
Fig. 5 Local orientation in
the neighborhood
6.
Thinning and skeletonization—The picture must be skeletonized to allow for
the extraction of minutiae: a series of morphological erosion operations would
reduce the thickness of the striations until they are equivalent to one pixel while
preserving striation connectivity (That is to say that the continuity of the striates
must be respected, holes must not be inserted). Some papers use the Rosenfeld
algorithm because it is simplistic. Skeletonization reduces binary artifacts to
representations that are just one-pixel wide. By making successive passes of the
picture, you can skeletonize your work. Border pixels are detected and removed
in each pass if they do not disrupt the connectivity of the corresponding object.
7.
Crossing number—The crossing number method is a very easy way to detect
ridge bifurcations and endings. 3 × 3 pixel blocks will be examined by the
crossing number algorithm. The CN value is determined using the following
formula (Fig. 6) [11]:
If the middle pixel (which reﬂects the ridge) is black: If a pixel on the boundary
crosses the ridge once, we have found the ridge’s end: We observe ridge
bifurcation if the pixel on the boundary crossed the ridge three times.
8.
Singularity detection using Poincare Index: The Poincare index algorithm [12]
is applied to calculate the sum of orientation variations associated with a closed
circle around a point to determine if it is a singular point or not. In this case, let
G be the ﬁeld denoting a ﬁngerprint orientation and let [i, j] be the element’s
position. The results can be estimated as follow: The curve C is a closed path
identiﬁed as an ordered sequence of some components of D with an internal
point [i, j], and the algebraic sum of the orientation differences between adjacent
elements of C yields PG, C(i, j). On closed curves, the Poincaré index assumes
Fig. 6 CN calculation

1016
M. Pitale et al.
just one of the discrete values: 0°, 180°, or 360°, as is well understood and easily
demonstrated. 0° does not belong to any singular area in the case of ﬁngerprint
singularities. 360° is a singular region of the whorl kind. 180° is a delta-type
singular region, while 180° is a loop-type singular region (Figs. 7 and 8).
Fig. 7 Minutiae extraction and singularity detection
Fig. 8 Model for ridge count

Prediction of Inborn Talents Using Fingerprint Analysis
1017
Fig. 9 Fingerprint contour
4.3
Contour Counting
Objects are recognized from the background by contour pixels. Based on its local
pattern, the Contour Tracing Algorithm [13] classiﬁes the form of contour pixel.
Then it uses the information of the previous pixel to map the next contour. As a
result, it can distinguish between straight lines, inner corners, outer corners, and
inner-outer corners and extract pixels of a particular contour form. The threshold
function is applied to apply ﬁxed-level thresholding to a multiple-channel array in
this project. The feature is commonly used to convert a grayscale image to a bi-
level (binary) image (compare may also be used for this) or to remove noise, that is,
ﬁltering out pixels with too small or too high values. The function supports a variety
of thresholding techniques. The category parameter determines what they are. Since
the contour function takes neighboring pixels into account in a continuous fashion,
a ridge is treated as a line, and contours are measured (Fig. 9).
4.4
Neuron Distribution and Brain Dominance Formulae
• Ridge Count percentage = 100 × Finger RC ÷ Total RC
• Lobe Count percentage:
Prefrontal = (R1 + R6) ∗100/TRC
Frontal
= (R2 + R7) ∗100/TRC
Parietal = (R3 + R8) ∗100/TRC
Temporal = (R4 + R9) ∗100/TRC
Occipital = (R5 + R10) ∗100/TRC.

1018
M. Pitale et al.
Fig. 10 Model for report generation
4.5
Report Generation
The main output of our system is 13 pages printable report using HTML and CSS.
This report has been designed keeping in mind the DMIT report generated by the
centers, under the guidance of a DMIT expert to make it as accurate as possible. The
initial pages explain in brief, how the report can be used, the various personality traits,
and the description of the DMIT. The most important part of the report is the neuron
distribution chart. This is generated dynamically after the calculation of the ridge
counts. The dominant and recessive traits of a person are displayed in percentages by
using a simple formula on the ridge counts of each ﬁnger. Next to be displayed is the
dominant ﬁngerprint type obtained from the CNN model. We also display the basic
traits of the dominant personality. At the end, the report contains a brain dominance
chart; this is also calculated using the ridge counts. It displays in percentages the
activity of the brain (Fig. 10).
5
Results
We have successfully developed a system by training a model: that identiﬁes the
pattern of the ﬁngerprint using the CNN algorithm and it is reﬂected in the gener-
ated report. Each ﬁngerprint has been associated with personality traits unique to
it. Identiﬁcation of personality traits through ﬁngerprint is not a recent discovery
but being used for many decades now. The three main pattern types as discussed
earlier are the loops, whorls, and arches. People with loop ﬁngerprint tend to have
a strong opinion, are content in life with what they have, and respect others. Due to

Prediction of Inborn Talents Using Fingerprint Analysis
1019
such nature, they make good partners and employees who lead a group comfortably
and have good work ethics. They may not be very well organized but can embrace
change very quickly. People with the whorl ﬁngerprint are above average in intelli-
gence they would be good followers and have a dominant personality type. Unlike
the loop pattern traits, they are organized, exacting, and controlling. A person having
whorls on both thumbs could be considered controlling. People with the arch ﬁnger-
print have analytical thinking and are cautious in the many steps they take thinking
analytically. The following is the output (Fig. 11):
With the help of minutiae extraction algorithm, singularity detection, and contour
counting, we were able to count the neuron distribution of an individual from which
9% and above shows strong neuron activity, 9% and below shows weak neuron
activity, and 6–9% is average neuron activity. The report generated also provides
information about left and right brain dominance. The following is the output
(Fig. 12):
The left and right hemispheres of our brain are partitioned. Each of the brain’s
hemispheres has its unique set of abilities. The functions of the left brain are repre-
sented by the ﬁngers of the right hand, while the functions of the right brain are repre-
sented by the ﬁngers of the left hand. Different bits of intelligence are represented
by different ﬁngers. Each intellect carries its monetary value. The total percentage of
Fig. 11 Dominant pattern

1020
M. Pitale et al.
Fig. 12 Neuron distribution chart

Prediction of Inborn Talents Using Fingerprint Analysis
1021
intelligence distributed will be 100%. This value measures the intensity of neo-cortex
neurons, implying that a function with a high degree of value will have a higher RC
value. Various pattern types will display the distribution of various values. Most
people’s values will vary from 8 to 30 in typical circumstances. If the value is high, it
means that the activity level of the brain cortex for that function is high. If a speciﬁc
intelligence’s RC value or percent distribution shows “0” or arch type, that value’s
minimum range can be 0 and the maximum range can be inﬁnity. The RC values’
potential will be in the range 0–inﬁnity. This merely means that this intelligence
has a high level of adaptability. The average RC value is 10%; if the distribution of
RC values in a certain intelligence is less than 5.99 percent, it means it is merely a
result of comparison with yourself, and it does not necessarily mean you are poor in
that intelligence. The difference in RC percentages between the left and right brains
should be around 5–7%. It is a sign that you are in the middle of a regular range. If the
discrepancy is greater than 7%, the weak side of the brain will affect the other side.
This, however, does not indicate a severe worry. To balance it, one must concentrate
on the weak side (Fig. 13).
Based on classiﬁcation into lobes, the brain can be studied as composed of the
frontal lobe, superior and inferior, parietal lobe, temporal and occipital lobes. The
cerebral cortex is divided into four lobes, each of which has its unique function.
Different functions have been linked to the frontal lobe, parietal lobe, occipital lobe,
and temporal lobe, spanning from reasoning to auditory perception [14]:
The Frontal Lobe
It is related to reasoning, problem-solving, logical thinking, computing process,
rationalization, linguistic function, visual-spatial imagination, idea generation, and
conceptualization. It is located in the front of the brain.
The Prefrontal Lobe
The prefrontal cortex is the anterior (front) region of the frontal lobe. It is essential in
the development of “higher cognitive functions” and personality. It aids in planning,
management, communication, coordination, and emotional and behavioral control.
It also controls our ability to be creative, to lead, to have intuition, and to visualize.
The Occipital Lobe
It’s in the rear of the brain, and it is responsible for understanding visual stimuli
and information. The occipital lobe houses the primary visual cortex, which receives
and processes information from the eye’s retinas. Visual identiﬁcation, observation,
and reading comprehension are controlled by the left side, whereas visual and image
enjoyment is controlled by the right side.
The Parietal Lobe
It is related to the processing of tactile sensory information such as pressure, touch,
and pain and is located in the middle part of the brain. The somatosensory cortex,
a part of the brain responsible for the processing of the body’s senses, is located in

1022
M. Pitale et al.
Fig. 13 Brain dominance
this lobe. It is in charge of movement distinction, physical movements, knowledge
of operations, and bodily mobility.

Prediction of Inborn Talents Using Fingerprint Analysis
1023
Fig. 14 Comparative analysis
The Temporal Lobe
It is found in the lower part of the brain. The primary auditory cortex, which is
responsible for comprehending sounds and language, is also located in this lobe.
For veriﬁcation part of the results generated, in the report of our application, we
have compared the outputs with the report generated by the Institute of Educational
Counseling and NLP—a unit of Guru Foundation—and the accuracy was 60%. The
novel part of our report is that we are generating a pattern dominant oriented report,
which makes it easy to understand and focus on that speciﬁc abilities.
Figure 14 compares the results generated through this system with the results
obtained from an actual DMIT software, with the help of professional assistance.
It has been observed that the outcomes from the proposed system are nearly equal.
Hence, with the guidance of the consultant, the results are examined.
6
Conclusion
By judging every aspect of the results, we concluded that the ﬁngerprint data which
we gathered had been subjected to a wide array of processing and pruning to satisfy
our goal of calculating ridge count. We contacted a psychologist who has been in the
ﬁeld for the last 15 years who explained in detail how the DMIT software functions
and what our main goal should be when trying to build the system. The psychologist
guided us regarding how to understand the various links between the personality traits
and patterns on the ﬁngerprint. Although the main question was still unanswered,
how do we connect the two? For the same, the psychologist helped us obtain the

1024
M. Pitale et al.
contact details of a DMIT expert. The expert helped us in getting a valid dataset and
premade reports to test our results, also explained in detail the entire mechanism of
the DMIT software.
We used a convolution neural network (CNN) model at the backend which predicts
the ﬁngerprint pattern. The CNN model efﬁciently predicts the pattern as an output
with a minimal error of 20 percent. The pre-processed images are used to calculate the
ridge count which has been performed manually since the origin of the technology.
Our application can predict a report within seconds against the DMIT software which
takes weeks. The user has to go to the nearest DMIT center to submit or give his/her
ﬁngerprints our application can be used at home by uploading ten clear scans of the
ﬁngers. DMIT is not a piece of common knowledge as of now, but our application
makes it easy to use and understand in depth the functionality of your brain which
would help this technology gain marketability.
The goal of our project, to help the knowledge of multiple intelligence become
universal and easily accessible, is achieved.
Acknowledgements We would like to thank Mr. Deepak Joshi, the founder of In True Talent
Services, for his invaluable assistance in providing us with the dataset and helping us in the classi-
ﬁcation of data. Also, we would like to thank Mrs. Swati Parab, a therapist, and a senior counselor,
for providing all the information related to DMIT. We would like to express our gratitude to Prof.
Ujwala Ravale for her invaluable guidance and our institute, SIES Graduate School of Technology,
and its patrons for their indirect and direct support.
References
1. Sharma, A., Sood, V., Singh, P., & Sharma, A. (2018). Dermatoglyphics: A review on
ﬁngerprints and their changing trends of use. CHRISMED Journal of Health and Research.
2. Milshtein, S, Pillai, A., Shendye, A., Liessner, C., & Baier, M. (2008). Fingerprint recogni-
tion algorithms for partial and full ﬁngerprints. In 2008 IEEE conference on technologies for
homeland security.
3. Agarwal, K. K., Saxena, A., Dutt, H. K., Dimri, D., Singj, D., & Bhatt, N. (2012, January).
General assumption of psychological behaviour based on ﬁngerprint pattern. Journal of Biology
and Life Science, 3(1). ISSN 2157-6076.
4. Dholiya, K., & Dholiya, A. (2017, April). Dermatoglyphic multiple intelligence Test.
International Journal of Memory and Intelligence, 1(1).
5. Gupta, V. P., & Shah, A. H. (2019). A study on ﬁngerprint patterns and blood groups in relation
to personality—A report from Nepal. Acta Scientiﬁc Medical Sciences 3(6).
6. Nguyen, H. T., & Nguyen, L. T. (2019, November). Fingerprint classiﬁcation through image
analysis and machine learning method. Algorithms 2019, 12, 241. https://doi.org/10.3390/a12
110241.
7. Srivastava, A. P., Awasthi, S., Kaushik, A. K., & Shukla, S. (2019). Fingerprint recognition
system using MATLAB. In 2019 International conference on automation, computational and
technology management (ICACTM) (pp. 213–216).
8. Shehu, Y. I., Ruiz-Garcia, A., Palade, V., & James, A. (2018, July). Sokoto coventry ﬁngerprint
dataset. ResearchGate.
9. Zhou, L., Li, Q., Huo, G., & Zhou, Y. (2017, February). Image classiﬁcation using biomimetic
pattern recognition with convolutional neural networks features. Computational Intelligence
and Neuroscience, 2017, Article ID 3792805.

Prediction of Inborn Talents Using Fingerprint Analysis
1025
10. Vaikole, S., Sawarkar, S. D., Hivrale, S., & Sharma, T. (2009, March). Minutiae feature extrac-
tion from ﬁngerprint images. In IEEE international advance computing conference (IACC
2009). Patiala.
11. Fingerprint Algorithm Recognition. https://medium.com/%40cuevas1208/ﬁngerprint-algori
thm-recognition-fd2ac0c6f5fc.
12. Zhou, J., Chen, F., & Gu, J. (2009, July). A novel algorithm for detecting singular points from
ﬁngerprint images. IEEE Transactions on Pattern Analysis and Machine Intelligence, 31(7).
13. Seo, J., Chae, S., Shim, J., Kim, D., Cheong, C., & Han, T.-D. (2016). Fast contour-tracing
algorithm based on a pixel-following method for image sensors. Sensors 2016.
14. Sing, M., & Majumdar, O. (2015, April–Septermber). Dermatoglyphics: Blueprints of human
cognition on ﬁngerprints. IJCSC, 6(2), 124–146.

Author Index
A
Abdulkader, Beema, 555
Abedin, Mohammad Zoynul, 411, 653
Achish, D., 357
Adinarayna, S., 475, 933
Advait, N., 319
Akshaya, A. V., 501
Alagirisamy, Mukil, 369
Ali, Md Rasid, 665
Alisha, Antony, 851
Aloysius, Athern, 209
Amaldev, C. V, 851
Ang, Chun Kit, 209
Anitha, R., 757
Annie, R. Arockia Xavier, 423
Aramugam, Kalaiselvi, 209
Arora, Himanshu, 1003
Asemie, Smegnew, 177
Asesh, Aishwarya, 31
Ashesh, K., 199, 357
Aysha Dilna, D. A, 851
Ayyappan, Manoj, 303
Azezew, Kassahun, 177
B
Babaria, Disha, 527
Bacanin, Nebojsa, 863
Bala, Shatabdee, 411
Banerjee, Arnob, 527
Banjarey, Khushboo, 691
Bhargav, D. Lohith, 357
Bhegade, Nikita, 799
Bisen, Gokul, 223
Bondre, Vipin, 577
C
Chaitra, B. M, 779
Chalke, Snehal, 347
Champa, H. N., 15
Chandra, Sumesha, 275
Chaudhari, Chetana C., 949
Chaudhary, Vinayak, 275
Chavan, Vaishnavi, 799
Chhabra, Amit, 863
Cyriac, Meril, 501
D
Dahiya, Yash, 275
Danti, Ajit, 779
Das, Bhaskarjyoti, 113
Das, Sweta, 1
Deeba Lakshmi, G. R., 185
Deisy, 209
Desai, Sanjana, 879
Deshpande, Abhishek, 223
Devi, R., 757
Devi, S. V. Gayetri, 487
Dewangan, Deepak Kumar, 691
Dhamanskar, Prajakta, 155
Dikkala, Udayini, 369
Dileep, M. R, 779
Dixit, Shatakshi, 577
Doshi, Sakshi, 625
Dsa, Adriel, 983
E
Egorov, D. P., 993
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Singapore Pte Ltd. 2022
S. Shakya et al. (eds.), Sentimental Analysis and Deep Learning, Advances in Intelligent
Systems and Computing 1408, https://doi.org/10.1007/978-981-16-5157-1
1027

1028
Author Index
F
Farooq, Syed Abu, 591
G
Gajera, Krishna, 347
Ganesan, Sowmya, 347
Ganesh, E. N., 829
Gangadhar, N., 237
Gaonkar, Gurudatt, 303
Garg, Anukriti, 703
Geetha, T. V., 423
George, Priya, 555
Ghaskadvi, Meera, 155
Ghongade, Aditya, 983
Ghorpade, Kalpana, 141
Gireesh, R., 129
Gonsalves, Rozebud, 155
Gowrishankar, S., 1
Guhagarkar, Neeraj, 879
Gupta, Aashuli, 527
Gupta, Saumya Raj, 893
H
Harikrishna, J., 129
Harisudha, K., 829
Himanshu, 47
Hossain, Elias, 79
Hrithik Devaiah, B. A., 319
I
Indu, S., 703
Ingle, Y. S., 625
Islam, Muhammad Nazrul, 383
J
Jacob, Teslin, 255
Jadala, Vijaya Chandra, 475, 933
Jadhav, Advet, 451
Jagadeeswari, M., 813
Jain, Prashuk, 47
Jakka, Aishwarya, 907
Jalal Uddin Joy, Abu Zahid Md., 79
Jayanthi, N., 703
Jebamani, B. Jency A., 291
Jha, Pradeep, 1003
Joseph, Richard, 303
Juj, Tejsvi, 703
K
Kale, Riya, 1009
Kaleem, Mohammed Khalid, 177
Kalshetty, Jagadevi N., 319
Kalyan, N. Pavan, 357
Kanase, Sayali, 799
Kanuru, Hamsini, 907
Kashetwar, Shreyas, 799
Kendhe, Shreya, 625
Khamkar, Manasi, 1009
Khan, Md. Nasﬁkur R., 411, 653
Khan, M. K. A. Ahamed, 209
Khaparde, Arti, 141
Khochare, Sakshi, 155
Kiranmayee, B. V., 439
Koshy, Ken, 319
Kravchenko, V., 993
Kumar, A. Arun, 397
Kumar, J. Ravin, 813
Kumar, S. Pradeep, 719
Kuriakose, Thomas, 769
L
Latha, N., 539
Limkar, Aditi, 625
Lim, Wei Hong, 209
Loka, Omkar, 735
Lokhande, Parth, 983
Lotlikar, Kunal, 527
M
Madeira, Malcolm Andrew, 255
Mahamuni, Nachiket, 735
Malathi, M., 539
Manda, Sridhar, 397
Mangipudi, Reshma Sri Sai, 615
Manikandababu, C. S., 813
Manjunath, K. G., 959
Mehra, Monika, 1003
Menaka, S., 465
Mittal, Ritvik, 47
Mizanur Rahman, Md., 79
Mohamed, E. Syed, 637
Mosiganti, Kezia Joseph, 369
Mothukuri, Radha, 475
Muhaimenur Rahman, Md., 59
Muley, Pradnya Abhay, 973
Munot, Harsh, 983
Murugeswari, R., 291, 719
N
Nadim Kaysar, Md., 79
Nadi, Shantunu Shakhwat, 653

Author Index
1029
Nagaraj, P., 291, 719
Nagaraj, Prajna, 113
Nagpal, Aashish, 303
Nalini, N., 397
Nalini, T., 487
Nascimento-Silva, Hieda A., 97
Navaneeth, A. V, 779
Neelagar, Mahesh B., 237
Nene, Manisha J., 69
Nikam, Hrishikesh, 735
Nivash, S., 829
P
Pardhi, Jatin, 223
Parihar, Anil Singh, 47
Parvin, Nargis, 565
Patil, Nita, 347
Patil, Pramod D., 799, 983
Patil, Rachana, 735
Patil, Rahul A., 799, 949, 983
Pattewar, Gaurav, 735
Paul, Ajil, 555
Pawar, Surabhi, 577
Pitale, Maitreyi, 1009
Poongothai, L., 757
Prabhu, T. S. Murugesh, 625
Pranitha, J., 615
Prathyusha, Munjuluri, 199
Preethi, S., 813
Priyadarshini, B. Indira, 615
Priyanka, R., 813
Q
Qayyum, Abdul, 209
R
Raﬁ, Mohamed, 959
Rahman, Md. Mahbubar, 383
Rahman, Md. Saifur, 565
Rahul, 185
Rai, Utkarsh, 451
Rajeswari, Malisetty, 199
Raj, S. N. Vivek, 603
Raju, Channa Krishna, 959
Raju, S. Hrushikesava, 475, 933
Rakshith, K., 319
Ramaswamy, Manicam, 209
Rani, J. Vakula, 907
Rao, G. Subba, 475, 933
Raut, Hema, 527
Ravale, Ujwala, 1009
Rayer, S. Prithiviraj Pallava, 603
Regina, M. Yasmin, 637
Rekha, K. Sashi, 465
Reshim, Pooja, 347
Resmi, N. G, 851
Rithika, V., 813
Roy Chowdhury, Dipanwita, 665
Roy, Sourabh Ranjan, 893
Rupa, Ch., 129
S
Sabu, Amal, 555
Saha, Anik Kumar, 59
Sahu, Indra Kumar, 69
Sahu, Satya Prakash, 691
Salb, Mohamed, 863
Saranya, M., 423
Saraswathi, H. S., 959
Satpute, Maheshwari, 451
Save, Ashwini, 879
Sethi, Manoj, 275
Shaﬁ, M. Naveed, 893
Shaikh, N. F., 625
Shakir, Asif Khan, 653
Shakya, Subarna, 789
Shakya, Sushil, 789
Shanmugam, Selvanayaki Kolandapalayam,
591
Shanthi, C., 757
Sharma, Ankit, 69
Sharmila, K., 757
Shetty, Tanvi, 303
Shilpa, K. C., 237
Shukla, Anshika, 185
Shwetha, N., 237
Sijin, P., 15
Singh, Himalaya, 1003
Snekhalatha, U., 893
Sreedevi, Sneha, 555
Sreenu, G, 851
Sreeraj, Amrutha, 769
Sreeraj, Ayswarya, 769
SreeRakshak, S., 439
Sreeram, S., 829
Sridevi, 209
Srujana, Padmanabhuni, 199
Strumberger, Ivana, 863
Subin, Sebastian, 851
Sunil, M. E., 677
Surendra, Usha, 539
Suresh, Chalumuru, 439
Swamy, T. M. Veeragangadhara, 515

1030
Author Index
T
Tale, Trupti, 577
Taranath, Poornima, 1
Thakur, Mahima, 893
Thomas, Jency, 769
Thoolkar, Shefali, 577
Tiwari, Laghima, 703
Tolstoukhov, D. E., 993
Truong, Anh, 331
V
Vaishampayan, Swanand, 879
Vani, N., 515
Varghese, Megha Mary, 769
Varsha, G. Sai, 615
Verina, Y. V., 993
Verma, Amit, 745, 917
Verma, Khushboo, 1003
Verma, Usha, 451
Vinay, S., 677
Vineetha, S., 893
Vinueza-Naranjo, Angel F., 97
Vinueza-Naranjo, Paola G., 97
Vrindavanam, Jayavrinda, 185
W
Wadibhasme, Apeksha, 451
Wahidur Rahman, 79
Waris, Saiyed Faiayaz, 475, 933
Y
Yashwanth, G., 357
Yasmeen, Syed, 199
Yendargaye, Girishchandra R., 625
Yesmin, Sarmila, 411
Z
Zivkovic, Miodrag, 863

