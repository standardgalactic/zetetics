The OpenNARS implementation of the
Non-Axiomatic Reasoning System
Patrick Hammer1, Tony Lofthouse2, Pei Wang3
1 Institute for Software Technology
Graz University of Technology, Inﬀeldgasse 16b/II, Austria,
patrickhammer9@hotmail.com
2 Evolving Solutions Ltd, Newbury, UK, Tony.Lofthouse@GMILab.com
3 Department of Computer and Information Sciences
Temple University, Philadelphia PA 19122, USA, pei.wang@temple.edu
Abstract. This paper describes the implementation of a Non-Axiomatic
Reasoning System (NARS), a uniﬁed AGI system which works under the
assumption of insuﬃcient knowledge and resources (AIKR). The system’s
architecture, memory structure, inference engine, and control mechanism
are described in detail.
1
Introduction
NARS is an adaptive system that works under the Assumption of Insuﬃcient
Knowledge and Resources (AIKR) [8, 6], meaning the system has to work under
the restrictions of being: Finite: the information processing capability of the
system’s hardware is ﬁxed, Real-time: all tasks have time constraints attached
to them and Open: no constraint is put on the content of the experience that
the system may have, as long as it’s expressible in the interface language [8].
Built in the framework of a reasoning system, NARS has a memory, a logic
component and a control component. The logic component consists of inference
rules that work on statements, where the statements are goals, questions and
beliefs. A statement can be eternal (non time-dependent) or an event (time-
dependent). Beliefs are statements that the system believes to be true to a certain
degree and goals are statements the system desires to be true to a certain extent.
An inference task is a statement to be processed, with additional control relevant
information.
NARS utilises the Non-Axiomatic Logic (NAL) [9] for inference and the Nars-
ese language for representing statements. The language and the logic are outside
the scope of this document. The aim of this paper is to describe the current
implementation of NARS in detail. The following aspects of the implementa-
tion are focused on: memory management with concept centric processing, non-
deterministic selection capabilities allowing anytime-processing of tasks, resource
constraint management, a logic system with meta rule DSL and Trie based exe-
cution engine, temporal inference control (including temporal windows, temporal
chaining, and interval handling), projection and eternalization, anticipation, and
attentional control via a budget based approach.

2
2
Memory
This section describes the architecture of the memory module, how NAL gram-
mar statements form a ‘Belief Network’ and the interdependence of the budget.
The memory module supports three primary operations: ﬁrstly, to return the
best ranked belief or goal for inference within concepts (local inference), secondly,
to provide a pair of contextually relevant and semantically related statements
for inference between concepts (general inference), and ﬁnally, to add statements
to memory whilst maintaining the space constraints on the system.
concept1
concept3
termlink
concept2
tasklink
tasklink
beliefs
tasklinks
termlinks
beliefs
tasklinks
termlinks
beliefs
tasklinks
termlinks
desires
desires
desires
Memory
Inference
Buffer
Input
select task
select belief
derive
process
The working process of NARS can be considered as unbounded repetitions of an
inference cycle that consists of the following sequence of steps [9]:
1. get a concept from memory
2. get a task and belief related to the selected concept
3. derive new tasks from the selected task and belief and put them into buﬀer
4. put the involved items back into the corresponding bags
5. put the new tasks into the corresponding bags after processing from buﬀer
NARS utilises elements of metadata (Budget and Stamp) that serve several
purposes: they prevent certain forms of invalid inference such as double counting
evidence and cyclic reasoning, abstract temporal requirements away from the
Narsese grammar, and provide certain implementation eﬃciencies.
Budget, considered as metadata for the purpose of this paper, determines
the allocation of system resources (time and space) and is deﬁned as (p, d, q) ∈
[0, 1] × (0, 1) × [0, 1].
Also, each statement in NARS has a Stamp deﬁned as (id, tcr, toc, C, E) ∈
N×N×N×P(N) where id represents a unique ID, tcr a creation time (in inference
cycles), toc an occurrence time (in inference cycles), C a syntactic complexity
(the number of subterms in the associated term) and E an evidential set.
Curve Bag is a data structure that supports a probabilistic selection according
to the item priority distribution. The priority value p of the items in the bag

3
maps to their access frequency by a predeﬁned monotonically increasing function.
This data structure is called “Curve Bag” since it allows us to deﬁne a custom
curve which is highly ﬂexible and allows emotional parameters and introspective
operators to have inﬂuence on this selection. The remaining factors of Budget,
the d durability and q quality parameter, get their meaning from the forgetting
function: Whenever an item is selected from the bag, its priority will be decreased
according to d and q, namely with qr = q ∗r, dp = p −qr (r being a system
parameter) the new priority is then: p′ = qr+p∗d
1
H∗p if dp > 0, otherwise p′ = qr,
where H is a forgetting rate system parameter. This ensures that forgetting does
not cause priority to decrease below quality, after re-scaling by r.
The memory consists of a Curve Bag of Concepts, where Concepts are con-
tainers for: Tasklink and Termlink Curve Bags, along with belief and goal tables.
The belief and goal tables are ranked tables (Section 8, sub-section Ranking).
A concept, named by a term, combines the beliefs and goals with this term
in it, and is connected to other concepts which share a common sub-term or
super-term via Termlinks.
3
Logic Module
The logic module is an instantiation of the Non-Axiomatic Logic (NAL). It is
composed of two components: an inference rule domain speciﬁc language (Meta
Rule DSL) and an inference rule execution unit. The meta rule DSL should
not be confused with the NAL grammar rules, these are separate and distinct.
The system currently implements 200+ inference rules, containing forward and
backward rules for reasoning under uncertainty.
Meta Rule DSL The meta Rule DSL was developed to serve three main pur-
poses: to provide a ﬂexible methodology to quickly experiment with alternate
inference rules, to support the goal of creating a literate program, and to sub-
stantially improve the quality of the software implementation.
Inference rules take the following form:
T, B, P1, ..., Pk ⊢(C1, ..., Cn)
where T represents the ﬁrst premise (precondition, corresponding to the task
to be processed), B represents the second premise (precondition, correspond-
ing to the belief retrieved for the task), and P1, ..., Pk are additional precon-
ditions which represent logical predicates dependent on T, B, C1, ..., Cn. Each
“conclusion” (or postcondition) Ci of C1, .., Cn has the form (Di, Mi) where Di
represents the term of the derived task the conclusion Ci deﬁnes, and Mi pro-
vides additional meta-information, such as which truth function will be used
to decide the truth or desire of the conclusion, how the temporal information
will be processed, or whether backwards inference is allowed. The DSL incor-
porates the Narsese grammar to retain consistency of syntax and conciseness of
representation.
Inference Rule Execution The role of the inference Rule Execution unit is
twofold: ﬁrstly, to parse the Meta Rule DSL into an eﬃcient and executable

4
representation, and secondly, to select and execute the relevant inference rules.
An optimised Trie is used to store the rule representation, whilst a Trie Deriver
is used to select and ‘execute’ the relevant inference rules.
Trie Representation - In the Meta Rule DSL, each inference rule has a set of
preconditions. These preconditions are stored as nodes in the Trie, where com-
mon preconditions form a common node (as with the Rete algorithm [3]). This
leads to a natural structuring of the conditions where non-leaf nodes store the
preconditions and leaf nodes form sets of post conditions that represent valid
derivations for a pair of input statements.
Trie Deriver - The deriver is responsible for inference: it matches from mem-
ory selected premise pairs to the relevant inference rules such that conclusions
can be obtained. The matching of rules to statements is simply a matter of
traversing the Trie, keyed on the matching preconditions. If the traversal ends
at a leaf node then this is a valid matching inference rule(s), leaf nodes can
contain more then one inference rule. Each traversal, if valid, returns a list of
postconditions/conclusions of the matched rules.
Since the complexity of statements is bounded due to AIKR, and the depth
of this trie is bounded by the ﬁniteness of the inference rules, applying the Trie
Deriver to a pair of statements is upper bounded in execution time by a constant.
This is an important consideration as NARS needs to respond to tasks in real-
time, whereby, no single inference step can exceed a roughly constant time.
4
Temporal Inference Control
An adaptive agent existing in a real-time environment needs to be capable of
reasoning about time. To support reasoning with time the non-temporal NAL
inference rules are extended by adding temporal variants. Temporal inference
is distinguished by several features: utilisation of a Temporal Window, Tempo-
ral Chaining, and Interval Handling, along with Projection, Eternalization and
Anticipation, discussed in the following sections.
Temporal Window - As argued in [2], human beings have the ability to syn-
chronize multiple stimulus events, when they are experienced within a Temporal
Window of roughly 80ms, as if they were experienced concurrently. These so
called subjective events behave like a point in time as well as an interval in time
[7]. A similar approach is used in NARS where a DURATION parameter de-
ﬁnes the temporal window of synchronization, whereby, events occurring within
the Temporal Window will be deemed to have occurred concurrently.
Temporal Chaining - Due to the AIKR, NARS does not allow arbitrary tempo-
ral relations to be formed, in fact the inference execution unit will only allow
semantically related statements (those which correspond to concepts which are
connected with each other via termlinks) to be used in derivations. This leads
to the question of, how do we temporally relate semantically unrelated events?
The approach taken in NARS is to perform inference between each incoming
event with the previous incoming event in order to create compound events

5
which link the (previously semantically unrelated) events together. Although
perception can form more complex temporal compound events than this, the
same principle applies.
These compound events can then be used by the inference system with other
semantically related statements to form further derivations. In this way, complex
chains of temporal reasoning can be formed as also demanded for perception.
Interval Handling - When an event a (for example, “wheel starts turning”) enters
the system, its occurrence time is recorded, but its duration is not known at this
time. Even without a duration, the event a can still be related to previous events
as the occurrence time is available.
If eventually an event b (for example, “wheel stops turning”) enters the sys-
tem, the system can derive an event (a, I, b) which has a custom duration and
encodes “the wheel was turning from this time to this time”, which behaves es-
sentially as an interval in interval algebra as a special case. However this interval
number I raises another question: To what extent does the duration of an event,
i.e. the interval number I, aﬀect how the statement should be observed? We took
the approach, to assume similar scales, based on the scale of the interval, would
be considered as similar observations. For example the interval of 1 second and
1.2 seconds will be observed as the same, similarly with 1 hour and 1.2 hours. If
there is need for a further distinction, a clock operator can provide the system
with additional context.
The Duration time window provides a tolerance that allows the system to
observe re-occurring patterns in time, coming from asynchronous input channels,
which would otherwise be seen as diﬀerent if the speciﬁc events are incoming in
a diﬀerent order, albeit, in millisecond scale.
5
Projection and Eternalization
When two semantically related statements are selected for inference, (if not
stated otherwise by the speciﬁc rule) it is necessary to map the occurrence time of
the belief to the occurrence time of the task, using the current time as reference.
This mapping function is called “projection” and describes how the truth
value of a statement decreases when projected to another occurrence time. In
this operation, the conﬁdence of the belief is decreased by a factor
kc =
|tB −tT |
|tB −tC| + |tT −tC|
where tB is the original occurrence time of the belief, tT the occurrence time it
is projected to, and tC the current time. The new conﬁdence of the belief is then
cnew = (1 −kc) ∗cold
Eternalization is a special form of induction, where the occurrence time is
dropped, so the conclusion is about the general situation. The eternalized con-
ﬁdence value is obtained with
ceternal =
1
k + ctemporal

6
where k is a global evidential horizon personality parameter [9].
In inference, whenever an event is derived, the eternalized version is also
derived. However the existence of eternal statements presents a problem: How
to justify inference between two premises, about diﬀerent times? In order to deal
with this scenario, there are two possible routes: the inference rule is a temporal
rule which measures the time between the premises, and takes it into account
when its conclusion is built, or, one of the following cases applies:
1. Premise1 is eternal, and premise2 is temporal. Here, premise2 is eternalized
before applying inference.
2. Premise1 is temporal, and premise2 is eternal. Since premise2 is eternal, it
also holds at the occurrence time of premise1, so inference can occur directly.
3. Premise1 is temporal, premise2 is temporal. In this case premise2 is pro-
jected to the occurrence time of premise1, and also eternalized. Inference
now happens between premise1 and the stronger in conﬁdence outcome,
either the result of the projection or the result of eternalization.
4. Both are eternal, in which case the derivation can happen directly.
In all the cases, the occurrence time of the ﬁrst premise (usually the task), is
assigned to the occurrence time of the derived task, and possibly a statement-
dependent time-shift as speciﬁed by some temporal inference rules, dependent
on the term encoded intervals, which measure time between events, is applied.
6
Anticipation
In NARS predictive statements usually take the form:
antecedent ⇒consequent
where observing antecedent leads to the derived event consequent, on which the
system can form an expectation on whether it will be observed as predicted, this
is called Anticipation. With Anticipation the system is able to ﬁnd negative evi-
dence for previously learned predictive beliefs which generate wrong predictions.
[6, 10]
If the event happens, in the sense that a new input event with the same term
as the anticipated event is observed, the anticipation was successful (conﬁrma-
tion), in which case nothing special needs to be done, since the statement will
be conﬁrmed via the normal process of temporal induction.
If the predicted event does not happen then the system needs to recognise
this. This is achieved by introducing a negative input event, not(a). Note that in
this case, such a negative input event has high budget and signiﬁcantly inﬂuences
the attention of the system.
Anticipation introduces three challenges: ﬁrstly, how to ensure that the sys-
tem doesn’t conﬁrm its own predictions? secondly, how to ensure that the system
only anticipates events which are observable and hence overcome the issue that

7
negative events are generated for events which are not observable? and thirdly,
how to deal with occurrence time tolerance as well as tolerance in truth value.
The ﬁrst is handled by letting only input events (not derived events) conﬁrm
a prediction. The second shows that the closed-world-assumption (CWA) is not
applicable in general, just because something isn’t observed doesn’t mean it
didn’t happen in general. This issue is overcome by letting only those predictions,
which correspond to observable concepts, generate anticipations. When a new
input event enters the system, the corresponding concept is marked observable,
in this way the observability of concepts is tracked. Regarding the third issue,
currently the system assumes that the event does not happen if it doesn’t occur
within time [toc −|toc−tcur|
u
, toc + |toc−tcur|
u
] where toc is the occurrence time of
the anticipated event, and tcur is the current time, with u usually being set to
2. To allow tolerance in truth, anticipation as well as the conﬁrmation currently
uses tasks with frequency greater than a threshold, by default 0.5, this tolerance
handling method may be reﬁned in the future and is still in discussion. Also
note that by this treatment, conceptual events like “Our team wins the football
match” have to be decomposed down to directly observable events by inference.
Whether and how this can be improved, is also still in discussion.
7
Evidence Tracking
One of the most important notions in NARS is the idea of evidence, note that
the truth value of a statement is essentially a (w+, w−) pair, where w+ repre-
sents positive evidence, and w−represents negative evidence, or alternatively
as conﬁdence c and frequency f tuple, where f =
w+
w++w−and conﬁdence is
c =
w++w−
k+w++w−, where k is a global personality parameter that indicates a global
evidential horizon. For full details on truth value derivations see [9]. Evidence in
NARS follows these principles:
1. Evidence can only be used once for each statement.
2. A record of evidence used in each derivation must be maintained, although
given AIKR (as also assumed in [6]), this is only a partial record, which is
not an issue in practice.
3. There can be positive and negative evidence for the same statement.
4. Evidence is not only the key factor to determine truth, but also the key to
judge the independence of the premises in a step of inference.
As described previously, each statement has a stamp which contains an ev-
idence set, E. Following each derivation, a new E is created, by interleaving
the two evidence sets of the premises, which is then truncated to a maximum
length by removing the oldest evidence. Interleaving the evidence sets is impor-
tant and ensures an even distribution of evidence from both evidence sets. The
evidence set, E, initially contains the unique statement id from the stamp. Prior
to derivation, evidence sets of the involved premises are checked for intersection,
if they intersect then there is overlapping evidence between the premises and no
derivation is allowed (as this would double count evidence).

8
8
Processing of New and Derived Tasks
This step consists of processing new inputs and derivations selected from the
buﬀer Curve Bag, by applying temporal chaining for new input events followed
by ranking based selection for local inference. Here the Revision Rule is applied
to belief and goal tasks, and the Choice Rule is applied to question and goal
tasks. Additionally the Decision Rule is applied to a goal task [9].
Temporal Chaining - As discussed in Anticipation, it is important to distin-
guish between new inputs and derivations, because only new input events invoke
Temporal Chaining. When a new input event enters the system, inference is
automatically triggered with the previous new input event [10], generating a
temporal derivation (Section 4, sub-section Temporal Chaining).
Ranking - Belief and Goal tables are ordered according to a ranking function,
where the conﬁdence is determined after projecting each new belief or goal, to
the target time. When the ranking is done for selective questions [9], the function
is e/C where e is the expectation value of the statement and C its complexity.
In all other cases the conﬁdence of the statement is used for ranking.
Adding to Belief/Desire Table - Once the ranking of a new belief or goal is
determined, this ranking speciﬁes the position of the entry in the table. If the
table is full, then the lowest ranked entry is deleted to maintain the maximum
capacity limit.
Selecting Belief for Inference - When a belief from the belief table is taken out
after the selection of the task for inference (Section 9, sub-section Phase 2), it
is done so by ranking all entries in the belief table according to the occurrence
time of the task. The best entry is selected for inference. This also holds for local
inference, where a new incoming belief task selects the best candidate to revise
with. The new belief and the revised one are then added as described in the
previous section. If the task is a question or goal, the new belief overwrites its
best solution, dependent on whether it is higher ranked according to the ranking
function as described in Ranking.
Revision - When a belief or goal task is processed (selected as task in an inference
cycle), it is projected to the current time. Now the highest ranked entry in the
belief / goal table in respect to the current moment is determined. When the
task is able to revise with this one, this is done and we are ﬁnished. If the task
is a goal, the Decision rule is also applied:
Decision - If the goal task is an operation (which is an event the system can
trigger itself) the desire value expectation, measured with expectation(x) =
(c ∗(f −1
2) + 1
2) (with f being the frequency, c the conﬁdence) of the highest
ranked desire is determined and if it exceeds a certain threshold, the system
executes this operation. After the execution, an event, stating that this operation
was executed, is input into the system. This event is then available for use in
temporal chaining supporting learning about the consequences of the systems
own operations in diﬀerent contexts.

9
9
Attentional Control
The attentional control stage is primarily concerned with managing the Atten-
tional Focus of NARS. This is achieved with a three phase process of: selecting
contextually relevant and semantically related tasks for inference, creating or up-
dating budget values based on user requirements and/or inference results, and
ﬁnally, updating memory with the results of the updated task and concepts.
Phase 1: Premises for inference are selected according to the following scheme:
1. Select a concept from memory (according to Curve Bag semantics).
2. Select a tasklink (with related task) from this concept.
3. Select a termlink from this concept
4. Select a belief from the concept the termlink points to, ranked by the task.
Phase 2: This phase forms new statements (tasks), with new metadata, from
the derivations. The task linked by the tasklink used in inference determines the
statement type and the occurrence time of the new task (unless the inference
rule states otherwise, which may also shift the occurrence time). The Budget of
a new task is deﬁned as (where T is the truth value of the new task and h ∈[0, 1]
is a personality parameter giving high quality to tasks of high frequency):
priority:
or(priority(tasklink), priority(termlink))
durability:
durability(tasklink) ∗durability(termlink) ∗1
C
quality:
max(expectation(T), (1 −expectation(T)) ∗h) ∗1
C
where, for quality, 1
C is applied for backward inference, and or(a, b) = 1−((1−
a)∗(1−b)) [1]. This budget is also used for the tasklink created for the new task.
Next the termlinks are strengthened by the derivation. Here Hebb’s rule is used:
priority(termlink)′ = or(priority(termlink), or(quality, and(a, b))) where a is
the concept priority referred by the tasklink, and b is the concept priority referred
by the termlink. Additionally, the durability of the termlink is also increased:
durability(termlink)′ = or(durability(termlink), quality).
Phase 3: Select new tasks from the buﬀer Curve Bag, process them, and insert
them into memory:
1. If Concept CT does not exist, where T is the task, create it and any other re-
quired concepts to match the sub-terms of the task, along with the necessary
termlinks.
Finally, the concept, containing T, is activated by adding the priority of the
task to the concept priority, and using the maximum of the task and concept
duration as the new concept duration as well as the maximum of derived task
and concept quality as the new concept quality. In this way concepts activate
each other context-sensitively and in a directed manner.
2. Construct a tasklink with the budget of T for this task and add it to CT
(note that the task will additionally also be linked from an in inference by
the termlink selected subterm concept).
3. Add the task to its statement type related table in CT .
4. Insert CT , and sub-term concepts, if any, into the concept bag (memory).

10
10
Conclusions
The current OpenNARS implementation, described by this document, follows a
uniﬁed principle of cognition whereby reasoning is carried out within an inference
cycle.
To our knowledge, OpenNARS is the only implementation of an AGI system
that captures perception, reasoning, prediction, planning and decision making
with a single uniﬁed principle. In particular we believe the handling of temporal
inference, as described in this paper, is a new approach and demonstrates many of
the aspects required for an agent to learn and act within a real-time environment.
Although it is diﬃcult for this implementation to be compared to other sys-
tems, there are certain aspects that make NARS similar to some other AGI
projects, such as AERA [6], OpenCog[4] and SOAR[5], though detailed compar-
ison with them is beyond the scope of this paper.
OpenNARS continues to be a research platform with diﬀerent aspects of
the design at varying levels of maturity. The logic prior to the introduction
of temporal logic is considered stable. Temporal logic, introspection and the
budget updating functions are work in progress and are not considered optimal at
this stage. Perception, introspective mental operators and emotional attentional
control are the focus for the next phase of our research. The attentional control
is not currently suﬃcient to handle a high bandwidth perception stream.
The current implementation, OpenNARS v1.7.0, is available for download at:
http://opennars.github.io/opennars. The download package contains examples
of learning by experience, and demonstrations of the aforementioned cognitive
functions as well as practical use cases for the system.
References
1. Bonissone P., Summarizing and propogating uncertain information with triangular
norms, International Journal of Approximate Reasoning(1987):1:71-101
2. Eagleman D. M. and Sejnowski T. J., Motion Integration and Postdiction in Visual
Awareness, Science287(2000):20368).
3. Forgy Charles L. Rete: A Fast Algorithm for the Many Pattern/Many Object
Match Problem, Artiﬁcial Intelligence, (19)1, Sept. 1982, pp. 17-37.
4. Goertzel B., Pennachin C., Geisweiller N., Engineering General Intelligence, Part
1 and 2, Springer, (2014)
5. Laird J., The Soar Cognitive Architecture, MIT Press, (2012)
6. Nivel E., Thrisson K. R., Dindo H., Pezzulo G., Rodriguez M., Corbato C., Ste-
unebrink B., Ognibene D., Chella A., Schmidhuber J., Sanz R., Helgason H. P.,
Autocatalytic Endogenous Reﬂective Architecture (2013)
7. P¨oppel E., Yan Bao, Temporal Windows as a Bridge from Objective to Subjective
Time, The Philosophy, Psychology, and Neuroscience of Temporality, The MIT
Press
8. Wang P.: Rigid Flexibility - The Logic of Intelligence, Springer (2006)
9. Wang P.: Non-Axiomatic Logic: A Model of Intelligent Reasoning, World Scientiﬁc,
Singapore (2013)
10. Wang P., Hammer P.: Issues in Temporal and Causal Inference, AGI 2015 Confer-
ence Proceedings, Springer (2015)

