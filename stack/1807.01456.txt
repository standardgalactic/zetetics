arXiv:1807.01456v2  [cs.SC]  20 Sep 2018
A Purely Functional Computer Algebra System
Embedded in Haskell
Hiromi Ishii
Doctoral Program in Mathematics,
University of Tsukuba, Tsukuba, Ibaraki 305-8571, Japan
h-ishii@math.tsukuba.ac.jp
Abstract. We demonstrate how methods in Functional Programming
can be used to implement a computer algebra system. As a proof-of-
concept, we present the computational-algebra package. It is a com-
puter algebra system implemented as an embedded domain-speciﬁc lan-
guage in Haskell, a purely functional programming language. Utilising
methods in functional programming and prominent features of Haskell,
this library achieves safety, composability, and correctness at the same
time. To demonstrate the advantages of our approach, we have imple-
mented advanced Gr¨obner basis algorithms, such as Faug`ere’s F4 and
F5, in a composable way.
Keywords: Gr¨obner basis; signature-based algorithms; computational
algebra; functional programming; Haskell; type system; formal methods;
property-based testing; implementation report.
1
Introduction
In the last few decades, the area of computational algebra has grown larger. Many
algorithms have been proposed, and there have emerged plenty of computer
algebra systems. Such systems must achieve correctness, composability and safety
so that one can implement and examine new algorithms within them. More
speciﬁcally, we want to achieve the following goals:
Composability means that users can easily implement algorithms or mathe-
matical objects so that they work seamlessly with existing features.
Safety prevents users and implementors from writing “wrong” code. For ex-
ample, elements in diﬀerent rings, e.g. Q[x, y, z] and Q[w, x, y], should be
treated diﬀerently and must not directly be added. Also, it is convenient to
have handy ways to convert, inject, or coerce such values.
Correctness of algorithms, with respect to prescribed formal speciﬁcations,
should be guaranteed with a high assurance.
We apply methods in the area of functional programming to achieve these
goals. As a proof-of-concept, we present the computational-algebra pack-
age [12]. It is implemented as an embedded domain-speciﬁc language in the

Table 1. Symbols in Code Fragments
Symbol
Code
Symbol
Code
Symbol
Code
Symbol
Code
N
Nat
Z
Integer
Q
Rational
Fp
F p
::
::
=
==
̸=
/=
λ ⃗x →e \⃗x -> e
×
*
⋉
!*
⌢
++
⊖
%-
≃
:~:
∼
~
→
->
←
<-
=⇒
==>
⇒
=>
:=
.=
:⇐
.%=
⊆
‘Subset‘
≤
<=
◦
.
∧
.&&.
•
.*
<$>
<$>
<∗>
<*>
∀
forall
Haskell Language [10]. More precisely, we adopt the Glasgow Haskell Compiler
(GHC) [7] as our hosting language. We use GHC because: its type-system allows
us to build a safe and composable interface for computer algebra; lazy evalua-
tion enables us to treat inﬁnite objects intuitively; declarative style sometimes
reduces a burden of writing mathematical programs; purity permits a wide range
of equational optimisation; and there is a plenty of libraries for functional meth-
ods, especially property-based testing. These methods are not widely adopted in
this area; an exception is DoCon [23], a pioneering work combining Haskell and
computer algebra. Our system is designed with more emphasis on safety and
correctness than DoCon, adding more ingredients. Although we use a functional
language, some methods in this paper are applicable in imperative languages.
This paper is organised as follows. In Section 2, we discuss how the progressive
type-system of GHC enables us to build a safe and expressive type-system for
a computer algebra. Then, in Section 3, we see how the method of property-
based testing can be applied to verify the correctness of algebraic programs in a
lightweight and top-down manner. To demonstrate the practical advantages of
Haskell, Section 4 gives a brief description of the current implementations of the
Hilbert-driven, F4 and F5 algorithms. We also take a simple benchmark there.
We summarise the paper and discuss related and future works in Section 5.
In what follows, we use symbols in Table 1 in code fragments for readability.
2
Type System for Safety and Composability
In this section, we will see how the progressive type-level functionalities of GHC
can be exploited to construct a safe, composable and ﬂexible type-system for
a computer algebra system. There are several existing works on type-systems
for computer algebra, such as in Java and Scala [18, 15], and DoCon. However,
none of them achieves the same level of safety and composability as our approach,
which utilises the power of dependent types and type-level functions.
2.1
Type Classes to Encode Algebraic Hierarchy
We use type-classes, an ad-hoc polymorphism mechanism in Haskell, to en-
code an algebraic hierarchy. This idea is not particularly new (for example, see

Mechveliani [23] or Jolly [15]), and we build our system on top of the existing
algebra package [17], which provides a ﬁne-grained abstract algebraic hierarchy.
Code 1 Group structure, coded in the algebra package
1
class Additive a where
2
(+)
::
a →a →a
3
class Additive a ⇒
Monoidal a where
4
zero
::
a
5
class Monoidal a ⇒
Group a where
6
negate
::
a →a
Code 1 illustrates a simpliﬁed version of the algebraic hierarchy up to Group
provided by the algebra package. Each statement between class or ⇒and
where, such as Additive a or Monoidal a, expresses the constraint for types.
For example, Lines 1 and 2 express “a type a is Additive if it is endowed with
a binary operation +”, and Lines 3 and 4 that “a type a is Monoidal if it is
Additive and has a distinguished element called zero”.
Note that, none of these requires the “proof” of algebraic axioms. Hence, one
can accidentally write a non-associative Additive-instance, or non-distributive
Ring-instance1. This sounds rather “unsafe”, and we will see how this could be
addressed reasonably in Section 3.
2.2
Classes for Polynomials and Dependent Types
Expressing algebraic hierarchy using type-class hierarchy, or class inheritance,
is not so new and they are already implemented in DoCon or JAS. However,
these systems lack a functionality to distinguish the arity of polynomials or the
denominator of a quotient ring. In particular, DoCon uses sample arguments
to indicate such parameters, and they cannot be checked at compile-time. To
overcome these restrictions, we use Dependent Types.
For example, Code 2 presents the simpliﬁed deﬁnition of the class IsOrdPoly
for polynomials. We provide an abstract class for polynomials, not just an imple-
mentation, to enable users to choose appropriate internal representations ﬁtting
their use-cases.
The class deﬁnition includes not only functions, but also associated types, or
type-level functions: Arity, MOrder and Coeff. Respectively, they correspond to
the number of variables, the monomial ordering and the coeﬃcient ring.
Note that liftMap corresponds to the universality of the polynomial ring
R[X1, . . . , Xn]; i.e. the free associative commutative R-algebra over { 1, . . . , n }.
1 Indeed, one can use dependent types, described in the next subsection, to require such
proofs. However, this is too heavy for the small outcome, and does not currently work
for primitive types.

Code 2 A type-class for polynomials
1
class (Module (Coeff poly ) poly , Commutative
poly , Ring poly ,
2
CoeffRing (Coeff poly ), IsMonomialOrder
(MOrder poly ))
3
⇒
IsOrdPoly
poly
where
4
type
Arity
poly
:: N
5
type
MOrder poly
::
Type
6
type
Coeff
poly
::
Type
7
liftMap
::
(Module (Scalar (Coeff poly )) alg , Ring
alg)
8
⇒(N<Arity poly
→
alg) →
poly
→
alg
9
leadTerm
::
poly
→
(Coeff poly , OrdMonom (MOrder
poly ) n)
10
...
Code 3 Examples for polynomial instances
1
instance (IsMonomialOrder
ord , CoeffRing
r)
2
⇒
IsOrdPoly (OrdPoly r ord n) where
3
type
Arity
(OrdPoly r ord n) = n
4
type
MOrder (OrdPoly r ord n) = ord
5
type
Coeff
(OrdPoly r ord n) = r
6
...
7
8
f
::
OrdPoly
Q
Grevlex 3
9
f = let [x,y,z] = vars in x ^ 2 × y + 3 × x + z + 1
10
11
instance (CoeffRing
r) ⇒
IsOrdPoly
(Unipol r) where
12
type
Arity
(OrdPoly r ord n) = 1
13
type
MOrder (OrdPoly r ord n) = Lex
14
type
Coeff
(OrdPoly r ord n) = r
15
...
In theory, this function suﬃces to characterise the polynomial ring. However, for
the sake of eﬃciency, we also include some other operations in the deﬁnition.
Code 3 shows example instance deﬁnitions for the standard multivariate and
univariate polynomial ring types. Note that, in Lines 8 and 12, number literal
expressions 1 and 3 occur in type contexts. Types depending on expressions are
called Dependent Types in type theory. GHC supports them via the Promoted
Data-types language extension [27] since version 7.4. Our library heavily uses this
functionality, and achieves the type-safety preventing users from unintendedly
confusing elements from diﬀerent rings.
2.3
Proofs in Dependent Types and Type-driven Casting Function
In theory, we can use liftMap to cast between any elements of “compatible”
polynomial rings. To reduce the burden to write boilerplate casting functions, our
library comes with smart functions, as shown in Code 4. The convPoly function

Code 4 Various casting function, with simpliﬁed type-signatures
1
convPoly
::
(Coeff r ∼Coeff r’, MOrder r ∼MOrder r’,
2
Arity r ∼Arity r’)
3
⇒
r →r’
4
injVars
::
(Arity r ≤Arity r’, Coeff r ∼Coeff r’)
5
⇒
r →r’
6
injVarsOffset
::
(n + Arity r ≤Arity r’, Coeff r ∼Coeff r’)
7
⇒
Sing n →r →r’
maps a polynomial into one with the same setting but diﬀerent representation;
e.g. OrdPoly Q Lex 1 into Unipol Q. The next injVars function maps an
element of R[X1, . . . , Xn] into another polynomial ring with the same coeﬃcient
ring, but with more number of variables, e.g. R[X1, . . . , Xn+m], regardless of
ordering. For example, it maps Unipol Q into OrdPoly Q Grevelx 3. Then,
injVarsOffset is a variant of injVars which maps variables with oﬀset; for
example,
1
injVarsOffset [sn | 3 | ]
::
Unipol
Q
→
Polynomial
Q
5
maps Q[X] into Q[X0, . . . , X4] with X 7→X3. Here, [sn|3|] is called a singleton
for the type-level natural number 3, ﬁrst introduced by Eisenberg et al. [4]. More
precisely, for any type-level natural n, there is the unique expression sing ::
Sing n and we can use it as a tag for type-level arguments.
To work with type-level naturals, we sometimes have to prove some con-
straints. For example, suppose we want to write a variant of injVars mapping
variables to the end of those of the target polynomial ring, instead of the begin-
ning. We might ﬁrst write it as follows:
1
injVarsAtEnd
::
(Arity r ≤Arity r’, Coeff r ∼Coeff r’)
2
⇒
r
→r’
3
injVarsAtEnd =
4
let sn = sing
::
Sing (Arity r)
5
sm = sing
::
Sing (Arity r’)
6
in injVarsOffset (sm
⊖
sn) -- Errors!
However, GHC cannot see Arity r’ - Arity r + Arity r ≤Arity r’. Al-
though this constraint is rather clear to us, we have to give the compiler its
proof. We have developed the type-natural package [14] which includes typical
“lemmas”. For example, we can use the minusPlus lemma to ﬁx this:
1
-- From type -natural:
2
minusPlus
::
Sing n
→
Sing m
3
→
IsTrue (m ≤n)
→
((n - m) + m)
≃
n
4
5
injVarsAtEnd
::
(Arity r ≤Arity r’, Coeff r ∼Coeff r’)
6
⇒
r
→r’

7
injVarsAtEnd =
8
let sn = sing
::
Sing (Arity r)
9
sm = sing
::
Sing (Arity r’)
10
in withRefl (minusPlus sm sn Witness) $
11
injVarsOffset (sm
⊖
sn)
Since giving such a proof each time is rather tedious, we can use type-checker
plugins to let the compiler try to prove constraints automatically. In particu-
lar, the author developed the ghc-typelits-presburger plugin [13] to resolve
propositions in Presburger arithmetic at compile time.
Our library also provides the LabPoly type, which converts existing polyno-
mial types into “labelled” ones. For example, one can write as follows:
1
f
::
LabPoly (Polynomial
Q
3) ’["x", "y", "z"]
2
f = 5 × #x ^ 2 × #y ^ 3 - #y × #z + 1
This relies on the DataKinds and OverloadedLabels language extensions of
GHC. GHC’s type system is strong enough to reject illegal terms and types,
such as #w :: LabPoly (Unipol Q) ’["a"] (w is not listed as a variable) or
LabPoly (Polynomial Q 3) ’["x", "y", "x"] (the variable x occurs twice).
Using the type-level information, one can invoke the canonical inclusion maps
naturally as follows:
1
f
::
LabPoly ’
Q
Grevlex ’["x", "y", "z"]
2
f = #x × #y × #z + 2 × #y - 3
× #z × #x + 1
3
g
::
LabPoly ’
Q
Lex ’["w", "z", "y", "u", "x"]
4
g = canonicalMap f
5
6
-- Where:
7
canonicalMap
::
(xs
⊆
ys , Wraps xs poly , Wraps ys poly ’,
8
IsPolynomial poly , IsPolynomial poly ’,
9
Coeff poly ∼Coeff poly ’)
10
⇒
LabPoly poly xs
→
LabPoly poly ’ ys
2.4
Optimising Casting Functions with Rewriting Rules
Since the casting functions are implemented generically, they sometimes intro-
duce unnecessary overhead. For example, if one uses injVars with the same
source and target types, it should just be the identity function. Fortunately, we
can use the type-safe Rewriting Rule functionality of GHC to achieve this:
1
{-# RULES "injVars/identity" injVars = id #-}
Each rewriting rule ﬁres at compile-time, if there is a term matching the left-hand
side of the rule and having the same type as the right-hand side.
In Haskell, it suﬃces just to consider algebraic laws to write down custom
rewriting rules. This is due to the purity of Haskell. That is, every expression in

Haskell is pure, in a sense that they evaluate to the same result when given the
same arguments. Note that this does not mean that Haskell cannot treat values
with side-eﬀects; indeed, the type-system of Haskell distinguishes pure and im-
pure values at type-level, and one can treat impure operations without violating
purity as a whole. The trick behind this situation is to describe side-eﬀects as
some kind of abstract instructions, instead of treating impure values directly.
Hence, for example, duplicating the same term does not make any diﬀerence in
its meaning, provided that it is algebraically correct. Such a rewriting rule is
used extensively in Haskell. For example, Stream Fusion [3] uses them to elim-
inate unnecessary intermediate expressions and fuse complicated functions into
eﬃcient one-path constructions. Yet, DoCon did not do any optimisation using
rewriting rules.
In our library, we also use rewriting rules to remove idempotent applications
such as “grading” a monomial ordering twice, e.g:
1
{-# RULES "graded/graded" ∀ord.
2
graded (graded ord) = graded ord #-}
2.5
Notes on applicability in imperative languages
The safety we achieved in this section cannot be achieved at compile-time with-
out dependent types and type-level functions. Existing works using type-classes
or class inheritance to encode algebraic hierarchy, such as JAS or DoCon, lack
this level of safety. In theory, one can achieve the same level of safety even in a
statically-typed imperative language, if it supports a kind of dependent types.
For example, in C++, templates with non-type arguments can be used to simulate
dependent types. On the other hand, in Java, Generics do not allow non-type
arguments and we need to mimic Peano numerals with classes. In either case,
it requires much eﬀort to prove the properties of naturals within them, because
they lack dedicated support for type-level naturals or type-checker plugins.
On the other hand, to make use of rewriting rules, we need purity as discussed
above.
3
Lightweight Correctness: Property-based Testing
3.1
Property-based testing introduced
In this section, we will address the correctness issue, in a top-down, or lightweight
manner. Especially, we apply the method of property-based testing [1] to verify
the correctness of our implementation. The idea is that one speciﬁes the formal
properties that the implemented algorithms and types must satisfy, and checks
if they hold by testing them against randomly or exhaustively generated inputs.
Although it is not as rigorous as a theorem proving, it still gives a guarantee of
the correctness at high assurance, after repeating tests time after time.

Code 5 Formal Speciﬁcation of Algebraic Programs
1
prop_division
::
Q
→
Property
2
prop_division
q =
3
q
̸=
0 =⇒(recip q × q
=
1 ∧q × recip q
=
1)
4
∧q × 1
=
q ∧1 × q
=
q
5
6
prop_passesSTest
n =
7
forAll (idealOfArity
n) $ λ ideal
→
8
let gs = calcGroebnerBasis
(toIdeal
ideal)
9
in all (isZero ◦(‘modPoly ‘ gs ))
10
[sPoly f g
|
f ←
gs , g ←
gs , f
̸=
g]
Code 5 presents the example speciﬁcations for algebraic programs. In Lines
1 through 4, prop_division states that the implementation of Q must satisfy
the axioms of division ring. The prop_passesSTest function demand the result
of calcGroebnerBasis to pass the S-test. The tester accepts the speciﬁcations
above, generates a speciﬁed number of inputs (default: 100) and tests against
them. If all the inputs satisfy the speciﬁcations, it successfully halts; otherwise,
it reports counterexamples, which is useful while debugging.
3.2
Discussion
There are several libraries for property-based testing adopting diﬀerent strategies
to generate inputs. For example, QuickCheck [1] generates inputs randomly,
while SmallCheck [26] exhaustively enumerates inputs in the depth-increasing
order. Even though there are other implementations of property-based testers in
languages other than Haskell [11], it does not seem that it is applied in existing
systems, such as Singular [9], JAS or DoCon.
By its generative nature, property-based testing has several drawbacks and
pitfalls. First, evidently, it cannot assure the validity as rigorously as the for-
mal theorem proving, unless the input space is ﬁnite. There are several pieces
of research that combine formal theorem proving and computational algebra
to rigorously certify correctness of implementations (for example, [24, 2]). These
ﬁrst formalise the theory of Gr¨obner basis in the constructive type-theory. Then,
execute them within the host theorem proving language, or extract the program
into other languages. However, by its nature, this approach requires everything
to be proven formally. It is not so easy a task to prove the correctness of every
part of a program, even with help from automatic provers. Even if one manages
to ﬁnish the proof of the validity of some algorithm, when one wants to optimise
it afterwards, then one must prove the “equivalence” or validity of that optimisa-
tion. Moreover, it is sometimes the case that the validity, or even termination, of
the algorithm remains unknown when it is implemented; e.g. the correctness and
termination of Fauger`e’s F5 [6] are proven very recently [25]. Furthermore, there
is an obvious restriction that we can extract programs only into the languages

supported by the theorem prover. We consider these conditions too restrictive,
and decided to adopt theorem proving only in trivial arity arithmetic.
Secondly, if the algorithm has a bad time complexity, property-based tests
can easily explode. Speciﬁcally, since Gr¨obner bases have double-exponential
worst time complexity, randomly generated input can take much time to be pro-
cessed. One might reduce the burden by combining randomised and enumerative
generation strategies carefully, but there is still a possibility that there are small
inputs which take much time. To avoid such a circumstance, one can reduce the
number of inputs, however it also reduces the assurance of validity.
Finally, they are not so good at treating existential properties. Although
SmallCheck provides the existential quantiﬁer in its vocabulary, it just tries
to ﬁnd solutions up to a prescribed depth. If solutions are relatively “larger”
than its inputs, this results in false-negative failures. For example, one can
write the following speciﬁcation that demands each element of the result of
calcGroebnerBasis to be a member of the original ideal, however it does not
work as expected:
1
prop_gbInc ideal =
2
let j = calcGroebnerBasis ideal
3
in exists $ λ cs
→
4
and (zipWith (λ f gs
→
f
=
dot ideal gs) j cs)
In the above, dot i g denotes the “dot-product”. As a workaround, we cur-
rently combine inter-process communication with property-based testing. More
speciﬁcally, we invoke a reliable existing implementation, such as SINGULAR,
inside the spec as follows:
1
prop_gbInc = forAll
arbitrary $ λ i
→
monadicIO $ do
2
let gs = calcGroebnerBasis i
3
is
←
evalSingularIdealWith [] [] $
4
funE "reduce" [
5
idealE gs, funE "groebner" [idealE i]]
6
return $ all isZero is
Thus, if the existential property in question is decidable and has an existing
reliable implementation, then it might be better to call it inside speciﬁcations.
4
Case Study: Implementing the Hilbert-driven, F4 and
F5 algorithms for calculating Gr¨obner bases
In this section, we will focus on three algorithms as case-studies: the Hilbert-
driven, F4 and F5 algorithms. Firstly, we demonstrate the power of laziness
and parallelism by the Hilbert-driven algorithm. Then by the F4 interface, we
illustrate the practical example of composability. Finally, we skim through the
simpliﬁed version of the main routine of F5 and see how imperative programming
with mutable states can be written purely in Haskell. For our purpose, we will

discuss only a fragment of implementations that elucidates the advantages of
Haskell, rather than the entire implementation and theoretical details.
4.1
Homogenisation and Hilbert-driven basis conversion
Code 6 Basic API for homogenisation
1
data
Homogenised
poly
2
instance
IsOrdPoly
poly
⇒
IsOrdPoly
(Homogenised
poly ) where
3
type
Arity
(Homogenised
poly ) = 1 + Arity poly
4
type
MOrder (Homogenised
poly ) = HomogOrder
(MOrder poly )
5
type
Coeff
(Homogenised
poly ) = Coeff poly
6
...
7
homogenise
::
IsOrdPoly
poly
⇒
poly
→
Homogenised
poly
8
unhomogenise
::
IsOrdPoly
poly
⇒
Homogenised
poly
→
poly
9
10
calcGBViaHomog
::
(Field (Coeff poly ), IsOrdPoly
poly )
11
⇒(∀r. (Field (Coeff r), IsOrdPoly
r)
12
⇒
Ideal r →
[r])
13
→
Ideal poly
→[poly ]
14
calcGBViaHomog
calc i
15
|
all
isHomogeneous
i =
calc
i
16
|
otherwise
= map
unhomogenise
( calc
(fmap
homogenise
i))
Homogenisation is a powerful tool in Gr¨obner basis computation. If I ⊆k[X]
is a non-homogeneous ideal and ¯I ⊆k[x, X] its homogenisation, then one can
get a Gr¨obner basis for I by unhomogenising the Gr¨obner basis ¯G for ¯I w.r.t. a
suitably induced monomial ordering. In this way, any Gr¨obner basis algorithm
for homogeneous ideals can be converted into one for non-homogeneous ones.
Code 6 is an API for these operations. The type Homogenised poly repre-
sents polynomials obtained by homogenising polynomials of type poly. Then
calcGBViaHomog calc i ﬁrst checks if the input i is homogeneous. If it is so,
then it applies the argument calc to its input directly (Line 15); otherwise,
it ﬁrst homogenises the input, applies calc , and then unhomogenises it to get
the ﬁnal result (Line 16). Note that, though it uses the same term calc in
both cases, they have diﬀerent types. In the ﬁrst case, since it just feeds an in-
put directly, calc has type Ideal poly →[poly]. On the other hand, in the
non-homogeneous case, it is applied after homogenisation, hence it is of type
Ideal (Homogenised poly) →[Homogenised poly]. Thus, calcGBViaHomog
takes a polymorphic function as its ﬁrst argument and this is why we have ∀
inside the type of the ﬁrst argument. Such a nested polymorphic type is called
a rank n polymorphic type, and it is supported by GHC’s RankNTypes language
extension2.
2 This can be achieved in object-oriented language with subtyping and Generics.

Code 7 Data-type of and operations on Hilbert–Poincar´e series
1
data
HPS n = HPS { taylor
::
[ Z ], hpsNumerator
::
Unipol
Z
}
2
3
instance
Eq (HPS a) where
4
( = ) = ( = ) ‘on ‘ hpsNumerator
5
instance
Additive (HPS n) where
6
HPS cs f + HPS ds g = HPS (zipWith (+) cs ds) (f + g)
7
instance
LeftModule
(Unipol
Z ) (HPS n) where
8
f •
HPS cs g = HPS (conv (taylor f
⌢
repeat 0) cs) (f × g)
9
10
conv
::
[ Z ] →[ Z ] →
[ Z ]
11
conv (x : xs) (y : ys) =
12
let parSum a b c = a ‘par‘
b ‘par‘
c
‘seq‘
(a + b + c) in
13
x × y :
14
zipWith3
parSum (map (x×) ys) (map (y×) xs) (0 : conv xs ys)
For example, one can use the so-called Hilbert-driven algorithm as the ﬁrst
argument to calcGBViaHomog. It ﬁrst computes a Gr¨obner basis w.r.t. a lighter
monomial ordering, compute the Hilbert–Poincar´e series (HPS) with it and use it
to compute Gr¨obner basis w.r.t. the heavier ordering. In this procedure, we need
the following operations on HPS: Equality test on HPS’s, nth Taylor coeﬃcient
of the given HPS, and the Z[X]-module operation on HPS. Code 7 illustrates
such an interface for HPS. For equality test, we use the numerator hpsNumerator
of the closed form, and an inﬁnite list taylor maintains Taylor coeﬃcients. By
the lazy nature of Haskell, we can intuitively treat inﬁnite lists and write a
convolution on them. In Line 12, par and seq specify the evaluation strategy.
In brief, expressions x and y in “x ‘par‘ y” (resp. seq ) are evaluated parallelly
(resp. sequentially). Since every expression is pure in Haskell, we can safely take
advantage of parallelism, without a possibility of changing results.
4.2
A composable implementation of F4
F4 is one of the most eﬃcient algorithms for Gr¨obner basis computation and
introduced by Faug`ere [5]. Brieﬂy, F4 reduces more than two polynomials at
once, replacing S-polynomial remaindering in the Buchberger Algorithm with
the Gaussian elimination of the matrices. This means that the eﬃciency of F4
reduces to that of Gaussian elimination and the internal representation of matri-
ces. Thus, it is useful if we can easily switch internal representations and elim-
ination algorithms. For this purpose, we provide type-classes for mutable and
immutable matrices which admit row operations and a dedicated Gaussian elim-
ination. Code 8 demonstrates the interface for immutable and mutable matrices
(Matrix and MMatrix) and the type signature of our F4 implementation (f4). In
Lines 1 and 6, the last type argument a of Matrix and MMatrix corresponds to
the type of coeﬃcients. Note that, one can give diﬀerent instance deﬁnitions for

Code 8 Matrix classes and the F4 function
1
class MMatrix
mat a where
2
fromRows
::
[Vector a] →
ST s (mat s a)
3
scaleRow
::
Multiplicative
a ⇒
Int
→a →
mat s a →
ST s ()
4
...
5
6
class MMatrix (Mutable
mat) a ⇒
Matrix
mat a where
7
type
Mutable
mat
::
⋆→⋆
8
freeze
::
Mutable mat s a →
ST s (mat a)
9
...
10
gaussReduction
::
Field a ⇒
mat a →
mat a
11
12
type
Strategy
f w = f →
f →w
13
f4
::
(Ord w, IsOrdPoly
poly , Field (Coeff poly ),
14
Matrix
mat (Coeff poly ))
15
⇒
proxy mat
→
Strategy
poly w
→
Ideal poly
→
[poly ]
the same mat but diﬀerent coeﬃcient types a. For example, one can implement
eﬃcient Gaussian elimination on Fp for Matrix Mat Fp, and then use it in the
deﬁnition of Matrix Mat Q, with the Hensel lifting or Chinese remaindering.
In Line 15, the ﬁrst argument of f4 of type proxy mat speciﬁes the internal
representation mat of matrices. In addition, f4 takes a selection strategy as the
second argument. Here, the selection strategy is abstracted as a weighting func-
tion to some ordered types, and we store intermediate polynomials in a heap
and select all the polynomials with the minimum weight at each iteration.
4.3
The F5 algorithm
Finally, we present the simpliﬁed version of the main routine of Faug`ere’s F5 [6]
(Code 9). Readers may be surprised that the code looks much imperative. This is
made possible by the ST monad [19], which encapsulates side-eﬀects introduced
by mutable states and prevents them from leaking outside. We use a functional
heap to choose the polynomial vectors with the least signature, demonstrating
the fusion of functional and imperative styles.
4.4
Benchmarks
We also take a simple benchmark and the result is shown in Table 2 (examples are
taken from Giovini et al. [8]). This compares the algorithms implemented in our
computational-algebra package and Singular. The ﬁrst four rows correspond
to the alrorithms implemented in our library; i.e. the Buchberger algorithm op-
timised with syzygy and sugar strategy (B), the degree-by-degree algorithm for
homogeneous ideals (DbyD), the Hilbert-driven algorithm (Hilb), and F5. S(gr)
and S(sba) stand for the groebner and sba functions in the Singular computer

Code 9 Main Routine of the F5 Algorithm
1
f5
::
(Field (Coeff pol), IsOrdPoly
pol)
2
⇒
Vector pol
→
[( Vector pol , pol )]
3
f5 (map monoize
→
i0) = runST $ do
4
let n = length i0
5
gs
←
newSTRef
[]
6
ps
←
newSTRef $ H. fromList [ basis n i
|
i ←
[0..n-1]]
7
syzs
←
newSTRef
8
[ sVec (i0 ! m) (i0 ! n)
|
m ←
[0..n-1], n
←
[0..j-1] ]
9
whileJust_
(H.viewMin <$> readSTRef
ps) $
10
λ (Entry sig g, ps ’)
→
do
11
ps
:=
ps ’
12
(gs0 , ss0)
←
(,) <$> readSTRef
gs
<∗>
readSTRef
syzs
13
unless (standardCriterion
sig ss0) $ do
14
let (h, ph) = reduceSignature
i0 g gs0
15
h’ = map (× injectCoeff
(recip $ leadingCoeff
ph)) h
16
if isZero ph then
syzs
:⇐
(mkEntry h : )
17
else do
18
let adds = fromList $ mapMaybe (regSVec (ph , h’)) gs0
19
ps
:⇐
H.union adds
20
gs
:⇐
(( monoize ph , mkEntry h’) :)
21
map (λ (p, Entry _ a) →
(a, p)) <$> readSTRef
gs
algebra system 4.0.3. The complete source-code is available on GitHub [12]3.
The benchmark program is compiled with GHC 8.2.2 with ﬂags -O2 -threaded
-rtsopts -with-rtsopts=-N, and ran on an Intel Xeon E5-2690 at 2.90 GHz,
RAM 128GB, Linux 3.16.0-4 (SMP), using 10 cores in parallel. We used the
Gauge framework to report the run-time of our library, and the rtimer primi-
tive for Singular. For actual benchmark codes, see http://bit.ly/hbench1 and
hbench2. Unfortunately, in our system, F4 takes much more computing time,
hence we did not include the result. The results show that, among the algo-
rithms implemented in our system, F5 works ﬁne in general, though it takes
much time in some speciﬁc cases. Nevertheless, there remains much room for
improvement to compete with the state-of-the-art implementations such as Sin-
gular, although there is one case where our implementation is slightly faster than
Singular’s groebner function.
5
Conclusions
In this paper, we have demonstrated how we can adopt the methods developed
in the area of functional programming to build a computer algebra system. Some
of these methods are also applicable in imperative languages.
3 More speciﬁcally, we used the implementation in commit 70e6e7b.

Table 2. Benchmark results (ms)
I1 (Lex)
I1 (Grevlex)
I2 (Lex)
I2 (Grevlex)
I3 (Grevlex)
B
1.820 × 100
1.593 × 101
1.400 × 101
4.129 × 100
6.689 × 102
DbyD
6.364 × 101
9.162 × 102
1.147 × 102
5.647 × 101
4.125 × 102
Hilb
1.644 × 102
2.313 × 102
5.265 × 101
3.414 × 101
9.645 × 103
F5
1.851 × 100
4.314 × 102
7.129 × 100
2.648 × 100
1.290 × 103
S(gr)
2.300 × 100
8.493 × 10−1
2.651 × 100
8.210 × 10−1
9.511 × 10−1
S(sba)
2.279 × 10−1
8.711 × 10−1
2.343 × 10−1
7.958 × 10−1
1.541 × 10−1
I1 := ⟨35y4 −30xy2 −210y2z + 3x2 + 30xz −105z2 + 140yt −21u,
5xy3 −140y3z −3x2y + 45xyz −420yz2 + 210y2t −25xt + 70zt + 126yu⟩
I2 := ⟨w + x + y + z, wx + xy + yz + zw, wxy + xyz + yzw + zwx, wxyz −1⟩
I3 := ⟨x31 −x6 −x −y, x8 −z, x10 −t⟩
In Section 2, we presented a type-system strong enough to detect algebraic
errors at compile-time. For example, our system can distinguish number of vari-
ables of polynomial rings at type-level thanks to dependent types. It also enables
us to automatically generate casting functions and we saw how their overhead
can be reduced using rewriting rules. As for type-systems for a computer algebra
system, there are several existing works [18, 23]. However, these systems are not
safe enough for discriminating variable arity at type-level and don’t make use of
rewriting rules.
In Section 3, we successfully applied the method of property-based testing for
veriﬁcation of the implementation, which is lightweight compared to the existing
theorem-prover based approach [2, 24]. Although property-based testing is not
as rigorous as theorem proving, it is lightweight and can be applied to algo-
rithms not yet proven to be valid or terminate and available also for imperative
languages.
We have seen that, in Section 4, other features of Haskell, such as higher-order
polymorphism, parallelism and laziness, can also be easily applied to computer
algebra by actual examples. Even though they are shown as fragments of code,
we expect them to be convincing.
Since some of the methods in this paper, such as dependent types or property-
based testing, are not limited to the functional paradigm, it might be interesting
to investigate their applicability in the imperative settings.
From the viewpoint of eﬃciency, there are much to be done. For example,
eﬃciency of our current F4 implementation is far inferior to that of the na¨ıve
Buchberger algorithm, and other algorithms are far much slower than state-of-
the-art implementations such as Singular. To optimise implementations, we can
make more use of Rewriting Rules and eﬃcient data structures. Also, the par-
allelism must undoubtedly play an important role. Fortunately, there are plenty
of the parallel computation functionalities in Haskell, such as Regular Parallel
Arrays [16] and parallel package [22], and another book by Marlow [21] on gen-
eral topics in parallelism in Haskell. Also, there is an existing work by Lobachev
et al. [20] on parallel symbolic computation in Eden, a dialect of Haskell with

parallelism support. Although Eden is retired, the methods introduced there
might be helpful.
Acknowledgements
The author would like to thank my supervisor, Prof. Akira Terui, for discussions,
and to anonymous reviewers for helpful comments. This research is supported
by Grant-in-Aid for JSPS Research Fellow Number 17J00479, and partially by
Grants-in-Aid for Scientiﬁc Research 16K05035. This is a pre-print of an article
published in “Computer Algebra in Scientiﬁc Computing” (2018). The ﬁnal au-
thenticated version is available online at: https://doi.org/10.1007/978-3-319-99639-4
References
1.
Claessen, K., Hughes, J.: QuickCheck: a lightweight tool for random testing of
Haskell programs. In: Proceedings of the Fifth ACM SIGPLAN International
Conference on Functional Programming. ICFP ’00, pp. 268–279. ACM, New York,
NY, USA (2000). http://doi.acm.org/10.1145/351240.351266
2.
Coquand, T., Persson, H.: Gr¨obner bases in type theory. In: Types for Proofs and
Programs, pp. 33–46. Springer, Berlin, Heidelberg (1999)
3.
Coutts, D., Leshchinskiy, R., Stewart, D.: Stream Fusion. From lists to streams
to nothing at all. In: Proceedings of the 12th ACM SIGPLAN International Con-
ference on Functional Programming. ICFP ’07. (2007)
4.
Eisenberg, R. A., Weirich, S.: Dependently typed programming with singletons.
ACM SIGPLAN Notices - Haskell ’12 47(12), 117–130 (2012)
5.
Faug`ere, J.-C.: A new eﬃcient algorithm for computing Gr¨obner bases (F4). Jour-
nal of Pure and Applied Algebra 139(1), 61–88 (1999)
6.
Faug`ere, J.-C.: A new eﬃcient algorithm for computing Gr¨obner bases without
reduction to zero (F5). In: Proceedings of the 2002 International Symposium on
Symbolic and Algebraic Computation, pp. 75–83. ACM, Lille, France (2002)
7.
GHC Team: The Glasgow Haskell Compiler. https://www.haskell.org/ghc/
(2018). Accessed 2018
8.
Giovini, A., Mora, T., Niesi, G., Robbiano, L., Traverso, C.: “One sugar cube,
please” or selection strategies in the Buchberger algorithm. In: Proceedings of
the 1991 International Symposium on Symbolic and Algebraic Computation. IS-
SAC’91, pp. 5–4. ACM, (1991)
9.
Greuel, G.-M., Pﬁster, G.: A Singular Introduction to Commutative Algebra. 2nd.
Springer, (2007)
10.
Haskell Committee: The Haskell Programming Language. http://haskell.org/
11.
Hypothesis: Most testing is ineﬀective - Hypothesis. https://hypothesis.works
(2018). Accessed 06/05/2018
12.
Ishii,
H.:
The
computational-algebra
package.
2018.
https://konn.github.io/computational-algebra
13.
Ishii,
H.:
The
ghc-typelits-presburger
package.
http://hackage.haskell.org/package/ghc-typelits-presburger (2017)
14.
Ishii,
H.:
The
type-natural
package.
2013.
http://hackage.haskell.org/package/type-natural

15.
Jolly, R.: Categories as type classes in the Scala Algebra System. In: Computer
Algebra in Scientiﬁc Computing, pp. 209–218. Springer, Cham (2013)
16.
Keller, G., Chakravarty, M. M., Leshchinskiy, R., Peyton Jones, S., Lippmeier,
B.: Regular, shape-polymorphic, parallel arrays in Haskell. In: Proceedings of
the 15th ACM SIGPLAN International Conference on Functional Programming.
ICFP ’10, pp. 261–272. ACM, Baltimore, Maryland, USA (2010)
17.
Kmett, E. A.: The algebra package. http://hackage.haskell.org/package/algebra
(2011). Accessed 2018
18.
Kredel, H., Jolly, R.: Generic, type-safe and object oriented computer algebra
software. In: Computer Algebra in Scientiﬁc Computing, pp. 162–177. Springer,
Berlin, Heidelberg (2010)
19.
Launchbury, J., Peyton Jones, S. L.: Lazy functional state threads. In: Proceed-
ings of the ACM SIGPLAN 1994 Conference on Programming Language Design
and Implementation. PLDI ’94, pp. 24–35. ACM, Orlando, Florida, USA (1994)
20.
Lobachev, O., Loogen, R.: Implementing data parallel rational multiple-residue
arithmetic in Eden. In: Computer Algebra in Scientiﬁc Computing, pp. 178–193.
Springer, Berlin, Heidelberg (2010)
21.
Marlow, S.: Parallel and Concurrent Programming in Haskell: Techniques for
Multicore and Multithreaded Programming. O’Reilly Media, (2013)
22.
Marlow, S., Maier, P., Loidl, H.-W., Aswad, M. K., Trinder, P.: Seq no more:
better strategies for Parallel Haskell. In: Proceedings of the Third ACM Haskell
Symposium on Haskell. Haskell ’10, pp. 91–102. ACM, Baltimore, Maryland, USA
(2010). http://doi.acm.org/10.1145/1863523.1863535
23.
Mechveliani, S. D.: Computer algebra with Haskell: applying functional–
categorial–“lazy” programming. In: Proceedings of International Workshop
CAAP, pp. 203–211. (2001)
24.
Mechveliani,
S.
D.:
DoCon-A
a
Provable
Algebraic
Domain
Construc-
tor. http://www.botik.ru/pub/local/Mechveliani/docon-A/2.02/manual.pdf
(2018). Accessed 06/05/2018
25.
Pan, S., Hu, Y., Wang, B.: The termination of the F5 algorithm revisited. In:
Proceedings of the 38th International Symposium on Symbolic and Algebraic
Computation. ISSAC ’13, pp. 291–298. ACM, Boston, Maine, USA (2013)
26.
Runciman, C., Naylor, M., Lindblad, F.: SmallCheck and Lazy SmallCheck: au-
tomatic exhaustive testing for small values. In: Proceedings of the First ACM
SIGPLAN Symposium on Haskell. Haskell ’08, pp. 37–48. ACM, Victoria, BC,
Canada (2008). http://doi.acm.org/10.1145/1411286.1411292
27.
Yorgey, B. A., Weirich, S., Cretin, J., Peyton Jones, S., Vytiniotis, D., Magalh˜aes,
J. P.: Giving Haskell a promotion. In: Proceedings of the 8th ACM SIGPLAN
Workshop on Types in Language Design and Implementation. TLDI ’12, pp. 53–
66. ACM, Philadelphia, Pennsylvania, USA (2012)

