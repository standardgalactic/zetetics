The Autodidactic Universe
Stephon Alexander1,2, William J. Cunningham3,4, Jaron Lanier5,
Lee Smolin3, Stefan Stanojevic5,6, Michael W. Toomey1,5, and Dave
Wecker5
1Brown Theoretical Physics Center and Department of Physics, Brown
University, Providence, RI 02906, USA
2Center for Computational Astrophysics, CCA, Flatiron Institute, New
York, NY, 10010, USA
3Perimeter Institute for Theoretical Physics,
31 Caroline Street North, Waterloo, ON N2J2Y5, Canada
4Agnostiq Inc., 180 Dundas St. W., Toronto, ON M5G1Z8, Canada
5Microsoft Research, Redmond, WA 98052, USA
6University of Michigan, Ann Arbor, MI 48109, USA
September 3, 2021
Abstract
We present an approach to cosmology in which the Universe learns its own phys-
ical laws. It does so by exploring a landscape of possible laws, which we express as a
certain class of matrix models. We discover maps that put each of these matrix models
in correspondence with both a gauge/gravity theory and a mathematical model of a
learning machine, such as a deep recurrent, cyclic neural network. This establishes
a correspondence between each solution of the physical theory and a run of a neural
network.
This correspondence is not an equivalence, partly because gauge theories emerge
from N →∞limits of the matrix models, whereas the same limits of the neural
networks used here are not well-deﬁned.
We discuss in detail what it means to say that learning takes place in autodidactic
systems, where there is no supervision. We propose that if the neural network model
can be said to learn without supervision, the same can be said for the corresponding
physical theory.
1
arXiv:2104.03902v2  [hep-th]  2 Sep 2021

We consider other protocols for autodidactic physical systems, such as optimiza-
tion of graph variety, subset-replication using self-attention and look-ahead, geomet-
rogenesis guided by reinforcement learning, structural learning using renormaliza-
tion group techniques, and extensions. These protocols together provide a number of
directions in which to explore the origin of physical laws based on putting machine
learning architectures in correspondence with physical theories.
2

Contents
1
Introduction
5
1.1
What is learning? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
1.2
How can physical law be understood as learning? . . . . . . . . . . . . . . .
9
2
Matrix models as learning systems
12
2.1
Matrix models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
2.2
Learning systems, gauge theories and laws that learn . . . . . . . . . . . . .
13
2.3
Neural network architectures . . . . . . . . . . . . . . . . . . . . . . . . . . .
14
2.3.1
Review of the RBM, with continuous variables . . . . . . . . . . . . .
15
2.3.2
Features of learning systems
. . . . . . . . . . . . . . . . . . . . . . .
18
2.3.3
Features of matrix models of gauge theories
. . . . . . . . . . . . . .
19
2.4
Plebanski gravity as a learning system . . . . . . . . . . . . . . . . . . . . . .
20
3
Cubic learning systems
24
3.1
Learning architecture of cubic matrix models . . . . . . . . . . . . . . . . . .
25
3.2
Dynamics of cubic learning systems
. . . . . . . . . . . . . . . . . . . . . . .
27
3.3
The correspondence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
3.4
Cubic matrix model and Chern-Simons theory . . . . . . . . . . . . . . . . .
30
4
Protocols for autodidactic systems
31
4.1
Renormalization group learning
. . . . . . . . . . . . . . . . . . . . . . . . .
34
4.1.1
Review of basic concepts
. . . . . . . . . . . . . . . . . . . . . . . . .
34
4.1.2
Variational RG
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
36
4.1.3
RG-guided graph growth . . . . . . . . . . . . . . . . . . . . . . . . .
37
4.2
Precedence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
4.2.1
Precedence, Weinstein, and machine learning . . . . . . . . . . . . . .
39
4.3
Self-sampling learning methods . . . . . . . . . . . . . . . . . . . . . . . . . .
41
4.4
Variety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
46
4.4.1
Asymmetry, irregularity, and heterogeneity . . . . . . . . . . . . . . .
50
4.4.2
Variety of structural node embeddings
. . . . . . . . . . . . . . . . .
52
4.5
Geometric self-assembly . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
56
4.5.1
Learning an optimal annealing schedule
. . . . . . . . . . . . . . . .
57
4.5.2
Self-guided assembly using precedence . . . . . . . . . . . . . . . . .
58
5
Discussion
59
5.1
Traversing and learning in theory space . . . . . . . . . . . . . . . . . . . . .
60
5.2
The Universe goes to school . . . . . . . . . . . . . . . . . . . . . . . . . . . .
61
5.2.1
Useless and usable information . . . . . . . . . . . . . . . . . . . . . .
62
5.2.2
DNA and machine learning systems compared as consequencers . .
63
5.2.3
Signal between a learning system and its environment
. . . . . . . .
65
5.3
Might autodidactic ideas become necessary rather than optional? . . . . . .
67
3

5.3.1
Learning systems and irreversibility . . . . . . . . . . . . . . . . . . .
67
5.3.2
Can irreversible learning systems arise from reversible laws?
. . . .
68
6
Conclusion
70
References
73
4

1
Introduction
We present ideas at the intersection of theoretical physics, computer science, and philoso-
phy of science with a discussion from all three perspectives. We begin with a philosophi-
cal introduction, proceed with a technical argument that combines physics and computer
science, and conclude with further non-technical discussion.
Until recently, most of the research done by theoretical physicists has had the aim of
discovering what the laws of physics are. While we haven’t ﬁnished that task, we seem
to know enough to take a few steps towards answering a deeper question: why are these
– and not others that seem equally consistent mathematically – the actual laws [1–5]?
It used to be thought that our standard model - including general relativity - is the low
energy description of a unique consistent theory satisfying a short list of principles. But
research in string theory, loop quantum gravity and other approaches to quantum gravity
point to the opposite conclusion: there is a vast landscape of equally consistent theories
[4–7].
What is then called for is a very different approach to the “Why these laws?” question:
Let us seek a dynamical mechanism by which laws can evolve and change, and search
within that setting for a reason why the present laws are more likely than another set. For
example, the coupling constants might turn out to be dynamical variables. This opens the
door to several kinds of explanation, new to fundamental physics, but well understood in
other parts of science. These range from deterministic evolution in a space of couplings
to stochastic forms of evolution on a landscape of theories. The possibility of a useful
explanation for some properties of accepted laws, analogous to the explanatory power of
natural selection in biology, becomes imaginable, and has been explored [4,8,9].
In biology there used to be a “Why these species?” problem: explain why dogs and
cats exist while unicorns and werewolves do not. With the rise of the modern Darwinian
perspective, it became clear that knowing the general principles, which apply to all biol-
ogy, is a necessary prelude to understanding the detailed - often highly contingent and
complex - stories that explain why a particular species likely emerged.
It turns out that there are a number of puzzles concerning the values of the parameters
of the standard model, which in one way or another indicate that their present values are
special in that they lead to a universe far more complex than would be obtained with
typical values [2,3]. These suggest that explanations of the sort which we ﬁnd in biology
might be useful [4,8].
The application of natural selection to cosmology was ﬁrst proposed by the American
philosopher, Charles Sanders Pierce, in 1893 [1].
The idea has been independently discovered by others since, and has been studied in
some detail, to the point that several testable predictions have been recognized [4,8,9].
There is more that could be done in that direction, but that is not our purpose here.
In this paper we want to go even further and suggest that the universe has the capacity
to learn its laws. Learning is, as we will explain, a much more general notion than evolving
by natural selection, it is also a more complex and demanding idea. But we hope to help
5

the reader to see it as within the realm of the possible.
How are these kinds of explanations possible? Why would they be helpful? What
could be the beneﬁt of taking on such radical ideas?
What do we mean by the laws of nature learning? The answer is simply that we can
construct a correspondence between possible laws of nature described by gauge ﬁelds,
gravity and matter ﬁelds, and some of the states of a machine learning model such as the
restricted Boltzmann machine. In the simplest language, the choice of a vacuum of a QFT
is mapped to a process of pattern recognition.
The structure of this paper is as follows.
The correspondence between a class of gauge ﬁeld theories and a class of neural net-
work models of machine learning is developed in the next two chapters. This is based in
each of them being describable in the language of matrix models [10]. The ﬁeld theories
involved include topological ﬁeld theories such as Chern-Simons [11] theory and BF the-
ory [12], as well as the closely related Plebanski [13] formulations of general relativity, by
itself and coupled to Yang-Mills theory [14, 15]. This provides an example of how a sys-
tem whose degrees of freedom encode possible laws-such as spacetime dimension, gauge
group and matter representations can be mapped onto formal descriptions of neural net-
work systems that we are comfortable describing as being capable of learning. We note
that as we are talking about the universe, there is no supervision; we call such systems
autodidactic.
Note that at this point these are correspondences, not equivalences.
These results came out of a more general search for physical systems that could learn
without supervision. In a search of physical systems that could qualify for autodidactic
interpretation, we studied a variety of proposals and models. A sample of these are pre-
sented in Chapter 4, and employ the renormalization group, the proposal that quantum
systems have no laws except to follow precedence, self-sampling methods, systems that
maximize variety and geometrical self-assembly. The discussions here are brief, as papers
are in preparation to detail each of these.
Chapter 5 is a collection of responses to philosophical questions relevant to the inter-
pretation of earlier sections.
1.1
What is learning?
When we refer to laws of physics changing, or being different in different regions of space-
time, we are speaking in the language of effective ﬁeld theory, which is to say we assume
that the laws relevant for low energy physics can involve collective coordinates, emer-
gent, renormalized and averaged ﬁelds, and also can be dependent on effective coupling
constants whose values depend on the values of ﬁelds, as well as on temperature, density
etc. More generally, we adopt the useful idea that the world can be analyzed in terms
of a hierarchy of levels; the degrees of freedom and the regularities described at each
level appear to observers there to be stable and unchanging or slowly changing. At the
same time, when expressed in terms of the degrees of freedom and laws of a lower level,
6

they may seem emergent and variable. We can then be agnostics as to whether there are
fundamental, timeless laws down at the smallest scale.
To proceed to deﬁne learning we need to specify some terms:
We speak of “subsystems” and “processes”. A system is an identiﬁable part of the
universe that contains a number of processes and persists over a time scale that is long
compared to the timescales of its constituent processes - and is often characterized by a
boundary which isolates it from processes not contained in it. What is not in the system
is called the system’s environment.
A system has a set of activities carried out in time, by means of which it does work:
it catalyzes or alters itself and other things in the environment. Each of these is called a
process, and each has a typical time scale. Each process is closed, which means that it
operates in cycles that bring it back to its initial state, after having done work. The thing
that a process does that furthers the whole of which it is a part, is called its function.
We require that a system must be decomposable into a network of such processes
which are interdependent on each other, in the sense that the continuation, and growth
of the whole is dependent on and furthered by that of the processes. This is sometimes
called a ”Kantian whole” [101–103].
Typical systems of this kind are found far from thermal equilibrium, where some of
their processes channel and control the rates of energy and materials through them. They
develop from the need of the whole to manage ﬂows of energy and materials through it.
We can say then that such a system learns when it is able to alter its internal processes
and actions in the world to better capture and exploit the ﬂows of energy through or near
it to further a goal, which is typically continued existence, but might become more than
that.
The notion of learning encompasses a variety of circumstances, including biological
natural selection and what we call learning in individual organisms such as a person.
Many things can learn and there are many ways to learn.
Biological evolution is a vast-scale learning system, but individual members of species
have also typically inherited the capacity to learn. This does not require that the “infor-
mation” learned is stored symbolically - or stored in any abstract way - a moth does not
know its wings are black or that the reason is its tree is black.
Darwin suggested that an esthetic dimension of mate choice, sexual selection, had
become a central driver of evolution. In human intellectual behavior, we sometimes ob-
serve learning that is not motivated by interaction with a proximate threat or survivability
criteria, but instead by such things as curiosity, a quest for elegance or beauty, or other
hard-to-deﬁne targets.
We will term these cases, where a learning system constructs its own criteria, “autodi-
dactic systems”. Autodidactic criteria will often, or perhaps always, be coupled to more
fundamental criteria, particularly survival, but indirectly.
The term “learning” has been commonly used in computer science to refer to a class
of programs, such as “deep learning networks”. These are typically driven by either
imposed criteria for the feedback that drives learning, even when an algorithm is unsu-
7

pervised, or by a simulation of evolution, in the case of “artiﬁcial life” experiments.
We have described a variety of learning processes: learning might occur through sur-
vival when populations of organism compete in a lethal environment and survivors pass
on genes; learning might occur in an individual through life experience, and the criteria
for what is worth learning might be autodidactic; learning might be engineered into a
software model by an engineer, using arbitrary criteria.
This list is not exhaustive. For instance, we could speculate about a form of alien
life which does not have a separate level of genes, but nonetheless undergoes variations
randomly – and in which interpenetrating swarms of structures destabilize each other,
causing a gradual emergence of more robust structures. This might have been what hap-
pened before the DNA system emerged on Earth. We should not assume that we are
aware of all forms of learning.
In one sense, learning is nothing special; it is a causal process, conveyed by physical
interactions. And yet we need to consider learning as special to explain events that tran-
spire because of learning. It is clarifying to introduce language to speak of the physics of
learning systems. It helps to have a word to refer to the things the sub-processes do for
the whole that contribute to the whole’s learning.
We will call these functions 1 consequence accumulators or consequencers, for short. A
consequencer accumulates information from the past that is more inﬂuential to the future
than is typical for other contents of the system. It is the negative feedback loop in your
home’s thermostat, or a star, or a naturally occurring reactor. It is a bit in a computer, or a
gene.
Other naturally occurring consequencers we can keep in mind are limit cycles, which
occur necessarily, and seemingly randomly in ﬁnite state deterministic dynamical sys-
tems [FSDS]. They gain robustness from the way small random excursions from the cycles
are captured and returned by basins of attraction. These occur randomly, without super-
vision or design, but are ﬁrst steps in the natural self-organization of life, ecosystems,
economic and food webs etc. It its perfectly plausible that the random occurrence of limit
cycles could arise in a network of tunnelling channels among a landscape of vacua in a
quantum ﬁeld theory.
We also note that the term ”consequencer” encompasses the idea of a knowledge base,
or knowledge graph, in the ﬁeld of artiﬁcial intelligence [16]. One of the simplest repre-
sentations of “learned knowledge” uses propositional logic or, in other words, a set (or
graph) of Boolean satisﬁability constraints. The choice of knowledge representation also
deﬁnes the ontology of the learning system.
How might cosmological-scale learning occur? There have been proposals of appli-
cations of natural selection to cosmology [4, 8]. If one focuses only on a single universe,
however, then there is no population of universes in which selection could occur; this
paper focuses on a single universe, so does not dwell on cosmological natural selection.
1The brief answer to the common objection that functional explanations conﬂict with reductionist expla-
nations is that a complete explanation requires both.
8

Instead, we consider autodidactic learning in physics. We shall consider cosmological
consequencers ﬁrst, and then cosmological autodidactic processes.
1.2
How can physical law be understood as learning?
In the following sections, notably 3.3, we will establish the following maps between a
class of physical theories and a class of neural network-based models of learning:
Matrix models
Quantum gauge theories
Learning machines
This will be accomplished using correspondences to matrix models:
Vectors, spinors
Quantum
matter ﬁelds
Machine learning
layers
Matrices
Quantum gauge,
gravity ﬁelds
Machine learning
weights
Thermalization,
quenches
Cosmological
embedding
External
training
9

The action is cubic in the matrices [17], so the equations of motion are quadratic equa-
tions. With the imposition of various identiﬁcations and constraints, the matrix degrees
of freedom can be shown to be isomorphic to the degrees of freedom of a large class of
gauge ﬁeld theories, on various background geometries, including Yang-Mills theories
and general relativity [18]. To some extent, the spatial dimensions, gauge groups, spatial
topology and matter representations can be chosen.
These can thus be seen as quantum gauge or gravity theories, on which a variety of
infrared cutoffs (also known as compactiﬁcations) have been imposed.
There is thus at least one more triangle:
Choice of compactiﬁcation,
constraints, identiﬁcations
under translations.
dimension, gauge
group, reps
hypothesis as to
symmetries in the data
Most of these correspondences have yet to be worked out.
In this paper we work with a particularly minimal set of matrix models, which have
at most cubic actions [17–21].
We note that these are in a different universality class then some of the matrix models
studied previously, which are explicitly dependent on a background geometry speciﬁed
by a constant metric [10,22,23]. We see an example of this in equation (1) where the ﬁxed
metric is gab. In the limit N →∞these can be interpreted either as an N = ∞Yang-Mills
theory [22,24] or a membrane theory [23,25]. The latter construction is based on the fact
that the N →∞of SU(N) goes to the group of volume preserving diffeomorphisms on
the 2-torus [23].
On the other hand the cubic matrix models do not depend on any background invari-
ant structure, save the trace of the algebra. So these appear to be parts of other univer-
sality classes, deﬁned algebraically, which include the topological ﬁeld theories, general
relativity, and perhaps other diffeomorphism-invariant theories.
On the other side, we will show here that there exists maps between a large class of
neural network models of machine learning and the cubic matrix models. By combining
maps we get a map between machine learning models and gauge and gravity theories.
The basic maps extend between the transformation matrices that take the data among
the several screens or layers of the neural network model and the degrees of freedom
of the gauge theories. In the case that the dimensions are the same-otherwise they may
correspond to renormalization group transformations.
We should note that the correspondences we have deﬁned are stated for ﬁnite N –
ﬁnite matrices N × N, ﬁnite screens, as well as a ﬁnite number of loops through the
10

sequence. Let us comment on the objects and correspondences in the triangles in this
case. First, the matrix models are all well deﬁned. The universality, i.e. being able to
model gauge ﬁelds SO(N) or U(N), in any dimension d, and the map between different
d and N is well deﬁned at this stage [18]. In the mapping to the QFT on d-torus, for
instance, there is both infrared and ultraviolet regularization which can be seen by the
discrete rotations around each S1 having a ﬁnite number of states. So it takes a ﬁnite
amount of energy to transition or tunnel between any pair of related ground states. The
corresponding cut off gauge ﬁeld theories are well deﬁned. Indeed QFTs are often deﬁned
by taking limits on such cutoff QFTs.
The restriction to ﬁnite N for neural networks is standard. It is the ﬁnite neural net-
work that has been shown to learn as well as to satisfy Chiara Moletta’s criteria to carry
information, that is, to have at least two distinguishable states which can be swapped and
copied [26]. The limit N →∞is subtle and requires great care, even in the best known
case – that of QFT – a study that has involved many of the best mathematical and the-
oretical physicists over most of the past century. It will be interesting to try to use the
correspondence to study what the inﬁnite N limit of a neural network is, but that is left
for later work2.
The behavior of a learning machine may include steps where the degrees of freedom
are thermalized or quenched. These may correspond to putting the gauge theory in a
cosmological model.
Through these maps, one can then imagine building a future learning machine out of
the very gauge and gravitational ﬁelds with which our world is constructed. The coding
will involve choices of topology of the compactiﬁcations of the matrix models.
But if we can build a computer out of parts which amount to choices of topologies,
boundary conditions and initial conditions, couldn’t they arise naturally? Then we would
have arrived precisely at an understanding of quantum geometry as an autodidactic sys-
tem, able to learn in an unsupervised context.
As we will see, once we can describe a means for the physics we know to have come
about through an adaptive process, we can also describe the means for that process to
take on properties of self-reference, modeling, and what we can call learning.
We will then seek a general paradigm of systems, not necessarily modeled on biolog-
ical systems, that can ”teach themselves” how to successfully navigate landscapes with
increasing robustness, allowing for a space of future contingencies. These autodidactic sys-
tems will provide new paradigms for how physical systems may explore landscapes of
theories.
In order to examine this idea, we can consider contemporary, engineered systems that
appear to be able to modify their behavior in a way that is generally understood to be
”learning”: machine learning algorithms.
Roughly speaking, contemporary computer science distinguishes two kinds of learn-
ing algorithms: supervised and unsupervised. The ﬁrst kind are operated by engineers
2We note there are a small number of papers in the literature that study a class of neural networks that
are called “inﬁnite”, see [27].
11

to match new inputs to desired outputs. It is impressive that we can build such devices.
But the unsupervised models are perhaps more impressive, because they have only sim-
ple starting criteria and require few interventions. They have architectures that apply
principles like internal adversarial processes to propel themselves.
Unsupervised systems are currently harder to predict; they appear to be more likely
to produce novel output such as chess tactics that are otherwise difﬁcult to discover. Thus
far, such systems have not generated important new theories in physics, but they might.
Machine learning ideas have been successfully used in a variety of ways in physics,
such as a new framework for stating accepted laws [28]. When endowed with cleverly
chosen priors, machine learning models have been able to ”learn” aspects of physics such
as the Lagrangian and Hamiltonian formalism [29–31], renormalization group transfor-
mations [32,33], and have ventured into the realm of holography [34, 35]. There are also
instances where ﬁeld theoretic concepts have been used to elucidate the foundations of
neural networks; see [36,37].
When a model becomes sufﬁciently good at mirroring observable reality, it becomes
natural to ask if it could be considered as if it were an aspect of reality, not just an ap-
proximation. A sense that models are substantial motivated the discovery of previously
unsuspected phenomena, such as antimatter, which was predicted because of the avail-
able solutions to an equation. We are extending Wigner’s trust given to the ”unreason-
able” success of theory. If neural networks can predict or rediscover the theories we know
about, might nature not be as similar to the neural networks as to the theories?
2
Matrix models as learning systems
In this section we will provide an example of a mapping between the degrees of freedom
of two well studied theories. On the one hand we have the deep neural network - the two
layer network familiar from the Boltzmann and restricted Boltzmann models.
On the other hand we have a theory also very studied - General Relativity in 3+1
dimensions - in a chiral form due to Plebanski.
2.1
Matrix models
Let us ﬁrst talk about matrix models in general. These are models whose degrees of
freedom are large N matrices. They can be of various types, say orthogonal, unitary, etc.
The matrix elements represent the physical degrees of freedom.
A common example is [22–24]
H = Tr m2
2 {Xa ◦Xb}gab −
1
24g2 Tr{[Xa, Xb][Xc, Xd]gacgbd} .
(1)
This depends on a ﬁxed constant background metric for space gab.
12

The basic idea behind many constructions in high energy theory and condensed mat-
ter physics is that of effective ﬁeld theory with an ultraviolet cutoff, EP. The idea is that
observing some phenomenon at an energy E << Ep , you will measure the inﬂuences of
all operators that could be in the action or Hamiltonian consistent with the symmetries
of the problem. These will organize themselves in a power series expansion organized in
powers of the ratio r =
E
Ep.
In this kind of scenario we only need specify the simplest action or Hamiltonian that
displays the global symmetries thought fundamental. The other relevant terms will be
generated by renormalization group transformations. Effective ﬁeld theory is an espe-
cially transparent method to develop the low energy consequences of spontaneously bro-
ken symmetries.
In addition, it is natural in a matrix model to pack the multiplets of the remaining
symmetry into multiplets of the higher symmetry, while using the Lagrange multiplier
trick to reduce the degree of the equations of motion, or Lagrangian, while increasing the
size of the matrices. Using this trick repeatedly you can always reduce the action of a non-
linear theory to a cubic, as you cannot express non-linear dynamics as linear equations.
In this simplest form the equations of motion are at most quadratic equations.
Thus, if we take a single very large matrix, M b
a we can write a universal action [17–21]:
SUniv = −
1
g2N 2 Tr M 3 ,
(2)
whose equations of motion are merely
M 2 = 0 .
(3)
This has originally U(N) symmetry, which can be broken by a choice of solution in a
very large number of ways. By choosing a diverse set of solutions and expanding around
them, we can ﬁnd to leading order a very large number of gauge and gravitational the-
ories, including Yang-Mills theory and general relativity, invariant under a large choice
of symmetries, in a variety of space-time dimensions. Some of these are described in [18]
One example, a ﬁrst order form of general relativity, is the subject of Sec. 2.4.
We ﬁrst study a simple example of a continuous theory generated from this matrix
model, which is Chern-Simons theory.
2.2
Learning systems, gauge theories and laws that learn
The question we want to investigate here is whether learning systems, might be useful
as models of, or frameworks for novel formulations of fundamental theories. There is an
ambiguity we accept about whether such models of frameworks might be similar to what
goes on in nature, or whether they are only a rough, remote sketch. In either case, these
will be laws that learn, and the setting for that learning will be cosmology.
An important clue for us is that all of the frameworks we currently have for funda-
mental theories, namely Yang-Mills theories, general relativity and string theories, have
13

local gauge invariances, both internal and diffeomorphisms. They are theories whose de-
grees of freedom are expressed in terms of parallel transport. Can theories with these
kinds of gauge invariances be coded as learning systems?
Another question immediately appears: what will they learn? These fundamental the-
ories have several mechanisms for changing the effective laws, including spontaneous
symmetry breaking, phase transitions, compactiﬁcations and decompactiﬁcations, di-
mensional reductions, and enhancement, and others.
These various moves gives us the beginnings of a vocabulary, which a theory may
learn to think in.
All of these can be easily described in the language of matrix models, which means
that if we can establish the kind of correspondence we seek, we will be able to learn how to
speak about them in the language of machine learning. We should also emphasize that in
this emulation of the idea, changing laws does not necessarily mean a changing learning
architecture, though more generally it could. The parts that we suppose do change via
learning are the matrix weights, the optimization strategy, and the cost function.
Let us look at what we know about these relationships.
2.3
Neural network architectures
Let us then get to know the basic architecture of a class of learning systems. We begin
by reviewing the structure of the simplest class of deep neural networks - those with a
single internal or hidden layer. These are similar to the restricted Boltzmann machines
- but we consider several variants. We will then comment on several special cases: the
Boltzmann machine, both ordinary and restricted (RBM), and recurrent neural networks
with memory.
The neural network models have variables that live on nodes, representing neurons,
which are organized into sheets or layers. These are connected, and the strength of each
connection is given by a variable weight, which are among the degrees of freedom.
In Restricted Boltzmann Machines (RBMs) there are just two layers of nodes, N visible
nodes, va, a = 1, . . . N, and a hidden layer of M hidden nodes hb, b = 1, . . . M. We will
consider ﬁrst the case M = N.
In the case of the RBM each neuron is connected with all the neurons in the other layer
- but there are no connections within layers. We adopt that architecture here.
The matrix of weights deﬁnes a linear transformation from the visible layer to the
hidden layer:
hb = W a
b va .
(4)
External (visible) layers interact directly with the environment and internal, or hidden
layers, do not. A neural network with one or more hidden layers is called a deep neural
network. Hidden layers improve the expressive power of a neural network, since the
sequential layers of linear units stack together in a way that allows the entire system to
model complex non-linear phenomena. Transformations between adjacent pairs of layers
14

are linear maps between sub-spaces. A transformation that maps a layer with N nodes to
one with N ′ < N nodes is, from the physics perspective, a renormalization.
There can also be maps which take a layer to one with the same number of nodes,
which can be thought of as linear transformations that permute the nodes.
In the case of a circle of layers, we may denote these maps as
hI+1
b
= [W I,I+1] a
b hI
a ,
(5)
up until the last which is
v′
b = [W I,0] a
b hI
a .
(6)
Of course we can imagine more complicated architectures, with branchings of signals, but
we will not study them here.
We return to the simplest case of one external and one internal layer.
The following is a variant of the restricted Boltzmann model, where we substitute real
continuous variables for the discrete binary variables of the original model. This also
lets some of the dynamics be deterministic rather than stochastic. This will not prevent
us from identifying correspondences. The alternative is to modify the matrix and ﬁeld
theory models to depend on binary variables.
2.3.1
Review of the RBM, with continuous variables
The usual Boltzmann model has discrete binary variables. We modify the theory by using
continuous variables. These can be thought of as coarse-grained averages over regions of
the layers and over time of the binary variables.
The reason we do this is that we are seeking to make a correspondence between in-
telligent machines, or more properly, designs or mathematical models of such machines,
and the dynamics of space-time and gauge ﬁelds. But before we search for such a cor-
respondence there are some basic issues to be mentioned. One is the difference between
smooth ﬁelds and smooth evolution equations and discrete variables. Another is the irre-
versibility of almost all computers, while the ﬁeld theories are most often reversible. Still
another is that some of the machines are stochastic while the classical ﬁeld theories satisfy
deterministic equations of motion.
These are subtle issues and we will go into them in detail later, in section 5.
The last issue suggests that we see the classical ﬁeld theories as effective ﬁeld theories
that hold in the thermodynamic limit, in much the same way that the semi-classical limits
of quantum ﬁeld theories are described by classical equations.
For the moment, we will be proceeding by constructing an extension of the RBM in
which the degrees of freedom are continuous variables, which evolve continuously in
time. We will formulate this as a Hamiltonian system, deﬁned by a Lagrangian, (25)
below. The resulting equations of motion below, are time reversal invariant.
We will then look for solutions in which the time derivatives all vanish - or are very
slow. This may break the time reversal symmetry. There is of course nothing wrong with
15

solutions to a theory not having all the symmetries of the dynamics - this is a very com-
mon situation. In the present case, this will lead to the recovery of a set of equations very
similar to those that describe a Restricted Boltzmann Machine. The effective equations
which deﬁne this RBM sector break time reversal invariance.
The RBM model evolves by iterating the following discrete steps:
1. Initialization: The visible nodes, va, are set, as in a photograph or another form of
input. We also choose the density weight matrix, W
b
a
and bias rb.
2. During the forward pass the states of the hidden screen hb are set by the following
mapping. We also include a bias, rb
hb(t) = W a
b va(t) + rb .
(7)
Note that the va, ha and W a
b are dimensionless.
3. Compute the outer product of va and hb, the result of which is the positive gradient.
p b
a = vahb = va(W a
b va + rb) .
(8)
4. There follows the backward pass, during which we reset the visible nodes by map-
ping the hidden nodes onto them, plus another bias, ub. We denote the new values
of the visible layer, v′
a.
v′
a = (W T)b
ahb + ub ,
(9)
Notice that we use the transpose of the weight matrix to make the backwards pass.
5. Repeat the forward pass to
h′ b = W b
av′
a + rb .
(10)
6. Compute the outer product of v′
a and h′
b, the result of which is the negative gradient.
N
b
a
= v′b
a h′
a .
(11)
7. This is followed by an update of the weights and the biases, via some learning
rate ϵ times the positive gradient minus the negative gradient. The biases are also
updated analogously,
∆W b
a = ϵ(vahT
b −v′
ah′T
b ) ,
(12)
∆ra = ϵ(va −v′
a) ,
(13)
∆ub = ϵ(hb −h′
b) .
(14)
16

The whole process is then iterated until a convergence criteria is met.
To understand these a bit better, we combine (7) and (9) to ﬁnd
˙va(t) =

W T(t) ◦W(t) −I
 a
b vb(t) + W aT
b rb + ub ,
(15)
To see the structure let us for a moment set the biases, rb and ub to zero.
˙va(t) =

W T(t) ◦W(t) −I
 a
b vb(t) ,
(16)
The weights evolve subject to
˙Wab = −α
2

˙vT
a hb + vT
a ˙hb

= −α
2
d
dt
 vT
a hb

(17)
We see that there are limit points and limit cycles given by W b
a = W T
b
a
is orthogonal,
which implies both
˙va = 0 and
˙W a
b = 0
(18)
This implies
0 = −α
2
d
dt
 vT
a hb

(19)
Thus, starting with a general W and v, we get a trajectory through the space of possible
“laws” that settles down when it runs into a orthogonal W. As these are unitary, we have
a system that converges to a real version of quantum mechanics.
One can show that ¨W b
a and ¨va are functions of the initial data W b
a and va.
Now we include the biases and we ﬁnd (15), which gives us a real,orthogonal form of
quantum mechanics
˙Wab
=
−α
2

˙vT
a hb + vT
a ˙hb

= −α
2
d
dt
 vT
a hb

,
=
−α
2
 
W T(t) ◦W(t) −I
 c
a + W ◦bT + uT
b vT
c

vb
+
vT
a
 
W T(t) ◦W(t) −I
 c
b vT
c + W ◦bT + uT
b

(20)
The orthogonal ﬁxed points are, as before, at (18)
˙Wab
=
0 ,
(21)
˙vc
=
0 ,
(22)
W ◦W T
=
I ,
(23)
W ◦bT
=
−uT
(24)
Thus, this is generically a time-asymmetric non-linear dynamical system, which has
ﬁxed points (or rather limit sets) which are the orbits of orthgonal transformations. The
17

dynamics is time reversible and orthogonal on the limit sets. Associated to each limit set
will be a basin of attraction of conﬁgurations that converge to it.
Each limit set deﬁnes a quantum dynamics whose time evolution operator is an or-
thogonal matrix.
Note that had we used complex weights and values, we would have gotten to the
same place, but with unitary dynamics governing the limit sets: ie quantum mechanics.
This may be useful for talking about the evolution of laws as well as the measurement
problem.
We would like to go one more step, to formulate the learning machine in terms of
continuous time evolution. We have two stages of dynamics: the ﬁrst where we hold
the weights and biases ﬁxed and evolve the layers, which alternates to the gradient ﬂow
stages where we do the opposite. Can we unify these into a single dynamical system?
One approach is the following. We unify the two stages within a single Hamiltonian
system, which is governed by an action principle of the form.
S =
Z
dt (−H[v, h, W, r, b])
(25)
Where the Hamiltonian, H is,
H[v, h, W, r, b] = vaW
b
a hb −raha −bava + γ
2(vava + haha) + ω2
2 (W a
bW a
b)
(26)
Let’s look at the equations of motion:
−W a
bvb
=
δS
δha
=
γha + ra
(27)
W Ta
b hb
=
γva + ba
(28)
−ω2W a
b
=
havb
(29)
We get the equations governing the RBM:
ha
=
γ−1  W a
bvb −ra
(30)
va
=
γ−1  W Ta
b hb −ba
(31)
W a
b
=
−1
ω2havb
(32)
The time derivative of (32) gives us the gradient rule of the RBM, which is (17).
2.3.2
Features of learning systems
• To each way of connecting the outside layer to the hidden layer, there corresponds
an adjacency matrix. Dynamics of the networks, such as those which occur in ma-
chine learning, are expressed in terms of operations on these matrices.
18

• But large matrices are often used to represent gauge ﬁelds and their dynamics, in-
cluding their self-coupling and their coupling with matter ﬁelds.
• The question is whether we can take these correspondences all the way across, to
represent the dynamics of gauge ﬁelds in terms of the dynamics of weights in ma-
chine learning? We will show in this section that we can. The main reason is that
we can restrict the matrices of connections and weights so that they code transfor-
mations from one layer to another. That is, they describe parallel transport among
the layers. So they are about the same kind of objects that gauge theories are based
on.
• The matrices of weights, deﬁned on networks, represent transformations of a sep-
arate set of degrees of freedom, which are various layers in which are encoded the
patterns that learning machines learn to recognize.
• By combining sequences of such transformations, we see that they satisfy the group
axioms. What sorts of groups are they? Because we want their properties to scale
as the sizes of the layers increases (indeed to very large N), it seems these are not
ﬁnite groups, they must be representations of Lie groups. This implies they will
have generators which are in the adjoint of some Lie algebra, A.
• The layer variables seem to transform linearly under the action of the weight ma-
trices. They are thus directly analogous to the matter ﬁelds of conventional gauge
ﬁeld theories. They may then be decomposed into combinations of representations
of G.
2.3.3
Features of matrix models of gauge theories
• Let us consider a matter ﬁeld, Φ, or a gauge ﬁeld, Aa, which is valued in a represen-
tation of a Lie group. Typically matter ﬁelds are valued in a fundamental represen-
tation while gauge ﬁelds are valued in the adjoint representation.
Given a ﬁeld theory, we can construct a matrix model by setting all the derivatives
to zero. This gives us a reduction to constant ﬁelds, i.e.
∂bΦ = 0,
∂bAa = 0 ,
(33)
under which the Φ and Aa are matrices.
The mapping involves sending ﬁelds to N × N matrices. That is, we set all deriva-
tives to zero so that,
F AB →[A, A]AB,
D ∧BAB →ϵabcd[Aa, Bbc]AB .
(34)
The resulting action is invariant under two kinds of gauge invariances.
19

• First, under the homogeneous SO(N) gauge transformations:
Aa →g−1 ◦Aa ◦g,
Φ →g ◦Φ ,
(35)
depending on the representation.
• In addition, gauge invariance of the continuum theory is, unlike (35), inhomoge-
neous. This implies a translation gauge invariance in which the action S or Hamil-
tonian H is invariant under translations of the form,
A j
ai →A j′
ai = A j
ai + I
j
i ca ,
(36)
where ca is time invariant.
This means that the dynamics of A j
ai must be expressed through commutators, i.e.,
[Aa, Ab], which is the constant-ﬁeld limit of Fab, and [Aa, Φ], which is the constant
ﬁeld limit of DaΦ.
• There is also an inverse transformation from matrices to gauge ﬁelds on compact
manifolds, described in [10].
2.4
Plebanski gravity as a learning system
To illustrate the points we have made, we give a quick example of a physical theory that
can be expressed as a matrix model, and through that, mapped to a corresponding neural
network model - general relativity.
We described dynamics of the restricted Boltzmann learning models in Sec. 2.3.
Plebanski’s version of general relativity [13,38] is not known to many people outside of
specialists in quantum gravity. This is unfortunate, as it is both elegant and compact; the
action is made of quadratic and cubic terms, and so the equations of motion are quadratic
equations. Remarkably, this is the case also with the equations and Hamiltonian of the
RBM.
The degrees of freedom for Plebanski gravity are a left handed SU(2) connection AAB
a
whose curvature two-form is written F AB = dAAB +(A∧A)AB, and a two-form BAB (also
far valued in the vector of SU(2) and hence symmetric in the spinor indices). In addition,
there is a scalar ﬁeld ΦABCD which is pure spin two in SU(2) and hence totally symmetric
in spinor indices.
There is a constraint on the two forms B,
B(AB ∧BCD) = 0 ,
(37)
which is satisﬁed if and only if there is a frame ﬁeld, eAA′ such that
BAB = e(A
A′ ∧eB)A′ .
(38)
20

We are going to make the matrix version, which sets all the derivatives to zero. For
simplicity we will study the Euclidean signature case in which all ﬁelds are real. We will
also restrict to cases where the time variable is periodic, with period 2πβ with β inverse
temperature.
We will use the simple action (65) and take for the single matrix
M = Φ ⊗γ5 + AaI ⊗T I ⊗γa + BabI ⊗T I ⊗γabγ5 .
(39)
Here let γa be the four Dirac gamma matrix, a, b, c = 0, 1, 2, 3 and let us write γab =
[γa, γb].
The matrix theory action is (65).
S = Tr M 3 = Tr(AaIAbJBcdK)ϵabcdf IJK + Tr(ΦIJBabIBcdJ)ϵabcd ,
(40)
where
ΦIJ
mn = [φmn]j
i(T IT J)i
j .
(41)
We will also impose the constraint
[Φmn]i
i = −Λδmn ,
(42)
where Λ is the cosmological constant.
We now can go back to a theory of smooth functions on a four manifold. To do this
we invert the reduction to matrix variables, giving us back ﬁelds.
Using the compactiﬁcation trick when we take N →∞we have the emergence of a
four-torus,
Tr →
Z
T 4 Tr ,
(43)
the action in terms of smooth ﬁelds is
SPl =
Z
M
BAB ∧FAB −Λ
3 BAB ∧BAB −1
2ΦABCDBAB ∧BCD .
(44)
There is of course much more to say about Plebanski’s formulation of general relativ-
ity.
We want to show the correspondence to neural networks. So our next step is to show
that the equations of motion of Plebanski gravity can be mapped to the equations of a
quadratic neural network – namely, one with two layers.
To do this we employ the fact that each can be mapped onto a neural network mode.
This is in particular a two layer network, it is essentially the one employed in restricted
Boltzmann models.
The mapping involves sending ﬁelds to N × N matrices, as in matrix models of gauge
theories. That is, we set all derivatives to zero so that,
F AB →[A, A]AB,
D ∧BAB →ϵabcd[Aa, Bbc]AB .
(45)
21

Next we construct a correspondence from the matrix representation of Plebanski to
the degrees of freedom of the neural network.
We make the following identiﬁcations:
• Visible Layer: The B ﬁeld,
B = BAB
ab P a ∧P b ⊗τAB ,
(46)
or, equivalently, the frame ﬁeld, eAA′, such that
BAB = e(A
B′ ∧eB′B) .
(47)
Note that the last relation is a quadratic equation. Solving and inverting quadratic
matrix equations play the role here of the gradient ﬂows in an RBM.
• Hidden Layer: the left handed SU(2) connection matrix is represented,
AAB
a (x) →A = AAB
a P a ⊗τAB ⊗SU(N) .
(48)
Note τ AB = τ BA are the SU(2) Pauli matrices, P a are the translation generators in
R3. N is taken very large; the QFT is claimed to be reproduced in the limit N →∞
The visible layer is connected to the hidden layer by the weights W, which are maps
from Sym⊗(0, 1) to Sym⊗(0, 1). We now call them ΦABCD, which are valued in the
spin-two representation, so they are completely symmetric in spinor indices,
Φ[AB]CD = 0 .
(49)
The dynamics consists of a sequence of a “forward pass”, a “backwards pass”, each fol-
lowed by an extraction of a matrix square root (rather than a gradient ﬂow). We note
that while RBM training can involve a non-zero temperature, which allows for stochas-
tic training, here we consider the deterministic T = 0 variant. For the time being the
two biases are turned off (these are the currents). The cosmological constant Λ could be
regarded as playing the role of a bias.
We now iterate the following steps, which are parallel to the steps that deﬁne the neural
network model.
1. Initialization: We set n = 1 and choose initial guesses for ΦAB
(1) CD and eAA′
(1) . Notice
that the latter is equivalent to choosing the metric
gµν = eAA′
µ
⊗eνAA′ ,
(50)
or self-dual two form subject to constraints (37),
BAB = e(A
B′ ∧eB)A′ .
(51)
22

2. Forward Pass: We compute F AB
(n) by
F AB
(n) →F AB
(n+1) = ΦAB
(n) CDBCD
(n) −Λ
3 BAB .
(52)
3. First Inversion: Update A
A(n) →A(n+1) .
(53)
using the new F(n+1) to satisfy the two constraints:
F AB
(n+1) = [A(n+1), A(n+1)](AB) ,
(54)
ϵabc[A(n+1)
a
, Bbc
(n)] = 0 ,
(55)
holding B(n) ﬁxed.
Next, update the ΦBCDE,
Φ(n)
BCDE →Φ(n+1)
BCDE = 0 ,
(56)
holding A(n+1) ﬁxed
[A(n+1)
E(A ΦE(n+1)
BCD) ] = 0 .
(57)
4. Backward Pass:
Finally, we update the self-dual two form, BAB,
BAB
(n) →BAB
(n+1) ,
(58)
by setting
BAB
(n+1) = Φ−1ABCD

[A(2), A(2)](CD) + Λ
3 δAB
CD

,
(59)
together with the quadratic constraint
B(AB
(n+1) ∧BCD) = 0 .
(60)
At this point we have updated each of the ﬁelds once
(AAB
(n) , BAB
(n) , ΦABCD
(n)
) →(AAB
(n+1), BAB
(n+1), ΦABCD
(n+1) ) .
(61)
We next impose a test of closure on these matrix ﬁelds. We may go around this loop
however many times it takes to converge to a solution which is when
(AAB
(n+1), BAB
(n+1), ΦABCD
(n+1) ) ≈(AAB
(n) , BAB
(n) , ΦABCD
(n)
) .
(62)
5. Second Inversion: Finally we update the frame ﬁeld, eAA′ by solving for
eAA′
(1)) →eAA′
(2) = BAB
(2) = e(A
B′(2) ∧eB′B)
(2)
.
(63)
23

3
Cubic learning systems
We now deﬁne a new class of intelligent machines called cubic learning systems; these
have three layers in total, one external and two internal. We ﬁnd direct correspondences
to a set of cubic matrix models, and through the latter’s correspondence with gauge and
gravitational ﬁeld theories, to those theories as well.
Related to cubic matrix model is the idea of triality and quantum reference frames.
This leads from a principle of background independence in which our fundamental the-
ories should be formulated independently of backgrounds they are expanded around.
Furthermore, the backgrounds themselves should be subjected to dynamics and not be
ﬁxed. Consider now the Born duality x →p, p →−x. What is clear is that in this case
time can be considered rigid, independent of the x and p and generally non-dynamical.
Consider now, instead of a duality, a triality between position, momentum and time. Con-
cretely, the standard Poisson bracket is now replaced by a triple product. One can make a
connection to the cubic matrix model by promoting x, p,
d
dt to large matrices from which
you can get out the symplectic structure.
For a large number of degrees of freedom, you can get out dynamics of Heisenberg
operators. In the Heisenberg picture you are in a dynamical picture of the operators -
these are matrices where matrix elements can be thought of as hidden variables. One
may translate the Born rule in quantum mechanics P = |⟨α|β⟩|2 to the form P = Tr(ABI)
where Ab
a = αaα†b, Bb
a = βaβ†b are the density matrices corresponding to states α, β and
I is the identity matrix. In the context of the cubic matrix model, we can think of rein-
terpreting the concept of triality as a statement for the laws. For example, consider the
matrices A, B, & C which we can think of as gauge ﬁelds. The dynamics for this theory
without fermions is given by,
˙A = [B, C] .
(64)
An interesting question to ask is whether the quantum dynamics of the matrix model
could be realized in the context of a machine learning algorithm.
Inspired by this rich space of theories, we formulate in this section a learning archi-
tecture for the general class of cubic matrix models. An autodidactic system then has the
ability to learn its laws by exploring the space of effective theories using moves which
are (de-)compactiﬁcations, dimensional reductions and expansions, symmetry breaking
and restorations, and possibly others. We begin by introducing general architectures for
neural networks, including some examples which include consequencers in the form of
memory modules. We then describe the precise relationships between discrete topolo-
gies, learning systems, and gauge ﬁeld theories, after which we propose a set of axioms
for the architecture and dynamics for cubic learning systems. We show that cubic learning
systems provide a concrete bridge between matrix descriptions of topologies and gauge
ﬁelds, which will be a critical step used in the next section, where we explore a handful
of examples of autodidactic dynamics.
24

3.1
Learning architecture of cubic matrix models
We seek an evolution rule for the weights of a neural network that can correspond to the
dynamics of a gauge theory, which in turn can evolve in time in a way that would reﬂect
nature learning its laws.
The matrices, or weights, are represented by an N × N matrix, with N taken very
large. These may be viewed either as matrices of weights or as adjacency matrices which
specify a large decorated graph.
The dynamical law, whether evolving or static, generates a sequence of such matrices,
{X1, X2, X3, . . . , } ,
(65)
which represents their evolution in time.
As shown in [39], a large class of these can be realized with the following assumptions:
1. The evolution rule should mimic second-order differential equations, as higher or-
der equations can breed instabilities. Moreover, no higher than second derivatives
appear in any of the ﬁeld or particle theories we know. So two initial conditions
should be required to generate the evolution. We should then need to specify X0
and X1 to generate the full sequence. Therefore, we are interested in rules of the
form,
Xn = F(Xn−1, Xn−2) .
(66)
2. For massive matter ﬁelds, the changes should be small from matrix to matrix, at
least given suitable initial conditions. This is needed so that there can be a long
timescale on which some of the information in the matrices is slowly varying. This
makes it possible to extract a notion of slowly varying law acting on a faster varying
state. We will ask that for matrix representation of matter ﬁelds,
X = F(X, X) .
(67)
For gauge ﬁelds, however, this is ruled out by the translation gauge invariance (36).
3. We require that the evolution rule be non-linear, because non-linear laws are needed
to encode interactions in physics. But we can always use the basic trick of matrix
models of introducing auxiliary variables, through the use of repeated instances of
the tensor product decomposition to expand the matrix, in order to lower the degree
of non-linearity. As we take N larger and larger, there is always room for more. This
accords with the fact that the ﬁeld equations of general relativity and Yang-Mills the-
ory can, by the use of auxiliary variables, be expressed as quadratic equations3 [39].
The simplest non-linear evolution rule will then sufﬁce, so we require a quadratic
evolution rule.
3As in the Plebanski action, for instance.
25

4. The basic theory should have a big global symmetry group, G, that can be spon-
taneously broken in various ways to reveal different fundamental theories. Our
theory will then unify gauge theories with diverse continuous and discrete symme-
tries [39].
A simple evolution rule that realizes our desired dynamics is
Xn = Xn−1 + [Xn−1, Xn−2] .
(68)
This rule is not unique, but it is nearly so. It is easy to derive the general rule satisfying
the four requirements just mentioned.
On the other hand, if we drop the translation symmetry (13), we ﬁnd a more restricted
solution that contains just the commutator term,
Xn = [Xn−1, Xn−2] .
(69)
As each move has only a single output and two inputs, we need no more than three
matrices at once. We relabel the time counter n to be
n →
jn
3
k
,
(70)
so that the set of three matrices form the sequence,
{A1, B1, C1, A2, B2, C2, A3, . . .} .
(71)
Then there is a simple evolution rule that preserves the forgoing as well as the permuta-
tion group on three elements:
An+1 = An + [Bn, Cn] .
(72)
and cyclic,
An+1 = An + [Bn, Cn] ,
Bn+1 = Bn + [Cn, An] ,
Cn+1 = Cn + [An, Bn] .
(73)
Again, in the case that we also impose the gauge/translation invariance conditions, we
ﬁnd
An+1 = [Bn, Cn] ,
Bn+1 = [Cn, An] ,
Cn+1 = [An, Bn] .
(74)
26

Thus the various restrictions we have imposed have led to a small class of matrix
theories. The degrees of freedom are three N × N matrices,
An , Bn , Cn ,
(75)
where n represents a discrete time. The matter ﬁelds are in some representation of SO(N).
The possible terms that are invariant, to leading order, under the full set of gauge invari-
ances, make up a simple Hamiltonian:
H =
X
n
 Tr(AnBnCn) + ΦTXn ◦Φ

.
(76)
This simplest possible matrix model contains (by virtue of various compactiﬁcations,
symmetry breaking, and so forth) most of the theories of interest for fundamental physics [39].
Concretely, one can obtain different physical theories from (76) using a combination of
tensor product decompositions, M = A × B, and circle compactiﬁcations realized by the
substitution A = [i∂θ] + [a(θ)]. Notice that (76) does not include any spatial or temporal
dependence, thus this step serves as a means to introduce dimension.
This is our Rosetta stone. Next we demonstrate how to translate these, plus a speciﬁ-
cation of the cosmological setting, into a learning system.
3.2
Dynamics of cubic learning systems
We can now sketch the architecture of a type of recurrent neural network that captures
the dynamics of the cubic matrix models.
Our model contains three layers, each represented by an N-dimensional vector,
Za
n = (an, bn, cn) ,
(77)
where n = 1, 2, , 3, . . . is an integer valued time variable (the clock). The three layers are
arranged in a loop as in Fig. 1.
There are also three weight matrices. As discussed above these form or generate a
group, which we will take to be SO(N). We choose to represent them by their Lie algebra
generators.
Li
n = (An, Bn, Cn) ,
(78)
which are antisymmetric matrices. At each time n we carry out the following update
rules:
An+1 = [Bn, Cn] + bT
nan and cyclic ,
(79)
bn+1 = eAn ◦an and cyclic .
(80)
If we want to thermalize to learn, then every three moves, which corresponds to one
time round the loop, we apply one of the thermalization algorithms to induce
Za
n = (an, bn, cn) ∼Za
n+3 = (an+3, bn+3, cn+3) .
(81)
27

an
bn
cn
An
Bn
Cn
Figure 1: Cycle symbolizing the relations (79), (80)
We do this by thermalizing with respect to a Hamiltonian (actually, just the potential
energy; there is no kinetic energy in this quenched version),
Hn = Tr eAeBeC + bT
n+1eAn ◦an + cT
n+1eBn ◦bn + aT
n+1eCn ◦cn .
(82)
We may want to study a weak ﬁeld expansion, so we scale by a small dimensionless
coupling constant g, to ﬁnd, to leading order in g2,
Hn = g Tr(AnBnCn) + bT
n+1[1 + gAn◦] ◦an + cT
n+1[1 + gBn] ◦an + aT
n+1[1 + gCn] ◦cn . (83)
3.3
The correspondence
We are now in a position to claim the following correspondence result.
We specify a solution to a cubic matrix model by the following parameters
• Pick a gauge symmetry, H to be the gauge symmetry after the ﬁrst level of sponta-
neous symmetry breaking. For example, to incorporate the standard model through
an extended Plebanski [14,15] embedding, we must pick
H = SUL(2) ⊗SU(3) ⊗SU(2) ⊗U(1) ⊗O(M)
(84)
28

The ﬁrst SUL(2) gives the chiral half of the local Lorentz gauge invariance, while the
ﬁnal M dimensions code the translations around a set of D tori. Here the radius of
each torus Ri is given by
Ri = Mil,
X
i=1
DRil = M .
(85)
• Pick a large, but ﬁnite N such that
H ⊂SO(N)
(86)
• Choose the topology, such as
[S1]x ⊗[S2]y
(87)
This leaves a global symmetry, R.
• We break the SO(N) symmetry to localH and global R by ﬁnding a classical solution
of the following form that preserves them.
The background geometry is speciﬁed by the three matrices A0, B0, C0 such that
[A0, B0] = 0, [B0, C0] = 0, [A0, C0] = 0 .
(88)
We next expand around the solution (88)
A = A0 + α B = B0 + β C = C0 .
(89)
The perturbations satisfy
[A0, β] = 0 [C0, α] = β [C0, β] = −α .
(90)
These describe a regulated gauge-gravity theory, on a closed 4 + D dimensional space-
time. with spatial topology ﬁxed.
We showed in the previous sub-section that the same data proscribes a cubic learn-
ing system. Thus we have a correspondence between the three theories. In particular the
correspondence connects a learning machine of the class deﬁned in Sec. 3.2 with a gauge
invariant QFT.
Before we close this section we should also make it clear what we do not have.
• We do not have an equivalence. The gauge and gravity theories are only complete
in the limit N →∞. But we don’t have a deﬁnition of the learning architecture in
that limit.
• The learning machines employ thermal effects to learn effectively in which the de-
grees of freedom are heated and then quenched. We conjecture that would employ
embedding our learning systems in cosmological models. But we have yet to work
out the details of this.
29

3.4
Cubic matrix model and Chern-Simons theory
The cubic matrix model may be reformulated as follows.
Deﬁne the metamatrix
M = τ a ⊗Aa ,
(91)
where a = 1, 2, 3, τ a are the three Pauli matrices and the three Aa are (N −2) × (N −2)
dimensional matrices.
The action is then
S = TrM 3 = ϵabcTrrAaAbAc ,
(92)
and the equations of motion are
[Aa, Ab] = 0 ,
(93)
We specify a solution to a cubic matrix model by the following parameters
• Pick a gauge symmetry, G.
• Pick a three dimensional topology, the simplest is the three torus, T 3.
• Pick three matrices, Da that solve for every N the equations of motion (93).
• Expand around each solution
Aa = Da + aa .
(94)
In the limit N →∞the Da act as derivatives and the theory that emerges is Chern-
Simons theory
S∞=
Z
T 3 Tr(a ∧da + a ∧a ∧a)
(95)
One reason that this is interesting is that Chern-Simons theory regarded as a func-
tional of embedded Wilson loops provides a class of knot and graph invariants. The
connections we have sketched here suggest that machine learning may offer a powerful
tool to creating and evaluating knot invariants4
Finally, we need to put the matter degrees of freedom Ψ back into the picture.
We will represent matter by an SU(2) spinor valued matrix ΨA, and dual spinor valued
matrix, with A = {0, 1),
We write the full matrix Chern-Simons action
SMCS = ϵabcTrrAaAbAc + TrΨ†
A[Ma, ΨB]σaAB ,
(96)
4For other approaches see also [40] .
30

This matrix theory is well deﬁned. When we take a limit to inﬁnite dimensional ma-
trices this goes to the full continuum Chern-Simons theory,
S∞=
Z
T 3 Tr(a ∧da + a ∧a ∧a)].
(97)
The most important thing to understand is the inﬂuence of a ﬁxed background metric,
η
Trσaσb = ηab
(98)
As a result the Chern-Simons theory, including coupling to a spinor ﬁeld is no longer
topological.
We can read off the neural network model from the form of (97 ); a diagram of it is
shown in Figure 1.
The screen degrees of freedom are distributed as follows. On the
a
mod3 screen we have
the variables
ΨA = σa
ABΨB
a
(99)
which are parallel transported to the next screen (
a
mod3 + 1) by taking a commutator with
Aa.
4
Protocols for autodidactic systems
We set out to explore whether the notion of a self-learning system could be relevant to
fundamental physics. Namely, we are interested in systems for which the rules governing
time evolution are partly learned from the features of the explored conﬁguration space.
We have argued that the idea of laws that learn gives us a powerful framework for
going beyond the earlier concept [4,8] of laws that evolve in time.
When we speak concretely of laws that learn, we realize that the usually strict lines
between laws, theories, states, and solutions of theories seem to break down [39].
How would we recognize such a system? One necessary, but not sufﬁcient require-
ment is that the late-time behavior of such systems will be highly sensitive to the initial
conditions and early-time dynamics. Another is that the dynamics includes a feature we
called a consequencer. This may be a simple feedback loop or a highly elaborate set of
hidden variables in a recursive network.
In this section we discuss several protocols for autodidactic systems, as well as some
preliminary computational experiments. A protocol deﬁnes a dynamic architecture with
rules for change that lend themselves to interpretations as learning strategies or reward
functions. Generally speaking, the autodidactic paradigm suggests none of these may be
ﬁxed a priori, since one history guided by a set of rules might transform itself to be guided
by altered rules, though in practice it is often helpful to limit the number of ways in
which the system may evolve. Autodidactic systems are distinct, however, from emergent
cosmological models that apply a priori growth rules consistently, as in [41].
31

We describe experiments in which small autodidactic systems are allowed to develop
in simulation so that we can observe emergent properties. In all experiments, the free
variables that describe the systems are expressed in terms of matrices.
Therefore, they can be considered in the context of the correspondence demonstrated
in previous sections. Compatibility with the correspondence leaves open a number of
possible interpretations for how autodidactic systems, such as the ones in the experiments
to follow, should be interpreted in the context of physics.
In the examples previously explored, there was an explicitly stated way that a law
could also be a part of a learning process, and part of the history of a universe, but in some
of the examples to come it might be argued that there is more room for interpretation. We
will do less to explicitly tie the models in this section to laws.
For instance, when we see structures that resemble deep learning architectures emerge
in simple autodidactic systems (as shown in Figure 9) might we imagine that the oper-
ative matrix architecture in which our universe evolves laws, itself evolved from an au-
todidactic system that arose from the most minimal possible starting conditions? That
notion correlates with a more complicated hypothesis of histories for the early universe.
An alternative is to suppose that a matrix structure substantial enough to support law
evolution was part of the starting conditions.
Our goal in this section is not to express preference for one story or ontology over
another, but simply to observe how emergent properties in small autodidactic models
display properties that are relevant to learning universe ideas.
We have already discussed two protocols whose degrees of freedom can be put in cor-
respondence with those of a gauge or gravitational theory. We were able to ﬁnd a formu-
lation of general relativity and put it in correspondence with a two layer neural network.
We then invented a class of three layer neural networks and put them in correspondence
with Chern-Simons theories, which are topological quantum ﬁeld theories.
We will continue in Sec. 4.1 by discussing learning using the renormalization group.
Using either the renormalization group neural network architecture or the RBM archi-
tecture, one can construct a learning algorithm which attempts to maximize the mutual
information between the learning system and its environment, without restriction to any
particular learning strategy. This approach is inspired by information theory and is mo-
tivated by the Wilsonian picture according to which quantum ﬁeld theories which have
good ultraviolet completions do so because their high energy behaviour is dominated by
an asymptotic scaling governed by the renormalization group.
We then discuss in Sec. 4.2 another protocol which uses the RBM architecture with a
novel learning strategy: the Principle of Precedence. Precedence describes an optimiza-
tion technique in which the future behavior of a system depends not just on its cost func-
tion, but also on its prior set of states. Precedence can be implemented in a number of
ways – as an attention layer, a memory module such as the LSTM or GRU, a set of hidden
variables, etc. We give an example of the hidden variable version using an RBM and then
provide an example of a continuum limit of a learning process.
The fourth method we study in Sec. 4.3 likewise uses self-attention via self-sampling
32

procedures. While the Principle of Precedence uses a measure on prior states, self-sampling
is used to grow graphs, so that prior states are described by subgraphs and the measure
on the prior is encoded in the measure on subgraphs. This compact representation is
particularly useful when we want to model a growing discrete system using a recurrent
learning architecture.
Another protocol which uses a recurrent learning structure is described in Sec. 4.4.
We introduce a cost function inspired by graph theory and quantum foundations called
the variety, which is, loosely speaking, a measure of topological heterogeneity. We use
a learning strategy based on simulated annealing to generate graphs which maximize
variety and show these graphs are distinct from the set of random graphs.
Finally, in Sec. 4.5 our last protocol describes another recurrent learning system that
uses annealing. We consider the components required for a discrete system to self-assemble
into a discrete manifold, either a simplicial manifold or a random geometric graph. Be-
cause it is not clear a priori whether geometry is bound to emerge from a pre-geometric
system, we mainly focus on a learning procedure in which the system optimizes the pa-
rameters of its cost function in order to generate a geometric system.
An autodidactic protocol must give rise to a consequencer, as deﬁned earlier; a reser-
voir functioning as an accumulator of information in a learning process. Here is how
consequencers can form in the above examples:
• In the RG section: Renormalization is by deﬁnition a consequencer generator pro-
vided it is part of a feedback dynamic. If renormalizations are relevant to the ongo-
ing evolution of a system, then that system is driven by an exemplary consequencer.
Renormalization in that case partitions the most causally relevant features of the
system.
In the Precedence section: Precedence is also by deﬁnition a consequencer genera-
tor; that is the very notion.
• In the Self-sampling section: The example of the “persistent hub” shows how a
consequencer emerges in self-sampling autodidactic systems.
• In the Variety section: In this case, the consequencer emerges negatively, as a pro-
gressive reﬁnement of adjacent conﬁgurations that have not yet appeared.
• In the Geometric Self-assembly section: Here the self-attention or precedence func-
tion is a form of consequencer, but so is the evolving optimization of the annealing
schedule.
The consequencer is no more and no less than the information that must change when
learning occurs.
We deﬁned ”learning” earlier in physical terms. Learning includes adaptive processes
that become anticipatory, doing ”more than they need to” based on any isolated instance of feed-
back or perhaps we can choose a deﬁnition that maximizes the causal impact of an adaptive
33

subsystem. As stated earlier, there need not be an abstractable “thing learned” - anything
symbolic or semantic - for a system to learn something, even according to a more ca-
sual and causal sense of information, as is often attributed to Gregory Bateson, as in the
already quoted phrase, a difference that makes a difference. 5
This interpretation of learning in the Batesonian sense was explored in [43] as info-
autopoiesis, which describes how information about a system may be created by the system
itself. Rather than subscribing to the notion that information exists outside matter and
energy, the Batesonian concept of learning is that information is described by differences
in matter and energy variables; hence, recursive dynamics characterize a fundamental
mechanism for an autodidactic system to learn its laws and self-organize accordingly.
The idea of Batesonian information is similar to, but not identical to the idea of a
consequencer. A ”lucky” cosmic ray that alters a gene is Batesonian, but not part of a con-
sequencer. Consequencers persist as structures in time even when physical components
are replaced, and are not random, while Batesonian events can be singular and random.
However, a consequencer is made of Batesonian information.
4.1
Renormalization group learning
A key aspect in many of the scenarios for emergent growth rules is the identiﬁcation
of relevant degrees of freedom, which may serve as a basis for such rules. One of the
idea threads stretching through our work is the notion that dynamical rules can be found
implicit in the properties of some substructure, which turns out to be both inﬂuential and
persistent. For example, at the end of Sec. 4.3, we have speciﬁed a number of proposals
for growth using self-sampling, which we hope may realize this idea.
This topic sits on the interface between physics and machine learning, where impor-
tant progress has been made in both directions. Let us brieﬂy review some of the key
ideas available in the literature6
4.1.1
Review of basic concepts
The position-space renormalization group (RG) procedure of Kadanoff [45] works by
rewriting a model in terms of coarse-grained degrees of freedom. In principle, any pos-
sible coarse-graining can be chosen; the RG transformation will result in an effective
Hamiltonian, which will in general contain all possible terms allowed by the symmetry
of the problem, along with scale-dependent coefﬁcients (coupling constants). The “right”
coarse-grained degrees of freedom are ones which result in a simple Hamiltonian with
a ﬁnite set of relevant couplings; for example, in the Ising model we start out with only
5We will not wade into the question of what should or should not be properly attributed to Bateson, but
we will speak of Batesonian information here since that is almost a common usage. Alternative terminolo-
gies have been proposed [42].
6For another approach to the relationship between deep learning and the RG see [44] Our view is that it
is that and much more.
34

nearest-neighbor interactions, and we want to preserve the locality in the renormalized
Hamiltonian.
In [32, 33], the authors propose how one can formulate this procedure in a way that
can be translated into a machine learning algorithm. They start by promoting all physical
degrees of freedom to random variables. As we discuss below, some of this work [46] is
inspired by tensor network methods for representing quantum states such as MERA [47];
when trying to apply a quantum mechanical method to classical physics it is natural that
we end up working with probability distributions. In [33], the system is partitioned into a
subsystem V, from which we want to capture several coarse-grained degrees of freedom,
and the “environment” E, which is the complement7. In the usual real-space renormal-
ization group story for, say, the 2D Ising model, V corresponds to square subsets that are
coarse-grained. Then, the “best” choice of coarse-grained variables H are those functions
of degrees of freedom in E which maximize the mutual information between variables in
H and variables in E.
The mutual information between two probability distributions PX and PY is deﬁned
as
I(X : Y ) =
X
x∈X
X
y∈Y
PX,Y (x, y) log
 PX,Y (x, y)
PX(x)PY (y)

,
(100)
where PX,Y refers to the joint probability distribution. This is an information-theoretic
measure which characterizes the uncertainty of a variable sampled from one distribution
given a variable from the other. Somewhat vaguely, it can also be thought of as a gener-
alized measure of correlation between variables X and Y that can also capture nonlinear
dependencies. In the context of the renormalization group, the best choice of coarse-
grained variables of a given cell are those which are maximally correlated with the rest of
the system. In [33], the renormalization group transformation is implemented by a kind
of restricted Boltzmann machine whose latent variables correspond to coarse-grainings,
such that (100) is minimized.
When working with probability distributions, it will be useful to remember how map-
pings between them work. Given a bijection between the two sets of random variables
f : X →Y , then for y = f(x) we have
PX(x) = PY (f(x))
det
∂f
∂x
 .
(101)
A class of real-valued non-volume preserving ﬂows (”normalizing ﬂow”) modules
parametrizing bijections between distributions have a particularly tractable computation
of Jacobians [49]. They are used in [48] to build a MERA-inspired neural network of the
form shown in Fig. 2, where blocks correspond to NVP modules, and crosses correspond
to latent variables that contain the coarse-grained degrees of freedom at different scales.
7In practice, one can also partition the environment E into the “buffer” B, which contains the degrees of
freedom closest to V, and the remainder.
35

Figure 2: Neural Network Implementing an Exact Renormalization Group. Courtesy
of [48].
Note that one novelty here is that the decimated degrees of freedom are also kept, and
since all operations are invertible, one may also perform the inverse of the RG transfor-
mation.
4.1.2
Variational RG
In [50], the authors propose that the action of the variational renormalization group of
Kadanoff can be identiﬁed with a class of restricted Boltzmann machines. In the varia-
tional renormalization group, a transformation between the ﬁne-grained spins {vi} and
the coarse-grained variables {hi} is given by a function Tλ({vi}, {hi}), with a number of
adjustable parameters λ. The renormalized Hamiltonian Hλ({hj}) is given by
e−Hλ({hj}) ≡Trvi eTλ({vi},{hj})−H({vi}) .
(102)
The original free energy is given by
F = −log Z = −log
 Trvi e−H({vi})
,
(103)
while the renormalized free energy is given by
Fλ = −log Zλ = −log
 Trhi e−Hλ({hi})
.
(104)
The parameters λ are then chosen to minimize the difference between the ﬁne and
coarse free energies:
36

∆F = Fλ −F .
(105)
Boltzmann machines start with a coupling between the visible neurons {vi} and the
hidden neurons {hi}, of the form (see section 2.3 for details)
E({vi}, {hi}) =
X
j
bjhj +
X
ij
viwijhj +
X
i
civi ,
(106)
for some set of ”weights” bi, ci, wij. Then, the probability of ﬁnding the system in a
state given by a set of values for vi and hj is
p = e−E({vi},{hj})
Z
.
(107)
In order to make contact between this restricted Boltzmann machine and variational
renormalization group, visible neurons vi are interpreted as spins in the ﬁne-grained
model, and hidden neurons are interpreted as course-grained spins. Weights and bi-
ases of the RBM play the role of variational parameters λ. The renormalization group can
then be conceived of as a sequence of successive coarse-graining transformations, which
is implemented using a deep neural network.
4.1.3
RG-guided graph growth
We now propose a kind of information-theoretic mechanism to study and reﬁne graph
growth. This complements our exploration of different notions of graph growth in Secs. 4.3
and 4.4 where we propose several simple algorithms that we conjecture might lead to the
appearance of relevant features which can dictate the course of the growth. By repeating
an algorithm such as these many times, with different starting conﬁgurations, we obtain a
statistical ensemble of graphs at each step in the growth process. This is a natural starting
point for applying the tools of Sec. 4.1.1; namely, we consider probability distributions
over the space of graphs rather than individual graphs. Using methods from persistent
homology, we can then identify features most consequential to the growth process by
maximizing the mutual information between such features and their environments, i.e.,
the rest of the graph; this could also be implemented using Restricted Boltzmann Ma-
chines, as described in [33].
Note that the process we just described is an “inverse renormalization group transfor-
mation”8; we essentially started with a set of coarse-grained graph features and slowly
added ﬁne-grained features. The step of this ﬁne-graining operation thus plays the role
of time. Such probabilistic “inverses” of RG transformations have been studied in the
context of the Ising model using deep Convolutional Neural Networks [51]. This work
is inspired by the methods used in computer vision for creating image super-resolutions,
and it applies similar tools to construct “ﬁne-grained” Ising model conﬁgurations. These
8Strictly speaking, renormalization group does not have an inverse
37

ﬁne-grained conﬁgurations turn out to be sampled from related Boltzmann distributions
so that they lead to correct thermodynamic quantities.
Stochastic growth processes can be speciﬁed by a probability distribution over poten-
tial graphs at different stages of the growth. The rules for making each following move
then comes from conditional probabilities.
The space of such growth processes is vast. In order to narrow it down, we contem-
plate two questions:
• How do we deﬁne a natural set of probabilities which specify a preferred growth
process?
• Given such a set of probabilities, what do the emergent rules for making moves look
like, and how do they depend on the state of the system?
Our intuition is that the two questions are intimately related. Namely, a good answer
to the ﬁrst question is one which allows the emergent rules to be easily captured by some
highly relevant graph substructures. Note that while the statement that the rules depend
on the state of the system is trivial, this requirement is quite constraining. For a particular
growth process, such relevant structures may be identiﬁed as those which maximize the
mutual information with the environment; the right growth process could be identiﬁed
through the simplicity of relevant structures. Both criteria can be precisely deﬁned and
implemented through machine learning.
4.2
Precedence
Let us consider the question of whether the laws of physics evolve over time. Might they
undergo some form of dynamics that leads to the laws we see today? An interesting
proposal for how a dynamics of laws may be realized is the Principle of Precedence [52].
This idea can be set within an operational formulation of quantum mechanics such
as that by Hardy [53] or Masanes and Muller [54], but it is easy to informally state the
general idea. Quantum theory is envisioned as an example of a more general probabilistic
dynamical theory. A quantum process is described, from an operational point of view, as
having three stages: 1) a choice of initial state (i.e., preparation), 2) an evolution within an
environment, described as an example of a general framework for probability preserving
evolution, and 3) a ﬁnal measurement, from which emerges one out of a ﬁnite number of
answers to a question.
The three stages deﬁne a matrix of probabilities, [P]a
b, for N inputs to evolve through
the environment to yield any of the N possible outcomes. These probabilities are usually
believed to not change in time because they reﬂect timeless laws.
The Principle of Precedence offers a different explanation for the probabilities and
their time independence. Given each choice of preparation and measurement, there is an
ensemble of past quantum processes. The principle says our system must pick out one
38

of those randomly and copy its output. If that ensemble is large enough, the process of
evolution via precedent converges to time-independent probabilities.
But what if there is no such past ensemble for a process deﬁned by certain particular
inputs and outputs? This seems to be a question well adopted to investigation via auto-
didactic neural networks such as the RBM. As we now explain, the notion of precedence
seems naturally suited to be realized in a setting such as machine learning.
In this case the system has a clear reservoir of consequence, because literally each
future quantum process has access to the whole ensemble of past processes with the same
initial state and time evolution operator. The access is through a random sampling of
outputs, which is all the system needs to learn from the past.
Hidden layers can represent non-local hidden variables
One reason precedence comes
naturally is that the RBMs have degrees of freedom in their hidden layers that can repre-
sent the non-local hidden variables that are needed for any realist completion of quantum
mechanics. This is shown in the model of Weinstein [55], where an RBM is trained to rep-
resent a hidden variable model of an EPR experiment.
One interesting aspect of Weinstein’s model is that it violates Bell’s inequality, not
because it exhibits non-locality (meaning locality in the normal Bell sense, i.e., measure-
ments at detector A should not impact those at B), as neurons of the visible layer are
by construction non-local. That is, the RBM is a bipartite graph, but because it violates
measurement independence, the distribution for hidden variables, ρ(λ), is independent
of the set up for the experiment. This violation is manifest from its construction, since the
hidden layer of the RBM can be written in terms of the input layer and weight matrix, so
P(λ) →P(λ|α) where α represents some model parameters.
4.2.1
Precedence, Weinstein, and machine learning
The approach of Weinstein is well suited as a starting point for realizing the idea of prece-
dence while encapsulating some of the other axioms for quantum theory. Imagine we
want to train an RBM to reproduce the correlations of a speciﬁc quantum state. The visible
layer v consists of a mixture of the details for the measurement (say a choice of polarizer
orientation in the standard Bell experiment) and the outcome for said measurement. The
hidden layer h corresponds to hidden variables which are connected to the visible layer
via a weight matrix Wij, see Fig. 3. As per the prescription for precedence, the ﬁrst mea-
surement of a given state in “cosmic history” will be completely random. Thus, we begin
training our architecture by initializing the weight matrix Wij to have random entries. We
next make a choice of measurements on the system, α, β, ..., and initialize their values to
random numbers xα, xβ, .... This is the ﬁrst pass.
We then update weights using contrastive divergence, which provides new values for
the matrix elements Wij.
The reconstructed visible layer v′ can now inform our next input to the architecture. A
simple idea would be to implement a basic rejection sampling routine based on the recon-
39

WIJ
vI
hI
''measurement
settings''
''measurement
outcome''
Figure 3: Restricted Boltzmann Machines. The RBM model is used to describe a physical
theory whose laws may evolve in time. The architecture consists of two layers of neurons,
one visible (green) and one hidden (blue). The visible layer is used both to specify the
measurement details and to measure outcomes, while the hidden layer enables non-local
connections between the visible nodes. As the training procedure iterates, the weights
which connect the two layers update according to the Principle of Precedence until they
converge on some limit set. We consider the case where the size of both layers very large,
and where there is an equal number of neurons in each of the layers.
40

structed probability for each neuron. One then repeats this procedure with the now less
random state. Also notice that the inﬂuence of the past states persists, because it informs
how the new visible layer is constructed by means of the weight matrix. As one iterates
this process, it should converge to a set probability distribution.
This approach is just an example and is likely extendable to other machine learning
architectures, e.g., autoencoders. What should be clear though, is that if the universe were
to exhibit a principle based on precedence, it seems inevitable that its physical manifes-
tation would resemble a machine learning algorithm, though with one important differ-
ence.
The architecture just described is different from the Principle of Precedence, as it does not
entirely realize the notion of being informed from past outcomes. In our RBM analogy,
it is indirectly inﬂuenced by the past via updates to the weights and not prior outcomes
explicitly. Depending on how it turns out, as well as whether one believes the past exists,
this may be a feature rather than a bug.
But nonetheless, whether the dynamics is continuous or discrete, the inﬂuence of
the past states, and the presence of the hidden state, means that this system has con-
sequencers built into the dynamics.
4.3
Self-sampling learning methods
In this section, we describe several proposals for using graph toy models which realize
self-guided growth.
Let us consider some possible stochastic base rules for growth which lead to interest-
ing emergent rules at larger scales. We are interested in growing structures that describe
not only the state of a “physical system” but also the emergent laws, all of which are de-
scribed using discrete data. Such laws can be determined by inﬂuential structures that are
highly persistent but not eternal. Formation of such structures at early times constitutes
Batesonian information [56].
As a simple toy model, we start by considering stochastic growth of graphs.
We saw a class of dynamical systems that could be described this way, in the matrix
models deﬁned by (65) to (67).As discussed in [39] the matrix degrees of freedom split,
as N →∞into fast and slow degrees of freedom. The former provide a ”background
Hamiltonian” which over intermediate scales can be considered stationary. Over shorter
times they dictate the evolution of the fast degrees of freedom. We see how the slow
degrees of freedom can be considered to function as a consequencer.
Now we consider some dynamics of graphs, which give another example of the emer-
gent splitting into ”Effective laws” which dictate the evolution of faster degrees of free-
dom. Again these splittings can be understood as creating consequencers. In the context
of graph dynamics, simple updates to nodes/edges can be understood as fast degrees of
freedom whereas changes in topology of the graph can be assigned to slow degrees of
freedom.
41

Figure 4: Graph with 7,088 nodes & 7,304 edges constructed from sampling possible fu-
tures with a notion of stochastically optimizing the Wiener index - maximizing the sum
of shortest distance between nodes. Graph is colored based on notion of modularity, with
73 total communities, and a very high modularity of 0.95 – note that this is a structure
very close to a tree.
42

Consider the time-evolution rule guided by a look-ahead algorithm which seeks to in-
crease a particular quantity Q. Namely, at each step in the graph growth process, choose
one from the subset of moves: we either add a new node and connect it to some subset of
the rest of the graph, or we add an edge between an existing node pair. In order to pick
the move, we perform a number of random walks several steps into the future and select
the one that led to the optimal value of Q. Then, our move is selected as the ﬁrst move in
this winning walk. We note that the size of the search space grows super-exponentially
with the graph size, so the accuracy of the look-ahead is limited by computational power.
In this work we implement a toy example of this model, the details of which are as fol-
lows.
Look-ahead algorithm
Our algorithm consists of taking a starting graph, in this work two connected nodes,
and applying the following procedure:
1. Generate NC copies of the starting graph G.
2. For each copy randomly add either an edge between existing nodes or add a new
node and connect it to an existing node randomly. For each copy repeat this step a
total of NF times - each copy now corresponds to a different future evolution of the
original graph.
3. For each future calculate the value of Q and identify the graph Gf that extremizes Q.
4. Now update G with the graph formed by the ﬁrst move in the history of Gf.
5. Return to Step 1. and iterate, in principle, ad inﬁnitum.
We show numerical results for Q as the Wiener index, i.e. sum of shortest distances
between nodes, Fig. 4, for Nf = 50 & FC = 64. The graph has 7,088 nodes & 7,304
edges and has diameter of 50. We show the degree distribution, eccentricity distribution,
and modularity class in Fig. 5. One of the interesting properties of this graph is that it
has a very high modularity of ∼0.95 which implies very sparse connections between
communities – of which there are 73 for this graph. Furthermore, we ﬁnd that the graph
is very close to the percolation threshold (i.e. that the connectivity of the graph is ∼2/#
nodes). One can appreciate this from Fig. 5 where we have calculated the fraction above
the percolation threshold as a function of number of graph updates for different values of
NC. We ﬁnd that considering more futures approaches closer to the percolation threshold.
This result is not surprising since the high modality implies that the graph is close to a
tree, i.e. a tree has a modularity of 1.
We also consider for Q the graph diameter (largest distance among the graph nodes),
which is depicted in Fig. 6 for Nf = 6 & FC = 64 at two different snapshots - after
100 moves and after 1000 moves. The ﬁnal iteration has 1,119 nodes & 1,335 edges and
43

Figure 5: Clockwise from the upper left: Degree distribution for the graph in Figure 4, the
eccentricity distribution, fraction that the connectivity is above the percolation threshold,
and modularity class.
44

has a modularity of 0.82 with 24 communities. Figure 7 shows the degree distribution,
eccentricity distribution, and modularity class. This graph helps us appreciate that this
algorithm doesn’t amount to optimizing Q; instead, it is using Q to guide the random
walk. Indeed, we would expect for an algorithm that optimized Q the ﬁnal form would
have a diameter much larger than 85 given the size of the graph. One thing to note in
Figure 6 is the presence of persistent structures – for example the central hub of the graph
and its arms which persist over many iterations of the algorithm. Since these structures
inﬂuence decisions for future updates to the graph, they can be thought of embodying a
form of Batesonian information.
Two other useful discrete topological objects are knots and braids. To model these, we
label graph edge crossings with chiral variables. Then, we apply the same guided random
walk algorithm, while using a guiding quantity Q that seeks to maximize both crossings
and graph diameter. An example simulation is shown in Fig. 8 where the graph has 91
nodes and 183 edges for Nf = 6 & FC = 64 and has attained a diameter of 14. Comparing
the degree distribution for this Q to only maximizing graph diameter, Fig. 7, one can see
the impact of rewarding crossings.
Additionally, one may iteratively take tensor products of graphs with selected sub-
graphs to produce graphs with interesting structure, which are conjectured to posses
fractal properties after a large enough number of iterations. While we were not able to
verify this in simulation due to the fact that the size of such graphs grows exponentially or
faster (depending on the details of implementation), we were able to produce some inter-
esting example structures. We iteratively identiﬁed subgraphs containing neighborhoods
of randomly chosen nodes, and took tensor products with the rest of the graph. We also
considered a second prescription in which we identiﬁed subgraphs via random walks on
the base graph, and then again took tensor products with the rest of the graph. The results
are shown in Fig. 9. Interestingly, this can lead to graphs with a layered structure, much
like we ﬁnd in deep neural networks.
The results here serve as a starting point for a more thorough study of graph growth
directed by self-sampling. A more thorough study would seek to better understand the
role of emergent substructures which become highly inﬂuential in determining the future
graph growth, i.e., subsets which are frequently sampled. Though we do not have con-
crete numerical results yet, we can speculate about the form that emergent rules might
take:
• The emergent rule for graph growth is related to fractal properties of the graph.
Structures present in the seed or formed early on in this process will determine the
basic fractal structure. A growth algorithm similar to the iterated tensor products
might satisfy this property.
• The emergent rule for graph growth is contained in a mechanical structure that im-
parts new shape. We may imagine a “brewing vat” embedded in a larger universe.
Note that such structures are known to exist in Conway’s Game of Life [57].
45

Figure 6: Left: A graph grown with look-ahead algorithm where Q is the graph diameter.
Right: The same graph after an order of magnitude more growth steps.
• The emergent rule is related to the way information is transmitted through the
graph. Rather than having a graph which constantly grows in all directions, like
in our iterated tensor products algorithm, we may imagine graph growth happen-
ing only at speciﬁc places at one time. In order to determine such growth locations,
we could in principle utilize something like the GraphWave algorithm, in which we
release a wavelet from a given node and see where it is most likely to land.
• The emergent rule consists of the graph itself interpreted in some machine language.
This begs the question of what complexity of the “external CPU” that interprets this
graph we are willing to allow.
• The look-ahead protocol is somewhat related to algorithms in reinforcement learn-
ing such as AlphaZero [58]. Yet, we note the sample space here is much larger, which
is likely to make learning more difﬁcult.
4.4
Variety
One might wonder whether the statistical learning methods are useful only for illuminat-
ing details of an application of existing mathematical methods, or if they can be used to
deﬁne new fundamental quantities, speciﬁcally in the context of discrete topological ob-
servables. Here, we provide an example of a physically motivated quantity associated to
graphs called the variety, ﬁrst introduced in [59]. Roughly, the variety is a global measure
46

Figure 7: Clockwise from the upper left: Degree distribution for the larger graph in Figure 6,
the eccentricity distribution, and modularity class.
47

Figure 8: Left: This graph is constructed such that it explicitly keeps track of edge cross-
ings, where yellow (green) correspond to over (under) crossings, thus we can discuss
knots and braids. Algorithmically, this graph is constructed with our look-ahead algo-
rithm where we simultaneously try to maximize crossings and graph diameter. Right:
The degree distribution for the graph.
of dissimilarity of subsystems, i.e., it is a quantitative measurement of the asymmetry
present in a discrete structure.
Notions similar to variety date back to Leibniz (identity of indiscernibles) [60], and they
have recently been applied to quantum foundations in order to reconstruct a version of
Bohmian mechanics [61]. Generally speaking, variety has to do with the distinctiveness
of views that subsets of a system have of each other. As such, it is naturally placed within
a relational approach to quantum foundations [59,61,62].
The simplest mathematical model of a fully relational system is a graph, and the def-
inition and study of measures of graph variety will be the main focus of this section. We
can think of a graph as a representation of a universe of relations: it is a closed system, de-
ﬁned only by the patterns of links, each deﬁning an elementary relation between the two
nodes at its ends. The original prescription of variety presented in [59] is that each node
of a graph has its view of the universe, which is characterized by how it is connected. One
way to describe the view of a node i is to consider the nth neighborhood of i, denoted N n(i).
This is a subgraph consisting of i and all the nodes connected to i by n or fewer hops, plus
all the links among them. One can then say two nodes i and j are m-step distinguishable
if m is the smallest integer such that the two neighborhoods, N m(i) and N m(j) are not
isomorphic. We deﬁne the distinguishability
D(i, j) =
1
m(i, j) ,
(108)
48

Figure 9: Tensor Products with Subgraphs. Upper Left: Graph obtained by identifying
neighborhoods of randomly chosen nodes and taking their tensor products with the rest
of the graph. Coloring scheme is based on vertex degrees. Upper Right: Graph obtained
by identifying subgraphs through random walks of length 3 and taking their tensor prod-
ucts with the rest of the graph. Coloring scheme is based on communities. Bottom Left:
Graph obtained by identifying subgraphs through random walks of length 4 and taking
their tensor products with the rest of the graph. Coloring scheme is based on commu-
nities. This example makes clear that structures resembling multi-layer neural networks
can emerge from extremely simple starting conditions in autodidactic systems. Bottom
Right: Graph obtained by identifying subgraphs through random walks of length 5 and
taking their tensor products with the rest of the graph. Coloring scheme is based on vertex
degrees.
49

which we use to precisely deﬁne the graph variety with the sum over all pairs,
V =
X
i<j
D(i, j) .
(109)
While this may seem like the most natural deﬁnition of graph variety, it is not the only
one, and it is not obvious a priori which is most well-suited for a quantum gravity appli-
cation. Our particular choice may also change if our graphs encode causal structure, e.g.
using directed graph edges.
In the theory of causal sets [63], discrete spacetime is represented by a set of events
together with a set of causal relations among them. This causal structure admits a natural
representation in terms of a directed acyclic graph. Only a very small fraction of such
graphs turn out to be faithfully embeddable in a low-dimensional (for example, 3+1 - di-
mensional) spacetime [64]. While there has been signiﬁcant progress on understanding
discrete Einstein-Hilbert actions, it is not yet clear whether all low-dimensional discrete
geometries satisfy some unifying optimization principle. It is in this context that we con-
jecture variety may play a role. More broadly speaking, the principle that different events
should be uniquely determined by their causal pasts has played a role in developing en-
ergetic causal set models [65].
A related implication of Leibniz’s principles is that neither classical nor quantum gen-
eral relativity should admit any global symmetries. This is strongly suggested by a theo-
rem of Karel Kuchar that states this is the case in classical general relativity with cosmo-
logical boundary conditions [66].
In the remainder of this section, we explore a handful of deﬁnitions of variety and
speciﬁcally focus on those which are discriminative – maximized for an exponentially
small subset of all graphs – and complex, i.e., it is hard to sample graphs which maximize
variety. We show that variety is difﬁcult to compute using the usual numerical methods
for discrete topologies, because the computational complexity of candidate functions is
at least cubic in the number of nodes, and because the dynamics can be highly non-local.
We conjecture that variety is an example of a kind of quantity that may be best deﬁned
and computed through use of an unsupervised learning algorithm which uses approximate
optimization with bounded error. To support this conjecture, we report at the end of this
section initial results from computational studies of graphs approximately optimizing a
new deﬁnition of variety based on structural node embeddings.
4.4.1
Asymmetry, irregularity, and heterogeneity
In graph theory, similar concepts have appeared under the names asymmetry, irregular-
ity, and heterogeneity. All of these attempt to capture a quantitative measure of graph
symmetry. The degree of asymmetry was introduced as a means to classify asymmetric
graphs, i.e., graphs which have only a trivial automorphism. This deﬁnition of variety,
in terms of (the inverse of) the size of the automorphism group, is close to what was
originally proposed in [59]. However, this deﬁnition of variety turns out to be trivially
50

satisﬁed by almost all ﬁnite graphs in the large-N limit. It was shown by Erd¨os and
R´enyi [67] that almost all ﬁnite graphs are asymmetric, and that almost all asymmetric
graphs have a degree of asymmetry near the maximum N/2. Because the ensemble of
random graphs is projective, the neighborhood N 1(i) is an element of the same ensemble
deﬁned on |N 1(i)| nodes and the same fraction of edges; hence, the subgraph induced by
the ﬁrst-nearest neighborhood is also almost surely asymmetric. Further, one can show
it is unlikely that any random subgraph N 1(i) is isomorphic to a different random sub-
graph N 1(j), a fact which can intuitively be understood by remembering neighborhoods
are a set of N random elements of an ensemble that is super-exponential in size.
Graph irregularity comes at the problem from the opposite perspective, attempting to
deﬁne the degree to which a graph is not regular. There are a number of deﬁnitions in
literature which we review here. The original deﬁnition due to Collatz and Sinogowitz
described irregularity as the difference between the adjacency matrix’s largest eigenvalue
and the average degree [68]. The set of graphs which maximize this notion of irregularity
is the set of quasi-complete graphs. Likewise, Bell deﬁned irregularity in terms of the
variance of the degree distribution [69], which leads to maximum-irregularity graphs that
are either quasi-complete or quasi-stars, depending on the edge density [70].
Two popular measures of graph irregularity are the so-called Albertson index [71],
which measures the imbalance of nearest-neighborhood sizes, and the related deﬁnition
of total irregularity [72], which measures the imbalance of degrees of all node pairs. The
Albertson index is maximized for clique-star graphs, which are stars whose core is a com-
plete subgraph containing at least a third of all nodes [73]. The total irregularity is max-
imized for graphs whose degrees are more heterogeneous, and the resulting ensemble
contains 2n/2 non-isomorphic graphs. Another measure similar to these deﬁnitions of ir-
regularity is network heterogeneity [74]. However, this deﬁnition is not so interesting for
our application as it is deﬁned so as to be extremized for perfect star graphs.
A different deﬁnition of irregularity – speciﬁcally, local irregularity – was introduced
in [75]. The nodes in a locally irregular graph each have a set of neighbors with distinct
degrees, though it is not the case that all degrees in the graph must be distinct9. Graphs
which satisfy this local deﬁnition of irregularity were termed “highly irregular graphs,”
and it was shown that the size of the associated ensemble has an asymptotic lower bound
of 2n2/32 [76].
We consider below a different deﬁnition of variety based on structural node embed-
dings. Several of the above similar deﬁnitions fail to capture the properties we desire
for a physical variety, speciﬁcally because they select graphs which are not topologically
interesting. That is, we do not believe that stars, clique-stars, quasi-stars, etc., have suf-
ﬁcient structure to encode the structure and laws of a spacetime. It may still be the case,
however, that metrics such as total or local irregularity are also compelling deﬁnitions of
variety. We will leave their study to future work.
9In fact, it is impossible to satisfy the irregularity constraint globally. There are no graphs whose degree
set is size N −1, and there is only one graph (and its dual) whose degree set is size N −2.
51

4.4.2
Variety of structural node embeddings
In this section, we propose a smoother notion of variety that we conjecture (based on our
preliminary results) leads to a novel ensemble of high-variety graphs. To this end, we
utilize an algorithm for constructing structural node representations known as Graph-
Wave [77]. While we used the published implementation of their method, let us brieﬂy
review the algorithm.
A brief description of GraphWave algorithm
While the previous two deﬁnitions of
variety make intuitive sense, we will see in the following section that their representative
high-variety graphs do not tend to possess enough structure. In order to come up with
a notion of variety more aligned with our ideas of what high-variety graphs ought to
be, we decided to leverage an unsupervised machine learning algorithm for constructing
structural node embeddings called GraphWave [77].Let us brieﬂy review this method as
explained in their original formulation.
This algorithm starts by considering the diagonalized Laplacian matrix L,
L = D −A = UΛU T ,
(110)
where D is the diagonal matrix of node degrees, A is the adjacency matrix, and Λ is a
diagonal matrix of the Laplacian’s eigenvalues. Then, we consider a ﬁlter gs(λ) = e−λs,
which we apply to Λ, yielding the following result:
L →L′ = UDiag(gs(λ1), gs(λ2), . . . , gs(λN))U T .
(111)
If we let δa be the one-hot encoding10 corresponding to node a, we can construct the
associated vector Ψa, deﬁned as
Ψa = L′δa .
(112)
Roughly speaking, we are starting with a signal δa which is peaked at node a and
studying how the signal diffuses through the graph. The vector Ψa then corresponds to
amplitudes of this signal at different nodes. The key idea of the GraphWave method is
to treat Ψa as a probability distribution, and compare such distributions through their
characteristic functions φa = E[ei t ψa]. Values of such characteristic functions evaluated at a
set of discrete points {ta} are then put together in vector χa representing each node a.
χa = [Re(φa(ti), Im(φa(ti))]{ta}
(113)
10The one-hot encoding of a categorical variable is a binary vector with a single entry ‘1’ and the rest ‘0’.
52

Additionally, a principal component analysis may be applied to reduce the dimension
of the representation.
The idea is that nodes which play the same structural role in the graph will end up
with the same representations; nodes from whose perspective the rest of the graph looks
slightly different will have nearby, but not identical representations. We identify such
node representations as views, and need to deﬁne the variety as a function of such views.
From node embeddings to variety
In our application of this method, we worked with
2-dimensional node representations, much like those shown on the example of Fig. 10. If
such 2-dimensional node representations are denoted as ˜χa, the variety is deﬁned as the
Coulomb potential
V = −
X
i,j
1
|˜χi −˜χj|
(114)
Thus, variety is deﬁned as the (negative) Coulomb potential energy between node
representations, treated as identical positive charges. One piece of inspiration behind this
formula is the idea of locality in the space of views being more fundamental than the
spacetime locality [78]. Then, we want to introduce variety through a physical interaction
between the views. The 1/r potentials are ubiquitous in physics, and would provide the
simplest way to push the views apart from each other.
This measure of variety heavily penalizes graphs whose nodes have completely iso-
morphic neighborhoods (which would lead to a variety of −∞); in general, node repre-
sentations try to spread out as much as possible. One can think of this deﬁnition of variety
as a smoothening of notion from earlier in 4.4.
We will see in the following section that this deﬁnition of variety leads to some poten-
tially appealing features of high-variety graphs, based on preliminary computations.
Numerical experiments
We next consider a set of numerical experiments which at-
tempts to characterize high-variety graphs using the above deﬁnitions. After applying
the notion of variety from Eq. (109) based on isomorphisms, we ﬁnd evidence that for
large N, a typical element of the Erd¨os-R´enyi ensemble [79] with a fraction of connected
edges p = 0.5 is likely to have all ﬁrst neighborhoods of nodes non-isomorphic to each
other. This gives the maximum value of variety that can be achieved with this deﬁnition.
The median values of GraphWave - based variety across members of the Erdos-Renyi
ensemble with n = 50 nodes and different values of p are shown in Fig. 11. Note that
the GraphWave variety of Erdos-Renyi ensembles with N = 50 is maximized for p ∼0.2.
Even for this value of p, we ﬁnd that typical members of Erdos-Renyi ensembles do not
maximize variety.
Graphs with high values of variety were constructed through the following proce-
dure. First, we estimated the value of p that approximately maximizes the value of variety
53

Figure 10: GraphWave Embedding Algorithm. A sample graph (left) is embedded us-
ing the two-dimensional PCA projection of the GraphWave embedding algorithm (right).
This method provides a way to distinguish between structural roles of different nodes in
a graph. This image was ﬁrst printed in [77].
among Erdos-Renyi graphs, generated 20 different Erdos-Renyi graphs with such values
of p and picked the one with the highest variety to serve as the starting point for the op-
timization procedure. Then, we used a simulated annealing method to make a number
of edge insertions and deletions to the graph, with the aim of maximizing the variety. A
resulting high-variety graph with 1000 nodes is shown in Fig. 11.
This graph has the variety that is 22.4 % greater then its median value with respect to
the Erdos-Renyi ensemble with the same connectivity. More work remains to be done on
the study of high variety graphs. For now, let us content ourselves with the observation
that our GraphWave based deﬁnition of variety led to high-variety graphs that are statis-
tically different from a typical random graph (for example, members of Erdos-Renyi en-
sembles with p = 0.5), have signiﬁcantly higher variety then typical Erdos-Renyi graphs
with the same p, and have features that agree with our intuitive notions of what variety
should mean. Comparing the degree distribution to the Poisson distribution, with mean
given by average degree of the graph, we can see that the GraphWave notion of variety
does not produce a Poisson degree distribution in the large-N limit. It is intriguing that
such a deﬁnition was obtained not from ﬁrst principles, but through an application of an
unsupervised learning algorithm.
In future work, it would be interesting to repeat the same simulated annealing proce-
dure a larger number of times and construct enough high-variety graphs so that further
statistical conclusions can be made about their properties. We would also like to consider
whether a connection may be found between our notion of variety and information theory.
54

Figure 11: High-Variety Graphs. Top: Beginning with a random graph on 1000 nodes and
3920 edges, we construct a high-variety graph with 1000 nodes using simulated anneal-
ing. Node hues reﬂect their degrees, which lie in the range of [3,18]. Left: Erd¨os-R´enyi
random graphs with N = 50 nodes are studied using the GraphWave-based deﬁnition of
variety deﬁned in (114). Right: Degree distribution and Poisson distribution with µ = 8.8,
i.e. the average degree for nodes in the graph.
55

Finally, we would like to note that GraphWave is certainly not a unique solution to
the problem of constructing structural node embeddings, and other algorithms such as
struc2vec [80] are also available. In future work, the effect of different algorithms on the
properties of variety could be studied.
4.5
Geometric self-assembly
The problem of geometrogenesis asks how the smooth, continuous geometric structure
of space-time may emerge from a sequence of random topological structures [81–88]. The
various approaches to quantum gravity, such as causal set theory [63], spin foams [89],
and causal dynamical triangulations [90], have considered how a discretized Einstein-
Hilbert action may drive the dynamics of discrete space-times into a geometric phase,
in which geometry, locality, and possibly transitivity are emergent properties. Yet, no
approach has fully succeeded in connecting the discrete and continuum worlds in the
form of a complete theory of gravitation. Therefore, it remains an open question which
properties are axiomatic and which are emergent, despite many compelling arguments
from a variety of perspectives (see also section 4 and especially 4.2 on precedence and
consequencers).
We consider in this section two ways in which machine learning may be used to study
the emergence of n-body local Ising-type interactions in a geometric space. The ﬁrst
method examines how one might learn a near-optimal annealing schedule from random
to geometric structures at ﬁxed size using knowledge of the existence of both phases. This
scheme represents the moves an omniscient agent would make to generate a geometric
space. The second method removes the perfection of the agent in an attempt to under-
stand whether the emergence of geometry is inevitable when the agent is not all-knowing
but does have the ability to learn from itself using consequencers in the form of self-
attention. We instead use a growing model where we assume exchangeability is inherent
(i.e., measures are always label-invariant) but the property of projectivity is learned. The
consequence of the latter is that the sequence of states at late times becomes projective,
i.e., larger discrete structures encode larger portions of the same geometric space, thereby
allowing a continuum limit to exist regardless of early-time behavior. This leads us to con-
clude the time taken to learn the geometric space is also associated with a fundamental
length scale.
In our toy models, we consider a set of Ising spins which form the base set of an ab-
stract simplicial complex used to encode interactions. Abstract simplicial complexes are
objects in algebraic topology formed by a collection of subsets of a base set, deﬁned such
that every subset is also an abstract simplicial complex. Given a particular realization,
the interaction among the elements of the base set, i.e., the Ising spins, are described by
the maximal subsets, called facets. A link between a pair of vertices describes a two-spin
interaction, a triangular face among a triplet of vertices describes a three-spin interaction,
and so forth. Hence, allowing both the Ising spins as well as the connections to change
dynamically enables, us to study the optimal interaction patterns among a set of Ising
56

variables.
4.5.1
Learning an optimal annealing schedule
We ﬁrst consider a reinforcement learning protocol to learn the near-optimal trajecto-
ries through the discrete phase space which take us between the random and geomet-
ric regimes. In the geometric regime, we choose relational structures with well-deﬁned
continuum limits, such as random geometric graphs or Delaunay complexes, which are
known to converge in geometry and topology to manifolds in a suitable limit [81,86]. The
laws are encoded in the undecorated simplicial complexes, i.e., there exist no hyperedges
linking three or more vertices, and there do not exist long-range connections between
vertices separated by a large graph distance. For a ﬁxed set of laws, the non-geometric
counterparts are Erd¨os-R´enyi random graphs and random piecewise linear manifolds
with non-interacting spins11. When we allow the laws to also take a random conﬁgura-
tion, the non-geometric phase is described by a random abstract simplicial complex, or
possibly a random hypergraph, depending on whether the existence of an n-spin inter-
action also implies the existence of (n −1)-spin interactions among the same vertex set.
We may also consider other initial conﬁgurations depending on our assumptions. The
early universe is thought to be highly symmetric [91], so one might postulate the laws
may be described very simply. For instance, the initial simplicial complex we use may be
either the fully disconnected or fully connected set, which represent the non-interacting
and fully-interacting systems, respectively. On the other hand, geometric conﬁgurations
should be less symmetric but still contain a few relevant symmetry groups, e.g., an SO(d)
rotational symmetry (with respect to a d-dimensional embedding), an SU(2) spin symme-
try, and a U(1) symmetry arising from a discrete Zn relabeling symmetry.
The objective task now is to generate a near-optimal sequence of updates which moves
the system from one regime to the other. We suppose the initial conﬁguration is the
fully non-interacting set: the laws are described by a zero-dimensional simplicial com-
plex K = K0, the spins {σ} take random positions, and the temperature of the system is
set to inﬁnity, β = 1/T = 0. The energy of the system is given by the generalized Ising
Hamiltonian,
H(K, {σ},⃗a) = a0
n0
X
i
σi + a1
X
δij∈K
σiσjδij + a2
X
δijk∈K
σiσjσkδijk + . . . .
(115)
The coefﬁcients ⃗a = {a0, a1, . . .} describe the couplings between spins, where spins are
denoted by σ and existence of facets are denoted by δs. The sums are over facets in the
simplicial complex which encodes the laws, which makes the Hamiltonian a function of
all of the variables in the model. When the system transitions to a geometric phase, the
Hamiltonian takes an effective form where the couplings scale with the size of the system.
11Note that spins may be non-interacting for two reasons: either the laws dictate they do not interact or
the temperature of the system is inﬁnite.
57

We now form a statistical manifold where each point corresponds to the measure for
a particular conﬁguration of the system,
µ(K, {σ},⃗a, β) = e−βH(K,{σ},⃗a) .
(116)
The optimal annealing schedule minimizes the thermodynamic length [92] with respect
to the Fisher information metric [93], i.e., it minimizes the change in entropy integrated
along the path between the initial and ﬁnal regimes. Updates which move the system
through the manifold occur in several ways. First, we use single-spin ﬂips which change
the energy of the system. Second, the laws may change by adding or removing a facet
in K. Third, the temperature may decrease according to an annealing schedule. We con-
sider a process by which these happen on different timescales, e.g., the spins update much
faster than the simplicial complex. We then train an agent using reinforcement learning to
select the updates to the laws which move them closer to our target regime. The reward
for a single update may be expressed in terms of the (inverse of the) estimated edit dis-
tance to the target ensemble, so that the maximum reward follows a geodesic in the statis-
tical manifold. When this distance is expensive to calculate, it may be approximated with
a compressed representation using a DNN trained beforehand with supervised learning.
As the system cools over the course of the simulation, the agent will have relatively fewer
opportunities to update the laws, hence the optimal schedule will be tied to the optimal
learning rate. In other words, if the system cools too quickly the system may remain stuck
in a quenched non-geometric phase.
4.5.2
Self-guided assembly using precedence
We now consider a second process by which an agent may learn from its own actions us-
ing the concept of precedence. Here we consider updates which grow the system: at each
step the base set is extended by one spin and new facets are added with some probability.
Initially, variables are updated purely at random, since there is no prior set of states that
a precedence mechanism might exploit. As the walker updates, it begins to learn from
its own moves using an attention layer. We ﬁrst learn a generic precedence function us-
ing one or more geometric target ensembles, and then use the precedence function as the
kernel of an autodidactic agent.
Let us deﬁne an exploration parameter ξ ∈[0, 1] and a precedence (self-attention)
function f. At each step, the system size increases, K →K′, and can update one or
more spins (generally we want the spins to thermalize between growth steps). One then
samples a random variable from the unit interval, and accepts the update to K if the
random variable is less than ξ. If it is greater than ξ, then the update depends on previous
states according to f. The self-sampling feedback mechanism may be implemented as
an attention layer in a deep attention network, which uses a measure on a sequence of
prior states to predict the next state. In other words, we either use a uniform measure or
a learned measure to decide the next move. Over the course of the walk, the exploration
parameter moves from one extreme to the other, so that initial updates are all random
58

and ultimately updates are all determined according to prior updates. The trajectory in
the phase space crucially depends on ξ and f which, generally speaking, allow us to
formulate a random walk between any pair of endpoints in the phase space.
Now consider the following objective: learn the exploration function ξ and precedence
function f which guide the walker from a given source to a given target along an optimal
trajectory. The precedence function can be learned in the form of attention coefﬁcients
in a DNN using the methods described in [94]. The exploration function changes at a
rate compatible with the DNN converging, which makes it similar to a learning rate. The
output layer of the DNN is a probability measure on the set of variables one can update,
so we may use it as a means for an agent to sample moves, i.e., it encodes the policy. In
a reinforcement learning scenario, the agent does not modify the policy directly; rather,
it can modify the exploration function, which in turn modiﬁes the measure over moves.
In doing this, we assume that we can continuously deform the policy DNN while taking
ξ →0, i.e., that the attention coefﬁcients change adiabatically when the input data is
gradually changed. In practice, we presume the learned ξ and f give a near-optimal set
of transitions of variables which freeze, in a statistical sense, when the target is reached.
The goal, then, is to see if ξ and/or f are universal in some sense. If this is the case, one
might argue geometric self-assembly may arise as a generic precedence-based annealing
procedure.
5
Discussion
This paper is intended to launch a new program in theoretical physics and cosmology,
whose aim is to investigate a novel conception of the laws of physics - one in which laws
evolve, but evolve by learning.
In this section we address certain initial philosophical questions that might arise.
Intimations, from the remarks of Charles Sanders Peirce, to Linde’s and Susskinds
use of biological language to describe how laws might evolve on a ”landscape” of string
theories (in the context of eternal inﬂation), to works of one of the authors applying the
logic of natural selection to cosmological scenarios, are all distinct from what we have
in mind here. Learning, as we discussed in 1.1, either in living things or in universes
is largely a mechanism to preserve the good fortune arriving through lucky accidents -
what Jacques Monod called chance and necessity; here we describe autodidactic learning
from various perspectives.
Systems with phases that are distinguished in part by being harder- or easier-to-predict
are often described using methods from the mathematics of chaos theory, but learning is
not the same thing as chaos. Learning requires an information architecture in which the
past is no longer randomly or uniformly inﬂuential. Instead, the past becomes inﬂuential
in a concentrated way, associated with the consequencer, which will play a role here as a
type of reservoir.
In most physical systems, there is no consequencer because the presence of noise
59

erases any correlations with structures acquired in the past. But noise-resistant structures
can come about.
We’ve used the concept of a consequencer in order to have a name for state that makes
learning causal. If physical laws emerge from an autodidactic process, then a conse-
quencer is associated with any lack of randomness in which laws come to be. Emergence
guided by a consequencer is more likely to produce ”interesting” structures, meaning
structures that become optimized for a form of ﬁtness, or support ever higher level struc-
tures based on them. This claim is hard to state or prove formally, but it is clear that
machine learning architectures have achieved what other approaches to algorithms have
not achieved.
If laws can evolve, then they can do more: We consider the notion that only a universe
that learns its laws can be expected to engender novel phenomena like life and physicists.
5.1
Traversing and learning in theory space
We can think of the history of physics as a search through theories that can be expressed
in mathematical notation, but that space of theories is not ordered in a way that allows
for a machine-learning-like exploration.
The space of cubic matrix models gives rise, under various compactiﬁcations, limits,
and symmetry breakings, to a space of theories that may be ordered in terms of complex-
ity and other principles. It is traversable by learning algorithms.
Among other properties, an important feature of learning dynamics on a landscape of
theories should be the inclusion of theories we might recognize as low-energy or effective
descriptions of other, more fundamental theories. The space of theories described by
cubic matrix models is a good example of such a landscape.
In [18] it was demonstrated that Chern-Simons theory, BF theory,general relativity,
alone and coupled with Yang-Mills ﬁelds, all appear in it. Certain formulations of string
theory appear as well. What else might appear?
There are several ways to think about this project.
We might think of this as a search for new theories in a space of theories. In that
case, we might hope to ﬁnd new formulations for unifying GR and QFT that have more
desirable qualities, such as a way to prefer a small number of candidate theories instead
of vast numbers of them.
A similar, but distinct, idea is that we might ﬁnd an explanatory theory for why nature
has settled on GR and QFT and the standard model out of a vast landscape of other viable
theories.
A third idea, which might or might not be taken as distinct from the ﬁrst two, is that
our machine learning model is a model of how nature works, as she ﬁnds theories to
operate within.
Furthermore, some might wish to speculate about the history and context in which
cosmological autodidactic processes might take place. The readiest idea is to suppose
that autodidactic processes are features of the natural world emerging from the big bang,
60

but one might also speculate about a metaphysical context or prefer a more complex idea
of histories that could ”precede” the big bang. The latter approaches might be motivated
by quests to explain an expanded set of questions about initial conditions, for instance.
Our proposal is that the autodidactic concept need only be operational, at least at this
stage in our inquiry, and can remain neutral towards or accepting of varied ontological
assumptions. It can be examined independently of such assumptions. There is a useful
shade of difference between ontological agnosticism and metaphysics. In particular, this
work is neutral regarding hypotheses about the status of reality, as in [95]. We occasion-
ally use a contingent ontology as a story telling device, because it makes the telling easier,
but we are not committed to any such frame.
In this spirit, we have sketched how a search through theory spaces can be undertaken.
We presented a viable approach to specifying a traversable space of theories as well as
computational experiments in the iteration of autodidactic systems.
5.2
The Universe goes to school
A cosmological consequencer accumulates information based on the history of the uni-
verse. It is causally accessible, which is not typically the case for all the information about
the past of a system.
Consequencers can take many forms. The whole state of a system, even the whole
Universe, might inform a learning process (such as the evolution of laws, which concerns
us here), or it might be that the consequencer is associated with only a subset.
In the Principle of Precedence, for example, the consequencer for a quantum process
might be all the instances of similar processes in the past [52].
A consequencer is an information reservoir that can correlate and store the conse-
quences of choices made in diverse situations. The consequencer within a brain allows
an animal to evaluate what is the best course of action to take in a given circumstances,
for instance, without trying them out in the risky physical world.
Another word for a consequencer is, from a certain perspective, the imagination. It
stores information in a way that reﬂects patterns, so it also, to a degree, foresees fu-
ture circumstances. A learning system effectively recognizes situations similar to ones
it may have encountered before, so learning systems also effectively foresee novel situa-
tions with similarities to past ones that might arise in the future.
A consequencer can become recursive, so that it would allow a system to refer to itself,
and other versions of itself. This is an outcome resulting from the general capacity to
capture similarities between patterns. So let us say that a learner has the ability to improve
its success in a variety of circumstances, and that it is made possible by consequencers.
Here we consider some further qualities of consequencers.
61

5.2.1
Useless and usable information
One of the deepest laws of physics we know is the principle of inertia, discovered by
Galileo, which in Newton’s formulation tells us that any body undergoing uniform mo-
tion continues in that state of motion unless impeded by a force. Information is exchanged
when bodies interact, but usually not in a way that would constitute a consequencer.
Information can be present in the universe and yet be ”useless”, meaning certain in-
formation, such as the spin of a particle, might only be part of a statistical distribution
and of no individual consequence. The information associated with a particle, or even a
collection of particles that is smaller than, say, a pebble, needs either an architecture or ex-
traordinary good luck to make it operational as a signal of consequence. But information
architectures with bits as big as pebbles are slow, and have many other problems, making
them unlikely to appear either naturally or through engineering.
Therefore, information architectures typically amplify the causal powers of rather
small collections of particles12.
The information in a computer is held in an architecture so that any bit might be of con-
sequence. Certain bits - which we will deﬁne as interaction potentials based on measurement
thresholds of state within cells in a symmetric, addressable structure - can matter profoundly
more than other bits.
A bit requires two contextual qualities: 1) a position within a symmetrical structure
that can function as an address and 2) operational consistency in results of multiple simi-
lar measurements of the bit so that it can reliably be known to have a value. The same ap-
plies to qubits, though in that case, multiple measurements require multiple enactments
of a calculation.
The second requirement above is similar to the notion of redundant results in ascer-
tainments of the past, which is described in [97]. A coarse grained bundling of similar
measurements all giving the same result is needed to explain why bits are different from
other distributions. The notions of computation and architecture build on the idea of bits
to allow certain ones to be more causally accessible, or inﬂuential, than others.
A typical portion of the universe - excluding computational architectures - only con-
tains a uniform, minimalist structure to make information causal, creating the continuity
described by physical law: momentum/position, energy, and so on.
Computers in their rarity are closer to Aristotelian physics: a change in the current of a
wire persists until the next instruction to change. In other words, there is no conservation
of momentum, only a preservation of state. Even computers like quantum or analog
computers that run in a non-Aristotelian mode for a time must be set up repeatedly for
repeated runs in what is essentially an Aristotelian dynamic at the larger operative scale.
The common interpretation is that the universe initially did not have an information
architecture, unless one wishes to interpret conservation as an underlying architecture,
but then architecture appeared, initially in the repetitive form of galaxies, black holes,
12There have been proposals for computers to be made someday by rearranging stars [96], black holes,
or other objects that are much more massive than pebbles.
62

stars, planets, and so on, then in exuberant life, and then later still in our hopeful in-
tellectual designs. However, we are here considering the possibility that cosmological
architecture was more creative (and earlier so) than in the typical story.
Does a creative universe require that Aristotelian systems emerge out of Newtonian
ones? The ”latching” of the more abstract Aristotelian sense of memory might be the
lowest level quality that allows a system to become self-referential and evolutionary.
As stated earlier, a cosmic ray that changes a gene is much more likely to be Bateso-
nian, perhaps facilitating a chain of events that leads to ﬂying dinosaurs, for instance. It
is vanishingly unlikely for Shannon information to be Batesonized. Furthermore, even
the Batesonian information only has a slight chance of being predictably consequential.
DNA only has predictably consequential content when in an egg or a womb that matches
it. 13
Consequential information can be thought of as compressed or encrypted information
which is only relevant in the presence of matching algorithms.
Therefore a context, environment, key, or architecture must co-appear to make conse-
quential information effective. We argued that the presumed history of the DNA/RNA/protein
system exempliﬁes the problem with a consequencer being its own key or compiler: Com-
plex, cumulative questions cannot be asked, only ﬂeeting ones. Therefore, the history of
a consequencer probably requires alignment of parallel structures.
In the simulations reported earlier, we see parallel structures begin to appear where
there was only uniform evolution. These structures often preclude large sets of futures
from being possible. This reduction of futures is the ﬁrst step in the appearance of archi-
tectures that make information consequential, analogous to a pinhole camera restricting
light paths in order to make an image resolvable.
5.2.2
DNA and machine learning systems compared as consequencers
The DNA/RNA/protein system and machine learning models in a human technological
context can each be thought of as consequencers that are placed in speciﬁc slots within
larger structurs, but we have already imagined early autodidactic systems in which this
was not so.
Coexisting systems distinguished only by the rules followed by their components
could overlap and compete in an iterative process to destabilize each other as they evolve,
for instance. In that case there might be learning without insulated consequencers. It is
also conceivable that a learning consequencer would not require a multilevel structure as
does the DNA/RNA/protein system.
The DNA system is an example of a consequencer in nature which takes up only a
small portion of its universe. The internal states of a machine learning model, which are
hidden, or at least unintelligible outside of the model, provide another example.
13This does not suggest that the context for consequential content cannot ever be duplicated or synthe-
sized, as in [98].
63

The locality and architecture of a consequencer might not be unchanging as a system
learns. As argued earlier, the original consequencer that facilitated the emergence of the
DNA/RNA/protein system was probably less insulated than what is operative today.14
DNA relies on replication to perform new tests in order to gain new lessons. Machine
learning models have been conﬁgured in various ways, but do not typically rely on self-
replication, though the ﬁeld of ”artiﬁcial life” is devoted to ones that do. A broad framing
that includes the humans in the loop might ﬁnd that all computation is self-replicating,
however, in the sense of Marshall McLuhan’s quip that humans are the sexual organs of
machines.
A mutation of a DNA sequence in a gene - which we would classify as a component of
an autodidactic system - changes both the corresponding protein and its representation,
coded into sequences of base pairs.
We can call it an ”idea”, which is like an ”atom” of a consequencer. It is not always
the case that consequencer atoms can be isolated, nor are they likely to mean anything
in isolation. It is going too far to suggest that DNA speciﬁes a protein or the phenotype
of a creature. As stated earlier, DNA came to be ﬁne-tuned to interact with molecular
machinery in an environment like a womb or an egg to specify a protein or a creature.
Consequential information is meaningless without a matching architecture or context, so
the chicken and the egg and the DNA must evolve in tandem. An idea isn’t an idea
without context.
Note how the DNA-RNA-protein system does more than it needs to, if we imagine
that the survival of an individual or a species were speciﬁed as goals by a cosmic engineer.
The code and mechanisms that enable a creature to reproduce are sufﬁcient to encode the
construction of a vast number of other possible creatures, more than could ever be realized
in a Universe. Biology is not ergodic. More generally, we conjecture that a learning system
that causes novel conﬁgurations to come about is also likely to be exploring a space that
is too large for the learning system to be ergodic.
Reproduction and inheritance might be thought of as supervised learning, since a
species phenotype is constrained by its ecosystem and environment, but at a larger scale
evolution can be thought of as an unsupervised, or indeed an autodidactic system, seem-
ingly propelled to discover endless novelty and revolutionary designs. This shows that
an autodidactic system able to perform in a supervised mode might also perform in an
unsupervised one, given the right scale and circumstances. If laws evolve, they might
pass through epochs in which they are more constrained by either the present conﬁgu-
14To restate: There is not yet a convincing theory for the origin of it in which it was the ﬁrst molecular
mechanism that could encode information and reproduce, so it is possible that there were earlier periods
when antecedent or alternate chemistries were present. And yet not a trace has been found of these.
This earlier period would have been characterized by multiple interpenetrating molecular information
systems. It would probably have started before molecules evolved membranes to protect themselves to
a degree and become persistent enough for experiments to be consequential. They would have initially
interacted with each other with unconstrained promiscuity and violence. The consequencer in this period
would have been more distributed and diffuse than in the later period when the DNA system came to
dominate.
64

ration of their universe (something like being supervised), or past ones, as reﬂected in a
consequencer (more like being unsupervised).
Biology works because the mechanisms of template synthesis allow molecular pat-
terns to do their work alongside representations – ideas – of themselves15. We have con-
sidered how physical laws might evolve in the context a multilevel structure analogous
to biology, but the ideas will sometimes apply as well to universes that evolve laws using
a self-similar structure, analogous to a hypothetical epoch of pre-biological reproducing
molecules on Earth.
Non-trivial learning systems must come to be able to ”learn” from semi-persistent
complexes of states-of-self rather than ﬂeeting, disconnected self-states.
This is why
species exist in natural evolution. We stated a canonical example earlier: At some early
point in the evolution of life, we presume that early pre-gene-like sequences in self-
replicating molecules were maximally promiscuous, with horizontal transfers being the
only mechanism of change. Later on, membranes appeared, and virus-like forms tested
more persistent collections of genes against other such collections.
In a rough sense, the internal layers in a machine learning network are similar to
species. They accrue ”lessons” based on a complex, but only slowly changing - if chang-
ing at all - measurement architecture.
Learning systems have some of the properties that make biology possible: the prop-
erty of self-reference, i.e. they can ”learn” things about themselves and store information
in an architecture that makes it inﬂuential. The same mechanisms make it possible to
learn about other learning systems, or variants of themselves; the space of alternative
versions of themselves is so vast that a learning process typically cannot achieve ergodic-
ity given the age of the universe.
Furthermore, small changes in genes result in small changes in a phenotype at least
to the minimal degree that ”learning” can be incremental. If the relationship of genotype
to phenotype was more typically random, then ”preadaptation” might not be prevalent
enough for evolution to proceed. The coherence of preadaptations suggests that the pro-
cess of evolution not only models species, but models it’s own change to a degree.
5.2.3
Signal between a learning system and its environment
As we argued in 1.1, there are many types of learning. How would cosmological learning
compare to familiar examples?
Here are ﬁve examples of learning that have drawn great attention: 1) the speciation
from which organisms arise, 2) adaptive behaviors found in a wide range of natural or-
ganisms (including ”simple” ones), 3) intellectual learning in people and occasionally in
other big-brained species, 4) social processes such as scientiﬁc and legal scholarship, and
5) certain algorithms such as machine learning algorithms. Other examples have been
proposed, such as the Gaia hypothesis, which suggests that the biosphere on Earth dis-
plays learning behavior, and many ideas about how human societies at large come to be
15Learning systems have properties that will outlined in section ??
65

like intelligent organisms, but these ﬁve examples are generally accepted and have clear
structures. What we will note is that in all ﬁve cases it would be unimaginable to under-
stand what is happening without treating learning as a fundamental process. It is not an
option but a necessity.
There are important differences between concepts of learning that have been applied
with varying success to the same examples. For example, Richard Dawkins famously
coined the term ”meme” initially to suggest that ideas competed and evolved in a Dar-
winian sense, like genes. But the term (meme) eventually came to be understood as being
somewhat derogatory. It came to be more often used to tag an item that becomes valuable
because of network effect prominence rather than relevance to any other ﬁtness test. For
instance a company’s stock or a video clip might be called a meme because it is suddenly
popular, but would not otherwise be so valued. In that case, the machinery of learn-
ing is functioning without reference to external circumstances to which it might respond,
but only to circumstances within the learning mechanism. It is no longer adaptation but
might at best have a function as untethered, pre-adaptive churn.
The notion of ”learning” as we use it is more than moment-to-moment, brute adapta-
tion. It is a cumulative process which takes on abilities that can be thought of as theoriz-
ing, modeling, and predicting the environment in which it is responsive. For instance, the
DNA/RNA/protein system on Earth must have arisen from an adaptive process, and yet
it foresees a space of organisms much larger than could be called upon in any given mo-
ment of adaptation. It is doing ”more than it needs to” in any one circumstance. Learning
can be said to become ”imaginitive” as we put it in 1.1, or perhaps ”Maslowian”, ac-
cruing a tower of ever more reﬁned criteria enabled by previous criteria.16 Fitness for
brute survival is the most fundamental, or ”self-bootstrapped”, basis for adaptive learn-
ing, upon which other bases might arise. For instance, a scientist might learn out of
curiosity, and yet the scientist would not have come to exist were it not for a natural,
existential/Darwinian process.
But learning must also remain moored to reality, and not merely a theater of memes
or other artifacts of its own structure. A learning system must be able to maintain access
to signal from the environment even as its own structure becomes noisy. Another way to
put this is that learning must serve the ”Kantian whole”.
These remarks are intended to warn against a meme-like concept of cosmological
learning.
The formative events in a cosmological autodidactic process might have a
meme-like character, but eventually an environment must occur, and then the autodi-
dactic process must be sensitive to the environment, not only to its consequencer.
The example of memes in human social structures show that a learning system that
is not constrained by ”brute survival” can sometimes become dominated by ”economic
network effects” in self-reference. It is interesting to consider cosmological criteria other
than brute survival that might give rise to autodidactic structures that are resistent to be-
coming unconnected to an environment. The autodidactic principles we present are pre-
16This allusion should not be taken to endorse all uses of Maslow’s metaphors.
66

liminary candidates for meeting such criteria. While they concentrate inﬂuence from past
”lessons”, they do not necessarily become dominated by ”viral” or ”meme-like” events.
5.3
Might autodidactic ideas become necessary rather than optional?
We cannot know what unexpected phenomena will be observed in the future, but it is
possible that autodidactic ideas will gracefully explain some of them. But would that be
only a matter of preference or might it become difﬁcult to avoid autodidactic ideas?
The question of irreversibility in learning models was raised earlier, as it is a source
of potential tension with reversible theories in physics. An additional motivation for
considering irreversabilty is that if the learning of laws were reversible, then it would be
possible to consider only original laws, the latter laws being no more than conveniences
of interpretation.
5.3.1
Learning systems and irreversibility
We are initially motivated to consider change in laws because it is a way to explain why
certain laws are in effect now, though a vast landscape of other laws appear to also be
possible. But the laws of physics we observe at present are either unchanging in this
epoch or are only changing too slowly for the change to have been observed.
We are considering natural systems, and natural systems are typically conserved in
some ways. Therefore we assume a ”substantial” process is required for laws to change;
that such a process is not entirely arbitrary or free of interactions or constraints. We treat
”consmological learning” as a puzzle solver.
One implication is that if the evolution of laws is real, it is likely to be unidirectional,
for otherwise it would be common for laws to revert to previous states, perhaps even
more likely than for them to ﬁnd a new state. This is because a new state is not random
but rather must meet certain constraints, while the immediate past state has already met
constraints.
A reversible but evolving system would randomly explore its immediate past fre-
quently. When we see an evolving system that displays periods of stability, it probably
evolves unidirectionally.
Biology enacts approximate, punctuated stabilities in order for evolutionary experi-
ments to take place. A species in a successful niche can change little over long periods
of time despite phenotypically irrelevant genotypic churn. Biological evolution can only
ever approximately backtrack; it is essentially locked into forward motion only. (Marine
mammals resemble ﬁsh but only superﬁcially.) These two observations are consistent
with one another.
Biology inherits fundamental properties from the physics of its universe. Physical
laws must give rise to irreversible processes for biology to be irreversible. If we wish
to minimize reliance on metaphysical assumptions, we should assume a conscilience be-
tween laws and the process that evolves laws.
67

If fundamental physics evolves, we should expect laws to evolve in a way that sup-
ports irreversible change, since they are subject to themselves, being in the same universe.
The laws that have evolved support irreversible phenomena, so the evolution of laws is
likely to also give rise to operational irreversibility. This is not the same as being abstractly
irreversible, as we will argue in the next section.
It is natural to ask whether, if fundamental physics is to be modeled by a learning
machine, the irreversibility of the learning machine should be part of the explanation for
the irreversibility of nature.
For example, some learning machines incorporate a quench step, which thermalizes
the system at temperature T and then takes T lower. It is interesting to imagine this
playing a role in a model of the early universe.
5.3.2
Can irreversible learning systems arise from reversible laws?
We are examining whether the Universe is a learning computer. How does the reversibil-
ity question play out in our investigation? Can the universe learn in a way that is irre-
versible while also being based on fundamental laws that are almost entirely conserved,
reversible, and deterministic?
The conventional answer is that it can, because the initial conditions are asymmetric
under reversals in time; as such a reversal would turn an expanding universe into a col-
lapsing universe. However one thinks about this consideration, here is sought a different
type of explanation for irreversibility: an emergent one.
We know from Landauer’s principle that machines that learn are dissipative unless
they record their history in order to be reversible. Such machines become irreversible in
time [99] at large scales because the memory requirements to retain reversibility become
unavailable.
However, laws of physics are conservative and reversible in time, provided some de-
tails related to weak interactions are taken into account. Therefore, ”learning” computa-
tion which generates unforeseen states would seem to have a different character than the
universe with which it operates, and might not serve well as a model for that universe.
This is a general issue, potentially affecting all of the vast number of numerical models
of use in physics. Rounding errors in numerical simulations, for instance, are not merely
errors, but potentially deceptive stories.
A number resulting from a simulation might be what it is for any number of reasons;
to know if ”a rounding error” is the correct story requires retracing the steps that led to
the number. This is hard to do, but doable, because scientiﬁc simulations are designed
speciﬁcally to support this process. The nuisance is familiar in astronomy, for instance,
when rounding errors become signiﬁcant. [100].
For our purposes, we note that when a result comes out of a computer or some other
systemic representation of abstractions, then errors can become better liars - or if one
chooses optimism, can become more likely channels for learning, innovation, or evolu-
tion.
68

We can consider a limited question: Can a conserved, reversible, deterministic, phys-
ical universe without ”just so” starting conditions contain a learning system that has dif-
ferent qualities?
An operationally irreversible computation can take place within such a universe. Here
is why: A reversible process requires not only that the entire information of its past exist
in some sense, but that it can speciﬁcally be accessed as causal information. This requires
an architecture for accessing it - additional information - that would become very large.
Small reversible computers can be built, but large ones cannot.
It might be objected that if the universe is fundamentally reversible, then it should not
matter if a reverse is only hypothetical. The laws at the lowest level work - in that case -
both forwards and backwards, after all.
Any classical computer program can hypothetically be reversed, given enough mem-
ory to store its history. If such storage is not enacted, we cannot call an arbitrary program
reversible in practice. The reason is that the additional information disambiguates pro-
foundly vast numbers of possible prior state progressions of the program that would all
be otherwise viable as theories about the past. (This is a feature of an Aristotelian system.)
Leaving aside the question of whether a previous state is the only one possible to
explain the current state, we must also ask whether the present state presents sufﬁcient
opportunity to calculate prior states.
Consider a computer forensics expert asked to reconstruct how a program came to a
result. There are techniques to discern how magnetic marks on a hard drive had been set
previously, but those are semi-persistent marks, so it is not surprising that careful study
can retrieve traces from previous marks.
However, consider the previous states of gates in a semiconductor chip. All the previ-
ous gate states are ”out there” in the radiation generated by the device, but the only way
to retrieve them would require comprehensive measurement of every particle that had
a causal relationship with that radiation, and a comparative analysis of those measure-
ments. Leaving aside measurement problems, and whether one believes the prior states
of the gates must somehow be out there, even if one does believe and one can measure,
it is clear that the forensics project would require resources of tremendous scope. The
computer needed to reverse a computer that had not planned to be reversed would be
have to be profoundly vaster than the original.
If we are talking about physical systems, we must distinguish between what can hap-
pen and what cannot. If a reverse cannot be engineered, even in the most wild specula-
tions, then that reverse should be treated as ontologically different from a reverse that can
at least hypothetically take place in reality.
Another way to put it is that an engineer working with arbitrarily impressive re-
sources from outside of the universe could perhaps take advantage of the reversibility
of foundational laws in order to reverse the universe, but no engineer working inside the
universe could ever muster the resources - such as a large enough memory - to reverse it.
They would undo their own labor.
So we can say that computational systems within our universe, including learning
69

systems, can be operationally irreversible, even if the underlying physical laws are re-
versible.
This does not imply monotonic changes in any particular property of a learning sys-
tem. Some viruses have relatively large genomes and others have relatively small ones,
and yet there is little evidence that phenotype vigor tracks the scale of the genome.
This framework places limits on how much we can interpret the past of consequencers
even when we can recover a detailed history of a consequencer’s states. Old learning only
makes sense in the context of the old conditions for learning. The history of a germ line
can be recovered approximately; we can infer the history of genes. What we cannot hope
to represent is the whole of the ”lesson” that inﬂuenced the evolution of genes.
6
Conclusion
This paper is one of a growing number that attack the question of why these laws?
Why these gauge groups, why these fermion and scalar representations, why the mys-
teries of chirality, CP violation, and baryogengesis? Why the vast hierarchies of scale and
why the particular ratios of parameters of the standard model, setting the values of the
masses and mixing angles? It is sobering to contemplate that not one problem of this type
has ever been solved, going all the way back to the measurements of the electron’s mass
and charge.
Roughly speaking, we are faced with a single stark choice:
Either: There are no rational reasons for any of these choices. The universe might have
been very different, but there will never be a reason why it took the path we observe it
on.
Or: There is at least one rational explanation - in which case we are obligated to ﬁnd
it. To ask the question is to suppose that, for instance, the constants could have been
different, but not randomly so. A scientiﬁc explanation would suggest that their values
are set as the result of a dynamical process, which means it can be modelled analogously
to all the other time dependent processes we are familiar with.
Here we consider a wide class of mechanisms based on the idea of learning. We ask
whether there might be a mechanism woven into the fabric of the natural world, by means
of which the universe could learn its laws. To investigate this question we had to under-
stand what learning is and how it differs from other ways a dynamical system can evolve.
This led us to the idea of the consequenser, which allows a system to respond to clues in
its environment by altering its responses.
Of course, this is just a ﬁrst step. Learning is a complex, heterogeneous and broad set
of behaviours. There are many different ways to learn. This paper reports some of our
results from an ongoing search for ways that a system of laws, governing particles and
ﬁelds, might either naturally or artiﬁcially come upon and learn the trick for, well, learn-
ing. These employ the renormalization group, the idea that there are no laws except to
follow precedence, self-sampling methods, systems that maximize variety and geometri-
70

cal self-assembly, and a direct mapping from a mathematical model of a learning system
into the equations of motion of a general relativity and gauge ﬁelds. The last-mentioned
effort establishes a three way correspondences between learning machines, gauge and
gravitational ﬁelds, and matrix models.
There are varied potential spin-offs from our approach: Our models might suggest
architectures for quantum machine learning systems. We might ﬁnd a way to use ma-
chine learning to simulate quantum or classical gauge ﬁeld theories. If we add controlled
couplings to external thermal reservoirs, we might be able to simulate the interplay of
thermal and quantum effects in a range of models of the early universe.
Achieving any of this would be a stunning advance. So it is with trepidation and
caution that we mention two more paths these ideas might motivate, each wildly more
ambitious than what we have just mentioned.
Imagine if we could use the correspondences discussed here to construct learning ma-
chines out of the degrees of freedom of gauge and gravitational ﬁelds. Perhaps one ver-
sion of this would be to construct a quark computer which computes using the spins and
isospins of quarks and gluons as qubits.
But beyond that, the correspondences suggest that the effective degree of freedom of
the actual vacuum of a quantum gravity or gauge ﬁeld might naturally evolve to become
an autodidactic learning system. This might be part of the explanation for the choices
of gauge ﬁelds and representations and values of the coupling constants of the standard
model.
Since the correspondence organizes a landscape of theories, it might lead to a search
in such a landscape, which might lead to discoveries of note, or might even serve as a
model for what the universe might be doing.
The results here are tiny, baby steps towards these hypotheses, to be further explored
in future work.
Acknowledgments
Research at Perimeter Institute is supported in part by the Government of Canada through
the Department of Innovation, Science and Economic Development Canada and by the
Province of Ontario through the Ministry of Colleges and Universities.
Microsoft provided computational, logistical and other general support for this work.
The authors thank Kevin Scott of Microsoft in particular for support of this project.
Authors Stefan Stanojevic and Michael W. Toomey were supported in this work as
research interns at Microsoft Research.
Authors Jaron Lanier and Dave Wecker were supported as researchers at Microsoft.
Author Jaron Lanier thanks Chetan Nayak for helpful challenges and discussion.
Author Lee Smolin’s work in these areas has been generously supported by NSER,
FQXi and the John Temleton Foundation. He would like to thank Marina Cortes, Andrew
Liddle, Stuart Kauffman, Clelia Verde for collaborations on related projects and Bianca
71

Dittrich, Laurent Friedel, Carlo Rovelli, and Yigit Yargic for encouragement and criticism.
72

References
[1] Charles Sanders Peirce. Architecture. March 1893.
[2] B. J. Carr and M. J. Rees.
The signiﬁcance of numerical coincidences in nature.
Nature 278, 1967.
[3] Barrow and Tipler.
The Anthropic Cosmological Principle.
(Oxford University
Press,Oxford), 1986.
[4] Lee Smolin. Life of the Cosmos. Oxford University Press, New York, 1997.
[5] Leonard Susskind. The Athropic landscape of String Theory. 2003.
[6] Raphael Bousso and Joseph Polchinski.
The string theory landscape.
Scientiﬁc
American, 291(3):78–87, 2004.
[7] Washington Taylor and Yi-Nan Wang. The f-theory geometry with most ﬂux vacua.
Journal of High Energy Physics, 2015(12):1–21, 2015.
[8] Lee Smolin. Did the universe evolve? Classical and Quantum Gravity, pages 173–
191, 1992.
[9] Lee Smolin. A perspective on the landscape problem, invited contribution for a
special issue of foundations of physics titled: Forty years of string theory: Reﬂecting
on the foundations. Foundations In Physics, feb 2012.
[10] Washington Taylor. Matrix theory: matrix quantum mechanics as a fundamental
theory. Reviews of Modern Physics, 73(2):419–461, Jun 2001.
[11] S.-S. Chern and J. Simons. Characteristic forms and geometric invariants. Annals
of Mathematics, 99 (1):48–69, 1974.
[12] G. Horowitz.
Exactly soluble diffeomorphism invariant theories. page 125:417,
1989.
[13] Jerzy F Pleba´nski.
On the separation of einsteinian substructures.
Journal of
Mathematical Physics, 18(12):2511–2520, 1977.
[14] Lee Smolin. Plebanski action extended to a uniﬁcation of gravity and yang-mills
theory. Physical Review D, 80(12), Dec 2009.
[15] A Garrett Lisi, Lee Smolin, and Simone Speziale. Uniﬁcation of gravity, gauge ﬁelds
and higgs bosons. Journal of Physics A: Mathematical and Theoretical, 43(44), Oct
2010.
73

[16] Stuart Russell and Peter Norvig. Artiﬁcial intelligence: a modern approach. Pear-
son, 2021.
[17] Lee Smolin. The cubic matrix model and the duality between strings and loops.
June 2000.
[18] Lee Smolin. Matrix universality of gauge and gravitational dynamics, 2008.
[19] Lee Smolin. M theory as a matrix extension of chern-simons theory. Feb 2000.
[20] Lee Smolin. The exceptional jordan algebra and the matrix string. April 2001.
[21] Lee Smolin Etera R. Livine. Brst quantization of matrix chern-simons theory. Dec
2002.
[22] T. Banks, W. Fischler, S.H. Shenker, and L. Susskind.
[23] J Hoppe. Ph.D. thesis (Massachusetts Institute of Technology), 1982.
[24] H. Nicolai B. de Wit, J. Hoppe. Nuclear Physics B305 (1988) 545, 1988.
[25] Hoppe J. On the construction of zero energy states in supersymmetric matrix mod-
els i, ii, iii.
[26] Chiara Moletta. The Science of Can and Can’t. Penguin Random House, 2021.
[27] Marc-Alexandre Cˆot´e and Hugo Larochelle. An inﬁnite restricted boltzmann ma-
chine. Neural Comput., 28(7):1265–1288, July 2016.
[28] Vitaly Vanchurin. The world as a neural network. Entropy, page 1210, 2020.
[29] Miles Cranmer, Sam Greydanus, Stephan Hoyer, Peter Battaglia, David Spergel,
and Shirley Ho. Lagrangian neural networks, 2020.
[30] Michael Schmidt and Hod Lipson. Distilling free-form natural laws from experi-
mental data. Science, 324(5923):81–85, 2009.
[31] Sam Greydanus, Misko Dzamba, and Jason Yosinski. Hamiltonian neural networks,
2019.
[32] Patrick M. Lenggenhager, Doruk Efe G¨okmen, Zohar Ringel, Sebastian D. Huber,
and Maciej Koch-Janusz. Optimal renormalization group transformation from in-
formation theory. Physical Review X, 10(1), Feb 2020.
[33] Maciej Koch-Janusz and Zohar Ringel. Mutual information, neural networks and
the renormalization group. Nature Physics, 14(6):578–582, Mar 2018.
74

[34] Koji Hashimoto, Sotaro Sugishita, Akinori Tanaka, and Akio Tomiya. Deep learning
and the ads/cft correspondence. Physical Review D, 98(4), Aug 2018.
[35] Koji Hashimoto. Ads/cft correspondence as a deep boltzmann machine. Physical
Review D, 99(10), May 2019.
[36] Samuel S. Schoenholz, Jeffrey Pennington, and Jascha Sohl-Dickstein. A correspon-
dence between random neural networks and statistical ﬁeld theory, 2017.
[37] Henry W. Lin, Max Tegmark, and David Rolnick. Why does deep and cheap learn-
ing work so well? Journal of Statistical Physics, page 1223–1247, 2017.
[38] R Capovilla, J Dell, T Jacobson, and L Mason.
Self-dual 2-forms and gravity.
Classical and Quantum Gravity, 8(1):41–57, jan 1991.
[39] Lee Smolin. Uniﬁcation of the state with the dynamical law, 2012.
[40] Olafs Vandans, Kaiyuan Yang, Zhongtao Wu, and Liang Dai. Identifying knot types
of polymer conformations by machine learning. Phys. Rev. E, 101:022502, Feb 2020.
[41] Stephen Wolfram. A Project to Find the Fundamental Theory of Physics. Wolfram
Media, 2020.
[42] Jaron Lanier. Gordian software. Edge, 2003.
[43] J.F. C´ardenas-Garc´ıa. The process of info-autopoiesis – the source of all information.
Biosemiotics, 13:199–221, 2020.
[44] Robert de Mello Koch Ling Cheng Ellen de Mello Koch. Is deep learning a renor-
malization group ﬂow. 12 Jun 2019.
[45] Leo P Kadanoff. Scaling laws for ising models near t c. Physics Physique Fizika,
2(6):263, 1966.
[46] C´edric B´eny. Deep learning and the renormalization group, 2013.
[47] G. Vidal. Class of quantum many-body states that can be efﬁciently simulated.
Physical Review Letters, 101(11), Sep 2008.
[48] Shuo-Hui Li and Lei Wang.
Neural network renormalization group.
Physical
Review Letters, 121(26), Dec 2018.
[49] Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using
real nvp, 2016.
[50] Pankaj Mehta and David J. Schwab. An exact mapping between the variational
renormalization group and deep learning, 2014.
75

[51] Stavros Efthymiou, Matthew J. S. Beach, and Roger G. Melko. Super-resolving the
ising model with convolutional neural networks. Physical Review B, 99(7), Feb
2019.
[52] Lee Smolin. Precedence and freedom in quantum physics. 5 2012.
[53] Lucien Hardy. Operational general relativity: possibilistic, probabilistic, and quan-
tum. arXiv preprint arXiv:1608.06940, 2016.
[54] Lluis Masanes and Markus P. Muller. A Derivation of quantum theory from physi-
cal requirements. New J. Phys., 13:063001, 2011.
[55] Steven Weinstein. Learning the einstein-podolsky-rosen correlations on a restricted
boltzmann machine, 2017.
[56] Gregory Bateson. Steps to an ecology of mind: Collected essays in anthropology,
psychiatry, evolution, and epistemology. University of Chicago Press, 2000.
[57] Martin Gardner. Mathematical games: The fantastic combinations of john conway’s
new solitaire game ”life”. pages 120–123, 1970.
[58] David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew
Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel,
et al. A general reinforcement learning algorithm that masters chess, shogi, and go
through self-play. Science, 362(6419):1140–1144, 2018.
[59] Julian Barbour and Lee Smolin. Extremal variety as the foundation of a cosmologi-
cal quantum theory, 1992.
[60] Gottfried Wilhelm Leibniz. Discourse on metaphysics. In Philosophical papers and
letters, pages 303–330. Springer, 1989.
[61] Lee Smolin. Quantum mechanics and the principle of maximal variety. Foundations
of Physics, 46(6):736–758, Mar 2016.
[62] Carlo Rovelli. Relational quantum mechanics. International Journal of Theoretical
Physics, 35(8):1637–1678, Aug 1996.
[63] Sumati Surya. The causal set approach to quantum gravity. Living Reviews in
Relativity, 22(1):1–75, 2019.
[64] Daniel J Kleitman and Bruce L Rothschild. Asymptotic enumeration of partial or-
ders on a ﬁnite set. Transactions of the American Mathematical Society, 205:205–
220, 1975.
[65] Marina Cortˆes and Lee Smolin. Quantum energetic causal sets. Physical Review D,
90(4), Aug 2014.
76

[66] ”Kuchar and Karel. 1971.
[67] P. Erd¨os and A. R´enyi. Asymmetric graphs. Acta Mathematica Hungarica, 14:295,
1963.
[68] Lothar Von Collatz and Ulrich Sinogowitz.
Spektren endlicher grafen.
In
Abhandlungen aus dem Mathematischen Seminar der Universit¨at Hamburg, vol-
ume 21, pages 63–77. Springer, 1957.
[69] Francis K Bell.
A note on the irregularity of graphs.
Linear Algebra and its
Applications, 161:45–54, 1992.
[70] B.M. ´Abrego, S. Fern´andez-Merchant, M.G. Neubauer, and W. Watkins. Sum of
squares of degrees in a graph. J. Inequal. Pure Appl. Math., 10:1, 2009.
[71] M.O. Albertson. The irregularity of a graph. Ars. Comb., 46:219, 1997.
[72] H. Abdo, S. Brandt, and D. Dimitrov. The total irregularity of a graph. DMTCS,
16:201, 2014.
[73] Hosam Abdo, Nathann Cohen, and Darko Dimitrov. Graphs with maximal irregu-
larity. Filomat, 28(7):1315–1322, 2014.
[74] Ernesto Estrada.
Quantifying network heterogeneity.
Physical Review E,
82(6):066102, 2010.
[75] Gary Chartrand, Paul Erd¨os, and Ortrud R Oellermann. How to deﬁne an irregular
graph. The College Mathematics Journal, 19(1):36–42, 1988.
[76] Yousef Alavi, Gary Chartrand, Fan RK Chung, Paul Erd¨os, Ronald L Graham, and
Ortrud R Oellermann. Highly irregular graphs. Journal of Graph Theory, 11(2):235–
249, 1987.
[77] Claire Donnat, Marinka Zitnik, David Hallac, and Jure Leskovec. Learning struc-
tural node embeddings via diffusion wavelets.
Proceedings of the 24th ACM
SIGKDD International Conference on Knowledge Discovery & Data Mining, Jul
2018.
[78] Lee Smolin. Einstein’s unﬁnished revolution: The search for what lies beyond the
quantum. Penguin Books, 2020.
[79] P Erdos and A Renyi. On random graphs i. Publ. math. debrecen, 6(290-297):18,
1959.
[80] Leonardo F.R. Ribeiro, Pedro H.P. Saverese, and Daniel R. Figueiredo. struc2vec.
Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, Aug 2017.
77

[81] Jeff Cheeger, Werner M¨uller, and Robert Schrader. On the curvature of piecewise
ﬂat spaces. Communications in mathematical Physics, 92(3):405–454, 1984.
[82] Zhihao Wu, Giulia Menichetti, Christoph Rahmede, and Ginestra Bianconi. Emer-
gent complex network geometry. Scientiﬁc reports, 5(1):1–12, 2015.
[83] Daan Mulder and Ginestra Bianconi. Network geometry and complexity. Journal
of Statistical Physics, 173(3):783–805, 2018.
[84] Christy Kelly, Carlo A Trugenberger, and Fabio Biancalana. Self-assembly of geo-
metric space from random graphs. Classical and Quantum Gravity, 36(12):125012,
2019.
[85] Christy Kelly, Carlo Trugenberger, and Fabio Biancalana. Emergence of the circle in
a statistical model of random cubic graphs, 2020.
[86] Pim van der Hoorn, William J. Cunningham, Gabor Lippner, Carlo Trugenberger,
and Dmitri Krioukov. Ollivier-ricci curvature convergence in random geometric
graphs, 2020.
[87] Mari´an Bogu˜n´a, Ivan Bonamassa, Manlio De Domenico, Shlomo Havlin, Dmitri
Krioukov, and M ´Angeles Serrano. Network geometry. Nature Reviews Physics,
pages 1–22, 2021.
[88] Christy Kelly, Carlo Trugenberger, and Fabio Biancalana. Convergence of combina-
torial gravity, 2021.
[89] Alejandro Perez. The spin-foam approach to quantum gravity. Living Reviews in
Relativity, 16(1):1–128, 2013.
[90] Renate Loll.
Quantum gravity from causal dynamical triangulations: a review.
Classical and Quantum Gravity, 37(1):013002, 2019.
[91] Neil Turk. The universe within. Massay Lectures, page 312, September 2012.
[92] Gavin E Crooks.
Measuring thermodynamic length.
Physical Review Letters,
99(10):100602, 2007.
[93] Shun-ichi Amari. Information geometry. Japanese Journal of Mathematics, pages
1–48, 2000.
[94] Petar
Veliˇckovi´c,
Guillem
Cucurull,
Arantxa
Casanova,
Adriana
Romero,
Pietro Lio, and Yoshua Bengio.
Graph attention networks.
arXiv preprint
arXiv:1710.10903, 2017.
[95] Klee Irwin, Marcelo Amaral, and David Chester. The self-simulation hypothesis
interpretation of quantum mechanics. Entropy, 22(2), 2020.
78

[96] Jaron Lanier. Rearranging stars to communicate with aliens. Discover, February
2008.
[97] C. Jess Riedel, Wojciech H. Zurek, and Michael Zwolak. Objective past of a quantum
universe: Redundant records of consistent histories. Physical Review A, 93(3), Mar
2016.
[98] Shani Aguilera-Castrejon, Oldak.
Ex utero mouse embryogenesis from pre-
gastrulation to late organogenesis. Nature, 2021.
[99] Simon Portegeise Zwart. The future. Computational astrophysics, 361(6406 979),
September 2018.
[100] Simon F. Portegies Zwart and Tjarda C. N. Boekholt. Numerical veriﬁcation of the
microscopic time reversibility of newton’s equations of motion: Fighting exponen-
tial divergence. Communications in Nonlinear Science and Numerical Simulation,
1-10(00), 2018.
[101] S. Kauffman. Reinventing the Sacred. Basic Books, N. Y. (2008).
[102] S. Kauffman.
A World Beyond Physics: The Emergence and Evolution of Life?
Oxford University Press, Oxford (2019).
[103] S. Kauffman Answering Schrodinger’s “What is Life?” Entropy 22, 815 (2020).
79

