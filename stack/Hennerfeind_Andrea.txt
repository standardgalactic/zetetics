Bayesian nonparametric regression for
survival and event history data
Andrea Hennerfeind
M¨unchen, 17.03.2006


Bayesian nonparametric regression for
survival and event history data
Andrea Hennerfeind
Dissertation
an der Fakult¨at f¨ur Mathematik, Informatik und Statistik
der Ludwig–Maximilians–Universit¨at
M¨unchen
vorgelegt von
Andrea Hennerfeind
aus Freising
M¨unchen, den 17.03.2006

Erstgutachter: Prof. Dr. Ludwig Fahrmeir
Zweitgutachter: Prof. Dr. Stefan Lang
Drittgutachter: Prof. Dr. Claudia Czado
Rigorosum: 22.6.2006

v
Vorwort
Diese Arbeit entstand w¨ahrend meiner T¨atigkeit als Mitarbeiter im Sonderforschungs-
bereich 386 ”Statistische Analyse diskreter Strukturen” am Institut f¨ur Statistik an der
LMU M¨unchen und wurde somit durch Mittel der Deutschen Forschungsgemeinschaft
gef¨ordert. In diesen Jahren haben mich viele Leute begleitet, die wesentlich zum Gelingen
meiner Dissertation und zu einem angenehmen Arbeitsklima beigetragen haben.
Zu allererst m¨ochte ich meinem Doktorvater Ludwig Fahrmeir aufrichtig f¨ur seine hervor-
ragende Betreuung danken. Ohne sein Vertrauen, seine Unterst¨utzung und seine sympa-
thische, unkomplizierte und wohlwollende Art, w¨are diese Arbeit sicher nie entstanden. Ein
ganz besonderer Dank gilt auch meinem Zweitgutachter Stefan Lang, der mir in den vergan-
genen Jahren in den verschiedensten Hinrichtungen (mein aktueller Lieblings–Versprecher)
eine unendlich große Hilfe war.
Des weiteren geb¨uhrt mein Dank auch allen ¨ubrigen Lehrstuhl– und Institutsmitarbeitern.
Insbesondere danke ich Christiane Belitz und Leyre Osuna, die das zweifelhafte Vergn¨ugen
hatten, mich als B¨urokollegin zu haben. Beide haben entscheidend dazu beigetragen, dass
ich mich am Institut so wohl gef¨uhlt habe und standen mir bei allen kleineren und gr¨oßeren
Problemen stets mit Rat und Tat zur Seite. Entgegen anders lautender Ger¨uchte musste
ich im ’M¨adchenb¨uro’ zum Gl¨uck nie ¨uber die neueste Schuhmode diskutieren. Bei Thomas
Kneib m¨ochte ich mich f¨ur die vielen hilfreichen Diskussionen und Inspirationen bedanken.
’Du tatest etwas großes ohne Geld zu kalkulieren.’ Meiner ’Grundausstattung’ Alexander
Jerak habe ich meine Existenz als ’Erg¨anzungsausstattung’ zu verdanken. Danke auch f¨ur
die vielen aufbauenden Worte, wenn wir alle mal wieder an unseren F¨ahigkeiten gezweifelt
haben. Auf keinen Fall unerw¨ahnt lassen m¨ochte ich Renata Gebhardt, die durch ihre
lebendige Art stets f¨ur Aufmunterung gesorgt hat, und Susanne Heim, die f¨ur unsere Fort-
bildungsreise nach Florenz die sch¨onste aller Unterk¨unfte ausﬁndig gemacht hat und stets
eine kompetente Ansprechpartnerin in Sachen ’fMRI’ war. Bei Petra Kragler m¨ochte ich
mich herzlich f¨ur Ihre Formulierungshilfen und gelegentliche Aufmunterungen bedanken.
Weiterhin m¨ochte ich mich bei meinen Koautoren Leonhard Held und Erik Sauleau f¨ur die
angenehme und fruchtbare Zusammenarbeit bedanken. Claudia Czado danke ich daf¨ur,
dass sie sich meiner Arbeit freundlicherweise als externe Gutachterin angenommen hat.
Nicht zuletzt m¨ochte ich von ganzem Herzen meinen Eltern und meiner Schwester danken,

vi
die immer vollstes Vertrauen in mich gesetzt haben und mir den n¨otigen famili¨aren R¨uckhalt
gegeben haben. Danke, dass ich mich immer voll auf Euch verlassen kann!
Mein gr¨oßter Dank gilt meinem Freund Andreas Brezger, der immer f¨ur mich da war.
Danke f¨ur die endlosen fachlichen Diskussionen und Erl¨auterungen, f¨ur wertvolle Ratschl¨age,
f¨ur all die Ermutigungen, f¨ur den Trost und die Ablenkung und nat¨urlich auch f¨ur die vie-
len sch¨onen gemeinsamen Erlebnisse in den letzten Jahren!
M¨unchen, Juli 2006
Andrea Hennerfeind

vii
Zusammenfassung
Die ¨Uberlebenszeitanalyse, oder allgemeiner die Verweildaueranalyse ﬁndet in der Praxis
zahlreiche Anwendungen vom klassischen Fall der klinischen Studie bis hin zur Model-
lierung von Kreditrisiken. Oftmals sind die Standard–Modelle jedoch nicht ﬂexibel genug,
um der Modellierung komplexer Kovariableninformationen gerecht zu werden. Neben para-
metrisch und nichtparametrisch modellierten Kovariableneﬀekten, sowie r¨aumlichen Eﬀek-
ten und zuf¨alligen Eﬀekten zur Ber¨ucksichtigung von unbeobachteter Heterogenit¨at, ist
bei der Verweildaueranalyse auch h¨auﬁg eine ﬂexible, nichtparametrische Modellierung
von zeitlich variierenden Eﬀekten gefragt.
Diese Arbeit besch¨aftigt sich mit der Entwicklung von Bayesianischen Verweildauer-
modellen, die Erweiterungen des klassischen Cox–Modells darstellen. Indem die Hazardrate
durch einen strukturierten additiven Pr¨adiktor modelliert wird, entsteht ein ﬂexibles Mo-
dell zur Analyse von stetigen Verweildauern unter ad¨aquater Ber¨ucksichtigung verschie-
denster Arten von Kovariablen. Zeitlich variierende Eﬀekte werden dabei durch P–Splines
modelliert. Die Sch¨atzung erfolgt mit Hilfe von Markov Chain Monte Carlo Verfahren.
Weitere Kapitel besch¨aftigen sich mit der sogenannten relativen ¨Uberlebenszeitanalyse
und mit Mehrzustandsmodellen. Bei ersterem geht es darum, ein zus¨atzliches Risiko einer
bestimmten Subpopulation zu modellieren, das ¨uber das allgemeine Risiko in der gesamten
Population hinaus besteht. Mehrzustandsmodelle stellen eine Verallgemeinerung der Ver-
weildauermodelle dar.
Anstelle eines bestimmten ¨Ubergangs k¨onnen hier mehrere ver-
schiedene ¨Uberg¨ange simultan analysiert werden.
Die in dieser Arbeit vorgestellten Methoden werden jeweils auf komplexe, reale Problem-
stellungen angewandt und erweisen sich als wirkungsvolle und ﬂexible Instrumente.
Abstract
Survival analysis, or more generally duration time analysis has a large number of practi-
cal applications ranging from the classical ﬁeld of clinical studies to credit risk analysis. In
most cases however, standard survival models do not oﬀer enough ﬂexibility to give appro-
priate consideration to modelling complex covariate eﬀects. In addition to parametric and

viii
nonparametric eﬀects as well as spatial eﬀects and random eﬀects to capture unobserved
heterogeneity, duration time analysis often demands a ﬂexible nonparametric estimation
of time–varying eﬀects.
This thesis is concerned with developing Bayesian duration time models representing
extensions to the classical Cox model. Modelling the hazard rate through a structured
additive predictor leads to a ﬂexible model for the analysis of continuous duration times
having regard to the inﬂuence of several diﬀerent types of covariates. Time–varying eﬀects
are modelled by P–splines. Inference is accomplished using Markov Chain Monte Carlo
simulation techniques.
Further topics are the so–called relative survival analysis and multi–state models. The
former topic is concerned with modelling the excess risk of a certain subpopulation relative
to the base risk that is present in the whole population. Multi–state models are a general-
ization of duration time models. Instead of analyzing one particular transition only they
allow for the simultaneous analysis of diverse transitions.
The methods presented within this thesis are applied to several complex, real problems
and prove to be eﬀective and ﬂexible tools.

Contents
Vorwort
v
1
Introduction
1
1.1
Basic concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
1.2
The Cox model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.3
Extensions of the Cox model . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.4
Full likelihood . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
1.4.1
Right censoring . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
1.4.2
Left truncation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
1.4.3
Time–varying covariates . . . . . . . . . . . . . . . . . . . . . . . .
9
1.5
Modelling the baseline hazard . . . . . . . . . . . . . . . . . . . . . . . . .
11
1.5.1
Weibull model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
1.5.2
Piecewise exponential model (p.e.m.) . . . . . . . . . . . . . . . . .
12
1.5.3
P–spline model . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
1.6
Relations to other survival models . . . . . . . . . . . . . . . . . . . . . . .
19
1.6.1
Discrete time survival analysis . . . . . . . . . . . . . . . . . . . . .
19
1.6.2
Log–location–scale models . . . . . . . . . . . . . . . . . . . . . . .
22
1.7
Competing risks and multi–state models
. . . . . . . . . . . . . . . . . . .
23
1.8
Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
2
Nonparametric regression for survival data
27
2.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
2.2
Models, likelihood and priors . . . . . . . . . . . . . . . . . . . . . . . . . .
30
2.2.1
Observation model and likelihood . . . . . . . . . . . . . . . . . . .
30

x
CONTENTS
2.2.2
Priors for parameters and functions
. . . . . . . . . . . . . . . . .
32
2.3
Markov chain Monte Carlo inference
. . . . . . . . . . . . . . . . . . . . .
38
2.3.1
Updating full conditionals . . . . . . . . . . . . . . . . . . . . . . .
40
2.3.2
Model choice
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
42
2.3.3
Propriety of posteriors in geoadditive survival models . . . . . . . .
42
2.4
Simulation Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
44
2.5
Application
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
59
2.5.1
Overdraft credit risk . . . . . . . . . . . . . . . . . . . . . . . . . .
60
2.5.2
Long term care insurance . . . . . . . . . . . . . . . . . . . . . . . .
61
2.5.3
Waiting times to CABG . . . . . . . . . . . . . . . . . . . . . . . .
68
2.6
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
74
3
Relative Survival Analysis
77
3.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
77
3.2
Model, likelihood and priors . . . . . . . . . . . . . . . . . . . . . . . . . .
78
3.3
Markov chain Monte Carlo inference
. . . . . . . . . . . . . . . . . . . . .
80
3.4
Application
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
82
3.5
Simulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
88
3.6
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
92
4
Multi–state models
95
4.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
4.2
Models, likelihood, priors and MCMC inference
. . . . . . . . . . . . . . .
97
4.3
Markov Chain Monte Carlo inference . . . . . . . . . . . . . . . . . . . . .
99
4.4
Application
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
101
4.4.1
Biological valve prostheses . . . . . . . . . . . . . . . . . . . . . . .
101
4.4.2
Human sleep processes . . . . . . . . . . . . . . . . . . . . . . . . .
103
4.5
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
111
5
Bayesian survival and multi–state analysis with BayesX: a tutorial
113
5.1
BayesX . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
114
5.2
Getting started . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
114
5.3
Dataset objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
115

Contents
xi
5.4
Map objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
116
5.5
Bayesreg objects
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
120
5.5.1
Survival models . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
120
5.5.2
Relative survival analysis . . . . . . . . . . . . . . . . . . . . . . . .
124
5.5.3
Multi–state models . . . . . . . . . . . . . . . . . . . . . . . . . . .
126
5.6
Post estimation commands . . . . . . . . . . . . . . . . . . . . . . . . . . .
130
A Calculation of IWLS weights
133
A.1 Geoadditive survival analysis . . . . . . . . . . . . . . . . . . . . . . . . . .
133
A.2 Relative survival analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . .
137

xii
Contents

Chapter 1
Introduction
The analysis of survival times is a speciﬁc type of regression analysis that has gained
considerable attention particularly in the classical ﬁeld of medical applications, wherefrom
the conventional denotation ’survival analysis’ arises.
The primary interest in medical
trials usually is the analysis of the inﬂuence of special drugs or therapies on the survival
times of patients that are diagnosed with a certain disease. Generally, survival analysis
is concerned with analyzing the inﬂuence of covariates on the duration time up to any
predeﬁned event of interest. As will be illustrated in this work there is a number of further
ﬁelds of applications including for example the ﬁeld of credit scoring, where the life of a
loan up to a default is analyzed.
In survival analysis a distinction is drawn between discrete time survival analysis, where
survival times are only given in certain units of time and continuous time survival analysis.
The former can be ascribed to binary response models and may therefore be based on
methodology for binary logit, probit or grouped Cox models. For this reason we will only
deal with the more challenging case, where survival times are measured on a continuous
time scale. Grouping the data for a discrete time survival analysis is possible, but leads to
a loss of information and is therefore not recommended. Another idea might be to analyze
survival times with generalized linear models for nonnegative continuous responses (like
lognormal or gamma regression). However, these methods do not account for censoring
and truncation, two speciﬁcs of survival data that are due to the fact that survival times
can often not be observed completely but only within a speciﬁc observation period. For
this reasons continuous time survival analysis actually is a separate area of statistical

2
1. Introduction
analysis that is treated extensively in the literature, see e.g. Lawless (1982), Kalbﬂeisch
and Prentice (1980), Blossfeld, Hamerle and Mayer (1989) and Klein and Moeschberger
(2003), or Andersen, Borgan, Gill and Keiding (1993) for a counting process representation.
1.1
Basic concepts
Consider survival time to be a nonnegative continuous random variable T, with density
function f(t). Then the corresponding distribution function F(t), which is the probability
of not surviving until time t is given by
F(t) = P(T ≤t) =
Z t
0
f(u)du.
In survival analysis however, it is more common to examine the so called survivor function,
which is the probability of the complementary event, i.e. the probability of surviving until
time t. It given by
S(t) = 1 −F(t) = P(T > t).
Another quantity that plays a decisive role in survival analysis is the hazard function λ(t),
which is deﬁned by
λ(t) = lim
∆t→0
P(t ≤T < t + ∆t|T ≥t)
∆t
and determines the instantaneous rate of death or failure at time t subject to the condition
of survival up to time t.
The following equations, where Λ(t) =
R t
0 λ(t) denotes the cumulative hazard function,
show how the quantities introduced above are related to each other:
λ(t)
=
f(t)
S(t)
S(t)
=
exp(−Λ(t))
f(t)
=
λ(t)S(t) = λ(t) exp(−Λ(t))
The distribution of T is completely determined by one of these quantities. As an illustration
consider the Weibull distribution, where the hazard rate has the following structure
λ(t) = λα(λt)α−1,

1.2 The Cox model
3
with scale parameter λ > 0 and shape parameter α > 0 (see Figure 1.3 below for a graphical
representation). The survivor function is thus given by
S(t)
=
exp

−
Z t
0
λ(u)du

= exp

−
Z t
0
λα(λu)α−1du

=
exp

−λαλα−1
Z t
0
uα−1du

= exp
 −λαα[α−1uα]t
0

= exp
 −λαα(α−1tα)

=
exp (−(λt)α)
leading to
f(t) = λ(t)S(t) = λα(λt)α−1 exp (−(λt)α) ,
which is indeed the density function of a Weibull distribution with parameters λ and α.
The exponential model, where the hazard rate is constant over time, i.e. λ(t) = λ > 0 is
included as the special case of α = 1.
1.2
The Cox model
Consider survival data in conventional form, i.e. assume that each individual i in the study
has a lifetime Ti and a censoring time Ci that are independent random variables (random
censoring). The observed lifetime is then ti = min(Ti, Ci), and δi denotes the censoring
indicator given by
δi =
(
1
Ti ≤Ci
0
else
(1.1)
In addition to the lifetime one usually considers some individual–speciﬁc covariates that
are assumed to have an inﬂuence on the lifetime. The data is then given by
(ti, δi; vi),
i = 1, . . . , n,
(1.2)
where vi = (vi1, . . . , vir) is the vector of the r covariates observed with individual i. Note
that covariates may also be time–dependent, but for the moment we restrict discussion
to time–constant covariates for simplicity. The benchmark in the area of analyzing the
inﬂuence of covariates on survival time is the proportional hazards model introduced by

4
1. Introduction
Cox (1972). Here the hazard rate of individual i is modelled as the product
λi(t, vi) = λ0(t) · exp(vi1γ1 + . . . + virγr) = λ0(t) · exp(v′
iγ),
(1.3)
where λ0(t) is the baseline hazard, that remains unspeciﬁed and is independent of the
covariates, but only depends on time t.
In contrast, the inﬂuence of the covariates is
independent of time and modelled via a linear predictor v′
iγ with a vector of regression
coeﬃcients γ = (γ1, . . . , γr). Through the exponential link function, the covariates act
multiplicatively on the hazard rate.
In the case of time–constant covariates the time
constance of the inﬂuence of the covariates implicates that the hazard rates of any two
individuals are proportional, which explains why the Cox model is called a proportional
hazards model. Let vi and vj denote the covariate vectors of two individuals i and j, then
the ratio of the hazard rates of these individuals is given by
λi(t, vi)
λj(t, vj) = λ0(t) · exp(v′
iγ)
λ0(t) · exp(v′
jγ) = exp ((vi −vj)′γ) ,
which yields
λi(t, vi) = c · λj(t, vj),
c = exp ((vi −vj)′γ) .
This implicit assumption of the traditional Cox model is rather restrictive and does often
not hold in practice. However, this assumption is crucial for inference based on the partial
likelihood proposed by Cox. Supposing that the baseline hazard λ0(t) is arbitrary, the
partial likelihood is derived by considering the observed survival times ti (at which we
assume for simplicity that ti ̸= tj for i ̸= j) and risk sets
R(ti) = {j|tj ≥ti}
including all individuals j whose survival time is at least ti, i.e. all individuals that are still
at risk shortly before ti. Given that time ti is an observed failure time and conditionally
on the risk set R(ti) the probability that the failure is actually observed on individual i
(instead of any other individual j ∈R(ti)) is given by
P(i fails at ti|one failure at ti, R(ti)) =
exp (v′
iγ)
P
j∈R(ti) exp
 v′
jγ
,

1.3 Extensions of the Cox model
5
which is independent of λ0(t). Under the assumption of independence the partial likelihood
is hence given by
L(γ) =
n
Y
i=1
exp (v′
iγ)
P
j∈R(ti) exp
 v′
jγ
.
The regression parameters γ may then be estimated by maximizing the partial likelihood.
Based on the estimated parameters ˆγ the cumulative baseline hazard Λ0(t) =
R t
0 λ0(u)du
may be estimated in a second step via the plug–in estimator by Breslow, which is deﬁned
as follows
ˆΛ0(t) =
X
i:ti≤t
1
P
j∈R(ti) exp(v′
j ˆγ).
(1.4)
Note that ˆΛ0(t) is a step function with jumps at the observed survival times ti.
1.3
Extensions of the Cox model
To many complex applications the basic Cox model (1.3) is not adequate with respect to
several aspects such as
• In applications where predictions are of interest an improved, smooth estimation of
the baseline eﬀect is needed.
• Eﬀects of continuous covariates might be of any unknown nonlinear form.
• Some eﬀects might be time–varying, at which the variation is of any unknown (non-
linear) form.
• Survival times might be spatially correlated.
• Unobserved heterogeneity among individuals or units might be present.
• Nonlinear interactions between covariates might exist.
In this thesis, we propose geoadditive survival models as a ﬂexible spatial and spatio–
temporal generalization of Cox–type models. Within a uniﬁed framework, we extend the
common linear predictor of the Cox model to an additive predictor, including a spatial
component for geographical eﬀects and nonparametric terms for modelling and exploring

6
1. Introduction
unknown functional forms of the baseline hazard rate, of nonlinear eﬀects of continuous
covariates and further time scales, such as calendar time, and of time–varying coeﬃcients.
The incorporation of such nonparametric components and their simultaneous estimation
with the baseline hazard and the spatial eﬀects motivates the term ”geoadditive”, originally
introduced by Kammann and Wand (2003) in a mixed model approach to semiparametric
Gaussian regression. In addition, uncorrelated random eﬀects (also referred to as frailty
eﬀects) or nonlinear two–way interactions can be incorporated if appropriate.
Modelling and inference is developed from a Bayesian perspective, using information
from the full likelihood rather than from a partial likelihood.
1.4
Full likelihood
In survival analysis the complexity of the likelihood depends on what kind of censoring
and/or truncation is present in the data. Figure 1.1 illustrates some examples of observation
structures that we treat within this thesis.
1.4.1
Right censoring
Usually right censored data are considered, where the exact survival time is only observed
for some individuals, whereas others are only observed until a certain point of time prior to
the event of interest. This involves that it is only known that the survival time is greater
than the observed survival time. Right censoring typically appears in studies where indi-
viduals enter the study gradually and are only followed within a certain observation period.
Observations where the event did not take place until the end of the observation period are
right censored. A censoring concept that is often assumed to hold was already presented
in Section 1.2 and is called random censoring. Here the survival time Ti and the censoring
time Ci of each individual i, i = 1, . . . , n are assumed to be independent random variables,
the observed survival time ti is the minimum of those two variables and the censoring indi-
cator δi is deﬁned as in (1.1). Considering time–constant covariates vi = (vi1, . . . , vip) and
under the assumption of non–informative censoring, i.e. the assumption that the censoring
time is not determined by parameters of interest, the likelihood contribution of individual

1.4 Full likelihood
7
-
6
calendar
time
values of
covariates
v1 = 2, v2 = 3
v1 = 2, v2 = 2
v1 = 2, v2 = 1
v1 = 1, v2 = 3
v1 = 1, v2 = 2
v1 = 1, v2 = 1
unknown
t
d
t
d
t
@
@
R
death
t
d
t
d
@
@
R
censoring
  
@
@
R
truncation
@
@
R
truncation
@
@
R
death
t
d
t
d
  
death
t

-
observation period
no censoring, no truncation, time–constant covariates v1 = 2, v2 = 1
right censored, no truncation, time–constant covariates v1 = 1, v2 = 1
no censoring, no truncation, v1 = 2, v2 is changing from 2 to 3
no censoring, left truncated, time–constant covariates v1 = 2, v2 = 3
right censored, left truncated, v1 = 1, v2 is changing from 2 to 3
Figure 1.1: Illustration of 5 diﬀerent right–censoring and left–truncation schemes each with
two covariates v1 ∈{1, 2} and v2 ∈{1, 2, 3}, that may be time–constant or time–varying.

8
1. Introduction
i is given by
Li
=
(
fi(ti, vi) = λi(ti, vi) · Si(ti, vi),
δi = 1
Si(ti, vi),
δi = 0
=
λi(ti, vi)δi · Si(ti, vi)
=
λi(ti, vi)δi · exp

−
Z ti
0
λi(u, vi)du

.
(1.5)
For non–censored observations the likelihood is as usual given by the density fi at ti, vi,
whilst the likelihood for censored observations, where it is only known that the survival
time is at least ti, is given by the survivor function Si at ti, vi. Thus, under the usual
assumption of conditional independence the likelihood for the whole sample (ti, δi, vi),
i = 1, . . . , n is given by
L =
n
Y
i=1
Li =
n
Y
i=1
λi(ti, vi)δi · Si(ti, vi).
1.4.2
Left truncation
Left truncation is the second type of incompletely observed survival data that we deal
with in this thesis. Here survival times of certain individuals can only be observed on
condition that they exceed a certain, individual–speciﬁc truncation time T tr
i
involving that
some survival times are not to be observed. Left truncation typically occurs in observation
studies where individuals that have already been at risk for a known, individual–speciﬁc
amount of time ttr
i at the beginning of the observation period are included (additionally
to individuals that get at risk at a later date within the observation period and thus enter
the study gradually). Note that those observations would not be included if their survival
time was shorter than ttr
i , i.e. it has to be considered that no shorter survival time than ttr
i
may be observed with those individuals. This matter of fact is crucial in data situations,
where those individuals being at risk at earlier times diﬀer from individuals being at risk
later, regarding values of inﬂuential covariates. Considering time–constant covariates, right
censoring and left truncation the data are given by

1.4 Full likelihood
9
(ti, δi, ttr
i ; vi),
i = 1, . . . , n,
where ttr
i
= 0 if observation i is not left truncated and ttr
i
> 0 if observation i is left
truncated. The individual likelihood contribution of individual i is given by
Li
=



















Si(ti, vi),
δi = 0, ttr
i = 0
λi(ti, vi) · Si(ti, vi),
δi = 1, ttr
i = 0
Si(ti,vi)
Si(ttr
i ,vi),
δi = 0, ttr
i > 0
λi(ti, vi) Si(ti,vi)
Si(ttr
i ,vi),
δi = 1, ttr
i > 0
=
λi(ti, vi)δi · exp
 
−
Z ti
ttr
i
λi(u, vi)du
!
,
(1.6)
where left truncation is accounted for by conditioning on Ti > ttr
i , which results in a division
by S(ttr
i , vi). For a detailed derivation of these likelihoods see e.g. Klein and Moeschberger
(2003).
Again, under the usual assumption of conditional independence the likelihood
for the whole sample (ti, δi, ttr
i , vi), i = 1, . . . , n is given by the product of the individual
likelihood contributions.
1.4.3
Time–varying covariates
So far we have only considered time–constant covariates.
Now we will illustrate, how
the likelihood of survival data with time–varying (piecewise constant) covariates can be
rewritten in the form of the likelihood of left truncated survival data with time–constant
covariates. For this purpose consider for instance survival data
(ti, δi, ttr
i ; vi(t)),
i = 1, . . . , n,
where v(t) is a time–varying covariate that may take two diﬀerent values v(1) and v(2). The
likelihood contribution of an observation i with a trajectory as displayed in Figure 1.2,
where t(1)
i
and t(2)
i
mark the points of time when the covariates change, is given by

10
1. Introduction
-
t
d
0
ttr
i
t
d
t(1)
i
t
d
t(2)
i
t
d
ti
t
unknown
v(1)
v(2)
Figure 1.2:
Exemplary trajectory for a time–varying covariate v(t) with two diﬀerent values
v(1) and v(2).
Li
=
λi(ti, vi(ti))δi · exp
 
−
Z ti
ttr
i
λi(u, vi(u))du
!
=
λi(ti, v(1))δi · exp
 
−
Z t(1)
i
ttr
i
λi(u, v(1))du −
Z t(2)
i
t(1)
i
λi(u, v(2))du −
Z ti
t(2)
i
λi(u, v(1))du
!
=
λi(t(1)
i , v(1))0 · exp
 
−
Z t(1)
i
ttr
i
λi(u, v(1))du
!
λi(t(2)
i , v(2))0 · exp
 
−
Z t(2)
i
t(1)
i
λi(u, v(2))du
!
λi(ti, v(1))δi · exp
 
−
Z ti
t(2)
i
λi(u, v(1))du
!
.
This individual likelihood is identical to the likelihood of three left truncated observations
with a time–constant covariate given by
ti
δi
ttr
i
vi
t(1)
i
0
ttr
i
v(1)
t(2)
i
0
t(1)
i
v(2)
ti
δi
t(2)
i
v(1)
For this reason time–varying covariates can be included in the settings described before
via data augmentation.

1.5 Modelling the baseline hazard
11
1.5
Modelling the baseline hazard
As can be seen from equations (1.5) and (1.6) the calculation of the likelihood involves
solving integrals over the baseline hazard rate, which is the only component that depends
on time in case of time–constant covariate eﬀects. Depending on the complexity of the
assumed structure of the baseline hazard the integrals may be solved analytically or a
numerical integration technique may be required.
Starting from the Cox model (1.3)
where the baseline hazard is typically unspeciﬁed, we present three alternatives to specify
the baseline hazard and their implications with calculating the likelihood.
1.5.1
Weibull model
The ﬁrst alternative is a parametric Weibull model, where the baseline hazard rate is given
by
λ0(t) = αtα−1
with an unknown shape parameter α > 0. Note that the exponential model, where the
baseline hazard is time–constant is included as the special case of α = 1, whereas values
of α < 1 (α > 1) yield a decreasing (increasing) baseline hazard. To give an example,
Figure 1.3 displays the shapes of λ0(t) for α = 0.75, α = 1 and α = 1.25. Usually the
Weibull distribution is deﬁned by a shape and a scale parameter. With our model the
scale parameter is included as an additive intercept term γ0 in the linear predictor, i.e. the
model is given by
λi(t, vi)
=
αtα−1 · exp (γ0 + v′
iγ) .
The integral in the likelihood given in (1.6) can be calculated analytically as follows
Z ti
ttr
i
λi(u, vi)du
=
Z ti
ttr
i
αuα−1 · exp (γ0 + v′
iγ) du
=
exp (γ0 + v′
iγ) ·
Z ti
ttr
i
αuα−1du
=
exp (γ0 + v′
iγ) · [uα]ti
ttr
i
=
exp (γ0 + v′
iγ) ·
 (ti)α −(ttr
i )α
.

12
1. Introduction
0
1
2
3
0
1
2
3
4
5
t
alpha=1
alpha=0.75
alpha=1.25
Figure 1.3:
Shape of the Weibull baseline hazard αtα−1 for diﬀerent values of α.
Thus a Weibull hazard rate allows for an easy estimation and is a frequently used model
assumption. However, the ﬂexibility is limited since the shape of the baseline hazard rate
is restricted to monotonic functions as displayed in Figure 1.3.
1.5.2
Piecewise exponential model (p.e.m.)
The basic idea of the p.e.m. is to divide the time axis into a grid that may be equidistant,
according to quantiles or of any arbitrary structure given by the intervals
(0 = ξ0, ξ1], (ξ1, ξ2], . . . , (ξs−1, ξs], . . . , (ξm−1, ξm], (ξm, ∞),
where ξm is the largest of all observed survival times ti, i = 1, . . . , n. The baseline hazard
rate λ0(t) is assumed to be piecewise constant on that grid, i.e.
λ0(t) = λ0s,
λ0s ≥0
for times t within the intervals (ξs−1, ξs], s = 1, ..., m.
Since estimating the unknown
parameters λ0s would involve imposing the restrictions λ0s ≥0, s = 1, . . . , m, we prefer to
estimate the unrestricted parameters g0s = log(λ0s) instead, i.e. we deﬁne
γ0(t) = log(λ0(t)) = γ0s

1.5 Modelling the baseline hazard
13
for times t in the interval (ξs−1, ξs], s = 1, ..., m. Furthermore, let ηi(ti, vi) denote the
whole linear predictor of individual i including the log–baseline hazard, i.e.
ηi(t, vi)
=
γ0(t) + v′
iγ
and hence
λi(t, vi)
=
λ0(t) · exp (v′
iγ) = exp (γ0(t) + v′
iγ) = exp(ηi(t, vi))
Here, ηis = γ0s + v′
iγ denotes the piecewise constant linear predictor in the time interval
(ξs−1, ξs], s = 1, ..., m.
In the case of a p.e.m., the integral reduces to a sum, and, after some calculations, the
likelihood contribution of observation i in each time interval (ξs−1, ξs] can be expressed as
Lis = exp (yisηis −exp (∆is + ηis))
where
yis
=
(
1
ti ∈(ξs−1, ξs],δi = 1
0
else.
∆∗
is
=























0,
ξs < ttr
i
ξs −ttr
i ,
ξs−1 < ttr
i ≤ξs < ti
ti −ttr
i ,
ξs−1 < ttr
i < ti ≤ξs
ξs −ξs−1,
ttr
i ≤ξs−1 < ξs < ti
ti −ξs−1,
ttr
i < ξs−1 < ti ≤ξs
0,
ti ≤ξs−1
∆is
=
log ∆∗
is
(∆is = −∞if ∆∗
is = 0).
That is to say that the likelihood of a p.e.m. is proportional to a Poisson–likelihood with re-
sponses yis and with the predictor ηis containing an additional oﬀset term ∆is, see Fahrmeir
and Tutz (2001, Section 9.1) or Ibrahim et al. (2001, Section 3.1) for details. This result
yields that a p.e.m. may be estimated based on methodology for Poisson regression mod-
els, i.e. within the context of generalized linear models (GLMs) via data augmentation.
In practise this means that the data set has to be modiﬁed in such a way that for every
individual i there is an observation row for each interval (ξs−1, ξs] beginning with the in-
terval that includes the left truncation time ttr
i up to the interval in that observation time
ti ends. Instead of the indicator of non–censoring δi the modiﬁed data set contains the

14
1. Introduction
indicator yis, instead of survival time ti the variable ξs as well as the oﬀset ∆is (covariates
are duplicated). To give a short example, if we have an equidistant grid with length 0.1,
the observations
i
t
δ
ttr
v1
v2
1
0.35
1
0.16
0
3
2
0.12
0
0
1
5
...
...
...
...
have to be modiﬁed to
i
y
ξ
∆
v1
v2
1
0
0.2
log(0.04)
0
3
1
0
0.3
log(0.10)
0
3
1
1
0.4
log(0.05)
0
3
2
0
0.1
log(0.10)
1
5
2
0
0.2
log(0.02)
1
5
...
...
...
...
...
...
and a Poisson regression with response y, covariates ξ, v1 and v2 and oﬀset ∆may be
accomplished.
Note that time–varying covariates can be accounted for by varying the
covariates adequately from line to line in the table above. Hence, the assumption of a
p.e.m. is quite convenient, however, due to the assumption of a piecewise constant hazard
rate the estimated (log–)baseline eﬀect is a step function on the deﬁned grid, which may
not be adequate with continuous survival times. Furthermore it is a moot question how
to choose an ”ideal” grid. While a small grid size might lead to intervals with sparse data
and hence unreliable estimates of the according parameters, a large grid size might not
allow for enough ﬂexibility. Within our Bayesian analysis we will use a rather small grid
size and specify random walk priors (as described in Fahrmeir and Lang (2001a)) for the
parameters γ0s to penalize too abrupt jumps between neighboring parameters γ0,s−1 and
γ0s yielding a ﬂexible ”smooth step function”.

1.5 Modelling the baseline hazard
15
1.5.3
P–spline model
Modelling the baseline hazard by a (Bayesian) P–spline is the most ﬂexible alternative, that
will be primarily discussed within this thesis. While the log–baseline hazard is assumed to
be a piecewise constant function with the p.e.m., i.e. a polynomial of degree zero within each
predeﬁned interval, we now consider extensions to piecewise polynomials of an arbitrary
degree l. Depending on the degree l this leads to more or less smooth functions instead of
step functions. Again, the time axis is divided into a grid
(0 = ξ0, ξ1], (ξ1, ξ2], . . . , (ξs−1, ξs], . . . , (ξm−1, ξm], (ξm, ∞),
where ξs are usually called (inner) knots within the context of spline regression. Then a
polynomial spline has the following smoothness properties:
• A spline is a polynomial of degree l within each interval ξs−1, ξs, s = 1, . . . , m.
• A spline is l −1 times diﬀerentiable at the knots ξs.
As shown in De Boor (1978) a spline with those properties may for example be written
as a linear combination of M = m + l B–spline basis functions Bsl of degree l. Hence
the function g0(t) = log(λ0(t)) that is denoting the (smooth) function that describes the
log–baseline eﬀect can be written as
g0(t) =
M
X
s=1
βsBsl(t),
where βs, s = 1, . . . , M are unknown parameters.
Note, that we are again estimating
the log–baseline hazard instead of the baseline hazard to avoid implying the restriction
λ0(t) ≥0. Figure 1.4 shows B–spline basis functions for degrees l = 0, l = 1 and l = 2,
respectively, with only several basis functions being displayed for reasons of clarity. B–
spline basis functions of degree zero are piecewise constant and do not overlap (in this
respect that each basis function Bs0 is nonzero only within the interval (ξs−1, ξs]), which
again illustrates that the p.e.m. is included as the special case of l = 0. B–spline basis
functions of degree one are nonzero within the range of two subsequent intervals (ξs−1, ξs]
and (ξs, ξs+1] and are linear functions within each interval, whereas basis functions of degree
two are nonzero within the range of three subsequent intervals and are quadratic functions

16
1. Introduction
within each interval. B–spline basis functions of degree l = 3 (not shown) would be nonzero
within the range of four subsequent intervals and be cubic functions within each interval
etc. Figure 1.5 exemplarily shows the construction of a B–spline of degree l = 2 with
m = 5 inner knots. Panel (a) displays the M = l + m = 6 basis functions Bs2 that cover
the considered range of (0, 1] in a way that for each point within this interval l + 1 = 3
basis functions take (positive) values diﬀerent from zero. The weighted basis functions
βsBs2 are displayed in panel (b) and panel (c) shows the resulting spline function, which
is the sum of the weighted basis functions PM
s=1 βsBs2. For more details on B–splines see
De Boor (2001).
ξ1
ξ2
ξ3
ξ4
ξ5
ξ6
ξ7
ξ8
ξ9
ξ10
 
 
 
 
 	
 
 
 
 
 




































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































 
 
 
 
 	
 
 
 
 
 




























































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Figure 1.4:
Some B–spline Basis functions for degrees l = 0, l = 1, and l = 2, respectively.
Besides the degree l the structure of the resulting spline considerably depends on the
number and the position of the knots. While a small number of knots might not guarantee
enough ﬂexibility, a very large number of knots might lead to over–ﬁtting and thus deliver
unreliable results. An attractive solution to this problem are penalized splines (P–splines),
that are based on roughness penalties and presented by Eilers and Marx (1996). The basic
idea is to use a rather large number of equidistant knots, but penalize too rough functions

1.5 Modelling the baseline hazard
17
-0.5 -0.25
 0
 0.25  0.5  0.75
 1
 1.25  1.5
 0
 0.2
 0.4
 0.6
(a) basis functions
-0.5 -0.25
 0
 0.25  0.5  0.75
 1
 1.25  1.5
 0
 0.2
 0.4
(b) weighted basis functions
 0
 0.25
 0.5
 0.75
 1
 0.2
 0.4
 0.6
(c) resulting spline
Figure 1.5:
Construction of B–splines: 6 B–spline basis functions of degree l = 2 with 5 inner
knots at 0.0, 0.25, 0.5, 0.75 and 1.0 (a), weighted basis functions (b), and the resulting spline (c).
by imposing diﬀerence penalties on neighboring parameters βs−1 and βs. In this thesis we
will use Bayesian versions of P–splines as developed in Lang and Brezger (2004).
While the integrals in the likelihood (1.5) and (1.6), respectively, can be solved analyti-
cally with the two previously presented approaches (Weibull model and p.e.m.), this is not
in general true for survival models where the baseline hazard is modelled by a P–spline.
Apart from B–splines of degree l = 0 and l = 1 these integrals can only be solved nu-
merically. For this we use numerical integration in form of the trapezoidal rule. Here the
basic idea is to approximate the function λ0(t) by a piecewise linear function ˜λ0(t) as dis-
played in Figure 1.6, where the area under ˜λ0 is trapezoidal within each interval. In order
to guarantee that the approximation is also fairly accurate in time slices where observed
survival times are sparse, equidistant time points are used as additional knots besides the
observed life times ti. Now an integral
R t
0 λ0(u)du is approximated by
R t
0 ˜λ0(u)du, which is
the sum of the areas of the corresponding trapezoids. For an interval (ti−1, ti] the area of

18
1. Introduction
t
a0
a1
a2
a3
a4
a5
t1
t2 t3
t4
t5
t6
t7
t8
t9
Figure 1.6:
Trapezoidal rule: The function λ0(t) (dashed line) is approximated by a piecewise
linear function through the points (ti, λ0(ti)), where ti are (ordered) observed survival times,
as well as the additional points (as, λ0(as)) with a0 = 0.
Hence the integral
R t9
0 λ0(u)du is
approximated by the sum of the areas of the gray shaded trapezoids.
the corresponding trapezoid would for example be given by
1
2 · (ti −ti−1) · (λ0(ti) + λ0(ti−1)).
Note, that we discussed the case of data where no left truncation is present, but the trape-
zoidal rule may be applied to left truncated observations as well. Here we use the truncation
times ttr
i as additional knots in Figure 1.6 and approximate the integrals
R ti
ttr
i λ0(u)du by
R ti
ttr
i
˜λ0(u)du.

1.6 Relations to other survival models
19
1.6
Relations to other survival models
The scope of this section is to clarify in what way the extended continuous–time Cox model
that is presented in this thesis is related to some other common survival models, namely
to discrete time survival models and to location–scale models for log(T), which are also
called accelerated failure time (AFT) models.
1.6.1
Discrete time survival analysis
Discrete time survival models are basically used in two diﬀerent situations. Firstly they
are used in cases where failures actually only occur at discrete time points. This is for
example the case with durations of unemployment, since employments usually end and
begin with monthly allowance. The second situation is given where failures may occur at
any arbitrary point of time, however survival times can not be observed continuously, but
are only known to lie between two successive follow ups. This case is known as interval
censoring and typically occurs in medical studies where data can only be observed at
regular consultations.
Now consider discrete time D ∈{1, 2, . . .}, then the discrete hazard function is given
by
λdiscr(s, v) = P(D = s|D ≥s, v),
s = 1, 2, . . .
which is the probability of failure at time point s, given that the failure time is at least s
and given the covariates v.
The grouped proportional hazards model
Consider the case of interval censoring where survival times T are continuous but are only
observed at k follow up times ξs, s = 1, . . . , k. Let time be divided in intervals
[ξ0, ξ1), [ξ1, ξ2), . . . , [ξs−1, ξs), . . . , [ξq−1, ξq), [ξk, ∞)
where ξ0 = 0 and q = k −1. Then D = s, s = 1, . . . , q denotes failure within the according
interval, i.e. T ∈[ξs−1, ξs) and the discrete hazard function is given by

20
1. Introduction
λdiscr(s, v)
=
P(D = s|D ≥s, v) = P(T < ξs|T ≥ξs−1, v)
=
P(ξs−1 ≤T < ξs|v)
P(T ≥ξs−1|v)
= F(ξs, v) −F(ξs−1, v)
S(ξs−1, v)
=
S(ξs−1, v) −S(ξs, v)
S(ξs−1, v)
=
1 −S(ξs, v)
S(ξs−1, v)
=
1 −
exp

−
R ξs
0 λ(t, v)dt

exp

−
R ξs−1
0
λ(t, v)dt

=
1 −exp

−
Z ξs
ξs−1
λ(t, v)dt

,
(1.7)
i.e. the discrete hazard function λdiscr may be written as a function of the continuous
survivor function S and the continuous hazard rate λ, respectively. Inserting the formula
of the proportional hazards model or Cox model for continuous time (1.3) given by
λ(t, v) = λ0(t) · exp (v′γ)
into (1.7) yields the grouped proportional hazards model given by
λdiscr(s, v)
=
1 −exp

−exp(v′γ)
Z ξs
ξs−1
λ0(t)dt

=
1 −exp (−exp(γ0s + v′γ))
with γ0s = log
R ξs
ξs−1 λ0(t)dt

. An alternative formulation is given by
log(−log(1 −λdiscr(s, v))) = γ0s + v′γ
and hence the grouped proportional hazards model is a sequential complementary log–
log model. Though in general grouping implies a loss of information (see e.g. Gould and
Lawless (1988)), it should be annotated that the parameter vector γ remains unchanged
by the transition between the continuous and the discrete model.

1.6 Relations to other survival models
21
Models for binary response
While sequential models for ordinal responses ﬁt for the estimation of discrete time survival
models without right–censoring, binary models for the indicators
yis =
(
1
di = s and δi = 1
0
else
i = 1, . . . , n,
s = 1, . . . , di
(1.8)
that indicate whether or not a failure occurred with individual i at time s or in interval
[ξs−1, ξs), respectively, may be used instead for discrete survival analysis in cases where
right–censoring is present. For the purpose of ﬁtting a binary model, the survival data
have to be augmented in a similar way as described in Subsection 1.5.2 for the p.e.m.
Note however, that the p.e.m. is a continuous time survival model, where the information
on the exact survival time (within each interval) is retained and enters the model via an
oﬀset term. To give a short example, right–censored discrete time survival data with two
covariates v1 and v2 given by
i
d
δ
v1
v2
1
3
1
0
3
2
2
0
1
5
...
...
...
...
...
have to be augmented to
i
s
y
v1
v2
1
1
0
0
3
1
2
0
0
3
1
3
1
0
3
2
1
0
1
5
2
2
0
1
5
...
...
...
...
...
where for every individual i one line has to be created for each discrete point in time s
(every time interval, respectively) at which the individual is observed.
Covariates are
duplicated and an indicator variable yis is created according to (1.8), that takes the

22
1. Introduction
value 0 in every line related to a right–censored observation i and takes the value 1 in
the last line related to an uncensored observation i and 0 in the preceding lines.
In
practice such a data augmentation for right censored data with time–constant covari-
ates might for example be accomplished with the STATA command prsnperd as illus-
trated on http://www.ats.ucla.edu/stat/stata/library/survival2.htm. Note that
left–truncation and time–varying covariates can be easily accounted for by omitting the
accordant ﬁrst lines in the tabular above and varying the covariates adequately from line
to line, respectively. The discrete hazard function may now equivalently be written as
λdiscr
i
(s, vi) = P(yis = 1|vi)
and a binary regression with response yis and covariates s, v1 and v2 may be accomplished.
Thompson (1977) for example considers the logistic model
λdiscr(s, v) =
exp(γ0s + v′γ)
1 + exp(γ0s + v′γ)
(1.9)
and shows that this model is very similar to the proportional hazards model if grouping
intervals become short.
1.6.2
Log–location–scale models
Log–location–scale models are an alternative model class for continuous survival data,
where, in contrast to the classical Cox model (with time–constant covariates and time–
constant eﬀects of covariates), proportional hazards are not presumed in general.
To
account for the nonnegativity of survival time, log(T) instead of T is related to a linear
predictor given by
log(T) = γ0 + v′γ + σε,
(1.10)
where σ is a constant scale parameter and ε is an error term independent of v. For the
special case where ε follows the standard extreme value distribution, we retain a Weibull
model with λ = exp (−(γ0 + v′γ)) and α = 1/σ, which is a proportional hazards model.
However, other distributions of ε do not yield proportional hazards models. Assuming a
normal distribution for ε, for example, results in lognormal distributed survival times and
a nonproportional hazards model. In the case of parametric models the parameters can
be estimated easily via maximum likelihood techniques. Since such parametric approaches

1.7 Competing risks and multi–state models
23
are quite restrictive, semi–parametric procedures that leave the distribution of the error
term unspeciﬁed and only provide the estimation of the parameter vector γ may be used
alternatively, see e.g. Kalbﬂeisch and Prentice (2002). However, there is no pendant to the
Breslow estimator (1.4) (which is used with Cox models to estimate the cumulative baseline
hazard on the basis of the estimated parameter vector ˆγ) and hence semi–parametric
procedures may not be used in cases where prediction is of interest. A method that oﬀers
a joint estimation of the parameter vector γ and the baseline hazard with a ﬂexible, smooth
error distribution is presented by Kom´arek, Lesaﬀre and Hilton (2005), who propose to use
a mixture of normals for the error distribution, with mixture weights being smoothed.
The model assumption in (1.10) may be rewritten as
T = exp(γ0 + v′γ) exp(σε),
which, according to Lesaﬀre, Kom´arek and Declerck (2004), leads to a hazard rate of the
following structure
λ(t, v) = exp (−(γ0 + v′γ)) · λ0(exp(−(γ0 + v′γ)) · t),
i.e. as with the Cox model the covariates act multiplicatively on the hazard rate, but
here the eﬀect of a covariate additionally acts as an acceleration (deceleration) of the
event time, which explains why such models are also referred to as accelerated failure time
models (AFT). In this way classical AFT models seem to be more general than classical
Cox models, however, in contrast to Cox models, AFT models do not allow for the inclusion
of time–varying covariates and time–varying eﬀects. For this reason we focus on extensions
of the Cox model, where the inclusion of time–varying covariates and time–varying eﬀects
yields nonproportional hazards models.
1.7
Competing risks and multi–state models
So far we have only considered one type of failure. However, with a number of applications
one may distinguish between several types of failures or events. In clinical studies, for
example, the events may stand for several causes of death. Models for this type of data
are referred to as competing risks models. Let h = 1, . . . , H denote the distinct events.

24
1. Introduction
Corresponding to the deﬁnition of the hazard rate in (1.3) event–speciﬁc individual hazard
rates λhi are given by
λhi(t, vhi) = λh0(t) exp (v′
hiγh) ,
h = 1, . . . , H.
(1.11)
Here, λh0(t) denotes the event–speciﬁc baseline hazard, vhi denotes the vector of covariates
having an inﬂuence on the accordant hazard rate and γh is the related event–speciﬁc
vector of parameters.
As mentioned in the context of Cox models this basic model is
not adequate to many complex applications and needs to be extended with respect to the
aspects mentioned in Section 1.3.
Note, that in a discrete time setting competing risks models may be analyzed by mul-
ticategorical regression models via data augmentation (in a similar way as described above
for models for binary response). Fahrmeir and Lang (2001b), for example, present ﬂexible,
Bayesian multicategorical regression models to analyze discrete unemployment durations,
with ﬁnding a full–time employment and ﬁnding a part–time employment as competing
events.
Multi–state models present a further extension to survival models. The models de-
scribed so far only consider one initial state and one or a number of terminating events.
Multi–state models on the other hand may be applied to analyze general event history
data. Here the various events are considered as transitions from one state to another. This
type of data is for example given in clinical studies where the interest lies in analyzing
transitions between diﬀerent states of health.
Event–speciﬁc or transition–speciﬁc hazard rates are deﬁned as before in (1.11), but
the likelihood of multi–state models is slightly more complex than the likelihood of com-
peting risks models. While (survival models and) competing risks models assume that
each individual is at risk to experience any event during the whole observation time, this is
not necessarily true with multi–state models. Here, a state structure speciﬁes the diverse
states (that might be absorbing or transient) and deﬁnes which transitions are possible
and which ones are not. Thus it is important to consider that some individuals might not
be at risk to experience certain events over periods of time being in certain states. For this
reason the application of multicategorical regression models to discrete time event history
data is not completely straightforward, but demands some additional consideration.

1.8 Overview
25
1.8
Overview
The thesis is organized as follows.
The second chapter, which forms the core of this
thesis, is based on the manuscript ”Geoadditive Survival Models” by Hennerfeind, Brezger
and Fahrmeir that is accepted for publication in the Journal of the American Statistical
Association (JASA) Theory and Methods Section. Here we will present our nonparametric
Bayesian survival model approach to extend the basic Cox model with respect to the
aspects listed in Section 1.3. We will describe models, likelihood and priors for unknown
functions and parameters, discuss the inference via MCMC and present some simulations
and applications to diﬀerent data sets.
In the third chapter of this thesis we deal with so called relative survival analysis, that
is used to model the excess risk of a certain subpopulation relative to the base risk that
is present in the whole population. Such models are typically used in the area of clinical
studies, that aim at identifying prognostic factors for disease speciﬁc mortality with data
on speciﬁc causes of death being not available. Our work has been motivated by real data
on breast cancer where causes of death are not known. This chapter forms an extension
of the analyses presented in the manuscript ”Age, period and cohort eﬀects in Bayesian
smoothing of spatial cancer survival with geoadditive models” by Sauleau, Hennerfeind,
Buemi and Held which is accepted for publication in Statistics in Medicine. The usefulness
of our relative survival approach is supported by means of a simulated data set.
The fourth chapter is concerned with extensions to more general event history models.
Embedded in the counting process framework (Andersen, Borgan, Gill and Keiding 1993)
we present ﬂexible multi–state models that are used to model transitions between a ﬁnite
number of diﬀerent states and include the survival model as well as the competing risks
model as special cases.
Applications to medical data on structural valve degeneration
of biological prostheses and to sleep–electroencephalography data with multiple recurrent
states of sleep illustrate our methods.
All approaches presented within this thesis are implemented in the statistical software
package BayesX. In Chapter 5 we present a tutorial to exemplify how Bayesian survival
and multi–state models may be analyzed using BayesX.

26
1. Introduction

Chapter 2
Nonparametric regression for
survival data
2.1
Introduction
In epidemiological, economic or social science applications, survival data often contain
geographical or spatial information such as the district or postal code of the residence of
individuals in the study. Analyzing and modelling geographical patterns for survival or
waiting times, in addition to the impact of other covariates, is of obvious interest in many
studies. For example, Henderson, Shimakura and Gorst (2002) model spatial variation
in survival of acute myeloid leukemia patients in northwest England, Banerjee, Wall and
Carlin (2003) apply a spatial frailty model to infant mortality in Minnesota, and Li and
Ryan (2002) analyze the eﬀect of risk factors on the onset of childhood asthma with spatial
data from the East Boston Asthma Study. In Subsection 2.5.3 of this thesis, we will apply
our approach to data on waiting times to coronary artery bypass graft (CABG). Within a
discrete–time setting, spatial survival data from this study are analyzed by Crook, Knorr–
Held and Hemingway (2003), and Fahrmeir, Lang, Wolﬀand Bender (2003) investigate the
impact of small area labor market regions and other covariates, such as calendar time, age
and unemployment beneﬁts, on unemployment duration with discrete–time models.
A particular advantage of our approach is that all unknown functions and parameters
are treated within a uniﬁed general framework by assigning appropriate priors with the
same structure but diﬀerent forms and degrees of smoothness. Based on previous work

28
2. Nonparametric regression for survival data
(Fahrmeir and Lang, 2001a; Lang and Brezger, 2004) on semiparametric regression, non-
linear eﬀects of unknown functions of time, in particular the log–baseline hazard rate, and
of continuous covariates or further time scales are modelled through Bayesian versions of
penalized splines (P–splines) introduced by Eilers and Marx (1996), Marx and Eilers (1998)
for generalized additive models in a frequentist setting. Basically, time is treated in the
same way as a continuous covariate, but the degree and amount of smoothness may be
diﬀerent. For example, simple random walk priors for the log–baseline eﬀect in a piecewise
exponential model are P–splines of degree zero. The spatial component is modelled by
Gaussian Markov random ﬁeld (MRF) priors, as common in disease mapping, by two–
dimensional penalized tensor–product splines, or by a geostatistical (kriging) stationary
Gaussian random ﬁeld (GRF) model. From a computational point of view, MRF’s and P–
splines are clearly preferable to GRF’s because their posterior precision matrices are band
matrices or can be transformed into a band matrix–like structure. This special structure
considerably speeds up computations and enhances numerical stability compared to the
full precision matrices arising from the GRF approach.
For data observed on a irregular discrete lattice, MRF’s seem to be most appropriate. If
exact locations are available, P–spline or GRF surface smoothers seem to be more natural,
but they can also be applied to discrete lattices after computing centroids of regions.
Our uniﬁed general framework also has theoretical and computational advantages for
posterior analysis. Extending previous results for mixed models in Sun, Tsutakawa and
Speckman (1999), we can show propriety of posteriors under regularity conditions. This
is important, because some of our priors are diﬀuse or partially improper. From the com-
putational point of view, full conditionals of blocks of parameters have similar structure,
and lead to eﬃcient MCMC techniques. Smoothing parameters are an integral part of
the model and can be estimated jointly with unknown functions and other parameters.
Inferential procedures have been implemented in C++ as part of BayesX (Brezger, Kneib
and Lang 2005).
Non– and semiparametric Bayesian survival models have become quite popular in re-
cent years, and some previous work deals with special or related cases of our approach.
For fully Bayesian models without a spatial component Ibrahim, Chen and Sinha (2001)
provide a good introduction and overview. Joint estimation of the baseline hazard and
usual linear covariate eﬀects in the Cox model has been considered by several authors.

2.1 Introduction
29
Gamerman (1991) proposes a Gaussian random walk model for the log–baseline hazard in
the piecewise exponential model, and Sinha (1993) suggests a joint Gaussian smoothness
prior, and Cai, Hyndman and Wand (2002) and Cai and Betensky (2003) use a mixed
model representation of linear regression splines to estimate the baseline hazard. In all
these approaches, however, eﬀects of continuous covariates are assumed to be of the usual
linear parametric form, and no spatial component is present.
Survival models with a spatial component have recently been suggested in several pub-
lications. The approaches diﬀer in the speciﬁcation of the baseline hazard rate and in the
model chosen for the spatial component, but the remaining part of the predictor is still of
linear parametric form. Thus, non–parametric terms for ﬂexible modelling and estimation
of the eﬀects of continuous covariates, further time scales and time–varying coeﬃcients
are not considered in these approaches. Li and Ryan (2002) add a spatial component in
form of a stationary Gaussian process to the linear predictor of the Cox model. Treating
the baseline hazard as a nuisance parameter, inference for the linear predictor and for
correlation function parameters is based on a marginal rank likelihood. No procedure for
estimating the spatial (random) eﬀects is provided. Henderson et al. (2002) propose a Cox
model with conditionally independent spatial gamma frailties, with means following either
a geostatistical model or a Markov random ﬁeld. For inference they use MCMC methods,
except the baseline hazard estimate. For this they plug in the Breslow estimator at each
iteration of the chain. Banerjee et al. (2003) assume a parametric Weibull baseline hazard
and geostatistical or MRF priors for the spatial component. In comparison they prefer
MRF priors, since computing times for geostatistical GRF models are much larger. This is
in agreement with our own ﬁndings. Banerjee and Carlin (2003) develop Bayesian spatio–
temporal survival models, modelling baseline hazard functions nonparametrically through
a beta mixture approach and assuming MRF or CAR (conditionally autoregressive) priors
for spatial eﬀects, and Carlin and Banerjee (2002) extend this approach to multivariate
MRF models, with applications to cancer survival data from Iowa. A good overview is
given in Banerjee et al. (2004).
An empirical Bayes pendant to our semiparametric fully Bayesian approach has been
developed in Kneib and Fahrmeir (2004) (see also Kneib, 2006).
The rest of the chapter is organized as follows. In Section 2.2 we describe models,
likelihood, and priors for unknown functions and parameters. MCMC inference and model

30
2. Nonparametric regression for survival data
choice are outlined in Subsection 2.3.1 and Subsection 2.3.2, respectively, and Subsection
2.3.3 provides results on the propriety of posteriors in geoadditive survival models under
regularity assumptions. Performance is studied in Section 2.4 through simulation studies.
Applications in Section 2.5 illustrate the method.
2.2
Models, likelihood and priors
2.2.1
Observation model and likelihood
Consider survival data in usual form, i.e., it is assumed that each individual i in the study
has a lifetime Ti and a censoring time Ci that are independent random variables. The
observed lifetime is then ti = min(Ti, Ci), and δi denotes the censoring indicator. The data
are then given by
(ti, δi; vi),
i = 1, . . . , n,
(2.1)
where vi is the vector of covariates. Covariates may also be time–dependent, but we restrict
discussion to time–constant covariates for simplicity. The same applies to left truncation
(see Subsection 1.4.2), which might easily be included, but it is not discussed here for
facility of inspection.
In Cox’s proportional model the hazard rate for individual i is assumed as the product
λi(t; vi) = λ0(t) exp(γ1vi1 + . . . + γrvir) = λ0(t) exp(v′
iγ).
(2.2)
The baseline hazard rate is unspeciﬁed, and, through the exponential link function, the
covariates v = (v1, . . . , vr) act multiplicatively on the hazard rate. As pointed out in the
introduction, in a number of applications there is a need for extending this basic model
with respect to several aspects. We propose novel nonparametric Bayesian survival mod-
els that can deal with these issues in a ﬂexible and uniﬁed framework. Reparametrizing
the baseline hazard rate through exp{g0(t)}, g0(t) = log{λ0(t)} and partitioning the vec-
tor of covariates into groups of covariates x, z, s and v, we extend model (2.2) to the
nonparametric multiplicative observation model
λi(t) := λi(t; xi, zi, si, vi) = exp{ηi(t)}
(2.3)

2.2 Models, likelihood and priors
31
with geoadditive predictor
ηi(t) = g0(t) +
p
X
j=1
gj(t)zij +
q
X
j=1
fj(xij) + fspat(si) + v′
iγ + bgi.
(2.4)
Here g0(t) = log{λ0(t)} is the log–baseline eﬀect, gj(t) is a time–varying eﬀect of the
covariate zj, and fj(xj) is the nonlinear eﬀect of a continuous covariate xj. The function
fspat(s) is a (structured) spatial eﬀect, where s, s = 1, . . . , S is either a spatial index,
with si = s if subject i is from area s, or an exact spatial coordinate s = (xs, ys), e.g. for
centroids of regions or if exact locations of individuals are known. The vector γ is the
vector of usual linear ﬁxed eﬀects, and bg is a subject– or group–speciﬁc frailty or random
eﬀect, with bgi = bg if individual i is in group g, g = 1, ..., G. For G = n, we obtain
individual–speciﬁc frailties, for G < n, bg might be the eﬀect of center g in a multicenter
study or the unstructured (uncorrelated random) spatial eﬀect of an area (i.e. bg = bs), for
example. Random slopes could also be introduced, but we omit this here. Several other
extensions of the model, such as choice of other link functions, inclusion of interactions and
competing risks, are possible. We discuss this in the concluding section. For identiﬁability
reasons, we center all unknown functions about zero, and include an intercept term in the
parametric linear term.
Under the assumption about noninformative censoring, the likelihood is given by
L
=
n
Y
i=1
λi(ti)δi · exp

−
Z ti
0
λi(u)du

=
n
Y
i=1
λi(ti)δi · Si(ti) ,
(2.5)
inserting (2.3) and (2.4).
To obtain a uniﬁed and generic notation, we rewrite the observation model in general
matrix notation. This is useful for deﬁning priors in the next subsection and for developing
posterior analysis in Section 2.3 as well as for describing results on propriety of posteriors
for mixed models in Subsection 2.3.3.
Let η = (η1, . . . , ηi, . . . , ηn)′ denote the predictor vector, where ηi := ηi(ti) is the value
of predictor (2.4) at the observed lifetime ti, i = 1, . . . , n.
Correspondingly, let gj =
(gj(t1), . . . , gj(tn))′ denote the vector of evaluations of the functions gj(t), j = 0, . . . , p,
f j = (fj(x1j), . . . , fj(xnj))′ the vector of evaluations of the functions fj(xj), j = 1, . . . , q,

32
2. Nonparametric regression for survival data
f spat = (fspat(s1), . . . , fspat(sn))′ the vector of spatial eﬀects, and b = (bg1, . . . , bgn)′ the
vector of uncorrelated random eﬀects. Furthermore, let ˜gj = (gj(t1)z1j, . . . , gj(tn)znj)′, j =
1, . . . , p.
In the following, we can always express vectors g0, ˜gj, f j, f spat and b as the matrix prod-
uct of an appropriately deﬁned design matrix Z, say, and a (possibly high–dimensional)
vector β of parameters, e.g. ˜gj = Zjβj, f j = Zjβj, etc. Then, after reindexing, we can
represent the predictor vector η in generic notation as
η = V γ + Z0β0 + . . . + Zmβm.
(2.6)
2.2.2
Priors for parameters and functions
The Bayesian model formulation is completed by assumptions about priors for parameters
and functions. For ﬁxed eﬀect parameters γ in (2.6) we assume diﬀuse priors p(γ) ∝const.
A weakly informative normal prior would be another choice. Uncorrelated random eﬀects
are assumed to be i.i.d. Gaussian, bg ∼N(0, τ 2
b ).
Priors for functions and spatial components are deﬁned by a suitable design matrix
Zj, j = 0, . . . , m, and a prior for the parameter vector βj. The general form of a prior for
βj in (2.6) is
p(βj|τ 2
j ) ∝τ
−rj
j
exp

−1
2τ 2
j
β′
jKjβj

,
(2.7)
where Kj is a precision or penalty matrix of rank(Kj) = rj, shrinking parameters towards
zero or penalizing too abrupt jumps between neighboring parameters. For P–splines and
MRF priors, Kj will be rank deﬁcient, i.e., rj < dj = dim(βj), and the prior is partially
improper.
For unknown functions fj(xj) or gj(t), we assume Bayesian P–spline priors as in Lang
and Brezger (2004). Random walk priors, suggested in Fahrmeir and Lang (2001a), may
be used as smoothness priors for the baseline eﬀect and time–varying covariate eﬀects in a
piecewise exponential model, correspond to the special case of P–splines with degree zero.
The basic idea of P–spline regression (Eilers and Marx 1996) is to approximate a function
fj(xj) as a linear combination of B–spline basis functions Bm, i.e.
fj(xj) =
dj
X
m=1
βjmBm(xj).
(2.8)

2.2 Models, likelihood and priors
33
The basis functions Bm are B–splines of degree l deﬁned over a grid of equally spaced
knots xmin = ξ0 < ξ1 < . . . < ξs = xmax, dj = l + s. The number of knots is moderate,
but not too small, to maintain ﬂexibility, but smoothness of the function is encouraged by
diﬀerence penalties for neighboring coeﬃcients in the sequence βj = (βj1, . . . , βjdj)′. The
Bayesian analogue are ﬁrst or second order random walk smoothness priors
βjm = βj,m−1 + ujm
or
βjm = 2βj,m−1 −βj,m−2 + ujm
(2.9)
with i.i.d. Gaussian errors ujm ∼N(0, τ 2
j ) and diﬀuse priors p(βj1) ∝const, or p(βj1)
and p(βj2) ∝const, for initial values. A ﬁrst order random walk penalizes abrupt jumps
βjm −βj,m−1, and a second order random walk penalizes deviations from a linear trend.
The amount of smoothness or penalization is controlled by the variance τ 2
j , which acts
as a smoothness (hyper–)parameter, with hyperprior deﬁned by (2.13). The joint prior
of the regression parameters βj is Gaussian and can be easily computed as a product of
conditional densities deﬁned by (2.9) as
βj | τ 2
j ∝τ
−rj
j
exp

−1
2τ 2
j
βj
′Kjβj

,
(2.10)
which is the generic form (2.7).
The penalty matrix Kj is of the form Kj = D′D, where D is a ﬁrst or second order
diﬀerence matrix. For second order random walks, for example, D is given by
Ddj−2×dj =




1
−2
1
...
...
...
1
−2
1



.
The matrix Kj has band structure which is very useful for computationally eﬃcient MCMC
updating schemes (compare Section 2.3). It has rank rj = dj−1 and rj = dj−2 for ﬁrst and
second order random walk priors, respectively. The n×dj design matrix Zj consists of the
basis functions evaluated at the observations xij, i.e., Zj(i, m) = Bm(xij). Priors for the
unknown functions gj(t) are deﬁned in complete analogy as in (2.8) and (2.9). The design
matrix for time–varying eﬀect terms ˜gj, j = 1, . . . , p is derived as Zj(i, m) = zijBm(xij).
A common choice for approximating smooth curves are quadratic or cubic B–splines and
a second order penalty. This speciﬁcation is also preferred by Eilers and Marx (1996) and
Lang and Brezger (2004) in order to obtain suﬃciently smooth results. Computationally,

34
2. Nonparametric regression for survival data
linear splines are simpler. The simplest choice are B–splines of degree zero, i.e. Bm(x) ≡1
over the m–th interval, and Bm(x) ≡0 elsewhere. Then the eﬀect is approximated by
a piecewise constant function, and the function values follow a random walk model as in
Fahrmeir and Lang (2001a). This special choice, with time t as covariate, is the easiest way
to smooth the baseline in the piecewise exponential model; moreover the integral in the
likelihood (2.5) reduces to a sum, see the next section. With P–splines of higher degree,
however, estimation of smooth baseline eﬀects is improved in terms of MSEs, see Section
2.4. Another nice feature of cubic B–splines is that the well known smoothing splines
appear as a special case with knots at every observation point.
For comparison we also consider an alternative parametric form. In the parametric case
we choose a Weibull form for the baseline hazard (Banerjee, Wall and Carlin (2003)):
λ0(ti) = αtα−1
i
.
(2.11)
A GA(0.01, 0.01) prior is assumed for α, so that α has a prior mean of 1 (corresponding to
a constant hazard over time) and a large variance of 100.
For the structured spatial eﬀect fspat(s) we assume either Markov random ﬁeld (MRF)
priors, two–dimensional tensor product P–spline priors, or Gaussian random ﬁeld (GRF)
priors, common in geostatistics (kriging).
In the case of MRF priors we deﬁne areas as neighbors if they share a common boundary
and assume that the eﬀect of an area s is conditionally Gaussian, with the mean of the
eﬀects of neighboring areas as expectation and a variance that is inverse proportional to
the number of neighbors of area s. Setting fspat(s) := βspat
s
we have
βspat
s
| βspat
s′
, s′ ̸= s ∼N
 
1
Ns
X
s′∈δs
βspat
s′
, τ 2
spat
Ns
!
,
where Ns is the number of neighbors of area s, and s′ ∈δs denotes that area s′ is a
neighbor of area s. The n × S design matrix Zspat is now a 0/1 incidence matrix. Its
value in the i–th row and s–th column is 1 if observation i is located in site or region
s, and zero otherwise. The S × S penalty matrix Kspat has the form of an adjacency
matrix with rank(Kspat) = rspat = S −1. As for one–dimensional functions the amount of
spatial smoothness is controlled by the variance τ 2
spat. A generalization to weighted means
of neighboring areas is possible but not considered here.

2.2 Models, likelihood and priors
35
Our second approach is based on two–dimensional P–splines, a rather parsimonious, but
ﬂexible method for modelling interactions between continuous covariates described in Lang
and Brezger (2004) for Gaussian regression. Considering the x– and y–coordinates of the
geographical center of each area, the spatial eﬀect can be seen as an interaction between two
continuous covariates xs and ys. The assumption is that the unknown structured spatial
eﬀect fspat(s) can be approximated by the tensor product of one–dimensional B–splines,
i.e.
fspat(s) = fspat(xs, ys) =
dspat
X
m1=1
dspat
X
m2=1
βspat
m1m2Bspat,m1(xs)Bspat,m2(ys).
Now the B–splines of degree l are deﬁned over a regular two–dimensional grid of a moderate,
but not too small number of equally spaced knots ξρν, ρ, ν = 1, . . . , dspat −1. We restrict
ourselves to an equal number of knots for each direction. Knots are equally spaced within
each direction, but the distance may diﬀer between direction xs and ys. Priors for βspat =
(βspat
11 , . . . , βspat
1dspat, . . . , βspat
dspat1, . . . , βspat
dspatdspat)′ are based on MRF priors for spatial data on a
regular lattice (see e.g. Besag and Kooperberg, 1995). Since there is no natural ordering of
parameters, priors have to be deﬁned by specifying the conditional distributions of βspat
m1m2
given neighboring parameters and the variance component τ 2
spat. The most commonly used
prior speciﬁcation based on the four nearest neighbors can be deﬁned by
βspat
m1m2|· ∼N
1
4(βspat
m1−1,m2 + βspat
m1+1,m2 + βspat
m1,m2−1 + βspat
m1,m2+1), τ 2
spat
4

(2.12)
for m1, m2 = 2, . . . , dspat −1 and appropriate changes for corners and edges. For example,
for the upper left corner we obtain βspat
11 |· ∼N( 1
2(βspat
12
+ βspat
21 ),
τ 2
spat
2 ). For the left edge, we
get βspat
1m2|· ∼N( 1
3(βspat
1,m2+1 + βspat
1,m2−1 + βspat
2,m2),
τ 2
spat
3 ).
The prior (2.12) is a direct generalization of a ﬁrst order random walk in one dimension.
Its conditional mean can be interpreted as a least squares locally linear ﬁt at knot position
ξρν given the neighboring parameters. More details can be found in Lang and Brezger
(2004). Deﬁning Kspat = D′
1D1 + D′
2D2, where D1 = I ⊗D and D2 = D ⊗I, the
prior can again be expressed in the general form (2.7). Here, D is the ﬁrst order diﬀerence
matrix known from the one–dimensional case, and D′
1D1 corresponds to the penalization
in the direction of x and D′
2D2 corresponds to the penalization in the direction of y.
Our third option are stationary Gaussian random ﬁeld (GRF) priors, which can be
seen as two–dimensional surface smoothers based on special basis functions, e.g. radial

36
2. Nonparametric regression for survival data
basis functions, and have been used by Kammann and Wand (2003) for modelling the
spatial component in Gaussian regression models. The spatial component fspat(s) = βspat
s
is assumed to follow a zero mean stationary Gaussian random ﬁeld {βspat
s
: s ∈R2} with
variance τ 2
spat and use an isotropic covariance function cov(βspat
s
, βspat
s′
) = C(∥s −s′∥) as
proposed by Stein (1999). For a ﬁnite array s ∈{1, . . . , S} of sites as in our application
the prior can be brought in the general form
βspat | τ 2
spat ∝exp

−
1
2τ 2
spat
(βspat)′Kspatβspat

with penalty matrix Kspat = C−1, where C[k, l] = C(∥sk −sl∥), 1 ≤k, l ≤n, and design
matrix Zspat = C.
For the covariance function C(r) we follow again recommendations of Stein (1999) and
use the Mat´ern family of covariance functions C(r; ρ, ν). For the special case ν = 1.5 for
the smoothness parameter the covariance functions simplify to
C(r; ρ, ν) = τ 2
spat(1 + |r|/ρ)e−|r|/ρ,
which is the simplest member of the Mat´ern family that results in diﬀerentiable surface
estimates as Kammann and Wand (2003) point out. The parameter ρ controls how fast
covariances die out with increasing distance r. We choose ρ according to the rule
ˆρ = max
k,l ∥sk −sl∥/c
to ensure scale invariability. This rule proved to work well in practice. The constant c is
chosen in such a way that C(c) is small, e.g. C(c) = 0.001.
While the dimension of the penalty matrix in a MRF equals the number of diﬀerent
regions S, in a GRF the dimension corresponds to the number of distinct locations which
is likely to be close to or equal to the sample size. To reduce this computational burden
Kammann and Wand (2003) propose low–rank kriging to approximate stationary Gaussian
random ﬁelds. Therefore they deﬁne a ’representative’ subset of knots D = {κ1, . . . , κM}
of the set of distinct locations by applying a space ﬁlling algorithm (compare Johnson et
al. (1990) and Nychka and Saltzman (1998) for details). Based on these knots, we obtain
the approximation fspat(s) = z′
spat(s)βspat with the M–dimensional design vector zspat(s) =
(C(∥s −κ1∥), . . . , C(∥s −κM∥))′ and penalty matrix Kspat = ˜C and ˜C[k, l] = C(∥κk −

2.2 Models, likelihood and priors
37
κl∥). The number of knots controls the trade–oﬀbetween accuracy of the approximation
and numerical simpliﬁcation. Details on GRF and (low–rank) kriging can be found in
Kammann and Wand (2003), Kneib and Fahrmeir (2005) or Kneib (2006).
Still a serious drawback of this approach is the computational eﬀort involved. Since
the penalty matrix Kspat has no longer band structure it is not possible to employ eﬃcient
matrix algorithms for sparse matrices like the Cholesky decomposition in order to draw
samples from our multivariate normal proposal density and to compute the determinant of
the precision matrix, which is needed to calculate the acceptance probability of the MH–
step in every iteration (compare Section 2.3). For the application in Section 2.5, e.g., this
means that the required CPU time multiplies approximately by the factor 20, even if we
use low–rank kriging with a moderate number of 100 knots. It depends mainly on the data
at hand, which of the diﬀerent approaches leads to the best ﬁt. For data observed on a
discrete lattice or on the level of geographical regions as in our application, MRFs seem to
be most adequate, while surface smoothers as 2d P–splines or kriging may be more natural
in situations where exact locations are available. In general, MRFs exhibit more rough
results, while 2d P–splines produce the smoothest estimates. GRFs also tend to give quite
smooth curves.
A decision between MRFs and 2d P–splines or GRFs, respectively, may depend on
ones beliefs about the characteristics of the corresponding eﬀect. If an eﬀect is supposed
to vary smoothly (e.g. in case it is inﬂuenced by temperature or atmospheric pressure)
surface estimators can be expected to be the better choice. If, on the other hand, an eﬀect
is likely to be induced, for example, by characteristics of geographical or political units,
which may depend on neighbors, but may quite as well be rather heterogenic, then a MRF
should be preferred. However, in applications sometimes surface estimators outperform
MRFs even for discrete data (and vice versa). This may be due to some regions having
few neighbors or observations, since a more smooth surface estimator is able to reduce the
bias for such regions.
In real data applications we do not know how much of the spatial variation is explained
by structured, spatially correlated eﬀects and how much by unstructured, uncorrelated
eﬀects. Therefore we may ﬁt an additional (unstructured) area–speciﬁc random eﬀect. We
recommend to interpret only the sum of the two eﬀects, since identiﬁability is weak in that
case.

38
2. Nonparametric regression for survival data
We routinely assign inverse Gamma priors IG(aj; bj)
p(τ 2
j ) ∝
1
(τ 2
j )aj+1 exp

−bj
τ 2
j

(2.13)
to all variances.
They are proper for aj > 0, bj > 0, and we use aj = bj = 0.001
as a standard choice for a weakly informative prior.
From our experience results are
rather insensitive to the choice of aj > 0 and bj > 0 for moderate to large data sets and
the posterior distribution is proper in any case under some regularity assumptions (see
Subsection 2.3.3 and Hennerfeind, Brezger and Fahrmeir (2005) for a proof). However,
since the limiting case, when aj and bj are zero, leads to an improper posterior distribution,
we present a sensitivity analysis in Section 2.4 and compare the results to those we obtained
with a uniform prior for the standard deviation τj, as proposed in Gelman (2004). Note
that uniform priors are a special (improper) case of the prior (2.13) with aj = −0.5, bj = 0,
still leading to proper posteriors under regularity assumptions.
The Bayesian model speciﬁcation is completed by assuming that all priors for parame-
ters are conditionally independent, and that all priors are mutually independent.
2.3
Markov chain Monte Carlo inference
In what follows, let β = (β′
0, ..., β′
m)′ denote the vector of all regression coeﬃcients in the
generic notation (2.6), γ the vector of ﬁxed eﬀects, and τ 2 = (τ 2
0 , ..., τ 2
m) the vector of all
variance components. Full Bayesian inference is based on the entire posterior distribution
p(β, γ, τ 2 | data) ∝L(β, γ, τ 2) p(β, γ, τ 2).
Due to the (conditional) independence assumptions, the joint prior factorizes into
p(β, γ, τ 2) =
( m
Y
j=0
p(βj | τ 2
j )p(τ 2
j )
)
p(γ),
where the last factor can be omitted for diﬀuse ﬁxed eﬀect priors.
The likelihood L(β, γ, τ 2) is given by inserting (2.3), (2.4) into (2.5), but the integral
requires integration over all terms depending on survival time t, i.e. terms of the form
Ii =
Z ti
0
exp
 
g0(u) +
p
X
j=1
gj(u)zij
!
du,
(2.14)

2.3 Markov chain Monte Carlo inference
39
where gj(t) = P βjmBm(t). Apart from B–splines Bm(t) of degree zero, i.e. random walk
models, and linear B–splines, these integrals are not available in closed form. The ﬁrst
case leads to the piecewise exponential model: The time axis is divided into a grid
0 = ξ0 < ξ1 < ... < ξt−1 < ξt < ... < ξs = tmax,
and gj(t) is assumed to be a piecewise constant function, i.e.
gj(t) = βjt
in time interval (ξt−1, ξt], t = 1, ..., s. In this case, the integral reduces to a sum, and, after
some calculations, the log–likelihood contribution of observation i in the interval (ξt−1, ξt]
can be expressed as
lit = yitηit −exp (∆it + ηit)
where
yit =
(
1
ti ∈(ξt−1, ξt],δi = 1
0
else.
∆′
it =







ξt −ξt−1,
ξt < ti
ti −ξt−1,
ξt−1 < ti ≤ξt
0,
ξt−1 ≥ti
∆it = log ∆′
it
(∆it = −∞if ∆′
it = 0).
This likelihood is proportional to a Poisson–likelihood, with the predictor ηit containing
an additional oﬀset term ∆it, see Fahrmeir and Tutz (2001, Section 9.1) or Ibrahim et
al. (2001, Section 3.1) for details.
For linear B–splines, the integrals can still be solved analytically, but expressions are
rather messy and the computational eﬀort is quite high, see Cai et al. (2002, Appendix).
Following their suggestion, we use simple numerical integration in form of the trapezoidal
rule for linear B–splines as well as for the commonly used cubic B–splines, where analytical
integration is not possible anyway.

40
2. Nonparametric regression for survival data
2.3.1
Updating full conditionals
Full Bayesian inference via MCMC simulation is based on updating full conditionals of
single parameters or blocks of parameters, given the rest of the data. For updating the
parameter vectors βj, which correspond to the time–independent functions fj(xj), as well
as spatial eﬀects βspat, ﬁxed eﬀects γ and random eﬀects b, we use a slightly modiﬁed
version of an MH–algorithm based on iteratively weighted least squares (IWLS) proposals,
developed for ﬁxed and random eﬀects by Gamerman (1997) and adapted to generalized
additive mixed models in Brezger and Lang (2006).
Suppose we want to update βj, with current value βc
j of the chain. Then a new value βp
j
is proposed by drawing a random vector from a (high–dimensional) multivariate Gaussian
proposal distribution q(βc
j, βp
j), which is obtained from a quadratic approximation of the
log–likelihood by a second order Taylor expansion with respect to βc
j, in analogy to IWLS
iterations in generalized linear models.
More precisely, the goal is to approximate the
posterior by a Gaussian distribution, obtained by accomplishing one IWLS step in every
iteration of the sampler. Then, random samples have to be drawn from a high dimensional
multivariate Gaussian distribution with precision matrix and mean
P j = Z′
jW (βc
j)Zj + 1
τ 2
j
Kj,
mj = P −1
j Z′
jW (βc
j)(˜y −˜η).
Here, ˜ηi = ηi(ti) −fj(xij), W (βc
j) = diag(w1, . . . , wn) is the weight matrix for IWLS with
weights calculated from the current state βc
j as follows
wi = exp
 
q
X
j=1
fj(xij) + fspat(si) + v′
iγ + bgi
!
· Ii.
Concisely written we get wi =
R ti
0 λi(u)du = Λi(ti), which is the cumulative hazard rate.
The working observations ˜yi are given by
˜yi = ηi(ti) + δi
wi
−1.
See Appendix A1 for a detailed derivation of those quantities. The proposed vector βp
j is
accepted as the new state of the chain with probability
α(βc
j, βp
j) = min

1, p(βp
j | ·)q(βp
j, βc
j)
p(βc
j | ·)q(βc
j, βp
j)


2.3 Markov chain Monte Carlo inference
41
where p(βj | ·) is the full conditional for βj (i.e. the conditional distribution of βj given
all other parameters and the data).
For a fast implementation, we use the fact that the precision matrices of the Gaussian
proposal distributions are banded for MRS and 2d P–spline models, so that Cholesky
decompositions can be performed eﬃciently. Now, random numbers from the high dimen-
sional proposal distributions can be eﬃciently drawn using an algorithm by Rue (2001).
The acceptance probability α(βc
j, βp
j) involves the determinant det(P j) of the proposal den-
sity, since P j depends on βc
j. Fortunately, this quantity is obtained as a simple by–product
of the Cholesky decomposition with negligible computational eﬀort.
Note, however, that this is not the case for GRF models. Here, Kj is not banded, and
thus P j is not banded, either. Therefore, drawing from the proposal and evaluating its
determinant is much more demanding in terms of CPU time.
For the parameters βj corresponding to the functions g0(t), ..., gp(t) depending on time
t, the IWLS–MH algorithm requires considerably more computational eﬀort, because the
integrals in the log–likelihood as well as ﬁrst and second derivatives are involved now.
Therefore, we adopt a computationally faster MH–algorithm based on conditional prior
proposals, although IWLS–MH has better mixing properties.
This algorithm was ﬁrst
developed by Knorr–Held (1999) for state space models and extended for generalized ad-
ditive mixed models in Fahrmeir and Lang (2001a). It requires only evaluation of the
log–likelihood, not of derivatives. However, draws are not performed for the entire vector
βj, but iteratively for blocks of subvectors, see Fahrmeir and Lang (2001a) for details. In
the case of the parametric Weibull prior (2.11) a new value αp is proposed by drawing from
a Gamma distribution GA(αc · bw, bw), with αc denoting the current value of the chain and
bw being tuned automatically during the burn–in period.
The full conditionals for the variance parameters τ 2
j are (proper) inverse Gamma with
parameters
a′
j = aj + 1
2rj
and
b′
j = bj + 1
2β′
jKjβj,
including the case aj = −0.5, bj = 0 of uniform priors on τj. Updating can be done by
simple Gibbs steps, drawing random numbers directly from the inverse Gamma densities.
In complete analogy, the full conditional for a variance component τ 2
spat of the spatial eﬀect
and τ 2
b of a random intercept or slope is again an inverse gamma distribution, and updating

42
2. Nonparametric regression for survival data
is straightforward.
2.3.2
Model choice
Bayesian model choice is an area of ongoing research with several competing proposals
ranging from (modiﬁed) Bayes factors to posterior predictive loss approaches (Gelfand and
Gosh 1998).
We routinely use the Deviance Information Criterion (DIC) developed in
Spiegelhalter, Best, Carlin and van der Linde (2002). It is given as
DIC = D(θ) + 2pD = D(θ) + pD,
where θ is the vector of parameters, D(θ) is the deviance of the model evaluated at the
posterior mean estimate θ, D(θ) is the posterior mean of the deviance and pD = D(θ) −
D(θ) is the eﬀective number of parameters. Since it is at least unclear, how the saturated
model should be deﬁned in the case of survival data when the baseline hazard and other
nonparametric functions are parameters of interest, we use the unstandardized deviance
D(θ) = −2·log–likelihood instead of the saturated deviance. Banerjee and Carlin (2004,
Section 4) provide good arguments why the DIC is a reasonable criterion in connection
with censored survival data.
2.3.3
Propriety of posteriors in geoadditive survival models
Consider a geoadditive survival model with predictor in generic form (2.6), where Z 0β0
corresponds to an eﬀect with prior (2.7) for β0 such that dim(β0) = d0 ≥dj, rank(K0) =
r0 ≥rj, j = 1, . . . , m. This assumption is usually fulﬁlled for the spatial component or for
a high–dimensional vector of group–speciﬁc uncorrelated random eﬀects.
Denote by ηu, V u, Zu = (Z1u, ..., Zmu), Z0u the (sub–)predictor and sub–design ma-
trices corresponding to uncensored observations. Assume that the following conditions
hold:
(C1) rank(V u) = rank(V ) = p = dim(γ),
rank(Zju) = rank(Zj) = dj = dim(βj),
j = 0, ..., m
rank(Z′
uRZu + K) = d
where d = d1 + ... + dm,
K = diag(K1, ..., Km),
R = I −V u(V ′
uV u)−1V ′
u

2.3 Markov chain Monte Carlo inference
43
(C2) The priors p(τ 2
j ), j = 1, ..., m, are proper, and
R
p(τ 2
0 )τ −(r0−p−(d−r)−(d0−r0))
0
dτ 2
0 < ∞,
where r = r1 + ... + rm.
Theorem 1: If conditions (C1), (C2) hold then the posterior p(γ, β, β0, τ 2, τ 2
0 | y), where
τ 2 = (τ 2
1 , . . . , τ 2
m)′ and β = (β1, . . . , βm)′, is proper.
The following corollary is easier to check.
Corollary 1: Assume proper inverse Gamma priors Ga(aj, bj) for τ 2
j with j = 0, ..., m and
r0 + 2a0 −p −(d −r) −(d0 −r0) > 0.
If condition (C1) holds, then the posterior p(γ, β, β0, τ 2, τ 2
0 | y) is proper.
Proofs are based on Sun et al. (1999), and are outlined in Hennerfeind, Brezger and
Fahrmeir (2005).
Remark 1: Condition (C1) is equivalent to rank(Z0u)=d0 and
rank
 
V ′
uV u
V ′
uZu
Z′
uV u
Z′
uZu + K
!
= p + d
Remark 2: Under additional assumptions, proper posteriors may also be obtained for
aj < 0, bj = 0, e.g. for the uniform prior on τj. A rigorous proof could be based on a
generalization of Sun, Tsutakawa and He (2001).
Remark 3: Informally expressed condition (C1) is fulﬁlled if the information provided
by uncensored observations is suﬃcient to support the estimation of each single parameter
in (γ, β, β0). Considering the cases where β0 denotes a spatial eﬀect or a group–speciﬁc
random eﬀect, rank(Z0u)=d0 is fulﬁlled if the data set comprises at least one uncensored
observation per area or group, respectively. Condition (C2) is fulﬁlled if the inverse Gamma
priors for τ 2
j are proper and r0 + 2a0 is greater than the number of improper priors for
parameters in (γ, β, β0).
Note that these conditions are suﬃcient conditions and may be weakened in some places.

44
2. Nonparametric regression for survival data
2.4
Simulation Study
Performance was investigated through simulation studies. In particular we were interested
in the following questions: How inﬂuential is the choice of MRF versus smoother spatial
priors and the choice of a piecewise exponential model (P–spline of degree zero) versus
a cubic P–spline model for the baseline hazard rate? How sensitive are the results with
respect to the hyperparameters for the variance parameters? And how does a P–spline
model perform compared to a Weibull–model in cases where the Weibull assumption is
indeed true and in cases where it is not true, respectively.
Simulation Setup I
Life times Ti, i = 1, ..., 1236, were generated from Weibull distributions according to the
hazard model
λi(t) = λ0(t) exp(f1(xi) + fspat(si) + γvi) = exp(log(3t2) + sin(xi) + sin(xsi · ysi) −0.3vi),
(2.15)
with Weibull baseline hazard rate λ0(t) = 3t2, a binary covariate v, with the vis randomly
drawn from a Bernoulli B(1; 0.5) distribution, and a continuous covariate x, with the xis
randomly drawn from a uniform U[−3, 3] distribution. The spatial covariate si denotes
one of the s = 1, . . . , S = 309 counties of the former Federal Republic of Germany and xsi
and ysi are the centered coordinates of the geographic center of county si. We simulated
four observations per county, resulting in 309 × 4 = 1236 observations in total.
The
censoring was done as follows: We randomly selected a certain proportion of observations
(≈17% and ≈50%, respectively) that were to be censored. Censoring variables Ci for
these selected observations were then generated as i.i.d. draws from corresponding uniform
U[0, Ti] distributions.
Keeping the predictor ﬁxed, 100 replications {T (r)
i
, C(r)
i , i = 1, ..., 1236} respectively
{(t(r)
i , δ(r)
i ), i = 1, ..., 1236}, r = 1, ..., 100 of censored survival times were generated.
To investigate the ﬁrst question, the log–baseline hazard g0(t) was modelled by second
order random walk priors, corresponding to a piecewise exponential model, and alterna-
tively as a cubic P–spline with 20 knots. The spatial eﬀect was modelled as a MRF and
alternatively as a two–dimensional cubic P–spline with 12 × 12 knots. Simulations with

2.4 Simulation Study
45
GRF priors are not feasible due to much higher computation times, but the general mes-
sage will be the same. A cubic P–spline prior with 20 knots was chosen for f1(x) = sin(x)
in each case. Hyperparameters of inverse Gamma priors for variance components were set
to a = 0.001, b = 0.001, the standard choice.
For each replication r = 1, ..., 100, we computed the mean square errors
MSEr(g0) =
1
1236
1236
X
i=1
(bg(r)
0 (t(r)
i ) −g0(t(r)
i ))2,
for the log–baseline hazard g0(t),
MSEr(f1) =
1
1236
1236
X
i=1
( bf (r)
1 (xi) −f1(xi))2
for f1(x) = sin(x), and
MSEr(fspat) =
1
1236
1236
X
i=1
( bf (r)
spat(si) −fspat(si))2
for the spatial eﬀect fspat(s) = sin(xc · yc), where bg(r)
0
and bf (r)
k , k = 1, spat, are posterior
mean estimates for simulation run r. The MSE(γ) was computed in the usual way.
Results: MRF versus 2d P–spline, p.e.m. versus P–spline model
Figures 2.1 and 2.2 display boxplots of the logarithmic MSEs (log(MSEr), r = 1 . . . , 100).
As was to be expected, the P–spline model has smaller MSEs for g0 when compared to
the piecewise exponential model. Interestingly, the MSEs for γ = −0.3, f1(x) and fspat(s)
are more or less unaﬀected by the choice of the smoothness prior for the log–baseline g0(t).
Estimated functions of replication r, with r chosen such that MSEr is the median of
MSE1, . . . , MSE100, for g0(t), f1(x) and fspat(s) are displayed in Figures 2.3–2.5 (for the
censoring level of 17%). Regarding the two diﬀerent levels of censoring Figures 2.1 and 2.2
show that the estimation of the log–baseline eﬀect is the eﬀect that is strongest inﬂuenced
by the level of censoring. While increasing the censoring level from 17% to 50% leads to
an approximately 2.75 times larger MSE for g0(t) the MSE for fspat(s) is only increased
by a factor of ca. 1.35. Due to the simulation scheme, where the spatial eﬀect is deﬁned as
a smooth 2–dimensional function of the spatial coordinates (fspat(si) = sin(xsi · ysi)), the
MSEs for fspat are smaller when a 2–dimensional P–spline prior is assumed instead of a
MRF prior.

46
2. Nonparametric regression for survival data
MRF
2d P–spline
low
high
−3
−2
−1
0
pem
p−spline
pem
p−spline
g_0
low
high
−3
−2
−1
0
pem
p−spline
pem
p−spline
g_0
low
high
−8
−7
−6
−5
−4
−3
−2
pem
p−spline
pem
p−spline
f_1
low
high
−8
−7
−6
−5
−4
−3
−2
pem
p−spline
pem
p−spline
f_1
Figure 2.1:
Simulation: model comparison via boxplots of log–MSEs for data sets with
low (ca. 17%) and high censoring level (ca. 50%), for estimations with MRF priors (left
panel) and 2–d P–spline priors (right panel) for the spatial eﬀect each with cubic P–spline
priors for the log–baseline and p.e.m.s, respectively.

2.4 Simulation Study
47
MRF
2d P–spline
low
high
−5
−4
−3
−2
pem
p−spline
pem
p−spline
f_spat
low
high
−5
−4
−3
−2
pem
p−spline
pem
p−spline
f_spat
low
high
−20
−15
−10
−5
0
pem
p−spline
pem
p−spline
gamma
low
high
−20
−15
−10
−5
0
pem
p−spline
pem
p−spline
gamma
Figure 2.2:
Simulation: model comparison via boxplots of log–MSEs for data sets with
low (ca. 17%) and high censoring level (ca. 50%), for estimations with MRF priors (left
panel) and 2–d P–spline priors (right panel) for the spatial eﬀect each with cubic P–spline
priors for the log–baseline and p.e.m.s, respectively.

48
2. Nonparametric regression for survival data
−6
−4
−2
0
2
4
g_0(t)
0
1
2
3
t
(a) p.e.m., MRF
−6
−4
−2
0
2
4
g_0(t)
0
1
2
3
t
(b) p.e.m., 2d P–spline
−6
−4
−2
0
2
4
g_0(t)
0
1
2
3
t
(c) P–spline model, MRF
−6
−4
−2
0
2
4
g_0(t)
0
1
2
3
t
(d) P–spline model, 2d P–spline
Figure 2.3: (log–)Baseline eﬀects g0(t) for the various model speciﬁcations; displayed are
posterior mean estimates and 95% credible intervals of run r, with r chosen such that
MSEr is the median of MSE1, . . . , MSE100 (solid line and grey shaded area), and the
true (log–)baseline eﬀect (dashed line).
a) p.e.m., MRF, r=11, MSE=0.183 b) p.e.m.,
2d P–spline, r=51, MSE=0.181 c) P–spline model, MRF, r=51, MSE=0.148 d) P–spline
model, 2d P–spline, r=7, MSE=0.145

2.4 Simulation Study
49
−1.5
−1
−.5
0
.5
1
1.5
f_1(x)
−3
−2
−1
0
1
2
3
x
(a) p.e.m., MRF
−1.5
−1
−.5
0
.5
1
1.5
f_1(x)
−3
−2
−1
0
1
2
3
x
(b) p.e.m., 2d P–spline
−1.5
−1
−.5
0
.5
1
1.5
f_1(x)
−3
−2
−1
0
1
2
3
x
(c) P–spline model, MRF
−1.5
−1
−.5
0
.5
1
1.5
f_1(x)
−3
−2
−1
0
1
2
3
x
(d) P–spline model, 2d P–spline
Figure 2.4:
Nonparametric eﬀects f1(x) for the various model speciﬁcations; displayed
are posterior mean estimates and 95% credible intervals of run r, with r chosen such that
MSEr is the median of MSE1, . . . , MSE100 (solid line and grey shaded area), and the
true function (dashed line). a) p.e.m., MRF, r=53, MSE=0.0064 b) p.e.m., 2d P–spline,
r=36, MSE=0.0053 c) P–spline model, MRF, r=67, MSE=0.0068 d) P–spline model, 2d
P–spline, r=19, MSE=0.0056

50
2. Nonparametric regression for survival data
(a)
(b)
(c)
(d)
(e)
Figure 2.5:
Spatial eﬀects for the various model speciﬁcations with eﬀects ranging from
-1.3 to 1.65; displayed are posterior mean estimates of run r, with r chosen such that MSEr
is the median of MSE1, . . . , MSE100 a) true function b) p.e.m., MRF, r=41, MSE=0.041
c) p.e.m., 2d P–spline, r=13, MSE=0.021 d) P–spline model, MRF, r=12, MSE=0.042 e)
P–spline model, 2d P–spline, r=13, MSE=0.021

2.4 Simulation Study
51
0
200
400
600
800
1000
−9
−7
−5
g_0(t),a=b=0.001
iteration
β1
0
200
400
600
800
1000
−10
−7
−5
g_0(t),a=b=1e−08
iteration
β1
0
200
400
600
800
1000
−12
−9
−6
g_0(t),a=−0.5,b=0
iteration
β1
0
200
400
600
800
1000
0.4
1.0
g_0(t),a=b=0.001
iteration
β13
0
200
400
600
800
1000
0.4
1.0
g_0(t),a=b=1e−08
iteration
β13
0
200
400
600
800
1000
0.4
1.0
g_0(t),a=−0.5,b=0
iteration
β13
0
200
400
600
800
1000
−1.0
0.5
f_1(x),a=b=0.001
iteration
β1
0
200
400
600
800
1000
−1.5
0.0
1.5
f_1(x),a=b=1e−08
iteration
β1
0
200
400
600
800
1000
−1.0
0.5
f_1(x),a=−0.5,b=0
iteration
β1
0
200
400
600
800
1000
0.2
0.5
f_1(x),a=b=0.001
iteration
β13
0
200
400
600
800
1000
0.2
0.5
0.8
f_1(x),a=b=1e−08
iteration
β13
0
200
400
600
800
1000
0.2
0.5
f_1(x),a=−0.5,b=0
iteration
β13
0
200
400
600
800
1000
−1.0
0.5
f_spat(s),a=b=0.001
iteration
β1
0
200
400
600
800
1000
−1.0
0.5
f_spat(s),a=b=1e−08
iteration
β1
0
200
400
600
800
1000
−1.0
0.5
f_spat(s),a=−0.5,b=0
iteration
β1
0
200
400
600
800
1000
0.5
1.5
f_spat(s),a=b=0.001
iteration
β13
0
200
400
600
800
1000
0.0
1.0
2.0
f_spat(s),a=b=1e−08
iteration
β13
0
200
400
600
800
1000
0.0
1.0
2.0
f_spat(s),a=−0.5,b=0
iteration
β13
Figure 2.6: Selected sampling paths of run r = 1 for parameters βj,1 and βj,13, j = 0, 1, spat and
diﬀerent choices for the parameters a and b of the IG(a; b) hyperpriors.

52
2. Nonparametric regression for survival data
Results: inﬂuence of hyperparameters
To investigate the second question, in particular to analyze the behavior of the Markov
chains when a and b approach zero (and the prior for the hyperparameters thus approaches
the IG(0; 0) distribution, that leads to an improper posterior), we focus on the P–spline
model with MRF–prior and a censoring level of 17% and alternatively set a = b = 0.0001,
a = b = 0.00001 and a = b = 0.00000001. We additionally run the simulation study with
a = −0.5, b = 0, i.e. uniform priors on the standard deviations τ0, τ1 and τspat that act as
smoothing parameters for the log–baseline, the nonlinear eﬀect of x and the spatial eﬀect,
respectively. Selected sampling paths of run r = 1 are exemplarily shown in Figure 2.6.
We did not face problems with mixing or convergence of Markov chains with any of these
prior distributions. An exception are the ﬁrst one or two parameters of the baseline eﬀect,
i.e. β0,1 and β0,2, corresponding to the eﬀect of small times t, where the mixing properties
are not always optimal. This can be explained by the very steep increase of the ’true’ log–
baseline, reaching to minus inﬁnity as t approaches zero whereas it is quite ﬂat elsewhere.
In this situation a global variance might not be an ideal choice. Another point may be
the usage of conditional prior proposals that usually lead to poorer mixing properties than
IWLS–proposals do. Figure 2.7 displays kernel density estimators of the posterior mean
of the variance parameters based on bτ 2
j
(r)
, r = 1, . . . , 100 for j = 0, 1, spat.
Obviously
the diﬀerent choices of the hyperparameters a and b of the inverse Gamma prior do not
seem to have much eﬀect, whereas the uniform prior on the standard deviations tends to
result in somewhat larger estimates for the variance parameters and thus in less smooth
eﬀects. The posterior distribution of the variance parameter of the spatial eﬀect is quite
robust, as the full conditional is dominated by the values of rj =rank(Kj) and β′
jKjβj at
this. Figure 2.8 displays boxplots of the logarithmic MSEs (log(MSEr), r = 1, . . . , 100),
that are computed as before. While the MSEs are quite unaﬀected by the choice of the
hyperparameters a = b of the inverse Gamma prior, the uniform prior results in a slightly
smaller MSE for g0(t), but a slightly bigger MSE for f1(x). Altogether we come to the
conclusion that (at least with this model) it does not seem to be crucial, which one of these
weakly informative priors is assumed for the variance parameters.

2.4 Simulation Study
53
0.0
0.1
0.2
0.3
0.4
0
2
4
6
8
10
variance of log−baseline effect
τ2^
Density
a=b=0.001,          µ^=.117
a=b=0.0001,        µ^=.113
a=b=0.00001,      µ^=.116
a=b=0.00000001,µ^=.110
uniform prior,       µ^=.158
0.02
0.04
0.06
0.08
0.10
0
10
20
30
40
50
60
variance of nonparametric effect of x
τ2^
Density
a=b=0.001,          µ^=.0408
a=b=0.0001,        µ^=.0400
a=b=0.00001,      µ^=.0400
a=b=0.00000001,µ^=.0401
uniform prior,       µ^=.0522
0.3
0.4
0.5
0.6
0.7
0
2
4
6
8
variance of spatial effect
τ2^
Density
a=b=0.001,          µ^=.461
a=b=0.0001,        µ^=.461
a=b=0.00001,      µ^=.460
a=b=0.00000001,µ^=.462
uniform prior,       µ^=.472
Figure 2.7:
Kernel density estimates based on bτ 2
j
(r)
, r = 1, . . . , 100 for j = 0, 1 and spat,
respectively. ˆµ denotes the mean estimated smoothing parameter.

54
2. Nonparametric regression for survival data
−3.5
−3
−2.5
−2
−1.5
−1
0.001
0.0001
1e−05
1e−08
−0.5,0
g_0
−7
−6
−5
−4
−3
0.001
0.0001
1e−05
1e−08
−0.5,0
f_1
−3.5
−3
−2.5
0.001
0.0001
1e−05
1e−08
−0.5,0
f_spat
−20
−15
−10
−5
0
0.001
0.0001
1e−05
1e−08
−0.5,0
gamma
Figure 2.8: Simulation: Comparison via boxplots of logMSEs for estimations with IG(a; b)
hyperpriors for a = b = 0.001, a = b = 0.0001, a = b = 1e −05, a = b = 1e −08 and
a = −0.5, b = 0 respectively.

2.4 Simulation Study
55
g_0
gamma
−20
−15
−10
−5
0
p−spline weibull p−spline weibull p−spline weibull
f_1
(a) Weibull hazard with α = 2
g_0
gamma
−20
−15
−10
−5
0
p−spline weibull p−spline weibull p−spline weibull
f_1
(b) linear baseline hazard
g_0
gamma
−20
−15
−10
−5
0
p−spline weibull p−spline weibull p−spline weibull
f_1
(c) bathtub–shaped baseline hazard
Figure 2.9: Simulation: model comparison via boxplots of log–MSEs.

56
2. Nonparametric regression for survival data
Weibull baseline with α = 2
−6
−4
−2
0
2
4
g_0(t)
0
1
2
3
4
t
−6
−4
−2
0
2
4
g_0(t)
0
1
2
3
4
t
linear baseline
−6
−4
−2
0
2
4
g_0(t)
0
1
2
3
4
t
−6
−4
−2
0
2
4
g_0(t)
0
1
2
3
4
t
bathtub–shaped baseline
−2
−1
0
1
2
g_0(t)
0
1
2
3
4
5
6
7
8
t
−2
−1
0
1
2
g_0(t)
0
1
2
3
4
5
6
7
8
t
Figure 2.10:
Simulation: posterior mean estimates together with 95% credible intervals for the
log–baseline eﬀects (solid line and grey shaded area) of run r, with r chosen such that MSEr(g0(t))
is the median of MSE1(g0(t)), . . . , MSE100(g0(t)) and the true log–baseline (dashed line).

2.4 Simulation Study
57
Simulation setup II
To shed some light on the question what is lost and gained by applying a P–spline model
instead of a Weibull–model in cases where the true baseline hazard is Weibull shaped and
not Weibull shaped, respectively, lifetimes Ti, i = 1, . . . , 1000 were generated according to
the hazard models
λi(t) = λ0(t) · exp(γvi + f1(xi)) = λ0(t) · exp (0.3vi + sin(xi)) ,
with v and x denoting a binary and a continuous covariate as in (2.15). The baseline
hazard λ0(t) is once chosen to be a Weibull baseline with shape parameter α = 2, i.e.
λ0(t) = α · tα−1 = 2 · t
once to be a likewise monotonic, linear, but non–Weibull hazard rate given by
λ0(t) = 0.25 + 2 · t
and once to be bathtub–shaped according to the following equation
λ0(t) =
(
0.75 · (cos(t) + 1.5) ,
t ≤2π
0.75 · (1 + 1.5),
t > 2π
i.e. the baseline hazard is assumed to be initially high, to decrease after some time and
increase again later on until the time t = 2π, from where on the hazard stays constant.
Such bathtub–shaped hazard rates appear quite frequently in survival time studies and
can not be comprehended with parametric approaches like the Weibull model.
While lifetimes Ti may be generated straightforward by drawing random numbers from
according Weibull distributions in the former case, i.e. Weibull distributions with shape
parameter α and scale parameter (1/ exp(0.3vi + sin(xi)))
1
α, a more elaborate simulation
technique is required for the second and third choice for the baseline hazard. Two possibil-
ities are for example given by the thinning method, a kind of rejection algorithm, where a
dominating hazard rate is required (see Lewis and Shedler, 1979) and the inversion method,
that is applicable in cases where the cumulative baseline hazard Λ0(t) and its inverse Λ−1
0 (t)
may at least be evaluated numerically (see e.g. Devroye, 1986 and Bender et al., 2005).

58
2. Nonparametric regression for survival data
With our simulation we used the inversion method, where lifetimes Ti are generated as
follows
Ti = Λ−1
0 (−log(Ui) exp(−0.3vi −sin(xi))) ,
with Ui randomly drawn from a standard uniform distribution, i.e. Ui ∼U[0, 1]. As before
the censoring was done in a second step: We randomly selected a proportion of ca. 30% of
observations that were to be censored. Censoring variables Ci for these selected observa-
tions were then generated as i.i.d. draws from corresponding uniform U[0, Ti] distributions.
Again, keeping the predictor ﬁxed, 100 replications {T (r)
i
, C(r)
i , i = 1, ..., 1000} respec-
tively {(t(r)
i , δ(r)
i ), i = 1, ..., 1000}, r = 1, ..., 100 of censored survival times were generated
with each of the three baseline hazards. Estimation was done with a cubic P–spline prior
with 20 equidistant knots for the log–baseline eﬀect g0(t) and with a Weibull model with
a GA(0.01; 0.01)–prior on α as described in (2.11), respectively. A cubic P–spline prior
with 20 knots was also assumed for the nonparametric eﬀect of x and a diﬀuse prior was
assumed for the ﬁxed eﬀect of v.
Results: P–spline model versus Weibull model
The MSEs were calculated as described above and Figure 2.9 displays boxplots of the log-
arithmic MSEs. As before with the comparison between P–spline models and p.e.m.s the
MSEs of f1 and γ corresponding to the nonparametric eﬀect of the continuous covariate x
and the ﬁxed eﬀect of the binary covariate v are barely aﬀected by the choice of the prior
for the baseline hazard. However, as was to be expected the MSE of the log–baseline
eﬀect g0(t) is smaller with the Weibull model in the case where the true baseline hazard
has a Weibull structure (Figure 2.9a)), but the MSE is smaller with the P–spline model in
case of λ0(t) = 0.25 + 2 · t and the bathtub–shaped baseline hazard (Figure 2.9 b) and c)).
Estimated log–baseline hazards of replication r, with r chosen such that MSEr(g0(t)) is
the median of MSE1(g0(t)), . . . , MSE100(g0(t)) are displayed in Figure 2.10. Concerning
the simulation where the true baseline hazard has an exact Weibull structure, Figure 2.10
reveals that the Weibull model yields very good results for ˆg0(t). The cubic P–spline model
also yields quite satisfactory results for the most part, but does not reﬂect the steep increase
at the beginning (note that g0(0) = −∞with Weibull hazard rates), which is the main rea-
son for the discrepancy in MSE when compared to the Weibull model. Bayesian P–splines

2.5 Application
59
with locally adaptive variances as developed in the context of generalized additive models
in Lang and Brezger (2004) for functions with changing curvature (and highly oscillating
functions) might provide a solution. Here the global variance parameters τ 2
j in equation
(2.9) are replaced by local variances τ 2
j /δjm, where the weights δjm are additional hyperpa-
rameters. Regarding the linear non–Weibull shaped baseline hazard (λ0(t) = 0.25 + 2 · t),
results are contrary to those the simulation with Weibull structure yields. While the cubic
P–spline model reﬂects the shape of the log–baseline satisfactorily, the true shape can by
deﬁnition not be reﬂected correctly by the Weibull model, which heavily underestimates
the log–baseline for very small values of t. The bathtub–shaped baseline is again reﬂected
rather suﬃciently by the P–spline model, but also this structure can not at all be retrieved
with a Weibull model, which suggests a largely ﬂat baseline hazard with an increased risk
for very small values of t.
Conclusion
Altogether we come to the conclusion that the choice of the prior for the baseline hazard
does not seem to be very important in cases where the only interest is to gain information
on time–constant eﬀects of covariates. However, in cases where the baseline hazard is of
interest, we do not recommend to use a Weibull model since it is quite restrictive and only
outperforms the P–spline model in cases where the baseline hazard actually is Weibull
shaped. A ﬂexible estimation becomes even more important in cases where time–varying
eﬀects of covariates are to be examined.
2.5
Application
To illustrate our methods we present three applications to complex data sets with slightly
diﬀerent requirements, with spatial information being given for the last data set only. The
examples arise from diﬀerent ﬁelds, namely from the ﬁelds of credit risk, insurance and
biometrics.
Unless otherwise noted:
• time–varying as well as nonparametric eﬀects of continuous covariates are modelled

60
2. Nonparametric regression for survival data
by cubic P–splines with 20 knots,
• diﬀuse priors are assumed for ﬁxed eﬀect parameters,
• MRF priors are assumed for structured spatial eﬀects,
• unstructured (uncorrelated) random eﬀects are assumed to be i.i.d. Gaussian with
mean zero,
• the parameters of IG(a; b) hyperpriors for variance parameters are set to a = b =
0.001.
2.5.1
Overdraft credit risk
Our ﬁrst application is on overdraft credit data from a Swiss bank. The data comprises
information on the monthly account movements of 2891 debtors (companies) with date
of ﬁrst borrowing within the observation period, i.e. between June, 1999 and June, 2004.
Besides the date when the credit was ﬁrst granted (date), the observed credit duration
ti and the external covariate ”rate of unemployment” (unempl), the following continuous,
monthly varying covariates are given:
• tvb: transaction volume (receipts of payments, credit items etc.)/borrowings (aver-
aged over 5 months, restricted to values between 0 and 20)
• ndtl: number of days with transgressed credit limit
The question of interest is to analyze the inﬂuence of these covariates on the risk of default,
i.e. the risk that a debtor cannot repay his credit. There are only 69 (ca. 2.4%) defaults
observed, whereas 2109 credits (ca. 73%) are still existing at the end of the observation
period in June 2004. The remaining 713 credits (ca. 25%) are either repayed between
June 99 and June 2004 or sold to another bank. It is unknown which case is true and we
consider these 713 observations as well as the 2109 observations, where credits were still
existing in June 2004 as right censored and deﬁne the indicator of non–censoring of debtor
i, i = 1, . . . , 3068 as follows:
δi =
(
1
default of debtor i
0
else

2.5 Application
61
Since all covariates are continuous, the hazard rate λi(t) is modelled as follows
λi(t) = exp(g0(t) + ftvb(tvbi) + funempl(unempli) + fndtl(ndtli) + fdate(datei)),
where the log–baseline eﬀect g0(t) as well as all other eﬀects are modelled by P–splines.
Since the distribution of the number of days with transgressed credit limits is quite left–
skew, the position of the 20 knots was chosen according to quantiles in the case of fndtl.
The estimated eﬀects are shown in Figure 2.11. It can be concluded that the log–baseline
hazard rate is highest in the ﬁrst months after a credit is ﬁrst granted and is decreasing
almost linearly with time. The eﬀect of the covariate transaction volume/borrowings is
u–shaped, meaning that low values near zero and high values near 20 lead to an increased
default risk. While it is quite perspicuous that debtors with a transaction volume that is
very low compared to their borrowings and a consequently low value of tvb are at a high
risk, it is less clear why the risk is increased with debtors with high values of tvb. A possible
explanation is that this eﬀect is caused by debtors that already have a bad credit history
and thus a reduced credit limit resulting in low borrowings and a therefor high value of tvb.
The eﬀect of the rate of unemployment is roughly linearly increasing, meaning that the risk
of default is rising with an increasing rate of unemployment. Furthermore we observe that
credits that were ﬁrst granted at the beginning of the observation period are at a higher
risk than credits granted in later years. This might either be due to an improved credit
risk management and a more restrictive credit policy or to the economic cycle. As was to
be expected the risk is rising with the number of days with transgressed credit limit, where
the increase is steepest in the beginning.
2.5.2
Long term care insurance
As a further illustration, we analyze data on survival time after entering long term care in-
surance (LTC) from a German private insurance company. The data was recorded between
April 1, 1995, when compulsory LTC insurance was introduced by the German government,
and December 31, 1998. It contains information on 5603 recipients of beneﬁts from LTC
insurance. This data set has already been analyzed by Czado and Rudolph (2002), and
more details on the data set are given there. In a ﬁrst step, they analyzed the data with a
conventional Cox model with ﬁxed eﬀects of covariates and products of covariates. After

62
2. Nonparametric regression for survival data
a) log–baseline eﬀect g0(t)
−8
−6
−4
−2
0
2
4
6
0
10
20
30
40
50
60
t
b) eﬀect of tvb
c) eﬀect of unempl
−8
−6
−4
−2
0
2
4
6
0
5
10
15
20
transaction volume/borrowings
−8
−6
−4
−2
0
2
4
6
1.5
2
2.5
3
3.5
4
4.5
rate of unemployment
d) eﬀect of date
e) eﬀect of ndtl
−8
−6
−4
−2
0
2
4
6
Jan 00
Jan 01
Jan 02
Jan 03
Jan 04
date
−8
−6
−4
−2
0
2
4
6
0
10
20
30
number of days with transgressed limit
Figure 2.11: Overdraft credit risk: posterior means together with pointwise 80% and 95%
credible intervals

2.5 Application
63
careful model diagnosis (and the inclusion of two dummy–coded variables for modelling
deviations from linear eﬀects) they extended their Cox model to a model with time–varying
eﬀects, which were modelled through 0–1 step functions. Our analysis is based on their
ﬁnal model – CR model for short. The covariates that are included are sex of claimant
(1=female, 0=male) and the following time–dependent covariates:
age(t) = age of claimant when a state transition occurs at time t,
nh(t) =
(
1
care in a nursing home at time t
0
care at home at time t
leveli(t) =
(
1
care at level i at time t, i = 2, 3
0
else,
with level1(t) as the reference category. Transition times between care levels and care
required (at home or in a nursing home) and dates of death or right–censoring are given
in day units. The three levels of care (and beneﬁts) are deﬁned as follows:
• Level 1: Care level 1 is reserved to persons in considerable need of LTC. They would
at least once a day require help for at least two activities in areas of personal hygiene,
nutrition or mobility. They would also need help several times a week with household
chores. Care level 1 can only be granted if the applicant needs help for at least 90
minutes a day, including 45 minutes of basic care.
• Level 2: Care level 2 is ear–marked for persons in severe need of LTC. They need
help at least three times a day with personal hygiene, eating or getting around. In
addition, they need help several days a week in housekeeping. In care level 2 the time
of help required must be at least 3 hours a day, of which 2 hours must be needed for
basic care.
• Level 3: Care level 3 is reserved to persons in extreme need of care. They require
round–the–clock help every day, as well as household help several times a week. Care
level 3 demands that the applicant needs at least 5 hours help a day, including a
minimum of 4 hours of basic care.

64
2. Nonparametric regression for survival data
BPH
CR
mean
std. dev.
mean
std. dev.
level2
0.81
0.07
0.81
0.07
level3
1.71
0.07
1.75
0.07
sex · nh
-0.42
0.10
-0.44
0.10
level2 · nh
-0.33
0.15
-0.33
0.14
level3 · nh
-0.66
0.14
-0.67
0.14
Table 2.1: LTC data: posterior means and standard deviations for ﬁxed eﬀects
The exact date of ﬁrst receipt of beneﬁts is given for every claimant. In most cases this
date is prior to April 1, 1995, i.e. most of the observations are left truncated (ca. 70%).
Furthermore, about 60% of the observations are right censored.
As a start we apply a Bayesian multiplicative proportional hazard (BPH for short)
model λ(t) = exp(η(t)) with predictor
η(t)
=
g0(t) + γl2 · level2(t) + γl3 · level3(t) +
fage(age) + fsex(age) · sex + fnh(age) · nh(t) +
γsnh · (sex · nh(t)) + γl2nh · (level2(t) · nh(t)) + γl3nh · (level3(t) · nh(t))
Results for ﬁxed eﬀects are given in Table 2.1. The log–baseline g0(t) and the main eﬀect of
age as well as the age–dependent eﬀects fsex(age) of sex and fnh(age) of nh are displayed in
Figure 2.12. Our results for the age–independent eﬀects are highly comparable to those of
the CR model. Although diﬀerences concerning modelling of the age–dependent functions
lead to slightly diﬀering results, the age–dependent eﬀects are as well quite similar for the
most part.
We conclude from our results that the hazard rate is increased in the ﬁrst three to four
years of receiving beneﬁts. The hazard is also increased for claimants receiving more care
(Level 2 and Level 3), but these main eﬀects decrease by ca. 40% for claimants living in
a nursing home. Furthermore, care in a nursing home seems to decrease the hazard rate
with young people, but increase the hazard risk in the case of elderly claimants. Compared
to male claimants, female claimants living in a nursing home have a lower hazard. The
main eﬀect of age increases almost linearly, while the interaction with sex is quite small.

2.5 Application
65
−1
0
1
2
g_0(t)
0
5
10
15
20
25
t
(a) BPH
−2
−1
0
1
2
age−dependent effects
0
10
20
30
40
50
60
70
80
90 100 110
age
f_age
f_nh
f_sex
(b) BPH
−2
−1
0
1
2
age−dependent effects
0
10
20
30
40
50
60
70
80
90 100 110
age
f_age
f_nh
f_sex
(c) CR
Figure 2.12: LTC data: posterior mean together with 80% and 95% credible intervals of the
centered log–baseline eﬀect (a), main eﬀect of age (centered) and age–dependent eﬀects of
nh and sex for BPH (b) and CR (c)

66
2. Nonparametric regression for survival data
mean
std. dev.
sex · nh
-0.42
0.10
level2 · nh
-0.33
0.14
level3 · nh
-0.59
0.14
Table 2.2: LTC data, BNPH model: posterior means and standard deviations for ﬁxed
eﬀects
The latter is comparable with the ﬁxed eﬀect interaction (including two steps) of the CR
model only for age over 50 years.
Since Czado and Rudolph found out that the eﬀect of care level is time–dependent, we
modify our PH–model to a nonproportional hazard (BNPH for short) model with predictor
η(t)
=
g0(t) + gl2(t) · level2(t) + gl3(t) · level3(t) +
fage(age) + fsex(age) · sex + fnh(age) · nh(t) +
γsnh · (sex · nh(t)) + γl2nh · (level2(t) · nh(t)) + γl3nh · (level3(t) · nh(t)).
In contrast to the global log–baseline hazard rate estimated with the BPH model the
log–baseline hazard rate g0(t) and the eﬀect gl2(t) of level2 are now more or less time–
constant (compare Figure 2.13 a) and b)). Note that g0(t) is centered about zero, while
gl2(t) ≈const. = 0.74. This means that the time–variation in the eﬀect of level2(t) of the
CR model cannot be detected. The increased hazard for level3(t) for smaller t (Figure
2.13 c)) corresponds to a similar ﬁnding of the initial CR. A possible interpretation is that
this eﬀect is caused by individuals which are already in a bad health state and therefore
need level 3 care immediately at the beginning of LTC. The BNPH model with time–
varying eﬀects of level2 and level3 can be interpreted as a model with three separate
baseline eﬀects g0(t), g0(t) + gl2(t), g0(t) + gl3(t) for claimants needing care of level 1,2
or 3, respectively. The corresponding estimated curves are displayed in Figure 2.13 d). As
can be gathered form Figure 2.13 e) and Table 2.2 the remaining eﬀects are quite similar
to those the BPH model yields.

2.5 Application
67
−2
−1
0
1
2
3
4
g_0(t)
0
5
10
15
20
25
t
(a)
−2
−1
0
1
2
3
4
g_l2(t)
0
5
10
15
20
25
t
(b)
−2
−1
0
1
2
3
4
g_l3(t)
0
5
10
15
20
25
t
(c)
−2
−1
0
1
2
3
4
log−baseline effects
0
5
10
15
20
25
t
level 1
level 2
level 3
(d)
−2
−1
0
1
2
3
4
age−dependent effects
0
10
20
30
40
50
60
70
80
90 100 110
age
f_age
f_nh
f_sex
(e)
Figure 2.13: LTC data, BNPH model: a)–c) posterior means together with 80% and 95%
credible intervals of time–dependent eﬀects, d) posterior means of log–baseline eﬀects for
claimants needing care level 1, 2 and 3, respectively, d) posterior means of age–dependent
eﬀects

68
2. Nonparametric regression for survival data
2.5.3
Waiting times to CABG
As a third illustration we apply our methods to data from a study in London and Essex that
aims to analyze the eﬀects of area of residence and further individual speciﬁc covariates on
waiting times to coronary artery bypass graft (CABG). The data comprise observations for
3015 patients with deﬁnite coronary artery disease who were referred to one cardiothoracic
unit from ﬁve contiguous health authorities. Waiting times from angiography to CABG
are given in days. Covariates are, among others, sex, age (in years), number of diseased
vessels (1, 2, 3), and the area of residence (one of 488 electoral wards).
The data were previously analyzed by Crook et al. (2003) who classiﬁed waiting times
in months and applied discrete–time survival methodology as described for example in
Fahrmeir and Tutz (2001, chap. 9). Here we apply continuous–time geoadditive survival
models, with waiting times given in days as in the original data set. We analyzed and
compared a hierarchy of models, with model comparison based on the deviance information
criterion (DIC), developed in Spiegelhalter et al. (2002). Whilst a log–baseline eﬀect is
included in any model, covariate eﬀects are only added gradually.
The (log–)baseline
prior was assumed as a (log–)piecewise exponential model with grid length △= 50 days
and, alternatively, as a cubic P–spline model with 20 knots. Table 2.3 gives values for ﬁt
(deviance) and complexity (eﬀective number of parameters pD) for a selected number of
models. A comparison between the two baseline speciﬁcations shows that the complexity
is quite alike, whereas the ﬁt is essentially better with the P–spline model than with the
p.e.m. The ranking of the models is the same as in Crook et al. (2003).
In the following we will present detailed results for the best models in terms of DIC.
Models 7 and 8 correspond to a continuous–time model with hazard rate
λ(t) = exp(g0(t) + fage(age) + fspat(ward) + γ1sex + γ2dv2 + γ3dv3),
where g0(t) is the log–baseline rate, fage(age) is the nonlinear eﬀect of age and fspat(ward)
is the structured spatial eﬀect. The remaining covariates are dummy–coded: sex = 1 for
female, and sex = 0 for male, dv2 = 1 if the number of diseased vessels equals 2, dv2 = 0
else, and dv3 = 1 if the number of diseased vessels equals 3, dv3 = 0 else. For comparison
we also estimated model 8 with a Weibull prior (2.11) for the baseline hazard. The DIC
of this Weibull model is 15273, composed of a deviance of 15190 and pD=42. Accordingly
the p.e.m. and the P–spline–model yield a lower DIC in spite of being less parsimonious.

2.5 Application
69
Table 2.3: Model comparison based on the DIC
P–spline–model
p.e.m.
model speciﬁcation
dev.
pD
DIC
dev.
pD
DIC
1
g0(t)
15607
13
15632
15777
12
15800
2
g0(t)+R
15553
38
15630
15722
38
15798
3
g0(t)+MRF+R
15523
47
15616
15693
44
15782
4
g0(t)+MRF
15532
40
15611
15705
38
15780
5
g0(t)+fage+sex+dv2+dv3
15069
20
15108
15234
19
15273
6
g0(t)+fage+sex+dv2+dv3+R
14934
79
15092
15085
83
15251
7
g0(t)+GRF+fage+sex+dv2+dv3
15017
33
15082
–
–
–
8
g0(t)+MRF+fage+sex+dv2+dv3
14967
56
15079
15125
58
15241
9
g0(t)+MRF+fage+sex+dv2+dv3+R
14943
68
15078
15097
71
15240
10
g0(t)+MRF+fage+sex+g1(t)dv2+g2(t)dv3
14945
64
15073
15107
65
15237
Since the DIC is not improved substantially by adding a random (unstructured) spatial
eﬀect (indicated by the letter R in Table 2.3) we do not discuss model 9 in detail.
Since the distribution of the values of age is quite skew, it would be an interesting
alternative to choose a P–spline prior with knot positions according to quantiles, but we
used equidistant knots here, which is our standard choice. The spatial eﬀect fspat(ward)
is modelled through a MRF prior.
In the case of the P–spline model we alternatively
modelled the spatial eﬀect through a GRF prior with 100 knots (model 7). Although this
model is more parsimonious, the DIC is greater than with a MRF prior due to a greater
deviance. Since the data augmentation that has to be accomplished for the p.e.m. results
in an ”observation number” of more than 30000, a GRF prior would lead to a computation
time of several days, which is not very viable.
The nonproportional hazard model 10, which has the lowest DIC of all models we
compared, is a modiﬁcation of the geoadditive proportional hazard rate model 8, where
the ﬁxed eﬀects γ2 and γ3 of dv2 and dv3 are replaced by time varying eﬀects.
Inverse Gamma priors IG(0.001; 0.001) were routinely assumed for the variances, but
we also speciﬁed uniform priors on standard deviations for comparison. The results were
quite alike (similar values of DIC and estimated eﬀects), but uniform priors tend to lead to a

70
2. Nonparametric regression for survival data
Table 2.4: Posterior mean estimates and standard deviations for the ﬁxed eﬀects on time to
CABG
eﬀect
P–spline m., GRF
P–spline m., MRF
p.e.m., MRF
Weibull m., MRF
sex
-0.04
(0.08)
-0.05
(0.08)
-0.04
(0.08)
-0.04
(0.08)
dv2
1.48
(0.10)
1.49
(0.10)
1.50
(0.10)
1.48
(0.10)
dv3
1.79
(0.09)
1.81
(0.09)
1.82
(0.09)
1.79
(0.10)
slightly better ﬁt coming along with a somewhat larger number of eﬀective parameters pD.
However, in contrast to our simulation study, we sometimes faced problems with mixing
of Markov chains with IG(ε, ε) priors with very small ε’s (like ε = 0.00000001) in the case
of the age eﬀect, which is presumably due to the skew distribution of the values of age
(i.e. the small number of young patients).
Table 2.4 contains estimation results for the ﬁxed eﬀects in models 7 and 8. While
the eﬀect of sex is nonsigniﬁcant, the eﬀects of two or three diseased vessels are clearly
signiﬁcant and show that waiting times are decreasing with increasing number of vessels.
These results correspond to the ﬁndings of Crook et al. (2003). The nonparametric baseline
eﬀects in Figure 2.14 show an initially high, but strongly decreasing chance of CABG
immediately after diagnosis, followed by a slow increase between 150 and 450 days. Later,
the chance of being operated decreases. The overall pattern is similar to the results in
Crook et al. (2003), obtained with a discrete–time model. However, with the P–spline
prior we get a distinctly smoother curve. The Weibull model also yields a sharp decline
in the ﬁrst days after diagnosis, however, due to the monotonicity of a Weibull baseline,
the slow increase between 150 and 450 days can not be detected. The eﬀect of age (Figure
2.14) is almost constant between 40 and 80 years and does not have signiﬁcant inﬂuence
on the waiting time. Also, the estimates under a piecewise exponential, a cubic P–spline
and a Weibull baseline prior are visually indistinguishable – regardless of which prior is
chosen for the structured spatial eﬀect.
The maps in Figure 2.15 show the estimates for the structured spatial eﬀects and give
an impression of the spatially varying chance of CABG with green (red) areas indicating
an increased (decreased) eﬀect. Again, the estimates under a piecewise exponential and
a cubic P–spline baseline prior are visually nearly indistinguishable in the case of a MRF

2.5 Application
71
P–spline
MRF
−15
−13
−11
−9
−7
−5
g_0(t)
0
250
500
750
1000
t
−3
−2
−1
0
1
f_age(age)
20
30
40
50
60
70
80
90
age
p.e.m.
MRF
−15
−13
−11
−9
−7
−5
g_0(t)
0
250
500
750
1000
t
−3
−2
−1
0
1
f_age(age)
20
30
40
50
60
70
80
90
age
P–spline
GRF
−15
−13
−11
−9
−7
−5
g_0(t)
0
250
500
750
1000
t
−3
−2
−1
0
1
f_age(age)
20
30
40
50
60
70
80
90
age
Weibull
MRF
−15
−13
−11
−9
−7
−5
g_0(t)
0
250
500
750
1000
t
−3
−2
−1
0
1
f_age(age)
20
30
40
50
60
70
80
90
age
Figure 2.14:
Posterior mean estimate for the (log–)baseline eﬀect including the intercept term
(left panel) and the (centered) eﬀect of age on time to CABG (right panel) together with 80%
and 95% credible intervals

72
2. Nonparametric regression for survival data
P–spline model, GRF
P–spline model, MRF
−0.5
0.5
0
−0.5
0.5
0
Figure 2.15:
Posterior mean estimates of the structured spatial eﬀect on time to CABG; the
estimates under the p.e.m. with a MRF prior are visually indistinguishable from those of the
P–spline model with MRF prior, and are therefore not shown here
P–spline model, GRF
P–spline model, MRF
Figure 2.16:
Posterior probabilities of the structured spatial eﬀects, with white (black) areas
indicating that at least 80% of the sample estimates were positive (negative)

2.5 Application
73
P–spline model
p.e.m.
−2
−1
0
1
2
3
4
5
0
100
200
300
400
500
600
700
800
900
1000
1100
t
dv1
dv2
dv3
−2
−1
0
1
2
3
4
5
0
100
200
300
400
500
600
700
800
900
1000
1100
t
dv1
dv2
dv3
Figure 2.17: (log–)baseline eﬀects on time to CABG: posterior mean estimates for 1 diseased
vessel (dv1), 2 diseased vessels (dv2) and 3 diseased vessels (dv3)
prior. Also a Weibull prior yields virtually the same result (not shown). Predictably, the
GRF prior results in a smoother estimated spatial eﬀect than the MRF prior does, but
besides that the results are quite alike. Areas with increased chances are Chelmsford and
Malden in North Essex, while in areas around Harlow in North Essex and Walthamstow
and Chingford in North East London chances are lower, that means patients have to wait
longer for surgery. The maps in Figure 2.16 show posterior probabilities of these spatial
eﬀects.
White (black) areas indicate that at least 80 % of the sample estimates were
positive (negative). Remaining grey areas are considered as ’nonsigniﬁcant’. Striped areas
denote wards, where no patient was observed.
Model 10 with time–varying eﬀects g1(t) and g2(t) of dv2 and dv3 can be interpreted as
a model with three separate baseline eﬀects g0(t), g0(t)+g1(t), g0(t)+g2(t) for patients with
one, two or three diseased vessels, respectively. The corresponding estimated curves are
displayed in Figure 2.17 and indicate that the proportional hazards assumption is violated,
because the baseline eﬀect of patients with three diseased vessels crosses the two other
curves.

74
2. Nonparametric regression for survival data
Diﬀerent choices for hyperpriors
In the following we exemplary present some additional results of model 8 that were obtained
with other choices of IG(a; b) priors. In addition to our standard choice a = b = 0.001 we
set a = b = 1e −08 and a = −0.5, b = 0 (i.e. uniform prior on the standard deviation).
Figure 2.18 exemplarily shows sampling paths of the ﬁrst and 19th parameter of each
vector βj, j = 0, age, spat corresponding to the log–baseline eﬀect, the eﬀect of age and the
spatial eﬀect, respectively. Independently of the choice of the prior for the hyperparameters
the mixing is not optimal for the ﬁrst parameters of the parameter–vector β0 corresponding
to the log–baseline eﬀect. In accordance with our simulation study this might be due to the
usage of conditional prior proposals and the assumption of a global variance, since the eﬀect
is steeply dropping in the ﬁrst 100 days, but comparatively ﬂat elsewhere. Apart from that
we did not face problems with mixing or convergence in the case of IG(0.001; 0.001) and
IG(−0.5; 0) priors. However, in the case of an IG(1e−08; 1e−08) prior mixing properties
are poor for the ﬁrst parameters of the eﬀect of age, where we have sparse data since there
is only a very small number of young patients that suﬀer from coronary artery diseases. As
shown in Figure 2.19 a) the estimated log–baseline eﬀects g0(t) are not inﬂuenced by the
choice of the hyperprior. The same applies to the ﬁxed eﬀects as well as the spatial eﬀect.
Figure 2.19 b) however reveals a much smoother eﬀect with the IG(1e −08; 1e −08) prior
compared to the eﬀects the other two choices for the hyperpriors yield. But since credible
intervals are quite large, each estimated eﬀect is within the 95% credible interval of each
other estimated eﬀect of age.
We conclude that the results are in general quite insensitive regarding the choice of
non–informative hyperpriors. However, in situations where data are sparse IG(a; b) priors
with a and b close to zero might lead to poor mixing and are therefore not recommended.
2.6
Conclusion
Spatial extensions of statistical models for analyzing survival data will be of increasing
relevance because spatial small–area information is often available. Assessment of spatial
eﬀects on hazard or survivor functions is not only of interest in its own but can be quite
useful for detecting unobserved covariates which carry spatial information. In this chapter,

2.6 Conclusion
75
0
200
400
600
800
1000
5
7
9
g_0,a=b=0.001
iteration
β1
0
200
400
600
800
1000
5
7
9
g_0,a=b=1e−08
iteration
β1
0
200
400
600
800
1000
5
7
9
g_0,a=−0.5,b=0
iteration
β1
0
200
400
600
800
1000
−3
−1
g_0,a=b=0.001
iteration
β19
0
200
400
600
800
1000
−3
−1
g_0,a=b=1e−08
iteration
β19
0
200
400
600
800
1000
−3
−1
g_0,a=−0.5,b=0
iteration
β19
0
200
400
600
800
1000
−10
−4
0
f_age,a=b=0.001
iteration
β1
0
200
400
600
800
1000
−6
−2
f_age,a=b=1e−08
iteration
β1
0
200
400
600
800
1000
−15
−5
f_age,a=−0.5,b=0
iteration
β1
0
200
400
600
800
1000
−0.2
0.6
1.2
f_age,a=b=0.001
iteration
β19
0
200
400
600
800
1000
0.0
0.6
f_age,a=b=1e−08
iteration
β19
0
200
400
600
800
1000
−0.5
1.0
f_age,a=−0.5,b=0
iteration
β19
0
200
400
600
800
1000
−1.5
0.0
1.5
f_spat,a=b=0.001
iteration
β1
0
200
400
600
800
1000
−1.0
0.5
f_spat,a=b=1e−08
iteration
β1
0
200
400
600
800
1000
−1.0
0.5
f_spat,a=−0.5,b=0
iteration
β1
0
200
400
600
800
1000
−1.0
0.0
1.0
f_spat,a=b=0.001
iteration
β19
0
200
400
600
800
1000
−1.0
0.5
f_spat,a=b=1e−08
iteration
β19
0
200
400
600
800
1000
−1.0
0.5
f_spat,a=−0.5,b=0
iteration
β19
Figure 2.18: Selected sampling paths for parameters βj,1 and βj,19, j = 0, age, spat and diﬀerent
choices for the parameters a and b of the IG(a; b) hyperpriors.

76
2. Nonparametric regression for survival data
−2
−1
0
1
2
3
g_0(t)
0
200
400
600
800
1000
1200
t
a=b=0.001
a=b=1e−08
a=−0.5,b=0
(a)
−1
−.5
0
.5
f_age
20
40
60
80
100
age
a=b=0.001
a=b=1e−08
a=−0.5,b=0
(b)
Figure 2.19: Estimated log–baseline eﬀects g0(t) and eﬀects of age fage with diﬀerent
speciﬁcations of IG(a; b) hyperpriors.
we have developed a ﬂexible class of nonparametric geoadditive survival models within a
uniﬁed Bayesian framework for modelling and inference. Model choice is an important
area of ongoing research. A comparison of competing proposals in the context of ﬂexible
Bayesian event history models will be of considerable importance.

Chapter 3
Relative Survival Analysis
3.1
Introduction
Many clinical studies aim at identifying prognostic factors for disease speciﬁc mortality.
However, data on speciﬁc causes of death is often not available or not reliable (Percy et
al. (1981)) and thus it is not possible to diﬀerentiate between cases of death that are
actually related to the disease of interest and those cases of death that are related to
other causes that are independent of this disease. Since the composition of patients in
a clinical study usually is quite heterogenous concerning covariates like age (which is the
main inﬂuencing factor for natural mortality), the natural mortality risk may diﬀer heavily
between patients. Thus it might very well be the case that a higher number of deaths
is observed with older people although a disease is more likely to be lethal with younger
people. In such situations the Cox model is not suitable since therewith it is not possible to
distinguish whether a variable like sex or age has an eﬀect on disease speciﬁc mortality, on
natural mortality or on both. Consequently this model will deliver eﬀects that represent
some mixture of the eﬀects on natural and disease related mortality and may therefore be
misleading regarding the identiﬁcation of prognostic factors. Moreover, comparisons of the
results from diﬀerent population–based prognostic studies are diﬃcult due to diﬀerences
in the natural mortality of the populations. A remedy to this problem is provided by a
relative survival analysis which allows for a correction for the eﬀect of other independent
causes of death by using the natural mortality in the underlying population as a reference.
Several models for relative survival analysis in a frequentist setting have been discussed

78
3. Relative Survival Analysis
in the literature.
Esteve et al. (1990) assume that the observed hazard for total mor-
tality is the sum of two hazards, namely the expected, natural mortality hazard and a
disease related mortality hazard. Whereas the ﬁrst component is obtained from exter-
nal sources the disease related hazard is estimated parametrically assuming a piecewise
constant baseline eﬀect and time–constant ﬁxed eﬀects of covariates. This approach was
extended by Bolard et al. (2001) and Giorgi et al. (2003) by allowing for time–varying
eﬀects, i.e. dropping the proportional hazards assumption. Bolard et al. (2001) consider
time–by–covariate interactions originally proposed by Cox (1972) as well as piecewise pro-
portional hazards, developed by Moreau et al. (1985) for crude survival analysis.
The
drawbacks of these methods are that temporal variations in the eﬀects of covariates are
limited to pre–speciﬁed parametric forms of interaction functions and step–functions on
pre–speciﬁed time intervals, respectively. A more ﬂexible method is proposed by Giorgi et
al. (2003) who assume quadratic B–splines with two inner knots for the baseline eﬀect as
well as for time–varying eﬀects of covariates. In the Bayesian approach we present here
we extend the model of Esteve et al. (1990) by modelling the disease related hazard with
a ﬂexible geoadditive predictor that may include a log–baseline eﬀect, nonlinear eﬀects of
continuous covariates and time–varying eﬀects modelled by P–splines, as well as a spatial
eﬀect, random eﬀects and the usual ﬁxed eﬀects.
The rest of this chapter is organized as follows. In Section 3.2 we describe models,
likelihood and priors for unknown functions and parameters.
Some comments on the
inference via MCMC are given in Section 3.3. To illustrate our approach we present an
application to data on the survival of women suﬀering from breast cancer in Section 3.4.
Reliability of our approach is veriﬁed in Section 3.5 by means of a simulated data set with
known risk proﬁle.
3.2
Model, likelihood and priors
Consider right–censored survival data as described in Subsection 2.2.1 in which Ti now
denotes survival time of observation i until death of any cause, ti denotes the observed
survival time and δi denotes the censoring indicator. Following Esteve et al. (1990) we as-
sume that the hazard rate for total mortality λi(t, ai, covi) := λi(t) at time t after diagnosis
of an individual i with age ai at diagnosis and a vector of covariates covi = (zi, xi, si, vi)

3.2 Model, likelihood and priors
79
(possibly including age) is deﬁned as the following sum of two hazards:
λi(t, ai, covi) := λi(t)
=
λe
i(ai + t, covsub
i
) + λc
i(t, covi)
(3.1)
=
λe
i(ai + t, covsub
i
) + exp (ηi(t, covi))
The ﬁrst summand λe
i(ai + t, covsub
i
) represents the expected hazard for natural mortality
in a population and is obtained from mortality tables using external sources, i.e. there are
no unknown parameters involved here. This component depends only on age at time t after
diagnosis (i.e. ai + t) and covsub
i
, a subvector including those covariates in covi mortality
tables account for (usually sex and period). The second summand λc
i(t, covi) is the disease
related mortality hazard rate which is estimated from the data at hand. This component
is modelled by a ﬂexible, possibly geoadditive predictor as in (2.4). To simplify notation
the dependence on covsub
i
and covi, respectively will be suppressed in the following, i.e. we
deﬁne λe
i(ai + t, covsub
i
) := λe
i(ai + t) and λc
i(t, covi) := λc
i(t). Depending on what kind of
covariates are given in covi, the predictor may be composed of the following summands:
ηi(t, covi) := ηi(t) = g0(t) +
p
X
j=1
gj(t)zij +
q
X
j=1
fj(xij) + fspat(si) + v′
iγ + bgi,
(3.2)
where g0(t) = log{λ0(t)} is the (disease related) log–baseline hazard, gj(t) are time–varying
eﬀects of covariates zj, fj(xj) is the nonlinear eﬀect of a continuous covariate xj, fspat(si)
is the (structured) eﬀect of a spatial covariate s, γ is the vector of linear eﬀects and bg is
a unit– or group–speciﬁc frailty or random eﬀect (see Subsection 2.2.1 for a more detailed
description).
Once more, for a interpretation of equation (3.1) one may say that the natural mortality
hazard λe
i covers the basic mortality risk a population is exposed to and the disease related
hazard λc
i models the excess mortality risk that patients are exposed to beyond the basic
risk due to the disease they suﬀer from. From a statistical point of view λe
i is an additive
oﬀset.
Under the assumption about noninformative censoring the likelihood is given by
L
=
n
Y
i=1
(λi(ti))δi · exp

−
Z ti
0
λi(u)du


80
3. Relative Survival Analysis
Inserting (3.1) results in
L
=
n
Y
i=1
(λe
i(ai + ti) + λc
i(ti))δi exp

−
ti
Z
0
(λe
i(ai + u) + λc
i(u)) du


=
n
Y
i=1
(λe
i(ai + ti) + λc
i(ti))δi exp

−
ti
Z
0
λc
i(u)du

exp

−
ti
Z
0
λe
i(ai + u)du

,(3.3)
where the last factor does not depend on the parameters to be estimated.
Hence the
following proportionality holds
L
∝
n
Y
i=1
(λe
i(ai + ti) + λc
i(ti))δi exp

−
Z ti
0
λc
i(u)du

.
(3.4)
This formula only diﬀers from the likelihood of a crude survival model given in (2.5) by
the term λe
i(ai + ti).
Again, for deﬁning priors and developing posterior analysis we can rewrite the observa-
tion model in generic matrix notation and represent the predictor η = (η1, . . . , ηi, . . . , ηn)′,
where ηi := ηi(ti), as
η = V γ + Z0β0 + . . . + Zmβm.
(3.5)
See Subsection 2.2.1 for details. Then, to complete the Bayesian model formulation priors
for parameters and functions are assumed as described for the crude survival analysis in
Subsection 2.2.2, i.e. we assume diﬀuse priors for ﬁxed eﬀect parameters, i.i.d. Gaussian
priors for uncorrelated random eﬀects, P–splines for the baseline eﬀect, nonparametric ef-
fects of continuous covariates and time–varying eﬀects, Markov random ﬁeld (MRF) priors,
two–dimensional tensor product P–spline priors, or Gaussian random ﬁeld (GRF) priors
for structured spatial eﬀects and inverse Gamma hyperpriors for all variance components.
3.3
Markov chain Monte Carlo inference
As before in Section 2.3 let β = (β′
0, ..., β′
m)′ denote the vector of all regression coeﬃcients
in the generic notation (3.5), γ the vector of ﬁxed eﬀects, and τ 2 = (τ 2
0 , ..., τ 2
m) the vec-
tor of all variance components. Full Bayesian inference is based on the entire posterior
distribution
p(β, γ, τ 2 | data) ∝L(β, γ, τ 2) p(β, γ, τ 2).

3.3 Markov chain Monte Carlo inference
81
Due to the (conditional) independence assumptions, the joint prior factorizes into
p(β, γ, τ 2) =
( m
Y
j=0
p(βj | τ 2
j )p(τ 2
j )
)
p(γ),
where the last factor can be omitted for diﬀuse ﬁxed eﬀect priors. The likelihood L(β, γ, τ 2)
is given by inserting (3.2) into (3.4). Note that the integral does not require integration
over the natural mortality hazard λe
i(ai + t) (which is ﬁx anyway), but just over the same
terms as before with the crude survival analysis, i.e. terms of the form
Ii =
Z ti
0
exp
 
g0(u) +
p
X
j=1
gj(u)zij
!
du,
where gj(t) = P βjmBm(t). As described in Section 2.3 we usually use the trapezoidal rule
to solve these integrals numerically.
Again, full Bayesian inference via MCMC simulation is based on updating full condi-
tionals of single parameters or blocks of parameters, given the rest of the data. Basically
all parameters are updated as described in Section 2.3. However, the calculation of the
means and precision matrices of the multivariate Gaussian distributions, that are used
within the IWLS–MH algorithm to approximate the posterior of the parameter vectors βj,
which correspond to the time–independent functions fj(xj), as well as spatial eﬀects βspat,
ﬁxed eﬀects γ and random eﬀects b, is slightly more complex. Suppose we want to update
βj, with current value βc
j of the chain. Then a new value βp
j is proposed by drawing a
random vector from a multivariate Gaussian distribution with precision matrix and mean
P j = Z′
jW (βc
j)Zj + 1
τ 2
j
Kj,
mj = P −1
j Z′
jW (βc
j)(˜y −˜η).
where ˜ηi = ηi(ti) −fj(xij), W (βc
j) = diag(w1, . . . , wn) is the weight matrix for IWLS with
weights
wi
=
Λc
i(ti) −λe
i(ai + ti)λc
i(ti)δi
λi(ti)2
obtained form the current state βc
j and with Λc
i(ti) =
R ti
0 λc
i(u)du. The working observations
˜yi are given by
˜yi = ηi(ti) + δiλc
i(ti)/λi(ti) −Λc
i(ti)
wi
.
See Appendix A2 for a detailed derivation of those quantities.

82
3. Relative Survival Analysis
3.4
Application
We illustrate our method by an application to data on breast cancer that was gathered in
the years from 1988 to 2002 by a cancer registry that covers the Haut–Rhin ’department’
which is located in the north-east of France, adjacent to Germany and Switzerland. This
department has 3525 km2 and 707555 inhabitants (in 1999) and is partitioned into 377
municipalities. The largest distance between the centroids of two municipalities is about
95 kms. The data set contains 3726 cases of breast cancer diagnosed between January the
1st 1988 and January the 1st 1998. There were 1235 (≈33%) deaths observed whereas
the causes of death are unknown. Observed lifetimes are given in days and range from 0
to 14 years, with a median of 6.4 years. Covariates are age at time of diagnosis (ranging
from 20.6 years to 87.1 years), date of diagnosis (ranging from 1988.0 (i.e. 01.01.1988) to
1998.0), area of residence (one of 377 municipalities) and number of metastases at the date
of diagnosis (no metastasis, one metastasis or more than one metastasis). This is part of
a data set that has been analyzed via crude survival analysis by Sauleau et al. (2006).
For comparison only we analyze the data with the crude survival model (2.3) although
this model does not account for natural mortality and is thus not appropriate to the data
at hand where causes of death are not available. Generally the speciﬁcation of the hazard
rate is given by
λi(t, covi)
=
exp(ηi(t, covi))
(3.6)
covi
=
(ai, pi, si, meta1i, meta2i),
where t is time since diagnosis and covi is the vector of covariates with ai denoting the age
of patient i at date of diagnosis pi (period), si denoting the municipality patient i resides
in and the dummy–coded covariates meta1i and meta2i denoting, whether patient i has
one metastasis and more than one metastasis, respectively.
A relative survival analysis should be more suitable and deliver better results. Therefore
we alternatively assume a composed hazard rate of the following structure
λi(t, covi)
=
λe
i(ai + t, pi + t) + exp(ηi(t, covi))
(3.7)
covi
=
(ai, pi, si, meta1i, meta2i),
where λe
i(ai + t, pi + t) is the natural mortality rate of women of age ai + t at date pi + t
as recorded in mortality tables for the Haut–Rhin department.
The second summand

3.4 Application
83
λc
i = exp(ηi(t, covi) represents the disease related hazard rate and is modelled in the same
way as the hazard rate in (3.6).
A hierarchy of models is analyzed with both approaches and compared via the deviance
information criterion (DIC). Whilst a log–baseline eﬀect g0(t) modelled by a cubic P–
spline prior with 20 knots is included in any model, covariate eﬀects are only included
gradually. Eﬀects fa(ai) and fp(pi) of continuous covariates are modelled by cubic P–splines
with 20 knots. Diﬀuse priors are assigned to the ﬁxed eﬀects γ1 and γ2 of the dummy–
coded covariates meta1 and meta2. The structured spatial eﬀect fspat(si) is modelled by a
MRF prior which is our standard choice with area–level data. An unstructured (random)
spatial eﬀect bsi is included additionally or alternatively in some of the models. Table 3.1
gives values for ﬁt and complexity of a selected number of models according to the two
components of the deviance information criterion. Model I, which contains a structured
spatial eﬀect modelled by a MRF–prior, the eﬀect of the number of metastases and the
eﬀect of age, yields a DIC of 9308 for the crude survival model with hazard rate (3.6) and
9249 for the relative survival model. Leaving out one or more of these eﬀects leads to a
larger DIC. As Table 3.1 shows the DIC is slightly reduced by the additional inclusion of a
period eﬀect. Models III and IV are versions of model II where the spatial eﬀect is modelled
by an unstructured (random) eﬀect bs and the sum of a structured and an unstructured
eﬀect, respectively. However, those models will not be discussed here since they do not
lead to an improvement in terms of DIC. Figure 3.1 displays the estimated nonparametric
eﬀects of model II with predictor
ηi = g0(t) + fa(ai) + fp(pi) + fspat(si) + γ1meta1 + γ2meta2.
With the software BayesX all unknown functions are centered about zero, and an intercept
term is included in the parametric linear term for identiﬁability reasons. For plotting, the
estimated eﬀects of age ai and period pi are all centered at the observed values, i.e.
3726
X
i=1
ˆfa(ai) =
3726
X
i=1
ˆfp(pi) = 0,
while the intercept is added to the log–baseline eﬀects.
Hence it can be derived from
Figure 3.1(a) and (b) that the estimated global risk level is higher with the crude survival
model (since the log–baseline eﬀect resulting from a crude survival analysis exceeds the

84
3. Relative Survival Analysis
log–baseline eﬀect resulting from a relative survival analysis). This results from the fact
that the crude survival analysis delivers an estimation of the risk of dying of any cause,
whereas only the disease related excess mortality risk of breast cancer patients is estimated
by means of a relative survival analysis, where the natural mortality risk is accounted for
separately. Panels (a) and (b) further reveal that the crude survival analysis yields a fairly
constant log–baseline eﬀect g0(t), whereas a relative survival analysis results in an eﬀect,
that is increasing in the ﬁrst two years and decreasing in the time between the third and
the 11th year after diagnosis. Presumably the decrease in risk is not reﬂected in panel
(a) as not accounting for natural mortality that is increasing with time after diagnosis
(since patients are aging) might lead to a neutralization. The estimated eﬀects of age at
time of diagnosis exhibit an u–shaped risk proﬁle and are displayed in panels (c) and (d).
While a crude survival analysis yields an increased risk for patients diagnosed with breast
cancer in their younger days, but a still much higher risk for those women diagnosed at
an age of more than 70 years, a relative survival analysis suggests that women diseased in
early life have the greatest risk. This result is in accordance with the fact that cancers are
often more aggressive with younger people. The diﬀerences between the two approaches
were to be expected since older women have a higher natural mortality risk that is not
accounted for separately with the crude, but only with the relative survival analysis. As
displayed in panels (e) and (f) both approaches yield a higher risk for patients that were
diagnosed with breast cancer in earlier periods. This eﬀect might be explained by medical
progress. Figures 3.2 (a) and (b) display the values of the structured spatial eﬀect in each
municipality. The two approaches yield a similar spatial pattern, but it is more pronounced
with the relative survival analysis. The risk seems to be higher in the south of the region.
None of these eﬀects is signiﬁcant on a level of 95%, but a couple of regions exhibit eﬀects
that are signiﬁcant on a level of 80%, such as some regions in the north–east that have
a lower risk (Figures 3.2(c) and (d)). The estimated parameters ˆγ1 and ˆγ2 for the ﬁxed
eﬀects of meta1 and meta2 are greater with the relative survival approach. In detail the
results are as follows:
crude
relative
ˆγ1
0.66
0.96
ˆγ2
2.23
2.74
meaning that compared to patients with no metastases the hazard rate is about 1.9 (9.3)

3.4 Application
85
crude survival
relative survival
Model
D(¯θ)
pD
DIC
D(¯θ)
pD
DIC
I
g0(t) + f(a) + fspat(s) + meta
9268
20
9308
9208
20
9249
II
g0(t) + f(a) + f(p) + fspat(s) + meta
9259
24
9307
9200
23
9246
III
g0(t) + f(a) + f(p) + bs + meta
9264
24
9312
9205
24
9253
IV
g0(t) + f(a) + f(p) + fspat(s) + bs + meta
9250
29
9308
9192
28
9248
V
g0(t) + f(a) + f(p) + fspat(s) + g(t) ∗meta
9239
28
9296
9187
27
9241
Table 3.1:
Deviance, eﬀective number of parameters pD and DIC for some of the models we
compare.
and 2.6 (15.5) times higher for patients with one (more than one) metastasis, respectively.
To investigate if the proportional hazards assumption is appropriate, the number of
metastases is included as a covariate with time–varying eﬀect in model II, i.e. the disease–
related log–hazard of model V is
λc
i = exp (g0(t) + meta1i · g1(t) + meta2i · g2(t) + fage(ai) + fp(pi) + fspat(si)) .
Here g0(t) is the log–baseline eﬀect for patients without metastases, g0(t)+g1(t) corresponds
to the log–baseline for patients with one metastasis and g0(t)+g2(t) for patients with more
than one metastasis. The time–dependent functions gk(t), k = 0, 1, 2 are modelled with
cubic P–spline priors with 20 knots. As displayed in Table 3.1 the DIC is reduced by
allowing for a temporal variation in the eﬀect of the number of metastases. The three
log–baseline eﬀects are plotted in Figure 3.3 and reveal that the diﬀerences in risk between
the patient groups seem to diminish with time after diagnosis. The log–baseline eﬀect for
patients with more than one metastasis even crosses the other curves, but this result must
not be over–interpreted since there are only 70 patients with more than one metastasis in
the study. The remaining estimated eﬀects of model V resemble the results of model II
and are not shown for this reason.

86
3. Relative Survival Analysis
−7
−6
−5
−4
−3
g_0(t)
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
t
(a) log–baseline eﬀect g0(t)
−7
−6
−5
−4
−3
g_0(t)
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
t
(b) log–baseline eﬀect g0(t)
−2
−1
0
1
2
f_age
20
30
40
50
60
70
80
90
age
(c) centered eﬀect of age
−2
−1
0
1
2
f_age
20
30
40
50
60
70
80
90
age
(d) centered eﬀect of age
−.5
0
.5
f_p
1988
1989
1990
1991
1992
1993
1994
1995
1996
1997
1998
period
(e) centered eﬀect of period
−.5
0
.5
f_p
1988
1989
1990
1991
1992
1993
1994
1995
1996
1997
1998
period
(f) centered eﬀect of period
Figure 3.1: Model II: Posterior means and pointwise 80% and 95% conﬁdence intervals for the
baseline eﬀect including the intercept term (a,b), the centered eﬀect of age (c,d) and the centered
eﬀect of period (e,f). Figures b,d and f result from a relative survival analysis.

3.4 Application
87
−0.25
0.25
0
(a)
−0.25
0.25
0
(b)
(c)
(d)
Figure 3.2: Model II: posterior means of the structured spatial eﬀect (MRF) and posterior
probabilities for a nominal level of 80%, where black denotes regions with strictly negative credible
intervals and white denotes regions with strictly positive credible intervals. Panels b) and d) result
from a relative survival analysis.

88
3. Relative Survival Analysis
−4
−3
−2
−1
0
1
2
3
4
log−baseline effects
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
t
no meta
1 meta
more than 1 meta
(a) crude survival
−4
−3
−2
−1
0
1
2
3
4
log−baseline effects
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
t
no meta
1 meta
more than 1 meta
(b) relative survival
Figure 3.3: Model V: posterior means of the log–baseline eﬀects for patients with no metastases,
one metastasis and more than one metastasis (dots in the lowest, middle and highest row mark
observed lifetimes of patients with no metastases, one metastasis and more than one metastasis,
respectively)
3.5
Simulation
To verify the reliability of our relative survival model and to show that a model that
does not account for natural mortality can indeed be misleading concerning the eﬀects of
covariates in such cases where data on speciﬁc causes of death is not available, we simulate
an appropriate data set with known risk proﬁle. Survival times are generated according to
a hazard rate that is the sum of a natural hazard rate and a disease related hazard rate.
This data set is then analyzed with a crude survival model like in (2.3) and with a relative
survival model like in (3.1) and the results are compared subsequently.
As for the data generation we simulate survival times based on the covariates of our
real breast cancer data set, using known speciﬁcations for the baseline and the covariate
eﬀects that resemble the eﬀects estimated by the relative survival analysis of the real data
set. However, for the sake of simpliﬁcation we neither consider a spatial eﬀect nor a period
eﬀect. We ﬁrst simulate survival times for each subject and the censoring is done in a
second step. In detail, survival times Ti, i = 1, . . . , 3726, are generated according to the
following hazard rate model

3.5 Simulation
89
λi(t, ai, meta1i, meta2i)
=
λe
i(ai + t) + λc
i(t, ai, meta1i, meta2i)
=
λe
i(ai + t) + exp(g0(t) + fage(ai) + γ1meta1i + γ2meta2i),
where the natural hazard rate λe
i is chosen in order to resemble the natural mortality rates
used with the application, but only depends on ai + t, which is the age of individual i at
time t after diagnosis. In our application natural mortality also depends on calendar time,
but we did not consider this here. As illustrated in Figure 3.4(a) the natural hazard rate
is increasing exponentially with age at time t after diagnosis. The disease related hazard
rate λc
i depends on time t after diagnosis, the age at time of diagnosis ai, and the two
binary covariates meta1i and meta2i, which indicate whether an individual i has one and
more than one metastasis, respectively. As displayed in Figure 3.4(b) the disease related
log–baseline g0(t) is increasing in the ﬁrst 2.5 years after diagnosis, decreasing in the time
span between 2.5 and 12 years and staying constant afterwards. In contrast to the natural
mortality risk, the eﬀect of age on the disease related risk is u–shaped and highest with
patients diseased in early life, whereas it is less increased with the initially oldest patients
in the study, who are diagnosed with breast cancer at the age of 87 (Figure 3.4(c)). Finally
the disease related log–hazard is increased by γ1 = 0.95 and γ2 = 2.75 for individuals with
one metastasis (meta1i = 1) and more than one metastasis (meta2i = 1), respectively.
Since the data used in our application were only gathered until the year 2002 we consider
all survival times exceeding the year 2002 as censored, i.e. observed survival times are given
by ti = min(Ti, 2002.0 −pi) with pi denoting the exact date of diagnosis observed in the
real data set. This mechanism results in a censoring rate of approximately 60% (compared
to approximately 67% with the real data set).
The data set generated in this way is initially analyzed with a crude survival model like
in (2.3) that does not distinguish between natural mortality and disease related mortality.
More precisely we wrongly assume a hazard rate as follows:
λi(t, ai, meta1i, meta2i)
=
exp(g0(t) + fage(ai) + γ1meta1i + γ2meta2i),
where the log–baseline g0(t) and the age–eﬀect fage are modelled as cubic P–splines with 20
knots (with second order random walk smoothness priors and IG(0.001, 0.001) priors for

90
3. Relative Survival Analysis
0
.1
.2
.3
.4
.5
lambda_e
20
40
60
80
100
a_i+t
a) natural hazard rate against age
λe
i(ai + t) = exp ((ai + t −30)/10) /2500
−.75
−.5
−.25
0
.25
.5
.75
g_0(t)
0
2
4
6
8
10
12
14
t
b) disease related log–baseline eﬀect
g0(t) =
(
0.5 · sin(t/3 + 0.75) −4 , t ≤4.5π −2.25
−4.5
, t > 4.5π −2.25
0
.5
1
1.5
f_age
20
40
60
80
a_i
c) disease related eﬀect of age at time of diagnosis
fage(ai) = ((ai −60)/35)2
Figure 3.4: Simulation: speciﬁcations for the natural hazard rate, the disease related log–baseline
eﬀect and the disease related eﬀect of age at time of diagnosis

3.5 Simulation
91
the variance components) and γ1 and γ2 are ﬁxed eﬀects with diﬀuse priors. Expectedly
the estimated log–baseline and the eﬀect of age do not reﬂect the true disease related
eﬀects but rather present a mixture of the two eﬀects on natural mortality and disease
related mortality. The estimated log–baseline eﬀect is increasing in the ﬁrst years after
diagnosis, but the subsequent decline is less steep than with the true log–baseline eﬀect
(Figure 3.5(a)). While the disease related log–baseline is decreasing between the 2.5th and
12th year after diagnosis, the natural mortality risk of each single patient is increasing
with time (since people are getting older) and these two eﬀects seem to kind of balance.
As can be seen from Figure 3.5(c) the crude survival model underestimates the risk for
women diagnosed with breast cancer in early years and overestimates the risk of women
diseased at an old age. Again, this high risk for older people results from the increasing
natural mortality risk that is not accounted for separately. Finally also the ﬁxed eﬀects of
the covariates meta1 and meta2 are not estimated correctly, but are rather underestimated
by ˆγ1 = 0.68 and ˆγ2 = 2.33 (with standard deviations of 0.05 and 0.13, respectively). This
underestimation is due to the fact that only a part of the cases of death (namely those
cases that are related to the disease) are in association with the number of metastases,
whereas the crude survival analysis estimates the average inﬂuence based on all cases of
death.
Now we re–analyze the generated data set with a relative survival model as described
in (3.1). That is we assume a hazard rate as follows:
λi(t, ai, meta1i, meta2i)
=
λe
i(ai + t) + λc
i(t, ai, meta1i, meta2i)
=
exp
  ai+t−30
10

2500
+ exp(g0(t) + fage(ai) + γ1meta1i + γ2meta2i),
where the disease related hazard rate λc
i is modelled as the total hazard rate λi was modelled
before. However, the total hazard is now amended by the known natural mortality rate
λe
i in order to account for cases of death that are not related to the disease of interest. As
displayed in Figures 3.5(b) and (d) the true disease related log–baseline and the eﬀect of
age are now estimated quite satisfactorily, even though the eﬀect of age is a bit too ﬂat
which might be due to the very small number of young patients. Also the ﬁxed eﬀects of
meta1i and meta2i are estimated quite well with ˆγ1 = 0.98 and ˆγ2 = 2.79 (with standard
deviations of 0.07 and 0.15, respectively).

92
3. Relative Survival Analysis
3.6
Conclusion
In summary it can be ascertained that the simulation supports the usefulness of the relative
survival approach since it yields results that are highly comparable to those of our appli-
cation. As the simulation has shown, a model that does not account for natural mortality
is not suitable for the identiﬁcation of prognostic factors for disease speciﬁc mortality in
cases where data on causes of death is not available since eﬀects of covariates on natural
mortality and eﬀects on disease speciﬁc mortality intermix and can not be separated easily
ex post.

3.6 Conclusion
93
crude survival
relative survival
−7
−6
−5
−4
−3
g_0(t)
0
2
4
6
8
10
12
14
t
(a) log–baseline eﬀect g0(t)
−7
−6
−5
−4
−3
g_0(t)
0
2
4
6
8
10
12
14
t
(b) log–baseline eﬀect g0(t)
−1
−.5
0
.5
1
1.5
2
f_age
20
40
60
80
age
(c) centered eﬀect of age
−1
−.5
0
.5
1
1.5
2
f_age
20
40
60
80
age
(d) centered eﬀect of age
Figure 3.5:
Simulation: posterior means (solid line) together with pointwise 80% and 95%
conﬁdence intervals and true disease related eﬀects (dashed lines) for the log–baseline eﬀect
including the intercept term (a,b) and the centered eﬀect of age (c,d). Figures b and d result
from a relative survival analysis.

94
3. Relative Survival Analysis

Chapter 4
Multi–state models
4.1
Introduction
In the previous chapters we described methods for analyzing data, where only one type of
event is considered. This chapter is concerned with extensions to more general event history
data, that is ascertained by observing individuals over time and contains information on
the times of occurrence of certain events and the types of events that occur.
In the simplest case one may distinguish between several distinct types of terminating
events, i.e. from a statistical point of view each event represents a transition from a transient
state to a certain absorbing state. Here just one transient state, but an arbitrary, ﬁnite
number of absorbing states may be considered. Models for this type of data are referred
to as competing risks models. In clinical studies, for example, the competing risks might
be the diverse causes of death.
The most general case that we discuss is given by continuous–time multi–state models.
Here the various events are considered as transitions from one state to another. A state
structure speciﬁes the diverse states (that might be absorbing or transient) and deﬁnes
which transitions are possible. Each individual may experience a certain number of events
over time, i.e. pass through the considered, possibly recurrent states, with transition times
being arbitrary and measured on a continuous time–scale. Hence we consider individual
counting processes instead of individual survival times. This type of data is for example
given in clinical studies where the interest lies in analyzing transitions between diﬀerent
states of health. Note that survival data represent a special type of event history data

96
4. Multi–state models
with just one type of event that is a transition from the only transient state to the only
absorbing state.
Multi–state models are discussed widely in the literature. Andersen and Keiding (2002)
provide a good overview over multi–state models with linear predictors in a frequentist set-
ting. Fahrmeir and Klinger (1998) propose a nonparametric multiplicative multi–state haz-
ard model that allows to model nonlinear functional forms of covariates and time–varying
eﬀects, with estimation being based on penalized likelihoods and smoothing splines. While
several models for the analysis of spatially correlated survival data have been proposed
in recent publications, spatial models have received far less attention in the more general
setting of multi–state models.
Within this chapter we will illustrate how the Bayesian methods presented in Chapter
2 for analyzing extended Cox models are carried forward to continuous–time multi–state
models.
We present an approach where the hazard or transition rates for the partic-
ular events are modelled via independent structured additive predictors each including
a nonparametrically modelled log–baseline eﬀect as well as transition–speciﬁc eﬀects of
(time–independent or time–dependent) covariates with possibly linear, nonlinear, spatially
correlated, time–varying or random eﬀects. In principle diﬀerent time scales, like e.g. time
since an individual–speciﬁc initial point of time and duration in the current state could
be considered as basic times for the various transition rates of a multi–state model. For
simpliﬁcation however, in what follows we consider time t since an individual–speciﬁc ini-
tial point of time as the basic time scale with every transition rate, while other time scales
might be treated as time–dependent, but piecewise constant covariates.
The rest of this chapter is organized as follows. In Section 4.2 we will describe models,
likelihood and priors for unknown functions and parameters. In Section 4.3 we comment
on how the MCMC inference described in Section 2.3 for extended Cox models may be
utilized with multi–state models. In Section 4.4 we illustrate our methods by applications
to medical data on structural valve degeneration (SVD) of biological prostheses where
reoperation and death without previous reoperation act as competing risks, and to sleep–
electroencephalography data with multiple recurrent states of sleep.

4.2 Models, likelihood, priors and MCMC inference
97
4.2
Models, likelihood, priors and MCMC inference
Within this chapter we will present two alternative representations of multi–state data. We
start oﬀwith a notation embedded in the counting process framework (Andersen, Borgan,
Gill and Keiding 1993), which is quite common with multi–state data. The second notation
is more closely related to the representation of survival data as introduced in Subsection
2.2.1.
Consider n individuals and let Nhi, for h = 1, . . . , H, i = 1, . . . , n, denote the counting
processes for events of type h, where Nhi(t) is the number of observed type h events expe-
rienced by the ith individual up to time t. We assume that individual intensity processes
exist and have multiplicative structure
αhi(t) = Yhi(t)λhi{t; zhi(t), xhi(t), shi(t), vhi(t)},
(4.1)
where Yhi(t) are left–continuous 1–0 processes indicating whether or not individual i is
at risk of experiencing a type h event just before time t. The individual type h hazard
or transition rate λhi in (4.1) depends on t and on possibly transition–speciﬁc and time–
dependent covariates. As in (2.4), the covariate vector zhi(t) is assumed to have time–
varying eﬀects, xhi(t) consists of continuous covariates with possibly nonlinear eﬀects, shi
denotes a spatial location and vhi(t) comprises covariates with linear eﬀects. Note that
right censored survival data with lifetimes Ti, independent censoring times Ci, i = 1, . . . , n,
observed lifetimes ti = min(Ti, Ci), and censoring indicators δi are a special case with
h = 1, Ni(t) = I(Ti ≤t, δi = 1), Yi(t) = I(ti ≥t) and λi(t) as in (2.3) and (2.4).
The transition rate λhi(t) for individual i is assumed to follow a multiplicative model
λhi(t) := λhi(t; zhi(t), xhi(t), shi(t), vhi(t)) = exp(ηhi(t)),
(4.2)
with the general form of the predictor given by
ηhi(t) = gh0(t) +
p
X
j=1
ghj(t)zhij +
p+q
X
j=p+1
fhj(xhij(t)) + fh,spat(shi) + v′
hi(t)γh.
(4.3)
Here gh0(t) = log (λh0(t)) is the log–baseline eﬀect for transition h, ghj(t) are time–
varying eﬀects of covariates zhj(t), fhj(xhj(t)) is the nonlinear eﬀect of xhj(t), fh,spat is
the spatially correlated eﬀect of sh, and γh is the vector of usual linear ﬁxed eﬀects.

98
4. Multi–state models
As a further extension, i.i.d. random eﬀects (also referred to as frailty eﬀects) and ran-
dom slopes could be introduced in (4.3), but we omit this here.
For given predictors
η = {ηhi, h = 1, . . . , H, i = 1, . . . , n}, the individual likelihood Li(η) and the likelihood
L(η) are given by
Li(η)
=
H
Y
h=1
Z ∞
0
λhi(s)dNhi(s) · exp

−
Z ∞
0
Yhi(s)λhi(s)ds

(4.4)
L(η)
=
n
Y
i=1
Li(η).
Note that the ﬁrst integral in (4.4) always reduces to a sum because Nhi(s) is a step function.
Numerical problems arise in the evaluation of the second integral in (4.4). Again, only if
time–varying functions in the predictor are step functions, this integral also reduces to a
sum (compare Section 2.3). Otherwise numerical integration in form of the trapezoidal
rule is employed as illustrated in Figure 1.6 in Chapter 1.
An alternative formulation of the likelihood, that shows the close connection to survival
models more clearly, arises from considering multi–state data where for each individual i
times of occurrences of certain events ti1, ti2, . . . , tini (as well as possibly a left truncation
time ti0) and H–dimensional event–type indicators δi1, δi2, . . . , δini are given, that indicate
which type of event occurred and are deﬁned as follows
δikh =
(
1
individual i experienced a type h event at time tik
0
else
for k = 1, . . . , ni and h = 1, . . . , H. Note that δini = (0, . . . , 0) if an observation is right
censored, i.e. if individual i is in a transient state at time tini but for some reason the
observation is discontinued at that point of time. Furthermore a state structure has to be
given that deﬁnes which state transitions are possible and hence deﬁnes the risk processes
Yhi(t). Via this kind of notation the individual likelihood may be alternatively written as
Li(η) =
H
Y
h=1
ni
Y
k=1
"
λhi(tik)δikh · exp
(
−
Z tik
ti,k−1
Yhi(s)λhi(s)ds
)#
.
(4.5)
From this equation it can be seen how the likelihood of such a multi–state model is mul-
tiplicatively composed of likelihood contributions of according survival models (for left
truncated data) where one of the H events is modelled at each.

4.3 Markov Chain Monte Carlo inference
99
As regards assumptions about priors for parameters and functions and hyperpriors for
variance components we may refer to Subsection 2.2.1 since we do not assume correla-
tions of any kind between transition rates and the priors do not depend on the type h
of transition (see Conclusion for a short discussion of this assumption). Hence with each
single transition rate may be proceeded as described in Chapter 2 for the hazard rate of
a survival model, i.e. each transition–speciﬁc log–baseline eﬀect gh0 as well as every un-
known function fhj and ghj might for example be modelled via a Bayesian P–spline, while
diﬀuse priors are assumed for ﬁxed eﬀects parameters γh and MRF priors are our stan-
dard choice for structured spatial eﬀects fh,spat. In the framework of the generic notation
as described for survival models in (2.6), after reindexing we can represent the predictor
vectors ηh=(ηh1(t1,1), . . . , ηh1(t1,n1), . . . , ηhn(tn,1, . . . , ηhn(tn,nn))′ as
ηh = Vhγh + Zh0βh0 + . . . + Zhmhβhmh.
(4.6)
Priors for functions and spatial components are then deﬁned by suitable design matrices
Zhj, h = 1, . . . , H, j = 0, . . . , mh, and a prior for each corresponding parameter vector βhj.
The general form of a prior for βhj is given by
p(βhj|τ 2
hj)
∝
τ
−rhj
hj
exp
 
−1
2τ 2
hj
β′
hjKhjβhj
!
,
(4.7)
where Khj is an adequate precision or penalty matrix of rank(Khj) = rhj, shrinking
parameters towards zero or penalizing too abrupt jumps between neighboring parameters.
We assign inverse Gamma priors IG(ahj; bhj)
p(τ 2
hj)
∝
1
(τ 2
hj)ahj+1 exp
 
−bhj
τ 2
hj
!
(4.8)
to all variances, with ahj = bhj = 0.001 being our standard choice.
4.3
Markov Chain Monte Carlo inference
As with survival models, full Bayesian inference via MCMC simulation is again based on
updating full conditionals of single parameters or blocks of parameters (each with para-
meters corresponding to the same transition rate λhi), given the rest of the data. For

100
4. Multi–state models
updating the parameter vectors βhj, which correspond to the time–independent functions
fhj, as well as spatial eﬀects βspat
h
, which correspond to spatial functions fh,spat, ﬁxed eﬀects
γh and random eﬀects bh, we use the slightly modiﬁed version of the MH–algorithm based
on iteratively weighted least squares (IWLS) proposals, which is described in Section 2.3
and the Appendix, respectively, for survival models. The full conditional of a parameter
vector βhj with prior p
 βhj|τ 2
hj

is for example given by
p(βhj|·)
∝
L(βhj) · p(βhj|τ 2
hj)
=
n
Y
i=1
H
Y
˜h=1
ni
Y
k=1
"
λ˜hi(tik)δik˜h · exp
(
−
Z tik
ti,k−1
Y˜hi(s)λ˜hi(s)ds
)#
· p
 βhj|τ 2
hj

∝
n
Y
i=1
ni
Y
k=1
"
λhi(tik)δikh · exp
(
−
Z tik
ti,k−1
Yhi(s)λhi(s)ds
)#
· p
 βhj|τ 2
hj

=
n
Y
i=1
ni
Y
k=1

Lhik
 βhj

· p
 βhj|τ 2
hj

,
at which the second proportionality holds because the transition rates λ˜hi, ˜h ̸= h do not
depend on βhj.
Note that for Yhi = 1 the likelihood contribution Lhik has the same
structure as an individual likelihood contribution Li for a left–truncated survival time
(compare equations (1.6) and (2.5)). For Yhi = 0 it follows that δikh = 0, since a type h
transition can only be observed if the individual is at risk for a type h transition, i.e. if
Yhi = 1. Hence Yhi = 0 implies that Lhik = 1. As a consequence of these insights IWLS
proposals for the parameter vectors βhj may be derived in the same manner as described in
Section 2.3 and the Appendix, respectively. Thus, a new value βp
hj is proposed by drawing
a random sample from a high dimensional multivariate Gaussian distribution q(βc
hj, βp
hj)
which is obtained from a quadratic approximation of the log–likelihood by a second order
Taylor expansion with respect to the current value of the chain βc
hj. The precision matrix
and mean of this proposal distribution are given by
P hj = Z′
hjW h(βc
hj)Zhj + 1
τ 2
hj
Khj,
mhj = P −1
hj Z′
hjW h(βc
hj)(˜yh −˜ηh).

4.4 Application
101
Here, ˜ηh = ηh−Zhjβhj, W h(βc
hj) = diag(wh,1,1, . . . , wh,n,nn) is the weight matrix for IWLS
with weights calculated from the current state βc
hj as follows
whik =
Z tik
ti,k−1
Yhi(s)λhi(s)ds,
i = 1, . . . , n,
k = 1, . . . , ni.
The vector of working observations ˜yh is given by
˜yh = W−1
h (βc
hj)∆h −1l + ηh
with ∆h = (δ1,1,h, . . . , δn,nn,h)′. The proposed vector βp
hj is accepted as the new state of
the chain with probability
α(βc
hj, βp
hj) = min
 
1, p(βp
hj | ·)q(βp
hj, βc
hj)
p(βc
hj | ·)q(βc
hj, βp
hj)
!
.
For the parameters βhj corresponding to the functions gh0(t), ..., ghp(t) depending on
time t, we again adopt the computationally faster MH–algorithm based on conditional
prior proposals, that only requires evaluation of the log–likelihood, not of derivatives (see
Fahrmeir and Lang (2001a) for details).
The full conditionals for the variance parameters τ 2
hj are (proper) inverse Gamma with
parameters
a′
hj = ahj + 1
2rhj
and
b′
hj = bhj + 1
2β′
hjKhjβhj,
Updating can be done by simple Gibbs steps, drawing random numbers directly from the
inverse Gamma densities.
4.4
Application
4.4.1
Biological valve prostheses
Our ﬁrst application is on data from 455 patients who underwent biological mitral valve
replacement (MVR) at the German Heart Center in Munich between 1974 and 2000. This
data has been analyzed before by Kaempchen et al. (2003) and more details about the
medical background may be found therein. The aim of our analysis is to assess the inﬂuence
of several covariates on reoperation free survival, at which death and reoperation due to
a failure of the biological valve are considered as competing risks. The state structure of

102
4. Multi–state models
this competing risks model is illustrated in Figure 4.1. Note that death after reoperation
is not of interest with this analysis and is therefore not considered. Within the observation
period 212 patients died without a previous reoperation and 125 patients had to undergo
a reoperation; the remaining 118 observations are right–censored.
Covariates that are
given include the sex and the age of patients at valve replacement as well as the diagnosis
(insuﬃciency, narrowness or malformation of the mitral valve) and information on the
initial valve replacement, namely the date of implantation and whether or not an additional
aortocoronary venous bypass (ACVB) was accomplished. Including all the covariates, the
transition rates λri (reoperation) and λdi (death without previous reoperation) are modelled
as follows
λri(t)
=
exp [gr0(t) + fr,age(agei) + fr,date(datei)
+γr1 · sexi + γr2 · diag1i + γr3 · diag2i + γr4 · acvbi]
λdi(t)
=
exp [gd0(t) + fd,age(agei) + fd,date(datei)
+γd1 · sexi + γd2 · diag1i + γd3 · diag2i + γd4 · acvbi] ,
where t is time since valve replacement, gh0, h = r, d are the log–baseline eﬀects, fh,age and
fh,date are nonlinear eﬀects of the age of a patient at valve replacement and of the date
of valve replacement, respectively. All of these possibly nonlinear eﬀects are modelled via
cubic P–splines with 20 knots. The remaining covariates are dummy–coded: sex = 1 for
female, and sex = 0 for male, diag1 = 1 if the patient was diagnosed with an insuﬃciency
of the mitral valve, diag1 = 0 else, diag2 = 1 if the patient was diagnosed with a
narrowness of the mitral valve, diag2 = 0 else and acvb = 1 if an additional ACVB
was accomplished, acvb = 0 else. Diﬀuse priors were assumed for the parameters γ.
Figure 4.2 displays the estimated nonlinear eﬀects. Concerning the risk of a reoperation
we observe that the risk is highest between ca. 9.5 and 16.5 years after the initial valve
replacement, while it is lower in the ﬁrst 9.5 years and after 16.5 years of reoperation free
survival, at which conﬁdence intervals become quite broad for t > 20 years. The risk of
death without previous reoperation on the other hand is very high directly after the valve
replacement and is steeply decreasing within the ﬁrst 2 years and slowly increasing from
that time on. The initially high risk might arise from consequences of the operation or
incompatibilities, while the slow increase for t > 2 is due to aging. The eﬀect of age at

4.4 Application
103
survival without reoperation
reoperation
death
     
@
@
@
@
@
R
λr
λd
Figure 4.1:
State structure of the competing risks model for the analysis of reoperation free
survival after biological mitral valve replacement.
valve replacement turns out to be rather linear with both predictors. While the risk of a
reoperation is decreasing with increasing age it is vice versa with the risk of death without
previous reoperation. This result seems quite perspicuous. The lifespan of patients that
got a biological valve prostheses at the age of 80 or more, for example, is likely to be shorter
than the endurance of the valve prostheses. The date of the valve replacement does not
seem to have an inﬂuence on any of the two risks. In the ﬁrst instance this appears to be
very disappointing since it would mean there has been no medical progress within 26 years.
However, medical progress involved that over the years more and more patients with very
severe illnesses could be operated, that would not have been operated in earlier years since
there would have been no chances of success. Consequently the composition of patient
groups with respect to the severity of the illness is heterogeneous over the years. Hence
our result is likely to be due to the fact that the severity of the illness is not considered with
our analysis as it is only recorded with 116 out of those 455 patients. Concerning the ﬁxed
eﬀects we observe that an additional ACVB reduces the risk of a reoperation signiﬁcantly
on the basis of a 80% signiﬁcance level (ˆγr4 = −1.32, with a standard deviation of 0.79),
while the remaining ﬁxed eﬀects are not signiﬁcant (compare Table 4.1).
4.4.2
Human sleep processes
Our second application is about analyzing human sleep processes. The data set arises from
recordings of electroencephalographic (EEG) data during one night taken for a group of 27

104
4. Multi–state models
λr (→reoperation)
λd (→death)
−6
−4
−2
0
2
4
g_r0(t)
0
5
10
15
20
25
t [years]
(a) log–baseline eﬀect
−6
−4
−2
0
2
4
g_d0(t)
0
5
10
15
20
25
t [years]
(b) log–baseline eﬀect
−6
−4
−2
0
2
4
f_r,age
20
40
60
80
age
(c) eﬀect of age
−6
−4
−2
0
2
4
f_d,age
20
40
60
80
age
(d) eﬀect of age
−6
−4
−2
0
2
4
f_r,date
1975
1980
1985
1990
1995
2000
date
(e) eﬀect of date
−6
−4
−2
0
2
4
f_d,date
1975
1980
1985
1990
1995
2000
date
(f) eﬀect of date
Figure 4.2: MVR data: posterior mean together with 80% and 95% credible intervals of
the centered log–baseline eﬀects (a) and (b), the eﬀects of age (c) and (d), and the eﬀects
of date (e) and (f) on the competing risks reoperation (left panel) and death (right panel).

4.4 Application
105
λr
λd
mean
std. dev.
mean
std. dev.
sex
0.17
0.22
-0.01
0.15
diag1
-0.29
0.25
0.14
0.18
diag2
0.07
0.23
-0.13
0.21
acvb
-1.32
0.79
0.11
0.20
Table 4.1: MVR data: posterior mean estimations of ﬁxed eﬀects γ together with standard
deviations.
patients at the Max–Planck–Institut f¨ur Psychiatrie in Munich. Sleep–EEG data describe
the nocturnal sleep rhythm, usually classiﬁed in several stages such as awake, non–rapid
eye movement (NREM) and rapid eye movement (REM). Such sleep states indicating the
depth of sleep are recorded every 30 seconds. In addition, secretion of several hormones is
measured every 10, 20 or 30 minutes. The hormone cortisol is for example supposed to be
interrelated with the sleep structure. Figure 4.3 exemplarily displays the processes of sleep
states and nocturnal cortisol secretion for two patients. Without any kind of smoothing
it is diﬃcult to identify typical sleep patterns. Furthermore individual–speciﬁc sleeping
customs must be considered in order to detect population eﬀects.
Besides a dynamic analysis of the transition intensities between the distinct states,
a main concern is to investigate the question whether high cortisol concentrations have
a positive eﬀect on the propensity to REM sleep, which has been hypothesized in simple
correlation and variance analyses. It is also of interest to allow this eﬀect to vary over night.
Due to the very low number of direct transitions from AWAKE to REM, we consider only
a somewhat reduced state structure, which is illustrated in Figure 4.4 and comprises the
following four types of events
h = 1
transition from AWAKE to SLEEP,
(AS)
h = 2
transition from SLEEP to AWAKE,
(SA)
h = 3
transition from REM to NREM,
(RN)
h = 4
transition from NREM to REM,
(NR)
where SLEEP implies REM and NREM sleep states. In principle it might be of interest

106
4. Multi–state models
AWAKE
NREM
REM
state
0
2
4
6
8
 
0
50
100
150
200
cortisol [nmol/l]
0
2
4
6
8
time since sleep onset [hours]
AWAKE
NREM
REM
state
0
2
4
6
8
 
0
50
100
150
200
cortisol [nmol/l]
0
2
4
6
8
time since sleep onset [hours]
Figure 4.3: Individual sleep processes for two patients (i = 1 and i = 21, respectively) together
with the corresponding cortisol secretion.

4.4 Application
107
AWAKE
NREM
REM
-

λNR
λRN
?
6
SLEEP
λAS
λSA
Figure 4.4:
State structure for the analysis of human sleep processes.
to separately analyze the transitions AWAKE →REM, AWAKE →NREM and NREM
→AWAKE, REM →AWAKE, respectively, but our data pool is not suﬃcient for such
a detailed analysis. In order to achieve some synchronization we take time t since sleep
onset as basic time scale.
For the analysis of the possibly time–varying eﬀect of high
cortisol secretion on the transition intensity from NREM to REM, we generate the time–
dependent dummy coded covariate ci(t), which takes the value one if the concentration
of cortisol is higher than 90 nmol/l at time t with patient i and the value zero otherwise.
Observed concentrations of cortisol range from 1 to 450 nmol/l, with 90 nmol/l being the
70% quantile. Based on the previous considerations, we analyze a multi–state model with
the following four transition rates
λhi
=
exp (gh0(t) + bhi) ,
h = AS, SA, RN
λhi
=
exp (gh0(t) + ci(t) · gh1(t) + bhi) ,
h = NR
at which again cubic P–spline priors are assumed for the transition–speciﬁc log–baseline
eﬀects gh0(t), h = AS, SA, RN, NR, as well as for the time–varying eﬀect of a high cortisol
level on the transition from NREM to REM gNR,1(t). The term bhi denotes transition–
and patient–speciﬁc random eﬀects with i.i.d. Gaussian priors bhi ∼N(0, τ 2
hb).
Estimated results for the time–varying baseline eﬀects gh0(t) for the transitions h =

108
4. Multi–state models
AS, SA, RN, NR and the time–varying eﬀect of a high cortisol level on the transition from
NREM to REM gNR,1(t) are displayed in Figure 4.5. As was to be expected the tendency to
fall asleep again is particularly low for patients who awake in the beginning and at the end
of the night, i.e. within the time spans t < 1 and t > 7, respectively. We further conclude
from our results that the propensity to fall asleep is notably high around t ∈[2, 3.3] and
seems to have a local minimum around ﬁve hours after sleep onset.
By contrast, the
tendency to wake up is roughly u–shaped and rather high in the beginning and especially
high at the end of the night while it is lowermost around t ∈[4, 6]. The intensity for
the transition from REM to NREM sleep is highest directly after sleep onset and is then
decreasing until t ≈4, increasing again until t ≈6 and staying rather constant from that
time on. Concerning the inverse transition from NREM to REM sleep, the log–baseline
eﬀect gNR,0(t) marks the eﬀect for a low level of cortisol, while gNR,1(t) describes deviations
from this eﬀect if the level of cortisol is high, i.e. exceeds 90 nmol/l. In case the cortisol
level is low, the intensity for a transition from NREM to REM is initially very low, but
steeply increasing within the ﬁrst hour after initial sleep onset followed by some ups and
downs with peaks at t ≈1.3, t ≈3.0, t ≈4.9 and (possibly) t ≈7.8, i.e. we observe a cyclic
developing with two pronounced peaks in the ﬁrst half of the night and two poor peaks
in the second half of the night. Since high levels of cortisol appear very rarely within the
ﬁrst hours after sleep onset, the (pointwise) credible intervals for the time–varying eﬀect
gNR,1(t) of ci(t) become quite broad for t < 2. Hence we can not draw any conclusions for
this time span. Figure 4.5 f) however, which displays the time–varying eﬀect gNR,1(t) for
t > 4, exhibits an increased propensity to REM sleep for a time span around six hours after
sleep onset. This is to say that our analysis only supports the hypothesis posted above
(high cortisol concentrations have a positive eﬀect on the propensity to REM sleep) for a
time span around t ∈[5.5, 6.8].
The estimated individual– and transition–speciﬁc random
eﬀects are displayed in Figure 4.6. There are several persons that show especially high or
low tendencies for one or more transitions. Patient i = 5 for example has an exceptionally
high tendency to awake, coming along with an exceptionally low tendency to fall asleep and
a low propensity to REM sleep. The individual sleep process of patient i = 5 is displayed
in Figure 4.7 and supports those results since it clearly diﬀers from the prevailing sleep
patterns as exemplarily displayed in Figure 4.3.

4.4 Application
109
−1.5
−1
−.5
0
.5
AS:g_0
0
2
4
6
8
time since sleep onset [hours]
(a) AWAKE →SLEEP
−.5
0
.5
1
1.5
SA:g_0
0
2
4
6
8
time since sleep onset [hours]
(b) SLEEP →AWAKE
−1
−.5
0
.5
1
1.5
RN:g_0
0
2
4
6
8
time since sleep onset [hours]
(c) REM →NREM
−15
−10
−5
0
5
NR:g_0
0
2
4
6
8
time since sleep onset [hours]
(d) NREM →REM
−30
−20
−10
0
10
NR:g_1
0
2
4
6
8
time since sleep onset [hours]
(e) NREM →REM
−3
−2
−1
0
1
2
NR:g_1
4
5
6
7
8
time since sleep onset [hours]
(f) NREM →REM
Figure 4.5:
Human Sleep Processes: Posterior mean estimates for the time–dependent eﬀects
gh0(t), h = AS, SA, RN, NR and gNR,1(t) together with 80% and 95% credible intervals.

110
4. Multi–state models
−2
−1
0
1
AS:random effect
1
5
10
15
20
25
i
(a) AWAKE →SLEEP
−2
−1
0
1
SA:random effect
1
5
10
15
20
25
i
(b) SLEEP →AWAKE
−2
−1
0
1
RN:random effect
1
5
10
15
20
25
i
(c) REM →NREM
−2
−1
0
1
NR:random effect
1
5
10
15
20
25
i
(d) NREM →REM
Figure 4.6:
Human Sleep Processes: Posterior mean estimates (black dots) of the transition–
and individual–speciﬁc random eﬀects bhi for h = AS, SA, RN, NR and i = 1, . . . , 27.
Grey
crosses denote signiﬁcance on a 95% level with -1: signiﬁcant negative eﬀect, 0: no signiﬁcant
eﬀect and +1: signiﬁcant positive eﬀect.

4.5 Conclusion
111
AWAKE
NREM
REM
state
0
2
4
6
8
time since sleep onset [hours]
Figure 4.7:
Individual sleep process for patient i = 5.
4.5
Conclusion
Within this chapter we have shown how the geoadditive survival models presented in Chap-
ter 2 are generalized to multiplicative continuous–time multi–state models. Our approach
allows the estimation of transition–speciﬁc nonlinear log–baseline eﬀects as well as time–
varying eﬀects of covariates, nonlinear eﬀects of continuous covariates and an appropriate
consideration of unobserved unit– or cluster–speciﬁc and spatial heterogeneity.
So far we have only considered transition–speciﬁc eﬀects and did not assume any corre-
lation structure between transition rates. With some applications however, it might make
sense to assume that unit– or cluster–speciﬁc random eﬀects or structured spatial eﬀects
are correlated across (some or all) transition rates or are even transition–independent.
Extensions towards this aspect are topics of future work.

112
4. Multi–state models

Chapter 5
Bayesian survival and multi–state
analysis with BayesX: a tutorial
All models presented in this thesis are implemented in the statistical software package
BayesX. The focus of this chapter is to demonstrate how complex survival data and multi–
state data may be analyzed within BayesX based on MCMC techniques. For this purpose
the estimation of some of the survival models presented in Subsection 2.5.3 to analyze
waiting times on CABG as well as the estimation of the relative survival model presented
in Section 3.5 on the basis of simulated breast cancer data, and the estimation of the
multi–state model presented in Subsection 4.4.2 to analyze human sleep processes are
described in detail. For a description of the data sets we refer to the according subsections.
Note that in addition to MCMC techniques BayesX also provides restricted maximum
likelihood (REML) techniques as described in Kneib (2006) for the estimation of crude
survival models and multi state models.
This chapter is organized as follows. After some comments on the overall capabilities
of BayesX and the general structure of this software package given in Section 5.1 and in
Section 5.2, respectively, we start with the analysis in Section 5.3, which is concerned with
a description on how to create a dataset object to incorporate, handle and manipulate the
data. Since we want to estimate a spatial eﬀect of the ward with the CABG data, we need
the boundaries of the districts to compute the neighborhood information of the map of
London and Essex. This information will be stored in a map object. Section 5.4 describes
how to create and handle these objects. Estimation of the regression models is carried

114
5. Bayesian survival and multi–state analysis with BayesX: a tutorial
out in Section 5.5 using bayesreg objects. Section 5.6 describes post estimation commands
which can be used to investigate the sampling paths and the autocorrelation functions of
the estimated parameters.
5.1
BayesX
BayesX is a public domain software package for performing complex full and empirical
Bayesian inference to estimate ﬂexible regression models with structured additive predic-
tors. Functions for handling and manipulating data sets and geographical maps, and for
visualizing results are added for convenient use. BayesX is available at
http://www.stat.uni-muenchen.de/~bayesx
An overview over the capabilities of BayesX is given in Brezger, Kneib and Lang (2005).
For more detailed information on all available features and the methodological background
see the manuals that are provided in addition to the software BayesX and the references
given therein.
5.2
Getting started
After having started BayesX, a main window with four sub–windows appears on the screen.
These are a command window for entering and executing code, an output window for
displaying results, a review window for easy access to past commands, and an object browser
that displays all objects currently available.
BayesX is object oriented although the concept is limited, i.e. inheritance and other
concepts of object oriented languages like C++ or S–plus are not supported. For every
object type a number of object–speciﬁc methods may be applied to a particular object.
The syntax for generating a new object in BayesX is
> objecttype objectname
where objecttype is the type of the object, e.g. dataset, and objectname is the name
to be given to the new object.

5.3 Dataset objects
115
5.3
Dataset objects
In a ﬁrst step we read the available data set information into BayesX. This is done by
creating three dataset objects named cabg, cancer and sleep for the CABG data, the
(simulated) breast cancer data and the human sleep data, respectively, by typing:
> dataset cabg
> dataset cancer
> dataset sleep
in the command window. We store the data in cabg, cancer and sleep using the method
infile. If the data is provided in the external ASCII ﬁles c:\data\cabg.raw, c:\data\
cancer.raw and c:\data\sleep.raw, respectively, we may type
> cabg.infile using c:\data\cabg.raw
> cancer.infile using c:\data\cancer.raw
> sleep.infile using c:\data\sleep.raw
Note, that this command supposes that the variable names are given in the ﬁrst row of
the according external ﬁle. In case the variable names are not given in the ﬁle we would
have to supply them right after the keyword infile. If a data set has more than 10000
observations it is recommended to set the option maxobs to the according number of rows.
This option allows BayesX to allocate enough memory to store all the data right from the
start, which speeds up the execution time of the infile command.
After having read in the data set information we can inspect the data visually. Exe-
cuting the command
> cabg.describe
for example opens an object–viewer window containing the according CABG data in form
of a spreadsheet. This can also be achieved by double–clicking on the according dataset
object in the object browser.

116
5. Bayesian survival and multi–state analysis with BayesX: a tutorial
Further methods allow to examine the variables in the dataset object. For a categorial
variable the tabulate command may be used to produce a frequency table and for con-
tinuous variables the descriptive command prints several characteristics of the variable
in the output window.
There are also methods to manipulate variables and generate new variables in a dataset
object. Assume for example that cagb includes the categorical variable numdv that takes the
values 1,2 and 3 and indicates the number of diseased vessels. Then the dummy variables
dv2 and dv3 that are used for the estimation may be created and added to cabg using
method generate. This might be done by executing the following commands
> cabg.generate dv2=0
> cabg.replace dv2=1 if numdv=2
> cabg.generate dv3=0
> cabg.replace dv3=1 if numdv=3
or in condensed form by executing the commands
> cabg.generate dv2=(numdv=2)
> cabg.generate dv3=(numdv=3)
Here (numdv=2) may be interpreted as the (row–wise) query ”is numdv equal to 2 or not?”
(written as numdv==2 with some programming languages). Hence the ﬁrst command causes
BayesX to add a new covariate dv2 to the dataset object cabg, that takes the value TRUE
coded as 1 if the corresponding row of numdv equals 2 and the value FALSE coded as 0
otherwise.
5.4
Map objects
In the following we want to estimate a spatially correlated eﬀect of the ward a patient with
coronary artery disease lives. Therefore we need the boundaries of the wards in London and
Essex to compute the neighborhood information of the map of this part of Great Britain.
We therefore create a map object

5.4 Map objects
117
> map m
and read in the boundaries using the infile command of map objects:
> m.infile using c:\data\LondonEssex.bnd
Having read in the boundary information, BayesX automatically computes the neighbor-
hood matrix of the map. The ﬁle following the keyword using is assumed to contain the
boundaries in form of closed polygons. To give an example we print a small part of the
boundary ﬁle of London and Essex. The map corresponding to the section of the boundary
ﬁle can be found in Figure 5.1.
...
"8849",37
532351,181179
532407,181166
532404,181147
532399,181143
532399,181136
532409,181131
532412,181116
532418,181112
532424,181109
532446,181106
532446,181082
532463,181082
532511,181083
532532,181082
532528,181060
532530,181050
532558,181064
532579,181072
532572,181051
532571,181045
532563,181013
532561,180999
532608,180984
532589,180926
532502,180952
532491,180920
532445,180932
532448,180959
532450,180969
532383,180991

118
5. Bayesian survival and multi–state analysis with BayesX: a tutorial
532373,180941
532345,180944
532310,180952
532320,181015
532324,181059
532350,181163
532351,181179
...
For each region of the map the boundary ﬁle must contain the identifying name of the
region, the number of vertices the polygon consists of and the vertices of the polygons that
form the boundary of the region. The ﬁrst line always contains the region code surrounded
by quotation marks and the number of vertices the polygon of the region consists of. Note
that the ﬁrst vertex (532351,181179 with our example) has to be repeated at the end to
obtain a closed polygon and hence the number of vertices of a pentagon would for example
be 6. The region code and the number of vertices must be separated by a comma. The
subsequent lines contain the vertices that are to be connected by straight lines and thus
form the boundary of the region. The vertices are represented by the according coordinates,
which must be separated by a comma. Compare Chapter 5 of the complete BayesX manual
for a detailed description of some special cases, e.g. regions divided into subregions.
Figure 5.1: Corresponding graph of the section of the boundary ﬁle
Map objects may be visualized using method describe:
> m.describe
resulting in the graph shown in Figure 5.2. Additionally, describe prints further infor-
mation about the map object in the output window including the name of the object, the
number of regions, the minimum and maximum number of neighbors and the bandwidth
of the corresponding adjacency or neighborhood matrix:

5.4 Map objects
119
MAP m
Number of regions: 488
Minimum number of neighbors: 1
Maximum number of neighbors: 14
Bandsize of corresponding adjacency matrix: 39
Figure 5.2: The wards of London and Essex.
The numerical complexity associated with the estimation of structured spatial eﬀects us-
ing MCMC techniques depends essentially on the structure of the neighborhood matrix.
Often the geographical information stored in a boundary ﬁle does not represent the ”ideal”
ordering (as regards to the estimation problem) of the districts or regions. Therefore it
may be useful to reorder the map using method reorder:
> m.reorder
Usually reordering results in a smaller bandwidth although the bandwidth is not the cri-
terion that is minimized by reorder. Instead the envelope of the neighborhood matrix is
minimized (compare George and Liu, 1981).
In order to avoid reordering the map object every time you start BayesX it is useful
to store the reordered version in a separate ﬁle. This can be achieved using the outfile
command of map objects:
> m.outfile, replace using c:\data\LondonEssexSort.bnd

120
5. Bayesian survival and multi–state analysis with BayesX: a tutorial
The reordered map is now stored in the given ﬁle. Note, that specifying the option replace
allows BayesX to overwrite an existing ﬁle with the same name. Without this option an
error message would be raised if the given ﬁle is already existing.
Reading the boundary information from an external ﬁle and computing the neighborhood
matrix may be a computationally intensive task if the map contains a large number of
regions or if the polygons are given in great detail. To avoid doing these computation
in every BayesX session, we store the neighborhood information in a so–called graph ﬁle
using method outfile together with the graph option:
> m.outfile, replace graph using c:\data\LondonEssexSort.gra
For more information on graph ﬁles we refer to Chapter 5 of the complete BayesX manual.
5.5
Bayesreg objects
We start with a detailed description of the estimation of survival models presented in
Subsection 2.5.3 to analyze waiting times on CABG. The description of the estimation of
relative survival models presented in Section 3.5, and the description of the multi–state
models presented in Subsection 4.4.2 to analyze human sleep processes follow thereafter.
5.5.1
Survival models
To estimate a survival model using MCMC techniques we ﬁrst create a bayesreg object
which we name surv_m8:
> bayesreg surv_m8
By default estimation results are written to the subdirectory output of the installation
directory. In this case the default ﬁlenames are composed of the name of the bayesreg
object and the type of the speciﬁc ﬁle. Usually it is more convenient to store the results
in a user–speciﬁed directory. To deﬁne this directory we use the outfile command of
bayesreg objects:
> surv_m8.outfile = c:\data\m8

5.5 Bayesreg objects
121
Note, that outfile does not only specify a directory but also a base ﬁlename (the char-
acters ’m8’ in our example). Therefore executing the command above leads to storage of
the results in the directory ’c:\data’ and all generated ﬁlenames start with the characters
’m8’.
In addition to parameter estimates BayesX also gives acceptance rates for the diﬀerent
eﬀects and some further information on the estimation process. In contrast to parameter
estimates this information is not stored automatically but is printed in the output window.
Therefore it is useful to store the contents of the output window. This can be achieved
automatically by opening a log ﬁle using the logopen command
> logopen, replace using c:\data\cabg_log.txt
After opening a log ﬁle, every information written to the output window is also stored in
this ﬁle. Option replace allows BayesX to overwrite an existing ﬁle with the same name
as the speciﬁed log ﬁle. Without replace results are appended to an existing ﬁle.
Our dataset object cabg contains the imported variables ward (electorial ward a patient
resides in), time (time since diagnosis), delta (indicator of non–censoring), sex (1=male,
0=female), numdv (number of diseased vessels) and age (age of patient at time of diagnosis)
as well as the newly generated dummy variables dv2 and dv3. Models 7 and 8 presented
in Subsection 2.5.3 correspond to a continuous–time survival model with hazard rate:
λ(t) = exp(g0(t) + fage(age) + fspat(ward) + γ1sex + γ2dv2 + γ3dv3),
The log–baseline eﬀect g0 and the continuous covariate age are assumed to have a possibly
nonlinear eﬀect on the hazard and are therefore modelled nonparametrically via P–splines.
The eﬀect of the spatial covariate ward is assumed to be spatially correlated, at which model
7 assumes a GRF prior and model 8 assumes a MRF prior. Note that the neighborhood
matrix and possible weights associated with the neighbors are obtained from the map object
m (compare Section 5.4).
To estimate model 8 (MRF prior for the spatial eﬀect) we use method regress of bayesreg
objects:
> surv_m8.regress delta = time(baseline) + age(psplinerw2)
+ ward(spatial,map=m,proposal=iwlsmode) + sex + dv2 + dv3,
family=cox iterations=30000 burnin=10000 step=20 predict using cabg

122
5. Bayesian survival and multi–state analysis with BayesX: a tutorial
Note that with family=cox BayesX expects the indicator of non–censoring (named delta
in our example) to be entered on the left side of the equals sign. This indicator has to
be a 0–1 coded variable taking the value 0 if an observation is censored and the value 1
otherwise. Furthermore a baseline term has to be entered on the right side of the equals
sign, which is modelled by a P–spline with second order random walk prior. Note that the
variable time which indicates the observed survival time has to be greater than zero. In
case the global option begin is not speciﬁed after the comma, it is assumed that each row
in the data set represents an observation from t = 0 to t = time, i.e. no left truncation
and time–varying covariates are present. The eﬀect of age is also modelled by a P–spline
with second order random walk prior, which is speciﬁed by psplinerw2. By default, the
degree of a spline is 3 and the number of inner knots is 20. Full details about all possible
options for P–splines are given in Section 7.1 of the BayesX reference manual. Concerning
the spatial covariate ward, the term spatial deﬁnes a MRF prior where the neighborhood
matrix is speciﬁed via the option map. The additional option proposal may be used to
specify the type of proposal density, with proposal=iwlsmode indicating an iteratively
weighted least squares (IWLS) proposal based on posterior mode estimation (see Brezger
and Lang (2006) for details). With this example iwlsmode turned out to yield higher
acceptance rates than the IWLS proposal based on the posterior mean which would be
used by default.
Options iterations, burnin and step deﬁne properties of the MCMC–algorithm. The
total number of MCMC iterations is given by iterations while the number of burn in
iterations is given by burnin. Therefore we obtain a sample of 20000 random numbers
with the above speciﬁcations. Since, in general, these random numbers are correlated, we
do not use all of them but thin out the Markov chain by the thinning parameter step.
Specifying step=20 as above forces BayesX to store only every 20th sampled parameter
which leads to a random sample of length 1000 for every parameter in our example. With
iterations=30000 the simulation run time of model 8 is about 40 minutes (Pentium 4
CPU 2.8 GHz).
If option predict is speciﬁed, samples of the unstandardized deviance, the eﬀective number
of parameters pD, and the deviance information criterion DIC of the model are computed,
see Spiegelhalter et al. (2002).
In addition, estimates for the linear predictor and the
expectation of every observation are obtained.

5.5 Bayesreg objects
123
For the estimation of model 7 (GRF prior with 100 knots for the spatial eﬀect) we enter
the commands
> bayesreg surv_m7
> surv_m7.outfile = c:\data\m7
> surv_m7.regress delta = time(baseline) + age(psplinerw2)
+ ward(geokriging,map=m,nrknots=100) + sex + dv2 + dv3,
family=cox iterations=30000 burnin=10000 step=20 predict using cabg
For clarity we created a new bayesreg object surv_m7 and speciﬁed the base ﬁlename m7
by the outfile command. Note that using the bayesreg object surv_m8 without changing
the base ﬁlename would also be possible, but would lead to overwriting result ﬁles. With
iterations=30000 the simulation run time of model 7 is about 700 minutes (Pentium 4
CPU 2.8 GHz).
Recall the hazard rate of Model 10
λ(t) = exp (g0(t) + fage(age) + fspat(ward) + γ1sex + g1(t)dv2 + g2(t)dv3) ,
where the eﬀect of the number of diseased vessels is modelled as a time–varying eﬀect.
This model is estimated as follows
> bayesreg surv_m10
> surv_m10.outfile = c:\data\m10
> surv_m10.regress delta = time(baseline) + age(psplinerw2)
+ ward(spatial,map=m,proposal=iwlsmode) + sex
+ dv2*time(baseline) + dv3*time(baseline),
family=cox iterations=30000 burnin=10000 step=20 predict using cabg
The third command speciﬁes cubic P–spline priors for the time–varying eﬀects of the
dummy variables dv2 and dv3. With iterations=30000 the simulation run time of model
10 is about 70 minutes (Pentium 4 CPU 2.8 GHz).
To shed some light on the inﬂuence of diﬀerent choices for hyperpriors we presented some
additional results of model 8 that were obtained with other choices of IG(a; b) priors. The
following command may for example be used to specify uniform priors on the standard
deviations (i.e. set a = −0.5 and b = 0)

124
5. Bayesian survival and multi–state analysis with BayesX: a tutorial
> bayesreg surv_m8u
> surv_m8u.outfile = c:\data\m8_uniform
> surv_m8u.regress delta=time(baseline,a=-0.5,b=0)+age(psplinerw2,a=-0.5,b=0)
+ward(spatial,map=m,proposal=iwlsmode,a=-0.5,b=0)+sex+dv2+dv3,
family=cox iterations=12000 burnin=2000 step=10 predict using cabg
In case the options a and b are not speciﬁed the parameters a and b are set to the default
values a = b = 0.001.
In addition to the information being printed to the output window results for each eﬀect
are written to external ASCII ﬁles. The names of these ﬁles are given in the output window.
By default the ﬁles contain the posterior mean and median, the posterior 2.5%, 10%, 90%
and 97.5% quantiles, and the corresponding 95% and 80% posterior probabilities of the
estimated eﬀects. The posterior quantiles and posterior probabilities may be changed by
the user using the global options level1 and level2.
The output window also contains information on how to visualize the estimation results.
For more details on visualizing estimation results we refer to Chapter 9 of the BayesX
reference manual.
Having ﬁnished the estimation we may close the log ﬁle by typing logclose. Note, that
the log ﬁle is closed automatically when you exit BayesX.
5.5.2
Relative survival analysis
To estimate the relative survival model presented in Section 3.5 we again start by creating
a bayesreg object by typing
> bayesreg rs
Note that we could also use the existing bayesreg object surv, but we prefer to create a
new one named rs for reasons of clarity. To store the results in the directory c:\data and
to specify rs as a base ﬁlename we enter the command
> rs.outfile = c:\data\rs
A log ﬁle where the contents of the output window are stored is then opened by

5.5 Bayesreg objects
125
> logopen, replace using c:\data\breastcancer_log.txt
The ﬁrst lines of the dataset object cancer are given by
time
delta
age
meta1 meta2 age_plus_time lambda_e
5.718018
0
46.6694
0
0
52.38742
.0037526
7.738525
0
50.91581
0
0
58.65434
.0070227
3.518052
1
63.14305
1
0
66.6611
.0156398
.5538804
1
78.95688
1
0
79.51076
.0565308
7.741333
0
80.16427
0
0
87.9056
.1308785
5.816528
0
82.85284
0
0
88.66936
.1412662
4.694092
0
83.3922
0
0
88.08629
.1332648
.9661008
1
83.95345
0
1
84.91956
.0970926
4.458618
0
80.96372
1
0
85.42234
.102099
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
where time is time t since diagnosis (in years), delta is the indicator of non–censoring,
which takes the value one if the patient died and the value zero if the observation is right–
censored. The covariate age denotes the age of the patient at time of diagnosis and the
dummy variables meta1 and meta2 indicate whether the number of metastases is one or
more than one, respectively. The variable age_plus_time is an auxiliary variable that
was used to generate the expected hazard rate. It is given by the sum of age and time
and denotes the age of the patient at the end of the observation, i.e. the age at death
or at the time, when the observation was right–censored. Finally, lambda_e denotes the
expected hazard rate, which with our example is given by lambda_e(age_plus_time) =
exp ((age_plus_time −30)/10) /2500. Note that a dataset object used for the estimation
of a relative survival model has to contain the expected hazard rate λe, that usually depends
on the age at death, the sex of a patient and possibly the date of death or further covariates.
Typically this variable will have to be generated in advance with the help of mortality
tables. Here it is important to consider that the observed survival time t and the hazard
rate λe refer to the same time unit. Mortality tables usually contain annual data. In that
case the survival times would have to be given in years as well.

126
5. Bayesian survival and multi–state analysis with BayesX: a tutorial
The model presented in Section 3.5 corresponds to a relative survival model with hazard
rate:
λ
=
λe(age, t) + λc(t, age, meta1, meta2)
=
λe(age + t) + exp(g0(t) + fage(age) + γ1meta1 + γ2meta2),
where the hazard rate is additively composed of the known expected hazard rate λe and
the unknown disease–speciﬁc hazard rate λc. The log–baseline eﬀect g0 and the continuous
covariate age are assumed to have a possibly nonlinear eﬀect on the (disease–speciﬁc)
hazard and are therefore modelled nonparametrically via P–splines.
To estimate this model we again use method regress of bayesreg objects:
> rs.regress delta = time(baseline) + age(psplinerw2)
+ meta1 + meta2 + lambda_e(offest),
family=cox iterations=30000 burnin=10000 step=20 using rs
Note that the only diﬀerence to the estimation of crude survival models as presented in the
previous subsection is the additional term lambda_e(offset), that is used to specify the
variable lambda_e as the expected hazard rate. With iterations=30000 the simulation
run time of this model is about 30 minutes (Pentium 4 CPU 2.8 GHz).
Again, additionally to the information being printed to the output window results for each
eﬀect are written to external ASCII ﬁles, with the names of these ﬁles being given in
the output window. Having ﬁnished the estimation we may close the log ﬁle by typing
logclose.
5.5.3
Multi–state models
To estimate the multi–state models presented in Subsection 4.4.2 we again start by creating
a bayesreg object by typing
> bayesreg ms
To store the results in the directory c:\data and to specify ms as a base ﬁlename we enter
the command

5.5 Bayesreg objects
127
id
identiﬁcation number of subject
beg
time of transition to the current state (admission time)
end
time of transition to the next state (emission time)
tas
1 a transition AWAKE→SLEEP is observed at t = end
0 else
tsa
1 a transition SLEEP→AWAKE is observed at t = end
0 else
trn
1 a transition REM→NREM is observed at t = end
0 else
tnr
1 a transition NREM→REM is observed at t = end
0 else
st
1 subject is currently in state AWAKE
2 subject is currently in state NREM
3 subject is currently in state REM
cort
cortisol level in nmol/l
Table 5.1: Original variables of the dataset object sleep.

128
5. Bayesian survival and multi–state analysis with BayesX: a tutorial
> ms.outfile = c:\data\ms
A log ﬁle where the contents of the output window are stored is then opened by
> logopen, replace using c:\data\humansleep_log.txt
The original variables of the dataset object sleep are summarized and explained in Table
5.1. The additional dummy coded covariate corthigh, which indicates whether or not the
cortisol secretion is higher than 90 nmol/l is generated by typing
> sleep.generate corthigh = (cort>90)
Now the ﬁrst lines of the dataset object sleep are given by
id
st
beg
end
tas tsa trn tnr cort corthigh
1
2
0
1
0
1
0
0
52.6
0
1
1
1
5
1
0
0
0
52.6
0
1
2
5
8
0
1
0
0
52.6
0
1
1
8
10
1
0
0
0
52.6
0
1
2
10
36
0
0
0
0
52.6
0
1
2
36
76
0
0
0
0
46.9
0
1
2
76
108
0
0
0
1
47.5
0
1
3
108
109
0
0
1
0
47.5
0
1
2
109
110
0
0
0
1
47.5
0
1
3
110
111
0
0
1
0
47.5
0
1
2
111
115
0
0
0
1
47.5
0
1
3
115
116
0
0
0
0
47.5
0
1
3
116
126
0
0
1
0
37.4
0
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
Note that the states have to be numbered consecutively from 1 to H, at which numbers are
exchangeable. Since we are considering continuous time scales, an observation should start
at t = 0 (unless the observation is left truncated) and the variables beg and end should
be generated so that within each observation process beg equals the value of end in the
previous row (unless observations are fragmentary only).

5.5 Bayesreg objects
129
The transition rates of the multi–state model analyzed in Subsection 4.4.2 are given by
λh
=
exp (gh0(t) + bh) ,
h = AS, SA, RN
λh
=
exp (gh0(t) + c(t) · gh1(t) + bh) ,
h = NR
This model is estimated with BayesX by entering the following command
> ms.mregress tas = end(baseline) + id(random):
tsa = end(baseline) + id(random):
trn = end(baseline) + id(random):
tnr = end(baseline) + corthigh*end(baseline) + id(random),
family=multistate begin=beg state=st iterations=30000 burnin=10000
step=20 using sleep
Note that the command regress used with the estimation of Cox models (and other
models with univariate response) is now replaced by the command mregress which is used
to analyze models with multivariate responses. With family=multistate BayesX expects
the speciﬁcation of at least two transitions separated by a colon, at which the corresponding
0–1 coded transition indicators are to be entered on the left side of the equals sign. With
the command above BayesX assumes cubic P–spline priors with 20 knots and second
order random walk priors for the log–baseline eﬀects as well as the time–varying eﬀect of
corthigh, diﬀuse priors for the ﬁxed eﬀects of sex and i.i.d. Gaussian priors with mean
zero for each individual and transition speciﬁc random eﬀect. With iterations=30000
the simulation run time is about 160 minutes (Pentium 4 CPU 2.8 GHz). Concerning the
state structure, BayesX assumes that an observation with current state st is at risk of
experiencing a transition of type h if the data set contains at least one type h transition
with the accordant state st. For checking purposes the following matrix, that indicates
the number of type h transitions observed with every single state, is printed in the output
window.

130
5. Bayesian survival and multi–state analysis with BayesX: a tutorial
Matrix of possible transitions:
Transition
1
2
3
4
State
1
460 0
0
0
2
0
399 0
306
3
0
77
234 0
Again, additionally to the information being printed to the output window results for each
eﬀect are written to external ASCII ﬁles, with the names of these ﬁles being given in
the output window. Having ﬁnished the estimation we may close the log ﬁle by typing
logclose.
5.6
Post estimation commands
Bayesreg objects provide some post estimation commands to get sampled parameters or to
plot autocorrelation functions of sampled parameters. For example
> surv_m8.plotautocor, maxlag=250
computes the autocorrelation functions for all parameters estimated with the regress
command (lastly) entered with the bayesreg object surv_m8. Here verb+maxlag+ speciﬁes
the maximum lag number.
If the number of parameters is large this may be computationally expensive, so BayesX
provides a second possibility to compute autocorrelation functions. Adding the option
mean to the plotautocor command as in
> surv_m8.plotautocor, mean
leads to the computation of only the minimum, mean and maximum autocorrelation
functions.
Note, that executing the plotautocor command also stores the computed autocorrelation
functions in a ﬁle named autocor.raw in the output directory of the bayesreg object.

5.6 Post estimation commands
131
To save memory, the sampling paths of the estimated parameters are only stored tem-
porarily by default and will be destroyed, when the corresponding bayesreg object is deleted.
If we want to store the sampling paths permanently, we have to execute the getsample
command
> surv_m8.getsample
which stores the sampled parameters in ASCII ﬁles in the output directory. To avoid
too large ﬁles, the samples are typically partitioned into several ﬁles.

132
5. Bayesian survival and multi–state analysis with BayesX: a tutorial

Appendix A
Calculation of IWLS weights
A.1
Geoadditive survival analysis
In Subsection 2.3.1, which is concerned with Bayesian inference for geoadditive survival
models, we describe how to update parameter vectors corresponding to time–independent
eﬀects by an MH–algorithm based on IWLS proposals. The IWLS weights wi and working
observations ˜yi used with this algorithm are derived as follows.
As speciﬁed in equation (2.4) the geoadditive predictor of our survival models is given by
ηi(t) = g0(t) +
p
X
j=1
gj(t)zij +
q
X
j=1
fj(xij) + fspat(si) + v′
iγ + bgi.
Suppose for example we want to update the parameter vector βj = (βj1, . . . , βj,dj)′ corre-
sponding to a time–independent function fj(xij), which is modelled by a P–spline. With
the generic notation of Subsection 2.2.1 this function may be written as
fj(xij) =
dj
X
m=1
βjmBm(xij) = Zjiβj
with Bm denoting B–spline basis functions and Zji =
 B1(xij), . . . , Bdj(xij)

denoting the
i–th row of the design matrix Zj introduced in Subsection 2.2.1. The predictor ηi(t) and
the vector of predictors η = (η1(t1), . . . , ηn(tn))′, respectively, may now be rewritten as
ηi(t) = Zjiβj + ˜ηi(t),
η = Zjβj + ˜η

134
A. Calculation of IWLS weights
The following proportionality holds for the full conditional of βj
p(βj|·) ∝L(βj) · p(βj|τ 2
j )
(A.1)
with the ﬁrst factor denoting the likelihood that depends among others upon βj and the
second factor denoting the prior of βj. The dependency of the likelihood on βj may be
expressed as follows
L(βj)
=
n
Y
i=1
λi(ti)δi · exp

−
Z ti
0
λi(u)du

=
exp
" n
X
i=1

δiηi(t) −
Z ti
0
exp(ηi(u))du
#
=
exp
" n
X
i=1

δi(Zjiβj + ˜ηi(t)) −
Z ti
0
exp(Zjiβj + ˜ηi(u))du
#
=
exp
" n
X
i=1
li(βj)
#
= exp

l(βj)

with li denoting the individual log–likelihood. As speciﬁed in equation (2.7), the general
form of a prior for βj is
p(βj|τ 2
j ) ∝τ
−rj
j
exp

−1
2τ 2
j
β′
jKjβj

,
Suppose the current value of the chain is βc
j. Then a new value βp
j is proposed by drawing
a random vector from a multivariate Gaussian proposal distribution, which is obtain from
a quadratic approximation of the log–likelihood by a second order Taylor expansion with
respect to βc
j given by
l(βp
j) ≈l(βc
j) + (βp
j −βc
j)′s(βc
j) + 1
2(βp
j −βc
j)′H(βc
j)(βp
j −βc
j)
(A.2)
at which s and H are the score function and the Hessian matrix (with respect to βj),
respectively. Inserting (A.2) in (A.1) yields

A.1 Geoadditive survival analysis
135
p(βp
j|·)
∝
exp

l(βp
j) −1
2β′
j
Kj
τ 2
j
βj

≈
exp

(βp
j)′s(βc
j) + 1
2(βp
j)′H(βc
j)βp
j −(βp
j)′H(βc
j)βc
j −1
2(βp
j)′Kj
τ 2
j
βp
j

=
exp

(βp
j)′s(βc
j) + 1
2(βp
j)′H(βc
j)βp
j −(βp
j)′H(βc
j)βc
j −1
2(βp
j)′Kj
τ 2
j
βp
j

=
exp

−1
2(βp
j)′

−H(βc
j) + Kj
τ 2
j

βp
j + (βp
j)′  s(βc
j) −H(βc
j)βc
j

which is proportional to a multivariate Gaussian distribution with precision matrix and
mean
Pj = −H(βc
j) + Kj
τ 2
j
,
mj = (Pj)−1  s(βc
j) −H(βc
j)βc
j

.
(A.3)
For the calculation of Pj and mj we need to compute the score function s and the Hessian
matrix H. The score function s is given by
s(βj) =
 n
X
i
∂li(βj)
∂βj1
, . . . ,
n
X
i
∂li(βj)
∂βj,dj
!′
with
li(βj)
=
δi(Zjiβj + ˜ηi(t)) −
Z ti
0
exp(Zjiβj + ˜ηi(u))du
=
δiZjiβj + δi˜ηi(t) −exp(Zjiβj)
Z ti
0
exp(˜ηi(u))du
and thus
∂li(βj)
∂βjm
=
δiZjim −Zjim exp(Zjiβj)
Z ti
0
exp(˜ηi(u))du
=
δiZjim −Zjim
Z ti
0
exp(ηi(u))du
at which Zjim is the element in the i–th row and m–th column of the design matrix Zj.
Hence the score vector s(βj) is given by
s(βj) = Z′
j∆−Z′
j ˜
W(βj)
(A.4)

136
A. Calculation of IWLS weights
at which ∆= (δ1, . . . , δn)′ and ˜
W = (w1, . . . , wn)′ with
wi =
Z ti
0
exp(ηi(u))du = Λi(ti).
(A.5)
The Hessian matrix H is deﬁned as follows
H(βj) =
 n
X
i=1
∂li(βj)
∂βjm∂βjk
!
m,k=1,...,dj
Computing the partial derivatives delivers
∂li(βj)
∂βjm∂βjk
= −ZjimZjik
Z ti
0
exp(ηi(u))du
leading to
H(βj) = −Z′
jW(βj)Zj
(A.6)
with the weight matrix W = diag(w1, . . . , wn) with wi as deﬁned in (A.5).
Inserting (A.4) and (A.6) in (A.3) yields
Pj
=
Z′
jW(βc
j)Zj + Kj
τ 2
j
mj
=
(Pj)−1 
Z′
j∆−Z′
j ˜
W(βc
j) + Z′
jW(βc
j)Zjβc
j

=
(Pj)−1Z′
jW(βc
j)
 W−1(βc
j)∆−1l + Zjβc
j

=
(Pj)−1Z′
jW(βc
j)
 W−1(βc
j)∆−1l + η −˜η

=
(Pj)−1Z′
jW(βc
j) (˜y −˜η)
with the n–dimensional vector of working observations
˜y = W−1(βc
j)∆−1l + η =

η1(t1) + δ1
w1
−1, . . . , ηn(tn) + δn
wn
−1
′

A.2 Relative survival analysis
137
A.2
Relative survival analysis
As mentioned in Section 3.3 updating of parameter vectors βj corresponding to time–
independent eﬀects within a relative survival model is performed according to the same
principle as described above for crude survival models. However, as a consequence of the
slightly more complex likelihood the weights and working observations that are used within
the IWLS–MH algorithm are slightly more complex as well. Using the results of (A.3) those
quantities are derived as follows.
For updating the parameter vector βj again consider the following decomposition of ηi(t) =
log (λc
i(t)) and η = (η1(ti), . . . , ηn(tn))′, respectively
ηi(t) = Zjiβj + ˜ηi(t),
η = Zjβj + ˜η
With λi = λe
i + λc
i, where λe
i := λe
i(ai + ti) denotes the expected hazard and λc
i = λc
i(ti)
denotes the disease related hazard, it can be seen easily from (3.3) that the individual
log–likelihood li(βj) is given by
li(βj)
=
δi log (λe
i + λc
i) −
Z ti
0
λe
i(ai + u)du −
Z ti
0
λc
i(u)du
=
δi log
 λe
i + exp
 Zjiβj + ˜ηi(ti)

−
Z ti
0
λe
i(ai + u)du −
Z ti
0
exp
 Zjiβj + ˜ηi(u)

du
=
δi log
 λe
i + exp
 Zjiβj

exp (˜ηi(ti))

−
Z ti
0
λe
i(ai + u)du −exp
 Zjiβj
 Z ti
0
exp (˜ηi(u)) du
Hence the partial derivative is given by
∂li(βj)
∂βjm
=
δi
λe
i + λc
i
Zjim exp
 Zjiβj

exp (˜ηi(ti))
−0 −Zjim exp
 Zjiβj
 Z ti
0
exp (˜ηi(u)) du
=
δiλc
i
λe
i + λc
i
Zjim −Zjim
Z ti
0
λc
i(u)du

138
A. Calculation of IWLS weights
and thus we get
s(βj) = Z′
j∆−Z′
j ˜
W
(A.7)
with ∆=

δ1λc
1
λe
1+λc
1, . . . ,
δnλc
n
λen+λcn
′
and ˜
W = ( ˜w1, . . . , ˜wn)′ with
˜wi =
Z ti
0
λc
i(u)du = Λc
i(ti)
(A.8)
By means of the quotient rule the elements of the Hessian matrix H are computed as
follows
∂li(βj)
∂βjm∂βjk
=
(λe
i + λc
i) ∂δiλc
iZjim
∂βjk
−δiλc
iZjim
∂λe
i +λc
i
∂βjk
(λe
i + λc
i)2
−ZjimZjik
Z ti
0
λc
i(u)du
=
(λe
i + λc
i) δiZjimZjikλc
i −δiλc
iZjimZjikλc
i
(λe
i + λc
i)2
−ZjimZjik
Z ti
0
λc
i(u)du
=
λe
iδiZjimZjikλc
i
(λe
i + λc
i)2
−ZjimZjik
Z ti
0
λc
i(u)du
=
Zjim
λe
iλc
iδi
(λe
i + λc
i)2Zjik −Zjim
Z ti
0
λc
i(u)duZjik
=
−Zjim
Z ti
0
λc
i(u)du −
λe
iλc
iδi
(λe
i + λc
i)2

Zjik
The Hessian matrix H may now be written as
H(βj) = −Z′
jWZj
(A.9)
with W = diag(w1, . . . , wn) at which
wi = ˜wi −
λe
iλc
iδi
(λe
i + λc
i)2 = Λc
i(ti) −λe
iλc
iδi
λ2
i
Inserting (A.7) and (A.9) in (A.3) yields the precision matrix and the mean of the Gaussian
proposal density for βp
j as well as the working observations ˜y, which are derived as follows

A.2 Relative survival analysis
139
mj
=
(Pj)−1  s(βc
j) −H(βc
j)βc
j

=
(Pj)−1 
Z′
j∆−Z′
j ˜
W(βc
j) + Z′
jW(βc
j)Zjβc
j

=
(Pj)−1Z′
jW(βc
j)

W−1(βc
j)∆−W−1(βc
j) ˜
W(βc
j) + Zjβc
j

=
(Pj)−1Z′
jW(βc
j)

W−1(βc
j)

∆−˜
W(βc
j)

+ η −˜η

=
(Pj)−1Z′
jW(βc
j) (˜y −˜η)
with ˜y = (˜y1, . . . , ˜yn), at which
˜yi = ηi(ti) + δiλc
i/λi −˜wi
wi
.

140
A. Calculation of IWLS weights

Bibliography
Andersen, P.K., Borgan, ∅., Gill, R.D., and Keiding, N. (1993), Statistical models based on
counting processes, New York: Springer.
Andersen, P.K., and Keiding, N. (2002), ”Multi–state models for event history analysis,”
Statistical Methods in Medical Research, 11, 91–15.
Banerjee, S., and Carlin, B.P. (2003), ”Semiparametric Spatiotemporal Frailty Modelling,”
Environmetrics, 14, 523–535.
Banerjee, S., and Carlin, B.P. (2004), ”Parametric Spatial Cure Rate Models for Interval–
Cencored Time–to–Relapse Data,” Biometrics, 60, 268–275.
Banerjee, S., Carlin, B.P., and Gelfand, A.E. (2004), Hierarchical Modeling and Analysis
for Spatial Data, Chapman and Hall/CRC, Boca Raton.
Banerjee, S., Wall, M. M., and Carlin, B. P. (2003), ”Frailty modeling for spatially corre-
lated survival data, with application to infant mortality in Minnesota,” Biostatistics,
4, 123–142.
Bender, R., Augustin, T., and Blettner, M. (2005), ”Generating survival times to simulate
Cox proportional hazards models,” Statistics in Medicine, 24, 1713–1723.
Besag, J. and Kooperberg, C. (1995), ”On Conditional and Intrinsic Autoregressions,”
Biometrika, 82, 733–746.
Blossfeld, H.-P., Hamerle, A., and Mayer, K.U. (1989). Event History Analysis. Hillsdale,
N.J.: Lawrence Erlbaum Associates.
Bolard, P., Quantin, C., Esteve, J., Faivre, J., and Abrahamowicz, M. (2001), ”Mod-
elling time–dependent hazard ratios in relative survival: Application to colon cancer,”
Journal of Clinical Epidemiology, 54, 986–996.

142
BIBLIOGRAPHY
Brezger, A., Kneib, T., and Lang, S. (2005), ”BayesX: Analysing Bayesian Semiparametric
Regression Models,” Journal of statistical software, Vol. 14, Issue 11. Open domain
software available from http://www.stat.uni-muenchen.de/~bayesx/.
Brezger, A., and Lang, S. (2006), ”Generalized structured additive regression based on
Bayesian P–splines,” Computational Statistics and Data Analysis, 50, 967–991.
Cai, T., and Betensky, R. A. (2003), ”Hazard Regression for Interval Censored Data with
Penalized Spline,” Biometrics, 59, 570–9.
Cai, T., Hyndman, R., and Wand, M. (2002), ”Mixed model-based hazard estimation,”
Journal of Computational and Graphical Statistics, 11, 784–798.
Carlin, B. P., and Banerjee, S. (2002), ”Hierarchical Multivariate CAR Models for Spatio–
Temporally Correlated Data,” In: Bayesian Statistics 7, eds. J.M. Bernardo et al.,
Oxford: Oxford University Press.
Cox, D.R. (1972), ”Regression models and life tables,” Journal of the Royal Statistical
Society, Series B, 34, 187–220.
Crook, A., Knorr-Held, L., and Hemingway, H. (2003), ”Measuring spatial eﬀects in time
to event data: a case study using months from angiography to coronary artery bypass
graft (CABG),” Statistics in Medicine, 22, 2943–2961.
Czado, C., and Rudolph, F. (2002), ”Application of survival analysis methods to long–term
care insurance,” Insurance: Mathematics and Economics, 31 (3), 395–413.
De Boor, C. (2001), A practical guide to Splines, New York.
Devroye L. (1986), Non–uniform random variate generation, New York: Springer.
Eilers, P.H.C., and Marx, B.D. (1996), ”Flexible smoothing using B-splines and penalized
likelihood” (with comments and rejoinder), Statistical Science, 11 (2), 89–121.
Esteve, J., Benhamou, E., Croasdale, M., and Raymond, L. (1990), ”Relative Survival and
the estimation of net survival: elements for further discussion,” Statistics in Medicine,
9, 529–538.
Fahrmeir, L., and Klinger, A. (1998), ”A nonparametric multiplicative hazard model for
event history data,” Biometrika, 85(3), 581–592.

BIBLIOGRAPHY
143
Fahrmeir, L., and Lang, S. (2001a), ”Bayesian Inference for Generalized Additive Mixed
Models Based on Markov Random Field Priors,” Journal of the Royal Statistical So-
ciety, Ser. C, 50, 201–220.
Fahrmeir, L., and Lang, S. (2001b), ”Bayesian semiparametric regression analysis of mul-
ticategorical time–space data,” Annals of the Institute of Statistical Mathematics, 53,
11–30.
Fahrmeir, L., Lang, S.,Wolﬀ, J., and Bender, S. (2003), ”Semiparametric Bayesian Time-
Space Analysis of Unemployment Duration,” Journal of the German Statistical Society
(Allgemeines Statistisches Archiv), 87, 281–307.
Fahrmeir, L., and Tutz, G. (2001), Multivariate Statistical Modelling based on Generalized
Linear Models, Springer–Verlag, New York.
Gamerman, D. (1997), ”Eﬃcient Sampling from the Posterior Distribution in Generalized
Linear Models,” Statistics and Computing, 7, 57–68.
Gelfand, A.E., and Gosh, S.K. (1998), ”Model Choice: A Minimum Posterior Predictive
Loss Approach,” Biometrika, 85, 1–11.
Gelman, A. (2004), ”Prior distributions for variance parameters in hierarchical models,”
provided by Economics Working Paper Archive at WUSTL in its series Econometrics
with number 0404001.
George, A. and Liu, J.W. (1981), Computer Solution of Large Sparse Positive Deﬁnite
Systems, Prentice–Hall.
Giorgi, R., Abrahamowicz, M., Quantin, C., Bolard, P., Esteve, J., Gouvernet, J. and
Faivre, J. (2003), ”A relative survival regression model using B–spline functions to
model non–proportional hazards,” Statistics in Medicine, 22, 2767–2784.
Gould, A., and Lawless, J.F. (1988), ”Estimation Eﬃciency in Lifetime Regression Models
when Responses are Censored or Grouped,” Comm. Statist. Simul., 17, 689–712.
Henderson, R., Shimakura, S., and Gorst, D. (2002), ”Modeling Spatial Variation in
Leukemia Survival Data,” Journal of the American Statistical Assosiation, 97, 965–
972.
Hennerfeind, A., Brezger, A., and Fahrmeir, L. (2005), ”Geoadditive Survival Models: A
Supplement,” SFB 386 Discussion Paper 454, University of Munich. Available from
http://www.stat.uni-muenchen.de/sfb386/.

144
BIBLIOGRAPHY
Hennerfeind, A., Brezger, A., and Fahrmeir, L. (2005), ”Geoadditive Survival Models,”
Journal of the American Statistical Association, Theory and Methods, to appear.
Ibrahim, J.G., Chen, M.H., and Sinha, D. (2001), Bayesian Survial Analysis. Springer
Series in Statistics, New York.
Kaempchen, S., Guenther, T., Toschke, M., Grunkemeier, G.L., Wottke, m., and Lange,
R. (2003), ”Assessing the beneﬁt of biological valve prostheses: cumulative incidence
(actual) vs. Kaplan–Meier (actuarial) analysis,” European Journal of Cardio–thoracic
Surgery, 23, 710–714.
Kalbﬂeich, J. and Prentice, R. (2002). The Statistical Analysis of Failure Time Data, 2nd
edition. Hoboken: John Wiley & Sons.
Kammann, E.E., and Wand, M.P. (2003), ”Geoadditive models,” Journal of the Royal
Statistical Society, Ser. C, 52, 1–18.
Klein, J.P. and Moeschberger, M.L. (2003). Survival analysis. Springer, New York.
Kneib, T. (2006). Mixed model based inference in structured additive regression. PhD thesis,
Dr. Hut Verlag.
Kneib, T. and Fahrmeir, L. (2004), ”A mixed model approach for structured hazard
regression,” SFB 386 Discussion Paper 400, University of Munich. Available from
http://www.stat.uni-muenchen.de/sfb386/, accepted for publication in the Scan-
dinavian Journal of Statistics.
Kneib, T. and Fahrmeir, L. (2005), ”Structured additive regression for multicategorical
space-time data: A mixed model approach,” Biometrics, to appear.
Knorr–Held, L. (1999), ”Conditional Prior Proposals in Dynamic Models,” Scandinavian
Journal of Statistics, 26, 129–144.
Kom´arek, A., Lesaﬀre, E., and Hilton, J.F. (2005), ”Accelerated failure time model for
arbitrarly censored data with smoothed error distribution,” Journal of Computational
and Graphical Statistics, 45, 726–745.
Lang, S., and Brezger, A. (2004), ”Bayesian P–splines,” Journal of Computational and
Graphical Statistics, 13, 183–212.
Lawless, J.F. (1982), Statistical Models and Methods for Lifetime Data. New York: Wiley.

BIBLIOGRAPHY
145
Lesaﬀre, E., Kom´arek, A., and Declerck, D. (2004), ”An overview of methods for interval–
censored data with an emphasis on applications in dentistry,” Technical report 0453,
IAP network. Available from http://www.stat.ucl.ac.be/IAP.
Lewis, P. A. W. and Shedler, G. S. (1979), ”Simulation of nonhomogeneous Poisson
processes by thinning,” Naval Research Logistics Quarterly, 26, 403–414.
Li, Y., and Ryan, L. (2002), ”Modeling Spatial Survival Data Using Semiparametric Frailty
Models,” Biometrics, 58, 287–297.
Marx, B.D., and Eilers, P. (1998), ”Direct Generalized Additive Modeling with Penalized
Likelihood,” Computational Statistics and Data Analysis, 28, 193–209.
Percy, C.L., Stanek, E., and Gloeckler, L. (1981), ”Accuracy of cancer death certiﬁcates
and its eﬀect on cancer mortality statistics,” American Journal of Public Health, 71,
242–250.
Rue, H. (2001), ”Fast sampling of Gaussian Markov random ﬁelds,” Journal of the Royal
Statistical Society, Ser. B, 63, 325–338.
Sauleau, E.-A., Hennerfeind, A., Buemi, A., and Held, L. (2006), ”Age, period and cohort
eﬀects in Bayesian smoothing of spatial cancer survival with geoadditive models,”
Statistics in Medicine, to appear.
Spiegelhalter, D.J., Best, N.G., Carlin, B.P., and van der Linde, A. (2002), ”Bayesian
measures of model complexity and ﬁt” (with discussion and rejoinder), Journal of the
Royal Statistical Society, Ser. B, 64, 583–639.
Stein, M.L. (1999), Interpolation of spatial data. Some theory for kriging, Springer, New
York.
Sun, D., Tsutakawa, R.K. and Speckman, P.L. (1999), ”Posterior distribution of hierarchi-
cal models using CAR(1) distributions,” Biometrika, 86, 341–350.
Sun, D., Tsutakawa, R.K. and He, Z. (2001), ”Propriety of posteriors with improper priors
in hierarchical linear mixed models,” Statistica Sinica, 11, 77–95.
Thompson, W.A.,Jr. (1977), ”On the Treatment of Grouped Observations in Life Studies,”
Biometrics, 33, 463–470.

146

LEBENSLAUF
Andrea Hennerfeind
geboren am 11. August 1976 in Freising
Schulbildung:
1982–1986
Grundschule St. Lantbert in Freising
1986–1995
Josef–Hofmiller–Gymnasium in Freising
(mathematisch–naturwissenschaftlich)
Studium:
1995–2001
Studium der Statistik an der Ludwig–Maximilians–Universit¨at
M¨unchen mit dem Anwendungsgebiet Versicherungswissenschaften
und der speziellen Ausrichtung mathematische Statistik
Sep. 1997
Diplom–Vorpr¨ufung
Mai 2001
Diplom–Hauptpr¨ufung
Beruf:
seit Juli 2001
wissenschaftlicher Mitarbeiter im Sonderforschungsbereich 386
”Statistische Analyse diskreter Strukturen” bei Prof. Dr. L.
Fahrmeir am Institut f¨ur Statistik der
Ludwig–Maximilians–Universit¨at M¨unchen

