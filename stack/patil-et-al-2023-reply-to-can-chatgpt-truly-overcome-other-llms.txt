Letter to the Editor
Canadian Association of
Radiologists’ Journal
2023, Vol. 0(0) 1
© The Author(s) 2023
Article reuse guidelines:
sagepub.com/journals-permissions
DOI: 10.1177/08465371231201379
journals.sagepub.com/home/caj
Reply to: “Can ChatGPT Truly Overcome
Other LLMs?”
Nikhil S. Patil1, Ryan S. Huang2, Christian B. van der Pol3, and
Natasha Larocque4
Thank you for your engagement with our article Dr. Partha
Pratim Ray.1,2 We selected the DXIT examination questions for
our analysis as these cover a broad range of radiology topics
across several domains including neuroradiology, mammogra-
phy, general & physics, nuclear medicine, pediatric radiology,
interventional radiology, gastrointestinal radiology, genitourinary
radiology, cardiac radiology, chest radiology, musculoskeletal
radiology, and ultrasound. It is an inherent limitation of our study
that the results cannot necessarily be extrapolated to other use
cases of ChatGPT or Google Bard. For example, in-depth in-
vestigation of user experience, long-term evaluation of these
chatbots, and use as a patient resource, or a clinical decision-
making aid, could constitute useful areas for future research. Of
course, in the future once large language models (LLMs) are able
to process multimodal input this will open the doors for a variety
of studies, however this is currently not an available feature. The
ethical implications of artiﬁcial intelligence chatbot use in
medicine remains an area that has yet to be fully explored.3 Our
explanation analysis revealed cases where despite obtaining the
correct answer, a chatbot may not provide an explanation ad-
dressing the educational content of the question. Determining
whether LLM’s can be tailored and ﬁne-tuned for speciﬁc use
cases within medicine, such as for use as a trainee study tool, may
also be a future direction for chatbot research. In short, several
good suggestions have been made that were beyond our scope
but may be worthwhile pursuing in future research.
Declaration of Conﬂicting Interests
The author(s) declared no potential conﬂicts of interest with respect to
the research, authorship, and/or publication of this article.
Funding
The author(s) received no ﬁnancial support for the research, au-
thorship, and/or publication of this article.
ORCID iDs
Nikhil S. Patil https://orcid.org/0000-0003-3929-0482
Ryan S. Huang https://orcid.org/0000-0002-3404-5376
Christian B. van der Pol https://orcid.org/0000-0002-1718-2619
Natasha Larocque https://orcid.org/0000-0003-0449-9438
References
1. Ray P. Can ChatGPT truly overcome other LLMs? Can Assoc
Radiol J. Published online 2023.
2. Patil NS, Huang R, van der Pol CB, Larocque N. Comparative
performance of ChatGPT and Bard in a text-based radiology
knowledge assessment. Can Assoc Radiol J. Published online
2023. doi:10.1177/084653712311937
3. Fournier-Tombs E, McHardy J. A medical ethics framework for
conversational artiﬁcial intelligence. J Med Internet Res 2023;25(1):
e43068. https://www.jmir.org/2023/1/e43068. doi:10.2196/43068
1 Michael G. DeGroote School of Medicine, McMaster University, Hamilton, ON, Canada
2 Temerty Faculty of Medicine, University of Toronto, Toronto, ON, Canada
3 Department of Diagnostic Imaging, Juravinski Hospital and Cancer Centre, Hamilton Health Sciences, Hamilton, ON, Canada
4 Department of Radiology, McMaster University, Hamilton, ON, Canada
Corresponding Author:
Nikhil S. Patil, Department of Radiology, Hamilton General Hospital, 237 Barton St., East Hamilton, ON L8L 2X2, Canada.
Email: nikhil.patil@medportal.ca

