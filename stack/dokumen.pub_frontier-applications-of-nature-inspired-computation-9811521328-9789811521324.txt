Mahdi Khosravy
Neeraj Gupta
Nilesh Patel
Tomonobu Senjyu Editors
Springer Tracts in Nature-Inspired Computing
Frontier Applications 
of Nature Inspired 
Computation

Springer Tracts in Nature-Inspired Computing
Series Editors
Xin-She Yang, School of Science and Technology, Middlesex University,
London, UK
Nilanjan Dey, Department of Information Technology, Techno India College of
Technology, Kolkata, India
Simon Fong, Faculty of Science and Technology, University of Macau, Macau,
Macao

The book series is aimed at providing an exchange platform for researchers to
summarize the latest research and developments related to nature-inspired
computing in the most general sense. It includes analysis of nature-inspired
algorithms and techniques, inspiration from natural and biological systems,
computational mechanisms and models that imitate them in various ﬁelds, and
the applications to solve real-world problems in different disciplines. The book
series addresses the most recent innovations and developments in nature-inspired
computation, algorithms, models and methods, implementation, tools, architectures,
frameworks, structures, applications associated with bio-inspired methodologies
and other relevant areas.
The book series covers the topics and ﬁelds of Nature-Inspired Computing,
Bio-inspired
Methods,
Swarm
Intelligence,
Computational
Intelligence,
Evolutionary Computation, Nature-Inspired Algorithms, Neural Computing, Data
Mining, Artiﬁcial Intelligence, Machine Learning, Theoretical Foundations and
Analysis, and Multi-Agent Systems. In addition, case studies, implementation of
methods and algorithms as well as applications in a diverse range of areas such as
Bioinformatics, Big Data, Computer Science, Signal and Image Processing,
Computer Vision, Biomedical and Health Science, Business Planning, Vehicle
Routing and others are also an important part of this book series.
The series publishes monographs, edited volumes and selected proceedings.
More information about this series at http://www.springer.com/series/16134

Mahdi Khosravy
• Neeraj Gupta
•
Nilesh Patel
• Tomonobu Senjyu
Editors
Frontier Applications
of Nature Inspired
Computation
123

Editors
Mahdi Khosravy
Media Integrated Communication Lab
Graduate School of Engineering
Osaka University
Osaka, Japan
Neeraj Gupta
Department of Computer Science
and Engineering
Oakland University
Rochester, MI, USA
Nilesh Patel
Department of Computer Science
and Engineering
Oakland University
Rochester, MI, USA
Tomonobu Senjyu
Department of Electrical and Electronics
Engineering, Faculty of Engineering
University of the Ryukyus
Nishihara, Japan
ISSN 2524-552X
ISSN 2524-5538
(electronic)
Springer Tracts in Nature-Inspired Computing
ISBN 978-981-15-2132-4
ISBN 978-981-15-2133-1
(eBook)
https://doi.org/10.1007/978-981-15-2133-1
© Springer Nature Singapore Pte Ltd. 2020
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part
of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations,
recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and transmission
or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar
methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this
publication does not imply, even in the absence of a speciﬁc statement, that such names are exempt from
the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this
book are believed to be true and accurate at the date of publication. Neither the publisher nor the
authors or the editors give a warranty, expressed or implied, with respect to the material contained
herein or for any errors or omissions that may have been made. The publisher remains neutral with regard
to jurisdictional claims in published maps and institutional afﬁliations.
This Springer imprint is published by the registered company Springer Nature Singapore Pte Ltd.
The registered company address is: 152 Beach Road, #21-01/04 Gateway East, Singapore 189721,
Singapore

Preface
Nowadays, as industries and real-life routines face more and more complicated
problems, there is a special need for stronger computation techniques with the
ability of providing fast and accurate solution. Problems grow complexity, non-
linearity as well as there is a great lack of information about the conditions, limi-
tation and the physical rules governing new technological aspects. Even if there was
not such a lack of knowledge and information about several hidden layers of the
problems, the numerous aspects, multiple formulations and nonlinearity of equa-
tions, all together make a wild nature of the problems which require methodologies
beyond the known classic computations. As from very ancient time, the mother of
nature had been being the greatest inspiring teacher for the human, now at this
modern era, natural phenomena as well inspire the scientists for meta-heuristic
computation techniques for efﬁciently solving the complex problems. Through
mimicking the natural phenomena, during the last two decades, a variety of
nature-inspired computational techniques have been invented, and a considerable
efﬁciency by these techniques has gained. A variety of problems have been man-
aged and solved by these techniques, and as nature-inspired computation is applied
to non-convex, nonlinear, incomplete informed problems, researchers focus on
three targets for (i) increasing the accuracy of the techniques, (ii) increasing the
speed as equivalently ﬁnding ways for reducing the complexity of the operators
(iii) and ﬁnally implementing these techniques on real-life applications.
This book gives some of the frontier edge theory and applications of
nature-inspired computation (NIC) in a wide range from electrical energy trans-
mission expansion planning to robotics and fault detection in agriculture machinery.
Accordingly, this book comprises 17 chapters as follows. In Chap. 1 Helmi and
Lotfy, after listing the famous classic NIC techniques and having a brief view of
newer techniques, give a review of the most recent six NIC techniques of 2018 and
2019. As the strategy of incorporating the prediction of a moving optimum
according to a priori information in optimization process has gained attention in
recent years, in Chap. 2 Meier and Kramer introduce the foundations of
prediction-based dynamic optimization with nature-inspired methods. They present
benchmark sets and quality measures and give insight into mechanisms to employ
v

predictions in evolution strategy and particle swarm optimization-based search.
Further, they show how predictive uncertainty information allows the optimizer to
explore regions with higher predictive uncertainty more extensively. Chapter 3
gives a descriptive tutorial to the very recent plant biology-inspired optimization
technique. The chapter contains illustrative ﬁgures and algorithm structure details
of the optimizer. In Chap. 4 Pei presents some new trends in ﬁtness landscape
analysis in evolutionary computation and meta-heuristic study. The ﬁtness land-
scape concept is brought from that of evolutionary biology that attempts to present
and visualize the relationship between genotype and its success. Evolutionary
computation algorithm utilizes this concept to describe the success of an optimized
variable. It takes a bridge between the evolutionary computation algorithm and its
optimizing problem. In Chap. 5 Rajakumar presents the biological motivation from
the lion’s behavior and its interpretation to the lion algorithm. The chapter brieﬂy
discusses the ﬁrst version of the algorithm followed by its detailed description with
illustration. Subsequently, the chapter discusses the performance accomplishments
of the LA in solving different benchmark suites as well as notable applications with
problem formulations. In Chap. 6 Zamani and Amirghasemi present a self-adaptive
search procedure for solving the quadratic assignment problem, exploring the
structure of the problem through regular interchanges of facilities made by a linear
assignment technique. The quadratic assignment problem has been traditionally
introduced as a mathematical model related to economic activities, modeling many
real-world problems from making optimal arrangement of machines in factories to
ﬁnd the best location of departments within plants. The biological systems consist
of self-adaptive mechanisms, and such self-adaptivity can inspire computer scien-
tists to use the same mechanism in their algorithms. In Chap. 7 Rebello and Oliveira
present applications of the meta-heuristic known as grey wolf optimizer (GWO) to
solve the NP-hard transmission network expansion planning (TNEP) problem. In
addition, in Chap. 8 Khosravy et al. study the searching behavior of the very recent
Mendelian evolutionary theory optimizer by tracing the points in search space. In
Chap. 9 Chatterjee et al. propose a novel meta-heuristic optimization algorithm by
employing the concept of artiﬁcial cells, which are inspired by biological living
cells. An efﬁcient application of artiﬁcial cell division (ACD) algorithm has been
employed to traverse the search space while decreasing the search time. In Chap. 10
Takano et al. introduce problem frameworks to determine coordinated operation
schedules of microgrid components including controllable generation systems
(CGs), energy storage systems (ESSs) and controllable loads (CLs). Discussions
of the problem frameworks include electricity trade with the conventional power
grids and uncertainty originated from variable renewable energy sources and/or
electric consumption. As the basis of the solution method, particle swarm opti-
mization (PSO) has been deployed. In Chap. 11 Duque et al. present the applica-
tions of the bio-inspired metaheuristic known as monkey search (MS) to the
planning of electrical energy distribution systems (EEDS). The technique is
inspired by the behavior of a monkey searching for food in a jungle through
movements of climbing trees.
vi
Preface

In Chap. 12 Gupta et al. discuss the training of artiﬁcial neural network by the
recent technique of plant biology-inspired optimizer. In Chap. 13 Fister et al.
propose a new method for evolving classiﬁcation pipelines automatically, founded
on stochastic nature-inspired population-based optimization algorithms. Chapter 14
reviews fourteen state-of-the-art nature-inspired optimizers and compares their
efﬁciency in training on an artiﬁcial neural network for fault detection in the
hydraulic system of agriculture machinery. In Chap. 15 Panoeiro et al. compare the
performance of the bat algorithm, grey wolf optimizer and sine cosine algorithm in
optimization problem consists of determining the optimal wind farm layout con-
ﬁguration with the objectives of maximizing the extracted power while minimizing
the costs related to the project. In Chap. 16 Mandava and Vundavilli develop an
adaptive neural network algorithm to tune the gains of the PID controller and
propose the modiﬁed chaotic invasive weed optimization (MCIWO) algorithm to
train the weights of the neural network (NN). Finally, in Chap. 17 Firmino et al.
optimize the crane operating time by ant colony optimization.
In a nutshell, this book provides cutting-edge research works in the NIC theory
and applications. A wide range of algorithms have been introduced and applied to
the advanced problems in real life and industries. We are thankful to all the con-
tributors for their valuable contributions. In addition, we are thankful to the book
series editor for endless support. Last but not least, no words can express our
sincere gratitude to the team members of Springer, who are always supportive as
usual.
Osaka, Japan
Mahdi Khosravy
Michigan, USA
Neeraj Gupta
Michigan, USA
Nilesh Patel
Okinawa, Japan
Tomonobu Senjyu
Preface
vii

Contents
1
Recent Advances of Nature-Inspired Metaheuristic
Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
Ahmed Mohamed Helmi and Mohammed Elsayed Lotfy
2
Prediction in Nature-Inspired Dynamic Optimization . . . . . . . . . . .
34
Almuth Meier and Oliver Kramer
3
Plant Genetics-Inspired Evolutionary Optimization:
A Descriptive Tutorial . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
Neeraj Gupta, Mahdi Khosravy, Nilesh Patel, Om Prakash Mahela,
and Gazal Varshney
4
Trends on Fitness Landscape Analysis in Evolutionary
Computation and Meta-Heuristics . . . . . . . . . . . . . . . . . . . . . . . . .
78
Yan Pei
5
Lion Algorithm and Its Applications. . . . . . . . . . . . . . . . . . . . . . . .
100
B. R. Rajakumar
6
A Self-adaptive Nature-Inspired Procedure for Solving
the Quadratic Assignment Problem . . . . . . . . . . . . . . . . . . . . . . . .
119
Reza Zamani and Mehrdad Amirghasemi
7
Modiﬁed Binary Grey Wolf Optimizer . . . . . . . . . . . . . . . . . . . . . .
148
Gustavo Rebello and Edimar José de Oliveira
8
Tracing the Points in Search Space in Plant Biology Genetics
Algorithm Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
180
Mahdi Khosravy, Neeraj Gupta, Nilesh Patel, Om Prakash Mahela,
and Gazal Varshney
9
Artiﬁcial Cell Swarm Optimization . . . . . . . . . . . . . . . . . . . . . . . . .
196
Sankhadeep Chatterjee, Subham Dawn, and Sirshendu Hore
ix

10
Application Example of Particle Swarm Optimization
on Operation Scheduling of Microgrids . . . . . . . . . . . . . . . . . . . . .
215
Hirotaka Takano, Hiroshi Asano, and Neeraj Gupta
11
Modiﬁed Monkey Search Technique Applied for Planning
of Electrical Energy Distribution Systems . . . . . . . . . . . . . . . . . . . .
240
F. G. Duque, L. W. De Oliveira, E. J. De Oliveira, B. H. Dias,
and C. A. Moraes
12
Artiﬁcial Neural Network Trained by Plant Genetic-Inspired
Optimizer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
266
Neeraj Gupta, Mahdi Khosravy, Nilesh Patel, Saurabh Gupta,
and Gazal Varshney
13
Continuous Optimizers for Automatic Design and Evaluation
of Classiﬁcation Pipelines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
281
Iztok Fister Jr., Milan Zorman, Dušan Fister, and Iztok Fister
14
Evolutionary Artiﬁcial Neural Networks: Comparative Study
on State-of-the-Art Optimizers . . . . . . . . . . . . . . . . . . . . . . . . . . . .
302
Neeraj Gupta, Mahdi Khosravy, Nilesh Patel, Saurabh Gupta,
and Gazal Varshney
15
Application of Recent Metaheuristic Techniques for Optimizing
Power Generation Plants with Wind Energy . . . . . . . . . . . . . . . . .
319
F. F. Panoeiro, G. Rebello, V. A. Cabral, C. A. Moraes,
I. C. da Silva Junior, L. W. Oliveira, and B. H. Dias
16
Design and Comparison of Two Evolutionary and Hybrid Neural
Network Algorithms in Obtaining Dynamic Balance
for Two-Legged Robots. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
344
Ravi Kumar Mandava and Pandu R. Vundavilli
17
Optimizing the Crane’s Operating Time with the Ant Colony
Optimization and Pilot Method Metaheuristics . . . . . . . . . . . . . . . .
364
Andresson da Silva Firmino, Valéria Cesário Times,
and Ricardo Martins de Abreu Silva
x
Contents

About the Editors
Mahdi Khosravy was born in Birjand city, Iran, 1979.
He
received
BSc.
in
Electrical
Engineering
(bio-electric) from Sahand University of Technology,
Tabriz, Iran, and MSc. in Biomedical Engineering
(bio-electric) from Beheshti University of Medical
Studies, Tehran, Iran. Mahdi received his Ph.D. in the
ﬁeld of Information Technology from University of the
Ryukyus, Okinawa, Japan. He was awarded by the head
of University for his excellence in research activities.
To grow his international experience in education and
research, in September 2010, he joined University of
Information Science and Technology (UIST), Ohrid,
Macedonia, in the capacity of assistant professor. In
2016, he established a journal in information technol-
ogy (ejist.uist.edu.mk) in UIST as currently hold its
executive editorship. UIST professorship helped him a
lot to extend his international collaborations. In July
2017, he became an associate professor. From August
2018 he joined the Energy lab in University of the
Ryukyus as a Visiting Researcher. Since April 2018, he
is jointly a visiting associate professor in Electrical
Engineering Department, Federal Universit of Juiz de
For a in Brazil. Since November 2019, Dr Khosravy is
an appointed researcher in media-integrated laborato-
ries, University of Osaka, Japan. Dr. Khosravy is a
member of IEEE.
xi

Neeraj Gupta was born in India on November 1979.
Multidisciplinary graduation studies provide him the
ability to make fusion of different engineering ﬁelds to
explore cutting edge research in optimization, informa-
tion technology, network design, image and smart
grids. He got Diploma in civil engineering (specialized
in Environmental and pollution control) in 1999,
Bachelor of Engineering in electrical and electronics
engineering in 2003, Master of Technology (M. Tech)
in engineering systems in 2006, and Ph. D. in
Economic operation of power systems (power &
control) in February 2013 from IIT Kampur, India.
He worked as postdoctoral fellow (Sr. Project Engineer)
at Indian Institute of Technology (IIT) Jodhpur, India
for one year (June 2012 - May 2013). Thereafter, joined
the same institute as faculty (May 2013 – August
2014). He has also two years of industrial along with
academic experience before M. Tech. At IIT Jodhpur,
he was involved as collaborator in many national and
international projects funded from MNRE, UNICEF
etc. He was the Assistant. Professor at University for
Information Science and Technology, “St. Paul the
Apostle”, Ohrid, Macedonia from 2014 to 2017.
Currently he is teaching and research staff at the
Department of Engineering and Technology, Oakland
University, USA. Due to the exposition of different
engineering ﬁelds and wide research domain, his
current research interests are in the ﬁeld of optimiza-
tion, smart grid technology, smart cities, big data
problem, multi-agent modeling, IoT and applications,
development of heuristic optimization algorithms, par-
ticularly in the area of multilateral and real-time
operation of the complex systems.
xii
About the Editors

Nilesh
Patel is
an
Associate
Professor
in
the
Department of Computer Science and Engineering at
Oakland University, Rochester, Michigan. Prior to his
tenure at Oakland University, he served as Assistant
Professor at University of Michigan, Dearborn. In
addition to his academic service, Dr. Patel served as a
Software Architect and Software Engineering Manager
at Ford Motors and Visteon Corporation, where he
played an instrumental role in design and development
of ﬁrst voice-enabled vehicular control and GPS
navigation systems. His research interest includes
Deep Machine Learning, Pattern Recognition, Visual
Computing, Evolutionary Computing, and Big Data
Analytics.
Tomonobu
Senjyu (SM’06)
was
born
in
Saga
Prefecture, Japan in 1963. He received the B.S. and
M.S. degrees in Electrical Engineering from the
University of the Ryukyus, Nishihara, Japan, in 1986
and 1988, respectively, and the Ph.D. degree in Electrical
Engineering from Nagoya University, Nagoya, Japan, in
1994. He is currently a Full Professor in the Department
of Electrical and Electronics Engineering, University
of the Ryukyus. His research interests are in the areas
of renewable energy, power system optimization and
operation, power electronics, and advanced control of
electrical machines.
About the Editors
xiii

Chapter 1
Recent Advances of Nature-Inspired
Metaheuristic Optimization
Ahmed Mohamed Helmi1 and Mohammed Elsayed Lotfy2,3(&)
1 Computer and Systems Department, Engineering Faculty, Zagazig University,
Zagazig 44519, Egypt
amhm162@gmail.com
2 Electrical Power and Machines Department, Engineering Faculty,
Zagazig University, Zagazig 44519, Egypt
mohamedabaozed@zu.edu.eg
3 Electrical and Electronics Engineering Department, Engineering Faculty,
University of the Ryukyus, Nishihara, Okinawa 903-0213, Japan
1
Introduction
Nature-inspired metaheuristic algorithms have received a notable interest in the opti-
mization research community [1]. They are applied in a wide range from medical
applications [2] to power system planning [3]. As well as by increasing growth in the
power and popularity of metaheuristic optimization, the researchers become more
interested in possible efﬁciency of them in a wide range of potential applications.
However, the techniques are already available but optimization may be needed like
signal processing [4, 5], image processing [6], image adaptation [7], image enhance-
ment [8], data mining [9], big data [10, 11], telecommunications [12–15], quality
assessment [16], noise cancelation [17], morphological kernel design [18], morpho-
logical ﬁltering [19], blind source separation [20–24], blind component processing
[25], and acoustic data embedding [26]. As a subclass of stochastic optimization,
metaheuristic techniques perform much better than blain random search and do not
stuck at neither complications of mathematical methods like continuity and differen-
tiability of functions, nor exponential time of the exhaustive search.
The historical genetic algorithm (GA) was introduced by Holland in 1960 [27, 28]
where the concept of Darwin’s theory of evolution inspired him. After that in 1989,
Goldberg introduced a detailed explanation of GA [28] from theory to implementation.
GA is the root of nature-inspired optimization family. The main concepts of applying a
heuristic search like GA draw an outline for similar coming techniques. Problem
formulation, solution encoding, ﬁtness function implementation, generating new
solutions mechanism, and termination conditions are the building blocks for any GA-
like technique.
Success of GA (and its small family evolutionary algorithms (EA) [29]) in different
ﬁelds opens a window to numerous participations in the literature of optimization.
Researchers got motivated by different sources in nature, for example, behavior of
animals, movements of insects, physical processes, chemical reactions, and other
© Springer Nature Singapore Pte Ltd. 2020
M. Khosravy et al. (eds.), Frontier Applications of Nature Inspired Computation,
Springer Tracts in Nature-Inspired Computing,
https://doi.org/10.1007/978-981-15-2133-1_1

natural phenomena. However, limitations of GA were also fruitful to direct the research
toward looking for alternative techniques, rather than enhancing existing ones. The
principles of Darwinian evolution for solving optimization problems have been reit-
erated in GA [30–32]. A very recent variation of GA implies Mendelian evolution on
multi-species as inspired from plants biology [33, 34] incorporating the use of double-
strand DNA for evolution.
Nature-inspired algorithms (NIA) constitute a big category in metaheuristic tech-
niques and maybe classiﬁed itself into subclasses. Without loss of generality, classi-
ﬁcation factors are mainly solution encoding, number of search agents, movement
mechanism and objective function, local or global optimality, and implementation or
coding style. Solutions may be encoded as real-valued numbers; hence, there is a
continuous search space with inﬁnite number of solutions. When number of feasible
solutions is countable, then search space is said to be combinatorial search space and
integer values compose the solutions. Later case of problems is well known in the
literature as combinatorial optimization problems (COPs) [35].
Number of search agents or solutions distinguishes techniques into single-based (or
trajectory-based solutions) and population-based techniques. Movement mechanism
involves in principle method of generating neighborhood solutions to the current one(s)
in order to examine various promising solutions. But this can be implicitly interpreted
into the ability of applied search techniques to explore as many regions as possible in
search space and exploit local regions around “good” solutions so far. Hence, any
member in NIA class is asked to achieve a good compromise between exploration and
exploitation tasks. Objective function provides the criteria for evaluating solutions
found by the searching algorithm. It determines if the problem is maximization or
minimization (i.e., ﬁtness function or cost function). On the other hand, if there are only
one measuring criteria, then a single-objective technique is enough to look for a global
optima/minima. In the case of more than one optimality factor for solutions, multi-
objective techniques should be called to ﬁnd one or more Pareto optima [36]. Search
technique may perform “local” optimal movements to enhance one “good” found
solution; hence, it is classiﬁed as a local optimizer, whereas global optimizers try to
ﬁnd near-optimal solutions starting from a random region in search space. On the level
of computer implementation of optimization techniques, it may go in a sequential
fashion or parallelization can take place in order to speed up the search process. For
more detailed and comprehensive study about such classiﬁcations, please refer to the
book of Talbi [37].
Besides the endless inspiration resources in nature, NIA extensibility has been
proven along with the literature. Various improvement entries for NIA have been
tackled due to the simple background and ﬂexible architecture. A very strong evidence
is most probably hybrid metaheuristic techniques [37, 38] where different levels of
cooperation between metaheuristic techniques and themselves or other exact ones are
possible. NIA has a notable share in hybrid techniques as recently discussed in [39].
It is worth mentioning that one interesting overview of NIA and its applications
was introduced by Yang [40] in 2014. This list of NIA was well reviewed in [40]:
simulated annealing [41], GA, differential evolution (DE) [42], ant algorithms [43],
bee-inspired algorithms [44–46], particle swarm optimization (PSO) [47], ﬁreﬂy
2
A. M. Helmi and M. E. Lotfy

algorithm (FFA) [48], cuckoo search algorithm (CSA) [49], bat algorithm [50], har-
mony search (HS) [51], and ﬂower pollination algorithms (FPA) [52].
Later in 2017, Lindﬁeld and Penny have handled NIA topic in their work [53]. EA,
CSA, FFA, artiﬁcial bee colony [46], and ant colony optimization [54] have been
reviewed again. PSO, bacterial foraging inspired algorithm [55], and physical-inspired
optimization algorithms [56] were introduced in detail. Implementation issues of
algorithms were also of interest in [53].
Bozorg-Haddad introduced a new set of NIA in [57] which contains cat swarm
optimization [58], league championship algorithm [59], anarchies society optimization
[60], teaching–learning-based optimization [61], krill herd algorithm [62], gray wolf
optimization (GWO) [63], shark smell optimization [64], ant lion optimization
(ALO) [65], gradient evolution [66], moth-ﬂame optimization (MFO) [67], crow search
algorithm (CRSA) [68], and dragonﬂy algorithm (DA) [69] while CSA and FPA are
revisited.
Yang came back in 2018 in a new study [70] where state of the art of many
aforementioned techniques was covered. The focus was oriented to the following
topics: mathematical analysis of NIA, no-free lunch (NFL) theorems in the literature
and various application areas of NIA, for example, feature selection, classiﬁcation,
computational geometry, wireless networks, modeling to generate alternatives, and
others.
In this chapter, we highlight the recent newborn techniques in NIA family that have
not been considered in similar previous studies. We introduce a comprehensive view
for all aspects of each considered algorithm here. Figure 1 shows a timeline for the
mentioned NIA techniques here.
Pity Beetle, Emperor Penguin
MO Artificial Sheep
Sine-Cosine, Electromagnetic Field
Dragonfly, Crow Search, Multi-verse
Gray Wolf, Shark Smell
Symbiotic Organisms Search
Flower Pollination, Anarchies Society
Krill Herd, Wolf Search, Water Cycle
Fireworks Algorithm, Bat Algorithm
Firefly Algorithm 
Cat Swarm
Bacterial Foraging
Differential Evolution
Ant Colony
Genetic Algorithm
19
18
17
16
15
14
13
12
11
10
09
08
07
06
05
02
2000
97
95
92
83
1960
Emperor Penguin Colony
Sailfish Opt., Seagull Opt.
Artificial sheep, Spotted Hyena
Salp Swarm, Satin Bowerbird
Moth-Flame, Ant Lion
Gradient Evolution
Mine Blast, Invasive Weed 
Teaching-learning 
Cuckoo Search, Group Search
Gravitational Search
League Championship
Monkey Search
Imperialist Competitive 
Bee-inspired Algorithms
Harmony Search
Particle Swarm
Simulated Annealing
Fig. 1. Timeline (per year) for historical and recent nature-inspired algorithms
Recent Advances of Nature-Inspired Metaheuristic Optimization
3

2
Recent Novel Techniques
The inspiration of a novel technique in NIA class arises the passion of interested
workers in the ﬁeld. Among the vast literature of NIA category, this section is focusing
on six novel techniques that have joined NIA family so recently. Five single-objective
optimization techniques are included here, namely emperor penguins colony (2019),
seagull optimization algorithm (2019), sailﬁsh optimizer (2019), pity beetle algorithm
(2018), and emperor penguin optimizer (2018). The multi-objective artiﬁcial sheep
algorithm (2018) is introduced as well.
For each introduced technique in this section, a summary of the inspiration back-
ground is given, search operators and algorithmic behavior are well clariﬁed, main
steps of proposed algorithm are simply stated, effect of search parameters on explo-
ration and exploitation is discussed, and ﬁnally, testing sites where empirical results
show the superiority of a proposed algorithm compared to other optimizers are
mentioned.
According to NFL theorem, we have seen that testing sites of each new proposed
optimization technique, as well as selected algorithms of comparison, should be ﬁgured
out.
2.1
Emperor Penguins Colony Algorithm
Hariﬁet al. have introduced emperor penguins colony (EPC) algorithm in [71]. It is a
social swarm-based technique which got inspired by the behavior of the largest kind of
living penguins in Antarctica, called emperor penguins. In order to overcome extreme
cold weather, male individuals are grouping into huddles (a huddle may collect hun-
dreds of penguins). Thus in a huddle, the body surface temperature of a penguin
reaches 37 °C in 2 h. A penguin requires to keep the temperature at certain level (about
35 °C) for the growth of its fetus. The center of a huddle is much warmer than
boundaries. Hence, outer penguins have spiral-like movements (see Fig. 2) toward
inside to capture more heat, and everyone in the huddle becomes warmer as required.
Each penguin determines its movement according to attractiveness measure which in
turn depends on the body temperature and heat radiation of each penguin [71]. Initial
population is formed of starting positions of penguins which are scattered in the huddle.
Penguins move toward the warmer one (i.e., a penguin with the highest heat intensity).
Cost is determined according to heat intensity and distance between penguins. When
attraction (based on a heat absorption coefﬁcient) is taking place, then new solutions are
generated and heat intensity is updated.
4
A. M. Helmi and M. E. Lotfy

Sorting all solutions result in determining the best solution so far. For purposes of
convergence, a damping ratio of heat radiation is updated, and then the movement is
applied and the attraction process is tested.
Radiation emitted from each penguin body QPenguin per unit time (W) is calculated
as:
QPenguin ¼ AerT4
s
ð1Þ
where total body surface area A ¼ 0:56 m2, emissivity of bird plumage e ¼ 0:98,
Stefan–Boltzmann constant r = 5.6703  10−8 W/m2 K4, and absolute temperature is
Ts = 308.15 K (Kelvin) (equals 35 °C).
Fig. 2. Spiral-like movement inside a huddle of emperor penguins
Fig. 3. Coordinated spiral movement of penguins
Recent Advances of Nature-Inspired Metaheuristic Optimization
5

The attractiveness is calculated as follows:
Q ¼ AerT4
s elx
ð2Þ
where l is the attenuation coefﬁcient and x represents the distance between penguins,
considering a linear radiation emitted from penguin bodies.
The spiral-like movement aims to optimize the temperature of a penguin. For a
penguin at position k when traveling from position i to position j (see Fig. 3), the xk and
yk components can be modeled as in Eq. 3.
xk ¼ ae
b1
b ln
1Q
ð
Þeb tan1yixi þ Qe
b tan1yj
xj
n
o
cos 1
b ln
1  Q
ð
Þeb tan1yi
xi þ Qe
b tan1yj
xj




yk ¼ ae
b1
b ln
1Q
ð
Þeb tan1yixi þ Qe
b tan1yj
xj
n
o
sin 1
b ln
1  Q
ð
Þeb tan1yi
xi þ Qe
b tan1yj
xj




ð3Þ
where a and b are two predetermined constants that control the shape of the logarithmic
spiral. In order to avoid monotonicity movement, a random component has to be added
as a mutation operator (Eq. 4).
xk  xk þ u  i;
yk  yk þ u  i
ð4Þ
where u is the mutation factor and  is a randomly generated vector for each solution
i in population. EPC algorithm uses a uniform distribution; however, other distributions
are also applicable.
Main steps and mathematical formulation of EPC algorithm are summarized in
Algorithm 1.
The algorithm is adaptively moving from the exploration phase into exploitation
phase via reducing the attenuation coefﬁcient l in Eq. 3 which leads, together with
reducing heat radiation in Eq. 1, to reduce the attractiveness factor Q. Also decreasing
the mutation factor u in Eq. 4 is directly leading to solution convergence.
6
A. M. Helmi and M. E. Lotfy

1:
Generate a random initial population of solutions
2:
Evaluate the cost of initial solutions
3:
Determine an initial value for heat absorption coefficient  
4:
Repeat until Max number of iterations is reached
5:
For all solutions in current population with size 
6:
Compare the cost of each pair 
of solutions,
7:
If
then
8:
Calculate heat radiation by Eq. 
10:
Calculate attractiveness by Eq. 
11:
Calculate coordinated spiral movement by Eq. 
12:
Generate new solutions by Eq. 
13:
Evaluate new solutions
14:
End if
15:
End for
16:
Find best solution so far after sorting
17:
Update parameters: decease heat radiation, decrease 
mutation coefficient and increase heat absorption 
coefficient.  
18:
End loop
Algorithm 1: Emperor Penguins Colony (EPC)
Performance of EPC algorithm has been examined using eight standard benchmark
test functions like Ackley, sphere, Rosenbrock functions, and others. The algorithms of
comparison were GA, imperialist competitive algorithm (ICA) [72], PSO, ABC, DE,
HS, GWO and invasive weed optimization [73]. Robustness of proposed algorithms
was tested by varying population size between 10 and 50. Empirical results show that
EPC performance is accepted, and it does not lose quality with larger dimensional
problems. Also, statistical analysis has been performed using Friedman test [74] and
Iman-Davenport test [75]. Moreover, authors in [71] stated that EPC algorithm can
perform well in multimodal and nonlinear optimization problems.
2.2
Seagull Optimization Algorithm
Dhiman et al. have introduced seagull optimization algorithm (SOA) in [76]. This
novel algorithm is inspired by the migration and attacking behaviors of a kind of sea
birds, called seagull. Seagulls are living in colonies; hence, we have another swarm-
based technique.
Recent Advances of Nature-Inspired Metaheuristic Optimization
7

Its seasonal movement or migration occurs also in groups, and it is noticed that
seagulls can avoid collisions between each other by adjusting their positions. The
migration direction of seagulls is determined according to the best survival ﬁttest one.
Seagulls can attack other birds making a spiral movement shape (see Fig. 4).
Migration and attacking behaviors are explicitly interpreted into exploration and
exploitation tasks of SOA. Search process starts by generating free-of-collision solu-
tions. To ensure this behavior, a movement operator A is applied to generate a new
population Cs
! from the current one Ps
! at iteration x as follows in Eq. 5.
Cs
! ¼ A  Ps
!ðxÞ
ð5Þ
where A is linearly decreased in the interval 2; 0
½
 using Eq. 6.
A ¼ fc  x  fc=Max Iteration
ð
Þ
ð
Þ
ð6Þ
where fc ¼ 2 and x ¼ 0; 1; . . .; Max Iteration.
During search process, seagulls make use of search experience and perform
attacking in a spiral movement behavior which can be modeled using Eq. 7.
r ¼ u  ekv
ð7Þ
where u and v are two constants that deﬁne the spiral path shape (both u and v are set to
1 in SOA), and k is a random value in the range 0; 2p
½
. The x, y, and z coordinated
components of the vector r can be derived as in Eq. 8.
x0 ¼ r  cosðkÞ;
y0 ¼ r  sinðkÞ;
z0 ¼ r  k
ð8Þ
Fig. 4. Attacking behavior of seagulls
8
A. M. Helmi and M. E. Lotfy

Solutions are updated according to positions of best neighbor using Eq. 9.
Ms
! ¼ B  ~Pbest x
ð Þ  Ps
! x
ð Þ


ð9Þ
where Ms
! represents positions of current solution Ps
! and ~Pbest is the best solution so
far. B introduces required randomization to control balancing between exploration and
exploitation phases. B depends on generating a random value rd 2 0; 1
½
, and it is
calculated as in Eq. 10.
B ¼ 2  A2  rd
ð10Þ
Now the distance Ds
! between current solution and best solution can be calculated
as in Eq. 11.
Ds
! ¼
Cs
! þ Ms
!


ð11Þ
Updating positions of search agents can be formulated as in Eq. 12.
Ps
!ðxÞ ¼ ~Ds  x0  y0  z0

	
þ~PbestðxÞ
ð12Þ
SOA is one simple algorithm as well captured from its main steps introduced in
Algorithm 2.
Algorithm 2: Seagull Optimization Algorithm (SOA)
1:
Generate an initial population 
2:
Initialize parameters: ,
,
and 
3:
Repeat until 
is reached
4:
Apply collision avoidance using Eq. 
5:
Evaluate solutions of current population and determine 
the best solution so far.
6:
Calculate using Eq. 
7:
Calculate ,
and 
components using Eq. 
8:
Calculate distance 
using Eqs. 
9:
Update current population using Eq. 
10:
Update 
using Eq. 
11:
End loop
Performance of SOA was examined using 23 commonly used benchmark test
functions. Some functions are unimodal where others are multimodal functions to test
exploitation around optimum solution and exploration (or diversity) where local optima
avoidance can be examined, respectively. Another set of test functions to test proposed
technique behavior (just mentioned above) involves CEC 2005 and CEC 2015 [77, 78].
SOA was compared to spotted hyena optimizer (SHO) [79], GWO, PSO, MFO, multi-
verse optimizer (MVO) [80], sine cosine algorithm (SCA) [81], gravitational search
algorithm (GSA) [82], GA, and DE. Empirical results suggested that SOA outperforms
many other optimizers in most testing cases.
Recent Advances of Nature-Inspired Metaheuristic Optimization
9

Wilcoxon signed-ranked test [83] has been applied at 5% level of signiﬁcance.
Also, Mann–Whitney U rank sum test [84] has been applied to average values of CEC
2015 problems. These statistical tests reveal the superiority of SOA. Moreover, SOA
efﬁciency was examined in solving many real-life constrained optimization problems,
namely constraint handling, optical buffer design problem, pressure vessel design
problem,
speed
reducer
design
problem,
welded
beam
design
problem,
tension/compression spring design problem, rolling-element bearing design problem,
and 25-bar truss design problem. Later set of testes show that SOA can be very
effective when solving constrained engineering problems with reasonable computa-
tional cost and high speed of convergence.
2.3
Sailﬁsh Optimizer
Shadravan et al. have introduced sailﬁsh optimizer (SFO) in [85]. SFO is a new swarm-
based optimization technique that depends on two populations of solutions. This
optimizer got inspired by the social behavior of a group of hunting ﬁsh called sailﬁsh. It
follows an amazing hunting strategy that involves alternating the attacks on a schooling
of a smaller ﬁsh-like sardine (see Fig. 5). Such strategy helps to save energy of hunters
while other members are injuring the prey. Another interesting behavior is changing
their body color before attacking which is—most probably—done to determine who
attacks ﬁrst and preventing overlapping between compatriots.
Sailﬁsh represents the population of candidate solutions which are the main search
agents in the search space. Another incorporated population is that one of sardines that
concerns to ﬁnd the best solution in their region. Along search process, an elite of ﬁttest
Fig. 5. A sailﬁsh is attacking a school of sardine
10
A. M. Helmi and M. E. Lotfy

solutions of both mentioned populations above are kept into Xi
elite
SF and Xi
injured
S (at
ith iteration) in order to determine the movements of the next solutions of each pop-
ulation. Sailﬁsh can attack the prey in all directions, and they shrink the circle of attack.
This strategy is translated into updating positions of current solution Xi
old
SF within a
hypersphere neighborhood around best solution Xi
elite
SF into Xi
new
SF as in Eq. 13.
Xi
new
SF ¼ Xi
elite
SF  ki

rand 0; 1
ð
Þ 
Xi
eliteSF þ Xi
injuredS
2
 
!
 Xi
old
SF
 
!
ð13Þ
where the coefﬁcient ki is calculated in Eq. 14 and it affects the search region around
sardine.
ki ¼ 2  randð0; 1Þ  PD  PD
ð14Þ
And PD is the prey density at ith iteration which is decreased along search process.
PD is adaptively updated according to population size of each of sailﬁsh and sardines,
namely NSF and NS, respectively, in Eq. 15.
PD ¼ 1 
NSF
NSF þ NS


ð15Þ
In SFO settings, NSF is a percentage of NS where initial number of sardines is larger
than number of sailﬁshes. Thus, ki 2 1; 1
½
 and its ﬂuctuation model the exploration
to ﬁnd a global solution. Now the other population of sardines is updated according to
the hunt process details. Sailﬁsh power is gradually decreased as well as the ability of
sardines to escape and maneuver. This leads to a quick capture of injured sardines; in
other words, the exploitation process is taking place. A new position of sardines Xi
new
S
of ith iteration can be calculated as given in Eq. 16.
Xi
new
S ¼ rand 0; 1
ð
Þ 
Xi
elite
SF  Xi
oldS þ AP


ð16Þ
where Xi
oldS represents current position of sardine, Xi
elite
SF is the position of best
sailﬁsh (i.e., best solution so far and), and AP is the sailﬁsh’s attacking power which is
linearly decreased each iteration as shown in Eq. 17.
AP ¼ A  1  2  Itr  e
ð
Þ
ð
Þ
ð17Þ
where A ¼ 4 and e ¼ 0:001. Reducing attacking power helps to assist convergence of
solutions, together with limiting the positions of updates in population of sardines. This
can be achieved using Eqs. 18 and 19.
Recent Advances of Nature-Inspired Metaheuristic Optimization
11

a ¼ NS  AP
ð18Þ
b ¼ di  AP
ð19Þ
Here, moving from exploration phase into exploitation phase can be controlled
based on the value of AP coefﬁcient. If ðAP  0:5Þ, then all sardines get updated,
whereas ðAP\0:5Þ limits the updatings to just a sardines with b positions.
At the end of hunting step, position of a sailﬁsh Xi
SF replaces the position of its
corresponding hunted sardine Xi
s (i.e., better solution) in order to increase the chance of
hunting a new prey. This situation is modeled in Eq. 20.
Xi
SF ¼ Xi
s;
if f Si
ð Þ\f SFi
ð
Þ
ð20Þ
Using two different populations where sailﬁsh updates depend on sardine best
positions guarantees good exploration of search space, rather than reducing chances of
trapping in local minima. Algorithm 3 introduces the main steps of SFO.
Algorithm 3: Sailfish Optimizer (SFO)
1:
Generate initial populations of sailfish and sardine. 
2:
Initialize the parameters 
and 
3:
Evaluate solutions in both populations and determine best 
solution of each one.
4:
Repeat until stopping criteria is met
5:
for each solution in sailfish
6:
Calculate using Eq. 
7:
Update positions of sailfish using Eq. 
8:
End for
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
Calculate 
coefficient using Eq. 
If
.
then
Calculate 
and 
using Eq. 
and Eq. 
Update 
positions of 
solutions in sardine by Eq. 
else
Update positions of all sardine by Eq. 
End if
Calculate the fitness of all sardine
If a better solution in sardine is found, then
Replace a sailfish with best sardine by Eq. 
Remove the best sardine from population
Update best sailfish and best sardine.
End if
22:
End loop
Experimental tests for performance examination of SFO were conducted using 20
benchmark functions with various characteristics. They vary between unimodal and
multimodal, other than dimensional variability. As mentioned earlier in this chapter,
unimodal optimization functions are suitable for checking exploitation behavior of the
examined algorithm, whereas multimodal ones are used for testing exploration capa-
bilities. The following optimizers were chosen for comparison: GA, PSO, GWO, satin
bowerbird optimizer (SBO) [86], ALO, and salp swarm algorithm [87]. Reported
results show a high speed of convergence and high efﬁciency of SFO over competitors
12
A. M. Helmi and M. E. Lotfy

in most cases. For non-convex optimization problems (i.e., there are multiple feasible
regions) as well as non-separable ones where variables are dependent or interrelated,
SFO shows great ability as an optimizer for such hard problems.
Also, the statistical t-test has been run on two different sets of population and p-
values show acceptance of SFO.
For large-scale problems, a set of 11 benchmark functions with 300 dimensions was
optimized by SFO which outperformed all other optimizers of comparison.
Moreover, SFO was tested in solving 5 engineering problems in comparison with
different groups of state-of-the-art optimizers. In the following, we mention each of the
5 problems together with other tested optimizers than the proposed SFO: I-beam design
problem with the optimizers MFO, adaptive response surface method (ARSM) [88],
improved ARSM [89], CSA, and symbiotic organisms search [90] algorithms; welded
beam design problem with the optimizers GA, GSA, an EA variant by Siddall [91], one
decision-making-based technique by Coello [92], Richardson’s random method, sim-
plex method, Davidon–Fletcher–Powell [93], and co-evolutionary PSO [94]; gear train
design problem with the optimizers GA, mine blast algorithm (MBA) [95], CRSA,
MFO, and CSA; three-bar truss design problem with the optimizers PSO-DE [96],
MBA, MFO, method of Ray and Saini [97], and CSA; lastly, circular antenna array
design problem with the optimizers SBO, water cycle algorithm [98], and GA. Efﬁ-
ciency of SFO in comparison with other optimizers was proven again with mentioned
class of engineering optimization problems above. In conclusion, SFO is highly sug-
gested as a global optimization algorithm. Assumptions of NFL theorem still hold;
however, SFO has passed exhaustive experimental and statistical tests.
2.4
Pity Beetle Algorithm
Kallioras et al. have introduced pity beetle algorithm (PBA) in [99]. The behavior of
the six-toothed spruce bark beetle has motivated Kallioras et al. to invent this new
swarm-based optimization technique. First generation of these insects starts with
searching a forest randomly by pioneer beetles in order to ﬁnd suitable hosts. Trees are
the aimed hosts by beetles. Once a host is found, and then other beetles are attracted
after communicating through a pheromone message, and new generation is created. In
this context, one beetle represents a solution, whereas a host is a randomly selected
region in search space. Population evolution is one crucial aspect of this kind of beetles
which discriminates PBA among swarm intelligence class. In searching stage, ran-
domly located hosts are explored by pioneer beetles. After that, an aggregation stage
starts by spreading out pheromones to collect more beetles (population is locally
increased). In this stage, both weakened and robust hosts are discovered. At some
threshold, there is an overcrowded population which reversely directs the beetles to
look for other hosts. The latter stage is known as anti-aggregation stage.
To simulate this interesting strategy, PBA uses a random sampling technique
(RST) to ensure that almost all portions of search space are equally represented in each
generated population. So that diversiﬁcation of search space is well performed. For a
D-dimensional problem, to construct a population of size N, the range of each of the
D variables is divided into N non-overlapping equal intervals. Then a single value is
Recent Advances of Nature-Inspired Metaheuristic Optimization
13

selected randomly from each variable range to produce a sample of size D. Thus, there
is a hypervolume of ND values which are randomly matched to generate a population.
The samples (i.e., initial solutions) are determined according to Eq. 21.
xij ¼ F1
x
i  1 þ rxi= ui  li
ð
Þ
N


ð21Þ
where rxi 2 li; ui
½
 is a random valued in the range of lower and upper bounds li and ui,
respectively, of ith parameter, and Fx is the cumulative distribution function of uniform
distribution for the jth solution xi;j. Following metaheuristic tradition, PBA has three
main steps: initialization, movement mechanism, and solutions update. PBA starts by
generating a population of N pioneer beetles that are randomly positioned in a
hypervolume space (generation 0). Each of these initial solutions is attracted to the best
ﬁttest one. A brood of six populations, each of size N, are created at the best-decided
position (second generation), and then a new hypervolume selection pattern (i.e.,
movement mechanism) is decided for each one. Finally, new populations replace old
ones.
In order to achieve a good balance with exploration and exploitation phases, PBA
depends on the quality of previously obtained solutions in contrast to depending on
neither the number of search iterations nor the number of objective function evalua-
tions. For the same purpose, updating the positions of solutions is following a distinct
strategy as explained below.
Moving in search space does not follow the same procedure all the time. PBA
mimics the beetles’ behavior in looking for a better position than starting one in order
to create its own population. PBA implements ﬁve methods for selecting a new
hypervolume, namely neighboring search volume, mid-scale search volume, large-
scale search volume, global-scale search volume, and memory consideration search
volume. For any of these selection patterns, once one pattern is chosen, and then a
search area is examined around the birth position (denoted as xbirth in Eq. 22) of
generated population as explained by Eq. 22 where the previously mentioned RST is
called again.
x g
ð Þ
j
¼ RST l g
ð Þ; u g
ð Þ; D; N


where
l g
ð Þ
i ; u g
ð Þ
i
h
i
2 x g
ð Þ
birth;i  1  fpat

	
; x g
ð Þ
birth;i  1 þ fpat

	
h
i
ð22Þ
where i represents the ith position of the jth solution xj, g denotes current generation
number, l g
ð Þ
i
and u g
ð Þ
i
are lower and upper bounds of the ith dimension in generation g,
respectively, and fpat is a particular parameter related to the applied search pattern
(called pattern factor), and it determines the size of investigated neighborhood around
x g
ð Þ
birth.
14
A. M. Helmi and M. E. Lotfy

Neighboring search hypervolume is used ﬁrst by each starting solution (Step #3 in
Algorithm 4) which results in a new population using Eq. 22.
positions of populations for
For 
If
then
then
Calculate a new 
using RST
Else If 
is better than 
then
Determine 
using Eq. 
after 
is less than 
then
Determine 
using Eq. 
after
Else
End If
End If
End If
End If
End
In Eq. 22, fpat is replaced by a neighboring factor fnb which works in the range
[0.01, 0.2]. In this pattern, the selected neighborhood is relatively close to starting
positions of birth solution. A predetermined number of populations (analogous to
broods in this stage) are generated. The best solution in each newborn population is
determined where the best solution among all populations is found and named as
x g þ 1
ð
Þ
birth . The latter solution replaces x g
ð Þ
birth if it is ﬁtter.
If the neighboring search hypervolume has failed to ﬁnd a better solution com-
paring to the starting one, then PBA switches to mid-scale search hypervolume pattern.
A search neighborhood is investigated around the current best solution using Eq. 22
but fpat is now replaced by a mid-scale factor fms with range [0.1, 1] (Step #8 in
Algorithm 4). Again, the best solution in the new positions is determined and compared
to the starting one. In case of improvement, the newly generated positions constitute a
new population.
The large-scale search hypervolume phase is also started when the neighboring
search hypervolume ceases to leave the starting solution to a better one. PBA switches
to this mode with a probability pr which is considered one parameter of this algorithm.
In Eq. 22, the large-scale factor fls with range [1, 100] replaces fpat (Step #10 in
Algorithm 4). Similarly, the new randomly positioned solutions are compared with
each other to determine the best starting one.
PBA has another choice of movement if it decides not to do a large-scale search
which is memory consideration search hypervolume pattern (Step #12 in Algorithm 4).
The N best solutions so far are kept in a memory MEM which is initialized with the
Recent Advances of Nature-Inspired Metaheuristic Optimization
15

positions of initial population. Now another interesting glimpse of beetle’s behavior
regarding colonies expansion can be modeled as memory consideration search
hypervolume pattern. The procedure of investigating new search area is different from
previously explained patterns and goes as follows: Just one solution in MEM is selected
to randomly move to a new position which replaces the worst one in MEM in case of
improvement. Also, a very narrow local search is carried out close to the newly found
position using Eq. 22 with a ﬁne-tuning parameter ftn in the range [0.005, 0.05].
When a large number of objective function evaluations FEun have been encountered
with no improvement in the quality of solutions, then the global-scale search hyper-
volume strategy is called. Regarding the maximum allowable number of function
evaluations FETotal, the FEun can be calculated using a multiplication factor fFE in range
[0.05, 0.25] (Step #5 in Algorithm 4). A new population is created using RST method
within the global lower and upper bounds.
Algorithm 5 presents a pseudo-code for PBA. The important steps of PBA (Steps
#4–#11 in Algorithm 5) are previously clariﬁed in Algorithm 4.
Algorithm 5: Pity Beetle Algorithm (PBA)
1:
Reset 
to 
2:
Initialize search parameters
3:
Repeat
4:
For each generated population in the 
5:
For each solution in the population
6:
Select a new hypervolume search pattern
7:
Evaluate solutions
8:
Increment 
9:
End
10:
Update population positions
11:
End
12:
Until 
exceeds 
value
Discussion. The applied perturbation mechanism developed in PBA tries to
overcome the known obstacles facing metaheuristic techniques. In the beginning,
initializing ﬁrst solutions using RST method is at least more efﬁcient than a plain
random start. Besides generating more than one population around promising locations,
this should reduce the effect of bad starts in search space.
The variety of generating neighborhoods via different walks in search space handles
implicitly the issues of premature convergence and trapping in local minima. PBA has
a chance to perform a mutation-like step in the large-scale search hypervolume pattern.
This is also the case if PBA enters the memory consideration search hypervolume
pattern, where the worst solution in the population of best solutions so far may be ﬁred
for the sake of a better one, rather than ﬁne-tuning that newcomer by means of local
search.
One ﬁnal advantage of PBA is using the number of function evaluations with no
improvement in solutions quality as an indicator of falling into nearby local minima. As
a direct or explicit treatment of such problem, PBA executes a random walk supervised
by RST in search space via its global-scale search hypervolume strategy.
16
A. M. Helmi and M. E. Lotfy

On the other side, PBA has some control parameters each with a speciﬁc range.
Authors have carried out sensitivity analysis for PBA where there is an empirical
evidence that PBA isn’t inﬂuenced by its parameters, as clariﬁed below. However, it
seems that there will be a bit overwork to optimize PBA parameters when being
implemented every once for a new optimization problem. This also opens a window to
examine some low-level hybridization between PBA and another auxiliary technique to
optimize PBA algorithmic parameters.
As just ﬁgured out above, PBA contains some control parameters. Each parameter
works in a preferable range and any problem-dependent implementation requires ﬁxing
the values of the parameters: N, fnb, ftn, fms, fls, pr, and fFE (Step #2 in Algorithm 5).
Authors in [99] have carried out sensitivity analysis to test the best combination of
search parameters. A 25 randomly generated combinations of parameters (each in its
speciﬁed range) were used while optimizing six commonly addressed unimodal and
multimodal benchmark test functions. This test reveals that PBA robustness against its
search parameters change rather than problem dimension growth.
For purposes of performance testing, another set of benchmark test functions, with
dimensions 10 and 30, has been optimized using PBA in comparison with many state-
of-the-art algorithms and most of them are PSO variants like PSO with inertia weight
[100], PSO with constriction factor [101], a local version of PSO with inertia weight
[102], uniﬁed PSO scheme [103], fully informed PSO [104], comprehensive learning
PSO [105], aging leader and challengers PSO [106], and weighted quantum PSO [107],
rather than group search optimizer (GSO) and improved GSO [107].
For most cases, PBA achieved better average best solutions than the optimizers of
comparison. Moreover, PBA outperformed the best two algorithms for solving some
30-dimensional instances of CEC 2013 competition [108].
Moreover, many instances between 10-dimension and 100-dimension from CEC
2014 benchmark problems [109] were tested using PBA against the optimizers:
simultaneous optimistic optimization [110], ﬁreworks algorithm with differential
mutation [111], and some improved versions of adaptive differential evolution in [112]
and [113]. Superiority of PBA has been proven in the mentioned particular problems as
well as its robustness and efﬁciency. Due to its considerable pros, PBA is expected to
receive a notable interest in stochastic optimization community and widely applied
with different-domain problems.
2.5
Emperor Penguin Optimizer
Dhiman et al. have introduced emperor penguin optimizer (EPO) in [114]. The social
behavior of emperor penguins birds inside their huddles has been the inspiration source
once again. As introduced earlier in this chapter, EPC optimization algorithm [71]
mimics the spiral movement of a penguin from huddle boundaries toward the wormer
point inside. However, Dhiman et al. [114] have ﬁrstly handled the huddling behavior
before the work in [71] from a different point of view. Dhiman et al. introduced the
EPO algorithm which implements other interesting activities like forming the huddle
boundaries, temperature proﬁle updates, distance calculations between individuals and
relocating the effective mover around the huddle.
Recent Advances of Nature-Inspired Metaheuristic Optimization
17

The huddle boundaries are generated randomly in the very beginning. The huddle is
assumed to be formed in one L-shaped polygon plane (see Fig. 6). The initial huddle
boundary can be generated using Eq. 23.
F ¼ U þ iX
ð23Þ
where F is an analytical function on the polygon plan, U deﬁnes the wind velocity that
affects the huddle boundary, X is another vector, and i is the imaginary constant.
The ambient temperature changes of the huddle can be modeled as given by Eq. 24.
T0 ¼
T 
MaxItr
ItrMaxItr


T ¼
0;
if R [ 1
1;
if R\1

ð24Þ
where the temperature T ¼ 0 when polygon radius R [ 1, and T ¼ 1 for R\1 (see
Fig. 6, the polygon is to the right). R is a randomly generated value in [0, 1]. T0 controls
the exploration and exploitation phases of the algorithm.
The distance between a penguin and the ﬁttest individual in the huddle in current
iteration Itr can be mathematically expressed as shown in Eq. 25.
~Dep ¼
S ~A
 
 ~P Itr
ð
Þ  ~C  ~Pep Itr
ð
Þ




ð25Þ
where ~P deﬁnes the position of best search agent while ~Pep indicates the position of the
concerned penguin. In order to insure collision avoidance between penguins, two
vectors ~A (see Eq. 26) and ~C are inserted. S ~A
 
is responsible to move the penguin
Fig. 6. A huddle of penguins forming like a L-shaped polygon to the left, and its equivalent
graphical model is to the right
18
A. M. Helmi and M. E. Lotfy

toward the optimal location and is computed as in Eq. 27 while ~C is a random vector in
[0, 1]. j j denotes the absolute value function.
~A ¼ M  T0 þ ~P  ~Pep



	
 RandðÞ

	
 T0
ð26Þ
S ~A
 
¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
f  eItr=l  eItr
q

2
ð27Þ
where M is set to 2 in Eq. 26 to maintain a gap between individuals. Two parameters f
with range [2, 3] and l with range [1.5, 2] (as suggested by sensitivity analysis of EPO)
are also helping to control the balance between exploration and exploitation. e denotes
the expression functions.
For an individual penguin, it can update its position after locating the best mover
one as shown in Eq. 28.
~Pep Itr þ 1
ð
Þ ¼ ~P Itr
ð
Þ  ~A  ~Dep
ð28Þ
Thus, changing the position of the mover penguin (i.e., optimal solution) causes re-
computing the huddling behavior and a new iteration of EPO algorithm is taking place.
Algorithm 6 shows a pseudo-code for EPO.
The proposed EPO algorithm has been tested using 44 benchmark test functions
divided into ﬁve categories: unimodal, multimodal, ﬁxed-dimension multimodal, and
composite functions.
Algorithm 6: Emperor Penguin Optimizer (EPO)
1:
Generate initial population 
2:
Choose search parameters
3:
4:
Evaluate search agents
Repeat
5:
Determine the huddle boundary using Eq. 
6:
Calculate the temperature profile using Eq. 
7:
Compute the distance for each individual using 
Eqs.
8:
9:
Update positions of search agents using Eq. 
Update search parameters 
10:
Check if any search agent exceeds the boundary and 
then amend it
11:
Evaluate search agents and determine the optimal 
Solution
12:
Until stopping criteria is met
13:
Report the optimal solution so far
Mathematical expressions for all instances of mentioned categories are available in
the paper and other sources. Fifth type of test problems belongs to CEC 2015 functions
[115]. A set of 8 state-of-the-art optimizers was chosen for comparison with EPO. It
contains GA, PSO, HS, GSA, GWO, SCA, SHO, and MVO.
Recent Advances of Nature-Inspired Metaheuristic Optimization
19

Parameter settings for EPO during experimental test were population size = 80,
T0 2 1; 1000
½
, ~A 2 ½1:5; 1:5, SðÞ 2 ½0; 1:5, M ¼ 2, f 2 2; 3
½
, l 2 1:5; 2
½
, and
MaxItr ¼ 1000. According to the performed sensitivity analysis of EPO, the indicated
parameter values seem to be recommended for any further applications of EPO.
EPO was able to ﬁnd optimal solution of most cases of both tested unimodal and
multimodal functions. Thus, EPO exploration and exploitation abilities were veriﬁed.
Composite test functions are formed by means of shifting, rotating, expanding, and
combining classical functions, so that they are well examination suit for local minima
avoidance capability on an optimizer. EPO was able to outperform other competitors in
this category of test function with reasonable convergence rates. EPO was also the best
optimizer for most of CEC 2015 benchmark test functions.
One more empirical test for scalability reveals that EPO performance hasn’t been
degraded so much while changing dimensionality between 30 and 100.
EPO undergoes the statistical analysis of variance test with sample size 30 and 95%
conﬁdence of interval. Results show that EPO is statistically signiﬁcant from other
compared algorithms for all 29 tested benchmark functions.
In the ﬁeld of engineering optimization, EPO has been applied to 7 constrained and
unconstrained nonlinear engineering problems like pressure vessel, speed reducer,
welded beam, tension/compression spring, 25-bar truss, rolling-element bearing, and
displacement of loaded structure. The proposed EPO was also very effective and
outperforms the other optimizers in most cases.
Like other new members of NIA class, authors of EPO are looking forward to adapt
this basic version of EPO to work in other important optimization sites like feature
extraction which requires binary-coded solutions, multi-objective optimization, and
COPs.
2.6
Multi-objective Artiﬁcial Sheep Algorithm
Lai et al. have introduced multi-objective artiﬁcial sheep algorithm (MOASA) in [116].
Social behavior of sheep ﬂocks was the inspiration source for Wang et al. to develop a
novel optimization technique called binary artiﬁcial sheep algorithm (BASA) [117].
Based on BASA, Lai et al. have created an enhanced version with new operators to
work in multi-objective optimization (MOO) area.
Inside a sheep ﬂock, individuals are always trying to follow their bellwether (see
Fig. 7) who is the strongest one in the herd, but they may collide with each other while
moving. The bellwether leadership represents one major behavior that affects position
updating of the rest of the herd. A sheep ﬂock is loose which reﬂects a good divisibility
over a search region. It may be considered blind herd due to the occurrence of collision
between individuals, but this also gives an indication of a high-efﬁciency positive
feedback. Here is another interesting conclusion that is individuals of the herd move
randomly in their local position when strolling or playing in a self-awareness behavior.
Herd members keep sharable information of the position of bellwether. Before illus-
trating the algorithmic features of MOASA, let’s have a quick look at MOO class.
Unlike single-objective optimization, there are more than one objective in MOO each
with an independent measuring criterion.
20
A. M. Helmi and M. E. Lotfy

Thus, there is an objective function vector attached to each solution, and the
concept of Pareto dominance [118] deﬁnes the optimal one. Optimal solution may be
also called Pareto optima which dominates all other candidates if and only if it is the
best one in all metrics. For the ith candidate solution Xi tð Þ at iteration t in a population
of
size
N,
the
objective
function
vector
can
be
expressed
as
F Xi tð Þ
ð
Þ ¼
f1 Xi tð Þ
ð
Þ; . . .; fo Xi tð Þ
ð
Þ
½
, i ¼ 1; . . .; N and a number of o objectives. In MOO, more than
on Pareto optima may exist and constitute what is called Pareto front. In the context of
MOO algorithms, Pareto front is called external archive which currently preserves non-
dominated elite solutions during search process.
The algorithm of MOASA consists of four main operators: selection of bellwether,
positions update, releasing tired sheep, and neighborhood search of external archive.
A leader selection strategy based on external archive appeared ﬁrst in [118], and it is
used here to determine the ﬁttest solution to be followed by the rest of herd. For a
hypercubic objective search space, only one particle is randomly chosen from the
external archive to be the bellwether.
Now let us XB tð Þ denote the position of the bellwether (in the center of the entire
ﬂock), and then the movement of the ith member toward the bellwether can be cal-
culated as in Eq. 29.
xbw
i;d tð Þ ¼ xd
B tð Þ þ c1  xd
B tð Þ  xd
i tð Þ

	
ð29Þ
where xbw
i;d tð Þ is the new position of the ith member with respect to only the d-dimension
and c1 is a random coefﬁcient which is calculated as: c1 ¼ a  2  r1  1
ð
Þ 1  t=T
ð
Þ
with a randomly generated number r1 2 0; 1
½
, a works in the range [0, 1] and T is total
Fig. 7. Leadership of a bellwether in a sheep herd
Recent Advances of Nature-Inspired Metaheuristic Optimization
21

number of iterations. The parameter c1 controls the effect of leadership inﬂuence where
it is linearly decreased over search lifetime.
When the bellwether isn’t able to make notable movements, then the rest of the
ﬂock are allowed to follow the self-awareness behavior to look for better positions
nearby their local region. Let Xself
i;d
tð Þ denote the new position of the ith individual in
just one dimension d and can be calculated as in Eq. 30. Then Xself
i;d
tð Þ represents the
inertia and local random search of a solution.
xself
i;d tð Þ ¼ xd
i tð Þ þ R  xd
B tð Þ  xd
i tð Þ

	
ð30Þ
where R is a random number in 1; 1
½
.
Now, the mechanism of updating positions of sheep makes the beneﬁt of both
bellwether inﬂuence and self-awareness movement as expressed in Eq. 31 for the
speciﬁc dth dimension.
xd
i t þ 1
ð
Þ ¼ ui  xself
i;d tð Þ þ 1  ui
ð
Þ  xbw
i;d tð Þ
ð31Þ
where ui ¼ b  r2 with a random number r2 in 0; 1
½
 and b is decreased from 0.5 to 0 in
order to gradually limit the local movements and go closer to the ﬁttest solution in the
external archive. After that, the sheep which is closer to the bellwether has more chance
to update its position. The closeness of the ith sheep is denoted as nDom ið Þ that is the
number of other dominated individuals in all dimensions by the ith sheep. Thus, the
probability Pi of the ith sheep in a population of size N to update its position is deﬁned
as in Eq. 32.
Pi ¼ nDom ið Þ
N
ð32Þ
Then just one sheep is randomly selected using roulette wheel selection method in
order to get updated in the randomly chosen dth dimension.
In order to escape from local optima regions, a chaotic mutation (based on chaotic
maps) is applied to what is called a “tired” sheep. When some sheep cannot be able to
move to a better position for a predetermined number of iterations, then it is considered
as a tired one.
The neighborhood search is conducted by the help of both external archives
together with neighbor particles which are generated using Eq. 33.
L1 ¼ L0  Bd
u  Bd
l

	
;
xd
n ¼ xd
rep þ ðrand  0:5Þ  L1
ð33Þ
where xd
rep represents the dth dimension of a particle in the external archive, xd
n is the
determined neighbor particle, and d ¼ d1; . . .; dr
ð
Þ is randomly chosen r dimensions.
The number r of dimensions has to be gradually decreased as shown in Eq. 34, for
solution convergence achievement.
22
A. M. Helmi and M. E. Lotfy

r ¼
D
Itr ¼ 0
D  ed
Itr
MaxIter
ð
Þ
h
i
0\Itr\0:8  MaxItr
1
Itr [ 0:8  MaxItr
8
<
:
ð34Þ
where d is a coefﬁcient that guarantees that r is gradually decreased from the problem
dimension D down to 0 while iteration number Itr grows from 0 to MaxItr. The
notation ½  in the middle case of r in Eq. 34 represents the nearest integer value.
Thus, there is a newly generated N particle as neighbor ones to the original N-sized
external archive. Both populations are merged into a new mixed archive of non-
dominated particles. Finally, if one hypercubic or grid in the objective search space
contains more than one solution, then only the closest one to the corner with the
smallest objective value is kept, while others are deleted. Pseudo-code of MOASA is
given in Algorithm 7.
2:
Initialize population and evaluate individuals.
3:
4:
Repeat
Determine Pareto front members and mark other 
dominated ones.
5:
Update the external archive by the set of Pareto front. 
6:
Update population positions using Eqs. 
, and
evaluate them.
7:
Replace old positions by updated ones in case of 
improvement, otherwise, increment a 
parameter 
by
.
8:
If
parameter exceeds its maximum value, then 
release this tired sheep, reinitialize it using chaotic 
mutation and increment 
by . Reset 
to .
9:
For every individual in the external archive, generate 
a neighborhood search particle using Eq. 
and Eq. 
, 
and evaluate them. Increment 
by
.
10:
Merge the population of external archive and that one
generated in Step 
to collect a new mixed archive of
undominated particles. Keep only one solution in each
grid. 
11:
Calculate 
12:
Until maximum number of function evaluations is reached.
13:
Output the external archive.
Algorithm 7: Multi-Objective Artificial Sheep Algorithm (MOASA)
1:
Set the values of search parameters.
The termination condition is chosen to be the maximum allowable number of
function evaluations which is initially set to maximum number of iterations
(MaxItr)  Population size (N). MaxItr has to be gradually decreased over the exe-
cution of algorithm, so that the variable nExEval is used in Steps #8 and #9 in
Algorithm 7 to count extra functions evaluations. Updating population positions (Step
#6 in Algorithm 7) can be illustrated in Algorithm 8
Recent Advances of Nature-Inspired Metaheuristic Optimization
23

Algorithm 8: Updating Population Positions of MOASA
1:
Calculate the closeness of every sheep (i.e., solution) to 
the bellwether (best solution), denoted by 
.
2:
For 
3:
4:
Calculate 
using Eq. 
Select one solution based on Roulette Wheel Selection
Method
5:
Calculate 
using Eq. 
6:
Calculate 
using Eq. 
7:
Calculate the new position using Eq. 
8:
Evaluate -th solution
9:
Replace old position by the new one in case of 
Improvement
10:
End For
Performance of MOASA has been compared to similar algorithms in the category
of MOO, namely MO-GWO [118], MO-PSO [119], fast and elitist MO-GA [120], and
MO-EA based on decomposition [121]. Benchmark test functions were selected from
CEC 2009 competition [122] classiﬁed into bi-objective and tri-objective uncon-
strained functions, and bi-objective constrained functions. Dimensionality was set to 30
in all tests.
Two metrics are used to quantitatively assess the performance of compared MOO
algorithms, namely the inverted generational distance (IGD) [122] and the maximum
spread (MS) [123]. IGD indicator is used to estimate how far the points are in the
obtained Pareto front by the proposed algorithm from those in the true Pareto front. It
reveals both the convergence and coverage of the obtained Pareto front. IGD is
mathematically expressed as in Eq. 35.
IGD P; A
ð
Þ ¼
P
#2P d #; A
ð
Þ
P
j
j
ð35Þ
where A is the obtained Pareto front by an algorithm, P is the true Pareto front, P
j
j
represents the cardinality of this set, and d #; A
ð
Þ is the Euclidean distance between the
points on true Pareto front and its closest point in A. Hence, a smaller IGD metric
reﬂects a better performance.
The MS indicator gives an information about the maximum spread of the Pareto
front obtained by an algorithm and is expressed as in Eq. 36.
MS ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
X
obj
i¼1
max d ai; bi
ð
Þ
ð
Þ
v
u
u
t
ð36Þ
where among a number of obj objectives, ai and bi represent the maximum and
minimum values in the ith objective, respectively, with an Euclidean distance d ai; bi
ð
Þ.
Here, a larger value of MS metric reﬂects the preference of the concerned algorithm.
24
A. M. Helmi and M. E. Lotfy

Authors hinted that MS metric should be considered if the two compared algo-
rithms have the same IGD value as the latter is more informative as just explained
above.
Before illustrating the exhaustive experimental work to fairly evaluate MOASA
performance, it might be helpful to refer to this paper where the mathematical
expressions for the used test functions are available, besides the initial values of search
parameters of compared algorithms.
A test of 10 unconstrained test problems proposed in CEC 2009 competition has
been occurred for MOASA in comparison with the 4 other classical MOO mentioned
algorithms, and IGD and MS metrics were registered for each one. MOASA outper-
formed all others where it reports the best convergence and coverage Pareto front, as
well as ﬁnding the boundary of the true Pareto front. In particular, for the bi-objective
discrete MOO problem called UF5, only MOASA and MO-GWO have reported rea-
sonable results. MOASA was absolutely better whereas other considered competitor
algorithms failed.
Superiority of MOASA over other algorithms was very clear for tri-objective test
problems. Another bunch of 7 constrained test problems in CEC2009 was considered
for comparison of MOASA against MO-GWO and MO-PSO. In most cases, MOASA
shows better results with the smallest average IGD metric. Wilcoxon signed-rank test
was run based on average IGD metric in this particular test and results support the
better performance of MOASA. Holm–Bonferroni procedure-based ranking method
(main steps are available in [116]) was used to judge the performance of the 5 algo-
rithms of comparison here, on the basis of average values of IGD metric. Competitive
results of MOASA highly suggest considering it as an outstanding MOO algorithm.
Moreover, MOASA was compared to two recently developed similar algorithms:
MO-DA [69] and MO-PSO-DE [124], using the same computational burden for a fair
comparison. Some instances from the popular ZDT dataset [125] in MOO were chosen
for this test. Results were positive on the side of MOASA for most functions.
Regarding CEC 2009 competition, authors of MOASA decided to examine their
optimization tool against the best participating ones in this competition. Based on IGD
metric, MOASA outperforms the top 5 of the 13 participant optimization algorithms for
unconstrained MOO problems, in most cases. It is also the case for the top 3 of the 7
participant ones for constrained MOO problems.
Sensitivity analysis that occurred for MOASA gives some helpful guidelines for
further implementations of the algorithm. Maximum number of iterations (MaxItr)
should be larger than 100. Best practice for the value of nGrid, which denotes the
number of divisions for each dimension in the objective space (or the number of
particles in external archive), is to be 100 for bi-objective problems.
Since engineering problems bear different complexities rather than test functions,
MOASA
was
tested
for
the
bi-objective
short-term
economic
environmental
hydrothermal scheduling (SEEH) problem [126] (with economic and emission objec-
tives). This later problem is well explained in the paper where mathematical expres-
sions of both objective functions and constraints are given, as well as MOASA search
parameter settings. Solution found by MOASA was better than that one obtained in a
previous study [126].
Recent Advances of Nature-Inspired Metaheuristic Optimization
25

Lastly, some empirical results reveal that MOASA may require more enhancements
for discontinuity and diversity issues of Pareto front found, as concluded by the
authors.
3
Conclusions
Nature is still inspiring humans in an endless learning process. Discovering important
details of the lifestyle of different communities of animals motivates researchers to
create solutions for open problems in all ﬁelds. Optimization using metaheuristic
techniques is the application ﬁeld of introduced techniques in this chapter. We have
focused on an important class of metaheuristics which is called nature-inspired algo-
rithms (NIA). The class of single-objective optimization has recently received ﬁve new
NIA members, namely emperor penguin colony (EPC), sailﬁsh optimizer (SFO),
seagull optimization algorithm (SOA), pity beetle algorithm (PBA), and emperor
penguin optimizer (EPO). The last NIA technique introduced here is the multi-
objective artiﬁcial sheep algorithm (MOASA). They are all considered as swarm-based
optimization techniques. In this section, basic steps of movement mechanism of each
technique are illustrated together with distinguishable features.
EPC algorithm depends on the spiral-like movement of individuals of penguins to
adapt body temperature in order to update solutions. SOA starts with generating a free-
collision population of solutions. Movement mechanism makes use of both the spiral
movement of seagulls when attacking and the distance to best solution so far. SFO uses
two populations: sailﬁsh and sardine, in a different fashion to similar swarm-based
techniques. Thus, updating solutions is taking place within a hypersphere neighbor-
hood using two different elites of solutions. This of course improves exploration
capabilities and increases SFO algorithm immunity against local minima. PBA uses a
random sampling technique to collect populations from almost all portions in search
space. It also generates more than one population around promising positions. This
helps to improve the diversiﬁcation of this algorithm. Movement mechanism is another
novel feature of PBA technique. PBA switches between ﬁve different perturbation
methods when generating a new population instead of only one systematic way as
usual. PBA also provides the possibility of a mutation-like step if the quality of found
solutions is no longer improving. PBA structure bears many distinguished features that
maximize the chance to deal with most problems facing metaheuristic techniques.
Similar to EPC, EPO got inspired by some behavior inside penguin colonies. Move-
ment mechanism for EPO depends on calculations of both huddle boundaries and
temperature proﬁle. The most outstanding feature of EPO is performing collision
avoidance between solution agents. MOASA returns one Pareto optima solutions of the
problem under study. Updating solutions get affected by position of the ﬂock leader
called bellwether and self-awareness behavior (or local movements) of ﬂock members.
For low-quality solutions, a chaotic mutation step is applied to escape to another
region. One good feature of MOASA is generating a neighbor population to the
original one by inserting some randomness. Then both populations are merged together
to produce a better dominating population.
26
A. M. Helmi and M. E. Lotfy

Experimental tests of each presented technique and the algorithms of comparison
have been clearly mentioned, and this emphasizes the way of examining and designing
new similar techniques. Also, interested readers can ﬁnd answers in case of looking for
a very recent technique to apply to their problems.
No-free lunch theorems open the door to make use of scientiﬁc discoveries around
us in order to design more efﬁcient and high-quality stochastic optimization techniques.
References
1. Dey N (2018) Advancements in applied metaheuristic computing. IGI Global, Hershey,
PA, 978-1
2. Khosravy M, Gupta N, Patel N, Senjyu T, Duque CA (2020) Particle swarm optimization
of morphological ﬁlters for electrocardiogram baseline drift estimation. In: Dey N,
Ashour AS, Bhattacharyya S (eds) Applied nature-inspired computing: algorithms and case
studies. Springer, Singapore, pp 1–21
3. Moraes CA, De Oliveira, EJ, Khosravy, M, Oliveira, LW, Honório, LM, Pinto MF (2020)
A hybrid bat-inspired algorithm for power transmission expansion planning on a practical
Brazilian network. In: Dey N, Ashour AS, Bhattacharyya S (eds) Applied nature-inspired
computing: algorithms and case studies. Springer, Singapore, pp 71–95
4. Sedaaghi MH, Khosravi M (2003) Morphological ECG signal preprocessing with more
efﬁcient baseline drift removal. In: Proceedings of the 7th IASTED international
conference, ASC, pp 205–209
5. Khosravi M, Sedaaghi MH (2004) Impulsive noise suppression of electrocardiogram
signals with mediated morphological ﬁlters. In: The 11th Iranian conference on biomedical
engineering, Tehran, Iran, pp 207–212
6. Khosravy M, Asharif MR, Sedaaghi MH (2008) Medical image noise suppression: using
mediated morphology. IEICE technical report, IEICE, pp 265–270
7. Khosravy M, Gupta N, Marina N, Sethi IK, Asharif MR (2017) Perceptual adaptation of
image based on Chevreul-Mach bands visual phenomenon. IEEE Signal Process Lett 24
(5):594–598
8. Khosravy M, Gupta N, Marina N, Sethi IK, Asharif MR (2017) Brain action inspired
morphological image enhancement. Nature-inspired computing and optimization. Springer,
Cham, pp 381–407
9. Gutierrez CE, Alsharif MR, Cuiwei H, Khosravy M, Villa R, Yamashita K, Miyagi H
(2013) Uncover news dynamic by principal component analysis. ICIC Express Lett 7
(4):1245–1250
10. Gutierrez CE, Alsharif MR, Khosravy M, Yamashita K, Miyagi H, Villa R (2014) Main
large data set features detection by a linear predictor model. In: AIP conference
proceedings, vol 1618, no 1, pp 733–737
11. Gutierrez CE, Alsharif MR, Yamashita K, Khosravy M (2014) A tweets mining approach
to detection of critical events characteristics using random forest. Int J Next-Gener Comput
5(2):167–176
12. Khosravy M, Alsharif MR, Guo B, Lin H, Yamashita K (2009) A robust and precise
solution to permutation indeterminacy and complex scaling ambiguity in BSS-based blind
MIMO-OFDM receiver. In: International conference on independent component analysis
and signal separation. Springer, Berlin, pp 670–677
Recent Advances of Nature-Inspired Metaheuristic Optimization
27

13. Asharif F, Tamaki S, Alsharif MR, Ryu HG (2013) Performance improvement of constant
modulus algorithm blind equalizer for 16 QAM modulation. Int J Innovative Comput Inf
Control 7(4):1377–1384
14. Khosravy M, Alsharif MR, Yamashita K (2009) An efﬁcient ICA based approach to
multiuser detection in MIMO OFDM systems. Multi-carrier systems & solutions. Springer,
Dordrecht, pp 47–56
15. Khosravy M, Alsharif MR, Khosravi M, Yamashita K (2010) An optimum pre-ﬁlter for
ICA based multi-input multi-output OFDM system. In: 2010 2nd international conference
on education technology and computer, vol 5. IEEE, pp V5-129
16. Khosravy M, Patel N, Gupta N, Sethi IK (2019) Image quality assessment: a review to full
reference indexes. Recent trends in communication, computing, and electronics. Springer,
Singapore, pp 279–288
17. Khosravy M, Asharif MR, Sedaaghi MH (2008) Morphological adult and fetal ECG
preprocessing: employing mediated morphology (医用画像). 電子情報通信学会技術研
究報告. MI, 医用画像107(461):363–369
18. Sedaaghi MH, Daj R, Khosravi M (2001) Mediated morphological ﬁlters. In: Proceedings
2001 international conference on image processing (Cat. No. 01CH37205), vol 3. IEEE,
pp 692–695
19. Khosravy M, Gupta N, Marina N, Sethi IK, Asharif MR (2017) Morphological ﬁlters: an
inspiration from natural geometrical erosion and dilation. Nature-inspired computing and
optimization. Springer, Cham, pp 349–379
20. Khosravy M, Asharif MR, Yamashita K (2009) A PDF-matched short-term linear
predictability approach to blind source separation. Int J Innovative Comput Inf Control
(IJICIC) 5(11):3677–3690
21. Khosravy M, Alsharif MR, Yamashita K (2009) A PDF-matched modiﬁcation to stone’s
measure of predictability for blind source separation. In: International symposium on neural
networks. Springer, Berlin, pp 219–228
22. Khosravy M, Asharif MR, Yamashita K (2011) A theoretical discussion on the foundation
of Stone’s blind source separation. Signal Image Video Process 5(3):379–388
23. Khosravy M, Asharif M, Yamashita K (2008) A probabilistic short-length linear
predictability approach to blind source separation. In: 23rd international technical
conference on circuits/systems, computers and communications (ITC-CSCC 2008),
Yamaguchi, Japan, pp 381–384
24. Khosravy M, Kakazu S, Alsharif MR, Yamashita K (2010) Multiuser data separation for
short message service using ICA (信号処理). 電子情報通信学会技術研究報告. SIP, 信
号処理: IEICE Tech Rep 109(435):113–117
25. Khosravy M, Gupta N, Marina N, Asharif MR, Asharif F, Sethi IK (2015) Blind
components processing a novel approach to array signal processing: a research orientation.
In: 2015 international conference on intelligent informatics and biomedical sciences
(ICIIBMS), IEEE, pp 20–26
26. Khosravy M, Punkoska N, Asharif F, Asharif MR (2014) Acoustic OFDM data embedding
by reversible Walsh-Hadamard transform. In: AIP conference proceedings, vol 1618, no 1,
pp 720–723
27. Holland J (1975) Adaptation in natural and artiﬁcial systems. University of Michigan Press.
Ann Arbor, MI.
28. Goldberg DE (1989) Genetic algorithms in search, optimization, and machine learning.
Reading, MA: Addison-Wesley
29. Beyer HG, Schwefel HP (2002) Evolution strategies—a comprehensive introduction. Nat
Comput 1(1):3–52
28
A. M. Helmi and M. E. Lotfy

30. Gupta N, Patel N, Tiwari BN, Khosravy M (2018) Genetic algorithm based on enhanced
selection and log-scaled mutation technique. In: Proceedings of the future technologies
conference. Springer, Cham, pp 730–748
31. Singh G, Gupta N, Khosravy M (2015) New crossover operators for real coded genetic
algorithm (RCGA). In: 2015 international conference on intelligent informatics and
biomedical sciences (ICIIBMS), IEEE, pp 135–140
32. Gupta N, Khosravy M, Patel N, Senjyu T (2018) A bi-level evolutionary optimization for
coordinated transmission expansion planning. IEEE Access 6:48455–48477
33. Gupta N, Khosravy M, Patel N, Sethi IK (2018) Evolutionary optimization based on
biological evolution in plants. Procedia Comput Sci 126:146–155
34. Gupta N, Khosravy M, Mahela OP, Patel N (2020) Plants biology inspired genetics
algorithm: superior efﬁciency to ﬁreﬂy optimizer. In: Applications of ﬁreﬂy algorithm and
its variants, from springer tracts in nature-inspired computing (STNIC). Springer
International Publishing, in press
35. Blum C, Roli A (2003) Metaheuristics in combinatorial optimization: overview and
conceptual comparison. ACM Comput Surv (CSUR) 35(3):268–308
36. Fleischer M (2003) The measure of Pareto optima applications to multi-objective
metaheuristics. In: International conference on evolutionary multi-criterion optimization.
Springer, Berlin, pp 519–533
37. Talbi EG (2009) Metaheuristics: from design to implementation, vol 74. Wiley, Hoboken
38. Blum C, Roli A (2008) Hybrid metaheuristics: an introduction. Hybrid metaheuristics.
Springer, Berlin, pp 1–30
39. Dixit A, Kumar S, Pant M, Bansal R (2018) Hybrid nature-inspired algorithms:
methodologies, architecture, and reviews. In: International proceedings on advances in
soft computing, intelligent systems and applications. Springer, Singapore, pp 299–306
40. Yang XS (2014) Nature-inspired optimization algorithms. Elsevier, Amsterdam
41. Kirkpatrick S, Gelatt CD, Vecchi MP (1983) Optimization by simulated annealing. Science
220(4598):671–680
42. Storn R, Price K (1997) Differential evolution—a simple and efﬁcient heuristic for global
optimization over continuous spaces. J Global Optim 11(4):341–359
43. Dorigo M, Caro GD, Gambardella LM (1999) Ant algorithms for discrete optimization.
Artif Life 5(2):137–172
44. Haddad OB, Afshar A, Mariño MA (2008) Honey-bee mating optimization (HBMO)
algorithm in deriving optimal operation rules for reservoirs. J Hydroinformatics 10(3):257–
264
45. Karaboga D (2005) An idea based on honey bee swarm for numerical optimization.
Technical report-tr06, vol 200. Erciyes University, Engineering Faculty, Computer
Engineering Department, pp 1–10
46. Karaboga D, Basturk B (2008) On the performance of artiﬁcial bee colony (ABC) algo-
rithm. Appl Soft Comput 8(1):687–697
47. Kennedy J, Eberhart R (1995) Particle swarm optimization. In: Proceedings of the IEEE
international conference on neural networks, Piscataway, NJ, USA, pp 1942–1948
48. Noller C, Smith VR (1987) Ultraviolet selection pressure on earliest organisms. In:
Kingston H, Fulling CP (eds) Natural environment background analysis. Oxford University
Press, Oxford, pp 211–219
49. Yang XS (2008) Nature-inspired metaheuristic algorithms, 1st edn. Luniver Press, Bristol
50. Yang XS (2012) Bat algorithm for multi-objective optimisation. arXiv preprint arXiv:1203.
6571
51. Geem ZW, Kim JH, Loganathan GV (2001) A new heuristic optimization algorithm:
harmony search. Simulation 76(2):60–68
Recent Advances of Nature-Inspired Metaheuristic Optimization
29

52. Yang XS (2012) Flower pollination algorithm for global optimization. In: International
conference on unconventional computing and natural computation. Springer, Berlin,
pp 240–249
53. Lindﬁeld G, Penny J (2017) Introduction to nature-inspired optimization. Academic Press,
Cambridge
54. Dorigo M, Stützle T (2004) Ant colony optimization. MIT Press, Cambridge
55. Passino KM (2010) Bacterial foraging optimization. Int J Swarm Intell Res (IJSIR) 1(1):
1–16
56. Biswas A, Mishra KK, Tiwari S, Misra AK (2013) Physics-inspired optimization
algorithms: a survey. J Optim
57. Bozorg-Haddad O (ed) (2018) Advanced optimization by nature-inspired algorithms.
Springer, Singapore
58. Chu SC, Tsai PW (2007) Computational intelligence based on the behavior of cats. Int J
Innovative Comput Inf Control 3(1):163–173
59. Kashan AH (2009) League championship algorithm: a new algorithm for numerical
function optimization. In: 2009 international conference of soft computing and pattern
recognition, IEEE, pp 43–48
60. Ahmadi-Javid A (2011) Anarchic society optimization: a human-inspired method. In: 2011
IEEE Congress of Evolutionary Computation (CEC), IEEE, pp 2586–2592
61. Rao RV, Savsani VJ, Vakharia DP (2011) Teaching–learning-based optimization: a novel
method for constrained mechanical design optimization problems. Comput Aided Des 43
(3):303–315
62. Gandomi AH, Alavi AH (2012) Krill herd: a new bio-inspired optimization algorithm.
Commun Nonlinear Sci Numer Simul 17(12):4831–4845
63. Mirjalili S, Mirjalili SM, Lewis A (2014) Grey wolf optimizer. Adv Eng Softw 69:46–61
64. Abedinia O, Amjady N, Ghasemi A (2016) A new metaheuristic algorithm based on shark
smell optimization. Complexity 21(5):97–116
65. Mirjalili S (2015) The ant lion optimizer. Adv Eng Softw 83:80–98
66. Kuo RJ, Zulvia FE (2015) The gradient evolution algorithm: a new metaheuristic. Inf Sci
316:246–265
67. Mirjalili S (2015) Moth-ﬂame optimization algorithm: a novel nature-inspired heuristic
paradigm. Knowl-Based Syst 89:228–249
68. Mirjalili S (2016) Dragonﬂy algorithm: a new meta-heuristic optimization technique for
solving single-objective, discrete, and multi-objective problems. Neural Comput Appl
27(4):1053–1073
69. Askarzadeh A (2016) A novel metaheuristic method for solving constrained engineering
optimization problems: crow search algorithm. Comput Struct 169:1–12
70. Yang XS (ed) (2017) Nature-inspired algorithms and applied optimization, vol 744.
Springer, Berlin
71. HariﬁS, Khalilian M, Mohammadzadeh J, Ebrahimnejad S (2019) Emperor penguins
colony: a new metaheuristic algorithm for optimization. Evol Intel 12(2):211–226
72. Atashpaz-Gargari E, Lucas C (2007) Imperialist competitive algorithm: an algorithm for
optimization inspired by imperialistic competition. In: 2007 IEEE congress on evolutionary
computation, IEEE, pp 4661–4667
73. Sang HY, Duan PY, Li JQ (2018) An effective invasive weed optimization algorithm for
scheduling semiconductor ﬁnal testing problem. Swarm Evol Comput 38:42–53
74. Derrac J, García S, Molina D, Herrera F (2011) A practical tutorial on the use of
nonparametric statistical tests as a methodology for comparing evolutionary and swarm
intelligence algorithms. Swarm Evol Comput 1(1):3–18
30
A. M. Helmi and M. E. Lotfy

75. Mendenhall W, Beaver RJ, Barbara MB (2012) Introduction to probability and statistics.
Cengage Learning, Boston
76. Dhiman G, Kumar V (2019) Seagull optimization algorithm: theory and its applications for
large-scale industrial engineering problems. Knowl-Based Syst 165:169–196
77. Liang JJ, Suganthan PN, Deb K (2005) Novel composition test functions for numerical
global optimization. In: Proceedings 2005 IEEE swarm intelligence symposium, SIS 2005,
IEEE, pp 68–75
78. Chen Q, Liu B, Zhang Q, Liang J (2015) Evaluation criteria for CEC special session and
competition on bound constrained single-objective computationally expensive numerical
optimization. In: CEC
79. Dhiman G, Kumar V (2017) Spotted hyena optimizer: a novel bio-inspired based
metaheuristic technique for engineering applications. Adv Eng Softw 114:48–70
80. Mirjalili S, Mirjalili SM, Hatamlou A (2016) Multi-verse optimizer: a nature-inspired
algorithm for global optimization. Neural Comput Appl 27(2):495–513
81. Mirjalili S (2016) SCA: a sine cosine algorithm for solving optimization problems. Knowl-
Based Syst 96:120–133
82. Rashedi E, Nezamabadi-Pour H, Saryazdi S (2009) GSA: a gravitational search algorithm.
Inf Sci 179(13):2232–2248
83. Wilcoxon F (1992) Individual comparisons by ranking methods. Breakthroughs in
statistics. Springer, New York, NY, pp 196–202
84. Mann HB, Whitney DR (1947) On a test of whether one of two random variables is
stochastically larger than the other. Ann Math Stat 50–60
85. Shadravan S, Naji HR, Bardsiri VK (2019) The sailﬁsh optimizer: a novel nature-inspired
metaheuristic algorithm for solving constrained engineering optimization problems. Eng
Appl Artif Intell 80:20–34
86. Moosavi SHS, Bardsiri VK (2017) Satin bowerbird optimizer: a new optimization
algorithm to optimize ANFIS for software development effort estimation. Eng Appl Artif
Intell 60:1–15
87. Mirjalili S, Gandomi AH, Mirjalili SZ, Saremi S, Faris H, Mirjalili SM (2017) Salp swarm
algorithm: a bio-inspired optimizer for engineering design problems. Adv Eng Softw
114:163–191
88. Wang GG (2003) Adaptive response surface method using inherited latin hypercube design
points. J Mech Des 125(2):210–220
89. Liu J, Li Y (2012) An improved adaptive response surface method for structural reliability
analysis. J Central South Univ 19:1148–1154
90. Cheng MY, Prayogo D (2014) Symbiotic organisms search: a new metaheuristic
optimization algorithm. Comput Struct 139:98–112
91. Siddall JN (1972) Analytical decision-making in engineering design. Prentice Hall, USA
92. Coello CAC (2002) Theoretical and numerical constraint-handling techniques used with
evolutionary algorithms: a survey of the state of the art. Comput Methods Appl Mech Eng
191(11–12):1245–1287
93. Ragsdell K, Phillips D (1976) Optimal design of a class of welded structures using
geometric programming. ASME J Eng Ind 98:1021–1025
94. He Q, Wang L (2007) An effective co-evolutionary particle swarm optimization for
constrained engineering design problems. Eng Appl Artif Intell 20(1):89–99
95. Sadollah A, Bahreininejad A, Eskandar H, Hamdi M (2013) Mine blast algorithm: a new
population based algorithm for solving constrained engineering optimization problems.
Appl Soft Comput 13(5):2592–2612
Recent Advances of Nature-Inspired Metaheuristic Optimization
31

96. Liu H, Cai Z, Wang Y (2010) Hybridizing particle swarm optimization with differential
evolution for constrained numerical and engineering optimization. Appl Soft Comput 10
(2):629–640
97. Ray T, Saini P (2001) Engineering design optimization using a swarm with an intelligent
information sharing among individuals. Eng Optim 33(6):735–748
98. Eskandar H, Sadollah A, Bahreininejad A, Hamdi M (2012) Water cycle algorithm—a
novel metaheuristic optimization method for solving constrained engineering optimization
problems. Comput Struct 110:151–166
99. Kallioras NA, Lagaros ND, Avtzis DN (2018) Pity beetle algorithm—a new metaheuristic
inspired by the behavior of bark beetles. Adv Eng Softw 121:147–166
100. Shi Y, Eberhart R (1998) A modiﬁed particle swarm optimizer. In: 1998 IEEE international
conference on evolutionary computation proceedings. IEEE world congress on computa-
tional intelligence (Cat. No. 98TH8360), IEEE, pp 69–73
101. Clerc M, Kennedy J (2002) The particle swarm-explosion, stability, and convergence in a
multidimensional complex space. IEEE Trans Evol Comput 6(1):58–73
102. Kennedy J, Mendes R (2002) Population structure and particle swarm performance. In:
Proceedings
of the
2002 Congress
on
Evolutionary Computation
CEC’02
(Cat.
No. 02TH8600), vol 2, IEEE, pp 1671–1676
103. Parsopoulos KE (2004) UPSO: a uniﬁed particle swarm optimization scheme. Lecture
series on computer and computational science, vol 1, pp 868–873
104. Mendes R, Kennedy J, Neves J (2004) The fully informed particle swarm: simpler, maybe
better. IEEE Trans Evol Comput 8(3):204–210
105. Liang JJ, Qin AK, Suganthan PN, Baskar S (2006) Comprehensive learning particle swarm
optimizer for global optimization of multimodal functions. IEEE Trans Evol Comput 10(3):
281–295
106. Chen WN, Zhang J, Lin Y, Chen N, Zhan ZH, Chung HSH, Shi YH (2012) Particle swarm
optimization with an aging leader and challengers. IEEE Trans Evol Comput 17(2):
241–258
107. Chen D, Wang J, Zou F, Hou W, Zhao C (2012) An improved group search optimizer with
operation of quantum-behaved swarm and its application. Appl Soft Comput 12(2):
712–725
108. Loshchilov I, Stuetzle T, Liao T (2013) Ranking results of CEC’13 special session &
competition on real-parameter single objective optimization. In: 2013 IEEE Congress on
Evolutionary Computation (CEC), June, pp 20–23
109. Liang JJ, Qu BY, Suganthan PN (2013) Problem deﬁnitions and evaluation criteria for the
CEC 2014 special session and competition on single objective real-parameter numerical
optimization. Computational Intelligence Laboratory, Zhengzhou University, Zhengzhou
China and Technical Report, Nanyang Technological University, Singapore, 635
110. Preux P, Munos R, Valko M (2014) Bandits attack function optimization. In: 2014 IEEE
Congress on Evolutionary Computation (CEC), IEEE, pp 2245–2252
111. Yu C, Kelley L, Zheng S, Tan Y (2014) Fireworks algorithm with differential mutation for
solving the CEC 2014 competition problems. In: 2014 IEEE Congress on Evolutionary
Computation (CEC), IEEE, pp 3238–3245
112. Hu Z, Bao Y, Xiong T (2014) Partial opposition-based adaptive differential evolution
algorithms: evaluation on the CEC 2014 benchmark set for real-parameter optimization. In:
2014 IEEE Congress on Evolutionary Computation (CEC), IEEE, pp 2259–2265
113. Tanabe R, Fukunaga AS (2014) Improving the search performance of SHADE using linear
population size reduction. In: 2014 IEEE Congress on Evolutionary Computation (CEC),
IEEE, pp 1658–1665
32
A. M. Helmi and M. E. Lotfy

114. Dhiman G, Kumar V (2018) Emperor penguin optimizer: a bio-inspired algorithm for
engineering problems. Knowl-Based Syst 159:20–50
115. Chen Q, Liu B, Zhang Q, Liang J, Suganthan P, Qu B (2014) Problem deﬁnitions and
evaluation criteria for CEC 2015 special session on bound constrained single-objective
computationally expensive numerical optimization. Technical report, Computational
Intelligence Laboratory, Zhengzhou University, Zhengzhou, China and Technical Report,
Nanyang Technological University
116. Lai X, Li C, Zhang N, Zhou J (2018) A multi-objective artiﬁcial sheep algorithm. Neural
Comput Appl 1–35
117. Wang W, Li C, Liao X, Qin H (2017) Study on unit commitment problem considering
pumped storage and renewable energy via a novel binary artiﬁcial sheep algorithm. Appl
Energy 187:612–626
118. Mirjalili S, Saremi S, Mirjalili SM, Coelho LDS (2016) Multi-objective grey wolf
optimizer: a novel algorithm for multi-criterion optimization. Expert Syst Appl 47:106–119
119. Coello CC, Lechuga MS (2002) MOPSO: A proposal for multiple objective particle swarm
optimization. In: Proceedings of the 2002 Congress on Evolutionary Computation, CEC’02
(Cat. No. 02TH8600), vol 2. IEEE, pp 1051–1056
120. Deb K, Pratap A, Agarwal S, Meyarivan TAMT (2002) A fast and elitist multiobjective
genetic algorithm: NSGA-II. IEEE Trans Evol Comput 6(2):182–197
121. Zhang Q, Li H (2007) MOEA/D: a multiobjective evolutionary algorithm based on
decomposition. IEEE Trans Evol Comput 11(6):712–731
122. Zhang Q, Zhou A, Zhao S, Suganthan PN, Liu W, Tiwari S (2009) Multi-objective
optimization test instances for the CEC 2009 special session and competition. University of
Essex
123. Sierra MR, Coello CAC (2005) Improving PSO-based multi-objective optimization using
crowding, mutation and 2-dominance. In: Evolutionary multi-criterion optimization.
Springer, Berlin
124. Su YX, Chi R (2017) Multi-objective particle swarm-differential evolution algorithm.
Neural Comput Appl 28(2):1–12
125. Zitzler E, Deb K, Thiele L (2000) Comparison of multiobjective evolutionary algorithms:
empirical results. Evol Comput 8(2):173–195
126. Basu M (2004) An interactive fuzzy satisfying method based on evolutionary programming
technique for multiobjective short-term hydrothermal scheduling. Electr Power Syst Res
69(2–3):277–285
Recent Advances of Nature-Inspired Metaheuristic Optimization
33

Prediction in Nature-Inspired Dynamic
Optimization
Almuth Meier(B) and Oliver Kramer(B)
{almuth.meier,oliver.kramer}@uni-oldenburg.de
Computational Intelligence Group, Department of Computer Science, University of
Oldenburg, Oldenburg, Germany
1
Introduction
Many real-world optimization problems are not stationary, but changing over
time. This optimization scenario is known as dynamic optimization. Changing
objective functions results in moving optima and may be due to changing con-
ditions like environmental parameters in real world and also due to varying
constraints, in particular, when the optimum lies at the boundary of the fea-
sible search region. In black-box optimization scenarios, where no information
is available, but only the evaluation of a solution at a certain point x ∈Rd in
solution space, the objective is to ﬁnd the optimal solution o ∈Rd, which is bet-
ter than any other solution w.r.t. the objective function f(x), i.e., f(o) ≤f(x)
for all x ∈Rd. In dynamic optimization, f is changing over time, so is o. The
task becomes to ﬁnd and follow the optimum, while it is dynamically moving in
solution space.
Standard methods in nature-inspired optimization like evolution strate-
gies (ES) and particle swarm optimization (PSO) may be able to follow a mov-
ing optimum without further modiﬁcations. However, prediction methods that
learn changes and movements of f often outperform standard methods in terms
of convergence speed and therefore save potentially expensive ﬁtness function
evaluations. Prediction methods are learning algorithms, often from the ﬁeld of
statistical learning or recently deep learning. They are based on the assump-
tion that repeating patterns occur and that learning these patterns helps the
optimization process to follow learned changes faster.
This chapter overviews prediction-based dynamic optimization, which is
one branch in the ﬁeld of nature-inspired dynamic optimization. The chapter
gives ideas for enhancing static optimization algorithms by prediction strategies
enabling them to solve dynamic optimization problems. Furthermore, it pro-
vides methodological hints for benchmarking and evaluating the quality of new
algorithms in this ﬁeld.
The chapter is structured as follows. In Sect. 2, we give a short introduc-
tion to ES and PSO, which are the baseline algorithms of the following depic-
tions. We present ways to characterize dynamic optimization problems in Sect. 3.
Section 4 overviews dynamic optimization approaches with an emphasis on
c
⃝Springer Nature Singapore Pte Ltd. 2020
M. Khosravy et al. (eds.), Frontier Applications of Nature Inspired Computation,
Springer Tracts in Nature-Inspired Computing,
https://doi.org/10.1007/978-981-15-2133-1_2

Prediction in Nature-Inspired Dynamic Optimization
35
prediction. Section 5 gives an introduction to prediction methods frequently
applied in dynamic optimization. Benchmark problem sets are introduced in
Sect. 6. Quality measures required for the comparison of approaches are described
in Sect. 7. Section 8 presents an approach to incorporate predicted optima into
ES-based search, while Sect. 9 explains the same for PSO. Section 10 shows
how uncertainty information from temporal convolutional neural networks can
improve the optimization process. Section 11 summarizes the most important
ﬁndings and presents an outlook to future research directions.
2
Nature-Inspired Optimization
Nature-inspired optimization methods are optimization algorithms, whose oper-
ators and algorithmic structure are inspired by principles that can be observed
in nature. Among the many optimization algorithms that exist, most research
on dynamic optimization focuses on the main branches, which are ES and PSO.
2.1
Evolution Strategies
ES belong to the family of evolutionary algorithms and have been introduced
by Rechenberg and Schwefel [42]. The search is based on a population P of
solutions, which are subject to recombination and mutation. Algorithm 1 shows
the pseudocode of the prominent (μ+λ)-ES. At the beginning, μ initial solutions
are generated, e.g., randomly in the whole solution space. In each generation, λ
oﬀspring solutions are generated based on crossover and mutation (Line 3), which
is often the Gaussian mutation in Rd; see [3]. At the end of each generation, the
best solutions are selected as parents for the following generation (Line 4).
Algorithm 1 (μ+λ)-ES
1: P ←initialize population()
# random solution candidates
2: for generations do
3:
P’ ←create λ oﬀspring individuals(P)
# recombination&mutation
4:
P ←select best μ individuals(P, P’)
2.2
Particle Swarm Optimization
PSO has been introduced by Kennedy and Eberhart [24] and is based on the
idea of a swarm of ﬂying solutions that are attracted by the best found solutions.
Algorithm 2 shows the pseudocode of the basic PSO algorithm.

36
A. Meier and O. Kramer
Algorithm 2 PSO
1: S ←initialize swarm particles()
# random position&velocity
2: for iterations do
3:
S ←move particles(S)
# following Eqs. (1), (2)
4:
update xp, xs
# re-compute xp for each particle
Each particle in a swarm has a position x ∈Rd and a velocity v ∈Rd. Both
parameters are iteratively updated as follows:
vt = ωvt−1 + θ1r1(xp −xt−1) + θ2r2(xs −xt−1)
(1)
xt = xt−1 + vt
(2)
Variable xp saves the best solution the particle has found during lifetime, while xs
saves the best position ever found by the whole swarm. Parameter ω is the inertia
weight inﬂuencing the previous velocity, and θ1 and θ2 are scalars balancing the
particle’s egoism and altruism. The random vectors r1, r2 ∈[0, 1]d allow random
explorations. The optimization process is terminated when a criterion is met.
3
Characteristics of Dynamic Optimization Problems
In a dynamic optimization problem, an objective function f(x, t) →R is opti-
mized, while the ﬁtness of solutions x ∈Rd is time-dependent. The character of a
dynamic optimization problem depends on the type of ﬁtness landscape and the
dynamics of changes. Fitness landscapes can be distinguished according to their
modality, separability, restriction, and whether the solution space is continuous
or discrete [25].
Diﬀerent approaches have been proposed to characterize the dynamics of
changes [48]. Sim˜oes and Costa [48] characterize dynamic optimization prob-
lems according to when and how they change. In some scenarios, the objective
function remains static during a change period over a speciﬁc number of func-
tion evaluations, while changes occur at discrete points in time. The length of
the period may follow a predictable pattern or may be completely random and
unpredictable. In other cases, the objective function varies continuously so that
each function evaluation leads to a diﬀerent value.
The way how the objective function changes can be classiﬁed regarding the
function shape. In some problems, the ﬁtness landscapes move, while their shape
does not change, i.e., the relative ﬁtness diﬀerences between solutions remain
constant. Other problems show a dynamic change of the ﬁtness landscape, where
new peaks can appear, becoming ﬂatter, or disappear. Sim˜oes and Costa [48]
introduce the predictability and the severity of the ﬁtness function change as
categories for a dynamic optimization problem taxonomy.
In this chapter, we consider unconstrained continuous objective functions
with diﬀerent properties regarding modality and separability. The dynamic opti-
mization problems are instantiated with deterministic changes at discrete points
in time. We chose predictable dynamics to show the algorithmic strengths of the
prediction approaches.

Prediction in Nature-Inspired Dynamic Optimization
37
4
Dynamic Optimization Approaches Based
on Prediction
If dynamic optimization problems are solved by standard approach from nature-
inspired optimization like ES or PSO, problems during the convergence process
may occur. When the optimum moves slowly through solution space, standard
algorithms may be able to follow. But if optima tend to jump within solution
space, standard optimization algorithms might fail to follow or even detect new
basins of attraction.
Meanwhile, many approaches have been proposed to solve dynamic opti-
mization problems. A convenient survey can be found in [2] and in [10]. Some
approaches are based on enforcing diversity by restart or integrating ran-
dom solutions, in this context often called immigrants or gifts, e.g., applied
in [9,13,19]. Other approaches are based on using a memory that stores good
solutions found during previous generations for replacing worse ones in the course
of the optimization process.
If changes in the objective function obey a certain pattern and are not
solely based on randomness, prediction approaches can be applied. Prediction
approaches use an archive as a training set which is used for learning, i.e., for
adapting parameters of the prediction method. Nguyen et al. [39] note that also
memory approaches belong to the class of prediction approaches as they use
information from the course of the optimization process. Prediction approaches
for dynamic optimization can be classiﬁed into the following concepts:
• Predicted optimum as immigrant: Predicted optima can be integrated into
the population to enrich the populations with immigrants. Hatzakis and
Wallace [17] use an autoregressive approach, and Rossi et al. [45] and Muru-
ganantham et al. [36] employ a Kalman ﬁlter for this sake. Related approaches
adapt the population based on the predicted Pareto set [11,44,50] or predicted
reference points [22,54].
• Predicted optimum for operators: Predicted optima can be used to bias oper-
ators, e.g., the mutation operator [45] or the PSO equation [32].
• Prediction for ﬁtness functions: Predictions can also be used to inﬂuence the
evaluation of solutions. For example, Rossi et al. [45] propose to improve the
ﬁtness of solutions in the neighborhood of predicted optima. It is also possible
to learn dynamic meta-models of the near future of the ﬁtness function, e.g.,
one step ahead [8].
• Prediction of individuals: In this class of approaches, for each individual its
next position is predicted based on the position of its predecessor [53].
• Prediction of points in time of next change: Some approaches [46,47] concen-
trate on predicting the time, when the next change takes place. This infor-
mation can be used to reset the algorithm, e.g., to initial settings like large
step sizes. It can also be combined with approaches that predict the optima
while using promising initial parameters.
• Prediction for time-linkage problems: If the dynamics of the problem is inﬂu-
enced by solutions chosen or generated by the optimization algorithm, e.g., in

38
A. Meier and O. Kramer
reinforcement scenarios or in job scheduling algorithms, approaches can take
into account the predictions of probable changes of the objective function
based on own solution choices [5,6,8,41].
The choice of the prediction approach is determined by the choice of the opti-
mization algorithm and the application context. For example, we have shown
that for PSO the approach to use predictions as immigrants is less successful
than biasing the swarm to the predicted directions [32]. Moreover, predicting
when the next change will occur is only helpful if the points in time of changes
follow a predictable pattern. For unpredictable points in time, the use of mech-
anism which detect changes is recommended.
In Sect. 5, we give a short overview of prediction methods that can be
employed for the mentioned approaches. Sections 8, 9 and 10 give examples
for using predicted optima as immigrants and for biasing operators.
5
Prediction Methods
Prediction methods are machine learning techniques that learn models based on
training data. In a supervised learning scenario, training data comes in pattern
label pairs (xi, yi) for i = 1, . . . , N. The training data is used to train a prediction
model ˆf that outputs a reasonable prediction ˆf(x′) given a novel pattern x′. For
an introduction to machine learning and prediction methods, of which most are
appropriate for the application in dynamic optimization, we recommend Hastie
et al. [16], Bishop [4] and further introductory textbooks. The methods diﬀer
mainly in their computational complexity and in types of relationships in the
data they are intended to cover, e.g., linear or nonlinear. In the following, we
restrict our depiction to the relevant methods that have found application in
evolutionary dynamic optimization, e.g., in [17,32,45].
5.1
Kalman Filter
Kalman ﬁlters [23] are linear recursive time series models that are based on the
assumption of noisy measurements in observable system states [45]. They can be
applied for both estimating the true state variables underlying noisy observations
and also for predicting the next state for that not yet observations are available.
First, a priori estimation of the next system state and the estimation’s error
covariance are computed. After obtaining an observation for the next time step,
the parameters of the ﬁlter model are optimized in order to minimize the a
posteriori covariance error. The updated model is used to compute the posteriori
estimation for the state and its error covariance.
5.2
Autoregressive Model
Statistical learning methods [21] are historically based on the area of statis-
tics. Basic methods are linear models that assume a linear relationship between

Prediction in Nature-Inspired Dynamic Optimization
39
input and output variables, i.e., features of patterns and labels. Autoregressive
models (AR) belong to this class and can be applied to various types of time
series [20].
An AR model predicts the value of a d-dimensional variable x ∈Rd for the
time step t + 1 with
xt+1 = θ +
p−1

i=0
Φixt−i + ϵt+1,
(3)
where x, θ, ϵ ∈Rd and Φi ∈Rd×d. The order p deﬁnes how many previous
time steps are considered [20], and Φi controls the inﬂuence of xt−i on xt+1.
Vector θ consists of constants. The noise parameters ϵt, containing values with
zero mean and covariance matrix C ∈Rd×d, are uncorrelated [37]. The least
squares method is used to determine parameters θ, Φ and C.
5.3
Recurrent Neural Networks
Neural networks have been introduced as nature-inspired learning methods in the
nineties of the last century. Since the success of convolutional networks, which
have been successfully applied in AlexNet [26] in 2012, and an ongoing growth
of powerful network architectures for various domains, which can be parallelized
on graphics processing units (GPU), neural networks celebrate great success in
various domains known as deep learning.
Recurrent neural networks (RNNs) have shown strengths in time series
prediction and are neural networks representing past observations with hid-
den states. In RNNs, neurons are connected with themselves so that the neu-
rons’ output is led back to the input [43]. Let xt ∈Rd be the input of a
neuron and f the function the neuron outputs. Then, the neuron computes
f (xt, f (xt−1, f (xt−2, . . .))) while taking into account values of x for previous
time steps. Due to their backward connections, RNNs can model relationships
between observations from diﬀerent time steps. How many time steps the RNN
considers for learning should be chosen depending on the problem. Due to the
vanishing gradient problem, RNNs are trained with a modiﬁed backpropagation
procedure known as backpropagation through time; see [43]. Various extensions
of RNNs have been proposed. A prominent one is the long short-term memory
(LSTM) network [18] that allows learning insertions and deletions of patterns
with mechanisms like attention and forget gates.
6
Benchmark Problem Sets
For evaluation and comparison of diﬀerent approaches, benchmark problem sets
are essential. In evolutionary dynamic optimization, various convenient bench-
mark sets have been proposed, e.g., [34,40,51,52]. Nguyen et al. [39] give a
convenient overview discussing strengths and weaknesses. In the following, we
introduce a subjective selection of dynamic benchmark problems which we found
appropriate for testing prediction methods.

40
A. Meier and O. Kramer
6.1
Moving Peaks Benchmark
The moving peaks benchmark (MPB) [7] is a standard test set in evolutionary
dynamic optimization. It consists of multiple peaks with randomly changing
positions, heights and widths. The optimum can move linearly controlled with
noise that can be adapted via a correlation factor; see [35]. The optimum may
jump if a previous local optimum becomes the new global one.
The ﬁtness of solution x in change period c is computed with
f(x, c) =
max
i=1,...,# peaks
Hi
c
1 + W ic∥x −Xic∥2
2
,
(4)
where ∥·∥2
2 is the squared Euclidean norm. The height Hi, width W i and position
Xi of the ith peak underly random change
Hi
c = Hi
c−1 + sh · ϵ
(5)
W i
c = W i
c−1 + sw · ϵ
(6)
Xi
c = Xi
c−1 + bi
c
(7)
with ϵ ∼N (0, 1), sh height severity and sw width severity. Vector bi
c causes
the position movement. Its severity is determined by the shift length sl, i.e., the
speciﬁed length of bi
c [35]. The vector is calculated with
bi
c =
sl
∥ϵ + bi
c−1∥2

(1 −η) ϵ + ηbi
c−1

(8)
where ϵ is a vector of standard normal distributed values. Correlation factor
η ∈[0, 1] leads to a completely random movement for η = 0 and with η = 1 to
a deterministic linear shift. Figure 1 visualizes a ten-dimensional MPB instance
with η = 1.
6.2
CEC Competition Benchmark
For the Congress on Evolutionary Computation (CEC), benchmark problem sets
have been introduced as a challenge in 2009 [29], 2012 [30] and 2014 [27]. For
example, the latter contains a rotation peak function and composition of basic
functions.
The dynamic rotation peak benchmark generator (DRPBG) is based on the
concept of peaks like MPB. The ﬁtness function in change period c is as follows:

Prediction in Nature-Inspired Dynamic Optimization
41
Fig. 1. MPB as minimization problem with ten peaks (η = 1). Left: Static ﬁtness
landscape. Right: For each change period the peaks’ positions (- - -) and the position
of the global optimum (—) in dimension 0
f(x, c) =
max
i=1,...,# peaks
Hi
c
1 + W ic

1
d∥x −Xic∥2
2
,
(9)
with symbols as deﬁned for MPB. In DRPBG, ten diﬀerent types exist to change
the peaks’ heights, width and position, e.g., with random, chaotic, recurrent and
noisy changes.
The second CEC 2014 benchmark is the dynamic composition benchmark
generator (DCBG). It allows for composing a weighted selection of the ﬁve basic
functions Sphere, Rastrigin, Weierstrass, Griewank and Ackley to one ﬁtness
function. The dynamics for moving these functions is the same as for DRPBG.
For more details on DRPBG and DCBG; see [27].
6.3
Free Peaks Benchmark
Li et al. [28] introduced an open framework for constructing continuous opti-
mization problems. The framework called free peaks benchmark (FPB) can gen-
erate global, multimodal, multi-objective, dynamic and constrained optimization
problems. In FPB, the solution space is divided into a deﬁned number of non-
overlapping partitions, in which each are equipped with one of the eight base
functions. The ﬁtness of an individual is computed with the base function of the
partition it is located in.
Among the dynamic optimization part, the free peaks benchmark oﬀers equa-
tions to change an optimum’s location, the shape of its neighborhood, the size of
the optimum’s basin of attraction, the height of the basin and number of optima.
Similar to MPB, the peaks’ movement within their respective subspace is linear
with adjustable noise. To modify the landscape around a peak, the correspond-
ing base function can be replaced by one of the eight ones. By relocating the
partition boundaries, a peak’s basin of attraction can be enlarged or reduced.

42
A. Meier and O. Kramer
Also, the basin’s height is randomly changed like in MPB. Since these functions
are unimodal, the number of peaks can dynamically be changed by varying the
numbers of partitions.
6.4
Dynamic Sine Benchmark
In [33], we proposed the dynamic sine benchmark (DSB) to address the prob-
lem that many benchmarks only allow simple movements of their optima not
reﬂecting dynamics that may occur in real-world problems. The DSB problems
are quantiﬁable in their dynamics and are based on moving classic stationary ﬁt-
ness functions fs, e.g., Sphere or Rosenbrock, with parameterized trigonometric
functions:
ζw(c) = τ +
ρ

i=1
(ιi · sin (βi · κ · (c −1) + γi))
(10)
Function ζw describes the optimum position in dimension w depending on the
change period c. Here, ρ sine functions with randomly parametrized amplitude ιi,
frequency βi and phase shift γi are multiplied and vertically moved by τ. Step size
κ represents the distance between succeeding points at which ζw is evaluated. The
DSB problems change after periods of constant length. Figure 2 illustrates the
DSB’s movement for the Sphere function in two dimensions. The left part shows
for each change period the optimum position separately for each dimension;
whereas, in the right ﬁgure the movement of the ﬁtness landscape in the resulting
two-dimensional solution space is visualized.
Fig. 2. DSB for Sphere function. Left: Optimum position separately for dimensions.
Right: Fitness landscape in the corresponding solution space at three diﬀerent time
points
7
Quality Measures
To evaluate the eﬃciency of dynamic optimization problems, various quality
measures have been introduced in the past. Ben-Romdhane et al. [2] and Nguyen
et al. [39] give a convenient survey of quality measures for dynamic optimization
problems. With this regard, Nguyen et al. [39] propose to diﬀerentiate between

Prediction in Nature-Inspired Dynamic Optimization
43
optimality-based measures, which evaluate the ability to track the optimum,
and behavior-based measures taking into account properties like convergence
speed or diversity within the population. In real-world scenarios, the application
context indicates which characteristics are of interest, and hence, which measures
to use. In the following, we present four measures which we also employed for
evaluating our prediction methods in [31–33].
7.1
Best of Generation
Best of generation (BOG) is a known ﬁtness-based performance measure averag-
ing the ﬁtness of the best found solution over a deﬁned number of g generations
and r runs of repeating experiments. It evaluates the algorithm’s behavior over
the whole run. The best possible value of BOG is problem-dependent:
BOG =
1
g · r
g

t=1
r

j=1
BOGtj,
(11)
where BOGtj is the best ﬁtness found during generation t in run j. Low values
are desirable in case of minimization problems.
7.2
Best Error Before Change
Best error before change (BEBC) [49] is a frequently used ﬁtness-based measure
considering the ﬁtness of the best solution found during a change period. It
averages the ﬁtness diﬀerences between the best found solutions fbest(c, ·) and
the optima f ∗(c) over all change periods c:
BEBC = 1
P
P

c=1
|f ∗(c) −fbest(c, ·)|
(12)
In contrast to BOG, BEBC takes into account only the lowest error per change
period. By this means, BEBC ignores ﬁtness peaks during the early generations
of a change period. An optimal algorithm ﬁnds the global optimum for each
change period leading to a BEBC of zero. BEBC has no upper bound for the
worst case.
7.3
Absolute Recovery Rate
The absolute recovery rate (ARR) is a behavior-based measure for the speed an
optimization algorithm starts converging to the global optimum before the next
change happens [38]. It is computed as follows:
ARR = 1
P
P

c=1
g(c)
t=1 |fbest(c, t) −fbest(c, 1)|
g(c)|f ∗(c) −fbest(c, 1)|
(13)

44
A. Meier and O. Kramer
Variable g(c) measures the number of generations during change period c, and
P is the overall number of change periods. Variable f ∗(c) signiﬁes the global
optimum ﬁtness for change period c, while fbest(c, t) represents the best ﬁtness
the algorithm has found in generation t of change period c. In [31], we proposed
to replace the signed diﬀerences by unsigned ones in ARR to compensate for
negative ﬁtness function values. The best value achievable for ARR is one, and
the worst is zero.
7.4
Relative Convergence Speed
In [31], we introduced relative convergence speed (RCS) since in dynamic opti-
mization it is not only important to quickly leave poor solutions, measured by
ARR, but also to ﬁnd the global optimum with as few generations as possible.
RCS measures how fast the ES approaches the global optimum relatively to the
other algorithms included in the comparison:
RCS = 1
P
P

c=1
g(c)
t=1 t · |fbest(c, t) −f ∗(c)|
g(c)
t=1 t · |fworst(c) −f ∗(c)|
(14)
The semantic of the symbols is the same as deﬁned for ARR. The worst ﬁtness
value any algorithm has achieved during change period c is denoted by fworst(c).
RCS ranges from zero as best to one as worst value.
8
Predicting Optima for Evolution Strategies
In this section, we show how ES can be equipped with prediction methods for
dynamic optimization problems. This approach falls into the category of pre-
diction as immigrant (Sect. 4). Algorithm 3 shows pseudocode for a prediction-
based ES. In each generation, the objective function is checked for changes, e.g.,
by re-evaluating a set of solutions on the objective function. The best solution
found at the change is saved in an archive O and is the basis of the training set
to train the prediction model. Here and in the following paragraphs, we consider
minimization problems.
Algorithm 3 (μ+λ)-ES with prediction
1: P ←initialize population()
# μ random solution candidates
2: O ←[ ]
# found optima
3: c ←1
# change period counter
4: for generations do
5:
if change detected() then
6:
c ←c + 1
7:
O.append(best(P))
# store best solution
8:
ˆoc ←train and predict(O)
# predict optimum
9:
P ←adapt population(P, ˆoc)
10:
P’ ←create λ oﬀspring individuals(P)
# recombination&mutation
11:
P ←select best μ individuals(P, P’)

Prediction in Nature-Inspired Dynamic Optimization
45
Before a prediction is done, the prediction model is trained in order to adapt
the model parameters to the updated training set. Often it is suﬃcient to retrain
the model with a subset of recently found solutions because the last found solu-
tions often have more inﬂuence on the optimum movement than the ﬁrst ones.
For the sake of performance, sometimes it is reasonable not to retrain the model
after each ﬁtness function change.
Based on the prediction ˆoc, the population is adapted. For example, solutions
obtained by adding small noise to the predicted optimum may be integrated
into the current population, or the whole population is relocated around the
prediction. Then, as in the ES for static optimization, oﬀspring individuals are
produced, and the best ones are selected for the next generation.
Table 1 [31] shows an exemplary result of an ES with a recurrent network as
prediction model (rnnES). When a change is detected, the population is enhanced
by immigrants that are located near the prediction. This ES variant is compared
to an ES without prediction (dynES), i.e., the immigrants are located randomly.
The benchmark sets are a dynamic Sphere function which is moved linearly
in all dimensions and MPB with random movement of ten peaks. The ﬁtness
function changes every 20 generations. The resulting BOG values show that
prediction supports the optimization process when the optimum follows a pre-
dictable pattern, while—as expected—prediction seems to be useless in case of
random movement.
Table 1. Comparison of ES variants
Dimensionality Sphere
MPB
dynES
rnnES
dynES
rnnES
2
0.21
0.09
−143.51 −123.12
5
3.12
2.04
−107.39 −102.31
10
15.16
10.73
−56.05
−56.45
20
61.97
44.52
−51.87
−52.12
50
384.65
270.22
−58.34
−58.55
100
1642.40 1186.55
−63.06
−63.33
9
Predicting Optima for Particle Swarm Optimization
In PSO, particles can also be integrated into the swarm like in ES [32]; see
Sect. 8. Algorithm 4 shows the pseudocode of a PSO with dynamic prediction
mechanisms. After a change is detected, the predicted optimum is used as par-
ticle in the swarm and replaces the particle with the worst ﬁtness. It is treated
like every other particle and will hence also participate to the concept of best
particles’ and swarms’ history.

46
A. Meier and O. Kramer
Algorithm 4 PSO with prediction
1: S ←initialize swarm()
# random position&velocity
2: O ←[ ]
# found optima
3: c ←1
# change period counter
4: for iterations do
5:
if change detected() then
6:
c ←c + 1
7:
O.append(xs)
# store best solution
8:
ˆoc ←train and predict(O)
# predict optimum
9:
S ←adapt swarm(S,ˆo)
10:
update xp, xs
# re-compute xp for each particle
11:
S ←move particles(S)
# following Eqs. (1), (2)
12:
update xp, xs
# re-compute xp for each particle
Table 2. Comparison of PSO variants
Dimensionality dynPSO
pred2p pred3
2
6.0e−2 9.6e−1 5.0e−1
5
3.1e+0 8.0e+0 3.1e+0
10
2.2e+1
3.1e+1 1.5e+1
20
1.6e+2
1.4e+2 7.7e+1
50
3.5e+3
2.7e+3 1.7e+3
100
7.0e+4
6.4e+4 4.0e+4
Besides the integration of predicted solutions into the swarm, another possi-
bility is to add a third term to the PSO update equations, which belongs to the
category of prediction for operators; see Sect. 4. The velocity update function (1)
is extended as follows:
vt = ωvt−1 + θ1r1(xp −xt−1) + θ2r2(xs −xt−1) + θ3r3(ˆo −xt−1)
(15)
Here, the predicted optimum ˆo ∈Rd of the current change period is an additional
attractor. The inﬂuence of ˆo −xt−1 is controlled by parameter θ3, while r3 is a
vector of random values.
Table 2 shows BOG results for experiments where the Sphere function is
moved linearly in all dimensions [32]. For higher dimensions, the ordinary
dynamic PSO with partial random restart of the swarm (dynPSO) is outper-
formed by both prediction-based variants. PSO with prediction as third attractor
(pred3) is even superior to PSO where the prediction serves as particle (pred2p).
10
Uncertainty Estimation
Integrating prediction into an optimization algorithm might hamper the opti-
mization process in case the predicted optimum diﬀers much from the true one.
If many individuals are re-initialized around a falsely predicted optimum or are

Prediction in Nature-Inspired Dynamic Optimization
47
attracted toward a false direction, the search is intensiﬁed in a region that does
not contain the true optimum. In this case, the optimization algorithms will need
more iterations to recover and ﬁnd the true region where the optimum lies. The
question comes up on how to decrease the inﬂuence of bad predictions. Some
prediction methods, e.g., Kalman ﬁlter [45] and artiﬁcial neural networks [12],
return additional information about how trustful their predictions are. This mea-
sure is called predictive uncertainty.
In the following, we describe how an uncertainty estimation could be inte-
grated into an ES. This approach belongs to two categories presented in Sect. 4,
i.e., prediction as immigrant and prediction for operators. Rossi et al. [45] and
Meier and Kramer [33] employ uncertainty information during population re-
initialization; see Line 9 in Algorithm 3. Their approaches are based on spreading
populations wider within the dimensions of the solution space for high predictive
uncertainties to support exploration in these directions. Figure 3 visualizes dif-
ferent re-initialization strategies in a two-dimensional solution space. The names’
ﬁrst letter denotes whether a prediction is done (p) or not (n); whereas, the other
letters indicate a random strategy (RND) or a strategy based on predictive uncer-
tainty (UNC).
Fig. 3. Re-initialization strategies nRND, pRND and pUNC (from left to right). The cross
marks the predicted optimum; whereas, the points visualize the re-initialized individ-
uals
With random re-initialization (nRND) [53], the new individuals xc in change
period c are sampled uniformly within the bounds xl and xu of the solution
space (xl < xu) if no prediction model is applied; see Fig. 3, left:
xc ∼U (xl, xu)
(16)
Here, no uncertainty information is provided, so the individuals are spread with
uniform density over the whole solution space.
Re-initialization strategy pRND introduced in [33] uses the predicted opti-
mum ˆoc as center for normally distributed random values; see Fig. 3, middle:
xc ∼z · N (ˆoc, I)
(17)

48
A. Meier and O. Kramer
Factor z is employed to scale the normal distribution; I is the identity. In contrast
to nRND, strategy pRND does not place individuals in probably non-promising
regions that are far from the predicted optimum.
As extension of pRND, re-initialization strategy pUNC [33] uses a multivariate
standard deviation taking into account the predictive uncertainty ˆuc with regard
to each dimension. This intensiﬁes the search in directions with more uncertain
predictions as follows:
xc ∼N

ˆoc, z ·
	
ˆuc

(18)
Fig. 4. Comparison of ES with random re-initialization (pRND) and ES with
uncertainty-aware re-initialization (pUNC) on DSB with Sphere function for d = 10
changing every 50 generations
Experiments have shown that predictive uncertainty for re-initialization
supports ﬁnding solutions with a better ﬁtness in the beginning of a change
period [33]. Figure 4 compares the ﬁtness development of an ES with pRND to
an ES using pUNC. Both ES variants employ a temporal convolutional network
(TCN) [1] as prediction model, which yields uncertainty information using a
dropout technique. Benchmark problem is DSB with Sphere function for d = 10
changing every 50 generations. The ﬁtness values are averaged over 20 runs.
The ﬁtness peaks of pUNC are often lower than the ones of pRND after a ﬁtness
function change. Also, the ﬁnal ﬁtness level is better.

Prediction in Nature-Inspired Dynamic Optimization
49
11
Conclusions
Dynamic optimization is an important ﬁeld as classical methods and standard
evolutionary methods may fail without proper modiﬁcations. An appealing and
increasingly important approach is the employment of prediction methods in
nature-inspired dynamic optimization. If the change of the objective function
follows a learnable pattern, prediction methods can improve evolutionary search.
We gave an overview of approaches and showed in more detail how to integrate
information about predicted optima in ES and PSO, e.g., by putting predic-
tions as candidate solutions into the population or by using predicted optima as
attractors in operators’ equations.
With the advent of new prediction methods, e.g., in the ﬁeld of deep learn-
ing, and the introduction of novel nature-inspired meta-heuristics, we will see
many new and fruitful algorithmic hybridizations in the future. For example,
latest work on bio-inspired meta-heuristics like Mendelian evolution on multi-
species as inspired from plants biology incorporating the use of double-strand
DNA [14] might adopt the principles of prediction-based dynamic optimization.
Also, enhanced selection techniques like proposed in [15] might proﬁt from the
proposed extensions. Interesting variants will further have to be developed for
dynamic constrained optimization and also multi-objective variants.
References
1. Bai S, Kolter JZ, Koltun V (2018) An empirical evaluation of generic convolutional
and recurrent networks for sequence modeling. CoRR abs/1803.01271
2. Ben-Romdhane H, Alba E, Krichen S (2013) Best practices in measuring algorithm
performance for dynamic optimization problems. Soft Comput 17(6):1005–1017
3. Beyer H-G, Schwefel H-P (2002) Evolution strategies—a comprehensive introduc-
tion. Nat Comput 1(1):3–52
4. Bishop CM (2007) Pattern recognition and machine learning. Information science
and statistics. Springer, Berlin
5. Bosman PAN (2005). Learning, anticipation and time-deception in evolution-
ary online dynamic optimization. In: Genetic and Evolutionary Computation
(GECCO) Workshop Proceedings, pp 39–47
6. Bosman PAN, La Poutr´e H (2007) Learning and anticipation in online dynamic
optimization with evolutionary algorithms: the stochastic case. In: Genetic and
evolutionary computation (GECCO), pp 1165–1172
7. Branke J (1999) Memory enhanced evolutionary algorithms for changing optimiza-
tion problems. In: Congress on evolutionary computation (CEC), pp 1875–1882
8. Bu C, Luo W, Zhu T, Yue L (2017) Solving online dynamic time-linkage problems
under unreliable prediction. Appl Soft Comput 56:702–716
9. Cheng H, Yang S (2013) Genetic algorithms for dynamic routing problems in
mobile ad hoc networks. Springer, Berlin, pp 343–375
10. Cruz C, Gonz´alez JR, Pelta DA (2011) Optimization in dynamic environments: a
survey on problems, methods and measures. Soft Comput 15(7):1427–1448
11. Fu X, Sun J (2017) A new learning based dynamic multi-objective optimisation
evolutionary algorithm. In: Congress on evolutionary computation (CEC), pp 341–
348

50
A. Meier and O. Kramer
12. Gal Y (2016) Uncertainty in Deep Learning. PhD thesis, University of Cambridge
13. Grefenstette JJ (1992) Genetic algorithms for changing environments. In: Parallel
problem solving from nature (PPSN), pp 139–146
14. Gupta N, Khosravy M, Patel N, Sethi IK (2018) Evolutionary optimization based
on biological evolution in plants. Proc Comput Sci 126:146–155
15. Gupta N, Patel N, Tiwari B, Khosravy M (2018) Genetic algorithm based on
enhanced selection and log-scaled mutation technique. In: Proceedings of the future
technologies conference. Springer, Berlin, pp 1942–1948
16. Hastie T, Tibshirani R, Friedman JH (2009) The elements of statistical learning:
data mining, inference, and prediction. Springer, Berlin
17. Hatzakis I, Wallace D (2006) Dynamic multi-objective optimization with evolution-
ary algorithms: a forward-looking approach. In: Genetic and evolutionary compu-
tation conference (GECCO), pp 1201–1208
18. Hochreiter S, Schmidhuber J (1997) Long short-term memory. Neural Comput
9(8):1735–1780
19. Hu X, Eberhart RC (2002) Adaptive particle swarm optimization: detection and
response to dynamic systems. In: Congress on evolutionary computation (CEC),
pp 1666–1670
20. Hyndman RJ, Athanasopoulos G (2013) Forecasting: principles and practice.
OTexts: Melbourne, Australia, 2013. Accessed on 03 June 2019
21. James G, Witten D, Hastie T, Tibshirani R (2013) An introduction to statistical
learning with applications in R. Springer, Berlin
22. Jin Y, Yang C, Ding J, Chai T (2016) Reference point based prediction for evolu-
tionary dynamic multiobjective optimization. In: Congress on evolutionary com-
putation (CEC), pp 3769–3776
23. Kalman RE (1960) A new approach to linear ﬁltering and prediction problems. J
Basic Eng 82(1):35–45
24. Kennedy J, Eberhart R (1995) Particle swarm optimization. In: International con-
ference on neural networks (ICNN), pp 1942–1948
25. Kramer O (2016) Machine learning for evolution strategies. Springer, Berlin
26. Krizhevsky A, Sutskever I, Hinton GE (2012) Imagenet classiﬁcation with deep
convolutional neural networks. In: Advances in neural information processing sys-
tems (NeurIPS), pp 1106–1114
27. Li C, Mavrovouniotis M, Yang S, Yao X (2013) Benchmark generator for the IEEE
WCCI-2014 competition on evolutionary computation for dynamic optimization
problems: dynamic rotation peak benchmark generator (DRPBG) and dynamic
composition benchmark generator (DCBG). Technical report, De Montfort Uni-
versity
28. Li C, Nguyen TT, Zeng S, Yang M, Wu M (2018) An open framework for con-
structing continuous optimization problems. IEEE Trans Cybern pp 1–15
29. Li C, Yang S, Nguyen TT, Yu E, Yao X, Jin Y, Beyer H-G, Suganthan PN (2008)
Benchmark generator for CEC 2009 competition on dynamic optimization. Tech-
nical report, University of Leicester
30. Li C, Yang S, Pelta DA (2011) Benchmark generator for the IEEE WCCI-2012 com-
petition on evolutionary computation for dynamic optimization problems. Techni-
cal report, Brunel University
31. Meier A, Kramer O (2018) Prediction with recurrent neural networks in evo-
lutionary dynamic optimization. In: Applications of evolutionary computation
(EvoAPPS), pp 848–863

Prediction in Nature-Inspired Dynamic Optimization
51
32. Meier A, Kramer O (2018) Recurrent neural network-predictions for PSO in
dynamic optimization. In: Genetic and evolutionary computation conference
(GECCO), pp 29–36
33. Meier A, Kramer O (2019) Predictive uncertainty estimation with temporal con-
volutional networks for dynamic evolutionary optimization. In: International con-
ference on neural networks (ICANN). Springer, pp 409–421
34. Morrison RW, De Jong KA (1999) A test problem generator for non-stationary
environments. In: Congress on evolutionary computation (CEC), pp 2047–2053
35. Moser I, Chiong R (2013) Dynamic function optimization: the moving peaks bench-
mark. In: Metaheuristics for dynamic optimization. Springer, Berlin, pp 35–59
36. Muruganantham A, Tan KC, Vadakkepat P (2016) Evolutionary dynamic multiob-
jective optimization via Kalman ﬁlter prediction. Trans Cybern 46(12):2862–2873
37. Neumaier A, Schneider T (2001) Estimation of parameters and eigenmodes of
multivariate autoregressive models. Trans Math Software (TOMS) 27(1):27–57
38. Nguyen TT (2011) Continuous dynamic optimization using evolutionary algo-
rithms. PhD thesis, University of Birmingham
39. Nguyen TT, Yang S, Branke J (2012) Evolutionary dynamic optimization: a survey
of the state of the art. Swarm Evol Comput 6:1–24
40. Nguyen TT, Yao X (2009) Benchmarking and solving dynamic constrained prob-
lems. In: Congress on evolutionary computation (CEC), pp 690–697
41. Nguyen TT, Yao X (2009) Dynamic time-linkage problems revisited. In: Applica-
tions of evolutionary computing. Springer, Berlin, pp 735–744
42. Rechenberg I (1973) Evolutionsstrategie: Optimierung technischer Systeme nach
Prinzipien der biologischen Evolution. Frommann-Holzbog, Stuttgart
43. Rojas R (1996) Neural networks: a systematic introduction. Springer, Berlin
44. Rong M, Gong D, Zhang Y, Jin Y, Pedrycz W (2018) Multidirectional prediction
approach for dynamic multiobjective optimization problems. IEEE Trans Cybern
pp 1–13
45. Rossi C, Abderrahim M, D´ıaz JC (2008) Tracking moving optima using Kalman-
based predictions. Evol Comput 16(1):1–30
46. Sim˜oes A, Costa E (2008) Evolutionary algorithms for dynamic environments:
prediction using linear regression and Markov chains. In: Parallel problem solving
from nature (PPSN), pp 306–315
47. Sim˜oes A, Costa E (2009) Improving prediction in evolutionary algorithms for
dynamic environments. In: Genetic and evolutionary computation conference
(GECCO), pp 875–882
48. Sim˜oes A, Costa E (2014) Prediction in evolutionary algorithms for dynamic envi-
ronments. Soft Comput 18(8):1471–1497
49. Trojanowski K, Michalewicz Z (1999) Searching for optima in non-stationary envi-
ronments. In: Congress on evolutionary computation (CEC), pp 1843–1850
50. Wu Y, Jin Y, Liu X (2015) A directed search strategy for evolutionary dynamic
multiobjective optimization. Soft Comput 19(11):3221–3235
51. Yang S, Yao X (2003) Dual population-based incremental learning for problem
optimization in dynamic environments. In: Asia paciﬁc symposium on intelligent
and evolutionary systems (IES), pp 49–56
52. Yazdani D, Omidvar MN, Branke J, Nguyen TT, Yao X (2019) Scaling up dynamic
optimization problems: a divide-and-conquer approach. Trans Evol Comput

52
A. Meier and O. Kramer
53. Zhou A, Jin Y, Zhang Q, SendhoﬀB, Tsang E (2007) Prediction-based popu-
lation re-initialization for evolutionary dynamic multi-objective optimization. In:
Evolutionary multi-criterion optimization (EMO), pp 832–846
54. Zhou J, Zou J, Yang S, Ruan G, Ou J, Zheng J (2018) An evolutionary dynamic
multi-objective optimization algorithm based on center-point prediction and sub-
population autonomous guidance. In: Symposium series on computational intelli-
gence (SSCI), pp 2148–2154

Chapter 3
Plant Genetics-Inspired Evolutionary
Optimization: A Descriptive Tutorial
Neeraj Gupta1, Mahdi Khosravy2,3(&), Nilesh Patel1,
Om Prakash Mahela4, and Gazal Varshney5
1 Department of Computer Science and Engineering, Oakland University,
Rochester, MI, USA
2 Media Integrated Communication Lab, Graduate School of Engineering, Osaka
University, Suita, Japan
mahdi.khosravy@ufjf.edu.br
3 Electrical Engineering Department, Federal University of Juiz de Fora, Juiz de
Fora, Brazil
4 Power System Planning Division, Rajasthan Rajya Vidyut Prasaran Nigam
Ltd., Jaipur, Rajasthan, India
5 University of Information Science and Technology, Ohrid, North Macedonia
1
Introduction
Optimization plays an essential role in achieving accuracy and increasing efﬁciency in
a variety of problems. Under the classes of real and binary-coded schemes, the liter-
ature proposes a variety of meta-heuristic population-based evolutionary algorithms
(EAs) [1, 2], i.e., genetic algorithm (GA) [3–5], PSO [6–10], bat algorithm [11–14],
ﬁreﬂy [15], plant genetics-inspired algorithm known as Mendelian evolutionary theory
optimization (METO) [16, 17], etc. [18–22].
Although the population-based EAs have been widely accepted by the researchers
and industries from different ﬁelds, it has been reported [18–23] that not all meta-
heuristics optimizers work well for training ANN as there are limitations [24] on some
of them, e.g., multi-modularity of the objective function of ANV. These limitations
invoke the researcher to ﬁnd a better meta-heuristic training technique, which should be
able to offer better results [25]. In this regard, this chapter tries to present a better ANN
training technique to handle multi-modularity of the associated objective function.
The literature shows tremendous effort from the 90s where we can observe many
innovations in EAs and swarm optimization techniques as training algorithms with
their variants. After observing the computational power of population-based opti-
mization algorithms in the last two decades, variants of swarm optimization [26],
shufﬂed frog leaping algorithm (SFLA) [27], biogeography-based optimization
(BBO) [28], cuckoo search (CS) [29], Bat algorithm (BA) [30], teaching–learning-
based optimization (TLBO) [31], etc., have been proposed, as in survey papers and
recent books [32, 33].
© Springer Nature Singapore Pte Ltd. 2020
M. Khosravy et al. (eds.), Frontier Applications of Nature Inspired Computation,
Springer Tracts in Nature-Inspired Computing,
https://doi.org/10.1007/978-981-15-2133-1_3

Nowadays, optimization and thereof the accuracy of the algorithms is the main
focus of the researchers. As the computational speed of the computers increases, there
are variety of theoretical and application ﬁelds that the online and ofﬂine optimization
can be applied like acoustic OFDM [34], blind component processing [35], blind
source separation [36–40], data mining [41], information hiding [42], ECG processing
[43–46], noise cancelation [47], imaging systems [48], image enhancement [49, 50],
image adaptation [51], morphological ﬁltering [52, 53], power line communications
[54], fault detection [55], quality assessment [56], text feature detection [57],
telecommunications [58–61], etc.
To add the state of the art, we inspired from the evolution theory of plant genetics
based on Mendel’s inheritance law to propose a genetically evolved optimization
algorithm. In this algorithm, the evolution process takes place by interbreeding the
plants of different species [62].
To design a novel evolutionary algorithm (EA), we redeﬁne the biologically
inspired metaphors in the binary domain to implement as a computer program. Due to
its binary structure, the proposed ﬁve operations: ﬂipping, pollination, breeding, dis-
criminating, and epimutation [63] have encoding and decoding techniques like the
genetic algorithm (GA) but in a different working structure the ancestors’ memory is
transferred in two consecutive generations, F1 and F2 offspring, as METO produces
two-generation offspring in the sequence. This makes the METO belongs to a different
class from the GA. METO is a gradient-free method that does not require the function
differential, thus best suited for the discontinuous and multimodal problems as well.
Table 1. Meta-heuristic algorithms and the corresponding characteristics and variables
Biography-Based Optimization
(BBO) [25]
Year: 2008
Type: EA
Single population
Inspiration: biogeography; the study of the distribution of
biological species through time and space
Parameter values: Keep rate = 0.2; emigration rates = linspace
(1,0,populationSize); immigration rates = 1 −Emigration
Rates; alpha = 0.9; mutation probability = 0.1; sigma = 0.02*
(xU −xL)
Binary Parallel Population
Hybrid GA (BBHGA) [5]
Year: 2018
Type: EA
Multiple population
Inspiration: Extension of GA—in each evolution epoch,
sampling of one crossover and selection strategy is carried out
from three different methods
Parameter values: Rx = randomly chosen from 1, 2, and 3 in
each iteration epoch. If Rx = 1, then single-point crossover,
elseif Rx = 2, then two-points cross over, else for Rx = 3, then
uniform crossover. Rx = randomly chosen from 1, 2, and 3 in
each iteration epoch. If Rx = 1, then Roulette Wheel selection,
elseif Rx = 2, then Tournament selection, elseif Rx = 3, then
random selection. Mutation probability = 0.2, b = 20;
crossover percentage = 0.8; mutation percentage = 0.9;
mutation rate = 0.02; Tournament size = 3
(continued)
54
N. Gupta et al.

Table 1. (continued)
Invasive Weed colonization (IWO) [39]
Year: 2006
Type: EA
Single population
Inspiration: Inspired by dynamic growth of weeds
Parameter values: Maximum population
size = (1 + 0.2)  population size; minimum number of
seeds = 0; maximum number of seeds = 5; variance reduction
exponent = 2; initial value of standard deviation = 0.5; ﬁnal
value of standard deviation = 0.001
Shufﬂed Frog Leap Algorithm
(SFLA) [23]
Year: 2006
Type: MA
Multiple population
Inspiration: frog foraging behavior with mimetic algorithm
concept
Parameters: memeplex size, parents number, offspring number,
step size, iteration number
Teaching–Learning-Based Optimization
(TLBO) [28]
Year: 2011
Type: SIA
Single population
Inspiration: simulates the teaching–learning process of the class
room
Parameters: parameters free algorithm
Cuckoo Search (CS) [4, 26]
Year: 2009
Type: SIA
Single population
Inspiration: obligate brood parasitism of some cuckoo species
by laying their eggs in the nests of other host birds [2]
Parameter values: Discovery rate of alien
eggs/solutions = 0.25; number of nests = Population size;
Levy exponent and coefﬁcient b ¼ 3=2;
r ¼ ðcð1 þ bÞ  sinðp  b=2ÞÞ=ðcðð1 þ bÞ=2Þ  b
 2ððb  1Þ=2ÞÞÞð1=bÞ;
Novel Bat Algorithm (NBA) [3, 6, 27]
Year 2015
Type: SIA
Single population
Inspiration: Echolocation behavior of simulated microbats,
where automatic balance in exploration and exploitation of
search space is by varying loudness and pulse emission rates
Parameter values: Maximal and minimal pulse rates = 1, 0;
maximal and minimal frequencies = 1.5, 0; maximal and
minimal loudnesses = 2, 1;
gamma = 0.2 + (0.9 −0.2)  rand;
alpha = 0.2 + (0.9 −0.2)  rand; frequency of updating the
loudness and pulse emission rate = 10; maximal and minimal
probability of habitat selection = 0.9, 0.6; maximal and
minimal compensation rate for Doppler effect in echoes = 0.9,
0.1; maximal and minimal contraction expansion
coefﬁcient = 0.9, 0.1; maximal and minimal inertia
weight = 0.9, 0.5
Gravitational Search Algorithm (GSA) [41] Year 2009
Type: Meta-
heuristic
Single population
Inspiration: Based on the law of gravity and the motion of
mass, interactions and information exchange by gravitational
force
Parameter values: Elitist check rate = 1; R power = 1 (R power
in Eq. (7) in Ref. [64]); R norm = 2 (R norm in Eq. (8) of Ref.
[64])
Social Learning PSO (SLPSO) [42]
Year 2015
Type: SIA
Single population
Inspiration: social learning of particle swarms
Parameters Values: c3 = nVar/PopulationSize  0.01
(continued)
Plant Genetics-Inspired Evolutionary Optimization
55

The evaluative study of METO performs an analytical comparison with twelve
optimizers, including the state-of-the-art techniques as described shortly in Table 1.
2
Features of METO
The following distinctive features describe the METO algorithm:
1. It is a binary-coded optimizer and explores the transformed genome search space
instead of real.
2. Mendel deduced his theory by the experimentation on the pea plants wherein
genetic information exchange took place by breeding the plants of different species.
Based on his experiments, METO employs multiple populations corresponding to
the species. This is the base of METO.
Table 1. (continued)
Fireﬂy Algorithm (FA) [43]
Year: 2009
Type: SIA
Single population
Inspiration: ﬂashing behavior of ﬁreﬂies
Parameter values: Light absorption coefﬁcient = 1; attraction
coefﬁcient base value = 0.2; mutation coefﬁcient = 0.2;
mutation coefﬁcient damping ratio = 0.98; uniform mutation
range = 0.05  (VarMax −VarMin); m = 2
Covariance Matrix Adaptation
Evolutionary Strategy (CMAES) [7, 8]
Year: 2003
Type: EA
Single population
Inspiration: Covariance matrix (CM) is used to deﬁne the
pairwise dependencies between the variables. Here, adaption of
this matrix belongs to CMA
Parameter values: Number of parents (k) = PopulationSize/2;
Parent Weights (w) = (log(k + 0.5) −log(1:k))/sum(log
(k + 0.5) −log(1:k)); number of Effective Solutions
(eff) = 1/sum(w2); step size control parameters (c_sigma and
d_sigma): sigmaðÞ ¼ 0:3  ðxU  xLÞ;
cs ¼ ðeff þ 2Þ=ðnVar þ eff þ 5Þ;
ds ¼ 1 þ cs þ 2  maxðsqrtððeff  1Þ=ðnVar þ 1ÞÞ  1:0Þ;
ENN ¼ sqrtðnVarÞ  ð1  1=ð4  nVarÞ þ 1=ð21  nVar2ÞÞ;
Here, nVar stands for number of variables covariance update
parameters: cc ¼ ð4 þ nP:eff=nVar)/(4 + nVar þ 2  eff=nVarÞ;
c1 ¼ 2=ððnVar þ 1:3Þ2 þ effÞ; alpha:nP ¼ 2;
cmu ¼ minð1  c1; ak  ðeff  2 þ 1=effÞ=ððnVar þ 2Þ2 þ ak  eff=2ÞÞ;
threshold for updating covariance matrix =
ð1:4 þ 2=ðnVar þ 1ÞÞ  ENN
DE with Dither technique (DED)
Year 2005
Type: EA
Single population
Variant: DE/rand/1/bin, Parameters: Weighting
factor = interval [0.5, 1.0], crossover constant = 0.9
Parameter values: Lower bound of scaling factor = 0.2; upper
bound of scaling factor = 0.8; crossover probability = 0.2
56
N. Gupta et al.

3. Instead of one crossover/breeding, which is usual in GA, METO deploys sequence
of crossbreeding and self-breeding in an evolution cycle to produce F1 and F2
generation offspring, respectively. The plants in current populations belong to F0
generation.
4. It is a memory-based optimizer where the heredity genes transmitted from ancestors
to descendants as a result of self-breeding in the form of recessive genes.
5. In an evolution cycle, parallel transmission of genes takes place in consecutive two
generations: F0 to F1 and F1 to F2. Dominant genes are transmitting to the next
generation, for example from F0 to F1 and then F1 to F2, where recessive genes
transmit from F0 to F2 generation. Thus, in F2 generation offspring, recessive genes
appear as dominating genes.
6. Because recessive genes are transmitting in alternative generations (F0 to F2,
without appearing in F1), thus subjected to the environmental mutation multiple
times over the life cycle of a plant. But, as a result of the self-organizing behavior of
nature, plant resists inappropriate changes, as the rehabilitation process.
7. An organism in the population is represented by the complementary double strands
artiﬁcial DNA structure, which is completely different from the GA. In GA and its
variants, an organism in a population is represented by a chromosome, where
dipole-GA contains two alleles in a gene.
8. DNA of F1 generation offspring, as a result of crossbreeding, is formed by com-
bining the opposite strands of DNA of two parents. This is a natural process of
breeding two organisms and has been introduced in METO. It is noted that based on
Mendel experiments, breeder parents belong to the two different species. That is
why at least two species are required to see the Mendelian evolution in plants.
3
Biological Inspiration
The presented algorithm is inspired by the biological evolution theory as brieﬂy
described below:
3.1
Evolutionary Theory of Mendel
We deﬁne here the potential laws given by Mendel, which he discovered by the
experimental observation on pea plants. Johann Gregor Mendel (1822–1884), known
as the father of genetics, observed the fundamental laws of inheritance through the
large data collected by the experiments on 10,000 pea plants in eight years (1856–
1863) [61]. He revealed the theory that in offspring inheritance, characteristics are
transferring from parents or the previous generation ancestors. To validate his theory,
he tracked the segregation of the parental genes and found that offspring resemble the
parent’s appearance as dominant or recessive traits. The theory of George Mendel
which he explained about the biological inheritance in 1865 and 1866 is rediscovered
Plant Genetics-Inspired Evolutionary Optimization
57

again in 1900. In the initial phase, this theory was controversial, but with the inte-
gration of Boveri–Sutton chromosome theory of inheritance in 1915, it has proved as
the core of classical population genetics. After that, Ronald Fisher had combined it with
the theory of natural selection based on probability theory and formulated the basis of
population genetics. This phenomenon is later known as modern evolutionary syn-
thesis, which eventually cemented Mendel’s place in the history of biological evolution
phenomenon. Mendel conceived the idea of heredity units/characteristics, which he
named as “factors”; right now, in genetics, known as genes. In an organism, each
physically appeared biological trait is represented by allele value in the genes of its
chromosome, which may be the same as its parents have or may take from ancestors
even after few generations. Mendel’s laws of heredity are deﬁned as follows:
1. The law of segregation: A gene pair represents each inherited trait which deﬁnes the
physical appearance of the parents. When fertilizing the two parents, genes in cells
of them are separated ﬁrst randomly and then participated in forming the offspring
cell unite by transmitting inherit genetic allele from each parent.
2. The law of independent assortment: It states that the inheritance of one trait is not
dependent on the inheritance of another when two or more characteristics are
inherited. This gives equal opportunity to independent factors for occurring during
the production of gamete.
3. The law of dominance: It states that one of the factors for a pair of inherited traits is
subjected to be dominant and the other recessive, unless both factors are recessive.
4. This population genetics and natural selection of the genes from parents are adopted
in our formulation to develop the population-based meta-heuristic algorithm.
Mendel demonstrated the true breeding concept of dominance and recessive traits in
the binary formulation. This is the base, through which a binary-coded algorithm is
possible to discover in this manuscript. This binary formulation gives the advantage
of bypassing the summation, product, and division on real numbers by shifting the
binary bits only for calculating the new solution. He follows the several successive
generations on pea plants of different species and records their variations with some
large samples to validate the results. Finally, he performed “test crosses” to reveal
the presence of recessive traits and their characteristics.
Fig. 1. Mendel’s law of transferring heredity characteristics
58
N. Gupta et al.

After experimenting crossbred of the purebred pea plants of different species, he
revealed that the result is not a blending one in the ﬁrst generation, named as F1
generation. In this generation progenies, a purple color trait in the ﬂowering of pea
plant is a dominating trait, and white color appeared as a recessive trait as hidden
characteristics. He again self-pollinated the F1 generation plants with itself, full of
dominant traits, and obtained few purple-ﬂowered plants and some white-ﬂowered
plants as progeny in subsequent F2 generation. He explained that in this F2 generation,
some recessive traits appear, even which cannot be seen in F1 generation plants.
Mendel gave this phenomenon as “Law of Dominance,” which decides the phenotype
appearance of the plant in F1 generation offspring and named it as “dominant genes,”
where “after few generations” or “next generation,” recessive genes/traits may appear
again with some probability as dominating one. We refer this probability of transferring
recessive genes to F2 generation offspring as Mendelian probability of recessive genes
transfer from the previous generation. This heredity information in the genes is carried
out from generation to generation by “selﬁes microbes,” coined by Dawkins in 1976, to
descendants. We inspired from the theory to model transmission of few selected genes,
based on Mendelian probability, from the ancestors. For the fertilization, two chro-
mosomes are assumed as homozygous, which means genes representing same traits
should be at the same locus to determine the particular phenotype appearance of the
offspring. In this case, an allele can shift and transfer at the same locus during the
transfer of dominant or recessive traits.
In short, in the sense of developing an evolutionary optimization algorithm, the
above described Mendelian phenomenon of dominance and recessive genes transfer in
F1, and F2 generations inspire us to model the breeding operation as it moves the
points in the genotype search space. For producing two-generation offspring in a
sequence, Mendel’s laws of heredity as deﬁned above are deployed. For example, F1
generation offspring follows the law of independent assortment, where each factor/gene
in parents has equal probability to transfer in offspring. Moreover, the selection of
recessive genes follows the law of dominance; however, the act of segregation is the
basis of the proposed evolutionary algorithm. Figure 1 illustrates the Mendel’s law of
transferring heredity.
3.2
The Biological Structure of DNA
Mendel’s theory is deployed on the chromosomes associated with each plant whose
essential unit is the DNA, which contains our unique genetic codes to represent phe-
notype traits in the form of genes. In biology, DNA is a double helix structure of
strands/chromosomes which are running in the opposite direction and appeared like a
twisted ladder and has been ﬁrst discovered by James Watson and Francis Crick in
1953 [65]. Chromosome is the composition of lined-up many DNAs as shown in
Fig. 2. Start and end points of each strand in a DNA are denoted by either 5 (ﬁve
prime) or 3 (three prime). If one strand of DNA starts from 3 and ends at 5, named as
“sense strand,” then the associated opposite strand named as “antisense strand” starts
with 3 and ends to 5. For the formation of DNA of produced offspring from two
Plant Genetics-Inspired Evolutionary Optimization
59

parents, one sense strand of one parent and one antisense strand of the other parent
combines, vice versa for other offspring as shown in Fig. 3.
In the context of METO, the length of chromosome strand depends on the number
of lined-up DNAs, which are equal to the number of weights and transfer functions in
the problem space.
3.3
Epimutation and Rehabilitation as Self-organizing Behavior
The third phenomenon is epimutation in biology which guides the evolution in the
organism to follow by cycles of nature self-organizing behavior of sequential mutation
and rehabilitation. Process in the universe is self-organizing, where at each instance,
nature tries to optimize the things as rehabilitation process after out-worst of a disaster.
This evolution is through a mutation in the organism followed by cycles of rehabili-
tation as called “epimutation” in biology. Due to this phenomenon, genes are being
subjected to the multiple time changes over a life cycle in the result of environmental
factors, i.e., UV light, fertilizers, chemicals, X-rays, ﬂood, etc. Microbes, which are
trillions in individual/organism, are responsible for these changes. They change
chromosomes subject to the food, touch, use of antibiotic, sanitizers, and above
described factors. Additionally, DNA synthesis under evolution process is another
factor of change in genes. If the above changes or mutations result in an inappropriate
state of the organism, then it tries to self-recover. This process is called temporary
mutation otherwise permanent if failed to recover as depicted in Fig. 4. Organism
resists itself to adapt sudden environmental changes by the epimutation mechanism.
According to Joseph Heitman, “epimutation is reversible and gives the organism more
ﬂexibility.” It means that it is easier to change the condition by reverting to the previous
state the way things were.
Fig. 2. Formation of double-strand chromosome by lined-up DNAs
60
N. Gupta et al.

Epimutation is employed in a variety of unfavorable environment situations to
enable an organism to adapt it again and again for improving conditions. This concept
leads to the rehabilitation, where an organism self-improves, maintains, restores
physical strength, cognition, and mobility. Figure 4 shows the epimutation process of
an organism where the ﬁve states of an organism are shown as p1, p2, p3, p4, and p5.
Here, p1 is the current state of the organism, and the others are the results of epimu-
tation. p2, p3, and p4 states are not better than the current state, and thus, the organism
returns to its original state p1 by a rehabilitation process. But, mutated state p5 is better
than the current state, and thus, in this case, organism accepts it as evolution perma-
nently. This mechanism is introduced to ﬁnd the better neighbor of the pseudo-best
solution (PBS), and we call it “ﬁne tuning” of the global best point by iterative
mutations followed by rehabilitation as called epimutation. Several attempts of this
mechanism over the life cycle of an organism give chromosome of better recessive
genes before going into the next evolution process.
Fig. 3. Generation of offspring DNAs through two opposite strands of two parents DNAs from
different species
Fig. 4. Epimutation process
Plant Genetics-Inspired Evolutionary Optimization
61

4
Implementation
The proposed optimizer implementation is inspired by the binary-coded GA but is
different in the structure. This algorithm works on the information exchange between
chromosomes, unlike GA. The sequential process of the above biologically inspired
phenomena provides an intelligent search algorithm as a global optimizer. A brief
description of the implementation of the above described biological procedures for
being used as a computer program to solve the problems is given in the main manu-
script. It deploys ﬁve biologically inspired operators as ﬂipper, pollination, breeding,
discrimination, and epimutation. To complete the structure of double-strand DNA,
ﬂipper operator is essential, where two strands of DNA are two complementary strands.
Before describing the operators, encoding and decoding schemes are presented here
to implement the strands of the chromosome. This is the base of PGEO on which all
operators work.
4.1
Binary Representation of Chromosome Strand
In the genotype, G, representation of the plant, each gene in the particular strand of the
chromosome, considered as lined-up DNAs, corresponds to the visible appearances, for
example, height, type, size, and color of the ﬂower, etc. Change in the gene value
changes the above characteristics and thus results the movement in genome search
space. Implementation of the genotype G representation of both lined-up DNA strands
is a sequence of binary bits g[l] 2 {0, 1z}, Fig. 5, where each bit is entitled for a gene,
and its value for alleles.
Here, l is the bit “locus” equivalent to the position of the corresponding gene g[l] in
the chromosome. The decoded value of G refers to the genetic contribution to the
phenotype, R = f(G). A certain pattern of binary bits g[l] in the chromosome string
encompasses speciﬁc information, and the decoded value of it represents a particular
point in phenotype space. Thus, PEGO requires a coding–decoding system to represent
Fig. 5. Binary to real search space representation of a chromosome strand
62
N. Gupta et al.

a binary-coded string in the corresponding state in real space as shown in Fig. 5. This
ﬁgure illustrates the relations of genotype representation for a point in phenotype space.
In Fig. 5, one strand of chromosome is shown to represent variables, where each
ten bit (genes) codes one variable. This ﬁgure shows the corresponding phenotype
appearance of the genotype representation of two variables w1 and w2. It would be
worth mentioning here that the number of genes representing a variable in the chro-
mosome strand is determined according to the desired solution accuracy. Variables are
bounded by lower and upper limits, represented by subscript L and superscript U,
respectively, for ith weight as (wi
L, wi
U). Between the above speciﬁed limits, all
intermediate chromosomes in G to represent points in H can be produced by changing
one or more respective bits at any locus using the mapping rule:
wi ¼ wL
i þ wU
i  wL
i
2li  1 Wi
0
ð1Þ
where Wi
0
is the decoded value of binary string and is calculated as
Wi
0 X
l1
i¼0
¼ 2ig½i
ð2Þ
For the l number of bits to represent a variable in the chromosome, there are 2l
possible distinct substrings.
4.2
Population Structure
Mendelian theory of evolution is based on the breeding of two species parents. Thus,
the proposed algorithm is multi-population optimizer, where each ith population is fi
as shown in Fig. 6. Here, two species populations are fj and fk. Both populations
contain two-strand DNAs corresponding to each parent. The initial population is called
F0 population, from which two parent DNAs are selected for the breeding process. The
ﬁrst DNAs are denatured in sense strand (SS) and antisense strand (AS). This can be
seen in Fig. 6 as fSS
j
and fAS
j
for jth species and fSS
k and fSS
k for kth species. The next
is population is the population of F1 generation offspring, which is represented by fF1
j
and fF1
k , respectively, for jth and kth species. Offspring of fF1
j
are formed by breeding
the SS and AS of different species. The third consecutive population is the population
of F2 generation offspring, fF2
j
and fF2
k , respectively, for jth and kth species, which is
the result of self-breeding of F1 generation offspring, fF1
j
and fF1
k , respectively.
Production of the F1 and F2 generation population from F0 completes an evolution
cycle, where new population fnew
j
and fnew
k
, respectively, for jth and kth species are
constructed by elite individuals from all three populations.
Plant Genetics-Inspired Evolutionary Optimization
63

4.3
Construction of Heredity
According to the Mendelian evolution theory, heredity transmits from one generation
to the next. Thus, construction of heredity is an important part of the algorithm.
According to the Mendelian theory, two types of heredity exist, dominant genes
(DG) and recessive genes (RG). DG appear in the F1 generation offspring where RG
are intended to appear in the F2 generation offspring. Thus, we retain RG as the
heredity H; to be available for F2 generation offspring.
Figure 7 shows the construction of heredity genes H by the ﬁltering process of
genes from one generation to the next.
Fig. 6. Population structure in the proposed ANN training algorithm
Fig. 7. Construction of heredity
64
N. Gupta et al.

After crossbreeding, two breeder parents rj;n and vk;n have their own recessive
heredity information. Since we are developing an evolutionary algorithm, best ﬁtness
genes are always intended to pass to the next generation—implicit elitism property.
This process is a ﬁltering process of heredity and accomplished by three comparators
Cj, Cj;k, and C in Fig. 7.
Cj compares and extracts the best from rj;n; vj;n


based on their ﬁtness. The output
of this ﬁlter is then compared with vk;n using comparator Cj;k, which provides the best
heredity from rj;n; vj;n; vk;n


: The output of this goes to the comparator C to compare
with the reference old heredity Hold
j;n . Then, the ﬁnal ﬁltered heredity Hj;n is available
for the nth F2 generation offspring of jth species. Similarly, Hk;n is produced for the nth
F2 generation offspring of k species.
4.4
Implementation of Basic Operators
The proposed algorithm deploys the formation of multiple species by deploying the
operations: ﬂipping, pollination, breeding, and epimutation.
The Flipper Operator
Each individual in ith species possess a DNA which is a double-strand structure
composed of the sense chromosome ri;n and the antisense chromosome vi;n which are
deﬁned as:
ri;n ¼ gi;n
* gi;n lstart
½
 is 5
0
and gi;n lend
½
 is 3
0
vi;n ¼ gi;n
* gi;n lstart
½
 is 3
0 and gi;n lend
½
 is 5
0
:
ð3Þ
It is a representation of two strands of DNA of plant, where 3 and ends at 5
chromosome is antisense strand and 5 to 3 chromosome is sense strand. lstart and lend
are, respectively, the ﬁrst and last bit of the chromosome.
Consequently, fi;j is the artiﬁcial DNA of nth individual plant of ith species which
is represented as a double row binary matrix.
fi;n ¼
ri;n
vi;n


ð4Þ
ri;n is the output of the fertilization process as it is generated randomly from a uniform
distribution at the ﬁrst evolution of the proposed algorithm. vi;n is obtained by reversing
the order of ri;n bits by a ﬂipper operator F as vi;n ¼ F ri;n


: Thus, the ﬂipper operator
is deﬁned as follows:
F gi;n


½l ¼ gi;n lend  l þ 1
½

ð5Þ
Plant Genetics-Inspired Evolutionary Optimization
65

Flipper operation reduces the risk to be trapped at premature convergence or local
minima. Algorithm for producing AS using ﬂipper operator is given in Algorithm 1, as
follows:
Algorithm 1. Algorithm for Producing AS from SS
The Pollination Operator
Sexual reproduction in the plant is subjected to the pollination process in which pollen
transfers from male reproductive part to female reproductive part of the plant. This
process is carried out in many ways like through air or movement of the living crea-
tures. Self-pollination is the process in which pollen transferred from another to the
stigma of the same plant ﬂowers, where cross-pollination involves the transfer of pollen
from another of one plant ﬂower to the stigma of a genetically different ﬂower. 80% of
66
N. Gupta et al.

the plant pollination happens through living creature and is called biotic pollination.
Mendel fertilized two breeds of pea plants in the laboratory by biotic pollination, where
he dropped pollen from male reproductive part to the female reproductive part of
different ﬂowers, as cross-pollination, and same ﬂowers, as self-pollination. This
process inspired to model pollination operation, where plants are selected from different
species to fertilize.
In the PGEO algorithm, two pollinations are used in the sequence as named here
random and sequential. First, the random pollination randomly picks two breeder
species from multiple even number of species as fj and fk. Then, each one individual
of the fj is sequentially paired with the individual of fk at the same order. As a result
of the sequential pollination, the individual chromosomes from the selected species are
taken from up to down one by one in a sequence. The pollination operator can be
extended to different pollination schemes such as Roulette Wheel, Tournament, etc.
The Breeding Operators
According to Mendelian theory in two successive generations F1 and F2, offspring are
produced as a result of crossbreeding and self-breeding, respectively.
The Crossbreeding Operator
Algorithm for F1 generation offspring is given in Figs. 5, 6, 7, 8, 9, and 10. For this,
crossbreeding is the breeding of two different species. Let us consider fj and fk as two
different species. To produce offspring DNA associated with F1 generation as evolution
of fj species, sense chromosome rk;n 2 fk;n and antisense chromosome vj;n 2 fj;n are
considered as breeding parental chromosomes.
The breeding produces the offspring sense strands, while the required antisense
strands are obtained by applying ﬂipper operation on them. The operator for cross-
breeding produces two offspring DNAs for jth species as follows:
f1
j;n; f2
j;n


¼ B fj;n; fk;n


f1
j;n ¼
r1
j;n
F r1
j;n


2
4
3
5 ; f2
j;n ¼
r2
j;n
F r2
j;n


2
4
3
5
ð6Þ
The twin offspring sense chromosomes r1
j;n and r2
j;n are composed of dominant genes
either from rj;n or vk;n based on natural selection. In a similar manner, the twin offspring
are produced for fk;n species where sense and antisense parents chromosomes are,
respectively, rk;n and vj;n.
Since k is hidden in producing r2
j;n and r1
j;n offspring in the output of the cross-
breeding equations, vk;n and vj;n are treated as virtual chromosome. However, multiple
offspring SS can be produced as shown in Fig. 9. For generating multiple twin
Plant Genetics-Inspired Evolutionary Optimization
67

offspring, the common genes can be obtained in advance using XNOR logical process,
and for the remaining locus of the genes, the above equation is used. In the case of very
long chromosomes, this can help to improve the time complexity for producing mul-
tiple offspring.
XNOR rj;n; vk;n


¼ rj;n½l ^ vk;n½l _ rj;n½l ^ vk;n½l:
ð7Þ
Transfer of common characteristics has been shown in Figs. 5, 6, 7, 8, 9, 10, and 11
where gray genes show the common ones at third and fourth locus as a result of XNOR
operator, where others are undeﬁned genes and represented by allele value X. The
undeﬁned locus X is ﬁlled by either parent rj;n or vk;n genes randomly using the above
equations based on natural selection as described in the equation below.
r1
j;n½l ¼
rj;n½l
c  0:5
vk;n½l
otherwise,

ð8Þ
Algorithm 2. Algorithm for producing F1 generation offspring
68
N. Gupta et al.

The Self-Breeding Operator
The self-breeding operator breeds the SS strands of offspring generated in F1 gener-
ation with itself to produce the F2 offspring SS. This is the process which makes
dominant the recessive heredity H with some Mendelian probability in the offspring as
shown in Fig. 9. Recessive genes dominate in F2 offspring by replacing the same locus
genes of F1 generation offspring according to the generated random number between
0.1 and 0.99. It can be changed according to the problem. Algorithm for producing F2
generation offspring is given in Algorithm 3.
Fig. 8. Illustration of production of multiple F1 generation offspring
Fig. 9. Illustration of production of F2 generation offspring
Plant Genetics-Inspired Evolutionary Optimization
69

Algorithm 3. Algorithm to produce F2 generation offspring
The Epimutation Operator
Figure 4 shows the epimutation process of an organism where the ﬁve states of
organism are shown as p1 p2, p3, p4, and p5. In this ﬁgure, we can observe that an
organism on p1 state is continually going through mutation process until it ﬁnds the
better state than before. Reverting to the previous state is called rehabilitation process.
At mutated state p5, organism ﬁnds better ﬁtness than the current state and thus accepts
it as evolution permanently. In METO, we use this mechanism to ﬁnd the better
neighbor of the pseudo-global optima (PGO) which is the result of recessive genes and
we call it “ﬁne tuning” of the global best point by iterative mutations followed by
rehabilitation as called epimutation.
Recessive genes self-organize the environmental effects via a rehabilitation oper-
ation where selﬁes microbes preserve the best recessive genes in the chromosome. It
shows that the chromosome realizes multiple mutations over the life span before going
to the next evolution. If chromosome ﬁnds a better mutation, adapts it, otherwise return
to the previous state as a rehabilitation. The associated epimutation probability should
be very low which is very important for “ﬁne tuning” of the pseudo-best solution.
Algorithm for rehabilitation against mutation (epimutation) process is shown in
Algorithm 4 as a function.
70
N. Gupta et al.

5
METO Algorithm
The best solution acquired by each individual is called here as “Individual Pseudo-best
(IP),” and the best of all IPs in a particular species is “Species Pseudo-best (SP).” Each
evolution extracts the best solution from all SPs as is called “Global Pseudo-best (GP).”
The term “pseudo” comes from the fact that the solutions improve their merit in being
closer to the global optimal solution at each evolution. IP solution associated with each
individual is saved as recessive chromosome and is used to produce F2 generation
offspring. Pseudo-code of METO is presented in Algorithm 5, where it deploys the
above described four operations in the sequence. In each evolution, IP solution asso-
ciated with each individual is compared to the outcome of F1 and F2 generations
offspring as well to the outcome of “epimutation” operation. The current IP is replaced
with better chromosome, if exists. Flow diagram for ﬁnding the global best pseudo-
solution (GBPS) is given in Fig. 10.
Fig. 10. Flow diagram for ﬁnding the global best-pseudo-solution (GBPS)
Fig. 11. Block diagram of METO algorithm
Plant Genetics-Inspired Evolutionary Optimization
71

METO concludes the solution, once, one of the following termination criteria met:
1. Maximum number of iterations.
2. Average of the species is not changing in N iteration.
3. The same answer is coming in each successive generation for m times.
4. If error is below than 10−5 or a desired value.
Condition 2 is for the sake of diversity. The block diagram of the algorithm is given in
Fig. 11.Here,wecanobservethattherearetwoparallelprocesses,outerprocessofevolution
and inner process of evolution. Outer process deals with the evolution of heredity, where
inner process concentrates on producing the two-generation offspring DNAs.
6
Conclusion
In this chapter, we illustrated the characteristics and the design of binary evolutionary
computational algorithm inspired from evolution in plant genetics. This framework
mainly consists of three concepts: First, the “denaturation” of DNAs of two different
species to produce the hybrid “offspring DNA.” Second, the Mendelian evolutionary
theory of genetic inheritance, which explains how the dominant and recessive traits
appear in two successive generations. Third, the epimutation, through which organisms
resist for natural mutation. The above concepts are reconﬁgured in order to design the
binary meta-heuristic evolutionary search technique. Based on this framework, four
evolutionary operators—(1) ﬂipper, (2) pollination, (3) breeding, and (4) epimutation—
are created in the binary domain. Moreover, pseudo-code and analysis on the move-
ment of points are discussed for better understanding of the algorithm.
Algorithm 4. Algorithm for epimutation
72
N. Gupta et al.

Algorithm 5. METO Algorithm
References
1. Dey N (ed) (2017) Advancements in applied metaheuristic computing. IGI Global,
Pennsylvania
2. Dey N, Ashour AS (2016) Antenna design and direction of arrival estimation in meta-
heuristic paradigm: a review. Int J Serv Sci Manag Eng Technol 7(3):1–18
Plant Genetics-Inspired Evolutionary Optimization
73

3. Gupta N, Patel N, Tiwari BN, Khosravy M (2018) Genetic algorithm based on enhanced
selection and log-scaled mutation technique. In: Proceedings of the future technologies
conference. Springer, Cham, pp 730–748
4. Singh G, Gupta N, Khosravy M (2015) New crossover operators for real coded genetic
algorithm (RCGA). In: 2015 international conference on intelligent informatics and
biomedical sciences (ICIIBMS), IEEE, pp 135–140
5. Gupta N, Khosravy M, Patel N, Senjyu T (2018) A bi-level evolutionary optimization for
coordinated transmission expansion planning. IEEE Access 6:48455–48477
6. Chatterjee S, Sarkar S, Hore S, Dey N, Ashour AS, Balas VE (2017) Particle swarm
optimization trained neural network for structural failure prediction of multistoried RC
buildings. Neural Comput Appl 28(8):2005–2016
7. Jagatheesan K, Anand B, Samanta S, Dey N, Ashour AS, Balas VE (2017) Particle swarm
optimisation-based parameters optimisation of PID controller for load frequency control of
multi-area reheat thermal power systems. Int J Adv Intell Paradigms 9(5–6):464–489
8. Chatterjee S, Hore S, Dey N, Chakraborty S, Ashour AS (2017) Dengue fever classiﬁcation
using gene expression data: a PSO based artiﬁcial neural network approach. In: Proceedings
of the 5th international conference on frontiers in intelligent computing: theory and
applications. Springer, Singapore, pp 331–341
9. Jagatheesan K, Anand B, Dey N, Gaber T, Hassanien AE, Kim TH (2015) A design of pi
controller using stochastic particle swarm optimization in load frequency control of thermal
power systems. In: 2015 fourth international conference on information science and
industrial applications (ISI). IEEE, pp 25–32
10. Khosravy M, Gupta N, Patel N, Senjyu T, Duque CA (2020) Particle swarm optimization of
morphological ﬁlters for electrocardiogram baseline drift estimation. In: Dey N, Ashour AS,
Bhattacharyya S (eds) Applied nature-inspired computing: algorithms and case studies.
Springer, Singapore, pp 1–21
11. Moraes CA, De Oliveira EJ, Khosravy M, Oliveira LW, Honório LM, Pinto MF (2020) A
hybrid bat-inspired algorithm for power transmission expansion planning on a practical
Brazilian network. In: Dey N, Ashour AS, Bhattacharyya S (eds) Applied nature-inspired
computing: algorithms and case studies. Springer, Singapore, pp 71–95
12. Satapathy SC, Raja NSM, Rajinikanth V, Ashour AS, Dey N (2018) Multi-level image
thresholding using Otsu and chaotic bat algorithm. Neural Comput Appl 29(12):1285–1307
13. Rajinikanth V, Satapathy SC, Dey N, Fernandes SL, Manic KS (2019) Skin melanoma
assessment using Kapur’s entropy and level set—a study with bat algorithm. In: Smart
intelligent computing and applications. Springer, Singapore, pp 193–202
14. Dey N, Samanta S, Yang XS, Das A, Chaudhuri SS (2013) Optimisation of scaling factors in
electrocardiogram signal watermarking using cuckoo search. Int J Bio-Inspired Comput 5
(5):315–326
15. Dey N, Samanta S, Chakraborty S, Das A, Chaudhuri SS, Suri JS (2014) Fireﬂy algorithm
for optimization of scaling factors during embedding of manifold medical information: an
application in ophthalmology imaging. J Med Imaging Health Inf 4(3):384–394
16. Gupta N, Khosravy M, Patel N, Sethi IK (2018) Evolutionary optimization based on
biological evolution in plants. Procedia Comput Sci 126:146–155
17. Gupta N, Khosravy M, Mahela OP, Patel N (2020) Plants biology inspired genetics
algorithm: superior efﬁciency to ﬁreﬂy optimizer. In: Applications of ﬁreﬂy algorithm and its
variants, from springer tracts in nature-inspired computing (STNIC). Springer International
Publishing, in press
18. BoussaïD I, Lepagnot J, Siarry P (2013) A survey on optimization metaheuristics. Inf Sci
237:82–117
74
N. Gupta et al.

19. Paszkowicz W (2013) Genetic algorithms, a nature-inspired tool: a survey of applications in
materials science and related ﬁelds: part II. Mater Manuf Processes 28(7):708–725
20. El-Mihoub TA, Hopgood AA, Nolle L, Battersby A (2006) Hybrid genetic algorithms: a
review. Eng Lett 13(2):124–137
21. Krasnogor N, Smith J (2005) A tutorial for competent memetic algorithms: model,
taxonomy, and design issues. IEEE Trans Evol Comput 9(5):474–488
22. AlRashidi MR, El-Hawary ME (2008) A survey of particle swarm optimization applications
in electric power systems. IEEE Trans Evol Comput 13(4):913–918
23. Burke EK, Gendreau M, Hyde M, Kendall G, Ochoa G, Özcan E, Qu R (2013) Hyper-
heuristics: a survey of the state of the art. J Oper Res Soc 64(12):1695–1724
24. Wolpert DH, Macready WG (1997) No free lunch theorems for optimization. IEEE Trans
Evol Comput 1(1):67–82
25. Garro BA, Vázquez RA (2015) Designing artiﬁcial neural networks using particle swarm
optimization algorithms. Comput Intell Neurosci 2015:61
26. Neshat M, Sepidnam G, Sargolzaei M, Toosi AN (2014) Artiﬁcial ﬁsh swarm algorithm: a
survey of the state-of-the-art, hybridization, combinatorial and indicative applications. Artif
Intell Rev 42(4):965–997
27. Eusuff M, Lansey K, Pasha F (2006) Shufﬂed frog-leaping algorithm: a memetic meta-
heuristic for discrete optimization. Eng Optim 38(2):129–154
28. Simon D (2008) Biogeography-based optimization. IEEE Trans Evol Comput 12(6):
702–713
29. Rajabioun R (2011) Cuckoo optimization algorithm. Appl Soft Comput 11(8):5508–5518
30. Xin-She Y (2011) Bat algorithm for multi-objective optimization. Int J Bio-Inspired Comput
3(5):267–274
31. Rao RV, Savsani VJ, Vakharia DP (2011) Teaching–learning-based optimization: a novel
method for constrained mechanical design optimization problems. Comput Aided Des 43
(3):303–315
32. Beheshti Z, Shamsuddin SMH (2013) A review of population-based meta-heuristic
algorithms. Int J Adv Soft Comput Appl 5(1):1–35
33. Zhan ZH, Zhang J, Li Y, Chung HSH (2009) Adaptive particle swarm optimization. IEEE
Trans Syst Man Cybern Part B (Cybernetics) 39(6):1362–1381
34. Khosravy M, Punkoska N, Asharif F, Asharif MR (2014) Acoustic OFDM data embedding
by reversible Walsh-Hadamard transform. In: AIP conference proceedings, vol 1618, no 1,
pp 720–723
35. Khosravy M, Gupta N, Marina N, Asharif MR, Asharif F, Sethi IK (2015) Blind components
processing a novel approach to array signal processing: a research orientation. In: 2015
international conference on intelligent informatics and biomedical sciences (ICIIBMS),
IEEE, pp 20–26
36. Khosravy M, Asharif MR, Yamashita K (2009) A PDF-matched short-term linear
predictability approach to blind source separation. Int J Innovative Comput Inf Control
(IJICIC) 5(11):3677–3690
37. Khosravy M, Alsharif MR, Yamashita K (2009) A PDF-matched modiﬁcation to stone’s
measure of predictability for blind source separation. In: International symposium on neural
networks. Springer, Berlin, pp 219–228
38. Khosravy M, Asharif MR, Yamashita K (2011) A theoretical discussion on the foundation of
stone’s blind source separation. Sig Image Video Process 5(3):379–388
39. Khosravy M, Asharif M, Yamashita K (2008) A probabilistic short-length linear
predictability approach to blind source separation. In: 23rd international technical conference
on circuits/systems, computers and communications (ITC-CSCC 2008), Yamaguchi, Japan,
pp 381–384
Plant Genetics-Inspired Evolutionary Optimization
75

40. Khosravy M, Kakazu S, Alsharif MR, Yamashita K (2010) Multiuser data separation for
short message service using ICA (信号処理). 電子情報通信学会技術研究報告. SIP, 信号
処理: IEICE Tech Rep 109(435):113–117
41. Gutierrez CE, Alsharif MR, Yamashita K, Khosravy M (2014) A tweets mining approach to
detection of critical events characteristics using random forest. Int J Next-Gener Comput 5
(2):167–176
42. Chakraborty S, Samanta S, Biswas D, Dey N, Chaudhuri SS (2013) Particle swarm
optimization based parameter optimization technique in medical information hiding. In:
2013 IEEE international conference on computational intelligence and computing research,
pp 1–6
43. Dey N, Mukhopadhyay S, Das A, Chaudhuri SS (2012) Analysis of P-QRS-T components
modiﬁed by blind watermarking technique within the electrocardiogram signal for
authentication in wireless telecardiology using DWT. Int J Image Graph Signal Process 4
(7):33
44. Dey N, Ashour AS, Shi F, Fong SJ, Sherratt RS (2017) Developing residential wireless
sensor networks for ECG healthcare monitoring. IEEE Trans Consum Electron 63(4):
442–449
45. Sedaaghi MH, Khosravi M (2003) Morphological ECG signal preprocessing with more
efﬁcient baseline drift removal. In: Proceedings of the 7th IASTED international conference,
ASC, pp 205–209
46. Khosravi M, Sedaaghi MH (2004) Impulsive noise suppression of electrocardiogram signals
with mediated morphological ﬁlters. In: The 11th Iranian conference on biomedical
engineering, Tehran, Iran, pp 207–212
47. Khosravy M, Asharif MR, Sedaaghi MH (2008) Medical image noise suppression: using
mediated morphology. IEICE technical report, IEICE, pp 265–270
48. Hore S, Chakraborty S, Chatterjee S, Dey N, Ashour AS, Van Chung L, Le DN (2016) An
integrated interactive technique for image segmentation using stack based seeded region
growing and thresholding. Int J Electr Comput Eng 6(6):2088–8708
49. Ashour AS, Samanta S, Dey N, Kausar N, Abdessalemkaraa WB, Hassanien AE (2015)
Computed tomography image enhancement using cuckoo search: a log transform based
approach. J Sig Inf Process 6(03):244
50. Khosravy M, Gupta N, Marina N, Sethi IK, Asharif MR (2017) Brain action inspired
morphological image enhancement. Nature-inspired computing and optimization. Springer,
Cham, pp 381–407
51. Khosravy M, Gupta N, Marina N, Sethi IK, Asharif MR (2017) Perceptual adaptation of
image based on Chevreul-Mach bands visual phenomenon. IEEE Signal Process Lett 24
(5):594–598
52. Sedaaghi MH, Daj R, Khosravi M (2001) Mediated morphological ﬁlters. In: Proceedings
2001 international conference on image processing (Cat. No. 01CH37205), vol 3. IEEE,
pp 692–695
53. Khosravy M, Gupta N, Marina N, Sethi IK, Asharif MR (2017) Morphological ﬁlters: an
inspiration from natural geometrical erosion and dilation. Nature-inspired computing and
optimization. Springer, Cham, pp 349–379
54. Picorone AAM, Oliveira TR, Sampaio-Neto R, Khosravy M, Ribeiro MV (2020) Channel
characterization of low voltage electric power distribution networks for PLC applications
based on measurement campaign. Int J Electr Power Energy Syst 116:105554
55. Gupta S, Khosravy M, Gupta N, Darbari H (2019) In-ﬁeld failure assessment of tractor
hydraulic system operation via pseudospectrum of acoustic measurements. Turk J Electr Eng
Comput Sci 27(4):2718–2729
76
N. Gupta et al.

56. Khosravy M, Patel N, Gupta N, Sethi IK (2019) Image quality assessment: a review to full
reference indexes. Recent trends in communication, computing, and electronics. Springer,
Singapore, pp 279–288
57. Gutierrez CE, Alsharif MR, Khosravy M, Yamashita K, Miyagi H, Villa R (2014) Main
large data set features detection by a linear predictor model. In: AIP conference proceedings,
vol 1618, no 1, pp 733–737
58. Khosravy M, Alsharif MR, Guo B, Lin H, Yamashita K (2009) A robust and precise solution
to permutation indeterminacy and complex scaling ambiguity in BSS-based blind MIMO-
OFDM receiver. In: International conference on independent component analysis and signal
separation. Springer, Berlin, pp 670–677
59. Asharif F, Tamaki S, Alsharif MR, Ryu HG (2013) Performance improvement of constant
modulus algorithm blind equalizer for 16 QAM modulation. Int J Innovative Comput Inf
Control 7(4):1377–1384
60. Khosravy M, Alsharif MR, Yamashita K (2009) An efﬁcient ICA based approach to
multiuser detection in MIMO OFDM systems. Multi-carrier systems & solutions. Springer,
Dordrecht, pp 47–56
61. Khosravy M, Alsharif MR, Khosravi M, Yamashita K (2010) An optimum pre-ﬁlter for ICA
based multi-input multi-output OFDM system. In: 2010 2nd international conference on
education technology and computer, vol 5. IEEE, pp V5-129
62. MARTINS LACP (1915) The dissemination of the chromosome theory of mendelian
heredity by Morgan and his collaborators around
63. Oey H, Whitelaw E (2014) On the meaning of the word ‘epimutation’. Trends Genet 30
(12):519–520
64. Rashedi E, Nezamabadi-Pour H, Saryazdi S (2009)GSA: a gravitational search algorithm.
Inf Sci 179(13):2232–2248
65. Sinden RR (2012) DNA structure and function. Elsevier, Amsterdam
Plant Genetics-Inspired Evolutionary Optimization
77

Trends on Fitness Landscape Analysis in
Evolutionary Computation and
Meta-Heuristics
Yan Pei(B)
Computer Science Division, University of Aizu, Tsuruga, Ikki-machi,
Aizuwakamatsu 965-8580, Japan
peiyan@saizu.ac.jp
https://www.u-aizu.ac.jp/∼peiyan/
1
Introduction
Evolutionary computation (EC) is referred as to a family of optimization algo-
rithms that are inspired by the phenomena of biological evolution. It has the
characteristics of meta-heuristic, population-based, trial and error, etc., in its
optimization process. The research scope of EC is usually involved in the ﬁelds
of artiﬁcial intelligence and soft computing. One is attempting to implement
intelligence by machine and lives, and the other obtains inexact solutions for a
hard computational problem, e.g. an NP-complete problem. It is one of the study
subjects of computational intelligence, which primarily includes neural networks,
fuzzy logic and system, and EC. Genetic algorithm [1], genetic programming [2],
evolution strategy [3,4], and evolutionary programming [5] are four well estab-
lished conventional algorithms in EC community. Ant colony optimization [6],
particle swarm optimization [7], and swarm intelligence (SI) [8] are developed
to enrich the algorithms of EC and introduce many nature-inspired hints and
phenomena into implementations of EC design and application. There are more
than two hundred EC algorithms that were proposed and studied in diﬀerent
optimization algorithm and application ﬁelds. The conventional EC algorithms
include crossover, mutation, and selection operations in their optimization pro-
cess. Most EC algorithms including SI ones have the same optimization frame-
work but have diﬀerent implementations of operations.
EC uses the techniques or implements the procedures from meta-heuristic,
which presents a high-level process abstraction and heuristic design to an opti-
mization algorithm [9]. In the technological term, EC is referred to as a set of
optimization of techniques that implement these optimization algorithms. The
research scope of meta-heuristic involves that of EC. Meta-heuristic is a con-
ceptual level terminology for designing an EC algorithm [10]. It also utilizes
Darwinian and Mendelian meta-heuristic techniques, whose principles for solv-
ing optimization problems to have been reiterated in genetic algorithms [11].
The objective of meta-heuristic attempts to obtain an eﬀective search strategy
to ﬁnd an approximate optimum. It presents a series of local searches, memetic
c
⃝Springer Nature Singapore Pte Ltd. 2020
M. Khosravy et al. (eds.), Frontier Applications of Nature Inspired Computation,
Springer Tracts in Nature-Inspired Computing,
https://doi.org/10.1007/978-981-15-2133-1_4

Trends on Fitness Landscape Analysis in Evolutionary Computation
79
searches, and learning processes in its methodology. Consequently, it is not a
problem-driven strategy terminology and has a common characteristic in its
principle in a stochastic process.
Fitness landscape concept of EC comes from that of evolutionary biology,
which presents or visualizes the relationship between genotype and procedure
success. Both sides of the relationship are optimized variables and their ﬁtness
values, respectively, in evolutionary optimization. It can be simply modelled
as a mathematical function to demonstrate this relationship formally. If the
optimized problem has only one objective, the ﬁtness function is designed to one
mathematical function. If that has more than one objectives, there are more than
one ﬁtness functions, i.e. the ﬁtness landscape of multi-objective optimization
problem. These modelling presentations are distinguished as the single-objective
and the multi-objective ﬁtness landscape. As in one ﬁtness landscape, if it has
one peak, it is a unimodal ﬁtness landscape. Otherwise, it is a multimodal ﬁtness
landscape that is with many local optima in the search space. The study of the
ﬁtness landscape relates to both EC algorithm and optimized problem; it is a
bridge of optimization algorithm and its application problem. Consequently, the
study of analysing, modelling, and investigating ﬁtness landscape is a crucial
subject in EC research community.
There are three primary study subjects in the EC research community. One is
the EC algorithm-oriented study, which tries to design an eﬀective EC algorithm
and to enhance the optimization capability of the EC algorithm inspired by meta-
heuristics. One is the EC application-oriented study, which attempts to apply
EC algorithms in a variety of real-world applications that cannot be perfectly
solved by a conventional deterministic optimization algorithm. Many EC-based
optimization software productions are also developed to the industry to enrich
the study subject of EC application. The third study subject of EC is the ﬁtness
landscape analysis that relates both the EC algorithm and its application. On
the one hand, it supports search information for EC algorithm to improve its
optimization performance. On the other hand, ﬁtness landscape analysis provides
structural information of a real-world optimization problem, especially helps
us to understand the problems that have no explicit ﬁtness functions, or the
problems that need to involve the human evaluation in the loop [12], such as
interactive evolutionary computation [13].
In this chapter, we introduce three innovative methods on analysing and
approximating ﬁtness landscape. They are (1). ﬁtness landscape approximation
using functional regression, where the approximation is not only conducted in
original parameter space but also done in a projected lower-dimensional param-
eter space. It was applied to enhance many well-known EC algorithms such
as diﬀerential evolution [14] and ﬁreworks algorithm [15]. (2). Fourier analysis
method on the ﬁtness landscape, where we ﬁnd the frequency information from a
parameter space using fast Fourier transform and estimate an elite search point
to accelerate EC search. And (3). convergence point estimation using moving
vectors information from ﬁtness landscape, where the evolution improvement
information supports us for the possible search area of the global optimum in

80
Y. Pei
parameter space, and we can use the information to estimate a convergence point
to accelerate EC search mathematically. These three study subjects present the
originality of the study in the ﬁtness landscape approximation. We brieﬂy explain
the motivation, implement each method, and present the outlook and future
trends of ﬁtness landscape analysis in the EC research community.
Following this introduction section, functional approximation method of the
ﬁtness landscape is introduced in Sect. 2. Fourier analysis of a ﬁtness landscape is
presented in Sect. 3. In Sect. 4, we present a convergence point estimation method
using the ﬁtness landscape. The motivation, implementation, and evaluation of
each method are presented in detail. Finally, we conclude the whole work and
present future opportunities and open topics of ﬁtness landscape analysis in the
EC research community in Sect. 5.
2
Fitness Landscape Approximation Using Functional
Approximation in Lower-Dimensional Space
2.1
Functional Approximation Method
Lagrange Interpolation Method A Lagrange interpolation polynomial has
characteristics of linearity and uniqueness. In a scenario in EC algorithm, there
is one parameter of an individual in EC algorithm, i.e. x0, x1, . . . , xn. We can
construct a polynomial with n degree, i.e. l0(x), l1(x), . . . , ln(x). We set its type
as li(xj) = δij, where the value of δij is set in Eq. (1).
δij =
0 if i = j
1 if i ̸= j
(1)
From Eq. (1), we can obtain the expression pn(x) = n
k=0 lk(x)yk, which is
the n degree interpolation polynomial, where li(x) is an n-th degree polynomial.
We can obtain the relationship shown in Eqs. (2), (3), (4), and (5).
pn(x) =
n

k=0
lk(x)yk
(2)
lk(x) = a(x −x0)...(x −xk−1)(x −xk+1)...(x −xn)
(3)
When lk(x) = 1, the parameter a can be expressed by Eq. (4).
a = [(xk −x0)...(xk −xk−1)(xk −xk+1)...(xk −xn)]−1
(4)

Trends on Fitness Landscape Analysis in Evolutionary Computation
81
Equation (4) can be rewritten as in Eq. (5).
l(x) =
n

i=1,i̸=k
(x −xi)
(xk −xi)
(5)
Equation (5) is a Lagrange interpolation benchmark function with n degree,
and an Lagrange interpolation polynomial with n degree is shown in Eq. (6).
Ln(x) =
n

k=0
lk(x)yk, i = 0, 1, ..., n
(6)
We use a Lagrange interpolation polynomial with two degrees as a simpliﬁed
regression ﬁtness landscape expression. The n individuals are used as interpola-
tion points to establish a regression function to approximate ﬁtness landscape.
The established interpolation polynomial is in the Eq. (7). Lagrange interpola-
tion method is used to calculate parameters of Eq. (7).
L(x) =
n

k=1
⎧
⎨
⎩
n

i=1,i̸=k
(x −xi)
(xk −xi)
⎫
⎬
⎭yk
(7)
Least Squares Approximation Method When we use the two-norm as the
error metric to evaluate an approximation function, the approximation method
is called the least squares method. We attempt to establish an interpolation
function that sets the error two-norm vector to be minimized, i.e. Eq. (9).
Φ = Span{ϕ0(x), ϕ1(x), ..., ϕn(x)}
(8)
||δ∗||2
2 =
m

i=0
δ∗2
i
=
m

i=0
[ϕ∗(xi) −yi]2 =
min
ϕ(x)∈Φ ||δ∗||2
2
(9)
The approximation function is shown in Eq. (10).
ϕ∗(x) = a∗
0ϕ0(x) + a∗
1ϕ1(x) + ... + a∗
nϕn(x)
(10)
If we obtain ϕ0(x), ϕ1(x), . . . , ϕn(x), the system is an orthogonal one, i.e.
(ϕi, ϕj) = 0(i ̸= j). The coeﬃcient matrix equations can construct a diagonal
matrix Eq. (11).
a∗
k = (f, ϕk)
(ϕk, ϕk)
(11)
Consequently, the approximation function becomes Eq. (12).
ϕ∗(x) =
n

i=0
(f, ϕi)
(ϕi, ϕi)ϕi(x)
(12)

82
Y. Pei
We use the one-degree power function as a regression function to approximate
the ﬁtness landscape in linear space, where the expression is presented as in Eq.
(13). The approximation method obtains the parameters of u and v in Eq. (13),
so that regression ﬁtness landscape can be deﬁned in the linear parameter space.
(ϕ0ϕ0)(ϕ0ϕ1)
(ϕ1ϕ0)(ϕ1ϕ1)
 u
v

=
y0
y1

(13)
2.2
Approximating Fitness Landscape in an Original Parameter
Space
There is a method to approximate an n-dimensional (n-D) ﬁtness landscape
using an n-D unimodal function, use the peak point of the unimodal function as
an elite individual, and replace the worst individual with the elite [16]. This idea
is inspired by the scale-space ﬁltering method [17]. The roughest approximation
of signal is a single peak function, and roughly speaking, its peak location is
near the global peak of the original signal. The scale-space ﬁltering method was
developed to detect several small peaks in signal originally. It has been used to
detect edges in image processing. As the amplitudes of small-signal peaks in the
time duration of low amplitude are smaller than noise added to signal in the
time duration of big amplitude, we cannot distinguish the small-signal peaks
and noise on a bigger signal using an amplitude threshold. However, human
can distinguish them visually. The idea of the scale-space ﬁltering is to convolve
Gaussian functions with gradually changed variances with the signal. Scale-space
is the collection of the convolved signals; imagine x-y axes are a time axis and
a variance axis, respectively. Convolved time signals become dull according to
increasing variances, and the dullest signal has an only single peak. This method
allows us to trance the nearest peaks from the ﬁnal single peak to the direction of
smaller variances gradually and ﬁnally reach several original signal peaks. Noise
peaks on a signal of bigger amplitude are not detected due to further bigger
signal peaks, while small-signal peaks without noise are detected. The obvious
feature of this original proposal to accelerate EC optimization is Low Risk and
High Return [16]. Even if the ﬁtness of an elite individual is poor, just the worst
individual among many individuals is replaced with the poor elite individual
that is still better than the worst individual, while the elite individual becomes
a powerful parent when its ﬁtness is high.

Trends on Fitness Landscape Analysis in Evolutionary Computation
83
)
,...,
,
(
2
n
e
til
e
1
elite
elite
x
x
x
−
−
−
New Elite =
Fig. 1. Dimensionality reduction, obtain elite in each projected dimensional landscape
and synthesizing elite methods. This ﬁgure is adopted from [18]
2.3
Approximating Fitness Landscape in a Dimensionality Reduced
Space
It is not easy for conventional approximation methods to construct an accu-
rate ﬁtness landscape in the original multi-dimensional parameter space. One
of the alternative methods tries to decrease the dimensionality of the original
parameter space and construct many approximation functional expressions in
a lower-dimensional parameter space [14]. In general, this proposed method is
a local search method for enhancing EC search and reduces the computational
complexity signiﬁcantly [18]. This represents its original contribution.
Dimensionality Reduction The method for decreasing the dimensionality of
the parameter space uses one of the n parameter axes at once to replace the
n parameter axes and projects individuals in each one-dimensional parameter
space. The ﬁtness landscape of a n-dimensional parameter space is presented by
a ﬁtness function, i.e. y = f(x1, x2, ..., xn). Fitness value of the m-th individual
is shown in Eq. (14).
ym = f(x1m, x2m, ..., xnm) (m = 1, 2, ..., M)
(14)
There are M individuals with n-dimensional parameter variables. We can
make a projection that makes the individuals into the i −th one-dimensional
parameter spaces as (xi1, y1) (xi2, y2) ... (xim, ym). In the n one-dimensional
parameter spaces, there are M projected individuals.
Landscape Approximation We approximate the ﬁtness landscape of each
one-dimensional parameter space using the projected M individuals and select n

84
Y. Pei
elite solutions from the n approximated one-dimensional parameter spaces. The
proposed method selects n elite point solutions in n one-dimensional parameter
spaces, respectively, as follows.
x1−elite, x2−elite, ..., and xn−elite.
Elite
Synthesization
The
n-D
elite
used
for
enhancing
EC
search
by inserting in the next generation to search is obtained as Elite
=
(x1−elite, x2−elite, . . . , xn−elite) (see Fig. 1). The method of elite synthesization
utilization replaces the individual who has the worst ﬁtness value in every gen-
eration with the estimated elite solution. We cannot avoid a less possibility that
the global optimum is located near an individual with the worst ﬁtness value.
However, the possibility, which an individual with the worst ﬁtness value can
become a parent individual in the next generation, is also low. Consequently,
deleting an individual with the worst ﬁtness value presents the least risk, and it
is a reasonable strategy as well.
2.4
Evaluations and Discussions
We use the eight benchmark functions in Appendix section to evaluate the accel-
eration performance of ﬁtness approximation in lower-dimensional space. The
dimension setting of these benchmark functions is three-dimensional (3-D), 2-
D, 5-D, 30-D, 2-D, 5-D, 5-D, and 5-D for F1–F8, respectively. Search ranges
of all the parameters are presented in the Appendix section. All these function
optimization benchmark problems are posed as minimization problems, i.e. the
optimum solution is a point with the lowest ﬁtness value. We use one of diﬀer-
ential evolution algorithms [20], i.e. DE/best/1/bin as an optimization method
to evaluate the proposed method. For each benchmark function, we make 50
trial runs and 50 generations. We apply the sign test to every pair comparison
to make the signiﬁcant conclusion in the performance of our proposed method.
We abbreviate the DE algorithm whose ﬁtness landscape is approximated using
a Lagrange interpolation polynomial with two degrees as DE-LR. The method
that approximates the ﬁtness landscape using a linear power function with the
least squares approximation method as DE-LS and conventional DE algorithm
as DE-N. These abbreviations are also presented in Fig. 2. Figure 2 shows the
mean value of convergence curves of the best ﬁtness values.
From these results, we can conclude the following.
1. Our proposed ﬁtness landscape approximation methods can accelerate the
search of all benchmark problems, except F3 and F7;
2. From the sign test result, there is no signiﬁcant diﬀerence, i.e. the p-value is
more than 0.05, between conventional DE and DE with our proposed methods
(DE-LR or DE-LS) in F3 and F7;
3. The acceleration performance of each benchmark problem is similar;

Trends on Fitness Landscape Analysis in Evolutionary Computation
85
F1
F2
F3
F4
F5
F6
F7
F8
Fig. 2. Convergence curves of F1–F8 from ﬁtness landscape approximation using
functional approximation in a lower-dimensional parameter space.
These ﬁgures are
adopted from reference [19]

86
Y. Pei
4. If there is any diﬀerence in search acceleration, the superiority depends on
the benchmark problem being performed, and;
5. DE algorithms with the proposed method are better than conventional DE
algorithm in latter generations, i.e. when the search points approach the
global optimum in each benchmark problem.
The proposed method can reduce the computational complexity of approx-
imation in the original parameter space. It is one of the characteristics of the
ﬁtness landscape approximation method. This method introduces a projection of
ﬁtness landscape into a one-dimensional space, synthesizing an elite in multiple
one-dimensional functions. The projections reduce the computation complexity
in approximation processes.
3
Fourier Analysis of Fitness Landscape
3.1
Fourier Transform
Since Jean Baptiste Joseph Fourier issued his classical paper on the distribution
of temperature by the trigonometric function in 1807, he proposed that any
continuous periodical functions can be expressed by a set of combination of
the sinusoidal function. Fourier transform has been used in many scientiﬁc and
industrial societies as a powerful mathematical analysis tool. There are four
types of Fourier transforms, i.e. Fourier transform, Fourier series, discrete-time
Fourier transform, and discrete Fourier transform (DFT), which can process
the signals that are continuous and aperiodic, signals that are continuous and
aperiodic, signals that are discrete and aperiodic, and signals that are discrete
and aperiodic, respectively. Because only the inﬁnite signals can be transferred
in Fourier analysis, we have to make the prolongation original signal, which
copies its existent part or set zero value in the undeﬁned range, to cope with
this restriction.
Due to the computer that can only process the discrete signals, the discrete
Fourier transform is valuable to the applications in many areas. Equations (15)
and (16) show the discrete Fourier transform and inverse discrete Fourier trans-
form (IDFT), which is the main tool that we use to analyse the EC ﬁtness
landscape.
X(k) = DFT[x(n)] =
N−1

n=0
x(n)W kn
N
(15)
x(n) = IDFT[X(k)] = 1
N
N−1

k=0
X(k)W −kn
N
(16)
In Eqs. (15) and (16), W kn
N is W kn
N = e−2kπ
N , and 0 ≤k ≤N −1 . The terms
x(n), X(k), n, and N are the original signal series, frequency signals by DFT
in frequency space, number of the original signal, and number of transform base
frequency, respectively. For one time DFT, its computational complexity is up to
O(N 2), so it is costly for introducing DFT into EC to analyse ﬁtness landscape
complexity and to apply to practical application.

Trends on Fitness Landscape Analysis in Evolutionary Computation
87
3.2
Fast Fourier Transform in One Dimension
For reducing the DFT computational cost, in 1965, Cooley and Tukey proposed
a fast discrete Fourier transform (FFT) [21]. The principle of FFT tries to sep-
arate long series to shorter ones. It utilizes the characteristics of periodic and
symmetric to reduce the calculation times in the transform. There are two FFT
algorithms. The one is decimation in time algorithm (DIT), and the other is
decimation in frequency algorithm (DIF).
X(k) = x(2r)W 2rk
N
± W k
Nx(2r + 1)W (2r+1)k
N
(17)
X(k) =
N
2 −1

n=0
[x(n) + (−1)(k)x(n + N
2 )]W n
Nk
(18)
Equations (17) and (18) present the fundamental principle of the DIT and
DIF, respectively. In Eq. (17), symbol + when k ∈[0, N
2 −1], symbol −when
k ∈[ N
2 , N −1]. These two algorithms reduce the computational complexity of
conventional FFT algorithm from O(N 2) to O(N log N). In this work, DIF is
used as the primary analysis method to transform the original EC ﬁtness land-
scape series into a frequency space to obtain the frequency information of the
original ﬁtness landscape.
Fig. 3. Flow diagram of ﬁtness landscape approximation using Fourier analysis. This
ﬁgure is adopted from [22]
3.3
Fitness Landscape Approximated Using Fourier Transform
We introduced to use discrete Fourier transform (DFT) for approximating ﬁtness
landscape and accelerating EC search [22]. There are primarily ﬁve steps for
implementing this method. These ﬁve steps are (1). re-sampling ﬁtness value in

88
Y. Pei
the original parameter space, (2). applying one-dimensional Fourier transform to
obtain frequency information, (3). ﬁltering the principal frequency component
as a primary approximation component, (4). conducting one-dimensional inverse
Fourier transform to approximate ﬁtness landscape, and (5). obtaining an elite
solution from peak point and using it into the next generation search.
Concept of the Proposal Figure 3 presents a ﬂow diagram of the ﬁtness land-
scape using Fourier analysis and how to use the elite obtained from the ﬁtness
landscape to enhance EC search. Frequency information of a ﬁtness landscape is
constructed by re-sampling a parameter space with regular intervals. We apply
the DFT to a sequence of ﬁtness values from the re-sampled points. Original ﬁt-
ness landscape is approximated by a trigonometric function with a primary fre-
quency component. We conduct the inverse DFT to the frequency components.
The ﬁtness landscape approximation using Fourier analysis aims to enhance EC
algorithm search. The approximated function obtained by FFT is a regression
model using trigonometric functions Eq. (19).
EC(X) =
N

i=0
ai cos(2πωiX + Bi)
(19)
Principal Frequency Component The trigonometric functions construct the
ﬁtness landscape as shown in Eq. (19). It is determined by frequency, amplitude,
and phase information. We deﬁne them as principal frequency components (PFC)
and call them the PFC, the second, and so on according to their maximum power
ranking.
Although the ﬁtness landscape of EC search is not periodical with 1/ω in
many conditions, we can universally approximate a local ﬁtness landscape when
using an arbitrary number of trigonometric functions. However, more trigono-
metric functions lead to more computational complexity in approximation. In the
evaluation, we approximate the ﬁtness landscape using only one trigonometric
function, i.e. ﬁrst PFC is introduced in the functional regression model.
Evolution Control Method for EC Search Acceleration We can obtain a
local ﬁtness landscape information in one-dimensional and n-dimensional param-
eter space from the constructed trigonometric function using a PFC. The infor-
mation supported from this regression function is more than that is from a little
number of individuals.
An EC ﬁtness landscape with this regression model can guide the EC search
or make a new elite solution to enhance EC search. Peak point solution locates
around the points of k(1/ω) + b and k(1/2ω) + b for the maximum problems
and minimum problems, respectively. Reference [23] investigated using n-D
Fourier transform to obtain the PFC to accelerate EC search, from its results,
it can enhance the benchmark problems that were not accelerated by the one-
dimensional Fourier method.

Trends on Fitness Landscape Analysis in Evolutionary Computation
89
0
10
20
30
40
50
0
0.5
1
1.5
2
2.5
3
3.5
4
Function 1 Convergence
Generation
Fitness
DE−N
DE−LR
DE−LS
DE−FR−GLB−nD
DE−FR−LOC−nD
DE−FR−GLB−1D
DE−FR−LOC−1D
0
10
20
30
40
50
0
0.5
1
1.5
2
2.5
3
3.5
Function 2 Convergence
Generation
Fitness
DE−N
DE−LR
DE−LS
DE−FR−GLB−nD
DE−FR−LOC−nD
DE−FR−GLB−1D
DE−FR−LOC−1D
F1
F2
0
10
20
30
40
50
−30
−28
−26
−24
−22
−20
−18
−16
Function 3 Convergence
Generation
Fitness
DE−N
DE−LR
DE−LS
DE−FR−GLB−nD
DE−FR−LOC−nD
DE−FR−GLB−1D
DE−FR−LOC−1D
0
10
20
30
40
50
0
20
40
60
80
100
120
140
Function 4 Convergence
Generation
Fitness
DE−N
DE−LR
DE−LS
DE−FR−GLB−nD
DE−FR−LOC−nD
DE−FR−GLB−1D
DE−FR−LOC−1D
F3
F4
0
10
20
30
40
50
0
20
40
60
80
100
120
Function 5 Convergence
Generation
Fitness
DE−N
DE−LR
DE−LS
DE−FR−GLB−nD
DE−FR−LOC−nD
DE−FR−GLB−1D
DE−FR−LOC−1D
0
10
20
30
40
50
5
10
15
20
25
30
35
40
45
50
Function 6 Convergence
Generation
Fitness
DE−N
DE−LR
DE−LS
DE−FR−GLB−nD
DE−FR−LOC−nD
DE−FR−GLB−1D
DE−FR−LOC−1D
F5
F6
0
10
20
30
40
50
−6000
−5500
−5000
−4500
−4000
−3500
−3000
−2500
−2000
−1500
−1000
Function 7 Convergence
Generation
Fitness
DE−N
DE−LR
DE−LS
DE−FR−GLB−nD
DE−FR−LOC−nD
DE−FR−GLB−1D
DE−FR−LOC−1D
0
10
20
30
40
50
0.35
0.4
0.45
0.5
0.55
0.6
0.65
0.7
Function 8 Convergence
Generation
Fitness
DE−N
DE−LR
DE−LS
DE−FR−GLB−nD
DE−FR−LOC−nD
DE−FR−GLB−1D
DE−FR−LOC−1D
F7
F8
Fig. 4. Convergence curves of F1–F8 from ﬁtness landscape approximation using
Fourier analysis. These ﬁgures are adopted from reference [22]

90
Y. Pei
3.4
Evaluations and Discussions
We use diﬀerential evolution (DE/best/1/bin) as an optimization method to
evaluate the proposed method and conventional DE algorithm and apply them
to eight benchmark functions from the Appendix section. We conduct each eval-
uation for 50 generations with 50 trial runs and analyse signiﬁcant eﬀect using
a sign test. Figure 4 presents the convergence curves of the best ﬁtness values
of these eight benchmark functions. There are four variations of a DFT-based
method proposed in this work, i.e. DE-FR-GLB-1D, DE-FR-GLB-nD, DE-FR-
LOC-1D, and DE-FR-LOC-nD. They mean DE with elite obtained by global
sampling in one-dimensional space, global sampling in n-dimensional space, local
sampling in one-dimensional space, and local sampling in n-dimensional space,
respectively. We can conclude the below discoveries from these evaluations.
1. Our proposed methods can enhance DE search in these benchmark functions,
except F2.
2. The performances of four proposed methods look similar, and their superiority
to each other depends on tasks even if there is a diﬀerence between their
performances.
3. DE-FR-GLB-nD method has shown better performance than other proposed
methods; it indicates that global sampling is a better method to obtain ﬁtness
landscape characteristic and ﬁnds the global optimum eﬃciently.
4. Our proposals in this work have presented a better enhancement performance
for F3, F5, F6, F7, and F8 than our previous acceleration methods in refer-
ence [14].
Approximation complexity reduction in a ﬁtness landscape is one of the
objectives of this work. We use the frequency characteristics of a ﬁtness land-
scape to establish the regression model. Global exploration and local exploitation
are the great features of the proposed method for accelerating EC search conver-
gence. The evaluation results have presented that these proposed methods can
accelerate EC.
4
Estimation of a Convergence Point from Fitness
Landscape
4.1
Estimation Method of a Convergence Point
The estimated convergence solution of a set of moving vectors from parent to
their oﬀspring can be constructed mathematically [24]. First of all, let us deﬁne
symbols for analysis and discussion. ai and ci in the Fig. 5 are the i-th parent
individual and their oﬀspring individual, respectively (ai, ci ∈Rd). The i-th
moving vector is deﬁned to be as a direction vector, bi = ci −ai. The unit
direction vector of the bi is presented as b0i = bi/||bi||, i.e. bT
0ib0i = 1.
Let x ∈Rd be the point that is the distance nearest one to n extended and
directional line segments, ai + tibi (ti ∈R). This nearest pretests that the total
distance from the x to the n extended and directional line segments, J(x, {ti})
in Eq. (20), is the minimum.

Trends on Fitness Landscape Analysis in Evolutionary Computation
91
Fig. 5. Moving vector bi (= ci −ai) is calculated from a parent individual ai and its
oﬀspring ci in the d-dimensional searching space. The ⋆mark is the convergence point
of these moving vectors. This ﬁgure is adopted from [24]
Because the minimum line segment from a convergence point x to the
extended and directional line segments is an orthogonal projection from the
x, we can establish an orthogonal condition, Eq. (21), use it in the Eq. (20), and
can delete a parameter, i.e. ti.
J(x, {ti}) =
n

i=1
∥ai + tibi −x∥2
(20)
bT
i (ai + tibi −x) = 0
(orthogonal condition)
(21)
The ˆx that can minimize the total distance as in Eq. (20) is calculated by
partially diﬀerentiating each element of x and making them equal to 0. Finally,
the convergence point ˆx is calculated by the Eq. (22), where Id is a unit matrix.
ˆx =
 n

i=1

Id −b0ibT
0i
−1  n

i=1

Id −b0ibT
0i

ai

(22)
4.2
Estimated Convergence Point to Accelerate Evolutionary
Computation
An estimated convergence point from the ﬁtness landscape information presents
a promising search area in parameter space. Because a peak point of approxi-
mated ﬁtness landscape can locate near the global optimum area, it can be used
as an elite search solution, and its acceleration eﬀect for EC search is analysed
and discussed [14]. Consequently, the estimated convergence point is expected
to have the same eﬀect, too.

92
Y. Pei
Algorithm 1 Estimated a convergence point to accelerate EC search. G: gen-
eration.
1: Population initialization.
2: Evaluate ﬁtness of each individual.
3: for G = 1 to MaxGeneration do
4:
Generate a next-generation using an EC algorithm.
5:
Calculating the estimated point and evaluate its ﬁtness value.
6:
if ﬁtness value of the estimated point is better than that of the worst individual
then
7:
replace the worst individuals with the estimated points
8:
end if
9: end for
10: return the optimal solution
The objective of this work is to use an estimated convergence point as an elite
individual and evaluate the search enhancement eﬀect for EC algorithms. This
method obtains the estimated point using this estimation method and replaces
the worst individual with the estimated point. Algorithm 1 presents the ﬂowchart
of the EC algorithm using this elitism strategy. The drawback of the estimation
method is the computational cost. Taking account of the balance between accel-
eration eﬀect and computational complexity is an important issue in practical
applications.
4.3
Evaluations and Discussions
We use six functions from Appendix section (F1–F6) as benchmark functions
to evaluate the proposed estimated points-based DE. Their dimensions are 2-D
and 30-D and search ranges of all parameters present in the Appendix section.
All these benchmark function tasks are posed as minimization problems.
We use diﬀerential evolution (DE/rand/1/bin) as the optimization method to
compare with the proposed estimated points-based DE. We test each benchmark
function with 30 trial runs of 100 generations and apply Wilcoxon sign-ranked
test to evaluate the performance of our proposed method in each generation. The
population size is 100; scale factor and crossover rate are both set to 1. Here,
we abbreviate the DE and estimated points-based DE as DE and DE-estimated,
respectively. These abbreviations are also used in Figs. 6 and 7. Figures 6 and 7
show the average convergence curves of the best ﬁtness values for 30 trial runs
of (DE vs. DE-estimated) of 2-D and 30-D, respectively. From the convergence
curves with the Wilcoxon sign-ranked test in Figs. 6 and 7, we can obtain the
conclusions as follows:
1. Our proposed estimated points-based DE can signiﬁcantly outperform DE in
both 2-D and 30-D test functions;
2. The acceleration performance of 30-D test functions is better than that of
2-D test functions;

Trends on Fitness Landscape Analysis in Evolutionary Computation
93
10
0
10
1
10
2
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
Generation
Fitness
DE
DE−estimated−point
10
0
10
1
10
2
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Generation
Fitness
DE
DE−estimated−point
F1
F2
10
0
10
1
10
2
0
0.5
1
1.5
2
2.5
Generation
Fitness
DE
DE−estimated−point
10
0
10
1
10
2
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1 x 10
−3
Generation
Fitness
DE
DE−estimated−point
F3
F4
10
0
10
1
10
2
0
1
2
3
4
5
6
7
Generation
Fitness
DE
DE−estimated−2points
DE−estimated−1point
10
0
10
1
10
2
0
20
40
60
80
100
120
140
160
180
200
Generation
Fitness
DE
DE−estimated−2points
DE−estimated−1point
F5
F6
Fig. 6. Convergence curves of 2-D functions. We can observe that the optimization
performances of DE and DE-estimated are diﬀerent, and there is a signiﬁcant diﬀerence
between DE and DE-estimated in all the test functions (F1–F6) from the results of
Wilcoxon sign-ranked tests (p < 0.05)

94
Y. Pei
10
0
10
1
10
2
0
20
40
60
80
100
120
140
160
180
Generation
Fitness
DE
DE−estimated−point
10
0
10
1
10
2
0
1000
2000
3000
4000
5000
6000
7000
Generation
Fitness
DE
DE−estimated−point
F1
F2
10
0
10
1
10
2
70
80
90
100
110
120
130
Generation
Fitness
DE
DE−estimated−point
10
0
10
1
10
2
0
10
20
30
40
50
60
70
80
90
100
Generation
Fitness
DE
DE−estimated−point
F3
F4
10
0
10
1
10
2
50
100
150
200
250
300
350
400
450
Generation
Fitness
DE
DE−estimated−2points
DE−estimated−1point
10
0
10
1
10
2
7500
8000
8500
9000
9500
10000
Generation
Fitness
DE
DE−estimated−2points
DE−estimated−1point
F5
F6
Fig. 7. Convergence curves of 30-D functions. We can observe that the optimization
performances of DE and DE-estimated are diﬀerent, and there is a signiﬁcant diﬀerence
between DE and DE-estimated in all the test functions (F1–F6) from the results of
Wilcoxon sign-ranked tests (p < 0.05)

Trends on Fitness Landscape Analysis in Evolutionary Computation
95
3. In most of the case, our estimated method can obtain only one estimated
point; and
4. The quality of the estimated point is diﬀerent due to the landscape of test
function from the evaluations of the distance between estimated points and
the global optimum.
The same estimation method can be applied in multi-objective optimization
problem [25] and multimodal optimization problem [26].
5
Conclusion
In this chapter, we reviewed and summarized new trends on ﬁtness landscape
approximation in EC research community. In the ﬁrst work, the EC landscape is
approximated with a two-degree Lagrange polynomial interpolation and a linear
power function least squares approximation to accelerate EC search convergence.
The feature of these EC search enhancement methods uses an elite synthesized
from lower-dimensional spaces. The priority of this method presents that the
computational complexity is reduced by approximation in lower-dimensional
parameter space. We also analysed the relationship between the performance
of the method and landscape characteristics of the benchmark function. We
found that it is an eﬀective method to approximate ﬁtness landscape in lower-
dimensional space for EC.
In the second work, we proposed a landscape approximation method that
analyses frequency characteristics of a ﬁtness landscape by using DFT, obtains
principal frequency components, ﬁlters the components, and applies inverse DFT
to the ﬁltered frequency characteristics. We also propose an EC acceleration
method that obtains the elite from the approximated landscape constructed
by trigonometric functions and replaces the worst EC individual with it. We
evaluated these methods with eight benchmark functions and shown that this
approximating a ﬁtness landscape method is an eﬀective way to accelerate EC
search. We also analysed and discussed the performance of our proposed meth-
ods. Frequency information is a metric to express ﬁtness landscape and analyses
the characteristic of ﬁtness landscape.
In the third work, we initially evaluated the optimization performance by
using a mathematical estimation method of the global optimum using multiple
moving vectors from parent individuals to their oﬀspring individuals. After we
obtained the estimated points, we replaced the individuals with worse ﬁtness
with these estimated points. Based on this basic principle, we designed an esti-
mated points-based DE algorithm and evaluated it by comparing with canonical
DE. From the evaluation results, we can conclude that the estimated points can
accelerate EC search. It is an eﬀective method to use a deterministic method to
model ﬁtness landscape and use it to enhance EC search.
In the future, we will continue developing a clustering method to improve
the estimation quality and develop more eﬃcient EC algorithms by using the
estimated points. We will also evaluate the optimization performance of other
EC algorithms by considering these estimated points. These and other works
will be involved in our future work and invited to further investigation.

96
Y. Pei
Appendix
F1: Sphere Function
f(x) = n
i=1 x2
i
Properties: x ∈[−5.12, 5.12], unimodal, separable
F2: Rosenbrock Function
f(x) = 100(x2
1 −x2)2 + (1 −x1)2
Properties: x ∈[−2.048, 2.048], multimodal, non-separable
F3: Step Function
f(x) = n
i=1⌊xi⌋
Properties: x ∈[−5.12, 5.12], unimodal, separable
F4: Quantic Function
f(x) = n
i=1 ix4
i + Gauss(0, 1)
Properties: x ∈[−1.28, 1.28], unimodal, separable
F5: Shekel’s Foxholes Function
f(x) = [0.02 + 25
j=1
1
j+2
i=1(xi−aij)6 ]−1
Properties: x ∈[−65.536, 65.536], multimodal, separable
F6: Rastrigin Function
f(x) = (10n) + n
i=1(x2
i −10 cos(2πxi))
Properties: x ∈[−5.12, 5.12], multimodal, separable
F7: Schwefel 2.26 Function
f(x) = n
i=1(−xi sin(

|xi|))
Properties: x ∈[−512, 512], multimodal, separable
F8: Griewank Function
f(x) = 1 + n
i=1
x2
i
4000 −n
i=1 cos( xi
√
i)
Properties: x ∈[−512, 512], multimodal, non-separable

Trends on Fitness Landscape Analysis in Evolutionary Computation
97
-6
-4
-2
0
2
4
6
-5
0
5
0
10
20
30
40
50
60
Sphere Function
-3
-2
-1
0
1
2
3
-2
0
2
-1
0
1
2
3
4
x 10
4
DeJong Function 2
F1
F2
-6
-4
-2
0
2
4
6
-5
0
5
-15
-10
-5
0
5
10
Quantic Function
-1.5
-1
-0.5
0
0.5
1
1.5
-1
0
1
0
2
4
6
8
F3
F4
-100
-50
0
50
100
-100
-50
0
50
100
0
100
200
300
400
500
-100
-50
0
50
100
-100
-50
0
50
100
0
10
20
30
40
Rastrigin Function
F5
F6
-600
-400
-200
0
200
400
600
-500
0
500
-1000
-500
0
500
1000
Schwefel Function
-600
-400
-200
0
200
400
600
-500
0
500
0
20
40
60
80
100
120
140
Griewank Function
F7
F8

98
Y. Pei
References
1. Holland JH (1975) Adaption in natural and artiﬁcial systems. In: An introductory
analysis with application to biology, control and artiﬁcial intelligence. MIT press
2. Koza JR (1992) Genetic programming: on the programming of computers by means
of natural selection. vol 1. MIT press
3. Ingo Rechenberg (1978) Evolutionsstrategien. Ph.D. thesis
4. Schwefel H-P (1977) Numerische optimierung von computer-modellen mittels der
evolutionsstrategie. (Teil 1, Kap. 1-5). Birkh¨auser
5. Fogel LJ, Owens AJ, Walsh MJ (1966) Artiﬁcial intelligence through simulated
evolution. John Wiley
6. Marco Dorigo and Luca Maria Gambardella (1997) Ant colony system: a coop-
erative learning approach to the traveling salesman problem. IEEE Trans Evol
Comput 1(1):53–66
7. Kennedy J, Eberhart R (1995) Particle swarm optimization (pso). In: Proceedings
of IEEE international conference on neural networks. Perth, Australia, pp 1942–
1948
8. Beni G, Wang J (1993) Swarm intelligence in cellular robotic systems. In: Robots
and biological systems: towards a new bionics? Springer, pp 703–712
9. Glover F (1986) Future paths for integer programming and links to artiﬁcial intel-
ligence. Comput Oper Res 13(5):533–549
10. Dey N (2017) Advancements in applied metaheuristic computing. IGI Global
11. Gupta N, Khosravy M, Patel N, Senjyu T (2018) A bi-level evolutionary optimiza-
tion for coordinated transmission expansion planning. IEEE Access 6:48455–48477
12. Pei Y, Takagi H (2018) Research progress survey on interactive evolutionary com-
putation. J Ambient Intell Humanized Comput, pp 1–14
13. Takagi H (2001) Interactive evolutionary computation: fusion of the capabilities of
ec optimization and human evaluation. Proc IEEE 89(9):1275–1296
14. Pei Y, Takagi H (2013) Accelerating iec and ec searches with elite obtained by
dimensionality reduction in regression spaces. Evol Intell 6(1):27–40
15. Pei Y, Zheng S, Tan Y, Takagi H (2015) Eﬀectiveness of approximation strategy
in surrogate-assisted ﬁreworks algorithm. Int J Mach Learn Cybern 6(5):795–810
16. Ingu T, Takagi H (1999) Accelerating a ga convergence by ﬁtting a single-peak
function. In: FUZZ-IEEE’99. 1999 IEEE international fuzzy systems. conference
proceedings, vol 3. IEEE, pp 1415–1420
17. Witkin A (1984) Scale-space ﬁltering: a new approach to multi-scale description.
In: ICASSP’84. IEEE international conference on acoustics, speech, and signal
processing. vol 9, IEEE, pp 150–153
18. Pei Y, Takagi H (2011) Comparative evaluations of evolutionary computation with
elite obtained in reduced dimensional spaces. In: 2011 third international confer-
ence on intelligent networking and collaborative systems. IEEE, pp 35–40
19. Pei Y, Takagi H (2011) Accelerating evolutionary computation with elite obtained
in projected one-dimensional spaces. In: 2011 ﬁfth international conference on
genetic and evolutionary computing. IEEE, pp 89–92
20. Storn R, Price K (1997) Diﬀerential evolution-a simple and eﬃcient heuristic for
global optimization over continuous spaces. J Glob Optim 11(4):341–359
21. Cooley JW, Tukey JW (1965) An algorithm for the machine calculation of complex
fourier series. Math Comput 19(90):297–301
22. Pei Y, Takagi H (2012) Fourier analysis of the ﬁtness landscape for evolutionary
search acceleration. In: 2012 IEEE congress on evolutionary computation. IEEE,
pp 1–7

Trends on Fitness Landscape Analysis in Evolutionary Computation
99
23. Pei Y, Takagi H (2012) Comparative study on ﬁtness landscape approximation
with fourier transform. In: 2012 sixth international conference on genetic and evo-
lutionary computing. IEEE, pp 400–403
24. Murata N, Nishii R, Takagi H, Pei Y (2015) Analytical estimation of the conver-
gence point of populations. In: 2015 IEEE congress on evolutionary computation
(CEC). IEEE, pp 2619–2624
25. Pei Y, Yu J, Takagi H (2019) Search acceleration of evolutionary multi-objective
optimization using an estimated convergence point. Mathematics 7(2):129
26. Yu J, Li Y, Pei Y, Takagi H (2019) Accelerating evolutionary computation using
a convergence point estimated by weighted moving vectors. Complex Intell Syst,
pp 1–11

Chapter 5
Lion Algorithm and Its Applications
B. R. Rajakumar(&)
Research and Development Unit, Resbee Info Technologies, Thuckalay, India
rajakumar.br01@gmail.com
1
Introduction
Nature-inspired algorithms are prominent techniques that take the principles from
nature’s theory of evolution, behavior, and characteristics. These nature-inspired
algorithms mostly follow metaheuristic principles. A metaheuristic is a sophisticated
technique, which is designed to provide quick but near optimal solutions for a high-
complex computing problem. Metaheuristics take sample of solutions from large pool
of possible solutions. These algorithms make limited assumptions on the problem
model to search for the potential solutions. Few nature-inspired metaheuristic algo-
rithms include Genetic Bee Colony Algorithm (GBC) [1], Fish Swarm Algorithm
(FSA) [2], Cat Swarm Optimization (CSO) [3], Whale Optimization Algorithm
(WOA) [4], Artiﬁcial Algae Algorithm (AAA) [5], Elephant Search Algorithm
(ESA) [6], Chicken Swarm Optimization Algorithm (CSOA) [7], Moth Flame Opti-
mization (MFO) [8], Grey Wolf Optimization (GWO) [9], and other optimization
algorithms [10–14].
LA is a recent nature-inspired optimization algorithm introduced in the year 2012
[15]. It is inspired from the social behavior of lion. Then, it is upgraded to a new
version in the year 2014 [16] and is used as the optimization algorithm for many
applications [17–21]. This algorithm is mainly compacted for solving the optimization
problems using two main operators, namely territorial defense and territorial takeover
[22]. For the past 6 years, the algorithm makes its successful journey on solving many
of the complex optimization problems under different applications like clustering [17],
VANET [23], text classiﬁcation [24], and so on. More positive results have been
encountered by this algorithm, which directly proves its future scope on upcoming
research works.
The main theme of the chapter is to discuss the LA in detail from its development,
its variants, performance on benchmark optimization problems and recent applications.
Accordingly, Sect. 2 of this chapter discusses the social behavior of lions and the
interpretation of its behavior to LA. Section 3 brieﬂy explains the LA, whereas Sect. 4
explains the optimization procedures of the LA with respect to the problem model.
Sections 5 and 6 list out the variants of LA and notable applications, respectively.
Section 7 presents the comparative performance of the LA for different test functions,
such as benchmark functions, large-scale problems, and engineering design problems.
Section 8 concludes with the reason behind the performance of the LA and gives
directions for further research on the topic.
© Springer Nature Singapore Pte Ltd. 2020
M. Khosravy et al. (eds.), Frontier Applications of Nature Inspired Computation,
Springer Tracts in Nature-Inspired Computing,
https://doi.org/10.1007/978-981-15-2133-1_5

2
Inspiration and Interpretation
2.1
Social Behavior of Lions
Apart from other cat species, lions endure a fascinating social behavior/system that is
referred as pride, to reinforce their own species on each generation. In general, 1–3 lion
pairs are included within the pride, where the tenant females give birth to offspring by
attending the males. A territory (an area) with peaceful interactions is shared by them.
This territory is ruled by the dominating lion, frequently referred as territorial lion, by
combating against other offensive animals that also involves the nomadic lions. The
territorial defense goes on until the cub reaches its adulthood, perhaps about 2–4 years.
On this gap, the nomadic lions made an attempt to attack the pride. The nomadic lion
and pride frequently ﬁght for their survival, called as territorial defense. The nomadic
lion gets defeated by the coalition among the lions, which are in pride. On the other
hand, when the nomadic lion wins, then the defeated one can be chased out or killed by
them. Then, the nomadic lion takes the position of pride and become the territorial lion.
After that, the cubs of the defeated lion will be killed and the lioness is derived to
estrus. Now, the copulation starts among the new territorial lion and lioness, in which
new offspring is generated. This system repeats till the territory cubs reach their
adulthood.
After the cubs get matured, they take over the territorial lion and if they veriﬁed as
stronger, the territorial takeover occurs. Similar to the territorial defense, the pride of
wholly grown cubs kills or chase out the territorial laggard lion along with their cubs
and give birth to new cubs by copulating with the pride lioness [25].
2.2
Interpretation
The algorithmic interpretation is explained as follows:
• The solution indicates the territorial lion in the LA, whereas the random solution is
the nomadic lion.
• The solution has to be stronger to ﬁght against the random solution.
• The weak solution deﬁnes the weaker lion or cubs.
• A weak solution is either eliminated from the solution pool or chased out from the
solution pool, after ample number of trails to generate cub.
• Successful solution is the succeeded lion in territorial defense of territorial takeover,
whereas the failed solution is mentioned as laggard lion.
• The solution that extracts from successful solution is stronger than the solution that
extracted from failed solution.
Lion Algorithm and Its Applications
101

3
Standard LA
In the year 2012 [15], the basic design of LA was presented as a searching algorithm.
Subsequent to this, this model was reconstructed with some improvements and is given
in [16]. Six processing stages are comprised within this model called, (a) pride gen-
eration, (b) fertility evaluation, (c) mating, (d) territorial defense, (e) territorial takeover,
and (f) termination. It is illustrated in Fig. 1.
The initialization procedure in LA is the Pride generation, which is same as that of
many of the swarm-based and evolution-based optimization algorithms. Mating is
performed as the second process to generate cubs (termed as new lions) from the birth
pride, which undergoes periodic fertility evaluation. This is considered as the note-
worthy process among the entire processing stage. The exceptional process from other
optimizations algorithms is discovered to be the territorial defense and territorial
takeover that mimics the social characteristics of the pride. These two processes are
accounted as the major function to direct the algorithm in the searching process and so
to ﬁnd the optimal solution. The termination criteria of LA depend on the problem
model and therefore that might be processed on the basis of gained solution’s opti-
mality or on a count of iterations/generations. The stepwise operation of standard LA is
explained by the pseudo-code given in Algorithm 1.
The performance of the LA is evaluated by conducting four different test suites. LA
is originated for large-scale and benchmark bilinear systems, which is in progress from
the year 2014. The major four processes in the LA, namely (a) pride generation,
(b) mating, (c) territorial defense, and (d) territorial takeover, are described in detail in
reference to an objective model in the following Sections.
Algorithm 1: Pseudo-code of standard LA [16]
Step No.
Processes
1
Initiate Xmale, Xfemale and Xnomad
1
2
Evaluate f ðXmaleÞ, f ðXfemaleÞ and f ðXnomad
1
Þ
3
Assign f ref ¼ f ðXmaleÞ and Ng ¼ 0
4
Store Xmale as well as f ðXmaleÞ
5
Carry out fertility evaluation
6
Carry out mating and form cubpool
7
Carry out gender clustering; Obtain Xm
cub and Xf
cub
8
Initiate Acub as zero
9
Implement the cub growth function
10
Execute territorial defense; if the result of defense is 0 move to step 4
11
If Acub\Amax move to step 9
12
Carry out territorial takeover and gain updated Xmale and Xfemale
13
Increment Ng by one
14
If the stopping criteria (Ng reaches maximum) did not met, move to step 4
15
Terminate and return Xmale as optimal solution
102
B. R. Rajakumar

4
Problem Model and LA Optimization
Let us assume the objective model to be minimized as given in Eq. (1).
Xoptimal ¼
arg min
xi2ðxmin
i
;xmax
i
Þ
f ðx1; x2; . . .; xnÞ;
n  1
ð1Þ
In Eq. (1), f ðÞ is the unimodal or multimodal with few or many modes for that the
size of the solution space is stated as <n, here < is the real numbers, xi : i ¼ 1; 2. . .; n
deﬁnes the solution variable in ith position and the solution vector dimension is
depicted as n, at ith position, the maximum and minimum limits of solution variable is
Step 1: Pride generation
Fertility evaluation 
Step 2: Mating 
Cub growth 
Survival fight 
New territorial 
lion  
Is nomadic 
lion defeated
Update nomad coalition   
Is cub matured
Is cub qualified 
to takeover pride
Is maximum 
generation gained
Terminate 
Step3: Territorial defense
Step 4: Territorial 
take over
Yes
Yes
Yes
No
No
No
No
Yes
Fig. 1. Flowchart presentation of LA [16]
Lion Algorithm and Its Applications
103

denoted by xmax
i
and xmin
i
, correspondingly. Equation (2) provides the size of the
solution space ff ðÞ and the optimal solution is deﬁned with Xoptimal and is stated in
Eq. (3).
<n ¼ P
n
i¼1ðxmin
i
 xmax
i
Þ
ð2Þ
Xoptimal ¼ X : f ðXÞ\f X0 X0 6¼ X; x0
i

2 xmin
i
; xmax
i




ð3Þ
In
this,
X
is
referred
to
be
the
solution
vector
and
is
explained
as
X ¼ ½x1; x2; . . .; xn. The optimization function that needs to resolve as a minimization
function is shown in Eq. (1).
• Pride Generation
On considering Eq. (1), the initiation of pride is made by territorial lion, lioness, and
nomadic lion as Xmale, Xfemale and nomadic lion Xnomad, respectively. The pride gen-
eration process discusses the nomadic lion’s generation. The solution vector and the
lion formulation are mostly similar. The vector element of Xnomad, Xmale and Xfemale is
stated as xnomad
l
, xmale
l
and xfemale
l
are accounted as random integers having maximum
and minimum limits it is provided in Eq. (5). When n [ 1, where l ¼ 1; 2. . .; L, the
Lion’s length L is expressed as per Eq. (4).
L ¼
n;
n [ 1
m;
otherwise

ð4Þ
Here, n and m are integers for deciding the lion’s length. When n ¼ 1, the search
with binary encoded lion is evolved in the algorithm, and hence, the generation of
vector elements may be either as 0 or 1.
gðxlÞ 2 xmin
l
; xmax
l


ð5Þ
m%2 ¼ 0
ð6Þ
In which,
gðxlÞ ¼
X
L
l¼1
xl2
L
2l
ð
Þ
ð7Þ
Equations (5) and (7) ensure that the generated lion is in binary format within the
bounds. Equation (6) guarantees the number of bits to be used to generate equal
number of real and decimal fractions of the solution so that the even number is ensured.
One among the two nomadic lion positions are ﬁlled by the produced Xnomad, because
of the assumption of two nomadic lions attempt to capture the territory. Only during the
territorial defense process, the other nomadic lion can be initiated. Therefore, the
position stays null up to that time and Xnomad can be denoted as Xnomad
1
.
104
B. R. Rajakumar

• Fertility Evaluation
Each territorial lion and lioness become infertile and started to age in the processing
steps of LA, whereby the lion are changed as laggards on territorial takeover or survival
ﬁghts. Xmale and Xfemale has either reached the local or global optima from where the
better solution is not obtained, if they become saturated in accordance with their ﬁtness.
Fertility evaluation has helped to pass over from the local optima solution. This process
assumes the Xmale as laggard and Lr is its laggardness rate and is increased by 1, when
f Xmale


is larger than reference ﬁtness f ref. Territorial defense is urged, while Lr goes
beyond its maximum limits Lmax
r
. After crossover, the fertility of Xfemale is guaranteed
by the sterility rate Sr and is increased by a unit step. The updating of Xfemale is
happened as per Eq. (8), when Sr surpasses the tolerance rate Smax
r
where, Smax
r
is set as
three [16]. In accordance with the improvement, mating process is evolved, when the
updated female Xfemale þ is provided as Xfemale. On the other hand, the updating process
goes on till the count of female generation gc attains gmax
c
where gmax
c
is set as ten. All
through the updating process, Xfemale is considered to be fertile to generate better cubs,
when there exist no Xfemale þ to substitute Xfemale [16].
xfemale þ
l
¼
xfemale þ
k
if l ¼ k
xfemale
l
otherwise

ð8Þ
xfemale þ
k
¼ min xmax
k
; maxðxmin
k
; rkÞ


ð9Þ
rk ¼ xfemale
k
þ ð0:1r2  0:05Þ xmale
k
 r1xfemale
k




ð10Þ
In this, lth and kth vector elements of Xfemale þ is denoted as xfemale þ
l
and xfemale þ
k
,
correspondingly. The random integer that produced under the intervals [1, L] is deﬁned
as k, the female update position is r, and the random integer is depicted as r1 and r2
that is produced within the range [0,1].
• Mating
The mating process in LA constitutes crossover, mutation, and gender clustering.
Various research works have been evolved in the literature on crossover and mutation
and their requirement on evolutionary algorithms [26–31], Xmale and Xfemale generates
the cubs, which acts as solutions that extracted from the elements of Xmale and Xfemale,
by performing this crossover and mutation process. In this, the maximum natural
littering rate is followed, that is stated as four cubs are generated by crossover process
in a lioness pregnancy [32]. Figure 2 symbolizes the proposed crossover operation on
producing one cub. Each cub is produced by varying the crossover mask B, i.e.
Xcubs p
ð Þ is gained by using pth mask Bp. The produced four cubs then undergo
mutation to generate new four cubs. Therefore, the cubs gained from crossover are
denoted by Xcubs and the cubs attained from mutation are speciﬁed as Xnew.
Lion Algorithm and Its Applications
105

The cub pool is occupied by this eight cubs and the gender clustering is performed
on these cub pools for ﬁnalizing Xm
cubs and Xf
cubs. The cub growth function is
applied to Xm
cubs and Xf
cubs to achieve the self-update [16].
• Lion Operators
Territorial defense [15, 16] provides extensive searching on solution space as well as
directs the algorithm to avoid from local optimal point and also identiﬁes the different
solutions having same ﬁtness. The order of territorial defense is given as producing
nomad coalition [33, 34], survival ﬁght [35], after that the pride and nomad coalition
updates. On applying the winner-take-all approach [22], the simpliﬁcation of nomad
coalition is made for identifying Xe
nomad. Moreover, Xe
nomad is selected, only if it
meets Eqs. (11) to (13).
f Xenomad


\f Xmale


ð11Þ
f Xenomad


\f Xm
cub


ð12Þ
f Xenomad


\f Xf
cub


ð13Þ
Only after defeating Xmale, the pride can be updated, while after the defeat of
Xe
nomad, the nomad coalition gets updated. The process of substituting Xmale by
Xe
nomad is termed as pride update, while nomad coalition update deﬁnes the choosing
female
X
1
2
3
...
L
( )
1
0
0
1
1
...
Mating Lions
B
Complement
Crossover mask
Hadamard Product
Crossover points
1
2
3
...
L
Crossover 
cub
X
1
2
3
...
L
( )
0
1
1
0
0
...
male
X
B
1
2
3
...
L
1
2
3
...
L
Fig. 2. Crossover operation of LA [16]
106
B. R. Rajakumar

of only one Xnomad that poses Enomad higher than or equivalent to the unity exponential.
Concurrently, during the subsequent territorial defense, the other position will be ﬁlled
up [16].
When Xm
cub as well as Xf
cub attains maturity, territorial takeover [15] happens to
get updated Xmale and Xfemale. The maturity is given as the age of cub that goes beyond
the maximum limit for cub maturity Amax.
• Termination
The termination of algorithm is executed only if any one of the following two termi-
nation criteria is satisﬁed.
Ng [ Nmax
g
ð14Þ
f Xmale


 f Xoptimal



  eT
ð15Þ
Here, the count of generations is Ng. Initially, it is set to zero and is then increased
by one while the territorial takeover happens, the maximum count of generations and
error threshold is depicted by Nmax
g
and eT, correspondingly and the absolute difference
is expressed as j j.
5
Variants of LA
LA has gained widespread attention from the researchers around the world. The
researchers have also worked on customizing the algorithm as per the optimization
problem of different applications. Some of the notable variants of the LA in use are
discussed below.
Fractional LA (FLA) [36, 37]: FLA exploits the LA operators such as territorial
defense and territorial takeover. However, the adopted mutation operation for esti-
mating the optimal centroid is modiﬁed with fractional theory. Similar to LA, crossover
and mutation are done within the clustering bounds. The two operators develop new
centroids that can cluster the datapoints in a better way than the centroids from parent
solutions.
Adaptive Dynamic Directive Operative Fractional Lion (ADDOFL) [17]: It is
updated with the solutions based on the fractional LA [36], but it introduces a newly
designed ﬁtness function for better evaluation of the male and female lions. As the
female fertility evaluation plays crucial role in updating the female lion, ADDOFL
exploits dynamic directive operative searching algorithm.
In [38], the standard LA is modiﬁed using three modiﬁcation strategies with the aid
of greedy search algorithm. The three alternative versions of the lion’s algorithm are
M1, M2, and M3. The M1 has come out with modiﬁed territorial takeover, while M2
has modiﬁcation in the territorial defense. M3 uses the modiﬁed version of both ter-
ritorial defense and takeover.
Lion Algorithm and Its Applications
107

The modiﬁed LA [23] has come with updated mutation process to handle the
routing problem. Similar to standard model, the crossover and the mutation processes
are carried out. The homogeneous mutation is carried out to generate new cubs from
the old cubs on the basis of a deﬁned mutation rate.
Lion fuzzy neural network (LFNN) [24]: Here, the LA is integrated with the Back-
Propagation Algorithm called as BPLion with fuzzy bounding. The algorithm is used
for incremental learning of fuzzy neural network to construct LFNN.
Niche immunity LA [18]: Niche immunity concept is introduced to LA to limit the
generation of duplicate solutions as well as to enhance the population diversity. The
algorithm is used as a training algorithm for convolutional neural network that forecasts
short term load for electric vehicle charging station.
Adaptive Fractional Lion TOpology-HIding Multipath Routing Protocol (AFL-
TOHIP) [39]: Here, the processing steps of LA is used, but the primary difference is
that the updating in AFL is adaptively performed based on a fractional derivative. To
ensure the number of nomadic and male lions to be equal to each other, fractional
calculus is conducted by the order of fractional derivative. The fractional derivative
takes the value between the interval [0, 1] in the updating process.
6
Notable Applications
The original version of the LA was initially applied to solve the nonlinear system
identiﬁcation process [16]. Since then, other researchers have used variants and hybrid
LAs for diverse applications such as WSN [36], VANET [23], and so on. Hence, we
ﬁrst discuss the use of LA in system identiﬁcation process followed by other
applications.
6.1
System Identiﬁcation
Nonlinear system identiﬁcation process speciﬁcally bilinear system identiﬁcation
process takes advantage of global optimization algorithms for enhancing the accuracy
in the system identiﬁcation process. Hence, the LA is applied in the bilinear system
identiﬁcation to achieve the precise system characteristics [16]. The system identiﬁ-
cation performance of LA is observed by determining standard bilinear model coefﬁ-
cients to deﬁne a nonlinear rationale digital benchmark system.
Bilinear Series Model: It is one of the nonlinear models is termed as bilinear model
to synthesize several real-time systems [40–46]. When a time series input is given as
un : n ¼ 0; 1; . . .; T  1, Eq. (16) provides the output yn from a bilinear series model,
where the kernel sets that are to be identiﬁed is stated as
a1; a2; . . .; aN; b0;
f
b1; . . .; bM; c0;1; c0;2; . . .; cM;Ng.
yn ¼
X
N
k¼1
akynk þ
X
M
k¼0
bkunk þ
X
M
k1¼0
X
N
k2¼0
ck1k21unk1ynk2
ð16Þ
108
B. R. Rajakumar

In this, the count of past outputs and inputs are denoted by N and M, respectively.
The kernel set cardinality K
j j is derived as per Eq. (17).
K
j j ¼ 1 þ N½M þ 2 þ M
ð17Þ
System Identiﬁcation Procedure: Figure 2 speciﬁes the system identiﬁcation model
by means of LA. It understands that the LA adjusts the kernel models on the basis of
variation in the output between the bilinear model and the actual system. Therefore, the
procedure of system identiﬁcation as a minimization problem can be designed using
Eq. (18).
Kopt ¼ arg min
K
1
T
X
T1
n¼0
½An  yn


ð18Þ
Here, the optimal kernel model set is deﬁned as Kopt, and An depicts the actual
system to be designed. LA made an effort to resolve the minimization issues and
identiﬁes the optimal kernel models (Fig. 3).
6.2
Other Applications
Data clustering: Clustering is the technique used to partition the data by grouping
homogenous data into one cluster and separating heterogeneous data in inter-
clusters. It is a process of selecting cluster centroid, which represents the entire
cluster. It can be solved as an optimization problem. A variant of LA is reported in
Lion Algorithm (LA)
Bilinear Series Model
Actual System
yn-1
yn-2
yn-N
un-1
un-2
un-M
a2
a1
cM,N
un
Kernel 
Model
Σ
yn
An
+
-
...
M-delay system
z-1
z-2
z-M
N-delay system
...
z-1
z-2
z-N
Fig. 3. Bilinear system identiﬁcation process using LA [16]
Lion Algorithm and Its Applications
109

the literature [17] called as Adaptive Dynamic Directive Operative Fractional Lion
(ADDOFL) algorithm to determine the centroids that can cluster the data more
effectively.
Wireless sensor network (WSN): In WSN, hierarchical routing process involves
clustering of sensor nodes and selection of cluster heads, which are the head of the
sensor clusters. Cluster head selection is a crucial step, because it decides the
network lifetime and energy efﬁciency. Fractional lion (FLION) [36] handles the
cluster head selection problem and hence increased the network lifetime.
Feature selection: In data processing, feature selection is a process of determining
the optimal subset of features in accordance with a given evaluation criteria and
further it reduces the count of unnecessary features. In order to attain the precise
classiﬁcation accuracy, the optimal selection of features is must. This problem has
been successfully handled by LA with the inclusion of greedy search process in the
territorial defense [38].
MANET: Mobile Ad hoc Network (MANET) is the best-known factor that used for
data transmission. In MANET, best optimal routing path selection is considered to
be the main challenge. The modiﬁed LA named fractional LA is incorporated within
the TOHIP (Topology-Hiding Multipath Routing Protocol) protocol and is named
as AFL-TOHIP, for improving the solution search [39]. A programming model is
constructed of the basis of hybrid optimization algorithm, called M-LionWhale,
which incorporates the LA into Whale Optimization Algorithm (WOA) for secure
routing [47].
VANET: Vehicular Ad hoc Networks (VANETs) are said to be a part of Mobile Ad
hoc Networks (MANETs) that provides reliable road safety. Since the routing
process considers multiple parameters that include Quality of Service (QoS) con-
straints, congestion parameters and many more, an optimization algorithm is the
best solution. Since the LA has been proven for benchmark problems, it has been
used to solve route discovery problem in VANET [23].
Text classiﬁcation: Text classiﬁcation is one of the text mining tasks that categorize
the documents based on its characteristics and user requirements. The main prob-
lems that exist in the text classiﬁcation are the dimensionality of search space. It
directly suffers from the curse of dimensionality. In this, the optimization concept is
involved by selecting the optimal weights of fuzzy neural network using the LA
[24].
Social network analysis: Social networks are information network in which people
can share common interest and interacts with each other. The community detection
is considered as the optimization problem in this social network analysis. Hence,
LA is used to determine the optimal number of user communities persist in the
social networks [18].
110
B. R. Rajakumar

7
Test Function
7.1
Test Case 1
In test case 1, 23 unimodal and multimodal benchmark functions are considered.
Various researchers have broadly used these standard functions in order to access the
optimization algorithm’s performance. The comparison on the performance of LA in
test case 1 is implemented using two groups. Group 1 has the conventional evolu-
tionary computation models, while the renowned optimization algorithms are in group
2, as given in Table 1. In order to make certain the reliability of the gained outcomes,
this LA executes 1000 times [48] and the statistical measures are evolved and sym-
bolized in Table 2. The statistical outcomes for 50 executions on multimodal bench-
mark functions with few local minima are delineated.
In Table 2, the outcome of the LA has attained the betterment over the other four
algorithms, while resolving Schwefel 2.21 and step functions. Instead, the LA is not
much useful in solving the rosenbrock and sphere functions, but it is major in resolving
the quartic function. Conversely, it is found that the LA is best known to solve Ras-
trigin, Ackley, and penalized 2 functions than any other evolutionary computation
algorithms. Similarly, the global minima of sixhump, branin and Hartman 3 functions
are determined by this all used algorithms (includes LA) and therefore attains the rank
as 1.
LA is best known on solving the foxholes function, while comparing over other
algorithms. However, the rest of the multimodal functions with few local minima is not
dominated by LA, it achieves better solution when solving Hartman 6 and shekel 7
functions than two algorithms, while solving shekel 10 function than three algorithms
and while solving Kowalik function than four algorithms.
Table 1. Grouping of conventional algorithms used for comparison
Evolutionary algorithms (Group 1)
Popular optimization
algorithms (Group 2)
Classical Evolutionary Programming (CEP)
Genetic Algorithm (GA)
Fast Evolutionary Programming (FEP)
Particle Swarm Optimization
(PSO)
Canonical Evolutionary Strategies (CES)
Artiﬁcial Bee Colony
Algorithm (ABC)
Fast Evolutionary Strategies (FES)
Group Search Optimizer (GSO)
Covariance Matrix Adaptation-Evolution Strategy (CMA-
ES)
Evolutionary Strategies Learned with Automatic
Termination criteria (ESLAT)
Lion Algorithm and Its Applications
111

Table 2. Performance of LA for test case 1
Function
LA versus Group 1
LA versus Group 2
Mean (SD)
R
Mean (SD)
R
(a) Unimodal functions
Sphere
5.45  10−3 (1.08  10−3)
7
5.45  10−3 (1.09  10−3)
4
Schwefel 2.22
3.7  10−3 (3.1  10−3)
4
3.74  10−3 (3.12  10−3)
4
Schwefel 1.2
2.1  10−2 (8.3  10−3)
5
2.16  10−2 (8.3 8  10−3)
3
Schwefel 2.21
4.21  10−2 (4.48  10−2)
3
4.21  10−2 (4.48  10−2)
1
Rosenbrock
56.77 (45.28)
7
56.77 (45.28)
4
Step
4.64  10−3 (1.20  10−3)
3
4.64  10−3y (1.21  10−3)
2
Quatric
6.73  10−11 (8.50  10−12)
1
6.73  10−11 (8.50  10−12)
1
Average rank
4.29
2.71
Final rank
5
3
(b) Multimodal functions with many local minima
Schwefel
−12559.52(34.02)
2
−12559.52(34.02)
4
Rastrigin
1.85  10−6 (4.07  10−6)
1
1.85  10−6 (4.07  10−6)
1
Ackley
3.72  10−3 (4.43  10−3)
1
3.72  10−3 (4.43  10−3)
4
Griewank
7.51  10−2 (5.98  10−2)
5
7.51  10−2 (5.98  10−2)
3
Penalized
2.3 (2.89)
7
2.3 (2.89)
5
Penalized 2
2.65  10−5 (6.41  10−5)
1
2.65  10−5 (6.41  10−5)
1
Average rank
2.83
3
Final rank
2
3
(c) Multimodal functions with few local minima
Foxholes
1 (1.12  10−15)
1
1 (1.12  10−15)
3
Kowalik
6.09  10−4 (2.17  10−4)
3
6.09  10−4 (2.17  10−4)
3
Sixhump
−1.03 (0)
1
−1.03 (0)
1
Branin
0.4 (4.49  10−16)
1
0.4 (4.49  10−16)
1
Goldstein-price
3 (0)
1
3 (0)
1
Hartman 3
−3.86 (4.49  10−15)
1
−3.86 (4.49  10−15)
1
Hartman 6
−3.26 (5.55  10−2)
5
−3.26 (5.55  10−2)
3
Shekel 5
−6.47 (2.36)
4
−6.47 (2.36)
3
Shekel 7
−6.65 (2.29)
5
−6.65 (2.29)
3
Shekel 10
−7.82 (2.49)
4
−7.82 (2.49)
3
Average rank
2.6
2.2
Final rank
3
3
112
B. R. Rajakumar

The overall performance on the basis of LA’s rank (R) is represented beside the
mean value along with the ﬁnal ranks while solving the test suite. Table 2 shows that
the LA outperforms most of the conventional algorithms.
7.2
Test Case 2
Test case 2 has 32 benchmark functions. The performance of the LA is compared over
the swarm algorithms and the results are analyzed. Further, three renowned evolu-
tionary algorithms are also used and compared with the LA. Every algorithm gains
different ranks on determining the optimal solution for the 42 benchmark functions.
The mean performance of LA achieves second position when comparing with other
swarm algorithms; still the performance comes up with low deviation. This expresses
the lead of the LA over the swarm intelligence.
7.3
Test Case 3
The investigation on LA in test case 3 is made by 17 benchmark functions, which have
been broadly utilized by several researchers to investigate the performance of opti-
mization algorithms. This test case takes these functions in large scale, i.e., the solution
dimension is given as 1000, as of its higher signiﬁcance.
From the results, the LA attains the top position in managing the large-scale
optimization problems. Due to multiple updating stages, the LA provides the updated
solution in all the solution variables to search in the large solution space.
7.4
Test Case 4
Test case 4 has broadly exhibited in the engineering problems like pressure vessel
design, tension/compression spring design, welded beam design, three-bar truss design,
and gear train design. From [47], the reference for problem model is taken. In this also,
the comparative analysis is formulated against the evolutionary algorithm, swarm
algorithm and, nature-inspired (optimization) algorithm. Every algorithm undergoes 20
test runs and their statistical results are shown in Table 3.
From Table 3, it is depicted that the LA provides better performance over the
swarm algorithms in solving welded beam, pressure vessel design, and gear train
design, whereas in solving the compression/tension spring design and three-bar truss
design, it attains the second position. On the other hand, while comparing with the
evolutionary and optimization algorithms, it achieves betterment in solving three-bar
truss design, gear train design, and welded beam design. The overall performance has
revealed that the LA outperforms the other algorithms by maintaining the maximum
tradeoff among the mean performance and standard deviation. Therefore, it stays in the
ﬁrst rank of all other algorithms.
Lion Algorithm and Its Applications
113

Table 3. Overall performance of LA for the three test cases
Function
Test case 2
Test case 3
Test case 4
Mean (SD)
R
Mean (SD)
R
Mean (SD)
R
Ackley
0
1
0
1
0
1
Beale
6.98 e−8
5
1.6 e−7
5
6.98 e−8
1
Bird
106.76
1
6.1 e−10
3
106.765
1
Booth
0
1
0
1
0
1
Bukin 4
0
1
0
1
0
1
Bukin 6
0
1
0
1
0
1
Carromtable
24.16
1
9 e−14
3
24.1568
1
Chichinadze
42.94
1
3.6 e−15
2
42.9444
1
Cross
4.85 e−5
1
4.8 e−21
1
4.85 e−5
1
Crossin tray
2.06
1
0
1
2.06261
1
Crosslegtable
1
1
0
1
1
1
crownedcross
1 e−4
1
0
1
0.0001
1
Cube
59.92
3
44.7719
5
59.9248
1
Easom
0.8
8
0
1
0.80002
3
Egg holder
6.8 e−3
1
863.7747
6
6877.68
2
Giunta
0.06447
1
1.45 e−12
6
0.06447
1
Goldsteinprice
3
1
0
1
3
1
Griewank
0
1
0
1
0
1
Helical valley
1.23
6
2.767411
8
1.237624
2
Himmeelblau
0
1
0
1
0
1
holder table
19.2085
1
6.78 e−11
2
19.2085
1
Leon
0
1
0
1
0
1
Levi
1.35 e−31
1
0
1
1.35 e−31
1
Matyas
0
1
0
1
0
1
Mccormick
1.913
1
1.96 e−11
6
1.91322
1
Modschaffer1
0
1
0
1
0
1
Modschaffer2
1.52 e−4
7
0.000339
8
0.000152
1
Modschaffer3
114.66
10
0.01794
10
0.011466
4
Modschaffer4
0.295745
10
0.005382
7
0.295745
4
Penholder
0.96
1
6.73 e−12
6
0.96353
1
Powell
144.740
9
323.6487
10
0
Rastrigin
0
1
0
1
0
1
Rosenbrock
1.8 e2
5
112.9015
7
0
Schweffel
837.966
1
4.75 e−07
7
837.966
1
Sinenvsin
0.410484
1
0.514455
10
0.410484
1
Sixhumpcamel
1.03
1
1.13 e−11
5
−1.03163
1
Styblinkskitang
391.662
1
3.11 e−07
2
391.662
1
Test Tube holder
10.8591
8
0.029416
6
10.8591
3
Three hump camel
0
1
0
1
0
1
(continued)
114
B. R. Rajakumar

8
Discussion and Conclusion
This chapter has explained the LA from its inspiration to the processing steps that solve
diverse optimization problems such as unimodal, multimodal and large-scale opti-
mization problems. The reported performance and the applications of LA and its
variants have showcased the LA as a promising solution for the considered types of
optimization problems.
8.1
Algorithmic Efﬁciency
As per biological inspiration, the lion’s unique social behavior has made the animal
strongest among the wild animals. The LA mimics the entire behavior and so it can be
interpreted that the algorithm can produce the best of the possible solutions. In the
perspective of algorithm operation, the LA searches for optimal solution with a perfect
blend of all searching procedures such as exploration (territorial defense), exploitation
(territorial takeover), randomization (nomad generation), selection (survival ﬁght),
abandonment (fertility and sterility check), inter-information (crossover), and intra-
information (mutation) updates. The survival ﬁght is designed in such a way that the
best solutions ﬁght against each other to ﬁnd the dominant one, while the abandonment
is made after considering the tradeoff between the saturation of the updating with
respect to the base solution (male/female lion) and generation of new ﬁt solutions
(takeover). Since the algorithm generates only three initial solutions, evaluating more
random solutions (initial solutions) are reduced to three. Hence, the evaluation fre-
quency can be used for strong solutions and so the updating can be made effective. All
these stages and principles have made LA better than the conventional algorithms.
8.2
Future Scope
The optimization problems are diverse and can be found in all the engineering as well
as non-engineering computational applications. So, the LA can ﬁnd wide range of
applications. Few engineering applications include security management, civil appli-
cations, wind farm installation, controller design, and so on. Also, the non-engineering
ﬁelds like drug measurements, radiation therapy, medical imaging, and mathematical
optimization, the optimization problems are applicable. The algorithm can also be
subjected to further research to study the central tendency of the algorithm, impact of
Table 3. (continued)
Function
Test case 2
Test case 3
Test case 4
Mean (SD)
R
Mean (SD)
R
Mean (SD)
R
Trigonometric Function
2 e−4
2
0.000355
2
0.000175
3
Wood
25.59
9
36.14519
9
25.57872
2
Zettl
3.7 e−3
1
0
1
−0.00379
1
Mean rank
2.66
3.666667
1.309524
Final rank
2
1
1
Lion Algorithm and Its Applications
115

quality of initial solutions (male, female, and nomad lions) and other parameters in the
performance of the algorithm. Moreover, the algorithm can be further developed to
handle the multi-objective optimization problem without transforming the objectives or
constraints into penalty functions.
References
1. Alshamlan HM, Badr GH, Alohali YA (2015) Genetic Bee Colony (GBC) algorithm: a new
gene selection method for microarray cancer classiﬁcation. Comput Biol Chem 56:49–60.
https://doi.org/10.1016/j.compbiolchem.2015.03.001
2. Neshat M, Sepidnam G, Sargolzaei M, Toosi AN (2012) Artiﬁcial ﬁsh swarm algorithm: a
survey of the state-of-the-art, hybridization, combinatorial and indicative applications. Artif
Intell Rev 42(4):965–997. https://doi.org/10.1007/s10462-012-9342-2
3. Chu SC, Tsai P, Pan JS (2006) Cat swarm optimization. In: Yang Q, Webb G (eds) PRICAI
2006: trends in artiﬁcial intelligence. PRICAI 2006. Lecture notes in computer science, vol
4099. Springer, Berlin, Heidelberg
4. Mirjalili S, Lewis A (2016) The whale optimization algorithm. Adv Eng Softw 95:51–67.
https://doi.org/10.1016/j.advengsoft.2016.01.008
5. Uymaz SA, Tezel G, Yel E (2015) Artiﬁcial Algae Algorithm (AAA) for nonlinear global
optimization. Appl Soft Comput 31:153–171. https://doi.org/10.1016/j.asoc.2015.03.003
6. Deb S, Fong S Tian Z (2015) Elephant search algorithm for optimization problems. In: 2015
tenth international conference on digital information management (ICDIM), Jeju, 2015,
pp 249–255. https://doi.org/10.1109/icdim.2015.7381893
7. Meng X, Liu Y, Gao X, Zhang H (2014) A new bio-inspired algorithm: chicken swarm
optimization. In: Tan Y, Shi Y, Coello CAC (eds) Advances in swarm intelligence. ICSI
2014. Lecture notes in computer science, vol 8794. Springer, Cham
8. Mirjalili S (2015) Moth-ﬂame optimization algorithm: A novel nature-inspired heuristic
paradigm. Knowl-Based Syst 89:228–249. https://doi.org/10.1016/j.knosys.2015.07.006
9. Mirjalili S, Mirjalili SM, Lewis A (2014) Grey wolf optimizer. Adv Eng Softw 69:46–61.
https://doi.org/10.1016/j.advengsoft.2013.12.007
10. Dey N (2018) Advancements in applied metaheuristic computing. Int J Appl Metaheuristic
Comput 7(2):16–38. https://doi.org/10.4018/IJAMC.2016040102
11. Gupta N, Patel N, Tiwari BN, Khosravy M (2019) Genetic algorithm based on enhanced
selection and log-scaled mutation technique. 1:730–748. https://doi.org/10.1007/978-3-030-
02686-8_55
12. Singh G, Gupta N, Khosravy M (2015) New crossover operators for real coded genetic
algorithm (RCGA). In: Intelligent informatics and biomedical sciences (ICIIBMS) IEEE,
international conference on robotics and human-computer interaction, Okinawa, Japan,
pp 135–140
13. Gupta N, Patel N, Tiwari BN, Khosravy M (2018) Genetic algorithm based on enhanced
selection and log-scaled mutation technique. Adv Intell Syst Comput 99:730–748. https://
doi.org/10.1007/978-3-030-02686-8_55
14. Gupta N, Khosravy M, Patel N, Sethi IK (2018) Evolutionary optimization based on
biological evolution in plants. Procedia Comput Sci Elsevier 126:146–155
15. Rajakumar BR (2012) The lion’s algorithm: a new nature inspired search algorithm. Second
Int Conf Commun Comput Secur 6:126–135
116
B. R. Rajakumar

16. Rajakumar BR (2014) Lion algorithm for standard and large scale bilinear system
identiﬁcation: a global optimization based on lion’s social behavior. In: 2014 IEEE congress
on evolutionary computation (CEC), pp 2116–2123
17. Chander S, Vijaya P, Dhyani P (2017) Multi kernel and dynamic fractional lion optimization
algorithm for data clustering. Alexandria Eng J 57
18. Li Y, Huang Y, Zhang M (2018) Short-term load forecasting for electric vehicle charging
station based on niche immunity lion algorithm and convolutional neural network. Energies
1253
19. Wagh MB, Gomathi N (2018) Route discovery for vehicular Ad hoc networks using
modiﬁed lion algorithm. Alexandria Eng J 57(4):3075–3087
20. Yazdani M, Jolai F (2016) Lion optimization algorithm (LOA): a nature-inspired
metaheuristic algorithm. J Comput Design Eng 3(1):24–36
21. Chander S, Vijaya P, Dhyani P (2018) Multi kernel and dynamic fractional lion optimization
algorithm for data clustering, Alexandria Eng J 57(1):267–276
22. Boothalingam R (2018) Optimization using lion algorithm: a biological inspiration from
lion’s social behavior. Evol Intel 11(1–2):31–52
23. Wagh MB, Gomathi N (2018) Route discovery for vehicular Ad hoc networks using
modiﬁed lion algorithm. Alexandria Eng J 57
24. Ranjan N, Prasad R (2018). LFNN: lion fuzzy neural network-based evolutionary model for
text classiﬁcation using context and sense based features. Appl Soft Comput 71
25. Bauer H, de Iongh HH, Silvestre I (2003) Lion social behaviour in the West and Central
African Savanna belt. Mamm Biol 68(1):239–243
26. Fogel LJ, Owens AJ, Walsh MJ (1966) Artiﬁcial intelligence through simulated evolution.
Wiley Publishing, New York
27. Doerr B, Happ E, Klein C (2012) Crossover can probably be useful in evolutionary
computation. Theor Comput Sci 425:17–33
28. Back T, Hoffmeister F, Schwefel HP (1993) An overview of evolutionary algorithms for
parameter optimization. J Evol Comput 1(1):1–24. (De Jong K (ed), MIT Press, Cambridge)
29. Jong De KA (1975) An analysis of the behavior of a class of genetic adaptive systems.
Doctoral thesis, Department Computer and Communication Sciences, University of
Michigan, Ann Arbor
30. Packer C, Pusey AE (1982) Cooperation and competition within coalitions of male lions: kin
selection or game theory? Nature 296(5859):740–742
31. Packer C, Pusey AE (1983) Male takeovers and female reproductive parameters: A
simulation of oestrous synchrony in lions (Panthera leo)”. Anim Behav 31(2):334–340
32. Packer C, Pusey AE (2016) Divided we fall: cooperation among lions. Sci Am 276:52–59
33. Grinnell J, Packer C, Pusey AE (1995) Cooperation in male lions: kinship, reciprocity or
mutualism? Anim Behav 49(1):95–105
34. Packer C, Pusey AE (1982) Cooperation and competition within coalition of male lions: kin
selection or game theory. Macmillan J 296(5859):740–742
35. LotﬁE, Akbarzadeh-T MR (2016) A winner-take-all approach to emotional neural networks
with universal approximation property. Inform Sci 346:369–388
36. Sirdeshpande N, Udupi V (2017) Fractional lion optimization for cluster head-based routing
protocol in wireless sensor network. J Franklin Inst 354
37. Satish Chander P, Vijaya Praveen Dhyani (2016) Fractional Lion algorithm-an optimization
algorithm for data clustering. J Comput Sci 12(7):323–340
38. Lin KC, Hung JC, Wei JT (2018) Feature selection with modiﬁed lion’s algorithms and
support vector machine for high-dimensional data. Appl Soft Comput 68
39. Ambekar RK, Kolekar UD (2017) AFL-TOHIP: Adaptive fractional lion optimization to
topology-hiding multi-path routing in mobile Ad hoc network. 727–732
Lion Algorithm and Its Applications
117

40. Schetzmen M (1980) The voltera and winner theories on nonlinear systems. Wiley, New
York
41. Dinga F, Chenb T (2005) Identiﬁcation of Hammerstein nonlinear ARMAX systems.
Automatica 41:1479–1489
42. Hernandez E, Arkun Y (1993) Control of nonlinear systems using polynomial ARMA
models. AIChE J 39(3):446–460
43. Lee TT, Jeng JT (1998) The Chebyshev polynomial-based uniﬁed model neural net-works
for functional approximation. IEEE Trans Syst Man Cybern B 28:925–935
44. Bruni C, DiPillo G, Koch G (1974) Bilinear systems: an appealing class of nearly linear
systems in theory and applications. IEEE Trans Automat Control. AC-19:334–348
45. Kim WK, Billard L, Basawa V (1990) Estimation for the ﬁrst-order diagonal bilinear time
series model. J Time Ser Anal 11(3):215–229
46. Mohler RR, Kolodziej WJ (1980) An overview of bilinear system theory and applications.
IEEE Trans Syst Man Cybern SMC-IO 683–688
47. Chintalapalli RM, Ananthula VR(2018). M-Lionwhale: multi-objective optimization model
for secure routing in mobile Ad-hoc network. IET Commun 12
48. He S, Wu QH, Saunders JR (2009) Group search optimizer: an optimization algorithm
inspired by animal searching behavior. IEEE Trans Evol Comput 13(5):973–990
118
B. R. Rajakumar

A Self-adaptive Nature-Inspired
Procedure for Solving the Quadratic
Assignment Problem
Reza Zamani1 and Mehrdad Amirghasemi2(B)
1 School of Computing and Information Technology, University of Wollongong,
Wollongong, NSW 2522, Australia
reza@uow.edu.au
2 SMART Infrastructure Facility, University of Wollongong, Wolllongong, NSW
2522, Australia
mehrdad@uow.edu.au
1
Introduction
The quadratic assignment problem (QAP) has ﬁrst been introduced in [29] as
the problem of ﬁnding the locations of a set of adjoined economical activities for
incurring a minimum cost. Represented with diﬀerent facilities, these activities
can be placed in diﬀerent locations and create various layouts. The cost asso-
ciated with each layout is deﬁned as a combination of a linear and a quadratic
part. Whereas the linear part is based on considering a speciﬁc cost for placing
each particular facility at a particular location, the quadratic part is based on
considering the ﬂow between every two facilities as well as their distance. The
term quadratic in the name of the problem stems from such a quadratic part.
This paper presents a self-adaptive nature-inspired procedure which includes
a local search exploiting the structure of the QAP through the notion of regular
interchange by using a linear assignment technique. The procedure which is
called self-adaptive facility interchange (SAFI) modiﬁes local optimal solutions
through self-adaptivity and runs a local search on the modiﬁed solutions.
Complex
systems
like
living
creatures
cannot
survive
without
self-
adaptiveness, inspiring the development of highly eﬃcient procedures. Such pro-
cedures should facilitate learning from past experience toward behavior adapta-
tion. When solving the QAP, feedback can be obtained from past experience, all
involved with measuring the eﬃciency of each interchange of facilities, from one
location to another.
Based on such feedback, the current procedure makes eﬃcient interchanges
and, like biological systems uses this self-adaptive mechanism to improve its
eﬃciency. In eﬀect, it decreases the length of cycles, in a self-adaptive manner,
until the cycle includes only two facilities.
Nature-inspired algorithms for metaheurstics like cuckoo search, bat algo-
rithm, and particle swarm optimization have been described in [55]. Among
c
⃝Springer Nature Singapore Pte Ltd. 2020
M. Khosravy et al. (eds.), Frontier Applications of Nature Inspired Computation,
Springer Tracts in Nature-Inspired Computing,
https://doi.org/10.1007/978-981-15-2133-1_6

120
R. Zamani and M. Amirghasemi
them, the recently developed bat algorithm has been applied to some practical
problems like multi-level image thresholding [47]. The same is true with par-
ticle swarm optimization which, as a traditional nature-inspired optimization
algorithm, has been applied to some practical problems such as optimization
processes related to proportional–integral–derivative controllers [25].
To exploit the structure of the problem, the SAFI strikes a delicate balance
between the intensity of changes and the quality of the modiﬁed solutions. This
is done in the hope that, with minimum computational eﬀort, a local optimal
solution can be converted to another local optimal solution of possibly higher
quality.
The success of any iterated local search [34], in general, and that of the
SAFI, in particular, depends on the quality of interchanges it can apply. That is
why the current linear assignment technique selected for applying interchanges is
one of the fastest optimization techniques for this purpose [30]. The reason why
the quality of an interchange can highly aﬀect the performance of any iterated
local search is known and can be stated by two interrelated facts that (i) if an
interchange is strong, it can degrade the quality of the iterated local search to a
random-restarting search and (ii) if it is too weak, it can be simply undone by
the local search [34].
The work reported in this paper is presented as follows. In Sect. 2, a formu-
lation of the QAP is provided and its current solution procedures are classiﬁed.
Section 3 presents the related work. Section 4 discusses the SAFI and provides
a stepwise description as to how the algorithm works. In Sect. 5, the results of
computational experiments are discussed. Finally, Sect. 6 presents the conclusion
and sketches several directions for the further development of the procedure.
2
Problem Formulation
With having a variety of applications in industry, the oldest application of the
QAP has been involved with determining the locations of electronic modules
on circuit boards [41,49]. The other areas where the QAP has been successfully
applied are computer manufacturing as well as parallel and distributed comput-
ing [33].
Two prominent applications of this widely applicable problem are (i) the
design of microchips in computer manufacturing, and (ii) minimizing the traﬃc
of data among modules running on diﬀerent processors that have access to the
shared data in parallel and distributed computing [33]. Among other applications
of the QAP, the assignment of gates to airplanes can be mentioned [24].
The QAP can be considered as a facility layout problem [38], involved with
the allocation of n facilities to n locations with the aim of minimizing the traﬃc
among facilities. In this problem, which has two input matrixes, the ﬁrst matrix
shows the distance between each two locations dkl, and the second matrix rep-
resents the ﬂow between each two facilities, fij. Assuming that the arrangement
Π includes n components, π(i), i = 1, 2, . . . , n, in which π(i) shows the location
of facility i, then the goal in the QAP is to minimize the traﬃc, which is the
sum of all possible distance-ﬂow products, represented as follows:

A Self-adaptive Nature-Inspired Procedure for Solving
121
Minimize Traﬃc =
n

i=1
n

j=1
fijdπ(i)π(j), over all permutations, π ∈Sn
(1)
where Sn is the set of all possible permutations of the numbers {1, 2, . . . , n}.
It is worth noting that, even for comparatively small-sized problems, the
number of possible arrangements is extremely large. For instance, for a number
as small as 30 facilities, there are over 2.6∗1032 diﬀerent arrangements, and still
worse, a small increase from 30 to 35 can increase the number of arrangements
over 107 folds, 35!/30!. This means that in ﬁnding a solution, using the explicit
enumeration of all solutions for practical problems is similar to looking for a
needle in a haystack, as such a procedure looks for the optimal. Because of
having such a large solution space, the lack of any eﬀective implicit enumeration
technique for the problem, and computational complexity of the problem [45],
the development of eﬀective heuristics seems to be the only viable alternative.
Heuristic techniques are mainly divided into construction and local searches.
In construction methods, an arrangement is built by adding a pair of facility-
location at a time. On the other hand, local searches repeatedly proceed from an
arrangement, Π, to a better arrangement, Π′. The diﬀerence between the traﬃc
volumes of two diﬀerent arrangements Π, Π′, which is Traﬃc(Π) −Traﬃc(Π′),
can be simply represented with Diﬀ(Π, Π′).
Diﬀ(Π, Π′) =
n

i=1
n

j=1
fij(dπ(i)π(j) −dπ′(i)π′(j))
(2)
3
Related Work
We start by describing the most related work to the SAFI, which are Progressive
Adjusting Structural Solver (PASS) [3] and Neighborhood Decomposition-based
Search (NDS) [4] as the notion of using a linear assignment technique in solving
the QAP has been originally introduced in [3] and [4]. Both of these methods,
the same as the SAFI, use linear assignment as a module for improving the
QAP. Also, unlike the description of [3] and [4], which, because of their space
restrictions, with respect to their linear assignment module were not stand-alone,
the description of the SAFI is stand-alone as the linear assignment operations
have been described in details.Whereas the SAFI modiﬁes local optimal solutions
and runs a local search on the modiﬁed solutions, [3] does not perform any
local search. Unlike [3] and the SAFI, the procedure reported in [4] uses ﬁve
synergetic layers as well as N-Lambda local search to improve its eﬃciency. All
these methods work based on approximation.
The other highly related procedure is the Very Large-scale Neighborhood
(VLSN) search [1], which as a novel multi-exchange approach, relies on the con-
cept of improvement graph. In eﬀect, improvement graph, as one of the main
contributions in [1], facilitates the calculation of cycle costs, which are good

122
R. Zamani and M. Amirghasemi
approximations of the cost of multi-exchange of facilities. Improvement graph
can also be utilized to make the evaluation of such a cost faster.
The exact methods have very limited capability in tackling the QAP. Approx-
imation methods presented for the QAP can be mainly categorized into the ﬁve
classes of (i) limited enumeration techniques, (ii) construction methods, (iii)
genetic algorithms, (iv) metaheuristics, and (v) hybrids. Some of these classes
themselves are further divided into smaller subclasses.
For instance, metaheuristics can be primarily divided into the two major
subclasses of (i) Tabu searches and (ii) simulated annealing algorithms. The sim-
ulated annealing algorithms developed in [10,11,38], and [6] and Tabu searches
developed in [15,17,39], and [44] have proved to be very eﬀective.
Also, construction methods can be mainly divided into the three subclasses of
(i) simple greedy procedures, (ii) greedy randomized adaptive search procedures
[42], and (iii) ant systems [14]. Among powerful ant systems developed for solving
the QAP are those presented in [19,35,48,52], and [12]. It is worth mentioning
that all ant systems, as construction methods, build solutions in an incremental
fashion.
All construction methods iteratively assemble a partial solution so that it
can become a complete solution. This is performed by iteratively ﬁnding the
best elements based on an evaluation function and progressively augmenting a
partial solution until it becomes a complete solution. This is in contrast with
local searches which iteratively alter a complete solution to another complete
solution by applying some limited local changes. They diﬀer from systematic
searches in that they normally probe a search space whose states are complete
rather than partial. Such search spaces are typically explored by local searches
through the hill-climbing method.
Unlike the other two solution strategies, genetic algorithms, which utilize the
metaphor of evolution, are not point-based but population-based. They recom-
bine ﬁtter solutions, perform random changes to genetic encoding, and conse-
quently improve the quality of their ﬁnal output. As nature-inspired algorithms
that adopt the survival of the ﬁttest principle in nature and improve an initial
population of solutions through generating diﬀerent generations, genetic algo-
rithms have three major components. These components include a crossover
operator, a mutation operator, and a selection system. In this section, construc-
tion methods, local searches, and genetic algorithms presented for the QAP are
brieﬂy surveyed.
The ﬁrst construction method for the QAP has been introduced in [20],
which, similar to all other construction methods, completes a solution progres-
sively. Considering a solution as n pairs of (i, j) of facilities and locations, this
simple greedy procedure, initially unmark all facilities and locations, signifying
that no location has yet been paired with a facility.
Then, an assignment is made through selecting a pair of unmarked facil-
ity and location that incurs the minimum cost to the current partial solution.
Selected locations and facilities are marked and the process is repeated until all

A Self-adaptive Nature-Inspired Procedure for Solving
123
facilities are assigned to locations. Some other simple greedy procedures include
those presented in [46], [5], [23], and [56].
The greedy randomized adaptive search procedure, as the second subclass of
construction methods, has ﬁrst been formally introduced in [18], one year after
its successful application to QAP in [31]. As a combination of greedy elements
and local searches, it repeatedly constructs a solution and then converts the
solution to a local optimum. Then, among the local optimal solutions generated,
it selects the best one. Eﬀective solution procedures of this type for solving the
QAP include those presented in [31], [43] and [42].
The second mechanism includes local searches and comprises a wide variety
of solution procedures for solving the QAP. Since in exploring solution space,
local searches use the hill-climbing method, they have the structural drawback of
getting stuck into local optima. To circumvent this drawback, two main guidance
mechanisms employed are the tabu list and the annealing process, which have led
to the development of Tabu search [21,22] and simulated annealing algorithms
[28], respectively. These mechanisms are based on allowing deteriorating moves,
albeit in two dramatically diﬀerent fashions.
In eﬀect, Tabu searches and simulated annealing algorithms are among the
most popular methods in dealing with the QAP, and this can partly be attributed
to the existence of an eﬀective mechanism for the manipulation of the k-exchange
neighborhood in this problem. This mechanism has originally been developed in
[51] for 2-exchange neighborhood and later has been extended to an eﬀective
manipulation of multiple exchanges [1].
The interesting feature of the Taillard’s algorithm is that it can explore the
complete 2-exchange neighborhood with O(n2), rather than O(n3), operations.
The eﬀective Tabu search presented in [27] is heavily relied on this interesting
feature. On the other hand, the remarkable characteristic of the Ahuja et al’s
algorithm [1] is the eﬀective heuristic enumeration of multi-exchange neighbor-
hood through employing a concept called improvement graph.
Considering the number of exchanges as a depth, this algorithm iteratively
checks all paths within a speciﬁed depth and never enters into a higher depth
until all nodes in the lower depth have been examined. Because of the enormous
size of the nodes existing in the depth of ﬁve and more, a limit of four for the
maximum depth has been set by its authors.
For employing local searches to solve the QAP, the method presented in
[31] has used an eﬀective neighborhood structure called N ∗. Starting with a 2-
exchange scheme, and expanding it repeatedly, N ∗prevents any two items that
have already been exchanged from returning to their original places. Since the
number of possible exchanges in the ﬁrst repeat is O(n2) and in each repeat only
one exchange is excluded, the total number of repeats is O(n2). This makes the
size of this neighborhood scheme as O(n4), which is 1 + 2 + 3 + . . . + O(n2).
An important point with this neighborhood structure is that its size is equal to
that of a 4-exchange neighborhood but its diameter, n, is larger than that of a
4-exchange neighborhood.

124
R. Zamani and M. Amirghasemi
As recognized in [31], the notion of diameter, as a distance between two
permutations, is one of the key issues in determining the eﬀectiveness of neigh-
borhood schemes for the QAP. Simply, the distance between two permutations
can be deﬁned as the number of their same positions that have been occupied
by diﬀerent items. For instance, when two items in a permutation are swapped,
a distance of two between the original and the new permutation is created. The
diameter of a neighborhood scheme is the maximum distance between two of the
neighbors of a single solution.
A neighborhood scheme can have a connectivity degree, which, the same as
the diameter, plays a crucial role in search eﬃciency. The connectivity degree
measures how any two neighbors of a solution can be linked by a path which
contains the other neighbors of the same solution, with any two consecutive
elements of the path having the smallest possible distance. It is the distance
between these consecutive elements of the paths that determines the connectivity
degree in the corresponding neighborhood scheme, with the smaller distances
implying larger connectivity.
A simple formula for ﬁnding the degree of connectivity has been presented
in [31]. In this formula, connectivity has been deﬁned as 1/K in which the value
of K is interpreted as follows. Consider a permutation, r, and its neighbors,
N(r), and assume that p and q belong to N(r). K is the maximum distance
between two consecutive permutations in a path connecting p to q, subject to
the two restrictions that (i) all of the elements of the path belong to N(r), and
(ii) the maximum distance between each two consecutive elements of the path
is minimized.
For each possible r, the value of K is calculated and the minimum value
among them is chosen as K for the corresponding neighborhood scheme. Con-
sidering a low degree of connectivity in random neighborhoods, it is the principle
of having a neighborhood with a high degree of connectivity that excludes the
use of any randomness in deﬁning neighborhoods.
As an eﬀective strategy in local searches applied to the QAP, we can name
iterated local search (ILS) introduced in [34] and applied to the QAP in [50].
In eﬀect, because of its both sophistication and eﬀectiveness, the ILS has been
repeatedly rediscovered by diﬀerent authors and with diﬀerent names, like large-
step Markov chains [37] and chained local optimization [36].
The ILS iteratively performs two operations of (i) perturbing a local optimal
solution and (ii) locally optimizing the perturbed solution. In other words, it
avoids random sampling of solution space and, without using any construction
method, performs a biased random walk in the space of local optimal solutions.
In [50], four mechanisms that should be set up for the application of the ILS
to any problem, in general, and to the QAP, in particular, have been identiﬁed.
These mechanisms include (i) generating an initial solution, (ii) making a per-
turbation, (iii) deciding about the local optimal solution to be perturbed, and
(iv) performing a local search. Without employing any construction method, the
initial solution is generated by randomly assigning facilities to locations.

A Self-adaptive Nature-Inspired Procedure for Solving
125
Then, an interchange is made through performing a k-exchange, with the
value of k being between kmin and kmax. In eﬀect, initially, k is set to kmin and if
the local search can make no improvement to the perturbed solution, the value
of k is increased by one. In this process, whenever an improvement occurs or
when k reaches at kmax, k is set back to its initial value, kmin.
The iterated local search presented in [50] for solving the QAP uses 2-
exchange neighborhood scheme for its local search and employs the ﬁrst improve-
ment strategy, in the sense that whenever an improvement is found, it is applied
immediately. Moreover, to avoid the disadvantage of full scan, which is involved
with the complexity of O(n3), it uses a strategy called “don’t look bits.”
Based on this strategy, any facility whose dislocation cannot improve the
solution in one iteration is marked, and in the next iterations, this facility is not
considered as a starting point for the neighborhood scan. However, if such facility
is included in a move and its location is changed, it will again be considered as a
starting point. This strategy the attention on the promising parts of the solution
space and makes the consideration of many unfruitful moves unnecessary.
Having brieﬂy surveyed the ﬁrst two mechanisms in solving the QAP, the
third mechanism to discuss is genetic algorithms. A number of authors have used
GAs for the QAP as separate modules, albeit of not producing superb solutions.
As an example of these approaches, we can mention the stand-alone genetic
algorithm presented in [53]. It is worth noting that because of the existence
of eﬀective means for the manipulation of multi-exchange neighborhoods, in
general, and for the 2-exchange neighborhood, in particular, local searches in
general outperform genetic algorithms for the QAP [53].
That is why in solving the QAP, genetic algorithms play the role of a com-
plementary machinery and mainly complement local searches. In these hybrids,
local searches and genetic algorithms usually complement each another to pro-
duce a synergy needed to tackle the complex nature of the QAP.
The importance of these hybrids can be described by the facts that (i) the
oﬀspring generated, because of preserving high-quality solutions, is a promising
starting solution for local searches, and (ii) by having high-quality solutions as
their starting points, the local searches require fewer iterations to attain local
optima. Perhaps, the combination of genetic algorithms and local searches, as a
hybrid, is one of the most eﬀective solution techniques for the QAP.
The hybrid genetic algorithm presented in [2] and that presented in [16,
17], with its variants, can be considered as the most elegant algorithms in this
category. They both use intensive crossover operators and periodically enhance
the performance of the search with eﬀective local searches. In eﬀect, the genetic
hybrid presented in [16,17] applies an intensive scheme called cohesive merging
procedure as its crossover operator, which is based on ﬁnding a median distance
from a pivot site.
This crossover operator is intensive in the sense that the pivot site can be
selected among all possible sites, whichever produces the best oﬀspring. The
algorithm employs a modiﬁed version of concentric Tabu search presented in
[15] as its local search component.
Consistent with this algorithm, in using an intensive crossover operator,
the algorithm presented in [2] applies path crossover, which, by using a greedy

126
R. Zamani and M. Amirghasemi
method, examines many promising oﬀspring solutions implicitly and selects the
best one. The high performance of this algorithm is due to striking a delicate
balance between greedy methods enhancing the quality of solutions and the
mechanisms raising diversity. In the literature of the search, the above algo-
rithms, as hybrid genetic, are referred to as memetic algorithms [40], with the
characteristic of applying a local search on any oﬀspring generated.
Hybrid algorithms usually combine diﬀerent strategies at the same time
to solve the problem. For instance, they can use genetic algorithm, point-
based metaheuristics, and truncated exact methods at the same time. Generally,
hybrids produce solutions with higher quality when compared with other proce-
dures. Some of the most eﬀective hybrid procedures presented for the QAP are
[13,26,27,54].
4
The SAFI
First, for initial solution construction, we implemented a randomized heuristic
(RH) which aims at assigning highly connected facilities to closely located sites.
As the initialization routine, for each facility (location), the total ﬂow (distance)
to all other facilities (locations) is calculated. Next, both the list of facilities
and locations are separately sorted based on the total ﬂow and total distance,
respectively.
Based on the two sorted lists of facilities and locations, RH constructs a
solution by iteratively assigning the facility having the highest total ﬂow to the
locations having the lowest total distance. Furthermore, RH is randomized in the
sense that, in each iteration, from the top K candidate locations for a facility,
one of them is selected uniformly at random. It is worth noting that only a ratio,
α, of facilities are assigned using this method and the rest are assigned so that
the minimum cost is incurred to the solution cost.
While α controls the intensiﬁcation aspect of RH, K determines the level
of diversiﬁcation. With respect to adding the pairs of facility-location’s to the
partial layout, RH operates similar to the procedure presented in [31].
After creating an initial solution, a linear assignment technique is used, in a
self-adaptive environment, to propose altering the locations of facilities through
circular modiﬁcations. The technique can suggest a change like (6, 7, 4, 3), which
indicates the facilities in locations 6, 7, 4, and 3 should be moved to the locations
of facilitates 7, 4, 3, and 6, respectively. It suggests, not one, but several of these
circular modiﬁcations, one after another, with each suggestion considering the
eﬀects of previous suggestions.
When the linear assignment technique cannot propose any further modiﬁca-
tion, a new initial solution is constructed and the linear assignment technique
is again applied to the new initial solution iteratively. This implies that for the
entire procedure to be eﬀective, the employed linear assignment technique, which
comprises the bottleneck of operations, should be very eﬃcient.
As mentioned, the employed self-adaptive linear assignment technique needs
to be called many times for the same problem to oﬀer diﬀerent suggestions.

A Self-adaptive Nature-Inspired Procedure for Solving
127
In this regard, not starting from scratch and using the results of all previous
calculations is a key point in decreasing the burden of computation. For this
purpose, we have used the QuickMatch [30] and adjusted it so that it can use
the results of all previous calculations. In the following, we describe QuickMatch
and the changes made.
In general, the linear assignment problem (LA) is deﬁned as the optimal
allocation of n agents to n tasks, with each agent assigned to a single task and
each task allocated to a single agent. The cost incurred by assigning an agent
to a task depends on the pair of agent-task assignment, and, for the pair of
(agent i— task j), is denoted by Cij, considering that if a speciﬁc agent cannot
do a particular task, the corresponding cost of their paring is inﬁnite. The goal
is to minimize the total cost of performing all tasks based on the assigning of
each single agent to a speciﬁc task. Assuming that π(i) shows the task to which
the agent i has been assigned, the mathematical model of the LA can be written
follows:
Minimize Z =
n

i=1
Ciπ(i)
(3)
As is seen, the objective function, in comparison to that of the QAP which is
quadratic, is linear, and this makes the problem extremely easier than the QAP.
Computational experiments have shown that the QuickMatch [30] empirically
reduces the average time of solving a randomly generated LA to O(n2), which
is as small as the time required to randomly generate a problem instance.
By having three main simple mechanisms, QuickMatch improves the per-
formance of the successive shortest path (SSP) by several orders of magnitude.
It is worth noticing that the improvement in average performance, is, however,
obtained at the cost of degrading worst case scenario by a factor of O(log2 n).
Before describing what makes QuickMatch, on average, orders of magnitude
faster than the SSP, we have to brieﬂy describe the SSP.
The SSP, which can be considered as a primal–dual algorithm, solves the
LA with the repeated application of the Dijkstra’s shortest path method. For
this purpose, it considers the LA as a bipartite network G = (A, T, P), whose
nodes comprise the sets A, and T, and arcs are shown with the set P. The sets
A and T show the agents and tasks, respectively, and the set P includes any
possible agent-task pair. The cost associated with each arc shows the cost of the
corresponding agent-task assignment. This can be expressed with the following
rule.
i ∈A
&
j ∈T
&
Cij is not inﬁnite →(i, j) ∈P
&
Cost(i, j) = Cij
(4)
For the optimal connection of the two sets of A and T through the arcs of
P so that each element of A is uniquely matched with one element of T and
to create a complete assignment, the SSP starts with a null assignment, which
includes no agent-task pair, and augments it by adding one agent-task pair at
a time. The process continues until a complete assignment, with n agent-task
pairs, is created.

128
R. Zamani and M. Amirghasemi
In the description of the SSP, any pair belonging to the partial assignment
is referred to as a selected pair, and its corresponding arc is referred to as
selected arc. For the purpose of keeping the optimality condition during the
entire progress of operations, the process of augmenting the partial assignment
with the kth pair can be involved with replacing a pair with any other pair. In
other words, a selected pair can be deselected later and replaced with another
pair.
In line with solving the maximum ﬂow problem, for each partial assignment,
x, a residual network, G(x), is deﬁned. There are three main diﬀerences between
G and G(x). First in G(x), associated with each node i, there is a dual variable
ϕi, referred to as node potential. Second, whenever a pair (i, j) is added to the
partial assignment, the arc (i, j) is reversed and the cost of the reversed arc,
(j, i), is set to the negative value of the original arc cost, Cji = −Cij. Third,
in G(x), it is the reduced cost of each arc that determines its attractiveness,
and not its real cost, with the reduced cost of the arc (i, j) being calculated
as Cϕ
ij = Cij −ϕi + ϕj. It is worth mentioning that reduced cost is a simple
mathematical concept in linear programming which can be used toward making
solution strategies more eﬀective.
Using reduced costs, instead of real costs, is because of two facts: (i) any
optimal solution found based on the reduced costs is an optimal solution based
on the real costs and (ii) with changing the node potentials, the reduced costs
of the arcs corresponding to the pairs added to the partial assignment can be
set to zero. The ﬁrst fact can be veriﬁed by considering that in any complete
assignment, all nodes participate exactly once and this causes only a constant
value of 
j∈T ϕj −
i∈A ϕi to be added to the real objective function, making
the optimal solution for the reduced costs the same as that for the real costs.
In setting the reduced costs of the selected arcs to zero, which is performed
through modifying node potentials, care is taken that the reduced costs of all
arcs is kept non-negative. Such a modiﬁcation of node potentials which keeps all
of the reduced costs non-negative plays a critical role in the algorithm and will
be discussed later.
Since there is no arc with negative reduced cost, if for a set of n feasible
selected pairs, their total reduced cost is zero, then the set represents an optimal
assignment. To ﬁnd such a feasible set of n pairs, the SSP ﬁrst marks all nodes
in A and T as free, indicating that the corresponding node has not participated
in any agent-task pair yet.
Hence, initially, the free nodes are divided into origin and destination nodes
with equal size n, with origin nodes belonging to the set A and destination nodes
belonging to the set T. Moreover, since in each iteration, only one free origin
node is paired with one free destination node, during the process of constructing
the optimal solution, the number of free origin nodes is kept the same as the
number of free destination nodes.
The matching process starts by selecting a free origin node i and ﬁnding
a free destination node j which has the shortest possible distance form it in
the residual graph. Then, node potentials are updated so that the reduced cost

A Self-adaptive Nature-Inspired Procedure for Solving
129
of the arc connecting node i to node j becomes zero, Cϕ
ij = Cij −ϕi + ϕj = 0.
Subsequently, the direction of arc i−j is reversed and its cost, Cji, is set to −Cij.
It should be noticed that by reversing this arc in the residual graph, its reduced
cost will remain the same, 0. This is because Cϕ
ij = Cij −ϕi + ϕj
&
Cϕ
ji =
Cji −ϕj + ϕi
&
Cij = −Cji, implying Cϕ
ij = −Cϕ
ji.
When a free node i is connected to a free node j, and create a pair of agent-
task, these two nodes are no more considered as free. The SSP continues the
process by selecting another free origin node i and ﬁnding a free destination
node j which has the shortest possible distance from the node i. Pairing a free
node i, with a free node j, continues until no free node is in existence, which
implies n agent-task pairs have been constructed.
In the process of pairing agents with tasks, whenever an augmented path from
an origin node i to a destination node j is found in the residual network, the
directions of the entire arcs on the augmented path are reversed, and the sign of
their costs is altered, from positive to negative and vice versa. Each augmented
path can include between 1 and 2n −1 of reversed arcs and each reversed arc
shows either a selected or deselected agent-task pair, with the reversal of a
reversed arc reﬂecting that the arc has now its original direction.
In other words, the corresponding agent and task participating at the two
ends of an already reversed arc in an augmented path no more create a pair.
This, however, does not make them as free nodes because they have participated
in some other pairs, related to the arcs that have recently been reversed. In
eﬀect, the reversal of a reversed arc causes the arc to have its original direction
and indicates that the corresponding agent pair has been deselected, and the
reversal of an original arc indicates that the corresponding agent pair has been
selected.
Having explained the major operations of the SSP, we now describe how,
in each iteration, after adding a new agent-task to the partial assignment, node
potentials are modiﬁed so that the reduced costs of the selected arcs are zero and
the reduced costs of other arcs are non-negative. In the SSP, the node potential
ϕj is updated as ˆϕj = ϕj + max {0, K −Lj}, in which Lj shows the shortest
path to the node j form an origin node s, and K shows an upper bound of
maximum distance from s. The reason this updating keeps C ˆϕ
ij , for any i and
j, non-negative is simple and can be shown by considering the fact that either
both i and j have distances from s smaller than K, or not.
In the ﬁrst case, C ˆϕ
ij = Cϕ
ij + Li −Lj and since both Li and Lj show the
shortest distance from the same node, s, it is required that Lj −Li ≤Cϕ
ij,
otherwise (i −j) is selected as part of the shortest path connecting s to j and
this makes Lj −Li = Cϕ
ij. This simply implies that in the ﬁrst case, C ˆϕ
ij ≥0. For
the second case, where either the distance of i or that of j from s is greater than
K, the node potential of the corresponding node is not changed and the change
in the node potential of the other node, if any, cannot make C ˆϕ
ij negative.

130
R. Zamani and M. Amirghasemi
The reason again is simple: if the node whose distance is greater than K is i,
this increases the value of Cϕ
ij by Lj −K. On the other hand, if the node whose
distance is greater than K is j, then the value of Cϕ
ij cannot be less than K −Li,
otherwise j could be connected to s through i with a path smaller than K and
this contradicts with the assumption that the distance of j from s is greater
than K.
Hence, in the second case, the fact that Cϕ
ij is not less than K −Li implies
that decreasing K −Li from Cϕ
ij cannot make it negative. This shows that node
potentials never become negative, and moreover, for any link (i, j) that belongs
to the shortest path to s, C ˆϕ
ij is zero, completing the proof that the SSP works
correctly.
The performance of the SSP, as a primal–dual approach, is sensitive as to
how shortest paths are found and how node potentials, as dual variables, are
updated. It is with respect to this sensitivity that QuickMatch improves the
SSP in three main directions. First, instead of setting K to an upper bound on
maximum distance from s, QuickMatch sets K to minimum Lj for any j which
is free and belongs to T.
In other words, whenever a free origin node, s, is selected and a free destina-
tion node with minimum distance is found, the distance between these two nodes
is considered as K. A point with this selection of K is that since the Dijkstra’s
algorithm permanently labels nodes in the non-decreasing order of their distance
from s, only node potentials are updated whose corresponding node has been
permanently labeled by the Dijkstra’s algorithm.
The second improvement involves testing the free origin nodes based on how
easily they can ﬁnd their corresponding free destination node and temporarily
abandoning a free origin node which cannot be matched with a free destination
node easily. In other words, shortest path computation is not guaranteed to pro-
ceed once started and can be terminated if it takes more than a small threshold,
implying that another free origin node should be tested. For this purpose, a
threshold t¸ is considered and after labeling t¸ nodes by the Dijkstra’s algorithm,
if still no free destination node has been found, the free origin node is abandoned
and another free origin node is considered.
If none of the free origin nodes can ﬁnd a free destination node with labeling
less than or equal to t¸ nodes by the Dijkstra’s algorithm, then the value of t¸ is
increased. The value of t¸ is initially set to 2 and is doubled whenever none of
the free origin nodes can ﬁnd a free destination node. This simple modiﬁcation
alone has made QuickMatch faster than the SSP by the orders of magnitude.
The third modiﬁcation is involved with alternating shortest path computa-
tion from free origin nodes to free destination nodes and from free destination
nodes to free origin nodes. In simple terms, before doubling the value of t¸, if a
free destination node can ﬁnd a free origin node in the mirror residual graph
within t¸ or less labeling operations, these two free nodes are paired before dou-
bling the value of t¸. This completes the description of the operations performed
by QuickMatch.

A Self-adaptive Nature-Inspired Procedure for Solving
131
Now, we can simply describe how we have adjusted QuickMatch and have
modiﬁed its operations to propose an algorithm called, Facility Elimination
QuickMatch, FEQM, so that the reduced costs calculated in its previous rounds
are used to facilitate the process. After all, only one or several reduced cost(s) of
the last stage has (have) been changed and the rest are the same. This decreases
the level of computation of the new optimal solution from the full solution of
the linear assignment problem to just several simple operations done in the last
stage of problem solving process.
The FEQM prevents any unnecessary calculation in its new rounds. In other
words, in this procedure, the calculation of the new optimal solution is not
required to be started from scratch and can fully utilize the results of all cal-
culations performed in the previous round. Assuming the facility f is supposed
to be removed from consideration, the value of Cff needs to be changed to
Cff −Cϕ
ff so that the new value of Cϕ
ff is changed to 0. In addition to this
modiﬁcation, the value of Cfk should be set to a large number for all k ̸= f.
Then, the facility f is simply augmented without any necessary restarting of the
FEQM.
The pseudocode of the SAFI has been outlined in Fig. 1, and as is seen, its
main while loop starts at line 4. In this while loop, the generated initial solution
is improved based on the N ∗neighborhood described and the value of solution
Z is initialized to X.
The solution Z, at lines 10 and 12, is deﬁned to be the best candidate to
replace the solution X. In line 13, the improvement graph of X is calculated
based on the method discussed in [1], and in line 14, linear assignment has been
applied to G(x) based on [3]. The loop starting in line 16 works based on cycles.
A cycle is the replacement of several facilities with one another, proposed by
the linear assignment procedure. For instance, 6-8-5-6 shows a cycle proposing
putting facility 6 in the location of facility 8, and placing facility 8 in the location
of facility 5, and ﬁnally putting facility 5 in the location of facility 6. In eﬀect,
while there is any cycle in the linear assignment result, L, the while loop started
at line 16 ﬁrst computes the best cycle of P and then applies it to the solution
X, in line 25. Lines 32 to 34 are used for the removal of cycle C applied to X
by facility elimination.
As a result of this process, if the resulting solution, Y , has a lower cost
than the best possible replacement, Z, the improvement will be set to true, the
solution Z is updated, and the procedure forces the facility with highest cost
to be removed from the cycle C. This process continues until a time limit is
reached.
5
Computational Experiments
The SAFI has been implemented in C++ and is compiled via GNU GCC com-
piler on a Dell PC with 2.93 GHz speed. For all the experiments, the standard
C++ random number generator (std::rand), with a seed value of 1, has been
used. As many as 74 representative benchmark instances from the QAPLIB [8]

132
R. Zamani and M. Amirghasemi
Fig. 1. The c-type pseudocode of the SAFI
have been used for the purpose of performing the computational experiments.
Among these instances, 8 of them are Taillard instances, taixxa, 13 of them
are Skorin-Kapov instances, skoxxx, and the rest are real-life instances (burxxx,
hadxx, chrxxx, kraxxx, stexxx, escxxx, and els19). It is worth mentioning that
among these 74 instances, the 8 instances of taixxa and the 13 instances of
skoxxx are comparatively harder than the rest. Before running the SAFI on the
benchmark instances, our initial solution construction method is analyzed.
5.1
Parameters Setting
Figure 2 shows the performance of the SAFI based on varying the two parameters
of RH, α and K, with the z-axis showing solution cost averaged over 3 benchmark
instances of chr20a, chr20b, and chr20c. As is seen, the worst performance has
occurred when α and K have been set to 0.1 and 5, respectively.

A Self-adaptive Nature-Inspired Procedure for Solving
133
Based on this preliminary observation, and to gain an eﬀective intensiﬁca-
tion/diversiﬁcation balance for RH, α and K, have been set to 0.45 and 9,
respectively. In other words, 45% of facilities are assigned to high-grade loca-
tions and the rest of facilities and locations are matched in a pairwise fashion
based on minimum increment to the objective function.
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
3
4
5
6
7
8
9
6200
6300
6400
6500
α
K
Cost
Fig. 2. Performance of the SAFI based on varying the two parameters α and K,
with the Z-axis showing solution cost averaged over 3 benchmark instances of chr20a,
chr20b, and chr20c
5.2
Comparing RH with Uniform
To further analyze RH, we have compared RH with UNIFORM construction
method. In UNIFORM method, a solution is constructed uniformly at random.
In other words, all n! permutations have an equal chance ( 1
n!) of being generated
as a solution. As Table 1 shows, we have run both RH and UNIFORM on Taillard
and Skorin-Kapov instances.
Each method has been run 1000 times for each instance, and, the average
(AVG) and standard deviation (STDEV) of solution cost is estimated based on
the sample of size 1000. The two columns %DEVavg and %STDEV in Table 1
show the percentage of deviation from the best known solution (BKS) and are
calculated as (AV G −BKS)/BKS ∗100 and STDEV/BKS ∗100, respectively.
Assuming normal distribution for %DEVavg and %STDEV, Fig. 3 shows the
probability distribution function for UNIFORM and RH. Based on normal cumu-
lative distribution function, P(X ≤0) = Φμ,σ2(0) for UNIFORM and RH can

134
R. Zamani and M. Amirghasemi
Table 1. Comparing UNIFORM and RH construction method on Taillard and Skorin-
Kapov instances
UNIFORM
RH
Instance
%DEVavg
%STDEV %DEVavg
%STDEV
tai20a
27.60
3.39
19.57
2.96
tai25a
23.88
2.42
17.11
2.13
tai30a
20.88
1.81
15.40
1.58
tai40a
20.58
1.53
14.07
1.24
tai50a
19.51
1.19
13.43
0.99
tai60a
18.12
0.99
12.51
0.81
tai80a
15.80
0.71
10.83
0.57
tai100a
14.36
0.57
9.71
0.48
sko42
26.95
2.21
17.55
1.78
sko49
24.17
1.87
15.13
1.43
sko56
23.75
1.67
14.29
1.24
sko64
21.22
1.43
13.79
1.10
sko72
20.32
1.24
12.42
0.92
sko81
19.18
1.07
11.73
0.81
sko90
18.44
1.00
11.58
0.75
sko100a
17.42
0.87
10.68
0.65
sko100b
17.43
0.90
10.47
0.64
sko100c
18.01
0.88
11.36
0.70
sko100d
17.53
0.90
10.97
0.64
sko100e
18.24
0.93
11.30
0.69
sko100f
17.24
0.90
10.81
0.68
Average
20.03
1.36
13.08
1.08
Total Time(sec.) 0.123
1.827
be computed as 2.1 ∗10−49 and 4.6 ∗10−34, respectively. In fact, this may indi-
cate that UNIFORM method should be orders of magnitude faster in order to
beat RH. However, as can be seen in Table 1, UNIFORM is only faster by a
factor of 1.827
0.123 = 14.85. This means that RH is superior to UNIFORM, despite
its comparative slowness.
Despite the fact that RH yields diverse, and high-quality starting solutions,
for handling some rare cases, a uniformly random solution is generated with the
small probability of 0.01. Hence, the initial solutions for the SAFI are constructed
in two ways in the sense that with a chance of 0.01 a random permutation is
generated as the initial solution and with the probability 0.99, the RH method
is used. In a large majority of cases, N * improves the initial solutions, regardless
of whether the RH or UNIFORM has been used.

A Self-adaptive Nature-Inspired Procedure for Solving
135
5
10
15
20
25
30
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
Average Deviation %
UNIFORM
RH
Fig. 3. Probability distribution functions assuming normal distribution for RH and
UNIFORM methods
5.3
Detailed Performance on Two Typical Instances with the Size
of 20 and 60
First, on one of the benchmark instances, lipa60a, the performance of the SAFI
is discussed and the ﬁtness landscape is depicted and then the SAFI is compared
with other high performance procedures.
As the pseudocode in Fig. 1 shows, in line 3, a loop starts that in its line
8 generates an initial solution and improves this solution toward solutions with
higher quality. Figure 4 depicts how these generated solutions are improved one
after another and that how after evaluating more than 1000 solutions, one of
them leads to a high-quality solution.
When during the process of the search, solutions are generated and evaluated,
the chance of improving the best obtained solution, based on a generated solu-
tion, decreases as the number of solutions generated increases. Figure 5 shows the
best solution obtained from the start of the process for the ﬁrst 1200 iterations.
As Fig. 5 shows, the highest improvement has occurred in around the ﬁrst ﬁfty
evaluations performed, decreasing the ﬁrst generated solution from near 109500
to less than 108100. As is seen, in the next 1150 iterations, the value of 108100
has decreased to 107218, which is the optimal solution value. This clearly indi-
cates that the improvement occurred in the ﬁrst 50 evaluations, 109500–108100,
has been higher than the improvement occurred in the next 1150 evaluations,
108100–107218.

136
R. Zamani and M. Amirghasemi
0
200
400
600
800
1000
1200
107,000
107,500
108,000
108,500
109,000
109,500
iteration
solution cost
Fig. 4. Best solution obtained from the start of each restarting on the lipa60a instance
for the ﬁrst 1200 iterations
Figure 6 depicts a ﬁtness landscape for the instance chr20a near its optimal
solution shown at point (0,0), in which the x-axis shows the swaps made in the
ﬁrst half of the permutation and the y-axis shows the swaps made in the second
half.
0
200
400
600
800
1000
1200
107,000
107,500
108,000
108,500
109,000
109,500
iteration
solution cost (best−so−far)
Fig. 5. Best solution obtained from the start of the procedure on the lipa60a instance
for the ﬁrst 1200 iterations

A Self-adaptive Nature-Inspired Procedure for Solving
137
0
20
40
60
80
100
0
10
20
30
40
50
60
70
80
90
0
2000
4000
6000
8000
10000
12000
14000
Fig. 6. Landscape of instance chr20a near its optimal solution shown at point (0,0)
Since each half interval includes 10, 20/2, items, there are 90, 10*(10–1),
points on each axis and 8100, 90*90, diﬀerent permutations have been evaluated
for drawing the ﬁgure. The reason the ﬁgure can depict a ﬁtness landscape is
that in x-y plane each permutation diﬀers from its neighboring permutations by
only the locations of two facilities. Since the QAP is a minimization problem,
the z-values have been shown with zmax −f(x, y) so that smaller values can be
represented as higher points. To the best of our knowledge, the ﬁrst time such a
method has been used to show the ﬁtness landscape for permutation problems
has been in [9].

138
R. Zamani and M. Amirghasemi
5.4
Performance on Real-Life Instances
In line with other similar procedures, for each instance, 10 independent trials
have been run, each with a diﬀerent random seed. For each run, a time limit of
n/3 minutes has been set, in which n shows the problem size. Furthermore, the
algorithm terminates as soon as the optimal solution value is obtained.
Table 2 shows the results of the computational experiments on real-life
instances. Since the optimal solution values for all real-life instances are known,
the optimal cost is shown in the column OPT. In addition, %DEVbest shows the
best percentage of deviation from the best known solution (BKS) and %DEVavg
shows the average deviation percentage from the OPT over all 10 runs.
The number of times OPT is found is also noted in parentheses. T best and
T avg show the best and average times, in minutes, in which the best solution
has been obtained. The reason T avg has been presented is that for all instances,
except ste36a, all 10 runs lead to generating the optimal solution. In eﬀect, even
for this instance, 8 out of 10 runs have led to generating optimal solutions.
5.5
Performance on Taillard and Skorin-Kapov Instances
Table 3 shows the experiment results on Taillard and Skorin-Kapov instances.
Since for the most instances presented in Table 3, the optimal solution is not
known, the deviation from the best known solution (BKS) is reported. In addi-
tion, the maximum allowed running time for each run, Tmax = n
3 , has also been
reported. As can be seen, the total average deviation from the BKS for Taillard
and Skorin-Kapov instances are 0.451% and 0.119% respectively. Moreover, for
all instances, the average percent deviation from BKS is less than 1%.
5.6
Comparing the Performance of the SAFI with that of Other
Procedures
The performance of the SAFI has been compared with that of six other well-
known procedures in the QAP literature. These procedures include Cooperative
Parallel Tabu Search (CPTS) of [26] and Diversiﬁed Tabu Search (DivTS) of
[27] a hybrid algorithm which combines ant colony optimization(ACO), genetic
algorithm (GA), and local search (LS), named ACO-GA/LS reported in [54],
the multi-start hyper-heuristic (MSH) of [13], the breakout memetic algorithm
(BMA) of [7], and progressive adjusting structural solver (PASS) of [3].
CPTS is a parallel approach which has been run on 10 Intel Itanium pro-
cessors with 1.3 GHz clock speed, on a SGI-Altix supercomputer, and DivTS
and ACO-GA/LS are sequential approaches which have been run on a single

A Self-adaptive Nature-Inspired Procedure for Solving
139
Table 2. Performance of the SAFI with respect to the percentage deviation from the
optimal solution on real-life instances
Instance OPT
Best
%DEVbest
T best
AVG
%DEVavg
T avg
bur26a
5,426,670
5,426,670
0.000
0.026
5,426,670
0.000(10)
0.045
bur26b
3,817,852
3,817,852
0.000
0.026
3,817,852
0.000(10)
0.158
bur26c
5,426,795
5,426,795
0.000
0.000
5,426,795
0.000(10)
0.006
bur26d
3,821,225
3,821,225
0.000
0.002
3,821,225
0.000(10)
0.018
bur26e
5,386,879
5,386,879
0.000
0.002
5,386,879
0.000(10)
0.008
bur26f
3,782,044
3,782,044
0.000
0.000
3,782,044
0.000(10)
0.006
bur26g
10,117,172 10,117,172 0.000
0.024
10,117,172 0.000(10)
0.365
bur26h
7,098,658
7,098,658
0.000
0.003
7,098,658
0.000(10)
0.005
Average
0.000
0.010
0.000
0.076
els19
17,212,548 17,212,548 0.000
0.008
17,212,548 0.000(10)
0.055
had12
1652
1652
0.000
0.000
1652
0.000(10)
0.000
had14
2724
2724
0.000
0.000
2724
0.000(10)
0.000
had16
3720
3720
0.000
0.000
3720
0.000(10)
0.000
had18
5358
5358
0.000
0.000
5358
0.000(10)
0.001
had20
6922
6922
0.000
0.000
6922
0.000(10)
0.000
Average
0.000
0.000
0.000
0.000
chr12a
9552
9552
0.000
0.000
9552
0.000(10)
0.000
chr12b
9742
9742
0.000
0.000
9742
0.000(10)
0.000
chr12c
11,156
11,156
0.000
0.000
11,156
0.000(10)
0.000
chr15a
9896
9896
0.000
0.000
9896
0.000(10)
0.001
chr15b
7990
7990
0.000
0.000
7990
0.000(10)
0.001
chr15c
9504
9504
0.000
0.000
9504
0.000(10)
0.002
chr18a
11,098
11,098
0.000
0.000
11,098
0.000(10)
0.003
chr18b
1534
1534
0.000
0.000
1534
0.000(10)
0.000
chr20a
2192
2192
0.000
0.010
2192
0.000(10)
0.179
chr20b
2298
2298
0.000
0.042
2298
0.000(10)
0.201
chr20c
14,142
14,142
0.000
0.000
14,142
0.000(10)
0.006
chr22a
6156
6156
0.000
0.005
6156
0.000(10)
0.036
chr22b
6194
6194
0.000
0.045
6194
0.000(10)
0.785
chr25a
3796
3796
0.000
0.063
3796
0.000(10)
0.685
Average
0.000
0.012
0.000
0.136
kra30a
88,900
88,900
0.000
0.000
88,900
0.000(10)
0.061
kra30b
91,420
91,420
0.000
0.140
91,420
0.000(10)
0.402
kra32
88,700
88,700
0.000
0.011
88,700
0.000(10)
0.039
Average
0.000
0.050
0.000
0.168

140
R. Zamani and M. Amirghasemi
Table 2. (continued)
Instance OPT
Best
%DEVbest
T best
AVG
%DEVavg
T avg
ste36a
9526
9526
0.000
0.089
9529.2
0.034(8)
1.993
ste36b
15,852
15,852
0.000
0.001
15,852
0.000(10)
0.104
ste36c
8,239,110 8,239,110 0.000
0.102
8,239,110 0.000(10)
0.880
Average
0.000
0.064
0.011
0.992
esc16a
68
68
0.000
0.000
68
0.000(10)
0.000
esc16b
292
292
0.000
0.000
292
0.000(10)
0.000
esc16c
160
160
0.000
0.000
160
0.000(10)
0.000
esc16d
16
16
0.000
0.000
16
0.000(10)
0.000
esc16e
28
28
0.000
0.000
28
0.000(10)
0.000
esc16f
0
0
0.000
0.000
0
0.000(10)
0.000
esc16g
26
26
0.000
0.000
26
0.000(10)
0.000
esc16h
996
996
0.000
0.000
996
0.000(10)
0.000
esc16i
14
14
0.000
0.000
14
0.000(10)
0.000
esc16j
8
8
0.000
0.000
8
0.000(10)
0.000
esc32a
130
130
0.000
0.000
130
0.000(10)
0.012
esc32b
168
168
0.000
0.000
168
0.000(10)
0.001
esc32c
642
642
0.000
0.000
642
0.000(10)
0.000
esc32d
200
200
0.000
0.000
200
0.000(10)
0.000
esc32e
2
2
0.000
0.000
2
0.000(10)
0.000
esc32g
6
6
0.000
0.000
6
0.000(10)
0.000
esc32h
438
438
0.000
0.000
438
0.000(10)
0.001
esc64a
116
116
0.000
0.000
116
0.000(10)
0.000
esc128
64
64
0.000
0.000
64
0.000(10)
0.017
Average
0.000
0.000
0.000
0.002
Intel Itanium (1.3 GHz), and an Intel Pentium (2.0 GHz) processor, respectively.
MSH has been run on a high performance cluster (HPC) computer with 46
nodes, each node having 2 CPUs(4 core p/CPU) and 16 GBs ram, giving a total
of 368 cores and 736 GBs of memory. The BMA has been run on a Xeon E5440
CPU with 2.83 GHz and 2 GB memory. Finally, the PASS has been run with
the same machine as with SAFI (2.93 Ghz Desktop PC). It is worth noting that
since computational times are dependent on several factors such as developer
skills, compiler eﬃciency, and CPU architecture, the running times comparisons
should be made with caution.

A Self-adaptive Nature-Inspired Procedure for Solving
141
Due to the fact that among the aforementioned approaches, only DivTS,
MSH, and BMA have reported the complete results on real-life instances, a
comparison of the SAFI and other procedures on real-life instances has been
shown in Table 4. Whereas all methods ﬁnd the optimal solution for majority of
instances on all ten trials, the SAFI and DivTS has positive average deviation
for 1 and 3 instances, respectively.
In particular, while the SAFI is unable to ﬁnd the optimal solution for ste36a
in only 2 out of 10 runs, DivTS fails to obtain the optimal value for chr20b,
chr22b, and chr25a in 1, 2 and 5 runs, out of 10 runs, for each instance respec-
tively. Also, by comparing the total average computation time, it can be seen
that DivTS is more than 10 times slower than the SAFI, which can partly be
due to a slower clock speed of Intel Itanium processor (1.3 GHz).
Table 3. Performance of the SAFI with respect the percentage deviation from the best
known solutions on Taillard and Skorin-Kapov instances
Instance
BKS
Best
%DEVbest
T best
AVG
%DEVavg
T avg
T max
Taillard instances
tai20a
703,482
703,482
0.000
0.004
703,482
0.000(10)
0.053
6.67
tai25a
1,167,256
1,167,256
0.000
0.048
1,167,256
0.000(10)
0.196
8.33
tai30a
1,818,146
1,818,146
0.000
0.004
1,818,146
0.000(10)
0.419
10.00
tai40a
3,139,370
3,141,702
0.074
9.616
3,148,867
0.303
6.345
13.33
tai50a
4,938,796
4,965,114
0.533
12.034
4,974,132
0.715
9.546
16.67
tai60a
7,208,572
7,245,314
0.510
18.645
7,257,941
0.685
7.302
20.00
tai80a
13,499,184
13,614,702
0.856
9.758
13,632,411
0.987
14.601
26.67
tai100a
21,052,466
21,208,856
0.743
30.822
21,245,229
0.916
21.593
33.33
Average
0.339
10.116
0.451
7.507
16.875
Skorin-Kapov instances
sko42
15,812
15,812
0.000
0.018
15,812
0.000(10)
0.552
14.00
sko49
23,386
23,386
0.000
0.307
23,387.2
0.005(9)
6.871
16.33
sko56
34,458
34,458
0.000
4.290
34,466.8
0.026(2)
6.651
18.67
sko64
48,498
48,498
0.000
7.184
48,516.8
0.039(3)
10.826
21.33
sko72
66,256
66,286
0.045
1.117
66,315
0.089
13.366
24.00
sko81
90,998
91,028
0.033
17.511
91,085.4
0.096
12.281
27.00
sko90
115,534
115,586
0.045
21.323
115,712.6
0.155
18.420
30.00
sko100a
152,002
152,128
0.083
3.000
152,243.8
0.159
19.427
33.33
sko100b
153,890
153,980
0.058
31.742
154,182.2
0.19
17.433
33.33
sko100c
147,862
147,886
0.016
28.664
148,062.4
0.136
15.774
33.33
sko100d
149,576
149,598
0.015
32.051
149,927.8
0.235
20.237
33.33
sko100e
149,150
149,212
0.042
24.928
149,376.4
0.152
19.902
33.33
sko100f
149,036
149,186
0.101
22.116
149,428.2
0.263
19.834
33.33
Average
0.034
14.942
0.119
13.967
27.026

142
R. Zamani and M. Amirghasemi
Table 4. Summarizing the performance of the SAFI, with that of DivTS, MSH, and
BMA on 53 real-life instances
Instances
SAFI
DivTS
MSH
BMAa
%DEVavg
T avg
%DEVavg
T avg
%DEVavg
T avg
%DEVavg
T avg
bur26a-h
0.000
0.08
0.000
0.52
0.000
1.30
0.000
0.01
els19
0.000
0.05
0.000
0.19
0.000
1.00
0.000
0.01
had12-20
0.000
0.00
0.000
0.32
0.000
0.80
0.000
0.00
chr12a-25a
0.000
0.14
0.093
0.50
0.000
0.89
0.000
0.03
kra30a-32
0.000
0.17
0.000
1.27
0.000
1.53
0.000
0.03
ste36a-c
0.011
0.99
0.000
2.26
0.000
1.80
0.000
0.05
esc16a-128
0.000
0.00
0.000
10.06
0.000
1.52
0.000
0.00
Average
0.002
0.204
0.013
2.159
0.000
1.264
0.000
0.018
aNote BMA results are averaged over 100 runs
Finally, Table 5 shows the comparison of the SAFI, PASS, CPTS, DivTS,
and ACO-GA/LS on Taillard and Skorin-Kapov instances. As is seen, the SAFI
outperforms PASS in terms of solution quality. Compared to CPTS,DivTS, and
ACO-GA/LS, the SAFI performs better on smaller instances. This could be
described by the fact that the SAFI, compared to other methods, has only
allowed a linear maximum allowed computation time for each run (Tmax = n
3 ).
The average computational time for other algorithms grows almost exponen-
tially with increasing the problem size. For instance, for the problems of size 100,
whereas the SAFI has only allowed a ﬁxed maximum running time of 33.3 min
for each run, CPTS, DivTS, and ACO-GA/LS has an average running time from
100 to over 300 min per run.
In eﬀect, while the SAFI has allowed a total maximum of 486.3 min for a
single run of all 21 Taillard and Skorin-Kapov instances, CPTS, DivTS, and
ACO-GA/LS have the average running times of 2723.2, 1175.9, and 2112.7 min
per run, respectively. It should be noted that, with respect to CPTS and DivTS,
this faster performance has been achieved at the expense of only 0.148 and
0.076% increase in the overall average percent deviation. As is seen, the overall
average percent deviation of the SAFI is 0.158% less than that of ACO-GA/LS,
indicating that the SAFI can achieve high performance in a reasonable amount
of computation time.

A Self-adaptive Nature-Inspired Procedure for Solving
143
Table 5. Comparing the performance of the SAFI with that of four metaheuristics on Taillard and Skorin-Kapov instances
Instances
SAFI
PASS
CPTS
DivTS
ACO-GA/LS
%DEVavg
T avg
T max
%DEVavg
T avg
%DEVavg
T avg
%DEVavg
T avg
%DEVavg
T avg
Taillard Instances
tai20a
0.000
0.1
6.7
0.000
0.2
0.000
0.1
0.000
0.2
–
–
tai25a
0.000
0.2
8.3
0.041
0.7
0.000
0.3
0.000
0.6
–
–
tai30a
0.000
0.4
10.0
0.181
1.6
0.000
1.6
0.000
1.3
0.341
1.4
tai40a
0.303
6.3
13.3
0.851
8.4
0.148
3.5
0.222
5.2
0.593
13.1
tai50a
0.715
9.5
16.7
1.324
11.8
0.440
10.3
0.725
10.2
0.901
29.7
tai60a
0.685
7.3
20.0
1.458
9.8
0.476
26.4
0.718
25.7
1.068
58.5
tai80a
0.987
14.6
26.7
1.524
17.9
0.570
94.8
0.753
52.7
1.178
152.2
tai100a
0.916
21.6
33.3
1.409
19.6
0.558
261.2
0.825
142.1
1.115
335.6
Average
0.451
7.5
16.9
0.849
8.7
0.274
49.8
0.405
29.8
0.866
98.4
Skorin-Kapov Instances
sko42
0.000
0.6
14.0
0.000
1.8
0.000
5.3
0.000
4.0
0.000
0.7
sko49
0.005
6.9
16.3
0.007
5.7
0.000
11.4
0.008
9.6
0.056
7.6
sko56
0.026
6.7
18.7
0.033
9.6
0.000
21.0
0.002
13.2
0.012
9.1
sko64
0.039
10.8
21.3
0.051
15.1
0.000
42.9
0.000
22.0
0.004
17.4
sko72
0.089
13.4
24.0
0.111
15.7
0.000
69.6
0.006
38.0
0.018
70.8
sko81
0.096
12.3
27.0
0.156
11.2
0.000
121.4
0.016
56.4
0.025
112.3
sko90
0.155
18.4
30.0
0.146
12.9
0.000
193.7
0.026
89.6
0.042
92.1
sko100a
0.159
19.4
33.3
0.164
12.2
0.000
304.8
0.027
129.2
0.021
171.0
sko100b
0.190
17.4
33.3
0.221
17.2
0.000
309.6
0.008
106.6
0.012
192.4
sko100c
0.136
15.8
33.3
0.113
19.2
0.000
316.1
0.006
126.7
0.005
220.6
sko100d
0.235
20.2
33.3
0.227
19.5
0.000
309.8
0.027
123.5
0.029
209.2
sko100e
0.152
19.9
33.3
0.182
11.2
0.000
309.1
0.009
108.8
0.002
208.1
sko100f
0.263
19.8
33.3
0.263
14.5
0.003
310.3
0.023
110.3
0.034
210.9
Average
0.119
14.0
27.0
0.129
12.8
0.000
178.8
0.012
72.1
0.020
117.1
Overall
0.285
10.7
22.0
0.489
10.8
0.137
114.3
0.209
50.9
0.443
107.8

144
R. Zamani and M. Amirghasemi
6
Concluding Remarks
The performance of metaheuristics is mainly inﬂuenced by the fashion they bal-
ance intensiﬁcation versus diversiﬁcation. Whereas diversiﬁcation conducts the
search into new regions of potentially high-quality solutions, intensiﬁcation pro-
visionally locks the search into promising areas by capitalizing on attributes
contributing to building high-quality solutions already encountered.
The conjecture that an extraordinary small part of the solution space com-
prises a large number of high-quality solutions indicates that any search method
capable of uniformly searching such a small area has some chance of ﬁnding
superior solutions. For uniformly searching such a small area, however, a search
procedure has no alternative except capitalizing on encountered high-quality
solutions by inclusive searching of their surroundings and avoiding cycles.
The SAFI has been established based on such notion. This has been per-
formed by employing a self-adaptive generation mechanism of cycles in a linear
assignment technique, facilitating interchanges to generate promising neighbors.
Being competitive with the best algorithms available for the QAP, the SAFI is a
candidate for further improvement. For this purpose, three promising directions
can be envisaged.
First, as a primal–dual approach, the SSP is quite sensitive as to how short-
est paths are found and how dual variables, represented as node potentials,
are updated. The FEQM, as the main component of the SAFI, can be further
enhanced so that it can more eﬀectively perform an interchange. In this direc-
tion, as well as using the reduced costs calculated in its previous rounds, the
FEQM can use extra memory to keep promising changes of a round to use it in
other rounds.
Second, to ensure consistent performance of the procedure in solving all
benchmark instances, the research can be extended by performing the sensi-
tivity analysis of its components and analyzing the eﬀect of each component on
the benchmark instances. After categorizing the benchmark instances based on
the performance of the procedure, the eﬀective components for each category of
benchmark instances can be identiﬁed. This can help a controller to activate dif-
ferent components for diﬀerent benchmark instances with diﬀerent parameters.
Third, the search process can be further directed toward unexplored regions
of solution space and contribute to diversiﬁcation at the cost of shifting focus
from intensiﬁcation, emphasizing on the repeated calls of the FEQM through
restarting and performing a more sophisticated interchange in a multi-start
schema. A prominent example in multi-starting schemes which, without dam-
aging intensiﬁcation, contributes to intensiﬁcation is double-bridging of Lin-
Kernighan procedure [32]. Since improving diversiﬁcation, if performed without
signiﬁcantly damaging intensiﬁcation, can enhance overall results, it is expected
that such improvement can increase the performance of the SAFI signiﬁcantly.

A Self-adaptive Nature-Inspired Procedure for Solving
145
References
1. Ahuja R, Jha K, Orlin J, Sharma D (2007) Very large-scale neighborhood search for
the quadratic assignment problem. INFORMS Journal on Computing 19(4):646–
657
2. Ahuja R, Orlin J, Tiwari A (2000) A greedy genetic algorithm for the quadratic
assignment problem. Computers & Operations Research 27(10):917–934
3. Amirghasemi M, Zamani R (2018) An eﬀective structural iterative reﬁnement tech-
nique for solving the quadratic assignment problem. In: Cerulli R, Raiconi A, Voß S
(eds) Computational Logistics. Springer International Publishing, Cham, pp 446–
460
4. Amirghasemi, M., Zamani, R.: Developing an eﬀective decomposition-based pro-
cedure for solving the quadratic assignment problem. In: Paternina-Arboleda, C.,
Voß, S. (eds.) Computational logistics. Springer International Publishing, Cham,
pp 297–316
5. Arkin E, Hassin R, Sviridenko M (2001) Approximating the maximum quadratic
assignment problem. Information Processing Letters 77(1):13–16
6. Baykasoˇglu A (2004) A meta-heuristic algorithm to solve quadratic assignment
formulations of cell formation problems without presetting number of cells. Journal
of Intelligent Manufacturing 15(6):753–759
7. Benlic U, Hao JK (2015) Memetic search for the quadratic assignment problem.
Expert Systems with Applications 42(1):584–595. https://doi.org/10.1016/j.eswa.
2014.08.011
8. Burkard RE, Karisch SE, Rendl F (1997) Qaplib-a quadratic assignment problem
library. Journal of Global Optimization 10(4):391–403
9. Cartwright, H.M., Mott, G.F.: Looking around: Using clues from the data space
to guide genetic algorithm searches. In: Proceedings of the Fourth International
Conference on Genetic Algorithms. pp. 108–114 (1991)
10. Connolly D (1990) An improved annealing scheme for the qap. European Journal
of Operational Research 46(1):93–100
11. De Abreu N, Querido TM, Boaventura-Netto P (1999) Redinv-sa: la simulated
annealing for the quadratic assignment problem. RAIRO-Operations Research
33(03):249–273
12. Demirel N, Toksarı M (2006) Optimization of the quadratic assignment problem
using an ant colony algorithm. Applied Mathematics and Computation 183(1):427–
435
13. Dokeroglu T, Cosar A (2016) A novel multistart hyper-heuristic algorithm on the
grid for the quadratic assignment problem. Engineering Applications of Artiﬁcial
Intelligence 52:10–25. https://doi.org/10.1016/j.engappai.2016.02.004
14. Dorigo M, Gambardella LM (1997) Ant colony system: A cooperative learning
approach to the traveling salesman problem. IEEE Transactions on Evolutionary
Computation 1(1):53–66
15. Drezner Z (2002) Heuristic algorithms for the solution of the quadratic assignment
problem. Journal of Applied Mathematics and Decision Sciences 6:163–173
16. Drezner Z (2003) A new genetic algorithm for the quadratic assignment problem.
Informs Journal on Computing 15(3):320–330
17. Drezner Z (2005) Compounded genetic algorithms for the quadratic assignment
problem. Operations Research Letters 33(5):475–480
18. Feo TA, Resende MGC (1995) Greedy randomized adaptive search procedures.
Journal of Global Optimization 6(2):109–133

146
R. Zamani and M. Amirghasemi
19. Gambardella L, Taillard E, Dorigo M (1999) Ant colonies for the quadratic assign-
ment problem. Journal of the Operational Research Society 50(2):167–176
20. Gilmore PC (1962) Optimal and suboptimal algorithms for the quadratic assign-
ment problem. Journal of the Society for Industrial & Applied Mathematics
10(2):305–313
21. Glover F (1989) Tabu search - part i. ORSA journal on computing 1(3):190–206
22. Glover F (1990) Tabu search - part ii. ORSA journal on computing 2(1):4–32
23. Gutin G, Yeo A (2002) Polynomial approximation algorithms for the tsp and
the qap with a factorial domination number. Discrete Applied Mathematics
119(1):107–116
24. Haghani A, Chen MC (1998) Optimizing gate assignments at airport terminals.
Transportation Research Part A: Policy and Practice 32(6):437–454. https://doi.
org/10.1016/S0965-8564(98)00005-6
25. Jagatheesan K, Anand B, Samanta S, Dey N, Ashour AS, Balas VE (2017) Par-
ticle swarm optimisation-based parameters optimisation of pid controller for load
frequency control of multi-area reheat thermal power systems. International Jour-
nal of Advanced Intelligence Paradigms 9(5–6):464–489. https://doi.org/10.1504/
IJAIP.2017.088143
26. James T, Rego C, Glover F (2009) A cooperative parallel tabu search algorithm
for the quadratic assignment problem. European Journal of Operational Research
195(3):810–826. https://doi.org/10.1016/j.ejor.2007.06.061
27. James T, Rego C, Glover F (2009) Multistart tabu search and diversiﬁcation strate-
gies for the quadratic assignment problem. IEEE Transactions on Systems, Man
and Cybernetics, Part A: Systems and Humans 39(3):579–596
28. Kirkpatrick S, Gelatt CD, Vecchi MP (1983) Optimization by simulated annealing.
Science 220:671–680
29. Koopmans, T., Beckmann, M.: Assignment problems and the location of economic
activities. Econometrica: Journal of the Econometric Society pp. 53–76 (1957)
30. Lee, Y., Orlin, J.: Quickmatch: a very fast algorithm for the assignment prob-
lem. Report, Massachusetts Institute of Technology, Sloan School of Management
(Report number: WP#3547-93) (1993)
31. Li Y, Pardalos P, Resende M (1994) A greedy randomized adaptive search pro-
cedure for the quadratic assignment problem. Quadratic assignment and related
problems 16:237–261
32. Lin S, Kernighan B (1973) An eﬀective heuristic algorithm for the traveling sales-
man problem. Operations Research 21:443–452
33. Loiola EM, de Abreu NMM, Boaventura-Netto PO, Hahn P, Querido T (2007)
A survey for the quadratic assignment problem. European Journal of Operational
Research 176(2):657–690. https://doi.org/10.1016/j.ejor.2005.09.032
34. Lourenco, H., Martin, O., St¨utzle, T.: Iterated local search. Handbook of meta-
heuristics pp. 320–353 (2003)
35. Maniezzo V, Colorni A (1999) The ant system applied to the quadratic assignment
problem. IEEE Transactions on Knowledge and Data Engineering 11(5):769–778
36. Martin O, Otto S (1996) Combining simulated annealing with local search heuris-
tics. Annals of Operations Research 63(1):57–75
37. Martin OC, Otto SW, Felten EW (1991) Large-step markov chains for the traveling
salesman problem. Complex Systems 5:219–224
38. Mavridou T, Pardalos P (1997) Simulated annealing and genetic algorithms for the
facility layout problem: A survey. Computational optimization and Applications
7(1):111–126

A Self-adaptive Nature-Inspired Procedure for Solving
147
39. Misevicius A (2005) A tabu search algorithm for the quadratic assignment problem.
Computational optimization and Applications 30(1):95–111
40. Moscato, P.: On evolution, search, optimization, genetic algorithms and martial
arts: Towards memetic algorithms. Caltech Concurrent Computation Program,
C3P Report 826, 1989 (1989)
41. Nugent C, Vollmann T, Ruml J (1968) An experimental comparison of techniques
for the assignment of facilities to locations. Operations Research 16(1):150–173
42. Oliveira, C., Pardalos, P., Resende, M.: Grasp with path-relinking for the quadratic
assignment problem. Experimental and Eﬃcient Algorithms pp. 356–368 (2004)
43. Pardalos, P., Pitsoulis, L., Resende, M.: A parallel grasp implementation for the
quadratic assignment problem. In: Ferreira, A., Rolim, J.D. (eds.) Parallel Algo-
rithms for Irregular Problems: State of the Art, pp. 115–133. Springer US (1995).
10.1007/978-1-4757-6130-6-6
44. Rego C, James T, Glover F (2010) An ejection chain algorithm for the quadratic
assignment problem. Networks 56(3):188–206
45. Sahni S, Gonzalez T (1976) P-complete approximation problems. Journal of the
ACM (JACM) 23(3):555–565
46. Sarker B, Wilhelm W, Hogg G (1998) One-dimensional machine location prob-
lems in a multi-product ﬂowline with equidistant locations. European Journal of
Operational Research 105(3):401–426
47. Satapathy, S.C., Sri Madhava Raja, N., Rajinikanth, V., Ashour, A.S., Dey, N.:
Multi-level image thresholding using otsu and chaotic bat algorithm. Neural Com-
puting and Applications 29(12), 1285–1307 (Jun 2018). 10.1007/s00521-016-2645-5
48. Solimanpur M, Vrat P, Shankar R (2004) Ant colony optimization algorithm to
the inter-cell layout problem in cellular manufacturing. European Journal of Oper-
ational Research 157(3):592–606
49. Steinberg L (1961) The backboard wiring problem: A placement algorithm. Siam
Review 3(1):37–50
50. St¨utzle, T.: Iterated local search for the quadratic assignment problem. European
Journal of Operational Research 174(3), 1519–1539 (2006)
51. Taillard E (1991) Robust taboo search for the quadratic assignment problem. Par-
allel Computing 17(4–5):443–455. https://doi.org/10.1016/S0167-8191(05)80147-
4
52. Talbi EG, Roux O, Fonlupt C, Robillard D (2001) Parallel ant colonies for the
quadratic assignment problem. Future Generation Computer Systems 17(4):441–
449. https://doi.org/10.1016/S0167-739X(99)00124-7
53. Tate D, Smith A (1995) A genetic approach to the quadratic assignment problem.
Computers & Operations Research 22(1):73–83
54. Tseng LY, Chen SC (2006) A hybrid metaheuristic for the resource-constrained
project scheduling problem. European Journal of Operational Research 175(2):707–
721
55. Yang, X.S.: Nature-inspired metaheuristic algorithms. Luniver press (2010)
56. Yu J, Sarker B (2003) Directional decomposition heuristic for a linear machine-cell
location problem. European Journal of Operational Research 149(1):142–184

Modiﬁed Binary Grey Wolf Optimizer
Gustavo Rebello(B) and Edimar Jos´e de Oliveira
Department of Eletrical Energy, Federal University at Juiz de Fora, Juiz de Fora,
MG, Brazil
{gustavo.rebello,edimar.joliveira}@engenharia.ufjf.br
1
Introduction
A robust and reliable energy transmission system plays a key role in the
socio-economic development of a nation. In large-sized countries such as Brazil
and the USA, for example, the energy generation can occur far away from the
load demand centres. In order to guarantee that the increasing power demand
is met, it is important to plan the expansion of transmission systems in an opti-
mal manner. This ﬁeld of research is known as transmission network expansion
planning (TNEP), and its main goal is to supply the power demand at minimal
investment costs and respect technical constraints, such as maximum allowable
power ﬂow on the transmission lines, network losses, among others [1,2].
Some characteristics of the TNEP problem are:
1. Non-convex solution space, with multiple local minima;
2. Combinatorial nature;
3. Integer and nonlinear variables, characterizing it as a mixed integer nonlinear
programming (MINLP) problem.
In light of the characteristics presented above, several works have been devel-
oped to obtain the optimal set of transmission reinforcements [3]. Many of
these works applied meta-heuristic optimization methods, with highlights going
to the nature-inspired techniques. Such techniques are based on the successful
behaviour of biological systems [4], such as particle swarm optimization (PSO)
[5–7], ﬁreﬂy optimization (FO) [8], evolutionary algorithm (EA) [9], genetic algo-
rithms (GA) [10], bat algorithm (BA) [11–13], bee colony algorithms (BC) [14],
social spider algorithms (SSA) [15], among others. These methods ease of imple-
mentation, as well as good adaptability [4] to solve this sort of NP-hard combi-
natorial problem, explain the reason why so many works in the literature deal
with solving the TNEP problem by using meta-heuristic approaches.
In addition to the swarm intelligence algorithms, Darwinian and Mendelian
approaches have also played an important role in this ﬁeld of research. The
principles of Darwinian evolution for solving optimization problems have been
reiterated in genetic algorithms (GA) [16–18]. A very recent variation of GA
implies Mendelian evolution on multi-species as inspired from plants biology
[19] incorporating the use of double-strand DNA for evolution.
c
⃝Springer Nature Singapore Pte Ltd. 2020
M. Khosravy et al. (eds.), Frontier Applications of Nature Inspired Computation,
Springer Tracts in Nature-Inspired Computing,
https://doi.org/10.1007/978-981-15-2133-1_7

Modiﬁed Binary Grey Wolf Optimizer
149
In this chapter, the authors present the application of the meta-heuristic
known as grey wolf optimizer [20] to solve the TNEP problem. Diﬀerently from
most computational intelligence techniques, the GWO uses information from
the three best solutions obtained throughout the process to guide its searching
mechanism. The GWO is a population-based optimization algorithm that has
its origin in the hunting and hierarchical behaviour of grey wolves. Originally,
the GWO algorithm was designed to solve continuous optimization problems,
however, the TNEP problem is of binary nature. Thus, the authors propose two
modiﬁcations in the original GWO, as follows:
1. To convert continuous variables into binary values, the proposed algorithm
uses a sigmoid transfer function;
2. To improve the local searching component of the algorithm, the authors pro-
pose a modiﬁcation which resulted in a better performance with respect to
the conventional GWO approach.
These modiﬁcations will be explained in the subsequent sections. Also, the
proposed modiﬁed binary grey wolf optimizer (MBGWO) will be used to solve
two well-known test systems from the literature and its results will be compared
to the original version of the algorithm and to other algorithms in the specialized
literature.
1.1
Chapter Structure
The TNEP formulation and the description of the test systems used in this work
are detailed in Sect. 2. In Sect. 3, the original version of the GWO algorithm is
detailed, as well as the proposed modiﬁcations made by the authors. Beneﬁts
over the traditional version of the GWO algorithm, as well as comparisons to the
literature, are presented in Sect. 4. A conclusion and future works are presented
in Sect. 5.
2
Transmission Network Expansion Planning Problem
Formulation
The well-known TNEP problem is a nonlinear integer program and its objective
function and restrictions are modelled from (1) to (11) where active transmission
losses are considered:
Min
nr

m=1
cm · rm +
nc

n=1
cn · EPn
(1)
subject to:
gi + ri +

j∈Ωi
fij = di
(2)
|fij| ≤f ij, ∀(i, j) ∈ΩE, ΩC
(3)

150
G. Rebello and E. J. de Oliveira
0 ≤gi ≤gi
(4)
0 ≤ri ≤ri
(5)
EPn ∈[0, 1], ∀n ∈ΩC
(6)
fij = γijθij + 1
2 · gijθ2
ij, ∀(i, j) ∈ΩE
(7)
fij = γijFIC · ϕij, ∀(i, j) ∈ΩF
(8)
fij = EPk · (γijθij + 1
2 · gijθ2
ij), ∀(i, j) ∈ΩC
(9)
ϕ ≫fij
γij
, ∀(i, j) ∈ΩF
(10)
γij ≫γijFIC, ∀(i, j) ∈ΩF
(11)
where:
nr
Number of ﬁctitious generators;
cm
Energy deﬁcit cost (US$/MW);
rm
Deﬁcit generation (MW);
nc
Number of candidate transmission lines;
cn
Investment cost of the candidate transmission line n (US$);
EPn
Binary expansion parameter associated to the line n;
gi
Active power generation at busbar i (MW);
gi
Maximum allowable active power generation at busbar i (MW);
ri
Active power generation of the ﬁctitious generator at busbar i (MW);
ri
Maximum allowable ﬁctitious active power generation at busbar i (MW);
di
Consumers power demand at busbar i (MW);
fij
Active power ﬂow of existing or candidate transmission line i −j (MW);
fij
Active power ﬂow limit of existing or candidate transmission line i −j;
γij
Susceptance of existing or candidate transmission line ij;
gij
Conductance of existing or candidate transmission line ij;
γijFIC Susceptance of ﬁctitious transmission line ij;
θij
Angular diﬀerence between busbars ij;
ϕij
Angular diﬀerence of ﬁctitious lines between busbars ij;
ΩE
Group of existing transmission lines;
ΩC
Group of candidate transmission lines;
ΩF
Group of ﬁctitious transmission lines.
The objective function, given by (1), minimizes the sum of investment
costs in transmission lines and the energy deﬁcit cost. The deﬁcit cost can be

Modiﬁed Binary Grey Wolf Optimizer
151
interpreted as a ﬁctitious active power generation of extremely high operational
cost. Equation (2) represents the active power ﬂow in the branch i −j to meet
the consumers demand at busbar i. Equations (3), (4) and (5) are the limits of
active power ﬂow on existing and candidate lines, maximum active power gen-
eration at busbar i and maximum ﬁctitious active power generation at busbar
i, respectively.
The TNEP problem consists of determining the best set of candidate lines
to meet the consumers demand at a minimum cost without load shedding. The
expansion parameter (EP), therefore, is the line-building decision variable. If
EPn = 1, the line n is built, and if EPn = 0, the line n is not built. This
constraint is represented in (6). In the proposed model, there are three sets of
lines: the lines in the existing topology, the candidate lines and the ﬁctitious lines,
created to avoid mathematical problems related to the existence of isolated buses
on the system. Equations (7), (8) and (9) model the active power ﬂow through
existing, ﬁctitious and candidate lines, respectively.
In this work, the electric power transmission network is represented by a
linearized load ﬂow direct current (DC) model. The DC model is widely used to
perform power ﬂux calculations for the STNEP problem, [21–23] since it gives
a reasonable approach with low computational eﬀort. The author’s proposed
approach also includes the transmission losses, usually neglected when using the
DC model.
2.1
Test Systems
The proposed MBGWO algorithm was tested in two well-known test systems
from the literature: the Garver system and the IEEE-24 bus system.
2.1.1
Test System 1: Garver System The Garver system, proposed in [24],
is composed of 6 buses, 6 circuits in the existing topology, 15 candidate routes
for expansion, at which up to 3 circuits can be built, resulting in a total of
245 possible investment combinations, and a forecast demand of 760 MW. Even
though this is a small-sized system, it illustrates one of the greatest challenges
in the TNEP problem, related to the existence of isolated buses, such as bus
number 6 as shown in Fig. 1.
2.1.2
Test System 2: IEEE-24 Bus System The IEEE-24 bus system,
shown in Fig. 2, is composed of 24 buses, 38 circuits in the existing topology, 41
candidate transmission lines for expansion, where up to 3 circuits can be built
for each route. Also, the system has 10 generating units and an expected load
demand of 8550 MW. The total number of possible investment combinations is
of 2123, showing that the solution of this system through techniques such as
exhaustive searching is prohibitive.

152
G. Rebello and E. J. de Oliveira
Fig. 1. Garver system
3
Grey Wolf Optimizer
The GWO is a bio-inspired meta-heuristic presented by Mirjalili, Mirjalili and
Lewis [20] in 2014 that mathematically models the hunting and social behaviour
of grey wolves to solve optimization problems. Grey wolves generally live on a
pack that is basically composed of four types of wolves: alpha (α), beta (β),
delta (δ) and omega (ω).
Figure 3 shows the hierarchy chain in a pack. The leading and most domi-
nant wolves in a pack are the alphas, being responsible for making major deci-
sions for the rest of the pack, such as determining where to sleep and hunt,
time to wake up and so on. Second in hierarchy, the beta wolves assist the
alphas in controlling the rest of the pack by reinforcing the alpha’s orders and
providing feedback, as well as helping in the decision-making process. Also,
the beta wolves are the main candidates to replace the alphas in the future.
Third in hierarchy, the delta wolves dominate the omega, and they are repre-
sented by sentinels, scouts, elders, hunters and caretakers. Last in hierarchy, the
omega wolves play the role of scapegoat. They submit to all other wolves in the
pack and play a key role on maintaining the peace in the pack and dominance
structure.

Modiﬁed Binary Grey Wolf Optimizer
153
Fig. 2. IEEE-24 bus system
The hunting strategy of grey wolves is divided in three steps, as follows:
1. Tracking, chasing and approaching the prey;
2. Chasing and encircling until stationary situation;
3. Attacking the prey.
Fig. 3. Grey wolves hierarchy. Level of dominance increases from bottom to top

154
G. Rebello and E. J. de Oliveira
3.1
Continuous GWO
Originally, the GWO algorithm was designed to solve continuous optimiza-
tion problems. In the optimization context, the three best candidate solutions
obtained by the algorithm are depicted by the α, β and δ wolves. These solu-
tions are used in the algorithm to dictate the searching process. The remaining
solutions are called ω, and over the course of iterations, they encircle the α, β
and δ wolves in order to attempt to reach better solutions.
The encircling behaviour is modelled from (12) to (15):
−→
X t+1 = −→
Xp
t −−→
A · −→
D
(12)
where t depicts the current iteration and −→
Xp represents the dominant wolf (α,
β or δ). Coeﬃcients −→
A and −→
D enable the algorithm to perform local or global
search during the position’s update in the search space and are obtained as
follows:
−→
A = 2−→a t · −→
r1 −−→a t
(13)
−→
D = |−→
C · −→
Xp
t −−→
X t|
(14)
The exploration coeﬃcient −→a t linearly decreases from 2 to 0 over the course
of the t iterations, and its behaviour is shown in Fig. 4.
0
10
20
30
40
50
60
70
80
90
100
Iteration
0
2
Fig. 4. Exploration coeﬃcient
As for the coeﬃcient −→
C , that is obtained by using Eq. 15, its value attenuates
or increases the magnitude of the best solution during the searching mechanism.
Vectors −→
r1 and −→
r2 are randomly distributed values ∈[0,1] and help the algorithm
to avoid stagnation at local minima.
−→
C = 2 · −→
r2
(15)
As stated in [20] and depicted in Fig. 5, the algorithm performs local search,
i.e. attacks the prey, if |−→
A| < 1, and global search, i.e. searches for other preys, if

Modiﬁed Binary Grey Wolf Optimizer
155
|−→
A| > 1. Figure 6 shows the encircling behaviour of GWO and how the position
of a ω wolf is estimated over the course of iterations.
   
 
 
  
 
 
Fig. 5. Local and global searching components of GWO
In nature, the hunting process is commonly guided by the α. However, in the
optimization context, the location of the optimal solution (prey) can be hard
to obtain. Thus, following this line of thinking, the GWO algorithm uses the
information of the three best solutions obtained during the optimization process
(Xα, Xβ and Xδ, respectively) to guide the search. Hence, all remaining wolves
in the pack update their position in the search space taking into account the
position of the three dominant wolves, as deﬁned in (16):
−→
X t+1 =
−→
X1 + −→
X2 + −→
X3
3
(16)
The values of −→
X1, −→
X2 and −→
X3 are deﬁned in (17)–(19):
−→
X1 = |−→
Xα −−→
A1 · −→
Dα|
(17)
−→
X2 = |−→
Xβ −−→
A2 · −→
Dβ|
(18)
−→
X3 = |−→
Xδ −−→
A3 · −→
Dδ|
(19)
The position of the three best search agents at iteration t is depicted by Xα,
Xβ and Xδ, −→
A1, −→
A2 and −→
A3 are obtained as in (13) and −→
Dα, −→
Dβ and −→
Dδ are
obtained as follows:
−→
Dα = |−→
C1 · −→
Xα −−→
X|
(20)

156
G. Rebello and E. J. de Oliveira
Fig. 6. Encircling behaviour and position estimate
Algorithm 1 Continuous Grey Wolf Optimizer
1: Initialize Wolves Population: (Xi, with i = 1, 2, ...Nwolves)
2: Evaluate Pack: OBF(Xi)
3: Deﬁne Hierarchy: (Xα, Xβ, Xδ)
4: While stopping criteria not met, do:
5:
Update searching parameter −→a t
6:
For each wolf ∈(i = 1, 2, ...Nwolves) do:
7:
−→
A = 2−→a t · −→
r1 −−→a t,
−→
r1 ∈[0, 1]
8:
−→
C = 2 · −→
r2,
−→
r2 ∈[0, 1]
9:
−→
Dα = |−→
C1 · −→
Xα
t −−→
Xi
t|,
−→
Dβ = |−→
C2 · −→
Xβ
t −−→
Xi
t|,
−→
Dδ = |−→
C3 · −→
Xδ
t −−→
Xi
t|
10:
−→
X1 = |−→
Xα
t −−→
A1 · −→
Dα|,
−→
X2 = |−→
Xβ
t −−→
A2 · −→
Dβ|,
−→
X3 = |−→
Xδ
t −−→
A3 · −→
Dδ|
11:
−→
Xi
t+1 =
−→
X1+−→
X2+−→
X3
3
12:
Evaluate Pack and Update Hierarchy: (Xα, Xβ, Xδ)
13:
end For
14: end While
15: Return Xα

Modiﬁed Binary Grey Wolf Optimizer
157
−→
Dβ = |−→
C2 · −→
Xβ −−→
X|
(21)
−→
Dδ = |−→
C3 · −→
Xδ −−→
X|
(22)
In Algorithm 1, a pseudo-code of the GWO algorithm is presented. At ﬁrst, a
random wolves population composed of Nwolves is created and evaluated through
an objective function (OBF). Then, the hierarchy is established and the iterative
process starts, using Eqs. (12)–(22) until a stopping criteria is met. At the end
of the iterative process, the best solution Xα is returned.
3.2
Binary Grey Wolf Optimizer
In the continuous version of GWO, the solutions are allowed to change their
position in a continuous spectrum in the searching space, following Eqs. (12)–
(22). However, as explained and modelled in Sect. 2, the TNEP is a MINLP
problem, with solutions restricted to binary {0,1} values. Some works in the
literature have adapted GWO to solve binary optimization problems. In this
chapter, the authors make use of the solutions applied in [25] and [26], that
use a sigmoid transfer function to force the updated solutions obtained by
Eq. (16) to be binary values. This sigmoid transfer function is depicted in Eq. (23)
and plotted in Fig. 7. The updated binary position −→
X bin at iteration t + 1 is
obtained in Eq. (24), where rand is an uniform distributed random number
∈[0,1], which can be diﬀerent for diﬀerent iterations, increasing the random-
ness in the algorithms searching procedure, thus enabling it to avoid local min-
ima.
sigmoid(x) =
1
1 + e−10(x−0.5)
(23)
where x =
−→
X 1 + −→
X 2 + −→
X 3
3
−→
X t+1
bin =

1, if sigmoid (x) ≥rand
0, otherwise
(24)
Another modiﬁcation proposed by the authors is related to the exploration
coeﬃcient −→a t. Instead of decreasing its value from 2 to 0, as originally proposed
in [20], the authors propose decreasing its value from 1 to 0, as depicted in Fig. 8,
in order to better handle the binary nature of the problem.
The proposed modiﬁcations are demonstrated in Algorithm 2. Line 7 depicts
the proposed modiﬁcation in the exploration parameter −→a t, and lines 11–12
introduce the sigmoid transfer function.

158
G. Rebello and E. J. de Oliveira
Algorithm 2 Binary Grey Wolf Optimizer (BGWO)
1: Initialize Wolves Population: (Xi, with i = 1, 2, ...Nwolves)
2: Evaluate Pack: OBF(Xi)
3: Deﬁne Hierarchy: (Xα, Xβ, Xδ)
4: While stopping criteria not met, do:
5:
Update searching parameter −→a t
6:
For each wolf ∈(i = 1, 2, ...Nwolves) do:
7:
−→
A = −→a t · −→
r1 −−→a t,
−→
r1 ∈[0, 1]
8:
−→
C = 2 · −→
r2,
−→
r2 ∈[0, 1]
9:
−→
Dα = |−→
C1 · −→
Xα
t −−→
Xi
t|,
−→
Dβ = |−→
C2 · −→
Xβ
t −−→
Xi
t|,
−→
Dδ = |−→
C3 · −→
Xδ
t −−→
Xi
t|
10:
−→
X1 = |−→
Xα
t −−→
A1 · −→
Dα|,
−→
X2 = |−→
Xβ
t −−→
A2 · −→
Dβ|,
−→
X3 = |−→
Xδ
t −−→
A3 · −→
Dδ|
11:
sigmoid(x) =
1
1+e−10(x−0.5) ,
where x =
−→
X1+−→
X2+−→
X3
3
12:
−→
X t+1
bin =

1, if sigmoid (x) ≥rand
0, otherwise
13:
Evaluate Pack and Update Hierarchy: (Xα, Xβ, Xδ)
14:
end For
15: end While
16: Return Xα
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
1
Fig. 7. Sigmoid transfer function
3.3
Modiﬁed Binary Grey Wolf Optimizer
Swarm intelligence-based algorithms have proven themselves as a great tool to
solve optimization problems. However, one of the greatest challenges faced by
these algorithms is related to local optima stagnation after a certain number of

Modiﬁed Binary Grey Wolf Optimizer
159
0
10
20
30
40
50
60
70
80
90
100
Iteration
0
1
Fig. 8. Exploration coeﬃcient
iterations. In order to avoid stagnation and obtain better results, several works in
the literature are making modiﬁcations in the original version of meta-heuristics.
Within the scope of the GWO, this is no diﬀerent: in [27] and [28], a nonlinear
adjustment of the exploration coeﬃcient −→a t is proposed. Also, in [27] and in [29],
the authors use the technique of opposition-based learning to obtain a better set
of initial solutions for the problems under study. Finally, in [30], the authors
propose the use of chaotic maps to update parameters −→
A, −→
C and −→a t to explore
the search space in a more dynamical fashion.
In this chapter, the authors propose a simple modiﬁcation in the local search-
ing component of the GWO algorithm suited to obtain better results for the
TNEP problem. The modiﬁcations consist on four steps:
• Temporary solution creation;
• Temporary solution disturbance;
• Temporary solution reﬁnement;
• Temporary solution evaluation and comparison.
The pseudo-code of the proposed MBGWO is shown in Algorithm 3, at which
lines 13–21 represent the proposed modiﬁcations. Figures 9 and 10 depict an
example of a ﬁctitious topology that up to 10 transmission lines can be built
and will be used as a tutorial system to explain the steps of solutions creation
and disturbance.
When the algorithm performs the local search, i.e. at the last iterations, a
temporary solution named Xtemp is created. This temporary wolf is created by
randomly replacing the current Xω under evaluation by one of the three best
solutions (Xα, Xβ or Xδ) obtained over the course of iterations. In Algorithm 3,
this is shown in line 14.
In Fig. 9, the temporary solution creation is presented for a case at which the
Xω topology under evaluation was replaced by the Xα topology.
After creating the temporary solution based on a dominant wolf topology, the
next step in the proposed MBGWO is to disturb this solution. The disturbance
process shown in line 15 of Algorithm 3 happens in the following manner: ﬁrst,
a percentage of the total number of candidate transmission lines for expansion

160
G. Rebello and E. J. de Oliveira
is set to be modiﬁed. Figure 10 illustrates the case at which 30% of the tem-
porary topology was selected to be disturbed. The exact positions, i.e. indices
of the candidate solution vector to be modiﬁed, are randomly drawn for each
temporary solution. In Fig. 10, positions 1, 4 and 10 were disturbed, resulting
in the topology named ˜Xtemp. It can be seen that the disturbed topology ˜Xtemp
ended up with one transmission line less than in the original temporary topology
Xtemp. However, since Xtemp came from one of the three best topologies, it is
important that the number of transmission lines in the disturbed solution ˜Xtemp
matches the number of transmission lines in Xtemp, to avoid load shedding or
over investment.
To solve this problem, the diﬀerence in the number of transmission lines
between ˜Xtemp and Xtemp is calculated and used as an input to reﬁne the solution
to be evaluated, i.e. to match the number of transmission lines at the topologies.
The reﬁned solution is called ˆXtemp.
At last, ˆXtemp is evaluated and compared to Xα, Xβ and Xδ. If an improve-
ment is observed, the pack is updated considering the reﬁned solution. On the
other hand, if no improvement is observed, the reﬁned solution is discarded and
the process restarts.
Xω 
Xα 
Xα 
Xα 
XTEMP
Xβ 
Xβ 
Xβ 
Xδ 
Xδ 
Xδ 
Random selection
(Xα, Xβ or Xδ)
Fig. 9. Temporary solution creation

Modiﬁed Binary Grey Wolf Optimizer
161
Disturbance 
XTEMP
~XTEMP
~
Refinement
66
5
-1
-1
6
Solution to be evaluated 
through the OBF 
XTEMP
XTEMP
^XTEMP
^
Fig. 10. Temporary solution disturbance and reﬁnement
4
Results and Discussion
As previously mentioned, in Sect. 2, the proposed MBGWO algorithm was imple-
mented in two well-known test systems: Garver system and IEEE-24 bus system.
For both test systems, a comparison between the results obtained by the
BGWO technique, shown in Algorithm 2 and by the proposed MBGWO app-
roach, depicted in Algorithm 3 is presented.
A total of 100 simulations were performed for each test system, and the
number of iterations was the stopping criteria adopted by the authors. The
authors present the results obtained for a maximum number of 10, 20, 30, 40, 50
and 100 iterations. All simulations were obtained by using on a Intel R
⃝CoreTM
i5-4210U CPU, 1.70 GHz, 6GB RAM, using MATLAB programming language.
Convergence curves, box plots and tables are used to present the results and
demonstrate the improvement provided by the MBGWO over the traditional
BGWO version.
4.1
Test Systems Analysis
For both test systems, it can be observed that for all iteration scenarios, the
proposed MBGWO obtained lower mean values, meaning that, for most sim-
ulations, the MBGWO obtained better plannings with respect to the BGWO.
Also, it can be observed from Tables 1 and 2 that the results obtained by the
proposed MBGWO had lower dispersion, shown through the lower values of
standard deviation (STD) calculated.

162
G. Rebello and E. J. de Oliveira
Algorithm 3 Modiﬁed Binary Grey Wolf Optimizer (MBGWO)
1: Initialize Wolves Population: (Xi, with i = 1, 2, ...Nwolves)
2: Evaluate Pack: OBF(Xi)
3: Deﬁne Hierarchy: (Xα, Xβ, Xδ)
4: While stopping criteria not met, do:
5:
Update searching parameter −→a t
6:
For each wolf ∈(i = 1, 2, ...Nwolves) do:
7:
−→
A = −→a t · −→
r1 −−→a t,
−→
r1 ∈[0, 1]
8:
−→
C = 2 · −→
r2,
−→
r2 ∈[0, 1]
9:
−→
Dα = |−→
C1 · −→
Xα
t −−→
Xi
t|,
−→
Dβ = |−→
C2 · −→
Xβ
t −−→
Xi
t|,
−→
Dδ = |−→
C3 · −→
Xδ
t −−→
Xi
t|
10:
−→
X1 = |−→
Xα
t −−→
A1 · −→
Dα|,
−→
X2 = |−→
Xβ
t −−→
A2 · −→
Dβ|,
−→
X3 = |−→
Xδ
t −−→
A3 · −→
Dδ|
11:
sigmoid(x) =
1
1+e−10(x−0.5) ,
where x =
−→
X1+−→
X2+−→
X3
3
12:
−→
X t+1
bin =

1, if sigmoid (x) ≥rand
0, otherwise
13:
If local search, do:
14:
Create temporary solution −→
X temp ←Xα, Xβ or Xδ
15:
Disturb temporary solution
16:
Reﬁne temporary solution
17:
If temporary solution is better do:
18:
Update Pack considering this solution
19:
Else
20:
Discard temporary solution
21:
end If
22:
Evaluate Pack and Update Hierarchy: (Xα, Xβ, Xδ)
23:
end For
24: end While
25: Return Xα
Figures 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21 and 22 depict the conver-
gence curves for all scenarios for both algorithms, and it can be seen that both
methodologies tend to converge to the optimal solution within the ﬁrst iterations
for all scenarios and for both systems, proving itself to be a good approach to
solve the TNEP problem. However, since the proposed MBGWO performs more
objective functions evaluations with respect to the classic BGWO, it presents
higher mean computational times for both test systems.
A statistical analysis of the results obtained can also be made by observing
Figs. 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33 and 34. For both test systems, it
can be seen that the proposed MBGWO provided less dispersed results, with

Modiﬁed Binary Grey Wolf Optimizer
163
0
1
2
3
4
5
6
7
8
9
10
Iterations
100
150
200
250
300
350
400
450
500
OBF (M$)
Best BGWO
Mean BGWO
Best MBGWO
Mean MBGWO
Fig. 11. Garver: 10 iterations
0
2
4
6
8
10
12
14
16
18
20
Iterations
100
150
200
250
300
350
400
450
500
OBF (M$)
Best BGWO
Mean BGWO
Best MBGWO
Mean MBGWO
Fig. 12. Garver: 20 iterations
fewer outliers, especially for the Garver system. As for the IEEE-24 bus system,
it can be seen that the proposed MBGWO provided lower median values for all
scenarios simulated, indicating that better plannings were obtained using this
methodology.

164
G. Rebello and E. J. de Oliveira
0
5
10
15
20
25
30
Iterations
100
150
200
250
300
350
400
450
500
OBF (M$)
Best BGWO
Mean BGWO
Best MBGWO
Mean MBGWO
Fig. 13. Garver: 30 iterations
0
5
10
15
20
25
30
35
40
Iterations
100
150
200
250
300
350
400
450
500
OBF (M$)
Best BGWO
Mean BGWO
Best MBGWO
Mean MBGWO
Fig. 14. Garver: 40 iterations

Modiﬁed Binary Grey Wolf Optimizer
165
0
5
10
15
20
25
30
35
40
45
50
Iterations
100
150
200
250
300
350
400
450
500
OBF (M$)
Best BGWO
Mean BGWO
Best MBGWO
Mean MBGWO
Fig. 15. Garver: 50 iterations
0
10
20
30
40
50
60
70
80
90
100
Iterations
100
150
200
250
300
350
400
450
500
OBF (M$)
Best BGWO
Mean BGWO
Best MBGWO
Mean MBGWO
Fig. 16. Garver: 100 iterations
Tables 3 and 4 depict the branches selected for expansion for both systems,
as well as their respective costs and quantity. For the Garver system, the optimal
result was obtained for an investment of 130 M$. As for the IEEE-24 bus system,
the optimal result was obtained for an investment of 188 M$.

166
G. Rebello and E. J. de Oliveira
0
1
2
3
4
5
6
7
8
9
10
Iterations
100
200
300
400
500
600
700
800
900
1000
1100
OBF (M$)
Best BGWO
Mean BGWO
Best MBGWO
Mean MBGWO
Fig. 17. IEEE-24 bus: 10 iterations
0
2
4
6
8
10
12
14
16
18
20
Iterations
100
200
300
400
500
600
700
800
900
1000
1100
OBF (M$)
Best BGWO
Mean BGWO
Best MBGWO
Mean MBGWO
Fig. 18. IEEE-24 bus: 20 iterations

Modiﬁed Binary Grey Wolf Optimizer
167
0
5
10
15
20
25
30
Iterations
100
200
300
400
500
600
700
800
900
1000
1100
OBF (M$)
Best BGWO
Mean BGWO
Best MBGWO
Mean MBGWO
Fig. 19. IEEE-24 bus: 30 iterations
0
5
10
15
20
25
30
35
40
Iterations
100
200
300
400
500
600
700
800
900
1000
1100
OBF (M$)
Best BGWO
Mean BGWO
Best MBGWO
Mean MBGWO
Fig. 20. IEEE-24 bus: 40 iterations

168
G. Rebello and E. J. de Oliveira
0
5
10
15
20
25
30
35
40
45
50
Iterations
100
200
300
400
500
600
700
800
900
1000
1100
OBF (M$)
Best BGWO
Mean BGWO
Best MBGWO
Mean MBGWO
Fig. 21. IEEE-24 bus: 50 iterations
0
10
20
30
40
50
60
70
80
90
100
Iterations
100
200
300
400
500
600
700
800
900
1000
1100
OBF (M$)
Best BGWO
Mean BGWO
Best MBGWO
Mean MBGWO
Fig. 22. IEEE-24 bus: 100 iterations

Modiﬁed Binary Grey Wolf Optimizer
169
BGWO
MBGWO
140
160
180
200
220
240
260
280
OBF (M$)
Fig. 23. Garver: 10 iterations
BGWO
MBGWO
130
140
150
160
170
180
190
200
210
OBF (M$)
Fig. 24. Garver: 20 iterations

170
G. Rebello and E. J. de Oliveira
BGWO
MBGWO
130
140
150
160
170
180
190
OBF (M$)
Fig. 25. Garver: 30 iterations
BGWO
MBGWO
130
135
140
145
150
155
160
165
170
OBF (M$)
Fig. 26. Garver: 40 iterations

Modiﬁed Binary Grey Wolf Optimizer
171
BGWO
MBGWO
130
140
150
160
170
180
190
OBF (M$)
Fig. 27. Garver: 50 iterations
BGWO
MBGWO
130
135
140
145
150
155
160
165
170
OBF (M$)
Fig. 28. Garver: 100 iterations

172
G. Rebello and E. J. de Oliveira
BGWO
MBGWO
180
200
220
240
260
280
300
320
340
360
OBF (M$)
Fig. 29. IEEE-24 bus: 10 iterations
BGWO
MBGWO
200
220
240
260
280
300
320
340
OBF (M$)
Fig. 30. IEEE-24 bus: 20 iterations

Modiﬁed Binary Grey Wolf Optimizer
173
BGWO
MBGWO
200
250
300
350
400
OBF (M$)
Fig. 31. IEEE-24 bus: 30 iterations
BGWO
MBGWO
180
200
220
240
260
280
OBF (M$)
Fig. 32. IEEE-24 bus: 40 iterations

174
G. Rebello and E. J. de Oliveira
BGWO
MBGWO
180
200
220
240
260
280
300
320
340
OBF (M$)
Fig. 33. IEEE-24 bus: 50 iterations
BGWO
MBGWO
180
190
200
210
220
230
240
250
260
270
280
OBF (M$)
Fig. 34. IEEE-24 bus: 100 iterations

Modiﬁed Binary Grey Wolf Optimizer
175
Table 1. Garver system: simulation results
Iterations
MBGWO
BGWO
Mean
STD
Best OBF
Time (min)
Mean
STD
Best OBF
Time (min)
10
143.30
12.00
130
61.76
148.57
21.03
130
38.26
20
141.39
8.86
130
89.37
146.12
17.20
130
69.09
30
141.20
8.98
130
112.46
145.28
13.68
130
102.46
40
140.90
10.66
130
166.07
141.90
9.92
130
130.71
50
139.20
9.04
130
204.06
144.80
13.52
130
161.82
100
138.50
7.83
130
393.82
140.70
10.66
130
322.35
Total of 100 simulations for each scenario. All results are in (M$).
Table 2. IEEE-24 bus system: simulation results
Iterations
MBGWO
BGWO
Mean
STD
Best OBF
Time (min)
Mean
STD
Best OBF
Time (min)
10
208.59
23.40
188
161.51
239.50
38.63
188
69.63
20
208.73
25.32
188
259.66
222.26
33.46
188
143.33
30
205.56
23.56
188
360.97
214.11
33.43
188
192.28
40
201.56
19.74
188
399.94
212.47
25.90
188
318.57
50
200.32
21.41
188
498.23
208.85
29.95
188
409.70
100
198.90
18.52
188
779.89
205.17
23.63
188
634.59
Total of 100 simulations for each scenario. All results are in (M$).
Table 3. Garver system branches
Branch Cost (M$) Quantity
2–3
20
1
4–6
30
3
3–5
20
1
4.2
Literature Comparison
Several works in the literature have applied diﬀerent techniques to solve the
TNEP problem. Table 5 depicts a comparison between the results obtained by
the proposed MBGWO algorithm and other techniques for the two test systems
presented in this chapter. In [11], the authors proposed the use of a construc-
tive heuristic algorithm to reduce the search space and then applied a modiﬁed

176
G. Rebello and E. J. de Oliveira
Table 4. IEEE-24 bus system branches
Branch Cost (M$) Quantity
7–8
16
2
6–10
16
1
10–12
50
1
14–16
54
1
16–17
36
1
version of the BA to solve the TNEP problem for the Garver and IEEE-24 bus
systems. In [31], the authors used a mixed integer linear model using mathe-
matical programming to solve the TNEP problem for both systems as well. In
[32], the authors applied the primal-dual interior point method, combined with a
sigmoid transfer function to solve the Garver system. It is important to highlight
that the proposed MBGWO was applied to the complete search space of both
test systems studied and obtained the best results found in the literature so far.
Table 5. Literature comparison
System
Reference
Cost (M$)
Garver
MBGWO 130
[32]
130
[11]
130
[31]
140
IEEE-24 Bus MBGWO 188
[11]
188
[31]
507.7
5
Conclusion and Future Works
This work presented a modiﬁed version of the meta-heuristic known as grey wolf
optimizer to solve the NP-hard transmission expansion Planning problem.
The original version of the meta-heuristic, suited to solve continuous opti-
mization problems was presented, with a pseudo-code detailing every step of the
algorithm.
Also, the authors presented an approach to suit the GWO to solve binary
optimization problems, such as the TNEP, by using a sigmoid transfer function
to convert the continuous variables into binary values.
An alternative to improve the local search component of the algorithm was
also presented in this chapter, giving rise to the proposed modiﬁed binary grey

Modiﬁed Binary Grey Wolf Optimizer
177
wolf optimizer. All steps taken to create, disturb and reﬁne the temporary solu-
tion were explained through the use of a pseudo-code and ﬁgures.
At last, the authors applied the proposed MBGWO approach in two well-
known test systems from the literature and proved through the results the eﬀec-
tiveness of the proposed modiﬁcations over the purely binary version of GWO,
here called BGWO. Also, a literature comparison was provided, showing that the
proposed MBGWO was able to obtain the best results found in the specialized
literature for the test systems studied in this chapter.
As for future works, the authors highlight the possibility of modifying the
way that the exploration coeﬃcient −→a t is updated. The use of chaotic maps
and/or pulsed functions can help the algorithm to explore the search space more
dynamically and obtain even better results.
Acknowledgements. The authors gratefully acknowledge the ﬁnancial support in
part of CAPES—Coordena¸c˜ao de Aperfei¸coamento de Pessoal de N´ıvel Superior—
Brasil, CNPq—Conselho Nacional de Desenvolvimento Cient´ıﬁco e Tecnol´ogico—
Brasil, INERGE—Instituto Nacional de Energia El´etrica and FAPEMIG—Funda¸c˜ao
de Amparo ´a Pesquisa no Estado de Minas Gerais. The authors also express gratitude
for the educational support of UFJF—Federal University of Juiz de Fora.
References
1. Hemmati R, Hooshmand R-A, Khodabakhshian A (2013) State-of-the-art of trans-
mission expansion planning: comprehensive review. Renew Sustain Energ Rev
23:312–319
2. Lumbreras S, Ramos A (2016) The new challenges to transmission expansion plan-
ning. survey of recent practice and literature review. Electr Power Syst Res 134:19–
29
3. Dewani B, Daigavane MB, Zadgaonkar AS (2012) A review of various computa-
tional intelligence techniques for transmission network expansion planning, pp 1–5
4. Fister I Jr, Yang XS, Fister I, Brest J, Fister D (2013) A brief review of nature-
inspired algorithms for optimization. arXiv:1307.4186
5. Gomes PV, Saraiva JT (2015) Static transmission expansion planning using heuris-
tic and metaheuristic techniques. In: 2015 IEEE eindhoven powertech, pp 1–6
6. Khosravy M, Gupta N, Patel N, Senjyu T, Duque CA Particle swarm optimization
of morphological ﬁlters for electrocardiogram baseline drift estimation
7. Jagatheesan K, Anand B, Samanta S, Dey N, Ashour AS, Balas VE (2017) Par-
ticle swarm optimisation-based parameters optimisation of pid controller for load
frequency control of multi-area reheat thermal power systems. Int J Adv Intell
Paradigms 9(5–6):464–489
8. de Mendon¸ca IM, Poubel RPB, Junior ICS, de Oliveira EJ, Marcato ALM, Oliveira
LW (2013) Static transmission network expansion planning of electric power sys-
tems using the ﬁreﬂy optimization. In: 2013 IEEE grenoble conference, pp 1–6
9. da Silva AML, Freire MR, Honorio LM (2016) Transmission expansion planning
optimization by adaptive multi-operator evolutionary algorithms. Electr Power
Syst Res 133:173–181
10. Gomes PV, Saraiva JT (2016) Hybrid genetic algorithm for multi-objective
transmission expansion planning. In: 2016 IEEE international energy conference
(ENERGYCON), pp 1–6

178
G. Rebello and E. J. de Oliveira
11. de Oliveira EJ, Moraes CA, Oliveira LLW, Honorio L, Poubel R (2018) Eﬃcient
hybrid algorithm for transmission expansion planning 10
12. Moraes CA, Oliveira EJD, Khosravy M, Oliveira LW, Honrio LM, Pinto MF A
hybrid bat-inspired algorithm for power transmission expansion planning on a
practical brazilian network
13. Satapathy SC, Raja NSM, Rajinikanth V, Ashour AS, Dey N (2018) Multi-level
image thresholding using otsu and chaotic bat algorithm. Neural Comput Appl
29(12):1285–1307
14. Das S, Verma A, Bijwe PR (2017) Transmission network expansion planning using a
modiﬁed artiﬁcial bee colony algorithm. Int Trans Electr Energy Syst 27(9):e2372–
n/a
15. El-bages M, Elsayed W (2017) Social spider algorithm for solving the transmission
expansion planning problem. Electr Power Syst Res 143:235–243
16. Gupta N, Patel N, Tiwari BN, Khosravy M (2018) Genetic algorithm based on
enhanced selection and log-scaled mutation technique. In: Proceedings of the future
technologies conference. Springer, pp 730–748
17. Deep K, Thakur M (2007) A new crossover operator for real coded genetic algo-
rithms. Appl Math Comput 188(1):895–911
18. Gupta N, Khosravy M, Patel N, Senjyu T (2018) A bi-level evolutionary optimiza-
tion for coordinated transmission expansion planning. IEEE Access 6:48455–48477
19. Gupta N, Khosravy M, Patel N, Sethi I (2018) Evolutionary optimization based
on biological evolution in plants. Procedia Comput Sci 126:146–155
20. Mirjalili S, Mirjalili SM, Lewis A (2014) Grey wolf optimizer. Adv Eng Softw
69:46–61
21. de Oliveira EJ, Junior ICS, Pereira JLR, Carneiro S (2005) Transmission system
expansion planning using a sigmoid function to handle integer investment variables.
IEEE Trans Power Syst 20(3):1616–1621
22. Baharvandi A, Aghaei J, Niknam T, Shaﬁe-Khah M, Godina R, Catalao JPS (2018)
Bundled generation and transmission planning under demand and wind generation
uncertainty based on a combination of robust and stochastic optimization. IEEE
Trans Sustain Energy 9(3):1477–1486
23. Verma S, Mukherjee V (2018) Investigation of static transmission expansion plan-
ning using the symbiotic organisms search algorithm. Eng Optim 50(9):1544–1560
24. Garver LL (1970) Transmission network estimation using linear programming.
IEEE Trans Power Apparatus Syst 7:1688–1697
25. Emary E, Zawbaa HM, Hassanien AE (2016) Binary grey wolf optimization
approaches for feature selection. Neurocomputing 172:371–381
26. Panwar LK, Reddy S, Verma A, Panigrahi BK, Kumar R (2018) Binary grey wolf
optimizer for large scale unit commitment problem. Swarm Evol Comput 38:251–
266
27. Wen L (2016) Grey wolf optimizer based on nonlinear adjustment control param-
eter. In: International conference on sensors, mechatronics and automation, pp
643–648
28. Mittal N, Singh U, Sohi BS (2016) Modiﬁed grey wolf optimizer for global engi-
neering optimization. Appl Comput Intell Soft Comput 2016:8
29. Zhang S, Luo Q, Zhou Y (2017) Hybrid grey wolf optimizer using elite
opposition-based learning strategy and simplex method. Int J Comput Intell Appl
16(02):1750012
30. Kohli M, Arora S (2018) Chaotic grey wolf optimization algorithm for constrained
optimization problems. J Comput Design Eng 5(4):458–472

Modiﬁed Binary Grey Wolf Optimizer
179
31. Alguacil N, Motto AL, Conejo AJ (2003) Transmission expansion planning: a
mixed-integer lp approach. IEEE Trans Power Syst 18(3):1070–1077
32. de Oliveira EJ, Junior ICS, Pereira JLR, Carneiro S (2005) Transmission system
expansion planning using a sigmoid function to handle integer investment variables.
IEEE Trans Power Syst 20(3):1616–1621

Chapter 8
Tracing the Points in Search Space in Plant
Biology Genetics Algorithm Optimization
Mahdi Khosravy1,2, Neeraj Gupta3(&), Nilesh Patel3,
Om Prakash Mahela4, and Gazal Varshney5
1 Media Integrated Communication Lab, Graduate School of Engineering, Osaka
University, Osaka, Japan
2 Electrical Engineering Department, Federal University of Juiz de Fora, Juiz de
Fora, Brazil
3 Department of Computer Science and Engineering, Oakland University,
Rochester, MI, USA
neerajgupta@oakland.edu
4 Power System Planning Division, Rajasthan Rajya Vdhyut Prasaran Nigam
Ltd., Jaipur, Rajasthan, India
5 University of Information Science and Technology, Ohrid, North Macedonia
1
Introduction
As the demand for accuracy and speed of algorithms and the corresponding systems
increases, the optimization techniques draw the attention of the researchers more and
more. A very important category of the optimizers with efﬁciency in managing the non-
linear non-convex problems is meta-heuristic nature-inspired algorithms [1, 2] known
as evolutionary algorithms (EAs). EAs techniques include a wide range of optimizers
which each is inspired from different natural phenomenon like genetic algorithm
(GA) [3–5], Bat algorithm [6–9], PSO [10–15], Fireﬂy [16], plant biology-inspired
optimizer known as Mendelian Evolutionary Theory Optimization (METO) [17, 18],
swarm optimization [19], shufﬂed frog leaping algorithm (SFLA) [20], biogeography-
based optimization (BBO) [21], cuckoo search (CS) [22], teaching learning-based
optimization (TLBO) [23], etc. [24–28] have been proposed, as in survey papers [29].
Besides all the development in the theory and application of nature-inspired meta-
heuristic optimization techniques, still there is a great potential of application EOs in a
variety of research ﬁelds as blind component processing [30], text feature detection
[31], data mining [32], ECG processing [33–36], information hiding [14], noise can-
cellation [37], imaging systems [38], image enhancement [39, 40], blind source sep-
aration [41–45], morphological ﬁltering [46, 47], fault detection [48], image adaptation
[49], quality assessment [50], power line communications [51], telecommunications
[52–55], acoustic OFDM [56], etc.
© Springer Nature Singapore Pte Ltd. 2020
M. Khosravy et al. (eds.), Frontier Applications of Nature Inspired Computation,
Springer Tracts in Nature-Inspired Computing,
https://doi.org/10.1007/978-981-15-2133-1_8

METO is a binary evolutionary computational algorithm inspired from evolution in
plant genetics. It comprises a framework of three concepts: (i) DNAs denaturation of
two different species and producing a hybrid “offspring DNA,” (ii) following the
Mendel law of evolution, and genetic inheritance wherein the dominant and recessive
traits play a role in two successive generations. (iii) Finally, the epimutation operation
which assists the organisms resist for natural mutation. METO by the deployment of
these three operators performs a binary meta-heuristic evolutionary search. To know
better the details related to four main operators of METO—ﬂipper, pollination,
breeding, and epimutation—we refer the reader to Ref. [17].
This chapter aims to study the behavior of alternative solutions as the points in
search space. It as an effort to give an animated view to the reader from the way that
METO swipes the search space and avoids being stuck in local extremes and moves
toward global solution.
To add to the state of the art, we inspired from the evolution theory of plant
genetics based on Mendel’s inheritance law to propose a genetically evolved opti-
mization algorithm. In this algorithm, the evolution process takes place by inter-
breeding the plants of different species [17].
To design a novel evolutionary algorithm (EA), we redeﬁne the biologically
inspired metaphors in the binary domain to implement as a computer program. Due to
its binary structure, the proposed ﬁve operations: ﬂipping, pollination, breeding, and
epimutation [17] have encoding and decoding techniques like the genetic algorithm
(GA) but in a different working structure. Based on the Mendelian theory, ancestors’
recessive genes are expected to transfer in the second consecutive generation (F2)
offspring with some probability. Thus, METO produces two consecutive generations,
F1 and F2, offspring in the sequence, where in F1 generation offspring genes are
dominating from their parents with high probability. This makes the METO in a
different class from the GA. METO is a gradient-free method that does not require the
function differential, thus best suited for the discontinuous and multimodal problems as
well. Moreover, its binary encoding makes it hardware friendly algorithm.
2
Exploration of the Search Space
It is essential to know about how METO [17] searches the hyper-volume. The asso-
ciated study can help researcher for further improvement of the technique according to
their capability of dealing with special type of problems. One of the most crucial
working principles involved in exploring the global point is a random search. It helps to
eliminate the biases which are introduced by ancestor species through transferring the
heredity properties in offspring. As a result, METO optimizer tries to come out from the
local solution.
It would be worth to mention here about the implemented schemes which pose
randomization in the process of search exploration in genome space. The ﬁrst
Tracing the Points in Search Space in Plant Biology Genetics
181

subsystem deployed in METO is pollination, where after the random sampling of two
species from the available alternatives, two parents are selected out for the fertilization
process to produce offspring. The second scheme, which makes it different from GA is
the formation of double-strand DNA instead of the single chromosome. Constructing
the second strand of DNA spreads the points randomly in the search space. As we have
described above that, both strands used in METO are in the opposite direction of each
other, where antisense strand (AS) of DNA is cast by reversing the sense strand (SS).
This mechanism takes out the optimizer from getting trapped at local minima and takes
away the search from the premature biased condition occupied by the ancestors.
Although, the random process, as described above, distracts the search in evolu-
tionary phases. To restrict the optimizer from the completely randomized procedure,
METO introduces the concept of recessive genes as the memory of the optimizer. It had
the best heredity characteristic until the current evolution and used as a biasing
mechanism, which inﬂuences the offspring by its best in heredity characteristics.
Biasing from already searched best results motivates the optimizer for going ahead to
search for better results, where the Mendelian probability decides the amount of
inﬂuencing the offspring from recessive characteristics. This transfer of recessive
heredity is a unique feature of the optimizer and can be controlled during the evolution
using an adaptive mechanism. This memory system is signiﬁcant in the case when
optimizer loses the region of interest due to stochastic processes as a result of casting
AS from SS to complete double-strand DNA structure. This is a principal feature of the
METO which provides diversity in the search space.
One evolution epoch of GA and its variants contain a sequence of selection,
crossover, and mutation, as shown in Fig. 1. Multiple evolutions of GA take place to
ﬁnd the optimal solution.
Fig. 1. Operations in an Epoch of GA and route of genes transfer from one generation to another
182
M. Khosravy et al.

Almost all evolutionary algorithms are transferring genes from F0 generation to the
F1 generation through a single route, where multiple operations are executing in the
sequence. This way of evolution is inspired by Darwin’s evolutionary theory, which
does not take account of the recessive genes transfer. Nevertheless, Mendel proposes
the concept of recessive genes propagation in the preceding generations by his
observation in two consecutive generations, F1 and F2. Based on this theory, it is
possible to develop an evolutionary algorithm, which transfers genes in the preceding
generations by two parallel routes, as shown in Fig. 2.
On route-I, ﬁrst F1 generation offspring are produced, and then genes are further
transferred to the F2 generation offspring. Additionally, in producing the offspring of
F2 generation offspring, genes from route-II are also dominating from F0 generation
parents. Transfer of genes from the second route is due to the theory of Mendel of
recessive genes transfer. Moreover, when genes are transmitting to alternative gener-
ations are subjected to the environmental mutation. An organism has self-healing
capability, through which it can rehabilitate themself against not-suitable environ-
mental conditions. In terms of biology, this process is named as epimutation. Thus, in
an Epoch of METO, two parallel processes are established. In the ﬁrst process, F1
generation offspring are the results of pollination and breeding. It is shown by route-I in
Fig. 2. The second process parallels to ﬁrst is shown by route-II and produces F2
generation offspring from F1 generation offspring. It is the result of self-breeding of F1
generation offspring where recessive genes from F0 generation parents appear in the F2
generation.
Fig. 2. Operations in an Epoch of METO and parallel routes of genes transfer from one
generation to another
Tracing the Points in Search Space in Plant Biology Genetics
183

In METO algorithm, it ﬁrst generates SS and then AS, thus arrows in Fig. 3 have
shown from SS to AS points in real space. Binary algorithms are suffering from an
undesirable situation, where due to the shifting of binary bits between the chromo-
somes of plants, sometimes the same offspring are the results. These are called as null-
offspring and the reason for additional unnecessary function evaluations. This null-
offspring may ruin the solution by pre-converging and restrict the algorithm to ﬁnd the
global solution by evaluating the same chromosome multiple times. To control the
situation of generating confounding null-offspring, we detected them and replaced by
some random strings. Moreover, for the global control of confounding null-offspring, a
mechanism of elicit memory can be adopted, which is the research of future
implementation.
Moreover, the integration of proliferation and truncation mechanism is adopted in
each evolution phase for better search. In the process of proliferation, multiple offspring
are generated instead of single offspring. This method explores the search space more
Fig. 3. Distribution of points in real space due to the formation of SS and AS in genome space
184
M. Khosravy et al.

efﬁciently. From the multiple offspring, the desired offspring are selected as truncation
process, which maintains the size of species in each evolution. This truncation is
carried out by selecting the progenies based on some criterion like the elite candidate as
in the proposal. Some other criteria, such as random sampling, and tournament sam-
pling, can be tested. The associated analysis we leave open for future research. Based
on the operators introduced in the proposed optimizer movement of the points in global
and local search strategies are described below.
3
Global Exploration
As METO adopts a mechanism of forming double-strand DNA as a global exploration
mechanism, this arrangement ensures the algorithm not to be trapped at local minima.
Due to this mechanism, the proposed optimizer is very much suited for solving the
multimodal, profoundly disturbed, and noisy functions.
Fig. 4. Distribution of points in real space due to the production of F1 generation offspring in
genome space
Tracing the Points in Search Space in Plant Biology Genetics
185

In this chapter, we show how points behave in the search space for the proposed
mechanism. We can see in Fig. 3 that the movement of points is random and does not
follow any pattern. The outcome of both strands does not have any relation except the
reversing characterization and is not dependent on the function value of each other.
This arbitrary and unbound movement of the points provides global exploration. This
phenomenon may be a drawback of the algorithm as an inefﬁcient optimizer for plate-
shaped and bowl-shaped functions.
In Fig. 3, we can also observe the movement of sense points is from lower function
value to higher function value, for example, P3-S, P4-S, P5-S, and P6-S. It is an
indication that it does not mean that the algorithm improves the function value in
subsequent evolution. Due to this mechanism, it restarts searching and avoids the
inﬂuence of bias from its ancestors. However, some points try to improve function
value and come to the region of interest like P1-S and P9-S.
4
Intermediate Search
Apart from global exploration, unlike GA, this algorithm utilizes an intermediary
search mechanism. This mechanism is a bit similar to the crossover mechanism in GA.
But in the context of Mendelian theory in genetics, we renamed it as cross-fertilization
for F1 generation offspring. METO proposes the concept of XOR, which is efﬁcient for
the proliferation where more than one offspring is the result. Figure 4 shows the
movement of the points as the fertilization process for F1 generation offspring. Here we
can see that offspring points are moving around, and a boundary drawn by the parent’s
chromosomes. A beneﬁciary feature can be noticed here that new offspring occupy
intermediary space brought by both parents. A parent attracts the resulting offspring by
transferring more dominant genes than another parent. In this mechanism, offspring are
not traveling far from the parents and roaming around them with a certain distance.
This operation is essential to ﬁnd intermediate points where parents belong to different
species. This mechanism is a biased process, and the quality of the offspring is
dependent on the parents and the probability of dominant gene transfer from them. In
Fig. 4, we can also observe that points P1-F1 and P7-F1 belong to F1 generation is
same as P1-S, and P7-S points respectively belong to sense parent. This is because of
transferring all dominant genes from sense parent instead of the antisense parent. The
position of F1-generation points inﬂuenced by the number of dominant genes from
parents, which can be controlled in the proposed algorithm by the Mendelian proba-
bility of dominance gene transfer. Possible position of F1 generation offspring for the
two parents can be seen in Fig. 5. Here, we can see that all progenies are near or
between the different species parents’ points. Offspring produced in right side or left
side have the same pattern or distance from parents.
186
M. Khosravy et al.

5
Local Exploration
Global exploration provides an unbiased investigation of the search space, and con-
sequently, F1 generation scheme reveals biased hunting of the intermediate points.
Apart from these two mechanisms, local exploitation technique is vital to check
neighbors’ points. For local exploitation, two mechanisms are introduced after F1
generation process.
The ﬁrst mechanism is called the production of F2 generation offspring, where
recessive genes from ancestors are transmitted to the offspring with a Mendelian
probability of recessive gene transfer. Movement of points due to this procedure can be
seen in Fig. 6.
Here, we can see that most of the F1 generation offspring are moving toward one
global point inside one rectangle. Out of ten new F2 generation offspring six of them
P3-F2, P4-F2, P6-F2, P8-F2, P9-F2, and P10-F2 search neighbor points previously
found the global best position.
Fig. 5. Possible distribution of points in real space due to the F1generation offspring procedure
of two parents in genome space
Tracing the Points in Search Space in Plant Biology Genetics
187

This is based on the number of recessive genes transferred to the F2 generation
offspring. If these transferred genes are much, the F2 generation offspring come near to
the biased point, otherwise may deviate but not far. F2 generation offspring production
with the formation of the AS of DNA behaves like a push-pull mechanism. In this
system generation of AS from S, strand pushes the new points far where they have
pulled back again in the F2 generation.
Fig. 6. Movement of points in real space due to the F2 generation offspring procedure in
genome space
188
M. Khosravy et al.

As we described before that pulling the points is dependent on the Mendelian
probability, Figs. 7, 8 and 9 show the movement of points for different Mendelian
probability. We can observe that for higher Mendelian probability, most of the points
pull back to the previous pseudo-best position, which is in the memory and behave like
a bias. In Fig. 3, eight points P1-F2, P2-F2, P3-F2, P4-F2, P5-F2, P6-F2, P7-F2, and
P8-F2 are knocking neighbor points of the pseudo-best point. These may vary with the
same Mendelian probability, where each gene in bias (chromosome of recessive genes)
has to qualify it. In Figs. 7, 8 and 9, we can see that as the Mendelian probability
decreases, the exploitation of neighbor points of already best position (bias) is
reducing.
Fig. 7. Distribution of points in real space due to Mendelian probability equal to 0.95
Tracing the Points in Search Space in Plant Biology Genetics
189

For Mendelian expectation equal to 0.75, as in Fig. 6, only four points P1-F2, P2-
F2, P6-F2, and P7-F2 are near the bias. Similarly, we can see for Mendelian probability
equal to 0.5 in Fig. 7, most of the points distract the exploitation of neighbor point of
preference. This distraction is increasing as the Mendelian probability goes down,
which can be observed in Fig. 8 with Mendelian probability equal to 0.25.
Fig. 8. Distribution of points in real space due to Mendelian probability equal to 0.75
190
M. Khosravy et al.

6
Conclusion
Here, we can see that METO is a unique algorithm, which implements two parallel
routes for transferring the genes from one generation to the other. Through this
mechanism, METO always utilizes two parallel evolution systems for searching for the
solution. First evolution, route-I, is due to cross-breeding and second, which is route-II
is due to the self-breeding. In route-I operations, cross-breeding explores the region
between and near around the two parents. So, in this case, a region bounded by two
best parents gives idea to ﬁnd a better solution. Since that region may have a global
solution. Moreover, not to stuck at premature solution ﬂipper operator is important,
which takes the current point far from the current solution region. However, this push
of points from their current situation can disturb the search process, thus, self-breeding
operation is deployed, which pull back the points to a better place. In this operation,
based on the Mendelian probability, most of the offspring are moving toward one best
Fig. 9. Distribution of points in real space due to Medelian probability equal to 0.50
Tracing the Points in Search Space in Plant Biology Genetics
191

point found so far. This best point is saved as recessive genes and always tries to
transfer in F2 generation with high probability, if have better ﬁtness then the F1
generation offspring. Over-all, we can see that the METO has push-pull mechanism.
Flipper and epimuation are working as push operator which pushes the points to
random position in the search space where self-breeding pull mechanism to bring the
deviated points back to the region of interest. Additionally, cross-breeding works as
intermediately search mechanism and tries to ﬁnd a better solution bounded by two
good parents.
References
1. Dey N (ed) (2017) Advancements in applied metaheuristic computing. IGI Global
2. Dey N, Ashour AS (2016) Antenna design and direction of arrival estimation in meta-
heuristic paradigm: a review. Int J Serv Sci Manage Eng Technol 7(3):1–18
3. Gupta N, Patel N, Tiwari BN, Khosravy M (2018, November). Genetic algorithm based on
enhanced selection and log-scaled mutation technique. In: Proceedings of the future
technologies conference. Springer, Cham, pp 730–748
4. Singh G, Gupta N, Khosravy M (2015, November). New crossover operators for real coded
genetic algorithm (RCGA). In: 2015 international conference on intelligent informatics and
biomedical sciences (ICIIBMS). IEEE, pp 135–140
5. Gupta N, Khosravy M, Patel N, Senjyu T (2018) A bi-level evolutionary optimization for
coordinated transmission expansion planning. IEEE Access 6:48455–48477
6. Moraes CA, De Oliveira, EJ, Khosravy, M, Oliveira, LW, Honório, LM, Pinto, MF (2020) A
hybrid bat-inspired algorithm for power transmission expansion planning on a practical
Brazilian network. In: Dey N, Ashour AS, Bhattacharyya S (eds) Applied nature-inspired
computing: algorithms and case studies. Springer, Singapore, pp 71–95
7. Satapathy SC, Raja NSM, Rajinikanth V, Ashour AS, Dey N (2018) Multi-level image
thresholding using Otsu and chaotic bat algorithm. Neural Comput Appl 29(12):1285–1307
8. Rajinikanth V, Satapathy SC, Dey N, Fernandes SL, Manic KS (2019) Skin melanoma
assessment using Kapur’s Entropy and level set—a study with bat algorithm. In: Smart
intelligent computing and applications. Springer, Singapore, pp. 193–202
9. Dey N, Samanta S, Yang XS, Das A, Chaudhuri SS (2013) Optimisation of scaling factors in
electrocardiogram signal watermarking using cuckoo search. Int J Bio-Inspired Computation
5(5):315–326
10. Chatterjee S, Sarkar S, Hore S, Dey N, Ashour AS, Balas VE (2017) Particle swarm
optimization trained neural network for structural failure prediction of multistoried RC
buildings. Neural Comput Appl 28(8):2005–2016
11. Jagatheesan K, Anand B, Samanta S, Dey N, Ashour AS, Balas VE (2017) Particle swarm
optimisation-based parameters optimisation of PID controller for load frequency control of
multi-area reheat thermal power systems. Int J Adv Intell Paradigms 9(5–6):464–489
12. Chatterjee S, Hore S, Dey N, Chakraborty S, Ashour AS (2017) Dengue fever classiﬁcation
using gene expression data: a PSO based artiﬁcial neural network approach. In: Proceedings
of the 5th international conference on frontiers in intelligent computing: theory and
applications. Springer, Singapore, pp 331–341
13. Jagatheesan K, Anand B, Dey N, Gaber T, Hassanien AE, Kim TH (2015, September) A
design of PI controller using stochastic particle swarm optimization in load frequency control
of thermal power systems. In: 2015 fourth international conference on information science
and industrial applications (ISI). IEEE, pp 25–32
192
M. Khosravy et al.

14. Chakraborty S, Samanta S, Biswas D, Dey N, Chaudhuri SS (2013, December) Particle
swarm optimization based parameter optimization technique in medical information hiding.
In: 2013 IEEE international conference on computational intelligence and computing
research, 1–6
15. Khosravy M, Gupta N, Patel N, Senjyu T, Duque CA (2020) particle swarm optimization of
morphological ﬁlters for electrocardiogram baseline drift estimation. In: Dey N, Ashour AS,
Bhattacharyya S (eds) Applied nature-inspired computing: algorithms and case studies.
Springer, Singapore, pp 1–21
16. Dey N, Samanta S, Chakraborty S, Das A, Chaudhuri SS, Suri JS (2014) Fireﬂy algorithm
for optimization of scaling factors during embedding of manifold medical information: an
application in ophthalmology imaging. J Med Imaging Health Inf 4(3):384–394
17. Gupta N, Khosravy M, Patel N, Sethi IK (2018) Evolutionary optimization based on
biological evolution in plants. Procedia Comput Sci Elsevier 126:146–155
18. Gupta N, Khosravy M, Mahela OP, Patel N (2020) Plants biology inspired genetics
algorithm: superior efﬁciency to ﬁreﬂy optimizer. In: Applications of ﬁreﬂy algorithm and its
variants, from springer tracts in nature-inspired computing (STNIC), Springer International
Publishing, in press
19. Neshat M, Sepidnam G, Sargolzaei M, Toosi AN (2014) Artiﬁcial ﬁsh swarm algorithm: a
survey of the state-of-the-art, hybridization, combinatorial and indicative applications. Artif
Intell Rev 42(4):965–997
20. Eusuff M, Lansey K, Pasha F (2006) Shufﬂed frogleaping algorithm: a memetic meta-
heuristic for discrete optimization. Eng Optim 38(2):129–154
21. Simon D (2008) Biogeography-based optimization. IEEE Trans Evol Comput 12(6):702–
713
22. Rajabioun R (2011) Cuckoo optimization algorithm. Appl Soft Comput 11(8):5508–5518
23. Rao RV, Savsani VJ, Vakharia DP (2011) Teaching learning-based optimization: a novel
method for constrained mechanical design optimization problems. Comput-Aided Design 43
(3):303–315
24. Boussaï DI, Lepagnot J, Siarry P (2013) A survey on optimization metaheuristics. Inf Sci
237:82–117
25. Paszkowicz W (2013) Genetic algorithms, a nature-inspired tool: a survey of applications in
materials science and related ﬁelds: part II. Mater Manuf Processes 28(7):708–725
26. AlRashidi MR, El-Hawary ME (2008) A survey of particle swarm optimization applications
in electric power systems. IEEE Trans Evol Comput 13(4):913–918
27. Krasnogor N, Smith J (2005) A tutorial for competent memetic algorithms: model,
taxonomy, and design issues. IEEE Trans Evol Comput 9(5):474–488
28. El-Mihoub TA, Hopgood AA, Nolle L, Battersby A (2006) Hybrid genetic algorithms: a
review. Eng Lett 13(2):124–137
29. Beheshti Z, Shamsuddin SMH (2013) A review of population-based meta-heuristic
algorithms. Int J Adv Soft Comput Appl 5(1):1–35
30. Khosravy M, Gupta N, Marina N, Asharif MR, Asharif F, Sethi IK (2015, November) Blind
components processing a novel approach to array signal processing: a research orientation.
In: 2015 international conference on intelligent informatics and biomedical sciences
(ICIIBMS). IEEE, pp 20–26
31. Gutierrez CE, Alsharif MR, Khosravy M, Yamashita K, Miyagi H, Villa R (2014, October)
Main large data set features detection by a linear predictor model. In: AIP conference
proceedings, vol 1618, no 1, pp 733–737
32. Gutierrez CE, Alsharif MR, Yamashita K, Khosravy M (2014) A tweets mining approach to
detection of critical events characteristics using random forest. Int J Next-Gener Comput 5
(2):167–176
Tracing the Points in Search Space in Plant Biology Genetics
193

33. Dey N, Mukhopadhyay S, Das A, Chaudhuri SS (2012) Analysis of P-QRS-T components
modiﬁed by blind watermarking technique within the electrocardiogram signal for
authentication in wireless teleradiology using DWT. Int J Image Graphics Signal Process
4(7):33
34. Dey N, Ashour AS, Shi F, Fong SJ, Sherratt RS (2017) Developing residential wireless
sensor networks for ECG healthcare monitoring. IEEE Trans Consum Electron 63(4):442–
449
35. Sedaaghi MH, Khosravi M (2003, July) Morphological ECG signal preprocessing with more
efﬁcient baseline drift removal. In: Proceedings of the 7th. IASTED International
Conference. ASC, pp 205–209
36. Khosravi M, Sedaaghi MH (2004, February) Impulsive noise suppression of electrocardio-
gram signals with mediated morphological ﬁlters. In: The 11th Iranian conference on
biomedical engineering. Tehran, Iran, pp 207–212
37. Khosravy M, Asharif MR, Sedaaghi MH (2008) Medical image noise suppression: using
mediated morphology. IEICE Tech Rep, IEICE, pp 265–270
38. Hore S, Chakraborty S, Chatterjee S, Dey N, Ashour AS, Van Chung L, Le DN (2016) An
integrated interactive technique for image segmentation using stack based seeded region
growing and thresholding. Int J Electr Comput Eng 6(6):2088–8708
39. Ashour AS, Samanta S, Dey N, Kausar N, Abdessalemkaraa WB, Hassanien AE (2015)
Computed tomography image enhancement using cuckoo search: a log transform based
approach. J Signal Inf Process 6(03):244
40. Khosravy M, Gupta N, Marina N, Sethi IK, Asharif MR (2017) Brain action inspired
morphological image enhancement. Nature-inspired computing and optimization. Springer,
Cham, pp 381–407
41. Khosravy M, Asharif MR, Yamashita K (2009) A PDF-matched short-term linear
predictability approach to blind source separation. Int J Innovative Comput Inf Control
(IJICIC) 5(11):3677–3690
42. Khosravy M, Alsharif MR, Yamashita K (2009) A PDF-matched modiﬁcation to stone’s
measure of predictability for blind source separation. International symposium on neural
networks. Springer, Berlin, Heidelberg, pp 219–228
43. Khosravy M, Asharif MR, Yamashita K (2011) A theoretical discussion on the foundation of
Stone’s blind source separation. SIViP 5(3):379–388
44. Khosravy M, Asharif M, Yamashita K (2008) A probabilistic short-length linear
predictability approach to blind source separation. 23rd international technical conference
on circuits/systems, computers and communications (ITC-CSCC 2008). Yamaguchi, Japan,
pp 381–384
45. Khosravy M, Kakazu S, Alsharif MR, Yamashita K (2010) Multiuser data separation for
short message service using ICA (信号処理). 電子情報通信学会技術研究報告. SIP, 信号
処理: IEICE Tech Rep 109(435):113–117
46. Sedaaghi MH, Daj R, Khosravi M (2001, October) Mediated morphological ﬁlters. In:
proceedings 2001 international conference on image processing (Cat. No. 01CH37205), vol
3. IEEE, pp 692–695
47. Khosravy M, Gupta N, Marina N, Sethi IK, Asharif MR (2017) Morphological ﬁlters: an
inspiration from natural geometrical erosion and dilation. Nature-inspired computing and
optimization. Springer, Cham, pp 349–379
48. Gupta S, Khosravy M, Gupta N, DARBARI H (2019) In-ﬁeld failure assessment of tractor
hydraulic system operation via pseudospectrum of acoustic measurements. Turkish J Electr
Eng Comput Sci 27(4):2718–2729
194
M. Khosravy et al.

49. Khosravy M, Gupta N, Marina N, Sethi IK, Asharif MR (2017) Perceptual adaptation of
image based on Chevreul-Mach bands visual phenomenon. IEEE Signal Process Lett 24
(5):594–598
50. Khosravy M, Patel N, Gupta N, Sethi IK (2019) Image quality assessment: a review to full
reference indexes. Recent trends in communication, computing, and electronics. Springer,
Singapore, pp 279–288
51. Picorone AAM, Oliveira TR, Sampaio-Neto R, Khosravy M, Ribeiro MV (2020) Channel
characterization of low voltage electric power distribution networks for PLC applications
based on measurement campaign. Int J Electri Power Energy Syst 116:105554
52. Khosravy M, Alsharif MR, Guo B, Lin H, Yamashita K (2009) A robust and precise solution
to permutation indeterminacy and complex scaling ambiguity in BSS-based blind MIMO-
OFDM receiver. International conference on independent component analysis and signal
separation. Springer, Berlin, Heidelberg, pp 670–677
53. Asharif F, Tamaki S, Alsharif MR, Ryu HG (2013) Performance improvement of constant
modulus algorithm blind equalizer for 16 QAM modulation. Int J Innovative Comput Inf
Control 7(4):1377–1384
54. Khosravy M, Alsharif MR, Yamashita K (2009) An efﬁcient ICA based approach to
multiuser detection in MIMO OFDM systems. Multi-carrier systems & solutions 2009.
Springer, Dordrecht, pp 47–56
55. Khosravy M, Alsharif MR, Khosravi M, Yamashita K (2010, June) An optimum pre-ﬁlter
for ICA based mulit-input multi-output OFDM system. In: 2010 2nd international
conference on education technology and computer, vol 5. IEEE, pp V5–129
56. Khosravy M, Punkoska N, Asharif F, Asharif MR (2014, October) Acoustic OFDM data
embedding by reversible Walsh-Hadamard transform. In: AIP conference proceedings, vol
1618, no 1, pp 720–723
Tracing the Points in Search Space in Plant Biology Genetics
195

Chapter 9
Artiﬁcial Cell Swarm Optimization
Sankhadeep Chatterjee1, Subham Dawn2, and Sirshendu Hore3(&)
1 Department of CSE, University of Engineering and Management, Kolkata,
West Bengal, India
sankha3531@gmail.com
2 Oracle, Bangalore, Karnataka, India
coder.sdawn@gmail.com
3 Department of CSE, Hooghly Engineering & Technology College, Hooghly,
West Bengal, India
shirshendu.hore@gmail.com
1
Introduction
Optimization provides a sophisticated combination of theory and applications to ﬁnd
the best possible/desirable solution. Numerous and extensive ranging optimization
applications are involved in several domains, such as engineering, medical, science,
economics, and industry, thus techniques for solving the optimization problems ought
to be an active research area. Recently, heuristic/meta-heuristic algorithms are extre-
mely inspired by nature or biological systems to achieve the potential solutions for real-
world problems. Meta-heuristics are based on iterative procedure development of either
a single solution (e.g., Tabu search) or population of solutions (as in swarm-based
algorithms and evolutionary algorithms “EA”), where randomization and local search
to solve a given optimization problem are employed. The most successful and pre-
dominant directions are the swarm-based algorithms, and the EA are instigated by the
collective behavior of animals and natural evolution, respectively.
The swarm intelligence algorithms are carried out to solve complex problems
starting from optimization to multi-agent decision making [1]. The PSO is a compu-
tational intelligence stochastic, oriented, population swarm intelligence-based global
optimization technique [2]. Typically, PSO-based algorithm is used to solve global
problems of optimization. It can handle effectively nonlinear, non-convex spaces
having discontinuities with fast convergence and robustness. It considers a population
of particles in D-dimensional search space [3–5]. Another nature-inspired meta-
heuristic is the ant colony optimization (ACO) [6–10]. It is built upon the concept of
indirect communication between artiﬁcial ants by means of a chemical substance called
the pheromone. Agents (artiﬁcial ants) share their experiences with others while trying
to achieve a particular goal using the numerical information regarding pheromone. The
information sharing leads a majority of colony agents that incline to the expected goal.
Swarming honeybees around their hives have inspired another set of algorithms which
efﬁciently uses the cooperative behavior of bees to solve several problems, such as the
combinatorial problems [11], robotic tasks [12], trafﬁc and transportation problems
© Springer Nature Singapore Pte Ltd. 2020
M. Khosravy et al. (eds.), Frontier Applications of Nature Inspired Computation,
Springer Tracts in Nature-Inspired Computing,
https://doi.org/10.1007/978-981-15-2133-1_9

[13, 14], max-sat [15], ECG baseline correction [16], power system planning [17], and
3-sat problem [18]. A similar approach has resulted in the development of another
algorithm called the glowworm swarm optimization (GSO) [19] that uses glowworms
as search agents. Glowworms communicate with each other using luciferin (a lumi-
nescence quantity). Moreover, inspired by the echolocation capability of bats, a meta-
heuristic called bat algorithm (BA) has been reported by Yang [20]. Bat algorithm has
been successfully opted for global engineering optimization [21], multi-objective
optimization [22], and constrained optimization [23] tasks. Another nature-inspired
heuristic algorithm has been proposed by Rashedi et al. [24]. The algorithm is known
as gravitational search algorithm (GSA) that based upon gravitational interaction theory
between masses. In addition, the GA is one of the efﬁcient population-based opti-
mization approach algorithms that has been used and sometimes coupled with machine
learning algorithm to solve real-world problems [25–28]. The GA is inspired by the
metaphor of natural evolution. The characteristics of a member of the population are
encoded in the chromosome of that individual.
The principles of Darwinian evolution for solving optimization problems have been
reiterated in genetic algorithms (GA) [29, 30]. A very recent variation of GA implies
Mendelian evolution on multi-species as inspired from plants biology [31, 32] incor-
porating the use of double-strand DNA for evolution.
Generally, the optimization algorithms [16, 17, 33–36], such as the PSO, ACO,
GA, and bat algorithm, can provide near to the optimum solutions to linear and non-
linear problems for several applications; nevertheless, in some case, they can labor
under being trapped in local optima. Consequently, in the present work, a novel meta-
heuristic optimization technique called artiﬁcial cell swarm optimization (ACSO) has
been proposed. The idea behind this optimization technique is mainly inspired by the
artiﬁcial cell division (ACD) algorithm [37]. The search agents in the proposed
methods are artiﬁcial cells, which are inspired by biological living cells. The proposed
method has been compared to PSO and GA.
The remaining sections organization of the article is as follows. Section 2 describes
the ACD mechanism in details. Section 3 reports the proposed ACSO with theoretical
background. In Sect. 4, the experimental methodology is deployed along with the
objective functions to test the proposed technique and to compare it with GA and PSO.
In Sect. 5, the experimental results are reported with comparative analysis and dis-
cussion. The conclusion of the work is included in Sect. 6.
2
Artiﬁcial Cell Division
Artiﬁcial cell division (ACD) is a process of artiﬁcial cells (ACs) reproduction [37],
where the artiﬁcial cells participate to produce the next generation of artiﬁcial cells. The
ACs participating in the ACD process has limited abilities and artiﬁcial rules. Each AC
in the current problem is employed as a search agent in the search space through
modifying the actual ACD process to frame it as an optimization technique. The
modiﬁcations are as follows:
Artiﬁcial Cell Swarm Optimization
197

(a) The necessity condition has been modiﬁed, where the ACs participate in ACD after
each interval of discrete time irrespective of its current status.
(b) The artiﬁcial cells regress to another artiﬁcial cell. They only participate in ACD.
The ACs generation can be depicted using the Generation Tree [37], which is a tree
data structure. Through the generation tree, every child node portrays that a new AC is
either produced or evolved from the parent node which is an ancestor of it. Figure 1
illustrated a typical Generation Tree. However; in the present work, while modeling the
optimization techniques, the ACs that are considered did not have any ability to evolve.
Only artiﬁcial cell division is employed.
In Fig. 1, the ACs’ subscripts denote the sequence of their ancestors, for example,
C11 is the ﬁrst successor of C1 and so on.
2.1
Artiﬁcial Cell Swarm
Artiﬁcial cell swarm (ACs) is a swarm of ACs, which is capable of participating in the
ACD. The major modiﬁcation in the characteristics of an artiﬁcial cell is their ability to
produce their successor ACs at a certain location other than its current position. The
ACs do not communicate with each other like the agents in other optimization tech-
niques. Some important parameters regarding the proposed method are deﬁned as
follows:
Fig. 1. A typical generation tree
198
S. Chatterjee et al.

• Life of Artiﬁcial Cell
The ACs in the proposed method are not immortal. Cells have an understanding of
discrete time. The life of an AC depends on the quality of its current position, which is
given by
Lt
i / fi
ð1Þ
where Lt
i denotes the life of ith cell at time t and fi denotes the ﬁtness of the current
location of ith cell.
• Productivity of Artiﬁcial Cell
Productivity should not be neither too large that populates the search space with too
many ACS nor too small that takes unreasonable time to ﬁnd the global optima. The
ACs productivity is considered to be a ﬁxed number of successor cells that are pro-
duced by each artiﬁcial cell after every instance of time.
• Successor Distance
After each time instance, the ACD occurs. Each artiﬁcial cell produces its successors at
certain distance from its current location. The distance depends on the current location
quality of the ACs as follows:
dt
ij / f 1
i
ð2Þ
where dt
ij denotes the distance of jth successor from the ith cell’s current location at
time t, and fi denotes the ﬁtness of the current location of ith cell. Each successor is
placed at the same distance from the current location of parent cell. This relation
reveals that the successor’s distance from its parent reduces if the current location
quality of the parent cell is superior. Thus, the successor produced by an artiﬁcial cell
will be close to its current location as the successor move toward the global optima.
• Signiﬁcance of Life and Successor Distance
Life and successor distance of an artiﬁcial cell take a vital role in optimization process.
From Eq. (1), it can be observed that Life of the ith cell at time t is proportional to the
ﬁtness of the ACs location. Hence, the ACs life increases as the movement becomes
close to the global optima. The successor distance of successor cells is inversely
proportional to the ﬁtness value of the ACs location as depicted in Eq. (2). Combining
Eqs. (1) and (2), the following relation is obtained:
dt
ij / Lt1
i
ð3Þ
Thus, at time t, the successor distance of successors due to the ith cell is inversely
proportional to the ACs Life. This signiﬁes that as the ACs Life is good (i.e., close to
the global optima), it would be unnecessary to place successors at a far distance; rather
it would be better to search in the current location proximity. Hence, the successor
distance, in this case, is lesser than the successor distance in the case when cell’s
Artiﬁcial Cell Swarm Optimization
199

location is comparatively bad. This property signiﬁcantly prevents the ACs from
producing successors having greater successor distance at proximity of locations that
are expected to be good. Otherwise, they would have overlooked the global optima
even if they are very close to it.
2.2
Population Control
Consequently, it was observed that the ACs production affects the search agent’s
number and it increases after every instance of time. Thus, after some iteration, the
number of search agents could be large. This may slow down the searching process.
Though, the adverse effect of increased ACs population is efﬁciently controlled by the
life of an artiﬁcial cell, it is evident that after some iteration, a number of cells would
complete its life span, and thus, they will neither be part of the population nor be
producing any cells further and the population is also expected to be decreased.
However, as the successor cells inherit the abilities of their parents, they also take part
in ACD process and thereby increase the population by some factor. Hence, the
uncontrolled increment of ACs population can only be prevented if there is a trade-off
between the number of the generated ACs at certain time instance and the number of
the cells died at the same time instance. The following deﬁnitions are included to
understand the nature of the population increment, which are
• Lambda Function
The lambda function is a function that maps from real to [0, 1] and provides an estimate
of the quality of overall population at time instance t.
K
X
i
f t
i
 
!
: R ! ½0; 1
ð4Þ
where P
i f t
i denotes the sum of ﬁtness of all living ACs at time instance t. The
approximate population at time instance t þ 1 is expressed as:
N t þ 1
ð
Þ ¼ n  K
X
i
f t
i
 
!
 N tð Þ
ð5Þ
where n denotes the ACs productivity, and NðtÞ is the approximate population at time
instance t.
• Utility of Lambda Function
Lambda function has been introduced to ﬁnd the approximate population at any certain
time instance. At any time instance t, the overall population quality can be measured as a
collective measurement of all the living ACs. This is performed by taking the sum of
ﬁtness of their current positions. Though, it is obvious that the sum of ﬁtness would vary
from problem to problem, in the current work, a deﬁnition for the Lambda function is
given to quality estimate of the current population within range [0, 1]. The value is
expected to tend to “1” if the most number of the ACs is close to the global optima.
200
S. Chatterjee et al.

It can also be observed from Eq. (1) that an artiﬁcial cell survives long if it is
residing in a location having good ﬁtness value, or in the other words, superior ﬁtness
value implies longer life span. Thus, the increase of the ﬁtness sum of all the ACs leads
to an increase for their chance to survive for long time. Similarly, a low value of sum of
ﬁtness would simply imply low life expectation of the overall population or majority of
the population. In this way, the sum of ﬁtness provides a good estimate for the overall
population quality. It is evident that a good-quality population would survive long and
eventually increase the population; on the other hand, poor quality indicates a loss or
decrement in population in the near future. Subsequently, in the present work, consider
that the approximate population at time t þ 1 depends on the productivity of ACs,
Lambda function, and the current population.
3
System Overview
Typically, the optimization problems are concerned with determining the values for one
or some decision variables that convene the objective(s) the best without violating the
constraint(s). According to the objective function, optimization problems may have
multiple solutions some of which may be local optima.
• Evolutionary Algorithm
Evolutionary algorithms (EA) utilize the simulated evolution as a search procedure to
generate candidate solutions, as it is inspired by genetics and natural selection. The
most well-known evolutionary algorithm type is the genetic algorithm (GA) [25]. In
genetic algorithms, the search is primarily driven by the use of recombination, a
mechanism of exchange of information between solutions to “breed” new ones,
whereas evolution strategies principally use mutation, a process of randomly modifying
solutions [38].
4
Proposed Work
The proposed ACSO optimization technique focuses on gaining the optimal ﬁtness
with the time increase. Hence, it is obligatory to provide a ﬁtness function with the
proposed ACSO algorithm. The main goal of the current work is to optimize the ﬁtness
function to achieve the best ﬁtness value. Thus, the following concepts are considered.
• Artiﬁcial Cell
An artiﬁcial cell is an abstract entity which can:
A. Evaluate the ﬁtness function with respect to a given vector m ¼ m1; m2; . . .mn
f
g for
each search agent.
Artiﬁcial Cell Swarm Optimization
201

B. Undergo the ACD to disintegrate into 2n new cells to form next generation.
C. Have a life limit which determines the longevity and a level that determines its split
range.
If the next generation cell produces better ﬁtness than its parent generation, then its life
remains unchanged and the successor distance decreases by a rate of decrement rd. This
ensures a search in closer proximity of its parent. If the next generation cell produces
less ﬁtness than its parent’s generation, then its life gets decremented by a unit and the
successor distance is incremented by a rate of increment ri, and thus, it searches in
distant search domains.
• Successor Distance
Successor distance (S) is a parameter introduced in the current proposed algorithm. It
determines the splitting range of the parent cell after evaluation. At each generation, the
successor distance is changed as follows:
A. The i þ 1
ð
Þth generation cell produces better value than the ith generation if di þ 1 ¼
di  rd and Si þ 1 ¼ Si  di þ 1
B. The ði þ 1Þth generation cell produces worse value than the ith generation if
di þ 1 ¼ di þ ri and Si þ 1 ¼ Si þ di þ 1;
where d is the change of successor distance.
• The Life
Life is a parameter introduced in the proposed algorithm that determines the longevity
of a cell and its next generations. After a parent cell undergoes ACD, the next gen-
eration child cell will inherit the life of the parent, and depending upon the ﬁtness
value, its life will either remain same or will be decremented by unity. At each gen-
eration, the life will change as follows:
A. The ði þ 1Þth generation cell produces better value than ith generation, when
lifei þ 1 ¼ lifei
B. The ði þ 1Þth generation cell produces worse value than ith generation, when
lifei þ 1 ¼ lifei  1
• The Artiﬁcial Cell Division Property
An artiﬁcial cell situated at m ¼ m1; m2; . . .mn
f
g in a n dimensional search space will
undergo ACD to produce 2n number of new children. If the parent has the vector as
v ¼ v1; v2; . . .vn
f
g,
then
it
will
split
to
form
child
1
with
vector
m ¼ m1 þ Si; m2; . . .; mn
f
g, child 2 with vector m ¼ m1  Si; m2; . . .; mn
f
g, child 3 with
vector m ¼ m1; m2 þ Si; . . .; mn
f
g, child 4 with vector m ¼ m1; m2  Si; . . .; mn
f
g, and so on
till child (2n  1)with vector m ¼ m1; m2; . . .mn þ Si
f
g, and child 2n with vector
m ¼ m1; m2; . . .mn  Si
f
g.
202
S. Chatterjee et al.

Initially, a certain number of cells with a certain successor distance and life are
initialized with a random vector. Afterward, each cell evaluates the ﬁtness value and
accordingly the best ﬁtness is stored as the “gbest” that refers to the global best ﬁtness
value. After the evaluation, the cells split to form the next child cells. Each child cell
will do the same procedure as its parent cell and if it produces a better ﬁtness value or
same ﬁtness value, then it will be granted with the same life value as its parent, else it
will gain a unit less life than its parent. Producing a better or same ﬁtness will also
result in decreasing the Successor Distance, i.e., the splitting range by the rate of
decrement, failure of which results in increasing the level by the rate of increment.
Again, each cell of the new generation will undergo ACD maintaining the same rules.
Hence, the process will continue until the life becomes zero. Thus, a particular ﬁrst
generation cell is capable of producing 2nlife


number of cells and can reach a distance
of
life  Successor Distance
b
c from its parent. The successor distance and life of the
cell actually governs the effectiveness of the search procedure. The proposed ACSO
algorithm can thus be described as follows.
5
Experimental Result and Discussion
The proposed ACSO has been compared to other widely used and successful standard
optimization algorithms, such as the GA, PSO, and the bat algorithm-based opti-
mization. Simple and traditional versions of GA and PSO are used. Bat algorithm as
described in [15] has been employed. Seven benchmark functions, namely Ackley’s
function (d = 128), Rosenbrock’s function (d = 16), Booth’s function, Schaffer
Artiﬁcial Cell Swarm Optimization
203

function (N2), Schaffer (N4), Schwefel’s function (d = 128), and Rastrigin’s function
[39–47] have been used to test and compare the algorithms. For each function, each
algorithm has been run 100 times and values of the mean along with the standard
deviation have been reported. The success rate of each algorithm in reaching the global
optima is reported. A small error e\105 has been used as stopping criteria. For the
GA procedure, a mutation probability of 0.06 and crossover probability of 0.94 has
been used, while in case of the PSO, number of particles varying from 15 to 35 is
sufﬁcient to achieve the global optima with learning parameter values set to 2 and 1,
respectively.
• Initial Experimental Analysis
The experiments are carried out in a 1.8 GHz dual-core processor PC by following the
experimental setup described in Sect. 4. In the current study, the performance is
measured in terms of the iterations taken to reach the expected accuracy for the ACSO
algorithm as well as the GA, PSO, and bat algorithm. The experimental results are
depicted in Table 1. Table 1 demonstrates the (mean ± standard deviation (success
rate)) for each row with the number of iterations’ values for each algorithm.
Table 1 establishes that the bat algorithm is superior to the GA and PSO. Though
the performance of the proposed ACSO is the best compared to all the other algorithms
employed in the current study, it achieves the least mean ± standard deviation for the
required number of iterations compared to the other corresponding values of the other
algorithms. Moreover, it is obvious that ACSO achieves the fastest convergence to the
maximum accuracy of 100% with the Ackley’s function (d = 128), Rosenbrock’s
function (d = 16), Booth’s function, Schaffer function (N2), and Rastrigin’s function,
while reached accuracy of 99% with both the Schaffer (N4) and Schwefel’s function
(d = 128). However, the GA, PSO, and the bat algorithms take a larger number of
iterations to converge to less accuracy values.
This is achieved by employing varying number of search agents in the ACSO,
which are not present in GA, PSO, and BA. Additional search agents are produced as a
result of the ACD procedure. Depending on the quality of the current positions of the
respective search agents, the ACD procedure produces a sufﬁcient number of additional
search agents to increase the number of local searches. Thus, the varying number of
search agents facilitates the proposed ACSO algorithm to search more number of points
on the search space at any time and thereby assures a fast convergence.
In addition, the same results are obtained by measuring the computational time-
consuming for the ACSO compared to the other methods in order to prove the supe-
riority of the proposed algorithm as illustrated in Table 2. Table 2 includes the time
entries that are the average of execution times in seconds for each algorithm which has
been run over 100 times.
204
S. Chatterjee et al.

Table 1. Comparative study of ACSO with GA, PSO, and BA
Benchmark functions/algorithms
GA
PSO
BA
ACSO
Ackley’s (d = 128)
32,720 ± 327 (90%)
23,407 ± 4325 (92%)
6933 ± 2317 (100%)
41 – 7 (100%)
Rosenbrock’s
(d = 16)
55,723 ± 901 (90%)
32,756 ± 5325 (98%)
7923 ± 3293( 100%)
53 – 11 (100%)
Booth’s
6384 ±617 (92%)
4567 ±765 (96%)
1352 ± 658 (99%)
8 – 2 (100%)
Schaffer (N2)
23,870 ± 259 (95%)
16,843 ± 356 (98%)
2496 ± 1209 (98%)
13 – 3 (100%)
Schaffer (N4)
29,483 ± 286 (90%)
19,572 ± 387 (92%)
3248 ± 1453 (96%)
17 – 5 (99%)
Schwefel’s (d = 128)
227,329 ± 7572 (95%)
14,522 ± 1275 (97%)
8929 ± 729 (99%)
84 – 17 (99%)
Rastrigin’s
110,523 ± 5199 (77%)
79,491 ± 3715 (90%)
12,573 ± 3372 (100%)
96 – 21 (100%)
Artiﬁcial Cell Swarm Optimization
205

Table 2 depicts that the bat algorithm tends to converge faster than the PSO and the
GA. However, the ACSO achieves the fastest convergence compared to the GA, PSO,
and bat algorithm. These results are supporting to the results obtained in Table 1,
which proves that the least required time which is equivalent to the least required
number of iterations for the ACSO is compared to the GA, PSO, or bat algorithm.
A plot of the population versus iteration for four benchmark functions used in the
present study is demonstrated in Fig. 2.
Figure 2 establishes that the population is dynamic in number which provides the
fastest converge compared to all the other algorithms. Moreover, in Fig. 3, a plot of
population versus iteration is depicted for the Rosenbrock function.
Table 2. Comparative study in terms of execution time in seconds
Benchmark functions/algorithms
GA
PSO
BA
ACSO
Ackley’s (d = 128)
21.85
12.88
7.46
2.5
Rosenbrock’s (d = 16)
38.20
26.58
23.54
20.42
Booth’s
6.38
4.08
3.04
2.24
Schaffer (N2)
17.48
16.87
15.87
14.87
Schaffer (N4)
23.43
16.24
16.09
15.42
Schwefel’s (d = 128)
151.89
25.04
23.48
22.15
Rastrigin’s
76.28
36.27
32.19
24.22
Fig. 2. A plot of population versus iteration for different benchmark functions optimized by
ACSO
206
S. Chatterjee et al.

Figure 3 contains both the real population graph and the expected population by
employing Lambda function. The ﬁgure reveals that the expected nature of population
distribution is almost similar in nature. In addition, Figs. 4, 5, and 6 include the error
plots versus the iteration plot for different benchmark functions using the ACSO
algorithm.
Figures 4, 5, and 6 illustrate the gradual reduce of the error till the proposed
algorithm achieves the optimal value with minimum error.
The preceding results proved the superiority of the proposed new ACSO algorithm
compared to the standard effective other optimization algorithms, namely the GA, PSO,
and the bat algorithm tested by seven benchmark functions. Hoverer, the limitation of
the proposed ACSO algorithm lies in achieving the fastest convergence with the cost of
employing more number of search agents, thereby incurring an extra space complexity.
Although it is noteworthy to mention that due to the advancement in modern tech-
nology, the space complexity has been well-tackled. Consequently, as a future scope,
reduction of space complexity can be attempted with the proposed ACSO algorithm.
• Experimental Analysis based on CEC’05 benchmark
The previous section studied the performance using benchmark functions from different
literatures in terms of the execution time and iterations to achieve previously set
tolerance. The current section introduces a similar comparative study in terms of the
function evaluations; thus, the CEC’05 benchmark [44] has been engaged for this
Fig. 3. A plot of population versus iteration for the Rosenbrock function including the expected
population predicted by Lambda function
Artiﬁcial Cell Swarm Optimization
207

purpose. The comparative study is carried out by following the evaluation criterion
suggested in [44]. Ten different functions are considered, where some of them are
randomly chosen and both 10-dimensional and 30-dimensional versions are tested. The
result is tabulated in Table 3.
Table 3 reports that for lower-dimensional variations of function (10 dimensions),
the PSO performed better in terms of function evaluations. The BA outperformed PSO
to a greater extent. The BA is at better than the traditional version of PSO. Finally,
ACSO is found to be signiﬁcantly better in F9, and in addition, in the remaining cases,
the performance is little better than BA. Higher-dimensional variations of the bench-
mark functions reveal similar results. The performance is gradually improving as we
move from GA to PSO and BA. The results of ACSO are promising. In this case, the
ACSO has outperformed BA to a greater extent.
Figures 7 and 8 depict a comparative plot of function evaluations using all four
algorithms under the current study for 10 dimensions and 30 dimensions; respectively.
The plot further establishes the superiority of ACSO. It illustrates that for higher
dimensions, the proposed ACSO performs well in comparison with its close perfor-
mance against BA in case of 10-dimensional variations of functions.
Fig. 4. A plot of error versus iteration for Ackley’s function
208
S. Chatterjee et al.

Fig. 5. A plot of error versus iteration for Schaffer (N2) and Schaffer (N4)
Fig. 6. A plot of error versus iteration for Booth’s function
Artiﬁcial Cell Swarm Optimization
209

Table 3. Comparison in terms of average function evaluations
Function
GA
PSO
BA
ACSO
F1 (10D)
70,400
42,450
7350
5690
F2 (10D)
32,400
18,837
3060
2650
F7 (10D)
31,750
18,750
2980
2240
F9 (10D)
98,550
70,332
12,350
9278
F12 (10D)
66,950
8264
5165
4966
F14 (10D)
98,650
55,765
9356
9128
F6 (30D)
290,760
215,040
112,000
66,450
F8 (30D)
227,800
167,550
98,535
39,414
F10 (30D)
108,250
80,185
48,830
36,420
F12 (30D)
119,600
12,360
7364
7252
F14 (30D)
158,000
97,450
18,330
17,457
F18 (30D)
163,850
98,027
19,026
18,879
Fig. 7. Comparative plot of functions (10 dimensions) from CEC’05 benchmarks
210
S. Chatterjee et al.

6
Conclusion
The present work proposed an artiﬁcial cell division inspired meta-heuristic novel
optimization technique. This proposed ACSO algorithm used a time-varying number of
search agents and ensured a fast convergence. The ACSO algorithm has been compared
to standard algorithms, namely the GA, PSO, and the bat algorithm, by applying a set
of benchmark functions to test the optimization techniques’ performance. The exper-
imental results established that the ACSO proposed algorithm is extremely successful
in locating the global optima faster than well-reputable optimization algorithms.
The ACSO algorithm achieved the fastest convergence ability.
References
1. Bonabeau E, Dorigo M, Theraulaz G (1999) Swarm intelligence: from natural to artiﬁcial
systems. Oxford University Press, New York
2. Kennedy J, Eberhart RC (1995) Particle swarm optimization. In: 1995 IEEE international
conference on neural networks, vol 4. pp 1942–1948
3. Chakraborty S, Samanta S, Biswas D, DeyN (2013) Particle swarm optimization based
parameter optimization technique in medical information hiding. In: IEEE international
conference on computational,pp 1–6
4. Chatterjee S, Sarkar S, Hore S,Dey N, AshourAS (2017) Particle swarm optimization trained
neural network for structural failure prediction of multistoried RC buildings. Neural Comput
Appl 28(8):2005–2016
Fig. 8. Comparative plot of functions (30 Dimensions) from CEC’05 benchmarks
Artiﬁcial Cell Swarm Optimization
211

5. CoelloCoello CA, Pulido GT (2005) Multiobjective structural optimization using a
microgenetic algorithm. Struct Multidisciplinary Optim 30(5):388–403
6. Dorigo M, Gambardella LM (1997) Ant colony system: a cooperative learning approach to
the travelling salesman problem. IEEE Trans Evol Comput 1(1):53–66
7. Dorigo M (2004) Ant colony optimization. MIT Press, Cambridge
8. Dorigo M, Maniezzo V, Colorni A (1996) The ant system: optimization by a colony of
cooperating agents. IEEE Trans Syst Man Cybernetics Part B 26(1):29–41
9. Kaliannan J, Baskaran A, DeyN (2015) Automatic generation control of thermal-thermal-
hydro power systems with PID controller using ant colony optimization. Int J Serv Sci
Manage 6(2):18–34
10. Dorigo M, Trianni V, Sahin Eet.al (2004) Evolving self-organizing behaviors for a swarm-
bot. Auton Robots 17:223–245
11. Tereshko,V (2000) Reaction–diffusion model of a honeybee colony’s foraging behaviour. In:
Schoenauer M (ed) Parallel problem solving from nature VI, Lecture notes in computer
science, vol 1917. Springer–Verlag, Berlin, pp 807–816
12. Tereshko V, LEE T (2002) How information mapping patterns determine foraging behaviour
of a honeybee colony. Open Syst Inf Dyn 9:181–193
13. Lucic P, Teodorovic D (2002) Transportation modeling: an artiﬁcial life aproach. In: ICTAI,
pp. 216–223
14. Teodorovic D (2003) Transport modeling by multi-agent systems: a swarm intelligence
approach. Transp Plann Technol 26(4)
15. Drias H, Sadeg S, Yahi S (2005) Cooperative bees swarm for solving the maximum
weighted satisﬁability problem, computational intelligence and bioinspired systems. In: 8th
international workshop on artiﬁcial neural networks IWANN 2005. Vilanova, Barcelona,
Spain, June 8–10
16. Khosravy M, Gupta N, Patel N, Senjyu T, Duque CA (2020) Particle swarm optimization of
morphological ﬁlters for electrocardiogram baseline drift estimation. In: Applied nature-
inspired computing: algorithms and case studies. Springer, Singapore, pp 1–21
17. Jagatheesan K, Anand B, Samanta S, Dey N, Ashour AS, Balas VE (2017) Particle swarm
optimisation-based parameters optimisation of PID controller for load frequency control of
multi-area reheat thermal power systems. Int J Adv Intell Paradigms 9(5–6):464–489
18. Benatchba K, Admane L, Koudil M (2005) Using bees to solve a data-mining problem
expressed as a max-sat one, artiﬁcial intelligence and knowledge engineering applications: a
bioinspired approach. In:First international work-conference on the interplay between natural
and artiﬁcial computation IWINAC 2005. Palmas, Canary Islands, Spain, June 15–18
19. Krishnanand KN, Ghose D (2009) Glowworm swarm optimization for simultaneous capture
of multiple local optima of multimodal functions. Swarm Intell 3:87–124
20. Yang X-S (2010) A new metaheuristic bat-inspired algorithm Nature inspired cooperative
strategies for optimization (NICSO 2010). Springer Berlin Heidelberg, pp 65–74
21. Yang X-S, Gandomi AH (2012) Bat algorithm: a novel approach for global engineering
optimization. Eng Comput 29:464–483
22. Yang X-S (2011) Bat algorithm for multi-objective optimization. Int J Bio-Inspired Comput
3:267–274
23. Gandomi AH et al (2013) Bat algorithm for constrained optimization tasks. Neural Comput
Appl 22:1239–1255
24. Rashedi E, Nezamabadi-pour H et al (2009) GSA: a gravitational search algorithm. Inf Sci
179(13):2232–2248
25. Holland JH (1975) Adaptation in natural and artiﬁcial systems. University of Michigan
Press, Ann Arbor, MI
212
S. Chatterjee et al.

26. Chatterjee S, Ghosh S, Dawn S, Hore S, Dey N (2016) Forest Type Classiﬁcation: a hybrid
NN-GA model based approach. In: Information systems design and intelligent applications,
pp. 227–236
27. Dey N, Ashour A, Beagum S, Pistola D, GospodinovM (2015) Parameter optimization for
local polynomial approximation based intersection conﬁdence interval ﬁlter using genetic
algorithm: an application for brain MRI image de-noising. J Imaging 1(1):60–84
28. Hore S, Chatterjee S, Santhi V, Dey N, AshourAS (2017) Indian sign language recognition
using optimized neural networks. In: Information technology and intelligent transportation,
pp:553–563
29. Dey N (ed) (2017) Advancements in applied metaheuristic computing. IGI Global
30. Gupta N, Patel N, Tiwari BN, Khosravy M (2018) Genetic algorithm based on enhanced
selection and log-scaled mutation technique. In: Proceedings of the future technologies
conference. Springer, pp 730–748
31. Singh G, Gupta N, Khosravy M (2015) New crossover operators for real coded genetic
algorithm (RCGA). In: 2015 international conference on intelligent informatics and
biomedical sciences (ICIIBMS). IEEE, pp 135–140
32. Gupta N, Khosravy M, Patel N, Senjyu T (2018) A Bi-level evolutionary optimization for
coordinated transmission expansion planning. IEEE Access 6:48455–48477
33. Gupta N, Khosravy M, Patel N, Sethi IK (2018) Evolutionary optimization based on
biological evolution in plants. Procedia Comput SciElsevier 126:146–155
34. Gupta N, Khosravy M, Patel N, Mahela OP Plant biology-inspired genetic algorithm:
superior efﬁciency to ﬁreﬂy optimizer. In: Applications of ﬁreﬂy algorithm and its variants,
from Springer tracts in nature-inspired computing (STNIC), Springer International
Publishing, in Press 2020
35. Jagatheesan K, Anand B, Dey N, Gaber T, Hassanien AE, Kim TH (2015, September) A
design of pi controller using stochastic particle swarm optimization in load frequency control
of thermal power systems. In: 2015 fourth international conference on information science
and industrial applications (ISI). IEEE, pp 25–32
36. Moraes CA, De Oliveira EJ, Khosravy M, Oliveira LW, Honório LM, Pinto MF (2020) A
hybrid bat-inspired algorithm for power transmission expansion planning on a practical
Brazilian network. In: Applied nature-inspired computing: algorithms and case studies.
Springer, Singapore, pp 71–95
37. Chatterjee S, Hore S, Paladhi S, DeyN (2015) Counting all possible simple paths using
artiﬁcial cell division mechanism for directed acyclic graphs. In: 2nd International
Conference on computing for sustainable global development (INDIACom), pp 1874–
1879, (2015)
38. Kamal S, Dey N, Nimmy SF, Ripon SH, AliNY (2018) Evolutionary framework for coding
area selection from cancer data. Neural Comput Appl 29(4):1015–1037
39. https://en.wikipedia.org/wiki/Test_functions_for_optimization
40. Mühlenbein H, Schomisch D, Born J (1991) The parallel genetic algorithm as function
optimizer. Parallel Comput 17:619–632
41. Schwefel HP (1981) Numerical optimization of computer models. Wiley
42. Hu J-J, Su Y-T, Li T-HS (2010) A novel ecological-biological-behavior particle swarm
optimization for Ackley’s function. In: International symposium on computer, communi-
cation, control and automation (3CA), vol 2, pp 377–380
43. Shamsudin HC, Irawan A, Ibrahim Z, Faiz A, Abidin Z, Wahyudi S, AbdulRahim MA,
Khalil K (2012) A fast discrete gravitational search algorithm. In: Fourth international
conference on computational intelligence, modelling and simulation, pp 24–28
Artiﬁcial Cell Swarm Optimization
213

44. Wang Y, DeBrunner LS, Zhou D, DeBrunner VE (2007) A novel multiplier less hardware
implementation method for adaptive ﬁlter coefﬁcients. In: IEEE international conference on
acoustics, speech and signal processing-ICASSP’07, vol 2, pp II–57
45. Sharma J, Singhal RS (2015) Comparative research on genetic algorithm, particle swarm
optimization and hybrid GA-PSO. In: 2nd international conference on computing for
sustainable global development (INDIACom), pp 110–114
46. Lee J, Song S, Yang Y, Shim H, Lee H, Lee K, Yoon Y (2007) Multimodal function
optimization based on the survival of the ﬁtness kind of the evolution strategy. In: 29th
annual international conference of the IEEE engineering in medicine and biology society,
pp 3164–3167
47. Suganthan PN, Hansen N, Liang JJ, Deb K, Chen YP, Auger A, Tiwari S (2005) Problem
deﬁnitions and evaluation criteria for the CEC 2005 special session on real-parameter
optimization. KanGAL report, 2005005
214
S. Chatterjee et al.

Chapter 10
Application Example of Particle Swarm
Optimization on Operation Scheduling
of Microgrids
Hirotaka Takano1(&), Hiroshi Asano1,2, and Neeraj Gupta3
1 Department of Electrical, Electronic and Computer Engineering, Gifu
University, 1-1, Yanagido, Gifu-Shi, Gifu 501-1193, Japan
takano@gifu-u.ac.jp, asano@criepi.denken.or.jp
2 Energy Innovation Center, Central Research Institute of Electric Power
Industry, 2-6-1, Nagasaka, Yokosuka-Shi, Kanagawa 240-0196, Japan
3 Department of Computer Science and Engineering, Oakland University,
Rochester, MI 48309, USA
neerajgupta@oakland.edu
1
Introduction
Microgrid is a concept of energy systems to manage a localized group of electrical power
sources and loads that can operate in both connecting and disconnecting to the con-
ventional power grids [1, 2]. This concept was originally proposed to provide the pos-
sibility of grid independence to electricity consumers with improving/keeping efﬁciency,
ﬂexibility, reliability and quality in the power supply–demand balancing operation.
Since the early 2000s, extensive researches and development have been in progress in
Europe, North America, and Japan in order to ﬁgure out efﬁcient solutions for microgrid
operations [3]. In association with the growth in penetration of renewable energy sources
(RESs), the microgrid has been attracting attention as one of the most realistic sustainable
energy systems in terms of efﬁcient use of the RESs. These are reasons why several
researches and development on microgrid-related techniques are continuously per-
formed and demonstrative ﬁeld tests have been actively promoted [1–6].
There are two types in components of the microgrid: One is controllable compo-
nent, and another is uncontrollable one. The former consists of controllable generation
systems (CGs), energy storage systems (ESSs) and controllable loads (CLs). A part of
the controllable components, such as electric vehicles (EVs), changes their attributes in
connection with the judgment whether the conventional power grids accept reverse
power ﬂow from them or not (accepted: ESS, not accepted: CL). On the other hand,
electrical loads in consumer side belong to the latter. Variable renewable energy-based
generation systems (VREGs), whose outputs strongly depend on the weather condition,
are also included. Solar photovoltaic generation systems (PVs) and wind power gen-
eration systems (WPs) are well known as the VREGs.
© Springer Nature Singapore Pte Ltd. 2020
M. Khosravy et al. (eds.), Frontier Applications of Nature Inspired Computation,
Springer Tracts in Nature-Inspired Computing,
https://doi.org/10.1007/978-981-15-2133-1_10

In the microgrids, since the VREGs take a signiﬁcant portion as the electrical power
sources, it becomes very difﬁcult to manage the power supply–demand appropriately
with few adverse effects on the conventional power grids [1–6]. If microgrid operators
cannot maintain the balance of power supply–demand, the resulting electricity
surplus/shortage must be compensated by trading electricity with an extra payment
(called imbalance penalty). Therefore, the operation scheduling method for the
microgrids is crucially required.
Focusing on the operations of CGs, operation scheduling problems in the micro-
grids are normally formulated as a mixed-integer programming (MIP) problem that
combines optimization problems of the unit commitment and economic load dispatch
(UC-ELD). The UC-ELD problem is one of the most popular optimization problems in
the electric power ﬁeld, especially for thermal generation scheduling in the conven-
tional power grids [7–13]. Traditional optimization-based and intelligent optimization-
based solution methods have been proposed to solve the problem around the world.
Dynamic programming (DP) and branch-and-bound (B&B) are typical traditional
optimization algorithms that have been applied to the UC-ELD problems [14–17].
Metaheuristic and evolutionary computation algorithms are used for solving the UC-
ELD problems, too [18–25]. Although several algorithms have been involved in the
solution methods of UC-ELD problems, there is no established solution method until
now.
Practical operation scheduling problems in the microgrids become complicated as
compared to those in the conventional power grids. This is because installation of the
other controllable components brings new optimization variables representing
charging/discharging operation of the ESSs and charging operation of the CLs. Fur-
thermore, inﬂuence of these controllable components cannot be neglected in the
microgrid operations, and therefore we have to treat all variables simultaneously from
the viewpoint of coordinated operation of the microgrid components [26–30].
This chapter, ﬁrst, presents problem frameworks to obtain coordinated operation
schedules of the controllable components in the microgrids. Discussions on how to
treat electricity trade and uncertainty originated from the VREGs and/or the electrical
loads are included. Next, particle swarm optimization (PSO) is selected as an example
of nature-inspired metaheuristic algorithms and applied to the formulated problems.
Afterward, the authors introduce a strategy, which utilizes characteristics of the for-
mulated problems, to enhance compatibility between the target problems and their
solution methods. By this strategy, application target of the PSO is speciﬁed to the UC
problems of CGs. Under the circumstances, another solution method that combines
binary particle swarm optimization (BPSO) and quadratic programming (QP) is pro-
posed. The BPSO is an extended algorithm of the standard PSO. Finally, validity of the
problem frameworks and usefulness of the PSO-based solution methods are veriﬁed
through numerical simulations and discussions on their results.
216
H. Takano et al.

2
Target Optimization Problems
Figure 1 illustrates a microgrid model composed by (1) CGs, (2) ESSs, (3) CLs,
(4) electrical loads and (5) VREGs. Components 1–3 are controllable, and Components
4 and 5 are uncontrollable. Detailed deﬁnition of the variables in this ﬁgure is described
in formulation of the target optimization problems (Sects. 2.1–2.3).
Operation scheduling problems of the microgrids are to determine a set of start-
up/shutdown timing and output shares of the CGs, charging/discharging states of the
ESSs and charging states of the CLs in response to the forecasted values of the net load
on each time interval. The net load is calculated by the sum of forecasted values of
electricity consumption in the electrical loads and outputs of the VREGs.
If the microgrid operators cannot procure necessary electricity to maintain the
balance in power supply–demand, the resulting electricity surplus/shortage must be
eliminated by the electricity trade with the conventional power grids. Extra payment is
required for compensating the electricity surplus/shortage as the imbalance penalty.
However, the trading electricity in the operation scheduling stage has the possibility to
relax difﬁculty in the power supply–demand balancing operation as compared to
adjusting operation of the controllable components. That is, appropriate operation
schedule considering the electricity trade provides the economic beneﬁt to the micro-
grid operators by improving/keeping the power supply reliability and quality. This is
the reason why the trading electricity is often regarded as an additional controllable
component in the operation scheduling problems of microgrids although components in
the conventional power grid side cannot be controlled by the microgrid side. Moreover,
it is one of the biggest differences with the UC-ELD problems for the conventional
power grids because the conventional power grids do not have such kind of backup
power sources.
In general, the operation scheduling problems of microgrids are formulated under
the following assumptions.
Fig. 1. Example of microgrid model
Application Example of Particle Swarm Optimization on Operation
217

• The forecasted values of the electricity consumption and the VREG outputs are
given no matter whether they include uncertainty or not.
• All efﬁciencies of the microgrid components are set as constant values to ease
difﬁculty in the target problem.
2.1
General Problem Framework
Traditionally, the operation scheduling problems are formulated under the premise that
the microgrids can be operated independently from the conventional power grids. The
optimization variables are deﬁned as
ui;t 2 0; 1
f
g; for 8i; 8t;
ð1Þ
gi;t 2 Gmin
i
; Gmax
i


; for 8i; 8t;
ð2Þ
sj;t 2 Smin
j
; Smax
j
h
i
; for 8j; t 2 TSj
ð3Þ
vk;t 2 Vmin
k
; 0


; for 8k; t 2 TVk;
ð4Þ
where t is time ðt ¼ 1; . . .; TÞ; i is the number of CGs ði ¼ 1; . . .; NGÞ; ui;t is the
ON/OFF state variable of CGs (ON: 1., OFF: 0.) which is an element of vectors ut and
u; gi;t is the output of CGs, which is an element of vectors gt and g; Gmax
i
and Gmin
i
are
the maximum and the minimum outputs of CGs; j is the number of ESSs
ðj ¼ 1; . . .; NSÞ; sj;t is the output of ESSs and an element of vectors st and s; Smax
j
and
Smin
j
are the maximum and the minimum capable outputs of ESSs
Smin
j
\0\Smax
j


;
TSj is the set of time that the ESSs are available; k is the number of CLs
ðk ¼ 1; . . .; NVÞ; vk;t is the consumption of CLs and an element of vectors vt and v;
Vmin
k
is the maximum capable consumption of CLs ðVmin
k
\0Þ; TVk is the set of time
that the CLs are available.
Fuel costs of the CGs are normally approximated as quadratic functions by means
of their outputs and thus can be minimized by controlling the CG outputs as steady as
possible. As opposed to the CGs, the ESSs consume no fuel in their operations directly,
and this makes a challenge in evaluation of their operating cost. Under these circum-
stances, the objective function is represented as
minF u; g; s; v
ð
Þ;
ð5Þ
F u; g; s; v
ð
Þ ¼
X
T
t¼1
Ct ut; gt
ð
Þ;
ð6Þ
Ct ut; gt
ð
Þ ¼
X
NG
i¼1
Ai þ Bigi;t þ Cig2
i;t


þ SCi 1  ui;t1


h
i
ui;t;
ð7Þ
218
H. Takano et al.

where C ut; gt
ð
Þ is the operation cost of CGs; SCi is the start-up cost of CGs; Ai, Bi and
Ci are the coefﬁcients of fuel cost.
The microgrid operation must satisfy the following operational constraints.
• Balance in power supply and demand
dt ¼
X
NG
i¼1
gi;tui;t þ
X
NS
j¼1
sj;t þ
X
NV
k¼1
vk;t; for 8t;
ð8Þ
• Reserve margin
P
NG
i¼1
gmin
i;t ui:t þ P
NS
j¼1
smin
j;t þ P
NV
k¼1
vmin
k;t  dt 1  alow
t


dt 1 þ aup
t
ð
Þ  P
NG
i¼1
gmax
i;t ui:t þ P
NS
j¼1
smax
j;t
;
8
>
>
>
<
>
>
>
:
for 8t;
ð9Þ
where dt is the forecasted net load which can be calculated by the sum of electricity
consumption and VREG outputs; aup
t
and alow
t
are the coefﬁcients for securing upper
and lower margins; gmax
i;t
and gmin
i;t are the maximum and the minimum outputs of CGs at
t; smax
j;t
and smin
j;t
are the maximum and the minimum outputs of ESSs at
t
smin
j;t \0\smax
j;t


; vmin
k;t is the maximum consumption of CLs at t
vmin
k;t \0


.
In addition, the microgrid components have several constraints for their operations
as shown below.
• State duration for controllable generation systems
If 0\uon
i;t \MUTi then ui;t ¼ 1
If 0\uoff
i;t \MDTi then ui;t ¼ 0

; for 8i; 8t;
ð10Þ
• Ramp rate for controllable generation systems
DGdown
i
 gi;t  gi;t1  DGup
i ; for 8i; 8t;
ð11Þ
• Maximum and minimum outputs of controllable generation systems
gmin
i;t  gi;t  gmax
i;t ; for 8i; 8t
ð12Þ
Application Example of Particle Swarm Optimization on Operation
219

gmin
i;t
¼ max Gmin
i
; gi;t1 þ DGdown
i


gmax
i;t
¼ min Gmax
i
; gi;t1 þ DGup
i


(
; for 8i; 8t;
ð13Þ
• Operation state for energy storage systems
Qmin
j
 qj;t  Qmax
j
; for 8j; t 2 TSj;
ð14Þ
If sj;t\0 then qj;t ¼ qj;t1  gjsj;t
If sj;t [ 0 then qj;t ¼ qj;t1  1
gj sj;t
(
; for 8j; t 2 TSj;
ð15Þ
• Maximum and minimum outputs of energy storage systems
smin
j;t  sj;t  smax
j;t ; for 8j; t 2 TSj;
ð16Þ
smin
j;t
¼ max Smin
j
; qj;t1  Qmax
j


smax
j;t
¼ min Smax
j
; qj;t1  Qmin
j


8
<
:
; for 8j; t 2 TSj;
ð17Þ
• Operation state for controllable loads
Pmin
k
 pk;t  Pmax
k
; for 8k; 8t;
ð18Þ
pk;t ¼ pk;t1  nvk;t; for 8k; t 2 TVk;
ð19Þ
• Maximum consumption of controllable loads
vmin
k;t  vk;t  0; for 8k; t 2 TVk;
ð20Þ
vmin
k;t ¼ max Vmin
k
; pk;t1  Pmax
k


; for 8k; t 2 TVk;
ð21Þ
where uon
i;t and uoff
i;t are the consecutive operating and suspending durations of CGs;
MUTi and MDTi are the minimum operating and suspending durations of CGs;DGup
i
and DGdown
i
are the ramp-up and the ramp-down rates of CGs; qj;t is the level of state of
charge (SOC) in ESSs; gj is the overall efﬁciency of ESSs; pk;t is the SOC level in CLs;
Pmax
k
and Pmin
k
are the maximum and the minimum SOC levels of CLs; nk is the overall
efﬁciency of CLs.
220
H. Takano et al.

This problem framework is similar to the UC-ELD problems in the conventional
power grids and suitable for independent operation of small power grids. By (8), the
ESSs and the CLs contribute to saving the operation cost of CGs described in (6) and
(7). However, it is not easy to decide the coefﬁcients for securing upper and lower
margins, aup
t
and alow
t
, appropriately. Since these equations do not include the trading
electricity, the imbalance penalty must be evaluated in the process of solution methods
additionally.
2.2
Including Electricity Trade
As already mentioned, the microgrids can operate in both connecting and disconnecting
to the conventional power grids. The electricity trade with the conventional power grids
often not only relaxes the difﬁculty in supply–demand management but also provides
operational alternatives for the microgrid operators. If we consider the electricity trade,
the objective function is modiﬁed as
F u; g; s; v
ð
Þ ¼
X
T
t¼1
Ct ut; gt
ð
Þ þ Mtet
½
;
ð22Þ
Ct ut; gt
ð
Þ ¼
X
NG
i¼1
Ai þ Bigi;t þ Cig2
i;t


þ SCi 1  ui;t1


h
i
ui;t;
ð23Þ
where et is the trading electricity ðet 2 RÞ; Mt is the price of electricity trade.
Moreover, the operational constraints are expressed by the following.
• Balance in power supply and demand
dt ¼
X
NG
i¼1
gi;tui;t þ
X
NS
j¼1
sj;t þ
X
NV
k¼1
vk;t þ et; for 8t;
ð24Þ
• Reserve margin
P
NG
i¼1
gmin
i;t ui:t þ P
NS
j¼1
smin
j;t þ P
NV
k¼1
vmin
k;t  dt 1  alow
t


 et
dt 1 þ aup
t
ð
Þ  et  P
NG
i¼1
gmax
i;t ui:t þ P
NS
j¼1
smax
j;t
;
8
>
>
>
<
>
>
>
:
for 8t:
ð25Þ
The other equations [Eqs. (5)–(21) excluding (6)–(9)] are common with the general
problem framework described in Sect. 2.1. In this problem framework, the microgrid
sells/buys electricity to the conventional power grids in response to the electricity price
at each time. Violation in (25) can be regarded as the imbalance penalty. However,
Application Example of Particle Swarm Optimization on Operation
221

there is still room for discussion on how to appropriately set aup
t
and alow
t
as same as the
problem formulation described in Sect. 2.1.
2.3
Considering Uncertainty
In the problem frameworks described in Sects. 2.1 and 2.2, the uncertainty in the net
load is treated by the coefﬁcients for securing upper and lower margins, aup and alow.
These coefﬁcients are normally set to secure several percent margins for the forecasted
value of net load, e.g., aup
t
¼ alow
t
¼ 0:05 (5% of the forecasted net load). However,
variation in the net load is not constant, especially in the case that we consider the
VREG outputs, and thus the forecasted value-based setting leads to discussion on its
appropriateness. If the coefﬁcients become bigger, operational risks originated from the
uncertainty can be reduced. In contrast, the resulting additional start-up/shutdown of
the CGs accompanies increase of the operation cost. With a view to solving the issue,
the authors deﬁne the net load as
dt 2 dmin
t
; dmax
t


; for 8t;
ð26Þ
where dmax
t
and dmin
t
are the maximum and the minimum assumable values of net load.
Now, the objective function is extended as
F u; g; s; v; e
ð
Þ
¼ P
T
t¼1
R
dmax
t
dmin
t
Ct ut; gt
ð
Þ þ Mtet þ Ite0
t


f dt
ð Þddt
(
)
;
ð27Þ
Ct ut; gt
ð
Þ ¼
X
NG
i¼1
Ai þ Bigi;t þ Cig2
i;t


þ SCi 1  ui;t1


h
i
ui;t;
ð28Þ
dt ¼
X
NG
i¼1
gi;tui;t þ
X
NS
j¼1
sj;t þ
X
NV
k¼1
vk;t þ et þ e0
t


; for 8t;
ð29Þ
Ifdt  et\ P
NG
i¼1
gmin
i;t ui:t þ P
NS
j¼1
smin
j;t þ P
NV
k¼1
vmin
k;t then
e0
t ¼ dt  et 
P
NG
i¼1
gmin
i;t ui:t þ P
NS
j¼1
smin
j;t þ P
NV
k¼1
vmin
k;t
 
!
Ifdt  et [ P
NG
i¼1
gmax
i;t ui:t þ P
NS
j¼1
smax
j;t then
e0
t ¼ dt  et 
P
NG
i¼1
gmax
i;t ui:t þ P
NS
j¼1
smax
j;t
 
!
Elsee0
t ¼ 0
;
8
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
:
for8t;
ð30Þ
222
H. Takano et al.

where f dt
ð Þ is the probability density function of net load; It is the price of imbalance
penalty.
In the proposed problem framework, dmax
t
, dmin
t
and f dt
ð Þ can be determined with
reference to the past record of microgrid operations. By (29) and (30), the operational
constraints of microgrids are integrated into a part of the objective function. The trading
electricity is classiﬁed into et and e0
t for individually calculating the expected trading
cost and the expected imbalance penalty in (27). As a result, we do not need to set the
coefﬁcients, aup
t
and alow
t
, because the reserve margin is secured automatically
depending on the result of expected cost calculation. The other constraints [Eqs. (10)–
(21)] are used in common with the previous frameworks.
Here, the authors ignore (10) and (11) from the target problem. This is because the
time interval in operation scheduling, Dt, often satisﬁes the following conditions, and
thus the constraints become inactive in the microgrids [21, 30, 31].
Dt  MUTi þ MDTi; for 8i;
ð31Þ
DGup
i  Gmax
i
 Gmin
i
DGdown
i
 Gmin
i
 Gmax
i

; for 8i:
ð32Þ
Similarly, the evaluation of (13) is unnecessary under these conditions. In this case,
gmax
i;t
and gmin
i;t
are simply equal to Gmax
i
and Gmin
i
, respectively.
3
Application of Particle Swarm Optimization
The target optimization problems formulated in Sects. 2.1–2.3 are complicated MIP
problems which have the discrete and the continuous optimization variables. As
deﬁned in (1)–(4), the former is the state of CGs, u, and the latter includes the outputs
of the CGs, g, the ESSs, s, and the CLs, v. In the formulation of Sect. 2.3, the trading
electricity, e, is included in the latter. Since it is extremely difﬁcult to solve the target
problems exactly, the intelligent optimization-based algorithms have been attracting
attention as a realistic alternative. In fact, several nature-inspired metaheuristics and
evolutionary computation algorithms have been applied to the similar problem
frameworks. Typical algorithms are genetic algorithm (GA) [18], simulated annealing
(SA) [19, 20], tabu search [21, 25] and PSO [22, 23, 30]. In this chapter, the PSO is
selected as the basis of solution method. An improvement strategy for solution methods
and its application are also introduced.
3.1
Solution Method Based on Standard Particle Swarm Optimization
PSO is a population-based stochastic computational method that optimizes a problem
by iteratively trying to improve a solution candidate with regard to a given measure of
solution quality (called ﬁtness function) [32]. Its algorithm was originally developed
through studies on the simulated social behavior representing the movement of birds or
ﬁshes (called particles) and has many similarities with GA. However, unlike the GA,
Application Example of Particle Swarm Optimization on Operation
223

the standard PSO has no evolutionary operators such as crossover and mutation. An
initial set of randomly created solutions (called initial swarm) propagates in the design
of search space toward the global optimal solution over a number of iterations (called
moves). All members of the swarm ﬁt and share information in search place. Each
particle l has a position, xn
l , and a velocity, yn
l , in iteration n ðn ¼ 1; 2; . . .; NÞ and ﬂies
through on the search space for ﬁnding their best positions and velocities in accordance
with (33) and (34).
xn þ 1
l
¼ xn
l þ yn þ 1
l
;
ð33Þ
yn þ 1
l
¼ xyn
l þ c1r1 x
l  xn
l


þ c2r2
min
lL x
l
	

 xn
l


;
ð34Þ
where c1 and c2 are the cognitive factors that represent the trust for each particle and the
swarm; r1 and r2 are the random numbers in the range, 0; 1
½
; x
l is the personal best for
particle l ðx
l : pbest, min
lL x
l : gbest); L is the set of all particles. Here, the inertia weight
factor, x, controls the iteration size in the PSO algorithm.
In this chapter, the position of particles is expressed as
xn
l ¼ u; g; s; v; e
ð
Þ:
ð35Þ
Although the PSO has succeeded in many continuous problems, it has still some
difﬁculties to treat the discrete optimization problems [33]. In order to modify the
ON/OFF states of CGs, ui;t, a sigmoid function is introduced in part of the PSO
algorithm.
If 0:5\
1
1 þ eui;t then ui;t ¼ 1; else ui;t ¼ 0; for 8i; 8t:
ð36Þ
As shown in (36), if value of the sigmoid limiting transformation function is greater
than 0.5, the ith CG becomes “ON” at time t; otherwise, it becomes “OFF”.
During the iterative process, the ﬁtness function of individual particles is valued to
measure their superiority. With the aim of handling the constraints described in Sects.
2.1–2.3, the penalty method, which replaces a constrained optimization problem by a
series of unconstrained problems, is applied. The ﬁtness function in the general
problem framework described in Sect. 2.1 can be formulated as
E u; g; s; v
ð
Þ ¼
X
T
t¼1
Ct ut; gt
ð
Þ þ VIOt
½
;
ð37Þ
where VIOt is the weighted sum of violation of the constraints including the violations
for (8) and (9) (if the constraints (10) and (11) become active, they are also included in
the calculation).
In the formulation of Sect. 2.2, the ﬁtness function is calculated as
224
H. Takano et al.

E u; g; s; v
ð
Þ ¼
X
T
t¼1
Ct ut; gt
ð
Þ þ Mtet þ VIO00
t


;
ð38Þ
where VIO00
t is the weighted sum of violation of the constraints including (24) and (25)
instead of (8) and (9).
On the other hand, the ﬁtness function in the problem framework described in
Sect. 2.3 can be represented as
E u; g; s; v; e
ð
Þ
¼ P
T
t¼1
R
dmax
t
dmin
t
Ct ut; gt
ð
Þ þ Mtet þ Ite0
t þ VIO0
t


f dt
ð Þddt
(
)
;
ð39Þ
where VIO00
t is the weighted sum of violation of the constraints excluding the violations
for constraints of the balance of supply–demand and the reserve margin because these
violations are already evaluated in Ite0
t:
3.2
Solution Method Based on Binary Particle Swarm Optimization
and Quadratic Programming
In order to improve compatibility between the target problems and their solution
method, the authors replace the optimization variables and the operation cost function
with
u0
h;t 2 0; 1
f
g; for 8h; 8t;
ð40Þ
g0
h;t 2 G0min
h
; G0max
h


; for 8h; 8t;
ð41Þ
Ct u0
t; g0
t


¼
P
NG þ 3
h¼1
Ah þ Bhg0
h;t þ Chg02
h;t


þ SCh 1  u0
h;t1


n
o
u0
h;t;
ð42Þ
where h is the number of controllable components ðh ¼ 1; . . .; NG; . . .; NG þ 3Þ; u0
h;t is
the state of controllable components, which is an element of vectors u0
t and u0; g0
h;t is the
output of controllable components, which is an element of vectors g0
t and g'; G0max
h
and
G0min
h
are the maximum and the minimum outputs of controllable components.
In (40) and (41), the ESSs and the CLs are aggregated into large-scale components,
respectively, to emphasize perspicuity of the formulation. The NG þ 1
ð
Þth component
means the aggregated ESS, the NG þ 2
ð
Þth component is the aggregated CL, and the
NG þ 3
ð
Þth component means the trading electricity. Since g0
NG þ 1;t, g0
NG þ 2;t and g0
NG þ 3;t
include 0 in their controllable range, we can set u0
NG þ 1;t, u0
NG þ 2;t and u0
NG þ 3;t by 1 in the
range of available periods of the target components (ESSs: t 2 TSj, CLs: t 2 TVkÞ, while
0 in the other periods (ESSs: t 62 TSj, CLs: t 62 TVkÞ. In the previous problem frame-
works, operation costs of the ESSs and the CLs are expressed as the fuel cost change of
CGs. That is, the ESSs and the CLs affect indirectly on the objective function. Therefore,
Application Example of Particle Swarm Optimization on Operation
225

the sets of coefﬁcients,
ANG þ 1; BNG þ 1; CNG þ 1
ð
Þ and
ANG þ 2; BNG þ 2; CNG þ 2
ð
Þ, are
both set by 0; 0; 0
ð
Þ. Meanwhile, the set of coefﬁcients, ANG þ 3; BNG þ 3; CNG þ 3
ð
Þ, is
set by 0; M; 0
ð
Þ. Since there is no start-up cost on the NG þ 1
ð
Þth– NG þ 3
ð
Þth compo-
nents, SCNG þ 1, SCNG þ 2 and SCNG þ 3 can be simply set by 0.
Constraints for the balance in supply–demand [(8) and (24)] and the reserve margin
[(9) and (25)] are expressed as shown below.
• Balance in power supply and demand
dt ¼
X
NG þ 3
h¼1
g0
h;tu0
h;t; for8h; 8t;
ð43Þ
• Reserve margin
P
NG þ 3
h¼1
g0min
h;t u0
h:t  dt 1  alow
t


dt 1 þ aup
t
ð
Þ 
P
NG þ 3
h¼1
g0max
h;t u0
h;t
8
>
>
<
>
>
:
; for8t;
ð44Þ
where g0max
h;t
and g0min
h;t
are the maximum and the minimum outputs of controllable
components at time t.
Equations (29) and (30) also can be represented as
dt ¼
X
NG þ 3
h¼1
g0
h;tu0
h;t þ e0
t; for8t;
ð45Þ
Ifdt\ P
NG þ 3
h¼1
g0min
h;t u0
h:t then
e0
t ¼ dt  P
NG þ 3
h¼1
g0min
h;t u0
h:t
Ifdt [
P
NG þ 3
h¼1
g0max
h;t u0
h:t then
e0
t ¼ dt  P
NG þ 3
h¼1
g0max
h;t u0
h:t
Elsee0
t ¼ 0
8
>
>
>
>
>
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
>
>
>
>
>
:
; for8t:
ð46Þ
Now, if we ﬁx the states of controllable components on each time, u0
h;t, the target
problem can be relaxed as a special type of optimization problem that has a quadratic
objective function and several variables subjected to linear constraints. As a result,
quadratic programming (QP) solvers can be applied to the target problem after creating
u0, and we do not need to concern difﬁculty of the determination of continuous variables
in the PSO algorithm. Under the circumstances, BPSO, which is an extended PSO
226
H. Takano et al.

algorithm, can be applied to the UC problems. In other words, we can reduce the
dimension of application target of nature-inspired metaheuristic algorithms from
u; g; s; v; e
ð
Þ to u0 by the transformation and thus expect to improve the search ability of
applied algorithms. In the proposed BPSO-QP, position of the particles can be deﬁned as
xn
l ¼ u0;
ð47Þ
If 0:5\
1
1 þ eu0
h;t then u0
h;t ¼ 1; else u0
h;t ¼ 0; for 8h; 8t
ð48Þ
This strategy is available not only for the PSO but also for the other intelligent
optimization-based algorithms.
4
Performance Evaluation of Particle Swarm Optimization
Preliminary numerical simulations were carried out to evaluate performance of the
standard PSO- and the BPSO-QP-based solution methods. Time interval, Dt, was set to
1 h, and daily operation schedules ðt ¼ 1; 2; . . .; 24Þ from 1:00 AM ðt ¼ 1Þ to 12:00
PM ðt ¼ 24Þ were determined. With a view to simplifying discussions, the general
problem framework formulated in Sect. 2.1 was selected, and the CLs were removed
from the microgrid model illustrated in Fig. 1. Table 1 summarizes numerical cases,
and Fig. 2 displays proﬁles of the net load consisting of the electricity consumptions
and the VREG outputs. As shown in Fig. 2, the PVs in sunny day (ideal condition)
were referred as the aggregated VREG. Speciﬁcations of the CGs are described in
Table 2 and Fig. 3. These speciﬁcations were made by referring to [21, 23, 30, 31].
In the preliminary numerical simulations, there was no time constraint on utilization
of the aggregated ESS. In other words, the variable, TS, did not specify available time
of the aggregated ESS. Initial SOC level of the aggregated ESS was set to 50% of its
capacity, and the SOC level had to be returned to the original level until the end of
Table 1. Numerical cases
Case
Available CGs
Available aggregated ESS
1
CGs 1 and 2
Smax ¼ 1:6 (MW), Smin ¼ 1:6 (MW),
Qmax ¼ 2:0 (MWh), Qmin ¼ 0:4 (MWh)
2
CGs 1–3
Smax ¼ 3:2 (MW), Smin ¼ 3:2 (MW),
Qmax ¼ 4:0 (MWh), Qmin ¼ 0:8 (MWh)
3
CGs 1–4
Smax ¼ 4:8 (MW), Smin ¼ 4:8 (MW),
Qmax ¼ 6:0 (MWh), Qmin ¼ 1:2 (MWh)
4
All CGs
Smax ¼ 6:2 (MW), Smin ¼ 6:2 (MW),
Qmax ¼ 8:0 (MWh), Qmin ¼ 1:6 (MWh)
Application Example of Particle Swarm Optimization on Operation
227

-20
-10
0
10
20
30
40
50
60
70
1 2 3 4 5 6 7 8 9 101112131415161718192021222324
Electric power [MW]
Time 
Net load
Electric loads
VREG outputs
-20
-10
0
10
20
30
40
50
60
70
1 2 3 4 5 6 7 8 9 101112131415161718192021222324
Electric power [MW]
Time 
Net load
Electric loads
VREG outputs
-20
-10
0
10
20
30
40
50
60
70
1 2 3 4 5 6 7 8 9 101112131415161718192021222324
Electric power [MW]
Time 
Net load
Electric loads
VREG outputs
-20
-10
0
10
20
30
40
50
60
70
1 2 3 4 5 6 7 8 9 101112131415161718192021222324
Electric power [MW]
Time 
Net load
Electric loads
VREG outputs
Case 1
Case 2
Case 3
Case 4
Fig. 2. Net load proﬁles in each case
Table 2. Speciﬁcations of CGs for Sect. 4 (#: any currency unit is applicable)
i
Aið#Þ
Bið#=MWÞ
Cið#=MW2Þ
SCið#Þ
GMAX
i
ðMWÞ
GMIN
i
ðMWÞ
1
12000.0
3800.0
1.2
3000.0
20.0
4.0
2
7800.0
3100.0
1.8
500.0
16.0
3.2
3
2400.0
2500.0
2.8
500.0
12.0
2.4
4
12000.0
3800.0
1.4
3000.0
20.0
4.0
5
2400.0
2500.0
3.0
500.0
12.0
2.4
0
20,000
40,000
60,000
80,000
100,000
0
5
10
15
20
25
Fuel cost [#]
CG output [MW]
0
20,000
40,000
60,000
80,000
100,000
0
5
10
15
20
25
Fuel cost [#]
CG output [MW]
CG 1
CG 2
CG 3
CG 4
CG 5
0
20,000
40,000
60,000
80,000
100,000
0
5
10
15
20
25
Fuel cost [#]
CG output [MW]
0
20,000
40,000
60,000
80,000
100,000
0
5
10
15
20
25
Fuel cost [#]
CG output [MW]
0
20,000
40,000
60,000
80,000
100,000
0
5
10
15
20
25
Fuel cost [#]
CG output [MW]
0
20,000
40,000
60,000
80,000
100,000
0
5
10
15
20
25
Fuel cost [#]
CG output [MW]
All CGs
CG1
CG 2
CG 3
CG 4
CG 5
Fig. 3. Fuel costs of CGs
228
H. Takano et al.

scheduling period. That is, the following additional constraint was satisﬁed in the ESS
operations.
X
NS
j¼1
qj;0 ¼
X
NS
j¼1
qj;T ¼ 0:5
X
NS
j¼1
Qmax
j
:
ð49Þ
4.1
Basis of Discussions
The PSO, as is well known, cannot guarantee mathematical optimality in its result.
Therefore, to set the basis for discussions, the author approximately solved the target
problem by the following enumeration-based solution method (enumeration-QP)
whose outline is as follows.
1. All the feasible UC solution candidates are enumerated assuming no ESS under
(31) and (32).
2. The QP solver derives the optimal output shares of the CGs for each enumerated
UC solution candidate in consideration of operation of the aggregated ESS. By the
relationship of Dgt ¼ st, the aggregated ESS inﬂuence the fuel costs of CGs.
3. The UC solution candidate having the best output shares of the CGs and the
aggregated ESS in the previous step is determined as the optimal operation schedule
of the microgrid.
If either one of (31) and (32) is not satisﬁed, the operation plan at time t  1 affects
it at time t. In contrast, under (31) and (32), we can regard the target optimization
problem in the above steps 1 and 2 as a static hierarchical optimization problem [21,
23, 30, 31]. This is because the optimization variables at time t ðui;t and gi;tÞ are
independent of their values at time t  1. It also means that the enumeration-QP only
can apply under (31) and (32). Moreover, since the UC problem and the ELD problem
are solved individually, the enumeration-QP does not guarantee the global optimality
of its solution. However, unlike the intelligent algorithms whose solutions much
depend on choices of initial solutions and/or random number sequences, this solution
method can provide stable and consistent solutions.
4.2
Results and Discussion in Performance of Particle Swarm
Optimization
The optimal operation schedules of microgrid components (CGs and ESSs) were
determined by the enumeration-QP, the standard PSO and the BPSO-QP, respectively.
Through trial and error, parameters of the standard PSO were set as follows: L
j j ¼ 100,
N ¼ 20; 000, x ¼ 0:7, c1 ¼ 1:4 and c2 ¼ 1:4. Since the BPSO-QP required much
calculation time, its parameters were modiﬁed as shown below: L
j j ¼ 100, N ¼ 1000,
x ¼ 0:7, c1 ¼ 1:4 and c2 ¼ 1:4. Difference between their parameters is only the
maximum iteration from the viewpoint of their required calculation time. Initial par-
ticles were randomly set in the search space. Table 3 summarizes the operation costs on
obtained solution. In Table 3, we can conﬁrm that the BPSO-QP obtained the best
Application Example of Particle Swarm Optimization on Operation
229

solutions in each case. The standard PSO became worse approximately 10% as com-
pared to those of the enumeration-QP although the maximum iteration was bigger than
that of the BPSO.
Figure 4 displays transitions of gbest in each PSO, and Table 4 describes com-
parison results of their calculation time. In Fig. 4, increase of the case number leads to
slower convergence of the gbest. This is because the target problem becomes difﬁcult
owing to increase of the number of CGs. Actually, the number of possible UC can-
didates in Case 1 can be simply calculated by (22)24, while the number in Case 4 is
(24)24. For the same reason, the calculation time in Case 4 was the worst in each PSO.
As shown in Table 4, the BPSO-QP has still plenty room for discussion on the cal-
culation time; nevertheless, its convergence was emphasized dramatically in compar-
ison with that of the standard PSO. In accordance with the problem transformation
described in Sect. 3.2, process in the QP solver became very complicated, and thus the
calculation time increased. However, the issue is beyond the scope of this chapter
because each calculation time was sufﬁciently fast from the viewpoint of practical use.
It will be solved/relaxed in the authors’ future works.
Table 3. Solution comparison of enumeration-QP, standard PSO and BPSO-QP
Case
Enumeration-QP
Standard PSO
BPSO-QP
1
1493958.2
1628064.8 (+9.0%)
1479829.3 (−0.9%)
2
1762434.9
1981212.9 (+12.4%)
1708589.9 (−3.1%)
3
2443987.8
2640737.1 (+8.1%)
2267596.6 (−7.2%)
4
3114027.3
3541872.7 (+13.7%)
3001256.0 (−3.6%)
0
2,000,000
4,000,000
6,000,000
8,000,000
10,000,000
0
100
200
300
400
500
600
700
800
900
1,000
Fitness function
Iteration
Case 1
Case 2
Case 3
Case 4
20,000
PSO
BPSO
Fig. 4. Comparison of search records of standard PSO and BPSO-QP
Table 4. Comparison of calculation time until 1000 iteration
Case
Standard PSO (s)
BPSO-QP (s)
1
16.23
109.46
2
17.16
422.70
3
17.84
919.39
4
19.62
2106.99
230
H. Takano et al.

5
Veriﬁcation of Validity in Problem Frameworks
The authors veriﬁed the validity of formulated optimization problems through numerical
simulations using the microgrid model illustrated in Fig. 1 and discussions on their
results. Time interval, Dt, was set to 1 h, and daily operation schedules ðt ¼ 1; 2; . . .; 24Þ
were determined as same as the preliminary numerical simulations described in Sect. 4.
However, the period of optimization target was set from 8:00 AM ðt ¼ 1Þ to 7:00 AM
ðt ¼ 24Þ considering operation of the time-constrained components in the microgrid
model. The controllable time of the CLs was set from 9:00 PM to 7:00 AM. Figure 5
shows the net load proﬁle and the price in electricity trade. As shown in Fig. 5, the
aggregated PV in sunny day was referred as the aggregated VREG. The imbalance
penalty was set to huge value for avoiding the electricity surplus/shortage in the oper-
ation stage. Parameters of the microgrid model were set as shown in Tables 5 and 6, and
these settings were basically ﬁxed in this section. These parameters were made by
modiﬁcation of the parameters described in Sect. 4. Here, there was no time constraint
on utilization of the aggregated ESS, and the aggregated ESS had to satisfy (49).
Under these conditions, the authors determined several operation schedules as
summarized in Table 7. As for reference, operation schedules without consideration of
the reserve margin were determined according to the problem framework of Sect. 2.1
0
5,000
10,000
15,000
20,000
25,000
8 9 101112131415161718192021222324 1 2 3 4 5 6 7
Price in trade [#/MWh]
Time
-20
-10
0
10
20
30
40
50
8 9 101112131415161718192021222324 1 2 3 4 5 6 7
Electric power [MW]
Time 
Net load
Electric loads
VREG outputs
Fig. 5. Net load proﬁle and electricity trading price
Table 5. Speciﬁcations of CGs for Sect. 5 (#: any currency unit is applicable)
i
Aið#Þ
Bið#=MWÞ
Cið#=MW2Þ
SCið#Þ
GMAX
i
ðMWÞ
GMIN
i
ðMWÞ
1
12000.0
3800.0
1.2
3000.0
20.0
4.0
2
7800.0
3100.0
1.8
1000.0
16.0
3.2
3
2400.0
2500.0
2.8
500.0
12.0
2.4
Table 6. Speciﬁcations of aggregated ESS and aggregated CL
ESS
CL
SmaxðMWÞ SminðMWÞ QmaxðMWhÞ QminðMWhÞ VmaxðMWÞ PmaxðMWhÞ PminðMWhÞ
1.8
−1.8
10.4
2.6
−1.5
9.6
2.4
Application Example of Particle Swarm Optimization on Operation
231

[the general framework excluding (9)]. The reserve margin was secured to compensate
deviation within 5% of the net load in the problem frameworks of Sects. 2.1 and 2.2.
Besides, the uncertainty originated from the aggregated VREG (PVs) was only con-
sidered in each problem framework to simplify discussions on the numerical results.
Case 1 is essentially same with the UC-ELD problems in the conventional power grids.
Case 4 is the most difﬁcult condition because the number of optimization variables
becomes large. Based on the results in Sect. 4, the BPSO-QP was selected as the
solution method. By the result of trial and error, parameters for the BPSO were set as
follows: X
j j ¼ 40, N ¼ 300, x ¼ 0:9, c1 ¼ 2:0 and c2 ¼ 2:0.
5.1
Results and Discussion
Operation costs for the forecasted net load are described in Table 8, and expected
operation costs are summarized in Table 9. Figures 6, 7, 8 and 9 display the resulting
operation schedules of the microgrid components. Figures 10, 11 and 12 show tran-
sitions of the SOC level in them.
Table 7. Available components in each numerical case
Case
Component
Framework
CGs 1–3
Aggregated ESS
Aggregated CL
1a
Available
Unavailable
Unavailable
Sect. 2.1 without (9)
1b
Available
Unavailable
Unavailable
Sect. 2.1
1c
Available
Unavailable
Unavailable
Sect. 2.2
1d
Available
Unavailable
Unavailable
Sect. 2.3
2a
Available
Available
Unavailable
Sect. 2.1 without (9)
2b
Available
Available
Unavailable
Sect. 2.1
2c
Available
Available
Unavailable
Sect. 2.2
2d
Available
Available
Unavailable
Sect. 2.3
3a
Available
Unavailable
Available
Sect. 2.1 without (9)
3b
Available
Unavailable
Available
Sect. 2.1
3c
Available
Unavailable
Available
Sect. 2.2
3d
Available
Unavailable
Available
Sect. 2.3
4a
Available
Available
Available
Sect. 2.1 without (9)
4b
Available
Available
Available
Sect. 2.1
4c
Available
Available
Available
Sect. 2.2
4d
Available
Available
Available
Sect. 2.3
Table 8. Numerical results (operation costs for forecasted net load)
Case
a
b
c
d
1
1941945.5
1956575.6
1956575.6
1980156.6
2
1913463.0
1920218.2
1917874.0
1949546.0
3
1953169.5
1967799.7
1961365.3
1991382.4
4
1924697.8
1931453.0
1929108.8
1960789.9
232
H. Takano et al.

Table 9. Numerical results (expected operation costs)
Case
a
b
c
d
1
–
–
1987690.3
1980315.3
2
–
–
2040216.1
1949630.0
3
–
–
2046965.7
1991366.8
4
–
–
2051418.4
1960832.3
-10.0
0.0
10.0
20.0
30.0
40.0
50.0
8 9 1011121314151617181920212223 0 1 2 3 4 5 6 7
Electric power [MW]
Time
g3
g2
g1
e
Net load
-10.0
0.0
10.0
20.0
30.0
40.0
50.0
8 9 1011121314151617181920212223 0 1 2 3 4 5 6 7
Electric power [MW]
Time
g3
g2
g1
e
Net load
-10.0
0.0
10.0
20.0
30.0
40.0
50.0
8 9 1011121314151617181920212223 0 1 2 3 4 5 6 7
Electric power [MW]
Time
g3
g2
g1
Net load
-10.0
0.0
10.0
20.0
30.0
40.0
50.0
8 9 1011121314151617181920212223 0 1 2 3 4 5 6 7
Electric power [MW]
Time
g3
g2
g1
Net load
Case 1a
Case 1b
Case 1c
Case 1d
Fig. 6. Operation schedules in Case 1
-10.0
10.0
30.0
50.0
8 9 1011121314151617181920212223 0 1 2 3 4 5 6 7
Electric power [MW]
Time
g3
g2
g1
s
e
Net load
-10.0
0.0
10.0
20.0
30.0
40.0
50.0
8 9 1011121314151617181920212223 0 1 2 3 4 5 6 7
Electric power [MW]
Time
g3
g2
g1
s
Net load
-10.0
0.0
10.0
20.0
30.0
40.0
50.0
8 9 1011121314151617181920212223 0 1 2 3 4 5 6 7
Electric power [MW]
Time
g3
g2
g1
s
Net load
-10.0
0.0
10.0
20.0
30.0
40.0
50.0
8 9 1011121314151617181920212223 0 1 2 3 4 5 6 7
Electric power [MW]
Time
g3
g2
g1
s
e
Net load
Case 2a
Case 2b
Case 2c
Case 2d
Fig. 7. Operation schedules in Case 2
Application Example of Particle Swarm Optimization on Operation
233

-10.0
0.0
10.0
20.0
30.0
40.0
50.0
8 9 1011121314151617181920212223 0 1 2 3 4 5 6 7
Electric power [MW]
Time
g3
g2
g1
v
Net load
-10.0
0.0
10.0
20.0
30.0
40.0
50.0
8 9 1011121314151617181920212223 0 1 2 3 4 5 6 7
Electric power [MW]
Time
g3
g2
g1
v
Net load
-10.0
0.0
10.0
20.0
30.0
40.0
50.0
8 9 1011121314151617181920212223 0 1 2 3 4 5 6 7
Electric power [MW]
Time
g3
g2
g1
v
e
Net load
-10.0
0.0
10.0
20.0
30.0
40.0
50.0
8 9 1011121314151617181920212223 0 1 2 3 4 5 6 7
Electric power [MW]
Time
g3
g2
g1
v
e
Net load
Case 3a
Case 3b
Case 3c
Case 3d
Fig. 8. Operation schedules in Case 3
-10.0
0.0
10.0
20.0
30.0
40.0
50.0
8 9 1011121314151617181920212223 0 1 2 3 4 5 6 7
Electric power [MW]
Time
g3
g2
g1
s
v
Net load
-10.0
0.0
10.0
20.0
30.0
40.0
50.0
8 9 1011121314151617181920212223 0 1 2 3 4 5 6 7
Electric power [MW]
Time
g3
g2
g1
s
v
Net load
-10.0
0.0
10.0
20.0
30.0
40.0
50.0
8 9 1011121314151617181920212223 0 1 2 3 4 5 6 7
Electric power [MW]
Time
g3
g2
g1
s
v
e
Net load
-10.0
0.0
10.0
20.0
30.0
40.0
50.0
8 9 1011121314151617181920212223 0 1 2 3 4 5 6 7
Electric power [MW]
Time
g3
g2
g1
s
v
e
Net load
Case 4a
Case 4b
Case 4c
Case 4d
Fig. 9. Operation schedules in Case 4
0.0
2.0
4.0
6.0
8.0
10.0
12.0
14.0
8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 0 1 2 3 4 5 6 7
State of charge [MWh]
Time
q
Qmax
Qmin
0.0
2.0
4.0
6.0
8.0
10.0
12.0
14.0
8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 0 1 2 3 4 5 6 7
State of charge [MWh]
Time
q
Qmax
Qmin
0.0
2.0
4.0
6.0
8.0
10.0
12.0
14.0
8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 0 1 2 3 4 5 6 7
State of charge [MWh]
Time
q
Qmax
Qmin
0.0
2.0
4.0
6.0
8.0
10.0
12.0
14.0
8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 0 1 2 3 4 5 6 7
State of charge [MWh]
Time
q
Qmax
Qmin
Case 2a
Case 2b
Case 2c
Case 2d
Fig. 10. SOC level in Case 2
234
H. Takano et al.

In Tables 8 and 9, we can understand that the ESSs and/or the CLs were operated
appropriately to save the operation costs of CGs by the comparison between Case 1 and
Cases 2–4. The operation costs and the expected costs in Case 2 were smaller than
those in Case 1. For example, in Fig. 6, the operation schedules in Cases 2–4 required
earlier start-up of the CG 1 as compared to Case 1 (Case 1: 15:00, Case 2: 14:00, Case
3: 14:00, Case 4: 13:00). The CG 1, as described in Table 5, is the costly CG, and the
resulting operation costs in Cases 2–4 became high. In Case 3, the operation costs
became highest. This is because the CLs increase total amount of electricity con-
sumption in the microgrids even though they have controllability in their operation. In
contrast, increment of the operation costs was relaxed in Case 4 by the cooperative
operation among the CGs, the ESSs and the CLs.
As shown in Table 8, the operation schedules in the general problem framework
described in Sect. 2.1 (Cases 1a–4a and 1b–4b) were the best results from the view-
point of operation cost for the assumed net load. It means that the operation cost
increases in the other cases for securing margin against the uncertainty in actual
operation. However, Cases 1a–4a and 1b–4b have the potential risk for the imbalance
0.0
2.0
4.0
6.0
8.0
10.0
12.0
14.0
8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 0 1 2 3 4 5 6 7
State of charge [MWh]
Time
p
Pmax
Pmin
0.0
2.0
4.0
6.0
8.0
10.0
12.0
14.0
8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 0 1 2 3 4 5 6 7
State of charge [MWh]
Time
p
Pmax
Pmin
0.0
2.0
4.0
6.0
8.0
10.0
12.0
14.0
8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 0 1 2 3 4 5 6 7
State of charge [MWh]
Time
p
Pmax
Pmin
0.0
2.0
4.0
6.0
8.0
10.0
12.0
14.0
8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 0 1 2 3 4 5 6 7
State of charge [MWh]
Time
p
Pmax
Pmin
Case 3a
Case 3b
Case 3c
Case 3d
Fig. 11. SOC level in Case 3
0.0
2.0
4.0
6.0
8.0
10.0
12.0
14.0
8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 0 1 2 3 4 5 6 7
State of charge [MWh]
Time
q
p
Qmax
Qmin
Pmax
Pmin
0.0
2.0
4.0
6.0
8.0
10.0
12.0
14.0
8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 0 1 2 3 4 5 6 7
State of charge [MWh]
Time
q
p
Qmax
Qmin
Pmax
Pmin
0.0
2.0
4.0
6.0
8.0
10.0
12.0
14.0
8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 0 1 2 3 4 5 6 7
State of charge [MWh]
Time
q
p
Qmax
Qmin
Pmax
Pmin
0.0
2.0
4.0
6.0
8.0
10.0
12.0
14.0
8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 0 1 2 3 4 5 6 7
State of charge [MWh]
Time
q
p
Qmax
Qmin
Pmax
Pmin
Case 4a
Case 4b
Case 4c
Case 4d
Fig. 12. SOC level in Case 4
Application Example of Particle Swarm Optimization on Operation
235

penalty which is caused by unexpected change in the VREG outputs. In Table 9, the
expected operation costs in this problem framework could not be evaluated by the
setting of imbalance penalty, and this is the reason why there were no values in the
table. Besides, the operation costs in Cases 1c–4c became worse than those in Table 8.
On the other hand, the operation costs in Cases 1d–4d were almost same with those in
Table 8; nevertheless, the potential risk was reﬂected in the expected operation cost. As
a result, the expected operation costs in Cases 1d–4d became smaller than those in
Cases 1c–4c as opposed to the operation cost for the forecasted net load. From these
results, we can conclude that the authors’ proposal described in Sect. 2.3 functioned
well.
5.2
Additional Numerical Simulations
In the numerical simulations described in Sect. 5.1, the time-constrained ESS is not
considered. As already mentioned, a part of the controllable components, such as EVs,
changes their attributes depending on the judgment whether the conventional power
grids accept reverse power ﬂow from them or not (accepted: ESS, not accepted: CL).
Therefore, the authors determined the optimal operation schedules in Case 4 with
replacement, the CLs into the ESSs having time constraint. In the determination, initial
SOC level of the aggregated time-constrained ESS was set to 50% of its capacity, and
the ESS had to be fully charged until the end of available period. The available time of
time-constrained ESS was set from 9:00 PM to 7:00 AM. Table 10 summarizes the
operation costs for forecasted net load. Table 11 describes the expected operation costs.
Figures 13 and 14 show the resulting operation schedules of the microgrid components
and their SOC level, respectively. From these results, we can conclude similar tendency
with the results in Sect. 5.1. By discharging of the ESS, the results of Case 5 were
better than those of Case 3.
Table 10. Results of additional numerical simulations (operation costs for forecasted net load)
Case
a
b
c
d
5
1923640.4
1930395.7
1928051.5
1959730.7
Table 11. Results of additional numerical simulations (expected operation cost)
Case
a
b
c
d
5
–
–
2050349.4
1959770.9
236
H. Takano et al.

6
Conclusions
This chapter presented several problem frameworks and their solution methods to
obtain coordinated operation schedules of the controllable components in microgrids.
In Sect. 2, three problem frameworks were discussed. Differences between the problem
frameworks were whether the electricity trade was considered or not, and the uncer-
tainty was considered or not. In Sect. 3, applications of the standard PSO and the
BPSO were selected as the basis of solution methods of the formulated problems. With
a view to applying the BPSO, the authors proposed the problem transformation to
reduce the dimension of solution space in application target of nature-inspired meta-
heuristic algorithms from u; g; s; v; e
ð
Þ to u0. In other words, the compatibility between
the target problems and their solution methods was improved by the proposed trans-
formation. In Sect. 4, the preliminary numerical simulations were performed to eval-
uate performance of the standard PSO and the BPSO-QP in the target problems.
Through discussions on their results, we could conclude that the solutions of standard
-10.0
0.0
10.0
20.0
30.0
40.0
50.0
8 9 1011121314151617181920212223 0 1 2 3 4 5 6 7
Electric power [MW]
Time
g3
g2
g1
s1
s2
Net load
-10.0
0.0
10.0
20.0
30.0
40.0
50.0
8 9 1011121314151617181920212223 0 1 2 3 4 5 6 7
Electric power [MW]
Time
g3
g2
g1
s1
s2
Net load
-10.0
0.0
10.0
20.0
30.0
40.0
50.0
8 9 1011121314151617181920212223 0 1 2 3 4 5 6 7
Electric power [MW]
Time
g3
g2
g1
s1
s2
e
Net load
-10.0
0.0
10.0
20.0
30.0
40.0
50.0
8 9 1011121314151617181920212223 0 1 2 3 4 5 6 7
Electric power [MW]
Time
g3
g2
g1
s1
s2
e
Net load
Case 5a
Case 5b
Case 5c
Case 5d
Fig. 13. Operation schedules in Case 5
0.0
2.0
4.0
6.0
8.0
10.0
12.0
14.0
8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 0 1 2 3 4 5 6 7
State of charge [MWh]
Time
q1
q2
Q1max
Q1min
Q2max
Q2min
0.0
2.0
4.0
6.0
8.0
10.0
12.0
14.0
8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 0 1 2 3 4 5 6 7
State of charge [MWh]
Time
q1
q2
Q1max
Q1min
Q2max
Q2min
0.0
2.0
4.0
6.0
8.0
10.0
12.0
14.0
8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 0 1 2 3 4 5 6 7
State of charge [MWh]
Time
q1
q2
Q1max
Q1min
Q2max
Q2min
0.0
2.0
4.0
6.0
8.0
10.0
12.0
14.0
8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 0 1 2 3 4 5 6 7
State of charge [MWh]
Time
q1
q2
Q1max
Q1min
Q2max
Q2min
Case 5a
Case 5b
Case 5c
Case 5d
Fig. 14. SOC level in Case 5
Application Example of Particle Swarm Optimization on Operation
237

PSO became worse than those of the proposed BPSO-QP from the viewpoint of their
accuracy. On the other hand, the BPSO-QP also had the challenge in its calculation
time. In Sect. 5, the differences between the problem frameworks were examined. As a
result, we could conclude that each problem framework functioned appropriately.
In the future works, the authors will solve/relax the issue in the calculation time of
BPSO-QP. Furthermore, the authors will propose more effective solution method with
reference to characteristics of the target problems and/or the nature-inspired meta-
heuristic algorithms.
Acknowledgements. The authors would like to acknowledge the support provided by Japan
Society for the Promotion of Science (KAKENHI Grant Numbers 16K06215 and 19K04325) and
Gifu Renewable Energy System Research Center of Gifu University. Contributions to this study
by Ryota Goto and Kan Nakae, who are pursuing their master’s degree in Gifu University, are
also acknowledged.
References
1. Ofﬁce of Electricity Delivery and Energy Reliability (2012) DOE microgrid workshop
report. Summary Report
2. Ton DT, Smith MA (2012) The U.S. Department of Energy’s microgrid initiative. Electr J
25(8):84–94
3. Hatziargyriou N, Asano H, Iravani R, Marnay C (2007) Microgrids for distributed
generation. IEEE Power and Energy Magazine
4. Liu CC, McAuthur S, Lee SJ (2016) Smart grid handbook. In: 3 Volume Set. Wiley
5. Investigating R&D Committee on advanced power system (2011) Current status of advanced
power systems including microgrid and smartgrid (in Japanese). IEEJ Technical Report 1229
6. New Energy and Industrial Technology Development Organization (2018) Case Studies of
Smart
Community
Demonstration
Project.
http://www.nedo.go.jp/english/reports_
20130222.html. Access date: 31 May 2019
7. Kerr RH, Scheidt JL, Fontana AJ, Wiley JK (1966) Unit Commitment. IEEE Trans Power
App Syst. PAS-85:417–421
8. Sen S, Kothari DP (1989) Optimal thermal generating unit commitment: a review. Int J
Electr Power Energy Syst 20(7):443–451
9. Hobbs BF, Rothkopf MH, O’Neill RP, Chao HP (2001) The next generation of electric
power unit commitment models. In: International series in operations research &
management science, vol 36
10. Padhy NP (2004) Unit commitment—a bibliographical survey. IEEE Trans Power Syst 19
(2):1196–1205
11. Bhardwaj A, Tung NS, Kamboj V (2012) Unit commitment in power system: a review. Int J
Power Eng 6(1):51–57
12. Saravanan B, Das S, Sikri S, Kothari DP (2013) A solution to the unit commitment problem
—a review. Front Energy 7(2):223–236
13. Zheng QP, Wang J, Liu AL (2015) Stochastic optimization for unit commitment—a review.
IEEE Trans Power Syst 30(4):1913–1924
14. Snyder WL, Powell HD, Raiburn JC (1987) Dynamic programming approach to unit
commitment. IEEE Trans Power Syst 2(2):339–348
238
H. Takano et al.

15. Ouyang Z, Shahidehpour SM (1991) An intelligent dynamic programming for unit
commitment application. IEEE Trans Power Syst 6(3):1203–1209
16. Cohen AI, Yoshimura M (1983) A branch-and-bound algorithm for unit commitment. IEEE
Trans Power App Syst PAS-102(2):444–451
17. Chen CL, Wang SC (1993) Branch-and-bound scheduling for thermal generating units.
IEEE Trans Energy Conversion 8(2):184–189
18. Kazarlis SA, Bakirtzis AG, Petridis V (1996) A genetic algorithm solution to the unit
commitment problem. IEEE Trans Power Syst 11(1):83–92
19. Mantawy AH, Abdel-Magid YL, Selim SZ (1998) A simulated annealing algorithm for unit
commitment. IEEE Proc Generation Trans Distribution 145(1):56–64
20. Simopoulos DN, Kavatza SD, Vournas CD (2006) Unit commitment by an enhanced
simulated annealing algorithms. IEEE Trans Power Syst 21(1):68–76
21. Takano H, Zhang P, Murata J, Hashiguchi T, Goda T, Iizaka T, Nakanishi Y (2015) A
determination method for the optimal operation of controllable generators in micro grids that
copes with unstable outputs of renewable energy generation. Electr Eng Japan 190(4):56–65
22. Jeong YW, Park JB (2010) A new quantum-inspired binary PSO: application to unit
commitment problem for power systems. IEEE Trans Power Syst 25(3):1486–1495
23. Hayashi Y, Miyamoto H, Matsuki J, Iizuka T, Azuma H (2008) Online optimization method
for operation of generators in micro Grid (in Japanese). IEEJ Trans PE128-B(2):388–396
24. Juste KA, Kita H, Tanaka E, Hasegawa J (1999) An evolutionary programming solution to
the unit commitment problem. IEEE Trans Power Syst 14(4):1452–1459
25. Rajan CCA, Mohan MR (2004) An evolutionary programming-based tabu search method for
solving the unit commitment problem. IEEE Trans Power Syst 19(1):577–585
26. Lu B, Shahidehpour M (2005) Short-term scheduling of battery in a grid-connected
PV/battery system. IEEE Trans PES 20(2):1053–1061
27. Palma-Behnke R, Benavides C, Lanas F, Severino B, Reyes L, Llanos J, Saez D (2013) A
microgrid energy management system based on the rolling horizon strategy. IEEE Trans
Smart Grid 4(2):996–1006
28. Li N, Uckun C, Constantinescu EM, Birge JR, Hedman KW, Botterud A (2016) Flexible
operation of batteries in power system scheduling with renewable energy. IEEE Trans
Sustain Energy 7(2):685–696
29. Hammati R, Saboori H (2016) Short-term bulk energy storage scheduling for load leveling in
unit commitment: modeling, optimization, and sensitivity analysis. J Adv Res 7(3):360–372
30. Soe TZ, Takano H, Shiomi R, Taoka H (2018) Determination method for optimal
cooperative operation plan of microgrids by providing alternatives for microgrid operators.
J Int Council Electr Eng 8(1):103–110
31. Takano H, Nagaki Y, Murata J, Iizaka T, Ishibashi T, Katsuno T (2016) A study on supply
and demand planning for Power Producer-Suppliers utilizing output of megawatt solar
plants. J Int Council Electr Eng 6(1):102–109
32. Clerc M (2006) Particle swarm optimization. ISTE Ltd
33. Lee S, Soak S, Oh S, Pedryczm W, Jeon M (2008) Modiﬁed binary particle swarm
optimization. Progress Natural Sci (18):1161–1166
Application Example of Particle Swarm Optimization on Operation
239

Chapter 11
Modiﬁed Monkey Search Technique Applied
for Planning of Electrical Energy Distribution
Systems
F. G. Duque, L. W. De Oliveira, E. J. De Oliveira, B. H. Dias(&),
and C. A. Moraes
Department of Electrical Energy, Federal University at Juiz de Fora (UFJF), Juiz
de Fora, Brazil
{Felipe.duque,camile.aredes}@engenharia.ufjf.br,
{leonardo.willer,edimar.oliveira}@ufjf.edu.br,
{Felipe.duque
1
Introduction
An electric power system (EPS) has the basic function of supplying electrical energy
with quality to commercial, industrial, and residential consumers. An EPS is deﬁned as
a set of equipment that operates in a coordinated way to convert, transmit, and supply
energy to consumers, maintaining the quality standard as high as possible and meeting
requirements such as [1]: continuity of supply; compliance with required standards;
ﬂexibility to adapt to possible network topology changes; and maintenance, with quick
recovery in case of faults.
The new philosophy of electric power systems, with lower cost and higher quality
of service requirements, coupled with their modernization, has led to the search for
more efﬁcient solutions to issues as the monitoring. An EPS comprises electrical dis-
tribution systems (EDS), which have a signiﬁcant impact on the planning of electric
networks [2] and high complexity [3, 4]. Among the challenges for EDS, it is possible
to highlight the diversity of loads connected to the feeders and their variations
throughout the day, as well as the presence of distributed generation (DG). For
achieving operation requirements, the National Electric Energy Agency (ANEEL)
regulates the EDS in Brazil [5].
Modern EDS are facing changes due to their increase and the development of new
technologies that can allow a more ﬂexible, dynamic and efﬁcient operation, as
intelligent electronic devices (IEDs), smart meters (SM), and phasor measurement units
(PMU) [6, 7]. The planning of measurement systems in EDS has objectives that differ
from transmission systems due to the presence of unbalanced loads between phases,
increased DG, and radial conﬁguration [8]. Therefore, different strategies should be
considered for allocating meters in EDS.
The previously mentioned scenario requires advanced monitoring, control, and
protection under network conditions. Since complete instrumentation for monitoring is
economically unfeasible, the state estimation (SE) process is crucial for the control of
© Springer Nature Singapore Pte Ltd. 2020
M. Khosravy et al. (eds.), Frontier Applications of Nature Inspired Computation,
Springer Tracts in Nature-Inspired Computing,
https://doi.org/10.1007/978-981-15-2133-1_11

the operation [1]. This was studied in terms of accuracy and allocation of measurement
devices in [9, 10]. In such studies, traditional measurements such as voltage and active
and reactive power at the substation (SS), in addition to low precision pseudo-
measurements based on historical data [11], are used in the SE to overcome the low
availability
of
direct
measurements.
However,
the
uncertainties
in
pseudo-
measurements impact the accuracy of the SE.
Moreover, online monitoring is important for modern distribution networks, par-
ticularly with regard to concepts such as smart grid and self-healing, which requires an
advanced data acquisition infrastructure [12]. Among the relevant data for supervision
and control, real-time synchronized voltage and current phasors can be pointed out. In
this context, the synchronized PMU emerge [13]. However, a technical–economic
feasibility analysis should be conducted to support the decision-making process on
investments in various measurement systems.
Tools for planning measurement systems must handle mixed types of measure-
ments and meters, such as SM and PMU. In addition, these tools can deal with the
representation of the equipment capacities, accuracies and related costs, as well as
traditional substation measurements and pseudo-measurements with low precision.
Finally, it is needed to model properly the different requirements of cost and state
estimation in the light of different indexes for decision making.
The smart grids concept opens a range of research to improve the EDS service
quality, with the components of an electric network operating as independent agents
with intelligence, competing and cooperating with each other to achieve general
objectives [14]. Hence, the role of a state estimator is crucial in modern energy
management systems, due to the diversity of applications that depend on accurate real-
time data to estimate the operational condition [15]. In particular, the problem of meter
allocation for the state estimation has the objective of deciding the type, quantity, and
location where the equipment should be strategically placed, aiming at better accuracy
and reduced costs to ensure the maximum efﬁciency of the distribution service.
The optimal allocation of meters in an EDS is a complex task that must be aided by
efﬁcient computational tools able to handle mixed-integer and combinatorial problems.
In this context, metaheuristics have potential to be applied due to their ability to ﬁnd
solutions with a good trade-off between quality and computational effort. Metaheuristic
algorithms are present in many applications of optimization problems, but deﬁning the
best-applied metaheuristic is a challenge. In this context, [16] conducted studies on the
effectiveness of these algorithms in providing optimal solutions to complex problems.
The principles of Darwinian evolution for solving optimization problems have been
reiterated in Genetic GA [17–19]. In [19], the main objective of the proposed study is
to show the effect of optimizing generators for capacity and location, both to reduce
transmission investment and to increase network reliability. A very recent variation of
GA implies Mendelian evolution on multi-species as inspired by plants biology [20]
incorporating the use of double-strand DNA for evolution.
The adapted bat-inspired algorithm (ABA) [21] associated with search space
shrinking (SSS) resulted in an efﬁcient hybrid algorithm (EHA) for transmission net-
work expansion planning (TEP). The SSS technique has a crucial role in the deﬁnition
Modiﬁed Monkey Search Technique Applied
241

of ABA initial candidates, thereof considerably reduction of solution search space, thus
the computational performance of the proposed ABA.
The analysis of low-frequency interference that causes electrocardiographic noise
(ECG) should be estimated and removed, which makes this study motivation give the
importance of ECG to assess the patient’s health condition. Particle swarm optimiza-
tion (PSO) is used to investigate a faster parameterization technique in the one-stage
morphological ECG baseline estimation [22].
This paper presents an approach to EPS for high state estimation problem. To solve
the problem is presented the MMS technique that stood out for its simplicity, effec-
tiveness and obtaining very promising results in other past applications.
1.1
Contributions
Regarding the context of meter allocation in distribution systems, the contributions of
this chapter are:
• The description of the application of a recent method in the literature to handle the
problem in mind, based on an improved metaheuristic;
• The improved algorithm has modiﬁcations in the original monkey search (MS) al-
gorithm to properly represent the meter allocation problem features and constraints;
• The aforementioned modiﬁcations are described in detail to contribute to the lit-
erature on metaheuristic applications;
• Regarding the meter allocation problem, important aspects and constraints such as
topological variations are considered.
1.2
Organization
The remainder of the chapter is organized as follows: Sect. 2 presents the original
monkey search and the improved algorithm with their mathematical foundations;
Sect. 3 describes the application of the MMS algorithm for the meter allocation
problem; Sect. 4 shows the simulations and case studies with an appropriate discussion
of the results. The concluding remarks are made in Sect. 5.
2
Background and Related Works
2.1
Original Monkey Search
The optimization technique called monkey search (2007) is inspired by the behavior of
a monkey in the search for food in a jungle [23]. This search is done through up and
down movements in trees that have food sources. During the search, the monkey stores
and updates in its memory the best routes found. This adaptive memory is then used to
obtain more promising routes.
The MS technique associates the mechanisms of adaptive memory and evolution of
routes with a search for solutions of combinatorial optimization problems. This asso-
ciation can be summarized as:
242
F. G. Duque et al.

• The root and “nodes” of a tree contain food sources that are related to possible
solutions of an optimization problem;
• A branch connects two consecutive nodes of a tree;
• The path is formed by the set of nodes from the root to the top of a tree;
• The height of a tree (h) determines the number of nodes of a path;
• Adaptive memory (AM) stores the best solutions acquired during the search for
solutions, which are used to lead the search process. In the optimization problem,
AM is also used to evaluate convergence.
Once the search is started, the monkey begins to traverse the branches of the trees
that are encoded by a binary structure [24]. Then, the monkey climbs a tree from its
root until its highest point (top), which is a parameter of the algorithm. The sequence of
chosen branches is referred to as a path from the root to the top. With every feasible
solution found, the monkey updates the data in its memory. Figure 1 shows the binary
structure of a tree with root given by node “A” and height given by h = 6 where, from
each node, one of the two options can be chosen and each option leads to a new node or
candidate solution. From the root, the process can evolve to node “B” through the right
branch, or to node “C” through the branch on the left. A possible codiﬁcation for the
decisions taken can be “0” (decision for the branch on the right); “1” (decision for the
branch on the left).
Considering that in the random search of Fig. 1a, the reinforced branches are
visited, the covered path “A-C-D-E-K-L-M” can be represented by its binary coding as
1(“A-C”)-0(“C-D”)-0(“D-E”)-1(“E-K”)-0(“K-L”)-0(“L-M”).
The rise from one node to another occurs through a branch and consists of
obtaining a new solution (top node) from the current solution (lower node). This is
accomplished through a disturbance in the current solution. The perturbation of one
solution can result in two other solutions (nodes) and the chosen solution corresponds
to the best one between them. A perturbation in the current solution can be an
Fig. 1. Tree structure: a random search; b targeted search
Modiﬁed Monkey Search Technique Applied
243

increment or decrement in the value of an element that forms the solution vector.
Therefore, the following procedures must be deﬁned:
• What elements should be modiﬁed?
• What should be the increase?
• What should be the decrease?
• How many elements should be changed?
It is worth mentioning that all these decisions impact the search process. A large-
scale change may modify the current solution too much and its quality will be greatly
affected, that is, the change may make the current solution to escape from a good point.
On the other hand, very low-scale changes may make the current solution to be trapped
in suboptimal points.
2.2
Modiﬁed Monkey Search Algorithm
The modiﬁed monkey search algorithm consists of two basic stages. The ﬁrst stage is to
generate a set of initial solutions to load adaptive memory with good quality solutions.
The second stage represents the climbing process in the trees to search for better
solutions until the adaptive memory contains only solutions of great quality identifying
the process convergence. Each stage of the algorithm can be described as follows.
Phase 1—Search for the Starting Tree
At the beginning of the optimization process, the AMis empty. Starting from an initial
solution, either the process of climbing the tree starts. In the allocation of meters, the
initial solution corresponds to the base case (no meter installed). As deﬁned, the tree
root is associated with a solution to the optimization problem, and more speciﬁcally, it
corresponds to the best individual, “ibest.” At the beginning of the process, the root
corresponds to the base case.
When the MMS method starts the search process, there is no information about the
paths to be investigated. In the present work, the exhaustive search of the root to the top
was adopted for this stage. That is, by disturbing a solution two other solutions are
obtained and so on up to the top. The maximum number of paths in the tree operation
(possible solutions) is given by Eq. (1). Thus, for example, if we consider a tree height
equal to eight (h = 8) we have 256 possible solutions starting from the root.
c ¼ 2h
ð1Þ
where c is the possible number of solutions of a tree and h is the height of the tree.
From the results obtained from this exhaustive search, the adaptive memory
mechanism starts to store a set of solutions that will serve as references for the next
trees. In the present work, the AM always stores the ten best nodes (solutions) in
descending order in such a way that the ibest (root) is the ﬁrst in the list. Figure 2a
244
F. G. Duque et al.

depicts the condition of exploration of the initial tree in which all initially unexplored
paths are traversed during the search process resulting in the “complete” exploration of
the tree.
Step 2—Search for Subsequent Trees
The subsequent trees investigated in the MMS search process are obtained from per-
turbations in the best solution found, that is, a tree always starts from the “ibest” of the
AM. However, in this case, there is no exhaustive search. In other words, only the best
node between the two generated by each disturbance will be visited. In this way, the top
of the tree is struck with h disturbances from the root.
Figure 2b depicts the condition of exploration of the subsequent tree in which some
of the initially unexplored paths are traversed during the search process resulting in the
“partial” exploration of the tree.
2.3
MMS Flowchart
Figure 3 shows the proposed algorithm ﬂowchart, MMS, where it can be observed that
the algorithm consists of nine steps. The following is a detailed description of the
ﬂowchart:
Step 1: Data entry. In this step, the system data to be analyzed as well as the MMS
parameters method are determined, such as the height of the trees (h), the size of the
AM, and the maximum number of trees to be visited ia_max.
Step 2: Climb up the starting tree. This step consists of exploring the starting tree
from its root. This root corresponds to any solution. Knowing the root determines
the corresponding ﬁtness. From there, the solution is successively disturbed until it
reaches the top of the tree with the evaluation of all the paths (solutions).
Step 3: Start AM. The “n” best solutions, where “n” represents the size of AM,
according to ﬁtness are stored neatly in the AM in descending order of quality. In
this case, the “ibest” is clearly identiﬁed as the ﬁrst element of the AM.
Fig. 2. Tree exploration steps
Modiﬁed Monkey Search Technique Applied
245

Fig. 3. MMS proposed algorithm ﬂowchart
246
F. G. Duque et al.

Step 4: Disturb “ibest”. Beginning of exploration (climb) of the subsequent tree Ai.
This step is always performed from “ibest” in an attempt to ﬁnd an even better
solution. The evolution from one node of the tree to another of higher level is
performed through the solution perturbation mechanism described above.
Step 5: Choose a new solution. As already described, the upper node chosen is the
one with the best ﬁtness between the two nodes generated with the disturbance.
Step 6: Evaluate the new solution. Two options may occur: (i) if the new solution
presents better ﬁtness than “ibest,” this solution becomes the “ibest” and new tree
must be analyzed, returning the process to step 4; (ii) if the new solution is not
better than “ibest,” then AM should be updated if this solution is better than some
AM solution. It is emphasized that the worst solution of the AM is abandoned to
give way to a better solution. In this case, the algorithm goes to step 7.
Step 7: Convergence test. The global convergence of the MS algorithm is achieved
when all adaptive memory solutions are close enough to each other. If this is not
achieved, the algorithm ends when all trees are visited (ia_max). The degree of this
proximity to the convergence is given by a tolerance whose value is important for
the performance of the algorithm. A very high value implies a shorter computing
time but may lead to premature convergence of the algorithm in a suboptimal
solution, whereas very low values result in high processing times, with a promise of
method efﬁciency. If convergence was not achieved, the algorithm should continue
in step 8 to see if it reached the top of the tree.
Step 8: Check top. This step consists of verifying that the top has been reached. If
the top is reached, it means that no better solution was found than “ibest.” Thus, the
algorithm must return to step 4 to perform a new perturbation from the root
(“ibest”). This procedure is called the descent of the tree. On the other hand, if the
top has not yet been hit, one should keep climbing the tree. Then, the algorithm
goes to “step 9.”
Step 9: Disturb the solution. As already described, two new solutions are obtained
by perturbing the current solution. From there, the algorithm returns to step 5.
Modiﬁed Monkey Search Technique Applied
247

The algorithm details are given below:
Global variables initialization
h, c, AM, ε, α, β, ia_max, nperi, CPMU, CSM ; 
Initial Tree Base Solution (without meters)
Definition of the root solution by applying eq (11.5) with NPMU = NSM = 0;
Search in the initial tree
Search all tree paths by disturbing the current solution;
Variations in Nb (increment and/or decrement) subject to (NPMU + NSM ≤  Nb – 1);
For each disturbed solution apply eq (11.5);
Calculations of subsequent tree parameters
ibest = best initial tree solution;
tolerance = AM(10) – AM(1);
Initialization of the subsequent tree counter (ih = 1);
While tolerance > ε or ih < ia_max
For ia = 1:c or ibest(ih) < ibest(ih-1)
Variations in Nb (increment and/or decrement) subject to (NPMU + NSM ≤  Nb – 1);
For each disturbed solution apply eq (11.5);
Comparison of each disturbed solution with ibest;
If the disturbed solution is better than ibest
Updating of AM and ibest;
Else
Updating of AM;
End If
End For 
Tolerance updating;
Increment in the tree counter (ih = ih + 1);
End While
2.4
Differences Between the MS and MMS Algorithms
The main differences between the basic method (MS) and the modiﬁed method
(MMS) are necessary to improve the algorithm performance for exclusive application
in meter allocation in distribution systems. The differences between MS and MMS are
described below:
248
F. G. Duque et al.

• The ﬁrst difference is the rise of subsequent trees. While the proposed MMS
evaluates only the best solution of the AM (“ibest”), the original MS evaluates any
of the solutions belonging to the AM set;
• The original MS algorithm has an equal treatment for all trees; thus, initial
tree = subsequent, and its exploration consists of an exhaustive search for all the
trees, since the proposed MMS has a differentiated treatment with respect to the
trees, and thus, initial tree 6¼subsequent, then only the initial tree consists of
exhaustive search and the subsequent trees attend to the tree convergence criterion;
• The original MS deﬁnes the path as a set of exploited branches not necessarily
deﬁned by the root-to-top sequence, but also from any level of the tree (6¼from the
root) to another level above (6¼from the top). The proposed MMS deﬁnes a path
with a sequence of branches explored from the root to the top (root-top) or to any
level where it obtains the convergence of the tree;
• Finally, the most important aspect is the process of intensifying the current solution.
The MMS proposed after a series of executions create a rank allowing a reduction
of the search space (stagnation of the search process) thus improving the quality of
the solution and computational time. In the original MS, such a procedure does not
exist.
2.5
MS and MMS Algorithm Approach
The work described in [23] demonstrated that the use of MS is competitive in relation
to other metaheuristic methods. In order to prove the method efﬁciency, tests were
performed to optimize the Lennard-Jones function and Morse clusters, and to simulate
protein molecules based on a geometric model for protein folding. The following year
Ref. [25] used the MS algorithm to solve optimization problems with continuous
variables applying to benchmark problems with 30, 1000, or even 10,000 dimensions,
showing that MS can ﬁnd good quality solutions for large dimensions.
Reference [24] applied the metaheuristic to solve multidimensional assignment
problems (MAP). Already the Ref. [26] applied the MS technique in discretizable
molecular distance geometry problem (DMDPG).
In relation to the MMS algorithm, three articles were proposed in the line of power
systems. Firstly, it was published [27] in which improvements in the MS optimization
technique are proposed to obtain a better representation of the capacitor allocation
problem and increase computational efﬁciency. The problem objective is to optimize
the operation of the distribution network over a planning horizon, minimizing system
losses with minimum investment cost in capacitors. It was later published [28] in which
the proposed model considers different load levels, voltage limit restrictions, and
practical values for ﬁxed and switched capacitor banks, as well as for unit costs and
emission coefﬁcient. The objectives are to minimize energy loss, improve voltage
levels, and reduce the emission of carbon dioxide. Finally, it was published [29] in
which an extended optimal power ﬂow (E-OPF) is presented for the estimating states in
energy distribution systems in which it considers different network conﬁgurations. The
objective function combines the state estimation error (SEE) of the weighted least
squares (WLS) approach with additional indexes related to state variables, which
improve the state estimation process.
Modiﬁed Monkey Search Technique Applied
249

3
Problem Formulation
3.1
Modeling of the Meter Allocation Problem via MMS
The main aspects such as parameter deﬁnition, convergence criteria, and perturbation
mechanisms of the proposed MMS algorithm applied to the meter allocation problem
are discussed in this section.
Tree Parameters
For the meter allocation problem, the initial solution is not random and corresponds to
the base case, that is, the system without allocation of meters. This solution is deﬁned
as the root of the initial tree. The tree parameter height (h) is of great importance since
it determines the number of nodes to be investigated and, consequently, the number of
solutions obtained. The determination of this parameter should consider the following
aspects:
• A high value of h increases the probability of obtaining good solutions, but implies
a high number of paths, candidate solutions, and computational effort;
• A low value of h implies low computational effort but also limits the search space,
which can affect the quality of the solution.
From the previous aspects, there is a compromise between solutions’ quality and
computational requirements in the choice of the value of h for a given problem.
Solution Perturbation Mechanism
The perturbation mechanism is required to derive new candidate solutions. For the
meter allocation problem, this mechanism consists of increasing or decreasing the
number of meters at a random bus of a randomly chosen solution. The number of
increments or decrements is also random from one to three variations. In order to
exemplify this mechanism, a 10-bus system is considered, for which the allocation of
Table 1 is a candidate solution.
According to Table 1, the solution establishes meters in buses 1, 2, 6, 8, and 11.
Applying the disturbance, the number of increments is considered equal to 1 and the
number of decrements equal to 2. The randomly chosen buses are bus 3 for increasing
and buses 6 and 8 for decrements. Thus, after this perturbation, the solution of Table 2
is derived.
Table 1. Meter allocation of a candidate solution
No. Bus
1
2
3
4
5
6
7
8
9
10
No. Meters
1
1
0
0
0
1
0
1
0
1
Table 2. New meter allocation candidate solution
No. Bus
1
2
3
4
5
6
7
8
9
10
No. Meters
1
1
1
0
0
0
0
0
0
1
250
F. G. Duque et al.

Adaptive Memory
The adaptive memory of the proposed MMS algorithm consists of a list containing the
ten current best solutions. This memory is formed during the search in the initial tree
and is updated in the subsequent trees. In order to explain the formation and updating
of the adaptive memory, AM in Eq. (2), it is considered that, after searching the initial
tree, it comprises the solutions AM1 to AM10, arranged in descending order of quality.
AM ¼ AM1; AM2; AM3; AM4; AM5; AM6; AM7; AM8; AM9; AM10
½

ð2Þ
The vector of Eq. (1) is obtained through an exhaustive search in the initial tree
(A1). The best solution, whose value is AM1, is deﬁned as the root of the ﬁrst sub-
sequent tree (A2). This solution is perturbed until the convergence criterion of the
subsequent tree is reached. The memory update is done whenever a solution better than
any belonging to the set [AM1: AM10] is found. Hence, the new solution found is
inserted into this set, in the position deﬁned according to its quality, and the subsequent
values are shifted to the right. The value of the last position, AM10, is discarded and
replaced by the value stored in AM9 before the shift. Notice that the size of memory
AM remains the same, with ten positions.
For instance, it is considered that during the search in tree A2, two solutions, AMx
and AMy, are better than AM3 and AM6 of the initial memory of Eq. (1), respectively.
In this case, the new conﬁguration of the adaptive memory, updated after the search in
tree A2, is shown in Eq. (3).
AM ¼ AM1; AM2; AMx
j
j; AM3; AM4; AMy

; AM5; AM6; AM7; AM8
h
i
ð3Þ
It is observed that the memory update is not limited to solutions better than AM1
(“ibest”). In the example, AMx and AMy are not better than AM1 but are better than
AM3 and AM6 of tree A1. This updated strategy allows a faster convergence of the
algorithm and thus increases the computational efﬁciency. For the meter allocation
problem, AM is in organized in the ascending order of the objective function
(OBF) that must be minimized.
Solution Intensiﬁcation Process
During the proposed MMS algorithm search process, the set of covered branches is
marked. In the meter allocation problem, the maximum quantity of meters is initially
not limited. After a given number of covered branches, the number of meters of the
aforementioned set is limited around the number of meters given by the solutions of
this set. Thus, from this point up to the convergence, the perturbation mechanism
changes the buses for meters but maintains the total number of meters, which results in
a reduced search space and speeds the algorithm. In order to exemplify, in the hypo-
thetical 10-bus system, after 300 iterations of the MMS algorithm, a “rank” is created
for the number of meters veriﬁed in the covered solutions, as in Table 3, where 100
solutions have 5 m, 45 solutions have 6 m, and so on.
Modiﬁed Monkey Search Technique Applied
251

The value of branches for limiting the maximum number of meters is a parameter.
A low value implies low processing time but can limit the search space too much,
whereas a high value can affect the computational efﬁciency. Thus, this value must
balance computational time with the quality of the solution.
Convergence Criterion
In MMS, the convergence criterion for the initial tree differs from the criterion for
subsequent trees, as described hereinafter.
• Criteria for the initial tree: The initial tree convergence is achieved when all paths of
this tree are covered (exhaustive search for paths).
• Criteria for subsequent trees: The subsequent tree convergence is achieved when at
least one of the following conditions is met: (i) When the solution obtained through
a perturbation is better than the root solution of the tree (ibest).
In addition to the tree convergence criteria, which allow the transition from one tree
to another, there is the criterion of the MMS algorithm global convergence, which is
achieved when the difference between the objective functions of the solutions of the
last and the ﬁrst position of the adaptive memory is less than or equal to a tolerance e,
as formulated in Eq. (4) for a given tree Ai.
OBF AM10
ð
Þ  OBF AM1
ð
Þ  e
ð4Þ
where OBF(AM10) is the adaptive memory solution in the ﬁnal position for Ai, OBF
(AM1) is the adaptive memory solution in the initial position for Ai, and e is the
tolerance value. Another global convergence criterion is achieved when all subsequent
trees are covered, that is, when the maximum number of trees (ia_max) is achieved.
3.2
Measurement Planning Methodology
The objective function of the meter allocation problem is formulated in Eq. (5) [30].
OBF ¼ Min c:
X
Nb
k¼1
cUMFk  xUMFk þ
X
Nb
k¼1
cMIk  xMIk
 
!
þ a 
X
c2C
Ic
MVD þ b 
X
c2C
Ic
AFD
"
#
ð5Þ
wherein cUMFk and cMIk are the investment costs in PMU and SM, respectively, in the
bus k; xUMFk and xMIk are the integer variables that represent the investment option in
PMU and SM, respectively, in bus k (1—investment, 0—investment not indicated), c, a
and b are weights for the investment cost and the indexes [30] related to module (IMVD)
Table 3. Rank for the number of meters in the found solutions
Number of meters
1
2
3
4
5
6
7
8
9
10
Score
0
0
10
25
100
45
15
5
0
0
252
F. G. Duque et al.

and phase angle (IAFD) of the nodal voltages, respectively. Notice the IMVD and IAFD
indexes are known as least absolute values (LAV).
Each individual of the MMS represents a candidate solution for the planning of
monitoring equipment, being coded in a vector with two parts: (a) part A—values for
the decision variables of the problem, that is, xUMFke xMIk; and (b) part B—branches
monitored by the equipment allocated according to part A. Figure 4 shows the coding
adopted in the MMS algorithm.
In the example of Fig. 4, the system has six buses, bus “1” refers to the substation
and buses “4,” “5,” and “6” are load buses. In this case, the maximum number of
equipment, PMU and/or SM, is ﬁve, since the SS already has its own measurement. It
means that another constraint for the optimization model is NPMU + NSM  Nb −1,
where NPMU and NSM are the numbers of PMU and SM, respectively. This constraint
was not included in the proposed OPF model since it is provided by the metaheuristic
MMS technique.
The proposed coding for part A is binary, where the value “1” in one position
determines the allocation of the meter in the bus associated with this position, while the
value “0” represents no investment in the corresponding bus. Also, each candidate
solution is represented by two vectors, one for PMU and one for SM. In the illustration
of Fig. 4, the upper vector stores the investment decisions in PMU and the lower vector
decisions on SM. Therefore, in this example, there is the allocation of PMUs in buses
“2” and “3,” and SM in bus “5.”
Fig. 4. Encoding a candidate solution in the proposed MMS
Modiﬁed Monkey Search Technique Applied
253

The coding of Part B also presents binary code where “1” indicates that the cor-
responding branch is monitored and “0” means the absence of measurement according
to Fig. 4. Thus, the monitored sections by the PMUs of Part A are highlighted in Fig. 4
(S2, S3, S4, S5, and S6), whereas the SM of Part A monitors S8.
It should be noted that the formation of Part B in the candidate solutions addresses
the possibility of monitoring the equipment of Part A, in order to ensure the solution
consistency, in terms of network elements to be monitored. For instance, in Fig. 4, the
PMUs of buses “2” and “3” can monitor sections S2, S3, S4, S5, and S6, taking in
account
their
locations
and/or
monitoring
channels
and/or
communication
infrastructure.
Candidate solutions that do not meet operational constraints, such as precision, are
penalized by the search process. Different conﬁgurations are considered for planning,
each referring to network topology, aiming at the best planning envisaging different
operating conditions to which SDE is normally subjected [31].
Each candidate conﬁguration is evaluated through the objective function of Eq. (5),
which includes the state estimation process accuracy and investment cost. To obtain the
estimator accuracy, the proposed E-OPF model is executed for each topology. The
optimization tool for solving the modiﬁed OPF model is based on the primal–dual
interior-point method [32].
4
Results and Discussion
The results that are presented in this section seek to show the MMS algorithm effec-
tiveness for the planning of meter in EDS. Other methods used for comparison are
modiﬁed monkey search (MMS) [27], original monkey search (MS) [28], genetic
algorithm (GA) [33], simulated annealing (SA) [34], and exhaustive search (ES).
4.1
The Parameters Used for the MMS and MS
The parameters of the modiﬁed monkey search and MS were the same used in the Refs.
[27, 28]: (i) the height of a tree h = 8, totaling c = 256 paths; (ii) the global conver-
gence process tolerance e = 0 (Case 1) and e = 100 (Case 2); (iii) the maxi-
mum number of trees ia_max = 20; (iv) adaptive memory size (AMS) = “10”; and
(v) the number of solutions for the intensiﬁcation process nperi = 100.
4.2
The Parameters Used for GA
The parameters used for the implementation of the GA were the same used in the
reference [33] for all cases: (i) the crossover rate about 95%; (ii) the mutation rate
about 2%; (iii) the population of 300 individuals; (iv) 100 generations; (v) the con-
vergence criterion is based on the maximum number of generations; (vi) elitism;
(vii) decimal encoding of individuals; (viii) the selection via roulette; and (ix) two cut-
off points for the crossover.
254
F. G. Duque et al.

4.3
The Parameters Used for SA
The parameters used for the implementation of the SA were the same used in the ref-
erence [34] for all cases: (i) Boltzmann constant, KB = 1; (ii) initial temperature, T0 = 30;
(iii) maximum number of iterations, kmax = 300; and (iv) cooling rate, a = 0.95.
4.4
The Parameters of the Meter Allocation Problem
Two case studies were used to evaluate the MMS.
Case 1—Tutorial with the 16-bus system [35]; and
Case 2—33-bus system [36].
The parameters of the meter allocation problem are:
• Investment costs as in Ref. [30]—(i) PMU: 1.0 c.u.; (ii) SM: 0.2 u.c. where “c.u.”
means “cost unit”;
• Measurement errors as in Ref. [30]—(i) about 1% for the measures of SS and PMU;
(ii) about 10% for SM; and (iii) about 50% for pseudo-measures based on historical
data; and
• Simulations number: about 100 simulations of each metaheuristic algorithm (MMS,
MS, GA, and SA).
4.5
The Machine Conﬁguration and the Software
The tests were performed by using a 4 GHz Intel Corei5–4200U processor with
3.20 GHz RAM. The proposed metaheuristics were developed by using the software
MATLAB version R2013a.
Case 1—Tutorial
The well-known 16-bus 23 kV test system of [35], shown in Fig. 5, is used as a tutorial
to explain the application of the proposed approach. In order to evaluate the impact of
Fig. 5. 16-bus test system [35]
Modiﬁed Monkey Search Technique Applied
255

different scenarios in the optimization, two analyses are performed. The ﬁrst one,
Analysis-A, considers only the base case, Fig. 5, whereas Analysis-B includes more
than one scenario.
Analysis-A
In Analysis-A, the weights a and b of Eq. (5) are equal to 1.0 as in [30] and Ns is also
equal to “1,” which means that only one scenario is considered, the conﬁguration of
Fig. 5. With no allocation of measurement devices, there is no investment cost and the
OBF is 24.3543 u.c. From the search in the initial tree of the proposed MMS, the best
ten solutions that form vector AM are presented in Table 4
Table 5 presents the number of evaluated solutions and the cost evolution obtained in
each tree. For instance, the root of tree A2 is the best solution found in tree A1(OBF =
8.4926 u.c.), which is subjected to a number of 2 perturbations to derive the best solution
found in A2(OBF = 8.4923 u.c.). Figure 6 presents the convergence of the algorithm.
Table 4. Solutions of the initial adaptive tree, 16-bus system
Position
OBF (u.c.)
Position
OBF (u.c.)
MA1
8.4926
MA6
8.5029
MA2
8.4927
MA7
8.5092
MA3
8.4941
MA8
8.5101
MA4
8.4942
MA9
8.5151
MA5
8.4943
MA10
8.5190
Table 5. Number of perturbations and the cost evolution per tree, 16-bus
Cost at the beginning ! cost at the end of the tree
Number of perturbations
Tree (Ai)
10.0560 ! 8.4926
256
1
8.4926 ! 8.4923
2
2
8.4923 ! 8.4665
14
3
8.4665 ! 8.4163
16
4
8.4163 ! 8.2883
35
5
8.2883 ! 8.0517
96
6
8.0517 ! 7.9386
158
7
7.9386 ! 7.5601
254
8
256
F. G. Duque et al.

Table 6 presents the reduction (in u.c. and %) in the total cost (OBF) obtained by
the MMS in relation to the base case without meter allocation. Table 7 presents the
average processing time and the average number of covered trees for 100 executions of
the MMS algorithm. Figure 7 shows the best solutions found in the 100 executions of
the proposed MMS.
Fig. 6. Convergence curve of the MMS algorithm, 16-bus
Table 6. Reduction in the total cost, 16-bus
Reduction (%)
68.96
Reduction (u.c.)
16.7942
Table 7. Average processing time and the number of trees, 16-bus
The average time (min.)
2.26
The average number of trees
9.56
Fig. 7. Best solutions found by the proposed MMS algorithm, 16-bus
Modiﬁed Monkey Search Technique Applied
257

The intensiﬁcation process is addressed in Table 8 and Fig. 8, where it can be
veriﬁed that after 310 perturbations, solutions with “3” m are found in MA more than
100 times, that is, the number “3” reaches the “rank” = 100. Thus, from this point up to
the convergence, the algorithm set the maximum number at “3.”
Finally, Table 9 presents the best-optimized results obtained by the MMS, MS,
GA, and SA algorithms, where the time refers to the processing time for convergence.
The investment cost (Inv. Cost) consists of the sum of the last two terms of Eq. (5),
which are associated with the investment in PMU and SM. It can be observed that the
MMS gives the best solution, associated with the smallest OBF, in this case. After 100
simulations of the MMS, the best result is 7.5601 u.c. and the worst is 8.1105 u.c.,
which means a deviation between the best and worst results of 1.66%.
Table 8. Rank of solutions according to the number of meters, 16-bus
Number of meters 1
2
3
4
5
6
7 8 9 10 11 12 13 14
Rank
29 48 100 71 40 14 2 6 0 0
0
0
0
0
Fig. 8. Intensiﬁcation process illustration
Table 9. Results for the 16-bus test system, Analysis-A
Algorithm PMU buses SM buses IMVD(%)
IAFD (crad)
Inv. cost (u.c.) OBF (u.c.) Time (min)
MMS
7-10-14
–
4.1509
0.4092
3.00
7.5601
2.26
MS
6-9-14
10
4.1391
0.3764
3.20
7.7155
5.65
GA
7-11
6-9-10
4.6417
0.5168
2.60
7.7585
9.81
SA
7-10-13
3
4.0439
0.4067
3.20
7.6506
6.29
258
F. G. Duque et al.

For comparison purpose, the estimation indexes and costs are also presented when:
(a) PMU, or SM, is placed at all system buses except the substation, Table 10;
(b) PMU, and/or SM, are placed at terminal buses of the feeder of Fig. 5, buses 5, 10,
and 14, Table 11; (c) exhaustive search (ES) process is used, Table 12, whose
objective is to assess the solutions obtained by the proposed optimization methodology.
The ES was applied to determine the best places to be monitored, by considering
the number of devices ﬁxed at “3,” as found by the MMS, as well as at “2” and “4” in
order to evaluate a smaller variation around “3.” It can be observed that the best result
from the ES matches with the best MMS solution. The results of Tables 10 and 11
show the presence of conﬂicting objectives in the OBF of Eq. (5). If a large amount of
precise and expensive devices as PMU are placed, the investment cost and OBF
increase in relation to the optimal results. On the other hand, if only SM is placed, even
though at all buses, the estimation indexes increase due to the lower accuracy of SM
compared to PMU. Then, the OBF increases despite the investment cost being lower.
Table 10. PMU and SM at all buses, 16-bus, one conﬁguration
The device at all buses
PMU
SM
The device at all buses
PMU
SM
IMVD (%)
1.0000
10.6674
Inv. cost (u.c.)
13.00
2.60
IAFD (crad)
0.0668
1.9326
OBF (u.c.)
14.07
15.20
Table 11. PMU and SM at the feeder terminals, 16-bus, one conﬁguration
PMU buses
SM buses
IMVD (%)
IAFD (crad)
Inv. cost (u.c)
OBF (u.c.)
5-10-14
–
5.0673
0.3333
3.00
8.40
5-10
14
10.7827
1.0141
2.20
14.00
5-14
11
7.5913
1.0865
2.20
10.88
10-14
5
5.4617
0.4241
2.20
8.09
14
5-10
8.7984
0.8355
1.40
11.03
11
5-14
11.9706
0.8329
1.40
14.20
5
11-14
17.0848
3.6249
1.40
22.11
–
5-10-14
20.3452
4.0092
0.60
24.95
Table 12. ES results, 16-bus, one conﬁguration
No. devices PMU buses SM buses IMVD (%)
IAFD (crad)
Inv. cost (u.c.) OBF (u.c.) Time (min)
2
7-11
–
5.2182
0.4757
2.00
7.69
2.69
3
7-10-14
–
4.1509
0.4092
3.00
7.56
22.02
4
3-6-7-14
–
3.2478
0.3207
4.00
7.57
122.21
Modiﬁed Monkey Search Technique Applied
259

Analysis-B
Analysis-B considers the same conditions of Analysis-A with the addition of eight
probable conﬁguration scenarios to the scenario of Fig. 5. The purpose is to ﬁnd an
optimal solution that can establish a suitable trade-off between different scenarios in
terms of state estimation precision and investment cost. The considered scenarios are:
Scenario 1—Open switches—S5, S10, S16; Scenario 2—Open switches—S5, S10, S14;
Scenario 3—Open switches—S5, S10, S15; Scenario 4—Open switches—S1, S10, S16;
Scenario 5—Open switches—S1, S10, S14; Scenario 6—Open switches—S1, S10, S15;
Scenario 7—Open switches—S1, S5, S16; Scenario 8—Open switches—S1, S5, S14; and
Scenario 9—Open switches —S1, S5, S15.
In Scenarios 1–3, the entire system is supplied by the feeder that starts from the
substation through S1. The feeder in scenarios 4–6 starts through S5 and in scenarios 7–
9, in turn, through S10. In this case, the weights a and b of OBF Eq. (5) are equal to
“1/9” to maintain the trade-off between state estimation precision and investment costs.
From empirical analyses, it could be concluded that a good choice for a and b is given
by the inverse of the number of scenarios. Without allocation of PMU or SM, the OBF
is 29.8138 u.c. Table 13 presents the best results. The ES was performed for the same
total number of measurement devices of the MMS, and however, ES requires much
more time than the proposed MMS with the embedded state estimation model
(SEM) and both lead to the same result for this case.
In 100 simulations of the MMS algorithm, which obtained the best result in
Table 13, the deviation between the best result, 8.3636 u.c., and the worst one,
9.1743 u.c., is 1.99%. The results of Analysis-B faced with Analysis-A show that the
consideration of different network scenarios impacts the planning of measurement
systems in EDS since the OBF increases with the number of scenarios due to the more
realistic representation.
Finally, Fig. 9 brings the convergence curve of the algorithms discussed in
Table 13.
Table 13. Results for the 16-bus test system, Analysis-B
Algorithm PMU buses SM buses IMVD (%)
IAFD (crad)
Inv. cost (u.c.) OBF (u.c.) Time (min)
MMS/ES
2-6-9-13
–
3.9732
0.3904
4.00
8.3636
20.78/1093.63
MS/GA
2-6-9-14
4
3.9269
0.4110
4.20
8.5379
52.01/84.90
SA
2-6-7-13
5
3.9203
0.3568
4.20
8.4771
61.15
260
F. G. Duque et al.

Case 2—33-bus system
The 12.66 kV 33-bus test system of [36], Fig. 10, is formed by a substation and 32
branches. The exhaustive search is performed with the total number of measurement
devices obtained by MMS to determine the global best location and assess the proposed
approach.
In this case, the considered scenarios are listed hereafter [28]: Scenario 1—Open
switches—S33(7–20), S34(8–14), S35(11–21), S36(17–32) and S37(24–28), the original
conﬁguration of Fig. 10; Scenario2—Open switches—S7(7–20), S10(8–14), S14(11–
Fig. 9. Convergence curve of the MMS, MS, GA, and SA algorithms, 16-bus, Analysis-B
Fig. 10. 33-bus test system [36]
Modiﬁed Monkey Search Technique Applied
261

21), S32(17–32) and S37(24–28); and Scenario 3—Open switches—S7(7–20), S9(8–14),
S14(11–21), S32(17–32) and S37(24–28), which is the optimized conﬁguration for
minimum loss [37]. The weight factors a and b of Eq. (5) are set at “1/3.” In this case,
the OBF is 24.5351 u.c. when no PMU or SM is allocated. Table 14 presents the best
results, where the one from the MMS/SEM is the best found. The deviation between
the best and worst solutions from the MMS/SEM is 4.60%, with the respective OBF
equal to 11.4439 u.c. and 13.6279 u.c. Again, the solution from the MMS algorithm is
close to the globally optimal ES solution, whereas GA and SA can also ﬁnd good
options in terms of OBF. Figure 11 brings the convergence curve of the algorithms
discussed in Table 14.
Table 14. Results for the 33-bus test system, Analysis-B
Algorithm PMU buses
SM
buses
IMVD (%)
IAFD
(crad)
Inv. cost
(u.c.)
OBF
(u.c.)
Time (min)
MMS
12-17-23-30
8
6.9554
0.2885
4.20
11.44
16.35
GA
12-17-21-23-25-
31
5-8-30
5.44206
0.3128
6.60
12.35
51.60
SA
5-8-12-17-23-31
21-25-30
5.2904
0.2350
6.60
12.13
39.60
ES
10-16-23-30
7
6.8430
0.2689
4.20
11.31
4.89  104
Fig. 11. Convergence curve of the MMS, GA, and SA algorithms, 33-bus, Analysis-B
262
F. G. Duque et al.

5
Discussion and Conclusions
The changes in the MS required to obtain the most appropriate MMS for application in
meter allocation were presented. The modiﬁcations provided greater ease in terms of
implementation and understanding. To clarify the modiﬁcations made in MS, a tutorial
was presented for the problem of meter allocation. Finally, the case study involves the
system of 33 buses. For this system, the proposed MMS obtained the best results in
computational terms, less processing time, and in terms of ﬁnancial, the lower total cost
in the optimal allocation of meters when compared to MS, GA, and SA.
5.1
Further Research Topics
Application of the proposed methodology in three-phase distribution systems with
unbalanced load characteristics, as well as under different load scenarios such as light,
medium and heavy loads and load changes throughout the day. Validation of the
method for current scenarios, involving the use of renewable energy sources, active
networks due to the insertion of distributed generation, analysis of contingencies, and
restoration scenarios.
Acknowledgements. The authors gratefully acknowledge the ﬁnancial support in part of
CAPES—Coordenação de Aperfeiçoamento de Pessoal de Nível Superior—Brasil, CNPq—
Conselho Nacional de Desenvolvimento Cientíﬁco e Tecnológico—Brasil, INERGE—Instituto
Nacional de Energia Elétrica, and FAPEMIG—Fundação de Amparo à Pesquisa no Estado de
Minas Gerais. The authors also express gratitude for the educational support of UFJF—Federal
University of Juiz de Fora.
References
1. Gomez-Exposito A, Abur A (2004) Power system state estimation: theory and implemen-
tation. CRC Press
2. Sallam AA, Malik OP (2018) Electric distribution systems. Wiley-IEEE Press
3. De Araujo LR, Penido DRR, Carneiro S Jr, Pereira JLR (2018) Optimal unbalanced
capacitor placement in distribution systems for voltage control and energy losses
minimization. Electr Power Syst Res 154:110–121
4. Primadianto A, Lu CN (2017) A review on distribution system state estimation. IEEE Trans
Power Syst 32(5):3875–3883
5. Available in http://www.aneel.gov.br. Agência Nacional De Energia Elétrica (Brasil)
[Online]
6. Fan J, Borlase S (2009) The evolution of distribution. IEEE Power Energ Mag 7(2):63–68
7. Repo S, Maki K, Jarventausta P, Samuelsson O (2008) ADINE-EU demonstration project of
active distribution network. In: Proceedings of CIRED Seminar 2008: SmartGrids for
Distribution, vol 23–24. Frankfurt, Germany, pp 1–5
8. Meliopoulos AS, Zhang F (1996) Multiphase power ﬂow and state estimation for power
distribution systems. IEEE Trans Power Syst 11(2):939–946
9. Singh R, Pal BC, Vinter RB (2009) Measurement placement in distribution system state
estimation. IEEE Trans Power Syst 24(2):668–675
Modiﬁed Monkey Search Technique Applied
263

10. Singh R, Pal BC, Jabr RA, Vinter RB (2011) Meter placement for distribution system state
estimation: an ordinal optimization approach. IEEE Trans Power Syst 26(4):2328–2335
11. Muscas C, Pilo F, Pisano G, Sulis S (2009) Optimal allocation of multichannel measurement
devices for distribution state estimation. IEEE Trans Instrum Meas 58(6):1929–1937
12. Madlener R, Liu J, Monti A, Muscas C, Rosen C (2009) Measurement and metering
facilities as enabling technologies for smart electricity grids in Europe. A Sectoral e-Business
Watch
13. Raghuraman S, Jegatheesan R (2011) A survey on state estimation techniques in electrical
power system. In: Recent advancements in electrical, electronics and control engineering
(ICONRAEeCE), pp 199–205
14. Amin SM, Wollenberg BF (2005) Toward a smart grid: power delivery for the 21st century.
IEEE Power Energ Mag 3(5):34–41
15. Exposito AG, Abur A, Jaen AV, Quiles CG (2011) A multilevel state estimation paradigm
for smart grids. Proc IEEE 99(6):952–976
16. Dey N (ed) (2017) Advancements in applied Metaheuristic computing. IGI Global
17. Gupta N, Patel N, Tiwari BN, Khosravy M (2018) Genetic algorithm based on enhanced
selection and log-scaled mutation technique. In: Proceedings of the future technologies
conference, pp 730–748. Springer
18. Singh G, Gupta N, Khosravy M (2015) New crossover operators for real coded genetic
algorithm (RCGA). In: Intelligent informatics and biomedical sciences (ICIIBMS), 2015
international conference on IEEE, pp 135–140
19. Gupta N, Khosravy M, Patel N, Senjyu T (2018) A bi-level evolutionary optimization for
coordinated transmission expansion planning. IEEE Access 6:48455–48477
20. Gupta N, Khosravy M, Patel N, Sethi IK (2018) Evolutionary optimization based on
biological evolution in plants. Procedia Comput Sci Elsevier 126:146–155
21. Moraes CA, De Oliveira EJ, Khosravy M, Oliveira LW, Honório LM, Pinto MF (2020) A
hybrid bat-inspired algorithm for power transmission expansion planning on a practical
Brazilian network. In: Applied nature-inspired computing: algorithms and case studies,
pp 71–95. Springer, Singapore
22. Khosravy M, Gupta N, Patel N, Senjyu T, Duque CA (2020) Particle swarm optimization of
morphological ﬁlters for electrocardiogram baseline drift estimation. In: Applied nature-
inspired computing: algorithms and case studies, pp 1–21. Springer, Singapore
23. Mucherino A, Seref O (2007) Monkey search: a novel metaheuristic search for global
optimization. AIP Conf Proc 953(1):162–173
24. Kammerdiner AR, Mucherino A, Pardalos PM (2009) Application of monkey search meta-
heuristic to solving instances of the multidimensional assignment problem. Optimization and
cooperative control strategies. Springer, Berlin, Heidelberg, pp 385–397
25. Zhao RQ, Tang WS (2008) Monkey algorithm for global numerical optimization. J Uncertain
Syst 2(3):165–176
26. Mucherino A, Liberti L, Lavor C, Maculan N (2009, July) Comparisons between an exact
and a metaheuristic algorithm for the molecular distance geometry problem. In: Proceedings
of the 11th annual conference on genetic and evolutionary computation, ACM, pp 333–340
27. Duque FG, de Oliveira LW, de Oliveira EJ, Marcato AL, Silva IC Jr (2015) Allocation of
capacitor banks in distribution systems through a modiﬁed monkey search optimization
technique. Int J Electr Power Energy Syst 73:420–432
28. Duque FG, de Oliveira LW, de Oliveira EJ (2016) An approach for optimal allocation of
ﬁxed and switched capacitor banks in distribution systems based on the monkey search
optimization method. J Control Autom Electr Syst 27(2):212–227
264
F. G. Duque et al.

29. Duque FG, de Oliveira LW, de Oliveira EJ, Augusto AA (2017) State estimator for electrical
distribution systems based on an optimization model. Electr Power Syst Res 152:122–129
30. Liu J, Tang J, Ponci F, Monti A, Muscas C, Pegoraro PA (2012) Trade-offs in PMU
deployment for state estimation in active distribution grids. IEEE Trans Smart Grid 3
(2):915–924
31. Tecchio PP, Benedito RA, Alberto LFC (2010) The behavior of WLS state estimator near
the maximum loadability point of power systems. In: Power and energy society general
meeting IEEE, pp 1–6
32. Oliveira EJ, Oliveira LW, Pereira JLR, Honório LM, Silva IC, Marcato ALM (2015) An
optimal power ﬂow based on safety barrier interior point method. Int J Electr Power Energy
Syst 64:977–985
33. da Silva IC, Carneiro S, de Oliveira EJ, de Souza Costa J, Pereira JLR, Garcia PAN (2008) A
heuristic constructive algorithm for capacitor placement on distribution systems. IEEE Trans
Power Syst 23(4):1619–1626
34. Su CT, Lee CS (2001) Feeder reconﬁguration and capacitor setting for loss reduction of
distribution systems. Electr Power Syst Res 58(2):97–102
35. Civanlar S, Grainger JJ, Yin H, Lee SSH (1988) Distribution feeder reconﬁguration for loss
reduction. IEEE Trans Power Deliv 3(3):1217–1223
36. Baran ME, Wu FF (1989) Network reconﬁguration in distribution systems for loss reduction
and load balancing. IEEE Trans Power Deliv 4(2):1401–1407
37. Oliveira LW, Carneiro S, de Oliveira EJ, Pereira JLR, Silva IC, Costa JS (2010) Optimal
reconﬁguration and capacitor allocation in radial distribution systems for energy losses
minimization. Int J Electr Power Energy Syst 32(8):840–848
Modiﬁed Monkey Search Technique Applied
265

Chapter 12
Artiﬁcial Neural Network Trained by Plant
Genetic-Inspired Optimizer
Neeraj Gupta1, Mahdi Khosravy2,3(&), Nilesh Patel1,
Saurabh Gupta4,5, and Gazal Varshney6
1 Department of Computer Science and Engineering, Oakland University,
Rochester, MI, USA
2 Media Integrated Communication Lab, Graduate School of Engineering,
Osaka University, Osaka, Japan
mahdi.khosravy@ufjf.edu.br
3 Electrical Engineering Department, Federal University of Juiz de Fora,
Juiz de Fora, Brazil
4 Department of Advanced Engineering, John Deere India Pvt. Ltd., Pune, India
5 Research Scholar, Department of Computer Science, Banasthali Vidyapith,
Vanasthali, Rajasthan, India
6 University of Information Science and Technology, Ohrid, North Macedonia
1
Introduction
Despite having different structure and connections, approximately, all ANN are using
common training algorithms. Backpropagation (BP) and gradient-based (GB) methods-
based training algorithms are widely in use as classical techniques. These training
mechanisms are mostly deterministic numerical approach [1]. These classical methods
for training/learning have the advantage of fast convergence but could entrap a local
extremum easily. However, after observing the inevitable performance of the evolu-
tionary algorithms on the problem of many ﬁelds, they have used to train the artiﬁcial
neural network (ANN) instead of conventional training algorithms [2, 3]. As the
population-based approach pulled the interest of many researchers to train the ANN,
genetic algorithm (GA), based on the law of natural selection, has been applied suc-
cessfully to improve the results [2–4]. A list of successful implementations of evolu-
tionary and swarm algorithms to train ANN is given in [2–6].
After observing the success rate of evolutionary algorithms as an intelligent
algorithm and increasingly signiﬁcant tool in the ﬁeld of neuroevolution, many meta-
heuristic optimization techniques had proposed by others and training strategy for ANN
[6, 7]. These algorithms can handle a broad set of the variables of all types such as
linear, nonlinear, and discrete without any additional bounding criteria. After observing
the computational power of nature-inspired algorithms [6, 7] in the last few decades, a
wide range of research papers are the results to design and train artiﬁcial neural network
(ANN) by them. For an overview of recent advanced techniques for training
© Springer Nature Singapore Pte Ltd. 2020
M. Khosravy et al. (eds.), Frontier Applications of Nature Inspired Computation,
Springer Tracts in Nature-Inspired Computing,
https://doi.org/10.1007/978-981-15-2133-1_12

algorithms, readers are suggested to follow an excellent survey and publications [8, 9].
Before implementing the METO as training algorithm, it would be worth to discuss the
ANN.
This framework of using the evolutionary algorithm as a training mechanism of
ANN is known as neuroevolution, a form of artiﬁcial intelligence [10]. Introduction of
this phenomenon increased the efﬁciency of computational intelligence (CA). Although
the above-mentioned neuroevolution technique is slower than the deterministic
approach, it trains the ANN at high accuracy as intelligent learning techniques.
Population-based evolutionary algorithms have shown their unavoidable dexterity over
single-solution-based optimizers and above-speciﬁed classical methods of training
ANN [9–12].
Several variants of evolutionary algorithms are proposed until the date to train the
ANN as an intelligent form of learning process [2–13]. The traces of neuroevolution
can be seen in survey papers [12, 14]. These papers [12, 14, 15] explained every corner
of the neuroevolution and its scope. Moreover, the study shown in [15] uses the genetic
algorithm as a training scheme to decide the weights for ANN. During the last decades,
variants of GA, evolutionary strategies, and memetic algorithms have been suggested
with different coding schemes to improve the accuracy of neuroevolution. Reference
[16] suggests using of GA and PSO together to train the ANN, where [17] focused on
BBO, and [17] proposes the improvement by utilizing DE as evolutionary training
algorithm [18]. Augmented by the conclusion given in above research papers, the
recent neuroevolution training algorithms are Ant lion optimization [19], grasshopper
optimization [20], invasive weed optimization (IWO) [21], Teaching–learning-based
optimization [22], and many more [19].
2
Evolutionary Nature-Inspired Optimizers
Nowadays, evolutionary optimization [23, 24] has drawn a great attention of the
researchers especially for non-convex nonlinear problems where the classic opti-
mization fails to solve. Despite existing a variety of nature-inspired meta-heuristic
optimizers, since the demand for accuracy and speed of algorithms is increasing, there
is an effort to present more accurate and faster optimizers. The wide range of evolu-
tionary algorithms (EAs) techniques covers a variety of optimizers inspired from dif-
ferent natural phenomena like genetic algorithm (GA) [25–27], biogeography-based
optimization (BBO) [28], PSO [29–34], Bat algorithm [35–37], cuckoo search [38],
ﬁreﬂy [39], teaching– learning-based optimization (TLBO) [40], Plant biology-inspired
optimizer known as Mendelian evolutionary theory optimization (METO) [41, 42], etc.
Although the focus of the chapter is on neuroevolution, EOs have a great potential
to be applied for variety of applications as text feature detection [43], blind component
processing [44], blind source separation [45–49], noise cancelation [50], image
enhancement [51, 52], ECG processing [53–56], quality assessment [57], data mining
[58], imaging systems [59], information hiding [33], telecommunications [60–63],
Artiﬁcial Neural Network Trained
267

morphological ﬁltering [64, 65], image adaptation [66], acoustic OFDM [67], power
line communications [68], fault detection [69], etc.
Main motivation of this work is improving the existing EAs training algorithms by
introducing a new evolutionary structure such as integration of multi-species and self-
organization in population genetics. Thus, the resulting distinctive features of proposed
METO are as follows:
1. This is a binary-coded ANN trainer as explores the transformed genome weight
search space instead of real.
2. A double-strand chromosome scheme makes it much better than the conventional
GA.
3. It deploys natural breading process of fusing opposite strands of DNA instead of
single-strand chromosome as in GA.
4. It possesses global information exchange strategy through the exchange of genetic
characteristics between different species parents.
5. It internally possesses a self-organizing process after mutation which resists the
inappropriate changes in genetic characteristics during the evolution.
6. Bypassing stagnation on local optima during the training of ANN.
7. Showing the outperformance of METO over peer algorithms as given in last chapter
Table-1.
8. Designing AI-based diagnostic tool for condition and monitoring of the oil ﬁlter in
AgM.
9. Reducing the number of ANN evaluations to obtain global optima.
3
Artiﬁcial Neural Network (ANN)
ANN is an artiﬁcial intelligence (AI) system which is a systematic composition of
several neurons as input, hidden and output layers, where neurons are connected in
various fashions through synaptic weights. Its designing process is a tedious task due to
its dependency on various parameters such as network structure, used transfer func-
tions, and values of synaptic weights. For the selected structure of the ANN, synaptic
weights associated with all connections between the neurons acquire new value as a
result of evolution phase and achieve sufﬁcient knowledge to solve the problem. This
process is continuous until the termination criteria found such as number of evolution
phases, acceptable mean square to achieve goal value. After training the ANN, it is
tested and validated by using unknown samples of trained ANN for the same problem.
This step certiﬁes that the design ANN can be used to solve the problem such as
classiﬁcation, pattern recognition, and regression. ANN problem can be deﬁned for the
set of inputs
X ¼ x ¼ xijx 2 Rn;
i ¼ 1; 2; . . .; n
f
g
ð1Þ
268
N. Gupta et al.

and outputs
Y ¼ y ¼ yojy 2 Rm;
o ¼ 1; 2; . . .; m
f
g
ð2Þ
It shows that input and output layers of ANN have, respectively, n and n artiﬁcial
neurons. For designing the ANN for above-given sets of data for chosen number of
hidden layers, the objective function can be represented as
F ¼ f ðX; Y; WÞ
ð3Þ
where W is the set of synaptic connections between all layers as
W ¼
W12; W23; . . .; Wl1;l


Here, l is the total number of layers including input, hidden, and output. In the
above formulation, minimizing the F, mean square error (MSE) gives an optimized
synaptic weight of ANN.
A pictorial view of MLP ANN can be seen in Fig. 1, where each neuron is com-
posed of two sections. First, it adds all the inputs and then passes to the transfer
function at second section. Thereafter, the output of this neuron is available as the input
to other neurons in the next layer. Possible connections between the neurons are also
shown in Fig. 1, where each neuron is connected to all neurons of next layers by the
synaptic weights. Mathematical representation forms each neuron is given as
yp ¼ F
X
n
i¼0
wp
i xp
i þ bp
 
!
ð4Þ
Here, xp
i is the ith input to the pth neuron, which is multiplied with wP
i synaptic
weight value associated with the connection between the ith and pth neuron. In the
expression, F denotes the transfer function, which can be any type for the neuron, such
as step function, linear function, and nonlinear functions. Each neuron requires a bias
for ﬁring efﬁciently and is represented by b in above equation. yp is the output of pth
neuron. Each neuron in any layer of the MLP follows above equation, which passes the
learned information as yp to the next neuron.
Artiﬁcial Neural Network Trained
269

Under the learning process of MLP, wP
i associated with each synaptic connection
between the neurons is subjected to change. The evaluation of optimal value of these
synaptic weights is the problem of learning ANN. These synaptic weights are stopped
to change once the network has learned the behavior of problem. In this case, the output
of the ANN is desired and justiﬁed by the minimized objective function.
After training the ANN, validation is the next step before utilizing to solve the
problem. For supervised learning, generally, ANN is tested for the set of input pattern
and associated output as per the following equation:
T ¼
ts ¼
xt
i 2 Rn; yt
j 2 Rm


n
ji ¼ 1; 2; . . .; n;
j ¼ 1; 2; . . .; mg
ð5Þ
In above equation, T is the testing set, where each element of this is composed of xt
i
input pattern and yt
i output. Here, xt
i and yt
i are vectors, respectively, of n and m
elements equal to the number of neurons in corresponding layers of ANN. ANN is
okay to use as an intelligent system for the given testing set to it if the MSE e calculated
from the output y of trained ANN and actual output yt is in acceptable limit.
e ¼
1
s  n
X
s
i
X
n
j
yt
i;s  yi;s

2
ð6Þ
Until the e is minimized, the synaptic weights are subjected to change to learn
behavior of the input pattern. For this, generally, classical learning algorithms were
used as gradient descendant technique and backpropagation etc. These techniques of
Fig. 1. Schematic of artiﬁcial neural network
270
N. Gupta et al.

learning the ANN can be trapped at local minima and resulted non-optimal synaptic
weights values. Non-optimality of weights value indicates that ANN is not able to
capture the exact behavior of problem. However, researchers at Uber have claimed that
a simple structural ANN-based trained by evolutionary algorithms is competitive with
sophisticated modern industry-standard gradient-descent deep learning algorithms. He
stated the reason that neuroevolution does not get stuck in dead ends. Inspired by this
concept and previous work, we present a novel binary-coded evolutionary algorithm
which takes advantage of biological intelligence to transfer the information from one
evolution phase to others.
4
Complexity Level in Designing ANN
The design levels of ANN are shown in Fig. 2, where search of connection weight for
the given network structure is at the low difﬁculty level. Main objective of the ANN is to
minimize the error subject to avoid over ﬁtting. Searching the optimal weights value is
called learning the network, for which we adopt the meta-heuristic evolutionary algo-
rithm. However, only ﬁnding the optimal weights does not provide the best solution,
where the structure of neurons in hidden layers is an important task. Thus, along with
ﬁnding the optimal weights proposed, meta-heuristic technique optimizes the behavior
of each neuron by ﬁnding associated transfer function. Thus, we handle quasi-level
design of architecture of the ﬁxed structure ANN. For deciding the learning rule, we
apply a variety of meta-heuristic algorithms and proposed the one which best trains the
network. In summary, three-level design of ANN has the following mode of automation.
1. Weight search strategy is fully automatic by the meta-heuristic learning algorithms
(evolution of learning rule).
2. Decision of learning algorithm/rule is manual (evolution of learning rule).
Fig. 2. Complexity level in designing ANN
Artiﬁcial Neural Network Trained
271

3. Selection of hidden layers and neurons in them are worked with the hand, where the
behavior of the neuron is automated.
4. Selection of hidden layers and neurons in them is worked with the hand, where the
behavior of the neuron is automated by meta-heuristic learning algorithm. Thus, the
evolution of architecture is quasi-automated, where only neurons’ behavior is
optimized along with weights.
5
Generation of Population
Each population contains n chromosomes strands. Each chromosome strand is com-
posed of b bits, where b is the sum of lw and lTF bits corresponding to weights and
transfer function (TF). Each chromosome represents the structure of an ANN, where
the total number of ANN is simulated equal to the number of chromosomes strands in
the population in an evolution. One evolution is completed by the sequential two sub-
evolution results from F1 and F2 generation. Offspring population and next parent
population are designed based on the ﬁtness value of each ANN. Figure 3 illustrates the
population of chromosomes to represent artiﬁcial neural networks.
For this strategy, we adopt an elite selection operator to form a population of better
ANN parents for the next generation.
Fig. 3. Population of chromosomes to represent artiﬁcial neural networks
272
N. Gupta et al.

A block diagram of training ANN is given in Fig. 4. Here, we can see that METO
provides weights and biases value to the ANN structure, and then, calculated ﬁtness is
reverted to the METO to select next better weights value. For the inputted weights,
ANN calculates the ﬁtness using training samples. Detailed explanation of the complete
process of METO is given in Fig. 5 in the context to optimize the ANN. Parent-1 and
parent-2 representing the set of weights and biases are ﬁrst cross-breeded to generate
F1 generation offspring, and then, heredity is transferred in it when self-breed to
generate F2 generation offspring. At the last, best of all generated offspring and both
parents are taken to form heredity to pass to the next evolution epoch.
Fig. 4. Block diagram of training ANN by PGO
Fig. 5. Evolution of ANN using PGO algorithms
Artiﬁcial Neural Network Trained
273

Figure 6 presents the genotype representation of the weights in the form of chro-
mosome. Each weight is represented by l number of bits, which can be considered as
max (10, wU  wL
½
). Here, wU and wL; respectively, are the upper and lower limit of
weight. METO operates on genotype representation of the weights, and then, the
decoded value is converted to input to the ANN. Also, in this Fig. 6, we can see at the
right-side bits representing transfer functions (TF)s, where they are different from the
weights. Right-side bits are providing integer values where each integer value repre-
sents a TF. For example, if we have four TFs, then the decoded output of one string will
be an integer between 1 and 4. However, string associated with weight provides
decoded real value.
6
Loss Function
Optimizing the ANN requires a way to measure the quality of the solution provided by
METO. This is done using the objective function, which brings the solution closer to
the goal. Objective function takes the weights’ real values, TF and training samples as
arguments and evaluates them to return a numerical value. Based on the output value,
METO optimizes ANN parameters to minimize the numerical value of objective
function.
In other words, we say loss function to measure the inconsistency between pre-
dicted value and actual label. Robustness of ANN is increasing with decreasing non-
negative loss function. Mean squared logarithmic error (MSLE) is widely used loss
function, which we used to train our model. It is deﬁned as
Fig. 6. Genotype representation of weights and transfer functions (TF)
274
N. Gupta et al.

L ¼ 1
n
X
n
i¼1
log yðiÞ þ 1


 log byðiÞ þ 1



2
ð7Þ
This function is a variant of mean square error (MSE) and used to measure the
difference between actual and predicted. Taking log of actual and predicted value does
not penalize huge difference in the predicted and actual value. It penalizes underesti-
mates as follows:
1. MSE and MLSE are equal for small actual and predicted values.
2. MLSE is smaller or almost negligible than MSE if predicted and actual values are
huge.
7
Feature Extraction
Feature extraction turns raw data into the information that is suitable for machine
learning algorithms. Feature extraction eliminates the redundancy present in many
types of measured data, facilitating generalization during the learning phase. We uti-
lized MFCC techniques, which extract 13 features from the acoustic signal. We have
extracted features in Chap. 4, which we have utilized with 13 MFCC features to train
the model. So, we have a total of 15 features as input to the ANN.
For example, for six fault conditions, we can label all extracted features from 1 to 6.
Developing a predictive model is an iterative process which involves these steps:
i. Select the training and validation data.
ii. Select a classiﬁcation algorithm.
iii. Iteratively train and evaluate classiﬁcation models.
For training the model, we can divide 70% data in training set and 30% data in the
validation set. We can randomly sample the training set and validation set, without
repetition. Evolutionary ANN is ﬁrst trained on training set and then checked for
validation set for its accuracy. The accuracy is calculated as
accuracy ¼
b1
n yvalidation  yvalidation
ð
Þ  100:
ð8Þ
8
Conclusion
In this chapter, we explained that how METO is integrated in the artiﬁcial neural
networks. To understand well this integration, a brief introduction to METO has been
presented. We have also described the objective function which is mean squared
logarithmic error to penalize underestimates more than over-estimates. The neuro-
evolutionary system of METO-ANN is suggested for faulty condition detection in
Artiﬁcial Neural Network Trained
275

hydraulic system of an agriculture machine, wherein the condition of system is pre-
dicted from the sounds of oil pump. To aim this goal, it is required to detect the
pollution level as suggested by this chapter a model for training over 15 features, where
13 features are from MFCC. In a separate research work, we will provide the simu-
lation results and relevant analysis evaluating thet METO performance compared to the
other optimizers.
References
1. Anthony M, Bartlett PL (2009) Neural network learning: theoretical foundations. Cambridge
university press
2. Blackwell T, Branke J (2004) Multi-swarm optimization in dynamic environments. In:
Workshops on applications of evolutionary computation. Springer, Berlin, Heidelberg,
489–500
3. Urgen Branke J (1995) Evolutionary algorithms for neural network design and training. In:
Proceedings of the 1st nordic workshop on genetic algorithms and its applications
4. Blackwell T, Branke J (2006) Multiswarms, exclusion, and anti-convergence in dynamic
environments. IEEE Trans Evol Comput 10(4):459–472
5. Branke J, Kaußler T, Smidt C, Schmeck H (2000) A multi-population approach to dynamic
optimization
problems.
Evolutionary
design
and
manufacture.
Springer,
London,
pp 299–307
6. Engelbrecht AP (2007) Computational intelligence: an introduction. John Wiley & Sons
7. Grefenstette JJ (1999) Evolvability in dynamic ﬁtness landscapes: a genetic algorithm
approach. In: Proceedings of the 1999 congress on evolutionary computation-CEC99, Cat.
No. 99TH8406, vol. 3, pp 2031–2038
8. Gudise VG, Venayagamoorthy GK (2003) Comparison of particle swarm optimization and
backpropagation as training algorithms for neural networks. In Proceedings of the 2003
IEEE swarm intelligence symposium. SIS’03, cat. no. 03EX706, pp 110–117
9. Holm JE, Botha EC (1999) Leap-frog is a robust algorithm for training neural networks.
Network Comput Neural Syst 10(1):1–13
10. Torrecilla JS, Otero L, Sanz PD (2007) Optimization of an artiﬁcial neural network for
thermal/pressure food processing: evaluation of training algorithms. Comput Electron Agric
56(2):101–110
11. Floreano D, Dürr P, Mattiussi C (2008) Neuroevolution: from architectures to learning. Evol
Intel 1(1):47–62
12. Stanley KO, Clune J, Lehman J, Miikkulainen R (2019) Designing neural networks through
neuroevolution. Nat Mach Intell 1(1):24–35
13. Pagliuca P, NolﬁS (2019) Robust optimization through neuroevolution. PLoS ONE 14(3):
e0213193
14. Sloss AN, Gustafson S (2019) 2019 Evolutionary algorithms review. arXiv preprint arXiv:
1906.08870
15. Mohammed MA, Ghani MKA, Arunkumar NA, Hamed RI, Abdullah MK, Burhanuddin MA
(2018) A real time computer aided object detection of nasopharyngeal carcinoma using
genetic algorithm and artiﬁcial neural network based on Haar feature fear. Future Gener
Comput Syst 89:539–547
16. Jamali B, Rasekh M, Jamadi F, Gandomkar R, Makiabadi F (2019) Using PSO-GA
algorithm for training artiﬁcial neural network to forecast solar space heating system
parameters. Appl Therm Eng 147:647–660
276
N. Gupta et al.

17. Pham BT, Nguyen MD, Bui KTT, Prakash I, Chapi K, Bui DT (2019) A novel artiﬁcial
intelligence approach based on multi-layer perceptron neural network and biogeography-
based optimization for predicting coefﬁcient of consolidation of soil. CATENA 173:
302–311
18. Dahou A, Elaziz MA, Zhou J, Xiong S (2019) Arabic sentiment classiﬁcation using
convolutional neural network and differential evolution algorithm. Comput Intell Neurosci
19. Heidari AA, Faris H, Aljarah I, Mirjalili S (2019) An efﬁcient hybrid multilayer perceptron
neural network with grasshopper optimization. Soft Comput 23(17):7941–7958
20. Alameer Z, Elaziz MA, Ewees AA, Ye H, Jianhua Z (2019) Forecasting gold price
ﬂuctuations using improved multilayer perceptron neural network and whale optimization
algorithm. Res Policy 61:250–260
21. Gong Y, Xiao S (2019) Synthesis of sparse arrays in presence of coupling effects based on
ANN and IWO. In: 2019 IEEE international conference on computational electromagnetics
(ICCEM), pp 1–3
22. Dash CSK, Behera AK, Dehuri S, Cho SB (2019) Building a novel classiﬁer based on
teaching learning based optimization and radial basis function neural networks for non-
imputed database with irrelevant features. Appl Comput Inf
23. Dey N (ed) (2017) Advancements in applied metaheuristic computing. IGI Global
24. Dey N, Ashour AS (2016) Antenna design and direction of arrival estimation in meta-
heuristic paradigm: a review. Int J Serv Sci Manage Eng Technol 7(3):1–18
25. Gupta N, Patel N, Tiwari BN, Khosravy M (2018 Nov) Genetic algorithm based on
enhanced selection and log-scaled mutation technique. In: Proceedings of the future
technologies conference. Springer, Cham, pp 730–748
26. Singh G, Gupta N, Khosravy M (2015 Nov) New crossover operators for real coded genetic
algorithm (RCGA). In: 2015 international conference on intelligent informatics and
biomedical sciences (ICIIBMS), IEEE, pp 135–140
27. Gupta N, Khosravy M, Patel N, Senjyu T (2018) A bi-level evolutionary optimization for
coordinated transmission expansion planning. IEEE Access 6:48455–48477
28. Simon Dan (2008) Biogeography-based optimization. IEEE Trans Evol Comput 12(6):
702–713
29. Chatterjee S, Sarkar S, Hore S, Dey N, Ashour AS, Balas VE (2017) Particle swarm
optimization trained neural network for structural failure prediction of multistoried RC
buildings. Neural Comput Appl 28(8):2005–2016
30. Jagatheesan K, Anand B, Samanta S, Dey N, Ashour AS, Balas VE (2017) Particle swarm
optimisation-based parameters optimisation of PID controller for load frequency control of
multi-area reheat thermal power systems. Int J Adv Intell Paradigms 9(5–6):464–489
31. Chatterjee S, Hore S, Dey N, Chakraborty S, Ashour AS (2017) Dengue fever classiﬁcation
using gene expression data: a PSO based artiﬁcial neural network approach. In: Proceedings
of the 5th international conference on frontiers in intelligent computing: theory and
applications. Springer, Singapore, pp 331–341
32. Jagatheesan K, Anand B, Dey N, Gaber T, Hassanien A E, Kim TH (2015 Sept) A design of
PI controller using stochastic particle swarm optimization in load frequency control of
thermal power systems. In: 2015 fourth international conference on information science and
industrial applications (ISI), IEEE, pp 25–32
33. Chakraborty S, Samanta S, Biswas D, Dey N, Chaudhuri SS (2013 Dec) Particle swarm
optimization based parameter optimization technique in medical information hiding. In:
2013 IEEE international conference on computational intelligence and computing research,
pp 1–6
Artiﬁcial Neural Network Trained
277

34. Khosravy M, Gupta N, Patel N, Senjyu T, Duque CA (2020) Particle swarm optimization of
morphological ﬁlters for electrocardiogram baseline drift estimation. In: Dey N, Ashour AS,
Bhattacharyya S (eds) Applied nature-inspired computing: algorithms and case studies.
Springer, Singapore, pp 1–21
35. Moraes CA, De Oliveira, EJ, Khosravy M, Oliveira LW, Honório LM, Pinto MF (2020) A
hybrid bat-inspired algorithm for power transmission expansion planning on a practical
Brazilian network. In: Dey N, Ashour AS, Bhattacharyya S (eds) Applied nature-inspired
computing: algorithms and case studies. Springer, Singapore, pp 71–95
36. Satapathy SC, Raja NSM, Rajinikanth V, Ashour AS, Dey N (2018) Multi-level image
thresholding using Otsu and chaotic bat algorithm. Neural Comput Appl 29(12):1285–1307
37. Rajinikanth V, Satapathy SC, Dey N, Fernandes SL, Manic KS (2019) Skin melanoma
assessment using Kapur’s entropy and level set—a study with bat algorithm. In: Smart
intelligent computing and applications. Springer, Singapore, pp 193–202
38. Dey N, Samanta S, Yang XS, Das A, Chaudhuri SS (2013) Optimisation of scaling factors in
electrocardiogram signal watermarking using cuckoo search. Int J Bio-Inspired Comput
5(5):315–326
39. Dey N, Samanta S, Chakraborty S, Das A, Chaudhuri SS, Suri JS (2014) Fireﬂy algorithm
for optimization of scaling factors during embedding of manifold medical information: an
application in ophthalmology imaging. J Med Imaging Health Inf 4(3):384–394
40. Rao RV, Savsani VJ, Vakharia DP (2011) Teaching learning-based optimization: a novel
method for constrained mechanical design optimization problems. Computer-Aided Des
43(3):303–315
41. Gupta N, Khosravy M, Patel N, Sethi IK (2018) Evolutionary optimization based on
biological evolution in plants. Procedia Comput Sci Elsevier 126:146–155
42. Gupta N, Khosravy M, Mahela OP, Patel N (2020) Plants biology inspired genetics
algorithm: superior efﬁciency to ﬁreﬂy optimizer. In: Applications of ﬁreﬂy algorithm and its
variants, from springer tracts in nature-inspired computing (STNIC). Springer International
Publishing (in press)
43. Gutierrez CE, Alsharif MR, Khosravy M, Yamashita K, Miyagi H, Villa R (2014) Main
large data set features detection by a linear predictor model. AIP Conf Proc 1618(1):733–737
44. Khosravy M, Gupta N, Marina N, Asharif MR, Asharif F, Sethi IK (2015 Nov) Blind
components processing a novel approach to array signal processing: a research orientation.
In: 2015 international conference on intelligent informatics and biomedical sciences
(ICIIBMS), IEEE, pp 20–26
45. Khosravy M, Asharif MR, Yamashita K (2009) A PDF-matched short-term linear
predictability approach to blind source separation. Int J Innov Comput Inf Control (IJICIC)
5(11):3677–3690
46. Khosravy M, Alsharif MR, Yamashita K (2009) A PDF-matched modiﬁcation to stone’s
measure of predictability for blind source separation. International symposium on neural
networks. Springer, Berlin, Heidelberg, pp 219–228
47. Khosravy M, Asharif MR, Yamashita K (2011) A theoretical discussion on the foundation of
stone’s blind source separation. SIViP 5(3):379–388
48. Khosravy M, Asharif M, Yamashita K (2008 July) A probabilistic short-length linear
predictability approach to blind source separation. In: 23rd international technical conference
on circuits/systems, computers and communications (ITC-CSCC 2008), Yamaguchi, Japan,
pp 381–384
49. Khosravy M, Kakazu S, Alsharif MR, Yamashita K. (2010) Multiuser data separation for
short message service using ICA (信号処理). 電子情報通信学会技術研究報告. SIP, 信号
処理: IEICE Tech Rep 109(435):113–117
278
N. Gupta et al.

50. Khosravy M, Asharif MR, Sedaaghi MH (2008) Medical image noise suppression: using
mediated morphology. IEICE Tech Rep, IEICE, pp 265–270
51. Ashour AS, Samanta S, Dey N, Kausar N, Abdessalemkaraa WB, Hassanien AE (2015)
Computed tomography image enhancement using cuckoo search: a log transform based
approach. J Signal Inf Process 6(03):244
52. Khosravy M, Gupta N, Marina N, Sethi IK, Asharif MR (2017) Brain action inspired
morphological image enhancement. Nature-inspired computing and optimization. Springer,
Cham, pp 381–407
53. Dey N, Mukhopadhyay S, Das A, Chaudhuri SS (2012) Analysis of P-QRS-T components
modiﬁed by blind watermarking technique within the electrocardiogram signal for
authentication in wireless telecardiology using DWT. Int J Image Graphics Signal Process
4(7):33
54. Dey N, Ashour AS, Shi F, Fong SJ, Sherratt RS (2017) Developing residential wireless
sensor networks for ECG healthcare monitoring. IEEE Trans Consum Electr 63(4):442–449
55. Sedaaghi MH, Khosravi M (2003 July) Morphological ECG signal preprocessing with more
efﬁcient baseline drift removal. In: Proceedings of the 7th IASTED international conference,
ASC, pp 205–209
56. Khosravi M, Sedaaghi MH (2004 Feb) Impulsive noise suppression of electrocardiogram
signals with mediated morphological ﬁlters. In: The 11th Iranian Conference on Biomedical
Engineering, Tehran, Iran, pp 207–212
57. Khosravy M, Patel N, Gupta N, Sethi IK (2019) Image Quality assessment: a review to full
reference indexes. Recent trends in communication, computing, and electronics. Springer,
Singapore, pp 279–288
58. Gutierrez CE, Alsharif MR, Yamashita K, Khosravy M (2014) A tweets mining approach to
detection of critical events characteristics using random forest. Int J Next-Gener Comput 5
(2):167–176
59. Hore S, Chakraborty S, Chatterjee S, Dey N, Ashour AS, Van Chung L, Le DN (2016) An
integrated interactive technique for image segmentation using stack based seeded region
growing and thresholding. Int J Electr Comput Eng 6(6):2088–8708
60. Khosravy M, Alsharif MR, Guo B, Lin H, Yamashita K (2009 Mar) A robust and precise
solution to permutation indeterminacy and complex scaling ambiguity in BSS-based blind
MIMO-OFDM receiver. In: International conference on independent component analysis
and signal separation. Springer, Berlin, Heidelberg, pp 670–677
61. Asharif F, Tamaki S, Alsharif MR, Ryu HG (2013) Performance improvement of constant
modulus algorithm blind equalizer for 16 QAM modulation. Int J Innov Comput Inf Control
7(4):1377–1384
62. Khosravy M, Alsharif MR, Yamashita K (2009) An efﬁcient ICA based approach to
multiuser detection in MIMO OFDM systems. Multi-carrier systems and solutions 2009.
Springer, Dordrecht, pp 47–56
63. Khosravy M, Alsharif MR, Khosravi M, Yamashita K (2010 June) An optimum pre-ﬁlter for
ICA based multi-input multi-output OFDM system. In: 2010 2nd international conference on
education technology and computer, IEEE, vol 5, pp V5–129
64. Sedaaghi MH, Daj R, Khosravi M (2001 Oct) Mediated morphological ﬁlters. In:
Proceedings 2001 international conference on image processing (cat. no. 01CH37205),
IEEE, vol 3, pp 692–695
65. Khosravy M, Gupta N, Marina N, Sethi IK, Asharif MR (2017) Morphological ﬁlters: an
inspiration from natural geometrical erosion and dilation. Nature-inspired computing and
optimization. Springer, Cham, pp 349–379
Artiﬁcial Neural Network Trained
279

66. Khosravy M, Gupta N, Marina N, Sethi IK, Asharif MR (2017) Perceptual adaptation of
image based on Chevreul-Mach bands visual phenomenon. IEEE Signal Process Lett 24(5):
594–598
67. Khosravy M, Punkoska N, Asharif F, Asharif MR (2014) Acoustic OFDM data embedding
by reversible Walsh-Hadamard transform. AIP Conf Proc 1618(1):720–723
68. Picorone AAM, Oliveira TR, Sampaio-Neto R, Khosravy M, Ribeiro MV (2020) Channel
characterization of low voltage electric power distribution networks for PLC applications
based on measurement campaign. Int J Electr Power Energy Syst 116:105554
69. Gupta S, Khosravy M, Gupta N, Darbari H (2019) In-ﬁeld failure assessment of tractor
hydraulic system operation via pseudospectrum of acoustic measurements. Turkish J Electr
Eng Comput Sci 27(4):2718–2729
280
N. Gupta et al.

Continuous Optimizers for Automatic
Design and Evaluation of Classiﬁcation
Pipelines
Iztok Fister Jr.1(B), Milan Zorman1, Duˇsan Fister2, and Iztok Fister1
1 Faculty of Electrical Engineering and Computer Science, University of Maribor,
Koroˇska cesta 46, 2000 Maribor, Slovenia
iztok.fister1@um.si
2 Faculty of Economics and Business, University of Maribor, Razlagova 14, SI-2000
Maribor, Slovenia
1
Introduction
As has been known for a long time, some basic research areas (e.g., medicine,
biology) cannot solve some speciﬁc problems in their highly specialized laborato-
ries without modern scientiﬁc computational methods and algorithms. Bioinfor-
matics stands for a very vibrant interdisciplinary research area that, nowadays,
has been solving problems where the aid of digital computers is unavoidable.
Therefore, it is no wonder that the scientiﬁc discipline encompasses specialists
from diﬀerent research areas, such as, for example, computer scientists, mathe-
maticians, biologists, geneticists, and statisticians.
Indeed, the advent of digital computers has changed the principles of experi-
mental work as well. In past, most of the experiments in science were performed
either in vitro or in vivo. The former case refers to controlled experiments that
are conducted outside of an organism (e.g., in cellular biology), while the lat-
ter to experimentation running on a living organism (e.g., animals). Recently,
most experiments have been performed in silico, where they are performed on
computers or as computer simulations (e.g., DNA analysis).
For instance, let us imagine the whole human genotype that consists of
approximately 25,000 diﬀerent genes. In line with this, several questions have
arisen in bioinformatics, as follows: How can we analyze all complex interactions
between them, or even gene expression proﬁles, without specialized computa-
tional algorithms? How to process big data that are produced by the next-
generation sequencing (NGS) technology [29] and can easily be measured in
gigabytes or even terabytes? How to acquire new information or laws from bio-
data? Very topical problems have arisen as a consequence of all these questions,
and the answers are searched for through the world sponsors of many scientiﬁc
related projects by many research agencies around the world. For example, in
recent years, the famous European Union Project Horizon 2020 supported many
projects from these areas. By the same token, many hospitals opened their doors
c
⃝Springer Nature Singapore Pte Ltd. 2020
M. Khosravy et al. (eds.), Frontier Applications of Nature Inspired Computation,
Springer Tracts in Nature-Inspired Computing,
https://doi.org/10.1007/978-981-15-2133-1_13

282
I. Fister et al.
and hired bioinformaticians. Bioinformaticians support clinicians or laboratory
researchers with new information that can be obtained from data [19]. Most of
the above posted questions coincide with the same as are faced by data science as
well [5]. Data science is a multi-disciplinary domain that uses scientiﬁc methods,
processes, algorithms, and systems for extracting knowledge, and, thus, enabling
new insights from structured and unstructured data. Often, data scientists also
need to use methods from machine learning (ML) by data analysis. ML is a
part of an artiﬁcial intelligence (AI) that is capable of building a mathematical
model of sample data in order to make predictions or decisions without being
programmed explicitly to perform this task [2]. Thus, they were confronted with
a question, how to employ these methods as eﬀectively as possible?
As a key solution, automated machine learning (AutoML) became a topic of
considerable interest [25]. The purpose of AutoML is to automate some phases
of ML tasks, especially those demanding from data scientists to select the proper
ML method, or to set the more appropriate hyperparameters. Obviously, these
tasks are far from easy for non-experts. Therefore, the AutoML searches for
customized ML pipelines which are actually optimized sequences of ML meth-
ods, processes, algorithms, and appropriate hyperparameters for controlling their
behavior.
AutoML can be modeled as an optimization problem. There is a big pool of
diﬀerent AutoML methods that are based on evolutionary algorithms (EAs) [12].
TPOT [26] is a tree-based pipeline optimization tool for AutoML. It is based on
GP. Some improvements of TPOT are oﬀered in the thesis [15]. RECIPE [8] is
another excellent example that is based on grammar-based GP that builds cus-
tomized classiﬁcation pipelines. Interestingly, paper [34] reports a new EA for
the AutoML task of selecting the best ensemble of classiﬁers and their hyperpa-
rameter settings automatically for an input dataset. An example of the swarm
intelligence (SI) algorithm ant colony optimization (ACO) was used in the work
by Costa and Rodrigues [7].
Classiﬁcation problems are very common within the bioinformatics area. The
classiﬁcation task of a sample data means to classify each item from the sample,
represented by features, into one of a predeﬁned set of classes. Although the
task seems trivial from the expert’s point of view, a data scientist, for example,
needs to perform at least three tasks to accomplish this: The proper feature
selection algorithm must be selected ﬁrst, followed by selection of the appropriate
ML classiﬁcation methods. Finally, the optimal hyperparameter setting must
be found for each of the selected algorithms and ML methods. As a result, a
classiﬁcation pipeline is modeled manually that represents a customized sequence
of classiﬁcation methods and algorithms from the data scientist’s point of view.
As we can see from the aforementioned example, modeling of a classiﬁcation
pipeline is a really complex task. Additionally, it is worth mentioning that the
bioinformatics community also consists of data scientists who are not computer
experts. Potentially, they have trouble in conducting classiﬁcation tasks using
their own sample datasets. For that reason, they rely mostly on some existing,
usually commercial, software. However, this has many bottlenecks, especially
due to a lack of robustness of software solutions on the market.

Continuous Optimizers for Automatic Design and Evaluation
283
In this paper, the stochastic nature-inspired population-based algorithms are
proposed for evolving classiﬁcation pipelines automatically in bioinformatics. In
line with this, a novel AutoML method, named NiaAML, is presented, which
has the following advantages:
• the problem of AutoML is modeled as a continuous optimization problem,
where each stochastic nature-inspired population-based algorithm can be used
for solving this problem,
• the proposed method is presented in layer style architecture. Hence, adding
new components (e.g., classiﬁers) can be done in a very easy way,
• it is also intended to be used by non-programmers.
The structure of this paper is as follows: Sect. 2 deals with AutoML and
its characteristics. Section 3 outlines the proposed NiaAML solution, and Sect. 4
shows performed experiments and results. Section 5 concludes the paper and
outlines directions for the future work.
2
AutoML
The advent of big data has brought an explosion of ML researches and applica-
tions [20]. Consequently, scientists from various areas have been confronted with
issues of how to analyze data as eﬃciently as possible. Typically, a lot of ML
methods are employed in this analysis. Unfortunately, the performance of the
analysis depends on the selected ML methods, on the one hand, while all those
methods are sensitive to a plethora of parameters controlling their behavior, on
the other.
Therefore, ﬁnding the optimal sequence of ML methods for application on
sample data (also ML pipeline), together with their optimal parameter settings,
represents big trouble even for experts, let alone other domain specialists. Obvi-
ously, the optimal ML pipeline cannot be found in one step, but demands a “trial-
and-error” approach that was conﬁrmed in evolutionary computation (EC) [12].
Unfortunately, this approach cannot be applied here, due to the huge amount of
sample data. As a result, searching for the novel approximation methods needs
to be performed achieving the results good enough for using in practice.
In order to simplify complex ML tasks, the AutoML has been evolved, with
the aim to automate creation of the optimal ML pipelines and to enable other
domain specialists to use the complex set of ML methods and their optimal
hyperparameter settings easily. This means that the AutoML is a way of democ-
ratization of ML, wherein ML experts wish to draw the state-of-the-art ML
methods nearer to the other domain specialists. Although we are witnesses of an
early stage of AutoML development, the AutoML can even outperform human
ML experts and show its potential for the future.
This fast-moving area of ML is focused on three main issues:
• Hyperparameter optimization (HPO),
• Meta-learning,

284
I. Fister et al.
• Neural architecture search (NAS).
Various settings of hyperparameter values are crucial for good performance
of ML methods. Typically, these methods have a lot of hyperparameters, with
ranges usually unknown in advance. Therefore, it is not easy to determine their
optimal values manually. This issue has led researchers in AutoML to HPO,
where two optimization types are proposed in summary:
• blackbox optimization,
• multi-ﬁdelity optimization.
The former captures algorithms such as: model-free blackbox HPO and Bayesian
optimization. The model-free blackbox HPO is referred to traditional search
algorithms starting from a grid search, going through random search, and end-
ing with stochastic nature-inspired population-based algorithms [13,16]. On the
other hand, the Bayesian optimization is applied successfully for tuning deep
neural networks. Commonly, both mentioned types of blackbox optimization
algorithms are too time-consuming to be used in deep learning (DL). The lat-
ter type speeds up the manual tuning by probing hyperparameter setting on
small subsets of data, casting this into a formal multi-ﬁdelity algorithm, and
applying it on sample data. This HPO type presents the best trade-oﬀbetween
optimization performance and runtime.
Meta-learning is the science of observing systematically how diﬀerent ML
methods perform on a wide range of learning tasks, and then learning from
this experience [20]. Actually, the challenge in meta-learning is to learn from
prior experience in a systematic, data-driven way, with the goal of searching
for optimal models for new tasks. This means, the learning does not start from
scratch, but bases on the collected meta-data.
Meta-learning consists of two steps [20]:
• Collecting a meta-data, which describes prior learning tools and previously
learned models. The meta-data consists of algorithm conﬁgurations, including
hyperparameter settings, pipeline composition and/or network architecture,
and model evaluation expressed as accuracy and training time.
• Exploring the meta-data to learn, extract, and transfer knowledge for guiding
the search for the optimal models for new tasks.
Unfortunately, learning from prior experience is eﬀective only until a new task
represents completely unrelated phenomena or random noise. However, the real-
world tasks are usually not sensitive to the mentioned disturbances.
Deep learning brought a need for using complex network architectures. The
more eﬃcient architectures cannot be searched manually. Therefore, growing
interest in an automated NAS has been increasing recently. Although NAS has
a signiﬁcant overlap with hyperparameter optimization and meta-learning, it can
be seen as a subﬁeld of AutoML. According to Hutter et al. [20], NAS methods
are classiﬁed with regard to:
• search space,

Continuous Optimizers for Automatic Design and Evaluation
285
• search strategy,
• performance estimation strategy.
Incorporating prior knowledge about the search space can reduce its dimen-
sionality, and, thus, simplify the search. A search strategy determines how to
explore the search space. A performance estimation strategy searches for those
performance measures that allow reduction of the cost of their estimations, on
the one hand, and achieve highly predictive performance on unseen data on the
other [20].
3
Proposed NiaAML Method
Although classiﬁcation pipelines have already been composed using various
stochastic nature-inspired population-based algorithms (e.g., TPOT, RECIPE.
etc.), their origins were usually found in genetic programming (GP) [22], where
individuals are represented as trees. This study is focused on the real-valued
stochastic nature-inspired population-based algorithms for evolving classiﬁca-
tion pipelines. A NiaAML method was developed according to the directions of
AutoML development, as proposed in [20]. In this sense, the NiaAML is referred
to the collecting meta-data step. As already seen, the collecting meta-data is a
meta-learning step devoted for pipeline composition including hyperparameter
optimization and model evaluation.
An evolving classiﬁcation pipeline is illustrated in Fig. 1, from which it can
be seen that the classiﬁcation pipeline composition consists of three tools:
• feature selection,
• classiﬁer selection,
• hyperparameter optimization.
Fig. 1. A classiﬁcation pipeline evolving

286
I. Fister et al.
The task of the feature selection tool is to determine the suitable algorithm
for feature selection, while the classiﬁer selection tool is to select the proper ML
method. However, the algorithms, as well as classiﬁcation methods, are incorpo-
rated into a framework of tools. The hyperparameter optimization serves as a
searching mechanism for specifying the proper values of the parameters arisen
in the feature selection algorithms and classiﬁcation methods.
The result of the pipeline composing is a customized classiﬁcation pipeline
that needs to be evaluated in the model evaluation step. The task of evaluation
is to assess the quality of the composed model on a sample data. The evolving
process, consisting of pipeline composing and model evaluation, is launched until
the termination condition is satisﬁed.
An architecture of the NiaAML method is depicted in Fig. 2. The architecture
is represented schematically as a feature diagram (FD) [21] and describes tasks
needed for composing customized classiﬁcation pipelines. Actually, the FD is
a tree consisting of vertices and arcs. Vertices represent task models, and arcs
determine relationships between these. The vertices are either mandatory or
optional, where the former are denoted by closed dots, and the latter by open
dots.
As can be seen from Fig. 2, the task of composing the customized classiﬁcation
pipelines (‘NiaAML’ vertex) has three conceptual levels, as follows:
• pipeline composing models (features in FD),
• model families (sub-features in FD),
• tools and hyperparameter settings (attributes in FD).
Interestingly, each feature/sub-feature is determined by its own set of sub-
features/attributes that are connected between each other with various rela-
tionships. There are three diﬀerent relationships in the FD: ‘and’, ‘one of’, and
‘more of’. The ‘one of’ relationship is denoted by an opened semicircle joining
Fig. 2. Feature diagram of NiaAML method

Continuous Optimizers for Automatic Design and Evaluation
287
the arcs from a feature to its sub-features, the ‘more of’ by a closed semicircle,
while the ‘and’ relationship is without any semicircle. The meaning of these rela-
tionships is explained simultaneously with a detailed description of the FD that
follows.
Composing the customized classiﬁcation pipeline with NiaAML consists of
three mandatory tasks that include modeling the feature selection, the classiﬁer
selection, and the hyperparameter optimization. These tasks are connected with
relation ‘and’, which means that all three tasks must be included in the process of
composing the pipeline. Modeling the feature selection is composed of modeling
the feature selection algorithm and feature scaling. Both sub-features in FD are
connected with the relation ‘more of’. Because modeling the feature scaling is
optional, the relation means that modeling feature selection can be performed
with or without the feature scaling. However, the feature selection algorithm
must be modeled anyway. A classiﬁcation method can even be modeled from four
classiﬁcation families as follows: linear, SVM, boosting, and decision tree. These
sub-features in FD are mutually connected with the relation ‘one of’, meaning
that one of the classiﬁcation families cooperates in composing the classiﬁcation
pipelines. The hyperparameter optimization is speciﬁc, because it has only one
task, i.e., modeling the hyperparameter setting that is dependent on the selected
feature selection algorithm, as well as the selected classiﬁcation method.
The lowest level in an FD tree represents a framework of tools and hyperpa-
rameter settings. This consists of feature selection/scaling algorithms, classiﬁca-
tion methods, and optimized hyperparameter settings. All framework elements
are selected with regard to the corresponding model families. For instance, a
feature selection algorithm can be modeled using four diﬀerent feature selection
algorithms. Moreover, the rescaling and normalization procedures are available
for the feature scaling. At the moment, one classiﬁer method is modeled for each
classiﬁcation family, except a decision tree supporting even three classiﬁcation
methods. Obviously, in the future, we plan to increase the number of classiﬁ-
cation methods. As already explained, the hyperparameters’ setting is model
dependent.
In the remainder of the paper, the algorithm for composing the classiﬁcation
pipeline is presented in detail. The section is concluded with illustrating the
model evaluation.
3.1
Composing the Classiﬁcation Pipeline
The problem can be deﬁned informally as follows: The task is to compose
the classiﬁcation pipeline from tools incorporated into a framework, where the
pipeline consists of feature selection and feature scaling algorithms, classiﬁcation
methods, and optimal setting of hyperparameters, controlling the algorithms
and/or methods, such that the maximum classiﬁcation accuracy is achieved.
The problem is deﬁned as an optimization and solved by the particle swarm
optimization (PSO) [11]. Although it can be solved with the other stochastic
population-based nature-inspired algorithms as well, the PSO was preferred due
to its simplicity.

288
I. Fister et al.
3.1.1
Particle Swarm Optimization PSO is a member of the SI-based
algorithm family that was developed by Eberhart and Kennedy in 1995 [11].
It is inspired by the social behavior of bird ﬂocking and ﬁsh schooling [9,17].
This algorithm works with a swarm (i.e., population) of particles representing
candidate solutions x(t)
i
of the problem to be solved. The particles ﬂy virtually
through the problem space and are attracted by more promising regions. When
the particles are located in the vicinity of these regions, they are rewarded with
the better values of ﬁtness function by the algorithm.
The PSO algorithm exploits usage of additional memory, where the particle’s
personal best p(t)
i , as well as the swarm’s global best g(t) locations in the search
space are saved. In each time step t (i.e., generation), all particles change their
velocities v(t)
i
toward its personal and global best locations according to the
following mathematical formula:
v(t+1)
i
= v(t)
i
+ C1 · rand(0, 1) ·

g(t) −x(t)
i

+ C2 · rand(0, 1) ·

p(t)
i
−x(t)
i

,
x(t+1)
i
= x(t)
i
+ v(t)
i ,
(1)
where C1 and C2 present learning rates typically initialized to 2, and rand(0, 1)
is a random value drawn from uniform distribution in the interval [0, 1].
The pseudo-code of the original PSO is illustrated in Algorithm 1, from
which it can be seen that the PSO is distinguished from the classical EAs by
four specialties:
• does not have survivor selection,
• does not have parent selection,
• does not have crossover operator, and
Algorithm 1 The original PSO algorithm
1: procedure ParticleSwarmOptimization
2:
t ←0;
3:
P (t) ←Initialize;
▷initialization of population
4:
while not TerminationConditionMeet do
5:
for all x(t)
i
∈P (t) do
6:
f (t)
i
= Evaluate(x(t)
i );
▷evaluation of candidate solution
7:
if f (t)
i
≤f (t)
besti then
8:
p(t)
i
= x(t)
i ; f (t)
besti = f (t)
i
;
9:
end if
▷preserve the local best solution
10:
if f (t)
i
≤f (t)
best then
11:
g(t) = x(t)
i ; f (t)
best = f (t)
i
;
12:
end if
▷preserve the global best solution
13:
x(t)
i
= Move(x(t)
i );
▷move the candidate w.r.t. Eq. (1)
14:
end for
15:
t = t + 1;
16:
end while
17: end procedure

Continuous Optimizers for Automatic Design and Evaluation
289
• the mutation operator is replaced by the move operator changing each element
of particle x(t)
i
with probability of mutation pm = 1.0.
Let us mention that the selection is implemented in the PSO implicitly, i.e., by
improving the personal best solution permanently. However, when this improving
is not possible anymore, the algorithm gets stuck in the local optima.
In what follows, the necessary modiﬁcations to the PSO algorithm are
described in order to prepare it for composing the classiﬁcation pipelines. The
section is concluded with a discussion about the classiﬁcation pipeline evaluation.
3.1.2
Representation of Individuals In the modiﬁed PSO algorithm, indi-
viduals are represented by ﬂoating-point vectors as follows:
x(t)
i
= {
x(t)
i,1

FeatureSelection
,
x(t)
i,2

FeatureScaling
,
x(t)
i,3

Classiﬁcation
, x(t)
i,4, . . . , x(t)
i,k, x(t)
i,k+1, . . . , x(t)
i,D



HyperParameters
},
(2)
where each element of the individual x(t)
i,j is mapped to the attribute from the
corresponding feature sets according to genotype–phenotype mapping illustrated
in Table 1. The table illustrates a mapping of the elements of a vector to the
features, and then into the attributes of the corresponding feature sets. Indeed,
the ﬁrst three elements of the ﬂoating-point vector are mapped to attributes, as
follows:
Table 1. Genotype–phenotype mapping
Vector elements
Feature name
Feature set
x(t)
i,1
FeatureSelection
{DE, PSO, GWO, BA}
x(t)
i,2
FeatureScaling
{No, Rescaling, Normalization}
x(t)
i,3
Classiﬁcation
{MLP, LS-SVM, ADA, RF, ERT, BAG}
x(t)
i,4, . . . , x(t)
i,k, x(t)
i,k+1, . . . , x(t)
i,D
HyperParameters
Model dependent
attr (t)
feat =

x(t)
i,j
|attr feat|

,
for j = 1, . . . , 3,
(3)
where attr (t)
feat denotes the speciﬁc attribute of the feature and the |attr feat| is
the size of feature set feat ∈{FeatureSelection, FeatureScaling, Classiﬁcation}.
Thus, the result of the division is truncated. The remaining elements of the
vector represent the absolute values of the corresponding hyperparameter laying
in the corresponding hyperparameter domain. Although the maximum number
of elements is ﬁxed according to the algorithm and method with the maximum
number of control hyperparameters, the number of eﬀective elements is variable
and depends on the selected tools. However, the hyperparameter domain depends
on the particular hyperparameter and must be determined experimentally.

290
I. Fister et al.
3.1.3
Hyperparameter Domains This subsection focuses on deﬁning the
hyperparameter domains. Actually, searching for the optimal setting of hyperpa-
rameters is a part of the NiaAML optimization process, and not by the separate
process as proposed by the AutoML community. Consequently, the NiaAML
performs HPO simultaneously with composing the classiﬁcation pipelines, and,
therefore, can be faster than the traditional AutoML.
In our study, we dealt with feature rescaling or normalization, four fea-
ture selection algorithms, and six classiﬁcation methods. The feature scaling
can either be selected (i.e., rescaling or normalization) or not selected. In both
cases, however, there are no special parameters for controlling these algorithms.
Among the feature selection algorithms, the following stochastic nature-inspired
population-based algorithms were proposed: Diﬀerential evolution (DE) [32],
PSO, gray wolf optimization (GWO) [23], and bat algorithm (BA) [35]. Obvi-
ously, even six methods, like multilayer perceptron (MLP) [27], least squares
support vector machine (LS-SVM) [33], AdaBoost (ADA) [28], random forest
(RF) [4], extremely andomized trees (ERT) [14], and BAGging (BAG) [3], can
be selected for classiﬁcation.
The hyperparameters of the proposed algorithms and methods, that were the
subject of HPO, are illustrated in Table 2.
Table 2. Hyperparameter domains
Alg.
Hyperparameter
Domain of values
DE
F, CR
F ∈[0.5, 0.9], CR ∈[0.0, 1.0]
PSO
C1, C2
C1 ∈[1.5, 2.5], C2 ∈[1.5, 2.5]
GWO
a
a ∈[0.0, 2.0]
BA
A, r, Qmin, Qmax
A ∈[0.5, 1.0], r ∈[0.0, 0.5], Qmin ∈[0.0, 1.0], Qmax ∈[1.0, 2.0],
MLP
act, sol, lr
act ∈{identity, logistic, tanh, relu}, sol ∈{lbfgs, sgd, adam}
lr ∈{constant, invscaling, adaptive}
LS-SVM
gamma, c
gamma ∈[0.1, 100], c ∈[0.1, 100]
ADA
n estim, alg
n estim = [10, 110], alg ∈{samme, samme.r}
RF
n estim
n estim ∈[10, 110]
ERT
n estim
n estim ∈[10, 110]
BAG
n estim
n estim ∈[10, 110]
Let us mention that the maximum number of hyperparameters occurring in
the selected algorithms and classiﬁcation methods is seven. As a result, the size
of the real-valued vector for composing the classiﬁcation pipeline is 10.
3.1.4
Fitness Function Evaluation In order to calculate the value of ﬁtness
function, tenfold cross-validation is used [1]. Thus, data are split into k = 10
equal parts using stratiﬁed sampling, and each of the k parts are classiﬁed by the
classiﬁcation pipeline. The main advantage of this approach is that all these so-
called training sets have 80% of data in common when k = 10. Consequently, the

Continuous Optimizers for Automatic Design and Evaluation
291
trade-oﬀbetween the bias and variance parts of the prediction error is minimized
due to reducing both as much as possible.
The performance of the classiﬁcation is estimated by accuracy (Accuracy), a
statistical measure that estimates the proportion of true predictions (i.e., true
positives and true negatives) among the total number of samples. Mathemati-
cally, this proportion can be expressed as:
Accuracy(M(xi)) =
TP + TN
TP + TN + FP + FN ,
(4)
where M(xi) denotes a model built on the basis of the customized classiﬁcation
pipeline xi, TP = True Positive, TN = True Negative, FP = False Positive,
and FN = False Negative.
The ﬁtness function is then deﬁned as follows:
f(xi) = 1 −1
k
k

i=1
Accuracy(M(xi)),
(5)
where Accuracy(M(xi)) is calculated according to Eq. (4). Let us emphasize
that the ﬁtness function evaluates the average performance of the classiﬁcation
methods obtained in 10-folds of training data. The task of the optimization is
to minimize the value of the ﬁtness function.
3.2
Model Evaluation
In this step, the quality of the composed classiﬁcation pipeline is evaluated, found
in the last step that consists of selected features, classiﬁer, and hyperparameters.
Typically, performance of the classiﬁcation method in data science is evaluated
by applying the evolving model to unseen test data. A standard 80–20% holdout
validation is used, where 80% of the data is used for training and the other
20% for testing. The classiﬁcation performance is then assessed according to the
accuracy as expressed in Eq. (4).
4
Experiments and Results
The purpose of our experimental work was to show that the algorithm for com-
posing the classiﬁcation pipeline ﬁnds comparable, if not better, results than
those tuned by the real data science experts. In line with this, three experiments
were performed using well-known datasets from the UCI machine learning repos-
itory [10]. Actually, three datasets from the life sciences domain were taken into
account. The characteristics of these datasets are depicted in Table 3.

292
I. Fister et al.
Table 3. Datasets used
Dataset name
Characteristics
Attribute characteristics
#instances
#features
Missing data
Yeast
Multivariate
Real
1,484
8
No
Ecoli
Multivariate
Real
336
8
No
Abalone
Multivariate
Categorical, integer, real
4,177
8
No
As can be seen from the table, all datasets are multivariate with 8 features.
As the number of features (denoted as #features in the table) is low, we can
expect that the feature selection algorithm cannot reduce this number a lot. On
the other hand, the number of instances (denoted as #instances in the table)
increases from 336 toward 4,177.
Although the NiaAML is prepared to tune the algorithm’s parameters as
well, the parameter values were ﬁxed in this preliminary study due to simplicity.
The parameter settings of the used algorithms are illustrated in Table 4.
Let us mention that the population size NP = 20 and the number of ﬁtness
function evaluations nFES = 400 are ﬁxed for all algorithms due to fairness by
mutual comparison. However, the parameter settings of the NiaAML algorithm
are the same as presented in Table 4 for the PSO, except the population size
of Np = 15 and the number of ﬁtness function evaluations nFES = 500. Inter-
estingly, the GWO algorithm is parameterless, and, therefore, does not demand
any parameter setting. The optimal setting of hyperparameters is the subject of
the HPO as presented in Table 2.
Table 4. Parameter setting
Algorithm
Acronym
Parameter 1
Parameter 2
Parameter 3
Parameter 4
Diﬀerential evolution
DE
F = 0.5
CR = 0.9
Gray wolf optimizer
GWO
Particle swarm algorithm
PSO
C1 = 2.0
C2 = 2.0
w = 0.7
v ∈[−4, 4]
Bat algorithm
BA
A = 0.5
r = 0.5
Q ∈[0.0, 2.0]
The results of the optimization were measured according to three statistical
measures: precision, Cohen’s kappa κ, and F1-score. The precision is deﬁned as
follows [1]:
precision(M(xi)) =
TP
TP + FP ,
(6)
where TP = True Positives, and FP = False Positives.
Metric for handling multivariate class problems is Cohen’s kappa deﬁned
as [6]:
κ(M(xi)) = n 	k
i=1 CM ii −	k
i=1 CM i.CM .i
n2 −	k
i=1 CM i.CM .i
,
(7)
where CM i. is the sum of the elements in the ith row of confusion matrix CM
and CM .i the sum of the elements in the ith columns of the CM [31]. The

Continuous Optimizers for Automatic Design and Evaluation
293
metric measures a level of agreement between two annotators on a multivariate
classiﬁcation problem and can occupy values in the interval [−1, 1]. Values below
0.8 mean that there is no agreement between annotators.
Finally, the F1-score based on precision and recall is expressed as follows:
F1(M(x)) = 2 · precision · recall
precision + recall ,
(8)
where recall =
TP
TP+FN , FN = False Negatives, and TP= True Positives.
It is worth mentioning that precision, recall, and F1 can be determined for the
binary classiﬁcation only, i.e., two prediction classes. However, using the sklearn’s
metrics library, one can compute a weighted average among many binary classi-
ﬁcation tasks and thus can use those measures for multiclass classiﬁcation.
Let us emphasize that we focus on the results of the composing of the clas-
siﬁcation pipeline in the preliminary study. This means that the results of the
model evaluation phase were left for the future. In the remainder of the paper,
the aforementioned experiments are described in detail.
4.1
The Results on the Yeast Dataset
The three top results of composing the classiﬁcation pipeline according to mea-
sure Accuracy on the Yeast dataset are illustrated in Table 7, from which it can
be seen that these were all obtained by applying the RF classiﬁcation method.
Fig. 3. Top three conﬁgurations found on the Yeast dataset
The numerical results of data, depicted in Fig. 3, are presented in Table 5,
where each of the best results is denoted by places from 1 to 3. In the table,
the values in square brackets denote the number of reduced features according
to the total set in the column ‘Feature selection’ and the optimized number of

294
I. Fister et al.
estimators used by the corresponding classiﬁcation method in the column ‘Clas-
siﬁcation method’. The sign ‘n/a’ (i.e., not applicable) in the column ‘Feature
scaling’ indicates that no feature scaling was applied. The column ‘Accuracy’
denotes the accuracy calculated according to the Eq. (4).
Table 5. Numerical results obtained on the Yeast dataset
Place Feature selection Feature scaling Classiﬁcation method Accuracy
1
[8/8]
n/a
Random forest [93]
0.6337
2
[8/8]
n/a
Random forest [98]
0.6329
3
[8/8]
n/a
Random forest [110]
0.6321
Interestingly, the best results were obtained using the PSO FS algorithm, no
feature scaling, and the RF classiﬁcation method. Although the FS procedure
was performed, it was found out on the basis of the top three conﬁgurations that
the best results are obtained by incorporating all the features. This indicates
that each feature plays a relevant role for interpretation of results and that
low redundancy is present among the features. RF, with 93 estimators, is the
best among all built models. We can see that accuracy performance lowers by
increasing model complexity.
The results according to the statistical measures, i.e., Accuracy, Precision,
Cohen’s kappa, and F1-score, are depicted in Table 6.
Table 6. Statistical measures obtained on the Yeast dataset
Statistical measure Statistical score
Accuracy
0.6465
Precision
0.6382
Cohen’s kappa, κ
0.5356
F1-score
0.6387
As can be seen from the Cohen’s kappa measure κ = 0.5356 in the table, the
value is higher than 0.5. This indicates moderate agreement between true and
prediction labels. Obtained Accuracy = 0.6465 is higher than in cross-validation
Accuracy = 0.6337.
4.2
The Results on the Ecoli Dataset
Three of the best results of the NiaAML algorithm for composing the classi-
ﬁer pipeline according to measure Accuracy obtained on the Ecoli dataset are
illustrated in Table 7. The meaning of the variables in the table is the same as

Continuous Optimizers for Automatic Design and Evaluation
295
discussed in the last experiment. Also, in this case, the RF classiﬁcation method
was the most preferable by the NiaAML, and the FS procedure has not shown to
be beneﬁcial. The feature scaling was not applied in any case, while the number
of estimators by classiﬁcation method was more than >100 for each instance.
Although the number of estimators are somehow similar to the Yeast dataset,
classiﬁcation accuracy is much higher for the Ecoli dataset.
Table 7. Numerical results obtained on the Ecoli dataset
Place Feature selection Feature scaling Classiﬁcation method Accuracy
1
[7/7]
n/a
Random forest [104]
0.8899
2
[7/7]
n/a
Random forest [101]
0.8882
3
[7/7]
n/a
Random forest [109]
0.8880
The graphical representation of the same results are presented in Fig. 4, from
which it can be seen that the second conﬁguration with the least number of
estimators provides the shortest standard deviation, and the third conﬁguration
with the highest number of estimators, the largest standard deviation. All three
conﬁgurations seize an approximately equal highest classiﬁcation accuracy score,
which is set at 0.9697. We can conclude that using an arbitrary number of esti-
mators (unless too low), high classiﬁcation accuracy can be scored, but standard
deviation increases, due to a possible over-ﬁtting problem. It is desired to lower
the classiﬁcation method complexity maximally to avoid such problems.
Fig. 4. Top three conﬁgurations found on the Ecoli dataset
The results according to the four statistical measures are illustrated in
Table 8, from which it can be seen that Cohen’s kappa κ increases signiﬁcantly

296
I. Fister et al.
Table 8. Statistical measures obtained on the Ecoli dataset
Statistical measure Statistical score
Accuracy
0.9412
Precision
0.9373
Cohen’s kappa, κ
0.9017
F1-score
0.9318
compared to the Yeast dataset. This indicates very high agreement between
true and predictive classes, and might highlight the more predictive (correlative)
nature of the Ecoli dataset. Using the optimal classiﬁcation method conﬁgura-
tion, Accuracy = 0.9412 is improved drastically compared to the cross-validation
Accuracy = 0.8899.
4.3
The Results on the Abalone Dataset
The last experiment was conducted on the Abalone dataset. In line with this,
the results of the NiaAML for composing the classiﬁcation pipeline obtained
on this dataset are presented in Table 9, from which it can be seen that ERT
and bagging classiﬁcation methods proved to be the most beneﬁcial results.
Overall Accuracy is the lowest among the three datasets, reaching barely over
0.55, which might indicate the increased complexity (i.e., number of instances)
of the Abalone dataset. In our opinion, this is also the main reason why the RF
performed worse.
Table 9. Numerical results obtained on the Abalone dataset
Place
Feature selection
Feature scaling
Classiﬁcation method
Accuracy
1
[8/8]
n/a
Extremely randomized trees [110]
0.5650
2
[8/8]
n/a
Bagging [81]
0.5545
3
[8/8]
n/a
Bagging [83]
0.5542
The same results are presented graphically in Fig. 5. As can be seen from
the ﬁgure, the ﬁrst conﬁguration reaches the highest overall Accuracy. ERTs are
comprehensive classiﬁcation methods which perform well for complex datasets.
Second conﬁguration, i.e., Bagging [81], scores the lowest standard deviation
among them but produces two outliers, i.e., black spots signiﬁcantly higher and
lower than the boxplot.

Continuous Optimizers for Automatic Design and Evaluation
297
Fig. 5. Top three conﬁgurations found on the Abalone dataset
Finally, the results according to four statistical measures are depicted in
Table 10, from which it can be seen that Cohen’s kappa κ indicates fair agree-
ment only. Although the Accuracy = 0.5754 is improved, compared to cross-
validation Accuracy = 0.5650, one should consider the obtained predictive per-
formance. The Precision also scores the lowest value among all three datasets,
which indicates an increase of FP predictions.
Table 10. Statistical measures obtained on the Abalone dataset
Statistical measure
Statistical score
Accuracy
0.5754
Precision
0.5701
Cohen’s kappa, κ
0.3589
F1-score
0.5725

298
I. Fister et al.
4.4
Summary
In order to compare the quality of classiﬁcation pipelines, the best results
obtained on the various datasets are presented in Fig. 6. The following
conclusions can be summarized after analyzing the results: The Yeast and Ecoli
datasets are shorter (i.e., 1,484 and 336 instances), compared to the Abalone
dataset consisting of 4,177 instances. Therefore, the RF overcomes the results
of the other classiﬁcation methods by classifying the shorter datasets. However,
by increasing the number of instances, e.g., the Abalone dataset, more compre-
hensive methods such as ERT and Bagging emerge.
Fig. 6. The best classiﬁcation pipelines obtained on the three datasets
The results obtained by NiaAML are comparable or better than the other
domain experts, e.g., for the Yeast dataset authors [36] report Accuracy = 0.5792
on a so-called inﬁnite latent SVM classiﬁer. This is signiﬁcantly less than in our
case, where we reached Accuracy = 0.6465. For the Ecoli dataset, the following
accuracies were reported by [24]: Accuracy = 0.8214 for the J48 decision tree clas-
siﬁer, Accuracy = 0.8095 for the Ridor classiﬁer and Accuracy = 0.8125 for the
JRip classiﬁer. The authors in [30] for the best case report the mean Accuracy =
0.8880 by cross-validation. Using the NiaAML, we scored Accuracy = 0.9412
for evaluation, and Accuracy = 0.8899 by cross-validation. While the evalu-
ation is signiﬁcantly improved, cross-validation is comparable. Review of [18]
revealed following results for the Abalone dataset: Accuracy = 0.5422 for deci-
sion trees, Accuracy = 0.5478 for Na¨ıve Bayes, Accuracy = 0.5393 for k-nearest
neighbors, and Accuracy = 0.5456 for SVM. The proposed approach gives
Accuracy = 0.5754, which is at least comparable to the domain experts.

Continuous Optimizers for Automatic Design and Evaluation
299
5
Conclusions and Future Work
Recently, ML methods like classiﬁcation became useful tools in various sciences.
Unfortunately, using these methods is far from being easy. Typically, these meth-
ods are controlled by many hyperparameters, where the optimal setting depends
on the problem to be solved. Fortunately, the diﬀerent methods solving a par-
ticular step in the ML phase, like feature selection/scaling, classiﬁcation, and
HPO, can be composed into pipelines and can be executed one after another.
Therefore, a new discipline of the ML has emerged, i.e., AutoML, with the goal
to help the ordinary users by applying the ML methods. The AutoML is capable
of selecting the most appropriate ML methods, as well as ﬁnding their optimal
parameters. Normally, the algorithms for composing the ML methods into ML
pipelines are of deterministic nature.
In our study, we go a step further, and propose the stochastic NiaAML for
composing the classiﬁcation pipelines. Actually, the stochastic NiaAML is capa-
ble of: (1) performing automated feature selection and feature scaling to reduce
the complexity of a dataset, (2) classiﬁer selection, and (3) HPO to ﬁnd the
optimal conﬁguration of the classiﬁer. Classiﬁer conﬁgurations are tested using
cross-validation.
The proposed NiaAML was tested on three diﬀerent ML datasets: Yeast,
Ecoli, and Abalone. Although feature selection was applied to each dataset, it
was not found to be beneﬁcial due to the too low number of features. The solu-
tion thus might help non-technical users obtain good classiﬁcation performance.
It was found that NiaAML searches successfully for the optimal classiﬁcation
method and its conﬁguration. As a result, we can conclude that the obtained
results are comparable to those proposed by domain experts.
In future, we would like to implement the NiaAML framework for detec-
tion and accounting the imbalanced datasets. Furthermore, constrained feature
selection might be proposed, where a user could specify the maximal number
of features to be incorporated into the classiﬁer. Nevertheless, a Web graphical
user interface and automated visualization framework might be desired as well.
References
1. Aggarwal Charu C (2014) Data classiﬁcation: algorithms and applications. Chap-
man and Hall/CRC, Chapman & Hall/CRC data mining and knowledge discovery
series
2. Bishop Christopher M (2007) Pattern recognition and machine learning, 5th edn.
Springer, Information Science and Statistics
3. Breiman L (1996) Bagging predictors. Mach Learn 24(2):123–140
4. Breiman L (2001) Random forests. Mach Learn 45(1):5–32
5. Cleveland William S (2014) Data science: an action plan for expanding the tech-
nical areas of the ﬁeld of statistics. Stat Anal Data Mining 7:414–417
6. Cohen J (1960) A coeﬃcient of agreement for nominal scales. Educ Psychol Mea-
sure 20(1):37–46

300
I. Fister et al.
7. Costa VO, Rodrigues CR (2018) Hierarchical ant colony for simultaneous classiﬁer
selection and hyperparameter optimization. In: 2018 IEEE congress on evolution-
ary computation (CEC). IEEE, pp 1–8
8. de S´a AGC, Pinto WJGS, Oliveira LOVB, Pappa GL (2017) RECIPE: a grammar-
based framework for automatically evolving classiﬁcation pipelines. In: European
conference on genetic programming. Springer, pp 246–261
9. Dey N (2017) Advancements in applied metaheuristic computing. IGI Global
10. Dua D, GraﬀC (2017) UCI machine learning repository
11. Eberhart R, Kennedy J (1995) Particle swarm optimization. In: Proceedings of
ICNN ’95—international conference on neural networks, vol 4, pp 1942–1948
12. Eiben AE, James E (2015) Introduction to evolutionary computing, 2nd edn.
Springer Publishing Company, Incorporated, Smith
13. Fister I Jr, Yang X-S, Fister I, Brest J, Fister D (2013) A brief review of nature-
inspired algorithms for optimization. Elektrotehniˇski vestnik 80(3):116–122
14. Geurts P, Ernst D, Wehenkel L (2006) Extremely randomized trees. Mach Learn
63(1):3–42
15. Gijsbers P (2018) Automatic construction of machine learning pipelines. Master’s
thesis, Eindhoven University of Technology
16. Gupta N, Khosravy M, Patel N, Senjyu T (2018) A bi-level evolutionary optimiza-
tion for coordinated transmission expansion planning. IEEE Access 6:48455–48477
17. Gupta N, Khosravy M, Patel N, Sethi I (2018) Evolutionary optimization based
on biological evolution in plants. Proc Comput Sci 126:146–155
18. Herranz J, Matwin S, Nin J, Torra V (2010) Classifying data from protected sta-
tistical datasets. Comput Sec 29(8):875–890
19. Holzinger A, Dehmer M, Jurisica I (2014) Knowledge discovery and interactive data
mining in bioinformatics—state-of-the-art, future challenges and research direc-
tions. BMC Bioinf 15(6):I1
20. Hutter F, KotthoﬀL, Vanschoren J (eds) (2019) Automatic machine learning:
methods, systems, challenges. Series on challenges in machine learning. Springer
21. Kang KC, Cohen SG, Hess JA, Novak WE, Peterson AS (1990) Feature-oriented
domain analysis (FODA) feasibility study. Technical report CMU/SEI-90-TR-021,
Software Engineering Institute, Carnegie Mellon University, Pittsburgh, PA
22. Koza John R (1992) Genetic programming: on the programming of computers by
means of natural selection. MIT Press, Cambridge, MA, USA
23. Mirjalili S, Mirjalili SM, Lewis A (2014) Grey wolf optimizer. Adv Eng Softw
69:46–61
24. Mohamed WNHW, Salleh MNM, Omar AH (2012) A comparative study of reduced
error pruning method in decision tree algorithms. In: 2012 IEEE international
conference on control system, computing and engineering. IEEE, pp 392–397
25. Olson RS, Bartley N, Urbanowicz RJ, Moore JH (2016) Evaluation of a tree-
based pipeline optimization tool for automating data science. In: Proceedings of
the genetic and evolutionary computation conference 2016, GECCO 2016. ACM,
New York, NY, pp 485–492
26. Olson RS, Moore JH (2016) TPOT: a tree-based pipeline optimization tool for
automating machine learning. In: Workshop on automatic machine learning, pp
66–74
27. Rosenblatt F (1961) Principles of neurodynamics. Perceptrons and the theory of
brain mechanisms. Cornell Aeronautical Lab Inc, Buﬀalo, NY
28. Schapire RE (1999) A brief introduction to boosting. In: Proceedings of the 16th
international joint conference on artiﬁcial intelligence, IJCAI ’99, vol 2. Morgan
Kaufmann Publishers Inc, San Francisco, CA, pp 1401–1406

Continuous Optimizers for Automatic Design and Evaluation
301
29. Schuster Stephan C (2007) Next-generation sequencing transforms today’s biology.
Nat Methods 5(1):16
30. Soda P, Iannello G (2010) Decomposition methods and learning approaches for
imbalanced dataset: an experimental integration. In: 2010 20th international con-
ference on pattern recognition. IEEE, pp 3117–3120
31. Stehman Stephen V (1997) Selecting and interpreting measures of thematic clas-
siﬁcation accuracy. Remote Sens Environ 62(1):77–89
32. Storn R, Price K (1997) Diﬀerential evolution—a simple and eﬃcient heuristic for
global optimization over continuous spaces. J Glob Opt 11(4):341–359
33. Suykens JAK, Vandewalle J (1999) Least squares support vector machine classi-
ﬁers. Neural Process Lett 9(3):293–300
34. Xavier-J´unior JC, Freitas AA, Feitosa-Neto A, Ludermir TB (2018) A novel evolu-
tionary algorithm for automated machine learning focusing on classiﬁer ensembles.
In: 2018 7th Brazilian conference on intelligent systems (BRACIS). IEEE, pp 462–
467
35. Yang X-S (2010) A new metaheuristic bat-inspired algorithm. Springer Berlin Hei-
delberg, Berlin, Heidelberg, pp 65–74
36. Zhu J, Chen N, Xing EP (2011) Inﬁnite latent SVM for classiﬁcation and multi-task
learning. In: Advances in neural information processing systems, pp 1620–1628

Chapter 14
Evolutionary Artiﬁcial Neural Networks:
Comparative Study on State-of-the-Art
Optimizers
Neeraj Gupta1, Mahdi Khosravy2,3(&), Nilesh Patel1,
Saurabh Gupta4,5, and Gazal Varshney6
1 Department of Computer Science and Engineering, Oakland University,
Rochester, MI, USA
2 Media Integrated Communication Lab, Graduate School of Engineering,
Osaka University, Suita, Japan
mahdi.khosravy@ufjf.edu.br
3 Electrical Engineering Department, Federal University of Juiz de Fora,
Juiz de Fora, Brazil
4 Department of Advanced Engineering, John Deere India Pvt. Ltd., Pune, India
5 Research Scholar, Department of Computer Science, Banasthali Vidyapith,
Vanasthali, Rajasthan, India
6 University of Information Science and Technology, Ohrid, North Macedonia
1
Introduction
Today evolutionary optimizers (EOs) [1, 2] play an important role in real-life problems.
EOs are inspiration from the natural phenomena such as genetic algorithm (GA) [3, 4]
and PSO [5–10]. Apart from the application discussed in this chapter, EOs have a great
potential to be applied in a wide range of ﬁelds such as text feature detection [11], blind
component processing [12], noise cancelation [13], blind source separation [14–18],
data mining [19], image enhancement [20, 21], ECG processing [22–25], quality
assessment [26], information hiding [9], image segmentation [27], morphological ﬁl-
tering [28, 29], acoustic OFDM [30], telecommunications [31–57], power line com-
munications (PLC) [35], image adaptation [36], and fault detection system [37].
In this chapter, we provide the result of designed ANN trained by plant genetics-
inspired optimizer which is known as Mendelian evolutionary theory optimizer
(METO) [38, 39] in comparison with thirteen other state-of-the-art optimizers. These
algorithms are (1) binary hybrid GA (BHGA) [40], (2) biogeography-based opti-
mization (BBO) [41], (3) invasive weed optimization (IWO) [42], (4) shufﬂed frog leap
algorithm (SFLA) [43], (5) teaching-learning-based optimization (TLBO) [44],
(6) cuckoo search (CS) [45], (7) novel bat algorithm (NBA) [46–48], (8) gravitational
search algorithm (GSA) [49], (9) covariance matrix adaptation evolution strategy
(CMAES) [50], (10) differential evolution (DE) [51], (11) ﬁreﬂy algorithm (FA) [52],
(12) social learning PSO (SLPSO) [53], and (13) real coded simulated annealing
(RSA) [54]. On these algorithms, one can ﬁnd huge literature that proves the efﬁciency
© Springer Nature Singapore Pte Ltd. 2020
M. Khosravy et al. (eds.), Frontier Applications of Nature Inspired Computation,
Springer Tracts in Nature-Inspired Computing,
https://doi.org/10.1007/978-981-15-2133-1_14

of these optimizers. We have selected two layers ANN: One is hidden, and another is
output layer as given in Fig. 1.
Hidden layer has 10 neurons, and output layer is softmax layer with six outputs.
This model is trained for 15 input samples. The data set under study is complex and
with different features. One can observe that dataset is highly disturbed to classify with
normal or machine learning techniques. Thus, it needs intelligent method that is METO
in our simulation. We trained ANN model 100 times, where each training is not
connected to each other. 100 times training gives us 100 trained models. Thus, we have
the distribution of the solutions from each optimizer. We statistically analyzed this
distribution by Kruskal–Wallis Test. The analysis is presented in this chapter to prove
that METO is statistically best among all optimizers.
2
Agriculture Machinery
The case of study for feature detection via application of neuro-evolutionary techniques
is prognostic condition evaluation as well as fault detection of agriculture machinery.
The tractor is the backbone of the agricultural industry. It is considered as a prime
mover. Tractors are classiﬁed as off road and agriculture machinery and are most
widely used for various other purposes in addition to agriculture. In India, tractor
industry is divided mainly into four main categories—less than 30 HP, 31 HP to
40 HP, 41 HP to 50 HP, and greater than 50 HP power. Since a tractor’s main function
is to operate as a prime mover and support the power requirements to operate the
various types of implements either from drawbar, 3-point hitch rear PTOs, or front
PTO. Most of the implements are draft implements and operated through hydraulic
system. Therefore, the most important part of a tractor is its hydraulic system.
To simply explain the hydraulic system of a tractor, it is an open center system
where the drivetrain acts as a sump. The oil is sucked into the hydraulic pump through
the hydraulic ﬁlter which then distributes it evenly to the steering unit and the rockshaft
unit (3-point hitch). This ﬁlter cleans the oil by blocking the impurities and debris
present in the oil. The output of the steering is the inlet of the brakes. Pump supplies
ﬂow to control valve, and control valve controls the rockshaft cylinder. In the ﬁeld, it is
very common that small particles easily contaminate hydraulic system. Filter is used to
separate out the impurities from the hydraulics. Filter has pre-deﬁned efﬁciency for
ﬁltration. 100% ﬁltration is not possible. Although the ﬁlter is able to keep them out
initially, once it is blocked, the bypass opens to avoid any pressure burst of the system
Fig. 1. ANN structure used in this comparative study
Evolutionary Artiﬁcial Neural Networks: Comparative Study
303

and the particles ﬁnd their way into the hydraulic system and get accumulated in the
pumps, valves, drivetrain, and gears to degrade performance.
The objective of the problem is to diagnose the choking stages using smart phones
and facilitate a timely change of the ﬁlter by characterizing the noise emitted by the
pump at different levels of ﬁlter choking. The inlet and outlet pressures, oil ﬂow, engine
RPM, and noise from pump will be collected and analyzed to identify the relation
between ﬁlter choking and pump noise. The output of this analysis will help to notify
the operator about the requirement of the ﬁlter change.
2.1
System Context
Figure 2 shows the system context for monitoring and tracking tractor performance.
Current system is capable to capture the real-time health and performance data of
tractor aggregates and transmit it on cellular network using cellular modem. Using of
sensors increases complexity of system. It is not feasible to put the sensors for con-
dition monitoring of all the aggregates. It is proposed to use cellphone to capture noise
of the aggregates on tractor and use algorithm to detect the current health of the
aggregates using available hardware on the tractor and transmit it on net to owner and
dealer to avoid any severe damage and down of machine.
2.2
Scenarios
The operational scenarios of the problem are as follows:
1. Manipulation of onboard vehicle data or code: Remotely manipulate code onboard
vehicle to cause unexpected vehicle behavior (e.g., applies brakes, kills engine, and
depresses accelerator).
2. Service technician accessibility: The service technician has access to the onboard
telematics system through the OBD-II port which is a mandated interface. A mali-
cious agent playing the role of the service technician is a security threat on the
system.
3. OEM software introduction: Regular updates are sent by the manufacturers to
improve or enhance the products and services provided by telematics systems.
The use scenarios are as follows:
1. Insurance: Pay-for-usage insurance policies allow drivers to only pay for as much
insurance as they need based on their driving usage. Insurance companies subscribe
to the driver’s telematics information to monitor time and hours of usage, driving
location, speeds, etc.
2. OEM: Tractor manufactures use tractor data to inform service needs, new software
updates, new features and offers, etc.
304
N. Gupta et al.

2.3
Stakeholders and Needs
Figure 3 shows the stake holder [55] description of all the major stakeholders with their
needs. The primary stakeholders are operator, tractor manufacturer, and service
technicians.
Fig. 2. Average convergence curve of all algorithms for optimizing the ANN
Evolutionary Artiﬁcial Neural Networks: Comparative Study
305

Other stakeholders act as a secondary stakeholder. Reduced scope mapped to
system requirements is shown in Fig. 4.
A tractor is an engineering vehicle speciﬁcally designed to deliver a high tractive
effort (or torque) at slow speeds, for the purposes of pulling a trailer or machinery used
in agriculture or construction. Most widely, the term is used to describe a farm tractor
Fig. 3. Stakeholder analysis
Fig. 4. Stakeholder analysis—reduced scope
306
N. Gupta et al.

that provides the power and traction to mechanize agricultural tasks, especially (and
originally) primary and secondary tillage, with the change in farming practices a great
variety of automation. Agricultural implements may be towed behind or mounted on
the tractor, and the tractor also acts as a prime mover if the implement is required
hydraulic or mechanical power. This implement is operated using the hydraulic power
from the highly complex hydraulic system of the tractor.
Since a tractor’s main function utilizes the hydraulic system, it is essential to keep
this system in prime functioning condition. However, due to the severity of the
operating conditions, this is not natural to done automatically and is done by the
operator. As there is human interaction involved, the accuracy or reliability of this
maintenance is not efﬁcient. Keeping this in mind, the project was established to
support fault diagnostic proﬁciency of operator.
3
Convergence Curve
As we have discussed before that we have distribution of the solution, 0020, we are
presenting average convergence curve to show the performance of the proposed trainer.
This curve in Fig. 5 shows the performance of the above-described algorithms. Here,
dark and highlighted blue line is for METO, which shows that how fast METO con-
verges to the global optimal solution compared to other optimizers.
In this ﬁgure, x-axis showing the number of ANN trained to achieve optimal
solution. Here, we have trained 100,000 ANN through all optimizers to get global
optimal solution. Vertical axis is for the value of objective function which we are
Fig. 5. Average convergence curve of all algorithms for optimizing the ANN
Evolutionary Artiﬁcial Neural Networks: Comparative Study
307

interested to minimize during the training the ANN. Associated result table is given in
Table 1, where performance of trainers is shown in eight measures. First is B, which is
the best trained ANN achieved by the particular trainer. Second is M, which is the
mean of the distribution achieved by each trainer from 100 individual runs. Third is
Me, which is the median of the solution distribution. Fourth and ﬁfth are Mo and MC,
which are, respectively, mode and number of time Mo is coming from all solution
attempts. Sixth is std, which is the standard deviation of the distribution and associated
with M. Seventh is C; this is consistency of the trainer, which reveals that how many
times the trainer achieves the solution below the threshold. Considered threshold in our
simulation is 2.06E−03 which is the mean of METO. The last attribute is W; it is the
worst performance of the trainer.
Fig. 6. ROC curve for PGO trained ANN
308
N. Gupta et al.

From the table, we can observe that METO is highly consistent and best trainer for
developing intelligent and efﬁcient ANN. Also, the validation accuracy achieved by
this is more than 70%. Associated ROC curve is shown in Fig. 6. Four ROCs are
shown in this ﬁgure. First is training ROC which shows that METO trainer is very
efﬁcient to train for Class 1 where it gives degraded performance for Class 5. Same can
be observed in validation ROC, test ROC, and all ROC curves.
Matrix of true class and predicted class is given in Fig. 7.
Fig. 7. Matrix for showing the distribution of output in true class and predicted class
Evolutionary Artiﬁcial Neural Networks: Comparative Study
309

The above matrix in Fig. 7 is supported by the matrix as given in Figs. 8 and 9.
In this, we can see positive predictive value for all classes, where each class belongs
to one fault condition of the monitoring system. We can observe that it is very high for
normal operating condition of the hydraulic pump. Based on this, we can sort the
performance of the monitoring system from high to low positive prediction capability
as Class 1, Class 6, Class 3, Class 4, Class 2, and Class 6. Also, matrix in Fig. 7 shows
the analysis in more detail.
Trained model is giving 90% true positive results for Class 1, where it is 79% for
Class 6, and so on for other classes.
Table 1. Comparative results of ANN for various training algorithms
Trainer
B
M
Me
Mo
MC
std
C
(%)
W
PGO
1.11E
−16
2.06E
−03
1.05E
−10
1.11E
−16
2
3.66E
−03
74
1.49E
−02
BHGA
6.55E
−02
1.33E
−017
1.29E
−01
6.55E
−02
1
3.08E
−02
0
2.19E
−01
BBO
1.45E
−01
2.60E
−01
2.41E
−01
1.45E
−01
1
6.97E
−02
0
4.17E
−01
IWO
3.15E
−01
4.16E
−01
4.18E
−01
3.15E
−01
1
4.38E
−02
0
4.95E
−01
SFLA
2.49E
−01
3.45E
−01
3.44E
−01
2.49E
−01
1
4.58E
−02
0
4.39E
−01
TLBO
1.01E
−01
3.41E
−01
3.70E
−01
1.01E
−01
1
1.06E
−01
0
4.84E
−01
CS
3.57E
−01
4.46E
−01
4.51E
−01
3.57E
−01
1
2.32E
−02
0
4.82E
−01
NBA
1.59E
−01
4.72E
−01
4.77E
−01
1.59E
−01
1
8.99E
−02
0
5.99E
−01
GSA
6.51E
−02
1.12E
−01
1.07E
−01
1.01E
−01
3
2.41E
−02
0
1.61E
−01
CMAES
9.50E
−02
1.59E
−01
1.49E
−01
9.50E
−02
1
4.67E
−02
0
2.64E
−01
DE
2.72E
−01
3.32E
−01
3.34E
−01
2.72E
−01
1
2.11E
−02
0
3.72E
−01
FA
6.98E
−01
7.73E
−01
7.76E
−01
6.98E
−01
1
2.61E
−02
0
8.13E
−01
SLPSO
5.54E
−01
6.40E
−01
6.41E
−01
5.54E
−01
1
3.32E
−02
0
7.08E
−01
RSA
2.32E
−01
3.15E
−01
3.07E
−01
2.32E
−01
1
4.40E
−02
0
4.19E
−01
310
N. Gupta et al.

Statistically speaking, the ANN-MLP algorithm escapes the local extremes in the
datasets with achieving the best classiﬁcation accuracy, thus achieving minimum
MSLE. According to the METO algorithm, it explores the search space and leads to
ﬁnd the diverse ANN structures during the optimization. In addition, the Flipper
operator randomly spreads the points in search space. This is an important mechanism
to avoid the local extremes. From the literature, we can see that ANN needs an
algorithm that should avoid local minima. Here, the results of METO show high
exploration mechanism; it avoids local minima for global solution. It is due to the
changing solution in every evolution epoch for every training dataset. Based on the
statistical results, METO appears as the very effective trainer.
Fig. 8. Result of trained ANN for giving positive and false alarm
Evolutionary Artiﬁcial Neural Networks: Comparative Study
311

4
Kruskal–Wallis Statistical Analysis of the Results
We tested distributions of all training algorithms for their signiﬁcant difference using
Kruskal–Wallis one-way ANOVA rank test [56, 57]. It is an extended version of the
Mann–Whitney test. For the test, we consider the null hypothesis, H0, as “distribution
of METO is same as the distribution of other training algorithm,” where the distri-
butions of all training algorithms are coming from independent experiments. It dis-
criminates the distribution of all trainer based on the calculated “critical chi-square
value f
X 2 and Kruskal–Wallis test (KWT) value”. If the value of KWT is smaller than
the f
X2, the H0 cannot be rejected. Thus, to reject the H0, KWT value should be greater
than f
X 2. For this procedure, p-value is utilized to test the signiﬁcant difference between
distributions with 1% signiﬁcance level.
Table 2 provides the additional test results. ANOVA results for each function have
six attributes. Sr represents the source of the variability. Based on the different types of
variability here, three types of sources are given. First is Cl, representing groups; it is
due to the variability that exists due to the differences among the distribution means.
Second is e, which is an error, and the variability exists due to the differences between
the dataset within the group and the group mean. This is also called variability within
the group.
Fig. 9. Result of trained ANN for giving true positive and false negative rate
312
N. Gupta et al.

The third is the T, total, which represents total variability. SS is the sum of square
due to each Sr, df is the degree of freedom, and df associated with each Sr is calcu-
lated. For Cl, df is the degree of freedom (DoF) between the distributions/groups and
calculated as df = K −1; here K = 13 the number of trainer. For e, the df is the DoF
within the distribution groups and deﬁned as df = N −K; here N = 650, the number of
observations. The total DoF is calculated as df = N −1, which is equal to
(N −K) + (K −1).
Next attribute, MS, is the mean squares for each source and calculated as SS
df .
F-statistics is represented for the Sr and the ratio of the MS. The last column of this
table is p-value, which is the probability that the f
X2 can take a value larger than the
computed test-statistic value. ANOVA1 derives this probability from the cdf of
F-distribution. In the ANOVA table, f
X 2 and p-value are important, where other above-
described parameters value support to calculate them.
Moreover, to show the signiﬁcant difference between the distributions of solutions
achieved by each trainer, notched box plot is shown in Figs. 7 and 8. The notched box
is associated with an optimizer which has two sections divided by a centerline, and this
is the median. Two end edges of each notched box, the bottom and the top, indicate the
q1 = 25th and q3 = 75th percentiles, respectively. Outliers O in the distribution are
plotted individually using the “+” symbol. In Figs. 7 and 8, we can observe that METO
results are free of any outlier. Also, there is a signiﬁcant difference between the METO
and other optimizers. We can observe that notches of METO box plot do not overlap
the others, which shows that true medians do differ with others with 95% conﬁdence
level. Beyond the whiskers length, the ith solution in the solution distribution is dis-
played as outliers Oi: If Oi [ q3 þ w q3  q1
ð
Þ or Oi [ q1 þ w q3  q1
ð
Þ, where w is
the maximum whisker length. Horizontal axis numbers in each subplot represent
training algorithms number, where from 1 to 13 they are METO, BHGA, BBO, IWO,
DE, CMAES, SFLA, FA, TLBO, CUCKOO, NBA, GSA, and SLPSO, respectively.
Table 2. Kruskal–Wallis ANOVA1 table
Sr
CI
e
T
SS
2.6 E+7
2.29 E+6
2.29 E+7
df
1.20 E+l
6.37 E+2
6.49 E+2
MS
1.72 E+6
3.60 E+3
–
eX 2
5.84 E+2
–
–
prob > eX 2
2.77 E−117
–
–
Evolutionary Artiﬁcial Neural Networks: Comparative Study
313

5
Conclusion
It is worth discussing the performance of the proposed trainer for ANN over others.
Generally speaking, that Epimutation operation maintains the diversity in the popula-
tion species. This is an additional mechanism along with Flipper operation to promote
the exploitation. However, in the later phase of the search strategy, it diverges the
solution; thus, F2 generation offspring brings back the solution toward the best solution
and promotes exploitation of the solution. We have discussed this in Chapter 5 as well.
Moreover, selection of individual ANNs in the population to go in the next evo-
lution epoch is done based on elitism, where best ﬁtness-valued ANN is selected. Also
F1 generation offspring explores the area between two parents. Therefore, the com-
position of all operators in METO avoids local optima and provides the best solution by
smoothly balancing the exploration and exploitation. Half of the iteration is devoted to
exploration and the rest to exploitation.
According to this comprehensive study, METO provides remarkable results and is
highly recommended as ANN trainer to develop intelligent monitoring system.
For very large dataset and the number of features, METO is efﬁcient where low
feature and dataset could be solved by gradient-based training algorithms (GBTA) such
as back-propagation. METO training is slower than the GBTA but provides better
results. We have simulated the ANN using other swarm and evolutionary algorithms,
and in contrast, we found that METO is best of all. It avoids the extreme number of
local minima of the objective function and makes the other algorithms almost inef-
fective (Fig 10).
Fig. 10. Genotype representation of weights and transfer functions (TF)
314
N. Gupta et al.

Moreover, the accuracy of ANN of optimized weights and biases is considerably
high. Here, we also discuss the reason of poor performances of other training algo-
rithms. This is due to the low exploration capability, where METO outperforms by two
exploration mechanism one in Epimutation and another is Flipper.
References
1. Dey N (ed) (2017) Advancements in applied metaheuristic computing. IGI Global
2. Dey N, Ashour AS (2016) Antenna design and direction of arrival estimation in meta-
heuristic paradigm: a review. Int J Serv Sci Manag Eng Technol 7(3):1–18
3. Gupta N, Patel N, Tiwari BN, Khosravy M (2018) Genetic algorithm based on enhanced
selection and log-scaled mutation technique. In: Proceedings of the future technologies
conference, Springer, Cham, pp 730–748
4. Singh G, Gupta N, Khosravy M (2015) New crossover operators for real coded genetic
algorithm (RCGA). In: 2015 international conference on intelligent informatics and
biomedical sciences (ICIIBMS), IEEE, pp 135–140
5. Chatterjee S, Sarkar S, Hore S, Dey N, Ashour AS, Balas VE (2017) Particle swarm
optimization trained neural network for structural failure prediction of multistoried RC
buildings. Neural Comput Appl 28(8):2005–2016
6. Jagatheesan K, Anand B, Samanta S, Dey N, Ashour AS, Balas VE (2017) Particle swarm
optimisation-based parameters optimisation of PID controller for load frequency control of
multi-area reheat thermal power systems. Int J Adv Intell Paradig 9(5–6):464–489
7. Chatterjee S, Hore S, Dey N, Chakraborty S, Ashour AS (2017) Dengue fever classiﬁcation
using gene expression data: a PSO based artiﬁcial neural network approach. In: Proceedings
of the 5th international conference on frontiers in intelligent computing: theory and
applications, Springer, Singapore, pp 331–341
8. Jagatheesan K, Anand B, Dey N, Gaber T, Hassanien AE, Kim TH (2015) A design of PI
controller using stochastic particle swarm optimization in load frequency control of thermal
power systems. In: 2015 fourth international conference on information science and
industrial applications (ISI), IEEE, pp 25–32
9. Chakraborty S, Samanta S, Biswas D, Dey N, Chaudhuri SS (2013) Particle swarm
optimization based parameter optimization technique in medical information hiding. In:
2013 IEEE international conference on computational intelligence and computing research,
pp 1–6
10. Khosravy M, Gupta N, Patel N, Senjyu T, Duque CA (2020) Particle swarm optimization of
morphological ﬁlters for electrocardiogram baseline drift estimation. In: Dey N, Ashour AS,
Bhattacharyya S (eds) Applied nature-inspired computing: algorithms and case studies.
Springer, Singapore, pp 1–21
11. Gutierrez CE, Alsharif MR, Khosravy M, Yamashita K, Miyagi H, Villa R (2014) Main
large data set features detection by a linear predictor model. In: AIP conference proceedings,
vol 1618, no 1, pp 733–737
12. Khosravy M, Gupta N, Marina N, Asharif MR, Asharif F, Sethi IK (2015) Blind components
processing a novel approach to array signal processing: a research orientation. In: 2015
international conference on intelligent informatics and biomedical sciences (ICIIBMS),
IEEE, pp 20–26
13. Khosravy M, Asharif MR, Sedaaghi MH (2008) Medical image noise suppression: using
mediated morphology. IEICE Tech Rep, IEICE, pp 265–270
Evolutionary Artiﬁcial Neural Networks: Comparative Study
315

14. Khosravy M, Asharif MR, Yamashita K (2009) A PDF-matched short-term linear
predictability approach to blind source separation. Int J Innov Comput Inform Control
(IJICIC) 5(11):3677–3690
15. Khosravy M, Alsharif MR, Yamashita K (2009) A PDF-matched modiﬁcation to Stone’s
measure of predictability for blind source separation. In: International symposium on neural
networks, Springer, Berlin, Heidelberg, pp 219–228
16. Khosravy M, Asharif MR, Yamashita K (2011) A theoretical discussion on the foundation of
Stone’s blind source separation. SIViP 5(3):379–388
17. Khosravy M, Asharif M, Yamashita K (2008) A probabilistic short-length linear
predictability approach to blind source separation. In: 23rd international technical conference
on circuits/systems, computers and communications (ITC-CSCC 2008), Yamaguchi, Japan,
pp 381–384
18. Khosravy M, Kakazu S, Alsharif MR, Yamashita K (2010) Multiuser data separation for
short message service using ICA (信号処理). 電子情報通信学会技術研究報告. SIP, 信号
処理: IEICE technical report, 109(435), pp 113–117
19. Gutierrez CE, Alsharif MR, Yamashita K, Khosravy M (2014) A tweets mining approach to
detection of critical events characteristics using random forest. Int J Next-Gener Comput 5
(2):167–176
20. Ashour AS, Samanta S, Dey N, Kausar N, Abdessalemkaraa WB, Hassanien AE (2015)
Computed tomography image enhancement using cuckoo search: a log transform based
approach. J Signal Inform Process 6(03):244
21. Khosravy M, Gupta N, Marina N, Sethi IK, Asharif MR (2017) Brain action inspired
morphological image enhancement. Nature-inspired computing and optimization. Springer,
Cham, pp 381–407
22. Dey N, Mukhopadhyay S, Das A, Chaudhuri SS (2012) Analysis of P-QRS-T components
modiﬁed by blind watermarking technique within the electrocardiogram signal for
authentication in wireless telecardiology using DWT. Int J Image Gr Signal Process 4(7):33
23. Dey N, Ashour AS, Shi F, Fong SJ, Sherratt RS (2017) Developing residential wireless
sensor networks for ECG healthcare monitoring. IEEE Trans Consum Electron 63(4):442–
449
24. Sedaaghi MH, Khosravi M (2003) Morphological ECG signal preprocessing with more
efﬁcient baseline drift removal. In: Proceedings of the 7th IASTED international conference,
ASC pp 205–209
25. Khosravi M, Sedaaghi MH (2004) Impulsive noise suppression of electrocardiogram signals
with mediated morphological ﬁlters. In: The 11th Iranian conference on biomedical
engineering, Tehran, Iran, pp 207–212
26. Khosravy M, Patel N, Gupta N, Sethi IK (2019) Image quality assessment: a review to full
reference indexes. Recent trends in communication, computing, and electronics. Springer,
Singapore, pp 279–288
27. Hore S, Chakraborty S, Chatterjee S, Dey N, Ashour AS, Van Chung L, Le DN (2016) An
integrated interactive technique for image segmentation using stack based seeded region
growing and thresholding. Int J Electric Comput Eng 6(6):2088–8708
28. Sedaaghi MH, Daj R, Khosravi M (2001) Mediated morphological ﬁlters. In: Proceedings
2001 international conference on image processing (Cat. No. 01CH37205), IEEE, vol 3,
pp 692–695
29. Khosravy M, Gupta N, Marina N, Sethi IK, Asharif MR (2017) Morphological ﬁlters: an
inspiration from natural geometrical erosion and dilation. Nature-inspired computing and
optimization. Springer, Cham, pp 349–379
316
N. Gupta et al.

30. Khosravy M, Punkoska N, Asharif F, Asharif MR (2014) Acoustic OFDM data embedding
by reversible Walsh-Hadamard transform. In: AIP conference proceedings, vol 1618, no. 1,
pp 720–723
31. Khosravy M, Alsharif MR, Guo B, Lin H, Yamashita K (2009) A robust and precise solution
to permutation indeterminacy and complex scaling ambiguity in BSS-based blind MIMO-
OFDM receiver. In: International conference on independent component analysis and signal
separation, Springer, Berlin, Heidelberg, pp 670–677
32. Asharif F, Tamaki S, Alsharif MR, Ryu HG (2013) Performance improvement of constant
modulus algorithm blind equalizer for 16 QAM modulation. Int Innov Comput Inform
Control 7(4):1377–1384
33. Khosravy M, Alsharif MR, Yamashita K (2009) An efﬁcient ICA based approach to
multiuser detection in MIMO OFDM systems. Multi-carrier systems and solutions 2009.
Springer, Dordrecht, pp 47–56
34. Khosravy M, Alsharif MR, Khosravi M, Yamashita K (2010) An optimum pre-ﬁlter for ICA
based multi-input multi-output OFDM system. In: 2010 2nd international conference on
education technology and computer, IEEE, vol 5, pp V5–129
35. Picorone AAM, Oliveira TR, Sampaio-Neto R, Khosravy M, Ribeiro MV (2020) Channel
characterization of low voltage electric power distribution networks for PLC applications
based on measurement campaign. Int J Electric Power Energy Syst 116:105554
36. Khosravy M, Gupta N, Marina N, Sethi IK, Asharif MR (2017) Perceptual adaptation of
image based on Chevreul-Mach bands visual phenomenon. IEEE Signal Process Lett 24
(5):594–598
37. Gupta S, Khosravy M, Gupta N, Darbari H (2019) In-ﬁeld failure assessment of tractor
hydraulic system operation via pseudospectrum of acoustic measurements. Turk J Electric
Eng Comput Sci 27(4):2718–2729
38. Gupta N, Khosravy M, Patel N, Sethi IK (2018) Evolutionary optimization based on
biological evolution in plants, vol 126. Procedia Computer Science, Elsevier pp 146–155
39. Gupta N, Khosravy M, Mahela OP, Patel N (2020) Plants biology inspired genetics
algorithm: superior efﬁciency to ﬁreﬂy optimizer. In: Applications of ﬁreﬂy algorithm and its
variants, from Springer tracts in nature-inspired computing (STNIC). Springer International
Publishing (in press)
40. Gupta N, Khosravy M, Patel N, Senjyu T (2018) A bi-level evolutionary optimization for
coordinated transmission expansion planning. IEEE Access 6:48455–48477
41. Simon D (2008) Biogeography-based optimization. IEEE Trans Evol Comput 12(6):702–
713
42. Xing B, Gao WJ (2014) Invasive weed optimization algorithm. Innovative computational
intelligence: a rough guide to 134 clever algorithms. Springer, Cham, pp 177–181
43. Eusuff M, Lansey K, Pasha F (2006) Shufﬂed frog-leaping algorithm: a memetic meta-
heuristic for discrete optimization. Eng Optim 38(2):129–154
44. Rao RV, Savsani VJ, Vakharia DP (2011) Teaching learning-based optimization: a novel
method for constrained mechanical design optimization problems. Comput-Aided Des 43
(3):303–315
45. Dey N, Samanta S, Yang XS, Das A, Chaudhuri SS (2013) Optimisation of scaling factors in
electrocardiogram signal watermarking using cuckoo search. Int J Bio-Inspir Comput 5
(5):315–326
46. Moraes CA, De Oliveira, EJ, Khosravy M, Oliveira LW, Honório LM, Pinto MF (2020) A
hybrid bat-inspired algorithm for power transmission expansion planning on a practical
Brazilian network. In: Dey N, Ashour AS, Bhattacharyya S (eds) Applied nature-inspired
computing: algorithms and case studies. Springer, Singapore, pp 71–95
Evolutionary Artiﬁcial Neural Networks: Comparative Study
317

47. Satapathy SC, Raja NSM, Rajinikanth V, Ashour AS, Dey N (2018) Multi-level image
thresholding using Otsu and chaotic bat algorithm. Neural Comput Appl 29(12):1285–1307
48. Rajinikanth V, Satapathy SC, Dey N, Fernandes SL, Manic KS (2019) Skin melanoma
assessment using kapur’s entropy and level set—a study with bat algorithm. In: Smart
intelligent computing and applications. Springer, Singapore, pp 193–202
49. Rashedi E, Nezamabadi-Pour H, Saryazdi S (2009) GSA: a gravitational search algorithm.
Inf Sci 179(13):2232–2248
50. Hansen N, Müller SD, Koumoutsakos P (2003) Reducing the time complexity of the
derandomized evolution strategy with covariance matrix adaptation (CMA-ES). Evol
Comput 11(1):1–18
51. Islam SM, Das S, Ghosh S, Roy S, Suganthan PN (2011) An adaptive differential evolution
algorithm with novel mutation and crossover strategies for global numerical optimization.
IEEE Trans Syst Man Cybern Part B (Cybern) 42(2):482–500
52. Dey N, Samanta S, Chakraborty S, Das A, Chaudhuri SS, Suri JS (2014) Fireﬂy algorithm
for optimization of scaling factors during embedding of manifold medical information: an
application in ophthalmology imaging. J Med Imaging Health Inform 4(3):384–394
53. Cheng R, Jin Y (2015) A social learning particle swarm optimization algorithm for scalable
optimization. Inf Sci 291:43–60
54. Hrstka O, Kučerová A, Lepš M, Zeman J (2003) A competitive comparison of different types
of evolutionary algorithms. Comput Struct 81(18–19):1979–1990
55. Händel P, Ohlsson M, Skog I, Ohlsson J, Movelo AB (2015) Determination of activity rate
of portable electronic equipment. U.S. Patent Application 14/377,689
56. Siegel S (1988) The Kruskal-Wallis one-way analysis of variance by ranks. Nonparametric
statistics for the behavioral sciences
57. Ostertagová E, Ostertag O, Kováč J (2014) Methodology and application of the Kruskal-
Wallis test. Appl Mech Mater 611:115–120
318
N. Gupta et al.

Chapter 15
Application of Recent Metaheuristic
Techniques for Optimizing Power Generation
Plants with Wind Energy
F. F. Panoeiro, G. Rebello, V. A. Cabral, C. A. Moraes,
I. C. da Silva Junior, L. W. Oliveira, and B. H. Dias(&)
Department of Electrical Energy, Federal University of Juiz de Fora (UFJF),
Juiz de Fora, Brazil
bruno.dias@ufjf.edu.br
1
Introduction
With the growth of energy consumption and generating costs, as well as an increasing
concern regarding environment preservation and global warming, novel alternative
energy sources, such as wind energy, have experienced exponential growth globally.
According to the Global Wind Energy Council (GWEC), 51.3 GW of installed
capacity was added in 2018, with an increase forecast of 300 GW in the next 5 years,
coming especially from emergent markets and from offshore wind farms [1].
The wind energy generation technology can be done in two manners: onshore and
offshore. Onshore wind farms present lower installation costs compared to offshore
wind farms, due to the simpler structures that sustain the wind turbines on the ground
and to the smaller size of the electrical collector system that reduces the ﬁnal cost of the
project. As for the offshore wind farms, besides not causing impact on people’s lives,
such as visual and noise pollution, they present lower payback times and larger efﬁ-
ciency, since the wind speeds are higher at the sea [2, 3].
In terms of generation reliability, the location of the wind turbines in a wind farm is
a factor of high relevance, since it directly impacts the extracted power and converted
energy, both associated with intermittent wind regimes. The process of transforming
the kinetic energy from the winds into electrical energy is not ideal. Besides the loss of
kinetic energy when interacting with the turbine, turbulences can be generated. Tur-
bines located downstream have their conversion potential reduced and experience an
effort increase in their supporting structures. This phenomenon is denominated wake
effect, and several studies have been proposed to model it, since it is an important factor
to be taken into account in the layout optimization process [4, 5].
The wind intermittency is the second factor to be considered, since it impacts on the
amount of energy that can be extracted. The two main aspects related to the wind are its
velocity and incidence direction [6, 7]. Several objective functions can be used to
obtain the optimal wind turbines layout, such as (i) maximizing power conversion;
(ii) maximizing net revenues; (iii) maximizing energy production; and/or (iv) mini-
mizing cost per extracted power [6, 8–10].
© Springer Nature Singapore Pte Ltd. 2020
M. Khosravy et al. (eds.), Frontier Applications of Nature Inspired Computation,
Springer Tracts in Nature-Inspired Computing,
https://doi.org/10.1007/978-981-15-2133-1_15

Several optimization algorithms have been used to solve the offshore wind turbine
optimal layout problem. The deployment of intelligent techniques such as metaheuristics
by evolutionary computation and swarm intelligence has been highlighted due to the
combinatory nature of the decision-making process, which involves continuous and
discrete variables. The standard genetic algorithm (GA) and variations are used in [8–13],
while in [6, 7, 14] other evolutionary algorithms (EA) were implemented to solve the
problem. The technique named artiﬁcial immune system (AIS) is used in [15]. In
[16–18], the particle swarm optimization (PSO) method is applied to solve the problem.
1.1
Contributions
Following this line of research, the present chapter aims at comparing the optimization
techniques bat algorithm (BA), grey wolf optimizer (GWO), and sine cosine algorithm
(SCA), applied to the offshore wind farm layout optimization (OWFLO) problem.
These techniques are able to perform global and local searching in an efﬁcient manner,
being applied in solving many nonlinear optimization problems, with non-convex
solution space and with large dimensions, such as the OWFLO problem. Also, a
resource named chaotic map is applied on the optimization techniques in order to
improve the local/global searching stages of the metaheuristics.
1.2
Organization
This chapter is organized in the following manner: Sect. 2 presents the problem for-
mulation, i.e., the objective function and problem constraints. The methodologies
employed, corresponding to the optimization algorithms, and the chaotic map resource
are described in Sect. 3. Section 4 presents the simulation results and analysis. The
ﬁnal observations and conclusion are presented in Sect. 5.
2
Problem Formulation
2.1
Wake Effect
In the OWFLO problem, it is necessary to consider the wind weakening effect. To do so,
the ‘wake effect’ model proposed in [5] is used. This is the effect that an upstream turbine
‘j’ causes on a downstream turbine ‘i’, or in other words the downstream output power is
reduced due to the variation in the mean wind speed caused by the upstream turbine [16].
The wind speed velocity at a downstream wind turbine ‘i’, with respect to the
variation caused by the upstream turbine ‘j’ (uði;jÞ), is obtained through Eqs. (1) and (2).
uði;jÞ ¼ u0 1 
2a
1 þ a
xij
ri
 
h
i2
0
B
@
1
C
A
2
64
3
75
ð1Þ
320
F. F. Panoeiro et al.

ri ¼ rj
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1  a
ð
Þ
1  2a
ð
Þ
s
ð2Þ
where
ri
effective radius of the rotor located downstream related to the upstream rotor rj
 
;
xij
distance between turbines i and j in the direction of wind incidence;
a
treadmill expansion rate;
a
axial induction factor;
u0
mean speed.
The axial induction factor is associated with the impulse coefﬁcient CT
ð
Þ, and the
treadmill expansion rate is associated with the soil roughness (z) and the height of the
wind turbine z0
ð Þ, obtained through Eqs. (3) and (4), respectively.
CT ¼ 4a 1  a
ð
Þ
ð3Þ
a ¼
0:5
ln
z
z0
 
ð4Þ
In the case of multiple interferences, i.e., when the downstream turbine is affected
by more than one upstream turbine, the resulting wind speed ures;i


is obtained by the
sum of kinetic energy weakening effects caused by the upstream turbines ‘j’, as shown
in Eq. (5).
ures;i ¼ u0 1 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
X
N
j ¼ 1
j 6¼ i
1  uij
u0

2
v
u
u
u
u
u
t
2
666664
3
777775
ð5Þ
2.2
General Formulation
The resolution of the OWFLO problem consists of determining, in the best possible
way, the location of the wind turbines by evaluating parameters that indicate the
performance of the conﬁguration. In this work, the total wind power production and the
annual costs of the project are used by the authors as the basis for evaluation.
The formulation of the nonlinear optimal layout problem is represented by the
Eqs. (6)–(9). In general, the objective function (OBF) of the optimal layout problem aims
at minimizing the project costs and maximizing the wind farm extracted power [16].
Application of Recent Metaheuristic Techniques for Optimizing
321

min OBF ¼
N
2
3 þ 1
3 e0:00174N2


P360
k¼0
PN
i¼1 fkPi ures;i


ð6Þ
s:t :
ures;i 2 <
ð7Þ
0  k  360
ð8Þ
0  fk  1
ð9Þ
N  Nmax
where
ures;i
resulting speed considering the wake effect (m/s);
N
rumber of wind turbines in the layout;
Nmax
maximum number of wind turbines;
fk
probability of a given wind incidence direction;
Pi
extracted power per wind turbine (kW);
k
wind incidence angle.
The power generated by each generating unit ‘i’ as a function of the resulting
velocity
ures;i


is obtained by Eq. (10), according to the characteristics of the wind
turbine used in the simulations [16].
Piðures;iÞ ¼
0
for
ures;i  2:3m/s
0:3u3
res;i
for
2:3\ ures;i  12:8m/s
630
for
12:8  ures;i  18m/s
0
for
ures;i [ 18m/s
8
>
>
<
>
>
:
ð10Þ
3
Metaheuristics
Metaheuristic algorithms are present in different applications in the most diverse
domains [19, 20]. The stochastic optimization methods known as metaheuristics are the
methodologies applied to solve the OWFLO problem. These techniques are applied in
several areas of knowledge, due to its ease of implementation, ﬂexibility in adapting to
different problems, and avoidance of derivative methods. In general, these techniques
are widely used in nonlinear problems, with non-convex solution space (with local
maximum and minimum values) and of large dimensions, such as the OWFLO problem.
Many metaheuristic implementations can be found in the literature. Genetic algo-
rithms (GA) reiterated the principles of Darwinian evolution for solving optimization
problems [21, 22]. GA as an optimization technique has gone through evolutions and
resulting in varieties. A recent variation implies Mendelian evolution on multispecies as
inspired from plants biology [23] incorporating the use of double-strand DNA for
evolution.
322
F. F. Panoeiro et al.

Currently, the metaheuristics are a widely popular approach to solve combinatorial
problems. This has been reﬂected in the application such as transmission expansion
planning (TEP), which is solved by a bi-level evolutionary optimization [24] and a
hybrid bat-inspired algorithm [25]. Particle swarm optimization (PSO) is used to
investigate a faster parameterization technique in the one-stage morphological ECG
baseline estimation [26] and also is used to do the load frequency control (LFC) of
multi-area
reheat
thermal
power
system
with
proportional–integral–derivative
(PID) controller [27]. PSO in combination with trained neural network is an approach
into structural failure prediction of multistoried RC buildings [28]. Chaotic bat algo-
rithm is applied in complex image processing such as automatic target recognition [29].
Due to this scenario of metaheuristic applications, in the specialized literature, there
are different classiﬁcations regarding metaheuristics techniques: (a) algorithm’s inspi-
ration (biology, physics, chemistry, among others); (b) number of solutions involved in
the optimization process (individuals or populations) [30]. Among these last two
classiﬁcations immediately cited, it can be observed recent applications of bio-inspired
techniques in swarm intelligence to solve the OWFLO problem. Such techniques are
based on the collective behavior of some species and, normally, have fewer
parameters/operators to be adjusted than evolutive techniques (crossover, mutation,
elitism, among others).
The population-based techniques normally use a set of random initial solutions that
are improved over the course of iterations (searching process). These techniques are
efﬁcient since the candidate solutions share information regarding the search space
allowing a more effective exploration toward the optimal solution of the problem. In the
solution searching process, each technique has its own characteristics/operators that
allow a search throughout the entire search space (global search) or around promising
regions (local search) [31].
In the present work, the authors chose to investigate different population-based
techniques, being two of them bio-inspired swarm intelligence algorithms and the other
one based on mathematical formulations. The goal is to determine the most efﬁcient
technique to solve the OWFLO problem. To do so, the bat algorithm, grey wolf
optimizer, and the sine cosine algorithm were implemented. Also, a feature called
chaotic map is applied on the optimization techniques to improve the global/local
search process of the methods.
3.1
Bat Algorithm—BA
The bat algorithm (BA), proposed in [32], is a bio-inspired optimization technique that
is based on the bats echolocation. Bats are able to locate obstacles and prey/food
through the emission and capture of ultrasonic waves, identifying distances by mea-
suring the wave time of return in the form of an echo. This biological capability is
named echolocation, being a resource widely used by bats and other animals with
nocturnal habits. Figure 1 depicts the pseudo-code of the bio-inspired BA.
In the bat algorithm, the number of bats ðnÞ, amplitude decay ðaÞ, and pulse
emission increase rates ðcÞ are deﬁned. The positions ðXiÞ and their individual
Application of Recent Metaheuristic Techniques for Optimizing
323

parameters such as velocity ðViÞ, frequency ðfriÞ, pulse emitting rate ðriÞ, and amplitude
ðAiÞ are randomly initialized respecting the solution region boundaries. The bats
positions represent the solutions to the problem under analysis that will be evaluated
and ranked according to the objective function value. The best position ðXÞ is asso-
ciated with the best bat in the population.
Then, the iterative process starts until a stopping criteria is met that can be, for
example, a maximum number of iterations or the stagnation of the best solution. For
each iteration (t), the frequencies ðfriÞ, velocities Vt þ 1
i


, and position Xt þ 1
i


of the
bat i are updated using Eqs. (11)–(13).
fri ¼ frmin þ frmax  frmin
ð
Þ  b
ð11Þ
Vt þ 1
i
¼ Vt
i þ Xt
i  Xt



 fri
ð12Þ
Xt þ 1
i
¼ Xt
i þ Vt þ 1
i
ð13Þ
Fig. 1. Algorithm 1—bat algorithm pseudo-code
324
F. F. Panoeiro et al.

where the bat’s (i) frequency is around the minimum ðfrminÞ and maximum ðfrmaxÞ
assigned values and ‘b’ is a random number in [0, 1].
After updating the bats positions, the local search stage begins, where the pulse
emitting rate ðriÞ is compared to a random value in [0, 1]. If the condition is met
ðrand [ riÞ, Eq. (14) is used to generate a new local solution for the bat Xt þ 1
i


, with
respect to the best bat
Xt



, mean pulse amplitude ðAtÞ, and ‘ɛ’, which is a random
vector in [−1, 1] of equivalent dimension to the bat.
Xt þ 1
i
¼ Xt
 þ e  mean At
ð
Þ
ð14Þ
In order to avoid violating the search space boundaries, the bat’s position is
checked with respect to the established minimum and maximum boundaries. The bats
are evaluated, and the global search stage begins. At this stage, two conditions are
analyzed: (1) If the numerical value of the objective function is smaller than at the
previous iteration f Xt þ 1
i


\f Xt
i




and (2) if the random number is smaller than the
pulse amplitude
rand\At
i


. In case the conditions are met, the bat’s
Xt þ 1
i


pulse
emitting rate
rt þ 1
i


and pulse amplitude At þ 1
i


are updated, according to Eqs. (15)
and (16).
rt þ 1
i
¼ r0
i  1  ect
½

ð15Þ
At þ 1
i
¼ a  At
i
ð16Þ
At last, the position of the best bat ðXÞ is updated. It is interesting to notice that
during the searching process, the pulse amplitude ðAiÞ decreases and the pulse emitting
rate ðriÞ increases, tending to the maximum initial value considered r0
i


. Therefore, at
the ﬁrst iterations the global search mechanism happens more frequently, but at the end
of the process the condition is hardly met due to the decrease in the pulse amplitude,
leading to a more thorough local search, since the mean amplitude tends to zero.
3.2
Grey Wolf Optimizer—GWO
The bio-inspired optimization technique named grey wolf optimizer (GWO) was
proposed in [31] and is based on the social hierarchy and hunting behavior of grey
wolves. The grey wolves’ hierarchy is divided in alphas, betas, deltas, and omegas,
respectively, in order of dominance. The alpha wolf, also named dominant wolf, is the
main responsible for making the decisions, e.g., time to hunt, places to sleep, and wake
up times. The beta wolf is the alpha’s right hand and helps in the decision-making
process. Also, the beta wolf is the main candidate to replace the alpha in the future. The
delta wolves belong to the categories of scouts, sentinels, elders, hunters, and care-
takers. At last, the omega wolves compose the lowest level of the hierarchy and play
the role of scapegoats. The wolves hunting strategy is divided into three steps:
(i) tracking, chasing, and approaching the prey; (ii) chasing and encircling until sta-
tionary situation; (iii) attacking the prey [31].
Application of Recent Metaheuristic Techniques for Optimizing
325

Figure 2 depicts the GWO pseudo-code.
In the GWO algorithm, the size of the wolves population is deﬁned ðgÞ, whose
positions ðXiÞ represent the number of solutions investigated within the solution region,
which are randomly initialized. The solutions are evaluated through the evaluation of
the objective function and the hierarchy of the wolf pack is deﬁned, where the three
best solutions of the set give rise to the alpha ðXaÞ, beta ðXbÞ, and delta ðXdÞ wolves,
respectively, in order of superiority.
After the initialization process, the iterative process of the algorithm starts, i.e., the
hunting step that will update the position of the wolves of the entire pack. To perform
such update, the search coefﬁcients ‘ A!’ and ‘C!’, deﬁned by Eqs. (17) and (18), are
calculated, where ‘ r!
1’ and ‘ r!
2’ are random vectors in [0, 1] and ‘at’ is the exploration
coefﬁcient that linearly decreases over the course of the (t) iterations.
A! ¼ at  r!
1  at
ð17Þ
C
! ¼ 2  r!
2
ð18Þ
These coefﬁcients provide the local or global search during the wolves update stage;
i.e., for A!\1, the wolves are forced to attack the prey (local search reﬁnement), and for
A![ 1, the wolves search for better preys in the search space (diverge from the best
Fig. 2. Algorithm 2—grey wolf optimizer pseudo-code
326
F. F. Panoeiro et al.

solution), according to Fig. 3a. As for the vector C, if C!\1 or C![ 1 attenuates or
increases the magnitude of the best solution in the searching mechanism, respectively.
Then, the wolves’ positions are updated. Equations (19) and (20) model the
encircling behavior during the hunting stage.
D
!t
i ¼ C!  X!t
p  X!t
i
			
			
ð19Þ
X!t þ 1
i
¼ X!t
p  A!  D
!t
i
ð20Þ
where ‘t’ depicts the current iteration at the convergence process, ‘Xt
p’ is the prey’s
position, and ‘Xt
i’ is the wolf’s position. It is supposed that the location of the prey is
(a)
(b)
Fig. 3. a Local/global search behavior. b Wolf’s estimate position for the GWO algorithm
Application of Recent Metaheuristic Techniques for Optimizing
327

not known and that the alpha, beta, and delta wolves, that represent the best solutions at
the pack, have a better knowledge regarding the prey’s position during the hunting
stage, according to Fig. (3b). Thus, the estimate position Xt þ 1
i


, to update the wolf’s
current position, is given by the mean displacement with respect to the positions of the
dominant wolves, deﬁned by Eqs. (21), (22), and (23).
D
!
a ¼ C!
1  X!t
a  X!t
i
			
			; D
!
b ¼ C!
2  X!t
b  X!t
i
			
			; D
!
d ¼ C!
3  X!t
d  X!t
i
			
			
ð21Þ
X!
1 ¼ X!t
a  A!
1  D
!
a; X!
2 ¼ X!t
b  A!
2  D
!
b; X!t
d  A!
3  D
!
d
ð22Þ
X!t þ 1
i
¼ X!
1 þ X!
2 þ X!
3
3
ð23Þ
After the update, it is veriﬁed if there are any violations to the search space
boundaries and the solution is evaluated through the objective function. Finally, the
wolves’ hierarchy is updated by replacing the alpha, beta, or delta wolves by the
current solution, if an improvement was observed.
3.3
Sine Cosine Algorithm—SCA
The optimization technique known as sine cosine algorithm (SCA) was proposed in
[30]. This optimization tool is based on the mathematical functions sine and cosine, in
which the local and global search components are made according to random adaptive
variables integrated to the algorithm. Figure 4 depicts the SCA pseudo-code.
Fig. 4. Algorithm 3—sine cosine algorithm pseudo-code
328
F. F. Panoeiro et al.

In the SCA algorithm, the total number of candidate solutions ðgÞ is deﬁned. The
positions of these ðXiÞ solutions are randomly dispersed in the solution region and
evaluated through the objective function, deﬁning the best solution in the set
P
ð
Þ.
Then, the algorithm’s iterative process starts, at which the search for the optimal
solution is performed by the approximation or distancing between the current solution
Xt
i


and the best solution P
ð
Þ. Based on this distancing, the updated position Xt þ 1
i


is given by Eq. (24), at which the random value in [0, 1] of the parameter ‘r4’
determines the choice of the sine or cosine component.
Xt þ 1
i
¼
Xt
i þ rt
1  sin r2
ð Þ  r3  P  Xt
i
		
		;
r4\0:5
Xt
i þ rt
1  cos r2
ð Þ  r3  P  Xt
i
		
		;
r4 [ ¼ 0:5

ð24Þ
With:
rt
1 ¼ a  t
a
Tmax
ð25Þ
Parameter ‘rt
1’ is a function of the maximum number of iterations ðTmaxÞ, the
current iteration (t), and an exploration coefﬁcient (a) that deﬁnes the solution
searching region; i.e., when rt
1\1, it is estimated that the updated position can be in the
region between the current solution Xt
i


and the best ðPÞ, or outside this region for
rt
1 [ 1, as shown in Fig. 5.
Since this parameter decreases over the course of iterations, the global search is
more likely to be performed at the beginning of the process and the local search at the
end of the process, reﬁning local solutions. Parameter ‘r2’ is related to the extension of
the step toward or outwards the best solution P
ð
Þ. As for parameter ‘r3’, r3\1, or
r3 [ 1, respectively, attenuates or increases the magnitude of the best solution,
Fig. 5. Local/global search behavior of SCA
Application of Recent Metaheuristic Techniques for Optimizing
329

both obtained in [0, 2p] and [0, 2]. Then, it is veriﬁed if there are any violations to the
search space boundaries and the solution Xt þ 1
i


is evaluated. At last, the position of
the best solution is updated P
ð
Þ.
3.4
Adaptations and Chaotic Map
The randomly generated initial solutions (Xi) in the methods are of binary nature, at
which ‘1’ and ‘0’ indicate the presence or absence of a wind turbine in the layout.
During the solution update process Xt þ 1
i


, random variables of continuous nature are
applied. This way, the updated solution is rounded (round
Xt þ 1
i


), and possible
violations to the search space boundaries are veriﬁed through Eq. (26).
Xt þ 1
i
¼
1
if
Xt þ 1
i
 0:5
0
if
Xt þ 1
i
\0:5

ð26Þ
In the specialized literature, different versions of the described optimization tech-
niques are found, aiming at improving the local/global search components of the
algorithms. In this context, one of the possible applications is the insertion of a chaotic
model in the replacement of the searching parameters of the optimization methods.
A chaotic system can be understood as a random generator obtained from deter-
ministic systems with dynamic properties, semi-stochastic, ergodic, and very sensitive
to initial conditions [33]. These deterministic systems are based upon a mathematical
relation and are known as chaotic maps. According to [34], the dispersion of random
numbers is better, allowing solutions to perform large steps to escape from local
minima or short steps allowing the reﬁnement in the local search. At the present work,
the authors will use the sinusoidal map, represented by Eq. (27) [35].
xk þ 1 ¼ ax2
k sinðpxkÞ
ð27Þ
where a = 2.3 and the chaotic numbers are generated in [0, 1].
At the BA optimization method, this chaotic map is applied in the adjustment of the
pulse amplitude Ai
ð
Þ and frequency random variable ðbÞ parameters. Equations (28)
and (29) depict the frequency and pulse amplitude including the chaotic map.
fri ¼ frmin þ frmax  frmin
ð
Þ  a  ðxt
iÞ2  sin p  xt
i


ð28Þ
At þ 1
i
¼ a  xt
i
 2 sin p  xt
i


ð29Þ
For the GWO and SCA optimization methods, the chaotic map is applied to sub-
stitute the exploration coefﬁcient (a) of the searching coefﬁcient (A) and
r1
ð Þ,
respectively.
330
F. F. Panoeiro et al.

Equations (30) and (31) depict the novel parameters.
A! ¼ a  xt
ð Þ2 sin p  xt
i


 2r1  1
ð
Þ
ð30Þ
rt
1 ¼ a  xt
ð Þ2 sin p  xt
i


ð31Þ
Parameters ‘ A!’ and ‘rt
1’ determine the global/local searching steps throughout the
search space, as previously mentioned. This dispersion caused by the chaotic map aims
at improving the exploration during these steps. Figure 6 depicts a comparison between
the linear and chaotic exploration coefﬁcients over 200 cycles/iterations.
4
Results and Discussion
To evaluate the methodologies investigated in this chapter, simulations were performed
for a well-known case study from the literature. The wind farm’s terrain has dimensions
of 2 km 	 2 km, totaling an area of 4 million m2. This region was divided in 100 bits,
at which the distance between the bits is of 200 m, equivalent to ﬁve times the rotor
diameter (5RD) [16]. The optimization process will be of binary nature, as previously
mentioned, at which the variable is a vector of 100 positions. The stopping criteria
applied to all techniques is the maximum iterations number. The simulations were
performed with the following conﬁgurations:
• Number of initial solutions: 100, 500, and 1000;
• Maximum number of iterations: 300;
• Wind incidence scenarios: (I) north–south (0°) and (II) multiple directions (0°, 45°,
90°, 135°, 180°, 225°, 270° and 315°).
For each conﬁguration, 40 simulations were performed starting from the same
random initial solution for all optimization techniques. The adopted parameters for the
optimization methods are shown in Table 1.
0
20
40
60
80
100
120
140
160
180
200
Iterations
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Exploration Coefficient
GWO/SCA
Sinusoidal Map
Fig. 6. Exploration coefﬁcients of GWO and SCA. Linear and chaotic models
Application of Recent Metaheuristic Techniques for Optimizing
331

4.1
Case (I): North–South
Case (I) is used to validate the methodology employed with respect to the specialized
literature. In this case, it is considered a mean wind speed u0
ð
Þ of 12 m/s at direction
k = 0º, corresponding to the north–south direction. Since there is no variation in the
incidence direction, the wind density probability fk
ð Þ is equal to 1. Therefore, there is
no weighing in the calculation of the extracted power.
The ﬁrst analysis is about obtaining the optimal values of the objective function for
the forty executions inherent to the proposed conﬁgurations. Figure 7 depicts the
results obtained for the objective function that represents the project costs per output
extracted power, for the forty simulations performed in this study.
From Fig. 7a, it can be observed that, among the basic methodologies, the GWO
presented the smaller results’ dispersion, disregarding discrepant values (+) named
outliers. However, from the results obtained, the SCA obtained the lowest mean,
median, and minimum solution, indicating that this methodology obtained better layout
conﬁgurations by achieving a lower cost per extracted power. Analyzing the intro-
duction of the chaotic maps in the adjustment of the algorithm’s parameters, it can be
observed that the results’ dispersion is different from the ones considering only the
basic methodologies. The CSCA presented the lowest dispersion, but presented some
outliers (+), differently from the SCA. It is interesting to mention that, among all
methodologies, the CBA was the only capable of obtaining the minimum solution of
0.0015436$/kW and that the CGWO obtained the lowest mean and median values.
With an increase in the number of initial solutions, it can be seen from Fig. 7b and c
that the results’ dispersion was smaller, which is expected, since there are a greater
number of solutions investigating the search space. Thus, the quality of solutions is
improved, with all methodologies reaching the solution of 0.0015436$/kW for the
conﬁguration of 1000 initial solutions. However, with 500 solutions the BA was not
able to reach the optimal value.
By analyzing Fig. 7b, it can be observed that the solutions’ dispersion is similar for
all methodologies, but it is more likely that the solutions obtained by the SCA and
CGWO will be better for more simulations, since these techniques obtained lower
median values. For the conﬁguration represented in Fig. 7c, the median for the CGWO
results is at the minimum value, indicating that at least half of the simulations reached
the optimal result. In general, the solutions’ dispersion, and median and mean values
for the CGWO technique were better compared to the other investigated techniques,
Table 1. Optimization techniques’ parameters
Optimization technique
Parameter
Value
Description
BA
frmin
0
Minimum frequency
frmax
1
Maximum frequency
k
0.85
Pulse emission increase rate
a
0.9
Amplitude decay rate
GWO
a
1
Exploration coefﬁcient
SCA
a
1
Exploration coefﬁcient
332
F. F. Panoeiro et al.

leading to the belief that this is the most reliable technique to solve the OWFLO
problem, in the sense of knowing what to expect from it.
Table 2 depicts the minimum, median, and mean values obtained from the simu-
lations for all optimization techniques for Case (I), highlighting the best results of each
conﬁguration.
(a)
(b)
(c)
Fig. 7. Solution dispersion for the conﬁgurations with a 100, b 500, and c 1000 solutions for
Case (I)
Application of Recent Metaheuristic Techniques for Optimizing
333

The second analysis concerns the convergence of the optimization techniques. The
convergence curves (objective function evaluation over the course of iterations)
depicted in Fig. 8 represent the best simulations for each optimization technique among
all forty performed simulations, in the sense of reaching the minimum values shown in
Table 1 with the smallest number of iterations.
By analyzing the convergence curves in Fig. 8a, it can be observed that only the
CBA technique reaches the optimal result of 0.0015436$/kW after performing 278
iterations. Another interesting aspect to be observed is the GWO/CGWO convergence
behavior, at which the convergence to a local minimum occurs within the ﬁrst itera-
tions, is faster when compared to the other techniques. From Fig. 8b, it can be seen that
299 iterations were needed for the SCA to reach the optimal value, whereas the chaotic
version CSCA reached it after 236 iterations. As for the GWO and CGWO, it can be
observed that the basic version reached the minimum of 0.0015436$/kW with less
iterations than its chaotic version.
Regarding Fig. 8c, the CGWO reaches the optimal result with less iterations
(68) than all other methodologies. In general, the convergence behavior for all simu-
lations performed was similar, with the CGWO showing itself the most efﬁcient
method to solve the OWFLO problem.
Figure 9 depicts the optimal layout obtained by the methodologies, corresponding
to a cost of 0.0015436$/kW.
Table 2. Statistical data for Case (I)
Optimization
technique
Number of
solutions
Minimum ($/
kW)
Median ($/
kW)
Mean ($/
kW)
BA
100
0.0015489
0.0015540
0.0015541
500
0.0015439
0.0015476
0.0015471
1000
0.0015436
0.0015451
0.0015457
GWO
100
0.0015469
0.0015513
0.0015519
500
0.0015436
0.0015466
0.0015459
1000
0.0015436
0.0015440
0.0015444
SCA
100
0.0015454
0.0015509
0.0015513
500
0.0015436
0.0015451
0.0015455
1000
0.0015436
0.0015451
0.0015447
CBA
100
0.0015436
0.001550
0.0015503
500
0.0015436
0.0015453
0.0015458
1000
0.0015436
0.0015451
0.0015456
CGWO
100
0.0015443
0.0015485
0.0015489
500
0.0015436
0.0015451
0.0015452
1000
0.0015436
0.0015436
0.0015444
CSCA
100
0.0015468
0.0015506
0.0015511
500
0.0015436
0.0015453
0.0015459
1000
0.0015436
0.0015451
0.0015446
334
F. F. Panoeiro et al.

Table 3 depicts the number of wind turbines, costs, and total output power
extracted from the wind farm obtained in the present study, compared to the results
found in the literature in order to validate the methodology employed.
(a)
(b)
(c)
Fig. 8. Convergence curves for the conﬁgurations with a 100, b 500, and c 1000 solutions for
Case (I)
Application of Recent Metaheuristic Techniques for Optimizing
335

4.2
Case (II): Multiple Directions
For Case (II), multiple wind directions are considered in order to analyze its impact in
the layout’s optimization. To do so, it is considered that the region of the wind farm
presents variations in the wind incidence directions k = (0º, 45º, 90º, 135º, 180º, 225º,
270º, and 315º), weighed with probability densities of fk ¼ 1=8 ¼ 0:125 and mean
speed of u0 ¼ 12 m=s. Figure 10 depicts the results’ dispersions for Case (II).
From the results obtained by the optimization techniques for the conﬁguration
depicted in Fig. 10a, the GWO and CGWO obtained the smallest dispersions. When
comparing the methodologies applied in Case (II), it is possible to observe that the
increase in the number of solutions did not cause a signiﬁcant impact in the solutions’
dispersion, as occurred in Case (I). However, better layouts were obtained for the
conﬁgurations shown in Fig. 10b and c; i.e., layouts with lower cost per extracted
Fig. 9. Wind farm layout for Case (I)
Table 3. Literature comparison: Case (I)
References
Number of wind
turbines
Cost ($) Output power (kW) Objective function
($/kW)
[13]
26
20
12,352
0.001620
[16]
30
22.1
14,310
0.0015436
Present study 30
22.1
14,310
0.0015436
336
F. F. Panoeiro et al.

power were found. The minimum solution obtained in this case was of 0.0015939$/kW
by the optimization techniques SCA, CSCA, CGWO, and CBA.
For each investigated solution, eight wind incidence directions are veriﬁed, as
previously mentioned. The probability density is the same for each direction, causing a
‘conﬂict’ during the layout optimization process, i.e., the location of the wind turbines’
impact in different performances due to the incidence angle. This impact is observed by
(a)
(b)
(c)
Fig. 10. Solution dispersion for the conﬁgurations with a 100, b 500, and c 1000 solutions for
Case (II)
Application of Recent Metaheuristic Techniques for Optimizing
337

the greater dispersion of the obtained results, justifying the difﬁculty of obtaining a
‘global’ minimum solution for the problem, getting stagnated at local minimum
solutions in many simulations.
Table 4 depicts the minimum, median, and mean values obtained from the simu-
lations for all optimization techniques for Case (II), highlighting the best results of each
conﬁguration.
Figure 11 depicts the convergence curves obtained for the best solutions for
Case (II).
From the convergence curves shown in Fig. 11a, it can be seen that even though the
methods GWO and CBA converge to the best solutions obtained, they get stagnated at
the beginning of the iterative process. For the conﬁguration related to the convergence
curve depicted in Fig. 11b, the CSCA and CBA converge to the value 0.0015929$/kW
at iterations 260 and 9, respectively. For the conﬁguration with 1000 solutions,
depicted in Fig. 11c, the SCA and GWO obtain the same value of 0.0015929$/kW at
iterations 114 and 31, respectively. For this case, there is no results’ progression; i.e.,
for each conﬁguration, the optimization methods converge to different solutions,
showing the complexity of Case (II).
The location of the wind turbines for the solution of 0.0015936$/kW is shown in
Fig. 12.
Table 4. Statistical data for Case (II)
Optimization
technique
Number of
solutions
Minimum ($/
kW)
Median ($/
kW)
Mean ($/
kW)
BA
100
0.0015949
0.0015996
0.0016001
500
0.0015966
0.0015990
0.0015995
1000
0.0015959
0.0016009
0.0015999
GWO
100
0.0015949
0.0015977
0.0015984
500
0.0015946
0.0015986
0.0015985
1000
0.0015976
0.0016021
0.0016018
SCA
100
0.0015951
0.0015974
0.0015994
500
0.0015949
0.0015965
0.0015984
1000
0.0015939
0.0016001
0.0015998
CBA
100
0.0015952
0.0015979
0.0015985
500
0.0015939
0.0015985
0.0015993
1000
0.0015963
0.0016008
0.0015999
CGWO
100
0.0015949
0.0015981
0.0015979
500
0.0015946
0.0015972
0.0015981
1000
0.0015939
0.0015967
0.0015973
CSCA
100
0.0015952
0.0015985
0.0015995
500
0.0015939
0.0015989
0.0015986
1000
0.0015959
0.0015981
0.0015990
338
F. F. Panoeiro et al.

Table 5 summarizes the obtained results for Case (II). Table 6 presents the output
power generated for each wind direction, at which it is possible to observe that for the
directions of 45º, 135º, 225º, and 315º, the wake effect is less intense.
(b)
(a)
(c)
Fig. 11. Convergence curves for the conﬁgurations with a 100, b 500, and c 1000 solutions for
Case (II)
Application of Recent Metaheuristic Techniques for Optimizing
339

5
Conclusion
The present work presents methodologies employed to solve the OWFLO problem
based on optimization techniques known as metaheuristics, including the representation
of intermittent wind regimes in the problem, considering different ﬂow directions.
Fig. 12. Wind farm layout for Case (II)
Table 5. Case (II) results’ summary
Number of wind
turbines
Cost ($)
Weighted output power
(kW)
Objective function
($/kW)
35
24.7177
15,512
0.0015939
Table 6. Output power at each wind direction
Direction (º)
Output power (kW)
0
14,653
45
16,644
90
13,749
135
17,029
180
14,686
225
16,557
270
13,778
315
17,003
340
F. F. Panoeiro et al.

Since the OWFLO is a complex problem, regarding the total number of possible
combinations, the chaotic map feature is used to adjust some parameters of the opti-
mization techniques in order to improve their global/local searching stages.
The main goal is to compare the performance of the basic and chaotic optimization
techniques in solving the OWFLO problem, regarding the solutions quality and con-
vergence. According to the results obtained, the chaotic methodology CGWO was able
to obtain the optimal solution for Cases (I) and (II). In general, the dispersion of the set
of solutions referring to the forty executions carried out by varying the number of initial
solutions was better in the CGWO; i.e., layouts with fewer investment costs per power
extracted were obtained, indicating this to be the most reliable technique in the sense of
knowing what to expect from it. From a convergence point of view, for some cases, the
CGWO reaches the optimal solution after a few iterations of the iterative process. This
fact is also observed in the CBA when applied to Case (II). However, Case (II) has
shown itself far more complex, causing difﬁculties for all investigated methods.
Regarding the layout problem, it is noticeable that the number and location of the
wind turbines are directly impacted by the wake effect for different wind incidence
scenarios. Thus, the project costs and extracted power vary according to the scenario
under study, justifying the proposed formulation and the application of the optimization
techniques for this modeling.
Novel strategies are introduced at the local/global searching steps of the opti-
mization techniques, mostly at the exploration coefﬁcients of the sine cosine algorithm
rt
1
 
and grey wolf optimizer (a). Regarding the OWFLO problem, different objective
functions are investigated, since the objective function used in this work is dimen-
sionless, i.e., more suited for academic studies.
Acknowledgements. The authors acknowledge the Brazilian National Research Council
(CNPq), the Coordination for the Improvement of Higher Education Personnel (CAPES), the
Foundation for Supporting Research in Minas Gerais, and Electric Power National Institute
(INERGE) for their great support.
References
1. Global Wind Energy Council GWEC (2019) Global wind report forecasts over 300 GW
capacity to be added in next 5 years—growth to come from emerging markets and offshore
wind, 3 Apr 2019. Available https://gwec.net/. Accessed 10 May 2019
2. Hou P (2017) Optimization of large-scale offshore wind farm. Ph.D Dissertation, Aalborg
Universitetsforlag
3. Kerkvliet H, Polatidis H (2016) Offshore wind farms decommissioning: a semi quantitative
multi-criteria decision aid framework. Sustain Energy Technol Assess 18:69–79 (Elsevier)
4. Han X, Guo J, Wang P, Jia Y (2011) Adequacy study of wind farms considering reliability
and wake effect of WTGs. In: Power and energy society general meeting, IEEE, pp 1–7
5. Jensen NO, Katic I, Hojstrup C (1986) A simple model for cluster efﬁciency. In: European
wind energy association conference and exhibition, pp 407–410
6. Kusiak A, Song Z (2010) Design of wind farm layout for maximum wind energy capture.
Renew Energy 35(3):685–694
Application of Recent Metaheuristic Techniques for Optimizing
341

7. González JS, Rodriguez AGG, Mora JC, Santos JR, Payan MB (2010) Optimization of wind
farm turbines layout using an evolutive algorithm. Renew Energy 35(8):1671–1681
8. Gao X, Yang H, Lin L, Koo P (2015) Wind turbine layout optimization using
multipopulation genetic algorithm and a case study in Hong Kong offshore. J Wind Eng
Indus Aerodyn, 139
9. Wu YK et al (2014) Optimization of the wind turbine layout and transmission system
planning for a large-scale offshore windfarm by ai technology. IEEE Trans Indus Appl 50
(3):2071–2080 (IEEE)
10. Changshui Z, Guangdong H, Jun W (2011) A fast algorithm based on the submodular
property for optimization of wind turbine positioning. Renew Energy 36(11):2951–2958
11. Duan B, Wang J, Gu H (2014) Modiﬁed genetic algorithm for layout optimization of multi-
type wind turbines. In: IEEE, American control conference (ACC), pp 3633–3638
12. Shakoor R et al (2014) Wind farm layout optimization by using deﬁnite point selection and
genetic algorithm. In: 2014 IEEE international conference on power and energy (PECon),
IEEE, pp 191–195
13. Mosetti G, Poloni C, Diviacco B (1994) Optimization of wind turbine positioning in large
windfarms by means of a genetic algorithm. J Wind Eng Ind Aerodyn 51(1):105–116
14. Jiang D et al (2013) Modiﬁed binary differential evolution for solving wind farm layout
optimization problems. In: 2013 IEEE symposium on computational intelligence for
engineering solutions (CIES), IEEE, pp 23–28
15. Gomes LL, Oliveira LW, Silva IC Jr, Passos Filho JA (2017) Optimization of wind farms
layout through artiﬁcial immune system. In: Latin—American congress on electricity
generation and transmission, GLACTEE, vol 12
16. Pookpunt S, Ongsakul W (2013) Optimal placement of wind turbines within wind farm
using binary particle swarm optimization with time-varying acceleration coefﬁcients. Renew
Energy 55:266–276 (Elsevier)
17. Hou P et al (2015) Optimized placement of wind turbines in large-scale offshore wind farm
using particle swarm optimization algorithm. IEEE Trans Sustain Energy 6(4):1272–1282
(IEEE)
18. Yang H et al (2016) Wind farm layout optimization and its application to power system
reliability analysis. IEEE Trans Power Syst 31(3):2135–2143 (IEEE)
19. Dey N (ed) (2017) Advancements in applied metaheuristic computing. IGI Global
20. Dey N (2018) Advancements in applied metaheuristic computing. IGI Global, Hershey, PA,
pp 1–978
21. Gupta N, Patel N, Tiwari BN, Khosravy M (2018) Genetic algorithm based on enhanced
selection and log-scaled mutation technique. In: Proceedings of the future technologies
conference, Springer, pp 730–748
22. Singh G, Gupta N, Khosravy M (2015) New crossover operators for real coded genetic
algorithm (RCGA). In: 2015 international conference on intelligent informatics and
biomedical sciences (ICIIBMS), IEEE, pp 135–140
23. Gupta N, Khosravy M, Patel N, Sethi IK (2018) Evolutionary optimization based on
biological evolution in plants. Proc Comput Sci 126:146–155 (Elsevier)
24. Gupta N, Khosravy M, Patel N, Senjyu T (2018) A bi-level evolutionary optimization for
coordinated transmission expansion planning. IEEE Access 6:48455–48477
25. Moraes CA, De Oliveira EJ, Khosravy M, Oliveira LW, Honrio LM, Pinto MF, A hybrid
bat-inspired algorithm for power transmission expansion planning on a practical Brazilian
network. In: Applied nature-inspired computing: algorithms and case studies, from springer
tracts in nature inspired computing (STNIC), Springer International Publishing, will be
appeared in 2019
342
F. F. Panoeiro et al.

26. Khosravy M, Gupta N, Patel N, Senjyu T, Duque CA (2019) Particle swarm optimization of
morphological ﬁlters for electrocardiogram baseline drift estimation. In: Applied nature-
inspired computing: algorithms and case studies, from springer tracts in nature-inspired
computing (STNIC),Springer International Publishing (in press)
27. Jagatheesan K, Anand B, Samanta S, Dey N, Ashour AS, Balas VE (2017) Particle swarm
optimisation-based parameters optimisation of PID controller for load frequency control of
multi-area reheat thermal power systems. Int J Adv Intell Paradig 9(5–6):464–489
28. Chatterjee S, Sarkar S, Hore S, Dey N, Ashour AS, Balas VE (2017) Particle swarm
optimization trained neural network for structural failure prediction of multistoried RC
buildings. Neural Comput Appl 28(8):2005–2016
29. Satapathy SC, Raja NSM, Rajinikanth V, Ashour AS, Dey N (2018) Multi-level image
thresholding using Otsu and chaotic bat algorithm. Neural Comput Appl 29(12):1285–1307
30. Mirjalili S (2016) Sca: a sine cosine algorithm for solving optimization problems. Knowl-
Based Syst 96:120–133 (Elsevier)
31. Mirjalili S, Mirjalili SM, Lewis A (2014) Grey Wolf optimizer. Adv Eng softw 69:46–61
(Elsevier)
32. Yang XS (2010) A new metaheuristic bat-inspired algorithm. In: Nature inspired cooperative
strategies for optimization. Springer, pp 65–74
33. Tavozoei MS, Haeri M (2007) Comparison of different one-dimensional maps as chaotic
search pattern in chaos optimization algorithms. Appl Math Comput 187(2):1076–1085
(Elsevier)
34. Mendel E, Krohling RA, Campos M (2011) Swarm algorithms with chaotic jumps applied to
noisy optimization problem. Inform Sci 181(20):4494–4514 (Elsevier)
35. Gandomi AH, Yang XS (2014) Chaotic bat algorithm. J Comput Sci 5(2):224–232 (Elsevier)
Application of Recent Metaheuristic Techniques for Optimizing
343

Chapter 16
Design and Comparison of Two Evolutionary
and Hybrid Neural Network Algorithms
in Obtaining Dynamic Balance
for Two-Legged Robots
Ravi Kumar Mandava1,2(&) and Pandu R. Vundavilli1
1 School of Mechanical Sciences, Indian Institute of Technology Bhubaneswar,
Bhubaneswar, Odisha 752050, India
ravikumar1013@gmail.com
2 Department of Mechanical Engineering, MANIT, Bhopal 462003, India
1
Introduction
Compared to wheeled robots, their legged counterparts are more comfortable while
moving on various discontinuous terrains of an environment. However, upholding the
dynamic balance of the legged robot is difﬁcult due to its discrete footholds. To achieve
this, we need to regulate the various motors, which are mounted on the individual joints
in a coordinated manner. Moreover, the stability of the two-legged robot is measured
with the help of DBM. In the past few decades, almost all of the scientists have been
working on the development of dynamically balanced gaits for the two-legged robot
under various terrain conditions. In [1], the authors have proposed a semi-inverse
method that is used to calculate the trunk motion of the two-legged robot for the
predeﬁned ZMP trajectories with various boundary conditions to move the ZMP inside
the foot support polygon. Alongside, Takanishi et al. [2] developed a novel control
algorithm for generating optimal trajectories for the waist and trunk motion of the two-
legged robot. For generating optimal trajectories for the waist and trunk, they used a
performance index that is considered to the relative position of the waist and trunk.
Finally, the developed algorithm was veriﬁed on real WL-12R two-legged robot.
Moreover, Goswami [3] discussed a concept called foot rotation indicator (FRI) for
determining the amount of DBM of the two-legged robot while in the single support
phase. Further, the authors [4] proposed a robust algorithm for regulating the angular
momentum of a two-legged robot with the manipulation of ZMP. In addition to the
above works, a control method has been developed by Sano and Furusho [5] to achieve
the dynamic walking for the two-legged robot in both the planes (i.e., sagittal and
frontal) by conserving the angular momentum. Further, the developed algorithm was
veriﬁed on BLR-G2 biped robot at a speed of 0.35 m/s. However, for developing a
dynamically balanced robust gait for a planar ﬁve-link two-legged robot, Seo and Yoon
[6] constructed a reasonable set of gaits to fulﬁll the periodicity of the two-legged robot
© Springer Nature Singapore Pte Ltd. 2020
M. Khosravy et al. (eds.), Frontier Applications of Nature Inspired Computation,
Springer Tracts in Nature-Inspired Computing,
https://doi.org/10.1007/978-981-15-2133-1_16

walking. The foot strike time margin was considered as a performance measure, and the
robot achieved the robust gait even with the external disturbances. The generation of
dynamically balanced gaits for ascending and descending the sloping surface [8] and
staircase [7] for a seven-DOF biped was established with the help of simulation studies
only. It was observed that in this approach, the authors did not use any controller to
control the motors and used the concept of DBM to maintain stable gait generation.
Nguyen et al. [9] also discussed the effect of foot structure while walking on the ﬂoor.
The center of gravity of the robot with varying toe is compared with the usual walking
on ﬂat terrain and determines the best toe mechanism. In [10], Gaurav and Ashish
proposed a method for generating trajectories and step planning for navigation of
12-DOF biped robot while walking on irregular terrains with the obstacles are pre-
sented. In addition to the above methods, Zhong et al. [11] designed a controller for the
robot after using a neural network (NN) and fuzzy logic controller (FLC) for walking
on uneven terrains. A modiﬁed PSO algorithm was used to minimize the weights of the
NN and rule base of FLC. It was observed that in some works [7, 8, 11, 12], they
worked on the structure of the robot that had a limited degree of freedom and
considered the moment only in a sagittal plane.
The objective of this study is to diminish the error between the desired setpoint and
actual value and to improve the balance of the robot. For reducing the error of each
joint of the two-legged robot, one has to tune the motors of the joints in a coordinated
way. Researchers all over the world are using different types of tuning methods, which
are explained below.
In [13], Visioli established a fuzzy logic-based PID controller for the robotic
manipulator. Further, the abovementioned developed controller was compared to the
standard PID controller in terms of incremental fuzzy expert PID controller (IFE),
fuzzy gain scheduling (FGS), fuzzy setpoint weighting (FSW), fuzzy self-tuning of a
single parameter (SSP) and fuzzy PID controllers [14]. Later on, Mandava and Vun-
davilli [15] designed a PID controller for four-DOF planar and spatial robotic
manipulators. The authors are proposed a manual tuning procedure to tune the gains of
the controller. It was observed that the authors did not use any optimizer to attain the
optimal tuning parameters of the PID controllers. Moreover, in [16], the author dis-
cussed a self-organizing PID controller for achieving the best tuning parameters for the
revolute joints of the robotic arm. When compared with ordinary PID controller, the
SOF-PID controller produced the small steady-state error, faster rise time, and
insigniﬁcant overshoot for the set input trajectory. Further, Helon and Leandro [17]
proposed a multi-objective genetic algorithm (i.e., NSGA-II) to tune the gains of a PID
controller for a two-DOF planar manipulator. It was simple to implement and provide
an excellent reference tracking performance. Gutierrez et al. [18] implemented a NN
tracking controller for a single-link ﬂexible manipulator and also compared the
enactment of the standard PD and PID controllers. Compared to the PID and PD
controller, the tracking performance of the NN-based controller was far better and
maintained the zero tracking error due to the addition of additional frictional terms. To
control the manipulator by using the model-based approaches, it requires more com-
putational time and gives poor control performance. To overcome this problem, Murat
et al. [19] presented a decentralized model, where each controller was accompanying
with one joint, and a distinct neural network was used to regulate the controller
Design and Comparison of Two Evolutionary and Hybrid
345

variables. Pirabakaran and Becerra [20] also demonstrated the application of artiﬁcial
NN for automatic tuning of a PID controller, i.e., model reference adaptive controller
(MRAC). In that approach, initially, the multilayer perceptron (MLP) network and a
plant emulator were built. The emulator was proposed to train the NN and adjust the
variables of the PID controller to diminish the error between the reference outputs and
measured outputs. Further, Joel Perez et al. [21] established an adaptive NN controller
for the two-link robot manipulator. The stability of the tracking error was evaluated
based on Lyapunov control functions, and the control law was attained based on the
concept of PID approach. In this regard, for verifying the tracked trajectory, a robot
model along with friction terms and unknown external disturbances were considered.
In [22], Zang et al. designed a PID controller for a musculoskeletal robot which helps
track the joint trajectory for achieving the desired motion. Moreover, Zhong and Chen
[23] presented an intelligent control system for the biped robot, which was analyzed the
stairs and calculated the required trajectories for the feet. To overcome the problems
arise while controlling, the biped robot is directly controlled by the neural network,
fuzzy logic controller. A modiﬁed PSO algorithm was used to train the weights of the
NN and the rules of FLC.
Through the above studies, the researchers laid the foundation for solving the
problems related to gains of the PID controllers [24]; however, they were not optimal in
any sense. Moreover, the manual tuning of the PID parameters is time-consuming and
computationally expensive; these are not suitable for online applications. To evolve
optimal tuning parameters for each of the motors, that control the robot and increase the
possibility of using the online control, it is necessary to develop an adaptive tuning
scheme. To tackle the difﬁculties like trapping in the local minima during the training
problem, metaheuristic optimization algorithms, namely genetic algorithm (GA)
[25–27] particle swarm optimization (PSO) [28], cat swarm optimization (CSO) [29],
ant colony optimization (ACO) [30, 31], bird mating optimizer (BMO) [32], and
modiﬁed invasive weed optimization (MIWO) [33] algorithms, were tried by various
researchers. Alongside, Ge et al. [34] developed a controller based on the concept of a
neural network and used an inverse dynamical model. A Gaussian radial basis function
network was used for achieving uniformly stable adaptation and asymptotical tracking.
The controller reduced the errors and bounding disturbances of the network. In addition
to the above methods, Woon et al. [35] designed an adaptive NN controller for the
coordinated motion of the manipulator. Further, Sun et al. [36] designed a NN-based
sliding mode adaptive control (NNSMAC), NN-based adaptive observer, and NN-
based sliding mode adaptive output feedback control (NNSMAOFC) for tracking the
trajectory of the robotic manipulator. For converging the tracking error to zero, the
Lyapunov theory was used. Finally, for ﬁnding the effectiveness of the problem, they
compared the three developed approaches. In addition to the above methods, Mehran
et al. [37] developed an adaptive NN integral sliding mode controller for a biped robot.
The gains of the sliding mode controller were tuned by using bat algorithm (BA) and
compared with the integral sliding mode controllers. It was observed that the study was
concentrated on designing the controller for limited degrees of freedom biped robot and
controlling the said robot only in the sagittal plane.
Based on the above study, most of the researchers have used the neural network
to control the ZMP within the foot support polygon of the two-legged robot [38].
346
R. K. Mandava and P. R. Vundavilli

Some other researchers also used NN-based approaches to tune the gains of the con-
troller for the robotic manipulators. In addition to the above works, very few
researchers used stochastic optimization algorithms to train the neural networks for the
problems related to the control of a two-legged robot. The contributions of the present
research work are as follows:
• The authors of this study have implemented a variation to the standard invasive
weed optimization algorithm by introducing chaotic and cosine variables during
spatial dispersal phase. These two variables help the algorithm to increase the
search space for distributing the seeds and to reduce the chances of solution trapped
into a local optimum, respectively.
• Alongside, to achieve the dynamically balanced walking of the two-legged robot
while moving on a ﬂat surface, a torque-based PID controller is designed for whole
joints of the two legs.
• Moreover, the gains (Kp, Kd, and Ki) of the PID controllers are regulated with the
support of the feed-forward neural network, and the weights of the network are
trained by using a non-traditional optimization algorithm (MCIWO). Further, the
performance of the developed algorithm (i.e., MCIWO-NN) has been compared
with PSO-NN algorithm concerning variation of error at each joint, average torque
essential to complete single cycle, and DBM of the two-legged robot.
• Finally, the gait developed by the optimal control algorithm is veriﬁed on a real
two-legged robot in a laboratory and established that the legged robot accomplished
its walk on the ﬂat surface effectively.
Fig. 1. Structure of the two-legged robot a line diagram, b actual robot
Design and Comparison of Two Evolutionary and Hybrid
347

2
Description of the Two-Legged Robot
The two-legged robots are having a structure similar to human beings and are looking
more anthropomorphic. These two-legged robots are intended to work in an environ-
ment where human co-exists like hospitals, hotels, houses, and ofﬁces. The current
research work focuses primarily on the design of a PID controller for the two-legged
robot on a ﬂat surface. Figure 1 shows the structure of the two-legged robot [39], which
was used in this work. Further, the block diagram presenting the methodology used to
solve the problem is given in Fig. 2.
Initially, coordinate frames are assigned for each joint, to attain the D-H parameters
of the two-legged robot. These D-H parameters help calculate the position and ori-
entation of the particular joint. For developing the dynamically balanced walk, third-
ordered polynomial trajectories are assigned for the hip joint and swing foot of the two-
legged robot. Moreover, the formulation related to the mathematical model for the two-
legged robot to walk on a ﬂat surface is done based on the following assumptions.
• Walking along the ﬂat surface, the foot is always parallel to the ground, i.e., there is
no ankle moment h6 ¼ h12 ¼ 0
• The mass of each limb is assumed uniformly throughout its length and center of
mass of each limb is at the one-third distance from the endpoint.
• The walking direction of the two-legged robot is assumed both in the sagittal and
frontal views.
• The walking cycle consists of both single and double support phases.
• The PID controller is developed for both the legs of the two-legged robot.
V11
V12
W11
W12
12
1
Input layer
Ki12
Kd12
Kp12
Hidden layer
Output layer
Kp1
Kd1
Ki1
V13
with the help of adaptive NN
Tuning the gains of the PID controller
by using MCIWO/PSO
Establish the equations of motion 
using L−E formulation
NO
Forward Kinematics
of the gait
Verify the DBM
YES
Derive the controller equation for
torque based PID controller
Configuration of the biped robot
Inverse Kinematics
Get the gains of the torque based
PID Controller
for each joint
Obtain the angular displacement 
Find the error in angular displacement
for each joint
Optimize the architecture of NN 
Biped Robot
Fig. 2. Block diagram presenting the methodology used to solve the problem
348
R. K. Mandava and P. R. Vundavilli

Further, the dynamic balance of the two-legged robot is determined with the support of
ZMP. Figure 3 shows the schematic diagram presenting the representation of ZMP.
In the present chapter, the PID controllers are designed for every joint of the two-
legged robot. These controllers are helpful to achieve the desired gait while walking the
two-legged robot on a ﬂat surface. Further, the Lagrangian–Euler formulation (Eq. 1) is
used to calculate the dynamics of the robot. The developed dynamics are helpful to
design of PID controller.
si;the ¼
X
n
j¼1
MijðqÞ qj
:: þ
X
n
j¼1
X
n
k¼1
Cijk qj
: qk
: þ Gi
i; j; k ¼ 1; 2. . .n
ð1Þ
where the terms si;the represent the theoretical torque (N m), qj indicates the dis-
placement in (rad), _qj denotes the velocity in (rad/s), and €qj represents the acceleration
in (rad/s2), respectively.
Mi;j ¼
X
n
p¼maxði;jÞ
Tr dpjIpdT
pi
h
i
i; j ¼ 1; 2. . .n
ð2Þ
Ci;j;k ¼
X
n
p¼maxði;j;kÞ
Tr @ dpk


@qp
IpdT
pi


i; j ¼ 1; 2. . .n
ð3Þ
Gi ¼ 
X
n
p¼i
mpgdpi
p
erp
i; j ¼ 1; 2. . .n
ð4Þ
X
X
Z
zmp
DBM
X
ZMP
Y
P
M
Z
P
M
Z
Sagittal Plane
DBM
Y
Y
Z
Frontal Plane
F
F
Lower limb
Lower limb
F: Ground reaction force
Fig. 3. Location of ZMP in X- and Y-directions
Design and Comparison of Two Evolutionary and Hybrid
349

where Ip and p
erp indicate the moment of inertia (kg m/s2) and the center of mass (m) of
pth link, respectively. Further, g represents the acceleration due to gravity in (m/s2).
It is important to note that the angular acceleration of each links plays a vital role
while governing every joint of the two-legged robot. Therefore, the expression obtained
by rearranging the above equation in terms of the acceleration of the link is given in
Eq. (5).
qj
:: ¼
X
n
j¼1
Mij q
ð Þ1 
X
n
j¼1
X
n
k¼1
Cijk qj
: qk
: Gi
"
#
þ
X
n
j¼1
Mij q
ð Þ1si;the
 
!
i; j; k ¼ 1; 2. . .n
ð5Þ
Now, by looking at the term
X
n
j¼1
MijðqÞ1  si;the ¼ ^s
ð6Þ
The expression for determining the actual torque essential for every joint of the
two-legged robot after utilizing the joint-based PID controller is mentioned below.
sact ¼ Kpe þ Kd _e þ Ki
Z
edt
ð7Þ
In Eq. (7), Kp represents the proportional, Kd indicates the derivative, and Ki
denotes the integral gains of the controllers, respectively. Moreover, after adding the
meaning of e and _e, the expanded form of Eq. (7) can be rewritten as follows.
e hi
ð Þ ¼ hif  his
si;act ¼ Kpi hif  his


 Kdi his
:
þ Kii
Z
e his
ð
Þdt
i ¼ 1; 2; . . .n
ð8Þ
where si;act speciﬁes the actual torque given to individual joints by the controller to
move from the initial angular position ðhisÞ to the ﬁnal angular position ðhif Þ. Also, the
integral terms of the Eq. (8) replaced by their state variables, namely _xi and its sig-
niﬁcance are mentioned in Eq. (9).
xi ¼
Z
e his
ð
Þdt ) xi
: ¼ hif  his
i ¼ 1; 2; . . .n
ð9Þ
Further, Eq. (10) represents the ﬁnal control equation which controls all the joints
of the robot.
350
R. K. Mandava and P. R. Vundavilli

qj
:: ¼
X
n
j¼1
Mij q
ð Þ1 
X
n
j¼1
X
n
k¼1
Cijk qj
: qk
: Gi
"
#
þ Kpi hif  his


 Kdi his
:
þ Kiixi
ð10Þ
3
Proposed Soft Computing-Based Approaches
In the present manuscript, two soft computing-based approaches, which are MCIWO
trained NN (MCIWO-NN) and PSO trained NN (PSO-NN) algorithms, have been
proposed to tune the gains of the developed PID controller of the two-legged robot. The
neural network consists of simple processing units connected to process the data.
Moreover, the network structure (Fig. 4) consists of three different layers, the input,
hidden, and output layers, which are made up of neurons. Further, the weighted sum of
the inputs and the bias value added to every neuron and passed through the linear
transfer functions at the input layer, log-sigmoid transfer function at hidden layer, and
tan-sigmoid transfer function at the output layer of the network, respectively. It is an
entirely connected network with neurons in each layer and is attached to the neurons in
the neighboring layer and passing the signal from one layer to another.
In this work, the weights of the feed-forward NN have been trained by using two
metaheuristic algorithms, namely MCIWO and PSO algorithms. It is signiﬁcant to note
that NN is a highly potential tool for learning and adaptation, and it also can solve
complex real-time problems. Initially, a set of training data is used for training the
network, and an optimization algorithm has been discussed in this training for evolving
the most appropriate weights for the network to diminish the error for the
1
2
12
11
Ki1
Ki12
Kp12
Kd12
Kd1
Kp1
bias1
bias2
Output Layer
Hidden Layer
Input Layer
W12
W11
W13
W21
W22
V11
V12
V13
Fig. 4. Structure of the neural network
Design and Comparison of Two Evolutionary and Hybrid
351

corresponding problem. The difference between joint angles of equal time intervals of
all 12 joints, Δh1, Δh2, Δh3, Δh4, Δh5, Δh6, Δh7, Δh8, Δh9, Δh10, Δh11, Δh12, is
considered as inputs to the neural network (Fig. 5).
Dhk ¼ hjhi;
ð11Þ
where i = 1, …, 11, j = 2, …, 12, and k = 1, … 12.
The gains of the PID controller such as Kp, Kd, and Ki for all the twelve controllers
are treated as network outputs.
The change in the deviation of RMS, the angular displacement between the com-
pletion of every interval (/ijkf) and the starting of the interval (/ijki), is considered as
the ﬁtness (f) of every population and is given in Eq. (12).
f ¼ 1
d
X
d
i¼1
1
b
X
b
j¼1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1
2
X
p
k¼1
aijkf  aijks

2
s
"
#
;
ð12Þ
where d, b, and p represent the number of training, intervals considered in one step, and
joints.
In this study, the authors of the present chapter have discussed two metaheuristic
optimization algorithms, such as MCIWO and PSO algorithm to train the architecture
12
1
i.e 
i.e Kp1, Kd1, Ki1 ...........................Kp12, Kd12,Ki12
Change in error, Actual Torque required, ZMP 
         and Dynamic balance
Neural Network Module
Outputs: Tuning parameters reqiured for different joints
for Neural Network Structure
Inputs: Change in angle of links at regular time intervals
Weight optimization using MCIWO/PSO
Fig. 5. The ﬂow chart showing the structure of the proposed algorithm
PID Controller
e
des
q
u
Control Plant
q
MCIWO−NN and PSO−NN approaches
act
q
Feed Back Controller
Fig. 6. Block diagram showing the proposed control strategy
352
R. K. Mandava and P. R. Vundavilli

of the NN. Figure 6 shows the pictorial representation of the suggested adaptive PID
controller used in this chapter. The detailed description related to the said optimization
algorithms is discussed in the following sections.
3.1
MCIWO Algorithm
The newly proposed MCIWO algorithm has been established based on the variation of the
standard IWO algorithm, which was initiated by the Mehrabian and Lucas [40]. Firstly, a
limited number of weeds are created to form a solution in N-dimensional space with a
random position (Fig. 7). Note that each seed position denotes one possible solution to the
problem. Further, in the reproduction stage, each weed is permitted to produce the number
of new seeds based on the ﬁtness value. The number of seeds reproduced from every weed
is determined based on the value of weed ﬁtness and assigned the lowermost and
uppermost ﬁtness values of the colony. Moreover, the weed with the worst ﬁtness will
produce fewer seeds, and the weed with superior ﬁtness will generate new seeds. The
primary beneﬁt of this algorithm is that, in a solution space, each weed will contribute to
the reproduction process, and the weed which will generate the worst ﬁtness value also
shares some valuable information to the evolution process. Moreover, Eq. (13) is helpful
to determine the number of seeds (S) developed by every weed, which is given below.
S ¼ Floor Smin þ
f  fmin
fmax  fmin
 Smax


;
ð13Þ
where fmin and Smin represent the minimum ﬁtness and production by each plant, fmax
and Smax denote the maximum ﬁtness and production by each plant, respectively.
To increase the enactment of the said algorithm, two terms are known as, i.e., a
chaotic variable [41, 42] and a cosine variable [43, 44] are added during spatial dis-
persal phase. In IWO, the seeds are dispersal after following the normal distribution.
However, in the present problem, the chaotic, random number is used to distribute the
seeds. This reduces the number of chances of the solution to be trapped in the local
optimum while searching. Further, the chaotic, random number used in the present
study, which is obtained after using a Chebyshev map, is given in Eq. (14).
Xk þ 1 ¼ cos k cos1 Xk
ð
Þ


ð14Þ
Also, the chaotic, random number the authors have added a cosine term which is
helpful to explore the search space in a superior manner. This cosine variable [45] is
helpful to increase the search space in a better manner after utilizing fewer resources.
Once the cosine variable is introduced, Eq. (15) can be revised into the following form.
rGen ¼ Genmax  Gen
ð
Þ
Genmax
ð
Þn
n
 cos Gen
ð
Þ
j
j  rinitial  rfinal
ð
Þ þ rfinal
ð15Þ
Finally, the developed seeds are grown into a ﬂowering weed and are located in the
weed colony along with the parent weeds, and the elimination is performed based on the
ﬁtness value. Moreover, the newly developed seeds and their locations on the search space
Design and Comparison of Two Evolutionary and Hybrid
353

are ranked along with their parent weeds. Based on the fast reproduction of the seeds, the
population size in the exploration space will cross its maximum limit (Pmax) after certain
generations. Once the size of the population is reached the maximum, the fewer ﬁt weeds
are excluded, and the weeds that have superior ﬁtness are used for the subsequent gen-
eration. Further, the above procedure is repeated until the termination condition is reached.
4
Results and Discussions
In this chapter, the gains of the developed controllers are tuned with the help of a feed-
forward NN, and the weights of the network are trained by using MCIWO and PSO
algorithms. The results obtained are presented and discussed in the subsequent subsections.
Initialization:
Spatial dispersal:
Start
The total no of
Exit weeds = Colony
No
Yes
Competative Exclusion:
Use all the weeds and seeds in the colony
No
Yes
Stop criteria
Stop
Next generation
Keep the best Kp, Kd and Ki
Evaluate the fitness of weeds and seeds
Choose the better fitnessweeds and seeds 
in the colony equal to Pmax
exponent, sigma_initial, sigma_final, Smax and Smin
Generate uniform random weeds in the search space
Evaluate the fitness value i.e error for each parameter
and assign the rank for entire population
The newely produced seeds are normally 
distributed in the search space by varying SD
weeds and seeds > Pmax
and other parameters i.e Generations, initial pop, maximum pop
after including cosine and chaotic variables are introduced
Reproduction:
Based on the fitness of the weeds the new seeds will be produced
Choose the parmeters i.e weights of the neural network
Fig. 7. MCIWO algorithm
354
R. K. Mandava and P. R. Vundavilli

4.1
MCIWO-NN Approach
Initially, a study was conducted to examine the optimal number of neurons in the hidden
layer of the NN structure. While carrying out this study, the following parameters of
MCIWO are kept ﬁxed in this study: initial population (npopi) = 5, ﬁnal population
(npopf) = 15, minimum no. of seeds (Smin) = 0, maximum no. of seeds (Smax) = 5, ﬁnal
standard deviation (rﬁnal) = 0.00001, initial standard deviation (rinitial) = 3%, modu-
lation index (n) = 3, and maximum no. of generations (Gen) = 20 (Fig. 8).
14
16
18
20
22
0.06108
0.06110
0.06112
0.06114
0.06116
0.06118
Fitness
No.of hidden neurons
Hidden layer=Tansigmoid, Output layer= Logsigmoid, 
Max it=20, Initial_pop=5, Final_pop=15, Smin=0, 
Smax=5, Sigma_initial=3%, Sigma_final=0.00001
1
2
3
4
5
6
7
0.0609
0.0610
0.0611
0.0612
0.0613
0.0614
0.0615
0.0616
0.0617
Fitness
Exponent
Hidden layer=Tan sigmoid, Output layer=Logsigmoid, 
No.of hidden neurons=16, Max it=20, Initial_pop=5, 
Final_pop=15, Smin=0, Smax=5, Sigma_initial=4%, 
Sigma_final=0.00001
1%
2%
3%
4%
5%
0.061150
0.061155
0.061160
0.061165
0.061170
0.061175
Fitness
Initial standard deviation
Hidden layer=Tan sigmoid, Output layer=Log sigmoid, 
No.of Hidden neurons=16, Max it=20, Initial_pop=5, n=3, 
Final_pop=15, Smin=0, Smax=5, Sigma_final=0.00001
2
3
4
5
6
7
8
0.06115
0.06116
0.06117
0.06118
0.06119
0.06120
0.06121
0.06122
0.06123
Fitness
Maximum seeds (Smax)
Hidden layer=Tansigmoid, Output layer= Logsigmoid, 
No.of hidden neurons=16, Max it=20, Initial_pop=5, 
Final _pop=15, n=5, Smin=0, Sigma_initial=4%, 
Sigma_final=0.00001
5
10
15
20
25
30
0.06115
0.06116
0.06117
0.06118
0.06119
0.06120
0.06121
Fitness
Final_population
Hidden layer= Tansigmoid, Output layer=Logsigmoid, 
No. of hidden neurons=16, Max it=20, Initial_pop=5, n=5, 
Smin=0, Smax= 6, sigma_initial=4%, sigma_final=0.00001
0
5
10
15
20
25
30
35
40
45
50
0.06100
0.06105
0.06110
0.06115
0.06120
Hidden layer= Tansigmoid, Output layer=Logsigmoid, 
No. of hidden neurons=16, Max it=20, Initial_pop=5,
n=5, Smin=0, Smax= 6, sigma_initial=4%, 
sigma_final=0.00001, Final_population=25
Fitness
Generations
(a)
(b)
(c)
(d)
(e)
(f)
Fig. 8. Graphs showing results of systematic study for MCIWO-NN controller a hidden neurons
versus ﬁtness, b exponent versus ﬁtness, c initial standard deviation versus ﬁtness, d maximum
number of seeds versus ﬁtness, e maximum no. of population versus ﬁtness, and f generations
versus ﬁtness
Design and Comparison of Two Evolutionary and Hybrid
355

Moreover, the deviation of ﬁtness with the number of hidden neurons in the NN is
shown in Fig. 9a. It has been observed that the NN architecture with 16 numbers of
hidden neurons is found to provide better ﬁtness. As there are 12 inputs and 36 outputs,
the number of connecting weights in the network is found to be equal to 768
(12  16 + 16  36). After including two bias values, the number of variables related
to the problem is coming out to be 770. While solving the problem, the connecting
weights are varied between 0.0 and 16.0, and the bias values are varied between 0.0
and 0.0001. Further, the transfer functions used in the problem are set as linear, tan-
sigmoid, and log-sigmoid for the input, hidden, and output layers, respectively.
Once the study is completed, the optimal parameters related to the above-said
algorithm are given below.
Modulation index (n) = 5
Initial standard deviation (rinitial) = 4%,
Final population (npopf) = 25,
Maximum no. of seeds (Smax) = 6,
Maximum no. of generations (Gen) = 50.
14
16
18
20
22
0.06086
0.06088
0.06090
0.06092
0.06094
0.06096
0.06098
0.06100
Fitness
No.of hidden neurons
Input_layer=Linear, Hidden_layer=Tansigmoid, 
Output_layer=Logsigmoid, w=1, wdamp=0.9, 
C1=C2=2, Maxi_population=10, Max_Generations=20
10
20
30
40
50
0.06055
0.06060
0.06065
0.06070
0.06075
0.06080
0.06085
0.06090
Input_layer=Linear, Hidden_layer=Tansigmoid, 
No.of Hidden neurons=18, Output_layer=Logsigmoid,
 w=1, wdamp=0.9, C1=C2=2, Max_Generations=20
Fitness
Population size
0
5
10
15
20
25
30
35
40
45
50
0.0602
0.0604
0.0606
0.0608
0.0610
0.0612
Input_layer=Linear, Hidden_layer=Tansigmoid, 
Output_layer=Logsigmoid, w=1, wdamp=0.9, 
C1=C2=2, Maxi_population=30
Fitness
Generations
(a)
(b)
(c)
Fig. 9. Graphs are showing results of the systematic study for PSO-NN controller a hidden
neurons versus ﬁtness, b ﬁnal population size versus ﬁtness, c maximum no. of generations
versus ﬁtness
356
R. K. Mandava and P. R. Vundavilli

4.2
PSO-NN Approach
Similarly, here also a study has been conducted to calculate the suitable number of
neurons at the hidden layer of the network. The following parameters of PSO are used
to perform this study: inertia weight (w) = 1, inertia weight damping ratio (wdamp) =
0.9, acceleration constants C1 = C2 = 2, maximum population size and the no. of
generations are equal to 10 and 20, respectively. To enhance the performance of NN,
the optimal no. of neurons at the hidden layer is equal to 18, and the total no. of
variables are required to the present problem is 866. Moreover, the coefﬁcient of
transfer functions used for the three layers is the same as the one used in the MCIWO-
NN approach. Further, the optimal values of the parameters achieved after the para-
metric study (Fig. 10) are mentioned below:
Population size (Pmax) = 30
No. of generations (Genmax) = 50.
Fig. 10. Comparison of error at different joints of the swing leg a joint 2, b joint 3, c joint 4, and
d joint 5
Design and Comparison of Two Evolutionary and Hybrid
357

4.3
Comparative Study
Once the optimal structure has been obtained for the NN-based PID controllers, a
comparative study was conducted among the PSO-NN, and MCIWO-NN tuned con-
trollers regarding the variation of angular error, average torque essential for every joint,
deviation of ZMP in foot, and DBM of the two-legged robot. Further, the quality of
solutions obtained by the PSO-NN and MCIWO-NN tuned controllers are measured in
simulations.
Figure 10a–d shows the deviation of error at various joints of the swing leg of the
robot. Based on Fig. 10a–d, it is seen to be observed that the magnitude of the error is
low in MCIWO_NN-based controller compared to PSO-NN based controllers at the
beginning and decreases slowly as it reaches steady state after a certain amount of time.
Moreover, it can also be observed that the both MCIWO-NN and PSO-NN based
controllers reach the steady-state error by showing the same trend, but for PSO-NN
based PID controller, the steady state has not been settled to zero. Similarly, the results
related to the standing leg for deviation of error at different joints of the two-legged
robot are shown in Fig. 11a–d, respectively.
Fig. 11. Comparison of error at different joints of the standing leg a joint 8, b joint 9, c joint 10,
and d joint 11
358
R. K. Mandava and P. R. Vundavilli

Further, Fig. 12a and b shows the results associated with the torque required at
different joints of the swing and stand leg, respectively. Based on these graphs, the
MCIWO-NN controller has consumed less torque when compared with the PSO-NN
tuned PID controller and has exhibited a similar trend. Moreover, the torque required at
the hip joint in both the legs that are joint 3 and joint 9 is seen to be high when
compared with the remaining joints of the two-legged robot in both MCIWO-NN and
PSO-NN based PID controllers. It may happen due to the reason that while moving the
robot from one point to another, the hip joint of the robot is carrying the other links of
the leg of the two-legged robot.
Fig. 12. The torque required at various joints of the a swing leg and b stands leg
-0.05
0.00
0.05
0.10
0.15
0.20
0.25
0.30
0.35
-0.3
-0.2
-0.1
0.0
0.1
0.2
0.3
 IWO-NN
 PSO-NN
 MCIWO-NN
Y-ZMP in 'm'
X-ZMP in 'm'
-0.030 -0.025 -0.020 -0.015 -0.010 -0.005 0.000
0.005
0.010
-0.095
-0.090
-0.085
-0.080
-0.075
-0.070
-0.065
Y-ZMP in 'm'
X-ZMP in 'm'
 IWO-NN
 PSO-NN
 MCIWO-NN
Enlarged view
Fig. 13. Deviation of ZMP a X-ZMP and b Y-ZMP
Design and Comparison of Two Evolutionary and Hybrid
359

Based on the above comparisons, a systematic study was conducted to see the
deviation of ZMP in both X- and Y-directions of the gait obtained (actual gait) after the
controller action. Figure 13 shows the plan view of the variation of actual ZMP in both
X- and Y-directions when the robot is moving on a ﬂat surface. It can be observed that
the X-ZMP point is moving from the rear side of the ankle joint toward the front side of
the same, whereas Y-ZMP is moving from the right side of the ankle joint to toward the
left side of the same. Further, it can also be observed that the position of ZMP is seen to
be very adjacent to the center of the foot in MCIWO-NN controller when compared
with the other two (IWO-NN and PSO-NN) algorithms. Finally, the generated gait is
found to be balanced in nature when the ZMP is inside the foot support.
Further, Fig. 14a, b shows the comparative study between DBM in X- and Y-
directions for IWO-NN, PSO-NN, and MCIWO-NN algorithms applied when the two-
legged robot is walking on the ﬂat surface. It has been observed that MCIWO trained
neural network-based PID controller has generated high dynamically balanced gaits
when compared with PSO trained neural network-based PID controller. Finally, the
gait angles generated by the MCIWO-NN based PID controller are fed into the real
two-legged robot (Fig. 15). It can be observed that the two-legged robot has well-
performed walk on the ﬂat surface with the help of the gait generated using MCIWO-
NN based controller.
5
Conclusions
The main aim of this chapter is to development of an adaptive PID controller for the
two-legged robot to walk on ﬂat terrain. MCIWO and PSO learning algorithms are used
to train the feed-forward artiﬁcial neural network. Further, the simulation results show
that together, the MCIWO and PSO algorithms produce high-quality solutions and can
develop balanced gaits for the two-legged robot. Moreover, it has been seen that the
gaits generated by using MCIWO-NN based PID controller are seen to develop
high dynamically balanced when compared with the PSO-NN based PID controller.
Fig. 14. Comparison of DBM a X-direction and b Y-direction
360
R. K. Mandava and P. R. Vundavilli

This may be due to the intention that the MCIWO algorithm has enhanced the search
space due to the inclusion of cosine variable and minimized the chances to grasp local
optimum solution due to the chaotic variable when compared with the PSO algorithm.
Later on, both algorithms have been tested in computer simulations. The learning time
for MCIWO-NN algorithm with a population size often for twenty numbers of gen-
erations is seen to be equal to 120 min on a Dell PC with Intel 3.30 GHz processor and
a RAM of 8 GB. However, the CPU time required for the execution of the adaptive NN
controller to generate the gains is found to be equal to 0.018 s on the same computer.
Finally, the optimal gait data obtained from MCIWO-NN is fed into the real two-
legged robot and seen that the robot has effectively negotiated the ﬂat terrain.
References
1. Juricic D, Vukobratovic M (1972) Mathematical modeling of biped walking systems. ASME
Publ. 72-WA/BHF13
2. Takanishi TM, Kaharaki H, Kato (1989) I Dynamic biped walking stabilized with optimal
trunk and waist motion. In: IEEE/RSJ international workshop on intelligent robots and
systems, 4–6 Sept 1989. Tsukuba, Japan, pp 187–192
3. Goswami (1999) Foot rotation indicator (FRI) point: a new gait planning tool to evaluate
postural stability of biped robots. In: IEEE international conference on robotics and
automation, May 1999. Detroit, Michigan, pp 47–52
4. Mitobi K, Capi G, Nasu Y (2004) A new control method for walking robots based on
angular momentum. Mechatronics 14:163–174
Fig. 15. Snapshots show the two-legged robot walking on the ﬂat surface
Design and Comparison of Two Evolutionary and Hybrid
361

5. Sano A, Furusho J (1990) Realization of natural dynamic walking using the angular
momentum information. In: IEEE international conference on robotics and automation,
pp 1476–1481
6. Seo YJ, Yoon YS (1995) Design of a robust dynamic gait of the biped using the concept of
dynamic stability margin. Robotica 13:461–468
7. Vundavilli Pandu R, Sahu SK, Pratihar DK (2007) Dynamically balanced ascending and
descending gaits of a two-legged robot. Int J Humanoid Rob 4(4):717–751
8. Vundavilli PR, Pratihar DK (2011) Balanced gait generations of a twolegged robot on
sloping surface. Sadhana Acad Proc Eng Sci 36(4):525–550
9. Nguyen T, Tao L, Hasegawa H (2017) The effect of foot structure on locomotion of a small
biped robot. In: MATEC web of conferences, vol 95
10. Mohammad R, Noorani S, Rashidi SF, Maryam S (2017) Gait generation and transition for
bipedal locomotion system using Morris-Lecar model of central pattern generator,
ScientiaIranica
11. Zhong Q-B, Fei C (2016) Trajectory planning for biped robot walking on uneven terraine
taking stepping as an example. CAAI Trans Intell Technol 1:197–209
12. Gupta G, Dutta A (2018) Trajectory generation and step planning of a 12 DoF biped robot
on uneven surface. Robotica, Cambridge University, pp 1–26
13. Visioli A (2001) Tuning of PID controllers with fuzzy logic. IEEE Proc Control Theory
Appl 148(1):1–8
14. Azimi SM, Miar-Naimi H (2018) Design an analog CMOS fuzzy logic controller for the
inverted pendulum with novel triangular membership function. ScientiaIranica. https://doi.
org/10.24200/SCI.2018.5224.1153
15. Mandava RK, Vundavilli PR (2015) Design of PID controllers for 4-DOF planar and spatial
manipulators. In: IEEE international conference on robotics, automation, control and
embedded systems, 18–20 Feb 2015. Hindustan University, Chennai, India, pp 1–6
16. Kazemian HB (2002) The SOF-PID controller for the control of a MIMO robot arm. IEEE
Trans Fuzzy Syst 10(4)
17. Helon VHA, dos Leandro SC (2012) Tuning of PID controller based on a multi-objective
genetic algorithm applied to a robotic manipulator. Expert Syst Appl 39(10):8968–8974
18. Gutierrez LB, Lewis FL, Lowe JA (1998) Implementation of a neural network tracking
controller for a single ﬂexible link: comparison with PD and PID controllers. IEEE Trans Ind
Electron 45:307–318
19. Sonmez M, Kandilli I, Yakut M (2006) Tracking control based on neural network for robot
manipulator. In: Artiﬁcial intelligence and neural networks, volume 3949 of the series lec-
ture notes in computer science, pp 49–57
20. Pirabakaran K, Becerra V (2002) PID autotuning using neural networks and model reference
adaptive control. 15th Triennial IFAC World Congress, Spain
21. Joel Perez P, Jose PD, Rogelio S (2012) Trajectory tracking error using PID control law for
two-link robot manipulator via adaptive neural networks. In: The Iberomerican conference
on electronics engineering and computer science published in procedia technology, vol 3,
pp 139–146
22. Zang X, Liu Y, Liu X, Zhao J (2016) Design and control of a pneumatic musculoskeletal
biped robot. Technol Health Care 24:S443–S454
23. Zhong QB, Chen F (2016) Trajectory planning for biped robot walking on uneven terrain—
taking stepping as an example. CAAI Trans Intell Technol 1:197–209
24. Ravi KM, Vundavilli PR (2018) Near optimal PID controllers for the biped robot while
walking on uneven terrains. Int J Autom Comput 15(6):689–706
25. Montana DJ, Davis L (1989) Training feed forward neural networks using genetic
algorithms. Mach Learn 762–767
362
R. K. Mandava and P. R. Vundavilli

26. Asadi H, Tavakkoli Moghaddam R, Shahsavari Pour N, NajaﬁE (2018) A new
nondominated sorting genetic algorithm based to the regression line for fuzzy trafﬁc signal
optimization problem. Scientia Iranica E 25(3):1712–1723
27. Alikhani H, Alvanchi A (2017) Using genetic algorithms for long-term planning of network
of bridges. ScientiaIranica. https://doi.org/10.24200/SCI.2017.4604
28. Gudise VG, Venayagamoorthy GK (2003) Comparison of particle swarm optimization and
back propagation as training algorithms for neural networks. IEEE Swarm Intell Symp 110–117
29. John Paul TY (2013) Optimizing artiﬁcial neural networks using cat swarm optimization
algorithm. Int J Intell Syst Appl 1:69–80
30. Blum C, Socha K (2005) Training feed-forward neural networks with ant colony
optimization: an application to pattern classiﬁcation. In: ﬁfth international conference on
hybrid intelligent systems
31. Moeini R (2017) Arc based ant colony optimization algorithm for solving sewer network
design optimization problem. ScientiaIranica A 24(3):953–965
32. Askarzadeh A, Rezazadeh A (2013) Artiﬁcial neural network training using a new efﬁcient
optimization algorithm. Appl Soft Comput 1206–1213
33. Giri R, Chowdhury A, Ghosh A, Das S, Abraham A, Snasel V (2010) A modiﬁed invasive
weed optimization algorithm for training of feed-forward neural networks. In: IEEE
international conference on systems man and cybernetics, pp 3166–3173
34. Ge SS, Hang CC, Woon LC (1997) Adaptive neural network control of robot manipulators
in task space. IEEE Trans Ind Electron 44(6):746–752
35. Woon LC, Ge SS, Chen XQ, Zhang C (1999) Adaptive neural network control of
coordinated manipulators. J Robotic Syst 16(4):195–211
36. Sun TR, Pei HL, Pan YP, Zhou HB, Zhang CH (2011) Neural network-based sliding mode
adaptive control for robot manipulators. Neurocomputing 74(14/15):2377–2384
37. Rahmani M, Ghanbari A, Ettefagh MM (2016) A novel adaptive neural network integral
sliding-mode control of a biped robot using bat algorithm. J Vib Control 23:1–16
38. Yazdani M, Salarieh H, Saadat Foumani M (2018) Hierarchical decentralized control of a
ﬁve-link biped robot. ScientiaIranica B 25(5):2675–2692
39. Ravi KM, Pandu RV (2018) Whole body motion generation of 18-DOF biped robot on ﬂat
surface during SSP and DSP. Int J Model Identif Control 29(3):266–277
40. Mehrabian AR, Lucas C (2006) A novel numerical optimization algorithm inspired from
weed colonization. Ecol Inf 1(4):355–366
41. Ahmadi M, Mojallali H (2012) Chaotic invasive weed optimization algorithm with
application to parameter estimation of chaotic systems. Elsevier Chaos Solitons Fract
45:1108–1120
42. Ghasemi M, Ghavidel S, Aghaei J, Gitizadeh M, Falah H (2014) Application of chaos-based
chaotic invasive weed optimization techniques for environmental OPF problems in the
power system. Elsevier Chaos Solitons Fract 69:271–284
43. Basak A, Pal S, Das S, Abraham A (2010) A modiﬁed invasive weed optimization algorithm
for time-modulated linear antenna array synthesis. IEEE Congress Evol Comput 1–10
44. Roy GG, Das S, Chakraborty P, Suganthan PN (2011) Design of non-uniform circular
antenna arrays using a modiﬁed invasive weed optimization algorithm. IEEE Trans
Antennas Propag 59(1):110–118
45. Ravi KM, Pandu RV (2018) Implementation of modiﬁed chaotic invasive weed optimization
algorithm for optimizing the PID controller of the biped robot. Sadhana Acad Proc Eng Sci
Springer 43(3):1–18
Design and Comparison of Two Evolutionary and Hybrid
363

Optimizing the Crane’s Operating Time
with the Ant Colony Optimization and
Pilot Method Metaheuristics
Andresson da Silva Firmino(B), Val´eria Ces´ario Times, and Ricardo Martins
de Abreu Silva
Center for Informatics, Federal University of Pernambuco, Recife, PE, Brazil
{asf2,vct,rmas}@cin.ufpe.br
1
Introduction
In container terminals, due to restricted space in the storage area, containers are
piled up vertically, creating various stacks. The stacks are grouped into blocks
and these are distributed over the container yard and delimited by terminal traf-
ﬁc lanes. A block consists of a parallel group of bays, and a bay consists of a
parallel array of stacks, as illustrated in Fig. 1. A longitudinal section of con-
tainers in a bay denotes a tier. The maximum stack height delimits the number
of tiers of the bay. A rail-mounted gantry crane is regularly used to operate
containers in a block. In this crane model, for many reasons, including safety
issues, the cranes mostly cannot travel across bays while sustaining a container
[3]. Thus, the movement of containers occurs between stacks in the same bay,
and the containers are accessed from the sides of the bay [20].
Fig. 1. A single container block divided into bays, stacks, and tiers
c
⃝Springer Nature Singapore Pte Ltd. 2020
M. Khosravy et al. (eds.), Frontier Applications of Nature Inspired Computation,
Springer Tracts in Nature-Inspired Computing,
https://doi.org/10.1007/978-981-15-2133-1_17

Optimizing the Crane’s Operating Time with the Ant Colony
365
The crane performs two operations: relocation, when a container located at
the top of a stack is transferred to the top of another stack, and retrieval, when a
container placed at the top of a given stack is moved outside the bay. Moreover,
in a bay, each container is assigned a value indicating a retrieval priority such
that all the containers are sequentially retrieved from the bay according to their
priorities. The container priorities are usually assigned to ships’ stowage plans
to ensure the ship’s stability and the container retrieval sequences demanded by
the ports that the ships will visit.
Retrieving a container that is not on top of a stack implies relocating contain-
ers above it to other stacks in the bay. These additional operations waste time,
consequently reducing the productivity of the container retrieval operations, as
well as the eﬃciency of a container terminal. Finding an optimal sequence of
operations for the crane, enabling it to retrieve all the containers from the bay
according to their retrieval priorities, is known as the container retrieval prob-
lem (CRP). The optimal sequence of operations is obtained by minimizing the
operating time of the crane, and thus maximizing the container’s removal eﬃ-
ciency, bearing in mind that operating time is one of the primary measures used
to evaluate the performance of ports [31].
Figure 2 illustrates an example of a CRP solution for an instance with eight
containers, four stacks and four tiers. The bay is displayed as a two-dimensional
Fig. 2. A representation of a solution for the container retrieval problem

366
A. da Silva Firmino et al.
storage structure for the sake of simplicity, since the number of stacks and tiers
delimits the bay dimensions and the bay stores uniformly shaped containers.
The black-bordered boxes represent the bay slots, where the numbered white
boxes indicate the slots occupied with containers (numbered according to their
priorities) and the others denote empty slots. In this example, the crane per-
formed four relocations and eight retrievals (i.e., twelve operations enumerated
from A to L), and all retrievals occurred at the upper right corner of the bay.
In relocation operations (A), (C), (E), and (J), respectively, the containers 8,
4, 6, and 8 (again) were relocated, allowing for all containers to be retrieved.
Note that the relocation operations are performed whenever the highest priority
container is currently placed at the top of a stack. For example, the retrieval
operation (B) occurs when the container with priority one is at the top of the
ﬁrst stack, and thus, the operation (B) retrieves the container with priority one
from the bay.
The logistic optimization in the container terminals has been increasingly
relevant for the scientiﬁc literature. One reason for that is the increase in the rates
of container port traﬃc over the last few decades [34]. Dealing with the heavy
traﬃc at container terminals requires the development of strategies to reduce
operational costs and increase terminal eﬃciency. Reﬂecting these trends, this
paper tackles the CRP with the aim of optimizing the crane’s operating time, a
relevant issue for reaching high yard operational eﬃciency in a container terminal
system. Moreover, metaheuristic algorithms are increasingly present in various
applications for diﬀerent domains in order to provide solutions to complicated
problems [5]. Hence, this paper proposes algorithms for the CRP based on the
metaheuristics: ant colony optimization (ACO) and pilot method.
It is also worth pointing out that although the relocation operations are time-
consuming and have to be avoided as much as possible, obtaining the solution
with the minimum crane’s operating time, by seeking the sequence of operations
with the minimum number of relocations, is not reliable. Lin et al. [20] have
already reported that the number of relocations and the crane’s operating time
do not necessarily mirror each other. Furthermore, da Silva Firmino et al. [27]
have proved that minimizing the number of relocations does not ensure the
solution with the minimum operating time for the CRP. Therefore, unlike most
studies, where algorithms have been proposed for the CRP in order to reduce
the number of relocation operations, this study proposes algorithms to lower the
crane’s operating time.
The next section reviews related work and presents the main approaches to
the CRP, connecting some of them to the approach of this work. Section 3 deﬁnes
the CRP and how the crane’s operating time is computed in this problem. Then,
Sect. 4 introduces the proposed heuristic algorithm for solving the CRP, which is
used as a constructive heuristic by the other algorithms proposed in this paper.
Afterward, Sects. 5 and 6 describe the proposed algorithms based, respectively,
on the ant colony optimization (ACO) and pilot method metaheuristics. The
computational experiments conducted are covered in Sect. 7. Finally, conclusions
and directions for future research are discussed in Sect. 8.

Optimizing the Crane’s Operating Time with the Ant Colony
367
2
Related Work
Several approaches have been proposed to solve the CRP problem, which belongs
to the NP-hard optimization problem category [4]. In literature, the CRP is also
known as the Block Relocation Problem [2], the Block Retrieval Problem [25], and
the Container Relocation Problem [9]. Traditionally, the CRP’s main optimiza-
tion goal is to reduce the number of relocation operations, because having a lower
number of relocations, empirically, implies a lower operational indicator—e.g.
time, energy, labor, equipment maintenance, and money consumed—to retrieve
all containers from the bay. In this respect, optimal approaches can be found
in [1,9,18,23,28,36], and near-optimal approaches in [2,13–15,29,30] in order
to handle larger instances. The optimal approaches ensure the optimal solution,
but due to the NP-hardness of CRP, the size of the problem instances that
such approaches can solve is very limited when compared to the near-optimal
approaches, where near-optimal solutions are pursued.
Nevertheless, minimizing the number of relocations does not ensure solutions
with the crane’s minimum operating indicator. For example, [20,27] indicate
that the number of relocation operations and the crane’s operating time are not
always proportionate, and [27] shows that minimizing the number of relocations
does not guarantee the solution for the crane’s minimal operating time. Accord-
ingly, there are a few other works that tackle with other optimization goals that
diﬀer from the number of relocations. In [11,26,32], the objective function is to
minimize, respectively, the fuel consumption, the horizontal travel distance of the
crane and the crane’s trajectory. The studies in [8,12,14,17,19,20,27] address
the crane’s operating time.
Regarding these studies that aim to minimize the crane’s operating time,
there are divergences in the computation of the crane’s operating time. Hence,
sometimes the crane’s operating times are not directly comparable, as stated in
[20]. For example, in [9] authors proposed an Integer Linear Programming (ILP)
formulation to minimize the crane’s travel time, but the travel time does not
consider the crane’s vertical travel time. Another example is found in [12,14],
where the crane’s operating time contemplates the crane’s horizontal and vertical
travel times. However, the travel time needed to align the crane’s spreader before
conducting any operation (i.e., relocation or retrieval) was not taken into con-
sideration for computing the crane’s operating time, as performed in [17,20,27]
and this study.
In particular, the algorithms proposed in [17,20,27] have produced good
results in reducing the crane’s total operating time. Lin et al. [20] minimize
the number of relocations, but also use in its heuristic a penalty function to
minimize the crane’s operating time. Kim et al. [17] proposed a heuristic based
on four circumstances present on a container bay. The two heuristics of [17,20]
have shown better results than the heuristic proposed in [19] in terms of reducing
the crane’s total operating time. da Silva Firmino et al. [27] developed an A*
search algorithm, an optimization model and a reactive GRASP algorithm to
minimize the operating time for the restricted CRP. The reactive GRASP algo-

368
A. da Silva Firmino et al.
rithm was able to achieve better results than the heuristic in [17], even though
this heuristic was designed for the unrestricted CRP.
According to the relocation fashion, there are two versions of CRP: the
restricted CRP and the unrestricted CRP. In the restricted CRP, the source
stack of each relocation is restricted to the stack in which the container with
the highest priority is currently located, whereas in the unrestricted CRP, such
constraint is not imposed. As an example, Fig. 2 displays a restricted CRP solu-
tion with four restricted relocations. Though most studies focus on the restricted
CRP, the unrestricted CRP yields more opportunities for optimization than the
restricted version, as mentioned in [30]. In other words, better solutions can be
achieved in the unrestricted CRP, since promising relocations may be done. Relo-
cations are considered promising if they are not restricted and involve moving a
container that needs to be relocated sooner or later in a way that results never
having to relocate it again. Thus, this work addresses the unrestricted CRP, as
done in a few other works, e.g., [7,13,17,20,30].
The pilot method [33] metaheuristic has already been used for optimizing
the unrestricted CRP. Tricoire et al. [30] proposed a pilot method algorithm and
a constructive heuristic utilized by this algorithm. However, the proposed pilot
method algorithm and its constructive heuristic were designed to minimize the
number of relocation operations rather than the crane’s operating time. Simi-
larly, the ant colony optimization (ACO) [6] metaheuristic has also been applied
for optimizing the unrestricted CRP. Jovanovic et al. [14] proposed an ACO
algorithm and a greedy heuristic used by this algorithm to minimize the num-
ber of container relocations. Jovanovic et al. [14] also explain how the proposed
algorithms can be extended to minimize the operating time. Nonetheless, as
mentioned, the crane’s operating time covered in [14] does not consider the time
required to align the crane’s spreader before performing any operation.
Taking all these into consideration, this paper diﬀers from earlier works for
the following reasons. Firstly, unlike the majority of studies, it addresses the
unrestricted CRP for optimizing the crane’s operating time. In addition, the
crane’s operating time covered in this paper is more complete than the one
deﬁned in [14], since our crane’s operating time computes the total time elapsed
(horizontal and vertical) for the crane to empty the bay, including the time
needed to align the crane’s spreader, as employed in [27].
Secondly, our approach for deﬁning the pheromone matrix diﬀers from that
of [14]. The pheromone matrix deﬁned in [14] consists of a multidimensional
array that stores information about diﬀerent bay conﬁgurations. However, this
multidimensional approach for deﬁning the pheromone matrix may generate a
high memory cost, as mentioned in [14]. In this work, such problem is avoided by
dynamically allocating pheromone values only for the encountered bay conﬁgu-
rations. Also, with respect to the crane’s operating time covered in this paper,
our ACO algorithm works with a diﬀerent heuristic function and a lower bound
to decide how to build the CRP solutions. Lastly, a constructive heuristic to
quickly build high-quality solutions, in terms of the crane’s operating time, is
developed. An ACO algorithm and a pilot method algorithm are also presented,
both making use of the constructive heuristic to ﬁnd even better solutions.

Optimizing the Crane’s Operating Time with the Ant Colony
369
3
Deﬁnition of the CRP
The CRP consists of ﬁnding a sequence of operations for the crane, enabling it
to retrieve all the containers from the bay according to their retrieval priorities,
where the optimal sequence of operations is that with the minimum operat-
ing time spent by the crane. The bay has the maximum width W and max-
imum height H and originally accommodates N containers, labeled 1, . . . , N.
The coordinates (i, j) indicate each slot within the bay, where i ∈{1, . . . , W}
and j ∈{1, . . . , H}, which denotes the stack and the tier within the bay, respec-
tively. Besides, v(c) indicates the value of retrieval priority for a container c,
where v(c) ∈{1, . . . , N}, and all containers are of the same size. Finally, the
initial conﬁguration of the bay is known in advance, and the relocation and
retrieval operations form the sequence of operations of the crane. These opera-
tions consume operating time and are subject to the following constraints:
– Each operation performed by the crane produces a bay conﬁguration (or
state), and the next crane operation must be conducted recognizing this new
conﬁguration.
– Only the container with the highest priority can be retrieved, and when a
container is retrieved, it is removed from the bay.
– The retrieval operation of container c, such that v(c) = N, deﬁnes the last
operation of the crane.
– Only containers from the top of a stack can be accessed (i.e., retrieved or
relocated).
– The relocation operations move containers to the top of stacks, and when a
stack is empty, the top is the ground (i.e., tier 1).
– The following relocation operations are not allowed: (1) from a stack i to the
same stack i; (2) to a tier l such that l > H, i.e., it does not comply with the
maximum height; (3) to a stack (k) such that k > W, i.e., it does not comply
with the maximum width.
– The crane’s spreader moves containers horizontally on height H + 1.
– In the restricted CRP, only the restricted relocation operations are allowed,
that is, the source stack of each relocation is restricted to the stack in which
the container with the highest priority is currently located.
A mathematical model for the CRP with a focus on minimizing the crane’s
operating time has been deﬁned in [27]. At the CRP resolution, in each bay
conﬁguration examined, when the container with the highest priority is not cur-
rently located at the top of an existing stack, a relocation operation needs to be
selected among all eligible relocations and then executed. Relocations are consid-
ered eligible if they comply with the constraints mentioned above. In addition to
the deﬁnitions presented so far, some notations used throughout this paper are
described below for a better understanding. Notations and deﬁnitions regarding
the crane’s operating time will be given in the following section.
– LCR expresses the list of candidate relocations to be executed by the crane
in a given bay conﬁguration. This list consists of all eligible relocations afore-
mentioned.

370
A. da Silva Firmino et al.
– ˘c and ˆc indicate, respectively, the container with the lowest priority and the
container with the highest priority that are present in the bay.
– The stack where ˆc is currently placed is designated as source stack, and ¯c
denotes the container located at the top of the source stack.
– S indicates the set of stacks of the bay, and p(s) indicates the position of
stack s in the bay, where p(s) ∈{1, . . . , W}.
– h(s) denotes the value of the highest priority present in stack s, and if the
stack s is empty, h(s) = v(˘c) + 1.
– a blocking is the event where a higher priority container is below a container
of lower priority, noting that a smaller value indicates a higher priority.
3.1
The Crane’s Operating Time
The crane’s operating time is the total operating time (horizontal and vertical)
the crane spends to empty the bay, considering the operating time related to
any operation conducted by the crane, i.e., relocation and retrieval operations.
The operating time inherent to any operation done by the crane is calculated
according to the steps given below.
Fig. 3. Example of the representation of the coordinates in a bay
Firstly, some notations and assumptions will be introduced. Each crane’s
operation has an origin coordinate and a target coordinate. The retrieval oper-
ations have as its target coordinate ( ˆW, ˆH), where ˆW = W + 1 and ˆH = H + 1,
and thus any retrieval operation occurs at the upper right corner of the bay.
In the initial bay conﬁguration, the crane’s spreader is originally over the stack
1. Besides, d(s) denotes the distance from stack s to the exit position (i.e.,
|p(s) −ˆW|). Figure 3 illustrates the representation of the coordinates in a bay
with four stacks and three tiers. Note that the coordinates outside the bay (1, 4)
and (5, 4) are, respectively, the initial coordinate of the crane’s spreader (i.e.,
(1, ˆH)) and the target coordinate of any retrieval (i.e., ( ˆW, ˆH)).

Optimizing the Crane’s Operating Time with the Ant Colony
371
The operating time is computed using the traveled distances and the respec-
tive crane speeds: the speed of the trolley (i.e., the horizontal speed) and the
speed of the spreader (i.e., the vertical speed). Four crane speeds are considered:
the horizontal speed carrying a container (ν1), the horizontal speed no carrying
a container (ν2), the vertical speed carrying a container (ν3), and the vertical
speed no carrying a container (ν4).
The function w(f, i, j, k, l) (Eq. 1) deﬁnes the operating time the crane spends
to perform any operation. This function represents the traveling time to align
the crane’s spreader from coordinate (f, ˆH) to coordinate (i, j) and then move
the container from coordinate (i, j) to coordinate (k, l). The coordinate (f, ˆH)
indicates the previous coordinate of the crane’s spreader before moving the con-
tainer. The function w(f, i, j, k, l) contemplates the following six operating times:
1. The operating time resulting from moving the crane’s trolley from position f
to i horizontally without carrying any container (|f −i|).
2. The operating time resulting from lowering the crane’s spreader from tier g
to j without carrying any container in order to collect the container (|j −ˆH|).
3. The operating time resulting from lifting the container from tier j (|j −ˆH|).
4. The operating time resulting from moving the container from stack i to posi-
tion k (|i −k|).
5. The operating time resulting from lowering the container to tier l (|l −ˆH|).
6. The operating time resulting from returning the crane’s spreader to the top
without carrying any container (|l −ˆH|).
w(f, i, j, k, l) = |f −i|/ν2



(1)
+ |j −ˆH|/ν4



(2)
+ |j −ˆH|/ν3



(3)
+
|i −k|/ν1



(4)
+ |l −ˆH|/ν3



(5)
+ |l −ˆH|/ν4



(6)
(1)
This paper focuses on the unrestricted CRP for optimizing the crane’s oper-
ating time explained above and deﬁned in [27]. However, it is worth men-
tioning that all algorithms proposed in this paper and described in the next
sections can be extended to solve the restricted CRP. For this purpose, the
LCR, adopted by the algorithms proposed here, should be comprised solely of
restricted relocations.
4
The Heuristic Algorithm
The proposed heuristic to solve the CRP, optimizing the crane’s operating time,
is called Triad. This constructive heuristic employs the three criteria deﬁned
below to select the operations used for building the solution.
Criterion 1: In case there are eligible stacks s ∈S such that h(s) > v(¯c),
then select a stack s with the smallest d(s) in order to relocate ¯c that is block-
ing ˆc. The advantage of this criterion is twofold. The former aims to move the

372
A. da Silva Firmino et al.
source container ¯c to a stack without generating additional relocations (i.e., non-
blocking), regardless of the organization of the existing containers in that stack
(i.e., when h(s) > v(¯c)). The second consists in selecting the stack closest to
exit position (i.e., the smallest d(s)), thus lowering the trolley travel time when
retrieving ¯c.
Criterion 2: When Criterion 1 is met, as a result, a stack t is selected to
receive the container ¯c. If stack t has n + 1 available spaces for stacking and
there exists a set C with a maximum of n containers to be pre-relocated to
stack t before moving container ¯c into t, then Criterion 2 is applied as follows.
The containers q ∈C must satisfy two conditions, (1) h(t) > v(q) > v(¯c) to
prevent blocking; and (2) container q is located at the top of its stack, blocking
another container. Moreover, the containers in C are pre-relocated in ascending
order by priority so that the container with the lowest priority is pre-relocated
ﬁrst to the stack t, thus avoiding blocking. This second criterion characterizes
a CRP unrestricted approach because containers other than ¯c can be relocated
(i.e., pre-relocated). The beneﬁt of this pre-relocation is to transfer containers,
at a suitable time, to a stack where they no longer will be relocated, preventing
further relocations. Furthermore, only blocker containers are transferred (i.e.,
condition 2), meaning they will need to be relocated sooner or later because
they are blocking another container.
Criterion 3: If Criterion 1 cannot be met and there are eligible stacks s ∈S,
then select a stack s with the largest h(s) to relocate ¯c. Once ¯c has been placed
in the selected stack s, a blocking is produced because Criterion 1 is not fulﬁlled
(i.e., h(s) < v(¯c)). Consequently, ¯c must be relocated again in a future as near as
¯c is close to h(s). Therefore, the purpose of this criterion is to delay as much as
possible this second relocation of ¯c, selecting the stack with the largest h(s). This
way, the second relocation will occur with fewer containers in the bay, so that
an appropriate relocation is more easily found. The relocation (A), illustrated in
Fig. 2, exempliﬁes the use of this criterion. In this example, the container with
priority eight, at the top of the ﬁrst stack, needs to be moved to enable the
removal of the container with priority one (i.e., v(¯c) = 8 and v(ˆc) = 1). The
second stack (s2) and the fourth stack (s4) are the existing eligible stacks, and
h(s2) = 7 and h(s4) = 3. Note that Criterion 1 cannot be met because h(s2) and
h(s4) are smaller than v(¯c). Hence, the second stack was selected to relocate ¯c
according to Criterion 3, since h(s2) > h(s4). This selected relocation (i.e., (A))
allowed the next relocation of the container 8 (i.e., (J)) to take place as late as
possible and thus, to occur with far fewer containers in the bay.
The proposed heuristic receives as input a partial solution to be built accord-
ing to the informed bay conﬁguration. Algorithm 1 depicts the pseudocode of
this constructive heuristic. The algorithm’s iterations occur continually while the
bay (bay) is not empty (lines 1–20). At the start of each iteration, the algorithm
veriﬁes whether the container with the highest retrieval priority in the bay (i.e.,
ˆc) is currently located at the top of the stack (line 2). If so, the container is
retrieved, and hence a retrieval operation is produced (line 3). Otherwise, the
container located at the top of the source stack (i.e., ¯c) needs to be moved to
the top of another stack.

Optimizing the Crane’s Operating Time with the Ant Colony
373
Algorithm 1 Pseudocode of the Triad Heuristic for solving the CRP
Require: bay: bay conﬁguration
Require: solution: partial solution
Ensure: solution built
1: while bay is not empty do
2:
if ˆc is located at the top then
3:
operation ←produce a retrieval in bay by retrieving ˆc
4:
else
5:
t ←select a stack with Criterion 1
6:
if t is not nil and is an unrestricted CRP then
7:
C ←select a set of containers with Criterion 2
8:
while C is not empty do
9:
q ←select a container in C with Criterion 2
10:
operation ←produce a relocation in bay by moving q to the stack t
11:
add operation to solution
12:
end while
13:
operation ←produce a relocation in bay by moving ¯c to the stack t
14:
else
15:
t ←select a stack with Criterion 3
16:
operation ←produce a relocation in bay by moving ¯c to the stack t
17:
end if
18:
end if
19:
add operation to solution
20: end while
21: return solution
Since there may be various relocation options in the LRC, Criterion 1 is
applied to select a stack t to place the container ¯c. If there is such a stack t
and a CRP unrestricted approach is employed, then a set of containers C is
generated according to Criterion 2 (line 7). Next, as deﬁned in Criterion 2, each
container q ∈C is relocated to stack t producing relocation operations in the
solution (lines 9–11). When all containers in C are pre-relocated to stack t, then
¯c is relocated to stack t, and a relocation operation is produced (line 13). In case
Criterion 1 does not return any stack, Criterion 3 is triggered, and a relocation
operation is produced (lines 15–16). At the end of each iteration, the operation
produced in the iteration (operation) is added to the solution (line 19). Finally,
when the bay is emptied, the solution built is returned (line 21).
It is noteworthy that the Triad heuristic is an extension of the heuristic with
a penalty function developed in [20] for the unrestricted CRP. The main diﬀer-
ences between these two heuristics are as follows. Firstly, here, the condition for
pre-relocating a container is [h(t) > v(q) > v(¯c)], while in the original heuristic,
such condition is [(h(t) > v(q) > h(t) −5) ∧(v(q) > v(¯c))]. The original con-
dition was not adopted in the Triad heuristic because it limits the number of
containers that can be pre-relocated. Secondly, the Triad heuristic is proposed
as a constructive heuristic and, in addition, it has no penalty factor. Further-
more, the Triad heuristic can be used to solve the restricted CRP as well, since
it provides diﬀerent treatments for both approaches: restricted and unrestricted.

374
A. da Silva Firmino et al.
Fig. 4. Example of states and edges for an instance of the CRP
5
The ACO Algorithm
The ant colony optimization (ACO) metaheuristic [6] may be seen as an iterative
process in which each iteration consists, brieﬂy, in repeating three tasks until a
certain stopping criterion is reached. The ﬁrst task consists in having a colony
of n artiﬁcial ants, where each ant generates a path (i.e., a solution), even if it is
only a partial one, and deposits a certain amount of pheromone while walking.
This pheromone information is used to guide the path-construction tasks of other
ants. The second task involves evaporating a certain amount of pheromone. The
last task comprises updating the best solution found so far.
For solving the CRP, an ACO approach incorporating a constructive heuristic
is presented. This approach considers the CRP as a path-construction problem,
where nodes (or states) represent the bay conﬁgurations, and edges denote con-
tainer operations. Hence, the aim is to ﬁnd a (shortest) path from the initial state
to a ﬁnal state, exploring the states and their edges. The initial state is generated
from the initial bay conﬁguration, and each new state to be explored is generated
through one operation (i.e., retrieval or relocation). The ﬁnal state is achieved
when all containers are retrieved. Figure 4 illustrates this representation with an
instance considering 3 containers and 3 stacks, where the initial state is the left-
most, and the ﬁnal state is the rightmost. Regarding the constructive heuristic
incorporated in the proposed ACO approach, it extends partial solutions pro-
duced by the ants, while they are walking through the states and edges. The
constructive heuristic works as an additional, fast and smart ant, where this one
ant quickly ﬁnds a path (i.e., a solution), guided only by its heuristic knowledge.

Optimizing the Crane’s Operating Time with the Ant Colony
375
Moreover, the proposed ACO approach adopts a probabilistic transition rule
to decide how to expand a partial solution and a dynamical pheromone model
in order to collect the expertise acquired by the artiﬁcial ants. This expertise is
gained through the deposit and evaporation of pheromone, the latter using global
and local update rules. The proposed ACO algorithm diﬀers from existing ones
for the following reasons. First, a constructive heuristic has been incorporated
to ACO for extending partial solutions produced by the ants. Secondly, as men-
tioned previously, a dynamic pheromone model has been adopted to avoid a high
memory cost. More details about this model are given in the next section. Lastly,
the proposed ACO approach addresses the unrestricted CRP for optimizing the
crane’s operating time. Due to this optimization goal, the ACO approach’s imple-
mentation needed to be customized to achieve this optimization goal. Therefore,
the following sections describe the pheromone model, the transition rule, the
local and global update rules, and the implementation details of the proposed
ACO algorithm for the CRP.
5.1
The Pheromone Model
The proposed pheromone model considers a pheromone value τ(b,o) to each state-
operation pair (b, o), where b is a bay conﬁguration (i.e., a state) and o is an
eligible crane operation (i.e., an edge) originated from the b. Thus, the pheromone
values guide the ants to follow promising (compound) operations, according to
the current bay conﬁguration.
The number of possible bay conﬁgurations grows exponentially as the bay
dimension gets bigger, i.e., the number of stacks, tiers, and containers increase
[18]. Hence, due to this exponential growth, storing all pheromone values in a
statically allocated matrix may generate a high memory cost, as declared in
[14]. Therefore, in the pheromone model proposed here, the pheromone values
are dynamically created on-the-ﬂy and eﬃciently maintained in a hash table.
5.2
The Transition Rule
At the time that an ant reaches a state b, it is necessary to decide which edge
must be selected among all existing edges, originated from the b, in order to
proceed to the next state. When applied to the CRP, for the bay conﬁguration
represented by b, this transition rule consists in selecting a container operation
among the operations of the LCR. This selection is done based on a heuristic
function and the expertise stored in the pheromone model deﬁned below.
Let σ be a container operation that moves a container c to a stack s, i.e.,
σ = (c, s). Thus, the proposed heuristic function f(σ) is deﬁned by Eq. 2, and
this function is equivalent to the function f(c, s) (Eq. 3).
f(σ) = f(c, s)
(2)
f(c, s) =

d(s)/W + 1/v(c),
if h(s) > v(c),
M + 1/h(s),
otherwise;
(3)

376
A. da Silva Firmino et al.
The function f(σ) (through f(c, s)) indicates how much the operation σ is
desirable, where a smaller value indicates higher desirability. The most desirable
operations are those that produce no blocking (i.e., h(s) > v(c)). For this reason,
M is a “suﬃciently large” constant used by Eq. 3 to ensure low desirability for
operations that produce blocking. If all existing operations produce blocking,
the preferred operations are those whose stacks s have higher values of h(s)
(indicated by 1/h(s)), and thus, delaying as much as possible the next relocation
of the container c. Among non-blocking operations, the most desirable are those
whose stacks s are closer to the exit position and their containers c have lower
priority, respectively, indicated by d(s)/W and 1/v(c). This preference increases
the chances of container c being the next to be removed from the bay and of
container c staying closer to the exit position, by lowering the trolley travel time
when retrieving c.
For convenience, the heuristic function f ′(σ) (Eq. 4) is adopted instead of
function f(σ), since for f ′(σ), a higher value indicates higher desirability. This
way the value of f ′(σ) is inversely proportional to the value of f(σ), while one
(1) is added to avoid a division by zero. Once the proposed heuristic function
was speciﬁed, the function g(σ) is deﬁned by Eq. 5. This function computes the
product of the heuristic function f ′ by the corresponding pheromone value.
f ′(σ) =
1
1 + f(σ)
(4)
g(σ) = f ′(σ) ∗τ(b,σ)
(5)
Finally, the transition rule proposed is speciﬁed by the Eq. 6, applying the
function g(σ). This way the next operation is selected deterministically or non-
deterministically according to a condition that compares a random variable q ∈
(0, 1) with a parameter q0 used to deﬁne the exploration rate. In the ﬁrst case
(q < q0), the operation with the maximal value of g(σ) is selected . Otherwise,
when (q ≥q0 ), the probability distribution, deﬁned by Eq. 7, is applied for
selecting an operation. The probability of selecting an operation σ is proportional
to g(σ) and inversely proportional to the sum of all g(σ′) for all the relocations
found in the LCR.
select =

arg
max
σ∈LRC g(σ),
q < q0,
prob(σ),
q ≥q0
(6)
prob(σ) =
g(σ)

σ′∈LRC g(σ′)
(7)
5.3
Global and Local Update Rules
The global and local update rules specify when and how the pheromone values
are updated. The proposed ACO approach is based on the ant colony system
(ACS) [6]. Consequently, the global update rule is applied after each iteration

Optimizing the Crane’s Operating Time with the Ant Colony
377
of the colony of ants, and only the best solution found deposits pheromone. The
objective of this global update rule is to intensify the exploration around high-
quality solutions, reinforcing the selection of operations contained in the set of
best solutions found. This update rule is formally deﬁned using the equations
below.
val(sol) =
1
1 + t(sol) −LB
(8)
τ(b,σ) = (1 −p) ∗τ(b,σ) + p ∗Δτ, ∀(b, σ) ∈solbest, Δτ = val(solbest)
(9)
The function val(sol) (Eq. 8) measures the quality of a solution sol, where this
quality is inversely proportional to the diﬀerence between its operating time (i.e.,
t(sol)) and the lower bound LB. This LB denotes a lower bound for all possible
CRP solutions derived from the initial bay conﬁguration and is measured in
terms of the crane’s operating time. Our ACO approach adopts the lower bound
proposed in [27], which is employed as a heuristic function in an A* algorithm.
Note that the addition of one was utilized in Eq. 8 to avoid a division by zero.
Using the function val with the current best solution solbest (i.e., val(solbest)),
the variable Δτ stores the quality of solbest. This variable is utilized by Eq. 9
for updating the pheromone values associated only to the operations found in
solbest. Therefore, the global update rule is applied by the Eq. 9, where the
parameter p ∈(0, 1) speciﬁes the inﬂuence of the best found solutions regarding
the deposit of pheromone.
Another updating method is the local update rule, and its goal is to diver-
sify the exploration of the solution space by preventing the ants from selecting
the same operations found in a given solution. In our ACO approach, after an
ant i has generated a solution soli, the local update rule is applied using the
Eq. 10. The parameter ϕ ∈(0, 1) is used to specify the intensity of pheromone
evaporation in the local update rule.
τ(b,σ) = ϕ ∗τ(b,σ), ∀(b, σ) ∈soli
(10)
5.4
Implementation
The ﬁrst implementation details that must be explained for the proposed ACO
method are the initialization value and the minimal limit for the pheromone
model. To this end, the Eq. 11 deﬁnes the initial value (τ0) and the pheromone
minimal limit (τmin). Both values are based on the solution quality, since τmin
is related to the current best found solution solbest, and τ0 is associated to the
solution solinit found by the constructive heuristic when solving the initial bay
conﬁguration.
τ0 = val(solinit)
W
τmin = val(solbest)
W 2
(11)

378
A. da Silva Firmino et al.
Algorithm 2 outlines the proposed ACO algorithm for the CRP. The ﬁrst
step of the algorithm is to generate a solution solinit applying the constructive
heuristic to the initial state (stateinit), such that the initial state is created from
the initial bay conﬁguration (bay). Besides, the current best solution (solbest) is
initialized with solinit (lines 1–3). Next, the lower bound (i.e., LB) is calculated
based on the initial state of the bay (stateinit), and thus, the initial pheromone
value is computed (lines 3–4). The ACO iterations are performed until some
stopping criterion is met (lines 6–30). At each iteration, a colony with n ants is
created, and each of these ants generates a full or empty solution (lines 7–28).
Algorithm 2 Pseudocode of the ACO algorithm for solving the CRP
Require: bay: initial bay conﬁguration, q0: the exploration rate
Require: p: the pheromone deposit rate, ϕ: the pheromone evaporation rate
Ensure: best solution found
1: stateinit ←bay
2: solinit ←create an initial solution by the constructive heuristic using stateinit and
an empty solution as input
3: solbest ←solinit
4: calculate the lower bound LB based on stateinit
5: compute the initial pheromone value using LB and solinit
6: while stopping criteria not satisﬁed do
7:
for n ants do
8:
sol ←∅; state ←stateinit
9:
while state is not ﬁnal state do
10:
if ˆc is located at the top then
11:
operation ←produce a retrieval in state by retrieving ˆc
12:
else
13:
operation ←produce a relocation in state according to the transition
rule and with the exploration rate q0
14:
end if
15:
if operation = nil then
16:
sol ←∅; break while
17:
end if
18:
add operation to sol
19:
if operation is a relocation then
20:
solh ←create a solution by the constructive heuristic using state and
sol as input
21:
update solbest with the best solution between solbest and solh
22:
end if
23:
end while
24:
if sol <> ∅then
25:
apply the local update rule using sol and the evaporation rate ϕ
26:
update solbest with the best solution between solbest and sol
27:
end if
28:
end for
29:
apply the global update rule using solbest and the deposit rate p
30: end while
31: return solbest

Optimizing the Crane’s Operating Time with the Ant Colony
379
At the beginning of each ant’s iteration, the solution (solution) is initialized
with an empty set of operations and the current exploration state (state) is
initialized with the initial state (line 8). Then, the ant’s exploration starts and
is executed continuously until the ﬁnal state is achieved, i.e., the corresponding
bay is empty (lines 9–23). At the start of each exploration step, the algorithm
veriﬁes whether the container with the highest retrieval priority in the bay (i.e.,
ˆc) is currently located at the top of the stack (line 10). If so, the container
is retrieved, meaning a retrieval operation is produced (line 11). Otherwise, a
relocation operation needs to be selected from within the LRC according to the
transition rule and the exploration rate q0 (line 13).
It is worth pointing out that, in the composition of the LRC operations,
potentially unpromising operations are banned from this list to obtain explo-
ration eﬃciency. Also, an operation σ produces a state b and composes a partial
solution solpartial together with the previous operations. Then, σ is considered
as potentially unpromising if solpartial cannot be potentially used to generate a
solution that is better than the current best found solution. Thus, σ is excluded
from the LRC when the sum of lower bounds for the state b with the crane’s
operating time of solpartial is greater than or equal to the crane’s operating time
of the current best found solution. Moreover, when an operation σ that has han-
dled a container c is added to the current solution, any subsequent operation
that handles the same container c is also banned from the LRC.
If there is no operation to be added to the solution, then the solution gen-
eration is aborted, thus decreasing in computational cost (line 16). Otherwise,
the operation produced (operation) is added to the solution (line 18). When an
operation is produced (line 11 or 12), the bay’s current state (state) is updated
according to operation. After operation is added, the constructive heuristic is
used for generating an additional solution solh using the current state (state)
and the partial solution (sol) achieved by operation (line 20). Afterward, the
solution with the lowest crane’s operating time is assigned to solbest comparing
the current best solution (solbest) to the solution obtained by the heuristic (solh)
(line 21).
After generating a non-empty solution sol, the local update rule is applied to
the solution sol, and solbest is updated if sol is better than solbest (lines 25–26).
Subsequently, when all the n ants of a colony have generated their solutions,
the global update rule is applied (line 29). The algorithm ends when any of
the following stopping criteria is met: either the runtime limit is achieved, or
a maximum number of consecutive iterations is reached without improvements
in the quality of the solution generated by the ants. Finally, the best solution
found is returned (line 31).
6
The Pilot Method Algorithm
The pilot method is a metaheuristic which enhances the quality of a heuristic that
incorporates it, by providing an intelligent, constructive mechanism to evaluate
certain decisions [33]. This metaheuristic applies a constructive heuristic, called

380
A. da Silva Firmino et al.
pilot heuristic, as a lookahead sub-heuristic to guide a master building process
toward a more promising solution. Starting from an initial state, three tasks
are repeated in an iterative process until a given stopping criterion is reached.
The ﬁrst task is evaluating every possible construction step of the current state
using the solution produced by the pilot heuristic. The second task consists in
performing the step higher ranking, and as a result, a new state is generated and
set as the current state. The last task is updating the best solution found so far.
In this paper, regarding the implementation of the pilot method for the CRP,
the proposed Triad heuristic is used as a pilot heuristic. Besides, the initial state
is created from the initial bay conﬁguration, and each new state is generated
by one operation, i.e., a construction step, which can be either a retrieval or
relocation. The ﬁnal state is achieved when all containers are retrieved. In addi-
tion, a construction state includes the current bay conﬁguration and the partial
solution derived from all the operations performed to achieve this conﬁguration
from the initial bay conﬁguration.
Algorithm 3 outlines the proposed pilot method for the CRP. Initially, the
best solution (bestsol) and the initial state (state) are initialized (line 1). At
each iteration, all containers that can be removed from the bay are retrieved and
state is updated (line 3). Afterward, the variables to store the best descendant of
(state) and its respective cost are initialized (line 4). Then, all possibles descen-
dants from state are evaluated using the heuristic procedure (lines 5–14). This
procedure returns a solution found by the constructive heuristic (i.e., Triad),
taking into account the partial solution and the bay conﬁguration present in
the current state d. The descendant whose solution presents the shortest crane’s
Algorithm 3 Pseudocode of the Pilot Method algorithm for solving the CRP
Require: bay: initial bay conﬁguration
Ensure: best solution found
1: bestsol ←nil; state ←bay
2: while stopping criteria not satisﬁed do
3:
state ←remove all retrievable containers in state and get the resulting state
4:
bestdescend ←nil; bestcost ←∞
5:
for all d ∈descendants(state) do
6:
solution ←create a solution by the constructive heuristic using the partial
solution and the bay conﬁguration present in the state d
7:
if cost(solution) < bestcost then
8:
bestdescend ←d
9:
bestcost ←cost(solution)
10:
if bestsol = nil or bestcost < cost(bestsol) then
11:
bestsol ←solution
12:
end if
13:
end if
14:
end for
15:
state ←bestdescend
16: end while
17: return bestsol

Optimizing the Crane’s Operating Time with the Ant Colony
381
operating time (i.e., cost(solution)) is deﬁned as the best descendant (line 8). If
the best descendant ﬁnds a new best solution, bestsol is updated (lines 10–12).
The algorithm ends when any of the following stopping criteria is met, which
may be the ﬁnal state being achieved (i.e., when state is nil), but also a run-
time limit being reached, or a maximum number of consecutive iterations being
reached without presenting any improvements to the quality of the best solution.
Finally, the best solution found is returned (line 17).
7
Computational Experiments
In this section, computational experiments carried out with instances of diﬀerent
sizes are presented and used to assess the proposed algorithms, as well as to
compare their results to those of existing algorithms already applied for the CRP.
Experiments were carried out on a computer with Intel(R) Core(TM) i7-5500U
CPU @ 2.40 GHz, 16 GB of RAM and operating with Windows 10 Education 64
bits. The Mersenne Twister found in the Apache Commons Math 3.3 library was
the adopted randomness generator. The random seeds were instantiated from
decimal places of π (.1415926535897932 . . .) and grouped in ﬁve, e.g. seed1 =
14, 159, seed2 = 26, 535, seed3 = 89, 793, and so on.
All analyzed algorithms were programmed in Java language and tested on
the instances suite presented in [27]. In it, each problem instance results from
the combination of the number of stacks and tiers with several bay occupancy
rates, where containers are randomly spread within the bay and have distinct
priorities. This combination resulted in 1200 instances with storage capacities
ranging from 20 to 128 containers, where the instances were classiﬁed as large,
medium, normal, and small, according to their storage capacities.1 The storage
capacity is the product of the number of tiers by the number of stacks. For
example, a bay with 4 tiers and 6 stacks (4 × 6) has a storage capacity equal to
4 × 6 = 24. It is worth mentioning that the evaluated instances suite is comprised
of instances far larger than practical use, where the storage capacity is typically
about 24 and 60 containers [22,35].
In all algorithms analyzed, the crane’s operating time was computed using
the operating time function deﬁned by Eq. 1 of Sect. 3.1. The speed of the trolley
is 2.4 s per container width while loaded and 1.2 s per container width while
empty (i.e., ν1 =
1
2.4 and ν2 =
1
1.2). The speed of the spreader is 5.18 s per tier
while loaded and 2.59 s per tier while empty (i.e., ν3 =
1
5.18 and ν4 =
1
2.59).
Lastly, in all the computational experiments, the proposed ACO algorithm used
the standard values of the ACO parameters speciﬁed in [6]. The parameter values
are p = 0.1, ϕ = 0.9 and q0 = 0.9. Besides, the number of artiﬁcial ants in a
colony (i.e., n) is equal to the number of stacks in the bay.
7.1
Analysis of the Triad Heuristic Algorithm
In this section, we analyze the performance of the Triad heuristic by comparing
the Triad heuristic of Sect. 4 with other heuristic methods. Three heuristics algo-
1 The 1200 instances are available at www.cin.ufpe.br/∼asf2/csp/instances/.

382
A. da Silva Firmino et al.
rithms are evaluated: TRIAD, PENALTY, and CASE, which were all designed
to reduce the crane’s operating time for the unrestricted CRP. The former is
the Triad algorithm proposed in this paper. The second is the heuristic with a
penalty function deﬁned in [20]. Because the PENALTY heuristic is inﬂuenced
by the penalty factor, in our experiments, the penalty factor was set to 30. This
value was adopted because it has produced the best results in the experiments
carried out in [20] regarding the crane’s operating time. The last algorithm, pro-
posed in [17], is also a recent heuristic algorithm with good results in reducing
the operating time. All analyzed algorithms were executed 21 times for each of
the 1200 instances.
Fig. 5. A comparison of TRIAD, PENALTY, and CASE algorithms regarding the
crane’s operating time
The performance results for the TRIAD, PENALTY, and CASE algorithms
processed over the 1200 instances are shown in Fig. 5. This ﬁgure shows the total
crane’s operating time for the solutions obtained by the algorithms over the
instance classes. Also, this ﬁgure displays the percentage reduction values pro-
moted by the TRIAD algorithm. The computational results indicate that TRIAD
produces better results than PENALTY and CASE for all instance classes. The
crane’s operating time obtained by TRIAD generated the lowest value when
compared to the two other algorithms, with an operating time reduction of 2.7%
when compared to PENALTY and of 10.3% when compared to CASE. The total
operating time in hours was 32,284, 33,168, and 35,982 for TRIAD, PENALTY,
and CASE, respectively. Besides, as the instance sizes increase, the PENALTY
and CASE algorithms tend to degrade the quality of solutions. This adverse sit-
uation is better evidenced in large-sized problem instances, where the reduction
values were 3.6 and 11.0%. It is worth mentioning that the TRIAD, PENALTY,
and CASE algorithms reported an average runtime below one millisecond for

Optimizing the Crane’s Operating Time with the Ant Colony
383
the 1200 instances. Therefore, direct comparisons concerning average runtime
are not reported.
Finally, the nonparametric Wilcoxon Rank Sum test [24] has conﬁrmed the
statistical relevance of the obtained results. With 99% of conﬁdence, this non-
parametric test reported that there is a statistically signiﬁcant diﬀerence between
the quality of the solutions obtained with TRIAD, PENALTY, and CASE algo-
rithms. Therefore, the proposed algorithm TRIAD produced signiﬁcantly better
solutions than the other algorithms for reducing the crane’s operating time.
7.2
Analysis of the ACO Algorithm
This experiment aims to evaluate the performance of the proposed ACO algo-
rithm. Because randomness inﬂuences the ACO algorithm, it was executed 21
0 %
0.35 %
0.7 %
1.05 %
1.4 %
1.75 %
2.1 %
2.45 %
COEFFICIENT OF VARIATION
INSTANCES ORDERED BY STORAGE CAPACITY IN ASCENDING ORDER
SMALL
0 %
0.35 %
0.7 %
1.05 %
1.4 %
1.75 %
2.1 %
2.45 %
COEFFICIENT OF VARIATION
INSTANCES ORDERED BY STORAGE CAPACITY IN ASCENDING ORDER
NORMAL
0 %
0.35 %
0.7 %
1.05 %
1.4 %
1.75 %
2.1 %
2.45 %
COEFFICIENT OF VARIATION
INSTANCES ORDERED BY STORAGE CAPACITY IN ASCENDING ORDER
MEDIUM
0 %
0.35 %
0.7 %
1.05 %
1.4 %
1.75 %
2.1 %
2.45 %
COEFFICIENT OF VARIATION
INSTANCES ORDERED BY STORAGE CAPACITY IN ASCENDING ORDER
LARGE
Fig. 6. Coeﬃcient of variation for the solutions produced by ACO over the instances

384
A. da Silva Firmino et al.
times for each instance, and each execution used the random seed correspond-
ing to its execution number. For example, execution 1 used seed1, whose value
is 14,159, while execution 2 used seed2, whose value is 26,535, and so on. The
ACO algorithm was executed with the following stopping criteria: (i) runtime
limitation of 6 s; and (ii) maximum of x consecutive iterations allowed without
improvements in the quality of the solution generated by ants, where x is the
product between the numbers of stacks (W), tiers (H) and containers (N) found
in the bay (i.e., x = W × H × N). The short time of 6 s was used as runtime
limit in order to make the comparison between the ACO and the other algo-
rithms possible, because the TRIAD, PENALTY, and CASE algorithms are fast
to execute.
Firstly, the solutions obtained by ACO over the 21 runs on each of the 1200
instances were evaluated for variability. The proposed algorithm reported a good
homogeneity in the solutions produced in terms of the crane’s operating time,
especially, for the small-sized and normal-sized instances, as shown in Fig. 6. The
ACO algorithm has demonstrated a low dispersion of objective values among the
solutions produced, bearing in mind that the highest coeﬃcient of variation is
2.43% and the mean coeﬃcient of variation is 0.25%. Therefore, although the
proposed algorithm is a random approach, its solutions tend to converge even
adopting distinct random seeds.
The comparison results presented in Fig. 7 bring to light the eﬃciency of
ACO when solving the assessed instances in terms of the crane’s operating
time. This ﬁgure compares the total crane’s operating time for the solutions
obtained by ACO, TRIAD, PENALTY, and CASE and shows the percentage
reduction values promoted by the ACO algorithm over the instance classes. The
computational results indicate that ACO obtains better results than the other
algorithms for all instance classes. The operating time reduction is of 6.1%
when compared to TRIAD, of 8.6% when compared to PENALTY, and of
15.7% when compared to CASE, considering that the total operating time in
hours is 30,325, 32,284, 33,168, and 35,982, for ACO, TRIAD, PENALTY, and
CASE, respectively.
In addition to these excellent results, the proposed algorithm ACO reported
signiﬁcantly better solutions than the other algorithms in reducing the crane’s
operating time, according to the nonparametric Wilcoxon Rank Sum test. This
test, with 99% of conﬁdence, has revealed a statistically signiﬁcant diﬀerence
between the quality of the solutions obtained with ACO and the other algo-
rithms. It is noteworthy that the ACO algorithm was able to ﬁnd even better
solutions than the TRIAD algorithm, highlighting the excellent features of ACO,
bearing in mind that TRIAD had already been found better solutions than the
other algorithms. Also, the TRIAD is utilized as a constructive heuristic by
ACO to produce its initial solution and additional solutions, while the ants are
walking.

Optimizing the Crane’s Operating Time with the Ant Colony
385
Fig. 7. A comparison of ACO, TRIAD, PENALTY, and CASE algorithms regarding
the crane’s operating time
7.3
Analysis of the Pilot Method Algorithm
A comparison between the pilot method algorithm (PILOT), proposed in this
paper, and other heuristic algorithms is also performed. PILOT was executed
with the following stopping criteria: (i) a runtime limitation of 6 seconds; and
(ii) a maximum of 25 consecutive iterations without improvements in the quality
of the best solution. The short runtime of 6 s was used for enabling comparisons
with the other fast-execution heuristics, similarly to the chosen runtime value
adopted for the ACO algorithm.
The proposed pilot method algorithm has been designed to enhance the qual-
ity of a heuristic. In this study, the aim is to improve the solution found by the
TRIAD heuristic. Having this in mind, comparative experiments between the
PILOT, TRIAD, ACO, PENALTY, and CASE algorithms were performed. The
experimental results are shown in Fig. 8. This ﬁgure compares the total crane’s
operating time generated by the algorithms and shows the reduction values pro-
moted by the PILOT algorithm for the 1200 instances over the 21 runs.
The operating time reduction is of 3.0% when compared to ACO, of 8.9%
when compared to TRIAD, of 11.3% when compared to PENALTY, and of
18.3% when compared to CASE. The total operating time in hours is 29,404,
30,325, 32,284, 33,168, and 35,982, for PILOT, ACO, TRIAD, PENALTY, and
CASE, respectively. Besides, as the instance sizes increase, the proposed algo-
rithms (notably the PILOT algorithm) tend to upgrade the quality of solutions
with respect to the PENALTY and CASE algorithms. This positive aspect is
more noticeable in large-sized problem instances, where the reduction values are
higher. It is worth mentioning that all algorithms reported an average runtime

386
A. da Silva Firmino et al.
Fig. 8. A comparison of PILOT, ACO, TRIAD, PENALTY, and CASE algorithms
regarding the crane’s operating time
of fewer than 3 s. Hence, due to these very short runtimes, a direct comparison
concerning average runtime is not reported.
The nonparametric Wilcoxon Rank Sum test has revealed, with 99% of con-
ﬁdence, a statistically signiﬁcant diﬀerence between the quality of the solutions
produced by PILOT and the other algorithms, for the 1200 instances. Thus, the
proposed algorithm PILOT reported signiﬁcantly better solutions than the other
algorithms in reducing the crane’s operating time. It is worth noting that the
PILOT solutions are slightly better than the ACO solutions in terms of the oper-
ating time reduction (i.e., 3.0%). In particular, on small-sized and normal-sized
instances, the reduction is only 0.4% and 1.7%, respectively.
8
Conclusion
This research has tackled the container retrieval problem (CRP) aiming at min-
imizing the crane’s operating time, a crucial issue for container terminals. This
paper presented several contributions for the CRP and concentrated on its unre-
stricted version, where better solutions can be achieved than using the restricted
version of CRP. First, a heuristic algorithm (TRIAD) was introduced, which
quickly builds high-quality CRP solutions. Thereafter, the TRIAD heuristic was
incorporated into the ACO algorithm (ACO) and the pilot method algorithm
(PILOT), as a constructive heuristic, in order to ﬁnd even better CRP solu-
tions. The computational results show that the TRIAD heuristic achieved the
best results in all evaluated instance classes when compared to other heuristics
from the studied literature. Besides, ACO and PILOT found better solutions
than TRIAD in short runtime. Therefore, the results emphasize the eﬃciency of

Optimizing the Crane’s Operating Time with the Ant Colony
387
all proposed algorithms compared to previous research. Furthermore, as shown
throughout this paper, all proposed algorithms can be extended to solve the
restricted CRP version.
For future research, the plan is to extend this work to optimize other opera-
tional costs incurred by the crane, such as money and energy. In this situation,
considering logistical constraints is also possible, e.g., due to the infection or
explosion hazard, a container cannot be close to another container. Regarding
the customization of the proposed algorithms, a promising line is to address
other stacking problems (e.g., the Premarshalling Problem) to optimize the
crane’s operating time, and another line is to solve, in an integrated manner, the
closely related optimization problems at the container terminal system. Lastly,
another future research may be to improve the performance of the proposed
ACO algorithm, evaluating other ACO algorithmic variants. Moreover, other
nature-inspired metaheuristic algorithms can be studied for solving the CRP,
e.g., bat-inspired algorithm [21], particle swarm optimization [16], and evolu-
tionary optimization based on biological evolution in plants [10].
References
1. Azari E (2015) Notes on “a mathematical formulation and complexity considera-
tions for the blocks relocation problem”. Scientia Iranica 22(6):2722–2728
2. Bacci T, Mattia S, Ventura P (2019) The bounded beam search algorithm for
the block relocation problem. Comput Oper Res 103:252–264. https://doi.org/10.
1016/J.COR.2018.11.008
3. Carlo HJ, Vis IF, Roodbergen KJ (2014) Storage yard operations in container
terminals: literature overview, trends, and research directions. Eur J Oper Res
235(2):412–430. https://doi.org/10.1016/j.ejor.2013.10.054
4. Caserta M, Schwarze S, Voß S (2012) A mathematical formulation and complexity
considerations for the blocks relocation problem. Eur J Oper Res 219(1):96–104.
https://doi.org/10.1016/j.ejor.2011.12.039
5. Dey N (ed) (2018) Advancements in applied metaheuristic computing. Advances
in data mining and database management. IGI Global. https://doi.org/10.4018/
978-1-5225-4151-6
6. Dorigo M, Gambardella LM (1997) Ant colony system: a cooperative learning
approach to the traveling salesman problem. IEEE Trans Evol Comput 1(1):53–
66. https://doi.org/10.1109/4235.585892
7. Feillet D, Parragh SN, Tricoire F (2019) A local-search based heuristic for the
unrestricted block relocation problem. Comput Oper Res 108:44–56. https://doi.
org/10.1016/J.COR.2019.04.006
8. Forster F, Bortfeldt A (2012) A tree search heuristic for the container retrieval
problem. In: Klatte D, L¨uthi HJ, Schmedders K (eds) Operations research pro-
ceedings 2011 SE-41, operations research proceedings. Springer Berlin Heidelberg,
pp 257–262. https://doi.org/10.1007/978-3-642-29210-1 41
9. Galle V, Barnhart C, Jaillet P (2018) A new binary formulation of the restricted
container relocation problem based on a binary encoding of conﬁgurations. Eur J
Oper Res 267(2):467–477. https://doi.org/10.1016/j.ejor.2017.11.053
10. Gupta N, Khosravy M, Patel N, Sethi I (2018) Evolutionary optimization based
on biological evolution in plants. Proc Comput Sci 126:146–155. https://doi.org/
10.1016/j.procs.2018.07.218

388
A. da Silva Firmino et al.
11. Hussein M, Petering MEH (2012) Genetic algorithm-based simulation optimiza-
tion of stacking algorithms for yard cranes to reduce fuel consumption at seaport
container transshipment terminals. In: 2012 IEEE congress on evolutionary com-
putation (CEC). IEEE, pp 1–8. https://doi.org/10.1109/CEC.2012.6256471
12. Inaoka Y, Tanaka S (2017) A branch-and-bound algorithm for the block relocation
problem to minimize total crane operation time. In: 19th international conference
on harbor maritime and multimodal logistics M&S (HMS 2017), pp 98–104
13. Jin B, Zhu W, Lim A (2015) Solving the container relocation problem by an
improved greedy look-ahead heuristic. Eur J Oper Res 240(3):837–847. https://
doi.org/10.1016/j.ejor.2014.07.038
14. Jovanovic R, Tuba M, Voß S (2019) An eﬃcient ant colony optimization algorithm
for the blocks relocation problem. Eur J Oper Res 274(1):78–90. https://doi.org/
10.1016/J.EJOR.2018.09.038
15. Jovanovic R, Voß S (2014) A chain heuristic for the blocks relocation problem.
Comput Ind Eng 75:79–86. https://doi.org/10.1016/j.cie.2014.06.010
16. Khosravy M, Gupta N, Patel N, Senjyu T, Duque CA (2019) Particle swarm opti-
mization of morphological ﬁlters for electrocardiogram baseline drift estimation.
Springer, pp 1–21. https://doi.org/10.1007/978-981-13-9263-4 1
17. Kim Y, Kim T, Lee H (2016) Heuristic algorithm for retrieving containers. Comput
Ind Eng. https://doi.org/10.1016/j.cie.2016.08.022
18. Ku D, Arthanari TS (2016) On the abstraction method for the container relocation
problem. Comput Oper Res 68:110–122. https://doi.org/10.1016/j.cor.2015.11.006
19. Lee Y, Lee YJ (2010) A heuristic for retrieving containers from a yard. Comput
Oper Res 37(6):1139–1147. https://doi.org/10.1016/j.cor.2009.10.005
20. Lin DY, Lee YJ, Lee Y (2015) The container retrieval problem with respect to relo-
cation. Transp Res Part C Emerg Technol 52:132–143. https://doi.org/10.1016/j.
trc.2015.01.024
21. Moraes CA, De Oliveira EJ, Khosravy M, Oliveira LW, Hon´orio LM, Pinto MF
(2019) A hybrid bat-inspired algorithm for power transmission expansion planning
on a practical Brazilian network. Springer, pp 71–95.https://doi.org/10.1007/978-
981-13-9263-4 4
22. Murty KG, Liu J, Wan YW, Linn R (2005) A decision support system for opera-
tions in a container terminal. Decis Support Syst 39(3):309–332. https://doi.org/
10.1016/j.dss.2003.11.002
23. Quispe KEY, Lintzmayer CN, Xavier EC (2018) An exact algorithm for the blocks
relocation problem with new lower bounds. Comput Oper Res 99:206–217. https://
doi.org/10.1016/J.COR.2018.06.021
24. Sheskin DJ (2007) Handbook of parametric and nonparametric statistical proce-
dures, 4th edn. Chapman & Hall/CRC
25. de Melo da Silva M, Erdogan G, Battarra M, Strusevich V (2018) The block
retrieval problem. Eur J Oper Res 265(3):931–950. https://doi.org/10.1016/j.ejor.
2017.08.048
26. da Silva Firmino A, de Abreu Silva RM, Times VC (2016) An exact approach for
the container retrieval problem to reduce crane’s trajectory. In: 2016 IEEE 19th
international conference on intelligent transportation systems (ITSC), pp 933–938.
https://doi.org/10.1109/itsc.2016.7795667
27. da Silva Firmino A, de Abreu Silva RM, Times VC (2019) A reactive grasp meta-
heuristic for the container retrieval problem to reduce crane’s working time. J
Heurist 25(2):141–173. https://doi.org/10.1007/s10732-018-9390-0

Optimizing the Crane’s Operating Time with the Ant Colony
389
28. Tanaka S, Takii K (2016) A faster branch-and-bound algorithm for the block reloca-
tion problem. Autom Sci Eng 13(1):181–190. https://doi.org/10.1109/TASE.2015.
2434417
29. Ting CJ, Wu KC (2017) Optimizing container relocation operations at container
yards with beam search. Transp Res Part E Logist Transp Rev 103:17–31. https://
doi.org/10.1016/j.tre.2017.04.010
30. Tricoire F, Scagnetti J, Beham A (2018) New insights on the block relocation
problem. Comput Oper Res 89:127–139. https://doi.org/10.1016/J.COR.2017.08.
010
31. UNCTAD: Review of Maritime Transport (2017). UNITED NATIONS PUBLICA-
TION. https://www.unctad.org/en/PublicationsLibrary/rmt2017 en.pdf
32. ¨Unl¨uyurt T, Aydin C (2012) Improved rehandling strategies for the container
retrieval process. J Adv Transp 46(4):378–393. https://doi.org/10.1002/atr.1193
33. Voß S, Fink A, Duin C (2005) Looking ahead with the pilot method. Annals Oper
Res 136(1):285–302. https://doi.org/10.1007/s10479-005-2060-2
34. World Bank: container port traﬃc (teu: 20 foot equivalent units) (2018). https://
www.data.worldbank.org/indicator/IS.SHP.GOOD.TU?end=2018&start=2000.
Accessed 30 Aug 2019
35. World
Cargo
News:
GCS
adds
RMG
at
Moscow
terminal
(2013).
www.
worldcargonews.com/news/news/gcs-adds-rmg-at-moscow-terminal-32292.
Accessed 30 Aug 2019
36. Zehendner E, Caserta M, Feillet D, Schwarze S, Voß S (2015) An improved mathe-
matical formulation for the blocks relocation problem. Eur J Oper Res 245(2):415–
422. https://doi.org/10.1016/j.ejor.2015.03.032

