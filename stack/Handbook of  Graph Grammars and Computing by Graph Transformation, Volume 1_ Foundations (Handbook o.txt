
HANDBOOK of 
GRAPH GRAMMARS and 
COMPUTING b y  GRAPH 
TRANSFORMATION 

HANDBOOK OF GRAPH GRAMMARS AND COMPUTING BY 
GRAPH TRANSFORMATION 
Managing Editor: G. Rozsnberg, Leiden, The Netherlands 
Advisory Board: 
6. Courcelle, Bordeaux, France 
H. Ehrig, Berlin, Germany 
G. Engsls, Leiden, The Netherlands 
D. Janssens, Antwerp, Belgium 
H.-J. Kreowski, Brernen, Germany 
U. Montanari, Pisa, lfaly 
Vol. 1: 
Foundations 
Forthcoming: 
Vol. 2: Specifications and Programming 
Vol. 3: 
Concurrency 

HANDBOOK of 
GRAPH GRAMMARS and 
COMPUTING b y  GRAPH 
TRANSFORMATION 
Edited by 
Grzeg o rz Rozen berg 
Leiden University, The Netherlands 
World Scientific 
NewJersey. London Hong Kong 

Published by 
World Scientific Publishing Co. Pte. Ltd. 
P 0 Box 128, Farrer Road, Singapore 912805 
USA office: Suite lB, 1060 Main Street, River Edge, NJ 07661 
UKoffice: 57 Shelton Street, Covent Garden, London WC2H 9HE 
Library of Congress Cataloging-in-Publication Data 
Handbook of graph grammars and computing by graph transformation / 
edited by Grzegorz Rozenberg. 
p. 
cm. 
Includes bibliographical references and index. 
Contents: v. 1. Foundations. 
ISBN 9810228848 
1. Graph grammars. 
I. Rozenberg, Grzegorz. 
QA261.3.H364 
1991 
2. Graph theory -- Data processing. 
51 1'.5--dc21 
96-37597 
CIP 
British Library Cataloguing-in-Publication Data 
A catalogue record for this book is available from the British Library. 
Copyright 0 1997 by World Scientific Publishing Co. Re. Ltd. 
All rights reserved. Thisbook, orparts thereoj maynotbereproducedinanyformorbyanymeans, electronic 
or mechanical, including photocopying, recording or any information storage and retrieval system now 
known or to be invented, without written permission from the Publisher. 
For photocopying of material in this volume, please pay a copying fee through the Copyright Clearance 
Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, USA. In this case permission to photocopy is not 
required from the publisher. 
This book is printed on acid-free paper. 
Printed in Singapore by Uto-Print 

Preface 
Graph grammars originated in the late ~ O ’ S ,  motivated by considerations about 
pattern recognition, compiler construction, and data type specification. Since 
then the list of areas which have interacted with the development of graph 
grammars has grown impressively. Besides the aforementioned areas it includes 
software specification and development, VLSI layout schemes, database design, 
modelling of concurrent systems, massively parallel computer architectures, 
logic programming, computer animation, developmental biology, music com- 
position, visual languages, and many others. Graph grammars are interesting 
from the theoretical point of view because they are a natural generalization 
of formal language theory based on strings and the theory of term rewriting 
based on trees. 
The wide applicability of graph grammars is due to the fact that graphs are a 
natural way of describing complex situations on an intuitive level. Moreover, 
the graph transformations associated with a graph grammar bring “dynamic 
behaviour” to such descriptions, because they model the evolution of graphi- 
cal structures. Therefore graph grammars and graph transformations become 
attractive as a “programming paradigm” for software and graphical interfaces. 
Over the last 25-odd years graph grammars have developed at a steady pace 
into a theoretically sound and well-motivated research field. In particular, they 
are now based on solid foundations, presented in this volume. It includes a 
state-of-the-art presentation of the foundations of all basic approaches to graph 
grammars and computing by graph transformations. 
The two most basic choices for rewriting a graph are node replacement and 
edge replacement, or, in the more general setting of hypergraphs, hyperedge 
replacement. In a node replacement graph grammar a node of a given graph is 
replaced by a new subgraph which is connected to the remainder of the graph 
by new edges depending on how the node was connected to it. In a hyperedge 
replacement graph grammar a hyperedge of a given hypergraph is replaced by 
a new subhypergraph which is glued to the remainder of the hypergraph by 
fusing (identifying) some nodes of the subhypergraph with some nodes of the 
remainder of the hypergraph depending on how the hyperedge was glued to 
it. Chapter 1 surveys the theory of node replacement graph grammars con- 
centrating mainly on “context-free” (or “confluent”) node replacement graph 
grammars, while Chapter 2 surveys the theory of hyperedge replacement graph 
grammars. Both types of graph grammars naturally generalize the context-free 
string grammars. 
V 

The gluing of graphs plays also a central role in the algebraic approach to graph 
transformations, where a subgraph, rather than a node or an edge only, can be 
replaced by a new subgraph (generalizing in this way arbitrary type-0 Chomsky 
string grammars). Originally, the rewriting of graphs based on gluing has been 
formulated by the so-called double pushout in the category of graphs and total 
graph morphisms. More recently a single pushout in the category of graphs and 
partial graph morphisms has been used for this purpose. Chapter 3 gives an 
overview of the double pushout approach, and Chapter 4 gives an overview of 
the single pushout approach; it also presents a detailed comparison of the two 
approaches. 
Graphs may be considered as logical structures and so one can express formally 
their properties by logical formulas. Consequently classes of graphs may be 
described by formulas of appropriate logical languages. Such logical formulas 
are used as finite devices, comparable to grammars and automata, to specify 
classes of graphs and to deduce properties of such classes from their logical 
descriptions. Chapter 5 surveys the relationships between monadic second- 
order logic and the context-free graph grammars of Chapters 1 and 2. 
The research on graph transformations leads to a careful re-thinking of the 
formal framework that should be used for the specification of graphs. The 
theory of Z?-structures, a specific relational framework, has turned out to be 
fruitful for the investigation of graphs especially in their relationship to graph 
transformations. The “static part” of the theory of 2-structures allows to ob- 
tain rather strong decomposition results for graphs, while the “dynamic part” 
of the theory employs group theory to consider transformations of graphs as 
encountered in networks. Chapter 6 presents the basic theory of 2-structures. 
In order to specify classes of graphs and graph transformations as they occur 
in various applications (e.g. databases and database manipulations) one often 
needs quite powerful extensions of the basic mechanisms of graph replacement 
systems. One such extension is to control the order of application of the graph 
replacement rules. Chapter 7 presents a basic framework for programmed graph 
replacement systems based on such a control. 
We believe that this volume together with the two forthcoming volumes - on 
specification and programming, and on concurrency - provide the reader with 
a rather complete insight into the mathematically challenging area of graph 
grammars which is well motivated by its many applications to computer science 
and beyond. 
vi 

My thanks go first of all to the graph grammar community - the enthusiastic 
group of researchers, often with very different backgrounds, spread all over the 
world - for providing a very stimulating environment for the work on graph 
grammars. Perhaps the main driving force in this community during the last 7 
years was the ESPRIT Basic Research Working Group COMPUGRAPH (Com- 
puting by Graph Transformation) in the period March 1989 - February 1992, 
followed by the ESPRIT Basic Research Working Group COMPUGRAPH I1 
in the period October 1992 - March 1996. The initial planning of the hand- 
book took place within the COMPUGRAPH project, and most of Volume I 
of the handbook has been written within the COMPUGRAPH period. The 
European Community is also founding now the TMR network GETGRATS 
(General Theory of Graph Transformation Systems) for the period from Sep- 
tember 1996 to August 1999. We hope to complete volumes I1 and I11 of the 
handbook within the GETGRATS project. The gratitude of the graph gram- 
mar community goes to the European Community for the generous support of 
our research. We are also indebted to H. Ehrig and his Berlin group for man- 
aging the COMPUGRAPH and COMPUGRAPH I1 Working Groups, and to 
A. Corradini and U. Montanari for their work in preparing the GETGRATS 
project. 
I am very grateful to all the authors of the chapters of this volume for their 
cooperation, and to the Advisory Board: B. Courcelle, H. Ehrig, G. Engels, D. 
Janssens, H.-3. Kreowski and U. Montanari, for their valuable advice. 
Finally, very special thanks go to Perdita Lohr for her help in transforming all 
the separate chapters into a homogeneous and readable volume as it is now. 
Neither she nor myself could foresee how much work it would be - but due to 
her efforts we could bring the project to a happy end. 
G. Rozenberg 
Managing Editor 
Leiden, 1996 
vii 


Contents 
1 Node Replacement Graph Grammars 
1 
(J . Engelfriet. G . Rozenberg) 
1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
3 
1.2 From NLC to edNCE . . . . . . . . . . . . . . . . . . . . . . .  
4 
1.2.1 Node replacement and the NLC methodology . . . . . .  
4 
1.2.2 Extensions and variations: the edNCE grammar . . . .  
9 
1.2.3 Graph replacement grammars . . . . . . . . . . . . . . .  14 
1.2.4 Bibliographical comments . . . . . . . . . . . . . . . . .  15 
Embedding . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
16 
1.3.1 Formal definition of edNCE graph grammars . . . . . .  16 
1.3.2 Leftmost derivations and derivation trees . . . . . . . .  38 
Leftmost derivations . . . . . . . . . . . . . . . . . . . .  
38 
Derivation trees . . . . . . . . . . . . . . . . . . . . . . .  
43 
1.3.3 Subclasses . . . . . . . . . . . . . . . . . . . . . . . . . .  
55 
1.3.4 Normal forms . . . . . . . . . . . . . . . . . . . . . . . .  
61 
1.4 Characterizations . . . . . . . . . . . . . . . . . . . . . . . . . .  
68 
1.4.1 Regular path characterization . . . . . . . . . . . . . . .  68 
1.4.2 Logical characterization . . . . . . . . . . . . . . . . . .  72 
1.4.3 Handle replacement . . . . . . . . . . . . . . . . . . . .  
79 
1.4.4 Graph expressions . . . . . . . . . . . . . . . . . . . . .  
81 
1.5 Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
82 
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
88 
1 
1.3 Node replacement grammars with Neighbourhood Controlled 
2 Hyperedge Replacement Graph Grammars 
95 
(F . Drewes. H.-J. Kreowski. A . Habel) 
95 
2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
97 
2.2 Hyperedge replacement grammars . . . . . . . . . . . . . . . .  100 
2.2.1 Hypergraphs . . . . . . . . . . . . . . . . . . . . . . . .  
102 
2.2.2 
Hyperedge replacement . . . . . . . . . . . . . . . . . .  104 
guages . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
105 
2.2.4 Bibliographic notes . . . . . . . . . . . . . . . . . . . . .  
109 
2.3 A context-freeness lemma . . . . . . . . . . . . . . . . . . . . .  
111 
2.3.1 
Context freeness . . . . . . . . . . . . . . . . . . . . . .  
111 
2.3.2 Derivation trees . . . . . . . . . . . . . . . . . . . . . . .  
114 
2.3.3 Bibliographic notes . . . . . . . . . . . . . . . . . . . . .  
115 
2.4 Structural properties . . . . . . . . . . . . . . . . . . . . . . . .  
116 
2.4.1 
A fixed-point theorem . . . . . . . . . . . . . . . . . . .  116 
2.2.3 Hyperedge replacement derivations, grammars, and lan- 
ix 

X 
CONTENTS 
3 
2.4.2 A pumping lemma . . . . . . . . . . . . . . . . . . . . .  
118 
2.4.3 Parikh’s theorem . . . . . . . . . . . . . . . . . . . . . .  
122 
2.4.4 
Bibliographic notes . . . . . . . . . . . . . . . . . . . . .  
123 
2.5 Generative power . . . . . . . . . . . . . . . . . . . . . . . . . .  
124 
2.5.3 Further results and bibliographic notes . . . . . . . . . .  130 
2.6 Decision problems . . . . . . . . . . . . . . . . . . . . . . . . .  
132 
2.6.1 Compatible properties . . . . . . . . . . . . . . . . . . .  132 
2.6.2 
Compatible functions . . . . . . . . . . . . . . . . . . .  135 
2.6.3 
Further results and bibliographic notes . . . . . . . . . .  138 
2.7 The membership problem . . . . . . . . . . . . . . . . . . . . .  
141 
2.7.1 NP-completeness . . . . . . . . . . . . . . . . . . . . . .  
141 
2.7.2 
Two polynomial algorithms . . . . . . . . . . . . . . . .  145 
2.7.3 Further results and bibliographic notes . . . . . . . . . .  154 
2.8 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
155 
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
156 
2.5.1 
Graph-generating hyperedge replacement grammars . . 124 
2.5.2 
String-generating hyperedge replacement grammars 
. . 125 
Algebraic Approaches to Graph Transformation . 
Part I: Basic 
Concepts and Double Pushout Approach 
163 
(A . Corradini. U . Montanari. F . Rossi. H . Ehrig. R . Heckel. M . Lowe) 163 
3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
165 
3.2 Overview of the Algebraic Approaches . . . . . . . . . . . . . .  168 
3.2.1 Graphs. Productions and Derivations . . . . . . . . . . .  168 
3.2.2 Independence and Parallelism . . . . . . . . . . . . . . .  172 
Interleaving . . . . . . . . . . . . . . . . . . . . . . . . .  
172 
Explicit Parallelism . . . . . . . . . . . . . . . . . . . .  
174 
3.2.4 
Amalgamation and Distribution . . . . . . . . . . . . .  178 
Amalgamation . . . . . . . . . . . . . . . . . . . . . . .  
178 
Distribution . . . . . . . . . . . . . . . . . . . . . . . . .  
179 
3.2.5 Further Problems and Results . . . . . . . . . . . . . . .  180 
Semantics . . . . . . . . . . . . . . . . . . . . . . . . . .  
180 
Control . . . . . . . . . . . . . . . . . . . . . . . . . . .  
181 
Structuring . . . . . . . . . . . . . . . . . . . . . . . . .  
182 
Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . .  
182 
More general structures . . . . . . . . . . . . . . . . . .  182 
3.4 Independence and Parallelism in the DPO approach . . . . . .  191 
3.5 Models of Computation in the DPO Approach . . . . . . . . .  200 
3.2.3 
Embedding of Derivations and Derived Productions . . 176 
3.3 Graph Tkansformation Based on the DPO Construction . . . .  182 

CONTENTS 
xi 
3.5.1 
The Concrete and Truly Concurrent Models of Compu- 
tation . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
201 
3.5.2 
Requirements for capturing representation independence . 208 
3.5.3 Towards an equivalence for representation independence . 212 
3.5.4 
217 
Embedding, Amalgamation and Distribution in the 
DPO approach . . . . . . . . . . . . . . . . . . . . . . . . . . .  
220 
3.6.1 Embedding of Derivations and Derived Productions . . 220 
3.6.2 
Amalgamation and Distribution . . . . . . . . . . . . .  224 
Amalgamation . . . . . . . . . . . . . . . . . . . . . . .  
224 
Distribution . . . . . . . . . . . . . . . . . . . . . . . . .  
225 
3.7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
228 
3.8 Appendix A: On commutativity of coproducts . . . . . . . . . .  228 
3.9 Appendix B: Proof of main results of Section 3.5 . . . . . . . .  232 
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
240 
The abstract models of computation for a grammar . . .  
3.6 
4 Algebraic Approaches to Graph Transformation . 
Part 11: Sin- 
gle Pushout Approach and Comparison with Double Pushout 
Approach 
247 
(H . Ehrig. R . Heckel. M . Korff. M . Lowe. L . Ribeiro. A . Wagner. 
A . Corradini) 
247 
4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
249 
4.2 Graph Transformation Based on the SPO Construction . . . .  250 
4.2.1 Graph Grammars and Derivations in the SPO Approach 250 
4.2.2 Historical Roots of the SPO Approach . . . . . . . . . .  258 
4.3 Main Results in the SPO Approach . . . . . . . . . . . . . . . .  259 
4.3.1 
Parallelism . . . . . . . . . . . . . . . . . . . . . . . . .  
260 
Interleaving . . . . . . . . . . . . . . . . . . . . . . . . .  
260 
Explicit Parallelism . . . . . . . . . . . . . . . . . . . .  
264 
4.3.2 Embedding of Derivations and Derived Productions 
. . 268 
4.3.3 
Amalgamation and Distribution . . . . . . . . . . . . .  273 
4.4 Application Conditions in the SPO Approach . . . . . . . . . .  278 
4.4.1 
Negative Application Conditions . . . . . . . . . . . . .  278 
4.4.2 Independence and Parallelism of Conditional Derivations 282 
Interleaving . . . . . . . . . . . . . . . . . . . . . . . . .  
282 
Explicit Parallelism . . . . . . . . . . . . . . . . . . . .  
284 
Transformation of More General Structures in the 
SPO Approach . . . . . . . . . . . . . . . . . . . . . . . . . . .  
287 
4.5.1 Attributed Graphs . . . . . . . . . . . . . . . . . . . . .  
288 
4.5.2 
Graph Structures and Generalized Graph Structures . . 292 
4.5 

xii 
CONTENTS 
4.5.3 High-Level Replacement Systems . . . . . . . . . . . . .  294 
4.6.1 Graphs, Productions, and Derivations . . . . . . . . . .  298 
4.6.2 
Independence and Parallelism . . . . . . . . . . . . . . .  301 
4.6 Comparison of DPO and SPO Approach . . . . . . . . . . . . .  296 
Interleaving . . . . . . . . . . . . . . . . . . . . . . . . .  
301 
Explicit Parallelism . . . . . . . . . . . . . . . . . . . .  
302 
4.6.3 Embedding of Derivations and Derived Productions . . 305 
4.6.4 
Amalgamation and Distribution . . . . . . . . . . . . .  306 
4.7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
308 
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
309 
5 The Expression of Graph Properties and Graph Transforma- 
tions in Monadic Second-Order Logic 
313 
(B . Courcelle) 
313 
5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
315 
5.2 Relational structures and logical languages . . . . . . . . . . .  317 
5.2.1 Structures . . . . . . . . . . . . . . . . . . . . . . . . . .  
317 
5.2.2 
First-order logic . . . . . . . . . . . . . . . . . . . . . .  
318 
5.2.3 
Second-order logic . . . . . . . . . . . . . . . . . . . . .  
319 
5.2.4 
Monadic second-order logic . . . . . . . . . . . . . . . .  320 
5.2.5 
Decidability questions . . . . . . . . . . . . . . . . . . .  322 
5.2.6 Some tools for constructing formulas . . . . . . . . . . .  324 
5.2.7 
Transitive closure and path properties . . . . . . . . . .  327 
5.2.8 Monadic second-order logic without individual variables 331 
5.2.9 
A worked example: the definition of square grids in MS 
logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
332 
Representations of partial orders, graphs and hypergraphs by 
relational structures . . . . . . . . . . . . . . . . . . . . . . . .  
334 
5.3.1 
Partial orders . . . . . . . . . . . . . . . . . . . . . . . .  
334 
5.3.2 
Edge set quantifications . . . . . . . . . . . . . . . . . .  335 
5.3.3 Hypergraphs . . . . . . . . . . . . . . . . . . . . . . . .  
339 
5.4 The expressive powers of monadic-second order languages . . .  340 
5.3 
5.4.1 Cardinality predicates . . . . . . . . . . . . . . . . . . .  340 
5.4.2 
Linearly ordered structures . . . . . . . . . . . . . . . .  342 
5.4.3 
Finiteness . . . . . . . . . . . . . . . . . . . . . . . . . .  
344 
5.5 Monadic second-order definable transductions . . . . . . . . . .  346 
5.5.1 Transductions of relational structures . . . . . . . . . .  346 
5.5.2 
The fundamental property of definable transductions . . 351 
5.5.3 
Comparisons of representations of partial orders, graphs 
and hypergraphs by relational structures . . . . . . . . .  354 

... 
CONTENTS 
Xlll 
5.6 Equational sets of graphs and hypergraphs . . . . . . . . . . . .  
5.6.1 Equational sets . . . . . . . . . . . . . . . . . . . . . . .  
5.6.2 
Graphs with ports and VR sets of graphs . . . . . . . .  
5.6.3 Hypergraphs with sources and HR sets of hypergraphs . 
5.7 Inductive computations and recognizability . . . . . . . . . . .  
5.7.1 Inductive sets of predicates and recognizable sets . . . .  
5.7.2 Inductivity of monadic second-order predicates . . . . .  
5.7.3 Inductively computable functions and a generalization of 
Parikh's theorem . . . . . . . . . . . . . . . . . . . . . .  
5.7.4 Logical characterizations of recognizability . . . . . . . .  
5.8 Forbidden configurations . . . . . . . . . . . . . . . . . . . . . .  
5.8.1 Minors . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
5.8.2 The structure of sets of graphs having decidable monadic 
theories . . . . . . . . . . . . . . . . . . . . . . . . . . .  
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
356 
356 
362 
367 
372 
372 
379 
383 
389 
390 
390 
396 
397 
6 2-Structures . A Framework For Decomposition And Trans- 
formation Of Graphs 
401 
(A . Ehrenfeucht. T . Harju. G . Rozenberg) 
40 1 
6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
403 
6.2 2-Structures and Their Clans . . . . . . . . . . . . . . . . . . .  404 
6.2.1 Definition of a 2-structure . . . . . . . . . . . . . . . . .  404 
6.2.2 
Clans . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
407 
6.2.3 Basic properties of clans . . . . . . . . . . . . . . . . . .  410 
6.3 Decompositions of 2-Structures . . . . . . . . . . . . . . . . . .  411 
6.3.1 Prime clans . . . . . . . . . . . . . . . . . . . . . . . . .  
411 
6.3.2 
Quotients . . . . . . . . . . . . . . . . . . . . . . . . . .  
412 
6.3.3 Maximal prime clans . . . . . . . . . . . . . . . . . . . .  
416 
6.3.4 
Special 2-structures . . . . . . . . . . . . . . . . . . . .  
418 
6.3.5 
The clan decomposition theorem . . . . . . . . . . . . .  419 
6.3.6 
The shape of a 2-structure . . . . . . . . . . . . . . . . .  421 
6.3.7 Constructions of clans and prime clans . . . . . . . . . .  424 
6.3.8 
Clans and sibas . . . . . . . . . . . . . . . . . . . . . . .  
427 
6.4 Primitive 2-Structures . . . . . . . . . . . . . . . . . . . . . . .  
430 
6.4.1 Hereditary properties . . . . . . . . . . . . . . . . . . .  430 
6.4.2 
Uniformly non-primitive 2-structures . . . . . . . . . . .  433 
6.5 Angular 2-structures and T-structures . . . . . . . . . . . . . .  434 
6.5.1 Angular 2-structures . . . . . . . . . . . . . . . . . . . .  
434 
6.5.2 
T-structures and texts . . . . . . . . . . . . . . . . . . .  438 
6.6 Labeled 2-Structures . . . . . . . . . . . . . . . . . . . . . . . .  
442 

xiv 
CONTENTS 
6.6.1 Definition of a labeled 2-structure . . . . . . . . . . . .  442 
6.6.2 
Substructures, clans and quotients . . . . . . . . . . . .  444 
6.7 Dynamic Labeled 2-Structures . . . . . . . . . . . . . . . . . .  447 
6.7.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . .  
447 
6.7.2 
Group labeled 2-structures . . . . . . . . . . . . . . . .  449 
6.7.3 Dynamic labeled 2-structures . . . . . . . . . . . . . . .  450 
6.7.4 
Clans of a dynamic A62-structure . . . . . . . . . . . .  454 
6.7.5 Horizons . . . . . . . . . . . . . . . . . . . . . . . . . . .  
455 
6.8 Dynamic C2-structures with Variable Domains . . . . . . . . . .  457 
6.8.1 
Disjoint union of C2-structures . . . . . . . . . . . . . .  457 
6.8.2 
Comparison with grammatical substitution . . . . . . .  458 
6.8.3 
Amalgamated union . . . . . . . . . . . . . . . . . . . .  
459 
6.9 Quotients and Plane Trees . . . . . . . . . . . . . . . . . . . . .  
460 
6.9.1 
Quotients of dynamic A62-structures . . . . . . . . . . .  460 
6.9.2 
Plane trees . . . . . . . . . . . . . . . . . . . . . . . . .  
461 
6.10 Invariants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
469 
6.10.1 Introduction to invariants . . . . . . . . . . . . . . . . .  469 
6.10.2 Free invariants . . . . . . . . . . . . . . . . . . . . . . .  
470 
6.10.3 Basic properties of free invariants . . . . . . . . . . . . .  472 
6.10.4 Invariants on abelian groups . . . . . . . . . . . . . . . .  473 
6.10.5 Clans and invariants . . . . . . . . . . . . . . . . . . . .  
476 
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
476 
7 Programmed Graph Replacement Systems 
479 
(A . Schurr) 
479 
7.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
481 
7.1.1 Programmed Graph Replacement Systems in Practice . 481 
7.1.2 Programmed Graph Replacement Systems in Theory . . 482 
7.1.3 
Contents of the Contribution . . . . . . . . . . . . . . .  483 
7.2 Logic-Based Structure Replacement Systems . . . . . . . . . .  484 
7.2.1 Structure Schemata and Schema Consistent Structures . 485 
7.2.2 Substructures with Additional Constraints . . . . . . . .  492 
7.2.3 
Schema Preserving Structure Replacement . . . . . . . .  498 
7.2.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . .  
504 
7.3 Programmed Structure Replacement Systems . . . . . . . . . .  505 
7.3.2 Basic Control Flow Operators . . . . . . . . . . . . . . .  507 
7.3.3 Preliminary Definitions . . . . . . . . . . . . . . . . . .  510 
7.3.4 A Fixpoint Semantics for Transactions . . . . . . . . . .  512 
7.3.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . .  
518 
7.3.1 Requirements for Rule Controlling Programs . . . . . .  506 

CONTENTS 
xv 
7.4 Context-sensitive Graph Replacement Systems . 
Overview . . .  519 
7.4.1 Context-sensitive Graph Replacement Rules . . . . . . .  520 
7.4.2 Embedding Rules and Path Expressions . . . . . . . . .  523 
7.4.3 Positive and Negative Application Conditions . . . . . .  526 
7.4.4 Normal and Derived Attributes . . . . . . . . . . . . . .  527 
7.4.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . .  
530 
7.5 Programmed Graph Replacement Systems - Overview . . . . .  530 
7.5.1 
Declarative Rule Regulation Mechanisms . . . . . . . .  532 
7.5.2 Programming with Imperative Control Structures . . .  534 
7.5.3 Programming with Control Flow Graphs . . . . . . . .  537 
7.5.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . .  
540 
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
541 
Index 
547 

Chapter 1 
NODE REPLACEMENT GRAPH 
GRAMMARS 
J. ENGELFRIET 
Department of Computer Science, Leiden University 
P.O.Box 9512, 2300 R A  Leiden, The Netherlands 
G. ROZENBERG 
Department of Computer Science, Leiden University 
P.O.Box 9512, 2300 R A  Leiden, The Netherlands 
and 
Department of Computer Science, University of Colorado at Boulder 
Boulder, Co 80309, U.S.A. 
In a node-replacement graph grammar, a node of a given graph is replaced by a 
new subgraph, which is connected to the remainder of the graph by new edges, 
depending on how the node was connected to it. These node replacements are con- 
trolled by the productions (or replacement rules) of the grammar. In this chapter 
mainly the “context-free” (or “confluent”) node-replacement graph grammars are 
considered, in which the result of the replacements does not depend on the order 
in which they are applied. Although many types of such grammars can be found in 
the literature, the emphasis will be on one of them: the C-edNCE grammar. Basic 
notions (such as derivations, associativity, derivation trees, normal forms, etc.) are 
discussed that facilitate the construction and analysis of these grammars. Proper- 
ties of the class of generated graph languages, such as closure properties, structural 
properties, and decidability properties, are considered. A number of quite different 
characterizations of the class are presented, thus showing its robustness. This ro- 
bustness of the class of C-edNCE graph languages, together with the fact that it is 
one of the largest classes of “context-free” graph languages, motivates the choice 
of the C-edNCE grammar to be central in this chapter. 
Contents 
1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . .  
3 
1.2 From NLC to edNCE . . . . . . . . . . . . . . . . . .  
4 
1.3 Node replacement grammars with Neighbour- 
hood Controlled Embedding. . . . . . . . . . . . . .  16 
1.4 Characterizations 
. . . . . . . . . . . . . . . . . . . .  
68 
1.5 Recognition . . . . . . . . . . . . . . . . . . . . . . . .  
82 
References . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
88 
1 


1.1. INTRODUCTION 
3 
1.1 Introduction 
Graph grammars provide a mechanism in which local transformations on 
graphs can be modelled in a mathematically precise way. The main component 
of a graph grammar is a finite set of productions; a production is, in general, 
a triple ( M ,  D ,  E )  where M and D are graphs (the ‘1m~ther7’ 
and “daughter” 
graph, respectively) and E is some embedding mechanism. Such a production 
can be applied to a (“host”) graph H whenever there is an occurrence of M 
in H .  It is applied by removing this occurrence of M from H ,  replacing it by 
(an isomorphic copy of) D ,  and finally using the embedding mechanism E to 
attach D to the remainder H -  of H .  
Two main types of embedding can be distinguished: gluing and connecting. 
In the gluing case, certain parts (i.e., nodes and edges) of D are identified 
with certain parts of H-. To be more precise, the latter are the parts of H -  
that were previously identified with certain parts of M .  The gluing parts of D 
are usually defined in terms of the gluing parts of M .  In the connecting case, 
certain new edges are used as bridges that connect D to H-, i.e., edges of 
which one node belongs to D and the other to H-. When M is removed from 
H ,  all bridges between nodes of M and nodes of H that do not belong to M 
are removed too. The new bridges are usually defined in terms of the old ones. 
Based on these two types of embedding there are two main approaches to graph 
grammars: the gluing approach and the connecting approach. Unfortunately, 
they are usually called the algebraic approach and the algorithmic (or set 
theoretic) approach, which names refer to the mathematical techniques that are 
used. In this chapter we describe the connecting approach to graph rewriting, 
and, apart from Section 1.2.3 we discuss context-free graph grammars only. 
For the general case we refer to Chapter 7. The gluing approach is described 
in Chapters 4, 5, 2. 
In the connecting approach, a context-free graph grammar has productions of 
the form ( M ,  D ,  E )  where M consists of one node only. Thus, nodes are re- 
placed by graphs. Moreover, we require that the result of a sequence of node re- 
placements does not depend on the order in which they are applied. This makes 
the context-free graph grammar well suited to describe recursively defined sets 
of graphs, i.e., recursive graph properties. And so, the context-free graph gram- 
mar is the appropriate generalization of the usual context-free grammar for 
strings. However, as opposed to the case of strings, there is not just one canon- 
ical way of defining context-free graph grammars. In the connecting approach, 
there are several natural ways of defining the embedding mechanism E and 
there are several natural restrictions on the form of the right-hand side D. 

4 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
In the gluing approach, context-free graph grammars rewrite edges (or even 
hyperedges) instead of nodes, see Chapter 2. In recent years it has turned out 
that for each embedding approach there is one main class of context-free graph 
grammars that is of most interest: the HR grammars in the gluing approach 
(where HR stands for 'hyperedge replacement'), and the so-called C-edNCE 
grammars in the connecting approach. The C-edNCE grammar is the most 
powerful context-free graph grammar of the connecting approach; it has a 
quite general embedding mechanism and no restrictions on right-hand sides. 
We also note that the C-edNCE grammar has more generating power than the 
HR grammar. Due to the importance of the C-edNCE grammars they are also 
called VR (vertex replacement) grammars. For a comparison between HR and 
VR sets of graphs see also Chapter 3. 
In Sections 1.2.1 and 1.2.2 we describe the connecting approach to context-free 
graph grammars in an informal way (as in [53]). We start with the easiest types 
of embedding and end with the C-edNCE grammar. In Section 1.3 we define 
the C-edNCE grammar formally, show a number of its elementary properties, 
and discuss some natural subclasses. In Section 1.4 we present four different 
characterizations of the class of C-edNCE graph languages: by regular path 
languages in regular tree languages, by monadic second-order logic translation 
of trees, by handle-replacement graph grammars, and by regular sets of graph 
expressions. Section 1.4.2 also contains a discussion of closure properties and 
decidability properties of that class. Finally, in Section 1.5, we take a brief look 
at the complexity of recognizing C-edNCE graph languages. 
The selection of the results that are presented is of course our personal choice. 
We assume the reader to be familiar with basic notions from formal language 
theory (in particular context-free grammars, to be used as a point of reference) 
and graph theory. 
1.2 From NLC to edNCE 
In this section we give an informal introduction to node replacement graph 
grammars. The reader who prefers formal definitions can skip this section and 
proceed to Section 1.3. 
1.2.1 Node replacement and the N L C  methodology 
The usual way of rewriting a graph H into a graph H' is to replace a subgraph 
M of H by a graph D and to embed D into the remainder of H ,  i.e., into 
the graph H -  that remains after removing M from H ;  H' is the resulting 

1.2. FROM NLC TO EDNCE 
5 
graph. We say that H is the host graph, M is the mother graph, and D is the 
daughter graph. In the connecting approach (see Section l.l), M is an induced 
subgraph of H and the removal of M from H consists of the removal of all 
nodes of M and of all edges of H that are incident with nodes of M. The 
embedding process connects D to the remainder H -  by building bridges, i.e., 
by establishing edges between certain nodes of D and certain nodes of H-. 
In the restricted case of node replacement the mother graph consists of one 
node only, a “local unit” of the host graph. Thus, if also the embedding is 
done in a local fashion (by connecting the daughter graph to host nodes that 
are “close” to the mother node), then a node rewriting step is a local graph 
transformation. The iteration of such node rewriting steps leads to a global 
transformation of a graph into a graph that is based on local transformations. 
This is the underlying idea of graph grammars based on node rewriting. In 
such a grammar the replacement of nodes is specified by a finite number of 
productions and the embedding mechanism is specified by a finite number of 
connection instructions. In many cases, each production has its own, private, 
set of connection instructions. The productions are the main constituent of the 
graph grammar, which is a finite specification of a graph rewriting system. 
A typical, very simple, example of a node-replacement mechanism is the Node 
Label Controlled mechanism, or NLC mechanism. In the NLC framework one 
rewrites undirected node-labeled graphs. The productions are node-replacing 
productions and the embedding connection instructions connect the daughter 
graph to the neighbourhood of the mother node -- hence the rewriting process 
is completely local. In the NLC approach “everything” is based on node labels. 
An NLC production is of the form X + D ,  where X is a (nonterminal) node 
label, and D is an undirected graph with (terminal or nonterminal) node labels. 
Such a production can be applied to any node m in the host graph that has 
label X (i.e., there are no application conditions); its application results in 
the replacement of mother node m by daughter graph D. All productions 
share the same connection instructions. A connection instruction is of the form 
( p , 6 ) ,  where both p and 6 are (terminal or nonterminal) node labels. The 
meaning of such an instruction is that the embedding process should establish 
an edge between each node labeled 6 in the daughter graph D and each node 
labeled p that is a neighbour of the mother node m. Note that the presence of 
edges cannot be tested; if m has no p-labeled neighbour, then the connection 
instruction (p, 6) remains unused. Since a connection instruction is an ordered 
pair, a finite number of connection instructions is a relation, called a connection 
relation. Warning: in the literature a connection instruction is often given as 
(6, p) rather than (p, 6). 

6 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
Example 1.1 
Consider the production X + D in Fig. 1.1, and consider the connection 
instructions (c, a ) ,  (b, b), and (b, X ) ,  where we assume that X is a nonterminal 
node label and a, b, c are terminal node labels. Consider also the host graph 
H in Fig. 1.2(a), and let m be the node of H with label X .  Note that graphs 
are drawn as usual, except that, for clearness sake, nonterminal nodes are 
represented by boxes. The application of X -+ D to mother node m is shown 
in two steps in Figs. 1.2(b) and 1.3. Figure 1.2(b) shows the result of replacing 
m by D; m is removed, together with its three incident edges, and D is added 
(disjointly) to the remainder H -  of H .  Figure 1.3 shows the resulting graph 
H‘, i.e., the result of embedding D in the remainder H - ;  the five edges that 
are added by the connecting process are drawn fatter than the other edges. 
0 
Thus, H is transformed into H‘ by the application of X + D to m. 
X 
-+ 
U 
b 
C 
Figure 1.1: A production of an NLC grammar. 
An NLC graph grammar is a system G = (C, 4, P, C, S )  where C - 4 and 
A (with A C: C) are the alphabets of nonterminal and terminal node labels, 
respectively, P is a finite set of NLC productions, C is a connection relation, i.e., 
a binary relation over C, and S is the initial graph (usually with a single node). 
As usual, the graph language generated by G is L(G) = { H  E GRA I S J* 
H } ,  
where GRA is the set of undirected graphs with node labels in 4, + represents 
one rewriting step, and =s* represents a derivation, i.e., a sequence of rewriting 
steps. 
To simplify the description of examples, we will use strings to denote certain 
“string-like” graphs. More precisely, a string a1a2 . . .an, with ai E 4 for some 
alphabet 4 and n 2 1, denotes the undirected node-labeled graph with nodes 
~ 1 ~ x 2 , .  
. . ,z, and edges {~i,zi+1} 
for every 1 5 i 5 n - 1, where zi is 
labeled by ai for every 1 5 i 5 n. In particular, Q E 4 denotes the graph with 
one a-labeled node and no edges. 
Example 1.2 
Let us consider an NLC graph grammar G = (C, 4, P, C, S )  such that L(G) 
is the set of all strings in (abc)+ with additional edges between all nodes with 
label b. G is defined as follows: C = { X ,  a, b, c}, A = {a, b, c}, S = X ,  P 
consists of the production in Fig. 1.1 and the production X -+ 
abc, and C = 

1.2. FROM NLC TO EDNCE 
7 
Figure 1.2: (a) A host graph. (b) Replacement of the mother node by the daughter graph. 
" f  
X 
Figure 1.3: Embedding of the daughter graph. 

CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
{(c, a ) ,  (b, b), (b, X ) } .  The intermediate graphs, or sentential forms, 
generated 
by this grammar are the strings in (abc)*X with additional edges between 
all nodes with label b or label X .  One rewriting step of G was considered in 
Example 1.1. 
0 
NLC graph grammars are one attempt to define a class of “context-free” graph 
grammars, i.e., graph grammars that are similar to the usual context-free gram- 
mars for strings. Such an attempt is useful if one wishes to carry over the 
nice properties of context-free grammars to the case of graphs. In particular, 
context-free graph grammars are meant to be a framework for the description 
of recursively defined properties of graphs. NLC graph grammars are context- 
free in the sense that they are completely local and have no application condi- 
tions. This allows their derivations to be modelled by derivation trees (which 
embody the recursive nature of context-free grammars). However, in general, 
NLC grammars do not have the desirable context-free property that the yield 
of a derivation tree is independent of the order in which the productions are 
applied. A graph grammar that has this property is said to be confluent or to 
have the finite Church-Rosser property (not to be confused with the related 
but different notions in term rewriting systems). 
Example 1.3 
Consider an NLC grammar G with initial graph S and productions S -+ AB, 
A + a and B -+ b (where S ,  A, B are nonterminal node labels and a, b are 
terminal node labels). Viewed as a context-free string grammar, L(G) = {ab} 
and G has exactly one derivation tree. Suppose now that G has connection 
relation C = { (23, a), (a, b)}. Then L(G) = {ab, a + b} where a + b is the graph 
with two nodes, labeled a and b, and no edges. Note that, intuitively, G still has 
one derivation tree, but the two ways of traversing this tree produce different 
graphs: ab is produced when A + a is applied before B + b, whereas a + b is 
produced when they are applied in the reverse order. Thus, G is not confluent. 
0 
Since, in this chapter, we are mainly interested in context-free grammars, we 
restrict attention to confluent NLC (or C-NLC) graph grammars. There is a 
natural structural restriction on the productions of the NLC grammar that is 
equivalent with confluence (see Section 1.3, Definition 1.3.5). There are other 
natural structural restrictions on the NLC grammar that guarantee confluence 
(but are not equivalent to it). An attractive example of such a restriction is the 
“boundary” restriction: in a boundary NLC (or B-NLC) graph grammar no two 
nodes with a nonterminal label are connected by an edge (in the right-hand 
sides of productions and in the initial graph). In fact, an important feature of 
NLC rewriting is the following: if, in a derivation, one obtains a sentential form 

1.2. FROM NLC TO EDNCE 
9 
with two nodes x and y that are not connected by an edge, then, whatever will 
happen later to these nodes in the derivation, no node descending from x will 
ever be connected to a node descending from y: connections can be broken, but 
cannot be re-established. In a boundary NLC grammar this feature ensures that 
in every sentential form the nodes with a nonterminal label are not connected 
to each other, and this in turn ensures that the grammar is confluent. It should 
be clear that the grammar of Example 1.2 is a B-NLC grammar; in fact, it is 
even linear: there is at most one node with a nonterminal label in every derived 
graph. 
1.2.2 
The NLC approach described in the previous section can be extended and 
modified in various ways. Here we discuss some of these generalizations which 
are also called “NLC-like” or “NCE-like” graph grammars. The last general- 
ization to be considered is the edNCE grammar, which is much more powerful 
than the NLC grammar. 
It is often convenient to be able to refer in the connection instructions directly 
to nodes in the daughter graph rather than through their labels. Hence each 
connection instruction will now be of the form (p, x), where x is a node in the 
daughter graph (i.e., in one of the right-hand sides of the productions of the 
grammar), and, as before, p is a node label. The meaning of this instruction 
is that node x should be connected to each node labeled p that is a neighbour 
of the mother node. This gives us a convenient way of distinguishing between 
individual nodes in the daughter graph. NLC-like grammars with this type of 
connection instructions are called NCE graph grammars, i.e., graph grammars 
with Neighbourhood Controlled Embedding. This acronym stresses the locality 
of the embedding process, which NCE grammars inherit from NLC grammars. 
Of course, NCE grammars are still “node label controlled” as far as replacement 
is concerned; the embedding process is node label controlled with respect to 
the neighbourhood of the mother node only, because the nodes of the daughter 
graph are accessed directly (independently of their labels). 
In the formal definition of an NCE graph grammar one could stick to one 
connection relation and require the right-hand sides of productions to be mu- 
tually disjoint. However, it is more natural to define an NCE grammar as a 
system (C, A, PI S ) ,  such that C, A, and S are as before, and P is a finite set 
of productions, where each production is now of the form X -+ ( D , C )  such 
that X + D is an NLC production and C is a connection relation “for D”, 
i.e., C 
Extensions and variations: the edNCE grammar 
C x VD (where VD is the set of nodes of 0). 

10 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
Example 1.4 
Consider the graph language L that is obtained from the one of Example 1.2 
by the assumption that b = a. Thus, the nodes of the graphs in L have labels 
a and c. An NCE grammar (similar to the one of Example 1.2) that generates 
L, has productions X -i (D1,Cl) and X -i 
(Dz,Cz), where X -+ 
D1 is 
shown in Fig. 1.1 (with b = a), C1 = {(c,xl), ( a , x ~ ) ,  
( a , ~ ) } ,  
0 2  = aac, and 
C, = { ( C , Z ~ ) , ( U , X ~ ) } ,  with the nodes of D1 and 0 2  numbered from left to 
right. Figs. 1.2 and 1.3 (with b = a) show a derivation step of this grammar. 0 
One might think of extending the connection instructions to be of the form 
(y,z), 
where x is a node of the daughter graph and y is a neighbour of the 
mother node. However, this does not work in general, because the number of 
neighbours of the mother node may be unbounded, which makes it impossible 
to access individual neighbours. A way to distinguish between neighbours in a 
better way than just through their labels will be discussed later. 
It is natural to extend the domain of graph rewriting to graphs more general 
than undirected node-labeled graphs. In particular we will discuss directed 
graphs and graphs with edge labels. 
To extend the NLC approach to directed node-labeled graphs is quite easy. 
The connection relation C now consists of triples (p, 6, d), where d E {in, out}, 
to deal with the incoming edges and the outgoing edges of the mother node, 
respectively. These connection instructions are used in an obvious way. Thus, 
a connection instruction (p, 6, in) means that the embedding process should 
establish an edge to each node labeled 6 in the daughter graph D from each 
node labeled p that is an “in-neighbour” of the mother node m (where the 
in-neighbours of m are all nodes n for which there is an edge from n to m in 
the host graph). Similarly, a connection instruction (p, 6, out) means that an 
edge should be established from each node labeled 6 in the daughter graph to 
each node labeled p that is an out-neighbour of m. Note that the grammar is 
direction preserving, in the sense that edges leading to m (from m, respectively) 
are replaced by edges leading to D (from D ,  respectively). There is also a 
variation that allows directions to be changed: the connection instructions are 
then of the form (p, 13, d, d’) with d, d’ E {in, out}, where d is the old direction 
and d‘ the new one. 
As observed before, neighbours of the mother node can be distinguished by the 
embedding process of an NLC grammar when they have distinct labels only. 
The extension to directed graphs already gives some more discerning power: 
the grammar can also distinguish between out-neighbours and in-neighbours 
of the mother node. Extending the NLC approach to (undirected) graphs that, 

1.2. FROM NLC TO EDNCE 
11 
in addition to node labels, also have edge labels gives even more discerning 
power in the neighbourhood of the mother node. 
Example 1.5 
For the host graph in Fig. 1.4, when replacing the mother node m, the em- 
bedding process can distinguish between neighbours x and y (both labeled a), 
because x is a pneighbour of m (i.e., is connected to m by an edge with label 
p )  and y is a q-neighbour of m. Note that it is still impossible to distinguish 
0 
between neighbours x and u. 
Figure 1.4: A neighbourhood of the mother node. 
Thus, intuitively, the neighbours of the mother node m are divided into several 
distinct types, depending on the label of the edge that connects the neighbour 
to m. A natural, and powerful, idea is to allow the embedding process to change 
the type of these neighbours: when the embedding process connects a daughter 
node x to a neighbour n of m, the type of n with respect to x may differ from 
its type with respect to m. This leads to connection instructions of the form 
( p , p / q ,  b), where p and q are edge labels, and p and S are node labels as before. 
The meaning of this connection instruction is that the embedding process 
should establish an edge with label q between each p-labeled pneighbour of 
the mother node and each 6-labeled node in the daughter graph. Thus, edge 
label p is changed into edge label q. This feature is also called dynamic edge 
relabeling. 
Even if one is not interested in generating graphs with edge labels, dynamic 
edge relabeling can be used as a natural additional control of the rewriting 
and embedding process during the derivation of graphs. In many cases this 
facilitates the construction and the understanding of the grammar. 
We use a small letter d to indicate that an NLC-like graph grammar generates 
directed graphs, and a small letter e to indicate that the generated graphs have 
edge labels in addition to node labels. Thus, one has, e.g., dNLC grammars, 
eNCE grammars, and edNLC grammars. 

12 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
The following example shows the use of dynamic edge relabeling. 
a 
1 
X 
X 
-+ 
X 
X 
-+ 
“0 
Figure 1.5: Productions of an eNCE grammar (without connection relations). 
Example 1.6 
(a) Consider an eNCE grammar G that generates the edge complements of 
all strings in a+, i.e., all graphs with a-labeled nodes 51,. . . , x, (n 2 1) and 
edges { x i ,  xj} with i 5 j - 2; all edges have label q. Note that the connection 
instructions of an eNCE grammar have the form ( p , p / q ,  x ) ,  where p is a node 
label, p and q are edge labels, and x is a daughter node. G = (C, A, J?, R, P, S )  is 
defined as follows: C = { X ,  a } ,  A = { a } ,  the edge label alphabet r is {1,2, q }  
with “final” edge label alphabet 0 = { q }  C r, S = X ,  and P consists of 
the two productions X + ( 0 1 ,  C1) and X + ( 0 2 ,  C2), where X + D1 and 
X + DZ are shown in Fig. 1.5, C1 = {(a,2/q,x), (a,2/2,y), (a, 1/2,y)} and 
Cz = { ( a ,  2 / q ,  z)}. G generates sentential forms of the form shown in Fig. 1.6. 
Figure 1.6: Sentential form of an eNCE grammar. 
The edge labels 1 and 2 divide the neighbours of the nonterminal node into 
two types: the first node to its “left”, and all the other nodes. Application of 
the production X + (01,Cl) leads to a change of type of the 1-neighbour 

1.2. FROM NLC TO EDNCE 
13 
of X :  after application it becomes of type 2; this dynamic change of type is 
caused by the connection instruction (a, 1/2, y). Note that G is linear and hence 
confluent, i.e., a C-eNCE grammar. 
(b) Consider the graph language L consisting of all strings in (am)+ with 
additional edges (labeled q) between any two nodes xi such that i = 2(mod 3); 
in fact, L is obtained from the graph language of Examples 1.2 and 1.4 by the 
assumption that c = b = a. It can easily be seen that L can also be generated by 
a linear eNCE grammar G. We just note that G has a production as in Fig. 1.1, 
such that the edges incident with X have distinct (“nonfinal”) labels. In every 
sentential form, X has two types of neighbours: the first type is the a-labeled 
node that is generated last, and the second type consists of all generated nodes 
0 
z, with i = 2(mod 3 ) .  
Combining all features discussed above naturally leads to the class of edNCE 
graph grammars. As argued in Section 1.2.1, of particular interest are the 
C-edNCE grammars: the confluent edNCE grammars. Also of interest is the 
subclass of B-edNCE grammars: the boundary edNCE grammars. 
Each production of an edNCE grammar is of the form X -+ (0, C), and each 
connection instruction in C is of the form (p,p/q,x,d), 
where p is a node 
label, p and q are edge labels, z is a node of D, and d E {in,out}. If, say, 
d = in, then this instruction is interpreted as follows: the embedding process 
should establish an edge with label q to node x of D from each p-labeled p 
neighbour of m that is an in-neighbour of m. Note that the grammar is direction 
preserving; it can be shown that allowing the directions of edges to change 
(with connection instructions of the form (p,p/q, 
x, dld‘)) does not increase the 
power of the edNCE grammar. Also, allowing the connection instructions to 
make use of multiple edges does not increase the power of the edNCE grammar 
(in that case a connection instruction is of the form (p, B/q, x, d) where B is 
a set of edge labels; it is applicable only to a neighbour of m that is a p 
neighbour of m for every p E B). On the other hand, it can be shown that 
the information concerning the labels of neighbours can be coded into the 
labels of the connecting edges. Thus, one might in fact assume the connection 
instructions to be of the simpler form (p/q,z,d) 
and disregard the label p of 
the neighbour of the mother node. 
In going from the class of NLC grammars to the class of edNCE grammars we 
have clearly made the embedding mechanism much more involved. Thus, since 
in analyzing derivations of edNCE grammars one has to keep track additionally 
of edge labels, directions, and individual nodes, it would seem that it is more 

14 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
involved to analyze edNCE grammars than NLC grammars. However, there is 
a definite trade-off here: it turns out that the additional features of the edNCE 
grammar can often be used in a straightforward, easily understandable fashion 
to show that they have certain desirable properties that are not possessed by 
NLC grammars. As a simple example, every B-edNCE grammar has an equiva- 
lent B-edNCE grammar in Chomsky Normal Form (appropriately defined, see 
Theorem 1.3.31); the analogous result does not hold for B-NLC grammars. As 
another example, it turns out that the class of C-edNCE graph languages can 
be characterized in several different, natural ways (see Section 1.4); no such 
characterizations are known for the class of C-NLC languages. 
1.23 Graph replacement grammars 
For an arbitrary graph grammar that uses the connecting approach to embed- 
ding, the productions of the grammar are of the form (MI D, C) where M and 
D are graphs (the mother and the daughter graph, respectively) and C is a 
set of connection instructions. Such an instruction is applied to a graph H by 
removing from H an induced subgraph (isomorphic to) M ,  replacing it by (a 
copy of) D, and embedding D in the remainder H -  of H by the connection 
instructions from C. 
Each of the node-replacement grammar types discussed in the previous sections 
has its counterpart in the graph-replacement case. As an example, for NCE 
grammars the connection instructions are of the form ( m , p , x ) ,  where m is 
a node of MI and, as in the node-replacement case, p is a node label and 
x is a node of D. The meaning of the instruction is that daughter node x 
should be connected to each p-labeled node of H -  that is a neighbour of 
mother node m. Similarly, for edNCE grammars a connection instruction is 
of the form (m, p, p / q ,  x, d) with obvious meaning: a q-labeled edge should be 
established between x and every p-labeled node of H -  that is a pneighbour 
of rn (preserving direction d). 
Up to now we have only considered the neighbourhood controlled embedding 
mechanism (NCE) that is completely local, in the sense that the nodes of the 
daughter graph are always connected to former neighbours of the nodes of the 
mother graph (which seems to be necessary in the context-free case). In general 
one can of course consider embedding mechanisms of arbitrary complexity that 
connect a daughter node to any node of H-. Thus, in the case of edNCE 
grammars one might have connection instructions of the form (m, lI/q, z, d) 
where II specifies a binary relation between nodes of M and nodes of H-; 
the meaning of such an instruction is: a q-labeled edge should be established 

1.2. FROM NLC TO EDNCE 
15 
between x and every node y of H -  that is in the relation II with m (preserving 
direction d). The graph grammars of [84,85,86] are of this type (see [3] for a 
special case). In the grammars of Nagl, the admissible binary relations n are, 
roughly speaking, defined recursively as follows: (1) for every edge label p and 
every node label p, the relations edge,, consisting of all (x, 
y) with a plabeled 
edge from x to y, and lab,, consisting of all (z,z) such that x has label p, are 
admissible, and (2) if n, II,, and II2 are admissible, then so are II, U I I 2 ,  nC 
(the complement of II), II-', II, o II1, and II*. Admissible relations are, e.g., 
edge;' 
o lab, 0 edge, which holds between y and m if there is a plabeled edge 
from y to a q-out-neighbour of m with label p, and (edge, U edge,)c which 
holds between y and m if y is neither a pin-neighbour nor a q-in-neighbour of 
m. Since the admissible relations can be written as expressions, this is said to 
be an expression-oriented approach to embedding. 
For more information on arbitrary graph grammars that use the connecting 
approach to embedding we refer to Chapter 7. 
1.2.4 
Bibliographical comments 
Graph grammars were introduced in [88] and [95], both based on the connecting 
approach (see the Introduction). In the seventies, several variations of these 
grammars were considered in, e.g., [2,9,80,84,89], as described in [85,86]. The 
graph grammars of Nagl subsume almost all these variations. 
The (node replacement) edNCE graph grammars were introduced (as a special 
case) in [84,86], where they are called depth-1 context-free graph grammars, 
and investigated in, e.g., [13,39,40,41,43,44,52,70,71,72]. Confluence was in- 
troduced explicitly for edNCE grammars in 1701, and the class of C-edNCE 
languages was studied in [14,15,16,18,20,27,28,46,47,49,51,96,99,100,1~1]. 
NLC graph grammars are a very special case of edNCE graph grammars. They 
were introduced in [60] as a more fundamental variant of the web grammars of 
[88,89], and investigated in, e.g., [12,36,38,45,58,61,62,65,69,73,75,102]. NCE 
graph grammars were introduced in [64] and used, e.g., in [42]; they are even 
closer to the web grammars of [89] than NLC grammars. 
Boundary NLC grammars were introduced in [92], and studied, e.g., in 
[93,94,104,105,106,108,109]. Boundary grammars are confluent. Confluence was 
introduced explicitly for NLC grammars in [36]. The notion of confluence for 
context-free graph grammars in general was stressed in [23], where also the 
C-NLC grammars were investigated. Another class of confluent grammars was 
considered in [66,23]: the neighbourhood-uniform NCE (or NLC) grammars. 
They were studied before, under other names, in [2,61,64,86]. 

16 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
The extension of the NLC grammar to directed graphs, i.e., the dNLC graph 
grammar, was introduced in [63] and investigated, e.g., in [1,4,5]. The extension 
to graphs with edge labels, i.e., the eNLC and edNLC graph grammar, was first 
considered in [68]. Some other extensions of NLC grammars are considered in 
[54,81,82]. The (confluent) edNCE grammars are extended to hypergraphs in 
The parallel rewriting of NLC grammars and edNCE grammars (similar to the 
L-systems for strings) is studied, e.g., in [36,68,86,90]. 
Graph replacement edNCE grammars (that disregard the labels of the neigh- 
bours of the mother graph) are used in [67] to formalize actor systems, a model 
of concurrent computation. 
A proposal for a categorical framework for NCE rewriting (and hyperedge 
rewriting) is presented in [6]. 
[741. 
1.3 Node replacement grammars with Neighbourhood Controlled 
Embedding 
1.9.1 
In this subsection we give formal definitions for the edNCE graph grammars, 
and in particular for the confluent edNCE (C-edNCE) graph grammars. These 
grammars generate directed graphs with labeled nodes and labeled edges. Most 
proofs of results in the literature on eNCE grammars (which generate undi- 
rected graphs) can be adapted to edNCE grammars in a straightforward way 
(but not always the other way around!); thus, in the sequel, we will quote re- 
sults for edNCE grammars from the literature even if, in the literature, they 
are stated for the eNCE case only. 
Let C be an alphabet of node labels and r an alphabet of edge labels. A graph 
over C and I' is a tuple H = (V, E, A), where V is the finite set of nodes, 
E C {(v,y,w) I w,w E V,v # w,y E I?} 
is the set of edges, and X : V 3 C 
is the node labeling function. The components of H are also denoted as VH, 
E H ,  and AH, respectively. Thus, we consider directed graphs without loops; 
multiple edges between the same pair of nodes are allowed, but they must have 
different labels. These restrictions are convenient, but not essential, for the 
considerations of this chapter. A graph is undirected if for every (u, 
7, w) E E, 
also (w, y, 
w) E E. Graphs with unlabeled nodes and/or edges can be modeled 
by taking C = {#) and/or r = {*), respectively. 
Formal definition of edNCE graph grammars 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
17 
As usual, two graphs H and K are isomorphic if’ there is a bijection f : VH -+ 
VK such that EK = {( f (w), y, 
f (w)) 
I (w, y, w) E EH} and, for all w E VH, 
X ~ ( f ( w ) )  = XH(W). For a graph H ,  the set of all graphs isomorphic to H is 
denoted [HI. In general, for any notion of isomorphism between objects, we 
use [z] to denote the set of objects isomorphic to z. Sometimes, z is called 
a ‘concrete’ object and [z] an ‘abstract’ object. As usual, we will not always 
distinguish carefully between concrete and abstract graphs. 
The set of all (concrete) graphs over C and l? is denoted GRc,r, and the set of 
all abstract graphs is denoted [GRc,r]. A subset of [GRc,r] is called a graph 
language. 
A production of an edNCE grammar will be of the form X -+ (D,C) where 
X is a nonterminal node label, D is a graph, and C is a set of connection 
instructions. A rewriting step according to such a production consists of re- 
moving a node labeled X (the “mother node”) from the given “host” graph H ,  
substituting D (the “daughter graph”) in its place, and connecting D to the 
remainder of H in a way specified by the connection instructions in C. The 
pair (0, 
C) can be viewed as a new type of object, and the rewriting step can 
be viewed as the substitution of this object (D, 
C) for the mother node in the 
host graph. Intuitively, these objects are quite natural: they are graphs ready 
to be embedded in an environment. 
Formally, a graph with (neighbourhood controlled) embedding over C and r is 
a pair (H ,C ) with H E GRc,r and C 
C x r x r x VH x {in,out}. C is 
the connection relation of ( H ,  C), and each element (cr, P, y, x, d) of C (with 
a E C, P,y E I?, x E VH, and d E {in,out}) is a connection instruction 
of ( H ,  C). To improve readability, a connection instruction (a, P, y, 
z, d) will 
always be written as (a, P l y ,  z, d). Warning: in the literature the elements of 
a connection instruction are often listed in another order. Two graphs with 
embedding ( H ,  C H )  and (K, C K )  are isomorphic if there is an isomorphism f 
from H to K such that CK = {(a, P/r, f (x), 
d) I (CT, Ply, z, d) E CH}. 
The set of all graphs with embedding over C and r is denoted GREc,r. Every 
ordinary graph is also viewed as a graph with empty embedding (i.e., C = 8); 
thus GRc,r C GREc,r. In what follows we will also say ‘graph’ instead of 
‘graph with embedding’; this should not lead to confusion. 
Intuitively, for a graph with embedding (D ,  C), a connection instruction 
(a, 
Ply, z, out) of C means that if there was a P-labeled edge from the mother 
node w for which (D,C) is substituted to a node w with label a, then the 
embedding process will establish a y-labeled edge from z to w. 
And similarly 
for ‘in’ instead of ‘out’, where ‘in’ refers to incoming edges of w and ‘out’ to 

18 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
outgoing edges of v. Note in particular that the edge label is changed from /3 
into y (which explains the notation ,O/?). 
An example is now given of a graph with embedding. At the same time we dis- 
cuss an elegant graphical specification of graphs with embedding (and hence 
of productions of edNCE grammars) that was introduced in [70], and imple- 
mented in the graph editor GraphEd of [56]. 
Example 1.7 
Let C = {X,Y,u,b,a,a’} and r = {cr,cr’,~,p’,~,~’,~1,y2,S,S’}. Con- 
sider the graph with embedding (D,CD) E GREc,r with VD = {x,y}, 
XD(Z) 
= X ,  Xo(y) = b, ED = { ( y , a , s ) } ,  and Go consists of the 
(a, Q/Q’, Z, out). In Fig. 1.7(b) a graphical specification of ( D ,  CD) is given. 
The graph D is drawn within a large box. Graphs are drawn in the usual way, 
except that nodes that are labeled by a capital (which is usually a nonterminal 
symbol), are represented by a small box. The area outside the large box around 
D symbolizes the environment of D ,  and the large box itself may be viewed as 
a (nonterminal) node, to be rewritten by ( D ,  CD). The connection instructions 
are represented by directed lines that connect nodes (of D )  inside the box with 
node labels outside the box. Such a directed line has two arrows (in the same 
direction) and two labels: the one outside the box is the “old” label and the 
one inside the box is the ‘hew” label. Lines outside the box may be shared, in 
an obvious way. 
As another example, Fig. 1.7(a) represents the graph with embedding ( H ,  CH) 
in GREc,r where VH = {u,v,w}, XH(U) 
= Y, XH(V) = X ,  Xw(w) = a, 
tuples (o,Y/4Y,OUt), (0/,Tt/S/, z,in), (Y,P/Yl,Y,in), (YlPIY2, Gin), and 
E H  = {(u,P,v), (v,a,w),(w,P~u)}> 
and C H  = {(g,P/?’lU,in)> (a,P/y,v,OUt), 
(~/,,O//Y/lv,in)l 
(c/,P//%win)}. 
0 
We now define formally how to substitute a graph with embedding for a node 
of a graph (see [20]). It is convenient (and natural) to allow the host graph to 
be a graph with embedding too; in the frequent case that the host graph is an 
ordinary graph, the result of the substitution will also be an ordinary graph. 
Substitution is defined for disjoint graphs with embedding only, i.e., for graphs 
with embedding that have disjoint sets of nodes. 
Definition 1.3.1 
Let ( H ,  C H )  and (D , CD) be two graphs with embedding, in G R E E , ~ ,  
such that 
H and D are disjoint, and let v be a node of H .  The substitution of (D,Co) 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
Y,, 
s 
19 
\ I  Yl 
li 
\I S' 
P 
Figure 1.7: Two graphs with embedding, and the result of their substitution: (a) is ( H , C H ) ,  
(b) is ( D ,  Co), and (c) is ( H ,  C H ) [ V / ( D ,  
CD)], 
where 'u is the node of H with label X .  
ii 
Q 

20 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
for u in ( H , C H ) ,  denoted ( H , C H ) [ ~ / ( D , C ~ ) ] ,  
is the graph with embedding 
(V, E, A, C) in G R E Z , ~  
such that 
V = ( V H  - {v}) u V D ,  
E 
= { ( z , Y , y ) E E H  I z # v , y # v } U E D  
u { ( W I Y I ~ )  I 3 P  E 
u {(z,Y,w) 130 E 
: (w,P,v) 
E E H ,  (AH(w),P/Y,X,in) E c D >  
: ( V I P , ~ )  E E H >  (AH(w),P/Y,z,OUt) E CD}, 
A(z) = AH(z) if x E VH - {u}, and A(z) = AD(x) if z E VD, 
c = {(c,P/?,z,d) E C H  I z # v> 
u {(a1 P/6, x, d) I 37 E 
: ((TI 
21, d) E C H  7 (a, 
Y/6,x, d) E CD}. 
Example 1.8 
Let ( H ,  C H )  and ( D ,  CD) be the graphs with embedding of Figs. 1.7(a) and (b) 
respectively (as considered in Example 1.7). Let w be the node of H with label 
X .  The graph with embedding ( H , C H ) [ ~ / ( D , C D ) ]  
is drawn in Fig. 1.7(c). 
The three edges that are the result of the embedding process are drawn fatter 
than the other edges. Formally, ( H I  C H ) [ ~ / ( D ,  
C D ) ]  is the graph (V, E ,  A, C) 
with V = {u,w,z,y}, A(u) = Y ,  A(w) = a, A(x) = X ,  A(y) = b, E = 
(a, P/r, u, 
in), (a, 
P / S ,  y, out), (a’, 
P‘/S‘, z, in)}. Note that, pictorially, the parts 
of ( H , C H )  and ( H , c ~ ) [ u / ( D , c ~ ) l  
outside their boxes are the same; a line 
inside the box of ( H , C H )  that represents part of a connection instruction is 
0 
{(w, 
P, u), (Yl a, x ) ,  (2, Q’,W), (u, Y1, 
Y)7 (71,Y2, 
z)}, and c = { ( O ’ , P ’ / Q ,  w, 
in), 
treated “in the same way” as an edge of H .  
The edges of ( H ,  CH)[u/(D, CD)] that are established by the embedding 
process, i.e., that are not in EH or ED, are sometimes called bridges (be- 
tween D and the remainder). It is easy to see that the number of bridges 
is at most 2 . #C . #r . b2, where 6 is the maximal degree of the nodes of 
( H I  CH)[U/(D, 
CD)]. 
In fact, for each a E C and P E r, if (a, P/r,z, 
out) E CD, 
then z is connected to every w with (v,P,w) E EH and AH(w) = a, and so 
the number of such w’s is at most the degree of such an z (and similarly for 
‘in’); thus, the number of neighbours of u that have bridges to D is at most 
2 .  #C . #r .b. This basic property of substitution was first used for boundary 
NLC grammars in the proof of Theorem 6.3 of [92], and then observed and 
exploited for confluent edNCE grammars in [96] (see also [14,15]); for linear 
edNCE grammars it was used in the proof of Theorem 15 of [39]. 
The connection relation C of the graph ( H ,  CH)[W/(D, 
CD)] that results from 
the substitution is defined in such a way that the substitution operation is 
associative. This is expressed in the following lemma that can easily be checked. 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
21 
Lemma 1.3.2 
Let K,H,D be three mutually disjoint graphs with embedding. Let w be a node 
0 
of K and u a node of H .  Then K [ w / H ] [ v / D ]  
= K [ w / H [ v / D ] ] .  
Associativity is one ot the two natural properties that is required tor context- 
free rewriting in the general framework of [23]. The other property is conflu- 
ence, to be discussed later in this section. 
After these preliminaries, we turn to the definition of the edNCE graph gram- 
mar. As mentioned already in Section 1.2.2, NCE stands for nezghbourhood 
controlled embeddzng, the d stands for “directed graphs”, and the e means that 
not only the nodes but also the edges of the graphs are labeled; in particu- 
lar, the e stresses the fact that the edNCE grammar allows for dynamzc edge 
relabelzng. Thus, edNCE grammars are graph grammars wzth nezghbourhood 
controlled embeddzng and dynamzc edge relabelzng. They were introduced in 
[84,85,86], as depth-1 context-free graph grammars (which also allow the em- 
bedding to change the direction of edges and to react to multiple edges, cf. the 
discussion at the end of Section 1.2.2). 
Definition 1.3.3 
An edNCE grammar is a tuple G = (C, A, I?, R, P, S )  where C is the alphabet 
of node labels, A C C is the alphabet of terminal node labels, r is the alphabet 
of edge labels, R C r is the alphabet of final edge labels, P is the finite set of 
productions, and S E C - A is the initial nonterminal. A production is of the 
0 
form X + (D,C) with X E C - A and ( D , C )  € GREc,r. 
Elements of C - A are called nonterminal node labels, and elements of r - s2 
nonfinal edge labels. A node with a terminal or nonterminal label is said to be a 
terminal or nonterminal node, respectively, and similarly for final and nonfinal 
edges. A graph is terminal if all its nodes are terminal (but its edges need not 
be final), i.e., it belongs to GREA,r. For a production p : X -+ (D, 
C), X is the 
left-hand side of p ,  (0, C) is the right-hand side of p ,  and C is its connection 
relation. We write lhs(p) = X and rhs(p) = (D,C). Two productions XI + 
( 0 1 ,  C1) and X2 + ( 0 2 ,  C2) are called isomorphic if XI = X2 and (01, C,) 
and ( 0 2 ,  Cz) are isomorphic graphs with embedding. We will assume that P 
does not contain distinct isomorphic productions. By copy(P) we denote the 
(infinite) set of all productions that are isomorphic to a production in P; an 
element of copy(P) will be called a production copy of G. 
The process of rewriting in an edNCE grammar is defined through the notion 
of substitution, in a standard language theoretic way, as follows. 

22 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
b 
Let G = (C, A, I?, 0, P, S )  be an edNCE grammar. Let H and H‘ be graphs 
in G R E X , ~ ,  
let u E VH, and let p : X -+ ( D , C )  be a production copy of G 
such that D and H are disjoint. Then we write H + u > p  H’, or just H + H’, if 
X H ( U )  = X and H‘ = H[zl/(D, C)]. H + u , p  H‘ is called a derivation step, and 
a sequence of such derivation steps is called a derivation. A derivation 
a 
a 
a 
a 
a 
,, 
a
=
 5
:
 =
=
 =
=
 : =  
0 
a 
a 
a 
a 
a 
I \  
I\ b 
II 
I \  
/ I  
/ I  
HO +vl,pl HI *uz,pz . ‘ +u*,p,, Hn, 
n 2 0, is creative if the graphs Ho and rhs(pi), 1 5 i 5 n, are mutually disjoint. 
W e  will restrict ourselves to creative derivations. Thus, we write H J* H’ if 
there is a creative derivation as above, with Ho = H and Hn = H‘. Let 
sn(S, 
z )  denote the (ordinary) graph with a single S-labeled node z ,  no edges, 
and empty connection relation. A sentential form of G is a graph H such that 
sn(S, z )  +* H for some z; note that H is an ordinary graph, i.e., H E G R Z , ~ .  
The graph language generated by G is 
L(G) = {[HI I H E GRa,n and sn(S,z) +* H for some z } .  
Thus, sentential forms of G are concrete graphs, but the language generated 
by G consists of abstract graphs. It is not difficult to show that if H and H’ are 
isomorphic and sn(S, z )  J* H ,  then sn(S, z’) +* H’ for some z’. Two edNCE 
grammars G and G’ are equivalent if L(G) - {A} = L(G’) - {A}, where A is 
the empty graph. 
Figure 1.8: A street. 
Assumption. From now on we wall assume, for every edNCE grammar G = 
(C,A,I?,O,P,S), that i f  S + (D,C) is in P, then C = 0. To change an 
arbitrary edNCE grammar into an equivalent one satisfying this assumption, 
take a new initial nonterminal S’ and add all productions S’ -+ ( 0 , s )  with 
S + ( D , C )  in P for some C. 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
23 
As observed before, we could have generalized the connection instructions of 
an edNCE grammar to be of the form (u,P/y,x,d/d’) with d,d’ E {in,out}, 
in which case edges with direction d are turned into edges with direction d‘ by 
the embedding process (see, e.g., [15,16,52]). It is easy to show that for each 
such grammar there is an equivalent edNCE grammar (for every edge (v, y, 
w) 
for which Y and w are not both terminal, add an edge (w,y,v), 
see [17] for 
details). 
An example of an eNCE grammar (i.e., an edNCE grammar in which all edges 
are undirected), showing the use of dynamic edge relabeling, was given in Ex- 
ample 1.6(a). In that example, a connection instruction (,u,p/q, x) abbreviates 
the two connection instructions ( p , p / q ,  x, in) and (,u,p/q, x, out). We now give 
some more examples of edNCE grammars; they are all confluent, i.e., C-edNCE 
grammars (to be defined in Definition 1.3.5). Each of these grammars is or will 
be used to illustrate certain aspects of C-edNCE grammars. 
Example 1.9 
(1) Let us consider an edNCE grammar GI such that L(G1) is the set of all 
“streets”, of the form shown in Fig. 1.8, where unlabeled edges (nodes) have 
label * (# respectively). G1 = (C, A, I?, R, P, S )  with C = {S, X ,  #}, A = {#}, 
r = {h,r,a,b,*} (where h stands for ‘house’ and T for ‘road’), R = { a ,  b , * } ,  
and P contains the three productions shown in Fig. 1.9. 
In Fig. 1.9, the right-hand side of a production (which is a graph with embed- 
ding) is drawn as explained in Example 1.7, and the left-hand side is given as 
a label of the large box (usually at the upper left corner); this suggests that 
the large box is a nonterminal node that can be rewritten by the represented 
graph with embedding. Thus, the first production has empty connection re- 
lation, and the other two productions both have the connection instructions 
x2, x3, and x4 are the terminal nodes of the right-hand side, numbered from 
above. The grammar GI generates a street with n houses, n 2 1, by starting 
with the first production, adding one house with each application of the second 
production, n - 1 times, and adding the nth house with the last production. 
An example of a derivation for n = 3 is given in Fig. 1.10, where, at each 
derivation step, the edges that are established by the embedding are drawn 
fatter. 
If the grammar GI is changed into grammar Gi by removing all unlabeled edges 
and both terminal nodes X I ,  then L(Gi) is the set of all chains (or paths) of 
which the edges are labeled by the strings anbunbun, n 2 1. This shows that, if 
one codes strings as chains in the obvious way, (confluent) context-free graph 
(#,h/*,x~,in), ( # , h / a , x ~ , i n ) ,  
(#,h/a,m,out), and (#,r/a,x4,in) where X I ,  

24 
S 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
h - 
h 
_t 
T 
-----f 
X 
X 
a 
h - 
h 
_t_ 
T - ?I 
b 
a 
Figure 1.9: Productions of G1 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
S 
* 
b
b
 
r 
X 
a 
a 
a 
a 
a 
a 
25 
Figure 1.10: A derivation of GI 

26 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
grammars can generate non-context-free string languages (see Section 2.5.2 of 
Chapter 2). 
(2) The next example is an edNCE grammar Gz that generates all rooted 
binary trees (with edges from a parent to its children) such that there is an 
additional edge from each leaf to the root. Gz = (C, A, r, R, P, S )  with C = 
{S,X,#},~={#},~={r,*},andR={*}.FurthermoreP={p,,p~,p,}, 
where pa, pb, and p ,  are the three productions that are shown in Fig. 1.11 
without their connection relations (and again, unlabeled nodes/edges have la- 
S 
r 
I 
L 
I 
X 
X 
Figure 1.11: Productions of G2, G3, G4 (without connection relations). 
be1 #/*, respectively). The connection relation C, of pa is empty, the con- 
nection relation cb of pb is {(#,*/*,z,in),(#,~/r,xl,out), 
(#,r/r,x2,out)}, 
and the connection relation C, of p ,  is {(#, */*, t, 
in), (#, r/*, 2, out)}. The r- 
labeled edges to the root are created by pa, they are “passed” from nonterminal 
to nonterminal by pb, and they are finally attached to the leaves (and changed 
into ordinary unlabeled edges) by p,. Edge label T is not really needed, but 
is used for clearness sake. An example of a derivation of a graph of L(G2) is 
given in Fig. 1.12, where (again) embedding edges are drawn fatter; the applied 
productions are pa, p,, pb, pb, p,, p,, p,, respectively. Note that the addition of 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
S 0 * 
X 
3 
X fi 
u 
27 
Figure 1.12: A derivation of Gz 

28 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
connection instruction (#, r/*, z, out) to pb would result in an additional edge 
to the root from each node of the tree. Note also that if we delete the nodes 
x2 (and their incident edges) from pa and pb, we obtain a grammar GL that 
generates all cycles. 
(3,4) Let G3 be the edNCE grammar that is obtained from G2 
above by dropping the connection instructions that contain r .  Thus, 
Cb = c, = {(#,*/*,.,in)}. 
Then L(G3) is the set of all rooted 
binary trees. Let Gq be the same grammar with C, 
= 8, Cb 
= 
Then L(G4) is the set of all transitive binary trees, i.e., all binary trees with 
an additional edge from each node to each of its descendants. Note that, in 
these two grammars, the r-labeled edges of pa can be dropped. 
(5) Let G j  be the edNCE grammar that is obtained from one of the grammars 
G2, G3, or Gq, by adding edge labels 1 to r - 0 and f to 0, adding edge 
( X I ,  1, x2) to the right-hand sides of p ,  and pb, adding connection instructions 
(a,l/l,xl,in) and (0,1/1,~2,out) to c b ,  with a E {X,#}, and adding connec- 
tion instructions (X,l/l,z,d) and (#,l/f,z,d) to C,, with d E {in,out}. Then 
the leaves of the trees generated by G5 are chained by f-labeled edges “from 
left to right” (where the order is obtained by taking node x1 to the left of node 
{(#, */*, Z, in), ( # I  */*, X l ,  in), (#, *I*, 
2 2 ,  in>> and Cc = {(#, 
* / * I  
.,in>>. 
x2). 
X 
Figure 1.13: Productions of G6. 
(6) The edNCE grammar G6 with the three productions shown in Fig. 1.13 
generates all (undirected) complete graphs K,, with n 2 1. As usual, an 
undirected edge stands for two directed edges. Similarly, two connection 
instructions (0, 
P/r, x, in) and (a, P l y ,  x, out) are represented by an undi- 
rected line. Moreover, as usual, we drop the labels # and * (also from 
connection instructions). Thus, the second production is X + ( D , C )  with 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
29 
VD = {Y,X}, XD(Y) = #, b ( x )  = X ,  ED = {(y,*,x),(x,*,y)}, and 
(7) Let Km,, be the (undirected) complete bipartite graph on m and n 
nodes, i.e., the graph (V, E ,  A) such that V = {ul,. . . ,urn, 
211,. . . ,vn}, E = 
{ ( ~ i , * , v j ) , ( v ~ , * , ~ ~ ) ~ 1 ~ i ~ m , 1 ~ ~ ~ n } , a n d A ( z ) = # f o r e v
The edNCE grammar G7 with the five productions shown in Fig. 1.14 
c = {(#,*/*,Y,i.), (#,*/*,Y,OUt), (#,*/*,z,in), (#,*/*,x,out)}. 
S 
Y 
I : 
Figure 1.14: Productions of G7. 
generates all graphs Km,, with m,n 2 1. A derivation of K2,3 is shown in 
Fig. 1.15 (with fat embedding edges). 
(8,9) A star is a graph K I , ~  
(see the previous example). The edNCE grammar 
G8 with the three productions shown in Fig. 1.16 generates all stars K I , ~  
with 
n 2 1. The wheel W, (with n spokes) is the undirected unlabeled graph with 
nodes u, v1,. . . , v, and edges {u, q} for 1 5 i 5 n, {wi, 
zli+l} for 1 5 i 5 n - 1, 
and {vn,q}. The edNCE grammar Gg with the three productions shown in 
Fig. 1.17 generates all wheels W, with n 2 3. 
(10) The edNCE grammar Glo with the four productions shown in Fig. 1.18 
generates all cogruphs. The grammar reflects the recursive definition of 
cographs: a cograph is either a single node, or the disjoint union of two 

30 
S n *  
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
Figure 1.15: A derivation of K2,3 in G7. 
S 
,I 
X 
X 
I x 
I1I 
Figure 1.16: Productions of Gg. 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
31 
S 
Figure 1.17: Productions of Gg. 
cographs, or the join of two cographs (see, e.g., [21]). 
(11) For this example the reader is assumed to be familiar with 2-structures 
(see Chapter 6). Consider the edNCE grammar GI1 = (C, A, r, R, P, S) with 
C = { S , X ,  #}, A = {#}, r = 0 (where R is an arbitrary alphabet), and 
P = {pl,pa}U{p,,b I a ,  b E R}. The productions are shown in Fig. 1.19 without 
their connection relations. For each production X + ( D ,  C), the connection 
relation is “hereditary”, i.e., C = {(a,y/y,z,d) I (T E C,y E r,z E V D , ~  
E 
{in, out}}. Grammar GI1 generates all uniformly non-primitive (labeled) 2- 
structures over 0, see Section 4.4.2 of Chapter 6 (and see Section 3.3 of [34] 
for the correctness of the construction). For a finite set F of primitive labeled 
2-structures, let Prim(F) be the set of all labeled 2-structures H such that 
every quotient of the shape of H is complete, linear, or in F (see Sections 4.2 
and 4.3 of [34]). Add to grammar G11 all productions X + (D,C) such that 
D E F (with, additionally, every node labeled by X )  and C is hereditary (as 
0 
above). The resulting edNCE grammar generates Prim(F). 
As mentioned in Section 1.2.1, the edNCE grammar has certain undesirable 
non-context-free properties. For instance, there is an edNCE grammar Gb that 
generates the set of all stars K I , ~  
with m + 1 = 2” + 1 nodes, n 2 0, see 
Example 13 of [44]. This grammar has sentential forms H with some nonfinal 
edges between terminal nodes. Such edges are called blocking edges (see p.38 
of [86], or p.129 of [84] where they are called “forbidden” edges), because 
they cannot be removed by rewriting H and, thus, no graph in L(Gb) can be 
generated from H (note that the edges of a graph in L(Gb) have to be final). 
This means that blocking edges can be used to filter out of the language some 
of the terminal graphs. It is shown in Theorem 1.3.17 of [86], for a related class 

32 
S 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
X 
X 
X 
X 
X 
Figure 1.18: Productions of Glo. 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
33 
of node-replacement graph grammars (see Section 1.2.3), that blocking edges 
allow the simulation of arbitrary context-sensitive graph grammars. 
Pl 
Figure 1.19: Productions of G11 (without connection relations). 
Definition 1.3.4 
An edNCE grammar G is nonblocking if every terminal sentential form H of 
G has final edges only (i.e., [HI is in L(G)). 
For a nonblocking grammar G, the string language {a" 
I 
n 
= 
#VH for some [HI E L(G)} is context-free (proof turn each production X + 
(D, C), of which the nodes of D are labeled 01, . . . , g k ,  into the string produc- 
tion X + e: . . . e; where cr = a if ci E A and e: = ci otherwise). This shows 
that the above-mentioned graph language L(Gb) cannot be generated by a non- 
blocking edNCE grammar. However, to forbid blocking edges is not a solution 
to the problem. In fact, let G = (C, A, r, 52, P, S )  be an edNCE grammar, and 
consider now the grammar G' = (C, A, I?, I?, P, S )  that has no nonfinal edge 
labels and hence no blocking edges. Clearly, L(G) = L(G') f l  [G&,n]; hence, 
every edNCE language can be obtained from a nonblocking edNCE language 
by intersecting with some language [ G R A , ~ ] .  
This implies that the class of 
nonblocking edNCE languages is not closed under intersection with languages 
of the form [ G R A , ~ ] ,  
which is also undesirable. 
The real cause of the non-context-free properties of edNCE grammars is that 
they need not be confluent, i.e., that the result of a derivation may depend 
on the order in which the productions are applied. This problem turns up in 
sentential forms that have edges between two nonterminal nodes, as in the 
following example (which is the edNCE version of Example 1.3). 
Example 1.10 
Consider an edNCE grammar G = (C, A, r, 52, P, S )  with C = {S, A, B, a, b}, 
A = {a,b}, r = {a.,/3,6,6'}, 52 = {6,6'}, and the following three productions 

34 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
x -+ (D,C): 
The application of productions p s ,  P A ,  p~ (in that order), gives a derivation 
sn(S,z) J
~
,
~
~
 
H 
HI +v,pe 
H12, where H is rhs(ps), and H12 is the 
graph with two nodes x and y, labeled a and b, respectively, and one edge 
(x,6, y). However, interchanging the application of PA and p~ to nodes u and 
v, respectively, gives a derivation sn(S,z) J
~
,
~
~
 
H *v,ps 
H2 *u,pA 
H21, 
where H21 is the same as HI2 except that its edge is (x,6',y). Since the order 
of application of productions results in two different graphs H12 and Hzl, the 
grammar is not confluent. 
0 
In the literature it is customary to give a dynamic definition of confluence. Here 
we propose a static one that can easily be checked on the embedding relations 
of the productions of the grammar (cf. Definition 5.1 of [36] and Lemma 3.11 
of [23]). 
Definition 1.3.5 
An edNCE grammar G = (C, A, I?, R, P, S )  is confluent, or a C-edNCE gram- 
mar, if for all productions X1 -+ (01, 
C1) and XZ + (Dz, C2) in P, all nodes 
x1 E VD, and x2 E Vo,, and all edge labels a, 6 E r, the following equivalence 
holds: 
3P E 
: (X2, Q/P, xi, out) E Ci and (AD, (xi ), P/S, 227 in) E C2 
3y E r : ( X l , o / y , x ~ , i n )  
E CZ and ( X D , ( ~ ~ ) , Y / ~ Z I , ~ U ~ )  
E C1. 
- 
By C-edNCE we denote the class of graph languages generated by C-edNCE 
grammars. To stress the importance of this class within the area of node re- 
placement graph grammars, it is also called VR, and C-edNCE grammars are 
also called VR grammars (where VR stands for 'vertex replacement'). This is 
analogous to the HR grammars which are the most important class of (hy- 
per)edge replacement grammars. 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
35 
As observed before, all grammars discussed in Example 1.9 are C-edNCE 
grammars. Many sets of graphs with “tree-like” graph theoretic properties 
can be defined by C-edNCE grammars. For example trees, cographs, series- 
parallel graphs, transitive VSP graphs, uniformly non-primitive 2-structures, 
complete bipartite graphs, acyclic tournaments, (maximal) outerplanar graphs, 
edge complements of trees, and for fixed k ,  k-trees, graphs of treewidth 5 k, 
pathwidth 5 k, cutwidth 5 k, bandwidth 5 k ,  cyclic bandwidth 5 k ,  and 
topological bandwidth 5 k (see, e.g., [92,39,46]). 
X1 
x 2  
Figure 1.20: Confluence 
A symbolic picture of Definition 1.3.5 is given in Fig. 1.20 (where 2 1  and x 2  may 
also be boxes). Intuitively the definition means that if the two productions are 
applied to a graph with a single edge (u1, a, u2), 
where ui is labeled Xi, then 
the same edges (21,6,22) are established between nodes of their right-hand 
sides, independent of the order in which the productions are applied. From 
this intuition the following characterization of confluence easily follows: the 
result of a derivation does not depend on the order in which the productions 
are applied. 
Proposition 1.3.6 
An edNCE grammar G = (C,A,r,fl,P,S) is confluent if and only if the 
following holds for every graph H E GRc,r (or H E GREc,r): 
if H J
~
~
,
~
~
 
HI J
~
~
,
~
~
 
H12 and H 
*uz,pz 
H 2  Jul,pl 
H21 are (creative) 
derivations of G with 211,212 E VH and u1 # 212, then H12 = Hzl. 
Pro0 f 
(Only if) Let pi be Xi 4 (Di,Ci). Note that H ,  D1, and DZ are mutually 
disjoint. It has to be shown that 
H [ u l / ( a ,  Cl)l[~2/(D2,C2)1 = H[U2/(D2,C2)1[~l/(Dl,Cl)l. 
Using Definition 1.3.1 it can easily be verified that these two graphs have the 
same nodes with the same labels, the same connection relation, and the same 

36 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
edges (w, y, 
w) with (v, w), 
(w, w) f Vo, x Vo,. It follows from Definition 1.3.5 
that they also have the same edges (21, y, w) with v E V,, , w E V’, 
or v E 
V D ,  , w E V D , .  
(If) To prove the property in Definition 1.3.5, consider the graph H with nodes 
u1 and u2, where ui is labeled X i ,  a single edge (u1, a, uz), 
and empty connec- 
tion relation, and let pi be Xi + (Di,Ci) (or, more precisely, copies of these 
productions with disjoint right-hand sides, disjoint with H ) .  The equivalence 
0 
in Definition 1.3.5 then follows from the equality of Hlz and H21. 
It should be noted that all HR grammars are confluent in the sense of Propo- 
sition 1.3.6 (see Section 2.2.2 of Chapter 2). 
We now give the definition of confluence from the literature (where it is also 
called the finite Church-Rosser, or fCR, property), see, e.g., [70,14,23,46,74]. 
It is exactly the same as the previous proposition, except that H should be a 
sentential form of G; we will call this “dynamic confluence”. 
Definition 1.3.7 
An edNCE grammar G = (C, A, I?, 0, P, S )  is dynamically conjhent if the 
following holds for every sentential form H of G: 
if H J~,,~, 
H I  * u z , p 2  
H12 and H J~,,~, H2 *ul,pl 
H21 are (creative) 
derivations of G with u 1 , u ~  
E VH and U I  # u2, then H12 = H21. 
Thus, every confluent edNCE grammar is dynamically confluent, but, clearly, 
not the other way around. However, we will show later (Theorem 1.3.11) that 
for every dynamically confluent edNCE grammar there is an equivalent conflu- 
ent grammar. Hence, the dynamically confluent edNCE grammars generate the 
same languages as the C-edNCE grammars. We note that dynamic confluence 
is decidable, because the set of all 2-node subgraphs of sentential forms is com- 
putable (see [70]), but we will not need this fact. In [59] an even weaker (and 
decidable) notion of confluence is investigated: an edNCE grammar is called 
order independent if, in Definition 1.3.7, the conclusion is not that H12 = H12, 
but that for every H‘ E G R A , ~ ,  
HI2 J
~
~
,
~
~
 
... J
~
~
,
~
~
 
H’ if and only if 
H21 JVl 
,ql . . . a,,, 
,qn HI. In (231 another, weaker notion of confluence is used 
implicitly (see the Correction to [23]): an edNCE grammar is abstractly con- 
fluent if, in Definition 1.3.7, the conclusion is that 
and H21 are isomorphic 
(rather than equal); it is open whether this is decidable. It will follow from 
Theorem 1.3.11 that also order-independent or abstractly confluent edNCE 
grammars have the same power as C-edNCE grammars. 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
37 
It is shown in [99] that blocking edges are not a problem in confluent grammars 
any more. Thus, it is not necessary (although quite feasible) to explicitly require 
C-edNCE grammars to be nonblocking (as, e.g., in (46,471). We will give the 
proof in Theorem 1.3.21. 
The class C-edNCE of graph languages generated by C-edNCE grammars has a 
large number of nice closure properties, see Theorem 1.4.7. Here we prove a very 
simple special case: closure under edge relabeling. Let p be an edge relabeling, 
i.e., a mapping p : R + R’, where R and R’ are edge label alphabets. For a 
graph H E G R A , ~  
we define p(H) E G R A ~  
to be the graph (VH, E, AH) with 
= { ( V , P ( Y ) , W )  I (.,T,W) 
E EH}. For a graph language L, P(L) = {[P(H)I I 
[HI E L.>. 
Proposition 1.3.8 
C-edNCE is closed under edge relabelings, i.e., if p is an edge relabeling and 
L E C-edNCE, then p(L) E C-edNCE. 
Pro0 f 
Let G = (C,A,r,R,P,S) be a C-edNCE grammar, and let p : 0 -+ 0’ 
be an edge relabeling. It can be assumed that r n 0‘ = 0. We 
construct the edNCE grammar G‘ 
= ( E , A , r  U R’,O’,P‘,S) with 
P‘ 
= { X  + p(D,C) I X + ( D , C )  is in P } ,  where, for a graph 
( D , C )  E G R E Z , ~ ,  
p(D,C) 
GREc,run! is defined to be the graph 
(VD, 
E ,  AD, C’) with embedding, such that 
E 
= 
{ ( V , P ( Y ) l W )  I 
( ~ , y , w )  
E ED,AD(~) 
E A, and y E R, 
and AD(w) E A} 
AD(v) E C - A ,  or y E I’- R, 
or X D ( W )  E C - A}, 
(a, 
Ply7 x,d) E c, b ( X )  E 4 and Y E 0, 
and CT E A} 
U { ( o , P / y , ~ , d )  
E C 1 
X D ( Z )  E C - A, or y E r - R, 
or o E C - A}. 
Thus, only the final edges between terminal nodes are relabeled. 
Using the confluence of G, it is easy to verify that G’ is still confluent (in 
Definition 1.3.5, first consider the case that z1 and x2 are terminal and b is 
final, and then the remaining case). It is also easy to see that the derivations 
of G’ starting with sn(S,z) are of the form sn(S,z) + p(H1) + ... 
p(H,) 
where sn(S, 
z )  + HI + . . . + H, is a derivation of G. Formally this can be 
0 
u { ( v , y , w )  E ED 1 
C’ 
= {(a,P/p(Y),z,d) I 
proved by induction on n. It shows that L(G’) = p(L(G)). 
C-edNCE is also closed under node relabelings (as opposed to NLC); see, e.g., 
Theorem 9 of [44] (and Theorem 4.1 of [93], respectively). 

38 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
1.3.2 Leftmost derivations and derivation trees 
An important property of a context-free string grammar, based on its conflu- 
ence, is that every derivation is equivalent with a leftmost derivation. Also, 
there is a one-to-one correspondence between leftmost derivations and deriva- 
tion trees. For edNCE grammars it turns out that this correspondence even 
holds in the non-confluent case, and that the language generated by leftmost 
derivations is in C-edNCE. Thus, restricting the derivations in edNCE gram- 
mars to be leftmost is an alternative solution to the problem of the non-context- 
free properties of edNCE grammars. 
Leftmost derivations 
To define leftmost derivations of an edNCE grammar G, we have to put a linear 
order on the nodes of the right-hand sides of the productions of G (since there 
is no natural linear order between them as in the case of strings). This order 
induces a linear order on the nodes of the sentential forms of G in a natural way. 
Note that a linear order on the nonterminal nodes would be sufficient; also, 
it would suffice to order the right-hand sides of the production copies, rather 
than the productions. However, the present choice seems to be more natural 
(compared to context-free string grammars) and technically convenient. 
An ordered graph (possibly with embedding) is a graph together with a linear 
order of its nodes. If H and D are disjoint graphs (with embedding) that are 
ordered, and v is a node of H ,  then the order of the substitution H[v/D] is 
obtained, informally, by substituting the order of D for w in the order of H ,  
just as for strings. Formally, if the nodes of H are ordered as ( ~ 1 , .  . . , vh) with 
v = vi, and those of D are ordered as ( ~ 1 , .  
. . ,wd), 
then the order of H[v/D] 
is (211, . . . , vi-1 , w1, . . . , wd, 
w i + l ,  . . . , vh). 
Let G be an edNCE grammar of which the right-hand sides of its productions 
are made into ordered graphs (by choosing a linear order on their nodes). The 
right-hand sides of the production copies inherit this order in the obvious way 
(i.e., they are ordered in such a way that the isomorphism is order preserving). 
Since the derivation steps of G are defined through the notion of substitution 
(Definition 1.3.1), the sentential forms of G also become ordered graphs, as 
explained above. It should be clear that this ordering of the sentential forms 
has no influence on the language L(G) generated by G (where we disregard the 
order of a generated terminal graph). For a derivation HO J
~
~
,
~
~
H I  J
~
~
,
. . . J~, 
,p,, H, where Ho is an ordered graph, we will also assume that the 
orders of HI to H, are determined by the above. 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
39 
Assumption. From now o n  we will assume that the right-hand sides of the 
productions of a n  edNCE grammar are ordered graphs, and that its sentential 
forms are ordered graphs, as explained above. 
Let G be an edNCE grammar. For an ordered graph H ,  a derivation step 
H +u,p H' of G is a leftmost derivation step if u is the first nonterminal 
node in the order of H .  A derivation is leftmost if all its steps are. We write 
H +m 
H' if there is a leftmost derivation from H to H'. The graph language 
leftmost generated by G is 
L,,(G) = {[HI I H E G R A , ~  
and sn(S,z) +rm H for some z } ,  
where the abstract graph [HI does not involve an order any more (i.e., we 
disregard the order of the graphs in L(G); the order is just used as a means 
to define leftmost derivations). Note that sn(S, z )  can be viewed as an ordered 
graph in one way only. 
By L-edNCE we denote the class of graph languages leftmost generated by 
edNCE grammars. 
As in the case of context-free string grammars (which are all confluent), every 
derivation of a confluent edNCE grammar can be transformed into a leftmost 
derivation, by repeated application of the dynamic confluence property (see 
Proposition 1.3.6 and Definition 1.3.7). 
Proposition 1.3.9 
For every C-edNCE grammar G, Ll,(G) = L(G). 
Proof 
The proof is similar to the case of context-free string grammars, Consider a 
non-leftmost derivation sn(S,z) +* H where H is a terminal graph. This 
derivation can be written as 
sn(S, 
z )  + . . . + Hi-l +v,,pt Hi + . . . + HjPl =+,, 
, p j  Hj + ... =+ H 
where Hi-1 + Hi is the first non-leftmost derivation step, and uj is the left- 
most nonterminal node of Hi-1 (note that since H is terminal, the leftmost 
nonterminal node of Hi-1 has to be rewritten in the derivation). Clearly, by 
the definition of a (creative) derivation, uj is a node of Hi,. . . , Hj-1, differ- 
ent from ui, . . . , u~j-1. Hence, by applying the dynamic confluence property of 
Proposition 1.3.6 j - i times, starting with Hj--2 +vj-l,pj-, 
Hj-1 J ~ , , ~ ~  
H j ,  
a derivation of H of the same length is obtained, in which the first leftmost 
derivation step occurs after the ith step (because the ith step is now of the 
form Hi-1 +vj,pj Hi for some graph Hi). Repetition of this procedure leads 
to a leftmost derivation of H. 
0 

40 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
This shows that for a C-edNCE grammar G the linear order on the right-hand 
sides of the productions of G can be chosen arbitrarily. 
Proposition 1.3.9 implies that C-edNCE 
L-edNCE. It is shown in [20,87,46] 
that also L-edNCE C C-edNCE, i.e., for every edNCE grammar G there exists 
a C-edNCE grammar G’ such that L(G’) = L,,(G). This means that the 
restriction to leftmost derivations is equivalent with the restriction to confluent 
grammars. The proofs in [20,87,46] use the alternative characterizations of the 
class C-edNCE discussed in Sections 1.4.3 and 1.4.1, respectively. Here we give 
a direct proof. TO simplify the proof, we first give a natural sufficient condition 
for an edNCE grammar to be confluent. 
Lemma 1.3.10 
Let G = (C, A, r, 0, P, S) be an edNCE grammar such that 
r = rl x r2 for certain sets rI and r2, and such that 
for every production X + (D, 
C ) ,  
(1) i f ( ~ , ( P l l P 2 ) / ( Y I , Y 2 ) 1 ~ , ~ ~ )  
E c, 
then PI = y1 and 
(c’, 
(PI , P~)/(PI 
, y 2 ) ,  5 ,  in) E C for every 0’ E C and PI E rl. 
then /?2 = 7 2  and 
( ~ ’ , ( P 1 , ~ 2 ) l ( n , p 2 ) , z , o u t )  
E C foreverya’E C andP2 E r 2 .  
(2) ~ f ~ ~ , ~ P 1 1 P 2 ~ l ~ Y 1 , ’ Y 2 ~ 1 ~ 1 ~ ~ ~ ~  
E c, 
Then G is confluent. 
Pro0 f 
Intuitively, the conditions on G mean that every edge in a sentential form H 
of G is of the form (u, 
(71, y2), w ) .  If u is rewritten, then the edge label changes 
into (y:,-y2) for some yi, and the embedding process does not inspect y2 or 
XH(U). Similarly, if w is rewritten, it changes into (71, 74) 
for some 74, and the 
embedding process does not look at y1 or XH(U). As a consequence, if both u 
and v are rewritten, the edge label will be (7: 
, ~
4
)
~
 
independent of the rewriting 
order. Thus, each node incident with an edge has a “private part” of the edge 
label; if the edge is outgoing, it is the first part of the label, and if the edge is 
incoming it is the second part. 
Formally, to prove the only-if direction of the equivalence in Definition 1.3.5, 
observe that a 2  = p2 and PI = 61, and take y = (al,62) (where the subscripts 
1 and 2 of course denote the first and second component of the edge label, 
respectively). Similarly, in the if direction, note that a1 = y1 and 7 2  = 6 2 ,  and 
take ,B = ( h 1 , a 2 ) .  
0 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
41 
Using this lemma, we now show that the classes L-edNCE and C-edNCE are 
equal (as opposed to the NLC case, see [36]). 
Theorem 1.3.11 
L-edNCE = C-edNCE. 
Proof 
Let G = (C,A,r,R,P,S) be an edNCE grammar. We will construct a 
C-edNCE grammar G’ = (C, A, I?’, R’, PI, S )  and an edge relabeling p such that 
L,,(G) = p(L(G’)). By Proposition 1.3.8 this implies that Ll,(G) E C-edNCE. 
The grammar G’ will have the properties stated in the previous lemma. In what 
follows we will say that a node u of an ordered graph H is “to the left” of a 
node w of H ,  if u comes before w in the linear order of the nodes of H .  
The intuitive idea is to replace every edge (u, 
y, v )  between nonterminal nodes 
u and w such that u is to the left of w, by all edges (u, 
((7, a, /?, a), (a, p)), u )  
with a E A, /? E r, and 0 is the label of v. In a leftmost derivation, first the 
node u is completely rewritten into terminal nodes x, and then v is rewritten. 
The pair (a, /?) represents an edge (x,/?, 
v )  where a is the label of x. In the new 
grammar G’, w only sees the (a,/?) part of the edge label and acts as if u has 
already been rewritten. Node u only sees the (y, a, /?, n) part of the edge label 
and acts (based on the y and a )  as if w has not yet been rewritten; moreover, 
at the moment that z is produced, the correct edge is selected on the basis 
of the a and /?, and the first part of the edge label is replaced by E (where 
E indicates that the first part is “empty”). A label ( E ,  (a, p)) of an edge in a 
terminal graph (with /? E 0) is turned into /? by the edge relabeling. In the 
case of an edge ( v , y , u ) ,  with u to the left of u, everything is “reversed”, i.e., 
the edge is replaced by all edges (w,((a,/?), 
(y,a,/?,a)),u). 
We now start the formal definitions. Let I” = rl x r2 with 
rl = r2 = (A x r) u (r x A x r x C) u { E } ,  and 
R’ = { ( E ,  (a,/?)) I a E A,/? E R} u {((a,/?),&) 
I a E A,/? E R). 
The edge relabeling is defined by p ( ~ ,  
(a,/?)) = p ( ( a , / ? ) , ~ )  
= /? for all a E A 
and /? E R. 
For an ordered graph H without embedding, in GRc,r, we define the ordered 
graph sim(H) E GRc,rf to be sim(H) = (VH,E,XH) 
with the same order on 
VH and with E obtained as follows. If (u, 
y, 
v )  is an edge of H with u to the 
left of w, and u is a nonterrninal node of H ,  then E contains all edges 
(u, 
((7, a, P, 01, (a, P)), v )  

42 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
with a E A, P E r, and B = X H ( ~ ) ;  if u is a terminal node of H ,  then E 
contains the edge 
(u, (El (a, PI), w) 
with a = X H ( U )  and P = y. Analogously, if (v,y,u) is an edge of H with u to 
the left of w, and u is a nonterminal node of HI then E contains all edges 
(w, ((a, P), (71 a, P, a)), 
u) 
with a E A, P E r, and (T = X H ( U ) ;  and if u is a terminal node of H ,  then E 
contains the edge 
(v, ((a, PI1 E l ,  u) 
with a = X H ( U )  and P = y. 
The set P’ of productions of G’ is now defined as follows: if X + ( D ,  C) is a 
production of PI then P’ contains the production X + (sim(D), C’) where C‘ 
is obtained as follows. 
If (~,y/y’,x,out) is in C, then C’ contains the following connection instruc- 
tions: 
(1) if x is a nonterminal node, then C’ contains all 
(B’, ((7, a, P, @), T)/((T’, 
a, P, 
a), r), 5, out) 
with (T’ 
E C, a E A, /3 E r, and T E 
(intuitively, for an edge (u, y, 
u), u is 
to the left of v, and u is rewritten into x; in the first part of the edge label, y 
is changed into y’), 
(2) if x is a terminal node, then C’ contains all 
with (T‘ 
E C and T E rz (again, for an edge (u, y, 
w), u is to the left of u, and u 
is rewritten into x; but now the correct edge is selected, with a = Xo(x) and 
/3 = y’, and the first part of the edge label is changed into E ) ,  
(3) if (T is in A, then C’ contains all 
(g‘, ~
~
@
,
~
~
,
~
~
/
~
~
~
,
~
with B’ E C and n E ra (now, for an edge (v, y, u), 
u is to the left of v, and v 
is rewritten into x; this case would be more intuitive if (T would be denoted by 
a, y by P, and y’ by p’: then (a, p) is changed into (a, P’)). 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
43 
Analogously, if (CT, y/y‘, 
2, in) is in C, then C’ contains all connection instruc- 
tions as specified above, in which the first and second part of all edge labels 
are interchanged (note that T E rl = rz). 
This ends the formal definition of G‘. Since it is obvious that G’ satisfies the 
requirements of Lemma 1.3.10, G’ is a C-edNCE grammar. To prove that 
LI,(G) = p(L(G‘)), it suffices to prove that Ll,(G) = p(Ll,(G’)) by Propo- 
sition 1.3.9. Thus, it suffices to compare the leftmost derivations of the two 
grammars. In fact, it is straightforward to verify that the mapping ‘sim’ de- 
fined above turns the leftmost derivations of G into those of G’. More pre- 
cisely, the leftmost derivations of G’ starting with sn(S,z) are of the form 
sn(S,z) + sim(HI) + ... 
HI * ... * H, is a 
leftmost derivation of G (which can be proved by induction on n). This shows 
that the terminal graphs leftmost generated by G’ are all sim(H) where N is a 
terminal graph leftmost generated by G. Hence Ll,(G) = p(Ll,(G’)), because 
for a terminal graph H ,  sim(H) is obtained from H by changing every edge 
label y into some label ( E ,  (a, y)) or ((a, y), 
E ) .  Such a label is final if and only 
if y is final, and if it is, then p replaces it by y. Thus, if H has final edges only, 
sim(H,) where sn(S,z) 
then p(sim(H)) = H .  
We now come back to the discussion after the definition of dynamic confluence 
(Definition 1.3.7). It should be clear that Proposition 1.3.9 also holds for a dy- 
namically confluent, and even for an order independent or abstractly confluent, 
grammar G (with the same proof). Thus, for such a grammar, L(G) = Ll,(G), 
and hence, by the previous theorem, a C-edNCE grammar can be constructed 
that is equivalent with G. This shows that the dynamically confluent (and the 
order independent and the abstractly confluent) edNCE grammars generate 
the same class of languages as the (statically) confluent edNCE grammars, 
viz. C-edNCE. 
Theorem 1.3.11 can be viewed as a first characterization of the class C-edNCE. 
Other characterizations will be discussed in Section 1.4. 
Derivation trees 
Due to our assumption that the right-hand sides of the productions of an 
edNCE grammar are ordered, the notion of derivation tree can be defined in the 
same way as for context-free string grammars. Thus, they are rooted, ordered 
trees, which we view here (as usual) as a special type of graph: each vertex of 
the tree has directed edges to each of its k children, k 2 0, and the order of the 
children is indicated by using the numbers 1,. . . , k to label these edges. A slight 
difference with the string case is that the vertices of the tree will be labeled by 

44 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
productions (or production copies) rather than symbols. Furthermore, for the 
sake of precision, we will distinguish here between two types of derivation trees: 
“c-labeled” derivation trees (in which the vertices are labeled by, mutually 
disjoint, production copies) and “p-labeled” derivation trees (in which they 
are labeled by productions). Note that the nodes of derivation trees are called 
‘vertices’, in order not to confuse them with the nodes of the graphs involved. 
For c-labeled derivation trees, the nonterminal graph nodes will also be used as 
vertices of the tree, in a natural way. We now first consider c-labeled derivation 
trees. 
Definition 1.3.12 
Let G = (C, A, I?, 0, P, S )  be an edNCE grammar. A c-labeled derivation tree 
of G is a rooted, ordered tree t of which the vertices are labeled by production 
copies in copy(P), such that 
(1) the right-hand sides of all the production copies that label the vertices of 
t are mutually disjoint, and do not contain the root o f t  as a node, and 
(2) if vertex w of t has label X + (D,C), then the children of v are the 
nonterminal nodes of D , and their order in t is the same as their order in D ;  
moreover, for each child w, the left-hand side of the label of w in t equals its 
label in D. 
If the root of a derivation tree t is labeled with production X + ( D ,  C), then 
we also say that t is a derivation tree for X (note that not necessarily X = S). 
Example 1.11 
Figure 1.21 shows a c-labeled derivation tree for S of edNCE grammar GZ of 
Example 1.9. The large boxes are the vertices of the tree, labeled by production 
copies (of which the connection relations are not shown). The order of the right- 
hand sides of the productions is such that 2 1  is before 22 (see Fig. 1.11). The 
dotted lines between the large boxes are the edges of the tree. To show that 
the nonterminal nodes of the right-hand sides of the production copies are also 
used as vertices of the tree, the tree edges are drawn from such a nonterminal 
node (represented by a small box) to the corresponding large box. Note that 
since the figure does not show connection relations, it can also be viewed as a 
0 
derivation tree of grammars G3 and Gq of Example 1.9. 
We note here that c-labeled derivation trees are closely related to shapes of 
2-structures (compare Fig. 1.21 with, e.g., Fig. 6.3.6 of Chapter 6). In partic- 
ular, the c-labeled derivation trees of the 2-structures generated by grammar 
G11 are closely related to their shapes. 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
S 
x 
I 
/ 
\ 
I 
\ 
I 
1 i 
/ 
x 
/ 
I 
I 
/ 
1 P  
I 
\ 
\ 
\ 
A\ 
X 
\ \ 
I 
I 
\ 
I 
\ 
1 Y 
\ 
\ 
A\ 
x \ \  
45 
Figure 1.21: A c-labeled derivation tree. 

46 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
As in the case of context-free string grammars, a derivation tree t for X will cor- 
respond to a derivation that starts from X, i.e., from a graph with a single node 
labeled X .  Since, intuitively, such a derivation will be part of a larger one, this 
single-node graph should generate a graph with embedding and, hence, should 
have an embedding itself. Clearly, this must be the “hereditary embedding”, 
which just “takes over” the edges of the environment. 
By sin(X, z) we denote the graph with embedding (V, E, A, C) with V = {z}, 
E = 0, X(z) = X ,  and C = {(a,y/y,z,d) I o E C,y E I‘,d E {in,out}}. 
Note that if sin(X, z) +u,p ( H ,  CH), then v = z and p equals X -+ ( H ,  CH). 
Thus, due to our Assumption in Section 1.3.1, we can use sin(S,z) instead 
of sn(S,z) in the definition of L(G) and Llm(G) , i.e., L(G) = {[HI I H E 
GRa,n,sin(S,z) +* H for some z } ,  and similarly for Llm(G). Note also that 
if K has a node v with label X, then K[v/sin(X, 
x)] is isomorphic to K .  
It is straightforward to associate derivation trees with derivations. With a 
derivation sin(X,vl) J
~
~
,
~
~
 
H1 J
~
~
,
~
~
 
... J,,,,~,, 
H, such that H, is a 
terminal graph with embedding, we associate the c-labeled derivation tree t 
with vertices v1, . . . , v,, labeled pl , . . . , p,, respectively, such that the children 
of vi are the nonterminal nodes of rhs(pi), in the same order. Since H, is 
terminal, the nonterminal nodes of rhs(pi) do appear among vi+l, . . . , v,. It 
is easy to verify the requirements of Definition 1.3.12: (1) holds because the 
derivation is creative (note that vl is the root oft), and (2) holds by definition 
and because the left-hand side of pi is the label of vi. Note that the construc- 
tion of t depends on (v1 ,PI), 
. . . , (v,,p,) only; thus, derivations with the same 
set { ( v l , p l ) ,  . . . , (v,,p,)} have the same derivation tree. In the case that the 
derivation is leftmost, it should be clear that the sequence v1 , .. . , v, is the 
pre-order of the vertices of t. As an example, the derivation tree of Fig. 1.21 is 
associated with the (non-leftmost) derivation of Fig. 1.12. 
Note that the association of derivation trees with derivations is even more 
straightforward than in the case of context-free string grammars, where one 
does not have a convenient notation for occurrences of (nonterminal) symbols, 
which are similar to the nodes w1 , . . . , v,. 
The other way around, it is also easy to associate leftmost derivations with 
derivation trees. For a c-labeled derivation tree t, let vl , . . . , v, be the sequence 
of its vertices in pre-order, let pi be the label of ‘ui, and let X = lhs(p1). Then 
it can be shown in exactly the same way as for context-free string grammars, 
that there is a leftmost derivation sin(X, v1) 
HI +vz,pz . . . J~, 
,p,, H, 
for certain H I ,  . . . , H, with H, terminal. Note that this leftmost derivation is 
uniquely determined by v1 and the sequence p l ,  . . . ,p,. For Example 1.11 this 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
47 
is the sequence pk, pi, pf., pt , pz p: , p:, where the superscripts indicate the fact 
that these are production copies. 
As in the case of context-free string grammars it is straightforward to prove 
that both compositions of the above two mappings between leftmost deriva- 
tions and c-labeled derivation trees are the identity, and hence that they are 
bijections. This shows the one-to-one correspondence between leftmost deriva- 
tions and c-labeled derivation trees for an arbitrary edNCE grammar. 
We will now define the yield of a derivation tree and show that the yield 
of the derivation tree corresponding to a leftmost derivation is the result of 
that derivation. It is natural to define the yield in a bottom-up fashion, as for 
context-free string grammars. 
Definition 1.3.13 
Let t be a c-labeled derivation tree of an edNCE grammar G = 
( C , A , r , R , P , S ) .  Let p E copy(P) be the label of the root of t, and let 
~ 1 , .  
. . ,z,+ 
be the nonterminal nodes of rhs(p), ordered as in rhs(p). Let 
tl,. . . , t k  be the direct subtrees of t (i.e., the subtrees rooted in 21,. . . ,xk, 
respectively). Then the yield of t is the graph with embedding, in G R E A , ~ ,  
defined recursively as yield(t) = rhs(p)[q/yield(tl)] . . . [zk/yield(tk)]. 
By Y ( G )  we denote the set {[yield(t)] E [ G R A , ~ ]  
I t is a c-labeled derivation 
tree of G for S}. 
Note that the yield of a derivation tree need not be in G R E A , ~ ,  
due to the 
possible presence of blocking edges (see Definition 1.3.4). 
Thus, the yields of the subtrees are substituted for the nonterminal nodes of 
the right-hand side of the root production, from left to right. It is easy to 
prove by induction that the set of nodes of yield(t) equals the set of terminal 
nodes of the right-hand sides of the labels oft; this ensures, by condition (1) of 
Definition 1.3.12, that the substitution is well defined. It also shows that each 
node u of yield(t) “belongs” to exactly one vertex vertext(u) oft, in the sense 
that it belongs to the right-hand side of the label of vertext(.). The yield of 
the derivation tree t of Fig. 1.21 (Example 1.11) is shown in Fig. 1.22(b) (see 
also Fig. 1.12); in this case the mapping vertext from the nodes of yield(t) to 
the vertices of t is a bijection (because each production contains exactly one 
terminal node), but in general it need not be injective or surjective. 
For a given derivation tree, the corresponding leftmost derivation executes 
substitutions in a top-down fashion, whereas the yield function executes them 
bottom-up. The fact that these two methods produce the same graph must 

48 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
therefore be based on the associativity of substitution (Lemma 1.3.2). In 
the following lemma we formulate an easy consequence of associativity (cf. 
Lemma 2.12 of [23]). 
Lemma 1.3.14 
Let sin(X,x) +ul,pl 
H1 *uz,p2 ... *,n,pn 
H, be a leftmost derivation of 
an edNCE grammar G (with ul = x and rhs(p1) = HI), and let H be an 
ordered graph such that x is the first nonterminal node of H and XH(X) = X. 
Then H J
~
~
,
~
~
 
H[x/H1] J
~
~
,
~
~
 
H[x/H2] + ... J,,,,~,, H[x/H,] is a leftmost 
derivation of G. 
Pro0 f 
Then H[./H, 
-1 I J U ,  ,P3 H[./H, 
- 11 [2.'3 / rhs(p, )I = H[x/H3-1 [?I /rhs(p, 111 by 
Clearly H +ul,pl 
H[x/H1], because rhs(p1) = HI. Consider the leftmost 
derivation step H,-l 
*u,,p, H,, for 2 5 j 5 n. Thus, H3 = H3-1[w,/rhs(p,)]. 
associativity, which equals H[x/H,]. Clearly, this is also a leftmost derivation 
step. 
0 
We now show that the yield of a derivation tree equals the result of the corre- 
sponding leftmost derivation. 
Theorem 1.3.15 
Let sin(X,vl) +ul,pl H1 +u2,pz ... +un,p,, H,, with H, terminal, be a left- 
most derivation of an edNCE grammar, and let t be the corresponding c-labeled 
derivation tree. Then yieZd(t) = H,. 
Pro0 f 
In this proof we will say that the sequence (w1,p1)(w2,p2)...(wn,p,) is the 
trace of a derivation KO J
~
~
,
~
~
 
K1 +u2,p2 .. . J,~,~, K,. 
Since there is only one leftmost derivation corresponding to t, it suffices 
to show that there is a derivation sin(X,vl) =+Tm 
yield(t) with trace s = 
(wl,pl)(v2,p2) ... (vn,pn), We prove this by induction on the structure of t. 
The root v1 oft has label pl, and H1 = rhs(pl). Let H1 have nonterminal nodes 
XI , . . . , xk, in that order, with labels x1 , . . . , XI, respectively. Then t has direct 
subtrees tl, . . . , tk. Since trace s is the pre-order sequence of the vertices of t, 
with their labels, it can be written as s = (wl ,pl)sl . . . S k ,  where si is the pre- 
order sequence of ti. By induction there is a derivation sin(Xi, xi) -Trn yield(ti) 
with trace si, for every 1 5 i 5 k. By Lemma 1.3.14, there is a derivation 
H1 +im H1 [xl/yield(tl)] with trace s1. Applying that lemma again, we obtain 
a derivation Hl[xl/yield(tl)] +Tm 
H~[x~/yield(t~)][x~/yield(t~)] 
with, trace s 2 .  
Repeating this argument k times, and putting the derivations together, we 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
49 
obtain a derivation H I  
HI [zl/yield(tl)][z~/yield(t~)] 
. . . [x:k/yield(tk)] = 
yield(t) with trace s1 . . . sic, and hence a derivation sin(X, q )  J
~
~
,
~
~
HI *rm 
0 
yield(t) with trace (w1 ,pl)sl . . . sk = s. 
As a corollary we obtain the fact that the language leftmost generated by an 
edNCE grammar equals the set of yields of its c-labeled derivation trees. 
Theorem 1.3.16 
For every edNCE grammar G, Ll,(G) = Y(G). 
0 
Thus, in particular, by Proposition 1.3.9, L(G) = Y ( G )  for every C-edNCE 
grammar G. In fact, for C-edNCE grammars Theorem 1.3.15 holds for arbitrary 
derivations (because derivations starting with some sin(X, II) can be turned 
into leftmost derivations, with the same derivation tree, as in the proof of 
Proposition 1.3.9). For a C-edNCE grammar G one might wonder whether, in 
the definition of yield(t), it is relevant that the graphs yidd(tl), . . . , yield(tk) 
are substituted from left to right. The following lemma shows that it is not. 
Lemma 1.3.17 
Let G = (C, A, I?, R, P, S )  be a C-edNCE grammar. Let u1 and u2 be two dis- 
tinct nonterminal nodes of H E G R E Z , ~  
with labels X1 and X z ,  respectively. 
Let K1 , KZ 6 G R E x , ~  
be such that sin(Xi, u,) J* 
Ki. 
Then H [ u ~ / K ~ ] [ u z / K z ]  
= H[u2/Kz][ul/K1]. 
Proof 
The proof is by induction on the sum of the lengths of the two deriva- 
tions. If that sum equals 2, then we are ready by Proposition 1.3.6, 
because Ki is the right-hand side of a production. Otherwise, consider 
an additional derivation step, say, K1 +v,p 
Ki with rhs(p) = M and 
so Ki = Kl[v/M]. Then H [ u I / K ~ ] [ u z / K z ]  
= H [ ~ ~ / K ~ [ V / M ] ] [ U Z / K Z ]  
= 
- 
H [. 
1 /K1] [v/M] 
[UZ / KZI 
- 
- 
H['LL1 lK11 [uz lK21 [v/MI 
- 
H[~Z/K21[W 
/KlI[V/MI = H[u2/K21 [Ul /K1 [vlMIl = H[%?/K2I[w 
lKil 
by associativity (Lemma 1.3.2), induction (twice), and associativity again. 0 
This leads to the following basic lemma on C-edNCE grammars (Lemma 2.14 of 
[23]). 
It is sometimes called the context-freeness lemma because it expresses the 
existence of derivation trees without explicitly mentioning them (see Section 2.3 
of Chapter 2). 

50 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
Lemma 1.3.18 
Let G = (C, A, I?, R, P, S) be a C-edNCE grammar. Let the graph H E G R E Z , ~  
have nonterrninal nodes ul , . . . , V k  with labels XI, . . . , XI, respectively, and let 
F E GREa,r be a terminal graph. Then H J* 
F if and only if there exist 
F1,. . . , Fk E GREAJ such that F = H[ul/Fl] ... [uk/Fk] (in any order) and 
sin(Xi,vi) J* Fi for all 1 5 i 5 k. 
Moreover, the length of the derivation H J' F is the sum of the lengths of 
the derivations sin(Xi,vi) a* 
F,, 1 5 i 5 k .  
Pro0 f 
By the previous lemma (and the confluence of the given grammar), we may 
as well prove the statement for leftrnost derivations of an arbitrary edNCE 
grammar G, and for an ordered graph H such that u1, . . . , Uk are in the correct 
order. Consider the edNCE grammar G' that is obtained from G by adding 
the new production X + H ,  where X is a new nonterminal. The result now 
follows from Theorem 1.3.15 by considering c-labeled derivation trees for X 
(of which the root is necessarily labeled with the new production). Clearly, F 
is the yield of such a tree, and the Fi are the yields of its direct subtrees. 
0 
If, in particular, H is a sentential form of G with one nonterminal node u1 
(i.e., k = l), then F = H[vl/Fl] and the number of bridges between F1 and 
F - F1 is at most 2 . #A . #r . S;, 
where SF is the maximal degree of the 
nodes of F (see the remark following Definition 1.3.1). Thus, in a derivation 
sin(S, ul) J
~
~
,
~
~
 
HI =
J
~
~
,
~
~
 
. . . J,,,,,~, 
F the part of F that is generated from 
ui (which is the yield of the subtree with root ui of the corresponding c-labeled 
derivation tree) has at most 2.#A.#r.d; 
bridges to the remainder of F. This 
fact is used in [96,14] to prove a separator theorem for C-edNCE languages. 
Roughly speaking, for every C-edNCE language L there is a constant c (with 
c = 2 .  #A . #I?) 
such that every graph F E L can be separated into two parts 
of almost the same size by removing at most c . d g  edges (intuitively, this can 
be done by cutting the derivation tree t of F into two parts of almost the same 
size by removing one edge of t, i.e., by cutting a subtree from t). A similar 
result for linear edNCE grammars is proved in Theorem 15 of [39]. 
We now turn to p-labeled derivation trees. 
Definition 1.3.19 
Let G = (C, A, I', R, P, S) be an edNCE grammar. A p-labeled derivation tree 
of G is a rooted, ordered tree t of which the vertices are labeled by productions 
in P ,  such that 
if vertex u of t has label p ,  and rhs(p) has nonterminal nodes 2 1 , .  . . , Z k ,  in 
that order, then u has children u1, . . . , U k ,  in that order, and the left-hand side 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
51 
of the label of vi in t equals the label of zi in rhs(p). 
By D(G) we denote the set of all abstract p-labeled derivation trees of G for 
S. 
Abstract p-labeled derivation trees can be written as ordinary expressions, 
viewing a production p as k-ary operator, where k is the number of nonterminal 
nodes of rhs(p). Thus, they are trees in the sense of tree language theory [55]; in 
fact, it is easy to see that D(G) is a regular tree language (see Definition 1.4.1 
and the discussion following it). 
From a given p-labeled derivation tree t, a c-labeled derivation tree ct can be 
obtained by choosing mutually disjoint copies of the productions that label 
the vertices oft (satisfying the conditions of Definition 1.3.12). Note that all c- 
labeled derivation trees can be obtained in this way. By definition, the yield of 
the p-labeled derivation tree t is the abstract graph yield(t) = [yield(&)]. This 
definition does not depend on the choice of ct by the following argument: if 
H and H‘ are isomorphic ordered graphs in GREc,r with nonterminal nodes 
2 1 , .  . . , x k  and xi,. . . ,zL in that order, respectively (where zi corresponds 
to x: by the isomorphism), and, for 1 5 i 5 k ,  Hi and H: are isomorphic 
graphs in G R E A , ~ ,  
then H[zl/H1] ... [ z k / H k ]  and H’[z:/W;] ... [zL/HL] are 
isomorphic. In fact, for a productionp E P ,  the operator p can be interpreted as 
an operation o n  abstract graphs (viz. the substitution of its argument graphs 
into the nonterminal nodes of its right-hand side, from left to right), and then 
the yield of an abstract p-labeled derivation tree t is the value of the expression 
t. This gives the following result. 
Proposition 1.3.20 
For every edNCE grammar G, Y ( G )  = yieZd(D(G)) n [GRa,n], and hence 
0 
JL(G) = yield(D(G)) n [GRa,n]. 
Example 1.12 
Figure 1.22(a) shows a p-labeled derivation tree t of edNCE grammar G2 
of Example 1.9. From t the c-labeled derivation tree ct of Fig. 1.21 can 
be obtained as indicated above. These trees have the same yield, shown in 
Fig. 1.22(b) (cf. Fig. 1.12). Viewing the productions of G2 as operators, t 
corresponds to the expression pa (pb (pc, pb (pc, p c ) )  , p c )  or, in parenthesis-free 
notation, papbpcpbpcpcpc. The value of this expression is the graph yield(t). Cl 
From Theorem 1.3.15 (or Lemma 1.3.18) and our considerations concerning 
p-labeled derivation trees, a least fixed point result for edNCE grammars easily 

52 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
Figure 1.22: (a) A p-labeled derivation tree, and (b) its yield. 
follows (see Section 2.4.1 of Chapter 2 for the analogous case of HR grammars). 
To be more precise, the graph languages Ll,(G, X) with X E E-A, defined by 
Ll,(G, X )  = {[HI E [ G R E A , ~ ]  
1 sin(X,x) 
H for some z}, are the least 
solution of the set of all inclusions p(X1, . . . , X,) C X ,  where p is a production 
of G (viewed as operation on graphs as explained above, and extended to graph 
languages in the obvious way), with lhs(p) = X and X I , .  . . , xk are the labels 
of the nonterminal nodes of rhs(p), in that order. For C-edNCE grammars 
the subscripts ‘lm’ can, of course, be dropped in the above. For confluent 
grammars this result was proved, in a general framework, in Theorem 2.16 of 
[23]. The above least fixed point result for leftmost derivations of non-confluent 
grammars can be carried over to that general framework. 
Derivation trees (and Theorem 1.3.15) can in particular be used in formal 
proofs on edNCE grammars that need a bottom-up argument, as opposed 
to top-down proofs that follow the steps of a derivation (such as the proofs 
of Proposition 1.3.8 and Theorem 1.3.11). This is a general fact, which is 
formally expressed, e.g., in Proposition 1.10 of [24] (see also Theorem 5.7.3 
of Chapter 3). Instead of derivation trees, one may also use Lemma 1.3.18, 
the “context-freeness lemma”, see also Sections 2.4 and 2.6 of Chapter 2. To 
illustrate this idea here, we will now prove that blocking edges can be removed 
from C-edNCE grammars, as shown in [99]. 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
53 
Theorem 1.3.21 
For every C-edNCE grammar an equivalent nonblocking C-edNCE grammar 
can be constructed. 
Pro0 f 
Let G = (C, A, I?, R, P, S )  be a C-edNCE grammar. We will construct a new 
grammar G’ = (C‘, A, r, 0, P’, S’) with nonterminals of the form (XI (b, c ) ) ,  
where X is a nonterminal of G and 6 is a boolean that contains the information 
whether or not sin(X, x) generates a terminal graph with blocking edges. This 
boolean can be computed bottom-up (on the derivation tree corresponding to 
the derivation), but to update it we also need some knowledge c about the 
connection relation of the generated terminal graph. 
To be precise, we define, for a terminal graph H E G R E A , ~ ,  
info(H) = (b,c) 
such that b is a boolean which is true if and only if H E G R E A , ~  
and c = 
{ ( o , P / Y , X H ( Z ) , ~ )  I (a,P/y,x,d) E CH for some x E VH} where CH is the 
connection relation of H .  
Grammar G’ will be constructed in such a way that if sin(X,x) gener- 
ates a terminal graph H, and info(H) = (6,c), then sin((X, (b,c)),x) gen- 
erates H’, where H’ is the same as H except that, due to the additional 
information in the nonterminals, each connection instruction (X’, P/r, x, d) 
of H (where X’ is a nonterminal) has to be replaced by all connection in- 
structions ((X’, (b’, c’)), P/r, %, d). This implies that sin((S, (true, @)), x) gen- 
erates all terminal sentential forms of G without blocking edges, whereas 
sin((S, (false, g)), z) generates those with blocking edges. Taking S‘ 
= 
(S, (true, 0)), G’ generates the same language as G, but does not generate 
any blocking edges any more. 
Let Q = {(b,c) I 6 E {true,false},c C (C x l‘ x r x A x {inlout})}, let 
C ’ = ( ( C - A )  x Q ) u A , a n d l e t  S’=(S,(true,0)). 
Let p : X -+ ( D ,  c) 
be a production of G, and let 21,. . . ,xk be the non- 
terminal nodes of D ,  in that order, with labels XI,. . . , Xk, respectively. It is 
straightforward (but tedious) to construct a function SP : Qk -+ Q such that 
for all terminal graphs HI, . . . , Hk : 
info((D,C)[xl/H1] ... [xk/Hk]) = bp(info(H1), . . . ,info(Hk)). 
Thus, according to the definition of ‘yield’, the information can be computed 
bottom-up on the derivation trees using the 6, (in fact, the 6, define a bottom- 
up tree automaton on the p-labeled derivation trees of GI with set of states Q, 
see [55]). 

54 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
The productions P‘ of G’ are defined as follows. For every production p of G 
as above, and all 91,. . . , q k  E Q ,  P’ contains the production prod(p, 41,. . . , q k )  
which has left-hand side ( X ,  bp(ql,. . . , q k ) )  and of which the right-hand side 
is obtained from the one of p by replacing the label X ,  of zi with (Xi,qi) 
and replacing each connection instruction (X’, P l y ,  z, d) with all connection 
instructions ( ( X ‘ ,  q’), P l y ,  z, d), q’ E Q. 
Since the productions of G‘ are a simple variation of those of G (and, in 
particular, their connection relations correspond in a straightforward way), 
it is easy to verify that G‘ is confluent. 
It can now be proved formally that sin((X,q),z) J* 
H‘ in G’ if and only 
if there exists H such that sin(X,z) J* H in G, info(H) = q, and H‘ is 
the same as H except that it has connection relation CHI = { (o’, 
P l y ,  z, d) I 
(g5(o’),/3/y,z,d) E C,} where $(X’,q’) = X‘ and 4(a) = a for a E A. 
The proof is by structural induction on the c-labeled derivation trees that 
correspond to the derivations, using Theorem 1.3.15. Or equivalently on the 
lengths of the derivations, using Lemma 1.3.18. This is, of course, a bottom-up 
induction argument. The details are left to the reader. Taking X = S ,  this 
0 
implies that L(G’) = L(G). 
The argument in the above proof is quite general. In fact, for every C-edNCE 
grammar G, and every bottom-up finite tree automaton A (see [55]), another 
C-edNCE grammar G’ can be constructed, as in the above proof, such that G’ 
generates only those terminal graphs that are the yield of a p-labeled deriva- 
tion tree of G that is accepted by A. If, in particular, A accepts t iff yield(t) 
is in a certain set II (i.e., has a certain desirable property), then G’ generates 
only those terminal graphs that are generated by G and have property II, and 
so L(G’) = L(G) n II (note that for the nonblocking property the generated 
language remained the same). This generalizes the well-known result on string 
languages that the class of context-free string languages is closed under inter- 
section with regular languages. Many properties of graphs can be recognized 
by finite tree automata that work on p-labeled derivation trees, in particular 
all properties that are compatible with substitution (see Section 2.6.1 of Chap- 
ter 2, and [24], for the HR case), including all properties that are expressible 
in monadic second order logic (see Proposition 3.19 and Corollary 4.6 of [23] 
for C-NLC grammars, and see Theorem 1.4.7 in Section 1.4). 
Theorem 1.3.21 is of importance, because it allows one to decide emptiness 
and finiteness of C-edNCE languages in the same way as for context-free string 
grammars. In fact, as observed after Definition 1.3.4, for a nonblocking gram- 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
55 
mar G, the string language S(G) = {a" I n = #VH for some [HI E L(G)} is 
context-free. Clearly, S(G) is empty (finite) if and only if L(G) is empty (finite, 
respectively). This shows the result. For nonblocking C-edNCE grammars the 
algorithms take polynomial time as usual, but for arbitrary C-edNCE gram- 
mars the emptiness problem is exponential time complete, as shown in [99] 
(which means that the removal of blocking edges needs exponential time, in 
general). 
Proposition 1.3.22 
It is decidable, for an arbitrary CedNCE grammar G, whether or not L(G) 
is empty, and also whether or not L(G) is finite. Moreover, if L(G) is finite, it 
can be constructed effectively. 
0 
Together with the above remarks, this shows that it is decidable for an arbitrary 
C-edNCE grammar G whether L(G)nKI # 8, where II is a graph property that 
can be recognized by a finite tree automaton on derivation trees. In general 
this problem has a high complexity (as shown in [105]); for a methodology 
to find efficient algorithms, see [106]. In the special case that L(G) contains 
exactly one graph H, 
the grammar G can be viewed as a succinct hierarchical 
representation of H, and the problem is to decide whether or not H has the 
property IT; for this case the decision algorithm is often more efficient (see 
[105,106]). 
Other decidability properties of C-edNCE grammars are discussed at the end 
of Section 1.4.2. 
I. 3.3 Subclasses 
Several natural subclasses of the C-edNCE grammars have been investigated 
in the literature. We mention a number of the most important ones. Whenever 
we define an X-edNCE grammar for some X, X-edNCE will denote the class 
of graph languages generated by X-edNCE grammars. X.Y-edNCE grammars 
are edNCE grammars that are both X and Y. 
Definition 1.3.23 
An edNCE grammar G = ( C ,  A, I?, 0, P, S )  is boundary, or a B-edNCE gram- 
mar, if, for every production X + (D, 
C), 
(Bl) D does not contain edges between nonterminal nodes, and 
(B2) C does not contain connection instructions (a, ,l?/r, 
x, d) where c is non- 
terminal. 

56 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
Grammars Gg, G ~ o ,  
and GI1 in Example 1.9 are not boundary, but all the 
others are. 
In the definition of B-edNCE grammar either one of conditions (Bl) and (B2) 
can be dropped, in the sense that for every edNCE grammar satisfying one of 
the conditions an equivalent grammar satisfying both conditions can easily be 
constructed: just remove either the LLwrong” 
edges or the “wrong” connection 
instructions (see Theorem 2.2 of [92]). For this reason, we will assume from 
now on that every edNCE grammar that satisfies one of the conditions (Bl) 
and (B2), also satisfies the other (i.e., we will disregard edNCE grammars that 
satisfy only one of the two conditions). 
Boundary grammars were introduced (in [92]) and studied because they are 
a natural example of confluent grammars, and because they are easy to “pro- 
gram”. The idea of a boundary grammar is that nonterminal nodes are not 
connected, i.e., every nonterminal node has a LLboundary” 
of terminal neigh- 
bours around itself. Note that it follows from (Bl) that no sentential form 
of G contains edges between nonterminal nodes; hence, it does not need the 
connection instructions mentioned in (B2). From (B2) it immediately follows 
that every B-edNCE grammar is a C-edNCE grammar. Since the construction 
in the proof of Theorem 1.3.21 preserves (Bl), blocking edges can be removed 
from any B-edNCE grammar (and note that the construction is even easier, 
because the connection relations remain the same; thus, only the labels of the 
nonterminal nodes are changed); the same holds for all other subclasses to be 
discussed. 
In terms of derivation trees, the boundary condition means the following: for 
a c-labeled derivation tree t of a B-edNCE grammar, if (u,y,v) is an edge 
of yield(t), then either vertext(v) is a descendant of vertext(u) in t, or the 
other way around (see the discussion after Definition 1.3.13); thus, edges are 
established “along paths” of the derivation tree only. 
Definition 1.3.24 
A B-edNCE grammar G 
= (C,A,r,R,P,S) is nonterminak neigh- 
b o w  deterministic, or a B,d-edNCE grammar, if, for every production 
X -+ ( D ,  C), every nonterminal node x E VD, and all y E 
(1) {Y 6 VD I (Y, Y, 
x) 
a singleton or empty, and, analogously for ‘out’, 
(2) {Y E VD I (a, 7, Y) E ED and X D ( Y )  = @> u {P E r 1 (0, 
P/r,x, out) E C }  
is a singleton or empty (where we assume that VD n I? = 0). 
and cr E A, 
ED and XD(Y) = o} u {P E r I (0, 
P/r, 2, in) E C }  is 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
57 
Of the grammars of Example 1.9, G1,G;,G2,Gh1G3,G8, and Gg are 
B,d-edNCE grammars. 
The idea of a B,d-edNCE grammar G is that the neighbours y of a nonterminal 
node u of a sentential form of G are uniquely determined by the label and 
direction of the edge between u and y, and by the label of y. This means 
that, when rewriting u, 
the embedding process can distinguish each neighbour 
of u separately. For this reason, B,d-edNCE grammars are close to the HR 
grammars of Chapter 2: a nonterminal node of a B,d-edNCE grammar, with 
its different edges, is similar to a nonterminal hyperedge of an HR grammar, 
with its different tentacles. In fact, it is shown in [52] (see [lo41 for closely 
related results) that B,d-edNCE grammars and HR grammars have the same 
generating power. To express this formally it has to be taken into account that 
HR grammars generate another type of graphs: they allow arbitrary multiple 
edges, and even hyperedges, but they do not allow node labels. Thus, it is 
necessary to encode each of the two types of graphs into the other one. 
Here, for reasons of comparison, and in order to stress explicitly the relation- 
ship between the node replacement and the hyperedge replacement grammars, 
we will restrict attention to HR grammars that generate our type of graphs, 
encoded in an obvious way (simulating node labels by hyperedges of rank 1). 
Moreover, we will denote the corresponding class of graph languages by HR. 
With this convention, we have the result that B,d-edNCE = HR (see Lemma 8, 
Theorem 2 of [52], where the encoding is called ‘hyp’). 
It is shown in Theorem 1 of [52] that also the other way around, encoding 
hypergraphs as bipartite graphs in the obvious way, B,d-edNCE grammars 
and HR grammars have the same hypergraph generating power; in fact, even 
C-edNCE grammars do not have more hypergraph generating power, as shown 
in Theorem 3.13 of [18]. 
A C-edNCE grammar is of bounded nonterminal degree, or a Cbntd-edNCE 
grammar, if there is a bound on the degree of the nonterminal nodes of its 
sentential forms (see [52,104]). The nonterminal degree of such a grammar is 
the maximal degree of these nodes. It is decidable whether a C-edNCE gram- 
mar is of bounded nonterminal degree, and if so, its nonterminal degree can 
be computed (see the end of Section 1.4.2). Clearly, every B,d-edNCE gram- 
mar is of bounded nonterminal degree; its nonterminal degree is the maximal 
number of tentacles of the nonterminal hyperedges of the corresponding HR 
grammar (also called its ‘order’). It is not difficult to show that, the other 
way around, every B-edNCE grammar of bounded nonterminal degree can be 
turned into an equivalent Bnd-edNCE grammar, with the same nonterminal 

58 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
degree (Lemma 8 of [52]). Even, for every Cbntd-edNCE grammar there is 
an equivalent B,d-edNCE grammar (see the discussion after Theorem 1.3.30). 
Hence Cbntd-edNCE = HR. 
Definition 1.3.25 
An 
edNCE 
grammar 
G 
= 
( C , A , r , R , P , S )  is 
apex, 
or 
an 
A-edNCE grammar, if for every production X + ( D , C )  and every con- 
nection instruction (0, 
P/y, %, d) E C ,  x and B are terminal. 
In Example 1.9, grammar GI, G‘, , and G3 are apex, and the others are not. 
The idea of an apex grammar G (introduced in Definition 1.4.9 of [86] and 
studied in, e.g., [41,42]) is that nonterminal nodes cannot “pass neighbours” 
to each other. When a nonterminal node u is replaced by a daughter graph 
D, only terminal nodes of D can be connected to the neighbours of v (which 
are terminal nodes too). This easily implies that the set of sentential forms 
of G, and in particular the language generated by G, is of bounded degree 
(which means that there is a bound on the degree of all nodes of all sentential 
forms): the edges of a node z are generated when z itself is generated in 
a daughter graph D , and when the nonterminal neighbours of x in D are 
rewritten. This way of building graphs is riminiscent of playing the domino 
game, and is particularly easy to visualize. Since every A-edNCE grammar is 
a B-edNCE grammar of bounded nonterminal degree, A-edNCE is a subset of 
B,d-edNCE, and hence of HR. There is a natural restriction on HR grammars 
that corresponds to the apex property, see [52,33]. 
In terms of c-labeled derivation trees, the apex condition means that if 
(u, P/r, z, d) is a connection instruction of yield(t), then vertext(.) is the root 
oft. This implies for an edge ( u , y , u )  of yield(t), that vertext(.) = vertext(u), 
or vertext(v) is a child of vertext(u), or the other way around. 
Definition 1.3.26 
An 
edNCE 
grammar 
G 
= 
( C , A , r , R , P , S )  is 
linear, 
or 
a 
LIN-edNCE grammar, if for every production X + (D,C), D has at 
most one nonterminal node. 
Grammars GI, G i ,  GL, Gs, G7, Gs, and Gg of Example 1.9 are linear. The gram- 
mar of Example 1.6(a) is also linear. 
Linear graph grammars are studied for the same reasons as linear string gram- 
mars (see, e.g., [86]). Their derivations are particularly easy to understand. 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
59 
Clearly, every LIN-edNCE grammar is a B-edNCE grammar. Since the re- 
sults of [52] hold for linear grammars too, LIN.B,d-edNCE = LIN-HR, and 
L1N.A-edNCE = L1N.A-HR, where linearity for HR grammars is defined in 
the obvious way. 
Linear edNCE grammars are maybe more powerful than one would expect: a 
fixed number of nonterminal nodes can be simulated by one (as opposed to 
the case of context-free string grammars). An edNCE grammar is nonterminal 
bounded if there is a bound on the number of nonterminal nodes in every 
sentential form of the grammar. It is shown in [39] that for every nonterminal 
bounded edNCE grammar there is an equivalent LIN-edNCE grammar (and 
the same holds for B,d and for apex grammars). This result does not hold for 
NLC grammars (see [38]). 
An inclusion diagram of the subclasses defined above, is given in Fig. 1.23 
(where, in order to improve the readability of the diagram, we have consistently 
omitted the suffix edNCE). The set of all binary trees is in A-edNCE (see G3 of 
Example 1.9) but not in LIN-edNCE (Theorem 16 of [39], see also Lemma 1.4.18 
of [86]). The set of all edge complements of all binary trees is in C-edNCE (see 
the end of Section 1.4.1, and Theorem 1.4.7) but not in B-edNCE (Theorem 35 
of [44]); in fact, for any graph language L that is in A-edNCE but not in LIN- 
edNCE, the set of edge complements of the graphs in L is in C-edNCE but not 
in B-edNCE. The set of all complete graphs is in LIN-edNCE (see grammar 
G6 of Example 1.9) but not in HR (see Theorem 1.3.27 below). The set of all 
stars is in LIN-HR (see Gg of Example 1.9) but not in A-edNCE (because apex 
languages are of bounded degree). 
The classes HR and A-edNCE can be characterized within the class C-edNCE: 
there are simple, and decidable, conditions on the graphs of a language L E 
C-edNCE that express membership of L in HR and in A-edNCE. To present 
these characterizations we need some more terminology. 
Recall that Km,n is the complete bipartite graph on m and n nodes (see G7 of 
Example 1.9). For a graph H we denote by und(H) the underlying undirected, 
unlabeled graph (i.e., V = VH, E = {(u, 
*,u) 
I (u,y,u) E EH or (v,y,u) E 
EH for some y}, and X(z) = # for every z E V). We will say that a graph 
language L is of bounded bi-degree if there exists a natural number n such 
that Kn,n is not a subgraph of any graph und(H), H E L (and hence the 
same holds for Km,m with m > n). This means that it is impossible to find 
a graph in L with 2n nodes u1,. 
. . ,unl v1,. 
, . ,u, such that there is an edge 
(in any direction) between each ui and each uJ, 1 5 i,j 5 n. As usual, a 
graph language L is of bounded degree if there exists n such that all nodes 
in all graphs of L have degree at most n. This is equivalent to saying that 
there exists n such that the star Kl,, is not a subgraph of any graph und(H), 

60 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
V R = C  
B / \  
/ \ /  
\ /  
L1N.A 
Figure 1.23: Inclusion diagram of C-edNCE and its subclasses. 
H E L. A graph language L is of bounded average degree (or sparse) if there 
exists n such that #EH 5 n . #VH for every H E L, i.e., if the number of 
edges of a graph of L is linearly bounded by its number of nodes. Of course, 
every language of bounded degree is also of bounded bi-degree and of bounded 
average degree, but, in general, the latter two properties are independent (see, 
e.g., Theorem VI.2.8 of [lo]: there is a graph language {Hk I k 2 ko}, for some 
natural number ko, such that # V H ~  = k ,  # E H ~  2 l/2(k3I2 - k4I3), and Hk 
has no subgraph K z , ~ ) .  
The following result is shown in [28]; see [lo81 for a related earlier result. 
Theorem 1.3.27 
For every graph language L E C-edNCE the following three properties are 
equivalent : 
L E HR, 
L is of bounded bi-degree, and L is of bounded average degree. 
It is decidable, for a C-edNCE grammar G, 
whether or not L(G) E HR. 0 
Thus, the set of all complete graphs is not in HR; and, e.g., the set of all graphs 
Km,n (which is in LIN-edNCE, see G7 of Example 1.9) is not in HR. 
It follows from Theorem 1.3.27 that every C-edNCE language of bounded de- 
gree is in HR. This was proved first for B-NLC languages in [76] and for 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
61 
B-edNCE languages in Theorem 7 of [52], and then for C-edNCE languages 
in [15,31]. The following grammatical characterization of the HR languages of 
bounded degree is shown in [33] (see also [48]). 
Theorem 1.3.28 
For every graph language L E C-edNCE, 
L E A-edNCE if and only if L is of bounded degree. 
It is decidable, for a C-edNCE grammar G, 
whether or not L(G) 
E A-edNCE. 
0 
It is open whether similar results hold for B-edNCE, LIN-edNCE, LIN.B,d- 
edNCE, and L1N.A-edNCE. It is proved in Theorems 12 and 18 of [39] that 
L1N.A-edNCE is properly included in the class of all linear edNCE languages 
of bounded degree. 
1.3.4 Normal forms 
In this subsection we discuss a number of normal forms of edNCE grammars. 
Some of the previous results can already be seen as normal form results. For 
instance, the C-edNCE grammar can be viewed as a normal form of the edNCE 
grammar, when only leftmost derivations are considered (Theorem 1.3.11), and 
Theorem 1.3.21 shows that blocking edges can be removed from C-edNCE 
grammars. Theorems 1.3.27 and 1.3.28 can also be viewed as normal form 
results, for languages of bounded (bi-)degree only. 
There are some normal forms that are similar to those for context-free string 
grammars. First of all, it is easy to see that every C-etlNCE grammar can 
be reduced, in the sense that nonterminals that do not occur in derivations 
sin(S,z) J* H with H terminal, can be removed; these nonterminals can be 
determined in exactly the same way as for context-free string grammars. Also, 
A-productions and chain productions can be removed from C-edNCE gram- 
mars. A production p of a C-edNCE grammar is a A-production if rhs(p) is the 
empty graph, and a chain production if rhs(p) has a single node, with a non- 
terminal label (for an example of a chain production, see the third production 
of Fig. 1.14). 
Lemma 1.3.29 
For every C-edNCE grammar an equivalent C-edNCE grammar can be con- 
structed without A-productions or chain productions. The same holds for the 
subclasses of Section 1.3.3. 

62 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
Proof 
The proof for A-productions is fully analogous to the one for context-free string 
grammars: substitute, in the right-hand sides of the productions, the empty 
graph A for some of the nonterminal nodes z that can generate A (i.e., for 
which sin(X,z) J* 
A, where X = X(z)). Now let G = (C,A,r,O,P,S) be 
a C-edNCE grammar without A-productions. The proof for chain productions 
is also the same as for context-free string grammars, except that we have to 
compute the correct connection relations. We construct G = (C, A, r, R, P’, S), 
where P’ is the smallest set of productions such that 
(1) P’ contains all non-chain productions of P, and 
(2) if p’ is in P’, and p E P is a chain production (copy, disjoint with p’) 
such that the single node z of rhs(p) has label lhs(p‘), then P’ contains the 
production lhs(p) + rhs(p) [z/rhs(p’)]. 
The correctness of this construction can be understood from the following 
fact. Let p and p’ be as above, and let H be a graph with a node v that is 
labeled with lhs(p). Then H[w/rhs(p)[z/rhs(p’)]] = H[v/rhs(p)][z/rhs(p’)], by 
associativity of substitution. This implies that every derivation of G’ can be 
turned into one of G with the same result, and, the other way around, that 
every leftmost derivation of G can be turned into one of G’ (note that in a 
leftmost derivation an application of chain production p has to be followed by 
a derivation step that rewrites z); hence L,,(G’) = L(G’) = L(G). 
It also 
implies that G’ is confluent, using the characterization of Proposition 1.3.6 
(or, alternatively, note the obvious fact that the construction in the proof of 
Theorem 1.3.11 does not introduce A-productions or chain productions). 
It can easily be verified that the above construction preserves all subclasses of 
Section 1.3.3. 
0 
From this lemma we obtain the following enumeration property of C-edNCE 
languages, as shown in a general framework in Corollary 10 of [107]. 
Theorem 1.3.30 
For every C-edNCE language L there is a constant c such that for every natural 
number n, #{[HI E L I #VH = n} 5 2“”. 
Proof 
Let G be a C-edNCE grammar generating L, without A-productions or chain 
productions. Then every derivation of a graph H with #VH = n is of length 
5 2n, and hence every (c- or p-labeled) derivation tree of such a graph has at 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
63 
most 2n vertices. Clearly, there are at most d2” abstract p-labeled derivation 
trees with 2n vertices, where d is the number of productions of G. 
As observed in [lo71 this implies that the set [GRA,~] 
of all graphs (over any 
A and 0) is not in C-edNCE. This is an unexpected weakness of context- 
free graph grammars that one has to live with; intuitively, the graphs in a 
context-free graph language are always “tree-like”. There does exist a non- 
blocking edNCE grammar G with L(G) = [ G R A , ~ ]  
(see, e.g., [46]). The fact 
that [GRA,Q] is not in C-edNCE also follows from the separator theorem of 
[96,14] mentioned after Lemma 1.3.18. Other graph languages that are not in 
C-edNCE as a consequence of Theorem 1.3.30 are, e.g., the set of all connected 
graphs and the set of all tournaments (where a tournament is a graph with 
exactly one edge between every two nodes); note that the set of acyclic tour- 
naments (or linear orders) is in LIN-edNCE, by an obvious modification of 
grammar Gg of Example 1.9. 
It can now be shown that Cbntd-edNCE = HR (cf. the discussion before Defi- 
nition 1.3.25). Let G be a C-edNCE grammar of bounded nonterminal degree. 
By the proof of Lemma 1.3.29, we may assume that G has no A- or chain 
productions. This implies that L(G) is of bounded average degree (see The- 
orem 1.3.27). In fact, if H € L(G) has n nodes, then it has a derivation of 
length 5 2n (as in the proof of Theorem 1.3.30). At each step of the deriva- 
tion, at most 2gm2 daughter edges are added and at most 2gmk new edges 
are established by the embedding, where g is the number of edge labels, m is 
the maximal number of daughter nodes, and k is the bound on the nonter- 
minal degree. Hence, H has at most 4g(m2 + m)k . n edges. It follows from 
Theorem 1.3.27 that L(G) is in HR. 
We now turn to an analogue of Chomsky Normal Form: a C-edNCE grammar 
G is in Chomsky Normal Form if for every production p of G, either rhs(p) 
has two nodes, not both with a terminal label, or rhs(p) has one node, with a 
terminal label. The following result is stated in Lemma 4 of [14]; see also the 
results on Chomsky Normal Form in [84,86]. 
Theorem 1.3.31 
For every C-edNCE grammar an equivalent C-edNCE grammar in Chomsky 
Normal Form can be constructed. The same holds for the subclasses B, Bnd, 
LIN, and LIN.B,d. 
Pro0 f 
Again, the proof is similar to the one for context-free string grammars. We 
use a variation of the proof in [87]. Let G be a C-edNCE grammar without 
A-productions or chain productions, and let p : X + (D, C) be a production of 

64 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
G that does not have the required form. We will show that this production can 
be simulated by two productions pl : X + ( 0 1 ,  C1) and pz : Y + ( 0 2 ,  CZ), 
where p l  is as required, and Dz is the result of removing one node from D. 
Repetition of this construction produces a grammar in Chomsky Normal Form. 
Let zo be a fixed (but arbitrary) node of D ,  with label ao. Take a new nonter- 
minal Y, and new edge labels (z, y) and (7, 
z) for every (old) edge label y and 
every node z of D ,  z # zo. The edge label (z,y) 
will be used on an outgoing 
edge of a Y-labeled node y ,  to indicate that when y produces Dz, the edge 
should be connected to z (and similarly for (7, 
z) and incoming edges). 
Production pl is defined as follows: D1 is a graph with two nodes y and zo 
(where y is new), labeled Y and 00, respectively, and all edges ( y ,  (z,y),zo) 
with (z,y,zo) E ED, and (xo,(y,z),y) with (zo,y,z) E ED; C1 contains 
all connection instructions (CT, Ply, 50, d) that are in C ,  and all connection 
instructions (0, 
y/y, 
y, d). 
Production p2 is defined as follows: 0 2  is the subgraph of D induced by 
VD - ( 5 0 ) ;  C, contains, for 5 E Vo - {zo}, all connection instructions 
(a, P/r, z, d) that are in C ,  and all connection instructions (a, (z, y)/y, z, out) 
with (z,y,zo) E ED, and (a, ( ~ , z ) / y , z , i n )  
with (zo,y, T) E ED. 
Let G’ be the grammar obtained from G by replacing p with pl and p z .  Since 
( 0 1 ,  Cl)[y/(Da, 
CZ)] = (0, 
C ) ,  it can be shown as in the proof of Lemma 1.3.29 
that Llm(G’) = Ll,(G) (where we take xo to be the last node in both pro- 
ductions p and p l ;  this forces an application of pz directly after one of pl in a 
leftmost derivation of G’). 
In general, G’ is not confluent (to see this, consider the application of pro- 
ductions to the two nodes of D1, assuming that z o  is nonterminal). Since the 
above construction works for arbitrary edNCE grammars (with leftmost deriva- 
tions), it would suffice to observe that the construction in the proof of Theo- 
rem 1.3.11 does not change the nodes (and their labels) of the right-hand side of 
a production. However, it is not difficult to turn G’ into a confluent grammar: 
just add to each production X’ + (D’,C‘) of G’ all connection instructions 
with (a, P/r, z, in) E C’. 
Also, if G is a B-edNCE grammar, then G’ need not be one. The problem is that 
if zo is a nonterminal node, then pl violates the boundary condition. However, 
the construction works if one chooses z o  to be a terminal node whenever D 
has one. Note that if D has nonterminal nodes only, then it has no edges, and 
hence D1 has no edges. It is easy to verify that this construction also preserves 
(a, 
(P, Z)/(Y, z ) , z ,  out) with (0, P/r, z, out) E C’, and all (a, 
(2, P ) / ( z ,  Y), z, in) 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
65 
the Bnd and the LIN properties. It does not preserve the apex property, due 
0 
to the connection instructions (CT, y/y, 
y, d) in C1. 
It is more usual to require for Chomsky Normal Form that right-hand sides 
with two nodes have nonterminal nodes only. It is not difficult to show that, 
for a C-edNCE grammar, this requirement can be met by a similar trick as 
for context-free string grammars. For B-edNCE grammars, it would mean that 
only discrete graphs can be generated. 
Note that LIN-edNCE grammars in Chomsky Normal Form are very close 
to the right-linear context-free string grammars: at every derivation step, the 
unique nonterminal node generates one terminal node (see the grammar in 
Example 1.6(a)). 
For apex grammars there is no Chomsky Normal Form. Even worse, there 
does not exist a normal form for apex grammars with a fixed bound on the 
number of nonterminal nodes in the right-hand side of a production. This is 
shown in [48] for HR grammars (and nonterminal hyperedges, of course), but 
the argument can easily be carried over to A-edNCE grammars (it is based on 
the property of derivation trees mentioned just before Definition 1.3.26). The 
set of all k-ary trees can be generated by an A-edNCE grammar with at most 
k nonterminal nodes in each right-hand side, but not with less than k. 
A C-edNCE grammar G is in Operator Normal Form (ONF) if the right-hand 
side of each production of G contains exactly one terminal node (see grammars 
Gz, . . . , G5 of Example 1.9). It seems to be likely that there exists an equivalent 
grammar in ONF for every C-edNCE grammar, but no proof can be found in 
the literature. For B-edNCE grammars this is proved in Theorem 24 of [44] 
(where it is called Greibach Normal Form). The construction in that proof 
preserves the Bnd property, and a similar construction can be used to show the 
existence of ONF for A-edNCE grammars (note that A-edNCE productions 
that have nonterminal nodes only, are of a very simple type: the set of edges 
and the connection relation are both empty). For linear grammars we observe 
that every LIN-edNCE in Chomsky Normal Form (Theorem 1.3.31) is also in 
Operator Normal Form. 
There are also normal forms that concern the embedding process, and in par- 
ticular the edges that are incident with nonterminal nodes. An edge that is 
incident with a nonterminal node u of a sentential form, is usually needed in 
order to connect terminal nodes generated by u to neighbours of u, using the 
connection instructions. In the next normal form (introduced in Definition 1.4.9 
of [SS]), it is required that all such edges are indeed used for that purpose, i.e., 

66 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
nonterminal nodes do not have superfluous edges. Intuitively it means that, 
when a production is applied, every edge that is incident with the mother 
node should be “passed” to at least one node of the daughter graph, i.e., edges 
are not “dropped” by the embedding process. This implies that every neigh- 
bour of the mother node is the neighbour of at least one daughter node (which, 
in general, is not equivalent with the above requirement, due to the presence 
of multiple edges). 
Definition 1.3.32 
An edNCE grammar G is neighbourhood preserving if, for every sentential form 
H of G, every nonterminal node v of H ,  and every production p with lhs(p) = 
XH(W), the following holds: 
if (w, p, v) is in EH ((v, 0, 
w) is in E H ) ,  then rhs(p) has a connection instruction 
of the form ( X ~ ( w ) , p / y , z , d )  
with d = in (d = out, respectively). 
All grammars in Example 1.9 are neigbourhood preserving. If one adds to Gz 
a production p: which is the same as p, except that it has connection relation 
C; = { (n, e / e ,  z ,  in)} instead of C, = { (n, e / e ,  z ,  in), (n, r/e, z ,  out)}, then a 
grammar is obtained that is not neighbourhood preserving. It generates the 
set of all binary trees such that the root is connected to some of the leaves 
(rather than all the leaves). 
The neighbourhood preserving normal form was proved for B-NLC in [92], for 
B-edNCE in [52], and for C-edNCE in [loll. 
Theorem 1.3.33 
For every C-edNCE grammar an equivalent neighbourhood preserving C- 
edNCE grammar can be constructed. The same holds for the subclasses of 
Section 1.3.3. 
Proof 
Let G = (C, A, r, 0, P, S )  be a C-edNCE grammar. Similar to the proof of 
Theorem 1.3.21, we define, for a terminal graph H E G R E A , ~ ,  
info(H) = 
{(a,P/y,X~(z),d) 1 (a,P/y,z,d) E CH for some z E VH}. First, we construct 
the equivalent C-edNCE grammar G’ = (C’, A, r, R, P‘, S’) as in the proof of 
Theorem 1.3.21 (but without the booleans). Note that C’ = ((C-A) x Q)UA, 
where Q is the powerset of C x r x r x A x {in, out}, and S’ = (S, 8). Thus, 
every nonterminal of G’ is of the form ( X ,  q ) ,  where X is a nonterminal of G 
and q is the info of the terminal graph generated by sin(X, zj in G. From q we 
can see which incident edges the nonterminal is going to use; the others can 
be deleted. So, in G’, whether or not an edge (v,y,w) is useful, in this sense, 

1.3. NODE REPLACEMENT GRAMMARS WITH NCE 
67 
depends on (X(v), y, 
X(w)) only. We define the triples in C' x r x C' that are 
useful, as follows. 
Any triple (a, P, b) with a, b E A is useful. A triple (a, P, ( X ,  4)) is useful 
if q contains some (a,P/y, b,in) with y E r and b E A, and, analogously, 
( ( X ,  q ) ,  P, b) is useful if q contains some (b, Ply, a, out) with y E r and a 6 A. 
A triple ( ( X I ,  q l ) ,  P, (X2, q 2 ) )  is useful if there exist tuples (X2, Ply, a, out) E 
q1 and (a,y/b,b,in) E q2, for some a,b E A and y , b  E I?. Note that the 
last definition can equivalently be stated with 1 and 2, and 'out' and 
interchanged (cf. Definition 1.3.5); this follows from Lemma 1.3.17. 
From G', the desired grammar G" is obtained by throwing away all useless 
edges and all useless connection instructions from the right-hand sides of the 
productions of GI, where an edge (v,y,w) is useless if (A(v),y,A(w)) is not 
useful, a connection instruction (d, P/y, z, in) is useless if (d, y, 
X(z)) is not 
useful, and a connection instruction (d, P/-y, 2, out) is useless if (X(z), y, a') is 
not useful. 
It can be verified that GI' is a C-edNCE grammar, equivalent with GI. It is 
easy to see that the sentential forms of G" contain useful edges only. From this 
0 
it can be deduced that G" is neighbourhood preserving. 
As an alternative (static) definition of the neighbourhood preserving property 
we could require that for every 0 E C, P E r, d E {in, out}, and every produc- 
tion p ,  rhs(p) has a connection instruction of the form (a,P/y,z,d). In fact, 
missing connection instructions can be added (because they will never be used) 
in such a way that the resulting grammar is still confluent. The details are left 
to the reader. 
For a node v of a graph H we define the context of v in H by contH(v) = 
context of a nonterminal node v indicates precisely which kinds of edges are 
incident with v, to be used by the embedding process. For boundary grammars 
it is possible to store the context of a nonterminal node in its label, as shown 
in Section 3 of [92]. An edNCE grammar G is context consistent if there is a 
mapping 77 from C - A to the set of all possible contexts, such that for every 
nonterminal node v of every sentential form H of G, contH(v) = ~(XH(V)). For 
every B-edNCE grammar there is an equivalent context consistent B-edNCE 
grammar (Lemma 4 of [52]), and the same is true for the subclasses of Sec- 
tion 1.3.3 below B-edNCE. It should be clear that there cannot be a context 
consistent normal form for arbitrary C-edNCE grammars: the context of a node 
can change when one of its neighbours is rewritten. For B-edNCE grammars 
one could introduce productions of the form: X + (D, 
C )  provided c, which 
{ ( Y , X H ( w ) )  I (v,Y,w) E EH) u {(XH(w),y) I (w,Y,v) 
E EH}. Thus, the 

68 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
can only be applied to a node v with label X if v has context c; thus, contexts 
are used as application conditions (see Theorem 3.3 of [92]). For C-edNCE 
grammars such productions would allow the generation of non-context-free 
graph languages such as the set of all stars Kl,m with m a power of 2. 
1.4 Characterizations 
The class C-edNCE of graph languages generated by confluent edNCE gram- 
mars can be characterized in a number of different ways, showing the robustness 
and naturalness of the class. The characterizations we have in mind are the fol- 
lowing: by leftmost derivations in edNCE grammars, i.e., C-edNCE = L-edNCE 
(Theorem 1.3.11), by regular tree and string languages, by Monadic Second Or- 
der logic translation of trees, by handle replacement graph grammars, and by 
regular sets of graph expressions. In this section these characterizations (except 
the first) will be discussed one by one. 
1.4.1 Regular path characterization 
As observed before, all graphs generated by a C-edNCE grammar are “tree- 
like”. An alternative way of describing a set of “tree-like” graphs H is by taking 
a tree t from some regular tree language, defining the nodes of H as a subset of 
the vertices oft, and defining an edge between nodes u and v of H if the string 
of vertex labels on the shortest (undirected) path between u and v in t belongs 
to some regular string language. Such a description of a graph language will be 
called a regular path description. This idea was introduced in [log], for linear 
graph grammars, and investigated for LIN-edNCE and B-edNCE grammars in 
[44], and for C-edNCE grammars in [87,46,51]. 
Let us first define the regular tree languages. The following definition of a 
regular tree grammar (in normal form) as a special type of A-edNCE grammar, 
is equivalent with the usual one (see [55]). As usual, a ranked aZphabet is an 
alphabet A together with a mapping rank : A + {0,1,2,. . . }. By 
we 
denote the maximal number rank(u), u E A. 
Definition 1.4.1 
An edNCE grammar G = (C,A,r,R,P,S) is a regular tree grammar, or a 
REGT grammar, if A is a ranked alphabet, 
= 0 = (1,. . .,ma}, and for 
every production X + (D,C) in P: 
VD = (20, 
xi,. . . , xk} for some k 2 0, 
AD(ZO) E A with rank(AD(z0)) = k, and AD(z~) E C - A for 1 _< i 5 k, 
ED = {(zo,i,zi) 
11 5 i 5 I c } ,  and 
C = {(u,z,z,z~,in) 
I i E r,u E A}. 

1.4. CHARACTERIZATIONS 
69 
Thus, for a production p of a regular tree grammar, rhs(p) consists of a (termi- 
nal) parent 20, and k (nonterminal) children 2 1 ,  . . . , xk. Edges lead from the 
parent to each child, and the children are ordered by numbering their edges 
from 1 to k. Such a production X + (D,C) 
can (modulo isomorphism) be 
denoted uniquely as X -+ C T X ~  
. . ' X I ,  with (T = XD(ZO) and X i  = XD(Z~) for 
l < i < k .  
A graph language generated by a REGT grammar is a regular tree language. 
For a ranked alphabet A, we denote by TA the set of all trees over A, i.e., the 
regular tree language generated by the REGT grammar with one nonterminal 
X and all productions X + oxk for every (T E A, where k = rank(a). 
As observed in Section 1.3.2, the set D(G) of (p-labeled) derivation trees of 
an edNCE grammar G is a regular tree language. In fact, it is generated by 
the regular tree grammar GD which has the set P of productions of G as 
ranked alphabet (where, for p E P ,  rank(p) is the number of nonterminal 
nodes in rhs(p)) and has the same nonterminals (and initial nonterminal) as 
G. For each production p of G, GD has the production X + pX1 . . . x k ,  where 
X = lhs(p) and XI, . . . , x k  are the labels of the nonterminal nodes of rhs(p), 
in that order. 
We now turn to the regular path description of graph languages. For an alpha- 
bet C, c = {Ti I CT E C}. 
Definition 1.4.2 
A regular path description is a tuple R = (C, A, R, T ,  h, W ) ,  where C is a ranked 
alphabet, A and R are alphabets (of node and edge labels, respectively), T is 
a regular tree language in Tc, h is a partial function from C to A, and W is a 
mapping from R to the class of regular string languages, such that, for every 
y E R, W(y) 
C*cC*. The graph language defined by R is L(R) = { [ g r ~ ( t ) ]  
I 
t E T } ,  where grR(t) is the graph H E GRa,n such that 
VH is the set of vertices w o f t  for which &(v) is in the domain of h, 
X H ( D )  = h(Xt(v)) for w E VH, and 
EH is the set of all edges (u,y,w) such that path,(u,v) E W(y), where 
path,(u, w) is the sequence of labels of the vertices on the shortest (undirected) 
path in t from u to w, in which the label CT of the least common ancestor of u 
and w is barred, i.e., replaced by Ti. 
Note that L(R) 5 [ G R A , ~ ] .  
Note that h is used both to determine which 
vertices of the tree t are nodes of the graph grR(t), and to define their labels 
in that graph (on the basis of their labels in the tree). Note that for each edge 
label y, W(y) is the regular string language that defines the graph edges with 

70 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
label y. And note that the shortest path from vertex u to w first ascends from 
u to the least common ancestor z of u and u, and then descends from z to w. 
Let RPD denote the class of graph languages that are defined by regular path 
descriptions. The main result of [51] is that RPD = C-edNCE. 
To give an idea of the intuition behind this result, consider the inclusion C- 
edNCE C RPD. One starts from a (nonblocking) C-edNCE grammar G such 
that each right-hand side of a production contains at most one terminal node, 
for instance by taking G to be in Chomsky Normal Form, see Section 1.3.4. A 
regular path description R of L(G) then has the set D(G) of p-labeled deriva- 
tion trees of G as regular tree language T .  Consider some p-labelled derivation 
tree t of GI and let t also denote a corresponding c-labeled derivation tree. R 
is defined in such a way that grR(t) = yield(t). By the above assumption, the 
function vertext that maps each node u of yield(t) to a vertex vertext(u) oft is 
injective. This means that the vertices o f t  that are labeled with a production 
p that has one terminal node in its right-hand side, can be used to represent 
the nodes of yield(t). Thus, the function h is defined for those productions 
p only, and h(p) is the label of the terminal node of rhs(p). The remaining 
problem is how to express the graph edges (u, y, 
w) in the regular language 
W(y), i.e., through the labels of the path from vertext(.) to vertext(u). This is 
done by simulating the embedding behaviour of G along that path by a finite 
automaton. For details see [51,46]. 
Example 1.13 
Consider the grammar G2 of Example 1.9. A regular path description R = 
(C, A, R, TI h, W )  of the graph language L(G2) (of all binary trees with edges 
from the leaves to the root) is defined as follows. C = {a, b, c} with rank(a) = 
rank(b) = 2 and rank(c) = 0 (where a, b, and c are used instead of pa, pa, 
and p,, for readability). A = {#} and R = {*}. T = D(Ga), the regular 
tree language of all p-labeled derivation trees of G2, which is generated by the 
regular tree grammar with productions S + a X X ,  X -+ bXX, and X -+ c 
(see Fig. 1.22(a) for an example of such a derivation tree). The node relabeling 
h has domain C, and h(a) = h(b) = h(c) = #. Finally, W(*) = WI(*) U W2(*) 
where W1(*) = {ab,~c,6b16c} 
and Wz(*) = cb*h. WI(*) is used to keep the 
edges of the tree t in the graph grR(t), and W2(*) is used to add the edges 
from the leaves to the root. 
A regular path description of L(G3) (all binary trees) is the same as R above 
except that W(*) = W1(*). For L(G4) (all transitive binary trees) we take 
W(*) = iib+ U ab*c U bb+ U 6b'c. 

1.4. CHARACTERIZATIONS 
71 
To obtain a regular path description for the graph language L(G5) (where the 
leaves are chained by f-labeled edges) is a bit more work, because we have 
hidden a technical detail from the above intuitive sketch of the proof. In fact, 
we need to be able to see from the label of a node whether it is the first or 
second child of its parent. Thus, we take the regular tree language generated 
by the productions S + aLR, L -+ blLR, R + b,LR, L + c1, and R + c,. 
I3 
And then we take W(f) = (c,b:bl U q ) ( Z  U ff U b,)(b,btcl U C r ) .  
Let B-RPD be the subclass of RPD obtained by restricting every W(y) to be a 
subset of C*C U CC* (see the examples above, except the last one). This means 
that graph edges are only established between tree vertices of which one is a 
descendant of the other (which is in accordance with the property of derivation 
trees of B-edNCE grammars mentioned just before Definition 1.3.24). It is 
shown in [44] that B-RPD = B-edNCE. Let LIN-RPD be the subclass of RPD 
obtained by restricting the symbols of the ranked alphabet C to have rank 1 
or 0. This means that the trees in the regular tree language are in fact strings 
(and note that derivation trees of LIN-edNCE are strings). Thus, a linear RPD 
uses regular string languages only. As an example, a regular path description 
of the set of all cycles (see L(GL) of Example 1.9) is obtained from the one 
of L(G2) in the above example by taking T = ub*c. It is shown in [44] that 
LIN-RPD = LIN-edNCE. Let A-RPD be the subclass of RPD obtained by 
restricting every W(y) to be finite. Thus, graph edges can only be established 
between tree vertices that are at a bounded distance from each other. It is 
shown in [51], using Theorem 1.3.28, that A-RPD = A-edNCE. 
Altogether we have the following result. It is not clear whether a natural RPD 
characterization exists for the B,d-edNCE graph languages 
_
_
 
Theorem 1.4.3 
C-edNCE = RPD, B-edNCE = B-RPD, A-edNCE = A-RPD, and LIN-edNCE 
= LlN-RPD. 
0 
For a graph H ,  its edge complement is the graph ec(H) = (VH, E, AH) where 
E is the set of all (w,y,w), w # w, 
that are not in EH. Since the regular 
string languages are closed under complement, it follows from Theorem 1.4.3 
that C-edNCE and LIN-edNCE are closed under edge complement (i.e., if 
L E C-edNCE then {ec(H) I H E L }  E C-edNCE). Thus, the set of edge 
complements of binary trees is in C-edNCE, and the set of edge complements of 
chains is in LIN-edNCE (see Example 1.6(a)). The class of B-edNCE languages 
is not closed under edge complement (see [44]). 

72 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
1.4.2 
Logical characterization 
The most useful, and entirely grammar independent, characterization of 
C-edNCE is by Monadic Second Order (MSO) logic. In particular, it leads 
to a lot of closure and decidability properties of C-edNCE. The main idea is 
that of an MSO definable function on graphs, introduced in [47,26]. The char- 
acterization says that C-edNCE is the class of all graph languages ~ ( T A )  
where 
TA is the set of trees over a ranked alphabet A and f is an MSO definable 
function from trees to graphs. Since f is defined on trees t, the graphs f ( t )  
are “tree-like”. The usefulness of the MSO characterization is that MSO logic 
is a convenient language to talk about graphs, and hence can be used as a 
specification language for sets of graphs and functions on graphs. Many results 
on C-edNCE languages have a proof through the MSO characterization that is 
much easier than the one based on C-edNCE grammars. For more information 
concerning the relationship between VR (= C-edNCE) and MSO logic we refer 
to Chapter 3. 
For alphabets C and r, we define a monadic second-order logical language 
MSOL(C, r), of which each closed formula expresses a property of the graphs 
in G R Z , ~ .  
The language has node variables, denoted u, u, . . . , and node-set 
variables, denoted U, V, . . . . For a given graph H ,  each node variable ranges 
over the elements of VH and each node-set variable over the subsets of VH. 
There are four types of atomic formulas in MSOL(C,I‘): laba(u), for every 
0 E C, edge,(u,v), for every y E I’, u = u, and u E U .  Their meaning 
should be clear: node u has label 0, there is an edge with label y from node 
u to node u, nodes u and u are the same, and node u is an element of node- 
set U ,  respectively. The formulas of the language are constructed from the 
atomic formulas through the propositional connectives A, V, 1, +, H, and 
the quantifiers V and 3, in the usual way. Note that not only node variables 
but also node-set variables may be quantified (which makes the logic monadic 
second-order rather than first-order). Note also that there are no edge or edge- 
set variables. As usual, a formula is closed if it has no free variables. For a 
closed formula 4 of MSOL(C, I‘) and a graph H of GRc,r we write H 
4 if 4 
is true for H .  If formula 4 has free variables, say u, u, and U (and no others), 
then we also write the formula as 4(u, u, U ) ;  if graph H has nodes x, y E VH 
and a set of nodes X C VH, then we write H 
+(z,y,X) to mean that 4 is 
true for H when u, u, and U are given the values x, y, and X ,  respectively. 
It is well known that there exists an MSOL formula path(u, w) that expresses 
the existence of a directed path from u to u (see Section 5.2.7 of Chapter 3). 
Thus, as a very simple example, H 
VuVu : path(u,u) means that H is 

1.4. CHARACTERIZATIONS 
73 
strongly connected. As another example, bipartiteness of a graph is expressed 
by the formula 3U3V : (part(U, V)AVuVv : edge(u, v) -+ (u 
E UAv E V ) V ( u  E 
V A v E U ) ,  where part(U, V )  expresses that U and V form a partition of the 
set of all nodes, and edge(u,v) is an abbreviation of the disjunction of all 
edge,(u,v), 
E r. 
Definition 1.4.4 
A graph language L C [GRc,r] is MSO definable if there is a closed formula C#J 
in MSOL(C,r) such that L = {[HI E [GRc,r] I H t= 
q5}. 
Many sets of graphs that are not “tree-like”, are MSO definable. Thus, as 
shown above, the set of strongly connected graphs and the set of bipartite 
graphs are MSO definable. Other examples of MSO definable sets of graphs 
are: all planar graphs, grids, chordal graphs, trees, and, for fixed k ,  k-colourable 
graphs, k-connected graphs, etc. (see Chapter 3). 
For tree languages L C TA (as defined in Section 1.4.1) the following classical 
result is well known: a tree language is MSO definable if and only if it is a reg- 
ular tree language; the analogous classical result holds for string languages (cf. 
Section 5.7.4 of Chapter 3). For graph languages there is no generally accepted 
notion of regularity, but the MSO definable graph languages enjoy several prop- 
erties that are similar to those of the regular tree and string languages (see, 
e.g., Theorem 1.4.7). 
We now turn to MSO definable functions f. The idea is that, for a given input 
graph H ,  the nodes, edges, and labels of the output graph H‘ = f ( H )  are 
described in terms of MSOL formulas on H .  For each node label g of H’ there 
is a formula &(u) expressing that u will be a node of H‘ with label 0. Thus, 
the nodes of H’ are a subset of the nodes of H .  For each edge label y of H’ 
there is a formula &(u, w) expressing that there will be a y-labeled edge from 
u to v in H’. Finally, to allow for partial functions, there is a closed formula 
&om that specifies the domain dom(f) of f (which means that dom(f) is an 
MSO definable set of graphs). 
Definition 1.4.5 
Let Ci and ri be alphabets, for i E {1,2}. An MSO definable function f : 
GRcl,rl -+ GRcz,rz is specified by formulas in MSOL(C1,I’l), as follows: 
0 a closed formula &om, the domain formula, 
0 a formula &(u), for every rs E C2, the node formulas, 
0 a formula &(u, v), for every y E r2, the edge formulas. 

74 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
The domain of f is { H  E GRc,,r, I H 
f ( H )  is the graph (V, E ,  A) E GRc,,r, such that 
&om}, 
and for every H E dom(f), 
0 V = {x E VH 1 there is exactly one (T E CZ such that H 
q6u(z)) 
E = {(Z,Y,Y) I Z I Y  
VIZ # Y,Y E Fa1 and H k 4,(Z,Y)>, 
and 
for x E V, A(x) = (T where H + &(x). 
Note that an MSO definable function f also works on abstract graphs. Thus, we 
will also view f as a function [GRc,,r,] + [GRc,,r,] with dom(f) 5 [GRc,,r,]. 
In Chapter 3, the MSO definable functions defined above are the non-copying 
(1 ,l)-definable transductions without parameters. 
Many functions on graphs are MSO definable, for instance, node relabelings, 
edge relabelings (cf. Proposition 1.3.8), edge complement, transitive closure, 
Hasse diagram, and the function that maps a cotree into the cograph it rep- 
resents (where a cotree of a cograph is the tree representing an expression, in 
terms of the operations of disjoint union and join, which denotes the graph, cf. 
Example 1.9(10) and [21]). 
Example 1.14 
(1) Consider the function f that is defined for every acyclic graph in GRc,r and 
computes its transitive closure in GRc,rq,) , where T is used to label the new 
edges. To show that f is MSO definable, we take $dam to be ~(3u3w 
: ~ ( u  
= 
w) A path(u, w) A path(v, u)), 
expressing that the input graph H is acyclic. For 
every (T E C, &(u) is Zab,(u), i.e., every node of H is a node of f ( H )  and has 
the same label. Finally, &(u, u) is edge,(u, v), for every y E I?, and &(u, w) is 
path(u,u). Thus, the edges of H remain in f ( H ) ,  but f ( H )  also contains all 
edges that correspond to paths in H .  
(2) In this example we show that the function yield, defined on the p- 
labeled derivation trees of the edNCE grammar Gz of Example 1.9(2), 
is MSO definable. Note that yield : [GR{a,b,c),{l,2}] 
+ [GR{,},{,)] and 
dom(yie1d) = D(Gz). For an example of an input and an output graph, see 
Fig. 1.22(a) and (b), respectively. For &om we take 4 b t  A Vu : (lab,(u) t) 
root(u)) A (lab,(u) t) leaf(u)), where &,t is a formula expressing that the 
input graph is a rooted, ordered binary tree, root(u) is 1% : edge(v,u), 
leaf(u) is ~ 3 u  
: edge(u,v), and edge(u,u) is edge,(u,v) V edge,(u,v). For 
q5#(u) we take u = u (which is always true), and for q5*(u,w) we take 
edge(u,v) v (leaf(u) A root(v)). This shows that the yield function of Gz is 
MSO definable. It is easy to see that the same holds for G3 and Gq. For G5 we 

1.4. CHARACTERIZATIONS 
75 
take 4j(u, u) to be left(u, w) A ~ 3 w  
: left(u, 20) A left(w, w), where left(u, u) is 
leaf (u) 
A leaf (u) 
A 3u’, w’, z : edge, ( z ,  u’) A edge, ( z ,  w’) A path(u’, u) 
A path( u’, 
u) , 
i.e., left(u,u) expresses that u and w are leaves such that u is to the left of u 
0 
in the given (ordered) derivation tree. 
The logical characterization of C-edNCE is the following (presented in [47], 
proved in [87], and generalized in [27]): C-edNCE = MSOF(TREES), where 
MSOF(TREES) denotes the class of all graph languages ~ ( T A )  
where TA is 
the set of all trees over some ranked alphabet A and f is an MSO definable 
function from G R A , { ~ , . . . , ~ ~ }  
to some GRc,r (for the definition of TA and 
ma, see Section 1.4.1). Let MSOF(STR1NGS) denote the class of all f(Ta) 
as 
above, with the restriction that the symbols of A all have rank 1 or 0. Then 
LIN-edNCE = MSOF(STR1NGS). To obtain a characterization of B-edNCE, 
we define B-MSOF(TREES) to be the class of all f(Ta) 
as above, with the 
restriction on f that for every edge formula c,h,(u,w) and every input tree 
t E dom(f), t 
Vu, u : &(u, u) + (path(u, u) V path(u, u)); as in the case of 
B-RPD, this means that graph edges are only established between tree vertices 
of which one is a descendant of the other. These results are summarized in the 
following theorem. 
Theorem 1.4.6 
C-edNCE = MSOF(TREES), B-edNCE = B-MSOF(TREES1, and 
LIN-edNCE = MSOF(STRINGS). 
0 
In 1181 a similar characterization is shown for Bnd (i.e., HR), of another nature: 
in this case, both the nodes and the edges are defined to be (disjoint) subsets 
of the set of vertices of the input tree, and the incidence relation between 
nodes and edges is defined by an MSOL formula. For details see Section 5.6.3 
of Chapter 3. 
In one direction, the proof of Theorem 1.4.6 in [87] is based on the fact that the 
yield function of an edNCE grammar is MSO definable (cf. Example 1.14(2)). 
In fact, this is quite straightforward using the regular path characterization 
of Theorem 1.4.3: roughly speaking, the regular tree language can be turned 
into the domain formula of the MSO definable function (because regular tree 
languages are MSO definable), and the regular string language W(y) can be 
turned into the edge formula &(u,w) (because regular string languages are 
MSO definable, and because the shortest path from u to w can be expressed in 
MSOL). In the other direction the proof is also based on Theorem 1.4.3. 

76 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
From Theorem 1.4.6 a lot of closure properties and decidability results can be 
deduced, which we will now discuss (see [47]). We start with closure properties. 
It is not hard to see that the class of MSO definable functions is closed under 
composition. Note also that for every MSO definable graph language L, the 
identity on L is an MSO definable function. This gives the following result. 
Theorem 1.4.7 
C-edNCE and LIN-edNCE are closed under MSO definable functions. In par- 
ticular, they are closed under intersection with MSO definable sets of graphs. 
0 
Since taking edge complement is MSO definable, B-edNCE is not closed under 
MSO definable functions (see the end of Section 1.4.1). However, B-edNCE is 
closed under intersection with MSO definable sets (because the composition 
of an MSO definable function f with an MSO definable identity only restricts 
the domain formula of f). By Theorem 1.3.28, A-edNCE is also closed under 
intersection with MSO definable sets. 
The closure under intersection with MSO definable sets was first proved by 
Courcelle in Corollary 4.8 of [24] (for the case of HR), which was the basis 
for all further developments in this area. For C-edNCE it was first shown in 
Theorem 6.9 of [20]. We now show how this closure result leads to examples 
of graph languages that are not in C-edNCE. Let Gm,n be the m x n grid, 
i.e., the graph with #-labeled nodes ui,j, 1 5 i 5 m, 1 5 j 5 n, and all 
edges (ui,.j, h, u i , j + ~ )  
and (ut,j, v ,  ui+~,.j) (where h and v indicate ‘horizontal’ 
and ‘vertical’ edges, respectively). A square grid is a grid Gn,n. It is not dif- 
ficult to show that the set of all grids is MSO definable: a grid is an acyclic, 
connected graph such that (1) each node has at most one incoming/outgoing 
horizontal/vertical edge, (2) if (2, 
h, PI), (yl, w, ZI), (z, w, yz), and (y2, h, 2 2 )  are 
edges, then z1 = 2 2 ,  and (3) if there is a horizontal edge from z to y or from y 
to z, and z has an outgoing (incoming) vertical edge, then y has an outgoing 
(incoming, respectively) edge; and similarly with ‘horizontal’ and ‘vertical’ in- 
terchanged. The set of all square grids is also MSO definable: a grid is square 
if there is a path n from the node with no incoming edges to the node with 
no outgoing edges such that the sequence of edge labels of n is in (hv)’, i.e., 
T is a “diagonal”. The following result was proved in Corollary 4.3 of [94] for 
B-NLC, and extended to C-edNCE in Theorem 1.5.16 of [96] (see also [14]); 
see Section 4 of [24] for HR. 
Proposition 1.4.8 
No C-edNCE graph language contains infinitely many square grids. 

1.4. CHARACTERIZATIONS 
77 
Pro0 f 
Let L be a C-edNCE language and let Lg = L n {[G,,,] I n 2 2). By Theo- 
rem 1.4.7 and the MSO definability of the set of square grids, Lg is in C-edNCE. 
Hence, the string language S(Lg) = {am I m = #VH for some [H] E Lg} is 
context-free (see the discussion before Proposition 1.3.22). Note that the num- 
ber of nodes of G,,, is n2. Hence, if Lg would be infinite, then S(Lg) would 
be an infinite subset of the string language {an2 I n 2 2}, which is impossible 
0 
This implies immediately that the graph language [GRa,n] (with #n 2 2) 
is not in C-edNCE (as we already know from Theorem 1.3.30). Similarly the 
following sets of graphs in [GRa,n] are not C-edNCE graph languages: all 
connected graphs, all planar graphs, all grids, all graphs of degree 5 4, and 
all chordal graphs (for this last set, add all edges from u , , ~  
to U , + I , ~ + ~  to the 
grids). With some more effort the same results can be shown in the case that 
all the edges have the same label and also for the undirected case (cf. the 
Section 5.2.9 of Chapter 3). 
In [96,94] the proof of Proposition 1.4.8 is by the separator theorem mentioned 
after Lemma 1.3.18. Since grids are of bounded degree, the separator theorem 
would imply that there is a constant c such that the grids in L can be separated 
into two parts of almost the same size by removing at most c edges. However, 
it is well known that R(&) 
edges need to be removed for dividing G,,n into 
two (see, e.g., [91]). In Theorems 15 and 16 of [39] it is proved in a similar way 
that no LIN-edNCE language contains infinitely many binary trees. 
The MSO definable functions of [26] are more general in two ways (see Chap- 
ter 3). First, each node of the input graph is used to represent (at most) k 
nodes of the output graph, where k is fixed. As an example, the function f 
that maps each graph H into the disjoint union of H with itself is then MSO 
definable (with k = 2); clearly this function is not MSO definable in our sense, 
because f ( H )  has more nodes than H .  Second, by admitting free variables in 
the defining formulas, MSO definable relations are obtained. Theorems 1.4.6 
and 1.4.7 are also valid for these generalized MSO definable relations. A special 
case of this is the following. For a graph H and X 
VH, we denote by H ( X )  
the subgraph of H induced by X .  Let 4(U) be an MSOL formula. We say that 
H ( X )  is an induced &-subgraph of H if H + 4 ( X ) .  
Theorem 1.4.9 
Let 4(U) be an MSOL formula. If L is in C-edNCE, then the set of all induced 
&subgraphs of L is in C-edNCE. The same holds for B-edNCE and LIN- 
edNCE. 
0 
by the pumping lemma for context-free string languages. 

78 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
Note that C-edNCE is not closed under taking subgraphs: the set of all com- 
plete graphs is in C-edNCE, but the set of all graphs (which is its set of 
subgraphs) is not in C-edNCE (see Theorem 1.3.30). On the other hand, HR 
is closed under taking subgraphs; moreover, if L is a C-edNCE language that 
is not in HR, then the set of subgraphs of L is not in C-edNCE (see Theo- 
rem 3.12 of [18]). This is a characterization of HR within C-edNCE similar to 
Theorem 1.3.27 (see also [lOS]). 
We now turn to decidability properties. First, Proposition 1.3.22 and Theo- 
rem 1.4.7 can be combined in an obvious way: it is decidable for an MSO 
definable function f and a C-edNCE language L whether or not f(L) 
is empty 
(and, whether or not it is finite). In particular, it is decidable whether or not 
L n R = 8, and whether or not L 
R, where R is an MSO definable set (see 
[105,106] for complexity aspects). This last fact means that the MSO theory 
of L is decidable; since no set of graphs of which the MSO theory is decidable 
contains infinitely many square grids (see Proposition 5.2.2 of Chapter 3), this 
gives still another proof of Proposition 1.4.8. Second, a similar combination of 
Proposition 1.3.22 and Theorem 1.4.9 gives the following result. Let 4 ( U )  be an 
MSOL formula and H a graph. By sizeb(H) we denote the maximal number of 
nodes of an induced &subgraph of H ,  and by num@(H) we denote the number 
of induced 4-subgraphs of H (where isomorphic ones are not identified). 
Theorem 1.4.10 
Let @(U) be an MSOL formula. It is decidable for a C-edNCE grammar G 
( I )  whether or not there exists a natural number b such that size4(H) 5 b for 
all [HI E L(G), and 
(2) whether or not there exists a natural number b such that num+(H) 5 b for 
all [H] E L(G). 
The decidability of boundedness of numerical functions on graphs was first in- 
vestigated (for HR) in [57] (see Section 2.6.2 in Chapter 2). Their result (which 
can be extended to C-edNCE, see [49]) is formulated in terms of compatible 
functions rather than MSO formulas. It is shown (for HR) in [22] that for every 
MSOL formula 4(U), size4 and num4 are compatible functions. 
As an example, since the connected components of a graph are induced & 
subgraphs (for an appropriate 4(U)), it is decidable for a C-edNCE graph lan- 
guage whether or not there is a bound on the size of the connected components 
of its graphs, and also, whether or not there is a bound on the number of con- 
nected components of its graphs. As another example, the cliques of a graph are 
induced &subgraphs. Hence, it is decidable for a C-edNCE language whether 

1.4. CHARACTERIZATIONS 
79 
there is a bound on the size of the cliques in its graphs. This was shown for 
B-NLC in [94]. By Theorem 1.3.27, HR languages always have bounded clique 
size. As a last example, since the subgraph induced by a node and all its neigh- 
bours is a &subgraph (for appropriate 4), it is decidable whether a C-edNCE 
graph language is of bounded degree (see Theorem 1.3.28). For (arbitrary) 
NLC grammars this was first proved in [69]. It was recently shown in [loo] 
that the problem is in NLOG for reduced nonblocking (not necessarily conflu- 
ent) edNCE grammars. Since it is easy to see that the set of sentential forms 
of a C-edNCE grammar is a C-edNCE language L, it is also decidable whether 
a C-edNCE grammar is of bounded nonterminal degree (see Section 1.3.3); if 
so, its nonterminal degree can be computed, because, for fixed Ic, the set R of 
all graphs of nonterminal degree 5 Ic is MSO definable (and decide L C R). 
Decidability of the bounded bidegree property (see Theorem 1.3.27) follows 
from a strengthened version of Theorem 1.4.10(1), involving MSOL formulas 4 
with an arbitrary number of free variables, shown in [28] (see also Section 5.7.3 
of Chapter 3). 
1.4.3 Handle replacement 
The C-edNCE languages can be generated by a different type of graph grammar 
that is based on handle rewriting: the separated handle hypergraph grammar, 
or S-HH grammar, introduced in [20]. Handle rewriting generalizes both node 
rewriting and edge rewriting: a handle is an edge together with its nodes. 
When a handle is rewritten, the edge, its nodes, and the edges incident with 
those nodes are removed, and, as usual, replaced by the right-hand side of the 
production. The S-HH grammar can be viewed as a generalization of the HR 
grammar: the graphs that it rewrites also have (nonterminal) hyperedges, but 
the embedding is simpler than the one of edNCE grammars. 
Let us describe the S-HH grammar in some more detail. A (directed) hypergraph 
is a graph with hyperedges. A hyperedge (of rank n) is a tuple ( ~ 1 , .  . . , w,, y), 
where u1, . . . , u, are nodes and y is a label; for n = 2, it is an ordinary edge. 
Note that we do not need multiple hyperedges, with the same nodes and the 
same label (as in the hypergraphs of Chapter 2). The sentential forms of an 
S-HH grammar are hypergraphs of which the edges are labeled by terminal 
and nonterminal symbols (node labels are simulated by terminal hyperedges 
(v,y) of rank 1); they should be separated, which means that nonterminal 
hyperedges do not have nodes in common; and, moreover, since we wish the 
generated language to consist of ordinary graphs, we require that all hyperedges 
of rank 2 3 are nonterminal. The productions of an S-HH grammar are of the 
form X -+ D, where X is a (ranked) nonterminal, say of rank n, and D is a 

80 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
hypergraph of the type just described, together with a mapping ‘port’ from 
{ 1,. . . , n} to the subsets of VD. Application of this production to a sentential 
form H results in a sentential form H‘ that is obtained as follows. First, a 
hyperedge (211,. . . ,vn,X) is removed, together with its nodes w1,. . . , w, and 
the edges incident with these nodes. Second, (a disjoint copy of) D is added 
to the remainder H -  of H .  And, third, D is embedded in H-: each ordinary 
edge (v,wi,y) of H (with w a node of H - )  is replaced by all edges (w,w,y) 
of H’, where w is a node of D such that w E port(i); and similarly, (wi,v,y) 
is replaced by all (w, w, y) (note that there is no dynamic edge relabeling). 
Intuitively, the nodes w of D that are labeled with number i (i.e., for which 
w E port(i)) are the new connection points for all edges that are incident with 
the ith node ui of the replaced nonterminal hyperedge. Thus, the embedding 
is based on the connecting approach (see the Introduction). It should be clear 
(to the reader familiar with HR grammars) that an S-HH grammar with the 
property that for each production X t D, port(i) is a singleton for every i ,  is 
an HR grammar. In that case the embedding can also be realized by the gluing 
approach: remove the nonterminal hyperedge (only), add D, and identify wi 
with the (unique) node in port(i), for every i. However, only separated HR 
grammars are obtained in this way (which are less powerful than arbitrary HR 
grammars, see Lemma 7.6 of [20]). 
It is shown in [20] that S-HH grammars generate exactly the C-edNCE lan- 
guages. An S-HH grammar is boundary if, in the right-hand sides of the pro- 
ductions, there is no edge (v,w,y) such that w belongs to one nonterminal 
hyperedge and w to another (i.e., there is no connection between nonterminal 
handles). The boundary S-HH grammars generate the B-edNCE languages. 
The linear S-HH grammars generate the LIN-edNCE languages (where, as 
usual, an S-HH grammar is linear if there is at most one nonterminal hy- 
peredge in each right-hand side of a production). It is open whether there is a 
natural characterization of the B,d-edNCE (= HR!) graph languages. It should 
be clear that S-HH grammars can also be used to generate hypergraph lan- 
guages. Unfortunately the classes of hypergraph languages generated by S-HH 
and HR grammars are incomparable, even for hypergraphs without multiple 
edges (see Theorem 7.5 of [20]). It would be nice to find a natural variation 
of the S-HH grammar that is able to generate all HR hypergraph languages. 
Another possibility is to extend edNCE rewriting to hypergraphs (as in [74]); 
this gives a more complicated embedding mechanism than the one of the S-HH 
grammar. 

1.4. CHARACTERIZATIONS 
81 
1.4.4 Graph expressions 
As observed in Sections 1.3.2 and 1.4.1, the set D(G) of abstract p-labeled 
derivation trees of an edNCE grammar G is a regular tree language, where each 
tree is a graph expression, i.e., an expression that denotes a graph when viewing 
each vertex label (i.e., each production of G) as an operation on graphs. This is 
a special case of a general approach (introduced in [83]) in which regular tree 
languages are used to define subsets of arbitrary algebras (see Section 1.4.1 
or [55] for the definition of regular tree languages). To be precise, if A is a 
ranked alphabet, and A is an algebra which has an operation CTA : Ak + A for 
every u E A of rank k, then every tree t E TA can be viewed as an expression 
that denotes an element val(t) of A. A subset L of A is said to be equational if 
L = val(R) for some regular tree language R C TA. It would also be appropriate 
to call them the “context-free” subsets of the algebra; the term “equational” 
comes from viewing the regular tree grammar that generates R as a system of 
equations of which val(R) is the least fixed point (as shown in [83]). For graphs 
this approach was introduced in [8]. See Section 5.6 of Chapter 3, and [49], for 
more information. 
If one now considers the algebra AGRE of all (abstract) graphs with em- 
bedding, with an operation PAGRE for every possible production p ,  then the 
considerations in Sections 1.3.2 and 1.4.1 show that C-edNCE is precisely the 
class of equational sets of graphs in this algebra. Since the operations PAGRE 
are rather complicated substitution operations on graphs with embedding, it 
would be nice to have simpler operations on a simpler type of graphs. The 
existence of such simple operations was shown in [8] for HR grammars and in 
[20] for C-edNCE grammars. We now define the operations for C-edNCE. 
Let AGRP be the set of (abstract) graphs with ports, where a graph with ports 
is a graph H together with a finite set port, of pairs (i, v), where i is a natural 
number and w E VH, cf. the right-hand sides of productions of S-HH grammars. 
The set AGRP is made into an algebra with the following operations. First 
of all, it has the empty graph and all graphs with a single node as constants. 
Second, it has the (usual) disjoint union HI + H2, where one just takes the 
union of the port sets. Third, it has operations of edge creation: for every edge 
label y and natural numbers i and j ,  ~ i , ~ , j ( H )  
is the graph that is obtained 
from H by the addition of all edges (v, y, 
w) such that (i, v), ( j ,  w) E portH. 
Finally, to be able to redefine the port numbers of nodes, it has operations of 
port selection: for every finite set z of pairs ( i , j )  of natural numbers, 7r,(H) is 
obtained from H by changing its port set into {(i, 
w) I ( i , j )  E z and ( j ,  w) E 
portH for some j } .  The operation of edge creation is typical for the connecting 

82 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
approach to embedding (see the Introduction): graphs can be built by putting 
them together (using disjoint union) and then connecting them by edges using 
edge creation. 
It is shown in [20] that C-edNCE is the class of all equational sets of graphs 
in the algebra AGRP defined above. It is open whether similar characteriza- 
tions exist for B-edNCE and LIN-edNCE. For HR a different set of operations 
(mainly based on gluing) is given in [8]. For a uniform approach to these two 
sets of operations see [49] (where also a characterization of A-edNCE can be 
found). 
1.5 Recognition 
In this final section we discuss the complexity of the recognition problem (or 
membership problem) for edNCE graph languages L. This is the problem, for a 
given (abstract) graph H ,  whether or not H belongs to L. As usual, we identify 
L with its recognition problem. 
We first consider arbitrary edNCE languages. Every edNCE language is gen- 
erated by an edNCE grammar without A-productions (because the removal 
of these productions, as discussed in Lemma 1.3.29, also works for arbitrary 
edNCE grammars). In a derivation of a grammar without A-productions the 
number of nodes of the sentential forms cannot decrease. Guessing such a 
derivation nondeterministically needs at most space n2, where n is the num- 
ber of nodes of the given graph. This means that every edNCE language can 
be recognized in NSPACE(n2) and hence belongs to PSPACE ([ll]). Since, 
as we have observed in Section 1.3.1, blocking edges can be used to simulate 
context-sensitive graph grammars (see [86]) and in particular context-sensitive 
string grammars (see Theorem 9 of [61]), there exist PSPACE-complete edNCE 
languages (see [13,14]). This stresses again the non-context-free nature of arbi- 
trary edNCE languages (because one would expect recognition in polynomial 
time for context-free grammars). 
We now turn to C-edNCE languages. By Lemma 1.3.29 every C-edNCE lan- 
guage can be generated by a grammar without A- or chain productions. Hence 
(as observed in the proof of Theorem 1.3.30) every derivation of a graph with 
n nodes has length at most 2n. This implies that every C-edNCE language is 
in NPTIME. Surprisingly, in comparison with context-free string languages, 
there exist quite simple NP-complete C-edNCE (and even C-NLC) languages, 
as shown independently in [92,79] and [5] (and first shown in [13,102] for non- 
confluent NLC grammars without A- or chain productions). With ‘simple’ we 
mean here that they can be generated by linear apex edNCE (and hence HR) 
grammars. 

1.5. RECOGNITION 
83 
Proposition 1.5.1 
There is an NP-complete LIN.A-edNCE graph language. 
Proof 
In [92,102] the NP-complete problem whether a graph H has circular band- 
width < 2 is used (which means that the nodes of H can be linearly ordered 
as wl,. . . , v, such that Ij - il < 2 mod n for every (u,, 
vu3) E EH). It is not 
difficult to write a linear apex edNCE grammar for the set of all graphs of 
circular bandwidth 5 2 (cf. the linear B-NLC grammar in Example 4 of [92] 
and the linear apex HR grammar in Example 2.2.4 of [77]). In [5] a graph 
language is given to which the strongly NP-complete 3-partition problem can 
be reduced (see also the proof of Theorem 3.5 in [l]). This language consists 
of all graphs with a-labeled nodes 21,. . . , 2, and blabeled nodes yl,. . . , yn 
(for some n 2 l), and a set E of edges such that E G {(z,,*,z,+~) I 1 < 
i 5 n - l} U {(y,,*,y,+l) I 1 5 i < n - 1) and if (zz,*,z,+l) E E, then 
(y,, *, yz+l) E E. It is generated by the linear apex edNCE (NLC) grammar C: 
with productions S -+ ( D ,  fl), X -+ (D, Cl), X t 
( D ,  Cz), X -+ (D,fl), and 
X -+ (A,0), where D = (V,E,X) with V = {z,y,z}, E = {(z,*,z), 
(y, * , z ) } ,  
X(z) = a, X(y) = b, X(z) = X ,  and where (21 = {(a, */*,z,in), (b, */*, y,in)}, 
C, = {(b,*/*,y,in)}, and A is the empty graph. Note that the nonterminal 
0 
The graphs in the NP-complete graph languages mentioned in the proof above 
are of bounded degree, but they are not connected. By starting with one ad- 
ditional node, and connecting all other nodes to it, it is easy to obtain NP- 
complete LIN.B,d-edNCE languages of which the graphs are connected, but 
not any more of bounded degree. 
Proposition 1.5.1 has led to a search for large classes of context-free graph 
languages that can be recognized in deterministic polynomial time. A natural 
requirement that guarantees PTIME recognition is that all graphs of the lan- 
guage are connected and of bounded degree. Such a result was first shown in 
[98]. For B-NLC languages it was proved in [92]. It was then extended to B- 
edNCE in [44] and to C-edNCE in [11,96], and for HR languages it was shown 
in [77]. Since we now know that all C-edNCE languages of bounded degree 
are in HR (see Theorems 1.3.27 and 1.3.28), these latter results are in fact 
all equivalent. However, it should be noted that, in these papers, the graphs 
are not only recognized, but also parsed, i.e., a derivation tree is produced 
as output. From the parsing point of view the algorithms are, of course, not 
equivalent. In [44,77] it was shown (using the closure of NLOG under comple- 
ment) that the graph languages considered are even in LOG(CFL), i.e., can 
be reduced to a context-free string language in logarithmic space. By a result 
of RUZZO, 
LOG(CFL) is the class of problems that can be recognized by an 
degree of G is 2. 

84 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
alternating Turing machine that uses logarithmic space and has a computation 
tree of polynomial size. The graph language can be recognized by such a ma- 
chine in such a way that the computation tree corresponds to the derivation 
tree of the input graph. Thus, if, in particular, the graph grammar is linear, 
then the machine is a nondeterministic log-space Turing machine. Hence the 
linear versions of the above graph languages are in NLOG (as first shown in 
[1,39]). In [77] these results were extended to certain graph languages that are 
not both connected and of bounded degree. We first state the results, and then 
the extensions. 
Proposition 1.5.2 
Every C-edNCE graph language L of which the graphs are connected and of 
bounded degree is in LOG(CFL), and hence also in PTIME. If, moreover, L is 
0 
a LIN-edNCE graph language, then L is in NLOG. 
Since (representatives of) the connected components of a graph can be enu- 
merated in nondeterministic logarithmic space, this proposition also holds for 
C-edNCE languages L of bounded degree such that a graph H is in L iff all 
connected components of H are in L (such as, for fixed k ,  the set of all graphs 
of bandwidth 5 k ,  of binary tree band-width 5 k, or of cutwidth 5 k). 
We now turn to the first extension of [77] (see Section 2.7.2 of Chapter 2 
for more details). For r 2 1, a graph language L is of bounded r-separability 
if there exists k 2 1 such that for every H E L and every subset V of VH 
with #V = r ,  the subgraph of H induced by VH - V has at most k connected 
components. Intuitively this means that if one takes away r nodes from a graph 
of the language, it falls apart into at most k pieces. The set of all stars is not of 
bounded r-separability for any T (taking away the center node gives arbitrarily 
many pieces). The set of all wheels (see grammar Gg of Example 1.9) is of 
bounded r-separability for every r: taking away r nodes gives at most T - 1 
pieces. Note that every graph language of which the graphs are connected and 
of bounded degree is of bounded r-separability for every r; in fact, if the degree 
is at most m, then the number of pieces is at most 1 + ~ ( m  
- 1). 
Recall from Section 1.3.3 that the nonterminal degree of a C-edNCE gram- 
mar is the maximal degree of the nonterminal nodes in its sentential forms. 
For a B,d-edNCE (= HR) grammar it is the maximal number of tentacles of 
the nonterminals of the corresponding HR grammar. The following result was 
shown in Theorem 4.2.1 of [77]. 

1.5. RECOGNITION 
85 
Theorem 1.5.3 
If G is a B-edNCE grammar of nonterminal degree 5 r and L(G) is of bounded 
r-separability, then L(G) is in LOG(CFL), and hence also in PTIME. 16 more- 
over, G is a LIN-edNCE grammar, then L(G) is in NLOG. 
Proof 
(Sketch) The algorithm is similar to the usual Cocke-Younger-Kasami algo- 
rithm for context-free string grammars. For a given input graph H it com- 
putes all triples ( X ,  K ,  F )  where X is a nonterminal, K is a graph with ex- 
actly one nonterminal node u, with label X, and F is an induced subgraph 
of H such that, for some connection relation CF, sin(X, z) J* 
(F, C F )  and 
K[u/(F,Cp)] = H .  The main problem is how to represent such a triple in 
logarithmic space. Clearly, if F is given, then K is determined by u, the neigh- 
bours of u, and the edges between them; since G is of nonterminal degree < r, 
u has at most r neighbours, and so K can be stored in logarithmic space. Since, 
by the bounded r-separability of L(G), removing the neighbours of u from H 
leads to at most k connected components, for some fixed k, F consists of a 
number of these components and can be represented by one node from each 
0 
component, also in logarithmic space. 
Bounded r-separability of L(G) is decidable: by Theorem 1.4.9 one obtains 
a grammar G' for the set of all induced subgraphs that are obtained from 
graphs of L(G) by removing r nodes, and by Theorem 1.4.10(2) it can be 
decided whether there is a bound on the number of connected components of 
the graphs in L(G'). 
Both Proposition 1.5.2 and Theorem 1.5.3 are optimal, in the following sense. 
Since, coding strings as chains, all context-free string languages can be gener- 
ated by HR grammars (see Section 2.5.2 of Chapter a), there are LOG(CFL)- 
complete C-edNCE graph languages of which all graphs are connected and of 
bounded degree. It is shown in Theorem 4.9 of [l] that there exist NLOG- 
complete LIN.B,d-edNCE graph languages of which all graphs are connected 
and of bounded degree (see also Theorem 4.3 of [73]). 
It is not clear whether Theorem 1.5.3 also holds for C-edNCE grammars (with 
the same restrictions). It certainly does not hold without the restriction of 
bounded nonterminal degree. In fact, let L be the language that is obtained 
from any NP-complete C-edNCE language (see Proposition 1.5.1) by adding a 
y-labeled edge (where y is a new label) between all nodes of all graphs. Then 
L is clearly still NP-complete, it is a C-edNCE language by Theorem 1.4.7 
(because the function that adds the edges is MSO definable), and it is obviously 
of bounded r-separability for all r. 

86 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
The PTIME result of Theorem 1.5.3 also holds if L(G) is of “logarithmically 
bounded” r-separability, which means that the number of “pieces77 is at most 
k . logn, where n is the number of nodes of the given graph H .  
A second general LOG(CFL) recognition result is proved in [77] that covers 
HR languages such as the set of all discrete graphs and the set of all graphs of 
tree-width 5 k ,  for fixed k. A connected component of a graph with embedding 
( H ,  C H )  is, as one would expect, a graph with embedding (K, C K )  where K is 
a connected component of H and CK is the restriction of CH to K ,  i.e., CK = 
{(a,P/y,x,d) E CH 12 E VK}. An edNCE grammar G = (C,A,r,R,P,S) 
has componentwise derivations if for every nonterminal X E C - A and every 
terminal graph H E G R E A , ~  
(and every x), sin(X,x) J* H if and only if 
sin(X,z) J* K for every connected component K of H .  In other words, for 
each of the graph languages L(G, X ),  defined after Proposition 1.3.20, H is 
in L ( G , X )  iff all connected components of H are in L( G,X) . The following 
result was shown in Theorem 4.2.2 of [77]. 
Theorem 1.5.4 
If G is a B,d-edNCE grammar that has component-wise derivations, then L(G) 
is in LOG(CFL), and hence also in PTIME. If, moreover, G is a LIN-edNCE 
0 
grammar, then L(G) is in NLOG. 
There is a B,d-edNCE grammar with component-wise derivations that gener- 
ates the set of all graphs of tree-width 5 k ,  for fixed k. Hence, by Theorem 1.5.4, 
the set of graphs of tree-width 5 k is in LOG(CFL), see [77]. For similar rea- 
sons the set of graphs of path-width 5 k is in NLOG. It is open whether it is 
decidable whether or not a B,d-edNCE grammar has component-wise deriva- 
tions. 
The proof of Theorem 1.5.3 only depends on the fact that there is a fixed 
k such that, for every nonterminal X ,  each graph in L(G,X) has at most k 
connected components. Thus, with the techniques from [77], it is not difficult 
to see that Theorems 1.5.3 and 1.5.4 can be combined as follows. Let G be a 
B,d-edNCE grammar such that for every nonterminal X ,  either the graphs of 
L(G, X )  have a bounded number of connected components, or H is in L(G, X )  
iff all connected components of H are in L(G, X). Then L(G) is in LOG(CFL) 
(and in NLOG if G is also linear). This covers for instance the LIN.B,d-edNCE 
grammar G8 of Example 1.9 that generates the set of all stars. In fact, for that 
grammar, L(G8,S) = L(G8) is the set of all stars, which satisfies the first 
requirement, and L(G8, X )  is the set of all discrete graphs H with connection 
relation {(#,*/*,x,d) I x E V H , ~  
E {in,out}}, which satisfies the second 
requirement. Hence the set of all stars is in NLOG (which is of course obvious). 

1.5. RECOGNITION 
87 
A completely different way to obtain polynomial time recognition is to assume 
that the generation order of the nodes of the input graph (i.e., the linear order 
described in Section 1.3.2) is given a priori. This means that one views a C- 
edNCE grammar as generating a set of (abstract) ordered graphs, rather than 
graphs. Let us call this the ordered recognition problem. With each C-edNCE 
grammar G one can easily associate a new C-edNCE grammar G’ such that 
G’ generates the graphs in L(G) to which the generation order of the nodes is 
explicitly added, as a chain of edges with a new edge label. Clearly, this reduces 
the ordered recognition problem of G to the (ordinary) recognition problem of 
G’. Since the resulting language L(G’) is of bounded r-separability for every r 
(because chains are), and since the construction preserves B,d-edNCE gram- 
mars, it follows from Theorem 1.5.3 that the ordered recognition problem for 
B,d-edNCE (= HR) grammars is in LOG(CFL), and hence in PTIME. It 
seems to be unknown, in general, whether the ordered recognition problem for 
C-edNCE grammars is in PTIME. The problem has been considered for some 
special cases, obtained by restricting the embedding. In Theorem 4 of [12] it 
was shown to be in PTIME for neighborhood uniform dNCE grammars (in 
which edge labels are allowed, but should not be changed by the embedding), 
and in Theorem 5.3 of [l] it was shown to be in DLOG for linear dNLC gram- 
mars in Chomsky Normal Form such that the nonterminal nodes have incoming 
edges only (called “regular” dNLC grammars). In other cases, the order of the 
input graph is not given explicitly, but can be (partially) obtained from the 
structure of the graph itself. Results of this type are shown in Section 3 of 
[96], Section 5 of [l], and Theorem 4.5 of [73]. In [lo31 it is shown for an edge 
replacement grammar generating 2-connected graphs, that the derivation tree 
can be obtained from the structure of the input graph, leading to recognition 
in O(n3) time (see Section 2.7.2 of Chapter 2 for details). 
All the above-mentioned PTIME algorithms recognize the input graph by a 
bottom-up dynamic programming technique that is similar to the usual Cocke- 
Younger-Kasami algorithm for context-free string grammars. Since the recog- 
nition is syntax-directed, the algorithms in fact parse the input graph, i.e., 
produce its possible derivation trees. In the above, the concern is with PTIME 
parsing methods that are as general as possible. Efficient parsing methods of 
context-free graph grammars (generalizing the usual methods for context-free 
string grammars) are outside the scope of this chapter; we refer the reader to 
the literature, in particular to the precedence parsing of C-edNCE grammars 
in O(n2) time of [70,71]. 
In [16] edNCE grammars are enriched by a layout component that specifies 
constraints on the drawing of the generated graphs, i.e., their embedding in a 

88 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
grid. For such a layout graph grammar G, a polynomial time algorithm is given 
that produces, for a given graph H E L(G), a nice drawing that satisfies the 
given constraints. The algorithm is based on a PTIME parsing algorithm (for 
a subclass of C-edNCE grammars) as discussed above, and uses an attribute 
grammar that computes, in polynomial time, for each vertex v of the deriva- 
tion tree t ,  the coordinates of the nodes u of H that “belong” to v, i.e., such 
that vertext(u) = u (see the discussion after Definition 1.3.13). The resulting 
drawing of the input graph is “nice” because it is syntax-directed (and hence 
well structured, assuming that G is well structured) and because the algorithm 
produces a syntax-directed layout that is optimal with respect to certain mea- 
sures such as area or maximal edge length. Such an algorithm is implemented 
in the HiGraD tool (see [7]) which is part of the GraphEd editor that draws 
and manipulates graphs and edNCE graph grammars (see [56]). 
Acknowledgment 
The authors are grateful to Bruno Courcelle, Dirk Janssens, and Hans-Jorg 
Kreowski for their comments on a previous version of this chapter. 
References 
IJ.J.Aalbersberg, J.Engelfriet, G.Rozenberg; The complexity of regular 
DNLC graph languages, J. of Comp. Syst. Sci. 40 (1990), 376-404 
N.Abe, M.Mizumoto, J.-I.Toyoda, K.Tanaka; Web grammars and several 
graphs, J. of Comp. Syst. Sci. 7 (1973), 37-65 
K.Aizawa, A.Nakamura; Graph grammars with path-controlled embed- 
ding, Theor. Comput. Sci. 88 (1991), 151-170 
IJ. J.Aalbersberg, G.Rozenberg; Traces, dependency graphs and DNLC 
grammars, Discrete Appl. Math. 11 (1985), 299-306 
IJ.J.Aalbersberg, G.Rozenberg, A.Ehrenfeucht; On the membership 
problem for regular DNLC grammars, Discrete Appl. Math. 13 (1986), 
M.Bauderon; A uniform approach to graph rewriting: the pullback 
approach, in Gruph- Theoretic Concepts in Computer Science, WG’95 
(M.Nag1, ed.), Lecture Notes in Computer Science 1017, Springer-Verlag, 
Berlin, 1995, pp.101-115 
W.Bach1, F.-J.Brandenburg, T.Hick1; Hierarchical graph design using Hi- 
GraD, Technical Report MIP-9405, Universitat Passau, 1994 
M.Bauderon, B.Courcelle; Graph expressions and graph rewritings, 
Math. Systems Theory 20 (1987), 83-127 
79-85 

REFERENCES 
89 
J.M.Brayer, K.S.Fu; Some properties of web grammars, Techn. Report 
TR-EE 74-19, Purdue University, 1974 
B.Bollob&s; Extremal Graph Theory, Academic Press, London, 1978 
F.-J.Brandenburg; The computational complexity of certain graph gram- 
mars, Proc. 6th GI Conference on Theoretical Computer Science, Lecture 
Notes in Computer Science 145, Springer-Verlag, Berlin, 1983, pp.91-99 
F.-J.Brandenburg; On the complexity of the membership problem of 
graph grammars, in Graph- Theoretic Concepts in Computer Science, 
WG'83 (M.Nag1, J.Per1, eds.), Tauner-Verlag, Linz, 1983, pp.40-49 
F.-J.Brandenburg; On partially ordered graph grammars, in [50], 99-1 11 
F.-J.Brandenburg; On polynomial time graph grammars, Proc. STACS 
88, Lecture Notes in Computer Science 294, Springer-Verlag, Berlin, 
F.-J.Brandenburg; The equivalence of boundary and confluent graph 
grammars on graph languages of bounded degree, in Rewriting Techn- 
niques and Applications (R.V.Book, ed.), Lecture Notes in Computer 
Science 488, Springer-Verlag, Berlin, 1991, pp.312-322 
F.-J.Brandenburg; Layout graph grammars: the placement approach, in 
F.-J.Brandenburg; Graph Grammatiken, Lecture Notes (in German), 
Passau University, 1994 
B.Courcelle, J.Engelfriet; A logical characterization of the sets of hy- 
pergraphs defined by hyperedge replacement systems, Math. Systems 
Theory 28 (1995), 515-552 
B.Courcelle, J.Engelfriet, G.Rozenberg; Handle-rewriting hypergraph 
grammars, J. of Comp. Syst. Sci. 46 (1993), 218-270 
D.G.Cornei1, H.Lerchs, L.Stewart Burlingham; Complement reducible 
graphs, Discrete Appl. Math. 3 (1981), 163-174 
B.Courcelle, M.Mosbah; Monadic second-order evaluations on tree de- 
composable graphs, Theor. Comput. Sci. 109 (1993), 49-82 
B.Courcelle; An axiomatic definition of context-free rewriting and its 
application to NLC graph grammars, Theor. Comput. Sci. 55 (1987), 
141-181; Correction: 
http://www.labri.u-bordeaux.fr/LaBRI/People/courcell.html 
B.Courcelle; The monadic second-order logic of graphs I: Recognizable 
sets of finite graphs, Inform. and Comput. 85 (1990), 12-75 
B.Courcelle; The monadic second-order logic of graphs 111: Tree- 
decompositions, minors and complexity issues, RAIRO Theoretical In- 
formatics and Applications 26 (1992), 257-286 
1988, pp.227-236 
[37], 144-156 

90 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
B.Courcelle; The monadic second-order logic of graphs V: On closing 
the gap between definability and recognizability, Theor. Comput. Sci. 80 
B.Cource1le; The monadic second-order logic of graphs VII: Graphs as 
relational structures, Theor. Comput. Sci. 101 (1992), 3-33 
B.Courcelle; Structural properties of context-free sets of graphs generated 
by vertex replacement, Inform. and Comput. 116 (1995), 275-293 
J.Engelfriet, L.M.Heyker; Hypergraph languages of bounded degree, J. 
of Comp. Syst. Sci. 48 (1994), 58-89 
J.Engelfriet, L.M.Heyker, G.Leih; Context-free graph languages of 
bounded degree are generated by apex graph grammars, Acta Informat- 
ica 31 (1994), 341-378 
J.Engelfriet, T.Harju, A.Proskurowski, G.Rozenberg; Characterization 
and complexity of uniformly non-primitive labeled 2-structures, Theor. 
Comput. Sci. 154 (1996), 247-282 
H.Ehrig, D.Janssens, H.-J.Kreowski, G.Rozenberg; Concurrency of node- 
label controlled graph transformations, Report 82-38, University of 
Antwerp, U.I.A., 1982 
H.Ehrig, H.-J .Kreowski, G.Rozenberg (eds.); Graph- Grammars and their 
Application to Computer Science, Lecture Notes in Computer Science 
532, Springer-Verlag, Berlin, 1991 
J.Engelfriet, G.Leih; Nonterminal bounded NLC graph grammars, Theor. 
Comput. Sci. 59 (1988), 309-315 
J.Engelfriet, G.Leih; Linear graph grammars: power and complexity, In- 
form. and Comput. 81 (1989), 88-121 
J.Engelfriet, G.Leih; Complexity of boundary graph languages, RAIRO 
Theoretical Informatics and Applications 24 (19901, 267-274 
J.Engelfriet, G.Leih, G.Rozenberg; Apex graph grammars, in [50], 167- 
185 
J.Engelfriet, G.Leih, G.Rozenberg; Apex graph grammars and attribute 
grammars, Acta Inforrnatica 25 (1988), 537-571 
J.Engelfriet, G.Leih, G.Rozenberg; Nonterminal separation in graph 
grammars, Theor. Comput. Sci. 82 (1991), 95-111 
J.Engelfriet, G.Leih, E.Welz1; Boundary graph grammars with dynamic 
edge relabeling, J. of Comp. Syst. Sci. 40 (1990), 307-345 
A.Ehrenfeucht, M.G.Main, G.Rozenberg; Restrictions on NLC graph 
grammars, Theor. Comput. Sci. 31 (1984), 211-223 
J.Engelfriet; Context-free NCE graph grammars, Proc. FCT '89, Lecture 
Notes in Computer Science 380, Springer-Verlag, Berlin, 1989, pp.148- 
161 
(1991), 153-202 

REFERENCES 
91 
J.Engelfriet; A characterization of context-free NCE graph languages by 
monadic second-order logic on trees, in [37], 311-327 
J.Engelfriet; A Greibach normal form for context-free graph grammars, 
Proc. ICALP '92 (W.Kuich, ed.), Lecture Notes in Computer Science 
623, Springer-Verlag, Berlin, 1992, pp.138-149 
J.Engelfriet; Graph grammars and tree transducers, Proc. CAAP'94 
(S.Tison, ed.), Lecture Notes in Computer Science 787, Springer-Verlag, 
Berlin, 1994, pp.15-36 
H.Ehrig, M.Nagl, G.Rozenberg, A.Rosenfeld (eds.); Graph-Grammars 
and their Application to Computer Science, Lecture Notes in Computer 
Science 291 , Springer-Verlag, Berlin, 1987 
J.Engelfriet, V.van Oostrom; Regular description of context-free graph 
languages, Report 95-34, Leiden University, October 1995, to appear in 
J. of Comp. Syst. Sci. 
J.Engelfriet, G.Rozenberg; A comparison of boundary graph grammars 
and context-free hypergraph grammars, Inform. and Comput. 84 (1990), 
J.Engelfriet, G.Rozenberg; Graph grammars based on node rewriting: an 
introduction to NLC graph grammars, in [37], pp.12-23 
H. J .Genrich, D. Janssens, G .Rozenberg , P.S .Thiagarajan; Generalized 
handle grammars and their relation to Petri nets, EIK 4 (1984), 179- 
206 
F.Gkcscg, M.Steinby; Tree automata, Akadkmiai Kiad6, Budapest, 1984 
M.Himsolt; GraphEd: an interactive tool for developing graph grammars, 
in [37], 61-65 
A.Habe1, H.-J.Kreowski, W.Vogler; Decidable boundedness problems for 
sets of graphs generated by hyperedge replacement, Theor. Comput. Sci. 
89 (1991), 33-62 
J.Hoffmann, M.G.Main; Results on NLC grammars with one-letter ter- 
minal alphabets, Theor. Comput. Sci. 73 (1990), 279-294 
J. Jeffs; Order independent NCE grammars recognized in polynomial 
time, Inf. Proc. Letters 39 (1991), 161-164 
D. Janssens, G.Rozenberg; On the structure of node-label-controlled 
graph languages, Information Sciences 20 (1980), 191-216 
D.Janssens, G.Rozenberg; Restrictions, extensions, and variations of 
NLC grammars, Information Sciences 20 (1980), 217-244 
D. Janssens, G.Rozenberg; Decision problems for node label controlled 
graph grammars, J. of Comp. Syst. Sci. 22 (1981), 144-177 
D.Janssens, G.Rozenberg; A characterization of context-free string lan- 
guages by directed node-label controlled graph grammars, Acta Infor- 
matica 16 (1981), 63-85 
163-206 

92 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
D. Janssens, G.Rozenberg; Graph grammars with neighbourhood- 
controlled embedding, Theor. Comput. Sci. 21 (1982), 55-74 
D.Janssens, G.Rozenberg; A survey of NLC grammars, Proc. CAAP’83, 
Lecture Notes in Computer Science 159, Springer-Verlag, Berlin, 1983, 
D. Janssens, G.Rozenberg; Neighborhood-uniform NLC grammars, Com- 
puter Vision, Graphics, and Image Processing 35 (1986), 131-151 
D.Janssens, G.Rozenberg; Actor grammars, Math. Systems Theory 22 
D. Janssens, G.Rozenberg, R.Verraedt; On sequential and parallel node- 
rewriting graph grammars, Computer Graphics and Image Processing 18 
(1982), 279-304 
D.Janssens, G.Rozenberg, E.Welz1; The bounded degree problem for 
NLC grammars is decidable, J. of Comp. Syst. Sci. 33 (1986), 415-422 
M.Kaul; Syntaxanalyse uon Graphen bei Prazedenz-Graph-Grammatiken, 
Dissertation, Universitat Osnabruck, 1985 
M.Kau1; Practical applications of precedence graph grammars, in [50], 
C.Kim, D.H.Lee; Separating k-separated eNCE graph languages, Theor. 
Comput. Sci. 120 (1993), 247-259 
C.Kim, D.H.Lee; Node replacement graph languages squeezed with 
chains, trees, and forests, University of Oklahoma, 1993, to appear in 
Inform. and Comput. 
R.Klempien-Hinrichs; Node replacement in hypergraphs: simulation 
of hyperedge replacement, and decidability of confluence, in Graph- 
Grammars and their Application to Computer Science, (J.Cuny, H.Ehrig, 
G.Engels, G.Rozenberg, eds.), Lecture Notes in Computer Science 1073, 
Springer-Verlag, Berlin, 1996, pp.397-411 
H.-J.Kreowski, G.Rozenberg; Note on node-rewriting graph grammars, 
Inf. Proc. Letters 18 (1984), 21-24 
C.Lautemann; Efficient algorithms on context-free graph languages, 
Proc. 15th ICALP (T.Lepisto, ASaIomaa, eds.), Lecture Notes in Com- 
puter Science 317, Springer-Verlag, Berlin, 1988, pp.362-378 
C .Lautemann; The complexity of graph languages generated by hyper- 
edge replacement, Acta Informatica 27 (1990), 399-421 
U.Lichtblau; Recognizing rooted context-free flowgraph languages in 
polynomial time, in [37], 538-548 
K.-J.Lange, E.Welz1; String grammars with disconnecting or a basic root 
of the difficulty in graph grammar parsing, Discrete Appl. Math. 16 
(1987), 17-30 
pp. 114-1 28 
(1989), 75-107 
326-342 

REFERENCES 
93 
U.G.Montanari; Separable graphs, planar graphs and web grammars, In- 
form. and Control 16 (1970), 243-267 
M.G.Main, G.Rozenberg; Handle NLC grammars and r.e. languages, J. 
of Comp. Syst. Sci. 35 (1987), 192-205 
M.G.Main, G.Rozenberg; Edge-label controlled graph grammars, J. of 
Comp. Syst. Sci. 40 (1990), 188-228 
J.Mezei, J.B.Wright; Algebraic automata and context-free sets, Inform. 
and Control 11 (1967), 3-29 
M.Nag1; Formal languages of labelled graphs, Computing 16 (1976), 113- 
137 
M.Nag1; A tutorial and bibliographical survey of graph grammars, in 
Graph Grammars (V.Claus, H.Ehrig, G.Rozenberg, eds.); Lecture Notes 
in Computer Science 73, Springer-Verlag, Berlin, 1980, pp.70-126 
M.Nag1; Graph- Grammatiken, Vieweg, Braunschweig, 1979 
V.van Oostrom; Graph grammars and 2nd order logic (in Dutch), M. Sc. 
Thesis, Leiden University, January 1989 
J.L.Pfaltz, A.Rosenfeld; Web grammars, Proc. Int. Joint Conf. Art. In- 
telligence, Washington, 1969, pp.609-619 
A.Rosenfeld, D.Milgram; Web automata and web grammars, Mach. In- 
telligence 7 (1972), 307-324 
H.-J.Roder; Parallel BNLC graph grammars, in Developments in Lan- 
guage Theory (G.Rozenberg, ASalomaa, eds.), World Scientific, Singa- 
pore, 1994, pp.438-449 
A.L.Rosenberg, LSnyder; Bounds on the cost of data encodings, Math. 
Systems Theory 12 (1978), 9-39 
G.Rozenberg, E.Welz1; Boundary NLC graph grammars - basic defin- 
itions, normal forms, and complexity, Inform. and Control 69 (1986), 
G.Rozenberg, E.Welz1; Graph theoretic closure properties of the family 
of boundary NLC graph languages, Acta Informatica 23 (1986), 289-309 
G.Rozenberg, E.Welz1; Combinatorial properties of boundary NLC graph 
languages, Discrete Appl. Math. 16 (1987), 59-73 
H. JSchneider; Chomsky-Systeme fur partielle Ordnungen, Arbeitsber. 
d. Inst. f. Math. Masch. u. Datenver. 3, Erlangen, 1970 
RSchuster; Graphgrammatiken und Grapheinbettungen: Algorithmen 
und Komplexitat, Technical Report MIP-8711, Universitat Passau, 1987 
A.O.Slisenko; Context-free grammars as a tool for describing polynomial- 
time subclasses of hard problems, Inf. Proc. Letters 14 (1982), 52-56 
KSkodinis, E.Wanke; Emptiness problems of eNCE graph languages, J. 
of Comp. Syst. Sci. 51 (1995), 472-485 
136-167 

94 
CHAPTER 1. NODE REPLACEMENT GRAPH GRAMMARS 
[loo] KSkodinis, E.Wanke; The bounded degree problem for non-obstructing 
eNCE graph grammars, in Graph-Grammars and their Application to 
Computer Science, (J.Cuny, H.Ehrig, G.Engels, G.Rozenberg, eds.), Lec- 
ture Notes in Computer Science 1073, Springer-Verlag, Berlin, 1996, 
[loll K.Skodinis, E.Wanke; Neighborhood-preserving confluent node replace- 
ment, Manuscript, November 1995 
[lo21 Gy.TurBn; On the complexity of graph grammars, Acta Cybernetica 6 
(1983), 271-280 
[lo31 W.Vogler; Recognizing edge replacement graph languages in cubic time, 
in [37], 676-687 
[104] W.Vogler; On hyperedge replacement and BNLC graph grammars, Dis- 
crete Appl. Math. 46 (1993), 253-273 
[105] E.Wanke; Algorithms for graph problems on BNLC structured graphs, 
Inform. and Comput. 94 (1991), 93-122 
[lo61 E.Wanke; The complexity of connectivity problems on context-free graph 
languages, J. of Comp. Syst. Sci. 49 (1994), 57-82 
[lo71 E.Welz1; Encoding graphs by derivations and implications for the theory 
of graph grammars, Proc. ICALP '84 (J.Paredaens,ed.), Lecture Notes 
in Computer Science 172, Springer-Verlag, Berlin, 1984, pp.503-513 
[lo81 E.Welz1; On the set of all subgraphs of the graphs in a boundary NLC 
graph language, in The Book of L (G.Rozenberg, ASalomaa, eds.), 
Springer-Verlag, Berlin, 1986, pp.445-459 
[109] E.Welz1; Boundary NLC and partition controlled graph grammars, in 
pp.211-224 
[50], 593-609 

Chapter 2 
HYPEREDGE REPLACEMENT 
GRAPH GRAMMARS 
F. DREWES,H.-J. KREOWSKI 
Universitat Bremen, Fachbereich 3, D-28334 Bremen (Germany) 
E-mail: (drewes,kreo) @informatik.uni-bremen.de 
A. HABEL 
Universztat Hildesheim, 0-31 141 Hildesheim (Germany) 
E-mail: habel@informatik.uni-hildesheim. de 
In this survey the concept of hyperedge replacement is presented as an elementary 
approach to graph and hypergraph generation. In particular, hyperedge replace- 
ment graph grammars are discussed as a (hyper)graph-grammatical counterpart to 
context-free string grammars. To cover a large part of the theory of hyperedge re- 
placement, structural properties and decision problems, including the membership 
problem, are addressed. 
Contents 
2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . .  
97 
2.2 Hyperedge replacement grammars . . . . . . . . . .  100 
2.3 A context-freeness lemma . . . . . . . . . . . . . . .  111 
2.4 Structural properties . . . . . . . . . . . . . . . . . .  116 
2.5 
Generative power . . . . . . . . . . . . . . . . . . . .  
124 
2.6 
Decision problems . . . . . . . . . . . . . . . . . . . .  
132 
2.7 
The membership problem . . . . . . . . . . . . . . .  141 
2.8 
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . .  
155 
References 
. . . . . . . . . . . . . . . . . . . . . . . . . . . .  
156 


2.1. INTRODUCTION 
97 
2.1 Introduction 
Graph grammars have been developed as an extension of the concept of for- 
mal grammars on strings to grammars on graphs. Among string grammars, 
context-free grammars have proved extremely useful in practical applications 
and powerful enough to generate a wide spectrum of interesting formal lan- 
guages. It is therefore not surprising that analogous notions have been devel- 
oped also for graph grammars. Corresponding to the different graph-grammar 
formalisms in the literature, and to the differing opinions about what the term 
“context-free” means, a number of different types of graph grammars have 
been given this attribute (cf. Feder [l], Pavlidis [2], Della Vigna and Ghezzi 
[3], Janssens and Rozenberg [4], Slisenko [5], Bauderon and Courcelle [6], Ha- 
be1 and Kreowski [7,8], Montanari and Rossi [9], Lautemann [lo], Engelfriet 
[11,12], and Lengauer and Wanke [13]). Among the most general, there are the 
C-edNCE graph grammars surveyed in Chapter 1 and the hyperedge replace- 
ment grammars dealt with in this chapter. 
Hyperedge replacement is an elementary approach of graph and hypergraph 
rewriting. It was introduced in the early seventies by Feder [l] and Pavlidis 
[2] (under other names) and has been intensively studied since the late sev- 
enties (starting with the special case of edge replacement) by Bauderon, 
Courcelle, and Engelfriet [6,14,15,16,17], Engelfriet, Heyker, Leih, and Rozen- 
berg [18,19,20,21,22,23], Drewes, Habel, Kreowski, Lautemann, and Vogler 
[24,25,7,26,10,27,28,29,30,31,32,33,34], Lengauer and Wanke [35,36,13], and 
others. 
A hyperedge is an atomic item with a fixed number of tentacles, called the 
type of the hyperedge. It can be attached to any kind of structure coming with 
a set of nodes by attaching each of its tentacles to a node. The hyperedge 
controls the sequence of these attachment nodes and can play the role of a 
place holder, which may be replaced with some other structure eventually. In 
such a hyperedge replacement, the hyperedge is removed, and the replacing 
structure R is embedded into the original structure. For this purpose, the 
considered structures are equipped with sequences of external nodes. R is then 
glued to the remainder of the original structure by fusing each external node 
with the corresponding attachment node. For this, the number of external 
nodes in R is required to equal the type of the replaced hyperedge. Thus, 
referring to the distinction between gluing and connecting approaches discussed 
in the introduction of Chapter 1, hyperedge replacement belongs to the gluing 
approaches. 

98 
CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
The replacement of a hyperedge by some structure can be iterated if the orig- 
inal structure or the replacing one is equipped with further hyperedges. If the 
hyperedges are labelled we may define productions. They consist of a label as 
left-hand side and a replacing structure as right-hand side. Hyperedge replace- 
ment grammars mainly consist of a start structure and a finite set of such 
productions. If a hyperedge labelled with the left-hand side of a production 
is replaced with the right-hand side this is called a direct derivation. If such 
a grammar, besides the set of productions and the start structure, provides 
a specification of terminal structures, it can generate a language: the set of 
terminal structures derivable from the start structure. 
The aim of this survey is to present the theory of hyperedge replacement graph 
grammars. To keep the technicalities as simple as possible, we deal with hy- 
pergraphs that consist of sets of nodes and sets of hyperedges as described 
above, rather than with hybrid objects where some underlying structures are 
equipped with hyperedges in addition. Hypergraphs are general and flexible 
enough to cover many interesting cases. In particular, the ordinary directed 
graphs are special hypergraphs because hyperedges of type 2 are just directed 
edges. Clearly, undirected graphs can also be handled as a special case. 
If a hyperedge is replaced its context is not affected. Therefore, hyperedge re- 
placement provides a context-free type of rewriting (as long as no additional 
application conditions are employed). This is the main reason for the fact that 
several structural results for hyperedge replacement grammars and languages 
are quite similar to the properties of context-free string grammars and lan- 
guages and that many interesting problems turn out to be decidable. In this 
survey we try to cover some typical parts of the theory of hyperedge replace- 
ment. In particular, we consider structural properties and decision problems. It 
turns out that the generative power is increasing with the type of hyperedges 
involved in the derivation process even if one wants to generate only graphs 
or even string graphs. The generative power of hyperedge replacement gram- 
mars generating string graphs can be characterized in terms of tree-walking 
transducers. 
Concerning decision problems we discuss two types of questions. First, one 
can ask whether the hypergraphs generated by a given hyperedge replacement 
grammar satisfy a property 7r of interest. This question-and 
related ones-are 
of course interesting for any kind of language generating device since the lan- 
guages are usually infinite sets. In the case of hyperedge replacement grammars 
one can find a large class of such properties x for which the mentioned question 
is decidable (closely related results are discussed in Section 5.7 of Chapter 5). 
The second decision problem we are going to address is the classical member- 
ship problem: Does a given hypergraph belong to the considered language? 

2.1. INTRODUCTION 
99 
As the reader probably expects, the problem is decidable for hyperedge re- 
placement languages. However, there is an important difference to context-free 
string grammars: The membership problem turns out to be NP-complete. Only 
restricted subclasses lead to polynomial membership algorithms. 
Two further, equally important parts of the theory are left out here. They 
can be found in other chapters of this volume. The relation of hyperedge re- 
placement and node replacement is discussed in Sections 1.3.3 and 1.3.4 of 
Chapter 1 and in Section 5.6 of Chapter 5. Furthermore, monadic second- 
order logic on graphs, its relation with hyperedge replacement, and its use 
in connection with hyperedge replacement is presented in Chapter 5 (see in 
particular Sections 5.6-5.8 of that chapter). 
The introduction above should have made clear that the chapter presents an 
overview of the theory of hyperedge replacement graph grammars rather than 
of their practical use. However, it must be pointed out that hyperedge replace- 
ment is not only a concept of mathematical beauty, but is useful also from a 
practical point of view. This is no surprise at all. Graphs are used successfully 
in all branches of computer science, and context-free generation mechanisms 
of formal languages are not less important. This opens a wide area of poten- 
tial applications. Just to mention some examples, hyperedge replacement can 
be used to model and support the design of VLSI circuits (see, for example, 
[13,37] by Lengauer and Wanke), and it has been used in a generator for dia- 
gram editors to describe the context-free part of the syntax of diagrams (see 
[38,39,40] by Minas and Viehstaedt). An early application to the generation 
of semi-structured control-flow diagrams was given by Farrow, Kennedy, and 
Zucconi [41] (see also Example 2.1). In general, wherever classes of graphs or 
hypergraphs are to be specified, generated, manipulated, etc. it seems a good 
idea to distinguish between context-free aspects and non-context-free ones, and 
to describe the former by a context-free rewriting mechanism like hyperedge 
or node replacement (see also Chapter 1). 
The survey is organized in the following way. Section 2.2 provides the basic 
notions and notations of hyperedge replacement grammars. In Section 2.3, 
the context-freeness lemma is presented stating that derivations in hyperedge 
replacement grammars do not interfere with each other as long as they concern 
different hyperedges. This is the key result to the major part of the theory of 
hyperedge replacement as discussed in this chapter. Some structural properties 
(including a fixed-point theorem, a pumping lemma and a Parikh theorem) are 
presented in Section 2.4, while the generative power is considered in Section 2.5. 
Sections 2.6 and 2.7 are devoted to decision problems. While in Section 2.7 
the membership problem is discussed, Section 2.6 concerns the decidability of 

100 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
properties of hypergraphs and hypergraph languages. Each of the main sections 
ends with bibliographic notes and hints to further results. 
2.2 Hyperedge replacement grammars 
In this section, we introduce hyperedge replacement grammars as hypergraph 
manipulating and hypergraph-language generating devices. A simple example 
may perhaps be useful to illustrate the idea. Let us consider directed graphs 
with multiple edges having two distinguished nodes begin and end. We can 
replace an edge e of a graph G with another graph G' by removing e from G, 
adding G' disjointly, and fusing the begin-node of G' with the source of e and 
the end-node of G' with the target of e. The resulting graph is denoted by 
G[e/G']. An example is given in Figure 2.1. 
Figure 2.1: The replacement of an edge 
Note that G[e/G'] keeps the begin- and end-nodes of G. 
Now, let us allow in addition to label edges with arbitrary symbols. Then we 
can build productions whose left-hand sides are labels and whose right-hand 
sides are graphs. A production S ::= G' is applied to a graph G by choosing an 
edge e labelled with S and replacing it with GI, which yields a direct derivation 
G ==+ G[e/G']. The productions shown in Figure 2.2, for instance, generate 
the set of series-parallel graphs (which describe a simple type of concurrent 
processes) if we start with a single, S-labelled edge and apply productions 
until no S-labelled edge is left. A sample derivation beginning with a slightly 
larger graph is shown in Figure 2.3. Here, ==+* denotes the transitive and 
reflexive closure of ===+, as usual. 
The notion of replacement discussed so far is commonly called edge replace- 
ment, for obvious reasons. It is a special case of the notion of hyperedge replace- 
s::= o--ro s::= 
e n d  s::= 
began @ 
e n d  
began e n d  
Figure 2.2: Productions to generate series-parallel graphs. 

2.2. HYPEREDGE REPLACEMENT GRAMMARS 
101 
begzn 
a
d
 
=j 
began 
-
n
d
 
=+ 
began 
a
n
d
 
** 
b
e
g
-
d
 
* 
began 
e
n
d
 
** 
be-zd 
Figure 2.3: A derivation using the productions of Figure 2.2. 
ment presented in this chapter. In the remainder of this section the approach 
will be defined formally. The first paragraph provides the basic notions con- 
cerning hyperedges and hypergraphs. In the introduced approach, a hyperedge 
is an atomic item with a label and an ordered set of tentacles. A set of nodes 
together with a collection of such hyperedges (usually with varying numbers of 
tentacles) forms a hypergraph if each tentacle is attached to a node. Directed 
and labelled graphs, undirected and unlabelled graphs as well as strings can be 
considered as special cases of hypergraphs. For technical reasons, we assume 
that the labels are typed by non-negative integers in such a way that, for each 
hyperedge, the type of its label and the number of its tentacles coincide. 
Moreover, a hypergraph is equipped with a sequence of external nodes, which is 
used to construct the replacement of hyperedges by hypergraphs. The external 
nodes correspond to the nodes began and end in the example above. To make 
the construction simpler, we assume in addition that the attachment nodes of 
each hyperedge on the one hand and the external nodes on the other hand are 
pairwise distinct. It must be pointed out, however, that this restriction is no 
vital one. If it is dropped one can prove normal-form results yielding systems 
of the type considered here. 
Similar to the example presented above, the replacement of some hyperedges 
of a hypergraph by other hypergraphs yields an expanded hypergraph by re- 
moving the chosen hyperedges, adding the replacing hypergraphs, and fusing 
their external nodes with the corresponding attachment nodes of the replaced 
hyperedges. This notion of hyperedge replacement yields the basic steps in 
the derivation process of a hyperedge replacement grammar, where the pair 
of the label of each replaced hyperedge and the replacing hypergraph form a 
production of the grammar. 

102 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
2.2.1 Hypergraphs 
By IN we denote the set of all natural numbers, including 0. For a set A, 
A* denotes the set of all strings over A, including the empty string A; A+ = 
A* - {A} denotes the set of all strings over A, except the empty string A. 
For w E A*, IwI denotes the length of w, [w] denotes the set of all symbols 
occurring in w, and w(i) denotes the i-th symbol in w, for 1 5 i 5 (201. The 
free symbolwise extension f * :  A* + B* of a mapping f :  A -+ B is defined by 
f * ( a l  . . . a k )  = f ( a l ) .  . . f (ak) for all k E IN and a, E A (i = 1,. . . , k ) .  
In the following, let C be an arbitrary, but fixed set of labels and let type : C + 
IN be a typing function for C. A (hyperedge-labelled, multi-pointed) hypergraph 
H over C is a tuple (V, E ,  att, lab, ext) where V is a finite set of nodes, E is 
a finite set of hyperedges, att: E -+ V* is a mapping assigning a sequence 
of pairwise distinct attachment nodes a t t ( e )  to each e E E ,  lab: E -+ C is 
a mapping that labels each hyperedge such that type(lab(e)) = latt(e)\, and 
ext E V* is a sequence of pairwise distinct external nodes. 
The components of a hypergraph H may be denoted by VH, EH, att, h b H ,  
extH, respectively. Furthermore, given a set X 5 C of labels we denote by 
EG the set { e  E EH I labH(e) E X }  of hyperedges of H with labels in X .  The 
number of nodes plus the number of hyperedges of H is called the size of H ,  
denoted by [HI. The class of all hypergraphs over C is denoted by Ec. 
If the hypergraph in question is understood, we say that e E E is an m-edge 
for some m E IN and m is its type, denoted by type(e), if type(lab(e)) = m. In 
order to avoid confusion we may also write typeH(e) if H is the hypergraph 
referred to. H E Ec is an n-hypergraph for some n E IN and n its type, denoted 
by t y p e ( H ) ,  if IextHI = n. 
The sequence of external nodes may be empty so that ordinary hypergraphs 
(without external nodes) may be seen as 0-hypergraphs and in this way as 
special cases of hypergraphs with external nodes. An n-hypergraph H over 
C is considered as a (directed) n-graph if all hyperedges of H are 2-edges. 
The first node of the attachment nodes of a 2-edge corresponds to the source 
and the second one to the target. The two external nodes of a 2-graph G are 
denoted by beginG and endG in this order. 
As a convention, an unlabelled hyperedge is a hyperedge labelled with a special 
label 
which we do not draw in figures. Subject to this convention, unlabelled 
graphs and hypergraphs turn out to be special cases of the sort of hypergraphs 
defined above. 
A graph G = ( { U O , U ~ ,  . . . ,v,}, { e l , .  . . ,en}, att, Zab,vov,) over C is called a 
string graph if wo, v1, . . . , w, are pairwise distinct and att(e,) = v,-1w, for 

2.2. HYPEREDGE REPLACEMENT GRAMMARS 
103 
T1 
1 
Figure 2.4: A hypergraph denoting the expression f(g(0, 0), h(g(0,O))). 
i = 1,. . . , n. If w = lab(e1) . . ' lab(e,), then G is called the string graph induced 
b y  w and is denoted by w*. 
Such a string graph provides a unique graph 
representation of the string 20 E C+. 
In drawings of hypergraphs, a dot ( 0 )  represents an external node, internal 
nodes are drawn as circles, and a box depicts a hyperedge with attachment 
nodes, where the label is inscribed in the box, and the i-th tentacle is attached 
to the i-th attachment node (i = 1,. . . , m). In other words, the graphical rep- 
resentation makes use of the one-to-one correspondence between hypergraphs 
and bipartite graphs. As an example, see the 1-hypergraph in Figure 2.4, which 
represents a functional expression with sharing. A 2-edge may also be drawn 
as an arrow pointing from its first attached node to the second. 
An m-hypergraph H with m nodes (that is, all nodes are external) and a single 
hyperedge e is said to be a h a n d l e  if a t t H ( e )  = extH. If l a b H ( e )  = A, then H 
is said to be the h a n d l e  induced by A and is denoted by A'. 
Let H,H' E UC. Then H is a sub-hypergraph of H ' ,  denoted by H C HI, 
if VH C V H ~ ,  
EH C E H J ,  a t t H ( e )  = a t t H l ( e ) ,  and h b H ( e )  = l a b H , ( e )  for all 
e E EH. Note that nothing is assumed about the relation of the external nodes. 
H and H' are i s o m o r p h i c  if there is a pair h = (hv, h E )  of bijective mappings 
hv: VH + VHI and h E :  EH + EHJ with h ; ( a t t H ( e ) )  = a t t H , ( h s ( e ) )  and 
labH(e) = l a b H f ( h E ( e ) )  for all e E EH as well as h;(eztH) = extH1. 
aNote that this notion of handles differs from the one used in Section 1.4.3 of Chapter 1. 

104 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
2.2.2 Hyperedge replacement 
Let H E 3tc be a hypergraph, B C EH be a set of hyperedges to be replaced. 
Let repl: B + 3tc be a mapping with type(repl(e)) = type(e) for all e 
B. 
Then the replacement of B in H by repl yields the hypergraph H[repZ] obtained 
by removing B from E H ,  adding the nodes and hyperedges of repl(e) for each 
e E B disjointly and fusing the i-th external node of repl(e) with the i-th 
attachment node of e for each e E B and i = 1,. . . , type(e). All hyperedges 
keep their labels and attachment nodes; the external nodes of H[repl] are those 
of H .  If B = {el,. . . ,en} and repl(ei) = Ri for i = 1,. . . ,n, 
then we also write 
H [ e l / R I , .  . . ,en/&] instead of H[repl]. 
If, for each e E B, the replacing hypergraph repl(e) consists of the attachment 
nodes as external nodes and nothing else, the replacement of B in H removes 
B and adds nothing. Hence, the result may be denoted by H - B in this case. 
The replacement of some hyperedges is illustrated in Figure 2.5. 
Figure 2.5: The replacement of (unlabelled) hyperedges el,. . . , e4 with R1,. . . , R4. 
Note that the result of a hyperedge replacement is defined only up to isomor- 
phism. Therefore, to keep the technicalities as simple as possible, we usually 
do not distinguish between isomorphic copies of a hypergraph. 
Hyperedge replacement enjoys some nice properties well-known from other 
rule-based formalisms. First of all, we have a sequentialization and paralleliza- 
tion property. It does not matter whether we replace some hyperedges of a 
hypergraph one after another, or simultaneously. The second property is con- 
fluence. Hyperedges of a hypergraph can be replaced in any order, without 
affecting the result. (In fact, this follows already from the sequentialization 
and parallelization property. If we replace hyperedges simultaneously there is 
no order among them at all.) The last and maybe most important property 

2.2. HYPEREDGE REPLACEMENT GRAMMARS 
105 
is associativity. If a hyperedge is replaced and afterwards a hyperedge of the 
new part is replaced with a third hypergraph, the same is obtained by first 
replacing the latter hyperedge and then replacing the first one with the result. 
These properties are stated formally below. 
Sequentialization and parallelization. 
Let H be a hypergraph with pairwise 
distinct el,. . . ,en E EH and let Hi be a hypergraph with type(Hi) = typeH(ei) 
for i = I,. . . ,n. Then 
Confluence. 
a hypergraph with type(Hi) = typeH(ei) for i E {1,2}. Then 
Let H be a hypergraph with distinct el, e2 E EH and let Hi be 
Associativity. 
such that typeH(e1) = type(H1) and typeHl (e2) = type(H2). Then 
Let H ,  HI, H2 be hypergraphs with el E EH and e2 E E H ~ ,  
2.2.3 
Let N C C be a set of nonterminals. A production over N is an ordered pair 
p = (A,R) with A E N ,  R E 7 - l ~  and type(A) = type(R). A is called the 
left-hand side of p and is denoted by lhs(p); R is called the right-hand side and 
is denoted by rhs(p). 
Let H E 7 - l ~  
and let P be a set of productions. Let e E EH and (labH(e), R) E 
P. Then H directly derives H' = H[e/R]. In this case, we write H ==+p H', or 
just H + 
H' if P is clear from the context, and call this a direct derivation. 
Examples of direct derivations have already been discussed in the beginning of 
this section (see Figure 2.3). 
A sequence of direct derivations HO ==+...==+Hk 
is called a derivation of 
length k from HO to Hk and is denoted by H ==+> H' or HO ==+* Hk. If the 
length of the derivation matters, we write Ho d k  
Hk. Additionally, if HA is 
isomorphic to Ho, we speak of a derivation from HO to HA of length 0. 
Using the concepts of productions and derivations, hyperedge replacement 
grammars and languages can be introduced in a straightforward way. This 
is done below. 
Hyperedge replacement derivations, grammars, and languages 

106 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
Definition 2.2.1 (hyperedge replacement grammar) 
A hyperedge replacement grammar is a system HRG = ( N ,  T ,  P, S )  where 
N C C is a set of nonterminals, T 
C with T n N = 0 is a set of terminals, 
P is a finite set of productions over N and S E N is the start symbol. 
The hypergraph language L(HRG) generated by HRG is Ls(HRG), where for 
all A E N ,  LA(HRG) consists of all hypergraphs in Zfl~ 
derivable from A' by 
applying productions of P: 
LA(HRG)={H €'?lfl~(A'=$-H}. 
We denote the class of all hyperedge replacement grammars by ZRG and the 
class of all hyperedge replacement languages by X X C .  A hyperedge replacement 
grammar HRG = ( N ,  TI PI S )  is said to be of order r (for some r E IN) if for 
all (il, 
R) E P ,  type(R) 5 r.  A hyperedge replacement language L is of order r 
(for some T E IN) if there is a hyperedge replacement grammar HRG of order 
T with L(HRG) = L. The classes of all hyperedge replacement grammars and 
languages of order r are denoted by ZRG, and ZRC,, respectively. A hyper- 
edge replacement grammar ERG = ( N ,  T, PI S )  such that all right-hand sides 
of productions in P are graphs is also called an edge replacement grammar. 
Note that, if given such an edge replacement grammar, one may always assume 
without loss of generality that all nonterminal labels except perhaps the start 
symbol have type 2. The class of all edge replacement grammars is denoted by 
EXG. 
Even if one wants to generate graph languages (or string-graph languages) 
rather than hypergraph languages, one may use nonterminal hyperedges be- 
cause the generative power of hyperedge replacement grammars increases with 
their order (see Section 2.5). By definition of derivations the set L(WRG) is 
closed under isomorphisms. Moreover, L(HRG) is homogeneous, that is, all its 
hypergraphs are of the same type. Therefore, non-homogeneous languages and 
languages not closed under isomorphism cannot be generated by the grammars 
introduced above. 
Example 2.1 (generation of semi-structured control-flow graphs) 
Control-flow graphs of so-called semi-structured programs are useful for data 
flow analysis, as shown by Farrow, Kennedy, and Zucconi [41]. These control- 
flow graphs (seen as hypergraphs) are generated by the hyperedge replacement 
grammar FLOW-GRAPHS = ({C, D}, {c, d } ,  PI C), where P contains the pro- 
ductions given in Figure 2.6 in a kind of Backus-Naur-Form. (The types of 
nonterminal labels are those of the corresponding right-hand sides.) A deriva- 
tion deriving a multi-exit loop is given in Figure 2.7, where tentacle numbers 
are omitted. 
0 

2.2. HYPEREDGE REPLACEMENT GRAMMARS 
1 -. 
2\ 
2 
107 
2 
c::= { 
D ::= f 
1 
2 
om 
3
1
 
1 2
3
 
1 
2v3 
2 
1 2 
i 3 
3 9 
2 i 
1 
* 
1 fi 
2 
3 
1 
? 
r-& 
a + 
3 3 
2 1 
1 
3 
b & 
2 
3 4 
I :  
2
3
 
I
?
 
1 
Figure 2.6: Productions of the hyperedge replacement grammar FLOW-GRAPHS 

108 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
2 
t 
==+* t 
2 
===+ 
===+ $9 
2 
1 
1 
*' 
2 
2 
Figure 2.7: A derivation in the hyperedge replacement grammar FLOW-GRAPHS. 

2.2. HYPEREDGE REPLACEMENT GRAMMARS 
109 
Figure 2.8: Productions of the hyperedge replacement grammar A%'?? 
Example 2.2 (generation of a string-graph language) 
Let 
us 
consider 
the 
hyperedge 
replacement 
grammar AnPCP" 
= 
({S, A } ,  {a, b, c}, P, S )  where P consists of the productions depicted in 
Figure 2.8. Beginning with So, the application of the second production 
yields the string graph (abc)'. By applying the first production, then applying 
the third production n - 1 times, followed by an application of the fourth 
production, we obtain the derivation in Figure 2.9. Furthermore, the only 
hypergraphs in L(AnPC@) are string graphs of the form (anbncn)* for n 2 1. 
0 
Thus, L(AnPC@) = { (anbncn)* 1 n 2 1). 
2.2.4 
Bibliographic notes 
The kind of introduction chosen here is similar to the one in [42]. It must be 
noted, however, that the notion of direct derivations chosen here is a purely se- 
quential one. A direct derivation replaces only one hyperedge. Instead, one can 

110 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
Figure 2.9: A derivation in AnBnC? 
as well use a notion of parallel direct derivations, where arbitrarily many hyper- 
edges can be replaced in one step. More precisely, we could say H 3~ 
H[repZ] 
if repl: B + %C is a mapping with B C EH and (labH(e), repZ(e)) E P for all 
e E B. Using the sequentialization property of hyperedge replacement quoted 
above, it is clear that every derivation consisting of this type of parallel direct 
derivations can be transformed into a derivation using only direct derivations 
as defined here. In particular, both notions of direct derivations lead to hyper- 
edge replacement grammars of equal generative power. 
The hyperedge replacement approach presented here is described on a set- 
theoretical level. Since hyperedge replacement may be seen as a special case 
of hypergraph replacement in the double-pushout approach (see [43]) and the 
double-pushout approach has an algebraic description (see Chapter 3) , hy- 
peredge replacement has an algebraic description, too. The relation between 
hyperedge replacement languages, logical definability of hypergraph languages, 
and recognizability has been intensively studied by Courcelle (see Chapter 5). 
Courcelle, Engelfriet , and Rozenberg [44] studied the notion of separated 

2.3. A CONTEXT-FREENESS LEMMA 
111 
handle-rewriting hypergraph grammars (see also Section 1.4.3 of Chapter 1). 
These grammars combine the rewriting mechanisms of vertex- and hyperedge 
replacement graph grammars. If we restrict our attention to the generation 
of graphs, handle rewriting grammars are as powerful as the C-edNCE graph 
grammars discussed in Chapter 1 and are thus more powerful than hyper- 
edge replacement grammars. Looking at the more general situation where hy- 
pergraphs are generated, hyperedge replacement and handle-rewriting graph 
grammars turn out to be incomparable, though. 
In [23] Engelfriet shows how regular tree grammars can be used to generate 
graphs, by generating expressions that denote graphs. Top-down and bottom- 
up tree transducers can then be used as a tool for proving properties of such 
graph generating tree grammars. 
As mentioned in the introduction, the idea of hyperedge replacement can also 
be applied to structures other than hypergraphs. Considering pictures (that is, 
subsets of IRd for some d E IN) as underlying structures Habel and Kreowski 
[45] introduced the so-called collage grammars. These allow to generate and to 
study (approximations of) fractal images and other sorts of pictures (see the 
work by Dassow, Drewes, Habel, Kreowski, and Taubenberger [46,47,48,49]). 
2.3 A context-freeness lemma 
In this section, we present a context-freeness lemma for hyperedge replacement 
grammars and languages. Furthermore, we employ the lemma in order to in- 
troduce derivation trees as a helpful and intuitive representation of derivations. 
2.3.1 
Context freeness 
Most of the results presented in this survey (as, for example, the fixed-point 
theorem and the pumping lemma) are mainly based on the context-free nature 
of hyperedge replacement. Suppose we are given any notion of replacement 
allowing to replace primitive components of certain objects with other such 
objects. In the string case the objects would be strings and the primitive com- 
ponents would be the individual letters. In the case of hyperedge replacement 
we have hypergraphs as objects and hyperedges as primitive components. In- 
tuitively, context-freeness means that in a derivation of an object 0’ from and 
object 0 we can consider the primitive components of 0 separately to derive 
from them the corresponding parts of 0’. More precisely, 0 derives 0‘ if and 
only if each nonterminal component x derives an object repZ(z) such that 0’ 
is the object obtained by replacing each nonterminal II: of 0 with repl(z). 

112 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
In the case of type-2 string grammars we can derive a string w from A1 . . . A, 
if and only if w = repl(A1) . . . repZ(A,), where each repl(Ai) is a string deriv- 
able from Ai. In the case of hyperedge replacement grammars the situation 
is similar, though not as completely obvious. Intuitively, during a derivation 
that derives a hypergraph H from a hypergraph R the nonterminal hyperedges 
of R are turned step by step into larger hypergraphs. Thus, each nonterminal 
hyperedge of R gives rise to a particular sub-hypergraph of H .  The important 
point is that the applicability of a production depends only on the existence of 
a hyperedge with the required label, and nothing but this hyperedge is affected 
by the application of the production. Therefore, if we are given a nonterminal 
hyperedge e E ERN we may simply forget about the context of e in R, keep- 
ing only the handle Z a b ~  
(e)', and restrict the original derivation accordingly. 
In this way we get for every e E ERN a sub-derivation ZabR(e)' J *  
repl(e) 
such that R[repl] = H .  Clearly, the converse is also true: If we are given the 
hypergraphs repZ(e) with labR(e)' ==+* repl(e) ( e  E E g )  then the hypergraph 
R[repZ] is derivable from R. This property justifies to call hyperedge replace- 
ment grammars context-free. 
Below, we state the result in a recursive version especially suitable for inductive 
proofs. If a derivation starts in a handle A' it must necessarily have the form 
A' ==+ R J* 
H ,  where (A, R) is a production. The remainder R ==+* H can 
now be decomposed as described above. 
For the rest of this chapter let us employ the following assumption. 
General assumption. Let N ,  T be two disjoint subsets of the alphabet C. 
Theorem 2.3.1 (context-freeness lemma) 
Let P be a set of productions over N .  Let H E XC, 
A E N ,  and k E IN. 
Then there is a derivation A' 
j k + l  H if and only if there is a production 
(A, R) E P and a mapping repl: ERN -+ 'Hc with H = R[repZ], such that 
labR(e)' ==+k(e) repl(e) for all e E E z  and CeEEg 
k ( e )  = k. 
Pro0 f 
We shall prove this result in detail because of its central character. By definition 
of direct derivations, if a derivation A' jk+' 
H exists it must have the form 
A' --r. R j k  
H for some (A, R) E P. Hence, the proof is finished if we can 
show the following. 
Let G, GI be hypergraphs. Then we have G 3' G' if and only 
if there is some repl: E: +- XC with G' = G[repZ], such that 
labc(e)' =+k(e) 
repl(e) for all e E Eg and CeEEg 
k(e) = k. 

2.3. A CONTEXT-FREENESS LEMMA 
113 
We proceed by induction on k. For k = 0 both directions are trivial, so 
let us assume k > 0. Proving first the only-zf direction, we must have 
G*GO*'-~G' 
where Go = G[eo/Ro] for some eo E E g  and some 
(labG(eo), Ro) E P. The induction hypothesis yields a mapping replo : Ego -+ 
7 - l ~  
with G' = Go[replo], such that labG,(e)' 
==+ko(e) replo(e) for all e E Ego, 
where the sum of the ko(e) is k-1. Now, let repl(e) = replo(e) fore E Eg\{eo} 
and repl(e0) = Ro[replb], where replb is the restriction of replo to ER",. Then, 
if repl: is the restriction of replo to EG \ {eo} we get G' = Go[replo] = 
G[eo/Ro] [ replo] = G[ replg] [eo/&] [ replb] = G[ repl:] [eo/repl( eo)] = G[ repl], as 
required. 
For the zf 
direction, let G' = G[repl] with labG(e)'*k(e) 
repl(e) for all 
e E E$ and CeGEg 
k(e) = k. We may assume without loss of generality 
that k(e) > 0 for all e E Eg (otherwise, consider the restriction of repl to 
those hyperedges). Suppose E g  = {el,. . . ,en}. Then there are hypergraphs 
G, (i = 1,. . . , n) such that labG(e,)' 
repl(e,) for z = 1,. . . n. 
Making use of the (already proved) only-zf direction there are repl, : Eg, + XC 
for i = 1,. . . , n such that G,[repl,] = repl(e,), labGr (e)' = = + ' I ( ~ )  
repl,(e) for all 
e E Eg,, and CeEEc" 
k,(e) = k(e,) - 1. 
Let GO = G[el/G1,. . . ,en/Gn] and replo(e) = repl,(e) for all e E Ec", (i = 
1 ,... ,n). Then we get G' = G[repl] = G [ e ~ / G ~ [ r e p l ~ ]  
,... ,en/Gn[repln]] = 
G[el/GI,. . . ,en/G,][replo] = Go[repl,]. By the induction hypothesis this 
yields a derivation Go j k V n  
G' and by construction of Go we have G J~ 
Go, 
which completes the proof. 
0 
G, 
The possibility of decomposing a derivation as stated in the context-freeness 
lemma may be illustrated as in Figure 2.10. The context-freeness lemma can 
also be formulated as a characterization of the languages generated from han- 
dles, which yields an alternative method of deriving hypergraphs. 
Corollary 2.3.2 
Let HRG = (N,T,P,S) E XRG. For all A 
E N let rhs(A) = 
{ R  E 3 - l ~  
I (A, R) E P}. Then 
Pro0 f 
Apply the context-freeness lemma to terminal graphs which are the elements 
0 
of the languages LA(HRG) for A E N .  

114 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
Figure 2.10: Decomposition of a derivation according to the context-freeness lemma 
2.3.2 
Derivation trees 
The context-freeness lemma allows us to introduce the concept of derivation 
trees as a convenient representation of derivations. Consider some derivation 
A' ==+* H .  If k = 0 then H = A' 
and we may represent the derivation by a 
one-node tree whose only node is the label A. Otherwise, the context-freeness 
lemma states that the derivation has the form A' ==+ R ==+* R[repl], where 
(A,R) is a production and ZabR(e)'==+* repZ(e) for all e E ERN. Thus, the 
derivation gives rise to a tree whose root is the production (A,R) and whose 
subtrees are the trees obtained recursively from the derivations labR(e)' ==+* 
repl(e) for e E ERN. Thus, derivation trees represent derivations up to some 
reordering of direct derivation steps (which does not affect the result of a 
derivation, as we know). The resulting hypergraph of a derivation tree is then 
given by R[repl], where R is the right-hand side of the production in its root 
and repl(e) is recursively obtained as the result of the subtree corresponding 
to e E ERN. 
Definition 2.3.3 (derivation tree) 
The set TREE(P) of derivation trees over P is recursively defined as follows. 

2.3. A CONTEXT-FREENESS LEMMA 
115 
0 N C TREE(P) with root(A) = A and resuZt(A) = A' for A E N 
0 For every production (AIR) E P and every mapping branch: ERN + 
TREE(P) such that we have type(e) = type(root(branch(e))) for all e E 
ERN, the triple t = (A, R, brunch) is in TREE(P). 
Furthermore, we let root(t) = A and resuZt(t) = R[repZ] where, for all 
e E ERN, repl(e) = resuZt(branch(e)). 
One should notice that a derivation tree contains nonterminal labels A E N as 
subtrees if and only if its result is not terminal. The theorem below states the 
expected correspondence between derivations and derivation trees. 
Theorem 2.3.4 
Let P be a set of productions over N ,  let A E N and H E 317.. Then there is 
a derivation A' J* 
H if and only if there is a derivation tree t over P with 
root(t) = A and result(t) = H .  
Proof 
For the first direction, suppose t is a derivation tree over P with root(t) = 
A and result(t) = H .  The proof is by induction. If t = A then root(t)* = 
A' ==+' A' = resuZt(t). If t = (A, R, brunch), using the induction hypothesis we 
get a derivation root(brunch(e))' ==+* resuZt(brunch(e)) for all e E ERN. By the 
context-freeness lemma, this yields a derivation root(t)' = A' +* 
R[repZ] = 
resuZt(t) with repl(e) = result(brunch(e)) for all e E ERN. 
The proof for the other direction can be done in a similar way by induction 
on the length of derivations using the other direction of the context-freeness 
lemma. 
0 
An interesting consequence of Theorem 2.3.4 is obtained by considering the 
root and the result of a derivation tree over P as a new production. Formally, 
let P* = {(root(t), result(t)) It E TREE(P)}. Then, A' ==+p 
H if and only if 
A' ==+$ H ,  by Theorem 2.3.4. By induction on the length of derivations this 
yields, for every label A and all hypergraphs HI 
A ==+> H if and only if A +>. H .  
This property will be used in Section 2.7 in order to obtain a cubic membership 
algorithm for a certain class of edge replacement languages. 
2.3.3 Bibliographic notes 
To emphasize their context-freeness, hyperedge replacement grammars are 
sometimes called context-free hypergraph grammars (see, for example, [26,18] 

116 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
and Chapter 1 of this handbook). The context-freeness lemma was first for- 
mulated and proved for edge replacement grammars (see 171); a formulation 
for hyperedge replacement grammars can be found in [26,42]. In [50] Cour- 
celle presents an axiomatic definition of context-free rewriting. The definition 
requires that a context-free notion of replacement be associative and conflu- 
ent. As mentioned in Section 2.2 hyperedge replacement indeed satisfies these 
requirements. Thus, hyperedge replacement is a context-free rewriting mech- 
anism in Courcelle’s sense. In fact, though in a somewhat different way, The- 
orem 2.3.1 also expresses nothing else than associativity and confluence of 
hyperedge replacement. It says that the order in which productions are ap- 
plied is not important (on one side of the equivalence there is no order) and 
that we can first build the results of the sub-derivations and afterwards replace 
the hyperedges of the initial hypergraph with these results instead of doing it 
step by step (which is associativity). 
In the literature, some suggestions concerning non-context-free extensions of 
hyperedge replacement are encountered. The parallel mode of rewriting as 
known from L-systems with tables may be employed. This was studied by Ehrig 
and Tischer [51] for edge replacement and by Kreowski [52] for hyperedge re- 
placement. David, Drewes, and Kreowski [53] combined this with a rendezvous 
mechanism. Here, nodes of different right-hand sides added in a parallel step 
can be fused in a certain way whenever the replaced hyperedges are neighbours. 
This allows to overcome most of the restrictions. Besides the parallel case and 
other application conditions, Kreowski [54] discusses hyperedge replacement as 
a means to specify infinite (hyper)graphs by infinite derivations, which were 
first investigated by Bauderon [55,56]. 
Derivation trees as they are defined here are closely related to rule trees as 
introduced and investigated by Kreowski [25]. 
2.4 Structural properties 
In this section, we discuss some structural properties of hyperedge replace- 
ment languages. They demonstrate that several results well-known for context- 
free string languages (like the fixed-point theorem, the pumping lemma, and 
Parikh’s theorem) can be generalized to hyperedge replacement languages. 
2.4.1 A jixed-point theorem 
We start with a fixed-point theorem for hyperedge replacement languages gen- 
eralizing Ginsburg’s and Rice’s fixed-point theorem for context-free string lan- 
guages [57]. It is shown that hyperedge replacement languages are the least 
fixed points of their generating productions (considered as a system of lan- 
guage equations). 

2.4. STRUCTURAL PROPERTIES 
117 
In the following, for every set C of labels let us denote by RLc the set of all 
languages of hypergraphs over C ,  that is, Rftcc is the powerset of XC. 
Definition 2.4.1 (system of equations and fixed-point) 
Let N ,  T 
C be sets of labels with N n T = 0. A system of equations over N 
is a mapping EQ : N -+ X L N ~ T .  
A mapping L : N -+ RLT is a fixed-point of 
EQ if, for all A E N ,  
L(A) = u 
R E E Q ( A )  
{R[repl: ERN -+ RT] I repl(e) E I;(labR(e)) for e E ERN}. 
L :  N -+ ZLT is a least fixed-point of EQ if L is a fixed-point of EQ and 
L(A) 5 L’(A) for all A E N and all fixed-points L’ of EQ. 
Remarks: 
1. A system of equations EQ: N -+ X L N ~ T  
over N may be denoted by 
A = EQ(A) for A 6 N to emphasize the name. Actually, it is nothing else 
than a representation of a set P of productions over N .  For P, there is an 
associated system of equations EQp : N -+ R L N U T  defined as EQp(A) = 
{R I ( A ,  R) E P}. Conversely, a system of equations EQ : N -+ R L N ~ T  
over N yields a set of productions P(EQ) = { ( A , R )  I R E EQ(A)}. 
2. The language family L : N + RLT generated by a hyperedge replacement 
grammar HRG is given by L ( A )  = LA(HRG) for A E N .  
According to Corollary 2.3.2, the language family generated by a hyperedge 
replacement grammar is a fixed-point of the system of equations associated 
with the set of productions of the grammar. Even better, the following holds. 
Theorem 2.4.2 (fixed-point theorem) 
Let HRG = ( N ,  T ,  P, S )  be a hyperedge replacement grammar, EQp : N -+ 
7 - i . c ~ ~ ~  
the system of equations associated with P, and L :  N -+ XCT the 
language family generated by HRG. Then L is the least fixed-point of EQp. 
Pro0 f 
Let L’: N + XCT be a fixed-point of EQ. We have to show L ( A )  C_ L’(A) for 
all A E N ,  that is, H E L’(A) for all H E X T  with A’ 
j
’
p
 H. This can be 
shown by induction on the length of derivations. A’ ==+& H implies (A, H )  E 
P with H E RT, 
so that H[empty] = H is defined for the empty mapping 
empty: 0 -+ RT. 
Since L’ is a fixed-point of EQ, H = H[empty] E L’(A). 

118 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
Consider now A' *:+' H .  Due to the context-freeness lemma, there are 
(A, R) E P, and derivations labR(e)' ==+k(e) repl(e) for e E ERN with k(e) 5 k 
and H = R[repl]. By the induction hypothesis, repl(e) E L'(labR(e)). There- 
0 
fore, H = R[repl] E L'(A) because L' is a fixed-point of EQ. 
2.4.2 A pumping lemma 
We now present a pumping lemma for hyperedge replacement languages. It 
says that each sufficiently large hypergraph belonging to a hyperedge replace- 
ment language can be decomposed into three hypergraphs FIRST, LINK, 
and LAST, so that a suitable composition of FIRST, k samples of LINK for 
each natural number k ,  and LAST yields also a member of the language. This 
theorem generalizes the well-known pumping lemma for context-free string lan- 
guages (see, for instance, [58,59]). As in the string case, the pumping lemma 
can be used to show that certain languages are no hyperedge replacement 
languages. 
A hypergraph H is substantial if VH # [ e x t ~ ]  
or l E ~ l  > 1. A hyperedge 
replacement grammar each of whose productions has a substantial right-hand 
side is growing. A growing hyperedge replacement grammar generates only 
substantial hypergraphs. Note that all except a finite number of hypergraphs in 
a hyperedge replacement language L are substantial, since {IextHI I H E L }  is 
finite. Using a straightforward extension of the proof for the well-known result 
saying that one can eliminate empty and chain productions from context-free 
Chomsky grammars it is not hard to prove the following normal-form result, 
which is used later on. 
Lemma 2.4.3 
For every hyperedge replacement grammar HRG we can effectively construct 
a growing hyperedge replacement grammar HRG' of the same order satisfying 
0 
L(HRG') = { H  E L(HRG) I H substantial}. 
Definition 2.4.4 (composition and iterated composition) 
1. Let X E C. Then H 6 31c is said to be X-handled if there is a unique 
type(X)-edge e E EH with label X. In this case, e is called the X-handle 
of H ;  the hypergraph without the X-handle, H - {e}, is denoted by He. 
2. Let H E 31c be a hypergraph with X-handle e and let H' E 7lc be a 
type(X)-hypergraph. Then the hypergraph H[e/H'] is called the compo- 
sition of H and H' with respect to e and is abbreviated by H 8 H'. 

2.4. STRUCTURAL PROPERTIES 
119 
3. Let H E 7 - l ~  be an X-handled type(X)-hypergraph. Then for k E IN, 
Hk E 3 - 1 ~  is recursively defined by H o  = X' and Hi+' = H @ Hi 
for 
i >_ 0. 
Note that, in the definition above, Hi 
is X-handled, thus Hi'-' is well-defined. 
Theorem 2.4.5 (pumping lemma) 
Let L be some hyperedge replacement language of order r (for some T E IN). 
Then there exist constants p and q such that the following is true: For every 
hypergraph H in L with (HI > p there are an X-handled hypergraph FIRST, a 
substantial X-handled type (X) -hypergraph LINK, and a type (X)-hypergraph 
LAST forsomeX E C with H = FIRSTBLINKBLAST, /LINK @ LAST1 5 
q, and type(LINK) 5 r ,  such that FIRST@ LINKk BLAST E L for all k E IN. 
Furthermore, for every hypergraph H in L with l V ~ l  > p we can choose LINK 
in such a way that VLINK \ [eXtLINK] # 0. 
Proof 
Let HRG = ( N , T ,  P, S) E XtlnG, with L(HRG) = L and n the number of 
nonterminals. Since there are only finitely many non-substantial hypergraphs 
in L(HRG) we may assume HRG is growing. Let max be the size of the 
largest right-hand side of HRG. Let t E TREE(P) with root(t) = S and H = 
result(t) E 3-17.. If [HI > muxn, then t contains a path from the root to a leaf 
longer than n such that one of the nonterminals, say XI occurs twice. In other 
words, t has a subtree t' with root X which has a proper subtree t" with root X .  
Choose LAST = resuZt(t"), LINK = result(t'-t") and FIRST = result(t-t') 
where t' - t" is obtained from t' by removing the subtree t" and t - t' by re- 
moving t' from t. Then, FIRST and LINK are X-handled, LINK and LAST 
are type(X)-hypergraphs, and H = FIRST @ LINK @ LAST. Since HRG is 
growing, LINK must be substantial. As in the case of the pumping lemma for 
context-free string languages one can now show FIRST @ LINKk @ LAST E L 
for all k E N. 
If we even have l V ~ l  > p we may choose t' - t" in such a way that result(t' - t") 
has at least one internal node. This is because, in this case it suffices to consider 
the nodes of the derivation tree of which the corresponding right-hand sides 
have internal nodes. This yields the second statement of the theorem and thus 
finishes the proof. 
0 
The composition of H using FIRST, LINK, and LAST can be depicted as 
shown in Figure 2.11. The pumped hypergraphs have the shape depicted in 
Figure 2.12. Note that FIRST0, LINK0, and LAST are not necessarily con- 
nected hypergraphs (see Example 2.3 below). 

120 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
Figure 2.11: The result of composing FIRST, LINK, and LAST 
... 
... 
... 
Figure 2.12: The hypergraph obtained by composing FIRST@, k samples of LINKB, and 
LAST. 
As in the case of context-free string grammars, the pumping lemma can be used 
to show that the finiteness problem is decidable for hyperedge replacement lan- 
guages. Another helpful consequence of the pumping lemma is the linear growth 
within hyperedge replacement languages. More explicitly, let L be an infinite 
hyperedge replacement language. Then the pumping of a large enough mem- 
ber of L yields an infinite sequence of hypergraphs in L, say Ho, HI, H2,. . . , 
and constants c, d E IN with c + d > 0 such that IVH,+~ 
1 = ~VH, 
1 + c and 
IEH,+~ 
I = [EH, 
1 + d, for all i 2 0. 
Example 2.3 
First, we want to illustrate the pumping property for the string-graph language 
L = { (anbncn)* 1 n 2 l} that can be generated by a hyperedge replacement 
grammar of order 4, as shown in Example 2.2. For n 2 3, the string graph 
(anbncn)* can be decomposed as indicated in Figure 2.13 for the case n = 4. 
FIRST is a 2-hypergraph containing the two external nodes of the string graph 
as external nodes. It consists of three chains of edges of length n - 2, an 
a-chain, a b-chain, and a c-chain, where the a-chain is attached to the first 
external node and the c-chain is attached to the end of the bchain. Moreover, 
it may be seen as 4-handled, where the first pair of tentacles is attached to 
the end of the a-chain and the beginning of the b-chain and the second pair of 
tentacles is attached to the end of the c-chain and the second external node. 
It is composed with the LINK-component with respect to this 4-handle. The 

2.4. STRUCTURAL PROPERTIES 
121 
Figure 2.13: Decomposition of (a4b4c4).. 
Figure 2.14: Pumping of ( a 4 b 4 c 4 ) *  
LINK-component possesses a 4-handle which is attached to the target of the a- 
edge, the source of the b-edge, the target of the c-edge and the second external 
node. Note that neither FIRSTe (FIRST without the 4-handle) nor LINKe 
(LINK without the 4-handle) nor LAST is connected. Moreover, LINK is 
non-trivial. 
The pumped 2-hypergraphs have the shape shown in Figure 2.14. Obviously, 
each resulting 2-hypergraph is a string graph of the form (unbncn). for some 
n 2 1. 
I3 
One of the main uses of results like the pumping lemma is to prove that specific 
hypergraph languages are no hyperedge replacement languages. There is, for 
example, no hyperedge replacement language of unbounded connectivity. To 
see this, assume such a language is generated by a hyperedge replacement 
grammar of order T .  Then, a sufficiently large graph of connectivity greater 

122 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
than r could be written as FIRSTBLINKBLAST, where \LINK @ LAST( 5 q 
for some fixed q, type(LINK) 5 T ,  and LINK contains at least one internal 
node. But since q is fixed we may assume that FIRST contains more than r 
nodes, so FIRSTBLINKBLAST is of connectivity at most r because removing 
the external nodes of LINK from the graph yields at least two components. 
As another example, the string-graph language {(an2)* 
1 n 2 l} cannot be gen- 
erated by a hyperedge replacement grammar because the growth of the number 
of edges is not linear. The pumping lemma can also be used to show that the 
string-graph language {(a: . . . a&)* I n E IN} cannot be generated by any hy- 
peredge replacement grammar of order less than 2k, for k 2 1. This will be 
done in Section 2.5 (see Example 2.5). 
24.5' 
Parikh's theorem 
As a third structural result, we present the hyperedge replacement version 
of Parikh's theorem [60] which relates hyperedge replacement languages to 
semilinear sets. The proof makes use of Parikh's theorem for context-free string 
languages by mapping hyperedge replacement grammars to context-free string 
grammars. In the following, for x = (XI,. 
. . ,zn) and y = (yl, . . . , gn) in INn 
g n ) ,  and cz = (cz1,. . . , an). 
andcE W,letusdefinex+y= ( z l + y ~ ,  ... ,zn+yn),x-y= (x1-yl )... ,xn- 
Definition 2.4.6 (Parikh mapping and semilinear set) 
1. Let T = {all.. . ,a,} be an alphabet and $: ? i ~  
+ INn be the mapping 
given by $ ( H )  = (#a, ( H ) ,  . . . , #a,(H)), where # a i ( H )  denotes the 
number of a,-labelled hyperedges in H E 3 1 ~ .  
Then $ is called a Parikh 
mapping. For every language L 
?i~, 
$(L) denotes the set $(L) = 
{+(HI I H E L). 
2. A set S 
INn is linear if S is of the form 
k 
s = { X O + ~ C i X i I c l , . . .  ,ck Ern}, 
i= 1 
w h e r e k > l a n d x l ,  ... , x ~ E I N ~ .  
3. S C IN" is semilinear if it is the union of a finite number of linear sets. 
Theorem 2.4.7 (Parikh's theorem) 
For all hyperedge replacement languages L and every Parikh mapping $, the 
set $(L) is semilinear. 

2.4. STRUCTURAL PROPERTIES 
123 
Pro0 f 
Let L be a hyperedge replacement language and HRG = ( N , T ,  P, S )  be 
a hyperedge replacement grammar with L = L(HRG). We construct a 
context-free string grammar G as follows: Let str: ;FthrU~ -+ ( N U T ) *  be 
the mapping assigning the string str(H) = labH(e1). . . labH(e,) to a hy- 
pergraph H with EH = {el,. . . , en} (ordered in some arbitrary way) and 
let G = ( N , T ,  str(P),S) with str(P) = {(A, str(R)) I (A,R) E P}. Then 
$(L(HRG)) = GstT(L(G)) 
where 
denotes the usual Parikh mapping for 
string languages. By Parikh's theorem for context-free string languages, the set 
Gstr(L(G)) 
is semilinear. Consequently, the set G(L(HRG)) = $(L) is semilin- 
ear. 
0 
It is perhaps interesting to notice that one may attach a 1-edge with a spe- 
cial label to each internal node of a right-hand side of a production. Then 
counting the hyperedges with the special label means counting the number of 
(internal) nodes. Consequently, counting the number of nodes in hypergraphs 
of a hyperedge replacement language yields a semilinear set, too. As a second 
remark, it is not hard to see that there are several languages L (such as the 
set of all graphs) which have the semilinearity property but are no hyperedge 
replacement languages. 
2.4.4 
Bibliographic notes 
The fixed-point theorem for hyperedge replacement languages was formulated 
for edge replacement in [7] by Habel and Kreowski and for hyperedge replace- 
ment by Bauderon and Courcelle in [6] (in a slightly different form). The reader 
should compare the fixed-point theorem with the way in which Courcelle de- 
fines HR sets of hypergraphs in Section 5.6 of Chapter 5. HR sets of hypergraphs 
are just the least fixed-points of systems of equations. However, the allowed 
equations do not make use of hyperedge replacement. They are built upon 
a more primitive set of operations, which nevertheless give rise to the same 
least fixed-points. Thus, HR sets of hypergraphs are hyperedge replacement 
languages and vice versa. 
The pumping lemma is based on the pumping lemma for edge replacement 
languages given in Kreowski [24]. A hyperedge replacement version was first 
given in [26] and proved in [42]. Moreover, a number of consequences of the 
pumping lemma for hyperedge replacement languages can be found in [42]. 
In particular, it is shown that for hyperedge replacement languages of simple 
graphs the clique size and the minimum degree is bounded. 

124 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
The extension of Parikh's theorem to hyperedge replacement languages was 
first published in [42]. Extensions of Parikh's theorem are also discussed in 
Section 5.7.3 of Chapter 5. 
2.5 
Generative power 
In this section, we discuss the generative power of hyperedge replacement gram- 
mars, dependent on their order. By definition, X R C o  5 
X R C 1  5 
X R C z  $ . . . 
since there cannot occur any hypergraph of type k in a language L E XRCk,, 
for k > k'. In the following the generative power of graph and of string-graph 
generating hyperedge replacement grammars is studied. 
2.5.1 
Graph-generating hyperedge replacement grammars 
We first show that the generative power of hyperedge replacement grammars 
depends on their order, that is, on the maximum number of tentacles involved 
in the replacement of hyperedges, even if only graph-generating grammars are 
considered. For example the set of all (partial) k-trees can easily be shown to 
be in ?iRCk. Using the pumping lemma it turns out that this language is not 
in X R l k - 1 .  In other words, the family (XRCk)kEm forms an infinite hierarchy 
of classes of hypergraph languages, that remains proper if restricted to graph 
languages because k-trees are graphs. 
Example 2.4 (k-tree and partial k-tree) 
As usual, let us call two nodes of a graph adjacent if they are connected by 
an edge. A k-clique of a graph is a subset of k pairwise adjacent nodes of this 
graph. For k 2 1, the set kTREE of all k-trees (see Rose [Sl]) is recursively 
defined as follows: 
Every complete graph with k nodes is a k-tree on k-nodes. 
Given a k-tree H on n nodes and a k-clique G C H ,  a k-tree on n + 1 
nodes is obtained when a new (n + 1)-th node is made adjacent to each 
node of G. 
A partial k-tree is an undirected graph that is obtained from a k-tree by 
removing an arbitrary number of edges. The set of all partial k-trees is denoted 
by kTREEP. For arbitrary, but fixed positive k ,  one can easily find a hyperedge 
replacement grammar H R G ~ T R E E  
of order k generating the set of all k-trees. 
The grammar simulates the recursive construction of a k-tree: There is one 
production that produces a new node new and k + 1 hyperedges indicating the 
old k-clique and the k newly created k-cliques. The second production allows 

2.5. GENERATIVE POWER 
125 
Figure 2.15: Productions to generate 3-trees 
to replace a hyperedge by a k-clique. For k = 3 this yields productions as 
shown in Figure 2.15. Thus, for k 2 1, the set kTREE can be generated by a 
grammar of order k. Suppose kTREE is a language of order k - 1. Then, except 
perhaps a finite number, all elements in kTREE are of connectivity 5 k - 1 
due to the pumping lemma. On the other hand, each k-tree with at least k + 1 
nodes is of connectivity k, a contradiction. 
Furthermore, for k 2 2 ,  the addition of a production removing an ordinary edge 
yields a hyperedge replacement grammar H R G k T R E E P  of order k generating 
the set of all partial k-trees. Hence, by the same arguments as above, for k 2 2 
the set pkTREE of all partial k-trees can be generated by a grammar of order 
0 
k ,  but not by a grammar of order k - 1. 
Let CGRAPH be the class of all graph languages. As an immediate consequence 
of Example 2.4, we get the following result, saying that the classes GCk = 
X R L k  n CGRAPH (k E IN) of hyperedge replacement graph languages of order 
k form a proper hierarchy. 
Theorem 2.5.1 (hierarchy theorem 1) 
GLk 5 
GLk+l for all k E IN. 
0 
2.5.2 String-generating hyperedge replacement grammars 
Let us now turn to the classes of string-graph languages generated by hyperedge 
replacement grammars of order k. We denote by S C k  the set of all hyperedge 
replacement languages of order k which solely consist of string graphs. Com- 
pared with the situation encountered above, these classes turn out to behave 

126 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
slightly different. We show that the family (S&I,)I,>~ 
forms an infinite hierar- 
chy that starts with the class of context-free string-languages (represented as 
string-graph languages), but S&I,+l = S&I, for all k E IN. 
It is quite obvious that, for a given string language L, L' is in S& if and only 
if L is context-free. If L is context-free, just choose the set of all productions 
(A,w') for which (A,w) is a production in the given context-free grammar 
to build an edge replacement grammar yielding Lo. For the other direction, 
using standard techniques one can remove productions that just delete an edge. 
Afterwards, it is not hard to see that every right-hand side of a production 
applied in a derivation yielding a string graph must be a string graph, and the 
productions of this kind obviously induce the needed context-free productions 
for the string case. 
In the following, we present an example of a string-graph language that can be 
generated by a grammar of order 2k, but not by a grammar of smaller order. 
As a consequence, we get a proper language hierarchy. 
Example 2.5 
The string-graph language LI, = {(u;" . ' . a&.)' 
1 n E IN) can be generated by 
the hyperedge replacement grammar of order 2k, for every k 2 1. The construc- 
tion is a straightforward generalization of the one presented in Example 2.2. 
Thus, LI, is a string-graph language of order 2k. Making use of the pumping 
lemma, it can be shown that LI, is no string-graph language of order 2k - 1. 
To see this, assume LI, is a language of order 2k - 1. Let FIRST, LINK, and 
LAST be as in the pumping lemma, for some sufficiently large member of 
Lk. Then LINK has type less than 2k and is substantial. The latter implies 
E L I N K G  # 0 because lV~l = l E ~ l  + 1 for all H E Lk. 
Since FIRST @ LINK @ LAST is a string graph the connected components 
of LINKe must be paths whose first and last nodes are in [ e Z t L I N K ]  U 
[ a t t ~ l ~ ~ ( e ) ] ,  
where e is the X-handle of LINK. Hence, the number of con- 
nected components of LINKe which contain at least one edge is at most k - 1. 
Moreover, none of these connected components can contain edges with differ- 
ent labels, since otherwise pumping obviously yields graphs not in L k .  But 
then LINKe lacks at least one of the labels, so FIRST @ LINK C3 LAST E L 
0 
implies FIRST @ LAST # L because EL INK^ # 0. 
A similar reasoning as in the previous example shows that the string-graph 
language W k  = {(wk)* 1 w E T+) is of the same type. It can be generated by 
a hyperedge replacement grammar of order 2k but not by any one of order 
2k - 1. The example proves the second hierarchy theorem. 

2.5. GENERATIVE POWER 
127 
Theorem 2.5.2 (hierarchy theorem 2) 
For all k E IN, sc2k 5 
SCa(k+l). 
0 
The obvious question is, of course, whether one can also prove sck 5 SCk+l. 
More general, which string-graph languages are generated by hyperedge re- 
placement grammars of order k? In the following, we want to give a charac- 
terization by Engelfriet and Heyker I191 of these languages by means of deter- 
ministic tree-walking transducers, a class of finite automata operating on trees 
that was introduced by Aho and Ullman. These transducers act on regular sets 
of terms (that we may also consider as sets of ordered trees over some ranked 
alphabet). A regular set of terms is generated by a regular tree grammar (see 
[62]) R = (C, r, Q, yo), where C is a ranked alphabet, I’ is a set of nonterminals 
with yo E r (the start symbol), and 9 is a finite set of productions of the form 
y + f(y1,. . . , yn), for y, 
71 , .. . , yn E r and f E C of rank n. The language 
L(R) of terms generated by R is defined in the obvious way. It contains all 
terms over C that can be derived from 70 by considering the productions as 
term rewrite rules. The set occ(t) of occurrences of a term t over C is defined as 
usual: If t = f ( t 1 , .  . . , tn) then occ(t) = {A} U {io 11 5 i 5 n and o E occ(ti)}. 
We denote by o(t) the symbol at occurrence o E occ(t) and by t / o  the subterm 
o f t  whose root is the occurrence o in t. The parent occurrence of oi (i E IN) is 
o and the parent occurrence of A is 1. 
Definition 2.5.3 (deterministic tree walking transducer) 
A 
deterministic tree walking 
transducer 
(dtwt) is a tuple M 
= 
(Q, R,A,h,qo,F), where Q is a finite set of states with qo E Q (the ini- 
tial state) and F C Q (the set of final states), R = (C, r, 9, 
yoyo) a regular tree 
grammar, A the output alphabet, and 6: Q x C + Q x D x 4’ the transition 
function with D = {stay, up} U { down(i) I i 2 1). 
A configuration of M is a tuple (q,t,o,w) with q E Q, t E L(R), o E occ(t) U 
{I}, 
and w E A*. A step of M turns (q,t,o,w) into (q’, t,o’,ww’) if we have 
S(q, o(t)) = (q’, d, w’) 
and either 
d = up and 0’ is the parent occurrence of 0, or 
d = stay and 0’ = 0, or 
0 o(t) is of rank 2 i, d = down(i), and 0’ = oi. 
If M ,  starting with configuration ( 4 0 ,  t, A, A), finally reaches a configuration 
(q, t, 1, 
w) with q E F then the computation is successful and yields the output 
w. L ( M )  denotes the language of all outputs of M ,  and D,7W7+ denotes the 
class of all dtwt’s M with X 6 L ( M ) .  

128 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
A property of dtwt's that will turn out to be related to the order of hyperedge 
replacement grammars is the so-called crossing number. Consider a successful 
run of M on t. Every move from an occurrence o to an occurrence 0' or from 0' 
to 0, where 0' is the parent occurrence of 0, is a crossing of the edge between 
o and 0'. If k E IN is such that for no successful run on any input tree, an edge 
is crossed more than 2k times then M is said to be k-crossing. Note that every 
dtwt is k-crossing for some k E IN, 
for if a computation crosses an edge more 
than IQI times, a node is visited twice with the same state, so the computation 
cannot end. Let us denote by DTW7-t the set of all k-crossing M E D'TWT'. 
Then, the following can be shown. 
Lemma 2.5.4 
For all k E IN, S,&+1 C L ( D T W 7 t ) .  
Pro0 f 
We roughly sketch the basic idea underlying the construction. One first proves 
that a given hyperedge replacement grammar HRG = ( N ,  T ,  P, S )  generating 
a string-graph language can be modified (without changing the order), such 
that for every A E N there is some O U ~ A  E {O,l}typ"(A) such that for all 
H E LA(HRG) the out-degree of extH(z) is O U t A ( z ) ,  for i = 1,. . . , type(A). 
Furthermore, one can ensure by a straightforward construction that for every 
right-hand side R in HRG and all distinct e,e' E ERN 
we have labR(e) # 
labR(e'). Then one can construct a dtwt M = (Q, R, T ,  6, qo, F )  E DTWT; 
with L ( M )  = L(HRG), as follows. 
R is designed so that, roughly speaking, L ( R )  is the set of derivation trees of 
HRG. The nonterminals of R are those of HRG, the start symbol is S ,  and the 
alphabet is P, where every (A, H )  E P has rank IEE I. For every production 
p = (A, H )  E P, choose an arbitrary (but fixed) order el,. . . ,en on E;, 
and let R contain the production A - + p ( l a b ~ ( e l ) ,  
. . . , ZabH(e,)). Now, M is 
constructed to walk on the trees t E L(R). Every node of a right-hand side of 
a production in P is a state of M .  If M is at occurrence o of t E L(R) and 
o(t) = (A, H ) ,  then the current state is a node u of H .  M works by searching 
for the occurrence in t generating the terminal edge e whose first attached node 
is the image of u in the generated string graph. If there is some e E Eg with 
a t t H ( e , l )  = u, the occurrence has been found. M follows e by changing its 
state to attH(e, a), outputs labH(e), and stays at the same occurrence of t. If 
there is no such edge, but there is ei E EE and j E ( 1 , .  . . , type(ZabH(ei))} with 
attH(ei,j) = u and outlabH(e,)(j) 
= 1, then M moves to the i-th subtree by a 
down(i)-move and proceeds in state e x t p  ( j )  (where H' is the right-hand side 
of the new occurrence). If neither one of these two possibilities holds, the edge 
sought is not generated within the current subtree, so u must be an external 

2.5. GENERATIVE POWER 
129 
node eztH(i) of H (since a string graph is generated). Then M performs an 
up-move and-if 
H' is the right-hand side of the occurrence reached thereby- 
assumes state 
( e ,  i), where e is the (unique) A-labelled hyperedge of H'. 
In order to implement the down- and up-moves correctly we have to use some 
auxiliary states that remember i and (A, i), respectively, since we do not know 
H' in advance. Since M enters and leaves the occurrences of an input tree 
in states which are external nodes of the right-hand sides, and none of these 
external nodes is used twice it is not hard to see that M is Ic-crossing. 
0 
Lemma 2.5.5 
For all IC E W, L ( v T w T ~ )  
2 S&k. 
Pro0 f 
The construction is based on the following ideas. First, one shows that it suffices 
to consider transducers M without stay-moves that produce exactly one output 
symbol in each step. (The latter is due to the fact that for L; E sck the image 
Lz of L1 under a string homomorphism satisfies L; E sck, provided 
# L2.) 
Now, if M satisfies these requirements and is &crossing, every subtree t l o  of 
an input tree t is visited at most lc times, where a visit to t l o  is considered 
to start at occurrence o at the time it is entered from its parent occurrence 
0' and ends at 0' at the time o' is reached the next time. During each visit, 
a (nonempty) substring of the output string is produced. The visit-and 
thus 
the string produced -- 
is composed of the visits to the immediate subtrees, 
which are connected by the steps where M is at occurrence 0, leaving it down- 
or upwards. 
To exploit these observations, one designs a hyperedge replacement gram- 
mar HRG whose derivation trees are more or less the trees in L(R), such 
that the result of a derivation tree corresponding to t / o  is the disjoint 
union of the 1 5 k substrings generated by the 1 visits of M to tlo. The 
21 end nodes of the strings are the external nodes, and the substrings re- 
sulting from the different visits are generated in parallel. Consistency can 
be ensured by guessing (using the nonterminal labels) the states M is in 
when the i-th visit begins and ends, respectively. The productions of HRG 
corresponding to a rule 70 -+ f(n,. 
. . ,-yn) 
of R are of the form (Xo, H ) ,  
where H has nonterminal hyperedges e l , .  . . , en labelled with X I  , . . . , X,. 
Every label Xi is of the form (ri, 
begini(l)endi(l) ... begini(li)endi(li)), where 
li 5 Ic and begini(j), e n d i ( j )  are the guessed states for the start and the 
end of the i-th visit to the tree generated by yi. The type of Xi is 21i 
and VH = Cr=n{begini(l), e n d i ( l ) ,  . . . , begini(li), endi(li)}, where we define 
attH(ei) = begini(l)endi(l) ... begini(li)endi(li) for i = 1,. . . ,n. In addition, 
H contains edges labelled with the output symbols M generates when leaving 

130 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
begino(j) and e n d ; ( j )  -$ 
begini(j) + 
Figure 2.16: A Right-hand side in the grammar constructed to simulate a dtwt. The tentacles 
of hyperedges are to be numbered from left to right. 
the node f ,  that is, the root of the subtree generated by 70, down- or upwards. 
As an example, see the hypergraph in Figure 2.16. For this to be a consis- 
tent right-hand side obtained from 70 t f(n, 
7 2 )  we must have, for instance, 
0 
Lemmas 2.5.4 and 2.5.5 have a number of interesting consequences, of which 
we mention only two. First of all, it follows that, indeed, the string generating 
power of hyperedge replacement grammars increases only every second step. 
h(q1, f) = (q37 downP),b). 
I3 
As mentioned above, every dtwt is k-crossing for some k E IN, so we get the 
following characterization of the class of all hyperedge replacement string-graph 
languages. 
Theorem 2.5.7 
sc = L ( D 7 W 7 + ) .  
0 
2.5.3 
Most of the results concerning the generative power are formulated in [26] and 
proved in [42]. 
Further results and bibliographic notes 

2.5. GENERATIVE POWER 
131 
The notion of tree-walking transducers was invented by Aho and Ullman ([63]; 
see also [64]). Lemmas 2.5.4 and 2.5.5 and their consequences are taken from 
a paper by Engelfriet and Heyker [19], where the results are proved in de- 
tail. (Figure 2.16 is also from [19], although slightly modified.) Engelfriet and 
Heyker mention a number of additional consequences, including results for lin- 
ear hyperedge replacement grammars that generate string-graph languages. 
Roughly speaking, one obtains the same results as presented here, by looking 
at two-way deterministic generalized sequential machines instead of dtwt’s. 
(The former can be seen as dtwt’s whose second component is a linear regu- 
lar tree grammar.) From results known for dtwt’s Engelfriet and Heyker also 
obtain the corollary that the class SL, its linear counterpart, and SC2k are 
substitution-closed full AFLs (see [65]). 
Asking similar questions for term-generating rather than string-generating 
hyperedge replacement grammars Engelfriet and Heyker show in [20] that hy- 
peredge replacement grammars have the same term-generating power as at- 
tribute grammars. In this context one should also mention the work by Engel- 
friet and Vogler [66]. They define the so-called tree-to-graph-to-tree transduc- 
ers, a sort of tree transducers making use of hyperedge replacement in order to 
construct the computed output trees. The main result of [66] states that these 
transducers-in 
the deterministic total case-have the same power as macro 
tree transducers (for the later see [67]). 
Quite a lot is also known about the generative power of hyperedge replace- 
ment grammars compared with other graph generating types of grammars. A 
comparison of hyperedge replacement grammars a.nd boundary edNCE graph 
grammars is established by Engelfriet and Rozenberg in [HI. It is shown that 
hyperedge replacement grammars and boundary graph grammars of bounded 
nonterminal degree have the same power, both for generating sets of graphs 
and for generating sets of hypergraphs. Arbitrary boundary graph grammars 
have more generating power than hyperedge replacement grammars, but they 
have the same hypergraph generating power (subject to a representation of 
hypergraphs as bipartite graphs). 
In [68], Engelfriet and Heyker compare the power of hyperedge replacement 
grammars and separated handle hypergraph grammars (or S-HH grammars) 
to generate hypergraph languages of bounded degree. It is shown that every S- 
HH language of bounded degree can be generated by a (separated) hyperedge 
replacement grammar. This implies that those two types of grammars generate 
the same class of graph languages of bounded degree. In the general case, 
incomparable classes of hypergraph languages are generated. 

132 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
In [22], Engelfriet, Heyker, and Leih show that hyperedge replacement graph 
languages of bounded degree are generated by apex graph grammars. 
In [ 161, Courcelle separates vertex replacement from hyperedge replacement: 
A set of graphs generated by vertex replacement is a hyperedge replacement 
language if and only if its graphs do not contain arbitrarily large complete 
bipartite graphs Kn,n as subgraphs if and only if its graphs have a number 
of edges that is linearly bounded in terms of the number of vertices. These 
properties can be shown to be decidable. 
In [17], Courcelle and Engelfriet give a grammar independent characteriza- 
tion of hyperedge replacement languages (see also Section 1.4.2 of Chapter 1). 
These are exactly the images of the recognizable sets of finite trees under cer- 
tain graph transformations definable in monadic second-order logic. Several 
results follow saying that sets of graphs defined by vertex-replacement satisfy- 
ing additional conditions (like bounded degree, planarity, bounded tree-width, 
or closure under subgraphs or minors) are hyperedge replacement languages. 
2.6 
Decision problems 
A hyperedge replacement grammar specifies a hypergraph language. Unfor- 
tunately, the derivation process never produces more than a finite subset of 
the language explicitly (and even this may consume much time before sig- 
nificant members of the language occur). Hence, one may wonder what the 
hyperedge replacement grammar can tell about the generated language. As a 
matter of fact, the context-freeness lemma leads the way. Given a hyperedge 
replacement grammar and an arbitrary terminal hypergraph H with derivation 
A' * 
R ==+* H ,  we get a decomposition of H into smaller components which 
are derivable from the handles of the hyperedges in R. This can be employed 
if one wants to reason about certain graph-theoretic properties or numerical 
functions on (hyper)graphs. The first leads to the notion of compatible proper- 
ties, the second to compatible functions. 
2.6.1 
Compatible properties 
If a graph-theoretic property can be tested for each H generated by a hyper- 
edge replacement grammar by testing the property (or related properties) for 
the components and composing the results to a result for H ,  it is called com- 
patible. It can be shown that compatibility implies decidability of the following 
questions: 

2.6. DECISION PROBLEMS 
133 
Is there a hypergraph in the generated language having the property? 
0 Do all hypergraphs in the generated language (except perhaps for a finite 
number) have the property? 
0 Are there only a finite number of hypergraphs in the generated language 
having the property? 
These decision problems are reduced to the emptiness problem and to the 
finiteness problem by a filter theorem that shows that the intersection of a 
hyperedge replacement language with the set of hypergraphs that satisfy a 
compatible property is a hyperedge replacement language, too. 
As an illustrating example, let us consider the property that two external nodes 
of a hypergraph are connected by a path. Let H E '?lc and v,v' E VH. A v d -  
path (in H )  is an alternating sequence uoelul .-.e,v, with VO,. . . ,u, E VH, 
el ,... ,en E EH, u = V O ,  and v' = u, such that, for i = 1, ... ,n, I J - ~  and u, 
are attachment nodes of e,. If there is such a path, H is called vd-connected. 
Let HRG = ( N ,  T ,  P, S )  E %RG, 
and consider A' j 
R ==+* H with (A, R) E 
P and H E %T as well as ZabR(e)' ==+* H ( e )  for e E ERN given by the context- 
freeness lemma. Hence we can assume H = R[repZ]. 
If H is vd-connected, there is a path p = uoe1u1 ... e,v, 
connecting IJ and 
v'. Then either e, E Eg or e, E ETepqe) for some e E ERN 
(i = 1,. . . ,n). 
Replace now, for all e E ERN, each longest subpath uz(e)e,(e)+l 
.,.e,(,)t~,(~) of p 
in repl(e) where i(e) < j ( e )  with u,(,) eu,(,). This yields a vd-path in R such 
that repl(e) is v,(,)v,(,)-connected for each e E ERN on this path. Conversely, 
if one has such paths in R and in the components repl(e), one gets obviously 
a vd-path in H .  
This means that the vd-connectedness of H can be checked by looking for a 
vd-path in R and checking corresponding connectedness properties for some 
components of H .  If u and u' are external nodes of HI one obtains a terminat- 
ing recursive procedure because the components have shorter derivations than 
H .  Moreover, connectedness needs to be considered for only a finite number 
of pairs of natural numbers because the external nodes of a hypergraph are 
ordered and their number is bounded by the order of the given grammar if the 
involved hypergraph is derived from a handle. 
Definition 2.6.1 (compatible predicate) 
Let C C X R G  and let I be a (possibly infinite) index set, such that there is 
an effective procedure constructing for every HRG = (N,T,P,S) E C a fi- 
nite subset IHRG of I ,  together with some distinguished index i(type(S)) E 

134 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
IHRG. Let PROP' be a decidable predicate defined on triples (R, ass,i), with 
R E Xc, ass: ERN + I a mapping, and i E I ,  and let PROP(H,i) = 
PROP'(H, emptyla) for H E X T  and i E I .  
Then PROP is ( C ,  PROP')-compatible if for every HRG = ( N ,  T ,  P, S )  E C ,  
all derivations A' ==+ R J* 
H with H E '?IT, and all i E IHRG we have that 
PROP(H,i) holds if and only if there is a mapping ass: ERN -+ IHRG such 
that PROP'(R, ass,i) holds and PROP(H(e), ass(e)) holds for all e E ERN. 
The unary predicate PROP0 that holds on H E X T  with type(H) = k if and 
only if PROP(H, i(k)) holds, is called C-compatible. 
It is not difficult to see that compatible predicates are closed under boolean 
operations. In addition to the properties of hyperedge replacement languages 
discussed in Section 2.4, one can now show one more structural property in 
connection with compatible properties: The set of all hypergraphs from a hy- 
peredge replacement language satisfying a compatible property is again a hy- 
peredge replacement language. 
Theorem 2.6.2 (filter theorem) 
Let PROPo be a C-compatible predicate for some C 2 X R G .  For every 
HRG E C there is a hyperedge replacement grammar HRGPROP~ 
such that 
L ( H R G ~ R O P ~ )  
= { H  E L(HRG) I PROPo(H)}. 
Proof 
Let HRG = ( N ,  T ,  P, S )  and let IHRG, PROP', and i ( t y p e ( S ) )  be as in Def- 
inition 2.6.1. Then we construct a hyperedge replacement grammar HRG' = 
(N', T ,  P', S') as follows. 
N' = N x IHRG; 
P' is the set of all pairs ((A,i), 
(R, ass)) such that (A, R) E P, nss(e) E 
IHRG for e E ERN, i E IHRG, and PROP'(R, ass,i) holds, where (R, ass) 
denotes the hypergraph (VR, ER, attR, lab, eztR) with lab(e) = labR(e) if 
labR(e) E T and lab(e) = (hbR(e), ass(e)) if hbR(e) E N ;  
S' = (S, type(S)). 
It remains to show L(HRG') = { H  E L(HRG) I PROP(H, type(S))}, which 
can be done by induction on the length of derivations in HRG and HRG' 
0 
respectively, in a straightforward way. 
The filter theorem can be used to get several decidability results. 

2.6. DECISION PROBLEMS 
135 
Theorem 2.6.3 (decidability of compatible properties) 
Let PROP0 be C-compatible with respect to some class C of hyperedge re- 
placement grammars. Then for all HRG E C, it is decidable whether 
1. PROP0 holds for some H E L(HRG); 
2. PROP0 holds for all H E L(HRG); 
3. PROP0 holds for no H E L(HRG) except perhaps a finite number; 
4. PROP0 holds for all H E L(HRG) except perhaps a finite number. 
Proof 
By the filter theorem, for every hyperedge replacement grammar HRG E C, 
we can effectively construct hyperedge replacement grammars HRGPROP~ 
and 
HRG7p~0po generating the sets 
L ( H R G P R o ~ ~ )  
= { H  E L(HRG) I PROPo(H)} 
and 
L(HRG,PRoP~) = { H  E L(HRG) I -+ROPo(H)}, 
respectively. Now PROP0 holds for some hypergraph H E L(HRG) if and only 
if L ( H R G ~ R O P ~ )  
is not empty. PROP0 holds for a finite number of hypergraphs 
H E L(HRG) if and only if L(HRGPROP~) 
is finite. PROP0 holds for all H E 
L(HRG) if and only if L ( H R G 7 p ~ ~ p o )  
is empty. And PROP0 holds for all H E 
L(HRG) except perhaps a finite number if and only if L ( H R G 7 p ~ 0 p o )  
is finite. 
As a consequence of the pumping lemma, it was noted above that the finiteness 
problem for hyperedge replacement languages is decidable. Furthermore, the 
emptiness problem is decidable using the same proof as in the string case. 
0 
Altogether, these facts yield the claimed results. 
2.6.2 
Compatible functions 
We now turn to the discussion of compatible functions, which generalize com- 
patible predicates. A function on hypergraphs is said to be compatible with the 
derivation process of hyperedge replacement grammars if it can be computed 
in the way a compatible predicate can be tested. We restrict the discussion to 
a certain type of compatible functions that are composed of minima, maxima, 
sums, and products on natural numbers. They induce compatible predicates 
of the form: the function value of a graph exceeds a given fixed integer, or 
the function value does not exceed a fixed integer. Consequently, we get the 
corresponding decidability results for these predicates as a corollary. 

136 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
Given a function on hypergraphs (like the size, the maximum degree, the num- 
ber of components, etc.) and considering the set of values for a hypergraph 
language, one may wonder whether this set is finite or not. The question is 
whether the language is bounded with respect to the given function. It can 
be shown that this boundedness problem is decidable for a class of hyperedge 
replacement grammars if the function is compatible and composed of sums, 
products and maxima of natural numbers. 
In order to discuss this result, it is appropriate to enrich IN by a special value 
0. This additional element is useful because sometimes the functions one would 
like to consider have no sensible integer value for some arguments. For example, 
if we are interested in computing the shortest path between two external nodes 
of a hypergraph we have to take into account that there is perhaps no path at all 
between these nodes. Therefore, let INo = IN+{o} with the following properties 
for every index set I and n,ni E INo for i E I, where I’ = {i E I I ni # o } :  
CiEI 
ni = o and ni,, 
ni = o if and only if nj = o for some j E I ,  
miniGI ni = minicp ni and maxiGI ni = maxiErj ni, and 
Now, the notion of a compatible function is defined as follows. 
Definition 2.6.4 (compatible function) 
1. Let C 
3cRG and let I be a (possibly infinite) index set, such that there 
is an effective procedure which constructs for every HRG = ( N ,  TI PI S )  E 
C a finite subset IHRG of I and a distinguished index i ( t y p e ( S ) )  E IHRG. 
Let VAL be a set of values, f’ be a function on triples (R, 
ass,i) with 
R ~ ’ ? i c , a s s :  
E:xI+ 
V A L , a n d i ~  I,andlet f ( H , i ) =  f ’ ( H , e m p t y , i )  
for H 6 3 c ~  
and i E I .  
Then f is (C, f’)-compatible if for all H R G  = ( N ,  TI PI S )  E C ,  all deriva- 
tions A** 
R** 
H with H E ‘HT, and all i E IHRG, 
f ( H , i )  = 
f’(R,ass,i),whereass: EEXI -+ VALisgivenbyass(e,j) = f ( H ( e ) , j )  
for e E EE and j E IHRG. 
The function fo : ‘HT + VAL given by f o ( H )  = f ( H ,  i ( k ) )  for all H E Zfl~ 
with t y p e ( H )  = k is called C-compatible. 

2.6. DECISION PROBLEMS 
137 
2. A function f : 3 t ~  
x I + No 
is said to be (C, min, max, +, .)-compatible 
if there exists a function f’ such that f is (C, f’)-compatible and for each 
right-hand side R of some production in C and each z E I ,  f’(R,-,i) 
corresponds to an expression formed with variables a s s ( e , j )  ( e  E ERN, 
j E I) and constants from IN by addition, multiplication, minimum, and 
maximum. The function f is (C, max, +, .)-compatible if the operation 
min does not occur. 
The function fo: 3 c ~  + INo given by f o ( H )  = f ( H , z ( k ) )  for all H E 
3 c ~  
with type(H) = k is (C, min, max, +, .)-compatible, or (C, max, +, .)- 
compatible, respectively. 
Remark: 
Let fo: 7 - l ~  -+ No 
be a (C, min, max, +, .)-compatible function, let n E N O ,  
and let w be one of the binary predicates 5, <, =, 2, 
and >. Then it is 
not difficult to see that the predicate PROP(f0,w) given for H E 3 t ~  
by 
PROP(fo,w)(H) u fo(H) w n is C-compatible. This together with the 
decidability results of the previous section yields the solution of some particular 
decision problems. For all H R G  E C it is decidable whether 
0 fo(H) w n holds for some H E L(HRG); 
0 fo(H) w n holds for only a finite number of hypergraphs H E L ( H R G ) .  
0 fo(H) w n holds for all H E L ( H R G ) .  
0 fo(H) w n holds for all H E L ( H R G )  except a finite number. 
0 
As an example, let us have a look at the function that yields the number of 
simple paths of a 2-graph connecting the two external nodes. Given a graph 
G, a path is called simple if each node appears only once. Let PATHG denote 
the set of all simple begincendc-paths of G and let numpath(G) = IPATHGI 
be its cardinality. Using the context-freeness lemma, if A’ ==+ R ==+* G we 
get PATHG = UpEPATHR 
{ repZace(p, path) I path : ERN -+ PATHG(,,}, where 
replace(p, path) denotes the path obtained from p by replacing all edges e E ERN 
on p by the corresponding paths path(e). This obviously yields 
numpath(G) = 
n numpath(G(e)). 
PEPATHR e E E g  on p 
These observations can be reformulated in terms of compatible functions. Let 
C be the class of all edge replacement grammars, I = { n p } ,  V A L  = INo, and 

138 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
f' be the function given by f'(R, ass, np) = xpEPATHR 
neEE; 
on 
ass(e, np). 
Then we have f ( G , n p )  = f'(G, empty,np) = xpEPATHG 
1 = numpath(G) 
and f ( G ,  n p )  = f'(R, ass, np) with ass(e, np) = f ( G ( e ) ,  np) ( e  E ER), so f 
turns out to be ( E R G ,  f')-compatible. Consequently, the function numpath = 
j ( - ,  np) is (&RG, 
max, +, .)-compatible. 
Other compatible functions are the number of nodes, the size, the density 
of a hypergraph, that is, the ratio of the number of edges and the number 
of nodes, the minimum-path length (of paths connecting external nodes), the 
maximum-simple-path length (of paths connecting external nodes), the number 
of simple cycles, the minimum-cycle length, the maximum-simple-cycle length, 
the minimum degree, the maximum degree and the number of components. 
Theorem 2.6.5 (meta-theorem for boundedness problems) 
Let fo be a (C, max, +, .)-compatible function for a class C of hyperedge re- 
placement grammars. Then, for all HRG E C ,  it is decidable whether there is 
a natural number n E IN such that fo(H) 5 n for all H E L(HRG). 
Pro0 f 
Let f, f' be the required functions, so that f is (C, f')-compatible and fo(H) = 
f ( H ,  i ( t y p e ( H ) ) )  for H E 3-11.. Let HRG = ( N ,  T ,  P, S )  E C. Then one can show 
that fo is unbounded on L(HRG) if and only if there are A E N ,  j E IHRG and 
A-handled hypergraphs X and Y with X0,Yo E 311. such that the following 
hold: 
1. A' ==+* H for some H E 'HT. 
2. S' =+* 
Y such that f ( H ,  j )  5 f ( Y  @ H ,  io) = fo(Y 8 H )  for all H E Rfl~ 
with A' ==+* H .  
3. A' ==+* X such that f ( H ,  j )  < f ( X  @ H ,  j )  for all H E 3-11. that satisfy 
A'==+* H .  
To check for such A, j ,  X and Y ,  one has to inspect the finite number of deriva- 
tions that start in handles and are of length up to the number of nonterminals. 
The somewhat tedious technical details are omitted. 
0 
2.6.3 
Results which are closely related to those discussed in this section are surveyed 
in Section 5.7 of Chapter 5 (see also the remarks on inductive predicates and 
inductively computable functions below). The results about compatibility are 
taken from [27,30] by Habel, Kreowski, and Vogler. It must be mentioned, 
however, that a finite index set was used in these papers. For the case of 
Further results and bibliographic notes 

2.6. DECISION PROBLEMS 
139 
compatible predicates an infinite index set was first used by Habel, Kreowski, 
and Lautemann in [34]. 
The filter theorem is published in [28,42]. A corresponding result can be found 
in [15]. The statements (1) and (2) of the decidability result are published 
in [27]. In that paper, a direct proof is given which is based on the idea of 
constructing the set of handles from which a hypergraph with the desired 
property can be derived and checking whether the start handle belongs to 
the constructed set. The statements (3) and (4) of the decidability result are 
presented in [28,42]. In [31] Lautemann shows how these and several related 
results in connection with tree decompositions and bounded tree-width can 
by systematized by the use of finite tree automata and well-known character- 
izations of recognizability. Some of the methods for finite tree automata are 
carried over to deal with certain tree automata with infinite state sets. In this 
way it is shown that graph properties defined by formulae of monadic second 
order logic with arithmetic can be decided efficiently for graphs of bounded 
tree-width, a result which was first shown (in somewhat more general form) 
by Arnborg, Lagergren, and Seese [69]. 
In [13], Lengauer and Wanke consider efficient ways of analyzing graph lan- 
guages generated by so-called cellular graph grammars. Cellular graph gram- 
mars are in fact hyperedge replacement graph grammars, defined in a slightly 
different way. In particular, they generate the same class of graph languages. A 
characteristic of graph properties called finiteness is defined, and combinator- 
ial algorithms are presented for deciding whether a graph language generated 
by a given cellular graph grammar contains a graph with a given finite graph 
property. Structural parameters are introduced that bound the complexity of 
the decision procedure and special cases for which the decision can be made 
in polynomial time are discussed. The results provide explicit and efficient 
combinatorial algorithms. 
In [15], Courcelle introduces the notion of a recognizable set of graphs. Every 
set of graphs definable in monadic second-order logic is recognizable, but not 
vice versa. It is shown that the monadic second-order theory of hyperedge re- 
placement languages is decidable. The notion of F-inductive predicates studied 
in [15] is closely related to the concept of compatible properties (see also Sec- 
tion 5.7.2 of Chapter 5). 
In [34], Habel, Kreowski, and Lautemann compare compatible, finite, and in- 
ductive graph properties and show that the three notions are essentially equiv- 
alent. Consequently, three lines of investigation in the theory of hyperedge 
replacement-including 
the one discussed h e r e m e r g e  into one. 

140 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
In [70], Wanke and Wiegers investigate the decidability of the bandwidth prob- 
lem on linear hyperedge replacement languages. In particular, they show the 
following. Let ZRGli,, denote the class of all linear hyperedge replacement 
grammars generating graphs. Then it is undecidable whether an instance gram- 
mar HRG E XRGli,, generates a graph G having bandwidth k ,  for any fixed 
integer k 2 3. The result implies that the bandwidth-k property for k 2 3 is 
not ZRGli,-compatible. 
Theorem 2.6.5 is published in [30]. Related work is done in [71] by Cour- 
celle and Mosbah, who investigate monadic second-order evaluations on tree- 
decomposable graphs and come up with a general method to translate these 
evaluations of graph expressions over suitable semirings. Their method allows 
the derivation of polynomial algorithms for a large number of problems on 
families of graphs, and especially on graphs definable by hyperedge replace- 
ment. The notion of inductively computable functions introduced by Courcelle 
and Mosbah ([71], see also Section 5.7.3 of Chapter 5) is a generalization of 
the concept of inductive predicates which corresponds closely to the notion of 
compatible functions. 
Boundedness problems for hyperedge replacement grammars correspond 
closely to boundedness problems for finite tree automata with cost functions 
over a suitable semiring, investigated by Seidl in [72]. Cost functions for tree 
automata are mappings from transitions to polynomials over some semiring or, 
in the so-called k-dimensional case, to k-tuples of polynomials. (The dimen- 
sions correspond to the different indices used in the definition of a compatible 
function.) Four semirings are considered, namely the semiring N over IN with 
addition and multiplication, the semiring A over W U { co} with maximum and 
addition, the semiring T over N U {-co} with minimum and addition, and 
the semiring F over the finite subsets of IN with union and addition. It turns 
out that for the semirings N and A, it is decidable in polynomial time (if the 
dimension k is fixed) whether or not the costs of accepting computations is 
bounded; for F, it is decidable in polynomial time whether or not the cardi- 
nalities of occurring cost sets are bounded. In all three cases, explicit upper 
bounds are derived. Moreover, for the semiring T, the decidability of bound- 
edness is proved, but a polynomial-time algorithm is obtained only in the case 
that the degrees of occurring polymonials are at most 1. 
In [37], Wanke considers another type of decidability problems on hyperedge 
replacement grammars, called integer subgraph problems. The main idea is 
to transform the decidability problem on hyperedge replacement languages 
concerning function values of graph x subgraph pairs to a decidability problem 
over semilinear sets. 

2.7. THE MEMBERSHIP PROBLEM 
141 
Finally, one should mention an approach to generalize the idea of compatible 
functions that was invented by Engelfriet and Drewes [23,73,49,74,75]. The 
approach is based on the observation that the definition of a compatible func- 
tion can be considered as a tree transduction. The input trees are derivation 
trees of the hypergraphs in question and the output trees are expressions us- 
ing maximum, addition, and multiplication (viewed as trees), that denote the 
computed numbers. Both the derivation trees (denoting hypergraphs) and the 
expressions (denoting natural numbers) may be viewed as terms in appropriate 
algebras (over hypergraphs and natural numbers, respectively). Thus, the idea 
is to consider such computations by tree transductions in general. A mapping 
f :  A + B between two algebras A and B is said to be computed by a tree 
transducer if every term denoting an element a of A is transformed into a term 
denoting f(a) in B. 
2.7 The membership problem 
In this section the possibilities for (efficient) algorithmic solutions to the mem- 
bership problem for hyperedge replacement languages are discussed. We con- 
sider membership with respect to a given hyperedge replacement grammar 
HRG, so the membership problem is defined as follows. 
Given: A hyperedge replacement grammar HRG. 
Instance: A hypergraph H .  
Question: Is H in the language generated by HRG? 
Algorithms that solve the membership problem are called membership algo- 
rithms. In many cases, one would also wish to purse hypergraphs with respect 
to a given grammar, that is, to find a derivation tree for a given hypergraph, if 
possible. For technical convenience, we concentrate on the membership problem 
here, but it is easy to see that both the presented algorithms can be extended 
in a straightforward way to yield solutions to the parsing problem as efficiently 
as they solve the membership problem. 
2.7.1 NP-completeness 
It is not hard to see that the membership problem is in N P  for every hyperedge 
replacement grammar HRG, because for every such grammar there is a linear 
function f such that, for every hypergraph H of size n, if H E L(HRG) then 
H has a derivation of length at most f(n). Thus we can simply use nonde- 
terminism to guess an appropriate derivation and test whether the generated 
hypergraph is isomorphic to H (again using nondeterminism) . 

142 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
Clearly, one would like to have more efficient algorithms than the one just 
sketched, and in particular deterministic ones. It turns out, however, that the 
complexity of the membership problem marks one of the few areas where the 
results for hyperedge replacement grammars differ significantly from what we 
know about context-free Chomsky grammars. Whereas, for the latter we have 
the well-known membership algorithm by Cocke, Kasami, and Younger, which 
runs in cubic time, hyperedge replacement grammars are able to generate NP- 
complete graph languages. Thus, one can expect that there is no generally 
applicable membership algorithm for hyperedge replacement languages. Intu- 
itively, the reason for this is that, in a string, symbols that result from one 
and the same nonterminal form a substring, and there are only O(n2) many 
substrings of a given string of length n. In contrast, from a nonterminal hy- 
peredge a somewhat disconnected subgraph may be generated in a hyperedge 
replacement grammar, so that, in general, there are exponentially many pos- 
sible choices for a subgraph to be generated from a given hyperedge. There 
are simply too many combinations to be tested, which leads to the two NP- 
completeness results presented below. For this, let us call a hyperedge replace- 
ment grammar linear if none of its right-hand sides has more than one nonter- 
minal hyperedge. The node degree of a graph is the maximal number of edges 
attached to a node of this graph, and the node degree of a graph languages is 
the maximum node degree of graphs in that language. 
Theorem 2.7.1 (NP-completeness 1) 
There is a linear edge replacement grammar that generates an NP-complete 
graph language of degree 2. 
Proof 
We reduce the NP-complete Hamiltoniun path problem (see Garey, Johnson 
[76], problem GT39, p. 199) to the membership problem for a particular 
edge replacement language generated by a linear grammar. In fact, there is 
a slightly easier way to prove Theorem 2.7.1 using the NP-complete problem 
3-PARTITION (see [77]). However, we are going to use a modified version 
of the proof in order to obtain another theorem below. As we do not know 
how this can be done using 3-PARTITION the Hamiltonian path problem is 
employed here. 
Let us first define the Hamiltonian path problem. We use a slightly more general 
version on undirected hypergraphs. An undirected, unlabelled hypergraph is a 
triple h = ( v h ,  E h ,  Utth), where v h  and E h  are the finite sets of vertices and 
hyperedges, respectively, and Utth is a mapping assigning to every hyperedge 
e E E h  the set utth(e) C v h  of attached nodes. Now, the Hamiltonian path 
problem can be formulated as follows. 

2.7. THE MEMBERSHIP PROBLEM 
143 
Instance: An undirected, unlabelled hypergraph h. 
Qvestzon: Is there a Hamiltonian path in h, that is, is there an alternating 
sequence voelv1 . . . envn of pairwise distinct nodes and hyperedges of h such 
that Vh = { V O ,  . . . , v,} and v,-l,vz E atth(e,) for all i, 1 5 i < n? 
Clearly, the generalization to hypergraphs does not affect the NP-hardness of 
the problem. Let us define S to be the set of all finite sets S = ( ~ 1 , .  
. . , s,} 
such that the s, (1 5 i 5 n) are strings of equal length of the form u,-u,, where 
u, E {O,l}*. We say that u,-u, is word adjacent to u3-u3 if ~
~
(
1
)
 
= ~
~
(
1
)
 
for 
some 1 ,  1 5 15 Iu,I. 
Every S E S defines an undirected, unlabelled hypergraph h(S). If S is as 
above, with Is,I = 2m + 1 for i = 1,. . . , n, the set of nodes of h(S) is S and 
the set of hyperedges is {l,.. 
. ,m}. Node s, is in the set of attachments of 
hyperedge j if u,(j) 
= 1. By definition, two nodes are adjacent in h(S) if the 
corresponding strings are word adjacent, so h(S) has a Hamiltonian path if and 
only if there is a sequence il, . . . , z n  with {il, . . . ,in} = { 1,. . . , n} such that, 
for i = 1,. . . , n - 1, s, and s,+1 are word adjacent. Clearly, every undirected, 
unlabelled hypergraph h is represented by some S E S. Furthermore, given 
any sensible representation of h we can compute some Sh E S with h = h(Sh) 
in polynomial time. 
We are going to construct a linear edge replacement grammar such that each 
of the generated graphs is a string graph, except that some of the edges are 
missing. Thus, such a graph represents a multiset of strings. The individual 
strings of the multisets generated have the form w-w’, where w, w’ E {0,1}*. 
The multisets themselves will be of the form 
{ ~ 0 - ~ 1 1 1 ~ 1 2 ,  
4 1  1w;,-w21 Iw22, 
Wbl1W&-W311w32, 
willW;2-w1} 
where each wil is generated along with the corresponding w : ~ ,  and each wi2 is 
generated together with the corresponding wi2. This is used to ensure that wij 
and w:? are of equal length, so that the digit 1 between wzl and wi2 appears 
at the same position as the one between wL1 and wi2. Thus, if such a multiset 
S is in S it defines a hypergraph with a Hamiltonian path passing the nodes 
represented by the strings above one after the other. 
Consider the grammar ERG = ({S, A, B, C, D } ,  {-, 0, l}, P, S), where all ter- 
minals and nonterminals are of type 2, except for S, which is of type 0, and 
where P consists of the productions given in Figure 2.17. (In Figure 2.17, a 

144 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
s ::= 
A ::= 
B ::= 
D ::= 
Figure 2.17: Productions of ERG in the proof of Theorem 2.7.1. 
right-hand side some of whose edges are labelled with “ O / l ”  stands for all 
right-hand sides in which the respective edges are labelled with 0 or 1.) If we 
interpret the graphs in L(ERG) as multisets of strings in the obvious way, this 
yields a set S(ERG) whose elements are these multisets. It is not too hard to 
see that, as explained above, all these multisets are of the form 
The wil and wil are generated using the nonterminal B, 
and the wi2 and wi2 
result from a nonterminal C. As a consequence, wij and wij are indeed of equal 
length, so that the 1 between wil and wi2 appears in the same position as the 
one between w:, and w12. Therefore, one can show that the following holds: 
S(ERG) n S is the set of all {sl,. . . , sn} E S for which there is 
an ordering il, . . . ,in of 1,. . . , n such that sij is word adjacent to 
sij+l for all i, 15 i < n. 

2.7. THE MEMBERSHIP PROBLEM 
145 
Clearly, for all S E S some graph H ( S )  .representing S in the same way as 
above can be constructed in polynomial time. Now, H ( S )  E L(ERG) if and 
only if h(S) has a Hamiltonian path. We have thus reduced the Hamiltonian 
0 
path problem to the membership problem for L(ERG), as required. 
If we drop the requirement of bounded degree in Theorem 2.7.1 we can even 
generate an NP-complete language of connected graphs, as one can see by an 
easy modification of the grammar used. 
Theorem 2.7.2 (NP-completeness 2) 
There is an edge replacement grammar that generates an NP-complete graph 
language of connected graphs. 
Proof 
We construct an edge replacement grammar ERG' that generates for every 
graph H E L(ERG), where ERG is the edge replacement grammar in the proof 
of Theorem 2.7.1, a graph obtained from H as follows. First, a new node vo is 
added. Then, every edge e labelled - is removed and its two attached nodes are 
identified, yielding a new node v,. Finally, for each v, a new unlabelled edge 
with attachment UOV, is added. The correspondence between the graphs in 
L(ERG) and their counterparts in L(ERG') constructed this way is a bijection 
that can be computed in polynomial time. Therefore, it remains to give an 
appropriate grammar ERG'. We may choose for this the grammar ERG' = 
({S, A, B, C, D}, 
(0, l}, P', S), where the types of symbols are as in ERG and 
the productions are the ones given in Figure 2.18. In order to understand how 
the grammar works, the reader should notice that, applying in a first phase 
only the productions with left-hand sides S ,  A, and B yields a hypergraph as 
in Figure 2.19. Now, it is easy to see that the remaining productions yield just 
0 
the type of graphs aimed at. 
2.7.2 Two polynomial algorithms 
In view of Theorems 2.7.1 and 2.7.2 there is not much hope that one can find 
an efficient solution to the membership problem for arbitrary hyperedge re- 
placement grammars (and not even for linear edge replacement grammars), 
since this would require P=NP. It is therefore natural to look for restrictions 
that can be imposed on the languages or grammars to allow for efficient mem- 
bership algorithms. The proofs of Theorem 2.7.1 and 2.7.2 give a hint. It seems 
that, in the first case, the high complexity of the generated language is caused 
by the fact that the graphs are disconnected, whereas in the the second case 
the potentially unbounded degree of nodes seems to be responsible. In fact, the 

146 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
LA 
B ::= 
D ::= 
A ::= 
0 
1 
H 
Figure 2.18: The productions of ERG’ in the proof of Theorem 2.7.2. 
0 , 
Figure 2.19: An intermediate graph generated by the productions in Figure 2.18. 

2.7. THE MEMBERSHIP PROBLEM 
147 
two cases do not differ too much: The unbounded degree in the second case 
is nothing else than a hidden disconnectedness that reappears if a single node 
is deleted. Later on, this observation will lead to the notion of k-separability, 
which is needed to formulate a condition under which the first membership 
algorithm we will discuss runs in polynomial time. As opposed to the string 
case both algorithms we are going to present rely on the fact that the gram- 
mar considered is supposed to be fixed. It is easy to see that the running time 
of these algorithms becomes exponential if the grammar is made part of the 
input. 
In the following, we use the notation H = Ho<el/H1,. . . , en/Hn> to express 
the fact that H = Ho[el/H1,. . . , en/Hn], where VH = VH, U . . . u VH_, 
EH = 
EH, U ... U EH,, , extH = extHo, and hbH(e) = lUbH,(e), attH(e) = attH,(e) 
for all e E EH n EH,, 0 5 i 5 n. In other words, Ho< . . . > is hyperedge re- 
placement on concrete hypergraphs without the possibility to take isomorphic 
copies (and is hence not always defined). The notion of X-candidates is central 
to the first algorithm we are going to present. 
Definition 2.7.3 (X-candidate) 
Let H be hypergraph and let X E VG. A hypergraph H' C H is an X-candidate 
of H if extHt = X and for every internal node u of H' and every hyperedge 
e E EH with u E [ a t t ~ ( e ) ]  
we have e E E H ~ .  
By definition of hyperedge replacement, every hyperedge of a hypergraph 
Ho<el/H1,. . . ,en/Hn> that is attached to an internal node of Hi for some 
i, 1 5 i 5 n, is a hyperedge of Hi. This can be used to prove that, in 
Ho<el/H1,. . . ,en/Hn>, every Hi (1 5 i 5 n) is an attH,(ei)-candidate of 
H for i = 1,. . . , n. This fact restricts the number of sub-hypergraphs to be 
tested recursively in the membership algorithm below. We formulate the al- 
gorithm for growing hyperedge replacement grammars. By Lemma 2.4.3 this 
means no loss of generality. 
Algorithm 2.7.4 
Given: A growing hyperedge replacement grammar HRG = ( N ,  T, P, 5'). 
Input: A hypergraph H over T .  
Output: Derive(,!?, I?), where Derive(A, H) = 
(1) 
(2) 
(3) 
(4) 
(5) 
if A' ==+ R with VR C VH and E; 
such that there are substantial attR(ei)-candidates Hi of H 
(i = 1,. . . , n) with 
EH 
(where {el, . . . , en} = E g )  
1. H = R<el/Hl,. . . ,en/Hn> 
2. for i = 1,. . . , n we have Derive(ZabR(ei), Hi) 
then return true else return false 

148 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
Theorem 2.7.5 
For all hypergraphs H E 3 1 ~  
Algorithm 2.7.4 terminates and yields true if 
H E L(HRG), and false otherwise. 
Pro0 f 
Since HRG is growing all hypergraphs that can be derived from A' are substan- 
tial. Therefore, Algorithm 2.7.4 is nothing else than an algorithmic formulation 
of the context-freeness lemma. Since the hypergraph R chosen in step (1) and 
the attR(e,)-candidates H, of step (2) are substantial we have (H,I < (HI for 
0 
i = 1,. . . ,n, so the algorithm must eventually terminate. 
Since there is only a finite set of productions in HRG there are only polynomi- 
ally many possibilities to consider in step (l), and the equality in step (3) can 
also be tested in polynomial time (note that the test is for equality, not isomor- 
phy). Hence, there is only a single point that causes an exponential running 
time of the algorithm: the number of X-candidates to be tested. Therefore, we 
aim at a condition to be imposed on L(HRG) that implies a polynomial upper 
bound on the number of X-candidates. Let us denote by HI", where H is a 
hypergraph and V C_ VH, the hypergraph (V, E H ,  att, l a b H ,  A), where att(e) is 
the restriction of attH(e) to V, for all e E E. A connected component of H is a 
maximal connected sub-hypergraph of H. (Note that a 0-edge is a connected 
component on its own.) 
Definition 2.7.6 (k-separability) 
For k E IN the k-separability k-sep(H) of a hypergraph H is the maximum 
number of connected components of H ( v ,  where V ranges over all subsets of 
VH of size at most k. For every language L of hypergraphs, Ic-sepL: IN + IN 
is defined by 
k-sepL(n) = max{k-sep(H) I H E L and IHI 5 n}. 
The following theorem says that logarithmic k-separability of L(HRG) (where 
HRG is of order k )  results in a polynomial upper bound on the running time 
of Algorithm 2.7.4. 
Theorem 2.7.7 
Let HRG E 3CRGk be growing. If k-sepL(HRG) E O(1og n) then Algorithm 2.7.4 
can be implemented to run in polynomial time in IHI. 
Let 
E ~ C T  and X E V$ with JXI 5 k. By definition of X-candidates, if 
a node of a connected component G of Hl[x] occurs in an X-candidate H 
Pro0 f 

2.7. THE MEMBERSHIP PROBLEM 
149 
of H ,  then G C H .  Since there are only a logarithmic number of connected 
components in HI[xl this yields a polynomial bound on the number of X- 
candidates in H if H E L(HRG). Since the number of sequences X E Vs with 
1x1 5 k is bounded by IVglk this yields a polynomial bound on the number 
of X-candidates to be considered in the algorithm (that is, if there are more 
X-candidates in the input graph it can be rejected immediately). 
We are now able to make use of the well-known idea underlying the mem- 
bership algorithm for context-free Chomsky grammars by Cocke, Kasami, and 
Younger. In an initial phase, we compute the set of all X-candidates of H ,  
where 1x1 5 k. This can be done in polynomial time since it essentially suffices 
to determine all combinations of connected components of the hypergraphs 
HI", where IVI 5 k. Now, every call to Derive with parameters A and H is 
performed only once and the result is stored in a list which is looked up when 
repeated calls occur. As a consequence, the algorithm runs in polynomial time 
in the number of X-components, which is polynomial in IB1, as required. 0 
The major drawback of Algorithm 2.7.4 is that, even if k-sepL(HRG) is a con- 
stant, the running time is bounded by a polynomial whose degree may vary 
with HRG. In view of step (1) of the algorithm, for instance, the degree de- 
pends on the size of right-hand sides used in the grammar. We now want to 
discuss a membership algorithm for edge replacement grammars that always 
runs in cubic time. It applies to all input graphs that are almost $connected, 
a notion to be defined below. Again, the algorithm exploits the idea by Cocke, 
Kasami, and Younger. 
From now on, let us consider some arbitrary (but fixed) edge replacement 
grammar ( N ,  T, P, S) with type(A) = 2 for all A 6 N U T .  (In particular, every 
graph is assumed to be of type 2 in the following, without mentioning.) 
Definition 2.7.8 (almost k-con.nected hypergraph) 
A hypergraph H is almost k-connected for some k E W if 
0 (VH( 2 k and 
for all hypergraphs H I ,  Hz and every hyperedge e E E H ~ ,  
if we have H = 
Hl[e/Hz] and V H ~  
\ [ a t t H ,  (e)] # 8 # VH, \ [ e x t ~ , ]  
then twe(Hz) 2 k. 
Intuitively, almost k-connectedness means that a graph cannot be decomposed 
into non-trivial parts using hypergraphs of type less than k. The graph H 
shown in Figure 2.20, for example, is almost 2-connected, but H' is not. 
A substantial graph H (of type 2) is a bond if VH = extH, that is, if H consists 
of at least two edges between the external nodes. A substantial string graph is 

150 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
H 
H' 
Figure 2.20: H is almost 2-connected while H' is not. 
said to be a chain. H is called a block if it is almost 3-connected, lV~l > 3, and 
[ a t t ~ ( e ) ]  
# [ e z t ~ ]  
for all e E EH. Notice that bonds, chains, and blocks are 
substantial and that these three classes of graphs are mutually disjoint. The 
smallest bonds and chains are those with two edges. We have the following 
theorem about almost 2-connected graphs, that we state without proof. 
Lemma 2.7.9 
1. Let H = Ho<e/H1> for substantial graphs Ho and H I .  Then H is almost 
2-connected if and only if both Ho and HI are almost 2-connected. 
2. Every substantial 2-connected graph H can be written as Wo<e/Hl>, for 
substantial graphs Ho, H I ,  unless H is a bond or chain with two edges, 
or a block. 
0 
In the following, let us reserve a label T to be used as a special one in some 
constructions, that is, we assume T $ N U T .  For the algorithm we are going 
to explain the following notions are of basic importance. 
Definition 2.7.10 (total and collapsed split tree) 
Let H be a hypergraph over T .  
1. A total split tree of H is a derivation tree for H over Pt, where Pt is 
the set of all productions over { T }  whose right-hand sides are bonds and 
chains with two edges, and blocks. 
2. Let P, be the set of all productions over {T} whose right-hand sides are 
bonds, chains, or blocks. A collapsed split tree of H is a derivation tree for 
H over P, such that no edge in this derivation tree connects two bonds 
or two chains. 
By definition, the result of a (total or collapsed) split tree t is a substantial, 
almost 2-connected graph. Since the left-hand side of productions in a split tree 
is always r we may consider a split tree as a pair ( H ,  brunch) rather than as a 

2.7. THE MEMBERSHIP PROBLEM 
151 
triple (7, H, branch). Using Lemma 2.7.9 it is not hard to see that. every sub- 
stantial, almost 2-connected graph has some total split tree. From a total split 
tree one can obtain a collapsed one as follows: As long as a subtree (H, branch) 
exists with branch(e) = (H’, branch’) for some e E EE, where both H and H’ 
are bonds or both are chains, replace the subtree by (H[e/H’], branch”), where 
Then H[e/H’] is a bond (chain, respectively), so the procedure eventually 
leads to a collapsed split tree. As a consequence, every substantial, almost 
2-connected graph has a total as well as a collapsed split tree, and for every 
(total or collapsed) split tree t the graph result(t) is substantial and almost 
2-connected. 
The algorithm we are going to present makes use of a result by MacLane [78] 
saying that collapsed split trees are unique in a, certain sense. It is easy to 
see that collapsed split trees cannot be really unique. This is because, if H 
and H‘ are graphs with e E E H ,  and we let G and G’ be obtained from them 
by reversing e in H and interchanging the external nodes of H’ we obviously 
obtain H[e/H’] = G[e/G’]. Hence, for split trees we must allow to reverse 
nonterminal edges if at the same time the external nodes of the graphs that 
replace them are interchanged. This is stated more precisely below. 
Definition 2.7.11 (similar split trees) 
Let t = (H,branch) and t‘ = (H’,branch’) be split trees with E$ = 
{el,. . . ,en} and, for i = 1,. . . ,n, branch(ei) = (Hi, branchi). Then t and t‘ 
are similar if there is some I 
{ 1, . . . , n} such that the following hold. 
1. The graph obtained from H by reversing all ei with i E I is isomorphic 
to H‘ via some isomorphism h. 
2. For all i E I ,  (H,’, branch,) and branch(hE(e,)) are similar, where H,’ is 
obtained from H, by reversing extH, if i E I and H,‘ 
= H, otherwise. 
As one can easily show by induction, similarity oft and t‘ implies that resuZt(t) 
and result(t’) are isomorphic. The algorithm we are developing is based on the 
following result by MacLane [78]. 
Fact 2.7.12 (uniqueness of collapsed split trees) 
All collapsed split trees of a substantial, almost 2-connected graph are similar. 
0 

152 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
Using Fact 2.7.12 we want to prove the following. 
Theorem 2.7.13 
Let ERG be an edge replacement grammar. Then there is a cubic algorithm 
that takes as input a graph H and decides whether H is an almost 2-connected 
member of L(ERG). In particular, if all graphs in L(ERG) are almost 2- 
0 
We are now going to develop the means to prove Theorem 2.7.13. Let us first 
assume some edge replacement grammar ERG = ( N ,  T ,  P, S )  as in the theorem 
is given. By Lemma 2.4.3 it may be assumed that ERG is growing. We modify 
ERG as follows. 
connected, the algorithm decides whether H E L(ERG). 
(1) Remove all productions whose right-hand side is not almost 2-connected. 
By Lemma 2.7.9 we are allowed to do so because this modification does 
not affect the set of almost 2-connected graphs in the language generated. 
(2) As long as there is a production (A,R) such that H = R[e/H’] for 
some substantial H and H‘, choose a new nonterminal label A’ for e 
in H and replace (A, R) by the two productions (A, H )  and (A’, H’). 
Obviously, such a modification does not influence the generated language. 
By Lemma 2.7.9 the right-hand sides of the grammar obtained are bonds 
and chains with two edges, and blocks. 
(3) Complete the grammar as follows: For every label A (nonterminal as 
well as terminal ones), add a new label A, and add for all productions 
(A, R) in the grammar obtained in step (2), all productions ( X ,  H ) ,  where 
X E {A,A} and H is obtained from R by reversing some edges while 
changing their label from labR(e) to labR(e), and reversing eztR if X = A. 
Let the edge replacement grammar resulting from steps (1)-(3) be given by 
ERG0 = (NO, To, Po, S). Then it follows by a straightforward induction that 
the set of graphs over T generated by ERGO coincides with the one of the 
grammar obtained by steps (1) and (a), that is, L(ERG0) = L(ERG). For 
every derivation tree t over Po’ (see page 115 for the definition of P,*) let us 
denote by unZabeZ(t) the derivation tree we obtain by replacing all nonterminal 
labels with T .  We have the following lemma. 
Lemma 2.7.14 
Let H E ?ift~~ 
and A E NO. If A’ &Go 
H and t is a collapsed split tree of H ,  
then there is a derivation tree t’ over Po’ with root A such that unZabel(t’) = t. 
Let to be a derivation tree for H in ERGO. As remarked above, by modification 
Pro0 f 

2.7. THE MEMBERSHIP PROBLEM 
153 
(2) unlabel(t0) is a total split tree for every derivation tree to over PO. Hence 
there is some derivation tree t b  over Po* such that unZabeZ(tb) is a collapsed split 
tree. (We can construct tb from to in the same way a collapsed split tree can 
be constructed from a total one; see the paragraph after Definition 2.7.10.) By 
Fact 2.7.12 the given collapsed split tree t and unlabel(tb) are similar. By modi- 
fication (3) this means there is a derivation tree t’ over Po’ with unlabel(t’) = t. 
0 
We are now able to sketch the construction of the cubic algorithm we aimed 
at, thereby proving Theorem 2.7.13. 
Proof of Theorem 2.7.13 
To find out whether an input graph H is in L(ERGo), where ERGO is con- 
structed as above, proceed as follows. First, compute a collapsed split tree t of 
H .  By a result proved by Hopcroft and Tarjan [79] this can be done in linear 
time. By Lemma 2.7.14, if H E L(ERG0) (and, of course, only then) we can 
exchange every 7 in t by an appropriate nonterminal label to obtain a deriva- 
tion tree over Po’ for H whose root is S. To find out whether this is possible, 
for all subtrees t’ o f t  we compute by a bottom-up approach the set poslab(t‘) 
of all A E No such that A’ *F0 
result(t’). This can be done efficiently, as 
follows. Suppose t’ = (R, branch) with branch(e) = t, for e E ERN, and we have 
already computed posZab(t,) for all e E ERN. Then, we have to decide whether 
A’ *go 
R1 for some R1 obtained from R by labelling every edge labelled with 
7- in R with one of the labels in poslab(t,). Since R is either a bond, a chain, 
or a block there are three possible cases to consider. 
1. R is a bond. 
Construct R’ from R by giving a hyperedge e E ER the label { labR(e)} if 
labR(e) E 7’0 and the label poslab(t,) if labR(e) = 7. Let R” be the graph 
obtained from R‘ by reversing all edges e with attR1 (e) = endR1 beginR1, 
while exchanging labR1 (e) with { A  I A E ZabRl (e)}. By the completion 
performed in modification (3) and Theorem 2.4.7 it is not hard to see 
that A E poslab(t’) if and only if $(R”) is in some fixed semilinear set 
associated with A. (To be able to apply Theorem 2.4.7, add productions 
(A,X’), where X & NO and A E X ,  or A E TO and X = {A}. Then we 
have to decide whether A’ ‘>, 
R”.) Due to results by Fischer, Meyer, 
and Rosenberg [80] membership in a semilinear set can be decided in 
linear time. 
2. R is a chain. 
Then, since in a derivation A’ *go 
R1 we cannot use any production 
with a substantial right-hand side which is not a chain, we can use 

154 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
Figure 2.21: A hyperedge replacement grammar with componentwise derivations. 
the well-known algorithm by Cocke, Kasami, and Younger to find out 
poslab(t’). (Note that we do not have to consider all the possible R1 sep- 
arately, because the CKY-algorithm works with sets of nonterminals like 
our poslab(t,) provide.) Since the CKY-algorithm runs in cubic time this 
step takes cubic time in the size of R. 
3. R is a block. 
Here, we only have to test a finite number of possibilities since R must 
be isomorphic to a right-hand side in ERGO, up to the labelling. Hence, 
this case can be handled in constant time. 
Altogether, we need at most a cubic number of steps (in ]HI) in order to find 
0 
posZab(t), and accept H if S E poslab(t). 
2.7.3 
The proof of NP-completeness given in the beginning of this section was found 
by Lange and Welzl [81], who presented it for string grammars with discon- 
necting rather than for edge replacement, as we did here. 
Algorithm 2.7.4 is due to Lautemann [29]. The paper contains a second variant 
of the algorithm that does not rely on logarithmic k-separability. Instead, it 
is required that the considered hyperedge replacement grammar has compo- 
nentwise derivations. Roughly speaking, this means that an X-candidate is 
derivable from A’ 
if and only if each of the connected components this X -  
candidate consists of is derivable from A’. As an example, one may consider 
the grammar HRG = ({S}, {u}, P, S )  (where “u” means “unlabelled”) whose 
productions are the two given in Figure 2.21. L(HRG) is the set of all (rooted, 
directed) trees, and a graph as in Figure 2.22 on the left is derivable from S’ 
if 
and only if each of its components (shown on the right) can be derived from S’. 
Under the condition that the grammar satisfies this requirement, we may look 
at the (linear number of) individual connected components rather than at all 
X-candidates, which yields a polynomial algorithm. As Lautemann remarks in 
Further results and bibliographic notes 

2.8. CONCLUSION 
155 
H 
components of H 
Figure 2.22: A graph generated by HRG and its components 
his paper, more sophisticated notions of componentwise derivations, that still 
lead to polynomial algorithms, may more or less obviously be thought of. 
The cubic membership algorithm was presented by Vogler in [82]. As shown by 
Drewes [33], Theorem 2.7.13 and the results used to prove it can be generalized 
to hyperedge replacement grammars of order k generating almost k-connected 
k-hypergraphs, where a k-hypergraph is a hypergraph all of whose hyperedges 
are of type k .  This yields the case treated here by choosing k = 2. It may be 
interesting to notice that the generalized version of the algorithm is still cubic; 
the exponent does not depend on the order of the grammar. 
As mentioned, the generalization works only for k-hypergraphs. It is therefore 
natural to wonder whether this restriction can be avoided. Is there still a poly- 
nomial algorithm if a grammar of order k generates, for instance, a language 
of almost k-connected graphs? Unfortunately, it is likely that this question has 
to be answered negatively, since it was shown by Drewes [32] that this case 
is again NP-complete for all k > 2. (For k = 2, we have Theorem 2.7.13.) 
Intuitively, this is caused by the fact that, if we replace every hyperedge in a 
k-connected k-hypergraph by, say, a clique on the k attached nodes, we retain 
k-connectedness, but loose the information which of the resulting edges belong 
together, so that a unique reconstruction of the hypergraph is not possible. 
2.8 
Conclusion 
In this survey, we have outlined the theory of hyperedge replacement as a gram- 
matical device for the generation of hypergraph, graph, and string languages 
with an emphasis on the sequential mode of rewriting. Hyperedge replacement 
(without application conditions) has a context-free nature which is the key for 
an attractive mathematical theory including structural properties and decid- 
ability results. 
Although several interesting (hyper)graph languages occurring in computer 

156 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
science and graph theory can be generated by hyperedge replacement gram- 
mars, their generative power is bound to be restricted. As we saw in Section 2.4 
there is, for instance, no way to generate a language of unbounded connectiv- 
ity. As mentioned in the bibliographic notes of Section 2.3, extensions can be 
found in the literature, which make it possible to overcome one or the other 
deficiency. However, one cannot expect to get additional power for free. Nor- 
mally, extensions lack some of the useful properties of hyperedge replacement, 
or their rewriting mechanisms are more complicated and therefore harder to 
reason about. In many cases hyperedge replacement seems to be a good com- 
promise between the wish to have a nicely developed mathematical theory and 
the demand for reasonable generative power. 
Acknowledgement 
We thank Grzegorz Rozenberg and the anonymous referee for helpful comments 
on a draft of this chapter. The work presented here has been supported by 
ESPRIT Basic Research Working Group 7183 (COMPUGRAPH 11). 
References 
1. Jerome Feder. Plex languages. Information Sciences, 3:225-241, 1971. 
2. Theodosios Pavlidis. Linear and context-free graph grammars. Journal 
of the ACM, 19(1):11-23, 1972. 
3. Pierluigi Della Vigna and Carlo Ghezzi. Context-free graph grammars. 
Information and Control, 37:207-233, 1978. 
4. Dirk Janssens and Grzegorz Rozenberg. Restrictions, extensions and vari- 
ations of NLC grammars. Information Sciences, 20:217-244, 1980. 
5. A.O. Slisenko. Context-free graph grammars as a tool for describing poly- 
nomial-time subclasses of hard problems. Information Processing Letters, 
6. Michel Bauderon and Bruno Courcelle. Graph expressions and graph 
rewriting. Mathematical Systems Theory, 20:83-127, 1987. 
7. Annegret Habel and Hans-Jorg Kreowski. Characteristics of graph lan- 
guages generated by edge replacement. Theoretical Computer Science, 
8. Annegret Habel and Hans-Jorg Kreowski. May we introduce to you: Hy- 
peredge replacement. In H. Ehrig, M. Nagl, G. Rozenberg, and A. Rosen- 
feld, editors, Graph-Grammars and Their Application to Computer Sci- 
ence, volume 291 of Lecture Notes in Computer Science, pages 15-26, 
1987. 
14:52-56, 1982. 
51:81-115, 1987. 

REFERENCES 
157 
9. Ugo Montanari and Francesca Rossi. An efficient algorithm for the so- 
lution of hierarchical networks of constraints. In H. Ehrig, M. Nagl, 
G. Rozenberg, and A. Rosenfeld, editors, Graph-Grammars and Their 
Application to Computer Science, volume 291 of Lecture Notes in Com- 
puter Science, pages 440-457, 1987. 
10. Clemens Lautemann. Efficient algorithms on context-free graph lan- 
guages. In T. Lepisto and A. Salomaa, editors, Automata, Languages 
and Programming, volume 317 of Lecture Notes in Computer Science, 
pages 362-378, 1988. 
11. Joost Engelfriet. Context-free NCE graph grammars. In J. Csirik, 
J. Demetrovics, and F. Gkcseg, editors, Fundamentals of Computation 
Theory, volume 380 of Lecture Notes in Computer Science, pages 148- 
161, 1989. 
12. Joost Engelfriet. A characterization of context-free NCE graph languages 
by monadic second-order logic on trees. In H. E,hrig, H.-J. Kreowski, 
and G. H.ozenberg, editors, Graph Grammars and Their Application to 
Computer Science, volume 532 of Lecture Notes in Computer Science, 
pages 311-327, 1991. 
13. Thomas Lengauer and Egon Wanke. Efficient decision procedures for 
graph properties on context-free graph languages. Journal of the ACM, 
14. Bruno Courcelle. Graph rewriting: An algebraic and logical approach. 
In J. van Leeuwen, editor, Handbook of Theoretical Computer Science, 
volume Vol. B., pages 193-242. Elsevier, Amsterdam, 1990. 
15. Bruno Courcelle. The monadic second-order logic of graphs I: Recogniz- 
able sets of finite graphs. Information and Computation, 85:12-75, 1990. 
16. Bruno Courcelle. Context-free graph grammars: Separating vertex re- 
placement from hyperedge replacement. In Z. Esik, editor, Fundamentals 
of Computation Theory, volume 710 of Lecture Notes in Computer Sci- 
ence, pages 181-193, 1993. 
17. Bruno Courcelle and Joost Engelfriet. A logical characterization of the 
sets of hypergraphs defined by hyperedge replacement systems. Mathe- 
matical Systems Theory, 28~515-552, 1995. 
18. Joost Engelfriet and Grzegorz Rozenberg. A comparison of boundary 
graph grammars and context-free hypergraph grammars. Information 
and Computation, 84:163-206, 1990. 
19. Joost Engelfriet and Linda Heyker. The string generating power of 
context-free hypergraph grammars. Journal of Computer and System 
Sciences, 43:328-360, 1991. 
20. Joost Engelfriet and Linda Heyker. Context-free hypergraph grammars 
have the same term-generating power as attribute grammars. Acta In- 
formatica, 29:161-210, 1992. 
40~368-393, 1993. 

158 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
21. Joost Engelfriet. A Greibach normal form for context-free graph gram- 
mars. In W. Kuich, editor, Automata, Languages and Programming, vol- 
ume 623 of Lecture Notes in Computer Science, pages 138-149, 1992. 
22. Joost Engelfriet, Linda Heyker, and George Leih. Context-free graph 
languages of bounded degree are generated by apex graph grammars. 
Acta Informatica, 31:341-378, 1994. 
23. Joost Engelfriet. Graph grammars and tree transducers. In CAAP’94, 
volume 787 of Lecture Notes in Computer Science, pages 15-36, 1994. 
24. Hans-Jorg Kreowski. A pumping lemma for context-free graph languages. 
In V. Claus, H. Ehrig, and G. Rozenberg, editors, Graph-Grammars and 
Their Application to Computer Science and Biology, volume 73 of Lecture 
Notes in Computer Science, pages 270-283, 1979. 
25. Hans-Jorg Kreowski. Rule trees represent derivations in edge replacement 
systems. In G. Rozenberg and A. Salomaa, editors, The Book of L, pages 
217-232. Springer-Verlag, Berlin, 1986. 
26. Annegret Habel and Hans-Jorg Kreowski. Some structural aspects of 
hypergraph languages generated by hyperedge replacement. In F. Bran- 
denburg, G. Vidal-Naquet, and M. Wirsing, editors, STACS 87, volume 
247 of Lecture Notes in Computer Science, pages 207-219, 1987. 
27. Annegret Habel, Hans-Jorg Kreowski, and Walter Vogler. Metatheorems 
for decision problems on hyperedge replacement graph languages. Acta 
Inforrnatica, 26557-677, 1989. 
28. Annegret Habel and Hans-Jorg Kreowski. Filtering hyperedge- 
replacement languages through compatible properties. In M. Nagl, editor, 
Graph- Theoretic Concepts in Computer Science, volume 411 of Lecture 
Notes in Computer Science, pages 107-120, 1990. 
29. Clemens Lautemann. The complexity of graph languages generated by 
hyperedge replacement. Acta Inforrnatica, 27:399-42 1, 1990. 
30. Annegret Habel, Hans-Jorg Kreowski, and Walter Vogler. Decidable 
boundedness problems for sets of graphs generated by hyperedge replace- 
ment. Theoretical Computer Science, 89:33-62, 1991. 
31. Clemens Lautemann. Tree automata, tree decomposition, and hyperedge 
replacement. In H. Ehrig, H.-J. Kreowski, and G. Rozenberg, editors, 
Graph Grammars and Their Application to Computer Science, volume 
532 of Lecture Notes in Computer Science, pages 520-537, 1991. 
32. Frank Drewes. NP-completeness of k-connected hyperedge-replacement 
languages of order k. Information Processing Letters, 45:89-94, 1993. 
33. Frank Drewes. Recognising k-connected hypergraphs in cubic time. The- 
oretical Computer Science, 109:83-122, 1993. 
34. Annegret Habel, Hans-Jorg Kreowski, and Clemens Lautemann. A com- 
parison of compatible, finite, and inductive graph properties. Theoretical 
Computer Science, 110:145-168, 1993. 

REFERENCES 
159 
35. Thomas Lengauer and Egon Wanke. Efficient analysis of graph properties 
on context-free graph languages. In T. Lepisto and A. Salomaa, editors, 
Automata, Languages and Programming, volume 317 of Lecture Notes in 
Computer Science, pages 379-393, 1988. 
36. Thomas Lengauer and Egon Wanke. Efficient solution of connectivity 
problems on hierarchically defined graphs. SIAM Journal on Computing, 
37. Egon Wanke. On the decidability of certain integer subgraph problems on 
context-free graph languages. Information and Computation, 113:26-49, 
1994. 
38. Mark Minas and Gerhard Viehstaedt. Specification of diagram editors 
providing layout adjustment with minimal change. In Proc. IEEE Symp. 
on Visual Languages (VL '93), pages 324-329. IEEE Comp. Society Press, 
1993. 
39. Mark Minas and Gerhard Viehstaedt. DiaGen: A generator for diagram 
editors providing direct manipulation and execution of diagrams adjust- 
ment with minimal change. In Proc. IEEE Symp. on Visual Languages 
(VL'95). IEEE Comp. Society Press, 1995. 
40. Gerhard Viehstaedt. A generator for diagram editors. Doctoral Disserta- 
tion, University of Erlangen, Germany, 1995. 
41. R. Farrow, K. Kennedy, and L. Zucconi. Graph grammars and global 
program data flow analysis. In Proc. 17th Ann. IEEE Symp. on Found. 
of Comp. Sci., pages 42-56, Houston, 1976. 
42. Annegret Habel. Hyperedge Replacement: Grammars and Languages, vol- 
ume 643 of Lecture Notes in Computer Science. Springer-Verlag, Berlin, 
1992. 
43. Annegret Habel. Hypergraph grammars: Transformational and algorith- 
mic aspects. Journal of Information Processing and Cybernetics EIK, 
44. Bruno Courcelle, Joost Engelfriet, and Grzegorz Rozenberg. Handle- 
rewriting hypergraph grammars. Journal of Computer and System Sci- 
ences, 46:218-270, 1993. 
45. Annegret Habel and Hans-Jorg Kreowski. Collage grammars. In H. Ehrig, 
H.-J. Kreowski, and G. Rozenberg, editors, Graph Grammars and Their 
Application to Computer Science, volume 532 of Lecture Notes in Com- 
puter Science, pages 411-429, 1991. 
46. Frank Drewes, Annegret Habel, Hans-Jorg Kreowski, and Stefan Tauben- 
berger. Generating self-affine fractals by collage grammars. Theoretical 
Computer Science, 145:159-187, 1995. 
17: 1063-1080, 1988. 
28:241-277, 1992. 

160 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
47. Jiirgen Dassow, Annegret Habel, and Stefan Taubenberger. Chain-code 
pictures and collages generated by hyperedge replacement. In H. Ehrig, 
H.-J. Kreowski, and G. Rozenberg, editors, Proc. Fifth Intl. Workshop on 
Graph Grammars and Their Applicataon to Computer Science, volume 
1073 of Lecture Notes in Computer Science, pages 412-427, Springer, 
1996. 
48. Frank Drewes and Hans-Jorg Kreowski. (Un)decidability of properties of 
pictures generated by collage grammars. Fundamenta Informaticae 25, 
49. Frank Drewes. Language theoretic and algorithmic properties of d- 
dimensional collages and patterns in a grid. Journal of Computer and 
System Sciences, 1996. To appear. 
50. Bruno Courcelle. An axiomatic definition of context-free rewriting and 
its application to NLC graph grammars. Theoretical Computer Science, 
51. Hartmut Ehrig and Karl Wilhelm Tischer. Graph grammars and appli- 
cations to specialization and evolution in biology. Journal of Computer 
and System Sciences, 11:212-236, 1975. 
52. Hans-Jorg Kreowski. Parallel hyperedge replacement. In G. Rozenberg 
and A. Salomaa, editors, Lindenmayer Systems, pages 271-282. Springer- 
Verlag, Berlin Heidelberg New York, 1992. 
53. Gnanamalar David, Frank Drewes, and Hans-Jorg Kreowski. Hyperedge 
replacement with rendezvous. In P. Jouannaud, editor, Proc. Theory and 
Practice of Software Development, volume 668 of Lecture Notes in Com- 
puter Science, pages 167-181, 1993. 
54. Hans-Jorg Kreowski. Five facets of hyperedge replacement beyond 
context-freeness. In Z. Esik, editor, Fundamentals of Computation The- 
ory, volume 710 of Lecture Notes in Computer Science, pages 69-86, 
1993. 
55. Michel Bauderon. Infinite hypergraphs I. Basic properties. Theoretical 
Computer Science, 82:177-214, 1991. 
56. Michel Bauderon. Infinite hypergraphs 11. Systems of recursive equations. 
Theoretical Computer Science, 103:165-190, 1992. 
57. Seymour Ginsburg and Gordon Rice. Two families of languages related 
to ALGOL. Journal of the ACM, 9:350-371, 1962. 
58. Y. Bar-Hillel, M. Perles, and E. Shamir. On formal properties of simple 
phrase-structure grammars. Zeitschrift fur Phonetik, Sprachwissenschaft 
und Kommunikationsforschung, 14:143-177, 1961. 
59. John E. Hopcroft and Jeffrey D. Ullman. Formal Languages and Their 
Relation to Automata. Addison-Wesley, Reading, Mass., 1969. 
295-325, 1996. 
55:141-181, 1987. 

REFERENCES 
161 
60. R.J. Parikh. On context-free languages. Journal of the ACM, 13:570-581, 
1966. 
61. Donald J. Rose. On simple characterizations of Ic-trees. Discrete Mathe- 
matics, 7:317-322, 1974. 
62. Ferenc Gkcseg and Magnus Steinby. Tree Automata. Akadkmiai Kiad6, 
Budapest, 1984. 
63. Alfred V. Aho and Jeffrey D. Ullman. Translations on a context free 
grammar. Information and Control, 19:439-475, 1971. 
64. Joost Engelfriet, Grzegorz Rozenberg, and Giora Slutzki. Tree transduc- 
ers, L systems, and two-way machines. Journal of Computer and System 
Sciences, 20:150-202, 1980. 
65. John E. Hopcroft and Jeffrey D. Ullman. Introduction to Automata 
Theory, Languages and Computation. Addison-Wesley, Reading, Massa- 
chusetts, 1979. 
66. Joost Engelfriet and Heiko Vogler. The translation power of top-down 
tree-to-graph transducers. Journal of Computer and System Sciences, 
67. Joost Engelfriet and Heiko Vogler. Macro tree transducers. Journal of 
Computer and System Sciences, 31:71-146, 1985. 
68. Joost Engelfriet and Linda Heyker. Hypergraph languages of bounded 
degree. Journal of Computer and System Sciences, 48:58-89, 1994. 
69. Stefan Arnborg, Jens Lagergren, and Detlef Seese. Problems easy for 
tree-decomposable graphs. Journal of Algorithms, 12:308-340, 1991. 
70. Egon Warike and Manfred Wiegers. Undecidability of the bandwidth 
problem on linear graph languages. Information Processing Letters, 
71. Bruno Courcelle and Mohamed Mosbah. Monadic second-order eval- 
uations on tree-decomposable graphs. Theoretical Computer Science, 
72. Helmut Seidl. Finite tree automata with cost functions. Theoretical Com- 
puter Science, 126:113-142, 1994. 
73. Frank Drewes. A lower bound on the growth of functions computed by 
tree transductions. Fundamenta Informaticae, 1996. To appear; short ver- 
sion in Lecture Notes in Computer Science 787 (CAAP 94). 
74. Frank Drewes. The use of tree transducers to compute translations be- 
tween graph algebras. In Proc. Fifth Intl. Workshop on Graph Gram- 
mars and Their Application to Computer Science, volume 1073 of Lecture 
Notes in Computer Science, pages 196-210, Springer, 1996. 
75. Frank Drewes. Computation by tree transductions. Doctoral Disserta- 
tion, University of Bremen, Germany, 1996. 
49: 2 58-305 , 1994. 
33~193-197, 1989. 
109:49-82, 1993. 

162 CHAPTER 2. HYPEREDGE REPLACEMENT GRAPH GRAMMARS 
76. Michael R. Garey and David S. Johnson. Computers and Intractability. A 
Guide to the Theory of NP-Completeness. W.H. Freeman and Company, 
New York, 1979. 
77. Ijsbrand Jan Aalbersberg, Andrzej Ehrenfeucht, and Grzegorz Rozen- 
berg. On the membership problem for regular DNLC grammars. Discrete 
Applied Mathematics, 13:79-85, 1986. 
78. Saunders MacLane. A structural characterization of planar combinatorial 
graphs. Duke Mathematical Journal, 3:460-472, 1937. 
79. John E. Hopcroft and Robert E. Tarjan. Dividing a graph into tricon- 
nected components. SIAM Journal on Computing, 2(3):135-158, 1973. 
80. Patrick C. Fischer, Albert R. Meyer, and Arnold L. Rosenberg. Counter 
machines and counter languages. Mathematical Systems Theory, 2:265- 
283, 1968. 
81. Klaus-Jorn Lange and Emo Welzl. String grammars with disconnecting or 
a basic root of the difficulty in graph grammar parsing. Discrete Applied 
Mathematics, 16:17-30, 1987. 
82. Walter Vogler. Recognizing edge replacement graph languages in cubic 
time. In H. Ehrig, H.-J. Kreowski, and G. Rozenberg, editors, Graph 
Grammars and Their Application to Computer Science, volume 532 of 
Lecture Notes in Computer Science, pages 676-687, 1991. 

Chapter 3 
ALGEBRAIC APPROACHES TO 
GRAPH TRANSFORMATION 
PART I: 
BASIC CONCEPTS AND 
DOUBLE PUSHOUT APPROACH 
A. CORRADINI, U. MONTANARI, F. ROSS1 
Dipartimento di Inforrnatica, Corso Italia 40, 
I-56125 Pisa, Italy 
H. EHRIG, R. HECKEL, M. LOWE 
Technische Universitat Berlin, Fachbereich 13 Informatik, Franklinstrafle 28/29, 
0-10587 Berlin, Germany 
The algebraic approaches to graph transformation are based on the concept of 
gluing of graphs, modelled by pushouts in suitable categories of graphs and graph 
morphisms. This allows one not only to give an explicit algebraic or set theoretical 
description of the constructions, but also to use concepts and results from category 
theory in order to build up a rich theory and to give elegant proofs even in complex 
situations. In this chapter we start with an overwiev of the basic notions common to 
the two algebraic approaches, the double-pushout (DPO) approach and the single- 
pushout (SPO) approach; next we present the classical theory and some recent 
development of the double-pushout approach. The next chapter is devoted instead 
to the single-pushout approach, and it is closed by a comparison between the two 
approaches. 
163 

164 
Contents 
3.1 
3.2 
3.3 
3.4 
3.5 
3.6 
3.7 
3.8 
3.9 
Introduction . . . . . . . . . . . . . . . . . . . . , . . . 165 
Overview of the Algebraic Approaches . . . . . . . 168 
Graph Transformation Based on the DPO Con- 
struction . . . . . . . . . . . . . . . . . . . , . . . . . . 182 
Independence and Parallelism in the DPO ap- 
proach. . . . . . . . . . . . . . . . . . . . . . . . . . . . 191 
Models of Computation in the DPO Approach . . 200 
Embedding, Amalgamation and Distribution in the 
DPO approach . . . . . . . . . . . . . . . . . . . . 220 
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . 228 
Appendix A: On commutativity of coproducts . . 228 
Appendix B: Proof of main results of Section 3.5 232 
References 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 240 

3.1. INTRODUCTION 
165 
3.1 
Introduction 
The algebraic approach to graph grammars has been invented at the Tech- 
nical University of Berlin in the early seventies by H. Ehrig, M. Pfender and 
H.J. Schneider in order to generalize Chomsky grammars from strings to graphs 
[I]. The main idea was to generalize the concatenation of strings to a gluing 
construction for graphs. This allowed to formulate a graph rewriting step by 
two gluing constructions. The approach was called “algebraic” because graphs 
are considered as special kinds of algebras and the gluing for graphs is defined 
by an “algebraic construction”, called pushout, in the category of graphs and 
total graph morphisms. This basic idea allows one to apply general results from 
algebra and category theory in the algebraic theory of graph grammars. In ad- 
dition to the idea to generalize Chomsky grammars from strings to graphs, 
it was B. K. Rosen’s idea to use graph grammars as a generalization of term 
rewriting systems where terms are represented by specific kinds of trees. In fact, 
graphs are suitable to model terms with shared subterms, which are no longer 
trees, and therefore term rewriting with shared subterms can be modelled by 
graph rewriting. 
Graph grammars in general provide an intuitive description for the manipula- 
tion of graphs and graphical structures as they occur in programming language 
semantics, data bases, operating systems, rule based systems and various kinds 
of software and distributed systems. In most of these cases graph grammars 
allow one to give a formal graphical specification which can be executed as 
far as corresponding graph grammar tools are available. Moreover, theoretical 
results for graph grammars are useful for analysis, correctness and consistency 
proofs of such systems. The algebraic approach [2,3,4,5] has been worked out 
for several years and provides interesting results for parallelism analysis [6,7], 
efficient evaluation of functional expressions [8,9] and logic programs [lo], syn- 
chronization mechanisms [ll], distributed systems [11,12,13,5], object-oriented 
systems [14], applied software systems [15], implementation of abstract data 
types [16] and context-free hyperedge replacement [17] (see also Chapter 3). 
Historically, the first of the algebraic approaches to graph transformation is 
the so-called double-pushout (DPO) approach introduced in [l] , which owes 
its name to the basic algebraic construction used to define a direct derivation 
step: This is modelled indeed by two gluing diagrams (i.e., pushouts) in the 
category of graphs and total graph morphisms. More recently a second alge- 
braic approach has been proposed in [5], which defines a basic derivation step 
as a single pushout in the category of graphs and partial graph morphisms: 

166 
CHAPTER 3. DOUBLEPUSH OUT APPROACH 
Hence the name of single-pushout (SPO) approach? This chapter includes an 
informal description of the basic concepts and results common to the DPO and 
SPO approaches, followed by a more detailed, formal presentation of the DPO 
approach. On the other hand, the SPO approach is the main topic of the next 
chapter, which is closed by a formal comparison of the two approaches. 
More precisely, in Section 3.2 many relevant concepts and results of the alge- 
braic approaches to graph transformation are introduced in the form of prob- 
lems stated in quite an abstract way: This provides an outline that will be 
followed (to a great extent) along the presentation of the two approaches, 
each of which will provide its own answers to such problems. The stated prob- 
lems concern independence and parallelism of direct derivations, embedding 
of derivations, amalgamation, and distribution. The last part of the section 
shortly recalls some other issues addressd in the literature of the algebraic 
approaches, including computation based semantics, application conditions, 
structuring of grammars, consistency conditions, and generalization of the al- 
gebraic approaches to other structures. Some of these topics will be presented 
in detail for just one of the two approaches, namely computation based se- 
mantics (in particular the so-called models of computation) for the DPO, and 
application conditions for the SPO approach; for the other topics relevant ref- 
erences are indicated only. 
Section 3.3 starts the presentation of the DPO approach by introducing the 
very basic notions, including the category of graphs we shall use and the def- 
initions of production, direct derivation, and derivation; also the fundamental 
notion of pushout and the gluing conditions (i.e., the conditions that ensures 
the applicability of a production at a given match) are discussed in some depth. 
Section 3.4 presents the main results of the theory of parallelism for the DPO 
approach, including the notions of parallel and sequential independence, the 
Local Church Rosser and the Parallelism theorems, and the synthesis and 
analysis constructions. This section on the one hand answers the problems 
about independence and parallelism raised in Section 3.2.2 and, on the other 
hand, it provides some basic notions exploited in the following section. 
Section 3.5 presents various models of computations for graph grammars on 
different levels of abstraction, i.e., various categories having graphs as objects 
and graph derivations as arrows. All such models are obtained from the most 
concrete one by imposing suitable equivalences on graphs and derivations. In 
particular, in the most abstract model, called the abstract truly-concurrent 
model, all isomorphic graphs are identified, as well as all derivations that are 
aOther definitions of graph rewriting using a single pushout in a category of partial graph 
morphisms exist: Their relationship with the SPO approach is discussed in Section 4.2.2. 

3.1. INTRODUCTION 
167 
related by the classical shift-equivalence (which considers as equal all deriva- 
tions which differ for the order of independent direct derivations only) or by 
equivalence -3, which relates derivations that are isomorphic and satisfy a 
further technical (but fundamental) condition. Finally Section 3.6 summarizes 
the main results concerning embedding of derivations, amalgamation and dis- 
tribution for the DPO approach, providing answers for the remaining problems 
raised in Section 3.2. 
Two appendices close the chapter. Appendix A (Section 3.8) introduces the 
definition of binary coproducts in a category, and shows that coproducts can- 
not be assumed to be commutative (in a strict way) unless the category is 
a preorder. This fact justifies the way parallel productions are defined and 
manipulated in Section 3.4, which may appear more complex than the corre- 
sponding definitions in previous papers in the literature. Appendix B (Section 
3.9) presents the proof of the main technical result of Section 3.5. That proof 
is based on the analysis and synthesis constructions which are reported as well, 
not only for completeness, but also because they demonstrate a typical exam- 
ple of reasoning that is used when results in the algebraic approach to graph 
transformations are proven on an abstract level. 
A formal, detailed comparison of the DPO and SPO approaches is presented 
in Section 4.6, where it is also shown that the DPO approach can be embedded 
(via a suitable translation) into the SPO approach. 
All the categorical notions used in this chapter are explicitly introduced; nev- 
ertheless, some knowledge of the basic concepts of category theory would be 
helpful. Standard references are [18,19]. 
How to read the chapters on the algebraic approaches. 
Readers interested in just one of the algebraic approaches are suggested to 
read either this chapter (for the DPO approach), or Section 3.2 and then all 
Chapter 4 excluded Section 4.6 (for the SPO approach; a few references to 
Section 3.3 will have to be followed). 
Alternatively, some parts may be skipped, depending on the specific interests 
of the reader. All readers (and in particular newcomers) are encouraged to 
read Section 3.2 first, where they can get a precise, although informal idea 
of the main topics addressed in the theory of the algebraic approaches. Such 
topics are then presented with all technical details for the DPO approach in 
Section 3.3, in the first part of Section 3.4 (till Theorem 3.4.6), and in Section 
3.6. For the SPO approach, they are presented instead in Section 4.2 and 4.3. 
After these sections, the reader interested in a careful comparison of the two 
approaches can read Section 4.6. 

CHAPTER 3. DOUBLE PUSHOUT APPROACH 
3.2 Overview of the Algebraic Approaches 
The purpose of this section is to provide an overview of the two algebraic ap- 
proaches to graph transformation, the double-pushout (DPO) and the single- 
pushout (SPO) approach. Taking a problem-oriented point of view allows us to 
discuss the main questions raised (and solutions proposed) by both approaches 
quite informally using the same conceptual terminology. Explicit technical con- 
structions and results are then presented for the DPO approach in the remain- 
ing sections of this chapter, and for the SPO approach in the next chapter. A 
detailed comparison of the two approaches can be found in Section 4.6. 
Among the various approaches to graph transformation, the algebraic ap- 
proaches are characterized by the use of categorical notions for the very basic 
definitions of graph transformation rules (or productions, as they are usually 
called), of matches (i.e., of occurrences of the left-hand side of a production in 
a graph), and of rule applications (called direct derivations). The main advan- 
tage is clearly that techniques borrowed from category theory can be used for 
proving properties and results about graph transformation, and such proofs 
are often be simpler than corresponding proofs formulated without categorical 
notions. In addition, such proofs are to a great extent independent from the 
structure of the objects that are rewritten. Therefore the large body of results 
and constructions of the algebraic approaches can be extended quite easily to 
cover the rewriting of arbitrary structures (satisfying certain properties) , as 
shown for example by the theory of High-Level Replacement Systems [20,21]. 
In this section, we first introduce informally the basic notions of graph, pro- 
duction and derivation for the DPO and SPO approaches in Section 3.2.1. We 
address questions concerning the independence of direct derivations and their 
parallel application in Section 3.2.2; the embedding of derivations in larger 
contexts and the related notion of derived production in Section 3.2.3; and the 
relationship between the amalgamation of productions along a common sub- 
part (a sort of synchronization) and the distributed application of several pro- 
ductions to a graph in Section 3.2.4. Finally Section 3.2.5 shortly recalls some 
other issues addressed in the literature of the algebraic approaches, including 
computation based semantics, application conditions, structuring of grammars, 
consistency conditions, and generalization of the algebraic approaches to other 
structures. 
3.2.1 
Graphs, Productions and Derivations 
The basic idea of all graph transformation approaches is to consider a produc- 
tion p : L -+ R, where graphs L and R are called the left- and the right-hand 

3.2. OVERVIEW OF THE ALGEBRAIC APPROACHES 
169 
side, respectively, as a finite, schematic description of a potentially infinite set 
of direct derivations. If the match m fixes an occurrence of L in a given graph 
G, then G % H denotes the direct derivation where p is applied to G leading 
to a derived graph H .  Intuitively, H is obtained by replacing the occurrence 
of L in G by R. The essential questions distinguishing the particular graph 
transformation approaches are: 
1. What is a “graph”? 
2. How can we match L with a subgraph of G? 
3. How can we define the replacement of L by R in G? 
In the algebraic approaches, a graph is considered as a two sorted algebra where 
the sets of vertices V and edges E are the carriers, while source s : E -+ V and 
target t : E -+ V are two unary operations. Moreover we have label functions 
lv : V + LV and le : E + LE, where LV and LE are fixed label alphabets 
for vertices and edges, respectively. Since edges are objects on their own right, 
this allows for multiple (parallel) edges with the same label. 
Each graph production p : L -+ R defines a partial correspondence between 
elements of its left- and of its right-hand side, determining which nodes and 
edges have to be preserved by an application of p ,  which have to be deleted, 
and which must be created. To see how this works, consider the production 
pl : L1 w R1 which is applied on the left of Figure 3.1 to a graph G1, leading 
to the direct derivation (1). The production assumes three vertices on the left- 
hand side L1, and leaves behind two vertices, connected by an edge, on the 
right-hand side R1. The numbers written near the vertices and edges define a 
partial correspondence between the elements of L1 and R1: Two elements with 
the same number are meant to represent the same object before and after the 
application of the production. In order to apply pl to the given graph G I ,  we 
have to find an occurrence of the left-hand side L1 in G I ,  called match in the 
following. A match m : L --+ G for a production p is a graph homomorphism, 
mapping nodes and edges of L to G, in such a way that the graphical structure 
and the labels are preserved. The match ml : L1 --+ G1 of the direct derivation 
(1) maps each element of L1 to the element of GI carrying the same number. 
Applying production pl to graph G1 at match ml we have to delete every 
object from G1 which matches an element of L1 that has no corresponding 
element in R1, i.e., vertex 2 of G1 is deleted. Symmetrically, we add to G1 each 
element of R1 that has no corresponding element in L1, i.e., edge 5 is inserted. 
All remaining elements of G1 are preserved, thus, roughly spoken, the derived 
graph H I  is constructed as GI - ( L I  - R1) U (R1 - L I ) .  

170 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
3-J 
" I  
Figure 3.1: Direct derivations. 
L-P-R 
I 
I 
T 
T 
G-p*-H 
Figure 3.2: Example and schematic representation of direct derivation G % H .  
The application of a production can be seen as an embedding into a context, 
which is the part of the given graph G that is not part of the match, i.e., 
the edge 4 in our example. Hence, at the bottom of the direct derivation, the 
co-production p; : GI y-f HI relates the given and the derived graphs, keeping 
track of all elements that are preserved by the direct derivation. Symmetrically, 
the co-match m'l, which is a graph homomorphism, too, maps the right-hand 
side R1 of the production to its occurrence in the derived graph HI. A direct 
derivation from G to H resulting from an application of a production p at a 
match m is schematically represented as in Figure 3.2, and denoted by d = 
(G % H ) .  
In general L does not have to be isomorphic to its image m(L) in G, i.e., 
elements of L may be identified by m. This is not always unproblematic, as we 
may see in the direct derivation (2) of Figure 3.1. A production pa, assuming 
two vertices and deleting one of them, is applied to a graph G2 containing only 
one vertex, i.e., vertices 1 and 2 of L2 are both mapped to the vertex 3 of G2. 
Thus, the production p2 specifies both the deletion and the preservation of 3: 
We say that the match m2 contains a conflict. There are three possible ways to 
solve this conflict: Vertex 3 of G2 may be preserved, deleted, or the application 
of the production p2 at this match may be forbidden. In the derivation (2) of 
Figure 3.1 the second alternative has been choosen, i.e., the vertex is deleted. 

3.2. OVERVIEW OF THE ALGEBRAIC APPROACHES 
171 
Another difficulty may occur if a vertex shall be deleted which is connected 
to an edge that is not part of the match, as shown in direct derivation (3) of 
Figure 3.1: Deleting vertex 1 of Gs, as specified by production p3, would leave 
behind the edge 3 without a source vertex, i.e., the result would no longer 
be a graph. Again there are two ways to avoid such dangling edges. We may 
either delete the edge 3 together with its source node, as in derivation (3) of 
Figure 3.1, or forbid the application of p3. 
The basic difference between the DPO and the SPO approach lies in the way 
they handle the above problematic situations. In the DPO approach, rewriting 
is not allowed in these cases (i.e., productions p2 and p3 are not applicable to 
matches m2 and m3, respectively). On the contrary, in the SPO approach such 
direct derivations are allowed, and deletion has priority over preservation; thus 
(2) and (3) of Figure 3.1 are legal SPO direct derivations. 
In both algebraic approaches direct derivations are modeled by gluing con- 
structions of graphs, that are formally characterized as pushouts in suitable 
categories having graphs as objects, and (total or partial) graph homomor- 
phisms as arrows. A production in the DPO approach is given by a pair 
L t 
K -% R of graph homomorphisms from a common interface graph 
K ,  and a direct derivation consists of two gluing diagrams of graphs and total 
graph morphisms, as (1) and (2) in the left diagram below. The context graph 
D is obtained from the given graph G by deleting all elements of G which have 
a pre-image in L, but none in K .  Via diagram (1) this deletion is described as 
an inverse gluing operation, while the second gluing diagram (2) models the 
actual insertion into H of all elements of R that do not have a pre-image in K. 
In order to avoid problematic situations like (2) and (3) in Figure 3.1, in the 
DPO approach the match m must satisfy an application condition, called the 
gluing condition. This condition consists of two parts. To ensure that D will 
have no dangling edges, the dangling condition requires that if p specifies the 
deletion of a vertex of G, then it must specify also the deletion of all edges of G 
incident to that node. On the other hand the identification condition requires 
that every element of G that should be deleted by the application of p has only 
one pre-image in L. The gluing condition ensures that the application of p to 
G deletes exactly what is specified by the production. 
1 
L-1-K-T-R 
I 
I 
t 
L-P-R 

172 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
In the SPO approach a production p is a partial graph homomorphism. A direct 
derivation is given by a single gluing diagram, as (3) in the right diagram 
above, where the match m is required to be total. No gluing condition has 
to be satisfied for applying a production, and this may result in side effects 
as shown in Figure 3.1. In fact, on the one hand, the deletion of a node of 
G automatically causes the deletion of all incident edges, even if this is not 
specified by the production. On the other hand conflicts between deletion and 
preservation of nodes and edges are solved in favor of deletion, and in this case 
the co-match m* becomes a partial homomorphism, because elements of the 
right-hand side that should have been preserved but are deleted because of 
some conflict do not have an image in H .  
Direct derivations in the SPO approach are more expressive than DPO deriva- 
tions, in the sense that they may model effects that can not be obtained in 
the more restricted DPO approach. A formal correspondence between direct 
derivations in the two approaches is presented in Section 4.6. 
A graph grammar G consists of a set of productions P and a start graph Go. 
A sequence of direct derivations p = (Go 3 
GI 3 
. . . % G,) constitutes 
a derivation of the grammar, also denoted by Go r=$* G,. The language C(G) 
generated by the grammar G is the set of all graphs G, such that Go ==+* G, 
is a derivation of the grammar. 
3.2.2 
Independence and Parallelism 
Parallel computations can be described in two different ways. If we stick to 
a sequential model, two parallel processes have to be modeled by interleaving 
arbitrarily their atomic actions, very similarly to the way multitasking is im- 
plemented on a single processor system. On the contrary, explicit parallelism 
means to have one processor per process, which allows the actions to take place 
simultaneously. 
Interleaving 
Considering the interleaving approach first, two actions are concurrent, i.e., 
potentially in parallel, if they may be performed in any order with the same 
result. In terms of graph transformations, the question whether two actions 
(direct derivations) are concurrent or not can be asked from two different 
points of view. 
1. Assume that a given graph represents a certain system state. The next 
evolution step of this state is obtained by the application of a production 

3.2. OVERVIEW OF THE ALGEBRAIC APPROACHES 
173 
at a certain match, where the production and the match are chosen non- 
deterministically from a set of possible alternatives. Clearly, each choice we 
make leads to a distinct derivation sequence, but the question remains, whether 
two of these sequences indeed model different computations or if we have only 
chosen one of two equivalent interleavings. (Here, two derivation sequences 
from some graph Go to G, are equivalent if both insert and delete exactly the 
same nodes and edges.) In other words, given two alternative direct deriva- 
tions H1 & G 3 
H2 we ask ourselves if there are direct derivations 
H I  8 
X & H2, showing that the two given direct derivations are not mutu- 
ally exclusive, but each of them can instead be postponed after the application 
of the other, yielding the same result. 
2. Given a derivation, intuitively two consecutive direct derivations G 3 
HI 3 
X are concurrent if they can be performed in a different order, as in 
G 3 
H2 3 
X ,  without changing the result. The existence of two different 
orderings ensures that there is no causal dependency between these applications 
of p l  and pa. 
Summarizing, we can say that two alternative derivations are concurrent if they 
are not mutually exclusive while two consecutive derivations are concurrent if 
they are not causally dependent. To stress the symmetry between these two 
conditions they are called parallel and sequential independence, respectively, 
in the more formal statement of this problem below. Originally investigated in 
view of the local confluence property of (term) rewriting systems, it is called 
the Local Church-Rosser Problem. 
Problem 3.2.1 (Local Church Rosser) 
1. Find a condition, called parallel independence, such that two alternative 
direct derivations H1 & G -21-11 H2 are parallel independent iff there are 
direct derivations H1 3 
X and H2 3 
X such that G 
H I  3 
X 
and G 3 
H2 3 
X are equivalent. 

174 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
2. Find a condition, called sequential independence, such that a derivation 
G a 
H1 3 
X is sequentially independent iff there is an equivalent 
More concretely, two alternative direct derivations are parallel independent if 
their matches do only overlap in items that are preserved by both derivations, 
that is, if none of the two deletes any item that is also accessed by the other 
one. If an item is preserved by one of the direct derivations, say G 3 
H I ,  
but deleted by the other one, the second one can be delayed after the first; 
we say that G 3 
H2 is weakly parallel independent of G % H I .  Parallel 
independence can then be defined as mutual weakly parallel independence. 
Two consecutive direct derivations are sequentially independent if (u) the 
match of the second one does not depend on elements generated by the first 
one, and (b) the second derivation does not delete an item that has been ac- 
cessed by the first. The first part of this condition ensures that p2 may already 
be applied before pl , leading to an alternative direct derivation G 3 
H2. We 
say that H1 3 
X is weakly sequentially independent of G 5 H I .  From (b) 
we can show that the latter is weakly parallel independent of G 3 
H2 in 
the above sense. So two consecutive direct derivations G 3 
H1 8 
X are 
sequentially independent if H1 3 
X is weakly sequentially independent of 
G 3 
H1 and the latter is weakly parallel independent of G 3 
H2. 
derivation G 3 
H2 3 
X .  
Explicit Parallelism 
Parallel computations can be represented more directly by parallel application 
of productions. Truly parallel application of productions essentially requires to 
abstract from any possible application order, which implies that no interme- 
diate graph is generated. In other words, a (true) parallel application may be 
modeled by the application of a single production, the parallel production. 
Given productions pl : L1 + R1 and pa : L2 + R2, their parallel composition 
is denoted by pl + p2 : L1 + L2 ^cf R1 + R2. Intuitively, p1 + p2 is just the 
disjoint union of pl and p2. Direct derivations like G & X ,  using a parallel 
production pl + pa, are referred to as parallel direct derivations. 
Now we have seen two different ways to model parallel computations by graph 
transformation, either using interleaving sequences or truly parallel derivations. 
How are they related? This question can be asked from two different points of 
view. Given a parallel direct derivation G & X we may look for a sequen- 
tialization, say G % HI 3 
X .  On the other hand, starting from the latter 
sequence we can try to put the two consecutive direct derivations in parallel. 
Pl+ 2 
P l +  2 

3.2. OVERVIEW OF THE ALGEBRAIC APPROACHES 
175 
The problem of finding necessary and sufficient conditions for these sequen- 
tialization and parallelization constructions, also called analysis and synthesis 
in the literature, is stated in the following way. 
Problem 3.2.2 (Parallelism) 
1. Find a sequentialization condition such that a parallel direct derivation 
Pl+ 2 
G ==$ X satisfies this condition iff there is an equivalent sequential 
derivation G 3 
H1 3 
X (or G 3 H2 3 
X ,  respectively). 
2. Find a parallelization condition such that a sequential derivation G 3 
H1 3 
X (or G 3 
H2 3 
X )  satisfies this condition iff there is an 
0 
equivalent parallel direct derivation G & X .  
Pl+ 2 
The solution to this problem is closely related to the notions of sequential and 
parallel independence. In the double pushout approach it turns out that each 
parallel direct derivation G & X may be sequentialized to derivations G 3 
HI 3 
X and G 3 
H2 3 
X ,  which are in turn sequentially independent; 
indeed, the sequentialization condition is already part of the gluing condition 
for the application of the parallel production. Vice versa, consecutive direct 
derivations can be put in parallel if they are sequentially independent, thus 
the parallelization condition requires sequential independence of the derivation. 
Hence in the double pushout approach the two ways of modeling concurrency 
are in fact equivalent, in the sense that they allow one to represent exactly the 
same amount of parallelism. 
In the single pushout setting, however, a parallel direct derivation G & X 
can be sequentialized to G 3 
H1 3 
X if G 3 
H2 is weakly parallel 
independent of G 3 
H I ,  where the two alternative direct derivations from G 
are obtained by restricting the match of p1 +p2 into G to the left-hand side of pl 
and pa, respectively. Since for a given parallel direct derivation this condition 
may not hold, it turns out that in this setting parallel direct derivations can 
P1+ 2 
Pl+ 2 

176 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
express a higher degree of concurrency with respect to derivation sequences, 
because there are parallel direct derivations that do not have an equivalent 
interleaving sequence. On the other hand, G % HI 
X can be put in 
parallel if the second direct derivation is weakly sequentially independent of 
the first one. 
3.2.3 
Systems are usually not monolithic, but consist of a number of subsystems 
which may be specified and implemented separately. After defining each sub- 
system over its own local state space, they have to be joined together in order 
to build the whole system. Then the local computations of each subsystem 
have to be embedded into the computations of the enclosing system. 
Speaking about derivations, p = (Go 3 
... % G,) is embedded into a 
derivation 6 = ( X O  3 
... a 
X,) if both have the same length n and 
each graph G, of p is embedded into the corresponding graph X ,  of 6 in a 
compatible way. The embedding is represented by a family of injections (G, 
X,),Efo, 
denoted by p --% 6. If it exists, it is uniquely determined by the 
first injection eo : Go t 
XO. Given p and eo, the following problem asks under 
which conditions there is a derivation 6 such that eo induces an embedding e 
of p into 6. 
Embedding of Derivations and Derived Productions 
Problem 3.2.3 (Embedding) 
Find an embedding condition such that, for a given derivation p = (Go % 
... 3 
G,), an injection eo : Go t 
Xo satisfies this condition iff there is a 
0 
derivation 6 = (XO 3 
. . . -211 X,) and an embedding e : p t 
6. 
Let us consider the simpler problem of embedding a direct derivation G & H 
along an injection eo : G t 
X first. According to our general introduction, the 
direct derivation of Figure 3.2 defines a cc-production p* : G y-f H ,  relating 
the given and the derived graphs. The injection eo : G t X provides us 
with a match for this directly derived production p*. The embedding condition 
for G 
H is now equivalent to the applicability of the directly derived 
production p* at the match eo. 

3.2. OVERVIEW OF THE ALGEBRAIC APPROACHES 
177 
This idea can be generalized to derivations of arbitrary length: Given p = 
(Go 
... % G,), we have to define a derived production p* : Go u-t G, 
that is applicable at an injective match Go 3 X O  if and only if eo induces an 
embedding e of p into a derivation S. 
Problem 3.2.4 (Derived Production) 
Let p = (Go 3 
... % G,) be a derivation. Find a derived production 
p* : Go + G, such that for each injection Go 3 X O  there is a direct derivation 
Xo & X ,  at eo iff eo induces an embedding e : p -+ 6 of p into a derivation 
0 
In order to obtain this derived production we will introduce a sequential com- 
position p1;pz of two productions pl : L1 + R1 and p2 : L2 u-t Rz with 
R1 = Lz. Then we define the derived production p* for a given derivation 
sequenceGo&...%G, 
byp*=p;; . . . ; p c .  
The embedding condition of Go 3 
... % G, for eo is equivalent to the 
applicability of the derived production p* at this match. In the DPO approach 
this means that eo has to satisfy the gluing condition for p* , which in this case 
reduces to the dangling condition, since the identification condition is ensured 
by the injectivity of eo. In the SPO approach, instead, the embedding is always 
possible since SPO derivations do not need any application conditions. 
There are other interesting applications for derived productions and deriva- 
tions. First they can be used to shortcut derivation sequences. Thereby they 
reduce the number of intermediate graphs to be constructed and fix the in- 
teraction of the productions applied in the sequence. Similar to a database 
transaction we obtain an “all-or-nothing” semantics: The single actions de- 
scribed by the direct derivations are either performed together (the derived 
production is applied) or they leave the current state unchanged (the derived 
production is not applicable). Due to the absence of intermediate states the 
transaction may not be interrupted by other actions. 
In parallel and concurrent systems intermediate states correspond to synchro- 
nization points. A parallel derivation sequence, as introduced in Section 3.2.2, 
may be seen as a synchronous computation: Several independent processors 
perform a direct derivation each and wait for the next clock tick to establish 
a global intermediate state. Then they proceed with the next application. The 
derived production forgets about these synchronization points. Therefore it 
may perform even sequentially dependent derivations in a single step. 
The representation of derivations by derived productions, however, is not at 
all minimal. Given a derivation 6, each derivation p that can be embedded into 
S = (XO 3 
. . . s X,). 

178 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
6 defines a derived production which can simulate the effect of p. If we look 
for a more compact representation, we can take all those derived productions 
corresponding to derivations p which are minimal w.r.t. the embedding rela- 
tion. We speak of minimal derived productions. Intuitively, the minimal derived 
production of a derivation p does not contain any context but is constructed 
from the elements of the productions of p, only. 
3.2.4 
Amalgamation and Distribution 
According to Subsection 3.2.2, truly parallel computation steps can be mod- 
eled by the application of a parallel production, constructed as the disjoint 
union of two elementary productions. This provides us with a notion of par- 
allel composition of productions and derivations. In many specification and 
programming languages for concurrent and distributed systems, however, such 
a parallel composition is equipped with some synchronization mechanism in 
order to allow for cooperation of the actions that are put in parallel. If two 
graph productions shall not work concurrently but cooperatively, they have to 
synchronize their applications w.r.t. commonly accessed elements in the graph: 
A common subproduction specifies the shared effect of the two productions. 
This general idea is used in this subsection in two different ways. First we con- 
sider systems with global states, represented as graphs in the usual way. In this 
setting the synchronized application of two subproduction-related productions 
may be described by the application of a so-called amalgamated production, 
i.e., the gluing of the elementary productions w.r.t. the common subproduc- 
tion. In the second part we consider distributed states, where each production 
is applied to one local state, such that synchronized local derivations define a 
distributed derivation. 
Amalgamat ion 
The synchronization of two productions pl and p2 is expressed by a subproduc- 
tion PO which is somehow embedded into pl and pa, The synchronized produc- 
tions are then denoted by pl 
PO + pa. They may be glued along P O ,  leading 
to the amalgamated production pl eP0 
pa. A direct derivation G 
==$ 
H 
using pl BPO 
p2 is called amalgamated derivation. It may be seen as the simul- 
taneous application of pl and p2 where the common action described by the 
subproduction PO is performed only once. If the subproduction po is empty, 
the amalgamated production pl eP0 
p2 specializes to the parallel production 
Pl f P 2 .  
g2 
P l a p  PZ 

3.2. OVERVIEW OF THE ALGEBRAIC APPROACHES 
179 
Distribution 
Like an amalgamated production is somehow distributed over two synchronized 
productions, a graph representing a certain system state can be splitted into 
local graphs, too. A distributed graph DG = (GI e Go 4 
G2) consists of two 
local graphs G1 and G2 that share a common interface graph Go, embedded 
into G1 and G2 by graph morphisms g1 and g2, respectively. Gluing G1 and 
G2 along Go yields the global graph @DG = G1 @c0 G2 of DG. Then DG is 
also called a splitting of BDG. The embeddings g1 , g2 of the interface into the 
local graphs may be either total or partial; accordingly we call DG a total or a 
partial splitting. A partial splitting models a distributed state where the local 
states have been updated in an inconsistent way, which may result from a loss 
of synchronization of the local updates. Imagine, for example, a vertex v that is 
shared by the two local graphs, i.e., which is in GI , G2, and in the interface Go. 
If this vertex is deleted from the local graph G1 but not from the interface Go, 
the embedding g1 : Go -+ GI becomes undefined for the vertex v, i.e., the two 
local states have inconsistent information about their shared substate. Then, 
the global graph @.DG of this partial splitting does not contain the vertex 21, 
but only those elements where the local informations are consistent with each 
other. 
Distributed graphs can be transformed by synchronized productions: Given 
local direct derivations di = (Gi 3 
Hi) for i E {0,1,2} which are compatible 
with the splitting GI 
Go 4 
G2, do becomes a subderivation of dl and dz. In 
this case, the (direct) distributed derivation dlIIdod2 : DG ==+ DH transforms 
the given distributed graph DG into the new one DH = (HI & HO 9 H2). The 
distributed derivation is synchronous if both DG and DH are total splittings. 
Now, since synchronized rules can be amalgamated and distributed graphs may 
be glued together, it seems natural to simulate a distributed derivation by an 
amalgamated one. Vice versa, assuming a splitting of the global graph, we may 
want to distribute a given amalgamated derivation. The corresponding condi- 
tions, enabling these constructions, are called amalgamation and distribution 
condition, respectively. 
Problem 3.2.5 (Distribution) 
Let DG = (GI 
synchronized productions. 
Go 4 G2) be a distributed graph and pl $ po % p2 be 
1. Find an amalgamation condition such that a distributed derivation 
dllldod2 : DG =+ DH with di = (Gi 3 
Hi) satisfies this condition 
iff there is an equivalent amalgamated derivation @DG 
Pl@p P2 BDH. 

180 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
2. Find a distribution condition such that an amalgamated derivation 
G & H satisfies this condition iff there is an equivalent distrib- 
uted derivation dl(ldod2 : DG * 
D H  with G = BDG, H = @DH and 
PI% 
PZ 
d, = (Gi 
Hi). 
0 
Simulating a distributed derivation by an amalgamated one means to observe 
some local activities from a global point of view. Since for asynchronous sys- 
tems such a global view does not always exist, it is not too surprising that the 
amalgamation construction in 1. is only defined if the given distributed graph 
is a total splitting, i.e., represents a consistent distributed state. In order to 
distribute an amalgamated derivation, the match of the amalgamated produc- 
tion has to be splitted as well. Such a splitting may not exist if the matches of 
the elementary productions are not in their corresponding local graphs. If the 
distributed derivation shall be synchronous, we need an additional condition, 
which can be seen as a distributed dangling condition. It takes care that noth- 
ing is deleted in any local component which is in the image of some interface, 
unless its preimage is deleted as well. 
3.2.5 Further Problems and Results 
This subsection is an overview of some further issues, problems and results 
addressed in the literature of the algebraic approaches. 
Semantics 
If a graph grammar is considered from the point of view of formal languages, its 
usual semantics is the class of graphs derivable from the start graph using the 
productions of the grammar, its generated language. Using graph grammars for 
specification of systems, however, we are not only interested in the generated 
graphs, corresponding to the states of the system, but also in the derivations, 
i.e., the systems computations. There are several proposals for semantics of 
graph grammars that represent graphs and derivations at different levels of 
abstraction. 

3.2. OVERVIEW OF THE ALGEBRAIC APPROACHES 
181 
0 A model of computation of a graph grammar is a category having graphs 
as objects and derivations as arrows. Different models of computations 
can be defined for a grammar, by imposing different equivalence relations 
on graphs and derivations. The main problem in this framework is to 
find an adequate notion of equivalence on graphs and derivations, that 
provides representation independence as well as abstraction of the order 
of independent (concurrent) derivation steps. Models of computations for 
grammars in the DPO are introduced in Section 3.5. 
Processes are well-accepted as a truly concurrent semantics for Petri nets 
(see for example [22]), and such a semantics has been defined for both 
algebraic approaches to graph grammars as well, using slightly different 
terminologies. In a graph process (DPO) or concurrent derivation (SPO), 
the graphs of a derivation are no longer represented explicitly. Instead 
a so-called type graph (DPO) or core graph (SPO) is constructed by 
collecting all nodes and edges of the derivation. Moreover, the linear or- 
dering of the direct derivations is replaced by a partial order representing 
the causal dependencies among the production applications, or actions 
(SPO). DPO processes and SPO concurrent derivations are introduced 
in [23] and [24,25], respectively. 
An event structure [26] consists of a collection of events together with 
two relations “5” and “#” modeling causal dependency and mutual 
exclusion, respectively. Event structures are widely accepted as ab- 
stract semantic domains for systems that exhibit concurrency and non- 
determinism. Such a truly concurrent semantics is more abstract than 
the one based on processes, where it is still possible to reconstruct the 
graphs belonging to a derivation (from the type or core graph), while 
this is not possible from the event structure. Event structure semantics 
have been proposed for the double-pushout approach in [27,28,29]. 
Control 
In order to specify systems with a meaningful behavior it is important that 
the application of productions can be controlled somehow. 
0 Application conditions restrict the applicability of individual productions 
by describing the admissible matches. In the SPO approach they are 
considered in some detail in Section 4.4. 
0 Imperative control structures like sequential composition, iteration, non- 
deterministic choice, etc, lead to the notions of programmed graph trans- 
formation and transactions. Such concepts are discussed, for example, in 
Chapter 7, while in the algebraic approaches they have been introduced 
in [30]. 

182 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
Structuring 
Systems usually consists of a number of subsystems, which are specified sep- 
arately and have some meaning in their own right. Structuring mechanisms 
for graph transformation systems based on colimits in the category of graph 
grammars are investigated in [31,32], and are shown to be compatible with the 
functorial semantics introduced in [33]. 
Analysis 
A main advantage of formal specification methods is the possibility of formal 
reasoning about properties of the specified systems. 
Consistency conditions describe properties of all derived graphs. The 
problem of specifying these conditions and of analyzing them w.r.t. a 
given grammar has been considered in [34,27] in the SPO approach. 
Since graph grammars generalize term rewriting systems, rewriting prop- 
erties as, for example, confluence, termination, etc., are interesting here 
as well. Corresponding results for (DPO) hypergraph rewriting can be 
found in [36,37], while confluence of critical pairs in the SPO approach 
has been studied in [38]. 
More general structures 
Different application areas of graph transformation require different notions of 
graphs. Fortunately, most of the results of the algebraic approaches are ob- 
tained on a categorical level, that is, independently of the specific definition 
of graph. Main parts of the theory have already been generalized to arbitrary 
categories of structures in high-level replacement (HLR) systems (mainly in 
the DPO approach [21], see [6] for corresponding concepts in the SPO ap- 
proach). The SPO approach has been developed for graph structures from the 
very beginning [40,5], which have recently been extended to generalized graph 
structures in [16]. 
3.3 Graph Transformation Based on the DPO Construction 
Following the outline of Section 3.2.1, in this section we introduce the formal 
definition of the very basic concepts of the double-pushout approach to graph 
transformation. This theory has been started in [l]; comprehensive tutorials 
can be found in [2,3,4]. 

3.3. GRAPH TRANSFORMATION BASED ON THE DPO CONSTR. 183 
First of all, let us introduce the class of graphs that we shall consider in the 
rest of this chapter (and also in the next one). These are labeled, directed 
multigraphs, i.e., graphs where edges and nodes are labelled over two different 
sets of labels, and between two nodes many parallel edges, even with the same 
label, are allowed for. A fundamental fact is that graphs and graph morphisms 
form a category since this allows one to formulate most of the definitions, 
constructions and results in pure categorical terms. Only seldom some spe- 
cific properties of the category of graphs are exploited, usually to present the 
concrete, set-theoretical counterpart of some abstract categorical construction. 
Definition 3.3.1 (labeled graphs) 
Given two fixed alphabets Rv and RE for node and edge labels, respectively, 
a (labeled) graph (over ( R ~ , R E ) )  is a tuple G = ( G v , G ~ , s ~ , t ~ , l v ~ , l e ~ ) ,
where Gv is a set of vertices (or nodes), GE is a set of edges (or arcs), sG, tG : 
GE + Gv are the source and target functions, and lvG : Gv + Rv and 
leG : GE + RE are the node and the edge labeling functions, respectively. 
A graph morphism f : G + G’ is a pair f = (fv : Gv + GL, fE : GE + GL) 
of functions which preserve sources, targets, and labels, i.e., which satisfies 
jv o tG = tG’ o fE, fv o sG = sG‘ o fE, I V ~ ’  
o fv = 1vG, and leG’ o f E  = leG. 
A graph morphism f is an isomorphism if both fv and fE are bijections. If 
there exists an isomorphism from graph G to graph H ,  then we write G g H ;  
moreover, [GI denotes the isomorphism class of G, i.e., [GI = { H  I H g G}. 
An automorphism of graph G is an isomorphism 4 : G + G; it is non-trivial if 
The category having labeled graphs as objects and graph morphisms as arrow 
is called Graph. 
4 # ZdG. 
Within this chapter we shall often call an isomorphism class of graphs abstract 
graph, like [GI; correspondingly, the objects of Graph will be called sometimes 
concrete graphs. 
Example 3.1 (client-server systems) 
As a running example, we will use a simple graph grammar which models 
the evolution of client-server systems. The (labeled) graphs are intended to 
represent possible configurations containing servers and clients (represented 
by nodes labeled by S and C, respectively), which can be in various states, 
indicated by edges. A loop on a server labeled by idle indicates that the server 
is ready to accept requests from clients; a loop on a client labeled by job means 
that the client is performing some internal activity, while a loop labeled by 
req means that the client issued a request. An edge from a client to a server 

184 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
Figure 3.3: (a) A sample labeled graph and (b) its isomorphism class. 
labeled by busy models the situation where the server is processing a request 
issued by the client. 
In our running example, the alphabets of labels contain only the labels just 
mentioned, thus Rv = {C,S} and 0~ = {idle, job, req, busy}. Figure 3.3(a) 
shows the graphical representation of graph G = (Gv, GE, sG, tG, lvG, leG) 
with Gv = {0,1,2,3,4}, GE = {Q,l,2,3,4}. Edges are drawn in the usual 
way as arrows from the source to the target, and the label of each node or edge 
is written after its identity, separated by a colon. We shall use natural numbers 
to denote nodes and underlined numbers to denote edges. Graph G represents 
a system with three clients and two servers, whose states are specified by the 
depicted edges. 
Figure 3.3(b) shows the graphical representation of the isomorphism class of 
graphs [GI: it is obtained from G by deleting all natural numbers, i.e., by 
forgetting the identity of nodes and edges. Their labels are kept because iso- 
morphisms must preserve labels. 
0 
A production in the double-pushout approach is usually defined as a span, i.e., 
a pair of graph morphisms with common source. In the formal definition that 
follows, a production is defined instead as a structure p : ( L  & K 4 R), where 
1 and T are the usual two morphisms, and the additional component p is the 
production name. The name of a production plays no role when a production 
is applied to a graph (see Definition 3.3.5 of direct derivation below), but it is 
relevant in certain transformations of derivations (as in the analysis construc- 
tion, Proposition 3.4.8) and when relating different derivations (as in Definition 
3.5.10); in fact, since the name will often be used to encode the construction 
that yields the production, it allows one to distinguish, for example, between 
two productions obtained in completely unrelated ways, but that happen to 
have the same associated span. Thus on the one hand we insist that the name 
is a relevant part of a productions, but, on the other hand, when applying a 
production to a graph the name is sometimes disregarded. 

3.3. GRAPH TRANSFORMATION BASED ON THE DPO CONSTR. 185 
Definition 3.3.2 (graph productions, graph grammars) 
A graph production p : ( L  t K 4 R) is composed of a production n a m e  p 
and a pair of injective graph morphisms 1 : K -+ L and r : K + R. The 
graphs L, K ,  and R are called the left-hand side (lhs), the interface, and the 
right-hand side (rhs) of p ,  respectively. Two productions p : ( L  & K < R) 
and p’ : (L’ t K‘ 5 R’) are span-isomorphic if there are three isomorphisms 
L % L’, K % K’ and R % R’ that make the two resulting squares 
commutative, i.e., 4~ 
o 1 = 1’ o 4~ and 4~ o r = r’ o 4 ~ .  
If no confusion is 
possible, we will sometimes make reference to a production p : ( L  t K A R) 
simply as p ,  or also as L t K 4 R. 
A graph grammar G is a pair G = ( ( p  : L t K 4 R)pEp, 
Go) where the first 
component is a family of productions indexed by production names in P, and 
Go is the start graph. 
1 
I’ 
1 
1 
1 
Suppose (without loss of generality) that in a production p : ( L  tk K < R) 
morphisms 1 and r are inclusions. Then, intuitively, the production specifies 
that all the items in K have to be preserved (in fact, they are both in L and 
in R); that the items of L which are not in K have to be deleted, and that the 
items in R which are not in K have to be created. 
Example 3.2 (graph grammar for client-server systems) 
The graph grammar which models the evolution of client-server systems de- 
picted as labeled graphs (as in Example 3.1) includes three productions, named 
REQ, SER, and REL, respectively, which are presented in Figure 3.4. Produc- 
tion REQ models the issuing of a request by a client. After producing the 
request, the client continues its internal activity (job), while the request is 
served asynchronously; thus a request can be issued at any time, even if other 
requests are pending or if the client is being served by a server. Production 
SER connects a client that issued a request with an idle server through a busy 
edge, modeling the beginning of the service. Production REL (for release) dis- 
connect the client from the server (modeling the end of the service), restoring 
the idle state of the server. 
It is worth stressing that the three productions neither delete nor create nodes, 
which means that the number of clients and servers is invariant. The interface of 
each production is a subgraph of both the left- and the right-hand sides, thus 
bUsually the definition of a grammar also includes a set of terminal labels, used to identify 
the graphs belonging to the generated language. Since we are not directly interested in graph 
languages, we omit them. 

186 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
REQ : 
1:s 
IS 
1:idle 
SER : 
busy 
13 
GO pJ 
1:idle 
Figure 3.4: Productions and start graph of the grammar modeling a client-server systems. 
Figure 3.5: Direct derivation as double-pushout construction. 
the morphisms are just inclusions. Note moreover that the natural numbers 
used as identities of nodes and edges are chosen arbitrarily. 
Formally, the grammar is called C-S (for client-server), and it is defined as 
C-S = ({REQ, SER, REL}, Go), where Go is the start graph depicted in Figure 
3.4. 
0 
Given a production p : ( L  t K 4 R) and a graph G, one can try to apply p 
to G if there is an occurrence of L in GI i.e., a graph morphism, called match, 
m : L + G. If p is applicable to match m yielding a graph H ,  then we obtain 
a direct derivation G 
H .  Such a direct derivation is a “double-pushout 
construction” , the construction that characterizes the algebraic approach we 
are presenting, and it is shown in Figure 3.5. 
Intuitively, regarding graphs as distributed states of a system, a pushout is 
a sort of “generalized union” that specifies how to merge together two states 
having a common substate [42]. For example, if the right square of Figure 3.5 
is a pushout in Graph, then graph H is obtained by gluing together graphs 
2 

3.3. GRAPH TRANSFORMATION BASED ON THE DPO CONSTR. 187 
R and D along the common subgraph K ,  and r* and m* are the resulting 
injections. 
Therefore the double-pushout construction can be interpreted as follows. In 
order to apply the production p to G, we first need to find an occurrence of its 
left-hand side L in G, i.e., a match m : L t 
G. Next, we have to delete from 
G all the (images of) items of L which are not in the interface graph K ;  in 
other words, we have to find a graph D and morphisms d and 1* such that the 
resulting square is a pushout: The context graph D is therefore required to be a 
pushout complement object of (1, m). Finally, we have to embed the right-hand 
side R into D ,  to model the addition to D of the items to be created, i.e., those 
that are in R but not in K :  This embedding is expressed by the right pushout. 
In order to introduce this construction formally we first have to define pushouts 
and pushout complements. It is worth stressing that the advantage of describ- 
ing such operation via a categorical construction instead of using standard 
set-theoretical notions is two-fold. On the one hand, in a set-theoretical frame- 
work one needs to handle explicitly the possible clashing of names used in the 
two states (in the non-shared parts): this is given for free in the categorical 
construction, at the price of determining the result only up to isomorphism. On 
the other hand, category theory provides handy techniques, based for example 
on diagram chasing, for describing and relating complex constructions, that it 
would be quite cumbersome to handle using standard set theory. 
Definition 3.3.3 (pushout [18] and pushout complement [2]) 
Given a category C and two arrows b : A -+ B, c : A t 
G of C ,  a triple 
(D, g : B + D ,  f : C -+ D )  as in the diagram below is called a pushout of (b, c) 
if 
[Commutativity] g o b = f 0 c, and 
[Universal Property] for all objects D' and arrows g' : B t D' and f' : 
C -+ D', with g' o b = f' o c, there exists a unique arrow h : D t 
D' such 
that h o g = g' and h o f = f'. 

188 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
In this situation, D is called a pushout object of (b, c). Moreover, given arrows 
b : A + B and g : B + D, 
a pushout complement of (b,g) is a triple (C,c : 
A -+ C, f : C -+ D) 
such that (D,g, 
f) is a pushout of (b,c). In this case C is 
called a pushout complement object of (b, 9). 
Example 3.3 (Pushout in Set and in Graph) 
The paradigmatic example of category is Set, i.e., the category having sets as 
objects and total functions as arrows. It is easy to show that the pushout of two 
arrows in Set always exists, and that it is characterized (up to isomorphism) 
as follows. If b : A + B and c : A + C are two functions, then the pushout 
object of (b,c) is the set D = (B + C)=, i.e., the quotient set of the disjoint 
union of B and C ,  modulo the equivalence relation ''&, which is the least 
equivalence relation such that for all a E A, b(a) M c(a), together with the two 
functions g : B -+ D and f : C + D that map each element to its equivalence 
class. 
(a) 
(b) 
In category Graph the pushout of two arrows always exists as well: It can be 
computed componentwise (as a pushout in Set) for the nodes and for the edges, 
and the source, target, and labeling mappings are uniquely determined. The 
above diagrams show two examples. In (a) morphisms b and c are inclusions, 
thus the pushout object D is obtained by gluing B and C on the common 
subgraph A. Diagram (b), where all morphisms are specified by listing the 
pairs argument-result (e.g., bv(0) = 4 and c ~ ( 1 )  
= 5), shows instead a pushout 
0 
in Graph of two non-injective morphisms b and c. 
In any category, if the pushout object of two arrows exists then it is unique up to 
a unique isomorphism because of the universal property (see Fact 3.8.2 for the 
corresponding statement for coproducts). On the contrary, since the pushout 

3.3. GRAPH TRANSFORMATION BASED ON THE DPO CONSTR. 189 
complement object is not characterized directly by a universal property, for 
a pair of arrows there may not be any coproduct, or there can exist many 
pushout complement objects which are not isomorphic. For example, consider 
the diagrams below in the category of sets and functions. For the left diagram, 
there exist no set and functions which can close the square making it a pushout, 
while in the right diagram there exist two pushout complement objects C and 
C’ which are not isomorphic. 
I 
I 
I 
V x - - - - -> 
B 
C 
D 
The characterization of sufficient conditions for the existence and uniqueness of 
the pushout complement of two arrows is a central topic in the algebraic theory 
of graph grammars, because, as we shall see below, in the DPO approach it 
allows one to check for the applicability of a production to a given match. As 
shown for example in [a], in category Graph, the pushout complement object 
of two morphisms (b, g) exists iff the gEuing condition is satisfied; moreover, it 
is unique if b is injective. 
Proposition 3.3.4 (existence of pushout complements) 
Let b : A t B and g : B t D be two morphisms in Graph. Then there exists 
a pushout complement (C, c : A + C, f : C t D )  of ( b , g )  if and only if the 
following conditions are satisfied: 
[Dangling condition] No edge e E DE - g E ( B E )  is incident to any node in 
g v p v  - bv(Av)); 
g(z) = g(y) and Y $ b(Av U AE). 
[Identification condition] There is no x,y E Bv U BE such that x # y, 
In this case we say that ( b , g )  satisfy the gluing condition (or g satisfies the 
gluing condition with respect to b). I f  moreover morphism b is injective,then 
the pushout complement is unique up to isomorphism, i.e., if (C,c, f) and 
(C’, c’, f’) are two pushout complements of (b, g ) ,  then there is an isomorphism 
0 
6 : C t C‘ such that q5 o c = c’ and f’ o q!~ = f. 

190 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
0 - 5  
C 
4 
2:c a4] 
B 
D 
REQ : 
@% 
1 :req 
m JI"Q 
Q: job 
@ 
3 
1:idle - 
GO 
d 1 0 - 4  
4::: 
-- J/ 
1 :idle 
GI 
Figure 3.6: (a) Pushout complement in Graph. (b) A direct derivation. 
Example 3.4 
Morphisms (b,g) of Figure 3.6 (a) satisfy the dangling condition, because the 
only edge incident to node 6 : S (which is in gv(Bv - bv(Av))) is 4 : busy, 
which is not in DE - ~ E ( B E ) .  
They also satisfy the identification condition 
because the only items identified by 9, nodes 2 : C and 3 : C, are in the 
image of b. Since b is injective, a pushout complement object of (b,g) is given 
by C = D - g ( B  - b(A)), i.e., it is the subgraph of D obtained by removing 
all items that are in the image of g but not in the image of g o b. Morphism 
C --+ D is the inclusion, and A 4 C is the (codomain) restriction of g to C. 
0 
f 
Definition 3.3.5 (direct derivation) 
Given a graph G, a graph production p : ( L  k K 4 R), and a match m : L + 
G, a direct derivation f r o m  G to H u s i n g p  (based o n  m) exists if and only if the 
diagram in Figure 3.5 can be constructed, where both squares are required to 
be pushouts in Graph. In this case, D is called the context graph, and we write 
H ,  
G 3 
H ,  or also G 
indicating explicitly all the morphisms of the double-pushout. 
( p , m , d  m * J * , T * )  
+ 
H ;  only seldom we shall write G 

3.4. INDEPENDENCE AND PARALLELISM IN THE DPO APPROACH191 
REQ 
Example 3.5 
Figure 3.6 (b) shows the direct derivation Go + GI. All horizontal mor- 
phisms are inclusions. The vertical morphisms are instead depicted explicitly 
by listing enough pairs argument-result (for example, the morphism from the 
right-hand side of the production to graph GI, denoted by {2-2,1-3}, 
maps 
edges 2 and 1 to edges 2 and 3, respectively, and therefore node 0 to node 4). 
Morphisms (1, m) obviously satisfy the dangling condition because no node is 
deleted by REQ, and also the identification condition because m is injective. 
Graph D is the pushout complement object of (Z,m), and G1 is the pushout 
object of (r, d). 
0 
Definition 3.3.6 (sequential derivations) 
A sequential derivation (over G) is either a graph G (called an identity 
derivation, and denoted by G : G J* 
G), or a sequence of direct deriva- 
tions p = (Gi-1 
for all 
i E (1,. . . , n}. In the last case, the derivation is written p : Go +-; G, or 
simply p : Go J* 
G,. If p : G J* 
H is a (possibly identity) derivation, then 
graphs G and H are called the starting and the ending graph of p, and will be 
denoted by a(p) and ~ ( p ) ,  
respectively. The length of a sequential derivation p 
is the number of direct derivations in p, if it is not identity, and 0 otherwise. 
The sequential composition of two derivations p and p' is defined if and only if 
~ ( p )  
= a(p'); in this case it is denoted p ;  p' : a(p) J* 
~ ( p ' ) ,  
and it is obtained 
by identifying ~ ( p )  
with a(p'). 
The identity derivation G : G J* G is ihtroduced just for technical reasons. 
By the definition of sequential composition, it follows that for each derivation 
p : G + *  H w e h a v e G ; p = p = p ; H .  
Example 3.6 (derivation) 
Figure 3.7 shows a sequential derivation using grammar C-S and starting from 
the start graph Go. The derivation models the situation where a request is 
issued by the client, and while it is handled by the server, a new request is 
issued. 
CI 
Gi}2Eil,,.,,5x} 
such that pi is a production of 
3.4 
According to the overview of Section 3.2.1 we have to define two notions of 
independence on direct derivations formalizing the following concepts: 
Independence and Parallelism in the DPO approach 
p2 mz 
two alternative direct derivations H1 'e 
G + Hz are not in conflict 
(parallel independence), and 

192 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
SER : 
Figure 3.7: A sequential derivation in grammar C-S starting from graph Go. 
P I  ,ml 
~
2
,
4
 
two consecutive direct derivations G ==+ 
H1 * X are not causally 
dependent (sequential independence). 
Intuitively, two alternative direct derivations are parallel independent (of each 
other), if each of them can still be applied after the other one has been per- 
formed. This means that neither G 's 
HI nor G '= H2 can delete elements 
of G which are also needed by the other direct derivation. In other words, the 
overlapping of the left-hand sides of p1 and p2 in G must be included in the 
intersection of the corresponding interface graphs K1 and K2. 
Definition 3.4.1 (parallel independence) 
Let G pq 
H1 and G 'g 
HZ be two direct derivations from the same 
graph G, as in Figure 3.8. They are parallel independent if ml (L1) nmz(L2) 5 
This property can be formulated in categorical terms in the following way: 
There exist two graph morphisms L1 --% Dz and La --% D1 such that 1% olcz = 
ml and 1; o Icl = m2. 
Two consecutive direct derivations G '* 
H1 '3 
X are sequentially inde- 
pendent if they may be swapped, i.e., if p2 can be applied to G, and pl to the 
resulting graph. Therefore p2 at match m2 cannot delete anything that has 
been explicitly preserved by the application of pl at match ml , and, moreover, 
it cannot use (neither consuming nor preserving it) any element generated by 
ml(ll(K1)) n mz(h.(Kz)). 
k 
k 

3.4. INDEPENDENCE AND PARALLELISM 
193 
Figure 3.8: Parallel independence of direct derivations 
Li + l 1 -  
Ki -TI 
+ Ri -, 
L2 --l2 - 
K2 --Tz 
+ R2 
Dz --T; 
+ Hz 
G+-l;-Di- 
T ;  -Hi 
-12 
~ 
\ /  
Figure 3.9: Sequential independent derivation. 
p l ;  this implies that the overlapping of R1 and LZ in HI must be included in 
the intersection of the interface graphs K1 and K2. 
Definition 3.4.2 (sequential independence) 
p2 mz 
Given a two-step derivation G ’3 H1 + H2 (as in Figure 3.9), it is 
sequential independent iff mT(R1) n m2(L2) L rn;(rl(Kl)) n mz(Z2(K2)). 
This property can be formulated also in categorical terms in the following 
way: There exist two graph morphisms R1 --% 0 2  and L2 4 
D1 such that 
1; o k2 = m; and I-; 
o kl = m2. 
k 
k 
Example 3.7 (sequential independence) 
Consider the derivation of Figure 3.7. The first two direct derivations are se- 
quential dependent; in fact, the edge 3:req of graph G1 is in the image of both 
the right-hand side of the first production and the left-hand side of the second 
one, but it is in the context of neither the first nor the second direct derivation: 
Thus the required morphisms for sequential independence do not exist. On the 

194 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
contrary, in the same figure both the derivation from GI to G3 and that from 
G2 to Gq are sequential independent, and the required morphisms are obvious. 
0 
The following theorem says that these two definitions of parallel and sequential 
independence indeed solve the Local Church-Rosser Problem of Section 3.2.2 
in the DPO approach. 
Theorem 3.4.3 (Local Church Rosser) 
1. Let G '@ H1 and G p* 
H2 be two parallel independent direct deriva- 
tions, as in Figure 3.8, and let m(2 = r; 0 kl , where arrow Lz 4 
D1 exists 
by parallel independence. Then morphisms ( 1 2 ,  m(2) satisfy the gluing con- 
dition, and thus production p2 can be applied to match m(2. Moreover, 
derivation G '3 
H1 
k 
P2 m; X is sequential independent. 
2. Let G p% 
H1 '3 
H2 be a sequential independent derivation as in Fig- 
ure 3.9, and let m(2 = 1; o k1, where arrow L2 
D1 exists by sequential 
independence. Then morphisms (12, mh) satisfy the gluing condition, and 
thus production p2 can be applied to match m(2. Moreover, direct deriva- 
0 
tions G p
*
 
H1 and G 3 Y are parallel independent. 
The proof of the Local Church Rosser theorem is postponed, because it follows 
easily from the proof of the Parallelism Theorem presented later. 
The notion of direct derivation introduced in Definition 3.3.5 is intrinsically 
sequential: it models the application of a single production of a grammar 4 
to a given graph. The categorical framework provides an easy definition of 
the parallel application of more than one production to a graph. The follow- 
ing definition of parallel production is slightly more complex than analogous 
definitions previously presented in the literature, which only used a binary, 
commutative and associative operator "+" on productions. Such a complexity 
is justified by the result reported in Section 3.8, where it is shown that the 
coproduct cannot be assumed to be commutative (in a strict way), unless the 
category is a preorder. 
Definition 3.4.4 (parallel productions) 
Given a graph grammar 4, a parallel production (over 4) has the form 
((pl,znl), . . . , (pk,ink)) : ( L  & K 
R) (see Figure 3.10), where k 2 0, 
pi : (L, tr_ Ki 3 Ri) is a production of G for each i E { 1 , .  . . , k } ,  L is a 
k 
p 2 , 7 4  
1 

3.4. INDEPENDENCE AND PARALLELISM 
195 
1 
Figure 3.10: The parallel production ((pl,in'), . .. , ( p k , z n k ) )  : ( L  t K 4 R). 
coproduct object" of the graphs in (L1,. . . , Lk), and similarly R and K are 
coproduct objects of (R1,. . . , Rk) and (K1,. . . , Kk), respectively. Moreover, 1 
and r are uniquely determined by the families of arrows {Zi}isk and { r i } i < k ,  
respectively (they are defined in a way similar to morphism f + g of Defini- 
tion 3.8.3). Finally, for each i E { 1, . . . , Ic}, in2 denotes the triple of injections 
(in; : Li -+ L,inh : Ki -+ K,inL : Ri + R). Note that all the component 
productions are recorded in the name of a parallel production. 
A parallel production like the one above is proper if Ic > 1; the empty production 
is the (only) parallel production with k = 0, having the empty graph 8 as left- 
and right-hand sides and as interface. Each production p : ( L  &- K & R )  of 
G will be identified with the parallel production ((p, ( i d ~ , i d ~ ,  
 id^))) : ( L  & 
K 4 R). 
Two parallel productions over G, p = ( ( P I  , in'), . . . , ( p k ,  in')) : ( L  t K 
R )  
and q = ( ( q l , h l ) ,  . . . , ( q k , , & k ' ) )  : (L' t K' 5 
R'), are isomorphic via n if 
k = k' and II is a permutation of (1,. . . , k }  such that and pi = qn(i) for each 
i E (1,. . . , k}; that is, the component productions of G are the same, up to 
a permutation. We say that p and q are isomorphic if there is a II such that 
they are isomorphic via II. 
The graph grammar with parallel productions G+ generated by a grammar G has 
the same start graph of G, and as productions all the parallel productions over 
G. A parallel direct derivation over G is a direct derivation over G+; it is proper 
or empty if the applied parallel production is proper or empty, respectively. 
If G j 
H is an empty direct derivation, then morphisms 1* and I-* are 
isomorphisms (see Figure 3.5); morphism r* 0 1*-l : G + H is called the 
isomorphism induced by the empty direct derivation. 
A parallel derivation over G is a sequential derivation over G+. 
1 
1' 
0 
CBinary coproducts are introduced in Definition 3.8.1. The generalization to arbitrary 
coproducts is straightforward. The coproduct of a list of graphs is given by their disjoint 
union (the coproduct object) and by all the injections. 

196 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
It is worth noting that two isomorphic parallel productions are, a fortiori, 
span-isomorphic (see Definition 3.3.2). 
Fact 3.4.5 (isomorphic parallel 
Let ( ( p l , i n l ) ,  . . . , (pk,ink)) : ( L  t K 4 R) and ( ( q l , h l ) ,  . . . , ( q k , h k ) )  : 
(L’ $ K’ < R’) be two parallel productions isomorphic via II. Then they are 
roductions are span-isomorphic) 
P 
span-isomorphic. 
0 
Proof 
By definition, we have that for each X E { L ,  K ,  R}, ( X ,  ink,. . . , in:) 
and 
(X‘,ink,. . . , i~&) are two coproducts of the same objects, and thus there is 
a unique isomorphism X % X‘ which commutes with the injections (see Fact 
3.8.2). It can be shown easily that these isomorphisms satisfy 4~ 0 1 = I’ o 4~ 
0 
In the rest of the chapter we will assume, without loss of generality, that a 
LLcanonical” choice of coproducts is given once and for all, i.e., a mapping as- 
sociating with every pair of graphs (A, B) a fixed coproduct ( A  + B, 
: 
A -+ A + B,in,A+B : B -+ A + B )  (see Definitions 3.8.1 and 3.8.3). Then for 
each pair of parallel productions p : ( L  t K 4 R) and p’ : (L’ c K’ < R’), 
where p = ( ( p l ,  in’), . . . , (pk, ink)) and p’ = ( ( p i ,  in’l), . . . , ( p i , ,  in’“)) we de- 
note by p + p’ the parallel production ( ( P I ,  in o in’), . . . , ( p k  , in o ink), ( p i ,  in’ o 
in“), . . . , (pi,, in‘ o in‘”)) : ( L  + L’ I?’ 
K + K‘ ’7’ 
R + R’), where ‘+’ is the 
coproduct functor induced by the choice of coproducts (Definition 3.8.3), and 
in and in’ are triples of canonical injections. Moreover, given a list 071, . . . , p k )  
of parallel productions of G, by pl +p2 + . . . +pk we denote the parallel produc- 
tion ((. , . (pl +pz) +. . . ) + p k ) .  Note that the + operator on productions defined 
in this way is in general neither associative nor commutative: such properties 
would depend on analogous properties of the choice of coproducts. Neverthe- 
less, it is obvious that + is associative and commutative “up to isomorphism”, 
in the sense that, for example, productions p + p’ and p’ + p are isomorphic. 
The canonical choice of coproducts is assumed here only to simplify the syntax 
of parallel productions: it does not imply that coproducts are unique (see also 
Proposition 3.8.6 and Corollary 3.8.7). 
and 4~ o r = r’ o 4 ~ .  
1 
Example 3.8 (parallel direct derivation) 
Figure 3.11 shows a parallel direct derivation based on the productions of 
Example 3.2. The upper part of the diagram shows the parallel production SER 
+ REQ. The component productions SER and REQ and the corresponding 

3.4. INDEPENDENCE AND PARALLELISM 
197 
J::: 
2 - A  
l : r e q  2:jot 
GI 
Figure 3.11: A parallel direct de ivation via a non-injective match. 
inclusions are not depicted explicitly in order to simplify the drawing; anyway, 
it is easy to recognize in the parallel production the isomorphic copies of SER 
and REQ. 
The parallel production SER + REQ is applied to graph GI via a non-injective 
match. This direct derivation models the situation where a new request is issued 
by client 4 exactly when the service of an older request is started by server 5. 
0 
Let us consider now Problem 3.2.2 of Section 3.2.2, asking under which con- 
ditions a parallel direct derivation can be sequentialized into the application 
of the component productions, and, viceversa, under which conditions the se- 
quential application of two (or more) productions can be put in parallel. As 
the following Parallelism Theorem states, such conditions are nothing else than 
the parallel and sequential independence conditions already introduced. More 
precisely, it states that the sequentialization condition is already part of the 
gluing condition of the parallel production, that is, each parallel direct deriva- 
tion may be sequentialized in an arbitrary order leading to sequentially inde- 
pendent derivations. Vice versa, the parallelization condition is the sequential 
independence of the derivation, since consecutive direct derivations can be put 
in parallel if they are sequentially independent. 
Theorem 3.4.6 (Parallelism) 
Given (possiblyparallel) productionspl : (L, & K1 3 R1) andpz : (L2 & 
KZ 3 R2) the following statements are equivalent: 
1 

198 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
Pl+P 
m 
1. There is a parallel direct derivation G &' 
X 
2. There is a sequentially independent derivation G ==+ HI * X 
p l  )ml 
PZ >mk 
The rest of this section is devoted to the proofs of the Parallelism and of 
the Local Church Rosser Theorems, and to the presentation of some technical 
results that will be used in the next section. First of all, let us clarify the 
relationship between a match of a parallel production and the induced matches 
of the component productions. 
Proposition 3.4.7 (applicability of parallel productions) 
Let q = ( ( p l ,  in'), . . . , (p', in')) : (L tk K 
R) be a parallel production (see 
Definition 3.4.4), and let L 3 G be a match for it. For each i E (1,. . . , k } ,  
let Li 3 G be the match of the i-th production in G induced by m, 
defined 
as mi = m o ini. 
Then (I, m) satisfies the gluing condition, i.e., there is a parallel direct deriva- 
tion G 
H ,  if and only if for all i E (1,. . . , k }  (li, mi) satisfies the gluing 
condition, i.e., pi can be applied at match mi, say with result Hi, and for each 
1 5 i < j 5 k ,  direct derivations G '3 
Hi and G 
Hj are parallel 
independent. 
Proof outline 
The parallel independence of the matches of the composing productions follows 
from the gluing conditions of the parallel direct derivations, and viceversa. 0 
Therefore there is a very tight relationship between parallel independence and 
parallel direct derivations: different matches of productions in a graph induce a 
match of the corresponding parallel production if and only if they are pairwise 
parallel independent. It is worth stressing here that this property does not hold 
in the SPO approach, where a parallel production can be applied even if the 
induced matches are not parallel independent (as discussed in Sections 4.3.1 
and 4.6). 
The next important results state that every parallel direct derivation can be 
decomposed in an arbitrary way as the sequential application of the component 
productions, and, conversely, that every sequential independent derivation can 
be transformed into a parallel direct derivation. These constructions are in 
general non-deterministic, and will be used in Section 3.5 to define suitable 
relations among derivations. The constructive proofs of Lemmas 3.4.8 and 3.4.9 
are reported in Section 3.9 (see also [43,21]). It is worth stressing that since we 
p .  m .  

3.4. INDEPENDENCE AND PARALLELISM 
199 
do not assume commutativity of coproducts, the statements of the following 
lemmas are slightly different from the corresponding statements in the related 
literature. 
Lemma 3.4.8 (analysis of parallel direct derivations) 
Let p = (G & H )  be a parallel direct derivation using the parallel production 
q = pl + . . . + p k  : ( L  t K 4 R). Then for each ordered partition ( I  = 
(il, ... , i n ) , J = ( j 1  ,... ,jm))of{l ,... , k }  (i.e ., I U J = { l ,  ... , k } a n d I n J =  
8) there is a constructive way to obtain a sequential independent derivation 
p’ = (G ==+ X ==+ H ) ,  called an analysis of p, where q’ = pi, + . . . +pi,, and 
q” = p,, + . . . + pj,,, . Such a construction is in general not deterministic (for 
example, graph X is determined only up to isomorphisms). If p and p’ are as 
0 
Therefore any parallel direct derivation can be transformed into a sequence of 
sequential independent direct derivations by repeated applications of the above 
construction. 
1 
4‘ 
4“ 
above, we shall write p‘ E A N A L I , J ( ~ )  
(or (p’,p) E A NA L~, J ) .  
Lemma 3.4.9 (synfthesis of sequential independent derivations) 
Let p = (G 
X & H )  be a sequential independent derivation. Then there 
is a constructive way to obtain a parallel direct derivation p‘ = (G ==$ H ) ,  
called a synthesis of p. Also this construction is in general not deterministic. 
0 
4‘+ ” 
If p and p‘ are as above, we shall write p’ E SYNT(p). 
Example 3.9 (analysis and synthesis) 
Let p be the two-steps derivation from graph G1 to graph G3 depicted in 
Figure 3.7, and let p‘ be the parallel direct derivation of Figure 3.11. Since 
p is sequential independent, the synthesis construction can be applied to it, 
and one possible result is indeed p’; thus we have p’ E SYNT(p). Conversely, 
the application of the analysis construction to p’ can produce p, and we have 
p E ANAL(1),(2)(p’). 
Also, through a different analysis of p‘ we may obtain the 
derivation p1 ; p2 of Figure 3.15 (a): In fact, we have p1 ; pz E ANAL(z),(l)(p’). 
It is worth stressing that the analysis and synthesis constructions are not in- 
verse to each other in a strict sense, but they are so up to isomorphism. Iso- 
morphisms of (direct) derivations and other equivalences among derivations 
will be discussed in depth in the next section. 
We are now ready to present the outline of the proofs of the Parallelism and 
of the Local Church Rosser Theorems 

200 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
Proof outline of Theorem 3.4.6 (Parallelism) 
Lemma 3.4.8 provides a constructive proof that 1 + 2 ,  and, similarly, Lemma 
0 
3.4.9 provides a constructive proof that 2 + 1. 
Proof outline of Theorem 3.4.3 (Local Church Rosser) 
G ps 
HI and G p= 
H2 are two parallel independent direct derivations, 
iff (by Proposition 3.4.7) there is a graph H such that G 
& 
H 
is a parallel direct derivation, iff (by Theorem 3.4.6) there is a sequentially 
0 
independent derivation G '3 
H I  =b X .  
Pl+PZ [rnl , m z ]  
PZ 4 
3.5 
In the previous sections we considered mainly definitions and properties (for 
the DPO approach) of direct derivations, i.e., of the basic graph rewriting 
steps. Since the derivations of a grammar are intended to model the compu- 
tations of the system modeled by-the grammar, it is certainly worth studying 
the operational behaviour of a grammar by developing a formal framework 
where its derivations can be described and analyzed. A model of computation 
for a grammar is a mathematical structure which contains relevant information 
concerning the potential behaviour of the grammar, that is, about all the pos- 
sible computations (derivations) of the grammar. Since the basic operation on 
derivations is concatenation, it is quite obvious that categories are very suited 
as mathematical structures for this use. In fact, a model of computation for a 
given grammar is just a category having graphs as objects, and where every 
arrow is a derivation starting from the source graph and ending at the target 
graph. Then the categorical operation of sequential composition of arrows cor- 
responds to the concatenation of derivations. Models of computation of this 
kind (i.e., categories of computations, possibly equipped with some additional 
algebraic structure) have been proposed (with various names) for many for- 
malisms, like Phrase Structure Grammars [44], Petri nets [45,46], CCS [47], 
Logic Programming [48,49], and others. Although in this section we focus on 
the DPO approach, it is obvious that models of computation can be defined 
easily for the SPO approach as well, and also for all other approaches to graph 
transformation. 
A concrete model of computation for a grammar is defined easily according to 
the above intuition: it has all concrete graphs as objects and all derivations as 
arrows. However, such a model often contains a lot of redundant information; 
in fact one is usually interested in observing the behaviour of a grammar from 
a more abstract perspective, ignoring some details which are considered as 
unessential. Consequently, more abstract models of computation are often of 
Models of Computation in the DPO Approach 

3.5. MODELS OF COMPUTATION IN THE DPO APPROACH 
201 
interest, where derivations (and graphs) differing only for insignificant aspects 
are identified. In general such abstract models can be defined by imposing an 
equivalence relation on derivations (and graphs) of the most concrete model: 
Such relation equates exactly those derivations (graphs) which cannot be dis- 
tinguished by the chosen observation criterion. A very natural requirement for 
such an equivalence is that it is a congruence with respect to sequential compo- 
sition. If such a condition is satisfied, one gets automatically the abstract model 
of computation corresponding to the chosen observation by taking the quotient 
category of the concrete model with respect to the equivalence relation. 
In the following subsections, besides the concrete model for a graph grammar in 
the DPO approach, we consider two different observation mechanisms on graph 
derivations, and we define the corresponding abstract models. Such observa- 
tion mechanisms are intended to capture true concurrency and representation 
independence, respectively. The equivalence we use for capturing true concur- 
rency is a slight variation of the well-known shift equivalence [43,3], and it is 
presented in Section 3.5.1. On the other hand, the most natural equivalence on 
graph derivations intended to capture representation independence (i.e., the 
equivalence equating pairs of isomorphic derivations) fails to be a congruence 
with respect to sequential composition. Therefore it has to be refined carefully 
through the use of the so-called standard isomorphisms (first introduced in 
[50]). This will be the topic of Sections 3.5.2 and 3.5.3. The full proofs of the 
main results of Section 3.5.3 are given in Section 3.9. 
Besides the models corresponding to these two equivalences, we shall introduce 
in Section 3.5.4 a third abstract model, called the abstract, truly-concurrent 
model, which satisfactorily composes the two equivalences, and we will relate 
it to the other models through suitable functors. In our view, such a model 
represents the behaviour of a graph grammar at a very reasonable level of 
abstraction, at which many classical results of the algebraic theory of grammars 
can be lifted. This model is used for example in [28] as a starting point for the 
definition of a truly-concurrent semantics for graph grammars based on Event 
Structures [26]. The present section is based mainly on the paper [51]. 
3.5.1 
As suggested above, the simplest, more concrete model of computation is just 
a category having graphs as objects and derivations as arrows. Thus the next 
definition just emphasizes the obvious fact that since derivations can be com- 
posed, they can be regarded as arrows of a category. All along this section, by 
derivation we mean a possibly parallel derivation. 
The Concrete and Truly Concurrent Models of Computation 

202 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
Definition 3.5.1 (the concrete model of computation) 
Given a graph grammar G, the concrete model of computation for G, denoted 
Der(G), is the category having all graphs as objects (thus it has the same 
objects as category Graph), and where p : G -+ H is an arrow iff p is a 
(parallel) derivation, a(p) = G and ~ ( p )  
= H (see Definitions 3.3.6 and 3.4.4). 
Arrow composition is defined as the sequential composition of derivations, and 
the identity of object G is the identity derivation G : G J* 
G (see Definition 
3.3.6). 
The following example shows why, in our view, the concrete model of compu- 
tation for a grammar contains too much information. 
Example 3.10 (concrete model of computation for grammar C-S) 
Let us have a look at the structure of category Der(C-S). As objects, it contains 
all labeled graphs introduced in Example 3.1. Thus, for example, for each non- 
empty graph G it contains infinitely many distinct objects isomorphic to G. 
As arrows are concerned, consider for example the graphs G1 and G3 of Figure 
3.7. Between these two graphs we have one arrow for the two-step derivation 
of Figure 3.7 which applies first SER and then REQ, and infinitely many ad- 
ditional distinct arrows, one for each isomorphic copy of that derivation, which 
can be obtained by changing arbitrarily the identity of nodes and edges in all 
the graphs of the derivation, except the starting and the ending ones. More- 
over, between GI and GS there are infinitely many distinct arrows representing 
the parallel direct derivation of Figure 3.11 and all its isomorphic copies. There 
are also infinitely many arrows having GI both as source and as target: among 
them there is the identity derivation GI : G1 J* GI, and some of the empty 
direct derivations mentioned at the end of Definition 3.4.4. 
0 
Therefore many arrows of the concrete model should be considered as not 
distinguishable, when looking at derivations from a more abstract perspective. 
Postponing to the next section the discussion about how isomorphic derivations 
can be identified, we introduce here an equivalence intended to capture true 
concurrency, yielding the truly-concurrent model of computation. 
According to the Parallelism Theorem (Theorem 3.4.6), two productions can 
be applied at parallel independent matches in a graph either at the same 
time, or one after the other in any order, producing the same resulting graph. 
An observation mechanism which does not distinguish two derivations where 
independent rewriting steps are performed in different order is considered to 
observe the concurrent behaviour of a grammar, instead of the sequential one. 
The corresponding equivalence is said to capture “true concurrency”. Such 
an equivalence has been deeply studied in the literature, where it is called 

3.5. MODELS OF COMPUTATXON XN THE DPO APPROACH 
203 
shift equivalence [43,2,52,15], and it is based on the analysis and synthesis 
constructions (Lemmas 3.4.8 and 3.4.9): It equates two derivations if they are 
related by a finite number of applications of analysis and synthesis. The name 
“shift equivalence” refers to the basic operation of “shifting” a production one 
step towards the left, if it is sequential independent from the previous direct 
derivation: In fact, Proposition 3.5.5 below will show that the analysis and 
synthesis constructions can be simulated by repeated shifts. 
Definition 3.5.2 (shift equivalence) 
If p and p’ are two derivations such that p’ E A N A L ~ , J ( ~ )  
(see Lemma 3.4.8), 
p1 = p2 ; p ;  p3, pi = p2 ; p’ ; p3, and pz has length n - 1, then we will write 
pi E ANAL;2,J(p1), indicating that pi is an analysis of p1 at step n. Similarly, 
if p’ E SYNT(p) (see Lemma 3.4.9), p1 = p2 ; p ;  p3, pi = p2 ; p’ ; p3 and p2 
has length n - 1, then we will write pi E SYNTn(pl), indicating that pi is 
obtained from p1 via a synthesis construction at step n. 
Now, let ANAL be the union of all analysis relations (i.e., ANAL = 
(-{ANAL;,, I n E N A I ,  J E N’}), and similarly let SYNT be the union 
of all synthesis relations (SYNT = U{SYNT” I n E N}). Furthermore, let 
SHIFT: be the relation defined as (p1,pZ) E SHIFT: iff p1 is an identity 
derivation G : G 3’ G and p2 : G 
G is an empty direct derivation such 
that the induced isomorphism is the identity idG : G + G (see Definition 
The smallest equivalence relation on derivations containing ANAL U SYNT 
U SHIFT: is called shift equivalence and it is denoted by E s h .  If p is a deriva- 
tion, by [plsh we denote the equivalence class containing all derivations shift- 
equivalent to p. 
From the last definition it follows immediately that p = s h  p’ implies ~ ( p )  
= 
~ ( p ’ )  
and ~ ( p )  
= ~ ( p ’ ) ,  
because synthesis and analysis do not affect the ex- 
tremes of a derivation. The truly-concurrent model of computation for a graph 
grammar is, like the concrete model of Definition 3.5.1, a category having con- 
crete graphs as objects; however, its arrows are equivalence classes of deriva- 
tions modulo the shift equivalence. There is an obvious functor relating the 
concrete model and the truly-concurrent one. 
0 
3.4.4). 
Definition 3.5.3 (the truly-concurrent model of computation) 
Given a graph grammar G, the truly-concunent model of computation for G, 
denoted Der(G)/sh, is the category having graphs as objects, and as arrows 
equivalence classes of derivations with respect to the shift equivalence. More 
precisely, [plsh : G -+ H is an arrow of Der(G)lsh iff a(p) = G and ~ ( p )  
= 

204 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
H .  The composition of arrows is defined as [plsh ; [p’Ish = [ p ;  p’Ish, and the 
identity of G is the equivalence class [GIsh, containing the identity derivation 
G. 
We denote by [-Ish the obvious functor from Der(G) to Der(G)/sh which is the 
identity on objects, and maps each concrete derivation to its shift equivalence 
class. 
Example 3.11 (truly-concurrent model of computation for C-S) 
Consider the concrete model for C-S described in Example 3.10. Category 
Der(C-S)/sh has the same objects but much fewer arrows. For example, since 
the two-steps derivation G1 ~ S E R  
Gz ~ R E Q  
G3 of Figure 3.11 and the par- 
allel direct derivation G1 JSER+REQ G3 of Figure 3.11 are shift-equivalent, 
they are represented by the same arrow between graphs G1 and G,; more- 
over, since the analysis and synthesis constructions are non-deterministic, it 
turns out that also all the isomorphic copies of the mentioned derivations are 
shift-equivalent to them. Therefore there is only one arrow from G1 to G3 rep- 
resenting the application of productions SER and REQ in any order, as one 
would expect in an abstract model. 
However, since the objects of the category are concrete graphs, looking at the 
arrows starting from G1 one may still find infinitely many arrows corresponding 
to the application of the same productions SER and REQ, but ending at 
different isomorphic copies of G3. This fact shows that the truly-concurrent 
model still contains too many arrows, as it may manifests unbounded non- 
determinism, like in the case just described. 
0 
Since arrows of the truly-concurrent model are equivalence classes of deriva- 
tions, it is natural to ask if they contain a “standard representative”, i.e., a 
derivation which can be characterized as the only one in the equivalence class 
which enjoys a certain property. Canonical derivations provide a partial answer 
to this question. In the thesis of Hans-Jorg Kreowski ([43]) it is shown that any 
graph derivation can be transformed into a shift-equivalent canonical deriva- 
tion, where each production is applied as early as possible. In general, since 
the analysis and synthesis constructions are not deterministic, from a given 
derivation many distinct canonical derivations can be obtained: nevertheless, 
all of them are isomorphic. This is formalized by a result in [43] stating that 
every derivation has, up to isomorphism, a unique shift-equivalent canonical 
derivation. 
Given a derivation, a shift-equivalent canonical derivation can be obtained by 
repeatedly “shifting” the application of the individual productions as far as 
possible towards the beginning of the derivation. It is worth stressing that, 

3.5. MODELS OF COMPUTATION IN THE DPO APPROACH 
205 
unlike the original definition, we explicitly consider here the deletion of empty 
direct derivations. 
Definition 3.5.4 (shift relation, canonical derivations) 
Let us write p' 
E ANALF(p) if p' 
E ANAL;,,(p), where I = (i) and 
J = (1,. . . , i  - 1,i + 1,. . . , k); i.e., when p' is obtained from derivation p 
by anticipating the application of the i-th production of the n-th direct deriva- 
tion. 
Now, for each pair of natural numbers (n, j ) ,  both greater than 0, the relation 
SHIFT; is defined as SHIFT? = SYNTn-'oANAL; 
( 0  is the standard com- 
position of relations). Moreover, for each n > 0, we write (
~
1
~
~
2
)
 
E SHIFT," 
iff p1 has length n, p1 = p ;  G 
H ,  and the double 
pushout G 
X by composing the right-hand 
side pushout with the isomorphism from X to H induced by the empty direct 
derivation X 
Relation < s h  is defined as the union of relations SHIFT," for each n, j E N. 
The transitive and reflexive closure of < s h ,  denoted &, is called the shift 
relation. A derivation is canonical iff it is minimal with respect to Ssh. 
Thus we have that p1 <sh p2 iff p1 is obtained from p2 either by removing the 
last direct derivation if it is empty (if p1 is the identity, then an additional con- 
dition must be satisfied), or by moving the application of a single production 
one step towards left. It is worth stressing here that for each n E N, 
rela- 
tion SHIFT," is deterministic, in the sense that (pl,pz), (pi,p2) E SHIFT," 
implies p1 = pi. 
H ,  pa = p ;  G 
X 
H is obtained from G 
H .  Finally, let SHIFT: be as in Definition 3.5.2. 
Example 3.12 (canonical derivation) 
Let dl be the derivation depicted in Figure 3.7. Figures 3.12 and 3.13 show two 
derivations, 62 and 64, both shift-equivalent to 61, and where 64 is canonical. 
Let us explain how 64 can be obtained from 61 through repeated applications 
of the shift construction. First, note that we have (62,61) E SHIFT;, i.e., 62 is 
obtained from 61 by moving the (second) application of REQ one step towards 
left. More formally, by Definition 3.5.4 we have SHIFT; = SYNT2 o ANAL:; 
thus 62 is obtained applying first an analysis construction to direct deriva- 
tion G2 ~ R E Q  
G3, obtaining the two-step derivation G2 ~ R E Q  
G3 ~g G3, 
and then by applying the synthesis construction to the sequential indepen- 
dent derivation G1 +SER 
G2 ~ R E Q  
G3, obtaining the direct derivation 
GI JSER+REL 
G3. In particular, note that the application of the empty 
derivation in 62 is generated by the analysis construction (see the corresponding 
proof in Section 3.9). 

206 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
Figure 3.12: Derivation 62, shift-equivalent to derivation 61 of Figure 3.7. More precisely, 
(&,6$ E SHIFT;. 
SER + RE0 : 
GO 
Figure 3.13: The canonical derivation 64, shift-equivalent to derivation 61 of Figure 3.7 

3.5. MODELS OF COMPUTATION IN THE DPO APPROACH 
207 
Next, we can apply the shift construction to the last part of 6 2 ,  because the 
derivation G3 +g 
G3 +REL Gq is clearly sequential independent. In this way 
we get a new derivation 63 E SHIFT;'(&), which is obtained by moving one step 
earlier the application of REL; derivation 6 3  is not depicted, but it is obtained 
easily by adding an empty direct derivation G4 +g G4 to 64. Now, since the 
last direct derivation of 63 is empty, by removing it we get the last derivation 
64 E SHIFT;($). Finally, the fact that 64 is canonical can be shown easily 
by checking that every production application in it deletes at least one item 
(edge) generated by the previous direct derivation. Thus the shift construction 
cannot be applied anymore. 
0 
The next proposition on the one hand justifies the name of the equivalence 
introduced in Definition 3.5.2, on the other hand it guarantees the existence of 
a shift-equivalent canonical derivation for any given derivation. This fact will 
be used in the next section. 
Proposition 3.5.5 (properties of the shift relation) 
1. The smallest equivalence relation containing the S s h  relation is exactly 
relation E s h  introduced in Definition 3.5.2. 
2. Relation <sh is well-founded, i.e., there is no infinite chain p1, p2,. . . of 
derivations such that pi+l <sh pi for all i E IN. Thus for each derivation 
p there exists a canonical (i.e., minimal with respect to S s h )  derivation 
pl such that p' Ssh p. 
Proof outline 
For the first point, denote by M s h  the smallest equivalence relation containing 
S s h .  Now Msh c G s h  is obvious by the definition. Conversely, one can prove that 
z s h  and 
SYNT" C 
Msh; in other words, if two derivations are related by a single analysis 
(or synthesis) construction, then they can be related by a sequence of basic shift 
constructions. For synthesis, if p' E SYNT(p), and p = G 
X 
==+ 
H ,  
then p' can be obtained from p by anticipating the production applications in 
X 
H one at a time, and deleting the remaining empty direct deriva- 
tion. For analysis the solution is a bit more tricky, because relation ANALI,J 
allows one to reorder all the productions in the parallel direct derivation. This 
effect can be simulated via shifts by moving individual productions back and 
forth until they reach the desired position. 
- 
- 
--sh c M S h  by showing that for each n E IN and I ,  J E w*, 
ANAL;,, 
Pl +...+Pk 
Pl+. ..+Pk 
==+ 

208 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
For the second point, see Lemma 4.6 and Theorem 5.3 of [43]. The corre- 
sponding proofs can be adjusted easily in order to match the slightly different 
definitions. 
0 
3.5.2 
Graph grammars are often introduced (in most of the approaches) as a formal- 
ism for specifying the evolution of certain systems. In this perspective, some 
sort of labeled graphs are used to represent system states, while graph trans- 
formation rules encode the basic system transformations as in the running 
example of this section. 
Almost invariably, two isomorphic graphs are considered as representing the 
same system state. In fact, such a state is determined by the topological struc- 
ture of the graph and by the labels only, while the true identity of nodes and 
edges is considered just as a representation detail. Therefore, in order to define 
a model of computation which represents faithfully the behaviour of a sys- 
tem, it is very natural to look for an equivalence which equates all isomorphic 
graphs. This is even more demanding in the algebraic approaches to graph 
grammars. In fact, since the pushout object of two arrows is unique only up 
to isomorphism, from the definition of direct derivation (Definition 3.3.5) it 
follows that given a graph G and a production p ,  if G 
H ,  then G 
H' 
for each graph HI isomorphic to H .  Thus the application of a production to 
a graph can produce infinitely many distinct results, which implies that both 
in the concrete and in the truly-concurrent models of computation there are 
infinitely many arrows starting from a graph and corresponding to distinct ap- 
plications of the same production. This fact is highly counter-intuitive, because 
in the above situation one would expect a deterministic result, or, at most, a 
finite set of possible outcomes. 
Indeed, in the classical theory of the algebraic approach to graph grammars, 
one often reasons (more or less explicitly) in terms of abstract graphs, i.e., of 
isomorphism classes of concrete graphs: With this choice, given as above a 
graph G and a production p with match m (satisfying the gluing condition), 
there is only one abstract graph [HI such that [GI % [HI, thus a direct 
derivation becomes in a sense deterministic. 
Such a solution is satisfactory if one is interested just in the set of (abstract) 
graphs generated by a grammar. However, if one considers instead a kind of 
semantics which associates with each grammar all the possible derivations (like 
the models of computation we are interested in), even with abstract graphs one 
still has too much representation-dependent information. In fact, in the above 
situation there are still infinitely many distinct direct derivations (i.e., double- 
Requirements for capturing representation independence. 

3.5. MODELS OF COMPUTATION IN THE DPO APPROACH 
209 
pushout diagrams) from [GI to [HI via p and m (as it follows from Definition 
3.3.5). Like for graphs, one can find many distinct derivations which should 
not be considered distinct as system evolutions, because they differ just for 
the identity of nodes and edges in the involved graphs. Therefore it is natural 
to reason not only in terms of abstract graphs, but also in terms of abstract 
derivations, i.e., suitable equivalence classes of derivations. 
We shall say that an equivalence on graphs and graph derivations captures 
“representation independence” if it equates all isomorphic graphs (and not 
more), and if it equates derivations which differ for representation details. It 
is worth stressing here that the shift equivalence (Definition 3.5.2), which has 
been recognized to capture the essentials of the semantics of parallel graph 
derivations, is clearly not representation independent, because it is able to 
relate only derivations starting from and ending with the same concrete graphs. 
In the following we first formalize the notion of “isomorphism of derivation- 
s” (which is the most natural candidate for the equivalence we are looking 
for), showing that the obvious definition based on the categorical notion of 
isomorphism of diagrams is not acceptable from a semantical point of view, 
because it would identify too many derivations. Next we will introduce some 
reasonable requirements for equivalences on derivations intended to capture 
representation independence, formalizing them as suitable algebraic proper- 
ties. More precisely, we will look for an equivalence that is a congruence with 
respect to sequential composition, and that is compatible with the construc- 
tion of canonical derivations, i.e., such that any pair of canonical derivations 
obtained from two equivalent derivations are equivalent as well. It is worth 
stressing that these requirements are motivated by the goal of defining an ab- 
stract, truly-concurrent model of computation for a grammar: If one would 
like to carry on to the abstract setting other results of the theory (for example 
those concerning concurrency and amalgamation (see Section 3.6.1 and [2]), it 
might be the case that additional requirements should be considered. 
Let us start with the definition of isomorphism of derivations. 
Definition 3.5.6 (isomorphism of derivations) 
Let p : Go +’ G, and p‘ : Gb J* 
GL be two derivations having the same 
length, as depicted in Figure 3.14. They are isomorphic (written p -0 p’) 
if there exists a family of isomorphisms {& 
: Go -+ Gb, q 5 ~ ,  : X ,  -+ X l }  
with X E { L ,  K ,  R, G, D }  and i E { 1, . . . , n} between corresponding graphs of 
the two derivations, such that all those squares commute, which are obtained 
by composing two corresponding morphisms X -+ Y and X’ -+ Y’ of the two 
derivations and the isomorphisms 4~ and q 5 ~  
relating the source and the target 
graphs. 
It is not difficult to see that the equivalence induced by isomorphisms of deriva- 
tions identifies too many derivations. In fact, as it is clear from the picture, 

210 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
Figure 3.14: Isomorphism of derivations. 
the productions in corresponding direct derivations only need to be span- 
isomorphic. Thus derivations which can hardly be considered as differing just 
for representation details may be identified. For example, if a grammar 6 con- 
tains two span-isomorphic productions p and p', two direct derivations using p 
and p' would be considered as equivalent. Even worst, two parallel productions 
q = pl + . . . + pk and q' = pi + . . . -I- p i ,  may happen to be span-isomorphic 
even if some of the involved sequential productions are distinct or if k # k', 
i.e., if the number of applied productions is different. 
SYNCHR : 
3 3  
Example 3.13 (extending the graph grammar) 
Suppose that grammar C-S is extended with the above production SYNCHR, 
which is intended to model the situation where the service of a request starts 
exactly when another service terminates. 
Such production happens to be span-isomorphic to the parallel production SER 
+ REL, thus two direct derivations G '*ZHR 
H and G S E R a R E L  
would be identified by equivalence -0. However, such direct derivations are 
 e em antic ally" very different: the second one is a parallel direct derivations, 
and, using the analysis construction, it can be sequentialized in any order, 
while the other is a sequential direct derivation, which cannot be decomposed. 
U 

3.5. MODELS OF COMPUTATION IN THE DPO APPROACH 
211 
In the next section we will propose other equivalences on derivations which 
require that the productions applied at each direct derivation are not only 
span-isomorphic, but also isomorphic: this is the main reason why in Definition 
3.4.4 we defined a production as a pair including both a name and a span. 
In the rest of this section, we establish some further requirements for a no- 
tion of equivalence on derivations which naturally captures representation in- 
dependence. Throughout this section M denotes an equivalence relation on 
derivations, and an abstract derivation, denoted [p], is an equivalence class 
of derivations modulo M. The first, obvious requirement is that the notion of 
abstract derivation is consistent with the notion of abstract graph, i.e., any 
abstract derivation should start from an abstract graph and should end in an 
abstract graph. 
Definition 3.5.7 (well-defined equivalences) 
For each abstract derivation [p], define a([p]) = { ~ ( p ‘ )  
I p’ E [p]}, and similarly 
?-([PI) = { ~ ( p ’ )  I p’ E [p]}. Then equivalence M is weZZ-defined if for each 
derivation p : G +* N we have that a ( [ p ] )  = [ ~ ( p ) ] ,  
and ?-([PI) = [ ~ ( p ) ] .  
If M is well-defined, then for each derivation p : G +* 
H we can write 
[p] : [GI J* 
[HI. Since our goal is to define abstract models of computa- 
tion as quotient categories of concrete ones, the second requirement is that the 
equivalence is a congruence with respect to sequential composition. 
Definition 3.5.8 (equivalence allowing for sequential composition) 
Given two abstract derivations [p] and [p’] such that ?-([PI) 
= a([p‘]), 
their 
sequential composition [p] ; [p‘] is defined iff for all p1, p2 E [p] and p i  , pb E [p’] 
such that 
= a(pi) and ~ ( p 2 )  
= a(&), one has that p1 ; p i  M p2 ; pb. In 
this case [p] ; [p’] is, by definition, the abstract derivation [pl ; p i ] .  
An equivalence M allows for sequential composition iff [p] ; [p‘] is defined for all 
[p] and [p’] such that ?-([PI) = ~ ( [ p ’ ] ) .  
The third requirement guarantees that we reobtain the result of uniqueness 
of canonical derivations in the abstract framework, i.e., that each abstract 
derivation has a unique shift-equivalent abstract canonical derivation. 
Definition 3.5.9 (uniqueness of canonical derivations) 
Equivalence M enjoys uniqueness of canonical derivations iff for each pair of 
equivalent derivations p M p’ and for each pair ( p c ,  p:) of canonical derivations, 
p E s h  pc and p’ E s h  p: implies that pc M pk. 

212 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
3.5.3 
In this section we introduce two different equivalences on derivations, and 
analyze their properties with respect to the requirements established in Sec- 
tion 3.5.2. Actually, since by the definitions all the equivalences are clearly 
well-defined in the sense of Definition 3.5.7, we will focus only on the other re- 
quirements. The first equivalence we consider is obtained from equivalence -0 
of Definition 3.5.6 by requiring that the productions applied at each (parallel) 
direct derivation are isomorphic and not just span-isomorphic. 
Towards an equivalence for representation independence. 
Definition 3.5.10 (equivalence -1) 
Let p : Go J* G, and p’ : Gb J’ Gk be two derivations such that p -0 p‘ as 
in Figure 3.14. Then they are l-equivalent (written p -1 p’) if 
1. there exists a family of permutations ( H I , .  . . , II,) 
such that for each 
i E { 1,. . . , n ) ,  productions qi and q: are isomorphic via Hi; 
2. For each i E { 1,. . . , n}, the family of isomorphisms (4~; 
: Li -+ L:, 4 ~ ;  
: 
Ki + K ; , ~ R ;  
: Ri + R:) that exists by Definition 3.5.6 is exactly the 
family of isomorphisms between corresponding graphs of qi and q: which 
is induced by permutation Hi, according to Fact 3.4.5. 
We say that p and p’ are l-equivazent via (IIi)i<, 
if (IIi)is, is the family of 
permutations of point 1 above. Given a derivation p, its equivalence class with 
respect to -1 is denoted by [p]l, and is called a l-abstract derivation. 
Let us consider now the algebraic properties of equivalence =I. We prove below 
that ~1 enjoys uniqueness of canonical derivations. This result is based on an 
important lemma which states that -1 behaves well with respect to analysis, 
synthesis, and shift of derivations. This is the main technical result of this 
section, and the whole Section 3.9 is devoted to its proof. 
Lemma 3.5.11 (analysis, synthesis and shift preserve equivalence -1) 
Let p -1 p’ via (&)is,, and let 4~~ and 4 ~ , ,  be the isomorphisms between 
their starting and ending graphs (see Figure 3.14). 
1. If p1 
E 
ANALi(p) then there is at least one derivation p2 
E 
ANAL$;(j,(p’). Moreover, for each p2 E ANALhi(j)(p‘), it holds that 
p2 -1 P1. 
2. If p1 E SYNTi(p) then there is at least one derivation p2 E SYNTi(p’). 
Moreover, for each p2 E SYNTZ(p’), it holds that p2 -1 p1. 

3.5. MODELS OF COMPUTATION IN THE DPO APPROACH 
213 
3. If pi 
E 
S H I F T ; ( p )  then there is at least one derivation p2 E 
SHIFT,&](p'). 
Moreover, for each p2 E SHIFT&,(p'), 
it holds that 
p2 =1 p1. 
Furthermore, in all these three cases, the isomorphisms relating the starting 
and ending graphs of the 1-equivalent derivations p2 and p1 are exactly iso- 
I3 
The observation that analysis, synthesis and shift preserve not only equivalence 
= I ,  but also the isomorphisms between the starting and ending graphs of 
equivalent derivations will be used later in Proposition 3.5.16. 
morphisms 4~~ and 4 ~ , ,  . 
Theorem 3.5.12 (=I enjoys uniqueness of canonical derivations) 
Let p, pl be two derivations such that p -1 p', and let pc, p: be two canonical 
derivations such that p =sh pc and pl E s h  pk. Then pc -1 p:. 
Proof outline 
Let C s h  be the relation on 1-abstract derivations defined as [ p l ] ~  
C s h  [p2]1 if 
p1 <sh p2, and let C s h  be its reflexive and transitive closure. Relation C s h  is 
clearly well-defined by point 3 of Lemma 3.5.11; moreover it is well-founded 
because so is < s h ,  by Proposition 3.5.5. 
Furthermore, C s h  enjoys the following local confluence property: if [p2]1 Csh 
[p4]1 &sh [p3]1. This can be proved by following the outline of Lemma 4.7 of 
[43] (where the case of concrete derivations is considered, and all critical pairs 
of relation < s h  are analyzed), and by exploiting Lemma 3.5.11 for handling 
the equivalence classes. 
Local confluence and well-foundedness (i.e. , termination) of relation c s h  im- 
ply confluence, which implies the statement because canonical derivations are 
0 
Despite the last result, equivalence -1 is not completely satisfactory, because 
it does not allow for sequential composition, as the following counterexample 
shows (a similar counterexample is discussed in [50]). 
[ P l ] l  and [P3]1 C s h  [ P l l l ,  then there is a [P4]1 such that [P4]1 L s h  
and 
minimal with respect to <sh. 
Example 3.14 (
~
1
 
does not allow for sequential composition) 
Let p1 ; p2 and p; be the derivations of Figure 3.15 (a) and (b), respectively. 
It is easy to check that p2 -1 
pk: In fact the productions applied are the 
same, and the family of isomorphisms @2 = { ~ G L  : Gk -+ G;, 4~~ : K2 + 
and identities elsewhere, makes everything commute. Clearly, we also have 
Ki 7 ~
G
Q
 
G3 -+ Gi } with d'GL (3) = 5, d'G; (5) = 3, $K2 (5) = 3, $GQ (5) = 3, 

214 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
bbsm 
G3 
Figure 3.15: (a) Derivation pl ; p2, and (b) direct derivation pk. Since ~ ( p l )  
= G’, = .(pi), 
p l  ; p; is well defined. 
p1 
 id^^  id^;}. Moreover] 
p1 ; pa is defined because +I) 
= G& = g(pL)] but derivations p1 ; p2 and 
p1 ; pa are not 1-equivalent] because families a1 and 
do not agree on graph 
GL and actually there is no family of isomorphisms between the corresponding 
graphs of the two derivations making the resulting diagram commutative. 
Note that the two derivations p1 ; p2 and p1 ; pI of Figure 3.15 are “semanti- 
cally” different (and thus they should be kept distinct by a reasonable abstract 
model): in fact, in the first derivation the first request issued by the client is 
served, while in the second derivation the second request is served. 
Figure 3.16 shows an alternative] equivalent way of presenting the same coun- 
terexample. We used a graphical representation of 1-abstract direct derivations] 
where all the involved graphs are abstract (thus identities of nodes and edges 
have been dropped). The figure shows abstract derivations [ p l ] l  (left) and 
[p2]1 = [pL]l (right). In both abstract double-pushouts all morphisms are de- 
termined by the labels of nodes and edges, except those having [GI] as target: 
Thus we added subscripts to the two edges of [GL] labeled by regl indicating 
for each morphism which edge is in the codomain. Such subscripts only have 
a “local scope”, in the following sense: if in [p2]1 (or [ p l ] ~ )  
we exchange 1 and 
2 in the morphisms having abstract graph [GI] as target, then the resulting 
abstract derivation is still [p2]1 (or [ p l ] ~ ) .  
p1. using the family of isomorphisms @1 = 

3.5. MODELS OF COMPUTATION IN THE DPO APPROACH 
215 
;k 
[Gjl 
idle 
SER : 
Figure 3.16: The abstract direct derivations corresponding to p1 and pz of Figure 11 (a). 
Now the fact that the sequential composition of [pill and [p2I1 does not yield 
a well-defined 1-abstract derivation follows from the observation that, there are 
two possible ways of matching 7 ( [ p l ] l )  with .( 
[ p 2 ] l ) ,  yielding different results. 
0 
In [50] it is shown that the problem is due to the fact that in the categorical 
framework many relevant notions cannot be defined “up to isornorphi~m’~ 
not 
even arrow composition. The solution proposed there will be used in the next 
notion of equivalence. We first need to introduce “standard isomorphisms”. 
Definition 3.5.13 (standard isomorphisms) 
A family s of standard isomorphisms in category Graph is a family of isomor- 
phisms indexed by pairs of isomorphic graphs (i.e., s = {s(G,G’) I G 
G’})7 
satisfying the following conditions for each G, G’ and G“ E IGraphl: 
0 s(G,G’) : G + G’; 
0 s(G”, G’) 0 s(G, G”) = s(G, GI). 

216 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
In the equivalence we are going to introduce, denoted f 3 ,  we make a limited 
use of standard isomorphisms: We require that the starting and ending graphs 
of equivalent derivations are related by such isomorphisms (see also [51]). It is 
worth recalling that in [51] also another equivalence is introduced, denoted -2, 
that requires that all the isomorphisms of the form 4 ~ ;  
for X E { G , D }  are 
standard: However, it is shown, through a counter-example, that such equiva- 
lence does not enjoy uniqueness of canonical derivations. 
Definition 3.5.14 (Equivalence - 3 )  
Let s be an arbitrary but fixed family of standard isomorphisms of category 
Graph, and let p, pr be two derivations. We say that p and pr are 3-equivalent 
(written p =3 p’) iff they are 1-equivalent, and moreover the isomorphisms 
4~~ and 4~,, 
relating their starting and ending graphs (see Figure 3.14) are 
standard. An equivalence class of derivations with respect to -3 is denoted by 
[p]3, and is called a 3-abstract derivation. 
Now the fact that equivalence ~3 allows for sequential composition follows 
easily by the above considerations. 
Proposition 3.5.15 (-3 allows for sequential composition) 
Let p1, p i ,  p2 and pb be four derivations such that p1 -3 p i ,  p2 -3 pb, .(PI) = 
4 3 2 )  and  pi) = &). 
Then PI ; p2 -3 pi ; ph. 
Pro0 f 
By hypothesis there are two families of isomorphisms making p1 and p2 3- 
equivalent to pi and ph, respectively. The two families must agree on ~ ( p 1 )  
= 
a(p2) (because there is only one standard isomorphism between a given pair 
of isomorphic graphs), and thus their union provides a family of isomorphisms 
0 
which makes 3-equivalent p1 ; p2 and pi ; ph. 
Example 3.15 (sequential composition of 3-abstract derivations) 
The counterexample of Example 3.14 does not apply to equivalence - 3 :  In 
fact, looking at the direct derivations of Figure 3.15, we have that p2 $3 pb, 
because one of the isomorphisms in 
(namely, 4
~
)
 
is certainly not standard 
(it is not the identity, see Definition 3.5.13). 
Consider now the abstract direct derivations of Figure 3.16. It can be shown 
that they are a faithful representation of 3-abstract derivations, provided that 
we give the subscripts 1 and 2 in graph [Gb] a “global scope” in the following 
sense: if we assume that the right abstract derivation is [p2I3, then by ex- 
changing subscripts 1 and 2 in the morphisms having [Gb] as target, we obtain 

3.5. MODELS OF COMPUTATION IN THE DPO APPROACH 
217 
abstract derivation [&,I3, which is a different one! Moreover, subscripts can 
now be used to concatenate abstract derivations: [p1]3 ; [p2]3 is obtained by 
matching the two copies of [G!J in such a way that subscripts are preserved. 0 
The fact that the shift relation preserves the isomorphisms relating the start- 
ing and ending graphs of two equivalent derivations, as stated explicitly in 
Lemma 3.5.11 , guarantees that equivalence -3 enjoys uniqueness of canonical 
derivations. Therefore equivalence -3 satisfies all the requirements of Section 
3.5.2, as summarized in the next proposition. 
Proposition 3.5.16 (Properties of equivalence ~
3
)
 
Equivalence -3 
is well-defined, it allows for sequential composition, and it 
enjoys uniqueness of canonical derivations. 
Proof outline 
For the uniqueness of canonical derivations, the same proof of Theorem 3.5.12 
can be used. In fact, since the analysis, synthesis and shift relations preserve 
not only equivalence z1, but also the isomorphisms relating the starting and 
the ending graphs of 1-equivalent derivations (Lemma 3.5.11), it is immediate 
to show that they preserve equivalence =3 as well. Sequential composition is 
well-defined by Proposition 3.5.15. 
0 
3.5.4 
Since equivalence ~3 on derivations is a congruence with respect to sequential 
composition, and since all canonical derivations which are shift-equivalent to 
3-equivalent derivations belong to the same 3-equivalence class, then this equiv- 
alence allows one to abstract out from the representation dependent aspects 
of derivations in a satisfactory way, defining the abstract model of computation 
for a grammar. 
The abstract models of computation for a grammar. 
Definition 3.5.17 (abstract model of computation) 
Given a grammar G, its abstract model of computation ADer(G) is defined 
as follows. The objects of ADer(G) are abstract graphs, i.e., isomorphism 
classes of objects of Graph. Arrows of ADer(G) are 3-abstract derivations, 
i.e., equivalence classes of (parallel) derivations of G with respect to equivalence 
=3. The source and target mappings are given by (T and T ,  respectively; thus 
[pI3 : ( ~ ( [ p ] ~ )  
-+ ~ ( [ p ] ~ ) .  
Composition of arrows is given by the sequential 
composition of the corresponding 3-abstract derivations, and for each object 
dSubscripts 1 and 2 can be replaced by any other marking able to distinguish the two req 
edges: the relevant fact is that once such a marking is fixed, by permuting the marks one 
gets a different abstract derivation. 

218 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
[GI the identity arrow is the 3-abstract derivation [G : G J* GI3 containing 
the identity derivation G. 
Category ADer(G) is equipped with an equivalence relation zzsh - on arrows, 
defined as [ p ] ~  
E-514 
[ p ’ ] ~  
if p Gsh p’. 
Proposition 3.5.18 (category ADer(G) is well-defined) 
Category ADer(G) is well-defined. Moreover, equivalence e s h  is a congruence 
with respect to arrow compositions, i.e., if [p1]3 -a 
[pi13 and [p2]3 ea [p1]3, 
then [p1I3 ; [p2I3 -& [pi13 ; [p1]3 (if the compositions are defined). 
Pro0 f outline 
The two facts follow easily from the properties of equivalence - 3  summarized 
in Proposition 3.5.16 and from Theorem 3.5.12. 
0 
Since E s h  is a congruence with respect to arrow composition, it is safe to 
define thequotient category of ADer(G) with respect to f s h :  
- This yields the 
abstract , truly concurrent model of computation. 
Definition 3.5.19 (abstract, truly-concurrent model of computation) 
The abstract, truly concurrent model of computation for a grammar G is defined 
as category ADer(G)/,h, having the same objects as ADer(G), and as arrows 
equivalence classes of arrows of ADer(G) with respect to equivalence e s h .  
- 
The next definition and result show the relationship among the four models 
of computations for a grammar, introduced in Definitions 3.5.1, 3.5.3, 3.5.17, 
and 3.5.19, respectively, in terms of functors relating them. 
Der(G) -[-lSh-DeW/sh 
I 
I 
A 
I 
- 
d 
I 
Definition 3.5.20 (functors among models of computation) 
Let G be a graph grammar. The various models of computation for G introduced 
in Definitions 3.5.1, 3.5.3, 3.5.17, and 3.5.19, are related by the four functors 
(as in the above diagram) defined as follows: 
0 Functor [-]sh : Der(G) t 
Der(G)/,h is the functor introduced in De- 
finition 3.5.3 which is the identity on objects, and maps each concrete 
derivation to its shift equivalence class. 

3.5. MODELS OF COMPUTATION IN THE DPO APPROACH 
219 
Functor [-Id : ADer(G) -+ ADer(G)/,h is the identity on objects, and 
maps each %abstract derivation to its equivalence class with respect to 
- 
=sh. 
- 
Functor A : Der(G) + ADer(G) maps each object G to its isomorphism 
class [GI, and each concrete derivation p to its 3-abstract equivalence 
class [pI3. 
Functor 4 : Der(G)/,h -+ ADer(G)/a maps each object G to its iso- 
morphism class [GI, and each arrow [p],h to the &-equivalence class of 
the corresponding 3-abstract derivation, i.e., to [[p]3Ish. 
- 
Theorem 3.5.21 (functors among models of computation) 
All the functors of Definition 3.5.20 are well-defined, and the diagram com- 
mutes. Moreover, functor A is an equivalence of categories. 
Proof outline 
Well-definedness is obvious for functors [-],h, [-]a 
and A. For A, we have 
to show that if p =sh p’, then [ p ] 3  rh [p’]3. This follows directly from the 
definition of =,h. - Also the commutativity of the diagram is immediate by the 
definitions. 
To prove that A is an equivalence of categories it suffices to show that it is 
full and faithful, and that each object [GI of ADer(G)/,h is isomorphic to 
- 
A ( H )  for some object H of Der(G),h. This last fact and fullness are ensured 
by surjectivity of 4. For faithfulness, let [p],h and [p’],h be two parallel arrows 
of Der(G),h. We have to show that 4([plsh) = A([p’],h) implies p =,h 
p’. 
By definition of 4, A([p],h) = A([p’],h) implies [p]3 =fi [p’]3. Then p =,h 
p’ 
follows by the general property that if p -3 p’, a(p) = a(p’), and ~ ( p )  
= ~ ( p ’ ) ,  
then p =sh p’ (that is, equivalence =3 is contained in the shift equivalence, if 
restricted to derivations having the same starting and ending graphs). The last 
property can be proved by exploiting the fact that the shift equivalence allows 
one to add empty direct derivations at the end of a derivation, to move them 
inside the derivation, and to change every intermediate graph of a derivation 
Let us shortly comment on the relationship among the various models of com- 
putation. The concrete model Der(G) records all the possible derivations of 
grammar G without abstracting any detail; its definition is straightforward 
because the sequential composition of concrete derivations is well-understood, 
and it is obtained simply by the juxtaposition of the corresponding diagrams. 
Since the shift equivalence proposed in the literature relates only derivations 
with an isomorphic copy. 
0 

220 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
between the same graphs, it can be used to define a congruence on the concrete 
derivations yielding the truly concurrent model of computation Der(G)lsh. 
However, this category is still too concrete, because it has all graphs as ob- 
jects. Therefore from each graph there are still infinitely many “identical” 
derivations, differing only for the ending graph. In the other direction, we 
showed that if one wants to reason on derivations disregarding “representation 
dependent” details, then equivalence ~3 can be used, because it allows for 
sequential composition; moreover, it is compatible with the shift equivalence. 
Finally, thanks to the properties of -3, the abstract, truly concurrent model 
of computation ADer(G)/,h can be defined. This model seems to represent 
all the derivations of grammar G at a very reasonable level of abstraction, 
both independent of representation-dependent details and consistent with the 
shift equivalence. The fact that functor A is an equivalence of categories essen- 
tially means that category Der(G)lsh already has between each pair of objects 
the “right” structure, although this structure has, in general, infinitely many 
copies. 
3.6 Embedding, Amalgamation and Distribution in the DPO ap- 
proach 
In this section we shortly recall some concepts and results of the DPO approach 
concerning the topics addressed in Sections 3.2.3 and 3.2.4. 
3.6.1 
In Section 3.2.3 the Embedding Problem (Problem 3.2.3) asked for conditions 
ensuring that a derivation can be embedded into a larger context. Given deriva- 
tions p = (Go i-i 
embedding of p into 6 is a family of injections e = (Gi % Xj)iEil,...,k} 
such 
that for all i E (1,. . . , I c }  
Embedding of Derivations and Derived Productions 
a Gk) 
and 6 = ( X o  ’11140 ... pk’nk-l Xk), an 
PI mo ... p k  mk-i 
ei o mi = ni, and 
there is an injection Di -% Y, making the two resulting squares commu- 
tative (see the diagram below). 
The embedding of p into 6 is denoted by p --% 6. Given p and 6, the embed- 
ding e is completely determined by the first injection eo, called the embedding 
morphism of e. 

3.6. EMBEDDING, AMALGAMATION AND DISTRIBUTION 
221 
/ 
/ 
/ 
mk-l 
/ 
mB 
eo.. 
._ 
el., 
ek-,l 
Ck ., 
/ 
Go,- - 
DI,- 
.. 
Gk-i--Dk,-- 
/ 
/ 
mo 
/ 
\
I
 
/ 
4
-
1
 
Q., 
Gk‘ 
Proof outline 
By composition and decomposition of the pushout diagrams (1) to (4) on the 
Now we want to extend this equivalence to derivations p = (Go ==+ . . . 
Gk) with k > 1. To this aim we introduce the notion of “sequential com- 
position” of two productions, in order to obtain a single derived produc- 
tion (p) from the composition of the sequence of directly derived productions 
( d l ) ;  (d2);. . . ; (dk). We speak of sequential composition because the application 
of such a composed production has the same effect of a sequential derivation 
based on the original productions. 
Given two productions pl : (L1 &- K1 3 R I )  and p2 : (L2 * 
K2 3 R2) 
Ilol; 
.,or: 
with R1 = La, the sequentially composed production p1;p2 : (L1 t 
K + 
left of Figure 3.17. 
0 
p l , m o  
pk,mk-i 
==+ 

222 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
L1-11- 
I 
'i' 
G-1;- 
--T2 
-I-; 
-7 
Figure 3.17: Horizontal and sequential composition of direct derivations. 
R2) is obtained as shown at the top of the right diagram of Figure 3.17, where 
(5) is a pullback diagram. Derivation G '3 
H1 
H2, where the match 
m2 of the second direct derivation is the co-match of the first, may now be 
realized in one step using the sequentially composed production p1;p2. Vice 
versa, each direct derivation G 
H2 via pl;p2 can be decomposed in a 
derivation G '3 
H1 i H2. 
PI.P m l  
9 
PZ m; 
Proposition 3.6.2 (Sequential Composition) 
Given two productions pl and pa and their sequential composition pl;p2 as 
above, the following statements are equivalent: 
1. There is a direct derivation G P1%m' 
H2. 
2. There is a derivation G '3 HI 
PZ m; H2 such that m; is the co-match 
of ml w.r. t. pl . 
Proof outline 
0 
Combining directly derived productions by sequential composition we now de- 
fine derived productions for derivations of length greater than one: The de- 
rived production (p) of a derivation p = (Go 
==+ Gk) is defined 
as the sequential composition (dl); . . . ; (dk) of the directly derived productions 
di = (Gi-1 
Gi) of p. A direct derivation K ==3 Y using (p) is called 
derived derivation. 
Each derivation sequence may be shortcut by a corresponding derived deriva- 
tion. Vice versa, each derived derivation corresponds to a derivation using the 
By the 3-cube pushout-pullback-lemma [33]. 
Pl,mO . . . Pkvmk-1 
p;,m,-i 
( P )  e 
==+ 

3.6. EMBEDDING, AMALGAMATION AND DISTRIBUTION 
223 
original productions. Hence, these notions solve the Derived Production Prob- 
lem 3.2.4 of Section 3.2.3 in the DPO approach, which is formally stated by 
the theorem below. 
Theorem 3.6.3 (Derived Productions) 
Let p be a derivation and (p) its derived production as defined above. Then 
the following statements are equivalent: 
( P )  eo 
1. There is a derived derivation X O  * Xk . 
2. There is a derivation b = ( X O  p
*
 
... ” b 
nk-l xk) and an embedding 
p -% 6, where eo is the embedding morphism of e. 
Proof outline 
Follows from Proposition 3.6.1, Proposition 3.6.2 by induction over the length 
0 
Let us come back to Problem 3.2.3 of Section 3.2.3 asking for an embedding 
of a derivation into a larger context. This question is now answered using the 
equivalence above, that is, a derivation p may be embedded via an embed- 
ding morphism eo if and only if the corresponding derived production (p) is 
applicable at eo. 
k of the derivation p. 
Theorem 3.6.4 (Embedding) 
Let p = (Go p
*
 
. . . pk%-l 
Gk) be a derivation, (p) its derived production, 
and Go % X o  an embedding morphism. Then there is a derivation b = 
(XO ===+ 
& 
Xk) and an embedding p -% 6 if and only if (p) 
is applicable at eo; that is, if there is a derived derivation X O  3 xk. 
Proof outline 
Theorem 3.6.4 follows from Theorem 3.6.3. 
0 
The embedding theorem above differs from the classical one in [2], which con- 
siders not only the embedding of a derivation into a larger context (called 
“JOIN” in [2]), but also the reduction of the context of a derivation (called 
“CLIP”). In fact, Theorem 3.6.4 corresponds to the “JOIN” part of the clas- 
sical embedding theorem, and the JOIN condition is just the applicability of 
the derived production. 
As anticipated in Section 3.2.3 already, the construction of a derived produc- 
tion for a given derivation p is not only useful in order to solve the embedding 
problem but is interesting in its own right. A related concept has been intro- 
duced in [20] under the name LLconcurrent 
production”, where two productions 
p1,eoomo . . . pr,,eh-lomk-i 
( P )  eo 

224 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
are composed w.r.t. a given dependency relation specifying an overlapping of 
the right-hand side of the first with the left-hand side of the second production. 
The resulting concurrent production enjoys similar properties as the derived 
production above, and is, moreover] minimal w.r.t. to the context included in 
the interface graph 
3.6.2 
Amalgamation and Distribution 
Section 3.2.4 introduced two concepts modeling the synchronization of direct 
derivations] namely amalgamated and (synchronous) distributed derivations. 
In this subsection we formalize these two concepts in the DPO approach and 
show how they are related. 
Amalgamat ion 
Amalgamated derivations describe the synchronized application of productions 
by a so-called amalgamate$d production. The synchronization of two produc- 
tions pl and p2 is modeled by identifying a common subproduction PO: Let 
pi : (L, &- Ki 3 R,) be three productions for k E {01112}. Then produc- 
tion PO together with graph morphisms in; : LO + L1, ink : KO -+ K1 and 
ink : & -+ R1 is a subproduction ofpl if the resulting squares (1) and (2) below 
commute. The embedding of po into pl is denoted by in' = (in;, ink, ink) : 
Po -+Pl. 
Lo --lo -Ko 
--To + Ro 
I 
I 
I 
in; (1) ink (2) ink 
+ 
+ 
t 
L1 --ll - 
K1 -n + R1 
Productions pl and p2 are synchronized w.r.t. pol shortly denoted by pl $ 
po 5 p2, if po is a subproduction of both pl and p2 with embeddings in' 
and in2, respectively. The amalgamated production is obtained as the gluing 
of pl and pa w.r.t. PO, formally described by pushout constructions: Given 
productions pi for i E {0,1,2} as above, the amalgamated production is p1 Bp0 
pz : ( L  A K -% R) in the left diagram below, where subdiagrams (1), (2) 
and (3) are pushouts, and I and r are induced by the universal property of (2) 
such that all subdiagrams commute. A direct derivation G % X using the 
amalgamated production p = pl Bpo p2 is called amalgamated derivation. 

3.6. EMBEDDING, AMALGAMATION AND DISTRIBUTION 
225 
The concept of synchronizing derivations by amalgamation of productions is 
introduced in [ll]. Based on a sequential decomposition of amalgamated pro- 
ductions into the common subproduction p~ and the remainders of the elemen- 
tary production pl -PO and pa -PO, a sequential decomposition of amalgamated 
derivations is developed. Generalizing the Parallelism Theorem, the Amalga- 
mation Theorem of [ll] then establishes a connection between amalgamated 
derivations and derivations using the elementary productions pl , p2 and their 
remainders. 
Distribution 
The concept of distributed graphs allows to model the state of a system by 
interrelated local substates: A distributed graph DG = (GI 
GO 9 
G2) 
consists of two local graphs G1 and G2, an interface graph Go, and graph 
morphisms g1 and 9 2  embedding the interface graph into the local graphs. 
The global graph @DG = GI @ G ~  
G2 of DG is defined as the pushout object 
of g1 and g2 in the right diagram above. Given G = @DG, the distributed 
graph is called a splitting of G. In the DPO approach we consider only total 
splittings, i.e., distributed graphs GI 
Go 4 
G2 where 91 and g2 are total 
graph morphisms. 
The local graphs can be transformed by local direct derivations. In order to 
form a distributed derivation, these direct derivations have to fulfill some com- 
patibility conditions, which are formulated in terms of their matches [22,23]: 
in' 
i n 2  
Let DG be a distributed graph, pl t 
po + p2 synchronized productions, and 
Li 3 Gi, (i E {0,1, a}) be matches for pi which are compatible with DG, i.e., 
g k  om0 = m k  ozni for k E {1,2}. In this case, the family (mi)iE~o,l,2} 
is called 
a distributed match for p l  zt4-' po 5 pa in DG. It satisfies the distributed gluing 
condition if all mi satisfy the local gluing condition of pi for i E {0,1,2}, and 
the connection condition, i.e., gk(Go-mo(Lo-lo(Ko)) C Gk-mk(Lk-lk(Kk)) 
for k E {l,2}. 
The connection condition states, that a distributed derivation is not allowed to 
delete, for example, a vertex 211 of the local graph GI if a corresponding vertex 
IJO in the interface graph Go (i.e., such that gl(v0) = q )  is preserved. Given 

226 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
p -  m. 
a distributed match as above, there are local direct derivations di = (Gi %' 
Hi) for i E {0,1,2} and distributed graphs D D  = (Dl 
DO 3 0 2 )  and 
DH = (H1 3 HO 2 H2) such that dllldod2 : DG * 
DH forms a distributed 
derivation, as shown in the left diagram of Figure 3.18. The graph morphisms 
c1 and c2 of the distributed graph D D  are defined by c1 = 1i-l 0 g1 o 1; and 
c2 = l;-' 
o 92 o 1;. The graph morphisms hl and h2 of DH are induced by 
the universal property of the right-hand side pushout (r;,mg) of the direct 
derivation do. 
Distributed derivations in the DPO approach are synchronous by definition, 
since only total splittings are considered. Given a total splitting @DG, the 
connection condition ensures that also the distributed graphs D D  and DH are 
total splittings [23]. 
The idea of modeling the distribution of states by a splitting a global graph 
into local subgraphs, related by an interface, has been developed in [la]. The 
derivation mechanism of [12], however, is more restricted than the one pre- 
sented here because the local direct derivations are not allowed to change the 
interface graph Go. This corresponds to distributed derivations (in the above 
sense) using a constant interface production PO. In order to be able to change 
the interface graph, a global direct derivation had to be performed with the 
global graph @DG of the distributed graph DG, and two additional opera- 
tions SPLIT and JOIN had to be introduced in order to switch between the 
distributed and the global representation. Distributed derivations with dy- 
namic interfaces (like in this section) have been introduced in [19] in the SPO 
approach. 
Of course, splitting a state into two substates with one interface is a very 
basic kind of a distribution. More general topologies are allowed in [23], where 
a distributed graph may be any diagram in the category Graph of graphs 
and total graph morphisms. In fact, the distribution concepts presented in this 
section are obtained by restricting distributed derivations in the sense of [23] to 
diagrams of the form G1 8- 
Go -% G2. The following distribution theorem 
is a special case of a corresponding theorem in [23]. It provides the solution to 
Problem 3.2.5 by relating amalgamated and distributed derivations. 
Theorem 3.6.5 (Distribution) 
Let DG be a distributed graph and pl $ po $ p2 be synchronized produc- 
tions. Then the following statements are equivalent: 
1. There are an amalgamated derivation @DG 
PI fBp0pz ,m 
+ H ,  and a distrib- 
uted match (mi)iE{o,l,2} 
such that 

3.6. EMBEDDING, AMALGAMATION AND DISTRIBUTION 
227 
Figure 3.18: Distributed derivation, and applicability of subproduction p ,  to local graph G,. 
(a) g; o ml = m o in:* and g; o m2 = m o in;* (i.e., the front and left 
(b) (mz)zE{0,1,2) 
satisfies the connection condition, and 
(c) for i = 0,1,2, m,ls* : L, + S, satisfies the local gluing con- 
dition of p,, where 5’1 = g;-’(m(L)), Sz = g;-’(m(L)), 5’0 = 
(9; o gl)-’(m(L)), and mzls- denotes the codomain restriction of 
m, to S,. 
square in the right diagram of Figure 3.18 commute), 
2. There is a distributed graph DH with @DH = H and a distributed 
derivation dlIIdod2 : DG ==+ DH with di = (Gi % Hi) for i = 0,1,2. 
P mk 
Proof outline 
“1. ==+ 2.”: According to the definition of distributed derivations we have to 
show that there are local direct derivations di = (Gi S Hi) for i = 0,1,2. 
Then, the existence of the distributed derivation dllldod2 : DG ==-+ DH follows 
from the existence of a distributed match satisfying (a) and (b) of 1. Condition 
(c) covers the difference between the gluing conditions of the local derivations 
and that of the given amalgamated derivation, i.e., the gluing condition for 
di follows from the gluing condition of @DG 
H and the dzflerence 
gluing condition (c). 
“2. ==+ l.’,: Given a distributed derivation d l I I dod2 : DG 3 DH as in Fig- 
ure 3.18 on the left, the amalgamated derivation @DG 
@DH is ob- 
tained by constructing the global graphs @DG, @DD, and @DH as pushouts, 
and the morphisms of the co-production @DG 
e D D  5 @DH as the 
universal morphisms induced by the pushout property of e D D .  The vertical 
morphisms m : L + @DG, d : K -+ @DD, and m* : R -+ @DH are induced 
p .  m .  
P I @ , ~ P Z , ~  
==+ 
P I @ , , P ~ , ~  
& 

228 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
in a similar way by the universal property of the pushout objects L, K ,  and R 
0 
of (ini,ini), 
(inklink), 
and (in&,znk). 
3.7 
Conclusion 
For a detailed comparison between the DPO and the SPO approach and for 
concluding remarks about the contents of the two parts we address the reader 
to Sections 4.6 and 4.7. 
Acknowledgements 
Most of the research results presented in this chapter have been developed 
within the ESPRIT Working Groups COMPUGRAPH (1989-1992) and COM- 
PUGRAPH I1 (1992-1996). 
3.8 
This appendix addresses a quite technical topic: it introduces the notion of 
binary coproduct in a category, and shows that coproducts cannot be assumed 
to be commutative (in a strict way) unless the category is a preorder. This 
fact justifies the way we defined parallel productions (Definition 3.4.4) and 
their manipulation in Section 3.4, which may appear more complex than the 
corresponding definitions in previous papers in the literature. 
In any category, a coproduct is an instance of the more general concept of 
colimit [18]. In the category Set of sets and functions (as well as in Graph) 
the coproduct of two objects is their disjoint union. In the following discussion 
we stick to binary coproducts, but most statements can be adapted to any 
kind of limit or colimit construction. 
Appendix A: On commutativity of coproducts 
Definition 3.8.1 (coproducts) 
Let C be a category and A, B be two objects of C. A coproduct of (A, B )  is a 
triple (A+B, 
where A+B is an object and 
: A + A+B, 
: B + A + B are arrows of C, such that the following universal property 
holds (see Figure 3.19(a)): 
0 for all pair of arrows (f : A + C, g : B + C )  there exists a unique arrow 
[ f , g ]  : A + B -+ C such that [ f , g ]  o 
= f and [ f , g ]  o 
= 9. 
In this case A + B is called a coproduct object of (A, B), and 
are 
called the injections; arrow [ f , g ]  is called the copairing of f and g. One says 
that category C has coproducts if each pair of objects of C has a coproduct. 

3.8. APPENDIX A 
229 
( a) 
(b) 
Figure 3.19: (a) Coproduct. (b) Isomorphisms between distinct coproduct objects. 
In the following we assume that C has coproducts. From the definition it is 
evident that the coproduct of two objects is in general not unique. However, 
given any two coproducts of two objects they are not only isomorphic, but 
there exists only one isomorphism commuting with the injections. This fact 
holds for limits and colimits in general [18]. 
Fact 3.8.2 (uniqueness of coproducts up to isomorphism) 
Let (A + B, i n f f B ,  i n t f B )  and ( A  @ B, 
be two coproducts of 
(A, B )  in C .  Then objects A + B and A @ B are isomorphic, and there exists 
only one isomorphism 4 : A + B -+ A @ B such that 
= 4 o in, 
A+B 
and in;'B = 4 o in;+B. As shown in Figure 3.19(b), 4 is determined by the 
universal property of A+B as 4 = [infeB, infeB], and similarly for its inverse 
0 
4-l = [in, 
,2n2 1. 
Often it is useful to regard the formal operator + used to denote coproduct 
objects as a real function, returning a specific object of C ,  and not merely 
specifying a class of isomorphic objects. This can be obtained by fixing a choice 
of coproducts, i.e., by fixing a specific coproduct for each pair of objects. Every 
choice of coproducts determines a coproduct functor as follows. 
A+B . A+B 
Definition 3.8.3 (coproduct functor) 
Suppose that a choice of coproducts for C is given, i.e., a mapping associating 
determines a bifunctor + : C2 + C ,  called the coproduct functor, defined on 
objects as +(A, B) = A + B. On arrows, if f : A + C and g : B -+ D are in 
C ,  then +(f,g) (more often written f + g) is uniquely determined, using the 
universal property of coproducts, as f + g = [zn, 
0 g] : A + B + 
C + D, as shown in Figure 3.20(a). 
with each pair of objects (A, B) a coproduct, say ( A  + B, in, 
A+B , zn2 
' A + B ) .  This 
def . C f D  
0 f, 

230 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
+(A, B )  = A + B 
Figure 3.20: (a) Coproduct of arrows. (b) Commutativity up to natural isomorphism. 
Coproducts are widely used in the algebraic theory of graph grammars, for ex- 
ample in the definition of parallel productions (see Definition 3.4.4). A natural 
question that arises in this framework is: Can one consider the coproduct func- 
tor as commutative? We show here that although every coproduct functor is 
commutative up to a natural isomorphism, in general it is not safe to assume 
that it is strictly commutative, i.e., commutative up to the identity natural 
transformation. 
Fact 3.8.4 (commutativity up to natural isomorphism of coproducts) 
Any coproduct functor + : C2 + C is commutative up to a natural iso- 
morphism, in the following sense. Let X : C2 + C2 be the functor that 
exchanges its arguments (i.e., X ( A ,  B) = (B, A)). Then there exists a natural 
transformatiofi y : + + + o X : C2 + C ,  such that Y A , B  is an isomorphism 
for each A, B. The component ~ A , B  
of the natural isomorphism y is easily de- 
termined as in Figure 3.20(b), and the proof of the naturality of y is routine. 
0 
We are now ready to say when a coproduct functor is strictly commutative. 
Although the following definition may look very restrictive, it seems to be the 
only reasonable one in a categorical framework: compare it, for example, to 
the definition of strict monoidal categories in [HI. 
Definition 3.8.5 (strictly commutative coproduct functors) 
A coproduct functor + : C2 + C is strictly commutative if the natural isomor- 
phism y : + + + o X : C2 + C is the identity natural transformation. This 
eGiven two functors F,G : C -+ D, a natural transformation y : F + G : C -+ D is 
a family of arrows of D indexed by objects of C ,  y = {YA I A E Obj(C)}, such that YA : 
F(A) --t G(A), and satisfying the following naturality condition: for each arrow f : A -+ B 
of C ,  W )  
0 YA = Y B  0 F ( f )  (see [181). 

3.8. APPENDIX A 
231 
Figure 3.21: Strict commutativity of coproducts implies that all parallel arrows (like f and 
g) are identical. 
means not only that A + B = B + A (they are the same object), but also that 
~ A , B  
=  id^+^ for each pair (A, B). 
The following result shows that if a category C has a coproduct functor that 
is strictly commutative, then C is a preorder, i.e., there is at most one arrow 
between each pair of objects. Since none of the categories of graphs (or of 
other structures) considered in the algebraic theory of graph grammars is a 
preorder, this fact shows that one cannot assume, in general, that “coproducts 
are strictly commutative”. 
Proposition 3.8.6 (strictly commutative coproducts and preorders) 
Let C be a category that has coproducts, and suppose that there exists a choice 
of coproducts for C such that the induced coproduct functor + : C2 -+ C 
is strictly commutative. Then C is a preorder, i.e., for each pair of arrows 
f,g : A -+ B, it holds f = g. 
Proof 
By the definition of strict commutativity, YA,B =  id^+^; thus the diagram 
in Figure 3.21(a) shows that the injections of A in A + B and in B + A, i.e., 
inffB and in;fA, are exactly the same arrow, because the two triangles must 
commute. Because of the same reason, if we consider the coproduct of A with 
itself, then it turns out that there is only one injection 
= 
from 
A to A + A, as depicted in Figure 3.21(b). Suppose now that there are two 
arrows f , g  : A 4 B. By the universal property there is only one arrow [f,g] : 
A + A + B (as shown in Figure 3.21(c)) such that [f, g] o 
= f and 
[f,g] o 
= g. Therefore, since inffA = in$+A, we have that f = g, and 
C is a preorder. 
0 

232 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
Other assumptions on the properties of coproducts or on the category C may 
yield similar results, as stated by the following corollary. 
Corollary 3.8.7 
1. Say that a category C has unique coproducts if it has coproducts and 
: 
: B -+ A + B) satisfying the universal property. If a 
for each pair of objects (A, B) there is only one triple ( A  + B, 
A + A + 
category C has unique coproducts, then it is a preorder. 
2. If C has coproducts and C has no non-trivial automorphisms (i.e., for 
each object A there is only one isomorphism from A to itself, the iden- 
0 
Both statements are easily proved by showing first that the hypotheses imply 
that there is only one injection from A to A + A, and then using the diagram 
of Figure 3.21(c). 
Finally, it is worth stressing that the uniqueness of coproduct objects is not 
sufficient to deduce that a category is a preorder. More formally, if C has 
coproducts, say that it has unique coproduct objects if for each pair of objects 
(A, B) and for each pair of coproducts of (A, B), say (C, in? : A -+ C, in: 
: 
B -+ C) and (D, inf : A + D , in? : B + D), 
one has C = D. For example, 
the (skeletal) full sub-category of finite sets having as objects (14 I n E N}, 
where n = { 1,2,. . . , n}, has unique coproduct objects but it is not a preorder. 
tity), then C is a preorder. 
3.9 
This appendix presents the proof of Lemma 3.5.11, which is the main technical 
result of Section 3.5.3. This proof is based on the constructive proofs of Lem- 
mas 3.4.8 and 3.4.9 (i.e., the synthesis and analysis constructions) which are 
reported below for completeness, and also because they show in an instructive 
way the kind of reasoning that is used when proving results in the algebraic 
approach to graph transformations. To start with, we need the following well- 
known technical lemma [3]. 
Appendix B: Proof of main results of Section 3.5 
Lemma 3.9.1 (Butterfly lemma) 
Let al and a2 be injective graph morphisms. Then the square (1) of Figure 
3.22 is a pushou t if and only if there are graphs X I ,  X z  and graph morphisms 
r, s, v, w, t and u, 
such that in the right part of the same figure diagrams (2), 
(31, and (4) are pushouts, (4) is a pullback, and all triangles commute. 

3.9. APPENDIX B 
233 
C- 
D 
Figure 3.22: Butterfly Lemma. 
Proof of Lemma 3.4.8 (analysis of parallel direct derivations) 
Let p = (G 
H )  be a parallel direct derivation using the parallel production 
q = pl + . . . + p k  : ( L  t K 3 R). Then for each ordered partition ( I  = 
(il ,... . i n ) , J = ( j l , . . .  , j m ) )  o f ( 1 ,  ... , k }  (i.e.,IUJ= (1 ,... , k }  a n d I n J =  
0 )  there is a constructive way to obtain a sequential independent derivation 
p‘ = (G ==+ X * 
H ) ,  called an analysis of p, where q’ = p,, + . . . +pa,,, and 
If I = () (or J = ()) the statement follows by taking X = G ( X  = H ) ,  
q” = q (q’ = q), and an empty direct derivation as q’ (4”). Now let us assume 
that q is a proper parallel production, and that I and J are not empty. By 
the hypotheses on I and J ,  productions q’ + q” and q are clearly isomorphic 
via the permutation ll defined as H(z) = i, if 1 5 z 5 n and II(z) = jz-.n 
if 
n < z 5 n+m (see Definition 3.4.4). Thus since the left diagram of Figure 3.23 
is a double-pushout by hypothesis, the right diagram is a double-pushout as 
well, where we supposed that q‘ : (L1 k XI 3 R1) and q“ : (L2 k K2 3 R2). 
Therefore we can apply Lemma 3.9.1 to (1) and (2), obtaining the pushouts 
(3)-(5) and (6)-(8), respectively, shown in Figure 3.24. Now let (9) be the 
pushout of arrows 1 and u, where the pushout object is called X (left part of 
Figure 3.25). Then we can build the required derivation via q‘ and q” as in 
the right part of Figure 3.25, where we exploited the well-known fact that a 
square consisting of two adjacent pushouts is again a pushout. Such derivation 
is sequential independent because it is easy to check that arrows f : Lz + X ,  
1 
q’ 
P” 
q“ = p,, + . . . + p,_. 

234 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
Figure 3.23: Splitting a parallel production. 
m2 
nz 
Figure 3.24: Application of the Butterfly Lemma. 

235 
q” = P J ,  + . . . + P j ,  : 
3.9. APPENDIX B 
q’=pa, +...+pi, : 
U 
(t1- 
I1 
Kl-Rl) 
r1 
(Lz&K2 
I 
+z) 
D- 
l’i 
J 
xz - 
X 
G- 
xz - 
X-- 
Yl - 
H 
Figure 3.25: Building the sequential derivation. 
xz -x-i1 
- 
H 
G7 
3 
P 
Figure 3.26: A sequential independent derivation. 
and t : R1 + Y1 satisfy the conditions of Definition 3.4.2. 
0 
Proof of Lemma 3.4.9 (synthesis of sequential independent derivations) 
Let p = (G 
X & H )  be a sequential independent derivation. Then there 
is a constructive way to obtain a parallel direct derivation p’ = (G 4 H ) ,  
called a synthesis of p. 
Let p be the sequential independent derivation of Figure 3.26. We have to 
show that the commutative diagrams of Figure 3.24 can be constructed, where 
squares from (3) to (8) have to be pushouts, and (4) and (8) need to be pull- 
backs. Then by two applications of the Butterfly Lemma we obtain the parallel 
production in the right part of Figure 3.23, as required. 
The diagrams of Figure 3.24 are constructed as follows. Some of the graphs and 
of the morphisms are taken from the derivation p of Figure 3.26. The others 
are obtained constructively in the following way: 
q’+ ” 
0 ( D ,  k2, 1) is taken as a pushout complement of (12, f). It is determined up 
to isomorphism because 12 is injective. Thus square (5) is a pushout by 
construction, and 1 is injective because so is 12 and in category Graph 
pushouts push out monos. 

236 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
0 Morphism kl : K 1  + D is determined by showing that morphism g : 
K1 -+ X 2  factorizes through I ,  i.e., that there exists a kl such that 
1 o k 1  = g; then, since 1 is injective, k1 is unique. 
We have to show that the image of K1 in X 2  (i.e.] g ( K 1 ) )  is contained 
in the image of D in X z ,  i.e., in 1(D). Since X 2  is the pushout object of 
( l z 1  kz), this is false only if g(K1) contains an item z E f ( L 2 )  such that 
z $! f ( l z ( K 2 ) ) .  But since X is the pushout object of (12, h) and j o f  = s, 
this would mean that j ( z )  is in s(&) but not in i ( Y l ) ,  which is absurd 
by the existence of a morphism t : R1 -+ 
Y 1  such that i 0 t = T .  
0 (X,,a,b) is taken as a pushout of (11,kl). Thus (3) is a pushout by 
construction, and b is injective because so is 11. 
0 Morphism x is defined as x = d o 1. 
Morphism c is uniquely determined by condition rnloll = dog = dolokl = 
x o k l ,  because (3) is a pushout. 
0 By a well-known decomposition property of pushouts, square (4) is a 
pushout because so are (3) and (3) + (4). Thus c is injective because so 
is 1. 
Square (4) is a pullback] because any pushout in Graph made of injective 
morphisms is a pullback as well. 
Let us show that j o 1 factorizes through i :  this uniquely determines 
morphism u so that square (9) in Figure 3.24 commutes and u is injective, 
because so are 1, j ,  and i; moreover, square (9) is a pushout because so 
are (5) and (5) + (9). 
To show that j o 1 factorizes through i we prove that the image of D in 
X ,  j ( l ( D ) ) ,  is contained in the image of Y1 in XI i(Y1). Otherwise] since 
X is the pushout object of (12, h), there is an item z = j ( l ( z " ) )  such that 
z E s(L2) and z 6 s(la(K2)). 
Let z' E L2 be such that s(z') = z (thus 
z' $! l z ( K 2 ) ) ;  then we have j ( f ( z ' ) )  = s(z') = z = j ( l ( ~ " ) ) ~  
which implies 
f ( z ' )  = l(z") by injectivity of j. But since X 2  is the pushout object of 
(12, k 2 ) ]  this implies that z' E 1 2 ( K 2 ) ,  which is absurd. 
(yZ, w, 
u )  is taken as a pushout of (kz, 1-2). Therefore (7) is a pushout and 
u is injective because so is 1-2. 
Morphism y is defined as y = p o u. 

3.9. APPENDIX B 
237 
A 
C 
Figure 3.27: Isomorphic pushouts and pushout complements. 
0 Morphism q is uniquely determined by the condition n2 o 1-2 = p o h = 
p 0 u 
0 kz = y o kz, because (7) is a pushout. 
0 Since (7) and (7) + (8) are pushouts, also (8) is a pushout. Thus q is 
injective because so is u. Square (8) is also a pullback because all its 
morphisms are injective. 
0 Finally, by the so-called “pushout-pullback decomposition property” (see 
[20]) which holds for category Graph (with injective morphism as dis- 
tinguished class of morphisms M), since (6) + (8) is a pushout, (8) is 
a pullback, and morphisms T I ,  u, 
w, q and p are injective, then (6) is a 
The next easy technical lemma will be helpful in the proof of the main result 
below. 
Lemma 3.9.2 (existence and uniqueness of some constructions) 
Given morphisms f ,  g, f’, and g’ and isomorphisms q 5 ~ ,  4 ~ ,  
and q5c1 as 
in Figure 3.27, such that the two resulting squares commute, let ( D ,  h, k )  be a 
pushout of (f, 
9). Then 
0 Thereexistsatleast onepushout of(f’,g’),given by(D,hoq5i1,koq5C1). 
0 For each pushout (D’, h’, k’) of (f‘, g’), there exists a unique isomorphism 
pushout as well. 
0 
1. 
4~ : D + D’ that makes the diagram commutative. 
2. 
Given injective morphisms f and f I, morphism h and h‘, and isomorphisms 
4~ , 4~ , and 4 ~ ,  
as in Figure 3.27, such that the two resulting squares commute, 
let (C, 9, k )  be a pushout complement of (f, h). Then: 
0 There exists at least onepushout complement of (f’, h’), given by (C,go 
42’1d’D O k ) .  

238 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
For each pushout complement (C‘,g‘, k’) of (f‘, h’), there exists an iso- 
morphism 4~ : C + C‘ that makes the diagram commutative. 
Proof 
Point 1 holds in any category, and it is a direct consequence of the uniqueness 
of colimits up to a unique mediating isomorphism [18]. Point 2 follows instead 
from specific properties of the category Graph, where the pushout complement 
happens to be unique up to isomorphism if the top arrow is injective (see 
Proposition 3.3.4). 
0 
Finally, we can present the proof of Lemma 3.5.11, stating that analysis, syn- 
thesis and shift preserve equivalence -1 on derivations. Since most of the work 
was in the presentations of the constructive proofs of Lemmas 3.4.8 and 3.4.9, 
some parts of the proof are just outlined. 
Proof of Lemma 3.5.11 (analysis, synthesis and shift preserve G I )  
Let p -1 
p’ via (IIi)isn, 
and let 4~~ and 4 ~ ”  
be the corresponding isomor- 
phisms between their starting and ending graphs (see Figure 3.14). 
1. (Analysis) If p1 E ANALj(p), then there exists at least one derivation 
p2 E ANAJ!&(~)(~’). 
Moreover, for each p2 E A N A G i ( , ) ( p ’ ) ,  it holds that 
pz ~1 p1 with the same isomorphisms 4 ~ , ,  
and 4 ~ , ,  
relating their starting and 
ending graphs. 
For simplicity, we assume that p and p’ are parallel direct derivations (thus 
p -1 p’ via 11): the generalization to equivalent derivations of arbitrary length 
is straightforward. The existence of a derivation p2 E ANAL,(,) (p’) is ensured 
by Lemma 3.4.8. 
If p = (G * H )  and p’ = (G’ 
HI), exploiting the same tech- 
nique used above at the beginning of the proof of Lemma 3.4.8, the two direct 
derivations can be transformed into corresponding derivations 77 = (G ==?- H )  
and 7’ = (G’ 
HI), where q2 = pl + . . . + pj-1 + p j + ~  + . . . + pk, and 
Suppose now that p j  : (L1 & K1 
Rl), ph(j, : (Li & Ki 5 Ri), q 2  : (Lz @ 
K2 3 Rz), and q& : (Li tT- Ka 3 Ri)! By construction it is clear that 77 and 
7’ are 1-equivalent because so are p and p’. Let If1 be the unique permutation 
Pl+. . . f P k  
P; +. . .+p; 
Pj+ 2 
P L ( , ) + d  
* 
qa = Pi + . . . + P k ( j ) - 1  1- &(,)+I + . . ‘ + Pk. 
1 
1’ 
1’ 
fNote that since p j  = p h c j , ,  we have X1 = X i  for X E {L, 
K ,  R,Z,r}. They have different 
names just for ease of reference. 

3.9. APPENDIX B 
239 
on { l} and I I 2  be the bijective mapping between the productions of q2 and qb 
induced by II: II1 and IIz will be used below. 
Without loss of generality, let us assume that derivations 7 and q’ have the same 
shape of the right double-pushout of Figure 3.23, more precisely, that the direct 
derivation (1) + (2) of Figure 3.23 is 7, that 7’ is an identical diagram (1‘) + (2’) 
where all the names of graphs and morphisms have an apex, and that 7 and 
7’ are related by a family of isomorphisms {C$X : X + X’ I X is a graph of q} 
making the diagram commutative. In particular, also the squares obtained 
by considering individually the components of each coproduct commute (for 
example, 4~ 
0 ml = mi 0 q
5
~
~
 
and q 5 ~  
o m2 = mi 0 4 ~ ~ ) .  
Following the construction of the proof of Lemma 3.4.8, diagrams as in Figure 
3.24 plus square (9) of Figure 3.25 can be constructed (in a non-deterministic 
way) for both q and 7’. We show below that each pair of collections of diagrams 
obtained in this way induces a unique family of isomorphisms between corre- 
sponding graphs of the diagrams, which includes the family of isomorphisms 
relating 7 and q’. These isomorphisms, together with the permutations II1 and 
I I 2  introduced above, prove that the two sequential derivations obtained from 
q and 7’ (like that in the right part of Figure 3.25) are indeed 1-equivalent. 
This construction shows also that the isomorphisms 4~ and $H relating the 
starting and ending graphs of p and p’ are not changed. 
Let us assume that the diagrams of Figure 3.24 and square (9) of Figure 3.25 
are obtained from derivation 7, and that similar diagrams (but where all the 
names of graphs and morphisms have an apex) are obtained from 7’. All the 
corresponding graphs of the two families of diagrams are related by the iso- 
morphisms relating 7 and q’, except of X I ,  X z ,  Y1, Y2 and X .  Isomorphism 
4x1 : X1 -i 
X i  is uniquely determined by point 1 of Lemma 3.9.2, because 
(3) and (3’) are pushouts; using the same argument, isomorphism 4x2, 4y1, 
4yZ and 4~ are uniquely determined as well, because their source and target 
graphs are pushout objects. It is straightforward to check that the resulting 
family of isomorphisms makes everything commutative. 
2. (Synthesis) Ifp1 E SYNTZ(p), then there exists at least one derivation 
p2 E SYNTZ(p’). Moreover, for each pz E SYNTi(p’), it holds that p2 
p1 
with the same isomorphisms 4~~ and $G,, 
relating their starting and ending 
graphs. 
We assume without loss of generality that p and p’ have length 2, thus p -1 p’ 
via (II1, I I 2 ) .  Since p1 E SYNT(p) by hypothesis, derivation p is sequential 
independent: let it be the derivation of Figure 3.26. To show the existence of a 
p2 E SYNT(p‘), by Lemma 3.4.9 it is sufficient to show that that p’ is sequential 
independent as well. Let p’ be as in Figure 3.26, but with all names of graphs 

240 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
and morphisms having an apex. Since p -1 
p’, there is a family of isomorphisms 
relating the corresponding graphs of p and p’ so that everything commutes: 
thus morphism f’ and t’ making p’ sequential independent exists, and are 
uniquely determined (because i’ and j’ are injective) as f’ = $x2 o f o 4;; 
and 
Since both p and p’ are sequential independent, the diagrams of Figure 3.24 
can be constructed (non-deterministically) for both of them, in such a way 
that the required squares are pushouts or pullbacks. 
We show below that such constructions induce a family of isomorphism be- 
tween the corresponding graphs of the diagrams, which includes the family of 
isomorphisms relating p and p‘. The resulting isomorphisms can then be used 
to show that the two parallel direct derivations (similar to that of Figure 3.23) 
obtained from p and p’ respectively are l-equivalent. For the mapping between 
productions, it is obtained in the obvious way by joining the permutations 
( I I 1 ,  II,) which relate the productions used in p and p’. 
To prove that the diagrams of Figure 3.24 constructed for p and p’ induce 
isomorphisms between corresponding graphs, it is sufficient to go through the 
proof of Lemma 3.4.9. In particular, the missing isomorphisms 4~ : D -+ D’, 
4x1 : X1 --+ X i ,  and i$y2 : Y2 + Yi are determined by Lemma 3.9.2, because 
the corresponding graphs are either pushout objects or pushout complement 
objects (and suitable morphisms are injective). The remaining steps of the 
mentioned proof are needed to show constructively that all the squares induced 
by the family of isomorphisms commute. 
3. (Shift) If p1 E SHIFTj(p), then there exists at least one derivation p2 E 
SHIFTi;(j,(p‘). Moreover, for each p2 E SHIFT$;(j,(p’), it holds that p2 -l 
p1 with the same isomorphisms 
and 4~~ relating their starting and ending 
graphs. 
If j 2 1, the proof is immediate by exploiting points 1) and 2), because 
SHIFT; = SYNTiP1 o ANAL; by Definition 3.5.4. If instead j = 0 (and thus 
IIi(j) = 0 as well), then both p and p‘ end with an empty direct derivation, and 
p1 and p2 are uniquely determined by the construction described in Definition 
3.5.4, because relation SHIFT; is deterministic. It is easy to check that if this 
construction is applicable to p, then it is applicable to p’ as well, producing 
l-equivalent derivations. 
0 
t‘ = 4y1 0 t 0 f&;. 
References 
1. H. Ehrig, M. Pfender, and H.J. Schneider. Graph-grammars: an alge- 
braic approach. In Proceedings IEEE Conf. on Automata and Switching 
Theory, pages 167-180, 1973. 

REFERENCES 
241 
2. H. Ehrig. Introduction to the Algebraic Theory of Graph Grammars. In 
V. Claus, H. Ehrig, and G. Rozenberg, editors, Proceedings of the 1st 
International Workshop on Graph-Grammars and Their Application to 
Computer Science and Biology, volume 73 of Lecture Notes in Computer 
Science, pages 1-69. Springer Verlag, 1979. 
3. H. Ehrig. Tutorial introduction to the algebraic approach of graph- 
grammars. In H. Ehrig, M. Nagl, G. Rozenberg, and A. Rosenfeld, edi- 
tors, Proceedings of the 3rd International Workshop on Graph-Grammars 
and Their Application to Computer Science, volume 291 of Lecture Notes 
in Computer Science, pages 3-14. Springer Verlag, 1987. 
4. H. Ehrig, M. Korff, and M. Lowe. Tutorial introduction to the algebraic 
approach of graph grammars based on double and single pushouts. In 
H. Ehrig, H.-J. Kreowski, and G. Rozenberg, editors, Proceedings of the 
4th International Workshop on Graph-Grammars and Their Application 
to Computer Science, volume 532 of Lecture Notes in Computer Science, 
pages 24-37. Springer Verlag, 1991. 
5. M. Lowe. Algebraic approach to single-pushout graph transformation. 
Theoret. Comput. Sci., 109:181-224, 1993. 
6. H.-J. Kreowski. Is parallelism already concurrency? Part 1: Derivations 
in graph grammars. In H. Ehrig, M. Nagl, G. Rozenberg, and A. Rosen- 
feld, editors, Proceedings of the 3rd International Workshop on Graph- 
Grammars and Their Application to Computer Science, volume 291 of 
Lecture Notes in Computer Science, pages 343-360. Springer Verlag, 
1987. 
7. H.-J. Kreowski and A. Wilharm. Is parallelism already concurrency? Part 
2: Non-sequential processes in graph grammars. In Proceedings of the 3rd 
International Workshop on Graph-Grammars and Their Application to 
Computer Science, volume 291 of Lecture Notes in Computer Science, 
pages 361-377. Springer Verlag, 1987. 
8. P. Padawitz. Graph grammars and operational semantics. Theoret. Com- 
9. B. Hoffmann and D. Plump. Implementing Term Rewriting by Jun- 
gle Evaluation. Informatique the'orique et Applications/Theoretical In- 
formatics and Applications, 25:445-472, 1991. 
10. A. Corradini and F. Rossi. Hyperedge Replacement Jungle Rewriting 
for Term Rewriting Systems and Logic Programming. Theoret. Comput. 
11. P. Bohm, H.-R. Fonio, and A. Habel. Amalgamation of graph transfor- 
mations: a synchronization mechanism. Journal of Computer and System 
Science, 34:377-408, 1987. 
put. Sci., 19:37-58, 1982. 
Sci., 109~7-48, 1993. 

242 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
12. H. Ehrig, P. Bohm, U. Hummert, and M. Lowe. Distributed parallelism of 
graph transformation. In 13th Int. Workshop on Graph Theoretic Con- 
cepts an Computer Science, volume 314 of Lecture Notes an Computer 
Science, pages 1-19. Springer Verlag, 1988. 
13. H. J. Schneider. Describing distributed systems by categorial graph gram- 
mars. In 15th International Workshop on Graph-theoretic Concepts in 
Computer Science, volume 411 of Lecture Notes in Computer Science, 
pages 121-135. Springer Verlag, 1990. 
14. M. Korff. Graph-interpreted graph transformations for concurrent object- 
oriented systems. Submitted for publication, 1995. 
15. H. Ehrig and R. Bardohl. Specification techniques using dynamic ab- 
stract data types and application to shipping software. In Proc. of the 
International Workshop on Advanced Software Technology, pages 70-85, 
1994. 
16. M. Lowe. Implementing algebraic specifications by graph transfor- 
mations. Journal for Information Processing and Cybernetics (EIK), 
17. A. Habel. Hyperedge Replacement: Grammars and Languages, volume 
643 of Lecture Notes in Computer Science. Springer Verlag, 1992. 
18. S. Mac Lane. Categories for the working mathematician. Springer Verlag, 
1971. 
19. J. Adamek, H. Herrlich, and G. Strecker. Abstract and Concrete Cate- 
gories. Wiley Interscience, 1990. 
20. H. Ehrig, H.-J. Kreowski, and G. Taentzer. Canonical derivations for 
high-level replacement systems. In H.-J. Schneider and H. Ehrig, editors, 
Proceedings of the Dagstuhl Seminar 9301 on Graph Transformations an 
Computer Science, volume 776 of Lecture Notes in Computer Science, 
pages 153-169. Springer Verlag, 1994. 
21. H. Ehrig, A. Habel, H.-J. Kreowski, and F. Parisi-Presicce. Parallelism 
and Concurrency in High-Level Replacement Systems. Mathematical 
Structures in Computer Science, 1:361-404, 1991. 
22. W. Reisig. Petri Nets: An Introduction. EACTS Monographs on Theo- 
retical Computer Science. Springer Verlag, 1985. 
23. A. Corradini, U. Montanari, and F. Rossi. Graph processes. Fundamenta 
Informaticae, 1996. To appear. 
24. M. Korff. True Concurrency Semantics for Single Pushout Graph Trans- 
formations with Applications to Actor Systems. In Proceedings Interna- 
tional Workshop on Information Systems - Corretness and Reusability, 
IS-CORE’94, pages 244-258. Vrije Universiteit Press, 1994. Tech. Report 
26(11/12):615-641,1990. 
IR-357. 

REFERENCES 
243 
25. M. Korff and L. Ribeiro. Concurrent Derivations as Single Pushout 
Graph Grammar Processes. In A. Corradini and U. 
Monta- 
nari, editors, Proceedings SEGRAGRA '95, volume 2 of Electronic 
Notes in Theoretical Computer Science. Elsevier Sciences, 1995. 
http://www.elsevier.nl/locate/entcs/volume2.html. 
26. G. Winskel. An introduction to event structures. In Linear Time, Branch- 
ing Time and Partial Order in Logics and Models for Concurrency, vol- 
ume 354 of Lecture Notes in Computer Science, pages 325-392. Springer 
Verlag, 1989. 
27. G. Schied. On relating rewriting systems and graph grammars to event 
structures. In H.-J. Schneider and H. Ehrig, editors, Proceedings of the 
Dagstuhl Seminar 9301 on Graph Transformations in Computer Sci- 
ence, volume 776 of Lecture Notes in Computer Science, pages 326-340. 
Springer Verlag, 1994. 
28. A. Corradini, H. Ehrig, M. Lowe, U. Montanari, and F. Rossi. An event 
structure semantics for safe graph grammars. In E.-R. Olderog, editor, 
Programming Concepts, Methods and Calculi, IFIP Transactions A-56, 
pages 423-444. North-Holland, 1994. 
29. A. Corradini, H. Ehrig, M. Lowe, U. Montanari, and F. Rossi. An Event 
Structure Semantics for Graph Grammars with Parallel Productions. In 
J. Cuny, H. Ehrig, G. Engels and G. Rozenberg, editors, Proceedings of 
the Fifth International Workshop on Graph Grammars and their Appli- 
cation to Computer Science, volume 1073 of Lecture Motes in Computer 
Science, pages 240-256. Springer Verlag, 1996. 
30. R. Heckel, J. Miiller, G. Taentzer, and A. Wagner. Attributed graph 
transformations with controlled application of rules. In G. Valiente and 
F. Rossello Llompart, editors, Proc. Colloquium on Graph Transforma- 
tion and its Application in Computer Science. Technical Report B - 19, 
Universitat de les Illes Balears, 1995. 
31. A. Corradini and R. Heckel. A Compositional Approach to Structur- 
ing and Refinement of Typed Graph Grammars. In A. Corradini and 
U. Montanari, editors, Proceedings SEGRAGRA '95, volume 2 of Elec- 
tronic Notes in Theoretical Computer Science. Elsevier Sciences, 1995. 
http://www.elsevier.nl/locate/entcs/volume2.html. 
32. R. Heckel, A. Corradini, H. Ehrig, and M. Lowe. Horizontal and Vertical 
Structuring of Graph Transformation Systems. Mathematical Structures 
in Computer Science, 1996. To appear. 
33. A. Corradini, H. Ehrig, M. Lowe, U. Montanari, and J. Padberg. The 
Category of Typed Graph Grammars and their Adjunction with Cate- 
gories of Derivations. In J. Cuny, H. Ehrig, G. Engels and G. Rozenberg, 

244 
CHAPTER 3. DOUBLE PUSHOUT APPROACH 
editors, Proceedings of the Fifth International Workshop on Graph Gram- 
mars and their Application to Computer Science, volume 1073 of Lecture 
Notes in Computer Science, pages 56-74. Springer Verlag, 1996. 
34. M. Korff. Single pushout transformations of equationally defined graph 
structures with applications to actor systems. In H.-J. Schneider and 
H. Ehrig, editors, Proceedings of the Dagstuhl Seminar 9901 on Graph 
Transformations in Computer Science, volume 776 of Lecture Notes in 
Computer Science, pages 234-247. Springer Verlag, 1994. 
35. R. Heckel and A. Wagner. Ensuring consistency of conditional graph 
grammars - a constructive approach. In A. Corradini and U. Mon- 
tanari, editors, Proceedings SEGRAGRA '95, volume 2 of Electronic 
Notes in Theoretical Computer Science. Elsevier Sciences, 1995. 
http://www.elsevier.nl/locate/entcs/volue2.html. 
36. D. Plump. Hypergraph Rewriting: Critical Pairs and Undecidability of 
Confluence. In M.R Sleep, M.J. Plasmeijer, and M. C.J.D. van Eekelen, 
editors, Term Graph Rewriting, pages 201- 214. Wiley, 1993. 
37. D. Plump. On termination of graph rewriting. In M. Nagl, editor, Proc. 
2lst Workshop on Graph- Theoretic Concepts in Computer Science (WG 
'95). volume 1017 of Lecture Notes in Computer Science, pages 88--100. 
Springer Verlag, 1995. 
38. M. Lowe and J. Miiller. Critical pair analysis in single-pushout graph 
rewriting. In G. Valiente Feruglio and F. Rosello Llompart, editors, Proc. 
Colloquium on Graph Transformation and its Application in Computer 
Science. Technical Report B-19, Universitat de les Illes Balears, 1995. 
39. H. Ehrig and M. Lowe. Categorical principles, techniques and results for 
high-level replacement systems in computer science. Applied Categorical 
Structures, 1(1):21-50, 1993. 
40. M. Lowe. Extended algebraic graph transformation. PhD thesis, Technis- 
che Universitat Berlin, 1990. 
41. M. Korff. Generalized graph structure grammars with applications to 
object-oriented systems. PhD thesis, Technical University of Berlin, 1995. 
42. J.A. Goguen. A categorical manifesto. Math. Struc. Comput. Sci., 1, 
1991. 
43. H.-J. Kreowski. Manipulation von Graphmanipulationen. PhD thesis, 
Technische Universitat Berlin, 1977. 
44. D.B. Benson. The basic algebraic structures in categories of derivations. 
Info. and Co., 28:l-29, 1975. 
45. J. Meseguer and U. Montanari. Petri Nets are Monoids. Info. and Co., 
88~105-155, 1990. 

REFERENCES 
245 
46. P. Degano, J. Meseguer, and U. Montanari. Axiomatizing Net Computa- 
tions and Processes. In Proceedings 4th Annual Symposium on Logic in 
Computer Science, pages 175-185, 1989. 
47. G. Ferrari and U. Montanari. Towards the Unification of Models for 
Concurrency. In Proceedings CAAP 1990, volume 431 of Lecture Notes 
in Computer Science, pages 162-176. Springer Verlag, 1990. 
48. A. Corradini and U. Montanari. An algebraic semantics for structured 
transition systems and its application to logic programs. Theoret. Com- 
put. Sci., 103:51-106, 1992. 
49. A. Corradini and A. Asperti. A categorical model for logic programs: 
Indexed monoidal categories. In Proceedings REX Workshop, Beekbergen, 
The Netherlands, June 1992, volume 666 of Lecture Notes in Computer 
Science. Springer Verlag, 1993. 
50. A. Corradini, H. Ehrig, M. Lowe, U. Montanari, and F. Rossi. Note 
on Standard Representation of Graphs and Graph Derivations. In H.- 
J .  Schneider and H. Ehrig, editors, Proceedings of the Dagstuhl Seminar 
9301 on Graph Transformations in Computer Science, volume 776 of Lec- 
ture Notes in Computer Science, pages 104-118. Springer Verlag, 1994. 
51. A. Corradini, H. Ehrig, M. Lowe, U. Montanari, and F. Rossi. Abstract 
Graph Derivations in the Double-Pushout Approach. In H.-J. Schnei- 
der and H. Ehrig, editors, Proceedings of the Dagstuhl Seminar 9301 
on Graph Transformations in Computer Science, volume 776 of Lecture 
Notes in Computer Science, pages 86-103. Springer Verlag, 1994. 
52. H. Ehrig. Aspects of Concurrency in Graph Grammars. In H. Ehrig, 
M. Nagl, and G. Rozenberg, editors, Proceedings of the 2nd International 
Workshop on Graph-Grammars and Their Application to Computer Sci- 
ence, volume 153 of Lecture Notes in Computer Science, pages 58-81. 
Springer Verlag, 1983. 
53. M. Lowe and J. Dingel. Parallelism in single-pushout graph rewriting. 
Lecture Notes in Computer Science 776, pages 234-247, 1994. 
54. E. Ehrig and B. K. Rosen. Parallelism and concurrency of graph manip- 
ulations. Theoretical Computer Science, 11:247-275, 1980. 
55. G. Taentzer. Hierarchically distributed graph transformation. In J. Cuny, 
H. Ehrig, G. Engels, and G. Rozenberg, editors, Proceedings of Fifth 
International Workshop on Graph Grammars and their Applications to 
Computer Science, volume 1073 of Lecture Notes in Computer Science, 
pages 304-320. Springer Verlag, 1996. 
56. G. Taentzer. Parallel and Distributed Graph Transformation: Formal De- 
scription and Application to Communication-Based Systems. PhD thesis, 
Technical University Berlin, FB13, 1996. 
57. H. Ehrig and M. Lowe. Parallel and distributed derivations in the single 
pushout approach. TCS, 109:123 - 143, 1993. 


Chapter 4 
ALGEBRAIC APPROACHES TO 
GRAPH TRANSFORMATION 
PART 11: 
SINGLE PUSHOUT APPROACH 
AND COMPARISON WITH 
DOUBLE PUSHOUT APPROACH 
H. EHRIG, R. HECKEL, M. KORFF, M. LOWE, L. RIBEIRO, A. WAGNER 
Technische Universitat Berlin, Fachbereich 13 Informatik, Franklinstrage 28/29, 
0-10587 Berlin, Germany 
A. CORRADINI 
Dipartimento di Informatica, Corso Italia 40, 
I-56125 Pisa, Italy 
The algebraic approaches to graph transformation are based on the concept of glu- 
ing of graphs corresponding to pushouts in suitable categories of graphs and graph 
morphisms. This allows one to give not only an explicit algebraic or set theoretical 
description of the constructions but also to use concepts and results from category 
theory in order to build up a rich theory and to give elegant proofs even in complex 
situations. 
In the previous chapter we have presented an overview of the basic notions 
and problems common to the two algebraic approaches, the double-pushout (DPO) 
approach and the single-pushout (SPO) approach, and their solutions in the DPO 
approach. In this chapter we introduce the SPO approach to graph transformation 
and some of its main results. We study application conditions for graph produc- 
tions and the transformation of more general structures than graphs in the SPO 
approach, where similar generalizations have been or could be studied also in the 
DPO approach. Finally, we present a detailed comparison of the DPO and the SPO 
approach, especially concerning the solutions to the problems discussed for both 
approaches in the previous chapter. 
247 

248 
Contents 
4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . 249 
4.2 Graph Transformation Based on the SPO Con- 
struction . . . . . . . . . . . . . . . . . . . . . . . . . . 250 
4.3 Main Results in the SPO Approach . . . . . . . . . 259 
4.4 Application Conditions in the SPO Approach . . 278 
4.5 
Transformation of More General Structures in the 
SPO Approach . . . . , . . . . . . . . . . . . . . . 287 
4.6 
Comparison of DPO and SPO Approach . . . . . . 296 
4.7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . 308 
References 
. . . . . . . . . . . . . . . . . . . . . . . , . , . . 309 

4.1. INTRODUCTION 
249 
4.1 Introduction 
The algebraic approach of graph grammars has been invented at T U  Berlin 
in the early 70’ies by H. Ehrig, M. Pfender and H.J. Schneider in order to 
generalize Chomsky grammars from strings to graphs [l]. Today this algebraic 
approach is called double-pushout approach, because it is based on two pushout 
constructions, in contrast to the single-pushout (SPO) approach where direct 
derivations are defined by a single pushout in the category of graphs and partial 
graph morphisms. A general introduction with main application areas and 
an overview of both algebraic approaches is presented in Chapter 3, in this 
handbook. 
The main aim of this chapter is to provide an introduction to the basic notions 
of the SPO approach, to present some of its main results and relevant exten- 
sions and generalizations, and to compare the notions and results of the SPO 
approach with the corresponding ones presented in Chapter 3 for the DPO 
approach. After this introduction, we suggest to read first Section 3.2 where 
many relevant concepts and results common to both algebraic approaches are 
introduced informally, in terms of problems. 
The following section gives an introduction to the basic notions of the SPO 
approach, like production, match, and (direct) derivation, and describes the 
historical roots of the SPO approach. In Section 4.3 we give answers to the 
problems of Section 3.2, concerning independence and parallelism, embedding 
of derivations, and amalgamation and distribution of derivations. In several 
graph grammar approaches it is possible to formulate application conditions 
for individual productions. But in very few cases the theoretical results can be 
extended to include these conditions. In Section 4.4 the SPO approach and the 
results concerning independence and parallelism are extended in order to allow 
for user-defined application conditions, as recently done in [2]. In Section 4.5 we 
show how the SPO approach can be applied to more general kinds of graphs 
and structures like attributed graphs [3], graph structures [4] (including for 
example hypergraphs), generalized graph structures [5], and even more general 
structures in high-level replacement systems [6]. 
In Section 4.6 we compare the main concepts and results of the two approaches, 
presented in Chapter 3 and this chapter, w.r.t. the problems stated in the 
overview of both approaches in Section 3.2. Finally in the conclusion we point 
out that both approaches are suitable for different application areas and discuss 
some main ideas for further research. 

250 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
I 
. 
r 
, 
Pacman Graph PG 
Figure 4.1: Pacman Game 
4.2 
Graph Transformation Based on the SPO Construction 
In this section we introduce the basic notions of the single-pushout approach to 
graph transformation. In order to be able to follow the formal definitions of this 
section the reader should be familiar with the notions introduced in Section 
3.3 for the double-pushout approach, although the informal motivation in the 
following can be understood without any preliminary knowledge. 
4.2.1 
As introductory example we use the model of a (simple version of a) Pacman 
game. 
Graph Grammars and Derivations in the SPO Approach 
Example 4.1 (Pacman game) 
The game starts with a number of figures (Pacman, ghosts, and apples) placed 
on a board. Pacman and each of the ghosts may autonomously move from field 
to field (up, down, left, right). Apples do not move. Pacman wins if he manages 
to eat all the apples before he is killed by one of the ghosts. 
Each of the states of the Pacman game can easily be modeled as a graph (see 
Figure 4.1). Vertices are used to represent Pacman, ghosts and apples as well as 
the fields of the board. These different kinds of vertices are distinguished using 
different graphical layouts (the obvious ones for Pacman, ghosts and apples 
and the black dots for the fields). Edges pointing from a vertex representing a 
figure to a field vertex model the current position of the figure on the board. 
Neighborhood relations between fields are explicitly represented using edges, 
too. 

4.2. SPO GRAPH TRANSFORMATION 
251 
Each possible activity in the Pacman game causes a change of the current state 
and hence is modeled by a transformation of the graph representing this state. 
To describe which activities, i.e., which graph transformations, are possible we 
use productions. The production moweP in Figure 4.1 describes that Pacman 
is moving one field. All objects are preserved but the edge pointing from the 
Pacman vertex to the field vertex is deleted and a new one is inserted. The 
production can be applied to a graph if Pacman is on a field which has a 
neighbor. As the effect of the application of this production, Pacman moves 
to a new position while everything else is left unchanged. Such an application 
of a production to a current graph is called derivation or transformation. To 
move the ghosts we have a production ( m o v e G )  which is not drawn but which 
follows the same scheme. The production eat can be applied when Pacman and 
an apple are on the same field. The result is that the apple and its outgoing 
edge are deleted. Analogously if Pacman and a ghost are on the same field the 
0 
Graphs and (total) graph morphisms have been formally introduced in Def- 
inition 3.3.1. In contrast to spans of total morphisms in the DPO approach, 
we use partial morphisms in order to describe, for example, the relationship 
between the given and derived graph in a derivation. The aim is to model a 
direct derivation by a single pushout instead of two. 
production kill can be applied and Pacman is deleted. 
Definition 4.2.1 (partial graph morphism) 
Let G = (Gv,G*,sG, tG, lvG, leG) be a graph. Recall that Gv,GE denote 
the sets of vertices and edges of G, sG, tG its source and target mappings, and 
lvG, leG the label assignments for vertices and edges, respectively. A subgraph 
S of G, written S C G or S L) G, is a graph with Sv C G v ,  SE C_ GE, 
ss = sGlsE, tS = t G ( S E ,  lvs = leGISE, and les = leGISE. A (partial) graph 
morphism g from G to H is a total graph morphism from some subgraph 
dom(g) of G to H ,  and dom(g) is called the domain of g. 
By defining composition of these morphisms by composition of the components, 
and identities as pairs of component identities", the graphs over a fixed labeling 
alphabet and the partial morphisms among them form a category denoted by 
GraphP. 
Usually, a production L 4 
R consists of two graphs L and R, called the left- 
and the right-hand side, respectively, and a partial morphism p between them. 
The idea is to describe in the left-hand side which objects a graph must contain 
such that the production can be applied, i.e., all objects (vertices and edges) 
aNote that a partial rnorphisrn can also be considered as a pair of partial functions. 

252 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
which shall be deleted and the application context which shall be preserved. 
The right-hand side describes how this part of the graph shall look like after 
the transformation, i.e., it consists of all the objects which are added together 
with the application context. The morphism p makes clear which objects in the 
left-hand side correspond to which ones in the right-hand side. Objects where 
the morphism is undefined are deleted. All objects which are preserved by the 
morphism form the application context. If an object in the right-hand side of 
the production has no preimage under the morphism, it is added. Note that 
the role of the application context coincides with that of the interface graph K 
in the DPO productions (see Definition 3.3.2). In the formal definition below 
the concept of production is enriched with a name, which is used to describe 
the internal structure of composed productions as, for example, the parallel 
production (see also the corresponding Definition 3.3.2 for the DPO approach). 
Definition 4.2.2 (production, graph grammar) 
A production p : ( L  4 R) consists of a production name p and of an 
injective partial graph morphism r, called the production morphism. The 
graphs L and R are called the left- and the right-hand side of p ,  respectively. 
If no confusion is possible, we will sometimes make reference to a production 
p : ( L  4 R) simply as p ,  or also as L A R. 
A graph grammar G is a pair G = ( ( p  : r)pEp,GO) where (p : ~
)
~
~
is a 
family of production morphisms indexed by production names, and Go is the 
start graph of the grammar. 
Since production names are used to identify productions, for example, in di- 
rect derivations, they should be unique, i.e., there must not be two different 
productions with the same name. This is ensured by the above definition of 
graph grammar. Later on, production names will be used to store the struc- 
ture of productions which are composed from elementary productions. In such 
cases the production name is usually a diagram, consisting of the elementary 
productions and their embeddings in the composed production. In elementary 
productions, production names are sometimes disregarded. Then we just write 
p : L + R in order to denote the production p : ( L  5 R) where the production 
morphism p is also used as the name of the production. In this section, all the 
productions are elementary and we use the notation just introduced. 
Example 4.2 (production) 
The figure below shows a production r which inserts a loop and deletes two 
vertices ( 0 2  and 03 resp. ). We consider the labeling alphabet to contain only 
one element *, i.e., the graph can be seen as unlabeled. The application context 
consists of the vertex 01. As indicated by the dashed line, r is defined for vertex 

4.2. SPO GRAPH TRANSFORMATION 
253 
01 mapping it to the only vertex on the right hand side. T is undefined for the 
other two vertices. The numbers are used to illustrate the morphism such that 
we can omit the dashed lines later on if graphs are more complex. Hence graph 
L can for example be formally denoted by L = ({el, 0 2 , 0 3 } ,  0, sL, tL, l w L ,  leL), 
where sL,tL and leL are empty functions. lvL is defined by 1vL(oi) = * for 
i = 1..3. 
Using partial instead of total morphisms, the categorical notion of pushout 
captures not only the intuitive idea of gluing but that of gluing and deletion. 
Therefore the construction is much more complicated. In order to make it easier 
to understand we divided it into three steps. The first two steps are gluings as 
known from Section 3.3. In the third step the deletion is performed. Intuitively, 
deletion is not seen as inverse to addition here, but as equalizing morphisms 
having different domains of definition. Two morphisms with the same source 
and target objects are reduced to their equal kernel by removing all those 
items from their range which have different preimages under the morphisms. 
Formally this is captured by the categorical notion of a co-equalizer. 
Definition 4.2.3 (co-equalizer) 
Given a category C and two arrows a : A t 
B and b : A -+ B of C ,  a tuple 
(C,c : B t 
C) is called co-equalizer of (a, b) if c o a  = c o b  and for all objects 
D and arrows d : B + D ,  with d o a = d o b, there exists a unique arrow 
u : C -+ D such that u o c = d. 
a 
C 
A-B-C 
b - 
For our pushout construction of partial morphism a very specific co-equalizer 
is sufficient, which is constructed in the following. 
Construction 4.2.4 (specific co-equalizer in GraphP) 
Let a ,  b : A t 
B be two (partial) morphisms such that for each x E A, if both 
a and b are defined on x then a(.) 
= b(x). Then, the co-equalizer of a and b 
in Graphpis given by (C, c) where 
- -  
0 C C B is the largest subgraph of [b(A) n a(A)] U [a(A) n b(A)], and 
0 dom(c) = C and c is the identity morphism on its domain. 

254 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
dom(a) 
C = dom(c) 
Figure 4.2: Deletion as a co-equalizer 
Proof 
It is obvious that c o a = c o b. The universal co-equalizer property follows from 
the fact that for each other morphism d : B -+ D with d o a = d o  b we have 
dom(d) 
dom(c). 
0 
Example 4.3 (deletion as a co-equalizer) 
Figure 4.2 shows the co-equalizer of the empty morphism a and a total mor- 
phism b in GraphP. According to Construction 4.2.4, C is the maximal sub- 
graph of B such that for all z E C, either z € a(A) n b(A), or z @ a(A) and 
z @ b(A). Thus, vertex 2 is deleted because it has a preimage under b but not 
0 
With these preliminaries we are able to construct the pushout of two partial 
morphisms in GraphP. 
Proposition 4.2.5 (pushout in GraphP) 
The pushout of two morphisms b : A -+ B and c : A -+ C in Graphpalways 
exists and can be computed in three steps, as shown in Figure 4.3: 
[gluing 11 Construct the pushout (C’, A -+ C’,C -+ C’) of the total mor- 
phisms dom(c) -+ C and dom(c) -+ A in Graph (cf. Example 3.3). 
[gluing 21 Construct the pushout ( D , B  -+ D,C’ -+ D) of the total mor- 
phisms dom(b) -+ A -+ C’ and dom(b) + B in Graph. 
[deletion] Construct the co-equalizer ( E l  D -+ E )  of the partial morphisms 
(El C -+ C’ -+ D -+ El B -+ D -+ E )  is the pushout of b and c in GraphP. 
under a. In order to obtain a graph, the dangling edge is deleted, too. 
A -+ B -+ D and A -+ C -+ C’ -+ D in GraphP. 

4.2. SPO GRAPH TRANSFORMATION 
255 
Figure 4.3: Construction of pushout in GraphP 
Proof 
Commutativity holds by construction. Assume that there is (F, C + F, B + 
F )  with A -+ B -+ F = A --+ C + F .  Prove that dum(b) -+ B + F = 
dom(b) + A + C‘ + F. Use the fact that pushouts in Graphare pushouts 
in GraphP [4] to construct a universal morphism D + F .  With the universal 
co-equalizer property we obtain a unique morphism E + F with B -+ D -+ 
E + F = B + F and C-+ C’+ D +  E + F = C  + F .  
0 
To apply a production to a graph G, one has to make sure that G contains 
at least all objects necessary for performing the desired operations and the 
application context. These are exactly the objects of the production’s left- 
hand side L. Hence we introduce the notion of a match as a total morphism 
matching the left-hand side of the production with (a part of) G. The match 
must be total because otherwise not all needed objects have a corresponding 
image in the graph G. We allow that different items from L are mapped onto 
the same item in G. This avoids additional productions in some cases. The 
actual transformation of G is performed by removing the part matched by the 
production’s left-hand side and adding the right-hand side. The result is the 
derived graph H .  
Definition 4.2.6 (match, derivation) 
A match for T : L -+ R in some graph G is a total morphism m : L --+ G. Given 
a production r and a match m for r in a graph G, the direct derivation from 
G with r at m, written G % H ,  is the pushout of r and m in GraphP, as 
TI ,ml 
shown in Figure 4.4. A sequence of direct derivations of the form p = (Go ==+ 
.. . + Gk) constitutes a derivation from Go to Gk by T I , .  . . ,rk, briefly 
denoted by Go ==+* Gk. The graph language generated by a graph grammar 
G is the set of all graphs Gk such that there is a derivation Go =+* Gk using 
productions of G. 
Tk m k  

256 
PG' d 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
PH 
Figure 4.4: Direct derivation as pushout in GraphP 
PO 
PG - 
, 
, 
, 
Figure 4.5: Direct derivation (example) 
To construct the direct derivation from graph G with T at m we use Proposition 
4.2.5. Since match m is a total morphism, step one of the construction is trivial 
and can be omitted. 
Example 4.4 (direct derivation as pushout construction) 
The production moveP from Example 4.1 can be applied to the graph PG 
(Figure 4.1) at match m, leading to the direct derivation shown in Figure 
4.5. Remember that due to the totality of the match the first step of the 
construction given in Proposition 4.2.5 is trivial. Hence we start with the second 
step: An edge between Pacman and the vertex modeling the field he moves to 
is added by performing the pushout of the total morphisms dom(moveP) + 
LmoUep -+ PG and dom(rncvueP) -i 
Rmovep. 
Afterwards the co-equalizer of 
Lmouep -+ Rmouep -+ PG' and Lmouep + PG -+ PG' leads to the derived 
graph PH which is the subgraph of PG' where the edge between Pacman and 
0 
In the example derivation above deletion is rather intuitive. In contrast Fig- 
ure 4.6 depicts a situation where a vertex is meant to be preserved as well 
as deleted on the left. The result of this derivation is the empty graph, i.e., 
deletion has priority. This property of the approach is caused by the order of 
the vertex representing his old position is deleted. 

4.2. SPO GRAPH TRANSFORMATION 
257 
I: 
I.? 
Figure 4.6: Deletion with conflicts. 
the construction steps: first gluing of conflicting items and then their deletion. 
Similarly the problem of the dangling edge on the right of Figure 4.6 is solved: 
it is deleted, too. This is illustrated in Example 4.3. 
In the following we will characterize simple deletion by properties of the match. 
If a match is d(e1ete)-injective then conflict situations are avoided. If it is d- 
complete, deletion does not cause the implicit deletion of dangling edges. 
Definition 4.2.7 (special matches) 
Given a match m : L + G for a production r : L + R. Then m is called 
conflict-free if m(z) = m ( y )  implies z, y E dom(r) or z, y $ dom(r). It is 
called d-injective if m(z) = m ( y )  implies 2 = y or z,y E dom(r). Finally, m 
is d-complete if for each edge e E GE with sG(e) E m v ( L v  - dom(r)v) or 
tG(e) E mv(Lv - dom(r)v) we have e E ~ E ( L E  
- dom(r)E). 
Lemma 4.2.8 (pushout properties) 
If (H,r* : G + H,m* : R + H )  is the pushout of r : L -+ R and m : G + H 
in GraphP, then the following properties are fulfilled: 
1. Pushouts preserve surjectivity, i.e. r surjective implies r* surjective. 
2. Pushouts preserve injectivity, i.e. r injective implies r* injective. 
3. r* and m+ are jointly surjective. 
4. m conflict-free implies m* total. 
Pro0 f 
See [7]. 

258 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
4.2.2 
Single-pushout transformations in a setting of some sort of partial morphisms 
have been investigated already by Raoult [8] and Kennaway [9]. The following 
historical roots are taken from [4]. 
Raoult [S] introduces two conceptually very different approaches. The first one 
is described in the category of sets and partial mappings. A rule is a partial 
morphism r : L + R, i.e. a partial map which respects the graph structure 
on all objects of L it is defined for. A match m : L + G in some graph G is 
a total morphism of this type. The result of applying r at m is constructed 
in two steps. First, the pushout (H,T* : G -+ H,m* : R + H )  of r and m 
in the category of sets and partial maps is built. In the second step, a graph 
structure is established on H such that the pushout mappings T* and m* 
become morphisms. He characterizes the situations in which this graph struc- 
ture uniquely exists; double-pushout transformations with gluing conditions 
are special cases of these situations. The second model of graph transforma- 
tion in [8] uses another kind of partiality for the morphisms: a rule is a total 
map r : L + R, which is only partially compatible with the graph struc- 
ture. Let rewrite(r) denote the set of objects which are not homomorphically 
mapped by T .  A match m : L + G is total which means now rewrite(m) = 0. 
Application of r at m is again defined by two steps. First construct the pushout 
( H ,  T *  : G + H ,  m* : R + H )  of r and m in the category of sets and total map- 
pings and then impose a graph structure on H such that the pushout mappings 
become as compatible as possible, i.e. such that rewrite(r*) = m(rewrite(r)) 
and rewrite(m*) = r(rewrite(m)). Raoult [8] gives sufficient conditions for the 
unique existence of this structure. This approach has the major disadvantage 
that objects cannot be deleted at all. 
Kennaway [9] provides a categorical description for the second approach of 
[8]. Graphs are represented the same way. Morphisms f : A -+ B are pairs 
(f, horn). The first component is a total mapping from A to B. The second 
component provides a subset of A on which f respects the graph structure. A 
rule r : L + R is any morphism in this sense and a match m : L -+ G is a total 
morphism which now means hom = L. He shows that under certain conditions 
the two-step construction of [8] coincides with the pushout construction in the 
category of graphs and the so-defined morphisms. 
Unfortunately, only sufficient conditions for the existence of pushouts are given. 
Besides that, object deletion remains impossible. The concept in [9] has been 
further developed in [lo]. They introduce “generalized graph rewriting” which 
uses the same kind of graph morphism. The corresponding transformation 
concept not only involves a pushout construction but also a coequalizer. Since 
Historical Roots of the SPO Approach 

4.3. MAIN RESULTS IN THE SPO APPROACH 
259 
both constructions are carried out in different categories (of total resp. partial 
morphisms) theoretical results are difficult to obtain. The SPO approach in [4] 
as discussed above is closely related to the first approach in [8]. His concept 
of partial mappings which are compatible with the graph structure on their 
domain can be generalized to a concept of partial homomorphisms on special 
categories of algebras such that pushout construction in the categories is al- 
ways possible. Hence, we get rid of any application conditions. If, however, 
the necessary and sufficient conditions of [8] are satisfied, the construction of 
pushout objects coincides with his two-step construction. 
Recently, Kennaway [ll] independently started to study graph transforma- 
tion in some categories of partial morphisms of this type. His work is based 
on the categorical formulation of a partial morphism provided by [12]. While 
[4] considers concrete algebraic categories, [ll] stays in a purely categorical 
framework. Future research has to show how both approaches can benefit 
from each other. Van den Broek [13] introduces another kind of single-pushout 
transformations based on “partial” morphisms. Partiality in this framework is 
described by total morphisms which map objects “outside their domain” to 
marked objects in their codomain. In this chapter we follow the SPO approach 
as introduced in [7,4] and extended in several subsequent papers mentioned 
below. 
4.3 Main Results in the SPO Approach 
In this section we present some of the main results of the SPO approach. 
They are concerned with the conceptual notions of parallelism, context em- 
bedding, synchronization and distribution, interpreted into the world of SPO 
derivations. The main reason for this choice is the fact that a most natural 
and very basic view on a graph transformation system is to see a graph as a 
system state and a production as a syntactical description of corresponding 
state transformations obtained by direct derivations. By further (informal) ar- 
guments certain derivations can be classified as to be concurrent, embedded 
into each other, or (somehow) synchronized or distributed. 
Complementary, on the syntactical level, different ways of composing pro- 
ductions can be considered, generating an integrated description, i.e., the 
composed production. As for derivations, we consider parallel, derived, and 
synchronized/amalgamated productions. An elementary production essentially 
provides a description of the direct derivations it may perform. A composed 
production, additionally, contains all the information about its construction 
from elementary productions, which is stored in the production name. If, e.g., 

260 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
p : r is a parallel production, the production name p contains the elementary 
productions and their embeddings into the resulting production morphism r. 
The (complete or partial) correspondence between composed derivations and 
derivations using (correspondingly) composed productions provides the essen- 
tial results of this section, which may be seen as answers to the problems stated 
in Section 3.2. Related results are mentioned briefly. 
4.3.1 
Parallelism 
There are essentially two different ways to model concurrent computations, 
the interleaving and the truly concurrent model. This subsection provides the 
basic concepts of these models in the world of SPO graph rewriting, including 
the solutions to the Local Church-Rosser Problem 3.2.1 and the Parallelism 
Problem 3.2.2. 
Interleaving 
In an interleaving model two actions are considered to be concurrent (i.e., 
potentially in parallel) if they may occur in any order with the same result. 
Modeling single actions by direct derivations, we introduce two notions of inde- 
pendence, formalizing this concept from two different points of view. The con- 
dition of parallel independence shall ensure that two alternative direct deriva- 
tions are not mutually exclusive. Safely, we may expect this if these direct 
derivations act on totally disjoint parts of the given graph. More precisely, a 
direct derivation dl = (G p* 
H I )  does not affect a second d2 = (G ==+ H2) 
if dl does not delete elements in G which are accessed by d2. In other words, 
the overlapping of the left hand sides of pl and p2 in G must not contain ele- 
ments which are deleted by p l .  The vertices deleted from G by dl are those in 
m l ( L 1  -dorn(pl)). An edge will be deleted from G if it is in m l ( L 1  - d o m ( r l ) )  
or - which is an additional feature in the SPO approach - one of its incident ver- 
tices is deleted. Formally, we obtain the following definition of weakly parallel 
independent derivations. 
p 2 , m  
Definition 4.3.1 (parallel independence) 
Let dl = (G '3 
H I )  and d2 = (G '3 
H2) be two alternative direct 
derivations. Then we say that d2 is weakly parallel independent of dl iff 
mz(L2) n m l ( L 1  - dorn(p1)) = 8. We call the derivations dl and d2 parallel 
independent if they are mutually weakly parallel independent. 

4.3. MAIN RESULTS IN THE SPO APPROACH 
261 
P2 
R2 - 
L2 
P l  
Li --+ RI 
Weak parallel independence can be characterized in more abstract terms on a 
categorical level. 
Characterization 4.3.2 (parallel independence) 
PZ m2 
Let dl = (G '3 
H I )  and d2 = (G 
Hz) be two direct derivations. Then 
dz is weakly parallel independent of dl if and only if pl* o m2 : L2 + H I  is a 
match for p2. 
Pro0 f 
Let there be a match mh = pl* o m2 as above. Then mz(L2) 5 dom(p,*) by 
definition of composition. The commutativity of pushouts provides ml (L1 - 
dom(p1)) n dom(p,*) = 8 which is the desired weak parallel independence. 
Vice versa, we must show that mh = pl* o m2 is total. According to the 
construction of a derivation, each vertex which is not explicitly deleted by pl 
is preserved, i.e., 'u E G - ml (L1- dom(p1)) implies 'u E dom(pl*). This implies 
that each preimage of u under m2 has also an image in HI. Each edge which is 
not explicitly deleted by pl is either (i) preserved or (ii) implicitly deleted by 
the deletion of an incident vertex i.e., for each edge e E G - ml (L1 - dom(p1)) 
we either have (i) e E dom(p1') which inherits the arguments for vertices; 
Otherwise, in case (ii), sG(e) E m l ( L ~ - d o m ( p l ) )  or tG(e) E ml(Ll-dom(p1)). 
By definition of parallel independence this implies sG(e) # mz(L2) or tG(e) # 
m2 (Lz) which, by definition of graph morphisms excludes e E m2 (L2). In other 
0 
The condition of sequential independence shall ensure that two consecutive 
direct derivations are not causally dependent. A direct derivation is weakly 
sequential independent of a preceding one if it could already have been per- 
formed before that. Analogous to the parallel case above, weak sequential in- 
dependence requires that the overlapping of the right hand side of the first 
production and the left hand side of the next must not contain elements which 
were generated by the first. The idea of the stronger notion of sequential in- 
dependence is that additionally the second will not delete anything which was 
needed by the first. 
words e E mz(L2) implies e E dom(pl*). 
Definition 4.3.3 (sequential independenpe) 
Let dl = (G + H I )  and d i  = (HI '3 
X ) ,  be two consecutive direct 
derivations. Then we say that dh is weakly sequentially independent of dl 
PI mi 

262 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
ifmb(L2)nml*(R1-pl(L1)) 
= 0. If additionally m',(L2-dom(p2))nml*(R1) 
= 
0, we say that db is sequentially independent of dl, and the derivation 
(G ==+ H1 ==+ X) 
is called sequentially independent. 
m,ml 
P Z , ~ ;  
-4 
P2 * 
+ Hl 
P1* 
G 
Again we will provide a categorical characterization. The formulation of this 
statement is analogous to the case of weak parallel independence. The proof 
has therefore been omitted 
Characterization 4.3.4 (sequential independence) 
Assume two direct derivations dl = (G ii HI) 
and da = (HI A X) 
to be given. Then db is weakly sequentially independent of dl iff there is a 
match m2 : L2 + G for pa such that rnh = pl* o m2. The derivation db is 
sequentially independent of dl iff d', is weakly sequentially independent of dl 
and dl is weakly parallel independent of the correspondingly existing derivation 
I7 
P I  mi 
PZ m; 
d2 = (G '3 
H2). 
By definition, the weakly parallel independence of two direct derivations im- 
plies the existence of consecutive direct derivations. The definition of weakly 
sequential independent derivations contains a symmetric implication. The ar- 
gumentation could be summarized in the following way: weak parallel inde- 
pendence allows to delay a derivation - complementary, weak sequential in- 
dependence allows to anticipate a derivation. Formally this is captured by the 
following lemma. 
Lemma 4.3.5 (weak independence) 
Given a direct derivation dl = (G pg 
HI), 
the following statements are 
equivalent: 
PZ mz 
1. There is a direct derivation d2 = (G + H2) which is weakly parallel 
independent of dl. 
PZ m; 
2. There is a direct derivation d', = (HI A X) which is weakly sequen- 
tially independent of dl . 

4.3. MAIN RESULTS IN THE SPO APPROACH 
L1 -PI 
R1 
I 
I 
I 
I 
+ 
m; 1 
Lz -rn2--G-p; 
-Hi 
263 
Figure 4.7: Local Church Rosser 
Up to isomorphism, a bijective correspondence between 1. and 2. above is given 
by mk = PI* 0 m2 and m2 = ( p ~ * ) - '  o mi. 
Pro0 f 
This is a direct consequence of Characterizations 4.3.2 and 4.3.4 together with 
the fact that, by Lemma 4.2.8, injectivity of productions implies injectivity of 
PI* and thus m2 = (PI*)-' o p l *  o m 2  as well as mh =PI* o (PI*)-' om;. 0 
According to our interpretation, the conditions of parallel and sequential inde- 
pendence formalize the concepts of concurrent computation steps. In a more 
abstract sense, two such steps are concurrent if they may be performed in 
any order with the same result. The following Local Church-Rosser Theorem 
shows the correctness of the characterization of concurrent direct derivations 
by their parallel and sequential independence. It provides the solution to the 
Local Church-Rosser Problem 3.2.1. 
Theorem 4.3.6 (local Church-Rosser) 
Let dl = (G '3 
H I )  and d2 = (G '3 
H2) be two direct derivations. Then 
the following statements are equivalent: 
1. The direct derivations dl and d2 are parallel independent. 
~ 2 , 7 7 4  
PI ,mi 
2. There is a graph X and direct derivations H1 =j X and H2 ==+ X 
such that G '3 
H1 =& 
X and G + H2 ==+ X are sequentially 
independent derivations. 
PZ m: 
PZ mz 
 PI,^; 
Up to isomorphism, a bijective correspondence between 1. and 2. above is given 
by m; = pl* o m2 and mi = p ~ *  
o r n l .  
Proof 
Consider the diagram in Figure 4.7. Subdiagrams (1) and (2) depict the deriva- 
tions dl and d2, respectively. Subdiagram (3) represents the pushout of pl* and 

264 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
p2*. The composition of pushout diagrams (2) and (3) yields a pushout dia- 
~2 m; 
gram (2)+(3) which is a derivation H1 i 
X provided that mh = pl* o m2 
is a match, i.e., total. But this is ensured since dl and d2 have been required 
to be parallel independent. Analogously we obtain a derivation H2 + X by 
composing pushout diagrams (1) and (3). The stated sequential independence 
0 
PI ,mi 
and the bijective correspondence follow from Lemma 4.3.5. 
Explicit Parallelism 
In contrast to the interleaving model above, a truly parallel computation step 
has to abstract from any possible interleaving order, i.e., it must not generate 
any intermediate state. Therefore, a parallel direct derivation is a simulta- 
neous application of productions, which are combined into a single parallel 
production. Constructing this production as the disjoint union of the given 
elementary productions reflects the view that the overall effect of a parallel 
production application can be described by a ‘most independent’ combination 
of both component descriptions. The formal definition below uses the fact that 
the disjoint union of graphs (obtained from the disjoint union of carrier sets) 
can categorically be characterized by a coproduct. The construction of the par- 
allel production as a coproduct of elementary productions is recorded in the 
production name pl +p2, which is given by the coproduct diagram below. This 
notation is well-defined, i.e., the diagram below is uniquely determined by the 
term pl +p2, if we fix a certain coproduct construction (like, for example, the 
disjoint union). 
Definition 4.3.7 (parallel productions and derivations) 
Given two productions pl : L1 -+ R1 and p2 : L2 + R2, the parallel pro- 
duction p~ + p~ : (L1 + L2 & R1 + R2) is composed of the production 
name pl +p2, i.e., the diagram above, and the associated partial morphism p. 
The graphs L1 + L2 and R1 + R2 (together with the corresponding injections 
ini,ini, ink, and ink) are the coproducts of L1, L2 and R1, Rz respectively. 
The partial morphism L1 + L2 & R1 + R2 is induced uniquely by the uni- 
versal property of the coproduct L1 + L2 such that p o in; = ink o pl and 
p o in: = in: o pa. The application of a parallel production pl + p2 at a 
match m constitutes a direct parallel derivation, denoted by G 
X .  

4.3. MAIN RESULTS IN THE SPO APPROACH 
265 
Figure 4.8: Weak Parallelism 
By referring to morphisms ml = m o in; and m2 = m 0 in: we also write 
p i + p z  m i f m 2  
* x. 
Direct parallel derivations provide us with an explicit notion of parallelism, 
which shall now be related to the interleaving model that has been formulated 
before. The Parallelism Problem 3.2.2 asked for conditions allowing the se- 
quentialization of a parallel derivation, and the parallelization of a sequential 
one. The following Weak Parallelism Theorem answers these questions in the 
SPO approach. 
Theorem 4.3.8 (weak parallelism) 
Given productions pl : L1 -+ R1 and p2 : LZ -+ R2, the following statements 
are equivalent: 
P I + P Z  m i f m z  
1. There is a direct parallel derivation G 
i-i 
X such that G '3 
pi mi 
H2 is weakly parallel independent of G --1-i H I .  
n , m l  
p z , m k  
2. There is a weakly sequential independent derivation G ==+ H1 
X .  
Up to isomorphism, a bijective correspondence between 1. and 2. above is given 
by mk = pl' 0 m2. 
Pro0 f 
Constructing the parallel derivation means first to construct the colimits (co- 
products) for in; and in; as well as for ink and in: then the colimit (pushout) 
of p and ml + m2 in a second step. In other words it means to construct the 
colimit of the diagram given by p1,ml and p2,m2 as depicted in the Fig- 
ure 4.8 above. Consider now Figure 4.7 of the Local Church Rosser Theorem. 

266 
CHAPTER 4 .  SINGLE PUSHOUT APPROACH 
Also this shows a colimit constructed from the diagram given by p l ,  m l  and 
pa, m2. Due to the commutativity of colimit construction (see [14]) ensuring 
that all colimits can iteratively be obtained from composing partial colimits, 
we conclude that both of these constructions coincide. So, the result of the 
parallel derivation can equivalently be obtained by first constructing the col- 
imits (pushout) of p1,ml and pz, m2 and second the colimit (pushout) for the 
resulting morphisms pl* and p ~ * .  
But this means first to construct the di- 
rect derivations dl = (G ==+ 
H I )  and d2 = (G =+ 
H2) represented by 
sub-diagrams (1) and (2) in Figure 4.7 respectively. Their preassumed weak 
parallel independence leads then to a derivation dk = ( H  i 
X )  represented 
by subdiagram (2)+(3). By Characterization 4.3.4 we finally observe that dh 
is weakly sequentially independent of dl as required. 
Vice versa, given an arbitrary sequentially independent derivation, we observe 
that all the arguments above can uniquely be reversed. The bijective corre- 
0 
Before looking at the counter-example below, the typical situation of Theorem 
4.3.8 shall be illustrated by the Pacman-game. 
Example 4.5 (killing is weakly parallel independent of eating) 
In Figure 4.9 a situation is shown where Pacman, a ghost and an apple are 
on the same field. We observe that two production applications are possible: 
Pacman may eat an apple and the ghost may kill Pacman. Weak parallel 
independence allows the ghost to be merciful. Pacman may eat his last apple; 
nevertheless, the ghost will in both situations G and HI be sure about his 
victim. In other words, killing is weakly independent of eating. Contrastingly, 
eating is not at all weakly independent of killing because killing implies that 
eating becomes impossible. The Weak Parallelism Theorem 4.3.8 now ensures 
that the procedure of eating the last apple and being killed can be shortcut by 
0 
The following example proves that there are parallel derivations which cannot 
be sequentialized. 
P I  ,mi 
PZ ,mz 
PZ mi 
spondence between 1. and 2. is due to Lemma 4.3.5. 
correspondingly applying the parallel production. 
Example 4.6 (non-sequentializable parallel derivations) 
Consider a production 0 : L + R where both L and R contain exactly one 
vertex 0 .  
Let L 
X be a parallel derivation with 0 + 0. Note that the two 
component matches m l  = m2 = id : L + L are parallel dependent since the 
0+0 id+id 
+ 
bi.e. both colimits may at most differ up to isomorphisms, but each obtained in one way 
can also be obtained in the other way. 

4.3. MAIN RESULTS IN THE SPO APPROACH 
k 
I 
k, 
I 
Figure 4.9: Killing and eating can be parallelized 
267 
Figure 4.10: A Parallel Derivation which cannot be sequentialized 

268 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
vertex in L is meant to be deleted. However, the derived graph X contains two 
vertices. Clearly this effect cannot be obtained by applying 0 in two sequential 
steps. Let us compare this formally obtained result with our intuition: We 
observe that 0 deletes a vertex and re-generates it afterwards. Correspondingly, 
the parallel production deletes two vertices and re-generates two. Hence we may 
expect that a match by which the two vertices in L + L are identified leads to a 
co-match (rnl + m2)* : R + R t 
X which identifies the two vertices. However, 
this does not happen in the parallel derivation which is due to the fact that, 
formally, the vertices in L and R are completely unrelated (i.e., there is no 
formal notion of ‘re’-generation). Hence, the two applications of 0 generate 
two different vertices. 
0 
Additional Remarks: The Weak Parallelism Theorem allows to define an oper- 
ation on derivations, which shifts the application of a certain production one 
step t,owards the beginning of the derivation. Iterated applications of this so- 
called shift operation lead to a derivation in which each production is applied 
as early as possible. This maximally parallel derivation is introduced in [15] as 
the canonical derivation. Another fundamental theoretical problem addressed 
in [15] are abstract derivations. It was shown that for each derivation there 
is a unique abstract canonical derivation. See also Chapter 3 for a detailed 
discussion of this topic. 
In the SPO approach, the results of this section have essentially been formu- 
lated in [7,4]. Originally, however, these problems have been investigated in 
the DPO approach, see Section 3.4 and 3.5. The differences and similarities of 
the corresponding results are discussed to some depth in Section 4.6. 
In [16] a new notion of a concurrent derivation captures the idea of a concur- 
rent history. A complementary notion of a morphism describes a concurrent 
subhistory relation; it is based on causal rather than sequential dependencies 
between activities. This leads to a category of abstract concurrent derivations 
taken as the concurrency semantics of a SPO graph grammar. In addition an 
interleaving semantics is proposed, given by a subcategory of abstract con- 
current derivations, partially ordered by a sequential subcomputation relation. 
The concurrency semantics is characterized as a configuration domain of a 
prime event structure. The explicit consideration of infinite derivations leads 
to a notion of a fair derivation and a corresponding fair concurrency semantics. 
4.3.2 
In this section we answer the question, under which conditions a derivation can 
be embedded into a larger context (cf. Problem 3.2.3). Therefore, we first have 
Embedding of Derivations and Derived Productions 

4.3. MAIN RESULTS IN THE SPO APPROACH 
269 
/ 
/ 
m k - l  
P 
/ 
mo 
6 
eo 
el 
e‘k-1 
-GI: 
Gk-i 
~ 
f 
Go - 
/ 
m k - l  
I 
-Gk., 
e k  
Proposition 4.3.11 (directly derived production) 
Given the directly derived production (d) : p’ of a derivation d = (G % H )  
as in Figure 4.11 on the left, the following statements are equivalent: 
(4 e 
1. There is a directly derived derivation d’ = ( X  i 
2). 

270 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
0 
Figure 4.11: Horizontal and sequential composition of direct derivations, and non- 
sequentializable derived derivation. 
2. There is a direct derivation d" = (X % 2) and an embedding (e,e*) : 
d' 3 
d". 
Up to isomorphism, a bijective correspondence between 1. and 2. is given by 
n = e o m .  
The directly derived derivation in 1. is represented by the pushout diagrams 
(1) and (2) on the left of Figure 4.11. Due to well-known pushout composition 
properties, diagram (1+2) is a pushout, too, which represents the direct deriva- 
tion in 2. Vice versa, we can reconstruct the pushouts (1) and (2) from (1+2) 
by the pushout (1) of p and m and the pushout (2) of p* and e. Uniqueness of 
pushouts up to isomorphism ensures the bijective correspondence between 1. 
and 2. 
Gk) with k > 1. To this aim we introduce the notion of "sequential com- 
position" of two productions, in order to obtain a single derived production 
( p )  from the composition of the sequence of its directly derived productions 
( d l ) ;  (d2);. . . ; ( d k ) .  We speak of sequential composition because the application 
of such a composed production has the same effect of a sequential derivation 
based on the original productions. 
Pro0 f 
P k , m k - l  
Now we want to extend this equivalence to derivations p = (Go '9 
. . . ==/ 
Definition 4.3.12 (sequential composition) 
Given two productions pl : L1 + R1 and p2 : L2 --+ R2 with R1 = L2, 
the sequentially composed production p1;p2 : L1 
R2 consists of the 
production name pl ; p2 and the associated partial morphism p = p2 o pl . 
Derivations G '3 
H1 '3 
H2, where the match m2 of the second direct 
derivation is the co-match of the first, may now be realized in one step using 
the sequentially composed production pl ; p2. Vice versa, each direct derivation 
P1.m mi 
pi,mi 
p z , m ;  
G 5 
H2 via pl;p2 can be decomposed into a derivation G 
H1 ==/ 

4.3. MAIN RESULTS IN THE SPO APPROACH 
271 
H2, provided that the co-match m; of the first direct derivation is total. In the 
Proposition below, this is ensured by the assumption that ml is conflict-free 
w.r.t. p l .  
Proposition 4.3.13 (sequential composition) 
Given two productions pl and p2 and their sequential composition p l ;  p2 : p as 
above, the following statements are equivalent: 
P I ; P Z  mi 
1. There is a direct derivation G ==3 H2 where ml is conflict-free w.r.t. 
Pl . 
p i  ml 
p 2 , m ;  
2. There is a derivation G + H1 =j H2 such that m; is the co-match 
of ml w.r.t. p l .  
Up to isomorphism, a bijective correspondence between 1. and 2. above is given 
by P = P2 0 Pl. 
Proof 
By properties of pushouts in GraphP (see Lemma 4.2.8), the co-match m* is 
total if and only if m is conflict-free w.r.t. p l .  Then Proposition 4.3.13 follows 
from pushout composition and decomposition properties, similar to Proposi- 
tion 4.3.11. 
0 
Combining directly derived productions by sequential composition we now de- 
fine derived productions for derivations of length greater than one: 
Definition 4.3.14 (derived production) 
PI mo 
p k  mk-i 
Let p = (Go + . . . % Gk) be a derivation consisting of direct deriva- 
p,,m;-i 
tions di = (Gi-1 =+ Gi) and (di) : p: the corresponding directly derived 
productions. Then, the derived production (p) : Go 5 Gk of p is given by 
the production name (p) = ( d l ) ;  . . . ; (dk) and the associated partial morphism 
p* = p; 0. . . op;. A direct derivation K 
Y using (p) : p' is called a derived 
derivation. 
( P )  e 
Each derivation sequence may be shortcut by a corresponding derived deriva- 
tion. Vice versa, each derived derivation based on a d-injective match cor- 
responds to an embedding of the original derivation. The following theorem 
provides the solutiori to the Derived Production Problem 3.2.4. 
Theorem 4.3.15 (derived production) 
Let p = (Go p
*
 
... "%-' Gk) be a derivation, (p) : p* the corresponding 
derived production, and Go 3 X O  a d-injective match for (p). Then the 
following statements are equivalent: 

272 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
( P )  eo 
1. There is a derived derivation X O  A Xk . 
2. There is a derivation 6 = (Xo 3 ... 
P I  n o  
p k  m - 1  X,) and an embedding 
p -% 6, where eo is the embedding morphism of e. 
Up to isomorphism, a bijective correspondence between 1. and 2. above is given 
byp' = p i  0 . .  . o p ;  and e, o m ,  = n, for i E {O,. . . , k  - I}. 
Proof 
By induction over the length k of p: Let k = 1. Then (p) is a directly derived 
production, and Theorem 4.3.15 follows from Proposition 4.3.11. Assume that 
po,mo 
1. and 2. are equivalent for derivations p of length k = 1. Let p' = (Go + 
. . . 
G1+1) be a derivation of length k = 1 + I, p the prefix of 
p' consisting of the first 1 direct derivations, and dl+l = (G1 =-A Gl+1) the 
last direct derivation of p'. Then, there is a derivation 6' and an embedding 
p' A S' iff there are embeddings p 
6 and (el, e l f l )  : dl+l + di+, where el 
is also the last injection of e (cf. Definition 4.3.9). We show that the embeddings 
e and (el, el+l) exist iff there are corresponding derived derivations using the 
derived productions (p) : Go % G1 of the derivation p and (dl+l) : p of the 
direct derivation &+I. Then, Theorem 4.3.15 follows from Proposition 4.3.13 
using the fact that, since eo is injective, it is in particular conflict-free w.r.t. 
p l , m r - 1  
P I + I , ~ ~  
+ G1 + 
PI+I ml 
(P). 
( P )  eo 
By applying the assumption, there is a derived derivation X O  ==3 Xl as in 1. 
iff there is an embedding p -% 6 into a derivation 6 = ( X O  '11140 . . . 'I%-' 
X l )  
as in 2. Using Proposition 4.3.11, the same equivalence holds between directly 
derived derivations Xl (dd 
Xl+1 and direct derivations X1 i Xl+1 
which are embeddings of dl+l. This concludes the proof of Theorem 4.3.15. 0 
The following example is taken from [7]. It illustrates that a derived derivation 
based on a non-d-injective match may not be sequentializable. 
I+I 
,el 
pit1 ni 
Example 4.7 (non-sequentializable derived derivation) 
Consider the right diagram of Figure 4.11 on page 270, where the very same 
production is used twice for generating the derived production. The original 
production deletes one vertex and generates a new one. 
The derived production specifies the deletion of two vertices and the generation 
of two others. But in fact by mapping the vertices to be deleted onto a single 
one leads to the generation of two vertices out of one. This is due to the fact 
that there is no direct connection between deleted and generated items, which 
in this situation means that, indeed, two instead of one vertex is newly added. 
0 

4.3. MAIN RESULTS IN THE SPO APPROACH 
273 
Let us come back now to Problem 3.2.3 which asked for an embedding of 
a derivation into a larger context. This question is now answered using the 
equivalence above, that is, a derivation p may be embedded via an embedding 
morphism eo if and only if the corresponding derived production (p) : p* is 
applicable at eo. Since in the SPO approach there is no further condition for 
the application of a production but the existence of a match, this implies that 
there is an embedding p 4 6 of the derivation p via each embedding morphism 
e0. 
Theorem 4.3.16 (embedding) 
Let p = (Go pg 
. . . pk3-1 
GI,) be a derivation and Go % X O  an embedding 
morphism. Then there is a derivation 6 = ( X O  ps 
... pks-l 
XI,) and an 
embedding p 
6. 
Proof 
( P )  eo 
Let (p) : p* be the derived production of p and XO ==3 XI, the derived 
derivation at the embedding morphism Go 3 X O .  Since eo is injective, it is 
in particular d-injective. By Theorem 4.3.15 this implies the existence of the 
Additional Remarks: A derived production represents the overall effect of the 
derivation it is constructed from, and fixes the interaction of the productions 
applied in the derivation. This representation, however, can still be reduced 
by cutting of the unnecessary context, i.e., all those elements of the starting 
and ending graphs of the derivation which are never touched by any of the 
productions. Such minimal derived productions (minimal w.r.t. the embedding 
relation) have been introduced in the SPO approach in [4] for two-step deriva- 
tions, generalized in [17] to derivations of length k 2 1. 
derivation S and the embedding p 
6. 
0 
4.3.3 Amalgamation and Distribution 
In this section we will investigate the simultaneous application of graph pro- 
ductions, which shall not work concurrently (as in a parallel derivation) but 
cooperatively, synchronizing their applications w.r.t. commonly accessed ele- 
ments in the graph (cf. Section 3.2). The synchronization of productions w.r.t. 
certain deleted and/or generated elements is expressed by a common subpro- 
duction in the definition below. 
Definition 4.3.17 (subproduction, synchronized productions) 
Let pi : Li + R, be three productions for i = 0,1,2. We say that po is a 
subproduction of pl if there is an embedding in1 = (in2,i.k) 
: po + pl, 
i.e., a pair of total graph morphisms in; : LO -+ L1 and ink : fi + R1 such 

274 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
that ink 0 po = pl 0 in;. The productions pl and p2 are synchronized w.r.t. 
PO, shortly denoted by pl * po 5 pa, if po is a subproduction of both pl and 
pa with embeddings in' and in2, respectively. 
Lo -PO+ 
Ro 
I 
I 
in; 
2
;
;
 
I 
Li -PI 
+ 
RI 
2121 
in2 
If synchronized productions pl t PO + p2 shall be applied simultaneously to 
one global graph, this may be modeled by the application of an amalgamated 
production which is constructed as the gluing of p1 and p2 along PO. Formally 
such a gluing is described by a pushout construction. Since the amalgamated 
production is a composed production, its production name has to record this 
construction. So similar as for the parallel production, the name pl ep0 
p2 of 
an amalgamated production is a whole diagram comprising the given synchro- 
nized productions pl * PO 5 p2 and their embeddings into the production 
morphism of the amalgamated production. 
Definitiop 4.3.48 (amalgamated productions and derivations) 
Let pl 
a& 
po '3 p2 be synchronized productions with pi : L, + R, for 
i E {0,1,2}. Then the amalgamated production pl cBp0 p2 : L -% R, 
consists of the production name pl Bp0 p2 and the associated partial morphism 
p. The production name pl Bp0 p2 is constructed on the left of Figure 4.12, 
where (in;*, in;*) and (in$*,ink*) are pushouts of (in;, in:) and (inh,ini), 
respectively, and L 4 
R is obtained as the universal morphism satisfying 
p o i n i *  = in&* opl and p o i n i *  = in$* op2. A direct derivation G 
==+ 
X 
using the amalgamated production pl ep0 
p2 is called amalgamated deriva- 
tion. By referring to morphisms ml = m o in:,* and m2 = m o in;* we also 
write G 
=3 
X .  
A distributed graph models a state which is splitted into substates related by 
common interface states. Gluing the local states along their interfaces yields 
the global state again. Below these ideas are formalized for two local states 
related by one interface. 
p l @ , , m , m  
p l @ p o p z , m l  @mz 
Definition 4.3.19 (distributed graph) 
A distributed graph D G  = (GI 
Go 3 G2) consists of two local graphs 
G1 and G2, an interface graph Go and graph morphisms g1 and g2 em- 
bedding the interface graph into the two local graphs. The global graph 
G = @ DG = G1 @ G ~  
G2 of DG is defined as the pushout object of g1 and g2 

4.3. MAIN RESULTS IN THE SPO APPROACH 
2 75 
Figure 4.12: Amalgamated Production 
Amalgamated Derivation 
in the diagram below. The distributed graph DG is a total splitting of G if 
the graph morphisms g1 and 92 are total. In general DG is called a partial 
splitting. 
A truly partial splitting models an inconsistent distributed state where, for 
example, there are dangling references between the local substates. In such 
situations, there is no general agreement if a certain item belongs to the cor- 
responding global state or not. Constructing the global graph as the pushout 
object of the splitting, this question is decided in favor of deletion, that is, 
conflicting items are removed from the global state. 
Distributed graphs can be transformed by synchronized productions, which 
specify a simultaneous update of all local graphs. 
Definition 4.3.20 (distributed derivation) 
Let DG = (GI & Go 3 G2) be a distributed graph and Li 3 Gi for 
i E {0,1,2} be matches for synchronized productions pl $ po 5 p:! as in 
Figure 4.13 on the left. The matches (mi)iEio,l,2} 
form a distributed match 
for pl @ po % p2 into DG if gk om0 = mk o z n i  for k E { 1,2}. In this case, the 
distributed derivation dllldod2 : DG ==+ DH with DH = (HI & HO hz, 
H:!) is constructed by the local direct derivations dl = (GI '9 
H I )  and 
d2 = (G2 + H:!) and the interface derivation do = (Go '3 
Ho). The 
partial morphisms hl and h:! are induced by the universal property of the 
pushout (&, m;) of (PO, mo) such that the left and bottom squares of the right 
P2 m2 

276 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
diagram of Figure 4.13 commute. If g1 and g2 as well as hl and h2 are total, 
we speak of a synchronous distributed derivation dl Ildoda. 
A distributed graph becomes inconsistent (i.e., a partial splitting) if we delete 
an item in a local graph which has a preimage in the interface that is not 
deleted. This situation can be characterized in set-theoretical terms: 
Characterization 4.3.21 (synchronous distributed derivation) 
Let d, = (Gi ps 
HI) for i E {0,1,2} be direct derivations at conflict-free 
matches. A distributed derivation dlIIdod2 : DG ==+ DH as in Figure 4.13 is 
synchronous if and only if DG is a total splitting, and for k E {1,2} we have 
that y E GO with gk(y) E r n k ( L k  - dom(pk)) implies y E ma(& - dom(p0)). 
Proof sketch 
The structures r n k ( L k  - dom(pk)) for k = 1,2 and rno(L0 - dorn(p0)) con- 
sist of those elements of GI, and Go which are explicitly deleted by the direct 
derivations d k  and do, respectively. The distributed derivation dl I Idod2 is syn- 
chronous if the morphisms hk in the right diagram of Figure 4.13 are total. 
We sketch the “if” part of the proof of Characterization 4.3.21. For a complete 
proof the reader is referred to [18]. 
Let z E Ha. Since pg and rng are pushout morphisms, they are jointly surjective 
by Lemma 4.2.8, i.e., z has either a preimage y E Go or z E Ro. In the first 
case there is gk(y) E GI, since gk is total. Since y is preserved by p;, it is 
not in ma(& - dom(p0)). Hence gk(y) 6 
r n k ( L k  - dom(pk)), which implies by 
some further arguments that gk(y) E dom(p;), i.e., p; o gk(y) is defined. By 
commutativity of the bottom square this implies that also hI,(pg(y)) = hk(z) is 
defined. If z has a preimage z E Ro, m;(znk(z)) is defined since rn; is total by 
conflict-freeness of m k  (see Lemma 4.2.8). By commutativity of the left square 
0 
Finally, we investigate the relationship between distributed and amalgamated 
derivations. Amalgamating a distributed derivation means to construct a global 
observation of the local actions. This is possible only if there is a consistent 
global view at least of the given distributed state DG. Hence DG is assumed 
to be a total splitting in the distribution theorem below. On the other hand, 
distributing an amalgamated derivation means to split a global action into 
local ones. Therefore, the matches of the elementary productions have to be 
compatible with the splitting of the global graph. The Distribution Theorem 
below provides the solution to Problem 3.2.5. 
this implies that also hk(mg(z)) = hk(z) is defined. 

4.3. MAIN RESULTS riv THE SPO APPROACH 
277 
PO 
Ro 
PZ 
;
j
 
$1 
;
I
 
:
;
 
i 
rnl 
m; 
.............. ........... 
pG 
I 
~ Eio 
I 
,
.
,
 
I 
.
,
 
:' 
' \ t  
............................ 
........ 
p;: .....; 
~ : ' ~ _ ~ ~ _ ~ ~ ~ ~ ~  
* HZ 
i 1.' 
Hi 
GI ............................ 
p ,  
* .......................... 
* 
Figure 4.13: A distributed derivation dllIdod2 : DG --t DH with do = (Go 'so 
Ho) and 
dk = (Gk 'Sk 
H k )  fork E {1,2}. 
Theorem 4.3.22 (distribution) 
Let DG = (GI & Go 3 G2) be a total splitting of G = @DG, p l  t 
po + p2 synchronized productions and pl ep0 
p2 : L -% R their amalgamated 
production. Then the following statements are equivalent: 
in' 
in2 
pi Go 
PZ ,m 
* 
1. There are an amalgamated derivation G 
H ,  and a distributed 
match (mi)iEio,1,2} forpl t po + p2 into DG, which is compatible with 
m, i.e., g2+ o m l  = m o in:* and gz o m2 = m o in;*. 
in' 
in2 
2. There is a distributed derivation dllldod2 : DG ==+ DH with di = 
pi ,m; 
(Gi ==+ Hi) for i E { O , l ,  a}. 
Proof sketch 
The proof of this theorem in [19] uses the 4-cube lemma presented in [20], 
which is valid in every category and can be derived as a special case of the 
Additional Remarks: Amalgamated derivations are introduced in the SPO ap- 
proach in [4], while corresponding concepts in the DPO approach have been 
developed in [21]. The Amalgamation Theorem in [4] is concerned with the 
sequentialization of an amalgamated derivation. It is based on the notion of a 
remainder (production) which can be roughly be considered as that part of a 
given production which is not covered by its subproduction. A suitably given 
amalgamated derivation can then be simulated by a derivation consisting of an 
application of the common subproduction, followed by a parallel application of 
the remainders [4]. The concept of amalgamated productions and derivations 
was generalized to cases including more than two elementary productions. Cor- 
responding developments in [18] were motivated by the idea to specify deriva- 
commutativity of colimits. 
0 

278 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
tions in which a variable number of mutually interacting productions must be 
synchronized. 
Distributed graphs and derivations in the SPO approach are introduced in [19], 
where also the Distribution Theorem is formulated. The comparison of several 
kinds of global and (synchronous and asynchronous) distributed derivations led 
to a hierarchy theorem for distributed derivations. Splitting a state into two 
substates with one interface is, of course, a very basic kind of a distribution. 
In [18] this is generalized to arbitrary many local states, pairwise related by 
interfaces. Even more general topologies are considered in [22,23], in the DPO 
approach. 
4.4 
Application Conditions in the SPO Approach 
Using the rule-based formalism introduced so far we may easily and intuitively 
describe, how given graphs shall be transformed into derived graphs. For spec- 
ifying when these transformations should occur, however, we are restricted to 
positive application conditions concerning the existence of certain nodes and 
edges, which can be specified within the left-hand side of the productions. In 
this section we introduce the possibility to specify also negative application 
conditions for each particular production, and extend the results of Section 
4.3.1 concerning independence and parallelism to productions and derivations 
with application conditions. 
4.4.1 
Negative Application Conditions 
We use the model of the Pacman game to motivate the use of negative appli- 
cation conditions. 
Example 4.8 
Recall the production moveP from Figure 4.1. As effect of this production 
Pacman moves to a new field not taking into account whether this field is 
dangerous for him or not. If Pacman moves to a field where a ghost is waiting, 
he may be killed in the next derivation step. An intelligent player of the Pacman 
game would like to apply the moveP production only if there is n o  ghost on the 
field Pacman is moving to. Hence we have a negative application condition for 
our production. The production ImoweP which models an intelligent moving of 
Pacman is depicted as the left upper production of Figure 4.14. The forbidden 
context, i.e., the ghost with the edge pointing to the field Pacman wants to 
move to, is enclosed by a dotted line and crossed out, in order to denote that 
these elements must not exist if the production shall be applied. Analogously 

4.4. APPLICATION CONDITIONS IN THE SPO APPROACH 
279 
Ti.Q1 [K~]%zqD 
Figure 4.14: Intelligent moving of Pacman and ghosts. 
one could think of an intelligent behavior of the ghosts. If they want to kill 
Pacman they have to occupy as many fields as possible. Hence a ghost should 
only be moved to a field on which there is not already another ghost (see 
production ImoveG in the right upper part of Figure 4.14). 
By now we have shown that negative application conditions can be used to in- 
clude rather simple strategies of the game in our model. Graph transformations 
are by default non-deterministic. But for our model it is desirable to restrict 
this non-determinism, i.e., to have priorities on the productions. Moving has a 
lower priority than eating an apple for Pacman or than killing Pacman for a 
ghost. These priorities can also be coded into negative application conditions 
for the move productions, such that they are only applicable if the eat resp. kill 
production is not applicable to Pacman resp. the same ghost (see lower part of 
Figure 4.14). Note that intelligent moving with lower priority has a negative 
application condition consisting of two forbidden contexts, called constraints 
in the following, one taking care of the field to move to and one making sure 
that moving is of lower priority. These application conditions with more than 
one constraint are satisfied if each of the constraints is satisfied. 
0 
The general idea is to have a left-hand side not only consisting of one graph 
but of several ones, connected by morphisms L --& L, called constraints, with 
the original left-hand L. For each constraint, L - l(L) represents the forbidden 
structure, i.e., the dotted bordered part of the example productions. A match 
satisfies a constraint if it cannot be extended to the forbidden graph i, 
i.e., 
if the additional elements are not present in the context of the match. If a 
constraint is non-injective and surjective, i.e., the forbidden structure i - l ( L )  is 
empty but items of L are identified by 1, it can only be satisfied by a match not 
identifying these items. Thus, negative constraints can also express injectivity 
requirements for the match. A match satisfies a negative application condition 
if it satisfies all constraints the application condition consists of. 

280 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
Definition 4.4.1 (application conditions) 
1. A negative application condition, or application condition for short, 
over a graph L is a finite set A of total morphisms L -kt L, called 
constraints. 
2. A total graph morphism L 3 G satisfies a constraint L --% L, written 
m + I ,  if there is no total morphism L -% G such that n 0 1 = m. m 
satisfies an application condition A over L, written m 
A, if it satisfies 
all constraints 1 E A. 
3. An application condition A is said to be consistent if there is a graph 
4. A production with application condition fi : ( L  -% R,A(p)), or 
conditional production for short, is composed of a production name 
l j  and a pair consisting of a partial graph morphism p and an application 
condition A(p) over L. It is applicable to a graph G at L -% G if m 
satisfies A(p). In this case, the direct derivation G 
H is called direct 
conditional derivation G @ H .  
G and a total morphism L -% G s.t. m satisfies A. 
Example 4.9 
In Figure 4.15 we show the formal representation of the production LImoveP : 
(moveP, {lp, int}) of Figure 4.14 consisting of the unconditional production 
moveP of Figure 4.1 and two constraints. Morphisms are denoted by numbers 
at corresponding nodes. The constraint int states that there must not be a 
ghost at the field Pacman wants to move to, and lp ensures that there is 
no apple at Pacmans current position. Accordingly the match m for moveP 
satisfies lp since we cannot extend m to Lip, while m does not satisfy int. 
Hence m does not satisfy {lp, int}. If, however, Pacman moves to the left, i.e. 
vertex 0 2  of L is mapped to vertex 0 6  in G, int is satisfied as well and the 
production can be applied. 
0 
It is possible to define application conditions which can not be satisfied by 
any match, i.e., the corresponding conditional production is never applicable. 
This is due to the fact that contradictions may appear between the positive 
requirements of the productions left-hand side and the negative constraints. 
A trivial example for such a contradiction is a constraint which is an isomor- 
phism. More generally, a contradiction occurs if the forbidden items of L - 1 ( L)  
can be mapped onto the required ones in L, i.e., a total morphism L --% L 
exists, extending the identity on L. Hence, a negative application condition A 
is consistent in the sense of Definition 4.4.1.3 (i.e., free of these contradictions) 
iff the match L 4 L satisfies A. 

4.4. APPLlCATlON CONDITIONS IN THE SPO APPROACH 
281 
moveP 
d 
R 
Figure 4.15: Formal representation of the conditional production LIrnoveP 
Lemma 4.4.2 (consistency of application conditions) 
An application condition A over L is consistent if and only if it is satisfied by 
Pro0 f 
If A is satisfied by  id^, A is consistent by Definition 4.4.1. Vice versa, let idL 
not satisfy A. Then there are a constraint L 4, i 
E A and a total morphism 
L 
G we have that 
m = m o idL, this implies that (m o n) o 1 = m, i.e., m does not satisfy the 
0 
Even more powerful application condition, which can express, for example, 
cardinality restrictions on the number of incoming edges of a given node, are 
obtained if the the forbidden morphisms L 4 G of Definition 4.4.1.2 are 
required to be injective. These application conditions with injective satisfaction, 
as they are called in [2], may, for example, express the gluing condition of the 
DPO approach (see Proposition 3.3.4) consisting of the dangling condition and 
the identification condition: For a given production L -% R we let 
idL . 
L s.t. n o 1 = idL. Since for any given match L 
constraint 1 E A, and hence not A. 
0 the identification condition of p be the set IC(p) of all total surjective 
morphisms I ,  except isomorphisms, such that for all 1 we have 1(x) = l(y) 
for some x, y E L with x # y and x $2 dum(p), and 
0 the dangling condition of p be the set DC(p) of all total morphisms 
L 4, L such that 1 is surjective up to an edge e (and possibly a node) 
with s(e) or t(e) in Z(L - dom(p)). 
Now a match rn satisfies the gluing condition if and only if it injectively satisfies 
the application conditions IC(p) and DC(p), i.e., iff there is no total injective 

282 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
morphism L --% G for any constraint L & L E I C ( p )  U DC(p) satisfying 
n o 1 = m. Using this equivalence, DPO derivations can be characterized by 
conditional SPO derivations. 
4.4.2 
Following the line of [2] we extend the results of Section 4.3.1 on independence 
and parallelism to conditional derivations. Thereby, we provide solutions to 
the Local Church-Rosser Problem 3.2.1 and the Parallelism Problem 3.2.2 for 
the SPO approach with application conditions. 
Independence and Parallelism of Conditional Derivations 
Interleaving 
According to Section 4.3, two derivations dl and d2 are considered to be par- 
allel independent if they may occur in any order with the same result. For 
unconditional derivations this is mainly a problem of deletion, i.e., none of 
the two derivations should delete something that is needed for the match of 
its alternative. Taking into account negative application conditions specifying 
forbidden application contexts, we have to ensure that, in addition, no such 
forbidden context is established. 
Definition 4.4.3 (parallel independence) 
Let dl = (G '3 
H I )  and dz = (G 
H2) be two direct conditional 
derivations using $1 : ( p l ,  A(p1)) and $2 : (p2, A(p2)), respectively. Then we 
say that d2 is weakly parallel independent of dl if mh = T I  * om2 : L2 -+ HI 
is a match for pa that satisfies the application condition A(p2) of $2 (see left 
diagram of Figure 4.17). Direct conditional derivations dl and d2 are parallel 
independent if they are mutually weakly parallel independent. 
Example 4.10 
Let (1) and (2) in the left side of Figure 4.16 be applications of the produc- 
tions m m e P  and m m e G  of Figure 4.1, respectively. Then these unconditional 
direct derivations are parallel independent. If we apply the conditional pro- 
duction I m o v e P  of Figure 4.14 instead of m o u e P ,  preventing Pacman from 
0 
A derivation dh is sequentially independent of its predecessor dl if dh may 
occur also alternatively to, or even before d l .  In Section 4.3 this is shown to 
be the case if the application context of dh has already been present before 
the occurrence of d l .  In the conditional case we additionally require that no 
forbidden context of d i  has been destroyed by d l .  
approaching the ghost, (1) is not weakly parallel independent of (2). 

4.4. APPLICATION CONDITIONS IN THE SPO APPROACH 
283 
Figure 4.16: Parallel and sequential independence (example). 
Definition 4.4.4 (sequential independenqe) 
Let dl = (G =% H I )  and d i  = (HI 
X )  be two direct conditional 
derivations using 51 : (pl, A(p1)) and 5, : (pz, A(pz)), respectively. Then we 
say that dh is weakly sequentially independent of dl if m2 = ( T I * ) - '  o m ;  : 
Lz -+ G is a match for p2 that satisfies the application condition A(p2) of p2 
(see right diagram in Figure 4.17). Let dz = (G p
3
 
H2) be the corresponding 
direct derivation. In case that, additionally, dl is weakly parallel independent 
of d2 the derivation sequence (G1 p% 
H1 ==+ X )  is called sequentially 
independent. 
Example 4.11 
In the right side of Figure 4.16 a sequential independent derivation sequence 
using kill and moveG of Figure 4.1 is shown. If, however, (2) results from an 
application of LIrnoveG of Figure 4.14, (2) is not independent of (1) because 
The following theorem is a straightforward generalization of the Local Church- 
Rosser Theorem of Section 4.3 to conditional derivations. It provides the so- 
lution to the Local Church-Rosser Problem 3.2.1 for SPO derivations with 
application conditions. 
PI ml 
P2 mz 
ih,m; 
the ghost has to kill Pacman before leaving his field. 
Theorem 4.4.5 (conditional local Church-Rosser) 
PZ mz 
Let dl = (G '3 
H I )  and d2 = (G + H2) be two direct conditional 
derivations. Then the following stat emen ts are equivalent : 
1. dl and dz are parallel independent. 
2. There are direct conditional derivations H1 & X and H2 ==+ X 
such that G P
S
 
H1 6 
X and G ==+ H2 * X are sequentially 
independent conditional derivations. 
Up to isomorphism, a bijective correspondence between 1. and 2. above is given 
byrnh=q*om2 andm', = r 2 * 0 m l .  
PZ ,m; 
PI mi 
82 m: 
Pz,mz 
Pi,m; 

284 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
Figure 4.17: Independence of conditional derivations. 
Proof 
Directly from Definitions 4.4.3 and 4.4.4 and the Local Church-Rosser Theorem 
4.3.6. 
0 
Explicit Parallelism 
Now we consider the construction of a parallel conditional production from 
two conditional elementary productions. Starting with the parallel production 
pl + p2 defined in Definition 4.3.7 we have to find a suitable application condi- 
tion for pl + p2. For unconditional single-pushout derivations, the applicability 
of the parallel production is (trivially) equivalent to the applicability of the 
elementary productions at their corresponding matches. Generalizing this we 
have to construct A(p1 + p 2 )  as conjunction of A(p1) and A(p2). 
If two application conditions are defined over the same left-hand side, their 
conjunction is simply given by their union. In our case however, A ( p l )  and 
A(p2) are application conditions over Ll and La, respectively. Thus the problem 
remains, how to extend the application conditions over L1 and L2 to the larger 
graph L1 + Lz. Below the extension of a constraint 1 along a total morphism 
m is defined by the pushout of 1 and mi. 
Definition 4.4.6 (extension) 
If L 3 G is a total morphism and L 
L a constraint, the extension m#(Z) 
of 1 along m is given by the pushout diagram (1) in the left-hand side of Figure 
4.18. The extension of an application condition A over L is defined by 
m#(A) = {m#(l)Il E A}. 

4.4. APPLICATION CONDITIONS IN THE SPO APPROACH 
285 
Q 
t 
Q 
1 
_1 
4 
1 
_2 
Figure 4.18: Extension of constraints and construction of a parallel conditional production 
Proposit ion 4 A .  7 (extension) 
Let L -% G be a total morphism and A an application condition over L. Then, 
for all matches G -% K ,  e k m#(A) iff e o m k A. 
Proof 
We show that for each 1 E A we have e 
m#(l) iff e o m  + I .  Assume n s.t. (2) 
in Diagram 4.18 commutes. Then nr = noriz and 72’01 = moe by commutativity 
of (1) and (2). Vice versa, let L 5 K be given with nr o 1 = e o m. Then n 
0 
Now we define the parallel conditional production 61 + $2 as the parallel pro- 
duction of the underlying productions pl and p2 of pl and p,, equipped with 
the extensions of the application conditions A(p1) and A(p2) of the component 
productions along in; and in:, respectively. 
with n o g = e exists by the universal property of (1). 
Definition 4.4.8 (parallel conditional production) 
Let fil : (L1 -% R1, A(p1)) and $2 : (Lz 3 Rz, A(p2)) be conditional produc- 
tions and pl +pa : L 
R the parallel production of pl and p2 according to De- 
finition 4.3.7. Then the parallel conditional production $1 + $2 : (p, A ( p ) )  
is composed of the production name $1 + $2 and the pair ( p , A ( p ) ) ,  where 
A ( p )  = in;#(A(pl)) U in;#(A(pz)). A conditional derivation G 
==%-’ 
X 
using $1 + $2 is called parallel conditional derivation. 
Pi+p m 
Example 4.12 
The construction above does not guarantee, that the application condition 
A(p1 + p2) of fil + $2 is consistent, even if both A(p1) and A(p2) are. In the 
right side of Figure 4.18 the production p1 : ( P I ,  (11)) adds a loop to a node 
if there isn’t already one. The production p, : (p2, { / 2 ) )  inserts a node in an 
empty graph. The application condition of the parallel production $1 + p ,  : 
(pl + pa, {l:, 1 ; ) )  is not consistent (compare Lemma 4.4.2) because we can 

286 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
reverse 1; by identifying the two nodes. On the other hand, there is no graph to 
which we can apply both p 1  and p 2 ,  i.e., their application domains are disjoint. 
That this is no mere coincidence is shown by the following proposition. 
0 
Proposition 4.4.9 (applicability of parallel production) 
Let p 1 , p z  and p 1  + p 2  be given as above together with matches L1 3 G 
and L2 3 G for pl and p2 into G and let L1 + La m%m2 
G be the parallel 
match for pl +p2. Then ml + m2 
A(p1) and 
Proof 
mk = ml + m 2  0 ink for k = 1 , 2  by universal property of L1 + La. Then 
Proposition 4.4.9 is a direct consequence of Proposition 4.4.7. 
0 
Since we can check consistency of application conditions by Lemma 4.4.2 this 
provides us with a method to decide whether a parallel production makes sense 
or not. Furthermore, we may now extend the Weak Parallelism Theorem 4.3.8 
to conditional derivations, which solves the Parallelism Problem 3.2.2 for con- 
ditional derivations. 
A(p1 + p ~ )  
if and only if ml 
m2 + &a). 
Theorem 4.4.10 (conditional weak parallelism) 
Given conditional productions pl and p a ,  the following two statements are 
equivalent: 
Pi+Pz mi+mz 
1. There is a direct conditional parallel derivation G 
+ 
X ,  s.t. 
Pi ,mi 
G p% 
HZ is weakly parallel independent of G ===+ H I .  
PZ ,mk 
Pz,m; 
2. There is a conditional derivation G p% 
HI ==+ X, where H I  =j X 
is weakly sequentially independent of G '3 
H I .  
Up to isomorphism, a unique correspondence between 1. and 2. above is given 
by mi = r1* o m2. 
Pro0 f 
Directly from Proposition 4.4.9, Definition 4.4.3 and 4.4.4 and the Parallelism 
Theorem 4.3.8. 
0 
Example 4.13 
In the left side of Figure 4.19 the parallel production of ImoveP and ImoveG 
is shown, modeling a simultaneous move of Pacman and one of the ghosts. 
Its graphical representation is given on the right. Applying this production to 
the graph in the upper left of Figure 4.16 we have an example of a parallel 
conditional derivation that cannot be sequentialized, because the alternative 

4.5. TRANSFORMATION OF MORE GENERAL STRUCTURES 
287 
moveP 
+ 
ImoveP 
+ 
Figure 4.19: Parallel production of ImoveP and ImoveG 
derivations using IrnoveG and ImoveP (denoted by (1) and (2) in the left side 
of Figure 4.16) are not parallel independent (cf. Example 4.10). 
Additional Remarks: The results of this section have been obtained in [2]. In 
the case of application conditions with injective satisfaction (cf. Section 4.4), 
similar results are possible. Moreover, most of the remaining results of Sec- 
tion 4.3 have already been extended to such application conditions in [24,25]. 
In addition to the left-sided negative application conditions of Definition 4.4.1, 
also right-sided application conditions and so-called propositional application 
conditions, i.e., propositional expressions over constraints, are considered in 
[25]. This is even further generalized in [26] and [27] by conditional application 
conditions. 
Another interesting line of research is the generative power of graph grammars 
with (different kinds of) conditional productions. In [a] it has been shown that 
context-free graph grammars with positive and/or negative application condi- 
tions are strictly more powerful than unconditional ones. Similar investigations 
can be found in [26] for graph grammars without nonterminal labels. 
4.5 
Transformation of More General Structures in the SPO Ap- 
proach 
Until now we presented SPO transformations and corresponding results based 
on labeled graphs. In this section we will show that the SPO approach is not 
restricted to this kind of graphs, but it is also applicable to more sophisti- 
cated structures. We will basically consider two kinds of extensions: a more 
powerful labeling concept - leading to the concept of attributed graphs in Sec- 
tion 4.5.1; and more complex graphical structures - leading to the concept 

288 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
of graph structures in Section 4.5.2. By a generalization of graph structures 
we will then be able to cope with these two different extensions within the 
same framework. This framework, introduced in [5,16], opens new possibili- 
ties for defining graphs. (For example we can use instead of sets and labeling 
functions, graphs and labeling graph morphisms - this idea was worked out in 
[28] for the definition of class-based graph grammars.) Finally in Section 4.5.3 
we review high-level replacement systems: a general axiomatic framework for 
transformation systems and their properties. 
4.5.1 Attributed Graphs 
The existence of labels allows us to distinguish vertices or edges within a graph 
according to their associated label. Thus, labels provide a very basic type 
concept for graphs. Usually in a software system the types of elements do not 
change during the execution of the system, and therefore the treatment of labels 
presented in the last sections (where label morphisms were identities) is very 
reasonable. Nevertheless, often a situation occurs in which the labels (types) 
of the elements in a graph are not relevant for the application of a production. 
In this case labels should take the role of parameters (generic types). But 
actually, the strict typing through labels presented so far requires a number 
of productions (one for each possible combination of labels) to describe this 
situation. For practical reasons this is not adequate, a higher-level kind of 
typing concept is needed. From now on we will refer to this kind of high-level 
types as attributes. The basic idea of attributes in graph transformations is 
to allow the handling of labels abstractly. This is realized by the presence of 
corresponding variables and a concept of assignment of these variables in an 
actual situation. In particular, the concept of attributes includes the presence 
of operations on these sets (of attributes). 
Attributes are used in all graph grammar proposals for software engineering 
since they integrate structural (i.e. graphical) aspects of a system with data- 
type aspects (i.e. calculation of values). This leads to compact descriptions in 
which e.g. well-known arithmetic operations need not artificially be coded into 
graphical structures. Similar concepts of combining structural and algebraic 
aspects can be found in the theory of attributed string grammars [29] in al- 
gebraic high-level Petri-nets [30,31,32], which are a combination of Petri-nets 
and algebraic specifications, and in the specification language LOTOS [33], 
which integrates CCS-like specifications for the structural part with algebraic 
specifications for the data type component. 
In the SPO approach, attributes have been integrated in [3] (see [34] for a 
corresponding extension of the DPO approach). This integration preserves the 

4.5. TRANSFORMATION OF MORE GENERAL STRUCTURES 
289 
fundamental derivation concept of the algebraic approach i.e., both the ma- 
nipulation of the graphical structure and the calculation of the new attributes 
are combined within a (single) pushout construction. In [3] attributes were 
specified using algebraic specifications in the sense of [35]. Algebraic specifi- 
cations provide a well-established formalism for treating data-types, variables, 
evaluations and substitutions. Moreover not only a set of types is available as 
attributes, but we can make use of the operations of the specification in order 
to indicate abstractly relationships between types. The proposal for the inte- 
gration of attributes into graph transformation reviewed here is a simplification 
of the approach in [3]. It has already been used in [36]. 
Before introducing formally the concept of an attributed graph, we need to 
introduce some basic notions of universal algebra. A signature Sig = (S, OP) 
consist? of a set of sorts and a family of sets OP = (OP,,s)wE~*,sE~ 
of opera- 
tion symbols. For op € OP,,,, we also write op : w + s. A Sag-algebra A is an 
S-indexed family ( A s ) s E ~  
of carrier sets together with an OP-indexed family of 
mappings (opA),,Eop such that opA : A,, x . . . x A,,, + A, if op E OP, ,... ,,,,. 
If w = s1.. .s, E S*, we sometimes write A, for A,, x . . . x A,,. A 
Sig-homomorphism f : A + B between two Sig-algebras A and B is a 
sort-indexed family of total mappings f = (f, : A, + B s ) s E ~  
such that 
o p B ( f ( z ) )  = f ( o p A ( z ) )  for all z E A,. The category A Z g ( S i g )  has as objects 
all Sig-algebras and as morphisms all total homomorphisms between them. 
It is well-know that A Z g ( S i g )  has all colimits. 24 : A Z g ( S i g )  + SetP is a 
functor assigning to each Sig-algebra A the disjoint union of its carrier sets 
A,, and to each homomorphism f the disjoint union the total functions f,, for 
all s E S.  
Attributes are labels of graphical objects taken from an attribute algebra. 
Hence, an attributed graph consists of a (labeled) graph and an attribute 
algebra, together with some attribute functions connecting the graphical and 
the algebraic part. 
Definition 4.5.1 (attributed graph) 
Given a label alphabet L and a signature Sig = (S,OP). Then AG = 
(AGv,AGE, sAG,tAG, 
luAG,leAG, AGA, auAG,aeAG) 
is a Sig-attributed graph, 
where 
i) AGG = (AGv,AGE,s AG , tAG , 1uAG,leAG) is an L-labeled graph with 
labeling functions 1uAG, leAG for vertices and edges (cf. Definition 3.3.1), 
ii) AGA is a Sag-algebra, 
iii) avAG : AGv + U(AGA) and aeAG : AGE + U(AGA) are the vertex 
and edge attributing functions 

290 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
A (Sig-attributed graph) morphism between two Sig-attributed graphs AGi = 
(AGiv, A G ~ E ,  
sAGi, tAGi, luAGi1 leAGi, A G ~ A ,  
auAGi, aeAGi) for i = 1,2 is a tu- 
ple f = ( f ~ ,  
f ~ )  
where fc = ( f v ,  f ~ )  
is a partial graph morphism, and f~ is 
a total algebra homomorphism such that Vu E dorn(fv). U(fA)(uuAG’(u)) = 
uuAGz(fV(u)) 
and Ve E d o m ( f ~ ) .  
U ( ~ A )  
(ueAG’(e)) = aeAG2(fE(e)); 
f is total 
(injective) if f~ and f~ are total (injective). 
Proposition 4.5.2 (category AGraphP) 
Sig-attributed graphs and Sig-attributed graph morphisms form a category, 
called AGraphP. 
Proof 
The proof is based on the fact that the composition of morphisms is well- 
defined. 
0 
For the definition of direct derivations of attributed graphs as single-pushout 
constructions, it is essential that AGraphPhas pushouts. The construction 
of pushouts in AGraphP can be seen as a special case of [3]: pushouts are 
constructed componentwise in GraphP and AZg(Sig). Actually, the category 
AgraphP has not only pushouts but all colimits (due to the fact that coprod- 
ucts in AgraphP can be constructed componentwise in Set). As most of the 
results presented in Section 4.3 are based on colimit constructions, they shoulct 
carry over to the AgraphP setting. For a proof of the following theorem we 
refer to [3]. 
Theorem 4.5.3 
The category AGraphP has pushouts. 
0 
Productions, grammars, matches, and (direct) derivations using attributed 
graphs are defined analogously to the Definitions 4.2.2 and 4.2.6 in Section 4.2, 
by replacing the category GraphP of graphs and partial graph morphisms by 
some category AGraphP of attributed graphs. 
Below we extend the Pacman example (Example 4.1 of Section 4.2) using 
attributes for counting the apples Pacman has eaten. 
Example 4.14 (attributed graph transformation) 
For the graphical part AGG we use the same labeled graphs as in Example 4.1. 
The signature of natural numbers 
Signature Nut: sorts nut 
opns 0 + nat 
succ : nut + nut 
+ : nut x nut ++ nut 
is used as the signature for the attribute algebras AGA. 

4.5. TRANSFORMATION OF MORE GENERAL STRUCTURES 
291 
Figure 4.20: Counting Pacmans apples. 
Attributes in productions are usually taken from “syntactical” (term) algebras. 
Figure 4.20 shows the attributed graph production eat(n), where the left- and 
right-hand side graphs are attributed over the term algebra T N ~ ~ ( X )  
with 
variables in X = {n}. The graphical part is similar to production eat in Figure 
4.1 on page 290.“ On the left-hand side, Pacman is attributed with the variable 
n representing the number of apples Pacman has eaten before the application 
of the production. On the right-hand side, n is replaced by succ(n), i.e., the 
number of apples increases by one. 
For the graphs to be rewritten, we fix some “semantical algebra”, the algebra 
IN of natural numbers. As a transformation of labeled graphs does not change 
the label set, this algebra is preserved by an attributed graph transformation 
as well. Figure 4.20 shows an application of the production eat(n) to a graph 
representing a state where Pacman has already eaten four apples, and is about 
to eat the fifth one. The graphical part is matched as usual. Then we have to 
find an assignment to the variable n which is compatible with the matching 
of the graphical part, i.e., n is mapped to 4. The derived graph is constructed 
componentwisely by taking the pushout in GraphP for the graphical part, 
and by extending the assignment n C) 4 to succ(n), leading to succ(n) H 5. 
In this way, attributes in the derived graphs are calculated from attributes in 
the given graphs. 
0 
CSince the compatibility conditions for attributed graph morphisms (cf. Definition 4.5.1) 
do not allow to change attributes, carrier loops have to be introduced at attributed vertices, 
which are deleted and re-generated each time an attribute is modified. In order to simplify 
the presentation, these carrier loops are often omitted in the drawings. 

292 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
4.5.2 
In order to be more flexible in system modeling, often hypergraphs are used 
instead of graphs [37,38,39], see also Chapter 2 in this handbook. 
Graph Structures and Generalized Graph Structures 
Definition 4.5.4 (hypergraph) 
A hypergraph G = (V, E , s , t )  consists of a set of vertices V ,  a set of edges 
E, and two total mappings s,t : E + V" from the set of edges into the free 
monoid over the set of vertices which provide each hyperedge e E E with a 
sequences of n source and m target vertices s(e) = 211 . . . v, and t(e) = v1 . . . urn, 
respectively. 
Since in the algebraic approaches graphs are considered as algebras w.r.t. a 
certain signature, also hypergraphs are defined in this way. The signature for 
hypergraphs is given below, where hyperedges are sorted according to their 
number of source vertices n and target vertices m. 
Signature HSig: sorts v, 
(En,m)n,mEIN 
wns ( ~ 1 , .  . . , sn, tl,. . . , tm En,m -+ V ) n , m ~ ~ ~  
Example 4.15 (hypergraph) 
In the following picture a concrete hypergraph of this signature is shown, hav- 
ing 3 non-empty carrier sets, namely Gv = {.1,.2,.3}, 
G E I , ~  
= {el,l}, and 
G ~ 1 , 2  = {e1,2>. 
e1.2 
t21.2 
Generalizing partial graph morphisms, a partial homomorphism f : G -+ H 
between two algebras can be defined as total homomorphism f! : dom(f) -+ H 
from some subalgebra dom(f) 
G. For each signature Sig this leads to a 
category of algebras and partial morphisms AZg(Sig)P. In [4] it was shown 
that this category is cocomplete if and only if all operations in Sig are unary, 
which motivated the following definition. 
Definition 4.5.5 (graph structure signature, graph structure) 
A graph structure signature GS is a signature which contains unary oper- 
ator symbols only. A graph structure is a GS-algebra. 

4.5. TRANSFORMATION OF MORE GENERAL STRUCTURES 
293 
Most of the results presented in Section 4.3 have originally been elaborated for 
graph structures [7,4], which do not only include graphs and hypergraphs, but 
also hierarchical graphs and higher order graphs (having edges between edges). 
An even larger framework is obtained by the concept of generalized graph 
structures [16]. In order to explain this let us reconsider Definition 4.5.4, where 
a hypergraph is given by two carrier sets G v ,  GE and two operations sG, tG : 
GE + G;. Such an algebra can not be defined directly as a graph structure 
since the mappings sG,tG are not between the carriers but from the set of 
edges GE to the free monoid G; over the set of vertices G v .  This has led to 
the infinite graph structure signature for hypergraphs above. Using generalized 
graph structures instead we may realize directly the hypergraphs of Definition 
4.5.4: A hypergraph is an algebra G = ( G ~ , G E ,  
sG,tG : FE(GE) + Fv(Gv)), 
where Gv and GE are sets of vertices and hyperedges, and sG, tG are operations 
between sets derived from the carrier sets by application of the functors FE 
and Fv, associated with the sort symbols E and V ,  respectively. The functor 
FE is the identity functor, i.e., FE(GE) = G E ,  and the functor FV maps every 
set of vertices to its free monoid, i.e., Fv(Gv) = G;. 
On morphisms (partial functions) these functors are defined as follows: FE 
is the identity functor, i.e., FE(fE) = f E .  F v ( f v )  = f ;  shall be defined 
pointwisely: for each sequence of vertices I = vlv2 . . . v, E G; 
f;(Z) 
= 
fv(vl)fv(v2). . . fv(vn) E H; if fv(vi) is defined for all i = 1.. .n, and other- 
wise it is undefined. 
This allows to define GGS-morphisms. Figure 4.21 depicts a partial mor- 
phism f = ( f E ,  f v )  : G + H between generalized graph structures G = 
(Gv, G E, sG, tG) and H = (Hv,HE, sH, tH). It consists of a pair of mappings 
f E  : GE + HE and f v  : G v  + H v  between edges and vertices of G and H ,  re- 
spectively, such that the top diagram commutes for each operation symbol, i.e. 
f ; o S G O  fE? = S H o  f E !  and f;otGO 
fE? = t H O  fE!, where fE? : dom(fE) -+ GE 
and f E !  : d o m ( f E )  + HE form the span-representation of f E .  
Thus generalized graph structures may be described as comma categories w.r.t. 
certain signatures where the compatibility requirement of morphisms has been 
relaxed in order to allow partial morphisms ('weak homomorphisms'). Anal- 
ogously to comma-categories, colimits in GGS-categories can be constructed 
componentwisely followed - 
in the GGS-case - by a free construction ('to- 
talization'). 
The concept of GGS provides a constructive approach for generating internally 
structured categories of graph-like structures and partial morphisms from sim- 
pler ones. Among the large number of examples there are labeled and unlabeled 

294 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
Figure 4.21: Definition of a partial GGS morphism f : G --t H 
graphs, hypergraphs, attributed graphs d ,  attributed and labeled hypergraphs, 
hierarchical graphs, graph-interpreted (or typed) graphs, graph grammars, 
Petri Nets, and Algebraic High-Level (AHL) Nets. Properties of these cate- 
gories, like cocompleteness, can be inferred from properties of the components 
and the way in which they are composed. 
4.5.3 High-Level Replacement Systems 
The formal investigation of graph grammars based on different kinds of graphs 
has often led to similar results based on similar proofs. This fact gave raise 
to the question whether it is possible to ‘reuse’ the proofs from one kind of 
graph grammar to obtain analogous results in another kind. The definition 
of High-Level Replacement Systems [6], shortly HLR systems, was the answer 
to this question. They provide an abstract framework in which not graphs, 
but objects of an arbitrary (instance) category are transformed (generalizing 
the ideas of graph grammars to arbitrary categorical grammars). Obviously, 
not every instance category gives raise to the same results; they depend very 
much on the properties of these categories. Hence, due to its categorical nature, 
the focus of HLR systems is not on the structure of objects (as in the GGS 
approach) but on the properties of its instance categories. Minimal conditions 
are extracted which allow for definitions and theorems concerning, for example, 
parallelism, embedding, or amalgamation, and in this way such theorems can be 
dRecall that attributed graphs cannot be seen as graph structures, due to the fact that 
arbitrary signatures, like of booleans and natural numbers, may have non-unary operations. 

4.5. TRANSFORMATION OF MORE GENERAL STRUCTURES 
295 
proven for the biggest class of instance categories. Originally HLR systems were 
defined following the DPO approach [40]. Here we present the basic definitions 
of HLR systems of type SPO, developed in [6]. In the following, HLR systems 
are assumed to be of type SPO. 
The basic assumption of HLR systems is that the structures we want to trans- 
form belong to some category Cat. The theory of HLR systems defines the 
basic concepts of production, derivation and grammar in a generic (categorical) 
way: a production is a morphism in Cat, a match belongs to a distinguished 
class of morphism, and direct derivations are given by pushouts. For example, 
if Cat=GraphP, we obtain the SPO framework as introduced in Section 4.2. 
Definition 4.5.6 (HLR system) 
Let Cat be a category and Match be a subcategory of Cat such that Match 
and Cat coincide on objects. 
1. A production r : L + R is a Cat morphism. 
2. An object G can be directly derived to an object H using a production 
T : L + R if there is a pushout (1) in Cat such that m is a match, i.e., 
it belongs to Match. 
3. A derivation is a sequence of direct derivations. 
4. An HLR system HLRS = ( I ,  P, T )  over Cat is given by a start object 
I ,  a set of productions P, and a class of terminal objects T C Cat. 
The HLR framework covers several concrete rewrite formalisms, which are ob- 
tained by choosing a concrete category Cat of structures, satisfying some basic 
conditions. The following conditions ensure that the well-known parallelism re- 
sults are valid in the instance category Cat. 
Definition 4.5.7 (SPO conditions and categories) 
The following conditions (1)-(4) are called SPO conditions for parallelism of 
HLR systems. A category Cat together with a subcategory Match as given 
in Definition 4.5.6 is called SPO category if these conditions are satisfied. 

296 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
1. Existence of pushouts with Match morphisms, i.e. Cat has pushouts if 
at least one morphism is in Match. 
2. Match has finite coproducts, which are preserved by the inclusion func- 
tor C: Match t 
Cat. 
3. Prefix closure of coproducts? 
4. Prefix closure of Match, i.e. if f o g E Match then g E Match. 
Examples for SPO categories are GraphP, AZg(GS)P (with GS being a 
graph structure signature), SPECP (category of algebraic specifications and 
strict partial morphisms) [6]. The interpretation of productions and derivations 
depends on the instance category. For example, transformations of algebraic 
specifications may be interpreted as interconnection of modules in the context 
of modular system design [41]. In [6] it is shown that slightly different versions 
of the Local Church Rosser Theorem 4.3.6 and the Parallelism Theorem 4.3.8 
hold in HLR-systems over SPO categories, and it is an interesting topic for 
further research to generalize also the other results of Section 4.3 to the HLR- 
framework. 
4.6 
Comparison of DPO and SPO Approach 
Section 3.2 provided an informal introduction in the algebraic theory of graph 
rewriting, where many relevant concepts and results have been introduced in 
terms of problems. In this section the solutions to these problems 
~ 
given 
throughout Chapter 3 and this chapter for the DPO and SPO approaches, 
respectively 
~ 
are summarized and compared with each other. Working out 
the similarities and the differences of the corresponding results will allow to 
understand the relationships between the two algebraic approaches. 
Since in Section 3.2 the concepts are introduced independently of a particular 
approach, this provides us with an abstract terminology that can be consid- 
ered as a common “signature” for (algebraic) graph rewriting approaches. This 
signature has sort symbols for graphs, productions, and derivations, etc., and 
operation or predicate symbols for (direct) derivation, parallel and sequential 
composition, etc., and the various relations that may hold between produc- 
tions or derivations like the subproduction or the embedding relation. Most of 
eA morphism p : L t 
P is called a pref;x of r : L t 
R if there is I : P 4 R such 
that I o p = r .  This type of properties which make reference to prefixes of productions and 
requires some closure properties for all prefixes is typical for the theory of HLRS. It is the 
device to control the interaction of “partiality” and “totality” of morphisms in Cat resp. 
Match (see [6] for more details). 

4.6. COMPARISON OF DPO AND SPO APPROACH 
297 
the problems of Section 3.2 ask for conditions, i.e., relations on derivations, 
ensuring that some construction is defined for these derivations. The paral- 
lelization condition of Problem 3.2.2, for example, which is a unary relation 
on two-step sequential derivations, ensures that the synthesis construction is 
defined, leading to an equivalent direct parallel derivation. 
In Chapter 3 and this chapter, the signature of Section 3.2 is interpreted in 
the DPO and SPO approach, respectively, by providing a definition for its 
sorts, operation and predicate symbols in terms of the productions, deriva- 
tions and constructions, etc., of the approach. Hence, the DPO and the SPO 
approach can be considered as models of the same signature. The interpreta- 
tion of the parallelization condition of Problem 3.2.2.2 in the DPO approach, 
for example, is given by Definition 3.4.2 of sequential independence, and the 
Synthesis Lemma 3.4.9 shows that this interpretation is indeed a solution to 
Problem 3.2.2.2. In a similar way, many of the definitions of Chapter 3 and this 
chapter can be seen as interpretations of the signature of Section 3.2, and the 
corresponding results show that they satisfy the statement of the problems. 
This view allows for two different ways of comparing the two algebraic ap- 
proaches. The first one is w.r.t. to their properties: A property of an approach 
is a statement using the abstract terminology of Section 3.2 that is valid in this 
particular approach. The basic property of the SPO approach, for example, is 
the completeness of its direct derivations, that is, given a match for a produc- 
tion there is always a corresponding direct derivation. DPO direct derivations 
are not complete because of the gluing condition. On the other hand, in the 
DPO approach we have that direct derivations are invertible, which is not true 
in the SPO approach. Summarizing in this way the valid statements leads to a 
nice abstract characterization of the two algebraic approaches in terms of their 
properties. 
It is well-known that models of the same signature can be compared by homo- 
morphisms. In our case the signature of Section 3.2 defines a notion of “homo- 
morphism” between graph rewriting approaches being interpretations of this 
signature. Such a homomorphism is given by mappings between the carriers, 
i.e., productions, matches, derivations, etc., which are compatible with the in- 
terpretation of the operation and predicate symbols, i.e., with the parallel or 
sequential composition of productions, for example. Thereby, it embeds one ap- 
proach in the other approach, which is necessary in order to compare directly 
the concepts of the two approaches. Below we show how the DPO approach 
may be embedded in the SPO approach. This applies not only to the basic con- 
cepts, like productions and direct derivations, but also to the constructions and 
results of the theory, like the parallel production and the parallelism theorem. 

298 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
Beside the direct comparison of corresponding concepts, such an embedding 
can be used in several other ways. On the one hand, we may transfer theoret- 
ical results, concerning for example analysis techniques for graph grammars, 
between the two approaches. On the other hand, it shows that we may simu- 
late the constructions of the DPO approach within the SPO approach, which 
may be quite useful if we aim at a common implementation for the algebraic 
approaches. Finally, if we restrict the SPO approach by suitable application 
conditions (as introduced, for example, in Section 4.4), we may use the idea of 
a homomorphism in order to show the equivalence of the DPO approach and 
the correspondingly restricted SPO approach. 
The section is organized like Section 3.2. In each of the following sections we 
summarize the solutions to the problems of Section 3.2, state the corresponding 
properties of the approaches, and discuss the embedding of the DPO in the 
SPO approach w.r.t. to the concepts of this section. 
4.6.1 
Graphs, Productions, and Derivations 
According to Section 3.2.1 each approach to graph rewriting is distinguished 
by three characteristics: its notion of a graph, the conditions under which a 
production may be applied, and the way the result of such an application is 
constructed. These characteristics define what is called a direct derivation. The 
DPO and SPO approach use the same kind of graphs (see Definition 3.3.1). 
The productions of the two approaches are essentially the same except of dif- 
ferences in the representation: A DPO production L t 
K & R is a span of 
total injective graph morphism (compare Definition 3.3.2). A SPO production 
is instead a partial graph morphism L 
R, i.e., a total graph morphism 
dom(p) -% R from some subgraph dom(p) of L to R (cf. Definitions 4.2.2 and 
4.2.1). Both concepts of production have been extended by a name, which is 
used for identifying the production and for storing its internal structure (in 
case of a composed production). 
1 
Definition 4.6.1 (translation of SPO and DPO productions) 
Let p : ( L  4 R) be a SPO production. Then D(p) : ( L  
dom(r) & R) 
denotes its translation to a DPO production, where 1 is the inclusion of 
dom(s) in L and T is the domain restriction of s to dom(s). Conversely, let 
p : ( L  A K & R) be a DPO production. Then, S ( p )  : ( L  
R) denotes its 
translation to a SPO production, where dom(s) = 1(K) and s = T o 1-l. 
The partial morphism s is well-defined since 1 is supposed to be injective in 
Definition 3.3.2. 

4.6. COMPARISON OF DPO AND SPO APPROACH 
299 
Hence, SPO productions can be considered as DPO productions where the 
interface graph K is represented in a unique way as a subgraph of the left- 
hand side graph L. The mapping S of DPO productions p to SPO productions 
S ( p )  will be used throughout this section to translate the concepts and re- 
sults of the DPO approach to the corresponding ones of the SPO approach. 
The most basic concept of each graph rewriting approach is that of a direct 
derivation. In fact, the mapping S translates each direct DPO derivation to a 
direct SPO derivation where the match is d-injective and d-complete (compare 
Definition 4.2.7). 
Proposition 4.6.2 (translation of DPO derivations) 
Let p : ( L  & K -% R) be a DPO production, S ( p )  : L -+ R its translation 
to a SPO production, and L q 
G a match for p into a graph G. Then m is 
also a match for S ( p )  and there is a direct DPO derivation d = (G % H )  if 
and only if there is a direct SPO derivation S(d) = (G d H )  such that m 
is a d-injective and d-complete match for S ( p ) .  In this way, the mapping S is 
extended from productions to derivations. 
Proof 
Not every direct derivation in the SPO approach can be obtained from a DPO 
derivation using the translation S. In contrast to DPO derivations a direct 
SPO derivation G % H always exists if there is a match m for a production 
p. This first and most important property distinguishing the DPO and the 
SPO approach is called Completeness of direct derivations. Indeed, most of the 
differences between the DPO and the SPO approach are caused by the fact 
that SPO derivations are complete while DPO derivations are not. 
S(P) m 
See [4]. 
0 
Property 4.6.3 (completeness of SPO derivations) 
Direct derivations in the SPO approach are complete, i.e., for each production 
p : L + R and each match L 3 G for p into a graph G there is a direct 
derivation G % H .  
0 
Because of the gluing condition (see Proposition 3.3.4), DPO derivations are 
not complete. In fact, being complete essentially means to be free of any ap- 
plication conditions, that is, SPO derivations with application conditions as 
introduced in Section 4.4 are incomplete as well. The gluing condition, how- 
ever, causes another interesting property of the DPO approach, the invertibility 
of direct derivations. 

300 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
Property 4.6.4 (invertibility of DPO derivations) 
Direct derivations in the DPO approach are invertible, i.e., for each direct 
derivation G 
H using production p : ( L  t 
K -% R) there is an inverse 
derivation H ’==3 G using the inverse production p-l : ( R  & K 4, L ) ,  
where R 3 H is the co-match of G 3 
H .  
Proof 
Constructing the inverse of a direct derivation can be seen as a kind of “un- 
do”. SPO direct derivations are not invertible in general since they may model 
implicit effects, like the deletion of dangling edges, which are not invertible. 
Because of these “side effects”, SPO derivations are more difficult to under- 
stand and to control than DPO derivations and may be considered, in certain 
situations, as “unsafe”. If direct derivations are invertible, there are no implicit 
effects. Hence, DPO derivations show a “safe” behavior that is easier to de- 
termine beforehand. In view of the overall complexity of the formalism, this is 
important if people from other areas shall use graph rewriting techniques for 
modeling their problems. 
Most graph grammar approaches are not dedicated to a particular application 
area but may be considered as “general purpose” formalisms. For many appli- 
cations, however, a tailored approach is more adequate which is as powerful 
as necessary and as simple as possible, in order to allow for a natural mod- 
eling of the problems. Then, standard application conditions like in the DPO 
approach are needed to restrict the expressiveness of the approach if neces- 
sary. Exceptions of these conditions, however, should be possible as well, if 
they are explicitly specified by the user. The graph grammar based specifica- 
tion language PROGRES [43] (see also Chapter 7 in this handbook) provides 
an example of this concept, where e.g. injective matches are standard, but 
identification of vertices may be explicitly allowed. 
It depends on the choice of the standard application conditions and of the 
possible exceptions, which approach is the most adequate one for a particular 
application. A very general solution is provided by user-defined application 
conditions, as introduced in Section 4.4. In particular in the SPO setting they 
complement in a nice way the generality of the pure approach. 
1 
-1 m* 
See [42]. 
0 

4.6. COMPARISON OF DPO AND SPO APPROACH 
301 
4.6.2 Independence and Parallelism 
Interleaving 
The Local Church-Rosser Problem 3.2.1 asked for two conditions formalizing 
the concept of concurrent direct derivations from two different points of view: 
1. Two alternative direct derivations H1 pe 
G pg 
HZ are concurrent if 
they are not in conflict (parallel independence). 
P I  ml 
PZ m; 
2. Two consecutive direct derivations G + H1 & X are concurrent if 
they are not causally dependent, i.e., if there are also direct derivations 
G + Ha & X (sequential independence). 
PZ m z  
PI 
For the DPO approach these conditions are given the Definitions 3.4.1 and 
3.4.2, and the Local Church-Rosser Theorem 3.4.3 ensures that they indeed 
solve Problem 3.2.1. The corresponding solution for the SPO approach is pro- 
vided by the Definitions 4.3.1 and 4.3.3 together with Theorem 4.3.6. 
Both solutions formalize the same intuitive idea. Due to the different represen- 
tation of productions in the DPO and SPO approach, however, the correspond- 
ing conditions are stated in a different way. The following proposition shows 
that they are equivalent via the correspondence of productions and derivations 
established in Definition 4.6.1 and Proposition 4.6.2. 
Proposition 4.6.5 (equivalence of DPO and SPO independence) 
Let pl : (L1 & K1 3 R1) and pa : (La & Ka 3 R2) be two DPO pro- 
ductions, and S(p1) : L1 + R1 and S(p2) : La + Ra their translation to SPO 
productions. Two alternative direct DPO derivations H1 pe 
G '3 
Ha are 
parallel independent in the sense of Definition 3.4.1 if and only if the corre- 
sponding SPO derivations H1 
C-i 
G + H2 are parallel independent 
in the sense of Definition 4.3.1. 
Two consecutive direct DPO derivations G =3 HI & X are sequential 
independent in the sense of Definition 3.4.2 if and only if the corresponding 
SPO derivations G S(pl),ml 
H1 s(p%ma 
X are sequential independent in the 
sense of Definition 4.3.3. 
Proof 
According to Definition 3.4.1 the direct DPO derivations H1 pe 
G p= 
Ha are parallel independent if ml(L1) n mz(L2) C ml(ll(K1)) n m2(12(Kz)). 
Using the translation S to SPO productions (see Definition 4.6.1) this is the 
case iff m l ( L 1 )  n ma(L2) C ml(dom(S(pl)) n m2(dom(S(pz))) 
holds for the 
S(m) 
ml 
S ( P Z )  
mz 
Pl ml 
P2 4 

302 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
S(PI) 
ml 
corresponding SPO derivations. The two direct SPO derivations HI 
ti 
G 
===$ 
H2 are parallel independent if ml(L1) fl 
mz(L2 - dom(S(p2))) = 8 
and mz(L2) n ml(L1 - dom(S(p1))) = 8, which is equivalent to rnl(L1) n 
mz(L2) C dom(S(p2))) and 7m(L2) n ~ I ( L I ( C  
dom(S(p~))), 
and hence to 
ml(L1) n ma(L2) c ml(dom(S(P1)) n m z ( d 4 q P 2 ) ) ) .  
pendence in the DPO and SPO approach. 
S(P2) m2 
In a similar way one shows the equivalence of the notions of sequential inde- 
0 
In Section 3.2.2 independent derivations have been interpreted as to be concur- 
rent in the interleaving model of concurrency. In this view, Proposition 4.6.5 
states that both approaches allow for the same amount of “interleaving paral- 
lelism”. 
Recently, both algebraic approaches came up with a weaker, asymmetric notion 
of independence, ensuring that two alternative direct derivation can at least 
be sequentialized into one order. In the DPO approach this concept has been 
introduced in [44] under the name “serializability” , while in the SPO approach 
we speak of “weak parallel independence” in Definition 4.3.1. In turn, the weak 
notion of sequential independence, introduced in Definition 4.3.3, ensures that 
the second direct derivation does not depend on the first one, that is, they may 
also occur in parallel. 
Explicit Parallelism 
In order to represent parallel computations in a more explicit way, Section 3.2.2 
assumed a parallel composition “+” of productions leading to the notions of 
parallel production and derivation. In the DPO and SPO approaches this op- 
erator is interpreted as the coproduct (disjoint union) of productions, see De- 
finition 3.4.4 f and Definition 4.3.7, respectively. In both approaches, a direct 
parallel derivation is a direct derivation using the parallel production. With 
respect to these definitions, the Parallelism Problem 3.2.2 asked for the rela- 
tionship between parallel and sequential derivations. The basic requirement is, 
of course, that each two direct derivations which are concurrent in the inter- 
leaving model can be put in parallel using the explicit notion of parallelism. 
This property is called completeness of parallel derivations below. On the other 
hand, if explicit parallelism allows for exactly the same amount of concurrency 
as the interleaving model, we say that it is safe (w.r.t. interleaving parallelism). 
In this case, the effect of a parallel derivation can always be obtained by a se- 
quential derivation, too. With the following DPO parallelism properties we 
f In fact, Definition 3.4.4 introduces the parallel composition of an arbitrary, finite number 
of productions. 

4.6. COMPARISON OF DPO AND SPO APPROACH 
303 
summarize the DPO solution to the Parallelism Problem 3.2.2 provided by the 
DPO Parallelism Theorem 3.4.6. 
Property 4.6.6 (parallelism properties of DPO) 
Parallel derivations in the DPO approach satisfy the following completeness 
and safety properties: 
PI mi 
Completeness: Each sequentially independent DPO derivation G + 
~2 ma 
HI i 
X satisfies the parallelization condition, i.e., there is an equiv- 
alent direct parallel DPO derivation G 2 
X .  
Pl+P ,m 
Pi+p m 
Safety: Each direct parallel DPO derivation G ==$ X satisfies the sequen- 
tialization condition, i.e., there are equivalent, sequentially independent 
0 
DPO derivations G 
HI 
Due to the completeness of SPO direct derivations, also its parallel direct 
derivations are complete, i.e., a parallel production L1 -t L2 4 
R1 + Rz 
is applicable to any match L1 + Lz 3 G. Therefore, each two alternative 
direct derivations HI pe 
G '3 
Hz can be composed to a parallel direct 
X ,  regardless of their independence. In particular, 
this allows for the parallel composition of weakly (parallel or sequential) inde- 
pendent direct derivations using the same notion of parallel production. Hence, 
SPO parallel derivations are also complete w.r.t. weakly independent sequential 
derivations, which is shown by the implication from 1. to 2. in the Weak Paral- 
lelism Theorem 4.3.8. Contrastingly, in the DPO approach, a more complex, so 
called synchronized (parallel) composition had to be developed in [44] in order 
to put two serializable (i.e., weakly parallel independent) direct derivations in 
parallel. 
On the other hand, because of its generality, SPO parallelism is no longer 
safe w.r.t. to sequential derivations, neither in the symmetric nor asymmetric 
version. We can, however, distinguish those direct parallel derivations which 
may be sequentialized at least in one order by considering the corresponding 
pair of alternative derivations, which is shown by the implication from 2. to 1. 
in the Weak Parallelism Theorem 4.3.8. 
Finally let us investigate the relationship between DPO and SPO parallelism 
using the translation S introduced in Section 4.6.1. The first important obser- 
vation is, that this translation is compatible with parallel composition, that is, 
given DPO productions p1 and pz, we have that S(p1) + S(p2) = S(p1 +pz)l 
PZ ma 
PI m; 
X and G '3 
Hz =b X. 
P l +  2 
derivation G PI fpz,ml f m 2  
==+ 
9In fact, this is true only up to isomorphism since there are infinitely many isomorphic 
parallel productions for the same two elementary productions. This problem can be solved 

304 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
This gives us the possibility to compare in a more direct way the relationships 
between parallel and sequential derivations in the two approaches. The follow- 
ing proposition states that the mapping S preserves the sequentialization and 
the parallelization conditions and is compatible with the analysis and synthesis 
construction. 
Proposition 4.6.7 (compatibility of S with analysis and synthesis) 
Let d = (G 
X )  be a direct parallel DPO derivation, and p1 = (G ps 
H1 i 
X) and p2 = (G '3 
H2 
X )  its sequentializations. Then 
S(d) = (G 
j 
X) may be sequentialized to S(p1) = (G 
==+ 
H1 
S ( p z ) , m ;  
~ ( P z )  m 
 PI) m' 
Moreover, let p = (G + H1 * X )  be a sequentially independent DPO 
derivation and d = (G 'larn 
X) the direct parallel DPO derivation obtained 
by the synthesis construction. Then S(p) = (G S(p,),ml 
HI S(pz),m; 
X )  is 
sequentially independent, and the corresponding direct parallel SPO derivation 
isS(d) = (G 
X ) .  
Pro0 f 
Let d be the direct parallel DPO derivation above. Then there are parallel 
independent direct derivations H1 'e 
G '3 
H2. According to the analysis 
construction in the DPO approach (cf. Lemma 3.4.8), the match rnl of the 
second direct derivation in p1 is defined by rnl = r; o kl in the diagram below, 
where p; : (G & D1 % HI) is the co-production of G 's 
H1 and k1 
exists by the above parallel independence s.t. subdiagram (1) commutes (cf. 
Definition 3.4.1). 
pi+p ,m 
3 
PZ m; 
PI m: 
S ( m ) + S ( p z ) , m  
S ( P 1 )  m~ 
==+ 
X )  andS(p2) = (G d H2 4 X ) .  
PI ml 
PZ m; 
S ( P l f P z ) , m  
1' 
Now let S(pr) be the translation of p i  to a SPO production (cf. Definition 
4.6.1). Then, mi = T ;  okl = r; o(Z;)-'orn2 = S(p;)orn2 since kl = (Z;)-'om2 
by commutativity of (1) and S(pT) = r; o (Z;)-' 
by Definition 4.6.1. But this 
by assuming a fixed coproduct construction (like, for example, the disjoint union), which 
induces a coproduct functor as shown in Appendix A.l of 3. 

4.6. COMPARISON OF DPO AND SPO APPROACH 
305 
is exactly the definition of the match of the second direct derivation in the 
SPO Weak Parallelism Theorem 4.3.8, i.e., G 
===5 
HI 
X is indeed 
a sequentialization of G 
==+ 
The second part of Proposition 4.6.7 can be shown in a similar way by ex- 
 PI) ml 
S ( p 2 )  4 
S(Pl)+S(PZ),rn x. 
changing m2 and mk. 
4.6.3 
Section 3.2.3 introduced two problems, the Embedding Problem 3.2.3 and the 
Derived Production Problem 3.2.4, and it has been anticipated that the solu- 
tion to the first problem is based on the solution to the second. The Embedding 
Problem asked for a condition under which an embedding of a graph Go via 
a morphism eo : Go + X O  may be extended to a derivation p = (Go '3 
. . . ++ 
G k ) ,  leading to an embedded derivation S = ( X O  
p% 
. . . p% 
X k ) .  
The idea was, to represent the informations relevant for the embedding of p by 
a derived production (p) : Go -+ G, such that there is an embedding p via eo if 
and only if the derived production (p) is applicable at this match. The corre- 
sponding constructions are given in Section 3.6.1 for the DPO approach and in 
Section 4.3.2 for the SPO approach. In both cases, the derived production (p) 
is obtained as the sequential composition (dl); . . . ; ( d k )  of the directly derived 
productions (d,) : G,-1 
y.l G, of the given derivation p. Then, horizontal and 
vertical composition properties of direct derivations ensure that the derived 
production is applicable at a given injective match if and only if the original 
derivation may be embedded along this morphism. This is formulated as the 
derived production property below, see Theorem 3.6.3 and Theorem 4.3.15 for 
corresponding statements in the DPO and SPO approach, respectively. 
Embedding of Derivations and Derived Productions 
P k  m
k
 
Property 4.6.8 (derived production) 
DPO and SPO approach satisfy the derived production property, that is, for 
each derivation p = (Go % ... 3 
G,) and each injection Go 3 X O  there 
is a derived derivation Xo ==+ X ,  using the derived production (p) : Go y.1 G, 
if and only if there is an an embedding e : p -i 
S of p into a derivation 
6 = ( X O  3 . . . 3 
X,) using the original sequence of productions pl , . . . , p,. 
0 
( P )  
The embedding problem is now reduced to the question if the derived pro- 
duction is applicable at the embedding morphism eo. In the DPO approach 
approach this means that a derivation p may be embedded via eo if this match 
satisfies the gluing condition of the derived production (which specializes to 
the dangling condition since eo is supposed to be injective). Since in the SPO 

306 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
approach there are no further conditions for the applicability of a production 
but the existence of a match, the embedding condition is satisfied for each 
derivation Go ’% . . . ’% Gk and each embedding morphism Go -% X O .  
Therefore, we say that the embedding of SPO derivations is complete. 
Property 4.6.9 (completeness of SPO embedding) 
The embedding of derivations in the SPO approach is complete, i.e., for each 
derivation p = (Go ii * Gk) and each embedding morphism eo : 
Go + X o  there is a derivation S = ( X O  ’% . . . p
*
 
X,) and an embedding 
P I  ml . , . p f i , m ~ .  
e : p - + S .  
0 
As anticipated above, the DPO approach is not complete w.r.t. the embedding 
of derivations. 
Finally it is worth stressing that the translation S of productions and deriva- 
tions from the DPO approach to the SPO approach is also compatible with 
the concepts of this section. For DPO productions pl and p2, for example, we 
have that S ( p l ; p a )  = S ( p l ) ; S ( p 2 )  provided that the left-hand side is defined. 
As a consequence, we may show that S is compatible with the construction of 
derived productions, i.e., given a DPO derivation p we have S((p)) = (S(p)). 
4.6.4 
Amalgamation and Distribution 
The concepts of amalgamated and distributed derivations are informally intro- 
duced in Section 3.2.4. Their formalization in the DPO approach is given in 
Section 3.6.2, while the SPO variants are introduced in Section 4.3.3. The main 
idea is more or less the same for both approaches: Synchronization of produc- 
tions pl and pa is modeled by a common subproduction po, i.e., a production 
that is related to the elementary productions by compatible embeddings. The 
application of two synchronized productions (to a global state) is modeled by 
applying their amalgamated production, that is, the gluing of the elementary 
productions along their common subproduction. 
A distributed graph DG = (GI & Go 3 G2) models a state that is splitted 
into two local substates, related by a common interface state. Gluing the local 
graphs GI and G2 along their interface Go yields the global graph @DG = 
GI $G,, G2 of the system. The local states are consistent (with each other) if 
they form a total splitting of the global graph, i.e., if the interface embeddings 
g1 and 92 are total. The transformation of a distributed graph DG = (G1 & 
Go 3 G2) is done by local direct derivations di = (Gi 2 
Hi) for i E 
{0,1,2} where pl t 
po -+ p2 are synchronized productions and mi : Li + Gi 
are compatible matches for pi into the two local graphs and the interface graph. 
p .  m -  
in’ 
in2 

4.6. COMPARISON OF DPO AND SPO APPROACH 
307 
A distributed derivation is synchronous if the given and the derived distributed 
graphs are total splittings. 
Distributed derivations in the DPO approach are synchronous by definition. 
The distributed gluing condition, which is used as a standard application con- 
dition for distributed derivations, ensures that no element in a local graph is 
deleted as long as it is referenced from the interface graph. This ensures that 
the derived distributed graph is again a total splitting. Hence, in the DPO 
approach, distributed derivations show the same safe behavior like 
direct derivations. The prize we have to pay is a global application condition, 
which may not be easy to check in a real distributed system. 
A distributed derivation in the SPO approach always exists if there are com- 
patible matches for synchronized productions in a distributed graph. Hence, 
also in the SPO approach, the basic property of direct derivations (i.e., their 
completeness) is resembled by distributed derivations. In contrast to the DPO 
approach, a distributed SPO derivation needs no global application conditions. 
However, it may cause global effects: Deleting a vert,ex in a local graph which 
is referenced from other local components leads to partial interface embed- 
dings. Constructing the corresponding global graph all dangling references are 
deleted. It depends very much on the problem to be solved, whether global con- 
ditions or global effects (i.e., DPO or SPO distributed derivations) are more 
appropriate. Relying on the distributed gluing condition certainly leads to a 
more abstract specification, which assumes that dangling references are avoided 
by some standard mechanism on a lower level. However, if the references itself 
are subject of the specification, as e.g. for garbage collection in distributed 
systems, we need to model explicitly the inconsistencies caused by the deletion 
of referenced items. 
These observations are also reflected in the solutions to the Distribution Prob- 
lem 3.2.5. In the DPO approach, each distributed derivation satisfies the amal- 
gamation condition, which means that each distributed computation can be 
observed from a global point of view. Vice versa, an amalgamated derivation 
can be distributed if its match can be splitted according to the splitting of the 
given graph and if this splitting satisfies the distributed gluing condition, see 
Theorem 3.6.5. In the SPO approach, a distributed derivation may be amalga- 
mated if at least the given distributed graph represents a consistent state. The 
distribution of an amalgamated derivation, on the other hand, requires only the 
existence of compatible matches. We do not state the corresponding properties 
here but refer to Theorem 3.6.5 for the DPO approach and Theorem 4.3.22 for 
the SPO approach. 

308 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
4.7 
Conclusion 
In Chapter 3 and this chapter we have presented the two algebraic approaches 
and compared them with each other. The double-pushout (DPO) approach was 
historically the first and has a built-in application condition, called the gluing 
condition, which is important in several application areas in order to prevent 
undesirable possibilities for the application of productions. The single-pushout 
(SPO) approach allows to apply productions without any application condi- 
tions, because the problem of dangling edges, for example, is solved by deletion 
of these edges. This is adequate in some application areas and problematic in 
other ones. In general it seems to be important to allow user-defined applica- 
tion conditions for productions in order to prevent application of productions 
in undesirable cases. In this chapter it is shown how to extend the SPO ap- 
proach to handle such user-defined application conditions, and in a similar way 
the DPO approach could be extended. 
In fact, the DPO approach could be considered as a special case of the SPO 
approach, because the SPO approach with gluing condition is equivalent to 
the DPO approach. However, as shown in the comparison of both approaches, 
they provide different solutions to the general problems stated in Section 3.2 
of Chapter 3. Moreover, it does not seem adequate to specialize all the results 
in the SPO approach to the case with gluing condition, because the explicit 
proofs in the DPO approach are much simpler in several cases. For this reason 
DPO and SPO should be considered as two different graph transformation 
approaches within the context of this handbook. 
Finally, let us point out that most of the concepts and results presented in 
Chapter 3 and this chapter are concerned with a single graph transformation 
system. This might be called the “theory of graph transformation systems 
in the small” in contrast to structuring and refinement concepts combining 
and relating different graph transformation systems which may form a “theory 
of graph transformation systems in the large”. The “theory in the large” is 
especially important if graph transformation concepts are used for the specifi- 
cation of concurrent, object oriented and/or distributed systems. In fact, both 
algebraic approaches seem to be most suitable to handle such “problems in 
the large”, and first attempts and results have been presented within the last 
couple of years (see [45,46,47,48,49]). Moreover, we believe that graph trans- 
formation in the large will be a main topic of research and development in the 
future. 

REFERENCES 
309 
Acknowledgment The research results presented in this paper have been 
obtained within the ESPRIT Working Groups COMPUGRAPH (1989-1992) 
and COMPUGRAPH 2 (1992-1995). We are most grateful to Raoult and Ken- 
naway for initial motivation of the single pushout approach and to the members 
of the working group for their contributions and stimulating discussions. 
References 
1. H. Ehrig, M. Pfender, and H. J. Schneider. Graph grammars: an algebraic 
approach. In 14th Annual IEEE Symposium on Switching and Automata 
Theory, pages 167-180, 1973. 
2. A. Habel, R. Heckel, and G. Taentzer. Graph grammars with negative 
application conditions. Accepted for special issue of Fundamenta Infor- 
maticae, 1996. 
3. M. Lowe, M. Korff, and A. Wagner. An algebraic framework for the 
transformation of attributed graphs. In M.R. Sleep, M.J. Plasmeijer, and 
M.C. van Eekelen, editors, Term Graph Rewriting: Theory and Practice, 
chapter 14, pages 185-199. John Wiley & Sons Ltd, 1993. 
4. M. Lowe. Algebraic approach to single-pushout graph transformation. 
5. M. Korff. Single pushout transformations of generalized graph structures. 
Technical Report RP 220, Federal University of Rio Grande do Sul, Porto 
Alegre, Brazil, 1993. 
6. H. Ehrig and M. Lowe. Categorical principles, techniques and results for 
high-level replacement systems in computer science. Applied Categorical 
Structures, 1(1):21-50, 1993. 
7. M. Lowe. Extended Algebraic Graph Transformations. PhD thesis, Tech- 
nical University of Berlin, 1990. short version in TCS (109):181 - 224. 
8. J. C. Raoult. On graph rewriting. Theoretical Computer Science, 32:l-24, 
1984. 
9. R. Kennaway. On “On graph rewriting”. Theoretical Computer Science, 
10. J. Glauert, R. Kennaway, and R. Sleep. A categorical construction for 
generalised graph rewriting. Technical report , School of Information Sys- 
tems, University of East Anglia, Norwich NR4 7TJ, U.K., 1989. 
11. R. Kennaway. Graph rewriting in some categories of partial maps. In 
Ehrig et al. [50], pages 475-489. Lecture Notes in Computer Science 532. 
12. E. Robinson and G. Rosolino. Categories of partial maps. Information 
and Computation, 79:95 - 130, 1988. 
TCS, 109:181-224, 1993. 
52:37-58, 1987. 

310 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
13. P.M. van den Broek. Algebraic graph rewriting using a single pushout. 
In Int. Joint Conf. on Theory and Practice of Software Development 
(TAPSOFT'SI), LNCS 493, pages 90-102. Springer Verlag, 1991. 
14. H. Herrlich and G. Strecker. Category Theory. Allyn and Bacon, Rock- 
leigh, New Jersey, 1973. 
15. M. Lowe and J. Dingel. Parallelism in single-pushout graph rewriting. 
Lecture Notes in Computer Science 776, pages 234-247, 1994. 
16. M. Korff. Generalized graph structure grammars with applications to 
concurrent object-oriented systems. PhD thesis, Technical University of 
Berlin, 1995. 
17. M. Korff. Minimality of derived rules in single pushout graph rewriting. 
Technical Report 94/ 10, Technical University of Berlin, 1994. 
18. G. Taentzer. Towards synchronous and asynchronous graph transforma- 
tions. Accepted for special issue of Fundamenta Informaticae, 1996. 
19. H. Ehrig and M. Lowe. Parallel and distributed derivations in the single 
pushout approach. Theoretical Computer Science, 109:123 - 143, 1993. 
Also in Tech. Rep. 91/01, Technical University of Berlin. 
20. H. Ehrig and B. K. Rosen. Parallelism and concurrency of graph manip- 
ulations. Theoretical Computer Science, 11:247-275, 1980. 
21. P. Bohm, H.-R. Fonio, and A. Habel. Amalgamation of graph transfor- 
mations: a synchronization mechanism. Journal of Computer and System 
Science, 34:377-408, 1987. 
22. G. Taentzer. Hierarchically distributed graph transformation. In 5th Int. 
Workshop on Graph Grammars and their Application to Computer Sci- 
ence, Williamsburg '94, LNCS , 1996. Accepted. 
23. G. Taentzer. Parallel and Distributed Graph Transformation: Formal De- 
scription and Application to Communication-Based Systems. PhD thesis, 
Technical University of Berlin, Dep. of Comp. Sci., 1996. 
24. R. Heckel. Embedding of conditional graph transformations. In G. Va- 
liente Feruglio and F. Rosello Llompart, editors, Proc. Colloquium on 
Graph Transformation and its Application an Computer Science. Techni- 
cal Report B-19, Universitat de les Illes Balears, 1995. 
25. R. Heckel. Algebraic graph transformations with application conditions. 
Master's thesis, TU-Berlin, 1995. 
26. A. Wagner. On the expressive power of algebraic graph grammars with 
application conditions. In Int. Joint Conf. on Theory and Practice 
of Software Development (TAPSOFT'95), LNCS 915. Springer Verlag, 
1995. 
27. R. Heckel and A. Wagner. Ensuring consistency of conditional graph 
grammars - a constructive approach. Proc. of SEGRAGRA '95 "Graph 
Rewriting and Computation", Electronic Notes of TCS, 2, 1995. 
http://www.elsevier.nl/locate/entcs . 

REFERENCES 
311 
28. M. Korff. Graph-interpreted graph transformations for concurrent object- 
oriented systems. Extended abstract for the 5th International Workshop 
on Graph Grammars and their Application to Computer Science, 1994. 
29. K. Raiha. Bibliography of attribute grammars. SIGPLAN Notices, 
30. C. Dimitrovici, U. Hummert, and L. Petrucci. Composition and net prop- 
erties of algebraic high-level nets. In Advances of Petri Nets, volume 483 
of Lecture Notes in Computer Science. Springer Verlag Berlin, 1991. 
31. W. Reisig. Petri nets and algebraic specifications. Theoretical Computer 
Science, 8O:l-34, 1991. 
32. H. Ehrig, J. Padberg, and L. Ribeiro. Algebraic high-level nets: Petri 
nets revisited. In Recent Trends in Data Type Specification, pages 188- 
206, Caldes de Malavella, Spain, 1994. Springer Verlag. Lecture Notes in 
Computer Science 785. 
33. ISO. Information processing systems ~~ Open Systems Interconnection - 
LOTOS - A formal description technique based on the temporal ordering 
of observational behaviour. International Standard IS0 8807, ISO, 1989. 
34. G. Schied. Uber Graphgrammatiken, eine Spezifikationsmethode fur Pro- 
grammiersprachen und verteilte Regelsysteme. Arbeitsberichte des Insti- 
tus fur mathematische Maschinen und Datenverarbeitung (Informatik), 
University of Erlangen, 1992. 
35. H. Ehrig and B. Mahr. Fundamentals of Algebraic Specification 1: Equa- 
tions and Initial Semantics, volume 6 of EATCS Monographs on Theo- 
retical Computer Science. Springer, Berlin, 1985. 
36. M. Korff. True concurrency semantics for single pushout graph trans- 
formations with applications to actor systems. In Working papers of 
the International Workshop on Information Systems - Corretness and 
Reusability IS-CORE’94, pages 244-258,1994. Tech. Report IR-357, Free 
University, Amsterdam. 
37. A. Habel and H.-J. Kreowski. May we introduce to you: Hyperedge re- 
placement. In 3rd Int. Workshop on Graph Grammars and their Appli- 
cation to Computer Science, LNCS 291, Berlin, 1987. Springer Verlag. 
38. A. Habel. Hyperedge Replacement: Grammars and Languages. PhD the- 
sis, University of Bremen, 1989. 
39. A. Habel. Hyperedge replacement: Grammars and Languages, volume 643 
of LNCS. Springer Verlag, Berlin, 1992. 
40. H. Ehrig, A. Habel, H.-J. Kreowski, and F. Parisi-Presicce. From graph 
grammars to High Level Replacement Systems. In Ehrig et al. [50], pages 
269-291. Lecture Notes in Computer Science 532. 
15(3):35-44, 1980. 

312 
CHAPTER 4. SINGLE PUSHOUT APPROACH 
41. F. Parisi-Presicce. Modular system design applying graph grammar tech- 
niques. In ICALP'89. Springer Lecture Notes in Computer Science, 1989. 
42. H. Ehrig. Introduction to the algebraic theory of graph grammars. In 
V. Claus, H. Ehrig, and G. Rozenberg, editors, 1st Graph Grammar 
Workshop, Lecture Notes in Computer Science 73, pages 1-69. Springer 
Verlag, 1979. 
43. A. Schiirr. Progress: A vhl-language based on graph grammars. In 
LNCS532. Springer, 1991. 
44. A. Corradini and F. Rossi. Synchronized composition of graph grammar 
productions. In 5th Int. Workshop on Graph Grammars and their Appli- 
cation to Computer Science, Williamsburg '94, LNCS , 1996. Accepted. 
45. H.-J. Kreowski and S. Kuske. On the interleaving semantics of trans- 
formation units - a step into GRACE. In 5th Int. Workshop on Graph 
Grammars and their Application to Computer Science, Williamsburg '94, 
LNCS , 1996. Accepted. 
46. H. Ehrig and G. Engels. Pragmatic and semantic aspects of a module con- 
cept for graph transformation systems. In 5th Int. Workshop on Graph 
Grammars and their Application to Computer Science, Williamsburg '94, 
LNCS , 1996. Accepted. 
47. G. Taentzer and A. Schiirr. DIEGO, another step towards a mod- 
ule concept for graph transformation systems. Proc. of SEGRAGRA '95 
"Graph Rewriting and Computation ", Electronic Notes of TCS, 2, 1995. 
http://www.elsevier.nl/locate/entcs . 
48. F. Parisi-Presicce. Transformation of graph grammars. In 5th Int. Work- 
shop on Graph Grammars and their Application to Computer Science, 
Williamsburg '94, LNCS , 1996. Accepted. 
49. R. Heckel, A. Corradini, H. Ehrig, and M. Lowe. Horizontal and vertical 
structuring of typed graph transformation systems. Accepted for special 
issue of MSCS, 1996. 
50. H. Ehrig, H.4. Kreowski, and G. Rozenberg, editors. 4th International 
Workshop on Graph Grammars and Their Application to Computer Sci- 
ence. Springer Verlag, 1991. Lecture Notes in Computer Science 532. 

Chapter 5 
THE EXPRESSION OF GRAPH 
PROPERTIES AND GRAPH 
TRANSFORMATIONS IN MONADIC 
SECOND-ORDER LOGIC 
B. COURCELLE 
LABRI (URA CNRS 1304), Bordeaux I University 
351, Cours de la Libe'ration, 33405 Talence - France 
e-mail: courcell@labri.u- bordeaux. fr 
By considering graphs as logical structures, one can express formally their prop- 
erties by logical formulas. We review the use of monadic second-order logic for 
expressing graph properties, and also, graph transformations. We review the inti- 
mate relationships of monadic second-order logic and context-free graph grammars. 
We also discuss the definition of classes of graphs by forbidden configurations. 
Contents 
5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . .  
315 
5.2 Relational structures and logical languages . . . .  317 
5.3 Representations of partial orders, graphs and hy- 
pergraphs by relational structures . . . . . . . . . .  334 
5.4 The expressive powers of monadic-second order 
languages . . . . . . . . . . . . . . . . . . . . . . . . . .  340 
5.5 Monadic second-order definable transductions . . 346 
5.6 Equational sets of graphs and hypergraphs . . . .  356 
5.7 Inductive computations and recognizability . . . .  372 
5.8 Forbidden configurations . . . . . . . . . . . . . . . .  390 
References . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
397 
313 


5.1. INTRODUCTION 
315 
5.1 Introduction 
By considering graphs as logical structures] one can express formally their prop- 
erties by logical formulas. One can thus describe classes of graphs by formulas 
of appropriate logical languages expressing characteristic properties. There are 
two main motivations for doing this: the first one, originating from the work by 
Fagin [37], consists in giving logical characterizations of complexity classes; the 
second one consists in using logical formulas as finite devices, comparable to 
grammars or automata] to specify classes of graphs and to establish properties 
of such classes from their logical descriptions. 
We shall only consider here the second of these motivations. The ideal language 
is in this respect monadic second-order logic, as we shall demonstrate. It is 
crucial for establishing L‘easilyll results like this one: 
the set of planar graphs belonging to a HR set of graph9 is HR, 
or this one: 
the set of Hamiltonian graphs belonging to a HR set of graphs is HR, 
by essentially the same proof, using the fact that planarity and Hamiltonicity 
can both be described by MS (Monadic Second-order) formulas. These two re- 
sults do not concern logic, but their proofs use logic as a tool. The deep reason 
why MS logic is so crucial is that it replaces for graphs (and for the development 
of the theory of context-free graph grammars) the notion of a fipite automaton 
which is very important in the theory of formal languages. It “replaces” be- 
cause no convenient notion of finite automaton is known for graphs. The notion 
of a transformation from words or trees to words or trees is also essential in 
language theory (Berstel [4], Raoult [52]). These transformations are usually 
defined in terms of finite automata] that produce an output while traversing 
the given word or tree. Since we have no notion of finite graph automaton] 
we cannot define graph transformations in terms of automata. However, we 
can define such transformations in terms of MS-formulas. We call them defin- 
able transductions. “Definable” refers to logic and LLtransduction’l to the way 
transformations of words and trees are usually named. 
MS logic is thus an essential notion in the extension of formal language theory 
to graphs, hypergraphs and related structures. Another important notion is 
that of a graph (or hypergraph) operation. By using it, one can define context- 
free sets of graphs as components of least solutions of systems of equations 
aA HR set of graphs is a set of finite graphs generated by a Hyperedge Replacement graph 
grammar 

316 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
(without using any graph rewriting rule) and recognizable sets of graphs (with- 
out using any notion of graph automaton). Context-free and recognizable sets 
can thus be defined and investigated in the general framework of Universal 
Algebra. They instanciate immediately to graphs and hypergraphs of all kinds 
as soon as appropriate operations on these structures are defined. Furthermore 
the notion of recognizability establishes the link between Logic and Universal 
Algebra because every MS-definable set of graphs is recognizable: this result 
extends the result by Buchi saying that every MS-definable set of finite words 
is a regular language. 
This chapter is organized as follows. Section 5.2 reviews relational structures, 
first-order logic, second-order logic and monadic second-order logic. Some basic 
lemmas helping in the construction of logical formulas are proved. Section 5.3 
introduces several possible representations of graphs, hypergraphs and partial 
orders by relational structures, and discusses how the choice of a represen- 
tation affects the expressive power of the three considered logical languages. 
Section 5.4 discusses the expressibility in MS logic of the finiteness of a set 
and of the parity of its cardinality when it is finite. Section 5.5 introduces 
definable transductions, reviews their basic properties and their application to 
the comparison of the different relational structures representing partial or- 
ders, graphs and hypergraphs reviewed in Section 5.3. Section 5.6 defines the 
hyperedge replacement (HR) hypergraph grammars and the vertex replace- 
ment (VR) graph grammars, in terms of systems of recursive set equations, 
by means of appropriate operations on hypergraphs and graphs respectively. 
Logical characterizations of the HR sets of hypergraphs and of the VR sets 
of graphs in terms of definable transductions are also given. These charac- 
terizations yield the stability of the corresponding classes under the relevant 
definable transductions. Section 5.7 introduces the recognizability of sets of 
graphs and hypergraphs. This notion is based on finite congruences relative to 
the operations on graphs and hypergraphs introduced in Section 5.6. In gen- 
eral, the intersection of an equational and a recognizable set is an equational 
set. (An instance of this result is the fact that the intersection of a context-free 
language and a regular one is context-free). The major result of this section 
says that a monadic second-order definable set of graphs or hypergraphs is 
recognizable. This result yields in particular the two results mentioned at the 
beginning of the introduction concerning HR sets of graphs, planarity and 
Hamiltonicity. Section 5.8 deals with the logical aspect of the definition of sets 
of graphs by forbidden minors. Kuratowski’s Theorem stating that a graph is 
planar iff it does not contain any of the two graphs K5 and K3,3 as a minor is 
a well-known example of such a definition. By using deep results by Robertson 
and Seymour, we relate definitions by forbidden minors with definitions by MS 
formulas and/or by KR grammars. 

5.2. RELATIONAL STRUCTURES AND LOGICAL LANGUAGES 
317 
5.2 Relational structures and logical languages 
In order to express graph properties by logical formulas, we shall represent 
graphs by relational structures, i.e., by logical structures with relations only 
(without functions). We shall review first-order logic, second-order logic and 
monadic second-order logic, which is an extension of the former and a fragment 
of the latter. We shall review some basic tools that will help in the construction 
of formulas in forthcoming sections. 
5.2.1 Structures 
Let R be a finite set of relation symbols. Each symbol R E R has an associated 
positive integer called its arity, denoted by p(R). An R-structure is a tuple 
S =< Ds, ( R s ) R ~ R  > such that Ds is a possibly empty set called the domain 
of S and each Rs is a p(R)-ary relation on Ds, i.e., a subset of Dg(R). We 
shall say that “R(dl;.. ,dn) holds in S” iff ( d l , . . .  ,d,) 
E Rs, where, of 
course, dl ,. . . , d, E Ds. We shall denote by STR(R) the class of R-structures. 
Structures may have infinite domains. 
We give two examples of the use of structures. A word u in A* is usually defined 
as a sequence of letters from A, equivalently as a mapping { 1,. . . , n} + A 
for some n E N (with n = 0 for the empty word). In order to represents 
words by relational structures we let R U , ~  
:= {suc, lab,, . . . , labd} where A = 
{ a , . . .  , d }  ( A  can have more than 4 letters), suc is binary and lab,,..- ,labd 
are unary. For every word u E A*, we let 11 u 
11 E STR(R,,A) be the structure 
S such that: 
DS 
= 8 
if u is the empty word E ;  
sucs 
= 
{(112),(2,3),..- 
,(n - l,n)}; 
i E lab,s 
otherwise Ds = (1;’. ,n} if u has length n; 
iffy is the i-th letter of u. 
In order to represent graphs by relational structures, we let R, = {edg} where 
edg is binary. With a directed graph G, we associate the R,-structure I G 11 
= < V ~ , e d g ~  
> where VG is the set of vertices of G (and the domain of 
I G 11) 
and (z,y) E edgG iff there is in G an edge from z to y. We do the 
same if G is undirected and we let (z,y) E edgG iff there is in G an edge 
linking z and y: it follows that edgG is in this case symmetric. The structure 
1 G 11 does not contain information concerning the multiplicity of edges. It is 
thus appropriate to represent simple graphs only because two simple graphs G 
and G’ are isomorphic iff the structures I G 11 and 1 G’ 11 are isomorphic. (In 
Section 5.3, we shall define another representation, denoted by I G 12, which will 

318 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
be appropriate for graphs with multiple edges). For directed graphs, we shall 
sometimes use suc instead of edg. We call y a successor of z if (2, y) 6 SUCG. 
Relational structures form the basis of the theory of relational databases 
(Abiteboul et al. [l]). More precisely, a finite R-structure S can be considered 
as a state of a relational database describing relations between the objects of 
Ds. The relations R s  for R E R are the various relations of the database. A 
finite structure S is represented by means of some coding of the objects of DS 
and for each R E R a list of p(R)-tuples of “codes” of the elements of Ds. The 
study of query languages for relational databases has also been a motivation 
for finite model theory. (See the survey by Kannellakis [46] and the book by 
Abiteboul et al. [l]). 
5.2.2 
Farst-order logic 
We let X be a countable alphabet of lowercase letters called individual vari- 
ables. Let R be a finite set of relation symbols. The atomic formulas are 
x =  y,R(xl,... , x n ) f o r x , y , z l , . . .  ,z, E X,R~R,n=p(R).Thefirst-order 
formulas are formed from atomic formulas with the propositional connectives 
A, V, 7 ,  +, @, and quantifications 32, Vx (for x E X). 
We shall denote by FO(R, y ) where J’ & X the set of first-order formulas 
over R with free variables in y .  In order to specify the free variables that 
may occur in a formula cp we shall write it cp(xl,... ,xn) if cp E FO(R, 
(21, . . , x,}). (Some variables in (z1, 
. . . , z,} 
may have no free occurrence 
in cp). If p(x1,. . . , z,) 
is a first-order formula over R, if S E STR(R), and if 
d l , . . .  ,d, E Ds, we write S 
cp to mean 
that cp is true in S if xi is given the value di for i = 1, . . . , n. If cp has no free 
variables, i.e., if it is closed, then it describes a property of S and not of tuples 
of elements of S. Here is an example. The formula cp(x) over R, defined as: 
cp(dl,... ,d,) or ( S , d l , . . .  ,d,) 
Vyi, ~
2
,
 
~ 3 [ e d g ( z ,  
YI) A e d d z ,  YZ) A e&(x, ~
3
)
 * YI = ~2 V YI 1 
~3 V ~2 = ~ 3 1  
expresses that the vertex z of the represented graph has out-degree at most 
2. The closed formula Vz.cp(z) expresses thus that the considered graph has 
outdegree at most 2. 
We now give an example concerning words. We let A = {a, b, c}. The formula 
0 below is constructed in such a way that, for every word u E A*: 
Here is 6: 
11 u 11 
0 iff u E ab*c. 
3x[laba(x) AV’y(lsuc(y, .))I 
Avx[laba(x) * gY(~~c(z, 
9) A (lab(?/) vlabc(Y)))] 

5.2. RELATIONAL STRUCTURES AND LOGICAL LANGUAGES 
319 
Av'z[lUbb(Z) =+ 
3 Y ( S U C ( Z , Y )  A (lUbb(y) v l~b,-(y)))] 
A v Z [ [ l U b , ( X )  + 
vY(-Uc(z, Y ) ) l .  
Let us remark that 0 has models that are not representations of words. So, 
0 characterizes abfc as a subset of A*; it does not characterize the structures 
representing the words of ub*c among those of STR(R,,A). The languages 
characterized in this way by a first-order formula form a subclass of the class 
of regular languages, called the class of locally threshold testable languages 
(see Thomas [61] or the survey by Pin [50]). 
5.2.3 Second-order logic 
We now let X contain individual variables as in Subsection 5.2.2 and also re- 
lation variables, denoted by uppercase letters, X ,  Y, X I ,  . . . , X,. Each relation 
variable has an arity which is a positive integer ( p ( X )  is the arity of X ) .  We let 
R be a finite set of relation symbols and we now define the second-order for- 
mulas over R. The atomic formulas are: x = y, R(x1,. . . , xn), X ( z 1 , .  . . , xn), 
where z, y, 2 1 , .  . . , z,, 
X E X ,  R E R and n = p(R) = p ( X ) .  The formulas are 
constructed from the atomic formulas with the propositional connectives (as in 
Subsection 5.2.2) and the quantifications 32, Vx, 3X, VX over individual and 
relation variables. (We do not give a formal syntax; see the examples below). 
We shall denote by SO(R,Y) the set of second-order formulas over R with 
free variables in y .  The notation 'p(x, y, z ,  X I , .  . . , X,) indicates that the free 
variables of cp belong to {x, y, z ,  X I , .  . . , X,}. 
Consider a formula 'p(x1,. . . , x,, X I ,  . . . , Xn). If S E STR(R) if d l , .  . . , d, E 
Ds, if El,. . . , En are relations on DS of respective arities p(X1), . . . , p(X,) 
then the notation S 
cp(d1, . . . , d,, 
El, . . . , En) means that 'p is true in S for 
the values dl , . . . , d, of x1, . . . , x, and E l ,  . . . , En of X I ,  . . . , X ,  respectively. 
Let Y = (x1 , . . . , x,, X I ,  . . . , X,}. A y-assignment in S is a mapping y with 
domain y such that y(xi) E DS for i = 1;'. ,m and y ( X j )  is a p(Xj)-ary 
relation on DS for each j = 1, . . . , n. We shall also use the notation (S, y) 
'p 
instead of S 
We now give some examples. Let p ( X )  be the formula in SO(0, {X}): 
'p(d1,. . . , d,, 
E l , .  . . ,En) where y(xi) = di and y(X,) = Ej. 
vx, 
y, .[X(x, Y) A X(x, z )  ===+ 
Y = 4 A vx, Y, z[X(x, 2 )  A X ( Y ,  .) ===+ 
x = Y1, 
where X is binary. It expresses that X is a functional relation, and that the 
corresponding function is injective on its domain. (This domain may be strictly 
included in the domain of the considered structure). Hence the following for- 
mula a ( X )  of SO(R,,{X}) expresses that X is an automorphism of a simple 
graph G represented by the structure lGl1 in STR(R,). Here is a ( X ) :  

320 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
3 X [ a ( X )  A 32, 
y(1. 
1 
Y A X ( z ,  y))]. 
Consider now the formula y(Y1, Y2) E SO(@, 
{YI, Yz}): 
3 x [ P ( X )  A vx(yi(z) s 
3YX(x, Y)) A vx(y2(z) * 
3YX(Y, .))I. 
It expresses that there exists a bijection (namely the binary relation defined 
by X )  between the sets Yl,Y, (handled as unary relations). One can thus 
characterize by the following second-order formula the nonregular language 
{ a " P / n  2 l}: 
3z[lab,(z)AVy(lS.uc(y, .))I 
Avx[laba(z) * 
3 Y  ( S u C ( z ,  Y) A (labs(!/) Vlabb(y)))] 
AVz, Y[labb(z) A S U C ( ~ ,  
y) =+ labb(y)]A 
% ,  Y,[y(yi, y2) A vx[laba(x) 
y1 (x)] 
A vx[labb(z) 
y2(z)]]- 
The main logical language to be used in this paper is monadic second-order 
logic which lies inbetween first-order and second-order logic. 
5.2.4 
Monadic second-order logic 
Let R be a finite set of relation symbols. Let X contain individual variables and 
relation variables of arity one. Since a relation with one argument is nothing 
but a set, we shall call these variables set variables. A monadic second-order 
formula over R is a second-order formula written with R and X :  the quantified 
and free variables are individual or sets variables; there is no restriction on the 
arity of the symbols in R. In order to get more readable formulas, we shall write 
2 E X instead of X ( x )  where X is a set variable. We denote by M S ( R , Y )  
the set of monadic second-order formulas (MS formulas for short) over R, with 
free variables in Y .  
We give some examples. The MS formula S E MS((suc},@) below expresses 
that a word in A' has an odd length. Since this property does not depend on 
the letters, the formula 6 does not use the relations lab,, z E A. Here is 6: 

5.2. RELATIONAL STRUCTURES AND LOGICAL LANGUAGES 
321 
where b'(X, Y )  is 
Vx, y(x E Y A suc(x,g) * 
g E x). 
For every word w E A* , there is a unique pair X ,  Y with X ,  Y C Dllwll satisfying 
6': the elements of X are the odd rank positions in w and the elements of Y 
are the even rank ones. The formula 6 expresses that the last position is odd, 
i.e., that the considered word has odd length. A theorem by Biichi and Elgot 
[8], [30] (see Thomas [60], Thm 3.2) says that the languages defined by MS 
formulas are exactly the regular languages. 
We now consider an example concerning graphs. The following formula 73 E 
M S ( { R , } )  expresses that the considered graph is 3-vertex colorable (with 
every two adjacent vertices of different colors; one may have loops). Here is 73: 
~X~,X~,X~[VZ(Z 
E xi V Z  E X2 V Z  E X3) 
AVZ(X E Xi 
* 
7~ E Xa A 7% E X3) 
At/z(z E X2 =$ 7~ E Xi A
~
x
 
E X,) A'd'z(z E X3 ==+ 7 Z  E Xi A 7 x  E x,) 
AVx, y(edg(x, y) A 
= Y 
=+ ~
(
x
 
E xi A y E X i )  A T(Z E X2 A y E X,) A l ( x  E X3 A 51 E X3))] 
A triple of sets X1, Xa, X3 satisfying this condition is a partition of the set 
of vertices. Considering i such that x E X i  as the color of 5, the formula 
expresses that adjacent vertices have different colors. For each positive integer 
k ,  one can write a similar formula Tk expressing that the considered graph is 
k-vertex colorable. 
Let L be any of the languages FO, M S  and SO. We write L ( R )  for L ( R ,  0). A 
property P of structures in STR(R) is L-expressible iff there exists a formula 
cp in L ( R )  such that, for every structure S E STR(R),P(S) holds iff S + cp. A 
class of structures C is L - definable iff it is the class of structures satisfying 
an L - definable property. These definitions can be relativized to specific 
classes of structures. Let 7 
S T R ( R ) .  Then, a property P of structures 
in 7 is L - expressible iff there exists a formula cp in L ( R )  such that, for 
every S in 7, P ( S )  holds iff S 
cp. One obtains similarly the notion of a 
subclass C of 7 that is L-de finable with respect to 7. A property P of tuples 
( d l , .  . . , d,, El,. . . , Em) in the structures S of a class 7 is L - expressible 
iff there exists a formula cp E L ( R ,  {XI,... ,x,,X1, ... ,X,}) such that for 

322 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
all S E 7, all (dl ,.. . , d,, E l , . .  . , Em) of appropriate type, P(S, dl ,.. . , Em) 
holds iff S 
One obtains thus a hierarchy of graph properties linked with the hierarchy 
of languages: FO C MS c SO. In Sections 5.3 and 5.4, we shall introduce 
intermediate languages between M S  and SO and discuss the strictness of the 
corresponding hierarchy of graph properties, relativized to various classes of 
graphs or related objects like words, partial orders and hypergraphs. The lan- 
guages defined by monadic second-order formulas are the regular languages by 
a theorem of [8] (see also the survey by Pin [50]). 
cp(d1, ..., Em). 
5.2.5 Decidability questions 
Let R be a finite set of relation symbols. Let C be a class of closed formulas 
expressing properties of the structures in STR(R). Let C 
STR(R). The 
C - theory of C is the set: 
T ~ E ( C )  
:= {'p E L / S  b 'p for every S E C } .  
We say that the L-theory of C is decidable if this set is recursive. The C- 
satisfiability problem for C is the problem of deciding whether a given formula 
belongs to the set 
S a t ~ ( c )  
:= {'p E C/ S 
cp for some S E C } .  
If C is closed under negation, the C-theory of C is decidable iff its C-satisfiability 
problem is decidable. We shall consider some conditions on a class of graphs C 
ensuring that its monadic theory (i.e., the MS-theory) is decidable. 
If C = { S }  where S is a finite (and effectively given) structure then the property 
S b 'p is decidable for every formula 'p of the languages L we have consid- 
ered, or we will consider. The L-theory of C is thus (trivially) decidable. An 
interesting question is thus the complexity of this problem. For an example, 
the property S 
'p is polynomial in size(S) if 'p is a fixed first-order formula 
and S is the input; it is N P  if cp is existential second-order (Fagin [37]), where 
again 'p is fixed and S is the input. Conversely, every N P  property can be 
described in this way. More generally, a property belongs to the polynomial 
hierarchy iff it can be described by a second-order formula (see Stockmeyer 
[58], Immerman [44] or Abiteboul et al. [l]). 
If C = { S }  where S is infinite, then the C-theory of C may be undecidable. 
However the study of the theories of infinite structures and especially of their 
monadic (second-order) theories is a very rich topic that we cannot even touch 

5.2. RELATIONAL STRUCTURES AND LOGICAL LANGUAGES 
323 
here. We refer the reader to survey papers like those of Gurevich [42], Courcelle 
[lo], Thomas [60]. 
Proposition 5.2.1 (Trakhtenbrot [62]) 
The first-order theory of the class of finite graphs is undecidable. 
0 
So are a fortiori its monadic and its second-order theories. The following result 
is a basic tool for obtaining undecidability results. It concerns square grids. 
A grid is a directed graph isomorphic to Gn,, for some n,m E N+ where 
VG,,, = [n] x [m] and EG,,,, = {((i,j), (i',j'))/l 5 i 5 i' 5 n, 1 5 j 5 j' 5 m 
and, either i' = i + 1 and j' = j ,  or i' = i and j' = j + l}. (N+ denotes the set 
of positive integers and for n E N+; [n] denotes {1,2,. . . , n}). A square grid 
is a graph of the above form where m = n. 
Proposit ion 5.2.2 
The monadic (second-order) satisfiability problem of every class of graphs C 
containing graphs isomorphic to Gn,n for infinitely many integers n is unde- 
cidable. 
Proof sketch 
One first constructs an MS formula y that defines the square grids among the 
finite simple loop-free directed graphs (see Subsection 5.2.9). Consider now a 
Turing machine M with total alphabet A (input letters, states, end markers) 
and an initial configuration WM. Let A = { a l , .  . . , a,}. 
If ( X I , .  . . , X,) 
is 
a partition of the set of vertices of a square grid Gn,n then one can consider 
that this partition defines a sequence of n words of length n in A*. (Each 
line of the grid represents a word where a line of Gn,n is a subgraph with 
set of vertices {i} x [n] for some i; the first line represents the configuration 
WM). One can construct an MS-formula V M  ( X I ,  . . . , X,) 
such that, for every 
XI,.. ' > xm 
VG,,, 
Gn,n + ( P M ( X I  
9 ' . . 7 X m )  
iff ( X I , .  . . , X,) 
is a partition of VG,,, which defines the sequence of configu- 
rations of a terminating computation of M .  (Configurations of length smaller 
than n can be extended to the right by a special symbol). It follows that if C 
contains infinitely many square grids, then M terminates iff some graph G in 
C satisfies the formula 
Y A 3x1,. 
. . , Xm.(PM 
(5.1) 
Hence the halting problem of Turing machine reduces to the monadic satis- 
fiability problem of any class C containing infinitely many square grids. This 
0 
latter problem is thus undecidable. 

324 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
Remark: 
In this construction, one may assume that the machine M is deterministic and 
one can write c
p
~
 
in such a way that the square grid on which its (unique) 
computation is encoded is minimal. It follows that there exists at most one 
graph satisfying formula (3.1). Hence, even if we know that a MS-formula cp 
has only finitely many finite models (up to isomorphism), we cannot construct 
0 
this set by an algorithm taking cp as input. 
5.2.6 
Two formulas cp, cp’ E SO(R, {XI,. . . , z,, 
X I , .  . . , X,}) 
are equivalent if for 
every S E STR(R), for all dl , . . . , d, E Ds, 
for all relations El, . . . , E, on 
Ds of respective arities p(X1), . . . , p(X,) we have: 
Some tools for constructing formulas 
Clearly, two equivalent formulas express the same properties of the relevant 
tuples ( d l , .  . . , d,, El, . . . , E,) 
in every structure S E STR(R). 
In some cases equivalence is relativized to a subclass S of STR(R): equivalent 
formulas express the same properties of the relevant tuples in the structures 
of S, not in all structures. 
Lemma 5.2.3 
Let cp E SO(R, y )  and 2 be a finite set of variables. One can transform cp into 
an equivalent formula cp‘ in SO(%.?, Y )  in which no variable of 2 is bound. If cp 
is M S ,  then cp’ is MS; if cp is FO, then cp’ is FO. 
Proof 
One simply renames the bound variables belonging to 2. Of course, one re- 
names a variable into one of same type (individual or relational) and arity 
(in case of a relation variable). This is possible because our “universal” set of 
0 
variables contains countably many variables of each type and arity. 
For readibility, one usually writes a formula by choosing bound variables that 
are not free in the formula. This is always possible without loss of generality. 
We now recall the definition of first-order substitutions in formulas. Let cp 
be a second-order formula; let 51,. 
. . ,z, 
be pairwise distinct variables; let 
y1, ... ,yn be variables, not necessarily pairwise distinct. (In order to avoid 
double subscripts, we do not index the variable in X; 
hence XI,... ,xn are 
metavariables denoting variables of X; 
they are not the variables 2 1 , .  . . ,z,; 

5.2. RELATIONAL STRUCTURES AND LOGICAL LANGUAGES 
325 
in the generic such list, we may have two variables equal). We denote by 
cp[yl/zl, . . . , y,/x,] 
the formula obtained as follows: 
0 using Lemma 5.2.3, one takes cp' equivalent to cp with no bound variable 
in { Y l , . . .  ,v,}; 
l , ' . .  ,n. 
0 then one substitutes in cp the variable yi for each occurrence of xi,i = 
Finally, 
if 
cp 
has 
been 
previously 
described 
as 
a 
formula 
cp(zl,. . . , xn, X1, . . . , X,) 
(which indicates that its free variables are 
among 2 1 , .  . . , x,, XI,. . . , X,) 
then, cp(y1,. . . , y,, 
XI,. . . , X,) 
will be 
another notation for cp[y1 /x1, . . . , yn/zn]. With this notation, we have the 
following lemma, giving the semantics of substitution. 
Lemma 5.2.4 
Let cp 6 SO(R, ( 2 1 ,  . . . , x,, x,+l,. . . , xp}) with 21, . . . , xp pairwise distinct. 
Let 91,. . . , y, 
be variables. Let {zl,. . . , zq} be an enumeration of the set 
of variables {yl,... ,yn,xn+l,... ,zp}, so that cp[yl/zl,... ,y,/x,] 
E SO(R, 
{ZI;.. , z q } ) .  ForeverySESTR(R),foreverydl,... ,dq E
D
~
 
wehave 
wheredi = dj iff 15 i 5 n and zj = yi or n + 15 i < p  and zj = xi. 
Pro0 f 
The sequence di , . . , , db is well-defined because {z1 , . . . , zq} is an enumeration 
0 
of the set {yl, . . . , y,, 
zn+l,. . . , xp}. The verification is easy. 
We now define second-order substitutions, by which relation symbols can be 
replaced by formulas, intended to define the corresponding relations. Let cp E 
SO(R, { X I , . . .  ,x,,Xl;.., 
X p } ) .  For each i = l;.. , p ,  we let y!12 E SO(R, 
let cp[$l/X~, 
. . . , $p/Xp] be the formula in SO(R, (21, . . . , x,}) 
constructed 
as follows: 
{ x1, ... , z,, 
y1 ,. . . , yP(x,)} where the listed variables are pairwise distinct. We 
0 by using Lemma 5.2.3 one first constructs cp' equivalent to cp where no 
variable of (51 , . . . , x, , XI, . . . , X,} is bound; 
0 then one replaces every atomic formula Xi(u1,. . . , uP(x,)) of cp' (where 
the variables u1, . . . , uP(x,) 
need not be pairwise distinct) by the formula 
y!I&l/Yl,... ,u,(x,)/Y,(xt)l. 
With this notation, we have the following lemma. 

326 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
Lemma 5.2.5 
Let S E STR(R), let d l , . . .  ,d, 
E Ds. For each i = l,... , p  let Ti 
be the p(Xi)-ary relation on Ds defined by ( a l , .  . . , a,(x,)) E Ti iff S b 
$i(dl 3 .  . . dm1 ~ 1 , .  
. ‘ 7 a p ( ~ i ) ) .  Then 
s /= cp[$l/Xl,. ’ .  , $p/XpI(dl 
. , dm) jffs b c p ( 4  , ’ ’ .  , dm, Tl, . . . 7 T p ) .  
Proof 
Straightforward verification from the definition, by using an induction on the 
structure of cp. 
Let S E STR(R) and E be a subset of Ds. We denote by S[E] the restriction 
of S to E, i.e., the structure S‘ E STR(R) with domain E and such that Rs! = 
Rs n Ep(R) for every R. (Since our structures are relational the restriction of 
a structure to a subset of its domain is always well-defined: this would not be 
the case if we had to ensure that some functions have a well-defined image.) 
If S represents a graph G, i.e., S = I G 11, then S[E] represents the induced 
subgraph of S with set of vertices E which will be denoted by G[E]. 
Lemma 5.2.6 
Let cp E SO(72, {XI,... 
,x,}); one can construct a formula cp‘ E SO(R, 
{XI,. . . , x,, X}) such that the following holds for every S E STR(R). For 
every E C Ds, for every d l , . . .  ,d, E E: 
s I= cp’(dl,... ,d,,E) jffS[El b cp(dl,.” ,&) 
If cp is M S  or FO then ‘p’ is M S  or FO respectively. 
Pro0 f 
We can assume (by Lemma 5.2.3) that X does not occur in cp. We let ‘p’ be 
associated with cp by the following inductive definition, where ‘p may have free 
variables of all types (relation variables as well as individual variables). 
(VY.$)’ = VY.?)’ 
(3Y.$)’ = 3Y.?)’ 
(Vx.$)’ = Vx.[x E x ==+ $7 
(3x.G)’ = %[x E x A $‘I 
($10&2)’ 
= G:o&b 
where OP E {A, V, =+, -} 
(+)’ 
= 7$’ 
$I’ = $ for every atomic formula $. 
0 
The formula ‘p’ is called the relativization of y, to X and will be denoted by 
(PIX. 

5.2. RELATIONAL STRUCTURES AND LOGICAL LANGUAGES 
327 
5.2.7 
We denote by T+ the transitive closure of a binary relation T. 
Transitive closure and path properties 
Lemma 5.2.7 
Let S be an {R}-structure where R is binary. The transitive closure of Rs is 
defined in S by the following formula cpo of M S ( { R } ,  { z ~ , x c z } ) :  
~ X [ { ~ Y , ~ ( Y E X A R ( Y , ~ ) ~ ~ E X ) A V Y ( R ( X ~ , Y ) ~ Y  
E X ) } * x 2  
EX] 
Proof 
Let dl,d2 E DS such that S 
(po(dl,d2). The set D = { d / R i ( d l , d ) }  satisfies 
thepropertyVy,z(y E XAR(y,z) ==+z E X ) ~ V y ( R ( x l , y )  
* y  
E X).Hence 
d2 E D, i.e. R i ( d 1 ,  d2). Conversely, if R Z ( d 1 ,  d2) then dz must belong to every 
set D such that R s ( d 1 , d )  for all d E D and that is closed under Rs, i.e., is 
such that d E D and R s ( d ,  d') implies d' E D. This shows that S 
cpo(d1, d2 . A 
We now discuss some applications of this lemma to path properties in graphs. 
We shall write formulas relative to 72,. 
Lemma 5.2.8 
One can write M S  formulas expressing in I G 11 the following properties of 
vertices x ,  y and sets of vertices X, where G is an arbitrary directed graph, 
represented by the structure I G (1 in STR(R,). 
P1: x = y or there is a nonempty path from x to y, 
P2: G is strongly connected, 
P3: G is connected, 
P4: x # y and there is a path from x to y, all vertices of which belong to the 
set X, 
P5: X is a connected component of G, 
P6: G has no circuit, 
P7: G is a directed tree, 
P8: G has no circuit, x # y and X is the set of vertices of a path from x to y, 
P9: G is planar. 
bA nonempty path in G is here a sequence of vertices ( X I ,  x2,. . . , 2,) with n 2 2 such 
that (zt,xz+l) E edgG for all z and x, = zj 3 
i = j or { i , j }  = {l,n}; if x1 = z,, 
this path 
is a circuit. We consider (z) as an empty path for every vertex z. 

328 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
Proof 
We shall denote by cpi,i = l,... 
,9 the formula expressing property Pi, in a 
structure S E STR(R,). 
(1) (PI is the formula z = yVcpo(z, y) where cpo is constructed in Lemma 5.2.7 
with R = edg. 
(2) cp2 is the formula Vz,y[cpl(z,y)]. 
(3) cp3 is the formula cp2[6/edg] where O(z1, z 2 )  is edg(z1, z2) V edg(z2, XI). 
(4) 
994 is the formula lz = y A z E X A y E X A 91 [X hence (p4(5, y, X )  says 
that z, y are vertices of G [ X ]  and that there is a path in G [ X ]  from z to 
y; this is equivalent to the property of the statement. (We recall that we 
denote by G [ X ]  the induced subgraph of G with set of vertices X . )  
(5) (ps(X) is the formula p3[X A V Y [ X  C_ Y Acp3[Y ==+ Y C XI; (note that 
cp3[X expresses that G [ X ]  is connected); the subformula X C Y stands 
for: Vu[u E X ==+ u E Y ] .  
(6) 996 is the formula Vz, y[edg(z, y) ==+ 791 (y, z)]. 
(7) cp7 is the formula (p6 A 3zvy[cpl(z, y)] A vx, y, Z[edg(z, z )  A edg(y, z )  ==+ 
z = y] expressing that G has no circuit, that every vertex is reachable 
from some vertex (the root) by a directed path and every vertex is of 
indegree at most 1: we consider directed trees with edges directed from 
the root, towards the leaves. 
(8) The construction of 9 3  is more complex. We let cpk(X) express that x is 
linearly ordered by the relation edg&[,] where G is assumed to have no 
circuit, i.e. cpg(X) is 
It says that the considered graph has no circuit, that X is linearly ordered 
by edg&[,] with first element z and last element y with y # 2. If X is 
finite, this is enough to express that X is the set of vertices of a path from 
z to y. But this is not true if X is infinite. (Take for example G with set 

5.2. RELATIONAL STRUCTURES AND LOGICAL LANGUAGES 
329 
of vertices N and set of edges { ( i , j ) / i  # 0 , j  E (0,i + I}}, take X = N ,  
z1 = 1 and x2 = 0.) We let O(zl,x2, X) be the following formula: 
expressing that x1,52 E X and x2 is the successor of x1 in X with respect 
to the linear order edg&[,]. Let E be the binary relation on X defined 
by 8. Then X is the set of vertices of a path from z to y iff (x,g) E E f .  
Hence the following formula cp*(z, y, X) expresses the desired property: 
where cpo is from Lemma 5.2.7. 
(9) This will be proved in Section 5.8 by using Kuratowski's theorem. 
0 
The condition that G be acyclic is important in P8: we shall prove in the next 
proposition that one cannot express by an MS formula that, in a finite directed 
graph, a given set X is the set of vertices of a path from z to y. 
We now review some properties that are provably not MS-expressible. A di- 
rected graph is Hamiltonian if it has at least 2 vertices and a circuit passing 
through all vertices. 
Proposition 5.2.9 
The following properties are not MS-expressible: 
1. two sets X and Y have equal cardinality, 
2. a directed graph is Hamiltonian, 
3. in a directed graph a set X of vertices is the set of vertices of a path from 
2 toy, 
4. a graph has a nontrivial automorphism. 
Proof 
We shall use the following result of Buchi and Elgot (see Thomas [60], Thm 
3.2): if L C {a,b}* is the set of words u such that 11 u 11 + cp where cp is a 
closed MS-formula, then L is a regular language. 

330 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
(1) Assume that we have a formula y5 E MS(0, {X, Y } )  such that for every set 
S ,  for every V, W C S: 
S 
+(V,W) if and only if Card(V) = Card(W). 
Then the MS-formula $ [ l u b a ( z ~ ) / X I  
labb(21)/Y] of MS(R,,{,,b)) would char- 
acterize (as a subset of {a, b}*) the language L of words having as many a’s as 
b’s. This language is not regular, so we get a contradiction. 
(2) With every word w E {u,b}+ represented by the structure ( 1  w 11 = < 
{ 1, . . . , n}, SZLCIJ,IJ, 
laball,ll, hbbll,ll 
> we associate the graph K, with set of 
vertices { 1 , .  . . , n} and an edge from i to j iff i E lab,~l,ll 
and j E labbllwll or 
vice-versa. Hence K ,  is a complete bipartite directed graph. It is Hamiltonian 
iff w belongs to the language L already used in (1). 
Let us now assume the existence of a formula 7 in MS(R,, 8) that would 
characterize the Hamiltonian graphs among finite graphs. Let p(z1 , z2) be the 
FO formula defined as: 
(l&(xi) A labb(xz)) v (labb(xi) A l & ( z 2 ) )  
This formula defines in I] w 11 the edges of K ,  (note that D1lwll = VK,). It 
follows that for every word w E {a, b}* of length n 2 2 we have 
w E L iff K, is Hamiltonian iff 11 w 11 
~ [ p / e d g ] ,  
and the set of words in L of length at least 2 is regular, a contradiction. 
(3) Assume we have a formula ‘p E MS(R,, {x, y,X}) expressing that in a 
directed graph, X is the set of vertices of a directed path from z to y. Then 
the MS formula: 
3X[tJU(U E X) A 3x1 Y(’p(Z, Y, X) A T E  = Y A edg(Y1 .))I 
expresses that the considered graph has at least two vertices and is Hamil- 
tonian. This is not possible by (2) hence no such formula ‘p does exist. 
(4) The proof is very much like that of (2). With every word of the form 
anbcam with n 2 2,m 2 2 one associates the graph Hn,m with set of vertices 
{-n, -n + 1 , .  . . , -1,O, 1 , 2 , .  . . , m} U {0’} and undirected edges between 0 
and 0’ and between i and i + 1 for every i ,  -n 5 i < m. This graph has 
a nontrivial automorphism iff n = m iff the given word belongs to the non- 
regular language {anbcan/n 2 2). Hence, no MS formula can express that a 
13 
graph has a nontrivial automorphism. We omit details. 

5.2. RELATIONAL STRUCTURES AND LOGICAL LANGUAGES 
331 
Remark: 
The structure representing H,,, 
can be obtained from the structure 
11 anbcam 11 by a definable transduction using quantifier-free formulas (to be 
0 
introduced in Section 5.5 below). 
5.2.8 
This technical subsection may be skipped on first reading. We define a syn- 
tactical variant of MS logic where all variables denote sets. The corresponding 
formulas are less readable than those used up to now, but the proofs concern- 
ing them and the properties they define will be easier, because the syntax is 
limited. 
We let R be as before; we shall only use set variables. We define MS‘(R, 
{XI, 
. . . , X,}) by taking atomic formulas of the forms: 
Monadic second-order logic without individual variables 
X C Y where X,Y 
are variables, 
R(Y1,. 
. . , Y,) where R E R, 
n = p(R) and Y1 ,.. . , Y, are variables. 
The formulas are constructed with the usual propositional connectives and set- 
quantifications 3X and VX. We denote by MS’(R, {XI,... 
,X,}) the set of 
such formulas with free variables among X I ,  . . . , X,. 
Let S E STR(R). The meaning of X C Y is set inclusion. If D1, 
... ,D, 
are 
sets denoted by Y1, 
. . . , Y, then R(Y1,. 
. . , Y,) is true in S iff (dl,. 
. . , d,) 
E 
Rs for some dl E D1,... 
,d, E D,. The validity of formulas in MS‘(R, 
{XI,. 
. . , X,}) in a structure S and for an assignment y : {XI,. 
. . , X,} + S 
follows immediately. 
Lemma 5.2.10 
For every formula cp E MS’(R, {XI, 
‘ . . , X,}) one can construct an equivalent 
formula p’ in M S ( R ,  {XI,... 
,X,}). 
Proof 
One replaces X C Y by Vx[x E X * x E Y] 
and R(Yl,... 
,Y,) 
by 
0 
331,. . . , yn[gl E YI 
A . . . A yn E Y, A R(y1,. 
. . , y,)]. 
We omit details. 
Lemma 5.2.11 
For every formula cp E MS(R,{zl,... ,x,,K,... 
,Y,}) one can construct 
a formula cp‘ E MS’(R,{X1,. 
. . , X,, Y1,. 
. . , Y,}) such that for every S E 
STR(R)foreveryassignmenty : {x1,.-. ,x,,Y1,.-. 
,Y,} + S then (S,r) 
cp iff (S,y’) + cp’ where r’(Xi) 
= {~(zi)} 
and y’(Y,) = y(Y,). 

332 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
Proof 
We first let X = 0 be the formula V Y [ X  C Y ]  in MS’(0, { X } )  which char- 
acterizes the empty set. We let also S i n g ( X )  E MS’(0, { X } )  be the formula 
V Y [ Y  c X * 
X 
We now translate ‘p into 9’. For each individual variable x, we let X denote a 
new set variable. (“New” means distinct of any variable in 9). 
We obtain ‘p’ 
from ‘p by the following inductive construction: 
Y V Y = 01 which characterizes the singleton sets. 
( x = y ) ’ = X C Y A Y C X ,  
(R(y1,. . ’ , yn))‘ = R(Y1, ’ . . 7 Yn), 
(. 
E Y)’ = x C Y, 
(CplOP’p2)’ = ‘p:oP’p~ 
for every binary connective op equal to V, A, =-=+ or e, 
(l’pl)’ = -Cp: , 
(VX.Cpl)’ = vx.‘p’, 
, 
(3X.’pl)’ = 3x.(p’,, 
(VZ.cp1)’ = VX[Sing(X) * 
‘pi], 
( ~ z . ( P I ) ’  
= 3X[Sing(X) A cp’,]. 
We omit details. 
0 
5.2.9 
The rectangular grid Gm,n is the graph with set of vertices V = {0,1, . . . , m - 
1}x{O,1,2,... ,n-l}andsetofedgesE={((i,j),(i’,j’))/(i,j), (i’,j’) EV 
and either i’ = i and j’ = j + 1 or i’ = i + 1 and j’ = j ) .  Its north-, west-, 
south, and east-borders are the sets of vertices: 
A worked example: the definition of square grids in MS logic 
X n  = {O,... ,m - I} x {n - I} 
X ,  = (0) x { O , . . .  ,n - l} 
X ,  = { O , . . .  ,m - l} x (0) 
x, = { m -  1j x { O , . . .  , n -  1). 

5.2. RELATIONAL STRUCTURES AND LOGICAL LANGUAGES 
333 
Its well-coloring is the 4-tuple of sets of vertices YO, Yl, Yz , Y3 such that: 
( i , j )  E Yk iff k = rnod(i) + 2(mod(j)) 
where rnod(i) is the remaining (in (0,l)) of the integer division of i by 2. 
We claim that for every positive integer rn there exists an MS formula 8 with 
free variables Yo, Y1, Yz, Y3, X,, X,, X,, X ,  that characterizes (among the fi- 
nite directed simple graphs) those isomorphic to Gzrn,zrn where, in addition, 
YO, Yl , Y2, Y3 form a well-coloring and X,, X ,  , X ,  , X ,  are the four borders. 
We let 6 express the following conditions concerning a simple graph G given 
with sets of vertices Yo,Yl,Yz, Y3, X,,X,,X,,X,: 
(1) G has no circuit; 
( 2 )  YO, 
Y1, Y2, Y> form a partition of VG; assuming this we shall call i-vertex, 
i-successor of g, i-predecessor of y a vertex, or a successor of y, or a 
predecessor of y that belongs to Y,; 
(3) every vertex has at most one i-successor and at most one i-predecessor 
for each i; 
(4) a 0- or a 3-vertex has no 0- or 3-successors; a 1- or a 2-vertex has no 1- 
or 2-successor; 
(5) G[X,] is a path consisting alternatively of 2- and 3-vertices; its origin is 
a 2-vertex and its end is a 3-vertex; the origin is the unique element of 
X ,  n X ,  and the end is the unique element of X ,  n X,; 
(5’) G[X,] is a path consisting alternatively of 1- and 3- vertices; its origin is 
a 1-vertex which is the unique element of X ,  n X,; its end is a 3-vertex 
which is the unique element of X ,  n X,; 
(5”) and (5”’) state similar conditions on the sets X ,  and X,; 
(6) each 2-vertex in X ,  has a 3-successor and no 0-successor; each 3-vertex 
in X ,  - X ,  has a 2-successor and no 1-successor; 
(6’) (6”) (6”’) state similar properties of X,,X,,X,; 
(7) each vertex in VG - ( X ,  u X ,  u X ,  U X,) has two predecessors and two 
successors; 
(8) there exists a path from the vertex in X ,  n X ,  to the one in X ,  n X ,  the 
vertices of which have the colors 0, 1,3,2,0,1,3,2,. . .O, 1,3 in this order. 

334 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
It is not hard to see that conditions (1) to (7) characterize the well-colored 
grids of the form G2n,2m for n 2 1,m 2 1. Condition (8) implies furthermore 
that m = n. It is not hard to modify this construction in order to characterize 
the grids of the form G2n+1 , G2n+1 for n 2 1. 
In view of the proof of Proposition 5.2.2, a line of G given with Yo, Y1 ,. . . , X ,  
as above is a set L C: VG such that 
(1) G[L] is a path from a vertex in X ,  to a vertex in X ,  
(2) either L 5 YO U Y1 or L C Y2 U Y3. 
5.3 Representations of partial orders, graphs and hypergraphs by 
relational structures 
In this section we discuss more in detail the various possibilities of representing 
a partial order, a graph or a hypergraph by a relational structure. The choice 
of the representation is important for the possibility of expressing a given 
property by some formula of the three logical languages we have introduced. 
5.3.1 Partial orders 
The simplest way to represent a partial order I D  on a set D is by the structure 
< D, so>. If D is finite, one can also represent < D, ID> 
by a graph < D ,  s > 
where S is binary, such that I D  is the reflexive and transitive closure of S. 
There is even a unique minimal such relation (minimal for inclusion) that we 
shall denote by SUCD (where suc means successor) and the corresponding graph 
< D, SUCD > is the classical Hasse-diagram of the partial order < D, <D>. 
A property of partial orders representable by a formula cp with respect to 
the representation < D ,  ID> 
will be representable by another (perhaps more 
complex) formula $I with respect to the representation < D ,  SUCD >. 
Proposition 5.3.1 
(1) A property of a finite partial orders is MS with respect to the representation 
< D, <D> iff it is MS with respect to the representation < D ,  SUCD > . 
(2) Furthermore, it is FO with respect to the representation < D ,  <D> if it is 
0 
FO with respect to the representation < D, 
SUCD >. 
If a property is FO with respect to the representation < D, ID> 
we can only 
conclude (by (1)) that it is MS with respect to the representation < D ,  SUCD >. 
We have actually the proper hierarchy: 
FOsw C FO< C MSsuc = MS<, 

5.3. REPRESENTATIONS OF PARTIAL ORDERS, GRAPHS ... 
335 
where the subscripts indicate the considered representation. The languages 
defined by first-order formulas in terms of 5 (as opposed to in terms of the 
successor relation) are the star-free languages. This class is a proper subclass 
of the class of regular languages (definable by MSsuc or MS< formulas) and 
contains properly the class of locally threshold testable languages (definable 
by FO,,, formulas) (see Pin [50]). >From these strict inclusions concerning 
classes of languages follow the corresponding strict inclusions for partial orders 
Proof 
We let sue be a binary relation symbol. Since I D  is the reflexive and transitive 
closure of SUCD, it follows that <D is defined in < D ,  SUCD > by the MS formula 
(FOSUC c FOI c MSsuc). 
4 Y 1 ,  Y2): 
y1 = Y2 v cpo[suc(z1, z2)/R] 
where cpo is from Lemma 5.2.7. Hence if a property is expressed by an MS or 
a FO formula cp with respect to < D ,  ID> it can be expressed by the MS 
(P[P(Yl,Y2)/ 51. 
Now SUCD is defined in < D ,  I D >  
by the FO formula: p’(y1, y2) 
Hence a property expressed in < D ,  SUCD > by an MS or FO formula cp’ can 
be expressed by the formula cp’[p’/suc] which is MS or FO respectively. 
0 
5.3.2 Edge set quantifications 
As already noted the representation of a graph by a relational structure that 
we have used up to now is not convenient to express properties of graphs that 
depend on the multiplicity of edges. We shall define another representation, 
where the edges are elements of the domain, which is more natural for express- 
ing logically the properties of multigraphs and which, furthermore, makes it 
possible to express more properties of simple graphs by MS formulas. 
We let 72, = {inc} where inc is ternary (inc stands for “incidence”). For every 
graph G, directed or not, simple or not, we denote by VG its set of vertices 
and by EG its set of edges. The incidence relation between vertices and edges 
is represented by the ternary relation incG such that: (2, 
y, z )  E incG iff z is 
an edge and either this edge is directed and it links y to z or it is undirected 
and it links y and z. If z is an undirected edge, we have: (z, y, z )  E incG iff 
( z , z , y )  E incG. 

336 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
We let DG := VG u EG (we always assume that VG n EG = 0) and we let I G 12 
be the structure < DG, 
Z ~ C G  > E STR(R,). If G has several edges linking y 
to z then, they are represented by distinct elements of DG. 
In a structure S = < Ds, incs > representing a graph, the edges are the 
elements x of Ds that satisfy the formula 3y, z[inc(x, y, z)]. The structures 
in STR(R,) representing directed graphs are exactly those which satisfy the 
following conditions: 
(1) Vx, 
y, z[inc(x, y, 2 )  ==+ 13u, v(inc(y, u, 
v) V in&, u, 
u))], 
and 
(2) b’x, y, z, y’, z’[inc(z, y, Z) A inc(x,y’, z’) --r‘ y = y’ A z = 2’1. 
In any such structure, if we let E = {x E Ds / S 3y,~.inc(z,y,z)} 
and 
V = Ds - E then incs C E x V x V and there exists a unique directed graph 
G with VG = V, EG = E and 1 G 12 = S. Similarly, the structures in STR(R,) 
representing undirected graphs are exactly those that satisfy (1) above together 
with: 
(2’) b’x,y, z, y’, z’[inc(x,y, z )  A inc(x, y‘, z‘) 
===+ (y = y‘ A z = z‘) V (y = z‘ A z = y‘)] 
(3’) vx,y, z[inc(x, y, z )  ==+ inc(x, 2, y)]. 
Graph properties can be expressed logically, either via the representation of 
a graph G by I G 12, or via the initially defined representation I G ]I:= < 
V ~ , e d g ~  
>. The representation I G 11 only allows quantification on vertices, 
sets of vertices, relations on vertices (according to the language we consider), 
whereas the representation I G 12 also allows quantifications on edges, sets of 
edges and relations on edges. We shall distinguish the MS1-definable classes 
(which are nothing but the MS-definable ones we have considered up to now), 
from the MSz-definable ones, which use formulas in MS({inc},0) and the 
representation of a graph G by I G 12. Similarly, we have FO1 -, FOz -, Sol- 
and SOz-definable classes of graphs.We shall also speak of FOi - or MSi - or 
SOi-expressible graph properties, where i = 1 or 2. 
Since a set of edges in a simple graph can be considered as a binary relation 
on its set of vertices it is quite clear that every MSz-expressible property is 
SO1-expressible (we shall prove that later). However it is not always MS1- 
expressible. 
Proposition 5.3.2 
The following properties of a directed graph G can be expressed by MS2- 
formulas. 

5.3. REPRESENTATIONS OF PARTIAL ORDERS, GRAPHS ... 
337 
(1) X is a set of edges (resp. of vertices) forming a path from x to y, where 
X f Y .  
(2) G is Hamiltonian. 
Proof 
(1) For every subset X of EG we denote by G [ [ X ] ]  
the subgraph H of G 
such that V, is the set of vertices incident to some edge in X and EH = X .  
The desired condition is thus that G[[X]] is a path from z to y. This can be 
expressed by a formula $: in MS(R,, {z, y, X}) constructed with the help of 
Lemma 5.2.6 and the formula ‘ps of Lemma 5.2.8. The desired formula $1 is 
thus 
TX = y A Vz[z E X ===+ 3u, w(inc(z, u, w))] A &. 
If we want to express that Y is the set of vertices of a path from x to y we 
take $2(x, y, Y )  defined as 
~ X [ $ ~ ( X , ~ , X ) A V Z [ Z  
E l” 
~ u , w ( U  E X A  ( i n c ( u , z , ~ ) V i n c ( v , ~ , ~ ) ) ) ] ] .  
The quantification on sets of edges is thus crucial in $2 since we have proved 
that no formula in MS(R,, {x, y, Y}) 
equivalent to $2 does exist (see Propo- 
sition 5.2.9). 
0 
(2) follows from (1): see the proof of Proposition 5.2.9, assertion (3). 
Proposit ion 5 -3.3 
Let C be a class of simple, directed or undirected graphs: 
(1) C is FO1-definable iff C is FO1-definable 
(2) C is SO2-definable iff C is Sol-definable 
(3) C is MSz-definable ifC is MS1-definable and the converse does not always 
hold. 
Proof 
The relation edgG is definable from incG by the formula 3u.inc(u, X I ,  z2). It 
follows that for each L E {FO, SO, MS}, C is &-definable if it is L1-definable. 
That the converse does not hold for MS follows from Propositions 5.2.9 and 
2.2: the class of simple Hamiltonian directed graphs (with at least 2 vertices) is 
MSz-definable but is not MS1-definable relatively to the class of simple graphs. 
It holds for FO because a quantification of the form “there exists an edge e...” 
can be replaced by a quantification of the form “there exist vertices x and y 

338 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
that form an edge such that...”. The proof is similar for SO: a quantification 
over n-ary edge relations is replaced by a quantification over 2n-ary vertex 
relations. We omit details. 
0 
The next theorem reviews some classes of graphs on which MS1 and MS2 are 
equally expressive. (Tree-width will be defined in Section 5.6). 
Theorem 5.3.4 
Let C be the class ofplanar directed simple graphs, or of directed simple graphs 
of degree at most k or finite directed simple graphs of tree-width at most k 
[for any fixed k). A property of graphs in C is MS2-expressible iff it is MS1- 
expressible. The same holds for the corresponding classes of undirected graphs. 
We do not reproduce the full proof of this theorem which is quite long (see 
Courcelle [14]). We only give the basic lemma and some consequences. 
Let G be a directed graph. A semistrong k - coloring of G is a mapping 
y : VG 
{1,2,. . . , k }  such that, for every two vertices u, 
w’ # u: 
1. if v,w’ are adjacent, then y(w) # y(v‘), 
2. if there are edges linking v to w and u’ to w, where w is a third vertex, 
The following lemma will be proved in Section 5.5. Let C k  be the class of finite 
or infinite simple directed loop-free graphs having a semistrong k-coloring. 
Lemma 5.3.5 
Let k E N. A property of graphs in C k  is MS1-expressible if it is MS2- 
then Y ( V )  # Y(V’), 
expressible. 
The class C2 contains the directed trees. (Edges are directed in such a way that 
there is a unique path from the root to each vertex). Hence the languages MS1 
and MS2 are equally powerful for expressing properties of directed trees. Let 
d E N and k = d2 + 1. Let us prove that C k  contains the simple directed loop- 
free graphs of degree at most d. Let G be such a graph. Let G’ be the graph 
obtained by adding an edge between any two vertices at distance 2. This graph 
has degree at most d + d(d - 1) = d2. Hence G’ has a k-coloring (in the usual 
sense, where one requires that any two adjacent vertices have different colors). 
Such a coloring is a semistrong k-coloring of G. Hence we have proved that 
Theorem 5.3.4 holds for the classes of directed trees and of simple directed loop- 
free graphs of degree at most any fixed d. The complete proof of Theorem 5.3.4 
is based on Lemma 5.3.5 and constructions of appropriate colorings. 

5.3. REPRESENTATIONS OF PARTIAL ORDERS, GRAPHS ... 
339 
5.3.3 Hypergraphs 
We define directed, hyperedge labelled hypergraphs. We let A be a finite ranked 
set: each symbol a 6 A has an associated rank, a nonnegative integer denoted 
by .(a). 
A hypergraph H has a set of vertices VH and a set of hyperedges 
E H ;  each hyperedge e has a label h b H ( e )  in A and a sequence of vertices of 
length T(labH(e)). The label of e may have rank 0 and in this case, e has no 
vertex. We always assume that VH n EH = 0. As for graphs we define two 
representations of hypergraphs by relational structures. 
We let R,(A) := {edg,/a E A} and R,(A) := {inc,/a E A} where edg, 
is .r(a)-ary and inc, is (.(a) + 1)-ary. With a hypergraph H we will as- 
sociate the structures I H 11 := < v ~ , ( e d g ~ ~ ) ~ ~ ~  
> E STR(R,(A)) and 
I H 12 := < VH U E H ,  
( ~ ~ c , H ) , E A  > E STR(R,(A)) where: 
(1) i n c , ~ ( ~ , y 1 ; . .  ,yn) holds iff z E E H , Y ~ , . . .  
, y n  E V ~ , l a b ~ ( z )  
= a , n  = 
.(a) and ( y ~ ,  
. . . , yn) is the sequence of vertices of z, and 
( 2 )  edg,H(yl,. . . , yn) holds iff ~ ~ c , H ( z ,  
y 1 , .  . . , yn) holds for some z E EH. 
The structure I H 11 contains no information on the hyperedges of type 0, and 
no information either on the number of hyperedges having the same label and 
the same sequence of vertices. A hypergraph is sample if it has no hyperedge of 
type 0 and if no two hyperedges have the same label and the same sequence of 
vertices. The structures I H 12 are appropriate for representing all hypergraphs 
H whereas the structures I H 11 are only appropriate for representing simple 
hypergraphs or for expressing logically properties of hypergraphs that are in- 
dependent of the multiplicity of hyperedges and of the existence of hyperedges 
of type 0. 
We shall refer by MSi to MS logic relative to the representation of a hypergraph 
H by the structure I H li where i = 1,2. The results of Proposition 5.3.3 hold 
for hypergraphs built over a fixed finite set A as well as for graphs. 
Proposition 5.3.6 
Let k E hf and A be a finite ranked alphabet. The same properties of finite 
simple hypergraphs over A of tree-width at most k are expressible in MS1 and 
in MS2. 
Proof 
See Courcelle and Engelfriet [23]. 
In certain cases, hypergraphs are equipped with distinguished vertices called 
sources or ports (see Section 5.6). These vertices will be represented in re- 

340 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
lational structures by means of additional unary relations. For instance, if a 
hypergraph H is given with k sets of distinguished vertices then the structure 
I H 11 contains k unary relations P ~ H ,  
. . . , P ~ H  
where PI, . . . , Pk are additional 
unary symbols. 
5.4 
The expressive powers of monadic-second order languages 
In the preceding section, we have seen that the choice of a representing struc- 
ture for an object like a partial order, a graph or a hypergraph may affect 
the first-order or the monadic second-order expressibility of properties of these 
objects. Here, we shall consider the extension of MS logic by cardinality predi- 
cates. In some cases this extension is just a syntactic shorthand, and in others 
we shall obtain a real extension of expressive power. 
5.4.1 Cardinality predicates 
We first extend MS logic by constructing formulas with the help of the new 
atomic formulas of the form F i n ( X )  where X is a set variable. Such a for- 
mula is valid iff X denotes a finite set. We shall denote by M S f ( R , y )  the 
corresponding sets of formulas. We have M S ( R , Y ) c  M S f ( R ,  Y ) .  
This extension is of interest only in the case where we consider possibly infinite 
structures. In finite structures, F i n ( X )  is always true, and every formula in 
M S f ( R ,  Y )  can be simplified into one in MS(R,Y), that is equivalent in finite 
structures. Otherwise, we obtain a real increase of expressive power because the 
finiteness of a set is not, in general, MS-expressible. See Corollary 5.4.3 below. 
We wrote “in general” because in certain structures like binary directed trees, 
it is, as we shall see. 
We now introduce an extension of MS logic called counting monadic second- 
order logic and denoted by CMS. For every integer p > 2, for every set variable 
X ,  we let Card,(X) be a new atomic formula expressing that the set denoted 
by X is finite and that its cardinality is a (possibly null) multiple of p. We 
denote by C M S ( R ,  J J )  the extension of MSf(R, J J )  with atomic formulas of 
the forms Card,(X) for p 2 2, where X is a set variable. We have thus a 
hierarchy of languages M S  c M S f  c C M S .  We shall discuss cases where the 
corresponding hierarchy of graph properties is also strict. 
Lemma 5.4.1 
For each k E N ,  there is a first-order formula in FO(0, { X } )  expressing that 
the set denoted by X has cardinality k. 

5.4. THE EXPRESSIVE POWERS OF ... 
341 
Proof 
We only give the formula for k = 3: 
3 ~ 1 , ~ 2 , ~ 3 [ ~ 1  
EX AX^ EX AX^ E X A T X I  = 5 2 A l X 1  = x ~ A T x ~  
= X 3  A 
Vy(y E x ==+ 5 1  = y v 5 2  = y v 2 3  = y)]. 
0 
It follows that one can express in CMS that a set X is finite and has a cardi- 
nality of the form q + Xp for some X E N where 1 5 q < p: it suffices to write 
that for some Y and 2, X = Y U 2, Y n 2 = 0, Curd(Y) = q and Curd(2) is 
a multiple of p .  We now recall a result from Courcelle [Ill. 
Proposition 5.4.2 
Every formula cp E MS(0, { X I , .  . . , X,}) is equivalent to a finite disjunction 
of conjunctions of conditions of the forms Card(Y1 n Y2 n . . . n Y,) = m or 
Card(Y1 n Y2 n . . . n Y,) > m where m E N and, for each i = 1,. . . , n, Y, is 
either Xi or D - X i ,  where D is the domain of the considered structure. 
0 
By Lemma 5.4.1 the conditions Card(Y1 n Yz n ... n Y,) = m and Curd 
(Yl n Y2 n . . . n Yn) > m can be expressed by formulas in FO(0, {Yl, . . . , Y,}). 
This result shows that MS logic is equivalent to FO logic for “pure” finite or 
infinite sets. 
Corollary 5.4.3 
CMS is strictly more expressive than MS on finite sets. M S f  is strictly more 
expressive than MS on infinite sets. 
Proof 
Let us assume that a formula cp E MS(0, { X } )  can express, in every finite set 
D that a subset X of D has even cardinality. By Proposition 5.4.2, ‘p can be 
expressed as a disjunction of conditions of the forms: 
(1) Card(X) = m and Card(D - X )  = m‘, 
(2) Card(X) = m and Curd(D - X )  > m’, 
(3) Card(X) > m and Curd(D - X )  = m’, 
(4) Curd(X) > m and Curd(D - X )  > m’. 
We let M be the maximum integer m or m’ occurring in these conditions. 
No condition of the form (3) or (4) can appear because it can be valid for 
sets X with large enough odd cardinality. The remaining conditions imply 
that Card(X) 5 M .  But then cp is not valid for certain sets X with even 
cardinality larger than M. Contradiction. 

342 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
If we now assume that cp as above expresses that X is finite we also get a 
[7 
contradiction by the same case analysis. 
This proves that for finite structures, we have the hierarchy (where c indicates 
a proper increase of expressive power and = indicates an equivalent one) 
M S  = M S f  c C M S  
whereas for general (possibly infinite) structures we have 
M S  c M S f  c CMS. 
We shall now investigate classes for which these proper inclusions become 
equivalences. 
5.4.2 Linearly ordered structures 
We let C be the class of finite linear orders; we shall represent them by struc- 
tures of the form < D ,  ID> 
as explained in Subsection 5.3.1. 
Lemma 5.4.4 
For everyp 2 2 one can construct a formula y p ( X )  E M S ( { s } ,  { X } )  express- 
ing in every D € L that X has a cardinality equal to 0 modulo p. 
Pro0 f 
One can easily write a formula yp expressing the following: 
either X is empty or there exist sets Yl,. . . , Yp forming a partition of X and 
such that 
1. the first element of X is in Y1, 
2. the last element of X is in Y,, 
3. for every two elements z,y of X such that y is the successor of z for 
the restriction to X of the order S D ,  then, y E Yi+1 if z E Yi, for some 
i = l,... ,p, and y E Y1 if z E Yp. 
This lemma extends to any class C of finite structures on which a linear order 
is definable by MS-formulas. Let us define precisely this notion. 
Let C C S T R ( R )  for some finite set R of relation symbols. Let 60 E M S ( R ,  
{XI,... , X n } )  and O1 E M S ( R ,  {z1,z2,X1,... ,Xn}). We say that (QO,6Jl) 
defines a linear order on the structures of C if the following conditions hold, 
for every S E C: 

5.4. THE EXPRESSIVE POWERS OF ... 
343 
2. s i= VXl,..‘ ,X,[Bo =j V ~ , Y , z { ~ 1 ( 2 , ~ ) A ( 8 1 ( 2 , v ) A ~ 1 ( Y l , 2 )  
==+ 5 = Y) 
A (01 ( 2 ,  Y) v 61 (Y, 
.))>I. 
A(& ( 2 ,  Y) A 81 (v, .) =j 01 ( 2 ,  
In words this means that for every choice of sets D1, . . . , D, satisfying 80, the 
binary relation defined by 81 where X I , .  . . , X ,  take respectively the values 
D1,. . . , D, is a linear order on Ds, and that for every S E C, there is at least 
one such tuple from which a linear order is definable by 81. 
Proposition 5.4.5 
Let C be a class of finite structures on which a linear order is MS-definable. 
The CMS-expressible properties of the structures in C are MS-expressible. 
Proof 
We let R be such that C C STR(R). 
Let (QO(X1, . . . , X,), 81 (2, y, X I ,  . . . , X,)) be a pair of formulas that defines a 
linear order on every structure of C. Let ‘p E C M S ( R ,  8) express some property 
of the structures of C. We can assume that the variables X I , .  . . , X ,  have no 
occurrence in cp. For each p ,  we let 7; = -yp[81/ <] 
M S ( R ,  { X I ,  . . . , X,}) 
where -yp is from Lemma 5.4.4. For every S E C, for every D I ,  ... , D, C Ds 
satisfying 80, for every D C_ Ds then 
s i= Y p , D 1 , - .  ,Dn) 
iff Card(D) is a multiple of p .  
We let ‘p’ be obtained from ‘p by the replacement of every atomic formula 
Card,(Y) by $ [ Y / X ] .  We let then ‘p” be the formula of M S ( R , { X } ) :  
3x1,. . . ,x,[@o(xi,. 
. . , X,) A ‘p’(X, Xi,. . . , X,)]. 
If S i= cp”(D) then S 
60(D1,... ,Dn) for some I l l , . - .  ,D, and S t= 
‘p’(D, Dl,... ,Dn) hence S + ‘p(D) by the construction of 9’. 
Conversely, 
if S + p(D) then there exists (Dl;.. ,Dn) satisfying 00 hence S 
~ ‘ ( 0 ,  
D1,. . . , D,) and S 
‘p”(D). Hence ‘p is equivalent to ‘p” in every struc- 
ture S in C. 
0 
A directed tree is a directed graph, every vertex of which is reachable from 
some vertex (called the root) by one and only one path. (In particular it is 
connected and has no circuit). 

344 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
Proposition 5.4.6 
Let d E N .  One can define by means of MS formulas a linear order on [possibly 
infinite) directed trees of degree at most d, and more generally on forests 
consisting of at most d trees of degree at most d. 
Proof 
Let T be a directed tree given by the structure < VT,SUCT 
>. We denote by 
si- the reflexive and transitive closure of SUCT. A partition (V1, V2,. . . , Vd) of 
VT is good if no two successors of a vertex belong to a same set V,. If T has 
degree at most d (i.e., if each vertex has at most d successors) then VT has 
a good partition in d sets. From a good partition (Vl,. . . , Vd) of VT, we can 
define the following linear order: 
x 5 y iff either x <T y or there exist z,x',y' such that ZSUCTZ' 
<T 
x, 
ZSUCTY' <T y,x' E K, y' E V, and i < j .  
It is not hard to see that 5 is a linear order on VT. An FO1-formula 
&(XI ,.. . , X,) can express that a given d-tuple (V1, V2,. . . , Vd) of subsets 
of VT is good and an MS1-formula 61 (2, y, X I , .  . . , Xd) can express that x 5 y 
holds where Xi takes the value V, (for i = l,... , d )  and (Vl,... ,V,) is the 
good partition from which 5 is defined. (One can write 61 with the help of the 
formula 'p1 of Lemma 5.2.8.) 
Hence (60, 61) defines a linear order of VT (and even a topological sorting) for 
every tree T of degree at most d. The proof for forests is similar except that 
in the definition of a good partition, we require that the roots of two trees of 
0 
the forest do no belong to the same set V,. 
We refer the reader to Courcelle [IS] for extensions of this result to other types 
of graphs than forests. 
5.4.3 Finiteness 
We know that the finiteness of a set is not MS-expressible in general. However 
it is in certain structures. Let < D , Lo> be a linear order isomorphic to N. A 
subset X of D is finite iff it has a maximal element, which is FO-expressible. 
We shall use this observation in order to define classes of graphs in which 
finiteness is MS-expressible. For these classes of graphs the languages M S  and 
M S f  are thus of equal expressive power. 
Proposition 5.4.7 
Let 7 be the class of directed trees, each vertex of which has finite degree. The 
finiteness of a set of vertices of a tree in 7 is MS-expressible. 

5.4. THE EXPRESSIVE POWERS OF ... 
345 
Proof 
We represent a directed tree T by the structure T = < VT, SUCT >. We denote 
by rootT the root of T .  Every vertex is accessible from the root by a directed 
path. The ST-maximal elements of VT are the leaves and rootT is the unique 
+minimal 
element. 
For each nonempty X 
VT we let I ( X )  := {y E VT / y LT x,x E X }  be 
the ideal generated by X .  The graph T [ I ( X ) ]  is a directed tree and its root is 
rootT. 
Claim: X is infinite iff the tree T [ I ( X ) ]  has an infinite branch. 
Proof of Claim: Let (yo7y1,y2,... , y i , . . . )  be an infinite branch in T [ I ( X ) ] .  
We 
construct as follows an infinite sequence in X I  proving thus that X is infinite: 
1. we let xo E X be an element such that yo <T XO; 
2. having defined xj, we define xj+l as follows: we let i be such that yi is at 
a larger distance to the root than xj. We let then xj+1 be any element 
of X such that yi <T x~j+l. 
The elements XO, 
51 , . . . , xj, . . . of X are at strictly increasing distances to the 
root. Hence they are pairwise distinct and X is infinite. 
Conversely, if X is infinite then I ( X )  is infinite (since X C I ( X ) )  hence the 
tree T [ I ( X ) ]  has an infinite branch by Koenig’s lemma. 
Pmof of Claim 0 
We now complete the proof of the proposition. One can construct an MS 
formula O(X, Y )  expressing that, in a directed tree T :  
Y is linearly ordered by < T ,  and for every y E Y there is z E Y such that 
y <T z and z ST x for some x E X .  
It follows from the claim that a set X is finite iff O(X, Y )  does not hold for any 
set Y .  
0 
Corollary 5.4.3 and Propositions 5.4.6 and 5.4.7 yield the following result (we 
omit details): 
Corollary 5.4.8 
(1) Let d E N .  The languages MS, M S f  and CMS are equally powerful for 
expressing properties of trees of degree at most d. 
(2) The languages MS and M S f  are equally powerful for expressing properties 
of trees of finite degree, and the language CMS is strictly more powerful than 
them. 
0 

346 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
5.5 Monadic second-order definable transductions 
In this section, we use MS formulas in order to define certain graph transfor- 
mations, that are as important in the theory of context-free graph grammars 
as are rational transductions in language theory. 
A binary relation R 
A x B where A and B are sets, typically of words or 
of trees, can be considered as a multivalued partial mapping associating with 
certain elements of A one or more elements of B. It is called in this case a 
transduction: A + B. Transductions of words and trees, defined in terms of 
finite-state automata with output are essential in Formal Language Theory, es- 
pecially in constructions concerning context-free grammars. (See Berstel [4]). 
Does there exist an analogous notion for graphs ? Since there is no convenient 
notion of graph automaton, there is no “machine-based” notion of graph trans- 
duction. However, by using a classical technique of logic called “interpretation”, 
by which a structure is defined in another one, one can define transformations 
of structures, whence of graphs and hypergraphs via their representations by 
structures. The formulas defining a structure T inside another one S (or rather: 
inside the union of k disjoint copies of S )  will be MS formulas. 
5.5.1 Transductions of relational structures 
We first define (monadic second-order) definable transductions of relational 
structures. Let R and Q be two finite ranked sets of relation symbols. Let W 
be a finite set of set variables, called here the set of parameters. (It is not a 
loss of generality to assume that all parameters are set variables.) A (Q,R)- 
definition scheme is a tuple of formulas of the form: 
A =(‘p, ‘$1,. . . 7 $k, (Qw)wEQ*k) 
where k > 0, Q*k := ((4,;) I q E Q7;E 
[k]p(g)}, 
‘p E MS(R7 W ) ,  
$i E M S ( R , W u  ( 5 1 ) )  fori = I , . . .  , k ,  
8, E M S ( R , W U  { X I , . . .  ,zp(g)}),for w = (4,;) E Q*k. 
These formulas are intended to define a structure T in STR( Q )  from a structure 
S in STR(R) and will be used in the following way. The formula ‘p defines 
the domain of the corresponding transduction; namely, T is defined only if cp 
holds true in S for some assignment of values to the parameters. Assuming 
this condition fulfilled, the formulas $1, . . . , $k, define the domain of T as 
the disjoint union of the sets D1,. . . , Dk, 
where Di is the set of elements in 

5.5. MONADIC SECOND-ORDER DEFINABLE TRANSDUCTIONS 
347 
the domain of S that satisfy $, for the considered assignment. Finally, the 
formulas Om for 20 = (q,;),; E [k]P(Q) define the relation q ~ .  
Here are the 
formal definitions. 
Let S E STR(R), let y be a W-assignment in S. A Q-structure T with domain 
DT C: Ds x [k] is defined in (S,y) by A if 
6) (S7Y) I= cp 
(ii) DT = { ( d , i )  I d E D s , ~  
E [k], 
(S,y,d) b $2) 
(iii) for each q in Q: 
qT = {((dl,il),... 
7 ( d t , i t ) )  E D& I (S>y,d17‘.. , d t )  
+ 
where j = (21,. . . , it) and t = p(q). 
(By (S,y,dl,... , d t )  k O(4,;), we mean (S,y’) k O(q,;), where y’ is the as- 
signment extending y, such that y’(xz) = d, for all i = l,... ,t; a similar 
convention is used for (S, y, 
d) k $z.) 
Since T is associated in a unique way with S,y and A whenever it is defined, 
i.e., whenever (S,y) k cp, we can use the functional notation defA(S,y) for T. 
The transduction defined by A is the relation de fA := { (S, T) I T = de fA(S, 
y) 
for some W-assignment y in S }  C STR(R)xSTR(Q). A transduction f C 
STR(72) xSTR(Q) is definable if it is equal to de fa for some ( Q ,  72)-definition 
scheme A. In the case where W = 0, we say that f is definable without para- 
meters (note that it is functional). We shall refer to the integer k by saying 
that de fa is k-copying; if k = 1 we say that it is noncopying and we can write 
more simply A as (cp,$, ( O q ) q E Q ) .  In this case: 
DT = { d  E D s  I (S,y,d) t= $} and for each q in Q 
q T = { ( d l , ‘ . . d t )  E D& I (S,y,dl,...dt) 
bdq),wheret=p(q). 
Before applying these definitions to general hypergraphs, we give three ex- 
amples. Our first example is the transduction that associates with a graph 
the set of its connected components. A graph G is represented by I G 12 (see 
Section 5.3). 
The definition scheme A given below uses a parameter X .  It is constructed 
in such a way that defA(1 G 12,{x}) is the structure I G’ 12 where G’ is the 
connected component of G containing the vertex 2. We let (cp, $, O,,,) 
be the 
noncopying definition scheme where: 

348 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
cp is a formula with free variable X expressing that X consists of a unique 
vertex, 
+ is a formula with free variables X and 2 1  expressing that either q is a vertex 
linked by a path (where edges can be traversed in either direction) to the 
vertex in X ,  or x1 is an edge, one end of which is linked by such a path 
to the vertex in X ,  
6inc is the formula inc(zl,x2, z3). 
It is straightforward to verify that A is as desired. 
Our second example is the functional transduction that maps a word u in 
{a,b}+ to the word u3. (We denote by {a,b}+ the set of nonempty words 
written with a and b.) In order to define it as a transduction of structures, we 
represent a word u in {a, b}+ by the structure I( u I( defined in Subsection 5.2.1. 
We let A be the 3-copying definition scheme without parameter (y,$1,+2,$3, 
(e(suc,i,j))Z,j=1,2,3 
i (6(laba,i))Z=1,2,3> 
(O(labb,Z) )Z=1,2,3) such that: 
cp expresses that the input structure indeed represents a word in { a ,  b}+, 
$1 , $9, $3 are identical to the Boolean constant true, 
q s u c , i , j )  ( 2 1  1.2) 
is suc(.1,z2) 
if i = j ,  
8(suc,i,j) (xl , z2) expresses that x1 is the last position and that x2 is the first 
6(suc,i,j)(z1,z2) 
is the constant false if i # j and if (i,j) @ {(1,2), (2,3)}, 
O(lab,,i)(xl) is lab,(zl) for i = 1,2,3, 
O(labb,i) ( z l )  is labb(zl) for i = 1,2,3. 
one if i = 1 and j = 2, or if i = 2 and j = 3, 
We claim that defa(S) = T if and only if S is a structure of the form ( 1  u 11 
and T is the corresponding structure 11 u3 11. To take a simple example, if 
S = < {1,2,3,4}, sue, lab,, lab* > representing the word abba, then defa(S) 
is the structure 
where we write ij instead of (i, j ) ,  so that i, is the jth copy if i for j = 1,2,3 
and 

5.5. MONADIC SECOND-ORDER DEFINABLE TRANSDUCTIONS 
349 
suc’(i, , km) holds if and only if k ,  is the successor of ij in the above enumer- 
ation of the domain of T ,  
Zabh(ij) holds if i E {1,4},j E {1,2,3} and 
Zabb(ij) holds otherwise. 
This is an example of a definable transduction from words to words that is 
not a rational one. (This transduction will also be used as a counterexample 
in Proposition 5.5.8 below). 
Our last example is the product of a finite-state automaton A by a fixed finite- 
state automaton t?. A finite-state automaton is defined as a 5-tuple A = < 
A, Q ,  M ,  I ,  F > where A is the input alphabet, (there we take A = {a, b}), Q is 
the set of states, M is the transition relation which is here a subset of Q x A x Q 
(because we consider nondeterministic automata without &-transitions), I is 
the set of initial states and F is that of final states. The language recognized 
by A is denoted by L(A). The automaton A is represented by the relational 
structure: I A1 = < Q, trans,, transb, I ,  F > where trans, and transb are 
binary relations and: 
trans,(p, q) holds if and only if (p, a, q) E M ,  
transb(p, q) holds if and only if (p, b, q) E M .  
Let t? = < A, Q’, M‘, I’, F’ > be a similar automaton, and A x B = < A, Q x 
Q’, MI’, I x 1’, F x F’ > be the product automaton intended to define the 
language L(d)nL(t?). We let Q’ be (1,. . . , k }  (let us recall that 23 is fixed). 
We shall define a definition scheme A such that defA(1 Al) = I AxBI; it will 
be k-copying since the set of states of A x B  is Q x { 1 , .  . . , k}. We let A = 
( p , $ ~ , . . .  
, $ k , ( 6 w ) w ~ ~ * k ) ,  where R = {trans,,transb,I,F} and: 
cp is the constant true (because every structure in STR(R) represents an au- 
tomaton; this automaton may have inaccessible states and useless tran- 
sitions), 
$1 ,. . . , G k  are the constant true, 
6(trans,,i,j) 
(x1,22) is the formula trans, (x1 , 22) if (i, a, j )  is a transition of B 
and is the constant false otherwise, 
B(transb,i,j) is defined similarly, 
6(1,i)(x1) is the formula I(x1) if i is an initial state of 23 and is false otherwise, 
B ( F , ~ )  
(21) is defined similarly. 

350 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
Note that the language defined by an automaton A is nonempty if and only 
if there is a path in A from some initial state to some final state. This latter 
property is expressible in monadic second-order logic. Hence it follows from 
Proposition 5.5.5 below that, for a fixed rational language K ,  the set of struc- 
tures representing an automaton A such that L(A)nx is nonempty is definable. 
This construction is used systematically in Courcelle [17]. 
The definitions concerning definable transductions of structures apply to hy- 
pergraphs via their representation by relational structures as explained above. 
However, since we have two representations of hypergraphs by logical struc- 
tures, we must be more precise. We say that a hypergraph transduction‘, i.e., 
a binary relation f on hypergraphs is (i,j)-definable, where i and j belong to 
{I, 2) if and only if the transduction of structures {(I G li, I G’ l j )  / (G,G’) E 
f} is definable. We shall also use transductions from trees to hypergraphs. 
Since a tree t is a graph, it can be represented either by I t 11 or by I t 12. 
However, both structures are equally powerful for expressing monadic second- 
order properties of trees and definable transductions from trees to trees and 
from trees to graphs. (This follows from the proof of Theorem 5.3.4). When 
we specify a transduction involving trees (or words which are special trees) as 
input or output we shall use the symbol * instead of the integers 1 and 2, in 
order to recall that the choice of representation is not important in these cases. 
We shall use definable for (*,* )-definable. 
Here are a few facts concerning definable transductions of structures. 
Fact 5.5.1 
Iff is a definable transduction, there exists an integer k such that Card(DT) 5 
0 
k Card(Ds) whenever T belongs to f (S). 
Fact 5.5.2 
The domain of a definable transduction is MS-definable. 
0 
Proof 
Let A be a definition scheme as in the general definition with W = 
0 
The next two propositions list examples of transductions of words, trees and 
graphs that are definable. 
{ X I , . . .  ,X,}. Then D m ( d e f a )  = { S  / S 
 XI,... ,X,cp}. 
Proposition 5.5.3 
The following mappings are definable transductions: (1) word homomorphisms, 
(2) inverse nonerasing word homomorphisms, (3) gsm mappings, (4) the mirror- 
image mapping on words, (5) the mapping Xu.[un] where u is a word and n 
=Graphs are special hypergraphs. We shall speak of graph transduction if appropriate. 

5.5. MONADIC SECOND-ORDER DEFINABLE TRANSDUCTIONS 
351 
a fixed integer, (6) the mapping that maps a derivation tree relative to a 
fixed context-free grammar to the generated word, (7) linear root-to-frontier 
or frontier-to-root tree transductions. 
0 
The proofs are easy to do. Let us recall that a gsm mapping is a transduction 
from words to words defined by a generalized sequential machine, i.e., a (pos- 
sibly nondeterministic) transducer that reads at least one input symbol and 
outputs and a (possibly empty) word on each move. A special case of (5) has 
been constructed in detail in our second example before Fact 5.5.1. See Gecseg 
and Steinby [40] or the survey by Raoult [52] for tree transductions. 
Fact 5.5.1 which limits the sizes of the output structures, shows that certain 
transductions are not definable. This is the case of inverse erasing word ho- 
momorphisms and of ground tree transducers except in degenerated cases (see 
Dauchet et al. [28] or [52] on ground tree transducers). 
Proposition 5.5.4 
The transductions that associate with a graph G: (1) its spanning forests, (2) 
its connected components, (3) its subgraphs satisfying some fixed 2-definable 
property, (4) its maximal subgraphs satisfying some fixed MSz-definable prop- 
erty (maximal for subgraph inclusion), (5) the graph consisting of the union of 
two disjoint copies of G, (6) its minors, are all (2,2)-definable. The mapping as- 
sociating with a graph its line graph is (2,l)-definable but not (2,2)-definable. 
0 
We recall that the lane graph of a graph G has EG as set of vertices and has 
undirected edges between any two vertices representing edges sharing a vertex 
(in G). 
Proof 
Assertions (1)-(6) are easy consequences of the existence of an MS formula ex- 
pressing that two given vertices are linked by some path. See Section 5.2. Asser- 
tion (6) is proved in Courcelle [12]. In the last assertion, the (2,l)-definability 
is an easy consequence of the definition of a line graph. See [23] for the negative 
part of this assertion. 
0 
5.5.2 
The following proposition is the basic fact behind the notion of semantic inter- 
pretation ([51]). It says that if T = defa(S,p) 
i.e., if T is defined in (S,p) by 
A, then the monadic second-order properties of T can be expressed as monadic 
second-order properties of (S, p). The usefulness of definable transductions is 
based on this proposition. 
The fundamental property of definable transductions 

352 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
Let A = (cp, $1, . . . , ?)k, ( 8 w ) w E ~ * k )  be a (&, 72)-definition scheme, written 
with a set of parameters W .  Let V be a set of set variables disjoint from W .  
For every variable X in V, for every i = 1, . . . , Ic, we let Xi be a new variable. 
We let V':= { X i / X  E V ,  i = 1, .. . , k}. For every mapping q : V' + P(D), we 
let qk : V + P ( D  x [Ic]) be defined by q k ( X )  = q(X1) x (l}U...Uq(Xk) x { k } .  
With these notations we can state: 
Proposition 5.5.5 
For every formula /3 in M S ( Q , V )  one can construct a formula P' in 
MS(72,V'UW) such that, for every S in STR(R), for every assignment p : 
W+ S for every assignment q : V + S, we have: 
defA(S, 
p )  is defined (if it is, we denote it by T), qk is a V-assignment in T ,  
0 
and (T,qk) k P 
if and only if (S, q U p )  + p' . 
Note that, even if T is well-defined, the mapping rlk is not necessarily a V- 
assignment in T ,  because qk ( X )  is not necessarily a subset of the domain of T 
which is a possibly proper subset of D s  x [Ic]. 
Proof sketch 
Let us first consider the case where de fa is noncopying. In order to transform 
P into p', one replaces every atomic formula q(u1, . . .  ,u,) by the formula 
8, (ul, 
. . . , u,) which defines it in terms of the relations of S (See Lemma 5.2.5). 
One also restricts quantifications to the domain of T ,  that is, one replaces 
32[p] by 3x[$(s) A p] and 3 X [ p ]  by 3X[V'z{z E X 3 $J(Z)} A p]. (See 
Lemma 5.2.6). In the case where Ic > 1, one replaces 3 X[p ] by a formula of 
the form 3x1, 
3 X 2 ,  . . . ,3Xk [p'] where p' is an appropriate transformation of 
p based on the fact that X = XI 
x { l} U . . . U XI, 
x {Ic} . The reader will find 
0 
From this proposition, we get easily: 
Proposition 5.5.6 
(1) The inverse image of an MS-definable class of structures under a definable 
transduction is MS-definable. 
(2) The composition of two definable transductions is definable. 
Pro0 f 
(1) Let L C STR( Q) be defined by a closed formula P and de fA be a trans- 
duction as in Proposition 5.5.5. Then defi'(L) C STR(72) is defined by the 
formula 3Yl, . . . , Y, [P'] where Y1, . . . , Y, are the parameters and P' is con- 
structed from P as in Proposition 5.5.5. 
a complete construction in [13], Proposition 2.5, p. 166. 

5.5. MONADIC SECOND-ORDER DEFINABLE TRANSDUCTIONS 
353 
(2) Let A = (cp, $ 1 ,  . . . , $ k ,  ( 6 w ) w E ~ * k )  
be a k-copying definition scheme and 
A’ = (p’, q!(, . . . , +h,, ( 6 ? k ) w E p * k , )  be a k’-copying definition scheme such that 
d e f A  is a transduction from STR(R) to STR(Q) and defA1 is a transduc- 
tion from STR(Q) to STR(P). Let f be the transduction defntodefa from 
STR(R) to STR(P): we shall construct a definition scheme A” for it. Just to 
simplify the notation we shall assume that the parameters of A are Y and Y‘ 
and that those of A’ are Z and 2’. 
We shall also assume that the relations of 
P are all binary. The general case will be an obvious extension. 
In order to describe A” we shall denote by S an R-structure, we shall denote 
by T the Q-structure de fA(s, Y, Y’) where Y and Y‘ are subsets of DS and 
we denote by U the P-structure de fa! 
(T, Z,Z’) 
where 2 and 2’ 
are subsets of 
DT. Hence DT is a subset of DS x [k], and Du is a subset of Ds x [k] x [k’] 
which is canonically isomorphic to a subset of Ds x [kk’]. Hence A” will be kk‘- 
copying. The parameters 2 and 2’ 
represent sets of the respective forms Z = 
21 x { l} U . .  . U z k  x { k }  and 2’ 
= 2; 
x { l } U . .  . U Z i  x { k } .  Hence the definition 
scheme A” will be written in terms of parameters Y, Y’, 2 1 ,  . . . , Z k ,  zi, . . . ,zh. 
It will be of the form: 
so that the domain of Du will be handled as a subset of Ds x [k] x [k’] and not 
of Ds x [kk’]. The formulas forming A” will be obtained from those forming A’ 
by the transformation of Proposition 5.5.5. We first consider cp” which should 
express that d e f A ( S , Y , Y ’ )  is defined, i.e., that (S,Y,Y’) 
cp, and that if 
z = 2 1  x (1) U . . .  U z k  x { k }  and z‘ 
= 2: x {I} U ... U 2; x { k } ,  then 
d e f a ( T ,  2,Z’) 
is defined, i.e., that (T, 2,Z‘) cp which is equivalent to: 
where T is obtained from cp’ by the transformation of Proposition 5.5.5. Hence 
cp“ is the conjunction of cp and 7. We omit the constructions of the other 
0 
formulas because they are quite similar. 
We could define more powerful transductions by which a structure T would be 
constructed “inside” S x S instead of “inside” a structure formed of a fixed 
number of disjoint copies of S (like in [38]). However, with this variant, one 
could construct a second-order formula p‘ as in Proposition 5.5.5 (with quan- 
tifications on binary relations), but not a monadic second-order one (at least 
in general). We wish to avoid non monadic second-order logic because most 
constructions and decidability results (like those of [ll], [12]) break down. In 

354 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
the third example given before Fact 5.5.1, we have shown that the transduc- 
tion associating the automaton A x B with an automaton A is definable (via 
the chosen representation of finite-state automata by relational structures) for 
fixed B. 
Here are some other closure properties of the class of definable transductions. 
Proposition 5.5.7 
The intersection of a definable transduction with a transduction of the form 
A x B where A and B are MS-definable classes of structures, is a definable 
transduction. 
Proof 
Straightforward. See [13] 
0 
Proposition 5.5.8 
(1) The image of an MS-definable class of structures under a definable trans- 
duction is not MS-definable in general. 
(2) The inverse of a definable transduction is a transduction that is not defin- 
able in general. 
(3) The intersection of two definable transductions is a transduction that is 
not definable in general. 
Pro0 f 
(1) The transduction of words that maps a"b to anba"banb for n 2 0 is defin- 
able (this follows from Proposition 5.5.7 and the second example given before 
Fact 5.5.1). The image of the definable language a'b is a language that is not 
regular (and even not context-free), hence not definable by the result of Buchi 
and Elgot ([60], Thm 3.2) saying that a set of words is MS-definable iff it is 
regular. 
(2) The inverse of this transduction is not definable since, if it were, its domain 
is would be definable (by Fact 5.5.2), hence regular, which is not the case. 
(3) The intersection of the definable transductions of words that map anbm to 
cn, and anbm to cm is the one that maps anbn to cn. It is not definable because 
0 
its domain is not a an MS-definable (regular) language. 
5.5.3 Comparisons of representations of partial orders, graphs and hyper- 
graphs by relational structures 
We shall formulate in terms of definable transductions some transformations 
between several relational structures representing the same object . 

5.5. MONADIC SECOND-ORDER DEFINABLE TRANSDUCTIONS 
355 
Fact 5.5.9 
The transduction of < D , ID> into < D ,  SUCD > where < D ,  <D> is a partial 
order is definable, and so is its inverse. The transduction of I G ( 2  into I G 11 
0 
where G is a graph or a hypergraph is definable. 
It follows in particular from Proposition 5.5.6 that a class of finite partial orders 
is MS-definable w.r.t. one of the representations < D ,  <D> or < D ,  SUCD > 
iff it is w.r.t. the other (this has been already proved in Proposition 5.3.1). 
It follows also that a class of graphs or hypergraphs is MSz-definable if it is 
MS1-definable. We shall prove the converse for any subclass of C k ,  the class of 
simple directed graphs having a semi-strong k-coloring, where k is any (fixed) 
integer (see Subsection 5.3.2). 
Lemma 5.5.10 
Let k E N .  One can construct a definable transduction 6 k  that associates with 
I G 11 a structure T isomorphic to I G 12, for every graph G in C k .  
Pro0 f 
Let G be a simple directed graph with a semi-strong coloring y : VG -+ 
(1, ... , k } .  A mapping y : Vc -+ (1, ... , k }  can be specified by the k-tuple 
(v1 , . . . , v k )  of subsets of VG such that V, = y-'(i) for every z = 1,. . . , k. 
Thus a formula 7r E MS(R,, {XI,... 
, X k } )  can express that a given tuple 
(Vl, . . . , v k )  represents a semi-strong k-coloring. It follows that the class c k  is 
MS-definable (the corresponding formula is 7r' defined as 3x1, 
. . . , Xk . K ) .  
Let G E c k  and (V1, . . . , v k )  represent a semi-strong k-coloring. We let rep : 
EG -+ E C VG x (1;'. , k }  be the bijection such that: rep(e) = (w,i) iff 
e links w to w where w is a vertex in K. It is one-to-one since (VI ,. . . , v k )  
represents a semi-strong coloring (the origins of two edges with same target 
have different colors). We shall thus construct T isomorphic to I G 12 with 
domain VG x {0} LJ E g VG x {0,1, . . . , k }  as image of I G 1 1  by a definable 
transduction. We let A be the following definition scheme with parameters 
A = (7r1$0,$1,... ~ $ k , ( e ( i n c , j ) ) j ~ [ o , k ] ~ ) ,  
X I ,  ' ' ' , X k :  
where 7r has already been defined, and: 
$0 is: true 
?,ha is: 3w[w E Xi A edg(w,zl)], 
for i = 1, ... ,k 
6(inc,i,o,o) is: z1 = 23 A edg(z2 , 2 3 )  A z2 E X i  for i = 1, . . . , k and 
8(anc,n,m,p) 
is: false if n = 0 or m # 0 or p # 0. 

356 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
Claim: For every graph G in C k ,  for every k-tuple V1, . . . , v k  representing a 
semi-strong k-coloring of G, the structure de fa( I G 11, Vl, . . . , v k )  is isomorphic 
to I G 12. 
Proof of Claim: Let T = defA(1 G Il,vl,... 
,vk). 
Then L)T = VG x {O}UE 
from the definitions. From the definition of the formulas f?(inc,3) we have: 
n # 0 and m = p = 0 and edg(xz,x3) and 2 2  E X ,  and 2 1  = 2 3  iff 
n # 0 and m = p = 0 and rep(e) = ( 5 1 ,  n) where e is the edge of G that links 
x2 to 2 3 .  
Proof "j Clnrm 
It follows that I G l 2  is isomorphic to T by the isomorphism mapping u E VG 
onto (w,O) and e E EG onto rep(e). 
0 
((xl,n), (52,m), 
( 5 3 , p ) )  E incT iff 
The lemma follows immediately. 
From Lemma 5.5.10, one obtains immediately Lemma 5.3.5 because any two 
isomorphic structures satisfy the same formulas. 
5.6 
Equational sets of graphs and hypergraphs 
The easiest way to define context-free sets of graphs is by systems of recursive 
equations. These equations are written with set union and the set extensions 
of operations on graphs that generalize the concatenation of words. By these 
operations one can generate all finite graphs from elementary graphs more or 
less as one can generate finite nonempty words from the letters, by means of 
concatenation. This idea also applies to hypergraphs. In this section, we first 
present systems of equations in a general algebraic setting. Then we review 
the operations on graphs and hypergraphs that yield algebraic presentations 
of the VR sets of graphs and of the HR sets of hypergraphs in terms of sys- 
tems of recursive set equations. The grammatical definitions of these sets, by 
context-free graph grammars of various types are investigated in detail in other 
chapters of this book. The relevant operations are presented in a uniform way 
in terms of operations on structures. This will be helpful for obtaining theo- 
rems relating MS logic and context-free graph grammars. We also state logical 
characterizations of the VR sets of graphs and of the HR sets of hypergraphs 
from which follow closure properties under definable transductions. 
5.6.1 Equational sets 
As in many other works, we shall use the term magma borrowed from Bourbaki 
[7] for what is usually called an abstract algebra or an algebra. The words 

5.6. EQUATIONAL SETS O F  GRAPHS AND HYPERGRAPHS 
357 
“algebra” and “algebraic” are used in many different contexts with different 
meanings. We prefer to avoid them completely and use fresh words. Many- 
sorted notions are studied in detail by Ehrig and Mahr [31], Wirsing [64] and 
Wechler [63]. We mainly review the notation. We shall use infinite sets of sorts 
and infinite signatures, which is not usual. 
F-magmas 
Let S be a set called the set of sorts. An S-signature is a set F given with 
two mappings a : F -+ seq(S) (the set of finite sequences of elements of S ) ,  
called the arity mapping, and a : F -+ S ,  called the sort mapping. The length 
of a( f) is called the rank of f, and is denoted by p(f). The type of f in F is 
the pair ( a ( f ) , g ( f ) )  
that we shall rather write s1 x s2 x ... x s, 
-+ s where 
a ( f )  = (sl,... 
,s,) and u(f) = s. (We may have n = 0; in this case f is a 
constant). If S has only one sort, we say that F is a ranked alphabet, and the 
arity of a symbol is completely defined by its rank. 
An F-magma, i.e. an F-algebra ([31], [64], [63]), is an object M = < 
( M s ) s E ~ ,  
( f M ) f E F  >, where for each s in S, M, is a nonempty set, called the 
domain of s o r t s  of M ,  and for each f E F ,  the object f M  is a total mapping : 
M,(f) + M o ( f ) .  These mappings are called the operations of M .  (For a non- 
emptysequenceofsortsp= (sI;.. ,s,),welet Mfi := M s l x M s 2 x ~ ~ ~ x M s , , ) .  
We assume that M, n MSl = 0 for s # s’. We let M also denote U{M,/s E S}, 
and for d E M ,  we let a(d) denote the unique s such that d E M,. 
If M and M’ are two F-magmas, a homomorphism h : M + M‘ is a mapping 
h that maps M, into Mi for each sort s, and commutes with the operations of 
F .  We shall call it an F-homomorphism if it is useful to specify the signature 
F. We denote by T ( F )  the initial F-magma, and by T ( F ) ,  its domain of sort 
s. This set can be identified with the set of well-formed ground terms over F 
of sort s. If M is an F-magma, we denote by h M  the unique homomorphism: 
T ( F )  + M .  If t E T(F),, then the image o f t  under h~ is an element of M,, 
also denoted by t M .  One can consider t as a term denoting t M ,  and t M  as the 
value o f t  in M .  We say that F generates a subset M‘ of M if M‘ is the set 
of values of the terms in T ( F ) .  We say that M‘ is finitely generated if it is the 
set of values of terms in T(F’) where F‘ is a finite subset of F .  
An S-sorted set of variables is a pair ( X , a )  consisting of a set X ,  and a sort 
mapping a : X -+ S. It will be more simply denoted by X, unless the sort 
mapping must be specified. We shall denote by T ( F ,  X )  the set of well-formed 
terms written with F U X  and by T ( F ,  X ) ,  the subset of those of sort s. Hence, 
T ( F , X )  = T ( F  U X )  and T ( F , X ) ,  = T ( F  U X),. However, the notations 
T ( F , X )  and T ( F , X ) ,  are more precise because they specify the variables 

358 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
among the nullary symbols of F U X .  Let X be a finite sequence of pairwise 
distinct variables from X .  We shall denote by T(F, X),, the set of terms of 
T(F,X), having all their variables in the list X .  If t E T(F,X),, we denote 
by t M , X  the mapping: Mq(x) + M, associated with t in the obvious way, by 
letting a symbol f from F denote f
~
,
 
(where o ( X )  denotes the sequence of 
sorts of the elements of the sequence X ) .  We call t M , X  a derived operation 
of M .  If X is known from the context, we write t M  instead of t M , X .  This is 
the case in particular if t is defined as a member of T(F, { X I , .  
. . , Xk}),: the 
sequence X is implicitely ( 2 1 ,  . . . , zk). 
Power-set magmas and polynomial systems 
Let F be an S-signature. We enlarge it into F+ by adding, for every sort s in 
S ,  a new symbol +, of type: s x s -+ 
s, and a new constant R, of sort s. With 
an F-magma M we associate its power-set m a g m a :  
P ( M )  :=< (P(MS))SES, ( f P ( M ) ) f E F +  > 
where 
R S P ( M )  = 0 
Al + , p ( ~ )  
Az := A1 U A2 (for A I ,  A2 C M,), 
.-7J 
.- 
~ M ( A ~ , . . .  
,Ak), i.e.:= { f ~ ( a l , . . .  
, a k ) / a l  
E 
f p ( ? ~ f ) ( ~ l ,  
‘. . > A k )  
A],... ,ak E &} 
M,, , . . . , Ak 
for A1 
M,, where a ( f )  = ( ~ 1 , .  . . , s k ) .  (We denote by p g  
the set extension of a mapping 9.) 
Hence P ( M )  is an F+-magqa. A p o l y n o m i a l  s y s t e m  over F is a sequence of 
equations S = < u1 = p l ,  ..., u, = p ,  >, where U = ( ~ 1 , .  . . , u,} is an 
S-sorted set of variables called the set of unknowns of S. Each term pi is a 
p o l y n o m i a l ,  i.e., a term of the form 0, or tl +s 
t 2  +, ... +, t,, 
where the 
terms t j  are monomials of sort s = o(ui). A m o n o m i a l  is a term in T(F U V ) .  
The subscript s is usually omitted in +, and in 0,. A mapping S ~ ( M )  
of 
Ip(Mg(ul)) 
x ... x P(Mq(,n)) into itself is associated with S and M as follows: 
for A1 G M,(,,),... ,A, C Mq(,,,), 
we let 
SP(M)(Al, 
I . *  , A,) = (PlP(M)(AI,. 
., , An), 
- . *  ,PnP(M)(AI, ... , An)). 
A s o l u t i o n  of S in P ( M )  is an n-tuple ( A ] ,  . . . ,A,) such that Ai 
e a c h i = l ; . -  , n a n d  (A,,... ,A,)=Sp(M)(Al,--- 
,A,),i.e., 
Mq(,i) for 
Ai = p i p ( ~ ) ( A l , . . .  
,A,), for every i = 1,..- ,n. 
(5.2) 

5.6. EQUATIONAL SETS OF GRAPHS AND HYPERGRAPHS 
359 
A solution of S is also called a fixed-point of S ~ ( M ) .  
Every such system S 
has a least solution in P ( M )  denoted by (L(( S , M ) , u l) ,  ... ,L((S,M),u,)). 
(“Least” is understood with respect to set inclusion). This n-tuple can be 
concretely described as follows: 
where A: = 8 for all i = l,... ,n and ( A { + ’ , . . .  ,AA+l) = Sp,M,(A:,... 
,A;) 
The components of the least solutions in P ( M )  of polynomial systems are the 
M-equational sets. We denote by Equat(M) the family of M-equational sets 
and by Equat(M), the subfamily of those included in M,. 
We review the classical example of context-free grammars. Let A be a finite 
alphabet, say A = {al,. . . ,a,}. Let FA = A U {., E }  be the ranked alphabet 
where p(a,) = 0 for all Z , ~ ( E )  = O,p(.) = 2. We denote by W A  the FA- 
magma < A* , ., E ,  a l ,  . . . , a, > where A* is the set of words over A, . is the 
concatenation, E is the empty word, al,. . . , a, denote themselves as words. 
It is a monoid (with a binary associative operation having a unit) augmented 
with constants. The set Equat(WA) is the set of context-free languages over 
A. This follows from the theorem of Ginsburg and Rice [41] that characterizes 
these languages as the components of the least solutions of systems of recursive 
equations written with the nullary symbols E ,  a1 , . . . , a,, the concatenation 
and, of course, set union (denoted here by +). Take for example, the context- 
free grammar G = {u -+ auuv, u -+ awb, 
w + awb, w -+ ab} with nonterminal 
symbols u and w and terminal symbols a and b. The corresponding system of 
equations is: 
S = < u = a.(u.(u.v)) + a.(v.b),v = a.(v.b) + a.b > . 
We now give an example concerning trees. By a tree T we mean a finite con- 
nected undirected graph without multiple edges and cycles. The set of trees 
is denoted by 7. A rooted tree is a pair R = (T,r) consisting of a tree T and 
a distinguished node r called the root. The set of rooted trees is denoted by 
R. The set of nodes of a rooted or unrooted tree T is denoted by NT. Any 
two isomorphic trees are considered as equal. (The set of trees is actually a 
quotient set w.r.t. isomorphism but we shall not detail this technical point). 
We now define a few operations on trees and rooted trees. The types of these 
operations will be given in terms of two sorts, t and r ,  namely, the sort t of 
trees and the sort r of rooted trees. The first operation is the root gluing //: 
r x r -+ r. For S and T in 72, we let S//T be the rooted tree obtained by 
fusing the roots of S and T (or rather, of two disjoint isomorphic copies of S 

360 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
and T ) .  The second operation is the extension denoted by ext : r -+ r. For T 
in R, we let ext(T) be the rooted tree obtained from T by the addition of a 
new node that becomes the root of ext(T), linked by a new edge to the root 
of T .  We denote by 1 the rooted tree consisting of a single node (the root). 
Finally, we let f g  : r -+ t be the mapping that "forgets" the root of a rooted 
tree R. Formally, fg(R) = T where R = (T, r )  E R. 
Hence, we have an {r, t}-sorted signature F := {/I, ext, 1, f g }  and a many- 
sorted F-magma TREE having R as domain of sort r, T as a domain of sort 
t, and the operations defined above. Hence, T R E E  = < R, 7, //, ext, 1, f g  >. 
The set of trees of odd degree, i.e., such that the degree of every node is odd, 
is equal to L((S, TREE), u) where S is the system 
21 = fg(ext(u)) 
s = {  u = w//w + u//w//w 
w = ext(v) + ext(1) 
The sorts of u, 'u and w are t, r and r .  It is not hard to see that L((S, TREE), u) 
is the set of (finite) trees of odd dregree. As a hint observe that L((S, TREE), 
u )  is the set of rooted trees different from 1, all nodes of which except the root 
have odd degree, and that L((S, TREE), w) 
is the set of rooted trees such that 
all nodes have odd degree and the root has degree one. 
The following result is due to Mezei and Wright [48]. 
Proposition 5.6.1 
Let M and M' be F-magmas. If h : M + M' is an F-homomorphism, if S is 
a polynomial system over F ,  then L((S,M'),u) = h ( L ( ( S , M ) , u ) )  
for every 
unknown u. 
Pro0 f 
The homomorphism h : M + M' extends into an F+-homomorphism Ph : 
P ( M )  + P(M') defined by ph(A) = {h(a)/a E A} for A C M S , s  E S. It is 
easy to verify that for every j E N :  
where of course Ph(A1,... ,A,) 
= 
( p h ( A l ) , . . .  ,Ph(A,)) for every 
A l , . . .  , A ,  C M .  (The proof is by induction on j, using the fact that Ph 
0 
is an F+-homomorphism) . The result follows immediately. 
Here is a consequence of Proposition 5.6.1. (We recall that h M  denotes the 
unique homomorphism T ( F )  -+ M ) .  

5.6. EQUATIONAL SETS OF GRAPHS AND HYPERGRAPHS 
361 
Corollary 5.6.2 
For every polynomial system S and for every unknown u of S we have 
L((S,M),u) = h,w(L((S,T(F)),u)). The emptiness of L((S,M),u) depends 
0 
only on S and u and is decidable. 
This means that an equational set, defined as a component of the least solution 
of a polynomial system S ,  is the image of the corresponding component of 
the least solution of S in the F-magma of terms T(F), under the canonical 
homomorphism. Hence the study of the equational subsets of M can, in a sense, 
be reduced to the study of the equational sets of terms and the homomorphism 
h M .  In particular, the emptiness of L((S,T(F)),u) can be decided by tree 
automata techniques (see below); by the first assertion this set is nonempty iff 
L( (S, M ) ,  u) is nonempty, where M is any F-magma. 
Sets of terms can be defined in several ways, by grammars of various types, 
by automata (usually called "tree automata"), or in terms of congruences on 
the magmas of terms T(F). Of special importance is the class of recogniz- 
able subsets of T(F) characterized in terms of finite-state tree automata, of 
regular tree-grammars, of congruences having finitely many classes and also 
of monadic-second order formula. (See Courcelle [22]). We do not recall these 
characterizations here; we only refer the reader to the book [40] for automata, 
grammars and congruences and to [60], Theorem 3.2 for the characterization 
in terms of MS formulas. 
In this section, we shall use the following result by Mezei and Wright [48], [40]. 
Proposition 5.6.3 
Let F be a finite signature. A subset of T(F) is equational iff it is recognizable. 
0 
The main part of its proof is the determinization of finite-state frontier-to-root 
tree-automata. 
Corollary 5.6.4 
Let M be an F-magma (where F may be infinite). A set L is M-equational 
iff L = h M ( K )  for a recognizable subset K of T(F') where F' is a finite 
subsignature of F .  
0 
If t E K and m = h ~ ( t )  
then t is a syntactic description of m, m is the value 
of t in M .  If m E L is given, the parsing problem relative to the system of 
equations (equivalently the grammar) from which K comes, consists in finding 
t in K such that m = h M ( t ) .  If such t does not exist, then m $! L. Otherwise 
the found t is the desired syntactic analysis of m. 

362 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
5.6.2 Graphs with ports and VR sets of graphs 
Graphs will be simple and directed, as in Section 5.2. They will have dis- 
tinguished vertices called ports and designated by special labels. We let C 
be a countable set called the set of port labels. A graph with ports is a pair 
G = < H,P > where H is a graph and P 
VH x C for some finite subset 
c of c. We denote P by pGTtG, VH by VG, EH by EG, incH by incG and edgH 
by edgG. We let also Go denote H .  A vertex u is a p-port if ( v , p )  E porto. We 
consider p as a label attached to v and marking it as a pport. A vertex may 
have several port labels. We let T(G) be the set of labels of ports of G and we 
call this set the type of G. 
We denote by GP(C) the class of graphs with ports G such that r(G) C C 
where C is a subset of C. We let GP denote the class of all graphs with ports. 
We now define some operations on GP. If G,G‘ E GP and G,G‘ are disjoint 
(i.e., VG n VG, = 0) then G @ G’ is the disjoint union of G and G’, and is 
defined as < Go U G’”, POrtG UpOrtGJ >. Clearly T(G @ GI) = T(G) U T(G’). 
The next operation adds edges to a given graph with ports. If p , q  E C and 
G E GP, we let add,,,(G) =< H,portG > where H is Go augmented with the 
edges ( x , y )  such that: 
x is a p-port, y is a q-port, x # y ,  (2, y )  is not already an edge of Go. 
Hence H is simple and the operation add,,, does not add loops to G. The 
type of addp,q(G) is equal to that of G and addP,,(G) = G if G has no p 
port or no q-port. Let us note finally that the number of edges added to G by 
add,,, depends on the numbers of pports and of q-ports and is not uniformly 
bounded. 
A third operation will be useful, in order to modify port labels. Let P be a 
finite subset of C x C. For G E GP we let: mdfp(G) = < Go,portG.P >. A 
vertex u is a q-port of mdfp(G) iff it is a p-port of G for some p such that 
(p,q) E P. We have T(rndfp(G)) = { q  / ( p , q )  E P for some p E r(G)}. Two 
special cases of this operation will be useful and deserve special notation: if 
C is a finite subset of C, we let for G E GP(D), fgc(G) = rndfp(G) where 
P = {(d,d) / d E D - C}: this operation “forgets” the p-ports for p E C. It 
simply “removes” the label p on the p-ports for each p E C; hence T(fgc(G)) = 
T(G) - c. 
If pl,p2,. . . , p k ,  41,. . . , q k  are labels in c with P I , .  ‘. ,pk pair- 
wise distinct, we let for G € GP(D), re72pl--tql,paiq2, 
. . . , p r . ~ q k ( G )  
= rndfp(G) 
operation “renames” the port labels pi into qi, for all i = l,... ,k. Hence 
where p = ((44 / d E D - {Pl,... , P k ) )  u { h , q 1 ) , . . .  ,(Pkr4k)). This 
T(renpl--tqr,... ,pr.+qk (G)) = (7(G) - {PI,. 
’ .  , ~ / c > )  U {qi / Pi E T(G), 1 L i 5 k}- 

5.6. EQUATIONAL SETS OF GRAPHS AND HYPERGRAPHS 
363 
Equational sets of graphs with ports 
Having defined operations on GP we can now write systems of equations in- 
tended to define equational subsets of GP. Here is an example. The equation 
u = P + ren,+p(addp,q(U 
Q ) )  
where p denotes the graph with a single vertex that is a pport, and similarly 
for q, is intended to define (in the sense of Subsection 5.6.1) the set of finite 
tournaments without circuits, all vertices of which are pports. However we are 
facing a difficulty: the operation @ is partial because G $ G’ is defined if and 
only if G and G’ are disjoint. It follows for instance that G $ G is undefined. 
We can make @ into a total operation by letting G’ be “replaced in G @ G’ 
by an isomorphic copy Gi disjoint with G”. But now comes another difficulty: 
we may have G @ (G’ $ Gi) not equal to (G @ G‘) @ G{ (depending on how 
the isomorphic copies of the second arguments of the operations $ are chosen) 
which is clearly unsatisfactory. However they are isomorphic and, actually, we 
are interested in properties of graphs that are invariant under isomorphism. 
Let us call concrete a graph in GP and abstract the isomorphism class of such 
a graph. We shall denote by GP the class of abstract graphs with ports. We 
have thus a magma structure on GP because isomorphism is a congruence for 
the operations $, mdfp and add,,,. Graph grammars and systems of equations 
define subsets of GP. Logical formulas do the same because any two isomorphic 
relational structures satisfy the same formulas of any of the logical languages 
we have considered. However, in order to simplify the presentation we shall 
omit the distinction between GP and GP, and we shall do as if @ was total on 
GP. 
We 
let 
FVR denote 
the 
set 
of 
all 
operations 
@,mdfp, fgc, 
Tenp,+ ,,,... ,pk+,lo,addp,, together with the constants p and pe for p E C. If 
K c C, we denote by FvR(K) the subset of FVR consisting of the above 
operations such that P 5 K x K, C c K,pl , q1 ,.. . , p k ,  q k , p ,  q E K. The 
constant pe denotes a graph consisting of one loop, the unique vertex of which 
is a psource. A term in T(FvR) will be called a VR-(graph) expression. It 
denotes a graph with ports (actually an element of GP to be precise). We 
shall denote this graph by waZ(t) for t E T(FvR). 
Proposition 5.6.5 
Every finite graph with port G is the value of some VR-expression in 
T(FvR(K)) where Card(K) 5 Maz{Card(Vc), Card(T(G))}. 

364 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
Proof sketch 
For each vertex w of G one chooses a port label p(w) (a different one for each 
vertex). One defines then G by: 
G = mdfp( ...~dd,(~),,(~~)(...(... 
@ p ( ~ )  
@ ...))) 
where the sum ... @p(w) @ ... extends to all w E VG, the operations addp(v),p(v,) 
are inserted for all edges from w to w’ and P is the set { (p(v), q)/(v, q) E portc}. 
One uses p(w)[ instead of p(v) if w has a loop. We omit further details. 
A complexity measure on graphs follows from this definition: 
c(G) = Mzn{Card(K)/G = v d ( t ) ,  t E T(FvR(K))} 
This complexity measure is investigated in Courcelle and Olariu [as]. In par- 
ticular it is compared with tree-width (defined below in Subsection 5.6.3). 
An equational subset of GP will be called a VR set of graphs. Here VR stands 
for “Vertex-Replacement” and refers to the generation of the same sets by cer- 
tain context-free graph grammars. These grammars are considered in chapter 1 
of this book. (The equivalence between equational systems on GP and these 
grammars was first proved in Courcelle et al. [24]). 
A logical characterization of the VR sets of graphs 
We obtain immediately from Corollary 5.6.4 that: 
a set of graphs with ports L is VR iff it is the set of values of the VR-expressions 
of 
a recognizable set K 
T(FvR(C)) 
for some finite set C 5 C. 
We have already recalled the theorem of Doner, Thatcher and Wright sta- 
ting that a subset of T ( F )  (where F is finite) is recognizable iff it is MS- 
definable (see Thomas [60], thm 11.1). We shall now prove that the mapping 
val : T(FvR(C)) 
+ GP is a definable transduction (see Section 5.5). More 
precisely: 
Proposition 5.6.6 
Let C be a finite subset of C .  The mapping wal : T(FvR(C)) 
+ GP(C) is 
(*, 1)-definable. 
Pro0 f 
A term t E T(FvR(C)) 
is considered as a finite directed tree the nodes of 
which are labelled in F = FvR(C) and represented by the structure I t I = 
< Nt, suc1, SUCZ, ( l a b j ) j E F  > where 

5.6. EQUATIONAL SETS OF GRAPHS AND HYPERGRAPHS 
365 
Nt is the set of nodes, 
suc1(z, y) :U 
y is the first (leftmost) successor of 2, 
suc2(z, y) :U y is the second successor of z, 
labf(z) :U f is the label of z. 
The nodes have at most two successors since the symbols in F have arity at 
most 2 (@ has arity two and all others have arity 1 or 0). A graph G in SP(C) 
is represented by the structure I G 1 1  
< VG, edgG, (ptcG)cEc > where 
VG is the set of vertices, edgG is the set of edges (edgc C VG x VG), p t c ~  
is 
the set of c-ports for c E C. We let R,(C) = {edg} U {ptc/c E C}. 
Let us now consider t E T(FvR(C)) 
and G = waZ(t) E SP(C). We shall 
define VG as a subset of Nt, edgG as a binary relation on Nt (such that edgG 
VG x VG), 
the sets PtcG as subsets of VG (hence of Nt), all this by MS-formulas. 
We take VG equal to the set of leaves o f t  (i.e., of nodes without successors). 
If t has no symbol m d f p  or Tenp+,,,... then we can define: 
edgG = { (2, y) E N t / z ,  y are leaves, x has label p ,  y has label q, there is a node 
z in Nt labelled by add,,,, a path from z to z on which there is no symbol 
f g c  with p E C and a path from z to y on which there is no symbol f g c  with 
= 
4 E c.1 
Let us take the following example: 
There are 6 leaves, x1,x2,. 
. . , z6 corresponding respectively to the constants 
p ,  q,p, q, q, r in t. Because of the “add,,,” operation there is an edge from 2 1  to 
z2 but there is no edge from 2 3  to xz because of the “fg{,}” operation which 
“kills” the label p of z3. 
The general construction must handle the fact that the operations rndfp (and 
Ten,+,,...) 
can modify certain port labels. Hence if z is a leaf of t with label 
p ,  if y is an ancestor of z then z is a vertex of the graph val(t/y) (where we 
denote by t/y the subterm o f t  corresponding to the subtree issued from node 
y) but it may not be a p-port: it may be a q-port with q # p or be not a 
port. In the last example 5 3  is not a p-port of vaZ(t). The construction can 
be completed with the help of the following lemma. We shall omit all further 
details. 
0 

366 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
Lemma 5.6.7 
We fix C as in Proposition 5.6.6. For each p E C,one can construct a formula 
cpp(x,y) such that, for everyt E T(FvR(C)) and x,y E Nt: 
iff x is a leaf, y is an ancestor of x in the tree t and x is a p-port of vaZ(t/y). 
Proof 
Without loss of generality we let C = {l,... 
,n} and p = 1. Let us take 
t E T(FvR(C)); 
let x be a leaf of t and y an ancestor of x. There exists a 
unique n tuple of sets XI, . . . , X, satisfying the following conditions: 
It I 
l=cpu?p(x,Y) 
(1) X1 U . . . U X ,  is the set of nodes of t of the path from y to x, 
(2) for every i = 1,. . . , n : x E X i  iff x has label i (in t), 
(3) for every z with y ST z <T x (see Section 5.3 for notation) for every 
i = 1,. . . ,n, letting z’ be the successor of z such that z’ <T x we have: 
z E Xi iff 
(3.1) either z has label @ or addj,jl for some j , j ’  and z‘ E Xi 
(3.2) or z has label m d f p  for some P C C x C and ( j , i )  E P for some j and 
(Since fgc and Ten.,. are special cases of m d f p  this last case also applies to 
them). It is clear that for every z with y ST z ST x,x is an i-port in vaZ(t/z) 
iff z E Xi. 
Conditions (1) (2) (3) above can be expressed by an h1S formula 
$(x, y, X I , .  . . , X,). The desired formula is thus ‘pp(x, y) defined as 
z‘ E xj. 
where @(x, y) expresses that x is a leaf and y is an ancestor of x. 
0 
We denote by B the set of finite binary directed trees. Formally (and more 
precisely) B = T (  { f, u } )  where f is a binary function symbol and a is nullary. 
Theorem 5.6.8 ([33], [15]) 
Let C be a finite subset of C. A subset of GP(C) is V R  iff it is the image of B 
under a (*, l)-definable transduction. 
Pro0 f 
“Only if”. From Corollary (5.6.4), one obtains that if L is a VR set then 
L = vaZ(K) where K is a recognizable subset of T(FvR(C)). 
By Doner et 

5.6. EQUATIONAL SETS OF GRAPHS AND HYPERGRAPHS 
367 
81,’s theorem, K is MS-definable and val is (*,l)-definable. It follows that 
L is the image of T(FvR(C)) 
by a (*, 1)-definable transduction (namely the 
restriction of val to K ,  see Proposition 5.5.7). The classical encoding of terms 
by binary trees can be adapted and yields a bijection k of K onto a definable 
subset K’ of B such that k and k-’ are both (*, *)-definable (See [23], Lemma 
2.4 for details). It follows that L is the image of B under a (*, 1)-definable 
transduction, namely the restriction of val o k-’ to K’. 
“If”. The proof is quite complicated and we refer the reader to [33] or [15], 
Corollary 4.9. 
0 
Corollary 5.6.9 
The family of VR sets of graphs is closed under (1,l)-definable transductions. 
Proof 
Immediate consequence of Theorem 5.6.8 and the fact that the composition of 
0 
two (1 ,l)-definable transductions is (1,l)-definable. 
It follows for instance that the set of connected components of the graphs of a 
VR set is a VR set. 
5.6.3 
This section is fully analogous to the preceding one. We present operations on 
hypergraphs upon which the (context-free) HR ( “Hyperedge Replacement”) 
hypergraph grammars can be defined as systems of equations. 
Hypergraphs have been defined in Section 5.3.3. We assume that the ranked 
set A of hyperedge labels is fixed and we shall not specify it in notation. We 
shall use operations on hypergraphs needing to distinguish certain vertices by 
means of labels. We let C be a fixed countable set of source labels, not to be 
confused with the set of hyperedge labels A. 
A hypergraph with sources is a pair H =< G, s > consisting of a hypergraph G 
and a total mapping s : C -+ VG called its source mapping, where C is a finite 
subset of C. We say that s(C) 
VG is the set of sources of H and that s(c) is 
its c-source where c E C. We shall also say that the vertex s(c) has source label 
c. A vertex that is not a source is an internal vertex. The set C is called the 
type of H and is denoted by T ( H ) .  The source mapping of H is also denoted 
by S T c H .  This mapping is not necessarily injective. 
We shall denote by NS(C) the class of all hypergraphs of type C and by 
XSd(C) the subclass of those having distinct sources, i.e., that have an injective 
source mapping. 
Hypergraphs with sources and H R  sets of hypergraphs 

368 
CHAPTER Fi. THE EXPRESSION OF GRAPH PROPERTIES ... 
We shall use the set S of finite subsets of C as a set of sorts. We now define 
some operations on hypergraphs with sources. These operations will form an 
S-signature. Note that S is infinite. The definitions will be given here directly 
in terms of abstract hypergraphs (i.e., of isomorphism classes of hypergraphs). 
(1) Parallel composition 
If G E XS(C) and G' E XS(C') we let H = G//c,clG' be the hypergraph 
in XS(C U C') obtained as follows: one first constructs a hypergraph H' by 
taking the union of two disjoint hypergraphs K and K' respectively isomorphic 
to G and G', and by fusing any two vertices u and v' that are respectively the 
c-source of K and the c-source of K' for some c E C n C'; the hypergraph H 
is defined as the isomorphism class of HI. Clearly, H does not depend on the 
choices of K and K'. We shall use the simplified (overloaded) notation G//G' 
when C and C' are known from the context or are irrelevant. We say that 
G//G' is the parallel composition of G and GI. In the case where G and G' 
have distinct sources, we have the following characterization: 
a hypergraph H of type T(G) U T(G') is isomorphic to G//G' if and only if H 
has subhypergraphs K and K' respectively isomorphic to G and G' such that: 
VK U VKJ = VH, EK U EKJ = EH, 
EK n E K ~  
= 0 and VK n V K ~  
is the set of 
sources of H that have label c where c E C n C'. 
(2) Source renaming 
For every mapping h : C -+ C', we let renh : XS(C') -+ X S ( C )  be the 
mapping such that renh(< G,s >) =< G,s o h >. In other words, the c- 
source of Tenh(G) is defined as the h(c)-source of G. If a vertex u of G is a 
c-source with c E C' - h(C) and is not a c'-source for any c' in h(C), then 
it is an internal vertex in renh(G). We shall say that renh(G) is the source 
renaming of G defined by h. Note that when we write renh, we assume that 
h is given together with the sets C and C', so that the type of renh (namely 
C' -+ C) is defined in a unique way. Nevertheless, we shall use the overloaded 
notation rena for renh when h is the empty mapping: 0 -+ C and C need not 
be specified (or is known from the context). 
(3) Source fusion 
For every set B, we denote by Eq(B) the set of equivalence relations on B. 
Let C be a subset of C. For every S E Eq(C) we let fuses be the mapping 
%S(C) -+ XS(C) such that: 
H = fusea(G) if and only if 
VH = VG/ -, where - is the equivalence relation on VG generated by the set 
of pairs {(sTcG(~), s ~ c G ( ~ ) )  
I ( i , j )  E 6}, 

5.6. EQUATIONAL SETS OF GRAPHS AND HYPERGRAPHS 
369 
E H  = E G ,  
vertH(e,i) = [vertG(e,i)], where [v] denotes the equivalence class of v with 
respect to -, 
[v] is a c-source of H whenever some v' - v is a c-source of G. 
Intuitively, H is obtained from G by fusing its c- and c'-sources for all c,c' 
for which c' is &equivalent to c. We shall say that H is obtained from G by a 
source fusion. 
For every p E C ,  we denote by p the graph with a single vertex which is the 
psource. Hence p E X S (  { p } ) .  For every a E A, for every pl , . . . , p ,  E C where 
n = ~ ( a ) ,  
we denote by a ( p l , . . .  ,p,) the hypergraph consisting of a single 
hyperedge with label a and a sequence of vertices (q, 
. . . , 2,) 
such that xi is 
the pi-source for every i = l,... ,n. Note that we have xi = xj iff pi = p j .  
We let FHR be the S-signature consisting of //c,ct, 
fuse8, renh, p ,  
a(p1,. . . ,pn) for all relevant C, C', S, h , p ,  a , p l , .  . . ,p,. For K C C ,  we de- 
note by FHR(K) 
the subsignature consisting of the above symbols with 
C, C' C K , p , p l , .  . . , p ,  E K etc ... We obtain thus an FHR-magma XS.The 
terms in T(FHR) are called the HR(hypergraph)-expressions. Each of them, say 
t ,  denotes a hypergraph val(t) in X S  called its value. (Hypergraph expressions 
based on different operations were first introduced in [3]). 
Clearly  PI,... ,P,) E X S ( { p l , . - .  , P , } ) .  
Proposition 5.6.10 
Every finite hypergraph in ZS(C) is the value of some HR-expression in 
T(FHR)c. 
Proof 
Quite similar to that of Proposition 5.6.3. One takes a source label p ( v )  for 
each v E VG. One defines G by an HR-expression of the form 
where VG = ( 2 1 1 , .  . . , w m }  and the expression contains one factor a(p1, . . . , p,) 
0 
for each hyperedge. We omit the details. 
The minimum cardinality of C 
C such that G = vaZ(t) for some t E 
T(FHR(C)) is connected with an important complexity measure on graphs 

370 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
and hypergraphs called treewidth. We refer the reader to [53] and to [20], The- 
orem 1.1 for more details. We only indicate that the minimum cardinality of C 
such that G = waZ(t),t E T(FHR(C)) 
is Maz{Card(r(G)),twd(G) + l} where 
twd(G) denotes the tree-width of G. 
A subset of %S(C) is called an HR set of hypergraphs iff it is %S-equational. 
The terminology HR refers to an equivalent characterization in terms of “Hy- 
peredge Replacement grammars” studied in chapter ?? of this book. 
We give here the example of series-parallel graphs. We shall use the source 
labels 1, 2, 3, and one edge label a of type 2. We define from the operations of 
FHR({ 1,2,3)) the following operations: 
G//G’ = G//c,cG’ where C = {1,2) and G,  G‘ E %S(C) 
where h : {1,2) + {1,3) maps 1 C) 1 and 2 +-+ 3, and h’ : {2,3) + {1,2) maps 
3 e 
2 and 2 C) 1. The equation 
G.G‘ = r e n h ( G / / ( 1 , 2 } , { 2 , 3 } r e ~ ~ ~  
(G‘)) 
21 = u / / u  + u.u’ + u(l,2) 
defines the class S P  of series-parallel graphs. (These graphs are directed and 
all their edges are labelled by u). 
A hypergraph H E XS(C) will be represented by the relational structure 
I H 12 = < VH U EH, ( i n c , ~ ) , ~ ~ ,  
( ~ s , H ) ~ ~ c  
> where i n c , ~  
has been defined 
in Section 5.3.3 and: ~ s , H ( x )  
is true iff z is the c-source. Hence I H 12 E 
STR(R,(A,C)) where R,(A,C) = Rm(A) U {ps,/c E C} and each ps, is 
unary. Clearly H and H’ are isomorphic iff I H 12 and I H’ 12 are isomorphic. 
Proposition 5.6.11 
Let K be a finite subset of C and C C K .  The mapping wal : T(FHR(K))c 
+ %S(C) is a (*, 2)-definable transduction. 
Pro0 f 
We refer the reader to Courcelle [13], Lemma 4.3, p. 177. 
0 
Theorem 5.6.12 
Let C be a finite subset of C. A subset of US(C) is H R  iff it is the image of 
the set of finite binary trees B under a (*, 2)-definable transduction. 
Proof 
The “only if” direction follows from the preceding proposition like that of 
Theorem 5.6.8 from Proposition 5.6.6. The “if” direction is quite difficult to 
0 
prove and we refer the reader to Courcelle and Engelfriet [23]. 

5.6. EQUATIONAL SETS OF GRAPHS AND HYPERGRAPHS 
371 
Corollary 5.6.13 
The family of H R  sets of hypergraphs with sources is closed under (2,2)- 
definable transductions. 
Proof 
Similar to that of Corollary 5.6.9. 
0 
Here are some examples of (2,2)-definable transductions that are meaningful 
in graph theory: the transduction from a graph to its spanning trees, or of a 
hypergraph to its connected components, or of a graph to its maximal planar 
subgraphs. (See Proposition 5.5.4 for other examples). 
Corollary 5.6.14 
The set of line graphs of the graphs of an HR set is a VR set of graphs. 
Proof 
Immediate consequence of Theorems 5.6.8 and 5.6.12 and the last assertion of 
Proposition 5.5.4. 
0 
We collect below some properties, the proofs of which are too long to be in- 
cluded in this chapter. The reader will note that the statements do not concern 
logic but only graph properties. However monadic second-order logic is an es- 
sential tool for the proofs. We denote by und(G) the undirected graph obtained 
from G by forgetting the orientations of edges. 
Theorem 5.6.15 
Every HR set of simple directed graphs is VR. Conversely, for a VR set L of 
directed graphs, the following conditions are equivalent: 
1. L is H R  
2. there exists an integer k such that Card(&) 5 k.Card(V,) for every 
G E L, 
not a subgraph of und(G) for any G E L. 
3. there exists an integer n, such that the complete bipartite graph Kn,n is 
0 
Proof hints: The first assertion is an easy consequence of Theorems 5.6.8 and 
5.6.12 because the transduction {(I G 12, I G 11) / G is a graph} is definable 
lone can also say that the identity on simple directed graphs is (2,1)-definable; 
see Fact 5.5.9). 
Implications (1) + (2) and (1) + (3) follow easily from general properties of 
HR sets of graphs (see chapter ?? in this book). The implications (2) + (1) 
and (3) 
(1) are difficult: see Courcelle [19]. 
0 

372 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
One can extend Theorem 5.6.15 as follows. A set L 
R(A) of simple hy- 
pergraphs (without sources) is said to be VR iff it is the image of B under a 
(*, 1)-definable transduction. Hence we use here the characterization of Theo- 
rem 5.6.8 of VR sets of graphs and we make it into a definition of VR sets of 
hypergraphs. (Equivalent characterizations in terms of systems of equations can 
be found in Courcelle [15], Thm 4.6 but no equivalent context-free grammar, 
based on appropriate rewriting rules has yet been defined.) 
For every hypergraph H we denote by K ( H )  the undirected graph obtained 
by substituting a complete undirected graph K ,  for every hyperedge of type 
m. 
Theorem 5.6.16 ([19]) 
Every H R  set of simple hypergraphs is VR. Conversely, for every VR set L of 
simple hypergraphs, the following conditions are equivalent: 
1. L isHR, 
2. there exists an integer k such that Card(EH) 5 k.Card(VH) for every 
H E L, 
3. there exists an integer n such that Kn,n is not a subgraph of K ( H )  for 
any H E L. 
Again, the only difficult implications are (2) + (1) and (3) + ( I ) .  
0 
5.7 Inductive computations and recognizability 
The notion of a recognizable set is due to Mezei and Wright [48]; it extends 
the notion of a regular language like the notion of an equational set extends 
that of a context-free one. It was originally defined for one-sort structures, 
and we adapt it to many-sorted ones, possibly with infinitely many sorts. We 
begin with a study of recognizability in a general algebraic framework. Then 
we state the basic result that MS-definable sets of graphs are recognizable. 
Finally we state a generalized version of Parikh’s theorem based on inductive 
computations, (the fundamental notion behind recognizability) and give some 
applications to VR and HR grammars. 
5.7.1 
Let F be an S-signature. An F-magma A is locally finite if each domain A, is 
finite. Let M be an F-magma and s E S. A subset B of M, is M-recognizable 
if there exists a locally finite F-magma A, a homomorphism h : M t 
A, and 
Inductive sets of predicates and recognizable sets 

5.7. INDUCTIVE COMPUTATIONS AND RECOGNIZABILITY 
373 
a (finite) subset C of A, such that B = h-l(C). We denote by Rec(M), the 
family of M-recognizable subsets of M,. 
If F is a finite signature, the recognizable subsets of terms over F, i.e., the 
T(F)-recognizable sets can be characterized by finite-state tree-automata (see 
Gecseg and Steinby [40]). The classical identification of terms with finite or- 
dered ranked trees explains the qualification of "tree"-automaton. 
By a predicate on a set El we mean a unary relation, i.e., a mapping E -i 
{true, false}. If M is a many-sorted F-magma with set of sorts S, a family of 
predicates on M is an indexed set { $ / p  6 P } ,  given with a mapping u : P -i 
S 
such that each l j  is a predicate on Mu(p). We call u(p) the sort of p .  Such a family 
will also be denoted by P. For p E P, we let L, = { d  E 
/ @(d) = true}. 
The family P is locally finite if, for each s E S the set { p  E P / u ( p )  = s} 
is finite. We say that P is f-inductive where f is an operation in F, if for 
every p E P of sort s = g(f) there exist ml, ... ,m, in N ,  (where n is the 
rank of f), an (ml + . . . + m,)-place Boolean expression B, and a sequence 
such that, if the type off is s1 x s2 x ... x sn + s we have: 
of (ml + . . . + m  
n) elements ofP,(pl,l,... , ~ l , r n 1 , ~ 2 , 1 , " '  ,p2,rnz,"' 
, . ~ n , m , , ) ,  
1. a(p,,,) = s, for all j = 1,. . . , m, and i = 1,. . . , R, 
2. for all dl E M,,,... ,d, E M,,, 
$(fM(dl ' . . I dn)) = B[lil,l (dl), . . . ,&,m1 (dl), &,mz ( d ~ ) ,  
' . . ,Ijn,rn,, (&)I. 
The sequence (B, pl,1 . . . p2,1 , . . . P ~ , ~ , , )  
is called a decomposition of p rel- 
ative to f. In words, the existence of such a decomposition means that the 
validity of p for any object of the form fM(d1,. . . , d,) can be computed from 
the truth values of finitely many predicates of P for the objects dl , . . . , d,. 
This computation can be done by a Boolean expression that depends only on 
p and f. We say that P is F-inductive if it is f-inductive for every f in F. 
Proposition 5.7.1 
Let M be an F-magma. For every s E S a subset L of M, is recognizable if and 
only if L = L,, for some predicate pa belonging to a locally finite F-inductive 
family of predicates on M .  
Pro0 f 
"Only if". Let L = h-' (C) 2 M, , for some homomorphism h : M -+ A where 
A is locally finite and C 
A,. We let P = u{At/t E S} U { p a } .  Each element a 
of At is of sort t (considered as a member of P). The domains of A are pairwise 
disjoint and pa is of sort s. For d E Mt, and a E At, we let: 

374 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
G(d) = true 
if h(d) = a, 
=false 
otherwise, 
For d E Ms, we let 
fio(d) 
= true 
if h(d) E C ,  
=false otherwise. 
It is clear that P is locally finite. It is F-inductive, and, clearly, L = L,,. 
“If”. Let P be a locally finite F-inductive family of predicates. Let L = L,, 
for some po E P. For every t E S we let Pt be the set of predicates in P of 
sort t. We let At be the set of mappings: Pt -+ {true, false}. We let h be the 
mapping: U{Mt / t E S }  -+ u{At / t E S }  such that, for every t E S and 
m E Mt, h(m) is the mapping: Pt + {true, false} such that h(m)(p) = p(m). 
We want to find operations on the sets At such that A = < ( A t ) i E ~ ,  
( f ~ ) f , = ~  
> 
is an F-magma and h : M -+ A defined above is a homomorphism. We need 
to define fA where f is of type s1 x ... x s, -+ t in such a way that for all 
(ml ,. ’. , m,) 
E M,, x . . . x Msn we have: 
h ( f ~ ( m l , . . .  
,mn)) 
= fA(h(ml),... ,h(mn)). 
But it is possible to find such f A  by using the decompositions of the predicates 
in Pt relative to f. Hence, L = L,, = h-l(C) where C = (0 E At / B(p0) = 
true}. It follows that L is M-recognizable since, by construction, A is locally 
finite. 
0 
Example 5.1 
Let L be the set of rooted trees with a number of nodes that is not a multiple 
of 3. Let p be the corresponding predicate on R. (We use the notation and 
definitions of Subsection 5.6.1) Let us consider the following predicates: for 
i = 0,1,2 we let qi(t) hold iff the number of nodes of t is of the form 3k + i 
for some k. It is easy to check that P = {p, qO,q1,42} is inductive with respect 
to the operations ext and // on rooted trees; this check uses in particular the 
following facts which hold for all rooted trees t and t’: 

5.7. INDUCTIVE COMPUTATIONS AND RECOGNIZABILITY 
375 
Since p is equivalent to 41 V 42,  we have: 
and one can easily write a similar definition of p(t//t’). Hence L = L, is 
recognizable. Note that {qo,q1} is inductive because 42 is definable as - y o  A-ql. 
0 
p(ezt(t)) = q o ( t )  v 41 (t) 
Proposition 5.7.2 
Let M be generated by F and t be a sort. A subset L of Mt is M-recognizable 
iff hG1 ( L )  is T(F)-recognizable. 
Proof 
We prove the “only if” direction. If L = h-l(C) for some homomorphism 
h : M + A, where A is locally finite, then hG1(L) = ( h o h ~ ) - l ( C ) ,  
and, since 
hohM is a homomorphism: T ( F )  t 
A, the set h i l ( L )  is T(F)-recognizable. 
0 
For the “if” direction, see Courcelle [22], Proposition 5.5.6. 
This proposition means that, in order to decide whether an element m of M 
belongs to L, it suffices to take any term t in T ( F )  denoting m and to decide 
whether it belongs to the recognizable set hG1(L) (for instance by running an 
automaton on this term). The key point is that the answer is the same for 
any term t denoting m. This should be contrasted with the characterization of 
equational sets of Corollary 5.6.4, which says that, if L is equational, then it is 
of the form ~ M ( K )  
for some recognizable set of terms K :  in this case, in order 
to establish that m belongs to L, one must find a specific term t denoting m, 
and the decision cannot be made from an arbitrary term in hG1(m). 
Relationships between equational sets and recognizable sets. 
We recall that we denote by Equat(M), the family of M-equational subsets 
of M,. 
Theorem 5.7.3 
If K E Rec(M), and L E Equat(M), then L n K E Equat(M),. 
Proof 
We can assume that L = L((S, M), uo) for some uo E U where S is a uniform 
polynomial system over F with set of unknowns U .  A polynomial system is 
uniform if its equations are of the form u = tl + t 2  +. . . + t, , where each ti is of 
the form f(u1, 
u2,. 
. . , uk) for some f E F ,  some unknowns u1,. 
. . , uk E U ;  the 
transformation of an arbitrary system into an equivalent one which is uniform 
is the essence of the transformation of an arbitrary context-free grammar into 
one in Chomsky normal form. An example will illustrate this step later. See 
Courcelle [22], Proposition 5.19 for the proof. 

376 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
Let F' g F be the finite set of symbols occurring in S ,  and let S' C S be the 
finite set of sorts of these symbols together with those of the unknowns of S. 
Hence F' is an S'-signature. Let h : M + A be an F'-homomorphism (with A 
locally finite), such that K = h-l(C) for some C C A,. 
For every u E U ,  we let L, := L((S, M ) ,  u). 
Let W be the new set of unknowns 
{[u,u]/u 
E U,u E A,,(,)}. It is finite. We shall define a system S', with set of 
unknowns W, such that: 
L((s',M), [u,u]) = L, n h-l(a) 
for every [u,a] E W .  Let u E U and a E Ag(,). Let us assume that the 
defining equation of u in S is of the form u = t l + .  . . + t k .  Consider one of the 
monomials, say ti. Let us assume that it is of the form f(u1,. 
. . , u,) for some 
unknowns u1,. . . , u,. For every a E A,,(,), a1 E A,,(,l), . . . ,a, E A,,(,") 
such 
that f ~ ( u l , . . .  
,an) = a, we form the monomial f([ul,ul],... 
,[u,,a,]), and 
we let t^i denote the sum of these monomials. If no such n-tuple (al,. . . , a,) 
exists, then t^i is defined as a. The defining equation of [u, 
u] in S' is taken as: 
[u, 
u] = il + i2 + . . . + ir,. 
It is clear from this construction that the W-indexed family of sets (L, n 
h-'(a))[,,,lE~ is a solution of S' in P(A4). Hence L, n h-l(u) 2 L,,,, where 
(Lu,,)[,,,lE~ denotes the least solution of S' in P ( M ) .  
In order to establish the opposite inclusion, we define from L,,a the sets LL = 
U{L,,,/u E Ag(,)} for u E U .  Clearly (L;),€U is a solution of S in P ( M ) .  
Hence L, C LL for all u. For all a E A,,(,), we have: 
L, n h - l ( ~ )  
g L; n h-l(a) = ( u { ~ , , ~ / b  
E A}) n h - l ( ~ ) .  
The latter set is equal to L,,, n h-'(a) since L,,, C L, n h-l(a) and, h-l (b) n 
h-'(b') = 8 for all b, b' with b # b'. Hence L, n h-l(u) G L,,,. 
By the first 
part of the proof, we have an equality, and (L, n h-l(a))[,,,lEW is the least 
solution of S' in P ( M ) .  We have: 
L n K 
= L,, n h-I(c) 
L n K = L((S", M ) ,  W )  
= U{L((S', M ) ,  [uo, .I)/. 
E C}. 
Finally, we get 
where S" is S' augmented with the equation 
'u) = [uo, a11 + [w, 
a21 + . . . + [uo, GI, 
w is a new unknown and C = {a1 , a2, . . . , u,.}. Hence L n K is M-equational. 0 

5.7. IND UCTIVE COMPUTATIONS AND RECOGNIZABILITY 
377 
/ / A  
(t,f) 
( t 7 . f )  
(Gf) 
(f,t) (f,f) 
(f,f) (f9.f) 
This theorem extends the classical result saying that the intersection of a 
context-free language and a regular one is context-free. The construction is 
effective if K is effectively given (i.e., if h is computable, if the finite sets A, 
are computable, etc ...) and L is defined by a given system. Hence, since the 
emptiness of an equational set (defined by a system of equations) is decidable, 
we have the following corollary. 
Corollary 5.7.4 
If K is an effectively given M-recognizable set, and if L is an M-equational set 
0 
defined by a given system, one can test whether L n K = 0. 
(f,t) (f,f) 
(f,f) (f,f) 
(f,t) (f,f) 
(f,f) (f,f) 

378 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
I ezta I 
Take for example the following system S which is not uniform: 
{ = u + ezt(v)//ezt(v). 
We transform it into the following uniform system S': 
{ w = ezt(v) 
and clearly L((S',R),u) = L((S,R),u). In order to construct L' 
= 
L((S', R), u) n L ,  we introduce the unknowns [z, y, z] with z E {u, v, w}, 
y, z E 
{t, f}, y and z not both true. We obtain the following equations forming a new 
system S": 
u = 1 + ezt(ezt(v)) 
u =  I + e z t ( w )  
Y = 1 + ezt(w) + w//w 
We are interested in L' = L( (S", R), 
[u, t, f]) and it is not hard to see that the 
unknowns of the form [z, f, f], z = u, 0, w are useless for the generation of the 
elements of L'. So is [u, 
f, t]. We can thus delete the corresponding equations. 
Letting z1 replace [z, t, f ]  and z2 replace [z, f, t] for z E {u, v, w} we obtain 
the more readable system T :  
u1 
= ezt(w2) 
211 
= ezt(w2) +w1//w1 
212 
= 1 + ezt(w1) + w2//w2 
w1 = ezt(v2) 
1 202 
= ezt(v1) 
and L' = L((T,R), u1). This system can be reduced into the following one, 
call it 7''. 

5.7. INDUCTIVE COMPUTATIONS AND RECOGNIZABILITY 
379 
u1 
= ezt(ezt(v1)) 
wl = ezt(ezt(v1)) + ezt(vZ)//ezt(vZ) 
w2 = 1 + ezt(ezt(v2)) + ezt(vl)//ezt(vl) 
Finally, we have L((T’,R), ul) = L((S,R),u) n L,. 
5.7.2 
In this section, we present the fundamental result saying that, roughly speak- 
ing, every monadic second-order definable set of graphs or hypergraphs is recog- 
nizable. However, in order to get a sensible statement, we must specify two 
things: 
Inductivity of monadic second-order predicates 
1. the representation of graphs and hypergraphs we are using (because 
we have defined two of them, yielding two different notions of monadic 
second-order definability), 
2. the relevant operations on graphs and hypergraphs (we have defined two 
signatures of operations denoted by FVR 
and FHR, defining respectively 
the magma GP of simple graphs with ports and the magma XS of hy- 
pergraphs with sources; see Subsections 5.6.2 and 5.6.3. 
We recall that if C is a set of port labels, we denote by FI/R(C) the subsigna- 
ture of FVR 
consisting of the operations involving only port labels from C. We 
denote by GP(C) the FvR(C)-magma with domain GP(C) and operations of 
FI/R(C). Hypergraphs will be over a fixed finite ranked set A of hyperedge la- 
bels that we will not specify in notation. We recall that CMSi refers to counting 
monadic second-order logic where a graph or a hypergraph G is represented by 
the structure I G Ji. 
(See Sections 5.3 and 5.4). We only consider finite graphs 
and hypergraphs, but we keep the notations GP(C) and US(C). 
Theorem 5.7.5 
(1) Let C be a finite set ofport labels. Every CMSl-definable subset of GP(C) 
is GP( C) -recognizable. 
(2) Let C be a finite set of source labels. Every CMSZ-definable subset of 
US(C) is US-recognizable. 
0 
We shall sketch the proof of the first assertion. For the second assertion, we 
shall refer the reader to the proofs given in [ll] and [15]. 
We need some notation. For every n E N ,  q E N-(0, l}, for every finite subset 
C of C, for every finite set W of set variables, L(n, q, C, W )  denotes the subset 
of CMS(R,(C),W) consisting of formulas of quantification depth at most 

380 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
n, possibly written with the atomic formulas Card,(X) for 2 5 p 5 q (see 
Subsection 5.4.1). 
We shall say that two formulas are tautologically equivalent if they can be 
transformed into each other by renamings of bound variables and uses of the 
laws of Boolean calculus. (For instance cp is tautologically equivalent to cp Acp). 
Every two tautologically equivalent formulas are equivalent and we shall as- 
sume that every formula is transformed into a tautologically equivalent formula 
of some standard form. With this convention, each set L(n, q, C, W )  is finite. 
Each formula cp E L(n, q, C, 0) defines a predicate ci, on GP(C) such that for 
every G E GP(C): 
We let C be fixed and we denote by L(n, q )  the corresponding family of pred- 
icates. It is finite. 
+(G) is true iff I G 11 
cp. 
Lemma 5.7.6 
For every n, q E N with q 2 2, the family of predicates L(n, q) is F"R(C)- 
inductive. 
Proof sketch 
We first consider the inductivity condition for the operation add,,d where c, d E 
C. Let us recall that G' = add,,d(G) iff G' is obtained from G by the addition 
of an edge from x to y where x is any c-port and y is any d-port such that 
(z,y) $! 
edgG and x # y. For every formula cp in CMS(R,(C),@) 
one can 
construct a formula $ in the same set and of no larger quantification depth 
such that, for every G 6 GP(C) 
i.e., 
In other words the family of predicates on W(C) associated with the formulas 
in L(n, q, c, 0) is {add,,d}-inductive. The decomposition of @ relative to add,,d 
is simply (B,G) (where B is the trivial Boolean combination such that B[$] 
is $). 
The proof of (3.4) is actually an immediate consequence of Lemma 5.2.5 be- 
cause if G' = add,,d(G) we have the following definition of edge,: 

5.7. INDUCTIVE COMPUTATIONS AND RECOGNIZABILITY 
381 
Hence, one can take $ equal to cp[B(zl, z ~ ) / e d g ]  
where B is the quantifier-free 
formula: 
edg(z1,zz) V (&(.I) 
A p t d ( z 2 )  A-a 
= ~ 2 ) .  
It is important to note that this transformation does not increase the quantifi- 
cation depth because the formula substituted for edg has no quantifier. The 
same holds (with similar argument) for the operations m d f p .  The inductivity 
of i ( n ,  q) with respect to the operations m d f p  can be proved similarly. 
Next we consider the case of $, the disjoint union operation. The statement 
analogous to (3.3) is the following one: for every formula cp in L(n, q, C, 0) one 
can find m E n/ and construct formulas $1, I
+
!
.
(
,
 
. . . , Grn, $k in L(n, q, C, 0) 
such that, for every G and G’ E GP(C): 
$(G CB G‘) = V Gi(G) A $‘i(G’). 
(5.5) 
1 <ism 
(The validity of (3.5) is actually known from Shelah [57], Section 5.3, given 
without proof as a easy modification of a previous result by Fefermann and 
Vaught [38] for first-order formulas). In this case the decomposition of $ with 
respect to $ is: 
((XI A z ~ ) V ( z 3  
A Z ~ ) V . . . V ( Z Z ~ - I  A z ~ ~ ) , ~ l 7 ~ ’ l , ~ ~ , ~ ’ z 7 . . .  
,‘$m7$’,). 
The proof is more complicated than for (3.3); it can be done by induction on 
the structure of cp and the cases where cp = ( P I  A cpz, cp = (PI V cpz, cp = -,01 
are rather straightforward. However, in order to handle inductively the cases 
where cp = 3Xpl, one needs a formulation of (3.5) where cp has free variables. 
Let W= {X17.. 
. , X,}. Let cp E L(n, q, C, W ) .  Let G E GP(C) and V1,. . . , V, 
be sets of vertices of G (i.e., subsets of the domain of the structure 1 G 11). We 
let $(G, V1,. . . , V,) = true if 
(1 G Il,Vl,’.. , K )  I= ~~(xl,... 
7x7) 
and @(G, 
V,, . . . , Vr) = false otherwise. The generalized version of (3.5) is 
now: for every formula cp E L(n,q,C, W ) ,  one can find m E n/ and construct 
$1, $;, . . . , $m, $k E L(n, q, C, W )  such that, for every G, G’ E GP(C) such 
that Vc n v& = 0, for every V1,. . . , V, C VG, for every V:, . . . , V,l C_ V&: 
@(G$G’,Vl U V : , . - -  ,V,UV,‘) = v &(G,Vl,-.. ,V,)A4’i(G’,V:,... ,V,‘) 
l l i l r n  
(5.6) 
This can now be proved by induction on the structure of cp. 
0 

382 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
Proof of Theorem 5.7.5 
(1) Let C be finite, let L C GP(C) be defined by a formula cp of CMS relatively 
to the representation of the graphs G in GP(C) by structures of the form 
I G I l .  For some large enough n and q the formula 'p belongs to L(n, q, C, 0). 
The predicate @ belongs to the finite family f,(n,q) of predicates which is 
FvR(C)-inductive (Lemma 5.7.6). Hence L is GP(C)-recognizable. 
(2) The proof is similar. We indicate the main ideas. The finite set A is fixed. 
The FHR-magma of hypergraphs XS is many-sorted and its set of sorts is the 
set S of finite sets of source labels. For every n,q,C,W as above, we denote 
by L'(n, q, C, W )  the set of formulas in CMS(R,(A, C), W )  of quantification 
depth at most n and using the special atomic formulas Card,(X) for p 5 
q. This set is finite. For each C ,  we consider the finite family of predicates 
(8 / 'p E Lr(n, q, C, 0)} where for H E XS(C): 
@ ( H )  is true iff I H 12 
We denote it by tr(n, 
q, C). Hence we obtain a locally finite family of predicates 
on ZS where @ E L'(n,q,C) is of sort C. For every n,q E N with q 2 2, 
the family u{Z'(n, q, C) / C E S} is FHR-inductive. It follows as above (see 
[ll] or [15] for details) that every CMS2-definable subset of XS(C) is X S -  
cp 
recognizable. 
0 
Corollary 5.7.7 
(I) The intersection of a VR set of graphs and a CMSl-definable subset of 
GP(C) (where C is finite) is a VR set. The CMSl-satisfiability problem for a 
VR set is decidable. 
(2) The intersection of an HR subset of ZS(C) (where C is finite) and a 
CMS2-definable one is HR. The CMS2-satisfiability problem for an HR set 
is decidable. 
Proof 
(1) Let L be a VR set of graphs. Let D be the finite set consisting of all port 
labels occuring in the operation of some system of equations defining L. Then, 
L is GP(D)-equational and L g GP(D). Let K be a CMS1-definable subset 
of GP(C) for some finite C 2 C. Then L is GP(C U D)-equational and K is a 
CMSI-definable subset of GP(CUD). Hence LnK is GP(CUD)-equational by 
Theorem 5.7.3 hence V R  since K is GP(CUD)-recognizable. (Theorem 5.7.5). 
(2) Let L be an HR-subset of ZS(C) and K be a CMS2-definable one. Then 
K is XS-recognizable by Theorem 5.7.5 and L n K is XS-equational (Theo- 
rem 5.7.3) hence HR. 
0 

5.7. INDUCTIVE COMPUTATIONS AND RECOGNIZABILITY 
383 
Corollary 5.7.8 
Let C be a finite set ofport or source labels. Let A be a finite ranked alphabet. 
(1) For every formula 'p E CMS(R,(C),0) the property I G 11 
y can be 
decided in time O(size(t)) where G = val(t) and t E T(FvR(C)). 
(2) For every formula y E CMS(Rm(Al C), 0) the property I H 12 
y can 
0 
be decided in time O(size(t)) where H = vaZ(t) and t E T(FHR(A))c. 
In these two assertions] the input is a term t denoting G or H .  Since not all finite 
graphs (hypergraphs) are the values of terms in T(FvR(C))(T(FHR(A))C), 
this 
corollary gives efficient algorithms only for CMS properties on (finite) graphs 
(hypergraphs) in special classes. Furthermore, the graphs or hypergraphs must 
be "parsed", i.e., given by terms. 
Pro0 f 
Let F be a finite signature. The membership of a term t in a recognizable 
subset of T ( F )  is decidable in time O(size(t)) because recognizable sets of 
terms are defined by finite-state deterministic frontier-to-root automata. The 
0 
two assertions follow then from Proposition 5.7.2 and Theorem 5.7.5. 
5.7.3 Inductively computable functions and a generalization of Parikh's the- 
orem 
Let F be an S-signature and M be an F-magma. Let N be a set and let & be a 
family of mappings called evaluations where each e E & maps Ms -+ N for some 
s E S. We call the sort s the type of e. We say that & is F-inductive if for every 
e E & and f E F there exists a partial function ge,f : N m  -+ N and k sequences 
each function ei has type a( f ) j  and we have, for every dl ,.. . d k  E M with 
a ( d i )  = a(f)i, for all i = 1;'. ,k: 
( e i , . . .  ,enl),... 
1 
,e(:... , e & )  where k = p ( f )  such that m = n l  +...+ n k ,  
e(fM ( d l  I ' ' ' 7 d k ) )  = g e , f  (e: ( d l  1 7  ' . . 7 ekl ( d l  1, ef (d2) 
7 ' ' ' , e: ( d k  ) I  . . . 1 ekk ( d k ) ) .  
(5.7) 
This means that the value of e at f M ( d 1 ,  . . . d k )  can be computed] by means 
of some fixed functions g e , f ,  from the values at dl , . . . , d k  of m mappings of & 
(the mappings ei are not necessarily pairwise distinct and some of them may 
be equal to e). We shall call the tuple 
(5.8) 
k 
( g e , f ,  (4, 
.. , e k l ) ,  (4, ... 
. 1 ( 4 1 . '  . ,enk)) 
the decomposition of e relative to fM. In Subsection 5.7.1, we have introduced 
inductive families of predicates: they are just the special case of inductive 

384 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
families of evaluations where N consists of the truth values true and false. 
If E is F-inductive, if d E M is given as t~ for some t E T(F) (i.e., this 
means that d has been “parsed” in terms of the operations of M ) ,  then one 
can evaluate e(d) by the following algorithm using two traversals oft. 
Algorithm: 
Input: a term t given as a tree, an evaluation eo in &: 
Output: the value eo(tM). 
Method: 
First traversal (top-down): One associates with every node u of the tree t a set 
of evaluations &(u), 
that will have to be computed at u, 
i.e., for the argument 
defined by the subtree o f t  issued of u. For the root T ,  we let &(r) := {eo}. 
For every node u such that E(u) is already known and that has successors 
u1, ... , u k ,  for every e in E(u), if f is the operation labelling u, 
and 
(5.9) 
is the decomposition of e relative to fM, we add to each set &(uT), 
i = 1,. . . , k, 
the evaluations eZ,, . . . , eki. 
Second traversal (bottom-up): Starting from the leaves, one computes at 
each node u the values of each function e E E(u) by using the decomposition 
of e relative to f M  (see (3.7)). One obtains at the root the desired value of 
eo. Denoting by e(u) such a value (i.e., we denote by e(u) the value of e for 
(t/u)M, we use the formula: 
based of the decomposition of e relative to f M  of the form (3.9). One obtains 
at the root the desired value of eo. 
This technique is useful for certain graph algorithms, taking as input graphs 
or hypergraphs expressed as values of V R  or H R  expressions. We refer the 
reader to [ll], [12], [2], [25] for the construction of efficient graph algorithms 
based on this algorithm. 
We shall now be interested in understanding the structure of sets of the form 
e(L) := {e(d) / d E L }  C N where e is a mapping belonging to an F-inductive 
family E and L is M-equational. We shall need the following assumptions: 
(Hl) & has finitely many mappings of each type s E S, 
(H2) N is an H-magma for some signature H with set of sorts S’ (S’ is not 
necessarily equal to S), 

5.7. INDUCTIVE COMPUTATIONS AND RECOGNIZABILITY 
385 
(H3) the functions g e , f  are derived operations of N ;  each of them is defined 
by a term t , , ~ .  
A term is linear if no variable has more than one occurrence. 
Proposition 5.7.9 
If conditions (H1) 
- (H3) hold, if in Equalities (3.7) we have n1 5 1,. . . , nk 5 1 
and if the terms t,,f are linear, then e(L) E Equut(N) for every L E Equut(M). 
Proof 
Let L = L((S, M ) ,  u1) where S is a uniform polynomial system with unknowns 
u1, . . . , un. We shall assume that M and N have only one sort: this simplifies 
the notation and is not a loss of generality. For every e E & and i E [l,n], we 
let [e,ui] be a new unknown. We shall build a polynomial system S' such 
that the component of its least solution corresponding to [e,ui] is the set 
e(L((S,M),ui)) 
for each e E & and i E [1,n]. For every equation 
uz = . . ' + f(uz,, 
. . . , U i k )  + 
of S ,  every e E & we create the equation 
noindent where (g, (el), . . . , (e')) is the decomposition of e relative to fM and 
t,,f is a linear term defining in N the function g. We let (A!, . . . , A:) be the 
j-th iterate (where j 2 0) approximating the least solution of S in P ( M )  (see 
Subsection 5.6.1). Similarly, we denote by A;,, for e E & and i E [1,n] the 
0 
component corresponding to [e, ui] of the j-th iterate of S$(N). 
Claim: For every j E N ,  every i E [l,n], every e E &, we have e(A{) = A$. 
Pro0 f 
0 
As an application, we obtain a form of Parikh's theorem. We let q E N+; 
we let N be the commutative monoid < NQ,O,@,ll,... 
,1, > where 0 = 
(0, .. . , O ) ,  l i  = ( O , O , .  . . , 1,. . . ,0) (and 1 is at position i), and @ is the vector 
addition: (UI, 
UZ, . . . , u,) @ (bl, . . . , b,) = (a1 CB bl, . . ,up @ bq). We assume 
that for every s E S there is in & a unique evaluation mapping e, : M, + N ,  
and that the functions ge,f of the decompositions are of the form: 
By induction on j. See Courcelle [22], Theorem 6.2 for details. 
ge,f("i,-'. ,Zk)=Xl@...@Zk$b 
where b E Nq. Since b can be written as a finite sum of constants 0,11,. . . ,1, 
the operation g e , f  is defined by a linear term in T({@, 
0,11,. . . , lq}). It follows 

386 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
that Equalities (3.7) have the form: 
e(f,w(dl,... ,&I) = e l ( d l ) @ . . . @ e k ( & ) @ b  
(5.10) 
where ei is the evaluation in & of type g(di). We shall say that & is a Parikh 
family of evaluations on M .  
We recall a few definitions. A set A C Nq is linear if it is of the form A = 
{ X l a l @ . . . @ X , a , @ b  / X 1 , . . . , X n  
E N } f o r s o m e a l , . . - , a , , b E  Nq and 
where, for X E N ,  a E Nq,Xa = 0 if X = 0 and Xu = a @ a @ . . . @ a  with X 
times a if X 2 1. A subset of Nq is semi-linear if it is a finite union of linear 
sets. Since a linear set as above can be written A = .;a; 
...a;b it follows 
that every linear set, hence, every semi-linear set is rational. Conversely, by 
using the laws: ( A  + B)* = A*B* and (A*B)* = E + A*B*B which hold for 
arbitrary subsets A and B of a commutative monoid, one can transform a 
rational expression defining A E Rat(NQ) into a sum of terms of the form 
a;aa . . . a:b for a l , .  . . , a,, b E NO. Hence, every rational subset of Nq is semi- 
linear. 
Corollary 5.7.10 
If L E E q u a t ( M )  and e belongs to a Parikh family of evaluations then e ( L )  E 
Equat(NQ) 
and is semi-linear. 
Proof 
That e ( L )  E Equat(Nq) follows from Proposition 5.7.9. Pilling has proved in 
[49] that every equational set of a commutative monoid is rational, hence, we 
0 
get that e(L) is semi-linear. 
Example 5.3 
We consider the magma of series-parallel graphs < SP, ., /I, 
e > of Subsec- 
tion 5.6.1. We consider the evaluation # : SP+ N2 such that 
#(G) = (number of edges of G, number of internal vertices of G). 
Since #(G//G’) = #(G) @ #(G’), #(G.G’) = #(G) @ #(G’) @ 1 2 ,  and # ( e )  = 
1 1 ,  from the equation u = u//u + u . u . ~  
+ e which defines a proper subset L of 
SP, we get the following equation that defines # ( L )  C N2: 
u = u @ u  + u a3 u @ u @ 1 2  @ 1 2  + 11. 
0 
We now define a more powerful extension of Parikh’s theorem which has also 
applications in graph grammars. We let M be an F-magma, we let N be a 
G-magma, we let & be a finite family of mappings: P ( M )  -+ P ( N )  satisfying 
the following conditions, for all sets Al, . . . , Ai, . . . C M of appropriate sorts, 
and for all f E F :  

5.7. INDUCTIVE COMPUTATIONS AND RECOGNIZABILITY 
387 
Proposition 5.7.11 
With these conditions, for every L E Equat(M), we have e(L) E Equat(N). 
Proof 
Essentially the same as the proof of Proposition 5.7.9. 
0 
Example 5.4 
As in Example 5.3, we use series-parallel graphs, but directed ones: this means 
that the basic graph e is a single edge directed from the first source to the 
second one. Series-parallel graphs have no circuit. We denote their set by SP’. 
For every graph G in SP’, we let T(G) be the set of lengths of directed paths 
in G that link the first source to the second one. Hence T maps SP’ into P(n/). 
For L C SP‘ we let II(L) = U{.rr(G) / G E L}. This mapping satisfies the 
conditions of Proposition 5.7.1 1 because it a homomorphism for union and: 
4 G / / G ’ )  = 4 G )  u 4 G ‘ )  = t l ? ( N )  ( 4 G ) )  u t Z F ( N )  ( 4 G ’ ) )  
t S P ( N )  (7r(G)7 4 G ’ ) )  
n(G.G’) 
= T(G) @ 7r(G’) 
= {n @ n’/n E n(G),n’ E 7r(G’)} 
- 
- 
where tl = 51, 
t 2  = 5 2  and t3 = x1 @ 2 2 .  Hence, for every {//, .}-equational 
set of series-parallel graphs L, the set n(L) is a semi-linear subset of N. For 
the equation of Example 5.4 we obtain: 
Its least solution is the set of odd numbers (1, 3, 5, 7...}. 
0 
This example is actually a special case of a general result of [19] that we recall 
and that we shall derive from Proposition 5.7.11 and some results of [25]. 
If G is a hypergraph represented by the structure I G 12, if cp is an MSz-formula 
with free set variables X I ,  . . . , X k ,  we let 
sat(G,cp) = {(Di,... ,Dk) / Di C VGUEG,(I G 12,D1,... ,Dk) 
t= ‘P) 
#sat(G,cp) = 
{(Card(Di);.. ,Card(Dk)) / (Dl,... ,Dk) E sat(G,p)} 5 N k .  

388 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
If L is a set of hypergraphs, we let 
Proposition 5.7.12 
If L is a HR set of hypergraphs and cp is an MS2-formula with free variables 
XI,. . . , Xk, then the subset #sat(L, cp) C N k  is semi-linear. A similar state- 
0 
ment holds for VR sets of graphs and MS1-formulas. 
This result is proved in [19] as Corollary 5.4.3. It yields immediately the result 
of Example 5.4 if one takes the formula cp(X1) saying that “XI is the set of 
edges of a path from the first source to the second one”. We now derive the 
first assertion of Proposition 5.7.12 from Proposition 5.7.11 and some results 
of [25]. 
Proof of the first assertion of 5.7.12 Let C, C’ be finite sets of source labels; 
let cp be an MSa-formula of quantification depth at most h and free variables 
XI , . . . , Xk. One can find MS2-formulas $1 , . . . , $,, 
$;, . . . , $:n of quantifica- 
tion depth at most h and vectors 721,. . . , n, E N k  such that, for all hyper- 
graphs G and G’ of respective types C and C’ we have: 
#sat(G//c,cfG’, cp) = u 
l l i l m  
#sat(G, $3) @ #sat(G‘, $;) @ n3. 
Similarly, for every finite set C of source labels, for each unary operation f in 
FHR, one can find MS2 formulas $1,. . . , ?I, 
of quantification depth at most 
h, and vectors n1, . . . , nm in N k  such that, for every hypergraph G of type C: 
sat(f(G), 
‘PI = u #sat(G, $j) @ nj. 
l < j < m  
These facts follow from Lemmas 2.4, 2.5 and 2.6 of [25]. Letting & be the 
family of evaluations e of the form e(G) = #sat(G, 9) 
for G of type C where 
C is a subset of a fixed finite set of source labels, we obtain that & satisfies 
the conditions of Proposition 5.7.11. It follows from this proposition that if 
L is an HR set of hypergraphs, and cp is an MSa-formula with free variables 
XI,. . . , Xk then #sat(L, 9) is in Equut(Nk) hence, by [49], is semi-linear. 
The proof of Proposition 5.7.12 is effective. This means that from cp and a sys- 
tem of equations defining L one can construct an expression of #sat(L,cp) 
as a finite union of linear sets where the linear sets are given by co- 
efficients al,... ,am,b (see the definition). It follows that a number of 

5.7. INDUCTIVE COMPUTATIONS AND RECOGNIZABILITY 
389 
"boundness" questions can be solved effectively. It can be decided whether 
Sup{zi / (z1 ,.. . , zk) E sat(L, cp)} is finite or not, and if it is, its value can 
be computed. Much more generally, for every sequence integers cl, . . . , Ck , one 
can decide whether Sup{zlcl+. . . fzkck / (z1, . . . , zk) E sat(L, 9)) 
is finite 
or not, and if it is, its value can be computed. 
5.7.4 
Logical characterizations of recognizability 
Theorem 5.7.5 has established that every set of finite graphs or hypergraphs 
defined by a formula of an appropriate monadic second-order language is recog- 
nizable with respect to an appropriate set of operations. It is thus natural to 
ask for the converse, which holds in several known cases summarized in the 
following theorem. 
Theorem 5.7.13 
(1) Let A be a finite alphabet. A language L c A' is regular iff it is MS1- 
definable. 
(2) Let F be a finite ranked alphabet. A set of terms L C_ T ( F )  is T ( F ) -  
recognizable iff it is MS1-definable. 
(3) A set of finite trees is 'TR&&-recognizable iff it is CMSl-definable. 
Proof 
Assertion (1) has been proved by Buchi and Elgot ([B], [30]), assertion (2) by 
Thatcher, Wright and Doner ([29], [59]); see [60], Thm l l . l ) ,  assertion (3) by 
Courcelle ([ 111). 
However, no logical characterization of recognizability can exist by the follow- 
ing result. 
Proposit ion 5.7.14 
Every set of finite square grids is 31s-recognizable and GP(C)-recognizable for 
every finite set of port labels C. 
Square grids have been defined in Section 5.2.9. This result is proved in Cour- 
celle [ll] for 31s-recognizability. The proof is easily adapted to yield the case 
of GP(C)-recognizability. It follows that the family of XS-recognizable (or of 
GP(C)-recognizable) sets of graphs is uncountable. Hence it cannot be charac- 
terized by the countably many formulas of any logical language like those we 
have considered here (including second-order logic). 

390 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
Courcelle conjectured in [13] that for every k ,  every recognizable set of graphs 
of tree-width at most k is CMS2 definable. This was proved in [13] for k = 2 
and by Kaller [45] for k = 3. 
5.8 Forbidden configurations 
Many classes of graphs can be characterized in terms of forbidden configu- 
rations, i.e., of certain graphs that cannot appear as subgraphs. The basic 
example is that of planar graphs: they can be characterized as the graphs that 
do not contain K:, or K3,3 as a minor. Such characterizations yield logical de- 
scriptions that could not be obtained otherwise: for example, the definition of 
the planarity of a graph G in terms of an embedding in the plane cannot be 
expressed logically in a structure like I G 11 or 1 G 12 which describes the graph 
G (its vertices and edges) but not the plane. One could also try to express the 
existence of an embedding of G (assumed finite) in a large enough rectangular 
grid but this is not possible (at least immediately) because this requires to 
express the existence of vertices and edges forming a grid lying outside of G. 
The logical formalism allows to express properties of a graph G in terms of its 
vertices and edges, not in terms of objects outside of I G (1 or I G 12. 
All graphs in this section will be finite. Hence, “graph” will mean “finite graph”. 
We shall review the links between finitary descriptions of sets of graphs in terms 
of grammars, MS formulas and forbidden minors. We also show how the notion 
of a minor and the results of Robertson and Seymour help in understanding 
the structure of the sets of graphs having a decidable MSz-theory. 
5.8.1 Minors 
Let G and H be undirected graphs. We say that G is a minor of H and we 
write this G 9 H iff there exist mappings f : VG + ’P(v~),f’ 
: VG -+ P(E,) 
and g : EG + EH satisfying the following conditions: 
(1) for every z E VG, (f(z), 
f’(z)) is a connected subgraph of HI 
(2) for every z, 2’ E VG with z # x’, we have f (x) n f(zr) = 0, 
(3) g is injective and g(e) does not belong to any set f’(z) 
for any 2 E VG, e E 
EG I 
(4) if e E EG links z and x’, then g(e) links a vertex of f(x) and a vertex of 
f (4. 

5.8. FORBIDDEN CONFIGURATIONS 
391 
It is clear that this definition depends only on the isomorphism classes of G 
and H .  Minor inclusion is transitive and reflexive. Because graphs are finite, 
if G a H 9 G then it is not hard to see that G and H are isomorphic. Hence 
minor inclusion is a partial order on graphs. (The corresponding strict order 
is denoted by a). 
Fact 5.8.1 
G a H iff G is obtained from a subgraph HI of H by a sequence of edge 
contractions. 
0 
Contracting an edge linking x and y results in the fusion of x and y and deletion 
of the resulting loop. Edge contraction may create loops and multiple edges. 
Proof 
Consider G 
subgraph of H such that 
H with functions f , f I ,  g as in the definition. We let H’ be the 
VA = U U C ~ )  
/ x E vc},~w 
= U{f’(x) / x E vG) u {g(e) / e E E G ) .  
Then one obtains G (up to isomorphism) by contracting (in any order) the 
0 
Let M be a set of graphs. We define F O R B ( M )  as the set of undirected graphs 
H such that G 
H for no G E M .  For example the set of undirected planar 
graphs can be characterized as the class FORB(K3,3,K5). This is a variant 
of Kuratowski’s theorem (see Bollobas [5]). We recall that K, is the n-clique 
consisting of n vertices and an edge linking any two distinct vertices, and that 
Kn,m is the complete bipartite graph with n + m  vertices. (Formally its vertices 
are --n7--(n-l),...,-1,l,2,... ,m and thereisanedgelinkingany “negative” 
vertex and any “positive” one). It is clear that every class of graphs of the form 
F O R B ( M )  is minor-closed which means that every minor of every graph in 
the class is also in the class. In order to get a converse we let, for every class C 
OBST(C) = {G / G $! C, every graph H such that H a G belongs to C}. 
OBST(C) is defined as a set of abstract graphs: its elements are by definition 
pairwise nonisomorphic. This set is called the set of obstructions of C. 
edges in the sets f‘(x), x E VG. The converse is proved similarly. 
Fact 5.8.2 
For every minor-closed class C of graphs: C = FORB(OBST(C)). 
0 
The major result in this field is the following result by Robertson and Seymour 
1541. 

392 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
Theorem 5.8.3 (Graph Minor Theorem [54]) 
Every infinite set of undirected graphs contains two graphs comparable by g .  
0 
Hence for every class C of graphs, the set OBST(C) is finite. 
The obstructions of minor-closed classes are known in relatively few cases. We 
have already mentioned planar graphs. The set of obstructions of forests is the 
singleton consisting of the graph reduced to a loop. That of graphs of tree- 
width at most 2 is {K4}. That of graphs of tree-width at most 3 consists of 4 
graphs one of which is K5. The obstructions of the classes of graphs of tree- 
width at most k are not known for k > 4. Intractable computation methods 
are known to compute them ([47]). In the following case, one does not even 
know such a method. Let C be the class of almost planar graphs, i.e. of graphs 
G such that G[VG - {w}] is planar for some vertex ‘u. (Every planar graph is 
almost planar and so are K5 and K3,S; K6 is not almost planar because one 
must delete at least two vertices in order to obtain from K6 a planar graph). 
R. Thomas knows already 60 graphs in OBST(C) one of which is K6, but does 
not know whether this list is complete. 
We now discuss the logical aspects of minor inclusion. 
Proposition 5.8.4 
Let H be a finite graph. The property that a graph G contains H as a minor 
is MS2-definable. If H is simple and loop-free, this property is MS1-definable. 
0 
It follows in particular that planarity is MS1-definable. 
Proof 
Let H be given with vertices 1,2,. . . , k and edges e l , .  . . , em. Let G be an ar- 
bitrary graph. In order to verify that H 
G, we have to find appropriate map- 
pings f, f’, g. Hence we need only find k subsets of VG namely f(l), 
. . . , f ( k ) ,  k 
subsets of EG namely f‘(l),... 
, f’(k), m edges of G: namely g ( e l ) , . . .  ,g(e,) 
and to check the conditions of the definition. This can be done easily by an 
MS2 formula. 
Assuming H simple and loop-free we now check that one can avoid quantifica- 
tions on sets of edges. We claim that H 
G iff there exist XI,. 
. . ,XI, 5 VG 
satisfying the following conditions: 
(1’) the induced subgraph G[Xi] of G with set of vertices Xi is connected for 
each i = l,... ,k. 
(2’) Xi X j  = 0 for i # j ,  

5.8. FORBIDDEN CONFIGURATIONS 
393 
(3’) for every edge of H linking i and j there is an edge of G linking a vertex 
of Xi and one of X j .  
If H 9 G with corresponding mappings f ,  f’, g then these conditions hold with 
Xi = f(z). Conversely, if X I , .  . . , xk satisfy them, then we take: 
f(i) = xi, 
f ’ ( i )  = E ~ x , ] ,  
for every i = 1;’. ,Ic, 
g ( e J )  to be an edge satisfying condition (3’). 
These mappings satisfy the conditions of minor inclusion: (1) follows from (l’), 
(2) follows from (2’), (3) holds from (3’) and, because H is simple and loop- 
free, (4) follows from (3’). The existence of X I , .  . . , Xk satisfying (1’) - (3’) is 
0 
We leave as an exercise the verification that the property of a graph G that 
it contains a fixed graph H as a minor is MS1 where H may have loops and 
multiple edges, and G is assumed to be simple. With Theorem 5.8.3 we obtain: 
easily expressed by an MS1-formula. 
Corollary 5.8.5 
Every minor-closed class of graphs is MSS-definable. Its subclass of loopfree 
simple graphs is MS1 -definable. 
Proof 
The first assertion is immediate from the Graph Minor Theorem and Proposi- 
tion 5.8.4. For the second one, we let: 
OBST’(C) := {G / G is simple and loop-free, G $ C, every simple loop-free 
graph H with H a G belongs to C}. 
If C is a minor-closed class of simple loop-free graphs, then C = 
FORB’(OBST’(C)) where FORB‘(M) is the class of simple loop-free graphs 
in FORB(M). The set OBST‘(C) is finite by the Graph Minor Theorem and 
0 
the result follows by Proposition 5.8.4. 
We shall denote by Minor(G) the set of minors of a graph G. Thus Minor is 
a transduction from graphs to graphs. We show it is (2,2)-definable. Let G be 
a graph. Let X 
VG, let Y, 2 C: EG. We say that ( X ,  Y, 2) defines a minor of 
G if the following conditions hold: 
(a) if 2,x’ E X ,  2 # d, 
then there is no 2-path in G linking them (a 2-path 
is a path all edges of which are in 2); 

394 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
(p) each end y of an edge in Y is linked to some vertex x of X by some 
2-path; (one may have x = y); 
(y) Ynz=0. 
Notice that by condition (a), the vertex z in condition (p) is uniquely defined. 
We shall denote it by Q. The minor defined by the triple (XI Y, 2) is the graph H 
such that VH = X, EH = Y and wertH(e) = {GI y} where y and y’ are such that 
wertG(e) = {y, y’}. We shall denote it by Minor(X, Y, 2). The corresponding 
mappings f ,  f‘, and g are as follows: f ( w )  is the set of vertices of G linked to 
by some 2-path (including w); f’(w) is the set of edges of 2 having their ends 
in f (w); and g is the identity: VH + V G ~ .  
Hence, Minor(X, Y, 2) is indeed a 
minor of G. It is not hard to see that every minor H of G is of this form for 
appropriate sets XI Y, 2. 
Moreover, Minor(X, Y, 2) 
is a strict minor iff 2 # 0 
or Y # EG or X # VG. We have thus proved the following 
Fact 5.8.6 
Minor is a (2,2)-definable transduction. 
0 
Proposition 5.8.7 
For every MS2-definable class 114 ofgraphs, each of the classes FORB(M) and 
OBST(M) is MS2-definable. MS2-formulas defining them can be effectively 
constructed from an MS2-formula defining M .  
Pro0 f 
Let cp be an MS2-formula such that M = {G / 
FORB(M) iff 
I H 12 
I G 12 
cp}. Then H E 
VX, Y, Z [  “ X ,  Y, 2 define a minor of H” + 
“Minor (XI Y, 2) 
does not satisfy cp”]. 
From the proof of Fact 5.8.6 this condition can be expressed by an MS2- 
formula. From the definition of OBST we get that for every graph HI H E 
OBST(M) iff 
I H 12 
l c p  A VX, Y, Z[“X, Y, 2 define a strict minor of H” a 
“Minor(X, Y, 2) satisfies cp”] 
0 
Again this latter condition is MS2-expressible. 
One might hope to be able to construct the sets of obstructions of MS2- 
definable classes of graphs. Consider for instance the class of almost planar 
graphs. It is not hard to prove that it is minor-closed, and to construct an 
MSz-formula defining it. One obtains thus an MSa-formula characterizing its 
finite set of obstructions. However this is not enough to make it possible to 

5.8. FORBIDDEN CONFIGURATIONS 
395 
construct (even by an intractable algorithm) this set itself. (See the remark 
following Proposition 5.2.2.). The best one can do presently is the following 
Proposition 5.8.8 
Let M be an MSz-definable class of finite graphs. For every HR set of graphs 
L one can compute the set L n O B S T ( M ) .  
In particular, taking L to be the set of trees (or of graphs of tree-width at most 
k ) ,  one can obtain effectively the obstructions of M that are trees or that have 
tree-width at most Ic. If one knows some upper-bound on the tree-width of the 
graphs in OBST(M) one can thus (at least in principle) compute O B S T ( M )  
explicitely. 
Proof 
This follows immediately from Propositon 5.8.7, Corollary 5.7.7 and the fact 
that if a finite set of graphs is HR (given by a known grammar or system of 
equations), then this set can be explicitely enumerated. (See Habel [43]). 
0 
This result was proved first in a different way by Fellows and Langston [39]. 
Sets of finite graphs can be specified effectively in various ways: by grammars 
of several types, by forbidden minors, by monadic second-order formulas. The 
following theorem summarizes the situation. 
Theorem 5.8.9 
Let L be a set of loop-free simple graphs containing the simple and loop-free 
minors of its members. The following properties are equivalent: 
(1) L is HR, 
(2) L is VR, 
(3) L has bounded tree-width, 
(4) OBST(L) contains a planar graph. 
Assuming these conditions satisfied, from any of the following devices defining 
L one can construct all others, namely: 
(5) an HR grammar (or FHR-system of equations), 
(6) a V R  grammar (or FvR-system of equations), 
(7) an MSI-formula, 
(8) the set OBST(L). 
Pro0 f 
The set L is MS1-definable by Corollary 5.8.5 (based on the Graph Minor 
Theorem). We have the following implications: 

396 
CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
(3) e 
(4) 
(3) e 
(1) 
(1) ==+ (2) 
(2) ==+ (1) 
(5) u (6) 
(8) u (7) 
(7) u (5) 
by Robertson and Seymour [53] 
by Corollary 5.7.7 (2) since the set of graphs of tree-width at 
most k is H R  (see [20]) 
by Theorem 5.6.15 
by a result of [23]. 
because the proofs of Theorem 5.6.15 and [23] are effective. 
by Proposition 5.8.4 
because Corollary 5.7.7 is effective and one can find the 
smallest square grid not in L; from this grid, one gets an 
upper bound on the tree-width of L by [53]. 
by a result of Courcelle and Shizergues [27]. 
We now consider effective constructions of such devices. 
0 
(5) u (8) 
5.8.2 
By combining techniques from logic (definable graph transductions) and from 
graph theory (minor inclusion), one obtains the following result of Seese [56]. 
The structure of sets of graphs having decidable monadic theories 
Theorem 5.8.10 
If a set of graphs has a decidable MS2-theory, then it is a subset of some H R  
set of graphs. 
Pro0 f sketch 
The mapping from a graph to the set of its minors is (2,2)-definable. Hence, if 
a set L of graphs has a decidable MSz-theory, then so has the set of its minors. 
But this set cannot contain all square grids by Proposition 5.2.2. Hence L has 
bounded tree-width (by [53]), hence L is a subset of the set of all graphs of 
tree-width at most k for some k which is H R .  
0 
This result is a kind of converse of the one (Corollary 5.7.7) saying that the 
MS2-theory of a H R  set is decidable. We make the following conjecture. 
Conjecture 5.8.1 1 
If a set of graphs has a decidable MS1-theory then it is a subset of some V R  
set of graphs. 
0 
Special cases of this conjecture are proved in Courcelle [16]. Seese [56] has made 
a conjecture which is equivalent to Conjecture 5.8.11 by the result of [33] in 
the generalized form given in [23]. 

5.8. REFERENCES 
397 
Acknowledgements 
Many thanks to Mrs. A. Dupont and to A. Pari6s for the Latex typing, and to 
E. Grandjean and the referees for comments. 
References 
The reference list below will be updated regularly. The updates can be obtained 
by email request to: 
courcell@labri.u-bordeaux.fr 
or downloaded from my home page on the Web: 
http://www.labri.u-bordeaux.fr/Ncourcell/courcell.html 
ABITEBOUL S., HULL R., VIANU V., Foundations of Data bases, Ad- 
dison Wesley, 1994. 
ARNBORG S., LAGERGREN J., SEESE D., Problems easy for tree- 
decomposable graphs, J. of Algorithms 12 (1991) 308-340. 
BAUDERON M., COURCELLE B., Graph expressions and graph rewrit- 
ings, Mathematical Systems Theory 20 (1987) 83-127. 
BERSTEL J., Transductions and context-free languages, Teubner Verlag, 
Stuttgart, 1979. 
BOLLOBAS B., Extremal Graph Theory, Academic press, New York, 
1978. 
BOSSUT F., DAUCHET M., WARIN B., A Kleene theorem for a class of 
planar acyclic graphs, Information and Computation 117 (1995) 251-265. 
BOURBAKI N., AlgBbre, Chap. 1, Hermann, Paris, 1970. 
BUCHI J., Weak second-order logic and finite automata, Z. Math. Logik 
Grundlagen Math. 5 (1960) 66-92. 
COURCELLE B., An axiomatic definition of context-free rewriting and 
its application to NLC graph grammars, Theoret. Comput. Sci. 55 (1987) 
COURCELLE B., Graph rewriting: An algebraic and logic approach, 
in “Handbook of Theoretical Computer Science, Volume B”, J. Van 
Leeuwen ed., Elsevier, 1990, pp. 193-242. 
COURCELLE B., The monadic second-order logic of graphs I: Recog- 
nizable sets of finite graphs. Information and Computation 85 (1990) 
COURCELLE B., The monadic second-order logic of graphs 111: Tree- 
decompositions, minors and complexity issues, Informatique Thkorique 
et Applications 26 (1992) 257-286. 
141-181. 
12-75. 

CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
COURCELLE B., The monadic second-order logic of graphs V: On clos- 
ing the gap between definability and recognizability, Theoret. Comput. 
Sci. 80 (1991) 153-202. 
COURCELLE B., The monadic second-order logic of graphs VI: On sev- 
eral representations of graphs by relational structures, Discrete Applied 
Mathematics, 54 (1994) 117-149 and erratum in 63 (1995) 199-200. 
COURCELLE B., The monadic second-order logic of graphs VII: Graphs 
as relational structures, Theoret. Comput. Sci. 101 (1992) 3-33. 
COURCELLE B., The monadic second-order logic of graphs VIII: Ori- 
entations, Annals Pure Applied Logic 72 (1995) 103-143. 
COURCELLE B., The monadic second-order logic of graphs IX: Ma- 
chines and their behaviours, Theoret. Comput. Sci. 151 (1995) 125-162. 
COURCELLE B.,The monadic second-order logic of graphs X: Linear 
orderings, Theoret. Comput. Sci., 160 (1996) 87-143. 
COURCELLE B., Structural properties of context-free sets of graphs 
generated by vertex replacement, Information and Computation, 116 
COURCELLE B., Graph grammars, monadic second-order logic and the 
theory of graph minors in “Graph Structure Theory” , Contemporary 
Mathematics 147 American Mathematical Society (1993) 565-590. 
COURCELLE B. , Monadic second-order definable transductions: a sur- 
vey, Theoret. Comput. Sci., 126 (1994) 53-75. 
COURCELLE B., Basic notions of universal algebra for language theory 
and graph grammars, Theoret. Comput. Sci., 163 (1996) 1-54. 
COURCELLE B., ENGELFRIET J., A logical characterization of the 
sets of hypergraphs defined by hyperedge replacement grammars, Math- 
ematical Systems Theory 28 (1995) 515-522. 
COURCELLE B., ENGELFRIET J., ROZENBERG G., Handle- 
rewriting hypergraph grammars 46 (1993) 218-246. 
COURCELLE B., MOSBAH M., Monadic second-order evaluations on 
tree-decomposable graphs, Theoret. Comput. Sci. 109 (1993) 49-82. 
COURCELLE B., OLARIU S., Clique-width, a new complexity measure 
on graphs, preprint, 1995. 
COURCELLE B., SENIZERGUES G., The obstructions of minor-closed 
sets of graphs defined by a context-free grammars, Proceedings of 
the international workshop on Graph Grammars, Williamsburg, 1994, 
DAUCHET M., HEUILLARD T., LESCANNE P., TISON S., Decidabil- 
ity of the confluence of finite ground term rewrite systems and of other 
related term rewrite systems, Information and Computation 88 (1990) 
(1995) 275-293. 
L.N.C.S., Vol. 1073, 1996, pp. 351-367. 
187-201. 

5.8. REFERENCES 
399 
DONER J., Tree acceptors and some of their applications, J. Comput. 
Syst. Sci. 4 (1970) 406-451. 
ELGOT C., Decision problems of finite automata design and related 
arithmetics, Trans. A.M.S. 98 (1961) 21-52. 
EHRIG H., MAHR B., Fundamentals of algebraic specifications 1: equa- 
tions and initial semantics, Springer, 1985. 
ENGELFRIET J., Context-free NCE graph grammars, Proc. FCT’89, 
Lec. Notes CompSci. 380 (1989) 148-161. 
ENGELFRIET J., A characterization of context-free NCE graph lan- 
guages by monadic second-order logic on trees, Lec. Notes CompSci. 
532 (1991) 311-327. 
ENGELFRIET J., HEYKER L., The string generating power of context- 
free hypergraph grammars, J. Comp. Syst. Sci. 43 (1991) 328-360. 
ENGELFRIET J., HEYKER L., Hypergraph languages of bounded de- 
gree, J. Comp. Syst. Sci. 48 (1994) 58-89. 
ENGELFRIET J., ROZENBERG G., Graph grammars based on 
node rewriting: an introduction to NLC graph grammars, Lec. Notes 
Comp.Sci. 532 (1991) 12-23. 
FAGIN R., Generalized first-order spectra and polynomial-time recog- 
nizable sets, in “Complexity of Computation”, SIAM-AMS Proceedings 
FEFERMAN S., VAUGHT R., The first-order properties of products of 
algebraic systems, Fund. Math. 47 (1959) 57-103. 
FELLOWS M., LANGSTON M., An analogue of the Myhill-Nerode the- 
orem and its use in computing finite basis characterizations, 30th symp. 
GECSEG F., STEINBY M., Tree Automata, Akademiai Kiado, Bu- 
dapest, 1984. 
GINSBURG S., RICE , Two families of languages related to ALGOL, J. 
GUREVICH Y., Monadic second-order theories, in J. Barwise and S. 
Feferman eds., “Model theoretic logic”, Springer, Berlin, 1985, pp. 479- 
506. 
HABEL A., Hyperedge replacement: grammars and languages, Lect. 
Notes Comput. Sci. 643, 1992. 
IMMERMAN N., Languages which capture complexity classes, SIAM J. 
Comput. 16 (1987) 760-778. 
KALLER D., Definability equals recognizability of partial 3-trees, 
preprint, 1995. 
(1974) 43-73. 
FOCS (1989) 520-525. 
ACM 9 (1962) 350-371. 

CHAPTER 5. THE EXPRESSION OF GRAPH PROPERTIES ... 
KANNELLAKIS P., Elements of relational data base theory, “Handbook 
of Theoretical Computer Science, Vol. B”, J. Van Leeuwen ed., Elsevier 
LAGERGREN J., ARNBORG S., Finding minimal forbidden minors us- 
ing a finite congruence, LNCS 510 (1991) 532-543. 
MEZEI J., WRIGHT J., Algebraic automata and context-free sets, In- 
formation and Control 11 (1967) 3-29. 
PILLING D., Commutative regular equations and Parikh’s theorem, J. 
London Math. Soc. 6 (1973) 663-666. 
PIN J.-E., Logic, semigroups and automata on words, Annals of Mathe- 
matics and Artificial Intelligence, 16 (1996). 
RABIN M., A simple method for undecidability proofs and some applica- 
tions, in “Logic, Methodology and Philosophy of Science 11”, Y. Bar-Hillel 
ed., North-Holland, Amsterdam, 1965, pp.58-68. 
RAOULT J.-C., A survey of tree transductions, in “Tree automata and 
languages”, M. Nivat and A. Podelski eds., Elsevier, 1992, pp. 311-326. 
ROBERTSON N., SEYMOUR P., Graph minors V: Excluding a planar 
graph, J. Comb. Theory Ser. B 52 (1986) 92-114. 
ROBERTSON N., SEYMOUR P., Graph minors XX: Wagner’s conjec- 
ture, September 1988. 
ROZENBERG G., WELZL E., Boundary NLC grammars, Basic defini- 
tions, normal forms and complexity, Information and Control 69 (1986) 
SEESE D., The structure of the models of decidable monadic theories of 
graphs, Annals Pure Applied Logic 53 (1991) 169-195. 
SHELAH S., The monadic theory of order, Annals of Maths 102 (1975) 
STOCKMEYER L., The polynomial-time hierarchy, TCS 3 (1977) 1-22. 
THATCHER J., WRIGHT J., Generalized finite automata theory with 
an application to a decision problem in second-order logic, Math. Systems 
Theory 3 (1968) 57-81. 
THOMAS W., Automata on infinite objects, “Handbook of Theoretical 
Computer Science, Volume B” Elsevier 1990, pp. 133-192. 
THOMAS W., Classifying regular events in symbolic logic, J. Comput. 
System Sci. 25 (1982) 360-376. 
TRAKHTENBROT B., Impossibility of an algorithm for the decision 
problem on finite classes, Dokl. Akad. Nauk.SSSR 70 (1950) 569-572. 
WECHLER W., Universal Algebra for Computer Scientists, Springer, 
1992. 
WIRSING M., Algebraic Specifications, “Handbook of Theoretical Com- 
puter Science, Volume B” J. Van Leeuwen ed., Elsevier 1990, 675-779. 
1990, pp. 1073-1156. 
136-167. 
379-419. 

Chapter 6 
2-STRUCTURES - A FRAMEWORK 
FOR DECOMPOSITION AND 
TRANSFORMATION OF GRAPHS+ 
A. EHRENFEUCHT 
Department of Computer Science, University of Colorado at Boulder 
Boulder, Co 80309, U.S.A. 
T. HARJU 
Department of Mathematics, University of Turku 
FIN-20500 Turku, Finland 
G. ROZENBERG 
Department of Computer Science, Leiden University 
P.O.Box 9512, 2300 RA Leiden, The Netherlands 
and 
Department of Computer Science, University of Colorado at Boulder 
Boulder, Co 80309, U.S.A. 
A 2-structure g is a pair ( D , R )  consisting of a finite set D and an equivalence 
relation R on the ordered pairs (z,y) E D x D with z # y. These structures can 
be used to study various combinatorial properties of systems such as graphs, par- 
tially ordered sets and communication networks. We present the basic theory of 
2-structures, where the main interest is in the clan decomposition of these struc- 
tures providing a generalization of the modular decomposition (or the substitution 
decomposition) of graphs and directed graphs. 
We consider also local transformations on 2-structures with a labeling of the edges, 
where the labels come from a group. For these one uses the group operations lo- 
cally in the nodes to induce transformations of the labels of the edges and thus 
generating from a single labeled 2-structure a set of labeled 2-structures, which is 
referred to as a dynamic labeled 2-structure. Since the transformations are based on 
groups, one obtains an elegant way to define graph transformations. This approach 
is a generalization of Seidel switching for undirected graphs. Also here the notion 
of a clan remains central. Now a clan of a dynamic labeled 2-structure is a clan 
of any of its component labeled 2-structures. As a matter of fact one of the main 
themes investigated in the theory of dynamic labeled 2-structures is the behaviour 
of the clan decomposition under the group induced by the local transformations. 
t The authors are grateful to BRA Working Groups ASMICS, COMPUGRAPH and 
Stieltjes Institute for their support. 
401 

Contents 
6.1 
Introduction . . . . . . . . . . . . . . . . . . . . . . . .  
403 
6.2 
2-Structures and Their Clans . . . . . . . . . . . . .  404 
6.3 Decompositions of 2-Structures . . . . . . . . . . . .  411 
6.4 Primitive 2-Structures . . . . . . . . . . . . . . . . .  430 
6.5 Angular 2-structures and T-structures . . . . . . .  434 
6.6 Labeled 2-Structures . . . . . . . . . . . . . . . . . .  442 
6.7 Dynamic Labeled 2-Structures . . . . . . . . . . . .  447 
6.8 Dynamic l2-structures with Variable Domains . . 457 
6.9 
Quotients and Plane Trees . . . . . . . . . . . . . . .  460 
6.10 Invariants . . . . . . . . . . . . . . . . . . . . . . . . .  469 
References . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
476 

6.1. INTRODUCTION 
403 
6.1 Introduction 
This paper is a tutorial on the theory of 2-structures as initiated in Ehrenfeucht 
and Rozenberg [16]. We have included only the most illustrative proofs from 
the literature together with new proofs for some of the older results. We assume 
that the reader is familiar with the basic concepts of graph theory, see Bondy 
and Murty [l]. 
A 2-structure g = (D , R) consists of a finite domain D together with an equiv- 
alence relation R on the ordered pairs (z,y) E D x D with z # y. Hence a 
2-structure can be considered as a complete directed graph with an ‘abstract 
colouring’ of the edges. 
To make a colouring of the edges concrete one adds a labeling function to a 
2-structure obtaining in this way a labeled 2-structure. In the literature the 
term ‘2-structure’ is used both as a technical term as defined above and as a 
generic term referring to the theory of labeled and ‘unlabeled’ 2-structures. 
These structures can be used to study various combinatorial properties of sys- 
tems such as graphs, partially ordered sets and communication networks, where 
all kinds of (binary) relationships hold between the objects of a system. We 
refer to Buer and Mohring [3], Ehrenfeucht and Rozenberg [IS] and Schmerl 
and Trotter [40] for some of the intuition and motivation. 
In this paper we present the basic theory of 2-structures. We cover both the 
‘static’ part of the theory concerned mainly with the hierarchical representa- 
tions of 2-structures, and the ‘dynamic’ part of the theory concerned with the 
local transformations of 2-structures. 
The general results on the static properties of 2-structures are presented in 
Sections 6.2 through 6.6, where the main interest is in the clan decomposition 
of these structures. A clan X of a 2-structure g is a subset of the domain of g 
such that an element y 6 X cannot make a distinction between the elements of 
X by using the equivalence relation R of g, i.e., for all y 6 X and 21, z2 E X 
Decompositions of combinatorial and algebraic structures are special cases 
of the divide-and-conquer method, where a large problem is partitioned into 
smaller problems, and a method is given how to link the solutions of the sub- 
problems into a solution of the original problem. The clan decomposition of 
2-structures is an example of such a method, which provides a generalization 
of the modular decomposition (or substitution decomposition) of graphs and 
directed graphs, see Gallai [25], Habib and Maurer [27], Cunningham [4] and 
Muller and Spinrad [37]. In the clan decomposition a 2-structure g is divided 
we have that (y,n)R(y,z2) and (21,y)R(z2,31)- 

404 
CHAPTER 6. BSTRUCTURES - A FRAMEWORK FOR ... 
into disjoint substructures g1 , . . . , g k ,  and a quotient 2-structure is constructed 
to indicate the relationships between the substructures gi. For another kind 
of a general approach to the clan decomposition theorem we refer to Mohring 
and Radermacher [36] and Mohring [35]. 
The results on the local transformations are presented in Sections 6.7 through 
6.10. Here one assumes that the labels used by a labeled 2-structure form a 
group. One uses then the group operations, applied locally in the nodes, to 
induce transformations of the labels of the edges. The domain, i.e., the set of 
nodes, does not change in these transformations. In this way a single labeled 
2-structure generates a whole set of labeled 2-structures, which is referred to as 
a dynamic labeled 2-structure. Since the transformations are based on groups, 
one obtains in this way an elegant way to define graph transformations. 
Also here the notion of a clan remains central. Now a clan of a dynamic labeled 
2-structure is a clan of any of its component labeled 2-structures. As a matter 
of fact one of the main themes investigated in the theory of dynamic labeled 2- 
structures is the behaviour of the clan decomposition under the group induced 
by the local transformations. 
It is interesting to notice that the notion of a clan has been rediscovered quite 
many times under various names. In particular, a clan corresponds to the 
domain of the right hand side of a production in node-rewriting graph gram- 
mars with hereditary connection relation, see Chapter 1 of the present book. 
For other appearances and applications of the notion of a clan, see Buer and 
Mohring [3] or Muller and Spinrad [37]. 
6.2 2-Structures and Their Clans 
6 . 2 1  Definition of a %structure 
Let D be a finite nonempty set, and let 
E2(D) = { ( Z , Y )  1 %  E D,Y E D , x  f Yl 
be the set of all (directed) edges between the elements of D. For an edge 
e = (z,y), 
we denote by e-l = (y,z) the reverse edge of e. 
A 2-structure g = ( D ,  R) consists of a finite nonempty set D ,  called its domain, 
and an equivalence relation R C &(D) x E2(D) on its edges. The domain of 
g is denoted by dom(g). The elements of the domain D of g are called nodes. 
The equivalence relation of a 2-structure g is sometimes written as R,. 
Equivalently, a 2-structure g = (D, R) can be defined as a triple G = 
(D,E,R’), where the pair ( D , E )  is a directed graph, i.e., E 5 E2(D), and 

6.2.2-STRUCTURES AND THEIR CLANS 
405 
R’ is an equivalence relation defined on E such that the equivalence relation 
R of g is obtained as an extension of R‘ by additionally setting elRe2 for all 
‘nonedges’ e l ,  e2 4 E. 
For a 2-structure g = ( D ,  R) and an edge e E E2(D), we let e R  = {e‘ I eRe’} 
denote the equivalence class of R containing e E E2(D), and we call e R  an 
edge class of g. Hence el Re2 if and only if el R = e2R for the edges el and e2 
A 2-structure g = ( D ,  R) can be represented as a complete directed graph with 
nodes D and (directed) edges Ez(D) together with a colouring of the edges 
corresponding to the edge classes. Here a colouring is a mapping a: Ez(D) + 
K of the edges into a set K of colours such that elRe2 if and only if a(e1) = 
a(e2). Notice, however, that such a colouring a for a 2-structure g is by no 
means unique, since the choice of the colours is arbitrary in the representation. 
The function a that maps each edge e to its edge class e R  is just one possible 
colouring of g. 
Example 6.1 
Let D = { q , x 2 , 2 3 ,  z 4 )  be a domain of four nodes, and let eij = (xt, 
xj) for 
i # j .  Define a 2-structure g = (D , R) by its edge classes: 
of g .  
e12R = (e12, e21, e13, e 2 3 ~  e24, e42, e41}, 
e3lR = (e31, e32, e 3 4 ~  ~ 3 ) .  
el4R = { e 1 4 } ~  
Clearly, these edge classes are disjoint, and E2(D) = e12R U el4R U e31R. 
Both of the complete coloured directed graphs below represent g .  In these 
representations the edge classes have received the colours a,b,c and b,a,d, re- 
spectively. 
0 
We notice that a 2-structure g = (D , R) can also be considered as a packing of 
the directed graphs geR = ( D , e R )  with the edge sets e R  for e E E2(D). For 
an edge class a = e R  we call ga a packed component of g .  See, e.g., Yap [43] 
for more information on the topic of packing (of trees). 
Example 6.2 
In Figure 6.2 we have unpacked the 2-structure of Example 6.1. Here the edge 
0 
An edge e of g is said to be symmetric, if eRe-’ 
( i e . ,  e R  = e-’R), and an 
edge class a is symmetric, if all edges e E a are symmetric, i.e., e E a if and 
classes of g are ( z 1 , ~ 2 ) R , ( z 3 , q ) R  
and (x1,zq)R. 

406 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR .._ 
Figure 6.1: Two colourings of a 2-structure 
Figure 6.2: The packed components of g 
only if e-’ 
E a. If a is a symmetric edge class then the packed component ga 
can be thought of as an undirected graph. 
In Example 6.1, the edge (q x2) is symmetric] but the edge class ( 5 1 ,  z2)R is 
not symmetric] because ( z l , x 2 ) R  = ( z ~ , Q ) R  
and ( x 1 , ~ ) R  
# (54,51)R. In 
fact, the 2-structure g from Example 6.1 does not have any symmetric edge 
classes. 
Example 6.3 
One can represent various properties of graphs using 2-structures. Let G = 
( D ,  E )  be an undirected graph. Here E is a subset of the set Sz(Z3) of 2- 
element subsets (2, y} of D with z # y. 
(1) The graph G can be represented as a 2-structure g(G) = ( D ,  R) with two 
symmetric edge classes by defining el Re2 for all el, e2 E E and for all el, e2 $ 
E. Notice, however, that the representing 2-structure g(G) cannot make a 
distinction between a graph G and the complement graph (D,Sz(D) \ E )  of 
G. 
(2) We can define a 2-structure g = (D , R) for G by setting elRe2 if and only 
if the edges el, e2 E Ez(D) belong to a common cycle of G. (Recall that a cycle 
in a graph is a sequence e1e2 . . . ek of edges ei = {xi, zi+l} for i = 1,2,. . . , Ic, 

6.2.2-STRUCTURES AND THEIR CLANS 
407 
where x1 = xk+l and the nodes X I ,  x2,. . . , xk are distinct from each other). 
Clearly, the so defined relation R is an equivalence relation on Ez(D), 
and the 
2-structure g that represents the cycle structure of G is usually quite different 
0 
from the representing 2-structure g(G) of G. 
Each 2-structure g with n nodes has n(n - 1) edges, and thus drawing a larger 
g is usually inconvenient. However, drawing reversible 2-structures (defined 
below) is easier. 
A 2-structure g = (D, R) is reversible, if g satisfies 
for all edges el , e2 E E2 (D). 
Equivalently, g is reversible, if for each edge class a there corresponds a unique 
edge class a-l, called the reverse class of a, such that for each edge e, 
e E a  
e-' 
~ a - l .  
Notice that we may have a = a-l, in which case the edge class a is symmetric. 
We simplify the drawings of reversible 2-structures by 
- omitting the reverse edge classes of the chosen edge classes, 
- drawing a line segment between x and y, if the edge (x,y) is symmetric, 
and 
- often omitting one symmetric edge class. 
Example 6.4 
The 2-structure g in Figure 6.3 with dom(g) = { X I ,  . . . , 2 8 )  has two symmetric 
edge classes c and d. The edges in the class d have not been drawn, e.g., the 
edges ( X I  , x3) and (x2, 2 7 )  together with their reverse edges are in the edge class 
d among quite many other edges (and their reverse edges). The 2-structure g 
has four nonsymmetric edge classes a, a-l , b and b-' , of which we have drawn 
0 
the classes a and b only. 
6.2.2 Clans 
Let X be a nonempty subset of the domain D of a 2-structure g = (D, R). 
Then the substructure induced by X is defined as the 2-structure 

408 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
a 
Figure 6.3: A simplified representation of a reversible 2-structure g 
which is obtained from g by restricting the relation R to the subset E2(X) of 
E2(D). 
The edge classes of h = sub,(X) are eRh = eR, n E2(X). 
The most important technical notion of this paper is that of a clan. We call 
a subset X C dom(g) a clan, if every node y $! X sees the nodes of X in the 
same way, 
and every two nodes XI , 2 2  E X see every node y $! X in the same way, 
(y, xl)R(y, 2 2 )  
for all 
2 1  , 2 2  E X ,  y $! X ,  
( 2 1  , y)R(22, y) 
for all 
5 1  , 2 2  E X ,  Y $! X .  
The set of all clans of g is denoted by C(g). 
A clan X E C(g) is said to be proper, if X is a proper subset of the domain of 
9- 
It follows directly from the definition that the empty set 8 and the domain 
dom(g) of g are clans of g. Also, it is equally clear that the singletons {x}, 
x E dom(g), are clans. The sets 0, dom(g) and the singletons are the trivial 
clans of g. A 2-structure g that has no other than the trivial clans is called 
primitive. 
The substructure sub,(X) induced by a nonempty clan X E C ( g )  is called a 
factor of 9. 
Example 6.5 
Consider the 2-structure g = (D, 
R) of Example 6.4, see Figure 6.3. The two 

6.2.2-STRUCTURES AND THEIR CLANS 
409 
substructures sub,(X) and sub,(Y), that have been indicated by rectangles in 
Figure 6.4, are factors of g. 
0 
Y 
X 
Figure 6.4: Two clans X and Y ,  and their factors in g 
We show now that restricting ourselves to reversible 2-structures does not 
imply a loss of generality as far as the clans are concerned. 
Consider a 2-structure g = ( D ,  R), and define a relation S on &(D) by 
else2 
elRe2 and eL1ReY1 
(e1,eZ E E2(D)). 
Clearly, S is an equivalence relation. We observe that the new 2-structure 
h = (D,S) is reversible. Indeed, if elsea, then by the definition of S, also 
eT1SeT1. On the other hand, if y,x1 and 2 2  E D are nodes such that either 
(y,zl)R # (y,zz)R or (z1,y)R # (z2,y)R in 9, then by the definition of S ,  
also (y,xl)S # (y,zz)S in h. The converse holds equally well, and therefore 
we have the following 'normal form theorem' for 2-structures. 
Theorem 6.2.1 
For each g = (D, R) there exists a reversible 2-structure h = (D, 
S )  such that 
0 
Reversible 2-structures are simpler to handle than the general 2-structures. As 
an example, we have the following one-way condition for clans: 
for all X C D, C(subg(X)) = C(subh(X)). In particular, C(g) = C(h). 
Lemma 6.2.2 
A subset X 5 dorn(g) of a reversible g is a clan if and only if for all y $ X and 
i x2 E x 7  (y, 
= (97 z2)R. 
0 

410 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
We take the advantage of Theorem 6.2.1, and consider only reversible 2- 
structures an the rest of the paper. 
6.2.3 Basic properties of clans 
Let g = ( D , R )  be a (reversible) 2-structure. The following result gives the 
basic closure properties of clans. 
Lemma 6.2.3 
Let X , Y  E C(g). Then 
(1) x n y  E C(g); 
(2) if X n Y # 0, then X u Y E C(g); 
(3) if Y \ X # 0, then X \ Y E C(g). 
Pro0 f 
The first two cases of the claim are rather easy to prove, and hence we prove 
only claim (3). Suppose that y E Y \ X .  Denote 2 = X \ Y ,  and let x 4 2, 
z1,z2 E 2. 
If x 4 X ,  then ( x , z l ) R  = (x,za)R, because z1,z2 E X and X is a 
clan. 
If, on the other hand, x E X ,  then x E X n Y .  Because Y is a clan and z1 , z2 4 Y 
and x , y  E Y ,  we have ( x , z l ) R  = ( y , z l ) R  and (x,z2)R = (y,aa)R. Moreover, 
X is a clan with y 4 X and z1,za E X ,  and therefore ( y , z l ) R  = (y,zz)R. 
Combining these we obtain 
( x , a ) R  = (Y, 
Z l ) R  = (v, z2)R = (2, z2)R, 
and therefore 2 = X \ Y is a clan. 
0 
We say that two subsets X and Y of a domain D overlap, if X n Y # 0, 
X \ Y # 0 and Y \ X # 0, ie., neither X C Y nor Y G X nor X n Y = 0. 
By Lemma 6.2.3, we have 
Lemma 6.2.4 
If X I  Y E C(g) overlap, then X n Y, X U Y, X \ Y E C(g). 
0 
In fact, the above reasoning can be sharpened to show 
Lemma 6.2.5 
If the clans X and Y overlap, then the edges in 
( X \ Y ) x ( X n Y )  u ( X \ Y ) x ( Y \ X )  u ( X n Y ) x ( Y \ X )  
belong to the same edge class. 
0 

6.3. DECOMPOSITION OF 2-STRUCTURES 
41 1 
On the other hand, the clans of a 2-structure g need not be closed under 
complement. Indeed, consider the primitive 2-structure g of four nodes and 
two symmetric edge classes from Figure 6.5. Since g has only the trivial clans, 
the complement dom(g) \ {z} of the singleton clan {z}, for z E dom(g), is not 
a clan of g. Also, C(g) is not necessarily closed under symmetric difference. 
However, if g has only symmetric edge classes, then C(g) is also closed under 
symmetric difference. 
0 
0 
0-0 
a 
Figure 6.5: A primitive g 
The following rather obvious lemma is crucial for the definition of a quotient. 
Lemma 6.2.6 
I f  X ,  Y E C(g) and X n Y = 0, then (21, yl)R = (z2, y2)R for all 5 1 ,  z2 E X 
and Y1,Y2 E y .  
0 
By the following result the clans of the factors sub,(X) are exactly those clans 
of g that are contained in X .  
Theorem 6.2.7 
Let h = sub,(X) be a factor of g .  Then 
C(h) = {Y I Y C X, Y E C(g)}. 
0 
Example 6.6 
The 2-structure g from Example 6.4 (see Figure 6.3) has a factor h = sub,(X) 
for X = {XI, z2, z3}, 
and 2 = (z1, z3) is a clan of h. Hence 2 is also a clan of 
9. 
0 
6.3 Decompositions of 2-Structures 
6.3.1 Prime clans 
A nonempty clan P E C(g) is a prime clan, if it does not overlap with any clan 
of g. Clearly, the nonempty trivial clans are prime clans. 

412 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
We denote by P(g) the set of all prime clans of g. For a prime clan P of g, the 
factor sub,(P) is called a prime factor of g. 
The next lemma follows immediately from the definition of a prime clan. 
Lemma 6.3.1 
Let g = ( D , R ) .  If P is a prime clan and X E C(g) intersects with P, then 
either P C X or X 
P. 
0 
By Theorem 6.2.7, we may easily deduce that if a prime clan P E P(g) is 
contained in a clan X E C(g), then P is a prime clan of the factor sub,(X). 
Also the converse holds for proper prime clans of the factor sub,(X) as can 
been seen using Lemma 6.3.1. Hence we have 
Theorem 6.3.2 
If h = sub,(X) is a factor of g, then 
P(h) = {P 1 P E P(g), 
P c_ X }  u {X). 
0 
6.3.2 Quotients 
Let g be a (reversible) 2-structure and let X = {XI, X Z ,  . . . , X k }  be a parti- 
tion of dom(g) into nonempty clans. We call X a factorization of g, and the 
substructures sub,(Xi) are the factors of this factorization. 
Each 2-structure g has at least the trivial factorizations X = {dom(g)} and 
X = {{z} I z E dom(g)}. 
The quotient of a g = (D, R) by a factorization X is defined to be the 2- 
structure g/X with the domain X, 
and the equivalence relation R x ,  for which 
(Xl,Yl)RX(X2,Y2) - 
(3a,Yl)W52,Y2) for some zi E xi, Yi E yi, 
where each Xi, Y, E X. 
Thus a quotient g/X is obtained from g by contracting 
each clan X in the partition X into a single node, and then inheriting the edge 
classes from g. 
By Lemma 6.2.6, the quotient g/X is well-defined, i.e., it is independent of the 
choice of the representatives: if (q,y1)R(z2,y2) for some 21 E XI, z 2  E X2, 
and y1 E Y1, y2 E Yz, then (sl,yl)R(zz,yz) for all z1 E XI, 5 2  E X2 and 
yl E Y1, y2 E Y2 (where Xi,Y, are in X). 
Example 6.7 
The 2-structure g from Example 6.4 (see Figures 6.3 and 6.4) has a factorization 

6.3. DECOMPOSITION OF 2-STRUCTURES 
413 
We can redraw g with respect to X as in Figure 6.6. The quotient g/X is now 
0 
obtained by contracting the factors into nodes as in Figure 6.7. 
2 1  \ 
a 
Figure 6.6: Disjoint factors of g 
Figure 6.7: g / X  
Y 
of a 2-structure g consists of the factors subg(Xi) with respect to a factorization 
X = {XI,. 
. . , X,} together with the quotient g/X that gives the relationships 
between the factors. 

414 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
In the general case of 2-structures (that we have been studying now in contrast 
to the labeled 2-structures of Section 6.6) we may lose some information in the 
formation of a decomposition. Indeed, as the next example shows, two different 
2-structures may possess a common decomposition. 
Example 6.8 
The 2-structures g1 and g2 of Figure 6.8 have a common factorization X = 
{{ZI,ZZ}, 
{ 2 3 , ~ 4 } } .  Moreover, 
~~bg1({21,2~}) 
= SUbg2({21,22)) 
and 
SUbg1({23,24}) = ~ ~ b g 2 ( { ~ 3 , ~ 4 } ) .  
h 
h 
21 - 
- 
x3 
Figure 6.8: g1 and g2 
Also, the quotients g1/X and gZ/X are equal as shown in Figure 6.9. How- 
ever, g1 and g2 are different 2-structures, since ( 2 1 ,  z2)Rg, = ( 2 3 ,  24)Rg, , but 
0 
( 2 1 ,  4 R g ,  # ( 2 3  , 24)Rg2. 
Figure 6.9: A common factorization X 
Next we shall study the clans of the quotients g / X  for factorizations X C C(g). 
For this we adopt the following notations. If d is a family of sets, then let 
ud= u A, 
and 
n d =  
A. 
A E d  
A E d  
Let g = ( D , R )  and let X be a factorization of g. For each subset Y C D ,  we 
let 
K ~ ( Y )  
= {x I x E x , X n Y  # 0 )  

6.3. DECOMPOSITION OF 2-STRUCTURES 
415 
be the frame of Y in g / X ;  the situation is illustrated in Figure 6.12 
Figure 6.10: The frame of Y in g / X  
We begin with an immediate result. 
Lemma 6.3.3 
Let g = ( D, R) and let X be a factorization of g. If Y E C(g), then K x ( Y )  E 
D 
C ( g / X )  and U K x ( Y )  E C(g). 
It can happen that for a prime clan 2 of a quotient g / X ,  the ‘inverse image’ 
U 2  is not a prime clan of g. Indeed, consider a factorization X and a clan 
X E X. Now, X is a singleton clan of the quotient g / X ,  and hence a prime 
clan in this quotient, but U{X} E P ( g )  only if X 6 P ( g ) .  The following lemma 
states that the singletons are the only examples of such a situation. 
Theorem 6.3.4 
Let g = ( D ,  R) and let X be a factorization of g. 
(1) If 2 E C ( g / X ) ,  then UZ 
E C ( g ) .  
(2) If 2 E P ( g / X )  is not a singleton, then U Z  E P ( g ) .  
(3) If X 
Case (1) follows easily from the definition of clan, and Case (3) is a consequence 
of (2) and the discussion above. Hence we need to prove only (2). 
Suppose 2 is a proper prime clan of the quotient g / X  (z.e., 2 # X). 
By (I), 
U Z  E C(g). Assume now that there exists a clan Y E C(g) that overlaps with 
U 2 .  By Lemma 6.3.3, the frame K x ( Y )  is a clan of g / X ,  and UKx(Y) 
E C(g). 
P ( g ) ,  then for each prime clan 2 E P ( g / X ) ,  also U 2  E P(g). 
Proof 

416 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
Since 2 is a prime clan in the quotient, K;y(Y) does not overlap with it. But 
clearly, 
K x ( Y )  n 2 # 8 
and 
K x ( Y )  \ 2 # 8, 
since Y flu2 # 0 and Y \ U 2  # 0. Therefore 2 C K x ( Y ) ,  where the inclusion 
is proper. 
By above, for each z E U 2  there exists an X E 2 such that X n Y # 8 and 
z E x. 
Let z E U 2  \ Y .  Such a z exists, because U Z  and Y overlap. Let X E 2 be 
such that X n Y # 8 and z E X \ Y .  The situation is now as in Figure 6.11. 
D 
~ 
~ 
Figure 6.11: X and Y overlap 
It follows that X and Y overlap with each other, and, in particular, Y \ X is a 
clan of g by Lemma 6.2.4. By Lemma 6.3.3, Kx(Y \ X )  E C ( g / X ) .  However, 
Kx(Y \ X )  = K x ( Y )  \ { X } ,  since X E X .  Now, Kx(Y \ X )  overlaps with 2 
0 
unless 2 = { X }  is a singleton clan of g / X .  This proves the claim. 
6.3.3 Maximal prime clans 
Let g = (D, 
R). A clan M E C(g) is called maxzmal, if it is a proper clan and 
for all proper clans X ,  M C X implies that X = M .  
A prime clan P E P(g) is a maximal prime clan, if it is a proper clan, and 
maximal among the proper prime clans of 9: for all proper prime clans Q, 
P C Q implies that Q = P. 
We denote by Pmax(g) the set of all maximal prime clans of g. For a maximal 
prime clan P E Pmax(g), 
the factor sub,(P) is called a maximal prime factor 
of g. 

6.3. DECOMPOSITION OF 2-STRUCTURES 
417 
We observe that all 2-structures g = (D, R) with ID1 2 2 have maximal prime 
clans, because every singleton is a prime clan. By definition of maximality, 
this is not true in the trivial case, where ID1 = 1. For this reason we set 
Pmax(g) = { D} , if ID1 = 1. 
Lemma 6.3.5 
Let g = ( D ,  R). Every x E D belongs to a unique maximal prime clan P, of g. 
Pro0 f 
Suppose ID1 2 2. For each x E D there is a proper prime clan containing x, 
namely {x}. Let P, be then a proper prime clan so that P, is maximal with 
respect to the condition x E P,. Such a P, exists because the domain D is 
finite. Now, if P # P, is a proper prime clan with x E P, then P n P, # 8, and 
by the maximality of P,, P, c P cannot hold. Hence since P is a prime clan, 
P c P,, and therefore P, is the unique maximal prime clan containing x. 0 
Theorem 6.3.6 
Let g be a 2-structure. The maximal prime clans form a partition Pmax(g) of 
dom(g), and therefore the quotient g/Pmax(g) is well-defined. 
Proof 
By Lemma 6.3.5, each node x belongs to a unique maximal prime clan P,, and 
thus dom(g) is a disjoint union of the maximal prime clans, because for each 
0 
z,y E dom(g) either P, = Pv or P, n Py = 0. 
Lemma 6.3.7 
For each clan Y E C(g) either Y C P for a maximal prime clan P E Pmax(g) 
or Y is a enion of maximal prime clans. 
Proof 
Assume Y is not a subset of any maximal prime clan of g. If Y n P # 8 for 
some P E Pmax(g), then Lemma 6.3.1 implies that P c Y .  Since every y E Y 
belongs to a unique maximal prime clan Py and Py n Y # 8, it follows that 
y =  UPY, 
llEY 
which proves the claim. 
0 
Since each singleton is a prime clan, it follows that every clan Y E C(g) is the 
union of prime clans P E P(g) that are contained in Y .  By Theorem 6.3.2, the 
prime clans P of the factor sub,(Y) are exactly the prime clans of g that are 
contained in Y .  Therefore we have the following result. 

418 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
Theorem 6.3.8 
Each nonsingleton clan Y E C(g) is the union of the prime clans P E P(g) that 
0 
are the maximal prime clans of the factor sub, (Y). 
6.3.4 Special 2-structures 
Recall that a 2-structure g is primitive if it has only the trivial clans. We 
generalize the notion of primitivity by defining a 2-structure g to be special, 
if all its prime clans are trivial. Hence if g is special, then Pmax(g) consists of 
the singletons of the domain. 
The next result from [16] is crucial for the clan decomposition theorem. 
Theorem 6.3.9 
The quotient g/Pmax(g) is special. 
Pro0 j 
Assume that g/Pmax(g) has a prime clan X = {PI,. 
. . , Pk} for k 2 2, where 
each Pi is a maximal prime clan of g. By Theorem 6.3.4(2), 
k 
x = U Pi E P(g). 
i= 1 
Hence, because each Pi c X (i = 1,2,. . . , k )  is a maximal prime clan of g, we 
must have that X = dom(g). Thus X is the domain of the quotient g/X, and 
0 
hence not a proper prime clan. 
Lemma 6.3.10 
Let g be a special 2-structure. Then either 
(1) the maximal clans M are all singletons, or 
(2) all the complements dom(g) \ M of the maximal c, 
Proof 
Suppose M E C(g) is a maximal clan with at least two nodes. Since in a special 
g all prime clans are trivial, M is not a prime clan, and hence there exists a clan 
X that overlaps with M .  By Lemma 6.2.4, M U X E C(g) and X \ A4 E C(g). 
Now, since M is maximal and M c M U X ,  it follows that M U X = dom(g), 
and hence, in particular, dom(g) \ M = X \ M .  By above, the complement 
of M ,  
is a prime clan, then it must be a 
singleton because g is special. On the other hand, if 
overlaps with another 
clan Y ,  then Y overlaps also with M by maximality of M ,  and in this case 
M U Y E C(g) would be a proper clan contradicting the maximality of M .  We 
conclude that a is a singleton clan. 
M are singletons. 
= dom(g) \ M ,  is a clan. If 

6.3. DECOMPOSITION OF 2-STRUCTURES 
419 
Finally, if N is any other maximal clan, then the above argument shows that 
either its complement 
is a singleton or N itself is a singleton. The latter 
condition cannot hold, because IN1 = 1 would imply N = % or N C M .  The 
inclusion N C M and the assumption N # M imply N c M ;  this contradicts 
the maximality of N .  Hence N = 
holds. Since X overlaps with MI we get 
0 
N c X contradicting the maximality of N .  
6.3.5 The clan decomposition theorem 
We shall now give a new proof of the clan decomposition theorem of [16] using 
maximal clans. 
A 2-structure g = (D, 
R) is said to be complete, if it has only one edge class, i.e., 
for all el, e2 E E2(D), 
elRe2. In particular, the only edge class is symmetric, 
i.e., eRe-' for all e E E2(D). 
Clearly, in a complete 2-structure g each subset 
of the domain is a clan. It follows from this that a complete 2-structure is 
special. 
A 2-structure g is said to be linear, if g has a nonsymmetric edge class a which 
linearly orders the domain D of g, i.e., D has an ordering 2 1 ,  x2,. . . , x, such 
that (xi,xj) 
E a if and only if i < j. In this case the nonempty clans of g are 
exactly the segments {xi,xi+l,. . . , x i + k }  for 1 5 i 5 i + k 5 n. Consequently, 
a linear 2-structure is special. 
Recall also that a g is primitive, if it has no nontrivial clans. Notice that a 
2-structure g with at most two nodes is always primitive and at the same time 
either complete or linear. For this reason we say that g is truly primitive, if it 
is primitive and it has at least three nodes. 
a 
0 
0 
0 
0 
a 
a 
0
-
0
 
0
-
0
 
a 
Figure 6.12: A complete and a linear 2-structure on four nodes 
As stated in the following theorem (from [IS]) there are only three types of 
special 2-structures. 

420 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
Theorem 6.3.11 
A 2-structure g is special if and only if it is either linear, or complete, or truly 
primitive. 
Proof 
It is easy to show that if g is complete, linear or primitive, then its prime clans 
are trivial. 
Suppose then that g = ( D ,  R) is special. We show by induction on the number 
ID[ of nodes in the domain that g is of one of the types as claimed. The claim 
clearly holds if ID1 5 3 (by simple case analysis). 
Assume that )Dl > 3, and let A4 be a maximal clan of g. If )MI = 1, then by 
Lemma 6.3.10 it follows that g is primitive] since now the maximal clans are 
singletons] and so all the proper clans are singletons. 
We may thus assume that IMI > 1, and hence, again by Lemma 6.3.10, that 
the complement 
of A4 is a singleton. Let D \ A4 = {v}. There exists a 
maximal clan N that contains 21, and, as above, IN1 > 1 and the complement 
N is a singleton] say D \ N = {w}, see Figure 6.13. 
- 
Figure 6.13: Maximal A4 and N 
Consider the maximal factor sub,(M). If P is a proper prime clan of sub,(M), 
then P is also a proper prime clan of g by Theorem 6.3.2, and hence P is 
necessarily a singleton. Therefore sub,(M) is special, and by the induction 
hypothesis sub, ( M )  is complete, linear or primitive. 
The factor sub, ( M )  cannot be primitive, since it has the nontrivial clan N n A4 
by Theorem 6.2.7 and by the fact that ID1 > 3. 
Assume that sub,(M) is linear or complete. Since M E C(g) and v f M ,  
(w, y)R = (v, w)R 
for all 
y E M .  
Also, since N E C(g) and w f N ,  
(v, 
w)R = (y,w)R 
for all 
y E N .  

6.3. DECOMPOSITION OF 2-STRUCTURES 
42 1 
From these it follows that (v, y)R = (y,w)R for all y E M n N ,  and thus g is 
0 
linear if sub,(M) is linear, and g is complete if sub,(M) is complete. 
We have thus proved the following clan decomposition theorem of [16]. 
Theorem 6.3.12 (Clan decomposition theorem) 
For any 2-structure g ,  the quotient g/Pmax(g) is either linear, or complete, or 
truly primitive. 
0 
There are also other proofs of the clan decomposition theorem, see Ehrenfeucht 
and Rozenberg [16], Engelfriet, Harju, Proskurowski and Rozenberg [23] and 
Harju and Rozenberg [30]. In a general setting the decomposition theorem is 
proved also in Mohring and Radermacher [36] and Mohring [35]. The decom- 
position theorem for submodular functions as presented by Cunningham [5] is 
closely related to the clan decomposition theorem. In [36] and [30] the proofs 
are given for infinite domains, for which the theorem has a minor modification 
due to the fact that maximal prime clans may not exist, if the domain of a 
2-structure is infinite. 
For a 2-structure g with the maximal prime clans PI,. . . , Pm, the clan de- 
composition g/Pmax(g)(subg(Pl), . . . , sub,(Pm)) of g consists of the maximal 
prime factors sub,(Pi) together with the special quotient g/Pmax(g). 
Example 6.9 
Consider the 2-structure g of Figure 6.14 with five vertices and five edge classes, 
a, a-', b, b-', c. In Figure 6.14 we have also extracted the maximal prime fac- 
0 
tors, and the linear quotient g/Pmax(g). 
6.3.6 
By the clan decomposition theorem, each 2-structure g can be decomposed 
into its maximal prime factors so that the resulting quotient is special. Also, 
the maximal prime factors can be decomposed, if they are not special already. 
This allows us to decompose g completely into its prime factors, not only into 
its maximal prime factors. Indeed, by Theorem 6.3.2, we have the following 
immediate result. 
The shape of a 2-structure 
Lemma 6.3.13 
(1) Let P be a nonsingleton prime clan of g. The maximal prime clans of the 
factor sub,(P) are exactly the prime clans of g that are properly contained in 
P, and are maximal in this respect. 

422 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
Figure 6.14: A clan decomposition 
(2) Every proper prime clan X of g is a maximal prime clan of some prime 
factor subg(P). 
D 
The partially ordered set T(g) = (P(g), c) of the prime clans forms a rooted 
tree, where the domain dom(g) is the root and the singletons are the leaves. 
We call the tree T(g) the prime tree of g. 
The shape of a 2-structure g is defined as a pair 
shape(9) = (T(g), *,I, 
where T(g) is the prime tree of g and 
Qg (P) = sub, (P)/pmax(subg (P)) 
is a function, which associates the special quotient sub,(P)/Pm,,(subg(P)) 
with each prime clan P E P(g). 
The shape of a 2-structure g can conveniently be represented as a tree-like 
object by contracting each prime factor sub,(P) to the corresponding quo- 
tient Q,(P), 
and then drawing a line down from a node Q of Qg(P) 
to the 
corresponding quotient Qg (Q) of Q. 

6.3. DECOMPOSITION OF BSTRUCTURES 
423 
Example 6.10 
The shape of the 2-structure g from Figure 6.16 is given in Figure 6.15. We have 
not identified the inner nodes (circles) of the quotients (rectangles). Indeed, 
each node Q E Qg(P) 
is the prime clan consisting of the singletons zi that 
are descendants of this node. Also, we have omitted the colours from this 
figure, since (in this example) each quotient Qg(P) 
has only one pair of edges, 
and hence it has either one symmetric edge class or two edge classes that are 
reverses of each other. 
0 
Figure 6.15: The shape of g 
The observation of Example 6.8 is valid also for the shapes. We may lose some 
information on the 2-structure g while forming the shape of g, ie., two different 
2-structures may have the same shape. 
We can also draw the shape of a 2-structure g by nesting the special quotients 
QE,(P): 
In this representation a quotient (rectangle) Qg(Q) is drawn inside of 
quotient Qg(P) 
replacing the node Q of Qg(P). 
Example 6.11 
In Figure 6.17 there is a nested representation of the shape of the 2-structure 
g from Figure 6.16. The result is again rather economical compared to the full 
drawing of g, 
0 

424 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
C 
2 3  
A 
a 
XR 
Figure 6.16: A 2-structure g 
6.3.7 Constructions of clans and prime clans 
The algorithmic complexity of forming the shape of a 2-structure was shown 
to be of order O(n2) in Ehrenfeucht, Gabow, McConnell and Sullivan [8]. Here 
n refers to the number of nodes in the 2-structures. 
The algorithm given in [8] is not incremental. In an incremental algo- 
rithm the shape of a 2-structure g with a domain (XI, 52,. . . , x,} 
is con- 
structed starting from the shape of a single node substructure sub,({zl}) 
and then for each a = 1,2,. . . , n  - 1 constructing the shape of the sub- 
structure subg({xl, 2 2 , .  . . , xi+l}) by updating the shape of the substructure 
An incremental algorithm of complexity O(n2) for the construction of the 
shape of a 2-structure is given in McConnell [34]. When restricted to undi- 
SUbg({Xl,22,...,22}). 

6.3. DECOMPOSITION OF 2-STRUCTURES 
425 
C 
Figure 6.17: The nested representation of the shape of g 
rected graphs this algorithm gives another method of constructing the modular 
decomposition of graphs in time O(n2), see also Muller and Spinrad [37]. 
We shall now give some constructive characterizations of clans and prime clans. 
These results were used in Engelfriet, Harju, Proskurowski and Rozenberg [23] 
in algorithmic constructions of shapes. 
Let g = (D, R) be a 2-structure, and let X E D. We shall denote by C ( X )  the 
smallest clan of g that contains the subset X .  Such a clan exists since C(g) is 
closed under intersection. 
For each x E D, define a relation R, on D as follows, 
In words, if uR,v, then v ‘sees’ u and x differently. A subset X 5 D is said to 
be closed under R,, if u E X and uR,v imply v E X .  Further, let R: be the 
reflexive and transitive closure of the relation R,. 
Lemma 6.3.14 
The following statements are equivalent for each nonempty subset X 5 dom(g): 
(1) X is a clan of g, 
(2) X is closed under R, for all x E X, 
(3) X is closed under R, for some x E X 

426 
CHAPTER 6. BSTRUCTURES - A FRAMEWORK FOR ... 
Pro0 f 
If X E C(g), then clearly X is closed under R, for all x E X .  Hence it suffices 
to show that (3) implies (1). 
Assume that (3) holds, and let z E X be a node such that X is closed under 
R,. Suppose to the contrary of the claim that X is not a clan. Hence there are 
nodes u $! X and y, z E X such that (u, 
y)R # (u, 
z)R. It follows that either 
(u,y)R # (u,z)R or (u,z)R # (u,x)R. Hence yR,u or zR,u, which implies 
that u E X ;  a contradiction. 
0 
The following characterization of C ( X )  was proved in [23]. 
Theorem 6.3.15 
For each subset X C dom(g) and node x 6 X ,  
C ( X )  = {u I yR:u for some y E X } .  
Proof 
Denote W ( X )  = (u1yRju for some y E X } .  First of all, X C W ( X ) ,  because 
Rj is reflexive. Moreover, by definition, W ( X )  is the smallest set containing 
0 
X and closed under R,, and hence, W ( X )  = C ( X )  by Lemma 6.3.14. 
Let x,y E dom(g). We write simply C(z,y) instead of C({x,y}). Not every 
clan is of the form C(x, y), but as the next lemma shows a clan is a prime clan 
just in case it does not overlap with a clan of this form. 
Lemma 6.3.16 
Let X E C(g) for a 2-structure g. Then X E P(g) if and only if X does not 
overlap with any C(x, y), where x E X and y $! X .  
Proof 
In the one direction the claim follows by the definition of a prime clan. On 
the other hand, if a clan X is not a prime clan, then it overlaps with a clan 
Y E C(g). Let x E X n Y  and y E Y \ X .  Now, C(x,y) g Y ,  and hence C(x,y) 
0 
is a clan that overlaps with X .  This proves the claim. 
Denote by P ( X )  the smallest prime clan containing X C dom(g). Such a prime 
clan exists since the prime clans do not overlap, and dom(g) E P(g). Define 
for each x E dom(g), 
S, = {(u,v) I uR,v or u $! C(x,v) or x $! C(u,v)}. 

6.3. DECOMPOSITION OF 2-STRUCTURES 
427 
Notice that the requirement u $! C(x,v) or x $! C(u,w) is equivalent with 
C(x,w) # C(u,v). Also, denote by Sz the reflexive and transitive closure of 
S,. Again, we write P(x, y) instead of P({x,y}). 
In [23] the sets P(X) 
were characterized as follows. 
Theorem 6.3.17 
For each subset X C dom(g) and node 3: E X, 
P ( X )  = {u I yS,*u for some y E X } .  
Proof 
Let W(X) = {u I ySju for some y E X } .  Clearly, X G W ( X ) .  Moreover, by 
Lemma 6.3.14, W ( X )  is a clan, since it is closed under the relation R,. 
We prove that W ( X )  is a prime clan. For this let u $! W ( X ) .  Hence, for all 
w E W ( X ) ,  wS,u does not hold. By definition of S, we have that w E C(x,u) 
and x E C(v,u). Hence C(x,u) = C(w,u) for all w E W ( X ) .  Consequently, 
W(X) C: C(w,u) for all u $! W ( X )  and w E W ( X ) ,  which proves that W(X) 
is a prime clan by Lemma 6.3.16. Thus P ( X )  C W ( X ) .  
Suppose then that u $! P ( X ) ,  and let w E P ( X ) .  Clearly, wS,u does not 
hold since P ( X )  is a prime clan, and hence u $! W ( X ) ,  which proves that 
The following theorem (from [23]) shows that every prime clan is of the form 
W ( X )  c P ( X ) .  
0 
P(X,Y). 
Theorem 6.3.18 
Let g be a 2-structure. For each prime clan P E P(g) there exist x, y E P such 
that P = P(x, y). 
Pro0 f 
If P = {x} is a singleton prime clan, then clearly P = P(x,x). Suppose then 
that IPI 2 2, and let PI and P2 be two maximal prime clans of sub,(P) with 
0 
PI # P2. Let x E PI and y E P2. Now, P = P(x, y) as required. 
6.3.8 Clans and sibas 
We shall now describe how the clan decomposition theorem can be applied to 
systems which possess clan-like structures in the sense defined below. 
Let S be a family of subsets of a finite set D. We say that S is a siba on D (or 
a semi-independent partial boolean algebra, see [15]), if it satisfies the following 
conditions: 

428 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
(1) 0 E S, D E S and {x} E S for all x E D; 
(2) if X, Y E S ,  then X n Y E S; 
(3) if X ,  Y E S and X n Y # 0, then X U Y E S; 
(4) if X ,  Y E S and Y \ X # 0, then X \ Y E S. 
The sets in (1) are called the trivial elements of S. 
Let S be a siba on D. We say that an element X E S is a prime element, if X 
does not overlap with any element of S ,  and that X E S is a maximal (prime) 
element, if it is maximal among the proper (prime) elements of S with respect 
to inclusion. 
Clearly, the maximal prime elements of S form a partition of the set D. Further, 
as in Lemma 6.3.7, we obtain 
Lemma 6.3.19 
Let S be a siba on D. For each Y E S either Y 
P for a maximal prime 
0 
element P of S or Y is a union of maximal prime elements. 
A siba S is said to be trivial, if its elements are trivial, and S is special, if its 
prime elements are trivial. Further, S is complete, if it is the power set 2O, and 
linear, if there exists a linear order {XI, xz,. . . ,xn} of D such that S consists 
of the emptyset and the segments {xi,. . . , xj} for 1 5 i i: j i: n. 
We notice that the proof of Lemma 6.3.10 applies as such to sibas, and the 
proof of Theorem 6.3.11 can be rather easily modified to prove the following 
result, see also Mohring [35] and Deutz [7]. 
Lemma 6.3.20 
A siba is special if and only if it is either linear, or complete, or trivial. 
Let S be a siba on D. 
We denote 
SIX = { X n Y  I Y ES} 
for each X E S. It is easy to show that SIX is a siba on X .  
If X = { X I ,  X z ,  . . . , X,} is a partition of D into elements X i  E S ,  then we 
define the quotient S I X  as the family of subsets of X such that y E S I X  if 
and only if UY E S. It is again easy to show that the quotient S I X  is a siba 
on X. 
By Lemma 6.2.3, C(g) is a siba for each 2-structure 9. The following theorem 
shows that also the converse is true. 

6.3. DECOMPOSITION OF 2-STRUCTURES 
429 
Theorem 6.3.21 
A family S of subsets of a finite set D is a siba if and only if there is a 2- 
structure g such that S = C(g). 
Proof 
Let S be a siba on D. We show by induction on the cardinality of D that there 
exists a 2-structure g with C(g) = S. If ID1 5 2, then the claim is obvious. 
Suppose thus that ID1 2 3. 
Clearly, if S is special, then the claim holds by Lemma 6.3.20, since there exist 
linear, complete and primitive 2-structures on the domain D. 
Assume now that S is not special, and let P be the partition of D into the max- 
imal prime elements of S. Denote Q = S / P ,  for short. By induction hypothesis 
there are 2-structures gp = (P, Rp) for each P E P such that C(gp) = SIP, 
and a 2-structure h = (P, Rh) on the domain P such that C(h) = Q. We define 
a 2-structure g = (D, R) on the domain D such that 
It is now straightforward to show that P = PmaX(g)] from which one can 
cl 
As shown by Mohring and Radermacher [36] the congruence classes of various 
systems such as set systems, relations and boolean functions form sibas. 
Example 6.12 
We consider here set systems as in Mohring and Radermacher [36]. A (normal) 
set system on a finite domain D is simply a family of subsets C of D such 
that U C  = D. Because of its generality, set systems are applicable in various 
contexts, see e.g. Shapley [39] for game theoretic applications. 
Let S be a set system on A, and let S, be a set system on A, for each z E A, 
where the domains A, are nonempty and disjoint. The substitution composition 
of {S,}sE~ 
for S is defined as the set system S[S,;z E A] consisting of the 
~(y), 
where Y runs through the sets in S and 7- the functions such 
t"?:t 
Y!;~E 
S, for each y E A. The domain of S[S,; z E A] is U,GAA,. 
For a set system ,C on D a subset X 
D is called an autonomous set, if it 
is empty or, in the above notations] C = S[S,;z 
E A] and X = A, for some 
z E A. A partition of D into nonempty autonomous sets is called a congruence 
partition of C. 
deduce that C(g) = S. 

430 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
It is now a straightforward task to verify that the autonomous sets of a set 
system C form a siba. Therefore each set system C can be represented as a 
2-structure such that the autonomous sets of C are exactly the clans of g. 
This representation g of C is easily seen to be faithful in the sense that the 
congruence partitions of C are exactly the clan partitions of g, and hence, in 
a sense, the ‘rough’ algebraic structure of C is faithfully represented by the 
2-structure g. 
The autonomous sets of a set system C have further closure properties that 
are not necessarily true for arbitrary 2-structures. In fact, see [36], X is an 
autonomous set of C if and only if for all S1, 
S, 6 C with Si n X # 0, also 
0 
(S1 \ X )  u (S, n X )  E C. 
6.4 Primitive 2-Structures 
6.4.1 Hereditary properties 
Of the three special 2-structures linear and complete are determined by (an 
ordering of) their domains, and therefore they need no further inspection. The 
only interesting special 2-structures are thus the primitive ones. Indeed, there 
are arbitrarily complex primitive 2-structures. 
By definition, all 2-structures with two nodes are primitive, but these are also 
either complete or linear. We shall thus consider those primitive 2-structures 
that are truly primitive. 
0 
0 
I
I
 
0-0 
/
O
\
 
0 4  
0 
Figure 6.18: A path of length three, and a cycle of length three 
In Figure 6.18 there are two simple truly primitive 2-structures. The first of 
these is a path of length three and the second is a cyclic triangle. 
We shall state now without proofs some interesting properties of the primitive 
2-structures. The first of these is from Ehrenfeucht and Rozenberg [17]. 
Theorem 6.4.1 (Downward hereditarity) 
Let g = (D, R) be a truly primitive 2-structure. There are nodes x and y 
0 
(possibly 2 = y) such that sub,(D \ (2,y)) is primitive. 

6.4. PRIMITIVE 2-STRUCTURES 
431 
As an example, from the path of length three (in Figure 6.18) one cannot 
remove a node without violating primitivity. Hence in this case two nodes have 
to be removed in order to obtain a primitive substructure. 
The proof of Theorem 6.4.1 is based on the following lemma, which gives 
a simple condition ensuring that a primitive 2-structure g = (D,R) has no 
primitive substructures of the form sub,(D \ {z}) with x E D. We call such a 
2-structure critically primitive. 
Lemma 6.4.2 
Let g = ( D , R )  be a truly primitive 2-structure, and suppose sub,(X) is a 
truly primitive substructure such that sub,(X U {x}) is non-primitive for all 
z E D \ X. Then for each x E D \ X the substructure sub,(X U {x}) has a 
unique nontrivial clan 2, such that either IZ,I = 2 with x E 2, or 2, = X .  0 
The critically primitive 2-structures were characterized in Schmerl and Trotter 
[40] and Bonizzoni [2]. In particular, the following result was proved in [40]. 
Theorem 6.4.3 
Let g = ( D , R )  be a critically primitive 2-structure with ID1 = n. If the sub- 
structure h = sub,(X) is primitive with 1x1 = m > 3, then n = m (mod 2). 
0 
This means that if a critically primitive g has an even (odd) number of 
nodes, then all its substructures with an odd (even) number of nodes are non- 
primitive. Moreover, 
Corollary 6.4.4 
Let g be a critically primitive 2-structure, and sub,(X) aprimitive substructure 
0 
of g with 1x1 2 4. Then sub,(X) is critically primitive. 
Example 6.13 
In Figure 6.19 we have a critically primitive 2-structure g. Notice that g has 
only two edge classes, a class together with its reverse class. In graph theoretical 
0 
terms, g is a tournament. 
Lemma 6.4.2 can be also used to prove the following hereditary result, see Harju 
and Rozenberg [30] or Schmerl and Trotter [40]. (Again, in [30] the result is 
proved for infinite 2-structures, for which Theorem 6.4.1 does not hold). 

432 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
Figure 6.19: Critically primitive 2-structure g 
Theorem 6.4.5 (Upward hereditarity) 
Let g = (D, R) be primitive, and let h = sub,(X) be a proper truly primitive 
substructure of g. Then there are nodes x,y E D \ X (possibly x = y) such 
0 
that sub,(X u {x, y}) is primitive. 
Consider, for a while, a 2-structure g as a directed graph g = (D, E, R) with 
an equivalence relation R on the edge set E 5 E2(D) as mentioned in the 
beginning of Section 6.2. 
For an edge e E E of g we let g - e = (D, E \ {el e-'}, Re), where Re is R 
restricted to E \ {e,e-'}. (This means that e is classified as 'nonedge' by the 
equivalence relation Re). 
Theorem 6.4.1 gives a hereditary property of primitivity concerning removals 
of nodes from a primitive 2-structure. We ask now whether one can remove an 
edge e from a primitive 2-structure g so that the result g - e is still primitive. 
We call a primitive g = (DIE, R) unstable (after Sumner [42]), if g - e is 
non-primitive for all edges e E E .  Figure 6.20 gives two examples of unstable 
2-structures. 
For unstable 2-structures we have the following result from Harju and Rozen- 
berg [29]. A leaf of a 2-structure g = (D, El R) is a node of degree one. 
Theorem 6.4.6 
Let g = (D, El R) be a primitive 2-structure. Either 
(1) g has an edge e such that g - e is primitive, or 
(2) g is unstable and it is either a path of length three or it has a leaf x such 
0 
that sub,(D \ {x)) is primitive. 

6.4. PRIMITIVE 2-STRUCTURES 
433 
I 
I 
0 
0 
0 
0 
\/ 
0 
0 
0 
Figure 6.20: Two unstable 2-structures 
6.4.2 Uniformly non-primitive 2-structures 
We shall now consider those 2-structures that do not contain primitive com- 
ponents. We call a 2-structure g uniformly non-primitive if g has no truly 
primitive substructures. 
A number of characterizations of the uniformly non-primitive 2-structures were 
proved by Engelfriet, Harju, Proskurowski and Rozenberg in [23]. In particu- 
lar, the graphs and directed graphs that are representable by uniformly non- 
primitive 2-structures were characterized by forbidden subgraphs in [23]. In 
the following we shall state only one general characterization result (Theo- 
rem 6.4.10) concerning uniformly non-primitive 2-structures. 
Theorem 6.4.7 
Let g be a uniformly primitive 2-structure. Then the substructures and the 
0 
quotients of g are uniformly non-primitive. 
By Theorem 6.4.1, if g is a primitive 2-structure with n nodes, then g has a 
primitive substructure on n - 1 or n - 2 nodes. In particular, 
Lemma 6.4.8 
Every truly primitive 2-structure g has a primitive substructure consisting of 
three or four nodes. 
0 
Recall that P ( X )  is the smallest prime clan of a 2-structure g = (D,R) that 
contains the subset X C D. The following result was proved by Ehrenfeucht 
and Rozenberg [16]. 

434 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
Theorem 6.4.9 
Let g = (D,R) be a 2-structure. If sub,(X) is a truly primitive substructure 
of g, then the quotient @,(P(X)) is primitive. 
We say that a 2-structure g has the %block property, if every substructure h 
of g with Idom(h)I 2 2 has a partition into two nonempty clans, Le., if every 
substructure h has a nonempty clan X E C(h) the complement dom(h) \ X of 
which is also a nonempty clan of h. Also, we say that g has the doubleton clan 
property, if every substructure h with at least two nodes has a clan of size 2. 
The following theorem was proved in [23]. 
Theorem 6.4.10 
The following statements are equivalent for a 2-structure g: 
(1) g is uniformly non-primitive, 
(2) g has no primitive substructures of size 3 and 4, 
(3) each node of shape(g) is linear or complete, 
(4) g has the 2-block property, 
(5) g has the doubleton clan property. 
0 
In fact, the proof in [23] reveals that g is uniformly non-primitive if and only 
if each substructure sub,(X) with 1x1 2 2 has a prime clan, the complement 
of which is a clan. 
Example 6.14 
Let g be the 2-structure from Figure 6.21. The shape of g is in Figure 6.22. By 
Theorem 6.4.10, g is uniformly non-primitive. 
6.5 Angular 2-structures and T-structures 
6.5.1 Angular 2-structures 
By Lemma 6.4.8 a truly primitive 2-structure contains a primitive substructure 
with 3 or 4 nodes. We call a g = ( D , R )  angular, if sub,(X) is non-primitive 
for every subset X with 1x1 = 3. 
Example 6.15 
Clearly, if a primitive g = ( D , R )  with ID] 2 4 has only two edge classes, 
a and b, both of which are symmetric, then each sub,(X) with 1x1 = 3 is 

6.5. ANGULAR 2-STRUCTURES AND T-STRUCTURES 
/\ 
x57k 
.\: 
c
c
/
 
Figure 6.21: A uniformly non-primitive 2-structure g 
435 
51 
2 2  
23 
Figure 6.22: The shape of g 

436 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
non-primitive. Therefore g is angular, and, by Theorem 6.4.1, g has a primi- 
tive substructure on four nodes. It is straightforward to verify that then this 
0 
primitive substructure is isomorphic to the path of length three. 
We define the feature of an edge class a of g as the set Fa = {a, a-I}. Note 
that a feature {a, u-'} is a singleton, if the edge class a is symmetric. 
We start with some immediate observations. 
Lemma 6.5.1 
Let g be an angular 2-structure. 
(1) If g has only one feature, then it is either linear or complete. 
(2) The substructures and the quotients of g are angular. 
CI 
By Theorem 6.5.3 below primitivity of angular 2-structures is preserved if 
the edge classes are made symmetric. For a 2-structure g = ( D ,  R) define its 
symmetric version as the 2-structure g" = ( D ,  R"), where 
elRSe2 e 
elRe2 or elRe;'. 
Clearly, gs has only symmetric edge classes, 
eR,. = eR, U e-'R, 
= e-'R,. 
. 
Example 6.16 
Consider the %structure g from the left part of Figure 6.23. Now, g is angular 
and primitive. The edge classes a and b of g are nonsymmetric, and the features 
{a, u-'} and {b, b-'} are disjoint. The symmetric version g" (the 2-structure 
from the right part of Figure 6.23) with two symmetric edge classes is also 
angular and primitive. 
0 
For an edge e of a 2-structure g = ( D ,  R), let ge = (0, 
eR,.) be the (undi- 
rected) graph, which is obtained from g by setting an edge {z,y} if and only 
if (z,y) belongs to the edge class eR,. of the symmetric version gs. 
We say that a 2-structure g is connected, if ge is connected for all e. Further, 
a subset X 
D is an a-connected component for an edge class a, if X is a 
connected component of the graph ge for some e E a. 
Lemma 6.5.2 
If g is an angular 2-structure7 then the a-connected components are clans of g. 
In particular, if g is primitive, then it is connected. 

6.5. ANGULAR 2-STRUCTURES AND T-STRUCTURES 
0 
c
o
 
0 
b
o
 
437 
0
4
 
0 
0 
0 
b 
b 
Figure 6.23: Primitive and angular g, and its symmetric version gs 
Proof 
Assume that X is an a-connected component of g for some a. If X = D or 
1x1 = 1, then the claim holds. Assume thus that X # D and 1x1 2 2. 
Let y 4 X and ~ 1 ~ x 2  
6 X. Since X is an a-connected component, there are 
nodes z1,. ..,Zk E X such that z1 = X I ,  Zk = 2 2 ,  and (zi,zi+l)R E Fa for 
all i = 1,2,. . . , k - 1. Moreover, (y,.zi)R 4 Fa for i = 1,2,. . . , k ,  since X is 
an a-connected component. By angularity, it follows that (y, zi)R = (y, z ~ + ~ ) R  
for i = 1,2,.. . , k  - 1, and thus also (y,zl)R = (y,xa)R. We conclude that 
x E C(9). 
The next theorem reduces the primitivity of angular 2-structures to their sym- 
metric versions. 
Theorem 6.5.3 
Let g = ( D ,  R) be angular. Then g is trulyprimitive if and onlyif the symmetric 
0 
version gs is truly primitive. 
Finally, we have the following result, for the proof of which we refer again to 
1191. 
Theorem 6.5.4 
Let g = ( D, R) be a truly primitive angular 2-structure. Then g has exactly 
two features. 
0 
Theorem 6.5.4 generalizes to all angular 2-structures in the following sense, see 
Harju and Rozenberg [30]. 
Theorem 6.5.5 
If an angular g is connected, then it has at most two features. 

438 
CHAPTER 6.2-STRUCTURES 
- A FRAMEWORK FOR ... 
Pro0 f 
Let g = (D,R) be angular with k features with k 2 2. If it is primitive, then 
the claim holds by Theorem 6.5.4. Otherwise, consider the special quotient 
g/Pmax(g). By Lemma 6.5.1(2) g/Pmax(g) is also angular. Since g is connected, 
by the formation of a quotient also g/Pma,(g) is connected and therefore it has 
the same number of features as g. Now, since k 2 2, g/Pmax(g) cannot be linear 
or complete, and hence it is primitive. Consequently, by Theorem 6.5.4, we have 
that k = 2. 
0 
Theorem 6.5.3 and Theorem 6.5.4 reduce essentially the study of primitive 
angular 2-structures to that of graphs. One can then use various methods 
of graph theory to decompose primitive angular 2-structures into smaller 2- 
structures. We mention here only the split decomposition of Cunningham and 
Edmonds [6] and the decomposition of graphs into P4-components of Jamison 
and Olariu [32]. 
6.5.2 T-structures and texts 
We say that a 2-structure g is a partial order, if it has two features one of which 
is symmetric and the other is nonsymmetric and such that its edge classes 
partially order the domain of g. It was shown in [19] that a truly primitive 
angular 2-structure g is either a graph ( i e , ,  g has two symmetric edge classes), 
or a partial order, or a T-structure. Here a 2-structure g is a T-structure, if g 
is angular and it has only nonsymmetric edge classes. 
The following lemma is obvious. 
Lemma 6.5.6 
Let g be a T-structure. Then the substructures and quotients of g are T- 
structures. Further, the special quotient g/Pmax(g) is either linear or truly 
primitive. 
0 
Assume that g is a truly primitive T-structure. By Lemma 6.4.8 and the fact 
that g is angular, g has a primitive substructure h = sub,(X) with 1x1 = 
4. Moreover, by Theorem 6.5.4, g (and h) has exactly two (nonsymmetric) 
features. One can show that the 2-structure N from Figure 6.24 is the only 
primitive T-structure with four nodes (up to isomorphism). 
Lemma 6.5.7 
If g is a truly primitive T-structure, then g contains a substructure N .  
0 

6.5. ANGULAR 2-STRUCTURES AND T-STRUCTURES 
c 
c o  
439 
Figure 6.24: The primitive T-structure N 
Consider then a 2-structure g without symmetric edge classes. A subset u of 
edge classes is a selection, if for all features F ,  Iu n 8’1 = 1. For a selection a 
we denote by a(g) the directed graph (dom(g), Uu). 
The next result was proved in Ehrenfeucht and Rozenberg [20]. 
Lemma 6.5.8 
Let g be a 2-structure having only nonsymmetric edge classes. Then g is a 
T-structure if and only if u(g) is a linear order of dom(g) for all selections u. 
0 
In general a T-structure may have arbitrarily many features, but by Theo- 
rem 6.5.4 a truly primitive T-structure has exactly two features. Therefore 
the nodes (the special quotients qg(P) 
for prime clans P )  in the shape of a 
T-structure g have at most two features. This fact was generalized in [20] to 
Theorem 6.5.9 
For each T-structure g there exists a T-structure g’ with at most two features 
0 
such that shape(g) = shape(g’). 
Remark: 
Notice that in [20] Theorem 6.5.9 is stated using ‘similarity’ instead of equality 
of shapes. However, one can easily check that for (unlabeled) 2-structures the 
two statements are equivalent. Therefore, we shall now consider T-structures 
with at most two features. For a partial order p we let p-’ 
denote the dual 
0 
0 
For the proof of the following result see [20]. 
partial order of p, ie., p-l = { (z, y) I (y, z) E p}. 
Theorem 6.5.10 
Let g be a 2-structure with at most two features. Then g is a T-structure if 

440 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR _.. 
and only if there exist two linear orders pl and p2 such that the edge classes 
of g are included in the set {PI n p2, p1 n p;', 
prl n p2 and p;' n p;'}. 
0 
In Theorem 6.5.10 some of the intersections may be empty. 
Notice that in the above each of the intersections of the linear orders p1 and 
p2 is a partial order of the domain, and moreover (PI n p 2 ) - l  = p;' 
np;' and 
From Theorem 6.5.10 it follows that each T-structure with at most two features 
is determined by two linear orders of its domain. 
Texts were defined in [20] as triples (A, p1, p ~ ) ,  
where X : D -+ A is a function 
from the domain D into an alphabet A, and p1, p2 are two linear orders of 
D. Hence a text T consists of a T-structure g(T) (specified by Theorem 6.5.10) 
together with a labeling function A. 
A text T = (X,pl,p2) with A: D -+ A can be considered as a 'structured 
word' over A. Indeed, let D = ( ~ 1 ~ x 2 , .  
. . ,x,} and p1 = (xil, xi,,. . . , xin), 
p2 = (xj, , xj, , . . . , xjn). The first linear order gives an ordinary word over the 
alphabet A, 
(pl n P;Y= 
P ; ~  n 
P2. 
= (wxi,), X ( Z i , ) , .  . . >X(Zin>), 
and the linear orders p1 and p2 together assign to the word X(p1) its structure 
as specified by the shape of the corresponding T-structure g(7). 
Example 6.17 
Let D = {1,2,3,4,5}, 
and A = {x,y,z}. Define a text T = (X,p1,p2) as 
follows: 
The word defined by T is X(p1) = (2, y, z ,  x, y), and its structure is given by 
p2. The T-structure g ( T )  has the features {a,a-'} and {b,b-'}, where 
and hence g ( 7 )  is as given in Figure 6.25. 
The maximal prime clans of g(7) are {2,3} and { 1,4,5}, and the shape of g ( 7 )  
0 
is given in Figure 6.26. 

6.5. ANGULAR 2-STRUCTURES AND T-STRUCTURES 
a 
1 
Figure 6.25: The T-structure g ( ~ )  
2 
3 
5
1
4
 
44 1 
Figure 6.26: The shape of g ( ~ )  

442 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
The texts can be classified with respect to the properties of the shapes of the 
corresponding T-structures. We say that a text T is alternating, if shape(g(7)) 
has only linear nodes, i.e., the special quotients !Pg(r)(P) 
are linear 2-structures 
for all prime clans P. 
If a text T = (A,pl,pz) is not alternating, then the shape of g(7) contains a 
primitive quotient, and therefore, by Lemma 6.5.7, g ( r )  contains a substructure 
N .  This means that the linear order p 1  of the text T contains a suborder 
(il,iz,is,i4) such that either (&,i4,il,i3) or (23,il,i4,22) is a suborder of p2. 
Next we define two operations Vrev and @ for texts. For a text T = (A,pl,pz) 
let 
For texts T = (A, p 1 ,  p 2 )  and T’ = (A’, p:, p!J with disjoint domains let 
Vrev(.r) = (A, p
~
l
 
, ~ 2 ) .  
T @ T ’ = ( A U A ‘ , p i  + p i 7 P 2 + p L ) ,  
where p i  + p!, = p1 U pi U {(x,y) I z E dom(r), y E dom(r’)}. 
For the proof of the following theorem we refer to [20]. 
Theorem 6.5.11 
The family of alternating texts is the smallest class of texts containing the 
0 
singleton texts and closed under the operations Vrev and @. 
For further combinatorial properties and applications of texts we refer to [20], 
[14] and [13]. 
6.6 Labeled 2-Structures 
6.6.1 
As noted in Sections 6.2 and 6.3 the decompositions of 2-structures are not 
unique in the sense that two different 2-structures may possess the same de- 
composition. In labeled 2-structures this ambiguity does not occur. 
A labeled 2-structure is obtained from a 2-structure g by setting a different 
label to each edge class of g. 
Equivalently, we define a labeled %structure or an l2-structure, for short, as 
a triple g = ( D , a , 4 ) ,  where D is the domain, 4 is the set of labels and 
a :  E2(D) -+ 4 is the labeling function on the edges. Again, we assume that 
our C2-structures are reversible, i.e., there is a permutation S: A -+ A of order 
two on the labels that satisfies the condition 
Definition of a labeled 2-structure 
a(.-’) = 6(a(e)) 
for all e E E2(D). 

6.6. LABELED 2-STRUCTURES 
443 
That the permutation 6 is of order two means that d2(a) = a for all labels 
a E A. Again we may have a = 6(a) for a label a E A, in which case a is called 
symmetric. 
In later sections the set A of labels will be a group in the algebraic sense, and 
the reversibility function 6: A -i A will be a group involution. For this reason 
we do not write a-l for the label of the reverse edge. 
We observe that an 12-structure g = (D, Q, A) is completely determined by 
its labeling function a, and therefore we shall identify g with a, i.e., we shall 
consider C2-structures as functions 
9 :  E2(D) + A. 
Notice, however, that the domain of the 2-structure g is D ,  not Ez(D). 
For each 12-structure 9 :  E2(D) -+ A there is the underlying unlabeled 2- 
structure g' = (0, 
R), where R is defined by 
For this reason the results of the previous sections can be easily modified for 
labeled 2-structures. 
The converse of this does not hold, since the same 2-structure corresponds to 
several C2-structures with different labeling functions. 
Let 91: Ez(D1) + A, and 92 : Ez(D2) + A2 be two labeled 2-structures. We 
say that g1 and g2 are isomorphic , if there are bijections 'p: D1 + D2 and 
$: A1 + A2 such that for all (z, y )  E E2(D2), 
Also, g1 and g2 are strictly isomorphic, if the bijection cp is the identity func- 
tion on D1 (and so D1 = D2). Hence two C2-structures g :  Ez(0) + A1 and 
h: E2(D) + A2 are strictly isomorphic, if there is a bijection $: A1 -i 
A2 
such that h(e) = $(g(e)) for all edges e E Ez(D). 
The next result gives a connection between the unlabeled and the labeled 2- 
structures. 
Theorem 6.6.1 
Two 12-structures g and h are strictly isomorphic if and only if they have the 
same underlying (unlabeled) 2-structure. 
0 

444 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
6.6.2 
Substructures, clans and quotients 
Let g: E2(D) -+ A be an e2-structure. We shall now modify the basic results 
and definitions of the previous sections, and state them for labeled 2-structures. 
The substructure sub,(X) induced by a subset X G D is defined as the restric- 
tion of g onto E2(X), i.e., sub,(X): &(X) -+ A satisfies sub,(X)(e) = g(e) 
for all e E E2(X). Clearly, a substructure sub,(X) has the same reversibility 
function 6: A -+ A as g. 
A subset X 5 D is a clan of g: &(D) -+ A, if for all z, y E X and all z 4 X, 
g(z, z) = g(z, y) (and hence g(z, 2 )  = g(y, z )  by the reversibility condition). 
Again, let C(g) denote the family of clans of g. Now, the basic results of Sec- 
tions 6.2 and 6.3 hold for C(g). 
Lemma 6.6.2 
Let 9: &(D) -+ A and let 9' = ( D , R )  be the underlying 2-structure. Then 
(1) for each X 2 D ,  sub,t(X) is the underlying 2-structure of sub,(X), and 
(2) C(g) = C(9'). 
0 
A partition X G C(g) of the domain D of g into clans is called a factorization 
of g. The quotient of g by X is the e2-structure g/X on the domain X such 
that for all X , Y  E X (with X # Y ) ,  (g/X)(X,Y) = g(z,y), whenever z E X 
and y E Y .  We need a modified result to ensure that the quotient g/X is 
well-defined for all 9. 
Lemma 6.6.3 
Let 6 be the reversibility function of A. Let X, Y E C(g) be two disjoint clans of 
an e2-structureg: E2(D) -+ A. There exists a label a E A such that g(z, y) = a 
0 
and g(y,z) = 6(a) for all z E X and y E Y .  
We observe that, by Lemma 6.6.3, every quotient g/X is isomorphic with a 
substructure of g, uiz. with sub,(X), where X is a set of representatives of X 
( i e . ,  X n Y is a singleton for every Y E X); this is a rather unusual situation 
from the general algebraic point of view. In this isomorphism the bijection 
4 :  A -+ A is just the identity. 
A decomposition h(g1,. . . , gm) of an CZstructure g consists of the factors gi = 
sub,(Xi) and the quotient h = g/X by a factorization X = {XI,. . . , Xm}. In 
contrast to the unlabeled 2-structures, see Example 6.8 the decompositions of 
a labeled 2-structure g are unique to 9. 

6.6. LABELED 2-STRUCTURES 
445 
Theorem 6.6.4 
Two e2-structures g1 and 9 2  have a common decomposition if and only if 
91 = g2. 
0 
The prime clans and the maximal prime clans of an C2-structure g are defined 
as in Section 6.3. Again, the family of prime clans is denotes by P ( g )  and the 
family of the maximal prime clans is denoted by Pmax(g). 
The following result modifies some of the results from Sections 6.2 and 6.3 for 
C2-structures. It shows that the (prime) clans of an C2-structure g are inherited 
by the substructures and by the quotients. 
Lemma 6.6.5 
Let g be an C2-structure. 
(1) For each X E C ( g ) ,  C(sub,(X)) = { Y  I Y E C ( g ) , Y  C X } .  
(2) For each X E P ( g ) ,  P(subg(X)) = {Y I Y E P ( g ) , Y  C_ X } .  
(3) If X 
P ( g )  is a prime factorization, then Q E C ( g / X )  if and only if 
UQ E C(g). 
0 
The clan decomposition theorem for 2-structures, Theorem 6.3.12, is restated 
in the labeled case as follows. 
Theorem 6.6.6 
For any e2-structure g ,  the quotient g/Pmax(g) is either linear, or complete, or 
truly primitive. 
0 
We say that an C2-structure g is a-linear, for a label a E A, if the relation 
x <,, y linearly orders the domain of g ,  where x <a y if and only if g ( x ,  y) = a. 
Also, g is a-complete, if g(e) = a for all e E &(D). 
As is the case for unlabeled 2-structures, the partially ordered set T ( g )  = 
( P ( g ) ,  C) of prime clans forms a directed and rooted tree, the prime tree of g. 
The root of T ( g )  is the domain dom(g), the leaves are the singleton sets, and 
there is an edge (X, Y )  in T(g), if X is the minimal element of P(g) such that 
Y 5 X and X # Y .  
Example 6.18 
Consider the C2-structure g from Figure 6.27 with nonsymmetric labels. In the 
figure we have omitted the edges having reverse labels d(a), S(b) and S(c). 
Here the nontrivial clans of g are X1 = {x1,x4,x5} and Xz = {xq,x5}; 
both clans are also prime clans of g ,  and X1 is a maximal prime clan. We 

446 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
Figure 6.27: An l2-structure g 
have Pmax(g) = {XI, { z ~ } ,  
{z3}}, and hence the quotient g/Pmax(g) has three 
nodes, and it is primitive. 
In Figure 6.28 of the prime tree T(g) of g we have not identified the inner 
nodes (the prime clans), since each inner node consists of the leaves zi that 
are descendants of this node. 
The substructure hl = sub,(X1) has two maximal primes, X2 and {XI}, and 
the quotient hl/Pmax(hl) is linear. The substructure h2 = subg(X2) has m u -  
imal primes {zq} and ( 5 5 )  and the quotient ha/Pmax(h2) 
is isomorphic to the 
linear C2-structure h2. 
Notice that the partition X = {{XI}, 
{Q}, { 5 3 } , X 2 }  is also a clan partition 
of g into prime clans. The quotient g/X has four nodes, and since X I  E C(g), 
also { { q } , X 2 }  is a clan of g / X .  Therefore this quotient is not special. 
0 
The shape of an C2-structure g :  Ez(D) + A is obtained in the same way as for 
unlabeled 2-structures. Hence the shape of 9, shape(g) = (T(g), qg), 
consists 
of the prime tree of g together with the function 
*,(PI = sub, (P>/Pmax(sub,(P)) 
that maps each prime clan P E P(g) to its special quotient. 
Example 6.19 
The shape of the C2-structure g from Example 6.18, see Figure 6.27, can be 

6.7. DYNAMIC LABELED 2-STRUCTURES 
447 
0 
/I\ 
Figure 6.28: The prime tree of g. 
drawn as in Figure 6.29. Here the labels of the edges in the special quo- 
tients Q g ( P )  have to be included, because now these quotients are labeled 
2-structures. 
6.7 Dynamic Labeled 2-Structures 
6.7.1 
Motivation 
Usually in a valuation of objects of a mathematical structure the values come 
from a set that is structured itself. Frequently such a set is an algebraic struc- 
ture, where the elements are bound together by one or more operations. As 
an example, a finite automaton may be considered as a directed graph, where 
the edges have values from a free monoid. Also, in graph theory the values of 
objects (the labels of edges or nodes) are often taken from an algebraic struc- 
ture, e.g., in many optimality problems such as the shortest path problem, the 
edges are labeled by elements of the field (R, 
+, .) of real numbers. 
In this and the following sections we shall study C2-structures that have a group 
structure on their sets of labels. The group structure of the labels gives then 
a method of locally transforming C2-structures into each other, and this leads 
to dynamic CZstructures. 
A group is a natural candidate for the set labels of a (reversible) C2-structure. 
The dynamic C2-structures were also motivated by Ehrenfeucht and Rozenberg 
[22] by evolution of networks and similar processes. Consider a network con- 
sisting of a set of processors D, where each x € D is connected by a channel 

448 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
Figure 6.29: The shape of 9. 
to each y E D for y # x. A channel ( z , ~ )  
may assume a certain value or state 
from the set A at a specific time, e.g., if there are only two values A = (0, l}, 
then the channels may be interpreted as having a sleeping and an active state; 
on the other hand, if A = R, 
then the channels can be considered as weighted 
by reals. 
The concurrent actions of the processors modify the states of the channels. 
The activity of each x E D will be described by two sets of actions, the output 
actions 0, and the input actions I,, by which x changes the states of the 
channels from and to z, respectively. The actions of z are thus mappings of A 
into A. 
Now, for each (x,y) there are two processors, x and y, that change the state 
of this channel concurrently (ie., independently of each other); x changes it 
by a mapping from 0, and y changes it by a mapping from Iy. In order to 
accommodate the concurrent behaviour of the processors, the mappings from 
0, and Iy should commute, ie., for all cp E 0, and 1c, E Iy, 
cp.11, = $p. 
To avoid unnecessary sequencing of actions the composition of two actions 
from 0, (I,, resp.) is again assumed to be an action, i.e., the sets 0, and I, 
form transformation semigroups on A under the operation of composition. 

6.7. DYNAMIC LABELED 2-STRUCTURES 
449 
Further, to assure a minimal freedom of the actions for each x we assume that 
for each a,b E A and x E D there exist a cp E 0, and a y E I, such that 
cp(a) = b and y(a) = b, i.e., the semigroups 0, and I, are transitive. 
The above assumptions simplify the situation considerably. Indeed, it was 
shown in [22] (see, also [9]) that if ID1 2 3, then there are two isomorphic 
groups 0 and I of permutations on A such that for each x E D, 0, = 0 and 
I, = I .  Thus the actions come from two groups 0 and I ,  which are indepen- 
dent of the processors. Moreover, we can define an operation on A such that 
A becomes a group isomorphic to 0 and I .  In fact, now the groups 0 and I 
become defined by left and (involutive) right multiplication of the group A. 
These observations lead to the definition of a dynamic C2-structure, given for- 
mally in Sections 6.7.2 and 6.7.3 in terms of selectors. A selector CT is a map- 
ping, which captures the action of each processor x € D at a specific stage of 
the network. By the above observations, a selector will be simply a function 
a : D - + A .  
A global state of a network is represented by an C2-structure, for which A is the 
set of labels. An evolution of the network is presented as a set of C2-structures 
that represent possible global states of the network. The transitions from one 
C2-structure g to another h (and therefore from one global state to another) 
are the transformations g * h induced by the selectors. 
6.7.2 Group labeled 2-structures 
We shall assume throughout the rest of the paper that the set A of labels forms 
a (possibly infinite) group. The identity element of A is usually denoted by la. 
A mapping 6: A -+ A is an involution of the group A, if it is a permutation of 
order two such that 6(ab) = G(b)b(a) for all a, b E A. An involution 6 satisfies 
S(a-') = 6(a)-l for all a E A, and in particular, S(la) = la. 
Example 6.20 
(1) For any group A the most obvious involution is the inverse function: 6(a) = 
a-l for each a E A. 
(2) If A is the group of nonsingular n x n-matrices (over a field F ) ,  then 
transposition, 6 ( M )  = M T ,  is an involution of A. 
(3) If A is a finite group of even order, then it has an element a of order 2, 
and, as easily seen, the mapping S(x) = ux-'a (z E A) is an involution. 
(4) If a :  A -+ A is an automorphism of order two, then 6 defined by 6(a) = 
a(.-') 
is an involution. 
0 

450 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
As before we will be dealing only with reversible CZstructures; now involutions 
will determine reversibility. Let 6 be an involution of the group A. We say that 
g :  Ez(D) + A is a 6-reversible C2-structure on A or a As2-structure, for short, 
if the involution 6 is its reversibility function: g(e-') = s(g(e)) for all edges 
e E Ez(D). 
We reserve the symbol D for a domain, the symbol A for a group and the 
symbol 6 for an involution of A. 
Example 6.21 
Let A = (Rf 
, .) be the multiplicative group of positive real numbers, and let 
6 be the inverse function of A. In Figure 6.30, we have an example of a A62- 
structure, where, as usual, the reverse edges are not shown. Thus, e.g., we have 
g(z2,zl) = s ( g ( x 1 7 2 2 ) )  = g ( x 1 , ~ 2 ) - '  = 1, g ( Z 2 , 2 3 )  = %, 
and g ( z 3 , Z Z )  = 5. 
0 
3 
2 - 
Figure 6.30: A A62-structure 
6.7.3 Dynamic labeled 2-structures 
The group A of labels of a A62-structure g becomes employed by the selectors, 
which, in essence, label the nodes x E D by the elements of the group A. 
Let g be a As2-structure for a group A and its involution 6. A function u :  D -+ 
A is called a selector. For a selector u :  D + A define the CZstructure g" by 
f ( z 1  Y )  = 4.) . g(z1 Y )  . 6 ( 4 Y ) )  
for all (z, y )  E Ez(D). The family [g] = {g" I ~7 a selector} is a (single aziom) 
dynamic As 2-structure (generated by 9). 
Hence a selector u :  D + A transforms each g into a g' 
by direct left and 
involutive right multiplication. The new value of an edge depends on the (values 
of the) nodes and on the label of the edge. 

6.7. DYNAMIC LABELED 2-STRUCTURES 
45 1 
Example 6.22 
Let g be as in Example 6.21, see Figure 6.30. Define a selector (T: D -+ R by 
.(xi) = 5 - i. Then, e.g., we have in the image g", g"(x1,xz) = 4 . 1  . 4 = f. 
The image g" is drawn in Figure 6.31, where we have labeled the nodes by the 
values of (T. 
0 
9 
4 - 
3 - 2  
Figure 6.31: The image g' 
In the pictorial representations of A62-structures, we shall usually omit the 
edges labeled by the identity element la of the group A. Recall that 6 ( l ~ )  
= 
la. This convention reflects a natural interpretation of la as the 'no edge' 
symbol. 
The dynamic A62-structures on the group Zz of labels are closely connected 
to Seidel switching, which was defined in connection with a problem of finding 
equilateral n-tuples of points in elliptic geometry (in this respect, see Van Lint 
and Seidel [33]). This problem has the following subproblem for undirected 
graphs. Determine the equivalence classes of undirected graphs with n nodes 
with respect to the following operation: Let G -+ GI, if there is a node x such 
that G' = (D, El) is obtained from G = (D, E )  by removing all edges (x, 
y) 
and (y, x) incident with x, and adding all pairs (2, y) and (y, x) not in E. Hence 
G -+ G', if for some node x, 
Let then - be the equivalence relation determined by +, ie., G - G' if and 
only if G = G' or there exists a finite sequence Go + GI -+ ... -+ Gk with 
{G, G'} = {Go, Gk}. One now asks how many equivalence of - classes are 
there for a set D of nodes? 
We can reformulate the above problem in terms of dynamic A'2-structures as 
follows. Let A = (Z, 
, +) be the cyclic group of order two. This group has only 

452 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
one involution 6, the inverse mapping, which in this simple case is the identity 
mapping of A: 6(0) = 0 and 6(1) = 1. We may consider a A62-structure 
g: E2(D) + A as an undirected graph, where g(e) = 1 ( g ( e )  = 0) means that 
e is (not, respectively) an edge of g. Consider a node z E D and a selector (T, 
for which ( ~ ( x )  
= 1 and u(y) = 0 for all other nodes y # z. Clearly, the image 
g" represents a graph, where the existing connections from x are removed and 
the nonexistent connections from z are created. Therefore G + G' holds if 
and only if for the corresponding As2-structures g and g', g' = g" for such a 
selector (T. From this we obtain that g - g' if and only if g' = g" for a selector 
For connections of Seidel switching to signed graphs and two-graphs we refer 
to Harary [28], Seidel and Taylor [41] and Zaslavsky [44], [45]. 
(T: D -+ Z 2 .  
Example 6.23 
Let A = (Z2,+), and let 6 be the identity mapping of A. Let D = 
{XI , x ~ , x ~ , x ~ }  
and consider a A62-structure g as in Figure 6.32, where a line 
denotes value 1. 
Figure 6.32: g with labels in IL2 
There are 21Dl = 16 different selectors (T: D + A, but some of them have the 
same image g'. In fact, there are only 8 different images g" as depicted in 
Figure 6.33, where again the nodes are labeled by the values of a selector u 
which applied to g yields g". 
As can be observed from this example, it can happen that g(e1) = g(e2), but, 
nevertheless, g"(e1) # g"(e2) for some edges e1,e2 E &(D). 
Notice also that 
0 
The notion of a substructure carries over to dynamic A62-structures as follows. 
g is primitive, but in [g] there are nonprimitive structures. 
Lemma 6.7.1 
Let [g] be a dynamic A62-structure, and let X C dom(g). Then 
[sub,(X)] = {sub,m(X) I (T selector}. 
0 

6.7. DYNAMIC LABELED ZSTRUCTURES 
1-0 
0 
0 
0 
0 
0- 
I/ 
0 
1- 
0 
1-0 
1 
1 
453 
0- 
1 
0 
0 
I
1
 
0 
0- 
Figure 6.33: The images g" 
We denote by subi,l(X) = [sub,(X)] for each dynamic A62-structure g and 
subset X C dom(g). 
The following lemma shows that the image g' 
under a selector (T of a A62- 
structure g is also &reversible. 
Lemma 6.7.2 
For a A62-structure g and a selector (T: D + A, the image g' 
is also a A62- 
structure. 
Proof 
Let (T be a selector and g a A'2-structure. For each edge e = (z,y) E E2(D) 
we have g(e-') = 6 ( g ( e ) ) ,  and hence 
g"(e-') 
Therefore go is also &reversible. 
= 4 Y )  . d e - 7  . 6(4z)) = 4 4 )  ' W e ) )  . 6(4z)) 
b2(4Y)) . &?(e)) . b(4z)) = 6(4z) . g ( e )  ' 6(4Y/))) = S(gU(e)>. 
= 
0 
The product of two selectors ol, ( ~ 2  
: D + A is defined by 
Clearly, ( ~ 2 ~ 1  
is a selector. 
Lemma 6.7.3 
For any selectors (TI, u2 : D -+ A and A62-structure g ,  guZu1 = (gu1)u2. 
0 
It is now immediate that the selectors form a group under this product. The 
inverse 0-l of a selector (T becomes defined by (~-l(z) 
= (~(z)-' for z E D. 

454 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
In group theoretic terms the group of selectors acts on the A62-structures, see 
Rotman [38]. 
The following lemma is now easy to prove. 
Lemma 6.7.4 
Let g be a A62-structure. Then [g'] = [g] for all 0: D + A. 
0 
6.7.4 
Let [g] be a dynamic A62-structure. A clan of each individual h E [g] is called 
a clan of [g]. We shall write 
Clans of a dynamic A6 2-structure 
C b l =  u C(h) 
h E b l  
for the family of clans of [g]. 
The closure properties of the clans of a dynamic A62-structure [g] are quite 
different from those of ordinary C2-structures. 
Example 6.24 
Recall that the intersection of two clans X , Y  E C(g) of an C2-structure g is 
always a clan. This does not hold in general for the dynamic A62-structures. 
Indeed, consider again A = Z 2 ,  and the following e2-structure g together with 
its image g': 
Figure 6.34: A A62-structure g and its image g'. 
Here X = {z2,z3,24} 
is a clan of g, and Y = {x1,x2,23} is a clan of g', and 
hence both of these are in C[g]. However, the intersection X n Y = {x2,x3} is 
0 
not in C[g] as can be easily verified. 
On the other hand, as shown in Lemma 6.7.5, the clans of [g] are closed under 
complement. As observed in Section 6.2.3 this is in general not true for C2- 
structures. 
We let x denote the complement D \ X of X 
D. 

6.7. DYNAMIC LABELED 2-STRUCTURES 
455 
A set X E C(g) is said to be isolated, if g(x,y) = la for all x E X and y E x. 
Hence, if X is an isolated clan, then its complement x is also a clan of g. 
Lemma 6.7.5 
Let g be a A62-structure, and let X E C(g) be a clan. There exists a selector 
u such that X is an isolated clan in g". 
Proof 
Let X E C(g), and define 0 as follows u(x) = la for all x E X ,  and u(y) = 
S(g(x,y)-') for all y 4 X .  Now, for all e = (x,y) with z E X and y f X ,  
g"(e) = la . g(e) . g(e)-' = la 
as required. 
0 
In particular, Lemma 6.7.5 implies the following closure result for dynamic 
As2-structures, see [22]. 
Theorem 6.7.6 
The set C[g] of clans of a dynamic A"-structure 
[g] is closed under comple- 
ments. 
0 
6.7.5 Horizons 
Let g: &(D) -+ A be a A'Zstructure. By Lemma 6.7.5, for each clan X E C[g] 
there exists an h E [g] such that X and 7 are both clans of h. In particular, 
this holds for the singleton clans {x} of [g], and therefore for each z E D, 
We shall call a node x E D a horizon of g: E2(D) -+ A, if g(x,y) = la for all 
y # x. By the proof of Lemma 6.7.5, for each g and each x E dom(g) x is a 
horizon of g"= , where 
D \ 
E C[gl. 
is the horizontal selector for x in g. 
We have the following uniqueness result for the horizontal selectors, which 
follows immediately from the definition of a horizon. 
Lemma 6.7.7 
Let g be a A62-structure, and x E dom(g). If for a selector IY, a(z) = la and 
0 
x is a horizon in g", then IY = uZ. 

456 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
A selector u :  D -+ A is said to be constaht on a subset X G D ,  if u(z1) = u ( ~ )  
for all 1 ~ ~ ~ x 2  
E X .  
Lemma 6.7.8 
Let g: Ez(D) -+ A be a A62-structure and h = g" for a selector 0. If for a 
subset 2 G D and a node z $! 2, g(z, zl) = g(z, 22) and h(z, 21) = h(z, z2) for 
all z1 , z2 E 2, 
then u is constant on 2. 
Pro0 f 
Suppose 2 C D is as stated in the lemma, and let zl,z2 E 2. We have 
g"(z, zz) = u(z) . g(s, zz) . b(u(z2)) 
(i = 1,2), 
and hence c(zl) = ~ ( z z ) ,  
because g"(z,z1) = g"(z,zz) and g(z,zl) = g(z,z2). 
This proves the claim. 
0 
When Lemma 6.7.8 is applied to clans, we obtain the next lemma which states 
that the derivation of a clan X E C[g] in a dynamic [g] depends only on X .  
Lemma 6.7.9 
Let X be a proper clan of a A62-structure g and let u be a selector. Then 
0 
X E C(g") if and only if u is constant on X .  
As a corollary of the above lemma we obtain that for each clan X of a dynamic 
A62-structure [g] either X or its complement is a clan of any h E [g] which has 
a horizon. 
Theorem 6.7.10 
Let [g] be a dynamic A62-structure, and let h E [g] be such that it has a 
horizon. Then 
C[g] = {X I X E C(h) or D \ X E C(h)}. 
Pro0 f 
Let z E D be a horizon of h. Let X E C[g], and let 2 E {X,x} 
be such 
that z $ 2. By Lemma 6.7.5, there exists a h' E [g] such that 2 E C(h') 
and 
E C(h'). Moreover, since [g] = [h], there exists a selector 0 such that 
h' = h". Because 2 E C(h') and 2 is a horizon in h, Lemma 6.7.8 implies 
that the selector u is constant on 2. By Lemma 6.7.9, 2 E C(h), and thus 
C[g] g {X 1 X E C(h) or D \ X E C(h)}. 
In the other direction the proof is obvious by Theorem 6.7.6. 

6.8. DYNAMIC C2-structures WITH VARIABLE DOMAINS 
457 
6.8 Dynamic C2-structures with Variable Domains 
6.8.1 Disjoint union of C2-sts-zlctures 
In some situations it is desirable that the domain of an C2-structure can be 
changed; one may, e.g., want to add or delete nodes of the C2-structure. Such 
change of a domain is standard in the theory of graph grammars. We shall now 
consider this problem in the framework of dynamic C2-structures as presented 
by Ehrenfeucht and Rozenberg [21]. The basic operation that we use to combine 
two C2-structures is the operation of disjoint union. 
Let A be a group and S its involution, and assume that g: E2(D1) -+ A and 
h: E2(D2) -+ A are disjoint A62-structures, ie., D1 n 0 2  = 8. We define the 
disjoint union of g and h as the C2-structure g + h: E2(dom(g) udom(h)) + A 
such that 
Clearly, g + h is a A62-structure, see Figure 6.35. 
Figure 6.35: Disjoint union g + h 
The following lemma is immediate from the definition. 
Lemma 6.8.1 
Let g and h be disjoint A62-structures. Then dom(g) E C([g+h]) and dom(h) E 
C([g + hl). 
0 
By Lemma 6.7.5, for any CZstructure g: E2(D) + A and for any clan X E 
C([g]), there exists a selector (T such that 
g = (sub,(D \ X) + sub,(X))" 

458 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
In particular, when we apply this result to the singleton clans, we obtain 
a construction of g from the singleton C2-structures as follows: Let D = 
{x1,xz, . . . , xn}, and denote for simplicity by x the singleton t2-structure 
with domain {x}. There are then A62-structures gi and selectors ( ~ i  for 
i = 1,2,. . . , T I  - 1 such that dom(gi) = (21,. . .,xi}, gi+l = (gi + ~ i + l ) ~ *  
and g = gn. 
6.8.2 Comparison with grammatical substitution 
In the theory of graph grammars the derivations of graphs are based on the 
operation of grammatical substitution. We shall now consider this operation 
in the context of dynamic Ab2-structures. 
Let g and h be As2-structures with A as their group of labels. Assume that 
z E dom(g) and that (dom(g)\{x})fldom(h) = 0. The grammatical substitution 
of h for x in g is the A62-structure g(x t h) : (dom(g) \ {z}) U dom(h) + A 
such that 
The operation of grammatical substitution as defined above corresponds to the 
case of node label controlled (eNLC) graph grammars (see 1) where the con- 
nection relation is hereditary in the sense that the labels of the edges adjacent 
to the ‘mother node’ carry over without change to the edges adjacent to the 
daughter graph. 
In the following if f = g + h, then we denote h = f - g. For a Ab2-structure 
g and a node x, let (T, 
be the horizontal selector for x. The following result 
from [21] states that the operation of substitution can be expressed by the 
operations of disjoint union and difference, and by (horizontal) selectors. 
Theorem 6.8.2 
Let g and h be A62-structures, and let x E dom(g) be such that (dom(g) \ 
{x}) n dom(h) = 0. Then 
g(x t h) = (T,l(((Tz(g) - x) + h). 
0 
Let g and h be disjoint A62-structures. We say that a A’Zstructure f decom- 
poses directly into g, h, denoted f + {g, h}, if f E [g + h], i.e., if there exists a 

6.8. DYNAMIC e2-structures WITH VARIABLE DOMAINS 
459 
selector ~7 such that f = (g + h)". Further, a dynamic A62-structure F decom- 
poses directly into dynamic A62-structures G and H ,  denoted F j 
{G, H } ,  if 
there exist an f E F ,  g E G and h E H such that f j 
{g, h}7 ie., if F = [g+h] 
for some g E G and h E H .  
The next theorem shows that a direct decomposition of F amounts to decom- 
posing F into clans. 
Theorem 6.8.3 
Let F,G and H be dynamic A62-structures, and let the domain of F be D. 
F 3 {G, H }  if and only if there exists a nonempty proper clan X E C(F) such 
0 
that G = subF(X) and H = subF(D \ X ) .  
6.8.3 Amalgamated union 
We relax now the disjointness condition of the domains and consider the situ- 
ation, where two A62-structures g and h share a common substructure. 
Let g and h be two A62-structures with A = dom(g) n dom(h) such that 
sub,(A) = subh(A), dom(g) \ A E C ( g )  and dom(h) \ A  E C(h). We define the 
amalgamated union g LI h of g and h as the As,-structure 
Clearly, g LI h is a As2-structure7 see Figure 6.36. 
Figure 6.36: Amalgamated union g II h 
Lemma 6.8.4 
Let f = g LI h. Then dom(g) E C([f]) and dom(h) E C([f]). 

460 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
The following decomposition result for dynamic A62-structure using amalga- 
mated unions was proved in [21]. 
Theorem 6.8.5 
Let F be a dynamic A62-structure on a domain D. If X , Y  E C(F) are non- 
empty and X U Y = D, then there exist g E subF(X) and h E subF(Y) such 
0 
One can now define the direct decomposition relation based on amalgamated 
unions analogously to the direct decomposition relation based on disjoint 
unions. For this let g and h be A62-structures with A = dom(g) n dom(h) 
such that sub,(A) = subh(A), dom(g) \ A  E C(g) and dom(h) \ A E C(h). 
We say that a A62-structure f directly amalgam decomposes into g, h, denoted 
f j L I  {g, h}, if f E [g LI h]. Further, we write F j L I  {G, H }  for dynamic 
A62-structures F ,  G and H ,  if F = [g II h] for some g E G and h E H .  
We obtain for amalgamated unions an analogous result to Theorem 6.8.3: 
Theorem 6.8.6 
Let F = [f] be a dynamic A62-structure. Then F j L I  {G, H }  if and only if 
there exist nonempty X , Y  E C(F) such that X u Y = dom(f), G = subF(X) 
that F = [g LI h]. 
and H = subp(Y). 
0 
6.9 Quotients and Plane Trees 
6.9.1 
Quotients of dynamic As2-structures 
Let [g] be a dynamic A62-structure. We define now the factorizations and 
quotients of [g]. These constructions are not quite so straightforward as for 
2-structures, because the clans X C C[g] forming a partition of the domain D 
of [g] may come from different images of g. 
A partition X of the domain D into clans of [g] is called a factorization of [g]. 
The quotient of [g] by X is the family 
[g]/X = {h/X I h E [g], X a factorization of h}. 
The family [g]/X is well-defined in the sense that each h / X  is a A"-structure. 
Below we show that for each factorization X 
C[g], the quotient [g]/X is 
nonempty and, indeed, it is the dynamic As2-structure [h/X] for some h E [g]. 
If a(x) = a is a constant selector on the whoIe domain D ,  then for all e E 
Ez(D), g"(e) = a . g(e) . S(a). Clearly, in this case, g' is strictly isomorphic 
with g. Hence the following lemma holds. 

6.9. QUOTIENTS AND PLANE TREES 
Lemma 6.9.1 
Let g be a A62-structure. If h = g" for a selector u, which is constant on D, 
then h and g are strictly isomorphic. In this case, the substructures sub,(X) 
and subh(X) and the quotients g / X  and h / X  are strictly isomorphic for all 
0 
461 
X C D and all factorizations X of g .  
The following theorem was proved in Ehrenfeucht, Harju and Rozenberg [12]. 
Theorem 6.9.2 
If X is a factorization of a dynamic [g], then there exists a selector u such that 
X is a factorization of g", and 
b I / X  = 19"/Xl. 
Proof 
Let X = { X I ,  X2, . . . , X,} 
and [g] be as stated in the claim. For each X E X, 
we have X E C ( g U x )  for some selector ox. By Lemma 6.7.9, we may assume 
that ax(y) = la for all y 4 X .  Define u = u~,,,ux,-~ . . .ox1. Hence u(z) = 
ux(z), if z E X ,  since X is a factorization of [g]. Moreover, by the choice 
of the selectors ux,, 
u = uxm~m)c~m(m-ll 
. . . 
for any permutation 7r of 
{1,2,. . . ,m}. Now, g" = ( g " x ) " ' " ~ l ,  where u .  
0%' is constant on X .  Hence 
by Lemma 6.7.9, X E C(g") for each X E X, 
and thus X is a factorization of 
h = g". 
Now, if X is a factorization of some 91 E [g], then from Lemma 6.7.4 we obtain 
that g1 = h"1 for a selector 01. Consequently, Lemma 6.7.9 yields that (TI 
is constant on each X E X, 
and, therefore g1/X = (h/X)"z for the selector 
0 2 :  X + A defined by u g ( X )  = u1(z) (z E X )  for all X E X .  
On the other hand, if u2: X -+ A is a selector, then it can be extended to 
a selector u1: D + A by setting u1(z) = 02(X), if z E X with X E X .  
Evidently, hQ1/X = (h/X)"z, and thus [g]/X = {(h/X)"2 I u2 a selector} as 
required. 
0 
6.9.2 Plane trees 
In general, two given g1 and g2 in [g] can be quite different from each other. 
Indeed, the clan structures of g1 and g2 may be drastically different as shown 
in the following example. 
Example 6.25 
Let D = {z1,22,z3}, A = Z, and let 6 be the inverse function of A. Let g 
be the complete A"-structure 
corresponding to the label 0, ie., g(e) = 0 for 

462 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
all e E E2(D). Hence all subsets of D are clans of g. Let then IT be a selector 
defined by g ( x l )  = 0, ( ~ ( 5 2 )  = 1 and 4 x 3 )  = 3. Then h = g' 
is specified by 
h ( q , x 2 )  = 4, h(22,x3) = 3 and h(x3,xl) = 3. Now, h is primitive - has only 
the trivial clans. 
0 
Let G = [g] be a dynamic A62-structure, and assume that x is a horizon of g. 
The substructure 
r z  (9) = sub, (D \ {XI) 
is called the x-plane of g (or an x-plane of G). We shall denote by GZ the 
family of x-planes of G. 
Since for each node x of a G = [g], {x} E C[g], Lemma 6.7.5 implies that there 
exists an h E G such that x is a horizon of h. Hence G: is always nonempty. 
The following result from [12] shows that the planes in GZ are quite similar to 
each other. 
Theorem 6.9.3 
Let G be a dynamic A62-structure. The planes in G: 
are strictly isomorphic. 
Pro0 f 
Let g1,92 E G be such that x is a horizon in both of them, and let hi = x,(gi) 
for i = 1,2. By Lemma 6.7.4, there exists a selector (T such that g2 = g;. 
Clearly, h2 = hyl, where C T ~  : D \ {x} -+ A is the restriction of IT. Since D \ {x} 
is a common clan of g1 and g2, Lemma 6.7.9 implies that (T is constant on 
D \ {x}. By Lemma 6.9.1, hl and h2 are strictly isomorphic, since hl and h2 
0 
In particular] it follows from Lemma 6.9.1 that for any two planes hl, h2 E G", 
C ( h 1 )  = C(h2) and P(h1) = P(h2). It follows also that for all X E P(hl) 
the special quotients Qhl(X) and g h 2 ( X )  are of the same type, i e .  they are 
both primitive or both complete or both linear. This justifies the following 
definition, where an element X E P(h1) obtains a label p,c or l? according to 
the type of !@\~h, (X). 
Let x E D for a dynamic As2-structure G. 
(1) Denote C(x) = C(h,), P(z) = P(h,) and N(x) = P(h,) U {x}, where h, 
is an arbitrary element of GZ. 
(2) Define @ z ( { x } )  = c and for all X E P(h,), let qx = *h,(X) and 
have the same domain D \ {x}. 
p ,  
c, if qx is complete, 
e, 
if qx is truly primitive, 
if qx is linear and Iqxl > 1. 

6.9. QUOTIENTS AND PLANE TREES 
463 
In the above definition we have the requirement 1qx I > 1 in the case of linear qx 
in order to have ax 
well-defined, because a singleton quotient is, by definition, 
both complete and linear. 
(3) The plane tree L(z) of the node x is the node-labeled directed rooted tree 
with the set of nodes N(z) labeled by $x, which is obtained from the prime 
tree T(hx) by adding {z} as a new root and ( 2 ,  D \ {x}) as a new edge. 
Example 6.26 
Let A = Z3 
and let 6 be the inverse function of A. Consider the A62-structure 
g from Figure 6.37. 
5 1  
0 
/- 
5 2  
0 
2 4  
/ 
\ 
1 
0 
Figure 6.37: A'2-structure 
g 
We note that g has a horizon xl. The xl-plane hl of g is given in Figure 6.38. 
The nontrivial prime clans of hl are { 2 2 , 2 3 }  and (24, Q,}, and the plane tree 
of 2 1  is given in Figure 6.39, where a nonsingleton node X has been labeled 
by d, if @.,(X) = d. Again, each nonsingleton node consists of the leaves that 
are its descendants in the directed tree, and so we have omitted the identities 
of these nodes in Figure 6.39. The singleton nodes xi have been identified, but 
without the label c. 
Let us then make 2 4  a horizon. This is done by the horizonal selector 5 as 
follows: ' ~ ( 2 4 )  = 0 and .(xi) = g(24,zi) for i # 4. Now, the x4-plane h4 of g' 
is given in Figure 6.40. 
The nontrivial primes of h4 are { 2 1 , 2 2 , 2 3 }  and ( 2 2 ,  z3}, and the plane tree 
of 2 4  is given in Figure 6.41. 

464 
1 
T 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR 
1 2  
0 
0 
.- 
0 
2 3  
c 
Figure 6.38: 21-plane of g 
c 
e 
e 
Figure 6.39: Plane tree L(x1) 

6.9. QUOTIENTS AND PLANE TREES 
2 
Figure 6.40: Plane h4 
5 4  
C 
x5 
465 
Figure 6.41: Plane tree L(24) 

466 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
The plane trees L(h1) and L(h4) are not isomorphic, but their underlying 
unrooted and undirected trees are node-isomorphic, and indeed, as we shall 
see, the quotients of the corresponding nodes are of the same size and type. 0 
By Theorem 6.7.10 we have the following lemma. 
Lemma 6.9.4 
Let x be a node of a dynamic A62-structure G. Then for each clan X of G 
such that X $ (8, D } ,  X E C(z), if x $ X ,  and x 
E C(z), if z E X .  
Pro0 f 
Let x be a horizon of g E G and let rZ(g) = h. Assume X is a clan of G. 
Assume Y E { X , x }  is such that Y E C(g). If z $ Y ,  then since the domain of 
h, D \ {x}, is a clan of g, Lemma 6.6.5 implies that Y E C(h). 
On the other hand, if x E Y ,  then 
E C(g). Indeed, for all y E Y (y # z) and 
z $ Y we have that g(y, z) = la = g(z, z), since x is a horizon of g. Moreover, 
since Y E C(g), g(x, z )  = g(y, z ) .  Hence g(y, z )  = l~ for all y E Y and z $ Y ,  
which shows that y E C(g). In this case 7 
E C(h) by Lemma 6.6.5. Now the 
claim follows from Theorem 6.7.10. 
0 
Our purpose is to compare the planes of a dynamic A”-structure G. For this 
we first study the relationships between the prime clans. 
Lemma 6.9.5 
Let G be a dynamic As2-structure, and let s l y  be two nodes of its domain. 
Assume that X E P(2). 
(1) If y $ X ,  then X E P(y). 
(2) If y E X ,  then x E P(y). In particular, P(2) and P ( y )  have the same 
number of prime clans. 
The claim follows directly from Lemma 6.9.4, when we observe that a clan Y 
0 
Proof 
of G overlaps with a subset 2 C: D if and only if Y overlaps with z. 
Example 6.27 
Consider the plane trees L(x1) and L(x4) of Example 6.26 (see, Fig- 
ures 6.39 and 6.41). Denote A = {ZZ,XQ} and B = {x4,x5}. We have redrawn 
these plane trees in Figure 6.42 in order to illustrate the 1-1 correspondence 
between them. Hence L(24) is obtained from L(z1) by reversing the direction 
of the path from x1 to 2 4 ,  and each inner node of this reversed path is the 
complement of its successor in the original path in L(z1); hence, e.g., the node 
B becomes G, The singleton node x4 that begins the reversed path does not 

6.9. QUOTIENTS AND PLANE TREES 
467 
change, because it does not have a successor in L(x1). Note that the corre- 
0 
sponding nodes in these plane trees are of the same type. 
2 1  : c  
2 1  : c 
- 
2 1  : c  /\ 
2 2  : c 
2 3 : c x 4 : c  
2 5 : c  
2 2 : c  
x 3 : c  2 4 : c  
2 5 : c  
Figure 6.42: Comparison of two plane trees 
Following Lemma 6.9.5 (and the previous example) we define for all z,y E D 
the mapping qzy : N(x) + N(y) as follows: 
X ,  if y @ X or X = {y}, 
(6.6) 
y E X ,  y E Y and ( X , Y )  is an edge in L(z). 
Lemma 6.9.6 
Let G be a dynamic A62-structure, and let x, y be two of its nodes. Then qzy 
is a bijective correspondence between N(x) and n/(y). 
Proof 
First of all qzy is well-defined. Indeed, for each X E N(x) with y E X and 
X # {y} there is a unique edge ( X , Y )  in L(x) such that y E Y and Y c X .  
Now, by Lemma 6.9.5, y E N(y) (with y @ s), 
and, by the definition of qZy, 
The injectiveness claim follows from the above stated uniqueness of the edge 
( X , Y ) ,  since if y E X for some X E N(z) with X # {y}, then for the unique 
Y E N(z) with v z y ( X )  = y we have that 
@ N(x) (because x E L). 
It 
Vzy(X) = y. 

468 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
follows that the mapping qzy is surjective, because the sets N(x) and N(y) 
are finite and have the same number of elements. 
0 
The following result from [12], which we state without proof, gives a simple 
construction that allows one to obtain the plain tree L(y) from L(x). Indeed, 
L(y) is obtained from L(x) by first changing the nodes by the mapping qsy, 
and then reversing the direction of the path from x to y. 
Theorem 6.9.7 
Let G be a dynamic A62-structure and let x, y be two of its nodes. If ( X ,  Y )  
is an edge of L(x), then 
(1) (7IY(XLVIY(Y)) is in L(Y), ifY 4 y ,  
(2) (rlZY(Y),77SY(X)) is in L(Y), i f Y  E y .  
0 
The correspondence qsY also preserves the types of the quotients: 
Theorem 6.9.8 
Let G be a dynamic A62-structure and let x,y be two of its nodes. Then 
0 
@ z ( X )  = @y(q,y(X)) for all X E N(x). 
Now, let z be a node of a dynamic A62-structure G. Define F(x) = (N(x), 
as the form of x, that is, F(x) is undirected and unrooted tree such that { X ,  Y }  
is an edge in F ( x )  if and only if either ( X ,  Y )  or (Y, X )  is an edge of L(x). The 
labeling az : N(z) + { p ,  c, .t} of the nodes remains the same as in L(x). 
Theorem 6.9.9 
Let x, y be two nodes in a dynamic A62-structure G. The forms F(x) and F ( y )  
are isomorphic. Indeed, qzy : N(x) -+ N(y) is a label preserving isomorphism 
from F(x) onto F(y). 
Proof 
By Theorem 6.9.7, if { X , Y }  is an edge of F(x), then {qzy(X),qzy(Y)} is an 
edge of F(y). 
Moreover, vzy is a bijection from N(s) onto N(y). This shows 
that qzy is an isomorphism between F ( x )  and F(y). 
By Theorem 6.9.8, a z ( X )  = GY(qzy(X)) 
for all X E N(x), and hence qsY 
0 
Theorem 6.9.9 allows us to construct a tree F(G), the form of G, for each 
dynamic A62-structure G as follows. Consider the tree F(x) for a node x and 
leave the nodes unidentified, but labeled by as. 
Hence a tree F(G) becomes 
an ‘abstract tree’ in the sense that the identities of the nodes are omitted. To 
be more precise, F(G) is the isomorphism class of the forms F ( x )  with x in 
the domain of G. 
preserves the labels of the nodes. This proves the claim. 

6.10. INVARIANTS 
469 
Example 6.28 
The form F(G) of the the dynamic A62-structure G from Example 6.26 (see, 
I3 
Figure 6.37), is given in Figure 6.42. 
C 
C 
e 
e 
C 
C 
C 
C 
Figure 6.43: The form F(G) 
6.10 
Invariants 
6.10.1 
Introduction to invariants 
In this section we shall consider the problem how to recognize that an C2- 
structure g is obtainable from another f22-structure h by an application of a 
selector. In order to answer this question invariant properties of C2-structures 
were studied by Ehrenfeucht, Harju and Rozenberg [ll], where the invariants 
were shown to be closely connected to the verbal identities of the group A of 
labels. In this paper we shall not go into these group theoretical considerations, 
and furthermore, we state a detailed characterization only for the abelian case 
(in Section 6.10.4). For the proofs and further results we refer to [ll]. 
In this section the involution 6 of the given group A will be the inverse function 
of A, 
b(u) = u-l 
( U  E A). 
For this reason we call a A”-structure more conveniently an inversive e2- 
structure. 
Denote by R ( D ,  A) the family of all inversive 12-structures g :  &(D) -+ A for 
a given domain D and for a given group A of labels. 
The inversive C2-structures in R ( D ,  A) are naturally divided into dynamic 12- 
structures, i.e., the family {[g] I g E R(D,A)} forms a partition of R(D,A). 

470 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
A function 7: 
R ( D ,  A) + A is an invariant, if it maps the elements of each 
dynamic [g] into the same element, 
Hence an invariant is immune to the selectors, and the study of invariants is 
the study of those properties of a network that remain unchanged during its 
evolution. 
A constant mapping, q(g) = u (u E A, g E R ( D , A ) )  is a simple example of 
an invariant. 
We shall also say that two C2-structures g1 and g2 are equivalent, if [gl] = [g2]. 
Hence a function q :  R ( D ,  A) + A is an invariant, if it maps equivalent C2- 
structures to the same element of the group A. 
6.10.2 
Free invariants 
In general an invariant, as defined above, is a function that can be independent 
of the specific properties of the C2-structures. In order to reflect these properties 
of the C2-structures, we shall restrict ourselves to those invariants that are more 
faithful to the 12-structures in the sense that they are defined by variables 
corresponding to the edges. 
Consider the free monoid M ( D )  = E2(D)* generated by the edges. The ele- 
ments of M ( D )  are the words e1e2.. . ek for Ic 2 0 and ei E E,(D). The empty 
word, denoted by 1, is the identity element of the monoid M ( D ) .  For a word 
w = e1e2.. . ek E M ( D )  we let w-l = eileL:l . . .el'. In this way M ( D )  
becomes a monoid with involution. 
In order to clarify the distinction between the edges in C2-structures and the 
generators of the free monoid M ( D ) ,  the generators e E M ( D )  will be called 
variables. 
Each word w = e1e2.. . ek E M ( D )  defines a function $Jw from R ( D ,  A) into 
A as follows, 
We call the function qW the variable function represented by w ,  and we let 
Var(D, A) denote the set of all variable functions represented by the words in 
Two words 201 and w2 from M ( D )  are said to be equivalent (over A), denoted 
w1 = w2, if they represent the same variable function, $Jw, = q ! ~ ~ , .  
M ( D ) .  

6.10. INVARIANTS 
471 
Further, if a variable function gW E Var(D, A) is an invariant, then it is a free 
invariant of R(D, A). Denote by Inv(D, A) the set of all free invariants gW of 
WD, A). 
Example 6.29 
Let A = Z3 = {0,1,2} be the cyclic group on three elements. Assume further 
that D = { ~ 1 , ~ 2 , ~ 3 } ,  
and write eij for (zi,zj). 
The word w1 = e12e23e31 
represents an invariant, Le., $,, 
E Inv(D,A), since for all g E R(D,A) and 
all selectors 0: 
D + A with .(xi) = ai, QW, (9) = g(e12) + g(e23) + g(e31) and 
$WI (9") = g"(e12) f g"(e23) + g"(e31) 
= (a1 + g(e12) - a2) + (a2 + g(e23) - a3) + (a3 + g(e31) - al) 
= g(el2) + g(e23) f g(e31) = QWI (9) 7 
because A is abelian. 
For the two structures g1 and g2 from Figure 6.44, we have $W, (gl) = 2 # 1 = 
&,,, (g2), which implies that for all selectors CT, g2 # g:, 
since $,, 
(gp) = 2 but 
$Wl 
( 9 2 )  = 1 for each 0. Hence in this case [gl] # [g~]. 
91 
92 
Figure 6.44: Nonequivaient inversive f?Zstructures 
On the other hand, let w2 = el~e32e31. Now, $W, (9) = g(el2) + g(e32) + g(e31) 
and 
$W,(g") = s"(e12) + f(e32) + g"(e31) = 2a3 - 2a2 + II, w2 ( 9 ) , 
and thus $,, 
(9") = GW2 (9) if and only if 2a3 - 2a2 = 0 in Z3. It follows that 
$Wz is not an invariant of R ( D ,  A), since, e.g., the selector may have chosen 
a2 = 1 and a3 = 2. 
0 

472 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
The constant functions q :  R ( D ,  A) -+ A are invariants, but as can be easily 
shown only the trivial constant function is a free invariant. 
6.10.3 
From the definition of Var(D, A) we obtain that for all words w, w1, 
w2 E M ( D )  
Basic properties of free invariants 
$wlw, (9) = $ w l b )  . $wz(g) 7 
$w-l(g) = $w(g)-' 
and 
$1(g) = l A ,  
whenever g is an inversive t2-structure. (Here 1 is the empty word). Therefore 
Var(D, A) is a group with the operation defined by 
$w, . $wz = $WlW, 
The identity of the group Var(D, A) is the variable function $1 represented by 
the empty word. Further, we have $,k(g) 
= $w(g)k for all w E M ( D ) ,  Ic E Z 
and g E R ( D ,  A). Therefore we can write 
$,k 
=$i and 
$ w-l =+; 
1 . 
Moreover, Var(D, A) is generated by the variable functions $e represented by 
the variables, e E Ez(D). 
The following result from [ll] shows that a free invariant GW is, in fact, a 
mapping $, 
: R ( D ,  A) + Z(A) into the center of the group A. This implies 
that the group Inv(D, A) is always abelian. Recall that the center of a group 
A is defined by 
Z(A) = { a  E A I ax = %a for all z E A}. 
Theorem 6.10.1 
(1) For all free invariants $w E Inv(D, A) and inversive g, +,(g) 
E Z(A). 
(2) 'Inv(D, A) is a subgroup of Z(Var(D, A)). In particular, Inv(D, A) is an 
abelian group. 
0 
By Theorem 6.10.1, if the center Z(A) is trivial, then there are no nontrivial 
free invariants for the inversive C2-structures g with the group A of labels, see 
Example 6.30 below. 
A word w = (20, 
q)(z1, 
z2). . . (zkw1, zo) from M ( D )  is called a closed walk 
of length k. A closed walk 

6.10. INVARIANTS 
473 
is called a triangle (at zo), if zi # zj for each i # j. The empty word 1 E M ( D )  
is a trivial walk. 
The next result is rather easy to prove. 
Theorem 6.10.2 
Let w E M ( D )  be a closed walk. Then 11, E Inv(D, A) if and only if GW(g) 6 
Z(A) for all inversive e2-structures g. In particular, if A is abelian, then GW is 
0 
a free invariant of R ( D ,  A). 
Example 6.30 
Consider the dihedral group Dan of 2n elements (n 2 3), 
Dzn = {l,a,a ,..., an-’, b, ba, ba’,. . . ,ban-’}, 
where 1 is the identity element of D2n. The group Dzn is the symmetry group 
of a regular n-gon of the Euclidean plane, and it is generated by a rotation 
a (with an angle of 27r/n) together with a reflection b of the n-gon. These 
generators satisfy the following defining relations 
an = 1, 
b2 = 1, 
ab = ba-’ 
It is rather easy to show that if n is odd, then Z(D2,) is trivial, and hence in 
this case the group Inv(D, A) of free invariants is also trivial by Theorem 6.10.1. 
On the other hand, if n is even, then Z(D2,) contains two elements, i.e., it 
is isomorphic to the cyclic group Z 2 .  Let us consider the case n = 4. In this 
case Z(&) = {l,a2}. Assume that the domain D has at least three nodes, 
and let w be any closed walk. We claim that the variable function &,,2 
is a free 
invariant. Here w2 is the closed walk that traverses w twice around. 
Indeed, let g be an inversive C2-structure. Then 
GWZ(9) = (hLJ(9))2, 
and it is easy to check that for all c E Dg, c2 = 1 or a2. Therefore $,z(g) 
E 
Z(&) for all g E R ( D ,  A), and thus $,2 
is a free invariant by Theorem 6.10.2. 
0 
6.10.4 
Invariants on abelian groups 
We shall show that in the abelian case the invariants represented by the trian- 
gles at z o  form a ‘complete’ set of invariants. 

474 
CHAPTER 6. BSTRUCTURES - A FRAMEWORK FOR ... 
Clearly, in the abelian case, for w1,wz E M(D) we have w1w2 = wzwl, and 
hence the occurrences of the variables in w E M ( D )  can be freely permuted 
without violating invariant properties. 
For an abelian group A the group Inv(D, A) has properties that are indepen- 
dent of the 2-structures in the following sense. Let w = (zl,yl). . . (xn, 
yn) be 
a word and B :  D + A a selector. Then we have for all g E R(D, A), 
?4Jw(g") = B ( d g ( ~ 1 , Y l ) 4 Y 1 ) r 1 . .  . B(Xn)g(G,Yn)4Yn)-1 
= 4 z l > 4 Y l ) - 1  . . .4Xn)B(Yn)-l . +w(g) 
I 
and thus ?4Jw is a free invariant if and only if a(zl)a(yl)-' . . . a ( z n ) ~ ( y n ) - l  = 
la for all selectors B. Notice that the latter condition does not depend on g, 
and hence we have the following characterization result from [ll]. 
Theorem 6.10.3 
Let A be an abelian group. The following conditions are equivalent for a vari- 
able function + w .  
(1) gw is a free invariant of R ( D ,  A). 
(2) For each g E R ( D ,  A) and for each selector B, &,(g") = &,,(g). 
(3) There exists a g E R ( D ,  A) such that for each selector 8, 
?4Jw(g") = +w(g). 
0 
For a fixed node xo E D ,  the set 
T,, = (t(z0, y, z )  I zo,y, z E D are distinct } 
is the bucket of triangles at XO. 
Each triangle t E T, is a closed walk, and so it represents a free invariant 
?4Jt E Inv(D,A) for abelian A. The next theorem (from [ll]) states that these 
invariants generate Inv(D, A). The proof of this is based on the following simple 
identity, which allows us to use triangles. Let xo be a fixed node. For each 
e = (y, z ) ,  where y # xo and z # 20, we have 
Theorem 6.10.4 
Let A be an abelian group and XO an element of the domain D. Then Inv(D, A) 
0 
is generated by the free invariants represented by the triangles at 20. 
The triangles (at a fixed node 20) not only represent generators of Inv(D, A) 
but form a large enough set to characterize the relation [g] = [h] between the 
inversive labeled 2-structures on an abelian A. 

6.10. INVARIANTS 
475 
A set W of invariants for R ( D , A )  is said to be a complete, if W satisfies for 
all 91, 
g2 the condition: [gl] = [g2] if and only if q(g1) = ~ ( 9 2 )  
for all 7 E W .  
We notice that in the above definition the converse implication is always valid, 
that is, if gp = g2 for a selector CT, then for every invariant 7, q(g2) = q(gP) = 
q(gl). On the other hand, if a set of invariants W is complete and [gl] # [g2], 
then there exists an invariant q E W such that q(g1) # ~ ( g 2 ) .  
Theorem 6.10.5 
Let A be an abelian group. For each xo E D the bucket of triangles T,, forms 
0 
a complete set of invariants. 
The above theorem allows the use of ‘local’ triangles for checking whether or 
not [gi] = [g2], i.e., if [gi] # (921, then we can find a (common) triangle in g1 
and g2 that induces non-equivalent substructures in g1 and g2. 
Example 6.31 
Let A = Z 2  and let 91, 
g2, g3 be the structures from Figure 6.45. Consider the 
triangle t = t(z1,22,X3). We have &(g1) = 1 # 0 = $t(g2), and hence by the 
above theorem there does not exist a selector CT for which g2 = g?. 
On the other hand, we observe that for the triangles t = t(x1,22,x3), 
t = 
0 
t(Zl,X3,Z4) and t = t(Zl?X2,X4), 
Gt(g1) = $t(g3), and hence $t(g1) = qt(g3) 
for all triangles t E TZl. Hence, by Theorem 6.10.5, [gl] = [g3]. 
1 
1 
91 
92 
93 

476 
CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
6.10.5 Clans and invariants 
Now, we do not assume that the group A is abelian. We shall state an invariant 
property of inversive (2-structures connected to the clans of C2-structures. 
Let a closed walk 
s(ZO,zl, 2 2  , 2 3 )  = (50 , 51) (21 2 2 )  (x2 5 3 )  ( 5 3  , 2 0 )  E M ( D )  
with four nodes be called a square. The following rather straightforward theo- 
rem (from [ll] states that being a clan is an invariant property of the dynamic 
inversive C2-structure [g]. 
Theorem 6.10.6 
Let 9: E2(D) -+ A be an inversive 12-structure on a group A of labels. A 
subset X 2 D is a clan of [g], if q ! ~ ~ ( g )  
= la for all squares s = ~ ( 2 1 ,  
y1,52, y2) 
0 
with y1, y2 E D \ X and x1,x2 E X .  
References 
J.A. Bondy and U.S.R. Murthy, Graph Theory with Applications, 
Macmillan, London 1978. 
P. Bonizzoni, Primitive 2-structures with the (n - 2)-property, Theoret. 
Comput. Sci. 132 (1994), 151 
~ 
178. 
H. Buer and R.H. Mohring, A fast algorithm for the decomposition of 
graphs and posets, Math. Oper. Res. 8 (1983), 170 - 184. 
W.H. Cunningham, Decomposition of directed graphs, SIAM J. Alg. 
Disc. Meth. 3 (1982), 214 ~ 228. 
W.H. Cunningham, Decomposition of submodular functions, Combina- 
torica 3 (1983), 53 - 68. 
W.H. Cunningham and J. Edmonds, A combinatorial decomposition the- 
ory, Canadian J. Math. 32 (1980), 734 - 765. 
A. Deutz, Privite communication. 
A. Ehrenfeucht, H.N. Gabow, R.M. McConnell and S.J. Sullivan, An 
O(n2) algorithm to compute the prime tree family of a 2-structure, J. of 
Algorithms, to appear. 
A. Ehrenfeucht, T. Harju and G. Rozenberg, Permuting transformation 
monoids, Semigroup Forum 47 (1993), 123 - 125. 
A. Ehrenfeucht, T. Harju and G. Rozenberg, Incremental construction 
of 2-structures, Discrete Math. 128 (1994), 113 - 141. 
A. Ehrenfeucht, T. Harju and G. Rozenberg, Invariants of 2-structures 
on groups of labels, Manuscript (1994). 

REFERENCES 
477 
[12] A. Ehrenfeucht, T. Harju and G. Rozenberg, Quotients and plane trees of 
group labeled 2-structures, Leiden University, Department of Computer 
Science, Technical Report No. 03, 1994. 
[13] A. Ehrenfeucht, H.J. Hoogeboom, P. ten Pas, and G. Rozenberg, An in- 
troduction to context-free text grammars, in Developments in Language 
Theory, G. Rozenberg and A. Salomaa, eds., World Scientific Publishing, 
1994. 
[14] A. Ehrenfeucht, P. ten Pas, and G. Rozenberg, Combinatorial properties 
of texts, RAIRO Theoret. Inf 27 (1993), 433 - 464. 
[15] A. Ehrenfeucht and G. Rozenberg, Finite families of finite sets, Part I 
and 11, Univ. of Colorado at Boulder Technical Report, April 1986. 
[lS] A. Ehrenfeucht and G. Rozenberg, Theory of 2-structures, Parts I and 
11, Theoret. Comput. Sci. 70 (1990), 277 - 303 and 305 - 342. 
[17] A. Ehrenfeucht and G. Rozenberg, Primitivity is hereditary for 2- 
structures Theoret. Comput. Sci. 70 (1990), 343 - 358. 
[18] A. Ehrenfeucht and G. Rozenberg, Partial (set) 2-structures; part 11: 
State spaces of concurrent systems, Acta Informatica 27 (1990), 343 ~ 
368. 
[19] A. Ehrenfeucht and G. Rozenberg, Angular 2-structures, Theoret. Com- 
put. Sci. 92 (1992), 227 - 248. 
[20] A. Ehrenfeucht and G. Rozenberg, T-structures, T-functions, and texts, 
Theoret. Comput. Sci. 116 (1993), 227 - 290. 
[21] A. Ehrenfeucht and G. Rozenberg, Dynamic labeled 2-structures with 
variable domains, Lecture Notes in Computer Science 812 (1994), 97 ~ 
123. 
[22] A. Ehrenfeucht and G. Rozenberg, Dynamic labeled 2-structures, Math- 
ematical Structures in Computer Science, to appear. 
[23] J. Engelfriet, T. Harju, A. Proskurowski and G. Rozenberg, Characteri- 
zation and Complexity of Uniformly Non-Primitive Labeled 2-Structures, 
Theoret. Comput. Sci., to appear. 
[24] J. Engelfriet and G. Rozenberg, Graph Grammars based on node rewrit- 
ing: on introduction to NLC graph grammars, Lecture Notes in Computer 
Science 532 (1990), 12 - 23. 
[25] T. Gallai, Transitiv orientierbare Graphen, Acta Math. Acad. Sci. Hun- 
gar. 18 (1967), 25-66. 
[26] J.L. Gross and T.W. Tucker, “Topological Graph Theory”, Wiley, New 
York, 1987. 
[27] M. Habib and M.C. Maurer, On the X-join decomposition for undirected 
graphs, Discrete Appl. Math. 1 (1979), 201 ~ 207. 
[28] F. Harary, On the notion of balance of a signed graph, Michigan Math. 
J. 2 (1953-54), 143 - 146; addendum, 2 (1953-54) preceding p.1. 

CHAPTER 6.2-STRUCTURES - A FRAMEWORK FOR ... 
T. Harju and G. Rozenberg, Reductions for primitive 2-structures, Fun- 
damenta Informatica 20 (1994), 133 - 144. 
T. Harju and G. Rozenberg, Decomposition of infinite labeled 2- 
structures, Lecture Notes in Computer Science 812 (1994), 145 
~ 
158. 
L.O. James, R.G. Stanton and D.D. Cowan, Graph decomposition for 
undirected graphs, in “Proc. 3rd Southeastern Conf. on Combinatorics, 
Graph Theory, and Computing”, 1972, 281 - 290. 
B. Jamison and S. Olariu, P-components and the homogeneous decom- 
position of graphs, SIAM J. on Discrete Math. to appear. 
J.H. van Lint and J.J. Seidel, Equilateral points in elliptic geometry, 
Proc. Nederl. Acad. Wetensch Ser A 69 (1966), 335 - 348. 
R.M. McConnell, A linear-time inremental algorithm to compute the 
prime tree family of a 2-structure, Algoritmica, to appear. 
R.H. Mohring, Algorithmic aspects of the substitution decomposition 
in optimization over relations, set systems and boolean functions, Ann. 
Oper. Research 4 (1985/6), 195 - 225. 
R.H. Mohring and F.J. Radermacher, Substitution decomposition for dis- 
crete structures and connections with combinatorial optimization, Ann. 
Discrete Math. 19 (1984), 257 - 356. 
J.H. Muller and J. Spinrad, Incremental Modular Decomposition, J. of 
the ACM 36 (1989), 1 - 19. 
J.J. Rotman, “The Theory of Groups: An Introductionff, Allyn and Ba- 
con, Boston, 1973. 
L.S. Shapley, Solutions of compound simple games, in “Advances in 
Game Theory”, Annals of Math. Study 52, Princeton Univ. Press, 1964, 
J.H. Schmerl and W. T. Trotter, Critically indecomposable partially or- 
dered sets, graphs, tournaments and other binary relational structures, 
Discrete Math. 113 (1993), 191 - 205. 
J.J. Seidel and D.E. Taylor, Two-graphs, a second survey, in “Proc. In- 
ternat. Colloq. on Algebraic Methods in Graph Theory”, Szeged, 1978. 
D.P. Sumner, Graphs indecomposable with respect to the X-join, Dis- 
crete Math. 6 (1973), 281 - 298. 
H.P. Yap, “Some Topics in Graph Theory”, Cambridge University Press, 
Cambridge, 1986. 
T. Zaslavsky, Characterization of signed graphs, J. Graph Theory 5 
T. Zaslavsky, Signed graphs, Discrete Appl. Math. 4 (1982), 47 - 74: 
erratum 5 (1983), 248. 
267 - 305. 
(1981), 401 - 406. 

Chapter 7 
PROGRAMMED GRAPH 
REPLACEMENT SYSTEMS 
A. SCHURR 
Lehrstuhl fur Informatik 111, RWTH-AACHEN, 
Ahornstr. 55, 0-52074 Aachen, Germany 
e-mad: andy9i3. informatik. rwth-aachen. d e  
Various forms of programmed graph replacement systems as extensions of context- 
sensitive graph replacement systems have been proposed until today. They differ 
considerably with respect to their underlying graph models, the supported forms 
of graph replacement rules, and offered rule regulation mechanisms. Some of them 
have additional constructs for the definition of graph schemata, derived graph 
properties, and so forth. It is rather difficult to develop precise and compact de- 
scriptions of programmed graph replacement systems, a necessary prerequisite for 
any attempt to compare their properties in detail. Programmed Logic-based Struc- 
ture Replacement (PLSR) systems are a kind of intermediate definition language 
for this purpose. They treat specific graph classes as sets of predicate logic formulas 
with certain properties, so-called structures. Their rules preserve the consistency of 
manipulated structures and use nonmonotonic reasoning for checking needed pre- 
and postconditions. So-called Basic Control Flow (BCF) expressions together with 
an underlying fixpoint theory provide needed means for programming with rules. 
This chapter introduces first the basic framework of PLSR systems and studies af- 
terwards the essential properties of context-sensitive graph replacement approaches 
themselves as well as popular rule regulation mechanisms. 
Contents 
7.1 
Introduction . . . . . . . . . . . . . . . . . . . . . . . .  
481 
7.2 Logic-Based Structure Replacement Systems . . .  484 
7.3 Programmed Structure Replacement Systems . . 505 
7.4 
Context-sensitive Graph Replacement Systems - 
Overview . . . . . . . . . . . . . . . . . . . . . . . . . .  
519 
7.5 Programmed Graph Replacement Systems - 
Overview . . . . . . . . . . . . . . . . . . . . . . . . . .  
530 
References . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
541 
479 


7.1. INTRODUCTION 
481 
7.1 Introduction 
The history of graph replacement systems starts 25 years ago with two seminal 
papers about so-called “web grammars” [55] and “Chomsky systems for partial 
orders” [62]. From the beginning graph replacement systems have been used 
and developed to solve “real world” problems in the fields of computer science 
itself, biology, etc. [1,52]. One of the first surveys about graph replacement 
systems [45] (and its short version in [46]) distinguishes three different types 
of applications: 
(1) Describing or generating known languages of graphs which have for in- 
stance certain graph-theoretical properties or model growing plants. 
(2) Recognizing languages of graphs which model for instance the underlying 
logical structure of natural language sentences or scanned images and 
office documents. 
(3) Specifying new classes of graphs and graph transformations which rep- 
resent for instance databases and database manipulations or software 
documents and document manipulating tools. 
For solving problems in the first category pure graph replacement systems are 
often sufficient and accompanying tools are not urgently needed. The second 
category of problems requires classes of graph replacement systems which are 
powerful enough to describe interesting languages of graphs, but which are 
restricted enough so that efficiently working parsing or execution tools can be 
realized. The design of adequate classes of graph replacement systems is still 
subject of ongoing research activities and outside the scope of this paper (cf. 
Section 2.7 of Chapter 2 in this volume as well as [24] and [58]). 
The third category of problems needs graph replacement systems as a kind 
of executable specification or even very high level programming language. In 
order to be able to fulfil the resulting requirements, many new concepts had to 
be added to “pure” first generation graph replacement systems (see [all and 
especially [7] for a discussion of needed extensions). One of the most important 
extensions was the introduction of new means for controlling the application 
of graph replacement rules. This lead to the definition of programmed graph 
replacement systems, which are the main topic of this contribution. 
7.1.1 
For historical reasons mainly, almost all earlier proposals for programmed 
graph replacement systems [11,12,23,28,38,45,64] belong to one of the main 
branches of graph replacement systems, the algorithmic, set-theoretic approach 
(cf. Chapter 1 and 2 of this volume), and not to the algebraic, category-theory 
Programmed Graph Replacement Systems in Practice 

482 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
approach (see Chapter 3 and 7 of this volume). Until now, two complete imple- 
mentations of programmed graph replacement systems have been built. The 
first one, Programmed Attributed Graph Grammars (PAGG), was mainly 
used for specifying graph editors and CAD systems [26,27,28]. The second one, 
PROgrammed Graph REplacement Systems (PROGRES) , is tightly coupled 
to the development of software engineering tools [53,65,66,76]. PROGRES and 
its predecessors were and are used within the project IPSEN for specifying in- 
ternal data structures and tools of Integrated Project Support ENvironments 
[21,22,47,48]. At the beginning, pure algorithmic graph replacement systems 
were used [45]. But soon it became evident that additional means for defin- 
ing complex rule application conditions, manipulating node attributes etc. are 
needed. Appropriate extensions were suggested in [23] and later on in [38]. But 
even then there was no support for 
separating the definition of static graph integrity constraints from dy- 
namic graph manipulating operations as database languages separate the 
definition of database schemata from the definition of database queries 
or manipulations, 
specifying derived attributes and relations in a purely declarative manner 
in a similar style as attribute tree grammars or relational languages deal 
with derived data, 
and solving typical generate and test problems by using implicitly avail- 
able means for depth-first search and backtracking in the same manner as 
Prolog deals with these problems. 
Therefore, various extensions of graph replacement systems were studied which 
resulted finally in the development of the programming language PROGRES 
and its integrated programming support environment P 
7.1.2 
To produce a formal definition of programmed graph replacement systems like 
PAGG or PROGRES by means of set theory only is a very difficult and time- 
consuming task. Especially the definition of control structures, derived graph 
properties, and graph schemata constitutes a major problem. And switching 
from set theory to the formalism of category theory does not solve it at all. 
Both the category-based Double Push Out (DPO) approach (cf. Chapter 3 of 
this volume) and the Single Push Out approach (cf. Chapter 7 of this volume) 
have about the same difficulties with the definition of integrity constraints, 
derived information, and the like. 
Programmed Graph Replacement Systems an Theory 

7.1. INTRODUCTION 
483 
Therefore] it was necessary to establish another framework for the formal def- 
inition of these application-oriented graph replacement systems. The following 
observations had a major influence on the development of this framework: 
a Relational structures are an obvious generalization of various forms of 
graphs or hypergraphs [44]. 
a Logic formulas are well-suited for defining required properties of gener- 
ated graph languages (cf. Chapter 9 of this volume) 
a Nonmonotonic reasoning is appropriate for inferring derived data and 
verifying integrity constraints in deductive database systems [43,54]. 
a Fixpoint theory is the natural candidate for defining the semantics of 
partially defined, nondeterministic, and recursive graph replacement pro- 
grams [41,51]. 
Combining these sources of inspiration, first logic-based graph replacement sys- 
tems were developed and used to produce a complete definition of the language 
PROGRES [66]. Later on they were generalized to Logic Based Structure 
Replacement (LBSR) systems [67] and Programmed Logic-based Structure 
Replacement (PLSR) systems [68]. 
7.1.5’ Contents of the Contribution 
The presentation of LBSR and PLSR systems over here as well as a survey of 
application-oriented and/or programmed context-sensitive graph replacement 
systems is organized as follows: 
a Section 7.2 introduces LBSR systems and demonstrates how they may 
be used to specify graph schemata] schema consistent graphs as well as 
consistency preserving graph transformations. 
a Section 7.3 presents a basic set of control structures for programming 
with graph replacement rules together with a denotational semantics 
definition based on fixpoint theory. Using these control structures, LBSR 
systems are extended to PLSR systems. 
a Section 7.4 compares typical representatives of application-oriented al- 
gorithmic graph replacement systems and sketches their translation into 
LBSR systems. Furthermore it discusses their relationships to the DPO 
and SPO families of algebraic approaches. 
a Section 7.5 finally surveys a collection of currently popular rule regulation 
mechanisms and translates them into basic control structures of PLSR 
systems. 
Other topics, like the design of a readable syntax and a static type system 
for the language PROGRES or the implementation of tools which support 

484 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
programming with graph replacement systems, are outside the scope of this 
volume [65,66,68]. 
7.2 
Logic-Based Structure Replacement Systems 
Nowadays, a surprisingly large variety of different graph replacement for- 
malisms is existent. Some of them have a rather restricted expressiveness and 
are well-suited for proving properties of generated graph languages. Some of 
them are very complex and mainly used for specification and rapid prototyp- 
ing purposes. Even their underlying graph data models differ to a great extent 
with respect to the treatment of edges, attributes, etc. 
In order to be able to reason about differences or common properties of these 
graph replacement approaches and their underlying data models in Section 7.4, 
a general framework is urgently needed. Such a framework has to provide 
proper means for the definition of specific graph models and graph replacement 
approaches. One attempt into this direction, so-called High Level Replacement 
(HLR) systems, is based on the construction of categories with certain prop- 
erties [ 181. It generalizes algebraic graph replacement approaches and incorpo- 
rates algebraic specification technologies for the definition of attribute domains 
(see also [34,39]). Until now, HLR systems still have problems with formalizing 
derived graph properties or graph integrity constraints as they are used within 
the graph grammar specification language PROGRES. 
Therefore, another generic framework was developed which comprises many 
different graph replacement systems as special cases and which is the underly- 
ing formalism of the specification language PROGRES. It combines elements 
from algorithmic and algebraic graph replacement systems with elements from 
deductive database systems. The outcome of the cross-fertilization process, 
Logic-Based Structure Replacement (LBSR) systems, are the topic of this 
section. 
The formalism of LBSR systems is not intended to be directly used as a spec- 
ification language, but provides the fundament for the definition 
0 of specific graph models as special cases of relational structures 
and of a whole family of accompanying graph replacement notations. 
The presentation of LBSR systems over here will be accompanied by a number 
of examples, which sketch how human-readable graph grammar specifications 
written in a PROGRES like notation may be translated into them. By means 
of these examples the reader will hopefully understand how LBSR systems may 
be used to define the semantics and compare the intended behavior of specific 
graph replacement systems. 

7.2. LOGIC-BASED STRUCTURE REPLACEMENT SYSTEMS 
The rest of this section is organized as follows: 
485 
Subsection 7.2.1 repeats some basic terminology of predicate logic and 
contains the formal definition of (relational) structures and structure 
schemata as sets of formulas. 
Subsection 7.2.2 deals with substructure selection, i.e. finding matches for 
left-hand sides of rules with additional application conditions. 
Subsection 7.2.3 introduces then the structure replacement formalism it- 
self. 
Subsection 7.2.4 finally summarizes the main properties of LBSR systems 
and their relationships to approaches like HLR systems. 
F t - -  
i:5000 
-+ 
+ 
0 
1:10000 
-T 
c3 
I 5000 
I100 
i 3000 
I2000 
wife edge 
child edge 
man node 
woman node 
income has 
value n 
Figure 7.1: The running example, a person database 
Within all these subsections we will use a coherent running example drawn from 
the area of deductive database systems. It is the specification of a graph-like 
person database and includes the definition of derived relationships, integrity 
constraints, and complex update operations (Figure 7.1 displays a sample data- 
base). 
7.2.1 
This subsection introduces basic terminology of predicate logic. Furthermore, it 
explains modeling of node and edge labeled graphs as special cases of schema 
consistent structures, i.e. as sets of formulas with certain properties. After- 
wards, our running example of a person database will be modeled as a directed 
graph. In this way, we are able to demonstrate that graphs are a special case 
of structures and that graph replacement is a special case of structure replace- 
ment. Nevertheless, all definitions and propositions of the following sections 
are independent of the selected graph model and its encoding. 
Structure Schemata and Schema Consistent Structures 

486 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
Definition 7.2.1 (Signature.) 
A 5-tuple C := (AF, 
A p ,  V ,  W ,  X) is a signature if 
(1) AF is an alphabet of function symbols 
(2) dp is an alphabet of predicate symbols? 
(3) V is a special alphabet of object identifier constants. 
(4) W is a special alphabet of constants representing sets of objects. 
(5) X is an alphabet of logical variables used for quantification purposes. 
(including constants). 
The signature definition above introduces names for specific objects and sets of 
objects as special constants. These constants will play an important role for the 
selection of LBSR rule matches. Elements of V in a rule’s left-hand side denote 
and match single objects of a given structure, whereas elements of W denote 
and match sets of objects of a given structure. Please note that W is not an 
alphabet of logical set variables, i.e. we do not use a monadic second order logic 
as in Chapter 9 of this volume. Quantification over set variables is needed for 
the definition of many graph-theoretic properties, but not a strict neccessity for 
the formal definition of graph replacement formalisms studied over here. Hence 
we will use a first order logic which makes no distinction between constant 
symbols in AF (functions of arity 0), V ,  and W .  Nevertheless, it is necessary 
to distinguish these three different kinds of constants within Subsection 7.2.2 
and 7.2.3, where they play very different roles for the application of structure 
replacement rules. 
The signature of the following example may be used for the definition of person 
databases, or more precisely, their graph representations as sets of formulas. 
Figure 7.1 above presents such a graph representation of a database with twelve 
persons. Each person is either a man node or a woman node. Both man and 
woman nodes may be sources or targets of child edges, whereas wife edges 
always have a man as source and a woman as target. Furthermore, each person 
has an integer-valued income attribute. 
Example 7.1 (Signature for a Person Database.) 
The graph signature for fig. 7.1 is C := (dF,dp,V,W,X) with: 
(1) AF := { child, woman, wife, man, person, income, integer, 0, . . . , + }. 
(2) dp := { node, edge, attr, type, .. . } . 
(3) V := { He, She, Value, ... } . 
(4) W := { HerChildren, HisChildren, . . . } . 
(5) X := { xl, x2, . . . } . 
0 
bA family of alphabets of symbols if we take domain and range of functions into account. 
=A family of alphabets of symbols if we take arities of predicates into account. 

7.2. LOGIC-BASED STRUCTURE REPLACEMENT SYSTEMS 
487 
The alphabets V ,  W ,  and X above are sets of arbitrarily chosen constant or 
variable names. The set dp, on the other hand, contains just all needed symbols 
for node labels, edge labels, attribute types, attribute values, and evaluation 
functions. 
The alphabet dp, finally contains four predicate symbols which are very im- 
portant for the more or less arbitrarily selected encoding of directed, attributed 
graphs, where each node has a distinct class as its label and where any attribute 
value has a designated type. They have the following interpretation: 
0 node(x, 1): graph contains a node x with label I ,  
0 edge(x, e, y): graph contains edge with label e from source z to target y, 
0 attr(x, a, v): attribute a at node x has value o, 
0 type(v, t): attribute value o has type t. 
In the sequel, we will always assume that C is a signature over the above 
mentioned alphabets. 
Definition 7.2.2 (C-Term und C-Atom.) 
7 x ( C )  is the set of all C-terms (in the usual sense) which contain function 
symbols and constants of dp, free variables of X, 
and additional identifier 
symbols of V and W .  d ( C )  is the set of all atomic formulas (C-atoms) 
over 7;c(C) which contain predicate symbols of dp and “=” for expressing the 
equality of two C-terms. Finally T ( C )  C Tx(C) is the set of all those terms 
which do not contain any symbols of X, 
V ,  and W ,  i.e. do not have variables 
or object (set) identifiers as their leafs. 
Definition 7.2.3 (C-Formula and Derivation of C-Formulas.) 
F(C) is the set of all sets of closedd first order predicate logic formulas (C- 
formulas) which have d ( C )  as atomic formulas, A, V, . . . as logical connec- 
tives, and 3,V as quantifiers. Furthermore with @ and @’ being sets of C- 
formulas, 
means that all formulas of @’ are derivable from the set of formulas @ using 
any (consistent and complete) inference system of first order predicate logic 
with equality. 
In the following, elements of F(C) will be used to represent structures, struc- 
ture schemata, schema consistent structures, and even left- and right-hand 
sides as well as pre- and postconditions of structure replacement rules. 
@ k @‘ 
dRequiring bindings for all logical variables (by means of existential or universal quan- 
tification) does not restrict the expressiveness of formulas but avoids any difficulties with 
varying treatments of free variables in different inference systems. 

488 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
Definition 7.2.4 (C-Structure.) 
A set of closed formulas F E F(C) is a C-structure (write: F E C(C)) :H 
F C d(C) and F does not contain formulas of the form “TI = ~ 2 ” .  
Example 7.2 (A Person Database Structure.) 
The following structure is a set of formulas which has the graph F of figure 7.1 
as a model: 
F := { node(Adam, man), node(Eve, woman), node(Sally, woman), . . . , 
attr(Adam, income, 5000), attr(Eve, income, lOOOO), . . . , 
edge(Adam, wife, Eve),edge(Eve, child, Sally), . . . }. 
0 
The set of formulas F has many different graphs as models. One of those 
models is the graph of Figure 7.1, but there are many others in which we are 
not interested in. Some of them may contain additional nodes and edges, and 
some use different identifiers like Eve and Sally for the same graph node. In 
Definition 7.2.5, we will introduce a so-called completing operator, which allows 
us to get rid of unwanted (graph) models of C-structures and to reason about 
properties of minimal models on a pure syntactical level. Therefore, models of 
structures are not introduced formally and will not be used in the sequel. 
The following example demonstrates our needs for a completing operator in 
more detail. It presents the definition of a single person database and explains 
our difficulties to prove that this database contains indeed one person only. A 
related problem has been extensively studied within the field of deductive data- 
base systems and has been tackled by a number of quite different approaches 
either based on the so-called closed world assumption or by using nonmonotonic 
reasoning capabilities (cf. [42,49,50]). The main idea of (almost) all of these 
approaches is to distinguish between basic facts and derived facts and to add 
only negations of basic facts to a rule base, which are not derivable from the 
original set of facts. 
It is beyond the scope of this chapter to explain nonmonotonic reasoning in 
more detail. Therefore, we will simply assume the existence of a completing 
operator C which adds a certain set of additional formulas to a structure. The 
resulting set of formulas has to be consistent (it may not contain contradic- 
tions) and suficiently complete such that we can prove the above mentioned 
properties by using the axioms of first-order predicate logic only. 
Definition 7.2.5 (C-Structure Completing Operator.) 
A function C : C(C) + F(C) is a C-structure completing operator :@ 
For all structures F E C(C) : F 
C(F) and C(F) is a consistent set of formulas 
and C(P(F)) = P(C(F)) 

7.2. LOGIC-BASED STRUCTURE REPLACEMENT SYSTEMS 
489 
with p : F(C) + 3 ( C )  being a substitution which renames object identifiers of 
V and object set identifiers of W in F without introducing name clashes; i.e. 
consistent renaming of identifiers and completion of formula sets are compatible 
operations. 
The identity operator on sets of formulas (structures) is one trivial example 
of a completion operator. Any given structure is a set of atomic formulas and, 
therefore, free of contradictions. Furthermore, all inference systems of predicate 
logic (should) have the property that consistent renaming of constants does 
not destroy constructed proofs. Hence, we will not have any troubles with the 
requirement above that renaming and completion are compatible. 
A useful example of a completion operation is the union of a given set of basic 
facts F with all derivable facts and a carefully selected subset of negated non- 
derivable facts like “a graph does not contain a node with a name unequal to 
Adam” in Example 7.3. Please note that we will need an additional set of for- 
mulas for being able to derive new facts from the atomic formulas of structures. 
This set of first order formulas is part of the following Definition 7.2.6. 
Example 7.3 (Nonmonotonic Reasoning.) 
The singleton set F := {node(Adam, man)} is a structure which has all graphs 
containing at least one man node as models. Being interested in properties of 
minimal F graph models only, we should be able to prove that F contains 
a single node. For this purpose, the operator C has to be defined as follows 
(omitted sets of formulas deal with edges etc.): 
C(F) := F U  ... U 
{Vz,Z : node(z, 1 )  + (z = v1 V . . . V z = wk) I vl,. . . , v k  E V 
C(F) I- (Vx, 1 : node(z, 1 )  -+ 2 = Adam) A node(Adam, man). 
are all used object ids in F}. 
0 
Now, we are able to prove that F contains only the male node Adam: 
Completing operators may have definitions which are specific for a regarded 
class of structures. Therefore, they are part of the following definition of struc- 
ture schemata: 
Definition 7.2.6 (C-Structure Schema.) 
A tuple S := (@,C) is a C-structure schema (write: C E S(C)) :H 
(1) @ E F(C) is a consistent set of formulas without references to specific 
object (set) identifiers of V or W (it contains integrity constraints and 
derived data definitions). 
(2) C is a C-structure completing operator. 

490 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
Definition 7.2.7 (Schema Consistent Structure.) 
Let S := (CP,C) E S(C) be a schema. A C-structure F E L(S) is schema 
consistent with respect to S (write: F E C(S)) :e 
C(F) u CP is a consistent set of formulas. 
The definition of schema consistency is very similar to a related definition of 
the knowledge representation language Telos [42]. It states that a structure 
is inconsistent with respect to a schema, if and only if we are able to derive 
contradicting formulas from the completed structure and its schema. 
The following example is the definition of a person database schema. Its set of 
formulas CP consists of three subsets: 
0 A first subset defines integrity constraints for the selected graph data 
model and excludes dangling edges and attributes of nonexisting nodes. 
0 The second subset contains all person database specific integrity con- 
straints, like “man and woman nodes are also person nodes”. 
0 The last subset deals with a number of derived graph properties like the 
well-known ancestor relation or the definition of the brother of a child. 
Example 7.4 (A Schema for Person Databases.) 
A structure schema S := (@,C) for graph F in Fig. 7.1 has the following form: 
@ := {Vz, e, y : edge(z, e ,  y) + 3x1, yl : node(z, 21) A node(y, yl), 
Vx,u,v : attr(z,u,v) -+ 31 : node(z,l), . . . } 
Vx : node(z, woman) t 
node(z, person), 
Vx, y : edge(z, wife, y) -+ node(z, man) A node(y, woman), 
Vx, y, z : edge(z, wife, y) A edge(z, wife, z )  -+ y = z ,  
Vz, y, z : edge(z, wife, z )  A edge(y, wife, z )  -+ z = y, 
Vx, 
w : attr(z, income, v) -+ type(v, integer), 
Vz : node(z, person) t 
3v : attr(z, income, w), . . . } 
U {Vz : node(z, man) -+ node(z, person), 
U {Vz, y : ancestor(z, y) +) (32 : edge(z, child, z) 
A ( z  = y V ancestor(z, y)), 
A node(y, man) A z # y,. . .}. 
Vz, y : brother(z, y) tf 32 : edge(z, child, z) A edge(z, child, y) 
C(F) : = F U  . . . 
0 
Figure 7.2 displays the corresponding PROGRES like specification of these 
graph properties. The first three declarations establish a node class hierarchy 

7.2. LOGIC-BASED STRUCTURE REPLACEMENT SYSTEMS 
491 
with person being the root class and man as well as woman being its subclasses. 
All nodes labeled with these classes have an income attribute. The following two 
declarations introduce child and wife edges and constrain the labels (classes) 
of their source and target nodes. Furthermore, the [0:1] annotations within the 
wife edge declaration even require that any man node has at most one outgoing 
wife edge and that any woman node has at most one incoming edge of this type. 
Finally, two derived binary relations are declared, so-called paths, which define 
the well-known concepts ancestor and brother. The ancestors of a person are 
determined by evaluating +child- &(self or ancestor) as follows: 
0 Compute the parents of a given person as the set of all sources of incoming 
0 Afterwards (& concatenates two subexpressions), return the union (or) 
child edges (+child- traverses child edges in reverse direction). 
of all parents (self) and their ancestors. 
The brothers of a person are computed by 
0 determining first all its parents (+child-), 
0 finding then all male children (-child+ & instance of man), 
0 and eliminating finally the person itself from the result (but not self). 
node c l a  person; 
d; 
node class man 
node class woman & person 
- 
child: person --f person ; 
-wife: 
man [0:1] --f woman [0:1] ; 
Q& ancestor: person -+ person = 
attribute income: inteaer ; 
person & ; 
; 
+child- 
& (Ma ancestor) 
md; 
Q& 
brother: person --f man = 
( +child- 
& -child-+ & instance of man ) 
but not self 
.a; 
Figure 7.2: Excerpt from a PROGRES graph schema definition 
In this way PROGRES allows its users to define complex graph schemata with 
elaborate integrity constraints as well as derived relationships (and attributes). 
The translation of these schema definitions into sets of formulas is always as 

492 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
straightforward as in the presented example above. All forthcoming rules of 
LBSR systems have to observe these integrity constraints, i.e. transform one 
schema consistent structure (graph) into another one. Furthermore, they may 
access derived information within pre- and postconditions. 
Please note that it is not possible to construct a structure replacement ma- 
chinery, where checking of integrity constraints or pre- and postconditions is 
guaranteed to terminate. It depends on the selected nonmonotonic reasoning 
strategy (the implementation of a programmed graph replacement approach) 
whether certain types of constraints are prohibited or lead a rule application 
process into an infinite loop. We will reconsider the termination problem later 
on in section 7.3 together with the fixpoint semantics definition for potentially 
nonterminating control structures. 
7.2.2 Substructures with Additional Constraints 
This subsection formalizes the term “rule match under additional constraints” 
by means of morphisms. This term is central to the definition of structure re- 
placement with pre- and postconditions, which follows afterwards. It determines 
which substructures of a structure are legal targets for a structure replacement 
step, i.e. match a given rule’s left-hand side. The main difficulty with the defi- 
nition of the new structure replacement approach was the requirement that it 
should include the expression oriented algorithmic graph grammar approach 
[45]. This approach has very powerful means for deleting, copying, and redi- 
recting arbitrary large bundles of edges. 
We will handle the manipulation of edge bundles by introducing special object 
set identifiers on a structure replacement rule’s left- and right-hand side. These 
set identifiers match an arbitrarily large (maximal) set of object identifiers 
(see Example 7.6 and Definition 7.2.15). As a consequence, mappings between 
structures, which select the affected substructure for a rule in a structure, 
are neither total nor partial functions. In the general case, these mappings 
are relations between object (set) identifiers. These relations are required to 
preserve the properties of the source structure (e.g. a rule’s left-hand side) while 
embedding it into the target structure (the structure we have to manipulate) as 
usual and to take additional constraints for the chosen embedding into account. 
Another problem comes from the fact that we have to deal with attributes, i.e. 
LBSR rules must be able to write, read, and modify attribute values in the 
same way as they are able to manipulate structural information. Therefore, it 
is not sufficient to map object (set) identifiers onto (sets of) object identifiers, 
but we need also the possibility to map them onto (sets of) attribute value 
representing C-terms. 

7.2. LOGIC-BASED STRUCTURE REPLACEMENT SYSTEMS 
493 
Definition 7.2.8 (C-Term Relation.) 
Let F, F’ E F(C) be two sets of formulas which have VF WF and V p  , W p  as 
their object (set) identifiers. Furthermore] T ( C )  is the set of all variable and 
object identifier free C-terms (cf. Def. 7.2.2). A relation 
is a C-relation from F to F’ :H 
u 2 ( V F  x (VF’ u 7(C))) u ( W F  x ( W F J  u VF’ u 7(C))) 
(1) For all w E VF : Iu(v)I = 1 with u(x) := {yl(x,y) E u}] 
i.e. every object identifier will be mapped onto a single object identifier 
or onto a single attribute value representing C-term. 
i.e. every object set identifier will be mapped either onto another ob- 
ject set identifier or onto a set of object identifiers or attribute value 
representing C-terms. 
(2) For all w E W F  : 1u(w)1 = 1 or u(w) C_ V p  or u(w) C 7(C), 
The definition above introduces relations between object (set) identifiers and 
(sets of) C-terms only. Their extensions to relations between arbitrary formulas 
are defined as follows: 
Definition 7.2.9 (C-Relation.) 
Let u be a C-term relation according to Definition 7.2.8. The extension u’ of 
u to the domain of C-formulas is called C-relation and defined as follows: 
u*($, 
4’) :H 3+ E F(C) with free variables x1,. . . x, 
but without any V or W identifiers 
34,. 
. . ,v, E V U W with wi # vj for i , j  E (1,. . . ] n }  
371, ... , T , E V U W U T ( C )  withu(v1,q) ,... l u ( v n , ~ , ) :  
A 
A 
dJ = + , [ ~ l / ~ l , .  
. . 1 ~ 7 J ~ n I  
A 4’ = +[Tl/Zl,. . . 1 - r , / ~ , 3 . e  
Furthermore] with 
sequel: u*(@) := (4’ E F(C) I 4 E @ and (4]4’) E u’}. 
The definition of u* above simply states that two formulas dJ and 4’ are related 
to each other if they differ with respect to u-related terms only. Any object 
identifier w in dJ must be replaced by the uniquely defined u(w) in 4’. Any 
object set identifier w in 4 must be replaced by some element u(w) 
in 4‘ such 
that all occurrences of w in 4 get the same substitute. 
Based on these relations between formulas] we are now able to define mappings 
(morphisms) between sets of formulas or structures which preserve certain 
properties. 
C F(C)] the following short-hand will be used in the 
[PI /xi,. . . , pn/xn] denotes consistent substitution of any xi by its corresponding pi. 

494 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
Definition 7.2.10 (C-(Structure-)Morphism.) 
Let F, F’ E F(C). 
A C-relation u from F to F’ is a C-morphism from F to 
F’ (write: u : F < F’) :H F’ t- u*(F). 
With F, F’ E C(C) F(C) being C-structures, u will be called C-structure 
morphism. 
The definition of a morphism u : F 
u*(F) is a subset of F’, as in the following example: 
F’ requires in the simplest case that 
Example 7.5 (A Simple Structure Morphism.) 
Let F’ be the structure of Example 7.2 which represents the graph of Figure 7.1 
and 
F 
:= {node(He, man), node(She, woman), 
attr(She, income, Value), edge(He, wife, She), 
edge(He, child, HisChildren), edge(She, child, HerChildren)} 
with He,She,Value E V ,  and HisChildren, Herchildren E W .  
There are two %relations from F to F‘ which are structure morphisms: 
u := { 
(HerChildren, Hannah), (HerChildren, Charlie), (HerChildren, Fred), 
u’ := { 
(HerChildren, Sally), (HerChildren, Andy), 
(He, Andy), (She, Maggie), (Value, SOOO), (HisChildren, Hannah)}, 
(He, Adam), (She, Eve), (Value, 10000)). 
0 
The selected examples of morphisms show that two different object (set) identi- 
fiers in F may be mapped onto the same object identifier in F’ (unless explicitly 
prohibited by means of additional formulas). Furthermore, an object set iden- 
tifier may be mapped onto an arbitrarily large set of identifiers (terms), with 
the empty set being a permitted special case. In the sequel, we will show that 
morphisms between structures define a transitive, reflexive., and associative 
relation, i.e. they build a category. 
Proposition 7.2.11 (The Category of C-Structures.) 
Assume “0” to be the usual composition of binary relations. Then, 3 ( C )  
together with the family of C-morphisms defined above and “0” is a cate- 
gory; the same holds true for the set of C-structures C(C) and the family of 
C-structure morphisms. 

7.2. LOGIC-BASED STRUCTURE REPLACEMENT SYSTEMS 
495 
Proof: 
(1) C-Morphisms are closed w.r.t. “o”, i.e. 
u and u’ are C-relations J D ~ ~  
7.2.8 (u 
o u’) is a C-relation and 
u, 
u’ are morphisms 
J D e f .  7.2.10 F’ k u*(F) and F” t u’*(F’) 
u : F 7 
F’, u‘ : F‘ 7 
F“ 3 (u 
o u’) 
: F 7 
F“: 
Def, 7.2.9 (u 
0 U’)* = u* 
0 u’*. 
F’ I- U*(F) *subst. preservesproofs u’*(F’) .’*(U*(F)) = (.o.’)*(F) 
*modus ponens 
F” I- (u 
o U’)*(F)~ 
i.e. (u 
0 u’) 
is a morphism from F to F“. 
Obviously, the relation idF, which maps any object (set) identifier in F 
onto itself, is a neutral element for the family of C -relations. Then, 
i.e. i d F  is the required neutral morphism. 
Follows directly from the fact that “o” is associative for binary relations. 
In order to obtain the proof that the family of C-structure morphisms together 
with C(C) and “0” is a category we simply have to replace any F(C) above by 
(2) Existence of neutral C-morphism i d F  for any F E .F’(c): 
idg(F) = F 3 F F idfF(F) *  id^ : F 7 
F ,  
(3) Associativity of “0” for C-morphisms: 
C W .  
0 
Definition 7.2.12 (Substructure.) 
F, F’ E C(C) are structures. F is a substructure of F’ with respect to a 
C-relation u (write: F (IzL 
F’) :@ u : F 
This definition coincides with the usual meaning of a homomorphic f substruc- 
ture (or subgraph), if F does not contain any object set identifiers. 
F’. 
F’ 
‘2 
Qu C(F’) 4 
Figure 7.3: Substructure selection with additional constraints 
f“homomorphic” means that different object identifiers in F may be mapped onto the 
same object identifier in F‘. 

496 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
Proposition 7.2.13 (Soundness of Substructure Property.) 
For F, F’ E C(C) being structures, the following properties are equivalent: 
F is a substructure of F’ with respect to a C-relation u 
w u*(F) is a subset of F’. 
Proof: 
F Cu F’ W D e f .  7.2.12 ’11 : F 
F’ 
*Def 
7.2.10 F’ t- u*(F) w u * ( F ) , F ’ E L ( C )  u*(F) c F‘. 
The last step of the proof follows from the fact that F and F‘ are sets of atomic 
formulas without “=”, such that 
(normal set inclusion) and t are equivalent 
relations. 
0 
Definition 7.2.14 (Substructure with Additional Constraints.) 
S := (ip,C) is a C-structure schema, F, F’ E C(C), and P E F(C) is a set 
of constraints with references to object (set) identifiers of F only. F is a con- 
strained substructure of F’ with respect to a C-relation u and the additional 
set of constraints P (write: F &\II F’) :W 
(1) F C, F’, i.e. F’ t- u*(F). 
(2) u : @ U F ~ @ u C ( F ’ ) , i . e .  
ipuC(F’)tu*(X€JUF) 
=u*(X€J)Uu*(F). 
These conditions are equivalent to the existence of the diagram in Figure 7.3, 
with inclusions il and i 2  being morphisms, which map any object (set) identifier 
onto itsgf 
il : F + X€JU F ,  
iz : F’ 7 
since i;(F) = F C 9 U F ,  i.e. 9 U F t- i;(F). 
since ia(F’) = F’ & C(F’), i.e. CP U C(F’) t- i;(F‘). 
U C(F’), 
Informally speaking, a structure F is a substructure of F’ with respect to 
additional constraints, if and only if we are able to prove that all constraints 
for the embedding of F in F’ are fulfilled. We may use the basic facts of F’ 
including all formulas generated by the completing operator C and the set of 
formulas ip of the structure schema S for this purpose. 
Findcouple = 
She :woman 
I Hischildren : person I I 
L - - _ _ - _ -  
JJ 
Gondition He.income < She.inmme; 
I Hechildren : person I I 
L - - - - - - -  JJ 
and 
Figure 7.4: A subgraph test written in PROGRES 

7.2. LOGIC-BASED STRUCTURE REPLACEMENT SYSTEMS 
497 
Example 7.6 (Substructure Selection.) 
Let S := ((a,C) be the schema of Example 7.4 and F’ the database of Ex- 
ample 7.2. The structure F € L(C) and its accompanying set of constraints 
Q E F(C), defined below, represent the PROGRES like subgraph test of Fig- 
ure 7.4 “select any pair of unmarried persons and all their children, who are 
not brother and sister and have appropriate income values together with all 
their children” : 
F 
:= {node(He, man), node(She,woman), 
attr(He, income, Hisvalue), attr(She, income, Hervalue), 
edge(He, child, HisChildren), edge(She, child, HerChildren)}. 
Q 
:= {Tbrother(She, He), 132 : edge(He, wife, x), 732 : edge(z, wife, She), 
HisValue < Hervalue, 
node(HisChildren, person), node( HerChildren, person)}. 
Remember that He, She, and Value are object identifiers, whereas HisChildren 
and HerChildren are object set identifiers (cf. Example 7.1). Therefore, the 
following definition 
u := {(He, Harry), (She, Sally), (Hisvalue, lOOOO), (Hervalue, 20000), 
(HisChildren, Linus), (HisChildren, Clio), 
(HerChildren, Clio), (HerChildren, Mary)} 
is a correct C-relation for F in F’ with F Cu,q F‘, since u*(F) C F‘ and 
thereby F C, F’. 
Furthermore, we can assume that the completing operator C generates formulas 
by means of which we are able to prove that 
0 Harry is not the target of a child-edge and, therefore, not the brother of 
0 Harry is not the source of a wife-edge, and 
0 Sally is not the target of a wife-edge. 
Sally (cf. definition of brother in Example 7.4) 
Next, HisValue is bound to 10000 and HerValue is bound to 20000, i.e. the 
attribute condition HisValue < HerValue is valid. Finally, using the formulas 
of the graph schema of example 7.4 we are able to prove that Linus, Clio, and 
Mary are not only direct members of the classes man and woman, respectively, 
0 
The relation u of Example 7.6 above is even maximal with respect to the 
number of object identifiers in F’ which are bound to set identifiers in F. This 
is an important property of C-relations, which are involved in the process of 
structure rewriting. 
but also members of the class person. 

498 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
7.2.3 Schema Preserving Structure Replacement 
Having presented the definitions of structure schemata, schema consistent 
structures, and structure morphisms, we are now prepared to introduce struc- 
ture replacement rules as quadruples of sets of closed formulas. The application 
of structure replacement rules will be defined as the construction of commut- 
ing diagrams in a similar way as it is done in the algebraic graph grammar 
approach (cf. Chapter 3). But note that we use C-relations instead of (partial) 
functions. Therefore, the main properties of the algebraic approach are neces- 
sarily lost: Our (sub-)diagrams are not pushouts and the application of a rule 
is not invertible in the general case. 
Unfortunately, we had to pay this price for the ability to formalize complex 
rules, which match sets of nodes and are thereby able to delete/copy/redirect 
arbitrarily large edge bundles. 
product ion Marry= rLx,+o 
thecT)3
She : woman 
F------ 
------ 
F----- 
---_--- 
I Hischildren : person I I 
I Herchildren : person I I 
L _ - - - _ _ -  
2 
L - _ _ _ - _ _  2 
wife, 
She : woman 
wife 
I 
I 
I 
I 
Condition He.income c She.income; 
She.income := She.income + taxReduction(She.income); 
end; 
Figure 7.5: A graph replacement rule written in PROGRES 
Definition 7.2.15 (Structure Replacement Rule.) 
A quadruple p := (AL, L, R, AR) with AL, A R  E F(C) and with L, R E C(C) 
is a structure replacement rule (production) for the signature C (write: 
(1) The set of left-hand side application/embedding conditions AL contains 
P E W ) )  
@ 
only object (set) identifiers of the left-hand side L. 

7.2. LOGIC-BASED STRUCTURE REPLACEMENT SYSTEMS 
499 
(2) The set of right-hand side application/embedding conditions AR contains 
only object (set) identifiers of the right-hand side R. 
(3) Every set identifier of L is also a set identifier in R and vice-versa; they are 
only used for deleting dangling references and for establishing connections 
between new substructures created by a rule’s right-hand side and the 
rest of the modified structure. 
The following example defines a structure replacement rule which is based 
on the structure selecting Example 7.6. It marries two persons under certain 
preconditions, whereby each person adopts the other person’s children. The 
corresponding PROGRES like production is displayed in Figure 7.5. 
Example 7.7 (The Structure Replacement Rule Marry.) 
With F and !P defined as in Example 7.6, the structure replacement rule 
Marry := (AL, L, R, AR) has the following form: 
(1) AL := !P . 
(2) L := F . 
(3) R := F \ {attr(She, income, Value)} 
U {edge(He, wife, She), 
attr(She, income, Value + taxReduction(Value)), 
edge(He, child, HerChildren), edge(She, child, HisDaughters)} . 
0 
(4) AR := {} . 
Figure 7.6 displays the result of applying the structure replacement rule Marry 
twice to the database of Figure 7.1. Sally is now married to Harry and Fred to 
Clio. The identifier bindings of the first structure replacement step are shown 
in Example 7.6. In the second structure replacement step, He is bound to Fred 
and She to Clio. Furthermore, all set identifiers of the rule’s left- and right- 
hand side have empty bindings (Fred and Clio have no children). Both steps 
are executed as follows: 
0 Find suitable matches for the object identifiers of L (She and He) in the 
database such that the corresponding preconditions in AL are satisfied. 
0 Extend the selected match to all object set identifiers in L and bind each 
set identifier to a maximal set of objects in the database such that all 
preconditions are valid. 
0 Remove the image of L without the image of R from the database (the 
old income attribute value of the selected She node). 
0 Add an image of R without the image of L to the database (the new 
income attribute value for She, a wife-edge between He and She, and 
child-edges to children nodes). 

500 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
0 Test the postconditions AR. If any postcondition is violated, then cancel 
all modifications, return to the first step of our list, and restart rule 
application with another match. 
0 Finally, test whether the constructed database is schema consistent and 
treat inconsistency like violated postconditions. 
Applications of the rule Marry do not have to worry about postconditions and 
schema inconsistencies. All necessary context conditions are already part of 
the preconditions AL. But we could also move the brother check from the set 
of preconditions AL to the set of postconditions AR. We could even drop the 
“already married” checks in AL, since the schema of Example 7.4 contains 
integrity constraints preventing polygamy. Normally, integrity constraints are 
used instead of repeated postconditions, and postconditions for new objects in 
R \ L replace very complex preconditions. It is still an open question, how 
any set of postconditions (referencing for instance derived properties of new 
objects) may be transformed into an equivalent set of preconditions. 
0 
rnannode 
0 
womannode 
Figure 7.6: A modified person database 
Definition 7.2.16 (Schema Preserving Structure Replacement.) 
S := (@,C) E S(C) is a structure schema and F, F’ E L(S) are two schema 
consistent structures. Furthermore, p := (AL, L, R, AR) E P(C) is a structure 
replacement rule. The structure F‘ is direct derivable from F by applying p 
(write: F 
F’) :% 
(1) There is a morphism u : L 7 
F with: L S u , ~ ~  
F , 
(2) There is no morphism fi : L 7 
F with: L CG,AL F and u c 
fi , 
i.e. the via u selected redex in F respects the preconditions AL. 
i.e. u selects a maximal substructure in F (with c being the inclusion 
for relations). 

7.2. LOGIC-BASED STRUCTURE REPLACEMENT SYSTEMS 
501 
(3) There is a morphism w : R < F’ with: R 
i.e. the via w selected subgraph in F’ respects the postconditions AR. 
(4) The morphism w maps any new object identifier of R, not defined in L, 
onto a separate new object identifier in F‘, which is not defined in F .  
( 5 )  With K := L n R the following property holds: 
v:={(z,y) E u I z is identifier in K }  = {(z,y) E w I z is identifier in K } ,  
i.e. u and w are identical with respect to all identifiers in K .  
H E L(C) : F \ (u*(L) \ .*(K)) = H = F’ \ (w*(R) 
\ v*(K)), 
i.e. H represents the intermediate state after the deletion of the old sub- 
structure and before the insertion of the new substructure. 
F’, 
(6) There exists a structure 
It is a straightforward task to transform the definition of schema preserving 
structure replacements above into an eflectiwe procedure for the application of 
a rule p to a schema consistent structure F .  The execution of p proceeds as 
already explained before in Definition 7.2.16 and is equivalent to the construc- 
tion of the diagram in Figure 7.7. Unfortunately, we cannot guarantee that 
the process of computing derived data or checking pre- and postconditions as 
well as integrity constraints terminates in the general case. Therefore, we will 
introduce a special symbol “co” for nonterminating computations in the next 
section, when we define the semantics of structure replacement programs. 
‘4 
W
R
 
b R u A R  
‘2 
i3 
L
4
 
K 
il 
A L u L  4 
Figure 7.7: Diagram for the application of a structure replacement rule 
Note that this kind of structure replacement does not prohibit the selection of 
homomorphic matches with two identifiers 01 and 02 in L being mapped onto 
the same object in F .  The application of the replacement rule Marry above 
relates for instance the two set identifiers Hischildren and Herchildren to the 
same node Clio of our graph database. “Sharing” is even permitted if 01 belongs 
to R and 02 not. These deleting/preserving conflicts are resolved in favor of 
preserving objects (unlike to the SPO approach in Chapter 7 of this volume). 
Otherwise, relation w, the restriction of u to K ,  would no longer be a morphism 
from K to H .  For readability reasons, C-morphisms which map different node 

502 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
identifiers of a production onto the same node in a given graph, may, but need 
not be prohibited in the language PROGRES. 
Finally note that we have to take care about dangling references in the general 
case of a person database replacement rule, where L is not a subset of R. 
We have to guarantee that any node(z, 1) is removed together with all related 
edge(z, e, y), edge(y, e, z), and attr(z, a, y) formulas. This may be accomplished 
by adding appropriate formulas with set identifiers (instead of y) to the rule's 
left-hand side. In this way, we are able to overcome the problem of the algebraic 
double pushout approach with deletion of nodes with unknown context (cf. 
Chapter 3 of this volume). 
Proposition 7.2.17 (Structure Replacement Diagrams.) 
Assuming the terminology of Definition 7.2.16 and F 3 F' we are able to 
construct the diagram of fig. 7 (with il, . . . , is being inclusions). This diagram 
has commuting subdiagrams (1) through (4). 
Proof: 
The existence of commuting subdiagrams (1) and (4) is guaranteed by Defiui- 
tion 7.2.14. For proving the existence of commuting subdiagrams (2) and (31, 
we will show that step (5) of Definition 7.2.16 constructs a morphism v from 
K to H :  
We start with Definition 7.2.16, condition (1): 
u : L q F  
*DeL 
7.2.10, Prop. 7.2.13, K 
L u*(K) u*(L) c F 
*condition 
(5) of Def 7.2.16 
v*(K) 5 u*(L) c 
*simple 
transformation 
v * ( W  \ (u*(L) \ v*(K)) c F \ (u*(L) \ v*(K)) 
*simple 
transformation 
v * ( W  c F \ ( u * ( L ) \ v * ( K ) )  
econdition (6) of Def. 7.2.16 
e D e L  7.2.10 and Prop. 7.2.13 
: K 
H 
v*(K) 
c 
The rest of the proof follows directly from 
since v is a restriction of u or w onto the identifiers in K .  
i 2 o u = v o i 6  a n d v o i T = i g o w ,  
0 
Being equipped with a definition of structure replacement we are now able to 
define LBSR systems and their generated languages. As usual, generated iso- 
morphic language elements are identified, i.e. concrete C-structures according 
to Definition 7.2.4 are replaced by equivalent classes of concrete C-structures, 
so-called abstract C-structures. 
Definition 7.2.18 (Abstract C-Structure.) 
The set of abstract C-structures dC(C) := L(C)/ 
consists of all equiv- 
alence classes of C-structures with respect to the following equivalence rela- 
tion =: 
N 
VF, F' E C(C) : F 2 F' :& 3 isomorphism u : F 
F'. 

7.2. LOGIC-BASED STRUCTURE REPLACEMENT SYSTEMS 
503 
It is worth-while to notice that any isomorphism between two C-structures is 
a bijective function which maps object identifiers onto object identifiers and 
object set identifiers onto object set identifiers (cf. Def. 7.2.8, 7.2.9, and 7.2.10 
of C-relations and C-morphisms). Otherwise, F would contain less object (set) 
identifiers than F’ or the other way round. As a consequence, it would not 
be possible to construct the left- and right-inverse morphism u-l for u. This 
line of argumentation is no longer true, when arbitary sets of C-formulas are 
regarded. A single nonatomic formula then represents a set of derivable facts. 
It is, therefore, possible that two sets of formulas are equivalent (isomorphic) 
although they differ with respect to the number of used object (set) identifiers. 
Definition 7.2.19 (Abstract Schema Consistent C-Structure.) 
Let S E S(C) be a schema and C(S) the set of all S-schema consistent struc- 
tures. The set of abstract schema consistent C-structures is defined as 
AC(C) := C ( S ) /  . 
Proposition 7.2.20 (Soundness of Abstract Schema Consistency.) 
Let S := (@,C) E S(C) be a schema and F, F’ E ,C(C) arbitrary C-structures. 
Then 
i.e. all C-structures of an equivalence class in AC(C) are either schema consis- 
ten t or in consis ten t. 
Proof: 
F 2 F’ + ( F  E C(S) * F’ E C(S)), 
F 
F’ 
*&f. 
7.2.18 
3 isomorphism u : F 
F’, a bijective function 
*Props. 7.2.13 
u*(F) = F’ 
Therefore, the following is true: 
F E C(S) J D e f .  7.2.7 
C(F) U @ is a consistent set of formulas 
* 
u*(C(F) U @) is a consistent set of formulas 
(consistent renaming preserves proofs) 
J
D
~
~
 
7.2.6 
u*(C(F)) U 
is a consistent set of formulas 
(@ has no identifiers of V or W 
J D e f ,  7.2.5 
C(u*(F)) U @ is a consistent set of formulas 
* 
C(F’) U @ is a consistent set of formulas 
.*(a) = @) 
* 
F’ E C(S). 
In a similar way, we can prove that F’ E C(S) + F E C(S). 
Definition 7.2.21 (LBSR System.) 
A tuple LBSR := (AS, P) is a logic-based structure replacement (LBSR) 
system with respect to a structure schema S E S ( C )  if 

504 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
(1) AS E dC(S) is the schema consistent initial abstract structure. 
(2) P c P(C) is a set of structure replacement rules. 
Definition 7.2.22 (Generated Language of LBSR System.) 
With LBSR := (AS,P) as in Definition 7.2.21, the language dC(LBSR) c 
dL(S) is defined as follows: 
P 
AF E dC(LBSR) :* 
AS ==+* AF 
==+* is the transitive, reflexive closure of ==+ 
AF‘ C dC(C) x dC(S) :@ 
3F E AF,F’ E A F ’ , ~ E  
P :  F 
where 
P 
P 
and AF 
F’. 
The definition above states that the language of a LBSR system consists of 
all those abstract structures which may be generated by applying its rules an 
arbitrary number of times to the initial abstract structure AS. A distinction 
between terminal and nonterminal structures has not been made in the pre- 
ceding subsections. Hence, any generated abstract structure is per definition 
an element of the generated language. 
7.2.4 Summary 
The definitions and propositions of the preceding subsections constitute a 
framework for the formal treatment of various forms of graph replacement 
systems as special cases of logic-based structure replacement (LBSR) sys- 
tems. Other approaches with the same intention are “High Level Replacement 
(HLR) systems” and “structured graph grammars”. HLR systems belong to 
the algebraic branch of graph grammars (cf. Section 4.5.3 of Chapter 7 and 
[MI). 
They provide a very general framework for the definition of new kinds of 
replacement systems, which is based on the construction of categories with cer- 
tain properties. Therefore, HLR systems are not restricted to the manipulation 
of graphs or relational structures (as LBSR systems are). 
Structured graph grammars [35], on the other hand, are restricted to a data 
model of directed acyclic graphs. They were a first attempt to combine prop- 
erties of algebraic graph grammars (cf. Chapter 3 and 7 of this volume) and 
algorithmic node replacement graph grammars (cf. Chapter 1 of this volume) 
within a single framework. Both HLR systems and structured graph gram- 
mars do not introduce the notion of a schema and do not support modeling of 
derived properties or constraints. 

7.3. PROGRAMMED STRUCTURE REPLACEMENT SYSTEMS 
505 
LBSR systems are an attempt to close the gap between the operation-oriented 
manipulation of data structures by means of rules and the declaration-oriented 
description of data structures by means of logic-based knowledge representa- 
tion languages. In this way, both disciplines - graph grammar theory and 
mathematical logic theory - 
might profit from each other: 
0 Structure (graph) replacement rules might be a very comfortable and 
well-defined mechanism for manipulating knowledge bases or deductive 
data bases (cf. [25,59]), whereas 
0 many logic-based techniques have been proposed for efficiently maintain- 
ing derived properties of data structures, solving constraint systems, and 
for proving the correctness of data manipulations (cf. [10,29,54]). 
Currently, LBSR systems are restricted to sequential graph replacement. It is 
subject to future work to extend the presented approach such that parallel 
application of rules is supported. Furthermore, the following questions should 
be considered in more detail: 
(1) Which restrictions are sufficient to guarantee that subdiagrams (2) and 
( 3 )  of Figure 7.7 are pushouts? 
(2) Can we characterize a “useful” subset of rules and consistency constraints 
such that an effective proof procedure exists for the “are all derivable 
structures schema consistent” problem (see also Chapter 9 of this volume 
and [13])? 
(3) Can we develop a general procedure which transforms any set of structure 
replacement rule postconditions into weakest preconditions? 
The problems (2) and (3) above are related to each other by transforming global 
consistency constraints into equivalent postconditions of individual rewrite 
rules using techniques proposed in [lo]. Having such a procedure which trans- 
lates postconditions into corresponding preconditions, problem (2) is reducible 
to the question whether these new preconditions are already derivable from the 
original set of preconditions of a given rule and the set of guaranteed integrity 
constraints (for the input of the rule). 
7.3 Programmed Structure Replacement Systems 
So far we would be able to define sets of schema consistent structure replace- 
ment rules and structure languages, which are generated by applying these 
rules in any order to a given structure (axiom). This might be sufficient from a 
theoretical point of view, but when we are using structure replacement systems 
for specification purposes additional means are necessary for regulating the ap- 
plication of rules. Many quite different proposals for controlling application of 
rules may be found in literature as for instance [11,15,44,45,64]: 

506 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
0 Apply rules as long as appropriate or as long as possible in any order; 
0 Introduce rule priorities and prefer applicable rules with higher priorities 
0 Use regular expressions or even complex programs to define permissible 
0 Draw control flow graphs and interpret them as graphical representations 
this is the standard semantics of replacement systems. 
at least in the case of overlapping matches. 
derivation sequences. 
of rule controlling programs. 
The idea of using programs for controlling the application of rules, i.e. impera- 
tive control structures, seems to be the most popular one and even superior to 
almost all other rule regulation approaches with respect to their expressiveness. 
On the following pages we will, therefore, 
0 first study required properties of graph replacement programs or, more 
general, of control structures for structure replacement rules (Subsec- 
tion 7.3.1), 
0 introduce a more or less minimal set of control structures in the form of 
so-called Basic Control Flow (BCF) operators and discuss their intended 
semantics on an informal level (Subsection 7.3.2), 
0 present an appropriate semantic domain for BCF operators and a recently 
developed fixpoint theorem (Subsection 7.3.3) , 
0 define the semantics of BCF expressions with recursion and, thereby, the 
semantics of Programmed Logic-based Structure Replacement (PLSR) 
systems by means of the presented fixpoint theorem (Subsection 7.3.4), 
0 and finally summarize the main properties of PLSR systems and discuss 
possible extensions (Subsection 7.3.5). 
7.3.1 Requirements for Rule Controlling Programs 
So-called programmed graph grammars were already suggested many years ago 
in [11,45]. Nowadays, they are a fundamental concept of the graph grammar 
specification languages PAGG [26,28] and PROGRES [66,71]. Experiences with 
using these languages and their predecessors for the specification of software 
engineering tools [21,22,38,75] showed that their control structures should pos- 
sess the following properties: 
(1) Boolean nature: the application of a programmed graph transformation 
either succeeds or fails like the application of a single graph replacement 
rule and, depending on success or failure, execution may proceed along 
different control flow paths. 

7.3. PROGRAMMED STRUCTURE REPLACEMENT SYSTEMS 
507 
(2) Atomic character: a programmed sequence of graph replacement steps 
modifies a given host graph if and only if all its intermediate replacement 
steps do not fail. 
(3) Consistency preserving: programmed graph replacement has to preserve 
a graph’s consistency with respect to a given set of separately defined 
integrity constraints. 
(4) Nondeterministic behavior: the nondeterminism of a single rule - 
it re- 
places any match of its left-hand side 
~ 
should be preserved as far as 
possible on the level of programmed graph transformations. 
(5) Recursive definition: for reasons of convenience as well as expressiveness, 
programmed graph transformations should be allowed to call each other 
without any restrictions including any kind of recursion. 
Without conditions (1) through (4) we would have difficulties to replace a 
complex graph replacement rule by an equivalent sequence of simpler rules, and 
without condition (5) the manipulation of recursively defined data structures 
would be quite cumbersome. 
In the sequel, programmed graph transformations with the above mentioned 
properties will be termed transactions. The usage of the term “transaction” un- 
derlines the most important properties of programmed transformations: atom- 
icity and consistency. The usually mentioned additional properties of transac- 
tions, isolation and duration, are irrelevant as long as parallel programming is 
not supported and backtracking may cancel the effects of already successfully 
completed transactions (cf. Subsection 7.3.2). 
7.3.2 Basic Control Flow Operators 
The definition of a fixed set of control structures for structure manipulating 
transactions is complicated by contradicting requirements. From a theoretical 
point of view the set of offered control structures should be as small as possible, 
and we should be allowed to combine them without any restrictions. But from 
a practical point of view control structures are needed which are easy to use, 
which cover all frequently occurring control flow patterns, and the application 
of which may be directed by a number of context-sensitive rules. 
Therefore, it was quite natural to distinguish between basic control flow oper- 
ators, in the sequel termed BCF operators, of an underlying theory of recur- 
sively defined transactions and more or less complex higher level programming 
mechanisms. Starting with a formal definition of basic control flow operators, 
we should then be able to define the meaning of a large class of program- 
ming mechanisms by translating them into equivalent BCF expressions (cf. 
Section 7.5). 

508 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
<Transaction> ::= 
<BCFExpr> ::= 
<BasicAction> ::= 
<ActionCall> ::= 
<BCFTerm> ::= 
<TransactionId> "=" <BCFExpr> ; 
<BasicAction> I <Actioncall> I <BCFTerm> ; 
"skiD" I "looo" ; 
<RuleId> I <TransactionId> ; 
"def" "(" <BCFExpr> ")" I "undef" "(" <BCFExpr> ")" I 
"(" <BCFExpr> ";" <BCFExpn ")" I 
"(" <BCFExpr> "0" <BCFExpr> ")" 
"(" <BCFExpr> "&" <BCFExpr> ")"; 
Figure 7.8: Syntax of graph transactions and BCF expressions 
Figure 7.8 contains the definition of BCF expressions themselves and of trans- 
actions as functional abstractions of BCF expressions. It distinguishes between 
basic actions like 
0 - 
skip, which represents the always successful identity operator and relates 
0 loop, which neither succeeds nor terminates for any given structure and 
calls of simple rules or other graph transactions, and finally between two unary 
and three binary BCF operators with 
0 deya) as an action which succeeds applied to a given structure F ,  when- 
ever a applied to F produces a defined result, and returns F itself, 
&f(a) 
as an action which succeeds applied to a structure F ,  whenever 
a applied to F terminates with failure, and returns F itself, 
0 (a ; b) as an action which is the sequential composition of a and b, i.e. 
applies first a to a given structure F and then b to any "suitable" result 
of the application of a, 
0 (a 0 b) as an action which represents the nondeterministic choice between 
the application of a or b, and 
0 (a & b) as an action which returns the intersection of the results of a and 
b (requires an equality or isomorphy testing operator on graphs). 
Note that the operators suggested above are intentionally similar to those 
proposed by Dijkstra [14] and especially to those presented by Nelson [51] 
with one essential difference: due to the boolean nature of basic structure 
replacement rules and complex transactions, we are not forced to distinguish 
between side effect free boolean expressions and state modifying actions. This 
has the consequence that complex guarded commands of the form 
a given graph G to itself, and 
represents therefore "crashing" or forever looping computations, 
- 
(Condl + Body, 0 . . . 1 Cond, + Body,) 

7.3. PROGRAMMED STRUCTURE REPLACEMENT SYSTEMS 
509 
are no longer necessary but may replaced by expressions like 
where def(Condi) tests either the applicability of a single rule or of a whole 
transaction without modifying the given input structure. 
Furthermore, BCF expressions offer almost all possibilities for combining bi- 
nary relations over structures, the semantic domain of structure manipulating 
transactions. There are operators for intersection, union, and concatenation. 
The missing difference operator is not supported for the following reasons: 
a \ bl is a subrelation of a \ b2, if b2 is a subrelation of b l .  As a consequence, 
the nonmonotonic difference operator had to be excluded in order to be able 
to come up with a sound definition for recursively defined transactions (cf. 
Subsection 7.3.4). 
Having motivated our reasons for the selection of two unary and three binary 
BCF operators, we are now prepared to discuss the intricacies of their intended 
semantics. A first problem comes with the definition of the meaning of (a;b) 
as “apply b to any suitable result of u”. Let us assume that the application 
of a transformation a to a structure F has three possible results named F1, 
F2, and F3, respectively. Furthermore, let us assume that the transformation 
b applied to F1 fails but applied to F2 and F 3  succeeds. In this case we 
may either select F2 or F3, but not F1 as a suitable result of the application 
of a. This means that we need knowledge about future states of an ongoing 
transformation process in order to be able to discard those possible results of 
a single transformation step, which cause failure of the overall transformation 
process. It should be quite obvious that a more realization-oriented definition 
of this kind of clairvoyant nondeterminism requires a kind of depth-first search 
semantics with backtracking out of “dead-ends” . 
Another problem comes with the definition of expressions like (a 0 b), where a 
loops forever applied to a certain structure F ,  but b has a well-defined set of 
possible results. Having a depth-first search semantics in mind, we are forced 
to define the outcome of the expression (u 0 b) as being either a nonterminating 
computation or any defined result produced by b. 
This means that the kind of nondeterminism we are going to define is not an- 
gelic but more or less erratic: Using backtracking we are able to discard nonde- 
terministic selections which lead to defined failures of basic actions or structure 
replacement rules but not selections which cause nonterminating computations. 
The following example uses nondeterministic depth-first search and backtrack- 
ing. It defines a transaction, which tries to complete a person database such 
that all person nodes are married afterwards. It uses the rule Marry of Ex- 
ample 7.7 and assumes the existence of another rule Markunmarried. The rule 
(def(Cond1); Body,) 0 . . . 0 (def(Cond,); Body,) 

510 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
Markunmarried selects and marks a single unmarried person in the database if 
existent and fails otherwise. 
Example 7.8 (A Person Database Manipulating Transaction.) 
Marry* = (( (&(Markunmarried); 
Marry); Marry*) 
0 undef(MarkUnmarried)). 
0 
The transaction above initiates calls of rule Marry as long as the rule 
Markunmarried is applicable. It terminates successfully, if and only if all per- 
sons are finally married. Otherwise] a database state will be reached, where 
neither the first nor the second branch of 0 is executable. In this case, the 
transaction aborts without any database modifications. Note that the execu- 
tion of Marry* requires backtracking in the general case. Consider for instance 
the application of Marry* to the database of Figure 7.1. The transformation 
process may start with marrying Linus and Marry first and marrying Harry and 
Sally afterwards. The problem is now that no partner for Hannah is left over. 
Therefore] backtracking starts and another couple instead of Harry and Sally is 
married (e.g. Harry and Hannah). 
7.3.3 Preliminary Definitions 
After an informal introduction of transactions as named BCF expressions we 
will now define their intended semantics: This is a semantic function from the 
domain of BCF expressions onto the range of (extended) binary relations over 
abstract structures. In order to be able to deal with recursion and nondeter- 
minism in the presence of an atomic sequence operator " ; I 1  we had to follow 
the lines of [51]9. There, a new form of the fixpoint theorem is used to give an 
axiomatic definition of so-called nondeterministic commands. 
Proposition 7.3.1 (Fixpoint Theorem.) 
Let f be a monotonic function(a1) on a partially ordered set in which every 
chain has a join, and let fa, for ordinal a, be defined inductively by 
Then f has a least fixpoint given by f", for some ordinal a. 
f" = (UO:O<a : f(f0)) . 
Proof: See appendix of [51]. 
For being able to apply the fixpoint theorem to BCF expressions an appropriate 
partially ordered semantic domain is needed: 
gThe sequence operator is not chain continuous in its 2nd argument. Therefore, the orig- 
inal version of the fixpoint theorem, proved in [41], 
does not work in our case. 

7.3. PROGRAMMED STRUCTURE REPLACEMENT SYSTEMS 
511 
Definition 7.3.2 (Semantic Domain.) 
With AC(S) being a S-consistent class of abstract structures for a schema 
S E S(C), the semantic domain of transactions is defined to be the following 
power set of binary relations: 
2) := 2AL(S)x(AL(W{=3)) , 
The semantics of a transaction is a binary relation between abstract structures, 
where the symbol L‘coll in a second component represents potentially nonter- 
minuting computations. The word “potential” includes computations with par- 
tially unknown effects, i.e. computations which may abort or loop forever. A 
relation R, := AC(S) x {co} for instance, which maps any structure F onto 
“mi’ , represents a computation with completely unknown outcomes. 
In order to be able to apply fixpoint theory to recursively defined transac- 
tions we have to construct a suitable partial order for our semantic domain 2). 
“Suitable” means from a practical point of view that the relation R, defined 
above should be less than any other element in 2) and that “Rl less than R2” 
means that Ra is a better approximation of a given transaction than R1. And 
“suitable” means from a theoretical point of view that we have to proof that 
any chain in 2) has a join, i.e. that any sequence of elements (Ra)aEordinal with 
R“ being less equal than Ra+P for any ordinals a and ,O has a least upper 
element in 2). 
Definition 7.3.3 (Partial Order on Semantic Domain.) 
With R,R’ E 2) and S being the underlying structure schema, a suitable 
partial order “5” is defined as follows: 
R < R ’ : H V F , F ’ E C ( S ) :  ( F , F ‘ ) E R * ( F ‘ = ~ ~ ~ ( ( F , F ’ ) E R ’ )  
Please note that 
A (F,co) @ R * ((F,F’) E RV (F,F’) 6 
R’). 
R < R ’ : H V F , F ‘ E L ( S ) :  ( F , F ’ ) E R ~ ( F ’ = c o V ( F , F ‘ ) E R ’ )  
A (F, 
co) 6 R + ((F, F’) E R @ (F, F‘) E R’). 
is an equivalent definition of the partial order “5”. It is easier to handle and 
will be used from now on. 
The relation R of the definition above approxamates R’ such that any input 
F is either related to the same set of outputs by R and R’ or is related to 
the symbol lLcmll in R and to a potentially greater set of outputs in R’ (by 
eventually dropping 
It is obvious that “5” is indeed a partial order, but 
we have to proof its chains have joins condition: 

512 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
Lemma 7.3.4 (Chains Have Joins.) 
Let ( R a ) a ~ o r d j n a ~  C V be a chain, i.e. for any ordinals a and b holds: 
Then the join of the given chain is defined as follows: 
R" 5 R"+p. 
R := U ( R " )  := {(F, F') I 
F' # 00 A 3a : (F, F') E R" 
v F' = 03 A V ~ :  
( F , m )  E R"}. 
Proof 
We have to show that the element R above is indeed greater than any element 
of our chain and that R is the least element in D with this property: 
V a : R " < R :  
( F , F ' ) E R "  
( F , F ' ) E R V F ' = c o .  
(F,co) '$! R" + V,BL a :  (F,F') E R" u (F,F') E RP 
(F, F') E R" * (F, F') E R . 
VR' E D : (Va : R" 5 R') + R 5 R' : 
( F , F ' ) E R  + 3 R " : ( F , F ' ) E R " V F ' = m  
(F,co) '$! R * 3R" : ( F , m )  &f R" 
3 
* 3 R " : ( F , F ' ) € R ~ ( F , F ' ) € R a u ( F , F ' ) ~ R ' .  
0 
(F, F') E R ' V  F' = co . 
7.3.4 
Now, we are prepared to define a semantic function R from the syntactic 
domain of BCF expressions or transactions onto the semantic domain D in- 
ductively: 
A Fixpoint Semantics for Transactions 
Definition 7.3.5 (BCF Expressions and Transactions.) 
S and D are defined as in Definition 7.3.3, and P C P(E) is a set of structure 
replacement rules. Then, &(P) denotes the set of all BCF expressions and 
7 ( P )  the set of all transactions over P. Their context-free syntax is displayed 
in Figure 7.8, and a semantic function R p  : &(P) -+ D is defined as follows 
with abstract structures F, F', F" E dC(S) and with a, b 
(1) (F, F') E RpI[skip] :u F = F'. 
(3) (F, F') E Rpk] 
:U 
&(P): 
(2) (F, F') E Rp[Gp] 
- 
:@ F' = 00. 
F 
F', for any production p E P(C) 
VF' = co, if execution of p may not terminate. 
(4) (F, F') E RP[def(a)] :@ 3F" # CO: (F, F") E R p [ a ]  A F = F' 
v(F,00) E RpI[a]l A F' = CO. 
hThe definition of transactions and transaction calls is postponed, until the precondition 
of the previously introduced fixpoint theorem are checked. 

7.3. PROGRAMMED STRUCTURE REPLACEMENT SYSTEMS 
513 
(5) (F,F’) E Rp(Iundef(a)] : 
(6) (F, F‘) E Rpl[(a; b)] :W 38’’’ # m: (F, F”) E R p [ a ]  A (F”, F’) E R p [ b ]  
(73’’’ 
: (F,F”) E R p [ a ] )  A F = F’ 
V ( F ,  W) E np[~] 
A F’ = CO. 
V(F, 
00) E RP[u] 
A F’ = CO. 
(7) (F, F’) E R ~ [ ( ~  
1 b)] :- (F, F‘) E RP[a] 
v (F, F’) E R ~ I [ ~ ] .  
(8) (F, F J )  E x p [ ( a &  b)] :e 
F’ = 00 A ((F, m) E np[a] 
v (F, CO) E Rp[q) 
V(F, F’) E RPnan A (F, F’) E R ~ I [ ~ ] .  
The definitions above are rather straightforward with the exception of the 
treatment of the operators def and undef. The expressions &(a) and undef(a) 
loop forever if a returns not a single defined result but loops forever. Further- 
more, &(a) may return its input if a returns at least one defined result, even 
if a may loop forever. It terminates with failure if a terminates with failure. 
On the other hand, &(a) 
returns its input if and only if a fails, and it fails 
if and only if a has at least one defined result and may not loop forever. 
Therefore, undef is stricter than def with respect to the treatment of looping 
computations; the expression &(a) may return a defined result even if a may 
loop forever. From a practical point of view, this distinction may be justified 
as follows: 
0 Often, we would like to know whether a computes at least one defined re- 
sult without evaluating all possible execution paths of a after a successful 
path has been found. 
0 On the other hand, answering the question whether a fails is not possible 
without taking all execution paths of a into account, thereby running 
into any nonterminating execution branch of a. 
Nevertheless, a strict version of def might be useful, too. It is no longer inde- 
pendent from the definition of undef, but may be given as follows: 
Definition 7.3.6 (Strict Version of def Operator.) 
A strict version of the def operator may be defined as follows with abstract 
structures F, F’, F” E AL(S), and a E E(P) as in Definition 7.3.5: 
(F,F’) E RpI[defrn(a)] :- 
(F, F‘) E Rp[undef(undef(a))] 
v(F, 00) E RpCundef(a)] A F’ = co 
% 
@ 
( 4 F ”  : (F, F”) E Rp[undef(a)]) A F = F’ 
(3F” # 00 : (F, F”) E RpI[a] A (F, m) 61 Rp[u] A F = F’) 
V(F, 00) E RPia] 
A F’ = 03. 
In order to be able to use Proposition 7.3.1 for the treatment of recursive trans- 
actions we have still to prove that BCF expressions correspond to monotonic 

514 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
functionals. A BCF expression which contains for instance applied transaction 
identifiers tl to t,, must be interpreted as a functional with the following sig- 
nature: 
Provided with the semantics Rp[tl], . . . ,Rp[tn] of tl to t,, the semantics of 
E is given by Definition 7.3.5 and is denoted as follows: 
In such a way, we are able to define the semantics of all BCF expressions and 
transactions bottom-up in the absence of recursion. But having a recursively 
defined transaction like 
we are looking for a least element R E D such that the following fixpoint 
equation 
Rppq : ~n -+ D. 
RPw[Rputln,. . . , ~ ~ ~ [ t , n i .  
Marry* = (((def(MarkUnmarried); Marry); Marry*) 1 undef(MarkUnmarried)), 
R = Rp[((( &(Markunmarried); Marry); Marry*) 0 
undef( MarkUnmarried))][R] 
holds. Proposition 7.3.1 provides us with such a least jixpoint if we are able to 
show that all BCF operators define monotonic functionals and, therefore, all 
complex BCF expressions, too: 

7.3. PROGRAMMED STRUCTURE REPLACEMENT SYSTEMS 
515 

516 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
(F, F’) E Rpudef(a)n 
j (SF‘‘ # CXJ : (F,F”) E Rp[a] A F = F’) V F’ = OC) 
(F, F’) E Rprdef(~’)] 
V F’ = CO. 
+ ( 3 ~ ”  
f- OC) : (F, 
E RP[a’n A F = F / )  v F‘ = OC) 
j 
ad (6) RpAundef(a)] 5 Rp[undef(a’)]: 
VF E AL(S) with (F, co) 6 
R p [ a ]  
=$- 
(F, F’) E R p [ a ]  # (F, F’) E Rp[a’]l 
+ (F, F’) E Rp[undef(a)] w (F, F’) E Rp[lundef(a’)j. 
V F  E dL(S) with (F, 00) E Rp[a]l implies: 
(F, F’) E Rp[undef(a)] @ F’ = co 
+ (F, F’) E Rp[undef(a)] @ ((F, F’) E RplTundef(a’)] V F’ = CO). 
0 
Based on the proof above we are now able to define a fixpoint semantics for 
a given set of transactions which may call each other in an arbitrary manner. 
Please note that from a superficial point of view the treatment of n transactions 
instead of one requires the introduction of a more complex semantic domain Dn 
and a corresponding semantic function. This function takes n binary relations 
as input, which are already computed approximations of n transactions; it 
produces better approximations in the form of n binary relations as output. 
Applying fixpoint theory to this extended setting the semantics of the i-th 
transaction is defined as the i-th component of their common least fixpoint in 
Dn. The extension of the semantic domain 2) to Vn - 
including a new partial 
chain continuous order - is rather straightforward. Therefore, it is omitted 
over here, although it is implicitly used in the following corollary: 
Corollary 7.3.8 (Fixpoint Semantics for Transactions.) 
Let T := {tl, . . . , tn} E T ( P )  be a set of transactions which contain in their 
bodies El to En E &(P) at most calls to transactions tl through t, and calls 
to structure replacement rules of P C P(C), i.e. 
With A.C(C) being the corresponding class of abstract schema consistent struc- 
tures, the following propositions hold and define a new semantic function 
ti = El [ti , . . . , t,], . . . , t, = En[tl , . . . , tn] . 
R; , : T + D:  
(1) tl, . . . ,t, have unique least fixpoints R;,[tl], . . . , R>[t,] E D. 
(2) Approximations of these fixpoints may be constructed as follows: 
RY := dC(S) x (00);. . . ;RE := d L ( S )  x {co}, 
R:+’ := R>[El][Rf,. 
. . , Rk]; . . . ; Rk+’ := R>IIEn][Rt,. . . , Rk], 
where R>[Ei] : Dn -+ ’D takes approximations for transactions tl , . . . , t, 
as input and yields a new approximation for ti by applying Defini- 
tion 7.3.5 to expression Ei. 

7.3. PROGRAMMED STRUCTURE REPLACEMENT SYSTEMS 
517 
Proof: 
ad (1) Follows directly from Proposition 7.3.1 and Lemmata 7.3.4 and 7.3.7. 
ad (2) The relations Rf are indeed approximations for tl , . . . , t, such that 
for any i, k : RY 5 . . . 5 RF 5 R>I[ti]. This follows directly from 
Proposition 7.3.1 and Lemmata 7.3.4 and 7.3.7 with 
0 
Note that the corollary above is not only interesting from a theoretical point of 
view by guaranteeing the existence of least fixpoints for any recursively defined 
set of transactions. Additionally, it provides us with a straightforward algorithm 
which computes the results of terminating transactions and approximates the 
results of (potentially) nonterminating transactions. Equipped with such a fix- 
point computing function, we are now able to define programmed structure 
replacement systems and their generated (abstract) structure languages. 
vi,E : Ri = Uk<lRf 
- 
5 R>I[ti] and uk,{)Rf = AL(S) X {m}. 
Definition 7.3.9 (PLSR System.) 
Assuming the vocabulary of Definition 7.3.5, PLSR := (S, A, P, T ,  t) is a pro- 
grammed logic-based structure replacement (PLSR) system with re- 
spect to a signature C if: 
(1) S E S( C) is a structure schema. 
(2) A E dL(S) is the schema consistent initial structure. 
(3) P C P(C) is a set of structure replacement rules. 
(4) T C: 7 ( P )  is a set of (recursively) defined transactions over P. 
(5) t E T is the main transaction of PLSR. 
Definition 7.3.10 (Language of a PLSR System.) 
With PLSR := (S,A, P,T,t) as in Def. 7.3.9, the language dL(PLSR) is de- 
fined as follows: 
F E AL(PLSR) :* 
(A, F )  E R>[t]) 
A F # 00. 
The definition above states that the language of a programmed structure re- 
placement system consists of all those structures which may be generated by 
applying a main transaction t to the initial structure A. The transaction t calls 
structure replacement rules from P and other transactions from T ,  which in 
turn contain calls of rules and transactions. 
In the case where PLSR systems are used to define abstract data types instead 
of structure (graph) languages only, it might be useful to replace the single 
main transaction “t” above by a set of exported transactions tl, . . . , t,. This 
would be a very first step towards a module concept for structure replacement 

518 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
systems. But even in that case the language of all possibly generated structures 
is definable as the result of the following new main transaction: 
which either returns its inputor applies the transactions tl, . . . , t, an arbitrary 
number of times. 
t’ = ((tl 1 . . . 1 t,); t’) 1 skip), 
7.3.5 Summary 
The definitions and propositions of the preceding subsections constitute a 
framework for defining and comparing various approaches which support pro- 
gramming with (graph) replacement rules. The framework provides us with 
a formal definition of partial, nondeterministic, and even recursive structure 
replacement programs, termed transactions. We added a new symbol “1x3” to 
the domain of structures which represents unknown results or nontermimting 
computations. Thereby, we were able to overcome the difficulties with opera- 
tors which test success or failure of subprograms in the presence of recursion 
(cf. [66] for a more detailed discussion about these problems). These operators 
are a prerequisite for writing programs like “try first to execute subprogram A 
and, if and only if A fails, try to execute B”. 
Note that [51], which presents an axiomatic semantics definition for nondeter- 
ministic partial commands, gave us the initial impulse for the introduction of 
the symbol ‘ ‘ ~ 0 ”  as well as for the selection of the adequate fixpoint theorem 
version. Nevertheless, we had to prefer the denotational instead of the ax- 
iomatic approach, since structure replacement rules play here about the same 
role as simple assignments in 1511. The definition of their intended semantics as 
binary relations is given in Definition 7.2.16, but it is a yet unsolved problem 
(in the general case) how to push postconditions through rules for obtain- 
ing their corresponding weakest preconditions (cf. list of unsolved question in 
Subsection 7.2.4). 
Furthermore note that BCF expressions as well as almost all related approaches 
discussed in Section 7.5 deal with sequential replacement processes only. The so- 
called programmed derivation of relational structures approach [44] is the only 
exception. This approach supports parallel programming with graph replace- 
ment rules and provides a fixpoint semantics for recursive programs based on 
program traces. Unfortunately, no constructs (like def and undef over here) are 
available for testing whether a complex structure transformation returns a de- 
fined result or not. Parallel composition of subtransformations as well as testing 
their applicability are both very valuable means and require completely differ- 
ent formal treatments. Parallel composition, on one hand, with its interleaving 
semantics excludes the definition of a program’s semantics as a function of the 

7.4. CONTEXT-SENSITIVE GRAPH REPLACEMENT SYSTEMS ... 519 
semantics of its subprograms. Testing success or failure of subprograms, on the 
other hand, enforces the introduction of a special symbol “03” for nontermi- 
nating computations and the usage of a rather complicated partial order for 
the resulting semantic domain. Further investigations are necessary to check 
whether a combination of both approaches is possible or not. 
Finally, we have to emphasize that all presented results in this section are valid 
for any rule-based approach, where rules define binary relations over a given 
domain of objects. Having developed such a common framework for rather 
different rule regulation mechanisms offers the opportunity to combine dif- 
ferent regulation mechanisms as needed within future graph grammar-based 
specification languages. This idea is closely related to the GRACE initiative 
[36], a first attempt to combine different graph models, graph replacement ap- 
proaches, and rule regulation mechanisms within a single GRAph CEntered 
language and environment. As far as we can see, PLSR systems could act as 
the common underlying formalism for all envisaged types of graphs, rules, and 
control structures. 
In GRACE, a complete specification is built by defining and composing so- 
called transformation units. Any transformation unit may use a different style 
of graph replacement (cf. section 7.4 and 7.5 for an overview about currently 
existing variants of graph replacement approaches). It defines a binary relation 
between certain classes of graphs. The operators which combine single trans- 
formation units to more complex transformation units are very similar to BCF 
operators presented over here. Hence, PLSR systems can be used to define the 
semantics of transformation units and their composition operators. The other 
way round, transformation units of GRACE provide a kind of module concept 
for structuring PLSR systems into reusable subcomponents with well-defined 
interfaces between them. 
7.4 
Until now, we presented a very general framework for the definition of specific 
graph data models and especially for the definition of various types of (pro- 
grammed) graph replacement systems. We will use this framework over here for 
reviewing a number of different context sensitive graph replacement approaches 
(cf. Table 1 in Subsection 7.4.5). These are the expression-oriented algorithmic 
graph replacement approach (EXP) of [45,46], and its afore-mentioned succes- 
sors PAGG [27,28] and PROGRES [65,66]. These approaches will be compared 
with the two families of algebraic graph replacement systems, DPO [19,20] and 
Context-sensitive Graph Replacement Systems - Overview 

520 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
SPO [20,40], which are the main subject of Chapter 3 and 7 of this volume. Fi- 
nally, we have selected so-called DELTA grammars [33], which are very similar 
to PAGG, but claim to be a member of the algebraic branch. 
It is rather obvious, how different graph data models 
~ 
like directed graphs 
or hypergraphs - may be seen as relational structures with certain proper- 
ties. Furthermore, all presented graph replacement systems have about the 
same data model of a directed graph with labeled nodes and edges. The only 
differences are that 
0 one approach (EXP) does not support (node) attributes, 
0 algebraic DPO and SPO approaches handle edges as identifiable objects 
and are easily extendible to n-ary relations in the form of hyperedges, 
0 and every second approach knows the concept of a label hierarchy, where 
more general node or edge labels match more specific node or edge labels. 
Therefore, we will omit a more detailed discussion of graph data model dif- 
ferences in the sequel and simply assume the same class of graphs as in the 
running example of Section 7.2. Furthermore, we will also omit the subject of 
graph schema definitions, which is already covered by Subsection 7.2.1. But 
even then, a bewildering long list of characteristics remains which distinguish 
the selected six graph replacement approaches: 
0 The following Subsection 7.4.1 discusses how matches of rules in a host 
graph may be restricted and how deletion of nodes and edges is handled. 
0 Subsection 7.4.2 presents then two completely different ways how to spec- 
ify the embedding of created nodes into the remaining part of the host 
graph. 
0 Subsection 7.4.3 shows afterwards why additional application conditions 
for rules are needed and how they are usually defined. 
0 Subsection 7.4.4 sketches then how attributes are handled within graph 
replacement systems. 
0 And subsection 7.4.5 summarizes the discussion in a table with one col- 
umn for each presented approach and one row for each of the identified 
25 graph replacement system characteristics. 
7.4.1 Context-sensitive Graph Replacement Rules 
In the simplest case, a graph replacement rule consists of two graphs with 
labeled, directed edges and labeled, identifier carrying nodes. These two graphs 
are their left- and right-hand side. The overall idea of the application of a graph 
replacement rule is to 

7.4. CONTEXT-SENSITIVE GRAPH REPLACEMENT SYSTEMS ... 521 
(1) find first a match for its left-hand side in a given host graph, 
(2) remove then the match from the host graph, 
(3) construct an isomorphic copy of the rule’s right-hand side, 
(4) and add the copy to the remaining rest of the host graph. 
DeleteMan = 
.._ 
Figure 7.9: Example of a context-sensitive graph replacement rule 
This procedure leads to a host graph, where the new subgraph is isolated from 
the old rest of the host graph. Therefore, an additional mechanism is needed, 
called embedding transformation, for establishing connections between new and 
old nodes. The most straight-forward realization of such an embedding trans- 
formation is based on the identification of nodes in a rule’s left- and right-hand 
side, the so called gluing approach. Matches of these nodes are neither deleted 
nor recreated during the application of replacement rules. They simply have 
to be present and are preserved with all their edges to unmatched nodes in the 
host graph. The graph replacement rule DeleteMan of Figure 7.9 has for in- 
stance two nodes v2 and v3, which are part of its left- and right-hand side and 
whose matches in a host graph may have connections to an arbitrary number 
of unmatched nodes in the host graph. 
Using this kind of graph replacement the following two questions arise: 
0 Shall we allow that the match of a rule is a nonisomorphic image of its 
left-hand side, i.e. that two nodes of the left-hand side share the same 
node in the host graph? 
And what about edges at a matched node which are not matched by an 
edge of the left-hand side although their node will be deleted by the rule? 
All six reviewed graph replacement formalisms have different answers for these 
questions. The E X P  approach [45,46] (with so-called path Expressions) does 
not know the concept of preserved nodes, but solves the embedding problem 
in a different manner (cf. Subsection 7.4.2). Therefore, all matched nodes are 
deleted and permitting nonisomorphic images makes no sense. Furthermore, 
unmatched edges between matched nodes are not allowed, i.e. the matched 
subgraph has to be equivalent to its induced subgraph. As a consequence, the 
rule DeleteMan is not applicable to any man node whose parents are connected 
to each other with a wife edge. Edges between matched nodes and unmatched 

522 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
nodes are handled in a different way. They will be deleted together with their 
matched nodes. Otherwise, graph replacement rules would never be able to 
delete nodes which have connections to preserved and, therefore, unmatched 
nodes. 
The PAGG (Programmed Attributed Graph Grammars) approach [26,27,28] 
knows the concept of preserved nodes, but requires still that matches are iso- 
morphic images of left-hand sides (with the exception of the embedding part 
of replacement rules which will be explained in Subsection 7.4.2). One of its 
differences to EXP is that the induced subgraph condition is dropped, i.e. 
all unmatched edges at a deleted node are handled in the same way and are 
deleted, too. Therefore, a graph replacement rule like DeleteMan can be used to 
delete any man node independent from the fact whether this node or its parent 
nodes are sources/targets of additional edges. Figure 7.10 of Subsection 7.4.2 
contains an example for the notation of PAGG rules. 
The default behavior of PROGRES graph replacement rules is the same as 
for PAGG. But explicit folding statements allow left-hand sides to share their 
matches as long as these nodes are also part of the right-hand side. This is the 
so-called identification condition, which prevents situations where a rule has 
to preserve and to delete a node at the same time. In the rule DeleteMan for 
instance nodes v l  and v3 may not match the same node in the host graph, 
even if the host graph contains a man node with a child edge loop. 
The next approach, DELTA [33] (its rules have the form of a A), is very similar 
to PROGRES with respect to the supported form of graph replacement (cf. Fig- 
ure 7.10 of Subsection 7.4.2). Isomorphic matching is the default, but explicit 
folding statements may be used to overwrite the default. Deletion/preservation 
conflicts are possible, but (probably) prohibited by the identification condition, 
too. 
The DPO (Double PushOut) approach [19,20] is the most restrictive one 
concerning the treatment of unmatched edges at nodes which should be deleted. 
The so-called dangling edge condition forbids the application of rules in this 
case. Therefore, DeleteMan may only be used to delete man nodes without 
outgoing wife or child edges. Furthermore, nonisomorphic matching together 
with the identification condition is the default. Both the dangling edge and the 
identification condition are summarized under the name gluing condition. 
The SPO (Single PushOut) approach [20,40], finally, permits any kind of 
nonisomorphic images of left-hand sides and drops also the dangling edge con- 
dition. As a consequence, edges at deleted nodes are deleted, too, and dele- 
tion/preservation conflicts are resolved in favor of deletion. 

7.4. CONTEXT-SENSITIVE GRAPH REPLACEMENT SYSTEMS ... 
523 
Last but not least we should mention that all discussed six approaches allow to 
a certain extent that a single node (edge) of a graph replacement rule matches 
more than one node (edge) in the host graph. At least EXP, DPO, and SPO 
have extensions which allow for the parallel application of a single rule (or of 
several rules) at various matches in a given host graph. Furthermore, both 
DPO and SPO variants were developed recently with so-called amalgamated 
graph replacement rules \9,31,72]. Such an amalgamated rule represents an in- 
finite family of simple rules in the general case. They are useful for manipulat- 
ing different occurrences of a single pattern in the host graph simultaneously. 
Simplified forms of amalgamation - mainly used for specifying embedding 
transformations in a graphical notation - 
are also part of PAGG, PROGRES, 
and DELTA. 
The following example summarizes the discussion of possible interpretations 
of simple graph replacement rules: 
Example 7.9 (Translation into a Structure Replacement Rule.) 
The translation of the graph replacement rule DeleteMan of Figure 7.9 into a 
structure replacement rule in accordance with the informal discussion above 
has about the following form: 
(1) Left-hand side translation: 
L := 
(node(v1, man), node(v2, woman), node(w3, man), 
edge(v2, child, vl), edge(v3, child, vl)} 
plus optional extension for deletion of otherwise dangling edges with 
S1, . . . being set identifiers: 
U (edge(v1, child, Sl), . . . }. 
(2) Right-hand side translation: 
(3) Dangling edge preventing (post-)condition translation: 
(4) Optional identification (pre-)condition: 
R := (node(v2, woman), node(v3, man)}. 
AR := {Vz, e,y : edge(z, e, y) -+ (31 : node(z, I )  A 31 : node(y, I ) ) } .  
AL := { v l  # v3} 
AL := ( 4 e  : edge(v2, e, v3) A . . . } 
or/and optional induced subgraph (pre-)condition: 
or/and - 
in this case useless - 
isomorphic match (pre-)condition: 
AL := { v l  # v2,vl # v3,v2 # ~ 3 ) .  
0 
7.4.2 
Using the style of graph replacement introduced in the previous subsection we 
have no chance to define a rule which 
Embedding Rules and Path Expressions 

524 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
deletes a man node v with an unknown number of emanating child edges 
and creates for any deleted child edge from v to another node w' two new 
grandchild edges from the parents of v to v'. 
This a scenario which requires complex embedding transformation rules. EXP 
is an early graph replacement approach which is famous for its powerful em- 
bedding rules. These rules have the following four components: 
A left-hand side node identifier, whose match in the host graph is poten- 
tially connected to an arbitrary number of unmatched context nodes. 
A so-called path expression describing a path through the host graph 
from the selected left-hand side node match to a relevant set of un- 
matched context nodes. 
A node of the right-hand side, whose copy in the host graph will be the 
source or target of a new embedding edge. 
A last part which determines the label and the direction of the new edge. 
PROGRES notation 
grandchild 
. , 
.I 
I. 
grandchild I . I 
I grandchild 
. 
& Igaandchild 
child 
rr--- 
11 
S2: man 
L - - J  
LSl-wo_mayJ 
52. mnnJJ 
,S 
l-wozayJ 
woman 
man 
man 
woman 
PAGG notation 
Caption: 
: edge with label "child" 
- _  + : edge with label "grandchild +" 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _  
DELTA notation 
I 
: edge with label "child" 
: edge with label "grandchild" 
Figure 7.10: Notations for graph replacement rules with graphical embedding rules 

7.4. CONTEXT-SENSITIVE GRAPH REPLACEMENT SYSTEMS ... 
525 
In the simplest case, a path expression of the form Rlabel or Llabel requires the 
traversal of a single edge in or against its direction as for instance in 
This embedding rule completes the rule DeleteMan and creates for any child 
edge from v l  to a context node v new grandchild edges from v2 and v3 to v. 
In the general case, path expressions are constructed by building concatena- 
tions, unions, iterations, etc. of simple path expressions. They may be used for 
defining derived relationships like ancestor or brother of Figure 7.2. 
The reader may imagine that path expression-based embedding rules are a 
rather powerful concept, but are sometimes difficult to understand. Therefore, 
PAGG and DELTA rely on graphical embedding rules, whereas PROGRES of- 
fers both textual embedding rules like EXP and graphical embedding rules 
like DELTA. All graphical embedding rules have in common that they mark 
certain nodes (edges) in their graph replacement rules which are allowed to 
match an arbitrary number of nodes (edges) in the host graph. In PROGRES, 
these nodes are depicted as double dashed rectangles (cf. Figure 7.5 in Subsec- 
tion 7.2.3 and Figure 7.10). The underlying formalism of structure replacement 
rules supports this concept by means of set identifiers: 
lgrandchild = (v2, v3; Rchild(V1)) . 
Example 7.10 (Translation of Embedding Rules.) 
The translation of the PAGG, PROGRES, and DELTA graph replacement 
rules of Figure 7.10 into an equivalent structure replacement rule is the same 
as in Example 7.9, except the fact that L and R are extended as follows: 
edge(v1, child, Sl), edge(v1, child, S2)). 
edge(v2, grandchild, Sl), edge(v2, grandchild, S2), 
edge(v3, grandchild, Sl), edge(v3, grandchild, S2)). 
(1) L' := L U {node(Sl,woman), node(S2, man), 
(2) R' := R U (node(S1, woman), node(S2, man), 
S1 and S2 are node set identifiers which match zero or one or two or . . . nodes 
0 
in a host graph (cf. Def. 7.2.1). 
The PAGG notation of the graph replacement rule in Figure 7.10 must be read 
as follows: 
(1) Nodes and edges in the left section of the X are deleted together with 
all incident edges during the application of such a rule. 
(2) Nodes and edges in the right section of the X are created anew when the 
rewrite rule is applied. 
(3) Nodes and edges of the lower section of the X denote the preserved part 
of the host graph which has to be present but remains unmodified. 

526 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
(4) And nodes and edges of the upper section of the X denote graphical 
embedding rules. They are preserved and have in the general case not a 
single match, but a maximal number of matches in the host graph. 
The meaning of section crossing edges should be obvious except those between 
the lower and the upper part of the X .  They wear either the additional label 
“-” or “+”. The label “-” denotes those edges which have to be present before 
the application of the rule but are no longer present afterwards. The label “+” 
denotes those edges which need not be present before the application of the 
rule, but will be present afterwards. 
DELTA grammar rules are rather similar to PAGG rewrite rules (cf. Fig- 
ure 7.10). The area left of the A corresponds to the left section of the X ,  
the area right of the A to the right section of the X, and the inner area of the 
A to the upper and the lower part of the X. Preserved nodes with multiple 
matches instead of single matches are identified by having an additional V’ 
label. The purpose of the region below the A will be explained within the next 
subsection. 
7.4.3 
It is quite often the case that a graph replacement step may only take place 
if additional nodes and edges are present or if a certain graph pattern is not 
present. Therefore, PROGRES, DELTA, and SPO know the concept of positive 
and negative context conditions. A very general version of these additional 
application conditions is suggested in [30] as an extension of the SPO approach. 
There, arbitrarily large context graphs may be attached to the left-hand side of 
a graph replacement rule, and their existence may be required or prohibited. 
DELTA has about the same concept of negative context graphs. They are 
depicted below the bottom line of the A. Positive context conditions correspond 
to the preserved part of the graph rewrite rule, the inner region of the A. In this 
way, SPO and DELTA are able to require the existence or absence of context 
subgraphs which have an a priori known size. The lower part of Figure 7.11 
shows an example of a DELTA replacement rule which marries two previously 
unmarried persons. The preconditions require that the two nodes do not have 
a wife edge in between them. They require furthermore that the two nodes do 
not have any wife edge connections to other nodes. 
The Figure 7.11 contains in its upper part the corresponding PROGRES de- 
finition with an additional restriction: The two nodes may not be ancestors 
of each other. This is an example of a negative context condition, where the 
size of the prohibited subgraph - a path through a given host graph 
~ 
is 
Positive and Negative Application Conditions 

7.4. CONTEXT-SENSITIVE GRAPH REPLACEMENT SYSTEMS . . . 527 
not fixed within the rule. Such a requirement is not expressible within SPO or 
DELTA. PROGRES reuses the concept of path expressions - 
originally used 
for defining n-context embedding rules - 
to overcome this restriction. In such 
a way, control structures of path expressions for conditional branching] tran- 
sitive closure, and conditional iteration are now available for defining complex 
n-context application conditions. 
The translation of positive as well as negative application context conditions 
into preconditions of structure replacement rules is rather obvious. Example 7.6 
of Subsection 7.2.2 presents already the complete translation of a subgraph test 
with similar context conditions as in Figure 7.11. Furthermore] the translation 
of complex path expressions with transitive closure operators and the like is 
already part of Example 7.4 in Subsection 7.2.1. 
v2: man 
PROGRES notation 
PROGRES notation 
v2: man 
DELTA notation 
n 
DELTA notation 
, 
woman ' 7 
,,,'2f\ 1 =negativecontext 
Figure 7.11: PROGRES and DELTA rules with negative context conditions 
7.4.4 Normal and Derived Attributes 
Until now, we have discussed only those means of graph replacement rules 
which allow the manipulation of nodes and edges, i.e. of data which has an im- 
portant internal structure from the specifiers point of view. But in many cases 
additional data is manipulated - like strings or numbers - which should 
be handled as atomic items. Therefore, all presented graph replacement ap- 
proaches ~ 
except EXP - 
support the definition of attributes] which are at- 
tached to nodes and which have a single item or a set of atomic items as their 
values. In order to be able to write or read these attributes, textual extensions 

528 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
of graph replacement rules are offered. They are always more or less similar to 
those of the language PROGRES, which were already used in Example 7.7 of 
Subsection 7.2.3. The graph replacement rule Marry presented there tests and 
modifies the income attribute of a matched person node. 
In general, two different categories of attributes may be distinguished as they 
are sometimes distinguished within attribute tree grammars: 
0 Intrinsic attributes, like the above mentioned income attribute, represent 
extensionally defined properties of nodes in a graph. They change their 
value only through explicit assignments within graph replacement rules. 
0 Derived attributes, on the other hand, represent intentionally defined 
node properties. They are defined by means of directed equations over 
attributes of other nodes, which are in the n-context of their own node. 
PROGRES supports both categories of attributes in their pure form. Nor- 
mal attributes are tested and manipulated within graph replacement rules (cf. 
Example 7.7 and Figure 7.5 of Subsection 7.2.3). Derived attribute value de- 
finitions are part of a graph schema construction. Again path expressions are 
welcome for specifying rather complex n-context references to attributes at for- 
eign nodes within directed equations. Figure 7.12 shows an example of such an 
attribute specification. The number of ancestors of a distinct person is the sum 
of the number of ancestors of her mother plus one (if existent) and the number 
of ancestors of her father plus one (if existent). In the case of nonexistence of 
the mother or the father the evaluation of the subexpression between [. . . I fails 
and the subexpression 0 between I . . .] is returned. 
node class person; 
derived 
noOfAncestors = 
[ 1 + self.<-child-.instance of rnan.no0fAncestors I 0 ] 
+ [ 1 + self.<-child-.instance of wornan.NoOfAncestors I 0 1; 
&; 
Figure 7.12: PROGRES definition of a derived attribute 
Example 7.11 (Translation of Derived Attribute Definition.) 
The attribute equation of Figure 7.12 may be translated as follows into a 
formula, which is part of a structure schema definition (cf. Definition 7.2.6): 
V x: node(x, person) -+ 
3v: (attr(x, noOfAncestors, v) 
A (3vl,v2 : v = v l  + v2 
A (3x1 : (edge(x1, child, x) A type(x1, man) A attr(x1, noOfAncestors, vl)) 
A(3x2: (edge(x2, child, x) A type(x2, woman) A attr(x2, noOfAncestors, v2)) 
V((13x1 :edge(xl, child, x) A type(x1, man)) A v l  = 0)) 
V((13x2 :edge(x2, child, x) A type(x2, woman)) A v2 = 0)))). 

7.4. CONTEXT-SENSITIVE GRAPH REPLACEMENT SYSTEMS ... 529 
BODY = begin 
3.income <- pocketMoney(1 .income, 2. income) ; 
3.noOfAncestors <- 1 .noOfAncestors + 2.noOfAncestors +2 ; 
end; 
Figure 7.13: Attribute manipulating graph replacement rule in PAGG 
Specifying derived attributes within graphs and keeping them consistent to 
each other is much more difficult if the underlying structure is an arbitrary 
directed graph and not a tree. The attempt to traverse an edge during the 
evaluation of a directed equation may fail due to the nonexistence of such an 
edge. On the other hand, it might be the case that a path expression within 
an attribute equation returns a set of nodes instead of a single node. There- 
fore, additional means are necessary for determining alternatives in the case 
of partially defined subexpression and for aggregating sets of attribute values 
to a single useful attribute value. For a detailed discussion of various incre- 
mental attribute evaluation strategies the reader is referred to [32,37,66]. Their 
presentation is outside the scope of this contribution. 
The developers of PAGG and of another attribute graph grammar approach 
[69] adopted the idea of attribute tree grammars to attach directed attribute 
equations to structure replacement rules (productions) instead of defining them 
separately. As a consequence, derived attribute definitions and value assign- 
ments to extensionally defined attributes are handled by the same syntactic 
construct (cf. Figure 7.13), and we are not able to distinguish between 
(1) the case where an attribute, like income, gets once a value computed from 
other attribute values and preserves its value afterwards if these foreign 
attributes change values, 
(2) and the case where an attribute, like noOfAncestors, has to change its 
value as soon as referenced foreign attributes change their values. 
Furthermore, attaching equations to rules has also the drawback that equations 
within different but somehow related rules - 
which insert, modify, and delete 
for instance a certain type of nodes ~ 
may become inconsistent to each other. 

530 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
This is not a real problem as long as graph replacement systems are only used 
for generating graph languages, but tends to be a serious disadvantage as soon 
as graph replacement systems are used for specifying (abstract) data types. 
Nevertheless] the attachment of attribute equations to graph replacement rules 
has some advantages] too. It is no longer necessary to define a separate graph 
schema, the equations which reference nodes in rules (instead of using path 
expressions for this purpose) are easier to read, and the derivation history of 
a graph may influence the selection of active attribute equations. 
Finally, we have to mention that EXP, DPO, and DELTA do not know the 
concept of derived attributes, whereas an SPO variant was defined very recently 
which supports derived data definition at least to a certain extent [34]. 
7.4.5 Summary 
The following table summarizes the presentation of six more or less different 
graph replacement approaches within the previous subsections. Being only a 
rather condensed version of the preceding discussion it should be readable 
without any further explanations. During its construction we had to solve the 
following problems: 
0 The available input for DELTA was not sufficient for answering all ques- 
tions and for verifying that DELTA belongs indeed to the family of al- 
gebraic graph replacement systems. Therefore, its column contains three 
question marks. 
0 The headlines SPO and DPO represent not only a single paper or pro- 
posal, but a whole family of related formalisms which evolved over the 
time. Therefore] it was very difficult to give definite cLyes” or “no” answers 
in some cases. 
0 The classification of embedding rules is traditionally more fine-grained 
than the classification used in Subsection 7.4.2. Therefore, additional 
embedding rows were added for those readers who are familiar with graph 
replacement systems. 
7.5 Programmed Graph Replacement Systems - Overview 
Section 7.3 introduced the basic means for defining and comparing various 
forms of sequential programmed graph replacement systems. It is the topic of 
this section to review previously made proposals for programmed grammars 
or - more specific - 
programmed graph grammars or replacement systems. 
The review is divided into three subsections: 

7.5. PROGRAMMED GRAPH REPLACEMENT SYSTEMS .. 
531 
I 
II 
I 
I 
I 1  
I 
I 
Separate Schema Definition 
11 
- 
+ 
- 
in [15] 
homomorph 
subgraph 
rule amal- 
gamation 
in 1301 
any graph 
+ n-C. (fix) 
graph in 1291 
+n-C. (fix) 
delete 
automatic 
deletion 
~ 
(simulation 
with 
amalga- 
mation 
possible) 
Table 7.1: Comparison of algorithmic and algebraic graph replacement approaches 

532 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
0 Subsection 7.5.1 introduces a number of programmed grammar for- 
malisms which preserve the declarative as well rule-oriented character of 
replacement systems. There exists still a single meta algorithm which ap- 
plies rules as long as appropriate and which takes additional information 
about rule preferences or required application sequences into account. 
0 Subsection 7.5.2 presents then a number of related programmed graph 
grammar approaches which belong to the application-oriented branch of 
algorithmic graph grammars. These approaches have in common that 
they adapt control structures of imperative programming languages for 
the purpose of controlling graph replacement rules. 
0 Finally, Subsection 7.5.3 deals with all those programmed graph gram- 
mars which belong to the family of algorithmic graph grammar ap- 
proaches, too, but use control flow diagrams instead of textually written 
control structures for regulating graph replacement processes. 
We will use a single example of a complex person database transformation to 
discuss the advantages and disadvantages of all presented approaches. This 
is an extended version of the transaction Marry* of Example 7.8. It assumes 
the existence of already introduced basic rules Marry and Markunmarried (cf. 
Example 7.8) as well as the new rule Deleteunmarried. The latter one fails if all 
person nodes are married and deletes a nondeterministically selected unmarried 
person node otherwise. 
Example 7.12 (Complex Database Transformation.) 
Marry* = (( (@(Markunmarried); Marry); Marry*) 0 &(Markunmarried)). 
Main = (Marry* 1 (undef(Marry*); (Deleteunmarried; Main))). 
0 
The transaction Main tries first to marry all singles in the database and termi- 
nates successfully if possible. Otherwise, the subtransaction Marry* fails and 
&(Marry*) 
succeeds. As a consequence, Deleteunmarried removes one person 
node from the database and Main calls itself again. The whole process stops 
as soon as all singles are either married or deleted. 
7.5.1 Declarative Rule Regulation Mechanisms 
This subsection presents three types of programmed graph grammars which 
preserve the rule-oriented and declarative character of rule-based systems. All 
of them offer only (very) limited support for determining the order of rule 
applications and have still the main match and replace loop of pure rule based 
systems. The main loop terminates if no more rules are applicable. The result 
is “per definition” an element of the specified language as long as terminals 
and nonterminals are not distinguished. 

7.5. PROGRAMMED GRAPH REPLACEMENT SYSTEMS ... 
533 
Having no user defined termination conditions at hand and almost no means 
to distinguish between failing and successful derivation sequences] it would be 
very difficult to simulate the behavior of the transactions Main and Marry*. 
Additional nonterminals, application conditions, and even new rules would be 
necessary to guarantee for instance that Deleteunmarried does not fire before 
all possible derivation sequences for Marry* failed. Therefore] we will not define 
our running example with the following formalisms: 
Definition 7.5.1 (Graph Grammars with Rule Priorities.) 
A graph grammar with rule priorities has an axiom plus a set of graph 
replacement rules P together with a partial order “<I1 
such that: 
with n E N and k : N + N.” 
The following transaction defines the semantics of rule priorities: 
with 
p := {PlJ,. . . ]Pl,k(l)I > . . ’  > {Pn,l,. . . lPn,k(l,n)l 
t = ((t’; t )  1 skip) 
t’= (tl 0 (undef(t1);tZ) 0 . . . 0 ((undef(t1) 0 . , . Oundef(tn-l));tn)) 
ti= (pi,l 0 ... ipz,k(il) for i := 1, ... ] n .  
- 
This definition of rule priorities is just an approximation of their usual seman- 
tics as e.g. in [8]. According to their definition over here, the execution of a 
lower priority rule is blocked as soon as a higher priority rule is executable, 
even in the case where both rules modify disjoint parts of a given graph. Unfor- 
tunately, a more liberal definition of rule priorities is beyond the capabilities of 
BCF expressions. This is a principle problem of our approach, since enlarging 
an already nonempty set of matches within a graph for a rule p may reduce the 
set of allowed matches of another graph replacement rule p’ with lower priority. 
This is a kind of nonmonotonic behavior, we are not able to deal with. 
A quite different rule regulation mechanism is studied in [15], so-called matrix 
(graph) grammars. They are simply sets of sequences of rules and have the 
following semantics: 
Definition 7.5.2 (Matrix Graph Grammars.) 
A matrix graph grammar has an axiom plus a set of graph replacement 
rule sequences of the form 
: N + N -  
The following transaction defines the semantics of such a set of sequences: 
with 
{(Pl,ll.. . lPl,k(l)),. . . 7 (Pn,ll.. . , P n , k ( n ) ) )  with n E N and 
t = ((t’; t )  0 __ 
skip) 
‘ N  := {0,1,. . . } is the set of all natural numbers including zero. 

534 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
t’= (tl 0 . . . 0 t,) 
ti=   pi,^ 0 undef(pi,l)); 
. . . ; (pi,k(i) 0 undef(~i,k(i)) for i := 1,. . . , n, 
i.e. rule sequences are selected and executed similar to simple rules of a gram- 
mar. Rules in a sequence are applied if possible and skipped otherwise. 
Another formalism studied in [15] are so-called programmed (graph) grammars 
which are at the borderline between purely declarative regulation mechanisms 
and programmed approaches in the sense of the following Subsection 7.5.2. 
They allow for the definition of atomic sequences of rule applications and 
support branching in the flow of control depending on success or failure of 
single rules. But without any support for functional abstraction they do not 
allow branching in the flow of control depending on success or failure of complex 
graph replacement processes. 
Definition 7.5.3 (Programmed Graph Grammars.) 
A programmed graph grammar over a set of gra.ph replacement rules P in 
the sense of [15] has an axiom plus a set of triples (pi,Ti,Fi) for i := 1,. . . ,n 
with components being defined as follows: 
(1) pi E P is the rule which has to be applied. 
(2) Ti := {pi,l,. . . , ~ i , k ( ~ ) }  
C P is the set of rules which may be applied after 
a successful replacement step with pi. 
(3) Fi := { P : , ~ ,  . . . ,&,(?} 
P is the set of rules which may be applied if 
the application of pi ails. 
The following transaction defines the semantics of this type of grammar: 
with 
where 
t = (tl 1 . . . 1 t,) 
ti= (Pi ; (ti,l 0 . ’. 0 ti,k(i))) 
n (undef(Pi); 
(CJ II . . . 0 t:,&f(z))) 
ti is the translation of (pi, 
{ P ~ J , .  
. . , ~ i , k ( i ) } ,  
{ & 7 . .  
. , P : , ~ , ( ~ ) } ) ,  
t,,jis the translation of (pi,j,. . .) for j := 1 , .  . . , k(i), and 
t:,jis the translation of (&,. . .) for j := 1 , .  . . ,k’(i). 
7.5.2 
Previously introduced regulation mechanisms were not adequate for defining 
complex graph transformation processes as those of our running Example 7.12. 
Therefore, new mechanisms had to be found, when people started to use graph 
grammars for specifying complex data structures of software engineering envi- 
ronments [21] or CAD systems [26]. In these cases it was quite natural to use 
control structures of imperative programming languages and to adapt them for 
the new purpose of regulating graph replacement processes. 
Programming with Imperative Control Structures 

7.5. PROGRAMMED GRAPH REPLACEMENT SYSTEMS ... 
535 
At the beginning, formal definitions of this kind of programmed graph gram- 
mars were rather vague. Furthermore, they didn’t make any attempts to resolve 
the conflict between nondeterministically working graph replacement rules and 
deterministically working control structures. Typical representatives of this cat- 
egory may be found in [23] and [38]. They are the direct predecessors of a new 
generation of programmed graph grammars which will be reviewed within this 
subsection. 
Let us start with the definition of a simplified version of control structures 
within the language PROGRES (cf. [66,71]). 
Definition 7.5.4 (Control Structures of PROGRES.) 
The control structures of PROGRES have about the following form and 
semantics 3 : 
(1) fail A undef(skip), 
the always failing command. 
the nondeterministic branch statement which executes either a or b. 
the deterministic branch statement which applies b if a would be applica- 
ble (testing applicability of a does not cause any graph modifications) 
and c otherwise. 
the deterministic and atomic sequence which fails whenever a or b fails. 
the nondeterministic sequence operator which executes a and b in arbi- 
trary order. 
(6) while def a & b 
the conditional iteration which executes b as long as a would be exe- 
cutable. 
(2) & a o J b d  A ( a i b ) ,  
(3) if def a then b & c end A ((&(a); b) 0 (&(a); 
c)), 
(4) = a ; b d  
A ( a ; b ) ,  
( 5 )  & a & b &  
A ( ( a ; b ) [ l ( b ; a ) ) ,  
1 call o f t  with t = ((&(a) ; ( b ; t ) )  [l undef(a)), 
Example 7.13 (The Transformation Main in PROGRES.) 
Using the control structure of Definition 7.5.4 we are able to produce a quite 
readable version of our running Example 7.12. 
Marry* = while def Markunmarried & Marry 4. 
Main = 
Marry* then Marry* else atom Deleteunmarried; Main end end. 0 
Another definition of programmed attributed graph grammars (PAGG) with 
imperative control structures may be found in [26,28]: 
3 The syntax is simplified for readability reasons and additionally available abbreviations 
etc. are not discussed. 
for often occurring control flow patterns like ‘‘M 
a then a else b 

536 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
Definition 7.5.5 (Control Structures of PAGG.) 
Control structures in PAGG have about the following form and semantics k :  
(1) - 
begin a ; b &  
A ((def(a)[[def(b));(a(Iundef(a));(b[Iundef(b))). 
(2) - 
try a & bend A (a 0 (&(a); 
b)). 
(3) repeat a & 5 call of t with t = (u; (t 0 undef(a))). 
These control structures compromise the required boolean nature and atomic 
character of graph transactions in favor of an efficiently working implementa- 
tion. They have to be read as follows: 
0 The construct - 
begin a ; b & requires sequential application of a followed 
by b. Its definition is rather complicated since its execution fails only if 
both a and b fail. Otherwise, the failing subexpression is skipped and the 
execution process continues. 
b & has the same semantics as the PROGRES 
control structureif a then a & b &. 
It may even be used with more 
than two arguments in the general case. 
0 The construct repeat a & applies a as long as possible and succeeds 
if a is applied at least once. It may also be used with more than one 
argument between repeat and &, 
but this is just a shorthand for a 
- 
begin/& 
sequence within repeat/&. 
Using the nonatomic sequence statement and offering no means which are 
equivalent to the previously introduced BCF operators def and undef (cf. 
Def. 7.3.5) reduces the expressiveness of PAGG significantly, but has the ad- 
vantage that an implementation has n o  needs for backtracking and undoing 
already performed graph modifications. Therefore, we are not able to provide 
the reader with a semantically equivalent PAGG version of transformation 
Main. Nevertheless, we will try to approximate the intended meaning as far as 
possible in order to illustrate the limitations of PAGG control structures: 
0 The construct try a 
Example 7.14 (The Transformation Main in PAGG.) 
Marry* = begin repeat Marry &; < fail if unmarried person exists > &. 
-- 
Main 
= repeat try Marry* & Deleteunmarried end end. 
0 
-- 
The problem with the example above is that we have no means to test whether 
a given graph replacement rule would be applicable without actually execut- 
ing it. And even replacing the needed test < fail i f . .  . > by a sequence like 
kThe original definition uses sapp instead of begin, capp instead of try and wapp instead 
- 
-- 
- - 
of repeat. 
- 

7.5. PROGRAMMED GRAPH REPLACEMENT SYSTEMS ... 
537 
- 
begin Markunmarried; Unmark & is useless, since unapplicable rewrite rules 
do not cause the failure of a sequence, but are simply skipped. 
Finally, we should emphasise that the discussed deficiencies of PAGG control 
structure are not relevant as long as specified graph transformation processes 
are deterministic or confluent. In this case, PAGG control structures are not 
only efficiently executable, but meet exactly the needs of their users. 
Another recently developed graph grammar programming approach I161 has 
about the same properties as PAGG and is, therefore, not discussed in further 
detail. It offers a combination of the already presented 
of PROGRES, its 
if then else with a restriction to boolean conditions, and finally the nonatomic 
begin/& 
of PAGG. 
- 
7.5.3 
Previous subsections presented typical exponents of various programmed graph 
replacement approaches. In all cases denotational semantics definitions were 
sketched by translating their control structures into BCF expressions with a 
well-defined fixpoint semantics definition. But all discussed approaches - 
ex- 
cept BCF expressions themselves and their more readable form in the language 
PROGRES - did not fulfill the list of requirements in Subsection 7.3.1. And 
even BCF expressions with their low level text representation compromise the 
visual nature of programming with graph replacement rules. 
An obvious solution for this problem is to replace text-oriented control struc- 
tures by some kind of control flow graphs. But almost all variants of control 
flow graphs do not fulfill all needed properties of control structures, too: 
0 Control flow graphs which are not allowed to call each other, i.e. do not 
properly support functional abstraction, are defined in [11,12]. 
0 In [45] control flow graphs are introduced, where a node may be a call to 
another control flow graph, but where branching depending on success 
or failure of subgraph calls is not supported. 
0 And [66] presents a variant of control flow graphs without the above 
mentioned deficiencies, but also without a nonoperational semantics de- 
finition. 
In the sequel, we will show how BCF expressions may be used to define a 
fixpoint semantics for the control flow graphs of [66]. These control flow graphs 
have about the same properties as previously defined transactions (boolean 
character etc.). Furthermore, they have the same expressive power as BCF 
expressions with the strict def" operator version and without the intersection 
operator &. Figure 7.14 contains an example of a control flow graph with two 
additional subgraphs. Their main properties are: 
Programming with Control Flow Graphs 

538 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
Main = 
Many* = 
NoMoreSingles = 
call Marry* 
undef 
call DeleteUnmarried 
call Main 
Figure 7.14: The control flow graph version of transformation Main 
Any vertex in a subgraph should be reachable from its unique start vertex 
and should have a path to its unique stop vertex. 
The execution of a (sub-)graph beginsatits 
vertex and ends at its 
stop vertex. 
=ma1 
vertices in the graph have a basic action as inscription, which 
is either nop or the call of a simple rewrite rule or (the start vertex of) 
another control flow subgraph. 
0 The execution of a vertex either succeeds or fails; execution of start, - 
stop, 
and nop vertices always succeeds without any effects. 
Aftersuccessful execution of a vertex we have to follow one of its outgo- 
ing def edges; multiple def edges reflect nondeterministic computations 
and absence of def edges partially defined computations. 
After a failing execution of a vertex we have to follow one of its outgoing 
undef edges; multiple undef edges reflect again nondeterministic compu- 
tations and absence of undef edges again partially defined computations. 
For a more detailed explanation of this kind of control flow graphs, including an 
operational semantics definition, the reader is referred to [66]. A denotational 
semantics definition may be provided by translating a control flow graph into 
an equivalent set of transactions (BCF expressions). Any vertex of the control 
flow graph will be translated into a transaction with calls to other transactions 
reflecting its outgoing def and undef edges: 
Definition 7.5.6 (Semantics of Control Flow Graphs.) 
The semantics of a set of control flow (sub-)graphs over a set of graph 
replacement rules P and a set of control flow vertices V is defined as follows: 

7.5. PROGRAMMED GRAPH REPLACEMENT SYSTEMS ... 
539 
Any vertex v of the control flow graphs with inscription “caJ a” or “m” 
or 
“nop” with outgoing “M’ edges to vertices w1,. . . , V k ,  and outgoing “Undef)’ 
edges to vertices wi, . . . ,211, is translated into: 
w = ((z; (211 0 . . . 0 wk)) 0 (undef(z); 
(wi 0 . . . 0 vi,))), if k ,  k’ > 0, 
and into 
2) = ( x ;  (w1 0 . ’ .  0 Vk)), 
w = (undef(x); (wi 0 . . . 0 w;,)), 
if k > 0, k’ = 0 
if k = 0, k’ > 0 
and into 
w = fail = undef(skip), 
where 
x = a, 
z = skip, 
otherwise. 
if k = 0, k’ = 0 
if inscription of w is “caJ a” and a E P U V 
~ 
FinallGny vertex n with inscription “stop” 
- 
is translated into the transaction 
therebyterminating the execution of its control flow subgraph successfully. 
Please note that this definition of control flow graphs is almost identical to the 
Definition 7.5.3 of programmed graph grammars. The essential difference is 
that control flow graphs know the concept of functional abstraction. Thereby, 
calls to complex subdiagrams may be treated in the same way as calls to simple 
rules. In this way, arbitrary forms of recursion are supported and complex 
conditions may be defined which cause failure or successful termination of 
derivation (sub-)processes. 
Proposition 7.5.7 (Equivalence of BCFs and Control Flow Graphs.) 
Any set of transactions with BCF expressions as their bodies - without the 
intersection operator & and with a strict defm operator version instead of the 
original def version (cf. Definition 7.3.5 and Definition 7.3.6) - 
may be trans- 
lated into an equivalent set of control Aow graphs according to Definition 7.5.6 
and vice versa. 
Proof: 
The translation from control Aow graphs into BCF expressions is already part 
of their Definition 7.5.6. The other direction follows also directly from Defini- 
tion 7.5.6. Rule sequences, nondeterministic branching, the operator skip, and 
calls to subprograms are directly supported. And undef(a); . . . may besimu- 
lated by a vertex with inscription a, no outgoingdef edge and a single outgoing 
undef edge to another vertex which represents the following computation step 
within the expression &(a);. 
. . . Finally, an expression of the form &*(a) 
0 
w = skip, 
is equivalent to undef(undef(a)) (cf Definition 7.3.6). 

540 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
Simple Rule 
Priorities (here) 
Sequ. Atomic 
Nondeterm. 
Success & 
Recursive 
Control Flow 
Control Flow 
Failure Test 
Calls 
no 
no 
no 
no 
Matnx Grammars 
atomic 
Programmed 
nonatomic 
rules 
sequence 
Grammars [ 131 
sequence 
rules 
Grammars [25,26] 
sequence 
only 
Paradigm 
& Notation 
declarative 
& text-oriented 
decl ./imperative 
& text-oriented 
decl./imperative 
& text-oriented 
imperative 
& text-oriented 
imperative 
& text-oriented 
imperative 
& text-oriented 
parallel imper. 
& text-oriented 
imperative 
& graphical 
imperative 
& graphical 
imperative 
& graphical 
Table 7.2: A comparison of various rule-regulation mechanisms 
Using the construction of the proof above, we are now able to translate Exam- 
ple 7.12 into a control flow diagram and the BCF expressions of the control 
flow diagrams of Figure 7.14 into BCF expressions. Please note that the results 
of these translation processes are always more complex structured than their 
inputs. Therefore, Example 7.12 and Figure 7.14 are translations of each other 
(in the sense of Proposition 7.5.7) followed by a number of semantic preserving 
simplification steps (cf. Def 7.3.5 and 7.5.6). 
7.5.4 Summary 
Within this section various approaches for sequential programming with graph 
replacement rules were defined and compared with each other by translat- 
ing them into equivalent BCF expressions. The results of our discussion are 

REFERENCES 
541 
summarized in Table 2 with column headlines referring to required rule pro- 
gramming properties in Subsection 7.3.1. This table shows that all proposed 
regulation mechanisms have their deficiencies. All of them - except PRO- 
GRES (Def. 7.5.4) and control flow graphs (Def. 7.5.6) - have difficulties 
with guaranteeing properties of simple graph replacement steps for complex 
transformation processes, too. Even worse, not a single approach is existent 
which supports parallel programming and testing success or failure of complex 
subtransformations at the same time. It is subject to future work to find out 
whether it is possible to combine the trace-based fixpoint semantics for parallel 
graph replacement systems in [45] with the fixpoint semantics approach over 
here for the definition of the operators &f 
and &f 
(see also Subsection 7.3.5). 
Acknowledgments 
The author is most grateful to Manfred Na.gl, Gregor Engels, Claus Lewerentz, 
Bernhard Westfechtel, Andreas Winter, Albert Ziindorf, and other (former) 
members of the IPSEN project for many stimulating discussions about pro- 
grammed graph replacement systems and their invaluable efforts to pave the 
way for the work presented here. Furthermore, thanks to the two anonymous 
referees of this chapter for their helpful comments on a previous version, to An- 
dre Speulmanns for producing a first version of Table 1 (comparison of graph 
replacement approaches), and to Alexander Bell for his excellent Framemaker 
to IN$$ compiling job. 
References 
1. V. Claus, H. Ehrig, G. Rozenberg (eds.): Proc. Int. Workshop on Graph 
Grammars and Their Application to Computer Science and Biology, 
LNCS 73, Springer Verlag (1979) 
2. H. Ehrig, M. Nagl, G. Rozenberg (eds.): Proc. 2nd Int. Workshop on 
Graph Grammars and Their Application to Computer Science, LNCS 
153, Springer Verlag (1983) 
3. H. Ehrig, M. Nagl, G. Rozenberg, A. Rosenfeld (eds.): Proc. 3rd Int. 
Workshop on Graph Grammars and Their Application to Computer Sci- 
ence, LNCS 291, Springer Verlag (1987) 
4. H. Ehrig, H.-J. Kreowski, G. Rozenberg (eds.): Proc. 4th Int. Workshop 
on Graph Grammars and Their Application to Computer Science, LNCS 
532, Springer Verlag (1991) 
5 .  J. Cuny, H. Ehrig, G. Engels, G. Rozenberg (eds.): Proc. 5th Int. Work- 
shop on Graph Grammars and Their Application to Computer Science, 
LNCS 1073, Springer Verlag (1996) 

542 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
6. G. Ausiello, P. Atzeni (eds.): Proc. Int. Conf. on Database Theory, LNCS 
243, Springer Verlag (1986) 
7. D. Blostein, H. Fahmy, A. Grbavec: Practical Use of Graph Rewriting, 
in: [5], 38-55 
8. I. Litowsky, Y. Metevier: Computing with Graph Rewriting Systems, in: 
Theoretical Computer Science, 115, Amsterdam: Elsevier Science Publ. 
9. P. Boehm, H.-R. Fonio, A. Habel: Amalgamation of Graph Transforma- 
tions with Applications to Synchronization, in: H. Ehrig, C. Floyd, M. 
Nivat, J. Thatcher (eds.): Mathematical Foundations of Software Devel- 
opment, LNCS 185, Springer Verlag (1985), 267-283 
10. F. Bry, R. Manthey, B. Martens: Integrity Verification in Knowledge 
Bases, in: [73], 114-139 
11. H. Bunke: Seguentielle und parallele programmierte Graphgrammatiken, 
Dissertation, TR No. IMMD-7-7, Universitat Erlangen, Germany (1974) 
12 H. Bunke: Attributed Programmed Graph Grammars and Their Appli- 
cation to Schematic Diagram Interpretation, IEEE Pattern Analysis and 
Machine Intelligence, Vol. 4, No. 6, IEEE Computer Society Press (1982), 
13. B. Courcelle: Graphs as Relational Structures: An Algebraic and Logical 
Approach, in: [4], 238-252 
14. E.W. Dijkstra: Guarded Commands, Nondeterminacy, and Formal 
Derivation of Programs, in: Communications of the ACM, No. 18, acm 
Press (1975), 453-457 
15. J. Dassow, G. Paun: Regulated Rewriting in Formal Language Theory, 
EATCS 18, Springer Verlag (1989) 
16. H. Dorr: Eficient Graph Rewriting and its Implementation, Ph.D. Thesis, 
FU Berlin, LNCS 922, Springer Verlag (1995) 
17. A. Corradini, R. Heckel: A Compositional Approach to Structuring and 
Refinement of Typed Graph Grammars, appears in: A. Corradini, U. 
Montanari (eds.): Proc. Joint COMPUGRAPH/SEMAGRAPH Work- 
shop on Graph Rewriting and Computation, Electronic Notes in Theo- 
retical Computer Science (ENTCS), Amsterdam: Elsevier Science Publ. 
18. H. Ehrig, A. Habel, H.-J. Kreowski, F. Parisi-Presicce: From Graph 
Grammars to High-Level Replacement Systems, in: [4] , 269-291 
19. H. Ehrig: Introduction to the Algebraic Theory of Graph Grammars (a 
Survey), in: [l], 1-69 
20. H. Ehrig, M. Korff, M. Lowe: Tutorial Introduction to the Algebraic Ap- 
proach of Graph Grammars Based on Double and Single Pushouts, TR 
No. 90/21, TU Berlin, Germany (1990) 
(1993), 191-224 
574-582 
(1995), 167-176 

REFERENCES 
543 
21. G. Engels, C. Lewerentz, M. Nagl, Schafer, A. Schurr: Building Integrated 
Software Development Environments Part I: Tool Specification, in: ACM 
Transactions on Software Engineering and Methodology, Vol. 1, No. 2, 
acm Press (1992), 135-167 
22. G. Engels, C. Lewerentz, W. Schafer: Graph Grammar Engineering: A 
Software Specification Method, in: [3], 186-201 
23. G. Engels: Graphen als zentrale Datenstrukturen in einer Software- 
Entwicklungsumgebung, Dissertation, Universitat Osnabruck, VDI Verlag 
(1986) 
24. H. Fahmy, B. Blostein: A Graph Grammar Programming Style for Recog- 
nition of Music Notation, Machine Vision and Applications, Vol. 6, No. 
2 (1993), 83-99 
25. H. Gallaire: Logic and Data Bases, Plenum Press (1978) 
26. H. Gottler, J. Gunther, G. Nieskens: Use Graph Grammars to Design 
27. H. Gottler: Attribute Graph Grammars for Graphics, in: [a], 130-142 
28. H. Gottler: Graphgrammatiken in der Softwaretechnik, IFB 178, Springer 
Verlag (1988) 
29. P. Van Hentenrynck: Constraint Satisfaction in Logic Programming, MIT 
Press (1989) 
30. A. Habel, R. Heckel, G. Taentzer: Graph Grammars with Negative Ap- 
plication Conditions, in: [57], 287-314 
31. R. Heckel, J. Muller, G. Taentzer, A. Wagner: Attributed Graph Transfor- 
mations with Controlled Application of Rules, in: G. Valienete Feruglio, 
F. Rossello Llompart: (eds.): Proc. Colloquium on Graph Transforma- 
tion and its Application in Computer Science, Technical Report B-19, 
Universitat de les Illes Balears (1995), 41-54 
32. S.E. Hudson: Incremental Attribute Evaluation: an Algorithm for Lazy 
Evaluation in Graphs, TR No. 87-20, Unviersity of Arizona (1987) 
33. S. Kaplan, J. Loyall, S. Goering: Specifying Concurrent Languages and 
Systems with A-Grammars, in: [4], 475-489 
34. M. Korff: Algebraic Transformation of Equationally Defined Graph Struc- 
tures, TR No. 92/32, TU Berlin, Germany (1992) 
35. H.-J. Kreowski, G. Rozenberg: On Structured Graph Grammars: Part 1 
and 11, TR No. 3/88, University of Bremen, FB Mathematik/Informatik, 
Germany (1988) 
36. H.-J. Kreowski, Graph Grammars for Software Specification and Pro- 
gramming: An Eulogy in Praise of Grace, in: G. V. Feruglio, F. R. Llom- 
part (eds.), Proc. Colloquium on Graph Transformation and its Appli- 
cation in Computer Science, Technical Report, B-19, Universitat de les 
Illes Balears, 55-62 
CAD-Systems, in [4], 396-410 

544 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
37. N. Kiesel, A. Schurr, B. Westfechtel: GRAS, a Graph-Oriented Database 
System for (Software) Engineering Applications, Information Systems, 
Vol. 20, No. 1, Pergamon Press (1995), 21-51 
38. C. 
Lewerentz: 
Interaktives Entwerfen groper Programmsysteme, 
Konzepte und Werkzeuge, Dissertation, RWTH Aachen, IFB 194, 
Springer Verlag (1988) 
39. M. Lowe, M. Korff, A. Wagner: An Algebraic Framework for the Trans- 
formation of Attributed Graphs, in: [70], 185-199 
40. M. Lowe: Algebraic Approach to Graph Transformation Based on Sin- 
gle Pushout Derivations, Ph.D. Thesis, TR No. 90/5, Fachbereich Infor- 
matik, TU Berlin, Germany (1990) 
41. Z. Manna: Mathematical Theory of Computation, McGraw-Hill, USA 
(1974) 
42. J. Mylopoulos, A. Borgida, M. Jarke, M. Koubarkis: Telos: a Language 
for Representing Knowledge about Information Systems, ACM Transac- 
tions on Information Systems, Vol. 8, No. 4, acm Press (1990), 325-362 
43. J. Minker: Perspectives in Deductive Databases, in: The Journal of Logic 
Programming, Elsevier Science Publ. (1988) , 33-60 
44. A. Maggiolo-Schettini, J. Winkowski: Programmed Derivations of Rela- 
tional Structures, in: [4], 582-598 
45. M. Nagl: Graphgrammatiken, Vieweg Verlag (1979) 
46. M. Nagl: A Tutorial and Bibliographical Survey on Graph Grammars, in: 
47. M. Nagl: Graph Technology Applied to a Software Project, in: [56], 303- 
48. M. Nagl: Characterization of the IPSEN Project, in: [74], 196-201 
49. Sh.A. Naqvi: Some Extensions to the Closed World Assumption in Data- 
bases, in: IS], 341-348 
50. Sh.A. Naqvi: Negation as Failure for First-Order Queries, in: Proc. 5th 
SIGACT-SIGMOD Symp. on Principles of Database Systems, acm Press 
51. G. Nelson: A Generalization of Dijkstra’s Calculus, in: ACM Transac- 
tions on Programming Languages and Systems, Vol. 11, No. 4, acm Press 
(1989), 517-561 
52. H. Noltemeier (ed.): Graphen, Algorithmen, Datenstrukturen, Proc. 2nd 
Workshop on Graphtheoretic Concepts in Computer Science (WG ’76), 
Applied Computer Science 4, Hanser Verlag (1976) 
53. M. Nagl, A. Schurr: A Specification Environment for Graph Grammars, 
in: [4], 599-609 
[l], 70-126 
322 
(1986), 114-122 

REFERENCES 
545 
54. Sh.A. Naqvi, Sh. Tsur: Data and Knowledge Bases, IEEE Computer So- 
55. J.L. Pfaltz, A. Rosenfeld: Web Grammars, Proc. Int. Joint Conf. Artifi- 
56. G. Rozenberg, A. Salomaa (eds.): The Book of L, Springer Verlag (1986) 
57. G. Engels, H. Ehrig, G. Rozenberg (eds.): Special Issue on Graph Trans- 
formation Systems, Fundamenta Informaticae, VoI. 26, No. 314 (1996), 
No.1/2, 10s Press (1995) 
58. J. Rekers, A. Schiirr: A Parsing Algorithm for Context-Sensitive Graph 
Grammars, appears in: Journal of Visual Languages and Computing, Vol. 
7, No. 3, Academic Press (1996) 
59. H. Rybinski: On First-Order-Logic Databases, in: ACM Transaction on 
Database Systems, Vol. 12, No.3, acm Press (1987), 325-349 
60. G. Schied: Uber Graphgrammatiken: Eine Spezifikationsmethode fur Pro- 
grammiersprachen und verteilte Regelsysteme, Dissertation, TR No. 
IMMD-25-2, Universitat Erlangen (1992) 
61. G. Schmidt, R. Berghammer (eds.): Proc. Int. Workshop on Graph- 
Theoretic Concepts in Computer Science (WG '91), LNCS 570, Springer 
Verlag( 1991) 
62. H.J. Schneider: Chomsky-Systeme fur partielle Ordnungen, TR No. 
IMMD-3-3, Universitat Erlangen, Germany (1970) 
63. H.J. Schneider, H. Ehrig (eds.): Proc. Int. Workshop on Graph Transfor- 
mations in Computer Science, LNCS 776, Springer Verlag (1994) 
64. H.J. Schneider: Conceptual Database Descriptions Using Graph Gram- 
mars, in: [52], 77-98 
65. A. Schiirr: PROGRES: A VHL-Language Based on Graph Grammars, 
in: [4], 641-659 
66. A. Schiirr: Operationales Spezifizieren mat Programmierten Grapherset- 
zungsystemens: Formale Definitionen, Anwendungen und Werkzeuge, 
Dissertation, RWTH Aachen, Deutscher Universitatsverlag (1991) 
67. A. Schiirr: Logic Based Structure Rewriting Systems, in: [63], 341-357 
68. A. Schiirr: Logic Based Programmed Structure Rewriting Systems, in: 
69. A. Schiitte: Spezifikation und Generierung von Ubersetzern fur Graph- 
sprachen durch attributierte Graphgrammatiken, Dissertation, EWH 
Koblenz, Express Edition (1987) 
70. M.R. Sleep, M.J. Plasmeijer, M.C. van Eekelen (eds.): Term Graph 
Rewriting: Theory and Practice, John Wiley & Sons Ltd (1993) 
71. -4. 
Schiirr, A. Ziindorf: Non-Deterministic Control Structures for Graph 
Rewriting Systems, in: [61], 48-62 
ciety Press (1989) 
cial Intelligence, Washington (1969), 609-619 
[57], 363-386 

546 CHAPTER 7. PROGRAMMED GRAPH REPLACEMENT SYSTEMS 
72. G. Taentzer, ILI. Beyer: Amalgamated Graph Transformations and Their 
Use for Specifying AGG - an Algebraic Graph Grammar System, in: [63], 
73. A. Voronkov (ed.): Logic Programming, LNCS 592, Springer Verlag 
74. H. Weber (eds.): Proc. of the Int. Conf. on Systems Development and 
Factories, Pittmann Press (1990) 
75. B. Westfechtel: Revisionskontrolle in einer integrierten Software- 
entwicklungs- Umgebung, Dissertation, RWTH Aachen, Informatik- 
Fachberichte 280, Springer Verlag (1991) 
76. .I. Zundorf: Eine Entwicklungsumgebung fur PROgrammierte GRaph- 
ErsetzungsSysteme, Dissertation, RWTH Aachen, Deutscher Univer- 
sitiitsverlag (1996) 
380-394 
(1991) 

Index 
C-formulas, 487 
C-morphism, 494 
C-relation, 493 
C-structure, 488 
C-terms, 487 
Graph 
2-structure, 404 
category, 183 
A-edNCE, 58 
abstract C-st ruct ures, 502 
algebra, 289 
almost k-connected, 149 
alternating text, 442 
amalgamated graph replacement 
amalgamated union, 459 
analysis construction, 199 
angular 2-structure, 434 
apex, 58 
application condition, 280 
application conditions, 527 
associativity, 105 
attachment, 102 
attr, 487 
attributes, 527 
automorphism, 183 
autonomous set, 429 
rules, 523 
B,d-edNCE, 56 
B-edNCE, 55 
backtracking, 509 
basic actions, 508 
BCF expressions, 512 
bi-degree, 59 
block, 150 
blocking edges, 31 
bond, 149 
boundary, 55 
boundedness problems, 138 
bucket of triangles, 474 
Butterfly Lemma, 232 
C-edNCE grammar, 34 
c-labeled derivation tree, 44 
category, 494 
center of a group, 472 
chain, 150 
Chomsky Normal Form, 63 
clan, 408, 444, 454 
clan decomposition, 421 
closed walk, 472 
closed world assumption, 488 
co-equalizer, 253 
cograph, 29 
collapsed split tree, 150 
colouring, 405 
compatible function, 136 
compatible predicate, 133 
complete l2-structure, 445 
complete 2-structure, 419 
complete set of invariants, 475 
completing operator, 488 
547 

548 
INDEX 
componentwise derivations, 86 
composition, 118 
concrete C-structures, 502 
condition 
dangling, 189 
gluing, 189 
identification, 189 
conflict-free, 257 
conff uence, 105 
confluent, 34 
congruence partition, 429 
connected 2-structure, 436 
connected component, 148, 436 
connection instruction, 17 
connection relation, 17 
constant selector, 456 
constraint, 280 
constraints, 496 
cont,ext conditions, 526 
context consistent, 67 
context-freeness lemma, 112 
control flow (sub-)graphs, 538 
control-flow graph, 106 
coproduct, 228 
choice of, 229 
commutativity, 230 
functor, 229 
uniqueness, 229 
creative derivation, 22 
critically primitive, 431 
d-complete, 257 
d-inj ective, 2 5 7 
dangling condition, 189, 281 
dangling edge condition, 522 
dangling references, 502 
decomposition, 444 
decomposition of 2-structures, 413 
degree, 142 
deleting/preserving conflicts, 501 
DELTA, 522 
depth-first search, 509 
derivable, 487 
derivation, 105, 255 
amalgamated, 274 
canonical, 205 
conditional, 280 
derived, 271 
direct, 255 
directly derived, 269 
distributed, 275 
HLR, 295 
identity, 191 
length of, 191 
parallel, 195, 264 
parallel conditional, 285 
sequential, 191 
sequential composition, 191 
derivation tree, 114 
derivations 
completeness of, 299 
invertibility of, 299 
isomorphism of, 209 
translation of, 299 
derived attributes, 528 
Derived Production Problem, 177, 305 
Derived Production Theorem, 223, 271 
deterministic tree-walking trans- 
direct derivable, 500 
direct derivation, 105 
Double-Pushout Approach, 190 
empty, 195 
parallel, 195 
disjoint union, 457 
Distribution Problem, 179, 307 
Distribution Theorem, 226, 276 
domain, 404 
DPO, 522 
dynamic C2-structure1 450 
ducer , 127 

INDEX 
549 
dynamically confluent, 36 
edge, 404, 487 
edge class, 405 
edge complement, 71 
edge replacement grammar, 106 
edNCE grammar, 21 
embedding, 269 
completeness of, 306 
embedding morphism, 269 
Embedding Problem, 176, 306 
Embedding Theorem, 223, 273 
embedding transformation, 521 
embedding transformation rules, 524 
equational set, 359 
equivalence 
El, 212 
shift, 203 
~
3
,
 
216 
equivalent f?2-structures, 470 
equivalent words, 470 
EXP, 521 
extension, 284 
external node, 102 
factor, 412 
factor of a 2-structure, 408 
factorization, 412, 444, 460 
feature, 436 
filter theorem, 134 
finiteness problem, 120 
fixed-point , 11 7 
fixed-point theorem, 117 
fixpoints, 516 
folding, 522 
form, 468 
frame, 415 
free invariant, 471 
generalized graph structure, 293 
gluing approach, 521 
gluing condition, 189, 281, 522 
GRACE, 519 
graph, 102 
abstract, 183 
attributed, 289 
context, 190 
distributed, 274 
interface, 185 
labeled, 183 
graph grammar, 185, 252 
graph language, 255 
graph morphism 
attributed, 290 
partial, 251 
total, 183 
graph structure, 292 
graph with embedding, 17 
graph, grid, 332 
graph, HR set of graphs or hyper- 
graph, operation on graphs or hy- 
graph, port in a graph, 362 
graph, source, 367 
graph,transduction, 346 
graphical embedding rules, 525 
growing 
hyperedge 
replacement 
grammar, 118 
graphs, 371 
pergraphs, 362 
Hamiltonian path problem, 142 
handle, 103 
hierarchy theorem 1, 125 
hierarchy theorem 2, 127 
HLR system, 295 
categories, 295 
conditions, 295 
homogeneous 
hypergraph 
lan- 
guage, 106 
homomorphism, 289 
horizon, 455 

550 
INDEX 
hyperedge, 102 
hyperedge replacement, 104 
hyperedge replacement grammar, 106 
hyperedge replacement language, 106 
hypergraph, 102, 292 
hypergraph, transduction, 346 
hypergraphs, 339 
identification condition, 189, 281, 522 
incremental attribute evaluation, 529 
independence 
parallel, 192, 260, 282, 301 
sequential, 193, 262, 283, 301 
induced subgraph, 521 
inductive set of predicates, 373 
integrity constraints, 489 
intrinsic attributes, 528 
invariant, 470 
inversive C2-structure, 469 
involution, 449, 469 
IPSEN, 482 
isolated clan, 455 
isomorphic, 103 
isomorphic C2-structures, 443 
iterated composition, 118 
Ic-tree, 124 
L-edNCE, 39 
label, 102 
labeled 2-structure, 442 
language, 504 
leaf, 432 
least fixed-point , 117 
left-hand side, 105 
LIN-edNCE, 58 
linear, 58 
linear l2-structure, 445 
linear 2-structure, 419 
linear 
hyperedge 
replacement 
grammar, 142 
Local Church Rosser Problem, 173 
Local Church-Rosser Problem, 301 
Local Church-Rosser Theorem, 263 
DPO approach, 194 
with application conditions, 283 
logic, first-order, 318 
logic, monadic second-order, 320, 340 
logic, second-order, 319 
LSBR System, 503 
magma, 356 
magma, many-sorted, 357 
magma, power-set, 358 
match, 190, 255 
distributed, 275 
HLR, 295 
matrix graph grammar, 533 
maximal clan, 416 
maximal prime clan, 416, 445 
maximal prime factor, 416 
membership problem, 141 
minor, 391 
model of computation 
abstract, 217 
abstract, truly-concurrent, 218 
concrete, 202 
truly-concurrent, 203 
modular decomposition, 403 
monoid with involution. 470 
NCE, 9 
negative context condition, 526 
neighbourhood preserving, 66 
NLC, 5 
node, 404, 487 
node class, 490 
node degree, 142 
nonblocking, 33 
nonmonotonic reasoning, 488 
nonterminal, 106 
nonterminal bounded, 59 

INDEX 
551 
nonterminal degree, 57 
morphism, 252 
nonterminal neighbour deterministic, 56 
normal set system, 429 
name, 252 
parallel, 194, 264 
obstruction, 392 
Operator Normal Form, 65 
order, 106 
order, linear, 342 
order, partial, 334 
overlap, 410 
p-labeled derivation tree, 50 
packed component, 405 
packing, 405 
PAGG, 482, 522, 536 
parallel independence, 192 
Parallelism Problem, 175, 302, 303 
Parallelism Theorem 
parallelization, 105 
Parikh mapping, 122 
Parikh’s theorem, 122, 385 
parsing problem, 141 
partial k-tree, 124 
partial order, 438 
path expression, 525 
paths, 491 
plane, 462 
plane tree, 463 
polynomial system, 359 
prime clan, 411, 445 
prime factor, 412 
prime tree, 422, 445 
primitive 2-structure, 408, 419 
production, 105, 106, 185, 252, 498 
DPO approach, 197 
amalgamated, 274 
conditional, 280 
derived, 223, 271 
directly derived, 221, 269 
empty, 195 
HLR, 295 
parallel conditional, 285 
sequential composition, 222 
sequential composition of, 270 
span-isomorphic, 185 
synchronized, 273 
translation of, 298 
productions 
programmed graph grammar, 534 
PROGRES, 482, 522, 535 
proper clan, 408 
pumping lemma, 119 
pushout, 187, 254, 257, 290 
object, 188 
pushout complement, 188 
object, 188 
quotient, 444, 460 
quotient of a 2-structure, 412 
r-separability, 84 
recognizable set, 373 
regular path description, 69 
regular tree grammar, 68, 127 
regular tree language, 69 
relation, 493 
replacement, 104 
representation of graphs, 406 
reverse class, 407 
reverse edge, 404 
reversible, 442 
reversible C2-structure, 450 
reversible 2-structure, 407 
right-hand side, 105 
RPD, 70 
rule priorities, 533 
S-HH, 79 
satisfiability problem, 322 

552 
INDEX 
schema, 489 
schema consistent, 490 
Seidel switching, 451 
selection, 439 
selector, 450 
semantic domain, 511 
semantic function, 512, 516 
semi-structured program, 106 
semilinear set, 122 
separability, 148 
separated 
handle 
hypergraph 
grammar, 79 
sequential independence, 193 
sequentialization, 105 
set system, 429 
shape, 422, 446 
shift equivalence, 203 
shift relation, 205 
siba, 427 
signature, 289, 486 
signed graph, 452 
similar split trees, 151 
size (of hypergraph), 102 
special 2-structure, 418 
split decomposition, 438 
split tree, 150 
splitting 
graph structure, 292 
partial, 275 
total, 275 
SPO, 522 
standard isomorphisms, 215 
star, 29 
start graph, 185, 252 
start symbol, 106 
strict isomorphism, 443 
string graph, 102 
structure morphism, 494 
structure replacement rule, 498 
structure(logical), 317 
sub-hypergraph, 103 
subgraph, 251 
subproduction, 273 
substantial hypergraph, 118 
substitution, 458 
substitution composition, 429 
substructure, 407, 444, 495 
symmetric edge, 405 
symmetric edge class, 405 
synthesis construction, 199 
system of equations, 117 
T-structure, 438 
Telos, 490 
terminal, 106 
text, 440 
theory, 322 
total split tree, 150 
transactions, 507, 512 
transformation units, 519 
tree, 344 
tree-walking transducer, 127 
tree-width, 396 
triangle, 473 
trivial clan, 408 
truly primitive 2-structure, 419 
two-graph, 452 
type, 102, 487 
typing function, 102 
underlying 2-structure, 443 
uniformly non-primitive, 433 
unlabelled, 102 
unstable !2-structure, 432 
variable, 470 
variable function, 470 
VR set of graphs, 364 
Weak Parallelism Theorem, 265 
with application conditions, 286 

INDEX 
wheel, 29 
X-candidate, 147 
yield, 47 
553 


