HAL Id: tel-01157834
https://tel.archives-ouvertes.fr/tel-01157834
Submitted on 28 May 2015
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not.
The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
Two Bayesian learning approaches to image processing
Yiqing Wang
To cite this version:
Yiqing Wang. Two Bayesian learning approaches to image processing. Other [cs.OH]. École normale
supérieure de Cachan - ENS Cachan, 2015. English. ￿NNT : 2015DENS0007￿. ￿tel-01157834￿

Ecole Normale Supérieure de Cachan
Centre de Mathématiques et de Leurs Applications
Dissertation
submitted in fulﬁllment of the requirements
for the degree of Doctor of Philosophy in Applied Mathematics
by
Yi-Qing Wang
Two Bayesian learning approaches
to image processing
Thèse soutenue le 2 Mars 2015 devant le jury composé de :
M.
Boaz Nadler
Weizmann Institute of Science
Rapporteur
M.
Gabriel Peyré
CEREMADE, Université Paris-Dauphine
Rapporteur
M.
Jean-Michel Morel
Ecole Normale Supérieure de Cachan
Directeur
M.
Alain Trouvé
Ecole Normale Supérieure de Cachan
Président du jury
M.
Frédéric Guichard
DxO Labs
Examinateur
M.
Charles Kervrann
INRIA Rennes
Examinateur


Dedicated to my parents


Acknowledgements
I
would like to express my profound appreciation and gratitude to my
advisor Prof. Jean-Michel Morel for having given me the opportunity to
embark on this enriching journey and providing me guidance and mentor-
ship throughout the process. I have beneﬁted enormously from his deep
understanding of wide-ranging subjects including, but not limited to im-
age processing. His passion and intuition for the discipline is what I have
been trying to measure up to. Our weekly discussions and frequent email
exchanges on my ongoing work as well as general research philosophy
and methodologies will remain one of my fondest memories.
I am also indebted to Prof. Nicolas Vayatis for offering me to work as
his teaching assistant for two years in the courses on the theoretical foun-
dations of machine learning. It greatly expanded my knowledge of what
the probability community has accomplished over the past few decades in
understanding various data analysis tools. This role also added a unique
dimension to my experience of academic life.
I would also like to thank Dr. Christophe Labourdette and Prof. Alain
Trouvé for being so forgiving of my running a horrible amount of train-
ing programs on their CPU and GPU servers. In a similar vein, I would
like to thank the exceptionally knowledgeable and talented Drs. Enric
Meinhardt-Llopis and Nicolas Limare for being extremely nice and pa-
tient with my dumb questions.
CMLA’s staff members Mmes. Véronique Almadovar, Micheline
Brunetti, Sandra Doucet, Virginie Pauchont and Carine Saint-Prix cer-
tainly deserve special thanks. My days at the laboratory would not have
been so smooth if it were not for their always timely help.
I am very grateful to Prof. Boaz Nadler and Dr. Gabriel Peyré for their
time in reviewing this thesis and to Dr. Frédéric Guichard, Dr. Charles
Kervrann and Prof. Alain Trouvé for agreeing to be my thesis committee
members.
I appreciate the generosity of DxO Labs which provided part of the
funding for my research.
Finally, to my parents, it is your love that gives me the strength to
complete the present work.
v


Title
Two Bayesian learning approaches to image processing
Abstract
This work looks at two patch based image processing meth-
ods in a Bayesian risk minimization framework. We describe a Gaussian
mixture of factor analyzers for local prior modelling and apply it in the
context of image denoising and inpainting. We also study multilayer neu-
ral networks from a probabilistic perspective as a tool for conditional ex-
pectation approximation, which suggests ways to reduce their sizes and
training cost.
Keywords
Bayesian modelling, conditional expectation, mixture of fac-
tor analyzers, artiﬁcial neural network, image processing
Titre
Traitement d’images par deux approches d’apprentissage Bayésien
Résumé
Cette thèse porte sur deux méthodes à patch en traitement
d’images dans le cadre de minimisation du risque Bayésien. Nous
décrivons un mélange d’analyses factorielles pour modéliser la loi à pri-
ori des patchs dans une seule image et l’appliquons au débruitage et à
l’inpainting. Nous étudions aussi les réseaux de neurones à multi-couches
d’un point de vue probabiliste comme un outil permettant d’approcher
l’espérance conditionnelle, ce qui ouvre quelques voies pour réduire leurs
tailles et coût d’apprentissage.
Mots-clés
modélisation Bayésienne, espérance conditionnelle, mélange
d’analyses factorielles, réseau de neurones artiﬁciels, traitement d’images

Contents
Contents
viii
Introduction
1
0.1
Overview
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
0.2
Contributions of this thesis . . . . . . . . . . . . . . . . .
2
Part I. Orientation based sparse patch modelling
9
1
SURE guided Gaussian mixture image denoising
11
1.1
Gaussian factor for patch orientation modelling . . .
11
1.2
Orientation based denoising . . . . . . . . . . . . . . . . .
17
1.2.1
Orientation based noisy patch classiﬁcation . . . . . . . .
17
1.2.2
SURE aided adaptive ﬁltering . . . . . . . . . . . . . . .
18
1.2.3
Pseudo-code and numerical results . . . . . . . . . . . .
23
1.3
Appendix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
2
E-PLE: un algorithme performant d’inpainting
29
2.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
2.1.1
Inpainting . . . . . . . . . . . . . . . . . . . . . . . . . .
29
2.1.2
Estimation linéaire par morceaux . . . . . . . . . . . . .
29
2.2
PLE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
30
2.2.1
Construction et sélection de modèle . . . . . . . . . . . .
30
2.2.2
Comment améliorer PLE ? . . . . . . . . . . . . . . . . .
31
2.3
E-PLE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
2.3.1
La classiﬁcation des patches avec EM . . . . . . . . . . .
31
2.3.2
Résultats numériques et discussions . . . . . . . . . . . .
32
Part II. Conditional expectation and neural networks
35
3
A multilayer neural network for image demosaicking
37
3.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
3.2
Training a deep neural network
. . . . . . . . . . . . . .
39
3.3
Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
3.4
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
42
4
Can a single image denoising neural network handle
all levels of Gaussian noise?
47
4.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . .
47
4.2
A single neural network for all noise levels . . . . . .
48
4.3
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
5
A note on the size of denoising neural networks
55
viii

5.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . .
55
5.1.1
Patch denoising and its probabilistic interpretation . . . .
55
5.1.2
Our contribution . . . . . . . . . . . . . . . . . . . . . .
57
5.2
Small-scale texture pattern denoising
. . . . . . . . . .
57
5.2.1
A conditional expectation decomposition . . . . . . . . .
57
5.2.2
Small neural networks for small-scale texture denoising .
59
5.3
Complementing BM3D with small neural networks . .
61
Part III. Reproducible research
65
6
E-PLE : an algorithm for image inpainting
67
6.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . .
67
6.2
PLE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
68
6.3
E-PLE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
70
6.3.1
Masked patch classiﬁcation and adaptive ﬁltering
. . . .
70
6.3.2
Algorithm outline
. . . . . . . . . . . . . . . . . . . . .
71
6.3.3
Numerical results . . . . . . . . . . . . . . . . . . . . . .
73
6.4
Appendix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
75
7
An analysis of the Viola-Jones face detection algo-
rithm
79
7.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . .
79
7.2
Algorithm
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
80
7.2.1
Features and integral image . . . . . . . . . . . . . . . .
80
7.2.2
Feature selection with adaboost . . . . . . . . . . . . . .
82
7.2.3
Attentional cascade . . . . . . . . . . . . . . . . . . . . .
85
7.2.4
Dataset and experiments . . . . . . . . . . . . . . . . . .
93
7.3
Post-processing
. . . . . . . . . . . . . . . . . . . . . . . . .
94
7.4
Appendix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
96
Conclusions and perspectives
101
Bibliography
105


Introduction
0.1
Overview
T
raditional image processing challenges such as denoising and in-
painting constitute a vital testing ground for our understanding of
the nature of digital images. Good solutions to these problems typically in-
volve identifying and modelling natural image regularities, whether they
lie in the spatial or transform domains. Historically, spatial domain meth-
ods such as level line Masnou and Morel (1998), total variation Rudin
et al. (1992), Shen and Chan (2002), anisotropic diffusion Perona and Ma-
lik (1990), Bertalmio et al. (2000) and bilateral ﬁlter Tomasi and Manduchi
(1998) all grew out of a desire to preserve image continuity, edges in par-
ticular.
The concept of regularity was then extended from pixels to image
parts, or patches. Its advantage is twofold. First, typically square in form,
patches form a standardized class of their own. With no restriction on their
positions, patches can be viewed as random realizations from the same
underlying distribution, thereby lending themselves naturally to statisti-
cal analysis. Second, depending on the size, patches can contain a ﬂexi-
ble amount of information, rich enough for image representation and at
the same time sufﬁciently limited for tractable numerical modelling. Non-
local means Buades et al. (2005), for instance, is a bilateral ﬁlter acting on
ℓ2-adjacent patches.
In a parallel development, sparse representation has been in vogue
ever since the appearance of wavelet analysis Daubechies et al. (1992), Mal-
lat (2008). This line of research builds on a fundamental belief that some
appropriately designed linear transforms can represent natural signals,
including images, with just a few coefﬁcients compared to their original
size. Other transforms of this genre include steerable pyramid Simoncelli
and Freeman (1995) and curvelet Candès (2003). Thanks to variational for-
mulation, coefﬁcient shrinkage Donoho and Johnstone (1994; 1995), and
model based thresholding, they led to effective algorithms Portilla et al.
(2003), Starck et al. (2002), Elad et al. (2005).
Advances in the ﬁeld have since blurred the line separating spatial and
transform methods. BM3D Dabov et al. (2007), for instance, uses spatial
block matching to obtain similar patches, which are then jointly ﬁltered in
a ﬁxed basis with coefﬁcient shrinkage. In addition, how best to construct
a basis has also been extensively investigated. Efﬁcient optimisation tech-
niques such as orthogonal matching pursuit Mallat and Zhang (1993) and
the LARS algorithm Efron et al. (2004) allow to approach basis pursuit
Chen et al. (1998) or Lasso Tibshirani (1996), which were formulated in an
explicit quest for sparse coding and have since expanded into an umbrella
1

2
Introduction
subject known as dictionary learning. This endeavor ultimately leads the
research community to look beyond the image to restore itself and seek
data driven priors. Various modelling tools including Gaussian mixture
Zoran and Weiss (2011), 1 as well as unsupervised and supervised K-SVD
Elad and Aharon (2006), Mairal et al. (2009; 2012) have been successfully
employed.
Increasingly powerful and accessible computing facilities now make
another line of research possible. Rather than try to summarize the ana-
lytically intractable patch space with dictionaries, one can process images
using essentially an empirical replica of the patch space generated with a
great number of samples from external image databases, which produced
impressive results Levin and Nadler (2011) Yue et al. (2014). Moreover,
with training cost no longer as prohibitive as it once was, researchers have
also started to harness the potential of neural networks Bengio (2009).
Convolutional neural networks Jain and Seung (2009), stacked sparse
auto-encoder Xie et al. (2012) and plain multilayer neural networks Burger
et al. (2012) all had success at image denoising.
The rest of the thesis consists of four parts: the ﬁrst two chapters de-
scribe an orientation based approach to patch prior modelling. The next
three chapters look at multilayer neural networks as a device for condi-
tional expectation approximation and derive applications from their inter-
play with the underlying patch distribution. The third section is centered
on reproducible research and details the Viola-Jones algorithm, a success-
ful application of the empirical risk minimization. Finally, the thesis ends
with a review of parametric denoising algorithms from a Bayesian risk
minimization perspective and some suggestions for future research.
0.2
Contributions of this thesis
The ﬁrst part was inspired by evidence pointing to edge-like patterns
as the most salient characteristics of relatively small image patches Ol-
shausen and Field (1996), Takeda et al. (2007), Lee et al. (2006), Chatterjee
and Milanfar (2009), Yu et al. (2012). Therefore, in order to reach the holy
sparse land, it is essential to build a dictionary with basis vectors sporting
similar features.
Gaussian mixture emerged as our modelling tool of choice as a univer-
sal density approximation device. As a result, patch classiﬁcation is also
straightforward thanks to the plug-in version of the Bayes rule Devroye
et al. (1996). More importantly, equipped with the Expectation Maximisa-
tion algorithm, mixture can evolve and better account for image patches as
data likelihood increases monotonously. Moreover, for both denoising and
inpainting, numerical results show that a dynamic mixture can achieve
similar or better performance as a static Gaussian mixture, despite being
ten times smaller.
Chapter 1 presents the SURE (Stein’s Unbiased Risk Estimator) guided
Gaussian mixture image denoising algorithm capable of delivering state-
of-the-art performance (see Figure 2) The algorithm ﬁts a Gaussian mix-
ture of factor analyzers to patches extracted from a single noisy image
which, thanks to its orientation related interpretation, enables a visually
accurate patch classiﬁcation (see Figure 1).

0.2. Contributions of this thesis
3
(a)
(b)
Figure 1 – (a) noisy image (σ = 10) (b) patch orientation classiﬁcation after one EM
iteration. Patches assigned to different mixture components are marked in different colors.
Those highlighted in white are detected as ﬂat.
When it comes to patch denoising, the algorithm switches between Wiener
ﬁlter and hard shrinkage for individual mixture models according to a
real time Bayesian risk tracking statistics (1) constructed with SURE (see
Deﬁnition 0.1 and Theorem 0.1).
Deﬁnition 0.1
Let ˜P be the sum of a κ-by-κ patch and a Gaussian random vector composed of
i.i.d. entries distributed as N (0, σ2). Let f be one of the following ﬁlters:
1. linear: f ( ˜P) = ∑κ2
j=1 cj⟨˜P −µ, bj⟩bj + µ
2. soft shrinkage: f ( ˜P) = ∑κ2
j=1 cjγsoft
t
 ⟨˜P −µ, bj⟩

bj + µ with γsoft
t
(ω) =
sgn(ω)(|ω| −t)+
3. hard shrinkage: f ( ˜P) = ∑κ2
j=1 cjγhard
t
 ⟨˜P −µ, bj⟩

bj + µ with γhard
t
(ω) =
ω1|ω|>t
where µ, (cj)1≤j≤κ2, (bj)1≤j≤κ2, and t are the ﬁlter’s ˜P-independent mean, coefﬁ-
cients, basis, and threshold. And their weak derivatives are deﬁned to be
1. linear: ∇· f ( ˜P) = ∑κ2
j=1 cj
2. soft shrinkage: ∇· f ( ˜P) = ∑κ2
j=1 cj1[t,+∞)
 ⟨˜P −µ, bj⟩

3. hard shrinkage: ∇· f ( ˜P)
=
∑κ2
j=1 cj
 1[t,+∞)
 ⟨˜P −µ, bj⟩
 + tE
(δt −
δ−t)
 ⟨˜P −µ, bj⟩
|P

where δx(·) represents a Dirac centered at x ∈R.
Theorem 0.1
Under the assumptions of Deﬁnition 0.1, SURE given the observation ˜P
SURE
f
( ˜P) := 1
κ2 ∥˜P −f ( ˜P)∥2 −σ2 + 2σ2
κ2 ∇· f ( ˜P)
(1)
is unbiased
E

SURE
f
( ˜P)|P
 = E
 1
κ2 ∥P −f ( ˜P)∥2|P

.
Hence given a great number of patches ( ˜Pi)1≤i≤n, the Bayesian quadratic
risk estimator n−1 ∑i SUREf ( ˜Pi) may be used as a ﬁlter selection criterion.
Moreover, thanks to Jensen’s inequality, patch MSE can be established as

4
Introduction
an asymptotic upper bound of image MSE, which makes our SURE based
patch MSE estimate an algorithm stopping rule.
(a)
(b)
(c)
(d)
Figure 2 – (a) original (b) noisy σ=20 (c) ours RMSE=10.73 (d) BM3D RMSE =10.77
Chapter 2 is based on a namesake paper published in French, which
is translated into English with more algorithm implementation details as
Chapter 6. They document the existing piecewise linear estimate (PLE)
algorithm for inpainting Yu et al. (2012) and propose several theoretical
and numerical improvements among which, the most signiﬁcant are
1. it uses a Gaussian factor mixture to put orientation models in a sin-
gle uniﬁed probabilistic framework, which also accommodates for
the ﬁrst time an extra model for ﬂat area detection;
2. it derives the associated Expectation Maximization (EM) procedure
for parameter learning from partially observable data;
3. it applies tensor structure Harris and Stephens (1988) to mixture ini-
tialisation, thereby signiﬁcantly accelerating the algorithm thanks to
a reduced number of iterations required at parameter learning (see
Figure 3).
(a)
(b)
(c)
Figure 3 – (a) original (b) masked image (ratio=0.8) (c) one iteration E-PLE RMSE=14.9

0.2. Contributions of this thesis
5
The second part focuses on multilayer neural networks and their appli-
cations to image processing. The fundamental observation is that driven
by backpropagation, feedforward neural networks seek to approximate a
conditional expectation. Though larger neural networks tend to be better,
our work explores the possibility to reduce their sizes and training cost.
We have chosen image demosaicking and denoising because unlike
random masks arising in the context of image inpainting, Bayer color ﬁlter
array and additive Gaussian noise are two types of distortion with locally
deﬁned data format and thus ﬁt well into the patch regression framework.
Chapter 3 presents a small two hidden layer neural network intended
to estimate the masked 32 color intensity values from a 4-by-4 mosaiced
patch. The neural network is designed to have an additive linear compo-
nent so as to let its tanh(·) enabled non-linear structure focus on approx-
imating the difference. Because of the π
2 -rotation-invariance of the Bayer
color ﬁlter array (CFA) (see Figure 4) and image patch statistics,
(a)
(b)
(c)
(d)
Figure 4 – Four basic blocks of the Bayer pattern
the neural network trained on the RGGB CFA pattern (see Figure 4(a)) can
demosaick all four basic Bayer CFAs. It is shown (see Figure 5) that this
neural network is competitive compared to the state-of-the-art algorithms
which typically take longer to process a mosaiced image because of their
larger input sizes.
(a) original
(b) NN (ours)
(c) KSVD
(d) CS
(e) original
(f) NN
(g) KSVD
(h) CS
(i) original
(j) NN
(k) KSVD
(l) CS
Figure 5 – Our neural network does not do well when image patterns to recover oscillate
much. In contrast, it does interpolate well where color changes abruptly. Visually speak-
ing, contour stencil Getreuer (2011a) yields the closest numerical results. However, the
neural network seems to be more accurate on blobs.

6
Introduction
Given the impressive image denoising results obtained with multilayer
neural networks Burger et al. (2012), Chapter 4 presents an attempt to re-
duce their training cost as these dedicated neural networks can only han-
dle one level of Gaussian noise ﬁxed at their respective training time and
that their training may take months Burger (2013). Through an investiga-
tion of the patch distribution invariance with respect to linear transforms,
we show how to make a single existing deep neural network work well
across all levels of Gaussian noise (see Table 1).
Table 1 – RMSE comparison between dedicated neural networks and our generic network
σ = 25
dedicated
generic
computer
7.99
8.10
dice
2.77
2.77
ﬂower
4.59
4.63
girl
3.38
3.41
trafﬁc
9.16
9.22
valldemossa
11.85
11.99
avg.
6.62
6.68
σ = 35
dedicated
generic
computer
9.63
9.82
dice
3.29
3.45
ﬂower
5.53
5.64
girl
3.88
4.07
trafﬁc
10.81
10.94
valldemossa
14.21
14.28
avg.
7.89
8.03
σ = 50
dedicated
generic
computer
11.59
11.92
dice
4.17
4.50
ﬂower
6.85
7.06
girl
4.60
4.92
trafﬁc
12.83
13.07
valldemossa
16.98
17.06
avg.
9.50
9.75
σ = 65
dedicated
generic
computer
13.16
13.82
dice
4.83
5.39
ﬂower
7.89
8.20
girl
5.28
5.74
trafﬁc
14.32
14.78
valldemossa
18.67
18.99
avg.
10.69
11.15
σ = 75
dedicated
generic
computer
14.10
14.78
dice
5.48
6.14
ﬂower
8.57
8.96
girl
5.66
6.20
trafﬁc
15.08
15.56
valldemossa
19.97
20.34
avg.
11.47
11.99
σ = 170
dedicated
generic
computer
20.51
21.81
dice
9.23
10.92
ﬂower
12.84
13.64
girl
8.79
10.54
trafﬁc
20.71
21.72
valldemossa
26.42
27.26
avg.
16.41
17.64
From a probabilistic study of how different patch denoising algorithms
approach condition expectation approximation, Chapter 5 presents a con-
ditional expectation decomposition (see Theorem 0.2). It shows that esti-
mation via conditional expectation mechanically involves likelihood ratio
induced pattern classiﬁcation and suggests a ﬁlter substitution strategy,
whereby large neural networks’ effective but computationally costly built-

0.2. Contributions of this thesis
7
in ﬁlters for structure and texture patterns are replaced by BM3D and
small neural networks respectively.
Theorem 0.2
Let P, M, Q be three probabilities deﬁned on a common measurable space satisfying
P = αM + (1 −α)Q for some α ∈(0, 1). Let U, V be two random vectors with
EP∥U∥1 < +∞deﬁned on the same space. Then we have
EP[U|V] = αEP[dM
dP |V]EM[U|V] + (1 −α)EP[dQ
dP |V]EQ[U|V],
P a.e.
where dM
dP and dQ
dP are the Radon-Nikodym derivatives of M and Q with respect
to P.
The analysis and empirical studies result in a light-weight algorithm
SSaNN, for self-similarity and neural network, that complements BM3D
with small neural networks geared towards granular texture pattern de-
noising, thereby improving BM3D at minor additional cost (see Table 2).
Table 2 – RMSE comparison between BM3D, small and large neural networks and our
algorithm
σ = 10
small
BM3D
SSaNN
large
computer
4.97
4.66
4.63
4.77
dice
2.58
1.79
1.79
1.89
ﬂower
3.19
2.83
2.81
2.77
girl
2.93
2.32
2.32
2.41
trafﬁc
5.67
5.64
5.54
5.52
valldemossa
6.55
6.61
6.51
6.48
σ = 25
small
BM3D
SSaNN
large
computer
8.88
8.15
8.13
8.20
dice
4.81
3.04
3.04
2.85
ﬂower
5.61
5.15
5.12
4.85
girl
5.08
3.64
3.64
3.46
trafﬁc
10.16
9.94
9.79
9.55
valldemossa
12.22
12.28
12.06
11.85
σ = 35
small
BM3D
SSaNN
large
computer
10.86
9.88
9.87
9.88
dice
6.24
3.80
3.80
3.39
ﬂower
6.99
6.40
6.38
6.00
girl
6.39
4.41
4.41
4.01
trafﬁc
12.26
11.85
11.75
11.36
valldemossa
14.81
14.74
14.53
14.24


Part I. Orientation based
sparse patch modelling
The ﬁrst part of this thesis is devoted to an orientation based approach
to image processing. It was inspired by a host of evidence pointing to
edge-like patterns as the most salient characteristics of relatively small
image patches. Therefore, in order to reach the holy sparse land, it is es-
sential to build a dictionary with basis vectors sporting similar features.
Gaussian mixture emerged as our modelling tool of choice because it
is a universal density approximation device. As a result, patch classiﬁ-
cation is also straightforward thanks to the plug-in version of the Bayes
rule. More importantly, equipped with the Expectation Maximisation al-
gorithm, mixture can evolve and better account for image patches as data
likelihood increases monotonously. For both denoising and inpainting, nu-
merical results show that a dynamic mixture can achieve similar or better
performance as a static Gaussian mixture, despite being ten times smaller.
9


1
SURE guided Gaussian
mixture image denoising
I
n this chapter, using Gaussian factor modelling, its dedicated Expecta-
tion Maximization (EM) inference as well as a statistical ﬁlter selection
and algorithm stopping rule, we develop a SURE (Stein’s Unbiased Risk
Estimator) guided image denoising algorithm capable of delivering state-
of-the-art performance.
1.1
Gaussian factor for patch orientation modelling
When applied to approximate an arbitrary probability distribution, a
Gaussian mixture’s main appeal lies in its versatility and interpretability.
Perhaps more importantly, it is equipped with the renowned Expectation
Maximization (EM) algorithm Dempster et al. (1977), Wainwright and Jor-
dan (2008) which makes its parameter inference particularly convenient.
Image patch distribution can be modelled with a Gaussian mixture.
Unlike Zoran and Weiss (2011), we decided to assign to all the mixture
components an orientation related interpretation because of the evidence
presented in Olshausen and Field (1996), Takeda et al. (2007), Lee et al.
(2006), Chatterjee and Milanfar (2009), Yu et al. (2012).
The covariance matrix of patches inclined at some angle θ, modelled
as a Gaussian random vector, cannot be of full rank. If it were, all of its
eigenvectors viewed as individual patches, would be oriented in either θ
or π −θ. As a result, none of their linear combinations could produce a
patch with oriented at π
2 −θ, which contradicts the assumed full-rankness.
However, for practical purposes, a model should account for a slightly
wider range of orientations than just θ: i.e. (θ −∆, θ + ∆) with a small
scalar ∆> 0. Thus, the above reasoning need not apply. But there is still
reason to believe that a reduced set of vectors sufﬁces for a good represen-
tation of patches of a narrow range of orientations. Therefore, instead of a
full-ﬂedged Gaussian distribution, an equally ﬂexible model candidate in
this case is a Gaussian factor model
Pθ = Fθc + µθ.
The variability of the κ-by-κ patch Pθ can be adjusted through the l-column
factor loading matrix Fθ. With µθ deterministic and c following N (0, Il),
11

12
Chapter 1. SURE guided Gaussian mixture image denoising
Pθ remains Gaussian. Note that the factor trimming also lowers the model
complexity, which should help resist over-ﬁtting.
In addition to these θ-indexed oriented models, two non-oriented mod-
els representing respectively textural and ﬂat patches should be set up as
well. If the resultant Gaussian mixture has K components, an i-indexed
κ-by-κ noisy patch ˜Pi can be represented by
˜Pi =
K−1
∑
k=0
(Fkcki + µk + σni)1si=k
where
1. Fk ∈Rκ2×lk: a deterministic lk-column matrix for the k-th model;
2. cki ∈Rlk: a Gaussian coefﬁcient distributed as N (0, Ilk);
3. µk ∈Rκ2: a deterministic vector representing the k-th model mean;
4. σ ∈R+: the standard deviation of zero-mean Gaussian noise;
5. ni ∈Rκ2: a noise vector following N (0, Iκ2) and independent of cki;
6. si ∈{0, · · · , K −1}: a random model for the i-th patch.
For EM to succeed at its task, we try to set a good starting position
in the parameter space by initializing the mixture using random patches
drawn directly from natural images with the help of the tensor structure
orientation detector Harris and Stephens (1988): given a patch P, the dis-
crete gradient ∇P(r, u) is calculated at all pixel sites (r, u) in its domain
dom(P). The patch’s orientation v∗can then be deﬁned by
v∗= argmin
∥v∥2=1
∑
(r,u)∈dom(P)
∥∇P(r, u) −vT∇P(r, u)v∥2
2
= argmin
∥v∥2=1
∑
(r,u)∈dom(P)
∥∇P(r, u)∥2
2 −(vT∇P(r, u))2
= argmax
∥v∥2=1
vT
∑
(r,u)∈dom(P)
∇P(r, u)(∇P(r, u))T
v.
(1.1)
The solution to 1.1 is the ﬁrst leading eigenvector of the positive semidef-
inite matrix (denoted by MP) enclosed in the parentheses. Let λb and λs
(λb ≥λs) be its eigenvalues. Because of the equality
∑
(r,u)∈dom(P)
∥∇P(r, u)∥2
2 = tr(MP) = λs + λb,
it seems natural to declare P oriented if
∑(r,u)∈dom(P) ∥∇P(r, u) −vT
∗∇P(r, u)v∗∥2
2
∑(r,u)∈dom(P) ∥∇P(r, u)∥2
2
=
λs
λs + λb
is small. We tuned a threshold torient = 5 empirically such that a patch is
labelled oriented if and only if its eigenvalues satisfy
λ−1
s λb ≥torient
(1.2)
Its orientation θ∗is then set to ψ(arctan y∗
x∗) with v∗= (x∗, y∗)T and
ψ(a) = a1a≥0 + (π + a)1a<0 which ensures that θ∗is positive. To distin-
guish between two non-oriented categories, we use
λb ≥tﬂat
and
λ−1
s λb < torient
(1.3)

1.1. Gaussian factor for patch orientation modelling
13
to deﬁne textural patches. The remaining set of patches satisfying
λb < tﬂat
and
λ−1
s λb < torient
(1.4)
are ﬂat. Again, the threshold tﬂat = 104 was selected empirically.
The deﬁnitions 1.2, 1.3, 1.4 split the ﬁrst quadrant (λs, λb) ∈R2
+ into
three regions, with the one characterized by 1.2 further divided into K −2
sub-areas by angle quantiﬁcation to form a K-zone partition (see Algo-
rithm 1). More precisely, a patch P is assigned to the k-th oriented model
if and only if it satisﬁes
λ−1
s λb ≥torient
and
θ∗∈[
k
K −2π, k + 1
K −2π).
Since λs, λb and θ∗all depend on P, the natural patch space is now en-
dowed with a coarse σ-algebra entirely induced by the tensor structure.

14
Chapter 1. SURE guided Gaussian mixture image denoising
Algorithm 1 Gaussian Mixture Initialization
1: Input: some clean natural grayscale images.
2: Parameter: number of mixture components K, patch dimension κ × κ.
3: for k = 0 to K −1 do
4:
Nk ←0 with Nk the number of sample patches collected for the k-th model.
5: end for
6: while min0≤k≤K−1 Nk < 5000 do
7:
randomly draw a κ × κ patch P from the image set.
8:
solve 1.1 to deduce the eigenvalues (λb, λs) and the eigenvector v associ-
ated with λb.
9:
if λb/λs < torient then
10:
if λb < tﬂat then
11:
assign P to the ﬂat model.
12:
NK−1 ←NK−1 + 1.
13:
else
14:
assign P to the textural model.
15:
NK−2 ←NK−2 + 1.
16:
end if
17:
else
18:
θ ←ψ(arctan y
x) with v = (x, y)T and ψ(a) = a1a≥0 + (π + a)1a<0.
19:
ﬁnd k∗such that θ ∈[ k∗
K−2π, k∗+1
K−2 π).
20:
assign P to the k∗-th model.
21:
Nk∗←Nk∗+ 1.
22:
end if
23: end while
24: for k = 0 to K −1 do
25:
Set the model prior
wk ←
Nk
∑K−1
j=0 Nj
.
26:
Set the model mean and covariance
µk ←
1
|Pk| ∑
P∈Pk
P,
Σk ←
1
|Pk| ∑
P∈Pk
(P −µk)(P −µk)T
with Pk the set of patches attributed to the k-th model.
27:
Set the factor loading matrix
Fk ←[ (λ1 −σ2)1/2φ1, · · · , (λlk −σ2)1/2φlk ] with σ2 =
1
κ2 −lk
κ2
∑
m=lk+1
λm
where lk denotes the number of factors required by the k-th model. V =
[φ1, · · · , φκ2] and Λ = diag(λ1, · · · , λκ2) results from the spectral decom-
position Σk = VΛVT.
28: end for
A few comments on Algorithm 1: ﬁrst, individual Gaussian factor
models are initialized by maximizing the likelihood of N presumably i.i.d.

1.1. Gaussian factor for patch orientation modelling
15
observations which are not assumed to be noise free
(F∗, σ∗) =
argmax
F∈Rκ2×l,σ∈R+
log
N
∏
i=1
exp

−1
2(Pi −µ)T(FFT + σ2I)−1(Pi −µ)

q
(2π)κ2 det(FFT + σ2I)
=
argmin
F∈Rκ2×l,σ∈R+
log det(FFT + σ2I) + tr

(FFT + σ2I)−1Σ

This problem introduced in Roweis (1998) led to a probabilistic interpre-
tation of the Principal Component Analysis Tipping and Bishop (1999a;b).
Its solution turns out to be quite intuitive
F∗= [ (λ1 −σ2)1/2φ1, · · · , (λl −σ2)1/2φl ]
σ2 =
1
κ2 −l
κ2
∑
m=l+1
λm
with the factor loading F∗unique up to a rotation in its l-dimensional
space as the Gaussian distribution N (0, Il) is itself rotation-invariant.
Second, the present patch sampling revealed another valuable piece of
information of the initial mixture structure, namely (wk)0≤k≤K−1, the prior
probability of having a random natural patch belonging to a particular
model. It was estimated by
wk =
Nk
∑K−1
j=0 Nj
with Nk the number of patches gathered by the k-th model at the end of
the sampling. As shown in Fig.1.2(c), the mixing weights are conﬁgured in
such a way that non-oriented patches are much more likely to appear than
their oriented counterparts. Moreover, within the non-oriented category,
the ﬂat patches were made to have a slightly higher probability to show
up. This setup conveys our belief on the patch composition of a typical
natural image and is not image speciﬁc: this prior was used in all of our
experiments.
In practice, we set K = 20 and collected for each model a minimum of
5000 8 × 8 random patches from the Berkeley Segmentation Dataset rendered
to grayscale. Shown in Fig.1.1 are three resulting covariance matrices. Sev-
eral observations are in order:
1. ﬁrst, leading eigenvectors in the oriented models not only preserve
their model feature orientation but also suggest that low frequency
patterns tend to appear more often in natural scenes: in view of
their much bigger variance, the true probability of the natural patch
space endowed with the Kolmogorov σ-algebra assigns a predomi-
nant weight to low frequency patches;
2. second, the oriented models’ eigenvalues do not go to zero as pro-
jected by the Gaussian factor models. However, their rapid decay
does not deviate far from what is expected of the model either. We
kept the ﬁrst few (e.g. 32) factors and left out the rest;
3. third, contrary to the oriented models, the texture model’s eigenvec-
tors resemble those of the ﬂat model. It is the associated eigenvalues

16
Chapter 1. SURE guided Gaussian mixture image denoising
that allows us to tell them apart, a hardly surprising fact given how
they are deﬁned. To prevent over-ﬁtting, the ﬁrst leading eigenvector
was made the sole factor representing the ﬂat model, a convenient
practice only possible because of the adoption of the Gaussian factor
model;
4. ﬁnally, to reﬂect texture’s inherent variability, 63 factors are allowed
in the textural model. A DCT-like isotropic basis is thus broken up
into two to handle two radically different patch categories.
(a)
(b)
(c)
(d)
(e)
(f)
Figure 1.1 – examples of the eigenvectors and eigenvalues resulting from Algorithm 1
running on the grayscale Berkeley Segmentation Dataset with K = 20 and κ = 8: a
patch view of the eigenvectors of the (a) 0-th (oriented), (c) 18-th (textural), (e) 19-th
(ﬂat) cluster and their eigenvalues displayed in the logarithmic scale: the (b) 0-th, (d)
18-th and (f) 19-th cluster.

1.2. Orientation based denoising
17
1.2
Orientation based denoising
1.2.1
Orientation based noisy patch classiﬁcation
To classify patches, we assess their chance of being generated by the
individual models in the mixture. For an illustration, we took the image
dice and added i.i.d. zero-mean Gaussian noise with standard deviation
equal to 10. To the three resultant color channels (uR, uG, uB), the follow-
ing PCA inspired transform was applied to enhance the ﬁrst transformed
channel’s signal to noise ratio (SNR):
˜u1 = uR + uG + uB
3
, ˜u2 = uR −uB
√
2
, ˜u3 = uR −2uG + uB
√
6
(1.5)
To be consistent with the origin (grayscale images) of the calculated statis-
tics, the denominator of the ﬁrst transform in 1.5 was set to 3 rather than
the noise normalizing
√
3.
With the noise standard deviation set to 10/
√
3, we ran EM on ˜u1. Each
iteration resulted in a set of newly calculated posterior probabilities for
every noisy observation ˜P which was used to determine their most likely
model with the plug-in version of the Bayes rule Devroye et al. (1996).
k∗= argmax
0≤k≤19
P(sP = k| ˜P) = argmax
0≤k≤19
P( ˜P|sP = k)P(sP = k).
(1.6)
The patch to model mapping, established using 1.6, will be referred to
as the patch map henceforth. For example, the patch map (Fig.1.2) shows
that by the time the ﬁrst EM iteration ended, pretty much as expected, an
overwhelming majority (87.4%) of patches identiﬁed with the ﬂat model.
(a)
(b)
(c)
(d)
Figure 1.2 – (a) noisy image (σ = 10) (b) patch map formed after one EM iteration (c)
initial model priors (d) updated model priors after one EM iteration on the ﬁrst trans-
formed channel. To visualize the resultant patch map, patches are colorized with white
color representing those ﬂat ones.

18
Chapter 1. SURE guided Gaussian mixture image denoising
1.2.2
SURE aided adaptive ﬁltering
Spatial patch denoising usually projects a noisy patch onto some pre-
ﬁxed basis, it is thus desirable to be able to select bases adaptively so that
any given patch can be well represented using just a few coefﬁcients. If this
condition proves too difﬁcult to satisfy for every patch, it would be good
if it holds true with the patch categories which tend to appear frequently.
Our orientation based dictionary construction and selection framework
suits this purpose well. For example, if a noisy patch ˜P is found to be best
described by the k-th model
˜P = Fkc + µk + σN
the eigenvectors of FkFT
k constitute a reasonable basis for its representa-
tion. It remains to decide how best to ﬁlter its resultant coefﬁcients.
We approach the problem with Stein’s unbiased risk estimator (SURE)
Stein (1981) to construct a statistic indicative of a ﬁlter’s real time perfor-
mance. Let us ﬁrst state a specialized version of the theorem due to Stein
in anticipation of its application in this context.
Deﬁnition 1.1
Let ˜P be the sum of a ﬁxed vector P ∈Rκ2 and a Gaussian random vector
composed of i.i.d. entries distributed as N (0, σ2). Let f be one of the following
ﬁlters:
1. linear: f ( ˜P) = ∑κ2
j=1 cj⟨˜P −µ, bj⟩bj + µ
2. soft shrinkage: f ( ˜P) = ∑κ2
j=1 cjγsoft
t
 ⟨˜P −µ, bj⟩

bj + µ with γsoft
t
(ω) =
sgn(ω)(|ω| −t)+
3. hard shrinkage: f ( ˜P) = ∑κ2
j=1 cjγhard
t
 ⟨˜P −µ, bj⟩

bj + µ with γhard
t
(ω) =
ω1|ω|>t
where µ, (cj)1≤j≤κ2, (bj)1≤j≤κ2, and t are the ﬁlter’s ˜P-independent mean, coefﬁ-
cients, basis, and threshold. And their weak derivatives are deﬁned to be
1. linear: ∇· f ( ˜P) = ∑κ2
j=1 cj
2. soft shrinkage: ∇· f ( ˜P) = ∑κ2
j=1 cj1[t,+∞)
 ⟨˜P −µ, bj⟩

3. hard shrinkage: ∇· f ( ˜P)
=
∑κ2
j=1 cj
 1[t,+∞)
 ⟨˜P −µ, bj⟩
 + tE
(δt −
δ−t)
 ⟨˜P −µ, bj⟩
|P

where δx(·) represents a Dirac centered on x ∈R.
Theorem 1.1
Under the assumptions of Deﬁnition 1.1, SURE given the observation ˜P
SURE
f
( ˜P) := 1
κ2 ∥˜P −f ( ˜P)∥2 −σ2 + 2σ2
κ2 ∇· f ( ˜P)
is unbiased
E

SURE
f
( ˜P)|P
 = E
 1
κ2 ∥P −f ( ˜P)∥2|P

.

1.2. Orientation based denoising
19
SURE is valuable in that it depends solely on the observable ˜P. How-
ever, in case of f being a hard shrinkage operator, the expectation
E
(δt −δ−t)
 ⟨˜P −µ, bj⟩
|P

involves the unknown P. To circumvent the issue, one may replace the
expectation with an estimator
1
2ǫ
 1[t−ǫ,t+ǫ] −1[−t−ǫ,−t+ǫ]
 ⟨˜P −µ, bj⟩

for a small ǫ > 0.
Thanks to Theorem 1.1, a useful statistic, the SURE empirical mean, can
be derived as a measure of how effective ﬁlters are. Note that patches in
a conventional ﬁltering schema are overlapping, hence correlated. How-
ever, given their restricted supports, it is plausible that these patches, seen
as a two-dimensional stochastic process, satisfy the wide-sense stationar-
ity Brockwell and Davis (1991), a weaker condition sufﬁcient for the next
corollary.
Corollary 1.1
Under the assumptions of Theorem 1.1 and some mild stationary conditions on
image patches (Pi)1≤i≤N, the SURE empirical mean
1
N
N
∑
i=1
SURE
f
( ˜Pi) := 1
N
N
∑
i=1
 1
κ2 ∥˜Pi −f ( ˜Pi)∥2 −σ2 + 2σ2
κ2 ∇· f ( ˜Pi)

(1.7)
is an unbiased estimator of the expected patch MSE κ−2E[∥P −f ( ˜P)∥2] and it
converges
lim
N→∞
1
N
N
∑
i=1
SURE
f
( ˜Pi) = 1
κ2 E[∥P −f ( ˜P)∥2]
almost surely and in L2.
Sketch of the ideas. Since patches are in abundant supply, the said esti-
mator can be of quite small variance in spite of the terms in the sum being
correlated
1
N
N
∑
i=1
 1
κ2 ∥˜Pi −f ( ˜Pi)∥2 −σ2 + 2σ2
κ2 ∇· f ( ˜Pi)

≈E
h 1
N
N
∑
i=1
 1
κ2 ∥˜Pi −f ( ˜Pi)∥2 −σ2 + 2σ2
κ2 ∇· f ( ˜Pi)
i
(1.8)
=E
h 1
N
N
∑
i=1
1
κ2 ∥Pi −f ( ˜Pi)∥2i
(1.9)
= 1
κ2 E[∥P −f ( ˜P)∥2]
(1.10)
where, under some mild condition on the covariance structure of image
patches (see 1.3), the approximation 1.8 is accurate with high probability
if N is big enough. Equality (1.9) holds because for all i, we have
E
 1
κ2 ∥˜Pi −f ( ˜Pi)∥2 −σ2 + 2σ2
κ2 ∇· f ( ˜Pi)
 = E
 1
κ2 ∥Pi −f ( ˜Pi)∥2

20
Chapter 1. SURE guided Gaussian mixture image denoising
thanks to the conditional unbiasedness of SURE. Finally, equality (1.10)
stems from (∥Pi −f ( ˜Pi)∥2)1≤i≤N sharing the same expectation, one of the
deﬁning conditions of the assumed stationarity.
Since the f-dependent estimator 1.7 is a ﬁlter performance gauge, we
can let both Wiener and shrinkage ﬁlters Donoho and Johnstone (1994;
1995) process the noisy patches and then decide the optimal ﬁlter for each
mixture component based on their respective model-wide SURE empirical
mean. The experiments showed that it was better to switch between the
hard shrinkage and Wiener ﬁlter than sticking with either one of them (see
Tab.1.1). Note however that ﬁlter selection is not well founded if applied
on a patch-by-patch basis because SURE, after all, is a random variable.
Table 1.1 – SURE Guided Filter Selection (HS for Hard Shrinkage)
σ = 2
HS
Wiener
Combined
computer
1.63
1.63
1.63
dice
0.91
0.94
0.91
ﬂowers
1.10
1.23
1.11
girl
1.16
1.15
1.16
trafﬁc
1.71
1.73
1.71
valldemossa
1.81
1.87
1.87
σ = 5
HS
Wiener
Combined
computer
3.13
3.20
3.14
dice
1.34
1.44
1.34
ﬂowers
1.99
2.33
1.99
girl
1.79
1.83
1.80
trafﬁc
3.53
3.56
3.48
valldemossa
3.91
4.07
4.04
σ = 10
HS
Wiener
Combined
computer
5.04
5.08
4.99
dice
1.86
2.01
1.87
ﬂowers
3.15
3.50
3.15
girl
2.47
2.55
2.46
trafﬁc
6.01
5.89
5.83
valldemossa
7.00
7.08
7.04
σ = 20
HS
Wiener
Combined
computer
7.84
7.80
7.73
dice
2.64
2.81
2.64
ﬂowers
4.83
5.17
4.88
girl
3.47
3.48
3.45
trafﬁc
9.43
9.04
9.01
valldemossa
11.48
11.36
11.29
σ = 30
HS
Wiener
Combined
computer
10.05
9.91
9.83
dice
3.40
3.57
3.43
ﬂowers
6.21
6.55
6.39
girl
4.26
4.33
4.24
trafﬁc
11.69
11.35
11.29
valldemossa
14.43
14.26
14.05
σ = 40
HS
Wiener
Combined
computer
11.77
11.71
11.57
dice
4.16
4.36
4.34
ﬂowers
7.47
7.70
7.69
girl
4.90
5.11
5.02
trafﬁc
13.40
13.12
13.02
valldemossa
16.55
16.48
16.24
Perhaps more interestingly, a link can be established between the SURE
empirical mean and the recovered image’s MSE. To carry out the analysis,
we need the next convention:
Deﬁnition 1.2
Let us denote a patch’s position by that of its upper-left pixel. A non-overlapping
ﬁltering schema including patch (p, q) means a partition of Z2 consisting of κ-by-
κ patches whose coordinates form the set {(x, y), (x −p) mod κ = 0 and (y −
q) mod κ = 0}.
Assume that all κ2 distinct non-overlapping ﬁltering schemas are used
to ﬁlter a large MU × NU noisy image ˜U which results in ( bUi)1≤i≤κ2. If
we denote U the clean image, Corollary 1.1 implies that for all i the MSE
M−1
U N−1
U ∥U −bUi∥2 will be close to κ−2E[∥P −f ( ˜P)∥2] if both NU and MU
are big enough. Jensen’s inequality leads to
∥1
κ2 ∑κ2
i=1 bUi −U∥2
MUNU
≤∑κ2
i=1 ∥bUi −U∥2
MUNUκ2
≈1
κ2 E[∥P −f ( ˜P)∥2].
(1.11)
Asymptotically speaking, the ﬁrst term in 1.11 is the restoration MSE with
the conventional sliding window schema.
Hence the SURE empirical mean becomes a real-time proxy for track-
ing how well an image gets denoised. Although as an upper bound this

1.2. Orientation based denoising
21
estimator cannot ensure a strict decline of the true MSE, it turned out to
be quite reliable in our experiments (Fig. 1.3).
(a)
(b)
Figure 1.3 – the evolution of MSEs and their SURE empirical means as EM iterates
on noisy (σ = 20) (a) traffic (resp. (b) valldemossa) in Fig.1.5. These two are
quite close. The deviation from the expected asymptotic behavior may be caused by the
calculated SURE being biased by the explained approximation in dealing with the patch
dependent Wiener ﬁltering coefﬁcients.
In addition, SURE allows to choose patch size for denoising ﬂat areas.
It is hard to overstate the importance of an algorithm’s effectiveness at
reducing noise in these regions because of the sheer proportion of pixels
composing the sky for instance. To help understand the sub-optimality
caused by a ﬁxed patch size, consider a slow varying signal τ ∈Z 7→xτ ∈
R corrupted by some additive white noise nτ. If the sliding windows of
length m are applied to recover the signal, its estimated value at time t is
bxt = 1
m
t
∑
τ=t−m+1
m−1
∑
s=0
xτ+s + nτ+s
m
= 1
m2
m−1
∑
s=1−m
ρs(xt+s + nt+s)
(1.12)
where ρ· is a probability kernel whose support consists of 2m −1 elements.
If noise is weak, although a bigger patch is conducive to a higher rate of
noise reduction, this gain is not signiﬁcant enough to counterbalance the
loss in signal. However, as noise increases in strength, a small patch tends
to keep more and more noise which ultimately leads to a poor MSE.
Therefore, we must extend patches whenever necessary. Unlike Buades
et al. (2005), Dabov et al. (2007), Lebrun et al. (2013b) which discounts
noise correlation of overlapping patches, when denoising a ﬂat patch P,
we focus on neighboring patches which do not intersect with P. One such
patch Q is deemed similar to P only if the following two conditions hold
simultaneously:
1. both patches belong to the same ﬂat region;
2. the true states of P and Q are similar;
The ﬁrst condition can be checked thanks to the patch map and the con-
nected component labeling algorithm Shapiro and Stockman (2001) while
the second one boils down to a chi-square test. Once similar patches are
identiﬁed, they are merged to form an expanded patch whose estimated
intensity is the arithmetic mean of its noisy pixels.

22
Chapter 1. SURE guided Gaussian mixture image denoising
Under strong noise, the rule 1.6 can mistake edges for noise, resulting
in some patch orientation not properly recognized, which usually hap-
pens in the areas of subtle color transition (Fig.1.4). The chi-square test
thus provides a remedy by favoring the locality of patch blending, thereby
enhancing the algorithm’s robustness.
(a)
(b)
(c)
(d)
Figure 1.4 – noisy dice with (a) σ = 10 and (b) σ = 30. EM iterated twice on the ﬁrst
transformed channel as explained in Fig.1.2 to produce the patch map for (c) σ = 10 and
(d) σ = 30. Notice that the oriented edge on the top side of the dice failed to be recognized
at σ = 30.
Nonetheless, as stated before, the proposed patch expansion can be
problematic at low noise levels. Again, SURE can be our decision aid be-
cause the ﬂat areas are restored using simple linear operations similar to
those in equation (1.12). The patch expansion can thus be validated or
invalidated based on the SURE estimates of the ﬁltered results. Our ex-
periments showed that this automatic device improves dramatically the
visual quality as well as the overall MSE of restored images especially
when noise is strong.

1.2. Orientation based denoising
23
Algorithm 2 Flat Patch Expansion
1: Input: patch map M and noisy patches ( ˜Pi)1≤i≤N.
2: Parameters: noise variance σ2, search window size w and similarity threshold
t.
3: Run a connected component labeling algorithm on M to locate ﬂat areas.
4: Identify the pixels belonging only to ﬂat patches and put them into a column
vector ˜p ∈Rnf .
5: for i = 1 to N do
6:
if
˜Pi belongs to the ﬂat model then
7:
ﬁnd, in the search window centered on ˜Pi, non-overlapping similar
patches in the same ﬂat area.
8:
merge them with ˜Pi to form the expanded noisy patch ˜Pe
i .
9:
estimate all pixels in ˜Pe
i by their arithmetic average which results in bPe
i .
10:
record in a nf × nf matrix Fe
i the ﬁlter used in the previous step.
11:
end if
12: end for
13: Restore noisy ﬂat patches with equally weighted patches bPe
i . Find the coefﬁ-
cients αi such that Fe = ∑i αiFi and bpe = Fe˜p where bpe denotes the restored
pixels on the same sites as those in ˜p.
14: Calculate the resultant SURE Se.
15: Repeat the same steps without patch expansion and denote the resultant
SURE S.
16: if Se < S then
17:
Take the estimates with patch expansion.
18: else
19:
Take the estimates without patch expansion.
20: end if
1.2.3
Pseudo-code and numerical results
Algorithm 3 details the pseudo-code of the proposed denoising algo-
rithm. For an online demo, please visit http://demo.ipol.im/demo/
52/ Wang (2013b).

24
Chapter 1. SURE guided Gaussian mixture image denoising
Algorithm 3 S-PLE
1: Input: a noisy gray image ˜U.
2: Parameter: noise level σ, number of EM iteration S.
3: Set up the patch orientation Gaussian mixture Θ0 using Algorithm 1.
4: E0 ←(σ + 1)2 where E0 denotes the initial SURE empirical mean.
5: Compute ∀˜P ∈P, ∀0 ≤k ≤19, PΘ0(sP = k| ˜P) where P is the set of all 8 × 8
noisy patches from ˜U.
6: for t = 1 to S do
7:
Update model priors:
∀0 ≤k ≤19, wk,t =
1
|P| ∑
˜P∈P
PΘt−1(sP = k| ˜P).
8:
Update model means:
∀0 ≤k ≤19, µk,t = ∑˜P∈P ˜PPΘt−1(sP = k| ˜P)
∑˜P∈P PΘt−1(sP = k| ˜P) .
9:
Update factor loadings for all k:
Fk,t = ˜Σ∗
k,t−1Fk,t−1(M−1
k,t−1FT
k,t−1 ˜Σ∗
k,t−1Fk,t−1 + σ2Ilk)−1
Mk,t−1 = FT
k,t−1Fk,t−1 + σ2Ilk
˜Σ∗
k,t−1 = ∑˜P∈P( ˜P −µk,t)( ˜P −µk,t)TPΘt−1(sP = k| ˜P)
∑˜P∈P PΘt−1(sP = k| ˜P)
with lk = 32 for all k except for the last two: l18 = 63 and l19 = 1.
10:
Create the patch map with the updated parameter set Θt:
M : ˜P ∈P 7→argmax
0≤k≤19
PΘt(sP = k| ˜P).
11:
For all k, ﬁlter the patches assigned to the k-th model with both Wiener and
the hard shrinkage ﬁlter and pick the better results based on their achieved
model-wide SURE empirical mean.
12:
Record the SURE empirical mean Et.
13:
Try patch expansion in ﬂat areas using Algorithm 2.
14:
if Et > Et−1 then
15:
Break (Or continue iterating to see if the SURE empirical mean will even-
tually go below Et−1).
16:
end if
17: end for
18: Assign equal weights to all restored patches and recover the image.
Our algorithm (S-PLE) is tested on a grayscale IPOL image set (Fig.1.5)
against PLE Yu et al. (2012), Wang (2013b), DCT Yu and Sapiro (2011),
GSM Portilla et al. (2003), Rajaei (2014), KSVD Elad and Aharon (2006),
Lebrun and Leclaire (2012), NLM Buades et al. (2005; 2011a), EPLL Zo-
ran and Weiss (2011) (source code from http://www.cs.huji.ac.il/
~daniez/), BM3D Dabov et al. (2007), Lebrun and NL-Bayes Lebrun et al.
(2013b;a). The results are compiled in Tab.1.2 where the algorithms are or-
dered according to their respective performance in RMSE.

1.2. Orientation based denoising
25
(a)
(b)
(c)
(d)
(e)
(f)
Figure 1.5 – test images (a) computer (704 × 469) (b) dice (704 × 469) (c) ﬂowers
(704 × 469) (d) girl (704 × 469) (e) trafﬁc (704 × 469) (f) valldemossa (769 × 338)
Table 1.2 – Algorithm Comparison
σ = 2
PLE
DCT
GSM
KSVD
NLM
EPLL
S-PLE
BM3D
NL-Bayes
computer
2.40
1.65
1.64
1.55
1.64
1.57
1.54
1.52
1.85
dice
0.96
0.91
0.92
0.96
0.97
0.89
0.86
0.84
1.31
ﬂowers
1.25
1.08
1.09
1.09
1.29
1.09
1.02
1.04
1.44
girl
1.24
1.13
1.12
1.14
1.17
1.09
1.09
1.05
1.50
trafﬁc
2.82
1.73
1.77
1.65
1.72
1.64
1.67
1.62
1.97
valldemossa
3.65
1.75
1.79
1.73
1.76
1.69
1.78
1.68
2.12
average
2.05
1.37
1.38
1.35
1.42
1.32
1.32
1.29
1.69
σ = 5
PLE
DCT
GSM
KSVD
NLM
EPLL
S-PLE
BM3D
NL-Bayes
computer
4.25
3.40
3.28
3.08
3.19
3.05
2.97
2.94
2.95
dice
1.45
1.44
1.51
1.89
1.70
1.32
1.29
1.27
1.72
ﬂowers
2.16
1.97
1.97
2.11
2.42
1.87
1.79
1.81
2.18
girl
1.92
1.85
1.89
2.11
2.01
1.74
1.69
1.69
1.93
trafﬁc
4.84
3.76
3.69
3.49
3.70
3.38
3.38
3.40
3.63
valldemossa
6.48
4.04
3.98
3.90
4.15
3.75
3.81
3.77
3.85
average
3.51
2.74
2.72
2.76
2.86
2.51
2.48
2.48
2.71
σ = 10
PLE
DCT
GSM
KSVD
NLM
EPLL
S-PLE
BM3D
NL-Bayes
computer
6.12
5.66
5.36
5.14
5.16
4.89
4.77
4.65
4.51
dice
2.08
2.08
2.24
3.42
2.80
1.90
1.80
1.82
2.15
ﬂowers
3.26
3.14
3.19
3.70
4.01
2.92
2.85
2.86
3.07
girl
2.65
2.61
2.82
3.60
3.21
2.44
2.35
2.35
2.56
trafﬁc
7.18
6.51
6.21
5.99
6.05
5.61
5.68
5.67
5.57
valldemossa
9.24
7.45
7.04
6.94
7.02
6.58
6.65
6.66
6.51
average
5.08
4.57
4.47
4.79
4.70
4.05
4.00
4.00
4.06
σ = 20
PLE
DCT
GSM
KSVD
NLM
EPLL
S-PLE
BM3D
NL-Bayes
computer
8.86
8.82
8.37
8.56
7.90
7.54
7.41
7.18
7.07
dice
3.20
3.05
3.19
6.74
3.55
2.95
2.66
2.67
2.76
ﬂowers
4.97
4.88
5.02
6.60
5.66
4.57
4.55
4.48
4.67
girl
3.84
3.65
4.33
6.55
4.18
3.55
3.35
3.28
3.40
trafﬁc
10.37
10.08
9.82
9.71
9.40
8.70
8.80
8.83
8.74
valldemossa
13.26
12.26
11.55
11.47
11.19
10.60
10.73
10.77
10.53
average
7.41
7.12
7.04
8.27
6.98
6.31
6.25
6.20
6.19
σ = 30
PLE
DCT
GSM
KSVD
NLM
EPLL
S-PLE
BM3D
NL-Bayes
computer
10.97
11.13
10.83
10.22
10.43
9.51
9.39
9.09
9.12
dice
4.43
3.88
4.18
6.09
4.87
3.94
3.37
3.44
3.35
ﬂowers
6.44
6.37
6.15
6.95
7.45
6.00
5.92
5.80
5.89
girl
4.85
4.46
4.64
6.24
5.45
4.51
4.11
4.04
4.10
trafﬁc
12.23
12.38
12.35
11.58
12.11
10.85
11.08
10.97
10.99
valldemossa
15.80
15.32
14.74
14.20
14.37
13.33
13.58
13.64
13.43
average
9.12
8.92
8.81
9.21
9.11
8.02
7.90
7.83
7.81

26
Chapter 1. SURE guided Gaussian mixture image denoising
σ = 40
PLE
DCT
GSM
KSVD
NLM
EPLL
S-PLE
BM3D
NL-Bayes
computer
12.61
12.92
12.85
12.20
12.41
11.13
11.24
10.72
10.85
dice
5.85
4.64
4.96
7.91
5.20
4.80
4.49
4.14
3.95
ﬂowers
7.68
7.59
7.32
8.55
8.96
7.12
7.14
6.94
6.98
girl
6.07
5.23
6.01
7.86
5.84
5.30
5.17
4.67
4.60
trafﬁc
13.87
14.17
14.70
13.61
14.24
12.53
12.86
12.70
12.90
valldemossa
17.71
17.48
17.22
16.52
16.90
15.57
15.83
15.73
15.62
average
10.63
10.33
10.51
11.10
10.59
9.40
9.45
9.15
9.15
(a)
(b)
(c)
(d)
(e)
(f)
Figure 1.6 – (a) original image (b) noisy image σ = 20 (c) EPLL RMSE = 3.55 (d)
S-PLE RMSE = 3.35 (e) BM3D RMSE = 3.28 (f) NL-Bayes RMSE = 3.40

1.3. Appendix
27
(a)
(b)
(c)
(d)
(e)
(f)
Figure 1.7 – (a) original image (b) noisy image σ = 20 (c) EPLL RMSE = 10.60 (d)
S-PLE RMSE = 10.73 (e) BM3D RMSE = 10.77 (f) NL-Bayes RMSE = 10.53
Though widely accepted, RMSE is not a perfect metric because un-
like human eyes, it is insensitive to details. For instance, Fig.1.6(d) and
Fig.1.6(f) show that a smoother background makes a more pleasant
looking portrait than 1.6(e), notwithstanding a higher RMSE. Similarly,
Fig.1.7(d) show that owing to a more subtle approach to identifying ﬂat
areas, S-PLE preserves more ﬁne structures than NL-Bayes 1.7(f).
However, 1.7(d) also reveals that because of its intrinsically local ap-
proach to orientation detection, structures only observable on a larger
scale cannot be kept well. In relation to BM3D and NL-Bayes, a tendency
for S-PLE to overlook structures amid strong noise is also documented by
the image computer. This points to another inherent deﬁciency of S-PLE:
patch similarity is not exploited because it is hard for a Gaussian mixture
to model patch position.
1.3
Appendix
Let us denote NN := Z ∩[1, N] in what follows.

28
Chapter 1. SURE guided Gaussian mixture image denoising
Theorem 1.2
Let (Xt,s)(t,s)∈Z2 be a real-valued stochastic process such that
∀(t, s), (t′, s′) ∈Z2, E[Xt,s] = µ, cov[Xt,s, Xt′,s′] = RX(t −t′, s −s′)
where µ is a constant and RX(·, ·) satisﬁes
∑
(t,s)∈Z2
|RX(t, s)| < +∞.
Then the empirical average
AN := N−2
∑
(t,s)∈N2
N
Xt,s
converges to µ both almost surely and in L2 as N goes to inﬁnity.
Proof: because of
E[∥AN −µ∥2] = N−4
∑
(t,s)∈N2
N
(t′,s′)∈N2
N
RX(t −t′, s −s′),
Lebesgue’s dominated convergence theorem implies
lim
N→∞N−2
∑
(t,s)∈N2
N
(t′,s′)∈N2
N
RX(t −t′, s −s′) =
∑
(t,s)∈Z2
RX(t, s).
The convergence in L2
lim
N→∞E[∥AN −µ∥2] = 0
follows from
E[∥AN −µ∥2] ≤N−2 ∑
(t,s)∈Z2
|RX(t, s)|.
(1.13)
In addition, Markov’s inequality, combined with (1.13), leads to
∀c > 0,
+∞
∑
N=1
P(|AN −µ| ≥c) < +∞.
The almost sure convergence follows from the Borel-Cantelli lemma. □
The condition
∑
(t,s)∈Z2
|RX(t, s)| < +∞
requires RX(·, ·) to decay fast enough so that instances of Xt,s from two
sites far from each other do not behave in sync. In view of the proof, this
condition can be weakened to
∃α ∈[0, 1), lim sup
N→∞
N−α
∑
(t,s)∈N2
N
|RX(t, s)| < +∞.

2
E-PLE: un algorithme
performant d’inpainting
L
e mélange de gaussiennes permet de décrire le comportement a priori des
patches. Dans ce chapitre, nous présentons une analyse probabiliste de
l’algorithme piecewise linear estimation (PLE) appliqué à l’inpainting et, en
utilisant efﬁcacement un mélange gaussien, proposons plusieurs amélio-
rations théoriques et numériques.
2.1
Introduction
2.1.1
Inpainting
Inpainting est une technique d’interpolation qui essaie de ramener une
image masquée à son état initial en exploitant au mieux l’information
présente dans la partie visible de la même image.
Historiquement, l’un des premiers travaux portant sur le sujet est Mas-
nou and Morel (1998) dans lequel les auteurs, en s’inspirant de la formule
de co-aire, proposent de minimiser la courbure de l’image à restaurer à
travers une fonctionnelle. Ensuite une variante dans l’espace de fonctions
à variation bornée Shen and Chan (2002) est suggérée. Depuis les efforts
se multiplient et plusieurs approches telles que les EDPs Bertalmio et al.
(2000) et les échantillonnages préférentiels Efros and Leung (1999) sont
mises en avant. Cette dernière fait partie d’un paradigme qui repose sur
la similarité et se décline en plusieurs algorithmes de renom dont Non-
Local Means Buades et al. (2005) et BM3D Dabov et al. (2007).
À l’initiative des travaux comme Elad and Aharon (2006), une autre
voie de recherche s’oriente vers la construction d’un dictionnaire redon-
dant permettant d’avoir une représentation parcimonieuse des patches. Il
en résulte des avancées récentes Zoran and Weiss (2011), Yu et al. (2012)
donnant encore un nouveau point du vue via la modélisation gaussienne.
2.1.2
Estimation linéaire par morceaux
L’idée sur laquelle reposent de nombreux algorithmes de restora-
tion d’image Chatterjee and Milanfar (2009), Yu et al. (2012) vient de
l’observation qu’à l’échelle du patch, la caractéristique la plus saillante
d’une image naturelle est l’orientation. Cela conduit à modéliser les
29

30
Chapter 2. E-PLE: un algorithme performant d’inpainting
patches par une famille de modèles gaussiens décrivant approximative-
ment toute inclinaison d’angle possible, à savoir entre 0 et π. Auxquels
s’ajoute un modèle supplémentaire pour rendre compte de la classe de
patches contenant essentiellement de la texture.
Pour restaurer une image masquée, il ne reste qu’à associer à tout
patch partiellement observé son meilleur modèle dans la famille gaussi-
enne et puis d’appliquer des outils usuels consistant à trouver un candi-
dat optimal qui minimise un terme d’attache aux données tout en tenant
compte d’une certaine contrainte de régularité.
Par conséquent, la restoration s’opère patch par patch et le ﬁltre
de Wiener est utilisé par défaut, d’où le nom estimation linéaire par
morceau, ou piecewise linear estimation (PLE) en anglais pour cette caté-
gorie d’algorithmes. Pour simpliﬁer le langage, dans tout ce qui suit, nous
désignons par PLE uniquement l’algorithme tel qu’il est décrit dans Yu
et al. (2012).
Dans ce chapitre, nous présentons une analyse probabiliste de PLE
appliqué à l’inpainting et, en utilisant efﬁcacement un mélange gaussien,
proposons une variante signiﬁcative E-PLE (où E signiﬁe Enhanced) de
manière à lui apporter plusieurs améliorations théoriques et numériques.
2.2
PLE
2.2.1
Construction et sélection de modèle
Aﬁn de souligner la nouveauté de notre algorithme, nous détaillons
comment PLE construit l’ensemble de modèles gaussiens et en choisit un
pour un patch donné.
Une gaussienne est complètement caractérisée par son espérance et sa
covariance. À l’exception du modèle pour les textures, PLE construit les
modèles orientés à partir d’exemples venant de quelques images synthé-
tiques en niveaux de gris dont les gradients à l’intérieur de leurs domaines
s’inclinent dans la même direction. Une telle image est créée en convolu-
ant un noyau gaussien avec une image dont les pixels n’ont que deux
valeurs distinctes et sont rangés de sorte qu’ils peuvent être séparés selon
leur valeur par un segment de droite.
Une décomposition spectrale de la covariance estimée donne une base
orthonormale. PLE garde tous ses composants pour le modèle en question
même si une matrice de covariance représentant une inclinaison θ n’est pas
de plein rang puisqu’aucune combinaison linéaire de ses vecteurs propres
ne peut produire l’inclinaison θ + π
2 .
Le modèle pour les textures est construit avec la base orthonormale
DCT et possède les mêmes valeurs propres que les modèles orientés qui,
à la différence de E-PLE, sont ﬁxées arbitrairement au début de même que
leur espérance.
Dès lors supposons qu’il y a K modèles gaussiens. Soit un patch par-
tiellement observé ˜P. PLE le ﬁltre K fois au total en maximisant la vraisem-
blance sous chacun de ces modèles
bPk = argmin
P
∥MP −˜P∥2
σ2
+ (P −µk)TΣ−1
k (P −µk)
(2.1)

2.3. E-PLE
31
où M, σ, µk, Σk désignent le masque associé au patch ˜P, le niveau de bruit
blanc des pixels visibles, l’espérance et la covariance du modèle k pour
l’indice k allant de 1 à K.
La sélection du modèle se fait ensuite par l’évaluation des probabilités
conditionnelles
k∗= argmax
1≤k≤K
p( bPk, ˜P | µk, Σk)
(2.2)
avec bPk∗retenu comme le meilleur estimateur de l’état initial.
Enﬁn, nous mettons à jour tous les modèles avec les estimateurs qui
leurs sont attribués et entamons un nouvel cycle de ﬁltrage et d’estimation
si besoin.
2.2.2
Comment améliorer PLE ?
Malgré ses bons résultats, PLE reste améliorable.
Premièrement, si l’algorithme décrit précédemment est appelé EM par
ses auteurs, il ne s’agit pas à proprement parler de expectation maximization
Dempster et al. (1977), la classe d’algorithmes reconnue pour leur capacité
de faire croître la vraisemblance d’un mélange sur lequel PLE ne repose
pas car son modèle manque la probabilité a priori w·
p(P) =
N
∑
k=1
wkN (P | µk, Σk)
(2.3)
qui ne peut être inférée par l’échantillonnage synthétique.
Deuxièmement, il est préférable que les modèles soient alimentés
par de vraies données dès le départ, ce qui permet d’accélérer la phase
d’apprentissage de l’algorithme face aux images réelles.
Finalement, comme les covariances des patches orientés n’ont pas be-
soin d’être de plein rang, restreindre le nombre de leurs vecteurs propres
réduit le risque de surapprentissage et aussi le coût de calcul.
2.3
E-PLE
2.3.1
La classiﬁcation des patches avec EM
La construction du mélange suit la procédure expliquée dans 1.1.
Similaire à 1, l’algorithme EM Dempster et al. (1977) est adapté à notre
cadre où les données ne sont que partiellement observées aﬁn d’inférer
les paramètres du mélange, y compris ceux pour caractériser les modèles
individuels et leur poids probabiliste wk. La classiﬁcation des patches vise
à miniser le risque de Bayes 1.6
La ﬁgure 2.1 illustre un exemple de classiﬁcation des patches.
L’échantillonnage nous donne une initialisation raisonnable du mélange
composé de 20 modèles À l’issue de trois itérations d’EM, les modèles
orientés se voient attribuer plus d’importance au détriment du modèle
texturé, un comportement auquel nous nous attendons bien.

32
Chapter 2. E-PLE: un algorithme performant d’inpainting
(a)
(b)
(c)
(d)
(e)
(f)
Figure 2.1 – La classiﬁcation des patches masqués à l’aide d’EM. (a) image originale (d)
image masquée (b) la probabilité a priori des modèles initialisés (e) la probabilité à priori
inférée par EM au bout de sa troisième itération (c) (resp. (f)) carte d’association patch-
modèle au bout de la première (resp. troisième) itération où les couleurs représentent les
différents modèles dont la couleur blanche pour le modèle plat.
2.3.2
Résultats numériques et discussions
Dans cette étude numérique, nous avons pris quatre images et deux
types de masques, à savoir le masque à texte et le masque aléatoire où
tout pixel a une certaine probabilité d’être rendu invisible. Les algorithmes
sont itérés six fois dans tous les cas. Le critère d’évaluation est RMSE (root
mean square error).
Les résultats montrés au tableau 2.1 conﬁrment que plus les images
à traiter sont dégradées, plus l’effet dû à l’incorporation de la probabil-
ité de mélange se fait sentir car c’est à ce moment là que nous avons le
plus besoin de faire appel à la connaissance a priori pour déterminer les
appartenances des patches.
En pratique, avec moins de facteurs à calculer, E-PLE est beaucoup plus
rapide que PLE, d’autant plus que grâce à une initialisation plus adaptée,
souvent E-PLE n’a besoin que d’une seule itération pour parvenir à un
bon résultat en RMSE tandis que PLE typiquement en nécessite beaucoup
plus.

2.3. E-PLE
33
(a)
(b)
(c)
Figure 2.2 – D’autres images utilisées dans la comparaison des algorithmes. (b) formes
(c) barbara (d) grenouille
Table 2.1 – Comparison des algorithmes
text
barbara
grenouille
parrot
formes
PLE
4.2
4.3
6.1
5.9
E-PLE
5.0
4.7
6.6
5.7
rand 0.2
barbara
grenouille
parrot
formes
PLE
1.7
2.0
3.7
2.4
E-PLE
1.9
2.2
3.8
2.3
rand 0.4
barbara
grenouille
parrot
formes
PLE
3.7
4.0
6.9
5.4
E-PLE
3.7
4.1
6.7
4.7
rand 0.6
barbara
grenouille
parrot
formes
PLE
10.6
7.1
10.9
11.2
E-PLE
7.9
6.8
10.0
8.8
rand 0.8
barbara
grenouille
parrot
formes
PLE
20.1
11.0
16.0
19.4
E-PLE
16.9
10.8
14.8
16.5


Part II. Conditional
expectation and neural
networks
The second part focuses on multilayer neural networks and their appli-
cations to image processing. The fundamental observation is that driven
by backpropagation, feedforward neural networks seek to approximate a
conditional expectation. Though larger neural networks tend to perform
better, the following work mainly explores the possibility to reduce their
sizes and training cost.
We have chosen image demosaicking and denoising because unlike
random masks arising in the context of image inpainting, Bayer color ﬁlter
array and additive Gaussian noise are two types of distortion with locally
deﬁned data format and thus ﬁt well into the patch regression framework.
35


3
A multilayer neural
network for image
demosaicking
T
he recent revival of interest in artiﬁcial neural networks has been fueled
by their successful applications in various image processing and computer
vision tasks. In this chapter, we make use of the rotational invariance of the
natural image patch distribution and propose a multilayer neural network
for demosaicking 4 × 4 image patches. We show that it does surprisingly
well compared to state-of-the-art approaches requiring much larger input
sizes.
3.1
Introduction
Most digital cameras place a Bayer Bayer (1976) color ﬁlter array (CFA)
in front of the sensor to record just one color (R, G or B) at each pixel
site. This results in a mosaiced image. The process of restoring the missing
color information in such an image through cross-channel interpolation is
termed demosaicking. A huge body of work has been done in this ﬁeld Li
et al. (2008) including two neural network inspired approaches Kapah and
Hel-Or (2000), Go et al. (2000). However, recent successful applications
of multilayer neural networks in image processing Burger et al. (2012)
warrant a revisit of the subject.
Evaluated in MSE, a patch based demosaicking algorithm should ap-
proximate the expectation of the missing pixels conditional on the visi-
ble ones under some patch distribution. For an illustration, we start with
pixels, or 1 × 1 patches, for which conditional expectations are simple to
evaluate. For instance, to estimate the green channel given its red counter-
part, it sufﬁces to sample a large number of color pixels having the same
red intensity and take the average of their green intensities (see Fig.3.1).
Unsurprisingly, despite their accuracy, the obtained conditional expecta-
tions do not work well even when applied to an image taken from the
same image set (see Fig.3.2). Because of the quasi-linear relationship in all
three cases, here demosaicking tends to make a gray-looking image out
of a mosaiced one. In addition, since the local geometry is not taken into
account, the so-called zipper effect is pronounced.
37

38
Chapter 3. A multilayer neural network for image demosaicking
(a)
(b)
(c)
(d)
(e)
(f)
Figure 3.1 – In the McMaster dataset Zhang et al. (2011): conditional expectations of
the other two channels given the (a) red (b) green (c) blue channel and their respective
un-normalized prior distributions (d) red (e) green (f) blue.
(a)
(b)
Figure 3.2 – Demosaicking a McMaster subimage with pixel-wise conditional expecta-
tions computed from the same dataset.
Therefore, the natural extension is to enlarge patches. Its beneﬁt is ob-
vious from the previous discussion, even though computing conditional
expectations are no longer as easy, because the same approach quickly
becomes intractable due to the curse of dimensionality. Fortunately, stud-
ies have shown that neural networks are universal approximators Barron
(1994), Hornik et al. (1989) and that deep networks tend to represent sig-
nals more efﬁciently Bengio (2009). Owing to the problem’s non-convex
nature in general, it was not clear as to how best to tap into this potential
from a numerical standpoint. However, since 2006, major advances have
been made in this direction Bengio (2009). One way to train a deep, or mul-

3.2. Training a deep neural network
39
tilayer, neural network is an autoencoder-enabled unsupervised learning
process.
3.2
Training a deep neural network
First, let us introduce the concept of autoencoder. An autoencoder is
a neural network whose fan-in x and fan-out bx are vectors of the same
dimension, related by a non-linear hidden layer of potentially different
size
bx = Va + h
a = tanh(Wx + b)
(3.1)
or
bx = tanh(Va + h)
a = tanh(Wx + b)
(3.2)
where tanh(·) is understood to be applied element-wise. The ﬁltering de-
ﬁned by (W, b) followed by the hidden layer transforms the fan-in x to
the activation a, which is supposed to code x in such a way as to make
the reconstruction bx close to x. Therefore, building an autoencoder can be
seen as extracting the most statistically relevant features from the fan-in.
Suppose that we have n input signals (xj)1≤j≤n ∈Rd×n which produce
n activations a := (aj)1≤j≤n ∈Rmd×n, the autoencoder’s parameters are
determined through minimizing the following objective
1
nd
n
∑
j=1
∥bxj −xj∥2
2 +
α
md2 (∥V∥2
2 + ∥W∥2
2) + βsp(a, n, d, ρ)
(3.3)
with α, β, ρ three preﬁxed hyper-parameters. The last penalty, intended to
induce an over-complete dictionary for sparse representation, is a function
of average activation
sp(a1, · · · , an, n, d, ρ) = 1
md
md
∑
k=1
KL
 ρ
 1
n
n
∑
j=1
|ajk|

where
1. m is a redundancy control. Together with the activation level ρ ∈
(0, 1), it suggests that ideally, ρmd hidden nodes per patch are fully
activated on average.
2. KL(·||·) is the standard Kullback-Leibler divergence between two
Bernoulli probabilities. Regardless of ρ, this divergence strongly pe-
nalises average activation near 0 and 1, either because the associated
feature is irrelevant or because it has rather low information value.
Yet it is still possible for a spurious feature to reach the prescribed
activation level if its norm is big enough, hence the regularization
term ∥W∥2
2.

40
Chapter 3. A multilayer neural network for image demosaicking
3. The term ∥V∥2
2 is there to prevent over-ﬁtting. Another concern is to
prevent an autoencoder from learning an identity, which may come
with a small W and a large V to exploit the quasi-linearity of tanh(·)
around zero. Thus the prior on V helps. See Vincent et al. (2008) for
another solution.
4. The features recorded in W ought to stay away from 0 thanks to the
sparsity constraint. If there are not enough distinct features to ﬁll all
the hidden nodes, almost identical features may result, which indi-
cates a higher than necessary m or poorly chosen hyper-parameters.
Turn now to our deep neural network. Given a κ × κ mosaiced patch
v (hence d = κ2), represented as a Rκ2-valued column vector, our network
with two hidden and one linear output layers will make an educated guess
bu as to what the missing pixels u ∈R2κ2 should look like according to
bu = W3[vt, tanh(W2 tanh(W1v + b1) + b2)t]t + b3.
Note that this architecture is meant to let the neural network focus on the
non-linear part of the color interpolation.
To determine (Wl, bl)1≤l≤3, a combination of supervised and unsuper-
vised learning, as advocated in Bengio (2009), was used. We ﬁrst drew n
random patches from some high quality color images. To each of these
patches, the RGGB Bayer CFA was applied to separate the visible pixels
v from the invisible ones u. An autoencoder was trained on v and the re-
sultant ﬁlter (W, b) henceforth became (W1, b1). The activations from the
ﬁrst hidden layer were then computed, on which another autoencoder was
trained to set up (W2, b2). Finally, the output linear layer was initialized
by a linear regression to ﬁt the teaching signals u. All the involved objec-
tives (3.3) were optimized using L-BFGS Nocedal (1980). Note that before
starting training, it helps to zero-phase whiten v and u (see Algorithm ).
Zero-phase whitening
1: Input: n vectors pj ∈Rd.
2: Output: the whitening operator W.
3: Parameter: smoothing factor σZ.
4: Center the inputs ˜pj = (pj −¯p)/255 with ¯p = 1
n ∑n
j=1 pj.
5: Run the principal component analysis (PCA) on ( ˜pj)1≤j≤n to get their eigenvectors and
eigenvalues (φi, λi)1≤i≤d.
6: W(p) = 255−1 ∑d
i=1
q
1
λi+σz

φi, p −˜p

φi with

·, ·

a standard scalar product.
Once fully conﬁgured, the deep network was ﬁne-tuned with the back-
propagation algorithm LeCun et al. (1998) on the same training data for
several more rounds. Fresh data was then drawn in to run the stochastic
gradient in the hope of further improving the network. In these last two
stages, the network’s generalization error was assessed on a distinct set
of validation examples. Since we could not know in advance the hyper-
parameters most conducive to good learning, an exhaustive exploration in
the parameter space was carried out.
Trained to restore color removed by the RGGB CFA represented in
Fig.3.3(a) for 2 × 2 patches, a network should be able to handle those
masked by any of the other three CFAs as well because the patch distribu-
tion is rotation-invariant. The same argument remains true when extended

3.3. Experiments
41
to 2k × 2k patches with k ≥1. In practice, it means that each missing color
pixel can be estimated multiple times, thereby enhancing the algorithm’s
overall performance.
(a)
(b)
(c)
(d)
Figure 3.3 – Four basic blocks of the Bayer pattern
3.3
Experiments
In our experiments, the patches were 4 × 4 and whitened using Algo-
rithm with σZ = 0.1 for inputs and σZ = 0 for outputs. The ﬁrst hidden
layer containing 80 nodes was trained 400 rounds using an autoencoder of
type (3.1) with α = 0.4, β = 5, ρ = 0.1 on 105 examples. The second hidden
layer also has 80 nodes, and was trained 400 rounds using an autoencoder
of type (3.2) with hyper-parameters α = 0.4, β = 0.1, ρ = 0.05. The ﬁnal
layer followed from
(W3, b3) = argmin
(W,b)
∥˜u −W ¯v −b∥2
2 + λ∥W∥2
2
where ¯v is the concatenation of the whitened input ˜v and their activations
from the network’s second hidden layer. ˜u is the whitened output. The
decay parameter λ was set to 0.005.
Figure 3.4 – Evolution of the validation RMSEs during the stochastic gradient descent.
Though noisy, this RMSE path clearly demonstrates the value of stochastic gradient de-
scent.
When tracking the neural network’s performance (Fig.3.4) on a valida-
tion dataset of 104 patches, we ran 4 × 106 rounds of stochastic gradient
descent with batch size 100 at a learning rate 0.001 to further drive down
the objective
∥˜u −f ( ˜v, θ)∥2
2 + λ∥W3∥2
2,
where f (·, θ) is the network deﬁned by its parameter set θ.

42
Chapter 3. A multilayer neural network for image demosaicking
(a)
(b)
(c)
(d)
Figure 3.5 – Examples of 3.5(a) color patches 3.5(b) RGGB CFA ﬁltered patches and
3.5(c) zero-phase whitened patches used in the training. 3.5(d) All the 80 learned features
stored in the ﬁrst hidden layer of the trained network.
The training and validation examples were collected from two distinct
sets, having respectively 2992 and 10 Flickr images. Having been demo-
saicked one way or another, these images were not fed directly to the
neural network or it might wind up simply imitating other demosaicking
algorithms. To guarantee their quality, we downsampled the images by 2
after convolving them with a Gaussian kernel of standard deviation equal
to 1.2 Morel and Yu (2011).
We tested our neural network against some best performing methods
available. The results, stated in both RMSE and the zipper effect as in
Buades et al. (2009), are reported in Tab.3.1 for the two datasets (Fig.3.6).
As stated in Mairal et al. (2009), the last ﬁve Kodak images were used to
tune KSVD. They were excluded for fairness.
Figure 3.6 – The Kodak and McMaster dataset
3.4
Discussion
The experiments show that our tiny neural network compares favor-
ably with these state-of-the-art algorithms. We have deliberately chosen
images of vibrant colors to constitute our training set, which explains in
part that the resultant network works better on McMaster than on Kodak.
Fig.3.7 shows that the network handles abrupt color transitions remark-

3.4. Discussion
43
McMaster
NN
KSVD
CS
SSD
HA
Paliy
ZW
1
8.52
9.67
8.92
10.60
10.45
11.61
11.65
2
4.66
4.89
5.03
5.03
5.08
5.36
5.44
3
5.75
5.54
5.57
5.81
6.53
5.97
6.03
4
3.70
3.49
4.37
3.90
4.53
4.48
5.09
5
4.84
5.98
5.37
6.17
6.00
6.82
7.20
6
3.61
3.36
3.82
4.33
4.41
5.14
5.65
7
3.83
2.68
2.50
3.80
4.37
2.78
2.79
8
3.16
2.96
3.26
3.46
3.76
3.23
3.49
9
3.57
3.65
3.97
4.11
4.32
4.79
5.17
10
3.05
3.13
3.25
3.30
3.50
3.88
4.02
11
2.78
2.74
2.97
3.06
3.33
3.61
3.66
12
2.96
3.20
3.32
3.33
3.54
3.82
3.89
13
2.42
2.51
2.61
2.50
2.65
2.99
3.03
14
2.96
3.09
3.28
3.15
3.27
3.76
3.60
15
2.89
3.02
3.10
3.15
3.29
3.51
3.63
16
4.82
6.32
6.15
7.15
6.94
8.92
8.11
17
5.44
6.05
5.55
7.40
7.28
8.83
9.10
18
4.38
4.71
5.03
5.16
5.22
5.34
5.34
rmse avg.
4.07
4.27
4.33
4.74
4.91
5.26
5.38
zipper avg.
0.34
0.34
0.30
0.33
0.38
0.38
0.39
Kodak
KSVD
Paliy
ZW
NN
SSD
CS
HA
01
2.23
2.44
2.73
4.62
4.70
4.09
5.35
02
2.19
2.26
2.42
3.32
3.91
4.32
3.49
03
1.54
1.69
1.86
2.57
3.05
3.88
3.04
04
1.98
2.34
2.53
3.05
3.10
4.05
3.30
05
2.64
3.33
3.25
4.19
4.36
4.72
4.88
06
2.13
2.30
2.38
4.24
4.16
4.29
4.78
07
1.64
1.82
2.06
2.45
2.94
3.82
2.84
08
3.33
3.51
3.72
5.72
5.19
5.14
6.32
09
1.62
1.67
1.74
2.37
2.64
3.69
2.75
10
1.78
1.87
1.92
2.40
2.75
3.71
2.88
11
2.16
2.36
2.43
3.80
3.71
4.11
4.09
12
1.48
1.62
1.70
2.48
2.57
3.50
2.58
13
3.74
3.95
4.19
7.76
6.48
5.10
8.09
14
2.81
3.51
3.65
4.01
4.71
5.01
4.66
15
2.25
2.62
2.73
3.17
3.94
4.59
3.97
16
1.44
1.58
1.56
2.98
3.57
3.95
3.63
17
1.95
2.02
2.02
2.95
2.74
2.20
2.97
18
3.17
3.65
3.50
5.20
4.55
4.15
5.20
19
1.95
2.20
2.19
3.52
3.02
2.54
3.40
rmse avg.
2.21
2.46
2.55
3.72
3.79
4.04
4.11
zipper avg.
0.22
0.24
0.25
0.36
0.32
0.23
0.35
Table 3.1 – The results from our neural network (NN), (the Kodak-tuned) KSVD Mairal
et al. (2009), CS Getreuer (2011a; 2012), SSD Buades et al. (2009; 2011b), HA Hamilton
and Adams (1997), Paliy Paliy et al. (2007) and ZW Zhang and Wu (2005), Getreuer
(2011b) on McMaster (top) and Kodak (bottom). The row-wise best results are in bold.
The columns are ordered to reﬂect the performances in RMSE. We only show the average
zipper effects for lack of space.

44
Chapter 3. A multilayer neural network for image demosaicking
NN
HA
CS
KSVD
ZW
Paliy
SSD
4×4
5×5
5×5
8×8
9×9
12×12
15×15
Table 3.2 – Comparison of the neighborhood size demanded by the seven algorithms.
Note that because of their design, these algorithms do not necessarily use every pixel in
a given neighborhood. Nonetheless, the neighborhood size remains a basic indicator of the
associated algorithmic complexity.
ably well. However, its also reveals the neural network’s inability to re-
cover high frequency patterns (Tab.3.2).
Recent evidence Burger et al. (2012) suggests that endowed with a
higher capacity, a deep network should perform substantially better with
larger patches, because more structural information can then be discov-
ered. However, training a larger network incurs a higher computational
cost. It took roughly three days on a 8-core Linux machine to train the
current network.
As opposed to many noise sensitive algorithms, the neural network
approach may be extended to noisy image demosaicking, which is cer-
tainly of a bigger practical interest because denoising and demosaicking
could then be handled in one single procedure Hirakawa and Parks (2006),
Chatterjee et al. (2011).

3.4. Discussion
45
(a) original
(b) NN (ours)
(c) KSVD Mairal
et al. (2009)
(d) CS
Getreuer
(2011a)
(e)
ZW
Zhang
and Wu (2005)
(f)
SSD
Buades
et al. (2009)
(g)
Paliy
Paliy
et al. (2007)
(h) HA Hamilton
and Adams (1997)
(i) original
(j) NN
(k) KSVD
(l) CS
(m) ZW
(n) SSD
(o) Paliy
(p) HA
(q) original
(r) NN
(s) KSVD
(t) CS
(u) ZW
(v) SSD
(w) Paliy
(x) HA
Figure 3.7 – Comparison of the seven algorithms: our neural network does not do well
when image patterns to recover oscillate much. In contrast, it does interpolate well where
color changes abruptly. Visually speaking, contour stencil Getreuer (2011a) yields the
closest numerical results. However, the neural network seems to be more accurate on
blobs.


4
Can a single image denoising
neural network handle all
levels of Gaussian noise?
A
recently introduced set of deep neural networks designed for the image
denoising task achieves state-of-the-art performance. However, they are
specialized networks in that each of them can handle just one noise level
ﬁxed in their respective training process. In this chapter, by investigating
the image patch distribution invariance with respect to linear transforms,
we show how to make a single existing deep neural network work well
across all levels of Gaussian noise, thereby allowing to signiﬁcantly reduce
the training time for a general-purpose neural network powered denoising
algorithm.
4.1
Introduction
Recently, a set of deep neural networks, or multi-layer perceptrons
(MLPs) designed for the image denoising task Burger et al. (2012) has
been shown to outperform BM3D Dabov et al. (2007), widely accepted as
the state-of-the-art. Although these enormous deep networks only work
at the noise levels which they were trained for, this turn of events clearly
demonstrates the potential of a pure learning strategy. A philosophical
difference sets the two patch-based methods apart: BM3D, a major spin-
off of the original non-local means Buades et al. (2005), seeks information
exclusively inside the noisy image while the neural network derives all its
power by looking at noisy and clean patch pairs gathered from other im-
ages. Other algorithms exist Elad and Aharon (2006), Mairal et al. (2009),
Zoran and Weiss (2011), Burger et al. (2013) which fall between these two
ends of the spectrum.
As pointed out in Chapter 3, whatever their architectures, neural net-
works as a class of universal approximators Barron (1994), Hornik et al.
(1989) seek to approximate the conditional expectation under some input
distribution. In our setting, let x, ˜x, and y denote the clean, noisy and de-
noised patch. Note that y does not necessarily have the same dimension
as ˜x. All the neural networks Burger et al. (2012) under this study, for in-
stance, produce a y ∈R17×17 based on a noisy observation ˜x ∈R39×39
47

48
Chapter 4. Can a single image denoising neural network handle all levels of Gaussian noise?
which includes not only y’s corresponding noisy pixels but also its sur-
rounding ones. Also note that with the true natural patch distribution
beyond reach, a huge number of patches are drawn stochastically Bot-
tou (2010) from a large natural image dataset to provide the underlying
distribution for computing
θ∗= argmin
θ
E∥f ( ˜x, θ) −x∥2
2
(4.1)
= argmin
θ
E∥f ( ˜x, θ) −E[x| ˜x]∥2
2
where f (·, θ) : ˜x 7→y is a neural network parametrized by its connection
weights θ. Due to this problem’s non-convex nature in general, instead of
the potentially intractable θ∗, a good θ, judged on the basis of the resulting
network’s generalization error, is usually accepted as a solution.
In spite of their impressive performance, the proposed deep networks
are impractical. As stated in the paper itself Burger et al. (2012): our most
competitive MLP is tailored to a single level of noise and does not generalize
well to other noise levels. This is a serious limitation which we already tried to
overcome with an MLP trained on several noise levels. However, the latter does
not yet achieve the same performance for σ = 25 as the specialized MLP. Since
a standard general-purpose algorithm for Gaussian noise removal ought
to be able to handle all levels of noise, this limitation seems to require a
series of such networks, one for each noise level, which is impractical and
even unrealistic especially in view of their prohibitive training time Burger
(2013).
In this chapter, through an analysis of the interplay between the neu-
ral networks and the underlying patch distribution they seek to learn,
we show how to construct a linear transform that moves natural image
patches within the support of their distribution, which is then used to
make a single existing deep neural network work well across all levels of
Gaussian noise. In the concluding section, using the natural patch distri-
bution invariance argument, we hint that further patch normalization may
help scale down these deep neural networks by reducing their domain of
deﬁnition without compromising their power.
4.2
A single neural network for all noise levels
To make a single neural network work for all noise levels, ﬁrst we
need to investigate the statistical regularity of the natural patch space, or
the support of the natural patch distribution, with respect to some linear
transforms: we drew 106 39-by-39 random patches from the Berkeley Seg-
mentation Dataset (BSD500) rendered to grayscale with Matlab’s rgb2gray
function. The patches were then normalized using the formula
¯p = (p/255 −0.5) · 5
(4.2)
provided in Burger et al. (2012) in order to conform them to these deep
neural networks’ training patch distribution. For each normalized patch,
we computed the mean and standard deviation of its 1521 pixels and
then plotted their population distribution along these two dimensions.
For comparison, we did the same with the PASCAL VOC 2012 dataset.

4.2. A single neural network for all noise levels
49
(a)
(b)
(c)
(d)
Figure 4.1 – 2D histogram of random patches from 4.1(a) the grayscale BSD500 and
4.1(c) the grayscale PASCAL VOC 2012. Their horizontal (resp. vertical) axis represents
the normalized patch’s mean (resp. standard variation). 4.1(d) and 4.1(b) plot their re-
spective marginal cumulative distribution function along the patch mean. In both cases,
the normalized patches have their mean concentrated around −0.5. Also note that at the
two ends of the horizontal axis, there are two important ﬂat patch clusters because of
saturation.
The results (Fig.4.1) show that the means of the normalized natural
patches concentrate around −0.5. Even without access to the supervised
pairs used in Burger et al. (2012), we can therefore expect their neural
networks trained according to the criterion (4.1) to do well with patches
from this neighborhood because of the sheer number of examples avail-
able. Moreover, the patch-wide variance peaking at the patch-wide means
around −0.5 strongly indicates a higher tolerance for linear transforms
there, that is, it is more probable for a natural patch p transformed by
q = a · (p −s) with s some constant patch and a ≥0
to remain natural if q’s mean is close to −0.5.
To verify this conjecture that a linear transform exists which only
moves patches within the support of the natural patch distribution, we de-
signed a test that shifts the means of the patches to the same value before
denoising them using a neural network, after which the shifted differences
were added back individually to obtain their ﬁnal, denoised versions. It is
important to note that thanks to a high ratio between the patch size and
σ, estimating the clean patch mean from its noisy version (Line 7 in Test)
is very reliable.

50
Chapter 4. Can a single image denoising neural network handle all levels of Gaussian noise?
Test Patch Mean Normalization Test
1: Input: n clean patches pj of dimension 39 × 39
2: Output: n denoised (resp. clean) 17 × 17 patches bpj (resp. pj)
3: Parameter: noise variance σ2 and desired patch mean value m
4: for j = 1 to n do
5:
retrieve the 17 × 17 clean patch pj in the center of pj
6:
generate the normalized noisy patch
˜xj ←((pj + nj)/255 −0.5) · 5
with nj having 1521 i.i.d. Gaussian random variables N (0, σ2) and nj independent
of nj′ for j ̸= j′
7:
compute the patch mean shift sj =
1
1521 ∑1521
k=1 ˜xjk −m where ˜xjk is the k-th pixel in
˜xj
8:
shift the network’s input ∀k, ˜xjk ←˜xjk −sj
9:
denoise yj = fσ( ˜xj, θ) where fσ(·, θ) is the deep neural network Burger et al. (2012)
trained with Gaussian noise standard deviation σ
10:
shift the network’s output by the same amount ∀k, yjk ←yjk + sj in the opposite
direction
11:
reverse the normalization bpj ←(yj/5 + 0.5) · 255
12: end for
Running the test on 105 39-by-39 random patches drawn from the
grayscale BSD500, we computed the resultant root mean square error
(RMSE). Fig.4.2 shows that regardless of the applied noise strength σ, the
best empirical performance is attained with the patch mean shift set to
−0.5, thereby fully conﬁrming our supposition. In addition, observe that
the optimal patch mean shift incurs surprisingly little RMSE loss, which
is less than 0.1 for a noise level as high as 75.
(a)
(b)
Figure 4.2 – 4.2(a) (resp. 4.2(b)) plots the RMSEs resulting from the test with σ = 25
(resp. 75). The blue curve records the dedicated network’s performance with the patch
mean values ranging from −1.5 to 0.9. And the red line is the RMSE achieved on the
same test data without patch mean shift. Other available neural networks have also been
tested with very similar results.
The previous analysis paves the way for a generic network able to
handle all levels of noise. Let us use the neural network trained with the
noise level σ∗for instance. To restore a noisy patch ˜p with noise standard
deviation at σ, one multiplies ˜p by σ∗σ−1, apply the patch mean shift and
let the neural network operate on the normalized patch (see Algorithm).
Henceforth σ∗itself becomes a parameter for further optimization, too.

4.2. A single neural network for all noise levels
51
Algorithm Generic Neural Network Denoising
1: Input: noisy patch ˜p of dimension 39 × 39 and its noise level σ
2: Output: denoised 17 × 17 patch bp
3: Parameter: noise level σ∗of the trained neural network fσ∗(·, θ) and optimal shift
m = −0.5
4: Scale the noise ˜p ←σ∗σ−1 ˜p
5: Normalize the patch ˜x ←( ˜p/255 −0.5) · 5
6: Compute the patch mean shift s =
1
1521 ∑1521
k=1 ˜xk −m where ˜xk is the k-th pixel in ˜x
7: Shift the network’s input mean ∀k, ˜xk ←˜xk −s
8: Run the generic neural network denoising y = fσ∗( ˜x, θ)
9: Shift the network’s output by the same amount ∀k, yk ←yk + s in the opposite
direction
10: Reverse the normalization bp ←(y/5 + 0.5) · 255 · (σ∗σ−1)−1
(a)
(b)
Figure 4.3 – 4.3(a) Performance discrepancy between dedicated neural networks and
σ∗-indexed generic neural networks at handling different noise levels. The horizontal axis
marks various test Gaussian noise levels and the vertical axis the achieved RMSEs on 105
random patches from BSD500. 4.3(b) singles out the best generic network with σ∗= 25.
A comparison among various σ∗-indexed generic networks con-
structed this way (see Fig.4.3) shows that the one built with σ∗= 25 is
the best, which is hardly surprising because a neural network can learn
the most about the underlying patch space when noise is weak. More-
over, except for the extremely noisy case, one sees no tangible difference
in Fig.4.3(b) between a dedicated network and the best generic network.
Also observe that the higher the σ∗, the worse the resulting RMSEs at low
noise levels, an expected phenomenon since a high σ∗σ−1 exaggerates the
patch-wide variation so much that resultant patches no longer remain in
the natural patch space.
The implication of this analysis for future research is straightforward:
training a network with the same architecture but at an even lower noise
level may be rewarding. But it should also be said that too low a σ∗is
not likely to work well in a strong noise environment, as already observed
in Fig.4.3. Because the factor σ∗σ−1 will then ﬂatten all the meaningful
patch-wide variations, leaving the network unable to tell one patch from
another.
Put differently, what we have shown is that the trained deep network is
not very different from its most informative section. Hence, one may want
to train a network on mean normalized patches to improve performance,

52
Chapter 4. Can a single image denoising neural network handle all levels of Gaussian noise?
Table 4.1 – Comparison between dedicated neural networks and our algorithm (generic
σ∗= 25)
σ = 25
dedicated
generic
computer
7.99
8.10
dice
2.77
2.77
ﬂower
4.59
4.63
girl
3.38
3.41
trafﬁc
9.16
9.22
valldemossa
11.85
11.99
avg.
6.62
6.68
σ = 35
dedicated
generic
computer
9.63
9.82
dice
3.29
3.45
ﬂower
5.53
5.64
girl
3.88
4.07
trafﬁc
10.81
10.94
valldemossa
14.21
14.28
avg.
7.89
8.03
σ = 50
dedicated
generic
computer
11.59
11.92
dice
4.17
4.50
ﬂower
6.85
7.06
girl
4.60
4.92
trafﬁc
12.83
13.07
valldemossa
16.98
17.06
avg.
9.50
9.75
σ = 65
dedicated
generic
computer
13.16
13.82
dice
4.83
5.39
ﬂower
7.89
8.20
girl
5.28
5.74
trafﬁc
14.32
14.78
valldemossa
18.67
18.99
avg.
10.69
11.15
σ = 75
dedicated
generic
computer
14.10
14.78
dice
5.48
6.14
ﬂower
8.57
8.96
girl
5.66
6.20
trafﬁc
15.08
15.56
valldemossa
19.97
20.34
avg.
11.47
11.99
σ = 170
dedicated
generic
computer
20.51
21.81
dice
9.23
10.92
ﬂower
12.84
13.64
girl
8.79
10.54
trafﬁc
20.71
21.72
valldemossa
26.42
27.26
avg.
16.41
17.64
thanks to a denser data distribution. However, in so doing, one implicitly
trains on a marginal distribution and thus risks losing information.
To conclude, we tested the Algorithm with σ∗= 25 on six noise-free
images proposed for benchmarking various denoising algorithms (see Fig-
ure 1.5) and the results are compiled in Tab.4.1. Recall that even for σ = 25,
our generic network is different from the dedicated one, in that ours in-
volves one additional step of patch mean shift. The obtained results are
thus consistent with Fig.4.2(a).
4.3
Conclusion
In this chapter, we have shown how to make a single existing neural
network work well across all levels of Gaussian noise, thereby allowing

4.3. Conclusion
53
to reduce signiﬁcantly the training time for a general-purpose neural net-
work powered denoising algorithm.
To make deep neural network based algorithm more practical, the
other major challenge is to reduce their sizes. This might be achieved
through further patch normalization so as to reduce the neural network’s
input complexity. Rotation and scale invariances of natural image statistics
might be used for that purpose.


5
A note on the size of
denoising neural networks
P
atch based denoising algorithms seek to approximate the conditional ex-
pectation of clean patches given their related noisy observations. In this
chapter, we give a probabilistic account of how various algorithms ap-
proach this problem and in particular, through a conditional expectation
decomposition, we argue that small neural networks can do almost as
well as their large counterparts at denoising small-scale texture patterns.
The analysis further indicates that self-similarity and neural networks are
complementary paradigms for patch denoising, which we illustrate with
an algorithm that effectively complements BM3D with small neural net-
works, thereby outperforming BM3D with minor additional cost.
5.1
Introduction
5.1.1
Patch denoising and its probabilistic interpretation
Patch denoising, which lies at the heart of most denoising algorithms,
is concerned with estimating a noise-free patch X from a noisy observation
˜Y
˜Y = Y + N
where Y is also noise-free and N zero-mean Gaussian noise with a known
standard deviation σ. Y is usually related to X although we do not make
any assumption on its nature until later. As stated in the previous chapters,
the ideal ﬁlter in the sense of mean squared error (MSE) is the conditional
expectation EP[X| ˜Y] because of the equality
EP[X| ˜Y] = argmin
f
EP∥f ( ˜Y) −X∥2
2,
P a.e.
where the probability P is the triplet (X, Y, ˜Y)’s joint distribution.
When X and ˜Y form a Gaussian family, this conditional expectation is
the classic Wiener ﬁlter Kay (1993). More generally, a version of this P al-
most surely deﬁned function of ˜Y can be estimated with weakly correlated
samples (xi, yi)i≥1 of (X, Y) thanks to the equality
EP[X| ˜Y = ˜y] = lim
n→∞
∑n
i=1 p( ˜y|yi)xi
∑n
i=1 p( ˜y|yi) ,
P a.e.
55

56
Chapter 5. A note on the size of denoising neural networks
with
p( ˜y|yi) ∝exp(−∥˜y −yi∥2
2
2σ2
).
This point-wise estimator was used as an upper bound of the optimal
patch denoising MSE Levin and Nadler (2011). Despite its theoretical ap-
peal, this estimator suffers from the curse of dimensionality of a generic
Monte-Carlo simulation for its inability of performing importance sam-
pling, that is, prioritizing the samples whose y component is close to ˜y. In
addition, given the huge variety of natural patches, the mere existence of
a single noise-free candidate for each noisy patch requires a data storage
capacity too demanding for practical use.
An alternative is to make direct use of noisy observations. Assuming
that X and Y are two disjoint sets of pixels, we may use
EP[X| ˜Y = ˜y] = EP[ ˜X| ˜Y = ˜y] ≈∑n
i=1 ˜xiW(∥˜y −˜yi∥2)
∑n
i=1 W(∥˜y −˜yi∥2)
with the choice of weight function W(·) reﬂecting our belief in the condi-
tional expectation’s smoothness. The proof of this estimator’s asymptotic
consistency is generally known as Stone’s theorem Devroye et al. (1996).
Owing to self-similarity in natural images, this approximation scheme
turns out to be very effective and was popularized by non-local means
Buades et al. (2005), leading eventually to BM3D Dabov et al. (2007).
Nonetheless these nonparametric estimators are constrained by the
availability of data. A potential remedy is a parametric approach. How-
ever, unlike the Wiener ﬁlter which results from a parametric data mod-
elling, we can look for a parametric approximation of the conditional ex-
pectation, which is possible with a large and well structured class of func-
tions parameterized by a vector-valued θ:
θ∗= argmin
θ
EP∥fθ( ˜Y) −X∥2
2 = argmin
θ
EP∥fθ( ˜Y) −E[X| ˜Y]∥2
2.
This is where multilayer feedforward neural networks come into play.
Their fully-connected structure consists of a succession of non-linear hid-
den layers followed by a linear decoder
fθ(·) = s ◦hn ◦· · · ◦h1(·), n ≥1
with
∀1 ≤l ≤n, hl(z) = tanh(Wlz + bl)
and
s(z) = Wn+1z + bn+1
where the activation function tanh(·) is applied element-wise and the
parameter vector θ comprises all the connection weights and biases
(Wl, bl)1≤l≤n+1. They are tuned with stochastic gradient descent, also
called backpropagation LeCun et al. (1998) Bottou (2010) due to their par-
ticular function structure. In spite of their non-convex training objective,
as pointed out before, neural networks enjoy widespread use thanks to
their superior practical performances Bengio (2009). Unfortunately, their
are typically computationally intensive. For instance with four hidden lay-
ers having over 2000 units each, denoising neural networks Burger et al.

5.2. Small-scale texture pattern denoising
57
(2012) effectively require tens of millions of multiplication operations per
pixel when denoising a grayscale image.
Since it is recognized Burger et al. (2012) that as denoising algorithms,
neural networks do not always dominate BM3D, it was proposed Burger
et al. (2013) to train one more neural network of comparable size which
takes in the denoised patches from both BM3D and neural networks in
addition to the original noisy patch and outputs a combined result. This
method improves both algorithms because, again in view of the condi-
tional expectation, we have for any random triplet (X, ˜Y, ˜H)
EP∥X −EP[X| ˜Y]∥2
2 −EP∥X −EP[X| ˜Y, ˜H]∥2
2 = EP∥EP[X| ˜Y, ˜H] −EP[X| ˜Y]∥2
2 ≥0,
that is, more information helps lower the theoretical MSE bound. However,
the proposed approach doubles the already heavy computational load.
5.1.2
Our contribution
In this chapter, we investigate whether it is possible to scale down
the neural networks while preserving their performance. After observ-
ing that they constitute a better alternative than self-similarity for small-
scale texture pattern denoising, we argue that large neural networks and
their heavy computational cost may be unnecessary for this speciﬁc task
through a conditional expectation decomposition. This analysis further
indicates that self-similarity and neural networks are complementary ap-
proaches to patch denoising, which we illustrate with a light-weight algo-
rithm complementing BM3D with small neural networks geared towards
granular texture denoising, which achieves better performance than either
individually at minor additional cost.
5.2
Small-scale texture pattern denoising
5.2.1
A conditional expectation decomposition
Patterns in natural images tend to repeat themselves. Non-local means
Buades et al. (2005) and BM3D Dabov et al. (2007) use this prior to ﬁnd
similar neighboring patches to denoise. Further efforts have been made to
characterize the similarity in terms of orientation (Chapter 1, 6) or even
ﬁner features Zoran and Weiss (2011). However, no convincing mecha-
nism exists in these algorithms to handle non-repetitive small-scale tex-
ture patterns, which can be a problem in denoising a picture taken against
a background of lush foliage for example.
Neural networks thus offer a valuable solution because in texture ar-
eas, the interactions among pixels are of short range by nature. Formally,
let ˜Z, ˜Y, ˜X be three nested noisy patches with strictly decreasing domains.
With ˜X’s noise-free state denoted as X, it seems reasonable to posit that
X and ˜Z \ ˜Y are independent conditional on ˜Y with the boundary ˜Y \ ˜X
wide enough. It means that under such a generative probability, we have
E[X| ˜Z] = E[X| ˜Y].
But the same cannot be said of all noisy patterns. Consider for instance
ﬂat patches with identical grayscale intensity. Then, with dx, dy and do

58
Chapter 5. A note on the size of denoising neural networks
denoted as the number of pixels in X, ˜Y and ˜O := ˜Z \ ˜Y, the joint law of
X, ˜Y and ˜O is proportional to
exp(−∥
p
d−1
x ∥x∥21do −˜o∥2
2
2σ2
) exp(−
∥
p
d−1
x ∥x∥21dy −˜y∥2
2
2σ2
)µ(dx)d ˜yd˜o
where 1do represents the do-dimensional vector with identical entries equal
to 1 and µ(·) a probability supported on the dx-dimensional segment [0 ·
1dx, 255 · 1dx]. Thus, the conditional independence of X and ˜O given ˜Y no
longer holds.
Mathematically speaking, neural networks are trained on a more com-
plex distribution P. If P can be decomposed as αM + (1 −α)Q for some
α ∈(0, 1) with M having short range properties and Q not, a connection
of the two conditional expectations can be made explicitly.
Theorem 5.1
Let P, M, Q be three probabilities deﬁned on a common measurable space satisfying
P = αM + (1 −α)Q for some α ∈(0, 1). Let U, V be two random vectors with
EP∥U∥1 < +∞deﬁned on the same space. Then we have
EP[U|V] = αEP[dM
dP |V]EM[U|V] + (1 −α)EP[dQ
dP |V]EQ[U|V],
P a.e.
(5.1)
where dM
dP and dQ
dP are the Radon-Nikodym derivatives of M and Q with respect
to P.
Proof: by the deﬁnition of conditional expectation, we have for any
bounded Borel function φ(·)
EP[EP[U|V]φ(V)]
(5.2)
=EP[Uφ(V)]
=αEM[Uφ(V)] + (1 −α)EQ[Uφ(V)]
=αEM[EM[U|V]φ(V)] + (1 −α)EQ[EQ[U|V]φ(V)]
=αEP[dM
dP EM[U|V]φ(V)] + (1 −α)EP[dQ
dP EQ[U|V]φ(V)]
(5.3)
=EP[

αEP[dM
dP |V]EM[U|V] + (1 −α)EP[dQ
dP |V]EQ[U|V]

φ(V)].
The equation (5.3) holds because M and Q are absolutely continuous with
respect to P by construction. As a result, if we deﬁne D(V) to be the ﬁrst
coordinate of the random vector
αEP[dM
dP |V]EM[U|V] + (1 −α)EP[dQ
dP |V]EQ[U|V] −EP[U|V],
(5.4)
then for all n ∈N
EP[D(V)1D(V)<−n−1] = EP[D(V)1D(V)>n−1] = 0
because both 1D(·)>n−1 and 1D(·)<−n−1 are bounded. So we deduce
n−1P(|D(V)| > n−1) ≤EP[|D(V)|1|D(V)|>n−1] = 0

5.2. Small-scale texture pattern denoising
59
because
EP[|D(V)|1|D(V)|>n−1] = EP[D(V)1D(V)>n−1] −EP[D(V)1D(V)<−n−1],
which implies
P(|D(V)| > 0) = lim
n→∞P(|D(V)| > n−1) = 0 ⇔P(D(V) = 0) = 1.
The same reasoning applies to the other coordinates of the random vector
(5.4). Hence the probability for this random vector to vanish is equal to 1.
□
Since the classic likelihood ratios Devroye et al. (1996) found in the
conditional expectation decomposition are positive and satisfy
αEP[dM
dP |V] + (1 −α)EP[dQ
dP |V] = EP[dP
dP|V] = 1,
we will denote them as
γ(V) := αEP[dM
dP |V], 1 −γ(V) := (1 −α)EP[dQ
dP |V]
for notational convenience. In our context, the theorem implies
EP[X| ˜X] = γ( ˜X)EM[X| ˜X] + (1 −γ( ˜X))EQ[X| ˜X]
EP[X| ˜Y] = γ( ˜Y)EM[X| ˜X] + (1 −γ( ˜Y))EQ[X| ˜Y].
For an observation whose likelihood ratios strongly favor the short range
hypothesis for both ˜X and ˜Y, that is,
γ( ˜X) ≈γ( ˜Y) ≈1
EP[X| ˜Y] can thus be approximated by EP[X| ˜X], thereby enabling an input
size reduction.
Note however that short range interaction is only an idealized depic-
tion of texture formation process. The objects composing a random texture
are usually of regular shape when viewed at a close distance relative to
their dimensions. Only when viewed from afar can they be adequately
accounted for by such a modelling assumption Portilla and Simoncelli
(2000). This observation motivates us to investigate the possibility of scal-
ing down the neural networks for denoising small-scale texture patterns.
5.2.2
Small neural networks for small-scale texture denoising
We set up three identical neural networks which act on a 7-by-7 noisy
input to estimate its central 3-by-3 patch. Comprising three hidden layers
with 147 units each, their architecture can be summarized as 49-147-147-
147-9. They were trained following the same procedure as explained in
Burger et al. (2012) under Gaussian noise standard deviation set to 10, 25,
35 respectively in order to match the published ones, whose architectures
are 441-2047-2047-2047-2047-81, 1521-3072-3072-2559-2047-289 and 1521-
3071-3071-2559-2047-289.
Two images were selected for testing purposes. The ﬁrst 746-by-264
image was cropped from a standard Kodak PhotoCD benchmark image

60
Chapter 5. A note on the size of denoising neural networks
Figure 5.1 – The two test images
rendered to grayscale with matlab’s rgb2gray function. It was chosen
because of its rich small-scale texture content. The second 1280-by-1280
image contains artiﬁcially generated structured patterns. Neither image is
in the Pascal VOC dataset from which our training and validation images
were drawn.
Table 5.1 – RMSE comparison between BM3D, small and large neural networks
σ = 10
BM3D
small
large
structure
1.31
2.42
1.65
texture
8.11
7.98
7.86
σ = 25
BM3D
small
large
structure
2.83
4.48
2.48
texture
14.91
14.48
14.16
σ = 35
BM3D
small
large
structure
3.74
5.84
3.06
texture
17.71
17.30
16.86
Table 5.1 indicates that small neural networks do almost as well as
their large counterparts at denoising small-scale texture patterns. But their
smallness does limit what they can do for highly structured patterns. On
the other hand, BM3D underperformed both neural networks where self-
similarity was lacking. BM3D’s 39-by-39 search window, vis-à-vis the large
neural networks’ input patch size (21-by-21 for σ = 10 and 39-by-39 for
the rest) also shows that it is more effective when noise is lower. Moreover,
computationally speaking, to denoise a grayscale image, these small neu-
ral networks require roughly 5 × 104 operations per pixel, which is more
than 500 times cheaper than their large counterparts and makes them on a
par with BM3D because BM3D needs 4 × 104 operations per pixel if all of
its transforms are implemented with a time complexity equal to N log2 N
Dabov et al. (2007).
To gain a further understanding of the texture patterns that satisfy
our hypothesis, we downloaded several texture images and downsampled
them to simulate a zoom out effect. Unsurprisingly, patterns with highly
varying intensity levels turned out best ﬁt our modelling assumption, be-
cause they look more like a noise process locally (see Fig.5.2).

5.3. Complementing BM3D with small neural networks
61
(a)
(b)
(c)
(d)
(e)
(f)
(g)
(h)
(i)
(j)
Figure 5.2 – (a)(b)(c)(d)(e) are the texture patterns for which similar results as in Table
5.1 were observed. The same cannot be said for (f)(g)(h)(i)(j).
5.3
Complementing BM3D with small neural networks
In this section, we present an algorithm named SSaNN, for self-
similarity and neural network, which relies on a Gaussian mixture clas-
siﬁcation device to switch between self-similarity based BM3D and neural
networks.
Let ˜X, ˜Y, ˜Z be three nested noisy patches with strictly growing do-
mains. Let X be the noise-free state of ˜X. The previous section shows
EP[X| ˜Y] ≈EM[X| ˜Z] ≈EP[X| ˜Z]
if ˜Z is generated under M. We can then combine the strength of BM3D and
small neural networks in a principled framework. The key is to observe
that the two algorithms underperform in different but complementary sce-
narios. In this circumstance, the conditional expectation decomposition is
ideally suited to guiding us because the formula
EP[X| ˜Z] = γ( ˜Z)EM[X| ˜Z] + (1 −γ( ˜Z))EQ[X| ˜Z]
suggests replacing the two built-in ﬁlters EM[X| ˜Z] and EQ[X| ˜Z] of large
neural networks by their less costly alternatives EP[X| ˜Y] and BM3D re-
spectively. Furthermore, the same formula shows that conditional expec-
tation mechanically involves a pair of related likelihood ratios, which can
also be estimated with the help of an external device for probabilistic patch
space modelling.
To this end, we may use the 20-component Gaussian mixture proposed
in Chapter 1. The restoration of regularly structured patterns, embodied
here by the ﬂat and oriented classes, can beneﬁt from more extensive ob-
servation. It is the basic premise of self-similarity based algorithms, which
is also supported by our previous analysis and comparison between BM3D
and the neural networks. Therefore, within the mixture, the law M is best
interpreted as the conditional probability attached to the texture class.
Given a noisy image and its noisy level, our algorithm ﬁrst produces
two denoised versions by the small neural network trained under the same
noise condition and BM3D. Then it extends the noisy image in order to

62
Chapter 5. A note on the size of denoising neural networks
form a one-to-one mapping between the 7-by-7 patches in the extended
image and the pixels in the original noisy image by associating a patch
with its central pixel. Next the EM algorithm is run three times with the
initialized Gaussian mixture on the extended noisy image to obtain for
each 7-by-7 patch its posterior probability of belonging to the texture class,
which is then attached to its associated pixel. Finally, the algorithm com-
bines the two denoised image versions using the posterior probabilities as
their respective weight. For a faster execution, one could apply the Bayes
rule Devroye et al. (1996) (Chapter 1) to ﬁrst classify the pixels into either
texture or non-texture, and then choose to denoise them with the neural
network or BM3D. Since this latter version incurs relatively little RMSE
loss (less than 0.5 across different images and noise levels), we only report
its results in Table 5.2. Also note that instead of 18 oriented models orig-
inally designed for the mixture 1, we put in 6 which costs an additional
2.8 × 104 operations per pixel as a result of the three EM iterations. The
parameters t f lat=104 and torient=1.2 were ﬁxed by testing the algorithm on
images separate from the ones reported in the Table.
(SSaNN) Combining BM3D and small neural networks
1: Input: noisy image ˜I, a Gaussian mixture initialized on 7-by-7 patches
2: Output: denoised image
3: Parameter: Gaussian noise standard deviation σ
4: Denoise ˜I with BM3D and the neural network to get IB and IN.
5: Extend ˜I to ¯I so that ¯I’s 7-by-7 patches form one-to-one mapping with ˜I’s pixels.
6: Run the expectation-maximization algorithm on ¯I’s patches to obtain the posterior
probability of each patch of belonging to the texture class. Assign them to their central
pixels so as to form TS.
7: Soft combination results from IB ◦(1 −TS) + IN ◦TS where ◦denotes the element-
wise product.
8: Form another matrix TH of the same size as TS such that its entry at (x, y) is
TH(x, y) = 1TS(x,y)>0.5.
9: Hard combination results from IB ◦(1 −TH) + IN ◦TH.
Table 5.2 demonstrates that our algorithm effectively combines the re-
spective strength of BM3D and small neural networks, thereby improving
BM3D on images with small-scale texture content. However, since the per-
formance of both the substituted ﬁlters and the classiﬁcation device is
negatively affected by noise (see Fig.5.3 and Chapter 1), the relative per-
formance gap between SSaNN and the large neural networks increases
with noise too.

5.3. Complementing BM3D with small neural networks
63
Table 5.2 – RMSE comparison between BM3D, small and large neural networks and our
algorithm
σ = 10
small
BM3D
SSaNN
large
computer
4.97
4.66
4.63
4.77
dice
2.58
1.79
1.79
1.89
ﬂower
3.19
2.83
2.81
2.77
girl
2.93
2.32
2.32
2.41
trafﬁc
5.67
5.64
5.54
5.52
valldemossa
6.55
6.61
6.51
6.48
σ = 25
small
BM3D
SSaNN
large
computer
8.88
8.15
8.13
8.20
dice
4.81
3.04
3.04
2.85
ﬂower
5.61
5.15
5.12
4.85
girl
5.08
3.64
3.64
3.46
trafﬁc
10.16
9.94
9.79
9.55
valldemossa
12.22
12.28
12.06
11.85
σ = 35
small
BM3D
SSaNN
large
computer
10.86
9.88
9.87
9.88
dice
6.24
3.80
3.80
3.39
ﬂower
6.99
6.40
6.38
6.00
girl
6.39
4.41
4.41
4.01
trafﬁc
12.26
11.85
11.75
11.36
valldemossa
14.81
14.74
14.53
14.24
(a)
(b)
(c)
(d)
Figure 5.3 – Highlighted in white are the pixels in (a) classiﬁed as texture at noise
standard deviation (b) σ = 10 (c) σ = 25 and (d) σ = 35.


Part III. Reproducible
research
The third part of this thesis consists of reproducible research. In ad-
dition to the algorithm introduced in Chapter 2, the Viola-Jones face de-
tection algorithm is studied in detail and implemented, which includes a
derivation of the core Adaboost feature selection algorithm.
65


6
E-PLE : an algorithm for
image inpainting
I
n this chapter, we present a probabilistic view of an existing image inpaint-
ing algorithm and propose several theoretical and numerical improve-
ments based on an effective use of Gaussian mixture.
6.1
Introduction
Inpainting is an interpolation technique developed for repairing a par-
tially masked image with information present in the visible parts of the
same image.
Historically, one of the ﬁrst works in the ﬁeld Masnou and Morel (1998)
proposed to connect level lines by minimizing a curvature functional due
to their link made clear by the co-area formula. Later a total variation ap-
proach Shen and Chan (2002) was introduced along a similar line whose
success comes from its insightful choice of functional space which avoids
the blur that could be created by a more regular space such as H1 under
an otherwise identical optimization schema. The subject has since gained
some popularity and inspires Bertalmio et al. (2000) where a high order
PDE is used to propagate structural information to ﬁll in relatively small
gaps. To infer missing textural content, a similarity driven algorithm Efros
and Leung (1999) is devised. The same idea has spawned an effective im-
age processing paradigm Buades et al. (2005), Dabov et al. (2007), Lebrun
et al. (2013b). Building on these developments on structure and texture in-
painting, some efforts Elad et al. (2005), Bertalmio et al. (2003) have been
made to unite these two by performing one preliminary step to separate
two types of content before carrying out their respective dedicated proce-
dure.
Another direction of research initiated in Aharon et al. (2005), Elad
and Aharon (2006) targets an overcomplete dictionary for sparse represen-
tation of image patches. The orientation based K-LLD for image denois-
ing Chatterjee and Milanfar (2009) is another example. In Yu et al. (2012) a
similar algorithm, called PLE, was proposed but intended to solve generic
image related inverse problems. In a recent development Zoran and Weiss
(2011), a Gaussian mixture patch prior modelling is put forth with a new
optimisation schema, which produces impressive results.
67

68
Chapter 6. E-PLE : an algorithm for image inpainting
In this chapter, motivated in part by the works of Chatterjee and Milan-
far (2009), Yu et al. (2012), Zoran and Weiss (2011), we present E-PLE, or
Enhanced PLE. Using a specialized Gaussian mixture initialized with real-
world images, we adapt expectation maximization (EM) algorithm Demp-
ster et al. (1977) to this particular setting and show its improved perfor-
mance at inpainting.
Section 2 summarizes PLE. An account of E-PLE is provided in section
3. Section 4 presents the new algorithm outline, followed by several com-
parative empirical studies in section 5. The appendix is devoted to the EM
algorithm.
6.2
PLE
In this section, we describe PLE Yu et al. (2012) to highlight its dif-
ference with E-PLE. PLE begins with a number of full-rank Gaussian di-
rectional models built with synthetic samples. Then one additional model
is added using DCT as its basis to account for textural patches. All these
models share the same mean vector and covariance eigenvalues, which are
arbitrarily ﬁxed (see algorithm 8).
Algorithm 8 PLE initialization
Parameter: number of Gaussian models K, patch dimension κ × κ.
for k = 0 to K −2 do
Create and sample synthetic images
1.
Create a binary image B of size 100 × 100 valued in {0, 255} with two
sets {(r, u) : B(r, u) = 0} and {(r, u) : B(r, u) = 255} separated by a
straight line inclined at
k
K−1π passing through the center of the image.
2.
Blur B with Gaussian kernels of different standard deviations
(σb)1≤b≤4: σb = 2b for all b.
3.
Draw a large number of κ × κ patches from these blurred images to
form the patch set Pk.
Compute the statistics
1.
Estimate the model mean and covariance:
µk =
1
|Pk| ∑
P∈Pk
P,
Σk =
1
|Pk| ∑
P∈Pk
(P −µk)(P −µk)T.
2.
Set µk = 0.
3.
Deﬁne the k-th directional basis Vk using the spectral decomposition
Σk = VkΛkVT
k . Replace the ﬁrst leading eigenvector in Vk by a normal-
ized constant component and apply Gram-Schmitt to orthogonalize
the remaining vectors. 1
end for
Set up a textural model using DCT as its basis. Set its model mean to zero.
Take a sequence of κ2 positive numbers of exponential decay (a working exam-
ple: m ∈[0, κ2 −1] ∩Z 7→220.5−0.5m) and make them the eigenvalues of all K
Gaussian models just built.
1. The implemented PLE leaves out both component substitution and basis orthogo-
nalization because they can cause numerical instability as it is difﬁcult to tell whether a set

6.2. PLE
69
Assume that there are K models in all. For each patch to restore, PLE
produces K estimates under individual model assumption and keeps the
one with the highest conditional probability to have both the observation
and its estimate. This patch is assigned to the same model.
Finally, all the models are updated with their assigned estimates. The
last two steps, called estimation and maximization by the paper, are then
repeated several times before the algorithm terminates (see algorithm 9).
Algorithm 9 PLE
Input: a masked gray image ˜U, its mask M.
Parameter: number of PLE iterations S.
Run algorithm 8. Extract all κ × κ patches from ˜U and their associated masks
from M, the collection of which is denoted by ˜P and M. With | ˜P| = |M|, the
i-th observed patch and its mask are ˜Pi and Mi.
for t = 1 to S do
Estimation:
1.
Filter the patch under K model assumptions:
∀(i, k),
bP(k)
i
= argmax
P
p(P| ˜Pi, µk,t−1, Σk,t−1)
= argmax
P
p(P, ˜Pi|µk,t−1, Σk,t−1)
= argmin
P
∥MiP −˜Pi∥2
σ2
+ (P −µk)TΣ−1
k,t−1(P −µk)

.
2.
Select a model for each patch:
ki = argmax
0≤k≤K−1
p( bP(k)
i
, ˜Pi|µk,t−1, Σk,t−1)
(6.1)
= argmin
0≤k≤K−1
∥Mi bP(k)
i
−˜Pi∥2
σ2
+ ( bP(k)
i
−µk)TΣ−1
k,t−1( bP(k)
i
−µk) + ln det Σk,t−1

which leads to its estimate bPi = bP(ki)
i
and assignment to the ki-th
model. 2
Maximization: Denote Qk the set of estimated patches attributed to the k-th
model.
for k = 0 to K −1 do
Estimate the model mean and covariance:
µk,t =
1
|Qk| ∑
P∈Qk
P,
Σk,t =
1
|Qk| ∑
P∈Qk
(P −µk,t)(P −µk,t)T + ǫI
where ǫ is a small positive number to ensure the deﬁniteness of Σk,t.
end for
end for
Assign equal weights to all restored patches and recover the image.
of vectors are collinear with the computer’s limited precision. With constant components
removed from the directional bases, PLE could discriminate better.
2. It would be more natural to incorporate at this stage what we know from the obser-
vations. Experiments conﬁrmed that the algorithm yielded better results if the estimated
pixels were replaced with the visible ones wherever possible. Hence, we implemented PLE
with this additional step.

70
Chapter 6. E-PLE : an algorithm for image inpainting
However, the Gaussian model used by PLE lacks the mixing weights
w· for it to be a mixture
p(P) =
N
∑
k=1
wkN (P | µk, Σk),
(6.2)
of which the synthetic image sampling cannot produce an estimate. Thus
algorithm 9 is not an EM, a class of algorithms known to increase the
likelihood of a mixture over iterations Dempster et al. (1977). The absence
of the mixing weights to knit the models also implies that the patch as-
signment step (6.1) is not statistically founded. Moreover, the use of full
rank covariance matrix to model directional patterns is questionable as the
synthetic samples clearly lie in a lower dimensional space (see 1.1)
6.3
E-PLE
6.3.1
Masked patch classiﬁcation and adaptive ﬁltering
To set up the Gaussian mixture for E-PLE, we follow 1.1 and feed it
with real-world data (see algorithm 1) so as to shorten the algorithm’s
learning phase, which is carried out by a version of EM developed for our
partially observed data (see appendix). A patch is then classiﬁed using the
Bayes rule (1.6).
(a)
(b)
(c)
(d)
(e)
(f)
Figure 6.1 – Masked patch classiﬁcation with EM. (a) original image (d) masked image
(b) initial mixing weights (e) mixing weights after three EM iterations (c) patch map
formed after one EM iteration (f) patch map formed after three EM iterations. The ﬂat
patches are painted white.
If a patch ˜P is classiﬁed to the k-th model
˜P = Fkc + µk + σN
where Fk, c, µk, σ and N denote its factor loading matrix, random coef-
ﬁcient, model mean, noise standard deviation and a standard Gaussian
random vector independent of c, Tikhonov regularization can be applied

6.3. E-PLE
71
to construct an estimator. Assume without loss of generality that Fk’s
columns (F(m)
k
)1≤m≤lk are the orthogonal leading eigenvectors of the co-
variance matrix FkFT
k . Then the following Wiener ﬁltering schema with an
adjustable parameter ξ controlling the degree of data ﬁt
bP =
argmin
∃β,P=Fkβ+µk
lk
∑
m=1
∥F(m)
k
∥−2
P −µk, ∥F(m)
k
∥−1F(m)
k
2 + ξ∥MP −˜P∥2
=
argmin
∃β,P=Fkβ+µk
lk
∑
m=1

P −µk, ∥F(m)
k
∥−2F(m)
k
2 + ξ∥M(P −µk −˜P + µk)∥2
deﬁnes a ξ-indexed mapping ˜P ∈Rκ2 7→bP ∈Rκ2. A much neater formu-
lation of the same problem can be obtained with some additional auxiliary
variables
β = [β1, · · · , βlk]T,
βm =

P −µk, ∥F(m)
k
∥−2F(m)
k

˜β = [ ˜β1, · · · , ˜βlk]T,
˜βm =

 ˜P −µk, ∥F(m)
k
∥−2F(m)
k

.
Now it follows:
bP = Fkβ∗+ µk,
β∗= argmin
β
∥β∥2 + ξ∥MFk(β −˜β) −MR ˜P∥2
with the residual:
R ˜P = ˜P −µk −Fk ˜β.
The solution to this quadratic minimization problem is straightforward
β∗= ξ(Ilk + ξFT
k MFk)−1FT
k M( ˜P −µk).
Hence the linear estimator
bP = ξFk(Ilk + ξFT
k MFk)−1FT
k M( ˜P −µk) + µk.
(6.3)
Thanks to the identity Ilk, the matrix inversion is well deﬁned. In addition,
because of the linear ﬁlter’s symmetric form, the factor orthogonalization
in Fk, otherwise required to meet the assumption of the analysis, can be
effectively avoided.
6.3.2
Algorithm outline
A recap of E-PLE. First, a Gaussian factor mixture is set up using natu-
ral images. Next, EM is called upon to infer its parameters from the image
to inpaint. Finally, adaptive linear ﬁlters ((6.3)) are used to restore patches
and hence the image.
For a color image, three color channels can be restored separately be-
fore forming the ﬁnal result. One way to speed up the algorithm in this
case however is to make EM only run on one channel and use the result-
ing patch map to guide the other two. It is the adopted approach in the
current implementation Wang (2013a).

72
Chapter 6. E-PLE : an algorithm for image inpainting
Algorithm 10 E-PLE
Input: a masked gray image ˜U, its mask M.
Parameter: number of EM iterations S.
Run algorithm 1. Extract all 8 × 8 patches from ˜U and their masks from M,
the collection of which are denoted by ˜P and M. With | ˜P| = |M| = N,
observation i and its mask are denoted by ˜Pi and Mi.
for t = 1 to S do
Expectation:
1.
Compute the mean and covariance of the coefﬁcient posteriors: ∀1 ≤
i ≤N, 0 ≤si ≤K −1,
Σci|si =
 FT
si,t−1MiFsi,t−1
σ2
t−1
+ I
−1
, µci|si = Σci|si
FT
si,t−1( ˜Pi −Miµsi,t−1)
σ2
t−1
.
The parameter set Θt−1 comprises (wk,t−1, Fk,t−1, µk,t−1)0≤k≤K−1 and
σt−1 for 1 ≤t ≤S. The couple (Σci|si, µci|si)1≤i≤N evolves over time,
but for notational convenience, their time index is omitted.
2.
Compute model posterior probabilities for all patches: ∀1 ≤i ≤
N, 0 ≤si ≤K −1,
Pt(si| ˜Pi) ∝wsi exp
1
2 ln det Σci|si +
µT
ci|siΣ−1
ci|siµci|si
2
−
∥Miµsi −˜Pi∥2
2σ2

.
under the constraint ∑K−1
k=0 Pt(si = k| ˜Pi) = 1.
Maximization:
1.
Update model priors: ∀0 ≤k ≤K −1, wk,t = 1
N ∑N
i=1 Pt(si = k| ˜Pi).
2.
Update noise variance:
σ2
t = ∑N
i=1 ∑K−1
k=0 Pt(si = k| ˜Pi) R
dcipi(ci|si = k)∥˜Pi −Mi ˜Fsi,t−1 ˜ci∥2
∑N
i=1 |Mi|
where |Mi| means the number of non-zero entries in Mi. See (6.4) for
the integral.
3.
Update model factors and means: solve the linear equation one row at
a time
N
∑
i=1
Mi ˜Fsi,tPt(si| ˜Pi)
 
Σci|si + µci|siµT
ci|si
µci|si
µT
ci|si
1
!
=
N
∑
i=1
MiPt(si| ˜Pi) ˜Pi

µT
ci|si
1

where ˜Fsi,t := [Fsi,t, µsi,t].
end for
Create the patch map:
f : ˜Pi ∈˜P 7→argmax
0≤k≤K−1
PΘS(si = k| ˜Pi).
Filter: ∀˜Pi ∈˜P, take the model ki = f ( ˜Pi) and ﬁll in ˜Pi’s missing pixel values
with the estimates from
bPi = Fki,Sβi + µki,S with βi = ξ(Ilk + ξFT
ki,SMiFki,S)−1FT
ki,SMi( ˜Pi −µki,S).
Assemble: assign equal weights to all restored patches and recover the image
in the usual way.

6.3. E-PLE
73
(a)
(b)
(c)
(d)
Figure 6.2 – test images: (a) parrot (b) shapes (c) barbara (d) frog
6.3.3
Numerical results
Figure 6.2 shows the images used in our experiments. Table 6.1 com-
pares the results of different inpainting algorithms in RMSE.
Table 6.1 – Algorithm Comparison in RMSE
text
barbara
frog
parrot
shapes
EPLL
5.7
4.8
6.4
6.5
PLE
4.2
4.3
6.1
5.9
E-PLE
5.0
4.7
6.6
5.7
rand 0.2
barbara
frog
parrot
shapes
EPLL
2.5
2.5
4.0
2.8
PLE
1.7
2.0
3.7
2.4
E-PLE
1.9
2.2
3.8
2.3
rand 0.4
barbara
frog
parrot
shapes
EPLL
4.7
4.5
6.7
5.6
PLE
3.7
4.0
6.9
5.4
E-PLE
3.7
4.1
6.7
4.7
rand 0.6
barbara
frog
parrot
shapes
EPLL
8.6
7.2
9.5
9.6
PLE
10.6
7.1
10.9
11.2
E-PLE
7.9
6.8
10.0
8.8
rand 0.8
barbara
frog
parrot
shapes
EPLL
15.8
11.2
15.0
17.6
PLE
20.1
11.0
16.0
19.4
E-PLE
16.9
10.8
14.8
16.5
Comments:
1. For fairness, all the algorithms used the same masked images. A
random mask has a certain ﬁxed probability for each pixel to become
invisible. Both PLE and E-PLE iterate six times. And EPLL refers to
the algorithm developed in Zoran and Weiss (2011).
2. The higher the masking ratio, the worse the recovery in all cases.
A higher masking ratio also implies that an algorithm has to guess
more so that a well constructed prior knowledge is the most needed.
Lacking such a structure, PLE does not do as well as the other two.
3. For natural images, one single iteration of E-PLE usually sufﬁces to
achieve a good restoration (see ﬁgure 6.3). More iterations do guar-
antee an increase in likelihood Dempster et al. (1977), though not

74
Chapter 6. E-PLE : an algorithm for image inpainting
necessarily in RMSE. Yet for a highly degraded image, more itera-
tions could allow better inpainting especially for those images rich
in structure such as barbara. The same cannot be said of PLE.
4. On the contrary, in case of artiﬁcial images, it is desirable to have the
algorithm update mixture components through learning in order to
adapt itself to this unexpected reality. This explains why EPLL yields
a consistently worse result with shapes (see ﬁgure 6.4).
(a)
(b)
(c)
(d)
(e)
(f)
Figure 6.3 – E-PLE iterates once on the masked images. (a) text masked image (d) in-
painted (RMSE = 7.9) (b) randomly masked image (ratio = 0.2) (e) inpainted (RMSE =
5.0) (c) randomly masked image (ratio = 0.8) (f) inpainted (RMSE = 14.9).

6.4. Appendix
75
(a)
(b)
(c)
(d)
Figure 6.4 – Inpainting an artiﬁcial image (a) masked shapes (40% pixels visible) (b)
inpainted with EPLL (RMSE = 9.6) (c) inpainted with PLE (six iterations and RMSE =
11.2) (d) inpainted with E-PLE (six iterations and RMSE = 8.8).
6.4
Appendix
In this section, EM used in E-PLE is derived.
E-PLE’s observation model is
˜P = M
  K−1
∑
k=0
1s=kP + N
 =
K−1
∑
k=0
M(P + N)1s=k
whereby the patch is affected by Gaussian noise N and a mask M. The
patch model s is governed by the mixing weights w· and independent of
N. Let Θ be the parameter set comprising
 Fk, µk, wk

0≤k≤K−1, and the
noise standard deviation σ.
Lemme 6.1
Given the linear model
∀1 ≤i ≤N,
˜Pi =
K−1
∑
k=0
Mi(Fkci + µk + σni)1si=k
the posterior law of the coefﬁcient ci conditional on ( ˜Pi, si) is Gaussian and its
density pi(ci|si) is characterized by the covariance matrix and mean
Σci|si =
 FT
siMiFsi
σ2
+ I
−1
and µci|si = Σci|si
FT
si( ˜Pi −Miµsi)
σ2
.
Moreover, the density of ˜Pi given si is
pΘ( ˜Pi|si) = CMi,σ2 exp
1
2 ln det Σci|si +
µT
ci|siΣ−1
ci|siµci|si
2
−
∥Miµsi −˜Pi∥2
2σ2

for some positive constant CMi,σ2 only depending on Mi and σ2.

76
Chapter 6. E-PLE : an algorithm for image inpainting
Proof: an elementary application of Bayes formula implies
pΘ( ˜Pi|si) =
Z
dcipΘ(ci|si)pΘ( ˜Pi|ci, si)
= CMi,σ2
(2π)lsi /2
Z
dci exp

−∥ci∥2
2
−
∥Mi(Fsici + µsi) −˜Pi∥2
2σ2

= CMi,σ2
(2π)lsi /2
Z
dci exp

−
(ci −µci|si)TΣ−1
ci|si(ci −µci|si)
2
+
µT
ci|siΣ−1
ci|siµci|si
2
−
∥Miµsi −˜Pi∥2
2σ2

=CMi,σ2 exp
1
2 ln det Σci|si +
µT
ci|siΣ−1
ci|siµci|si
2
−
∥Miµsi −˜Pi∥2
2σ2

Hence the lemma’s claims. □
As a by-product, we ﬁnd the posterior probability
PΘ(si| ˜Pi) ∝pΘ( ˜Pi|si)PΘ(si)
∝wsi exp
1
2 ln det Σci|si +
µT
ci|siΣ−1
ci|siµci|si
2
−
∥Miµsi −˜Pi∥2
2σ2

.
Hence ˜Pi is best associated to
ki = argmax
0≤si≤K−1

ln wsi + 1
2 ln det Σci|si +
µT
ci|siΣ−1
ci|siµci|si
2
−
∥Miµsi −˜Pi∥2
2σ2

.
With the parameter set Θt known at time t, EM ﬁrst calculates the con-
ditional expectation of the log-likelihood completed with latent variables
(si, ci)1≤i≤N (by abuse of notation, the probabilities P and densities p are
mixed up as the context is clear)
N
∑
i=1
EΘt

ln PΘ( ˜Pi, si, ci)| ˜Pi

=
N
∑
i=1
K−1
∑
k=0
EΘt

ln PΘ( ˜Pi, si, ci)| ˜Pi, si = k

PΘt(si = k| ˜Pi)
=
N
∑
i=1
K−1
∑
k=0

EΘt

ln PΘ( ˜Pi, ci|si = k)| ˜Pi, si = k
 + ln wk

PΘt(si = k| ˜Pi)
=
N
∑
i=1
K−1
∑
k=0

EΘt
 −∥ci∥2
2
−∥˜Pi −Mi(Fkci + µk)∥2
2σ2
−|Mi|
2
ln σ2 + Ck,Mi| ˜Pi, si = k
 + ln wk

PΘt(si = k| ˜Pi)
where |Mi| is the number of non-zero elements in Mi and Ck,Mi is a con-
stant that depends only on the couple (k, Mi). The only variables that re-
main random in the conditional expectation are (ci)1≤i≤N and this allows
us to put the previous lemma to good use. Since only the second order
moments are involved, the computation is straightforward:
EΘt
∥ci∥2| ˜Pi, si
 = tr(Σci|si + µci|siµT
ci|si) := tr(Ci)
(6.4)
EΘt
∥˜Pi −Mi(Fkci + µk)∥2| ˜Pi, si
 = ∥˜Pi −Miµk∥2 −2

 ˜Pi −µk, MiFkµci|si
 + tr(CiFT
k MiFk).
Next, EM maximizes the expectation just obtained w.r.t. the model param-
eters. For a more compact expression, let us combine the factor loading
matrix Fsi with the mean µsi to form ˜Fsi (thus the coefﬁcient ci is extended

6.4. Appendix
77
by one additional constant equal to 1). Now derive the expectation w.r.t.
˜Fk and set it to zero
∂
∂˜Fk
N
∑
i=1
PΘt(si = k| ˜Pi)
Z
d˜cipi(˜ci|si = k)∥˜Pi −Mi ˜Fk ˜ci∥2 = 0
which leads to
N
∑
i=1
Mi ˜FkPΘt(si = k| ˜Pi)
Z
d˜cipi(˜ci|si = k)˜ci ˜cT
i =
N
∑
i=1
Mi ˜PiPΘt(si = k| ˜Pi)
Z
d˜cipi(˜ci|si = k)˜cT
i .
Updating ( ˜Fk)0≤k≤K−1 amounts to solving a linear equation: denoting by
(M)q the q-th row of a matrix M, we have ∀1 ≤q ≤κ2
( ˜Fk)q
n
∑
i=1
δMi(q,q),qPΘt(si| ˜Pi)
Z
d˜cipi(˜ci|si)˜ci ˜cT
i =
 N
∑
i=1
Mi ˜PiPΘt(si| ˜Pi)
Z
d˜cipi(˜ci|si)˜cT
i

q
where δ·,· is the Kronecker delta and
Z
d˜cipi(˜ci|si)˜ci ˜cT
i =
 
Ci
µci|si
µT
ci|si
1
!
,
Z
d˜cipi(˜ci|si)˜cT
i =

µT
ci|si
1

.
Hence, if none of the observed patches has a visible pixel at row q, we will
not be able to estimate the factors’ or means’ coordinate at that position.
However, it rarely happens if we have a large enough dataset and that the
mask behaves sufﬁciently randomly.
Similarly, the new model prior can be found via the next problem
argmax
w1,···wK−1
K−1
∑
k=0
ln wk
N
∑
i=1
PΘt(si = k| ˜Pi) s.t.
min
0≤k≤K−1 wk ≥0 and
K−1
∑
k=0
wk = 1
whose solution is
∀0 ≤k ≤K −1, wk = 1
N
N
∑
i=1
PΘt(si = k| ˜Pi).
Finally, the noise level can be estimated by
∂
∂σ2
N
∑
i=1
K−1
∑
k=0
PΘt(si = k| ˜Pi)
Z
dcipi(ci|si = k)

−|Mi|
2
ln σ2 −∥˜Pi −Mi ˜Fsi ˜ci∥2
2σ2

= 0
whose solution is quite intuitive:
σ2 = ∑N
i=1 ∑K−1
k=0 PΘt(si = k| ˜Pi) R
dcipi(ci|si = k)∥˜Pi −Mi ˜Fsi ˜ci∥2
∑N
i=1 |Mi|
.
where the integral is the same as (6.4).


7
An analysis of the
Viola-Jones face detection
algorithm
I
n this chapter, we decipher the Viola-Jones algorithm, the ﬁrst ever real-
time face detection system. There are three ingredients working in concert
to enable a fast and accurate detection: the integral image for feature com-
putation, Adaboost for feature selection and an attentional cascade for
efﬁcient computational resource allocation. Here we propose a complete
algorithmic description, a learning code and a learned face detector that
can be applied to any color image. Since the Viola-Jones algorithm typi-
cally gives multiple detections, a post-processing step is also proposed to
reduce detection redundancy using a robustness argument.
7.1
Introduction
A face detector has to tell whether an image of arbitrary size contains
a human face and if so, where it is. One natural framework for consid-
ering this problem is that of binary classiﬁcation, in which a classiﬁer is
constructed to minimize the misclassiﬁcation risk. Since no objective dis-
tribution can describe the actual prior probability for a given image to
have a face, the algorithm must minimize both the false negative and false
positive rates in order to achieve an acceptable performance.
This task requires an accurate numerical description of what sets hu-
man faces apart from other objects. It turns out that these characteristics
can be extracted with a remarkable committee learning algorithm called
Adaboost, which relies on a committee of weak classiﬁers to form a strong
one through a voting mechanism. A classiﬁer is weak if, in general, it can-
not meet a predeﬁned classiﬁcation target in error terms.
An operational algorithm must also work with a reasonable computa-
tional budget. Techniques such as integral image and attentional cascade
make the Viola-Jones algorithm Viola and Jones (2004) highly efﬁcient: fed
with a real time image sequence generated from a standard webcam, it
performs well on a standard PC.
79

80
Chapter 7. An analysis of the Viola-Jones face detection algorithm
7.2
Algorithm
To study the algorithm in detail, we start with the image features for
the classiﬁcation task.
7.2.1
Features and integral image
The Viola-Jones algorithm uses Haar-like features, that is, a scalar
product between the image and some Haar-like templates. More precisely,
let I and P denote an image and a pattern, both of the same size N × N
(see Figure 7.1). The feature associated with pattern P of image I is deﬁned
by
∑
1≤i≤N ∑
1≤j≤N
I(i, j)1P(i,j) is white −∑
1≤i≤N ∑
1≤j≤N
I(i, j)1P(i,j) is black.
To compensate the effect of different lighting conditions, all the images
should be mean and variance normalized beforehand. Those images with
variance lower than one, having little information of interest in the ﬁrst
place, are left out of consideration.
(a)
(b)
(c)
Figure 7.1 – Haar-like features. Here as well as below, the background of a template like
(b) is painted gray to highlight the pattern’s support. Only those pixels marked in black
or white are used when the corresponding feature is calculated.
(a)
(b)
(c)
(d)
(e)
Figure 7.2 – Five Haar-like patterns. The size and position of a pattern’s support can
vary provided its black and white rectangles have the same dimension, border each other
and keep their relative positions. Thanks to this constraint, the number of features one can
draw from an image is somewhat manageable: a 24 × 24 image, for instance, has 43200,
27600, 43200, 27600 and 20736 features of category (a), (b), (c), (d) and (e) respectively,
hence 162336 features in all.
In practice, ﬁve patterns are considered (see Figure 7.2 and Algo-
rithm 11). The derived features are assumed to hold all the information
needed to characterize a face. Since faces are by and large regular by na-
ture, the use of Haar-like patterns seems justiﬁed. There is, however, an-
other crucial element which lets this set of features take precedence: the
integral image which allows to calculate them at a very low computational
cost. Instead of summing up all the pixels inside a rectangular window,

7.2. Algorithm
81
Algorithm 11 Computing a 24 × 24 image’s Haar-like feature vector
1: Input: a 24 × 24 image with zero mean and unit variance
2: Output: a d × 1 scalar vector with its feature index f ranging from 1 to d
3: Set the feature index f ←0
4: Compute feature type (a)
5: for all (i, j) such that 1 ≤i ≤24 and 1 ≤j ≤24 do
6:
for all (w, h) such that i + h −1 ≤24 and j + 2w −1 ≤24 do
7:
compute the sum S1 of the pixels in [i, i + h −1] × [j, j + w −1]
8:
compute the sum S2 of the pixels in [i, i + h −1] × [j + w, j + 2w −1]
9:
record this feature parametrized by (1, i, j, w, h): S1 −S2
10:
f ←f + 1
11:
end for
12: end for
13: Compute feature type (b)
14: for all (i, j) such that 1 ≤i ≤24 and 1 ≤j ≤24 do
15:
for all (w, h) such that i + h −1 ≤24 and j + 3w −1 ≤24 do
16:
compute the sum S1 of the pixels in [i, i + h −1] × [j, j + w −1]
17:
compute the sum S2 of the pixels in [i, i + h −1] × [j + w, j + 2w −1]
18:
compute the sum S3 of the pixels in [i, i + h −1] × [j + 2w, j + 3w −1]
19:
record this feature parametrized by (2, i, j, w, h): S1 −S2 + S3
20:
f ←f + 1
21:
end for
22: end for
23: Compute feature type (c)
24: for all (i, j) such that 1 ≤i ≤24 and 1 ≤j ≤24 do
25:
for all (w, h) such that i + 2h −1 ≤24 and j + w −1 ≤24 do
26:
compute the sum S1 of the pixels in [i, i + h −1] × [j, j + w −1]
27:
compute the sum S2 of the pixels in [i + h, i + 2h −1] × [j, j + w −1]
28:
record this feature parametrized by (3, i, j, w, h): S1 −S2
29:
f ←f + 1
30:
end for
31: end for
32: Compute feature type (d)
33: for all (i, j) such that 1 ≤i ≤24 and 1 ≤j ≤24 do
34:
for all (w, h) such that i + 3h −1 ≤24 and j + w −1 ≤24 do
35:
compute the sum S1 of the pixels in [i, i + h −1] × [j, j + w −1]
36:
compute the sum S2 of the pixels in [i + h, i + 2h −1] × [j, j + w −1]
37:
compute the sum S3 of the pixels in [i + 2h, i + 3h −1] × [j, j + w −1]
38:
record this feature parametrized by (4, i, j, w, h): S1 −S2 + S3
39:
f ←f + 1
40:
end for
41: end for
42: Compute feature type (e)
43: for all (i, j) such that 1 ≤i ≤24 and 1 ≤j ≤24 do
44:
for all (w, h) such that i + 2h −1 ≤24 and j + 2w −1 ≤24 do
45:
compute the sum S1 of the pixels in [i, i + h −1] × [j, j + w −1]
46:
compute the sum S2 of the pixels in [i + h, i + 2h −1] × [j, j + w −1]
47:
compute the sum S3 of the pixels in [i, i + h −1] × [j + w, j + 2w −1]
48:
compute the sum S4 of the pixels in [i + h, i + 2h −1] × [j + w, j + 2w −1]
49:
record this feature parametrized by (5, i, j, w, h): S1 −S2 −S3 + S4
50:
f ←f + 1
51:
end for
52: end for

82
Chapter 7. An analysis of the Viola-Jones face detection algorithm
this technique mirrors the use of cumulative distribution functions. The
integral image I of I
I(i, j) :=
(
∑1≤s≤i ∑1≤t≤j I(s, t),
1 ≤i ≤N and 1 ≤j ≤N
0,
otherwise
,
is so deﬁned that
∑
N1≤i≤N2
∑
N3≤j≤N4
I(i, j)
=I(N2, N4) −I(N2, N3 −1) −I(N1 −1, N4) + I(N1 −1, N3 −1),
(7.1)
holds for all N1 ≤N2 and N3 ≤N4. As a result, computing an image’s
rectangular local sum requires at most four elementary operations given
its integral image. Moreover, obtaining the integral image itself can be
done in linear time: setting N1 = N2 and N3 = N4 in (7.1), we ﬁnd
I(N1, N3) = I(N1, N3) −I(N1, N3 −1) −I(N1 −1, N3) + I(N1 −1, N3 −1).
Hence a recursive relation which leads to Algorithm 12.
Algorithm 12 Integral Image
1: Input: an image I of size N × M.
2: Output: its integral image I of the same size.
3: Set I(1, 1) = I(1, 1).
4: for i = 1 to N do
5:
for j = 1 to M do
6:
I(i, j) = I(i, j) + I(i, j −1) + I(i −1, j) −I(i −1, j −1) and I is deﬁned
to be zero whenever its argument (i, j) ventures out of I’s domain.
7:
end for
8: end for
As a side note, let us mention that once the useful features have been
selected by the boosting algorithm, one needs to scale them up accordingly
when dealing with a bigger window (see Algorithm 13). Smaller windows,
however, will not be looked at.
7.2.2
Feature selection with adaboost
How to make sense of these features is the focus of Adaboost Freund
and Schapire (1997).
Some terminology. A classiﬁer maps an observation to a label valued
in a ﬁnite set. For face detection, it assumes the form of f : Rd 7→{−1, 1},
where 1 means that there is a face and −1 the contrary (see Figure 7.3)
and d is the number of Haar-like features extracted from an image. Given
the probabilistic weights w· ∈R+ assigned to a training set made up of
n observation-label pairs (xi, yi), Adaboost aims to iteratively drive down
an upper bound of the empirical loss
n
∑
i=1
wi1yi̸= f (xi),

7.2. Algorithm
83
Algorithm 13 Feature Scaling
1: Input: an e × e image with zero mean and unit variance (e ≥24)
2: Parameter: a Haar-like feature type and its parameter (i, j, w, h) as deﬁned in
Algorithm 11
3: Output: the feature value
4: if feature type (a) then
5:
set the original feature support size a ←2wh
6:
i ←Jie/24K, j ←Jje/24K, h ←Jhe/24K where JzK deﬁnes the nearest integer
to z ∈R+
7:
w ←max{κ ∈N : κ ≤J1 + 2we/24K/2, 2κ ≤e −j + 1}
8:
compute the sum S1 of the pixels in [i, i + h −1] × [j, j + w −1]
9:
compute the sum S2 of the pixels in [i, i + h −1] × [j + w, j + 2w −1]
10:
return the scaled feature (S1−S2)a
2wh
11: end if
12: if feature type (b) then
13:
set the original feature support size a ←3wh
14:
i ←Jie/24K, j ←Jje/24K, h ←Jhe/24K
15:
w ←max{κ ∈N : κ ≤J1 + 3we/24K/3, 3κ ≤e −j + 1}
16:
compute the sum S1 of the pixels in [i, i + h −1] × [j, j + w −1]
17:
compute the sum S2 of the pixels in [i, i + h −1] × [j + w, j + 2w −1]
18:
compute the sum S2 of the pixels in [i, i + h −1] × [j + 2w, j + 3w −1]
19:
return the scaled feature (S1−S2+S3)a
3wh
20: end if
21: if feature type (c) then
22:
set the original feature support size a ←2wh
23:
i ←Jie/24K, j ←Jje/24K, w ←Jwe/24K
24:
h ←max{κ ∈N : κ ≤J1 + 2he/24K/2, 2κ ≤e −i + 1}
25:
compute the sum S1 of the pixels in [i, i + h −1] × [j, j + w −1]
26:
compute the sum S2 of the pixels in [i + h, i + 2h −1] × [j, j + w −1]
27:
return the scaled feature (S1−S2)a
2wh
28: end if
29: if feature type (d) then
30:
set the original feature support size a ←3wh
31:
i ←Jie/24K, j ←Jje/24K, w ←Jwe/24K
32:
h ←max{κ ∈N : κ ≤J1 + 3he/24K/3, 3κ ≤e −i + 1}
33:
compute the sum S1 of the pixels in [i, i + h −1] × [j, j + w −1]
34:
compute the sum S2 of the pixels in [i + h, i + 2h −1] × [j, j + w −1]
35:
compute the sum S3 of the pixels in [i + 2h, i + 3h −1] × [j, j + w −1]
36:
return the scaled feature (S1−S2+S3)a
3wh
37: end if
38: if feature type (e) then
39:
set the original feature support size a ←4wh
40:
i ←Jie/24K, j ←Jje/24K
41:
w ←max{κ ∈N : κ ≤J1 + 2we/24K/2, 2κ ≤e −j + 1}
42:
h ←max{κ ∈N : κ ≤J1 + 2he/24K/2, 2κ ≤e −i + 1}
43:
compute the sum S1 of the pixels in [i, i + h −1] × [j, j + w −1]
44:
compute the sum S2 of the pixels in [i + h, i + 2h −1] × [j, j + w −1]
45:
compute the sum S3 of the pixels in [i, i + h −1] × [j + w, j + 2w −1]
46:
compute the sum S4 of the pixels in [i + h, i + 2h −1] × [j + w, j + 2w −1]
47:
return the scaled feature (S1−S2−S3+S4)a
4wh
48: end if

84
Chapter 7. An analysis of the Viola-Jones face detection algorithm
under mild technical conditions (see Appendix 7.4). Remarkably, the de-
cision rule constructed by Adaboost remains reasonably simple so that it
is not prone to overﬁtting, which means that the empirically learned rule
often generalizes well. For more details on the method, we refer to Freund
et al. (1999), Friedman et al. (2001). Despite its groundbreaking success, it
ought to be said that Adaboost does not learn what a face should look like
all by itself because it is humans, rather than the algorithm, who perform
the labeling and the ﬁrst round of feature selection, as described in the
previous section.
(a)
(b)
Figure 7.3 – Some supervised examples: (a) positive examples (b) negative examples. All
of them are 24 × 24 grayscale images. See Section 7.2.4 for more on this dataset.
The building block of the Viola-Jones face detector is a decision stump,
or a depth one decision tree, parametrized by a feature f ∈{1, · · · , d}, a
threshold t ∈R and a toggle T ∈{−1, 1}. Given an observation x ∈Rd, a
decision stump h predicts its label using the following rule
h(x) = (1πfx≥t −1πfx<t)T ∈{−1, 1},
(7.2)
where πfx is the feature vector’s f-th coordinate. Several comments follow:
1. Any additional pattern produced by permuting black and white rect-
angles in an existing pattern (see Figure 7.2) is superﬂuous. Because
such a feature is merely the opposite of an existing feature, only a
sign change for t and T is needed to have the same classiﬁcation
rule.
2. If the training examples are sorted in ascending order of a given
feature f, a linear time exhaustive search on the threshold and toggle
can ﬁnd a decision stump using this feature that attains the lowest
empirical loss
n
∑
i=1
wi1yi̸=h(xi),
(7.3)
on the training set (see Algorithm 14). Imagine a threshold placed
somewhere on the real line, if the toggle is set to 1, the resulting rule
will declare an example x positive if πfx is greater than the threshold
and negative otherwise. This allows us to evaluate the rule’s empiri-
cal error, thereby selecting the toggle that ﬁts the dataset better (lines
8–16 of Algorithm 14).

7.2. Algorithm
85
Since margin
min
i: yi=−1 |πfxi −t| + min
i: yi=1 |πfxi −t|,
and risk, or the expectation of the empirical loss (7.3), are closely re-
lated Friedman et al. (2001), Rosenblatt (1958), Schapire et al. (1998),
of two decision stumps having the same empirical risk, the one with
a larger margin is preferred (line 14 of Algorithm 14). Thus in the
absence of duplicates, there are n + 1 possible thresholds and the
one with the smallest empirical loss should be chosen. However it is
possible to have the same feature values from different examples and
extra care must be taken to handle this case properly (lines 27–32 of
Algorithm 14).
By adjusting individual example weights (Algorithm 16 line 10), Ad-
aboost makes more effort to learn harder examples and adds more de-
cision stumps (see Algorithm 15) in the process. Intuitively, in the ﬁnal
voting, a stump ht with lower empirical loss is rewarded with a bigger
say (a higher αt, see Algorithm 16 line 9) when a T-member committee
(vote-based classiﬁer) assigns an example according to
f T(·) = sign
 T
∑
t=1
αtht(·)

.
How the training examples should be weighed is explained in detail
in Appendix 7.4. Figure 7.4 shows an instance where Adaboost reduces
false positive and false negative rates simultaneously as more and more
stumps are added to the committee. For notational simplicity, we denote
the empirical loss by
n
∑
i=1
wi(1)1yi ∑T
t=1 αtht(xi)≤0 := P( f T(X) ̸= Y),
where (X, Y) is a random couple distributed according to the probability
P deﬁned by the weights wi(1), 1 ≤i ≤n set when the training starts. As
the empirical loss goes to zero with T, so do both false positive P( f T(X) =
1|Y = −1) and false negative rates P( f T(X) = −1|Y = 1) owing to
P( f T(X) ̸= Y) = P(Y = 1)P( f T(X) = −1|Y = 1) + P(Y = −1)P( f T(X) = 1|Y = −1).
Thus the detection rate
P( f T(X) = 1|Y = 1) = 1 −P( f T(X) = −1|Y = 1),
must tend to 1.
Thus the size T of the trained committee depends on the targeted false
positive and false negative rates. In addition, let us mention that, given
n−negative and n+ positive examples in a training pool, it is custom-
ary to give a negative (resp. positive) example an initial weight equal to
0.5/n−(resp. 0.5/n+) so that Adaboost does not favor either category at
the beginning.

86
Chapter 7. An analysis of the Viola-Jones face detection algorithm
Algorithm 14 Decision Stump by Exhaustive Search
1: Input: n training examples arranged in ascending order of feature πfxi:
πfxi1 ≤πfxi2 ≤· · · ≤πfxin, probabilistic example weights (wk)1≤k≤n.
2: Output: the decision stump’s threshold τ, toggle T , error E and margin M.
3: Initialization: τ ←min1≤i≤n πfxi −1, M ←0 and E ←2 (an arbitrary upper
bound of the empirical loss).
4: Sum up the weights of the positive (resp. negative) examples whose f-th
feature is bigger than the present threshold: W+
1
←∑n
i=1 wi1yi=1 (resp.
W+
−1 ←∑n
i=1 wi1yi=−1).
5: Sum up the weights of the positive (resp. negative) examples whose f-th
feature is smaller than the present threshold: W−
1 ←0 (resp. W−
−1 ←0).
6: Set iterator j ←0, bτ ←τ and c
M ←M.
7: while true do
8:
Select the toggle to minimize the weighted error: error+ ←W−
1 + W+
−1 and
error−←W+
1 + W−
−1.
9:
if error+ < error−then
10:
bE ←error+ and bT ←1.
11:
else
12:
bE ←error−and bT ←−1.
13:
end if
14:
if bE < E or bE = E & c
M > M then
15:
E ←bE, τ ←bτ, M ←c
M and T ←bT .
16:
end if
17:
if j = n then
18:
Break.
19:
end if
20:
j ←j + 1.
21:
while true do
22:
if yij = −1 then
23:
W−
−1 ←W−
−1 + wij and W+
−1 ←W+
−1 −wij.
24:
else
25:
W−
1 ←W−
1 + wij and W+
1 ←W+
1 −wij.
26:
end if
27:
To ﬁnd a new valid threshold, we need to handle duplicate features.
28:
if j = n or πfxij ̸= πfxij+1 then
29:
Break.
30:
else
31:
j ←j + 1.
32:
end if
33:
end while
34:
if j = n then
35:
bτ ←max1≤i≤n πfxi + 1 and c
M ←0.
36:
else
37:
bτ ←(πfxij + πfxij+1)/2 and c
M ←πfxij+1 −πfxij.
38:
end if
39: end while

7.2. Algorithm
87
Algorithm 15 Best Stump
1: Input: n training examples, their probabilistic weights (wi)1≤i≤n, number of
features d.
2: Output: the best decision stump’s threshold, toggle, error and margin.
3: Set the best decision stump’s error to 2.
4: for f = 1 to d do
5:
Compute the decision stump associated with feature f using Algorithm 14.
6:
if this decision stump has a lower weighted error (7.3) than the best stump
or a wider margin if the weighted error are the same then
7:
set this decision stump to be the best.
8:
end if
9: end for
Algorithm 16 Adaboost
1: Input: n training examples (xi, yi) ∈Rd × {−1, 1}, 1 ≤i ≤n, number of
training rounds T.
2: Parameter: the initial probabilistic weights wi(1) for 1 ≤i ≤n.
3: Output: a strong learner/committee.
4: for t = 1 to T do
5:
Run Algorithm 15 to train a decision stump ht using the weights w·(t) and
get its weighted error ǫt
ǫt =
n
∑
i=1
wi(t)1ht(xi)̸=yi,
6:
if ǫt = 0 and t = 1 then
7:
training ends and return h1(·).
8:
else
9:
set αt = 1
2 ln( 1−ǫt
ǫt ).
10:
update the weights
∀i, wi(t + 1) = wi(t)
2
  1
ǫt
1ht(xi)̸=yi +
1
1 −ǫt
1ht(xi)=yi

.
11:
end if
12: end for
13: Return the rule
f T(·) = sign
 T
∑
t=1
αtht(·)

.

88
Chapter 7. An analysis of the Viola-Jones face detection algorithm
(a)
(b)
Figure 7.4 – Algorithm 16 ran with equally weighted 2500 positive and 2500 negative
examples. Figure (a) shows that the empirical risk and its upper bound, interpreted as the
exponential loss (see Appendix 7.4), decrease steadily over iterations. This implies that
false positive and false negative rates must also decrease, as observed in (b).
7.2.3
Attentional cascade
In theory, Adaboost can produce a single committee of decision stumps
that generalizes well. However, to achieve that, an enormous negative
training set is needed at the outset to gather all possible negative pat-
terns. In addition, a single committee implies that all the windows inside
an image have to go through the same lengthy decision process. There has
to be another more cost-efﬁcient way.
The prior probability for a face to appear in an image bears little rele-
vance to the presented classiﬁer construction because it requires both the
empirical false negative and false positive rate to approach zero. However,
our own experience tells us that in an image, a rather limited number
of sub-windows deserve more attention than others. This is true even for
face-intensive group photos. Hence the idea of a multi-layer attentional
cascade which embodies a principle akin to that of Shannon coding: the
algorithm should deploy more resources to work on those windows more
likely to contain a face while spending as little effort as possible on the
rest.
Each layer in the attentional cascade is expected to meet a training tar-
get expressed in false positive and false negative rates: among n negative
examples declared positive by all of its preceding layers, layer l ought to
recognize at least (1 −γl)n as negative and meanwhile try not to sacriﬁce
its performance on the positives: the detection rate should be maintained
above 1 −βl.
At the end of the day, only the generalization error counts which un-
fortunately can only be estimated with some validation examples that Ad-
aboost is not allowed to see at the training phase. Hence in Algorithm 20
at line 10, a conservative choice is made as to how one assesses the error
rates: the higher false positive rate obtained from training and validation
is used to evaluate how well the algorithm has learned to distinguish faces
from non-faces. The false negative rate is assessed in the same way.
It should be kept in mind that Adaboost by itself does not favor either
error rate: it aims to reduce both simultaneously rather than one at the
expense of the other. To allow ﬂexibility, one additional control s ∈[−1, 1]

7.2. Algorithm
89
is introduced to shift the classiﬁer
f T
s (·) = sign
 T
∑
t=1
αt
 ht(·) + s

,
(7.4)
so that a strictly positive s makes the classiﬁer more inclined to predict a
face and vice versa.
To enforce an efﬁcient resource allocation, the committee size should
be small in the ﬁrst few layers and then grow gradually so that a large
number of easy negative patterns can be eliminated with little computa-
tional effort (see Figure 7.5).
Algorithm 17 Detecting faces with an Adaboost trained cascade classiﬁer
1: Input: an M × N grayscale image I and an L-layer cascade of shifted classi-
ﬁers trained using Algorithm 20
2: Parameter: a window scale multiplier c
3: Output: P, the set of windows declared positive by the cascade
4: Set P = {[i, i + e −1] × [j, j + e −1] ⊂I : e = J24cκK, κ ∈N}
5: for l = 1 to L do
6:
for every window in P do
7:
Remove the windowed image’s mean and compute its standard devia-
tion.
8:
if the standard deviation is bigger than 1 then
9:
divide the image by this standard deviation and compute its features
required by the shifted classiﬁer at layer l with Algorithm 13
10:
if the cascade’s l-th layer predicts negative then
11:
discard this window from P
12:
end if
13:
else
14:
discard this window from P
15:
end if
16:
end for
17: end for
18: Return P
Appending a layer to the cascade means that the algorithm has learned
to reject a few new negative patterns previously viewed as difﬁcult, all the
while keeping more or less the same positive training pool. To build the
next layer, more negative examples are thus required to make the training
process meaningful. To replace the detected negatives, we run the cascade
on a large set of gray images with no human face and collect their false
positive windows. The same procedure is used for constructing and re-
plenishing the validation set (see Algorithm 17). Since only 24 × 24 sized
examples can be used in the training phase, those bigger false positives
are down-sampled (Algorithm 18) and recycled using Algorithm 19.
Assume that at layer l, a committee of Tl weak classiﬁers is formed
along with a shift s so that the classiﬁer’s performance on training and
validation set can be measured. Let us denote the achieved false positive
and false negative rate by bγl and bβl. Depending on their relation with the
targets γl and βl, four cases are presented:
1. If the layer training target is fulﬁlled (Algorithm 20 line 11: bγl ≤γl
and bβl ≤βl), the algorithm moves on to training the next layer if
necessary.

90
Chapter 7. An analysis of the Viola-Jones face detection algorithm
Algorithm 18 Downsampling a square image
1: Input: an e × e image I (e > 24)
2: Output: a downsampled image O of dimension 24 × 24
3: Blur I using a Gaussian kernel with standard deviation σ = 0.6
q
( e
24)2 −1
4: Allocate a matrix O of dimension 24 × 24
5: for i = 0 to 23 do
6:
for j = 0 to 23 do
7:
Compute the scaled coordinates ˜i ←e−1
25 (i + 1), ˜j ←e−1
25 (j + 1)
8:
Set ˜imax ←min(J˜iK + 1, e −1), ˜imin ←max(0, J˜iK), ˜jmax ←min(J˜jK +
1, e −1), ˜jmin ←max(0, J˜jK)
9:
Set O(i, j) = 1
4

I(˜imax, ˜jmax) + I(˜imin, ˜jmax) + I(˜imin, ˜jmin) + I(˜imax, ˜jmin)

10:
end for
11: end for
12: Return O
Algorithm 19 Collecting false positive examples for training a cascade’s
(L + 1)-th layer
1: Input: a set of grayscale images with no human faces and an L-layer cascade
of shifted classiﬁers
2: Parameter: a window scale multiplier c
3: Output: a set of false positive examples V
4: for every grayscale image do
5:
Run Algorithm 17 to get all of its false positives Q
6:
for every windowed image in Q do
7:
if the window size is bigger than 24 × 24 then
8:
downsample this subimage using Algorithm 18 and run Algorithm 17
on it
9:
if the downsampled image remains positive then
10:
accept this false positive to V
11:
end if
12:
else
13:
accept this false positive to V
14:
end if
15:
end for
16: end for
17: Return V

7.2. Algorithm
91
Algorithm 20 Attentional Cascade
1: Input: n training positives, m validation positives, two sets of gray images
with no human faces to draw training and validation negatives, desired over-
all false positive rate γo, and targeted layer false positive and detection rate
γl and 1 −βl.
2: Parameter: maximum committee size at layer l: Nl = min(10l + 10, 200).
3: Output: a cascade of committees.
4: Set the attained overall false positive rate bγo ←1 and layer count l ←0.
5: Randomly draw 10n negative training examples and m negative validation
examples.
6: while bγo > γo do
7:
u ←10−2, l ←l + 1, sl ←0, and Tl ←1.
8:
Run Algorithm 16 on the training set to produce a classiﬁer f Tl
l
=
sign

∑Tl
t=1 αtht

.
9:
Run the sl-shifted classiﬁer f Tl
l,sl = sign

∑Tl
t=1 αt
 ht + sl

, on both the
training and validation set to obtain the empirical and generalized false
positive (resp. false negative) rate γe and γg (resp. βe and βg).
10:
bγl ←max(γe, γg) and bβl ←max(βe, βg).
11:
if bγl ≤γl and 1 −bβl ≥1 −βl then
12:
bγo ←bγo × bγl.
13:
else if bγl ≤γl, 1 −bβl < 1 −βl and u > 10−5 (there is room to improve the
detection rate) then
14:
sl ←sl + u.
15:
if the trajectory of sl is not monotone then
16:
u ←u/2.
17:
sl ←sl −u.
18:
end if
19:
Go to line 9.
20:
else if bγl > γl, 1 −bβl ≥1 −βl and u > 10−5 (there is room to improve the
false positive rate) then
21:
sl ←sl −u.
22:
if the trajectory of sl is not monotone then
23:
u ←u/2.
24:
sl ←sl + u.
25:
end if
26:
Go to line 9.
27:
else
28:
if Tl > Nl then
29:
sl ←−1
30:
while 1 −bβl < 0.99 do
31:
Run line 9 and 10.
32:
end while
33:
bγo ←bγo × bγl.
34:
else
35:
Tl ←Tl + 1 (Train one more member to add to the committee.)
36:
Go to line 8.
37:
end if
38:
end if
39:
Remove the false negatives and true negatives detected by the current cas-
cade
fcascade(X) = 2
 l
∏
p=1
1f
Tp
p,sp(X)=1 −1
2

.
Use this cascade with Algorithm 19 to draw some false positives so that
there are n training negatives and m validation negatives for the next
round.
40: end while
41: Return the cascade.

92
Chapter 7. An analysis of the Viola-Jones face detection algorithm
2. If there is room to improve the detection rate (Algorithm 20 line 13:
bγl ≤γl and bβl > βl), s is increased by u, a preﬁxed unit.
3. If there is room to improve the false positive rate (Algorithm 20 line
20: bγl > γl and bβl ≤βl), s is decreased by u.
4. If both error rates fall short of the target (Algorithm 20 line 27: bγl >
γl and bβl > βl), the algorithm, if the current committee does not
exceed a preﬁxed layer speciﬁc size limit, trains one more member
to add to the committee.
Special attention should be paid here: the algorithm could alternate be-
tween case 2 and 3 and create a dead loop. A solution is to halve the
unit u every time it happens until u becomes smaller than 10−5. When it
happens, one more round of training at this layer is recommended.
As mentioned earlier, to prevent a committee from growing too big,
the algorithm stops reﬁning its associated layer after a layer dependent
size limit is breached (Algorithm 20 line 28). In this case, the shift s is set
to the smallest value that satisﬁes the false negative requirement. A harder
learning case is thus deferred to the next layer. This strategy works because
Adaboost’s inability to meet the training target can often be explained by
the fact that a classiﬁer trained on a limited number of examples might
not generalize well on the validation set. However, those hard negative
patterns should ultimately appear and be learned if the training goes on,
albeit one bit at a time.
To analyze how well the cascade does, let us assume that at layer l,
Adaboost can deliver a classiﬁer f Tl
l,sl with false positive γl and detection
rate 1 −βl. In probabilistic terms, it means
P( f Tl
l,sl(X) = 1|Y = 1) ≥1 −βl and P( f Tl
l,sl(X) = 1|Y = −1) ≤γl,
where by abuse of notation we keep P to denote the probability on some
image space. If Algorithm 20 halts at the end of L iterations, the decision
rule is
fcascade(X) = 2
 L
∏
l=1
1f
Tl
l,sl (X)=1 −1
2

.
A window is thus declared positive if and only if all its component layers
hold the same opinion
P( fcascade(X) = 1|Y = −1)
=P(
L\
l=1
{ f Tl
l,sl(X) = 1}|Y = −1)
=P( f TL
L,sL(X) = 1|
L−1
\
l=1
{ f Tl
l,sl(X) = 1} and Y = −1)P(
L−1
\
l=1
{ f Tl
l,sl(X) = 1}|Y = −1)
≤γlP(
L−1
\
l=1
{ f Tl
l,sl(X) = 1}|Y = −1)
≤γL
l .

7.2. Algorithm
93
Likewise, the overall detection rate can be estimated as follows
P( fcascade(X) = 1|Y = 1)
=P(
L\
l=1
{ f Tl
l,sl(X) = 1}|Y = 1)
=P( f TL
L,sL(X) = 1|
L−1
\
l=1
{ f Tl
l,sl(X) = 1} and Y = 1)P(
L−1
\
l=1
{ f Tl
l,sl(X) = 1}|Y = 1)
≥(1 −βl)P(
L−1
\
l=1
{ f Tl
l,sl(X) = 1}|Y = 1)
≥(1 −βl)L.
In other words, if the empirically obtained rates are any indication, a face-
less window will have a probability higher than 1 −γl to be labeled as
such at each layer, which effectively directs the cascade classiﬁer’s atten-
tion on those more likely to have a face (see Figure 7.6).
(a)
(b)
(c)
(d)
(e)
(f)
(g)
(h)
(i)
(j)
(k)
(l)
(m)
(n)
(o)
(p)
(q)
(r)
(s)
(t)
(u)
(v)
(w)
(x)
Figure 7.5 – A selection of negative training examples at round 21 (a) (b) (c) (d) (e)
(f), round 26 (g) (h) (i) (j) (k) (l), round 27 (m) (n) (o) (p) (q) (r), round 28 (s) (t) (u)
(v) (w) (x). Observe how the negative training examples become increasingly difﬁcult to
discriminate from real faces.
7.2.4
Dataset and experiments
A few words on the actual cascade training carried out on a 8-core
Linux machine with 48G memory. We ﬁrst downloaded 2897 different im-
ages without human faces from Jégou et al. (2008), Tkaˇcik et al. (2011), Ol-
mos (2004), National Oceanic and Atmospheric Administration (NOAA)
Photo Library and European Southern Observatory. They were divided

94
Chapter 7. An analysis of the Viola-Jones face detection algorithm
(a)
(b)
(c)
(d)
Figure 7.6 – How the trained cascade performs with (a) 16 layers, (b) 21 layers, (c) 26
layers and (d) 31 layers: the more layers, the less false positives.
into two sets containing 2451 and 446 images respectively for training and
validation. 1000 training and 1000 validation positive examples from an
online source were used. The training process lasted for around 24 hours
before producing a 31-layer cascade. It took this long because it became
harder to get 2000 false positives (1000 for training and 1000 for validation)
using Algorithm 19 with a more discriminative cascade: the algorithm
needed to examine more images before it could come across enough good
examples. The targeted false positive and false negative rate for each layer
were set to 0.5 and 0.995 respectively and Figure 7.7 shows how the ac-
cumulated false positive rate as deﬁned at line 12 and 33 of Algorithm 20
evolves together with the committee size. The fact that the later layers re-
quired more intensive training also contributed to a long training phase.
7.3
Post-processing
Figure 7.6(d) and Figure 7.8(a) show that the same face can be detected
multiple times by a correctly trained cascade. This should come as no sur-
prise as the positive examples (see Figure 7.3(a)) do allow a certain ﬂexi-

7.3. Post-processing
95
(a)
(b)
Figure 7.7 – (a) Though occasionally stagnant, the accumulated false positive rate de-
clines pretty fast with the number of layers. (b) As the learning task becomes more difﬁ-
cult as the cascade has more layers, more weak learners per layer are called upon. (In our
experiments, the number of weak learners cannot exceed 201 per layer.)
bility in pose and expression. On the contrary, many false positives do not
enjoy this stability, despite the fact that taken out of context, some of them
do look like a face (also see Figure 7.5). This observation lends support
to the following detection conﬁdence based heuristics for further reducing
false positives and cleaning up the detected result (see Algorithm 21):
1. A detected window contains a face if and only if a sufﬁcient num-
ber of other adjacent detected windows of the same size conﬁrm it.
To require windows of exactly the same size is not stringent because
the test window sizes are quantiﬁed (see Algorithm 17 line 2). In
this implementation, the window size multiplier is 1.5. Two e × e
detected windows are said to be adjacent if and only if between
the upper left corners of these two windows there is a path formed
by the upper left corners of some detected windows of the same
size. This condition is easily checked with the connected component
algorithm 1 Shapiro and Stockman (2001). The number of test win-
dows detecting a face is presumed to grow linearly with its size. This
suggests the quotient of the cardinality of a connected component
of adjacent windows by their common size e as an adequate conﬁ-
dence measure. This quotient is then compared to the scale invariant
threshold empirically set at 3/24, which means that to conﬁrm the
detection of a face of size 24 × 24, three adjacent detected windows
are sufﬁcient.
2. It is possible for the remaining detected windows to overlap after
the previous test. In this case, we distinguish two scenarios (Algo-
rithm 21 line 15–25):
(a) If the smaller window’s center is outside the bigger one, keep
both.
(b) Keep the one with higher detection conﬁdence otherwise.
Finally, to make the detector slightly more rotation-invariant, in this
implementation, we decided to run Algorithm 17 three times, once on
1. We
obtained
a
version
from
http://alumni.media.mit.edu/~rahimi/
connected/.

96
Chapter 7. An analysis of the Viola-Jones face detection algorithm
the input image, once on a clockwise rotated image and once on an anti-
clockwise rotated image before post-processing all the detected windows
(see Algorithm 22). In addition, when available, color also conveys valu-
able information to help further eliminate false positives. Hence in the
current implementation, after the robustness test, an option is offered as
to whether color images should be post-processed with this additional
step (see Algorithm 23). If so, a detected window is declared positive only
if it passes both tests.
Algorithm 21 Post-Processing
1: Input: a set G windows declared positive on an M × N grayscale image
2: Parameter: minimum detection conﬁdence threshold r
3: Output: a reduced set of positive windows P
4: Create an M × N matrix E ﬁlled with zeros.
5: for each window w ∈G do
6:
Take w’s upper left corner coordinates (i, j) and its size e and set E(i, j) ←e
7: end for
8: Run a connected component algorithm on E.
9: for each component C formed by |C| detected windows of dimension eC × eC
do
10:
if its detection conﬁdence |C|e−1
C
> r then
11:
send one representing window to P
12:
end if
13: end for
14: Sort the elements in P in ascending order of window size.
15: for window i = 1 to |P| do
16:
for window j = i + 1 to |P| do
17:
if window j remains in P and the center of window i is inside of window
j then
18:
if window i has a higher detection conﬁdence than window j then
19:
remove window j from P
20:
else
21:
remove window i from P and break from the inner loop
22:
end if
23:
end if
24:
end for
25: end for
26: Return P.
7.4
Appendix
This section explains, from a mathematical perspective, how and why
Adaboost (Algorithm 16) works. We deﬁne the exponential loss
∀(x, y) ∈Rd × {−1, 1},
L(y, f (x)) = exp(−y f (x)),
where the classiﬁer f : Rd 7→R takes the form of a linear combination of
weak classiﬁers
f (·) =
T
∑
t=1
αtht(·),

7.4. Appendix
97
Algorithm 22 Face detection with image rotation
1: Input: an M × N grayscale image I
2: Parameter: rotation θ
3: Output: a set of detected windows P
4: Rotate the image about its center by θ and −θ to have Iθ and I−θ
5: Run Algorithm 17 on I, Iθ and I−θ to obtain three detected window sets P,
Pθ and P−θ respectively
6: for each detected window w in Pθ do
7:
Get w’s upper left corner’s coordinates (iw, jw) and its size ew
8:
Rotate (iw, jw) about Iθ’s center by −θ to get (˜iw, ˜jw)
9:
Quantify the new coordinates ˜iw ←min(max(0, J˜iwK), M −1) and ˜jw ←
min(max(0, J˜jwK), N −1)
10:
if there is no ew × ew window located at (˜iw, ˜jw) in P then
11:
Add it to P
12:
end if
13: end for
14: Replace θ by −θ and go through lines 6–13 again
15: Return P
Algorithm 23 Skin Test
1: Input: an N × N color image I
2: Output: return whether I has enough skin like pixels
3: Set a counter c ←0
4: for each pixel in I do
5:
if the intensities of its green and blue channel are lower than that of its red
channel then
6:
c ←c + 1
7:
end if
8: end for
9: if c/N2 > 0.4 then
10:
Return true
11: else
12:
Return false
13: end if

98
Chapter 7. An analysis of the Viola-Jones face detection algorithm
(a)
(b)
Figure 7.8 – The suggested post-processing procedure further eliminates a number of
false positives and beautiﬁes the detected result using a 31 layer cascade.
with T ∈N, min1≤t≤T αt > 0 and ∀t, ht(·) ∈{−1, 1}. Naturally, the
overall objective is
min
ht,αt≥0
n
∑
i=1
wi(1)L(yi,
T
∑
t=1
αtht(xi)),
(7.5)
with some initial probabilistic weight wi(1). A greedy approach is de-
ployed to deduce the optimal classiﬁers ht and weights αt one after an-
other, although there is no guarantee that the objective (7.5) is minimized.
Given (αs, hs)1≤s<t, let Zt+1 be the weighted exponential loss attained by a
t-member committee and we seek to minimize it through (ht, αt)

7.4. Appendix
99
Zt+1 := min
ht,αt≥0
n
∑
i=1
wi(1)e−yi ∑t
s=1 αshs(xi)
= min
ht,αt≥0
n
∑
i=1
Di(t)e−αtyiht(xi)
= min
ht,αt≥0
n
∑
i=1
Di(t)e−αt1yiht(xi)=1 +
n
∑
i=1
Di(t)eαt1yiht(xi)=−1
= min
ht,αt≥0 e−αt
n
∑
i=1
Di(t) + (eαt −e−αt)
n
∑
i=1
Di(t)1yiht(xi)=−1
=Zt min
ht,αt≥0 e−αt + (eαt −e−αt)
n
∑
i=1
Di(t)
Zt
1yiht(xi)=−1,
Therefore the optimization of Zt+1 can be carried out in two stages:
ﬁrst, because of αt’s assumed positivity, we minimize the weighted error
using a base learning algorithm, a decision stump for instance
ǫt := min
h
Z−1
t
n
∑
i=1
Di(t)1yih(xi)=−1,
ht := argmin
h
Z−1
t
n
∑
i=1
Di(t)1yih(xi)=−1.
In case of multiple minimizers, take ht to be any of them. Next choose
αt = 1
2 ln 1 −ǫt
ǫt
= argmin
α>0
e−α + (eα −e−α)ǫt.
Hence ǫt < 0.5 is necessary, which imposes a minimal condition on the
training set and the base learning algorithm. Also obtained is
Zt+1 = 2Zt
q
ǫt(1 −ǫt) ≤Zt,
a recursive relation asserting the decreasing behavior of the exponential
risk. Weight change thus depends on whether an observation is misclassi-
ﬁed
wi(t + 1) = Di(t + 1)
Zt+1
= Di(t)e−yiαtht(xi)
2Zt
p
ǫt(1 −ǫt) = wi(t)
2
 1ht(xi)=yi
1
1 −ǫt
+ 1ht(xi)̸=yi
1
ǫt

.
The ﬁnal boosted classiﬁer is thus a weighted committee
f (·) := sign
 T
∑
t=1
αtht(·)

.


Conclusions and
perspectives
A patch based approach to image processing, like the binary classiﬁca-
tion problem examined in Chapter 7, can be framed as a risk minimization
program. Examples of this formulation are abundant. Here let us focus on
the denoising problem where a patch X and its noisy observation Y are
related by
Y = X + N
with the Gaussian noise term N independent of X. The local performance
of a ﬁlter f designed to estimate X from Y can be evaluated with the
quadratic risk
RX( f ) := E[∥X −f (Y)∥2
2|X].
Since X is rarely ﬁxed in most applications, two overall risk criteria are
used to deﬁne an optimal ﬁlter design. The ﬁrst one is the minimax risk
inf
f sup
X
RX( f ).
Given a basis in which X can be sparsely represented, this criterion leads
to the remarkable shrinkage (thresholding) estimators Donoho and John-
stone (1994; 1995), which is then generalized to numerous variational for-
mulations with ℓ1 sparsity constraint Fornasier and Rauhut (2008) whose
most rudimentary form is
f (Y) = Dα∗with α∗= argmin
α
∥Y −Dα∥2
2 + λ∥α∥1
in which the dictionary D need not be an orthonormal basis and can be
learned from data Elad and Aharon (2006), Mairal et al. (2009).
In contrast, this thesis adopts the minimal Bayesian risk criterion
inf
f ERX( f ),
which requires probabilistic modelling so as to make the meaning of the
expectation E precise. Note that a Bayesian optimal ﬁlter is not necessarily
minimax and vice versa. But it has an explicit probabilistic interpretation
because of the quadratic risk:
argmin
f
ERX( f ) = argmin
f
E∥X −f (Y)∥2
2 = E[X|Y].
101

102
Conclusions and perspectives
We now review several parametric approximations of this Bayesian
optimal ﬁlter (see Chapter 5 for the non-parametric ones). Note again that
Bayesian optimality hinges on X’s distribution.
1. as E[X|Y] only depends on the posterior distribution P(X|Y), if we
model it as a multivariate Gaussian and infer its parameters from
similar patches in the same image, it results in the highly successful
NL-Bayes Lebrun et al. (2013b).
2. an indirect approach to get P(X|Y) is to model the marginal law of
X, or the Bayesian prior. Ideally this prior should be the patch com-
position of the image to restore (Xi)1≤i≤N because then the Bayesian
risk ERX( f ) equals the expected patch MSE
1
N
N
∑
i=1
E[∥Xi −f (Yi)∥2
2|Xi]
(7.6)
which, as argued in Chapter 1, serves as an asymptotic upper bound
of the expected image MSE.
This motivates a Gaussian mixture modelling because of the ease
with which such a device can ﬁt patches extracted locally from noisy
images thanks to the Expectation and Maximization algorithm. The
use of Gaussian mixture also produces a closed form of the condi-
tional expectation as a weighted sum of Wiener ﬁlters (see Chap-
ter 1, 5). However, the fact that such a ﬁlter did not yield superior
numerical results indicates the limitation of the modelling premise.
Nonetheless, it enables a posterior likelihood based patch classiﬁ-
cation and results in an over-complete dictionary for sparse patch
representation. In addition, thanks to SURE, the Bayesian risk (7.6)
can be estimated, which aids ﬁlter selection within the Bayesian risk
minimization paradigm.
Without SURE guided ﬁlter selection, the main conceptual difference
between this algorithm and NL-Bayes is that the former is less con-
servative in its inference of P(X|Y) as it involves patches with similar
orientations rather than just similar patches. Their performance gap
thus highlights the fundamental difﬁculty of image denoising due to
the rather varying nature of Y 7→P(X|Y): it is not smooth from one
patch to another within the same orientation class.
3. to circumvent the difﬁculty of inferring from a single noisy image
its prior patch distribution, we may use a more complex patch dis-
tribution from a generic image database Levin and Nadler (2011),
Burger et al. (2012). In so doing, we set the stage for the deﬁnitive
Bayesian framework as a ﬁlter’s Bayesian risk now represents its
aggregate performance on a wide-range of natural images. Clearly,
the beneﬁt brought by this approach is unlimited noise-free data.
With multilayer neural networks, it seems ﬁnally possible to get our
hands on this Bayesian optimal ﬁlter. But the Bayesian nature also
has its own share of issues. For instance, it is reported Burger et al.
(2012) that multilayer neural networks have trouble restoring regu-
lar but high frequency patterns, which is unsurprising given their
relative scarcity (see Chapter 1). Hence the ability to evaluate a pat-

Conclusions and perspectives
103
tern’s Bayesian prior is desirable as it allows to switch between the
Bayesian and minimax ﬁlters for a better result.
Finally, we note that larger observations help reduce the Bayesian risk,
as shown by the conditional expectation argument (see Chapter 5). But for
all practical purposes, we should overcome the temptation to employ ever
larger neural networks. Chapter 4, 5 are such examples which make use of
the image patch distribution’s special properties. Furthermore, an analogy
between the conditional expectation and an ordinary function indicates
two other possibilities:
1. as in linear interpolation, we may partition a complex neural net-
work’s domain of deﬁnition so as to approximate it with several
simpler ones with restricted domains;
2. as in function approximation, we may consider some hand crafted
algorithms as a ﬁrst approximation and use neural networks exclu-
sively for computing the difference.


Bibliography
M. Aharon, M. Elad, and A. Bruckstein. K-SVD: Design of dictionaries
for sparse representation. Proceedings of Signal Processing with Adaptive
Sparse Structured Representations, 5:9–12, 2005. http://dx.doi.org/
10.1109/TSP.2006.881199.
A. R. Barron. Approximation and estimation bounds for artiﬁcial neu-
ral networks. Machine Learning, 14(1):115–133, 1994. http://dx.doi.
org/10.1007/BF00993164.
B. E. Bayer. Color imaging array, Juillet 20 1976. US Patent 3,971,065.
Y. Bengio. Learning deep architectures for AI. Foundations and trends R⃝in
Machine Learning, 2(1):1–127, 2009. http://dx.doi.org/10.1561/
2200000006.
M. Bertalmio, G. Sapiro, V. Caselles, and C. Ballester.
Image inpaint-
ing.
In Proceedings of the 27th Annual Conference on Computer Graph-
ics and Interactive Techniques, pages 417–424. ACM Press, 2000. http:
//dx.doi.org/10.1145/344779.344972.
M. Bertalmio, L. Vese, G. Sapiro, and S. Osher. Simultaneous structure and
texture image inpainting. IEEE Transactions on Image Processing, 12(8):
882–889, 2003. http://dx.doi.org/10.1109/TIP.2003.815261.
L. Bottou. Large-scale machine learning with stochastic gradient descent.
In Proceedings of the 19th International Symposium on Computational Statis-
tics, pages 177–186. Springer, 2010. http://dx.doi.org/10.1007/
978-3-7908-2604-3_16.
P. J. Brockwell and R. A. Davis. Time Series: Theory and Models, 1991.
A. Buades, B. Coll, and J. M. Morel. A review of image denoising algo-
rithms, with a new one. Multiscale Modeling & Simulation, 4(2):490–530,
2005. http://dx.doi.org/10.1145/344779.344972.
A. Buades, B. Coll, and J. M. Morel. Non-Local Means Denoising. Im-
age Processing On Line, 2011a. http://dx.doi.org/10.5201/ipol.
2011.bcm_nlm.
A. Buades, B. Coll, J. M. Morel, and C. Sbert. Self-similarity driven color
demosaicking.
IEEE Transactions on Image Processing, 18(6):1192–1202,
2009. http://dx.doi.org/10.1109/TIP.2009.2017171.
A. Buades, B. Coll, J. M. Morel, and C. Sbert. Self-similarity Driven Demo-
saicking. Image Processing On Line, 2011b.
105

106
Bibliography
H. C. Burger, C. Schuler, and S. Harmeling. Learning how to combine
internal and external denoising methods. In Pattern Recognition, pages
121–130. Springer, 2013.
H. C. Burger, C. J. Schuler, and S. Harmeling. Image denoising: Can plain
neural networks compete with BM3D? In Computer Vision and Pattern
Recognition, pages 2392–2399. IEEE, 2012. http://dx.doi.org/10.
1109/CVPR.2012.6247952.
H.C. Burger. Modelling and Learning Approaches to Image Denoising. PhD the-
sis, Eberhard Karls Universität Tübingen, Wilhelmstr. 32, 72074 Tübin-
gen, 2013.
Emmanuel J Candès. What is... a curvelet? Notices of the American Mathe-
matical Society, 50(11):1402–1403, 2003.
P. Chatterjee, N. Joshi, S. B. Kang, and Y. Matsushita. Noise suppression in
low-light images through joint denoising and demosaicing. In Computer
Vision and Pattern Recognition, pages 321–328. IEEE, 2011. http://dx.
doi.org/10.1109/CVPR.2011.5995371.
P. Chatterjee and P. Milanfar.
Clustering-based denoising with locally
learned dictionaries. IEEE Transactions on Image Processing, 18(7):1438–
1451, 2009. http://dx.doi.org/10.1109/TIP.2009.2018575.
S. Chen, D. L. Donoho, and M. A. Saunders. Atomic decomposition by
basis pursuit.
SIAM journal on scientiﬁc computing, 20(1):33–61, 1998.
http://dx.doi.org/10.1137/S1064827596304010.
K. Dabov, A. Foi, V. Katkovnik, and K. Egiazarian. Image denoising by
sparse 3D transform-domain collaborative ﬁltering. IEEE Transactions
on Image Processing, 16(8):2080–2095, 2007. http://dx.doi.org/10.
1109/TIP.2007.901238.
I. Daubechies et al. Ten lectures on wavelets, volume 61. SIAM, 1992.
A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum likelihood from
incomplete data via the EM algorithm.
Journal of the Royal Statistical
Society. Series B (Methodological), pages 1–38, 1977.
L. Devroye, L. Györﬁ, and G. Lugosi. A Probabilistic Theory of Pattern Recog-
nition, volume 31. Springer, 1996. http://dx.doi.org/10.1007/
978-1-4612-0711-5.
D. L. Donoho and I. M. Johnstone. Ideal spatial adaptation by wavelet
shrinkage. Biometrika, 81(3):425–455, 1994. http://dx.doi.org/10.
2307/2337118.
D. L. Donoho and I. M. Johnstone. Adapting to unknown smoothness via
wavelet shrinkage. Journal of the American Statistical Association, 90(432):
1200–1224, 1995. http://dx.doi.org/10.2307/2291512.
B. Efron, T. Hastie, I. Johnstone, R. Tibshirani, et al. Least angle regression.
The Annals of statistics, 32(2):407–499, 2004.

Bibliography
107
A. A. Efros and T. K. Leung. Texture synthesis by non-parametric sam-
pling. In International Conference on Computer Vision, volume 2, pages
1033–1038. IEEE, 1999. http://dx.doi.org/10.1109/ICCV.1999.
790383.
M. Elad and M. Aharon. Image denoising via sparse and redundant rep-
resentations over learned dictionaries. IEEE Transactions on Image Pro-
cessing, 15(12):3736–3745, 2006. http://dx.doi.org/10.1109/TIP.
2006.881969.
M. Elad, J.L. Starck, P. Querre, and D.L. Donoho. Simultaneous cartoon
and texture image inpainting using morphological component analy-
sis (MCA). Applied and Computational Harmonic Analysis, 19(3):340–358,
2005. http://dx.doi.org/10.1016/j.acha.2005.03.005.
M. Fornasier and H. Rauhut. Iterative thresholding algorithms. Applied
and Computational Harmonic Analysis, 25(2):187–208, 2008. http://dx.
doi.org/10.1016/j.acha.2007.10.005.
Y. Freund and R. Schapire. A decision-theoretic generalization of on-line
learning and an application to boosting. Journal of Computer and System
Sciences, 55(1):119–139, 1997. http://dx.doi.org/10.1006/jcss.
1997.1504.
Y. Freund, R. Schapire, and N. Abe.
A short introduction to boosting.
Journal of Japanese Society For Artiﬁcial Intelligence, 14:771–780, 1999.
J. Friedman, T. Hastie, and R. Tibshirani. The Elements of Statistical Learning,
volume 1. Springer Series in Statistics, 2001.
P. Getreuer. Contour stencils: Total variation along curves for adaptive im-
age interpolation. SIAM Journal on Imaging Sciences, 4(3):954–979, 2011a.
http://dx.doi.org/10.1137/100802785.
P. Getreuer. Zhang-Wu Directional LMMSE Image Demosaicking. Image
Processing On Line, 2011b.
P. Getreuer. Image Demosaicking with Contour Stencils. Image Processing
On Line, 2012.
J. Go, K. Sohn, and C. Lee. Interpolation using neural networks for digital
still cameras. IEEE Transactions on Consumer Electronics, 46(3):610–616,
2000. http://dx.doi.org/10.1109/30.883419.
J. F. Hamilton and J. E. Adams. Adaptive color plan interpolation in single
sensor color electronic camera, Mai 13 1997. US Patent 5,629,734.
C. Harris and M. Stephens. A combined corner and edge detector. In Alvey
Vision Conference, volume 15, page 50. Manchester, UK, 1988.
http:
//dx.doi.org/10.5244/C.2.23.
K. Hirakawa and T. W. Parks. Joint demosaicing and denoising. IEEE
Transactions on Image Processing, 15(8):2146–2157, 2006.
http://dx.
doi.org/10.1109/TIP.2006.875241.

108
Bibliography
K. Hornik, M. Stinchcombe, and H. White. Multilayer feedforward net-
works are universal approximators. Neural Networks, 2(5):359–366, 1989.
http://dx.doi.org/10.1016/0893-6080(89)90020-8.
V. Jain and S. Seung. Natural image denoising with convolutional net-
works. In Advances in Neural Information Processing Systems, pages 769–
776, 2009.
H. Jégou, M. Douze, and C. Schmid.
Hamming embedding and weak
geometric consistency for large scale image search. In European Con-
ference on Computer Vision, volume I from Lecture Notes in Computer Sci-
ence, pages 304–317. Springer, 2008. http://dx.doi.org/10.1007/
978-3-540-88682-2_24.
O. Kapah and H. Z. Hel-Or. Demosaicking using artiﬁcial neural networks.
In Electronic Imaging, pages 112–120. International Society for Optics and
Photonics, 2000. http://dx.doi.org/10.1117/12.382904.
S. M. Kay. Fundamentals of statistical signal processing: estimation theory.
1993.
M. Lebrun. An Analysis and Implementation of the BM3D Image Denois-
ing Method. Image Processing On Line, 2012. http://dx.doi.org/
10.5201/ipol.2012.l-bm3d.
M. Lebrun, A. Buades, and J. M. Morel.
Implementation of the "Non-
Local Bayes" (NL-Bayes) Image Denoising Algorithm. Image Processing
On Line, 2013a. http://dx.doi.org/10.5201/ipol.2013.16.
M. Lebrun, A. Buades, and J. M. Morel. A nonlocal bayesian image denois-
ing algorithm. SIAM Journal on Imaging Sciences, 6(3):1665–1688, 2013b.
http://dx.doi.org/10.1137/120874989.
M. Lebrun and A. Leclaire. An Implementation and Detailed Analysis of
the K-SVD Image Denoising Algorithm. Image Processing On Line, 2012.
http://dx.doi.org/10.5201/ipol.2012.llm-ksvd.
Y. LeCun, L. Bottou, G. B. Orr, and K. R. Müller. Efﬁcient backprop. In
Neural Networks: Tricks of the Trade, pages 9–50. Springer, 1998. http:
//dx.doi.org/10.1007/3-540-49430-8_2.
Honglak Lee, Alexis Battle, Rajat Raina, and Andrew Y Ng.
Efﬁcient
sparse coding algorithms. In Advances in neural information processing
systems, pages 801–808, 2006.
A. Levin and B. Nadler. Natural image denoising: Optimality and inherent
bounds. In Computer Vision and Pattern Recognition, pages 2833–2840.
IEEE, 2011. http://dx.doi.org/10.1109/CVPR.2011.5995309.
X. Li, B. Gunturk, and L. Zhang. Image demosaicking: a systematic sur-
vey. In Visual Communications and Image Processing, volume 6822, pages
68221J–68221J, 2008. http://dx.doi.org/10.1117/12.766768.
J. Mairal, F. Bach, and J. Ponce. Task-driven dictionary learning. IEEE
Transactions on Pattern Analysis and Machine Intelligence, 34(4):791–804,
2012. http://dx.doi.org/10.1109/TPAMI.2011.156.

Bibliography
109
J. Mairal, F. Bach, J. Ponce, G. Sapiro, and A. Zisserman. Non-local sparse
models for image restoration.
In International Conference on Computer
Vision, pages 2272–2279. IEEE, 2009. http://dx.doi.org/10.1109/
ICCV.2009.5459452.
S. Mallat. A wavelet tour of signal processing: the sparse way. Academic press,
2008.
S. Mallat and Z. Zhang. Matching pursuits with time-frequency dictio-
naries.
IEEE Transactions on Signal Processing, 41(12):3397–3415, 1993.
http://dx.doi.org/10.1109/78.258082.
S. Masnou and J. M. Morel. Level lines based disocclusion. In International
Conference on Image Processing, pages 259–263. IEEE, 1998. http://dx.
doi.org/10.1109/ICIP.1998.999016.
J. M. Morel and G. Yu. Is SIFT scale invariant? Inverse Problems and Imag-
ing, 5(1):115–136, 2011. http://dx.doi.org/10.3934/ipi.2011.
5.115.
J. Nocedal. Updating quasi-newton matrices with limited storage. Math-
ematics of computation, 35(151):773–782, 1980.
http://dx.doi.org/
10.2307/2006193.
A. Olmos. A biologically inspired algorithm for the recovery of shading
and reﬂectance images. Perception, 33(12):1463–1473, 2004. http://dx.
doi.org/10.1068/p5321.
B. A. Olshausen and D. J. Field. Emergence of simple-cell receptive ﬁeld
properties by learning a sparse code for natural images. Nature, 381
(6583):607–609, 1996. http://dx.doi.org/10.1038/381607a0.
D. Paliy, V. Katkovnik, R. Bilcu, S. Alenius, and K. Egiazarian. Spatially
adaptive color ﬁlter array interpolation for noiseless and noisy data. In-
ternational Journal of Imaging Systems and Technology, 17(3):105–122, 2007.
http://dx.doi.org/10.1002/ima.20109.
P. Perona and J. Malik. Scale-space and edge detection using anisotropic
diffusion. IEEE Transactions on Pattern Analysis and Machine Intelligence,
12(7):629–639, 1990. http://dx.doi.org/10.1109/34.56205.
J. Portilla and E. P. Simoncelli. A parametric texture model based on joint
statistics of complex wavelet coefﬁcients. International Journal of Com-
puter Vision, 40(1):49–70, 2000.
http://dx.doi.org/10.1023/A:
1026553619983.
J. Portilla, V. Strela, M. J. Wainwright, and E. P. Simoncelli.
Image
denoising using scale mixtures of Gaussians in the wavelet domain.
IEEE Transactions on Image Processing, 12(11):1338–1351, 2003.
http:
//dx.doi.org/10.1109/TIP.2003.818640.
B. Rajaei.
An Analysis and Improvement of the BLS-GSM Denoising
Method. Image Processing On Line, 2014. http://dx.doi.org/10.
5201/ipol.2014.86.

110
Bibliography
F. Rosenblatt. The perceptron: a probabilistic model for information stor-
age and organization in the brain. Psychological review, 65(6):386–408,
1958. http://dx.doi.org/10.1037/h0042519.
S. Roweis. EM algorithms for PCA and SPCA. Advances in Neural Informa-
tion Processing Systems, pages 626–632, 1998.
L. I. Rudin, S. Osher, and E. Fatemi. Nonlinear total variation based noise
removal algorithms. Physica D: Nonlinear Phenomena, 60(1):259–268, 1992.
http://dx.doi.org/10.1016/0167-2789(92)90242-F.
R. E. Schapire, Y. Freund, P. Bartlett, and W. S. Lee. Boosting the margin:
A new explanation for the effectiveness of voting methods. The Annals
of Statistics, 26(5):1651–1686, 1998.
http://dx.doi.org/10.1214/
aos/1024691352.
L. Shapiro and G. C. Stockman. Computer Vision, 2001.
J. Shen and T. F. Chan.
Mathematical models for local nontexture in-
paintings. SIAM Journal on Applied Mathematics, 62(3):1019–1043, 2002.
http://dx.doi.org/10.1137/S0036139900368844.
E. P. Simoncelli and W. T. Freeman. The steerable pyramid: A ﬂexible ar-
chitecture for multi-scale derivative computation. In International Con-
ference on Image Processing, volume 3, pages 3444–3444. IEEE Computer
Society, 1995. http://dx.doi.org/10.1109/ICIP.1995.537667.
J.L. Starck, E. J Candès, and D. L. Donoho. The curvelet transform for
image denoising. IEEE Transactions on Image Processing, 11(6):670–684,
2002. http://dx.doi.org/10.1109/TIP.2002.1014998.
C. M. Stein. Estimation of the mean of a multivariate normal distribution.
The Annals of Statistics, pages 1135–1151, 1981. http://dx.doi.org/
10.1214/aos/1176345632.
H. Takeda, S. Farsiu, and P. Milanfar. Kernel regression for image pro-
cessing and reconstruction. IEEE Transactions on Image Processing, 16(2):
349–366, 2007. http://dx.doi.org/10.1109/TIP.2006.888330.
R. Tibshirani. Regression shrinkage and selection via the lasso. Journal of
the Royal Statistical Society. Series B (Methodological), pages 267–288, 1996.
M. E. Tipping and C. M. Bishop. Mixtures of probabilistic principal com-
ponent analyzers.
Neural Computation, 11(2):443–482, 1999a.
http:
//dx.doi.org/10.1162/089976699300016728.
M. E. Tipping and C. M. Bishop. Probabilistic principal component analy-
sis. Journal of the Royal Statistical Society: Series B (Statistical Methodology),
61(3):611–622, 1999b. http://dx.doi.org/10.1111/1467-9868.
00196.
G. Tkaˇcik, P. Garrigan, C. Ratliff, G. Milˇcinski, J. M. Klein, L. H. Seyfarth,
P. Sterling, D. H. Brainard, and V. Balasubramanian. Natural images
from the birthplace of the human eye. Public Library of Science One, 6(6):
e20409, 2011.

Bibliography
111
C. Tomasi and R. Manduchi. Bilateral ﬁltering for gray and color images.
In International Conference on Computer Vision, pages 839–846. IEEE, 1998.
http://dx.doi.org/10.1109/ICCV.1998.710815.
P. Vincent, H. Larochelle, Y. Bengio, and P.-A. Manzagol. Extracting and
composing robust features with denoising autoencoders. In Proceedings
of the 25th international conference on Machine learning, pages 1096–1103.
ACM, 2008. http://dx.doi.org/10.1145/1390156.1390294.
P. Viola and M. J. Jones.
Robust real-time face detection.
International
Journal of Computer Vision, 57(2):137–154, 2004. http://dx.doi.org/
10.1023/B:VISI.0000013087.49260.fb.
M. J. Wainwright and M. I. Jordan. Graphical models, exponential families,
and variational inference. Foundations and Trends R⃝in Machine Learning,
1(1-2):1–305, 2008. http://dx.doi.org/10.1561/2200000001.
Y. Q. Wang. E-PLE: an Algorithm for Image Inpainting. Image Processing
On Line, 2013a. http://dx.doi.org/10.5201/ipol.2013.54.
Y. Q. Wang. The Implementation of SURE Guided Piecewise Linear Image
Denoising. Image Processing On Line, 2013b. http://dx.doi.org/10.
5201/ipol.2013.52.
J. Xie, L. Xu, and E. Chen. Image denoising and inpainting with deep
neural networks. In Advances in Neural Information Processing Systems,
pages 341–349, 2012.
G. Yu and G. Sapiro. DCT image denoising: a simple and effective image
denoising algorithm. Image Processing On Line, 2011. http://dx.doi.
org/10.5201/ipol.2011.ys-dct.
G. Yu, G. Sapiro, and S. Mallat. Solving inverse problems with piecewise
linear estimators: from Gaussian mixture models to structured sparsity.
IEEE Transactions on Image Processing, 21(5):2481–2499, 2012. http://
dx.doi.org/10.1109/TIP.2011.2176743.
H. Yue, X. Sun, J. Yang, and F. Wu. CID: Combined Image Denoising in
Spatial and Frequency Domains Using Web Images. In Computer Vision
and Pattern Recognition, pages 2933–2940. IEEE, 2014. http://dx.doi.
org/10.1109/CVPR.2014.375.
L. Zhang and X. Wu. Color demosaicking via directional linear minimum
mean square-error estimation.
IEEE Transactions on Image Processing,
14(12):2167–2178, 2005. http://dx.doi.org/10.1109/TIP.2005.
857260.
L. Zhang, X. Wu, A. Buades, and X. Li.
Color demosaicking by local
directional interpolation and nonlocal adaptive thresholding. Journal of
Electronic Imaging, 20(2):023016–023016, 2011.
D. Zoran and Y. Weiss. From learning models of natural image patches to
whole image restoration. In International Conference on Computer Vision,
pages 479–486. IEEE, 2011.
http://dx.doi.org/10.1109/ICCV.
2011.6126278.

