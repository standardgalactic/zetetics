ClaimsKG:
A Knowledge Graph of Fact-Checked Claims
Andon Tchechmedjiev1, Pavlos Fafalios2, Katarina Boland3, Malo Gasquet5,
Matth¬®aus Zloch3, Benjamin Zapilko3, Stefan Dietze3,4, Konstantin Todorov5
1 LGI2P, IMT Mines-Ales, France
2 L3S Research Center, Leibniz University of Hanover, Germany
3 GESIS - Leibniz Institute for the Social Sciences, Germany
4 Heinrich-Heine-University D¬®usseldorf, Germany
5 LIRMM / University of Montpellier / CNRS, France
andon.tchechmedjiev@mines-ales.fr, fafalios@L3S.de,
malo.gasquet@etu.umontpellier.fr, {katarina.boland, matthaeus.zloch,
benjamin.zapilko, stefan.dietze}@gesis.org, konstantin.todorov@lirmm.fr
Abstract. Various research areas at the intersection of computer and
social sciences require a ground truth of contextualized claims labelled
with their truth values in order to facilitate supervision, validation or
reproducibility of approaches dealing, for example, with fact-checking
or analysis of societal debates. So far, no reasonably large, up-to-date
and queryable corpus of structured information about claims and related
metadata is publicly available. In an attempt to Ô¨Åll this gap, we introduce
ClaimsKG, a knowledge graph of fact-checked claims, which facilitates
structured queries about their truth values, authors, dates, journalistic
reviews and other kinds of metadata. ClaimsKG is generated through a
semi-automated pipeline, which harvests data from popular fact-checking
websites on a regular basis, annotates claims with related entities from
DBpedia, and lifts the data to RDF using an RDF/S model that makes
use of established vocabularies. In order to harmonise data originating
from diverse fact-checking sites, we introduce normalised ratings as well
as a simple claims coreference resolution strategy. The current knowledge
graph, extensible to new information, consists of 28,383 claims published
since 1996, amounting to 6,606,032 triples.
Keywords: Claims; Fact-checking; Societal debates; Knowledge Graphs
1
Introduction
The spread of controversies, biased discourse and falsehoods on the Web has
become an increasingly important issue, from both a societal as well as a research
perspective [1,30]. Recently, a wide range of interdisciplinary research directions
are being explored in this broad area, which often rely on a ground truth of
labelled claims. Such works include investigations into the spreading pattern of
false claims on Twitter [30], pipelines for discovering the stance of claim-relevant

2
Tchechmedjiev et al.
(Web) documents [34], approaches for classifying sources of news, such as Web
pages, domains, users or posts [7, 20], or research into fake news detection [27]
and automatic fact-checking [12]. In all these cases, the availability of a labelled
ground truth, consisting of claims, their corresponding metadata and, in partic-
ular, their truth values (or ratings), is essential in order to enable supervision of
machine learning methods, reproduction and explainability of the results, and to
facilitate fair evaluation and follow-up work. In addition, as documented by the
aforementioned works, claims are usually not considered in isolation, but in a
context. Thus, reproducing such research requires not only archiving claims and
their truth values, but also their related documents, such as journalistic claim
reviews, the associated entities and time-frames that can be linked to particular
events, accounting in that way for the continuous evolution of Web content.
To our knowledge, no reasonably large and up-to-date corpus of structured
information about claims and their context has been made publicly available.
We attempt to Ô¨Åll this gap by introducing ClaimsKG, a knowledge graph (KG)
of fact-checked claims, which facilitates structured queries about their truth
values and other kinds of metadata, constructed and published following the
W3C recommendations and best practices. In our context, we deÔ¨Åne a claim
as a statement which has been reviewed by a fact-checking organisation in order
to assess its truthfulness. ClaimsKG is generated through a semi-automated
pipeline, which periodically harvests data from popular fact-checking websites.
The claims and their reviews (articles written by fact-checkers that accompany
a claim and explain its context and veracity judgement) are annotated with
related entities from DBpedia, and all data are lifted into RDF using a dedicated
RDF/S model (dubbed Claims), which is based on established vocabularies such
as schema.org and NIF. In order to harmonise data originating from diverse
fact-checking sites, we introduce a normalised truth ratings scheme, as well as
a simple claim matching strategy. ClaimsKG enables advanced exploration and
information discovery, e.g., via queries such as ‚ÄúÔ¨Ånd all false claims by D. Trump
in 2017 that also mention the FBI‚Äù, or ‚ÄúÔ¨Ånd the top 5 politicians per month
involved in false claims‚Äù, as well as exploitation of data from various sources via
federated SPARQL queries, e.g., ‚Äúretrieve all claims mentioning journalists‚Äù.
We also provide a Web interface for exploring the graph, enabling users from
outside of the computer science community to retrieve information or sample
data from our resource. The dataset, as of April 2019, consists of 28,383 claims
published since 1996, amounting to 6,606,032 triples in our KG.
In summary, we provide (1) the Claims data model for representing fact-
checked claims and associated information, (2) an open-source pipeline for crawl-
ing and extracting data from fact-checking websites, and for lifting these data
following the Claims model, (3) an openly available dynamic large-scale KG of
claims and associated metadata, and (4) a Web interface for search and explo-
ration of the resource. In the following section, we provide general information
about the resource and links for access. We detail the KG generation process in
Sect. 3. We introduce our Claims model in Sect. 4, while use-cases and queries

ClaimsKG: A Knowledge Graph of Fact-Checked Claims
3
are discussed in Sect. 5 along with an overview of the exploratory user interface.
We review related work in Sect. 6 before concluding.
2
ClaimsKG in a Nutshell
ClaimsKG consists of data extracted from a number of fact-checking websites.
To select the fact-checking websites, we relied on the International Fact-Checking
Network‚Äôs (IFCN) signatories list,1 admitting only sources considered by the
fact-checking community as highly reputable. At this stage, we only consider in-
formation in English from six sources: africacheck.org, factscan.ca, politifact.com,
snopes.com, checkyourfact.com, truthorÔ¨Åction.com. Note that ClaimsKG is ex-
tensible to new websites, however, the information extraction process may vary
from one website to another due to structural speciÔ¨Åcities of the sources (cf.
Sect. 3). Each fact-checking article from these sources is parsed for extracting
the text of the claim under review as well as useful related (meta)data including
the author of the claim, the date the claim was uttered, its veracity label as well
as keywords (tags describing topics) and links to related resources. Moreover, the
text of the claim and of its review is annotated with Wikipedia/DBpedia entities
mentioned in it. Key links related to ClaimsKG are given in Table 1. The KG
is currently accessible from a Virtuoso triplestore with a SPARQL endpoint and
downloadable as a Zenodo dump. All represented entities (claims, authors, etc.)
are assigned resolvable identiÔ¨Åers following the W3C best practices (see Sect. 3
for an example). The dataset has a DCAT description and is released for free
distribution under a Creative Commons Attribution-NonCommercial-ShareAlike
4.0 licence.2 The graph can be also accessed through ClaimsKG‚Äôs oÔ¨Écial web-
page, which displays detailed up-to-date statistics and a set of example SPARQL
queries. All tools developed for the KG‚Äôs creation are made available as open
source on GitHub. Table 2 oÔ¨Äers some general and per-source coverage statistics
for the data, in particular the coverage of key properties. In order to account for
emerging claims, the dataset is updated regularly (every 3-6 months).
Table 1: Key links to ClaimsKG‚Äôs data and tools.
ClaimsKG website
https://data.gesis.org/claimskg/site
Dataset DOI
https://doi.org/10.5281/zenodo.2628745
DCAT description
Included in the KG
Zenodo dump
https://zenodo.org/record/2628745
SPARQL endpoint
https://data.gesis.org/claimskg/sparql
The Claims ontology
https://data.gesis.org/claimskg/site/#model
Exploratory interface
https://data.gesis.org/claimskg/explorer
ClaimsKG pipeline source code
https://github.com/claimskg
1 https://ifcncodeofprinciples.poynter.org/signatories
2 https://creativecommons.org/licenses/by-nc-sa/4.0/

4
Tchechmedjiev et al.
Table 2: Claim metadata coverage and statistics (as of April 2019)
Property\Fact-checking website
Global
Snopes
Politifact
AfricaCheck
TruthOrFiction
CheckYourFact
FactScan
Number of claims
28,383
10,685
15,743
560
778
492
125
Claim text
100%
100%
100%
100%
100%
100%
100%
Claim author
93.6%
100%
100%
0.0%
0.0%
0.0%
100%
Claim date published
92.1%
96.3%
100%
0.0%
0.0%
0.0%
98.4%
Claim with references (‚â•1)
86.5%
99.8%
75.9%
97.0%
100%
99.6%
100%
Claim with keywords (‚â•1)
93.8%
95.4%
100%
99.5%
0%
0.0%
100%
Claim with entities (‚â•1)
99.7%
99.9%
100%
98.2%
99.6%
92.9%
100%
Claim review URL
100%
100%
100%
100%
100%
100%
100%
Claim review title
100%
100%
100%
100%
100%
100%
100%
Claim review author
100%
100%
100%
100%
100%
100%
100%
Claim review date published
100%
100%
100%
100%
0%
100%
100%
Claim review language
100%
100%
100%
100%
100%
100%
100%
Claim review with entities (‚â•1)
66.9%
74.1%
58.7%
80.2%
76.0%
97.0%
96.0%
Claim rating
100%
100%
100%
100%
100%
100%
100%
Exact claim matches
87
38
49
0
0
0
0
True claims
3,725
1,311
2,255
60
97
0
2
False claims
11,068
6,002
4,663
209
191
0
3
Mixture claims
10,420
1,798
8,564
0
56
2
0
Other claims
3,170
1,574
261
291
434
490
120
3
Generating ClaimsKG
ClaimsKG is built through a pipeline, which periodically crawls popular fact-
checking sites, normalises ratings and entity mentions, reconciles identical claims,
and lifts the data onto the speciÔ¨Åcally developed Claims model, described in Sect.
4. Hereafter, we detail the technical steps of the pipeline, summarised in Fig. 1.
Links to its open-source components are given in Table 1.
Extracting claims and metadata. The Claims extractor crawls the identiÔ¨Åed
fact-checking websites and collects the information in a JSON or Microdata
format to consolidate a large multi-sourced data set (as a CSV Ô¨Åle). The collected
data consist mainly of: (a) the textual statement of the claim; (b) its truth-value
or rating (both the normalised and the original one); (c) a link to the claim review
from the fact-checking website; (d) the references cited in the claim reviews; (e)
the entities extracted from the text of the claim and from the review body; (f)
the author of the claim and the author of the review; (g) the date of publication
of the claim and that of the review; (h) the title of the review article; (i) a set
of keywords extracted from the websites acting as topics (e.g. ‚Äúabortion‚Äù).
Note that the extraction process is tailored individually to the structure of
each of the diÔ¨Äerent fact-checking websites, resulting in a set of website-speciÔ¨Åc
extractors. The statistics generated at each run of the pipeline (globally and
per domain) allow to monitor the ‚Äúhealth‚Äù of the extracted data by detecting
potential issues that may be related to changes of the structures of the respective
fact-checking websites that may have occurred between two runs of the pipeline.
Virtuoso
Claims 
Extractor
Knowledge
Graph
Generator
Fact-checking 
websites
Redis
Caching
Redis
Caching
Statistics
SPARQL Endpoint
ClaimsKG Explorer
Fig. 1: Overall architecture of the ClaimsKG pipeline.

ClaimsKG: A Knowledge Graph of Fact-Checked Claims
5
Entity annotation of the claims. We annotate the entities (e.g., names of
persons, organisations, locations, etc.) mentioned in the texts of the claims and
their reviews using the TagMe tool [8]. TagMe allows the automatic identiÔ¨Åcation
of entities in a text and their linking to a Wikipedia page and a DBpedia URI. It
is known to achieve particularly good results when annotating short texts, which
is the case for the statements in this domain, although we also annotate the body
of the claim reviews. We run a local version of TagMe, allowing us to update
the database regularly, using the latest available dump of Wikipedia (October
2018). We performed all the annotations using the optimal parameters described
in [8]. We evaluated our updated TagMe model on the YAGO CONLL-TestB
ground truth dataset [14] and obtained an accuracy of 75.5%, which is in line
with state of the art performance reported for TagMe.3
Normalization of ratings. Each of the fact-checking websites has its own
labels describing the truthfulness of the claims, with diÔ¨Äerent discrete textual
values of ratings. While some sites have a controlled vocabulary of possible truth
values, others apply an open-ended rating schema. For example, Truth or Fic-
tion has a large number of non-uniform labels, such as ‚Äútruth & misleading‚Äù or
‚Äúreported as Ô¨Åction‚Äù. In order to harmonize our dataset, alongside the original
ratings, we also provide a normalized rating score, applied across all claims con-
tained in the dataset. For each of the sources, we summarised the distribution of
rating values and then assigned them to a conservative and coarser-grained set of
labels that correspond to the least common denominator between all the classiÔ¨Å-
cations of the individual sites. Given the varied rating schemes, where individual
labels often are hard to objectively apply or interpret, we opted for a simple rat-
ing scheme consisting of four basic categories (TRUE, FALSE, MIXTURE, OTHER)
that can be mapped to existing rating schemes.4 The two extreme cases of a
claim being proven true or false are captured by TRUE and FALSE, while MIXTURE
characterises something on a truth scale or that holds both a degree of truth
and a degree of falsehood. For anything that does not fall into this spectrum,
we chose OTHER as a fallback. While the TRUE/FALSE ratings are straightfor-
ward, MIXTURE conÔ¨Çates a very large number of possible truth values, as diverse
as ‚Äúdownplayed‚Äù or ‚Äúmostly true‚Äù. For OTHER, we have rating names such as
‚Äúhalf-Ô¨Çip‚Äù, ‚Äúscam‚Äù or ‚Äúresearch in progress‚Äù.
Lifting and Serialisation. We created a Python 3.6 script to read the ex-
tracted claims as a CSV Ô¨Åle in the extraction step, and then create the corre-
sponding KG following the data model described in Sect. 4. We used the rdflib
library to create the model and an abstract RDF graph to then serialize it in
one of the many supported formats. All the caching needs of the generation pro-
cess are met with a Redis server. We generate unique URI identiÔ¨Åers as UUIDs
based on an one-way hash of key attributes for each instance. For example,
the dereferenceable URI http://data.gesis.org/claimskg/creative_work/
5f7e8c65-3d8b-57da-bab9-eb3a373bd2ab is created for the claim in https://
3 http://nlpprogress.com/english/entity_linking.html
4 We provide full correspondence tables here: https://goo.gl/Ykus98.

6
Tchechmedjiev et al.
www.snopes.com/fact-check/was-megyn-kelly-fired-from-nbc/. The tripli-
Ô¨Åcation package is made available under an open-source licence on GitHub (along
with documentation and usage examples) and will be updated regularly with the
latest improvements (link given in Table 1).
Handling simple claim coreferences. A certain number of identical claims
is present within the websites, published at diÔ¨Äerent dates, with possibly varying
reviews. For example, the same claim published at a later date than the original
publication will have an updated review. For this reason, instead of fusing these
claims, we have opted for establishing owl:sameAs links among them. We imple-
mented a simple approach to identify these claims, which aims to ensure 100%
precision of the discovered links (exact matches). We normalise the text of the
claims and the text of the claim titles only (lowercase; remove all quote charac-
ters and certain stop-words, such as ‚Äúsaid‚Äù and ‚Äúclaimed‚Äù) and then apply an
identity string similarity measure on these texts. This resulted in 38 owl:sameAs
links on claims from Snopes and 49 from Politifact.
4
The Claims Data Model
Our data model, depicted in Fig. 2, exploits terms from established vocab-
ularies, speciÔ¨Åcally schema.org, NLP Interchange Format (NIF),5 and Interna-
tionalization Tag Set (ITS).6 The selection of the vocabularies was based on the
following objectives: i) avoiding schema violations, ii) enabling data interoper-
ability through term reuse, iii) having stable identiÔ¨Åers, persistent hosting and
open license, iv) being supported by a community, v) being extensible (ability
to easily extend ClaimsKG with more data).
The core elements of our model are the claim and the claim review. To
represent them, we make use of schema.org. Following Google‚Äôs suggestion for
Web markup of claims,7 a claim is of type schema:CreativeWork and a claim
review of type schema:ClaimReview. An instance of schema:ClaimReview is
connected to an instance of schema:CreativeWork through the property sche-
ma:itemReviewed. A claim is associated with the actual text of the claim, a date
(when the claim was uttered), an author (who uttered the claim), as well as with
keywords (tags related to the claim acting as topics) and one or more citations
(URLs of related resources, e.g., a tweet or a video). Since there might be many
instances of the same claim coming from the same or diÔ¨Äerent fact-checking sites,
two claims can be connected through a owl:sameAs property.
A claim review is associated with metadata, in particular its author, its
publication date, its language, its URL (pointing to the full text of the review),
its full text (optionally, according to copyright restrictions), as well as with a
title and one or more truthfulness assessments (ratings). The assessment is of
5 https://persistence.uni-leipzig.org/nlp2rdf/ontologies/nif-core/
nif-core.html
6 https://www.w3.org/TR/its20/
7 https://developers.google.com/search/docs/data-types/factcheck

ClaimsKG: A Knowledge Graph of Fact-Checked Claims
7
	








	

	


	




	







	



	




	







 











		

		

		

	

	
			
	








	

	







 




! 

Fig. 2: The Claims data model.
	

	


	

	
	



	





	


	
	

	


		

	



 
!
"
!# "$% 


%& ' 



% 
(
) * 


% 
+,
-



% 
( 
* #.


/
0
		

		

		

	

	
			
	
		
   !	"
#		
#




# $%  












	

 !	


&
%  

(
%12
	

	


3,%
 	
	"


#	

	
	





3,%
 




%
4%   5 

 % 

% 55 

!


%
4% 


6

%
% %75 
"

Fig. 3: Instantiation of the Claims model for a claim sourced from Politifact made
by Donald Trump on June 6, 2018.

8
Tchechmedjiev et al.
type schema:Rating and is connected with the review through the property
schema:reviewRating. A rating is represented through three properties: author
(who provides the rating), rating value (a number in a pre-speciÔ¨Åed range, e.g., 1
to 5), and alternate name (a textual label of the rating value, e.g., ‚Äúfalse‚Äù). The
author property allows to provide more than one ratings for the same instance
of a claim review.
Both a claim and a claim review can be associated with one or more entity
mentions, i.e., names of entities mentioned in the short text of the claim or in
the claim review. To describe this information, we make use of the NIF and
ITS vocabularies, which provide classes and properties to describe the result of
natural language processing tools applied on texts or documents. An instance of
an entity mention is described through Ô¨Åve properties: nif:beginIndex (starting
position in the text), nif:endIndex (ending position in the text), nif:isString
(a word or sequence of words representing the entity), itsrdf:taIdentRef (the
identity of the mentioned entity), and itsrdf:taConfidence (the conÔ¨Ådence
that the entity has been disambiguated correctly). Depending on the speciÔ¨Åc
requirements with respect to precision and recall, data consumers can select
suitable conÔ¨Ådence ranges to consider when querying the data.
Fig. 3 depicts an example of a claim review by Politifact for a claim made
by Donald Trump on June 6, 2018.8 We notice that there are two instances of
schema:Rating, one for the original rating by Politifact and one for the normal-
ized rating provided by our KG. Apart from metadata information, we also see
that the review mentions the entity name ‚ÄúWhite House‚Äù, which probably (with
conÔ¨Ådence 0.9/1.0) corresponds to the oÔ¨Écial residence of the US President.
5
Use Cases and Exploitation
Use-cases and queries. The publication of structured data about a large
collection of claims allows the uncovering of explicit and implicit relations be-
tween claims, entities, and sources. A number of existing fact-checking appli-
cations rely on linking claims to fact-checked statements in a database (e.g.
https://fullfact.org/automated/, [32,35]). By combining claims and ratings
from multiple portals and providing a uniÔ¨Åed structure, ClaimsKG facilitates
these eÔ¨Äorts. Moreover, the data can be used to enable supervision of machine
learning models to support the advancement of automatic fact-checking algo-
rithms [13,20]. In addition to supplying a large number of claims, ClaimsKG en-
ables advanced, entity-centric search, exploration and information discovery, by
exploiting data from various sources via federated SPARQL queries. This allows
us, for example, to query entities belonging to a speciÔ¨Åc group (e.g., politicians
or journalists) and create complex queries using both the claims metadata and
the extracted entities. We provide diÔ¨Äerent examples on our website (see Table 1
for a link). By exploiting the claim metadata and extracted entities, we can run
complex queries that combine diÔ¨Äerent types of information. The query in Fig. 4
8 http://www.politifact.com/texas/statements/2018/jun/07/donald-trump/
donald-trump-says-people-went-out-their-boats-watc/

ClaimsKG: A Knowledge Graph of Fact-Checked Claims
9
requests all false claims of 2017 mentioning Donald Trump and Climate change.
For each claim, the query returns its text, date, as well as the URL of its review
by a fact-checking site. The query returns the following claim: Donald Trump
signed an executive order naming climate change as a threat ‚Äòboth to the economy
and national security‚Äô (2017-02-01). In a similar way, we can generate a sample
of claims based on certain criteria and use it in other tasks, e.g., for evaluation
or training by automated fact-checking approaches [13, 20]. Such a sample can
be easily produced through a concise SPARQL query over ClaimsKG.
1SELECT ?text ?date ?reviewurl WHERE {
2 ?claim a schema:CreativeWork ; schema:datePublished ?date FILTER(year(?date)=2017)
3 ?claim schema:author ?author ; schema:text ?text ; schema:mentions ?entity1, ?entity2 .
4 ?entity1 itsrdf:taIdentRef dbr:Climate_change .
5 ?entity2 itsrdf:taIdentRef dbr:Donald_Trump .
6 ?claimReview schema:itemReviewed ?claim ; schema:reviewRating ?rating ; schema:url ?reviewurl .
7 ?rating schema:author <http://data.gesis.org/claimskg/organization/claimskg> ;
8
schema:alternateName ?ratingName ;
9
schema:ratingValue ?ratingValue FILTER (?ratingValue = 1) }
Fig. 4: SPARQL query requesting false claims of 2017 mentioning both Donald
Trump and Climate change.
Going beyond the computer science domain, ClaimsKG can be a valuable
resource supporting (computational) social scientiÔ¨Åc research investigating, for
example, societal debates and agenda-setting. Agenda-setting theory refers to
the inÔ¨Çuence of mass media on the public‚Äôs focus of attention [22]. While Ô¨Årst-
level agenda-setting relates to inserting topics, events or entities into the public
discourse, thereby regulating societal priorities, second-level agenda-setting is
about increasing the salience of speciÔ¨Åc features or attributes of entities in the
discourse. This is also referred to as frame-setting. With the web evolving into
a platform where every citizen may become a publisher, express their views
and reach out to a large audience, citizens are now able to play a more active
role in inÔ¨Çuencing the public discourse [3]. Online debates about political issues
typically exhibit the pattern of a few dominant ideological positions emerging,
with diÔ¨Äerent groups expressing diÔ¨Äerent viewpoints and often referring to a
disparate set of information sources [24] which, in turn, may focus on diÔ¨Äerent
attributes and frames for a given topic. Using ClaimsKG, an exploratory search
on a topic and related entities may be performed in order to gain insights on
relevant viewpoints, attributes and actors. Also, the KG allows the tracking of
diÔ¨Äerences over time and in relation to speciÔ¨Åc events, and the relation of views
of speciÔ¨Åc actors to ideological positions.
To illustrate, consider the 2012 incident of the neighbourhood watch coor-
dinator George Zimmerman shooting 17-year-old African-American high school
student Trayvon Martin, the incident that later gave rise to the Black Lives
Matter movement [15]. The query given in Fig. 5 retrieves all claims mention-
ing Trayvon Martin or George Zimmerman, yielding 68 claims in total with 8
claims rated true, 33 false, and 24 mixture. The distribution of truth values
hints at this being a highly controversial topic with potentially highly polarized
viewpoints. Central to the debate is the aspect of racism; some framing the in-

10
Tchechmedjiev et al.
cident as an example of racist violence against black people,9 some seeing race
as an overemphasized point in the Zimmerman trial10, and others framing the
Black Lives Matter debate as racist against white people.11 An entity frequently
mentioned in these claims is the ‚Äústand your ground‚Äù law. The query in Fig.
6 retrieves other entities connected to it revealing a strong association to the
Trayvon Martin case.
1SELECT ?text ?reviewurl ?rating WHERE {
2
?claim a schema:CreativeWork ; schema:text ?text ; schema:mentions ?entity1 .
3
?entity1 itsrdf:taIdentRef ?entity2Uri
4
FILTER (?entity2Uri IN (dbr:Trayvon_Martin, dbr:George_Zimmerman))
5
?claimReview schema:itemReviewed ?claim ; schema:reviewRating ?rating ; schema:url ?reviewurl }
Fig. 5: SPARQL query requesting all claims mentioning Trayvon Martin or
George Zimmerman.
1SELECT ?entityUri WHERE {
2
?claim a schema:CreativeWork ; schema:mentions ?entity1, ?entity2 .
3
?entity1 itsrdf:taIdentRef dbr:Stand-your-ground_law .
4
?entity2 itsrdf:taIdentRef ?entityUri FILTER (?entityUri != dbr:Stand-your-ground_law) }
Fig. 6: SPARQL query requesting entities mentioned in claims together with
Stand your ground law.
1SELECT year(?date) as ?year count(?claim) as ?num WHERE {
2
?claim a schema:CreativeWork ; schema:datePublished ?date FILTER(year(?date)>=2012)
3
?claim schema:author ?author ; schema:text ?text ; schema:mentions ?entity .
4
?entity itsrdf:taIdentRef dbr:Black_Lives_Matter } GROUP BY year(?date) ORDER BY year(?date)
Fig. 7: SPARQL query requesting the number of claims mentioning Black Lives
Matter by year.
The query in Fig. 7 illustrates the tracking of changes over time and the
discovery of important events. While for 2015, 2017, 2018 and 2019 maximum
three claims per year mentioning the entity Black Lives Matter are found, there
is a striking peak in 2016 with 17 mentions. This aligns with the incident of
law enforcement oÔ¨Écers being shot during a Black Lives Matter protest march
in July 2016 which reopened a heated debate about the movement. In fact,
analysis of the respective claims reveals the emergence of frames attributing
violent and disruptive behaviour to the Black Lives Matter movement.12 Note
that the discussed scenarios represent only starting points for initiating further
analyses.
9 https://www.politifact.com/florida/statements/2013/jul/24/
jesse-jackson/homicides-blacks-have-tripled-stand-your-ground-wa/
10 https://www.politifact.com/florida/statements/2013/jul/17/tweets/
look-statistic-blacks-and-murder/
11 https://www.snopes.com/fact-check/keith-passmore-murder/
12 https://www.politifact.com/wisconsin/statements/2016/dec/02/
sean-duffy/donald-trump-backer-sean-duffy-links-attacks-polic/,
https://www.politifact.com/wisconsin/statements/2017/apr/17/
sheriff-david-clarke-us-senate/pro-sheriff-david-clarke-group-says-clarke-called-/

ClaimsKG: A Knowledge Graph of Fact-Checked Claims
11
ClaimsKG Explorer. In order to facilitate data access for researchers from
outside of the computer science domain, like journalists and sociologists, we pro-
vide ClaimsKG Explorer (link in Table 1), a user-friendly, Web-based interface
to query and explore ClaimsKG. The application sends HTTP requests to the
ClaimsKG SPARQL endpoint and provides information through a Web user
interface. The users are given the possibility to Ô¨Ålter their search space with re-
spect to a number of facets (Fig. 8a): entities contained in the text of the claim
or its review, keywords (topics related to the claims), truth ratings (the nor-
malised ones), time frame of interest, authors of claims, sources (fact-checking
websites), and languages (currently only English; work in progress will incorpo-
rate non-English websites). After clicking on the CLAIMS SEARCH button, the
user is provided a list of clickable claims ordered by their date of publication
(most recent ones on top), as shown in Fig. 8b. The search result corresponding
to the selected criteria can be exported as a CSV or an RDF Ô¨Åle and reused
in a particular scenario by clicking on the EXPORT button on the results page.
Finally, cicking on a particular claim, the user can access all the information
related to that claim, like the review article, the entities mentioned in the claim
or the review text, the references, and the keywords.
(a) The Explorer‚Äôs search engine.
(b) Results
Fig. 8: The ClaimsKG Explorer user interface
6
Related Work
As outlined above, ground truth data in the form of labelled and contextu-
alised claims is necessary for a number of interdisciplinary research problems.
Among the most prominent use-case scenarios is the task of automatic fact-
checking, which has been of growing interest for the AI community. A number
of approaches have been proposed to extract check-worthy pieces of informa-
tion from text [12] and to further assess their veracity automatically [31]. The
majority of these approaches can be classiÔ¨Åed either as reference or machine

12
Tchechmedjiev et al.
learning approaches. The former model claims computationally to achieve struc-
tured representations [4,23,29,32,35], allowing for their comparison to certiÔ¨Åed
facts contained in knowledge bases or for the application of graph mining tech-
niques on these bases. The latter rely on data in the form of labelled claims in
order to train and apply machine learning models. The current section provides
an overview of datasets for training and/or evaluation covering these two fami-
lies of approaches. We categorise these datasets according to the process of their
collection.
Extracting gold standard from web sources. Alongside ClaimsKG, a num-
ber of approaches rely on extracting data from fact-checking websites, allowing
the collection of large number of claims together with veracity annotations of
high quality that stem from serious journalistic work. One of the Ô¨Årst initiatives
in that Ô¨Åeld is introduced in [28]. The data extraction process is manual, result-
ing in merely 221 statements collected from Channel 4 and PolitiFact. Since the
two sources do not apply the same rating scale, similarly to our approach, the
authors map the two respective sets of labels to a common scale consisting of
Ô¨Åve categories: ‚Äútrue‚Äù, ‚Äúmostly true‚Äù, ‚Äúhalf true‚Äù, ‚Äúmostly false‚Äù and ‚Äúfalse‚Äù.
The Liar benchmark [33] collects 12.8K Politifact claims over 10 years. Addi-
tional information is stored regarding the speaker, the context, the label and
the justiÔ¨Åcation. The fact-checking approach presented in [21] relies on a data
set of approximately 10K claims, also crawled from Politifact in 2016, while [16]
and [20] have collected, respectively, 1K and 5K claims from Snopes. Wikipedia‚Äôs
lists of proven hoaxes13 and Ô¨Åctitious people14 have been used in [19,20] in order
to generate ground truth labels, resulting in 157 claims labelled as ‚Äúfake‚Äù. In
parallel, the authors also collect around 4.8K labelled claims from Snopes, pub-
lished before Faburary 2016. The Clef-2018 challenge includes the fact-checking
task Check that! [2]. The benchmark data (150 claims) consists of sentences col-
lected from debates from the 2016 US Presidential Election Campaign, as well
as from other political speeches during and after the campaign. Evaluations are
obtained from FactCheck.org articles resulting in labels of the kind ‚Äúfactually
true‚Äù, ‚Äúhalf-true‚Äù, or ‚Äúfalse‚Äù.
The Emergent data set15 results from collecting claims from various web
sources, such as Politifact, Snopes and Twitter accounts such as @Hoaxalizer,
particularly dedicated to rumors and hoaxes [9]. The data set contains 300 claims
with three types of annotations (‚Äútrue‚Äù, ‚Äúfalse‚Äù, ‚ÄúunveriÔ¨Åed‚Äù) provided by jour-
nalists. A large scale collection of tweet news (126K stories) labelled on the ba-
sis of signiÔ¨Åcant degree of agreement among several fact-checking sites (Snopes,
Politifact, Factcheck, Truth-or-Fiction, Hoax-slayer and Urbanlegends) is used
in [31]. As a result, a sample of news stories assigned one of three possible labels
(‚Äútrue‚Äù, ‚Äúfalse‚Äù or ‚Äúmixed‚Äù) is created. However, the data is only available upon
request for the purposes of reproducing the reported experiments.
13 https://en.wikipedia.org/wiki/Listofhoaxes#Provenhoaxes
14 https://en.wikipedia.org/wiki/List_of_fictitious_people
15 http://www.emergent.info

ClaimsKG: A Knowledge Graph of Fact-Checked Claims
13
Crowdsourced or manually annotated data sets. Crowdsourcing tech-
niques allow for the extraction and labelling of relatively large sets of claims, al-
though some care should be taken to ensure the reliability of the data harvested.
The Open Domain Deception Dataset contains ‚Äúfreely contributed truths and
lies‚Äù [18]. By using the Amazon Mechanical Turk, each worker has been asked to
freely formulate seven one-sentence truths and lies. After cleansing the collection,
the Ô¨Ånal dataset consists of 7.2K sentences provided by 512 unique contributors,
for whom demographic data is also collected and made available. The SemEval‚Äô17
challenge dataset contains 5.5K crowdsourced annotated claims [11], while the
FEVER dataset, with 185K entries, extracts claims from Wikipedia. Semantics-
preserving sentence altering techniques are then applied and the resulting claims
are annotated by the crowd [25]. Finally, the approach in [17] relies on a dataset
of 250 manually annotated claims.
Automatic annotations. Fact veriÔ¨Åcation methods can be applied in order to
construct automatically ground truth datasets for fact-checking. An example is
the fake-news dataset,16 containing text and metadata scraped from 244 websites
that have been identiÔ¨Åed as untrustworthy by the BS Detector Chrome Extension
tool.17 This approach has the risk that the imperfections of the veriÔ¨Åcation
system are propagated onto the annotated data.
Knowledge graphs for fact-checking. Finally, we focus on KGs that have
been used in a number of fact veriÔ¨Åcation approaches from the reference group.
Usually, a statement is modelled as a triple and is veriÔ¨Åed on the basis of prop-
erties of the paths involving elements of that triple in existing KGs, considered
as ground truth, such as DBpedia [4, 10, 23]. The Knowledge Vault [6] and the
KnowMore [37] resources, or the Voldemort KG [26], rely on structured markup
annotations in order to match them to established KGs or perform graph com-
pletion. This process implies the veriÔ¨Åcation of the truthfulness of statements
and the production of reliable factual information that can be used as ground
truth.
Positioning. ClaimsKG is entirely based on data from a number of established
fact-checking websites and therefore falls into the Ô¨Årst category of datasets pre-
sented above. With its more than 28K claims, it is, to our knowledge, the largest
resource of structured fact-checking information so far made available but also
one archiving the largest spectrum of metadata categories. The open-source tools
for its regeneration and update that we provide will allow for it to grow in size
over time. In contrast to existing approaches, we model claims by the help of an
RDF/S data model speciÔ¨Åcally designed for that purpose, fostering re-usability
and extensibility. As compared to KG-based reference approaches, by dynam-
ically collecting data from fact-checking websites, we focus on information of
particular interest for the veriÔ¨Åcation of newly emerging statements that are
not available in Wikipedia or established KGs. ClaimsKG can be used as both
training and evaluation data, allowing users (researchers in computer science or
16 https://www.kaggle.com/mrisdal/fake-news
17 http://bsdetector.tech

14
Tchechmedjiev et al.
computational sociology, for example) to compile thematic samples of it with the
help of structured queries, or by using the web application (cf. Sect. 5). Beyond
the purposes of fact-checking, this is expected to foster research and data-driven
studies in diÔ¨Äerent areas of social and computational social science, as discussed
in our use-case scenarios.
7
Conclusion and Future Work
We have introduced ClaimsKG, a knowledge graph of fact-checked claims,
which facilitates structured queries of related metadata, such as their truth val-
ues, authors or time of release. ClaimsKG is generated through a semi-automated
pipeline, which harvests data from popular fact-checking sites on a regular ba-
sis, lifts data into a speciÔ¨Åcally developed for that purpose model, and annotates
claims with related entities from DBpedia. The KG is expected to provide sup-
port to research in the areas of fact-checking, stance detection and multiple
topics related to the analysis of societal debates, where a quality ground truth
of labelled claims is required in order to facilitate supervision, validation or re-
producibility of research methods.
There are several limitations of the current KG that are the focus of on-
going and short-term eÔ¨Äorts. The development of an advanced claim matching
approach and its evaluation is among them. We are working on building a gold-
standard dataset of claim-pairs, annotated with respect to diÔ¨Äerent relatedness
categories, in order to evaluate the process and to provide training data to Ô¨Åne-
tune state-of-the-art deep language modelling approaches such as BERT [5] to
our matching task. We also intend to extend the content of our graph to other
fact-checking websites and languages, enabling multi- and cross-lingual infor-
mation retrieval and approaches for fact veriÔ¨Åcation. With respect to augment-
ing ClaimsKG with additional claims, we also intend to harvest semi-structured
schema.org markup of claims from Web pages by exploiting data fusion pipelines
developed as part of prior work [36]. Regarding the exploratory Web interface,
in the future we aim to support the execution of federated queries that inte-
grate information from external KGs like DBpedia, as well as the inclusion of
a statistical observatory allowing us to extract distributions and correlations of
diÔ¨Äerent entities, topics and claims.
Acknowledgements
We thank Vinicius Woloszyn for providing support on the Ô¨Årst step of the
pipeline (claim extraction), as well as Josselin Alezot, Imran Meghazi and Elisa
Gueneau for their work on the Web interface. We thank all fact-checking sites and
the fact-checkers community for the laborious work of manual claim veriÔ¨Åcation.
References
1. Allcott, H., Gentzkow, M.: Social media and fake news in the 2016 election. Journal
of Economic Perspectives 31(2), 211‚Äì36 (2017)

ClaimsKG: A Knowledge Graph of Fact-Checked Claims
15
2. Barr¬¥on-CedeÀúno, A., Elsayed, T., Suwaileh, R., M`arquez, L., Atanasova, P., Za-
ghouani, W., Kyuchukov, S., Da San Martino, G., Nakov, P.: Overview of the
clef-2018 checkthat! lab on automatic identiÔ¨Åcation and veriÔ¨Åcation of political
claims, task 2: Factuality. In: CLEF. CEUR-WS (2018)
3. Bennett, W.L., Pfetsch, B.: Rethinking Political Communication in a Time
of Disrupted Public Spheres. J. of Communication 68(2), 243‚Äì253 (04 2018).
https://doi.org/10.1093/joc/jqx017, https://doi.org/10.1093/joc/jqx017
4. Ciampaglia, G.L., Shiralkar, P., Rocha, L.M., Bollen, J., Menczer, F., Flammini,
A.: Computational fact checking from knowledge networks. PloS one (2015)
5. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: Pre-training of Deep
Bidirectional Transformers for Language Understanding. ArXiv e-prints, cs.CL
1810.04805 (2018)
6. Dong, X., Gabrilovich, E., Heitz, G., Horn, W., Lao, N., Murphy, K., Strohmann,
T., Sun, S., Zhang, W.: Knowledge vault: A web-scale approach to probabilistic
knowledge fusion. In: ACM SIGKDD. pp. 601‚Äì610. ACM (2014)
7. Esteves, D., Reddy, A.J., Chawla, P., Lehmann, J.: Belittling the source: Trust-
worthiness indicators to obfuscate fake news on the web. In: 1st Workshop on Fact
Extraction and VERiÔ¨Åcation (FEVER). pp. 50‚Äì59 (2018)
8. Ferragina, P., Scaiella, U.: Tagme: On-the-Ô¨Çy annotation of short text fragments
(by wikipedia entities). In: ACM ICIKM. pp. 1625‚Äì1628. ACM (2010)
9. Ferreira, W., Vlachos, A.: Emergent: a novel data-set for stance classiÔ¨Åcation. In:
NAACL-HLT. pp. 1163‚Äì1168 (2016)
10. Gerber, D., Esteves, D., Lehmann, J., B¬®uhmann, L., Usbeck, R., Ngomo, A.C.N.,
Speck, R.: Defactotemporal and multilingual deep fact validation. Web Semantics:
Science, Services and Agents on the World Wide Web 35, 85‚Äì101 (2015)
11. Gorrell, G., Bontcheva, K., Derczynski, L., Kochkina, E., Liakata, M., Zubiaga, A.:
Rumoureval 2019: Determining rumour veracity and support for rumours. Semantic
Evaluation pp. 60‚Äì67 (2017)
12. Hassan, N., Adair, B., Hamilton, J.T., Li, C., Tremayne, M., Yang, J., Yu, C.: The
quest to automate fact-checking. world (2015)
13. Hassan, N., Arslan, F., Li, C., Tremayne, M.: Toward automated fact-checking:
Detecting check-worthy factual claims by claimbuster. In: ACM SIGKDD. pp.
1803‚Äì1812. ACM (2017)
14. HoÔ¨Äart, J., Yosef, M.A., Bordino, I., F¬®urstenau, H., Pinkal, M., Spaniol, M.,
Taneva, B., Thater, S., Weikum, G.: Robust disambiguation of named entities
in text. In: EMNLP. pp. 782‚Äì792. ACL, Stroudsburg, PA, USA (2011), http:
//dl.acm.org/citation.cfm?id=2145432.2145521
15. Hon,
L.:
Social
media
framing
within
the
million
hoodies
movement
for
justice.
Public
Relations
Review
42
(12
2015).
https://doi.org/10.1016/j.pubrev.2015.11.013
16. Ma, J., Gao, W., Mitra, P., Kwon, S., Jansen, B.J., Wong, K.F., Cha, M.: Detecting
rumors from microblogs with recurrent neural networks. In: IJCAI. pp. 3818‚Äì3824
(2016)
17. Mihaylova, T., Nakov, P., Marquez, L., Barron-Cedeno, A., Mohtarami, M.,
Karadzhov, G., Glass, J.: Fact checking in community forums. AAAI pp. 879‚Äì886
(2018)
18. P¬¥erez-Rosas, V., Mihalcea, R.: Experiments in open domain deception detection.
In: CEMNLP. pp. 1120‚Äì1125 (2015)
19. Popat, K., Mukherjee, S., Str¬®otgen, J., Weikum, G.: Credibility assessment of tex-
tual claims on the web. In: ACM ICIKM. pp. 2173‚Äì2178. ACM (2016)

16
Tchechmedjiev et al.
20. Popat, K., Mukherjee, S., Str¬®otgen, J., Weikum, G.: Where the truth lies: Explain-
ing the credibility of emerging claims on the web and social media. In: WWW. pp.
1003‚Äì1012 (2017)
21. Rashkin, H., Choi, E., Jang, J.Y., Volkova, S., Choi, Y.: Truth of varying shades:
Analyzing language in fake news and political fact-checking. In: EMNLP. pp. 2931‚Äì
2937 (2017)
22. Scheufele, D.A.: Agenda-setting, priming, and framing revisited: Another look at
cognitive eÔ¨Äects of political communication. Mass Communication and Society
3(2-3), 297‚Äì316 (2000). https://doi.org/10.1207/S15327825MCS0323 07, https:
//doi.org/10.1207/S15327825MCS0323_07
23. Shiralkar, P., Flammini, A., Menczer, F., Ciampaglia, G.L.: Finding streams in
knowledge graphs to support fact checking. In: ICDM. pp. 859‚Äì864. IEEE (2017)
24. Smith, M., Shneiderman, B., Rainie, L., Himelboim, I.: Mapping twitter topic
networks: From polarized crowds to community clusters (02 2014)
25. Thorne, J., Vlachos, A., Christodoulopoulos, C., Mittal, A.: Fever: a large-scale
dataset for fact extraction and veriÔ¨Åcation. NAACL-HLT pp. 809‚Äì819 (2018)
26. Tonon, A., Felder, V., Difallah, D.E., Cudr¬¥e-Mauroux, P.: Voldemortkg: Mapping
schema. org and web entities to linked open data. In: ISWC. pp. 220‚Äì228. Springer
(2016)
27. Tschiatschek, S., Singla, A., Gomez Rodriguez, M., Merchant, A., Krause, A.: Fake
news detection in social networks via crowd signals. In: WWW. pp. 517‚Äì524 (2018)
28. Vlachos, A., Riedel, S.: Fact checking: Task deÔ¨Ånition and dataset construction.
In: Language Technologies and Comp. Social Science. pp. 18‚Äì22 (2014)
29. Vlachos, A., Riedel, S.: IdentiÔ¨Åcation and veriÔ¨Åcation of simple claims about sta-
tistical properties. In: CEMNLP. pp. 2596‚Äì2601. ACL (2015)
30. Vosoughi, S., Roy, D., Aral, S.: The spread of true and false news online. Science
359(6380), 1146‚Äì1151 (2018)
31. Vosoughi, S., Roy, D., Aral, S.: The spread of true and false news online. Science
359(6380), 1146‚Äì1151 (2018)
32. Walenz, B., Wu, Y., Song, S., Sonmez, E., Wu, E., Wu, K., Agarwal, P.K., Yang,
J., Hassan, N., Sultana, A., et al.: Finding, monitoring, and checking claims com-
putationally based on structured data. In: Computation+Journalism (2014)
33. Wang, W.Y.: Liar, liar pants on Ô¨Åre: A new benchmark dataset for fake news
detection. AMACL pp. 422‚Äì426 (2017)
34. Wang, X., Yu, C., Baumgartner, S., Korn, F.: Relevant document discovery for
fact-checking articles. In: WWW. pp. 525‚Äì533 (2018)
35. Wu, Y., Agarwal, P.K., Li, C., Yang, J., Yu, C.: Toward computational fact-
checking. Proceedings of the VLDB Endowment 7(7), 589‚Äì600 (2014)
36. Yu, R., Gadiraju, U., Fetahu, B., Lehmberg, O., Ritze, D., Dietze, S.: Know-
more knowledge base augmentation with structured web markup. Semantic Web
Journal, IOS Press (2019), http://www.semantic-web-journal.net/content/
knowmore-knowledge-base-augmentation-structured-web-markup-1
37. Yua, R., Gadirajua, U., Fetahua, B., Lehmbergb, O., Ritzeb, D., Dietzea, S.:
Knowmore-knowledge base augmentation with structured web markup. Semantic
Web J., IOS Press (2017)

