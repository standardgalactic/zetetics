

Mathematical Logic 
A Course with Exercises 
Part 1: Propositional calculus, 
Boolean algebras, Predicate calculus 
Rene Cori and Daniel Lascar 
Equipe de Logique Mathematique 
Universite Paris VII 
Translated by 
Donald H. Pelletier 
York University, Toronto 
OXFORD 
UNIVERSITY PRESS 


Mathematical Logic 
A Course with Exercises 

This book has been printed digitally and produced in a standard specification 
in order to ensure its continuing availability 
OXFORD 
UNIVERSITY PRESS 
Great Clarendon Street, Oxford OX2 6DP 
Oxford University Press is a departinent of the University of Oxford. 
It furthers the University's objective of excellence in research, scholarship, 
and education by publishing worldwide in 
Oxford New York 
Auckland Bangkok Buenos Aires Cape Town Chennai 
Dar es Salaan1 Delhi Hong Kong Istanbul Karachi Kolkata 
Kuala Ltnnpur Madrid Melboun1e Mexico City Mtunbai Nairobi 
Sao Paulo Shanghai Singapore Taipei Tokyo Toronto 
Oxford is a registered trade 1nark of Oxford University Press 
in the UK and in certain other countries 
Published in the United States 
by Oxford University Press Inc., New York 
This English Edition © Oxford University Press 2000 
Published with the help of the Ministere de la Culture 
First published in French as Logique mathematique 
© Masson, Editeur, Paris, 1993 
The n1oral rights of the author have been asserted 
Database right Oxford University Press (1naker) 
Reprinted 2002 
All rights reserved. No part of this publication 1nay be reproduced, 
stored in a retrieval systen1, or trans1nitted, in any fonn or by any 1neans, 
without the prior pennission in writing of Oxford University Press. 
or as expressly pennitted by law, or under tenns agreed with the appropriate 
reprographics rights organization. Enquiries concerning reproduction 
outside the scope of the above should be sent to the Rights Depart1nent, 
Oxford University Press, at the address above 
You n1ust not circulate this book in any other binding or cover 
and you n1ust i1npose this sa1ne condition on any acquirer 
ISBN 0-19-850049-1 

Foreword to the Original French edition 
----·-··- ·-· 
Jean-Louis Krivine 
In France, the discipline of logic has traditionally been ignored in university-level 
scientific studies. This follows, undoubtedly, from the recent history of mathe­
matics in our country which was dominated, for a long while, by the Bourbaki 
school for whom logic was not, as we know, a strong point. Indeed, logic origi­
nates from reflecting upon mathematical activity and the common gut-reaction of 
the mathematician is to ask: 'What is all that good for? We are not philosophers 
and it is surely not by cracking our skulls over modus ponens or the excluded 
middle that we will resolve the great conjectures, or even the tiny ones . . .  ' Not 
so fast! 
A new ingredient, of some substance, has come to settle this somewhat byzantine 
debate over the importance of logic: the explosion of computing into all areas of 
economic and scientific life, whose shock wave finally reached the mathematicians 
themselves. 
And, little by little, one fact dawns on us: the theoretical basis for this nascent 
science is nothing other than the subject of all this debate, mathematical logic. 
It is true that certain areas of logic were put to use more quickly than oth­
ers. Boolean algebra, of course, for the notions and study of circuits; recursive­
ness, which is the study of functions that are computable by machine; Her brand's 
theorem, resolution and unification, which form the basis of 'logic programming' 
(the language PROLOG); proof theory, and the diverse incarnations of the Com­
pleteness theorem, which have proven themselves to be powerful analytical tools 
for mature programming languages. 
But, at the rate at which things are going, we can imagine that even those areas 
that have remained completely 'pure', such as set theory, for example, will soon 
see their turn arrive. 
As it ought to be, the interaction is not one-way, far from it; a flow of ideas and 
new, deep intuitions, arising from computer science, has come to animate all these 
sectors of logic. This discipline is now one of the liveliest there is in mathematics 
and it is evolving very rapidly. 
So there is no doubt about the utility and timeliness of a work devoted to a 
general introduction to logic; this book meets its destiny. Derived from lectures 
for the Dipl6me d'Etudes Approfondies (DEA) of Logic and the Foundations 
of c:omputing at the University of Paris VII, it covers a vast panorama: Boolean 

. 
Vl 
F O R EWO R D  T O  TH E O RIGI N A L  F R E N C H  E DIT I O N  
algebras, recursiveness, model theory, set theory, models of arithmetic and Godel's 
theorems. 
The concept of model is at the core of this book, and for a very good reason 
since it occupies a central place in logic: despite (or thanks to) its simple, and even 
elementary, character, it illuminates all areas, even those that seem farthest from 
it How, for exampleਗ਼ can one understand a consistency proof in set theory without 
first mastering the concept of being a model of this theory? How can one truly 
grasp Godel 's theorems without having some notion of non-standard models of 
Peano arithmetic? The acquisition of these semantic notions is, I believe, the mark 
of a proper training for a logician, at whatever level. R. Cori and D. Lascar know 
this well and their text proceeds from beginning to end in this direction. Moreover, 
they have overcome the risky challenge of blending all the necessary rigour with 
clarity, pedagogical concern and refreshing readability. 
We have here at our disposal a remarkable tool for teaching mathematical logic 
and, in view of the growth in demand for this subject area, it should meet with a 
marked success. This is, naturally, everything I wish for it. 

Foreword to the English edition 
Wilfrid Hodges 
School of Mathematical Sciences 
Queen Mary and Wes{field College 
University of London 
There are two kinds of introduction to a subject. The first kind assumes that you 
know nothing about the subject, and it tries to show you in broad brushstrokes 
why the subject is worth studying and what its achievements are. The second kind 
of introduction takes for granted that you know what the subject is about and 
why you want to study it, and sets out to give you a reliable understanding of the 
basics. Rene Cori and Daniel Lascar have written the second sort of introduction 
to mathematical logic. The mark of the book is thoroughness and precision with a 
light touch and no pedantry. 
The volume in your hand, Part I, is a mathematical introduction to first-order 
logic. This has been the staple diet of elementary logic courses for the last fifty 
years, but the treatment here is deeper and more thorough than most elementary 
logic courses. For example the authors prove the compactness theorem in a general 
form that needs Zorn's Lemma. You certainly shouldn't delay reading it until you 
know about Zorn's Lemma- the applications here are an excellent way of learning 
how to use the lemma. In Part I there are not too many excitements - probably the 
most exciting topic in the book is the Godel theory in Chapter 6 of Part II, unless 
you share my enthusiasm for the model theory in Chapter 8. But there are plenty of 
beautiful explanations, put together with the clarity and elegance that one expects 
from the best French authors. 
For English students the book is probably best suited to Masters' or fourth-year 
undergraduate studies. The authors have included full solutions to the exercises; 
this is one of the best ways that an author can check the adequacy of the definitions 
and lemmas in the text, but it is also a great kindness to people who are studying 
on their own, as a beginning research student may be. Some thirty-five years ago 
I found I needed to teach myself logic, and this book would have fitted my needs 
exactly. Of course the subject has moved on since then, and the authors have 
included several things that were unknown when 1 was a student. For example 
their chapter on proof theory, Chapter 4 in this volume, includes a well-integrated 
section on the resolution calculus. They mention the connection with PROLOG; 
but in fact you can also use this section as an introduction to the larger topic 

Vlll 
F O R E W O R D  T O  THE E NGL I SH E D I T I O N  
of unification and pattern-matching, which has wide ramifications in computer 
. 
science. 
One other thing you should know. This book comes from the famous Equipe de 
Logique Mathematique at the University of Paris, a research team that has had an 
enormous inft uence on the development of mathematical logic and its links with 
other branches of mathematics. Read it with confidence. 

Preface 
This book is based upon several years' experience teaching logic at the UFR of 
Mathematics of the University of Paris 7, at the beginning graduate level as well 
as within the DEA of Logic and the Foundations of Computer Science. 
As soon as we began to prepare our first lectures, we realized that it was going 
to be very difficult to introduce our students to general works about logic written 
in (or even translated into) French. We therefore decided to take advantage of this 
opportunity to correct the situation. Thus the first versions of the eight chapters 
that you are about to read were drafted at the same time that their content was being 
taught. We insist on warmly thanking all the students who contributed thereby to 
a tangible improvement of the initial presentation. 
Our thanks also go to all our colleagues and logician friends, from Paris 7 and 
elsewhere, who brought us much appreciated help in the form of many comments 
and moral support of a rare quality. Nearly all of them are co-authors of this work 
since, to assemble the lists of exercises that accompany each chapter, we have 
borrowed unashamedly from the invaluable resource that comprises the hundreds 
and hundreds of pages of written material that were handed out to students over 
the course of more than twenty-five years during which the University of Paris 7, 
a pioneer in this matter, has organized courses in logic open to a wide public. 
At this point, the reader generally expects a phrase of the following type: 'they 
are so numerous that we are obviously unable to name them all'. It is true, there 
are very many to whom we extend our gratitude, but why shouldn't we attempt to 
name them all? 
Thank you therefore to Josette Adda, Marouan Ajlani, Daniel Andler, 
Gilles Amiot, Fred Appenzeller, Jean-Claude Archer, Jean-Pierre Azra, Jean­
Pierre Benejam, Chantal Berline, Claude-Laurent Bernard, Georges Blanc, 
Elisabeth Bouscaren, Albert Burroni, Jean-Pierre Calais, Zoe Chatzidakis, 
Peter Clote, Fran<;ois Conduche, Jean Coret, Maryvonne Daguenet, Vincent 
Danos, Max Dickmann, Patrick Dehornoy, Fran<;oise Delon, Florence Duchene, 
Jean- Louis Duret, Marie-Christine Ferbus, Jean-Yves Girard, Daniele Gondard, 
CatherineGourion, SergeGrigorieff, Ursula Gropp, Philippelthier, BernardJaulin, 
Ying Jiang, Anatole Khelif, Georg Kreisel, Jean-Louis Krivine, Ramez Labib­
Sami, Daniel Lacombe, Thierry Lacoste, Richard Lassaigne, Yves Legrandgerard, 
Alain Louveau, Franਜ਼ois Lucas, Kenneth MacAloon, Gilles Macario-Rat, Sophie 
Malecki, Jean Malifaud, Pascal Manoury, Franc;ois Metayer, Marie-Helene 
Mourgues, Catherine Muhlrad-Greif, Francis Oger, Michel Parigot, Donald 

X 
P R EFACE 
Pelletier, Marie-Jeanne Perrin, Bruno Poizat, Jean Porte, Claude Pnੜcetti, 
Christophe Raffalli, Laurent Regnier, Jean-Pierre Ressayre, Iegor Reznikoff, 
Philippe Royer, Paul Roziere, Gabriel Sabbagh, Claire Santoni, Marianne Simonot, 
Gerald Stahl, Jacques Stern, Anne Strauss, Claude Sureson, Jacques Van de Wiele, 
Franc;oise Ville. 
We wish also to pay homage to the administrative and technical work accom­
plished by Mesdames Sylviane Barrier, Gisele Goeminne, and Claude Orieux. 
May those whom we have forgotten forgive us. They are so numerous that we 
are unable to name them all. 
September 1993 
The typographical errors in the first printing were so numerous that even Alain 
Kapur was unable to locate them all. May he be assured of all our encouragement 
for the onerous task that still awaits him. 
We also thank Edouard Dorard and Thierry Joly for their very careful reading. 

Contents 
---------------------------------
Contents of Part II 
. 
XIV 
Notes from the translator 
. 
XVI 
Notes to the reader 
. . 
xvu 
Introduction 
] 
1 
Propositional calculus 
7 
1.1 
Syntax 
8 
1 . 1 . 1  Propositional formulas 
8 
1 . 1  .2 
Proofs by induction on the set of formulas 
1 1 
1. 1.3 The decomposition tree of a formula 
13 
1.1.4 
The unique decomposition theorem 
15 
1.1.5 
Definitions by induction on the set of formulas 
18 
1.1.6 
Substitutions in a propositional formula 
19 
1.2 
Semantics 
21 
1.2.1 
Assignments of truth values and truth tables 
21 
1 .2.2 Tautologies and logically equivalent formulas 
27 
1.2.3 Some tautologies 
31 
1.3 
Normal forms and complete sets of connectives 
34 
1.3.1 Operations on {0 
.. 1} and formulas 
34 
1 .3.2 Normal forms 
38 
1.3.3 Complete sets of connectives 
40 
1.4 
The interpolation lemma 
42 
1.4.1 
Interpolation lemma 
42 
1.4.2 
The definability theorem 
44 
1.5 
The compactness theorem 
45 
1 .5.1 
Satisfaction of a set of formulas 
45 
1 .5.2 
The compactness theorem for propositional calculus 
48 
1.6 
Exercises for Chapter I 
53 
2 
Boolean algebras 
63 
2.1 
Algebra and topology review 
64 
2.1.1 Algebra 
64 
2.1.2 
Topology 
67 
2.1.3 
An application to propositiona1 calculus 
71 
2.2 
Definition of Boolean algebra 
71 
2.2.1 
Properties of Boolean algebras, order relations 
72 

Xll 
CONTENTS 
2.2.2 Boolean algebras as ordered sets 
75 
2.3 
Atoms in a Boolean algebra 
79 
2.4 
Homomorphisms, isomorphisms, subalgebras 
81 
2.4.1 
Homomorphisms and isomorphisms 
81 
2.4.2 
Boolean subalgebras 
86 
2.5 
Ideals and filters 
88 
2.5.1 
Properties of ideals 
88 
2.5.2 
Maximal ideals 
91 
2.5.3 Filters 
93 
2.5.4 Ultrafilters 
94 
2.5.5 
Filter bases 
96 
2.6 
Stone's theorem 
97 
2.6.1 The Stone space of a Boolean algebra 
98 
2.6.2 Stone's theorem 
102 
2.6.3 
Boolean spaces are Stone spaces 
102 
2.7 
Exercises for Chapter 2 
106 
3 
Predicate calculus 
112 
3.1 
Syntax 
113 
3.1.1 
First order languages 
113 
3.1.2 Terms of the language 
115 
3.1.3 Substitutions in terms 
121 
3.1.4 Formulas of the language 
122 
3.1.5 
Free variables, bound variables, and closed formulas 
125 
3.1.6 Substitutions in formulas 
127 
3.2 
Structures 
130 
3.2.1 
Models of a language 
131 
3.2.2 Substructures and restrictions 
133 
3.2.3 Homomorphisms and isomorphisms 
135 
3.3 
Satisfaction of formulas in structures 
137 
3.3.1 
Interpretation in a structure of the terms 
137 
3.3.2 Satisfaction of the formulas in a structure 
140 
3.4 
Universal equivalence and semantic consequence 
147 
3.5 
Prenex forms and Skolem forms 
157 
3.5.1 
Prenex forms 
157 
3.5.2 Skolem forms 
160 
3.6 
First steps in model theory 
165 
3.6. 1 
Satisfaction in a substructure 
165 
3.6.2 Elementary equivalence 
170 
3.6.3 The language associated with a structure and formulas 
with parameters 
174 
3.6.4 Functions and relations definable in a structure 
176 

CONTENTS 
3. 7 
Models that may not respect equality 
3.8 
Exercises for Chapter 3 
Xlll 
179 
1 82 
4 
The completeness theorems 
193 
4.1 
Formal proofs (or derivations) 
194 
4.1 . 1  Axioms and rules 
1 94 
4.1 .2 
Formal proofs 
1 96 
4. 1.3 
The finiteness theorem and the deduction theorem 
200 
4.2 
Henkin models 
202 
4.2.1 Henkin witnesses 
4.2.2 The completeness theorem 
4.3 
Herbrand's method 
4.3.1 
Some examples 
4.3.2 The avatars of a formula 
4.4 
Proofs using cuts 
4.4.1 
The cut rule 
4.4.2 Completeness of the method 
4.5 
The method of resolution 
4.5.1 
Unification 
4.5.2 Proofs by resolution 
4.6 
Exercises for Chapter 4 
Solutions to the exercises of Part I 
Chapter 1 
Chapter 2 
Chapter 3 
Chapter 4 
Bibliography 
Index 
203 
205 
209 
209 
212 
217 
217 
221 
224 
224 
230 
241 
245 
270 
293 
320 
330 
332 

Contents of Part II 
5 
Recursion theory 
5.1 
Primitive recursive functions and sets 
5.1 . 1  
Some initial definitions 
5 .1.2 
Examples and closure properties 
5.1 .3 
Coding of sequences 
5.2 
Recursive functions 
5.2.1 
Ackerman's functions 
5 .2.2 The M-Operator and the partial recursive functions 
5.3 
Turing machines 
5.3.1 
Description of Turing machines 
5.3.2 T-computable functions 
5.3.3 T-computable partial functions are recursive 
5.3.4 
Universal Turing machines 
5.4 
Recursively enumerable sets 
5.4.1 
Recursive and recursively enumerable sets 
5 .4.2 The halting problem 
5.4.3 The smn theorem 
5.4.4 The fixed point theorems 
5.5 
Exercises for Chapter 5 
6 
Formalization of arithmetic , Godel 's theorems 
6.1 
Peano's axioms 
6.1.1 The axioms 
6.1 .2 The ordering on the integers 
6.2 
Representable functions 
6.3 
Arithmetization of syntax 
6.3. 1 
The coding of formulas 
6.3.2 The coding of proofs 
6.4 
Incompleteness and undecidability theorems 
6.4.1 
Undecidability of arithmetic and predicate calculus 
6.4.2 Godel's incompleteness theorems 
6.5 
Exercises for Chapter 6 
7 
Set theory 
7.1 
The theories Z and ZF 
7. 1.1 
The axioms 

CONTENTS 
7 .1.2 
Pairs, relations and maps 
7.2 
Ordinal numbers and integers 
7.2.1 
Well-ordered sets 
7 .2.2 The ordinals 
7 .2.3 
Operations on ordinal numbers 
7 .2.4 The integers 
7.3 
Inductive proofs and definitions 
7.3.1 
lnduction 
7 .3.2 The axiom of choice 
7.4 
Cardinality 
7.4.1 
Cardinal equivalence classes 
7.4.2 
Operations on cardinal equivalence classes 
7 .4.3 The finite cardinals 
7 .4.4 Countable sets 
7.4.5 The cardinal numbers 
7.5 
The axiom of foundation and the reflection scheme 
7 .5.1 
The axiom of foundation 
7 .5.2 
Some relative consistency results 
7 .5.3 
lnaccessible cardinals 
7.5.4 The reflection scheme 
7.6 
Exercises for Chapter 7 
8 
Some model theory 
8. 1 
Elementary substructures and extensions 
8 .1.1 Elementary substructures 
8 .1.2 
The Tarski-Vaught test 
8.2 
Construction of elementary extensions 
8.2.1 Elementary maps 
8.2.2 The method of diagrams 
8.3 
The interpolation and definability theorems 
8.4 
Reduced products and ultraproducts 
8.5 
Preservation theorems 
8.5.1 
Preservation by substructures 
8.5.2 Preservation by unions of chains 
8.5.3 
Preservation by reduced products 
8.6 
Aleph-zero categorical theories 
8.6.1 
The omitting types theorem 
8.6.2 Aleph-zero categorical structures 
8. 7 
Exercises for Chapter 8 
Solutilons to the exercises of Part II 
XV 

Notes from the translator 
In everyday mathematical language, the English word 'contains' is often used 
indifferently, sometimes referring to membership of an element in a set, E, and 
sometimes to the inclusion relation bet ween sets, c. For a reader who is even 
slightly familiar with the subject, this is not a serious issue since the meaning is 
nearly always clear from the context. But because this distinction is precisely one 
of the stumbling blocks encountered by beginning students of logic and set theory, 
I have chosen to consistently use the word 'contains' when the meaning is E and 
the word 'includes' when the meaning is c. 
It is perhaps more common in mathematical English to use the phrases 'one-to­
one' and 'onto' in place of the more formal-sounding 'injective' and 'surjective'. 
I have none the less retained 'injective' and 'surjective' as more in keeping with 
the style of the original; even those who object must admit that 'bijective' has the 
advantage over 'one-to-one and onto'. 
Where the original refers the reader to various standard texts in French for some 
basic facts of algebra or topology, I have replaced these references with suitable 
English-language equivalents. 
It is useful to distinguish between bold zero and one (0 and 1) and plain zero and 
one ( 0 and 1). The plain characters are part of the metalanguage and have their usual 
denotations as integers. The bold characters are used, by convention, to denote the 
truth values of two-valued logic; they are also used to denote the respective iden­
tity elements for the operations of addition and multiplication in a Boolean algebra. 
Ap ril, 2000. 
Donald H. Pelletier 

Notes to the reader 
The book is divided into two parts. The first consists of Chapters 1 through 4; 
Chapters 5 through 8 comprise the second. Concepts presented in a given chapter 
presume knowledge from the preceding chapters (but Chapters 2 and 5 are excep­
tions to this rule). 
Each of the eight chapters is divided into sections, which, in turn, are composed 
of several subsections that are numbered in an obvious way (see the Contents). 
Each chapter concludes with a section devoted to exercises. The solutions to 
these are grouped together at the end of the corresponding volume. 
The solutions, especially for the first few chapters, are rather detailed. 
Our reader is assumed to have acquired a certain practice of mathematics and 
a level of knowledge corresponding, roughly, to classical mathematics as taught 
in high school and in the first years of university. We will refer freely to what 
we have called this 'common foundation', especially in the examples and the 
. 
exercises. 
None the less, the course overall assumes no prior knowledge in particular. 
Concerning the familiar set-theoretical (meta-)language, we will use the termi­
nology and notations that are most commonly encountered: operations on sets, 
relations, maps, etc., as well as N, Z, Zj nZ, Q, IR for the sets we meet every day. 
We will use N* to denote N- {0}. 
If E and F are sets and iff is a map defined on a subset of E with values in F, 
the domain of f is denoted by dom(j) (it is the set of elements in E for which 
f is defined), and its image is denoted by lm(f) (it is the set of elements y in F' 
for which y 
== f (x) is true for at least one element x in E). If A is a subset of 
the domain of f, the restriction of f to A is the map from A into F, denoted by 
f r· A, which, with each element X in A ,  associates f(x). The image of the map 
f I A is also called the direct image of A under f and is denoted by f[A]. If B 
is a subset of F, the inverse image of B under f, denoted by f-1 [B], consists of 
those elements x in E such that f(x) E B. In fact, with any given map f from a 
set E into a set F, we can associate, in a canonical way, a map from p (E) (the set 
of subsets of E) into p (F): this is the 'direct image' map, denoted by f which, 
with any subset A of £, associates f[A], which we could then just as well denote 
by f(A). In the same wayӝ with this given map f, we could associate a map from 
p (F) into p (E), called the 'inverse imageӠ map and denoted by f -I
, which, with 
any subset B of F, associates f-1 [Bl, which we could then just as well denote 
by·! -I (B). (See also Exercise 19 from Chapter 2.) 

XVlll 
N O T E S  T O  T H E  R E A D E R  
Perhaps it is also useful to present some details concerning the notion of word 
on an alphabet; this concept will be required at the outset. 
Let E be a set, finite or infinite, which we will call the alphabet. A wordș w, 
on the alphabet E is a finite sequence of elements of E (i.e. a map from the set 
{0, I, . . .  , n - 1} (where n is an integer) into E); w = (ao, a 1 ,  ... , an-t), or 
even aoar . . .  an-1 , represents the word whose domain is {0, 1, . . . , n - 1} and 
which associates a; with i (for 0 < i < n - 1). The integer n is called the 
length of the word w and is denoted by lg( w j. The set of words on E is denoted 
by W(E). 
If n = 0, we obtain the empty word. We will adopt the abuse of language that 
consists in simply writing a for the word (a) of length 1. The set W (E) can also 
support a binary operation called concatenation: let WI = (ao, at, .. .  , an-1 ) 
and w2 = (bo, bt, . . .  , bm-I) be two words; we can form the new word w = 
(ao,ar, ... , an-r , bo , b r, . . .  , bm-I), i.e. the map w defined on {0,1, . . .  , 
n + m - 1} as follows: 
w(i) = { ai 
bi-n 
ifO < i < n - I ;  
if n < i < n + m - 1 .  
This word is called the concatenation of v;1 with w2 and is denoted by WI w2. This 
parenthesis-free notation is justified by the fact that the operation of concatenation 
is associative. 
Given two words w and WI, we say that WI is an initial segment of w if there ex­
ists a word w2 such that w = w rw2. Toputitdifferently,ifw = (ao, a1, . . .  , an-1 ), 
the initial segments of w are the words of the form (ao, a 1 ,  . . .  , ap-1 ) where p is 
an integer less than or equal to n. We say that w J is a final segment of w if there 
exists a word w2 such that w = w2 w r; so the final segments of (ao, a 1 ,  ... , an-I ) 
are the words of the form (ap , ap+l, . . .  , an-J) where p is an integer less than or 
equal to n. In particular, the empty word and w itself are both initial segments and 
final segments of w. A segment (initial or final) of w is proper if it is different 
from w and the empty word. 
When an element b of the alphabet 'appears' in a word w = aoa 1 
•
•
•
 an-l , we 
say that it has an occurrence in w and the various 'positions' where it appears are 
called the occurrences of bin w. We could, of course, be more precise and more 
formal: we will say that b has an occurrence in w if b is equal to one of the a; 
fori between 0 and n - 1 (i.e. if b belongs to the image of w ). An occurrence of 
b in w is an integer k, less than lg[w], such that b == ak. For example, the third 
occurrence of b in w is the third element of the set { k : 0 < k < n - 1 and ak = b} 
in increasing order. This formalism will not be used explicitly in the text; the idea 
sketched at the beginning of this paragraph will be more than adequate for what 
we have to do. 

N O T E S  T O  T H E  R E A D E R  
The following facts are more or less obvious and will be in constant use: 
• for all words WJ and w2, lg[w1w2] == lgtwd + lg[w2]; 
XIX 
• for all words w 1, w2 and W3, the equality w 1 w2 = w 1 W3 implies the equality 
w2 = W3 (we call this left cancellation); 
• for all words WJ, w2 and W3, the equality w I w2 = W3 w2 implies the equality 
w 1 = W3 (we call this right cancellation); 
• for all words WJ, w2, W3 and w4, if WIW2 = W3W40 then either WI is an initial 
segment of W3 or else W3 is an initial segment of WJ. Analogously, under the 
same assumptions, either w2 is a final segment of w4 or else w4 is a final segment 
of w2; 
• if WI is an initial segment of w2 and w2 is an initial segment of Wt, then 
WI = W2. 
We will also use the fact that W(E) is countable if E is either finite or countable 
(this is a theorem from Chapter 7). 


Introduction 
There are many who consider that logic, as a branch of mathematics, has a some­
what special status that distinguishes it from all the others. Curiously, both its 
keenest adversaries and some of its most enthusiastic disciples concur with this 
conception which places logic near the margin of mathematics, at its border, or 
even outside it. For the first, logic does not belong to 'real' mathematics; the others, 
on the contrary, see it as the reigning discipline within mathematics, the one that 
transcends all the others, that supports the grand structure. 
To the reader who has come to meet us in this volume seeking an introduction to 
mathematical logic, the first advice we would give is to adopt a point of view thai 
is radically different from the one above. The frame of mind to be adopted should 
be the same as when consulting a treatise in algebra or differential calculus. It is a 
mathematical text that we are presenting here; in it, we will be doing mathematics. 
not something else. It seems to us that this is an essential precondition for a proper 
understanding of the concepts that will be presented. 
That does not mean that the question of the place of logic in mathematics i԰. 
without interest. On the contrary, it is enthralling, but it concerns problems external 
to mathematics. Any mathematician can (and we will even say must) at certain 
times reflect on his work, transform himself into an epistemologist, a philosopher 
or historian of science; but the point must be clearly made that in doing this .. 
he temporarily ceases his mathematical activity. Besides, there is generally no 
ambiguity: when reading a text in analysis, what the student of mathematics expects 
to find there are definitions, theorems, and proofs for these theorems. If the author 
has thought it appropriate to add some comments of a philosophical or histori­
cal nature, the reader never has the slightest difficulty separating the concerns 
contained in these comments from the subject matter itself. 
We would like the reader to approach the course that follows in this way and to 
view logic as a perfectly ordinary branch of mathematics. True, it is not always 
easy to do this. 
The major objection surfaces upon realizing that it is necessary to accept simul­
taneously the following two ideas: 
( l )  logic is a branch of mathematics; 
(2) the goal of logic is to study mathematics itself. 

2 
I N T R O D U C T I O N  
Faced with this apparent paradox, there are three possible attitudes. First, one 
may regard it as so serious that to undertake the study of logic is condemned in 
advance; second, one may deem that the supposed incompatibility between ( 1) 
and (2) simply compels the denial of (I), or at least its modification, which leads 
to the belief that one is not really doing mathematics when one studies logic; the 
third attitude, finally, consists in dismantling the paradox, becoming convinced 
that it is not one, and situating mathematical logic in its proper place, within the 
core of mathematics. 
We invite you to follow us in this third path. 
Those for whom even the word paradox is too weak will say: 'Wait a minute! 
Aren't you putting us on when you finally get around, in your Chapter 7, to provid­
ing definitions of concepts (intersection, pair, map, ordered set, . . .  ) that you have 
been continually using in the six previous chapters? This is certainly paradoxical. 
You are surely leading us in a vicious circle'. 
Well, in fact, no. There is neither a paradox nor a vicious circle. 
This text is addressed to readers who have already 'done' some mathematics, 
who have some prior experience with it, beginning with primary school. We do not 
ask you to forget all that in order to rebuild everything from scratch. It is the oppo­
site that we ask of you. We wish to exploit the common background that is ours: 
familiarity with mathematical reasoning (induction, proof by contradiction, . . .  ), 
with everyday mathematical objects (sets (yes, even these!), relations, functions, 
integers, real numbers, polynomials, continuous functions, . . .  ), and with some 
concepts that may be less well known (ring, vector space, topological space, . . .  ). 
That is what is done in any course in mathematics: we make use of our prior 
knowledge in the acquisition of new knowledge. We will proceed in exactly 
this way and we will learn about new objects, possibly about new techniques 
of proof (but caution: the mathematical reasoning that we habitually employ will 
never be called into question; on the contrary, this is the only kind contemplated 
here). 
If we simplify a bit, the approach of the mathematician is almost always the 
same whether the subject matter under study is measure theory, vector spaces, 
ordered sets, or any other area of so-called classical mathematics. It consists in 
examining structures, i.e. sets on which relations and functions have been defined, 
and correspondences among these structures. But, for each of these classical areas, 
there was a particular motivation that gave birth to it and nurtured its development. 
The purpose was to provide a mathematical model of some more or less 'con­
crete' situation, to respond to an expressed desire arising from the world outside 
mathematics, to furnish a useful mathematical tool (as a banal illustration of this, 
consider that vector spaces arose, originally, to represent the physical space in 
which we live). 
Logic, too, follows this same approach; its particularity is that the reality it 
attempts to describe is not one from outside the world of mathematics, but rather 
the reality that is mathematics itself. 

I NT R O DU C T I O N 
3 
This should not be awkward, provided we remain aware of precisely what is 
involved. No student of mathematics confuses his physical environment with 
an oriented three-dimensional euclidean vector space, but the knowledge of this 
environment assists one's intuition when it comes to proving some property of this 
mathematical structure. The same applies to logic: in a certain way, we are going 
to manufacture a copy, a prototype, we dare say a reduced model of the universe 
of mathematics, with which we are already relatively familiar. More precisely, we 
wil1 build a whole collection of models, more or less successful (not every vector 
space resembles our physical space). In addition to a specimen that is truly similar 
to the original, we will inevitably have created others (at the close of Chapter 6, 
we should be in position to understand why), often rather different from what 
we imagined at the outset. The study of this collection teaches us many lessons; 
notably, it permits those who undertake this study to ask themselves interesting 
questions about their perceptions and their intuitions of the mathematical world. 
Be that as it may, we must understand that it is essential not to confuse the original 
that inspired us with the copy or copies. 8 ut the original is indispensable for the 
production of the copy: our familiarity with the world of mathematics guides us in 
fabricating the representation of it that we will provide. But at the same time, our 
undertaking is a mathematical one, within this universe that we are attempting to 
better comprehend. 
So there is no vicious circle. Rather than a circle, imagine a helix (nothing vicious 
there!), a kind of spiral staircase: we are on the landing of the nth floor, where our 
mathematical universe is located; call this the 'intuitive level'. Our work takes us 
down a level, to the (n -l)st floor, where we find the prototype, the reduced model; 
we will then be at the 'formal' level and our passage from one level to the other 
will be called 'formalization'. What is the value of n? This makes absolute} y no 
diiierence; there is no first nor last level. Indeed, if our model is well constructed, 
if in reproducing the mathematical universe it has not omitted any detail, then 
it will also contain the counterpart of our very own work on formalization; this 
requires us to consider level n 
-- 2, and so on. At the beginning of this book, we find 
ourselves at the intuitive level. The souls that inhabit it will also be called intuitive 
objects; we will distinguish these from their formal replica by attaching the prefix 
'meta' to their names (meta-integers, meta-relations, even meta-universe since the 
word 'universe' will be given a precise technical meaning in Chapter 7). We will 
go so far as to say that for any value of n, the nth level in our staircase is intuitive 
relative to leveJ n - I and is formal relative to level n + 1. As we descend, i.e. as 
we progress in our formalization, we could stop for a rest at any moment, and take 
the opportunity to verify that the formal model, or at least what we can see of it, 
agrees with the intuitive original. This rest period concerns the meta-intuitive, i.e. 
level n + 1 .  
So we must face the facts: it is no more feasible to build all of mathematics 
'ex nihilo' than to write an English-English dictionary that would be of use to 
a Martian who knows nothing of our lovely language. We are faced here with 

4 
I N T R O D U C T ION 
a question that had considerable importance in the development of logic at the 
beginning of the century and about which it is worth saying a few words. 
Set theory (it matters little which theory: ZF, Z, or some other), by giving legit­
imacy to infinite objects and by allowing these to be manipulated just like 'real' 
objects (the integers, for example), with the same logical rules, spawned a fair 
amount of resistance among certain mathematicians; all the more because the ini­
tial attempts turned out to be contradictory. The mathematical world was then split 
into two clans. On the one hand, there were those who could not resist the freedom 
that set theory provided, this 'Cantorian paradise' as Hilbert called it. On the other 
hand were those for whom only finite objects (the integers, or anything that could 
be obtained from the integers in a finite number of operations) had any meaning 
and who, as a consequence, denied the validity of proofs that made use of set 
theory. 
To reconcile these points of view, Hilbert had imagined the following strategy 
(the well-known 'Hilbert programme'): first, proofs would be regarded as finite 
sequences of symbols, hence, as finite objects (that is what is done in this book 
in Chapters 4 and 6 ); second, an algorithm would be found that would transform 
a proof that used set theory into a finitary proof, i.e. a proof that would be above 
all suspicion. If this programme could be realized, we would be able to see, for 
example, that set theory is consistent: for if not, set theory would permit a proof 
of 0 = I which could then, with the help of the algorithm suggested above, be 
transformed into a finitary proof, which is absurd. 
This hope was dashed by the second incompleteness theorem of Godel: surely, 
any set theory worthy of this name allows the construction of the set of natural 
numbers and, consequently, its consistency would imply the consistency ofPeano's 
axioms. Godel's theorem asserts that this cannot be done in a finitary way. 
The conclusion is that even finitary mathematics does not provide a foundation 
for our mathematical edifice, as presently constructed. 
The process of formalization involves two essential stages. First, we fix the 
context (the structures) in which the objects evolve while providing a syntax to 
express their properties (the languages and the formulas). Here, the important 
concept is the notion of satisfaction which lies at the heart of the area known as 
semantics. It would be possible to stop at this point but we can also go further and 
formalize the reasoning itself; this is the second stage in the formalization. Here, 
we treat deductions or formal proofs as mathematical objects in their own right. 
We are then not far from proof theory, which is the branch of logic that specializes 
in these questions. 
This book deliberately assigns priority to the first stage. Despite this, we will 
not ignore the second, which is where the most famous results from mathematical 
logic (Godel's theorems) are situated. Chapter 4 is devoted to the positive results 
in this area: the equivalence between the syntactic and semantic points of view in 
the context that we have selected. This equivalence is called 'completeness'. There 
are several versions of this simply because there are many possible choices for a 

I N T R O D U C T I O N  
5 
formal system of deduction. One of these systems is in fashion these days because 
of its use in computer science: this is the method of resolution. We have chosen to 
introduce it after first presenting the traditional completeness theorem. 
The negative results, the incompleteness theorems, will be treated in Chapter 6, 
following the study of Peano's arithmetic. This involves, as we explained above, 
abandoning our possible illusions. 
The formalization of reasoning will not occur outside the two chapters that we 
have just mentioned. 
Chapter I treats the basic operations on truth values, 'true' and 'false'. The 
syntax required is very simple (propositional formulas) and the semantics (well­
known truth tables) is not very complicated. We are interested in the truth value of 
propositions, while carefully avoiding any discussion of the nature of the properties 
expressed by means of these propositions. Our concern with what they express, 
and with the ways they do it, is the purpose of Chapter 3. We see immediately that 
the operators considered in the first chapter (the connectives 'and', 'or', 'implies' 
and so on) do not suffice to express familiar mathematical properties. We have to 
introduce the quantifiers and we must also provide a way of naming mathemati­
cal objects. This leads to formulas that are sequences of symbols obeying rather 
cornplicated rules. Following the description of a syntax that is considerably more 
complex than that for propositional calculus, we define the essential concept: sat­
isfaction of a formula in a structure. We will make extensive use of all this, which 
is called predicate calculus, in Chapters 4 and 6, to which we referred earlier, as 
well as in Chapters 7 and 8. You will have concluded that it is only Chapter 5 that 
does not require prior know ledge of predicate calculus. Indeed, it is devoted to the 
study of recursive functions, a notion that is absolutely fundamental for anyone 
with even the slightest interest in computer science. We could perfectly well begin 
with this chapter provided we refer to Chapter 1 for the process of inductive def­
inition, which is described there in detail and which is used as well for recursive 
functions. 
In Chapter 7 we present axiomatic set theory. It is certainly there that the sense 
of paradox to which we referred will be most strongly felt since we purport to 
construct mathematical universes as if we were defining a field or a commutative 
group. But, once a possible moment of doubt has passed, one will find all that a 
mathematician should know about the important notions of cardinals and ordinals, 
the axiom of choice, whose status is generally poorly understood, and, naturally, 
a list of the axioms of set theory. 
Chapter 8 canies us a bit further into an area of which we have so far only caught 
a glimpse: model theory. Its ambition is to give you a taste for this subject and to 
stiroulate your curiosity to learn more. In any case, it should lead you to suspect 
that mathematical logic is a rich and varied terrain, where one can create beautiful 
things, though this can also mean difficult things. 
l-Iave we forgotten Chapter 2? Not at all! It is just that it constitutes a singularity 
in this book. To begin with, it is the only one in which we employ notions from 

6 
I N T R O D U C T I O N  
classical mathematics that a student does not normally encounter prior to the upper­
level university curriculum (topological spaces, rings and ideals). Moreover, the 
reader could just as well skip it: the concepts developed there are used only in some 
of the exercises and in one section of the last chapter. But we have included it for 
at least three reasons: the first is that Boolean algebras are the "correct" algebraic 
structures for logic; the second is that it affords us an opportunity to display how 
perfectly classical mathematics, of a not entirely elementary nature, could be linked 
in a natural way with the study of logic; the third, finally, is that an exposure to 
Boolean algebras is generally absent from the mathematical literature offered to 
students, and is even more rarely proposed to students outside the technical schools. 
So you should consider Chapter 2, if you will, as a little supplement that you may 
consult or not, as you wish. 
We will probably be criticized for not being fair, either in our choice of the 
subjects we treat or in the relative importance we accord to each of them. The 
domain of logic is now so vast that it would have been absolutely impossible to 
introduce every one of its constituents. So we have made choices: as we have 
already noted, proof theory is barely scratched; lambda calculus and algorithmic 
complexity are absent despite the fact that they occupy an increasingly important 
place in research in logic (because of their applications to the theory of comput­
ing which have been decisive). The following are also absent: non-classical logics 
(intuitionist . . .  ) , second-order logic (in which quantifications range over relations 
on a structure as well as over its elements), or so-called 'infinitary' logics (which 
allow formulas of infinite length). These choices are dictated, first of all, by our 
desire to present a basic course. We do not believe that the apprentice logician 
should commence anywhere else than with a detailed study of the first-order pred­
icate calculus; this is the context that we have set for ourselves (Chapter 3 ). Starting 
from this, we wished to present the three areas (set theory, model theory, recursive 
function theory and decidability) that seetn to us to be the most important. Histor­
ically speaking, they certainly are. They also are because the 'grand' theorems of 
logic are all found there. Finally, it is our opinion that familiarity with these three 
areas is an indispensable prerequisite for anyone who is interested in any other 
area of mathematical logic. Having chosen this outline, we still had the freedom to 
modify the relative importance given to these three axes. In this matter, we cannot 
deny that we allowed our personal preferences to guide us; it is clear that Chapter 8 
could just as well have been devoted to something other than model theory. 
These lines were drafted only after the book that follows was written. We think 
that they should be read only after it has been studied. As we have already pointed 
out, we can only truly speak about an activity, describe it (formalize it!), once we 
have acquired a certain familiarity with it. 
Until then. 

1 
Propositional calculus 
Propositional calculus is the study of the p1vpositional connectives; these are 
operators on statements or on formulas. First of all there is negation, which we 
denote by the symbol-, which is placed infivntofaformula. The other connectives 
are placed between two formulas: we will consider conjunction ('and', denoted 
by A), disjunction ('or', denoted by v ), implication ( =} ), and equivalence ( {} ). 
Thus, for example, from two statements A and B, it is possible to form their 
conjunction: this is another statement that is true if and only if A is true and B is 
true. 
The .first thing we do is to construct purely formal objects that we will call propo­
sitional formulas, 01; more simply in this chapter, formulas. As building blocks we 
will use propositional variables which intuitively represent elementary proposi­
tions, and we assemble them using the connectives mentioned above. Initially, 
formulas appear as suitably assembled sequences of symbols. In Section 1.1, we 
will present precise rules for their construction and means for recovering the 
method by which a given formula was constructed, which makes it possible for the 
formula to be read. All these formal considerations constitute what we call syntax. 
This formal construction is obviously not arbitrary. We will subsequently have 
to give meaning to these formulas. This is the purpose of Section 1.2. lf, for each 
elementa1y pro position appearing in a formula F, we know whether it is true or 
not (we speak of the truth value of the proposition), we must be able to decide 
whether F itse{f is true or not. For instance, we will say that A =} B is true in 
three of the four possible cases: when A and B are both true, when A and B 
are both false, and when A is false and B is true. Notice here the d(fference from 
common usage: for example, in everyday language and even in mathematics texts, 
the phrase 'A implies B 'suggests a causal relationship which, in our context, does 
not exist at all. 
Thereby we arrive at the important notions of this chapter: the concept of tau­
tology (this is a formula that is true regardless of the truth values assigned to the 
propositional variables) and the notion of logical equivalence (two formulas are 
logically equivalent if they receive the same truth value regardless of the truth 
values assigned to the pro positional variables). 

8 
P R O P O S T T I O N A L  C A L C U L U S  
In Section 1.3, we see that a formula is always logically equivalent to a formula 
that can be written in a very particular form (disjunctive or conjunctive normal 
form) while Section 1.4 is devoted to the interpolation theorem and the de.finability 
theorem whose full import will be appreciated when they are generalized to the 
predicate calculus (in Chapter 8). In the last section (ǆf this chapte1; the compact­
ness theorem is particularly important and it too will be generalized, in Chapter 3. 
It asserts that if it is impossible to assign truth values to p1vpositional variables 
in a way that makes all the formulas in some infinite set X true, then there is some 
finite subset of X for which it is also impossible to do this. 
1.1 Syntax 
1.1.1 Propositional formulas 
The preliminary section called ȸNotes to the reader' contains, among other items, 
some general facts about words on an alphabet. The student who is not familiar 
with these notions should read that section first. 
Let us consider a non-empty set P, finite or infinite, which we will call the set 
of propositional variables. The elements of P will usually be denoted by capital 
letters of the alphabet, possibly bearing subscripts. 
In addition, we allow ourselves the following five symbols: 
which we read respectively as: 'not', 'or', 'and', 'implies' and 'is equivalent to' 
and which we call symbols for propositional connectives. We assume that they 
are not elements of P. 
The symbols --., v, 1\, =:} ,  <? are respectively called: the symbol for negation, 
the symbol for disjunction, the symbol for conjunction, the symbol for implica­
tion and the symbol for equivalence. 
In view of the roles that will be assigned to them (see Definition 1 .2 below), we 
say that the symbol Ȝ is unary (or has one place) and that the other four symbols 
for connectives are binary (or have two places). 
Finally, we consider the following two symbols: 
) 
( 
respectively called the closing parenthesis and the opening parenthesis, distinct 
from the symbols for the connectives and also not belonging to P. 
Certain finite sequences composed of propositional variables, symbols for propo­
sitional connectives, and parentheses will be called propositional formulas (or 
propositions). Propositional formulas are thus words formed with the following 
alphabet: 
A =  P u { --., v, A, =>, <? }  u { ), ( } . 

S Y N T A X  
9 
Remark 1.1 From the very first sentences in this chapter, we can already sense 
one of the difficulties which, unless we are careful, will confront us continually 
during our apprenticeship with the basic notions offormal logic: certain words 
and certain symbols are both used in everyday mathematical language (which we 
will call the metalanguage) and also appear in the various formal languages that 
are the principal objects of our study: for example, the word 'implies' and the 
symbol :::>, which, to say the least, arise frequently in all mathematical discourse, 
are used here to denote a precise mathematical object: a symbol for one of the 
connectives. We will attempt, insofar as is possible, to eliminate from our meta­
language any word or symbol which is used in a formal language. It would none 
the less be d(fficult to renounce altogether in our discourse the use of words such 
as 'and', 'or', 'not' or parentheses. (This very sentence illustrates the fact clearly 
enough.) This is why we wish to call the reader's attention to this problem right 
from the beginning and we invite the reader to be constantly alert to the distinction 
between a formal language and the metalanguage. (The same problem will arise 
again in Chapter 3 with the symbols for the quant{fiers.) 
As stated in 'Notes to the Reader', we will identify, by convention, the elements 
of A with the corresponding words of length 1 in W(A). In particular, P will be 
considered a subset of W(A). 
Definition 1.2 The set F of propositional formulas constructed from P is the 
smallest subset ofW(A) which 
• includes P; 
• whenever it contains the word F, it also contains the word ..., F; 
• whenever it contains the words F and G, it also contains the words 
(F A G), (F v G), ( F  => G) and (F -¢:> G). 
In other words, F is the smallest subset ofW(A) which includes P and which 
is closed under the operations: 
F r+ ...,p, 
(F, G) r+ (F A G), 
(F, G) r+ (F v G), 
(F, G) r+ (F ==> G), 
(F, G) r+ (F {:> G). 
Observe that there is at least one subset of W (A) which has these properties, 
namely W(A) itself. The set :F is the intersection of all the subsets of W(A) that 
have these properties. 

10 
P R O P O S I T I O N A L  C A L C U L U S  
Here are examples of formulas (A, B, and C are elements of P): 
A 
(A ==} (B ¶ A)) 
(-.A =? A) 
-.(A ==} A) 
(((A 1\ (-,B => -. A)) 1\ (-,B v -.C)) =} (C =} -.A)). 
And here are words that are not formulas: 
A /\ B  
-.(A) 
(A => B v C) 
A =}  B, C 
(A 1\ B 1\ C) 
VA(A v _,A) 
((A 1\ (B => C)) v (-.A => (B 1\ C)) 1\ (-.A v B)). 
Later we will agree to certain abuses in the writing of formulas: for example, 
A 1\ B could be accepted in some cases as an abbreviation for the formula (A 1\ B). 
Obviously, this changes nothing in the definition above; we are simply giving 
ourselves several ways of representing the same object: if A 1\ B is a permitted 
way to write the formula (A 1\ B), the length of A 1\ B is none the less equal to 
5. Observe in passing that the notion of the length of a formula is already defined 
since we have defined the length of any word on any alphabet. (See the Notes to 
the Reader.) 
It is possible to give a more explicit description of the set F: to do this, we will 
define, by induction, a sequence (.r11 )nEN of subsets of W(A). We set 
Fo = P 
and, for each n ,  
Fn + 1 = Fn U {--. F : F E Fn} U { ( F a G) : F, G E Fn, a E { 1\, v, =>, ¶ }} 
Observe that the sequence (Fn)nEN is increasing (for n < m, we have Fn c Fm). 
Theorem 1.3 F = UnEN .rn. 
Proof It is clear that UnEN Fn includes P and is closed under the operations 
indicated above (if two words F and G belong to Fn for a certain integer n ,  then 
-,F, (F 1\ G), (F v G), (F =* G) and (F ¶ G) 
belong to Fn+ 1· It follows that UnEN .rn includes the smallest set having these 
properties, namely, F. 
To obtain the reverse inclusion, we show by induction that for each integer n, 
we have Fn c F. This is true by definition if n = 0, and if we assume (this is the 

S Y N T A X  
1 1  
induction hypothesis) Fk c F, we also have Fk+ 1 c F according to the definition 
of Fk+1 and the closure properties of F. 
• 
We thus have two equivalent definitions of the set of propositional formulas. We 
often speak of ' definition from above' in the first case and 'definition from below' 
for the one that follows from the previous theorem. 
At several places in this book, we will encounter this type of definition, said to be 
inductive or by induction (see, for example, the set of terms or the set of formulas 
of the predicate calculus in Chapter 3, or again the set of recursive functions in 
Chapter 5). In each case, we are concerned with defining the smallest subset of a 
fixed set E that includes a given subset and that is closed under certain operations 
defined on E (this is definition from above). We always have an equivalent defi­
nition from below: this consists in constructing the set that we wish to define one 
leve] at a time; the subset given initially is the lowest level and the elements of 
level n + 1 are defined to be the images under the given operations of the elements 
from the lower levels. The set to be defined is then the union of a sequence of 
subsets, indexed by the set of natural numbers. In all instances of sets defined by 
induction that we will meet in the future, as well as in the method of proof by 
induction described below, we will encounter the notion of height. 
Definition 1.4 The height of a formula F E F is the least integer n such that 
F E Fn. It is denoted by h[F]. 
For example, if A and B are propositiona] variables, we have 
h[A] = 0 ;  
h[((A v B) 1\ (B ==> A))] = 2 ;  
h [-.-.-,-.-.Aj = 5. 
Note that Fn is the set of formulas of height less than or equal to n, and that 
Fn+ 1 
- Fn is the set of formulas of height exactly n + 1. 
It also follows from the definition that for all formulas F and G E F, we have: 
h[-.F] < h [F] + 1 
and 
h[(F a G)] < sup(h[F], h[G]) + 1, 
where a denotes an arbitrary symbol for a binary connective. 
(In fact, we will see, after Theorem 1 .12^ that we can replace these inequalities 
by equalities). 
1.1.2 Proofs by induction on the set of formulas 
Suppose we wish to show that a certain property X (F) is satisfied by every formula 
F E F. To do this we can use an argument by induction (in the usual sense) on the 
height of F: so we would be led first to show that X (F) is true for every formula 
F belonging to :Fo, and afterwards that if X(F) is true for every F E Fn, then it 
is also true for every F E Fn+l (and thus, for any n). 
This style of argument is associated with definition 'from below' of the set of 
formulas. 

12 
P R O P O S I T I O N A L  C A L C U L U S  
It is more practical and more natural, however, to take the first definition as our 
point of departure and proceed as follows. The initial step is the same: we show 
that X(F) is satisfied for all formulas belonging to P (that is, to Fo); the induction 
step consists in proving, on the one hand, that if the formula F satisfies the property 
X, then so does the formula -, F, and on the other hand, that if F and G satisfy X, 
then so do the formulas (F 1\ G), (F v G), (F ==} G), and (F {:} G). 
As we see, the notion of the height of formulas does not appear explicitly in this 
style of argument, nor does any other natural number. 
Before establishing the correctness of this method of proof (which is the purpose 
of Lemma 1 .7) let us give an initial example of its use: 
Theorem 1.5 The height of a formula is always strictly less than its length. 
Proof In this case, the property X(F) is: h[F] < lg[Fl. 
If F is a propositional variable, we have h [F] == 0 and lg[F] == I; the inequal­
ity is verified. Let us now pass to the induction step. Suppose that a formula F 
satisfies h[F] < lg[ F]; we then have 
h [  -,F] < h[F] + l < lg[F] + 1 == lg[ -,p], 
which shows that X( -,F) is true; and now suppose that F and G are formulas that 
satisfy h[F] < lg[F] and h[ G] < lg[ G]; then, where a is any symbol for a binary 
connective, we have 
h[(F a G)] < sup(h[F], h[Gl) + 1 < sup(lg[F], lg[G]) + 1 
< lg[F] + lg[G] + 3 == lg[(F a G)], 
which means that X(F a G) is satisfied and the proof is finished. 
• 
As a consequence of this property, observe that there are no formulas of length 0 
(which is one of the ways to show that the empty word is not a formula!) and that 
the only formulas of length 1 are the propositional variables. 
The two lemmas that follow allow us to justify the method that we just described 
and used. The first is a variant of it that we will then easily modify below. 
Consider a property Y(W) of an arbitrary word W E W(A) (which need not 
necessarily be a formula). Here is a sufficient condition that every formula satisfies 
the property Y: 
Lemma 1.6 Suppose, on the one hand, that Y( W) is true for every word W E P, 
and, on the other hand, that for any words W and V, if Y( W) and Y(V) are 
true, then 
Y( _,F), Y(F A G), Y(F v G), Y(F ==} G), and Y(F ¢> G) 
are also true. Under these conditions, Y(F) is true for every formula F. 
Proof Let Z be the set of words that have property Y: 
z = {W E W(A) : Y(W)}. 

S Y N T A X  
13 
The hypotheses of the lemma indicate that Z includes P and that it is closed 
with respect to the operations: 
W f-). 
-, W, (W, V) M (W A V), (W, V) N (W v V), 
(W, V) M (W =} V) and (W, V) O (W <:> V). 
It follows, according to Definition 1 .2, that :F is included in Z, which means that 
every element of :F satisfies the property Y. 
• 
Let us now consider the case where we have a property X (F) which is only 
defined for formulas and not for arbitrary words. (This is the case, for example, 
with the property: h[ F] < lg[F], since the notion of height is defined only for 
elements of :F.) 
Lemma 1.7 Suppose, ontheonehand, that X(F) istrueforeveryformula F E  P, 
and, on the other hand that, for all formulas F and G, if X(F) and X(G) are 
true) then 
X(-,F), X(F A G), X(F v G), X(F =} G), and X(F <:> G) 
are also true. Under these conditions, X(F) is true for every formula F. 
Proof It suffices to consider the property Y(W): 'W E :F and X(W)', which is 
defined for every word W E W(A). Since :F includes P and is closed under the 
operations 
W / 
-, W, (W, V) f-). (W A V), (W, V) t-+ (W v V), 
(W, V) P (W =? V) and (W, V) M (W <:> V), 
we see immediately that if the property X satisfies the stated hypotheses, then the 
property Y satisfies those of the preceding lemma. We conclude that Y< F) is true 
for every formula F and hence the same holds for X(F). 
• 
1.1.3 The decomposition tree of a formula 
Among the first examples of formulas that we gave earlier was the following 
word W: 
The reader, who justifiably has no intention to take us on faith, should be con­
vinced by what follows that this word is indeed a formula: 
By setting 
and 
WI == (C ? -,A), 
we first observe that W can be written as (Wo ==} Wt). 

14 
P R O P O S I T I O N A L  C A L C U L U S 
Then, after setting 
Woo = (A A (-.B =} -,A)), 
Wo1 = ( -,B v -,C), 
Wto = C, 
wll = _,A, 
we can write Wo = (Woo A Wot) and W1 = (Wto ::::> W11). 
Continuing in this way, we will be led successively to set 
in such a way that 
Wooo = A  
W01o = -,B 
Wno = A  
Woou = -,A 
Wot io = C  
Woo1 10 = A  
Woo1 = (-,B  -.A) 
W011 = -.C 
Wo01o = -,B 
Wo10o = B 
WooiOO = B 
Woo = (Wooo A Wool) ,  Wot = (Woio v Wo11 ), W1 1 = -,  W11o, 
Woot 
== (Woo to =} Woo1 1  ), Wo1o = -,  Wowo, Wou = -,Wo1 10, 
Wooto = -, WooiOo and Woo1 1 = .. ., Woouo-
This shows that the word W was obtained by starting from propositional variables 
and by applying, a finite number of times, operations allowed in the definition of 
the set of formulas. It follows that W is a formula. 
We can represent the preceding decomposition in the form of a tree: 
w 
/-------------
- Ɗ 
Wo 
/ 
1\ 
------ƍ 
Woo 
WOI 
1\ 
ƌ 
r 
v Ƌ 
Wooo 
Wool 
Wow 
Won 
Wuo 
• 
r-
:::> Ɖ 
-, 
• 
Wcxno 
Woon 
Wo1oo 
Wono 
--. 
..., 
• 
• 
Wo01oo 
Woo no 
• 
• 
The root of the tree (the formula W) is at the top and the branches 'grow' toward 
the bottom. Each node of the tree is a word V (which is always a formula if the 
word at the root of the tree is a formula). Three cases can arise: V is a propositional 

S Y N T A X  
15 
variable and, in this case, will be an extremity of the tree (the words corresponding 
to this situation are identified by a black dot in our figure above); V can be written 
as ._, V' in which case there is a single branch starting from V and ending at the 
level immediately below at the node V'; or finally, V can be written as (V' a V") 
(where a is a symbol fora binary connective)andin thiscasetherearetwobranches 
starting from V and ending at the level immediately below at the two nodes V' and 
V" (in this case the appropriate symbol for a binary connective has been placed in 
the figure between the two branches). 
The decomposition that we have chosen for our formula shows that it belongs to 
Fs. Its height is therefore less than or equal to 5. At the moment, nothing allows 
us to claim that its height is exactly 5. Might we not, in fact, imagine a second 
way of decomposing this formula which would lead to a shorter tree? All we can 
say (and this is thanks to Theorem 1.3) is that for every formula F E F, there 
is at least one decomposition of the type we have just exhibited. The uniqueness 
will be established in the next theoremਖ਼ for which we first require a few lemmas 
which, with the exception of Lemma 1 . 1  0 
.. will be proved by induction on the set 
of formulas. 
1.1 
.. 4 The unique decomposition theorem 
For each word W E W(A), let us agree to denote by o[W] (respectively: c[W]) 
the number of opening (respectively: closing) parentheses that occur in W. 
Lemma 1.8 In any formula, the number of opening parentheses is equal to the 
number of closing parentheses. 
Proo1[ 
We argue by induction on the formula F. 
• For any formula F E  P, we have o[F] = c[F] = 0. 
• For any formula F E F such that o[F] = c[F], since o[-1F] = o[F] and 
c[-.F] = c[F], we have o[-,F] = c[-,F]. 
• For all formulas F and G belonging to F such that o[F] = c[F] and o[G] = 
c[ G], and where a is an arbitrary symbol for a binary connective, we have 
o[(F a G)] = o[F] + o[G]+l = c[F] + c[G]+l = c[(F a G)]. 
Thus, o[F] = c[ F] for any propositional formula F. 
• 
Lemma 1.9 For any formula F E F and any word W E W(A), if W is an initial 
segment ofF, then o[W] > c[W]. 
Proof The induction is on the formula F. 
• If F E P, then for every initial segment W of F , we have o[W] = c[W] = 0, 
hence o[W] > c[W]. 
• Let F be a formula such that for every initial segment W of F, we have o[W] > 
c[W]. Consider an initial segment V of -.F: if V is the empty word, then 

16 
P R O P O S I T I O N A L  C A L C U L U S  
o[V]  c[V] == 0; if V is not the empty word, then there is an initial segment 
W ofF such that V == ..., W; we have of V] == o[W] and c[V] == c[W], and since 
o[W] > c[W] (by the induction hypothesis), we conclude that o[V] > c[V]. 
• Let F and G be two formulas all of whose initial segments have at least as many 
opening parentheses as closing parentheses, and let a be a symbol for a binary 
connective. Set H == (F a G). Let V be an initial segment of H. Four cases 
can anse: 
* either V == 0: in this case, o[V J == c[V] == 0; 
* or V  (W 
(where W is an initial segment of F): 
then o[V] == o[W] --r 1 and c[V] == c[W], and since o[W] > c[W] (by the 
induction hypothesis), we conclude that ol V] > c[V]; 
* or V  (F a K 
(where K is an initial segment of G): 
then o[V] == o[F] + o[K] + I and c[V] == c[F] + c[K]; but o[F]  c[F] 
(by Lemma 1 .8) and o[K] > c[Kl (by the induction hypothesis), which 
allows us to conclude once more that o[V] > c[V]; 
* or V == H: in which case o[Vl > c[V] (by Lemma 1.8). 
So we see that in all cases, o[V] > cL V]. 
• 
Lemma 1.10 For any formula F E F whose first symbol is an opening paren­
thesis and for every word W E W(A) which is a prvper initial segment of F, 
we have 
o[ W] > c[W]. 
(strict inequality) 
Proof For once, the proof is not by induction! 
Consider a formula F which can be written as F == (G a H) where G and H are 
arbitrary formulas and a is a symbol for a binary connective. Let W be a proper 
initial segment of F. There are two possible cases. 
• either W == (K 
(where K is an (arbitrary) initial segment of G); 
in this case, o[W]  o[K] + I and c[WJ  c[K], and since o[K] > eLK] (by 
Lemma 1.9), we conclude that o[W] > c[W]; 
• or W == (G a L 
(where L is an initial segment of H); 
inthis case, o[W] == o[G]+o[L]+ 1 and c[W] == c[G]+c[L]; but o[G] == c[G] 
(by Lemma 1.8 ) and o( L] > c[L I (by Lemma 1.9), which leads once again to 
o[W] > c[W]. 
• 
Lemma 1.11 For any formula F E F and for any word W E W(A), if W is a 
pro per initial segment ofF lhen W is not a formula. 
Proof Here too, the induction is on the formula F. 
• A propositional variable does not have any proper initial segments. 
• If F is a formula none of whose proper initial segments is a formula, and if 
V is a proper initial segment of ...,F, then either V == ..., and is not a formula 
(the only formulas of length I are the elements of P), or else V ==
..., W where 

S Y N T A X  
17 
W is a proper initial segment of F; in this case, W is not a formula (by the 
induction hypothesis) nor is V == -, W. Observe that, contrary to what we might 
have been tempted to believe, the fact that 
'if W is not a formula, then neither is --. W' 
is not a trivial application of the definition of the set of formulas, but requires a 
proof. Here it is: if -. W is a formula, examination of its first symbol shows that it 
is neither a propositional variable nor a formula of the type (H a K); therefore 
(by Theorem 1.3) there exists at least one formula G such that -, W == --.G; if the 
words --. W and -,a are identical, then so also are the words W and G, which 
proves that W is a formula. 
• Let F and G be two arbitrary formulas, a a symbol fora binary connective, and 
V aproperinitialsegmentof(F a G). Wehave o[V] > c[V] (by Lemma 1 .10). 
We conclude that V is not a formula (by Lemma 1 .8). Note that it was not 
necessary, in this part of the argument by induction, to assume that the proper 
initial segments of F and G are not formulas. 
• 
Theorem 1.12 (Unique decomposition) For any formula F E  F, one and only 
one of the following three cases can arise: 
Case 1: F E  P. 
Case 2: there is a unique formula G such that F == -,G. 
Case 3: there is a unique symbol for a binary connective a and a unique pair of 
formulas (G, H) E F2 such that F == (G a H). 
Proof I tis obvious that these three cases are mutually exclusive: weare incase 1, 
in case 2, orin case 3 (still subject to proving uniqueness in each of these cases) 
according as the first symbol of F is an element of P, the symbol -., or the symbol ( 
(these are, by virtue of Theorem 1.3, the only possibilities). 
What we know already (Theorem 1 .3) is this: either F E P, or else there is at 
least one formula G such that F == -.G, or else there is at least one symbol for a 
binary connective a and formulas G and H such that F == (G a H). 
So it only remains for us to prove the uniqueness of the decomposition in cases 
2 and 3. 
This is more or less obvious for case 2: i f F == -.G ::: -.G', then G == G'. 
As for case 3, suppose that there exist formulas G, H, K, and L and symbols 
for binary connectives a and f3 such that F == (G a H) ::: (K f3 L). We conclude 
that the two words G a H and K f3 L are equaL which shows that one of the two 
formulas G and K is an initial segment of the other. By Lemma I .  I 1, this cannot 
be a proper initial segment. Since the empty word is not a formula, we conclude 
that G == K. From this, it follows that the words a H and f3 L are equal. The 
symbols a and f3 are therefore identical, as well as the formulas H and L. 
• 
As the first application of the unique decomposition theorem, we have the unique­
ness of the decomposition tree of a formula, as described above. 

18 
P R O P O S I T I O N A L  C A L C U L U S  
We may also conclude from it (as announced at the end of Subsection 1 . 1 . 1 )  that 
for all formulas F and G belonging to F., we have 
h[-.F] == h[F] + 1 
and h[(F a G)] == sup(h[F], h[G]) + 1 
for any symbol for a binary connective a. 
For example, let us prove the second equality (the other one is treated in an 
exactly analogous fashion): let H denote the formula (F a G). Since this is not an 
element of P, there exists a (unique) integer n such that h[H] = n + 1 .  This means 
that H E Fn+ 1 and H fj_ Fn . By the definition of :Fn+ 1 and because H begins 
with an opening parenthesis, we conclude that there exist two formulas Hr and 
H2 E :Fn and a symbol for a binary connective {3 such that H = (H1 {3 H2). The 
unique decomposition theorem then shows that {3 == a, H1 == F, and H2 = G. 
Consequently, F and G belong to :F,ԯ. If there were some integer m < n such that 
F and G belonged to :Fm, the formula (F a G) would belong to F,n+l ,  hence also 
to :Fn , which is false. It follows that at least one of the formulas F and G has height 
n, and so: h[(F a G)] = sup(h[F], h[Gl) + 1. 
1.1.5 Definitions by induction on the set of formulas 
Just as we can give proofs by induction on the set of formulas, we can provide 
definitions by induction of functions or of relations whose domain is the set 
of formulas. The principle is as follows: given an arbitrary set E, to define a 
mapping ¢ from :F into E, it suffices to give, first of all, the values of ¢ on P, 
and then to give rules which allow us, for all formulas F and G, to determine the 
values of 
¢(-.F), ¢((F 1\ G)), ¢((F v G)), ¢((F ==> G)) and ¢((F ਚG)) 
from the values of ¢(F) and ¢(G). Let us be more precise: 
Lemma 1.13 Let ¢o be a mapping from P into E, f a mapping from E into 
E, and g, h, i, and j four mappings from £2 into E. Then there exists a unique 
mapping ¢from :F into E satisfying the following conditions: 
• the restriction of¢ to P is ¢o; 
• foranyformula F E  :F, ¢(-.F) ==f (¢(F)); 
• for all formulas F and G E :F, 
¢((F 1\ G)) == g(¢(F), ¢(G)) 
¢((F v G)) == h(¢(F), ¢(G)) 
¢ ( ( F ==} G)) == i ( ¢ (F), ¢ (G)) and ¢ ( ( F {} G)) = j ( ¢ (F), ¢ (G)) 
Proof The uniqueness of¢ is easily proved by induction on the set of formulas 
using the unique decomposition theorem. The existence of¢, which is intuitively 
clear, is proved with an elementary argument from set theory that we will not 
present here. 
• 

S Y N T A X  
19 
Here is an initial example of definition by induction, for the concept of sub­
formula of a propositional formula: 
Definition 1.14 With each formula F E F we associate a subset sf(F) ofF, 
called the set of sub-formulas of F, which is defined by induction according to 
the following conditions: 
• ifF E P, 
sf(F) = { F}; 
• ifF == -,G, 
sf( F) == sf( G) U {F} ; 
• ifF == ( G a H) where a E { /\ ,  v, :::} , ¢> }, 
sf(F) == sf( G) U sf(H) U {F}. 
[t is easy to verify that the sub-formulas of a formula are exactly those that appear 
as nodes in its decomposition tree. 
1.1.6 Substitutions in a propositional formula 
Let F be a formula in F and let A I , A2, . . .  , An be propositional variables from 
P that are pairwise distinct (this hypothesis is essential). We will use the notation 
F[Ab A2, . . .  , An] for F when we wish to emphasize that the elements of P that 
occur at least once in F are among A I ,  A2, . . .  , An. For example, the formula 
F == (A =}  (B v A)) could be written as F[A, B], but also as F[A ,  B, C, D] if 
it is useful to do so in a given context. 
If we are given a formula F[A I, A2, . . .  , An ,  B1 , B2, . . .  , Bml and n formu­
las G I , G2, . . .  , G n ,  consider the word obtained by substituting the formula G 1 
(respectively: G2, . . .  , Gn) for the variable A 1 ,  (respectively: A2, . . .  , An) at each 
occurrence of these in F. This word will be denoted by Fc1jA 1 ,c2JA2, 
• • • • G11fAn 
(read this as 'F sub G 1 replaces A I ,  G2 replaces A2, et cetera, Gn replaces An'), 
but we will also denote it by F[G 1 , G2, . . .  , Gn , B1 ,  B2, . . .  , B mJ despite the fact 
that this might cause some delicate problems. 
Forexample, ifF == F[A , B ] isthe formula (A =} (BvA)) and G istheformula 
(B =} A), then FcjA is the word ((B =} A) =} (B v (B :::} A)) which we could 
denote by F[G, B] or equally well by F[(B  A), B]. If we then consider a 
propositional variable C (distinct from A and B) and the formula H = C, then 
F H/A is the word (C =} (B v C)), which could be written, according to our 
conventions, as F[C, B]. A nasty ambiguity then arises, since it is unclear how to 

20 
P R O P O S I T I O N A L  C A L C U L U S  
determine from the equalities 
F[A, B] == (A ==>  (B v A)) 
and 
F[C, B] == (C =? (B v C)) 
which of these two formulas is the formula F. 
Nevertheless, the notation F[G I , G2, . . .  , Gn, B, , 82, . . .  , Bm] is extremely 
practical and, most of the time, perfectly clear. That is why we will permit our­
selves to use it, despite the danger we have pointed out, by limiting its use to 
circumstances where there can be no ambiguity. 
In fact we could give a definition of Fc1jA1 ,c2jA2, .... G11fA11 by induction on 
the formula F (where G , ੖G2, . . .  , Gn E F and A1, A2, . . .  , An E P remain 
fixed): 
• if F E P, then 
• if F ==  -.G, then 
• if F == (G a H), then 
if F =  Ak (I < k < n); 
if F fj {AI , A2, . . .  , An}. 
for all formulas G and H and symbol for a binary connective a. 
In the examples that we provided, we were able to observe that the word obtained 
after substituting formulas for propositional variables in a formula was, in every 
case, itself a formula. There is nothing surprising in this: 
Theorem 1.15 Given an integer n,formulas F, G1. G2, . . .  , Gn, and proposi-
tional variables A , ,  A2, . . .  , An, the word FcJ fA , ,G2tA2, ... ,c11jA11 is aformula. 
Proof Letting G 1 , G2, . . .  , Gn E F and A 1 ,  A2, . . .  ., An E P remain fixed, we 
prove this by induction on the formula F. 
• i f F  E P, Fc1jA 1 ,c2jA2, .... G11/A11 is equal to Gk if F =  Ak (1 < k < n) and to 
F if F ¢. { A  1 , A 2, . . .  , An}; in both cases this is a formula. 
• if F == -.G, and if we suppose that GG 1jA1 . c2jA2, ... ,G11fA11 is a formula, then 
F G 1jA1 ,G2jA2 .... ,G11 /A11 , which is the word -, Gc1jA1 .c2jA2, .... G11fA11 , is again a 
formula. 
• if F ==  (G a H) (where a is a symbol for a binary connective) and if we suppose 
that the words Gc1jA1.c2jA2 ..... G11fA,1 and HcJ!A1 .c2jA2, ... ,G11fA11 are formulas, 
then F c1jA1 .c2! A2, ... ,Gn/A" ' which is the word 
(GGt fAt ,G2/A2·····Gn/An a lfct fAJ .G2/A2 ..... G, jA,), 
is also a formula. 
• 

S E M A N T I C S  
Remark 1.16 It behooves us to insist on the fact that the formula 
Fcl / A1 ,Gz/ A2, ... ,Gn! An 
21 
is the result of simultaneously substituting the formulas G 1 ,  G2, . . .  , Gn for the 
variables A 1 ,  A2, . . .  , An in the formula F. A priori we would obtain a dɕfferent 
formula ɕfwe performed these substitutions one after another; moreover, the result 
we obtain might depend on the order in which these substitutions were performed. 
Let us take an example. 
Set 
We then have: 
whereas 
and 
We may also, in a given formula F, substitute a formula G for a sub-formula H 
of F. The word that results from this operation is once again a formula. Although, 
in practice, this type of substitution is very frequent, we will not introduce a special 
notation for it and will not enter into details. Let us be satisfied with an example. 
Suppose that 
F == (((A 1\ B) => (-.B 1\ (A ==> C))) v (B -¢?  (B ==> (A v C)))), 
G == (A -¢? ( B v C)) and 
H == ( _,B A (A ==> C)). 
Then, by substituting G for the sub-formula H in the formula F, we obtain the 
formula 
(((A 1\ B) ==> (A -¢? (B v C))) v (B ¶ (B ==> (A v C)))). 
1.2 Semantics 
1.2.1 Assignments of truth values and truth tables 
Definition 1.17 An assignment of truth values to P is a mapping from P into 
the set {0, 1}. 
Instead of 'assignment of truth values', some speak of a 'valuation', others of 
an 'evaluation', or 'distribution of truth values'. 

22 
P R O P O S l T l O N A L  C A L C U L U S  
An assignment of truth values to P is therefore an element of the set 
{0, 1}P. 
An assignment of truth values 8 E {0 1} P attributes, to each propositional 
variable A, a value 8(A) which is 0 or 1 (intuitively, false or true). Once this is 
done, we will see that it is then possible, in one and only one way, to extend 8 to 
the set of all propositional formulas while respecting the rules that agree, more or 
less, with our intuition as suggested by the names we have given to the various 
symbols for propositional connectives. Why 'more or less'? Because, although it is 
doubtful that anyone would be surprised that a formula F will receive the value 1 if 
and only if the formula -.F receives the value 0, the decision to attribute the value 
1 to the formula (F => G) when the formulas F and G each have the value 0 will 
perhaps give rise to more uneasiness (at least at first sight). One way to dissipate 
this uneasiness is to ask ourselves under what circumstances the formula (F ==} G) 
could be considered false: we would probably agree that this would only happen 
in the case where F were true without G being true, which leads us to attribute 
the value 1 to (F :::} G) in the other three possible cases. The difficulty no doubt 
arises from the fact that, in mathematical arguments, we have the impression that 
we practically never have to consider situations of the type 'false implies false' 
or 'false implies true'. But this impression is misleading. No one will contest, for 
example, that the statement 'for every natural number n ,  n divisible by 4 implies 
n is even' is true. But an inevitable consequence of this is that the following two 
statements are true: 
' 1  divisible by 4 implies 1 is even'; 
'2 divisible by 4 implies 2 is even'. 
The situations 'false implies false' and 'false implies true' were already present 
in our initial statement; let us simply say that we don't really care. 
Another remark is called for here. If we took a poll among mathematicians asking 
them whether the statement 
'
n divisible by 3 implies n odd' is true or false, the 
second response would win overwhelmingly. For any mathematician would think 
to have read or heard the statement 'every natural number divisible by 3 is odd' 
and would legitimately respond: it's false. This is because standard mathematical 
usage considers that statements having theformof an implication are automatically 
accompanied by a universal quantifier that is taken for granted. 
There is no shortage of examples (the statement 
VE > 0 38 > 0 (lx ·- yl < 8 ::} ff(x) - f(y)l < E) 
is often taken as the definition of uniform continuity of a function f; in this context, 
the quantifiers Vx and \ly, which should be placed between '38 > 0' and the first 
opening parenthesis, are frequently omitted because they are considered to be 
understood; this could explain the difficulty that certain students have when asked 
to describe a function that is not uniformly continuous . . .  ). As for the question in 
our poll, it makes no sense as we have stated it, until we know what the integer n is. 

S E M A N T I C S  
23 
And it suffices to replace n by 3, by 4 or by 5 for the statement to be true (it 
will be, respectively, of type 'true implies true', 'false implies false', and 'false 
implies true'). 
There is another difficulty concerning implication, which is that mathematicians 
generally see in it a notion of causality, which propositional calculus absolutely 
does not take into account. If PI and P2 are two true statements, propositional 
logic imposes the value true on the statement ' PI implies P2 ' .  But a mathematician 
will refuse, more often than not, to affirm that 'Pt implies P2 • is true when the 
statements Pt and P2 have 'nothing to do' with one another. Is it true that Rolle's 
theorem implies the Pythagorean theorem? Those who do not dismiss this question 
as absurd will generally respond no, because to say yes suggests that they are in 
position to provide a proof of the Pythagorean theorem in which Rolle's theorem 
is actually involved. 
Though the conflicts between intuition or mathematical usage and the definitions 
that we are about to give arise especially with implication, the other connectives 
may also make a modest contribution to this (disjunction is often interpreted as 
exclusive (A or B but not both) whereas our v will not be). 
In propositional calculus, these kinds of questions are not to be considered. We 
will be content to perform very simple operations oo two objects: 0 and 1, and our 
only reference wilJ be to the definitions of these operations, i.e. to what we will 
later call the truth tables. 
Let it be perfectly clear that the intuition we referred to above is exclusively 
mathematical intuition. Our concern is not at all to invoke 'everyday' logic (the one 
that is known as 'common sense'). Mathematicians make no pretence of possessing 
a universal mode of reasoning. It is hard to resist applying mathematical reasoning 
to situations outside mathematics, seduced as we are by the rigour of this reasoning, 
when we discover it. But the result is not what we had hoped: we soon face the 
fact that human problems do not allow themselves to be resolved by mathematical 
logic. As for the supposed pedagogical virtues of giving 'real-life examples', they 
are the opposite of what some may expect from them. This type of approach does 
not, in any determining way, make the apprenticeship of the rules of mathematical 
logic any easier, but it is very useful for teaching us prudence, and even humility: 
to learn mathematical reasoning, let us study mathematics. In fact, we can ask 
ourselves whether, to illustrate that a formula involving implication is equivalent 
to its contrapositive, it is more convincing to take the very celebrated example 'if 
it is raining I take my umbrella' compared to 'if I do not take my umbrella it is not 
raining' or the example 'if n is prime then n is odd' compared to 'if n is even then 
n is not prime'. Indeed੗ it suffices to perform the two experiments to conclude that 
the example of the umbrella immediately provokes, justifiably, a slew of objections. 
It is not uninteresting to also note that the contrapositive of 'if it is raining I take 
my umbrella' is most often stated in the form: 'I do not take my umbrella, therefore 
it is not raining', which more closely resembles an 'argued conjunction' than an 
implication. The application of mathematical logic to 'everyday life' has produced 

24 
P R O P O S I T I O N A L  C A L C U L U S  
a choice collection of hilarious examples that the students of Daniel Lacombe know 
well and which have attained a certain popularity among logicians: 
• A father threatens his son: 'if you are not quiet you will get a slap!', and he 
proceeds to administer the slap even though the child had immediately become 
quiet; from the point of view of mathematical logic, this man is not at fault: the 
truth table for=} shows that, by becoming quiet, the child makes the implication 
true regardless of the truth value of 'you will get a slap' . . .  (a good father should 
have said 'you will get a slap if and only if you are not quiet'). 
• In view of tautology no. 1 7  from Section 1 .2.3, what should we think about the 
equivalence between 'if you are hungry, there is some meat in the fridge' and 
its contrapositive: 'if there is no meat in the fridge, you are not hungry'? 
• When a contest offers as its first prize 'a new car or a cheque for $ 1 00 000', 
why shouldn't the winner claim both the car and the cheque, relying on the truth 
table for disjunction? 
As we see, all this no doubt has an amusing side, but it does not help us at 
all in resolving exercises from mathematics in general or mathematical logic in 
particular. We will therefore leave our umbrella in the closet and remain in the 
world of mathematics, where there is already enough to do. 
Theorem 1.18 For any assignment of truth values 8 E {0, 1}P, there exists a 
unique map 8 : :F =} {0, 1 }  which agrees with 8 on P (i.e. it extends 8) and which 
satisfies the following properties: 
( 1 )  foranyformula F, 
-
-
8(-,F) == 1 if and only if 8(F) == 0; 
(2) for all formulas F and G. 
-
-
-
8(F 1\ G) = 1 if and only if 8(F) == 8(G) == 1; 
(3) for all formulas F and G, 
-
-
-
8 (F v G) = 0 (f and only if 8(F) == 8(G) == 0; 
( 4) for all formulas F and G, 
-
-
-
8(F =} G) == 0 (f and only (f 8(F) == 1 and 8(G) == 0; 
(5) for all formulas F and G, 
-
-
-
8(F {:} G) == 1 (f and only if 8(F) == 8(G). 
Proof To simplify the notation, let us observe right away that conditions ( I )  to 
(5) can be expressed using the operations of addition and multiplication on the 
two-element field 'l/2'1L, with which we can naturally identify the set {0, 1}. These 

S E M A N T I C S  
conditions then become equivalent to: 
for all formulas F and G: 
(i') 
(ii') 
(iii') 
(iv') 
(v') 
-
-
8(-,F) = 1 + 8 (F); 
-
-
-
8((F 1\ G)) = 8(F) 8(G); 
8((F v G)) = 8(F) + 8(G) + 8(F) 8(G) 
8((F ==} G)) = 1 + 8(F) + 8(F) 8(G); 
-
-
-
8((F <=> G)) = 1 + 8(F) + 8(G). 
(The proof is immediate.) 
25 
We see that the function 8 is defined by induction on the set of formulas, which is 
what guarantees its existence and uniqueness by Lemma 1.13; here, the functions 
f, g, h, i, and j are defined on 7lj27l by: for all x and y, 
f(x) = I +  x, g(x, y) = xy, h(x, y) = x + y + xy, 
i (x, y) = 1 + x + x y and j (x, y) = 1 + x + y. 
• 
We should point out that identifying {0, 1 }  with 7Lj27l is extremely practical and 
will be used in what follows. 
We can recapitulate conditions (i') to ( v') above in tables which we call the 
truth tables for negation, for conjunction, for disjunction, for implication and for 
equivalence: 
F G (F 1\ G) 
F G (F v G) 
--
F -,F 
0 
0 
0 
0 
0 
0 
--
0 
1 
0 
0 
1 
1 
0 
1 
1 
0 
0 
1 
0 
1 
1 
0 
1 
l 
1 
1 
1 
1 
---
F G (F ==} G) 
F G (F <=> G) 
0 
0 
1 
0 
0 
1 
0 
1 
1 
0 
1 
0 
l 
0 
0 
1 
0 
0 
1 
1 
1 
1 
1 
1 
In practice, we will not really make the distinction between an assignment of 
truth values and its extension to the set of formulas. We will speak of the 'truth 
value of the formula F under the assignment 8' and we will eventually forget the 
bar over the 8 which would have indicated that we were dealing with the extension. 
If F is a formula and 8 is an assignment of truth values, we will say that F is 
satisfied by 8, or that 8 satisfies F, when 8( F) = 1. 

26 
P R O P O S I T I O N A L  C A L C U L U S  
Given a formula F and an assignment of truth values 8, the definition of the 
-
-
extension 8 clearly points to a method for calculating 8 (F): this consists in calcu-
lating the values taken by 8 on the various sub-formulas of F, beginning with the 
sub-formulas of height 1 (the values for those of height 0 being precisely what is 
given), and applying the tables above as many times as necessary. For example, if 
F is the formula ((A ==? B) ==? (B v (A ¢> C))) and if 8 is an assignment of truth 
values for which 8(A) == 8(B) = 0 and 8(C) == 1, then we have successively: 
8((A ==? B) ) == 1 ; 8((A ¢> C)) == 0 î 8((B v (A ¢> C))) == 0 and 8(F) == 0. 
Of course, it can happen that calculating the values of 8 for all the sub-formulas 
of F is unnecessary: to see this, consider the formula 
G == (A ==? (((B 1\ -·A) v (-,C 1\ A)) ¢> (A v (A ==? -·B)))) 
and an assignment of truth values A for which A(A) == 0; we may conclude that 
A(G) == l without bothering with the truth value of the sub-formula 
(((B 1\ -·A) v (-.C 1\ A)) ¢> (A v (A ==? _,B))). 
In the examples that we have just examined, to calculate the truth value of a 
formula, we only used the values taken by the assignment of truth values under 
consideration on the variables that actually occur in the formula. It is clear that 
this is always the case. 
Lemma 1.19 For any formula F[A 1 ,  A2, . . .  , An] (involving no propositional 
variables other than A 1 ,  A2, . . .  , An) and any assignments of truth values A and 
J.L E {0, l}P, ੘{A and J.L agree on {At, A2, . . .  , A}, then A( F) == JL(F). 
Proof The proof involves no difficulties. It is done by induction on the formulas . 
• 
Let G[A 1 ,  A2, . . .  , An] be a formula. To discover the set of truth values of G 
(corresponding to the set of all possible assignments), we see that it is sufficient 
to 'forget' momentarily the variables in P that do not occur in G, and to suppose 
that the set of propositional variables is just {A 1 ,  A2, . . .  , An}- There are then 
only a finite number of assignments of truth values to consider: this is the number 
of mappings from {At , A2, . . .  , An} into {0, 1}, namely 2n (recall that the nota­
tion G[At, A2, . . .  , An] presumes that the variables Ai are pairwise distinct). We 
can identify each mapping 8 from {A 1 ,  A2, . . .  , An} into {0, 1} with the n-tuple 
(8(At ), 8(A2), . . .  , 8(An)) E {0, l}n and place the set of truth values taken by G 
into a tableau in which each row would correspond to one of the 2n n-tuples and 
would contain the corresponding truth value of G. Such a tableau, which could 
also contain the truth values of the sub-formulas of G, will be called the truth 
table of the formula G. Ultimately, this is nothing more than the table of values 
of a certain mapping from {0, 1 }n into {0, 1}. 

S E M A N T I C S  
Let us return to the example given just above: 
G == (A =} (((B A -,A) v (-,C A A)) <:> (A v (A =} -.B)))). 
Set 
H == (B A -.A), I == ( -.C A A), J == (A =} -.B), 
K == (H v /), 
L == (A v J), M == (K <:> L). 
Then we have G == (A ::::} M). Here is the truth table for G: 
A 
B 
c -,A -,B 
-,c H I J K 
L M G 
0 
0 
0 
1 
1 
1 
0 
0 1 
0 
1 
0 
1 
0 
0 
1 
1 
1 
0 
0 
0 1 
0 
1 
0 
1 
0 
1 
0 
1 
0 
1 
1 
0 1 
1 
1 
1 
1 
0 
1 
1 
1 
0 
0 
1 
0 1 
1 
1 
1 
1 
1 
0 
0 
0 
1 
1 
0 
1 
1 
1 
1 
1 
1 
1 
0 
1 
0 
1 
0 
0 0 1 
0 
1 
0 
0 
1 
1 
0 
0 
0 
1 
0 
1 0 1 
1 
1 
1 
1 
1 
1 
0 
0 
0 
0 0 0 
0 
1 
0 
0 
We should note that, with our conventions concerning the notation 
27 
we do not have uniqueness of the truth table for a formula (for example, the first 
four columns of the table above could be considered as the truth table of the formula 
-,A). There is, nonetheless, a 'minimal' table for every formula, the one which 
involves only those propositional variables that occur at least once in the formula. 
1-Iowever, even restricting ourselves to this notion of minimal table, there can 
stil1 be, for the same formula, many tables which differ in the order in which the 
n-tuples from {0, l }n are presented. 
It is reasonable to choose, once and for all, a particular order (among the 2n ! that 
are possible) and to adopt it systematically. We have chosen the lexicographical 
order (the 'dictionary' order): in the table, the n-tuple (a1 ,  a2, . . .  , an) will be 
placed ahead of (bt , b2, . . .  , bn) if, for the first subscript j E { 1 ,  2, . . .  , n} for 
which a j =P b j ,  we have a j < b j .  
] n view of these remarks, we will allow ourselves to speak about 'the' truth table 
of a formula. 
1.2 .. 2 Tautologies and logically equivalent formulas 
Definition 1.20 
• A tautology is a formula that assumes the value 1 under every assignment of 
truth values. 

28 
P R O P O S I T I O N A L  C A L C U L U S  
• the notation for 'F is a tautology' is: I-* F; 
whereas¥* F signҪfies: 'F is not a tautology'. 
• Given two formulas F and G, F is logically equivalent to G if and only ({the 
formula (F {} G) is a tautology. 
The notation for ' F  is logically equivalent to G' is: F "-.J G. 
Remark 1.21 The next two properties follow immediately from these definitions: 
• For all formulas F and G, we have F "-.J G 1j and only iff'or every assignment 
oftruth values 8 E {0, l}P, o(F) = 8(G). 
• The binary relation ț is an equivalence relation on :F. 
The equivalence class of the formula F for the relation 
 is denoted by 
ci(F). 
A tautology is therefore a formula whose truth table contains only ls in its last 
column, in other words, a formula that is ੓always true'. Two logically equivalent 
formulas are two formulas that are satisfied by exactly the same assignments of 
truth values, which thus have the same truth table. Any formula logically equivalent 
to a tautology is a tautology. Therefore the tautologies constitute one of the equiv­
alence classes for the relation "-.J, denoted by 1. The formulas whose negations are 
tautologies (some call these antilogies, others antitautologies) constitute another 
equivalence class, distinct from 1. denoted by 0: these are the formulas that are 
'always false', which is to say that their truth tables contain only Os in the last 
column. 
When we do semantics, we argue 'up to equivalence'. This will be justified by 
the study of the set of equivalence classes for the equivalence relation ""', which 
we will do a bit further on and will complete in Chapter 2. 
Let us now examine the effect of substitutions on the truth values of formulas: 
Theorem 1.22 Given an assignment of truth values, 8, a natural number, n, 
formulas F, G 1 ,  G2, . . . , Gn, and pairwise distinct propositional variables A 1 ,  
A2, . . . , An, let A be the assignment of truth values defined by 
{ 8(X) 
for all X E P, A.(X) = 
8(Gi) 
We then have 
Ҫf X ° {A 1 , A2, . . .  , An }; 
if X = Ai ( l  < i < n). 
Proof We argue by induction on the formula F: 
• i f F  is an element of P, then: 
either F ¢:. {A I ,  A2, . . . , An}; in this case, Fc1 ;A1 .G2jA2 
• • • •  ,G11/Ail = F and 
-
-
8(FG,/At .G2fA2····•Gil/A,) == o(F) == o(F) == "A(F) == "A(F); 

S E M A N T I C S  
29 
by definition of A. 
• If F =  _,G, and if we suppose that 8(Ge 1 1A1,e21A2, ... ,e11IA,) = A.(G) 
(the 
induction hypothesis), then 
-
-
8( Fe 1 I A 1 ,e21 A2, .... en1 An ) = 8( -,Ge 1 I A 1 ,e21 A2, ... ,en1 An ) 
- 1 + 8(G 
) 
-
e1IAI.e2/A2, ... ,en/An 
-
-
-
= 1 + A(G) = A(--,G) = A( F). 
• If F =  (G 1\ H), and if we suppose (the induction hypothesis) 
8(Ge1 1A 1,e21A2, ... ,e111A11 ) = A(G) and 8(He11A1,e21A2, ... ,e11IA11 ) = A(H), 
then 
8(Fe1;A1,e2;A2 .... ,e11jA,J = 8((Ge 1IAI ,e2IA2, ... ,e,;An 
1\ He 1 I A 1 .e21 A2, ... ,en I A, )) 
= 8(Ge J !At ,e2IA2, ... ,eniA, ) 
X 8(He1j A1,e2/A2, ... ,en/An ) 
= A(G) A(H) = A.((G 1\ H)) = A.(F). 
• The cases F = (G v H), F = (G =} H), and F == (G <=? H) are treated 
in a similar fashion without the slightest difficulty; indeed, we could really not 
bother with them at all (for this, see Remark 1.33 later on). 
• 
The next corollary follows immediately from the theorem: 
Corollary 1.23 For all formulas F, G 1 , Gz, . . .  , G n and pairwise distinct pro po­
sitional variables A 1 ,  A2, . . .  , An, {f F is a tautology, then so is the formula 
Proof Given an arbitrary assignment of truth values 8, by defining the assignment 
A as in the previous theorem, we have 
since F is a tautology. 
• 
Another type of substitution also allows us to preserve logical equivalence of 
formulas: 
Theorem 1.24 Consider a formula F, a sub-.formula G ofF and aformula H that 
is logically equivalent to G. Then the formula F', obtainedfrvm F by substituting 
H for the sub-formula G, is Logically equivalent to F. 

30 
P R O P O S I T I O N A L  C A L C U L U S  
Proof We argue by induction on the formula F. 
• I f F  E P, then, necessarily, G = F and F' = H. We certainly have F'  F. 
• If F = -.Ft ,  then either G = F, F' = H, and we have F'  F, or else G is 
a sub-formula of F 1 and, by the induction hypothesis, the formula F; , which 
results from substituting H for G in F 1 ,  is logically equivalent to F 1 .  Then the 
formula F' is the formula -,F{; it is therefore logically equivalent to F since, 
for any assignment of truth values 8, we have 
-
I
 
-
I
 
-
-
-
8(F ) = 1 + 8(F1 ) = 1 + 8(F1) = 8(--.FI) = 8(F). 
• If F = (Ft 1\ F2), then there are three possibilities. Either G = F, F' = H, 
and we have F'  F. Or else G is a sub-formula of F 1 ,  and, by the induction 
hypothesis, the formula F[, which results from substituting H for G in F 1 ,  is 
logically equivalent to F 1 · Then the formula F' is the formula (Fƈ 1\ F2); it is 
logically equivalent to F because, for any assignment 8, we have 
The argument is strictly similar in the third case, when G is a sub-formula 
of F2. 
The cases F = (FI v F2), F = (FI ==} F2), and F == (Fl {;> F2) are treated in 
an analogous fashion using relations (iii') to ( v') from Theorem 1.18. 
• 
In practice, to show that a formula is a tautology, or that two formulas are 
logically equivalent, we have several methods available. First of all, we could use 
truth tables, but this is no longer viable once the number of variables exceeds 3 or 
4. In certain cases, we could have recourse to what might be called 'economical 
truth tables' :  this consists in discussing the values taken by a restricted number of 
variables; in a way, we are treating several lines of the truth table in a single step. 
Let us take an example: we will show that the following formula F is a tautology: 
((A ==} ((B v -.C) 1\ _,(A ==} D))) v ((D 1\ --.£) v (A v C))). 
By setting 
H = (A ==} ((B v -.C) 1\ ...,(A => D))) and 
K = ((D 1\ --,£) v (A v C)), 
wehave F = (Hv K). Next, consideran assignmentoftruth values8.If8(A) = 0, 
-
-
-
then we see that 8(H) = 1, thus also 8(F) = l . I f  8(A) = 1, then 8( A v C) = 1, 
-
-
hence 8 (K) = 1 and 8 (F) = 1. 
Just as well, we could invoke Corollary 1 .23 and Theorem 1 .24 by making use 
of certain 'basic' tautologies (see the list in Section 1 .2.3 ). For example, to show 
that the formula G = ((...,A v B) v -,(A ==} B)) is a tautology, we first use the 
fact that the formulas (-,A v B) and (A ==} B) are logically equivalent, which shows 

S E M A N T I C S  
31 
that G is logically equivalent to ( (A ==} B) v -,(A ==} B)) (by Theorem 1.24 ), then 
observe that this latter formula is obtained by substituting the formula (A => B) 
for the variable A i n  the tautology (A v-,A), and is therefore itself a tautology (by 
Corollary 1 .23 ). 
Needless to say, we will only rarely be led to present such an argument with this 
degree of detail. 
੔fhere are also purely syntactical methods which can be used to prove that a 
formula is a tautology (see Chapter 4 ). 
Finally, Exercise 14 shows how we can reduce all this to a simple calculation 
involving polynomials. 
1.2.3 Some tautologies 
Here is a list of common tautologies (which are just so many exercises for the 
reader, with no solutions given!): 
(A , B and C denote propositional variables (but we may, by Corollary 1 .23, 
substitute arbitrary formulas in their place); T denotes an arbitrary tautology and 
_L the negation of T, which is to say a formula that always takes the value 0.) 
( l )  ((A 1\ A) ¢> A) 
(2) 
((A v A) $ A) 
(Ԯ) 
((A 1\ B) $ (B 1\ A)) 
( 4) 
( (A v B) $ ( B v A)) 
(5) 
((A 1\ (B 1\ C)) y ((A 1\ B) 1\ C)) 
( 6) 
( (A v ( B v C)) $ ( (A v B) v C)) 
(7) 
((A 1\ (B v C)) $ ((A 1\ B) v (A 1\ C))) 
(8) 
((A v (B 1\ C)) $ ( (A v B) 1\ (A v C,))) 
(9) 
((A 1\ (A v B)) ¢> A) 
( 1 0) 
((A v (A 1\ B)) ¢> A) 
(l l )  (_,(A v B) {} (_,A 1\ _,B)) 
( 1 2) 
(_,(A 1\ B) $ (_,A v -,B)) 
( 1 3) 
((A 1\ T) {} A) 
( 1 4) 
( (A v .L) {} A) 
( 1 5) 
( (AA _L) {} _L) 
(16) 
((A v T) $ T) 
( 1 7) 
((A ==} B) {} (-rB ==} -rA)) 
These tautologies reflect important properties. Numbers (1) and (2) express the 
idempotence of conjunction and disjunction, (3) and (4) their commutativity, (5) 
and (6) their associativity, (7) and (8) the distributivity of each over the other. 
But be careful! All this is taking place up to logical equivalence (which is to say 
that these properties are really properties of operations on the set :F I Ȇ of equiv­
alence classes for the relation ӡ on F: for more details, refer to Exercise 1 from 
Chapter 2). Numbers (9) and (10) are called the absorption laws. Numbers ( 1 1 )  

32 
P R O P O S I T I O N A L  C A L C U L U S  
and ( 1 2) express de Morgan's laws (see Chapter 2 as well). Tautology number ( 13) 
(respectively, number ( 14 )) expresses that the class of tautologies 1 (respectively, 
the class of antilogies 0) is the identity element for conjunction (respectively, for 
disjunction). Number ( 15) (respectively, number (1 6)) expresses that the class 0 
(respectively, the class 1) is the zero element for conjunction (respectively, for 
disjunction). The formula ( _,B => _,A) is called the contrapositive of (A => B) 
and tautology number ( 17) expresses that every implicative formula is logically 
equivalent to its contrapositive. 
We will now continue our list with additional common tautologies: 
( 1 8) 
(A v _,A) 
( 19) 
(A => A )  
(20) 
(A <=> A )  
(21) (-.-.A =? A )  
(22) 
(A => (A v B)) 
(23) 
((A 1\ B) =? A) 
(24) 
(((A =} B) 1\ A) =? B) 
(25) 
(((A => B) 1\ -.B) => -.A) 
(26) 
((-.A =? A) =? A) 
(27) 
((-.A =? A) <=> A )  
(28) 
(-.A => (A =? B)) 
(29) 
(A v (A =? B)) 
(30) 
(A => (B =? A)) 
(3 1 )  
(((A => B ) 1\ (B =? C )) => ( A =>  C)) 
(32) 
((A =? B) v (C =? A )) 
(33) 
((A =} B) v (-.A => B)) 
(34) 
((A =? B) v (A =? -,B)) 
(35) 
((A =? B) => ((B => C) =?  (A :::;> C))) 
(36) 
(-,A =? (-.B <=> (B =? A ))) 
(37) 
((A => B) => (((A => C) => B) => B)) 
Moreover, in the list below, formulas that are all on the same line are pairwise 
logically equivalent. 
(38) 
(A =? B), (-.A v B), (-.B => -.A), ((A 1\ B) {:? A), ((A v B) {:? B) 
(39) 
_,(A =? B), (A 1\ -.B) 
(40) 
(A # B), ((A 1\ B) v (_,A 1\ -.B)), ((-.A v B) 1\ (-1B v A)) 
(41 )  (A <=> B), ((A => B )  1\ (B =? A )), (-ȕA <=> -.B), (B <=> A )  
(42) 
(A <=> B), ((A v B) =? (A 1\ B)) 
(43) 
-.(A <=> B), (A <=> -.B), (-,A # B) 
( 44) 
A , -.-.A, (A 1\ A), (A v A), (A v (A 1\ B)), (A 1\ (A v B)) 
(45) 
A ,  (-.A => A), (A => B) => A), ((B => A) 1\ (-.B =? A )) 
(46) 
A ,  (A 1\ T), (A v T), (A <=> T), (T => A )  
(47) 
-.A, (A =? -.A), ((A =? B) 1\ (A =? -.B)) 
(48) 
-.A, (A =>_L), (A ¢>_L) 

( 49) _.L, (AI\ l_), (A % --·A) 
S E M A N T I C S  
(50) 
T, (A v T), (A ==> T), (J-=> A) 
(5 1 )  (A 1\ B), ( B 1\ A), (A 1\ (-.A v B)), -.(A => -.B) 
(52) 
(A v B), (B v A), (A v (-OA ;, B)), (-,A => B), ((A => B) ==> B) 
(53) 
(A ==> (B =} C)), ((A 1\ B) :::} C), (B ==> (A ==> C)), ((A ==> B) ==> 
(A ==> C)) 
(54) 
(A ==> (B 1\ C)), ((A => B) 1\ (A ==> C)) 
(55) 
(A ==> (B v C)), ((A ==> B) v (A ==> C)) 
(56) 
((A A B) => C), ((A  C) v (B ==> C)) 
(57) 
((A v B) ==> C), ((A => C) 1\ ( B  ==> C)) 
(58) 
(A {} (B {} C)), ((A {} B) {} C). 
33 
We should take notice, from lines (54) to (57), that implication does not distribute 
over conjunction nor over disjunction. We see however that it does distribute from 
the left ((54) and (55)), which is to say when 1\ and v occur to the right of=>. In the 
case when one or the other is located to the left of ੕, we have a kind of artificial 
distributivity, the ;, (respectively, the v) being transformed into v (respectively, 
into t,) after its 'distribution' ((56) and (57)). It behoves us to be vigilant in all 
cases when manipulating this type of formula. 
From now on, we will admit the following abuses of notation: 
• In general, in writing a formula, we will allow ourselves to omit the outer­
most parentheses. This convention supposes that these parentheses automati­
cally reappear as soon as this formula occurs as a (strict) sub-formula of another 
formula: for example, we will accept the formula F = A  ¢> B, and the formula 
F ==> -.c, but the latter will obviously be written (A {} B) => --.c and not as 
A. ¢> B =? _,C. 
• For all formulas F, G, and H, 
the formula ((F 1\ G) 1\ H) will be written (F 1\ G ;, H), 
the formula ((F v G) v H) will be written (F v G v H). 
We could also, by applying the previous convention concerning the omission of 
parentheses, write F 1\ G 1\ H or F v G v H. 
• More generally, for any non-zero natural number k, if Fr , F2, . . .  , Fk are 
formulas, we will let Fr 1\ F2 1\ - · - 1\ Fk represent the formula 
(which begins with k - 1  occurrences of the open parenthesis symbol). Of course 
we make the analogous convention for disjunction. 
• If I = {i 1 , i 2, . . . , ik} is a non-empty finite set of indices and if F; 1 '  Fi2 ,  •
•
•
 , Fik 
are formulas, the formula F; 1 A Fh 1\ · · · 1\ Fik will also be written: 
(to be read as 'the conjunction of the F j for j belonging to I'). 

34 
P R O P O S I T I O N A L  C A L C U L U S 
We will notice that with this notation, there is an ambiguity relating to the order 
of the indices in the set I, which needs to be fixed for this manner of writing 
to have a meaning. But in fact੒ as long as we are concerned with semantics, the 
choice of this ordering has no importance whatever in view of the commutativity 
of conjunction. 
In the same way, the formula F;1 v F;2 v · · · v Fik will be abbreviated: 
V F· 
.I 
jE/ 
(to be read as 'the disjunction of the F.i for j belonging to /'). 
Naturally, we will also have variants, such as V 1 <k<n Gk or 1\FEX F (where X 
is a non-empty finite set of formulas), whose meaning is clear. 
In fact, our decision, for example, that the expression A v B v C represents 
the formula ((A v B) v C) is based on an arbitrary choice. We could just as well 
have opted for the formula (A v (B v C)) which is logically equivalent to the 
first one. It is the associativity of conjunction and disjunction (numbers (5) and (6) 
from Section 1 .2.3) that led us suppress these parentheses knowing that, whatever 
method is used to reintroduce them, we obtain a formula from the same equivalence 
class. (In Exercise 16, we will understand why it would be imprudent to allow the 
analogous abuses of notation in the case of {} ,  although this appears, according 
to number (58) from Section 1 .2.3, to allow it just as well as 1\ and v). 
1.3 Normal forms and complete sets of connectives 
1.3.1 Operations on {0, 1} and formulas 
Up to and including Section 1 .3.3, we will assume that the set P of propositional 
variables is a finite set of n elements (n > 1): 
P == {A1, A2, . . .  , An}-
This allows us to consider that every formula F E F has its variables among 
A t , A 2, . . .  , An and to write F == F [A 1 , A 2, . . .  , A 11 j. 
Notation: 
• For every n-tuple (EI ,  £2, . . .  , En) E {0, l}n , 8€1 ,€2, 
• . .  ,811 denotes the distribution 
of truth values defined by 881 ,82, 
. . .  ,€11 (A;) == £; for each i E { 1 ,  2, . . .  , n }. 
• For each propositional variable A and for each element £ E {0, 1 }  we let EA 
denote the formula that is equal to A if£ == 1 and to _,A if£ == 0. 
For each formula F, we let 6. (F) denote the set of distributions of truth values 
that satisfy F: 
t:.r.(F) == {8 E {0, l}P 
: 8(F) == 1}. 

N 0 R M A L F 0 R M S A N D C 0 M P L E T E S E T S 0 F C 0 N N E C T I V E S 
35 
For each formula F, we define a mapping CfJF from {0, l}P into {0, 1} by 
The mapping CfJF is thus none other than the one defined by the truth table of F. 
We will allow ourselves the slight abuse of language involved in saying that <p F is 
the truth table of F. 
Notice that two formulas F and G are logically equivalent if andonly if cp F = cpc. 
What this means precisely is that the mapping F M (/JF (from F into {0, l}({O,l}n)) 
is compatible with the relation Ț. We also see that this mapping is not injective 
(for example, for any formula F, we have: cp-.-.F = CfJF ), but that the mapping 
that it induces, from F/ Ȇ into {0, l}({O,l}n) (the mapping ci(F) M (/JF) is injec­
tive (recall that ci(F) denotes the equivalence class of the formula F under the 
equivalence relation Ӧ ). This shows that the number of equivalence classes for 
the relation Ӧ on F is at most equal to the number of mappings from {0, 1 }n into 
{0, 1}, which is to say 22n . 
It remains to discover if there are exactly 22n equivalence classes of formulas or 
if there are fewer. In other words, is the mapping F M CfJF surjective? Or again, 
can the table of an arbitrary mapping from {0, 1}n into {0, 1} be viewed as the truth 
table of some formula? 
The answer to these questions is positive, as we will see with the next theorem. 
The proof of the theorem will furnish us with an explicit method for finding such 
a formula, knowing only its truth table. 
Lemma 1.25 For any n-tuple (ct, £2, . . . , en) E {0, l}n, the formula 
is satisfied by the distribution of truth values 881 ,82, ... ,817 and by no othe1: 
In our notation, this would be written: Ƀ(/\1 :s_k:s_n E'kAk) = {881 .82, 
. . . •  8n }. 
Proof For any distribution of truth values A., we have A.(/\ 1 <k<n E'k Ak) = 1 i f  and 
only iff or every k E { 1 , 2, . . .  , n}, A. ( £ k A k) = 1, which, in view of the definition 
of 881 ,82, 
. • . . en , is equivalent to: 
in other words, to A. = 881 ,82, ... ,8, 
• 
• 
Lemma 1.26 Let X be a non-empty subset of {0. l }n and let F x be the formula 
Then the formula F x is satisfied by those distributions of truth values 881 ,82, ... ,811 
for which (EI , E2, •
.
.
 , en) E X and only by these. 

36 
P R O P O S I T I O N A L  C A L C U L U S  
With our notations, 
Proof For any distribution of truth values A, we have A(Fx) = 1 if and only if 
there exists ann-tuple (8t , 82, . . .  , 8n) E X  such that A.( A1 <i<n Bi Ai) = 1, which, 
according to Lemma 1 .25, isequivalentto:thereexists ann-tuple (8I , 82, . . .  , 811) E 
X such that A = 8£1 ,£2, • • •  ,811 , or equivalently, to 
• 
Theorem 1.27 For any mapping cp from {0, l}n into {0, 1 } ,  there exists at least 
one formula F such that cp F = cp. 
(In other words, every mapping from {0, 1}11 into {0, l} is a truth table). 
Proof Fix a mapping <p from {0, l}n into {0, l}. 
• I fit assumes only the value 0, then it is a truth table, for example, of the formula 
F = (At 1\-,A I). 
• In the opposite case, the set 
is non-empty and, by virtue of Lemma 1 .26, the formula 
is satisfied by those distributions of truth values 861 ,62, .... 611 for which 
cp(t:1 , 82, . . . , t:11) = 1 and only by these. 
In other words, for any n-tuple (8t ,  £2 , . . . , En) E {0, 1 }n, we have 
8c1,c2, 
• . • ,sn (F) = 1 if and only if cp(8I , 82, . . . , 8n ) = 1. 
This means precisely that <p is the function <p rx , the truth table of the formula F . 
• 
Thus we see that there are 2211 equivalence classes of formulas on a set of n 
propositional variables, corresponding to the 2211 possible truth tables. 
Mappings from {0, 1 }17 into {0, l }  are sometimes called n-place propositional 
connectives. We see that it is harmless to identify such an object with the class of 
formulas which is naturally associated to it 
In the cases n = I and n = 2 which we will examine in detail (and which lead 
respectively to 4 and to 1 6  truth tables), we will rediscover, among the common 

N 0 R M A L F 0 R M S A N D C 0 M P L E T E S E T S 0 F C 0 N N E C T I V E S 
37 
names for these one- or two-place connectives, names that were already used to 
denote symbols for propositional connectives. Thus, for example, v simultane­
ously denotes the symbol for the propositional connective and the equivalence 
class of the formula (A1 v A2) as well as the corresponding mapping from {0, 1}2 
into {0, 1 }. 
Tables 1 . 1  and 1 .2 present all the two-place and one-place propositional con­
nectives (cp1 to <pi6 and 1/11 to 1/14). The first columns give the values of each 
mapping at each point of {0, 1}2 or of {0, 1}. The column that follows gives a 
formula belonging to the corresponding equivalence class. Finally, the last column 
displays the symbol in common use, if any, that represents the connective or its 
usual name. 
Table 1.1 The two-place connectives 
Values of cp; 
Example of a 
Usual denotation for CfJi 
formula whose 
E1 
0 
0 
1 
1 
truth table is cp; 
E2 
0 
1 
0 
1 
Symbol 
Name 
- ----·-
______ ... _ 
CfJl ( E I ,  E2) 
0 
0 
0 
0 
(AJ A -.A J ) 
0 
FALSE 
CfJ2(E ! ,  E2) 
0 
0 
0 
1 
( A 1 A A2) 
" 
AND 
CfJ3(E l ,  E2) 
0 
0 
1 
0 
-.(AJ ? A2) 
=I? 
DOES NOT IMPLY 
CfJ4(EJ , E2) 
0 
0 
I 
1 
A ,  
C{J)(fl , E2) 
0 
1 
0 
0 
-.(A2 => A 1 )  
CfJ6(Et , E2) 
0 
1 
0 
1 
A2 
CfJ7(E J ,  E2) 
0 
1 
1 
0 
-.(AI ¢> A2) 
{/} 
NOT EQUIVALENT 
cpg(E J .  E2) 
0 
1 
1 
1 
(AJ v A2) 
v 
OR 
C{J9(E i , E2) 
1 
0 
0 
0 
-.(A 1 v A2) 
'¥ 
SHEFFER'S 'OR' 
CfJJO(EJ , E2) 
1 
0 
0 
1 
(A, ¢> A2) 
{:} 
IS EQUIVALENT TO 
C{JJ ] (EJ, E2) 
I 
0 
I 
0 
-.A2 
CfJJ2(!: J ,  E2) 
1 
0 
1 
1 
(A2 ? A J )  
C{JJJ (EJ, E2) 
I 
1 
0 
0 
-.A I 
f/)J4( EJ ,  E2) 
1 
1 
0 
1 
(A , @ A2) 
=> 
IMPLIES 
C{JJS(EJ , E2) 
l 
1 
1 
0 
-.(A 1 A A2) 
,f\ 
SHEFFER'S 'AND' 
CfJJ6(EJ , E2) 
1 
I 
1 
1 
(At v -.A J )  
1 
TRUE 
Table 1.2 The one-place connectives 
Values of 1/1; 
Example of a 
Usual 
formula whose 
designation 
E) 
0 
1 
truth table is 1/li 
of 1j1; 
1/JJ ( E I )  
0 
0 
(AJ " -.A I )  
0 
(FALSE) 
1/12 ( E I) 
0 
1 
A t 
IDENTITY 
1/13 ( E I )  
1 
0 
-.AI 
--., 
(NOT) 
1/14( EI) 
1 
I 
(AJ v -.A I )  
1 
(TRUE) 

38 
P R O P O S I T I O N A L  C A L C U L U S  
1.3.2 Normal forms 
There are important consequences of Theorem 1 .27. Before examining them, we 
need some definitions: 
Definition 1.28 
( 1 )  A formula F is in disjunctive normal form (DNF) ěf and only if there exist 
(a) an integer m > 1 ,  
(b) integers k1, k2, ... , km > l, 
(c) for every i E { 1, 2, . . .  , m}, k; propositional variables: Bit, B;2, ... , B;k, 
and k; elements 8; 1 ,  8;2, ... , 8; ki in {0, 1}, such that 
F == V (8; 1 Bil 1\ 8;2B;2 1\ · · · 1\ 8ik; B;ki ). 
J <i<m 
(2) A formula F is in canonical disjunctive normal form (CDNF) if and only if 
there exists a non-empty subset X of{O, l}n such that 
F ==  
V ( (\ 8;A;) 
(€1 ,€2, ... ,€n )EX 
1 <i <n 
(3) By interchanging the symbols for disjunction and conjunction in parts (1) 
and (2), we obtain respectively the definitions of a formula being in conjunctive 
normal form (CNF) and a formula being in canonical conjunctive normal 
form (CCNF). 
These definitions call fora few remarks. First of all, we see that to be in canonical 
disjunctive normal form is a special case of being in disjunctive normal form (the 
case where each k; is equal to n, where for each i E { 1 ,  2, ... , n} and j E 
{ 1 ,  2, ... , m}, Bij == A j and where the m n-tuples 8; 
1 ,  8;2, . . .  , 8iki are pairwise 
distinct; note, in passing, that this forces m to be at most equal to 2n). 
Furthermore, by examining the proof of Theorem l.27, we see that given a 
mapping cp from {0, l }n into {0, 1} distinct from the zero mapping, there exists a 
formula F in canonical disjunctive normal form such that ({JF == cp. (The formula 
Fx that we have been considering is certainly in CDNF.) As well, we conclude 
a kind of uniqueness for canonical disjunctive (or conjunctive) normal forms, in 
the sense that two canonical disjunctive (or conjunctive) normal forms which are 
logically equivalent can differ only in the 'order of their factors'. More precisely, 
if the formulas: 
( (\ s; A;) and 
V ( (\ r}; A;) 
J<i<n 
(171JJ2 • . • •  ,1Jn)EY 
J <i<n 
are logically equivalent, then the subsets X and Y of {0, l}n are identical. The 
analogous fact is obviously true for conjunctive normal forms. 

N 0 R M A L F 0 R M S A N D C 0 M P L E T E S E T S 0 F C 0 N N E C T I V E S 
39 
These remarks lead us to the following normal form theorem: 
Tht:Ȗorem 1.29 Every formula is logically equivalent to at least one formula in 
disjunctive normal form and to at least one formula in conjunctive normal form. 
Any formula that does not belong to the class 0 is logically equivalent to a unique 
formula in CDNF; every formula that does not belong to the class 1 is logically 
equivalent to a unique formula in CCNF, where uniqueness is understood to be 
'up to the order of the factors'. 
Proof Let F be a formula. 
• If F is a tautology, it is logically equivalent to A 1 v -,A 
1 ,  which is both a DNF 
and a CNF. 
• If ...,p is a tautology, F is logically equivalent to A 
1 1\ ...,A 1 ,  which is DNF and 
CNF. 
• In the other cases, we have just observed that F is logically equivalent to a 
formula in CDNF. But this is also true for ...,p, which means that there is a 
non-empty subset X of {0, 1}n such that 
v 
(Et ,£2, ... ,£n)EX 
Therefore we have 
(by de Morgan's laws). This last formula, once we delete any double negations, 
is in CCNF. 
The second part of the theorem clearly follows from the first and from the remarks 
that preceded it. 
• 
We can therefore speak of 'the CDNF' of a formula (provided it is not an antilogy) 
and of 'the CCNF' of a formula (provided it is not a tautology). 
The normal form theorem also furnishes us with a practical method for obtaining 
the CDNF and the CCNF of a formula (when they exist) once we know its truth 
table. Thus, for example, the formula 
G = (A  (((B 1\ ...,A) v (-,C 1\ A)) ¢> (A v (A ? ...,B)))), 
whose truth table was given in Section 1 .2.1, is satisfied by the distributions (0,0,0)Æ 
(0,0,1), (0,1,0), (0,1,1), (1,0,0), (1,0,0) and (1,1,0), while -.G is satisfied by (1,0,1) 

40 
P R O P O S I T I O N A L  C A L C U L U S  
and (1,1,1 ). From this we conclude that the CDNF of G is 
(-,A 1\ -,B 1\ -,C) v (-,A 1\ -,B 1\ C) v (-,A 1\ B 1\ -.C)v 
(-.A 1\ B 1\ C) v (A 1\ -.8 1\ -.C) v (A 1\ B 1\ -,C), 
and the CDNF of _,G is 
(A 1\ -,B 1\ C) v (A 1\ B 1\ C), 
and finally the CCNF of G is 
Remark 1.30 We should mention that formulas of the type Bi A; are sometimes 
called literals (mostly by computer scientists), that formulas of the type V kEJ '1k Bk 
(i.e. a disjunction of literals) are often called clauses and that conjunctive nor­
mal forms are then called clausal forms. We will encounter this terminology in 
Chapter4. 
1.3.3 Complete sets of connectives 
In a formula that is in disjunctive normal form, the only symbols for connectives 
that can occur are -,, A and v. So we may conclude from Theorem 1 .29 that every 
formula is equivalent to at least one formula in which these are the only connectives 
that may appear. 
This property can be restated in terms of propositional connectives, that is, in 
terms of operations on {0, 1}: 
Lemma 1.31 For every integer m > 1 ,  every mapping from { 0, 1 }m into { 0, 1} can 
be obtained by composition of the mappings -, (from {0, 1} into {0, 1} ) , together 
with 1\ and v (ji--om (0, l }2 into {0, 1} ) . 
Proof Let m be a non-zero natural number and cp be a mapping from {0, 1 }m 
into { 0, 1}. Choose a formula F which has cp as its truth table and which is written 
with no symbols for connectives other than -., 1\ and v (for example, a formula 
in DNF). The decomposition tree of F then gives us a composition of mappings 
taken from among the mappings -., 1\ and v which coincides with the function cp. 
Without going into uselessly heavy detail, let us be satisfied with an example. 
The mapping cp from {0, 1}3 into {0, 1} which assumes the value 0 for (1,0,1) 
and (1,1,1) and the value 1 for the six other triples in {0, 1}3 is, as we have already 
shown above, the truth table of the formula 
(Here we chose the CCNF, which is much shorter than the CDNF and is also 
written using only -,, 1\ and v). 

N O R M A L  F O R M S  A N D  C O M P L E T E  S E T S  O F  C O N N E C T I V E S  
41 
The truly correct way to write this formula is 
(((ҡA v B) v ਙC) 1\ ((-,A v ǚB) v C)) . 
We conclude that for any elements x, y and z from {0, 1}, we have 
cp(x, y, z) = A(v(v(Cx, y), Cz), v(v(Cx, ǚy), 0z)) . 
(In this expression, ǚ, 1\ and v are on this occasion denoting operations on {0, 1} ) . 
We see that the operations ǚ, 1\ and v generate all possible operations (with any 
number of places) on {0, 1}. 
• 
We express the property that has just been exhibited by saying that { ǚ, 1\, v} is 
a complete set of connectives. 
Definition 1.32 A set of connectives is called complete if it generates, under 
composition, the set of all pro positional connectives. A complete set of connectives 
is called minimal when no proper subset is a complete set of connectives. 
The set { ǚ, 1\, v} is not a minimal complete set. Actually, with every formula 
F which involves no connectives other than 
, 1\ and v we can associate a log­
ically equivalent formula that involves only the symbols for connectives 
 and 
v: it suffices to substitute, for each sub-formula of F of the form (H 1\ K), the 
logically equivalent formula ǚ( ǚHv ǚK), repeating the operation as many times 
as necessary to eliminate all the /\. This shows that { 

, v} is a complete set of 
connectives that is a proper subset of { --,, 1\, v} . 
The set {  , v} is a minimal complete set. To be sure, it is sufficient to show that 
{-,} and { v} are not complete sets. 
Formulas in which no symbol for a connective other than ǚ occur are the formu­
las of the type - . .
. ȗA (a propositional variable preceded by a finite number, 
possibly zero, of occurrences of the symbol 
) . A formula of this type is logically 
equivalent either to A or to ҡA, and it is clear that there are formulas (for example, 
(A v B)) that are not logically equivalent to any formula of this type. Thus., { 
0} 
is not complete. As for {v}, note that a formula in which the only symbol for a 
connective that occurs is v will be satisfied by the distribution of truth values 81 
defined by 81 (X) = 1 for every propositional variable X. This can be proved with­
out difficulty by induction (Exercise 20). From this we conclude that the formula 
Ș A 1 ,  which takes the value 0 for 81., cannot be logically equivalent to any formula 
which uses only v as a symbol for a connective. Thus { v} is not complete. 
ln Exercise 15, we will see that each of the connectives known as Sheffer strokes 
(tand ्) has the property of being, by itself alone, a complete set of connectives. 
We will also show that, among the one- or two-place connectives. these are the 
only ones with this property. 
Remark 1.33 Suppose we wish to show, by induction, that a certain p1vperty 
X(F) is trueforeveryformula F E :F, and suppose that this property is compatible 
with the relation rv (which is to say that any formula that is logically equivalent to 

42 
P R O P O S I T I O N A L  C A L C U L U S  
a formula having property X also has the property). We can then exploit the fact 
that { -., v} is a complete set by limiting ourselves, in the proof by induction, to the 
induction steps relating to ..., and to v. If we prove that X(F) is true when F is 
an element of P, and that, whenever X(F) and X(G) are true, then X(-.F) and 
X((F v G)) are also true, this will guarantee that the p1vperty X is true for all 
formulas in which no symbols for connectives other than -·and v occur. Now let H 
beanarbitraryformulafromF. Since{-., v} is complete, His logically equivalent 
to at least one formula K which can be written using only these connectives. So 
X(K) is true, and since X is compatible with""', X(H) is also true. Of course, 
this remark applies just as well to any other complete set of connectives. 
To give an example, note that in the proof of Theorem 1.22 we could have 
legitimately dispensed with the steps relating to v, :::} and {:? thanks to the remark 
that was just made (for { -., 1\ }  is a complete set), to the compatibility of the 
property in question with ""' (which is obvious)ɸ and subject to verifying that the 
completeness of the set { -., v} can be proved without recourse to Theorem 1 .22 
(otherwise we would be running in circles!). 
1.4 The interpolation lemma 
1.4.1 Interpolation lemma 
Lemma 1.34 Let F and G be two formulas having no pro positional variable in 
common. The following two p1vperties are equivalent: 
( 1 )  The formula ( F => G) is a tautology. 
(2) At least one of the formulas -,For G is a tautology. 
Proof It is clear first of all that the second property implies the first: for any 
distribution of truth values 8, we have 8 (G) = 1 if G is a tautology and 8 (F) = 0 
if .., F is one. In both cases, 8 ( ( F :::} G)) = 1. 
Now suppose that property (2) is false. Then we can choose a distribution of 
truth values A. such that A.( -.F) = 0, which is to say A.(F) = 1, and a distribution 
of truth values tt such that tL( G) = 0. Now define a distribution of truth values 8 
by setting, for each propositional variable X, 
8(X) = { A.( X) if X occurs at least once in F; 
ॊ-t(X) if X does not occur in F. 
Since, by hypothesis, any variable that occurs in G cannot occur in F, we see that 
8 coincides with A. on the set of variables of F and with 11- on the set of variables of 
G. Weconclude (Lemma 1.19) that8(F) = A.(f,) = 1 and that8(G) = t-t(G) = 0, 
and, consequently, that 8 ( (f, ::::> G)) = 0. So property (1) fails. 
• 
The following result is known as the interpolation lemma: 
Theorem 1.35 Let n be a non-ze1v intege1; A 1 ,  A2, ... , An pairwise distinct 
propositional variables, and F and G two formulas that have (at most) the 

T H E  I N T E R P O L A T I O N  L E M M A  
43 
propositional variables A1, A2, . . .  , An in common. The following two proper­
ties are equivalent: 
( 1 )  Theformula (F => G) is a tautology. 
(2) There is at least one formula H, containing no propositional variables other 
than A 1, A2, . . .  , An, such that the formulas 
(F => H) and (H => G) 
are tautologies. 
(Such a formula H is called an interpolant between F and G). 
Proof Suppose Ҡ* (F z H) and Ҡ* (H z G) and consider an arbitrary distri­
bution of truth values 8. If 8(H) = 0, then 8 (F) = 0 (because 8((F => H)) = l); 
if 8 (H) = l, then 8 (G) = 1 (because 8((H => G)) = 1). In both cases, 
8((F=> G)) = 1, which proves property ( 1). 
To show the converse, we will assume ो* (F => G) and argue by induction on 
the number of propositional variables which have at least one occurrence in F but 
have none in G. 
• If this number is zero, then by setting H = F we clearly obtain a formula which 
contains no propositional variables other than A t ,  A2, . . .  , An and is such that 
1-* (F => H) and Ș* (H => G). 
• Suppose (the induction hypothesis) that property (2) is true for formulas F 
that contain at most m variables that do not occur in G and let us examine 
the case in which there are m + 1 .  Let 81 , B2, . . .  , Bm, Bm+I denote the 
variables of F that do not occur in G. According to our conventions, we thus 
have F = F[A 1 ,  A2, . . .  , An, B1, 82, . . .  , Bm, Bm+I l- Set 
F 1 = F [A 1 , A 2, . . .  , An , B I , B 2, · · · , B m ' A 1 ] = FA]/ B m+ 1 
Fo = F[A I , A2, . . .  , An, B1 , B2, . . .  , Bm, -.A I ] = F_,A1/Bm+l " 
Notice that because Bm+I does not occur in G, the result of substituting the 
formula A1 for the variable Bm+l in the formula ( F  => G) is the formula 
(F1 => G), and the result of substituting the formula -.AI for the variable Bm+l 
i n  the formula (F => G) is the formula (Fo => G). Invoking Corollary 1 .23 
and our hypothesis, we conclude that ( Ft => G) and ( Fo => G) are tautologies, 
and hence so are the formulas 
((Ft => G) 1\ (Fo => G)) and ((FI v Fo) => G) 
(see number (57) in our list in Section 1 .2.3). 
The variables in the formula (FI v Fo) are among A 1 ,  A2, . . .  , An, Bt , B2, . . .  , Bm. 
So we can apply our induction hypothesis and find a formula H that is an interpolant 

44 
P R O P O S I T I O N A L  C A L C U L U S  
between ( F 1 v Fo) and G, which is to say that its variables are among A 1 , A 2, . . .  , An 
and it is such that 
f-* ((Ft v Fo) ==> H) and f-* (H ==> G). 
We will now show that ( F ==> ( Ft v Fo)) is also a tautology. This will conclude the 
proof since we can then conclude (invoking tautology number (31 )) f-* (F==>H), 
which will make H an interpolant between F and G. 
So let o be an assignment of truth values which satisfies F. We have (by 
Theorem 1 .22): 
either o(A J )  == o(Bm+t )Ҟ and in this case o(Ft ) == o(F) == l, 
or else o(At) # o(Bm+l ), and so o(Fo) == o(F) == 1. 
In all cases, o((Ft v Fo)) == 1. And so t-* (F ==> (Ft v Fo)). 
• 
1.4.2 The definability theorem 
Here is a corollary of the interpolation lemma, the definability theorem: 
Theorem 1.36 Let A , B, A 1 , A 2, . . .  , Ak be pairwise distinct propositional vari­
ables and F == F[ A, A 1 ,  A2, . . .  , Ak] be a formula (whose variables are therefore 
among A, A t ,  A2, . . .  , Ak). We assume that theformula 
is a taurology. Then there exists a formula G == G[A 1 ,  A2, . . .  , Ak], whose only 
variables are among A 1 ,  A2, . . .  , Ak and is such that the formula 
is a tautology. 
Intuitively, the hypothesis is saying that the formula F[A, A 1 ,  A2, . . .  , AkJ 
determines the value of A as a function of the values of A I ,  A2, . . .  , Ab in the 
sense that distributions of truth values that satisfy F and that assign the same 
value to A 1 , A 2, . . .  , Ak must also assign the same value to A; the conclusion 
is that the value thereby assigned to A is the value taken by a certain formula 
G [A 1 , A2, . . .  , Ak] which does not depend on A and which could be called a 
'definition of A modulo F'. Exercise 1 8  suggests a proof of the theorem directly 
inspired by this intuition. Here, we are content to apply the preceding lemma. 
Proof Taking into consideration numbers (41 ), (53), and (54) from our list in 
Section 1 .2.3, the hypothesis leads successively to the following tautologies: 
f-* ((F[A, A t ,  A2, . . .  , Ak] 1\ FIB, At, A2, . . .  , Ak]) ==> (A ==>  B)), 
f-* (((F[A, A 1 ,  A2, . . .  , Ak] 1\ Ff B, A 1 ,  A2, . . .  , Ak]) 1\ A) ==> B), 
f-* (((F[A, A t ,  A2 , . . . , Ak] A A) A F[B, A1 , A2, . . .  , Akl) ौB), 
f-* ((F[A, A I ,  A2, . . . , Ak] 1\ A) => (F[B, A I ,  A2, . . .  , Ak] :=> B)). 

T H E  C O M P A C T N E S S  T H E O R E M  
The interpolation lemma then guarantees the existence of an interpolant 
G [A I , A 2, . . .  , Ak] between ( F [A, A I , A 2, . . .  , Ak] 1\ A) 
and (F[B, A t ,  A2, . . .  , Ak]) ==> B). 
So, in particular, 
I-* ((FlA, A t ,  A2 , . . .  , Ak] 1\ A) ==> G) 
and hence 
I-* (F[A , A t ,  A2 , . . .  , Ak] ==? (A =>  G)). 
On the other hand, 
and so 
f-* ((G 1\ FlB, A t ,  A2, . . .  , Ak]) => B) 
I-* ((F[B, A t ,  A2, . . .  , Ak] 1\ G) => B), 
I-* (F[B, A t ,  A2, . . .  , Ak] ==> (G ==> B)). 
45 
The result of substituting A for B in this latter formula is again a tautology 
(Corollary 1 .23 ): 
1-* (F[A, A 1 ,  A2, .
.
.
 , Ak] => (G => A)). 
Properties (*) and (**) together with tautologies (41 ) and (54) from Section 1 .2.3 
finally give us 
1.5 The compactness theorem 
1.5.1 Satisfaction of a set of formulas 
• 
Definition 1.37 Let A and B be two sets offormulas of the propositional calculus 
on the set of propositional variables P, let G be a formula and let 8 be a distribution 
(ųf truth values on P. 
• A is satisfied by 8 (or 8 satisfies A) if and only if 8 satisfies all the formulas 
belonging to A. 
• A is satisfiable (or consistent, or non-contradictory) if and only if there exists 
at least one distribution of truth values that satisfies A. 
• A is finitely satisfiable if and only if every finite subset of A is satisfiable. 
• A is contradictory if and only if it is not satisfiable. 

46 
P R O P O S I T I O N A L  C A L C U L U S  
• G is a consequence of A (which we denote by: A t-* G) if and only if every 
distribution of truth values that satisfies A satisfies G. 
(The notation for 'G is not a consequence of A' is: A J.L* G). 
• A and B are equivalent {f and only if every formula of A is a consequence of 
B and every formula of B is a consequence of A. 
For example, consider pairwise distinct propositional variables A ,  B, A 1 , 
A2, . . .  , Am, . . .  : the set {A, B ,  (_,A v B)} is satisfiable; {A, _,B, (A :::} B)} 
is contradictory; the empty set is satisfied by any distribution of truth values what­
ever (if this were not true, we could find a distribution of truth values 8 and a 
formula F E 0 such that 8 ( F) == 0; but such a feat is clearly impossible . . .  ). 
We have 
{A, B }  I-* (A 1\ B) and {A, (A Ý B)} I-* B .  
The sets {A, B }  and { ( A  1\ B ) }  are equivalent, as are the sets 
The following lemma lists a certain number of properties that follow from these 
defi.nitions. Nearly all of them are immediate consequences. It will profit the begin­
ning reader to carefully prove all of these. We will content ourselves with proving 
the three properties marked by two bullets ( ••) rather than one. 
Lemma 1.38 For all sets of formulas A and B, integers m and p > 1, and 
formulas G, H, F1 , F2, . . .  , Fm and G 1 ,  G2, . . .  , G P' the following properties 
are ver{fied: 
• A I-* G f'and only if A U  { _,G} is contradictory. 
• If A is satisfiable and if B c A, then B is satisfiable. 
• If A is satisfiable, then A is finitely satisfiable. 
• {fA is contradictory and if A C B, then B is contradictory. 
• If A +* G and if A c B, then B I-* G. 
• A u  {G} I-* H if and only if A I-* (G :::} H). 
• A I-* (G 1\ H) if and only if A I-* G and A I-* H. 
• { FI ,  F2, . . .  , Fm } I-* G if and only ifl-* ((FI A F2 1\ . . .  1\ Fm) :::} G). 
• 
• G is a tautology {{and only ifG is a consequence of the empty set. 
• G isatautologyifandonly {fG is a consequence of any setofformulaswhateveJ: 
• A is contradicto1y {f and only {fA I-* (G A -,G). 
• A is contradictory if and only if every formula is a consequence of A. 
• A is contradicto1y if and only if every antilogy is a consequence of A. 
• A is contradictory if and only if there exists at least one antilogy that is a 
consequence of A. 

T H E  C O M P A C T N E S S  T H E O R E M  
47 
• { FJ , Fz, . . . , Fm } is contradictory {{and only if(-,FJ v -,pz v . . .  v _, Fm) is a 
tautology. 
• A and B are equivalent if and only if they are satisfied by the same assignments 
of truth values. 
• When we replace each formula in Abya Logically equivalent formula, we obtain 
a set that is equivalent to A. 
• If A is contradictory, then B is equivalent to A if and only if B is contradictory. 
• 
• A is equivalent to the empty set if and only {f every formula belonging to A 
is a tautology. 
• The empty set is satisfiable. 
• The set :F of all formulas is contradictory. 
• The sets { G} and {H} are equivalent if and only if the formulas G and H are 
Logically equivalent. 
• The sets { F1 , Fz, . . .  , Fm } and { G 1, Gz, . . .  , G p} are equivalent {f and only if 
the formula ((F1 1\ Fz 1\ · · · 1\ Fm) <=> (G1 A Gz 1\ . . .  1\ G p)) is a tautology. 
• Every finite set of formulas is equivalent to a set consisting of a single formula. 
• 
• When the set P is infinite, and only in this case, there exist sets of formulas 
that are not equivalent to any finite set of formulas. 
• The binary relation 'is equivalent to' is an equivalence relation on the set of 
subsets of F. 
Proof 
•• I-* G if and only if 0 I-* G: because the empty set is satisfied by every 
distribution of truth values, G is a consequence of the empty set if and only if 
every distribution of truth values satisfies G, in other words: if and only if G is a 
tautology. Observe, as a result, that the notation ੑ* G for 'G is a tautology' seems 
natural. 
•• A is equivalent to 0 if and only if every element of A is a tautology: it is 
clear, first of all, that every formula belonging to 0 is a consequence of A, and 
this holds for any set A whatever (otherwise, there would be a formula belonging 
to 0 which would not be a consequence of A, and this is clearly impossible); 
so what we have to prove is that every formula in A is a consequence of 0 if 
and only if every formula in A is a tautology; but this is precisely the preceding 
property. 
•• P is infinite if and only if there exists a set of formulas that is not equivalent 
to any finite set: if P is fi.nite and has n elements, there are 22n classes of logically 
equivalent formulas; choose a representative from each class. We can then, given 
an arbitrary set of formulas X, replace each formula of X by the representative 
chosen from its equivalence class; the resulting set is equivalent to X and is finite 
since it can contain at most 22n elements. If P is infi.nite, consider the infinite 
set of formulas Y = {A 1 ,  Az, . . .  , Am, . . .  } (where the A; are pairwise distinct 
propositional variables); if Y were equivalent to a finite set of formulas Z, then Z 

48 
P R O P O S [ T I O N A L  C A L C U L U S  
would be satisfied, as is Y, by the constant distribution 81 equal to l, and we could 
choose at least one integer k such that the variable Ak does not occur in any of 
the formulas of Z (which are finite in number); so the distribution A which takes 
the value 1 everywhere except at Ak, where its value is 0, would still satisfy Z 
(Lemma 1 . 1 9) but would obviously not satisfy Y, thereby yielding a contradiction: 
thus we have a set Y which is not equivalent to any finite set. 
• 
1.5.2 The compactness theorem for propositional calculus 
We have arrived at what is incontestably the major theorem of this chapter. We 
will see several applications of it in the exercises. 
It can be stated in several equivalent forms: 
The compactness theorem, version 1: 
Theorem 1.39 For any set A of formulas of the propositional calculus, A is 
satisfiable if and only if A is finitely sati,ਗfiable. 
The compactness theorem, version 2: 
Theorem 1.40 For any set A of formulas of the propositional calculus, A is 
contradictory if and only ɕfat least one finite subset of A is contradictory. 
The compactness theorem, version 3: 
Theorem 1.41 For any set A of formulas (ਘ{the propositional calculus and for 
any formula F, F is a consequence of A if and only if F is a consequence of at 
least one finite subset (ւfA. 
Proof The proof that the three versions are equivalent is a simple exercise that 
uses the elementary properties stated in Lemma 1 .38. We also observe that the 'only 
if' direction of version I and the 'if' direction of versions 2 and 3 are obvious. 
We will now prove the 'if' direction of version l .  
Here is a first proof that is valid for the case in which the set of propositional 
variables, P, is countably infinite: 
(For the case when P is finite, the theorem is more or less obvious (there is only 
a finite number of equivalence classes of formulas), but we can always invoke the 
situation of the present proof by extending P to a countable set.) 
So consider a set A of formulas that is finitely satisfiable. We must prove the 
existence of a distribution of truth values that satisfies all of the formulas in A. 
To do this, we will define, by induction, a sequence (cn)11EN of elements of {0, 1} 
such that the distribution of truth values 8 o defined by: 
for every n E N, 8o(An) == en , 
satisfies A. 

T H E  C O M P A C T N E S S  T H E O R E M  
49 
To define so, we distinguish two cases: 
• Case Oo: for every finite subset B C A, there exists at least one distribution of 
truth values 8 E {0, 1}P which satisfies B and is such that 8(Ao) == 0. 
In this case, we set so == 0. 
• Case lo: this is the contrary case: we can choose a finite subset Bo c A such 
that, for every distribution of truth values 8 E {0, 1}P which satisfies Bo, we 
have 8 (Ao) == 1. 
In this case, we set so == 1. 
In case 1 o, the following claim is verified: 
For every finitesubsetB c A, there exists at least one distribution of truth values 
8 E {0, 1}P which satisfies B and is such that 8(Ao) == 1. 
To see this, given a finite subset B c A, note that B U Bo is a finite subset of A 
that is satisfiable according to the initial hypothesis. Choose a distribution of truth 
values 8 that satisfies it. Then 8 satisfies Bo (which is a subset of B U Bo!), and, 
by the choice of Bo, we have 8 (Ao) == 1. But since 8 also satisfies B, the claim is 
established. 
Thus, from our definition of so, we may conclude the following property (Ro): 
For every finite subset B c A, 
(Ro) 
there exists at least one assignment of truth values 8 E {0, 1}P 
which satisfies B and is such that 8 (Ao) == so. 
Suppose (the induction hypothesis) that so, s1 , . . .  , s11 (elements of {0, 1}) have 
been defined in such a way that the following property (Rn) is satisfied: 
For every finite subset B c A, there exists at least one assignment 
(An) 
of truth values 8 E {0, 1}P which satisfi.es B and is such that 
8(Ao) == so, 8(Al) == St, . . .  , 8(An-J) == Sn-l , and 8(An) == £11 • 
We then define sn+l by distinguishing two cases: 
• Case On+ I : For every finitesubsetB c A, thereexistsatleastonedistribution of 
truth values 8 E {0, 1}P which satisfies B and is such that 8(Ao) == so, 8(A 1) == 
El , . . .  , 8(An) == Sn and 8(An+l ) == 0. 
][n this case we set Sn+l == 0. 
• Case ln+ 1 : this is the contrary case : we can choose a finite subset Bn+l c A 
such that, for every distribution of truth values 8 E {0, 1}P which satisfies Bn+l 
and which is such that 8(Ao) == so, 8(At) == s1, . . .  , 8(An) == Sn, we have 
8(An+t) == 1. 
In this case, we set sn+l == I. 
Let us show that property (An+ 1 )  is then satisfied. This amounts to proving, for 
case 1n+ 1, that for every finite subset B c A, there exists at least one distribution 

50 
P R O P O S I T I O N A L  C A L C U L U S  
of truth values 8 E { 0, 1} P which satisfies B and is such that 8 ( Ao) = so, 8 (A 1 )  = 
c ) ,  . . .  , 8(An) = En and 8(An+l )  = 1. 
So consider a finite subset B c A. Then B U Bn+l is a finite subset of A; 
and, according to property (An ), we can choose a distribution of truth values 8 
which satisfies it and is such that 8(Ao) = so, 8(A I )  = £ ] ,  . . .  , 8(An) = En . So 8 
satisfies Bn+ 1 and, because of the way this set was chosen, we may conclude that 
8(An+I) = 1. Since 8 satisfies B, our objective is achieved. 
The sequence (sn)nEN is thus defined; and, for every integer n, property (An) is 
satisfied. 
As anticipated, set 8o( An) = En for every n. 
Let F be formula belonging to A, and let k be a natural number such that all 
the propositional variables that occur in F are among {A 1 ,  A2, . . .  , Ak} (F being 
a finite string of symbols, such an integer necessarily exists). Property (Rk) and 
the fact that { F} is a finite subset of A show that we can find a distribution of 
truth values 8 E {0, l}P which satisfies F and is such that 8(Ao) = so, 8(At) = 
£ 1 ,  . . .  , 8 (Ak) = Ek. We see that 8 and 8o agree on the set {A 1 , Az, . . .  , Ak}, which 
allows us to conclude (Lemma 1 .19) that 8o(F) = 8 (F) = 1. 
The conclusion is that 8o satisfies all the formulas in A. 
• 
Let us get to the proof of the theorem in the general case: we no longer make 
any particular assumptions about the set P. 
We have to invoke Zorn's lemma (see Part 2, Chapter 7). 
Proof Once more, we are given a finitely satisfiable set of formulas, A. 
Let £ denote the set of mappings whose domain is a subset of P, which take 
values in {0, 1} and which, for every finite subset B c A, have an extension to the 
whole of P which is a distribution of truth values that satisfies B. 
Formally: 
£ = {qJ E U {0, l}x : 
XCP 
(VB E gJF(A)) (3 8 E {0, 1}p) (8 rx = (/) and (VF E B) (8(F) = 1))}. 
Note that this set is not empty, for it contains the empty mapping (those who 
find this object perplexing can find additional comments concerning it in Part 2, 
Chapter 7). To see this, note that by our hypothesis, there exists a distribution of 
truth values 8 on P that satisfies B. As 8 is obviously an extension of the empty 
mapping, the latter satisfies the condition for membership in £. 
It is interesting to observe that this is the only point in the proof where we use 
the hypothesis that A is finitely satisfiable. 
Define the binary relation < on £ by 
qJ < 1/1 if and only if ljr is an extension of qJ 
(inotherwords, dom(qJ) c dom(1/r) andforevery A E dom(qJ), qJ(A) = '¢'(A)). 
It is very easy to verify that < is an order relation on £. 

T H E  C O M P A C T N E S S  T H E O R E M  
5 1  
We will prove that the ordered set ( [, < ) i s  inductive, which is to say that every 
subset of [ that is totally ordered by < has an upper bound in [. This is the same 
(see Part 2, Chapter 7) as showing that [ is non-empty and that every non-empty 
subset of [ that is totally ordered by < has an upper bound in £. This will permit 
us (by Zorn's lemma) to assert the existence of a maximal element in [ for the 
order <. 
We have already observed that [ is non-empty. Consider a non-empty subset 
C c: [ that is totally ordered by <. We define a mapping A as follows: 
• The domain of A is the union of the domains of the elements of C. 
• For every A E dom("A) and for every cp E C, if A E dom(cp), then 'A(A) == 
cp(A). 
This definition makes sense because, if cp and 1/1 are elements of [ such that 
A E dom( cp) and A E dom( 1/1 ), then we have either cp < 1/J or 1/1 < cp, and in 
both cases cp(A) == 1/f(A); so the value of the mapping A at the point A can be 
legitimately defined as the value at A taken by an arbitrary mapping that belongs 
to the subset C and is defined at A; thus A is the natural common extension of all 
the elements of C. 
Let us show that A is an element of [. For this, given a finite subset B c A, we 
must find a distribution of truth values Jvt E {0, l}P which extends A and which 
satisfies B. Since B is finite, there are at most a finite number of propositional 
variables appearing in the formulas of B. 
Let A 1 ,  A z, .
. . , An be the propositional variables that occur in at least one 
formula from B and which belong to the domain of A, in other words, to the union 
of the domains of the elements of C. Then there exist in C elements f.fJL ,  f.fJ2, .
.
• , 
f.fJn: such that A 1 E dom( f.fJl ), A2 E dom( f.fJ2 ), •
•
.
 , An E dom(cpn ) . Because C is 
totally ordered by <ӛ one of the cp; is an extension of all the others: call it f.fJO· Thus 
we have f.fJo E C and {At, A2, •
•
•
 , An } c dom(cpo). Being an element of £, f.fJo 
has an extension 1/Jo to P that satisfies B. Let us define the mapping Jvt from P into 
{0, 1} as follows: 
(A) == {'A( A) 
if A E dom('A); 
Jvt 
1/lo(A) if A ¢ dom('A). 
• Jvt is an extension of 'A: it agrees with A on dom('A). 
• Jvt satisfies B: to see this, we have on the one hand that for every variable 
A E dom(cpo), 
Jvt(A) == 'A(A) == cpo(A) == 1/lo(A); 
we conclude from this that Jvt agrees with 1/Jo on {At , A2, .
.
•
 , A11}; on the other 
hand, if A is a variable that occurs in some formula of B without belonging 
to the set {A1 , A2, . . .  , An}, we have A ¢. dam( A.), so Jvt (A) == 1/lo(A); thus 

52 
P R O P O S I T I O N A l . C A L C U L U S  
we see that JL takes the same value as 1/Jo on all propositional variables that are 
involved in the set B; and since 1/Jo satisfies B, so does JL (Lemma 1 .  I 9). 
So we have found a distribution of truth values that extends A and that satisfies 
B; thus A E £ and £ is seen to be an inductive ordered set. Zorn's lemma then 
allows us to choose an element y from £ that is maximal for the order <. 
Suppose that the domain of y is not the whole of P and consider a propositional 
variable A that does not belong to the domain of y. We will define an extension 
y' of y to the set dom( y) U {A} in the following way: 
• y' r dom(y)== y; 
• y'(A) == 0 if for every finite subset B of A there exists a distribution of truth 
values 8 on P that satisfies B, that extends y, and is such that 8(A) == 0; 
• y' (A) == 1 otherwise. 
We then make the following claim: if y' (A) == 1, then for every finite subset 
B c A, there is a distribution of truth values 8 on P that satisfies B, that extends 
y, and is such that 8(A) == 1. 
To see this, note that if y' (A) # 0, we can find a finite subset Bo c A such that 
for every distribution of truth values 8 that satisfies Bo and extends y, we have 
8(A) == 1. Now let B be an arbitrary finite subset of A. The set B U Bo is a finite 
subset of A so there is (by definition of the set £ to which y belongs) a distribution 
of truth values 8 that extends y and satisfies B U Bo; 8 satisfies Bo and extends y: 
so 8 (A) == 1. So we have truly found an extension of y to P that satisfies B (since 
B c B U Bo) and takes the value 1 at the point A. 
So we see that whatever the value of y' (A), there exists, for every finite subset B 
of A, an extension 8 of y to P that satisfies B and is such that 8(A) == y'(A). But 
this simply amounts to saying that 8 is in fact an extension of y'. Consequently, 
for every finite subset B c A, y' can be extended to a distribution of truth values 
that satisfies B. This means that y' belongs to £; and so y' is in £ and is strictly 
greater than y for the order < (dom(y)  dom(y')), which contradicts the fact 
that y is a maximal element of £. 
So the assumption we made about the domain of y was absurd. 
It follows that dom(y) == P. Thus we see that y is a distribution of truth values 
on P and that any extension of y to P is equal to y. So by definition of £, every 
finite subset B of A is satisfied by y. In particular, this is true for every singleton 
subset, which means that every formula F E A is satisfied by y. So A is satisfiable . 
• 
In Chapter 2, we will give two other proofs of this theorem. 

E X E R C I S E S F O R  C H A P T E R  I 
53 
E X E R C I S E S  F O R  C H A P T E R  1 
1. Given two natural numbers m and n, what is the length of a formula of the 
propositional calculus that has n occurrences of symbols for binary connectives 
and m occurrences of the symbol for negation? 
2. Consider formulas of the propositional calculus on a set of propositional vari­
ables P. Given a natural number n, determine the possible different lengths of 
a formula whose height is n .  
3. The setofpseudoformulas constructed from a setofpropositional variables P is 
defined to be the smallest set of words on the alphabet P U { --,, A, v, =}, {:}, ( }  
that satisfies the following conditions: 
• every element of P is a pseudoformula; 
• if F is a pseudo formula, then so is .., F; 
• i f F  and G are pseudoformulas, then so are the words: 
(F A G, 
(F v G, 
(F =} G, 
(F {:} G. 
Thus the pseudoformulas are the words obtained from the usual formulas by 
suppressing all closing parentheses. 
(a) Show that there is a unique readability theorem for pseudoformulas analo­
gous to the one for the usual formulas. 
(b) Would the analogous result be true if we suppressed of all the opening 
parentheses rather than the closing parentheses? 
4. Let F denote the set of all formulas constructed from a given set of propositional 
variables P. Let F* denote the subset ofF consisting of those formulas in which 
the sym bois A, v, and <=} do not occur. 
(a) Give an inductive definition of the set F*. 
(b) Let Jl be a map from P into F*. Show that there exists a unique extension 
11 of Jl to F* such that for all formulas F and G belonging to F*: 
/1( ..,p) = ..,fi(F), and 
/i(F =} G) = ..,(/i(G) =} /i(F)). 
(c) Show that for all formulas F and G belonging to :F*, if F is a sub-formula 
of G, then /i(F) is a sub-formula of /i(G). 
(d) Define Jto : P Q F* as follows: for all A belonging to P, Jto(A) = ..,A. 
Write down the formulas i7Q((A =} B)) and i7Q((-,A =} B)). Show that 
for every formula F in F*, /i6(F) is logically equivalent to F. 

54 
P R O P O S I T I O N A L  C A L C U L U S  
5. (a) Show that the following two formulas are tautologies. (They use the propo­
sitional variables A t ,  A2, A3, B1 , B2, and B3 and theirwrittenforminvolves 
some abuses of language.) 
F2 = (((A t =} Bt) 1\ (A2 =} B2) 1\ -,(Bt 1\ 82) 1\ (At v A2)) 
=} ((Bt =} A t )  1\ (B2 =} A2))); 
F3 = (((A 1 =} Bt) 1\ (A2 =} B2) 1\ (A3 =} B3) 
1\ -.(Bt 1\ B2) 1\ --.(Bt 1\ B3) 1\ ··(B2 1\ B3) 1\ (At v A2 v A3)) 
=} ( B2 =} A 2) 1\ ( B 3 =} A 3))). 
(b) Write a tautology Fn that generalizes F2 and F3 using the 2n variables A 1 ,  
Bt A2, B2, . . . , An , Bn-
6. E is the formula ((B 1\ C) =} (A <? (-·B v C))) in which A, B, and C are 
propositional variables. 
(a) Find a formula that is logically equivalent to E and that is written using 
only the connectives => and {}. 
(b) Find a disjunctive normal form for E that is as reduced as possible. 
(c) How many terms (elementary conjunctions) are there in the canonical dis­
junctive normal form of E? 
(d) Show that the formulas 
(C =} (B =} (A {:} (B =} C)))) and (C => (B => A)) 
are logically equivalent. 
7. What are the assignments of truth values on P = { A J ,  A2, . . .  , An } that satisfy: 
(a) the formula F = ( (A t =} A 2) 1\ (A 2 => A 3) 1\ · · · 1\ (An-t =} An)) ? 
(b) the formula G = (F 1\ (An =} A 1 )) ? 
(c) the formula H = 
A (A; =} -,A ;) ? 
l <i<n 
l <j<n 
ij.j 
Write down disjunctive normal forms for F, G, and H. 
8. Consider the set of propositional variables P = {A 1 , A 2, . . .  , An } .  
(a) Show that the following formula is a tautology: 
( V 
(A; 1\ A i)) {:} (\ (v A.i) · 
l <i<j<n 
l <i<n j=f=i 

E X E R C I S E S  F O R  C H A P T E R  l 
55 
(b) Which assignments of truth values on P make the following formula false: 
(c) Show that the preceding formula is logically equivalent to 
9. A safe has n locks and can be opened only when all n of the locks are open. 
Five people, a, b, c, d, and e are to receive keys to some of the locks. Each 
key can be duplicated any number of times. Find the smallest value of n, and 
a corresponding distribution of keys to the five people, so that the safe can be 
opened if and only if at least one of the following situations applies: 
• a and b are present together; 
• a, c, and d are present together; 
• b, d, and e are present together. 
10. Consider a set of 15 propositional variables: 
P = { Ao, A 1 , . . .  , A 14}. 
The subscripts are viewed as elements of the additive group ('!l/ I57l, +) and 
the operations ( + and -) on the subscripts are those of this group. 
Find all assignments of truth values to P that satisfy the following set of 
formulas 
{Ao} U {(A; =*  A_;) : 0 < i < 14} U { ((A; A Aj) => Ai+j) : 
0 < i < 14, 0 < j < 14}. 
11. Consider distinct propositional variables A and B and a symbol a for a binary 
connective. A formula that is neither a tautology nor an antilogy will be called 
neutral. For each of the formulas 
Fa = (A a ( B a A )), and 
Ga = ((B a A) a -.(A a B)), 
determine whether it is a tautology, an antilogy or neutral when 
(a) a = 1\ 
(d) a = <=? 
(b) a =  v 
(e) a =  -1? 
(c) a = =} 
(f) a =  t 
Of course, in cases (e) and (f), a is not a symbol for a connective, but it is used 
with the obvious conventions; for example, (B ( A) is the formula --,(B 1\ A). 

56 
P R O P O S I T I O N A L  C A L C U L U S  
12. (a) Show that there exists a unique 3-place connective qJ such that for all t 
belonging to {0, 1}, we have 
({J(t, -.t, t) = ({J(t, 0, 0) = 1 and 
({J(t, t, -.f) = ({J(l, 1, 1) = 0. 
(b) Find a disjunctive normal form for the connective defined in (a) that is as 
reduced as possible. 
(c) In each of the following cases, give an example of a formula F of the 
propositional calculus on {A, B, C} which, for all assignments of truth 
values 8 E {0, 1}{A,B.CJ, satisfies the condition indicated: 
( 1 )  8(F) = qJ(8(A), 8(A), 8(A)) 
(2) 8(F) = qJ(8(A), 8(B), 8(B)) 
(3) 8(F) = qJ(8(A), 8(A), 8(B)) 
(4) 8(F) = qJ(8(A), 8(B), 8(A)) 
(5) 8(F) == qJ(8(A), qJ(8(B), 8(B), 8(B)), 8(A)) 
(6) 8(F) = qJ(8(A), 8(B), 8(B)) :=} qJ(8(A), 8(B)Ā 8(A)). 
[Notice that in (6), :=} is not a symbol for a binary connective (since this is 
not a formula in the formal language) but rather denotes the corresponding 
binary operation on {0, 1}. An analogous remark applies to the use of ._, in 
the conditions imposed on qJ in part (a).] 
(d) Can the connective v be obtained by composition from the connective qJ? 
(e) Is { ({J} a complete set of connectives? 
13. When we add two numbers that when written in the binary number system 
(numbers in base 2) use at most two digits, say ab and cd, we obtain a number 
withat mostthreedigits, pqr. For example, 1 1  + 0 1  = 100. Using the standard 
connectives, write formulas that express p, q, and r as functions of a, b, c, 
and d. 
14. Consider a set of propositional variables P. 
We identify the set {0, l} with the field ('l/2'/L, +, x, 0, 1}. 
(a) Express the usual connectives using the operations + and x. 
(b) Express the operations + and x using the usual connectives. 
(c) Show that with each propositional formula F[A 1 ,  A2, . . .  , An] we can as­
sociate a polynomial in n unknowns P F E 'l/27l[X I , X 2, . . .  , X11] such 
that for all assignments of truth values 8 E {0, 1}P, we have 
,.._, 
-
Þ 
8(F) = PF(8(A J ), 8(A2), . . . , 8(A11)), 
where PF denotes the polynomial function (from {0, 1}11 into {0, 1}) asso-
ciated with the polynomial PF-
For a given formula F, is the polynomial PF unique? 

E X E R C I S E S  F O R  C H A P T E R  J 
57 
(d) From the preceding, deduce a procedure for determining whether two for­
mulas are logically equivalent or whether a formula is a tautology. 
15. We propose to slightly modify the notion of propositional calculus that we have 
defined by adding to its syntax the 'constants true and false'. 
We still have a set of propositional variables P, the parentheses and the five 
symbols for connectives, and, to complete the alphabet from which the formulas 
will be built, we add two new symbols T (the constant, true) and ..l (the constant, 
false) which we may consider, if we wish, to be symbols for 0-ary connectives. 
The only modification to the definition of the set of formulas is to admit two 
new formulas of height 0: 
T and 1 .. 
From the semantical point of view, we must augment the definition of the 
extension 8 of an assignment of truth values 8 (which remains a map from P 
into {0, 1}) in the following way: 
-
-
8(T) = 1 and 8(1_) = 0. 
All other definitions are unchanged. 
The formula T belongs to 1, the class of tautologies, and the formula ..l to 
the class of antilogies, 0. This justifies the use we made of these symbols in our 
earlier list of tautologies. 
(a) Show that, in this new context, the interpolation lemma is true, even without 
the hypothesis that the formulas F and G have at least one variable in 
common. 
(b) Show that any formula that is written with the unique variable A together 
with the symbols for connectives /\, v, T, and ..l (to the exclusion of all 
others) is logically equivalent to one of the three formulas T, 1., A. 
(c) Show that any formula that is written with the two variables A and B together 
with the symbols for connectives -,, '¢:>, T, and 1. (to the exclusion of all 
others) is logically equivalent to one of the eight formulas 
T, 1., A, B, -,A, -,B, (A '¢> B), _,(A '¢> B). 
(d) Show that the following systems of connectives are complete: 
{=>, 0}; {0, '¢>, v}; {0, '¢>, A}; {'}'}; {ҟ}. 
(e) Show that the following systems of connectives are not complete: 
{1, ::}, /\, v}; {0. 1, A, v}; {0, 1, -,, '¢>}. 
(f) Show that among the zero-place or one-place or two-place connectives, the 
only ones that, by themselves alone, constitute a complete set of connectives 
are the Sheffer strokes, t and ҟ· 

58 
P R O P O S I T I O N A L  C A L C U L U S  
16. (a) Show that the formula (A <=> (B <=> C)) is logically equivalent to 
((A <=> B) <=> C) but not to ( (A <=> B) 1\ (B <=> C)). The first of these 
observations might have led us to adopt a simplified way of writing the for­
mula as A <=> B <=> C as we did for conjunction and disjunction. Explain 
why the second of these observations motivates us to avoid doing so. 
(b) Consider a natural number n > 2 and a set of pairwise distinct proposi­
tional variables B = { B 1 , B2, . . .  , B n}. Let Q (B) denote the set of formulas 
that can be written using one occurrence of each of the n propositional 
variables Bt , B2, . . .  , Bn, n - I occurrences of the opening parenthesis, 
n - I occurrences of the closing parenthesis and n - I occurrences of 
the symbol <:>. Show that all the formulas in Q(B) are (pairwise) logically 
equivalent and are satisfied by a given assignment of truth values 8 if and 
only if the number of variables Bi (I < i < n) assigned the value false by 8 
. IS even. 
'"-' 
(c) For any formula G E Q(B), G denotes the formula obtained from G by 
,.., 
replacing all occurrences of <=> with §. Show that G is logically equivalent 
to G if n is odd and to ºG if n is even. 
(d) Let E be a set. For every natural number k > 2 and for all subsets X I ,  
X 2, . . .  , X k of E, we define the symmetric difference of X I , X 2, . . .  , X k, 
denoted by X I tJ. X 2 tJ. 
• . . tJ. X k, by induction in the following way: 
X 1 /),. x2 = {x E E : X  E X I {/:? X  E X 2}; 
X I !:J.X 2l:J. •
•
•
 !:J.Xk+I = (X 1 !:J.X 2l:J. . . .  !:J.X k) !:J. Xk+l · 
Show thatforevery natural numberk > 2 andforall subsets X I ,  X2, . . .  , 
X k of E, X 1 tJ. X 2 tJ. .
.
•
 tJ. X k is the set of elements of E that belong to an 
odd number of the subsets Xi. 
17. Consider propositional variables A ,  B, A 1 ,  A2, . . .  , An. 
(a) Prove the converse of the definability theorem: 
for any formula F[A I ,  A2, . . .  , An , A-1, if there exists a formula G[A I ,  
A 2, . . .  , An] such that the formula 
is a tautology (we say in this case that G is a definition of A modulo F), 
then the formula 
is also a tautology. 

E X E R C I S E S  F O R  C H A P T E R  I 
59 
(b) In each of the five following cases, with the given formula of the form 
F[At ,  A2, . . .  , An, A], associate a formula GfAt, A2, . . .  , An] that is a 
definition of A modulo F. 
1. F = A t ¢> A; 
2. F = (At :::} A) 1\ (A =::} A2) 1\ (AI ¢> A2); 
3. F = At A A2 A A; 
4. F = (At =} A) 1\ (A v A2) 1\ -,(A 1\ A2) 1\ (A2 :::} AI); 
5. F = (At =} A) 1\ (A2 =} A) 1\ (A3 =} A) 1\ (_,At ¢> (A2 ¢> _,A3)). 
18. This exercise suggests another proof of the definability theorem. 
Let F[At, A2, . . .  , An, A] be a propositional formula such that the formula 
is a tautology. Recall that CfJF denotes the map from {0, 1}n+l into {0, 1} asso­
ciated with F (its 'truth table'). 
We define a map ljr from {0, 1}n into {0, 1} as follows: for all elements et, 
£2, . . . , en in {0, 1 }  
ifcpF(et, e2, . . .  , en, 0) = 1 
otherwise. 
(a) Show that if CfJF(et, e2, . . .  , en, 1) = 1, then 1/l(et , e2, . . .  , en) = 1. 
(b) Let G = G[At ,  A2, . . .  , An] be a formula that has t/1 as its truth table (i.e. 
is such that CfJG = t/1 ). Show that G is a definition of A modulo F, i.e. that 
the formula 
is a tautology. 
19. Consider a set with five propositional variables, P = {A, B, C, D, E}. 
(a) How many formulas, up to logical equivalence, are satisfied by exactly 
seventeen assignments of truth values? 
(b) How many formulas, up to logical equivalence, are consequences of the 
formula (A 1\ B)? 
20 .. Consider a set of propositional variables P. 
Let 81 denote the assignment of truth values on P defined by 
81 (A) = 1 for every element A E P. 
(a) Show that for every formula F, there exists at least one formula G that does 
not contain the symbol -, and is such that F is logically equivalent either 
to G or to -,G. 

60 
P R O P O S I T I O N A L  C A L C U L U S  
(b) Show that for every formula F, the following three properties are 
equivalent: 
(i) F is logically equivalent to at least one formula in which the only 
connectives that may appear are /\, v, and ==}. 
(ii) F is logically equivalent to at least one formula which does not contain 
the symbol --,. 
(iii) 8}(F) == 1. 
21. Consider a finite set of propositional variables P = {A I ,  A2, . . .  , A11 } . 
0 n the set of assignments o ftruth values on P, we define a binary relation << 
by the condition 
"A << ,u if and only if for all i E { I ,  2, . . . , n }, "A(A;) < JL(Ai). 
(a) Show that << is an order relation. Is it a total ordering? 
(b) A formula F is called increasing if and only if for all assignments of truth 
values A. and Jl to P, if A. << Jl, then 'A(F) < M(F). 
Is the negation of a formula that is not increasing necessarily an increasing 
formula? 
(c) Show that for every formula F, F is increasing if and only if: 
(i) F is a tautology, or 
(ii) -,F is a tautology, or 
(iii) there exists a formula G that is logically equivalent to F and in which 
none of the three connectives --,, ::}, and {:} occurs. 
22. A set A of formulas of the propositional calculus is called independent if and 
only if for every formula F E A, F is not a consequence of A - { F}. 
(a) Which of the following sets of formulas are independent? 
{ (A ==} B), (B ==} C), (C ==} A)} 
{ (A => B), (B ==} C), (A => C)} 
{ (A v B), (A ==} C), (B ==> C), (_,A ==> (B v C))}; 
{ A ,  B, (A ==} C), (C ==} B)}; 
{ (A ==} ( B v C)), ( C ==} __,B), ( B => (A v C)), ( ( B A C) {:} B), 
(A ==} C), (B ==} A)}; 
{ ((A ==} B ) ==} C ) ,  ( A ==} C), (B ==} C), ( C  ==} (B ==} A)), 
((A ==} B) ==} (A {:} B))}. 
For each of them, if it is not independent, find ooe (and, if possible, 
several) equivalent independent subsets. 
(b) Is the empty set independent? Provide a necessary and sufficient condition 
for the independence of a set consisting of a single formula. 

E X E R C I S E S  F O R  C H A P T E R  I 
61 
(c) Show that every finite seto fformulas has at least one independent equivalent 
subset. 
(d) Show that for a set of formulas to be independent, it is necessary and suffi­
cient that all its finite subsets be independent. 
(e) Doestheinfiniteset {A 1 ,  A 1 AA2, A 1 AA2AA3, . . .  , A t AA2A· · ·/\An, . . .  } 
have an equivalent independent subset? (The Ai are propositional variables.) 
Does there exist any independent set that is equivalent to it? 
(f) Show that for any countable set of formulas { F1 , F2, . . .  , Fn, . . .  }, there 
exists at least one equivalent independent set. 
23. Given a set £, a graph on E is a binary relation G that is symmetric and 
antireflexive (which means that for every element x E £, (x, x) ҩ G). 
If k is a non-zero natural number and if G is a graph on E, we say that G is 
k -colourable if and only if there exists a map f from E in to { 1 , 2, . . .  , k} such 
that for all (x, y) E G, f(x) =!= f(y). 
(a) Foreverypair (x, i) E E x  {1, 2, . . .  , k}, letAx,i be a propositional variable. 
Define a set A(E, G, k) of formulas of the propositional calculus on the set 
of variables Ax,i that is satisfiable if and only if the graph is k-colourable. 
(b) Show that for a graph to be k-colourable, it is necessary and sufficient that 
all of its finite restrictions be k-colourable. 
24 .. An abelian group ( G, ·, 1) is called orderable if and only if there exists a total 
order relation < on G that is compatible with the group operation, which means 
that for all elements x, y, and z of G, if x < y, then x · z < y · z. 
An abelian group (G, ·, 1) is called torsion-free if and only iff or any element 
x of G different from 1 and for any non-zero natural number n, xn is different 
from 1. (xk is defined by induction: x 1 == x and for all integers k > 1, xk+ 1 
== 
x · xk .) 
An abelian group (G, · ,  1) is said to be of finite type if and only if it is 
generated by a finite subset of G (which means that there is a finite subsੌ੍t 
X c G such that the smallest subgroup of G that includes X is G itself). 
We will use the following theorem from algebra (for example, see Theo­
rem 5.09 in The Theory of Groups by I.D. Macdonald, Oxford University Press, 
1968) For every torsion-free abelian group of finite type (G, · ,  1) that does not 
reduce to the single element 1, there is a non-zero natural number p such that 
(G, · ,  1) is isomorphic to the group {7LP, + ,  0). 
(a) Let (G, · , 1) be an abelian group. Take {Ax,y : (x, y) E G2} as the set of 
propositional variables and write down a set A( G) of formulas of proposJ.­
tional calculus that is satisfiable if and only if the group G is orderable. 
(b) Show that for an abelian group to be orderable, it is necessary and sufficient 
that all of its subgroups of finite type be orderable. 
(c) Show that for an abelian group to be orderable, it is necessary and sufficient 
that it be torsion-free. 

62 
P R O P O S I T l O N A L  C A L C U L U S  
25. Consider two sets E and F and a binary relation R c E x F. 
For every element x E E, let R x denote the set of elements of F that are 
related to x under R: 
Rx == {y E F :  (x, y) E R}. 
For every subset A c E, the following set is called the image of A under R: 
We make the following two hypotheses: 
(I) For every subset A of E, the cardinality of RA is greater than or equal to 
the cardinality of A. 
(II) For every element x E £, the set Rx is finite. 
The purpose of this exercise is to prove the following property: 
(III) There exists an injective map f from E into F such that for every element 
x E £, f (x) E Rx (i.e. an injective map from E into F that is included 
in R). 
(a) Suppose that E is finite. Without using hypothesis II, prove III by induction 
on the cardinality of E by examining two cases: 
1. there is at least one subset A of E such that A =/= 0, A t= E, and 
card(A) == card(RA); 
2. for every non-empty subset A 5 E, card(A) < card(RA). 
(b) Give an example in which I is true while II and III are false. 
(c) By using the compactness theorem, prove III when E is infinite. 

2 Boolean algebras 
When we ident{fy logically equivalent formulas of the propositional calculus, we 
obtain a set on which, in a natural way, we can define a unary operation and 
two binary operations which correspond respectively to negation, to conjunction, 
and to disjunction. The structure obtained in this way is an example of a Boolean 
algebra. Another example of a Boolean algebra is provided by the set of subsets 
of a given set together with the operations of complementation, intersection, and 
union (which, by the way, are ojien called Boolean operations). 
There are diverse ways of app1vaching Boolean algebras. While we will begin 
with two purely algebraic presentations (as rings or as ordered sets), we will 
discover at the end of the chapter that we can just as well adopt a topological 
point of view: every Boolean algebra can be ident{fied with the set of those subsets 
of some compact, zero-dimensional space that are both open and closed. The 
reader should not be concerned by these perhaps unfamiliar words; Section 2. _l 
will contain all the necessary reminders, both from algebra and topology (we 
nonetheless assume that the reader does know the definitions of ring, field, and 
topological space; if not, the reader should consult, for example, A Survey of 
Modern Algebra by Garrett Birkhoff and Saunders Maclane (A. K. Peters Ltd, 
1997) and the text General Topology by John L Kelley (Springer-Verlag, 1991 ) . 
Section 2.2 contains the algebraic definitions and corresponding basic plvper­
ties. A Boolean algebra is a ring in which every element is equal to its square; but 
it is just as well a distributive, complemented lattice, i.e. an ordered set in which: 
(i) there is a least element and a greatest element, (ii) every pair of elements has 
a lower bound and an upper bound, each of these operations being distributive 
with respect to the other, and, finally, (iii) every element has a complement. We 
will establish the equivalence of these two points of view and study examples. 
Section 2.3 is devoted to atoms: non-zero elements that are minimal with respect 
to the order on the Boolean algebra. This important notion arises frequently in 
what follows, especially in several exercises. 
In Section 2.4 we are interested in homomorphisms of Boolean algebras. As 
always in algebra, the kernels of these homomorphisms (which in this context are 
ideals) play an essential 1vle. When we consider a Boolean algebra A as a lattice, 
we prefer to study not the ideals but rather the filters which are canonically asso­
ciared with them (we obtain a filter by taking the complements of the elements o.f 

64 
B O O L E A N  A L G E B R A S  
an ideal). Study o.lthese ideals and filters is the objective of Section 2.5. Particular 
attention is paid to maxima/filters or ultrafilter.਒·, which obviously correspond to 
maximal ideals, but also correspond to homomorphisms of A into the Boolean 
algebra {0, 1}. The set of these homomorphisms is given a topology: this is then 
called the Stone space of A, a space which is studied in the sixth and last section o.l 
this chapte1: The compactness theorem for propositional calculus, which we will 
prove using topology in Section 2.1, is related in a natural way to the compactness 
of the Stone space of the algebra of equivalence classes of logically equivalent 
formulas (Exercise 13 ). 
2.1 Algebra and topology review 
2.1.1 Algebra 
Consider a commutative ring with identity A =  (A, +, x, 0, 1). 
We will always assume that in such a ring, we have 0 =I= 1. As is customary, 
either of the notations a x b or ab will denote the product of two elements 
a and b of A. 
Definition 2.1 An ideal of A is a subset I of A such that 
• (I, +, 0) is a subgroup of (A, +, 0); 
• For every element x of I and for every element y of A, x x y E I. 
The set A itself obviously satisfies these conditions. An ideal of A distinct from 
A is called a proper ideal. An idea] I of A is a proper ideal if and only if 1 1-.  I. 
(If I ::: A, then 1 E I; if 1 E I, then for every element y of A, 1 x y = y E I, 
hence A =  /). 
We will only consider proper ideals here. So for us, an ideal of A will be a 
subset I of A which, in addition to the two conditions above, satisfies the following 
property: 
• l (j-. 1 . 
To adopt this point of view can sometimes be inconvenient: for example, given 
two ideals 1 and J of A, there may not be a smallest idea] containing both I and 
J because the sum of two ideals 1 and J, i.e. the set 
1 + ]  ::: {x E A :  (3y E I)(3z E J)(x = y + z)} 
which usually plays this role, may well not be a proper ideal. For instance, in the 
ring of integers IE, the sum of the ideals 21E (the set of multiples of 2) and 31E is 
the entire ring IE. 
Nonetheless, these potential inconveniences are not bothersome in the current 
context. The reader who absolutely insists on preserving the usual definition of 
ideal should, in what follows, replace ੎ideal' by 'proper ideal' everywhere. 

A L G E B R A  A N D  T O P O L O G Y  R E V I E W 
65 
Krull's theorem can be stated this way: 
Theorem 2.2 Every ideal in a commutative ring with identity is included in at 
least one maximal ideal. 
(An ideal is maximal if it is not strictly included in any other ideal.) 
Proof The proof uses Zorn's lemma (see Chapter 7 in Part 2). Let I be an ideal 
in the ring A. Let E denote the set of ideals in A that include I; 
E = {J E 5 (A) : J i s  an ideal and I c J}. 
The theorem will be proved if we can establish the existence of at least one maximal 
element in the ordered set (£, C). For this it suffices (Zorn's lemma) to show that 
this ordered set is non-empty (but this is clear since I E £) and that every non­
empty totally ordered subset of E has an upper bound in £. So let X be a subset 
of E that is totally ordered by the relation of inclusion (also known as a chain in 
(£. C)); we assume that X is not empty. Let Io be the union of the elements of 
X: lo = UJEX J. As X is not empty and as any element of X includes I_ I is 
included in Io, thus 0 E Io. If x and y are elements of lo, there are two ideals J and 
K in X such that x E J and y E K. As X is totally ordered, we have either J c K 
or K c J. If we are, for example, in the first situation, then x E K and y E K .  
therefore x - y E K and x - y E Io. It follows that (Io, + ,  0) i s  a subgroup of 
(A, +, 0). As well, if x E /o and y E A, then for at least one ideal J E X, we have 
x E J, hence xy E J and xy E Io. Finally, we have l fj Io, for in the opposite 
case, 1 would belong to one of the elements of X, which is forbidden. We have 
thus established that Io is an ideal of A which includes I, i.e. is an element of E 
For each J in X, J c Io: it follows that lo is, in £, an upper bound for the chain X 
• 
Let I be an ideal in the ring A. We define an equivalence relation on A called 
congruence modulo I and denoted by -K : 
for all elements x and y of A, x =t y if and only if x - y E I. 
The fact that this is an equivalence relation is easily proved. Let a denote the 
equivalence class of the element a E A. We have 0 = I. Congruence modulo I is 
compatible with the ring operations + and x: this means that if a, b, c, and d are 
elements of A, if a -K c and b = 1 d, then a + b =1 c + d and a x b -K c x d. 
This allows us to define two operations on the set A/ -K of equivalence classes, 
which we will continue to denote by + and x ,  defined by: for all elements x and J' 
of A, x + y = x + y and x x y = x x y. These two operations on the set AI -l 
give it the structure of a commutative ring with unit (the zero element is I, the unit 
element is 1) called the quotient ring of A by the ideal I and denoted by AI I rather 
than by A/ = I · All required verifications are elementary. The most well-known 
example of what we have just described is given by the rings 7lf n7l (where n is a 
natural number greater than or equal to 2). 

66 
B O O L E A N  A L G E B R A S  
Theorem 2.3 The quotient ring A/ I is afield ({and only if the ideal / is maximal. 
Proof If we suppose that I is not maximal, we can choose an ideal J of A such 
that I ੏ J (strict inclusion). Let a be an element of J that does not belong to /. 
We have a # I, hence a is a non-zero element in the quotient ring. If this element 
-
-
were invertible, there would be an element b E A such that a x h = 1ӥ which is to 
say ab =1 1, or equivalently ab - l E I, so also ab - 1 E J. Because a E J and 
J is an ideal, ab E J. Thus the difference ab - (ab - 1) = 1 would belong to J, 
which is impossible. It follows that there is at least one non-zero, noninvertible 
element in the ring A/ I :  it is therefore not a field. 
Now suppose that I is maximal. Let a be an element of A such that a # 0 
(equivalently, a fj. /). Our goal is to show that a is an invertible element of the 
quotient ring A/ I. Consider the following set: 
K = {x E A : (3y E A)(3z E /)(x = ay + z)}. 
It is easy to verify that (K, +, 0) is a subgroup of (A, +, 0): first of all, 0 E K 
since 0 = (a x 0) + 0; also, if XJ E K and x2 E K, then we can find elements YI 
and Y2 in A, and ZI and 22 in I, such that Xi = ay1 + Z l and x2 = ay2 + 22; we 
conclude from this that 
XI - X2 = a(YI - Y2) + Zl - Z2, 
that YI - Y2 E A, and that Z I  - 22 E I ,  thus Xt - x2 E K. On the other handӜ if 
x E K and t E A, then x t E K :  indeed, there are elements y E A and z E I such 
that x = ay + z, thus xt = a(ty) + tz; but ty E A and tz E /, so xt E K. This 
shows that the first two conditions in the definition of an ideal are satisfied by K. 
If the third of these conditions were also satisfied (thus if 1 rf. K), K would be an 
ideal in A. But the set K strictly includes the set I :  indeed, every element x of I 
can be written x = (a x 0) + x, and thus also belongs to K; and the element a, 
which can be written (a x 1) + 0, belongs to K but not to I. As I is a maximal 
ideal, K could not then be an ideal in A. We conclude from this that 1 E K. So 
we can then find two elements y E A and z E I such that 
ay + z = 1. 
So we have l - ay = z E / 
.. or equivalently, passing to the equivalence classes 
-
-
for the relation =1, 1 - ay = 0, which translates as a x y = l. So the element a 
does have an inverse in the quotient ring A//. 
We have thus shown that every non-zero element of this ring is invertible: A I I 
is therefore a field. 
• 
Observe that the proof we have just given contains an illustration of what we said 
earlier concerning the sum of two ideals. Indeed, the set K which we considered 
is the sum of the ideal I and what is known as the principal ideal generated by a 
(i.e. the ideal consisting of multiples of a). We found ourselves precisely in the 
situation in which this sum of ideals is the entire ring. 

A L G E B R A  A N D  T O P O L O G Y  R E V I E W  
67 
2.1 .. 2 Topology 
Let X be a topological space and Y a subset of X. We give Y a topology, called the 
topology induced on Y by that of X, by taking as the open sets in this topology 
the intersections with Y of open subsets of X. In other words, for a subset Q c Y 
to be open in the induced topology, it is necessary and sufficient that there exist an 
open set 0 in the topology on X such that Q = 0 n Y. We see immediately that 
the closed sets for the induced topology on Y are the intersections with Y of the 
closed subsets of X. When we speak of a subspace of a topological space X, we 
mean a subset with its induced topology. 
A basis for the open sets of a topological space X is a family ( 0; );E/ of open sets 
in the topology such that every open set is a union of open sets from this family; 
in other words, for every open set G, there is at least one subset J c I such that 
G == U jEJ Oj. When a basis for the open sets of a topological space has been 
chosen, the elements of this basis are called basic open sets. The complements in 
X of the basic open sets are called basic closed sets and it is clear that every closed 
set is an intersection of basic closed sets. For the usual topology on the set IR of 
real numbers, the bounded open intervals (i.e. sets of the form ]a, b[ where a E IR, 
b E IR. and a < b) constitute a basis for the open sets. Moreover, it is obvious that 
in any topological space whatever, the family of all open sets is a basis for the open 
sets. The following property is immediate: 
Lemma 2.4 If( 0; );EJ is a basis for the open sets of the topological space X and 
if Y is a subset of X, then the family (0; n Y);E/ is a basis for the topology on Y 
induced by that of X. 
This means that the intersections with Y of the basic open subsets of X are basic 
open subsets of Y. 
Let X and Y be two topological spaces. A map f from X into Y is called 
continuous if and only if the inverse image under f of every open subset of Y is 
an open subset of X. In other words, f is continuous if and only if, for every open 
subset Q of Y, the set f-1 [Q] = {x E X: f (x) E Q} is an open subset of X. 
Lemma 2.5 Let (Q;)iEI be a basis for the open subsets of a topological space 
Y and let f be a map ftvm X into Y. For f to be continuous, it is necessary and 
sufficient that for every index i E /, f-1[Qil be an open subset of X. 
Proof This is necessary due to the definition of continuity (something that must 
hold for all the open subsets of Y must hold in particularf or the basic open subsets). 
This is sufficient since, if Q is any open subset of Y, then there is a subset J c I 
such that Q = U jEJ Oj, hence f-1 [Q] = U jEJ f-1 [ 0 j] (this last fact is a 
wcॉll-known property of inverse images); if all of the f- 1 [ 0;] are open subsets of 
X'} f-1 [Q] will be a union of open subsets, and hence an open subset of X. 
• 
Definition 2.6 A homeomorphism of the topological space X onto the topolog­
ical space Y is a b{iective, continuous map from X into Y whose inverse is a 

68 
B O O L E A N  A L G E B R A S  
continuous map from Y into X. (We speak in this context of a bijective bicontinu­
ous map). 
Definition 2. 7 A topological space X is called Hausdorff (or separated) if and 
only (f for every pair of distinct elements x and y of X there exist di.\joint open 
sets G and H such that x E G and y E H. It is immediate that every subs pace of 
a Hausdorf space is Hausdorf 
Lemma 2.8 Let X be a topological space that is Hausdorf and let Y be a subset 
of X. Then the topology induced on Y by that of X makes Y a Hausdorf space. 
Proof If x and y are distinct points of Y, the intersections with Y of two disjoint 
open subsets of X that contain x and y respectively will be two disjoint open 
subsets of Y that contain x and y respectively. 
• 
Definition 2.9 A covering (or cover) of a topological space X is a family (Ei )iel 
of subsets of X such that X = Uie/ Ef. If all of the Ei are open sets, we speak 
of an open covering (or open cover). A subcovering of a covering (Ei )iel is 
a subfamily (Ej)jeJ (J c /) which is itse?f a covering of X. We will speak 
of a finite covering (or subcovering) when the corresponding set of indices is 
finite. 
Definition 2.10 A topological space is called compact if and only if 1°) it is 
Hausdor:f and 2°) from every open covering of X we can extract a finite 
subcovering. 
Lemma 2.11 Let X be a Hausdorff 's pace. For X to be compact, it isnecessa1yand 
sufficient that every family of closed subsets (ਓf X whose intersection is non-empty 
have a finite subfamily whose intersection is non-empty. 
Proof It suffices to observe that if (F; )iEl is a family of closed subsets of X and 
if, for each i E I, we denote the complement of Fi in X by Oi (which is an open 
set), then ni El Fi = 0 if and only if uiE/ oi = X. Thus, to each family of closed 
subsets of X whose intersection is empty, there corresponds, by complementation, 
an open covering of X, and vice versa. 
• 
Lemma 2.12 Let (Qi )iel be a basis for the open sets of a Hausdorf space X. 
For X to be compact, it is necessary and su.fficient that from every covering of X 
by basic open sets we can extract a .finite subcovering. 
Proof The condition is obviously necessary. Assume it is satisfied and that 
(Gk)kEK is a covering of X by arbitrary open sets. We have X = UkeK Gk, 
but since each G k is a union of basic open sets, we have a covering of X by a 
family of basic open sets (Qj)jEJ ( J  c /), with each Qj included in at least one 
of the open sets G k· So, given our assumption, we can extract from this cover­
ing a finite subcovering and we will have, for example, X = Q j1 U Q j2 U · · · U 
Q j11 
• It is now sufficient to choose open sets G k 1 , G k2 , . . .  , G kn from the family 
( G k )kEK which include n.il , Q j2, .
.
•
 , Q j11 respectively; we will then have a finite 

A L G E B R A  A N D  T O P O L O G Y  R E V I E W 
69 
subcovering from ( G k)kEK since X == G k1 U G k2 U · · · U G kn. This proves that X is 
compact. 
• 
Naturally, the previous property can be rephrased in terms of closed sets: 
Lemma 2.13 Let X be a Hausdorff space with a given basis for the open sets. 
For X to be compact, it is necessary and sufficient that from every family of basic 
closed sets whose intersection is empty, we can extract a finite subfamily whose 
intersection is already empty. 
Definition 2.14 A subset of a topological space X that is simultaneously open 
and closed (i.e. an open subset whose complement in X is also open) will be called 
clopen. 
Definition 2.15 A topological space which has a basis consisting of clopen sets 
is called zero-dimensional. For example, in the space Q of rational numbers, the 
bounded open intervals whose endpoints are irrational constitute a basis of clopen 
sets for the usual topology (as is easily ver(fied): thus Q is a zero-dimensional 
topological space. 
Lemma 2.16 Fora topological space to be zero-dimensional, it is necessary and 
su:fficient that the family of clopen subsets be a basis for the open sets. 
Proof It is obvious that any family of open sets that includes a basis for the 
open subsets of X is itself a basis for the open subsets of X. Thus, if X is zero­
dimensional, then the family of all its clopen subsets is a basis for the open sets. 
The converse is immediate. 
• 
Lemma 2.17 Every subspace Y of a zero-dimensional topological space X is 
ze tV·-dimensional. 
Proof Let ( Oi );EI be a basis for the open subsets of X consisting of clopen sets. 
The family ( 0; n Y)iEl is a basis for the open subsets of Y (Lemma 2.4) but these 
open sets are also closed subsets of Y since they are the intersections with Y of 
closed subsets of X. 
• 
Definition 2.18 A compact zero-dimensional topological space is called a 
Boolean space. 
Definition 2.19 Let (Xi )tEl be a family of topological spaces. On the product 
niE/ X; of this family, we can define a topology by taking as the basic open sets 
all subsets oftheform niEI 0; where, for each index i E /, 0; is an open subset 
of X;, but wherefor all but finitely many indices i, we have 0; = Xi. lt is easy to 
verify that the collection consisting of unions of sets of this type is closed under 
intersections and arbitrary unions. It is this collection of sets that we take as the 
family of open sets for the topology on niEl X;. The topology defined in this way 
is called the product topology. 

70 
B O O L E A N  A L G E B R A S  
Tychonoff's theorem asserts that: 
Theorem 2.20 The product of any family of compact topological spaces is a 
compact topological space. 
The proof makes use of Zorn's lemma and can be found, for example, in 
the text by J.L. Kelley (General Topology, Van Nostrand, 1955, republished by 
Springer-Verlag, Graduate Texts in Mathematics, 1991) (but it has the drawback 
of using the notion of filter which will be studied later in this chapter). 
Let us now examine the special case which will interest us in this chapter 
(Section 2.6): the case in which each Xi in the family of spaces (Xi)iEI is the 
set {0, 1} with the discrete topology (the one in which all subsets are open). 
In this case, the product lliE/ X; is the set {0, 1}1 of maps from 1 into {0, 1 }. 
To produce a basic open set Q in the product topologyɸ we must take a finite 
number of indices, i], i2, . . .  ' ik in 1 and open sets 0;1 ' oi2 '  . . .  ' oik from {0, l}, 
which, in this case, are arbitrary subsets of {0, 1}. We then set 
or alternatively 
It is natural to suppose that we are really interested only in those indices i j for 
which the corresponding open set is something other than the set {0, 1} itself. It 
is also pointless to consider cases in which one of the Oi; is the empty set, for 
we would then have Q = 0. There remain only two possible choices for the Oij : 
oij = {0} or oij = {1}. 
Thus we see that to produce a basic open set Q in the product topology on { 0, l}, 
we must take a finite number of indices i1, i2, . . . , ik in I and the same number of 
elements £1, £2, . . .  , Bk in {0, 1} and then set 
Q = {f E {0, 1}1 : f(i J )  = £J and f(i2) = £2 and . . .  and f(ik) = Bk}. 
A basic open set, therefore, is the set of all maps from I into {0, 1} which assume 
given values at some finite number of given points. 
Observe that the complement in {0, 1}1 of the set Q that we just considered is 
the following set: 
u {f E {0, 1}1 : f(ij) = l - £j }-
l <j<k 
So it is the union of k basic open sets, which is obviously an open set. We 
conclude that Q is a closed set. 

D E F I N I T I O N  O F  B O O L E A N  A L G E B R A  
7 1  
The basic open sets in the topology on {0, 1 }  are therefore clopen sets. Conse­
quently, we have proved: 
Lemma 2.21 The topological space {0, 1 }  1 is zero-dimensional. 
Since the discrete space {0, 1} is clearly compact, we may conclude, using 
Tychonoff's theorem, that: 
Theorem 2.22 The space {0, 1 }1 is a Boolean topological space. 
2.1.3 An application to propositional calculus 
Tychonoff's theorem allows us to give a very rapid proof of the compactness 
theorem for propositional calculus (Theorem 1.40). 
Proof Let P be a set of propositional variables and let F denote the associated 
set of formulas. For each F E F, let 6.(F) denote the set of assignments of truth 
values that satisfy it: 
6.(F) == {8 E {0, l }P : 8(F) == 1} . 
If A t ,  A2, . . .  , An are the variables that occur in the formula F, we see that the 
set t.%(F) is a union of sets of the form 
where the £; are elements of {0, 1}. 
Indeed, the satisfaction of a formula F by an assignment 8 does not depend on 
the values that 8 assumes outside the set {AJ , A2, . . .  , An} (Lemma 1.19). 
So the set 6.(F) is a union of basic open sets in the topological space {0, 1}P. 
This is a finite union: it involves at most 2n sets. So we conclude that 6.(F) is itself 
a clopen set. 
Now consider a set of formulas T c F that is not satisfiable. This means, 
precisely, that the intersection, nFET bt.(F), is the empty set. Thus the family 
(bt.(F))FET is, in the compact space {0, 1 }P, a family of closed sets whose inter­
section is empty. So it is possible to extract a finite subfamily whose intersection 
is already empty; so there is a finite subset To c T such that nFETo bt.(F) = 0. 
This means that there is some finite subset ofT that is not satisfiable. This proves 
(version 2 of) the compactness theorem for propositional calculus. 
• 
In Exercise 13, we will encounter another proof of this compactness theorem; 
this proof will make use of the results from Sections 2.5 and 2.6 and will avoid 
any appeal to Tychonoff's theorem, for which we have not given a proof. 
2.2 Definition of Boolean algebra 
Definition 2.23 A Boolean algebra (sometimes called a Boolean ring) is a ring 
(A) +, x ,  0, 1) in which each element is an idempotent for multiplication (i.e. is 
equal to its square). 

72 
B O O L E A N  A L G E B R A S  
Example 2.24 The ring (IZ/2͕, +, x ,  0, 1). 
Example 2.25 The ring (8;J(£), b., n, 0, E), where E is an arbitrary non-empty 
set, b. and n are the operations of symmetric difference and intersection respec­
tively on the set 8;J (E) of all subsets of E (see Exercise 2). 
Example 2.26 Another interesting example is furnished by propositional 
calculus. 
Consider a set of propositional variables and the corresponding set :F of formulas. 
As we will make precise in Exercise 1 ,  the set F I ੐ of equivalence classes of 
logically equivalent formulas with the operations of § and 1\ has the structure of 
a Boolean algebra (these operations can be defined on this set because the relation 
Ȇ is compatible with the propositional connectives). The class 0 of antilogies and 
the class 1 of tautologies are, respectively, the identity elements for the operations 
§ and /\. We will have occasion to return to this example, which is in fact our 
principal motivation for studying Boolean algebras. 
2.2.1 Properties of Boolean algebras, order relations 
Lemma 2.27 
• In any Boolean algebra, every element is its own additive inverse. 
• Every Boolean algebra is commutative. 
Proof Let (A, +, x ,  0, 1) be a Boolean algebra and let x and y be elements of 
A. From the definition, we have x2 = x, y2 == y, and (x + y)2 = x + y, while 
moreover, as in any ring, we have 
S o w  e may conclude 
x + y = x + xy + yx + y, 
or after simplification, xy + yx = 0. Letting y == 1, we obtain in particular that 
x + x = 0 or x = -x, which proves the first point. For arbitrary x and y therefore, 
xy is the inverse of xy, but since xy + yx == 0, it is also the inverse of yx. From 
this we conclude that xy = yx and that the algebra is commutative. 
• 
Remark 2.28 The Boolean ring (͕/2͕, +, x ,  0, 1) is the only Boolean ring that 
is a field, and even the only Boolean ring that is an integral domain: indeed, the 
relation x2 = x, which is equivalent to x (x - 1) = 0, requires, in an integral 
domain, that x = 0 or x = 1. 
Let (A, +, x, 0, 1) be a Boolean algebra. We defi.ne a binary relation < on A as 
follows: for all elements x and y of A, x < y if and only if xy = x. 

D E F I N I T I O N  O F  B O O L E A N  A L G E B R A  
73 
We will now verify that this is indeed an order relation. For all elements x, y, 
and z of A, we have 
• x < x, since x2 = x by definition; 
• if x < y and y < z, then xy = x and yz = z; hence, xz = (xy)z = x(yz) = 
xy = x, so x < z; 
• if x < y and y < x, then xy = x and yx = y, hence x = y by commutativity. 
So the relation < is reflexive, transitive, and antisymmetric. 
The following theorem lists the main properties of this order relation. 
Theorem 2.29 
( 1) 0 is a least element and 1 is a greatest element for the relation <. 
Proof Indeed, for every x, 0 x x :::: 0 and 1 x x = x, hence 0 < x and x < 1 . 
• 
(2) Any two elements x and y of A have a greatest lower bound (i.e. a common 
lower bound that is greater than any other common lower bound), denoted by 
x , .. y: specifically, their product xy. 
Proof We have (xy)x = x2 y = xy and (xy)y = xy2 = xy, thus xy is a lower 
bound both for x and for y. Moreover, if z is a common lower bound for x and y, 
we have zx = z and zy = y, hence z(x y) = (zx) y :::: zy = z, which means that 
z =:: x y; thus x y is the greatest of the common lower bounds for x and y. 
• 
(3) Any two elements x andy of A have a least upper bound (i.e. a common upper 
bound that is smaller than any other common upper bound), denoted by x '"'" y: 
specifically, the element x + y + x y. 
Proof Indeed, 
x(x + y + xy) = x2 + xy + x2y = x + xy + xy = x + 0 = x, 
and in analogous fashion, y(x + y + xy) = y. So we certainly have x < x + y + 
x y and y < x + y + x y. On the other hand, if z is an element of A such that x < z 
and y < z, which is to say xz = x and yz = y, then 
(x + y + xy)z = xz + yz + xyz :::: x + y + xy, 
so x + y + x y < z; thus x + y + x y is the least of the common upper bounds for 
x and y. 
• 
( 4) The operations ,.. and '-" thus defined on A are associative and commutative. 
Proof This is true (and very easy to prove!) in any ordered set that satisfies 
properties (2) and (3). 
• 

74 
B O O L E A N  A L G E B R A S  
( 5) 0 is an identity element for the operation '-' and an absorbing element for the 
operation r,; while 1 is an identity element for the operation Ŏ and an absorbing 
element for the operation N. 
Proof To put this another wayӥ for every element x of A, we have x '-' 0 = x, 
x Ŏ 0 = 0, x Ŏ 1 = x and x '-' 1 = 1. This is true in any ordered set that satisfies 
properties ( 1 ), (2), and (3). It is trivial to verify this. 
• 
(6) Every non-empty finite subset {XI, x2, . . .  ,Xk} of A ( k E N*) has a greatest 
lower bound equal to x1 Ŏ x2 Ŏ · · · Ŏ Xk and a least upper bound equal to 
X I '-' X2 '-' · • • '-' X k· 
Proof Except for the obvious case in which k = 1, this is a simple generalization 
of properties (2) and (3) which we naturally obtain by induction on k. 
We wish to call your attention to the following fact: the expression XJ Ŏ x2 Ŏ 
· · · "--. Xk is not a new notation intended to denote some newly introduced object. 
It denotes an element of A that is legitimately defined (by induction) as soon as 
the operation Ŏ has been defined (it is the element that we ought to denote by 
an expression that contains k - 1  pairs of parentheses, which wehavesuppressed in 
view of associativity. Concerning the operation r-, property (6) asserts two distinct 
facts: first, that the elements x 1 ,  x2, . . .  , Xk have a greatest common lower bound; 
and second, that this greatest common lower bound is 
The proof of these two facts is certainly extremely simple (indeed, we have avoided 
giving it!), but the difficulty perhaps lies in determining precisely what needs to 
be proved. (The same remark applies, of course, to the operation '-' ). 
• 
(7) Each of the operations '-' and ਔ is distributive over the other. 
Proof On the one hand, 
x Ŏ (y "-" z) = x(y + z -t- yz) = xy -t- xz + xyz 
= xy -t- xz + xy · xz = (x Ŏ y) "-" (x Ŏ z) 
for any elements x, y, and z of A which guarantees that O distributes over '-'. 
On the other hand, with x, y, and z still arbitrary elements of A, 
(x '-' y) Ŏ (x '--' z) = (x + y -f- xy)(x + z -t- xz) 
2 
2 
2 
2 
= x -t- xz -ր- x z -t- yx -f- yz -f- yxz -t-x y + xyz -t- x yz 
= x + yz -t- xyz 
after obvious simplifications. 

D E F I N I T I O N  O F  B O O L E A N  A L G E B R A  
75 
But x + yz + xyz = x '-./ (yz) = x '-./ (y r- z), hence the other distributive 
property. 
• 
(8) For every element x in A, there is an element x' in A called the complement of 
͗ such that x '-./ x = 1, and x r-x' = 0. 
Proof If such an element x' exists, it satisfies xx' = 0 and x + x' + xx' == 1, 
hence also x + x' == 1, or again x' = 1 + x. It is easy to verify on the other hand 
thatx '-./ (1 + x) = 1 and x r- (1 + x) == 0. 
We have thus established not only the existence but also the uniqueness of the 
complement of x: it is 1 + x. 
• 
(9) The map x r-ʬ 1 + x from A into A is a bijection that reverses the order. 
Proof This map is even an involution (a bijection that is its own inverse) since, 
for every x, 1 + (1 + x) = x. On the other hand, for any elements x and y, we 
have 
(1 + X) ( 1 + y) == 1 + X + y + X y. 
This element is equal to 1 + x if and only if y + xy = 0, or again xy = y. We see 
in this way that 1 + x < 1 + y if and only if y < x. 
• 
Remark 2.30 The order relation in a Boolean algebra is compatible with multi­
plication: this means that if the elements a, b, c, and d satisfy a < b and c < d, 
then a x c < b x d (if a x b = a and c x d = c, then a x c x b x d = a x c). 
The important fact to retain is that this order is not compatible with addition: for 
example, we have 0 < 1, but we do not have 0 + 1 < 1 + 1. 
Here is a property that we will frequently use: 
Lemma 2.31 For any elements x and y of A, we have x < 1 + y if and only if 
xy = 0. 
Proof Indeed, x < 1 + y means by definition that x (1 + y) = x, or again 
x +· xy = x, which is certainly equivalent to xy = 0. 
• 
2.2.2 Boolean algebras as ordered sets 
In fact, properties ( 1 ), (2), (3), (7), and (8) from Theorem 2.29 characterize Boolean 
algebras, as the following theorem shows; it also provides us with a second method 
for defining Boolean algebras. 
Theorem 2.32 Let (A, <) be an ordered set with the following properties: 
(a) there is a least element (denoted by 0) and a greatest element (denoted 
by 1); 

76 
B O O L E A N  A L G E B R A S  
(b) any two elements x and y have a least upper bound (denoted by x '-" y) and 
a greatest lower bound (denoted by x r-. y ); 
(c) each of the operations '-" and r-. is distributive over the other; 
(d) for every element x in A, there is at least one element x' in A such that 
x '-" x' = 1 and x r-. x' == 0. 
Then A can be given the structure of a Boolean algebra (A, +, x ,  0, 1) in such 
a way that the given order < on A will coincide with the order that is associated 
with its Boolean algebra structure (i.e. we will have x < y if and only if xy = y). 
The proof will be given in several stages. 
• Preliminary remarks: An ordered set that has properties (a) and (b) of the 
theorem is called a lattice. If it also has property (c), it is called a distribu­
tive lattice. If it is properties (a), (b), and (d) that are satisfied, we speak of a 
complemented lattice, where the complement of an element x is the unique 
element x' for which x '-" x' = 1 and x 
r-. x' = 0. Uniqueness is easy 
to prove: 
Proof Suppose that x' and x" are each complements of x and consider the element 
y = (x r-. x') '-" x". On one hand, y is equal to 0 '-" x", and hence to x". On the 
other hand, distributivity leads us to 
y = (x '-" x") r-. (x' '-" x") = 1 r-. (x' '-" x'') = x' '-" x". 
So we have x" = x' '-" x", which means x' < x". By interchanging the roles of 
x' and x" in this argument, we naturally obtain x" < x', and, in the end, x' = x" . 
• 
The complernent of the element x will be denoted by xc. We obviously have 
1 c  0 and oc  1. Observe that as a consequence of the uniqueness of the com­
plement, the map x ʭ xc from A into A is a bijection that is equal to its own 
inverse (for every x, (xc)c = x). 
Note in addition that, as we have already observed, when hypotheses (a), (b), 
(c), and (d) are satisfied, so too are properties (4), (5), and (6) from Theorem 2.29. 
• We will now establish what are generally known as de Morgan's laws: 
Lemma 2.33 For any elements x andy of A, 
(x r-. y )c 
= xc '-" yc and 
(x '-" y)c = xc r-. Yc. 
Proof The second law follows from the first by replacing x with xc and y with 
yc and then using the properties of complementation. 

D E F I N I T I O N  O F  B O O L E A N  A L G E B R A  
77 
To prove the first law, we show that (xc '-' yc) '-' (x ,.._ y) = 1 and that 
(xc 
'-/ yc) ,.._ (x " y) = 0: to do this, we use the distributivity of the operations 
'-' and ,.._ as wel1 as their associativity and commutativity: 
(xc '-' yc) '-' (x ,.._ y) = (xc '-' Yc '-' x) ,.._ (xc '--' Yc '-' y) 
= ( 1 '-' y C) S--. (XC 
'-' 1) = 1 Q 1 = 1; 
(xc '-' yc) Q (x ,.._ y) = (xc R"'· x " y) "" (yc " x  " y) 
= (0 " y) '-' (0 ,_.._ x) = 0 '--' 0 = 0. 
• De Morgan's laws generalize immediately (by induction) as follows: 
Lemma 2.34 For any integer k > 1 and elements Xt, x2, . . . , Xk from A, 
• 
• We will now define an addition + and a multiplication x on the set A: for all x 
and y, we set 
X X y = X /--. y 
and 
x + y = (x " yc) "" (xc 
J"', y). 
We can obtain another expression for x + y by using the fact that '--' distributes 
over r'\: 
x -+- y = (x '-' xc) /, (x '--' y) " (yc '-' xc) " (yc '-' y) 
= 1 ,.._ (x '--' y) " (xc '-' yc) /--. 1, 
hence 
x + y = (x '-' y) ,.._ (xc '-' yc). 
We will now prove that (A, +, x ,  0, 1) is a Boolean algebra. 
Proof 
• The property 'for all x, x2 = x' is immediate (x Ӥ--. x = x ); 
• (A, +, 0) is a commutative group: 
* commutativity follows immediately from that of Ӥ--. and '-' . 
* 0 is an identity element for addition: for all x in A, 

78 
B O O L E A N  A L G E B R A S  
* every element x of A has an inverse: namely, itself: 
* Addition is associative: if x, y, and z are elements of A, we have 
(x + y) + z  == ([x + y] " zc) '-J ([x + y]c " z) 
(using the definition of +) 
== ([(x " yc) '-J (xc " y)] "' zc) '-J ([x + y]c " z) 
(using the definition of +) 
== ([ (x " yc) '-' ( xc " Y)] "' zc) '-' ([ (x '-' Y) " (xc '-J yc) ]c " z) 
(using ( * )) 
== ([(x " yc) '-' (xc ,_ y)] " zc) '-' ([(x '-' y)c '-' (xc '-' yc)c] " z) 
(by de Morgan's laws) 
== ([ (x " yc) '-' (xc "' y)] " zc) , ([ (xc " yc) ș (x "' y)] " z) 
(by de Morgan੊ s laws) 
== [ (x " yc " zc) '-' {xc " Y " zc)] '-' [ {xc " Yc " z) 
'-' (x " y " z)] 
( "' distributes over '-._/ ). 
At last, using the associativity of '--', we obtain 
The commutativity of '--' and " implies that all permutations on x, y, and z 
produce this same result. In particular, (x + y) + z == (y + z) + x, but since the 
addition operation is commutative, we also have 
(x + y) + z == x + (y + z). 
• The multiplication x is associative and has 1 as an identity element: these are 
obvious properties of the operation ". 
• Multiplication distributes over addition: to prove this, we again invoke the asso­
ciativity and commutativity of ._, and "', the distributivity of " over \../, together 
with de Morgan's laws. This time we will omit the justifications of each step in 
the calculation; the reader will have no difficulty supplying them. 

A T O M S  I N  A B O O L E A N  A L G E B R A  
Let x, y, and z be elements of A. We have 
xy + xz = (x '"' y) + (x '"'z) 
= [ (x ͘ y) '"' (x '"'z)c] ͙ [ (x '"' y)c '"'(x 
'"' z)] 
= [ (x '"' y) '"' ( xc '" zc)] '" [ (xc ͚ yc) '"' (x '"' z)] 
79 
= [ (x '"' y "xc) '-/ (x '"' y '"' zc)] '" [ (xc '"' x '"' z) '" (yc '"' x '"' z)] 
= (x '"' y '"' zc) '-/ (x '"' yc " z) 
= x '"' [ (y '"' zc) ͛ (yc '"' z)] 
= x '"'[y + z] 
= x(y + z). 
This completes the proof that (A,+, x, 0ਕ 1) is a Boolean algebra. 
• 
Let << denote the order associated with this structure. For any elements x and 
y of A, x << y if and only if xy = x, or again, x --. y = x, but this last equality 
means precisely that x is less than or equal to y for the order < given initially on 
A. It follows that these two orders coincide. 
Therefore, a Boolean algebra is, optionally, a ring in which every element is 
equal to its square, or an ordered set which has the structure of a complemented, 
distributive lattice. 
Without making this a strict rule, we will tend to adopt the second point of view 
in the rest of the course. 
For the case given in Example 2.25 of the set of subsets of a given set, this point 
of view is more natural than the first. The order relation is the inclusion relation. 
The operations '-./ and '"' are, respectively, union and intersection. The complement 
of an element is its set-theoretic complement (see Exercise 2). 
In what follows, regardless of the point of view adopted, we will allow ourselves 
to use, simultaneously, the order relation <, multiplication and addition, and the 
operations '" and '"' · 
2.3 Atoms in a Boolean algebra 
Definition 2.35 An element A in a Boolean algebra (A, <, '", '"', 0, 1) is called 
an atom {f and only {fit is non-zero and has no non-zero strict lower bound. 
In other words, a is an atom if and only if a =/= 0 and, for every element b in A, 
if b Ŵa, then either b = a  orb = 0. 
Example 2.36 In the Boolean algebra fP (E) of subsets of the set E, the atoms 
are the singletons (i.e. subsets containing a single element). 

80 
B O O L E A N  A L G E B R A S  
Example 2.37 There are Boolean algebras without atoms: this is the situation 
for the Boolean algebra F I "-./ of equivalence classes of formulas of propositional 
calculus when the set P of propositional variables is infinite (see Example 2.26). 
Proof The order relation In this Boolean algebra is the following (Exercise 1): 
if F and G are formulas, 
then ci(F) < cl( G) if and only if the formula (F ==> G) is a tautology. 
To prove that there are no atoms in F I 
"-./' we will show that every non-zero 
element has a strict lower bound other than 0. So consider a formula F such that 
cl(F) =I= 0, i.e. such that -,F is not a tautology, or equivalently that there is at least 
one assignment of truth values to P that satisfies F. Choose such a distribution 
and denote it by 8. Also choose a propositional variable X that does not occur in 
the formula F. This is possible because P is infinite. Let G denote the formula 
(F 1\ X). We obviously have ੋ-* ((F 1\ X) ==> F), hence ci(G) < cl(F). The 
assignment of truth values A defined by 
for all Y E P, 
A(Y) = { 8
1
(Y) 
if f ::/= X 
if f =  X 
satisfies F (since X does not occur in F) and satisfi.es X, so it satisfies G. It follows 
that cl( G) =I= 0. On the other hand, the assignment of truth values փvt defined by 
for all Y E P, 
J,L(Y) = { -(Y) if Y ::/= X 
if f =  X 
satisfi.es F (for the same reason that A does) but does not satisfy G, so it does 
not satisfy the formula (F ==> G). So we do not have ci(F) < cl(G), which 
shows that cl( G) is a strict lower bound for ci(F); so it is a strict, non-zero lower 
bound. 
• 
Definition 2.38 A Boolean algebra is atomic if and only {f every non-zero element 
has at least one atom below it. 
This is the situation, for example, with the Boolean algebra of all subsets of a 
given set (every non-empty set contains at least one singleton). 
Theorem 2.39 Every finite Boolean algebra is atomic. 
Proof Let (A, <, '-", ""', 0, 1) be a finite Boolean algebra and let x be a non-zero 
element of A. Denote by m (x) the set of non-zero strict lower bounds of x in A. 
If m(x) is empty, then x is an atom. If m(x) is not empty, then because it is finite, 
at least one of its elements is minimal in the ordering <, i.e. no element of m(x) 

H 0 M 0 M 0 R P H I S M S, I S 0 M 0 R P H I S M S, S U B A L G E B R A S 
8 I 
is strictly below it. It is easy to see that such a minimal element is an atom of A 
that is below x. 
• 
Theorem 2.40 Let (A, +, x ,  0, 1} be a Boolean algebra (finite or not). Then for 
eve1y non-zero element a of A and for every integer k > 2, the following properties 
are equivalent: 
( I )  a is an atom; 
(2) for every element x in A, we have a < x or a < 1 + x; 
(3) for all elements X I ,  x2, . . .  , x k in A, ɕfa < XI '-" x2 '-./ · · · '-./ Xh then a < XJ 
ora < x2 or . . .  a < xk. 
Proof First observe that by virtue of Lemma 2.31 and the definition of the order 
<, (2) is equivalent to 
(2') 
for every element x in A, we have ax = a or ax = 0. 
Now let us prove the theorem. 
Let a be a non-zero element of A and k a natural number greater than or 
equal to 2. 
• ( I )  :::} (2'): for every element x in A we have ax < a, hence, since a is an 
atom, ax = a or ax = 0. 
• (2) :::} (3): assume (2) and choose elements X I ,  x2, . . .  , Xk in A such that 
a :< XJ '-J x2 '-" · · · '-./ Xk. If none of a < Xt , a < x2, . . .  , a < Xk is true, then we 
conclude, from (2), thata < 1 +xt , anda < 1 +x2, and . . .  anda < 1 +xk; so a 
wouldbea commonlowerbound for 1 +xt , 1 +x2, . . .  , 1 +xk, andhencewould 
be less than or equal to their greatest lower bound 1 + (x 1 '-' x2 '-/ · · · 
"'-' Xk) 
(de Morgan). The element a would then be simultaneously less than or equal to 
both x 1 '-J x2 '-" · · · '-J Xk and its complement, which is impossible since a is 
non-zero. So (3) is proved. 
• (3) :::} ( 1 ) :  assume (3) and let b be a lower bound for a. It is obvious that 
a < b '-J (1 + b) = 1. By taking Xt = b and x2 = x3 = · · · = Xk = 1 + b in 
(3), we deduce that a < b or a  < 1 + b. In the first case, we obtain b = a  and 
in the second case, b ::: ab ::: 0 (Lemma 2.3 1 ). We have thereby proved that a 
is an atom. 
• 
2.4 Homomorphisms, isomorphisms, subalgebras 
2.4.1 Homomorphisms and isomorphisms 
We will generally refer to a homomorphism of rings with a unit (i.e. a map that 
preserves both addition and multiplication as well as the identity elements of these 
operations) as a homomorphism of Boolean algebras. We will give definitions, 
examples, counterexamples, and characterizations in terms of ordered sets. 

82 
B O O L E A N  A L G E B R A S 
Definition 2.41 Let A = (A, +, x ,  0, 1) and A' = (A', +, x ,  0, 1) be Boolean 
algebras and h be a map from A into A'. We say that h is a homomorphism of 
Boolean algebras from A into A' if and only iffor all elements x and y in A, 
we have 
h(x + y) = h(x) + h(y); 
h(x x y) = h(x) x h(y); 
h(l) = 1. 
Remark 2.42 The condition h (0) = 0 is not part of the definition since it can be 
deduced immediately/rom the first condition (just set x = y = 0). 
The situation is different for the multiplicative identity element: the third relation 
is not a consequence of the second, as the following example shows; take A = 
f)J (N) and A' = f)J (Z) with their natural Boolean algebra structures and take h to 
be the identity map from A into A (which we can consider as a map from A into 
A' since A c A'); it is very easy to verify that the first two relations above are 
satisfied, but the third is not since the identity element for multiplication in A is N 
while in A' it is Z. 
The reader will have observed that we committed an abuse of language by 
giving the same names to the operations (as well as to their identity elements) in 
A and A'. 
Remark 2.43 The notion of homomorphism defined here is nothing more than 
the general notion of homomorphism/or rings with unit, specialized to the case of 
Boolean rings. (We should note in passing that there can exist a homomorphism of 
rings with unit between a Boolean algebra and a ring with unit that is not a Boolean 
algebras.) Properties that hold for arbitrary homomorphisms of rings with unit 
continue to hold, obviously, for Boolean algebras: for example, the composition o.f 
two homomorphisms of Boolean algebras is a homomorphism of Boolean algebras. 
The same line of thought shows that we could actually dispense with Corollary 2.49 
below. 
Lemma 2.44 Let A =  (A, <, 0, 1) and A' = (A', <, 0, 1) be two Boolean alge­
bras and h be a homomorphism of Boolean algebras from A into A'. Then we have 
(continuing with the earlier notations and with the abuse of language mentioned 
in Remark 2.42): 
For all elements x and y of A, 
h(x " y) = h(x) " h(y); 
h(xc) = (h(x))c; 
h(x _, y) = h(x) '-/ h(y); 
{fx < y, 
then h(x) < h(y). 

H 0 M 0 M 0 R P H I S M S, I S 0 M 0 R P H I S M S, S U B A L G E B R A S 
83 
Proof Because the operations x and "' are identical, the first relation is already 
a consequence of the definition of homomorphism. The second can be rewritten 
as h(1-,-x) = 1 + h(x), which is an immediate consequence of h(1) = 1 and the 
additivity of h. The third relation follows from the first two by de Morgan's laws. 
Finally, the last relation can be rewritten: if xy = y, then h(x)h(y) = h(x); and 
the latter is true since h (x y) = h (x )h(y ). 
• 
Theorem 2.45 Let A = (A,<, 0, 1} and A' = (A' <, 0, 1} be two Boolean 
algebras and h be a map from A into A'. For h to be a homomorphism of Boolean 
algebras, it is necessa1y and sufficientthatfor all elements x andy in A, we have 
h(x "'y) = h(x) "'h(y), 
h(xc) = (h(x))c. 
Proof According to the lemma, the condition is necessary. Suppose it is satisfied 
and let x and y be elements of A. We then have: 
h(xy) = h(x "'y) = h(x) "'h(y) == h(x)h(y), 
h(x + y) = h((x "yc) '-' (xc "'y)) = h(((x "'yc)c "' (xc"' y)c)c) 
= (h((x "'yc)c"' (xc "'y)c))c=(h((x "'y)c)c "'h((xc "'y)c))c 
= ((h(x "'yc))c"' (h(xc "'y))c)c = h(x "'yc) '-' h(xc "'y) 
= (h(x) "'h{yc)) '-' (h(xc) "'h(y)) 
= (h(x)"' (h(y))c) '-' ((h(x))c "'h(y)) 
= h(x) + h(y). 
It follows that h(O) = 0 (see Remark 2.42) and hence that 
This shows that h is a homomorphism. 
• 
Remark 2.46 It is clear that in the statement of the preceding theorem, we could 
replace the operation "' by the operation '-' everywhere. 
Definition 2.47 An isomorphism of Boolean algebras is a homomorphism of 
Boolean algebras that is bijective. 
Theorem 2.48 Let A = (A, <, 0, 1} and A' = (A' <, 0, 1} be two Boolean 
algebras and h be a surjective map from A onto A'. For h to be an isomorphism 
of Boolean algebras, it is necessa1y and sufficient that 
(*) for all elements x andy of A, x < y {and only f h(x) < h(y). 
Proof First let us suppose that h is an isomorphism and let x and y be elements 
of A. If x < y, then by Lemma 2.44, h(x) < h(y). If h(x) < h(y), then by 

84 
B O O L E A N  A L G E B R A S  
the definition of < and because h is a homomorphism, h(x) = h(x)h(y) = h(xy). 
But since h is injective, this requires x = xy, which is to say, x < y. So (*) is 
satisfied. 
To prove the inverse, suppose ( *) holds and that u and v are two elements of 
A such that h(u) = h(v). We have h(u) < h(v) and h(v) < h (u), thus, by (*), 
u < v, and v < u, and so u = v. Thus, h is injective. Next, let x and y be arbitrary 
elements of A. Set t = h (x) ,.,. h (y ). Since h is a bijection, there is a unique element 
z in A such that t = h(z). We have h(z) < h(x) and h(z) < h(y), hence, using 
(*), z < x, and z < y, and so z < x ,.,. y. But since x ,.,. y < x and x ,.,. y < y, 
we have, always using (*), that h(x ,.,. y) < h(x) and h(x ,.,. y) < h(y), which 
implies 
h(x ,.,. y) < h(x),.,. h(y) = h(z). 
Using ( *) once more, we obtain x ,.,. y < z, and putting all this together, z = x ,.,. y, 
which proves 
h(x ,.,. y) = h(x),.,. h(y). 
When we replace ,.,. by \,.J and < by > in the previous argument, we obtain 
h ( x ..__,. y) = h (x) \,.J h (y). 
Let u be an arbitrary element of A' and let t be its unique preimage in A under 
h. In A, we have 0 < t and t < 1. lt follows, using (*), that, in A', h(O) < u ,  and 
u < h(1). This shows that h(O) and h(1) are, respectively, the least and greatest 
elements of A', or in other words, that h(O) == 0 and h(1) = 1. 
So for every element x in A, we have 
h(xc) ,.,. h(x) = h(xc ,.,. x) = h(O) = 0 
and 
h(xc) \,.J h(x) = h(xc---x) = h(l) = 1 .  
Therefore h(xc) is the complement o f  h(x), orin other words, 
We conclude, using Theorem 2.45, that h is a homomorphism of Boolean 
algebras. 
• 
Notice that the relation h (x \,.J y) = h (x) ...., h (y) is not required to apply 
Theorem 2.45; rather, it was useful in proving that h commutes with the operation 
of taking complements. 
Corollary 2.49 The composition of two isomorphisms of Boolean algebras, as 
well as the inverse of an isomorphism of Boolean algebras, are isomorphisms of 
Boolean algebras. 

H 0 M 0 M 0 R P H I S M S. I S 0 M 0 R P H I S M S. S U B A L G E B R A S 
85 
Proof Let A =  (A, +, x ,  0, 1}, B = (B, +, x ,  0, 1}, and C = (C, +, x ,  0, 1} 
be Boolean algebras, let ¢ bean isomorphism of Boolean algebras from A onto B 
and 1jl an isomorphism of Boolean algebras from B onto C. The mappings ¢ -l and 
1/1 o ¢ are obviously surjective. For all elements u and v of B, ¢- 1 (u) < ¢-1 (v) 
is equivalent to ¢ (¢-1 (u)) < ¢(¢-1 (v)), i.e. to u < v. On the other hand, for 
all elements x and y of A, we have x < y if and only if </J(x) < </J(y), and 
¢ (x) < ¢(y) if and only if 1jl(¢(x)) < 'IJ(¢(y)). With the preceding theorem, we 
conclude that ¢ - l and 1jl o ¢ are isomorphisms of Boolean algebras, from B onto 
A and from A onto C respectively. 
• 
Theorem 2.50 Every finite Boolean algebra is isomorphic to the Boolean algebra 
of subsets of some set. 
Proof Let A == (A, +, x ,  0, 1} be a finite Boolean algebra and let E be the set 
of its atoms. Note that E is not empty since there is at least one atom that is less 
than or equal to the non-zero element 1 (Theorem 2.39). We will show that A is 
isomorphic to the algebra of subsets of E. 
lo do this, consider the map h from A into f>J (E) which, with each element x 
of A, associates the set of atoms that are below x: 
for each x E A ,  h (x) = {a E E : a < x}. 
• h is surjective: indeed, we first of all have h (0) = 0 (there is no atom below 0); 
as well, let X = {a1 ,  a2, . . .  , ak} be a non-empty subset of E and set M x = 
a1 '-" a2 '-" · · · '-" ak; we claim h(Mx) = X: the inclusion X c h(Mx) follows 
immediately form the definition of h (every element of X is an atom which 
is below Mx ); the reverse inclusion is shown using Theorem 2.40: if a is an 
element of h(Mx ), i.e. an atom which is below Mx = a1 '-" a2 '-" · · · \,../ ak, 
then we have a < a; for at least one index i (this is clear if k = 1 and this is 
clause (3) of the theorem if k > 2), but since a and a; are atoms, this entails 
a = a;, and so a E X. 
• For all elements x and y of A, if x < y, then h (x) < h (y ): indeed, if x < y, 
every atom that is below x is an atom that is below y. 
• For all elements x and y of A, if h(x) c h(y), then x < y: indeed, if x is not 
less that or equal to y, then x (l + y) # 0 (Lemma 2.31). As A is finite, it is 
atomic (Theorem 2.39) so we can find an atom a E E such that a < x (1 + y ). 
The atom a is thus below both x and 1 + y; it cannot be below y as well since it 
is non-zero. So we have a E h(x) and a ¢: h(y), which shows that h (x) is not 
included in h(y). 
We may now conclude, thanks to Theorem 2.48, that h is an isomorphism of 
Boolean algebras from A onto f>J (E). 
• 
Corollary 2.51 The cardinality of any finite Boolean algebra is a power of 2. 
Proof 
If the finite set E has cardinality n, then the set of its subsets, f>J (E), has 
cardinality 211• 
• 

86 
B O O L E A N  A L G E B R A S  
2.4.2 Boolean subalgebras 
Definition 2.52 Let A == (A, +, x ,  0, 1) be a Boolean algebra. A subset B of A 
constitutes a Boolean subalgebra of A if and only if B contains the elements 0 
and 1 and is closed under the operations + and x (in other words, 0 E B, 1 E B, 
and if x E B and y E B, then x 4- y E B and x y E B). 
A Boolean subalgebra of A is thus a subring of A that contains the element 1. 
This distinction is essential: in a ring with unit, a subring can itself be a ring with 
unit without containing the unit element of the full ring: in this case, the role of 
the identity element for multiplication is played by some other element. Let us 
reexamine the ring (p (Z), į '  n, 0, Z): p (N) is a subset that is closed under the 
operations į and n and it contains 0; it is therefore a subring of OJ (Z). Obviously, 
Z ¢:. p (N). Nonetheless, N is the identity element for the ring p (N). Thus the 
Boolean ring p (N) is a ring with unit and is a subring of p (Z), but is not a 
substructure of p (Z) as a ring with unit: it is therefore not a Boolean subalgebra 
of p (Z). 
Theorem 2.53 Let A == (A, +, x ,  0, 1) be a Boolean algebra and let B be a 
subset of A. For B to be a Boolean subalgebra of A, it is necessary and sufficient 
thatthereexistsaBoolean algebra A' == (A', +', x', 0', 1') anda homomorphism 
of Boolean algebras, h, from A' into A such that the image of the map h is the 
subset B. 
Proof 
• necessary: take A' == B, +' == +, x' == x ,  0 == 0, 1' == 1, and h == the identity 
map from B into A. It is immediate to verify that h is a homomorphism of 
Boolean algebras whose image is B. 
• sufficient: choose A' and h as indicated. We have h (0') == 0, hence 0 E B, and 
h(l') == 1, so 1 E B. Moreover, if x and y are elements of B, then we can 
choose elements x' and y' in A' such that x == h(x') and y == h(y'). We then 
have 
x + y == h(x') + h(y') == h(x' + y'), 
hence x + y E lm(h) == B; 
and 
xy == h(x')h(y') == h(x'y'), 
hence xy E lm(h) == B. 
So B is a Boolean subalgebra of A. 
• 
Theorem 2.54 In a Boolean algebra A == (A, +, x, 0, 1),for a subset B to be a 
Boolean subalgebra, it is necessary and sufficient that B contain 0 and be closed 
under the operations x . xc and (x, y) H x ,.. y. 
Proof 
• necessary: since xc == 1 + x and x ,.. y == x y, and since B must contain 0 and 1 
and be closed under + and x ,  the result is immediate. 

H 0 M 0 M 0 R P H I S M S, I S 0 M 0 R P H I S M S, S U B A L G E B R A S 
87 
• sufficient: for every x and y in A we have x .._, y == (xc "' yc)c. So the closure of 
B under complementation and "' guarantees its closure under.._,. Moreover, 1 c = 
0 must belong to B. Since the operations + and x can be defined exclusively 
in terms of "', '-', and complementation, we conclude that B is closed under + 
and x and that (B, +, x ,  0, 1) is a Boolean subalgebra of A. 
• 
Example 2.55 Let E be an infinite set, let A == g;> (£), the set of all its subsets, 
and let B be the subset of A consisting of those subsets of E that are finite or 
whose complement is finite. We will show, using the previous theorem, that B is 
a Boolean subalgebra of the Boolean algebra of subsets of E. 
Proof A subset of E whose complement is finite will be called cofinite. The 
empty set, which is a finite subset of E, belongs to B. It is clear that B is closed under 
complementation: the complement (in this instance, the set-theoretic complement) 
of a finite subset of E is a co finite subset and the complement of a co finite set is 
finite. Also, B is closed under"' (in this instance, set-theoretic intersection): indeed, 
the intersection of a finite subset of E with any subset of E is a finite subset of E; 
as for the intersection of two co finite subsets of E, this too is a cofinite subset of 
E: to see this, suppose that U c E and V c E are co finite; this means that E - U 
and E - V are finite and hence, so is their union ( E - U) U (£ - V) which is 
simply (de Morgan) E - (U n V); it follows that U n V is cofinite. 
• 
Example 2.56 Here is an example that will be of use in Section 2.6. Let X be a 
topological space and let B(X) be the subset of g;> (X) consisting of subsets of X 
that are both open and closed in the topology on X (recall that we speak of clopen 
sets in this context). This set B(X) is a Boolean subalgebra of the Boolean algebra 
of subsets of X. 
Proof First of all, the empty set (0) and the whole space X (1) itself are naturally 
clopen sets. Next, the complement of a clopen set is clopen and the intersection 
of two clopen sets is clopen. So Theorem 2.54 allows us, here as well, to arrive at 
the expected conclusion. 
• 
lt can happen that the Boolean algebra B (X) under consideration here reduces to 
{0, 1 l  (this is the case, for example, when X is the space IR with its usual topology: 
0 and IR are the only subsets that are both open and closed); B(X) can also coincide 
with g;> (X) (when thetopologyon X is the discretetopology(thetopology in which 
all subsets are open) and, obviously, only is this case). 
Let us now give two examples of homomorphisms of Boolean algebras. 
Example 2.57 Consider the Boolean algebra F I 
rv of equivalence classes of 
logically equivalent formulas of the propositional calculus built from a set of 
variables P (see Examples 2.26). Choose an assignment 8 of truth values on P 
and as usual let 8 denote the extension of 8 to the set F of all formulas. We can 
then define a map hE> from F I rv into {0, 1 }  by setting, for every formula F, 
ho ( ci(F)) = 8 (F). 

88 
B O O L E A N  A L G E B R A S  
This definition is legitimate since 8 (F) assumes the same value on all formulas 
in a given equivalence class. 
This map, h0, is a homomorphism of Boolean algebras from F ;ӡ into {0, 1}. 
By virtue of Theorem 2.45 and the definition of the operations for the Boolean 
algebra F ;θ, it suffices to establish that for all formulas F and G in F, we have 
h0 (ci(F 1\ G)) = h0 (ci(F))h0 (ci(G)) 
and 
h8 (ci(...,F)) = l - htS(CI(F)). 
Now these relations are equivalent to 
-
-
-
8 (F 1\ G) == 8 (F) 8 (G) 
and 
-
-
8(-,F) = 1 - 8 (F), 
which are true by definition of 8. 
We will prove (Exercise 1 3) that all Boolean algebra homomorphisms from 
F I "' into {0, 1} are obtained in this manner. 
Example 2.58 Let A 
= (A, +, x ,  0, 1) be a Boolean algebra and let a be an 
atom in this algebra (we are assuming that one exists). Let us define a map h. from 
A into {0, 1} by 
h. (x) = 
-
{ 1 
if x E A and a < x 
0 
if x E A and a < 1 + x 
(these two cases are mutually exclusive since a is different from 0, and there are 
no other cases since a is an atom: see Theorem 2.40). 
We claim that h. is a homomorphism of Boolean algebras from A into {0, 1}. 
Proof To prove this, let us use Theorem 2.45: let x and y be two elements of 
A. We have h. (x "' y) = 1 if and only if a < x ,.., y, but this is equivalent, by 
the definition of greatest lower bound, to a < x and a < y, hence to h. (x) = 1 
and h. (y) = 1, which is necessary and sufficient to have h. (x) "' h. (y) = 1. It 
follows that 
ha (X "' y) == ha (X) "' ha (y). 
Also, ha (xc) = 1 if and only if a < xc, i.e. a < 1 + x, which is equivalent to 
h. (x) = 0. Since h. only assumes the values 0 or 1, this means that 
2.5 Ideals and filters 
2.5.1 Properties of ideals 
As mentioned in the reminders, 'ideal' means 'proper ideal'. 
• 

I D E A L S  A N D  F I L T E R S  
89 
Theorem 2.59 Let A =  (A, <, 0, 1) be a Boolean algebra and 1 a subset of A. 
For I to be an ideal, it is necessary and st:fficient that the following three conditions 
be satisfied: 
(i) 0 E l and 1 ¢ l; 
(ii) for all elements x and y of I, x '-' y E 1; 
(iii) for all x E 1 and for all y E A, if y < x, then y E /. 
Proof Suppose first that I is an ideal. Then in particular, it is a subgroup of the 
group (A, +, 0), so 0 E 1. If 1 were in I, then 1 would be the entire ring and 
we have excluded this case; so (i) is verified. If x and y are in /, then so is their 
product xy and, consequently, the sum x + y + xy = x 
'-' y, which proves (ii). 
Finally, let us verify (iii): if x E I and y E A, then xy E I and if y < x as well, 
then x y = y and, consequently, y E I. 
Conversely, suppose that (i), (ii), and (iii) are satisfied. We must show that I is 
an ideal in A. If x E l and y E /, then x '-' y E l by (ii), but since x + y < x ͖ y 
(this is trivial to check) and since x + y = x -- y (we are in a Boolean algebra), we 
conclude using (iii) that x - y E /. Since 0 E 1, we have all we need for (/, +, 0) 
to be a subgroup of (A, +, 0). Moreover, if x E l and y E A, then since xy < x, 
we may conclude from (iii) thatxy E /. The set I is therefore an ideal in A (1 =1= A 
since 1 ¢ /). 
• 
Corollary 2.60 If I is an ideal in a Boolean algebra (A, +, x ,  0, 1), there is no 
element x in A that can satisfy both x E I and 1 + x E I. 
Proof If the ideal l contains both x and 1 + x, it would also contain the element 
x 
..._, (1 + x) = 1 (invoke property (ii) of the theorem). But this is not possible 
since 1 ¢ l (property (i)). 
• 
Corollary 2.61 Let A =  (A, +, x ,  0, 1) be a Boolean ring and let 1 be an ideal 
in A. For any integer k > 1 and any elements XI , x2, . . .  , Xk in /, the least upper 
bound XI 
'-' x2 '-' · · · '-' Xk belongs to I. 
Proof This is a generalization of property (ii) of the theorem; its proof is imme­
diate by induction on the integer k (the case k = 1 needs no argument). 
• 
Example 2.62 
( 1) If E is an infinite set, the set f>J f (E) of finite subsets of E is an ideal in the 
Boolean algebra f>J (E). It is easy to verify conditions (i), (ii), and (iii) of the 
theorem: 0 is a finite subset of E while E itself is not one, the union of two 
finite subsets of E is a finite subset of E, and any subset of a finite subset of 
E is a finite subset of E. 
(2) Let A = (A, +, x ,  0, 1) be a Boolean algebra and let a be an element of A 
that is not equal to 1. The set Ia = {x E A : x < a} is an ideal in A. Here too, 
the verification of properties (i), (ii), and (iii) is immediate: we have 0 < a 

90 
B O O L E A N  A L G E B R A S  
and, since a is distinct from 1, we do not have 1 < a ;  if x < a and y < a, then 
x '--' y < a; finally, if x < a  and y < x, then y < a. Ia is called the principal 
ideal generated by a. This agrees with the usual definition of a principal ideal 
in an arbitrary commutative ring since, in a Boolean ring, the set of elements 
below a given element is also the set of its multiples. 
(3) In any Boolean algebra, {0} is obviously an ideal. 
Lemma 2.63 For any Boolean ring A =  (A, +, x ,  0, 1) and for any ideal I in 
A, the quotient ring A/ I is a Boolean ring. 
Proof For each element x in A, let x denote the equivalence class of x modulo I. 
We already know that AI I is a ring with unit. So it is sufficient to show that every 
element is an idempotent for multiplication. But this is an immediate consequence 
of the definition of multiplication in A/ I and of the fact that A is a Boolean algebra: 
ifx E A, x2 = x2 = x. 
Recall that in an arbitrary commutative ring with unit, the ideals are precisely 
the kernels of homomorphisms of rings with unit defined on the ring. (See 
Remark 2.43.) The theorem that follows merely takes up this result for Boolean 
rings, with this added precision: it shows that the ideals in a Boolean ring are 
precisely the kernels of homomorphisms of Boolean algebras defined on the ring . 
• 
Theorem 2.64 Let A = (A, +, x , 0, 1) be a Boolean ring and let I be a subset 
of A. The following properties are equivalent: 
(1) I is an ideal in A; 
(2) there exists a homomorphism of Boolean algebras, h, defined on A 
whose kernel is I (in other words), 
I =  h-1 [{0}] = {x E A :  h(x) = 0}; 
(3) there exists a homomorphism of commutative rings with unit defined on A 
whose kernel is I. 
Proof The equivalence of ( I )  and (3) is the result in the preceding reminder; 
(2) =} (3) is obvious. We will nonetheless prove (3) =} (1) and then (1) =} (2), 
which is, as observed above, more precise than ( 1) =} (3). 
• (3) =} (1): suppose there exists a homomorphism h from A into a ring with unit 
B = (B, +, x ,  0, 1) such that I = h-1 [{0}] = {x E A :  h(x) = 0}. Let us 
verify that conditions (i), (ii), and (iii) from Theorem 2.59 are satisfied. 
We have h(O) = 0 and h(1) = 1, hence 0 E I and 1 rJ_ I. If x E 1 and y E /, 
then h(x) = 0 and h(y) = 0, so 
h(x '--' y) = h(x + y + xy) = h(x) + h(y) + h(x)h(y) = 0 

I D E A L S A N D  F I L T E R S  
9 1  
and sox '--" y E I. Finally, ifx E l, y E A, and y < x, then h(x) = O andxy = y, 
hence h(y) = h(x)h(y) = 0, i.e. y E I. 
Thus, I is an ideal of A. 
(Of course, it would have made no sense to use an order relation or the '-./ and .-. 
operations in B). 
• ( 1) ==> (2): suppose that I is an ideal in A and consider the map h from A into 
A/ I which, with each element x, associates its equivalence class, x, modulo 
J (h is what is generally known as the canonical surjection of A onto A//). h 
is a homomorphism of Boolean algebras (the canonical homomorphism of A 
onto A/ 1): to see this, we invoke Theorem 2.45; if x E A and y E A, then 
h(x ,Ș y) = h(xy) = xy = :X x y = h(x) x h(y) = h(x) .--. h(y) and 
h(xc) = h(1 + x) = 1 + x  == 1 + x = 1 + h(x) = (h(x))c. 
-
-
Also, it is clear that I = 0 = {x E A : h(x) = 0}: I is the kernel of h. 
• 
2.5.2 Maximal ideals 
Here is a collection of ways to characterize maximal ideals in a Boolean algebra: 
Theorem 2.65 For evety Boolean ring A = (A, +, x ,  0, 1), for eve1y ideal I in 
A, and for every integer k > 2, the following properties are equivalent: 
(I) I is a maximal ideal; 
(2) A/ I is isomorphic 10 the Boolean algebra {0, l}; 
(3) I is the kernel of a homomorphism of A into {0, 1}; 
(4) for every element x in A, x E I or l + x E I; 
(5) for all elements x and y of A, if xy E I, then x E I or y E I; 
(6) for all elements xr, xz, . . . , Xk in A, {fxrxz · · · Xk E I, then xr E I or xz E I 
or · · ·  or Xk E I. 
Proof 
• ( 1 )  ==> (2): In Section 1 ,  we recalled that if the ideal I is maximal, then the 
quotient ring A/ I is a field. But we also observed (Remark 2.28) that the only 
Boolean ring that is a field is {0, 1}. So the result follows using Lemma 2.63. 
• (2) ==> (3): It suffices to note that I is always the kernel of the canonical homo­
morphism h from A into A/ I. If there is an isomorphism ¢ from A/ I onto 
{0, 1}, then I will obviously be the kernel of the homomorphism ¢ o h from A 
into {0, 1}. 
• (3) ==> (4): Consider a homomorphism h from A into {0, 1} whose kernel is I 
and let x be an arbitrary element of A. We have h (x) = 0 or h (x) = 1. In the 
first case, x E I; in the second case we have 1 + h (x) = 0, so h(1 + x) == 0 
and 1 + x E I. 

92 
B O O L E A N  A L G E B R A S  
• ( 4) => (5): Let x and y be elements of A such that x ¢. I and y ¢. I. If ( 4) holds, 
then 1 + x E I and 1 + y E I, so (1 + x) 
'-../ (1 + y) E I (property (ii) of 
Theorem 2.59). But 
(1 + x) '-./ (1 + y) = 1 + (x r- y) = 1 + xy, 
so, by Corollary 2.60 xy ¢. I, and so (5) is proved. 
• (5) =} (1): Suppose that I is not maximal. Let J be an ideal of A that strictly 
includes I and a be an element of J that does not belong to I. Using Coro­
llary 2.60, 1 + a ¢. J. and so 1 + a ¢. I since I c J. The ideal I contains 
neither a nor 1 + a, but it does obviously contain the product a(1 + a) = 0. We 
conclude that (5) is not satisfied. 
• (5) ==> (6): We assume that (5) is satisfied and we argue by induction on the 
integer k. For k = 2, (6) coincides with (5). Assuming (6) is verified for k, we 
will prove that it is satisfied for k + I .  Let XJ , x2, . . .  , xਜc, Xk+l be elements of 
A such that XJX2 · · · XkXk+l E I. By (5) we must have either x1x2 · · · Xk E I or 
Xk+ 1 E I. In the first instance, by the induction hypothesis, we have x1 E I or 
x2 E I or . . .  or Xk E I. We then conclude that we must have Xi E I for at least 
one index i such that I < i < k + l ; this proves (6) for k + I .  
• (6) => (5): Let x and y be two elements of A such that xy E I .  Set Xi = x and 
x2 = x3 = 
.
.
.
 = Xk = y. So we have x1x2 · · · Xk = xy E I. So if (6) is true, 
we must have Xi E I for at least one index i between I and k; so either x E I 
or y E 1 and (5) is verified. 
• 
Remark 2.66 In an arbitrary commutative ring, an ideal with property (5)from 
the preceding theorem is called a prime ideal. What we have just p1vved is that in 
a Boolean ring, the prime ideals are precisely the same as the maximal ideals. But 
there are ringsforwhichthisfails to be true. What is always true is that an ideal is 
prime Ŵ{and only if the associated quotient ring is an integral domain (this is easy 
to prove); we conclude from this as well that a maximal ideal must necessarily 
be prime (it st:ffices to consider the corresponding quotient ring). Thus it is the 
converse of this that can fail (for example, in the ring IR[X, Yl a,{ polynomials in two 
variables with real coefficients: the ideal generated by the polynomial X, i.e. the set 
{X P : P E IR[X, Y]} is prime but is not maximal since it is strictly included in the 
ideal generated by the polynomials X andY, i.e. the set {X P+ Y Q : P E IR[X, Y], 
Q E IR[X, Y)}). 
Remark 2.67 In particula1; we should take note of the equivalence between prop­
er ties ( 1) and (3). Observe that if two homomorphisms h and g from a Boolean 
algebra A = (A, +, x ,  0, 1) into {0, 1} have the same kernel, I, then they are 
equal: this is because for any element x in A, either x ¢. I and g (x) = h (x) = 0 
or else x ¢. l and g(x) = h(x) = 1. We may conclude from this that there is a 
bijection between the set of maximal ideals in a Boolean algebra and the set of 
homomorphisms of Boolean algebras from this algebra into {0, 1}. 

I D E A L S  A N D  F I L T E R S  
93 
2.5.3 Filters 
We will now introduce the notion that is dual to that of an ideal on a Boolean 
algebra: we will define filters. 
Definition 2.68 A filter in a Boolean algebra A = {A, +, x ,  0, 1) is a subset F 
of A such that the set 
{x E A : x8 E F} 
is an ideal in A. 
Let F be a filter in a Boolean algebra A = (A , +, x ,  0, 1). Let I be the 
ideal {x E A : xc E F}. I is realized as the inverse image of F under the oper-· 
ation of complementation: x t---7 xc. But, as this operation is an involution (se(ੈ 
parl (9) of Theorem 2.29), I is also the direct image of F under this operation: 
I == {x E A :  3y(y E F and x = y8)}. In other words, I is the set of complements 
of elements of F and F is the set of complements of elements of /. The ideal / i!; 
called the dual ideal of the filter F. It is easy to see that, given an arbitrary ideal 
J in A, the set G = {x E A : xc E J }  is a filter whose dual ideal is precisely J. 
To everyone's surprise, we will call G the dual filter of the ideal J. There is thus 
a bijection between the set of ideals and the set of fi.lters in a Boolean algebra. For 
filters, we have the dual of Theorem 2.59. 
Theorem 2.69 Let A =  (A, <, 0, 1) be a Boolean algebra and F a  subset of A. 
For F to be a .filter, i tis necessary and sufficient that the following three conditions 
be satisfied: 
(f) 0 ¢ F and 1 E F; 
(ff) for all elements x andy of I, x "' y E F; 
(ftf) for all x E F and for all y E A, if y > x, then y E F. 
Proof Set I = {x E A : xc E F}. If F is a filter, then I is its dual ideal and 
conditions (i), (ii), and (iii) from Theorem 2.59 are satisfied. So we have 0 E I, 
hence oc = 1 E F, and 1 ¢ /, hence 1c = 0 Ě F, which proves (f). If x E F and 
y E: F, then XC E / and yC E /, SO XC 
.._., yC E 1 (by (ii)), and, as XC 
.._., y8 =
= 
(x "' y )c, we conclude that x "' y E F and that (ff) is satisfied. Finally, if x E F, 
y E A, and y > x, then xc E I and yc < xc, so, (by (iii)) y8 E 1 and y E F, hence 
(fff). 
Conversely, in a strictly analogous fashion, (i) follows from (f), (ii) from (ff) and 
(iii) from (fff). 
H 
Corollary 2.70 Let A =  (A, <, 0, 1) be a Boolean algebra and F a  subset of A. 
f'or any integer k > 1 and any elements Xt , x2, . . . , Xk in F, the greatest lower 
bound XI 
"' x2 "' · · · "' Xk belongs to F. 
Proof Analogue of Corollary 2.61. 
H 

94 
B O O L E A N  A L G E B R A S  
2.5.4 Ultrafilters 
Definition 2.71 l n a Boolean algebra, an ultrafilter is a maximal filter, i.e. a 
filter which is not strictly included in any other filteJ: 
It is clear that, in view of the duality explained above, ultrafilters correspond to 
maximal ideals. In other words, the dual filter of a maximal ideal is an ultrafilter 
and the dual ideal of an ultrafilter is a maximal ideal. 
There is an analogue for filters of Theorem 2.65: 
Theorem 2.72 For every Boolean ring A = (A, +, x ,  0, 1),for every ideal F in 
A, and for every integer k > 2, the following properties are equivalent: 
( 1 ') F is an ultrafilter; 
(3') there is a homomorphism h from A into {0, 1} such that 
F = {x E A : h(x) = 1}; 
(4') for every element x in A, x E F or 1 + x E F; 
(5') for all elements x and y of A, if x '-" y E F, then x E F or y E F; 
(6') for all elements x 1 ,  x2, . . .  , Xk in A, if XJ 
-._; x2 './ · · · -._; Xk E F, then x1 E F 
or x2 E F or . . . or Xk E F. 
Proof Given the algebra A, the filter F and the integer k, let I denote the ideal 
dual to F. It is elementary to verify that properties (1'), (3'), (4'), (5'), and (6') 
for the filter F are respectively equivalent to properties ( 1 ), (3), ( 4 ), (5), and (6) 
of Theorem 2.65 for the ideal I (we use the correspondence between I and F, de 
Morgan's laws, etc.) 
• 
Remark 2.73 The 'or' in property (4) of Theorem 2.65, as well as the one in 
property (4') above, is in fact an 'exclusive or' (see Corolla1y 2.60). This means 
that if F is an ultrafilter in a Boolean algebra (A, +, x ,  0, 1) and (f I is the 
maximal ideal dual to F, then I and F constitute a partition of A. Thus each of 
the sets I and F is simultaneously: 
• the complement of the other (viewed as subsets of A), 
• the set of complements of the elements of the other (in the sense of comple­
mentation in the Boolean algebra under consideration). 
The second of these properties holds whenever we have an ideal and a filter that 
are dual to one another, but the first holds only when the ideal and filter in question 
are maximal. 
Remark 2.74 Returning to Remark 2.67, we can now add to it and insist on the 
factthatforaBooleanalgebra, A, there are canonical one-to-one correspondences 
among (i) the maximal ideals in A, (ii) the ultrafilters in A and (iii) homomorphisms 
of Boolean algebras from A into {0, 1}. 

I D E A L S  A N D  F I L T E R S  
95 
Examples: To have examples of filters, it obviously suffices to refer to the previ­
ously described examples of ideals (in Subsection 2.5 .1) and to transform them by 
duality. The reader can, without any difficulty, provide the necessary verifications: 
(1) If E is an infinite set, the setofall cofinite subsets of E (seeExample 2.55) is a 
filter in the Boolean algebra (g;y (E), c, 0, E). This filter is called the Frechet 
filter on E .  It is not an ultrafilter since there are subsets of E which are infinite 
and whose complements are also infinite, so condition (4') of Theorem 2.72. 
is not satisfied. 
(2) If a is a non-zero element in a Boolean algebra (A, <, 0, 1), the set Fa = {x E 
A : x > a} is a filter called the principal filter generated by a. It is the duaJ 
filter of the ideal generated by 1 + a. 
( 3) The set { 1} is the dual filter of the ideal { 0}. 
Theorem 2.75 Let (A, <, 0, 1) be a Boolean algebra and Let a be a non-ze1v 
element of A. For the principal filter generated by a to be an ultrafiltel; it is 
necessary and sufficient that a be an atom. 
Proof By virtue of Theorem 2.40 and the definition of the filter Fa , a is an atom 
if and only if for every element x of A, x E Fa or 1 + x E Fa ; but for this to 
happen, it is necessary and sufficient that Fa be an ultrafilter ( ( 4') :::} ( 1') from 
Theorem 2.72). 
• 
When the principal filter Fa generated by a non-zero element a of A is an 
ultrafilter (thus, when a is an atom), we say that this is a trivial ultrafilter. The 
homomorphism ha with values in {0, 1 }  that is associated with it is also called a 
trivial homomorphism. As it is defined by : ha (x) = 1 if x E Fa and ha (x) = 0 if 
x rt Fa , and as this is obviously equivalent to: ha (x) = 1 if a < x and ha (x) = 0 
if a < 1 + x, we see that what is involved is precisely the homomorphism studied 
in Example 2.58. 
Lemma 2.76 Let A be a Boolean algebra and Let U be an ultrafilter on A. For 
U to be trivial, it is necessary and sufficient that it contain at least one atom. 
Proof If U is trivial, it is generated by an atom, a, and since a < a, a E U. 
Conversely, ifU contains an atom, b, it also contains all elements greater than or 
equal to b (condition (fff) of Theorem 2.69). It follows that the principal filter F1; 
generated by b is included in U. But since b is an atom, Fb is maximal and cannot 
be strictly included in the filter U. Hence U = Fh and U is a trivial ultrafilter. 
•1 
Theorem 2.77 Let E be an infinite set and let U be an ultrafilter in the Boolean 
algebra g;y (E). ForU to be non-trivial, it is necessary and sufficient that it includes 
the Frechetfilter on E. 
Proof The atoms of g;y (E) are the singletons (subsets consisting of a single el­
ement); so they are finite sets. If U includes the Frechet filter, every co finite sub­
set of E belongs to U, hence no finite subset of E can belong to U (U canno1 

96 
B O O L E A N  A L G E B R A S  
simultaneously contain a subset of E and its complement: see Remark 2.73). 
In particular, no atom can belong to U. It follows, by the preceding lemma, that U 
is non-trivial. 
If U does not include the Frechet filter, we can choose a cofinite subset X of E 
that does not belong to U, and hence whose complement E - X does belong to U. 
As E is the identity element for the Boolean algebra f>J (E), E E U; hence X # E. 
The complement of X in E is thus a non-empty finite subset of £: for example, 
E - X = {at , a2, . . .  , an } (n > 1). So we have {ai , a2, . . .  , an } E U, which is to 
also say: 
{ai } U {a2} U · · · U {an } = {ad 4 {a2 }  5 · · · 6 {an } E U. 
If n = 1, {at }  E U. If n > 2, then by property (6') of Theorem 2.72, we have 
{ad E U for at least one index i between I and n. We see that in every case, 
U contains a singleton, i.e. an atom. The preceding lemma then shows that U is 
trivial. 
• 
Remark: In Exercise 16, we will prove a property which includes this theorem 
as a special case. 
2.5.5 Filterbases 
Definition 2.78 In a Boolean algebra (A, <, 0, 1), a basis for a .filter (filterbase) 
is a subset of A that has the following ptvperty, known as the finite intersection 
property: every non-empty finite subset of B has a non-zero greatest lower bound. 
In other words, B c A is a filterbase if and only if: for any integer k > 1 and 
any elements Xt , x2, . . . , Xk of B, x1 r-. x2 r-. • • • r-. Xk # 0. 
Lemma 2.79 Let (A, <, 0, 1) be a Boolean algebra and let X be a subset of A. 
For the existence of a filter on A that includes X, it is necessary and sufficient that 
X be a filterbase. 
Proof If X is included in a filter F, and if x t, x2, . . .  , Xk are elements of X, then 
their greatest lower bound XJ r-. x2 r-. • • • r-. Xk belongs to F (Corollary 2.70), and 
as 0 ҩ F, this greatest lower bound is non-zero; thus X is a filter base. 
Now suppose that X is a filterbase. 
• If X = 0, { 1} is a filter on A that includes X. 
• I f  X is not empty, we set 
Fx = {x E A : (3k E N*)(3xl E X)(3x2 E X) . . .  (3xk E X) 
(X > XI r-. X2 r-. • • • r-. Xk)}. 
So F x consists of greatest lower bounds of non-empty finite subsets of X 
together with all elements greater than or equal to one of these greatest lower 
bounds. In particular, each element of X belongs to F x, hence F x includes X. 
I t is easy to prove that Fx is a filter. We will restrict ourselves to the following 

remarks: 
S T 0 N E'S T H E 0 R E M 
97 
(f) 0 Ȕ F x (otherwise the finite intersection property would not be true for X) 
and 1 E Fx (because X is non-empty: at least one element of X is less than 
or equal to 1). 
(f1) If x > XI "' x2 "' · · · "' Xh and y > YI "' Y2 "' · · · 
"' Yk, then we have 
X "' y > XI "' X2 "' . . .  "' Xk "' YI /'"' Y2 "' . . .  "' Yk· 
(fff) If x > XI "' x2 "' · · · 
"' Xk and y > x, then y > XI "' x2 "' · · · "' Xk- So 
we have found a filter that includes X. 
• 
In the particular case of Boolean algebras, we can state Krull's theorem (see the 
beginning of this chapter) in terms of filters. It is then known as the ultrafilter 
theorem: 
Theorem 2.80 In a Boolean algebra, every filter is included in at least one 
ultrafilter. 
Proof Given a filter F, the ideal dual to F is included in at least one maximal 
ideal; its dual filter is then an ultrafilter that includes F. 
Of course, for Boolean algebras, the formulation in terms of filters and the 
formulation in terms of ideals are equivalent. 
The ultrafilter theorem allows us to give a slightly different restatement of 
Lemma 2.79: 
• 
Lemma 2.81 Let (A, <, 0, 1) be a Boolean algebra and let X be a subset of A. 
For the existence of an ultrafilter on A that includes X, it is necessary and sufficient 
that X be a filterbase. 
Proof The properties Ӣthere exists an ultrafi.lter on A that includes X' and Ӣthere 
exists a filter on A that includes X' are equivalent: the first clearly implies the 
second; the reverse implication follows from the ultrafilter theorem. The conclusion 
then fallows from Lemma 2. 79. 
• 
2.(]1 Stone's theorem 
The first example of a Boolean algebra that comes to mind is, without a doubt, that 
of the algebra of subsets of a given set. !severy Boolean algebra equal to (we really 
mean 'isomorphic to') the Boolean algebra of subsets of some set? We already have 
sufficient knowledge to answer 'no' to this question: we have encountered Boolean 
algebras without atoms (Example 2.37) and we know that the algebra of subsets 
of a set always contain atoms: the singletons; and any isomorphism transforms 
atoms into atoms (see Exercise 3 ); a Boolean algebra that does not contain atoms 
cannot therefore be isomorphic to an algebra that does. 
None the less, Stone's theorem, to which this section is devoted, shows that there 
is always a link that connects a Boolean algebra to an algebra of subsets of a set. 

98 
B O O L E A N  A L G E B R A S  
More precisely, every Boolean algebra is isomorphic to a subalgebra of a Boolean 
algebra of subsets of a set. 
2.6.1 The Stone space of a Boolean algebra 
Consider a Boolean algebra A =  (A, +, x ,  0, 1). 
Definition 2.82 The set of homomorphisms of a Boolean algebra A into {0, 1} is 
denoted by S (A) and is called the Stone space of A. 
We could just have well chosen the set of maximal ideals or the set of ultrafilters 
on A (by virtue of Remark 2. 7 4 ). 
The set S(A) is a subset of {0, l}A, the set of maps from A into {0, 1}, which 
we have considered earlier as a topological space by taking the discrete topology 
on {0, 1} and giving this space the product topology (see Definition 2.19). So we 
can give S(A) the topology induced by that of {0, 1}A. The open subsets of S(A) 
are then the intersections with S(A) of the open subsets of {0, 1 }A. 
Lemma 2.83 The topological space S(A) is zero-dimensional. 
Proof We saw (Lemma 2.21) that {0, 1 }A is zero-dimensional. So it suffices to 
apply Lemma 2.17. 
• 
We have exhibited, just before Lemma 2.21 ,  a basis (Q; );E/ for the space {0, 1 }A 
consisting of clopen sets. Each of the Q; is the set of all maps from A into {0, 1} 
that take specified values at a specified finite numberofpoints. If for each i, we set 
r; = Qi n S(A), as in Lemma 2.17, then the family (r; )iEI is a basis for the open 
sets in S(A) consisting of clopen sets. Each r; is the set of homomorphisms of 
Boolean algebras from A into {0, l} which assume given values at a finite number 
of given points. 
From now on, it is exclusively this basis for the open sets that we will consider 
for the space S(A). When we speak of a basic open set for the Stone space of A, 
we mean one of the clopen sets in the family (ri );EJ· 
Lemma 2.84 For a subset ͔ of S(A) to be a basic open set, it is necessary and 
sufficient that there exist an element a in A such that 
͔ = {h E S(A) : h(a) = 1}. 
M oreove1; when this condition is realized, such an element is unique. 
Proof 
• sufficient. Suppose that ͔ = {h E S(A) : h (a) = 1}; ӣ is the set of homomor­
phisms from A into {0, 1} that assume the value 1 at the point a: so it is one of 
the basic open sets in S(A). 
• necessary. Suppose ੉ is a basic open subset of S(A). 
* If 6. = 0, then 6. = {h E S(A) : h(O) == 1}. 

S T 0 N E'S T H E 0 R E M 
99 
* If Ɏ =I= 0, then there is an integer n > 1 ,  elements a 1 ,  az, . . .  , an in A and 
elements cJ , £2, . . .  , En in {0. 1} such that 
11 == {h E  S(A) : h(at) == cJ and h(a2) = £2 and . . .  and h(an) == En}. 
For every k E { 1 , 2, . . .  , n}, set 
bk = {ak 
if t:k = 1; 
1 + ak 
ift:k = 0. 
For every homomorphism h E S(A) and for every k E { 1 ,  2, . . .  , n}, we have 
It follows that for h E S(A), h E !:1 if and only if h (bk) 
{ 1, 2, . . . , n}. But this latter condition is equivalent to 
1 for all k E 
or again, since a homomorphism is involved, to 
So we see that by setting a = br r-. b2 r-. 
• • • 
r-. bn, we have 
!:1 = {h E S(A) : h(a) = 1}. 
Now let us prove uniqueness: if a and b are distinct elements of A, then a+ b =1= 0; 
so we may consider the principal filter generated by a + b and, in view of the 
ultrafilter theorem, an ultrafilter that includes this filter. To such an ultrafilter, there 
is an associated homomorphism ¢ from A into {0, 1} that satisfies ¢ (a + b) = 1, 
or again, ¢ (a)+¢ (b) == 1, which means that one and only one of the two elements 
¢ («) and ¢ (b) is equal to 1. This proves that 
" 
{h E S(A) : h(a) = 1} i= {h E S(A) : h(b) = 1} 
since ¢ belongs to one of these two sets and not to the other. 
• 
Corollary 2.85 The set of basic closed subsets of S(A) coincides with the set of 
its basic open subsets. 
Proof Let r be a basic closed subset of S(A). Then ӣ = S(A) - r is a basic 
open subset; hence (by the preceding lemma) there is an element a E A such 
that 
!:1 = {h E S(A) : h(a) = 1}. 

100 
Hence, 
B O O L E A N  A L G E B R A S  
r = {h E  S(A) : h(a) =1- 1} 
= {h E S(A) : h(a) == 0} 
= {h E S(A) : h(l + a) = 1}. 
So we see, thanks again to the preceding lemma, that r is a basic open subset. 
In the same way, we can show that every basic open set is a basic closed set. 
• 
Lemma 2.86 The topological space S(A) is compact. 
Proof First of all, since the topology on {0, 1 }A is Hausdorff, so is the topology 
of S(A). 
Next, we must show that from any family of closed subsets of S(A) whose 
intersection is empty, wecanextractafinitesubfamily whose intersection is already 
empty. But we have seen (Lemma 2.1 3) that it suffices to do this for families of 
basic closed sets. Now, as we have just seen, the basic closed sets coincide with 
the basic open sets. So consider an infinite family ('L j) J E.! of basic open subsets 
of S(A) such that njEJ E.i == 0. By the preceding lemma, there exists, for each 
j E J, a unique element xi in A such that 
'Li == {h E  S(A) : h(xj) = 1}. 
Set X =  {Xj : j E J}. Tosay thatthe intersection ofthe family ('Lj)jEJ is empty 
is to say that there is no homomorphism of Boolean algebras from A into {0, 1} 
that assumes the value 1 for all elements of X, or again, that there is no ultrafilter 
on A that contains X. This means (Lemma 2.8 1 )  that X is not a filter base. So there 
exists a finite subset {x ii ,  x h ,  . . .  , x jk } c X whose greatest lower bound is zero. 
So no ultrafilter on A could simultaneously contain x.ii , x h, and . . . and x.ik . In 
other words, no homomorphism from A into {0. 1 }  can simultaneously assume the 
value 1 at the points x.h , x h, and . . . and x.ik . This amounts to saying that 
We thus have a finite subfamily of the family ('Lj )jE.! whose intersection is 
empty. 
• 
Remark 2.87 We can give a dਉfferent proof that S(A) is compact by invoking the 
fact that {0, 1 }A is itseਊf compact (Theorem 2.20). It would then suffice to show that 
S(A) is closed in {0, 1 }A (since every closed subset ofa compact space is compact): 
For a E A and b E A, set 
n (a, b) == { .f E { 0, 1 }  A 
: f ( ab) == f (a) f (b) and f ( 1 + a) == I + f (a)} . 

S T 0 N E'S T H E 0 R E M 
101 
From Theorem 2.45, we have S(A) = naEA Q (a, b). But for all elements a and 
hE A 
b of A, we can write: 
Q (a, b) = 
{f E {0, l}A : f(a) = 0 and f(b) = 0 and f(ab) = 0 and f(1 + a) =  1} 
LJ {f E {0, l}A 
: f(a) = 0 and f(b) == 1 and f(ab) = 0 and f(1 + a) = 1} 
LJ {f E {0, 1}A 
: f(a) = 1 and f(b) == 0 and f(ab) = 0 and f(1 + a) = 0} 
U {f E {0, l}A 
: f(a) = 1 and f(b) = 1 and f(ab) = 1 and f(1 + a) =  0}. 
Allfourofthe setsonthe right side of this equality are basic open subsets of{O, 1}A , 
hence are clopen. So in particulat; their union is closed. So the intersection of all 
setsoftheform Q (a, b) as a and b range over A is a closed subsetof{O, 1}A. And 
as we have seen, this intersection is S(A). 
For us, this second proof suffers by depending on a theorem that we did not 
prove (Tychonoff's theorem, which was invoked to claim that {0, l}A is compact). 
The first proof that we gave depends on Krull's theorem, which we did prove in 
Section 2. 1 .  
Corollary 2.88 The Stone space of A is a Boolean topological space. 
Proof Indeed, the space is compact (Lemma 2.86) and is zero-dimensional 
(Lemma 2.83). 
• 
Lemma 2.89 The set (ҧfclopen subsets of S(A) coincides with the set of its basic 
open sets. 
Proof We already know that all the basic open sets are clopen (Lemma 2.83). 
Conversely, let 1 be an arbitrary clopen subset of S(A). As 1 is open, it is a 
union of basic open sets: for example, r = uiEJ r i for some subset J c I. But 
since r is a closed subset of the compact space S (A), it is itself compact. So from 
the open covering (1; )iEJ of r, we can extract a finite subcovering, for example: 
1 == 1j1 U liz U · · · U rjm · We know (Lemma 2.84) that we can find elements 
X J  ȗ x2, . . . , Xm in A such that 
for every k E { 1 ,  2, . . .  , m}, rik = {h E  S(A) : h(xk) = 1}. 
Set x = X I "-' x2 "-' · · · "-' Xk and set Ɏ = {h E S(A) : h(x) = 1}; we will show 
that I =  Ɏ- Every element of r is a homomorphism that assumes the value 1 on at 
least one of the points X t ,  x2, . . .  , Xm ; so it also assumes the value 1 at x which is 
their least upper bound. Thus, r c 11. On the other hand, any homomorphism that 
is not in r, and so does not assume the value 1 at any of the points XI , x2, . . . , Xm , 
must assume the value 0 at each of these points, and so too at the point x which is 
their least upper bound; so it cannot belong to /1. This proves that 11 c r. Finally, 
r = /1, and as 11 is a basic open set (by Lemma 2.84 ), r must be one as well. 
• 

102 
B O O L E A N  A L G E B R A S  
2.6.2 Stone's theorem 
Theorem 2.90 (Stone's theorem) Every Boolean algebra is isomorphic to the 
Boolean algebra of clo pen subsets of its Stone space. 
Proof The Boolean algebra of clopen subsets of S(A) is denoted by B(S(A)) 
(see Example 2.56). 
Let H denote the map from A into Ҩ(S(A)) which, with each element a in A, 
associates 
H(a) = {h E  S(A) : h(a) = 1}. 
Letusshow that H is anisomorphismofBooleanalgebras from A onto B(S(A)). 
According to Lemmas 2.84 and 2.89, the map H assumes its values in B(S(A)) 
and its image is the whole of B(S(A)). So H is a surjection from A onto 
B(S(A)). 
By virtue of Theorem 2.48, to show that H is an isomorphism of Boolean 
algebras, it suffices to guarantee that for all elements x and y in A, x < y if 
and only if H(x) c H(y). 
So let x and y be two elements of A. If x is less than or equal to y, then for 
any homomorphism h that satisfies h(x) = 1, we must also have h(y) = 1, which 
means that H (x) is a subset of H (y). If x is not less than or equal to y, then 
x(1 , y) =I= 0 (Lemma 2.31 ). So we may consider the principal filter generated 
by x(1 -r- y ), an ultrafilter that includes it (by the ultrafilter theorem) and the 
homomorphism h E  S(A) associated with this ultrafilter. Wehaveh(x(1+y)) = 1, 
hence h(x) = 1 and h(1 + y) = 1, i.e. h(y) == 0. We conclude that h E H(x) and 
h ¢ H (y ), and so H (x) is not included in H (y ). 
• 
Stone's theorem allows us to give a very simple proof of Theorem 2.50. 
Corollary 2.91 Every finite Boolean algebra is isomorphic to a Boolean algebra 
of subsets of some set. 
Proof If the set A is finite, then the topology on {0, 1 }A is the discrete topology. 
So this is also the case for the topology induced on the subset S(A). All subsets of 
S(A) are then both open and closed. So the Boolean algebra B(S(A)) coincides 
with K-J(S(A)) and A is isomorphic to Ҩ(S(A)). 
• 
In the case of an arbitrary Boolean algebra, what Stone's theorem shows is that 
it is isomorphic to a Boolean subalgebra of the algebra of subsets of some set 
(Example 2.56). 
2.6.3 Boolean spaces are Stone spaces 
With each Boolean algebra, we have associated a Boolean topological space: its 
Stone space S(A), and we have seen that A is isomorphic to the Boolean algebra 
of clopen subsets of this Boolean space. It is the ref ore natural to study the case 
in which A is given as the Boolean algebra of clopen subsets of some Boolean 

S T 0 N E'S T H E 0 R E M 
1 03 
topollogical space X. The problem that then arises is to compare the space X to 
this other Boolean space that is the Stone space of A, in other words, to compare 
X and S(B(X)). The result of this comparison will reveal that these two objects 
very much resemble each other. 
Theorem 2.92 Every Boolean topological space X is homeomorphic to the Stone 
space S(B(X)) of the Boolean algebra ofclopen subsets of X. 
Proof Let X be a Boolean space. According to Lemma 2016, we can take the 
Boolean algebra B(X) of clopen subsets of X as a basis for the open sets in the 
topology on X. 
For each x E X, let fx denote the map from B(X) into {0, 1} defined by 
{ 1 
if X E Q; 
fx ( Q) == 0 
if X 1- Q . 
We will show that the map f which, with each x E X, associates fx, is a 
homeomorphism from the topological space X onto the topological space S (B (X)) 
0 
• 
As f is, a priori, a map from X into {0, 1}B(X), we must show, to begin with, 
that it really assumes values in S(B(X)): 
• For each x E X, fr is a homomorphism of Boolean algebras: 
Proof For any clopen subsets Q and b:. of X, we have fx(Q n .6.) == 1 if and 
only if X E Q n b:., i.e. X E Q and X E .6., which is equivalent to fx (Q) == l and 
fx(l:i) == 1, and hence to fx(Q)fx(.6.) == 1. We conclude from this that 
fx (Q n .6.) = fx (Q) fx (.6.). 
On the other hand, fx (X - Q) == 1 if and only if x E X - Q, i.e. x 1- Q, or 
again, fx (Q) == 0. Thus, fx (X - Q) == 1 + fx (Q). We see that the conditions 
from Theorem 2.45 are satisfied: fx is indeed a homomorphism. 
• 
• The map f is injective: 
Proof Let x and y be distinct elements of X. As X is Hausdorff, we can find an 
open set 0 such that x E 0 and y 1- 0 (for example, we could take 0 = X- {y} ). 
But 0 is a union of basic open sets from the basis B(X); so there is some clopen 
set n E B(X) such that X E n and y 1- no We have fx(Q) = 1 and /y(Q) = 0, 
which proves that fx is different from /y 0 
• 
• The map f is surjective onto S(B(X)): 
Proof Let h be an element of S(B(X)), i.e. a homomorphism from B(X) into 
{0 
.. 1}. The ultrafilter on B(X) associated with h is 
u == {Q E B(X) : h(Q) == 1} == h-1 [{1}]0 

104 
B O O L E A N  A L G E B R A S  
Since U has the finite intersection property (Lemma 2.81 ), since the elements of 
U are closed, and since the topological space X is compact, we may assert that 
the intersection of all the elements of U is non-empty. Let x be an element of this 
intersection. 
Foreveryclopenset Q E B(X), we have: either Q E U, in which case fx (Q) = 1 
and h (Q) = 1, or else Q ¢ U, in which case X -਋ Q E U (Remark 2.73), so 
fx (Q) = 0 and h (Q) = 0. Thus, for every Q E B(X), fx(Q) = h(Q). It follows 
that h = fx = j(x). 
• 
We may observe that the element x, which we have just shown is a preimage 
of h under the map J, is the unique element in the intersection of all the clopen 
sets belonging to U. To see this, note that any element y in this intersection would, 
exactly as above, satisfy h = J(y), and since f is injective, this would imply 
x = y. This observation will allow us to describe the inverse bijection f-1 : it is 
the map from S(B(X)) into X that, to each homomorphism h of B(X) into {0, 1}, 
associates the unique element in the intersection of all the clopen sets belonging 
to the ul trafi Iter h-1 [ { 1}]. 
• The map f is continuous. 
Proof Let G be an open set belonging to the basis of clopen subsets of S(B(X)). 
According to Lemma 2.84, there exists a unique element Q in B(X) such that 
G = {h E S(B(X)) : h (Q) = 1}. The inverse image of G under the map f is 
{x E X :  j਌ E G} = {x E X :  ft (Q) = 1} = {x E X :  x E Q} = Q .  
So it is an open subset of X. 
• 
• The inverse map f-1 is continuous. 
Proof Let Q be a basic open set in the space X (i.e. an element of B(X)). Since 
f is a bijection, the inverse image of Q under f--l is its direct image under f. 
Thus it is the set j[Q] = {.fx : x E Q}. We have to show that this is an open set 
in the space S(B(X)). 
Set V = {h E S(B(X)) : h(Q) = 1}. 
The set V is open (it is even a basic open set) in S(B(X)) (Lemma 2.84). If we 
show that j[Q] = V, this will complete the proof. 
For every x E Q, we have fx(Q) = 1 by definition of .ft, so fx E V. Thus 
j[Q] c v. 
Every h E V has a preimage y E X under the bijection f, say h = /y. As 
h E V, we have h (Q) = f).(Q) = 1, so y E Q and /y = h E j[Q]. Hence, V is 
included in j[Q]. 
• 
We should remark that the proof of this last point was superfluous: there is a 
famous theorem of topology asserting that any continuous bUection of a compact 
topological space into a Hausdorff space is a homeomorphism (the continuity of 
the inverse bijection is guaranteed). 

S T 0 N E'S T H E 0 R E M 
105 
We have definitely established a one-to-one correspondence between Boolean 
algebras and Boolean topological spaces (up to isomorphism on one side, up to 
homeomorphism on the other): 
• every Boolean algebra is (isomorphic to) the Boolean algebra of clopen subsets 
of some Boolean topological space; 
• every Boolean topological space is (homeomorphic to) the Stone space of some 
Boolean algebra. 
In passing, let us observe that we had very good reasons for calling compact 
zero-dimensional spaces 'Boolean spaces'. 
In a natural way, we have the following two properties (which are easily proved 
from all that has preceded): 
• for any two Boolean algebras to be isomorphic, it is necessary and sufficient 
that their Stone spaces be homeomorphic; 
• for any two Boolean topological spaces to be homeomorphic, it is necessary 
and sufficient that the Boolean algebras consisting of their respective clopen 
subsets be isomorphic. 

1 06 
B O O L E A N  A L G E B R A S  
E X E R C I S E S  F O R  C H A P T E R 2 
1. (Refer to Example 2.26) Consider a set P of propositional variables and the 
associated set :F of formulas. We are going to study the quotient set :F I rv, i.e. 
the set of classes of logically equivalent formulas. The equivalence class of a 
formula F will be denoted by cl(F). 
(a) Show that if, for all formulas F and G of :F, we set 
-lci(F) = cl( _,F) 
cl(F) A ci(G) = ci(F A G) 
cl(F) v ci(G) = ci(F v G) 
ci(F) => ci(G) = cl(F => G) 
cl(F) <=} cl( G) = ci(F <=} G) 
ci(F) § ci(G) = cl(F § G), 
this defines internal operations on :F lrv (denoted, abusively, by the same 
symbols for the corresponding connectives). Show that :F lrv is a Boolean 
algebra with respect to the operations § and /\. (Reminder: (F § G) = 
a(F <=} G)). 
(b) Show that the order relation in this Boolean algebra is the following: for all 
formulas F and G of :F, 
ci(F) < ci(G) if and only if * (F => G). 
(See Example 2.37). 
Explain how the operations of greatest lower bound, least upper bound 
and complementation are defined. 
(c) Show that if the set p is finite, then the Boolean algebra :F I rv is atomic; 
describe the set of atoms. 
2. Let E be an arbitrary set. On f)J (E), we define a binary operation Ɏ (symmetric 
difference, see Exercise 16 from Chapter 1 )  as follows: 
for all elements X and Y of f)J (E), 
X Ɏy = (X U Y) - (X n Y) = (X n (E - Y )) U ((E - X) n Y). 
(The symmetric difference of the subsets X and Y is the set of elements of E 
that belong to one and only one of these subsets). 
After observing that for all subsets X and Y of E we have 
X Ɏy == {x E E : x E X § x E Y}, 
show, using the properties of the usual connectives, for instance 1\ and §, that 
the set f)J (E), with the two binary operations Ɏ and n, is a Boolean algebra. 
For this Boolean algebra, explain how the order relation and the operations of 
greatest lower bound, least upper bound and complementation are defined. 

E X E R C I S E S  F O R  C H A P T E R  2 
107 
3. Let A =  (A, +, x ,  0, 1) and B = (B, +, x ,  0, 1) be two Boolean algebras and 
let f be an isomorphism of Boolean algebras from A onto B. 
(a) Show that an element a E A is an atom of A if and only if f(a) is an 
atom of B. 
(b) Show that A is atomless if and only if B is atomless. 
(c) Show that A is atomic if and only if B is atomic. 
(d) Show that a subset I c A is an ideal of A if and only if fl/], its direct 
image under f, is an ideal of B. 
(e) Show that a subset U c A is an ultrafilter of A if and only if f [U] is an 
ultrafilter of B. 
4. We say that a Boolean algebra (A, +, x ,  0, 1) is complete if and only if every 
non-empty subset of A has a greatest lower bound. 
(a) Show thatfora Boolean algebra to be complete, it is necessary and sufficient 
that every non-empty subset have a least upper bound. 
(b) Show that a Boolean algebra that is isomorphic to a complete Boolean 
algebra is complete. 
(c) Show that the Boolean algebra of subsets of a set is complete. 
(d) Show that if E is infinite, the Boolean algebra of subsets of E that are finite 
or cofinite (see Example 2.55) is not complete. 
(e) Is the Boolean algebra of classes of logically equivalent formulas of the 
propositional calculus (see Exercise 1 above) complete? 
(f) Show that for a Boolean algebra to be isomorphic to the Boolean algebra 
of subsets of some set, it is necessary and sufficient that it be atomic and 
complete. 
5. Let A =  (A, +, x ,  0, 1) be a Boolean algebra and let B = (B, +, x ,  0, 1) be a 
Boolean subalgebra of A. Show that an element of B that is an atom of A must 
also be an atom of B but that there can be atoms of B that are not atoms of A. 
6. Let A = (A, +, x ,  0, 1 )  be a Boolean algebra. Show that for every element 
a E A, the set 
B = {x E A : x > a  or x < 1 + a} 
is a Boolean subalgebra of A and that it is a complete (see Exercise 4 above) 
Boolean algebra if A itself is complete. 
7. Let A =  (A, +, x ,  0, 1) be a Boolean algebra. Consider a non-empty subset Z 
of fYJ (A) whose elements are filters on A. 
(a) Show that the set nFEZ F, the intersection of the filters that belong to Z, 
is also a filter on A, but that the union U FEZ F of the elements of Z may 
not be a filter. 

108 
B O O L E A N  A L G E B R A S  
(b) Suppose, in addition, that Z is totally ordered by the inclusion relation. 
Show that in this case, UFEZ F is a filter on A. 
8. Let E be a countable subset of tJ (N) that has the finite intersection property 
(i.e. E is a fi.lterbase in the Boolean algebra tJ (N)). The set of filters on tJ (N) 
that include E is then non-empty and the intersection of the elements of this set 
(see Exercise 7 above) is called the filter generated by E. 
Show that if the filter generated by E is an ultrafilter, then it is the trivial 
ultrafilter. 
9. Consider a set P of propositional variables and its associated Boolean algebra 
:F frv (see Exercise l ). We say that a class x E :F frv is positive if there is at 
least one formula F in x which does not contain any occurrences of the negation 
symbol. 
(a) Show that for any class x E :Fjrv, x is positive if and only if for every 
formula F E x, 81 (F) == 1 (81 is the assignment of truth values that assigns 
the value 1 to every variable: see Exercise 20 from Chapter 1.) 
(b) Show that the set J of positive classes is an ultrafilter in the Boolean alge­
bra :F frv. 
(c) What is the homomorphism from .r /'"' into {0, 1} associated with this ul­
trafilter? 
10. Let X be a topological space. A subset Y c X is said to be dense in X if and 
only if every non-empty open subset of X has a point in common with Y. (Some 
authors say everywhere dense instead of dense.) An element x E X is called 
an isolated point if and only if the singleton set { x} is an open subset of X. 
Let A == (A, +, x ,  0, 1) be a Boolean algebra. Let S denote its Stone space 
and let H denote the isomorphism from A onto B(S) defined in the proof of 
Stone's theorem (Theorem 2.90). 
(a) Show that for any element x E A, x is an atom of A if and only if the set 
H (x) is a singleton. 
(b) Show that A has no atoms if and only if the topological space S has no 
isolated points. 
(c) Show that A is atomic if and only if the set of isolated points of S is 
dense in S. 
11. We say that a Boolean algebra (A, +, x ,  0, 1) is dense if and only if the order 
relation < on A is dense, which means that for all elements a and h of A, if 
a < h, then there exists at least one element c E A such that a < c < h. 
Naturally, it is important not to confuse the notion of dense Boolean algebra 
with the notion of dense subset of a topological space introduced in Exercise 10. 
Show that a Boolean algebra is dense if and only if it has no atoms. 
12. The purpose of this exercise is to show that, up to isomorphism, there is only 
one countable atomless Boolean algebra. 

E X E R C I S E S  F O R  C H A P T E R  2 
109 
Consider a Boolean algebra A =  (A, +, x ,  0, 1) that has no atoms. Assume 
that the set A is countable and fix an enumeration A = {an : n E N}. 
(a) Given a non-zero element x in A ,  a splitting of x is a pair (y, z) E A2 such 
that y i= 0, z # 0, y r-. z = 0, and y "--' z = x. Show that (y, z) is a splitting 
of x if and only if 0 < y < x and z = y + x. Show that in A, every non-zero 
element has at least one splitting. 
(b) Show that it is possible to define a family: 
of non-zero elements of A such that UVJ = 1 and, for every integer n, 
and 
(uc- C' 
o u 
. 
1) is a splitting of u 
c;Qc;( . • .  £n-l , 
£QE( . .
• cn-1 
£Q£J ... £n-l ' 
(Thus, if ao f {0, l}, then uo = ao and u 1  = 1 + ao; otherwise, (uo, U I )  
is an arbitrary splitting of 1 ). 
(c) Show that for every element x E A and every sequence c = (cn)neN of 
elements of {0, 1}, one and only one of the following two conditions is 
satisfied: 
(i) for every n E N, x r-. U£o£1 ... £n-Icn # 0; 
(ii) for every n E N, ( 1  + x) "' Uc0c1 ... Bn-I£n # 0. 
(d) Consider two integers m and n satisfying 0 < n < m and m + n + 2 ele­
ments co, c t ,  . . .  , En , so, Sl , . . .  , sm in {0, l}. Show that for u80c1 ... £n-IBn r-. 
u:0;1 . . . {m-I {m to be non-zero, it is necessary and sufficient that co = so and 
cJ = SI and . . .  and En = Sn. 
(e) Let h be the map from A into Ӟ ({0, l}n) which, with each element x E A, 
associates 
h (x) = {/ E {0, 1}n : ('v'n E N)(x r-. UJO)f(l) ... f(n)) -=/= 0)}. 
Show that h is an isomorphism of Boolean algebras from A onto the 
Boolean algebra 8({0, 1}N) of clopen subsets of {0, 1}N. 

1 1 0  
B O O L E A N  A L G E B R A S  
13. See Example 2.57 for the notation used here. 
(a) Show that the map g from {0, 1}P into {0਍ 1}F/"' which, with each 
assignment of truth values 8, associates the homomorphism h0 from F ;Ȇ 
into {0, 1}, is a bijection from {0, 1 }P onto the Stone space S(:F jȆ). 
(b) Show, without using the compactness theorem, that for any subset T of F, 
T is satisfiable if and only if the set T ;Ȇ = {ci(G) : G E T} is a filterbase 
in the Boolean algebra :F IȆ. 
(c) Use this result to provide a new proof of the compactness theorem for 
propositional calculus (Theorem 1.39). 
14. Let A =  {A, <, 0, 1) be a Boolean algebra and let a be an element of A. Let B 
be the principal ideal generated by a (Example following Corollary 2.61) and 
I be the principal ideal generated by aC: 
B = {x E A : x < a}; 
I = { x E A : x < ac } . 
(a) Showthattheorderrelation <B, the restriction to B oftheorderrelation < on 
A, makes B into a Boolean algebra. Compare the operations in this Boolean 
algebra with the corresponding operations in the Boolean algebra A. 
(b) Show that the Boolean algebra { B, <B) is isomorphic to the quotient Boolean 
algebra A/ I. 
15. Let E be a non-empty finite setandletA be the Boolean algebra of subsets of E. 
(a) Show that for a subset I c fiJ (E) to be an ideal of A, it is necessary 
and sufficient that there exists a subset X ै E (strict inclusion) such that 
I = fiJ (X). 
(b) Let C = (C, <, 0, 1) be an arbitrary Boolean algebra and let h be a homo­
morphism from A into C. Show that there exists a unique subset K C E 
such that for every element Y E fiJ (E), h(Y) = 0 if and only if Y c K. 
Let Z be the complement of K in E. 
Show that the restriction of h to fiJ ( Z) is an isomorphism of Boolean 
algebras from fiJ (Z) onto the image of A under h (which is a Boolean 
subalgebra of C). 
16. Let A =  {A, <, 0, 1) be a Boolean algebra. 
(a) Show that if A is finite then every ideal of A is principal. Compare this 
result with that from Exercise 15(a). 
(b) Show that if there exists an integer k > 1 and atoms a I ,  a2, . . .  , ak of A 
such that a I 
..._, a2 ..._, · · · "-./ ak = 1, then A is finite. 
(c) Assume that the Boolean algebra A is infinite. Show that the set 
G = {x E A : 1 + x is an atom} 
is a filter base on A. 

E X E R C I S E S  F O R  C H A P T E R  2 
1 1 1  
(d) Again suppose that A is infinite. Show that for an ultrafilter U on A to be 
non-trivial, it is necessary and sufficient that G be included in U. Use this 
result to reprove Theorem 2.77. 
(e) Show that for the existence of a non-trivial ultrafilter on A, it is necessary 
and sufficient that A be an infinite Boolean algebra. 
17. Let E be a set and let A = {g;; (E), C) be the Boolean algebra of subsets of E. 
(a) Consider a family (E t)iEI of subsets that constitutes a partition of E (which 
means each Et is non-empty, that UtE/ E i = E, and that for i =I= j, 
E i =I= E i). Show that the set 
is a Boolean subalgebra of A and that each of the E; is an atom in this 
Boolean subalgebra. 
(b) Suppose that E is finite and non-empty and that C is a Boolean subalgebra 
of g;; (E). Show that the atoms of the Boolean algebra C constitute a family 
of subsets of E that partitions E .  
(c) Show that i f  E i s  a non-empty finite set, there is a bijection between the set 
of partitions of E and the set of Boolean subalgebras of g;; (E). 
18. (a) I severy Boolean subalgebra of an atomic Boolean algebra an atomic Boolean 
algebra? 
(b) Are there Boolean algebras all of whose Boolean subalgebras are atomic? 
(c) Is every Boolean subalgebra of an atomless Boolean algebra an atomless 
Boolean algebra? 
(d) Are there Boolean algebras all of whose Boolean subalgebras are 
atomless? 
(e) Is every Boolean subalgebra of a complete Boolean algebra a complete 
Boolean algebra? 
(f) Are there Boolean algebras all of whose Boolean subalgebras are 
complete? 
19. Let A and A' be two Boolean algebras and let S(A) and S(A') be their Stone 
spaces. 
(a) Show that we can establish a bijection ¢ between the set Hom(A, A') of 
homomorphisms of Boolean algebras from A into A' and the set C0(S(A'), 
S(A)) of continuous maps from S(A') into S(A). 
(b) Show that for every homomorphism cp E Hom(A, A'), cp is injective 
(respectively, surjective) if and only if ¢ (cp) is surjective (respectively, 
i੅jective). 

3 Predicate calculus 
----
-----
------
---- - -
--- --
-
The fundamental work of the mathematician is to examine structures, to suggest 
properties that might pertain to these and to ask whether these properties are sat­
isfied or not. Predicate calculus is, in some way, the first stage in the formalization 
of mathematical activity. Two aspects are involved: first, we provide ourselves with 
formal tools that are adequate to name these objects (these will be the terms) and 
to express (some of) their properties (these will be the formulas); second, we study 
the satisfaction of these properties in the structures under consideration. 
As with the propositional calculus, the formulas are sequences of symbols that 
are taken from some alphabet and that obey precise syntactic rules. 
There will not be a unique alphabet but rather an appropriate alphabet, called a 
language, for each type of structure under consideration. By structure, we mean a 
non-empty set M, provided with the following: a certain number qf"distinguished 
elements; for each positive integer p, a certain number of p-place relations on M 
(also called 'predicates', hence the expression 'predicate calculus '); and for each 
positive integer p, a certain number of functions from M P into M. Obviously, 
we would not use the same language to speak, for example, of groups and of 
ordered sets. 
Certain symbols are common to all the languages: these are the propositional 
connectives and parentheses, already used in propositional calculus, but also, and 
this is the essential innovation, the quantifiers \:1 (:for all') and 3 ('there exists') 
and the variables vo, VI , . . .. 
The other symbols depend on the type of structure we have in mind; they will 
represent distinguished elements, predicates or fitnctions. For example,for groups, 
we need a constant symbol (to represent the identity element) and a symbol for 
a binary function (to represent multiplication). For ordered sets, we only need a 
symbol for a binary relation. 
The formulas that are involved here are called 'formulas of first order predicate 
calculus'. The reason for this name is that the quantifiers will range over elements 
of the structure. There are numerous mathematical properties for which this re­
striction is fatal. For example, to express the fact that a set A is well ordered, we 
need to say: for every subset B lҧl A, ԭl B is not empty, then B contains a least 
element. We note that the quantŴfier :for all' in this definition ranges over subsets 

S Y N T A X  
1 13 
of· A and not over elements of A. This is a second order quantifier. The concept of 
a well-ordered set is not expressible by a first order formula. 
The problems of syntax, treated in Section 3. /, are substantially more compli­
cated than for the propositional calculus. First of all, because we have to define 
terms before we can define formulas; second, because we have to inttvduce the 
notions of free and bound variable: we immediately sense that the status of the 
variable vo is not the same in the following two formulas: vo + vo ::: vo and 
'v'vo(vo -t- vo ¥ vo). We say that vo is free in the .first and bound in the second. This 
distinction is fundamental in what follows. 
In Section 3.2, we temporarily abandon logic to explain what we mean by struc­
ture. In Section 3.3, we define sati.ҥfaction of a formula in a structure (we also 
say that the structure is a model of the formula). The two facts mentioned above, 
particularly the fact that we will have to define satisfaction for formulas that 
contain free variables, will weigh us down considerably. But the reader must 
noJ be worried: despite its complication, the definition of satisfaction involves 
noJhing more than what the reader would probably have guessed from the 
beginning. 
In Section 3.4 we show that every formula is equivalent to (i.e. is satisfied in the 
same structures as) a formula that is written in a very particular form (with all the 
quant{fiers at the beginning: this is called a prenexform). We will also see how to 
eliminate existential quantifiers by adding function symbols to the language (the 
Skolemform). In Section 3.5, we will present the ABCs of model theory, which is 
the study of the correspondence between a set of formulas and the class of models 
of this set. This will be studied in more depth in ChapterS. Finally, in Section 3.6, 
we will examine the behaviour of equality, which is a binary predicate not quite 
like the others. 
3.1 Syntax 
3.1.1 First order languages 
Definition 3.1 A .first order language (often we will simply say language) is a 
set L of symbols composed of two parts: 
• the.first part, common to all languages, consists, on the one hand, of a countably 
iJ਎finite set, 
V = { VQ, V 1 , •
•
•
 , Vn, •
.
.
 }, 
of elements called symbols for variables or more simply variables, and, on the 
other hand, of the following nine symbols: 
* the parentheses: ), ( and the symbols for the connectives: -, ,  1\, v, =:}, <¢:> 
used previously in propositional calculus, 
* and two new symbols: 
'v', which is called the universal quantifier and is read as 'for all', and 

1 14 
P R E D I C A T E  C A L C U L U S  
3, which is called the existential quantifier and is read as 'there exists at least 
one' or 'for at least one' or simply 'there exists'; 
(each of these quantਏfiers is called the dual of the other),· 
• the second part, which can vary f1vm one language to another, is the union of 
a set C and of two sequences (Fn)nE.N* and (Rn)nE.N* of sets (pairwise disjoint 
and all diਐjoint from C); 
* the elements of C are called constant symbols; 
* for every integer n > 1, the elements of Fn are called n-place (or n-ary 
orofarity n, or with n arguments)function symbols (or functionals) and 
the elements of Rn are called n-place (or n-ary or of arity n, or with n 
arguments) relation symbols (or predicates); (we say unary, binary and 
ternary respectively instead of 1-ary, 2-ary and 3-aly ); 
* we consider one particular symbol with a special status that will be explained 
later: the symbol Ö' called the equality symbol, which, when a first order 
Language contains it, is an element ojR2, i.e. is a binary relation symbol. 
Languages that contain this symbol are called languages with equality. 
Except in one important circumstance (see Chapter 4 ), the languages we 
encounter in this text will be of this type and when we say 'language', with no 
modifier, we always mean a language with equality. 
Of course, all the symbols that we have just listed and which constitute the 
language are assumed to be pairwise distinct. 
Thus, to have a first order language, L, is to define the two sequences (Rn)nEN* 
and (Fn)nEN* and to consider the set: 
The symbols for the constants, the functions and the relations are sometimes 
called the non-logical symbols of the language. Some other presentations differ 
slightly from our own: it can happen that constant symbols are treated as 0-place 
function symbols or that specific 0-place relation symbols are allowed, T ('true') 
and _L ('false'). These slight variants do not modify anything that is essential in 
what follows. 
In most of the cases that we will examine, the languages will involve only a small 
number of symbols for constants, functions and relations, so that in practice, most 
of the sets Rn and Fn will be empty and those that are not empty will contain at 
most two or three symbols. Under these circumstances, rather than give a fa<itidious 
definition of the sequences (Rn )nEN* and (Fn )nEN*, we will be content to provide 
a list of the symbols that appear in these sequences, while indicating their status 
(relation, function) and their arity, and to specify the elements of the set C. 
As it is obviously pointless to repeat, for each language, the unchanged list of 
symbols consisting of, for example, the variables, the connectives and quantifiers, 
we will commit the abuse that consists in identifying a language with the list of its 

S Y N T A X  
1 15 
symbols for constants, functions and relations. Thus, when we are led to say: 
'Consider the language L == { R, c, f, g} where R is a binary relation symbol, c 
is a constant symbol, and f and g are two unary function symbols', this wil1 mean 
that we are interested in the set C == {c} and in the two sequences (Rn)nEN* and 
(Fn)nEN* defined by: 
R2 == {Ö, R}, Rn == 0 
for n I- 2, 
F 1 == {f, g} and Fn == 0 
for n > 2. 
(In the absence of any mention to the contrary, the language will be one with 
equality.) 
Starting from a first order language viewed as an alphabet, we will now construct, 
following the inductive method used previously for the propositional calculus, a 
family of words that we will call the first order formulas associated with our 
language. To do this will require an intermediate step in which we define, also 
inductively, another family of words called terms. 
As our ultimate purpose is to use the language to formally describe certain 
properties of mathematical objects (or individuals), we may intuitively consider 
that terms will serve as names to denote these individuals whereas the formulas 
will serve as statements of facts concerning them. 
Let us consider a first order language L. 
3. 1.2 Terms of the language 
The symbols that serve as raw materials for the construction of terms are the 
variables and the function symbols. Note that the parentheses are not involved in 
writing terms. 
Definition 3.2 The set T(L) ofterms of the language L is the smallest subset of 
W(L) that: 
• contains the variables and the constant symbols (i.e. includes the set V U C); 
• is closed under the operation 
for every integer n > I and every element f E Fn. 
In other words, terms are words that can be obtained by applying the following 
rules a finite number of times: 
• variables and constant symbols are terms (recall that we do not distinguish 
between a symbol of the alphabet and the word of length I consisting of this 
symbol); 
• if n E N*, if f is an n-ary function symbol of L, and if t1, t2, . . .  , tn are terms, 
then the word f t1 t2 . . .  tn is a term. 

1 16 
P R E D I C A T E  C A L C U L U S  
After this definition 'from above', let us consider the equivalent definition 'from 
below': 
Set To(L) = V U C, and for every integer k, set 
7k+ 1 ( L) = 7k ( L) U u { f t 1 t2 . . .  In : .f E F,z, t 1 E 7k ( L), 
nE.N* 
t2 E 7k ( L), . . . , t 
n E 7k ( L)}. 
Definition 3.3 The lwight of a term t E T(L) is the least integer k such that 
t E 7k(L). 
Observe that in a language, there are always terms of height 0: the variables; but 
it is altogether possible that there are no terms whose height is non-zero (this will 
happen when there are no function symbols at all). 
For terms, we can define the concept of a decomposition tree in a manner anal­
ogous to the one we used for formulas of the propositional calculus, with the 
difference that at each node, there can be any number of branches, this number 
being precisely the arity of the function symbol used at the given stage in the con­
struction of the term. There will also be a unique readability theorem (3. 7) which 
wi II guarantee the uniqueness of the decomposition tree. 
Consider, for example, the language that has one constant symbol c, one unary 
function symbol f and a ternary function symbol g. Consider the word 
W = ggffvogv2vocfcff8fcgv2fvof}'cfcfc. 
Is this a term of the language? 
After careful inspection, or a few probings, or with a bit of luck, by setting 
r = gff'vo8V2vocfc, s == ffgfcgv2fvoffcfc, 
and t = fc, 
and, even better, by inserting spaces wisely, 
r = g ffvo gv2voc fc, s = f fg fcgv2fvoffc fc, 
and t = fc, 
w 
/ 
/ 
r 
"" 
s 
ffvo 
/ 
gv2voc -Ƅ 
fc 
Sl 
I 
I 
I 
I 
fvo 
112 
vo 
c 
c 
/ 
S2 
--Ƃ 
I 
• 
• 
• 
• 
I 
vo 
fc 
/ 
SJ -ƅ 
fc 
• 
I 
I 
I 
c 
'V2 
fvo 
ffc 
c 
• 
• 
I 
I 
• 
vo 
fc 
• 
I 
c 
• 
ƃ 
t 
I 
c 
• 

S Y N T A X  
1 17 
we discover that r, s and t really are terms and that the proposed word W, 
which is written grst (a ternary function symbol followed by three terms), is 
itself a term (of height 7) whose decomposition tree is not difficult to sketch (to 
improve its legibility we have set s3 == gv2fvoff c, s2 == gf cs3f c and s1 == f s2, 
so that s == fst). 
The theorem that follows furnishes a simple test for determining whether a word 
in a given language is or is not a term. It also provides, when the test is positive, 
a method for finding the decomposition of the term. Finally, it provides us with a 
simple proof of the unique readability theorem. First we give a definition: 
Definition 3.4 The weight of a function symbol is equal to its arity minus 1. The 
weight of a variable or a constant symbol is -1. If W is a word written with 
variables, constant symbols and function symbols, the weight of W, denoted by 
p( W), is the sum of the weights of the symbols that occur in the word W (the 
weight of the empty word is 0). 
We say that a word W satisfies the rule of weights if and only ਑{the weight 
of W is -1 and the weights of all its proper initial segments are greater than or 
equal to 0. 
Theorem 3.5 For a word W, written with variables, constant symbols and func­
tion symbols, to be a term, it is necessary and sufficient that it satisfy the rule of 
weights. 
Proof First we will show, by induction, that all terms satisfy the rule of weights. 
As far as variables and constant symbols are concerned, this is clear: their weight 
is equal to - 1  and they do not admit any proper initial segments. 
Consider an integer n > 1, an n-ary function symbol f and n terms t1 , t2, . . .  , tn 
which are assumed (by the induction hypothesis) to satisfy the rule of weights. 
Set t == f t1 t2 · · · tn. 
We have p(t) == p(f)+p(tt ) + p(t2) + · · · + p(t11) == n - 1 +n x (-1) == -1. 
Now let m be a proper initial segment of t. Then there exists an index i E 
{ I ,  2, . . .  , n} and an initial segment m; of t; such that 
Note that if i == n, mi is necessarily a proper initial segment oft; but that if i =I= n, 
then m; might also equal t; or the empty word. 
We have 
p(m) == p(f) + p(tt ) + p(t2) + · · · + p(t;-I) + p(m;) 
== n - l + (i - 1) x ( -1) + p (m;) 
(by the induction hypothesis) 
== n - i + p(m; ). 
Now, by the induction hypothesis, p(mi) is either - I  or is an integer greater than 
or equal to 0 (according as mi == t; or not). It follows that p(m) > n - i - 1 ,  which 

1 18 
P R E D I C A T E  C A L C U L U S  
IS a number greater than or equal to zero if i is strictly less than n. If i = n, then 
m; -=/= li (otherwise m would equal t), and so p(m) = p(m; ) > 0. 
We see then that, in all cases, the weight of m is greater than or equal to zero, 
which shows that t satisfies the rule of weights. 
Now we have to show the converse: that every word that satisfies the rule of 
weights is a term. We will prove it by induction on the length of words. 
The word of length 0 does not satisfy the rule of weights (its weight is 0). 
If a word of length l satisfies the rule of weights, then its weight is - 1 .  Thus 
we are dealing with either a variable or a constant symbol, so it is, in all cases, 
a term. 
Consider an integer k > 1 .  Suppose (this is the induction hypothesis) that any 
word of length strictly less than k that satisfi.es the rule of weights is a term. 
Consider a word W of length k which satisfies the rule of weights. For example, 
where the ai are variables or constant symbols or function symbols (so that 
p(ai) > - 1  for every i). 
Thus we have p(W) = -1 and, for every i E { 1, 2, .
. . , k - 1}, 
Since k > 1, a 1 is a strict initial segment of W; thus p( a1 ) > 0, which shows that 
a 1 must be a function symbol of arity at least equal to 1 .  Denote this arity by n + 1 
(n = p(at) > 0). 
Ifn == 0, the worda2a3 . . .  ak satisfies the ruleofweights (suppressing the initial 
symbol of weight 0 changes neither the total weight nor the weights of any proper 
initial segments); since the length of this word is k - 1, the induction hypothesis 
applies: therefore a2a3 . . .  ak is a term; and so is W since, in this case, a 1 is a 
unary function symbol. 
Now let us examine the case n > 0. 
Denote by ¢ the map from {I, 2, . .
. , k} into tZ which associates with each 
index, i, the value 
Wehave ¢ ( 1 )  = n  > O and ¢ (k) = - l . Since the passage from ¢(i) to ¢(i + l) 
adds an integer, p(a;+I), that i s  greater than or equal to -1, we see that the map 
¢, to get from its initial value n to its final value -1, must assume each of the 
intermediate values n - 1 ,  n 
- 2, . .
. , 1, 0, at least once (this function cannot 
decrease by more than 1 at each step). 
Denote by it (and by .h , . . .  , in respectively) the first integer in { 1, 2, . . .  , k} 
for which the function ¢ takes the value n - 1 (n - 2, .
. . , 0 respectively). Extend 
this by setting jo = 1 and j11+ 1 = k so that ¢ (jo) = n and ¢ (j11+ 1 )  = - 1 .  

S Y N T A X  
1 19 
We must have 
io == 1 < j1 < i2 < · · · < in < in+l == k. 
(The argument that we just gave can be repeated to prove that the function ljJ can 
not pass from the value ¢ ( 1) = n to the value ¢ (j2) = n - 2 without assuming at 
least once the value n - 1 ,  hence j1 < .i2, and so on.) 
Set 
We are going to show that each of these n + 1 words is a term; given that a1 is a 
function symbol of arity n + I and that the word W is written a 1 tt t2 . . .  tn+ 1 ,  this 
will prove that W is also a term. 
Let h be an integer such that 1 < h < n + 1 .  We have 
hence 
p(th ) == </J (jh) - </J(jh-I )  = n - h - (n - (h - 1)) = -1. 
Moreover, if th had a proper initial segment whose weight is strictly negative, this 
would mean that there exists an index i E {jh-1 + I ,  . . .  , jh - 1 }  such that 
p (ajh-I + l  . . .  ai) = ¢(i) - ¢(ih- I )  = ¢(i) - (n - (h - 1)) < 0; 
or again, 
¢(i ) < n - h. 
But ¢ (j h-1 )  = n - h + l. According to the argument already used twice previ­
ousJy, the value n - h would then be assumed by the function ¢ for some index 
between j h- l and i, i.e. strictly less than j h, and this would contradict the definition 
of ih· 
We have thereby proved that th satisfies the rule of weights and, as its length is 
strictly less than k, we conclude from the induction hypothesis that it is a term . 
• 
The unique readability theorem (for terms) will be proved in two stages. 
Lemma 3.6 For any term t E T(L), no proper initial segment oft is a term. 
Proof This is an immediate consequence of the rule of weights: if t is a term and 
u is a proper initial segment of t, then the weight of u is positive or zero, and so u 
cannot be a term. 
• 

120 
P R E D I C A T E  C A L C U L U S  
Theorem 3.7 (unique readability theorem for terms) For any term t E T(L), 
one and only one of the following three cases applies: 
• t is a variable of L; 
• t is a constant symbol of L; 
• there is a unique integerk > 1, a unique k-aryfunction symbol f oft he language 
L and a unique k-tuple (u1 , u2, . . .  , Uk) E T(L)k such that t = fu1 u2 . . .  Uk-
Proof Consider a term t E T(L). By the definition of T(L), we are in one of 
the first two cases, or else in the third but without any guarantee in advance of 
uniqueness. It is clear, moreover, that these three cases are mutually exclusive (to 
see this, it suffices to examine the first symbol in the word t). So the only thing 
that we have to prove is the uniqueness for the third case. 
For this, consider two natural numbers k and h, two function symbols f and g of 
the language L that are k-ary and h-ary respectively and k + h terms tr , t2, . . .  , tk, 
u 1 ,  u2, . . .  , Uh in T(L) and suppose that: 
From this equality, we conclude that f and g are identical (they are the first 
symbols of the same word) hence their arities are equal. So we have 
Suppose now that there is some index i E { 1 ,  2, . . .  , k} such that 
tt = u1, t2 = u2, . . .  , t;-1 = Ui-1, and t; =/= u;. 
After simplifying, we obtain 
which proves that one of the two terms t; and u; is a proper initial segment of 
the other (this property was established at the beginning of the text in the section 
'Notes to the Reader'). But this situation is precisely what is forbidden by the 
preceding lemma. 
• 
Definition 3.8 A term in which there is no occurrence of a variable is called a 
closed term. 
We immediately see that a closed term must contain at least one occurrence of 
a constant symbol. It follows that for a language that has no constant symbols, 
there are no closed terms. 
Notation: Given a term t E T(L) and pairwise distinct natural numbers 
i I ,  i2, . . .  , in, We will USe the notation t = t [ Vf 1 ,  V;2, . . .  , Vi,] to indicate that the 
variables that have at least one occurrence in the term t are among Vi 1 ,  Vi2, •
•
•
 , Vi11 • 

S Y N T A X  
121 
We should note that for any term t, there is an integer m such that 
t = t [ VQ, VI , 
•
•
•
 , Vm]; 
(because t involves only a finite number of symbols, and hence a finite number of 
variables, it suffices to let m be the largest of the indices of all the variables that 
have at least one occurrence in t ). 
3.1.3 Substitutions in terms 
Definition 3.9 Let k be a natural number, let w 1 ,  w2, . . .  , Wk be pairwise distinct 
variables, and let t, UJ, u2, . . .  , Uk be terms. The word tu1 Jw1 ,u2;w2, ... ,uk/wk (read 
as 't sub u I replaces w I ,  u2 replaces w2, . . .  , Uk replaces Wk ') is the result of 
substituting the terms u 1 ,  u2, . . .  , ukfor the variables Wt, w2, . . .  , Wk respectively 
for all occurrences of these variables in t and it is defined by induction (on t) as 
follows: 
• Ŵlt is a constant symbol or a variable other than WJ, w2, . . .  , Wk, then 
• (/' t = Wi ( I  < i < k), then 
• if t = fti t2 . . .  tn (where n is an integer greater than or equal to I, f is an 
n-ary function symbol and t1, t2, . . .  , tn are terms), then 
tu I /WI ,U2/W2• ···•llk /Wk 
== f t 1 
I 
· 
I 
· 
I t2 I · 
I 
· 
I 
· · 
· tn 
I 
I 
I 
· 
. 
111 1q .u2 ll-2·· . •  uk Wk U )  Wt ,Li2 u,2 ..... Uk Wk 
U! Wl .U2 W2··-·•Llk U'k 
Lemma 3.10 For any natural number k, any pairwise distinct variables w 1 ,  
w2, . . .  , Wk, and terms t, u J, u2, . . .  , uਛc, the word tu1 fw1,u2fw2, .... ukfwk is a term. 
Proof The proof is obvious by induction on t. 
• 
Notation: Given two natural numbers k and h, k + h variables z 1 ,  22, . .
. , Zh, 
W t, 1v2, .
.
•
 , Wk, a term t[ZI , 22, . .
. , Zh, w 1 ,  w2 , . . .  , Wk], andk terms u,, u2, . . .  , 
Uk, the term tu1;w1 .u2;w2, ... ,ukfwk will be denoted by 
Remark 3.11 
• Obviously, it is merely for convenience in writing that we have listed the vari­
ables in an order such that those involved in the substitution appear at the end 
of' the list. It goes without saying that given, for example, a term 

122 
P R E D I C A T E  C A L C U L U S  
and two arbitrary terms u and u', we understand that the expression 
t [ W I , U 1 ,  W3 , U , W 5] 
can be used to denote the term 
• The notation involving brackets presents some inconveniences analogous to 
those we discussed earlier concerning substitutions in formulas of the pro­
positional calculus (see Chapter 1). We will use it, but with the usual 
precautions. 
• As with the pro positional calculus, it is appropriate to recall the fact that the 
substitutions defined above take place simultaneously; the same substitutions, 
implemented one after another, yield diferent results, in general, which depend, 
among other things, on the order in which they are peiformed. 
3.1.4 Formulas of the language 
We will now undertake the definition, by induction, of the set of formulas of the 
language L. Here, first of all, are the formulas 'on the ground floor' (those that 
will have height 0); we call these the atomic formulas. 
Definition 3.12 A word W E  W(L) isanatomicformula {fandonlyifthere exist 
a natural number n E N*, an n-ary relation symbol R, and n terms It, t2, . . .  , tn 
of the language L such that 
In the case where L is a language with equality and t and u are arbitrary terms 
in T(L), we agree to write 
t ¥ u  
for the atomic formula 
 tu. 
We will denote the set of atomic formulas of the language L by At(L). 
Observe that we have unique readability for atomic formulas: we can easily 
convince ourselves by noting that an atomic formula becomes a term if we replace 
its first symbol (which is a relation symbol) by a function symbol of the same arity; 
it then suffices to apply the unique readability theorem for terms to obtain unique 
readability for atomic formulas (the convention we introduced for the equality 
symbol presents no difficulty in this matter). 
We may now proceed with the definition of the set of formulas of L .  

S Y N T A X  
123 
Definition 3.13 The set F(L) of(jirst order)formulas of the language L is the 
smallest subset ofW(L) that 
• contains all the atomic formulas; 
• whenever it contains two words V and W, it also contains the words 
-. W, 
(V 1\ W), (V v W), (V =} W), 
(V <=> W) 
and, for every natural number n, the words 
Vvn W and 3vn W. 
Given two formulas F and G in F(L), theformulas -.F, ( F  1\ G), and ( F  v G), 
are called, respectively: the negation of the formula F, the conjunction of the 
formulas F and G and the disjunction of the formulas F and G. 
We are naturally led to compare the definition above, or at least the part of 
it that concerns the propositional connectives, to the definition of propositional 
formulas given in Chapter 1 .  We note in this context that the role played there 
by the propositional variables is played here by the atomic formulas. The major 
difference arises from the fact that there, the propositional variables were primary 
indecomposable ingredients whereas here, the atomic formulas are already the 
product of a fairly complicated construction. It is essential, in any case, not to 
imagine any analogy between the propositional variables of Chapter 1 and what, 
in this chapter, have been called variables; here they are certain symbols that are 
constituents of terms, which in turn are ingredients in the production of atomic 
formulas. The other obvious fundamental difference between the two situations is 
the appearance of quantifiers which provide new means for constructing formulas. 
By analogy with Theorem 1 .3, the following theorem, whose proof is left to the 
reader, provides a description 'from below' of the set of formulas. 
Theorem 3.14 Set 
Fo(L) = At(L); 
and, for every integer m, 
Fm+I (L) = Fm(L) U {-.F : F E  Fm (L)} 
U { (F a  G) : F E  Fm(L), G E :Fm(L), a E {A, v, =}, ¢> } }  
U {VvkF : F E  Fm(L), k E N} U {3vk F: F E  Fm(L), k E N}. 
We then have 
F(L) = U Fn(L). 
nEN 
As it should be, the height of a formula F E F(L), denoted by h[F], is the 
smallest integer k such that F E Fk ( L). 

124 
P R E D I C A T E  C A L C U L U S  
For first order formulas, there is a unique readability theorem: 
Theorem 3.15 (Unique readability theorem for formulas) For any formula F E 
F(L), one and only one of the following five cases applies: 
• F is an atomic formula (and there is then only one way in which it can be 
tread'); 
• there is a unique formula G E F(L) such that F = -,G; 
• there is a unique pair of.formulas ( G, H) E F ( L) 2 and a unique symbol for a 
binary connective a E {A, v, ==>, <=:>} such that F = (G a H); 
• there exists a unique integer k and a unique formula G E F ( L) such that 
F ::: 'VvkG; 
• there exists a unique integer k and a unique formula G E F(L) such that 
F = 3vkG. 
Proof We can easily adapt the proof given for the case of formulas of the propo­
sitional calculus: here too, it is clear that the five cases are mutually exclusive 
and that at least one of the cases is applicable (ignoring the feature of unique­
ness). In the last two cases, for which the propositional calculus has no analogue, 
uniqueness is obvious. In the fi.rst case, unique readability has already been noted 
(in the paragraph that follows Definition 3.13); in the second and third cases, the 
proof from Chapter 1 carries over with no problems (in particular, the relevant four 
lemmas concerning parentheses and proper initial segments remain valid). 
• 
Here too, we can speak of the decomposition tree of a formula: relative to the 
propositional calculus, the changes are, on the one hand, that the leaves are the 
atomic formulas and, on the other hand, that there are three kinds of unary branching 
instead of one: 
F 
The sub-formulas of a first order formula are those that appear at the nodes of 
its decomposition tree. To be precise: 
Definition 3.16 The set sf(F) of sub-formulas of a formula F E F(L) is defined 
by induction as follows: 
• ifF is atomic, 
sf(F) = {F}; 
• ifF = -,G, 
sf(F) = {F} U sf( G); 

S Y N T A X  
• ifF = (G a H) where a is a symbol for a binary connective, 
sf(F) = {F} U sf( G) U sf(H); 
sf( F) = {F} u sf( G). 
1 25 
3.1.5 Free variables, bound variables, and closed formulas 
Definition 3.17 Given a natural number k and a formula F E F(L), the occur· 
rences, if any, of the variable Vk in the formula F can be of two kinds: free or 
bound. We proceed by induction: 
• ifF is atomic, then all occurrences of Vk in F are free; 
• ifF = -ਅG, the free occurrences ofvk in F are the free occurrences ofvk in G: 
• ifF = (G a H) where a isasymbolforabinaryconnective, the free occurrences 
ofvk in F arethefreeoccurrencesofvk in G andthefreeoccurrencesofvk in H :  
• if F = YvhG or if F = 3vh(G), (h =I= k), thefree occurrences ofvk in F are 
the free occurrences of Vk in G; 
• ਆf F = YvkG or ਇf F = 3vk(G), none of the occurrences ofvk in F is free. 
The occurrences of Vk in F that are not free are called bound . 
Concerning thepassagefromtheformula G totheformula'VvkG (3vkG, respec­
tively) we say that the variable Vk has been universally quantified (existentially 
quantified, respectively) or that the formula G has been subjected to univer·· 
sal quantification (existential quantification, respectively) with respect to (or 
over) the variable Vk-
Example 3.18 In the language L = { R, c, f} where R is a binary relation symbol, 
c is a constant symbol and f is a unary function symbol, consider the formula 
F =  
Yvo(3viYvo(Rvivo ==> -wvo ¥ v3) 1\ Yv2(3v2(Rv1 V2 v fvo ¥ c) 1\ v2 " v2)). 
I n  F, all occurrences of vo and all occurrences of v2 are bound; the first two 
occurrences of v 1 are bound while the third is free; finally, the unique occurrence 
of v3 is free. 
Definition 3.19 The free variables in a formula F E F(L) are those variables 
that have at least one free occurrence in F. A closed formula is one in which no 
variable is free. 
Thus, in the preceding example, the free variables in F are VI and V3. Conse­
quently, F is not a closed formula. 
We should also note that a closed formula need not contain any quantifiers: 
the formula Rf cc is a closed atomic formula in the language of Example 3. 18. 

1 26 
P R E D I C A T E  C A L C U L U S  
However, in a language without constant symbols, there are no closed formulas 
without quantifiers. 
Notation: Given a formula F E F(L) and pairwise distinct natural numbers i 1 ,  
i 2 ,  . .
. , in, we will use the notation F = F[ v; 1 , v;2, • • •  , v;,] to indicate that the 
free variables of the formula F are among v;1 ,  v;2, • . • , V;11 • 
As is the case for terms, we should note that for every formula F E F(L), there 
exists an integer m such that 
F = F r vo' v l ' . . .  ' Vm]. 
Definition 3.20 Given a formula F = F[ v;1 , v;2, • • •  , v;, J of the language L in 
which each of the variables v; 1 ,  v;2, • • •  , v;11 has at least one free occurrence, the 
formula 
and all similar formulas obtained by permuting the order in which the variables 
v; 1 ,  v;2, • • . , v;n are quant{fied are called universal closures of the formula F. 
Observe that the universal closures of a formula are closed formulas. 
Remark 3.21 We hardly ever distinguish among the universal closures of a for­
mula F and we speak of the universal closure of F, intending in this way to 
denote any one of them (the choice might be dictated by the order in which the 
free variables ofF occur or by the order of their indices or by some other con­
sideration). This abuse of language is unimportant: we will see that the various 
universal closures of a formula are all equivalent for our intended purposes, both 
from the semantic point of view (in the sections that follow) and for formal proofs 
(see Chapter 4 ). 
Let us return to the formula F in Example 3 . 1 8. We said that the third oc­
currence of the variable v1 , as opposed to the first two, is free. This is because, 
as the decomposition tree of F makes clear, the quantification 3vl 'acts' on the 
first two occurrences but not on the third. We say that the first two occurrences 
of VI are within the scope of the quantifi.er 3v1 • Anticipating a precise general 
definition, consider the occurrence in a formula F of a quantifi.er Qv (where Q 
denotes V or 3 and v the variable that necessarily follows Q in F). The word 
Qv is necessarily followed, in the word F, by a (unique) sub-formula G of F 
(the word QvG being, in turn, a sub-formula of F which could be character­
ized as the sub-formula of least height that contains the occurrence of Qv under 
consideration). 
Definition 3.22 Using the preceding notation, the occurrences ofv that are within 
the scope of the quantifier Q v are the free occurrences of v in G as well as the 
occurrence of v that immediately follows the quantŴfier Q. 

S Y N T A X  
127 
For example, in the formula 
3v(((v ͕ v) v Vv-,(v ¥ v)) z v Ö v), 
the occurrences of v that are in the scope of the first quantifier are the first three 
and the last two. The fourth, fifth and sixth occurrences are excluded, despite their 
being in the 'geographical range' of 3v, because it is reasonable to agree that each 
occurrence of a variable is within the scope of at most one quantifier. 
3.1.6 Substitutions in formulas 
We will now define the notion of substitution of terms for free variables in 
a formula. The variables in a formula necessarily occur inside terms, and since 
substitution of terms for variables in a term has already been defined, our new 
definition would be automatic if it were not for an important restriction that will 
apply: substitution will only take place for the free occurrences of the variables 
under consideration. The definition is given, as we might expect, by induction. 
Definition 3.23 Consider a formula F, a natural number k, pairwise distinct 
variables w [, w2, . . . , Wk and terms u I, u2, . .
. , uk. The word Fu, fw1 ,u2jw2, 
• . •  ,ukfwJ. 
(read: 'F sub u I replaces w 1 ,  u2 replaces w2, . . .  , Uk replaces w k ') is the result 
of substituting the terms u 1 ,  u2, . . .  , Uk respectively for all free occurrences oftluਈ 
variables WI, w21 . . . , Wk in the formula F and it is defined as follows: 
• if F is the atomic formula Rti t2 . . .  tn (where n is an integer greater than or 
equal to I, R is an n-ary relation symbol and ti, t2, . . .  , tn are terms), then 
• if F == DG, then 
• if F = (G a H) where a is a symbolfora binary connective, then 
• if F = VvG (v ¢:. {wl, w2, . . .  , Wk}), then 
Fu 1 /WJ ,u2fw2,---,uk/Wk == VvGu 1 /WI ,u2fw2,····ukfwk ; 
• if F = 3vG (v ¢:. {wt, w2, . . . , Wk}), then 
Fut jw, ,u2fw2.--.,uk/wk = 3vGu l fwt ,u2/W2,····uk/Wk ; 
• if F == Vw; G (i E { 1 ,  2, . . . , k}), then 

128 
P R E D I C A T E  C A L C U L U S  
• if F = 3wi G (i E { 1 , 2, . .
. , k}), then 
Fu l  fwt .U2/W2 
• . . .  ,uk fwk == 3wi Gu 1 /Wt ,uz/Wz , ... ,u;--I /w;_, ,u;+I /wi+I , .... uk fwk 
• 
Notation: Given two natural numbers h and k, h + k variables z 1 ,  22, 
.
.
•
 , Zh , 
WJ, wz, . . .  , Wk, a formula F[zt, 22, . . .  , Zh , Wf ,  wz, . . .  , Wk], and k terms U J ,  
uz, . . .  , Uk, the formula Fu1 fw1 ,u2 fw2, ... ,ukfwk will be denoted by 
This notation requires certain precautions similar to those already noted con­
cerning terms. Remark 3. 1 1 concerning the distinction between simultaneous and 
successive substitutions and the influence of the order of substitutions is relevant 
here too. 
Example 3.24 Let us revisit the formula that we have used previously as an 
example: 
F ==  
Vvo (3vt Vvo(Rv1 vo :::} ]vo Ö v3) 1\ Vvz (3vz (Rvl vz v fvo Ö c) 1\ vz ¥ vz)). 
Let t denote the term jj·c. Then the word FrJv1 is 
The result of substituting terms for the free variables in a formula is always a 
formula: 
Lemma 3.25 Consider a formula F, a natural number k, pairwise distinct vari­
ables WJ, wz, . . . , Wk andterms u1, uz, . . .  , Uk. The word Fu1 fw1 .u2fw2 
• . . . ,ukfwk is 
a formula. 
Proof The proof is immediate by induction on F. 
• 
Another kind of substitution, analogous to what we have already encountered 
with the propositional calculus, consists in replacing, in a given formula of the 
language, an occurrence of some sub-formula by some other formula. Without 
going into the details of a precise definition, we are content to point out what is 
essential: the result of these substitutions is always a first order formula. 
More important, because they are more delicate, are substitutions that we will 
call renaming a bound variable. This involves, specifically, the substitution into 
a formula of a variable (and not an arbitrary term!) for some given variable at all 
the occurrences of this variable that are in the scope of some given quantifier. For 
example, in our formula 
F =  
Vvo(3v1Vvo(Rvl vo :::} _,vo £ v3) 1\ Vvz(3vz(Rv1 vz v fvo Ö c) 1\ vz ¥ vz)), 

S Y N T A X  
1 29 
we can rename the bound variable vz by substituting Vs for all occurrences of vz 
that are within the scope of the quantifier \:lvz. This leads to the formula 
F ==  
'Vvo(3vt'Vvo(Rvivo =} -.vo  v3) 1\ \:lvs(3vz(Rv! V2 v fvo Ö c) 1\ vs £ vs)). 
ln general, if, in a formula H, there is a sub-formula QvG, then changing the 
name of the variable v to w in the scope of the quantifier Qv consists in simply 
replacing the sub-formula QvG in H by the formula 
QwGwfv · 
So we see that the result obtained is necessarily a formula. 
Remark 3.26 Renaming a bound variable is a p1vcedure that deserves the great­
est care. We may be tempted to believe that this is merely an anodine transforma­
tion that preserves the 'meaning' that we will later be giving to formulas (in other 
words, if we may anticipate, which transforms a formula into a logically equiv­
alent formula). However, this may be false if we do not take certain precautions 
(we will see which ones at the appropriate time: Proposition 3.54 and Chapter 4 ). 
For example, in the formula 3w'Vv v ! w, changing the name of the variable v t(; 
w leads to the formula 3w'Vw w ¥ w which, we may suspect, will not have the 
same meaning as the first. 
We have not reserved any special notation for these name changes of bound 
variables. 
Before concluding this presentation of syntax, we will mention one more type 
of substitution that is of a slightly different nature from the ones we have treated 
so far but which is just as common. We will not dally over its definition nor on the 
fact, important but easy to verify, that the result of these substitutions is always 3 
first order formula. 
This involves starting from a formula J of the propositional calculus on an ar­
bitrary set P of propositional variables and substituting for each propositiona' 
variable, at each of its occurrences in J, a first order formula of the language 
L. Here is an example involving the language L = { R, f, c} used above. Sup­
pose that A, B and C are propositional variables and consider the propositiona I 
formula 
J = J[A, B, C] = ((A 1\ B) => (-.A v C)) 
and the following three formulas of the language L: 
F = \:lvo-Rv! vo; 
G = (vi J c :::} 3vzRvt .fvz); 
H = -.f c :::=: c. 

130 
P R E D I C A T E  C A L C U L U S  
Then by substituting the formulas F, G, and H respectively for the variables A, 
B, and C in the propositional formula J, w e  obtain the first order formula 
which we may choose to denote by J [ F, G, H] if this does not create an ambiguity. 
Remark 3.27 Every formula without quantifiers is obtained by a substitution of 
the typejustdescribed: it suffices to treat the set ofatomicformulas of the language 
as the pro positional variables. 
3.2 Structures 
The word 'structure' is generally understood in mathematics to mean a set on which 
a certain number of functions and relations (or internal operations) are defined 
along with, upon occasion, what are habitually called 'distinguished elements'. 
For example, the ordered field of real numbers i s  the structure 
(IR, <, +, X '  0, 1 )  
(sometimes, it is considered superfluous to specify the two identity elements so 
these might be omitted); the additive group of integers is the structure (Z, +) 
(or (Z, +, 0)). The formulas that we have described in the previous section serve 
to express properties of such structures. For this purpose, the language must be 
adapted to the structure under consideration. Thus, we can easily guess that to speak 
of the ordered field of real numbers, the language will require a binary relation 
symbol R (intended to represent the order <), two binary function symbols f and 
g (for the two operations + and x ), and, upon occasion, two constant symbols c 
and d (for 0 and 1 ). In this situation, we would express the fact that 1 is an identity 
element for multiplication by saying that the first order formula 
Vvo(gvod ͔ Vo 1\ gdvo ru Vo) 
is satisfied in the given structure. As for the formula 
it is satisfied because there exists an identity element for addition. But the formula: 
is not satisfied because the binary relation < on IR is not symmetric. 
What about the formula Rcvo? We realize that the question of whether this for­
mula is satisfied or not does not make sense in the absence of any specification 
concerning the individual vo. However, it seems natural to say that Rcvo is sat­
isfied when the real represented by vo is n and that it is not satisfied when vo 
denotes - 1. 

S T R U C T U R E S  
1 3 1  
So w e  see that the concept of satisfaction of a formula will need to be defined 
carefully and that the definition must take into account, in an essential way, the 
presence or absence of free variables in the formula under consideration. Another 
observation is forced upon us by these few examples: the syntax that we have 
defined requires us to break some entrenched habits; if the act of representing 
multiplication by some symbol other than x does not bother us much, the change 
from the usual way of writing vo g V t  to writing gvov1 (so-called 'prefix' or 'Polish' 
notation) can be more disturbing. However, this Polish notation is necessary if we 
wish to have a uniform syntax, applicable in all situations and, in particular, to the 
representation of functions whose arity is greater than 2. The other considerable 
advantage of Polish notation is to free us from the use of parentheses which, with 
the standard way of writing binary operations, we could not do without. The same 
remark applies, to a lesser degree, to atomic formulas: we hardly ever write < vo v 1 
instead of vo < v 1, but the prefix notation is none the less encountered occasionally. 
The purpose of all these remarks is to prepare the reader for a series of definitions 
that are marked by the constraints of syntax. Following a path that is familiar to 
mathematicians, once these definitions have been given, we will immediately begin 
committing all sorts of abuses, writing vo x v 1 and 1 < 0 instead of gvov1 and Rd c 
and, more generally, taking any measures that render a formula more intelligible, 
at the risk of scandalizing those for whom rigour is sacrosanct. But we are not 
there yet! 
We will, in an initial phase, give a series of purely algebraic definitions and 
properties that relate to structures, with syntax involved only incidentally (the 
language will serve to make precise the type of structure under consideration 
while the formulas will have no role to play in this first phase). After defining 
structures, we will examine certain tools that allow us to compare them: sub­
structures, restrictions, homomorphisms, isomorphisms. 
(t is only in Section 3.3 that we will approach the purely logical aspect of things 
by presenting the notion of satisfaction of a formula in a structure. 
3.2.1 Models of a language 
Consider a first order language L that is not necessarily a language with equality. 
Definition 3.28 A model of the language L, or L-structure, is a structure M 
consisting of 
• a non-empty set M, called the domain or the base set or the underlying set of 
the structure M; 
• for each constant symbol c of L, an element eM of M called the interpretation 
of the symbol c in the model M; 
• for every natural number k > 1 and for eve1y k-ary function symbol f of L, a 
mapping fM from Mk into M (i.e. a k-ary operation on the set M) called the 
interpretation of the symbol f in the model M; 

1 32 
P R E D I C A T E  C A L C U L U S  
• for every natural number k > 1 and for every k-ary relation symbol R of L, a 
subset RM of Mk (i.e. a k-ary relation on the set M) called the interpretation 
of the symbol R in the model M. 
• In the case where L is a language with equality, we say that the model M 
respects equality {f ""M, the interpretation in M of the equality symbol of L. 
is the equality relation on M (i.e. is the set {(a, b) E M2 : a = b}, also called 
the diagonal of M2 ). 
As we have already mentioned, only exceptionally (see Section 3. 7) will we 
deal with languages without equality. Thus, in the absence of any indication to the 
contrary, 'language' and 'model' will always mean, respectively, 'language with 
equality' and ੆model that respects equality'. 
It is important to remember that the base set of a first order structure must be 
non-empty. 
In practice, models will be described in the following way: we will denote models 
by calligraphic letters (usually M or N) and will usually use the corresponding 
Latin letter to denote the underlying set; we will then provide the interpretations 
of the various symbols for constants, functions and relations (preferably in the 
same order that was used in the presentation of the language): this may range 
from a simple enumeration (in circumstances where there are standard symbols or 
names for these interpretations) to a more laboured definition. Thus, if the language 
L = { R, f, c} involves a binary relation symbol R, a unary function symbol f and 
a constant symbol c, it will suffice to write 
N = (¨, <, cos, n) 
to define the model of L in which the base set is the set of reals and in which the 
interpretations of the symbols R, f and c are respectively the usual order relation, 
the map x . cos x, and the real number n .  On the other hand, we would need a 
bit more space to define the L-structure 
M = (M, RM. fM, eM) 
whose underlying set is the set of natural numbers that are not divisible by 5, and 
in which 
• the relation RM is defined by the following: for every a and b in M, (a, b) E 
RM if and only if gcd(a, b) = 3; 
• the map JM is the one which, to each element a E M, associates the integer 
a +  Ioa; and 
• 
eM is the first prime number which, written in base 1 0. requires at least a million 
digits. 
We emphasize that in this example, the language is one with equality and that 
the model M respects equality since there was no mention to the contrary. 

S T R U C T U R E S  
133 
It is obviously essential to make a clear distinction between a symbol of the lan­
guage and its interpretations in various models; this explains the somewhat clumsy 
notation sM to denote the interpretation of the symbol s in the model M. Despite 
this, we will omit mention of the model in contexts where there is no possible 
confusion. It sometimes happens that it is the symbols denoting the relations and 
operations of a particular structure that determine our choice of symbols of the 
language appropriate for that structure. Thus, for the structure 
N = (JR., <, cos, n) . 
we might choose the language { <, cos, rr_} where < is a binary relation symbol, cos 
is a unary function symbol and n. is a constant symbol. We will have understood 
that the underlining is, in a way, the inverse of over lining (underlining represents 
passing from the structure to the language, while over lining (or barring) represents 
passing from the language to the structure). For example, cosN = cos. This kind 
of notation will be used in particular for arithmetic (in Chapter 6). 
In contexts where additional knowledge of the interpretations of the symbols for 
constants, functions and relations is not necessary, we will speak of 'an L-structure 
M = (M, . . .  ) ' .  
3.2.2 Substructures and restrictions 
How can we pass from a structure to another structure that is 'larger'? There are 
two rather natural ways to imagine this passage: either we enlarge the underlying 
set and extend the given functions and relations in an appropriate way, keeping the 
language unchanged; (in this case, the result is called an extension of the original 
structure); or else, we keep the same under I ying set and add new relations, new 
functions or new constants to this set; we are consequently obliged simultaneously 
to enrich the language by adding a matching collection of new symbols to it. (In this 
case, the resulting structure is called an expansion, or enrichment, of the original 
structure.) It is unfortunate that the use of the two very similar words, 'extension' 
and 'expansion', can be the source of some confusion; it is vital to avoid this 
confusion. 
Definition 3.29 Given two L-structures M = (M, . . .  ) and N = (N, . . .  ), M 
is an extension of N and N is a substructure (or submodel) of M Ԭf and only if 
the following conditions are satisfied: 
• 
tv is a subset of M; 
• for eveiJ' constant symbol c of L, 
• for every natural number k > I and every k-ary function symbol f of L, 
JN = fM r Nk; 

1 34 
P R E D I C A T E  C A L C U L U S  
• for every natural number k > I and every k -ary relation symbol R of L, 
Thus, for N to be a substructure of M, the requirement is that the interpreta­
tions in N of the symbols of L be the restrictions to the subset N of their interpre­
tations in M. This has an important consequence for the constants and functions 
of the structure M. On the one hand, if e is a constant symbol, the element eM 
of M must belong to the subset N (since eN = eM). On the other hand, if f is 
a k-ary function symbol of the language L, the restriction of the map JM to the 
subset Nk must be the map JN, i.e. a map from Nk into N. We conclude from this 
that the subset N must be closed (or stable or invariant) under the k-ary operation 
-M 
f 
. In other words, given an L-structure M = (M, . . .  ) and a subset N c M, 
the existence of an L-structure whose base set is N and which is a substructure of 
M requires, first of all, that the set N is non-empty, and second, that N contains 
all the interpretations in M of the constant symbols of L and is closed under all 
the functions of the structure M. It is not difficult to verify that these conditions 
are also sufficient; when they are satisfied, the substructure is obviously unique. 
Let us examine, once again, the structure 
N = (IR, <, cos, rr) 
that is a model of the language L = ( R, f, e). This does not admit a substructure 
whose underlying set is [ - 1 ,  1 ]  because the interpretation of the constant symbol 
e is n, which does not belong to this subset of JR. Nor does it admit a substructure 
whose underlying set is [0, n] since this subset ofiR is not closed under the cosine 
function, which is the interpretation in N of the function symbol f. There is, on 
the other hand, a substructure of N whose underlying set is A = [ -rr , n ]; it is the 
substructure 
A = (A , <, cos f A, n) . 
This constraint relating to functions has no counterpart for relations: if L is a 
language with no symbols for constants nor for functions and if M = (M, . . . ) 
is a model for this language, then for any non-empty subset N of M, there is one 
(and only one) L-structure whose base set is N and which is a substructure of M: 
it is the structure in which the interpretation of every relation symbol is obtained 
by taking the trace on N of its interpretation in M (namely, for a symbol whose 
arity is k, its intersection with Nk ). 
In general, although there may not be a substructure of a given structure whose 
underlying set is some given subset N, there is, none the less, a substructure that is 
minimal, in a certain sense, whose underlying set includes the given subset N: this 
is called the substructure generated by N. This concept is described in detail in 
Exercise 3. 12. 

S T R U C T U R E S  
135 
Let us now turn to expansions (or enrichments) of structures (and hence of 
languages). 
Definition 3.30 Let L and L' be two first order languages such that L c L' 
(we say, in this case, that L' is an expansion or enrichment of L and that L is a 
restriction of L'). Let M be an L-structure and M' be an L' -structure. M' is an 
enrichment (or expansion) of M and M is a restriction of M' {f and only if M 
and .M' have the same underlying set and each symbol for a constant, a function 
or a relation of the language L has the same interpretation in the L-structure M 
as in the L' -structure M'. 
Very simply, this means that M' is an enrichment of M if and only if M' 
is obtained from the L-structure M by adding to it the interpretations of those 
symbols for constants, functions or relations of the language L' that were not 
already present in the language L. 
We also say that M is the reduction (or reduct) of M' to the language L. 
For example, where L is the language { R, f, c} and where Lo is the language 
{ R}, the L -structure 
N = (¨, <, cos, n) 
is an enrichment (or expansion) of the Lo-structure 
(¨. <) . 
3.2.3 Homomorphisms and isomorphisms 
A single language L is under consideration here. Let M = (M, . . .  ) and N = 
( N, . . .  ) be two L-structures and let ¢ be a map from M into N. 
Definition 3.31 The map ¢ is a homomorphism of L-structures from M into N 
if and only if the following conditions are satisfied: 
• for every constant symbol c of L, 
• for evefJ' natural number n > 1, for every n-ary function symbol f of L and 
for all elements a 1 ,  az, . . .  , an belonging to M, 
• for every natural number k > l,for every k-ary relation symbol R of L and for 
all elements a1, az, . . .  , ak belonging to M, 

1 36 
P R E D I C A T E  C A L C U L U S  
Thus, a homomorphism from one L-structure into another is a map from the 
base set of the first into the base set of the second which 'respects' all the relations, 
functions and constants of these structures. 
Definition 3.32 A monomorphism of L-structures from M into N is a homo­
morphismftvm M intoN which has the following ptvperty: 
for every natural number k > 1, for every k-ary relation symbol R of L 
( *) and for all elements a 1 , a2, . . .  , ak belonging to M, 
-M 
-N 
(at, a2, . . .  , ak) E R 
ਃfand only (f(¢(aJ ), ¢(a2), . . .  , ¢(ak)) E R . 
As our definition of monomorphism, we could just as well taken Definition 3.31 
and replaced its third clause by condition ( *) above. 
Lemma 3.33 Every monomorphism is injective. 
Proof We must remember here that we are only considering languages with 
equality and models that respect equality. If ¢ is a monomorphism from M into 
N, property (*) applied to the equality symbol ȷ shows that for all elements a and 
b of M, we have 
(a, b) E -.-M if and only if (¢(a), ¢ (b)) E ;:vN, 
which is to say that a = b if and only if ¢ (a) = ¢(b). 
• 
Lemma 3.34 Let N = (N, . . .  ) be an L-structure and let N, be a subset of N; 
for the existence of a substructure of N whose underlying set is N1, it is necessary 
and sufficient that there exists an L-structure M = (M, . . .  ) and a monomorphism 
¢ ftvm M into N such that the subset Nt is the image of¢. 
Proof First, suppose that there is a substructure N, of N whose base set is N 1 • 
Then Definitions 3.29 and 3.32 clearly show that the identity map from N1 into 
N1 is a monomorphism from N, into N whose image is Nt . 
Conversely, suppose there exists an L-structure M = (M, . .
. ) and a monomor­
phism ¢ from M into N whose image is NJ . Then for every constant symbol c 
of L, we have eN = ¢  (eM), hence eN E Nt; similarly, for every k-ary function 
symbol f of L (k > I )  and for all elements a 1, a2, . . .  , ak belonging to N 1, we 
can find elements b 1 ,  b2, . . .  , bk of M such that ¢ (b;) = a; for 1 < i < k, so we 
then have 
-N 
-M 
f (a1,a2 . . .  - , an) = ¢(/ (b1.b2 . . . .  , bn)), 
-N 
which proves that f (at,a2 . . . .  , a11) belongs to N, . We may now conclude, based 
on the paragraphs that followed Definition 3.29, that there exists a substructure of 
N whose base set is N1 . 
• 
Definition 3.35 Anisomorphismjivman L-structure M ontoanother L-structure 
N is a monomorphismftvm M intoN that is surjective. 

S A T  I S  F A C T  I 0 N 0 F F 0 R M U L A  S I N  S T R U C T U R E S  
137 
An automorphism of an L-structure M is an isomorphism from M onto M. 
It is clear that if a bijective map ¢ : M Q N is an isomorphism of the structure 
M onto the structure N, then the inverse map ¢-I : N ' M is an isomorphism 
of N onto M. If there is an isomorphism between two structures, they are said to 
be isomorphic. 
Remark 3.36 It follows from Lemma 3.34 that any monomorphism from a struc­
ture M == (M . . . .  ) into a structure N == (N, . . .  ) may be considered as an 
isomorphism of M onto a substructure of N. 
Example 3.37 (in which the details are left to the reader) 
• Where the language consists of one constant symbol c and one binary function 
symbol g, the structures (JR+, 1, x} and (IR, 0, +) are isomorphic; the map x M 
In x from JR+ into JR is witness to this fact. 
• With this same language, the map n ( ( -1)12 is a homomorphism from the 
structure (Z, 0, +) into the structure ({-1 ,  1}, 1 ,  x). 
• In the language whose only symbol is the binary relation symbol R, the struc­
tures (JR, <) and ((0, 1), <) are isomorphic thanks to the map 
from JR into (0, 1). 
1 
I 
x M - + - arctan x 
2 
Jr 
However, the identity map from (0, 1 )  into JR is only a monomorphism. 
The reader will have noted the abuse of language that consists in using the same 
symbol to denote the order relation in JR and the one in (0, 1 ). 
• With this same language, consider the structures M = ({0, I }, ==) and N = 
( {0, I }, <). The identity map from {0, I }  into {0, 1 }  is obviously bijective and is 
a homomorphism from M into N, but it is not an isomorphism. This shows that 
we cannot replace 'monomorphism' by 'homomorphism' in Definition 3.35. 
3.3 Satisfaction of formulas in structures 
3.3.1 Interpretation in a structure of the terms 
We have already mentioned that the terms of a language will serve to denote 
objects. Suppose that the language involves a constant symbol c and two function 
symbols f and g that are unary and binary, respectively. We suspect that in a 
structure M == (M, c, f, g), the term ffc will be interpreted by f(f(c)), which 
is an element of M, and the term gfcgcc by the element g(f(c), g(c, c)). But to 
interpret the term fvo, we first need to know what element is denoted by vo. Now, 
we will not be giving fixed interpretations in a structure for the variables (otherwise, 
we wouldn't have called them variables). To be more precise, the interpretation in 
a structure of a symbol for a variable can vary. This leads us to the fact that the 

1 38 
P R E D I C A T E  C A L C U L U S  
interpretation of the term fvo will depend on the interpretation given to vo. Thus 
for any element a of M, we will say, when the interpretation of vo is a, that the 
interpretation of the term fvo in M is the element .f(a). It is obvious that, when 
the interpretation of V4 is a, the term f V4 will have this same interpretation. As 
for the term gf gv2cvi, it will be interpreted, when VI is interpreted by a and v2 
by b, by the element 
g (f(g(b, c)), a). 
Definition 3.38 Let n be a natural number, let wo, WI, . . .  , Wn-1 be n pairwise 
distinct variables, let t = tf wo, w 1 ,  . . .  , Wn- 1 ] be a term of the language L, let 
M = (M, . . .  ) be an L-structure and let ao, at, . . .  , an-I be n elements of M; the 
interpretation of the term t in the L-structure M when the variables wo, w 1, 
•
•
•
 , 
Wn-1 are interpreted respectively by the elements ao, a 1, . . .  , an-1 is an element 
of M; it is denoted by 
-M 
t [ wo 	 ao, w 1 	 a 1 , . . .  , Wn- 1 	 an-I ]  
and is defined by induction on t as follows: 
• ift = Wj (0 < j < n - 1 ), 
-M 
t [ wo 	 a o, w 1 ' a 1 , . . .  , w n - l  ' an-t ] = a j ;  
• ift = c (a constant symbol of L), 
-M 
] 
-M 
t [wo 	 ao, WI 	 at, . . .  , Wn- 1  	 an-I 
= c ; 
• if t = f t1 t2 . . .  tk (where k E N*, f is a k-ary function symbol of L and 
tt, t2, . . .  , tk are terms of L), 
-M 
] 
t [wo 	 ao, WJ 	 a 1, . . .  , Wn-1 ' an- I  
= 
-M -M 
f 
(lt 
fwo --+ ao, . . .  , Wn-1 --+ an-d, 
-M 
] 
t2 [wo 	 ao, . . .  , Wn-l 	 an-I , 
-M 
. . .  , tk 
[wo 	 ao, WI 	 a1 . . . .  , Wn- 1  	 an- I J) . 
In practice, we will denote the element iM r wo --7 ao, . . .  ' Wn- 1 ' an- I ] more 
simply by 
despite the fact that this notation is ambiguous: indeed, it contains no reference 
to a specific sequence of f ree variables (including those that have one or more 
occurrences in t ); there are, in fact, an infinite number of such sequences which 
differ from one another either by containing extra variables (that do not occur in t) 
or by the order in which these variables are listed. Were it not for this ambiguity, it 
would have been practical to define, as is sometimes done, the interpretation oft 

S A T I S F A C T I O N  O F  F O R M U L A S  I N  S T R U C T U R E S  
139 
in the structure M as a map from Mn into M, i.e. the map that, to each n-tuple 
(ao, a I ,  . . . , an- I), assigns the element 
-M 
] 
t 
[ wo ---+ ao, w 1 ---+ a J , •
•
•
 , w n -1 ---+ an -I . 
None the less, this simplified notation will prevail in most concrete situations 
in which the context removes all ambiguity. For example, in the language under 
consideration at the beginning of this subsection, if t is the term gvofvJ and M 
is the structure (IR, 0, cos, +), everyone will understand that for all reals a and 
b, tM [a, b] denotes the real a -r- cos b (however, the situation would already be 
less clear if the term had been gvi fvo: it would be prudent in this instance to 
be precise, for example, by specifying t = t[vo, vt ] or by relying on the official 
notation). 
Remark 3.39 In the preceding definition, it is clear that the order in which the 
interpretations of the variables are spec(fied is immaterial: precisely, for any per­
mutation a of the set (0, 1 ,  . . .  , n - 1 }, we have 
-M 
t 
[wo ± ao, . . .  , Wn- I  ² an-d 
-M 
= t 
[Wa(O) ---+ aa(O) , .  · . ,  Wa(n-I) ³ aa(n-J )]. 
Strictly speaking, this would require a proof by induction on t , but it is obvious. 
The purpose of the lemma that follows is to show that the interpretation of a 
term in a structure does not depend on the values assigned to variables that do not 
occur in it. 
Lemma 3.40 Let m and n be two natural numbers, let wo, w I ,  . . .  , Wn- I , zo, 
ZI , . . .  , Zm-1 be m + n pairwise distinct variables and let t be a term of L whose 
variables are among wo, W I ,  •
•
.
 , Wn-I (while zo, Z1 , •
.
.
 , Zm-1 do not occur in t) 
so that it makes sense to write 
t = t [ W 0, W 1 , . . .  , Wn- t 1  = t [ W 0, W 1 , · · · , W n -1 , ZO, Z I , . · . , Zm -1 ] ; 
then for any L-structure M = ( M, . . .  ) and for any elements ao, a 1 ,  .
.
.
 , an-1 , 
bo, b1 ,  . .
. , bm- 1 of M, we have 
--M 
t 
[wo ----+ ao, WI --+ a1 , . . .  , Wn- 1  ³ an-d 
-M 
= t 
[wo ---+ ao, . . .  , Wn-I --+ an-1 ,  ZO ---+ bo, · · ·
, Zm-I ---+ bm_tJ. 
Proof The proof is immediate by induction on t. 
• 
We will now examine the effect of a substitution in a term on its interpretation. 
Proposition 3.41 Let n be a natural number and let v, wo, WI, •
•
•
 , Wn-1 ben +  1 
painvise distinct variables; consider two terms of L, t = t [ wo, w 1 ,  . . .  , Wn-d and 
u = u[v, wo, w r ,  . . .  , Wn-d andletrdenotethetermu[t, wo, w 1 ,  . . .  , Wn-I ], i.e. 
r is the term Utfv· 

140 
P R E D I C A T E  C A L C U L U S  
Thenforany L-structure M = (M, . . .  ) andforany elements ao, a1, . . .  , an-l 
of M, we have 
rM[wo -7 ao, WJ ǿ a  
-
-"- a 
j 
----, 
L , 
• 
• 
• , W n - l ___.,.. n -I 
-M [ 
-M 
J 
= U 
V -7 t [WO , ao, . . .  , Wn-1 Ȁ an--d, WO / ao, · · ·
,
 Wn-1 -7 an-l · 
Proof Note first of all that the variables that occur in r are among wo, WJ , . . .  , 
w12 -1 , so that the term on the left side of the equality makes sense. The equality is 
proved by induction on the term u: 
• ifu is a constant symbol cofL, we haver = u = c and each sideoftheequality 
denotes the element eM ; 
• if u is the variable w; (0 < i < n - 1), r = u = w; and each side of the equality 
denotes the element a;; 
• if u is the variable v  we have r = t and each side of the equality denotes the 
-M 
]· 
element t [wo ȁ ao, wt -7 a1, · · - , Wn--l -7 an-1 , 
• if u = fut U2 · · · uk (where k E N*, f is a k-ary function symbol of L and 
u l ,  u2, . . .  , Uk are terms of L), then by setting rt = u 1 t/v ,  r2 = u2,1L., . . .  , 
rk = Ukt/v ,  we have 
the induction hypothesis is that for i E { 1 ,  2, . . . , k}, 
YiM [wo -7 ao, WI -7 at, . . .  , Wn-l --7 lln-t J  = 
-M਄ 
-M 
]· 
u; 
LV -7 t [wo -7 ao, . - . ,  Wn-1 ʪ an-I], wo --7 ao, . . .  , Wn-1 -ʫ an- 1 , 
so we see, by referring to the definition above, that 
-M r 
-M 
] 
U 
tV -7 t [wo -7 aoå · . -
. Wn-1 -7 an-d  WO -7 ao  . . .  å Wn-1 -7 an-1 . 
3.3.2 Satisfaction of the formulas in a structure 
• 
We are given a language L, an L-structure M = (M, . . .  ), a natural number n, 
n pairwise distinct variables wo, w 1 ,  •
.
•
 , Wn-1 , n elements ao, a1, . . . , an-- 1  of M 
and a formula 
F = F[wo, WJ, •
.
.
 , Wn-1 1 E F(L). 

S A T I S F A C T I O N  O F  F O R M U L A S  I N  S T R U C T U R E S  
141 
The definition that follows, which will be given by induction on the formula F, 
will give meaning to the following phrase: 
'the formula F is satisfied in the structureM when the variables wo, WI , 
.
.
.
•
 Wn - 1  
are interpreted respectively by the elements ao. a 1 ,  . . .  , an -I ·' 
The notation for this property will be 
(M : wo 	 ao, WI 	 a ] ' . . .  ' Wn-1 	 an- t ) I= F 
(the symbol I= is read 'satisfies'). 
In practice, as with the interpretation of terms, we will most often resort to a way 
of speaking and a notation that are less cumbersome, but not without ambiguity. 
We will write 
M I= F[ao, a 1 ,  . . .  , an- d 
and will say 
M satisfies F of ao, a I ,  . . .  , an- I ; 
or 
the n-tuple (or the sequence) (ao, a 1 ,  . . .  , an-I ) satisfies the formula F in M; 
or 
the formula F is satisfied in M by the n-tuple (ao, a 1 ,  . . . , an-I ); 
or 
the n-tuple (ao, a 1 ,  . . .  , an- I ) satisfies the formula F[wo, w1, . . .  , Wn -I l in M. 
The last of these formulations is intended to recall our understanding that wo, 
w 1, .
. . , Wn-1 are to be interpreted respectively by ao, a t ,  . . .  , a11_J ; the first three 
formulations ignore this. The ambiguity here is analogous to the one mentioned 
previously concerning terms: the choice of some fixed ordered list of variables 
that includes the free variables of F is left unspecified. But, just as for terms, the 
context will most often make things clear. 
For the moment, the reader is invited to interpret the notation 
M I= F[ao, at , . . .  , an-d 
as mere shorthand; one should not consider that F[ao, a 1 ,  . . .  , an-I ] denotes a 
formula. In fact, none of what has preceded would authorize this. None the less, 
such a point of view will be possible a bit later; we will atthatpointhavethe means 
to justify it (Theorem 3.86). 

142 
P R E D l C A T E  C A L C U L U S  
The negation of' (M : wo  ao, w 1  a 1 ,  . . .  , Wn-1  an-I )  I= F' is written 
(M : wo  ao, WI  Q } '  •
•
• ' Wn-l  an-I ) տ F 
or again, using the simplified notation 
M T F[ao, at, . . .  , an-d-
Here is the promised defi.nition. 
Definition 3.42 
• 1. If F  is the atomic formula R t1 t2 · · · tk where k is a natural number greater 
than or equal to I, R is a k-ary relation symbol of L and t1, t2, . . .  , tk are 
terms of L (such that for each i E {1, 2 . . .  , k}, t; == t;[wo, WI, . . .  , Wn-J D, 
we have(M : wo  ao, Wt P a1, . . .  , Wn-1 Ȃ an-I ) F= F if and only if 
-M 
-M 
(t1 
[WQ  ao, . . .  , Wn-1  an--tJ, . . .  , tk 
[WO  ao, . . .  , Wn-1 ---* 
-M 
an-d) E R ; 
(in particular, {f L is a language with equality and if M is a model that respects 
equality, we have 
(M : wo  ao, WJ  at, . . . , Wn--1  an-t ) I= t1 Ö t2 if and only if 
-M 
--M 
lt 
[WO  ao, . . .  , Wn-l ȃ an-d == t2 
fwo ---* ao, · · 
·
, Wn-l  an-1 1. 
• 2. If F == -, G: 
(M : wo  ao, WI  at , . . .  , Wn-l  an-d I= F if and only if 
(M : WQ  ao, WI  aJ, . . .  ' Wn-l  an-1 ) T G. 
• 3. IfF == (G A H): 
(M : wo  ao, WJ  a1, . . . , Wn-1  an-I) F= F if and only if 
(M : wo  ao, WI  ai ,  . . .  , Wn-1 P an-I) I= G and 
(M : wo  ao, WJ  at, . . .  , Wn-I  an-i ) I= H. 
• 4. IfF == (G v H): 
(M : wo  ao, Wi æ at ,  . . .  , Wn--l -7 an-I ) !=  F ifandonly if 
(M : wo  ao, w I  a1, . . .  , Wn-I  an-I ) I= G or 
(M : WQ  ao, WI  al , . . .  ' Wn-1  an-I ) I= H. 
• 5. ৼf F == (G ==> H): 
(M : wo ---* ao, WI ---* a1 , . . .  , Wn-I ---* an-I )  I= F (f and only (f 
(M : U{) P ao, WI P a1, . . .  , Wn-I ---* an-I ) T  G or 
(M : wo P ao, w 1 P a,' . . .  ' Wn -I  an-I ) I= H. 
• 6. /f F == (G <=> H): 
(M : wo  ao, WI æ at, . . .  , Wil-l  anȄ-I )  I= F {(and only ৽f 
(M : wo P ao, WJ P a1, . . .  , Wn-1 ---* an-I ) I= G and 
(M : WQ  ao, W J   a), . . .  , Wn-1  an-d I= H; 
or else 
(M : WQ  ao, WI  ai, . . .  ' Wn-I ---* an- d jt: G and 
(M : wo ---* ao, W I P G} , . . . , Wn-1  Gn- I ) T H. 

S A T I S F A C T I 0 N 0 F F 0 R M U L A S I N S T R U C T U R E S 
143 
• 7. IfF = \fvG (where v E V - {wo, WI, . . .  , Wn-1 }): 
(M : wo  ao, WI ; GI, . . .  , Wn-l  an-I ) F= F {f and only if for every 
elementa E M, 
(M : v  a, wo  ao, w I ; a 1, . . .  , Wn-1  an -I ) F= G. 
• 8. IfF = 3vG (where v E V - {wo, WI, . . .  , Wn- d): 
(M : wo  ao, WI  a1, . . .  , Wn-1 Ø an- I )  I= F if and only {(for at least 
one element a E M, 
(M : v  a, wo ; ao, w 1  a I , 
•
•
•
 , w n-I  an-I ) F= G. 
• 9. /fF = YwiG (where O < i < n - 1 ), 
(M : wo  ao, WI ৾a  I ,  . . .  , Wn-l  an-I ) F= F {f and only if for every 
element a E M, 
(M : wo  ao, Wi-I  Gi-l , Wi  a, wi+l  Gi+I ,  Wn-I ਖan-I) F= G. 
• 10. IfF = 3wiG (where 0 < i < n - 1), 
(M : wo  ao, WI ȅ GI, . . .  , Wn-1  an-I ) F= F {f and only if for at least 
one element a E M, 
(M : wo r ao, Wi-1  ai-l, Wi Ȇ a, Wi+l -;.. Gi+l , Wn-I -;.. an- t ) F= G. 
For a correct reading of this definition, it is appropriate to recall that in clauses 
2, 3, 4, 5, and 6, the free variables of the formula G as well as those of H are 
among wo, WI, . . .  , Wn-1 ;  in clauses 7 and 8, the free variables of G are among 
v, wo, WJ, . . .  , Wn-1 ; and finally in clauses 9 and 10, the free variables of G are 
among wo, wi-1, Wi+I, Wn-1 (the variable wi is no longer free in F, though this 
in no way prevents us from considering that F = F[ wo, WI , . . .  , Wn--d). 
This definition notably applies to the case when the formula F is closed. In this 
context the property becomes 
M f= F 
which is read: 'M satisfies F'. When this property is satisfied, we also say that F 
is true in M, or also that M is a model of F. 
Remark 3.43 The definition of sati৿faction does not depend on the order in which 
the interpretations of the variables are spec{fied. This means that for any permu­
tation a of the set {0, 1, . . . , n -- 1}, we have 
(M : wo --7 ao, Wt  a1, . . .  , Wn-I  Gn-I ) F= F {(and only if 
{M : Wa(O)  Ga(O), Wa(l) ---;.. Ga(l), . . .  , Wa(n-1)  Ga(n-1)} F F. 
The proof is obvious: the argument is by induction on F; the case for atomic 
formulas is governed by Remark 3 .39; the rest goes without saying. 
We have observed that the list of variables that includes the free variables of a 
given formula can be artificially lengthened (by adding to this list variables that 
have no free occurrence in the formula). It is natural to ask whether this can have 

144 
P R E D I C A T E  C A L C U L U S  
any effect on the notion of satisfaction that has just been defined. The answer, in 
the negative, is given by the next lemma. 
Lemma 3.44 Let m and n be two natural numbers, let wo, Wt, . . .  , Wn-b zo, ZI, 
. . .  , Zm - 1  be m + n pairwise distinct variables and let F be a formula of L whose 
free variables are among wo, WI , . . .  , Wn-1 (while zo, z 1 ,  •
•
.
 , Zm-l have no free 
occurrence in F) so that it makes sense to write 
F == F[wo, Wt, . . .  , Wn-1 ] == F[wo, W I ,  . . .  , Wn- I ,  zo, ZI, 
.
•
.
 , Zm-d. 
Thenforany L-structure M == (M, . . .  } andfor any elements ao, a1, . . . , an-I' 
bo, bt, . . . , bm-1 of M, the following p1vperties are equivalent: 
( 1 )  (M : wo --:)> ao, W I  ĝ a t ,  . . .  , Wn-- 1 
- an-d F= F 
(2) 
(M : woao, . . .  , Wn- t --:)oan-1 , zobo, . . .  , Zm-lbm-d F= F 
Proof The proof is, of course, by induction on F. 
• If F is the atomic formula Rtt t2 . . .  tk where k is a natural number greater than 
or equal to 1, R is a k-ary relation symbol of L and tt, t2, . . .  , tk are terms of L, 
then, by hypothesis, for each i E { I ,  2, . . .  , k}, we are free to write one or the 
other of 
t; = t; [WO, WI , . . .  , Wn-d Or li == t; [WO, W I ,  . . .  , Wn- 1 ,  ZQ, Zt, · 
·
.
,
 Zm-d. 
S o w  e may conclude, using Lemma 3 .40, that 
-M 
t; 
[wo r ao, Wt r a t , . . · , Wn-1 Ĝ an- I ] 
-M 
== t; 
[wo  ao, . . .  , Wn- 1  an-I, Z0  bo, · · · , Zm-l  bm-1], 
which, by the definition of satisfaction (Clause I ), yields the equivalence between 
( l ) and (2). 
• For those stages of the induction that refer to the symbols for connectives, the 
proof is obvious. 
• It is also obvious for the cases where F = VvG or F = 3vG when the variable 
v does not belong to {zo, z 1 ,  . . .  , Zm-tl. 
• If F = V Zh G where h E {0, 1, . . .  , m -- l } , then the free variables of G are 
among Zh, wo, W t ,  . . .  , Wn- 1 · Property ( 1 )  is verified if and only if for every 
element b of M, 
(M : Zh  b, wo  ao, Wt  a1 , . . .  , lVn-1 r an- I ) I= G, 
which is equivalent, by the induction hypothesis and Remark 3.43, to: for all 
b E  M, 
(M : wo  ao, . . .  , Wn- 1  an- t, zo  bo, . . .  , 
. . .  , Zh-1  bh-l, Zh  b, Zh+l --7 bh+I , .  
· ·
,
 Zm-1  bm-I} F G, 

S A T I S F A C T I O N  O F  F O R M U L A S  I N  S T R U C T U R E S  
145 
but this means, by definition (Clause 9): 
(M : wo  ao, . . .  , Wn-1  an- I , zo Ø bo, .
.
. 
' 
. . .  , Zh-l Ø bh-1 , Zh ã bh, Zh+I  bh+J, . . .  , Zm-1  bm-d F= 'VvhG, 
which is precisely property (2). 
• The case F = 3vhG where h E {0, 1 ,  . . .  , m - 1 }  is treated analogously. 
• 
llere is a very usefu] consequence of the definition of satisfaction; it concerns 
substitutions into formulas. 
Proposition 3.45 Suppose n and p are natural numbers, v, wo, w 1, . . .  , Wn-1, 
uo, ut, . . .  , Up-l aren+p+1pairwisedistinctvariables, t = t[wo, WJ, . . .  , Wn-l ]  
is a term of L and F = F[v, wo, W t ,  .
. . , Wn-1 , uo, U J ,  
.
•
.
 , Up-d is a formula 
of L. Suppose further that in the formula F, there is no free occurrence of v in the 
scope of any quant{fication Vw; or 3w; (0 < i < n - 1). 
Then for any L-structure M = (M, . . .  } andforany elements ao, at , 
. . .  , an - J ,  
bo, h t ,  . . .  , bp-I of M, the following two properties are equivalent: 
( I )  (M : wo ȇ ao, . . . .  Wn-1 --+ an-I ·  uo  bo . . . . , Up-1  bp-- t } F Ft;v; 
(2) (M : v --+ tM[wo  ao, WI  a1 , . . .  , Wn-1 --+ an-d, wo  ao. 
WJ --+ aJ , •
•
.
 , Wn-1 --+ an-l, UO ___. bQ, UJ --+ bJ , . . .  , Up-1 --+ bp-l ) 
I== F. 
Proof Note first of all that the free variables of the formula Ft/v are among wo, 
w 1 , •
.
•
 , w n -l , uo, u 1 , .
•
.
 , up-1, which shows that property ( 1 )  makes sense. The 
proof proceeds by induction on F. 
• If F is the atomic formula Rtt t2 . . .  tk where k is a natural number greater than 
or equal to 1, R is a k-ary relation symbo] of L and tt. t2, . . .  , tk are terms of 
L, then, for each i E { 1 , 2, . . .  , k}, we may write 
li = t;[V, WQ, lV1 ,  
•
•
.
 , Wn-J ,  UQ, U), •
•
•
 , Up-t l 
and, according to Clause 1 in the definition of satisfaction, if we set 
r; = t;tfv' property ( 1 )  means 
(rrM[WO ---+ ao , · · · , Wn-1 ã an-I , UO __,. bo, . .  · , Up-l --+ bp-J J, .
.
 · 
. . .  , rkM[wo --+ ao, . . .  , Wn-l ; an-I , uo --+ bo, . . .  , Up-l ___. bp-d) 
-M 
E R ; 
now, by virtue of Proposition 3.41, if for each i E { 1 ,  2, . .
. , k} we set 
-M[ 
-M 
bi = ti 
v  t [wo --+ ao, . . .  , Wn-l --+ an-d, wo --+ ao, .
.
.
 
. . . , Wn-l Ǽ an-I , UO  bo, . . .  , Up-1 ʨ bp- t J] , 

146 
P R E D J C A T E  C A L C U L U S  
this becomes equivalent to 
i.e. (by Clause 1 of the definition) to the following assertion, which is prop­
erty (2): 
( 
-M 
M : v ; t 
[wo ä ao, Wt ä at, . . .  , Wn-1 ; am-lL wo  ao, 
Wt  at ,  . . .  , Wn-1  an-1, uo - bo, Ut  bt, . . .  , Up-I  bp-1) 
f= F. 
• The stages of the induction that concern the symbols for connectives are obvious. 
• Suppose F is the formula 3zG; the free variables of G are among z, v, wo, 
w 1, . . .  , 1Vn-1, uo, u 1 ,  . . .  , u p-1 . If z is one of the 1n; , then by hypothesis v has 
nofreeoccurrence in G, nor in F; ifz == v, v has no free occurrence in F; in both 
these cases, Ft;v == F; the equivalence of (1) and (2) is then a straightforward 
consequence of the previous lemma. If z is different from v and from all the w; 
(0 < i < n - 1), then we have Ft/v == 3zG1 ;v; in the case where z differs as 
well from all the u j (0 < j < p - 1) then z is not among the variables of t so 
property (1) is equivalent to the existence of an element a E M such that 
(M : z  a, wo  ao, . . .  , Wn-1  an-1 ,  uo  bo, . . .  , Up- I --7 hp-t} 
I= Gr;v; 
by the induction hypothesis, this is also equivalent to the existence of an element 
a E M such that 
( 
-M 
M : v  t [wo ; ao, . . .  , Wn-1 ; an-d, z ; a, wo { ao, . . .  
. . . ' Wn-1 - an-1 '  uo --7 bo, . . .  ' Up-1 --7 bp-1) F= G, 
or, in other words, to the following assertion which is precisely property (2): 
{M 
-M 
: v | t [wo ; ao, WI --7 at , . . .  , Wn-1 --7 an-11, wo --7 ao, . . .  
. . . , Wn-1 ; an-1, uo ǽ bo, . . .  , Up-1 ; bp-t} Ԫ 3zG. 
In the case where z == u j (0 < j < p - 1), it suffices to repeat the five previous 
lines omitting r.u j ; b j ' from the assignments for the variables. 
• The case involving universal quantification is similar. 
• 
In this proposition, the hypotheses that concern the variables are rather com­
plicated. Most of the time, we will have stronger (and simpler) hypotheses at our 
disposition: this is the case, for example, when none of the variables wo, w1 , . . .  , 
Wn-1 has a bound occurrence in the formula F. 
Consider once again the language L == { R, f, c} used earlier as well as the 
L-structure N ;;;;; (JR, <, n, cos} . Here is an assortment of examples of a formula 

U N I V E R S A L  E Q U I V A L E N C E  A N D  S E M A N T I C  C O N S E Q U E N C E  
1 47 
F[uo] of L along with the set ofreals a such that N F= F[aJ (which is, we should 
recallӠ another way to write (N : vo --+ a) t= F). 
Rcvo 
3vifVI 6 vo 
3vifvo  VJ 
fvo ! c 
3vi (Rcvo 1\ fvl ! vo) 
3VI (RCVI 1\ fvl Ö Vo) 
'Vv1 Rvofvi 
'Vvt Rfvofvl 
V v t 3  vz ( R v 1 vz 1\ f vz ! vo) 
Vvo3vt fvi ! vo 
3vl 'VvzRfvz v1 
[n, +oo) 
[ -1, l l  
JR. 
0 
0 
[-1, 1] 
(-00, - 1] 
{ (2k + 1 )n : k E Z} 
[-1 , 11 
0 
JR. 
The reader will have noticed that the last two illustrative formulas are closed. The 
last one is satisfied inN while the next-to-last is not. Listing these two formulas in 
the category of formulas with onefreevariable may appear preposterous, especially 
after encountering the fastidious verifications to which we are led by the definition 
we have adopted. It would seem much more natural to be satisfied by associating 
with each formula the list ofvariablesthatactually have at least one free occurrence 
in it. This is, by the way, what happens spontaneously in practice: when we are 
interested in the sequences of elements that satisfy the formula ('VvoRvoc ==> 
( -,Rv1 v2 v Rvzfv3)) in a given structure, we obviously tend to think of sequences 
of length 3. What justifies the more expansive definition that we have adopted 
in spite of this is, essentially, the fact that the subformulas of a formula do not 
necessarily involve all the free variables of the formula (and may even involve 
others which become bound in the whole formula); thus, to proceed otherwise 
would have led us to define the notion of satisfaction with a much more complicated 
induction. We realize that all these considerations are (merely) technical and that 
it is not necessary to pay undue attention to the purely formal subtleties that we 
might easily raise concerning this definition. 
The essential notion to retain from all the preceding is that of the satisfaction of 
a closed formula in a structure. 
3.4 Universal equivalence and semantic consequence 
In this section, we will provide definitions and a basic vocabulary that are of 
constant use in model theory. 
We are given a first order language (with or without equality). 
Definition 3.46 
• A closed formula of L is called universally valid {f and only if it is satisfied 
in every L-structure. Instead of 'universally valid formula' we sometimes say 
'valid formula'. 

148 
P R E D I C A T E  C A L C U L U S  
The notation for: 'F is universally valid' is 
8* F 
' 
while .14* F stands for: 'F is not universally valid'. 
• A closed formula of L is called a contradiction (or is said to be contradictory 
or inconsistent) if and only (lits negation is universally valid. 
• A formula with free variables is universally valid if and only if its universal 
closure is universally valid (see Remark 3.47 below). 
• Given two formulas F and G of L (whether closed or not), we say that F is 
universally equivalent (or logically equivalent, or simply equivalent) to G Ŵl 
and only Ŵf the formula (F {:;> G) is universally valid. 
The notation for 'F is universally equivalent to G ' is 
• A set of closed formulas of L is called a theory of L. 
• Given a theory T and an L-structure M, we say that M is a model of T (or 
that M satisfies T, or that T is satisfied in M) Ŵland only {f M satisfies each 
formula that belongs to T. 
The notation for 'M is a model ofT' is 
M F= T, 
while M S T stands for : 'M is not a model ofT'. 
• A theory is consistent (or non-contradictory, or satisfiable) if it has at least 
one model. 
A theory that is not consistent is called contradictory (or inconsistent). 
• A theory is finitely consistent (or finitely satisfiable) if all its finite subsets are 
consistent. 
• Given a theory T and a closed formula F of L, F is a semantic consequence 
of T (or simply, a consequence of T) Ŵland only Ŵl every L-structure that is a 
model ofT is also a model of F. 
The notation for 'F is a consequence ofT· is 
T 9* F, 
while T }L* F stands for 'F is not a consequence ofT'. 
• 1fT is a theory and F is a formula of L with free variables, F is a consequence 
ofT if and onlyŴltheuniversal closureo.lF is a consequence ofT. The notation 
is the same as for closed formulas. 
• Two theories Tt and T2 are equivalent if and only Ŵlevery formula in Tt is a 
consequence of T2 and every formula in T2 is a consequence of T1. 

U N  I V  E R S A L  E Q U I  V A L E N C E  A N D  S E M A N T I C  C 0 N S E Q U E N C E  
149 
Remark 3.47 The definition that is given here for the universal validity of a for­
mula with free variables is, a priori, incorrect. It only makes sense once it has been 
verified that the various universal closures of a formula are all universally equiv­
alent. This fact, which is intuitively clea1; is proved by referring to the definition 
of satisfaction ( 3.42). We will have to deal later with more or less this same issue 
to prvve prvperty (5) ofTheorem 3.55. 
Remark 3.48 We must be wary of the concept of universally equivalent formulas 
as it applies to formulas that are not closed: for two formulas to be equivalent, it 
is not sufficient that their universal closures be equivalent. Consider, for example, 
the following two formulas in the language whose only symbol is equality: 
Their universal closures are, respectively: 
The formulas Ft and G 1 are universally equivalent: indeed, they are both con­
tradictory, for {f we take an arbitrary structure M and an element a from its 
underlying set (necessarily non-empty), we have (M : vo -+ a, VI -+ a) Į F 
and (M : vo -+ a, v2 -+ a) S G, which shows that M satisfies neither F1 nor 
G 1, and hence does satisfy ( F1 ¢> G 1 ). However, the formula (F ¢> G) is not 
universally valid, for its universal closure, 
'v'vo'v'v1'v'v2(_,vo ¥ Vt ¢> _,vo  v2), 
is not satisfied in the structure whose base set is {0, 1 }; to see this, note that 
(M : vo -+ 0, Vt --+ 1, v2 --+ 0) F= Fand(M : vo  0, Vt --+ 1 ,  v2 --ʩ 0} JC G. 
I tfollows that 
So the universal closure of this last formula is false in the structure under consid­
eration. 
What is true, none the less, is that if two fonnulas are universally equivalent, 
then so are their universal closures (see Exercise 6). 
It is time to indicate precisely which abuses of notation we will allow ourselves 
concerning first order formulas. In fact, we will be satisfied simply to recycle those 
that we have already decided to use for formulas of the propositional calculus: 
• suppressing the outermost pair of parentheses; 
• writing (F 1\ G 1\ H) instead of ( ( F 1\ G) 1\ H); 
• using 'large' conjunctions and disjunctions such as 1\ Fi. 
iEI 

]50 
P R E D I C A T E  C A L C U L U S  
The justification for using these shorthand notations is essentially the same as it 
was for the propositional calculus. Their transfer to first order formulas is based 
on the following very simple and constantly used result: 
Lemma 3.49 Let A 1 .  A2, . . .  , Ak be p1vpositional variables, let] [A 1, A2, . . .  , Ak] 
be a propositional formula and let Ft, F2 .. . . . Fk be first order formulas of a 
language L. If the formula J is a tautology, then the first order formula 
JLFt ,  F2, . . .  , Fk] (the result of substituting the formulas Ft, F2, . . .  , Fk for 
the variables A 1. A2, . . .  , Ak, respectively, in the formula J) is a universally valid 
formula. 
Proof Suppose that the free variables of the formulas Ft , F2, . . .  , Fk are among 
vo, v1 , . . .  , Vn-1 ·  Then this is also the case for the formula F = J[Ft F2, . . .  , Fk]. 
, 
Consider an L-structure M = (M . . .
. ) and elements ao, a1 , . . .  , an- I of M. 
We define an assignment of truth values 8 on { A  1 , A 2, . . .  , An } by setting, for 
0 < i < k: 
Here we have used the simplified notation for satisfaction. The definition of 
satisfaction shows clearly (argue by induction on J) that the formula F is satisfied 
in M by the n-tuple (ao, a 1 ,  . . .  , an-- I) if and only if the assignment of truth values 
8 assigns the value 1 to the formula J. We conclude immediately that when J is a 
tautology, 
M F= F[ao, a1, . . .  , an-I], 
and that this holds for any n-tuple (ao, a1 , • 
_ . , an-I), which proves that the uni­
versal closure of F is satisfied in any L-structure, i.e. that F is universally valid . 
• 
Definition 3.50 The universally valid formulas that are obtained from proposi­
tional tautologies by the method we have just described are called tautologies of 
the predicate calculus. 
So we see that everything that was said in Chapter 1 concerning tautologies 
(associativity of conjunction and disjunction, among other facts) transfers with­
out difficulty to first order formulas; the concepts of tautology and of equivalent 
formulas become, respectively, those of universally valid formula and universally 
equivalent formulas. 
Note finally that we adopt no particular abbreviations involving the quantifiers. 
The properties asserted in the following theorem are immediate consequences 
of the definitions given above. 

U N I V E R S A L  E Q U I V A L E N C E  A N D  S E M A N T I C  C O N S E Q U E N C E  
151 
Theorem 3.51 For any theories T and S ofL, any integers m and p > 1, and any 
closedformulas G, H, F1,F2, . . .  , Fm, and G1, G2, . . .  , Gp of L, thefollowing 
properties are satisfied: 
• The formula G is contradictory if and only ((no L-structure satisfies it. 
• The formula G is a consequence of T if and only if the theory T U { -.G} is 
contradictory. 
• {fT is consistent and if S c T, then S is consistent. 
• Jf T is consistent, then T is finite! y consistent. 
• Jf T is contradictory and if T c S, then S is contradictory. 
• ਀{T ʱ-* G and ifT c S, then S ʱ-* G. 
• T U { G} 1-* H if and only ifT ʱ-* ( G => H). 
• T Ҧ-* (G 1\ 11) if and only ifT 1-* G and T ਁ-* H. 
• { Ft ,  F2, . . .  , Fm} ʱ-* G ifand only ifਂ-* ((F1 1\ F2 1\ · · · /\ Fm) =} G). 
• G is universally valid (f and only ifG is a consequence of the empty theory. 
• G is universally valid if and only if G is a consequence of eve1y theo1y of L. 
• T is contradicto1y if and only ifT Ҧ-* (G 1\ -.G). 
• T is contradictory if and only if every formula of L is a consequence ofT. 
• T is contradictory ((and only if for every universally valid formula F, -.F is a 
consequence ofT. 
• T is contradictory if and only if there exists at least one univer sail y valid formula 
F such that -,F is a consequence ofT. 
• The theory { F1, F2, . . .  , Fm} is contradictory if and only ((the formula 
(-'FI v ... ,F2 v · 
· · v -.Fm) is universally valid. 
• The theories T and S are equivalent if and only {(they have the same mod­
els (in other words, for T and S to be equivalent, it is necessary and suffi­
cient that for every L-structure M, M is a model ofT {(and only {(M is a 
model of S). 
• Jf every formula in T is replaced by a universally equivalent formula .. the 
resulting theory is equivalent to T. 
• 1( T is contradictory, then S is equivalent to T if and only if S is contradictory. 
• The theory T is equivalent to the empty theory if and only if. every formula 
belonging to T is universally valid. 
• Every L-·structure is a model of the empty theory. 
• The empty theory is consistent. 
• The set of all closed formulas of L is contradictory. 
• The theories {G} and {H} are equivalent ((and only ((the formulas G and H 
are logically equivalent. 

1 52 
P R E D I C A T E  C A L C U L U S  
• The theories { Fr, F2, . . .  , Fm} and { G 1 ,  G2, . . .  , G p} are equivalent if and only 
if the formula 
is universally valid. 
• Any finite theory is equivalent to a theoty that consists of a single formula. 
• The binary relation 'is universally equivalent to' is an equivalence relation on 
the set of formulas of L. 
• The binary relation 'is equivalent to' is an equivalence relation on the set of 
theories of L, i.e. on the set of subsets of the set of closed formulas of L. 
Proof We invite thereadertosupply proofs independently (this primarily involves 
arguments analogous to those used in the proof of Lemma 1.38). 
• 
The next proposition expresses the fact that the equivalence relation Ȇ for for­
mulas is compatible with the operations that enter into the construction of formulas 
(the use of connectives and quantifiers). 
Proposition 3.52 For all formulas F, G, F' and G' and for every integer k, ifF 
and G are equivalent to F' and G' respectively, then the formulas 
-,p, (F A G), (F v G), (F :::} G), (F {:} G), Vvk F and 3vk F 
are equivalent, respectively, to 
-,p', (F' 1\ G'), (F' v G'), (F' :::} G'), (F' {:} G'), VvkF' and 3vk F'. 
Proof Let us treat, for example, the case of existential quantification. Suppose 
that the formulas F and F' are equivalent and that their free variables are among 
vo, VI, •
.
.
 , Vn (n > k). We need to prove that the universal closure of the formula 
(3vk F <=> 3vk F') is satisfied in an arbitrary L-structure M == (M, . . . }. So let us 
consider elements ao, a 1 ,  . .
. , ak-l, ak+ 1 , .
.
•
 , an of M. If we suppose that 
then we can find an element a E M such that 
(M : vo --+ ao, . . .  , Vk-J --+ ak-l ,  Vk ͓ a, Vk+l ͓ ak+l , . . .  , Vn ͒ an) F= F; 
but, since F and F' are equivalent, we also have 
(M : vo = ao, . . .  , Vk-1 --+ ak-1, Vk } a, Vk+1  ak+l ,  . . .  , Vn - ʧ an) t= F', 
and hence 

U N I V E R S A L E Q U I V A L E N C E A N D S E M A N T I C C 0 N S E Q U E N C E 
153 
The converse is obtained in exactly the same manner. If 
then 
so we may conclude that 
(M : Vo __. ao, VI ৷ a1 , . . .  , Vk- 1 ৸ ak-l ,  Vk+l ʯ ak+I ,  . . .  , Vn ʯ an) 
৹ (3vkF <=> 3vkF'). 
The other cases are treated in a similar fashion. 
• 
Corollary 3.53 Suppose that F is a formula, that G is a sub:formula ofF and 
that G' is equivalent to G. Then the formula F', obtained from F by substituting 
G' for an arbitrary occurrence of the sub-formula G, is equivalent to F. 
Proof The argument is by induction on F. When F is atomic, G can only be 
equal to F, so F' = G' and the result is immediate. For all other stages of the 
induction, it suffices to apply the preceding proposition. 
• 
We have thus justified an operation that we perform practically all the time when 
we manipulate first order formulas from a semantic point of view: we replace sub­
formulas by equivalent formulas. 
Changing the name of a bound variable, provided it is done subject to certain 
conditions, transforms a formula into an equivalent formula (see Remark 3.26): 
Proposition 3.54 For any integers k and h and any formula F, if the variable vh 
does not occur in F, then the formulas 
are equivalent. 
Proof The result is trivial if h = k. So suppose h and k are distinct and that 
F = F[ V;1 , v;2 , 
•
•
•
 , v;n , Vk], where the integers i 1 ,  i2, . . .  , in are pairwise distinct 
and distinct from h and k (which the hypothesis allows). Given an L-structure 
M = (M, . . .  ) and arbitrary elements a1. a2, . . .  , an of M, what needs to be 
proved is that 
(*) 
if and only if 
and the analogue for 3. 

154 
P R E D I C A T E  C A L C U L U S  
Property (*) means that for any element a E M, we have 
but according to Lemma 3.44, this is also equivalent to 
We may then apply Proposition 3.45 (our hypotheses allow this), upon observing 
that 
and we obtain the following property, which is equivalent to (*): 
which, by definition, means 
in other words, property (**). 
• 
Using the tautologies and the equivalent propositional formulas from Chapter 1, 
we obtain, i n  a natural way, countless examples of universally valid formulas and 
others equivalent to them. The important properties that follow will supply us with 
examples that have no analogue in the propositional calculus since they involve 
quantifiers. These properties are extremely useful. in particular, for mastering the 
manipulation of quantifiers in statements of everyday mathematics: among the first 
exercises at the end of this chapter, several are aimed at precisely this. 
Theorem 3.55 For all integers h and k and for all formulas F and G, we have 
the following logical equivalences: 
--.\lvk F ° 3vk-,F, 
\lvk ( F 1\ G) ° ('Vvk F 1\ 'VvkG), 
3vk (F v G) ° 3vk F v 3vkG, 
3vk (F ==> G) "-J ('Vvk F => 3vkG), 
'Vvk \lvh F "-J 'Vvh 'Vvk F, 
3vk3Vh F "-J 3v¶z3Vk F. 
Moreove1; the following three formulas are universally valid: 
3vk (F 1\ G) ==> 3vk F 1\ 3vkG, 
('Vvk F v 'VvkG) ==> 'Vvk(F v G), 
3vk'VVh F ==> 'Vvh3VkF. 
(1) 
(2) 
(3) 
(4) 
(5) 
(6) 
(7) 
(8) 
(9) 

U N I V E R S A L E Q U I V A L E N C E A N D S E M A N T J C C 0 N S E Q U E N C E 
]55 
In addition, {fthe variable Vk is not free in G, then: 
\lvkG "v 3vk G "' G, 
( 10) 
\lvk(F 1\ G) - (\lvk F 1\ G), 
( I I ) 
3vk(F v G) ""' (3vk F v G), 
( 12) 
\lvk (F v G) ""' (\lvkF v G), 
( 1 3) 
3vk (F 1\ G) ""' (3vk F 1\ G), 
(14) 
3vk (G ʰ F) ৺ (G ʰ 3vk F) ,  
(15) 
\lvk(G ? F) ° (G ʰ \lvk F), 
(16) 
3vk (F µ G) °  (\lvk F ? G), 
( 17) 
\lvk(F µ G) ° (3vk F ʰ G). 
( 1 8) 
Proof We obtain ( 1 ), (2), (5), (6), (7) and (9) without difficulty by referring to 
Definition 3.42ੇ (3) and (8) are deduced from (2) and (7) respectively (applied 
to -.,F and -´G) together with ( 1 )  and familiar tautologies; (4) is an immediate 
consequence of (3) applied to -,F and G; when we take the additional hypoth­
esis about Vk into account, ( 10) and ( 1 3) follow from the definition and Lemma 
3.44; ( 1 1 )  and ( 15) can be deduced from (I 0) and from (2) and ( 4 ); it is again 
thanks to ( 1 )  and to some tautologies that we obtain (12) from (1 1), ( 14) from 
( 13), (17) from (15) and ( 1 8) from (16); (16) is obtained from ( 1 3) applied to F 
and _,G. 
• 
It should be understood that these brief suggestions presuppose intensive use of 
Proposition 3.52 and Corollary 3.53. 
We could say, loosely speaking, that the universal quantifier is 'distributive' over 
conjunction but not over disjunction, while the opposite is true for the existential 
quantifier. That is what is expressed by properties (2) and (3), together with the fact 
that the universal validity of formulas is not preserved, in general, when we replace 
the symbol ==} by ੃ in (7) and (8): to see this, consider the language L that has two 
unary relation symbols A and B ;  let F = Avo and G = B vo and take the model 
M whose underlying set is N and in which A and B are interpreted, respectively, 
by the relations 'is even' and 'is odd'; it is then clear that M satisfies the formulas 
3vo F 1\ 3voG and \lvo(F v G) but does not satisfy the formula 3vo(F 1\ G) nor the 
foirmula \lvoF v \lvoG. The behaviour of the quantifiers with respect to implication 
is more complicated; what one can keep in mind is this: if we try to 'distribute' 
the quantifier in a formula of the form Q vk(F => G), where Q is \1 or 3, then, in 
those circumstances where this is possible, 
• if the quantifier 'enters' on the right side of the symbol ==}, then it 'enters' as 
is; whereas, 
• if the quantifier 'enters' on the left side of the symbol ?' it must be replaced 
by its dual Q* (Q* = 3 if Q = \1 and Q* = V if Q = 3). 

156 
P R E D I C A T E  C A L C U L U S  
We can permute two consecutive universal (existential, respectively) quantifiers 
(properties (5) and (6)), but not a 'V with a 3: (9) is no longer universally valid if we 
replace  with <=>. To see this, consider once again the model M above and let F 
be the formula (Avo {:} Bv1); then M F= Vvo3vt F (since for any integer ao, we 
can find an integer a1 whose parity is different from that of ao) but M P: 3vt VvoF 
(for we can hardly insist that an integer have a parity that is distinct from the parity 
of an arbitrary integer . . .  ). The formula 'Vvh 3vk F expresses the existence of a Vk 
for each Vh (so it may vary with Vh) whereas the Vk whose existence is expressed 
by the formula 3vk Vvh F must be 'the same for all Vh ', which is what makes this 
formula 'strongeŗ than the preceding. There are classic illustrations of this remark 
in analysis involving the distinction between simple and uniform continuity and 
the distinction between simple and uniform convergence: we know well that the 
heart of the problem consists in determining whether 'the 8 (or the N) depends 
on x or not' . . .  and, ultimately, when we express these properties formally, they 
differ precisely by an inversion of the order of the quantifiers. 
Using the results from Chapter 1 on complete sets of connectives, together with 
Lemma 3.49, Proposition 3.52 and Corollary 3.53, and property ( 1 )  of the preceding 
theorem, we immediately obtain 
Theorem 3.56 Every first order formula is universally equivalent to at least one 
formula whose only symbols for connectives and quantifiers are: -., v and 3. 
In this statement, we can obviously replace -. and v by the elements of any 
complete set of connectives; we can also replace 3 by 'V. 
Remark 3.57 An analogue of Remark 1.33 applies here as well: to prove that 
a certain property, compatible with the relation "', is true for every first order 
formula, it is sufficient, in a proof by induction, to 'restrict' oneself to the stages 
that relate to negation, di৻junction and existential quantification. 
We conclude this section with a result that is very easy but indispensable. It 
concerns comparing the satisfaction of a formula in a structure for its own language 
with its satisfaction in a structure for a richer language. 
Lemma 3.58 Consider a first order language L and a language L * that is an 
enrichment of L. Let M = (M, . . .  ) be an L-structure, let M* be an enrichment 
of M for the language L *, let F = F[vo, Vt , . . .  , Vn-l] be a formula of the 
language L and let ao, a 1 ,  . . . , an-I be elements of M. 
Under these conditions, we have 
M F= F[ao, a1 , . . .  , an-t ]  if and only if M* F F[ao, a1, · · · , an-l]. 
Proof The only thing that is perhaps not obvious is that these two properties 
make sense! We convince ourselves by noting that F is both a formula of L and a 
formula of L *. For the rest, a quick glance at the definition of the satisfaction of 
F in M* reveals that this depends only on the symbols of L and on the functions 

P R E N E X  F O R M S  A N D  S K O L E M  F O R M S  
157 
and relations of the structure M. So the result is automatic (the reader who wishes 
to be completely rigourous should give a proof by induction on F). 
Il 
Observe, however, that this question would not have made sense if F contained 
symbols of L * that did not belong to L. 
3.5 Prenex forms and Skolem forms 
What we do in this section will be amply used in the next chapter in which we 
will describe methods that allow us to answer questions of the form: 'is this closed 
formula universally valid?' or 'is it a consequence of such and such a theory?' Tht 
idea will be to reduce the question, at the cost of changing the language੄ to formulas 
whose syntactic construction is relatively simple: the Skolem forms. Beforehand 
we will show that every formula F is equivalent to a formula (of the same language) 
structured as a sequence of quantifications followed by a quantifier-free formula 
(this will be called a prenex form of F). The interest and import of Theorem 3.60 
about prenex forms extends beyond the context just described. It also presents "' 
(slight) danger, in that it leads one to believe that a formula is 'easier to understand' 
when it is in prenex form: in fact, one quickly realizes that the contrary is true and 
that, to comprehend the property expressed by a closed formula, one is well advised 
to 'distribute' the quantifiers to the maximum extent possible, i.e. to do the exact 
opposite of putting it in prenex form. 
3.5.1 Prenex forms 
Definition 3.59 A formula F is prenex {f and only if there exist an integer k, 
variables W J ,  w2, . . .  , Wk, symbols for quantifiers Q1, Q2, . . .  , Qk and a formula 
G without quant{fiers such that 
The word Ql W I  Q2w2 . . .  Qkwk is then called the prefix ofthe prenexformula. 
A prenexformula is polite {f and only if its prefix contains at most one occurrence 
of each variable. 
If H is a formula, a prenex formula that is universally equivalent to H is called a 
prenexform of H. 
A universal formula is a prenexformula with no existential quantifiers. 
An existential formula is a prenex formula with no universal quantifiers. 
l\Taturally, the case k = 0 corresponds to the situation in which F = G, which is 
to say that formulas without quantifiers are special cases of prenex formulas (and 
they are, by the way, polite, universal, and existential). 
We see immediately that any universal closure of a prenex formula is also a 
prenex formula. 
Caution: a formula such as 'v'vo(3vl vo J VJ =} vo  v1) is not prenex! 
Theorem 3.60 Every first order formula has at Least one polite prenexform 

158 
P R E D I C A T E  C A L C U L U S  
Proof We will prove by induction that for any formula F, we can find a polite 
prenex formula F' that is universally equivalent to F. Because it is clear that this 
property is compatible with the relation f"v we may, by Remark 3.57, restrict the 
number of cases to be considered. 
• If F is atomic, it suffices to take F' = F. 
• If F = -,G, and if G is equivalent to Q1 VI Q2 v2 . . .  Qk Vk G", where G" is 
quantifier-free and the variables w i are pairwise distinct, it suffices to take 
F' = Q1 VI Q2v2 . . .  Qkvk-,G" where, for 1 < h < k, Qh is the dual of Qh. 
• If F = (G v H), if G is equivalent to G' = Q I VI Q2v2 . . .  QkvkG" and H to 
H' = QȈ z I Qȉz2 . . .  Q;nZm H" (where G" and H" are quantifier-free and where, 
in each prefix, the variables are pairwise distinct), then after first choosing k + m 
pairwise distinct variables XI , x2, . . .  , xk, YI, Y2, . . .  , Ym that have no occurrence 
in G' or in H', it suffices to set 
and to take 
To verify that this formula is indeed equivalent to F, we mainly apply 
(k + m times) Proposition 3054 and properties ( 12) and ( 1 3) of Theorem 3.55. 
It is appropriate to note that the order in which we repeatedly apply these two 
properties is of no importance: we might, for example, first bring all the Qj to 
the front, then all the Q;, or else alternate them arbitrarily; on the other hand, 
what cannot change (except in special cases) is the order of the Q i among them­
selves, or that of the Qj among themselves. We see, in any case, that we are far 
from having a unique prenex formula equivalent to F. 
• If F = 3vG and if G is equivalent to Q1 w1 Q2w2 . . .  QkwkG", where G" 
is quantifier-free and the variables w; are pairwise distinct, then either v rf. 
{WI, w2, . . .  , Wk} and it suffices to take F' = 3vQI WI Q2w2 . . .  QkwkG", or 
else w = w j for some index j between 1 and n: in this case, w is not free 
in the formula QI WI Q2w2 . . .  QkWkG", so we can take F' = Q1 WI Q2w2 .  
0 
0 
Qk WkG" since this polite prenex formula is equivalent to F by virtue of property 
(1 0) of Theorem 3.55. 
• 
Remark 3.61 The proof we have just given furnishes a p1vcedure for constructing 
a prenexformula that is equivalent to a given formula F (we also speak of 'putting 
F in prenexform'). ({we scrupulously follow this p1vcedure, we must begin by 
eliminating the symbols 1\, ==> ,  ¢> and 'V. In truth, the only indispensable step is 
to eliminate ¢> . It is then possible, by judiciously changing the names of bound 
variables, to progressively 'bring the quantifiers to the front' by climbing the 
decomposition tree, using, step by step, the properties presented in Theorem 3.55 
as we did above for the induction step involving disjunction. Of course, depending 

P R E N E X  F O R M S  A N D  S K O L E M  F O R M S  
1 59 
on the circumstances, we can be more or less efficient in changing the names of 
variables: it is rarely necessary to rename all the variables that occur, as we did 
above. 
The obvious pur pose of these name changes of bound variables is to obtain a 
formula in which no variable occurs in the scope of more than one quantification, 
in order that Theorem 3.55 apply in all cases. A byproduct is a potential increase 
in the number of variables in use. How ever, if we wish to minimize the length (and 
height) of the prenexform, it can happen, on the contrary, that we are better served 
by substituting, for a given bound variable, a variable that already occurs in the 
scope of some other quantification. Let us take an example: the formula 
is equivalent to the prenex formula 
obtained as described above, by changing the name of the bound variable v 1 (into 
v3) in the scope of the rightmost quantification in F; but we can find a simpler 
prenex form when we observe that properties (2) and (4) of Theorem 3.55 are 
applicable here: this leads us to substitute (in F) VI for the occurrences of v2, 
then vofor the last three occurrences ofv1; the formula obtained in this way is 
H == Vvo(Vvt (--.vt ʦ VJ z 3vtvo  Vt) l\ Vvovo ! vo; itis indeed equivalent to 
F and the properties to which we just referred ptvduce the following prenexform. 
whose height is 5 (that ofG is 7) and which is obviously shorter than G. 
Remark 3.62 The last part of the proof of the preceding theorem clearly showed 
that to get from an arbitrary formula in prenexform to an equivalent prenexformula 
that is polite, it suffices, for each variable, to suppress in the prefix ofF all but the 
rightmosT quantification involving that variable. For example, if G is a formula 
without quant{fiers, the formula 
is logically equivalent to the polite prenexformula 
Remark 3.63 When we apply the method described above to obtain a prenexforrn 
of some givenformula F, the result is a formula that has the same free variable 
.. ,· 
as F (this is immediately verified). In particular, applying the method to a closed 
formula produces a prenex formula that is closed. 
Let F be a first order formula, let G be a prenex form of F, and let H be the 
subformula of G obtained by suppressing the prefix. As H is quantifier-free, it is 

160 
P R E D I C A T E  C A L C U L U S  
obtained from some propositional formula J by a substitution of the kind described 
in Remark 3.27. As for any propositional formula, 1 has a conjunctive normal form 
J1 and a disjunctive normal form J2. The substitution that transforms J into H 
will transform It and J2, respectively, into first order formulas HI and H2 which 
are clearly universally equivalent to H. The prenex formulas G I and G2 obtained 
by placing the prefix of G at the front of HI and flz, respectively, are equivalent to 
F. We say that G I ( G2, respectively) is a conjunctive (disjunctive, respectively) 
prenex form of F. 
3.5.2 Skolem forms 
Consider a polite prenex formula of a language L. Thus there exist pairwise distinct 
variables w J ,  w2, . . .  , Wn, quantifiers Q 1 ,  Q2, . . .  , Q11 and a quantifier-free formula 
G of L such that F = QI WI Q2w2 · · · QnwnG. 
Denote by j I , }2, . .
. , j P the indices of those Q that correspond to an existential 
quantification: that is, 
{ j 1 , .i2 , . . . , j p } = { j E { 1 , 2, . . . , n } : Q j = 3 } 
(we assume l < }1 < }2 < · · · < }p < n). 
With F, we will associate a language Lsk(F) that will be an enrichment of 
the language L obtained by adding p new symbols /1 .
. {2, . . .  , ./p for constants or 
functions (these are called the symbols for the Skolem functions associated with 
F and they correspond to the p occurrences of the symbol 3 in the prefix of F). 
For 1 < h < p, the arity of the symbol fh must equal .ih - h, i.e. the number of 
times the quantifier V occurs to the left of Qj11 in the prefix of F (we adopt the 
convention of treating constant symbols as function symbols of arity 0; for fh to 
be a constant symbol, it is necessary and sufficient that jh = h, i.e. that the first h 
quantifications in the prefix of F be existential; naturally, in such a situation, /1, 
.f2, . . .  , /h-I will also be constant symbols; moreover, the arity of fh increases 
with h). For example, if the prefix of F is 
five new function symbols !1 , .f2, j3, 14 and fs whose respective arities are 2, 3, 
5, 5, and 7 will be added to the language L. 
Now that we have defined our new language, we will use it to define a formula 
F sk, which will be a polite universal formula of the language L sk (F) and which 
we will call the Skolem form of F 
First of all, for 1 < h < p 
.. we let uh denote the term of Lsk (L) that consists of 
the symbol /h followed by the }h 
- ·  h universally quantified variables that occur 
to the left of the variable w jh in the prefix of F. In other words, 

P R E N E X  F O R M S  A N D  S K O L E M  F O R M S  
161 
Then, for each index h between 1 and n, we replace each occurrence of the 
variable w jh in G by the term Uh. 
Finally, in front of the formula thus formed, we place the prefix ofG from which 
all existential quantifications have first been deleted. 
We arrive in this way at the Skolem form of F, which is, therefore, 
f' S k = 'v' W 1 . • . 'v' W j 1 -- 1 'v' W j 1 + 1 . . . 'v' W j h -1 'v' W j h + 1 . · . 'v' W j p - I 'v' W j P + 1 · . · 'v' W n 
Guifw.i1 ,uz/wh .... ,up/w;p 
· 
Example 3.64 Suppose the language L consists of a unary function symbol f 
and a binary relation symbol R. Consider the following formula F of L: 
The language Lsk(L) then contains, in addition to the symbols R and f, four 
new symbols: two constant symbols !1 and !2, a unary function symbol /3 and a 
ternary function symbol /4. The Skolem form of F is the formula 
Given an arbitrary formula F in a language L, we have seen how to fi nd a polite 
prenex formula F' that is equivalent to F. The Skolem form of F' will also be 
called a Skolem form of F (so we do not have uniqueness of the Skolem form of 
an arbitrary formula). 
lt is very important not to lose sight of the fact that a Skolem form of a formula 
F of a language L is not (in general) a formula of L, but of a richer language. 
This will allow us to avoid a rather common error which consists in thinking that 
a formula is equivalent to its Skolem form. Such a statement makes sense only if 
we view F as a formula of the enriched language Lsk (F), which is, of course, 
possible but we realize right away that in order to support this, we would be led 
to examine arbitrary Lsk( F)-structures and that the proposed equivalence would 
be rather pointless. An example would really be more convincing that an overly 
lengthy dissertation: the Skolem form of the formula F = 'v'vo3v1 Rvovt is the 
formula 'v'voRvogvo (we have added the symbol for the unary Skolem function g 
to the initial language L consisting of the binary relation symbol R); the structure 
whose base set is Z, in which R is interpreted by the usual order relation and g by 
the map n Ț---+ n - 1, obviously satisfies the first formula but not the second. 
What is true, none the less, is that every formula F, considered as a formula of the 
language Lsk(F), is a semantic consequence of its Skolem form. As well, provided 
we allow the Axiom of Choice (see Chapter 7 in Volume 2), any L-structure that 
satisfies a (closed) formula F can be enriched to an Lsk(F)-structure that satisfi.es 
the Skolem form of F. A notable consequence of this is that for a closed formula to 
be satisfiable, it is necessary and sufficient that its Skolem form be satisfiable (we 
sometimes say that F and F Sk are equisatisfiable, in the absence of their being 
equivalent). It is this last property that will be mainly used in the next chapter. 

162 
P R E D I C A T E  C A L C U L U S  
Before proving everything that we have just claimed, let us verify it on a very 
simple example in which the essential ideas are clearly apparent. 
Let us reconsider the formula F = V'vo3VI Rvovi that we just used as an example. 
So we have L = {R}, Lsk(F) = { R, g} and Fsk = 'VvoRvogvo. Let M = 
(M, R, g} be an Lsk(F)-structure that satisfies Fsk· This means that for every 
element a E M, we have (a, g(a)) E R. Obviously then, for every element a E M, 
we can find an element b E  M (namely, g(a)) such that (a, b) E R, which means 
that M satisfies the formula F. Thus, F Sk ==} F is a universally valid formula of 
Lsk (F). 
Now consider an L-structure N = (N, p} that is a model of the formula F. 
This means that for every element a E N, the set of those elements b E N such 
that (a, b) E p is non-empty. It is here that the Axiom of Choice intervenes: it 
guarantees the existence of a map ¢ from the set of non-empty subsets of N into 
N (called a choice function on N) such that for every non-empty subset X c N, 
the value of¢ at X is an element of X (¢(X) E X). With the help of such a choice 
function ¢, we will enrich N into an Lsk(F)-structure that will satisfy Fsk· The 
problem is to provide an interpretation for the extra symbol g. For this, we will 
take the map y defined on N in the following way: for all a E N, 
y(a) = ¢ ({b E N : (a, b) E p}). 
I t is then clear that the Lsk(F)-structure (N, p, y) is a model of Fsk· 
Let us now approach these properties in the general case. 
Lemma 3.65 Let y 1 ,  Y2, . . .  , Yn be pairwise distinct variables and let F 
F[Yl , Y2, . . .  , Yn] be a polite prenex formula of a language L. Then the formula 
Fsk =} F of the language Lsk(F) is universally valid. 
Proof By induction on the number of occurrences of the existential quantifier in 
the prefix of F, we will prove, for every Lsk(F)-structure M = (M, . . .  } and for 
all elements hi, b2, . . .  , bn of M, that if the formula Fsk is satisfied in M by the 
sequence (hi ,  b2, . . .  , bn), then the formula F is also satisfied in M by the same 
sequence (recall that the formulas F Sk and F have the same free variables). The 
result is evident when the formula F has no existential quantifiers at all, for then 
F Sk = F. Suppose (this is the induction hypothesis) that the result is true for all 
polite prenex formulas that have at most k existential quantifications and suppose 
that F has k + 1 of them. Thus 
where G itself is a polite prenex formula with at most k existential quantifications. 
There is then an m-ary function symbol fi in the language Lsk(F) such that the 
Skolem form of F is the formula obtained from the Skolem form of the formula 
by substituting the term fiXlX2 . . .  xm for the variable x. 

So we have 
P R E N E X  F O R M S  A N D  S K O L E M  F O R M S  
Fsk = FƁk 
· 
/1 x 1 X2···xm/x 
163 
(We should note that Lsk(F') = Lsk(F) - {fJ }. So we may consider F' as a 
formula of Lsk(F), whose satisfaction in an Lsk-structure is equivalent to its 
satisfaction in the reduced language Lsk(F) (see Lemma 3.58)). 
But we see immediately, by referring to the definition of the Skolem form, that 
starting from the formula F', the result of first taking its Skolem form and then 
substituting into it !IXIX2 . . .  Xm for x is exactly the same as the result of perform­
ing these two operations in the opposite order, i.e. of first doing the substitution in 
F' and then taking the Skolem form of the formula thereby obtained; this depends, 
essentially, on the fact that the variables involved in the substitution are not exis­
tentially quantified in F'. So we also have 
The formula F1' x x 
/x is a polite prenex formula with at most k existential 
l 
I 2·· ·Xm 
quantifiers, so we may apply the induction hypothesis to it: 
if (M : YI > htǾ Y2  b2, . . .  , Yn  bn) վ Fsk, then we also have 
(M : Yl = b1 , Y2 = b2, · · · '  Yn = bn) F FJ1x1x2 
• • •  xm/X '  
which means that for all elements a 1, a2, . . .  , am of M, 
(M : Yt  bt , . . . ' Yn + bn, Xl  at, . . .  , Xm  am} t= G !JX]X2 ... Xm/X · 
Again, this is equivalent (Proposition 3.45) to 
(M : YI  bt , . . .  , yn  bn, XI  a1, . . .  , Xm  am, 
-M 
) 
x  !1 
(a1 , a2, . . .  , am) F= G. 
Thus, for all a 1, a2, . . .  , am, there exists an element b E M, namely 
-M 
!1 
(a 1 , a2, . . .  , am), 
such that 
which proves that 
and, finally, 
(M : YI  bt ,  Y2  b2, . . .  , Yn  bn) F Vxt'VX2 . . .  Vxm3xG, 
which is the long awaited property. 
• 

1 64  
P R E D I C A T E  C A L C U L U S  
Lemma 3.66 (using the axiom of choice) Assume that L is any language, that 
YI. Y2, . . .  , Yn are pairwise distinct variables, that F = F[YJ , Y2, . . .  , Yn] is in 
polite prenex form, that N = (N, . . . ) is an L-structure. and that the n-tuple 
(bt , b2, . . .  , bn) of elements of N satisfies the formula F inN; then it is possible to 
enrich the structure N to an Lsk (F)-structure in which then-tuple (bt , b2, . . .  , bn) 
satisfies the formula Fsh the Skolemform of F. 
Proof Once again, the proof is by induction on the number of existential quan­
tifications in the formula F and, as before, we note that the case in which this 
number is 0 is trivial (Lsk(F) = L, Fsk = F andN is sufficiently rich as is). So 
we assume that the result is true for all polite prenex formulas (in all languages) 
that have at most k existential quantifications and that F has k + 1 of these. Under 
the same conditions as in the proof of the previous lemma, we may set 
F = Vxt Vx2 . . .  Vxm3xG[YI , Y2, . . .  , Yn, X) , X2, . . .  ' Xm, x]; 
F' = Vx1 Vx2 . . .  VxmG[YI , Y2, . . .  , Yn, XI , x2, . . .  , Xm, x]; 
and, for the same reasons, we have 
Since our hypothesis is (N : y 1 --* b 1 , Y2 --* b2, . . .  , Yn --* bn) F= F, it follows 
that for all elements a1 , a2, . . .  , am of N, the set 
is non-empty. So, using a choice function ¢ on N, we may define a map y from 
Nm into N by setting 
for all a L , a2, . . . , am in N. 
We may immediately assert that (*): 
(N : Y1 	 b 1 ,  . . . , Yn 	 bn, XJ --* a 1 ,  . . .  , Xm --+ am, X } y (a 1 ,  a2, . . .  , am)) 
t= G. 
Let L 1 denote the language obtained by adding to L the m-ary function symbol 
lt of the language Lsk (F) (the one corresponding to the firstoccurrenceof3 in F). 
We can enrich N to an L ॅ-structure N1 if we interpret the symbol f1 by the map y. 

F I R S T  S T E P S  I N  M O D E L  T H E O R Y  
165 
The previously displayed assertion (*) then becomes (by applying Lemma 3.58): 
This is also equivalent (by Proposition 3.45) to 
Consequently, 
(NI : Yl , b1, · · · , Yn , bn} I= 'lx1 \lx2 · · · 'lxm [G fiXJX2···xmfx]. 
Since x is distinct from the x; , this last formula is none other than 
which is a polite prenex formula F1 of the language L 1 with at most k existential 
quantifications. By the induction hypothesis, we can enrich the structure N1 to an 
L 1 Sk ( Ft )-structure N* such that 
{N* : YI -4 h t, Y2 + h2, · · ·
'
 Yn - bn} F FfJXJX2···xm/Xsk ·  
We recognize this to be the formula F (in passing, we will have observed that the 
language L15k (F1) is exactly the language Lsk(F). 
• 
Corollary 3.67 For a closed formula to have a model, it is necessary and sufficient 
that any one of its Skolemforms have a model. 
Proof This is an immediate consequence of the two preceding lemmas and the 
theorem about prenex forms (Theorem 3.60). 
• 
The exercises in Chapter 4 will provide other occasions to practise the art of 
putting a formula in prenex from or in Skolem form. 
3.6 First steps in model theory 
3 .. 6 .. 1 Satisfaction in a substructure 
We will begin to take interest in what happens to the satisfaction of formulas when 
we pass from one structure to another. Though we should not expect to have much 
information when the two structures are completely arbitrary, we do have a few 
elementary results at our disposal in particular cases. In fact, we have already 
encountered one: the case where we compare the satisfaction of a formula in a 
structure with its satisfaction in an enrichment of the structure to a more extensive 
language (Lemma 3.58). We will now examine, successively, what can be said 
when we study the satisfaction of a formula in two structures, first, where one is 
an extension of the other, and second, where the two structures are isomorphic. 

166 
P R E D I C A T E  C A L C U L U S  
Knowing that a formula is satisfied in a certain structure, can we conclude (when 
this is meaningful) that it is satisfied in a substructure or in an extension? In general, 
the answer is no, but we do have, none the less, some useful information if the 
formula under consideration is sufficiently simple (see the next two theorems 
below). We need a lemma to begin with: 
Lemma 3.68 Assume that L is a language, M == (M, . . .  ) is an L-structure, 
N == (N, .
. . ) is an extension of M, t == t[vo, VJ , .
.
•
 , Vm-tl is a term of L, 
and ao, a I, . . .  , am-I are elements of M. Then 
-M 
-N 
t [ ao' a 1 ' •
•
•
 ' am-I] == t [ ao, a 1 ' •
•
•
 ' am-tJ . 
Proof This is proved by induction on t: 
-M 
] 
• if t is the variable Vj (0 < J < m - 1), then t [ao, a1, . . .  , am-I 
-N 
t [ ao, a 1 ,  . . .  , am--I] == a j; 
• if t is a constant symbol c, then tM [ao, a1, 
•
•
•
 , am-d 
eM 
eN 
tN[ao, at, . . .  , am-d (since N is an extension of M); 
• if t == f t1 t2 . . .  t p, where f is a p-ary function symbol and tt , t2, . . .  , t p are terms 
. f -M 
] 
-N 
] f 
. 
h" 
that satts y li [ao, a1 ,  . . .  , am-1 
== ti [ao, a1 , . . .  , am-I or 1 < l < p (t IS 
is the induction hypothesis), then 
-M 
t [ ao, a 1 , •
•
•
 , am-1 ] 
-M -M 
-M 
== f  (tt [ao,ai, . . .  , am-Il, . . .  , tp [ao, at, - - - , am- d) 
-,.N -M 
-M 
]) 
== J (t1 [ao, a1 , . . .  , am-IL . . . , tp [ao, at , . . .  , am-1 
fN(-N 
-N 
] 
== 
t1 [ ao, a 1 ,  . . . , am-I], . . .  , t p [ ao, a 1 , . . .  , am- L ) 
-M 
== t [ ao, a 1 , . . .  , am -I ], 
(*) 
(**) 
where (*) is justified by the fact that fM is the restriction of fN to Mk and 
(**) is a consequence of the induction hypothesis. 
• 
Theorem 3.69 Assume that L is a language, M = ( M, . . .  ) is an L-structure, 
N = (N, . . . ) is an extension of M, F = F[vo, VI, . . .  , Vm-I l is a quantifier-free 
formula of L, and ao, a1 ,  . . .  , am-I are elements of M. Then F is satisfied in M 
by the sequence (ao, a1 , . . .  , am-I) if and only ifF is satisfied in N by this same 
sequence. 
Proof The proof is by induction on F. 
• IfF is atomic, there is a k-ary ( k > 1) relation symbol R and terms t1 , t2, . . .  , tk 
whose variables are among vo, VJ, •
•
• , Vm-l such that F == Rtt t2 · · · tk. So 
(M : vo ---+ ao, V] ---+ a], . .  - '  Vm-1 --+ am-d F F 

F I R S T  S T E P S  I N  M O D E L  T H E O R Y  
if and only if 
-M 
] 
-M 
-M 
(lt 
[ ao, a I, . . .  , am-I , . . .  , lk [ ao, a I ,  . . .  , am-I J) E R . 
Now, according to the lemma, we have 
-M 
-N 
ti [ao, a1, . . .  , am-r] :::: ti [ao, at, . . .  , am-d 
for 1 < i < k and, since RM :::: RN n Mk, (t) is equivalent to 
N 
-N 
-Ԩ 
(iJ [ao, a}, . . .  , am-d, .
. . , tk [ao, at, . . .  , am-I ]) E R
, 
which means precisely that 
(N : vo --+ ao, VI --+ at, . . .  , Vm-l ---+ am-d F= F. 
167 
(t) 
• The induction steps that concern the connectives -., 1\, v, =}, and {:} are obvious. 
There are no other cases to consider since F has no quantifiers. 
• 
Theorem 3. 70 Assume that L is a language, M = (M, . . .  ) is an L-structure, 
N == (N, . . .  ) is an extension of M, F = F[vo, VI, 
•
•
•
 , Vm- I] is a universal 
formula of L, G = G[vo, VI, . . .  , Vm-t l  is an existential formula of L, and ao, a I, 
. . .  , am-I are elements of M. Under these conditions: 
ifF is satisfied inN by the sequence (ao, at , . . .  , am-I )  then F is satisfied in M 
by this same sequence; 
(f G is satisfied in M by the sequence (ao, a 1, 
•
•
.
 , am-l) then G is satisfied in N 
by this same sequence. 
Proof The second assertion follows immediately from the first: if G is existential, 
-,G is equivalent to a universal formula F' (property (1) ofTheorem 3.55). If G is 
satisfied in M by (ao, a I ,  . . .  , am-I), then F' is not, hence (by the contrapositive 
of the first assertion) F' is not satisfied in N by ( ao, a 1, . . .  , am-I ), which proves 
that G is. 
We prove the first assertion by induction on the number of universal quantifiers 
in the prefix of F. If this number is 0, the result follows from Theorem 3.69. 
Otherwise, F = Vvk H (where H is universal and has one fewer universal quan­
tifier than F, so, by the induction hypothesis, it satisfies the assertion). Subject to 
replacing k by h == sup(k, m) and H by Hvhfvk (which produces a formula that is 
equivalent to F), we may assume k > m (and even, if we wish, k :::: m). We then 
have H = H[vo, VI, . . .  , Vm-I , Vk] and the fact that 
(N : vo --+ ao, vI --+ a 1 ,  
•
•
•
 , Vm-I ---+ am-1) F= F 
means that for every element a E N, 
(N : vo --+ ao, VI ---+ a1, 
•
•
•
 , Vm-1 ---+ am-1, Vk ---+ a) F= H; 

168 
P R E D I C A T E  C A L C U L U S  
in particular, this must be true for every element a E M. Thanks to the induction 
hypothesis, we may now conclude 
• 
The content of Theorem 3.70 can be summarized by saying that universal for-
mulas are preserved by substructures while existential formulas are preserved 
by extensions. Some more refined preservation properties will be presented in 
Chapter 8 (we will also have a converse to Theorem 3.70: every formula that is 
preserved by substructures (extensions, respectively) is equivalent to a universal 
(existential, respectively) formula.) 
There is one preservation property that we have every reason to expect should 
apply to arbitrary formulas: preservation by isomorphisms. This will be guaranteed 
by the next theorem. 
Lemma 3.71 Assume that L is a language, M == (M, . . .  ) and N == (N, . . .  ) 
are two L-structures, and that h : M t-
ʥ N is a homomorphism from M into 
N. Then for every term t == t [ vo, v 1 , •
•
•
•
 Vm 
_ t1 and for all elements ao, a 1, •
•
•
 , 
am-I of the set M, we have 
(-M 
) -N 
· 
] 
h t [ao, a1 , . . .  , am-Il 
== t [h(ao), h(at), . . .  , h(am-1) . 
Proof The proof is by induction on t: 
• if t is the variable v j ( 0 < j < m - 1 ), then each side of the proposed equality 
is equal to h(a j ); 
• if t is the constant symbol c, then the left side is h (eM) and the right side is eN 
and these are equal since h is a homomorphismॆ 
• if t == ft1t2 . . .  t P' where f is a p-ary function symbol and tt , t2, . . .  , tp are 
h 
. 
-M 
-N 
) 
terms t at satlsf y h (t i 
[ ao, a 1 , •
•
• , am-t J) == t i [ h ( ao), h (a I , •
•
•
 , h (am- 1 ) ] 
for 1 < i < p (this is the induction hypothesis), then 
h (I M [ ao, a I , . . .  , am- d) 
(-M(-M 
-M 
)) 
== h f 
ti [ao, a1, . . .  , am-IL . . .  , tp [ao, a 1 , . . . , am -d 
== JN (h(t)M[ao, a1, . . . , am-d), . . .  , h(tp M [ao, a1 , . . .  , am-d)) (*) 
-.N(--N 
== f 
t 1 [ h ( ao), h (a 1 ) , . . .  , h (am -I ) ] , . . . , 
tpN [h(ao), h(al ), . . .  , h(am-1 )]) 
(**) 
-N 
h 
== t [h(ao), h(a1), . . . , (am-I )], 
where (*) holds because h is a homomorphism and (**) follows from the 
induction hypothesis. 
• 
Theorem 3.72 Assume that L is a language, that M == (M, . . .  ) and N == 
(N, . . .  ) are two L-structures, that h : M .- N is an isomorphism from M 

F I R S T  S T E P S  I N  M O D E L  T H E O R Y  
169 
onto N, that F = F[ vo, v 1 ,  . . .  , Vm- 1 ]  is an arbitrary formula of L and that 
ao, a 1 ,  . . .  , am-I are elements of the set M. Then F is satisfied in M by the 
sequence (ao, a 1 ,  . . .  , am- I )  if and only if F  is satisfied in N by the sequence 
(h(ao), h(a1), . . .  , h(am-1 )). 
Proof The proof is by induction on F. 
• If F is atomic, there is a k-ary (k > 1) relation symbol R and terms tt , t2, . . .  , 
tk whose variables are among vo, V t ,  . . .  , Vm-1 such that F = Rt1t2 . . .  tk. So 
(M : vo ¶ ao, VI · a t ,  . . .  , Vm-1 ͒ am-I) F= F if and only if 
-M 
-M 
-M 
(t1 [ao, a1, . . . , am- t ], . . .  , tk [ao, a1, . . .  , am-t l) E R  . 
(*) 
Because h is an isomorphism, (*) is equivalent to 
-M 
-M 
-N 
(h(tt [ao, a1, . . . , am- d), . . .  , h(tk 
[ao, a t ,  . . .  , am- d)) E R 
, 
or again, according to the lemma, to 
-N . 
-N 
(tt [h(ao), h(a1), . . .  , h(am-1)], . . .  , tp [h(ao), h(at ), . . . , h(am-dD 
-N 
E R 
, 
which means precisely that 
(N : vo ¸ h(ao), VI ¸ h(a t), . . .  , Vm- 1  --+ h(am-1)) F= F. 
• The subsequent induction steps present no problems (in view of Remark 3.57, 
we may restrict our attention tot he cases involving --,, v and 3). For example, let 
us treat the case of existential quantification: so we suppose that F = 3vkG and, 
as in the proof of Theorem 3.70, that k > m and G = G[vo, Vt , . . .  , Vm- 1 , Vk]; 
then 
( M : vo ¶ a o, v 1 ---?- a 1 , .
•
•
 , v m- 1 ¸ am -1 ) F= F 
means that we can find an element a E M such that 
(M : vo --+ ao, VI --+ a t ,  . . .  , Vm-1 ---+ am-1 , Vk ¸ a) F= G; 
by the induction hypothesis, this is equivalent to 
(N : vo -)· h(ao), V t  --+ h(a1), . . .  , Vm-1 -4 h (am-1), Vk --4- h(a)) F= G, 
which proves that 
(N : vo ¸ h(ao), VI ---+ h(a t  ) ,  . . .  , Vm-1 --+ h(am-1 )) F= F. 
Conversely, if this condition is satisfied, we can find an element b E N such 
that 
(N : vo -ʤ h(ao), Vt ¸ h(ai), . . . , Vm- l  ¸ h(am-1), Vk ¸ b) F= G, 

170 
P R E D I C A T E  C A L C U L U S  
and, since h is a bijection, an element a E M such that b = h(a); the conclusion 
now follows, as before, from the induction hypothesis. 
• 
3.6.2 Elementary equivalence 
An immediate consequence of the previous theorem is that two isomorphic L­
structures satisfy exactly the same closed formulas of the language L. This leads 
us to a notion that is absolutely fundamental in model theory, that of elementary 
equivalence. 
Definition 3.73 An L-structure M is elementarily equivalent to another L­
structure N (we will denote this by M = N) if and only if every closed formula 
of L that is satisfied in M is also satisfied in N. 
We immediately conclude that M = N if and only if M andN satisfy the same 
closed formulas of L: indeed, if a closed formula F is not satisfied in M, then 
M F= -sF, so N F= -,p and F is not satisfied in N. Thus we see that = is an 
equivalence relation on the class of £-structures. So we will indifferently say 'M 
is elementarily equivalent to N' or CM and N are elementarily equivalent'. 
The notation M =I= N means that M and N are not elementarily equivalent. 
Therefore, the following is a consequence of Theorem 3.72: 
Proposition 3.74 If two L-structures are isomorphic, then they are elementarily 
equivalent. 
We will have countless opportunities to observe that the converse of this is far 
from being true. The existence of elementarily equivalent models that are not 
isomorphic is clear evidence for the fact that the expressive power of first order 
languages is limited: in the usual practice of mathematics, when two structures are 
not isomorphic, we can generally discern some property that is satisfied by one 
and not by the other; but if the structures are elementarily equivalent, then such 
a distinguishing property will not be expressible as a first order formula of the 
language, nor even by a set of such formulas. If we permit ourselves to anticipate, 
we can discuss an example: it will turn out that the structures (Ε, <) and (Q, <) are 
elementarily equivalent (naturally, the language consists of a single binary relation 
symbol); they cannot possibly be isomorphic since the second is countable while 
the first is not; consequently, none of the properties that distinguish them can be 
expressible by a theory of the language. In particular, this is the case for the famous 
least upper bound property (every non-empty subset that has an upper bounded 
has a least upper bound) which is true in llս but not in Q. 
The remarks we have just made lead us to the foJlowing definition: 
Definition 3.75 Let L be afirstorder language and let X(M) be a property that 
an L-structure M may or may not satisfy. 
The property X(M) is axiotrUltizable (respectively, finitely axiomatizable) if 
there exists a theory T of L (respectively, a closed formula F of L) such that 
for every L-structure M, X(M) is ver{fied if and only Df M is a model of T 

F I R S T  S T E P S  I N  M O D E L  T H E O R Y  
171 
(respectively, of F). When this happens, we say that the theo1y T (respectively, the 
closed formula F) axiomatizes the property X(M). 
We say that X(M) is pseudo-axiomatizahle if there exists a language L * that 
extends L and a theory T of L * such that for every L-structure M, the property 
X(M) is satisfiedifandonlyif M is the reduct to the language L of an L *-structure 
that is a model ofT. 
Obviously, every axiomatizable property is pseudo-axiomatizable. 
Instead of 'axiomatizable property', we often say 'first order property'. 
What we noted above can then be paraphrased as follows: the property (for a set 
and a binary relation on it) of 'being a totally ordered set in which every non-empty 
subset that has an upper bound has a least upper bound' is not axiomatizable (it is 
not even pseudo-axiomatizable ). 
Lemma 3.76 {fa property is finitely axiomatizable, then so is its negation. 
Proof This is immediate from the definition: if a property is axiomatized by the 
closed formula F, its negation is axiomatized by the formula -.F. 
• 
Lemma 3.77 ৱfa property is not axiomatizable, then its negation is not finitely 
axiomatizable. 
Proof This follows from the contrapositive of the previous lemma. 
• 
To show that a property is axiomatizable, it obviously suffices to find a set of 
closed formulas whose models are precisely the structures that have the property 
in question. One suspects that it is a more delicate matter to show that a property 
is not axiomatizable. The fact that you have not found a theory that works clearly 
does not imply that such does not exist. The example of lR and Q suggests a 
possible route: find two elementarily equivalent structures, one of which satisfies 
the property while the other does not. Many of the exercises will focus on this type 
of question. We will treat some simple examples a bit further on. 
Beforehand, let us develop a very efficient tool for resolving not only these 
problems of non-axiomatizability but also numerous other problems of model 
theory. This is the compactness theorem for predicate calculus, which we should 
consider as one of the 'grand' theorems of mathematical logic. Only in Chapter 4 
will we see the proof, but it would be unfortunate not to allow ourselves the 
possibility of using it right away (which will be done in many of the exercises), 
especially since its statement is very simple, all the more for those who have 
previously studied the analogous theorem for propositional calculus. 
Theorem 3.78 (with the axiom of choice) For a theory in a first order language 
to be consistent, it is necessary and sufficient that it be finitely consistent. 
As for the propositional calculus, this compactness theorem has several equiva­
lent versions: 
l-or a first order theory to be contradictory, it is necessary and SU;{ficient that 
some finite subset be contradicto1y. 

172 
P R E D l C A T E  C A L C U L U S  
Or again: 
For a closed formula F of a.fir st order language L to be a semantic consequence 
of a theory T of L, it is necessary and sufficient that there exists a .finite subset To 
ofT such that F is a semantic consequence of To. 
The equivalence of these three versions follows directly from Theorem 3.5 1 .  
Also, the 'necessary' part of the first version and the 'sufficient' part of the other 
two are evident. 
We will now examine the question of the axiomatizability of some standard 
properties, relative to structures for the simplest possible language: the language 
whose only symbol is the equality symbol. Clearly, these structures are none other 
than the non-empty sets. 
For every integer n > 2, the property 4is a set with at least n elements' is finitely 
axiomatizable thanks to the formula: 
1\ 
....,v· ,..._ v ·  
l 
-
J .  
l <i<j<n 
The property 'is a set with at most n elements' is axiomatizable by the formula 
-.,Fn+l · 
The property 'is an infinite set' is axiomatizable by the following theory: 
{ Fn : n E N and n > 2}. 
Two natural questions now arise. Is the property 'is an infinite sef finitely ax­
iomatizable? Is the property 'is a finite set' axiomatizable? The answer in both 
cases is 'no'. 
Theorem 3.79 The property 'is a finite set' is not pseudo-axiomatizable. 
Proof The proof is by contradiction. Suppose T is a theory in a language L that 
conforms with the properties required by Definition 3.75. Then T U { Fn : n E N 
and n > 2} is a set of closed formulas of L that is contradictory (for to satisfy it, 
a set would have to be both finite and infinite!). By the compactness theorem, we 
can find a finite subset T' c T U { f11 : n E N and n > 2} that is contradictory. 
There certainly exists an integer p such that 
T' c T p = T U { Fn : 2 .ռ n < p}. 
So the theory Tp itself is contradictory. But we can see right away that this is false: 
for the finite set {2, 3, . . .  , p} is, according to our hypothesis, the underlying set 
of at least one L-structure M that is a model of T, and M obviously satisfies F2, 
F3, . . .  , Fp, so is a model of Tp. 
• 
From Lemma 3.77, we also immediately obtain: 
Theorem 3.80 The ptvperty 'is an infinite set' is not finitely axiomatizable. 

F I R S T  S T E P S  I N  M O D E L T H E O R Y  
1 73 
However, the infinite sets are precisely those that can support a dense total order­
ing. So we might say that 'being an infinite set' is a 'pseudo-finitely-axiomatizable' 
property. 
Here is another absolutely fundamental notion: 
Definition 3.81 A theory T in a language L is complete ɕf and only if 
( 1 )  T is consistent; and 
(2) all the models ofT are elementarily equivalent. 
Lemma 3.82 For a theory T in a language L to be complete, it is necessary and 
SU;fjicient that 
(I) T is consistent; and 
(2)for every closed formula F of L, we have that either T r-* F or T  r-* -,F. 
Proof If the second condition is not satisfied, we can find a closed formula F of 
L such that T ¥* F and T ¥* -,F, which means that there are two models M and 
N of T such that M Jt= F and N Jt= -, F, or in other words, M S F and N t= F. 
So we see that M :/=. N, which contradicts condition (2) of the definition and so 
T is not complete. Conversely, if T is not complete but is consistent, we can find 
two models A and B of T such that A ¢= B, which proves that there is some closed 
formula F that is satisfied in A but not in B; so neither T r-* F nor T r-* -,p can 
hold. 
• 
Example 3.83 In the language whose only symbol is equality, the theory con­
sisting of the single formula 'v'vo 'v'v1 vo ¥ VI is complete. Indeed, the models of 
this theory are the sets with only one element; these are all isomorphic, hence 
elementarily equivalent. In this same language, the empty theory is not complete: 
indeed, every L-structure is a model of this theory and it is not difficult to find two 
L-structures that are not elementarily equivalent; thus a set with only one element 
satisfies the formula 'v'vo 'v' v1 vo ::: VI but a set with at least two elements does not 
satisfy it. 
Remark 3.84 The fact that a theory is complete or not depends in an essential 
way on the chosen language: if we consider the formula 'v'vo 'v'v1 vo ! VJ as a 
formula of a language that has, in addition to the symbol :::, a unary relation 
symbol P, we see immediately that it is no longer a complete theory, for some of 
its models will satisfy 3voPvo and others will not. 
Having some more interesting examples in mind, let us consider another defini­
tion: 
Definition 3.85 Given an L-structure M, the set of closed formulas of L that are 
satisfied in M is called the theory of M and is denoted by Th(M): 
T h(M) = {F E F(L) : F is closed and M t= F}. 
Theorem 3.86 For any L-structure M, Th(M) is a complete theory of L. 

174 
P R E D I C A T E  C A L C U L U S  
Proof On the one hand, Th(M) is consistent since M is, evidently, a model. On 
the other hand, for any closed formula F of L, we have 
• either M F F, in which case F E Th(M), so 1n(M) t-* F; 
• orelse M Į F, in which case M F -.F, so -,F E Th(M) and Th(M) t-* -.F. 
Invoking Lemma 3.82 now completes the proof. 
• 
We will find many examples of complete and incomplete theories in the exercises. 
3.6.3 The language associated with a structure and formulas 
with parameters 
Consider a language L and an L-structure M == (M, . . .  ) . We will enrich the 
language L to a language, denoted by LM and called the language associated 
with the L-structure M, in the following way: with each element a E M, we 
associate a new constant symbol denoted by a_; we assume that these new symbols 
are really new (i.e. are distinct from all the symbols of L) and that they are pairwise 
distinct (if a =/= b, then a =/= b). We then set 
LM == L U {a. : a E M}. 
It is then not very difficult to enrich M into an L M -structure. We must decide 
on an interpretation for each of the new symbols. No one will be surprised when 
we decide to interpret the symbol a by the element a. If we denote the enriched 
structure by M*, we then have for every a E M: 
aM* - a  
-
-
' 
and we assign to the symbols of L the same interpretations in M* that they had 
in M. 
With every formula F == F[vo. VI , .
•
.
 , Vm-d of L and with every nt-tuple 
(ao, a1, 
•
•
•
 , am-1 )  of elements of M, we can, in a natural way, associate a closed 
formula of the language LM: specifically, the formula Faofvo.a1jv1, • • •  ,am--I_/vm-l 
which, according to our conventions, could also be written 
F[ao, ar , . . .  , am-d-
We then obtain the following result: 
Theorem 3.87 The following properties are equivalent: 
( 1) (M : vo . ao, v 1 ৲ a 1, 
•
.
.
 , Vm - I  , am-1) F F 
(2) M* F F[ao, ar, . . .  , am-d· 
Proof Recall that F[ao, a1, . . .  , am-I ]  is the following formula of LM: 

F I R S T  S T E P S  I N  M O D E L  T H E O R Y  
175 
Before giving the proof, we should note that it will provide the justification that 
we promised in Section 3.3.2 for the notation: 
(*) 
that we have already suggested as a possible abbreviation for property ( 1) above 
(and of which we have already made use). Indeed, we get from property (2) to (*) 
by forgetting to place the asterisk on M and to underline the a;. The abuses that 
consist in identifying, on the one hand, the elements of a model with the constant 
symbols that represent them in the enriched language, and, on the other hand, 
identifying the model with its natural enrichment to this language, present no real 
da11ger and we will often adopt them. Once the theorem is provedҞ an assertion 
such as (*) can have two distinct meanings but the theorem tells us precisely that 
these meanings may legitimately be treated as one. 
• 
In factΓ this theorem is a special case of the following more general result: 
Lemma 3.88 For any integers p and q, any pairwise distinct variables xo, x 1 ,  . . .  , 
Xp--1, yo, YJ, . . .  , Yq-1, any L-formula G = G[xo, XJ , . . .  , X p-I , yo, YI, . . .  , Yq-d 
and any (p + q)-tuple (ao,aJ, . . .  , ap-1, bo, b1, . . . , bq-l) of elements of M, the 
following two properties are equivalent: 
( 1) (M : xo ͒ ao, XI --+ a 1 , . . .  , x p-l --+ a p-I , 
Yo --+ bo, Y 1 --+ b 1 , . . .  , Yq- t ʯ b q -l ) I= G; 
(2) (M* : YO -৶ bo, YI ͓ bt, . . .  , Yq- 1  --+ hq-1 ) I= Gao/xo,lj_/XJ. ... ,ap-t/Xp-1 "  
Proof The proof is by induction on G. If G is the atomic formula Rtt t2 . . .  lk 
(where !t , t2, . . .  , lk are terms of the language whose variables are among xo, 
XI , . . .  , Xp-1, yo, YI, . . .  , Yq-I), then property (1) is equivalent to 
-͓ 
-M 
-M 
(t1 
[ao, . . .  , ap-t ,  bo, . . .  , bq-IL . . .  , tk [ao, . . .  , ap-I, bo, . . .  , bq-d) E R , 
and property (2) is equivalent to 
-M* 
M* 
M* 
( t 1 
[ ao 
, . . . , a p -1 
, bo , . . . , b q- t J , • 
. . , 
-M* 
M* 
M* 
-M* 
t k 
[ ao 
, . . .  , a p-I 
, bo, . . .  , b q -I ] ) E R 
. 
-M* 
-M 
-M* 
-M 
Now, R 
= R 
and t_; 
= t .i 
for I < j < k since these are symbols for a 
relation and for terms of L. The desired equivalence is now a consequence of the 
definition of the a_; M*. 
The other steps in the induction are easy. Let us examine existential quantifica­
tion: if G = 3zH[xo, XI, . . .  , Xp-l, yo, YI, . . .  , Yq--1 ,  zJ (for reasons mentioned 
in Theorem 3.70 and in Theorem 3.72, we may suppose that z is distinct from the 

1 76 
P R E D I C A T E  C A L C U L U S  
x; and the y j ), then property ( 1 )  means that there exists an element a E M such 
that 
(M : xo ʣ ao, . . . , Xp-1 - ap- 1 , yo ৳ bo, . . .  , Yq-1 -) bq-1 , z -৴a) F= H, 
which is equivalent, by the induction hypothesis, to the existence of an element 
a E M such that 
(M* : YO - bo, Yl Ø h1 ,  . . .  , Yq-1 --'> bq-1 , Z } a) F Haofxo,l_!J./X I ,  ... ,ap-1 /Xp-1 ;  
but, by the definition of satisfaction, this is equivalent in turn to 
and this last formula is none other than Gaofxo.'!.J.fx1, ... ,a"_1 fxp-t · This proves the 
equivalence of properties ( l )  and (2). 
• 
To obtain the theorem, it obviously suffices to take q = 0 in the lemma. Observe 
that there was no way to bypass the generalization that this lemma provides: indeed, 
in the induction proof, it is not possible to only consider closed formulas of the 
language LM. 
The formulas of the language L M are often called formulas with parameters 
in M, the parameters being precisely the elements of M which have 'become' 
constant symbols. We will use this concept extensively in Chapter 8. At that time, 
we will have a need for the following two definitions that relate to a model M and 
a language L: 
Definition 3.89 The set of closed quant{fie r-free formulas of L M that are satisfied 
in M* is called the simple diagram of M and is denoted by 6. (M). 
Definition 3.90 The set of closed formulas of the language L M that are sati.ҥfied 
in M* (i.e. the set Th(M*)) is called the complete diagram of M and is denoted 
by D(M). 
Some authors use the phrase elementary diagram instead of complete diagram. 
They have an excellent reason for doing this that will appear in Chapter 8. As it is 
not necessarily simple to make the distinction between simple and elementary, we 
prefer to insist on our terminology (an elementary precaution . . .  ). 
We will state right away a result whose proof will be given in Chapter 8. It allows 
us to characterize, up to isomorphism, the extensions of a structure. 
Theorem 3.91 Given an L-structure M, for an LM-structure N to be a model 
of the simple diagram of M, it is necessary and st;fficient that M be isomorphic 
to a sub-structure of the reduct of N to the language L. 
3.6.4 Functions and relations definable in a structure 
Consider a first order language L and an £-structure M = (M, . . .  ) . 

F I R S T  S T E P S  I N  M O D E L  T H E O R Y  
) 77 
Definition 3.92 
• For any integer k > 1 and any subset A of Mk, A is definable in M by a 
formula of L if and only ifthereexistsaformula F = F[w1, w2, . . .  , Wk] of L 
with at most k free variables such that for all elements a 1, a2, . . .  , ak of M, 
When this happens, we say that such a formula F is a definition of A in M. 
• An element a E M is said to be definable in M by a formula of L if the subset 
{a} is. Any de_finition of {a} is then called a definition of the element a. 
• For any integer k > I and any map ¢from Mk into M, ¢ is definable in M by 
a formula of L (f and only if there exists a formula F = F[w1, w2, . . .  , Wk, z] 
of L with at most k + 1 free variables such that for all elements b, a1, a2, . . .  , 
ak of M, 
Such a fonnula is then called a definition of¢ in M. 
When we consider the graph of a map ¢ from Mk into M to be the set 
{(a1, a2, . . .  , ak, b) E Mk+I : b = ¢(a1, a2, . . .  , ak)}, 
we immediately see that such a map is definable in M by a formula of L if and 
only if its graph is also, and that the formulas that define the map are the same 
ones as those that define its graph. 
It is important to note that the definability of a subset of Mk or of map from Mk 
into M depends in an essential way on the language under consideration and on 
the structure that accompanies the set M. For example, it may happen that a subset 
that is not definable in M by a formula of L becomes definable in an enrichment 
of ivt thanks to a formula of the extended language. 
However, when there can be no reason to fear confusion over the subjects of 
language or structure, we will be content to speak of a definable subset (or relation) 
or function, without further precision. 
Example 3.93 
• The set Mk and the empty set are always definable subsets of Mk: the first, 
thanks to the formula Wt ¥ w, and the second, thanks to its negation. 
• The set of even integers is definable in the structure (Z, +) by a formula of the 
language {g} (g is a binary function symbol): it suffices to consider the formula 
3wogwowo = w1. 
Theorem 3.94 For any integer k > I , the set of subsets of Mk that are definable 
in Nl by a formula of L is a sub-algebra of the Boolean algebra of all subsets 
ofMk. 

178 
P R E D I C A T E  C A L C U L U S  
Proof We have just seen that 0 and Mk are definable. Now, if A and B are defin­
able subsets of Mk and if F = F[w 1 ,  w2, . . . , Wk] and G = G[wi , w2, . . .  , Wk] 
are, respectively, definitions of A and B, it is clear that -,p, (F A G) and ( F  v G) 
are, respectively, definitions for the complement of A in Mk, the intersection of A 
and B and the union of A and B. 
• 
Theorem 3.95 If k is an integer greater than or equal to I and A is a subset of 
Mk that is definable in M by a formula of L and if h is an automorphism of the 
structure M, then the set A is invariant under h (this means that for all elements 
at, a2 , . . . , ak ofM, if(ar, a2, . . .  , ak) E A, then (h(ar), h(a2), . . .  , h(ak)) E A). 
Proof Suppose that F = F[w1, w2, . . .  , Wk] is a formula of L that defines 
A C Mk and that a 1 ,  a2, . . .  , ak are elements of M. If (at , a2, . . .  , ak) E A, 
then M F F[ar , a2, . . .  , ak]; in this case, then for any automorphism h of the 
structure M, we also have M F F[h(at), h(a2), . . .  , h(ak)] (by Theorem 3.72), 
which proves that (h(at ), h(a2), . . .  , h(ak )) E A (because F is a definition of A) . 
• 
This theorem is useful when we want to show that a set is not definable: to do 
this, it suffices to find an automorphism of the structure under consideration that 
does not leave the set in question invariant. 
To illustrate this, let us prove that no subsets offfi( other than JR( and 0 are definable 
in the structure (JR, <) by a formula of the language { R} (R is a binary relation 
symbol). We will argue by contradiction; suppose that there is a subset A c JR(, 
distinct from {Fg and 0, that is definable by a formula F == F[ w] of this language. 
Then choose an element a E A (A is not empty) and an element b E 1R - A (JR- A 
is not empty). Observe that the map h from JR( into JR( which, with every real x, 
associates the real x + b - a, is an automorphism of ( JR, <) which does not leave 
A invariant (since h(a) = b), which contradicts the previous theorem. 
Next, we will introduce the notion of definability with parameters, which 
generalizes the notion we just studied. 
We still consider a first order language L and an L-structure M = (M, . . .  ). 
Definition 3.96 For any integer k greater than or equal to I and any subset A of 
Mk, A is definable with parameters from M if and only if there exist an integer 
m > I, aformula F = F[w1, w2, . . . , Wk, Z l ,  22, . . . , zm] ofL withatmostk+m 
free variables, and m elements b 1 ,  b2, . . . , bm of M such that for all elements a 1 ,  
a2, . . .  , ak of M, 
When this happens, the formula F[ w 1 ,  w2, . . .  , Wk, b 1 ,  b2, . . .  , bm] is called a 
definition of A in M with parameters b 1 ,  b2, . . .  , bm. 
The notion of a map from Mk into M that is definable with parameters from 
M has an analogous definition. 

M O D E L S  T H A T  M A Y  N O T  R E S P E C T  E Q U A L I T Y  
1 79 
For example, every finite subset { 0:'1, a2, . . .  , a p} of M is definable in M with 
the parameters a 1, 0:'2, . . . , a P thanks to the formula 
v w Ɩ O:'i . 
l<i<p 
We immediately see that to be definable with parameters from M is equivalent 
to being definable (in the sense of Defi.nition 3.92) by a formula of the language 
lेM in the structure M*, the natural enrichment of M to LM (see Theorem 3.87). 
3. 7 Models that may not respect equality 
Our excursion into this topic will be as brief as possible. 
We consider a language that includes the symbol for equality, Ɩ. Let E denote 
the theory of L that consists of the following closed formulas (called the axioms 
of Eȓquality): 
• the formula: Vvovo i".J vo; 
• the formula: VvoVv1 (vo " VJ ==? v1 Ɩ vo); 
• the formula: VvoVv1 Vv2((vo Ɩ v1 /\ v1 ʢ v2) ==? vo i".J v2); 
• for every integer k > I and every k-ary function symbol f of L, the formula: 
Vv1 . . .  VvkVVk+l . . .  Vv2k ( 1\ v;  Vk+i => fvl . . .  Vk Ɩ fvk+l . . . V2k ); 
l<i<k 
• for every integer k > I and every k-ary relation symbol R of L, the formula: 
Vv1 . . .  Vvk Vvk+ 1 . . . Vv2k ( ( Rv1 . . .  Vk 1\ 1\ v; ı Vk+i) => RVk+J . . .  v2k). 
I <i<k 
It is quite clear that all of these formulas are satisfied in any L-structure that 
respects equality. 
Consider an arbitrary L-structure M = ( M, . . .  ) in which the symbol for equal­
ity, :::, is interpreted by some binary relation on M that we will denote by e .  We 
are going to show that if M is a model of the theory E, then we can define from 
M, in a natural way, another model that does respect equality and possesses some 
interesting properties. 
So suppose that M F= E. Then, according to the first three formulas of E, 
the relation () is an equivalence relation on M that is, according to the remaining 
formulas of E, compatible with the functions and relations of the structure. Let 
A denote the quotient M je (the set of equivalence classes relative to e). The 
equivalence class of the element a E M will be denoted by cl(a). We can make 
A into an L-structure A by defining the interpretations of the symbols of L in the 
following way: 
• for each constant symbol c of L, cA = cl(cM); 

180 
P R E D I C A T E  C A L C U L U S  
• for every integer k > I and every k-ary function symbol f of L, .FA is the map 
from Ak into A which, to each k-tuple (cl(at), cl(a2), . . .  , cl(ak)) E Ak, assigns 
the element cl(fM (at , a2, . . .  , ak)); this makes sense because e is compatible 
-M 
with f ; 
• for every integer k > 1 and every k-ary relation symbol R of L, RA is the 
k-ary relation on A defined by: (cl(ai), cl(a2), . . .  , cl(ak)) E RA if and only 
if (a I , a2, . . .  , ak) E RM (again, this makes sense because e is compatible 
-M 
with R ) . 
We see immediately that the £-structure A defined in this way respects equality: 
indeed, the interpretation in A of the symbol ॄ is the set of pairs (cl(a), cl(b)) E 
A2 such that (a, b) E ""'M, i.e. such that (a, b) E e, or equivalently, such that 
cl(a) = cl(b ); this is precisely the diagonal of A2• 
Lemma 3.97 For every formula F = F [ vo, v 1 ,  .
.
•
 , Vn-1] of L and for all ele­
ments ao, a 1, .
•
.
 , an--I, bo, bt, . . .  , bn-I of M, we have: 
(1*) if(a;, b;) E e forO < i < n - 1 ,  then 
M F F[ao, at, . . .  , an-I] if and only ilM F= F[bo, bt, . . .  , bn-d: 
(2*) M F= F[ao, at, . . .  , an--I l ifandonlyifA t= F[cl(ao), cl(a1), . . .  , cl(an-1)]. 
Proof We prove these two properties by induction on F. The case for atomic 
formulas is settled by the very definition of A. Next, Remark 3.57 allows us to 
limit our attention to the induction steps that relate to -., 1\ and 3. It is only this 
last one that deserves any effort: so suppose, then, that 
F = 3vm G[vo, V I ,  . .
. , Vn-1 ,  Vm]. 
We may suppose that m > n - 1 in view of a remark that we have made on many 
earlier occasions. Under these conditions, for M to satisfy Ff ao, a 1 ,  .
.
.
 , a11_ 1 ], 
it is necessary and sufficient that there exist an element b E M such that M F= 
G [ao, a 1 ,  . . .  , an-1, b]. Given that G satisfies the lemma (by the induction hypoth­
esis) and that for every b E M, (b, b) E e (the first formula of E), if (a;, b;) E e 
for all i, then we may conclude that M t= F[ao, a1 ,  . . .  , an-t] if and only if 
there exists an element b E M such that M t= G[bo, bt , . . .  , bn-1 , b J. In other 
words, M F= F[ao, a1, . . .  , an-d if and only if M t= F[bo, b1 , . . .  , bn-d, 
which proves (I *). In the same way, we see by the induction hypothesis that 
M F= F[ao, a1, . . .  , an-I] if and only if there exists an element b E M such that 
A t=  G[(CI(ao), cl(ai), . . .  , cl(an_!), cl(b)], 
which is equivalent to 
{A : vo - cl(ao), V) --4 cl(at), . . .  , Vn- 1  ʯ cl(an-I)} F= 3vmG, 

M O D E L S  T H A T  M A Y  N O T  R E S P E C T  E Q U A L I T Y  
or again, to 
A f= Ffcl(ao), cl(a1 ), . . .  , cl(an-1 )]; 
this proves property (2*) for F. 
1 8 1  
• 
Theorem 3.98 For a theory T of a language L containing Ɩ to have a model 
that respects equality, it is necessary and sufficient that the theory T U E have an 
(arbitrary) model. 
Proof lf T has a model that respects equality, then E is satisfied in such a model, 
as we have already noted just after the definition of E; hence, T U E has a model. 
If T U E has a model M = (M, . . .  ), then since M is a model of E, we can, as 
above, construct the model A on the quotient of M by the interpretation in M of 
the symbol - It is a consequence of the preceding lemma that every formula of T 
(recall that these are closed formulas) that is satisfied in M will also be satisfied 
in A. So the structure A is a model of T that respects equality. 
• 
The reader who is interested can show that the second and third formulas in 
the list of axioms of equality (the ones that express the symmetry and transitivity 
of equality) could have been omitted for they are derivable from the ones that 
express compatibility with the relations of the structure (among which can be 
found, naturally, the interpretation of Ɩ). 

1 82 
P R E D I C A T E  C A L C U L U S  
E X E R C I S E S  F O R  C H A P T E R  3 
1. The language L consists of a unary function symbol f and a binary function 
symbol g. Consider the foil owing closed formulas: 
Ft : 3x3yfgxy  fx 
F2 : Vx\:lyfgxy Ɩ fx 
F3 : 3y\:lxfgxy ;-v fx 
F4 : \:lx3yfgxy ;-v fx 
Fs : 3x\:lyfgxy  fx 
F6 : \:ly3xfgxy ° fx. 
Consider the four structures whose underlying set is N*, where g is interpreted 
by the map (m, n) ʡ 
-
·., m + n, and where f is interpreted respectively by 
(a) the constant map equal to 103; 
(b) the map which, with each integer n, associates the remainder after division 
by 4; 
(c) the map n Ȓ inf(n2 + 2, 19); 
(d) the map which, with each integer n, associates 1 if n = 1 and the smallest 
prime divisor of n if n > 1 .  
For each of the six formulasɸ determine whether it is satisfied or not in each 
of the four structures. 
2. The Language consists of a unary predicate symbol P and a binary predicate 
symbol R. Consider the following six formulas: 
G 1 : 3x'Vy3z((P x ==> Rxy) 1\ Py 1\ --.Ryz) 
G2 : 3x3z((Rzx ==} Rxz) ==} \:lyRxy) 
G3 : \:ly(3z\:lt Rtz 1\ \:lx(Rxy ==> --.Rxy)) 
G4 : 3x\:ly((Py ==> Ryx) 1\ (\:lu(Pu ==} Ruy) ==> Rxy)) 
Gs : \:lx\:ly((Px 1\ Rxy) ==} ((Py 1\ --.Ryx) ==> 3z(--.Rzx 1\ --.Ryz))) 
G6 : \:lz\:lu3x\:ly((Rxy 1\ Pu) ==} (Py ==} Rzx)). 
For each of these formulas, determine whether or not it is satisfied in each of 
the three L-structures defined below: 
(a) The base set is N, the interpretation of R is the usual order relation <, the 
interpretation of P is the set of even integers. 

E X E R C I S E S F O R  C H A P T E R  3 
1 83 
(b) The base set is 6J (N) (the set of subsets of N), the interpretation of R is 
the inclusion relation c, the interpretation of P is the collection of finite 
subsets of N. 
(c) The base set is Ε, the interpretation of R is the set of pairs (a, b) E Ε2 such 
that b ::: a2, the interpretation of P is the subset of rational numbers. 
3. The language L has two unary function symbols f and g. 
(a) Find three closed formulas F, G, and H of L such that for every L-structure 
M ::: {M, f, g}, we have 
M I= F if and only if f ::: g and f is a constant map; 
M I== G if and only if lm(f) c lm(g); 
M I= H if and only if lm(/) n lm(g) contains a single element. 
(b) Consider the following five closed formulas of L: 
F1 : 'Vxfx Ɩ gx 
F2 :  'Vx'Vyfx  gy 
F3 : 'Vx3yfx  gy 
F4 : 3x'Vyfx Ɩ gy 
Fs : 3x3yfx  gy 
Find a model for each of the following six formulas: 
4. Let L be a first order language. For every formula F[vo, v1 , . . .  , Vk] of L, the 
expression 3! vo F denotes the following formula: 
3!voF is read: 'there exists one and only one vo such that F'. 
Note that in any L-structure M ::: (M, . . .  ), 3!voF is satisfied by a k-tuple 
(at, a2, . . .  , ak) if and only if there exists a unique object a E M  such that the 
(k + 1 )-tuple (a, a1 , a2, . . .  , ak) satisfies F. 
Let F[vo, vt] be a formula of L. Find a closed formula G of L which is 
satisfied in an L-structure M = (M, . . .  ) if and only if there exists a unique 
pair (a, b) E M2 such that (M : vo , a, Vt , b) F= F. Are the formulas 
equivalent? 
5. Let L be a first order language and let A [ x, y] be an arbitrary formula of L with 
two free variables. 

184 
P R E D I C A T E  C A L C U L U S  
(a) rs the formula 
'v'x3y A[x, y] ==> 3y'v'xA[x, y] 
satisfied in any L-structure? 
(b) Repeat question (a) for the formula 
3yVxA[x, y] ==> 'v'x3yA[x, yj. 
(c) Show that for arbitrary formulas with two free variables A [x, y l and B [x, y ], 
the following formula is universally valid: 
('v' x'v'y A[x, y] ==> 3x3y B[x, y]) <=? 3x3y(A[x, y] ==> B[x, y ]). 
(d) Let F be the formula 
'v'x'v'y(A[x, y] ==> A[y, x]) ==> 
(('v'u'v'v(A[u, v] ==> B[u, v]) ==> 3x3y(A[x, yJ ==> C[x, yJ))) 
where A, B and C are arbitrary formulas with two free variables. 
Show that there exists a quantifier-free formula G = Gfx, y] with two 
free variables such that F is universally equivalent to 3x3yG. 
6. Show that if two formulas are universally equivalent, then so are their universal 
closures. 
7. In all of the languages considered in this exercise, R is a binary relation symbol, 
* and EB are binary function symbols, c and d are constant symbols. 
We will write x EB y and x * y respectively, rather than EBxy and *XY (with 
a reminder that this necessitates the use of parentheses when writing terms). 
x2 will be an abbreviation for x * x. 
(a) In each of the following six cases ( 1  < i < 6), a language Li and two 
Li-structures Ai and Bi are given and you are asked to find a closed formula 
of Li that is true in Ai and false in Bi . 
( 1 )  LI = {R} 
At = (N, <) 
(2) L2 ::= { R} 
A2 = (Q, <) 
(3) L3 = {*} 
A3 = (N, x) 
(4) L4 = {c, *} 
A4 = (N, 1, x) 
(5) Ls = {c, d, EB, *} 
As = (JR, 0, 1, +, x} 
(6) L6 = {R} 
A6 = (Z, -2) 
BI = (/Z, <) 
B2 = (/Z, <) 
B3 == (8'J (N), n) 
B4 = (Z, 1, X )  
Bs = (Q, O, 1, +, x } 
B6 = (Z, =3) 
( x and + are the usual operations of multiplication and addition, n is the 
operation of intersection, =P is the relation of congruence modulo p.) 
(b) For each of the following closed formulas of the language {c, EB, *, R}, find 
a model of the formula as well as a model of its negation. 
Ft : 'v'u'v'v3x( -.v Ơ c ==> u EB (v * x) Ơ c) 
F2 : 
VuVvVw3x(-.w ı c ==> u EB (v * x) EB (w * x2) ı c) 

E X E R C I S E S  F O R  C H A P T E R  3 
F3 : 
VxVyVz(Rxx /\ ((Rxy /\ Ryz) => Rxz) /\ (Rxy => Ryx)) 
F4 : 
VxVyVz(Rxx => R x * z y * z) 
Fs : 
VxVy(Rxy => -,Ryx ). 
8. The language L consists of a single binary predicate symbol, R. 
1 85 
Consider the L-structure M whose base set is M = {n E N : n > 2} and in 
which R is interpreted by the relation 'divides', i.e. R is defined for all integers 
m and n > 2 by the condition: (m, n) E R if and only if m divides n. 
(a) Foreach ofthe following formulas of L (with one free variablex), describe 
the set of elements of M that satisfy it. 
Ft : 
Vy(Ryx => x ::: y) 
F2 : 
VyVz((Ryx A Rzx) => (Ryz v Rzy)) 
F3 : 
Vy\lz(Ryx => (Rzy  Rxz)) 
F4 : 
Vt3y3z(Rtx => (Ryt /\ Rzy /\ _,Rtz)). 
(b) Write a formula G[x, y, z, t] of L such that for all a, b, c and d of M, the 
structure M satisfies G[a, b, c, d] if and only if d is the greatest common 
divisor of a, b and c. 
(c) Let H be the following closed formula of L: 
VxVyVz((3t(Rtx/\Rty)A3t(Rty/\Rtz)) :::} 3tVu(Rut => (Rux/\Ruz))). 
(I) Find a prenex form of H. 
(2) Is the formula H satisfied in M? 
(3) Give an example of a structure M' = (M', R) such that when M is 
replaced by M' in the previous question, the answer is different. 
9. Let L be the first order language which has one unary relation symbol Q and 
two binary relation symbols I and R. 
Consider the following formulas of L: 
Ft : 
'tfx-,Rxx 
F2 : 
Vx(Qx => -,Rxx) 
F3 : 
VxVy\lz((Qx A Qy /\ I  xz /\ I  zy) => Qz) 
F4 : 
VxVyVz((Qx /\ Qy /\ Qz /\ Rxy /\ Ryz) => Rxz) 
Fs : 
Vx't/y((Qx /\ Qy) => ( -,Rxy v -,Ryx)) 
F6 : 
VxVy((Qx /\ Rxy) => Qy) 
F1 : 
Vx\ly(Qx /\ Ryx) => Qy) 
Fs : 
Vx3y3z(Ryx /\ Rxz) 
Fy : 
Vx3y3z(Qx => (Ryx /\ Rxz /\ Qy /\ Qz)) 
FLO : 
VxVy3z((Qx /\ Qy /\ Rxy) => (Rxz /\ Rzy /\ Qz)). 
(a) Consider the L-structure M whose base set is &J (N), in which the inter­
pretation of Q is the unary relation '. . . is infinite and its complement is 
infinite', the interpretation of I is is the inclusion relation, and the pairs 

186 
P R E D I C A T E  C A L C U L U S  
(A, B) that satisfy the the interpretation of the binary relation R are those 
for which A c B and card(A) = card(B - A) (the notation card(X) 
denotes the cardinality of a set X; see Chapter 7). 
For each of the formulas above, determine whether it is satisfied or not in 
the structure M. 
(b) We add a new unary predicate symbol D to the language. ls i t  possible to 
enrich the structure M with an interpretation of D such that the following 
four formulas are satisfied? 
G1 : 
VxVy((Dx /\ Dy) => (Ixy v Iyx)) 
G2 : 
VxVy3z((Dx /\ Dy /\ I  xy A -.x Ɩ y) => 
(Dz /\ Ixz /\ Izy /\ -,x  z /\ -.y  z)) 
G3 : 
Vx3y3z(Dx => (Dy /\ Dz /\ I  xy /\ I  zx /\ -.x  y 1\ -.x ͥ z)) 
G4 : 
3xDx 
10. Let L be a language and let F be a formula of L. 
The spectrum of F is the set of cardinalities of finite models o f F; i.e. it is 
the set of natural numbers n such that F has a model whose base set has exactly 
n elements; it is denoted by Sp( F). 
(a) For each of the following subsets of N, exhibit, when this is possible, an 
example of a language L and a closed non-contradictory formula F of L 
whose spectrum is the subset in question. 
(1) 0; 
(2) N; 
(3) N*; 
(4) {n E N* : (3p E N') (n = 2p)}; 
(5) {n E N* :  (3p E N) (n = p2)}; 
(6) {3}; 
(7) { 1 ,  2, 3, 4}; 
(8) N - {O, I ,  . . .  , k}; 
(9) the set of non-zero composite natural numbers; 
( 1 0) the set of prime numbers. 
(b) Show that any formula whose spectrum is infinite has at least one infinite 
model. 
11. Show that if all the models of a non-contradictory theory are isomorphic, then 
the theory is complete. 
12. Let L be a first order language, let M be an L-structure and let A be a subset 
of the base set of M. 
(a) Show that if A is not empty, there exists a unique sub-structure A of M 
such that: 
( 1 )  the base set of A includes A; 
(2) every sub-structure of M whose base set includes A is an extension 
of A. 
A is called the substructure of M generated by A. 
(b) Show that, when A = 0, there may not be a substructure generated by A. 
Give an example, however, in which one does exist. 

E X E R C I S E S  F O R  C H A P T E R  3 
1 87 
(c) Suppose that L contains no function symbols of arity > 1 .  What is the 
substructure generated by a subset A in this case? 
(d) A sub-structure N of M is said to be of finite type if and only if N is 
generated by a non-empty finite subset of M. 
Let F be a closed universal formula of L. Show that F is satisfi.ed in M 
if and only if F is satisfi.ed in every sub-structure of M of finite type. 
(e) Give a counterexample to (d) for a formula that is not universal. 
13. The language L consists of one constant symbol c and two unary function 
symbols f and g. The theory T consists of the following formulas: 
Ht : 
Vvof fvo Ö fvo 
H2 : 
Vvoggvo ¥ gvo 
H3 : 
Vvo(f gvo ¥ c 1\ gfvo ::: c) 
H4 : 
VvoVvt ((f vo ¥ fvt 1\ gvo ::: gvt) ==> vo ::: VI) 
Hs : 
Vv1Vv2((fv1 ::: VI 1\ gv2 Ö2) => 3vo(fvo ¥ VI 1\ gvo Ȇ v2)). 
(a) Show that for any term t of L, at least one of the following cases applies: 
o T !-* t ¥ c; 
o there exists a variable x such that T 1-* t ¥ x ;  
o there exists a variable x such that T 1-* t ¥ f x ;  
o there exists a variable x such that T 1-* t Ö g x .  
(b) Let A and B be two non-empty sets with ao E A and bo E B. We denote 
by M (A, B, ao, bo) the L-structure whose underlying set is A x B, and in 
which c is interpreted by (ao, bo), f by the map (a, b) r----7 (a, bo) and g 
by the map (a, b) ৵ (ao, b). Show that M(A, B, ao, bo) is a model of T. 
(c) Show that the following formulas are consequences ofT: 
H6 : 
fc ¥ c  
H1 : 
gc ¥ c 
Hs : 
Vvo(fvo Ɩ vo <=> gvo Ö c) 
Hg : 
Vvo(gvo Ö vo <=> fvo ¥ c) 
Hio : 
Vvo(f vo Ö vo {:} 3vt jv1 Ö vo) 
H1 1 : 
Vvo(gvo ::: vo <=> 3vtgVI Ö vo) 
H12 : 
Vvo((fvo ¥ vo 1\ gvo Ö vo) <=> vo ¥ c) 
H13 : 
VvoVvt (fvo Ö gvi => fvo ¥ c). 
(d) Given four non-empty sets A, B, C and D and four elements ao E A, bo E B, 
co E C, and do E D, show that if A and C are equipotent and if B and 
D are equipotent (two sets are called equipotent if there exists a bijection 
between them), then the structures M(A, B, ao, bo) and M(C, D, co, do) 
are isomorphic. 

1 88 
P R E D I C A T E  C A L C U L U S  
(e) Let M = (M, a, cp, l/1 )  be a model of T. Set 
A = {X E M : cp (x) = X}, B == {X E M : lj! (X) = X}, ao = ho = a. 
Show that M is isomorphic to the structure M (A, B, ao, bo). 
For every integer n > I ,  write a closed formula Fn (respectively G n) of 
L that is true in M if and only if the set A (respectively, B) contains at least 
n elements. 
Show, for all integers n and p > 1. that the theory 
is complete. 
(f) Let F be a closed formula of L that is satisfied in every infinite model of T. 
Show that there exists at least one integer n such that T U { Fn v G n }  1-* F. 
Is the theory T U { Fk v G k : k E N* } complete? 
The last two questions make use of concepts that will be introduced only 
in Chapters 7 and 8. 
(g) Describe all the countable models of T. 
(h) Is the theory T'' = TU{Fk : k E N*} U{Gk : k E N*} complete? (To answer 
this question, we will need Vaught's theorem (see Volume 2).) 
14. The language L consists of one unary function symbol f. 
We let A denote the following formula: 
Vx (fffx  x 1\ -.fx  x). 
(a) Show that the following formula is a consequence of A: 
Vx3y'Vz(-,ffx ° x 1\ -,ffx ° f x 1\ fy ° x 1\ (.fz  x =? z  y)). 
For every integer n E N*, we let Fn denote the following formula; 
3xr 3x2 . . .  3xnvx( ( 1\ 
-·x; " Xj) !\ ( V x  x;) ). 
1 <i < j <n 
1 <i <n 
(b) Show that, for every integer n E N*, the fonnula A 1\ F n has a model if and 
only if n is a multiple of 3. 
(c) Show that, for every p E N*, the theory {A, F3 P } is complete. 
(d) Exhibit a countable model of the formula A (i.e. a model of A whose base 
set is in bijection with the set of natural numbers). 
(e) Show that all the countable models of A are isomorphic. 
15. The language L consists of two unary function symbols r and I. For every term t 
of L, set r0t = t0t = t and, for every integer k, rk+l t = rrkt and zk+ l t  = Itk t. 

E X E R C I S E S  F O R  C H A P T E R  3 
1 89 
Let F be the formula 
Yx'v'y3u3v(((rx  ry v lx ¥ ly) :::} x  y) 1\ 
(x  ru 1\ x ¥ lv) 1\ (--.rx ¥ lx 1\ rlx  lr x)), 
and for every pair (m, n) of natural numbers, let Fmn be the formula 
Let T be the theory consisting of F together with the set of all the F mn such 
that (m, n) =f. (0, 0). 
(a) Show that for every term t of L, there exists a variable x and integers m and 
n such that 
T 1-* Vx(t  rmlnx). 
(b) Show that the structure Mo whose underlying set is Z x Z and where r 
and l are interpreted respectively by the maps 
Sr : (i, j) r-+ (i, j + 1) (right successor) 
Si : (i, j) ңҤ (i + 1 ,  j) (left successor) 
is a model of T; it will be called the standard model of T. 
(c) Show that for any two integers A and B, the map hab from Z x Z into 
Z x Z defined by hab{i, j) = (i + a, j + b) is an automorphism of Mo. 
(d) Which subsets of Z x Z are definable in the structure Mo by a formula 
of L? 
16. We wil1 allow the following abuse of notation: for every integer n > 1, we will 
let 0, 1, . . .  , n - 1 denote the elements of Z/ n Z (i.e. the respective equivalence 
classes modulo n of 0, 1, . . .  , n - 1 )  and will let + denote addition in this set. 
(a) The language L has a single unary function symbol f. 
Consider the following L-structures: 
M1 = (ZjnZ, x / x + 1) ; 
M2 = (ZjnZ, x r-+ x + 2) . 
For each structure, determine which subsets of the underlying set are 
definable. 
(b) The language L' has a single binary function symbol g. 
Consider the following L' -structures: 
N1 = (Z/37l, (x, y) ৬৭ x + y) ; 
N1 = (Z/6Z, (x, y) ң৮ x + y) ; 
Nt = (¨, (x, y) ৯Ҥ xy) . 
For each structure, determine which subsets of the underlying set are 
definable. 

1 90 
P R E D I C A T E C A L C U L U S  
(c) The language L" has a single binary relation symbol R. 
Consider the L" -structure (IR, <}. 
( 1) Which subsets of 1R are definable in this structure? 
(2) Which subsets of JR2 are definable in this structure? 
17. Given an integer n > 2 and a binary relation S on a set E, a cycle of order 
n (or n-cycle) for S is an n-tuple (at , a2 , . . .  , a11) of elements of E satisfying: 
(at , a2) E S, (a2, a3) E S, . . .  , (a11-t, an) E S and (an, at) E S. For example, 
the usual strict ordering on 1R has no n-cycles, whereas the binary relation on the 
set { 1 ,  2, 3} whose graph is { ( 1, 2 ), (2, 3 ), (3, I)} has 3-cycles but no 2-cycles. 
In the first order language L that has a single binary relation symbol R, 
consider, for every n > 2, the following formula Fn : 
Set T = { Fn : n E N, n > 2}. 
We say that an L-structure (M, R} is cycle-free if for every n > 2, R has no 
n-cycles; in the opposite case, we say that the structure has cycles. It is clear 
that the models of T are the cycle-free L-structures. 
(a) For every n > 2, exhibit a model of of the formula 
(b) Show that if G is a closed formula of L that is a consequence of T , there 
exists at least one integer p > 2 such that G is satisfied in every L-structure 
in which the interpretation of R has no cycles of order less than or equal 
to p. 
(c) Show that every closed formula that is a consequence of T has at least one 
model that has cycles. 
(d) Show that T is not equivalent to any finite theory. (Hence the concept of a 
cycle-free binary relation, which T axiomatizes, is not finitely axiomatiz­
able). 
18. Recall that an order relation on a set E is a  well-ordering if and only if every 
non-empty subset of E has a smallest element with respect to this order. This 
exercise shows that this concept is not pseudo-axiomatizable. 
Let Lo be the language whose only symbol is a binary relation symbol R and 
let L be a language that enriches Lo. Show that there does not exist a theory T 
of L with the following property: for every L0-structure M = (M, p}, p is a 
well-ordering of M if and only if M can be enriched to an L-structure that is a 
model of T. 
To do this, use the language L' obtained from L by adding a countably infinite 
set of new constant symbols, co, c1, . . . , en, . . . (pairwise distinct) and, for every 
integer n, consider the following closed formula F11 of L': 

E X E R C I S E S  F O R  C H A P T E R  3 
191 
19. Let L be a first order language and let L' be the language obtained from L by 
adding new constant symbols CI, c2, . . .  , Ck· 
Consider a theory T and a formula F[Xt, X2, . . .  , Xk] of L. 
Show that if the closed formula F[c1, c2, . . .  , Ck] of L' is a consequence of 
T (considered as a theory of L'), then T f-* Vx1 Vx2 . . .  VxkF[x1 , x2, . . .  , Xk I 
(this conclusion concerns only the language L ). 
20. We are given a first order language L, an L-structure M = (M, .
. . ) and a 
theory T of L. 
Recall that Ң(M) denotes the simple diagram of M (Definition 3.89). 
(a) Assume that no extension of M is a model of T. Show that there exists a 
quantifier-free formula G[x1 , x2, . . .  , Xn] of L such that 
T f-* Vx1 Vx2 . . .  VxnG[XI , X2, . . .  , Xn] and 
M Jr Vx1 Vx2 . . .  VxnG[XI , X2, . . .  , Xn]. 
(Consider the theory T U Ң (M); use Theorem 3. 91 and Exercise 1 9). 
(b) Let U(T) denote the set of closed universal formulas of L that are conse­
quences of T. 
Show that for the existence of an extension of M that is a model ofT, it 
is necessary and sufficient that M be a model of U(T). 
(This result is a special case of what is called the extension theorem). 
(c) A sub-structure of M that is generated by a non-empty finite subset of !VI 
is called a sub-structure of finite type. (The sub-structure of M generated 
by a non-empty subset A c M is the smallest sub-structure of M whose 
base set includes A: see Exercise 12.) 
Show that for the existence of an extension of M that is a model of T, it 
is necessary and sufficient that every sub-structure of M of finite type have 
this same property. 
21. Let L be a first order language and let F1 denote the set of formulas of L that 
have at most one free variable. Given an L-structure M = (M, . . .  ) and an 
element a E M, the set ()(a) of formulas in F1 that are satisfied in M by a is 
called the type of a in M (or simply, the type of a if there is no ambiguity; 
this vocabulary will be taken up again in Chapter 8). In other words: 
()(a) = {F[v] E F1 : v is a variable and M f= F[a]}. 
(a) Show that if all the elements of a subset A c M have the same type in 
an L-structure M = (M, . . .  ), then every subset of M that is definable 
in M by a formula of L must either include A or be disjoint from A (see 
Definition 3.92). 
(b) Let h be an automorphism of an L-structure M = (M, . . .  ), and let a be 
an element of M. Show that a and h(a) have the same type. 

192 
P R E D I C A T E  C A L C U L U S  
(c) R, f, g and c are, respectively, a binary relation symbol, a unary function 
symbol, a binary function symbol and a constant symbol. In each of the 
foil owing examples, find two elements a and b of the proposed model 
whose types are distinct, or show that this is not possible. 
L1 = {R} 
L2 = {f} 
L3 = {f} 
L4 = {g, c} 
Ls = {g} 
M1 = (JR, <) ;  
M2 = (N, n ʟ n + 1 )  ; 
M3 = (Z, n M n + 1 )  ; 
M4 = (Z, +, 0) ; 
Ms = (Z, ·+) . 
(d) Let T be a theory of L and let F1 , F2, . . .  , Fn be n formulas of Ft (n > 1). 
Suppose that the formula 
G = VvoVvt ( 1\ (F; [ vo] <o> F; [vt l) =? vo :::: Vi) 
l <i<n 
is a consequence of T. 
Show that every model of T has at most 2 n elements. 
(e) Let S be a theory of L that has at least one infinite model. 
Show that there exists a model M = (M, . . .  ) of S such that M contains 
at least two elements that have the same type. 
(Hint for an argument by contradiction: enrich the language with two 
new distinct constant symbols and apply the compactness theorem to an 
appropriate theory in the enriched language, then make use of Exercise 1 9 
and the preceding question.) 
(f) Give an example of a language L and a theory T such that: 
• there exists at least one model of T of cardinality > 2; 
• there is no model ofT that contains two distinct elements of the same 
type. 
(g) Give an example of an infinite model of a finite language L that contains 
no distinct elements of the same type. 

4 The completeness theorems 
The formalization that we have implemented thus far allows us to represent math­
ematical statements, or at least some of them, in the form of sequences of symbols. 
We will now pur sue further in this direction and formalize proofs. There are many 
ways of doing this and, let us admit it from the start, the one we have chosen 
comes with a certain number of inconveniences; in particula1; it does not properly 
reflect the manner in which proofs are conceived in the minds of mathematicians. 
Moreover, it does not lend itself well to the analysis of proofs, a topic that is known 
as proo.ftheory and that we will discuss only briefly in this text. In its favour, our 
method is a bit closer to the way in which proofơ are actually written and, primar­
ily, it requires the introduction of few prerequisites. That is why it appeared to us 
that this approach is the easiest to understand upon first exposure. 
A formal proof (or derivation) is a sequence of formulas in which each is 
just{fied either because it is an axiom or because it can be deduced from for­
mulas that precede it in the sequence. It is quite clear that, provided we do things 
correctly, a formal p1vo.f can lead only to formulas that are universally valid. The 
converse of this assertion, namely that eve1y universally valid formula has a for­
mal p1vof, is what we will call a completeness theorem; indeed, such a result will 
show that the axioms and rules that we have allowed ourselves are sufficiently 
strong, 01ͦ in other words, that they are complete. In Section 4.2 we will present a 
proof of this that uses a method due to Henkin, and from this we will extract an 
important, purely semantic consequence, the compactness theorem. The purpose 
o.{Section 4.3 is to describe Herb rand's method which reduces the satisfiability of 
a formula of predicate calculus to the satisfiability of an infinite set of propositional 
formulas. 
An essential aspect of these notions is their effective character. For example, here 
is a natural question: can we find an algorithm that produces proofơ of theorems? 
We will see late1; in Part 2, Chapter 6, how to think about this question in general 
terms. In Section 4.4, our interest turns to a restricted class of universal formulas 
(the universal clauses) and we will introduce a new type of proof; this is the method 
o.f resolution. This method is better suited to implementation on computers (it is 
the basis for the language PROLOG). We will be content to sketch the required 
algorithms without giving the details of a potential realization. 

194 
T H E  C O M P L E T E N E S S  T H E O R E M S  
In this chapter, we will not speak of equality; thus, we will not assume that 
the equality symbol is part of our language and, when it is, we will not assume 
that the models we construct necessarily re.\JJect equality. However, thanks to 
Theorem 3.97, we can reduce to a model that does respect equality. 
To avoid misunderstandings, the word 'derivation ' will be reserved, throughout 
this chapte1; to mean formal proof The word 'p1vof' by itself will be used to denote 
what is necessary to prove the stated theorems; so we could, to conform with what 
was said in the introduction, call these 'meta-derivations'. 
4.1 Formal proofs (or derivations) 
4.1.1 Axioms and rules 
In mathematics, to prove a theorem is to derive it from propositions given in ad­
vance, called axioms, according to exactly specified rules. It is this notion of proof 
that we will formalize in this section. What the axioms are and what the rules are 
must, therefore, be made absolutely precise. Let us begin with the rules. These are 
rules that allow us to deduce a formula from one or more other formulas. For the 
notion of derivation that will be presented here, there are two deduction rules: 
Definition 4.1 THE DEDUCTION RULES 
• Modus ponens: from the two formulas F and F =} G, modus ponens allows 
us to derive G. 
• The rule of generalization: if F is a formula and v is a variable, the rule of 
generalization allows us to derive VvF f1vm F. 
Despite its Latin name, with which you may not be familiar, the idea behind 
modus ponens is totally banal. 
The rule of generalization is a bit more troubling but its justification is simple: 
if we know, without any particular assumptions about v, how to derive F(v), 
then we know that V v F ( v) is also true. It is used all the time in mathematics. 
Imagine, for example, that you wish to prove that every positive integer is the sum 
of four perfect squares. You would say: let n be a positive integer, and you would 
develop an argument that concluded with: hence, there exist a, b, c, and d such that 
n = a2 +b2 +c2 +d2
, and you would, justifiably, consider the proof to be finished. 
This is nothing but an application of the rule of generalization in which n plays 
the role of the free variable. Exercise 5 will help us to appreciate the usefulness of 
this rule. 
Definition 4.2 THE LOGICAL AXIOMS. These are the following formulas: 
• The tautologies. Recall that the tautologies o.f predicate calculus are obtained 
in the following way: we start with a tautology F of the propositional calculus 
whoseptvpositionalvariablesare, say, At, A2, . . .  , An; we also have nformulas 
Gt, Gz, . . .  , Gn of tire language under consideration. The formula H obtained 

F 0 R M A L P R 0 0 F S (0 R D E R I V A T I 0 N S) 
195 
by replacing in F all occurrences of A 1 by G 1, all occurrences of A2 by 
G2, and so on, is, by definition, a tautology of the predicate calculus (see 
De.finition 3.49). 
• The quantification axioms. These are grouped into three infinite sets (these 
infinite sets are usually called axiom schemes): 
* formulas of the form: 
where F is an arbitrary formula and v is an arbitrary variable; 
* formulas of the form: 
'Vv(F  G)  ( F  => 'VvG) 
(a) 
(b) 
where F and G are arbitrary formulas and v is a variable that has no free 
occurrence in F; 
* formulas of the form: 
'VvF => Ft;v 
(c) 
where F is a formula, t is a term and there is no free occurrence ofv in F 
that lies in the scope of a quantification that binds a variable oft. 
For each of these three axiom schemes, we will show that we are dealing only 
with universally valid formulas and we will also justify the restrictions that we 
have placed on the variables. 
(a) These axioms present no difficulty. Their purpose is to give a syntactical 
definition of the existential quantifier in terms of the universal quantifier (see 
part ( 1 )  of Theorem 3.55. 
(b) This one is not very difficult either (see part (16) of Theorem 3.55). Clearlyा 
the restriction on the variable v is necessary: for example, consider a language 
that has only one unary predicate symbol P and set F == G == Pv. Then 
'Vv(Pv =} Pv) is always true, while this is not the case for Pv =} 'VvPv 
which means that if something satisfies P then everything satisfies P. 
(c) This scheme is the hardest one to understand because the condition that is 
attached to it is not simple and also, perhaps, because a superficial analysis 
might lead one to believe that \:fvF =} Ftfv is always satisfied without the 
need for any restrictions. Let us show that this is an illusion. 
In the language consisting of the single binary relation symbol R, consider the 
formula F = 3vt ͧRvvl and the term t == v l · So that Ftfv = 3vt ͨRv1 VI and 
this formula is false, for example, in a structure whose base set contains more than 
one element and in which R is interpreted by equality. 

196 
T H E  C O M P L E T E N E S S  T H E O R E M S  
We can see what is happening: contrary to what we may have naively expected, 
the formula F1fv does not, in any way, say that the object represented by t possesses 
the property expressed by the formula F; the reason is that the term t, which, here, 
is a variable, finds itself quantified in F1fv· 
Now we will show that all the formulas from scheme (c) are universally valid. 
Let u 1 ,  u2, . . .  , Un be the variables in t and let W J ,  w2, . . .  , Wp be the free variables 
of Vv F other than u 1 ,  u2, . . .  , U n .  We insist: the variables Wi are distinct from the 
u j, but the u j may well occur, either free or bound, in Vv F, and it is possible that 
the variable v is among the Uj. This hypothesis places us precisely in a situation 
where Proposition 3.45 is applicable. 
Let M be a structure for the language of F; we will show that the formula 
VvF :::} Ftfv is true in M. Consider elements a1 Ȗ a2, . . . .  an, bt, b2, . . .  , bp of the 
underlying set M of M such that 
This means, by definition, that for every element a E M, we have 
-M 
When a is taken to be the element t 
[a1 ,  a2, . . .  , an], we may conclude, thanks 
to Proposition 3 .45, that 
which finishes the proof. 
In fact, schema (c) will be used most frequently in situations where no variable 
of t is bound in F (which is obviously a stronger condition than the one imposed 
by schema (c)), and, in particular, when t is a closed term. We will also use it in the 
fourth example of the next section; that example will itself be used several times 
during the proof of the completeness theorem. 
4.1.2 Formal proofs 
We can now give the definition of a derivation (or formal proof). Recall that the 
formulas that constitute a theory are all closed formulas. 
Definition 4.3 Let T be a theory and F be a formula of L; an L-derivation of 
F in T is a .finite sequence of formulas V == (Fo, F1 , . . .  , Fn) of L that ends with 
F and is such that each F; (jor 0 < i < n) satisfies at least one of the following 
conditions: 
• Fi E T; 
• Fi is a logical axiom; 
• Fi is derivable from one or two of the formulas that precede it in the sequence 
V by one of the two deduction rules. 

F 0 R M A L P R 0 0 F S (0 R D E R I V A T I 0 N S) 
197 
If there exists a L-derivation of F in T, we say that F is L-derivable in T or 
that F is an L-syntactic consequence of T or that F is an L-theorem ofT and 
we write T L F. In the case where T is empty, we say that F is L-derivable and 
we write L F. 
Remark 4.4 Foraformula F and a theoty T in a  language L, it could happen, at 
least a priori, that F is notderivablefrom T in L but that it is derivable from T {{we 
allow a richer language. The completeness theorem will show, howeve1͠ that this is 
not the case. Once this theorem is proved, we will simply say 'derivable' rather than 
'L-derivable' and 'syntactic consequence' instead of 'L-syntactic consequence'. 
In the meantime, if we do not specİfically mention the language L, you should 
consider that the language is fixed and is sufficiently rich that it contains all the 
formulas and theories determined by the context. 
Example 4.5 Suppose that F and G are two closed formulas and set T = { F, G}; 
we are going to prove that T Ș F 1\ G. Here is a sequence of formulas that 
constitutes a derivation of F 1\ G in T: 
(1) 
F 
(2) 
G 
(3) 
F =} (G =} (F 1\ G)) 
(4) 
G =} (F 1\ G) 
(5) 
F 1\ G 
( FisinT) 
(Gis inT) 
(a tautology) 
(by modus ponens from (1) and (3)) 
(by modus ponens from (2) and (4)). 
Example 4.6 Let F be a formula and t be a term and suppose that no free 
occurrence of v in F is within the scope of a quantification that binds a variable 
of t. We will show (Table 4.1 )  that 1- Frtv =} 3vF. 
Table 4.1 
(1 ) Vv-.F => -.Ft;v 
(2) (Vv-.F => -.Ft;v) => (Ft;v => -.\fv-.F) 
(3) Ft;v => -.\fv-.F 
(4) 3vF ¢> -.\fv-.F 
(5) (Ft;v => -.\fv-.F) 
=> ((3vF <=? -.\fv-.F) => (F1;v => 3vF)) 
(6) (3vF <=? -.\fv-.F) => ( F1;v => 3vF) 
(7) Ft;v => 3vF 
quantifier axiom of type (c) 
tautology obtained from 
(A => -.B) => (B => -.A) 
by modus ponens from (1) and (2) 
quantifier axiom of type (a) 
tautology obtained from 
(A => B) -=> ((C <=> B) => (A => C)) 
by modus ponens from (3) and (5) 
by modus ponens from (4) and (6) 
Example 4.7 If w is a variable that has no occurrence in F (neither free nor 
bound), then l- Vw Fw;v ::} Vv F: 

1 98 
T H E  C O M P L E T E N E S S  T H E O R E M S  
The justification for step ( 1 )  in the derivation that follows involves a somewhat 
acrobatic use of schema (c): in the formula Fw;v, the only free occurrences of w 
are those that replaced the free occurrences of v in F and, quite obviously, these 
do not lie within the scope of a quantifier that binds v (otherwise, they would not 
be free!). So formula (1) in Table 4.2 does belong to axiom schema (c). 
Table 4.2 
(I) 
(I') 
(2) 
(3) 
(4) 
VwFwjv => (Fw;v)vjw 
VwFwft• => F 
Vv(VwFw;v ==> F) 
Vv(VwFwjv => F) 
=> (VwF wfv => VvF) 
VwFw;v => VvF 
quantifier axiom of type (c) 
since w does not occur in F 
(F w/t•)vfw = F so (I') is a rewriting of (I ) 
from ( J ') by generalization 
quantifier axiom of type (b) 
since v is not free in VwFw;v 
by modus ponens from (2) and (3) 
Example 4.8 Let us prove that 1- VvF :=> F. 
Again, this is a use of axiom schema (c). Indeed, F 
r8;v, and it is certain 
that the free occurrences of v in F do not lie in the scope of a quantification 
that binds v. 
Example 4.9 Finally, let us prove (Table 4.3) 1- Vvo'VVI F :=> 'Vv1 VvoF. 
Table 4.3 
(1) Vv0 Vv1 F => Vv1 F 
(2) 
Vv1 F => F 
(3) 
(VvoVv1 F => Vv, F) 
=> ((Vv1 F => F) => (VvoVv1 F => F)) 
(4) 
VvoVv1 F => F 
(5) 
Vvo(VvoVVI F => F) 
(6) 
Vvo(Vvo Vv1 F => F) => (Vvo Vv, F => Vvo F) 
(7) 
Vvo Vv1 F => VvoF 
(8) 
Vv1(VvoVv,F ==> VvoF) 
(9) 
(Vv1 (Vvo Vv 1 F ==> VvoF)) 
=> (VvoVv1F => Vv, VvoF) 
(I 0) 
VvoVv, F => Vv1VvoF 
Example 4.8 
Example 4.8 
a tautology 
from ( 1), (2) and (3) 
by modus ponens. twice 
from (4) by generalization 
axiom schema (b) 
from (5) and (6) by modus ponens 
from (7) by generalization 
axiom schema (b) 
from (8) and (9) by modus ponens 

F 0 R M A L P R 0 0 F S (0 R D E R I V A T I 0 N S) 
199 
Remark 4.10 Suppose that F =} G is a tautology. Then Vv F =} VvG is a 
theorem. 
VvF =} F 
F =} G  
(VvF => F) => ((F => G) => (VvF => G)) 
VvF => G 
Vv(VvF =} G) 
Vv(VvF =} G) =>  (VvF => VvG) 
VvF =} VvG 
Example 4.8 
a tautology, by hypothesis 
a tautology 
by modus ponens, twice 
by generalization 
axiom schema (b) 
by modus ponens 
Remark 4.1 1  Suppose that F is a closed formula, that T Ș F and that T U { F} I­
G,4 then T 1- G. 
To see this, note that if (Fo, F1 , . . .  , Fn) is a derivation of F in T (so Fn = F) 
and (Go, G t ,  . . .  , Gm) is a derivation of G in T U {F} (so Gm = G), then 
(Fo, F1, . . .  , Fn , Go, G l ,  . . .  , Gm) is a derivation of G in T. 
Definition 4.12 A theory T is called non-contradictory in L if there is no formula 
F such that we have both T Ș L F and T Ș L --,F simultaneously. If this does 
happen, T is called contradictory in L. 
Remark 4.13 If T is contradictory, then every formula is derivable in T. 
Indeed, suppose that both T 8 F and T a 
... ., F and let G be an arbitrary formula. 
Begin a sequence by placing the derivations of F and ···1F end-to-end. To produce a 
derivation of G from this, it suffices to add to the sequence the following formulas 
from Table 4.4. 
Table 4.4 
F -> (-.F => G) 
-.F => G 
G 
a tautology 
by modus ponens, since F 
occurs earlier in the sequence 
again by modus ponens, since -.F 
occurs earlier in the sequence. 
The converse ('if every formula is derivable in T, then T is contradictory') is 
obvious from the definition. Moreover, we may immediately verify that: 
Remark 4.14 
• ͡fT is contradicto1y, thenfor every formula F, T r- F 1\ -,F; 
• for T to be contradictory. it is necessary and sufficient that there exist one 
formula F such that T a F 1\ -,F. 

200 
T H E  C O M P L E T E N E S S  T H E O R E M S  
4.1.3 The finiteness theorem and the deduction theorem 
The next simple but extremely important theorem is known as the finiteness 
theorem. 
Theorem 4.15 For any theory T and any formula F, if T a F, then there is a 
finite subset To ofT such that To ĭ F. 
Proof Let V be a derivation of F in T; it is a finite sequence of formulas. Only 
a finite number of formulas of T can appear in it. If To is the finite subset of T 
consisting of these formulas, then V is also a derivation of F in To. 
• 
Corollary 4.16 JfT is a theory all of whose .finite subsets are non-contradictory, 
then T is non-contradictory. 
Proof If not, then from T we can derive F 1\ -िF (here, F is an arbitrary formula) 
and we conclude from the finiteness theorem that F 1\ __,F is derivable from some 
finite subset To of T; so To is contradictory (by Remark 4.13) and this violates our 
hypothesis. 
• 
Let us be more precise: 
Proposition 4.17 Let I be an ordered set and for every i E /, let T; be a theory 
in a language L; which is not contradictory in L;. Suppose that if i is less than j, 
then L; C Lj and 1j C 1). Set T = UiEI T; and L = UiE/ L;. Then the theory 
T is not contradictory in L. 
Proof The proof is almost the same as the proof of Corollary 4. 16: an L-derivation 
D of a formula F in T is in fact an L;-derivation in T; for some i E I provided 
that L; and 1j contains all the formula in D. Such an index i exists. thanks to our 
hypothesis. 
• 
It is more or less obvious that if the formula F =? G is derivable in T, then the 
formula G is derivable in T U {F} (by modus ponens). The converse of this is a 
very useful tool and is known as the deduction theorem. 
Theorem 4.18 Assume that F is a closedformula and that T U {F} ĭ G. Then 
T t- F =} G. 
Proof Let V = (Go, G 1 ,  . . .  , Gn ) be a derivation of G in T U { F}. We will 
construct a derivation V' of F =} G in T by inserting various formulas into the 
sequence (F =} Go, F =} G 1 ,  . . .  , F =} Gn). 
• If G; is a tautology, there is no problem since F :::} G; is then also a tautology. 
• If G; is a quantification axiom or is an clement of T, we need to insert the two 
formulas G; and G; =} (F =} G;) (which is a tautology) between F ==> G; - I 
and F =} G; (or, more simply, in front of F =} G; in case i = 0); F =} G; is 
then derivable from these two preceding formulas by modus ponens. 
• Jf G; = F, there is no problem since F =? F is a tautology. 

F 0 R M A L P R 0 0 F S (0 R D E R I V A T I 0 N S) 
201 
• Now suppose that Gi is obtained by modus ponens, which is to say that there 
exist integers j and k, strictly less than i, such that G k is the formula G j => G i .  
We then insert the following formulas between F => Gi-t and F => Gi: 
( F  => G j) => ((F => (G j => G; )) => ( F => G i)) 
(this is a tautology) 
(F => (G j => Gi)) => (F => Gi) 
(this is derived by modus ponens 
from the previous formula together with F => G j which appears earlier in 
the sequence) 
F => Gi 
(this follows by modus ponens from the previous formula 
together with F => ( G .i => G i) which is equal to F => G k and has 
the ref ore also appeared earlier). 
• Suppose G; is derived by generalization from G.i with j < i (thus, G; is 
VvG.; ). Then the following formulas should be inserted between F => Gi-1 
and F => G;: 
Vv(F => G i) 
(obtained by generalization from F ::::> G j) 
Vv(F => Gj) => (F => VvG j) 
(this is quantification axiom because, 
since F is closed, v is certainly not free in F) 
F => G; 
(this follows by modus ponens from the two preceding 
formulas). 
• 
The next corollary justifies the general use of proofs by contradiction. 
Corollary 4.19 T ո F if and only ifT U { ...,F} is contradictory. 
Proof It is clear that if T a F, then T U { ...,F} is contradictory. Conversely, if 
T U { -, F} is contradictory, any formula is derivable from it, and, in particular, 
F; by applying the deduction theoremी we then see that T r- -,F => F. Now, 
(-. F => F) => F is a tautology, so we may conclude that T I- F. 
• 
The least of the demands that we might make on derivations is that they should 
lead to formulas that are true (more precisely, a derivation from a theory should 
lead to formulas that are semantic consequences of the theory). That is what we 
will now prove. 
Theorem 4.20 Let T be a theoty, F a formula and F' a universal closure of F. 
Then 
( ] )  If T ͒ F, then every model ofT is a model of F' (in other words, T r-* F). 
and 
(2) If'. F, then F' is universally valid. 
(Recall that the universal closures of a formula are obtained by universally quan­
tifying all the free variables in the formula; it may have several universal closures 
because there is a choice in the order of the quantifications: see Definition 3 .20). 

202 
T H E  C O M P L E T E N E S S  T H E O R E M S  
Proof Since (2) is a special case of ( 1) (take T = 0), it suffices to prove ( 1 ). 
We have already observed that all the axioms are universally valid; their universal 
closures are therefore true in every model of T. We will now prove the following 
property by induction on n: 
I 
Let ( Fa ,  F1 , . . .  , Fn ) be a derivation of Fु in T and let Fn be 
a universal closure of Fn ; then T f-* Fx. 
• Case n = 0: then the formula Fo is either an axiom or else is an element of T. 
In both instances, Fƀ is true i n  every model of T. 
• For the passage from n to n + 1, we distinguish several subcases: 
* if Fn+ 1  is an axiom or an element of T, then, as in the previous case, every 
• 
I 
model of T IS a model of Fn+ 1 . 
* if Fn+ 1 is obtained by modus ponens, there exist integers i and j less than 
or equal to n such that F; is Fj  Fn+ 1 ·  Suppose that the free variables of 
Fi are vo, v 1 ,  . . .  , v P (and so the free variables of Fj and of Fn+ 1 are among 
these); F j and Fj => fू+1 have derivations whose length is at most n. So 
by the induction hypothesis, if M is a model of T, then 
and 
hence, 
I 
Because the formulas 'v'vo'lv1 . . .  'v'vp Fn+ l and F11+1 are universally equiva-
1 
lent, we may now conclude that M F= Fn+ 1 . 
* if Fn+ 1  is obtained by generalization, there exists an integer i < n and a 
I 
variable v such that Fn+ 1 = 'v' v F; . Fn+ 1 is then a universal closure of F; and 
the conclusion now follows from the induction hypothesis. 
• 
Corollary 4.21 If T has a model, then T is non-contradictory. 
Proof If T were contradictory, then F 1\ -,p would be derivable from it, yet this 
formula has no model. 
• 
4.2 Henkin models 
We will now prove the converse of the corollary that concluded the previous section: 
if T is non-contradictory, then T has a model. The proof must necessarily proceed 
by constructing a model and, for this reason, is certainly much more difficult. We 
will need a certain number of preliminary definitions and )em mas. 

H E N K I N  M O D E L S  
203 
4.2.1 
Henkin witnesses 
Definition 4.22 Let T be a theory in a language L. We say that T is syntactically 
complete (in L) if it is not contradicrory in L and if, for every closed formula F 
of L, we have T ƟL F or T  ƟL _,F. 
It is worth noting that the syntactical completeness ofT depends on the language 
in which it is viewed; in principle, if we do not specify the language, it will be 
because the context already makes it clear. 
It will follow from the completeness theorem ( 4.29) and from Theorem 4.20 that 
a theory is syntactically complete if and only it is complete (see Definition 3.80). 
There will be no need, from that point on, to distinguish between these two notions. 
The next item is the one that will allow us to construct models: 
Definition 4.23 Let T be a theory in a language L. We say that T possesses 
Henkin witnesses if for every formula F[ v] wirh a single free variable v, there is 
a constant symbol c in L such that the formula 
3vF[v] =} F[c] 
belongs to T. 
The proof of the completeness theorem splits into two parts: first we show that 
a syntactically complete theory which possesses Henkin witnesses has a model; 
then we show that any non-contradictory theory can be enriched to a syntactically 
complete theory that possesses Henkin witnesses. 
Proposition 4.24. (A) ff T is a syntactically complete theory in a language L 
that possesses Henkin witnesses, then T has a model. 
Proof Starting from a theory T that satisfies the hypotheses of the theorem, we 
will construct a model of T from virtually nothing. 
Let T be the set of closed terms of L. Since the theory has Henkin witnesses, 
the language contains constant symbols and the set T is non-empty. Here is the 
L-structure M that will turn out to be a model of T: 
• The underlying set of M is the set T. 
• If c is a constant symbol, its interpretation in M is c. 
• If R is an n-ary relation symbol, the interpretation RM of R is defined by: for 
all lt , t2, . . .  , tn in T, 
(lt , 12, .
. . , In) E RM if and only if T 1- Rtt t2 . . .  ln. 
• If f is an n-ary function symbol, the interpretation fM of f in M has to be a 
map from yn into T: for lt, t2, . . .  , ln in T, let fM (tt , t2, . . .  , tn) be the term 
f ft t2 · · · ln. 
With this definition, we see that for any closed atomic formula F, we have T ͢ F 
if and only if M I= F. We will now prove that this equivalence continues to hold 

204 
T H E  C O M P L E T E N E S S  T H E O R E M S  
for all closed formulas of L .  The proof is by induction on F. Since the case for 
atomic formulas has been treated, we may assume that the formula F has one of 
the following forms: 
(1) 
F == -.G; 
(2) 
F == G 1\ H; 
(3) 
F == G v H; 
(4) 
F == G =} H; 
(5) 
F == G <=> H; 
(6) 
F == VvG; 
(7) 
F == 3vG. 
We will only treat cases (1), (3), (6), and (7), leaving the others to the reader. 
( 1) By the induction hypothesis, we know that T 1- G if and only if M F= G. 
Now M t= F if and only ifit is false that M F= G. Because T is a syntactically 
complete theory, T  F if and only if it is false that T 1- G; hence the result. 
(3) Suppose first that M t= F; then M F= G or M F= H; if, for example, 
M շ G, then, by the induction hypothesis, T 1- G; but the formula G =} G v H 
is a tautology, and so T 1- F. 
In the other direction, suppose T 1- G v H. lf T 1- G, then, by the induction 
hypothesis, M F= G, so M f= F. If not, then, again because T is syntac­
tically complete, T 1- -.G; and since G v H =} (-,G =} H) is a tautol­
ogy, it follows that T 1- H. So by the induction hypothesis, M F= H, and so 
M f= F. 
(6) If T 1- VvG and if t E T, then because the formula VvG :::} Grfv is an 
axiom (t is a closed term), we see that T 1- G1 /v and, by the induction hypothesis, 
M f= G 1 fv. Now, since every element of M is the interpretation of a closed term, 
it follows that J\1 F= VvG . 
Now suppose that V v G is not derivable in T. Invoking Remark 4.1 0  (noting that 
-.-.G  G is a tautology), we see that the formula Vv-.-.G is not derivable in 
T either, and since T is syntactically complete, T 1- -.vv-,-.G. But the formula 
3v-.G ¢} -.vv-,-.G is an instance of axiom scheme (a); this allows us to conclude 
T 1- 3v-,G thanks to modus ponens and some tautologies. Because T has Henkin 
witnesses, there is a constant symbol c such that T f- -.G cfv (v is the only free 
variable of G since F is closed). As T is non-contradictory, G cfv is not derivable 
in T; by the induction hypothesis, M F= -,Gcfv so VvG is false in M. 
(7) If M F= 3vG, this must be because there is an element oft E T such that 
M F= G11v so, by the induction hypothesis, T 1- G1 fv· It is easy to find a derivation 
of 3vG from G1 fv (see Example 4.6) and hence T 1- 3vG. 
Conversely, suppose that T 1- 3vG thanks to the flenkin witnesses, it follows 
that there exists a constant symbol c of T such that T 1- G cfv so by the induction 
hypothesis, M F= Gcfv; hence M F= 3vG. 
This completes the proof of Proposition A. 
• 

H E N K I N  M O D E L S  
205 
4.2.2 The completeness theorem 
We will now see how to obtain, from a non-contradictory theory. a theory that 
satisfies the conditions of Proposition A. 
Proposition 4.25. (B) Let T be a non-contradictory theory in a language L; then 
there exists a language L' that includes L and a theory T' that includes T, that is 
syntactically complete and possesses Henkin witnesses in L'. 
Here, since we are working with several languages, we have to be careful. We 
will need the following two lemmas. 
Lemma 4.26 Let S be a theory in a language L and let F be a formula in L with 
at most one free variable v and let c be a constant symbol that does belongs to L; 
if S ś-LU{c} Fcjv, then S 1-L VvF. 
Proof Let (Ht , H2, . . .  , Hn) be an (L U {c})-derivation of Fcfv in S (thus H11 = 
Fcfv). Choose a variable w that does not occur in any of the formulas Hi 
( 1 < i < n) and let K; denote the formula obtained from H; by substituting w 
for c. A straightforward examination of the rules and axioms shows that: 
• if H; is a logical axiom, then so is Ki ; 
• if Hi is derived either by generalization or by modus ponens from one or 
two preceding formulas, then K; is derived in exactly the same way from the 
corresponding formulas; 
• furthermore, if Hi belongs to S9 then Ki = Hi so K; belongs to S. 
It follows from all this that (K 1 ,  K2, . . .  , Kn) is an L-derivation in S of Fwfv· 
By generalization, we now obtain S 1-L VwFwfv and, thanks to the quantification 
axioms, S 1-L VvF (see Example 4.7). 
• 
Lemma 4.27 Let T be a theory in some language L, and assume that T is not 
L-contradictory. Let L' be the language obtained/rom L by adding a .finite set C 
of constant symbols. Then T is not L' -contradictory. 
If C contains just one new constantृ then it is an immediate corollary of the 
preceding lemma (with F a  closed formula of L). In the general case, we just have 
to apply this several times. 
• 
Following the same pattern as for the compactness theorem of propositional 
calculus (Theorem 1.39) we are going to give two proofs (in fact, two versions of 
the same proof) of Proposition B. In the second, we will appeal to the axiom of 
choice; in the first, which is easier to understand, we will add as a supplementary 
hypothesis that the set of symbols of L is finite or countable. We will see later 
(in Chapter 7 of Part 2) that under these conditions, we can find an enumeration 
( Fa. Ft , . . . , Fn , . . . ) of all the formulas of L. 
First proof We add to L a  countably infinite set C = {co, ct . . . .  , Cn, . . .  } of new 
constant symbols (this means that none of the c; already belong to L ). Denote the 

206 
T H E  C O M P L E T E N E S S  T H E O R E M S  
resulting language by L'. The language L' is also countable and we can find an 
enumeration (Fo, Ft , . . .  , Fn, . . .  ) of all the closed formulas of L. 
By induction on n, we will define a language Ln and a theory Tn, starting with 
Lo = L and To = T, in such a way that the following conditions are satisfied: 
• Tn is not Ln contradictory; 
• Ln C Ln+I and Tn C Tn+ I; 
• Ln - L is finite; 
• Fn E 7ҝ+1 or -,Fn E Tn+l ;  
• if Fn is of the form 3 v H and belongs to 1;'l+ 1, then there exists a constant symbol 
c such that Hcjv E Tn+ 1· 
Here is the procedure for constructing Ln+I and Tn+l from Ln and Tn: it operates 
on Fn which is the (n + l)st formula in the enumeration that we fixed at the 
beginning of the proof. Let L be the language obtained from Ln by adding the 
constants of C that occur in Fn· We see from Lemma 4.27 and by the induction 
hypothesis that Tn is not contradictory in L. If Tn U { Fn } is not contradictory in 
L>, then set G n = Fn; if it is contradictory in L, the reason is because Tn f-Lն 
-,Fn, and we then set Gn = -,Fn· In both cases, the theory T U {Gn} is not 
contradictory in L>. 
If Gn is not of the form 3vH, we stop here and set Ln+I = L and Tn+l = 
Tn U {Gn}· 
If G n is of the form 3vH, we choose a symbol c E C which is not in L; this is 
possible because L> - L is finite. We then set 
Ln+l = Lſ U {c} 
and 
The last four conditions required of Tn+ 1 are clearly satisfied. It remains to prove 
that the theory 7;1+ 1 is not contradictory in L n+ 1 ; we show that the opposite cannot 
hold: suppose that 7ҝ+1 is contradictory in Ln+I· From Corollary 4.1 9, we see that 
From Lemma 4.26 and by our choice of the constant c, we deduce that 
which is not possible since Tn U ( G n} is not contradictory in L11• 
We have thus completed the construction of the theories Tn; now set 
L' = U Ln 
nEN 

H E N K I N  M O D E L S  
207 
and 
T' == U Tn . 
nEN 
The fact that T' is not contradictory in L' follows from Corollary 4.1 7. To show 
that T' is syntactically complete, suppose that F is a closed formula of L'; then 
there exists an integer n such that F == Fn and, by construction, F E Tn+ 1 or 
-,J'i E Tn+ l · Also, T' has Henkin witnesses: let H be a formula of L' with one 
free variable v; again, there exists an integer n such that Fn == 3vH and, either 
-,£n E Tn+l or there exists a symbol c such that Hcjv E Tn+l · In both casesқ 
Tn-t- 1 յL' 3vH :::} Hcjv, which proves that 3vH :::} Hcjv E T' (otherwise T' 
would contain -,(3vH :::} Hcjv) and would be contradictory). 
• 
Second proof This time we will use Zorn's lemma. We begin by adding Henkin 
constants to the language. According to Lemma 4.26, if a theory T in a language L 
is not L-contradictory, if F is a formula of L whose only free variable is v and if c is 
a constant symbol that does not belong to L then the theory T U { 3 v F [ v] :::} F [ c J} 
is not contradictory in (L U {c} ). Let us introduce a new constant symbol cp for 
each formula F of L that has one free variable and let L I be the language thus 
obtained. Let n be an integer and for every integer p between 1 and n, let Fp be 
a formula with one free variable w p; then by applying Lemma 4.26 n times, we 
conclude that the theory 
T U {3wpFp [Wp] :::} Fp[cpP] : 1 < p < n} 
is not contradictory in (L U {cpP : I < p < n}). It then follows from Propo­
sition 4.17 that the theory 
T1 == T U {3vF[v] :::} F[c F] : F is a formula of L with one free variable v }  
i s  not contradictory in L I · 
One must not jump to the conclusion that Tt has Henkin witnesses: it has them, 
but only for formulas of L, and this is insufficient since the language L I is richer. 
But it will pay us to be stubborn and to repeat the process: let us, for each new 
formula F of L 1 with one free variable, add a new constant symbol c F ;  let L2 be 
the resulting language and set 
T2 = r, u 
{3vF[ v] :::} F[c F] : F is a formula of L 1  (not of L) with one free variable v }. 
T2 is non-contradictory in L2 and we define, using the same pattern, L3 and 
T3, and so on. All the theories Tn obtained this way are non-contradictory and, 
since they extend one another, we see, using Proposition 4. 17, that T' == UnEN Tn 
is not contradictory in L', where L' == UnEN Ln and, this time, has Henkin wit­
nesses: for if F is a formula of L' with only one free variable v, then there is an 
integer n such that F is in Ln. Consequently, 3vF[v] :::} F[cp] belongs to Tn+l 
and hence to T'. 

208 
T H E  C O M P L E T E N E S S  T H E O R E M S  
It remains to find, while remaining in L', a theory T" that includes T', that is 
non-contradictory and that is syntactically complete in L'. It is clear that T" will 
still have Henkin witnesses since we are no longer changing the language. The 
lemma that follows provides the required conclusion. 
Lemma 4.28 Let T' be a non-contradictory theory in a language L'. Then there 
exists a theory T" in L' which is non-contradictory, syntactically complete, and 
includes T'. 
Proof It is here that we will invoke Zorn's lemma. Consider the set 
r = {S : S is a non-contradictory theory in L' that includes T'}. 
r is not empty since it contains T I .  Moreover, let 
S = {S; : i E /} 
be a subset of r that is totally ordered by inclusion, meaning that if i and j are 
elements of I, then either S; c Sj or s1 c S; . Then the theory 
is still non-contradictory (Proposition 4.17) so is an upper bound for S in r. Thus 
Zorn's lemma (see Part 2, Chapter 7) applies and we can find an element T" in r 
that is maximal for inclusion. We will now show that T" is syntactically complete. 
Let F be a closed formula of L' and suppose that F ¢:. T". This implies that 
T U { F} strictly includes T", so by the maximality of T", it is contradictory. Using 
Corollary 4.19, we conclude that T" ś-- -,p. 
• 
This concludes the second proof of proposition B. 
• 
We will finish this section with the completeness theorem. 
Theorem 4.29 ( Godel, 1 930) Evety non-contradictory theory has a model. 
Proof Using Proposition B, we produce a language L' extending L and a theory 
T' in L' that includes T, that is non-contradictory, syntactically complete and 
possesses Henkin witnesses; using Proposition A, we find a model M' of T'. The 
reduct of M' to L is then a model of T. 
• 
The following is an alternate way of stating the completeness theorem: 
Proposition 4.30 IfT is a theory and F is a closed formula that is true in every 
model ofT, then T l- F. 
Proof If F is not derivable in T, then T U { _,p} is non-contradictory 
(Corollary 4.19) so it has a model. 
In particular, we see that the universally valid formulas are precisely those that 
are derivable from the empty theory. 
• 
Remark 4.31 We are finally convinced, thanks to the completeness theorem, that 
the twtions of semantic consequence and syntactic consequence coincide. So from 

H E R B R A N D' S M E T H 0 D 
209 
now on, it is no longer indispensable to distinguish them. In particulat; beyond 
this chapter, we will identİfy the two symbols 1-* and 1- that were reserved until 
now for these two notions, respectively, and will only use the second. 
Let us conclude with a harmonious marriage, that of the finiteness theorem 
(Theorem 4.15) and the completeness theorem (Theorem 4.29); the offspring has 
been expected since Chapter 3; it is the compactness theorem for predicate 
calculus: 
Theorem 4.32 If every finite subset of a theory T has a model, then T itse?f has 
a model. 
Proof Every finite subset of T is non-contradictory, and hence (by the finiteness 
theorem) T is non-contradictory. The completeness theorem then tells us that T 
has a model. 
• 
4.3 Herbrand's method 
4.3.1 Some examples 
In this section we will give another proof of the completeness theorem, essentially 
for the opportunity it offers us of explaining Herbrand's method. So forget that we 
have already proved the completeness theorem. Despite the fact that Herbrand's 
method applies to all formulas, we will be content here to restrict our attention to 
prenex formulas. The reader who is upset by this restriction can reduce the general 
case to this one by proving that every formula F is syntactically equivalent to a 
formula in prenex form (caution: this is not the same as Theorem 3.60; here, this 
means that there exists a formal proof of F <:> G, where G is a prenex form of F). 
We will develop an argument that is similar in style to those familiar to high 
school students; it begins with: 'suppose the problem has been solved'. We are 
trying to determine whether a formula F has a model. So we suppose that we 
indeed have a model at our disposal and we observe that in it, there have to be 
some elements that satisfy certain quantifier-free formulas. We gather, in this way, 
a certain amount of information and after a while, we notice either that all this 
information is contradictory or else that we actually have enough to construct a 
model. Before presenting the general case, here are two examples. 
Example 4.33 The language consists of a single ternary predicate, P . We seek 
to determine whether the following formula F, 
has a model. 
Vvo3vt 3V2 
((-,Pvovt v2 <=> Pvo v2 v 1 )  !\ (..,Pvovt v2 ¢} Pv2v1 vo) 
!\ ( -, p Vo VI V2 ¢> p V I Vo V2)), 

210 
T H E  C O M P L E T E N E S S  T H E O R E M S  
Any eventual model cannot be empty, so assume a is one of its elements. The 
formula tells us that there must exist two points, call them ao and a 1, such that 
(-.Paaoal ¢> Paa1ao) 
A (-,Paaoal <=> Pa1aoa) 
A (-.Paaoal ¢> Paoaa1) 
is true in the model. Next in turn, for ao, we require the existence of two other 
points; obviously, it may happen that one of these points is equal to a or to ao or 
to a1 ; but in the absence of any other information, we will give these points new 
names (in any case, nothing prevents us from giving several names to the same 
point). So there are two points aoo and ao 1 such that 
(-,Paoaooaoi <=> Paoao1aoo) 
A ( -.Paoaooaol <=> Pao1aooao) 
A (--, P aoaooao1 <=> P aooaoao 1) 
is true in the model. Repeating this for a 1, we find two points a 10 and a 11 such that 
(-.Pa1a1oa1 1  ¢> Pa1a1 1a1o) 
A (-.Pal a1oa1 1 ¢> Pa1 1a1 oai ) 
A ( 
_, P a 1 a 1 oa 1 1 ¢> P a 1 oa 1 a 1 1 ) 
is also true in the model. Then we have to start all over for the points aoo, ao1, 
a1o, and a1 1 and after that, repeat the process for the eight new points, etc. Let S 
denote the set of finite sequences of Os and 1 s. Continuing in this way then, we 
define, for each s E S, a point as in such a way that for every s E S, 
( -, P asasoas 1 ¢> Pas as 1 a so) 
A (-.Pasasoa.d ¢> Pasiasoas) 
A (..,Pasasoasl ¢> Pasoasa . ..,-1) 
is true. This information now guides us toward the actual construction of a model 
of F: for every s E S, we choose a point c.৪ in such a way that if s =f. t, then 
Cs # c1 (we could, quite simply, take Cs = s ) . The underlying set of our model M 
will be 
M = { cs : s is a finite sequence of Os and 1 s}. 
It remains to define the interpretation of P and it suffices to do this in such a 
way that for every s E S, 
(..,PcsCsoCsl ¢> PcsCsi Cso) 
A (..,PCsCsoCsJ ¢> PcslCsOCs) 
A (..,PcsCsOCsl ¢> PcsoCsCsl) 

H E R B R A N D' S M E T H 0 D 
2 1 1  
is true. At this point, we are reduced to a problem of the propositional calculus: 
indeed, let us introduce, for each triple (s, t, u) of elements of S, a propositional 
variable As ,t .u. We seek an assignment of truth values 8 that makes all of the 
following formulas true: 
--.As,sO,sl ¢> As,sl ,sO 
for S E S 
--.As,sO,sl ¢> Asl,sO,s 
for s E S 
--.As,sO,s 1 ¢> Aso,s,s 1 
for s E S. 
If we find one, it will suffice to define the interpretation PM of P by 
for all s, t, u in S, (cs, cr, Cu) E PM if and only if 8(As.t,u) = 1. 
If, on the contrary, there is no such assignment, we will then know that F does not 
have a model. 
For the case at hand, such an assignment s is very easy to find: for example, we 
may take 8(As,t.,u) = 1 for all triplets of the form (s, sO, s 1 )  and 8(As,t,u) = 0 for 
all the others. 
We have thus found a model of F. 
Example 4.34 The language contains one ternary predicate symbol P and one 
constant symbol c. Consider the following four formulas: 
F1 : VvoVvtVv2Vv3Vv4Vvs((Pvov1v3 1\ Pv1v2v4 1\ Pv3V2Vs) =? Pvov4vs) 
F2 : VvoVv1Vv2Vv3Vv4Vvs((Pvov1v3 1\ Pv1v2v4 1\ Pvov4vs) =? Pv3V2vs) 
f3 : VvoPvocvo 
£4 : Vvo3vl Pvov1c. 
We wish to prove that these four formulas imply VvoPcvovo. So we add the 
negation of this formula (or rather a formula that is equivalent to this negation), 
Fs : 3vo--.Pcvovo, 
and we attempt to construct a model of the formulas F1 , 
.
•
•
 , F 5 by the same 
method as in the previous example. The failure of this attempt will give us a proof 
of the fact that the set { F, , . . .  , Fs} is contradictory and hence that VvoPcvovo 
follows from F1, . . .  , F4. 
So suppose that M is a model of F1, . . .  , Fs. The satisfaction of the formula Fs 
requires the existence of a point d in M such that 
(1) M F= -·Pcdd; 
then F4 commits us to the existence, for i E N, of points c; and d; in M starting 
with co = c and do = d, such that 
(2) M t= Pc;Ci+l c for all i E N; 
(3) M F= Pd;d;+IC for all i E N. 
Set A = {c; : i E N} U {d; : i E N). The interpretation of P in M must satisfy 
conditions (1), (2), and (3) as well as the following conditions (4), (5), and (6) 

212 
T H E  C O M P L E T E N E S S  T H E O R E M S  
imposed by formulas F, , F2, and F3: 
(4) M F= (Pxyu 1\ Pyzv 1\ Puzw) ==} Pxvw 
for all elements x, y, z, u, v, w of A; 
(5) M F= (Pxyu 1\ Pyzv 1\ Pxvw) ==;> Puzw 
for all elements x, y, z, u, v, w of A; 
(6) 
M F= Pxcx for all x E A. 
So we are once again reduced to the question of the satisfiability of a set of 
propositional formulas (whose propositional variables are the Pxyz for x, y, z 
in A). We will show that it is not satisfiable. 
To see this, observe that when we take ( 4) with x == c and v == w = d, we obtain 
implications whose conclusion is Pcdd, which is false according to (1). Hence, 
we must have 
(7) -.(Pcyu 1\ Pyzd 1\ Puzd) for all elements y, z, u of A; 
and so, by taking u = y = c, 
(8) -.(Pccc 1\ Pczd 1\ Pczd) for all z in A. 
We know from (6) that Pccc must be true, and so, taking z = d2, 
(9) -.Pcd2d. 
Condition (5) with w == x == d, y = d1 , z = d2 and u = v == c yields 
(10) (Pdd, c 1\ Pd1 d2c 1\ Pdcd) ==} Pcd2d. 
Now Pddrc and Pd1d2c are true according to (3) and Pdcd is true according to 
(6) but Pcd2d is false according to (9): so our set is contradictory. Thus 'VvoPcvovo 
does follow from F1 , . . .  , F4. 
Remark 4.35 We will better understand this proof İf we think of P as the graph 
(ͣf a bina1y operation. Then F1 and f2 express the fact that this operation is 
associative, F3 that it has a right identity, and F 4 that eve1y element has a right 
inverse. The conclusion asserts that the right identity is also a left identity. This is 
a fact that can be proved rather easily; we are slightly surprised here to learn that 
we can do without the hypothesis that P is the graph of a binary operation. 
4.3.2 The avatars of a formula 
. 
We will now approach things in full generality. We will also do things better since, 
in situations where the attempt to construct a model of F fails, what we will obtain 
is a derivation of -, F. First of all, here are a few definitions. 
Definition 4.36 
( 1  °) A formula F is said to be propositionally satisfiable (f -ऺF is not a 
tautology. 
(2°) A finite set E of formulas is said to be propositionally satisfiable if 
the conjunction of the formulas in E is pro positionally satisfiable. 

H E R B R A N D' S M E T H 0 D 
213 
(3°) A set of formulas is propositionally satisfiable if all of its finite 
subsets are. 
Let L be a language and let F be a fixed closed prenex formula of L. We may 
assume that L is countable since it suffices to retain only the symbols that actually 
occur in F. We are going to take as a hypothesis that in the sequence of quantifiers 
appearing at the beginning of F, the universal quantifiers and existential quantifiers 
alternate, that the first one is universal and the last one is existential. In other words, 
we suppose F has the form 
where B is a quantifier-free formula. Without this hypothesis, the proof would 
be exactly the same, except that it would require considerably more complicated 
notation. Besides, we can always artificially reduce the situation for an arbitrary 
formula to this case by adding quantifications over variables that have no free 
occurrence in the formula (and proving that the resulting formula is syntactically 
equivalent to the initial one, which is not too difficult to do). 
Let T be the set of terms of L and, for i E N, let 8; be the set of sequences of 
length i of elements of T. For each i between 1 and k, fix, once and for all, an 
injective map a; from 8; into N so that the following conditions are satisfied: 
(i) if Vn occurs in one of the terms t t ,  t2, . . .  , t;, then a; (ti , t2, . . .  , t;) > n; 
(ii) if j < i and (tt , t2, . . .  , t;) is a sequence that extends (ti , t2, . . .  , t_;), then 
aj(tt , t2, . . .  , tj) < a; (tt , t2, . . .  , ti); 
(iii) if r and a are two distinct sequences, whose respective lengths are i and j 
then a; (r) =I= aj (a). 
It is very easy to construct such maps: for example, using the codings that will 
be implemented in Chapter 6, we can set, for i between l and k, 
a; (t! ,  t 2, .
.
.
 ' t;) = 2m3r(tdsr(t2) . . · n(i )r(t;) ' 
where m is the largest index of any variable that occurs in one of the t j ( I  < j < i ), 
where r is the map denoted by # in Chapter 6, and where n is the function that, 
with each integer n, associates the (n + l)st prime number. 
Definition 4.37 An avatar ofF = Yv13v2Vv3 . . .  'v'v2k-t 3V2kB[Vt, v2, . . .  , V2k] 
is a formula oftheform 
where t1, t2, . . .  , tk are arbitrary terms of L. 
Each avatar A of F is a formula without quantifi.ers, so is a boolean combination 
of atomic formulas. Let At denote the set of atomic formulas of L. If we view the 
elements of At as propositional variables, then the avatars behave as propositional 

214 
T H E  C O M P L E T E N E S S  T H E O R E M S  
formulas. To say that a finite set E of avatars is propositionally satisfiable (see 
Definition 4.36) is to say that there is an assignment of truth values, 0 or 1, to 
each atomic formula whose extension to boolean combinations makes each of the 
propositional formulas corresponding to the elements of E true. Thanks to the 
compactness theorem for propositional calculus (Theorem 1 .39), this remains true 
for any set of avatars. We are now in position to state the first important result of 
this section: 
Theorem 4.38 If the set of avatars ofF is propositionally satisfiable, then F has 
a model. 
Proof Let 8 be a map from At into {0, 1} such that 8(A) = 1 for all avatars A 
of F, where, as usual, 8 is the canonical extension of 8 to the set of quantifier-free 
formulas of L. 
We have to construct a model M of F. The simplest idea would be to take T 
itself as the underlying set of M and to use 8 to define the interpretations of the 
various symbols of the language in such a way that all the avatars of F are true in 
M; this is hardly desirable, however, for symbols such as vo would then at the same 
time denote both a variable and an element of the model; and, as a consequence of 
our abuses of language, there would be an ambiguity when we encountered them 
in a formula. We are therefore going to make a copy of T by adding new constant 
symbols Ci , for i E N, to the language L whose purpose is to take the place of the 
variables v; ; let L * denote the language obtained in this way. For each term t of 
L, let t* denote the closed term of L * obtained by replacing, for every integer n, 
the occurrences of V11 in t by Cn . (In other words: 
if the only variables of t are vo, v 1 ,  . . .  , Vn.) We will do the same thing with the 
formulas: if G is a formula of L, G* is the closed formula of L * obtained by 
replacing, for every integer n, the free occurrences of Vn in G by en. Let T* denote 
the set of closed terms of L * (this is also the set {t* : t E T}). Also, At* will be 
the set of closed atomic formulas of L * (this too is the set { G* : G E At}). 
It is clear that the set {A* : A is an avatar of F} is also propositionally satisfiable; 
let us define an assignment of truth values c on At* in the following way: 
for all G E At, c(G*) = 8(G); 
then, for any quantifier-free formula H of L, we will have 
c(H*) = 8(H), 
and consequently, for any avatar A of F, 8(A *) = 1. 
We are finally ready to define M. Its underlying set is T*. lf c is a constant 
symbol of L, then eM = c; if f is a function symbol of L, of arity n, say, and 

H E R B R A N D' S M E T H 0 D 
u 1 ,  u2, . . .  , Un E T*, then 
-M 
f 
(U I,U2, . . ·
, Un) = fu t U2 · · · Un. 
215 
If R is a relation symbol of L, again of arity n, say, and u 1, u2, . . .  , Un E T*, then 
(ut,U2, . . .  , un) E RM if and only if s(Rut u2 . . .  un) = 1, 
which can also be written 
M F= Ru1u2 . .
. Un if and only if s(Ru1u2 . . .  Un) = 1 .  
This equivalence extends to all quantifier-free formulas (the proof is by induction 
on the height of the formula): if H[vt, v2, . . .  , vn] is a quantifier-free formula and 
u 1, u2, . . .  , Un E T*, then 
M F H[u 1u2 . . .  un] if and only if &(H[u 1 u2 . . .  un]) = 1. 
In this way, we are assured that if A is an avatar ofF, then M F= A*. 
It remains to verify that we do have a model of F. This is where the functions a; 
reveal their true nature: they are Skolem functions in disguise. For each i between 
I and k, let us define the map fi from (T*i into T* by 
Then for every sequence (ti , t2, . . .  , lk) of elements of M, we have 
because 
B ltt ,  ft (tt ), t2, f2Ct1 , t2), . . .  , tk, fk(tt ,  t2, . . .  , tk)] 
= B[tt , Va1 (tl ) '  t2, Va2(t1 ,t2) , • • · , tk, Vak(CJ ,C2, ... ,tk)]* . 
If we consider the functions f; as Skolem functions, we see that M satisfies a 
Skolem form of F, and hence M satisfies F (Lemma 3.65). 
• 
The previous theorem shows that if F does not have a model (which is the case, 
in particular, if . ...,p is derivable), then there is a conjunction of avatars of F whose 
negation is a tautology. We now wish to prove the converse of this. 
Theorem 4.39 If the set of avatars of a formula F is not pro positionally satisfi­
able, then -,p is derivable. 
Proof We know that there are a finite number of avatars of F, say Ap for p 
between 1 and n, such that the formula V 1 <p<n -,Ap is a tautology. 
Let A denote the set of formulas of the following form: 
VW2i+! 3W2i+2 . . .  VW2k-t 3W2k 
B [t1 , VaJ (ll )' l2, Va2(c1 ,c2) , • • ·
,
 t;, Vai (lt ,f2,· .. ,ci)' W2i+I , W2i+2, . . .  , W2k] 

216 
T H E  C O M P L E T E N E S S  T H E O R E M S  
where i is an integer between 0 and k, t 1 ,  t2, . . .  , t; E T, and where the w j are 
variables that do not occur in any of the terms t1 , •
•
•
 , t; and are different from 
Var (tl)' Va2 (t1 ,t2)' · 
• · '  Vai (lJ ,f2, 
. . . • ti)· 
The avatars of F clearly belong to A (take i = k). So we know there is a 
finite subset I of A such that Δ V.tEI -,f. The idea is to gradually quantify all 
of the free variables in this formula. Once this is done, we will have a formula 
equivalent to ._,F. 
So suppose that I is a finite subset of A such that Δ V.tEI _,f. We will find 
another finite subset, J, of A such that Ș V 1 El _,f and such that the number of 
free VariableS in Δ v /EJ -,f iS at leaSt One fewer than in f- vfE/ -.j. 
Let 
f = Yw2i+I 3W2i+2 . . .  Yw2k-t3W2k 
B[ti ' Val(tJ ) , t2, Va2 (tJ ,l2)' · · · ,  t;, Vai(t1 .t2, ... ,ti ) ,  W2i+l, W2i+2, . . .  , W2k] 
be a formula of A. We associate the integer n(f) = a; (ti , t2, . . .  , t;) with f. This 
is the largest index of a variable that has a free occurrence in f; in other words, 
if p > n(f), then Vp does not occur free in f. This follows from the properties 
we imposed on the functions a;. Suppose, as welt that for some other formula 
f' E A, we have n(f) = n(f'); set 
f' = YZ2J+ t3Z2)+2 . . .  YZ2k-13Z2k 
B[u1, Va1 (u1), U2, Va2(u 1,u2), •
•
•
 , U.l , Vaj(u 1 ,u2 
• • • •  ,u1)R Z2j+l ,  Z2)+2, . . .  , Z2k]. 
By construction, the images of the different functions a; are disjoint; it follows 
from this that i = j and, since the a; are injective, that t1 = u 1 ,  •
•
•
 , t; = u;. In 
other words, f and f' differ only in the names of their bound variables and hence, 
Ș f <=> f' (see the Examples in the subsection on formal proofs). 
We can begin by eliminating the repeats in I; the remarks that we have just made 
allow us to suppose that if f and f' are in /, then n(f) # n(f' ). Now choose the 
formula g E I for which the integer n (g) is maximum. Then the variable Vn(g) is 
not free in any other formula f of I. Set 
g = Yw2i+t 3W2i+2 . . .  Yw2k-t3W2k 
B[t1 , Va1 (11 ) ,  t2, Va2(tr ,t2), · · · , l;, Vctc(t1,t2 
• • • •  ,ci), W2i+l , W2i+2, •
.
.
 , W2k] 
and 
H = l - {g}. 
By generalization, we obtain 
1- Vvn(g) ( V %J) 
/El 

P R O O F S  U S I N G  C U T S  
and, since it is only in g that Vn(g) has free occurrences (see Exercise 4 ), 
1- ( V -.j) V VVn(g) -.g . 
jEH 
217 
Let w2i-l be a variable that has no free occurrence in g and take w2; = Vn(g) ·  Let 
g' =VW2i-1 3W2i · · . 3w2k 
B[tt, Vaq (tt ) , t2, Va2(tt ,l2)' · · · , t;-1 ' Va;-x(ti ,l2, .... li-1)' W2i-! , W2;, · · ·
' W2k]. 
So 1- g' => 3vn(g)g ('take' W2i-I = t; ) and hence 
1- VVn(g) -,g => -,g' 
and it remains only to set J = H u {g'} to have 1- v.fEJ -.f. 
Once all of the free variables have been eliminated and after suppressing the 
duplicates, we obtain 
and this last formula differs from -.F only in the names of their bound 
variables. 
• 
Let us recapitulate: 
Theorem 4.40 The following three conditions are equivalent: 
(i) F does not have a model; 
(ii) there existavatarsA1 , A2, . . .  ȕ AnofFsuch that VI <p<n -.Ap is a tautology; 
(iii) 1- -1F. 
Proof The implication (i) => (ii) is Theorem 4.38; the implication (ii) => (iii) is 
Theorem 4.39; and the implication (iii) => (i) is Theorem 4.20. 
• 
Remark 4.41 The proof of the completeness theorem that we have just presented 
applies only to a single formula, whereas Henkin's methodp1vves it for an arbitrary 
theory. We will see, in Exercise 8, how to use Herbrand's method to prove the 
completeness theorem for a countable theory. 
Remark 4.42 From the preceding proof, we can perfectly well extract an algo­
rithm that allows us to construct a derivation of -,p starting from a tautology of 
theform V! <p<n _,Ap. 
4.4 Proofs using cuts 
4.4.1 The cut rule 
In these last two sections, we are going to present a new kind of derivation. In it, 
the deduction rules, rather than the axioms, will play a privileged role. But these 

218 
T H E C O M P L E T E N E S S T H E O R E M S  
proofs only apply to a very restricted class of formulas, the universal clauses. 
Why should we prove the completeness theorem once again, especially in a much 
less general context? Because these are the kinds of derivations that we can most 
easily ask acomputerto do. They form the basis of the language PROLOG. Hidden 
within nearly every result in this section, there is an algorithm; we will be content, 
however, to to give the idea behind the method, without really concerning ourselves 
with the algorithms. 
In the first sections of this chapter, we did not bother with formal proofs in 
propositional calculus, quite simply because we chose to brutally include all the 
tautologies as axioms. That is not what we will do here because we wish to provide 
a method that is much faster than using truth tables for determining whether a 
proposition is a tautology or not. So this section relates only to propositional 
calculus. First, a reminder concerning a definition that appeared in Chapter 1 (see 
Remark 1 .30). 
Definition 4.43 A clause is a proposition of the form 
where the A; and B j are p1v positional variables. 
The clause 
is logically equivalent. when n and m are strictly positive, to the formula 
and this is the way we will usually write it. The premiss of this clause is the 
conjunction 
while its conclusion is the disjunction 
It can happen that either n or m  is zero; in this situation, the clause 
will be written 
=> ( B 1 v 82 v · · · v Bm) 
and the clause 
will be written 
(A I 1\ A2 1\ · · · 1\ An) => . 

P R O O F S  U S I N G  C U T S  
219 
(We could extend the conventions adopted in Chapter 1 and define the conjunction 
of an empty set of formulas to be the proposition that is always true and the 
disjunction of an empty set of formulas to be the proposition that is always false). 
If n and m are both zero, we obtain an empty disjunction which, by conven­
tion, denotes the false proposition; we will call this the empty clause and denote 
it by D. 
It has already been shown that every proposition is equivalent to a finite set of 
clauses (Theorem 1 .2 9 ). 
Proofs by cut proceed exclusively with the use of the deduction rules. The first 
is the rule of simplification: if a propositional variable A appears several times 
in the premiss of a clause A, then the clause A' obtained from A by deleting all 
but one of the occurrences of A in the premiss of A is a formula that is logically 
equivalent to A. Obviously, the same property holds for the conclusion of A. In 
these circumstances, we say that A has been simplified and that A' is derived 
from A by simplification. 
For example, 
can be simplified to 
which, in tum, can be simplified to 
Definition 4.44 (The cut rule) Let 
anͤ 
V = ( C 1 1\ C 2 1\ · · · 1\ C p) ==> ( D 1 V D2 V · · · V D q) 
be two clauses. If there exist integers i (1 < i < m) and j (1 < j < p) such that 
Bi =: Cj and if£ is the clause 
(A I A A 2 A · · · 1\ An 1\ C 1 1\ C 2 1\ · · · 1\ C j - 1  1\ C j + 1 1\ · · · 1\ C p) 
  (Bt V B2 V · · · v B;_J v B;+I v · · · v Bm v D1 v D2 v · · · v Dq), 
we say that £ is derived from C and V (or from V and C) by cut. 
In other words, if there is a propositional variable that occurs in both the con­
clusion of C and the premiss of V, then we can derive from these two clauses a 
third clause whose premiss and conclusion are, respectively, the conjunction of 
the premisses and the disjunction of the conclusions of C and V from which the 
common variable has been deleted. 

220 
T H E  C O M P L E T E N E S S  T H E O R E M S  
Example 4.45 Consider the two clauses: 
C == (A A B A C) =} (D v E v F) 
V = (D A A A G) ==? (E v H). 
We can apply the cut rule so that the variable D disappears from both the conclusion 
of C and the premiss of V. We obtain the clause 
(A A B A C A A A G) :=} ( E v F v E v H) 
which, after simplification, yields the clause 
(A A B 1\ C A G) =? (E v F v H). 
The cut rule is justified semantically by the following proposition. 
Proposition 4.46 Suppose that [ is derived by the cut rule f1vm C and V. Then 
every assignment of truth values that makes both C and V true will also make 
[ true. 
Proof Take C and V as in Definition 4.44, with Bi = C.i , and 
[ = (A t A A2 A · · ·  A An A Ct A C2 A · · · A C.i-1 A Cj--rl A · · ·  1\ C p) 
=} (Bt v 82 v · · · v Bi-t v Bi+ l v · · · v Bm v Dt v D2 v · · · v Dq). 
Let £ be an assignment of truth values for which s(£) = 0. We will show that 
we must then have either s(C) = 0 or s(V) = 0. 
We must have 
(1) s(Ak) = 1 for all k such that I < k < n; 
(2) s(Ck) = 1 for all k such that 1 < k < p and k =1- j; 
(3) s(Bk) = 0 for ali k such that l < k < m and k =I i; 
(4) s(Dk) = 0 for all k such that I < k < q. 
And since Bi = Cj , we have 
* either s(Cj ) = 1, so s(V) = 0 (because of (2) and (4)), 
* or s(Bi ) = 0, so s(C) = 0 (because of ( I )  and (3)). 
Remark 4.47 
• 
• It is obvious that if a given variable occurs simultaneously in both the premiss 
and the conclusion of a clause, then this clause is a tautology. The converse is 
also true: if a clause is a tautology, then its premiss and iis conclusion have at 
least one variable in common. 
• It is useful to note that the empty clause cannot be derivedf1vm another clause 
by simpl{fication. 

P R O O F S  U S I N G  C U T S  
221 
• Moreover, {f D is derivedftvm clauses C and V by cut, then there must be a 
pro positional variable A such that C is A =} and V is =} A, or vice versa. 
In practice, proofs by cut are usually implemented as refutations: we show that 
a set of clauses is not satisfiable. 
DeUnition 4.48 Let C be a clause and let r be a set of clauses. A derivation by 
cut of C from r is a sequence of clauses (Vt , V2, . . .  , Vn) that ends with the 
clause C (i.e. Vn = C) and is such that for all i between 1 and n, either V; belongs 
to r, or V; is derived by simpl{ficationfrom a clause Vj where j is strictly less 
than i, or V; is derived by cut from two clauses V j and Vk where j and k are 
strictly less than i. 
We say that C is derivable by cut from r if there is a derivation by cut of C 
from r. 
A refutation of r is a derivation by cut of the empty clause D from r. 
{{there exists a refutation ofr, we say that r is refutable. 
This method of proof is adequate, which means that the only things we can refute 
are those that are never true. 
Proposition 4.49 /fr is refutable, then r is not satisfiable. 
Proof Let (Vt , V2, . . .  , Vn) be a refutation of r and suppose, to arrive at a 
contradiction, the & is an assignment of truth values that makes all of the clauses 
in r true. We will argue by induction on i, for i between 1 and n, that &(Vi) = 1. 
This is clear i fV; E r. If Vi is derived by simplification from V j (j < i), then 
&(V j) = 1 (by the induction hypothesis) so &(V;) = 1 because V; and V j are 
logically equivalent. Finally, if V; is obtained by cut, we invoke Proposition 4.46. 
If D belongs to r thenऻ according to our conventions, r is not satisfiable (we 
may observe, by the way, that this case is of no real interest: the method that we are 
describing is intended to be applied to sets of 'real' propositional formulas). If not., 
then as we have seen, Vn = D is derivable by cut from two clauses A ==> ( = V;) 
and => A ( = V j) where j and i are less than n (see the last item in Remark 4.4 7). 
But this is not possible for we would have to have &(V;) 
1, which implies 
&(A) = 0 and &(Vj) = 1 ,  which implies &(A) = 1. 
• 
4 .. 4 .. 2 Completeness of the method 
We will now show that this method is complete. 
Theorem 4.50 Any set of clauses that is not satisfiable is refutable. 
Proof Let r be a set of clauses that is not satisfiable. Thanks to the compactness 
theorem for propositional calculus (Theorem 1 .39), we may assume that r is 
finite. Our argument is by induction on the number of propositional variables that 
appear in r. 

222 
T H E  C O M P L E T E N E S S  T H E O R E M S  
For a clause C, let us denote its premiss and conclusion by c- and c+ respectively. 
We will first show that the general situation is reducible to the case where r satisfies 
the following hypotheses: 
( 1  °) r does not contain any tautologies; 
(2°) r does not contain the empty clause; 
(3°) all clauses in r are are simplified; 
(4°) for any propositional variable A that occurs in a clause of r, there exist two 
distinct clauses C and V in r such that A occurs in the premiss ofC and in the 
conclusion of V. 
To obtain the first three conditions, there is hardly any problem: if we delete the 
tautologies and replace each clause of r by a simplified clause, we still have a set 
that is not satisfiable; and if r contains the empty clause, then we know it is not 
satisfiable. To obtain condition ( 4 °), it suffices to apply the next lemma: 
Lemma 4.51 If A is a propositional variable that does not occur in the premiss 
of any clause of r (or not in the conclusion of any clause of!), then: 
r' 
= {C : c E r and A does not occur in C} 
is not satisfiable. 
Proof Suppose fi.rst that A does not occur in the premiss of any clause in r and, 
in view of arriving at a contradiction, suppose that r' is satisfiable. Let 8 be an 
assignment of truth values such that 8(C) = 1 for any clause C of r'. Let 8' be 
the assignment of truth values that agrees with 8 everywhere except perhaps at A, 
and such that 8'(A) = 1. If C E r', then 81(C) = 8(C) = 1 (because A does not 
occur in C), and ifC E r - 1' .. then 81(C) = l (because A appears in the conclusion 
of C). 
The argument is analogous when A does not appear in the conclusion of any 
clause of r; in this case, we set 8' (A) = 0. 
• 
The proof of the theorem continues by induction on the number n of propositional 
variables involved in r. We note that n is not zero since r ¥= 0 (the empty set is 
satisfiable!) and o rt: r. 
Suppose n = 1. Having eliminated tautologies and the empty clause, the only 
simplified clauses that involve only the variable A 1 are : A 1 ==} and ==} A 1 · Since 
1 is not satisfiable, r = {A 1 ==}, ==} A 1 }, so r is refutable. 
Next, letustreatthepassagefrom n ton+ 1 .  Supposetherearen+ 1 propositional 
variables appearing in r and let A be one of them. Set: 
1o = {C E 1 : A does not occur in C}; 
r-
= {C E r :  A occurs in C-} = {Ct , C2, . . .  , Cm}; 
1 + = { C E 1 : A occurs in c+} = { V 1 , V2, . . .  , V p} . 

P R O O F S  U S I N G  C U T S  
223 
From our hypotheses, we see that r is the disjoint union of fo, r- and r+ and 
that neither r-- nor r+ is empty. If i is between 1 and m and j is between 1 and 
p, we may apply the cut rule to C; and V j to eliminate the variable A; let £;.j bt़ 
the clause obtained in this way. If one of the clauses E;,j is the empty clause, then 
we have found a refutation of r. If not, set 
r' = ro U {E;,j : 1 < i < m and I < j < p}. 
We will show that r' is not satisfiable. As there are only n variables appearing in 
r' (they are all those of r with A omitted), the induction hypothesis will tell us 
that r' is refutable; in view of the way the £;,j were defined, this refutation of r' 
will be immediately extendible to a refutation of r. 
The argument is by contradiction. Suppose that 8 is an assignment of truth values 
that satisfies r'. Since A does not occur in r', we may assume that 8 (A) = 0; it 
is clear that r' is also satisfied by the assignment A which agrees everywhere with 
8 except that A(A) = 1. We see that 8 satisfies fo (since fo is included in f') 
and r- (since 8 (A) = 0) but not r (which is not satisfiable). So there must exist 
at least one integer i between l and p such that 8 (V;) = 0, which implies that 
8(Vj ) = 1 and 8(Vf) = 0. 
Fix an integer j between I and m .  We know that 8 satisfies Ei,j· Hence one or 
the following two holds: 
• 8(Ei,j) = 0; now £,"0 = Vj- A C', where C' is the formula obtained from C)­
by suppressing the variable A; in this case, 8 (C') = 0 (because 8 (Vj) == 1 )  
and, since 8 and A agree on all the variables except A, A(C') = 0, which implies 
A(Cm) = 0. 
J 
• 8(E;+j) = 1 ;  this time, Ei+. = Cj v V', where V' is obtained from vt by 
suppressing the variable A{ as 8 (Vi) = 0, we must have 8 (Cj) ::: A(Cj) = 1. 
In both cases, A(Cj) = 1. Since this argument is valid for all j between 1 and m ,  
it follows that A satisfies r-. But A also satisfies r o (since it satisfies f') and r-t 
(since A(A) = 1). Hence A satisfies r, which is impossible. 
II 
To determine whether a fi.nite set r of clauses is satisfiable, it suffices to apply 
the following algorithm: first, simplify all the clauses in r and then eliminate all 
clauses that have a variable that is common to both its premiss and its conclusionɸ 
then apply the cut rule systematically to all pairs of formulas in r in all possible 
ways; having done this, repeat the process. After a while, we will not obtain any 
new clauses (because the number of propositional variables is finite, so is the set 
of simplified clauses and this cannot grow forever); if we obtain D by this process, 
r is not satisfiable; otherwise it is. Obviously, if we wish to undertake this work 
ourselves, or even ask a computer to do it, we will have to employ a slightly more 
subtle strategy than the one we just described. But that is another story. 
Example 4.52 We use the cut rule to derive the clause B ::} from the clauses 
(A 1\ B) A C, A A and C B (in other words, derive -.B from (A 1\ B) A C, A 

224 
and -,C). 
T H E  C O M P L E T E N E S S  T H E O R E M S  
From (A 1\ B) ==> C and C ==;. , we derive (A 1\ B) ==> • 
From (A 1\ B) ==> and => A, we derive B ==> . 
Example 4.53 We show that the following set of clauses is not satisfiable: 
C I is (A 1\ B) ==> (C v D) 
C2 is ( C 1\ E 1\ F) => 
C3 is (A 1\ D) => 
C4 is =} (B v C) 
C s is => (A v C) 
C6 is C ==> E 
C1 is C => F. 
Here is a refutation of { C I , . . .  , C1}: 
(1) 
(C 1\ C 1\ F) ==> from C2 and C6 
(2) 
(C 1\ F) ==> 
from (1) by simplification 
(3) 
( C 1\ C) ==> 
from (2) and C7 
(4) 
C ==> 
from (3) by simplification 
(5) 
=} A  
from (4) and Cs 
(6) 
==> B 
from (4) and C4 
(7) 
D ==> 
from (5) and C3 
(8) 
B ==> (C v D) 
from (5) and Ct 
(9) 
==> (C v D) 
from (8) and (6) 
(10) 
==> D 
from (9) and (4) 
( 1 1) 
D 
from ( 1 0) and (7). 
4.5 The method of resolution 
4.5.1 Unification 
In this section, we will introduce the technique of unification which will be needed 
to extend the method of proofs by cut to the predicate calculus. Here is the 
problem: in a given language containing function symbols, we have two terms 
t1 [ VJ , v2, . . .  , Vn] and t2[ w1, w2, . . . , Wm] in which the Vi and the w j are variables; 
the problem is to decide whether there exist terms a I , a2, . . .  , an and b 1 , b2, . . .  , bm 
such that the terms t1 [a1 , a2, . . .  , an] and t2[b1 , b2, . . .  , bm] are identical, and if 
so, to find all possible solutions. This is what is called unifying the terms t1 and t2. 
We will proceed in a rather formal way. 
Let L be a language with no predicate symbols and let V be a fixed subset of the 
set of variables. Let T ( V) denote the set of terms of L whose variables all belong 
to V. Most of the time, V will either be determined by the context or else will be 

T H E  M E T H O D  O F  R E S O L U T I O N  
225 
of no particular importance, in which case we will not even mention it and simply 
write T in place of T (V). We can, in a natural way, define an L-structure whose 
underlying set is T ( V ); we will denote it by 'I ( V) (or 'I): if c is a constant symbol, 
the interpretation of c in 'I is c itself; if f is a function symbol of arity n, then the 
interpretation frr of f in 'I is the function from yn into T defined by 
rr 
f (tr, t2, . . .  , tn) = ftrt2 . . .  tn. 
For example, if L has only a single unary function symbol (and no constant sym­
bols), and if V = { v; : i E N}, then 
T = {f11v; : n E N, i E N}, 
where it is understood that fn is an abbreviation for the sequence consisting of n 
occurrences of the symbol f (it is the empty sequence if n = 0). 
Let us recall Definition 3.31 which, in our present situation where there are no 
predicate symbols in L, becomes 
Definition 4.54 Let M = (M, . . .  ) and N = (N, . . .  ) be two L-structures and 
let u be a map from M into N. The rna p a is a homomorphism (f and only if the 
following conditions are satisfied: 
• for every constant symbol c of L, 
a(cM) = eN; 
• for every natural number n > 1, for every n-ary function symbol f of L and 
for all elements a 1 ,  a2, . . .  , an belonging to M, 
17M 
-N 
a \J 
(a1,a2, . . .  , an)) = f (a(ai ), a(a2), . . .  , a (an)). 
The structure 'I ( V) is freely generated by the set V, which, to be precise, means 
the following: 
Proposition 4.55 Let M = {M, . . .  ) be an L-structure and let a be an arbitrary 
map from V into M. Then there is a unique homomorphism/rom ':r(V) into M 
which extends a. 
Proof We are going to define a map f3 from T(V) into M by induction on terms· 
( i) if t = c is a constant symbol, the set f3 ( t) = eM ; 
(ii) if t = v; is a variable, then f3(t) = a(v; ); 
(iii) if t = ftrt2 . . .  tn, where f is an n-ary function symbol and the t;, for i 
between 1 and n, are terms for which f3(t;) has already been defined, then 
-M 
f3(t) = f (f3(tr), f3(t2), . . .  , f3(tn)). 
The map f3 defined in this way clearly extends a (because of (ii)) and is a 
homomorphism because of conditions (i) and (iii). Moreover, if {J' is another 

226 
T H E  C O M P L E T E N E S S  T H E O R E M S  
homomorphism that extends a, then for every term t, f3(t) = f3'(t): this is easily 
proved by induction on t. 
• 
Definition 4.56 Homomorphisms from 'I into itseǅf are called substitutions. 
This name is entirely justified: for if a is a map from V into T(V), with 
a ( Vn ) = u n, and f3 is the unique homomorphism of 'I into itself that extends a, 
then f3 is none other than the map which sends a term t [ v 1 ,  v2, . . .  , Vn J into 
lu1 ;v1 .u2jv2, •• • ,unfv11 • A substitution is therefore entirely determined by the values 
it assumes on the set V of variables. Obviously, we will not bother to use two 
distinct notations to denote a map from V into T and the unique substitution that 
extends it. 
Definition 4.57 Let S =  {(!I , ut), (t2, u2), . . .  , (tn, un)} be a finite set of pairs 
of terms. A unifier of S is a substitution a such that, for every i between 1 and n, 
a (t;) = a (u; ). To un{fy S is to find all the un{fiers of S. A finite set of pairs of 
terms will also be called a system. 
Remark 4.58 If a is a unifier of S and if r is an arbitrary substitution, then r o a 
is also a un{fier of S: it is clear that if a (t;) = a  (u; ), then r o a (t;) = r o a (u; ). 
Example 4.59 Suppose that V = {vi, v2, v3, v4}, that c and d are constant sym­
bols, that h is a unary function symbol and that f and g are binary function 
symbols. 
• S = {(.fvihV2, gv2gv1 v3)}. For any substitution a, the term 
begins with the symbol f whereas the term 
begins with g: so there is no unifier. 
• S = { (VI , g vI v2)}. Here again, there is no unifier: indeed, for any substitution a, 
a (gvi v2) = ga( VI )a ( v2) is a term that is strictly longer than a (vi ). 
• S = { (.fVt8V2V3, f hv3v4)}. Let a be a substitution and suppose., for v; E V, 
that a (vi) = Ui. For a to be a unifier, it is necessary and sufficient that the terms 
fu1gu2u3 and fhu3u4 be identical, hence (Theorem 3.7) that 
So we see that the values of u2 and u3 can be arbitrary, but once these are fixed, 
these equations determine the values for u 1 and u4. So here is a unifier, n ,  that 
is the simplest one that comes to mind: 

T H E  M E T H O D  O F  R E S O L U T I O N  
227 
We have already seen that any substitution of the form r o n  is also a unifier. In 
fact, this gives us all the unifiers (we say, in this situation, that n is a principal 
unifier; the next definition will treat this in detail): for suppose that a is an 
arbitrary unifier of S and that r is a substitution such that r ( v2) = a ( v2) and 
r(v3) = a (v3). We will show that a =  r o n. Indeed, if i is equal to 2 or to 3, 
then a(v;) = r(v;) = r o n(v;). Also, a(vt ) = ha (v3) (because a is a unifier) 
and ha (v3) = hr(v3) = r (hv3) (because r is a substitution) and we know 
that hv3 = n (vJ). So the conclusion is that a (v i )  = r o n(vi). The proof that 
a (v4) = r o n(v4) is similar. 
Definition 4.60 We say that n is a principal unifier of a system S if it is a unifier 
of S and {f for every unifier a of S, there is a substitution r such that a = r o n. 
The existence of a principal unifier is not a special case. 
Proposition 4.61 Every system that has a unifier has a principal unifier. 
Proof Let S = { (ti, u 1), (t2, u2), . . .  , (tn, u n)} be a non-empty system. 
Let V (S) denote the (finite) set of variables that occur at least once in some 
term that appears in S and let Uni(S) denote the set of unifiers of S. Two systems 
will be called equivalent if they have the same set of unifi.ers. We will say that a 
term t appears efficiently in S if S contains a pair of the form (t, u) or (u, t) with 
t =} u. The height of a system is the smallest of the heights of the terms that appear 
eiliciently in S. 
We are going to describe an algorithm that will permit us to 
• either prove that S does not have a unifier; 
• or else find a system, S1 , and a substitution r such that V (S1 ) has strictly fewer 
elements than V (S) and U ni(S)={ a o r : a E U ni(S 1 )}. 
This algorithm involves three stages: clean-up, simplification, and reduction. 
(A) Clean-up (or garbage collection). In this stage, we first eliminate from S 
alii pairs of the form (t, t ); next, if a pair occurs more than once, we only keep a 
single occurrence; finally, if both pairs (t, u) and (u, t) belong to the system under 
consideration, we keep only one of them. We then have a new system S1 that iऽ 
equivalent to S and has the same height. 
(B) Simplification. This stage will allow us either to find an equivalent system 
whose height is 1 or to conclude that unification is impossible. Let h be the height of 
St and assume it is greater than or equal to 2 (otherwise there is nothing to prove). 
Choose a pair (t, u) in St such that the height of t, say, is equal to h. We know 
that the height of u is greater than or equal to h and that, hence, the first symbol of 
both t and u is a function symbol. We then perform the first compatibility test: 
if t and u begin with different function symbols, there is no point in continuing 
since neither St nor S has a unifier. 
Otherwise, we may write t = f r1 r2 . . .  rk and u = f St s2 . . . Sk, where k is the 
arity of f. The system S2 obtained from St by replacing the single pair ( t, u) by the 

228 
T H E  C O M P L E T E N E S S  T H E O R E M S  
k pairs (ri , SI), (r2, s2), . . .  , (rkSk) is equivalent to St. Also note that the height of 
each r; is strictly less than h. As we have assumed t f. u, there exists an i between 1 
and k such that r; =I= s; . So by performing another clean-up, we obtain a system S2, 
equivalent to S, whose height is strictly less than h and which, moreover, satisfies 
V (S2) c V (S) since we have not introduced any new variables. 
By iterating this process, we will, unless we are led sooner to conclude that S 
has no unifier, arrive at a system S3, equivalent to S, whose height is I and is such 
that V ( S3) c V ( S). 
So let (XI , YI ) E S3, Xt # YI , with the height of XI equal to 1. 
(C) Reduction. We will now concentrate on the unification of (xi ,  YI). We 
begin with a few tests in order to eliminate certain cases: 
• the second compatibility test: if XI is a constant symbol and YI is not a symbol 
for a variable, there is no unifier. 
• the occurrence test: if x 1 is a variable, say v;, and if v; occurs in YI (but is 
not equal to YI since XI # YI ), then for any substitution a, o· (VI ) is a proper 
sub-term of a (YI )1 so a (xi ) = a (YI ) is impossible and there is no unifier. 
Except for these cases, and by interchanging XI and YI if necessary, we obtain 
a pair (v; ,YI ) such that the variable v; does not occur in YI · The unification of XI 
and Yt is then possible: let r1 be the substitution defined by 
• Tt (V;) = YI 
e if j ;f; i, rt (Vj) = Vj . 
Since !I leaves all the variables that occur in YI fixed , rt (YI ) = y l · It follows 
that !I (v;) = rt (YI ), so r1 is a unifier of (v; ,YI ). Better yet, i tis a principal unifier: 
for suppose a is a unifier of (v; ,Yl ). We will show that a = a o r1 . Indeed1 on 
the one hand, if j # i, !I ( v.i) = v,; and o· o !I ( v.i) = a (v .i ) ; on the other hand, 
a (v;) = o·(yi) (because a is a unifier of (v;,YI)) and rt (V;) = YI and hence 
o- o rt (V;) == a (YI ) = a(vi). So we have in fact found a substitution o-
'
, namely 
o-, such that o· = a' o r1 . 
Let us return now to the system S3. All the unifiers of S3 are, in particular, unifiers 
of (xi , YI) so must be of the forma o rt , where r1 is the substitution defined above. 
Let us list S3: 
For a o rt to be a unifier of S3, it is necessary and sufficient that for all i between 1 
and m, a (rt (x;)) = a(rt (Y;)). We already know, from our choice of r1 , that 
a ( r1 (xt )) = a ( rt (YI) ). So it is necessary and sufficient that a be a unifier of 
S 1 
= { (!I ( x2 ) , r 1 (Y2)) , ( r 1 ( X3 ) , r 1 ( Y 3)) , . . . , r 1 ( x m ) , r 1 (y m ) } . 
Now exactly which variables can occur in rt (xk) or in r1 (Yk) for 2 < k < m? 
Only those variables that occur in a term rt ( v .i) such that v .i itself occurs in one 
of the terms xk or Yk for k between 2 and m; i.e. such that Vj belongs to V(S3). 

T H E  M E T H O D  O F  R E S O L U T I O N  
229 
Referring back to the definition of r1, we see that V (S1 ) does not contain v; and 
is included in V ( S3). We have thereby kept our promises. 
It then suffices to repeat these three operations A, B, and C, to eliminate all 
the free variables: either we come upon an impossibility or we find systems 
s1 ' S2' . . .  ' sk' where V(Sk) is empty, and substitutions TI' T2, . . .  ' Tk such 
that for all i between 1 and k - 1 ,  
Uni(S;) = { a  o r;+I : a  E Uni(Si+I)}. 
At this point, the terms appearing in sk are all closed terms (since V (Sk) is empty); 
hence, they are left fixed by any substitution. So, if there exists a pair (t, u) E sk 
such that t # u, then neither sk, nor S, consequently, has a unifier. If no such pair 
exists, then all substitutions are unifiers of sk and the unifiers of S are then exactly 
those substitutions of the form a o Tk o · · · o r2 o r1 where a is any substitution; 
Tk o · · · o r2 o r1 is then a principal unifier of S. 
• 
This proof furnishes us with an algorithm that can be used to decide whether a 
system has unifiers and, if it does, to find a principal unifier. We have to alternate 
two sub-algorithms: on the one hand, the operations of clean-up and simplification 
produce an equivalent system that contains no pairs of the form (t, t) and which 
involves at least one term of height 1 ;  on the other handΓ the reduction operation 
decreases the number of variables. 
Example 4.62 In this example, c is a constant symbol, f and g are binary func­
tion symbols and k is a ternary function symbol. We will proceed to unify the 
system S: 
S = {(kjcgV4V3jcgV3V4kV3V4V2 , kV2V2VI)}. 
lB: Simplification. The system S is equivalent to 
{(j'cgV4V3, V2), (jcgV3V4, V2) , (kV3V4V2, VI)}. 
l C: Reduction. Set r1 (v2) = jcgv4v3 and r1 (v;) = v; for i # 2. We obtain the 
system 
S1 
= {(jcgV3V4, jcgV4V3), (kV3V4jcgV4V3, Vt)}. 
2 A and 2B: There is nothing to do: the system is simplified. 
2C: Reduction. Set r2(v1) = kv3v4jcgv4v3 and r2(v;) = v; for i # L We 
obtain the system 
S2 
= {(jcgV3V4, jcgV4V3)}. 
3B: Simplification. We obtain, in succession, systems equivalent to S2: 
then 
{(c, c), (v3, v4), (v4, v3)}; 
and after a clean-up, we see that S2 is equivalent to { (v3,v4) }. 

230 
T H E  C O M P L E T E N E S S  T H E O R E M S  
3C: Reduction. We now set r3(v4) = V3 and r3(v;) = v; for i # 4. The system 
S3 is empty. The substitution r = T3 o r2 o rt is a principal unifier of S We may 
calculate 
Remark 4.63 We could have calculated this differently (for example, by reducing 
the pair (kv3v4v2, VI) at stage 1B or by setting T3(v3) = V4 at stage 3B); we 
would have found a d{ fferent principal unifier: Exercise 15 explains how to find all 
principal unifiers of a system once one is known. 
Remark 4.64 For some systems, there may arise the possibility of performing 
several reductions at one time. For example, suppose S contains the pairs (Vt, t1 ) 
and (v2, t2). If these pairs satisfy the occurrence and the compatibility tests and 
if, moreover, v2 does not occur in t1 nor v1 in t2, then we may reduce using the 
substitution r defined by r (vi )  = t1, r(v2) = t2, and r(v;) = v; for i  diferent 
from 1 and2. 
4.5.2 Proofs by resolution 
We are going to adapt the method of proof by cuts to the predicate calculus. 
As with the propositional calculus, we deal in practice with refutations rather 
than derivations and the method will only apply to a restricted class of formulas, 
the class of universal clauses. We fix a language L (which may contain relation 
symbols) and denote the set of terms of L by T. Let us agree that when we speak of 
substitutions in what follows, we mean substitutions in the sense of Definition 4.56 
relative to the language L without its relation symbols. 
Definition 4.65 A universal clause is a closed formula of the following type: 
where the A; and B j are atomic formulas. 
We will often be content to write 'clause' rather than 'universal clause'. We will 
also adopt several conventions which simplify the writing of clauses: 
( 1 °) We will not write the quantifiers: this is justifi.ed by the fact that all the 
quantifiers are universal and all the variables are quantifi.ed. The only ambiguity 
is then in the order in which the variables are quantified and this, in fact, has no 
importance. 
(2°) Along with our convention to omit writing the universal quantifiers and just 
as for the propositional calculus, we will use the notation: 
to denote the universal clause: 

T H E  M E T H O D  O F  R E S O L U T I O N  
231 
As before, (A 1 1\ A2 1\ · · · 1\ An) will be called the premiss and ( B 1 v B 2 v . . .  v B m) 
the conclusion of the clause. 
(3°) It is possible that the integers n or m or both are zero. We adopt the same 
notations as in the previous subsection: (At 1\ A2 1\ . . .  1\ An) =} is the clause: 
and ==> (Bt v B2 v . . .  v Bm) is the clause: 
If n and m are both zero, we have, by convention, the empty clause which will 
again be denoted by o. 
Let a be a substitution ofT (the set of terms of L ) . Then a also acts on formulas: 
if F is a formula whose free variables are VI, v2, . . . , vk, then by definitionҜ a (F) 
is the formula 
where, for i between 1 and k, x; = a(v; ). For example, if A is an atomic formula, 
it has the form 
where R is a predicate symbol of arity j and where tt , t2, . . .  , tj are terms; in 
this case, 
If C is a universal clause, say C = (A 1 1\ A2 1\ · - · 1\ An) =} (BI v B2 v · · · v Bm), 
then, by definition, 
Remark 4.66 From the definition of satisfaction of a formula in a structure 
(Definition 3.42), we immediately deduce the following very important property: 
ifF is a universal clause and if M is a model ofF, then for every substitution a, 
M is also a model of a (F). 
Unification, in turn, applies to formulas. Suppose A I, A2, . . .  , An are atomic 
formulas. We wish to determine all substitutions a such that a(At) = a(A2) = 
· · · = a (An); these will be called unifiers of (A I ,  A2, . . .  , An). Since the A; are 
atomic formulas, they can be written 

232 
T H E  C O M P L E T E N E S S  T H E O R E M S  
where the R; are predicate symbols of arity m; and the tt. are terms. We have seen 
.I 
that if a is a substitution, then 
a (A;) = R;a(tf)a(tŽ) . . .  a(tž;). 
Thus if, for distinct integers i and j between 1 and n, R; is different from R i ,  
then there are no unifiers. In the opposite case, all the m; must equal a common 
value, which we will call m, and the unifiers of (A 1 ,  A2, . . .  , An) are precisely the 
unifiers of the set 
{ (ti, t£) : 1 < k < m. l < i < n}, 
so we may apply the results of the previous subsection: either there is no unifier 
or else there is a principal unifier. 
Definition 4.67 Two clauses are said to be separated (f they do not have any 
variable in common. 
If C and D are two clauses and the set V of variables is infinite, then we can 
find a permutation a of V (i.e. a bijection of V onto itself) such that C and a (V) 
are separated. It suffices to define a so that for every variable v; that occurs in D, 
a (vi) is a variable that does not occur in C. 
We are now in position to describe the rule of resolution. 
Given two clauses C and V, we will explain what we mean by 'a clause £ is 
derived from C and D by resolution '. 
The situation is analogous to the one for propositional calculus where we 
explained the cut rule. The role played there by the propositional variables is 
played here by the atomic formulas. The essential difference in the method is that 
in the present context, we will not require that some specific atomic formula appear 
both in the premiss of one and in the conclusion of the other; we will only require 
that we can reduce the situation to this case by means of a unification. 
Starting with C and D (it is quite possible that C = D), we begin by separating 
them, i.e. we replace D by a clause D' = 
1: (D), where 1: is a permutation of 
variables such that C and V' are separated, as we explained above. Suppose that C 
and D' are written: 
C = (A 1 1\ A2 1\ · 
· 
· 1\ An) =} (B 1 v B2 v · · · v Bm) and 
D' = ( C 1 1\ C 2 1\ · 
· 
· 1\ C p) =} ( D 1 V D2 V · 
· · V D q). 
Suppose that certain formulas i n  the conclusion of C can be unified with certain 
formulas in the premiss of D'; more precise! y, suppose there exist a non-empty 
subset X of { 1 ,  2, . . .  , m} and a non-empty subset Y of { 1 ,  2, . . .  , p} such that the 
set { B; : i E X }  U { C.i : j E Y }  has a unifier. Suppose then that a is a principal 
unifier of {B; : i E X} U {Cj : j E Y}. 

T H E  M E T H O D  O F  R E S O L U T I O N  
233 
The rule of resolution permits, in this circumstance, the derivation of the universal 
clause £ from the clauses C and V, where: 
• the premiss of £ is the conjunction of a(AI) 1\ a(A2) 1\ · · · 1\ a(An) and the 
formulas a ( C h) for h E { I , 2, .
. . , m} 
- X; 
• the conclusion of£ is the disjunction of a(Dt) v a(D2) v · · · v a(Dq) and the 
formulas a ( Bk) for k E { 1 ,  2, .
. . , p} - Y .  
We could also say that £ is obtained from C and V' by simplification and cut (in 
the sense of the previous section). 
Remark 4.68 In the rule of resolution, we insist that the un{fication is performed 
with a principal un{fier. The reason for this lies in computer science: it is much 
easier to write an algorithm that searches for a principal un{fier than to write one 
that searches for all un{fiers. 
Example 4.69 The language consists of one unary function symbol h, a binary 
function symbol f, a binary predicate symbol R and a ternary predicate symbol P. 
Consider the following clauses: 
C is PVt V2V3   (Rfvi V2V3 V Rfvl V2hfv1 V2) 
V is Rv1hvt   Pv1 VJ VJ. 
We begin by separating the clauses: so we replace V by V': 
It is easy to unify P v 1 v2 v3 in the premiss of C with P V4 v4 v4 in the conclusion 
of V': a principal unifier of {(VI , v4),( v2, v4),( V3 ,v4)} is a: 
Then 
and 
From the rule of resolution, we now derive the clause 
It is also possible to unify Rfvl v2v3, Rfvt v2hfv1 v2, and Rv4hv4. For this, we 
must find a principal unifier of 

234 
T H E C O M P L E T E N E S S T H E O R E M S  
The reader should verify that the substitution T that follows is a principal unifier: 
We then have 
and 
The rule of resolution then allows us to derive 
The next proposition expresses the fact that the rule of resolution is semantically 
justified. 
Proposition 4.70 Suppose that the universal clause £ is derivable from clauses 
C and V by an application of the rule of resolution. If M is a model ofC and V, 
then M is also a model of£. 
Proof Clearly, we may assume that C and V are separated. So there is a substitu­
tion a such that £ is obtained from a (C) and a (V) by a cut, possibly after a simpli­
fication. Let M = (M, . . .  ) be a model of C and V. We have seen (Remark 4.66) 
that M is also a model of a (C) and a (V). Let us be explicit: suppose 
a (C) = (AI 1\ A2 1\ · · · 1\ An) =>  (B1 v B2 v · · · v Bm) and 
a (V) = (C1 1\ C2 1\ · · · 1\ Cp) => (DI v D2 v · · · v Dq), 
and suppose that the cut is performed on the formulas Bt for i E X where X c 
{ 1 ,  2, . . .  , m} and Cj for j E Y where Y c { 1 ,  2, . . . , p}. Thus £ is equivalent to 
the formula 
£' = (A 1 1\ A2 1\ · · · 1\ An 1\ ( 6 Ch)) 
=* ( D1 v D2 v · · · v Dq v ($ Bk)) 
where I = { 1,2, . . . ,m} - X and J = {1,2, . . .  , p} - Y. 
Suppose that the variables appearing in these clauses are v 1, v2, . . .  , Vk and that 
a 1 ,  a2, . . .  , ak are elements of M. Set 
(Note that we are passing to the language L M.) 

T H E  M E T H O D  O F  R E S O L U T I O N  
We then have 
M F= (AƆ 1\ A; 1\ • 
· 
· 1\ Ai) => (BU v BV v · · · v BW) and 
M F (CE A CV A · · · A CF) :::} (Dg v Dh v · · · v DŻ). 
235 
By using simplification and the cut rule in the context of propositional calculus 
(Definition 4.44 ), we obtain 
M t= (A; 1\ AƇ 1\ · · · 1\ Ai 1\ ( [J CG)) 
=? ( Dg v Dh v · · · v Dż v ( :L Bk)) 
and hence, 
• 
Definition 4. 71 Let r be a set of clauses. A refutation of r is a sequence of 
clauses S = {Vt,V2, . . .  ,Vn} that ends with D and is such that for every i between 
1 and n, either V; belongs to r, or V; is derivable from two clauses that pre­
cede it in S by the rule of resolution. We say that r is refutable if there exists a 
refutation of r. 
It follows from what we said, as in Proposition 4.49, that if r is refutable, then 
r does not have a model. It is the converse that we are concerned with here. So if 
r is not refutable, we need to construct a model of r. We will reduce this to the 
case for propositional calculus by using a simplification of Herbrand's method. 
Recall that V = { Vk 
: k E N} is the set of variables and T is the set of 
terms of L_ Since there are no quantifiers that require manipulation, we need 
not be as scrupulous as we were in Section 4.3 and we will construct a model 
whose underlying set is precisely T. The interpretation of the function symbols is 
defined as in the proof of Theorem 4.38: if f is a function symbol of arity n, then, 
naturally enough, the interpretation of f is the function from yn into T that sends 
(tt . t2, . . .  , tn) to f t1 t2 . . . tn. Let P be the set of atomic formulas. To completely 
define our L-structure, it remains to decide, for every integer n, for every n-ary 
predicate symbol R and for every sequence (tt ,t2, . . . , ln), whether Rt1t2 . . . tn is 
true or not. All these decisions are independent from one another and may be taken 
arbitrarily. In other words, for every function 8 from P into {0,1}, we construct 
an L-structure Mo in the following way: if R is an n-ary predicate symbol and if 
t1 ,, t2, . . .  , tn E T, then (tt , t2, . . .  , tn) belongs to the interpretation of R in Mo 
(i.e. M0 F= Rt1t2 . . .  tn ) ifand only if8(Rt1 t2 . . .  tn) = l. 
We will consider the elements ofP as propositional variables and 8 as an assign­
ment of truth values. We extend 8 in a canonical way to a map 8 which assigns truth 

236 
T H E  C O M P L E T E N E S S  T H E O R E M S  
values to the quantifier-free formulas of L and so, if F is one of these formulas 
without quantifiers, 
Mo F= F if and only if 8 (F) = 1. 
Now let G = Vvt Vv2 . . .  Vvn F[vt , v2, . . .  ,Vn ] be a universal formula. Under 
what conditions is Mo a model of G? The response is simple: it is necessary and 
sufficient that for all sequences (lt , t2, . . .  , tn) of elements of T, we have 
Mo 1=: F [tt , t2, . . .  , tnL 
which amounts to saying that for any substitution a, Mo F= a (F), or, alternatively, 
8 (a (F)) = 1. 
It remains to prove: 
Theorem 4.72 Let r = {C; 
1 < i < n} be a set of universal clauses that has 
no model; then r is refutable. 
Proof The set 
X = {a (C;) : 1 < i < n and a is a substitution} 
is not propositionally satisfiable: if 8 were a distribution of truth values satisfying 
X, then the structure M0 constructed above would be a model of r. By the com­
pactness theorem for propositional calculus, we conclude that there is a finite subset 
Xo of X which is not propositionally satisfiable, and, by Theorem 4.50, that there 
is a refutation of Xo using simplification and the cut rule. We are going to see how 
to transform this refutation into a refutation of f" (in the sense of Definition 4.71). 
First, we must introduce some more precise concepts. 
• [f Ô is a set of universal clauses and V is a universal clause, we will say that 
V is derivable from Ô by cut if there exists a sequence (Vt ,V2, . . . , Vn) such 
that V = Vn and, for all i between 1 and n, either V; E Ƀ' or there exists j < i 
such that V; is derived from V j by simplification, or there exist j and k less 
than i such that V; is derived from V j and Vk by the cut rule. 
• If t:,. is a set of universal clauses and V is a universal clause, we will say that V 
is derivable from Ô by resolution if there exists a sequence (Vt ,V2, . . .  , V11) 
such that V = Vn and, for all i between 1 and n, either Vi E !:,. or there exist 
j and k less than i such that V; is derived from V j and Vk by resolution. 
• If C is a clause, c+ will denote the set of atomic formulas appearing in its 
conclusion, and c- the set of those appearing in its premiss. If C and V are two 
clauses, we will write c c v if c- c v- and c+ c v+. 
We already know that the empty clause D is derivable by cut from Xo. We will 
prove: 
Lemma 4.73 Let V be a clause that is derivable by cut from X. Then there exists 
a clause £ that is derivable by resolution from r and a substitution r such that 
r(£) c V. 

T H E  M E T H O D  O F  R E S O L U T I O N  
237 
First of all, it is clear that the theorem follows from the lemma: by applying it 
to the empty clause, we see that there exists a clause £ that is derivable from r 
by resolution and a substitution r such that r (£) c 0. Necessarily, r (£) = 0 
and £ =  D .  
Proof (of the Lemma) Let (Vt , V2, . . .  , Vn ) be a derivation from X ofV by cut 
(so V = Vn ). We will argue by induction on the integer n. There are several cases 
to consider. 
(a) Vn E X; this means that there is a substitution a and a clause Ci E r such 
that v = a(Ci ). It then suffices to take £ = ci and T = a. 
(b) There exists an i < n such that Vn is obtained by simplification from Vi . 
This implies that Vi c Vn since Vj = V,-; and Vj = V;t. By the induction 
hypothesis, there exists a clause £ that is derivable by resolution from r and a 
substitution r such that r (£) c Vi . The conclusion follows. 
(c) Vn is obtained by cut from two clauses Vi and V j where i and j are integers 
less than n .  By the induction hypothesis, there exist clauses £1 and £2 derivable 
by resolution from r and substitutions r1 and r2 such that r1 C£1 ) c Vi and 
r2 (£2) c Vj. Let us separate £1 and £2: let a be a permutation of the set of 
variables such that, by setting £3 = a  (£2), £1 and £3 are separated. There is then 
a substitution 1-L such that: if Vi is a variable that occurs in £1 , then tt( v;) = TJ (Vi) 
and if Vi is a variable that occurs in £3, then J.i-(v;) = r2 o a -1 (vi). Under these 
conditions, 
/l(£t ) = TJ (£1 ) c Di; 
Jvt(£3) = r2 o a -1 (£3) = r2(£2) C Vj . 
Let us write £1 and £3 explicitly: 
£1 = (AI 1\ A2 1\ · · · 1\ Ar) => (Bt v B2 v · · · v Bs) and 
£3 = ( C 1 1\ C 2 1\ · · • 1\ C t) => ( D 1 v D2 v · · · v Du). 
We know that the cut rule applies to the pair (V; ,V j ). This means that there is an 
atomic formula E that appears in the conclusion of V; and in the premiss of V j 
(or vice versa); we may assume, without loss of generality, that E E Vi and 
E E Vj. Because Vn is obtained by cut from V; and Vj and since 11(£1 ) c V; 
and t-t (£3) c V j, we see that 
{tL(A;) : I < i < r} U ({tL(Ci ) : I <  i < t } - {£}) c V,-;, and 
{ J-l ( Dt ) : I < i < u} U ( { /l ( B i ) : I < i < s} - { E}) c VT . 
(*) 
The formula E may not appear in tt(Et)+ nor in tL(£3)-; this forces us to 
distinguish several cases: 
( J) for all k between 1 and s, E =I= Ù-t(Bk ); in this case, tL(£1 ) c Vn and we have 
the desired conclusion; 
(2) for all k between 1 and t, E =I= JL(Ck); in this case, tl.-(&3) = r2C£2) c Vn 
and again we have what we seek; 

238 
T H E  C O M P L E T E N E S S  T H E O R E M S  
(3) The sets 
I = {i : 1 < i < s and tL(B; )  = £} 
and 
J = {j : 1 < j < t and J1-( C j )  = E} 
are non-empty. Then we can unify { B; : i E /} U { C.i : j E J }  and apply the rule 
of resolution to £1 and £2. Here, more precisely, is how this can be done. We have 
already separated £1 and £2 to obtain £1 and £3. Let a be a principal unifier of 
{ B; : i E / }  U {Cj : j E J}. Since JJ. unifies these formulas, there is a substitution 
r such that J-L = r o a. By resolution, we obtain a clause £4 with all the desired 
properties: 
• It is derivable by resolution from r (since £1 and £2 are). 
• £;t = {a(B;) : 1 < i < s and i fj / }  U {a(D; ) : 1 < i < u}; this shows that 
Invoking (*), we conclude that r (£;t) c vt. 
• A similar argument shows that r (£4-) c V,-;. 
• 
Example 4. 74 The language contains one constant symbol c, two unary predicate 
symbols S and Q, a binary predicate symbol R and a unary function symbol f. 
We will derive the empty clause from the following six clauses: 
( 1) Qfvo ==> Svo 
(3) Pvo ==> Qvo 
(5) ==> Pc 
(2) 
==> (Svo v Rfvovo) 
( 4) ( P VI A R VQ V 1 ) ==} P VQ 
(6) Sc ==> 
First, we apply the rule of resolution to ( 1 )  and (6) by unifying Svo and Sc using 
the principal unifi.er a(vo) = c (by convention, if we are not explicit about a(v; ), 
it is understood that a (v;) = v; ). We obtain 
(7) Qfc =*· 
Then, from (3) and (7), by unifying Qfc and Qvo (the principal unifier is 
a'(vo) = fc). we obtain 
(8) P fc ==>; 
and together with (4), by unifying P f c and Pvo using a', we obtain 
(9) ( Pvt A Rf cv1 ) =}. 
We may now unify Rf cv1 from (9) and Rfvovo from (2). The principal unifier 
is a'' ( vo) = a" ( v 1 ) = c and the rule of resolution yields 
(10) Pc ==> Sc. 
With (5), we obtain ==? Sc and with (6) we obtain the empty clause. 

T H E  M E T H O D  O F  R E S O L U T I O N  
239 
Example 4. 75 We will reconsider Example 4.34. Formulas F4 and Fs are not 
clauses. To reduce the situation to this case, we introduce Skolem functions, specifi­
caHy, a constant symbol d and a unary function symbol f. We must then derive 
the empty clause from the fallowing clauses: 
(1) (PVoVIV3 A PVIV2V4 A PV3 V2V5)   PVoV4V5 
(2) (PvoVI V3 A Pv1 V2V4 A PVOV4V5)   PV3V2V5 
(3) 
  Pvocvo 
(4) => Pvofvoc 
(5) Pcdd :::} 
From (1) and (5), by unifying Pvov4V5 and Pcdd (the unifier is obvious), we 
obtain 
(6) (Pcv1 v3 1\ Pv1 v2d A Pv3v2d) :::} . 
Clauses (6) and (3) are separated and we can unify Pvocvo and Pcv1 v3 using the 
principal unifier a(vo) = a(vi) = a(v3) = c; we obtain 
(7) ( Pcv2d A P cv2d) :::} . 
We now apply the rule of resolution to (7) and (2): they must first be separated, 
so we replace (7) by (Pcv6d A Pcv6d) :::}. We then unify Pcv6d and Pv3v2vs 
(using a(v3) = c, a(vs) = d, a(v6) = v2) and we obtain 
(8) (PVOVtC A PVt V2V4 A Pvov4d) :::}. 
To separate (3) and (8), we replace (3) by PV6CV6 and by unifying this formula 
with Pvov4d (using a(vo) = a(v6) = d, a(v4) = c), we obtain 
(9) (Pdvrc A Pv1 V2c) :::}. 
We then apply the ruleofresolution to(4) and(9)by unifying Pvofvoc and Pdv1c 
(using a(vo) = d, a(Vt) = f d ); from this, we derive 
( 1 0) P f dv2c :::} 
and a final application of the rule of resolution to (4) and (10) (using a(vo) = fd, 
a(v2) = ff d) yields the empty clause. 
Proposition 4.70 and Theorem 4.72 furnish a theoretical basis for the method 
of resolution. Imagine that we wish to derive a formula F from the formulas 
G 1 , G2, . . .  , Gn. We would instead try to show that the set 
does not have a model. We begin by replacing these formulas by a set of clauses. To 
accomplish this, we first add Skolem functions and in this way we obtain universal 
formulas. We then replace the quantifier-free part of each of these formulas by their 
conjunctive normal forms (see Defi.nition 1 .28). Finally we distribute the universal 
quantifiers over the conjunctions (see Theorem 3.55) to produce a set of clauses. 
It is then from this set that we try to derive the empty clause using the rule of 
resolution. Obviously, in practice, we cannot merely apply the rule of resolution 

240 
T H E  C O M P L E T E N E S S  T H E O R E M S  
systematically in all possible ways. It is necessary to adopt a strategy; a great 
number of these strategies, which we will not treat here, have been elaborated. 
Note that there is an essential theoretical difference between the propositional 
calculus and the predicate calculus when it comes to applying the method: we 
have already mentioned that in the former case, the search is bounded. By this, we 
mean that after a certain number of applications of the cut rule, a number which 
can be bounded in advance (at most 3n if there are n propositional variables: 
see Exercise 10), if we have not obtained the empty clause, then we will never 
obtain it and the original set of clauses is satisfiable. This is no longer true for 
the predicate calculus (except for some particularly impoverished languages). In 
the general case, we cannot be certain that the search is complete until the empty 
clause is obtained. It is only if we never obtain the empty clause and if the search is 
conducted in a systematic fashion that we may conclude for certain that the initial 
set of clauses is satisfiable (Theorem 4.72). We will express this difference in a 
more striking way in Chapter 6: the propositional calculus is decidable while, in 
general, the predicate calculus is not. 

E X E R C I S E S  F O R  C H A P T E R  4 
241 
E X E R C £ S E S  F O R  C H A P T E R  4 
-
-----------
1. Is the formula F ==> Vv F universally valid for any formula F? 
2. (This exercise is motivated by Example 4.7.) 
(a) Give an example which illustrates why the restriction 'w is not free in F' 
must accompany the assertion that V v F => F w/v is universally valid. 
(b) Give an example which illustrates why the restriction 'w is not bound in F' 
must accompany the assertion that VvF => VwFw/v is universally valid. 
3. In a language L, we are given a theory T and two formulas F and G. Assume 
that 
T I- 3vo F and T I- Vvo(F => G). 
Without appealing to the completeness theorem, show that 
T I- 3voG. 
4. Let F and G be two formulas and suppose that the variable v is not free i n  F. 
Give a derivation of F v VvG starting from Vv( F v G). 
5. Let L be a language and F be the set of formulas of L. 
(a) Show that there exists at least one map ¢ from the set F into {0,1} that 
satisfies the following conditions: 
( I )  If F E F and F begins with a universal quantifier, then ¢ (F) = 0; 
(2) If F E F and F begins with an existential quantifier, then ¢ (F) = 1; 
(3) IfF is of the form ·स·,G, then ¢ (F) = 1 - ¢ (G); 
(4) If F is of the form (G a H ), where a is a binary connective, then 
¢ (F) = a(¢ (G), ¢ (H)), where a is the map from {0, 1}2 into {0, 1} 
corresponding to the connective a. 
(b) Show that if F is an axiom, then ¢(F) = 1. 
(c) Show that if ¢(F => G) =  1 and ¢ (F) = 1, then ¢ (G) = 1; 
(d) Show that if there exists a derivation of F that makes no appeal to the rule of 
generalization, then ¢(F) = 1. Conclude from this that we cannot do with­
out the rule of generalization, i.e. that there exist formulas that are derivable 
but which are not derivable without using the rule of generalization. 
6. Using a method analogous to the one just used in Exercise 5, we can show that 
the quantification axiom schema (c) is indispensable. 
(a) Define a map ¢ from F into {0, 1} which satisfies conditions (3) and (4) 
from Exercise 5 as well as: 

242 
T H E  C O M P L E T E N E S S  T H E O R E M S  
( 1 )  If F E F and F begins with a universal quantifier, then ¢ (F) = 1; 
(2) I f F  E F and F begins with an existential quantifierɸ then ¢( F) = 0. 
(b) Show that if F has a derivation in which axiom schema (c) is never used, 
then t;(F) = 1. 
(c) Find a formula that is derivable but whose derivations all use schema (c). 
7. For any formula F, let F* denote the formula obtained by replacing all occur­
rences of the existential quantifier by the universal quantifier. Show that if F 
has a derivation that makes no appeal to axiom schema (a)Ҝ then 
Ș F*. 
Find a formula that is derivable but whose derivations all use schema (a). 
8. Use Herbrand's method to prove the following completeness theorem. 
Let T = { Fn : n E N} be a set of closed formulas in prenex form. Show 
that if T is non-contradictory, then T has a model. 
9. Using a derivation with cuts, exhibit a refutation of each of the following four 
sets of clauses: 
(a) {(A 1\ B) :::} C, :::} A ,  C =}, :::} B}; 
(b) { (A 1\ B) =} C, A =} B, =} A , C =}}; 
(c) {(A 1\ B) =}, C =} A, 
=} C, D =} B, =} (D v B)}; 
(d) {(A 1\ B) =} (C v D), (C 1\ E 1\ F) :::}, (A 1\ D) :::}, :::} (B v C), 
:::} (A v C), C :::} E, C :::} F}. 
10. Suppose the set of propositional variables has cardinality n and is equal to 
{AJ, A2, . . .  , An}. We wish to count the number of clauses, but subject to 
two conditions: first, we count only those in which no propositional variable 
occurs more than once (if a propositional variable occurs more than once in 
the premiss or more than once in the conclusion, the clause can be simplified; 
if a propositional variable occurs in both the premiss and the conclusion of a 
clause, then this clause is a tautology); second, clauses which differ only in the 
order of the variables that occur in either the premiss or the conclusion should 
be counted only once. We will say that a clause is reduced if it is of the form 
where (i 1 ,  i2, .
. . , in) and (j1 ȓ }2, .
. . Ȕ jm) are strictly increasing sequences. The 
number we seek is the number of reduced clauses. What is it? 
11. Let S be a set of7 clauses such that at least three distinct propositional variables 
occur in each of them. Show that S is satisfiable. 

E X E R C I S E S  F O R  C H A P T E R  4 
243 
12. Let r consist of the following four clauses: 
Ct is (A A B) ==> C 
C3 is A ==> B 
C 2 is ( B A C) ==> 
C4 is ==> A. 
(a) Exhibit a refutation of r using a proof with cuts. 
(b) Show that the clause V == A ==> C is derivable from clauses C 1 and C 3 using 
the cut rule and simplification but that the set {C2, C4 , V} is not refutable. 
13. The language L has two constant symbols a and b, two unary function symbols 
h and k, and two binary function symbols f and g. Unify each of the following 
five pairs of formulas: 
(a) (gvoghbgv2v3, gggvsv1hv4ghbvo); 
(b) (gv3ggv2agvov1, gggvov2gvov1ggv2av3); 
(c) (gv4ggj gv1 V6f V5 VI2gfV1QGV2fV?V8, 
gjjv3v9! vu v 1 1 ggv2gf v1oafv6vov4); 
(d) (fv2fffgv4v1 fv3vsfgV?bvogv6V8, 
f ggv9V3gV9V10ff vof gv?b/Vll V12v2); 
(e) (gvogggk vsgVI I  v7ggv1ghV2kvsv6hV9, 
ghgvto v3g gv6g gkkv4gh v2 v 1 gv 12 vg vo). 
14. Let V be the set of variables and T the set of terms. Let a be a permutation of 
V (i.e. a bijection of V onto itself). Show that the unique substitution, a, that 
extends a is bijective. 
Conversely, assuming that the substitution a is a bijection from T into T, 
show that the restriction of a to V is a permutation of V. 
15. I n  this exercise, we assume that the set V of variables is finite and is equal to 
{VI , v2, . . .  , Vn}. Let T be the set of terms. 
(a) Suppose that t is a term, a is a substitution, and that a (t) = t. Show that if 
v occurs in t, then a (v) = v. 
(b) Let a and rr be two substitutions and let v be a variable. Assume that 
rr 
= a o rr. Show that at least one of the following two assertions must 
be true: 
(i) a (v) = v; 
(ii) for any term t, v does not occur in rr (t). 
(c) Suppose now that rr .  JT 1, a. a 1 are substitutions. that rr = a o rr  1 and that 
n1 = a1 o rr . Set 
A = { v E V : there exists a term t such that v occurs in rr ( t)}, and 
B = {at(v) : v E A}. 

244 
T H E  C O M P L E T E N E S S  T H E O R E M S  
Show that B c V, that a1 is a bijection from A onto B, that a is a bijection 
from B onto A, and that a o a1 is the identity on A. 
Construct bijections a ' and a; from V into V such that 
(i) for every v E A, a1 (v) = aź (v); 
(ii) for every v E B, a (v) = a' (v); 
(iii) a' o a[ and a; o a' are equal to the identity on V; 
(iv) rr = a' o 1 q ;  
(v) n t  = a; o n . 
(d) Suppose that n is a principal unifier of a system S .  Show that the set of 
principal unifiers of S is equal to 
{a o n : a is a substitution and a bijection from T onto T}. 
16. The language consists of three unary relation symbols P, R and S, one binary 
relation symbol Q, and one unary function symbol f. Apply the rule of resolu­
tion in two different ways to the following two universal clauses: 
Svo ==> (Pvo v Rvo), 
17. The language is the same as in Exercise 1 6. Add Skolem functions to the 
language to rewrite the following formulas as clauses and use the method of 
resolution to show that the set they form is contradictory: 
3voV'vi (Pvo 1\ (Rv1 ==> Qvov1 )); 
YvoV'v1 (...,Pvo v -,Sv1 v -,Qvovi); 
3vi(Rvi 1\ Svt ) .  
18. The language consists of one binary relation symbol R and one unary function 
symbol f. Consider the following formulas: 
Ft Yvo(3vi Rvovl ==> Rvofvo); 
F2 Yvo3vi Rvov1; 
F3 3voRffvovo; 
G 3vo3vi 3V2 (Rvov1 1\ Rv 1 v2 1\ Rv2vo). 
Using the methodofresolution, show that G is a consequence of {FI ,  F2, F3}. 

Solutions 
Solutions to the exercises for Chapter 1 
1. For an arbitrary formula F, we let b[ F] and n [F] denote the number of 
occurrences of symbols for binary connectives and for negation, respectively. 
We will prove by induction that the length of F is 
lg[F] = 4b[F] + n [F] + 1 .  
(*) 
• If F E P, then b[F] == n[F] == 0 and lg[F] == 1 ;  so (*) is verified. 
• If F = -.G, then blF] = b[G], n [F] = n [G] + I ,  and lg[F] = lg[G] + l .  
By the induction hypothesis, lg[G] = 4b[G] + n [G] + I .  It follows that (*) 
is again satisfied. 
• If F = (G a H) (where a is a binary connective), then b[F] = b[G] + 
b[H] + I ,  n [F] = n[G] + n[H], and lg[F] = lg[G] + lg[H] + 3. By the 
induction hypothesis, lg[G] = 4b[G] + n [G] + 1 and lg[H] = 4b[H] + 
n [H] + 1 .  Here too, (*) is satisfied. 
2. (a) Let Xn denote the set of lengths of formulas of height n. Since the formulas 
of height 0 are the elements of P, we have Xo = { 1 } .  
We have proved (Theorem 1 .5) that the height of a formula i s  always 
strictly less than its length. We may conclude from this that every element 
of X n is greater than or equal to n +  1 .  Now the formula -,-t . . .  -.A (with n 
occurrences of the symbol -.) is of length n + I and of height n. This proves 
that n + 1 is an element of X n and that it is the smallest element. 
To convince ourselves that Xn is finite, we note that if all the formulas 
of height n 
- 1 have a length that is at most some integer x, then all the 
formulas of height n will have a length that is at most 2x + 3: to see this, 
observe that if F is a formula of maximum length among the formulas of 
height n - 1 ,  then the length of any formula of height n will be less than or 
equal to the length of the formula (F a F), where a is a symbol for a binary 
connective. Since Xo = { 1 }, we have thereby proved by induction that for 
every integer n, the set Xn is bounded and hence finite (since it is a set of 
natural numbers). Let Ln denote the greatest element of Xn. The argument 
above establishes the following recurrence relation: 
Ln = 2Ln-J + 3. 

246 
S O L U T I O N S  
A classic computation then shows that 
Ln = zn+2 - 3. 
The length of any formula of height n is thus between n + 1 and zn+2 -3, 
where the minimum corresponds to formulas that use n occurrences of the 
negation symbol and no occurrences of symbols for binary connectives 
while the maximum corresponds to formulas in which the negation symbol 
does not occur. The reader may find it amusing to show that all values 
between these two extreme values are possible, except for 
n + 2, n + 3, 2n+2 
- 8, 2n+2 
- 5 and 211+2 - 4. 
3. (a) For any word W on the alphabet P U {-., /\, v, ::}, {:;> ,  ( }, let b[W] denote 
the number of occurrences in W of symbols for binary connectives and 
recall that o[W] is the number of opening parentheses in W. 
In a way that is more or less analogous to the one used for formulas. we 
prove the fallowing four facts by induction: 
(1) Every pseudoformula ends with a propositional variable. 
(2) If F is a pseudoformula, then o[F] = b[F]. 
(3) If W is a proper initial segment of a pseudoformula F, then o[W] > 
b[W]. 
(4) If W is a proper initial segmentofa pseudoformulaandifthe last symbol 
of W is a propositional variable, then o[W] > b[W]. 
From this, it is not difficult to show that 
( 5) A proper initial segment of a pseudoformula cannot be a pseudof ormula. 
We may then continue, as in the case for formulas, and arrive at the unique 
readability theorem for pseudof ormulas: 
For any pseudoformula F, one and only one of the following three situ­
ations is applicable: 
• F is a propositional variable; 
• there is a unique pseudoformula G such that F = -.G; 
• there exists a unique symbol a for a binary connective and a unique pair 
of pseudoformulas H and K such that F = (H a K). 
(b) So we have proved that, for writing formulas, we can very well do without 
closing parentheses. We must avoid jumping to the conclusion that we could 
just as well eliminate opening rather than closing parentheses: the culprit 
here is the presence of the symbol for the unary connective, negation, which 
destroys all symmetry. As an illustration, consider the formula -.(A ==> B) 
which, in the context above, becomes the pseudo formula -, (A =} B; if 
opening parentheses are suppressed, this becomes -.A =} B), but this is 
exactly the same word that would result if the formula -,(A ==> B) were to 
receive the same treatment. So this procedure is doomed to fail. 

S O L U T I O N S  F O R  C H A P T E R  I 
247 
4. (a) T* is the smallest set of words on the alphabet P U {...,, :::} , ) , ( } that includes 
P and is closed under the operations X M ...,X and (X, Y) / (X :::} Y). 
To have an equivalent definition from below, we would set To* = P and 
for every integer n E N, 
ʹ*+ 1 = ʹ* U {..., F : F E '4z*} U { ( F :::} G) : F E ʹ*, G E ॎ*}. 
We would then have T* = UneNʹ*. 
(b) The given conditions allow us to define a unique map /1 from T* into T* by 
induction: /1 is already defined (equal to JL) on To* = P, and, if we assume 
it is defined on ʹ*, the given conditions determine its values on S*+1• 
(c) We argue by induction on G. If G E P, then the only sub-formula of G 
is F = G and, in this case, /i(F) = /i(G) is a sub-formula of /i(G). 
If G = ...,H and if F is a sub-formula of G, then either F = G and 
/l(F) = /l(G) is a sub-formula of /l(G), or else F is a sub-formula of H 
and, by the induction hypothesis, /i(F) is a sub-formula of /i(H), hence 
also of -,/i(H) = /i( -,H) = /i(G). If G = (H => K) and if F is a sub­
formula of G, then either F = G and /i(F) = /i(G) is a sub-formula of 
/i(G), or else F is a sub-formula of H or a sub-formula of K and, by the 
induction hypothesis, /l(F) is a sub-formula of /l(H) or a sub-formula of 
/i(K), hence also of the formula 
-.,(jl(K) =} /l(H)) = /l((H =} K)) = /l(G). 
(d) jlQ((A :::} B)) = _,(...,B :::} _,A) and jlQ((...,A :::} B)) = ...,(...,B => ...,...,A). 
It would obviously be an error to write, for example: 
jlQ((A => B)) = -.(A :::} B), 
despite the fact that these formulas turn out to be logically equivalent. With 
each formula ofT*, the map jlO associates a uniquely determined formula. 
The last property is proved by induction on F. If F E P, ilQ(F) = -.F, 
thus jlQ(F) r-v ...,F. If F = ...,G and if(induction hypothesis) jlQ(G) r-v -,G, 
then ilQ(F) = --,jlQ(G) is logically equivalent to --,-,G = -..,F. If F = 
(G :::} H) and if (induction hypothesis) jlQ(G) r-v -.G and ilQ(H) r-v -.,H, 
then ilQ(F) = -.(jlO(H) :::} fiQ(G)) is logically equivalent to -,(...,H => 
-,G), hence also to -.(G =? G) = -.F. 
5. We will treat question (b) directly since (a) merely presents two special cases. 
A .. s Fn (n E N, n > 2) we take the following formula: 

248 
S O L U T I O N S  
If we set Gn = 1\l<i<n(A; ::} B;), Hn 
= 1\l<i<i<n -,(B; 1\ Bj), Kn 
V 1 <i <n A;, and Ln = /\î <i <n (B; => A;), then we 
-
caԧ write 
Let 8 be an assignment of truth values and suppose that 8(Ln) = 0. This 
means that we can find an index j between 1 and n such that 8(B j) = 1 and 
8(A j) = 0. If we suppose as well that 8(Hn) = 1, then we must conclude that 
for all indices i between 1 and n and distinct from j, we have 8 ( B;) = 0. Now 
let us add the hypothesis that 8(Gn) = 1. Then for all i different from j, we 
must have 8(A;) == 0. But since 8 (A j) is also zero, the conclusion is that 8 does 
not satisfy the formula Kn. In this way, we see that it is not possible for 8 to 
assign the value 0 to Ln while simultaneously assigning the value 1 to Gn, to 
Hn and to Kn. This amounts to saying that 8 cannot assign the value 0 to Fn. 
So this formula is a tautology. 
6. (a) With the help of items 38 and 53 from the list in Section 1 .2.3, we see that 
E is logically equivalent to 
(B => (C ::} (A {:} (B ::} C)))), 
which is a formula that satisfies the required conditions. 
(b) Any assignment of truth values that gives the value 0 to B or to C will 
satisfy the formula E. If 8 is as assignment of truth values such that 8 (B) = 
-
-
8(C) = 1, then 8((..,B v C)) = 1, from which we deduce that 8(£) = 1 
if and only if 8(A) = 1. ThusΓ there is a unique assignment of truth values 
to the set {A, B, C} that makes the formula E false: namely, it assigns 1 to 
B and to C and 0 to A. This observation provides us with the CCNF of the 
formula £: 
(A v _,B v -,C). 
which is, at the same time, in reduced disjunctive normal form. 
(c) It follows from what has just been said that there are seven assignments 
of truth values to {A, B, C} that satisfy E. So there are seven elementary 
conjunctions in the CDNF of E. 
(d) In question (a) we noted that the formula E is logically equivalent to 
(B ::} (C ::} (A {:} (B => C)))), 
but this formula is also logically equivalent to 
(C ::} (B   (A {:} (B ==> C)))) 
(again, refer to item 53 of Section 1 .2.3). Also, the disjunctive normal form 
of E that we found in (b) is clearly logically equivalent to (C ==> (B ::} A)); 
this proves the desired result. 

S O L U T I O N S  F O R  C H A P T E R  l 
249 
7. (a) Let 8 be an assignment of truth values to P that satisfies F and let i be an 
integer between I and n. We see immediately that 
• if 8(A;) 
= 1, then 8(A;+t) = <5 (A;+2) = ... 8 (An) 
= 1; 
• if8(A;) 
= 0, then 8(A;-I) 
= <S(A;-2) = ... 8(AI) 
= 0. 
It follows that the assignments of truth values to P that satisfy F are the 
n + I assignments 8 
P (0 մ p < n) that give the value 1 to the last p variables 
in P and the value 0 to the first n -p variables; specifically: 
{0 if i < n-p; 
8 (A·)-
P 
' 
-
1 
·f · 
I 
l > n -p. 
From this, we may obtain the CDNF ofF: 
(-,AI 1\ -,A2 1\ · · · 1\ -,An) V (_,A, 1\ · · · 1\ -,An-I 1\ An) 
v (_,At 1\ · · · 1\ -,An-2 1\ An-I 1\ An) V . . .  
· · · V (-,AI 1\ A2 1\ • • • 1\ An) V (AI 1\ A2 1\ • • · 1\ An-I 1\ An). 
(b) Let 8 be an assignment of truth values to P that satisfies G. Obviously, 8 
must satisfy F, so 8 must be one of the assignments 8p above. But 8 must 
also satisfy (An => A 1 )  so it is not possible that we have both 8(An) = 1 
and 8 (A 1 )  = 0; this excludes the possibility that 8 could equal 8 
P when 
1 < p < n - 1 .  We easily verify that the assignments of truth values 8o and 
8n (i.e. the two constant assignments) satisfy G. It follows from what was 
just said that these are the only ones. 
We conclude from this that the CDNF of G is 
(-,At 1\ -,A2 1\ · · · 1\ -,An) V (At 1\ A2 1\ · · · 1\ An-1 1\ An). 
(c) The formula (A; => -,A j) is logically equivalent to -,(A; 1\ A 
j ). Con­
sequently, a necessary and sufficient condition for an assignment of truth 
values to satisfy H is that there not exist a pair of distinct indices i and j 
such that 8 (A;) = 8 (A .i) = 1. So the assignments of truth values to P that 
satisfy H are those that give the value 1 to at most one variable in P: these 
are then+ 1 assignments Ap (0 < p < n) defined by 
A (A·)-{0 ifi::f.p 
P 
l -
t ·f · 
I 
l = p. 
(Thus A.0 is the constant assignment equal to 0). We conclude from this 
that the canonical disjunctive normal form of H is 
(-,A 1 1\ -,A2 1\ · · · 1\ -,An) V (A I 1\ -,A2 1\ · · · 1\ -,An) 
V (-,AI 1\ A2 1\ -,A3 1\ · · · 1\ -,An) 
v . . .  
· · · v (-,At 1\ · · · 1\ -,An-2 1\ An-1 1\ -,An) v (-,At 1\ · · · 1\ -,An-I 1\ An). 

250 
S O L U T I O N S  
8. (a) Set F == Vt <i<j<n (Ai A Aj) and G = l\ 1 <i <n <Vj#i Aj). 
Let 8 be an assignment of truth values on P. 
For 8 to satisfy F, it is necessary and sufficient that 8 assume the value l 
for at least two of the variables A t ,  A2, . . .  , An. In order that 8 not satisfy G, 
it is necessary and sufficient that there exist an index i such that 8 (A j) = 0 
for every index j different from i. In other words, 8 (G) = 0 if and only if 8 
assigns the value 1 to at most one of the variables At , A2, . . .  , An. We may 
conclude that 8 satisfies G if and only if 8 assigns the value 1 to at most one 
of the variables A t ,  A 2, . . .  , An. So we see that 8 satisfies G if and only if 
8 satisfies F. The formula (F {:} G) is thus a tautology. 
(b) Set H = V 1 <i <n A; and consider an assignment of truth values 8 on P. 
For 8 to satisfy H, it is necessary and sufficient that 8 assign the value 1 to 
at least one of the variables At , A2, . . .  , An . Now we have just seen that 8 
satisfies G if and only if 8 assigns the value 1 to at least two of the variables 
A 1 ,  A2, . . .  , An· It follows immediately that 
-
-
• if 8 assigns the value 0 to all the variables in P, then 8( G) = 8 (H) = 0; 
• if 8 assigns the value 1 to one and only one of the variables in P, then 
-
-
o (G) == 0 and o(H) = 1; 
• if 8 assigns the value 1 to at least two of the variables in P . then 8 (G) = 
o (H) = 1. 
Thus the assignments of truth values that make the formula (H ¢? G) 
false are precisely the n assignments 81 , 82, . . .  , 8 n defi.ned by 
{ l if i == j 
8· (A · -
l 
j ) -
0 if i # j 
(for 1 ճ i < n and 1 < j < n). 
(c) Once we know the assignments of truth values that make the formula 
( H {:} G) false, we immediately obtain its CCNF: 
(..,A t  v A2 v · · · v An) A (A1 v _,A2 v A3 v · · · v An )  A . . .  
A (At v · · · v An-I v ..,An). 
For I < i < n, the ith of these n clauses is logically equivalent to 
this provides us with the desired result. 
9. Consider a set of five propositional variables: 
P == {A, B, C, D, £}. 
Intuitively, the variable A (respectively, B, C, D, E) will have the value 'true' 
if and only if persona (respectively, hց c, d, e) is present. The safe can be opened 

S O L U T I O N S  F O R  C H A P T E R  I 
251 
if and only if the following propositional formula is satisfied: 
F == (A A B) v (A 1\ C 1\ D) v (B 1\ D A £). 
Let S1 , S2, . . .  , Sn denote the keys to the safe. To be able to open the safe, it 
is necessary and sufficient that for every integer i between I and n, at least one 
person possessing the key S; be present. If, for example, the holders of the key 
S; are persons c and e, the ability to unlock S; is equivalent to the satisfaction 
of the formula (C v £). The ability to open the safe is thus equivalent to the 
satisfaction of the conjunction of formulas of this type (in which i assumes 
the values l ,  2, . . .  , n), i.e. to a formula in conjunctive normal form. Now, as 
we saw above, the ability to open the safe is equivalent to the satisfaction of 
the formula F which is in disjunctive normal form. So it will suffice to find 
a conjunctive normal form for F that is as reduced as possible; the number 
of disjuncts (clauses) in this CNF will correspond to the minimum number of 
keys required and each clause will provide a list of those persons who should 
receive a key to the corresponding lock. By distributing the con junctions over the 
disjunctions in F (which leads to a CNF that has eighteen clauses, each having 
three variables) and then simplifying (using the properties of idem potence and 
absorption as in items (2) and (I 0) from the list of tautologies: for example, 
(B v C v B) becomes (B v C) which then allows us to eliminate (B v C v D) 
and (B v C v £)), we arrive at the following CNF for F: 
(A v B) 1\ (A v D) 1\ (A v £) 1\ ( B v C) 1\ ( B v D). 
Some fastidious verifications would convince us that we cannot further reduce 
the number of clauses. We will not attempt to treat this issue. 
The CNF that we have obtained tells us that the number of locks required is 
five and that one possible distribution of keys consists in giving: 
• to a, the keys for St , S2, and S3; 
• to b, the keys for St, S4, and Ss; 
• to c, the key for S4; 
• to d, the keys for S2 and Ss; 
• to e, the key for S3. 
10. Let 8 be an assignment of truth values to P that satisfies A. Let H 8 denote the 
set of elements i of IZ/15/Z such that 8(Ai) = 1. We see that 0 E H8 and that 
lf8 is closed under the operations i M -i and (i, j) / i + j. This means that 
H 8 is necessarily a subgroup of the group (IZ/ 15/Z, +). Conversely, if H is a 
subgroup of (IZ/ 15/Z, +), then the assignment of truth values 8 defined by 
8 (A;) = { if i E H 
if i ҙ H 

252 
S O L U T I O N S  
clearly satisfies the set A. Now (Z/15Z, +) has precisely the following four 
subgroups: Z/15Z, {0}, {0, 5, 10}, and (0, 3, 6, 9, 1 2}. There are thus four 
assignments of truth values that satisfy A: the one that is constant and equal to 
1, the one whose value is 1 on Ao and 0 elsewhere, the one whose value is 1 on 
Ao, As, and A 10 and 0 elsewhere and, finally, the one whose value is 1 on Ao, 
A3, A6, Ag , and A 12 and 0 elsewhere. 
11. The formulas F.=:;> and Gv are tautologies. The formulas G 1\ ,  G <=?' G::t?, and Gt 
are antilogies. The six other formulas are neutral. 
We list them here and place, below each of them, a simpler formula that is 
logically equivalent. The proofs present no difficulties. 
Fv 
A v B  
F<=? 
B 
F::tr> 
A 
12. (a) The given conditions entirely determine <p: the first tells us that <p must 
assume the value 1 at the points (0, 0, 0), (0, 1 ,  0), (I, 0, 0), and (I, 0, I ) ;  
the second tells us that cp must assume the value 0 at the points (0, 0, 1), 
(0, 1, I, ), (1, 1, 0), and (1, 1 .  1). 
(b) A DNF for <p is given by the following formula: 
(c) lt suffices to take a formula that is logically equivalent to G[A, A ,  A] 
in case I ,  to G[A, B, B] in case 2, to G[A, A ,  B] in case 3, to G [A ,  B, A] 
in case 4, to G[A, G[B, B, B], A] in case 5, and to (G[A, B, B] z 
G[A ,  B, A]) in case 6. Here are some possible answers: 
(1) _,A 
(4) (--rA v _,B) 
(2) -·.,B 
(5) (A  B) 
(3) (--,A 1\ _,B) 
( 6) (--·,A v A). 
(d) As the formula (A v B) is logically equivalent to (-,--·,A v -,-,B) , we will 
refer to case 4 of the preceding question; it is then not difficult to verify that 
the connective 1/f defined by 
for all x and y belonging to {0, 1}, 
1/f(x, y) = <p(<p(x, x, x), <p(y, y, y), <p(x, x, x)) 
i s  precisely disjunction. 
(e) Using composition, the connectives disjunction (question (d)) and negation 
(case 1 of question (c)) can be expressed in terms of the sole connective <p. 
As every connective can be expressed in terms of negation and disjunction, 
it follows that every connective can be expressed in terms of the connective 
<p. Thus, { <p} is a complete system of connectives. 

S O L U T I O N S  F O R  C H A P T E R  I 
13. The solution is 
p == (a A b A d) V (b A C A d) V (a A -.b A c) V (a A C A -.d); 
q = (b A d) <=> (a <=> c) 
r = -,(b {} d). 
253 
It is not difficult to verify this. Here, of course, -, , A, v, and <=> denote 
operations on {0, 1}. 
14. (a) Our concern is to express the connectives as operations in 7lj27l. For all 
elements x and y of this set, we have 
-,X = 1 + X  
X A y = xy 
x ==> y = 1 + x + xy 
X V  y = X +  y + xy 
x {} y = 1 + x + y. 
The verifications are elementary. As usual, we permit ourselves to write 
xy in place of x x y. 
(b) For all elements x and y of'lj2Z, we have 
xy = X  A y; 
X +  y = -,(X {} y) = X  {I} y = (x A -.y) V (-.x A y). 
(c) Obviously inspired by question (a), we define PF by induction. 
• If F is the propositional variable A; (1 < i < n), set PF == X;. 
• If F =  
-,G , set PF = 1 + Pc. 
• If F = (G 1\ H), set PF = Pc x PH. 
• If F =  (G v H), set PF = Pc + PH +  Pc PH. 
• If F = (G ==> H), set PF = 1 + Pc + PcPH. 
• If F = (G {} H), set PF = 1 + Pc + PH. 
We then prove by induction that for every assignment of truth values 
8 E {0, 1 } P, we have 
,..,_, 
8(F) == PF(8(A J ), 8 (A2), . . .  , 8 (An)). 
(*) 
If F is the propositional variable A i ,  we have P F = X;, and the associated 
polynomial function PF is the ith projection, i.e. the map from {0, 1 }P into 
{0, 1} whose value on any n-tuple (ct ,  £2, . . .  , en) is £i · This shows that the 
relation (*) is satisfied. 
If F ::: (G 1\ H) and if (induction hypothesis) for all assignments of truth 
values 8, we have 
-
I"J 
8(G) = Pc (8(A I ), 8 (A2), . . .  , 8(An)) and 
-
ť 
8(H) = PH (8(A J ), 8 (A2), . . .  , 8 (An)), 

254 
S O L U T I O N S  
Ȓ 
, 
, 
then, given that Pp = Pc PH, we would have PF = Pc PH; thus, for any 
assignment 8, 
-
-
-
Pp(8(A t), 8(A2), . . .  , 8(An)) = 8(G)8(H) = 8((G 1\ H)) 
(by definition of 8 ); this proves (*). 
The other steps in the induction are treated in an analogous manner. 
The definition that we have adopted defines, for every formula F, a 
unique polynomial Pp; but we could have chosen others while still preserv­
ing property (*): for example, the polynomial associated with the formula 
(A t ¢> A2) is, according to our definition, 1 + Xt + X2, but it is clear that 
the polynomial 1 + Xf + Xi would work just as well. What is unique, for 
a given formula FҘ is the associated polynomial function (it is the truth 
table of F). 
(d) From what we have just seen, we conclude that for a formula to be a tauto­
logy, it is necessary and sufficient that the associated polynomial (or rather, 
the polynomial function) assume the constant value 1. For two formulas 
to be logically equivalent, it is necessary and sufficient that their associ­
ated polynomial functions coincide. To illustrate this, let us verify that the 
formulas 
G = (A =? (B =? C)) and H = ((A 1\ B) =? C) 
are logically equivalent (to simplify, we have used A, B, and C instead of 
A 1 ,  A2, and A3 and X, Y, and Z instead of X 1 ,  X2, and X3). We have 
Pc = 1 + X +  X ( l  + Y + YZ) = I +  X Y  + XYZ 
(since X -r- Y is the null polynomial), and 
PH = I +  ((XY) + (XY)Z) = 1 + X Y  + XYZ = Pc . 
15. (a) We have seen (Lemma I .34) that if the formulas F and G have no propo­
sitional variable in common, and if the formula (F =} G) is a tautology, 
then either the formula G is a tautology or the formula F is an antilogy. It 
is obvious that in the first case, the formula T is an interpolant between F 
and G while in the second case, the formula l. is an interpolant between F 
and G. 
(b) The proof is by induction on F. If the height ofF is 0, this is obvious. We 
then simply need to verify that, given two formulas G and H, if both of 
them are logically equivalent to one of the three formulas T, l..қ and A, then 
the same is true for (G 1\ H) and (G v H); this presents no difficulty. 
(c) The argument is analogous. This time, we show that if each of the formulas 
G and H is logically equivalent to one of the eight formulas T, l., A, B, 
-,A, --,B, (A ¢> B),-,(A <:> B), then this is also the case for the formulas 

S O L U T I O N S  F O R  C H A P T E R 1 
25:5 
( G 1\ H) and ( G v H). There are 64 cases to examine but some elementary 
arguments allow us to reduce this number considerably. 
(d) Since we already know that the systems { ȑ..,, v} and {···,, /\} are complete, to 
show that a given system of connectives is complete, it suffices to prove that 
the connectives ..., and /\, or else the connectives ..., and /\, can be obtained by 
composition from the system of connectives under consideration. We will 
apply this remark to the systems that have been proposed. For all elements 
x and y belonging to {0, 1}, we have 
• -,x = x Β 0 and x v y = (x श 0) Β y; hence {Β, 0} is complete. 
• -,x = x ¢> 0 and v E {0, ¢>, v}; hence {0, ¢>, v} is complete. 
• -,x = x ¢> 0 and 1\ E {0, ¢>, 1\}; hence {0, ¢>, /\} is complete. 
• -,x = x'{tx and x 1\ y = (x'{ty)'{t(x'{ty ); hence {हt} is complete. 
• -,x = xt}x and x v y = (xt}y)t}(xt}y); hence {,ष} is complete. 
(Here, the symbols ...,, /\, v, :::}, ¢>, t, and !}denote operations on {0, 1 }.) 
(e) Let 81 denote the assignment of truth values to P that is constant and equal 
to 1 and let 1t denote the set of formulas that can be written using the 
symbols for connectives T, =?, 1\, and v, to the exclusion of all others. 1-{ 
is defined inductively as the smallest set of formulas that includes P U {T} 
and that is closed under the operations 
(M, N) t-7 (M  N), (M, N) M (M 1\ N) and (M, N) L (M v N). 
(We may compare this with Exercise 20). By induction, we show that the 
assignment of truth values 81 satisfies all the formulas that belong to 11. For 
the propositional variables, this is true by definition of 81 ; it is also true for 
the formula T, hence for all formulas in 1t of height 0. Assuming that f' 
and G are two formulas of 'H such that 81 (F) = 81 (G) = 1, then we have 
81 ((F => G)) = 81 ((F 1\ G)) = 81 ((F v G)) = l .  
It follows from this that the formula ...,A is not equivalent to any formula of 
1t since 81 (-,A) = 0. The conclusion is that {1, :::} , 1\, v} is not a complete 
system. 
It is easy to find a formula, -.A for example, that is not logically equivalent 
to any of the three formulas T, ..L, and A. We conclude from this, by virtue 
of question (b), that -.A is not logically equivalent to any formula that can 
be written using the variable A and only the connectives T, _L, /\, and v ;  this 
shows that the system {/\, v, 0, 1 }  is not complete. One may object that we 
have not considered the possibility that _,A could be logically equivalent to 
a formula that involves only the connectives T, _L, /\, and v but that might 
involve variables other than A: if G were such a formula, the formula G' 
obtained from A by replacing all occurrences of variables other than A by 
T would still be equivalent to -.A (Lemma J . 1 9) and this would contradict 
what we proved earlier. 

256 
S O L U T I O N S  
A similar argument, using question (c), will show that the system { 0, 1, -., 
{} } is not complete. Consider, for example, the formula (A v B) which is not 
logically equivalent to any of the eight formulas in the set E of question (c). 
From this, we conclude that it is not logically equivalent to any formula 
that can be written using only the connectives T, 1_, -., and {}. (If such a 
formula existed, we could find one that is logically equivalent, that is written 
with the same connectives and with the propositional variables A and B 
alone.) 
(f) Refer to the tables of one-place and two-place connectives given in 
Section 1.3. No system of one-place connectives is complete: for example, 
the formula (At v A2) is not logically equivalent to any formula written 
with only the connectives T, 1_, and -.,. 
Let us now prove that, with the exception of cpg and cprs, no two-place 
connective constitutes, by itself, a complete system. As far as cp2, cp4, cp6, 
cps, cpro, cp12, cp14, and cp16 are concerned, notice that each of these connec­
tives assumes the value 1 at the point (1, 1), which proves that the con­
nective cps, for example, which assumes the value 0 at the point (1, 1), 
cannot be obtained by composition from one of these (nor from several of 
these, for that matter). This argument was already used in another form, 
in question (e) to show that the system {1, ==> ,  1\, v} (which is none other 
than {CfJ2 ,  cpg, cp14, cpr6}) is not complete. A kind of dual argument applies 
for connectives that assume the value 0 at (0, 0): the case of cp1 , cp3, cps, and 
cp7 are thereby settled. As for cp] 1 and cp13, they really depend on only one 
of their arguments; so if either of these constituted a complete system by 
itself, the same would be true for the corresponding one-place connective 
and we have seen that this is not true. Since we said in question (d) that 
each of the connectives <pfJ and cp IS constitutes a complete system, we have 
arrived at the desired conclusion. 
16. (a) We have already indicated, several times, the logical equivalence between 
(A {} (B {} C)) and ((A {} B) {} C) (item 58 in Section 1.2.3 ); we could 
check this with the help of the corresponding polynomials in Z/2Z[X, Y, Z] 
(Exercise 14) or, as well, by verifying that these two formulas are sat­
isfied by precisely the same assignments of truth values to {A, B, C}, 
namely (0, 0, 1), (0, 1, 0), (1, 0, 0), and (1, 1, 1). As for the formula ((A {} 
B) 1\ (B {} C)), it is satisfied by the two assignments of truth values 
(0, 0, 0) and (1, 1, 1) and only these; it is therefore not logically equivalent 
to (A {} (B {} C)). Now it is a nearly universal practice, in contemporary 
mathematics, to write equivalences in a 'chain'; for example, when we say of 
three properties I, II, and III that they are equivalent, which we would write 
I{} II{} III, what we mean is that either all three of them are true or else that 
all three of them are false; and we, in effect, interpret the written expression 
I{}II{}Ill as (1{}11) 1\ (II{}III) and certainly not as (I{}(II{:}III)) which, 

S O L U T I O N S  F O R  C H A P T E R  I 
257 
as we have seen, has a different meaning. Naturally, this goes against the 
usual conventions relating to associativity which, were they applied in this 
case, would lead to interpreting I{:} II{:} III indifferently, as an abbreviation 
for either (I%(II%III)) or ((I<:>II)%III). That is the reason why, in this 
particular case, it is important not to use any abbreviations: neither the one 
suggested by associativity, for the formula (A % (B % C)), nor the one 
dictated by mathematical practice, for the formula ((A $ B) 1\ (B <=> C)). 
(b) The argument is by induction on the cardinality, n ,  of the set B. For n = 2p. 
it is obvious. Suppose that the property is true for all sets of cardinality less 
than n and let us prove it if the cardinality of B is equal to n. 
Let F E Q(B). It is appropriate to distinguish three cases: 
• The formula F has the form (H % B), where B is a propositional variable 
belonging to B and H E Q(B - { B}). For an assignment of truth values 
8 to satisfy F, it is necessary and sufficient that one of the following two 
situations holds: 
(i) 8 satisfies H and B 
(ii) 8 does not satisfy H nor B .  
In case (i), there are an even number of elements of B - { B }  that are 
not satisfied by 8 and exactly the same number in B. In case (ii), there are 
an odd number of elements of B - { B }  that are not satisfied by 8 and, as 
8(B) == 0, there are an even number in B. 
• The formula F has the form (B $ H), where B is a propositional variable 
in B and H E Q(B - {B} ). The same analysis applies. 
• There exists a partition of B into two sets B1 and fn, each having at least 
two elements, and formulas H1 and H2 belonging respectively to Q(BI ) 
and Q(B2) such that F = (Ht % H2). For 8 to satisfy F, it is necessary 
and sufficient that 8 satisfy both H 1 and H2 or else that 8 satisfy neither 
H 1 nor H2. In the first case, the number of propositional variables in B 1 
that are not satisfied by 8 is even (by the induction hypothesis) and so 
is the number of propositional variables in B2 that are not satisfied by 8 
which, i n  all, make an even number. In the second case, the number or 
propositional variables in Bt that are not satisfied by 8 is odd and so is the 
number of propositional variables in B2 that are not satisfied by 8, which) 
once again, make an even number in all. 
(c) We prove by induction on the cardinality of the set B that, for every formula 
"' 
G E Q(B), the formula G is satisfied by an assignment of truth values 8 
if and only if 8 satisfies an odd number of propositional variables in B. 
The proof is analogous to the one for (b). The required equivalence follows 
immediately. 

258 
S O L U T I O N S  
(d) Let x E E .  For each integer i between 1 and k, we introduce a propositional 
variable A; and define the assignment of truth values 8 by 
8(Ai) = ] if and only if x E Xi . 
We easily see, by induction on the integer k, that x E X 1 t:J,.X 2l:J,. . . .  t:J,.X k 
if and only if 8 satisfies the following formula F: 
the result now follows from question (c). (Also see Exercise 2 from 
Chapter 2.) 
17. (a) We argue by contradiction. If the formula 
is not a tautology, there exists an assignment of truth values 8 that satisfies 
the formulas F[A 1 ,  A2, . . .  , An, A] and F[A 1 ,  A2, . . .  , An, B] and does 
not satisfy the formula (A <:> B). But, by hypothesis, 8 must satisfy the 
formula 
since this is a tautology, as well as the formula obtained by substituting B 
for A in the preceding, namely, 
(F[A t ,  A2, . . .  , An , B] :::} (G[A 1,A2, . . .  , An] ¢;> B)). 
Since8(F[A 1 ,  A2, . . .  , An, AJ) = 8(F[A I , A2, . . .  , An, B]) = 1, we must 
have 
8(G[A 1.A2, . . .  , A11]) = 8(A) = 8(B), 
which is incompatible with the fact that 8 does not satisfy (A $ B). 
(b) For each of the cases under consideration, we present formulas G [A 1 ,  
A2, . . .  , An] that are possible definitions of A modulo F (these need not be 
unique). The verifications are immediate and are left to the reader. 
( 1 )  G = A  1 
(2) G = A 1  or G = A2 
(3) G = At or G = A2 or G = (AI v ..,A I )  
(4) G = (A J v _,A J )  or G = _,A2 
(5) G = (AI v _,A I )  or G = (At ¢> (A2 ¢> A3)). 
18. (a) It suffices to prove that if cp F( cJ , £2, . . . , En, 1) = 1, then we do not have 
cp F(El , £2, . . .  , En, 0) = 1. We argue by contradiction. If these two equal­
ities were verified, this would mean that the assignments of truth val­
ues 'A and Ji.· on {A t ,  A2, . . .  , An, A }  defined by 'A(A J )  = Jl.(AI )  = £I, 
'A(A2) = tL(A2) = c2, . . . , 'A(An) = tL(An) = en, 'A(A) = 1 and p,(A) = 0 

S O L U T I O N S  F O R  C H A P T E R  I 
259 
both satisfy the formula F[A 1 ,  A2, . . .  , An, A]. This amounts to saying that 
the assignment of truth values 8 on { A t ,  A2, . . .  , An, A ,  B }  defined by 
simultaneously satisfies the formulas 
As we have assumed that 
is a tautology, 8 must also satisfy (A <=> B); but this contradicts the definition 
of 8. 
(b) Having chosen G as indicated, let us consider a distribution of truth values 
8 on {A 1 ,  A2, . . .  , An, A }  that satisfies the formula F[A 1 ,  A2, . . .  , An, A] 
and set 
• If 8 (A) = 0, then cpF(8I , 82, . . .  , 8n , 0) = 1, hence cpc (8 I ,  82, . . .  , 8n) = 
1/1 (8 1 ,  82, . . .  , 8n) = 0, which means that 8 (G) = 0. 
• If 8 (A) = 1, then cpF(8I , 82, .
•
.
 , 8n , 1) = l ,  hence according to the first 
question, cpc (81 ,  82, . . .  , 8n) = 1/1(81 , 82, . . .  , 8n) = 1, which means that 
8 (G) = 1. 
So in every case, 8 (A) = 8 (G), which shows that 8 satisfies the formula 
(G[A 1 ,  A2, . . .  , An] <=> A). Thus we have proved that the formula 
is a tautology, since every assignment that satisfies the left side of this 
implication also satisfies the right side. 
19. (a) A formula is determined, up to logical equivalence, by its truth table or, 
which amounts to the same thing, by the set of assignments of truth values 
that satisfy it. Thesetofassignments oftruthvalueson P = {A, B, C, D, £] 
has 25 = 32 elements. There are therefore 17C32 subsets that have seven­
teen elements. If one prefers, there are 17 C 32 ways to place seventeen 1s and 
fifteen Os in the last column of a truth table that has 32 lines. Consequently, 
there are, up to logical equivalence, 
32! 
17C32 = 
= 565 722 720 
17! 15! 
formulas that are satisfied by seventeen assignments of truth values (whereas 
there are 232 = 4 294 967 296 equivalence classes for the equivalence 
relation on formulas that is logical equivalence). 

260 
S O L U T I O N S  
(b) Let A denote the set of assignments of truth values 8 on {A, B , C, D, E} that 
satisfy 8(A) = 8 (B) = 1. For a formula to be a consequence of (A 1\ B), it 
is necessary and sufficient that it receive the value 1 for all the assignments 
that belong to A .  There are eight such assignments (we extend each of the 
eight assignments from { C, D, E} into {0, 1} by setting their values on A 
and B equal to l). A formula that is a consequence of (A 1\ B) is therefore 
determined, up to logical equivalence, by the set of assignments of truth 
values, other than the eight required, that satisfy it. So there are as many 
such formulas as there are subsets of the set {0, l }P 
- A, which is to say, 
224 = 16 777 216. 
If one prefers, in the last column of the truth table of a formula that is a 
consequence of (A 1\ B), the value 1 must appear in the eight lines corre­
sponding to the assignments of truth tables in A ;  in the other 24 lines, we 
may arbitrarily place the values 0 or 1; this leads to exactly 224 possible 
truth tables. 
20. (a) We argue by induction on F. If F is a propositional variable, we may 
obviously take the formula G to be F itself. Next, let H and K be two 
formulas with which we have associated (induction hypothesis) negation­
free formulas H' and K' such that H is logically equivalent to H' or to -,H' 
and K is logically equivalent to K' or to -,K'. 
We will distinguish four possibilities: 
1 I .  H "' H' and K "' K'; 
1 0. H "' H' and K "' -.K'; 
OL H "' -.H' and K ""' K'; 
00. H ""' -,H' and K ""' -.K'. 
We will prove that in each of the following five cases: 
I. 
F = -.H 
11. F = (H 1\ K) 
III. F = (H v K) 
IV. F = (H :::} K) 
V. 
F = (H <=> K) 
we can find a formula G that does not involve negation and is such that F 
is logically equivalent either to G or to -.G. 
I. If H is logically equivalent to H', F is logically equivalent to -.H'; if 
H is logically equivalent to -.H', F is logically equivalent to -·-.H', hence 
to H'; we may therefore take G = H'. 
II. In case 1 1 , we take G = (H' 1\ K') and we have F 
- G. In case 
10, we take G = (H' :::} K') and we have F "' -.G. In case 0 1 ,  we take 
G = (K' :::} H') and we have F "' -.G. Finally, in case 00, we take 
G = (H' v K') and we have F "' -.G. 

S O L U T I O N S  F O R  C H A P T E R  I 
261 
III. In case 1 1, we take G = (H' v K') and we have F 
r-v G. In case 
1 0, we take G = ( K' =} H') and we have F 
r-v G. In case 01. we take 
G = (H' => K') and we have F 
r-v G. Finally, in case 00, we take 
G = (H' 1\ K') and we have F r-v -,G. 
IV. In case 1 1, we take G = (H' =} K') and we have F 
r-v G. In 
case 1 0, we take G = (H' 1\ K') and we have F r-v -,G. In case 0 1 ,  we 
take G = (H' v K') and we have F r-v G. Finally. in case 00. we take 
G = (K' ͑ H') and we have F r-v G. 
V. I n cases 1 1  and 00, we take G = ( H '  <¢:> K') and we have F r-v G. In 
cases 10 and 00, take G = (H' ¢> K') and we have F "' -,G. 
(b) It is obvious that (i) implies (ii). To see that (ii) implies (i) is not difficult: 
as the formula (G <¢:> H) is logically equivalent, for all formulas G and H, 
to ((G =} H) 1\ (H =} G)), any formula written using thefourconnectives 
1\, v, =}, and ¢} is logically equivalent to a formula that can be written 
using only the first three of these symbols. (Perfectionists would prove this 
by induction on F.) Let us now prove the equivalence of (ii) and (iii). 
(ii) implies (iii). We can see this by induction on the height of formulas 
F written without negation: if it is a variable, 8 1  (F) = 1 by definition of 
8 1 ,  if it is (G 1\ H), (G v H), (G =} H), or (G ¢} H), where 81 (G) = 1 
-
-
and 81 (H) = 1, then we obviously have 81 (F) = 1 also. 
Conversely, let F be a formula such that 81 (F) = 1. According to (a), we 
can find a negation-free formula G such that F is logically equivalent either 
to G or to -lG. As G is negation-free, we may conclude, knowing that (ii) 
-
-
implies (iii), that 8 1  (G) = 1 = 8 1  (F). It is therefore not possible for F to 
be logically equivalent to -,G; F is consequently logically equivalent to G. 
We have thus shown that (iii) implies (ii). 
21. (a) The reflexivity, transitivity, and anti symmetry of the relation << are proved 
without difficulty. This is certainly an order relation, but this is not a tota] 
ordering: if n > 2, the assignments of truth values A and 11- defined by 
A(A I )  = 0, M (A t )  = 1, A(Ai) = 1, and M(A;) = 0 for 2 < i < n do not 
satisfy A. << 11- nor 11- << A. 
(b) The formula (A 1 =} A2) is an example of a formula that is not increasing 
and whose negation is not increasing: to see this, it is sufficient to consider 
the assignments of truth values A, /J-, and v defined by 
A (A i )  = 0 for all i E { 1 , 2, . . .  , n } ; 
M(Al ) = 1 and M(Ai) = 0 for all i E {2, 3, . . .  , n}; 
v ( A  i )  = 1 for all i E { 1. 2 . . . . , n } . 
So we have A << /J-, A.(F) = 1, and M (F) = 0; hence F is not increasing. 
On the other hand, 11- << v, p.,( _,F) = 1, and v(-.,F) = 0; hence -,p is not 
. 
. 
tncreastng. 

262 
S O L U T I O N S  
(c) First we prove 'if'. It is clear that if F is a tautology, or if -.F is a tautology 
(i.e. F is an antilogy), then F is increasing. Let C denote the set of formulas 
in which the symbols ...,, =}, and {} do not occur. Because it is evident that 
any formula logically equivalent to an increasing formula is itself increasing, 
it suffices to prove that if F belongs to C, then F is increasing. We prove 
this by induction on the height of the formula F: it needs to be proved that 
propositional formulas are increasing (this is obvious) and that if G and H 
are increasing, then so are (G 1\ H) and (G v H); this is not very difficult. 
Next we prove 'only if'. Let F be an increasing formula that is neither 
a tautology nor an antilogy. We must prove that there exists a formula G 
belonging to C, defined above, that is logically equivalent to F. 
Let !:l.(F) denote the set of assignments of truth values that satisfy F: 
!:l.(F) = {8 E {0, 1}P : 8(F) = 1}. 
For an arbitrary assignment of truth values 8, set 
V+(8) = {A E P :  8(A) = 1}. 
Note that the sets defined this way are finite and that !:l. (F) is not empty 
(otherwise -.F would be a tautology). We also see that for every 8 belonging 
to !:l. F), V + ( 8) is not empty: for there is only one assignment of truth values 
8 for which V+(8) = 0, namely the assignment 8o defined by 8o(A) = 0 
for all propositional variables A. And if 8o belonged to !:l.(F), we would 
have 8o(F) = 1; but as F is increasing and since every assignment of truth 
values 8 satisfies 8o << 8, we would also have 8 (F) = 1 for all 8 E {0, 1 }P; 
but this is impossible since F is not a tautology. 
We may thus define the formula 
G =  V ( f\ A) 
oE6.(F) 
AEV+(o) 
which is clearly an element of the set C. 
Now let us show that F and G are logically equivalent. Let /.. be an 
assignment of truth values on P that satisfies F; it follows that /.. E !:l.(F), 
hence the formula /\AEV+(A)A isoneofthe terms in the disjunction that is the 
formula G. Since we have, by definition, that /..(A) = 1 for all A E V+(/..), 
-
-
we conclude that /..(1\AEV+(o)A) = 1 and hence that /..(G) = 1. Conversely, 
if J.l is an element of {0, l}P that satisfies G, there exists an assignment of 
truth values 8 E !}.(F) such that f.l(/\AEV+(o)A) = 1; this means that for 
all A belonging to V +(8), J.l(A) = t which in turn means that for every 
propositional variable A, if 8 (A) = 1, then J.l (A) = 1; in other words, for 
every propositional variable A, 8(A) < J.l(A); this says that 8 << J.l. Since 
8 E !:l. (F) (so 8(F) = 1) and F is an increasing formula, it follows that 
਼(F) = 1. We have established that F and G are satisfied by exactly the 

S O L U T I O N S  F O R  C H A P T E R  l 
263 
same assignments of truth values to P; so the two formulas are logically 
equivalent. 
22. Given a finite set of formulas { Ft .  F2, . . . .  FkL to show that it is independenţ 
it suffices to find, for each index i, an assignment of truth values that satisfies 
all the Fj (j =/: i) and that does not satisfy Fi ; on the contrary, to prove that it is 
not independent, we show that one of the Fi is a consequence of the others. 
In the situation where the set of formulas under consideration is not indepen­
dent, we invoke the following observation when we wish to find an equivalent 
independent subset: if A is a set of formulas and if the formula F is a conse­
quence of A - {F}, then the sets A and A - {F} are equivalent. 
(a) We will only treat sets ( 1 ), (2), and (6). None of the other sets is independent. 
(1) The set {(A =} B), (B => C), (C =} A)} is independent. Note that 
the assignment of truth values 8 defined by 8 (A) = 1, 8(B) = 0., and 
8 (C) = 1 does not satisfy the first formulas but does satisfy the other 
two; similarly, we note that any assignment of truth values that makes 
one of these formulas false will necessarily satisfy the other two. 
(2) The set {(A =} B), (B =} C), (A => C)} is not independent since 
{(A => B), (B => C)} 1-* (A =::} C). 
The subset {(A => B), (B =} C)} is independent and is equivalent 
to the given set. It is easy to see that this is the only subset with this 
property. 
(6) The set {((A =} B) =} C), (A =::} C), (B => C), (C =} (B => A)), 
((A => B) => (A <=> B))} is not independent; observe that the last 
formula is equivalent to (B =} A) and so the next to last formula is a 
consequence of it. There are two independent equivalent subsets: 
{ ((A =} B) =} C), (A =} C), (C =} (B =} A))} and 
{ ((A =} B) =} C), (A => C), ((A => B) => (A <=> B))}. 
(b) The empty set is independent: if it were not, it would contain a formula 
F such that 0 - {F} Ś* F; this is obviously impossible. If A = { G}, 
then A - { G} J=* G is equivalent to 0 Ś* G (which means that G is 
a tautology). Consequently, a necessary and sufficient condition for a set 
containing a single formula to be independent is that this formula is not a 
tautology. 
(c) We establish this property by induction on the number of formulas in the 
set. [t is true when this number is 0 because 0 is an independent subset that 
is equivalent to 0. Suppose that every set containing n formulas has at least 
one equivalent independent subset and consider a set A of n + 1 formulas. 
If A is independent, it is itself an independent subset equivalent to A. If not, 
then we can find in A a formula F that is a consequence of B = A
- {F}. B, 
which contains n formulas, hasӜ by the induction hypothesiş an independent 

264 
S O L U T I O N S  
subset C that is equivalent to B. But B is equivalent to A according to the 
remark at the beginning of this solution. As a result, C is a subset of A that 
is independent and equivalent to A. 
Remark: Concerning this proof, there are two errors to be avoided (which, 
by the way, are related). The first consists in believing that if A is an 
independent set of formulas and if F is a formula that is not a consequence 
of A, then A U { F} is independent. The second consists in thinking that a 
maximal independent subset of a set of formulas is necessarily equivalent to 
this set. The example that follows shows that these two ideas are incorrect. 
Let A = {A}, F = (A 1\ B) and B = A U  {F}. We see immediately 
that A is independent, that F is not a consequence of A, that A U { F} is 
not independent and that A is a maximal independent subset of B but is not 
equivalent to B. 
(d) If A is an independent set of formulas and if B is a subset of A (finite 
or not), then B is independent. Now suppose that A is a set of formulas 
that is not independent. So there is at least one formula G in A such that 
A - { G} 1-* G. According to the compactness theorem, there is some 
finite subset B of A - { G} such that B 1--¥ G. Set C = B U { G}; we then 
have C - { G} r-* G, which proves that C is a finite subset of A that is not 
independent. Thus, for a set of formulas to be independent, it is necessary 
and sufficient that all its finite subsets are independent. 
(e) For each integer n > I ,  set Fn = A 1 1\ A2 1\ · · · 1\ An and let A denote 
the set { Fn : n E N*}. For n < p, Fn is a consequence of Fp; thus the 
only subsets of A that are independent consist of a single element. It is 
also clear that for every n, fԫ+ 1 is not a consequence of Fn Gust take the 
assignment of truth values that satisfies A 1 ,  A2, . . .  , A11 and not An+d; 
it follows that no independent subset of A can be equivalent to A. None 
the less, there exist independent sets that are equivalent to A, for example, 
{A t .  A2, .
.
.
•
 A,p . . .  }. 
(f) We seek a set of formulas equivalent to :F = {Fo. Ft , . . .  , Fn •
.
.
.
 }. First, 
we obtain a set that is equivalent to :F by removing those formulas F n that 
are a consequence of { Fo, Ft , . . . , F਽-d. In other words, we may assume 
thatforevery n, the formula F n is not a consequence of { Fo, F1 , . . .  , Fn-I} 
and, in particular, that Fo is not a tautology. We then consider the following 
set Q: 
Q = {Fo, Fo =} Ft . (Fo 1\ Ft ) ::} F2, . . .  , 
(Fo 1\ F1 1\ · · · I\  Fn) ::} Fn+J , . . .  }. 
It is clear that i f  an assignment of truth values satisfies all the formulas Fn, 
then it satisfies Q; conversely, if it satisfies all the formulas in Q, then we 
see, by induction on n, that it satisfies all the formulas Fn. The sets F and 
Q are thus equivalent. We will show that Q is independent by exhibiting, for 

S O L U T I O N S  F O R  C H A P T E R  I 
265 
every formula G in Q, an assignment of truth values that does not satisfy G 
but that satisfies all the other formulas of Q. 
• If G == Fo, we take an assignment that makes Fo false (one exists since 
Fo is not a tautology). The other formulas of Q are then all satisfied. 
• If G = (Fo 1\ F1 1\ · · · 1\ Fn) ==> Fn+I , we choose an assignment of 
truth values 8 that satisfies Fo, Fr , . . .  , Fn and that makes Fn+ 1 false 
(one exists since Fn+l is not a consequence of {Fo, F1 , . . . .  Fn-1 }); it is 
easy to verify that 8 has the required properties. 
23. (a) For each a E E, consider the formula Fa : 
Fa = ( V Aa,i) 1\ ( (\ 
-,(Aa ,i 1\ Aa,j)) , 
1 <i<k 
l <i<}<k 
and for every pair (a, b) E £2, the formula: 
Ha,b = (\ -(Aa.i 1\ Ab,i ). 
I <i<k 
We will show that G is k-colourable if and only if the set 
A(E, G) = {Fa : u E E} U { Ha,b : (a, b) E G} 
is satisfiable. If f is a function from E into { 1, 2, . . . , k} that satisfies the 
conditions that are required for G to be k-colourable, we define the assign­
ment of truth values 8 by 
8(Aa,i ) == 1 if and only if f (a ) == i, 
and we easily see that 8 satisfies all the formulas in A(E. G). 
Conversely, suppose that we have an assignment of truth values 8 that 
satisfies all the formulas in A(E, G). Let a E E. The fact that F n is satisfied 
by 8 means that there is one and only one integer i between 1 and k such 
that 8(Aa,i ) = 1; denote this integer by f(a). The fact that 8 satisfies the 
formulas Ha,b for (a, b) E G shows that if (a, b) E G, then f(a) i= f(b). 
G is therefore k-colourable. 
(b) It is clear that if a graph is k-colourable, then all its subgraphs and, in 
particular, all its finite subgraphs are k-colourable. Conversely, suppose 
that all the finite subgraphs of G are k-colourable. We will establish that G 
is k-colourable by showing that A(E, G) is satisfiable and, to do this, we 
willinvokethecompactnesstheorem. So letA be a finite subset of A(E, G). 
Let E' denote the subset of points a in E such that for some integer i, the 
variable Aa,i occurs in some formula of A and let G' denote the restriction 
of G to E'. G' is a finite subgraph of G and A c A(E', G'). Since G' is 
k-colourable, A(E', G') is satisfiable (question (a)) and so too is A. Hence, 
by the compactness theorem, A(E, G) is satisfiable and G is k-colourable 
(question (a)). 

266 
S O L U T I O N S  
The following illustration explains the terminology used in this exercise. 
For E, take a set of countries and for G the relation 'have a common bor­
der that does not reduce to a single point'; in this context, k-colourability 
corresponds to the possibility of attributing a colour to each country (in 
view of producing a geographical map), the diverse colours available being 
E 1 ,  £2, . . .  , Ek. The obvious constraint is that bordering countries must 
always receive distinct colours. Cartographers rarely have to deal with an 
infinite set of countries, so this exercise is of no great use to them. It is 
rather the problem of finding the smallest possible value for k that con­
cerned specialists in graph theory for a long time. The conjecture was that 
this smallest value is 4 (for a certain class of graphs that are not too com­
plicated): this was the famous four-colour problem that remained unsolved 
until 1986, when two American mathematicians together with a number of 
powerful computers produced a 'proof' of this conjecture. The quotes are 
justified here by the fact that, even if the number of pages of this book were 
increased beyond anything the reader might imagine, and if we had the nec­
essary competence, we would still be hard pressed to provide it here . . . .  
This is the first example of its kind for a theorem of mathematics. The only 
thing that logic has taught us is that the four-colour problem is no easier for 
finite sets than it is for infinite sets. 
24. (a) Intuitively, the propositional variable Ax,y has the value 1 if and only if x 
is less than or equal to y. We set: 
and 
B(G) == {Ax,x : X E G}; 
C(G) == {(Ax,y 1\ Ay.z) =? Ax,z : X E G, y E G, Z E G}; 
V(G) = {(Ax.y <#? Ay,x) : X  E G, y E G, X # y}; 
E(G) = {Ax.y =} Ax·z,y·z : X  E G, y E G, Z E G}; 
A(G) == B(G) u C(G) u V(G) U E(G). 
Suppose that the group G is orderable. Let < be a total ordering on G that is 
compatible with the group operation. Define an assignment of truth values 
8 on P by setting: 
for all elements x and y of G, 
8((x, y)) == 1 if and only if x < y. 
This assignment satisfies all the formulas in A( G): those in B(G) because 
the relation < is reflexive, those in C (G) because it is transitive, those 
in V(G) because it is antisymmetric and total, and finally, those in E(G) 
because it is compatible with the group operation. 
We have thus shown that the set A( G) is satisfiable when the group 
G is orderable. Conversely, suppose that A( G) is satisfiable. Let A. be an 

S O L U T I O N S  F O R  C H A P T E R  1 
267 
assignment of truth values that satisfies it and define a binary relation R on 
G as follows: 
for all elements x and y of G, 
(x, y) E R if and only if A.(Ax,y) = 1. 
The fact that the sets B(G), C(G), and E(G) are satisfied shows that R is 
reflexive, transitive, and compatible with the group operation. Also, R is 
antisymmetric and total because A. satisfies the formulas in V( G). This rela­
tion is therefore a total ordering that is compatible with the group operation, 
i.e. G is orderable. 
(b) If a group is orderable, it is clear that all its subgroups (in particular, the 
subgroups of finite type) are orderable (by the restriction to the subgroup 
of the order on G). It is the converse of this property that is not obvious. 
Suppose that (G, ·, 1) is a group all of whose subgroups of finite type are 
orderable. According to (a), to prove that G is orderable, it suffices to show 
that the set of formulas A( G) is satisfiable. By the compactness theorem, 
it is then sufficient to show that every finite subset of A( G) is satisfiable. 
Let U be a finite subset of A( G). Let M denote the set of elements of G 
that appear in at least one formula of U; this is, of course, a finite subset of 
G, so the subgroup, H, that it generates is of finite type. According to our 
hypothesis, H is orderable, hence (question (a)) the set of formulas A( H) 
is satisfiable. Because U is included in A(H), U is therefore satisfiable. 
(c) First we will show the easy part of the equivalence: if an abelian group is 
orderable, then it is torsion-free. Let (G, ·, 1) be an abelian group that is 
ordered by <. Suppose that G is a torsion group, i.e. that there is an element 
x in G, distinct from 1, and a non-zero natural number n such that xn = 1. 
(Such an element x is called a torsion element). Because the ordering < is 
total, we have either 1 < x or x < 1. If we suppose that 1 < x, then using 
the compatibility of < with the group operation ·, we obtain successively 
It follows that x < 1 by transitivity and hence, by antisymmetry, x = 1, 
which is not possible. In a similar way, we arrive at a contradiction from 
the assumption that x < 1. Thus the group is torsion-free. 
Let us now tackle the other implication. Suppose that ( G, · ,  1) is a torsion­
free abelian group and consider a subgroup, H, of G of finite type. Then 
H is also a torsion-free abelian group (for a torsion element in H would 
obviously be a torsion element in G also). If H is the trivial subgroup {1}, 
it is obviously orderable. If H is non-trivial, then by the theorem stated as 
part of the exercise, there is a non-zero natural number p such that (H, · ,  1 )  
is isomorphic to the group (ZP, +, 0). Now the group (G, ·, 1) is orderable: 
it suffices to consider the lexicographical ordering on ZP, specifically, if the 
elements (at , a2, . . .  
, ap) and (hi , b2, . . .  , b p) of ZP are distinct and if k 

268 
S O L U T I O N S  
is the smallest of the indices i between 1 and p such that ai # bi, then 
This is clearly a total ordering and it is compatible with the group operation 
(which, in this case, is coordinate-wise addition): more precisely, if 
then for any element (c1 , c2, . . .  , cp) of 7lP, we also have 
which is to say, 
( Q I + C I , a2 + C2, . . .  , a p + C p) < ( b I + C J , b2 + C2, •
.
• 
, b p + C p). 
If cp is an isomorphism of the group (G, · ,  1) onto the group (ਾP, +, 0), 
then the binary relation -< defined on H by 
for all elements x and y of H, 
x --< y if and only if cp(x) < cp(y) 
is a total ordering on H that is compatible with the group operation (what 
we are saying here is that any group that is isomorphic to an orderable group 
is orderable ). 
We have just proved that every subgroup of (G, · ,  1) of finite type is 
orderable. According to question (b), this proves that G itself is orderable. 
25. Where precision matters, we will denote properties I, II, and III by I£ .F. R, 
IlE,F.R, and IIIE.F.R respectively. 
(a) If E is the empty setӝ III is trivially verified (the empty map is injective). 
This is also the case when E consists of a single element, a: for then, I 
means that Ra is non-empty, so by choosing an element b in Ra and setting 
f (a) = b, we define a map f that satisfies the requirements. Let k be a 
natural number greater than or equal to 2. We suppose (induction hypothesis) 
that for all sets X and Y and relations S £ X x Y, if card( X) < k and if 
lx.r.s is satisfied. then so is Illx, Y.S· Now suppose that E is a  set with k 
elements. 
First, we examine case 1 :  there exists at least one non-empty subset A 
of E, distinct from E, such that card(A) = card(RA). By the induction 
hypothesis, we can find an injective map !1 from A into RA such that for 
every element a in A, f1 (a) E Ra. Set B = E - A, C = F - RA , and 
S = R n (B x C). We will show that 18 c s is true. To see this, consider an 
' ' 
arbitrary subset M of B and set N = A U M. It is not difficult to verify that 

S O L U T I O N S  F O R  C H A P T E R  I 
269 
This implies (because RA and SM are disjoint) that 
card(RN) == card(RA) + card(SM) 
and, according to IE,F.R, card(RN) > card(A) + card(SM) (since A and 
M are disjoint). It follows that 
card(A) -r card(S M) > card(A) + card( M). 
Since card( A) is finite, we may conclude that 
card(SM) > card (M), 
which shows that IB,c.s is satisfied. 
So the induction hypothesis is applicable; this yields an injective map /2 
from B into C such that, for all b in B, f2(b) belongs to Sb, which means 
that (b, 12 (b)) E R. The desired map f is the map that is equal to /1 on A 
and to !2 on B. 
Next, consider case 2: for every non-empty subset A of E, distinct from E, 
the cardinality of A is strictly greater than that of RA. Choose an element 
u in E (which is not empty) and an element v in Ru (which is also not 
empty by virtue of IE,F.R and which even has, in the present case, at least 
two elements). By the induction hypothesis, there is an injective map from 
E - { u} into Ru 
- { v}. It suffices to extend this map to the whole of E by 
setting f(u) == v. 
(b) If E == F == N and if R = {(0, n) : n E N} U {(n + I , n) : n E N}, we can 
check that property I is satisfied while II and III are not. 
(c) Let X and Y be two sets and let S c X x Y be a binary relation such that 
properties Ix.r,s and Ilx.r.s hold. 
Take P == X x Y as the set of propositional variables and consider the 
foil owing sets of formulas: 
B x, Y.S = { V (x, y) : x E X } 
yESx 
Cx, Y ,S == {--.((x, y) A (x, z)) : x E X, y E Y, z E Y and y -#  z} 
Vx, Y,S == {--.((x, y) A (t, y)) : x E X, t E X, y E Y and x =1= t}. 
Then set: 
Ax, r.s == Bx. Y,S U Cx,Y.S U Vx,Y,S· 
Observe that for each element x of X, v yESx (x, y) is a formula because 
the set Sx is finite (property II) and non-empty (property I: card(Sx) > 
card( {x}) ). 
If 8 is an assignment of truth values that satisfies Ax, r.s, then we can 
define a map f from X into Y that satisfies the conditions in III in the 

270 
S O L U T I O N S  
following way: for all x E X, f (x) is the unique element of Y for which 
8 (Ax,y) = 1. 
Conversely, if we have a map f that satisfies the conditions in III, then 
we can obtain an assignment of truth values 8 that satisfies Ax,Y,S by 
setting: 
for all ( x, y) E X x Y, 
8(Ax,y) = 1 if and only if (x) = y. 
So we see that the set of formulas Ax,Y,S is satisfiable if and only if 
property Illx,Y.S is verified. 
Now consider the sets E and F and the relation R that we have been 
studying. Since they satisfy properties I and It to show that they also sat­
isfy III, it suffices to prove that the associated set of formulas AE, F, R is 
satisfiable. By the compactness theorem, this amounts to proving that every 
finite subset of this set is satisfiable. Let Q be such a finite subset. We easily 
see that there exists a finite subset X of E such that, if we set Y = Rx and 
s = R n (X X Y), then Q is included in Ax,Y,S· Now properties Ix,Y,S and 
Ilx,Y,S are obviously verified; hence, from (a), IIIx, Y,S is also verified and, 
from the preceding argument, Ax,Y,s is satisfiable as well as Q. 
The property proved in this exercise is known as the marriage theorem. 
We can illustrate it this way: E represents a set of men, F a set of women, 
(x, y) E R means that '"x knows y' and y = f (x) means 'x marries y'. 
What we have proved is that if an arbitrary number of men chosen from E 
collectively know at least the same number of women, then it is possible to 
marry each man in E to a woman in F that he knows, with no polygamy 
occurring. (Let us add that if we wish to consider the improbable case in 
which these sets are infinite, we would have to add the hypothesis that each 
man knows only a finite number of women . . .  ). Such an illustration could 
naturally be criticized, specifically for the asymmetric roles played by E 
and F, or else for its conformity with the imposed rules: monogamy and 
marriage between people who know each other. 
Solutions to the exercises for Chapter 2 
1. (a) It is the fact that the relation of logical equivalence, θ, is compatible with 
the propositional connectives that allows us to define internal operations on 
F I θ by the relations given in the statement of the exercise (these relations 
are independent of the choice of representatives from the equivalence classes 
of formulas). More precisely, and in conformity with Theorem 1 .24, for all 
formulas F, G, F', and G', if ci(F) = ci(F') and ci(G) = ci(G'), then 
cl( -,p) = cl( -,p'), ci(F A G) = ci(F' A G'), ci(F v G) = ci(F' v G'), 
ci(F ==} G) = ci(F' ==} G') and ci(F <¢:> G) = ci(F' <¢:> G'). (Also see 
our comments in Section 1 .2). 

S O L U T I O N S  F O R  C H A P T E R  2 
271 
We have the following logical equivalences (T is a tautology, ..l an anti­
logy, the numbers in brackets refer to the list established in Section 1 .2): 
• (A § B) ʠ (B § A); [no. 4 1 ]  
• ((A {I} B )  {I} C )  + (A í (B § C)); [the first of these formulas is 
...,(...,(A <=> B) <=> C) which is logically equivalent to ((A {:?- B) <:> C) 
[no. 43], to (A <=> (B <=> C)) [no. 58], and hence to the second formula.] 
• (A § .l) r-v A 
[no. 48 and no. 41] 
• (A § A) '"'"'J_ 
[no. 49 and no. 43] 
• (A 1\ B) "'"' (B 1\ A) 
[no. 3] 
• ((A "\ B) 1\ C) ,.._. (A 1\ (B 1\ C)) 
[no. 5] 
• (A 1\ (B § C)) ,.._. ((A 1\ B) í (A 1\ C)) 
[we justify this using the 
method of Exercise 14 from Chapter 1 :  the polynomial associated with 
the first formula is x ( 1 + 1 + y + z); the one associated with the second 
is 1 + 1 -r- xy -r xz, which is the same.] 
• (A 1\ T) + A; [no. 46] 
• (A ;, A) ,.._. A; 
[no. 1]. 
These equivalences prove that the operation § on F I ,.._. is commutative 
and associative, that it admits the class 0 of antilogies as an identity ele­
ment, and that every element has an inverse element (itself) relative to this 
identity element. The structure (F I ""', §} is thus a commutative group. 
Moreover, the operation 1\ is commutative, associative, distributive over 
{!}, is idempotent and has an identity element: the class 1 of tautologies. 
Consequently, the structure (F I r-v, {!}, /\) is a commutative ring with unit 
that is a Boolean ring. 
(b) It is true by definition that for all formulas F and G, cl(F) < ci(G) if and 
only if cl(F) 1\ cl( G) = ci(F), which is equivalent to ci(F 1\ G) = ci(F), 
which is to say ( F 1\ G) ,.._. F, or also to !-* ( ( F 1\ G) <=> F). Now the 
formula ( ( F 1\ G) <=> F) is logically equivalent to ( F => G) (see [no. 38]). 
It follows that 
cl(F) < ci(G) if and only if !-* (F => G). 
(Let us observe in passing that the property '(F => G) is a tautology' 
defines a binary relation on F that is compatible with the relation of logical 
equivalence, ""', and that the relation induced by it on the quotient set F I ""' 
is the order relation of the Boolean algebra.) 
Let us also observe that this is in no case a total ordering: if A is a 
propositional variable, wehaveneithercl(A) < ci(...,A) norci(...,A) < ci(A) 
since neither ofthe two formulas (A ::=:> -,A) nor (...,A => A) is a tautology 
(they are equivalent, respectively, to -,A and to A). 
For the ordering <, the smallest element is the class 0 of antilogies and 
the greatest element is the class 1 of tautologies. 

272 
S O L U T I O N S  
Let x == ci(F) and y == cl( G) be two elements of :F I ""'. We have 
(Theorem 1.18) 
x "' y == xy == x A y == ci(F A G) 
and 
XC == 1 + X  == l {I} X = CI(-,F). 
It follows, using de Morgan's laws, that 
( c 
c)c 
x 'J y = x "' y  
== ci(­(®F A -.G)) == ci(F v G) == x v y. 
Hence, the operations of least upper bound, greatest lower bound, and 
complementation are, respectively, disjunction, conjunction, and negation. 
(c) Suppose that P is the finite set {A 1 ,  A2, . . .  , An} (n E N*). Then the 
quotient set :F 1 ""' is also finite and has 22" elements (see Section 1 .3). This 
shows that the Boolean algebra (:F I ""' ,§ ,A ,O, 1) is atomic (Theorem 2.39) 
andalso that the number of its atoms is 2n (Theorem 2.50 and Corollary 2.51 ). 
We will show that these atoms are the the equivalence classes of the formulas 
(\ ekAk, 
I <ksn 
obtained as the n-tuple (et , £2, . . . , Bn) varies over {0, 1}n. 
Let us observe from the outset that there are 2n such classes, which 
amounts to saying that these formulas under consideration are pairwise 
logically inequivalent (which is guaranteed by Lemma 1 .25). Thus, if we 
succeed in showing that these classes are atoms, we will be assured that we 
have thereby found all the atoms of this Boolean algebra. 
Consider an n-tuple (c-1 , £2, •
•
•
 , en) E {0, 1}11 and let H denote the asso­
ciated formula: 
H == (\ ckAk. 
lsk<n 
We will reuse the notation from Section 1 .3. We have ¯(H) == {c5c1c2 
• . •  cn } 
(Lemma 1.25); hence, ci(H) =I= 0. It also follows from this that for any 
formula F such that ci(F) < ci(H) (which means that ਿ* (F ==> H) and 
is obviously equivalent to ¯ (F) c 8(H) ), 
• either D.(F) == {c5s182 
. . • c, } == ¯(H), and so ci(F) == ci(H); 
• or D.(F) == 0, and in this case, ci(F) == 0. 
We have thus proved that ci(H) is a non-zero element of the Boolean 
algebra :F I ""' below which the only elements are itself and 0; this means 
that it is an atom. 
2. We will make use of the results from Exercise 1 .  
Let X and Y be two subsets of E .  For every element x E X ,  we have x E X D. Y 
if and only if one and only one of the statements x E X and x E Y is true; this 

S O L U T I O N S  F O R  C H A P T E R  2 
273 
means precisely that x E X ղy if and only if the statement x E X <#? x E Y is 
true. The commutativity of ̨!,. follows from that of <#?; for all subsets X and Y 
of E, 
X I!,.Y = {x E E : x E X <#? x E Y} 
= {X E E : X E y {I} X E X} = y I!,. X. 
The associativity of ̨!,. is obtained from that of§ in an analogous fashion_ 
Moreover, 
X 1!,.0 = {X E E : X E X {/? X E 0} = {X E E : X E X} = X 
(here, we have used the fact that x E 0 is false and that false is an identity 
element for § ). Also, 
X/). X = {X E E : X E X {I} X E X} = 0. 
Thus, for the operation ̨!,., 0 is an identity element and every element of t;.J (E) 
is its own inverse. 
These remarks show that (t;J (£), Ա!,.) is a commutative group. 
The intersection operation on t;J (E) is commutative, associative and has E 
as an identity element. These facts follow from the corresponding properties of 
the propositional connective 1\. Moreover, 
X n (Y I!,.Z) = {x E E : X  E X  1\ (x E y {/} X  E Z)}; 
(X n f) ±!,.(X n Z) = {x E E :  (x E X  1\ X E Y) {/} (x E X 1\ X E Z)}ੀ 
these two sets coincide in view of the distributivity of 1\ over §. Thus, inter­
section distributes over symmetric difference. We have thereby shown that the 
structure (t;J (£), ̨!,. , n) is a commutative ring with unit. It is also a Boolean 
algebra since for every X E fiJ (E), we have X n X =  X. 
[t is immediate to verify that the order relation in this Boolean algebra is 
inclusion, that union and intersection correspond to the operations '-J and "', and 
that the complement of an element is its usual complement in the set-theoretic 
sense. 
3. The fact that properties of the kind considered in this exercise are preserved 
under isomorphism is banal and it is never a problem to verify this. As an 
example, we will treat question (a), leaving the others to the reader. 
(a) Let a E A be an atom of A and let y E B be less than or equal to f (a) in B. As 
f is an isomorphism, there is a unique element x E A such that y = f (x) 
and this element, x, is such that 0 < x < a since 0 < f(x) < f(a) 
(Theorem 2.48). But a is an atom; hence either x = 0 (and soy = f(x) = 0) 
or else x = a (and so y =  f(x) = f(a)}. It follows that the only elements 
less than or equal to f(a) are 0 and f(a). Given that a is non-zero, that 

274 
S O L U T I O N S  
/(0) == 0 and that f is injective, we can only conclude that f(a) is non-zero 
and hence that it is an atom of B. 
Conversely, if we suppose that it is f (a) that is an atom of B, it suffices 
to apply what we have just done to the isomorphism f-1 from B into A to 
convince ourselves that a == f-1 (f(a)) is an atom of A. 
4. (a) Let (A, <, 0, l) be a Boolean algebra. Suppose that it is complete and 
consider a non-empty subset X of A. Set Y == {x E A : xc E X} and let b 
denote the greatest lower bound of Y (Y is obviously a non-empty subset of 
A). It is very easy to prove that a == be is the least upper bound of X: on the 
one hand, for every x E X, we have b < xc, hence x < be == a and a is an 
upper bound for X; on the other hand, if m is an upper bound of X, then me is 
a lower bound of Y (trivial to verify), hence me < b and a == be < m, which 
shows that a is the least of the upper bounds of X. When we interchange 
the words 'upper' and 'lower' and reverse the inequalities in the preceding, 
we prove that if every non-empty subset of A has a greatest upper bound, 
then the Boolean algebra is complete. 
(b) Let A == (A, <, 0, l) and B == (B, <, 0, 1) be two Boolean algebras and let 
f be an isomorphism of Boolean algebras from A onto B. We assume that 
A is complete and will show that the same is true of B. Let B be a non-empty 
subset of Y and let X denote its preimage under f; X is a non-empty subset 
of A since f is a bijection. It is very easy to verify that if a is the greatest 
lower bound of X (which exists, by hypothesis), then f (a) is the greatest 
lower bound of Y. 
(c) Let E be a set and let X be a non-empty subset of fiJ (E). It is clear that 
the set G = nzEX Z, the intersection of the elements of X, is the greatest 
lower bound of X. 
(d) Let E be an infinite set and let H be an infinite subset of E whose com­
plement in E is infinite. (Concerning the existence of such a set, refer to 
Chapter 7.) Consider the following subset X of Ӟ (E): 
X ==  { {x} : x  E H}. 
If the Boolean algebra of finite orcofinite subsets of E were complete, X 
would have a greatest upper bound, M. Then M would have to be a finite 
or cofinite subset of E that is greater than or equal to (i.e. includes) all the 
elements of X: so we would have H c M ;  this prevents M from being 
finite so forces it to be cofinite. Since H, by hypothesis, is not cofinite, the 
preceding inclusion would be strict so we could find an element a E E such 
that a E M and a fj. H. The set N == M 
- {a} would then be, as is M, a 
cofi.nite subset of E that would still be an upper bound for X. But in this 
case, M would not be the least upper bound of X, which is a contradiction. 
The Boolean algebra under consideration is therefore not complete. 

S O L U T I O N S  F O R  C H A P T E R  2 
275 
(e) To begin with, let us recall that every finite Boolean algebra is complete 
(property 6 of Theorem 2.29). It fallows that when the set P of propositional 
variables is finite, then the Boolean algebra :F I ੁof equivalence classes of 
logically equivalent formulas (which is then itselffi.nite) is complete. 
Now suppose that the set P is infinite. Consider two sequences (Pn)nEN 
and (qn )nEN of pairwise distinct elements of P. We construct two sequences 
of formulas, (Fn)nEN and (Gn)nENo in the following way: 
Fo = po V qo; F1 = p J V qo V q 1 ;  
. . .  p Fk = p k v qo v q 1 v · · · v q k ;  . .  . 
Go = qo; G 1 = qo v ( q 1 /\ Po); . .  . 
. . . , G k = qo V ( q J /\ Po) V · · · V ( q k /\ Po /\ P 1 /\ · · · /\ P k - !  ) ; 
For every integer n, we have Gn+l = Gn v (qn+l /\ PO /\  PI 1\ · · · /\ Pn), 
hence r-* Gn ==> Gn+1 ;  in other words, ci(Gn) < ci(Gn+I), relative to the 
order relation in the Boolean algebra F I '"'"'· This inequality is strict, for we 
can find an assignment of truth values Dn that satisfies Gn+1 but that does 
not satisfy Gn ; it suffices to set 
Dn (qo) = Dn (qi )  = · · · = Dn(qn) = 0 and 
Dn(Po) = Dn (pt ) = · · · = Dn (Pn) = Dn (qn+I ) = 1; 
the values of Dn on the other propositional variables may be chosen 
arbitrarily. 
Let n be an integer and consider an assignment of truth values A such that 
A(Fn) = 0. We then have 
and, for every integer k > 1, A(qk /\ po /\ PJ 1\ · · · /\ Pk-1) = 0. Indeed, 
if k < n, 'A(qk) = 0; and if k > n, then Pn occurs in the conjunction 
Po /\ PI /\ · · · /\ Pk 1 which is therefore not satisfied by A. So we see that 
for every m, 'A(Gm) = 0. We have thus shown, for all integers m and n, that 
Gm => Fn is a tautology, or, as well, that ci(Gm) < ci(F11). The inequality 
is strict since, with what we have just proved, we have 
ci(Gm ) < ci(Gm+I ) < ci(Fn). 
Suppose that the set {ci(Fn) : n E N} has a greatest lower bound, ci(F). 
According to the preceding, we would then have 
which is to say 
for all integers m and n, 
ci(Gm) < ci(F) < ci( Fn), 
1-* Gm => F and 1-* F => Fn . 
(t) 

276 
S O L U T I O N S  
Choose an integer r such that for every integer k > r, neither Pk nor qk 
occurs in the formula F (this is possible since a formula can involve only 
finitely many propositional variables). We will now define two assignments 
of truth values a and f:J that are obtained, respectively, by modifying the 
value assumed by the assignment or, defined above, at the points Pr and qr: 
a(pr) = 0 and a(x) = or(x) for all variables x other than Pr; 
f:J (qr) = 1 and f:J(x) = or (x) for all variables x other than qr. 
Since Pr and qr do not occur in F, we obviously have 
a(F) = f:J(F) = or (F). 
(tt) 
On the other hand, it is easy to verify that a(Fr) = 0 and f:J(G r) = 1, 
which, according to (t), requires a(F) = 0 and {3 (F) = 1; but this mani­
festly contradicts (tt). 
It was therefore absurd to assume the existence of a greatest lower bound 
for the set {ci(Fn) : n E N}. So the Boolean algebra under consideration is 
not complete. 
(f) We have seen that the Boolean algebra of subsets of a set is atomic and, in 
question (c) above, that it is complete. We are guaranteed by question (c) 
of Exercise 3 and by question (b) above that every Boolean algebra that 
is isomorphic to a Boolean algebra of subsets of some set is necessarily 
atomic and complete. 
Now let us consider the converse. We will be motivated by the proof of 
Theorem 2.50, which can be viewed as a special case of the result to be 
proved here. Let A =  (A, <, 0, 1) be a Boolean algebra that is atomic and 
complete. Denote the set of its atoms by E and let cp denote the map from 
A into tp (E) which, with each element x in A, associates the set of atoms 
that are less than or equal to it: 
cp(x) == {a E E :  a < x}. 
Let us show that cp is surjective. Let X be a subset of E. If X is empty, 
then X = cp (0) (there is no atom below 0). If X is not empty, it has a least 
upper bound that we will denote by M. Every element of X is an atom that 
is below M, thus X c cp(M). If b is an atom that does not belong to X, then 
for every element x in X, we have x < he (this follows from Theorem 2.40: 
x is an atom and we do not have x < h since b is also an atom and x < b 
would mean that either x = h or x E X and b ¢ X). We conclude from 
this that M < he and, consequently, that b is not below M (for, since b is 
non-zero, we cannot have b < he). It follows that every atom that is below 
M is an element of X, i.e. cp(M) c X. To conclude, X == cp(M) and cp is 
surjective. 

S O L U T I O N S  F O R  C H A P T E R  2 
277 
For all elements x and y of A, if x < y, then cp(x) c cp(y) since any atom 
that is below x is an atom that is below y. 
For all elements x and y of A, if cp(x) c cp(y ), then x < y: indeed, if x 
is not below y, then x yc # 0 (Lemma 2.3 1 ;  since A is atomic, we can then 
find an atom a E E such that a < xyc, which is to say a < x and a < yc; 
but the atom a cannot simultaneously lie below y and yc; this shows that 
a E cp(x) and a tj cp(y), hence cp(x) Ź cp(y). 
Theorem 2.48 permits us to conclude that cp is an isomorphism of Boolean 
algebrasfromA onto t;J (E). Thus, every Boolean algebra that is atomic and 
complete is isomorphic to the Boolean algebra of subsets of some set. Since 
every finite Boolean algebra is atomic and complete, Theorem 2.50 is a 
corollary of what we have just proved. 
5. Let b be an element of B that is not an atom of the Boolean algebra B. Then 
either b = 0 and so b is not an atom of A or else we can find an element c E B 
that is non-zero, distinct from b, and that satisfies c < b; but, since c E A, we 
have found a non-zero element of A that is strictly below b, which shows that 
b is not an atom of A. 
6. We apply Theorem 2.54. We have 0 E B since 0 < 1 + a; if x E B, we have 
either x > a and so xc < l + a, or else x < 1 + a and so xc > a; so in all 
cases, xc E B ;  finally, if x and y are elements of B and if at least one of these 
is below 1 + a, then so is their greatest lower bound x ;-. y; and if this is not 
the case, then we have x > a and y > a, hence x "' y > a; so in all cases, 
X "' y  E B. 
Suppose that A is complete and consider a non-empty subset X of B. In A, 
X has a greatest lower bound, m. Let us show that m E B; this will prove that 
the Boolean sub-algebra that is B is complete. To do this, observe that if at least 
one of the elements of X is below 1 + a, we have m < 1 + a; and otherwise, 
for every element x E X, x > a and so a is below X, hence below m; in all 
cases, m E  B. 
7. (a) Set G == nFEZ F. We will verify that G satisfies the three conditions of 
Theorem 2.68. Let Fo be a filter in the (non-empty) set Z. We have 0 þ Fo 
hence 0 E G. As well, we have 1 E F for every F E Z, hence 1 E G. This 
verifi.es condition (f). Let x and y be two elements of G; for every F E Z, 
we have x E F and y E F, hence x "' y E F; it follows that x "' y E G 
and that condition (ff) is satisfied. Finally, if x E G, y E A, andx < y, then 
for every .f E Z, we have x E F, hence y E F; this shows that y E G and 
that condition (fff) is satisfied. So the set G is a filter on A. 
Let a be an element of A that is distinct from 0 and 1 (we assume such 
an element exists). Consider the principal filters Fa and Ft+a generated by 
a and 1 -r a, respectively and let Z == { Fa, Ft +a }. The set K == U FEZ F = 
Fa U Ft +a is certainly not a filter since a E K, 1 + a  E K and a "' (1 +a) = 
0 tj K. 

278 
S O L U T I O N S  
(b) We set H == U FEZ F and once again apply Theorem 2.69. As before, choose 
a specific filter Fo E Z. We have 1 E Fo hence 1 E H. For every F E Z, 
we have 0 ӟ F, hence 0 ӟ H. So H satisfies condition (f). Let x and y be 
elements of A such that x E H and y > x ;  there exists a filter F E Z such 
that x E F, and so y E F; hence y E H. This verifies condition (fff) for 
H. As we see, the additional hypothesis on Z is not involved in the proofs 
of these two conditions. We will use it to verify condition (ff): given two 
elements x and y of H, we have to show that x 
"' y E H. There are filters 
Ft and F 2 in the set Z such that x E Ft and y E F2; as Z is totally ordered 
by inclusion, we have either Ft c F 2 or F 2 c F1 ; F == F1 U F 2 is therefore 
a filter in Z that contains both x and y; so it contains their greatest lower 
bound x "' y. We thus have x "' y E F and F E Z, from which it follows 
that x "" y E U FEz F == H. 
8. Let E* denote the set of intersections of finitely many elements of E. We can 
construct E* in the following way: set Eo == E and for every n E N, 
En+l == {Z E &J (N) : (3X E E)(3Y E En)(Z == X n Y)}; 
we then have 
E* == u En. 
nEN 
Since the set E is countable, we easily show, by induction, that each of the 
sets En is countable; so their union E* is also countable (a countable union of 
countable sets). We may refer to Chapter 7 in Volume 2 for details concerning 
these questions of cardinality. 
We can therefore produce an enumeration of E*: 
E* == {Xn : n E N}. 
Let us now show that the filter generated by E is the set 
F == {X E <9 (N) : (3n E N)(X :J Xn)}. 
We can convince ourselves that F is a filter that includes E by examining the 
proof of Lemma 2.79 (note that the elements of E* are all non-empty). To 
continue, suppose that G is a filter that Includes E ;  G must contain any element 
that is a lower bound (i.e. intersection) of finitely many elements of E, as well 
as any element that is above such an element. The first condition is equivalent to 
G J E and the second, to G :J F. We have proved that F is a filter that includes 
E and that it is itself included in any filter that includes E; accordingly, F is the 
intersection of all filters that include E or, equivalently, the filter generated by E. 
Suppose that F is an ultrafilter. We will distinguish two cases. In the first, we 
will show that F is trivial and in the second, we will arrive at a contradiction. 

S O L U T I O N S  F O R  C H A P T E R  2 
279 
We will thereby have established the desired property. 
• If there exists an integer n such that the set X n is finite, then since X n E F, 
N - X n ° F, which shows that F does not extend the filter of co finite subsets 
of N (the Frechet filter); so F is a trivial ultrafilter (Theorem 2.77). 
·• In the case where Xn is infinite for every n E N, we will construct a subset 
A c N such that neither A nor N - A belongs to F, which shows that F 
is not an ultrafilter, contrary to our hypothesis. Let us define two sequences 
(an )nEN and (bn)nEN of natural numbers by induction as follows: 
ao is the least element of Xo and bo is the least element of Xo -- {ao}; 
and for every n E N, 
an+ I is the least element of Xn+ 1 - {ao, a 1 ,  •
•
•
 , an , bo, b1 , . . . , hn} and 
bn+l is the least element of Xn+ l - {ao, a 1 ,  . . .  , an, an+l , bo, h1 , . . .  , bn} .  
The fact that all of the sets X n are infinite guarantees that this is a valid 
definition. 
Set A =  {an : n E N} and B = N - A .  
It is clear that the set {bn : n E N }  is included in B and that the sets A and B 
are both infinite. 
For every integer n, we have 
which shows that the set Xn is not included in A nor in B . It follows that neither 
of the sets A nor B = N - A belongs to the filter F. So it is not an ultrafilter. 
9. (a) This property was established in Exercise 20 from Chapter 1 .  
(b) and (c) Consider the map cp : :F I "'---+ { 0. 1 } defined for all x E :F I "' by 
( { 1 
if 81 (F) = 1 for all formulas F E x  
cp x) = 
0 
if 81 (F) = 0 for all formulas F E x  
(there are obviously no other cases). 
We see that cp is nothing more than the assignment of truth values 81 
'modulo' the relation of logical equivalence "'; it is the map that would be 
denoted by h01 using the notation from Example 2.57 and it is a homomor­
phism of Boolean algebras from :FI "' into {0, l}. We obviously have 
J = {x E :FI "' : cp(x) = 1}, 
which proves that J is an ultrafilter and that cp is its associated homomor­
phism (Theorem 2.72, (1') ¢> (3')). 
10. (a) Let x be an element of A. To say that H (x) is a singleton is to say that 
there is a unique homomorphism of Boolean algebras from A into {0, 1} 
that assumes the value 1 at x .  

280 
S O L U T I O N S  
• Suppose that x is an atom: so we have x # 0 and H (x) is then non­
empty. But if h is an element of H (x ), then for all y E A, we have either 
that x y == y, which requires h (y) == 1, or else x y == 0 which requires 
h (y) == 0 (since h(xy) == h(x)h(y) == h(y)). The value of h(y) is thus 
determined for any element y E A. There is therefore a unique element 
in H (x ): it is a singleton. 
• Now suppose that H (x) is a singleton: it is then necessarily an atom 
in the Boolean algebra B(S) (since it is an atom in g;y (S) (Exercise 5)). 
As H is an isomorphism of Boolean algebras, x is an atom of A 
(Exercise 3a ). 
Remark: In the first part of the proof, we could have, in similar fashion, 
observed that H (x) is an atom in B(S); but this would have in no way 
implied that H (x) is a singleton, for an atom in B(S) is not necessarily an 
atom in g;y (S) (Exercise 5). 
(b) If A contains an atom a, H (a) is an open (and closed) subset of S that re­
duces to a single point: consequently, S contains at most one isolated point. 
Conversely, if h is an isolated point in S, then {h} is an open subset of S. 
As the topology of S is Hausdorff, every singleton is closed. It follows that 
{h} is clopen, i.e. an element of B(S). As a consequence, there is a (unique) 
element a E A whose image under the isomorphism H is {h} .  According 
to question (a), a is necessarily an atom. 
(c) As the clopen sets constitute a basis of open sets for the topological space 
S, and as every non-empty open set must include at least one open set from 
a given basis, we see that for a set X c S to meet every non-empty open set 
(i.e. for it to be dense in S), it is necessary and sufficient that it meet every 
non-empty clopen set. 
Let I denote the set of isolated points of S. 
Suppose that A is atomic. Let Q be a non-empty clopen subset of S. There 
then exists one and only one element x in A such that H (x) == Q. As Q is 
not empty, x is not zero; so we can choose an atom a E A that is below x. 
Then H(a) is included in H (x) since H is order-preserving. But according 
to (a), H (a) is a singleton and its unique element is an isolated point of S; 
so Q contains a point from I. This proves that I is dense in S. 
Conversely, suppose that I is dense in S. For every non-zero element 
x E A, H (x) is a non-empty clopen subset of S and, in view of this, it 
contains at least one isolated point, h. But then { h} is the image under 
H of one (and only one) atom a in A (see the proof of (b)). We have 
h(a) == {h} c H (x), hence a < x (Theorem 2.48). We have found an atom 
that is below x, i.e. A is atomic. 
11. Suppose first that the Boolean algebra A ==  (A, <, 0, 1) is dense. If b is a non­
zero element in A, then, by definition, there is at least one element c E A such 
that 0 < c < b, which shows that b is not an atom. Conversely, suppose there 

S O L U T I O N S  F O R  C H A P T E R  2 
28 1 
are no atoms in A and consider two elements a and b of A such that a < b; 
then a + b is not zero and is not an atom. So there is an element d E A such 
that 0 < d < a + b. Set c == a .._, d. It is immediate to verify that we then have 
a < c < b; so A is dense. 
12. (a) Suppose that (y, z) is a bipartition of x. We then have 
x = y .._, z == y + z + yz = y + z + (y r-.. z) ::: y + z. 
It follows immediately that x + y = z. We have y # x since z # 0, and 
y < x since x = y '-' z. As y # 0, we conclude that 0 < y < x. 
Conversely, if 0 < y < x and z == x + y, then we have y # 0, z # 0 
(since y # x ), 
2 
y '-' Z = y + Z + yz == Y + X +  y 1 yx + y = X +  y + XY = X '-' y = X  
and finally, y r-. z = y(x + y) == yx + y2 = y + y = 0. 
Let a be a non-zero eJement of A. Since a is not an atom, there is an 
element b E A such that 0 < h < a. From all that has preceded, (b, a + b) 
is a bipartition of a. 
(b) We proceed by induction. The choice of uo and u 1 is explicitly given in the 
statement of the exercise. 
Suppose that the element u£0£1 
•
. . £n- l has been defined in conformity with 
the imposed conditions (by convention, for the case n = 0, u£0£1 ... £11_ 1 = 
u0 = 1). Then this element is non-zero and, according to (a), has at least 
one bipartition. If the condition u£0£1 
. .. 8"_ 1 r-. an =/= 0 and u£0£1 .. . c:n- 1 
r-.. 
(1 +a) =/= 0 is not satisfied, we choose an arbitrary bipartition of uc:0£1 ... c:n- l 
as the pair (u£0c:1 • • •  £n_1 o ,  u£0c:1 . . .  £n_ 1 I  ). If the condition is satisfied, then it is 
easy to verify that the pair (u£o£J ... £n-l ''"" an, u£0£1 ... £n- l r-.. (1 + an)) is a 
bipartition of uc:0£1 ... En 
1 
• 
(c) Let x and £ be as indicated. First, observe that for all natural numbers m 
and n ,  if n < m, then u£08 1 ... £m < uc:0£1 . . .  £n . It follows that for every integer 
k E N, 
( 1 )  if x " u£0£1 ... £" = 0, then for every integer p > k, x "' uc:0£ 1 ... £p = 0; 
(2) if x "' Uc:o£ 1 • • •  £" =/= 0R then for every integer q < k, x r-. u£0£1 • • • £q =/= 0. 
Let us next prove that at least one of the conditions (i) or (ii) is satisfied: 
if (i) is not satisfied, we can find an integer k such that x ''"" u£0c:1 ... £" == 0; 
according to ( 1 ), we then have that for every integer p > k ,  Uc:o£ 1 ... c:P == 0; 
but Uc:0c:1 .
.. £p =/= 0, and 
u 
= (x r-. u 
) ...._, ((1 + x) r-.. u 
)· 
£Q£) ... £p 
£Q£] ... £p 
£Q£f ... £p ' 
it follows that (1 + x) r-. u£0£1 .•• Ep # 0, which means that condition (ii) is 
satisfied. 

282 
S O L U T I O N S  
Now let us show that (i) and (ii) cannot be satisfied simultaneously (it is 
herethatthatthecountabilityof A intervenes). Sincex isoneoftheelements 
of A ,  there is an integer k such that x = ak. Three cases are then possible: 
• ak "" u8081 ... sk-l = 0; this contradicts condition (i); 
• (1 + ak) "" us0s1 • • •  sk-t = 0; this contradicts condition (ii); 
• ak "" Us0s1 ... sk-l # 0 and (1 + ak) "" U8081 ... sk-t # 0; in this case, 
and 
u 
o - ak "" u 
h' h · 
I' 
£Q£t ... Bk-1 
-
£Q£I 
•.. Bk-l , W 
IC 1mp IeS 
Us0s1 • • • sk-t0 "" (1 + ak) = 0: 
Us0s1 ... sn_1 I = (1 + ak) "" Usosl ...£k-I ,  which implies 
Us0s1 . • • £k-l 1 
"" ak = 0. 
Thus, if ek = 0, then u80s1 ... sk0 "" (1 + ak) = 0 and condition (i) fails. or 
if ek = 1, then u8081 • • •  8k "" ak = 0 and it is condition (ii) that fails. 
(d) The condition is sufficient: indeed, we have already noted that if n < m, 
Us0s1 . . • £m < u8081 • • •  £n · It follows that 
To show that it is necessary, suppose there exists an integer k such that 
0 < k < n, eo = o, . . .  , Ek-I = k-1 and ek # k· We then have 
u80s1 • • . sk "" uot ---k = 0, because (u80q ... sm '  u01 
.
•
. k ) is a bipartition of 
u01 
. • .  l;k-t .  On the other hand, Us0s1 • . .  s, < u8081 • . . sk and u01 ... m < u01 . . • k ; 
hence U8081 . • . sn "" u01 ---m = 0. 
(e) Let x be an element of A .  Question (c) shows that for any sequence f E 
{0, l}N, we have f E h(x) or f E h(1 +x), but never both simultaneously. 
In other words, h(1 + x) is the complement of h(x) in {0, l}N. 
For every integer n E N, set 
r n(X) = {.f E {0, l}N : (x "" U f(O)f(l) ... f(n) # 0}, and 
Vn = { (eo, e l ,  . . .  , en) E {0, 1 }n+l : x "" Us0s1 ... s11 # 0}. 
We then have 
u 
{.f E {0, l}N : .f(O) = eo and 
f ( I ) = E 1 and . . . and f (n) = en } 
and h(x) = nnENr n(X). 
So for every n, rn (x) is a finite union of clopen sets from the basis of 
open sets for the topology on {0, l}N. So it is itself clopen. 

S O L U T I O N S  F O R  C H A P T E R  2 
283 
The set h (x ), an intersection of closed sets, is then closed. But we have 
seen that the complement of h(x) in {0, l}N is h(l + x ); so it too is a closed 
set. We conclude from this that h (x) is clopen, i.e. is an element of the 
Boolean algebra B({O, l }N). 
Let us prove that h preserves the order and least upper bounds: if x and y 
are elements of A such that x < y, then for every sequence f E h (x) and 
for every integer n E N, we have 
Y "' U f(O)f(I ) ... f(n) > X | U /(0)/( l) ... f(n) > 0, 
which shows that f E h(y)र hence h(x) c h(y). It follows that for all 
elements z and t of A, we have h (z) c h(z '-' t) and h(t) c h (z '-' t), hence 
h (z) u h (t) c h (z '-' t). 
Conversely, suppose that f is an element of h(z '-' t) and that f tj h (z): 
this means that there exists an integer k such that z r-. u f(O)f(I ) ... f(k) = 0. 
According to remark ( I )  from (c)Ҙ we also have that for every integer p > k± 
z r-. u f(O)f(I ) ... f(p) = 0. Now, for every integer n, we have 
(z r-. u f(O)f(I) ... f(n)) '-' (t "' u f(O)f(l) ... f(n)) 
= (z '-' t) r-. u f(O)f(I ) ... f(n) =I= 0. 
It follows that tc r-. u f(O)f(I ) ... f(p) =I= 0 for all p > k; but remark (2) 
from (c) shows that this must also be true for the integers p < k. Finally, 
for every integer n, we have t r-. u f(O)f(l) ... f(n) =I= 0, i.e. f E h (t ) . Thus 
h (z '-' t) c h (z) U h (t ) , which completes the proof that h preserves greatest 
upper bounds. 
Fromthedefinitionofh, it is immediatethath(O) = 0 andh(l) = {0, l}N. 
Theorem 2.45 and Remark 2.46 allow us to conclude from the preceding 
that h is a homomorphism of Boolean algebras from A into B( {0, l}N ). 
This homomorphism is injective: to see this, it suffices to verify that for 
every non-zero element a E A, h (a) is not empty. To accomplish this, we 
will define by induction a sequence f E {0, l }N as follows: 
/(0) = { , if a "' uo =I= 0 . 
if a r-. uo = 0 ' 
and for every n, 
f(n + 1 )  = { , if a r-. u f(O)f(l ) ... f(n)O "# 0 
if a | u f(O)f(I ) ... f(n)O = 0 . 
As a is non-zero, we cannot have a r-. uo = 0 and a r-. u 1 = 0 simulta­
neously (since u 1 == 1 + uo ); hence a r-. u f(O) i= 0. 

284 
S O L U T I O N S  
Suppose (induction hypothesis) that a r--
u f(O)f(l) ... f(n) =I= 0. Since 
the pair 
(UJ(O)J(I) ... f(n)Q, U f(O)J(l) .. .f (n)l) 
is a bipartition of u f(O)f( 1 ) • .. f(n), we can not have a r-- u J(O)f(l) ... f(n)O == 0 
and a r-- u f(O)f(l) .. .f (n) 1 == 0. We conclude from this that 
a r-- a r-- u f(O)f(l) ... f(n)f(n+l) =I= 0. 
We have thereby proved that f E h(a) ; hence h(a) =I= 0. 
It remains to prove that h is surjective. For every integer n and every 
(n + I )-tuple (ao, a1 ,  . . .  , an) E {0, l}n+I, set 
r2a0a1 • • . a11 == {.f E {0, l}N : /(0) == ao, f(a) == a1 , . . . , f(n) == an}, 
and let us show that h(ua0a1 • . •  a11 ) == 22a0a1 .. _a11 • If f E r2a0a1 .• _a11 and k E N, 
we have 
UaoaJ ... an r-- UJ(O)f(l) ... f(k) == 
aoaJ ... an 
{ u  
U j(O)J(I) ... J(k) 
if k < n . 
if k > n ' 
so in both cases, we have a non-zero element of A̧ which proves that .f 
belongs to h (ua0a1 • • • an ). Conversely, if f E h (ua0a1 ___ a11 ), we have, in par-
ticular, that 
Uaoar ... an ---. U j(O)f(l ) ... f(n) =/= 0; 
hence, according to question (d), j(O) == ao, .f(a) == a 1 ,  . . . , and f(n) == 
an, which shows that f E r2a0a1 ... a11 • 
It is easy to be convinced that the family 
constitutes a basis of open sets for the topology of {0, 1 }N. Indeed, in 
Section 2.1.2, we considered basic open sets of the following form: the set 
of maps from N into {0, 1} that assume given values at a given finite num­
ber of points; now such a set is manifestly a (finite) union of sets from the 
family 0. 
So let us consider an arbitrary clopen set V E 8({0, t}N). V is a union 
of sets from the family 0 but, since we are in a compact space, there is a 
finite number of sets from the family 0 whose union is V. Suppose, for 
example, that V == G 1 U G2 U · · · U G P where each G; is a set of the 
form Qa0a1 • • •  a11 • Now each set r2a0a 1 • . •  a11 is the image under h of the ele­
ment Ua0a1 • • •  an .  Hence there exist elements h1 , b2, . . .  , hp in A such that 
G 1 == h(hi), G2 == h(b2), .
.
 q and Gp == h(bp). Since h preserves greatest 
upper bounds, we may conclude that 
V == h ( b I '-J b2 '-J • • • '-J b p) . 
It follows that the image of the map h is the whole of 8({0, l}N). 

S O L U T I O N S  F O R  C H A P T E R  2 
285 
We have thus proved that every countable atomless Boolean algebra is 
isomorphic to the Boolean algebra of clopen subsets of the space {0, 1 }N 
(with the discrete topology on {0, l }  and the product topology on the space). 
We may also conclude from this that any Boolean topological space with a 
countable basis of clopen sets is homeomorphic to the space { 0, 1 }N. This 
space is often called the Cantor space. It is in fact homeomorphic to the 
Cantor ternary set (the set of real numbers in the interval [0, 1 ]  that are of 
the form 
where, for every n, Xn is equal either to 0 or to 2), where this set has the 
topology induced as a subset of JR. Details concerning this can be found 
in the text of Kelly which we cited earlier in connection with Tychonoff's 
theorem. 
13. (a) The map G is injective: indeed, if 8 and 'A are two distinct elements of 
{0, 1 }P, then for at least one propositional variable A, we will have 8 (A) i= 
'A(A), hence h8(ci(A)) # hJ.(ci(A)), which implies that h8 =/:. hJ., i.e. 
g(8) i= g('A). 
The map G is surjective onto S(:F I roy): indeed, let h be a homomorphism 
from :F 1 roy into {0, 1}; define 8 : P -7 {0, 1} by 8(A) == h (ci(A)) for any 
propositional variable A. We will prove that hs == h, in other words, that 
for every formula F E F, 
8(F) == h (cl(F)). 
It suffices, in fact, to prove this for formulas that can be written exclusively 
with the symbols for connectives --, and 1\ (and the propositional variables!) 
since we know that every equivalence class contains such a formula. We 
argue by induction on the height of formulas: 
• for propositional variables, this is the definition; 
• if 8(F) == h (ci(F)), then 8(-,F) == 1 + h (cl(F)) == h ((ci(F))c) since h 
is a homomorphism; but (ci(F))c == ci(--,F), hence 8(-,F) == h (ci(--.F)}; 
-
-
• if 8(F) == h (ci(F)) and 8(G) == h(ci(G)), then 
8(F A G) == 8(F) x 8(G) == h(ci(F)) x h(ci(G)) 
== h (ci(F) x ci(G)) == h (ci(F A G)). 
(b) Let T be a subset of F. 
• Suppose that T I roy is a filter base. Then (Lemma 2.8 1 )  there is an ultra­
filter U on :F I ° that includes T I °. Let h denote the homomorphism of 
Boolean algebras from:F I roy into {0, l }  that is associated with this ultrafil­
ter. We then have that h (x) == 1 for every x E T I °. According to (a), we 
can find a (unique) assignment of truth values 8 on P such thath0 == h. For 

286 
S O L U T I O N S  
every formula F E T, we will have ci(F) E Tl "-', hence h8(ci(F)) = 1, 
or in other words, 8(F) = 1. We conclude that T is satisfiable. 
• Conversely, suppose that T is satisfiable and that 8 is an assignment that 
satisfies it. Then for every formula F E T, we have h8(ci(F)) = 1, 
which can also be expressed as: for every element x in T I ,.._, , h8 (x) = 1. 
It follows that T 1 "-' is included in the set 
u = {y E F I "-': h 8 ( y) = l}' 
which is none other than the ultrafilter on F I "-' associated with the ho­
momorphism h8. So there does exist an ultrafilter that includes T 1 "-', 
which amounts to saying (Lemma 2.8 1 )  that T I ऱis a filterbase for the 
Boolean algebra :F I "-'. 
(c) We will prove the non-trivial implication in the second version of the com­
pactness theorem. So suppose that T is a contradictory set of formulas from 
:F. According to (b), T I "-' is not a filterbase, i.e. T I "-' does not have 
the finite intersection property or, equivalently, there exist (a finite number 
of) formulas F1 , F2, . . .  , F k such that the greatest lower bound in T I ल 
of ci(F, ), ci(F2), . . .  , ci(Fk) is 0. Now this greatest lower bound is the 
equivalence class of the formula 
It follows that this formula is not satisfied by any assignment of truth 
values, or again that the set ( Fr , F2, . . .  Fk} is a finite subset of T that is 
contradictory. 
14. (a) Let us verify that the order relation < 8 satisfies the properties listed in 
Theorem 2.32. 
• 0 E B and is obviously the least element; a is the greatest element; 
• if x and y are elements of B, then x < a and y < a, hence x "' y < a 
and x '-./ y < a, which shows that any two elements of B have a greatest 
lower bound (a least upper bound, respectively) which is their greatest 
lower bound (least upper boundɸ respectively) in .A; 
• since the operations "' and '-./ are the same as in A, they are obviously 
distributive with respect to one another; 
• for any element x in B, we have a "' xc E B (since a "' xc < a); more­
over, it is immediate that (a "' xc) '-./ x = a and that (a '"' xc) '"' x = 0. 
Thus B, with the order relation <, is a Boolean algebra which has the 
same least element and the same operations "' and '-.-/ as the Boolean algebra 
.A, but whose greatest element and whose complementation operation are 
different: the greatest element is a and the complement of an element x E B 
is a "' xc (where xc is its complement in A). 

S O L U T I O N S  F O R  C H A P T E R  2 
287 
(b) Consider the map cp from A into B which, with each element x, associates 
x ) a. For all elements x and y in A, we have 
cp(x [ y) = (x * y) [ a =  (x ¢ a) [ (y [ a) = cp(x) [ cp(y), and 
cp(xc) = xc Ǆ a =  (xc ¢ a) '--' (ac '"" a) = (xc '"' ac) "' a 
= (x [ a)c "' a  = (qJ(x))c [ a. 
Since (cp(x))c ¢ a is the complement of cp(x) i n  the Boolean algebra 
(B, <) considered in the previous question, Theorem 2.45 allows us to con-­
clude that cp is a homomorphism of Boolean algebras from A into (B, <). 
This homomorphism is surjective since for all y E B, y = cp(y). 
The kernel of cp is 
{ x E A : x + a = 0} = { x E A : x < ac}, 
which is precisely the ideal /. The Boolean algebra (B, <), which is the 
image of the homomorphism cp, is thus isomorphic to the quotient Boolean 
algebra A/ I (the isomorphism being the map from B into A/ I that, with 
each element x in B, associates the set : {y E A : y ) a = x} ). 
15. (a) Let X be a subset of E distinct from E. We have 
t;J (X) = { Y  E t;J (E) : Y c X}. 
Here, we recognize the principal ideal of A generated by the element X 
(Example 2.62). 
Conversely, let I be a subset of t;J (E) that is an ideal of A. Let X denote the 
union of all the subsets of E that belong to I (I is non-empty since 0 E /): 
X =  U Y. 
YEl 
I tis obvious that I is included in t;J(X). Since E is finite, so is I and hence 
X is the union, i.e. the least upper bound, of a non-zero finite number of 
elements of the ideal /, which proves (Corollary 2.61) that X belongs to /. 
As a consequence, every subset of X, i.e. everything below X ,  also belongs 
to I (part (iii) of Theorem 2.59). Thus SJ (X) is included in /. As we also 
have the reverse inclusion, we conclude that I = SJ (X). Note that X can 
not possibly equal E, for this would mean that l = SJ (E) and I would no 
longer be an ideal. 
(b) The kernel I of the homomorphism h is an ideal in the Boolean alge ... 
bra A (Theorem 2.64 ). According to question (a), there must then ex-­
ist a subset K c E such that I = SJ ( K ). Uniqueness is automatic: i:f 
I = SJ (K) = SJ (L), then K c L and L c K, so K = L. It is the case that 
for every element Y in SJ (£), h(Y) = 0 if and only if Y c K. 

288 
S O L U T J O N S  
Given that h is a homomorphism of Boolean algebras, that h(K) == 0 and 
that Z == E - K is the complement of K in the Boolean algebra fYJ (E), 
we necessarily have h(Z) == 1. For all subsets V and W of Z, we have 
h(V n W) == h(v) r h( W) (this is true for arbitrary subsets of A ) and, on 
the other hand, 
h(Z - V) == h(Z n (E - V)) == h(Z) --. h(E - V) 
== 1 O (h(V))c == (h(V))c. 
Sow e may assert (Theorem 2.46) that the restriction of h to f[.J ( Z) is a ho­
momorphism of Boolean algebras from fYJ (Z) into C. The image h(f>J (Z)) 
of this homomorphism is a Boolean sub-algebra of C (Theorem 2.53) and 
we obviously have h(f)J (Z)) c h(f)J (E)). Let us now prove the reverse 
inclusion: for every element y E C, if y E h(f>J (E)), there exists a subset 
V c E such that y == h(V); but V == (V n K) U (V n Z), hence 
y == h(V n K) '-' h(V n Z) == 0 "'  h(V n Z) == h(V n Z) 
(since V n K C K); it follows that y E h(f)J (Z)). Moreover, the kernel of 
h is I == fYJ (K) and, since fYJ (K) n fYJ (Z) == {0}, we see that the homomor­
phism restricted to fYJ (Z) is injective. Finally, the restriction of h to fYJ (Z) 
is an isomorphism from fYJ (Z) onto h(f)J (E)). 
16. (a) Let A == (A, <, 0, 1} be a finite Boolean algebra and let I be an ideal of 
A. As 1 is finite and non-empty (0 E I), we can consider the least upper 
bound a of all the elements of /. By virtue of Corollary 2.61, a belongs to 
I. Every element of I is obviously below a and every element of A that is 
below a belongs to I (part (iii) of Theorem 2.59). Thus we have 
I == {x E A : x < a}, 
which means that 1 is the principal ideal generated by a. 
In 1 5(a) we showed that in the Boolean algebra of subsets of a finite set, 
every ideal is principal. But we also know that every finite Boolean algebra 
is isomorphic to the algebra of subsets of some set (Theorem 2.50) and, as 
it is easy to verify that the property of being a principal ideal is preserved 
by isomorphism, we realize that in fact, nothing new has been proved here 
that is not already included in 15(a). 
(b) Naturally, we assume that the atoms a; are pairwise distinct. Let qJ denote 
the map from A into fYJ ({ 1 ,  2, . . .  , k}) which, with each element x E A, 
associates the set 
(/) (X) == {i E { 1 , 2, . . . , k} : X P a; = ai } . 
For every x E A we have 

S O L U T I O N S  F O R  C H A P T E R  2 
289 
But since the a; are atoms, each of the elements x " ai is either equal to ai 
or equal to 0. 
It follows that x is the least upper bound of the atoms a; for which 
i E cp(x). This proves that the map cp is a bijection: for every subset 
J c { 1 ,  2, . . .  , k }, there exists a unique element x E A (the least upper 
bound of the atoms aJ such that j E J) that satisfies cp(x) = J. We may 
then conclude that the Boolean algebra is finite: we can even show with ease 
that cp is an isomorphism of Boolean algebras from A onto g; ({ 1 ,  2, . . . , k} ). 
(c) If G were not a filterbase, there would exist a finite number of atoms 
a1, a2, . . .  , ak in A such that 
which translates as: a 1 .._, a2 .._, · · · .._, ak = 1 (de Morgan). According to 
question (b), A would then be finite, which is contrary to our hypothesis. 
(d) If U is trivial, then it contains at least one atom a E A (Lemma 2.76); we 
then have 1 + a  E G and 1 + a  ¢ U, hence G is not included in U. lf U i5. 
non-trivial, then it does not contain any atom (Lemma 2.76); in this case, for 
every x E G, 1 ,-x is an atom; hence 1 + x ¢. U, so x E U (Theorem 2. 72) .. 
which shows that G is included in U. 
In the particular case where A is the Boolean algebra of subsets of ar. 
infinite set £, G is the collection of co finite subsets of E, i.e. the Frechet 
filter on E. So the result that we have just proved is precisely Theorem 2.77. 
(e) It follows immediately from question (a) that if A is finite, every filter on 
A is principal (dual of a principal ideal); in particular, every ultrafilter on 
A is principal, i.e. is trivial. Now suppose that A is infinite. According 
to question (c) and the ultrafilter theorem (Theorem 2.80), we can find an 
ultrafilter that includes G. According to (d), such an ultrafilter must be 
non-trivial. 
17. (a) If we take 1 = 0, then UjEJ Ej = 0, hence 0 E B. If X E B and Y E B! 
there exist subsets J and K of I such that X =  u jE J E j and y = ukEK Ek . 
Given that the Ei forma partition of E ,  then by setting L = J n K, we have 
X n Y = UiEL E; (indeed, Ej n Ek = 0 if j '# k and Ej n Ek = E,; = Ek 
if j = k). We conclude from this that X n Y E B. On the other hand, it is 
clear that the complement of X in E is the set E - X = U j EI-J E.i, which 
shows that E - X E B. We may thus conclude, using Theorem 2.54, that 
B is a Boolean sub-algebra of A. 
Fix an index i E I and consider an element X in B such that X c E; . We 
have X = U jEJ Ej for a certain subset J of I. Thus, for every j E J, we 
have E j c E; , which requires (since we are in the presence of a partition) 
that Ej = Ei or Ej = 0. We conclude that X = E; or X = 0, which 
proves that Ei is an atom of B. 

290 
S O L U T I O N S  
(b) Let U and V be two distinct atoms of C. We have U n V  E C and U n V  c U, 
hence either U n V = 0 o r  U n V = U. The second possibility is excluded 
since, U and V being atoms, we can only have U c V if U = V. It follows 
that distinct atoms of C are dis joint subsets of E. On the other hand, the 
least upper bound of the atoms of C (i.e. their union) is the set E. Indeed, in 
a finite Boolean algebra, every non-zero element is the least upper bound 
of the set of atoms below it (this follows from the proof of Theorem 2.50 
and, in the notation used there, we have that x = Mh(x) for every non-zero 
element x of A). We have thereby established that the atoms of C constitute 
a partition of the set E. 
(c) To each Boolean sub-algebra of g;y (E), there corresponds the partition of E, 
studied in part (b), formed by the atoms of this sub-algebra. This correspon­
dence is injective: indeed, as we have just recalled, every non-zero element in 
a finite Boolean algebra is the least upper bound of the atoms below it; thus, 
if the same set of atoms is associated with two Boolean sub-algebras, these 
sub-algebras must coincided. This correspondence is also surjective: given a 
partition of E, we may, as in (a), associate with it a Boolean sub-algebra B of 
A and we have seen that the elements of the given partition are the atoms of 
B. These are, by the way, all the atoms of B for if there were others, the atoms 
of B would no longer constitute a partition of E and (b) would be violated. 
18. We have seen (Exercises 3 and 4) that the properties 'is atomic' and 'is com­
plete', as well as their negations, are preserved by isomorphisms of Boolean 
algebras. As well, we know that every Boolean algebra is isomorphic to a sub­
algebra of a Boolean algebra of subsets of some set (Stone's theorem) and that 
the Boolean algebra of subsets of a set is atomic and complete (Exercise 4 ). 
Finally, we know that there exist Boolean algebras that are not complete and 
others that are not atomic. These remarks permit us to answer questions (a) 
and (e): consider a Boolean algebra that is non-atomic (respectively, not com­
plete); it is isomorphic to a Boolean sub-algebra of some Boolean algebra 
A of subsets of a set; A is a Boolean algebra that is atomic and complete 
and has at least one sub-algebra, B, that is not atomic (respectively, not 
complete). 
The answers to questions (b) and (f) are affirmative: it suffices to consider 
a finite Boolean algebra. For (b), there are also examples that are infinite 
(Example 2.55); but for (f). it can be shown that the finite Boolean algebras 
are the only ones. 
The answers to questions (c) and (d) are negative: every Boolean algebra has 
at least one sub-algebra that contains atoms: the sub-algebra consisting of 0 and 
1, in which 1 is obvious! y an atom. 
19. Preliminary remarks: Given a map .f from a set E into a set F, let us agree 
to write J-1 to denote the 'inverse image map' from g;y (F) into g;y (E) (which, 
with each subset Y of F, associates the set {x E E :  .f(x) E Y}; we reserve the 

S O L U T I O N S  F O R  C H A P T E R  2 
291 
notation .r- 1 to denote the inverse (from F into E) of the map f in the case 
where f is a bijection). 
Let us recall some well-known properties of the inverse image map. 
As opposed to the 'direct image' map, the inverse image map preserves all 
the Boolean operations on g; (F) and p (E), which means that for all subsets X 
and Y of F, we have 
or in other words, J- 1 is a homomorphism of Boolean algebras from t;.J (F) 
into p (E). 
Moreover, we have the following two equivalences: 
J- 1 is injective if and only if f is surjective; 
J-1 is surjective if and only if f is injective. 
Proof: If f is surjective and if Y and Z are subsets of F such that f- 1 (Y) =· 
--
J -1 (Z), we see easily that Y n lm(j) = Z n lm(j), i.e. Y 
:= Z, hence 
²--1 is injective; if f is not sutjective, and if y E F 
- lm(j), then we have 
J-l ({y}) = j- 1 (0), hence J- 1 is not injective; i f f  is injective and if X is 
a subset of E, then we have X = J-1 (f(X)) (we have abused notation and 
written f(X) for the direct image of X under f), hence J-1 is surjective; fi­
nally, if f is not injective and if x and y are distinct elements of E such that 
j(x) = f(y), then it is clear that {x} ° lm(f-1 ) and y fJ lm(j-1 ), hence f-1 
is not surjective). 
Suppose now that A =  (A, +, x ,  0, 1) and A' = (A', +, x ,  0, 1). 
As well, let us write HA (respectively, HA') to denote the isomorphism of 
Boolean algebras from A onto B(S(A)) (respectively, from A' onto B(S(A'))) 
constructed using Stone's theorem. 
(a) For every homomorphism cp E Hom(A, A'), let us define <l>(cp) to be the 
map from S(A') into S(A) which, with each homomorphism h from A' into 
{0, 1}, associates the homomorphism h o cp from A into {0, 1} obtained by 
composition. 
Let us prove that <I> ( cp) is a continuous map: 
We will tnvoke Lemma 2.5, naturally taking the clopen subsets of S(A') 
and S(A) as bases for the open subsets. Let Q be a basic open subset of 
S (A). There then exists an element a E A such that Q = H A (a) = {h E 
S(A) : h (a) = 1}. Thus we have 
<l> (cp)-1 (Q) = {h' E S(A') : ((<l> (cp)) (h'))(a) = 1} 
= {h' E S(A') : (h' 
o cp)(a) = 1} 
= {h' E S(A') : h' (cp(a)) = 1 } = HA'( cp(a}). 
So this is a basic open subset of S(A') .  Hence Q (cp) E C0(S(A'), S(A)). 

292 
S O L U T I O N S  
We are now going to define a map \lJ from C0(S(A'), S(A)) into 
Hom(A, A') and we will then show that it is the inverse of the map ¢. 
For every map a E C0(S(A')S S(A)), set 
Observe that because a is continuous, the inverse image of any clopen 
subset of S(A) is a clopen subset of S (A'); in other words, the restriction 
of the map a-1 to B(S(A)) assumes its values in B(S( A')); this validates 
our definition of \IJ(a). Moreover, as we recalled earlier, a-1 is a homo­
morphism. Consequently, the map \l(a), which is the composition of three 
homomorphisms of Boolean algebras (see the diagram below) is indeed an 
element of Hom(A, A'). 
A 
-
-
-
---+ 
A' 
I 
w(a) 
i 
I 
I 
HA 
I 
I 
H-t 
A' 
I 
I 
! 
I 
B(S(A)) -
-
--
---+ B(S(A')) 
- -1 
0 
Let us show that \I o <I> is the identity on Hom(A, A'). For every cp E 
Hom(A, A'), ('-1 o <I>)(cp) is the map from A into A' which, with each 
element a E A, associates 
((tl o <l>)(cp))(a) = H A' 1 ( <l> (cp)-1 ({h E S(A) : h(a) == 1})) 
= HV/ ({g E S(A') : ((¢(cp))(g))(a) == 1}) 
= HA/ ({g E S(A') : (g o  cp)(a) == l}) 
= HA/ (HA'(cp(a))) == cp(a). 
Hence, 
(\lJ 0 <l>)(cp) = cp. 
Next, we show that <I> o \I is the identity on C0(S(A'), S(A)). For every 
continuous mapa from S(A') into S(A), (¢ o W)(a) is the map from S(A') 
into S(A) which, with each element g E S(A'), associates 
((¢ o \IJ)(a))(g) = (<t>(HA,1 o a-1 o HA))(g) 
= g o HA} o a·- I o HA . 

S O L U T I O N S  F O R  C H A P T E R  3 
293 
Now, by definition of H A'J , we have (for example, see the proof of 
Theorem 2.92) that for all a E A ,  
g( H A} (a- 1 (H A (a)))) = 1 if and only if g E a-1 (HA (a)), 
which is equivalent in turn to 
and to 
(a(g))(a) = 1. 
Consequently, for every a E A, 
(let us not forget that the only possible values are 0 and 1). 
We conclude that 
H-1 
ձ 
H 
( ) 
g o 
A' o a 
o A = a g , 
which shows that ( <}) o \lJ )(a) = a. 
We have thus established that ¢ and \IJ are two bijections that are inverses 
of one another. 
(b) It amounts to the same thing to prove that for every map 
a E C0(S(A'), S(A)), 
a is injective (respectively, surjective) if and only if \lJ (a) is surjective 
(respectively, injective). Now this is a nearly immediate consequence of 
the definition of \IJ and the properties of the inverse image map that were 
discussed in the preliminary remarks. Indeed, we have 
\(! (a) = H A' 1 o a -1 o H A. 
Since H A'l and HA are both bijections, we also have 
a-1 = HA o 'lJ(a) o HA,1 • 
We conclude that \l (a) is injective (respectively, surjective) if and only 
if a-1 is; but we have seen that this happens if and only if a is surjective 
(respectively, injective). 
Solutions to the exercises for Chapter 3 
1. First we observe that Ft is a consequence of each of the F;, that each of the 
F; is a consequence of F2, that F4 is a consequence of F3 and that F6 is a 
consequence of Fs (see Exercise 5(b)). 

294 
S O L U T I O N S  
Moreover, it is easy to verify that in every structure whose base set is N*, in 
which the symbol g is interpreted by the 'addition' map, and the symbol f by a 
sequence u = (un)nEN* (a map from N* into N*), the following properties will 
hold: 
• Ft is satisfied if and only if u is a sequence that assumes some value at least 
twice (i.e. it is not injective); 
• F2 is satisfied if and only if u is a constant sequence; 
• F3 is satisfied if and only if the sequence u is periodic; 
• F4 is satisfied if and only if each value assumed by the sequence u is assumed 
infinitely many times; 
• Fs is satisfied if and only if the sequence u is stationary (i.e. is constant from 
some point on); 
• F6 is satisfied if and only if u is a sequence such that for every integer p E N*, 
there exists an index n E N* for which un == Un+p· 
These remarks allow us immediately to answer the questions asked: 
(a) The six formulas are satisfied since F2 is. 
(b) Are satisfied: F1 , F3 (the period is 4) and F4; are not satisfied: F2, Fs, and 
F 6 (there is no integer n for which Un == Un+l ). 
(c) Are satisfied: Ft, Fs, and F6; are not satisfied: F2, F3, and F4 (the values 
3, 6, 1 1 ,  and 18 are assumed only once; these are, respectively, u 1 ,  u2, u3, 
and u4). 
(d) FJ is satisfied (we have u2 == u4 == 2); the other five formulas are not 
satisfied: the sequence is neither constant nor periodic nor stationary and it 
assumes the value 1 only once; finally, if n > I, n, and n + 1 can not have 
the same smallest prime divisor ( 1  is not a prime number!). 
2. Using the distributive rules for quantifiers (Theorem 3.55) as well as some 
common tautologies, in particular, 
(A => (B ==> C)) <=> ((A 1\ B) => C), 
we obtain the following formulas H; that are equivalent to the corresponding G; : 
HI : 3x'v'y(Px ==> Rxy) 1\ 'v'yPy 1\ 'v'y3z-.Ryz; 
H2 : 'v'x'v'z(Rzx ==> Rxz) ==> 3x'v'yRyz; 
H3 : 3z'v'tRtz 1\ 'v'y'v'x(Rxy ==> -.Rxy); 
H4 : 3x('v'y(Py =? Ryx) 1\ 'v'y('v'u(Pu =? Ruy) ==> Rxy)); 
H 5 : 'v'x'v'y( (Px 1\ Py 1\ Rxy 1\ -·Ryx) ==> 3z(-•Rzx A -.Ryz)); 
H6 : 3u'v'x3y(Rxy A Pu A Py) ==> Vz3xRzx. 
We then see that HI is false in any structure in which Vy P y is false, which 
is obviously the case for the three structures under consideration. We also see 

S O L U T I O N S  F O R  C H A P T E R  3 
295 
that H3, which is equivalent to 
3zYt Rtz A Yy\lx--,Rxy, 
is contradictory. Finally, we observe that H6, which is further equivalent to 
(3uPu A Yx3y(Rxy 1\ Py)) :::} Yz3xRzx, 
is clearly a universally valid formula. 
It follows from these remarks that in the three structures under consideration, 
G 1 and G3 are false and G6 is satisfied. As for G2, G 4, and G s, we must examine 
each structure separately. 
(a) The formula 3xYy Rxy is satisfied (0 is the least element for <), hence H2 is 
satisfied. If H4 were satisfied, then the formula 3xYy(P y =} Ryx) would 
also be satisfied and there would exist an integer that is an upper bound 
for all the even integers, which is absurd; thus H4 is false. As for Hs, it is 
satisfied: if m and n are even integers such that m < n, then we can find 
an integer p (for example, one half the sum of m and n ) such that m < p 
and p < n. 
Conclusion: G2, Gs, and G6 are satisfied while G 1 ,  G3, and G4 are not. 
(b) The formula H2 is satisfied for reasons that are analogous to those for case 
(a): the empty set is the least element for the relation c. The formula H4 is 
satisfied: it suffices to take x to be the set N; indeed, N contains all its finite 
subsets and any subset of N that contains all the finite subsets of N is the 
whole of N. The formula Hs is also satisfied: if X and Y are finite subsets 
of N such that X ळ Y (strict inclusion), then by choosing an integer n that 
is not in Y (which is always possible), the subset {n} of N is not included 
in X and does not include Y (note that Y can not be empty). 
Conclusion: G2, G4, Gs, and G6 are satisfied while G 1 and G3 are not. 
(c) The formula H2 is satisfied: indeed, the interpretation of the symbol R is 
not symmetric, so the formula YxYz(Rzx :::} Rxz) is false. If H4 were 
satisfied, then the formula 3xYy(Py :::} Ryx) would also be satisfied, so 
there would exist a real number that would equal the square of al1 rational 
numbers, which is absurd; so H4 is false. The formula H s is satisfied: if 
x and y are two rational numbers such that y = x2 and x =!= y2, then it 
suffices to take z = x and we will have x =!= z2 and z =!= x2. 
Conclusion: G2, Gs, and G6 are satisfied while G 1 ,  G3, and G4 are not. 
3. (a) We may take 
F = Yxfx  gx A Yx'Vyfx  fy; 
G = Yx(3y x ¥ fy ==} 3z x ¥ gz); 
H = 3x3y(fx  gy A YzYt(fz  gt :::} fz H fx)). 

296 
S O L U T I O N S  
We could just as well have taken the formulas F2 and F3 from (b) in place 
of F and G respectively. 
(b) For every £-structure M = (M, f, g), we have: 
o M  I= Ft if and only if f = g; 
o M I= F2 if and only if f = g and f is a constant map; 
o M I= F3 if and only if lm(f) c lm(g ); 
o M I= F4 if and only i f  lm(g) c lm(f) and g is constant; 
o M I= F s if and only if lm(f) n lm(g) is a non-empty set. 
Based on these remarks, it is easy to produce the desired models. In each 
case, the underJying set is N and we will simply give the interpretations f 
and g of f and g: 
for a model of Ft 1\ -.F2 : 
for a model of F2 : 
for a model of --.FI 1\ F3 : 
for a model of --. F1 1\ F4 : 
for a model of --.F3 1\ -.F4 1\ F 5 : 
for a model of --. Fs : 
4. For G, we may take the formula 
f = g = n . n + 1 ; 
f = g = n N-;- 0; 
f = n t--7 1 and g = n •ʞ n + 1 ;  
f = n L n + 1 and g = n L 1; 
f == n t--7 2n and g = n / n2; 
f = n t--7 2n and g = n . 2n + 1 .  
Set H = 3!vo3!v1 F and K = 3!vl3!voF. If the language L has a single 
binary relation symbol R and if F is the formula 
Rvovt , 
then the L-structure {N, < )  is a model of K but it is not a model of H nor of 
G. Indeed, the following properties hold: 
{a E N : { N : vo M a) I= 3! v 1 R vo vI } = C1 
(no integer has a unique upper bound); 
{b E N : {N : VI ---+ b) F= 3!voRvovd = {0}; 
(0 is the only natural number that has a unique lower bound (which is, of 
course, 0)). 
So it is true that there is a unique natural number that has a unique lower bound, 
but it is false that there exists a unique natural number that has a unique upper 
bound. Since it is obviously false that there exists a unique pair (a, b) E N2 
such that a < b, we have here a mode) of K, of _,H and of _,G. We obtain a 
model of H and --.K by considering the structure {N, >). This shows that the 
formulas G, H, and K are pairwise inequivalent. 

S O L U T I O N S  F O R  C H A P T E R  3 
297 
5. (a) The answer is negative: in the language whose only symbol is the one for 
equality, consider the formula A [x, y] = ...,x ° y͙ it is clear that in any 
structure that has at least two elements, the formula V'x3yA[x, y] is satisfied 
but the formula 3yVxA[x, y] is not. 
(b) This time the answer is positive: let M = (M, . . .  ) be an L-structure that 
satisfies the formula 3yVxA[x, y] and consider an element a belonging to 
M such that (M : y  a ) F= VxA [x, y]; then for every b in M, we have 
(M : y  a, x M b) F= A [x, y], 
hence (M : x ě b) F= :3yA[x, y], which shows that M F= Vx3yA[x, y]. 
This result is already included, by the way, in part (9) of Theorem 3.55. 
(c) 1 t suffices to apply part ( 4) of Theorem 3.55 twice. 
(d) Subject to a change of bound variables, question (c) shows that the formula 
VuVv(A[u, v] :::} B[u, v]) :::> 3x3y(A[x, y] :::} C[x, y]) 
is equivalent to 
3x3y((A[x, y] :::} B[x, y]) ==} (A[x, y] :::} C[x, y])). 
Applying (c) a second time, we see that if we set 
G = (A [X ' y] :::} A [y' X]) :::} 
((A [x, y] => B[x ,  y]) :::} (A[x, y] :::} C[x, y])), 
then F is equivalent to 3x3yG. 
6. Let F [ x 1 , X2, .
•
.
 , Xm , y 1 , Y2, .
.
•
 , y n] and G [ x 1 , X2, .
.
•
 , Xm , Z 1 , Z 2, . . .  , z p] be 
two formulas in a language L that are universally equivalent. This means that 
for every L-structure M = (M, . . .  ) and for all elements a 1 ,  a2, . . . , am , bt , 
b2, . . . , bn, CJ , c2, . . .  , Cp belonging to M, we have 
if and only if 
(*) 

298 
S O L U 1  I O N S  
We need to prove that the formulas 
Fo == 'Vx1'Vxz . . .  'Vxm'VYI'VYz . . .  'Vyn F and 
Go == 'Vx1'Vx2 . . .  'Vxm'VZJ 'Vz2 . . .  'VzpG 
are universally equivalent. To do this, consider a model M == (M, . . .  ) of Fo and 
arbitrary elements a 1 ,  a2, . . .  , am, C J ,  c2, . . . , cp of M. By choosing arbitrary 
elements b1, b2, . . .  , bn in M, we have M F F[aJ, a2, . . .  , am, b1 , b2, . . . , bn] 
since M is a model of Fo; thus, by (*), M F= G[a i ,  a2, . . .  , am, CJ , c2, . . .  , cp], 
which shows that M is a model of Go. In the same way, we show that any model 
of Go is a model of Fo, which proves the desired result. 
7. (a) For every i between 1 and 6, we provide a formula Gi that answers the 
question; we leave the verifications to the reader. 
G 1 == 3x'VyRxy; 
G2 == 'Vx'Vy((Rxy 1\ ..,x  y) =} 3z(Rxz 1\ Rzy 1\ -,z  x 1\ ..,  y)); 
G3 == 3x ··x * x  x; 
G4 == 'Vx(x * x  c =} x  c); 
Gs == 3x x * x  d tB d; 
G6 == 'Vx'Vy'Vz(Rxy v Ryz v Rxz). 
(b) The formula F1 (where the language is {c, ffi, *}) is satisfied in the structure 
(ੂ, 0, +, x) (in IR, every polynomial of degree 1 has a root); ··FI is satisfied 
in the structure (Z, 0, +, x) (the polynomial 2X + 1 ,  for example, does not 
have a root in Z). 
The formula F2 (in the same language) is satisfied in the structure 
(<C, 0, +, x) (in <C, every polynomial of degree 2 has a root); -.F2 is satis­
fied in (IR, 0, +, x) (the polynomial X2 + I ,  for example, does not have a 
root in IR). 
The formula F3, which expresses (in the language {R}) that the interpre­
tation of R is an equivalence relation, is satisfied in the structure (Z, =2) 
while ..,p3 is satisfied in the structure (Z, <) (the relation < on Z is not 
symmetric). 
The formula F4 (in the language { *' R}) is satisfied in the structure 
(N, x ,  <), while -,p4 is satisfied in (Z, x ,  <) (the usual order relation 
is compatible with multiplication in N but not in Z). 
The formula Fs, which is equivalent to 'Vx\Jy-,(Rxy A Ryx ), is satisfied 
in the structure (Z, <) (strict order) while its negation is satisfied in the 
structure ( Z, < ) . 
8. (a) F1 is satisfied by an integer n E M if and only if n has no other divisor than 
itself, i.e. if and only if n is prime. 
F2 is satisfied by an integer n if and only if any two divisors of n are 
comparable for the relation 'divides'. Now any number that is a power of 

S O L U T I O N S  F O R  C H A P T E R  3 
299 
a prime has this property: indeed, if n = pk, and if r and s divide n, then 
there are integers i and j less than or equal to k such that r = pi and s = pl 
and it is clear that either r divides s or s divides r. On the other hand, an 
element of M that is not a power of a prime has at least two distinct prime 
divisors (note that I is not in M), neither of which divides the other. So such 
an element does not satisfy F2. Thus, the integers in M that satisfy F2 are 
precisely the powers of primes. 
If an integer n E M satisfies F3., it also satisfies the following consequence 
of F3 (obtained by letting y equal z in F3 and invoking a well-known 
tautology): 
'Vy((Ryx 1\ Ryy) į Rxy). 
So every divisor of n must equal a multiple ofn, which amounts to saying 
that every divisor of n must equal n, as for Fr . It follows that a number that 
is not prime does not satisfy F3. On the other hand, if n is a prime number, 
if r divides n and if s divides r and if n, r, and s are in M, then r == s == n, 
hence n divides s ;  so we see that n satisfies F3. Thus, the elements of M 
that satisfy F3 are precisely the prime numbers. 
By 'distributing' the quantifiers according to the usual rules, we easily 
see that f4 is universally equivalent to the following formula: 
'Vt (Rtx ? 3y3z(Ryt 1\ Rzy 1\ -,Rtz)). 
But it is easy to verify that the formula 3y3z(Ryt 1\ Rzy 1\ -,Rtz) is also 
equivalent to 
-,"f/y'Vz(Ryt į (Rzy į Rtz)). 
Now this last formula is none other than _, F3rtx . So the formula f4 is 
equivalent to 
In this way, we see that for an element n E M to satisfy F4, it is necessary 
and sufficient that no divisor of n satisfy F3, which amounts to saying that 
the elements of M that satisfy F4 are those that have no prime divisors. But 
in M, every integer has at least one prime divisor. Hence the set in question 
is the empty set. 
(b) For G, we may take the following formula: 
Rtx 1\ Rty 1\ Rtz 1\ ( (Rux 1\ Ruy 1\ Ruz) ͚ Rut), 
which is satisfied by a quadruple (a, b, c, d) from M if and only if d is a 
common divisor of a, b, and c and every common divisor of a, b, and c is 
a divisor of d. 

300 
S O L U T I O N S  
(c) (1) We change the names of the bound variables in H and then 'bring them 
to the front' by applying the usual rules. In this way, we obtain, in 
succession, the following formulas that are equivalent to H, with the 
last formula in prenex form: 
VxVyVz((3v(Rvx 1\ Rvy) 1\ 3w(Rwy 1\ Rwz)) 
=} 3tVu(Rut =} (Rux A Ruz))); 
VxVyVz(3v3w((Rvx A Rvy) A (Rwy 1\ Rwz)) 
=} 3tVu(Rut =} (Rux 1\ Ruz))); 
VxVyVzVvVw3tVu(((Rvx 1\ Rvy) 1\ (Rwy 1\ Rwz)) 
=} (Rut =} (Rux A Ruz))) . 
(2) Consider the following sub-formula of H: 3tVu(Rut =} (Rux A Ruz)). It 
is satisfied in M when the variables x and z are interpreted respectively by 
a and c if and only if there exists an integer d E M all of whose divisors 
(in M) divide a and c; this amounts to saying that a and c have at least 
one common divisor in M, or again that a and c are not relatively prime. 
The interpretation of H in M is then clear: H is satisfied in M if and only 
if for all integers a, b, and c greater than or equal to 2, if a and b are not 
relatively prime and if b and c are not relatively prime, then a and c are 
not relatively prime. Now this is manifestly false: (a, b, c) == (2, 6, 3) is a 
counterexample. 
(3) We obtain a model of H by taking N as the underlying set and interpreting 
R by the equality relation in N; it is immediate to verify this. 
9. (a) Let QI , /1 , and R1 denote the respective interpretations of Q, /, and R in 
the structure M. First, observe that the infinite subsets of N all have the 
same cardinality (they are all in one-to-one correspondence with N). 
The formula F1 is not satisfied in M since we have 0 c 0 and card(0) == 
card(0 - 0); so M  3x Rxx. Note that for every non-empty subset X 
of N, we have (X, X) tt. R1 since card( X) > 0 while card(X - X) == 0. 
As the elements of n1 are infinite, hence non-empty, we see that M F= F2. 
Suppose that X and Y are two elements of n 1 and that Z is a subset of N 
such that X c Z c Y; then Z is infinite (since it includes the infinite set 
X) and N - Z is infinite (since it includes the infinite set N - Y); hence 
Z E Q 1 , which proves that M F= F3 . Let X, Y, and Z be three elements 
of n1 such that (X, Y) E Rt and ( Y, Z) E Rt; then we have X c Y c Z 
and the sets Y - X and Z - Y are infinite; thus Z - X is infinite since 
Z - X == (Z - Y) U (Y - X); it follows that (X Z) E Rt and that M F F4. 
For all subsets X and Y of N, we can not have both (X, Y) E R1 and 
( Y, X) E R 1 unless X == Y == 0; as 0 tt n 1 ,  we conclude that M I= Fs. 
Let 2N denote the set of even natural numbers; we have 2N E n 1 and 
(2N, N) E R1 but N tt n 1 ,  hence M հ F6. For all subsets X and Y of 
N such that X E n, and ( Y, X) E Rt , Y is a subset of X that must be 

S O L U T I O N S  F O R  C H A P T E R  3 
301 
infinite (otherwise X - Y would be finite and (X - Y) U Y = X would be as 
well); moreover, N - Y, which includes N - X, must also be infinite; hence 
Y E Q 1 and M I= F1. If X is a finite subset of N whose cardinality is odd, 
then there is no partition of X into two sets whose cardinalities are equal; 
then no subset Y of N can satisfy ( Y, X) E R 1 ;  so M S Fg. In contrast, if 
X is an element of Ql , then we can find, on the one hand, a partition of X 
into two infinite sets Y and Y' and, on the other hand, a partition of N - X 
into two infinite subsets Z 1 and Z2; by setting Z = X U Z 1 ,  we see that Y 
and Z belong to Q 1 and that ( Y, X) E R1 and that (X, Z) E R 1 ;  it follows 
that M t= Fg. Let X and Y be two elements of QI such that (X, Y) E R1 ; 
then the set Y - X is infinite (for it is equipotent to X); so we can then 
partition it into two infinite subsets X 1 and X 2; set Z = X U X 1 ;  we then 
have X c Z c Y and the sets X, Z - X = X 1 ,  Y - Z = X2, and N - Z 
are all infinite, which proves that (X, Z) ҙ R1, (Z, Y) E R1, and Z E QI; 
it follows that M t= FIO· 
(b) Let D 1 be a subset of 8J (N) and let M' be the enrichment of the structure M 
obtained by interpreting the symbol D by the set D I ·  For the four formulas 
under consideration to be satisfied in M', it is necessary and sufficient that 
D1 be non-empty (formula G4) and that the inclusion relation restricted to 
D1 be a total ordering (formula G 1 )  that is dense (i.e. for all subsets X and 
Y in D1, if X ऴ Y, then there exists a subset Z E D1 such that X Α Z Α Y) 
(formula G2) and that has no least or greatest element (formula G3). We 
will now construct a subset D 1 of tp (N) that has these properties. First, 
we define a subset E 1 of g;y (Q) that has these same properties: this is not 
difficult; it suffices, for example, to set J r = r -r, r] n Q for each rational 
r > 0 and to then set £1 = {lr : r E Q৫}; we have £1 =I= 0 and the 
inclusion relation on E 1 is a dense total ordering (if 0 < r < 
s, and if 
t = r!s, then J r Ÿ lt Α ls) with no least nor greatest element. 
We then convert from g; (Q) to g; (N): choose a bijection cp from Q onto 
N (one does exist; see Chapter 7); cp induces a bijection ¢ from g;J (Q) 
onto g;y (N) (for every X E g;y (Q), ¢(X) = {qJ(x) : x E X}) that is an 
isomorphism between the ordered structures (g;y (Q), C) and (g;y (N), C) 
(the verification is immediate). It follows that the subset D1 = ¢ (Et) 
of N answers the question. 
10. (a) In the examples that we are about to give, 0 and 1 are constant symbols, f 
is a unary function symbol, g, +, and व are binary function symbols, U 
and V are unary relation symbols, and R is a binary relation symbol. To 
show that the set X c N is the spectrum of a formula F, we must show, on 
the one hand, that the cardinality of every finite model of F is an element 
of X and, on the other hand, that for every element n in X, there exists a 
model of F whose cardinality is n. There is a tendency to omit this second 
condition, which is, however, indispensable. 
( 1 ) L = {f}; F = VxVy(fx ::: fy =} x  y) 1\ 3xVy-.x ::: fy. 

302 
S O L U T I O N S  
(The existence of an injective map from the base set into itself that is 
not surjective is possible only if this set if infinite; so F does not have 
any finite models). 
(2) Impossible. The base set of any structure is non-empty, hence 0 can not 
belong to the spectrum of any first order formula. 
(3) L reduces to the equality symbol; F = Y x x ¥ x. 
(4) L = {f}; F = Yx(ffx ¥ x 1\ -,jx Ö x). 
(Let (M, cp) be a finite model ofF. Then cp is an involution (i.e. cp o cp 
is the identity map) from M onto M that has no fixed points. The binary 
relation Қ defined on M by 
a Қ b if and only if cp(a) = b or cp(b) = a  
is an equivalence relation whose equivalence classes each contain ex­
actly two elements. As the classes constitute a partition of M, we see 
that the cardinality of M is an even number. Conversely, for a non-zero 
even number n = 2 p, we obtain a model of F of cardinality n by taking 
{ 1 ,  2, .
. . , n} as the base set and by taking the interpretation of f to be 
the map 
k M k + p 
if I < k < p ;  
k M k - p if p + I < k < n .  
( 5) L = { U, G}; F is the con junction of the formulas 
and 
G = Yx3y3z(Uy 1\ Uz l\ X  gyz) 
H = Yx\:ly\:lz\:lt ((Ux /\ Uy 1\ Uz 1\ Ut 1\ gxy Ö gzt) 
=} (X Ö Z I\ y ৰt)). 
(Let (M, Uo, go) be a finite model of F. Then the restriction of go to 
Uo x Uo is a bijection from Uo x Uq onto M; thus the cardinality of 
M is that of Uo x Uo, which is a perfect square. Conversely, for every 
integer n > I ,  if n is a perfect square, for example n = p2, it is easy 
to verify that the formula F is satisfied in the L-structure (M, Uo, go), 
where M = {0, 1 ,  2., .
. . , n - 1}, Uo = {0, 1 , 2, . . .  , p - 1} and go is 
the map from M x M into M which, with each pair (a, b), associates 
ap + b if a and b both belong to Uo and 0 otherwise.) 
(6) L = {¥}; F is the formula 
3x3y3z(-,x ʝ y 1\ -,Y " z 1\ _,x " z 1\ Yt(t & x v t "' t v  t " z)). 
(7) L = {¥}; F = 3x3y3z3t\:lu(u  x v u ¥ y v u  z v u '"'v t). 
(8) L = {¥}; F = 3vo3vi . . .  3vk 1\o<i<j<k _,v; Ö Vj· 

S O L U T I O N S  F O R  C H A P T E R  3 
(9) L = { U, V, g}; we set 
A = VxVy x Ø y; 
B = Vx3y3z(Uy 1\ Vz 1\ x Ø gyz); 
C = VxVy'VzVt((Ux 1\ Vy 1\ Uz 1\ Vt 1\ gxy Ø gzt) 
:::} (x H z 1\ y H t)); 
D = 3x3y(Ux 1\ Uy 1\ -.x Ø y) 1\ 3z3t(Vz 1\ Vt 1\ -·z H t); 
and we take 
F == (A v (B 1\ C 1\ D)). 
303 
(The inspiration comes from (5)). Given a finite model (M, Uo, Vo, go) 
of F, either M is a singleton or else Uo and Vo each have at least 
two elements and the restriction of go to Uo x Vo is a bijection from 
Uo x Vo onto M. Thus the cardinality of M is either equal to 1 or else is 
the product of two integers that are both greater than or equal to 2, i.e. 
it is, in all cases, not a prime number. Conversely, for every non-zero 
integer n that is not prime, it is easy to construct a model of F that has 
n elements). 
(10) L = {0,1,+,͛, R} (the language of fields, together with a binary rela­
tion symbol). Let I denote the conjunction of the axioms for a commu­
tative field together with formulas expressing that the interpretation of 
R is a total order relation; let J be the following formula: 
'VxROx 1\ 'Vx(3y(Rxy 1\ -.x ͜ y) ==> (Rxx+l 1\ 'Vt((Rxt 1\ --,x Ø t) 
:::} Rx+ lt))). 
We then set 
F = I  1\ J. 
(Let (K, 0, 1, +, x ,  <} be a finite model of F; K is then a finite field 
with an order relation < for which 0 is the least element and in which 
every element a that has a strict upper bound has a least strict upper 
bound (a successor), namely a + 1. Let us agree to denote the strict 
order associated with < by <. Recall that the characteristic of K is 
the least integer m > 0 such that m1 = 0 (m1 denotes the element 
1 + 1 + · · · + 1, with m occurrences of 1) and it is easy to show that this 
characteristic is always a prime number, which we will here denote by 
p. The satisfaction of the formula J shows that we have (if, for every 
integer j, we denote the element j1 by j) 
0 < 1 < 2 < · · · < p- l ,  
(so the cardinality of K is at least equal to p) and that for every integer 
k with 0 < k < p - 2, there is no element of K that is strictly between 

304 
S O L U T I O N S  
K and k + 1. Since the order is total and since 0 is the least element, 
any element of K other than 0, 1, . . .  , p - 1 must be strictly greater 
than p - 1. 
It follows that if the cardinality of K is strictly greater than p, we 
can find an element b in K for which p - 1 < b; p - 1 then has a 
strict upper bound hence, according to formula J, it is strictly less than 
p - 1 + 1 == p == 0 since p is the characteristic of K. We would then 
have 0 < p - 1 and p - 1 < 0, and hence 0 < 0 by transitivity, which 
is absurd. So the cardinality of K is equal to p (and K is isomorphic 
to the field 7l/ p?l). Thus the cardinality of any finite model of F is a 
prime number. 
Conversely, for every prime number p, if we let < denote the total or-
-
-
-
dering on 7lf p?l defined by: 0 < 1 < · · · < p - 1 (here, k is the equiv-
alence class of k modulo p ), then the structure (7l/ p?l, 0, 1 ,  +, x ,  <) 
is a model ofF of cardinality p. The verification is immediate.) 
(b) Let G be a closed formula, in an arbitrary language, whose spectrum is 
infinite. For every integer k > 1, let Fk denote the formula 
3vo3v 1 
•
•
•
 3vk (\ 
..., Vi  v.i 
O<i<j<k 
that was previously used in part (8) of (a). Let T be the theory 
{ G} U { Fk : k E N* } . 
Given an arbitrary integer n ,  G has at least one model whose cardinality 
is greater than or equal to n + 1 since the spectrum of G is infinite. Such 
a model is also a model of { G} U { F1 , F2, . . .  , Fn }. This shows that every 
finite subset of T has a model. By the compactness theorem, T also has a 
model. But a model of T is nothing other than an infinite model of G. 
11. Let T be a non-contradictory theory in a language L such that all its mod­
els are isomorphic. All the models of T are then elementarily equivalent 
(Proposition 3.74); this means that T is complete (Definition 3.8 1 ). 
12. (a) Let M denote the base set of M. RecaJl the three conditions that are nec­
essary and sufficient for a subset C to be the base set of a sub-structure 
of M: 
( 1 )  C is non-empty; 
(2) C contains the interpretations in M of the constant symbols of L; 
( 3) C is closed under the functions that are the interpretations in M of the 
function symbols of L. 
It is clear that the intersection of all the subsets of M that satisfy these 
conditions and that include A will be a set that again includes A (so is 
non-empty since we assumed that A is non-empty) and satisfies conditions 

S O L U T I O N S  F O R  C H A P T E R  3 
305 
(2) and (3) above. It is therefore the base set of some sub-structure of M 
that includes A. It is the base set of the desired structure A. 
The uniqueness of A is clear: if a sub-structure B has the indicated prop­
erties, then each of the structures A and B is a sub-structure of the other, 
hence A =  B. 
(h) If the language consists of the single binary relation symbol R, there is 
no sub-structure generated by 0 in the structure (IR, <): indeed, the two 
substructures ( {0}, <) and ( {1}, <) can not have a common sub-structure, 
so property (2) must fail. In fact, whenever the language does not contain 
any symbols for functions or for constants, then there can not be a sub­
structure generated by the empty set in any structure whose underlying 
set contains at least two distinct elements. However, in ( {0}, <) for exam­
ple, there is a sub-structure generated by the empty set: it is the structure 
itself! 
If the language has at least one constant symbol, then in any structure, 
the empty set generates the same sub-structure as that generated by the 
set of interpretations of the constant symbols (which in this case is non­
empty). For example, if the language is {c, f} (one constant symbol and 
one unary function symbol), then in the structure (N, 0, n L n -r- 1), 0 
generates the entire structure whereas in the structure (N, 0, n 
 n), 0 
generates the sub-structure ({0}, 0, n L n + 1). Let us give another ex­
ample, without constant symbols, but with a unary function symbol f. 
Consider a structure M in which f is interpreted by the constant function 
equal to a. In M, there is a sub-structure generated by the empty set: it is 
( {a}, identity). 
(c) Let C be the set of interpretations in M of the constant symbols of the 
language. If A U C is not empty, the substructure A generated by A has 
A U C as its base set; the interpretations of the constant symbols are the 
same as in M and the interpretation in A of each relation symbol is the 
restriction to A U  C. In the case where A = C = 0, the examples given in 
(b) show that nothing can be said in general. 
(d) If F is satisfied in M, then F is satisfied in every sub-structure of M 
(Theorem 3.70), in particular, in every sub-structure of finite type. 
Conversely, suppose that F is not satisfied in M .  
• If F has no quantifiers, then F is not satisfied in any sub-structure of M 
(Theorem 3.69; note that F is closed). Let a be an arbitrary element of 
M. The sub-structure of M generated by {a} is then a sub-structure of 
M of finite type in which F is not satisfied. 
• If F =: 'Vxt'Vxz . . .  'VxnG[xi , Xz, . . .  , xn] (where G has no quantifiers 
and n > I ), then we can find elements a 1 , az, . . .  , an in M such that 
M S G[a 1, az, . . .  , an]. Let A denote the sub-structure (of finite type) 
of M generated by {a1 , a2, . . .  , an}. We have A S G[a1 , a2, . . . , an] 

306 
S O L U T I O N S  
(Theorem 3.69). It follows that 
so we have a sub-structure of M of finite type in which F is not satisfied. 
(e) Let L be the language consisting of the equality symbol and let F be the 
formula 3x3y --,x H y; F is satisfied in the structure (N) but is not satisfi.ed 
in the sub-structure ( { 0}) generated by { 0}. 
13. (a) We argue by induction on t. 
• If t is of height 0, it is either a constant symbol c or a variable x. So one 
of the the formulas t ƞ c or t  x is universally valid and, a fortiori, a 
consequence of T. 
• If t = f u, the induction hypothesis presents us with four possibilities 
concerning the term u :  
* T F=* u H c; then T F=* t H fc; or T I=* fc H Jjgc(H3), T F=* ffgc H 
fgc (formula Ht) and T I=* fgc H c; it follows that T I=* t  c; 
* there exists a variable x such that T F'* u H x; then T I=* t ƞ fx; 
* there is a variable x such that T I=* u H fx; then T I=* t H fix; we may 
then conclude (formula HI) that: T I=* t H fx; 
* there is a variable x such that T ͔* u H gx; then T ͕* t H fgx; it then 
follows (formula H3) that: T F=* t ° c. 
• For the case where t = g u, the argument is analogous. 
(b) Let f and g denote, respectively, the maps (a, b) r-+ (a, bo) and (a, b) r-+ 
(ao, b) from A x B into A x B. For all pairs (a, b) E A x B, we have 
f(f(a, b)) = f(a, bo) = (a, bo) = f(a, b); 
g (g (a, b)) = g ( ao, b) = ( ao, b) = g (a, b); 
f (g (a, b)) = f ( ao, b) = ( ao, bo) = g (a, b o) = g ( f (a, b)); 
this shows thatthe formulas Ht, l/2, and H3 aresatisfiedin M(A, B ,  ao, bo). 
Let (a, b) and (a', b') be two elements of A x B. If f(a, b) = f(a', b'), 
then a = a'; and if g(a, b) = g(a', b'), then b = b', which proves the 
satisfaction of H4. Moreover, if f(a, b) = (a, b) and if g(a', b') = (ab'), 
then b = bo and a' = ao; in these circumstances, we have f (a, b') = (a, b) 
and g(a, b') = (a', b'); we have thus found an element whose image under 
f is (a, b) and whose image under g is (a', b'); thus Hs is satisfied in 
M (A, B, ao, bo). 
(c) Let M = ( M, a, cp, 1/1) be an arbitrary model ofT. In the fi.rst case under (a), 
we have already seen that M t= H6 and we prove in an analogous fashion 
that M F= H1. 
For every element x E M, if cp(x) = x, then l/f(x) = 1/J(cp(x)) = a 
(according to H3); conversely, if 1/f(x) = a, then 1/J(cp(x)) = a  (according 

S O L U T I O N S  F O R  C H A P T E R  3 
307 
to H3); since we also have q?(q?(x)) = q?(x) (according to Ht), the elements 
q? (x) and x have the same image under q? and the same image under 1/J; it 
follows (according to H4) that q?(x) = x. So we see that M կ= Hs. The 
proof that M I= Hg is analogous. 
Let us show that M I= H 10· The implication from left to right is evident 
(take v 1 equal to vo). Let x be any element of M. If there exists an element 
y in M such that x = q?(y)͖ then q?(x) = q?(q?(y)) = q?(y) (according to 
Ht ), so q? (x) = x. The proof for H1 1 is analogous. 
To show that M I= H12, we first note that the implication from right to 
left follows immediately from H6 and H1. In the other direction, let x be an 
element of M such that q? (x) = x and 1/r (x) = x; we then have 1/r (x) = a 
and cp (x) = a according to H 8 and Hg; hence x = a. 
It is immediate to verify that H13 is satisfied in M: if x and y are elements 
of M such that q?(x) = 1/J (y), then q?(q?(x)) = q?(1j;(y)), hence (according 
to H1 and H3) q?(x) = a. 
(d) Let f and g be the respective interpretations of f and g in M (A, B, ao, bo) 
and let J and g be their interpretations in M ( C, D, co, do). We may choose 
a bijection A (respectively, J.L) from A onto C (respectively, from B onto D) 
such that"A(ao) = co (respectively, tt(bo) = do). The map y from A x  B into 
C x D which, with each pair (x, y ), associates the pair ("A(x ), J.L(Y)) is an iso­
morphism between the structures M (A, B, ao, bo) and M ( C, D, co, do): 
indeed, y is first of all a bijection from A x B onto C x D; also, we have 
y (ao, bo) = (co, do) and'! for an pairs (a. b) E A X B. 
y(f(a, b)) = y (a, bo) = ("A(ao), do) = f("A(a), tt(b)) = f(y(a, b)), 
and, analogously, y (g(a, b)) = g(y (a, b)). 
(e) We begin by observing that a E A and a E B (H6 and H7 ); so the 
structure M (A, B, ao, bo) is well defined (we will continue to denote the 
interpretations of f and g in this structure by f and g). Let h denote the map 
from M into M x M which, with each element x in M, associates the pair 
( cp(x), 1/J (x)). The sa tis faction in M of the formulas H 10 and H II shows that 
A = lm(q?) and B = lm( 1/J ); so the values assumed by h are in A x B. The 
satisfaction of H4 shows that h is injective (if (q?(x), ljl(x)) = (q?(y), 1/J (y)), 
then x = y ), and the satisfaction of Hs shows that h is surjective onto A x B 
(if x = q?(x) and y = 1/1 (y ), then we can find an element z E M such 
that (x͗ y) = (q?(z)͘ 1/J(z)) = h (z)). So the map h is a bijection from M 
onto A x B. We will now show that it is a monomorphism from M into 
M (A ,  B, ao, bo). This is a consequence of the following properties: 
0 
0 
h (a) = (q?(a), 1/J (a)) = (a, a) = (ao, bo); 
for every x E M, h (cp(x)) = f(h(x)); 

308 
S O L U T I O N S  
. stnce 
h(cp(x)) == (cp(cp(x)), t/J(cp(x))) == (cp(x), a) 
(HJ and H3) 
== ( cp (X), ho) == f ( cp (X), l/J (X)) = j ( h (X)). 
o for every x E M, h(1jl(x)) = g(h(x)) (using a similar argument). 
The formulas 
F n = 3vo3VJ . . .  3Vn- L ( 1\ 
-·vi :::: v j 1\ 1\ f Vi :::: Vi) 
OÖi<j<n 
O×i <n 
and 
Gn = 3vo3vJ . . .  3vn-l ( 1\ -·vi :::: Vi 1\ 1\ gv; :::: Vi) 
OÖt <J <n 
O×i<n 
(for n > l) then clearly answer the question. 
Fix two strictly positive integers n and p. Let Tnp denote the models of T 
in which the interpretations off and g have n and p elements, respectively. 
ConsidertwomodelsM = (M, a, cp, 1/J) andM' == (M', a', cp', 1/J') ofTnp· 
Let A ==  lm(cp), B = lm(1jl), A' == lm(cp'), and B' = lm(1jl'); A and A' are 
equipotent (theybothhaven elements) and so are B and B' (which each have 
p elements). According to question (d), the structures M (A , B, a, a) and 
M(A', B', a' a') are isomorphic. Now we have seen that M is isomorphic 
to the first of these and M' to the second. It follows that any two models of 
the theory Tnp are isomorphic, which proves (Exercise I I )  that this theory 
is complete (it is non-contradictory by question (b)). 
(f) The infinite models of T are those models M == (M, a, cp. 1jl) of T for 
which at least one of the sets lm(cp) or lm(v;) is infinite. It follows that 
these are exactly the models of the theory 
T' == T U { Fk v Gk : k E N*}. 
The closed formulas that are satisfied in every infinite model of T are thus 
the closed formulas that are consequences of T'. If F is such a formula, 
there exists, by the compactness theorem, a finite subset X of T' such 
that X !-* F. There then exists an integer n > I such that X c Tn == 
T U { Fk v G k : 1 < k < n} and we have, naturally, Tn 1-* F. But it is 
obvious that for every integer k such that I < k < n, Fk is a consequence 
of Fn and Gk is a consequence of Gn; so Fk v Gk is a consequence of 
Fn v Gn. As a result, the theories Tn and TU{F11 VGn }  are equivalent and we 
have 
T U { Fn v Gn }  1-* F. 
The theory T' is not complete: as we have seen, its models are the in­
finite models of T; now in such models, one of the sets I m ( cp) or I m ( 1/J) 

S O L U T I O N S  F O R  C H A P T E R  3 
309 
can have an arbitrary finite number of elements; for example, the struc­
tures M(N, N, 0, 0) and M (N, {0}, 0, 0) are models of T' (they satisfy the 
formulas Fk for all k > 1) but the first satisfies the formula G2 while the 
second does not satisfy this formula; so these structures are not elementarily 
equivalent. 
(g) Questions (d) and (e) show that the models of T are determined up to 
isomorphism by the cardinalities of the sets that are the interpretations of 
f and g. Precisely, given a countably infinite model M of T, there exist 
two non-empty sets A and B, each of cardinality less than or equal to ηo, 
at least one of which is infinite, and two elements ao E A and bo E B such 
that M is isomorphic to the structure M (A, B, ao, bo). For each integer 
n E N*, set 
Moc n  =
= M (N, {0, 1 ,  . . . , n - 1 } ,  0, 0); 
Mnoo = M ({O, 1 ,  . . .  , n - 1 }, N, 0, 0); 
Moooo = M (N, N, 0, 0). 
We see that every countably infinite model of T is isomorphic either to 
M 00 oc or to one of the M 00 n or to one of theM noo. Naturally, these models 
are pairwise non-isomorphic. There are therefore, up to isomorphism, ηo 
countably infinite models of T. 
(h) The models of T" are the models of T in which the sets of fixed points 
of the interpretations of f and g are both infinite. The structure Moo 00 is 
clearly one such model. According to (g), it is immediate that every count­
ably infinite model of T" is isomorphic to M0000• The theory T" is thus 
ηa-categorical (Chapter 8); moreover, it is consistent and only has infinite 
models; it is therefore complete (Vaught's theorem, Part 2, Chapter 8). 
-
- -
14. (a) LetM = (M, f) bea model of A. Ifanelementa E M satisfies f(f(a)) = 
-
- - -
-
a, then by applying f againӛ we obtain f(f(f(a))) == f(a); but since 
- - -
-
A is satisfied in M, we have f(f(f(a))) = a and hence a = f(a), 
which is excluded (also by A). In an analogous manner, if we suppose 
- -
-
- - -
- -
- -
/(f(a)) = f(a), we obtain /(/(f(a))) = f(f(a)), i.e. a = f(f(a)) 
which, as we have just seen, is impossible. So the structure M satisfies the 
following formula G: 
\:1 X (--"f f X £ X 1\ -, f f X £ fx) 
· 
Furthermore, if we let b denote f(f(a)), we have f(b) = a and every 
-
- - -
element c E M that satisfies f(c) = a will also satisfy /(/(f(c))) = 
- -
f(f(a)), so c =  b. In other words, every element of M has a unique preim-
age under f (which is therefore bijective) and M satisfies the formula H: 
Vx3yVz(fy Ԧ x 1\ (fz 6 x ==> z ջ y)). 

310 
S O L U T I O N S  
The rules concerning 'distribution' of quantifiers show that the formula 
(G 1\ H) is equivalent to the formula proposed in the statement of the exer­
cise. So this formula is satisfied in every model of A, i.e. it is a consequence 
of A .  
(b) Letn bean elementofN* and letN = (N, J) be a model o f  A 1\ Fn· Define 
a binary relation p on N as follows: 
for all a and b in N, 
,..,_ 
,..,_ 
,..,_ 
(a, b) E p if and only if a = b or a = f(b) or a = f(f(b)). 
It is not difficult to verify that this is an equivalence relation. The equiv-
,.._, 
alence class of the element a is its orbit under the function f: it contains 
,..., 
""'-' 
"' 
the three elements a, j(a), and f(f(a)) (which are pairwise distinct) and 
only these. So every equivalence class contains three elements. Since these 
constitute a partition of N which has n elements, we conclude that n is a 
multiple of 3. 
Conversely, for every integer p > 0, we may construct a model Mp of 
A 1\ F3p that has 3p elements in the following way: 
For the underlying set, we take M P = {0, 1, 2} x {0, 1, 2, . . .  , p - 1 }  and 
as the interpretation of f we take the function /p defined as follows: 
for every pair (i, j) E M P' 
/p(i, j) = (i + l [mod 3], j). 
(c) It is sufficient (Exercise 1 1) to prove that for every p E N*, the models 
of A 1\ F3p are all isomorphic. So consider an integer p > 0 and a model 
M = (M, g) of A 1\ F3p· There are p classes for the equivalence relation 
p defined as in part (b). Denote them by Bo, B 1 ,  . . .  , B p-t and choose an 
arbitrary element b; in each B;. 
Now, define a map (J? :  M t-+ {0, l ,  2} x {0, 1 ,  . . .  , p - 1 }  by 
(J?(b;) = (0, i); 
(/> (g ( b; ) ) = ( 1, i ) 
(/> (g (g ( b;)) ) = ( 2 ' i). 
for all i E { 0 , 1 , . . . , p - 1 } 
(J? is an isomorphism from M onto the model Mp defined in (b) because 
the classes are in correspondence with one another and for every a E M, 
we have 
(J? (g (a)) = f p ( (J? (a)). 
(d) It suffices to generalize the construction of the models Mp from ques­
tion (b). 
This time, we take {0, l ,  2} x N as the underlying set. The interpretation 
of F is the unique function defined on this set that simultaneously extends 

S O L U T I O N S  F O R  C H A P T E R  3 
3 1 1  
all the /p (where the definition of /p is the same except that the index j 
can assume any integer value). 
(e) We generalize (c). Consider a countably infinite model of A. This time there 
is a countably infinite number of equivalence classes for p; denote them by 
{Bn : n E N}. Again, select a sequence {bn : n E N} such that bn E Bn 
for all n .  We define the isomorphism from this model onto the one defined 
in part (d) exactly as cp is defined in (c), the only difference being that n 
ranges over N. The verification is simple. All the countably infinite models 
of A are isomorphic (since they are all isomorphic to the model that we 
have constructed). 
15. PRELIMINARIES: First, observe that F is equivalent to the conjunction of the 
following formulas: 
'Vx'Vy(dx  dy =} x  y) 'Vx'Vy(gx ¥ gy =} x 6 y) 'Vx3u x ¥ du 
'v'x3v x ¥ gv 
'v'xdgx ¥ gdx. 
It follows that for F to be satisfied in a structure M = (M, d, g), it is 
necessary and sufficient that d and g be bijections that commute and that, at any 
given point, never assume the same value. As well, if M I= F, then for every 
natural number m, we have 
for every element a E M, dm(g(a)) == g(dm(a)). 
This is obvious if m == 0; suppose it is true for m == k; then 
dk+l (g(a)) == dk(d(g(a))) = dk (g(d(a))) 
[since g and d commutel 
== g(dk(d(a))) 
[by the induction hypothesis] 
= g(dk+I (a)). 
(a) We argue by induction on the height o fthe term t. Since there are no symbols 
for constants in L, a termt of height 0 is a variable, y for example, and since y 
can also be written d0 g 0 y (this is the same term), the formula 'V y t J d0 g0 y 
is universally valid; in particular, it is a consequence of T. 
If t == du and if T չ-* Vx u 6 dm gn x, then T r* 'Vx t 6 dm+l gn x. 
If t == gu and if T պ-* 'Vx u J dmgnx, then in every model M 
(M, d, g) of T, we have that for all a E M, g(dm(gn(a))) == dm(gn+l (a)) 
(preliminaries), which shows that T r-* Vx t 6 dm gn+I x. 

312 
S O L U T I O N S  
(We will have observed, although this was not explicitly used in the proof, 
that every term of L can be written in the form 
where x is a variable and where the m; and n; are natural numbers that are 
all non-zero, except possibly m 1 and nk ). 
(b) Mo is a model of F since the maps sd and sg are bijections that commute 
[sd(sg (i, j)) == sg (sd(i, j)) == (i + 1 ,  j + l) ] and do not assume the same 
value at any point [(i, j + 1 )  # (i + 1 ,  j)] . Also, for all i and j in ll and 
for all natural numbers m and n, we have 
Sdm (Sgl1 (i, j)) == (i + n, j + m). 
It follows that for (m. n) # (0, 0), we have 
Sdm (sgn (i, j)) # (i, j) and Sdm (i, j) == (i, j + m) # (i + n, j) = s8n (i, j). 
Thus, Mo is a model of each of the formulas Fmn((m, n) # (0, 0)) and, 
consequently, is a model of T. 
(c) The map hah is a bijection whose inverse bijection is h-a-h· Moreover, for 
all pairs (i, j) E ll x ll, we have 
hab(sd (i, j) ) = (i + a, j + I + h) == Sd(habU, j)); and 
hab (sg (i, j)) == (i + 1 + a, j + h) ==  Sg(hab(i, j)). 
So hah is an automorphism of Mo. 
In fact, it can be shown that there are no automorphisms of Mo other 
than the ones in the family of hah· (Hint: given an automorphism h of 
Mo, let h 1 and hz denote the maps from ll x ll into ll obtained by com­
posing h with the two projections [which means that for i and j in Z, 
h (i, j) == (h 1 (i, j), hz (i, j))] ; then show that h 1 does not depend on the 
second coordinate, that hz does not depend on the first coordinate, and that 
the functions of one variable that are naturally associated with h 1 and hz 
are bijections on ll that commute with the successor function.) 
(d) We already know that ll x ll and 0 are definable. 
Let A be a subset of ll x ll that is distinct from ll x ll and 0. Let i ,  j, k, 
andl be elements ofZ such that (i, j) E A and (k, l) fj A. Seta == k == i and 
h = l - j. We have hab Ci, j) == (k, l), which shows that A is not invariant 
under the automorphism hab and hence (Theorem 3.95) is not definable. So 
Z x Z and 0 are the only subsets of Z x Z that are definable in Mo. 
16. PRELIMINARIES: We describe a method that we will then use several times for 
determining all the definable subsets of the base set (or of some cartesian power 
of this set) in a model M == (M, . . .  } of a language L. 

S O L U T I O N S  F O R  C H A P T E R  3 
313 
Suppose that we have determined a finite number of subsets A 1 ,  A z ,  . . .  , An 
of Mk that are all definable in M and that constitute a partition of the set Mk. 
Suppose as well that for every index i between I and n and for all elements 
a = (at, az, . . .  , ak) and {3 = (hi ,  bz, . . .  , bk) belonging to A;, there exists 
an automorphism of the structure M that sends a to {3, i.e. that sends a 1 to 
bt1 az to bz, . . .  , ak to bk (this property is automatically satisfied for those A; 
that contain only a single element; the automorphism in question reduces to the 
identity). 
Under these circumstances, according to Theorem 3.95, for every subset X 
of Mk that is definable in M, each of the A; is either included in X or else 
is disjoint from X. It is then easy to conclude that every subset of Mk that is 
definable in M must be a union of sets chosen from among A 1 ,  Az, . . .  , An. In 
other words, the Boolean algebra of subsets of Mk that are definable in M is 
the sub-algebra of tJ ( Mk) generated by A 1 ,  A 2, . . .  , An. This sub-algebra has 
2n elements (refer to Exercise I 7  and to Corollary 2.5I). 
(a) Let A be a non-empty subset ofZ/nZ that is definable in M1 and let k be 
an element of A. For every element h E 7ljn7l, the map ifJ : x r-7 x + h - k 
is a bijection of 'l/ n'l onto itself that commutes with the map x ͝ x + I 
(which means that for all x E 7ljn7l, ({J(x + 1 )  = ifJ(x) + 1); so ifJ is an 
automorphism of the structure M 1 •  Since A is definable, it follows that h, 
which is equal to ({J(k), belongs to A (Theorem 3.95). Hence A = 7lfn7l 
since the only definable subsets of 'l/ n'l that are definable in M 1 are 0 and 
7ljn7l. 
In exactly the same way, (by replacing M 1 by Mz and x I-> x + 1 by 
x ͞ x + 2) we prove that the only subsets of 'l/ n'l that are definable in 
Mz are 0 and 'l/ n'l. 
(b) In the structure N1, the set {0} is defined by the formula gvovo H vo, and 
the set { I ,  2} by the negation of this formula. Also, the map x 1-ʜ x + x is 
clearly an automorphism of the structure that interchanges the elements 1 
and 2. We conclude, from the preliminaries, that there are four subsets of 
7lf37l definable in N1 : 0ԩ 7lf37l, {0}, and { 1 ,  2}. 
In the structure Nz, the sets { 0}, { 3}, { 2, 4}, and { 1, 5} are defined respec­
tively by 
Ho : gvovo H vo; 
H3 : ggvovogvovo H gvovo 1\ -.Ho; 
H24 : :3vtgvt vt H vo 1\ -.Ho; 
H1s : ·-,Ho 1\ -.H3 1\ -.H24· 
Moreover, the map x r-7 
-x is an automorphism of Nz that interchanges 
2 and 4, on the one hand, and I and 5 on the other hand. So the circumstances 
described in the preliminaries are fulfi.lled and we may conclude that the 
subsets of 7lj67l that are definable in Nz are the 16 elements of the algebra 

314 
S O L U T I O N S  
generated by {0}, {3}, {2, 4}, and { 1 ,  5}, namely: 
0, {0}, {3}, {2, 4}, { 1 ,  5}, {0, 3}, {0, 2, 4}, {0, 1 ,  5}, {2, 3, 4}, { I ,  3, 5}, 
{ 1 ,  2, 4, 5}, {0, 2, 3, 4}, {0, 1 ,  3, 5}, {0, 1 ,  2, 4, 5}, {1, 2, 3, 4, 5}, 'll6'1l. 
Finally, we consider the structure N3. The sets {0}, { 1 }, { -1 }, and IR+ are 
defined, respectively, by the formulas: 
Fo : 
V'v1 gv1 vo Ö vo; 
F1 : 
V' v 1 g v 1 vo H v 1 ; 
F - 1 : V' v 1 g vI g vo vo Ö VI 1\ --., FI ; 
FJR+ : 3vl gv1 v1 Ö vo. 
All Boolean combinations of these four sets are also definable 
(Theorem 3.94 ), in particular, IR$ - { I }  and IRԣ - { - 1}. 
If a is a non-zero real number, the map 1/r[a] from JR. into IR which, with 
each real xT associates 
0 
if X =  0; 
xa 
if x > 0; 
-(-X )a if X < 0; 
is a bijection which commutes with the map (x, y) ʛ x y (for all reals x 
and y, ljr[a](x, y) = ljr[a](x) ljr[a](y)); so this is an automorphism of the 
structure N3. Let a and b be two elements of IR$ - { 1 } ; In b I In a is then 
a non-zero real number and the automorphism 1/r [In b I In a l sends a to b. 
We obtain the same conclusion when we replace IR$ - {1 } by IRÿ - { -1}, 
assume that a and b belong to IRř - { -1}, and consider the automorphism 
1/rfln(-b)/ ln(-a)]. 
In this way, we see that the five sets {0}, { 1 }, {-1}, %$ - { 1 }, and 
IRř - { - 1 }, which are definable in N3 and which constitute a partition 
of IR, satisfy the conditions described in the preliminaries. It follows that 
the Boolean algebra of subsets of IR that are definable in N3 is the subal­
gebra of !9 (IR) generated by {0}, { 1 }, { - 1  }, IR$ - { I }, and Ԥԥ - { - 1  }. It 
contains 32 elements. 
(c) Question ( 1 )  was answered just after Theorem 3. 95 where we saw that the 
only subsets of IR definable in (JR, <} are 0 and JR. We will again invoke the 
preliminaries to answer question (2). Consider the following three subsets 
of IR2: 
A 1 = { (x, y) E IR2 : x = y}, which is defined by the formula 

S O L U T I O N S  F O R  C H A P T E R  3 
A2 == { (x, y) E IR2 : x < y} , which is defined by the formula 
Rvov1 1\ --,vo  v 1 ;  
A3 == { (x, y) E IR2 : x > y} , which is defined by the formula 
Rv1 vo 1\ -,vo H v 1 .  
315 
Let a == (a, b) and f3 == (c, d) be two elements ofiR2. If they both belong to 
A 1 , then a == band c == d and the map x M x -rc-a is an automorphism of 
the structure (IR, <) that sends a to f3. If a and f3 belong to A2 (respectively, 
to A3), then a < b and c < d (respectively, a > b and c > d); the real : ŷ 
is strictly positive and the map 
d - c 
be - ad 
x म 
x +
--
b - a  
b - a  
is an automorphism of (IR, <) that sends a to f3. So the conditions described 
in the preliminaries are satisfied and we see that there are eight subsets of 
IR2 that are definable: 0, IR2, A 1 ,  A2, A3 and the following three sets: 
A 2 U A3 == { (x, y) E IR2 : x # y}; 
A1 U A3 == {(x, y) E IR2 : x  > y}; 
A t  U A2 == {(x, y) E JR2 : x  < y}. 
17. (a) Wetake Z/(n+ 1)Z == {0, 1, . . .  , n}asthebasesetand forthe interpretation 
of R, we take the binary relation R defined by 
for all elements a and b in Z/(n + 1 )Z, 
(a, b) E R if and only if b == a  + 1 ;  
in other words, R is addition in 'l/(n + 1 )Z. The (n + 1 )-tuple (0, 1 ,  . . .  , n) 
is an (n + I)-cycle for R hence the structure we have just defined does not 
satisfy Řz+ 1 ·  Moreover, it is easy to verify that if 2 < k < n, then there 
are no k-cycles in this structure; this shows that it satisfies the formulas 
F2, F3, . . .  , Fn. 
(b) If T I-* G, then, by the compactness theorem, there is a finite subset T' 
of T such that T' 1-* G. We can find an integer p > 2 such that T' c 
{F2, F3, . . .  , Fp}; naturally, this implies that {F2, F3, . . .  , Fp} 1-* G, which 
means precisely that G is satisfied in any L-structure that does not have any 
cycles of length less than or equal to p. 
(c) Let G be a closed formula that is a consequence ofT and let p bean integer 
greater than or equal to 2 such that G is satisfied in any L-structure that 
does not have any cycles of length less than or equal to p (see question (b)). 
Consider a model of the formula 

316 
S O L U T I O N S  
(part (a) guarantees that such a model exists); G is satisfied in this model 
which contains at least one cycle of length p + 1 .  
(d) We argue by contradiction. Let To be a finite theory that is equivalent to 
T and let H be the conjunction of the formulas of To. The theory T is 
then equivalent to {H}. In particular, the formula H is a consequence of T; 
hence (question (c)), it has at least one model that contains a cycle; but such 
a model is not a model of T (whose models must not contain any cycles). 
This contradicts the equivalence of T and { H}. 
18. We will suppose the existence of a theory T of L that has the indicated property 
and arrive at a contradiction. Consider the theory (in the language L') 
T' == T U {Fn : n E N}. 
So a model of T' must be an L'-structure in which the interpretation of R 
is a well-ordering and in which the set of interpretations of the en constitutes 
an 'infinite descending chain', i.e. a non-empty subset of the base set that does 
not have a least element modulo R. This situation is obviously contradictory 
and we conclude that T' is contradictory. From the compactness theorem for 
predicate calculus, we can find a finite subset T" of T' that is contradictory. 
So there is a natural number N such that T" c T U { Fn : n < N}. The 
theory T U { Ř1 : n < N} is then itself contradictory. However, consider the Lo­
structure Mo == (N, <) (in which R is interpreted by the usual order relation on 
N). According to our hypothesis, Mo can be enlarged to an L-structure M that 
is a model of T. M can be further enlarged to an L' -structure M' by interpreting 
each symbol en by the integer N + I 
- n if n < N + I and by 0 if n > N + I . 
It is clear that M' is a model of the formulas Fo, Ft , . . .  , F N and also a model 
of T. Thus we have a model of the theory TN, which is absurd. 
So the property 'is a well-ordering' is not finitely axiomatizable. 
19. Suppose that F[ct, c2, . .
. , ck] is a consequence ofT. Let M == (M, .
. . ) be an 
L-structure that is a model of T. For all elements a 1 ,  a2, . . .  , ak of M, we can 
enrich M to an L' -structure M' by interpreting each of the constant symbols c; 
(for 1 < i < k) by the element a;; M' is also a model of T (Lemma 3.58) and 
hence, by our hypothesis, a model of F[ct, c2, . . .  , ck]. It follows (by applying 
Proposition 3.45 k times) that 
but this is clearly equivalent to 
which allows us to conclude that the formula YxtVx2 . . .  VxkF[xt , x2, . . .  , Xk] 
is satisfied in M. This formula, which is true in every L-structure that is a model 
of T, is therefore a consequence of the theory T. 

S O L U T I O N S  F O R  C H A P T E R  3 
317 
20. (a) According to Theorem 3.91, the stated hypothesis means that the theory 
T U Ƀ (M) (in the language L M) does not have a model. By the compactness 
theorem, we conclude that some finite subset E of this theory does not have 
a model. Let K denote the conjunction of the formulas from Ƀ(M) that 
belong to E (there are only finitely many). The theory T U { K} is then 
contradictory. Note that any conjunction of formulas from Ƀ (M) is again 
a closed, quantifier-free formula of LM that is satisfied in M* (the natural 
extension of M to the language L M  ). Thus K E Ƀ(M). So there exists 
a quantifier-free formula H = H[x1, x2, . . .  , Xn] of the language L and 
parameters a1 , a2, . . .  , an in M such that K = H[at , a2, . . .  , an] (we have 
omitted the underlining and avoided the distinction between the parameters 
and the corresponding constant symbols of the language L M  ). To say that 
T U { K} is a contradictory theory in the language L M is equivalent to saying 
that the formula -,K is a consequence of the theory T: 
Using the result from Exercise 19, we conclude that the formula 
is a consequence of the theory T. Since we also have that 
(because K E Ƀ (M) ), the formula 
is not satisfied in M. So the formula G = -,H answers the question. 
(b) Suppose there exists an extension N of M that is a model of T. Then N also 
satisfies all the closed formulas that are consequences of T, in particular, 
those that are universal; soN is a model of U (T). But any universal closed 
formula that is satisfied in N must also be satisfied in the substructure M 
of N (Theorem 3.70); it follows that M is a model of U (T). 
Conversely, suppose that M is a model of U (T). Then there cannot exist 
a quantifier-free formula G[x1, x2, . . .  , Xn] of L such that 
T I-* \lx1\lx2 . _
.
 VxnG[xl, x2, . . .  , Xn] and 
M ਻ Vx1 \lx2 . . .  V'xnGfxl , X2, . . .  , Xn]. 
So we cannot be in the situation described in the previous question. The 
conclusion is that there exists at least one extension of M that is a model 
of T. 
(c) If M has an extension that is a model of T, then every substructure of M 
has this same property since an extension of M is also an extension of any 

3 1 8  
S O L U T I O N S  
substructure of M. In particular, every substructure of M of finite type has 
an extension that is a model of T. 
To prove the converse, we will use the equivalence established in (b): it 
suffices to prove that M is a model of U (T), knowing that all its substructures 
of finite type are. But this result follows immediately from part (d) of 
Exercise 12: every formula of U (T) is universal; if it is true in every sub­
structure of M of finite type, then it is true in M; hence M is a model 
of U(T). 
21. (a) We argue by contradiction. Suppose that all the elements of A have the 
same type; suppose also that B is a subset of M that is definable in M 
by a formula F[v] of L and is such that B n A =f. 0 and A cJ. B. If we 
choose elements a and b in A such that a E B and b ¢ B, then we have that 
M ծ F[a] and M Jr F[b]; It follows that F E e(a) and F ¢ e (b), hence 
e(a) =f. ()(b); this contradicts that fact that a and b have the same type. 
(b) Again, we argue by contradiction. If e(a) =f. e(h(a)), then there exists a 
formula f[vd E Ft such that M F= F[a] and M ;t F[h(a)]; but this 
situation contradicts Theorem 3.72. 
(c) In M 1, all elements have the same type: if a and b are elements of Z, the 
map x L x + b - a  is an automorphism of M 1 that sends a to b; so a and b 
have the same type according to the preceding question (we find ourselves 
in the situation that was already studied in Section 3.6.1 and again in part 
(c) of Exercise 16). 
In M2, 0, and l do not have the same type: indeed, the formula 3w fw  
w is satisfied by I but not by 0. 
In M3, all elements have the same type: if a and b are elements of Z, the 
map x r--? x + b - a is an automorphism of M3 that sends a to b; so a and 
b have the same type according to question (b). 
In M4, 0, and 1 do not have the same type: indeed, the formula gvv  v 
is satisfied by 0 but not by 1 .  
(d) Let M = (M, . . .  ) be a model ofT .  We define a map cp from M into {0, l}n 
in the following way: for every element a E M and for al1 i between 1 and 
n ,  we set 
and define 
8i 
= {1 if Fi E ()(a); 
0 if Fi ¢ 8(a); 
cp (a) = ( c 1 , c2 , . . . , c n ) . 
Let a and b be two elements of M such that cp(a) = cp(b); this means that 
for all i between 1 and n, F; E ()(a) if and only if Fi E ()(b), or equivalently 
that the formula 1\t<k<n(Fi [vo] {} Fi[vd) is satisfied in M by the pair 
(a, b). 

S O L U T I O N S  F O R  C H A P T E R  3 
319 
Given that M is a model of T and that we have assumed that the formula 
G is a consequence of T, it follows that we must have a == b, which proves 
that the map q; is injective. So the cardinality of M is at most that of {0, l}n 
which is 2n. 
(e) As indicated, let us add two new constant symbols c and d to the langu­
age L and let us consider the following theory S1 of the enriched 
language Lt : 
SI == S U {Ffc] ¢> F[d] : F E  Ft (L)} U {-,c  d}. 
It is clear that in every model of S I , the interpretations of c and d are two 
distinct elements that have the same type in the reduct of this model to the 
language L. So to answer the proposed question, it suffices to show that 
S1 is a consistent theory in L 1 · Suppose it is not. Then by the compactness 
theorem, there would be a finite subset of S 1 that is contradictory; so there 
would exist a finite number of formulas F1 , F2, . . .  , Fn of L with one free 
variable such that the theory 
is contradictory. It amounts to the same thing to say that the formula 
f\ ( Fi [ c] ¢> Fi [ d]) A c  d 
I <i<n 
is a consequence of S. We may then apply the result from Exercise 19 and, 
relative only to the language L, conclude that 
S f-* VvoVv1 ( 6
n 
(F; [vo] {} F;[vJ]) =? vo H VJ). 
According to question (d), this requires that any model of S can have at 
most 2n elements. But we assumed that S had at least one infinite model; 
so we have arrived at a contradiction. 
We could give a shorter proof of the property that we just obtained by 
invoking a theorem that will be proved in Chapter 8 of Part 2, the ascend­
ing Lowenheim-Skolem theorem, which asserts that when a theory has a 
countably infinite model, then it has models of every infinite cardinality. 
So let M = (M, . . .  ) be a model of S and suppose that there is no pair of 
elements of M that have the same type; this means that the map a r-+ e (a) 
from M into the set of subsets of F1 is injective (indeed, if it were not. we 
could find two distinct elements a and b in M for which fJ(a) = ()(b), i.e. 
distinct elements having the same type). As a consequence, the cardinality 
of the model M is bounded by the cardinality of the set fiJ (FI ). So it would 
suffice to take a model of S of cardinality strictly greater than that of fiJ (Ft ) 
(such a model would exist by the Lowenheim-Skolem theorem cited above, 

320 
S O L U T I O N S  
since we have assumed that S has at least one infinite model) to guarantee 
the existence of at least one pair of distinct elements having the same type. 
(f) According to what we have just proved, a theory T can satisfy the required 
conditions only if it does not have any infinite model. We could consider, 
for example, in the language L that has only two distinct constant symbols 
c and d, the theory T consisting of the single formula 
V'vo(vo Ö c v vo Ö d) 1\ -.c ""' d. 
It is obvious that every model ofT has exactly two elements, c and d, and 
that these two elements do not have the same type since the formula vo Ɩ c 
belongs to e (c) but does not belong to e (d). 
(g) The language L consists of a constant symbol c and a unary function symbol 
f. Consider the L-structureN whose base set is N, in which c is interpreted 
by 0 and f by the successor function. This structure is infinite and contains 
no pair of distinct elements having the same type: indeed, if n and p are 
integers such that 0 < n < p' the formula vo " fpc belongs to e (p) but 
does not belong to e (n); so n and p do not have the same type. 
Solutions to the exercises for Chapter 4 
1. There are cases in which F => V' v F is not universally valid. For example, 
in a language that contains a unary predicate symbol P, take F = P v. The 
universal closure of Pv :::} V'vPv is equal to V'v(Pv :::} V'vPv) which is 
itself equivalent to 3vPv =} V'vPv. This last formula is false in a structure in 
which the interpretation of P is neither the empty set nor the entire underlying 
set. 
2. (a) In a language that contains a unary predicate symbol P, take the formula 
F = Pw. Then V'vF =} V'w Fwfv is equal to V'vPw =} V'wPw which 
is logically equivalent to Pw :::} V'wPw. We saw in Exercise 1 that this 
formula is not universally valid. 
(b) This time, the language has a binary predicate symbol R and F = 3w Rvw. 
Then V'vF =} V'wFw/v is equal to 
V'v3wRvw =} V'w3wRww, 
which is logically equivalent to V'v3wRvw => 3wRww. This formula is 
false, for example, in the structure whose base set is N and in which R is 
interpreted by the strict order relation. 
3. We begin by writing a derivation of 3vo F  in T, followed by a derivation of of 
V'vo(F :::} G), always in T (these two proofs exist by hypothesis). We complete 
this with the sequence of formulas in Table S4.1, which constitute a derivation 
of 3voG from 3vo F  and V'vo(F =} G). 

S O L U T I O N S  F O R  C H A P T E R  4 
321 
Table S4.1 
(I) Vvo(F => G) => (F => G) 
(2) 
(F => G) 
Example 4.8 
by modus ponens, since 
Vvo(F => G) appears earlier 
(3) 
Vv0-.G => -.G 
Example 4.8 
(4) 
(F => G) =>  ((Vvo-.G => -.G) => (Vvo-.G => -.F)) 
tautology 
(5) 
(Vvo-.G => -.G) => (Vvo-.G => -.F) 
from (2) and (4) by modus ponens 
(6) 
Vvo-.G => -.F 
from (3) and (5) by modus ponens 
(7) Vvo(Vvo-.G => -.F) 
(8) 
Vvo(Vvo-.G => ¤F) => (Vvo¤G => Vvo-.F) 
(9) 
Vvo-.G => Vvo-.F 
( 1 0) 
3voF ¢? -.Vvo-.F 
( 1 1) 
(3voF ¢? -.Vvo-.F) => (3voF => -.Vvo-.F) 
(12) 
3voF => -.Vvo¥F 
( 1 3) 
-.Vvo-.F 
from (6) by generalization 
axiom schema (b) 
from (7) and (8) by modus ponens 
axiom schema (a) 
tautology 
from ( 10) and ( I I) by modus ponens 
from ( 1 2) by modus ponens, since 
3voF appears earlier 
(14) 
(Vvo¥G => Vvo¥F) => (-.Vvo-.F => -.Vvo-.G) 
(15) 
¦Vvo¦F => ¦Vvo¦G 
tautology 
from ( 1 4) and (9) by modus ponens 
from (15) and (13) by modus ponens 
axiom schema (a) 
( 1 6) 
-.Vvo-.G 
( 1 7) 
3voG ¢? -.Vvo¥G 
( 1 8) 
(3voG ¢? -.Vvo-.G) => (-.Vvo-.G => 3voG) 
( 1 9) 
-.Vvo-.G => 3voG 
(20) 
3voG 
tautology 
from ( 17) and ( 1 8) by modus ponens 
from ( 16) and ( 1 9) by modus ponens 
4. Here is a proof of F v VvG from Vv(F v G): 
(1) Vv(F v G) ::} (F v G) 
(2) Vv(F v G) 
(3) (F v G) 
(4) (F v G) ::} (--.F ::} G) 
(5) -,p ::} G 
(6) Vv(--.F ::} G) 
(7) Vv( --.F :=:} G) ==} ( ..,p ==> VvG) 
(8) ( ..,p ::} VvG) 
(9) (-.F ::} VvG) ::} (F v VvG) 
(10) (F v VvG) 
5. (a) We define cp(F) by induction on F: 
axiom schema (c) 
formula of the theory 
from ( 1 )  and (2) by modus ponens 
tautology 
from (3) and ( 4) by modus ponens 
by generalization 
axiom schema (b) (v is not free in F) 
from (6) and (7) by modus ponens 
tautology 
from (8) and (9) by modus ponens 
o if F is an atomic formula, then cp(F) = 1 (in fact, here, we could just as 
well have chosen cp(F) = 0) 
o if not, we use conditions (1), (2), (3), and (4) as the definition, after noting 
that they are compatible with one another. 
(b) The verification is immediate: if F is a tautology, then cp(F) = 1 thanks to 
conditions (3) and (4); if F is of the form 3vG $ -.vv-.G, then cp(3vG) = 1 

322 
S O L U T I O N S  
by condition (2), cp( -.vv--,G) = l by condition ( 1 )  and hence cp(3vG {:} 
__,yv--,G) = 1 by condition (4). For the formulas of schema (b) or (c), the 
same type of argument applies. 
(c) According to condition ( 4) when the connective a is ==>, if cp( F ==> G) = l 
and cp(F) = 1, we must have cp(G) = 1. 
(d) Let (F1 , F2, . . .  , Fn) be a derivation of F(F = Fn) that does not invoke 
the rule of generalization. This means that for all i between 1 and n, one of 
the following two situations must hold: 
• F; is an axiom, 
• F; follows by modus ponens from two formulas that precede it, i.e. there 
exist j and k less than i such that Fj = Fk ==> F;. 
We can show immediately by induction on the integer i ,  using the results 
from parts (b) and (c), that cp(F;) = 1. Hence cp(F) = 1. 
Now consider the formula F = Vv( G ͐ G) where G is an arbitrary 
formula. This formula is clearly provable (it is obtained by generalization 
from the tautology G ==> G). However, cp(F) = 0 and hence it cannot be 
derived without the rule of generalization. 
6. (a) We adapt the definition from the previous exercise in an obvious way. 
(b) One must first verify that cp assumes the value 1 for the tautologies and for 
the formulas of axiom schemas (a) and (b); this follows from the conditions 
imposed on cp. Finally, if F is obtained by generalization, then F begins 
with a universal quantifier so cp(F) = l. 
This allows us to show, as before, that if F has a proof that does not make 
use of axiom schema (c), then cp( F) = 1. 
(c) Let F be a formula of axiom schema (c) such that cp( F) = 0, for example, 
F = Vvo3vt G ==> 3v 1 G, where G is an arbitrary formula. This formula 
is provable but, since cp (F) is not equal to 1, it cannot be proved without 
appealing to schema (c). 
7. Let (F1 , F2, . . .  , Fn) be a derivation of F (F = Fn) that does not appeal to 
axiom schema (a). We will show that (Ft, F{, . . .  , F;) is a derivation of F*. 
• If F; is a tautology, then so is F;*. To see this, note that there exists a proposi­
tional tautology P [A 1 , A 2, . . .  , Ak] depending on the propositional variables 
A 1 ,  A2, . . .  , Ak and formulas G 1 ,  G2, . . .  , Gk such that 
So F;* = P[GT, G2, . . .  , G/:] which shows that F;* is a tautology. 
• If F; belongs to axiom schema (b), say F; = Vv(H => G) ==> (H ==> VvG) 
where v is a variable that has no free occurrence in H, then 
F;* = Vv(H* ==> G*) :=> (H* ==> VvG*) 
so F;* is also an axiom. 

S O L U T I O N S  F O R  C H A P T E R  4 
323 
• The argument is similar if F; belongs to axiom schema (c). 
• If F; is obtained by modus ponens from F j and Fk with j and k less than i, 
then Fj = Fk  F; Ȑ hence Fj = F! ==> Ft is obtained by modus ponens 
from Fj and Fk*. 
ta If F; is obtained by generalization from Fj U < i ), then Fz* is obtained by 
generalization from Fj. 
This shows that ifF can be proved without an appeal to axiom schema (a), then 
1- F*. For example, if P is a unary predicate symbol, F = 3v Pv {:? -,Vv-.Pv 
is certainly provable (it is an axiom) but it is not provable without schema 
(a): otherwise, F* = VvPv य -,\lv-,Pv would also be provable, which is 
not the case since F* is not universally valid (it is universally equivalent to 
VvPv <:> 3vPv). 
8. We are asked to prove, using Herbrand's method, that if T does not have a 
model, then T is not consistent. As in the section on Her brand's method, we 
assume that each formula Fn can be written in the form 
where k is an integer and Bn is a formula without quantifiers. 
Let T denote the set of terms of the language and 8; denote the set of 
sequences of length i of elements of T. We then introduce, for all n and i, 
a map a;,n from 8 i into N in such a way that the following properties are 
satisfied: 
( I )  if Vm occurs in one of the terms lt, 12, . . .  , 1; , then a;,n(1I , 12, . . . , 1;) > m; 
(2) i f  j < i and (11 , 12, . . . , 1;) is a sequence that extends (1t , 12, . .
. , 1j), then 
a;,n (11 ,  12 , . . .  , 1j) < a;,n (1I , 12, . . .  , 1; ); 
(3) if r and o· are two distinct sequences whose respective lengths are i and j 
and if n and m are arbitrary integers, then a;,n(r) =I= a j.m(a). 
The codings from Chapter 6 show how such functions can be constructed 
without difficulty. 
By definition, an avatar of F n will be a formula of the form 
Denote the set of all avatars of Fn by An . To prove the two lemmas that follow, 
it more or less suffices to recopy the proofs of Theorems 4.38 and 4.39. 
Lemma I: If UnEN An is propositionally satisfiable, then { Fn : n E N} has a 
model. 
Lemma 2: If I is a finite subset of N and if UnE/ An is not propositionally 
satisfiable, then -, 1\nEI Fn is provable. 
These two lemmas permit us to prove the desired theorem. 

324 
S O L U T I O N S  
9. Here are some possible refutations. 
(a) 
(b) 
(c) 
(d) 
(A 1\ B) =} 
B =}  
D 
(A 1\ B) ͟ 
(A 1\ A) =} 
A =?  
0 
(B 1\ C) =} 
B z 
=} (B v B) 
=} B  
D 
from (A 1\ B) :=} C and C => by cut on C 
from (A 1\ B) =} and =} A by cut on A 
from B =} and B =} by cut on B 
from (A 1\ B) => C and C Å by cut on C 
from (A 1\ B) =::;> and A =} B by cut on B 
from (A 1\ A) by simplification 
from A =} and :::} A by cut on A 
from (A 1\ B) =} and C =} A by cut on A 
from (B 1\ C) =} and Å C by cut on C 
from D z B and z (D v B) by cut on D 
from =} (B v B) by simplification 
from B :::} and =} B by cut on B 
(A 1\ A 1\ B) =::;> C from (A 1\ B) =::;> (C v D) and (A 1\ D) =? 
(A 1\ B) =} C 
B  (C v C) 
B =} C  
=} (C v C) 
=} C  
Å F  
(E v F) z 
F ==}  
D 
by cut on D 
from (A 1\ A 1\ B)  C by simplification 
from (A 1\ B) z C and =} (A v C) by cut on A 
from B :::} (C v C) by simplification 
from B =} C and =} (B v C) by cut on B 
from ( C v C) by simplifi.cation 
from =? C and C  E by cut on C 
from =? C and C =} F by cut on C 
from =} C and (C 1\ E 1\ F)  by cut on C 
from =} E and (E 1\ F) =} by cut on E 
from F :::} and =} F by cut on F 
10. Let A denote the set of propositional variables. We define a map from the set 
of reduced clauses into the set of maps from A into {0, 1 ,  2 }: to each clause C 
corresponds the map ac from A into {0, I ,  2} defined by 
ac (A) = 0 if and only if A appears in the premiss of C î 
ac(A) = 1 if and only if A appears in the conclusion of C; 
ac(A) = 2 if and only if A does not appear in C. 
This map has an inverse: it is the map which, with a given map a from A 
into {0, 1 , 2}, associates the clause whose premiss is the conjunction of the 
propositional variables A for which a(A) = 0, taken in the order of increasing 
index, and whose conclusion is the dis junction of the propositional variables A 

S O L U T I O N S  F O R  C H A P T E R  4 
325 
forwhicha(A) = 1, also taken in theorderofincreasingindex. Therefore, there 
are as many reduced clauses as there are maps from A into {0, 1 ,  2} 
ȏ namely 3n . 
11. Suppose that there are, in all, n propositional variables appearing in S. Let P be 
a clause in S. We may begin by supposing that any given propositional variable 
occurs at most once in P: for if some variable occurs in both the premiss and the 
conclusion of P, then P is a tautology and we can ignore it; if not, we can reduce 
to this case by simplification. Let M be the number of variables appearing in P; 
m is greater than or equal to 3 by hypothesis. For P to be false, all the variables 
in its premiss must be true and all the variables in its conclusion must be false. 
Among the 2n assignments of truth values to P, there are at most 2n-m (i.e. at 
most one-eighth of them, since 2n-m < 2n · !) that could make P false. 
If we perform this calculation for each of the seven clauses in S, we see that 
there are at most seven-eighths of the assignments of truth values that could 
make one of the clauses in S false. So there are some left over that must satisfy 
all the clauses in S. 
12. (a) Here is the desired refutation: 
Cs = =>  B 
c6 = c ==> 
C7 = (A !\ B) => 
Cs = A =>  
D 
from C3 and C4 by cut on A 
from Cz and Cs by cut on B 
from c. and c6 by cut on c 
from Cs and C7 by cut on B 
from C4 and Cs by cut on A 
(b) From C1 and C3, we derive (A !\ A) => C by cut on B, then A ͏ C = I> 
by simplification. The set {Cz, C4, V} is satisfied by the assignment of truth 
values 8 defined by 8(A) = 8 (C) = 1 and 8(B) = 0; therefore it is not 
refutable. 
Our conclusion is that in a derivation of the empty clause from a finite set 
of clauses r, it is not legitimate to replace two arbitrarily chosen clauses 
by a clause that can be obtained from them by cut. What is possible (and 
which is what we did to prove Theorem 4.50), is to perform this operation 
systematically for all pairs of clauses that permit the elimination of some 
given variable (and only these pairs). 
13. We will be content to provide the details for (a), (c), and (d) and to simply state 
the answer for the others. 
(a) l .B. Simplification. The system (a) is equivalent to 
(vo, g gvsVJ hv4), (g hb gvzv3 g hb vo). 
I .  C. Reduction. First set r1 (vo) = g gvs VJ hv4 then unify: 
(g hb gvzv3, g hb ggvsv1hv4). 
2. A and B. Simplification and clean-up; we obtain in succession 
(hb, hb), (gvzv3, g gvsVJ hv4); 
(vz, gvsvt), (v3, hv4). 

326 
S O L U T I O N S  
2.C. Reduction. We can perform two reductions simultaneously by 
setting r2(v2) = gvsv1 and r2(v3) = hv4. We then obtain the empty 
system. 
The substitution r = r2 o ri is a principal unifier. We may calculate 
r (vo) = g gvsv1 hv4, r (v2) = gvsvi , r (v3) = hv4. 
(b) There is no unifier. 
(c) LB. Simplification. We obtain: 
( V4, f j V3 V9 j V 1 1  VI I ) , 
(g gjgVJ V6jV5VI28fVIOQV2 jV7Vg, g gV2gfVJoafV6VO V4). 
l .C. Reduction. Set r1 (v4) = f jv3v9 fVII VII and the reduced system is 
(g gjgVI V6fVsV128fVIOQV2 jV?V8, g gv2gfVJOllfV6VO jjV3V9jV1 1  VI I ). 
2.B. Simplification. 
(g jgv1 V6fV5VI28fVIOQV2, g V2 gfvtoafV6VO), (.fV7V8, j jV3V9 jv11 Vu). 
Then 
(f gVI V6 jV5Vl2, V2), (g jVIOQ V2, g fVlOQ jV6VO), 
(V7, jV3V9), ( Vg, fVI I Vl l ) · 
2.C. Reduction. Set r2(v2) = f gviV6 fvsVJ2, r2(v7) == jv31J9, r2(vg) = 
fvi l VII · We then obtain 
(g jV(OQ jgVI V6fV5Vl2, g jV]OQ jV6Vo). 
3. A and B. Simplification and clean-up. We obtain in succession 
(jv10a, fvJoa), (f gv1 V6 jvsv12, fv6vo); 
(gVI V6, V6), (jV5Vl2, VO). 
It is impossible to unify (gv1 V6, V6) so system (c) does not have a unifier. 
(d) 1 .  B. Simplification. 
(v2, g gv9v3 gv9vw), (f jjgv4V1 jv3vsjgv7bvo gv6V8, 
f fvofgv?bfvi i  v12 V2). 
1. C. Reduction. We set TI (v2) = g gv9v3 gv9v1o and we obtain 
(f ffgv4VJ .fv3vsjgv7bvo gv6V8, f fvofgv?bfvu VI2 ggvgv3gvgv1o). 
2. B. Simplification. 
(f jgV4V1fV3V5 jgv7bVO, j VO jgV?bfVll VI2), (gV6V8, g gv9V3 8V9VIO); 
(.f gv4V] jV3V5, VO), (f gV?b VO, j gv7b jVJ I VJ2), (V6, gV9V3), 
( vg, gv9 VJ o). 
2. C. Reduction. Weset r2 (vo) = f gv4v1 jv3v5, r2(v6) == gv9V3, r2(vg) == 
gV9VIO and we obtain 
(j gv7b jgv4 VIfV3V5, f gv7b fVII VJ2). 
3. A and B. Simplification. We obtain in succession 
(gv7b, gV?b), (.f gv4V1 jv3V5, fVII VI2); 
(gV4VI. Vll), (.fV3V5, VI2). 
3. C. Reduction. We set T3(V I I )  = gv4v1 and r3(v12) = jv3v5. The system 
we then obtain is empty and r == r3 o !'2 o r1 is a principal unifier of 

.. 
S O L U T I O N S  F O R  C H A P T E R  4 
system (d). We may calculate 
r(vo) = f gv4v1 jv3v5, r(v2) = g gv9v3 gv9v1o, r(v6) = gv9v3, 
r(vs) = gv9V!O, r (v1 1 ) = gv4v1 and r(v12) = jv3v5. 
327 
(e) There is no unifier (we notice this from the occurrence test after having 
completely decomposed the terms). 
14. Consider the inverse a-1 of a (it is a permutation of V) and let o-' denote the 
substitution that extends it. It is immediate to verify that o· o a' and a ' o a are 
substitutions that equal the identity on V, and hence are equal to the identity: 
therefore a has an inverse so it bijective. 
For the converse, we begin by observing that if a is a substitution and t is 
a term, then the length of t, lg[t], is less than or equal to that of a (t) (easily 
proved by induction on t ). Suppose that r and r' are two substitutions such that 
both r o r' and r' o r  are equa] to the identity. Then. for every variable v. 
lg[r(v)] < lg[r'(r(v))] = 1 ; 
since r'(r(v)) = v, r(v) cannot be a constant symbol, so it must be a variable. 
So the restriction of r to V is a map from V into V and we see, without difficulty਺ 
that the restriction of r' to V is the inverse map. 
15. (a) By induction on t. If t is a variable or a constant symbol, there is nothing 
to prove. If t is of the form ft1 t2 . . .  tn where n is an integer and f is an 
n-ary function symbol, then the equality t == a (t) = fa (tr )a (t2) . . .  a Ctn) 
implies tr = a (t1 ), t2 = a (t2), . . .  , ln = a (tn) by the unique readability 
theorem. We then invoke the induction hypothesis. 
(b) This follows immediately from (a). 
(c) Let v E A; then v has an occurrence in a term of the form rr(t). But 
rr == a o ar o rr and so, according to (b), a o ar ( v) = v. This shows thac 
a1 ( v) cannot be a constant symbol nor a term whose length is greater than 
1 (see Exercise 14 ). Hence it is a variable and the restriction of a1 to A. 
is a surjective map from A onto B. But since for every variable v E A l 
a o a1 (v) == v, this map is also injective. 
Let A' denote the complement of A in V and B' the complement of B in 
V .  Then A' and B' have the same number of elements and we can find a 
bijection r from B' onto A'. Let r1 denote the inverse bijection. We define 
the substitutions a' and a{ by 
a'(v) == a (v) 
a'(v) = r(v) 
a{(v) == ar (v) 
a{(v) = rr (v) 
if v E B; 
if v E B'; 
if v E A; 
ifv E A'. 
Then properties (i), (ii), and (iii) in the statement of the exercise are 
evident. Let us consider (iv): for example, we need to show that for every 

328 
S O L U T I O N S  
variable v, we have a' o Jrt (v) = a o n1 (v); but this is clear since all the 
variables that occur in rr 1 ( v) (which is equal to o·1 o n ( v)) are in B and a 
and a' agree on B. 
(d) First of all, it is clear that if a is a bijective substitution from T into T, 
then a o r  is also a principal unifier. Conversely, suppose that rr' is another 
principal unifier of S. Then there are substitutions a and a' such that n = 
a o n1 and n1 = a1 o n . But, according to (c) there also exists a bijective 
substitution a { such that n 1 = a { o n. 
16. To apply the rule of resolution, we must. begin by separating the two clauses. 
We obtain 
Before applying the cut rule, we can unify Pv2 and Pvo or else Pv2 and 
P/V]. 
In the first case, the principal unifier is r(vo) = v2 and r (v;) = v; for i =!= 2. 
The result is 
(Sv2 1\ P !vi) ::} (Rv2 v Qvovi)-
In the second case, the principal unifier is r(v2) = fv1 and r(v;) = v; for 
i =f=. 2. The result is 
17. To obtain the Skolem forms of these formulas, we must add two constant sym­
bols, say a and b, to the language. We obtain the following formulas: 
Vv1 (Pa 1\ (Rvt ::} Qavt); 
Vvo'Vvt (-. Pvo v -.sv1 v-.Qvovi); 
Rb i\ Sb. 
When we rewrite these in the form of clauses, we obtain the set: 
( 1 )  => Pa 
(2) 
Rv1 => Qav1 
( 3) 
( p VQ 1\ S VI 1\ Q VQ V I )  ::::} 
(4) 
==? Rb 
(5) => Sb. 
Using the principal unifier r(vo) = a  and r (vi ) = v; for i =!= 0, we can unify 
Pa in ( 1 )  with P vo in (3) and obtain, by the cut rule: 
(6) 
(Sv1 1\ Qav1 ) =}. 
We can then apply the cut rule to (2) and (6) (to be strictly rigorous, we 
would first have to separate these two formulas, for example, replacing (2) by 
Rv2 =} Qav2 , and then return to the two original formulas with the help of a 
unifier!): 
(7) 
(Rv1 1\ Sv1 ) =}. 

S O L U T I O N S  F O R  C H A P T E R  4 
329 
Now we can unify Rb and Rv1 (the principal unifier is r(vt) = b )  and apply 
the cut rule to ( 4) and (7): the result is 
(8) Sb =:> 
which, together with (5), yields the empty clause. 
18. We must refute the set { F1 , F2, F3, -.G}. So we begin by putting F1 and -,G in 
prenex form; this produces, respectively: 
VvoVvt (Rvov1 :::} Rvofvo) and 
VvoVvt Vv2(-.Rvov1 v ...,Rv1 v2 v ...,Rv2vo). 
Then, we must add Skolem functions to the language in order to rewrite these 
formulas as clauses; we need a unary function symbol g and a constant symbol 
a. We obtain 
( 1 )  Rvovi =? Rvofvo 
(2) ==> Rvogvo 
(3) 
:::} Rffaa 
( 4) ( R vo vI 1\ R v 1 V2 1\ R V2 vo) =}. 
We may apply the rule of resolution to ( 1 )  and (2 ). To separate these clauses, 
we replace (2) by ==} Rv3gv3 then we unify Rv3gv3 with Rvovt (the unifier is 
r(vo) = v3, r(vi) = gv3) and we obtain 
(5) 
:::} Rv3jv3. 
We can then unify R v3 f v3 with R vo v 1 which occurs in the premiss of ( 4) 
(the unifier is r (vo) = V3, r (vt) = jv3) and, after resolution, we have 
(6) (Rjv3 v2 1\ Rv2 v3) =}. 
Replace (5) by :::} Rvofvo to separate it from (6), then unify Rvofvo with 
Rv2v3 (the unifier is r(v2) == vo and r(v3) = fvo). The result is 
(7) Rf f vovo :::} 
and after unifying with (3) (r(vo) = a), we obtain the empty clause. 

Bibliography 
·---- ---
-------------
First, we will suggest a list (no doubt very incomplete) of works concerning mathe­
matical logic. These are either general treatises on logic or more specialized books 
related to various topics that we have presented. There is one exception: the book 
edited by J. Barwise, whose ambition was to produce, at the time it was published, 
a survey of the state of the art. Some of these titles are now out of print but we have 
included them none the less because they should be available in many university 
libraries. 
J.P. Azra and B. Jaulin, Recursivite, Gauthiers-Villars, 1973. 
j. Barwise (editor), Handbook of mathematical logic, North-Holland, 1 977. 
J.L. Bell and A.B. Machover, A course in mathematical logic, North-Holland, 1977. 
J.L. Bell and A.B. Slomson, Models and ultra products, North-Holland, 197 1 .  
E. W. Beth, Formal methods, D. Reidel, 1 962. 
C.C. ChangandJ.H. Keisler, Model theory, North-Holland, 1 973. 
A. Church, Introduction to mathematical logic, Princeton University Press, I 996. 
P. Cohen, Set theoty and the continuum hypothesis, W.A. Benjamin, I 966. 
H. Curry, Foundation of mathematical logic, McGraw-Hill, 1963. 
D. van Dalen, Logic and structures, Springer-Verlag, 1 983. 
M. Davis, Computability and unsolvability, McGraw-Hill, 1 958. 
F. Drake, Set theory, North-Holland, 1 979. 
H.D. Ebbinghaus, j. Flum and W. Thomas, Mathematical logic, Springer-Verlag, 1 984. 
R. Fralsse, Cours de logique mathematique, Gauthier-Villars, 1 972. 
J.Y. Girard Proojtheo1y, BibliopolisÅ 1 987. 
P. Halmos, Lectures on Boolean algebras, D. Van Nostrand, 1963. 
P. Halmos, Naive set theory, Springer-Verlag, 1 987. 
D. Hilbert and W. Ackermann, Mathematical logic, Chelsea, 1 950. 
K. Hrbacek and T. Jech, Introduction to set theory, Marcel Dekker, 1 984. 
T. Jech, Set theoty, Academic Press, 1 978. 
S. Kleene, Introduction to metamathematics, Elsevier Science, 1 97 1 .  
G. Kreisel and J.L. Krivine, Elements de logique mathematique, Dunod, 1 966. 
J .L. Krivine, Theorie des ensembles, Cassini, I 998. 
K. Kunen, Set theory, North-Holland, 1 985. 
R. Lalement, Logique, reduction, resolution, Masson, 1 990. 
R.C. Lyndon, Notes on logic, D. Van Nostrand, 1966. 
A.I. Mal'cev, The metamathematics o.falgebraic systems, North-Holland, 1971 
J. Malitz, An introduction to mathematical logic, Springer-Verlag, 1979. 
Y. Manin,A course in mathematical logic (translated from Russian), Springer-Verlag, 1977. 
M. Margenstern, Langage Pascal et logique dupremier ordre, Masson. 1 989 and 1 990. 
E. Mendelson, Introduction to mathematical logic, D. Van Nostrand, I 964. 

B I B L I O G R A P H Y  
331 
P.S. Novikov, Introduction a La 
logique mathematique (translated from Russian), 
Dunod, 1 964. 
P. Odifreddi, Classical recursion theory, North-Holland, 1 989. 
J.F: Pabion, Logique mathematique, Hermann, 1976. 
R. Peter, Recursive functions, Academic Press, 1967. 
B. Poizat, Coursdetheorie des modeles, Nural-Mantiq wa1-Ma'rifah (distributed by Offilib, 
Paris), 1 985. 
D. Ponasse, Logique mathematique, OCDL, 1967. 
W. Quine, Mathematical logic, Harvard University Press, 1 98 1 .  
W. Quine, Methods of logic, Harvard University Press, 1 989. 
H .. Rasiowa and R. Sikorsh:i, The mathematicsofmetamathematics, PWN-Polish Scientific 
Publishers, 1 963. 
A. Robinson, Complete theories, North-Holland, 1 956. 
A. Robinson, Introduction to model theory and to the metamathematics of algebra. 
North-Holland, 1 97 4. 
H .. Rogers, Theory of recursive functions and effective computability, McGraw-Hill, 1 967. 
J.lB. Rosser, Logic for mathematicians, McGraw-Hill, 1 953. 
J.lR. Shoenfield, Mathematical logic, Addison-Wesley, 1 967. 
K .. Shiitte, Ptvof theory, Springer-Verlag, 1 977. 
W. Sierpinski, Cardinal and ordinal numbers, PWN-Polish Scientific Publishers, 1 965. 
R. Sikorski, Boolean algebras, Springer-Verlag, 1 960. 
R. Smullyan, First order logic, Springer-Verlag, 1968. 
R.I. Soare, Recursively enumerable sets and degrees, Springer-Verlag, 1 987. 
J. Stern, Fondements mathematiques de l 'informatique, McGraw-Hill, 1 990. 
P. Suppes, Axiomatic set theory, D. Van Nostrand, 1 960. 
P. Suppes, Introduction to logic, D. Van Nostrand, 1 957. 
A. Tarski, Introduction to logic and to the methodology of deductive sciences, Oxford 
University Press, 1 965. 
A. Tarski, A. Mostowski and R. Robinson, Undecidable theories, North-Holland, 1 953. 
R.L. Vaught, Set theory, Birkhaiiser, 1 985. 
Below, for the benefit of the eclectic reader whose curiosity may have been piqued, we 
supplement this bibliography with references to books which, while related to our subject 
overall, are of historical or recreational interest. 
L. Carroll, The game of logic, Macmillan, 1 887. 
M. Gardner, Paradoxes to puzzle and delight, W .H. Freeman, 1 982. 
K .. Godel, Collected works (published under the supervision of S. Feferman), Oxford 
University Press, 1 986. 
J. van Heijenoort, From Frege toGodel, a source book in mathematical logic ( 1879-1931), 
Harvard University Press, 1967. 
A. Hodges, A lan Turing: the enigma, Simon & Schuster, 1 983. 
R. Smullyan, What is the name of this book?, Prentice Hall, 1 978. 
J. Venn, Symbolic logic, Chelsea, 1 97 1  (first edition: 18 8 1). 

Index 
Absorption laws, 31 
Alphabet, xviii 
And, 8 
Antilogy. 28 
Antireflexive, 61 
Antitautology, 28 
Appears efficiently, 227 
Assignment 
of truth values, 21 
Associativity, 31 
Atom 
in a Boolean algebra. 80 
Atomic 
Boolean algebra, 80 
formula, 122 
Automorphism 
of structures, 13 7 
Avatar, 214 
Axiom of Choice. 162. 165, 172 
axiom schemes, 195 
Axiom(s) 
logical, J 94 
of equality, 179 
of predicate calculus, 195 
of quantification, 195 
tautologies, 1 94 
Axiomatizable, 170 
Base (set), 131 
Basis 
for a filter, 97 
for a topology, 67 
B icontinuous, 68 
Boolean 
algebra, 71 
ring, 7 1  
space, 69 
subalgebra, 87 
Boolean algebra 
atomic, 80 
complete, 107 
dense. 108 
Bound 
variable, 125 
Canonical 
homomorphism, 91 
Cantor set, 285 
Cantor space, 285 
CCNF, 38 
CDNF, 38 
Chain. 65 
Characteristic 
of a field, 303 
Choice function, 162 
Clausal forms, 40 
Clause, 40, 218 
uni versa I, 230 
Clean-up, 227 
Clopen (set), 69 
Closed 
formula, 1 25 
term, 120 
Closure 
of a formula, 126 
CNF, 38 
Cofinite, 87 
Con1mutativity, 31 
Compact (space), 68 
Compactness theorem 
for predicate calculus, 171, 
209 
for propositional calculus, 48 
Compatability test 
first, 227 
second, 228 

Complement 
in a Boolean algebra, 75 
Complemented 
lattice, 76 
Complete 
Boolean algebra, 1 07 
diagram, 1 76 
set of connectives, 41 
theory, 173 
Completeness 
syntactical, 203 
Completeness theorem 
for predicate calculus, 209 
Concatenation, xviii 
Conclusion 
of a clause, 218, 230 
Congruence 
modulo an ideal, 65 
Con junction, 8, 1 23 
Conjunctive 
normal form, 38 
prenex form, 1 60 
Connective 
0-ary, 57 
complete set of, 41 
minimal set of, 41 
n-place, 36 
Sheffer's, 37 
Consequence, 46 
of a theory, 148 
syntactic, 197 
Consistent 
set of formulas, 45 
theory, 148 
Constant, 1 14 
Continuity 
uniform, 22 
Continuous 
map, 68 
Contradiction, 1 48 
Contradictory 
set of formulas, 45 
theory, l99 
contradictory in L, 199 
Contrapositive, 32 
Covering 
of a topological space, 68 
cut rule, 219 
I N D E X 
Cycle, I90 
Cycle-free, 1 90 
de Morgan's laws, 32 
in a Boolean algebra, 76 
Decomposition tree 
of a formula 
of predicate calculus, 1 24 
of propositional calculus, 1 3, 
124 
Deduction ru]es, 1 94 
Deduction theorem, 200 
Defi nability theorem, 44 
Definable 
set, 177 
with parameters, 1 78 
Definition 
by induction, 1 1 
by induction on formulas, 1 8  
from above, 1 1  
from below, 1 I 
inductive, I 1  
modulo A formula, 44 
of a set in a structure, 1 77 
with parameters, 1 78 
Dense 
Boolean algebra, I 08 
subset of a topological space, 1 08 
Derivable 
by cut, 236 
by resolution, 236 
formula, I97 
Derivation, 196 
by cut 220 
Derived 
by cut, 219 
by resolution, 232 
by simplification, 219 
Diagonal, I 32 
Diagram 
of a model, I 76 
Discrete (topology), 70 
Dis junction, 8, 123 
Disjunctive 
normal form, 3 8 
prenex form, 160 
Distribution 
of truth values, 21 
333 

334 
Distributive 
lattice, 76 
Distributivity, 31 
DNF, 38 
Domain, xvii, 131 
Dual 
filter, 93 
ideal, 93 
Elementary 
diagram, 17 6 
equivalence, 170 
Enrichment 
of a model or a structure, 1 35 
Equality, 1 I 4 
axioms of, 179 
Equisatisfiable, I 61 
Equivalence, 8 
elementary, 170 
of formulas, 148 
of theories, 1 48 
Equivalent 
sets of formulas, 46 
Evaluation, 21 
Existential 
formula, 157 
quantifier, 1 14 
Expansion 
of a model or a structure, 1 35 
Extension, I 33 
Extension theorem, 191 
Filter 
dual, 93 
Frechet, 95 
generated by a set, 1 08 
in a Boolean algebra, 93 
maximal, 94 
principal, 95 
Filterbase, 97 
Finite intersection property, 96 
Finite type, 61, 187 
Finitely axiomatizable 
property, 170 
Finitely consistent 
theory, 148 
Finitely satisfiable, 45 
Finiteness theorem, 200 
I N D E X  
First order 
formula, I 23 
language, I I 3 
First -order 
property, 1 7 I 
For all 
. . .  , 1 1 3  
Formal proof, 196 
Formula 
antilogy, 28 
antitautology, 28 
atomic, 1 22 
avatar of, 2 I 3 
canonical conjunctive normal form, 38 
canonical disjunctive normal form, 38 
clausal form, 40 
clause, 40 
closed, 125 
conjunctive normal form, 38 
conjunctive prenex form, 160 
contradictory, 148 
contrapositive of˫ 32 
derivable, 197 
disjunctive normal form, 38 
disjunctive prenex form, 160 
equisatisf1able, 161 
existential, 157 
in prenex form, 157 
in Skolem formˬ 160 
inconsistent, I 48 
increasing, 60 
literal, 40 
logically equivalent, 28 
model of, 143 
neutral) 55 
polite, I 57 
prefix of, I 57 
propositional, 9 
pseudoformula, 53 
satisfiable, 45 
spectrum of, 186 
sub-formula, 19 
tautology, 2 7 
universal, 1 57 
valid, 147 
with parameters, 176 
Frechet (filter), 95 
Free 
variable, I 25 

Freely generated, 225 
Functional, 1 14 
Garbage collection, 227 
Generalization 
Jrule of, 1 94 
Graph, 61 
k-colourable, 61 
Greatest lower bound, 7 3 
Group 
of finite type, 61 
orderable, 61 
torsion-free, 61 
Hausdorff (space), 68 
Height, I I  
of a formula, 124 
of a term, 1 16 
Henkin witness, 203 
Hilbert's programme, 4 
Homeomorphism, 68 
Homomorphism 
canonical, 91 
of Boolean algebras, 81 
of structures, 135, 225 
Ideal, 64 
dual, 93 
in a Boolean algebra, 90 
maximal, 65 
prime, 92 
principal, 90 
proper, 64 
sum of ideals, 64 
Idempotence, 31 
Idempotent, 7 1  
Identity element, 3 2 
Image 
of a subset under a relation, 62 
Implication, 8 
Implies, 8 
Inconsistent 
theory, 148 
Increasing (formula), 60 
Independent 
set of formulas, 60 
Induction 
definition by, 1 1  
Inductive, 51 
I N D E X  
Interpolant, 43 
Interpolation lemma, 42 
Interpretation, 1 3 1  
of a symbol, 1 3 1  
o f  a term i n  a structure. 137 
Involution, 7 5 
Isolated point 
of a topological space, 108 
Isomorphic 
structures, 13 7 
Isomorphism 
of Boolean algebras, 83 
of structures, 1 36 
Kelley, J. L., 70 
Krull's theorem, 65 
L-derivation, 196 
L-syntactic consequence, 197 
Language, I 1 3 
associated with a structure, 174 
model of, 1 3 1  
with equality, 1 14 
Lattice, 76 
complemented, 76 
distributive, 76 
Least upper bound, 73 
Lemma 
interpolation, 42 
Zorn's, 50 
Length 
of a word, xviii 
Literal, 40 
Logical axioms, 194 
Logical equivalence, 28 
Lowenheim-Skolem theorem, 319 
Macdonald, I. D., 61 
Map 
bicontinuous, 68 
continuous, 67 
homeomorphism, 6 7 
Marriage theorem, 2 70 
Maximal 
filter, 94 
ideal, 65 
Metalanguage, 9 
Minimal 
set of connectives, 41 
335 

336 
Model 
diagram of, 1 76 
of a formula, 143 
of a language, 1 3 1  
standard, 1 89 
that respects equality, 132 
Modus ponens, 1 94 
Monomorphism 
of structures, 1 36 
Morgan, see de Morgan's laws 
Negation, 8, I 23 
non-contradictory in L, 1 99 
Non-contradictory 
set of formulas, 45 
theory, 199 
Normal form 
canonical conjunctive, 38 
canonical disjunctive, 38 
conjunctive, 38 
disjunctive, 38 
Normal form theorem, 3 9 
Not, 8 
Occurrence 
of a letter in a word, xviii 
Occurrence test, 228 
Or, 8 
Orbit, 310 
Order 
of a cycle, 190 
Orderable, 6 1  
Parameter(s), 1 76 
definable with, I7 8 
Polish notation, 1 3 1  
Polite (formula), I 57 
Polynomial function, 254 
Positive 
class of formulas, 1 08 
Predicate, I 14 
Prefix 
of a formula, 1 57 
Premiss 
of a clause, 218, 230 
Prime 
ideal, 92 
Principal 
filter, 95 
I N D E X  
ideal, 90 
unifier, 227 
Product topology, 70 
Proof 
by induction on the set of formulas, I I 
formal, 196 
Proper 
final segment, xviii 
ideal, 64 
initial segment, xviii 
Property 
axiomatizable, 170 
finitely axiomatizable, I 70 
first -order, 171 
pseudo-axiomatizable, 1 7 1  
Proposition, 8 
Propositionally satisfiable, 212 
Pseudo-axiomatizable, 1 71 
Pseudoformuia, 53 
Quantification axioms, I 95 
Quantified 
existentially, 125 
universally, 125 
Quantifier 
existential, I 13 
scope of, I26 
universal, 1 13 
Quotient ring, 66 
Reduction 
of a model or a structure, 135 
Refutable, 221 
set of clauses, 235 
Refutation, 221 ,  235 
Restriction 
of a model or a structure, 135 
Rule 
cut, 2I9 
deduction, I 94 
of generalization, I 94 
of simplification, 219 
of weights, I 17 
of resolution, 232 
Satisfaction 
of a formula by an assignment, 25 
of a formula in a structure, 141 
of a formula in a substructure, I 66 

of a set of formulas, 45 
of a theory in a structure, 148 
Satisfiable 
proposi tionall y, 213 
set of formulas, 45 
Scope, 126 
Semantic consequence, 148 
Semantics, 21 
Separated 
clauses, 232 
space, 68 
Se[ 
base, 1 3 1  
basic closed, 67 
basic open, 67 
clopen, 69 
closed, 67 
cofinite, 87 
definable, 177 
dense, 108 
of first order formulas, 123 
open, 67 
underlying, 131 
Sheffer 
strokes, 57 
Sheffer's connectives, 37 
Simple diagram 
of a model, 176 
Sitnplification, 227 
rule of, 219 
Singleton, 79 
Skolem normal form, 1 60  
Space 
Boolean, 69 
Cantor, 285 
compact, 68 
Hausdorff, 68 
separated. 68 
Stone, 98 
zero-dimensional, 69 
Spectrum 
of a formula, I 86 
Splitting, 1 09 
Standard model, 189 
Stone space. 98 
Stone's theorem, 97, I 02 
Structure, 131 
isomorphic, 1 36 
I N D E X 
language associated with, 174 
of finite type, 1 87 
theory of, 1 73 
Sub-formula, 19, 124 
Subcovering 
of a topological space, 68 
Submodel, 1 33 
Substitution 
in a propositional formula, 19 
in terms, 121 
of terms, 1 27 
order of, 21 
Substitution(s), 225 
Substructure, 13 3 
generated by, 134 
generated by a subset, 186 
Symbol 
binary, 8 
constant, I 14 
equality, 1 1 4 
for propositional connective, 8 
for Skolem functions, 1 60  
function, 1 14 
non-logical, 1 14 
one-place, 8 
predicate, 1 14 
relation, 1 14 
two-place, 8 
unary, 8 
Symmetric difference, 58 
Syntactic consequence, 1 97 
Syntactically complete, 203 
Syntax, 8 
System, 226 
Tautology 
of the predicate calculus, 150 
of the propositional calculus, 27 
Term, l 15 
closed, 120 
Theorem, 197 
compactness 
337 
for predicate calculus, 1 7 1 ,  209 
for propositional calculus, 48 
completeness 
for predicate calculus, 208 
Deduction, 201 
Definability, 44 
existence of prenex form, 157 

338 
finiteness, 200 
Krull's, 66 
Lowenheim-Skolem, 319 
marriage, 270 
normal form, 39 
Stone's, I 02 
Tychonoff's, 70 
to prove the compactness theorem, 
71 
Ultrafilter, 97 
Unique decomposition 
for propositional calculus, 15 
Unique readability 
for formulas, 124 
for pseudoformulas. 53. 246 
for terms, 1 20 
Theory, 148 
complete, 173 
consistent, 148 
contradictory, 148, 1 99 
finitely satisfiable, 148 
inconsistent, 148 
non-contradictory, I 99 
of a structure, 17 3 
There exists 
. . .  , I I 4 
Topology 
basic closed sets, 6 7 
basic open sets, 67 
basis for, 6 7 
discrete, 70 
Hausdorff, 68 
induced, 67 
product, 69 
separated, 68 
Torsion element, 267 
Torsion-free, 6 1  
Tree 
decomposition tree of a formula 
of predicate calculus, 124 
of propositional calculus, 14 
root of, 1 4  
Trivial 
homomorphism, 95 
ultrafilter, 95 
True 
in a model, 143 
Truth table(s), 25 
I N D E X  
Truth value(s), 21 
assignment of, 22 
Tychonoff, 70 
Type 
of an element i n  a structure, 191 
Ultrafilter, 94 
Ultrafilter theorem, 97 
Underlying (set), 131 
Unifier, 226 
principal. 227 
Uniform continuity, 22 
Unify, 226 
Unique readability theorem 
for formulas, 1 24 
for pseudoformulas, 246 
for terms, 1 20 
Universal 
clause, 230 
closure, 1 26 
formula, 157 
Valid (formula), 147 
Valuation, 21 
Variable 
bound, 125 
changing the name of, 1 28 
free. 125 
propositional, 8 
Weight 
of a constant symbol, 1 1 7  
of a function symbol, 1 17 
of a variable, 1 17 
of a word, 1 17 
rule of, 1 1 7  
Well-ordering, 190 
Word 
final segment of, xviii 
initial segment of, xviii 
left simplification of, xix 
on an alphabet, xviii 
right simplification of, xix 
Zero element. 32 
Zero-dimensional (space), 69 
Zorn's lemma, 50, 65, 70, 208, 209 

