arXiv:2011.13115v1  [cs.CL]  26 Nov 2020
Learning Causal Bayesian Networks from Text
Farhad Moghimifar, Afshin Rahimi, Mahsa Baktashmotlagh and Xue Li
The School of ITEE
The University of Queensland, Australia
{f.moghimifar,a.rahimi,m.baktashmotlagh}@uq.edu.au
xueli@itee.uq.edu.au
Abstract
Causal relationships form the basis for reason-
ing and decision-making in Artiﬁcial Intelli-
gence systems. To exploit the large volume
of textual data available today, the automatic
discovery of causal relationships from text has
emerged as a signiﬁcant challenge in recent
years. Existing approaches in this realm are
limited to the extraction of low-level relations
among individual events. To overcome the lim-
itations of the existing approaches, in this pa-
per, we propose a method for automatic infer-
ence of causal relationships from human writ-
ten language at conceptual level. To this end,
we leverage the characteristics of hierarchy of
concepts and linguistic variables created from
text, and represent the extracted causal rela-
tionships in the form of a Causal Bayesian
Network. Our experiments demonstrate supe-
riority of our approach over the existing ap-
proaches in inferring complex causal reason-
ing from the text.
1
Introduction
Causation is a powerful psychological tool for
human to choreograph his surrounding environ-
ment into a mental model, and use it for rea-
soning and decision-making.
However, inabil-
ity to identify causality is known to be one of
the drawbacks of current Artiﬁcial Intelligence
(AI) systems (Lake et al., 2015).
Extraction of
causal relations from text is necessity in many
NLP tasks such as question answering and tex-
tual inference, and has attracted a considerable
research in recent years (Wood-Doughty et al.,
2018; Zhao et al., 2018, 2017; Ning et al., 2018;
Rojas-Carulla et al., 2017). However, the state-of-
the-art methods are limited to the identiﬁcation
of causal relations between low-level individual
events (Dunietz et al., 2017; Hidey and McKeown,
2016; Mirza and Tonelli, 2016) and fail to capture
such relationships at conceptual level.
Further-
more, relying on linguistic features limits the iden-
tiﬁcation of causal relations to those whose cause
and effect are located in the same sentence or in
consecutive sentences.
In this paper, we propose a method for ex-
tracting concepts and their underlying causal re-
lations from written language.
Furthermore, to
leverage the extracted causal information, we rep-
resent the causal knowledge in the form of a
Causal Bayesian Network (CBN). Having this tool
enables answering complex causal and counter-
factual questions, such as: How psychotherapy
can affect the patient’s emotion?, or What would
happen if instead of medicine X, medicine Y was
prescribed?
The contribution of this paper is three-fold.
Firstly, we focus on identifying causal relation be-
tween concepts (e.g. physical activity and health).
Secondly, We propose a novel method to repre-
sent the extracted causal knowledge in the form of
a Causal Bayesian Network, enabling easy incor-
poration of this invaluable knowledge into down-
stream NLP tasks. Thirdly, we release PSYCAUS
dataset which can be used to evaluate causal re-
lation extraction models in the domain of psy-
chology 1.
In addition, our proposed method
identiﬁes causality between concepts independent
of their locations in text, and is able to identify
bi-directional causal relations between concepts,
where two concepts have causal effect on each
other. By aggregating linguistic variable, we con-
struct a hierarchy where each variable, e.g. delu-
sional disorder, lies under its related concept, e.g.
disorder. This hierarchical and inheritance struc-
ture allows for the inference of causal relations be-
tween concepts that are not directly discussed in
the text.
1https://github.com/farhadmfar/psycaus

In order to evaluate our proposed method, we
gathered a corpus of psychological articles The ex-
perimental results shows that the proposed method
performs signiﬁcantly better than the state-of-the-
art methods.
2
Related Works
Identiﬁcation of causality in NLP is not triv-
ial as a result of language ambiguity.
Hence,
most current approaches focus on verb-verb, verb-
noun, and noun-noun relations.
The explicit re-
lations are often captured with narrow syntac-
tic and semantic constructions (Do et al., 2011;
Hendrickx et al., 2009; Mirza and Tonelli, 2016;
Hidey and McKeown, 2016) which limits their
recall.
To go beyond surface form construc-
tions few works have proposed neural mod-
els (Mart´ınez-C´amara et al., 2017; Dasgupta et al.,
2018; Zhao et al., 2017) covering wider causal
constructions. However, most works don’t go be-
yond extracting causality between adjacent events,
and so lack the ability to capture causality in non-
adjacent concept level, e.g.
genetics and hallu-
cination. Therefore, in this paper we propose a
model for identifying causality between concepts,
independent of their location, and represent the
causal knowledge in form of a Causal Bayesian
Network.
3
Methodology
Given the input, in form of human written lan-
guage, we aim to extract the causal relation be-
tween concepts and represent the output in form of
a Causal Bayesian Network. Hence, we split this
task into three sub-tasks: extracting linguistic vari-
ables and values, identifying causality between ex-
tracted variables, and creating conditional proba-
bility table for each variable. In the following sub-
sections each of these sub-tasks are explained.
3.1
Linguistic Variables
A linguistic variable is a variable which values are
words in natural language (Zadeh, 1983). For ex-
ample, if we consider the word Age as a linguis-
tic variable, rather than having numeric values, its
values are linguistic, such as young and old. A lin-
guistic word is speciﬁed as (C, T(C)) where C in
the name which represents the set of words or in
other word the variable’s name, and T(C) is the
set of represented words or linguistic values. In
this context, a variable and corresponding value
have an asymmetric relation, in which the hyper-
nym (superordinate) implies the hyponym (subor-
dinate).
In order to create a Bayesian Network (BN)
from text, we ﬁrst need to extract linguistic vari-
ables and values from our corpus.
To this end,
we leverage a probabilistic method introduced by
Wu et al. (2012) to extract all possible IsA rela-
tions from corpus.
To enhance the accuracy of causality identiﬁca-
tion and runtime performance of our model, us-
ing Formal Concept Analysis (Ganter and Wille,
2012), we represent the extracted hypernym-
hyponym relations in form of a hierarchy. In the
context of our corpus, let V be the set of lin-
guistic variables and v be the set linguistic val-
ues, we call the triple of (V, v, I) a formal con-
text where V and v are non-empty sets and I ⊆
V × v is the incidence of the context. The pair
of (Vi, vi) is called a formal concept of (V, v, I)
if Vi ⊆V, vi ⊆v, V
′
i = vi and v
′
i = Vi, where
V
′
i and v
′
i are sets of all attributes common to V
and v, respectively. The formal concept of a given
context are naturally in form of a subconcept-
superconcept relation, given for formal concepts
of (Vi, vi) and (Vj, vj) of (V, v, I) : (Vi, vi) ≤
(V2, v2)
⇐⇒
Vi ⊆Vj( ⇐⇒
vi ⊆vj)). Con-
sequently, we can identify that every attributes in
the former formal concepts are also in the latter.
Hence, this set of formula gives us the hierarchy
of superconcept-subconcepts. Since every link in
this hierarchy implies inheritance, attributes at the
higher level are inherited by lower nodes. There-
fore, if a concept Vi at level n of our hierarchy has
a causal relation with another concept Vj, all the
subconcepts of Vi at lower level m (where m < n),
also have causal relation with Vj.
3.2
Identifying Causality
The core part of this paper is to identify the cause-
effect relation between concepts, or linguistic vari-
ables. In a lower-level approach, causality is usu-
ally presented by syntactic relations, where a word
or a set of words implies existence of causality.
For example, ‘cause’ in ‘Slower-acting drugs, like
ﬂuoxetine, may cause discontinuation symptoms”
indicates a causal relation. These set linguistic fea-
tures can be shown either in form of a verb or a
discourse relation. The Penn Discourse Tree Bank
(PDTB) (Prasad et al., 2008) contains four coarse-
grained relations, comparison, contingency, expan-

sion and temporal, in which contingency may in-
dicate causality.
There are 28 explicitly causal
marker out of 102 in PDTB, with the barrier of
causal relation. Furthermore, we leverage the sets
of verbs included in AltLexes, such as ‘force’
and ‘caused’, which show causality in a sentence.
Using both discourse and verb makers of causal-
ity, we create a database of cause-effect (Γ) from
given sentences. To this end, each of the input sen-
tences are split into simpler version, using depen-
dency parser, and once any of causality markers
are identiﬁed in a sentence, the stopwords from
cause and effect parts are eliminated and the re-
maining words are stemmed.
Having the con-
structed cause-effect database (Γ), the causal re-
lation between two concepts is deﬁned as:
CR(Vm, Vn) =
P|Vm|
i=1
P|Vn|
j=1
1[(vi
m, vj
n) ∈Γ]⃗vi
m · ⃗Vm
P|Vm|
i=1 ⃗vim · ⃗Vm
−
P|Vn|
j=1
P|Vm|
i=1
1[(vj
n, vi
m) ∈Γ]⃗vj
n · ⃗Vn
P|Vn|
j=1 ⃗vj
n · ⃗Vn
(1)
where Vm and Vn are two concepts or linguistic
variables in the concept space V , and vi
m is the i-th
value of Vm; the functions r and w are deﬁned as
below:
r(a, b) =
(
1
if(a, b) ∈Γ
0
if(a, b) /∈Γ
(2)
and
w(a, b) = 1 −Sc(a, b) = 1 −sim(a, b)
(3)
where sim is Cosine similarity of words a and b.
The purpose of function w is to measure the rel-
evance of the value to the corresponding variable,
in order to increase the inﬂuence of more relevant
values. The output of CR can be categorised as
follow:
CR(A, B) ∈





(µ, 1]
A cause; B effect
[−µ, µ]
no causal relationship
[−1, −µ)
B cause; A effect
(4)
where µ is a threshold given to the model as a
hyper-parameter.
3.3
Creating Conditional Probability
Distribution
Conditional Probability Distribution (CPD) shows
conditional probability of corresponding values to
a variables with respect to values of parents of the
variable P(Xi|Parents(Xi)). In order to extend
the implementation of CPD for sets of linguistic
variables we use Normalized Pointwise Mutual In-
formation (PMI) score to calculate the probability
distribution (Bouma, 2009).
in(x, y) = (ln p(x, y)
p(x)p(y))/ −ln(p(x, y))
(5)
The reason behind using PMI comes from Suppes’
Probabilistic theory of Causality (Suppes, 1973),
where he mentions that possibility of an effect to
co-happen with cause is higher than happening by
itself. In mathematical word it can be shown as
P(effect|cause) > P(effect), which can be
easily written as
P(cause, effect)
P(cause)P(effect) > 1, similar
to PMI for positive values.
To create a Causal Bayesian Network from tex-
tual data, let G be our graphical model, and V =
{V1, V2, ..., Vn} be the set of extracted linguistic
variables (as deﬁned in §3.1) from our corpus ζ.
We deﬁne PaG
Vi = {V j : V j
causal
−−−−→Vi}, indi-
cating set of nodes in ζ which have causal relation
with Vi. By expressing P as:
P(V1, V2, ..., Vn) =
n
Y
i=1
P(Vi|PaG
Vi)
(6)
we can argue that P factorises over G. The individ-
ual factor P(Vi|PaG
Vi) is called conditional proba-
bility distribution (explained in 3.3). In a more
formal way, we deﬁne Causal Bayesian Network
over our corpus ζ as β = (G, P) where P is set of
conditional probability distributions. In addition
to the aforementioned usages of a CBN, having
a Causal Bayesian Networks enables the possibil-
ity of answering questions in three different layers
of Association, Intervention and Counter-factual
(Pearl and Mackenzie, 2018).
4
Experimental Results
In this section, we evaluate the effectiveness of our
method and compare it with that of the state-of-
the-art methods on a collection of Wikipedia ar-
ticles related to Psychology. Each article within
this collection is selected based on the terms
in APA dictionary of Psychology (VandenBos,
2007).
This collection contains a total number
of 3,763,859 sentences.
Among all possible re-
lation between concepts, we studied 300 relation-
ships between concepts, which were annotated
by 5 graduate student from school of Psychol-
ogy. Each tuple of relationship in form of (A, B),
were labelled as −1, 0, or 1, where 1 indicates
A
cause
−−−→B, −1 shows that B
cause
−−−→A, and 0
implies no causal relations. With the overlap tu-
ples (25%) we measured the degree of agreement
between annotators using Fleiss’ Kappa measure

majority class
frequency
PMI
prec-PMI
precedence
dist. PMI
dist. counts
dist. prec-PMI
dist. prec-counts
dist. w2vio
dist. w2vii
dist. w2voi
feat. counts
feat. prec-counts
feat. PMI
feat. prec-PMI
feat. w2vio
feat. w2voi
feat. w2vii
CR
0.2
0.4
0.6
0.42
0.17
0.33
0.46
0.49
0.5
0.5
0.51
0.51
0.51
0.51
0.52
0.52
0.53
0.54
0.55
0.55
0.55
0.56
0.69
Figure 1: The test accuracy of CR compared with feature-based, distribution-based, heuristic methods, and the majority class.
(Fleiss and Cohen, 1973), which was around 0.67.
This indicates the reliability of our test setup.
We compare our model to the feature-based
and
distribution-based
methods
proposed
by
Rojas-Carulla et al. (2017), with different proxy
projection functions, including { w2vii,
w2vio,
w2voi,
counts,
prec-counts,
pmi,
prec-pmi}.
Furthermore, we compare our model to heuris-
tic models, consisting of frequency, precedence,
PMI, PMI (precedence), where in each of the mod-
els two parameters are calculated, SVi→Vj and
SVi→Vj, indicating Vi
cause
−−−→Vj if SVi→Vj
>
SVi→Vj and Vi
cause
←−−−Vj if SVi→Vj < SVi→Vj.
Figure 1 shows the accuracy of different meth-
ods for identifying causal relationships.
We ob-
serve that our method (the red bar) outperforms all
other approaches with an accuracy of 0.694. This
indicates an improvement of 13% over the state-
of-the-art feature-based methods (the blue bars),
17% over the distribution-based approaches (the
orange bars), and 20% over the baseline meth-
ods (green bars).
The baseline methods repre-
sented the worst performance, however, the accu-
racy achieved by precedence suggests that most of
our corpus is written in form of active rather than
passive voice, resulting in consequential connec-
tion between concepts.
To analyse the sensitivity of our method to the
threshold µ in Equation 1, we trained the model
on PSYCAUS’s training set(Dtr), and analysed the
development set performance in terms of macro-
averaged F1 with a range of values [0, 1) for µ. As
shown in Figure 2, F1 score reaches the maximum
of 0.66 with µ = 0.05, well above a random clas-
siﬁer.
During the annotation process, we noticed that
some concepts, e.g. eating disorder and emotion,
may have bi-directional causal relations, depend-
ing on the context (eating disorder
cause
←−→emotion).
We ran our model against these examples and
found out that our approach is interestingly ca-
pable of identifying these relations as well.
In
Equation 1, approximation of absolute values of
both operands in the negation to one indicates bi-
directional causality. While a bi-directional causal
relation cannot be presented in a CBN, as it is a
directed graphical model, a decision tree can con-
tain these types of information. In addition, some
concepts, e.g.
delusional disorder and displea-
sure, that have not been connected with any type
of causality connectives were also accurately iden-
tiﬁed as causal relations. This is due to the hierar-
chical design of variable-values in our model.
0
0.25
0.5
0.75
0.95
0
0.2
0.4
0.6
0.8
0.1
µ
macro-averaged F1 score
CR
majority class
Figure 2: The macro-averaged F1 score of our proposed
method on the development of PSYCAUS with different val-
ues of µ (Equation 1), compared with macro-averaged F1
score of the majority class model.
5
Conclusion
In this paper we have presented a novel approach
for identifying causal relationship between con-
cepts.
This approach enables machines to ex-
tract causality even between non-adjacent con-

cepts. Hence, a signiﬁcant improvement was deliv-
ered comparing to naive baselines. Furthermore,
we represented the causal knowledge extracted
from human-written language in form of Causal
Bayesian Network.
To the best of our knowl-
edge this representation is novel. Having a Causal
Bayesian Network can empower many down-
stream applications, including question-answering
and reasoning.
Among all applications, causal
and counter-factual reasoning, which can be build
on top of the outcome of this paper, may address
some current hallmarks of Artiﬁcial Intelligence
systems.
References
Gerlof Bouma. 2009. Normalized (pointwise) mutual
information in collocation extraction. Proceedings
of GSCL, pages 31–40.
Tirthankar Dasgupta, Rupsa Saha, Lipika Dey, and
Abir Naskar. 2018. Automatic extraction of causal
relations from text using linguistically informed
deep neural networks. In Proceedings of the 19th
Annual SIGdial Meeting on Discourse and Dialogue,
pages 306–316.
Quang Xuan Do, Yee Seng Chan, and Dan Roth.
2011. Minimally supervised event causality identi-
ﬁcation. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing,
pages 294–303. Association for Computational Lin-
guistics.
Jesse Dunietz, Lori Levin, and Jaime Carbonell. 2017.
Automatically tagging constructions of causation
and their slot-ﬁllers. Transactions of the Association
for Computational Linguistics, 5:117–133.
Joseph L Fleiss and Jacob Cohen. 1973. The equiv-
alence of weighted kappa and the intraclass corre-
lation coefﬁcient as measures of reliability. Educa-
tional and psychological measurement, 33(3):613–
619.
Bernhard Ganter and Rudolf Wille. 2012. Formal con-
cept analysis: mathematical foundations. Springer
Science & Business Media.
Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva,
Preslav Nakov, Diarmuid ´O S´eaghdha, Sebastian
Pad´o, Marco Pennacchiotti, Lorenza Romano, and
Stan Szpakowicz. 2009.
Semeval-2010 task 8:
Multi-way classiﬁcation of semantic relations be-
tween pairs of nominals.
In Proceedings of the
Workshop on Semantic Evaluations: Recent Achieve-
ments and Future Directions, pages 94–99. Associa-
tion for Computational Linguistics.
Christopher Hidey and Kathy McKeown. 2016. Iden-
tifying causal relations using parallel wikipedia arti-
cles. In Proceedings of the 54th Annual Meeting of
the Association for Computational Linguistics, vol-
ume 1, pages 1424–1433.
Brenden M Lake, Ruslan Salakhutdinov, and Joshua B
Tenenbaum. 2015.
Human-level concept learning
through probabilistic program induction.
Science,
350(6266):1332–1338.
Eugenio Mart´ınez-C´amara,
Vered Shwartz,
Iryna
Gurevych, and Ido Dagan. 2017.
Neural disam-
biguation of causal lexical markers based on context.
In 12th International Conference on Computational
Semantics Short papers (IWCS).
Paramita Mirza and Sara Tonelli. 2016. Catena: Causal
and temporal relation extraction from natural lan-
guage texts. In Proceedings the 26th International
Conference on Computational Linguistics: Techni-
cal Papers, pages 64–75.
Qiang Ning, Zhili Feng, Hao Wu, and Dan Roth. 2018.
Joint reasoning for temporal and causal relations. In
Proceedings of the 56th Annual Meeting of the As-
sociation for Computational Linguistics, volume 1,
pages 2278–2288.
Judea Pearl and Dana Mackenzie. 2018. The book of
why: the new science of cause and effect.
Basic
Books.
Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind K Joshi, and Bon-
nie L Webber. 2008. The penn discourse treebank
2.0. In LREC. Citeseer.
Mateo Rojas-Carulla, Marco Baroni, and David Lopez-
Paz. 2017. Causal discovery using proxy variables.
arXiv preprint arXiv:1702.07306.
Patrick Suppes. 1973. A probabilistic theory of causal-
ity.
Gary R VandenBos. 2007. APA dictionary of psychol-
ogy. American Psychological Association.
Zach Wood-Doughty, Ilya Shpitser, and Mark Dredze.
2018. Challenges of using text classiﬁers for causal
inference. arXiv preprint arXiv:1810.00956.
Wentao Wu, Hongsong Li, Haixun Wang, and Kenny Q
Zhu. 2012. Probase: A probabilistic taxonomy for
text understanding. In Proceedings of the 2012 ACM
SIGMOD International Conference on Management
of Data, pages 481–492. ACM.
LotﬁA Zadeh. 1983.
Linguistic variables, approxi-
mate reasoning and dispositions. Medical Informat-
ics, 8(3):173–186.
Sendong Zhao, Meng Jiang, Ming Liu, Bing Qin, and
Ting Liu. 2018. Causaltriad: Toward pseudo causal
relation discovery and hypotheses generation from
medical text data. In Proceedings of the 2018 ACM
International Conference on Bioinformatics, Com-
putational Biology, and Health Informatics, pages
184–193. ACM.

Sendong Zhao, Quan Wang, Sean Massung, Bing Qin,
Ting Liu, Bin Wang, and ChengXiang Zhai. 2017.
Constructing and embedding abstract event causality
networks from text snippets. In Proceedings of the
Tenth ACM International Conference on Web Search
and Data Mining, pages 335–344. ACM.

This figure "disorders.png" is available in "png"
 format from:
http://arxiv.org/ps/2011.13115v1

