
SYMMETRY AND COMPLEXITY
THE SPIRIT AND BEAUTY OF NONLINEAR SCIENCE

This page intentionally left blank

SYMMETRY AND COMPLEXITY
THE SPIRIT AND BEAUTY OF NONLINEAR SCIENCE
Klaus Mainzer
World Scientific
We
University of Augsburg, Germany
Series Editor: Leon O. Chua
Series A Vol. 51
ONLINEAR SCIENC
WORLD SCIENTIFIC SERIES ON
N
E
NEW JERSEY · LONDON · SINGAPORE · BEIJING · SHANGHAI · HONG KONG · TAIPEI · BANGALORE

British Library Cataloguing-in-Publication Data
A catalogue record for this book is available from the British Library.
For photocopying of material in this volume, please pay a copying fee through the Copyright
Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, USA. In this case permission to
photocopy is not required from the publisher.
ISBN 981-256-192-7
All rights reserved. This book, or parts thereof, may not be reproduced in any form or by any means,
electronic or mechanical, including photocopying, recording or any information storage and retrieval
system now known or to be invented, without written permission from the Publisher.
Copyright © 2005 by World Scientific Publishing Co. Pte. Ltd.
Published by
World Scientific Publishing Co. Pte. Ltd.
5 Toh Tuck Link, Singapore 596224
USA office:  27 Warren Street, Suite 401-402, Hackensack, NJ 07601
UK office:  57 Shelton Street, Covent Garden, London WC2H 9HE
Printed in Singapore.
SYMMETRY AND COMPLEXITY
The Spirit and Beauty of Nonlinear Science

Preface
Symmetry and complexity determine the spirit of nonlinear science.
The expansion of the universe, the evolution of life and the globaliza-
tion of human economies and societies lead from symmetry and sim-
plicity to complexity and diversity. The emergence of new order and
structure means symmetry breaking and transition from unstable to
stable states of balance. It is explained by physical, chemical, biolog-
ical, and social self-organization, according to the laws of nonlinear
dynamics. Atoms and molecules, stars and clouds, organisms and
brains, economies and societies are only some examples of dynamical
systems. Thus, symmetry and complexity are the basic principles
of a common systems science in the 21st century, overcoming tra-
ditional boundaries between natural, cognitive, and social sciences,
mathematics, humanities and philosophy.
This book treats the essence of my scientiﬁc work that can be
described by a kind of dialectical triad.
In a ﬁrst step, I pub-
lished a comprehensive treatise on Symmetries of Nature in 1988
(English: 1996). Early studies in geometry and space-time had in-
spired my interest in mathematical invariance and universal laws.
As many other scientists, philosophers, and artists, I was also fas-
cinated by the beauty of mathematical symmetries.
But, physi-
cal, chemical, and biological symmetries are broken by natural pro-
cesses, leading to the observed complexity and diversity of the world.
Therefore, I studied the foundations of nonlinear dynamics and, as
a second step, published the book Thinking in Complexity.
The
v

vi
Symmetry and Complexity
Complex Dynamics of Matter, Mind, and Mankind in 1994 (4th
enlarged edition 2004).
My interest in complexity dates back to
my Ph.D. thesis on the foundations of constructive mathematics
and computational degrees of complexity in 1973.
In many other
books and articles, I enlarged the applications of nonlinear systems
to computer science, cognitive science, and social science.
After
thesis and antithesis, this book is the synthesis of Symmetry and
Complexity. It also connects my life-long love of music and art with
nonlinear science.
Research is always realized in a network of cooperation and com-
munication. Therefore, I want to thank some colleagues, friends and
institutions. Leon O. Chua (Department of Electrical Engineering
& Computer Sciences, University of California, Berkeley) invited me
to publish a book in his series on Nonlinear Science. He is also the
editor of the International Journal of Bifurcation and Chaos in Ap-
plied Sciences and Engineering. As a member of the editorial board
of this journal, I have the opportunity to get an interdisciplinary
overview of worldwide explorations in nonlinear science. Symmetry
and complexity are also topics of international and cultural inte-
gration. International translations of my books underline the inter-
est in symmetry and complexity beyond all cultural boundaries. I
would like to thank the European Academy of Science (Academia
Europaea in London) who invited me for a lecture on symmetry
and complex systems in January 2005. Furthermore, I would like
to thank the Leibniz-Community of German Research Institutions
and the Japanese Research Institute of Integration Science for their
kind invitation on a lecture on complex systems in October 2004.
Thanks also to Hermann Haken and Wolfgang Weidlich (Institute
of Theoretical Physics, University of Stuttgart), J¨urgen Mittelstraß
(Department of Philosophy, University of Constance), Martin Quack
(Laboratory of Physical Chemistry, ETH Z¨urich), and Alwyn Scott
(Department of Mathematics, University of Arizona) who have in-
spired and supported my work.
Last but not least, I would like to thank Dominik B¨osl, Michael
Hochholdinger, Jutta Janßen, Tobias Jung, Paul Williams (Univer-

Preface
vii
sity of Augsburg) and Lakshmi Narayan (World Scientiﬁc Publish-
ing) for preparing the publication.
Augsburg and Munich, September 2004
Klaus Mainzer

This page intentionally left blank

Contents
Preface
v
Introduction
1
1.
Symmetry and Complexity in Early Culture and Philosophy 23
1.1 Cultural and Cosmic Harmony
. . . . . . . . . . . . .
23
1.2 Cultural and Cosmic Diversity
. . . . . . . . . . . . .
48
2.
Symmetry and Complexity in Mathematics
63
2.1 Symmetry and Group Theory . . . . . . . . . . . . . .
64
2.2 Symmetry Breaking and Bifurcation Theory . . . . . .
83
2.3 Complexity, Nonlinearity and Fractals . . . . . . . . .
99
3.
Symmetry and Complexity in Physical Sciences
107
3.1 Symmetry in Physics . . . . . . . . . . . . . . . . . . . 110
3.2 Symmetry Breaking and Phase Transitions
. . . . . . 147
3.3 Complexity, Attractors and Dynamical Systems . . . . 158
4.
Symmetry and Complexity in Chemical Sciences
171
4.1 Symmetry in Chemistry . . . . . . . . . . . . . . . . . 171
4.2 Symmetry Breaking and Chirality
. . . . . . . . . . . 184
4.3 Complexity, Dissipation and Nanosystems . . . . . . . 190
ix

x
Symmetry and Complexity
5.
Symmetry and Complexity in Life Sciences
199
5.1 Symmetry in Biology . . . . . . . . . . . . . . . . . . . 199
5.2 Symmetry Breaking and Evolution . . . . . . . . . . . 210
5.3 Complexity and Biodiversity of Life
. . . . . . . . . . 223
6.
Symmetry and Complexity in Economic and
Social Sciences
239
6.1 Symmetry, Social Balance and Economic
Equilibrium . . . . . . . . . . . . . . . . . . . . . . . . 239
6.2 Symmetry Breaking and Socio-economic
Transitions
. . . . . . . . . . . . . . . . . . . . . . . . 248
6.3 Complexity and Sociodiversity of Globalization . . . . 259
7.
Symmetry and Complexity in Computer Science
273
7.1 Symmetry and Complexity in Information
Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . 273
7.2 Symmetry and Complexity in Computational
Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . 284
8.
Symmetry and Complexity in Philosophy and Arts
329
8.1 The Philosophy of Symmetry and Complexity . . . . . 329
8.2 The Beauty of Symmetry and Complexity . . . . . . . 357
References
389
Subject Index
425
Name Index
435

Introduction
Long before any science, man was fascinated by symmetry. Symmet-
ric ornaments seem to represent perfect order, beauty, and divine
harmony. Symmetrical forms and symbols are to be found in art and
architecture as well as in everyday useful objects and in the mytholo-
gies of religions. Symmetry is a multi-cultural phenomenon. It spans
the human life world, technology, culture and nature, and thereby
searches out a unity of the natural and human sciences. Until today,
symmetries have been a theme of current interest in the natural sci-
ences. Nobel prizes in physics have been awarded for research into
the symmetry of the elementary particles and the universe. Ques-
tions of symmetry are discussed in chemistry and biology as well.
The various basic laws of natural sciences are derivable from unitary
mathematical structures of symmetry. Modern scientists often share
with the Pythagoreans of Antiquity the belief in a cosmos ordered
and in balance by the highest and most perfectly mathematical laws:
in the beginning, there was symmetry and simplicity.
But, actually, the world is neither always simple nor in static bal-
ance and harmony. There is also steady change, dynamics, random
and chaos. Symmetry is locally and globally broken by phase tran-
sitions of instability in dynamical systems generating a variety of
new order and partial symmetries with increasing complexity. The
states of complex dynamical systems can refer to, e.g., atomic clus-
ters, crystals, biomolecules, organisms and brains, social and eco-
nomic systems. This book analyzes dynamical balance as dynamical
1

2
Symmetry and Complexity
symmetry in dynamical systems. Their beauty can be visualized by
computer simulations of computational systems.
Symmetry breaking and the emergence of new order and chaos
is an interdisciplinary challenge of nonlinear science. Linear systems
are simple and can be resolved into more simple components, the
eﬀects of which are treated separately: the whole is the sum of its
parts. Nonlinear systems are complex with several interacting eﬀects
of their components: the whole is greater than the sum of its parts,
leading to the emergence of new structures and sometimes chaos.
What is the common link between symmetry and complexity? It is
symmetry breaking as the origin of dynamics and variety of forms
and systems in the world. Thus, symmetry and complexity are the
spirit of nonlinear science.
The ﬁrst chapter deals with symmetry and complexity in early
culture and philosophy up to the beginning of the modern natural
sciences in the Renaissance. The ﬁrst section directs the reader to
the use of symmetry patterns in early cultures. In the mythologies
of the nature religions, gods and goddesses determine natural forces.
These are replaced in the Greek natural philosophy by symmetry
models for the rational explanation of nature.
The mathematical
formulation of the concept of symmetry was a decisive prerequisite.
In the Pythagorean quadrivium — geometry, arithmetic, music and
astronomy — the harmony and proportionality (of nature
became the central concern of a mathematical philosophy. Animated
by technical, aesthetic or religious motives, symmetry remains a fa-
vorite theme of Antique-Medieval mathematics. In geometry, the-
orems about regular plane ﬁgures and regular solids of Euclidean
space are proven. In arithmetic and music, laws of proportion and
harmony are explored. In astronomy, spherical models are used to
explain the phenomena of the heavens.
But what would harmony be without dissonance and violation of
symmetry? Presumably, without charm, and boring, since it would
be the everyday, the normal. But in fact we are ﬂooded with infor-
mation from the outer world in which chaotic multiplicity and change
are the probable. Order and lasting symmetries seem to be the im-

Introduction
3
probable. The centro-symmetric spherical models of Eudoxus and
Aristotle soon come into conﬂict with discrepant observations of the
sky, which right up to N. Copernicus require increasingly elaborate
geometrical and kinematic assumptions in order to save the symme-
try of the model. What remains are artiﬁcial and complicated models
of planets which lose their credibility because — as Copernicus in his
Platonic tradition still believes — only the simple can be real, the
simple which underlies the multiplicity of phenomena. The history
of Antique-Medieval astronomy oﬀers a convincing case study for in-
vestigating the interplay of original assumptions of symmetry on the
one hand, and the breaks of symmetry on the basis of new realiza-
tions on the other hand, as a basic pattern of the development of
research, which will be repeated on into modern physics.
But not only the Greek macrocosm is determined by symmetries.
The Greek atomists form a contrast to the organic conception of
nature, not even comprehending life as it is holistically given, but
instead wanting to trace all existent things back to the aimless col-
lision of the smallest indivisible building blocks () in empty
space. They design a simple and linear world. Plato’s natural philos-
ophy introduces a mathematical model of the microcosm for the ﬁrst
time, explaining the elements by means of the geometric symmetry
of regular bodies. Modern physicists feel in the Platonic tradition,
when they try to explain the world’s fundamental equations by more
sophisticated mathematical principles of symmetry.
Contrary to the eternal symmetries of macro- and microcosm,
the mesocosm of the human world seems to be characterized by
steady change, development, growth and decay, birth and death.
In Antiquity, the mesoworld between the celestial spheres and atoms
remains extensively separate from mathematics, since, as Aristotle
says, physics deals with motion and change; mathematics with the
unchanging. Therefore only the eternally recurring circular motions
of the heavens are formulated mathematically and are considered di-
vine. Only simplicity can be mathematized. The complexity and
variability of nature on earth is collected, ordered, and explained by
means of various qualitative principles of the natural philosophy from

4
Symmetry and Complexity
the time of the Presocratics. Examples are the change from ﬂuid to
solid states, from cold to heat as well as the organic developments
and the life of humans and animals from birth to death, or the growth
and decay of plants, which are understood to be goal-directed pro-
cesses. Obviously, Aristotle explains change and process in nature as
state transitions leading to ﬁnal attractors of development. Nature
is seen as a great organism whose processes are tuned to each other
in balance, but which can be destabilized by catastrophes. It is a
holistic and qualitative view of a dynamical world that is later on
mathematized by nonlinear science.
Symmetry assumptions in the astronomy and natural philosophy
of Antiquity were founded on plane and solid ﬁgure symmetries of
Euclidean geometry: the circle, the sphere, and regular solids. But
in order to understand the laws of nature of modern physics as as-
sumptions of symmetry, it is necessary to investigate symmetry and
complexity in modern mathematics (second chapter). It was ﬁrst of
all algebra and group theory from the end of the 18th century that
created the basis for the rigorous, general mathematical deﬁnition of
the concept of symmetry (the “automorphism group”), which found
its ﬁrst application in the crystallography and stereochemistry of the
19th century and then in almost all parts of modern natural science.
The second chapter treats the discrete symmetries of the ornaments
and crystals from the point of view of group theory. But historically
the group concept was ﬁrst applied in the algebraic theory of equa-
tions (“Galois theory”), which can also be used to solve construction
problems of symmetries from Antiquity. The continuous groups of
diﬀerential geometry (“Lie groups”) became important for modern
physics.
Mathematically, symmetry is characterized by a group of trans-
formations that leave certain features of a system unchanged.
A
system characterized by a larger group of transformations has higher
symmetry. For example, a circle has more rotational transformations
bringing it back into itself than a regular polygon. The symmetry
of a system is broken when new features emerge that are not in-
variant under at least some of its transformations. An example is

Introduction
5
a corner appearing on a circle. Broken symmetry is a crucial con-
cept to understand emergent phenomena of dynamical systems. If
dynamical systems become unstable, they can jump from one state
to another one with a completely diﬀerent pattern of behavior. Such
instabilities in behavioral patterns are called bifurcations. A cascade
of bifurcations can lead from order to chaos which involves broken
symmetries.
Since Poincar´e’s discovery of deterministic chaos, the mathemat-
ical theory of bifurcation had been a basic topic of nonlinear science.
The transition from order to chaos is connected with the emergence
of fractals. They opened new avenues to the nonlinear world of our
everyday life, which Aristotle strictly excluded from mathematiza-
tion. Obviously, Euclidean geometry is unable to describe the shape
of a cloud, a mountain, a coastline or a tree, because they are no
spheres, cones, or circles. B.B. Mandelbrot introduced the notion
of a fractal to describe these bizarre shapes with a new geometry of
nature. Fractals are characterized by structures that are self-similar
on various scales. They do not change their appearance when they
are enlarged or diminished to arbitrary size. Self-similarity is a kind
of symmetry. Therefore, fractal geometry reveals the mathematical
beauty of symmetries even behind the nonlinear world of change and
chaos.
In the third chapter symmetry and complexity are examined in
physical sciences. In classical physics, symmetry is understood to
be invariance of natural laws or physical equations with respect to
continuous transformation groups. This establishes that a natural
law is objectively valid — independently of changes in the position
or the point in time of its examination by an experimenter or ob-
server. Symmetries correspond to the freedom to choose the system
of coordinates of the observer. All natural laws are invariant with
respect to translation, rotation and reﬂection of the system of coor-
dinates. The symmetries are global in the sense that natural laws are
invariant with respect to equivalent transformations for all points in
the space. With the concept of an inertial system, the principle of
relativity in classical physics is deﬁned by Galilean invariance.

6
Symmetry and Complexity
The joining of electricity, magnetism and optics succeeds math-
ematically in electrodynamics, which can be formulated invariantly
to the Lorentz group. J.C. Maxwell had already predicted that light
could be reduced to the electromagnetic ﬁeld.
In fact, the wave
equations for the phase velocity of light were derived from Maxwell’s
equations and conﬁrmed experimentally by H. Hertz. This brought
about, for the ﬁrst time, a uniﬁcation of the phenomena of nature
in mathematical physics. Further, Maxwell’s electrodynamics con-
stituted, for the ﬁrst time, a physical theory for which the modern
physical concept of symmetry could be expressed with precision. The
electromagnetic ﬁeld has both “global” symmetry in accordance with
the Lorentz invariance — in which all space-time coordinates can be
altered — and also “local” symmetry in the sense of a gauge ﬁeld.
Even in 1923 H. Weyl characterized the theory of the electromagnetic
ﬁeld as “the most perfect piece of physics that we know today.”
The application of physical symmetry concepts is closely con-
nected with mathematical developments in algebra and geometry
in the 19th century. In 1872, F. Klein, in his well-known “Erlanger
Program”, had characterized and classiﬁed various geometric theo-
ries by means of continuous transformation groups. Under the direct
inﬂuence of F. Klein, E. Noether in 1918 expanded this program
for physics and showed how physical conservation principles can be
characterized by means of transformation groups and traced back to
space-time symmetries.
The mathematical variational and extremal principles are of cen-
tral signiﬁcance for the physical concept of symmetry. Historically
they arise out of the background of Leibniz’s natural philosophy of
pre-established harmony and are determined by the search for a co-
herent basic principle of nature.
For the symmetry concepts of modern physics, ﬁrst to be dis-
cussed is the Lorentz invariance of the force-free 4-dimensional
Minkowski space of the special relativity theory, in which two ob-
servers have constant velocity relative to each other. It is a matter
of global symmetry, since the transformations refer to all space-time
coordinates. The local Lorentz invariance of the general theory of

Introduction
7
relativity has to fulﬁll much stricter requirements. Now the physi-
cal laws have to keep the same form even when every single point
is transformed independently of all the others. This mathematical
sharpening has the same signiﬁcance as the physical postulate that
two observers may also increase their speed relative to each other,
that is, that gravitational forces come into play. A key concept of
modern physics is to describe the introduction of fundamental forces
mathematically by means of the transition from a global symmetry
to a local symmetry. Relativistic cosmology applies the diﬀerential-
geometric theory of symmetrical spaces, which E. Cartan had devel-
oped in the twenties of the last century from the theory of spaces
with constant curvature (B. Riemann, S. Lie, H. von Helmholtz
et al.).
The solutions to Einstein’s gravitation equation allow for
varying symmetrical models, e.g. that the spatially homogeneous uni-
verse expands isotropically, or collapses, or oscillates. The Platonic
belief in a macroscopically symmetrical cosmos on the whole is once
more urgent, even if mathematically more complicated and no longer
in the form of the ancient harmony of the spheres.
In this context it is noteworthy that D. Hilbert derived the rela-
tivistic equations together with Mie’s electrodynamic equations from
a variation principle independently of A. Einstein.
This was the
ﬁrst attempt at a uniﬁcation of the fundamental forces in modern
physics, which, however, succeeded only later under the conditions
of quantum mechanics. Mie’s “theory of matter” from 1912 is also an
important document of nonlinear science. He suggested a nonlinear
augmentation of Maxwell’s electromagnetic equations out of which
elementary particles (e.g. the electron) would arise in a natural way.
Although Mie’s theory was later on refuted by experiments, Einstein
was deeply convinced that elementary particles must be represented
by exact solutions of nonlinear partial diﬀerential equations founding
a uniﬁed ﬁeld theory of matter. Therefore, Einstein never accepted
the quantum mechanical approach.
Next to the relativity theory, quantum mechanics is the frame-
work theory of modern physics.
Recall ﬁrst, the spherically sym-
metrical characteristics of the early atom models by which N. Bohr

8
Symmetry and Complexity
explained the discontinuous spectral lines of the chemical elements.
According to these models the electrons move on ﬁxed paths around
the nucleus, like the ancient planets.
By analogy to the develop-
ment of the Aristotelian planet models, Bohr’s originally simple atom
model must also be assimilated by means of certain artiﬁces (in this
case the quantum numbers) to the complicated relationships that re-
veal themselves for various elements in the laboratory. Thus the basic
equation of quantum mechanics, the Schr¨odinger equation, exhibits
two kinds of symmetry. It can be assumed, at least approximately,
that the electrons have a spherically-symmetrical potential energy
for which no direction is distinguished, so that the corresponding
Hamiltonian function is invariant towards the symmetry operations
of the sphere. Further, electrons are indistinguishable (G.W. Leib-
niz: “indiscernibiles”) in the sense that it makes no diﬀerence for
the Hamiltonian function whether the positions of the electrons are
exchanged and permuted.
This permutation symmetry is closely
connected to Pauli’s principle of exclusion, according to which two
electrons do not have the same quantum number. With reference
to Leibniz’s principle of indistinguishability, Weyl also speaks of the
Leibniz-Pauli-principle of symmetry.
Mathematically, the states of quantum systems (atoms, electrons,
etc.) can be represented by vectors of a Hilbert space. The symmetry
(automorphism group) of the Hilbert space formalism of von Neu-
mann’s quantum mechanics has been investigated especially by Weyl,
E.P. Wigner et al. since the end of the twenties of the last century,
and related to the unitary transformations of the Hilbert space. The
space-time symmetries are determined by a subgroup that can be rep-
resented by the Galileo group of classical physics. But the decisive
distinction from classical physics (and from the relativity theory) is
that quantities in (von Neumann’s) quantum mechanics that can be
used as measuring quantities (“observables”), are not exchangeable
(“commutative”).
This group-theoretic characteristic of quantum
systems comes to expression in terms of measurement technique in
that it makes a diﬀerence in what sequence quantities are measured.
There is an aggravating disadvantage in von Neumann’s quantum

Introduction
9
mechanics in that no classical (“commutative”) observables are al-
lowable. But how can the demonstrable existence of commutative
quantities in the quantum realm, e.g. spin or rest masses, be under-
stood (the problem of “superselection rules”, respectively “violation
of the principle of superposition”)? How can the measuring process
of quantum mechanics be described? It is an interaction between a
classical measuring instrument and a quantum system. Hence, gener-
alized formalisms of quantum mechanics (e.g. C∗-algebra, quantum
logic) have been developed which also admit classical observables
and are determined by symmetry groups. Thereby, from the per-
spective of uniting natural-science theories, a framework is built in
which classical systems, quantum systems (in von Neumann’s sense),
generalized quantum systems and thermodynamic systems can be
examined.
The historical development of physical theories is deﬁned by a
step-by-step uniﬁcation.
I. Newton achieved the ﬁrst great uniﬁ-
cation when he traced trajectories of free-falling or projected ter-
restrial bodies to the same conformity with celestial bodies. Next
came Maxwell who based electricity, magnetism and optics on elec-
trodynamics.
Newton’s gravitation theory had to be replaced by
Einstein’s general relativity theory, and Maxwell’s electrodynam-
ics had to be enlarged by special relativity theory, and quantum
mechanics by quantum ﬁeld theories, especially quantum electro-
dynamics.
The ﬁrst step in that direction was made, already in
1928, by P.A.M. Dirac, when he predicted — with a relativistic
quantum mechanical wave equation — an anti-particle to the elec-
tron (“positron”), which in fact was discovered in 1932. The break-
through for the theory of the electromagnetic interaction of electrons,
positrons and photons came at the end of the forties with the work
of R.P. Feynman, J.S. Schwinger et al. The group of (unitary) trans-
formations, which leaves the laws of this theory invariant, has the
so-called U(l) symmetry.
Physically these transformations corre-
spond to a process in which a particle is transformed from one state
into another without changing its identity. Thus an electron can go
to another energy state by sending out a photon. The initial state

10
Symmetry and Complexity
and the ﬁnal state do not diﬀer in electrical charge, and the tran-
sitions between the two states by means of the emission of photons
can be represented by an 1 × 1 matrix. Here we encounter an en-
tirely new kind of symmetry that is no longer a matter of “external”
space-time symmetries such as reﬂections, rotations, translations,
etc. but instead of “inner” (intrinsic) symmetries of transformations
of matter.
Another inner symmetry is isospin symmetry establishing a con-
nection between the nuclear particles proton and neutron and the
nuclear forces. Both particles possess the same spin and almost the
same mass, so that they — as W. Heisenberg recommended — can
be conceived of as two possible states of a particle, the nucleon.
Transitions from one state to another are described by means of the
so-called SU(2) group.
While neutrons and protons are the only
particles with strong interaction which are stable for a long time,
with today’s high-energy technology a multiplicity of very short-
lived particles with strong interactions (“hadrons”) can be produced.
This “zoo” of hadrons, which was discovered in the ﬁfties of the last
century more or less by chance, was ﬁnally derived from a unitary
symmetry structure. Since then all hadrons are built up out of sub-
elemental “quarks”. Their strong interaction can be described by
means of a SU(3) symmetry. This theory is built up according to
the model of quantum electrodynamics and is called quantum chro-
modynamics since the strong force does not come into play between
electric charges but between so-called color charges of the quark.
Today a fourth fundamental force of nature, weak interaction,
is distinguished from gravitational energy and the electromagnetic
and strong interactions. While gravitational energy and electric and
magnetic phenomena are well-known through everyday experience,
nuclear forces and weak interactions can be observed only by means
of the modern technologies. Thus the weak interaction is responsible
for the β-decay. This force proves to be especially critical for the
discussion of left-right symmetry (“parity”) in nature. Namely, ex-
periments at the end of the ﬁfties of the last century conﬁrm that
for the weak interaction in the case of β-decay of 60Co — in contrast

Introduction
11
to the other three basic forces — neither parity (P) nor reversal of
charge (C = charge) is a symmetry operation; rather, it is only the
combination CPT with the operation T (T = time) for reversal of
time (CPT theorem). After Weyl, already in 1918, had attempted
a uniﬁcation of the electromagnetic forces with gravitation, S. Wein-
berg, A. Salam, S. Glashow et al. succeeded in 1967 at uniting the
electromagnetic and the weak interactions. Both forces derive from
the so-called SU(2) × U(1) symmetry, which nevertheless is present
only in extremely small spatial ranges and is broken already in spac-
ings in the size range of the nuclear radii. While the interactions of
gravitation and electromagnetism are spatially limitless and there-
fore are transmitted by massless particles (graviton, photon), the
weak interaction (as well as the strong one) extends only for short
distances.
Therefore the breaking of the SU(2) × U(1) symmetry
becomes observable when the intermediary particles (except for the
photon) suddenly take on large masses.
So far, the uniting of all four fundamental forces in one symmetry
group has only been carried by assumption in mathematical models.
Thus the SU(5) group, which is the smallest simple group which com-
bines the SU(3) symmetry and SU(2)×U(1) symmetry, proves to be
especially interesting for describing strong, weak and electromagnetic
interaction. This theory predicts a tiny extension in which there are
no fundamental diﬀerences between quarks and leptons or between
the strong, weak and electromagnetic interactions, but instead only
one kind of matter and only one fundamental force.
In cosmic evolution the SU(5) symmetry would have existed a
fraction of the ﬁrst second after the big bang. The rest of the spatio-
temporal evolution of matter consists of breaking of the basic symme-
try and the appearance of partial symmetries with varying particles
and fundamental forces — a cosmic kaleidoscope whose symmetries
depend on spatial orders of magnitude and temporal developmental
phases. Certain rules of conservation then become time-dependent,
so that the decay of the proton is among the most spectacular prog-
noses of this theory and is sought after in expensive experiments.
Finally, the superstring theory strives for a modern theory of the

12
Symmetry and Complexity
Platonic supersymmetry, in which all four fundamental forces are
indistinguishable.
The cosmic steps of symmetry breaking initiate the expansion of
the universe. Thus, they determine the cosmic arrow of time break-
ing the symmetry of time. The cosmic distinction of a time direction
seems to correspond to the second law of thermodynamics demand-
ing increasing entropy for (isolated) dynamical systems until a max-
imal value of thermal equilibrium is reached. On the other hand, all
fundamental laws of classical, relativistic, and quantum physics are
invariant with respect to the reversal of time. But there is no contra-
diction: The thermodynamical arrow of time is a macroscopic feature
of complex ensembles (e.g. gas) with elements (e.g. molecules) which
still obey laws of interaction with invariance of time on the micro-
level (microreversibility). Nevertheless, according to L. Boltzmann,
the second law of thermodynamics indicates a direction of time from
order to chaos, noise and decay of order.
But there are not only collapses of stars to black holes, death of
organisms, and dissolution of energy in the expanding universe, but
also the birth of new stars and life. Since the ancient philosophers
it has been a fundamental problem to understand how order arises
from complex, irregular, and chaotic states of matter. There is no
contradiction to the second law of thermodynamics that is restricted
to isolated systems without any interaction with their environment.
Modern thermodynamics describes the emergence of order by the
mathematical concepts of nonlinear science. New dynamic entities
emerge from phase transitions of complex dynamical systems with
underlying partial diﬀerential equations (PDE). We distinguish two
kinds of phase transition (self-organization) for order states: con-
servative self-organization means the phase transition of reversible
structures in thermal equilibrium. Typical examples are the growth
of snow crystals or the emergence of magnetization in a ferromag-
net by annealing the system to a critical value of temperature.
Conservative self-organization mainly creates order structures with
low energy at low temperatures that are described by a Boltzmann
distribution.

Introduction
13
Dissipative self-organization is the phase transition of irreversible
structures far from thermal equilibrium. Macroscopic patterns arise
from the complex nonlinear cooperation of microscopic elements
when the energetic interaction of the dissipative (“open”) system
with its environment reaches some critical value. The stability of
the emergent structures is guaranteed by dynamical balance of non-
linearity and dissipation. Too much nonlinear interaction or dissi-
pation would destroy the structures. A typical example is the laser
light emerging from a complex system of nonlinearly interacting pho-
tons at a critical value of energy pumping. But even the ﬂame of
an ordinary candle is a simple example of nonlinear dissipative self-
organization. The heat from the ﬂame diﬀuses into the wax, vapor-
izing it at a rate required to provide fuel for the ﬂame. The stability
of the ﬂame is being enabled by the dynamical balance of thermal
diﬀusion and nonlinear energy release.
The phase transitions of dissipative complex systems are mathe-
matically described by nonlinear partial diﬀerential equations. The
emergent structures are their solutions. In a more qualitative way
we may say that old structures become unstable and break down
by changing conditions (“control parameters”). On the microscopic
level, the stable modes of the old states are dominated by unstable
modes. They determine the macroscopic order and pattern of the sys-
tem (“order parameter”). There are diﬀerent ﬁnal patterns of phase
transitions corresponding to diﬀerent attractors. Diﬀerent attractors
may be pictured with a stream, the velocity of which is accelerated
step by step. A stream is a complex system of nonlinearly interact-
ing molecules on the microscopic level, generating ﬂuid patterns on
the macroscopic surface. At a low degree of velocity a homogeneous
state of equilibrium is shown (“ﬁxed point”). At a higher degree the
bifurcation of two or more vortices can be observed corresponding to
periodic and quasi-periodic attractors. With increasing velocity we
get a bifurcation tree of increasing complexity. Finally the complex
order decays into chaos as ﬁnal attractor of the ﬂuid dynamics. These
steps of phase transition mostly involve broken symmetries. Thus,

14
Symmetry and Complexity
generally speaking, the evolution of matter is caused by symmetry
breaking.
In a more mathematical way, the microscopic view of a complex
system is described by the nonlinear partial diﬀerential equation of
a state vector where each component depends on space and time
and where the components may denote, e.g. the velocity components
of a ﬂuid or a temperature ﬁeld. In a linear-stability analysis, we
can distinguish the stable and unstable modes by eigensolutions of
a corresponding eigenvalue equation. At critical values of a control
parameter, the unstable modes of some few components can increase
exponentially to macroscopic scale and dominate all the other sta-
ble ones. Thus, they become order parameters. The adaptation of
the stable modes to the dominating unstable behavior is mathemat-
ically described by the fact that all terms of stable modes can be
expressed by the few terms of unstable ones. Consequently, the mil-
lions of equations determining the single components of a gas, ﬂuid
or light on the microscopic level can be eliminated and replaced by
some few macroscopic equations of order parameters: it is not nec-
essary to know all microscopic states of a complex system, in order
to understand its dynamics.
Chemistry is the bridge between the microworld of atoms and the
mesoworld of living organisms. The fourth chapter analyzes symme-
try and complexity in chemical sciences. Symmetries, dissymmetries
and asymmetries of molecular structures, orbits and crystals can be
explained, using the methods of group theory. Chemical structures
fascinate us with the beauty of their symmetries. Again, molecules
can be considered as emergent entities, generated by the underlying
rules of nonlinear partial diﬀerential equations. In this case, atomic
elements organize themselves into molecules according to the laws of
quantum chemistry. It thus becomes clear how, at a certain stage
of development of matter, new structures of symmetry, dissymmetry
and asymmetry occur which do not yet exist on the level of the ele-
mentary particles. For example, if one views a crystal in the atomic
size realm, only the symmetry of the individual atoms becomes dis-
tinct. On the larger scale, the binding forces appear, breaking atomic

Introduction
15
symmetry but building up the new molecular symmetry of the crystal
lattice. The old problem of left-right symmetry was already investi-
gated in the 19th century for crystals in relation to polarized light,
and led to stereochemistry.
Chirality means molecular symmetry
breaking of left–right with sometimes dramatic consequences for liv-
ing organisms. The question arises if chirality is caused by a deeper
cosmic symmetry breaking of parity violation with the emergence of
weak forces or if it is a new phenomenon on the molecular level. On
the level of nanomolecules, chemistry becomes a nonlinear complex
science. These macromolecules are the building blocks of new materi-
als. Gigantic chemical structures with beautiful symmetries emerge
from the underlying rules of nonlinear interactions. Complex sys-
tems of the nanoworld and self-constructing materials are challenges
of key technologies in the future.
In the ﬁfth chapter we consider symmetry and complexity in life
sciences. In biochemistry the symmetry principles and their viola-
tions are today a widespread research ﬁeld. The determination of a
molecular chain direction is often important, for example, to reach
an unequivocal gene coding for the DNA molecules. It seems to be
characteristic that organisms prefer the middle realm of the transi-
tion from highest symmetry (e.g. crystal) to perfect chaos and ran-
domness (e.g. gases). In the 19th century, L. Pasteur had advanced
the thesis that dissymmetry was typical for life. We ﬁnd this opinion
reﬂected in literature in Thomas Mann’s “The Magic Mountain”:
Hans Castorp, gazing at snow crystals, surmises: “Life shuddered
before this exact correctness.” Indeed the dynamics of life processes
can be described by means of symmetry breakings, as in the case of
cell division.
On the other hand, it is precisely living creatures, as self-
reproducing systems, that display particular temporal developmental
symmetries, which show themselves in the course of generations as
the periodic recurrence of the cyclical course of growth of individu-
als. In today’s biology one also speaks of the “cell cycle” and the
“hypercycle”.

16
Symmetry and Complexity
Morphological symmetries of plants and trees are striking to any-
one. Movement in all directions in the isotropic medium of water is
made possible by the central symmetry of many sea organisms, while
the arrow form of the ﬁsh is expedient for a goal-oriented movement.
Under speciﬁc environmental conditions symmetrical forms oﬀer se-
lective advantages, which have been imitated and further developed
by modern technology (e.g. in building cars, airplanes and rockets).
The bilateral symmetry of higher animals seems to solve the problem
of optimal mobility with simultaneous balance of forces, while this
organizational principle is followed only partially in the anatomy of
the inner organs. Thus, although we have two lungs, we have only
one left-leaning heart. In the macroscopic realm also it comes down
to a layering and breaking of varying symmetries. The human brain
is a remarkable complex organ with bilateral symmetry, but also local
symmetry breaking.
In the framework of complex systems the emergence of life is law-
ful in the sense of dissipative self-organization. Only the conditions
for the emergence of life (for instance on the planet earth) may be
contingent in the universe. In general, biology distinguishes ontoge-
nesis (the growth of organisms) from phylogenesis (the evolution of
species). In any case we have complex dissipative systems the devel-
opment of which can be explained by the evolution of (macroscopic)
order parameters caused by nonlinear (microscopic) interactions of
molecules, cells, etc., in phase transitions far from thermal equilib-
rium. Forms of biological systems (plants, animals, etc.)
are de-
scribed by order parameters. Aristotle’s teleology of goals in nature
is interpreted in terms of attractors in phase transitions.
Phase transitions often involve broken symmetries and the emer-
gence of new entities. Spencer’s idea that the evolution of life is char-
acterized by increasing complexity can be made precise in the context
of dissipative self-organization. It is well known that A.M. Turing
analyzed a mathematical model of organisms represented as com-
plex cellular systems. G. Gerisch, H. Meinhardt et al. described the
growth of an organism (e.g. a slime mould) by evolution equations for
the aggregation of cells. The nonlinear interactions of amoebas cause

Introduction
17
the emergence of a macroscopic organism like a slime mould when
some critical value of cellular nutrition in the environment is reached.
The evolution of the order parameter corresponds to the aggrega-
tion forms during the phase transition of the macroscopic organism.
The mature multicellular body can be interpreted as the “goal” or
(better) “attractor” of organic growth. Multicellular bodies, like ge-
netic systems, nervous systems, immune systems, and ecosystems,
are examples of complex dynamical systems, which are composed of
a network of many interacting elements.
Even the ecological growth of biological populations may be sim-
ulated using the concepts of nonlinear science. Ecological systems
are complex dissipative systems of plants or animals with mutual
nonlinear metabolic interactions with each other and with their en-
vironment. The symbiosis of two populations with their source of
nutrition can be described by three coupled diﬀerential equations
which were already used by E. Lorenz to describe the development
of weather in meteorology. In the 19th century the Italian mathe-
maticians A.J. Lotka und V. Volterra described the development of
two populations in ecological competition.
The nonlinear interac-
tions of the two complex populations are determined by two coupled
diﬀerential equations of prey and predator species. The evolution
of the coupled systems has stationary points of equilibrium.
The
attractors of evolution are periodic oscillations (limit cycles).
Evolution is obviously a process of phase transitions with sym-
metry breaking and the emergence of new molecular structures, or-
ganisms, species, and populations. Atomic elements organize them-
selves into molecules. Out of the nonlinear interactions of chemical
molecules emerge the proteins acting as catalysts and enzymes in
biochemical cycles. Biochemical cycles support the replications of
biomolecules, underlying cellular reproduction. Cellular bodies are
arranged as organs, which join together to form organisms. They go
on to interact nonlinearly with each other to become components of
species and the biosphere. Nervous systems and brains generate new
patterns of behavior by learning and adapting to changing conditions
of environment. Each of these hierarchical levels from molecules to

18
Symmetry and Complexity
the human mind is thought to be characterized by some order param-
eters obeying nonlinear rules. In this sense new locally stable entities
emerge as solutions from nonlinear diﬀerential equations underlying
each level in a dynamical hierarchy of life.
In the sixth chapter we discuss symmetry and complexity in eco-
nomic and social sciences. In the framework of complex systems the
behavior of human populations is, again, explained by the emergence
of order parameters generated by nonlinear interactions of human
beings or human subgroups (states, institutions, etc.). Social or eco-
nomic order is interpreted via attractors of phase transitions involv-
ing broken symmetries. Symmetry is understood as social balance
and economic equilibrium. We distinguish the microlevel of individ-
ual decisions and the macrolevel of dynamical collective processes in a
society. But people are not atoms or molecules determined by well-
known microscopic equations of nonlinear interactions. People are
guided by their individual intentions, feeling, and thinking. In prin-
ciple, we could consider their individual brain dynamics determined
by some nonlinear partial diﬀerential equations. Intentions, feelings,
and thoughts are new states (order parameters) of the brains, emerg-
ing from their nonlinear dynamics. But, until today, we have only
had some very rough ideas of their underlying equations. Even if
we had them, then their complexity would prevent us computing
solutions for predicting individual behavior in the future.
For practical reasons, a probabilistic description of the individual
decision processes is preferred, neglecting individual details of be-
havior. It takes into account the trend forming inﬂuence of social
macrovariables on the decision making of individuals. Examples are
stock and ﬂow variables in economy, social attitudes in sociology,
or political opinions in politics. They are comprehended in socio-
conﬁgurations representing the collective macrostate of the whole
social system at a certain time. Individual decisions and actions are
considered as individual transitions of microstates (e.g. change of a
political opinion before an election) that are described by probabilis-
tic processes. So the individual freedom of decision and action is
not restricted. The dynamics of a social system is modeled by the

Introduction
19
probabilistic transition rates of its social macrovariables. They are
the constitutive elements for setting up a macroscopic equation of so-
ciodynamics. It is a stochastic partial diﬀerential equation (master
equation) describing the time-depending evolution of a probabilistic
distribution function over the socioconﬁgurations of a social system.
An example of application is symmetry and complexity of migra-
tion in a society. We can distinguish typical scenarios of migration
like, for example, stable balance of ethnic groups in a society or iso-
lation in ghettos with dangerous instabilities.
Social symmetry is
a basis for social peace. In the framework of complexity, scenarios
of migration are new macrostates of sociodynamics, emerging from
social phase transitions. They correspond to attractors of nonlinear
sociodynamics such as stable ﬁxed points, oscillations or chaos that
are well-known from other applications of nonlinear dynamics.
Economy opens deep insights into symmetry and complexity of
sociodynamics. From a qualitative point of view, Smith’s model of a
free market was already an example of a dynamical symmetry, emerg-
ing from phase transitions of economic self-organization. A. Smith
underlined that the good or bad intentions of individuals are not
essential. In contrast to a centralized economical system, the bal-
ance of supply and demand is not directed by a leader, but is the
eﬀect of an “invisible hand” (Smith), i.e. nothing but the nonlinear
interaction of consumers and processors.
Later on, the Lausanne
school explicitly used mathematical terms of thermodynamics like,
for example, equilibrium to describe economic balance. The recent
interest of economists in nonlinear dynamics is inspired by the dy-
namics of globalization and the unstable attractors of oscillation and
even chaos.
Symmetry and complexity are not always obvious in the dynamic
processes of the universe, life, and human society. During the last
years, they could only be detected, computed, and visualized by
the increasing power of high-speed computers. Thus, in the seventh
chapter, we consider symmetry and complexity in computer science.
Fractal geometry was a ﬁrst example of computational application.
Mandelbrot’s detection of the Mandelbrot set was a historical mile-

20
Symmetry and Complexity
stone in the history of computational mathematics. Its self-similar
symmetries of complex fractals could only be illustrated in computer
graphics. They reveal a hidden virtual world of mathematical beauty
behind chaos. Phase transitions of nonlinear dynamics can be ani-
mated in visual computational processes. Sometimes their features
were detected in computer experiments before they were analytically
proved from the underlying equations. Computer experiments en-
large mathematical imagination and thought experiments with high
technology. Multimedia and Internet deliver new tools of mathemat-
ical exploration.
The traditional analytical approach of nonlinear
science is sometimes replaced by computer experiments, because it
is easier to ﬁnd features of complex dynamical systems by compu-
tational visualization than by analytical solution of the underlying
nonlinear equations.
According to the principle of computational equivalence, every
nonlinear dynamical system corresponds to an appropriate compu-
tational system. Prominent examples are cellular automata which, in
principle, can simulate all kind of symmetries and complexities which
have been considered in this book. Nevertheless, computer experi-
ments are not mathematical proofs. The standards of mathematical
rigor have not been changed since the days of Euclid and Plato.
Cellular Nonlinear Networks (CNN) make it possible to prove exact
indices of symmetry and complexity in nonlinear science. Further-
more, they are no longer only simulations on standard computers like
cellular automata. In the age of miniaturization, they can be built
as high-speed chips.
Computational systems are not restricted to human technology.
According to the principle of computational equivalence, any nonlin-
ear dynamical system can be understood as a computational system.
In this sense, atomic, molecular or cellular systems are computational
systems with phase transitions as computational processes. They are
coded by the rules of atomic, molecular or cellular interaction. Like
all nonlinear complex systems, they can have chaotic or even ran-
dom dynamics that cannot be forecast in the long run. In short,
complex computational systems may not be computable, although

Introduction
21
we know all the basic laws of their locally interacting elements. Is
the universe in the end nothing more than an expanding complex
quantum computer, generating symmetries and symmetry breaking?
In this case, phase transitions of matter are coding transformations
of quantum information that is reduced to quantum bits as digital
building blocks. Symmetry and complexity are explained by an ul-
timate duality of binary units and their superpositions — the yang
and yin of the quantum universe.
In the last eighth chapter we discuss symmetry and complexity in
arts and philosophy. What means beauty of symmetry and complex-
ity today? It means the beauty of a nonlinear world. The unity of
the experience of nature, art and religion in the myths of early peo-
ples is surely lost. The Antique unity of the mathematical teaching
of harmony, natural philosophy and art has also dissolved since the
Renaissance. In art history (e.g. in Classicism), to be sure, there was
always resonance to the Antique conception of art. But it has the
eﬀect of reciting old texts; it reﬂects a merely partial taste, and it no
longer mirrors the cosmos and its laws.
Art and science in modern times have diﬀerentiated themselves
from each other into distinct media of life experience.
The var-
ied multiplicity of contemporary artistic attempts corresponds en-
tirely to the complexity of the modern life world. In contrast to the
Antique-Medieval life world, whose aesthetic forms depended on the
potentialities of their handwork, we live today in a civilization that is
determined by industry, technology and science, which co-determine
our action, thinking and sensibility.
The “Bauhaus” of the twenties of the last century was an artistic
movement of modernity that tried to develop a new world of form
under the conditions of technology and industry. The community of
handworkers and artisans in the cathedral associations of builders
and artisans of the Middle Ages and the artist engineers of the Re-
naissance led W. Gropius to the thought of uniting art and technol-
ogy again under the conditions of modern industrial society. Archi-
tects, painters, graphic artists, sculptors, form designers, etc. were
to work in coordination and by division of labor, seeking forms that

22
Symmetry and Complexity
would provide practical and functional solutions to people’s needs,
whether it was a matter of furniture, dishes, homes, oﬃce buildings,
factories, streets or leisure facilities. The measure, the “logos,” of
this art is the human being with his needs in the technical-industrial
life world. In the age of globalization mankind is growing together
under new technological, social and economic conditions. Cultural
symmetry is a challenge in a world of cultural diversity. Cultural
asymmetries are dangerous for a peaceful balance in the world.
Symmetry means unity. In science uniﬁed theories are explained
by mathematical symmetries. Are they only theoretical tools used
in order to reduce the diversity of observations and measurements
to some useful schemes of research or do they represent fundamental
structures of reality? This has been a basic question of philosophy
since the Antiquity. Empirical results of modern science conﬁrm that
symmetries are not only mathematical imaginations of our mind.
They dominated the universe long before mankind came into exis-
tence: in the beginning there was a dynamical symmetry expanding
to the complex diversity of broken symmetries.
Phase transitions
involve the emergence of new phenomena on hierarchical levels of
atoms, molecules, life, and mankind.
They have not been deter-
mined from the beginning, but depend on changing conditions that
happen more or less randomly. It is a challenge of nonlinear science
to explore their fascinating symmetry and complexity.

Chapter 1
Symmetry and Complexity in Early
Culture and Philosophy
Regular patterns and symmetries are used in all known cultures.
They recur continually as ornaments on ﬁnery, cult objects, and ev-
eryday objects. Regular forms in crafts and architecture prove to be
more stable, more economical in the use of materials, more distinct,
simpler, easier to reproduce and to hand down to succeeding genera-
tions and — not least — of great aesthetic charm. Since the earliest
times nature itself has manifestly been a model, evincing regularity
in sundry forms and occurrences — from the minerals and plants, to
the anatomy of living beings, to the regularly recurring stellar con-
stellations. The old high cultures, as well as the still extant cultures
of various ethnic groups, e.g. Asia, Africa, North and South America,
use certain symmetrical patterns to give order to nature and their
life-world. Modern natural science and technology were not the ﬁrst
to achieve this.
1.1
Cultural and Cosmic Harmony
Anyone who seeks out the Navajo Indians in the North American
Southwest is astonished by the symmetry forms that govern their
culture [1.1]. What is so striking, is not so much the regular pat-
terns and ornamentations of their artful textiles or ceramics, but
rather the Navajo’s use of symmetries in the ordering of their rituals
and myths, in short, their “Weltbild” (image of the world). In this
context “Weltbild” is to be understood literally, as the representation
23

24
Symmetry and Complexity
of their life-world and mythologies of nature, not as a philosophical
doctrine that has been derived from particular principles. Here we
have in mind the sand paintings of the Navajo, which represent a
“Weltbild” that has a particular ceremonial intention. These paint-
ings are produced from pulverized sandstone in red, yellow or white,
the pigments of cornmeal, plant pollens or ﬂower petals.
Fig. 1 shows the sandpainting of the “rainbow people” who are
meant to be mythological representations of rain and light. In the
centrally-symmetric hub of the cosmos there is the source of life —
water, bordered by four rainbow bands in the four directions of the
heavens or the four directions of the wind. The four sacred plants
— maize, beans, pumpkin and tobacco — grow out of the cen-
ter. Two masculine (round-headed) and two female (angular-headed)
rainbow people are situated behind each of the four rainbow bands.
The enclosing circle represents the goddess of the rainbow who pro-
tects the life-world of the Navajo.
Two ﬂies serve as messengers
or sentinels.
This sandpainting displays an abundance of superimposed sym-
metries. The centrally-symmetric square has all the reﬂection sym-
metries of the diagonals and lateral bisectors. Therefore the center,
with water as the basis of life, produces a statically resting eﬀect,
which is emphasized by its black color. However, the surroundings
of this center display only rotational symmetries. Thus the foursome
groups of rainbow people in the four directions of the sky can be
joined to each other by quarter-turns of the circle around the center.
The feather decorations and the outstretched arms have the eﬀect
of small directional arrows and provide an impediment to reﬂection
symmetry at the diagonals and lateral bisectors of the square, which
would otherwise convey an impression of resting stasis. Therefore
the rainbow people travel around the center in the direction of the
sun. This dynamic impression is further underscored by the rainbow
goddess, whose arc, with its inscribed head and feet, has the eﬀect of
a torque vector. Therefore the message of this world picture is clear:
the element water is at the center, and all natural and life processes
revolve around it.

Symmetry and Complexity in Early Culture and Philosophy
25
Fig. 1.
Symmetric sandpainting of the Navajo Indians [1.2]
In the world of the Navajo, symmetry does not have a separate
aesthetic, religious or technical purpose.
Their central concept is
called “h´ozh´o,” which is often translated as beauty, but cannot be
separated from health, happiness and harmony [1.3]. The life and
culture of the Navajo is based on a unity of experience that is ex-
pressed as “h´ozh´o.” “H´ozh´o” is the intellectual concept of order, the
emotional state of happiness, the moral value of the good, the bio-
logical condition of health and well-being and the aesthetic charm of
balance, harmony and beauty — a projection of wishes, ideas and ex-
periences which is found also in other cultures of America (e.g. Aztec
world map).

26
Symmetry and Complexity
An Asian example is the “Weltbild” of the Jaina from the Indian
sphere of inﬂuence. In addition there are miniatures of the Jaina
K¯alpasutra, which were not documented until the 15th and 16th
century, but go back to very old sources. Represented here is the
Samavasarana that the gods erect for every Jina [1.4]. It is a round
or square space, surrounded by three circular walls with four gates
to the regions of the world. The Jina sits in the center and meditates
or preaches, magically quadrupled on lion thrones under a tree. The
tranquility and composure that these images radiate is achieved for-
mally by means of central symmetry and reﬂection symmetry. This
impression is strengthened by the fourfold point reﬂection of the Jina
at the midpoint of the four corners of the miniature. The inner wall
consists of jewels and is decorated with pinnacles of rubies; the mid-
dle one is made of gold.
In various cultures symmetry characteristics are used cabbalisti-
cally, i.e. with words or letters, in order to gain insights by means of
geometrical arrangements and combinations. A noteworthy exam-
ple of Indian cabbalistics is the Scr¯ıcakra. It consists of a diagram
made of 43 triangles, called Meru (Fig. 2). It is surrounded by an
8-petaled lotus and a 12-petaled lotus, which are again enclosed by
four circles. It is characterized by four T-formed structures at the
sides of the outer square frame. Instructions are indicated for the
two lotus blossoms, and most especially for the potential combina-
tions inherent in the Meru diagram. Proceeding from the outside to
the inside, one distinguishes a 14-pointed star, an outer 10-pointed
star and an inner 10-pointed star. The center is a triangle which
is also the structural principle of the diagram. It is interpreted ei-
ther according to the nature mythology of the three Vedic lights —
the moon, the sun and ﬁre; or linguistically in accordance with the
sounds of various syllables; or anthropologically in accordance with
the trinity of thought, voice and body.
Although no historical explanation can be cited, the Buddhist di-
agrams from India show a strong similarity to Chinese mirrors from
the early Han period. These mirrors with their characteristic T-, L-
and V-formed corners (“TLV mirrors”) are interpreted unequivocally

Symmetry and Complexity in Early Culture and Philosophy
27
Fig. 2.
Symmetric Meru diagram from India [1.5]
as cosmological. The animals of the wind directions (dragon, bird,
tiger and a turtle with snakes twisted around it) are frequently por-
trayed with a swarm of legendary animals and demons. Later these
mirrors are further developed into compass cards, which employ —
along with the four cosmic animals — 12 cyclical animals (in analogy
to the l2-day week), 28 star pictures as constellation ﬁgures, etc.
The use of symmetries in China has a special charm. Very early
on, they were interpreted in the framework of philosophy of nature.
In the “Book of Changes” (the I Ching), from the 8th century B.C.,
four pairs of natural opposites — forces and elements such as heaven-
earth, ﬁre-water, lake-mountain and thunder-wind — were symbol-
ized by eight triagrams arranged according to reﬂection symmetry
(Fig. 3a). They were also represented on coins (Fig. 3b). According
to a later interpretation in the “Great Treatise” (Ta Chuan), these
symmetries derive from the duality of light (—) and dark (– –), yang
and yin. The use of it as an oracle book for divining decisions by

28
Symmetry and Complexity
Fig. 3a.
Chinese symmetries of the I Ching [1.6]
Fig. 3b.
Chinese symmetries on coins [1.6]
combinations of yes (—) and no (– –) approaches contemporary ideas
of information theory, but remains hypothesis.
According to the Chinese conception, symmetry also had to do
with rightful proportional relationships, which in a large central

Symmetry and Complexity in Early Culture and Philosophy
29
apparatus of state and government like the Chinese imperial realm
had to be regulated in detail. There is much similarity here to the
known mathematical documents from Babylon. Particular forms and
proportional relationships are designated for cultic and ritual pur-
poses.
In Egypt pyramids served as monuments to the dead.
In
the Indian Salvasutras the symmetry of the Hindu altars was calcu-
lated with the use of Pythagorean number triads. In the astronomy
of these cultures periodic celestial motions were registered and then
viewed astrologically in connection to the course of lives on earth.
But in Greek mathematics something happened that was com-
pletely new. Symmetries were made the systematic object of mathe-
matical research. It is probable, to be sure, that the early Pythagore-
ans drew their basic mathematical knowledge from Egyptian and
Babylonian sources.
There, however, individual proportions re-
mained related to technical-practical purposes. They were not based
on proofs but, at best, determined by approximate reckoning pro-
cedures. Yet the Pythagoreans made the mathematical concept of
harmony the central theme of their philosophy, which is based on
geometry, arithmetic, music and astronomy. In Plato’s time a gen-
eral mathematical doctrine of proportions was developed, and it re-
mained the mathematical basis of the concept of symmetry until the
beginning of the modern era.
In all known cultures the circle is the symbol of perfection or of
eternal recurrence. While it displays inﬁnitely many symmetries re-
sulting from random rotations and reﬂections at the diameters, the
regular polygons inscribed in it possess a ﬁnite number of symme-
tries. If one connects the vertices of regular polygons with the center,
one derives directional indicators that are useful for geodetic and as-
tronomical orientation. The technical application as wheel was an
important innovation of mankind. Appropriate connections of the
vertices render aesthetically charming star patterns that are also of-
ten used as ritual symbols. In architecture, centrally symmetrical
ediﬁces still play a great role.
Accordingly, the Pythagoreans set themselves the objective of
constructing regular polygons with mathematical precision using the

30
Symmetry and Complexity
Fig. 4.
Euclid’s construction of the 15-angled polygram [1.7]
compass and the ruler.
This, then, is not only a matter of near-
regularities which are found approximately by trial and error and
which could be altogether adequate for technical purposes. It has
come to be a matter of mathematical symmetry, which is provable
and exists independently of technical application and perception, as
an ideal form, as Plato will later say. The Pythagorean doctrine of
the regular polygons has been handed down in Book IV of Euclid’s
“Elements”. It deals with the construction of the 3-, 4-, 5-, 6- and
15-angled polygons (Fig. 4).
The symmetries of regular polygons were clearly of considerable
practical interest. That is documented by the practical geometry of
Medieval Arab mathematicians for craftsmen. The great astronomer
Ptolemy recognized trigonometric signiﬁcance of certain polygons
and applied their construction for chord tables in astronomical cal-
culations. The mathematical question: which regular polygons can
be constructed with the compass and the ruler, was answered fully
by the young C.F. Gauss at the end of the 18th century. He found
that a regular n-sided polygon can be constructed with a compass

Symmetry and Complexity in Early Culture and Philosophy
31
and a ruler if, and only if, the uneven prime factors of n are diﬀering
Fermat prime numbers pk = 22k + 1.
Fermat’s prime numbers are po = 21+1 = 3, p1 = 22+1 = 5, p2 = 24+1 = 17,
p3 = 28 + 1 = 257, p4 = 216 + 1 = 65 537. Since 7 is not one of Fermat’s prime
numbers, in principle a heptagon cannot be constructed with a compass and a
ruler. Since the prime factors of 9 are not diﬀerent, the same conclusion holds for
the regular nonagon. This negative argument was absolutely new compared with
the geometry of Antiquity. New also was Gauss’ positive deduction that it must
be possible in principle to construct the regular 17-sided polygon with a compass
and a ruler. But this conclusion was not reached by means of experimenting.
Instead, the constructibility of the regular 17-sided polygon was predicted on the
basis of the algebraic analysis of the problem. In 1832 F.J. Richelot constructed
the regular 257-sided polygon. J. Hermes worked for ten years on the construction
of the 65 537-sided polygon.
The geometric constructability of regular polygons is now reduced
to the number-theoretical question of whether Fermat pk numbers
can also be prime numbers for certain greater values of k. Such prob-
lems in number theory today depend extensively on the eﬃciency of
modern computers. Therefore the symmetry of regular polygons is
an “evergreen” which has been newly investigated in every phase of
mathematical history — from the elementary constructions with a
compass and ruler in Antiquity, via algebraic number — theoretical
analyzes in modern times to the calculability problems of modern
computers [1.8].
The star polygons, derived from the regular polygons, were in-
vestigated in the High Middle Ages, possibly reﬂecting a special aes-
thetic interest, such as that expressed in the lovely rosette windows
of Medieval cathedrals.
Especially well-known are the pentagram
made from the pentagon as a secret sign of the Pythagoreans, and
the Star of David made from the regular hexagon (Fig. 5). J. Kepler
was also interested in the star polygons [1.9]. Regular polygons and
star polygons can be realized optically by means of the reﬂections
of a kaleidoscope. It is presumed that such an instrument was ﬁrst
described historically in the “Ars magna lucis et umbrae” (1646) of
A. Kirchner, the great Baroque scholar, who tried to ﬁnd the univer-
sal symmetries of the cosmos.

32
Symmetry and Complexity
Fig. 5.
Symmetries of star polygons
Along with the regular symmetry ﬁgures in the plane, the sym-
metrical bodies of space have fascinated human beings from of old. In
pre-Greek times some of these bodies already had cultic and religious
symbolic value because of their regular construction and their crys-
talline structure. The Pythagoreans were acquainted with the regular
tetrahedron composed of four regular triangles, the cube composed
of six regular squares and the dodecahedron composed of twelve reg-
ular pentagons (Fig. 6). A specimen of the dodecahedron made from
steatite is extant from the Etruscan time (500 B.C.). But a com-
plete derivation of all ﬁve possible regular solids was ﬁrst handed
down in the last (XIII) book of Euclid’s “Elements”, which dates
back to the Greek mathematician Theaetetus (415–369 B.C.). There-
fore the octahedron with eight regular triangles and the icosahedron
with twenty regular triangles were probably also ﬁrst constructed
by Theaetetus (Fig. 6). The last theorem of Euclid’s “Elements”:
that these are the only regular solids in Euclidean space, is already
a signiﬁcant mathematical insight.
The proof is this: it is generally required of a regular polyhedron that all its
corners, edges and surfaces be indistinguishable. Further, all surfaces should be
regular polygons. This deﬁnition suﬃces to justify the ﬁve mentioned Platonic

Symmetry and Complexity in Early Culture and Philosophy
33
Fig. 6.
The regular (Platonic) solids of Euclidean space
solids as the only regular bodies. First, a regular polyhedron will not possess any
invaginated corners and edges. Since not all corners and edges could invaginate,
some corners or edges would be distinctive — contrary to the deﬁnition. There-
fore, also, the sum of the polygonal angles that come together at one corner must
be smaller than 2π. Otherwise these polygons would lie in one surface and invagi-
nating edges would go out from this corner. Further, at least three polygons must
come together in one corner. Beyond that, for the sake of regularity all angles
of the polygon must be equal. Therefore they must all be smaller than 2π/3.
In the regular hexagon the polygonal angle amounts to an even 2π/3. Since the
angles for n ≥3 increase in the regular n-angled polygon, only regular 3-, 4- and
5-angled polygons can be chosen as surfaces of regular polyhedra. In the case of
the regular 4-angled polygon, the square, which has only right angles, no more
than three squares can come together in a corner without exceeding the angle
sum of 2π. In the case of the regular pentagon, no more than three pentagons
can meet in a corner. A regular body is by deﬁnition already completely deter-
mined if the number of surfaces abutting in a corner and their number of corners
is known. Therefore there can be, at the most, only a single regular polyhedron
that is bordered by squares and similarly only one bordered by regular pentagons.
By contrast, three, four or ﬁve equilateral triangles can come together in a cor-
ner since it takes six triangles to yield the corner angle sum 2π. The regular
(equilateral) triangle can thus appear as a surface in three diﬀerent polyhedra.

34
Symmetry and Complexity
Altogether, therefore, ﬁve possible regular polyhedra emerge:
number of
surfaces
bordering
meeting at
polyhedron
polygon
corners
edges
surfaces
a corner
tetrahedron
triangle
4
6
4
3
octahedron
triangle
6
12
8
4
icosahedron
triangle
12
30
20
5
cube
square
8
12
6
3
dodecahedron
pentagon
20
30
12
3
Solid stars are examined by analogy to the star ﬁgures in the
plane. To every regular solid a reciprocal one can be assigned which
is enclosed by the planes of the polygon at every corner of the original
polyhedron. For that reason the edges of the reciprocal polyhedron
are centrally perpendicular to those of the original. Fig. 7 shows the
octahedron as a reciprocal polyhedron to the cube and vice versa,
and the reciprocal polyhedron of the regular tetrahedron as an equal
tetrahedron. In nature the combination of the two reciprocal tetra-
hedra appears as the twin crystal. The semi-regular polyhedra do
exhibit forms of solid bodies that were already familiar in the ev-
eryday as crystals, precious stones or building stones. These poly-
gons are called semi-regular since each is bounded by various regular
polygons. Systematic constructions of the solids were indicated by
Kepler in his work “Harmonice mundi.”
In many early cultures proportional relationships are described by
means of numbers. But the Pythagoreans, as far as we know, were
the ﬁrst to want to base characteristics of harmony and symmetry on
speciﬁc numerical relationships. With the Pythagoreans the tetrak-
tys (quaternity) of the numbers 1, 2, 3, 4 occupies a special position
since it “begets the number ten” arithmetically, forms a regular tri-
angle geometrically, is assigned musically to the four strings of the
lyre, namely Hypate, Mese, Paramese, and Nete, and their properties
correspond to the harmonious sounds of the musical fourth (4:3), the

Symmetry and Complexity in Early Culture and Philosophy
35
Fig. 7.
Regular solid (octahedron) and its reciprocal one
ﬁfth (3:2) and the octave (2:1) [1.10]. In the Pythagorean concep-
tion, the harmony of nature is expressed in the unity of arithmetical,
geometrical and musical proportions. Euclid calls such proportions
“logos” (λ
). In this sense the logos is the measure of all being.
Pythagoras demonstrates in his music theory why the numbers 12,
9, 8, 6 are excellent. To that purpose he uses the monochord, an
instrument with only one string, which is divided into twelve equally
large intervals. It is possible, namely, to express in whole numbers
half, two-thirds and three-quarters of the number 12, thus the short-
ened lengths 6, 8, 9 of the whole string 12, which correspond to the
octave, ﬁfth and fourth.
The arithmetic, geometric and harmonic means constitute the
three Pythagorean ratios called  i.e. proportional ratios of
three magnitudes, the middle one being determined by the other
two on the basis of proportion. At a later time further ratios are
added, by means of equivalent formulations of the Pythagorean ratios
and exchange of the component parts. The famous Golden Section,
which Pythagoras is said to have taken over from the Babylonians or
Zarathustra, and which was considered for centuries to be simply the
aesthetic standard, came to our attention earlier in the pentagram
of the Pythagoreans (Fig. 5).
Each of its ﬁve lines divides each
other one according to the Golden Section, i.e. the ratio of the whole
line to the greater part is equal to the ratio of the greater part to

36
Symmetry and Complexity
the smaller part. The proof is an immediate consequence of similar
triangles.
There are many indications that precisely this symbol of the order
of the Pythagoreans made their philosophy fundamentally question-
able. What is under consideration here is the discovery of incommen-
surable straight-line proportions — presumably by the Pythagorean
Hippasus of Metapontum in the 5th century B.C. — which is said
to have set oﬀa shock in Pythagorean circles. Ultimately this dis-
covery called into question the assumption on which the philosophy
of the Pythagoreans was originally based, namely that all propor-
tions of magnitude could be expressed in ratios of whole numbers
— like the harmonies on the monochord [1.11]. In this sense har-
mony and whole-number rationality coincide in the philosophy of
the Pythagoreans. For that reason the discovery of proportions of
magnitude that are not in the ratio of whole numbers also seemed to
them to be an incursion of the irrational, which according to legend
brought the punishment of the gods upon the discoverer.
Fig. 8.
Symmetry of the Golden Spiral [1.12]
Another application of the Golden Section is the Golden Rect-
angle being used for constructing the Golden Spiral (Fig. 8): in a
Golden Rectangle the longer side is divided according to the Golden

Symmetry and Complexity in Early Culture and Philosophy
37
Section. We get a square that is separated from the Golden Rect-
angle and the remaining rectangle is again “golden,” and once more
a square is separated oﬀ, etc.
Two opposite corner points of the
squares form points of intersection of the spiral in the manner of a
clock dial.
In fact, already in 1202 Leonardo of Pisa (“Fibonacci”) gave a
number sequence whose values correspond to the rotation angles of
the spiral and behind which, Leonardo conjectured, must lie a law of
biological proliferation. He imagined that rabbits live as long as they
like and that every pair produces a new pair every month, which in
a month produces its ﬁrst pair. The experiment begins, at the start
of the ﬁrst month, with a new-born pair. In the second month the
same pair exists. In the third month there are 2 pairs, in the fourth 3
pairs, in the ﬁfth 5 pairs, etc. If one designates the number of rabbit
pairs in the n-th month as fn, one obtains the following table:
n
fn
fn+1/fn
0
0
∞
1
1
1
2
1
2
3
2
1, 5
4
3
1, 6667
5
5
1, 6
6
8
1, 625
7
13
1, 6154
8
21
1, 6190
9
34
1, 6176
10
55
1, 6182
Later Kepler expressed the general law of this sequence, namely,
f0 = 0, f1 = 1, fn + fn+1 = fn+2. Kepler also noted that the quo-
tients fn+1/fn approach the Golden Section as n increases. How-
ever, this was ﬁrst actually proven in the 18th century by R. Simon.
J.W. von Goethe was yet to speak of the spiral eﬀect in nature.
Eighteenth-century biologists such as C. Bonnet (1754) were to try
to identify the developmental law of the Fibonacci sequence in the
coiling arrangement of blossoms and leaves (phyllotaxis) or in snail
shells, leading up to the preoccupation of contemporary mathemati-

38
Symmetry and Complexity
cians with the computer-assisted computability of this (recursive)
number sequence. This modern application reﬂects the age-old in-
terest in a universal law of harmony and development stemming from
the Pythagorean time and continuing into the present.
Retroactively it is remarkable that the Antique doctrine of pro-
portions provided not only the bases for laws of harmony of nature
and aesthetics, but also for jurisprudence in human communities.
Aristotle’s Nicomachean Ethics states: “This, therefore, is what is
just: the proportional.
And the unjust is the oﬀence against the
proportional. But the proportional is a middle way [1.13].”
On the basis of the mathematical doctrine of proportions Aristotle
made a thoroughly modern juridical distinction between distributive
justice in public law and compensatory justice in civil law. When it
is a matter of distribution of a common good — honors, oﬃces, sums
of money, etc. (today one would add the distribution of the tax bur-
den) — the “commensurability” of the distributions and awards is
determined by the proportions of the achievements, merits, diligence,
etc., of the individual person. However, if it is a matter of compen-
sating for damages in the contractual relations between people, “the
law regards only diﬀerences in the degree of damages; it views the
partners as equal.” Therefore Person a and Person b count as equal,
i.e. a = b. The injustice that b exercises against a, e.g., by taking
away good c, damages the equality, i.e. a −c < b + c. The compen-
sation consists of the return of c, thus (a −c) + c = (b + c) −c. But
that is nothing other than an arithmetical mediation that is generally
provided by civil law.
On the basis of the doctrine of proportion, therefore, there arises
a unitary image of a proportionally well-ordered world of numbers,
geometric magnitudes, musical harmonies and law. A question arises
as to whether these mathematical harmonies ﬁt the reality of nature.
To answer that, we begin with a look at Antique-Medieval astronomy,
which historically was the ﬁrst discipline in the physical sciences
to be mathematical and which constituted the fourth mathematical
discipline of the Pythagorean quadrivium — along with arithmetic,
geometry and music (the doctrine of harmony).

Symmetry and Complexity in Early Culture and Philosophy
39
In all early cultures we ﬁnd astronomical knowledge that con-
tributes to temporal and spatial orientation but is also meant to sup-
port astrological and religious interpretations of the world. Technical
methods are developed for describing certain celestial phenomena in
relation to the position of the observer. Among these are the rising
and setting of the sun, moon and stars. Beginning ca. two millenia
B.C., for example, Egyptian star calendars documented the heliacal
rise of Sirius. The periodic celestial cycles helped determine the cal-
endar and were brought into synchrony with annual occurrences in
nature as, for example, the ﬂooding of the Nile which insures the
fruitfulness of the ﬁelds and thereby the basis for human life. The
Oriental cult of resurrection and rebirth has its origin in the rising
and setting of the stars and the fruitful periods on the earth that are
linked to them, as well as the star mythology of the love and death of
the gods Osiris (Orion) and Isis (Sirius). The Babylonian moon ta-
bles have an admirable exactitude, allowing laws of periodic courses
to be inferred from them [1.14]. Along with determining the time by
calendars, the Babylonian rulers were interested in horoscopes that
were meant to determine their souls’ passage through life in the signs
of the zodiac. This is not to be mistaken for the privatistic curios-
ity and horoscope credulity found among our contemporaries. The
horoscope of the ruler was a matter of political interest: the stabil-
ity and crises of the ruler, who represented the state, needed to be
predictable and calculable. In the astronomy of the Maya, as well,
exact observational tables were of primary interest, but so were the
prophecies drawn from solar eclipses.
In Chinese astronomy, spherical models of the celestial globes
were developed very early. They were copied in mechanical models
before the time of the Occidental celestial globes. Here too, astron-
omy was a matter of the national political interest, evidenced by the
artful sundials and celestial globes in the Imperial Palace in Beijing
or elsewhere. It was not priests or independent scientists, but high
government oﬃcials in the imperial bureaucracy, who for centuries
registered all celestial movements with painful exactitude [1.15]. The
starry sky as image of the hierarchy of the imperial realm: in the

40
Symmetry and Complexity
center the pole of the sky like the emperor around whom everything
turns. However, the Chinese possessed no mathematical theory like
Euclid’s geometry, with its proofs, to give them a geometrical model
for the exact explanation and derivation of their observations. It was
Greek astronomy that ﬁrst succeeded at that.
There the movements of the planets were reconstructed in the
movements of spheres, which were tuned to each other in art-
ful proportions.
The celestial harmony was the central theme of
Pythagorean astronomy. It taught that each planet in its circular
motion generates musical notes and that these sounds express a har-
mony of the spheres. Later the seven recognized planets were as-
signed to the seven strings of the lyre: “The heavens are harmony
and number.”
By the time of Plato the conviction prevailed that the cosmos
is ordered in a centrally symmetrical manner, with the earth as a
sphere in the center.
Around it the whole sky turns to the right
around the celestial axis, which goes through the earth. Sun, moon
and planets turn to the left on spheres that have diﬀerent distances
from the earth in the sequence of moon, Mercury, Venus, sun, Mars,
Jupiter, Saturn. The most external shell carries the sphere of the
ﬁxed stars. According to the Platonic-Pythagorean conception, the
rotational periods are related to each other by whole numbers. There
is a common multiple of all rotational times, at the end of which
all the planets are exactly in the same place again.
The motion
of each one produces a sound so that the tones of the movements
of the spheres jointly form a harmony of the spheres in the sense
of a well-ordered musical scale. Geometry, arithmetic and aesthetic
symmetries of the cosmos ring through the universe in a harmonious
music of the spheres.
Soon this emphatically symmetrical model of the cosmos was
called into question by exact observations. A diﬃcult problem was
presented by the irregular planetary orbits, especially their retro-
grade movements.
The irregularities in the sky were disquieting,
especially for philosophers in the Pythagorean tradition, who were
accustomed to comprehending the heavens — in contrast to the earth

Symmetry and Complexity in Early Culture and Philosophy
41
— as the realm of eternal symmetry and harmony. At this point
the mathematician Eudoxus of Knidos suggested an ingenious so-
lution. Namely, according to Eudemus, Plato posed this question
to Eudoxus: By means of what regular, ordered circular movements
could the phenomena of the planets be “saved,” i.e. kinematically ex-
plained [1.16]? This report formulated a new astronomical research
program with the goal of a kinematic explanation for empirical data
in a centrally-symmetrical model of the spheres that is presupposed
a priori.
Eudoxos suggested a planetary model with its spheres still posi-
tioned centrally around the earth. The retrograde movement of a
planet is generated on the surface of an outer sphere by a combina-
tion with moving inner spheres of diﬀerently inclined axes. Because
of the constant spacing of the spheres, the changing brightness of the
planets could not be explained by Eudoxos. A greater exactitude in
the reconstruction of observed curves was achieved when Apollonius
of Perga (ca. 210 B.C.) recommended that the common center of the
spheres be given up. But the spherical form of planetary movement
and the equal speed of the spheres were to be retained. According
to this proposal, the planets rotate uniformly on spheres (epicycles),
whose imagined centers move uniformly on great circles (deferents)
around the centerpoint (earth). By appropriately proportioning the
speed and diameter of the two circular motions and by varying their
directions of motion, it was possible to produce an unanticipated
potential for curves, and these found partial application in astron-
omy from Ptolemy to Kepler also. The constant spherical symme-
try of the models was therefore preserved, even if they no longer
had a common center, but were distributed among various circle
centers.
The following examples from the epicycle-deferent technique show
what a multiplicity of apparent forms of motion can be created by
appropriately combining uniform circular motions [1.17]. This makes
the Platonic philosophy more comprehensible in its view that behind
the changes in “phenomena” there are the eternal and unchangeable
forms. In Fig. 9 an elliptical orbit is produced by combining a defer-

42
Symmetry and Complexity
ent motion and an epicycle motion. Fig. 10 shows a closed cycloid.
In this way, changing distances between planets and the earth can
also be represented.
In principle, even angular ﬁgures can be produced.
In Fig. 11, when the
epicycle diameter approaches the deferent diameter, an exact straight line results.
Copernicus mentioned this construction in his book “De Revolutionibus.” Even
regular triangles and rectangles (Figs. 12 and 13) can be produced by means
of appropriate combinations of an epicycle motion and a deferent motion, if one
changes the speed of the east-west motion of a planet that is moving on an epicycle
with a west-east motion.
If one lets the celestial body circle on a second epicycle whose midpoint moves
on the ﬁrst epicycle, one can produce a multiplicity of elliptical orbits, reﬂection-
symmetry curves, periodic curves (Fig. 14), and also nonperiodic and asymmetri-
cal curves (Fig. 15). From a purely mathematical and kinetic standpoint, Plato’s
problem of “saving the phenomena” is completely solved. There is no curve in
observational astronomy that cannot be produced with almost any desired ex-
actitude whatever, as a result of a combined epicycle-deferent motion. Indeed,
looking at asymmetrical curves such as those in Fig. 15 leads one to add that even
the trajectories of elementary particles that are captured on the photographic
plates of contemporary high-energy physicists can be extensively reconstructed
by the epicycle-deferent technique. In principle, therefore, Plato’s paradigm of
symmetry in the sense of uniform circular motion (modiﬁed by Apollonius and
Fig. 9.
Elliptical orbit

Symmetry and Complexity in Early Culture and Philosophy
43
Fig. 10.
Closed cycloid
Fig. 11.
Straight line produced by epicycle-deferent technique
Ptolemy) could inﬂuence the sciences right up until today. In any case it can-
not be disproved by phenomenological description of curved paths. In particular,
from this standpoint not only the reversal of the earth and the sun in the so-called
Copernican revolution, but also Kepler’s change from circular to elliptical orbits,

44
Symmetry and Complexity
Fig. 12.
Regular triangle produced by epicycle-deferent technique
Fig. 13.
Rectangle produced by epicycle-deferent technique
seem secondary, since both initiatives can be traced back to the combination of
circular motions in accordance with the epicycle-deferent technique.
The decisive question in this case is, instead, which motions the
planets “really” carry out, whether they are, in fact, combined,

Symmetry and Complexity in Early Culture and Philosophy
45
Fig. 14.
Periodic curve produced by epicycle-deferent technique
Fig. 15.
Nonperiodic and asymmetrical curve produced by epicycle-deferent
technique
uniform and unforced circular motions that seem to us on earth to
be elliptical paths, or whether they are in fact compelled to fol-
low elliptical paths by forces.
This determination, however, can-
not be made geometrically and kinematically, but only dynamically,

46
Symmetry and Complexity
i.e. by means of a corresponding theory of forces, hence, by means
of physics. But Antique-Medieval astronomy as the fourth discipline
of the Pythagorean quadrivium is a purely geometric-kinematic dis-
cipline. The reasons that led to the abandonment of the Platonic
symmetry program could, therefore, be understood only in connec-
tion with the Antique-Medieval philosophy of nature and the begin-
ning of modern physics.
Plato did not only propose a research plan for the macrocosm ac-
cording to which the apparently irregular celestial phenomena were
to be traced to unchangeable mathematical regularities and sym-
metries. In his dialogue “Timaeus,” he introduced the ﬁrst synthe-
sis of atomism and mathematical symmetry. The changes, mixings
and separations on earth were traced to unchangeable mathemati-
cal regularities and symmetries of an atomic microcosm. The Dem-
ocritean atoms were mathematically too unspeciﬁc and structureless
for that. Moreover, in Empedocles’ four elements, namely ﬁre, air,
water, earth, a classiﬁcation was at hand that was immediately ac-
cessible to experience.
All the regular solids of Euclidean geometry (Fig. 6) were joined
to the natural elements then on the basis of external features that
seem arbitrary to us today: Fire was composed of the smallest and
most pointed bodies, the tetrahedra; earth was composed of the most
stable ones, the cubes. Air, composed of octahedra, and water of
icosahedra, were assumed to be like two intermediate proportionals.
The dodecahedron was used for the celestial sphere because of its sim-
ilarity to the cube; therefore in the narrow sense it did not belong in
Plato’s earth physics. In fact the dodecahedron, with its character-
istic of the Golden Section, met the highest Greek requirements for
symmetry and thus may have seemed especially appropriate as the
celestial symbol.
The regular bodies can be cut open along appropriate edges, and
their surface elements can be unfolded as nets (Fig. 16). One can
easily see how two tetrahedra with a common edge can be formed
from the net of the octahedron, and two octahedra and a tetrahedron
or ﬁve tetrahedra can be formed from the net of the icosahedron.

Symmetry and Complexity in Early Culture and Philosophy
47
Fig. 16.
Symmetries of Platonic physics
From the point of view of philosophy of nature one could speak here of
a kind of chemical analysis and synthesis [1.18]. If one characterizes
the Platonic elements as F (ﬁre), A (air), W (water), E (earth), then
the obvious “chemical formulas” are 1 A = 2 F and 1 W = 2 A +
1 F = 5 F.
Plato consciously avoided the Democritean designation “atom”
for his elements, since they can, after all, be decomposed into
separate plane ﬁgures. Thus tetrahedra, octahedra and icosahedra
consist of equilateral triangles with sides 1, 2 and √3, while the regu-
lar rectangles of the cubes, when they are bisected, yield right-angled
triangles with side lengths 1, 1 and √2 (Fig. 16). A consequence is

48
Symmetry and Complexity
that “ﬂuida” like water, air and ﬁre can combine with each other
whereas a solid made of earth building blocks, because of its diﬀer-
ent triangles, can only be converted into another solid.
However, the signiﬁcance of this initiative was essentially unap-
preciated until modern times, if one disregards sporadic mention by
a few Neoplatonists.
With the rise of crystallography and stereo-
chemistry, the Platonic core idea became a successful mathematical
research program for explaining crystals and atomic and molecular
compounds by means of a concept of symmetry (an expanded one)
and for making new phenomena predictable and subject to empirical
re-examination. A high point up to now in this development is mod-
ern elementary particle physics. Heisenberg made this observation
about it: “. . . The elementary particles have the form Plato ascribed
to them because it is the mathematically most beautiful and simplest
form. Therefore the ultimate foot of phenomena is not matter, but
instead mathematical law, symmetry, mathematical form.”
In Antiquity and the Middle Ages Plato’s mathematical atom-
ism gained little reception. The basic problem, for his successors, in
his geometric theory of matter was already evident in the dialogue
Timaeus. How are the functions of living organisms to be explained?
The suggestion that certain corporeal forms are as they are in order
to fulﬁll certain physiological purposes (e.g. the tunnel shape of the
gullet for assimilation of food) cannot, in any case, be derived from
the theory of regular solids. In addition, the idea of explaining the
changing and pulsating processes of life on the basis of the “rigid”
and “dead” ﬁgures of geometry, must have seemed thoroughly unnat-
ural, speculative and far-fetched to the contemporaries of that time.
Contemporaries of our time still have diﬃculties understanding the
detour that today’s scientiﬁc explanations take through complicated
and abstract mathematical theories.
1.2
Cultural and Cosmic Diversity
In our everyday-world we experience complexity and diversity,
change and movement, chaos and random, and no eternal symme-

Symmetry and Complexity in Early Culture and Philosophy
49
tries. Platonic astronomers tried to reduce the irregular and complex
planetary orbits as they were observed to regular and simple move-
ments of spheres.
For our everyday-world, this trial seems to be
hopeless. Since the presocratic philosophers it has been a fundamen-
tal problem of natural philosophy to discover how order arises from
complex, irregular and chaotic states of matter. What the presocratic
philosophers did was to take the complexity of natural phenomena
as it is experienced back to “ﬁrst origins”
, “principles” or
a certain order. Let us look at some examples. Thales of Miletus
(625–545 B.C.), who is said to have proven the ﬁrst geometric the-
orems, is also the ﬁrst philosopher of nature to believe that only
material primary causes could be the original causes of all things.
Thales assumes water, or the wet, as the ﬁrst cause. His argument
points to the observation that nourishment and the seeds of all beings
are wet and the natural substratum for wet things is water.
Anaximander (610–545 B.C.), who is characterized as Thales’ stu-
dent and companion, extends Thales’ philosophy of nature.
Why
should water be the ﬁrst cause of all this? It is only one of many
forms of matter that exist in uninterrupted tensions and opposites:
heat versus cold and wetness versus dryness . . . Therefore Anaximan-
der assumes that the “origin and ﬁrst cause of the existing things” is a
“boundlessly indeterminable” original matter (–
) out of which
the opposed forms of matter have arisen. Accordingly we have to
imagine the “boundlessly indeterminable” as the primordial state in
which matter was boundless, without opposites, and, therefore, ev-
erywhere of the same character. Consequently, it was an initial state
of complete homogeneity and symmetry. The condition of symmetry
is followed by symmetry breaking, from which the world arises with
all its observable opposites and tensions:
The everlasting generative matter split apart in the creation of our world and
out of it a sphere of ﬂame grew around the air surrounding the earth like the bark
around a tree; then, when it tore apart and bunched up into deﬁnite circles, the
sun, moon and stars took its place [1.19].
The ensuing states of matter that Anaximander described in his
cosmogeny were therefore by no means chaotic; instead they were

50
Symmetry and Complexity
determined by new partial orders. The fascination with Anaximan-
der increases when one reads his early ideas of biological evolution.
He assumes that the ﬁrst human beings were born from sea animals
whose young are quickly able to sustain themselves, as he had ob-
served in the case of certain kinds of sharks. A century later searches
were already being made for fossils of sea animals as evidence of the
rise of humans from the sea. The third famous Milesian philosopher
of nature is Anaximenes (†525 B.C.), who is thought to have been a
companion of Anaximander. He regards change as the eﬀect of the
external forces of condensation and rarefaction. In his view, every
form of matter can serve as basic. He chooses air
:
And rareﬁed, it became ﬁre; condensed, wind; then cloud; further, by still
stronger condensation, water; then earth; then stones; but everything else origi-
nated by these. He, too, assumed eternal motion as the origin of transformation.
What contracts and condenses matter, he said is (the) cold; by contrast, what
thins and slackens is (the) warm [1.20].
Thus Anaximenes assumes external forces by which the various
states of matter were produced out of a common original matter and
were transformed into each other.
Heraclitus of Ephesus (ca. 500 B.C.), “the dark one”, as he was
often called, is of towering signiﬁcance for our theme. His language
is indeed esoteric, more phrophetic than soberly scientiﬁc, and full
of penetrating metaphors. He took over from Anaximander the doc-
trine of struggle and the tension of opposites in nature. The original
matter, the source of everything, is itself change and therefore is
identiﬁed with ﬁre:
The ray of lightning (i.e. ﬁre) guides the All. This world order which is the
same for all was created neither by one of the gods nor by one of the humans, but it
was always, and is, and will be eternally living ﬁre, glimmering and extinguishing
according to measures [1.21].
Heraclitus elaborated further on how all states of matter can be
understood as distinguishable forms of the original matter, ﬁre. In
our time the physicist Heisenberg declared:
At this point we can interpose that in a certain way modern physics comes
extraordinarily close to the teaching of Heraclitus. If one substitutes the word

Symmetry and Complexity in Early Culture and Philosophy
51
“ﬁre”, one can view Heraclitus’ pronouncements almost word for word as an
expression of our modern conception. Energy is indeed the material of which all
the elementary particles, all atoms and therefore all things in general are made,
and at the same time energy is also that which is moved . . . Energy can be
transformed into movement, heat, light and tension. Energy can be regarded as
the cause of all changes in the world [1.22].
To be sure, the material world consists of opposite conditions and
tendencies which, nevertheless, are held in unity by hidden harmony:
“What is opposite strives toward union, out of the diverse there
arises the most beautiful harmony
, and the struggle makes
everything come about in this way.”
[1.23] The hidden harmony
of opposites is thus Heraclitus’ cosmic law, which he called “logos”
(
).
What happens when the struggle of opposites comes to an end?
According to Heraclitus, then the world comes to a ﬁnal state of ab-
solute equilibrium. Parmenides of Elea (ca. 500 B.C.) described this
state of matter, in which there are no longer changes and motions
in (empty) spaces.
Matter is then distributed everywhere equally
(homogeneously) and without any preferred direction for possible
motion (isotropically). It is noteworthy that inﬁnity is thought to
be imperfection and therefore a ﬁnite distribution of matter is as-
sumed. In this way Parmenides arrived at the image of a world that
represents a solid, ﬁnite, uniform material sphere without time, mo-
tion or change.
The Eleatic philosophy of unchanging being was,
indeed, intended as a critique of the Heraclitean philosophy of con-
stant change, which is put aside as mere illusion of the senses. And
the later historical impact of the Eleatic philosophy in Plato appears
in his critique of the deceptive changes that take place in sensory per-
ception in contrast to the true world of unchangeable being of the
ideas. But from the point of view of philosophy of nature, the world
Parmenides described was not necessarily opposite to the teaching
of Heraclitus; in his cosmogeny it can be understood entirely as a
singular end state of the highest symmetry.
After water, air and ﬁre were designated as original elements, it
was easy to conceive of them as raw materials of the world. Empe-

52
Symmetry and Complexity
docles (492–430 B.C.) took that step and added earth as the fourth
element to ﬁre, water and air. These elements are free to mix and
bind in varying proportions, and to dissolve and separate. What,
now, according to Empedocles, were the enduring principles behind
the constant changes and movements of nature? First there were
the four elements, which he thought arose from nature and chance
(
), not from any conscious intention. Changes were caused by
reciprocal eﬀects among these elements, that is, mixing and sepa-
ration: “I shall proclaim to you another thing: there is no birth
with any of the material things, neither there is an ending in ruinous
death. There is only one thing: mixture and exchange of what is
mixed.” [1.24] Two basic energies were responsible for these recip-
rocal eﬀects among the elements; he called them “love” (
) for
attraction and “hatred” (
) for repulsion.
There is an anal-
ogy in the yin-yang dualism of Chinese philosophy.
Empedocles
taught a constant process of transformation, i.e., combination and
separation of the elements, in which the elements were preserved.
He did not imagine these transformation processes to be at all me-
chanical (as the later atomists did), but rather physiological, in that
he carried over processes of metabolism in organisms to inanimate
nature.
In his medical theories, equilibrium is understood to be a gen-
uinely proportional relationship.
Thus, health means a particular
balance between the opposite components and illness arises as so on
as one of them gets the upper hand. If we think of modern bacteri-
ology with its understanding of the antibodies in the human body,
then this view of Empedocles proves to be surprisingly apt.
Anaxagoras (499–426 B.C.) advocated what was in many regards
a reﬁnement of his predecessors’ teaching. Like Empedocles he devel-
oped a mixing theory of matter. But he replaced Empedocles’ four
elements with an unlimited number of substances that were
composed of seed particles (
) or equal-sized particles
.
They were unlimited in their number and
smallness, i.e. matter was assumed to be inﬁnitely divisible.
The
idea of a granulated continuum comes forceably to mind. Anaxago-

Symmetry and Complexity in Early Culture and Philosophy
53
ras also tried to explain mixtures of colors in this way, when he said
that snow is, to a certain degree, black, although the whiteness pre-
dominates. Everything was contained in each thing, and there were
only predominances in the mixing relationships.
More distinctly than some of his predecessors, Anaxagoras tried
in his philosophy of nature to give physical explanations for the celes-
tial appearances and motions that were described only kinematically
in the mathematical astronomy of the Greeks. So in his cosmology
he proceeded from a singular initial state: a homogeneous mixture
of matter. An immaterial original power, which Anaxagoras called
“spirit” (
), set this mixture into a whirling motion which brought
about a separation of the various things depending on the speed of
each of them. Earth clumped together in the middle of the vortex,
while heavier pieces of stone were hurled outward and formed the
stars. Their light was explained by the glow of their masses, which
was attributed to their fast speed. Anaxagoras’ vortex theory ap-
pears again in modern times with R. Descartes, and then in more
reﬁned form in the Kant–Laplace theory of the mechanical origin of
the planetary system.
In modern natural sciences atomism has proved to be an ex-
tremely successful research program. In the history of philosophy
the atomic theory of Democritus is often presented as a consequence
of Heraclitus’ philosophy of change and Parmenides’ principle of un-
changing being. The Democritean distinction between the “full” and
the “empty,” the smallest indestructible atoms
and empty
space, corresponded to Parmenides’ distinction between “being” and
“not-being.” Heraclitean complexity and change was derived from
distinguishable reconﬁgurations of the atoms. Empty space was sup-
posed to be homogeneous and isotropic.
Atoms diﬀer in their form (
), their position (h
), and
their diverse conﬁgurations
in material combinations. The
conﬁguration of the atoms for the purpose of designation is com-
pared with the sequence of letters in words, which has led to the
presumption that atomistic ideas were developed only in cultures
with phonetic alphabets.
In fact, in China, where there was no

54
Symmetry and Complexity
phonetic alphabet but instead ideographic characters, the particle
idea was unknown and a ﬁeld-and-wave conception of the natural
processes prevailed. The Democritean atoms move according to ne-
cessity
in a constant whirl (* <
or * < ). Here, by con-
trast with later Aristotelian notions, motion means only change of
location in empty space. All phenomena, all becoming and perish-
ing, result from combination (
) and separation (
).
Aggregate states of matter, such as gaseous, liquid or solid, are
explained by the atoms’ diﬀering densities and potentialities for
motion. In view of today’s crystallography, the Democritean idea
that even atoms in solid bodies carry out oscillations in place is
noteworthy.
Plato developed an internally consistent mathematical model by
which various aggregate states and reciprocal eﬀects of substances
could be explained if one accepted his — albeit more or less arbi-
trary — initial conditions for interpretation of the elements. Nev-
ertheless, as mentioned before in Chapter 1.1, even contemporaries
of our time have diﬃculties to believe in mathematical symmetries
behind the complexity and diversity of the apparent world. This is
where Aristotelean physics begins [1.25].
Aristotle formulated his
concept of a balance or “equilibrium” in nature chieﬂy on the basis
of the ways in which living organisms such as plants and animals
function. The process and courses of life are known from everyday
experience. What is more obvious than to compare and explain the
rest of the world, which is unknown and strange, with the familiar?
According to Aristotle, the task of science is to explain the princi-
ples and functions of nature’s complexity and changes [1.26]. This
was a criticism of those philosophers of nature who identiﬁed their
principles with individual substances. The individual plant or the
individual animal was not simply the sum of its material building
blocks. Aristotle called the general, which made the individual be-
ing what it was, form ( Í*@H). What was shaped by form was called
matter (à80). Yet form and matter did not exist in themselves, but
were instead principles of nature derived by abstraction. Therefore,
matter was also characterized as the potential (*b<":4H) for being

Symmetry and Complexity in Early Culture and Philosophy
55
formed. Not until matter is formed does reality (¦<XD(g4") come into
being [1.27].
The real living creatures that we observe undergo constant
change.
Here Heraclitus was right and Parmenides, for whom
changes were illusory, was wrong.
Changes are real.
Yet accord-
ing to Aristotle, Heraclitus was wrong in identifying changes with a
particular substance (ﬁre). Aristotle explained those changes by a
third principle along with matter and form, namely, the lack of form,
which was to be nulliﬁed by an adequate change. The young plant
and the child are small, weak and immature. They grow because in
accordance with their natural tendencies (form), they were meant to
become big, strong and mature. Therefore it was determined that
movement in general was change, transition from possibility to real-
ity, “actualization of potential” (as people in the Middle Ages were
to say). The task of physics was to investigate movement in nature
in this comprehensive sense. Nature
— in contrast to a work
of art produced by man or a technical tool — was understood to be
everything that carried the principle of movement within itself. If
the Aristotelian designations make us think, ﬁrst of all, of the life
processes of plants, animals and people as they present themselves
to us in everyday experience, these designations seem to us to be
thoroughly plausible and apposite.
Nature is not a stone quarry
from which one can break loose individual pieces at will.
Nature
itself was imagined to be a rational organism whose movements were
both necessary and purposeful. Aristotle distinguished three sorts
of movement, namely quantitative change by increase or decrease in
magnitude, qualitative change by alteration of characteristics and
spatial change by change of location. Aristotle designated four as-
pects of causality as the causes of changes. Why does a plant grow?
It grows (1) because its material components make growth possible
(causa materialis), (2) because its physiological functions determine
growth (causa formalis), (3) because external circumstances (nutri-
ents in the earth, water, sunlight, etc.) impel growth (causa eﬃciens),
(4) because, in accordance with its ﬁnal purpose, it is meant to ripen
out into the perfect form (causa ﬁnalis) [1.28].

56
Symmetry and Complexity
Aristotle then employed these same principles, which are obvi-
ously derived from the life cycles of plants, animals and humans, to
explain matter in the narrower sense, that is, what was later called
the inorganic part of nature.
Here too Aristotle proceeded from
immediate experience. What we meet with is not so and so many
elements as isolated building blocks of nature. Instead we experience
characteristics such as warmth and cold, wetness and dryness. Com-
binations of these yield the following pairs of characteristics which
determine the elements: warm-dry (ﬁre), warm-wet (air), cold-wet
(water), cold-dry (earth). Warm-cold and wet-dry are excluded as si-
multaneous conditions. Therefore, there are only four elements. This
derivation was later criticized as arbitrary, but it shows the Aris-
totelian method, namely to proceed not from abstract mathematical
models, but instead directly from experience. Fire, air, water and
earth are contained more or less, more intensively or less intensively,
in real bodies and they are involved in constant transformation. Ac-
cording to Aristotle, eliminating the coldness of water by means of
warmth results in air, and eliminating the wetness of the air results
in ﬁre. The changes of nature are interpreted as maturational and
transformational processes.
How could such a predominantly organic philosophy of nature de-
liver physical explanations for mathematical natural science, insofar
as it was extant at that time? There were only two elementary spa-
tial motions — those that proceeded in a straight line and those that
proceeded in a circle. Therefore there had to be certain elements
to which these elementary motions come naturally. The motions of
the other bodies were determined by these elements and their natu-
ral motions, depending on which motion predominated with each of
them. The most perfect motion was circular motion. It alone could
go on without end, which was why it had to be assigned to the im-
perishable element. This was the ﬁfth element (quintessence), which
made up the unchangeable celestial spheres and the stars. The con-
tinual changes within the earthly (sublunar) world were to be set oﬀ
from the unchangeable regularity of the celestial (superlunar) world.
These transformational processes were associated with the four ele-

Symmetry and Complexity in Early Culture and Philosophy
57
ments to which straight-line motion is peculiar, and speciﬁcally the
straight-line motion toward the center of the world, toward which
the heavy elements earth and water strive as their natural locus, and
the straight-line motion toward the periphery of the lunar sphere,
toward which the light elements air and ﬁre strive upwards as their
natural locus.
Among the natural motions [1.29] there was also free fall. But
Aristotle did not start out from isolated motions in idealized exper-
imental situations as G. Galilei did. A falling body is observed in
its complex environment without abstraction of frictional (“dissipat-
ing”) forces. During its free fall a body is sinking in the medium
of air like a stone in water. Thus, Aristotle imagines free fall as a
hydrodynamical process and not as an acceleration in vacuum. He
assumes a constant speed of falling υ, which was directly propor-
tional to the weight p of the body and inversely to the density d of
the medium (e.g. air), thus in modern notation υ ∼p/d. This equa-
tion of proportionality at the same time provided Aristotle with an
argument against the void of atomists. In a vacuum with the density
d = 0, all bodies would have to fall inﬁnitely fast, which obviously
did not happen.
A typical example for a (humanly) forced motion is throwing,
which, again, is regarded in its complex environment of “dissipative”
forces. According to Aristotle a nonliving body can move only as
a result of a constant external cause of motion.
Think of a cart
on a bumpy road in Greece, which comes to a stop when the don-
key (or the slave) stops pulling or pushing. But why does a stone
keep moving when the hand throwing it lets it go?
According to
Aristotle, there could be no action at a distance in empty space.
Therefore, said Aristotle, the thrower imparts a movement to the
continuous medium of the stone’s surroundings, and this propels the
stone farther. For the velocity υ of a pulling or pushing motion, Aris-
totle asserted the proportionality υ ∼K/p with the applied force
K. Of course, these are not mathematical equations relating mea-
sured quantities, but instead proportionalities of qualitative determi-
nants, which ﬁrst emerged in this algebraic notation in the peripatetic

58
Symmetry and Complexity
physics of the Middle Ages. Thus, in Aristotelian dynamics, in con-
trast to Galilean–Newtonian dynamics, every (straight-line) change
of position required a cause of motion (force). The medieval theory
of impetus altered Aristotelian dynamics by attributing the cause
of motion to an “impetus” within the thrown body, rather than to
transmission by an external medium.
How did peripatetic dynamics explain the cosmic laws of heaven?
The central symmetry of the cosmological model was based on the
(unforced) circular motion of the spheres, which was considered nat-
ural for the “celestial” element, and on the theory of the natural locus
in the centerpoint of the cosmos. Ptolemy was still to account for the
position of the earth on the basis of the isotropy of the model and by
a kind of syllogism of suﬃcient reason. Given complete equivalence
of all directions, there was no reason why the earth should move in
one direction or another.
Besides the epicycle-deferent technique, Ptolemy employed imag-
inary balance points relative to which uniform circular motions were
assumed that, relative to the earth as center, appear non-uniform.
This technique proved to be useful for calculation, but constituted a
violation of the central symmetry and therefore had the eﬀect of an
ad hoc assumption that was not very convincing from the standpoint
of philosophy of nature, a criticism later made especially by Coper-
nicus. The reasons that Copernicus exchanged the earth for the po-
sition of the sun were predominantly kinematic. Namely, a certain
kinematic simpliﬁcation of the description could be achieved in that
way with a greater symmetry. Thus, in the heliocentric model the
retrograde planetary motions could be interpreted as eﬀects of the
annual motion of the earth, which according to Copernicus moved
more slowly than the outer planets Mars, Jupiter and Saturn and
faster than the inner planets Mercury and Venus. But Copernicus
remained thoroughly conservative as a philosopher of nature since
he considered greater simplicity in the sense of “natural” circular
motion to be a sign of proximity to reality.
With Kepler, the ﬁrst great mathematician of modern astronomy,
the belief in simplicity was likewise unbroken. In his “Mysterium cos-

Symmetry and Complexity in Early Culture and Philosophy
59
mographicum” of 1596, Kepler began by trying once more to base
distance in the planetary system on the regular solids, alternatingly
inscribed and circumscribed by spheres. The planets Saturn, Jupiter,
Mars, earth, Venus and Mercury correspond to six spheres ﬁtted in-
side each other and separated in this sequence by a cube, a tetrahe-
dron, a dodecahedron, an icosahedron and an octahedron. Kepler’s
speculations could not, of course, be extended to accommodate the
discovery of Uranus, Neptune and Pluto in later centuries.
Fig. 17.
Kepler’s symmetry of the planetary system (Mysterium Cosmograph-
icum 1596)
Yet Kepler was already too much of a natural scientist to lose
himself for long in Platonic speculations. His “Astronomia Nova” of
1609 is a unique document for studying the step-by-step dissolution
of the old Platonic concept of simplicity under the constant pres-
sure of the results of precise measurement. In contrast to Coperni-
cus, Kepler supplemented his kinematic investigations with original
dynamic arguments. Here the sun is no longer regarded as being
physically functionless at a kinematically eccentric point, as with
Copernicus, but is seen as the dynamic cause for the motion of plan-
ets. The new task was to determine these forces mathematically as

60
Symmetry and Complexity
well. Kepler’s dynamic interpretation with magnetic ﬁelds was only
a (false) initial venture. Success came later, in the Newtonian theory
of gravity.
The simplicity of the celestial (“superlunar”) world and the com-
plexity of the earthly (“sublunar”) are also popular themes in other
cultures. Let us cast a glance at the Taoist philosophy of nature of
ancient China. To be sure, it is edged with myth and less logically
argued than the Greek philosophy of nature, and it also invokes more
intuition and empathy; nevertheless, there are parallels between the
two. Taoism describes nature as a great organism governed by cycli-
cal motions and rhythms, such as the life cycles of the generations,
dynasties and individuals from birth to death; the food chains con-
sisting of plant, animal and human; the alternation of the seasons;
day and night; the rising and setting of the stars; etc. Everything
is related to everything else. Rhythms follow upon each other like
waves in the water. What forces are the ultimate causes of this pat-
tern in nature? As with Empedocles, in Taoism two opposite forces
are distinguished, namely yin and yang, whose rhythmic increase and
decrease govern the world. In the book “Kuei Ku Tzu” (4th century
B.C.) it says: “Yang returns cyclically to its origin. Yin reaches its
maximum and makes way for yang.” [1.30] While according to Aris-
totle all individuals carry their natural purposes and movements in
themselves, the Tao of yin and yang determines the internal rhythms
of individuals, and those energies always return to their origins. The
cyclical rotational model of the Tao provides explanations for mak-
ing calendars in astronomy, for water cycles in meteorology, for the
food chain and for the circulatory system in physiology. It draws its
great persuasiveness from the rhythms of life in nature, which people
experience every day and can apply in orienting themselves to life.
Nature appears as a goal-directed organism.
It is noteworthy that the Chinese philosophy of nature had no no-
tions of atomistic particles and therefore did not develop mathemat-
ical mechanics in the sense of the occidental Renaissance. Instead,
at its center there was a harmonious model of nature with rhythmic
waves and ﬁelds that cause everything to be connected to everything.

Symmetry and Complexity in Early Culture and Philosophy
61
The preference for questions of acoustics and the early preoccupation
with magnetic and electrostatic eﬀects is understandable given this
philosophy of nature. The Taoists’ view bears more resemblance to
the philosophy of nature of the Stoics than to Aristotle. Here too
the discussion centers on eﬀects that spread out in a great continuum
like waves on water. This continuum is the Stoics’ pneuma, whose
tensions and vibrations are said to determine the various states of
nature. The multifarious forms of nature are only transitory patterns
that are formed by varied tensions of the pneuma. Modern thinking
leaps, of course, to the patterns of standing water waves or sound
waves or the patterns of magnetic ﬁelds. Nevertheless, neither the
Stoic nor the Taoist heuristic background led to the development of a
physical theory of acoustic or magnetic ﬁelds comparable to Galilean
mechanics with its background of an atomistic philosophy of nature.
The emergence of order from complex, irregular and chaotic states
of matter was only qualitatively described, using diﬀerent models for
earth and for heaven.

This page intentionally left blank

Chapter 2
Symmetry and Complexity in
Mathematics
In the modern era the study of mathematical symmetries has led to
an algebraic theory that has found application in almost all branches
of mathematics and has become fundamental for a coherent theory
of nature. This is group theory, which has come into being since the
end of the 18th century in the theory of equations, number theory,
and geometry, although initial attempts made in earlier centuries
were known at that time. Thus, the ancient interest in regular ﬁg-
ures and bodies led to a systematic study of so-called discrete groups
in the plane and in space, which became fundamental, in the natu-
ral sciences, for spectroscopy and crystallography and which found
application in elementary particle physics in the exact deﬁnition of
a coherent theory of natural forces. But it is not only the character-
istics of various mathematical theories and natural phenomena that
fulﬁll the axioms of these groups. Artistic decorations and musical
tone patterns can also be examined from the coherent point of view
of this mathematical structure. It marks a reemergence of the old
Pythagorean idea of a coherent symmetry structure in mathematics,
art and nature, this time algebraically generalized and considerably
more comprehensive than what was deﬁnable on the basis of the An-
tique theory of proportions. The concept of transformation group
became central to geometry.
The various geometric theories that
had arisen in the 19th century can be characterized by those trans-
formation groups that leave the laws of the speciﬁc theory unchanged
(“invariant”). That also produced the mathematical prerequisites for
determining natural laws by symmetry groups.
63

64
Symmetry and Complexity
2.1
Symmetry and Group Theory
Figures or bodies were called “symmetrical” in Antiquity when they
possessed common measures or proportions. Thus the Platonic bod-
ies can be rotated and turned at will without changing their regu-
larity. Half of the human body can be mirrored along the middle
axis without change in its proportions. In general, according to the
Antique doctrine of proportions, ﬁgures have common proportions if
they possess the same geometrical form, i.e. if they are similar.
Similarity transformations, therefore, leave the geometric form
of a ﬁgure unchanged, i.e. the proportional relationships of a cir-
cle, equilateral triangle, rectangle, etc. are retained, although the
absolute dimensions of these ﬁgures can be enlarged or decreased.
Therefore one can say that the form of a ﬁgure is determined by the
similarity transformations that leave it unchanged.
What is meant by a transformation is a mapping that maps a
set of points (e.g. the points of the circle) onto itself with one-to-one
correspondence. To illustrate the form invariance of two similar bod-
ies Leibniz uses the example of two temples (for example, the temple
building itself and a smaller model) that are “indistinguishable” from
each other if each of the two structures is regarded by itself without
reference to an external unit of measure [2.1].
Therefore a geometric form arises from abstraction, from ab-
stracting away all characteristics of the respective ﬁgures (e.g. ab-
solute sizes) except their similarity.
Abstraction with respect
to similarity can be logically deﬁned by the following demands:
(1) Each ﬁgure is similar to itself. (2) If ﬁgure F is similar to ﬁgure
F ′, then F ′ is also similar to F. (3) If F is similar to F ′ and F ′ is sim-
ilar to F ′′, then F is similar to F ′′. Relations that fulﬁll the demands
of (1) reﬂexivity, (2) symmetry and (3) transitivity, are called equiv-
alence relations. Therefore we can establish the geometrical form of
a ﬁgure by abstracting all characteristics except similarity because
similarity is an equivalence relation.
A similarity transformation is an example of an automorphism
[2.2]. In general an automorphism is the mapping of a set (e.g. points,

Symmetry and Complexity in Mathematics
65
numbers, functions) onto itself that leaves unchanged the structure of
this set (e.g. proportional relations in Euclidean space, arithmetical
rules for numbers). Automorphisms can also be characterized alge-
braically in this way: (1) Identity I that maps every element of a set
onto itself, is an automorphism. (2) For every automorphism T an
inverse automorphism T ′ can be given, with T · T ′ = T ′ · T = I. (3)
If S and T are automorphisms, then so is the successive application
S · T.
A set of elements (e.g. points, numbers, transformations) with
a composition that fulﬁlls these axioms, is called a group. Now in
particular, the reﬂection T at a plane, which underlies right-left sym-
metry, can be characterized by T · T = I (i.e. T is its own inverse
transformation).
From Euclid to Newton and Helmholtz, a great
role is played by those similarity transformations that do not alter
the size of a body. These are the transformations (“movements”) of
rigid bodies (e.g. rulers) in space, which geometrically are also called
congruences or isometries. They constitute the prerequisite for phys-
ical measuring and therefore were traditionally regarded as the basic
concept of geometry.
But in fact we do not need to know of any “rigid” bodies
in the physical sense in order to investigate geometric isometries
or congruences.
Mathematically an isometry is the mapping of
a metric (e.g. Euclidean) space on itself that leaves the intervals
(e.g. Pythagorean distances) between all points unchanged. Every
isometry is by deﬁnition a similarity. In Euclidean geometry there
are similarities, namely the enlargement and reduction of a ﬁgure,
that are not isometries (congruences), i.e. in these cases the congru-
ences form a genuine subgroup of the similarity group.
In this connection, congruences are called proper if they connect
the position of the points of a measure before and after a movement,
in contrast to congruent reﬂections, in which a body is transformed
into its mirror image.
The simplest examples of congruences are
parallel shifts or translations, which as vectors form the basis of
aﬃne geometry [2.3].
Another example for congruences is rotation around a ﬁxed point,
as in the case of the pentagram (Fig. 5), which comes back to the

66
Symmetry and Complexity
same position through 5 proper rotations around the center, whose
angles of rotation equal m · 2π/5 with 1 ≤m ≤5, and which in
addition possesses 5 reﬂections along the straight lines that connect
the center with the corners. These 10 transformations constitute a
group that completely describes the symmetry characteristics of the
pentagram.
In general, then, the symmetry of a spatial ﬁgure is determined
by the group of those automorphisms that let it unchanged (“invari-
ant”).
Since Euclidean space is characterized by the group of all
automorphisms (“similarities”), it has the full symmetry. The sym-
metry of a ﬁgure in space is then determined by means of a subgroup
of the full automorphism group [2.4].
Now we turn to the discrete groups of movements on the plane,
since they include, as special cases, the regular ﬁgures and orna-
ments known since Antiquity. In that connection, a group of mo-
tions is called discrete if it contains no arbitrarily small movements
(e.g. rotations or translations) that are diﬀerent from the identity
I. Because of this restriction, for example, the rotational group of
the circle with inﬁnitesimally small rotations around the center, and
the translation group of the straight lines with inﬁnitesimally small
translations, are excluded. These continuous groups have also played
a role in physics and are separately examined.
A discrete group of movements is called a point group if there is
a point that is ﬁxed by all of its movements. This is always the case
when the group of motions contains no translation (other than the
identity). Thus the cyclic groups Cn consist of rotations around the
angles m · 2π/n with 1 ≤m ≤n around a ﬁxed point [2.5]. Exam-
ples are the regular polygons or the star polygons in Fig. 5. Indeed
these examples possess, along with rotational symmetry, also reﬂec-
tion symmetry. For example, a pure C4 rotational symmetry without
the static rest of reﬂection symmetry, is the swastika (hooked cross)
which has appeared as a symbol of the wheel of the sun in vari-
ous cultures and which became the symbol of a destructive political
“movement” in the last century.
If one extends the rotational group Cn by the n reﬂections along
the reﬂection axes with the angles π/n, one obtains the dihedral

Symmetry and Complexity in Mathematics
67
group Dn. Thus, for example, the symmetry of the star polygons is
completely determined by the corresponding dihedral groups. Thus
the complete table C1, C2, . . . and D1, D2, . . . of all possible ﬁnite
groups of proper and improper rotations in the plane provides all
possible central symmetries in the plane.
Now we come to the translation symmetries, which, in cultural
history, were attained especially in the magniﬁcent Indian and Is-
lamic ornaments, but which also appear in later epochs of style. First
we treat the stripe ornaments, which can be classiﬁed in the seven
so-called frieze groups. A frieze group is a discrete movement group
which contains the translations (̸= I) and for which all translations
except for the sign have the same direction. This direction is called
the longitudinal axis of the stripe; the direction that is perpendicular
to it is called the transverse axis. If one applies all the translations
of a frieze group to one point in the plane, there arises an inﬁnitely
long row of points along the longitudinal axis with equal intervals
(“elementary distance”) between neighboring points. If one exam-
ines the coincidence movements of these stripes, the following seven
translation groups can be distinguished (Fig. 18a).
Fig. 18b presents examples of stripe ornaments [2.6]. They are
produced by the following transformations: (1) a translation; (2) a
translation, a reﬂection (on the longitudinal axis); (3) a translation,
a reﬂection (on a transverse axis); (4) a translation and an inversion
(rotation by 180◦); (5) combination of the frieze groups (1), (2),
(3), (4); (6) a translation and a glide plane (= a translation by
half the elementary distance and a reﬂection); (7) combination of
the frieze groups (3), (4), (6) producing the impression of a relief
(Fig. 18c). Cases like this can also be dealt with symmetry groups if
one conceives of the plane as two-sided. Then one speaks of two-sided
ornaments.
From the stripe ornaments we arrive now at the plane ornaments.
Historically these elaborate and artful patterns have been used in the
mosaics, fabric patterns, etc. of various cultures. Intuitively, we are
dealing here with the presumably earliest evidences of higher algebra.
As long ago as the 12th century B.C. we ﬁnd plane ornaments in the

68
Symmetry and Complexity
Fig. 18a.
Frieze groups
Fig. 18b.
Stripe ornaments
Fig. 18c.
Two-sided stripe ornament
wonderful paintings of Egyptian burial chambers and temples.
It
is not surprising that of all cultures, it was the Indian and Islamic
one, whose mathematicians were pioneer algebraists, that had highly
developed this art form. In his “Harmonice mundi” (Book II) Kepler
investigates the possible covering of the plane with equal regular
polygons. However, the symmetry groups of the plane ornaments
were not determined until very late.
It was the crystallographer
E.S. Federov who demonstrated that there are exactly 17 ornament
groups in the plane.
They can be produced by means of the following transformations (Fig. 19)
[2.7]: (1) translations; (2) translations and inversions; (3) a combination of (8),

Symmetry and Complexity in Mathematics
69
Fig. 19.
Ornament groups of the plane
(11), (12); (4) a combination of (2), (6); (5) translations and reﬂections along
parallel axes; (6) translations and glide reﬂections along parallel axes; (7) combi-
nations of (2), (5), (6); (8) combinations of (2), (9); (9) translations, reﬂections
and glide reﬂections along parallel axes; (10) combinations of (4), (8), (12); (11)
combinations of (2), (5); (12) translations and rotations of 90◦; (13) translations
and rotations of 120◦; (14) combinations of (9), (15), (17); (15) combinations of
(9), (13) in which not all the rotation points lie on reﬂection axes; (16) combi-
nations of (9), (13) in which all the rotation points lie on reﬂection axes; (17)
combinations of (2), (13). One can easily see which ornaments are left invariant
by rotation and dihedral groups. The classiﬁcation C1 applies to ornament (1);
C2 applies to (2); C3 to (13); C4 to (12); C6 to (17); D1 to (5), (6), (9); D2 to
(4), (7), (8), (11); D3 for (15), (16); D4 for (3), (10); D6 for (14). Fig. 20 displays
examples of ornaments from various cultures.
Now we distinguish the discrete point groups in space [2.8]. Group
Cn of the proper rotations around a midpoint on the horizontal plane
can be interpreted as the group of rotations in space around a ver-
tical axis through the midpoint. Reﬂection at a straight line in the
plane is brought about by a 180◦rotation around this straight line

70
Symmetry and Complexity
Fig. 20.
Ornaments from various cultures
(“ﬂipping”). Thus a group D′
n of proper rotations in space results
from group Dn in the plane. It includes the rotations of 2π/n around
an axis vertical to the plane through the midpoint and the ﬂippings
around n horizontal axes through the midpoint, which share the same
angles of π/n.
Moreover D′
1 and C2 are identical since both consist of the identity
and 180◦rotation around a straight line. D′
2 encompasses the identity
and ﬂippings around three axes that are perpendicular to each other
(“four group”). In any case this gives us the following inﬁnite number
of proper rotation groups in space: C1, C2, C3, . . . D′
2, D′
3, . . . .

Symmetry and Complexity in Mathematics
71
Fig. 21.
Symmetry of cube and octahedron [2.9]
Whereas in the plane a regular n-sided polygon can be described
for every n > 2, only 5 regular (“Platonic”) polyhedra exist in 3-
dimensional space. Moreover, if we consider, additionally, the ﬁnite
number of proper rotation groups around a center in space, we ﬁnd
only three new groups which leave unchanged or invariant (i) the
regular tetrahedron, (ii) the cube or the octahedron, and (iii) the
dodecahedron or icosahedron, respectively.
For case (ii), inscribe
an octahedron into a cube in such a way that the corners of the
octahedron meet the corresponding sides of the cube at the center-
points of the six square surfaces.
Conversely, a cube can also be
inscribed into an octahedron (Fig. 21). Then compare the analysis
of the corners, edges and surfaces of the Platonic solids in the table
of Fig. 6. Every rotation that turns the cube back into itself also
leaves the octahedron invariant and vice versa. Therefore, the group
for the octahedron is the same as for the cube. Analogously, it can
be shown that the dodecahedron and the icosahedron are described
by means of the same group. The regular solid that corresponds to
the regular tetrahedron is the tetrahedron itself.
This gives us three groups of proper rotations — group T of the
tetrahedron, group W of the cube or octahedron and group D of
the dodecahedron or icosahedron, with 12, 24 and 60 operations
respectively. Corresponding to Euclid’s uniqueness of the Platonic
solids in space, it can be shown that groups Cn (n = 1, 2, 3, . . .), D′
n
(n = 2, 3, . . .), T, W and P are the only proper rotation groups in

72
Symmetry and Complexity
space. This list has to be supplemented by the number of improper
rotations in space, analogously to the plane rotation groups. An im-
proper rotation in space is nothing but a rotation-reﬂection, i.e. the
combination of a reﬂection and a rotation around an axis that is per-
pendicular to the mirror. A rotation-reﬂection can also be grasped
as a rotation inversion, i.e. as a combination of a point reﬂection or
inversion at the center O (which brings every point P back to P ′
on the extension OP ′ of line PO with PO = OP ′) and a rotation
around an axis through the reﬂection point.
By analogy to the situation in a plane, one can ask which of the
ﬁnite point groups of motions leave space lattices invariant. In the 2-
dimensional case there are 10 point groups. In the 3-dimensional case
one obtains 32 crystal classes that are of considerable signiﬁcance for
crystallography [2.10]. The corresponding groups to the 17 ornament
groups in three dimensions are the 230 discrete groups of movements
with three independent translations. As a whole, all the groups were
ﬁrst described by the Russian crystallographer Fedorov (1890), and
also independently by the German A. Schoenﬂies (1891) and the
Englishman W. Barlow (1894) [2.11].
The ﬁrst 65 consist of proper movements. The simplest group contains only
translations.
The remaining 64 contain in addition rotations and screw axes,
i.e. combinations of translations and rotations.
Of these, 22 appear as 11 so-
called enantiomorphic pairs, which are mirror images of one another, i.e. one
member of the pair contains a left-, the other a right-handed screw. Examples
in nature include the left- and right-rotating quartz, known since the early day
of mineralogy. If one drops these practically important distinctions, one obtains
only 54 cases, consequently altogether 219 groups. The remaining 165 groups
contain, in addition to proper movements, also improper ones, such as reﬂections,
rotation-reﬂections and glide reﬂections.
In mathematics the symmetry of ﬁgures or bodies is determined
by the group of those mappings of them onto themselves (“auto-
morphisms”) that let them unchanged (“invariance”). This idea can
be generalized for all kinds of mathematical structures that are de-
ﬁned by axioms or theories. The old deﬁnition of “geometry” in the
sense of “measuring the earth” became inadequate to cover special-
izations in research as early as the 19th century. Only with F. Klein’s

Symmetry and Complexity in Mathematics
73
“Erlanger Program” of 1872, with the concept of “geometric invari-
ants” which remain unchanged with metric, aﬃne, projective or topo-
logical transformation groups, among others, did it become possible
to organize the various directions of research into a hierarchy of the-
ories. Coordinate transformations of course played a large role in
analytical geometry as long ago as the 17th and 18th centuries.
In 2-dimensional analytical geometry, for example, geometric expressions con-
cerning points of a plane are translated into analytical expressions of coordinate
values, so that functions x and y for each point P correspond to the real values
x = x(P) and y = y(P). The transformations x′ = ax+by+e and y′ = cx+dy+f
can be summarized as

x′
y′

=

ab
cd

x
y

+

e
f

whereby the matrix
ab
cd

must be orthogonal with

ab
cd

ac
bd

=

10
01

The Cartesian geometry of the plane then consists of those expressions and
characteristics that are invariant under these transformations. Since the succes-
sive application of Cartesian transformations in turn leads to more of the same,
they form a group that clearly characterizes the invariant properties of Cartesian
geometry. Examples of Cartesian transformations are rotation, reﬂection, and
inversion, which can be represented by corresponding matrices.
According to Klein, the investigation of a geometric theory gener-
ally consists of the following algebraic problem: “There is a manifold,
and in it there is a transformation group; we must investigate the
elements belonging to the manifold with regard to those character-
istics which are not changed by the transformations of the group.”
In short: “There is a manifold, and in it there is a transformation
group. Develop the invariant theory relating to the group.” [2.12]
F. Klein distinguishes similarity transformations as key concept
for Euclidean geometry, because there, ﬁgures can be enlarged or
reduced arbitrarily without changing shape.
Consider a triangle,
for example, which can be arbitrarily enlarged or reduced without
changing the angles.
Only in Euclidean geometry is the group of
motion a genuine subgroup of the similarity group.

74
Symmetry and Complexity
Absolute geometry arises from Euclidean geometry, without the
acceptance of Euclid’s parallel postulate, according to which, through
a given point, there is only a single line parallel to a given straight
line. We move from absolute geometry to Euclidean or non-Euclidean
geometry by adding either Euclid’s parallel postulate or one of the
non-Euclidean versions. On the other hand, the parallel line plays a
central role in aﬃne geometry. For Euclid, the aﬃne theorems are
those that remain unchanged after parallel projection from one plane
into another. Analytically, the aﬃne geometry of the plane can be
characterized by transformations with an invertible matrix.
In contrast to aﬃne geometry, there is no parallelism in projec-
tive geometry. Nor do length or angular measurements play any role.
The historical origin of projective geometry is the problem of per-
spective. Each transformation from one ﬁgure to another by central
and parallel projection or a ﬁnite series of projections is called a pro-
jective transformation. The projective geometry of the plane or of
the straight line consists of the totality of those geometric proper-
ties that remain valid and unchanged over any number of projective
transformations of the ﬁgures to which they relate. In contrast, met-
ric geometry consists of the system of those geometric properties that
relate to the sizes of ﬁgures, and remain invariant only under rigid
motions.
The most general of all geometries is topology, which is charac-
terized by the group of continuous transformations. As an example
of characteristics that are left invariant under transformations, let
us consider polyhedrons. A polyhedron is called a simple polyhe-
dron when its surface can be continuously deformed into a spherical
surface, i.e. simple polyhedrons do not have “holes,” like a torus,
for example. The Euler formula for the simple polyhedron is thus:
E −K + F + 2 for the number of corners E, the number of edges
K and number of surfaces F. We can easily verify this formula for
the Platonic bodies, for example, but it covers a great deal more
than just the polyhedrons of metric geometry with straight edges
and plane surfaces. It even remains valid if we imagine the surface of
a regular polyhedron made of rubber, which can be deformed arbi-

Symmetry and Complexity in Mathematics
75
trarily, as long as it is not torn. That is because only the number of
corners (points), edges (lines) and surfaces is important for this for-
mula. Length, surface area, linearity, cross ratio and other concepts
of metric, aﬃne or projective geometry are not left invariant under
topological transformations.
To explain the relationship between continuous groups and the
concept of symmetry let us ﬁrst consider a simple example. A ro-
tation of a plane coordinate system around its origin in a counter-
clockwise direction by an angle θ can be considered a symmetry of
the plane, because it leaves the relationships between distance and
angle invariant. These rotations form a group. If, for example, the
rotation by the angle θ1 is followed by an additional rotation by the
angle θ2, then the result is a rotation by the angle θ1 + θ2. It can
easily be veriﬁed that this rule of composition satisﬁes the group ax-
ioms. For example, the rotation by the angle 0 can be used as the
unit element I. If σ1 is the rotation by the angle θ, and σ2 is the
reverse rotation by the angle 2π −θ, then σ1σ2 = I = σ2σ1.
The group of rotations is continuous, since it is a function of a
continuous parameter θ. The discrete groups of regular polygons are
embedded in the continuous group of the circle. It describes the per-
fect symmetry of the circle that so fascinated ancient and medieval
philosophers and scientists. As a result of a suitable composition of
continuous rotation and stretching, we get a continuous rotation and
stretching, by means of which the logarithmic spiral can be gener-
ated. The Swiss mathematician J. Bernoulli was so fascinated by its
symmetry that he had the inscription “Eadem mutata resurgo” chis-
elled on his tombstone in the Basel Cathedral. In fact, this motto
expresses the symmetry of the logarithmic spiral, since by means of
continuous rotation and stretching, it can be transformed into itself.
The Golden Spiral (Fig. 8) is an approximation of the logarithmic spi-
ral. Like the spiral in the plane, the circular helix can be introduced
in space by continuous helical motion, the technical application of
which was discovered as long ago as Archimedes.
The methods of group theory in geometry were an initial appli-
cation in the natural sciences of the modern mathematical concept

76
Symmetry and Complexity
of symmetry. They were also based on earlier, visual and human
notions of symmetry in art. But in the history of mathematics, the
algebraic and number theoretical origins of the group theory con-
cept of symmetry are older than the geometric approaches. They
go back to the 18th century, and are related to the equation theo-
ries of J.L. Lagrange, Gauss, N.H. Abel and E. Galois in particular.
The application of group theory in geometry is a question of dis-
tinguishing the symmetry characteristics of ﬁgures and bodies by
invariance in relation to groups of transformations, for example, ro-
tations, translations or reﬂections. It was the brilliant idea of Galois
to also characterize the solutions of equations by characteristics of
symmetry, which remain unchanged under speciﬁed transformations
(“permutation group”), to thereby obtain information on solutions
and the solubility of equations. Galois used this theory to answer
basic problems of equation theory, and his achievement is thus the
culmination of a development that stretches far back into Antiquity.
On the other hand, his group theory methods are revolutionary, even
independent of equation theory, and stand at the beginning of mod-
ern structural mathematics, which was also fundamental for physics.
The analytical formulations of geometry since Descartes have fol-
lowed analytical mechanics since J. d’Alembert and Lagrange, among
others. Problems of motion in physics were translated into equations
of motion, which in general have the form of diﬀerential equations.
Under some side conditions, therefore, the solution of motion prob-
lems in physics meant the solution of diﬀerential equations. A trans-
fer of the Galois Program from algebraic equations to diﬀerential
equations was therefore also of interest in terms of physics. Then it
was possible, to a certain extent, to determine the characteristics of
the solutions to these equations, i.e. including the solutions of corre-
sponding problems of motion, by means of symmetry observations.
In 1874, Lie began to classify continuous transformation groups. He
designated a group continuous, if all of its transformations are gen-
erated by “an inﬁnite number of repetitions of inﬁnitesimal trans-
formations”. Lie’s theory of continuous groups became the “Galois
theory” of diﬀerential equations when he used it in 1888 to character-

Symmetry and Complexity in Mathematics
77
ize their solutions of equations [2.13]. The theory of continuous and
ﬁnite groups was investigated in the 1890s in France by H. Poincar´e
and E. Cartan, among others, attracted a great deal of attention in
physics (in particular with the theory of relativity).
The diﬀerential geometry of Gauss, Riemann, Cartan and others
form the basis for the symmetries of Einstein’s theory of relativity.
Using the example of Gauss’ theory of surfaces [2.14], we shall ﬁrst
compile several illustrative results of diﬀerential geometry.
The coordinate system on a surface xi (u1, u2) which is generated by the
curves u1 = const., and u2 = const., is called a Gaussian coordinate system.
Curves on the surfaces (e.g. distances on the curved surface of the earth) with
a < t < b can now be described by surface coordinates u1 = u1(t), u2 = u2(t) and
by spatial coordinates xi = xi(u1(t), u2(t)). Since partial diﬀerentiation gives
dxi
dt = ∂xi
∂u1
du1
dt + ∂xi
∂u2
du2
dt
such a curve has the arc length:
s =
 b
a




3
	
i=1

dxi
dt
2
dt
=
 b
a

3
	
i=1
∂xi
∂u1
∂xi
∂u1

 du1
dt
2
+ 2 ∂xi
∂u1
∂xi
∂u2
du1
dt
du2
dt + ∂xi
∂u2
∂xi
∂u2

du2
dt
2 1
2
dt .
If, according to the Ricci calculation for Greek letter indices µ, ν, we accept
summation over the indices of the surface coordinates, and for the Latin indices
summation of the spatial coordinates, we get the abbreviated notation
s =
 b
a

gµν duµ
dt
duν
dt dt
with the metric coeﬃcients
gµν = ∂xi
∂uµ
∂xi
∂uν ,
where gµν = gµν (u1, u2) is only a function of the surface points, and the direction
of the arbitrarily selected surface curves is expressed in terms duµ/dt.
The surface metric ds2
=
gµνduµduν is a positive-deﬁnite
quadratic diﬀerential form, also called ﬁrst fundamental form, which
is generated by the (Euclidean) scalar product in the tangential plane

78
Symmetry and Complexity
of the surface point in question. It is invariant under well-deﬁned co-
ordinate transformations that are also continuously diﬀerentiable in
each direction. The decisive factor is the Gauss’ assumption that
in any small area of the surface, a “local” Euclidean coordinate sys-
tem (y1, y2) can be found, in which the distance from (y1, y2) and
(y1 + dy1, y2 + dy2) can be measured by the Pythagorean metric
ds2 = du2
1 + du2
2. There are length-preserving (with invariance of
the curve length), conformal (with invariance of the angle) and area-
preserving (with invariance of the surface area) transformations. In
cartography, for example, the Mercator projection is drawn by means
of a conformal, but area-distorting mapping, while a Lambert pro-
jection is drawn with an area-preserving transformation.
According to Gauss’ theorema egregium, the curvature of a sur-
face can be determined solely by the metric coeﬃcients gµν and their
derivations, i.e. the curvature is a function only of the intrinsic ge-
ometry of the surface and not of the surrounding space. Therefore,
for length-preserving transformations (bending of the surface), the
Gaussian curvature of the surface points is preserved.
Gauss’ as-
sumption of local Euclidean coordinate systems is also a function
of intrinsic metric characteristics of the surface, and not of the sur-
rounding space. The overall curvature of a surface patch, according
to the theorem of Gauss and O. Bonnet, is related in a simple manner
to the total lateral curvature of its edge. Geodesic lines as the short-
est and straightest connections between points on a surface found
applications both in geodesy and in mechanics.
The results of the Gaussian surface theory can be generalized without restric-
tion to the n-dimensional surfaces. Riemann made a broader generalization, by
expanding the intrinsic geometry of the 2-dimensional surfaces to n-dimensional
diﬀerentiable manifolds whose metrics are no longer induced by embedding in a
surrounding Cartesian space and its Euclidean scalar product [2.15]. Here, rather,
a fundamental tensor gµν is speciﬁed for µ, ν = 1, . . . , n with the positive-deﬁnite
metric ds2 = gµνduµduν. Analogous to the 2-dimensional Gaussian surfaces, it
is assumed for n-dimensional Riemannian manifolds M, that a Euclidean coor-
dinate system y1, . . . , yn with Pythagorean metric ds2 = dy2
1 + · · · + dy2
n can be
found locally (“in the inﬁnitely small neighborhood of a point P of M”), which
can be represented in the “tangential space” TP of M in point P.

Symmetry and Complexity in Mathematics
79
The 2-dimensional Gaussian surfaces can generally have diﬀerent
curvatures varying at diﬀerent points. Mathematically, the curva-
ture of a surface at one point can be deﬁned as a function which
is dependent only on the metric coeﬃcients gµν, with µ, ν = 1, 2.
Without going into any further mathematical detail here, it is also
possible to deﬁne a curvature tensor for n-dimensional Riemannian
manifolds which is a function only of the fundamental tensor gµν
with µ, ν = 1, . . . , n [2.16]. While additional visualizations can be
combined with the term “curvature” for the Gaussian curved sur-
faces in Euclidean space, this heuristic approach fails completely for
Riemannian manifolds with an arbitrary number of dimensions. But
even in the 2-dimensional case, the Gaussian surface curvature is de-
termined by the “intrinsic” metric characteristics, and is therefore
not always identical to the visual curvature that relates to the sur-
rounding space. A trivial example is the surface of a cylinder, which
is “visually curved,” but which has the same Gaussian curvature as
the Euclidean plane.
By generalizing the special 2-dimensional Riemannian manifolds
with constant curvature, symmetrical spaces can be studied which
are characterized by homogeneity and isotropy. Leibniz had previ-
ously identiﬁed homogeneity as a symmetry characteristic of space,
because, in this case, all points of the space are indistinguishable.
In a presentation entitled “The facts on which geometry is based”
(1868), Helmholtz attempts to explain these symmetry characteris-
tics of 3-dimensional physical space in terms of measurement tech-
niques and physiology. He begins with a visually-based introduction
of homogeneous point manifolds.
Helmholtz, in his research into the sensory organs, investigated
the manifolds of acoustic and color sensations as a physiologist and
physician.
Sounds can be deﬁned by their continuously changing
pitch and volume, i.e. as points of a 2-dimensional manifold. Ac-
cording to Helmholtz, colors can be generated as mixtures of three
basic colors, the respective proportions of which are continuously
changing, on the retina, i.e. they can be interpreted as points of a
3-dimensional manifold. The surface of the skin on the body is an

80
Symmetry and Complexity
example of a 2-dimensional manifold, whose “points of sensitivity”
are characterized by diﬀerent sensitivity to stimuli from location to
location.
How do these physiological manifolds diﬀer from the known ge-
ometric manifolds, such as a plane?
Helmholtz’s answer is that,
on geometric manifolds, we can compare distances between points
everywhere, i.e. we can freely move a rigid measurement body ev-
erywhere over the manifold. On the other hand, for example in the
2-dimensional acoustical manifold, there is no such comparability of
distances between points everywhere: Two sounds of the same pitch
and diﬀerent volumes are not comparable to two sounds of diﬀerent
pitch but the same volume.
The Euclidean plane is a homogeneous manifold in the sense of
the free mobility of a rigid measurement body. But the surface of
a sphere is homogeneous, if we select as the scale a segment of a
great circle in “close” contact. The surface of an egg is a contrasting
example. For example, if we plot a circle with the radius r at the
small end and at the big end of the egg, the circumference U of the
circle is smaller in the ﬁrst case than in the second case. The circle
cannot be moved freely, since the curvature of the surface of the egg
is diﬀerent at the small end and at the big end.
Are there also homogeneous surfaces with negative constant cur-
vature? An initial model was proposed by E. Beltrami (1835–1900).
But among them, there is no shape as simple as the surface of a
sphere, because they have singularities, beyond which the surfaces
may not be continuously extended.
The Helmholtz requirement for the “free mobility of a rigid mea-
surement body” and the homogeneous manifold was explained and
generalized n-dimensionally by Lie with his concept of the continuous
group [2.17]. Lie proceeds from the assumption of an n-dimensional
continuous and diﬀerentiable manifold M. Instead of a physically
rigid body, there is a metric d(x, y) for points x, y from M. The
physically free mobility of the rigid body is explained mathemati-
cally by one-to-one point transformations that leave the distances
between points deﬁned by the metric unchanged. They are therefore

Symmetry and Complexity in Mathematics
81
isometries or congruent mappings. They can occur, for example, as
translations or rotations, and the operations can be performed one
after the other.
The geometric composition of movements corresponds alge-
braically to a composition of the transformations that satisfy the
group characteristic. In particular, Weyl gave the following explana-
tion of the Helmholtz–Lie requirement:
The group of congruent mappings can transform any arbitrary
point into any arbitrary point of the manifold, and with a deﬁned
point, can transform any arbitrary line direction in this point into
any other line direction, with a deﬁned point and deﬁned line direc-
tion, any arbitrary surface direction running through it into any other
arbitrary such surface direction, etc., up to the (n −1)-dimensional
direction elements. But if there is a point, a line direction running
through it, a surface direction etc. passing through it up to an (n−1)-
dimensional direction element, apart from identity there is no con-
gruent mapping which preserves this system of elements connected
in this way, like point, line direction, etc.
The decisive factor is then the mathematical proof that under this
homogeneity requirement, only Euclidean, hyperbolic and parabolic
manifolds are possible, i.e. only the three known types of geometries
with constant curvature. Mathematically, this explanation makes it
clear that for homogeneous manifolds, the free mobility of a “body”
need not be required, but free mobility “in the inﬁnitesimal”, in
the sense of the indicated homogeneity requirement for the contin-
uous group of congruent mappings. The homogeneous Riemannian
manifolds are therefore not — as Helmholtz believed — based on
a physical “fact”, but on a mathematical concept: the continuous
isometry group. But Helmholtz’s visual and physical considerations
were of major heuristic value in the discovery of this concept [2.18].
The Helmholtz–Lie idea of constructing homogeneous manifolds
with the requirement of a continuous isometry group was generalized
by Cartan.
Finally, we should discuss his theory of symmetrical
spaces, since it forms the mathematical framework for discussions of
symmetry in modern (relativistic) cosmology.

82
Symmetry and Complexity
Cartan deﬁnes a “symmetrical space” [2.19] as a Riemannian manifold in
which the reﬂection at any given point A is an isometric transformation.
A
reﬂection is deﬁned as the assignment to a point M suﬃciently close to A of that
point M ′ which is obtained if the geodesic arc MA is constructed, and is changed
so that MA and AM ′ have equal lengths. An isometry is deﬁned as a coordinate
transformation uµ →¯uµ which leaves the form of the metric of the manifold
invariant, i.e. for the metric coeﬃcients ¯gµν = gµυ. It is immediately apparent
that the Cartan symmetry requirement is equivalent to the requirement that the
Riemannian curvature is preserved at any given point A in relation to any plane
element proceeding from A, if this plane element is displaced anyway in a parallel
fashion. A parallel displacement of a vector from a point A to an inﬁnitesimally
adjacent point A′ results from the two successive reﬂections at A and at the
center of the geodesic arc AA′. If the reﬂection is an isometric transformation,
the parallel displacement leaves the metric and thus also the curvature unchanged.
A symmetrical Riemann space allows a transitive group of rigid
displacements. In this case, transitivity means that each point of
the space can be transformed into any other point by an element of
the group. For example, if A and B are two points suﬃciently close
together, then the product of the reﬂection at A and at the center
of the geodesic arc AB is an isometry which transforms A into B.
Inﬁnitesimal isometries are of particular interest to physicists.
A
Riemannian space is called isotropic if it is isotropic in every point.
The symmetries of quantum mechanics are investigated in the
mathematical framework of Hilbert spaces and representations of
discrete and continuous groups.
A Hilbert space is nothing more
than a complete linear space with a scalar product.
In quantum
mechanics, the states of particles are described by wave functions.
Therefore the function spaces play a major role for the application
in physics. The linear operators on Hilbert spaces are of interest in
physics because they describe changes of the Hilbert spaces, i.e. in
terms of physics, the changing states of the quantum systems.
The operators are an important mathematical technique for the
study of the symmetry characteristics of vector spaces. Symmetries
in vector spaces are described by group transformations of the vec-
tors (e.g. rotations, translations). In the vector space V , let us deﬁne
a group of transformations G which transform the vectors from V
into corresponding vectors from V . Let us also consider the func-

Symmetry and Complexity in Mathematics
83
tional space F(V ) with functions f, which are dependent only on
the vectors x from V . In terms of physics, V can be visualized as
the 3-dimensional coordinate space of a body, by means of which
determined symmetry operations such as rotations around the origin
can be executed.
The functional value f(x) can be imagined, for
example, as the temperature of a body at the position x.
The question arises what temperatures the body has after the ro-
tation. In response, we can say that a symmetry operation G in the
vector space induces a transformation T(G) of the temperature func-
tion. In quantum mechanics, the functional space will be a Hilbert
space with corresponding wave or state functions. The question then
arises, what operators on the states of the quantum system are in-
duced by symmetries of the coordinate systems.
The deﬁnition of the linear operators by their matrices, i.e. the
representation of groups by matrices is physically very important
[2.20]. For example, to be able to use the symmetry of an abstract
group in physics, the elements of the group must be quantiﬁed. That
is what the matrices do. We cannot only investigate representations
of symmetries in 3-dimensional spaces of classical physics, but also
in functional spaces, which are a key concept in quantum mechanics.
For (ﬁnite) groups, it can be demonstrated that all possible repre-
sentations can be constructed of a ﬁnite number of representations
that cannot be further reduced. Therefore, it is always suﬃcient to
study these irreducible representations of a group.
2.2
Symmetry Breaking and Bifurcation Theory
The symmetry of dynamical systems is mathematically analyzed in
the theory of diﬀerential equations. The reason is that the dynamics
of a system, that is, the change of its states depending on time,
is mathematically described by diﬀerential equations.
They allow
to compute the ﬁnal states of a dynamical system as solutions of
equations. In the following chapters, we shall see that the state of
a system is a very universal concept which does not only refer to
moving states of, for example, atoms or molecules in physical or

84
Symmetry and Complexity
chemical systems, but to states of, for example, cells in organisms or
products in a market system, too. Thus, problems of symmetry and
symmetry breaking in these areas are reduced to the symmetry of
diﬀerential equations, that is, their invariance with respect to certain
groups of transformations.
A 1-dimensional system is described by a diﬀerential equation
of the form dx/dt = f(x) with state x and time t. In diﬀerential
calculus, dx/dt is the rate of change of x with respect to time t. We
study linear and nonlinear equations of this form that are symmetric
Fig. 22a.
Harmonic oscillator
Fig. 22b.
Linearity of Hooke’s law

Symmetry and Complexity in Mathematics
85
Fig. 22c.
Potential energy
with respect to certain transformations. But the symmetry can be
broken by actually realized solutions.
A simple example is a harmonic oscillator (Fig. 22a) with a mass attached to a
spring resting on a table [2.21]. If the spring is neither stretched nor compressed,
the mass will rest a steady-state position x = 0. If the spring is compressed with
x < 0 or stretched with x > 0, there will be a force tending to increase or to
decrease the elongation x of the mass. According to Hooke’s law the force f is
proportional to the position x with a certain spring constant α that is, f(x) =
−αx. The minus sign results from the fact that the elastic force tends to bring
the particle back to its equilibrium position. Hooke’s law is a linear relationship
between force and position, represented by a linear equation (Fig. 22b).
The
potential energy of a mass on a spring is U(x) = 1/2αx2 (Fig. 22c). In general,
the potential energy is a function with the property dU(x)/dx = −f(x), that is,
the negative expression of its rate of change is the force.
We consider an equation of motion, that is, the rate of change of
position x of a particle under the action of a force, which has the
form of a linear diﬀerential equation dx/dt = −αx. Obviously, this
equation remains unchanged with resepect to the inversion x →−x,
that is, the linear system is symmetric with respect to inversion. The
potential energy (Fig. 22c) remains also invariant under this trans-
formation U(x) →U(−x) = U(x). Its symmetric curve illustrates

86
Symmetry and Complexity
the full stability of the system. If the particle is displaced, its poten-
tial energy is brought to a certain point on the curve like a ball on
the slope of a hill. In any case of displacement, the ball will fall back
down the slope and, taking friction into account, come to rest at the
bottom of the hill, the stable equilibrium point x = 0 of the system
with dx/dt = 0. The situation changes for nonlinear 1-dimensional
diﬀerential equations of the form dx/dt = f(x, α), depending on a
changing control parameter α. In this case we can study the symme-
try of equations, but also symmetry breaking by unstable equilibrium
points.
An example is the anharmonic oscillator [2.22] which contains a cubic term
besides a linear term in its equation of motion dx/dt = −αx −x3. The cubic
term can be interpreted as a perturbation of the oscillator. For a changing control
parameter with α < 0 and α > 0, we get diﬀerent curves of potential energy
(Fig. 23a–b).
The equilibrium points are determined by dx/dt = 0.
Under
this condition, mathematical solutions of the equation can easily be found: We
get only one solution x = 0 in the case of α > 0, but three solutions x = 0,
x1 = −√|α|, and x2 = +√|a| in the case of α < 0. If the values of potential
energy in Fig. 23a–b are interpreted as positions of a ball on the slope on a hill,
then the ball rests in a stable position at x = 0 for α > 0 and for α < 0 at x1 and
x2, but in an unstable position at x = 0 for α < 0, where it can roll down the hill
after tiny elongations.
Fig. 23a.
Potential energy of anharmonic oscillator

Symmetry and Complexity in Mathematics
87
Fig. 23b.
Potential energy of anharmonic oscillator
Fig. 23c.
Bifurcation scheme of anharmonic oscillator
Again, the diﬀerential equation and the potential energy are sym-
metric with respect to inversion x →−x. But the symmetry is bro-
ken by actually realized solutions with changing control parameter.
If the control parameter is gradually changed from positive to neg-
ative values, then the stable equilibrium position x = 0 becomes

88
Symmetry and Complexity
unstable at α = 0 and two new stable equilibrium points emerge.
The development can be illustrated by the changing potential curve
in Fig. 23a–b. If it is deformed from α > 0 to α < 0, it becomes
ﬂatter and ﬂatter in the neighborhood of x = 0. Consequently, the
ball rolls down the curve more and more slowly. At α = 0 two new
symmetric valleys with stable equilibrium positions at the bottom
emerge. The ball at x = 0 breaks the symmetry spontaneously and
rolls down into one of them. In an actual system the potential energy
settles into one of them in stable equilibrium.
In Fig. 23c symmetry breaking is illustrated by a bifurcation
scheme.
The equilibrium coordinate xe is deﬁned as a function
of α.
For α > 0, it is xe = 0, but for α < 0, xe = 0 be-
comes unstable (dashed line) and is replaced by two stable positions
which are plotted by a solid fork. Thus, bifurcation mathematically
only means the emergence of new solutions of equations at critical
values.
Actually, bifurcation and symmetry breaking is a purely math-
ematical consequence of the theory of nonlinear diﬀerential equa-
tions.
But, bifurcations of ﬁnal states as solutions of diﬀerential
equations correspond to qualitative changes of dynamical systems
and the emergence of new phenomena in nature and society that will
be studied in the following chapters. The most important case of
1-dimensional nonlinear systems is the situation, when besides a sta-
ble point after changing control parameter a new couple of a stable
and an unstable point emerge.
The possibilities of ﬁnal states is enlarged by 2-dimensional sys-
tems which are represented by 2-dimensional diﬀerential equations of
the form dx/dt = f(x, y, α) and dy/dt = g(x, y, α). In this case, there
are not only points on the x-axis as ﬁnal stable or unstable states,
but also points and closed curves (“limit cycles”) on the x–y plane.
In dynamical systems, closed curves can be interpreted as periodic
time-depending behavior. Thus, these equations are mathematical
models for a large class of rhythms or oscillating systems like clocks
and watches, but also oscillating electronic systems in technology,
biological or even economic and social oscillations.

Symmetry and Complexity in Mathematics
89
An example is the anharmonic oscillator with a rotational symmetric potential
energy [2.23]: The potential curve U(x) is rotated around the U-axis (Fig. 24a)
with two equations of motion for polar coordinates r (radius) and ϕ (angle of
rotation): dr/dt = f(r, α) is the nonlinear equation of the anharmonic oscillator
and dϕ/dt = ω the equation of constant angular velocity of rotation. We can
also use orthogonal coordinates x = r cos ϕ and y = r sin ϕ which span up a
2-dimensional x–y plane (Fig. 24b). The path of a ball along the valley is a circle.
If the ball starts to roll down at the unstable center x = y = 0, it spirals away
to the circle. Again, we observe symmetry breaking if the control parameter is
changed from α > 0 to α < 0. Since the ball also ends up in this cycle, if it starts
from the outer side, the limit cycle is stable.
In Fig. 24c the symmetry breaking of a limit cycle is illustrated
by a bifurcation scheme.
The equilibrium coordinates xe and ye
are deﬁned as functions of control parameter α. For α > 0, it is
xe = ye =0, but for α < 0, xe = ye = 0 becomes unstable (dashed
line) and is replaced by the stable limit cycle which is plotted by a ro-
tated fork. This new form of bifurcation is called a Hopf-bifurcation.
Limit cycles need not be circles, but can be other closed curves. In
dynamical systems they describe a periodic time-depending behav-
ior as ﬁnal stable state. In 1- and 2-dimensional dynamical systems,
stationary points and limit cycles are the only possible stable ﬁ-
nal states.
Their bifurcation behavior were already discovered by
Poincar´e (1885), and further analyzed by the American and German
mathematicians G. Birkhoﬀand E. Hopf (1942) [2.24].
Fig. 24a.
Rotational symmetry of potential energy

90
Symmetry and Complexity
Fig. 24b.
Symmetry breaking of a limit cycle
bifurcation point
fixed point attractor
limit cycle
Fig. 24c.
Symmetry breaking of a limit cycle (bifurcation scheme)
The possibilities of ﬁnal states are dramatically enlarged and
changed for systems with more than two dimensions.
A 3-
dimensional system can be represented by 3-dimensional diﬀerential
equations of the form dx/dt = f(x, y, z, α), dy/dt = g(x, y, z, α), and
dz/dt = h(x, y, z, α).
In this case, stationary points, limit cycles,
quasi-periodic oscillations and the famous chaos emerge as possible

Symmetry and Complexity in Mathematics
91
solutions.
How is their bifurcation behavior?
Poincar´e suggested
to reduce the complexity of a 3-dimensional state space to the well-
known dynamics in a 2-dimensional state space.
His genius idea
reminds us of Plato’s famous cave-allegory. According to Plato, hu-
man beings recognizing the real world are like prisoners in a cave who
try to reconstruct the 3-dimensional real shape of objects outside the
cave from their 2-dimensional shadows on a wall inside the cave. Ac-
tually, Poincar´e introduced a 2-dimensional plane (Poincar´e map)
intersecting the orbits in the 3-dimensional state space transversally.
These curves (trajectories) represent the time-depending develop-
ments of states in the 3-dimensional system. We analyze their in-
tersecting points on the Poincar´e map (Fig. 25). Their sequential
positions P0 = (x0, y0), P1 = (x1, y1), P2 = (x2, y2), . . . with two
coordinates xn and yn (n = 0, 1, 2, . . .) on the Poincar´e map describe
discrete time dynamics which deliver suﬃcient information about the
continuous dynamics in the 3-dimensional state space. As the inter-
val of time between the sequential positions on the Poincar´e map
are ﬁnite, the discrete time dynamics deﬁne a sequence of recurrence
in the 3-dimensional system. Mathematically, it can be represented
by 2-dimensional ﬁnite diﬀerence equations xn+1 = f(xn, yn) and
yn+1 = g(xn, yn).
At ﬁrst, we study oscillations of limit cycles in a 3-dimensional
space on a 2-dimensional Poincar´e map [2.25]. If the points P0, P1,
P2, . . . converge to a ﬁxed point P on the Poincar´e map, then the cor-
Fig. 25a.
Poincar´e map and limit cycle

92
Symmetry and Complexity
Fig. 25b.
Poincar´e map and spiral
 
Fig. 25c.
Poincar´e map and torus
responding 3-dimensional dynamics lead to a limit cycle (Fig. 25a).
The existence of a ﬁxed point P is proved by the fact that the ﬁ-
nite diﬀerence equations have a simultaneous solution xn+1 = xn,
yn+1 = yn resp. xn = f(xn, yn), yn = g(xn, yn).
In general, we
can consider the case that xn+1, xn+2, . . . are diﬀerent to xn and

Symmetry and Complexity in Mathematics
93
yn+1, yn+2, . . . resp. to yn until an iteration k with xn+k = xn and
yn+k = yn is reached. An iteration k is called a cycle of order k.
Obviously, Fig. 25a shows a cycle of order one with one ﬁxed point.
Fig. 25b is a cycle of order two corresponding to the three-dynamical
dynamics of a spiral with two cycles. Another case is Fig. 25c where
the points P0, P1, P2, . . . converge to a closed curve C on the Poincar´e
map. The corresponding trajectories of the 3-dimensional dynamics
spiral on the 2-dimensional surface of a torus.
An example of chaotic 3-dimensional dynamics is given by the
three diﬀerential equations dx/dt = −y −z, dy/dt = x + ay, and
dz/dt = bx −cz + xz with positive constants a, b, c and only a
quadratic nonlinearity.
These equations have two ﬁxed points P0
with x0 = y0 = z0 = 0 and P1 with x1 = c −ab, y1 = b −c/a,
and z1 = c/a −b. In the neighborhood of P0 we observe unstable
chaotic behavior of the trajectories. They seem to be sometimes at-
tracted and sometimes repelled by P0, although they are caught in
a bounded region of P0. The orbits round about P0 are completely
non-periodic without recurrence of any pattern. Further on, the tra-
jectories depend sensitively on initial states. Only tiny changes of
them lead to completely diﬀerent developments of trajectories af-
ter a few steps. Fig. 26a shows the 3-dimensional R¨ossler attrac-
tor of chaos for numerical integration with a = 0.32, b = 0.3, and
c = 4.5.
The 3-dimensional chaotic behavior can also be studied on a 2-
dimensional Poincar´e map intersecting the state space in Fig. 26a
with coordinates, for example, y = 0, x < 0, z < 1 [2.26].
In
a further reduction we can consider the position of the n + 1-th
intersecting point on the Poincar´e map as function of the preceding
position of the n-th intersecting point, that is a discrete iteration
equation xn+1 = f(xn). In the case of the R¨ossler attractor, we get
a bell-like curve of sequential cutting points. But they are not given
by an ordered sequence of points, but randomly and statistically
distributed (Fig. 26b).
The discrete iteration equation of the R¨ossler attractor is similar
to the function xn+1 = f(xn, α) = 1 −αx2
n. It generates an inﬁnite

94
Symmetry and Complexity
Fig. 26a.
Chaotic R¨ossler attractor
Fig. 26b.
Poincar´e map and R¨ossler attractor
sequence of bifurcations which happen at well-deﬁned critical values
α1 < α2 < · · · < αn < · · · leading to cycles of higher order. Their
periods double at each new bifurcation (Fig. 27). The critical values
concentrate at a certain value α∞. Beyond α∞, orbits with inﬁnite

Symmetry and Complexity in Mathematics
95
Fig. 27.
Cascade of symmetry breaking: Periodic doubling bifurcations
periods emerge with chaotic non-periodic behavior.
The discrete
dynamics of period doubling bifurcations ends in a chaotic scenario.
It is governed by a law of constancy, because the critical values αn
converge to α∞with a constant ratio, the so-called Feigenbaum-
constant δ ≈4.669.
The period doubling cascade is numerically
calculated in the following table. It can easily be done by a pocket-
computer and is a ﬁrst example of experimental mathematics:
n (period of
orbit = 2n)
bifurcation
point
αn −αn−1
δ = αn −αn−1
αn+1 −αn
0
0.75
1
1.25
0.5
4.233738275
2
1.3680989394
0.1180989394
4.551506949
3
1.3940461566
0.0259472172
4.645807493
4
1.3996312384
0.0055850823
4.663938185
5
1.4008287424
0.0011975035
4.668103672
...
...
...
...
∞
1.4011552
4.669
(unperiodic behavior)

96
Symmetry and Complexity
The tree of periodic doubling bifurcations in Fig. 27 is also a
cascade of symmetry breaking [2.27].
If the control parameter α
is gradually changed, then the locally stable equilibrium states be-
come unstable and new locally stable equilibrium states emerge. The
tree bifurcates into sequential forks with increasing complexity rep-
resenting the whole scenario of possible developments of a dynamical
system. The symmetry is broken by actually realized solutions with
changing control parameter. Thus, the complex tree of sequential
bifurcations illustrates the possible developments of a dynamical sys-
tem, but the path of actually realized branches represents the factual
history of the system.
Locally stable states are not only points in a state space, but
also periodic patterns of behavior on limit cycles (e.g. Fig. 24c and
25a–b), quasi-periodic patterns of behavior on a torus (e.g. Fig. 25c),
or chaotic patterns (e.g. Fig. 26a–b). A cascade of bifurcations and
symmetry breaking can lead to these types of locally stable states.
An example is the Navier–Stokes equation of ﬂuid dynamics. One
way to stir water in a glass is with a cylindrical rod, the rotation
of which is driven by a machine with increasing velocity. The speed
of rotation is the control parameter of the equations.
When it is
increased, one can observe ﬂuid patterns with increasing complexity
from a homogeneous ﬂuid mass at rest, in uniform rotation, and with
wavy cells up to mild and chaotic turbulence.
A ﬁrst mathematical model for the state of the ﬂuid is a velocity
vectorﬁeld in the ﬂuid domain. At each point in this domain is drawn
a vector representing the velocity of the particle of the ﬂuid. The
instantaneous state of a whole vectorﬁeld can be regarded as a point
of a state space. An orbit in the state space represents the temporal
development of a state. In Fig. 28, the state space is shown as a
vertical plane. The third dimension represents the control parameter,
i.e. the speed of rotation. The composite space of the state space and
the control parameter is called the bifurcation space of a dynamical
system illustrating the whole complex dynamics.
In Fig. 28, the ﬂuid at rest is represented by a point at the origin
of the bifurcation space. The next step is the ﬂuid mass in uniform

Symmetry and Complexity in Mathematics
97
Fig. 28.
Thom’s superspace (“Big Picture”) of bifurcation and symmetry break-
ing [2.29]
rotation. In the third step, we observe a moderate increase in the
rate of stirring. The ﬂuid motion has separated into a stack of ring-
shaped cells. In spite of the increasingly complex ﬂuid motion, the
vectorﬁeld is still stationary. It is a point attractor of the correspond-
ing state space. In the next step the cells’ boundaries have developed
waves, and the wavy cells are slowly rotating around the central axis.
The wavy vortex phenomenon is represented by a velocity vectorﬁeld
in the ﬂuid domain. The pattern repeats every few seconds. The pe-
riodic change in the ﬂuid velocity vectorﬁeld indicates a periodic
limit cycle in the corresponding state space. In the bifurcation space
the periodic attractor emerge after a Hopf-bifurcation. In the fol-

98
Symmetry and Complexity
lowing step we observe mild turbulence. The complete rings are still
wavy vortices, but they wave irregularly. The corresponding velocity
vectorﬁeld is rather complex and never returns to an exact copy of
an earlier state. The wandering of the state point within the state
space ﬁlls out with a thickened torus or some other chaotic attrac-
tor. The last step shows fully developed turbulence. The dynami-
cal system has suﬀered further bifurcations, from one type of chaos
to another.
Depending on their control parameter the equations of dynam-
ical systems can have diﬀerent state spaces with diﬀerent patterns
of behavior, from point attractors, periodic limit cycles and quasi-
periodic tori up to chaotic attractors.
The state of a system is a
point wandering along the orbits in a state space. Is there a univer-
sal superspace to represent all kinds of state spaces and dynamical
systems? In 1972, the French mathematician R. Thom introduced
a bigger picture of bifurcation theory in a further step of abstrac-
tion [2.28]. In Thom’s Big Picture, every kind of attractor in a state
space at a certain value of the control parameter is represented by
a single point. In Fig. 28, these steps of modeling abstraction are
illustrated. On the basis, there are the velocity vectorﬁelds of the
observed ﬂuid patterns. In a second step, we get the corresponding
attractors in state spaces depending on increasing values of the con-
trol parameter. In a third step, the dynamics in the bifurcation space
is transformed into Thom’s superspace. Each and every value of the
control parameter speciﬁes a copy of the state space having its own
superdynamics. Each of these superdynamics becomes a single point
in the superspace, generating an orbit with increasing control param-
eter. The starting superdynamics determines a point corresponding
to the lower endpoint of this curve, further superdynamics determine
sequential points on the curve up to the ﬁnal superdynamics with a
point corresponding to the upper endpoint of this curve. The bifur-
cation points correspond to intermediate points in the curve, shown
at the intersection of the curve and a surface. There are inﬁnitely
many of these sheets that accumulate in the end with increasing
complexity.

Symmetry and Complexity in Mathematics
99
The sheets of the superspace are parts of the so-called bad set. In
1937, the Russian mathematician A. Andronov proved that the bad
set consists of dynamical systems that are not structurally stable. A
vectorﬁeld is called structurally stable if suﬃciently small perturba-
tions of it stretches or slides the state space only a small amount.
Thom’s Big Picture analyzes the structure of the bad set within the
superspace. It represents all kinds of unstable situations leading to
bifurcations and symmetry breaking with new locally stable states
of equilibria. In the following chapters, we will recognize that lo-
cally stable states of equilibria are connected with the emergence of
new phenomena in nature and society. Thus, Thom’s superspace is
a universal abstract model for all kinds of evolutionary processes in
nature and society. According to Plato, there are eternal, invariant
and stable mathematical structures (Plato’s ideas) behind the insta-
bility, change and dynamics of phenomena we observe in the world.
Thom’s book “Structural Stability and Morphogenesis” (1975) seems
to be in the Platonic tradition.
2.3
Complexity, Nonlinearity and Fractals
Bifurcation trees of nonlinear dynamics leading to chaos attractors
have nevertheless a remarkable property of symmetry: They are self-
similar. Self-similarity deﬁnes the geometry of structures in which a
small part when expanded looks like the whole. If one cuts a limb
oﬀa tree, the resulting object will resemble the tree itself in minia-
ture. If one cuts a branch oﬀthis limb, the shape of the resulting
object will again be similar to the limb and to the entire tree. Con-
trary to mathematical trees with inﬁnite bifurcations, self-similarity
in natural objects cannot be observed for arbitrary miniaturization.
But many objects in nature are self-similar with a limited scale. Ex-
amples are the branching system of the bronchi in the lungs or the
networks of streams that ﬂow into rivers.
Self-similarity is not limited to objects with treelike geometry.
Some types of clouds are also self-similar. In reality, it is worthwhile
to consider self-similarity at least in a statistical sense. In this case,

100
Symmetry and Complexity
a structure is self-similar if its parts, on average, are similar to the
whole. The shore of an ocean, for instance, has inlets or bays, which
often contain similar inlets or bays of smaller size themselves, and so
on. Thus, Mandelbrot asked the famous question: “How long is the
coastline of Great Britain?” [2.30] If one follows up all sections with
smallest length of scaling, its length seems to become inﬁnite. This
example reminded him of geometrical ﬁgures which were analyzed by
the Swedish mathematician H. von Koch in the beginning of the last
century. Koch’s snowﬂake (Fig. 29a) is an exact self-similar shape
that consists of four copies of itself, each of which is one-third the
size of the whole set. In sequential generations each copy is divided
into three parts, and the construction of the equilateral triangle is
recursively iterated. The recursion corresponds geometrically to the
self-similarity of the pattern that arises with arbitrary scaling. The
length of the emerging ﬁgure increases with 3 · 4/3 · 4/3 · 4/3 · . . . ad
inﬁnitum.
With analogue recursive procedures, we can construct the Hilbert
and Sierpinski curves which ﬁll out a plane with self-similar pat-
Fig. 29a.
Recursive program of Koch curve

Symmetry and Complexity in Mathematics
101
Fig. 29b.
Recursive program of Cantor set
terns in iterated steps of increasing density. They seem to be more
than lines with dimension one, but less than planes with dimension
two. Their dimension is a “fraction” between the integers one and
two. The fractal dimension can be illustrated by the geometrical di-
mension D of similarity. For Euclidean objects of dimension D, the
length, area or volume of an object with edge length ε is proportional
to εD. For example, a square with edge length ε has the area ε2, a
cube has the volume ε3. For self-similar objects, one way to measure
the length, area or volume of an object is to count the number of
self-similar copies. If there are N copies each with an edge length ε,
then the length, area or volume of the object is related to its dimen-
sion: N is proportional to εD. Thus, one gets D ∝log N/ log ε. For
Koch’s curve, the number of self-similar copies is N = 4 and the edge
length is ε = 3. Therefore, Koch’s curve has a fractal dimension of
D = log 4/ log 3 ≈1.26, which diﬀers from its topological dimension
1. Another example is the Cantor set (Fig. 29b). It consists of two
copies of itself, and the length of each copy is one third the length
of the whole set, separated by an empty region whose length is also
one third that of the whole set. Again, sets are generated in sequen-
tial steps with increasing recursion depth. The Cantor set seems to
dissolve into a dust of points. Although its topological dimension is
zero, it has the fractal dimension D = log 2/ log 3 ≈0.63.
Self-similar mathematical objects consist exclusively of smaller
copies of themselves. Our procedure to calculate the dimension of

102
Symmetry and Complexity
a fractal object is only useful if we know the number N of self-
similar copies and the size ε of the original relative to each copy. For
practical applications (e.g. a map or picture of a fractal object or real
objects of the 3-dimensional world) we need a procedure to estimate
the fractal dimension. The following procedure is directly motivated
by the deﬁnition of fractal dimension: In a ﬁrst step all points in the
object are covered with N(ε0) squares or cubes of edge length ε0.
This step is repeated with squares or cubes of edge length ε1 = ε0/2,
then with ε2 = ε1/2, and so on. By doing this, we get a function N(ε)
sampled at the values ε = ε0, ε1, . . . . In theory, the dimension D is
deﬁned by limε→0 N(ε) = k · ε−D with a constant k. In practice, D
can be estimated as D ≈(log(N(εi+1)/N(εi)))/(log(εi/εi+1)). But,
of course, it is inappropriate to make the squares or cubes smaller
than the cells or particles that are considered as building blocks of
the object.
Fractals are constructed in a recursive process of iteration.
In
order to follow their iterated steps of construction on a plane rather
than on a line, Mandelbrot looked at complex numbers instead of
real numbers. Complex numbers z = x + iy consist of an imaginary
number i and real numbers x and y. According to Gauss, they can
be represented as points on a plane which is deﬁned by a cartesian
coordinate system with the real part Re(z) = x as x-axis and the
imaginary part Im(z) = y as y-axis.
Recursive equations zn+1 =
f(zn) correspond to iteration processes z0 →z1 →z2 →· · · of
sequences of points on the Gauss plane. An example is the functon
zn+1 = z2
n + c with a complex constant c, which is named in honor
of Mandelbrot. For c = 0 the number is squared at each iteration,
generating the sequence of points z0 →z2
0 →z4
0 →· · · . There are
three possibilities for the sequence, depending on z0: In the ﬁrst
case, the numbers become smaller and smaller, and their sequence
approaches zero.
Zero is a ﬁxed point and is called attractor of
the point sequence. All points less than a distance of 1 from this
attractor are drawn into it. They are in the basin A(0) of attractor
0. In the second case, the numbers become larger and larger, tending
to inﬁnity. Inﬁnity is the attractor for this process. All points further

Symmetry and Complexity in Mathematics
103
than a distance of 1 from zero are drawn into it. They are in the basin
A(∞) of attractor ∞. In the third case, the points are at a distance
of 1 from zero and stay there. Their sequence lies on the boundary
between the two basins of attraction A(0) and A(∞), which, in this
case, is the unit circle around zero.
For c ̸= 0, say c = −0.12375 + 0.56508i, the sequence z0 →
z1 →z2 →· · · has the choice between these three possibilities,
again.
But the inner attractor is no longer zero.
The boundary
is no longer smooth, but resembles a fractal closed coast line of an
island (Fig. 30a).
Inﬁnity is a distinguished attractor for all c of
the Mandelbrot function. The boundary of the basin A(∞) of at-
tractor ∞for c is called a Julia set Jc. The self-similarity of these
sets was already known to the French mathematicians G. Julia and
P. Fatou who studied them at the end of the First World War [2.32].
Julia sets depend on the choice of the complex number c. For, say
c = −0.12 + 0.74i, the Julia set is no longer a single, deformed circle
but consists of an inﬁnite number of deformed circles in a connected
set (Fig. 30b).
The interior of this Julia set is not attracted by
one ﬁxed point like in the former case (Fig. 30a), but by a cycle of
period 3.
Fig. 30a.
Basin of an attractive ﬁxed point

104
Symmetry and Complexity
Fig. 30b.
Basin of an attractive cycle of period 3 [2.32]
Fig. 30c.
Mandelbrot set
With his Mandelbrot set, Mandelbrot found a principle to de-
cide which kind of Julia set a choice of c implies. The Mandelbrot
set M contains all points c of the complex Gauss plane whose se-
quences of points, according to the corresponding Mandelbrot func-

Symmetry and Complexity in Mathematics
105
tion, do not only converge to inﬁnity. Consequently, it follows 0 ∈M
(0 is element of M), because for c = 0 sequences of points with
|zn| < 1 converge to the attractor 0, but it is 1 /∈M (1 is not
element of M), because for c = 1 all sequences of points con-
verge to the attractor ∞.
For example, 0 ∈A(∞) because of
0 →1 →2 →5 →26 →677 →· · · . In Fig. 30c, all points
of the Mandelbrot set in the window −2.25 < Re(c) < 0.75 and
−1.5 < Im(c) < 1.5 of the Gauss plane are colored black.
Intu-
itively, one recognizes that the buds on the fractal boundary repeat
the shape of the Mandelbrot set with self-similarity and arbitrary
miniaturization. The Julia sets Jc of the Mandelbrot set M can have
extremely fractal structures, especially if c is in the interior of a bud
or a germination point of a bud or any other boundary point of a bud.
They were studied in computer experiments revealing the fascinating
beauty of fractal geometry (Chapter 8.2). In 1982, A. Douady and
J.H. Hubbard proved that all Julia sets of the Mandelbrot set are
connected [2.33]. A Julia set Jc as boundary of the basin A(∞) is
connected, if not all sequences of points, according to the Mandelbrot
function with c, converge to inﬁnity, that is 0 /∈A(∞). Thus, the
Mandelbrot set can also be deﬁned as the set of all complex numbers
c the Julia sets Jc of which are connected. The other Julia sets are
Cantor sets and dissolve into dust of points.
Fractals have great importance for bifurcation and chaos theory.
Obviously, the period doubling bifurcation tree of nonlinear dynamics
leading to a chaos attractor has a self-similar structure (Fig. 27). It
can even be related to the Julia sets of the Mandelbrot set. As the
period doubling bifurcation tree takes place on the real axis, the
elements c of the Mandelbrot set are varied now as real parameter.
Imagine a path in the c-plane which begins in M and terminates
outside of M. When c crosses the boundary of M, it will decompose
into tiny buds with more miniaturized buds on their boundaries, and
so forth. The associated Julia sets seem to explode into a cloud of
inﬁnitely many points. Obviously, the budding of the Mandelbrot
set corresponds to the bifurcations of the periodic doubling scenario
in nonlinear dynamics.

106
Symmetry and Complexity
Philosophically, fractal geometry opens new avenues to under-
stand our world. The real world is not built up by idealized Euclidean
forms and bodies like, for example, perfect spheres, cubes or cones.
Mandelbrot had the great vision that, at least in a statistical sense
and with limited depth, fractality is characteristic for many observed
phenomena of reality. Nevertheless, he defends a platonic view of
the world, because symmetry in the sense of self-similarity is hidden
behind the sometimes bizarre and fractal silhouette of its phenomena.
In mathematics, fractal geometry delivers new methods to analyze
attractors of nonlinear dynamics. If an attractor is a ﬁxed point, the
fractal dimension is zero. For a stable limit cycle the fractal dimen-
sion is one. But for many nonperiodic (“strange”) attractors we get
a fractal dimension. In this case, the dynamics of a system converge
neither to a ﬁxed point nor to a closed curve but to a bounded re-
gion of a state space that is ﬁlled up by irregular and nonperiodic
trajectories with self-similarity. On Poincar´e maps, there are clouds
of points reminding the observer of the Cantor set. The principles of
fractal geometry were proven by analytic and axiomatic mathemati-
cal methods. But the complexity of fractals could only be discovered
by computer-assisted visualization, due to the increasing capacities
of modern computers.

Chapter 3
Symmetry and Complexity in
Physical Sciences
The symmetries of the laws and theories of physics and of the nat-
ural sciences in general became clear only after the application of
group theory methods in the 19th and 20th centuries. In particular,
F. Klein’s “Erlanger Program”, according to which the objective va-
lidity of geometric laws is deﬁned by their invariance under certain
groups of transformations, turned out to be the key concept for the
mathematical explanation of the objectivity and invariance of the
laws and theories of physics. Lie’s continuous groups became a valu-
able resource for classical physics. In classical mechanics, invariance
under groups of transformations leads to important consequences.
If the Lagrange equations of a physical problem are invariant with
respect to an n-parameter symmetry group in the Lie sense, the
n conservation quantities can be indicated explicitly. Conservation
theorems of physical quantities, which have a long tradition in the
philosophy of nature, as in the case of the conversation of mass,
can now be traced to space-time symmetries. These general rela-
tionships between symmetry groups and conservation quantities are
later found in an analogous fashion in the theory of relativity and
quantum mechanics.
Important characteristics of the modern concept of symmetry
were already clear in Maxwell’s electrodynamics: a uniﬁed theory
explained diﬀerent physical phenomena which had been considered
completely unrelated as recently as in the late 18th century, e.g. elec-
trostatic charge, the eﬀect of a magnet on a compass needle and
107

108
Symmetry and Complexity
the light from a candle. But in terms of group theory, electrody-
namics does not have the space-time symmetry of classical mechan-
ics (“Galilean invariance”), but what is termed Lorentz invariance.
Since Einstein’s theory of special relativity, Lorentz invariance also
determines the space-time symmetry of relativistically corrected me-
chanics. This is a global symmetry, since the Lorentz transformations
modify all space-time coordinates in the same manner. The occur-
rence of electromagnetic interactions of moving charges had already
been explained in electrodynamics by means of a novel symmetry
designated gauge invariance. This is an example of a local symme-
try, which takes into account local changes of the electrical ﬁeld and
the resulting magnetic ﬁelds. The gravitational ﬁelds of Einstein’s
general relativity theory are also described by the transfer from the
global symmetry of the special relativity theory to local Lorentz in-
variance. In relativistic cosmology, the diﬀerential-geometric theory
of symmetrical spaces is applied, which Cartan had developed from
the theory of spaces with constant curvature according to Gauss,
Riemann, Lie, Helmholtz et al. The Platonic belief in a cosmos sym-
metrical on a large scale becomes clear once again, although it no
longer employs the image of the ancient harmony of the spheres.
In addition to the theory of relativity, quantum mechanics is the
framework of modern physics. The symmetry of the Hilbert space
formalism of (J. von Neumann) quantum mechanics was investigated
by Wigner, Weyl and others, in the late 1920s, and a relationship was
established with the unitary transformations of Hilbert space. In con-
trast to classical and relativistic physics, measurable quantities (“ob-
servables”) occur which are not interchangeable (“commutative”) in
terms of group theory, i.e. there is a diﬀerence in the measurements,
depending on the sequence in which they are measured. The uniﬁca-
tion of special relativity theory and quantum mechanics started with
Dirac’s relativistic quantum mechanics wave equation for the electron
in 1928, and is currently being investigated in quantum electrody-
namics. The electromagnetic interaction of quantum electrodynam-
ics is also based on a local gauge invariance (U(1) symmetry), as
are the strong interactions which occur, for example, between the

Symmetry and Complexity in Physical Sciences
109
atomic nuclear particles protons and neutron (which are examples of
“hadrons”), and which are investigated in quantum chromodynam-
ics (SU(3) symmetry). Overall, the transition from global to local
symmetries turns out to be a key concept to describe the occurrence
of fundamental forces of physics.
In addition to gravitational force, electromagnetic and strong in-
teractions, the fourth fundamental force is currently identiﬁed as
weak interaction. This force is well-known from radioactive β-decay
and once again brings up the problem of left-right symmetry (par-
ity) in nature. In 1967, Weinberg, Salam, Glashow, among others,
explained a uniﬁcation of electromagnetic and weak interaction with
local gauge invariance of SU(2) × U(1) symmetry. Under conditions
that are correctly deﬁned by this uniﬁed theory, cases of symme-
try breaking occur and can be observed experimentally using the
resources of modern high-energy technology.
For a uniﬁcation of
strong, weak and electromagnetic interaction, the SU(5) group is
the smallest single group which comprises the corresponding gauge
groups of these interactions.
This theory predicts a tiny dilation
in which there is no fundamental diﬀerence between the elementary
particles of this interaction, but only one type of matter and only
one fundamental force. In the evolution of the cosmos, the SU(5)
symmetry would have existed for a fraction of the ﬁrst second af-
ter the Big Bang. The subsequent space-time evolution of matter
then consists of breaking of the basic symmetry and the occurrence
of sub-symmetries with diﬀerent particles and fundamental forces —
a cosmic kaleidoscope, the symmetries of which are a function of
spatial orders of magnitude and temporal development phases. The
goal of the superstring theory seems to be a modern version of the
Aristotelian “materia prima” with supersymmetry, in which all fun-
damental forces are indistinguishable. Do symmetry, transformation,
and invariance only illuminate the structure of our physical models
or do they represent real structures of the world?
In the framework of modern physics, the emergence of the struc-
tural variety in the universe from elementary particles to stars and
living organisms is modeled by phase transitions and symmetry

110
Symmetry and Complexity
breaking of equilibrium states. In the present state of superstring
theories and M-theory, we do not have a complete theory explaining
the evolution of matter with its increasing complexity. The preso-
cratic wondering that “there is something and not nothing” is not
dissolved.
But the theory of complex systems opens new insights
into the emergence of new structures by self-organization. From a
methodological point of view, the question arises, how can we detect
attractors of pattern formation in an immense variety of measured
data. Complex data mining and time series analysis are challenges
of the current theory of complex systems [3.1].
3.1
Symmetry in Physics
From the point of view of everyday perception, the symmetry of
space and time, i.e. their homogeneity and isotropy, is by no means
self-evident. While in Euclidean geometry, space is of the same con-
dition everywhere and in all directions, unchanging and unlimited,
our senses give us the impression of the inequality of directions, of
the changeability of points in space, and of the limited nature of per-
ceptions. While physics proceeds on the assumption of a time that is
constant and uniform, stress and fear can make minutes “seem like
an eternity,” and hours of happiness can pass “in a few seconds”.
The arbitrary capabilities of movement and action of the body as
a unit, and its ability to adopt any given orientation, promote the
opinion that we can execute these same movements everywhere and
in all directions, and that space can be imagined as having the same
properties, unlimited and inﬁnite, everywhere and in all directions.
If we continue to change our orientation, e.g. by rotation around the
vertical axis, these same changes of positions in space are repeated
over and over. Thereby, not only does the uniformity become clear,
but also the inexhaustibility, the unlimited repeatability and conti-
nuity of certain spatial perceptions become clear. For example, our
spatial perceptions of course gradually approximate geometric space,
but are unable to completely achieve it in this manner. Therefore, it
is necessary to deﬁne geometric ﬁgures such as lines, points, planes,

Symmetry and Complexity in Physical Sciences
111
etc. as basic concepts of a geometric theory, for which the physio-
logical phenomena of points and surfaces etc. or corners, edges, sur-
faces etc. which can be technically produced are only approximated
realizations.
But the homogeneous and isotropic space in which we can move
bodies without restriction in all directions does not have any met-
ric. Only with the additional requirement that spatial dimensions,
i.e. lengths and angles, be measured with rigid measuring rods,
do we move from homogeneous sensory space to metric geometry.
In the next abstraction step, Euclidean geometry is transformed
into Cartesian geometry, in which geometric shapes such as points,
lines, etc. are designated by (real) numerical coordinates, ordered
sequences of numbers, equations, etc. Only now can we deﬁne the
symmetry group of (Euclidean) space R3. This is the 6-parameter
Euclidean group that consists of the 3-parameter translation group
and the 3-dimensional rotation group.
Time is experienced in the form of changing positions where bod-
ies or (idealized) mass points are located. The 1-dimensional quantity
of all space points through which a mass point passes is a geometric
path line. The process of the successive, point by point and con-
tinuous generation of a curve can be represented geometrically by
deﬁning the curve by a function x = x(θ) with a real, continuous
parameter θ ≥0, whereby the curve originates with the constant
increase of θ from a point of origin x = x(0). Since the selection of
the parameter is speciﬁed only with the exception of one-to-one and
continuous transformations, we can also speak of topological time.
It designates only the sequence of points of time without a metric. It
can be realized by any given continuous movement of a mass point.
In particular, therefore, a straight line can also be selected.
On the continuum of topological time, a metric is deﬁned by any
selected movement process, e.g. a standard clock. For that purpose,
it is speciﬁed that identical Euclidean segments (“Pythagoras”) on
the path of a mass point are traversed in equal intervals of time.
With regard to this metric time, we designate a movement uniform,
if the path traverses equal distances in equal intervals of time.

112
Symmetry and Complexity
The symmetry of 1-dimensional Euclidean time T (= R) is de-
ﬁned by the one-parameter translation group.
Events occur at a
given position at a given time, i.e. they can be represented as points
(x, t) with x ∈R3 and t ∈T. In this case, the direct product can
also be written R3 × T for the 4-dimensional space-time in which
the events occur. The symmetry of this space-time in which, in ad-
dition to spatial rotations and translations, there are only temporal
shifts, is naturally minimal. Mathematically, it is a question of a 7-
parameter group consisting of the 6-parameter Euclidean group (with
3-parameter rotation group and 3- parameter translation group) and
the one-parameter translation group of time. In this space-time, it is
correct to say of two events (x1, tl) and (x2, t2) that they are spatially
separate, even if they occur at diﬀerent times.
Physical events are related to space-time systems satisfying New-
ton’s law of inertia (“inertial systems”): mass points move uniformly
on straight lines if they are left to themselves, that is no force is
exerted on them. The laws of classical mechanics are invariant with
respect to the Galilean transformations of all inertial systems. In-
tuitively, the invariance or symmetry of laws means that they are
universally true, at any time and everywhere in the world if an appro-
priate inertial system as reference can be found. In general, physical
laws and theories can be characterized by transformation groups in
the sense of F. Klein’s “Erlanger Program” for geometrical theories.
In the case of classical mechanics, the Galileo group Ggal consists of
the following transformations:
(1) The transition from an inertial system Σ to a system Σ′ shifted
in space around the vector ai is given by the transformation x′
i =
xi+ai and t′ = t. This space transformation is obviously a function of
three parameters, namely the components of the space-time constant
vector ai.
(2) The transition from a system Σ with the coordinates xi
to a system Σ′ with a rotated coordinate system is given by the
transformation x′
i = aikxk and t′ = t with orthogonal matrix
aikalk = δil = akiakl and the Kronecker symbol δil = 1, if i = l
and δil = 0 otherwise.
In vector notation, it is also abbreviated

Symmetry and Complexity in Physical Sciences
113
⃗r ′ = R⃗r with the orthogonal rotation matrix R.
The rotations
in 3-dimensional space are also a function of three independent
parameters.
(3) The transition from a system Σ to a system Σ′ displaced by
the constant time interval b is given by the transformation t′ = t + b
and x′
i = xi, which is a function of one parameter, the constant b.
(4) The transition from a system Σ to a system Σ′ displaced in
relation to it at a constant velocity vi is given by the transformation
x′
i = xi + vit. These transformations are a function of three parame-
ters, namely the space-time constant components vi of the vector of
the relative velocity of Σ compared to Σ′.
From transformations (1)–(4) we can also indicate the most general form
of a Galileo transformation, namely ⃗r ′ = R⃗r + ⃗vt + ⃗a and t′ = t + b, which
is a function of a total of 3 + 3 + 1 + 3 = 10 parameters, namely 3 pa-
rameters for ⃗a, 3 parameters for R, 1 parameter for b and 3 parameters for
⃗v.
The Galileo transformations, with reference to the sequential execution of
transformations, form a continuous 10-parameter Lie group: Since the elements
are a function of ⃗a, R, b and ⃗v, we can also write the general group element
as σ = σ(⃗a, R, b,⃗v) = (⃗a, R, b,⃗v).
The identity transformation is the iden-
tity element t = (0, 1, 0, 0) of the group.
The group operation has the form
σ′ • σ = (⃗a′, R′, b′,⃗v ′)(⃗a, R, b,⃗v) = (⃗a′ + R′⃗a + b⃗v ′, R′R, b′ + b,⃗v ′ + R′⃗v). Obvi-
ously, the sequential execution of two transformations from Ggal again results in
a transformation from Ggal. For each group element σ = σ(⃗a, R, b,⃗v) an inverse
element σ−1 = −R−2(⃗a −b⃗v), R−1, −b, −R−1⃗v) can be indicated, which satisﬁes
the requirement σ • σ−1 = σ−1 • σ = I.
Several interesting subgroups can now be identiﬁed in Ggal [3.2].
Corresponding to the transformations (1)–(4) there are the following
subgroups: (1) the 3-parameter (Abelian) group GT of the space
translations, (2) the 3-parameter group GD of rotations in space, (3)
the 1-parameter (Abelian) group Gt of the time translations, (4) the
3-parameter (Abelian) group G0 of the pure Galileo transformations.
Additional examples of subgroups are the Euclidean group GE =
GT × GD, which all contain space translations and rotations, and
the subgroup U = Gt × G0 from the time translations and the pure
Galileo transformations. U is important from a group theory point
of view, since it is the maximum abelian invariant subgroup of Ggal.

114
Symmetry and Complexity
It can thus be shown that the Galileo group Ggal is not “simple” in
the sense that it cannot be broken down into other groups.
It can be proven that the Galileo group has the product repre-
sentation Ggal = (GD × GT ) × U. We say that it is the semi-direct
product of an (Abelian) group U with the (semi-direct) product of
an (Abelian) group GT with GD. It should now be noted that the
Galileo group Ggal and thus the space-time symmetry of classical
mechanics is signiﬁcantly more complicated than the symmetry of
the Lorentz group which we will encounter in electrodynamics and
relativistic physics.
In the 18th century mechanics, like geometry, was transformed
into an analytical theory, in which it became possible to solve prob-
lems of physics as a result of the solution of certain diﬀerential equa-
tions. The high point of this trend came in 1788, with “M´ecanique
analytique” by Lagrange, i.e. 100 years after Newton’s “Principia,”
after d’Alembert and L. Euler, among others, had worked on an an-
alytical description of mechanics.
To bring the Newtonian equation of motion into the Lagrange
form, let us consider as an example the motion of a mass point with
(Cartesian) coordinates xk(k = 1, 2, 3), t, the inertial mass m under
the inﬂuence of an external force F(xi, ˙xi, t) with i = 1, 2, 3. The
Newtonian equation of motion is:
F(xi, ˙xi, t) = md2xk
dt2 = m¨xk
Langrange transformed the Newtonian equation of motion into a
general model which can be applied to systems of mass points with
and without rigid connections, to rigid bodies and the deformable
continuums. For that purpose, he introduces a function (Lagrangian
function) which characterizes the physical system in question. The
Lagrangian function expresses the fact that a physical system is de-
termined by its kinetic and potential energy. The Lagrange equations
of motion are the direct result. This approach can be generalized
for systems with a ﬁnite number of degrees of freedom. A system
with n degrees of freedom is characterized by a Lagrangian function

Symmetry and Complexity in Physical Sciences
115
L(qk, ˙qk, t) with generalized coordinates qk(t) and generalized veloc-
ities ˙qk(t). Its development over time is described by the Lagrange
equations:
∂L
∂qk
−d
dt
∂L
∂˙qk
= 0 .
In this case, therefore, the physical events correspond to the solu-
tions qk(t) of a system of second-order diﬀerential equations. The
event which actually occurs corresponds to a special solution which
is unambiguously deﬁned by initial conditions for qk(0) and ˙qk(0). In
place of Newtonian causality, which spoke of “forces” as the cause of
eﬀects or phenomena, there is now a formal system of equations which
unambiguously determine the development of a physical system over
time in the conﬁguration space deﬁned by position and time coordi-
nates. A physical system is then characterized only by the Hamilton
function H(qk, pk, t), which is a function of the coordinates of po-
sition, momentum and time. The 2n-dimensional space deﬁned by
the n coordinates qk and the n momentums pk is designated phase
space. Each point (qk, pk) of the phase space corresponds to a state
of the system in question. The development over time of the system
states in the phase space is determined by the Hamilton equations
of motion:
˙qk = ∂H
∂pk
,
−˙pk = ∂H
∂qk
.
There is the following formal diﬀerence between the Lagrange and Hamilton
equations: Since δL/δ ˙qk generally contains ˙qi, the second derivations of qi in the
Lagrange equations are by time. In contrast, the Hamilton equations contain only
ﬁrst derivations of pi and qi. However, there are now twice as many equations.
Both formalisms, however, supply exactly the same results. In Hamiltonian for-
malism, it is a question of ﬁrst-order diﬀerential equations which, together with
the initial conditions for qk and pk at the instant t = 0, determine the causality
of the system.
The Lagrangian and Hamiltonian formalism open new insights
into the symmetric structure of classical mechanics. Our everyday

116
Symmetry and Complexity
experience tells us that in nature, there exist systems which, in spite
of changing ambient conditions, change little or not at all, i.e. they
remain constant. Even the presocratic philosophy of nature could
be summed up in the dispute between Parmenides and Heraclitus,
according to which, on one hand, the world is unchanging and eter-
nal, and on the other hand is in constant ﬂux.
In the 18th and
19th century, laws of conservation for mechanical energy, momen-
tum, angular momentum, etc., were proven in mechanics. Thus, the
conservation of physical quantities seemed to be a universal princi-
ple of nature. This idea was made precise by the fact that laws of
conservation could mathematically be derived from space-time sym-
metry. To deﬁne the conservation quantities of a physical system
in general, we start with a mechanical system of mass points with
the Lagrange function L, the motions of which are determined by
Lagrange equations of form, with suitable initial conditions of the
location and velocity coordinates.
A physical quantity E = E(xk, ˙xk, t) is called the conservation
quantity of the system, and remains constant for all paths xk(t) that
are solutions of the equations of motion, i.e.
d
dtE(xk, ˙xk, t) = 0.
On the basis of this deﬁnition, the conservation quantities are
ﬁrst integrals of the equations of motion. The knowledge of a law
of conservation thus has the mathematical advantage that only a
ﬁrst-order diﬀerential equation needs to be solved, and no longer
a second-order diﬀerential equation such as the Lagrange equation.
Now, the relationship between laws of conservation and space-time
symmetry comes in [3.3]. The initially surprising tracing of conser-
vation quantities to invariance characteristics of space and time can
be explained with reference to simple examples.
The equation of motion of a particle of mass m which is moved
in one dimension under the inﬂuence of a potential V (x) reads
m¨x = −dV
dx . We now assume that V (x) is invariant under trans-
lations, i.e. V (x) is constant, independent of x. Then m¨x = 0. By
integration, it follows that m ˙x is a constant, that is the law of con-
servation of linear momentum m ˙x.

Symmetry and Complexity in Physical Sciences
117
The equations of motion of this particle in two dimensions are:
m¨x = −∂V
∂x
and
m¨y = −∂V
∂y .
We now assume that the potential V (x, y) is invariant under rotation around the
origin. If we replace the Cartesian coordinates x, y, with polar coordinates r, θ
with the polar angle θ, then the potential V is independent of the polar angle θ.
In this case, ∂V
∂θ = 0. On the other hand,
∂V
∂θ = ∂x
∂θ
∂V
∂x + ∂y
∂θ
∂V
∂y
= −y ∂V
∂x + x∂V
∂y ,
so that it follows, on the basis of the equations of motion, that
∂V
∂θ = m(y¨x −x¨y) = m d
dt(y ˙x −x ˙y) .
From the invariance under rotation it therefore follows that the quantity m(y¨x −
x¨y), i.e. of the angular momentum around an axis through the origin perpendic-
ular to the plane is also constant.
For motions of the particle in three dimensions, in which the po-
tential is invariant under rotation around any axis in space, each
component of the angular momentum is constant. Therefore, for a
spherically symmetrical potential, the value and direction of the an-
gular momentum are conserved. In general, the following is appar-
ently true: if the characteristic functions L (or H) of a physical sys-
tem are independent of the location coordinate qk, i.e. if ∂L/∂qk = 0,
then it follows that ˙pk = 0, i.e. the corresponding momentum pk is
constant. If L (or H) is independent of time, it follows that H is
constant. The Hamilton function, describes the energy of a physical
system. To summarize, therefore: the conservation of energy follows
from the homogeneity of space.
Under the inﬂuence of F. Klein’s “Erlanger program”, Noether
[3.4] demonstrated how the 10 conservation quantities of mechanics
follow from the invariance characteristics of the Lagrange function
and Hamilton’s action integral in relation to the (inﬁnitesimal) trans-
formations of the 10-parameter Galileo group. This represents the

118
Symmetry and Complexity
application of a general mathematical law to the special physical case
of mechanics.
Noether’s theorem claims in general that, for a mechanical prob-
lem, there exist n conservation quantities if the equation of motion
is invariant under an n-parameter continuous group of transforma-
tions of the (3+ 1)-dimensional space-time continuum. On the other
hand, we already know that the space-time of classical mechanics
is determined by the Galilean principle of relativity, i.e. the equa-
tions of motion of a closed system of mass points are invariant under
the transformations of the 10-parameter Galileo group. On the ba-
sis of Noether’s theorem, therefore, the 10 conservation quantities
of a closed mechanical system are fully deﬁned. The mathematical
context of the Noether theorem not only makes possible a complete
determination of conservation laws of classical mechanics, but also
of electrodynamics, relativistic physics, and, with appropriate mod-
iﬁcations, applications in quantum mechanics.
In the beginning of the 20th century, physicists were shocked by
the fact that the symmetry of classical space-time seemed to be vi-
olated by electrodynamics. According to the Galileo group of clas-
sical mechanics, the velocities of inertial systems are added relative
to one another. But in electrodynamics, the constancy of light de-
mands that the speed of light is independent of the speed of the light
source. Thus, there is no velocity faster than light that results from
adding velocities of inertial systems to the velocity of light. In his
famous paper on the electrodynamics of bodies in motion (1905),
Einstein uniﬁed the space-time of classical mechanics and electro-
dynamics. Therefore, Einstein considered inertial systems satisfying
the principle of the constancy of light. To guarantee the invariance
with respect to coordinate transformations, both for the equations
of Newtonian mechanics and also those of Maxwellian electrodynam-
ics, Einstein replaced the Galilean transformations with the Lorentz
transformations.
Mathematically,
Einstein’s space-time is represented in the
Minkowskian geometry. In Minkowski’s presentation, space and time
are combined into a 4-dimensional space-time M4 with Cartesian

Symmetry and Complexity in Physical Sciences
119
space coordinates x, y and z, and the time coordinate t. For the
sake of simplicity, the units are selected so that the speed of light
equals one, i.e. c = 1. Then the units of length and time are com-
mutative, whereby 1 sec = 299 792.458 m and 1 year = 1 light-year.
Fig. 31.
Space-time symmetry of special relativity
Bodies at the speed of light move in this 4-dimensional model
on straight lines at 45◦to the t-axis.
In accordance with the
Pythagorean theorem, they form the light cone t2 = x2 + y2 + z2
(Fig. 31). On account of the constancy of the speed of light, future
or past events can only lie within the light cone (“timely events”).
Mass particles move on straight lines (“uniformly”) or curves (“non-
uniformly”) within the cone; photons move as massless particles of
light on the surface of the cone. The distance OQ from the origin O
to a point Q with coordinates t, x, y, z in the Minkowski world M4
is OQ2 = x2+y2+z2 −t2, which diﬀers from the Pythagorean metric
term in a 4-dimensional Euclidean geometry by the minus sign. If Q
lies on the surface of the cone, then OQ = 0; if Q lies inside the sur-
face of the cone, then OQ > 0. For our considerations of symmetry in
the Minkowskian world M4, it is appropriate to replace the Galilean

120
Symmetry and Complexity
coordinates with the designations x0 = t, x1 = x, x2 = y, and x3 = z.
The Lorentz transformations which leave the Minkowskian metric in-
variant have the form x′
α = a0αx0 +a1αx1 +a2αx2 +a3αx3 +aα, with
α = 0, 1, 2, 3 [3.6]. One of the fundamental consequences of the
Lorentz transformations is the rejection of Newton’s absolute time.
The measurement of time is no longer identical in any inertial sys-
tem, but depends on its velocity.
Today, this is a well conﬁrmed
fact of measurement. Atomic clocks moving with high speed (e.g. by
airplanes) are slower relative to resting ones. In accordance with Ein-
stein’s summation convention, Lorentz transformations can also be
written x′α = aα
βxβ + aα with β = 0, 1, 2, 3. These transformations
form the inhomogeneous Lorentz group or Poincar´e group Gpoi. For
aα = 0, we get the homogeneous Lorentz group.
The subgroup of space-time rotations characterizes the isotropy of
the Minkowski world, while the invariance of the Minkowskian met-
ric with respect to the subgroup of space-time translations expresses
its homogeneity. The Minkowski world is also invariant with respect
to spatial reﬂection and reversal of time. Intuitively, invariance with
respect to a reversal of time means that if a natural event is ﬁlmed,
and the ﬁlm is run backwards, the natural event corresponds to a pro-
cess that does not violate the natural laws. The laws of conservation
are also consequences of the space-time symmetry of the Minkowski
world. Speciﬁcally, the conservation of momentum results from the
invariance with respect to spatial translations, the conservation of en-
ergy from the invariance with respect to temporal translations, the
conservation of angular momentum from the invariance with respect
to spatial rotations, and the conservation of the center of mass from
the invariance with respect to uniform motions. These symmetries
are global, i.e. the laws of nature are invariant with respect to them
only if the same transformation is applied for all four points of 4-
dimensional space. Lorentz invariance therefore includes the general
assumption that the same laws of nature as in a research laboratory
apply everywhere, i.e. the laws of physics always have the same form
in any given coordinate system, regardless of how these systems are
displaced or rotated, as long as they move at a constant velocity

Symmetry and Complexity in Physical Sciences
121
relative to one another. The global symmetries of Minkowski space
therefore give us the freedom to arbitrarily select our laboratory’s
coordinate system in the context of the above-mentioned conditions.
Like Galilean invariance, Lorentz invariance is now identiﬁed as a
global symmetry, since the Lorentz transformation change all points
of Minkowski space-time in the same manner, and thus leave the
laws of special relativity theory unchanged without the occurrences
of forces. For example, if two astronauts are moving at a constant
motion relative to one another, the transformation that transforms
their two coordinate systems into one another is identical for all
points.
An intensiﬁcation occurs if the two observers can also accelerate
relative to one another, i.e. move diﬀerently “locally” or vary from
the “global” constant relative motion to one another. Under these
conditions, it will be initially suspected that the two observers would
not derive the same (“invariant”) laws of physics, because an acceler-
ated observer seems to be exposed to forces, such as centrifugal force
during rotation. In his general theory of relativity, Einstein formu-
lated a connection between these accelerations and the gravitational
forces of masses.
There are many observations and experiments conﬁrming vari-
ances from the ﬂat Minkowski metric under the eﬀect of strong grav-
itational ﬁelds. Historically, Eddington’s 1919 observation is worth
noting, namely that beams of light from distant stars are deﬂected
in the sun’s gravitational ﬁeld, although according to special rela-
tivity theory they ought to follow the Minkowski cone. Thus, the
shortest connection of a light beam with maximal speed between
two points in a gravitational ﬁeld is not a straight line in sense of
Euclidean geometry, but a curved line the curvature of which corre-
sponds to the strength of the gravitational force. Therefore, Einstein
assumed a kind of diﬀerential geometry to describe the curved space-
time of gravitational ﬁelds. The Minkowskian geometry is reduced
to local regions where gravitational ﬁelds are absent.
Thus, Ein-
stein demands that at least “locally,” i.e. in very small segments of
space-time in which the gravitational ﬁeld does not change, an in-

122
Symmetry and Complexity
ertial system can be selected, whereby the eﬀect of gravitation is
eliminated. Historically, this principle was preceded by Galileo’s ob-
servation that all bodies, regardless of their properties, fall toward
the earth at the same acceleration (if we overlook air resistance).
The equivalence of heavy and inert masses had been experimentally
conﬁrmed. We all have seen the pictures of astronauts in orbit, who
experience weightlessness during free fall in the earth’s gravitational
ﬁeld.
On the assumption of a curved space-time the equations of motion
had to be reformulated. An equation is valid in a general gravita-
tional ﬁeld if the following requirements are satisﬁed: (1) The equa-
tion is valid without the eﬀect of gravitation, i.e. in this case, it corre-
sponds to the laws of the special relativity theory. (2) The equation
is invariant in general (“covariant”), i.e. it retains its form (“form
invariance”) with respect to general coordinate transformations of
a curved manifold. A gravitational ﬁeld is therefore described as a
so-called pseudo-Riemannian manifold with local Minkowski metric
(Fig. 32), which replaces the local Euclidean metric in a Riemannian
manifold [3.7].
Fig. 32.
Space-time symmetry of general relativity
Actually, the laws remain invariant if we include the gravitational
ﬁeld in the corresponding equations. That is precisely what occurs
in the relativistic equations of motion and gravitation. The “local”
deviations from the global symmetry are therefore eliminated by the
assumption of additional force ﬁelds. Therefore, the equations are

Symmetry and Complexity in Physical Sciences
123
said to have local symmetries. In this sense, the relativistic theory
of gravitation arises from the transition from the global Lorentz in-
variance of ﬂat Minkowski space-time to local Lorentz invariance of a
curved space-time. In general, we are already deﬁning a model that
will turn out to be fundamental in physics. If certain physical laws
are invariant, then invariance under local symmetry can be achieved
by introducing new force ﬁelds. We can also say that local symmetry
is connected with the emergence of new force ﬁelds [3.8].
In relativistic cosmology, the universe is described as a whole
system.
Everyone on earth can be convinced of the symmetrical
characteristics of the universe on a cosmic scale, at least to some ex-
tent. If we, from the earth, observe the “starry heavens overhead,”
the naked eye and the strongest telescope always see the same condi-
tions, a more or less uniform distribution of matter visibly condensed
into heavenly bodies. These observations led to a general cosmologi-
cal postulate, according to which matter is, on the average, uniformly
distributed over the entire universe (homogeneity) and its character-
istics remain unchanged, regardless of the observer’s angle of sight
(isotropy). In this sense, homogeneity must be understood in the
sense that gases, for example, can also be called homogeneous: ho-
mogeneity does not relate to the universe in detail, but to cells hav-
ing a diameter of 108 to 109 light years, in which individual irregular
condensations of matter can occur in the form of galaxies.
Historically, the cosmological postulate corresponds to modern
experience beginning with the Copernican revolution. Mankind and
the earth on which it lives do not occupy a special position in the uni-
verse. In the cosmological postulate of contemporary astronomers,
Bruno’s grandiose vision becomes a reasonable working hypothesis.
In 1929, E.P. Hubble discovered that the speed of the receding
motion of the galaxies increases with the distance between a group
of galaxies and its observer. He reported observing that the light
from very distant galaxies was shifted to the red portion of the spec-
trum, i.e. to longer wavelengths. The basis of this explanation is the
Doppler eﬀect, according to which the wavelengths of light emitted
by a moving light source seem longer to a stationary observer when

124
Symmetry and Complexity
the light source is moving away, and shorter when it is approaching.
The redshift can therefore be used to measure the speed at which
galaxies are moving away from an observer. The amount Z of the
redshift is equal to the relative increase ∆λ of the recorded wave-
length λ, i.e. Z = ∆λ/λ.
From the redshift, Hubble was able to
calculate the speed at which galaxies are receding, and thus the total
speed at which the universe is expanding.
Fig. 33.
Space-time symmetry of the cosmological principle
To explain the symmetry assumptions of the cosmological princi-
ple mathematically, Cartan proposed a diﬀerential geometry of sym-
metrical spaces (cf. Sec. 2.1). In such a geometry, all space points
must physically undergo the same development, and must be corre-
lated for time so that to an observer, all points at a ﬁxed distance
from him appear to be in exactly the same stage of development.
In this sense, the spatial state of the universe at each point in the
future (+) and past (−) must appear homogeneous and isotropic to
the observer P (Fig. 33). Geometrically, for example, let us provide
our observer, located in the center of the Milky Way, with a standard
system of coordinates. The direction of three spatial coordinates xµ
can be deﬁned, for example, by the lines of sight from the observer

Symmetry and Complexity in Physical Sciences
125
to typical galaxies. For the time coordinate t, we can select a “cos-
mic clock”, e.g. the radiation temperature of a black body which
decreases in monotone fashion everywhere.
Therefore, the “cosmic standard coordinate system” of an ob-
server is deﬁned by transformations xµ →¯xµ, t →¯t = t, in which the
physical condition remains unchanged, e.g. form invariance applies
for the gravitational potential and the energy-momentum quantity
of matter. Mathematically, therefore, the universe is portrayed as
a 4-dimensional space-time manifold whose 3-dimensional “spatial”
sub-spaces are isotropic and homogeneous. That was the assumption
of the “cosmological principle”. In terms of diﬀerential geometry,
therefore, it was the assumption of an isometry group which — in
purely mathematical terms — makes it possible for us to deﬁne the
“cosmic” metric of the 4-dimensional universe [3.9].
In 1935/36, H.P. Robertson and H.G. Walker indicated the con-
ventional standard form of this metric. It depends on a world radius
R(t) which increases in the expanding universe with the time t. Up
to this point, the geometric description of the universe follows ex-
clusively from the cosmological principle. R(t) remains an unknown
time-dependent function. To be able to verify the symmetry charac-
teristics of the universe in terms of physics, the “radius” R(t) must
be calculated. For that purpose, assumptions concerning the mate-
rial characteristics of the universe are necessary, like those expressed
in Einstein’s gravitational equations.
Therefore the Robertson–
Walker metric must be deﬁned as the solution of the gravitational
equations.
On the assumption of the cosmological principle, i.e. the assump-
tion of a homogeneous and isotropic universe, we get standard mod-
els for three possible values k = +1, −1 or 0, by means of which
spatial curvature is deﬁned. Mathematically, these standard models
are described by the development R(t) of the universe by means of
ﬁrst-order diﬀerential equations which can be derived from Einstein’s
gravitational equation. In each case, this is a 4-dimensional space-
time manifold whose 3-dimensional homogeneous “spatial” subspaces
expand temporally isotropically.

126
Symmetry and Complexity
Fig. 34.
Cosmic expansion of the three homogeneous and isotropic standard
models
Fig. 34 illustrates these subspace expanding in time as “spatial
cross sections” for the three possible cases of k. In the case k = −1,
each spatial cross section is a 3-dimensional Lobachevski geometry
L3 with negative curvature. For k = 0, the spatial cross sections
are 3-dimensional Euclidean spaces. For k = 1, they are spherical or
elliptical spaces.
In each case, there is an initial singularity, in which the space-
time curvature is inﬁnite. Cosmologically, this is designated the Big
Bang. According to this theory, the universe initially expanded very
rapidly, and then continued to expand somewhat more slowly. In the
case k = 1, the expansion reverses to a collapse, which represents a
new singularity.
We then speak of a closed universe.
For k = 0
or k = −1, the expansion continues, but more rapidly in the case
k = −1. Once it has been formed, the universe remains in existence
and unlimited in both cases. We can therefore also speak of an open
universe.

Symmetry and Complexity in Physical Sciences
127
The cosmological principle and the theory of relativity no longer
suﬃce to explain this regularity and symmetry of the universe. Mod-
ern cosmogony is merging with quantum mechanics and elementary
particle physics into a theory of physics in which the evolution of the
universe is explained by the step-wise emergence of elementary par-
ticles, atoms, molecules, etc. Against this background, it can then
be shown how, in the individual phases of development, some of the
currently known basic physical forces of strong, weak and electro-
magnetic interaction initially prevailed, until the current structure
of the universe with its macroscopically predominant gravitational
force arose. Modern cosmology therefore regards the universe as a
gigantic high-energy physics laboratory requiring a uniﬁed theory of
natural forces for its complete explanation.
Up to this point, the global and local symmetries of relativity
have been considered as invariance of classical and relativistic the-
ories.
Historically, however, the theory of relativity was also the
impetus for new ideas on a uniﬁcation of various physical theories
and explanations for the emergence of matter.
The ﬁrst attempt
at a uniﬁed theory of matter in the 20th century dates back to the
physicist Mie [3.10]. In his 1912–1913 publication on the “Principles
of a Theory of Matter,” he attempted to deﬁne a link between the
existence of electrons and gravitation. The mathematician Hilbert,
in his 1915 and 1917 publications on “The Principles of Physics”
established a uniﬁed mathematical theory of matter, in which the
approaches adopted by Mie and Einstein are taken into considera-
tion Hilbert’s proposal is also of great methodological interest, since
it applies to physics the axiomatic method which Hilbert had pre-
viously explored in mathematics [3.11]. He celebrates his derivation
of Einstein’s gravitational equations and the Maxwell–Mie equations
of electrodynamics as the greatest triumph of the axiomatic method.
Mathematical elegance, methodical simplicity and beauty were for
him the motivation for a uniﬁed theory of matter. Such a uniﬁed
theory would be the secularized version of an ideal of natural philos-
ophy, which since the days of Pythagoras had linked harmony and
beauty to mathematical regularity.
During that time, gravitation

128
Symmetry and Complexity
and electromagnetics were the only known physical forces. Thus, he
seemed to suggest a kind of world-formula.
Mie used a nonlinear augmentation of Maxwell’s electromagnetic
equations out of which elementary particles (e.g. the electron) would
arise in a natural way. A world-function was introduced as an en-
ergy functional depending upon electric ﬁeld intensity, magnetic ﬂux
density, and electromagnetic potential. The world function satisﬁed
relativistic invariance. A speciﬁc choice led to a static spherically
symmetric electric potential. Mie got a spherical model for the elec-
tron with a certain radius and electric potential. The Lorentz in-
variance that was built into the theory permits this solution of his
equation to travel with any speed up to the limiting velocity of light
with relativistic eﬀects (e.g. Lorentz contraction). Although Mie’s
atomic theory was physically false, it inspired Einstein’s life-long be-
lief that the emergence of elementary particles should be founded
by solutions of nonlinear diﬀerential equations. In short, emergence
of matter results from nonlinearity. But Einstein’s ideas of uniﬁca-
tion with symmetry and emergence with nonlinearity could only be
successful in the framework of quantum mechanics.
The ﬁrst atomic models proceeded on the assumption of visual
symmetry characteristics that recall the planetary models of Antiq-
uity. Bohr’s atomic model of 1913 was the ﬁrst to provide informa-
tion about how the electrons are distributed around the nucleus on
the shell [3.12]. According to Bohr, the hydrogen atom consists of
one proton and one electron. The negative electron moves centro-
symmetrically like a planet in the Aristotelian planetary model on an
orbit of radius r without any loss of energy (i.e. it emits no radiation)
at a linear velocity v around the positive nucleus. The orbit is stable,
because the centrifugal force which acts on the electron is equal to
the Coulomb attraction between the electron and the nucleus. The
energy E of the electron in its orbit is composed of potential and
kinetic energy. According to the energy equation, as a function of
the radius r, all values are allowed from 0 (for r = ∞) to ∞(for
r = 0).

Symmetry and Complexity in Physical Sciences
129
Fig. 35.
Central symmetry of Bohr’s atomic model
To make the model compatible with the atomic spectra, Bohr
assumed a quantization requirement. He linked the orbital angular
momentum mvr of an electron with the mass m with Planck’s con-
stant in the equation mvr = n · h/2π. For the “principal quantum
number” n, only whole numbers 1, 2,. . . may be used. For each value
of n there is a centro-symmetrical orbit with a deﬁned energy E,
which corresponds to a discrete energy level of the atom (Fig. 35).
The most stable state of an atom is the lowest energy state. Higher
orbits or states are called excited. According to Bohr, transitions
between diﬀerent orbits are possible when the amount of energy cor-
responding to the energy diﬀerence between the states in question
is either input (absorbed) or emitted in the form of electromagnetic
radiation (photons). Bohr used this model to calculate a theoretical
spectrum for hydrogen that is in good agreement with the measured
spectrum.
The further development of Bohr’s atomic model recalls the his-
tory of the Aristotelian planetary model. Even then, the original
spherical symmetry had to be restricted on the basis of more accu-
rate observations by additional ad hoc hypotheses, and thus adjusted
to ﬁt reality. When transitions in heavy atoms were investigated,
Bohr’s model no longer suﬃced.

130
Symmetry and Complexity
Thus, Bohr’s atomic model was expanded to include elliptical or-
bits. Elliptical orbits, in contrast to circular orbits, have two degrees
of freedom, since they are deﬁned by two semiaxes. To describe the
atomic spectra by transitions between elliptical orbits, two quantum
conditions are therefore necessary. The orbital quantum number k
is used in addition to the primary quantum number n. To explain
spectra of atoms with a plurality of electrons, k was replaced by the
secondary quantum number l. The secondary quantum number l de-
ﬁnes the orbital angular momentum of the electron. The magnetic
quantum number m was introduced as the third quantum number,
to deﬁne the inclination of the plane of an elliptical orbit in relation
to an external magnetic ﬁeld.
In spite of this and other improvements (e.g. the introduction
of the spin quantum number as the fourth quantum condition), the
atomic models failed for the same reason the symmetry models of
the planetary theory of Antiquity had to be given up. There was
no physical theory to explain these models. In Bohr’s atomic model,
electrons are imagined as particles moving like mass points on ﬁxed
orbits. But depending on the manner in which the test is conducted,
electrons can also behave like waves. For example, the electron of the
hydrogen atom can be understood as a spherical, stationary wave in
the space around the atomic nucleus, whose maximum amplitude is
described by a corresponding wave equation. The electron is thereby
described by a wave function ψ(x, y, z) in the space coordinates x,
y and z.
This interpretation, promoted by L. de Broglie, led to
Schr¨odinger’s quantum mechanics, which proceeded on the basis of
the wave model.
In classical Hamiltonian mechanics, a closed system is described
by a Hamiltonian function. An example is a pendulum that oscillates
with diﬀerent energies. We then say that the system is in diﬀerent
states. In an analogous manner, a hydrogen atom is in the fundamen-
tal state or in one of the many excited states. In Schr¨odinger’s sense,
the states of an atom are represented by wave functions. M. Born
established a connection between the wave and particle image of mat-
ter, by suggesting that an electron wave must be interpreted from

Symmetry and Complexity in Physical Sciences
131
the standpoint of probability. Places where the (square of the) mag-
nitude of the wave is large are places where the electron is more
likely to be found. Places where the magnitude is small are places
where the electron is less likely to be found. In general, therefore,
the states of a quantum system are described by the functions of a
Hilbert space, i.e. a functional space of functions (“states”) as ele-
ments. The quantum system must be represented by a Hamiltonian
operator, i.e. a functional depending on wave functions as system
states.
In classical Hamiltonian mechanics, the development of a
closed system over time is described by the Hamiltonian equations
of motion. In quantum mechanics, the development of a state over
time is given by the time-dependent Schr¨odinger equation. Physical
quantities such as position vector, momentum, angular momentum or
energy must also be represented by operators (“observables”) of the
corresponding Hilbert space. Mathematically, the operator approach
is a signiﬁcant diﬀerence of quantum mechanics to classical mechan-
ics. It results from the probabilistic description and the wave-particle
dualism of the quantum world.
Consequently, symmetries of a quantum system are deﬁned as in-
variant properties of the corresponding Hamiltonian operator that
can be explained in terms of group theory [3.13]. Let us imagine the
motion of an electron around an atomic nucleus. Without external
inﬂuence, it would be assumed that the Hamiltonian operator of this
system possesses full rotational symmetry. This symmetry can be
reduced by external inﬂuences. If an atom is embedded in a crys-
tal lattice, the rotational symmetry corresponding to the bonds of a
ﬁnite number of surrounding atoms can be reduced to a ﬁnite rota-
tional group. Further on, electrons are not distinguishable, so that
their position can be permuted in any given manner. Mathemati-
cally, that means that the Hamiltonian operator characterizing an
atom with n electrons is invariant with respect to the permutation
group with n! permutations. Notable consequences of symmetries
with which we have already become acquainted in classical physics
and relativity theory are the laws of conservation of physical quanti-
ties. According to the probabilistic approach of quantum mechanics,

132
Symmetry and Complexity
an observable of a quantum system is said to be conservative if its
mean value or expected value in each quantum state of the system
does not vary with time.
Quantum mechanics is also invariant with respect to space reﬂec-
tion. But does it possess time symmetry, like the equations of motion
of classical mechanics? In classical terms, the Hamiltonian equations
of position q and momentum p of a particle must be invariant with
respect to the transformation t →−t, that means q′(t) = q(−t) and
p′(t) = −p(−t). That corresponds to the idea that all positions of the
corresponding particles are reversed. For example, a particle which
is ascending at the time t = 0 and reaches the highest point at time
t = 1, is replaced by a particle which falls from the same height at
time t = −1 and reaches at the ground at the time t = 0. Another
example of classical and relativistic physics comes from astronomy.
Planets surrounding the sun could run in both directions without
violating the laws of motion. Actually, time reversal has never been
observed in the macroscopic world.
a
b
Fig. 36.
Time reversibility of planets
Mathematically, the invariance of the macroscopic equations of
motion with respect to the transformation t →−t can easily be
proved. In the Newtonian version of mechanics, the acceleration of
a body is proportional to the interacting force. Acceleration is the
time-depending change of velocity. Velocity is the time-depending
change of position. Thus, acceleration is the time-depending change
of the time-depending change of position, i.e. the second derivation of
the position of the body with respect to time. That is the reason why

Symmetry and Complexity in Physical Sciences
133
time is squared in the Newtonian equation of motion. If the positive
values +t of forward running time are replaced by the negative values
−t of backward running time, then the square t2 = (−t)(−t) =
(+t)(+t) remains unchanged.
In quantum mechanics, position and momentum are replaced by
corresponding operators. Instead of measurement values, there are
expected values in speciﬁed states (wave functions) of the system.
Wigner introduced a time-reversal operator that satisﬁes the time
symmetry of the corresponding Hamiltonian operator equation. But
time symmetry of quantum mechanics is not merely the result of
formal requirements. In the collision process of elementary particle
physics, the time reversal operator describes a permutation of the
incoming and outgoing particles that can be conﬁrmed in experi-
ments. In Fig. 37, both diagrams a and b can be read two ways —
either as electron–photon scattering, whereby the electron is repre-
sented by the solid arrow and the photon as the broken line (a), or
as positron–photon scattering, whereby the positron is represented
as a downward arrow (b).
a
b
Fig. 37.
Time reversibility of elementary particles
So far, we have investigated the symmetries of a Galileo invari-
ant quantum mechanics with slow velocities like in classical mechan-
ics. But actually, elementary particles like electrons move with high
speeds near to or even with velocity of light. The goal of a Lorentz

134
Symmetry and Complexity
invariant quantum mechanics, that is a combination of special rela-
tivity theory and quantum mechanics, is pursued in quantum ﬁeld
theory. The ﬁrst historical example of a relativistic quantum ﬁeld
theory was quantum electrodynamics, that is the combination of
Lorentz invariant electrodynamics with quantum theory. Dirac’s ini-
tial approach to a relativistic quantum mechanical wave equation of
the electron in 1927/28 turned out to be heuristically fruitful, since
it led to what at that time was the surprising prediction of an an-
tiparticle of an electron e−with negative charge which diﬀers only
by the reverse charge e+ (“positron”) [3.14].
Fig. 38.
Particle-antiparticle symmetry
Dirac’s prediction was magniﬁcently conﬁrmed by the discovery
of positrons in cosmic rays. Fig. 38 shows the bubble chamber pho-
tograph of an e−e+ pair generation resulting from the collision of a
photon (γ-quantum) with an electron. (The paths of the charged
particles are curved “left” and “right,” as a function of their charge,
on account of the application of a magnetic ﬁeld perpendicular to the
plane of the image.) Obviously, Dirac discovered a new symmetry
of matter: For electrons there are antiparticles, namely positrons.
Mathematically, the particle–antiparticle symmetry is described by

Symmetry and Complexity in Physical Sciences
135
an operator (“charge conjugation”), which transforms a particle in
its antiparticle with conjugated charge.
The particle–antiparticle symmetry seems to be fundamental in
the sense that for every particle there is an antiparticle. An antipar-
ticle can only exist if, at the site of its generation, the corresponding
antiparticle originates at the same time. It is destroyed if it encoun-
ters a particle with which it is annihilated. Energy thereby originates
in the same quantity as must be applied during generation. Accord-
ing to current elementary particle theory, matter consists strictly
symmetrically of a particle world and an antiparticle world, which
are connected to one another by the origin and annihilation of their
elements. On one hand, of course, this particle-antiparticle symme-
try has been conﬁrmed by the experiments of high-energy physics,
but on the other hand the universe seems to consist of more particles
than antiparticles. This asymmetry would be explained as symmetry
breaking at the origin of the universe, which will be discussed later
in more detail.
The basic theme of quantum electrodynamics is the interaction
of particles of matter (e.g. electrons) or wave ﬁelds of matter with
electromagnetic ﬁelds. Besides electromagnetic force modern physics
distinguishes further fundamental forces like strong, weak and grav-
itational force.
In the theory of relativity we learnt that gravita-
tion arises by transition from the global Lorentz invariance of ﬂat
Minkowski space-time to local Lorentz invariance of a curved space-
time. In the framework of quantum physics, all physical forces can be
introduced by transition from a global to a local symmetry. Accord-
ing to Weyl, forces are interpreted as so-called gauge ﬁelds compen-
sating local deviations of a global symmetry. This is a fundamental
insight into the theory of physical forces. So, let us brieﬂy recall the
diﬀerence between global symmetry and local symmetry in general.
For example, imagine a balloon which is covered by a grid of coor-
dinates (Fig. 39a). If the balloon is rotated around its axis around
the center of the sphere, its shape remains unchanged or invariant
(Fig. 39b). This invariance or symmetry is global, since all points of
the surface were rotated by the same angle. For a local symmetry, the

136
Symmetry and Complexity
a
b
c
Fig. 39.
Global and local symmetry
sphere must also retain its shape when the points of the sphere are
rotated independently of one another by diﬀerent angles (Fig. 39c).
But the surface of the sphere is thereby distorted, i.e. forces occur
on the surface of the sphere between the points. We therefore fre-
quently speak of dynamic (“local”) symmetry. The forces or force
ﬁelds compensate for the local changes in symmetry and retain the
overall symmetry of the system (“shape of the balloon”).
There-
fore, we could also speak of a “restoration of symmetry” after local
changes.
In electrodynamics a magnetic ﬁeld compensates a local change
of an electric ﬁeld, i.e. the movement of a charged body, and pre-
serves the invariance of electromagnetic ﬁeld equations. A bird on
a high-tension line survives by global symmetry. There are no local
diﬀerences of potentials. If the bird has contact with the high-tension
pole, there is a local diﬀerence and the bird is killed. In quantum elec-
trodynamics an electromagnetic ﬁeld compensates the local change
of a material ﬁeld (the phase deviation of an electronic ﬁeld) and
preserves the invariance of the corresponding ﬁeld equations. Math-
ematically, the phase deviations of a wave function ψ of an electron
are described by transformations ψ →eiαψ with a (unitary) 1 × 1-
matrix of the phase factor eiα. So the electromagnetic force is deﬁned
by a local (unitary) U(1) symmetry group of transformations. Such

Symmetry and Complexity in Physical Sciences
137
a gauge group characterizes a physical interaction mathematically
in terms of local symmetry. But the existence of a physical force is
an empirical question which, of course, cannot be derived from an a
priori demand of local symmetry.
We are already familiar with electromagnetic interactions from
everyday life. The emission of electromagnetic waves by an accel-
erated atom is familiar, for example, from radio antennas or X-ray
machines. On the other hand, the weak interactions in atoms are
much less frequently observed, e.g. in the β-decay of a neutron which
is transformed into a proton with the simultaneous emission of an
electron-antineutrino pair. Initially, it seems that weak and electro-
magnetic interactions have little in common. The weak force is ap-
proximately a thousand times weaker than the electromagnetic force.
While electromagnetic interaction can act over a great distance, the
weak force acts only at distances that are signiﬁcantly less than, for
example, the radius of the neutron. Radioactive decays are much
slower than electromagnetic decays. In electromagnetic interactions
(e.g. dispersion of an electron on a proton), in contrast to the β-
decay, no elementary particles are transformed into other particles.
The particles that participate in the weak interaction are called lep-
tons (from the Greek word for “tender”), e.g. neutrinos, electrons
or muons.
One of the most exciting diﬀerences was discovered in the 1950s.
While electromagnetic interaction is invariant with respect to spatial
reﬂection weak interaction violates parity or left–right orientation in
space. In contrast to the other fundamental forces of physics, the spin
of elementary particle plays a major role in weak interaction [3.15].
It can be imagined roughly as its characteristic angular momentum.
The spin of a particle is represented by a vector which is parallel to
the axis of rotation. It cannot be increased or decreased, and in the
case of the lepton is h/4π (abbreviated 1/2). Spin 1/2 particles can
only assume two directions in space allowed by quantum mechanics:
the spin is either in the velocity direction of the particle or in opposite
direction.

138
Symmetry and Complexity
In this context, we also speak of the right and left-handedness
(chirality) of the particle. For example, if you hold your right hand
so that the four ﬁngers point in the direction of rotation of the ro-
tating particle, the right thumb points in the velocity direction. The
handedness of an electron, for example, can be reversed experimen-
tally, by decelerating it and accelerating it in the opposite direction,
but without changing the spin.
Since massless particles (such as
neutrinos and their anti-particles) move at the speed of light, such a
deceleration and related change of orientation is not possible. Thus,
they always retain their chirality or their helicity.
In 1956, the theoretical physicists T.D. Lee and C.N. Yang described ex-
periments in which the leptons might prefer a speciﬁed helicity.
In fact, the
experiments (e.g. those of the experimental physicist C.S. Wu), showed that for
weak decays, particles are emitted only left-handed and antiparticles only right-
handed [3.16]. In concrete terms, the neutrinos which seem to have exclusively
weak interaction occur only as a left-handed helix (νL), and antineutrinos only as
a right-handed helix (νR). Only the left-handed helix portion (e−
L) participates
in the β-decay of the neutron (analogously for the muon). On the other hand,
the electromagnetic interaction is characterized by no helicity. Both helix por-
tions of the electron participate equally. The neutrinos do not participate. But
if we specify that the weak interaction is related to a weak charge, then only the
left-handed particles and right-handed antiparticles have a weak charge, while
right-handed particles and left-handed antiparticles are neutral for the weak in-
teraction. Therefore the weak charge is not conserved if an electron changes its
handedness during its motion. Only if the leptons had no mass, i.e. could not
change their direction of motion and handedness, would a conservation law apply
for the weak charge like the one for the electrical charge.
As noted above, only the left-handed helix portion e−
L of the elec-
tron participate in the β-decay of the neutron. Furthermore, only
the left-handed helix portion νL of the corresponding neutrino oc-

Symmetry and Complexity in Physical Sciences
139
curs in nature. It follows that the left-handed helix portion which
participates in the β-decay of the neutrino can be combined in a two-
component wave function, which is notated as a left- hand doublet:
L =

νL
e−
L

With global SU(2) symmetry, the states of the two-component wave
function L are changed everywhere, at the same time and in the same
way. For a local SU(2) symmetry, three gauge ﬁelds must be intro-
duced corresponding to the three group transformations generated.
Mathematically, the SU(2) combination of the three gauge ﬁelds is
notated in the following matrix [3.17]:
e−
L
νL
e−
L
W 0
µ
W −
µ
νL
W +
µ
W 0
µ
The parity symmetry of a quantum system means that the Hamil-
ton operator of the system is invariant with respect to the induced
operator transformation P. Analogously, the time-reversal symmetry
T and charge symmetry C of particle antiparticle means invariance
of the corresponding Hamilton operator. The successive application
of all three symmetry operations leads to a famous symmetry, which
is known as the CPT theorem.
According to this theorem, the Hamilton operator of a (Lorentz
invariant) quantum system is invariant with respect to the combina-
tion of parity, charge and time-reversal transformation. For classical
systems of physics, this result is trivial, since such systems are more
or less invariant with respect to each individual transformation of
this type.
That is also true for the electromagnetic (and strong)
interaction, but not for the weak interaction. From a left-handed
particle, for example, the parity transformation P produces a right-
handed particle which does not exist in nature. From a left-handed
neutrino, however, the successive application of P and C makes a

140
Symmetry and Complexity
right-handed anti-neutrino which does indeed occur in nature. For
the weak interaction, therefore, during the β-decay, the product CP
is conserved, as is T, but not P. It should be noted that several
experiments with the decay of K◦mesons also indicate a violation of
PC and T with the conservation of the total symmetry CPT.
Elementary particle physics intends to unify the four physical
forces in one fundamental force. In spite of their diﬀerent features,
electromagnetic and weak forces could already be uniﬁed by very high
energies in an accelerator ring of CERN. It means that at a state of
very high energy the particles of weak interaction (electrons, neutri-
nos, etc.) and electromagnetic interaction cannot be distinguished.
They can be described by the same symmetry group U(1) × SU(2).
There are three gauge ﬁelds of SU(2) symmetry of weak interaction
and one gauge ﬁeld of the U(1) symmetry of the electromagnetic
interaction [3.18].
The complex variety of particles like hadrons (protons, neutrons,
etc.) which interact with strong forces (e.g. atomic nuclear force)
can be reduced to the so-called quarks with three degrees of free-
dom which are called “colors” red (R), green (G) and blue (B). A
baryon is built up by three quarks that are distinguishable by three
diﬀerent colors. These three colors are complementary in the sense
that a hadron is neutral (“without color”) to its environment. The
color state of the hadron preserves invariance with respect to a global
transformation of the colors. But a local transformation of a color
state (i.e. a color change of only one or two quarks) needs a gauge
ﬁeld, in order to compensate the local change and to save the invari-
ance (symmetry) of the whole hadron. Mathematically we have a
local so-called SU(3) symmetry group of transformations [3.19].
After the successful uniﬁcation of electromagnetic and weak in-
teraction physicists try to realize the “big” uniﬁcation of electromag-
netic, weak and strong forces, and in a last step the “superuniﬁca-
tion” of all four forces. In the context of quantum ﬁeld theory, the
strong, weak and electromagnetic interactions have been traced to
fundamental symmetry structures. The trend in recent physics to
unify diﬀerent theories using the ideas of symmetry is therefore con-

Symmetry and Complexity in Physical Sciences
141
Fig. 40.
Uniﬁcation of physical forces
ﬁrmed once again. This trend is illustrated in Fig. 40, which shows
Newton’s uniﬁcation of Kepler’s celestial mechanics and Galileo’s
terrestrial mechanics into the theory of gravitation, and ﬁnally Ein-
stein’s relativistic version, Maxwell’s uniﬁcation of electricity and
magnetism into electrodynamics, the relativistic version of quantum
electrodynamics, its uniﬁcation with the theory of weak interaction
and the theory of strong interaction.
The framework of these uniﬁcations is formed by gauge theories in
which the physical forces are introduced by the transition from global
to local symmetries. Mathematically, it seems to be easy to embed
the characteristic gauge symmetries of the quantum forces into larger
common gauge groups of transformations [3.20]. But after the grand

142
Symmetry and Complexity
uniﬁcation of weak, strong and electromagnetic forces, gravitation
must now also be included. In a supersymmetry of all four forces,
therefore, general relativity theory of gravity would have to be uniﬁed
with quantum mechanics of quantum forces. The usual application
of general relativity is that of large, astronomical distance scales. On
such distances relativistic theory of gravitation implies that the ab-
sence of mass means that space is ﬂat. But, on the short distance
scales of Planck’s constant, quantities like momentum and location,
energy and time, start to ﬂuctuate according to Heisenberg’s un-
certainty principle. Although classical reasoning implies that empty
space has zero gravitational ﬁeld, quantum mechanics shows that on
average it is zero, but that its actual value undulates up and down
due to quantum ﬂuctuations. J.A. Wheeler used the term “quan-
tum foam” to describe the ultramicroscopic quantum ﬂuctuations
of space-time [3.21]. Obviously, the notion of a smooth spatial ge-
ometry of a relativistic universe is no longer true in the quantum
world of short distances. But it is the level of Planck’s constant with
the minimal Planck’s length of 10−33 centimeter (which means a mil-
lionth of a billionth of a billionth of a billionth of a centimeter) where
gravitation and quantum forces have to be uniﬁed by symmetry laws.
At the level of elementary particles, there is no chance to unify the
quantum forces with relativistic gravitation. Therefore, it seems to
be quite natural to assume a common material sublevel at Planck’s
constant and Planck’s length where elementary particles of the quan-
tum world and gravitation are generated. According to string theory,
the elementary ingredients of the universe are not point particles.
Rather, they are tiny, 1-dimensional ﬁlaments of Planck’s length like
inﬁnitely thin rubber bands, vibrating to and fro. Just as the diﬀer-
ent vibrational patterns of a violin string give rise to diﬀerent musical
notes, the diﬀerent vibrational patterns of a string give rise to diﬀer-
ent masses and charges of elementary particles. The loops in string
theory can vibrate in resonance patterns in which a whole number
of peaks and troughs ﬁt along their spatial extent (Fig. 41).
More frantic vibrational patterns have more energy than less fran-
tic ones. The greater the amplitude and the shorter the wavelength

Symmetry and Complexity in Physical Sciences
143
Fig. 41.
Symmetries of strings [3.22]
of vibration are, the greater is the energy. According to special rel-
ativity, energy and mass are equivalent. The mass of an elementary
particle is determined by the energy of the vibrational pattern of
its internal string. Heavier particles have internal strings that vi-
brate more energetically, while lighter particles have internal strings
that vibrate less energetically. According to general relativity, mass
and energy determine gravitational properties. Thus, even the gravi-
ton as messenger particle of gravitational interaction between masses
is generated by characteristic vibrational patterns of strings. String
theory avoids the inconsistencies, divergencies, and inﬁnities of quan-
tities that have arisen with point particles in the framework of quan-
tum gravitation. What appear to be diﬀerent elementary particles
can actually be considered as diﬀerent notes on a fundamental string.
In the Platonic universe, the harmonies of nature could be illus-
trated by the Pythagorean music of celestial spheres. According to
string theory the vibrational patterns of fundamental strings orches-
trate the harmonies of the universe.
It is assumed that all kinds
of symmetries, e.g. space-time symmetries, gauge symmetries of ele-
mentary particles, CPT-symmetry, originate from string theory. In a
supersymmetry of uniﬁcation, particles or vibrational patterns with
diﬀerent spins must be included [3.23]. For example, fermions are
typically matter particles with half a whole odd number amount of
spins, while bosons as typically messenger particles of interactions
(e.g. photons of electromagnetic force or gravitons of gravitation)
have a whole number amount of spin. A string theory with incor-
porated supersymmetry of fermions and bosons is called superstring
theory. In this case, for each bosonic pattern of vibration there is

144
Symmetry and Complexity
a fermionic pattern and vice versa whose respective spins diﬀer by
half a unit. These supersymmetric pairs are called superpartners.
Mathematically, they can be combined as doublets of bosons and
fermions. A supersymmetry transformation describes the transfor-
mation of bosons and fermions with spin numbers next to one an-
other, i.e. diﬀering by half a unit.
In a quantum ﬁeld theory, a boson-fermion ﬁeld would have to
be described by a Lagrangian operator that is invariant with respect
to supersymmetry transformations. But, as far as we know, super-
symmetry can be incorporated into string theory in not one but ﬁve
diﬀerent ways. These ﬁve superstring theories are called the Type I
theory, the Type IIA theory, the Type IIB theory, the Heterotic type
O(32) theory, and the Heterotic type E8 × E8 theory with diﬀer-
ent symmetry groups of transformations. Each method results in a
pairing of bosonic and fermionic vibrational patterns, but the details
of this pairing as well as other properties diﬀer. Are these theories
alternative hypotheses, which must be decided by experiments, or
should they be uniﬁed in another supertheory?
Superstring theories lead to a surprising and dramatical change of
generally accepted physical concepts of our universe: Their uniﬁca-
tion of forces at high levels of energy needs more spatial dimensions
than the three familiar ones of our universe. Historically, the idea
of further spatial dimensions dates back to the Polish mathemati-
cian T. Kaluza who, in 1919, suggested a uniﬁcation of Einstein’s
gravitational theory with Maxwell’s electrodynamics.
In Kaluza’s
uniﬁed theory, the equations pertaining to the three ordinary di-
mensions were essentially identical to Einstein’s ﬁeld equations of
gravitation. His extra equations associated with the new dimension
were those of Maxwell’s electrodynamic force. In those days, the idea
of a fourth spatial dimension that could not be observed was rather
strange. But in 1926, the Swedish mathematician O. Klein, for the
ﬁrst time, assumed that the spatial structure of our universe may
have both extended and observable dimensions as well as curled-up
ones that cannot be observed because of their tiny size [3.24]. The
fourth curled-up dimension was illustrated by tiny circles at every

Symmetry and Complexity in Physical Sciences
145
point in the familiar 3-dimensional space, like the circular loops of
thread making up the pile of a carpet.
In superstring theories, the uniﬁcation of more forces means the
need for even more dimensions. Again, for instance, two extra di-
mensions can be imagined as curled up in the shape of tiny spheres or
torus which are tacked on to every point of the familiar extended di-
mensions. But, the uniﬁcation of electromagnetic, weak and strong
forces with gravitation requires the particular number of six extra
dimensions, i.e. nine space dimensions and one time dimension in a
superstring theory. The reasons are purely mathematically explained
by the formalism of a superstring theory in order to avoid inconsis-
tent and senseless concepts. Obviously, a curled-up 6-dimensional
space cannot be illustrated like the cases of one or two extra dimen-
sions.
In 1984, it could be proven that the so-called Calabi–Yau
spaces meet the conditions which are required by the six curled-up
extra dimensions of superstring theories. These tiny six-dimensional
Calabi–Yau spaces are assumed to be tacked on to every point of the
familiar 3-dimensional space.
The 10-dimensional superstring theories have extremely symmet-
ric properties. Their supersymmetry forecasts the existence of su-
perpartners which should be detected by appropriate accelerators of
elementary particles. But, from a theoretical point of view, one of
their main advantages is their power of explanation. Newton and
Einstein developed their theories of gravity only because their ob-
servations of the world showed them that gravity exists, and that,
therefore, it required a mathematical model describing gravitational
interactions. On the contrary, string theory demands and forecast
the existence of gravity even if nobody ever has observed gravita-
tional eﬀects. Like the other fundamental forces, they are derived
from superior principles of symmetry.
But what about the ﬁve possibilities of superstring theories? State
of the art is that they share many basic features.
For example,
their vibrational patterns determine the possible mass and charge of
particles, they require 10 space-time dimensions, and their curled-up
extra dimensions satisfy the conditions of a Calabi–Yau space. But

146
Symmetry and Complexity
there are also diﬀerences.
Type I string theory, for example, has
open strings with two loose ends in addition to the closed loops of
Fig. 41. In a ﬁrst approach, the ﬁve superstring theories were thought
of as being complete separate alternatives which must be decided by
observation. But further insights have supported the idea that all of
the superstring theories can be viewed as a single, all-encompassing
framework. Kaluza’s idea of uniﬁcation by extra dimensions makes
it mathematically possible. The uniﬁed theory should have ten space
and one time dimension. One additional spatial dimension allows for
a synthesis of all ﬁve versions of the theory. The ﬁve established
superstring theories are only approximations of an exact theory that
is still unknown in all its details. This 11-dimensional theory has
provisionally been called M-theory.
The ultramicroscopic, extended nature of a string can be ap-
proximated by a structureless point particle, using the framework
of point-particle quantum ﬁeld theory. When dealing with short dis-
tance and high-energy processes where gravity and quantum forces
are uniﬁed, this approximation can no longer be used. The quantum
ﬁeld theory that most closely approximates superstring theories in
this way is the 11-dimensional theory of supergravity. A remarkable
consequence of the 11-dimensional M-theory is that the theory of
supergravity can also be incorporated into the network of common
dualities with superstring theories. M-theory does not only contain
vibrating 1-dimensional objects like (closed or open) strings, but also
includes 2-dimensional vibrating membranes, 3-dimensional objects
(so-called three-branes), and a host of other more dimensional ingre-
dients (so-called p-branes). The uniﬁcation of M-theory is supported
by proofs of dualities which describe exactly the common features
of the ﬁve superstring theories. They are mainly derived from their
symmetry principles.
M-theory seems to be the ultimate framework of the initial sym-
metric state of our universe.
In the beginning, all of the spatial
dimensions are curled up to their ﬁnite smallest possible extent of
Planck’s length, but not to zero. The temperature and energy are
high, but not inﬁnite. In the hot environment of the early universe,

Symmetry and Complexity in Physical Sciences
147
all fundamental forces were indistinguishable and merged together
in one uniﬁed force.
M-theory and superstring theories avoid the
inconsistencies of an inﬁnitely compressed zero-size starting point of
inﬁnite energy, which was assumed by the relativistic standard model
of cosmology. Perhaps, some day, the ﬁnite conditions of the early
universe can even be tested in a future accelerator ring. At this begin-
ning state of the universe, the spatial dimensions are completely sym-
metric and curled up into a multidimensional, Planck-sized nugget.
How could it expand and generate the variety of structures emerging
at successive steps of cosmic evolution?
3.2
Symmetry Breaking and Phase Transitions
In the beginning, there was symmetry. Thus, the observed variety
and diversity of structures in nature could only emerge by a reduction
of symmetry or symmetry breaking. Processes of symmetry breaking
are well known from everyday life. A (mathematically perfect) egg
has rotational symmetry and symmetry of reﬂection with reference
to its longitudinal axis. If we stand it vertically on a plate, and leave
it to its own devices, it rolls over on its side and remains lying in some
direction: The symmetry of the egg relative to the vertical axis on
the table is broken, although the symmetry of the eggshell remains
intact. The symmetry breaking is spontaneous, since it was impossi-
ble to predict the direction in which the egg ultimately came to rest.
In this case, the cause is the earth’s gravitation, which allows the
egg to assume an energetically more favourable state: the symmet-
rical state relative to the vertical axis of the plate was energetically
stable.
If the early universe started in a state of high symmetry, it was
rather featureless with only one force. More features emerged as the
universe cooled and expanded. The universe underwent a series of
cosmic phase (or state) transitions, in which the primal symmetry
was successively broken and the gravitation, strong, weak and elec-
tromagnetic interactions successively froze out.
Phase transitions
with symmetry breaking can be illustrated in many physical systems

148
Symmetry and Complexity
by lowering their temperature. Water provides a simple example.
A complex system of water molecules is a gas or steam above 100
degrees Celsius. In this state, the system has a high degree of sym-
metry, because the molecules can move completely freely without any
distinction of direction. If the temperature is lowered below 100 de-
grees Celsius, water droplets emerge by passing through a gas–liquid
phase transition, and the symmetry is reduced. If the temperature is
further lowered down to 0 degrees Celsius, the system pass through
a liquid–water/solid–ice phase transition that is connected with an-
other spontaneous decrease in symmetry. In this state, the liquid
water begins to freeze and turn into solid ice. Liquid water looks the
same regardless of the angle from which it is viewed. In this sense,
the system is rotationally symmetric. But solid ice has a crystalline
block structure looking diﬀerent from diﬀerent angles. The phase
transition has resulted in a decrease in the amount of rotational
symmetry.
At 10−43 seconds after the Big Bang, the so-called Planck-time,
the temperature of the universe is calculated to be about 1032 Kelvin.
As time passed, the universe expanded and cooled.
Between the
Planck time and a hundredth of a second, the uniﬁed theory fore-
casts phase transitions with symmetry breaking and emergence of
new structures which are similar to the phase transitions of wa-
ter. E. Witten proved that, within M-theory, the strengths of all
four forces can be uniﬁed (Fig. 42) [3.25]. When the temperature
of the universe, above 1028 Kelvin, was still high enough, then, ac-
cording to quantum ﬁeld theory, at least the three nongravitational
forces merged together.
A bifurcation between gravitation and a
uniﬁed electro-weak-strong force had happened. As the temperature
dropped below 1028 Kelvin, the universe underwent a phase transi-
tion in which the three forces crystallized out from their union in
diﬀerent ways. Therefore, the symmetry among the forces at higher
temperatures was broken as the universe cooled. Only the weak and
electromagnetic forces were still interwoven. At 1015 Kelvin, the uni-
verse went through another phase transition that aﬀected the electro-
magnetic and weak forces. At this temperature, they too crystallized

Symmetry and Complexity in Physical Sciences
149
gravitation
GUT
electro-
weak
strong interaction
weak interaction
electromagnetic
interaction
energy
temperature
Planck-time
cosmic age
established physics
10 GeV
19
10 K
32
10 sec
-43
10 GeV
14
10 K
27
10 sec
-35
10 K
15
10 sec
-12
100GeV
Fig. 42.
Bifurcation tree of cosmic symmetry breaking [3.26]
out from their previous, more symmetric union. A bifurcation tree of
spontaneous symmetry breaking led to the emergence of the familiar
physical forces during phase transitions of the expanding and cooling
early universe.
The standard model of symmetry breaking in quantum ﬁeld the-
ory uses a Yang–Mills theory of quantum forces and the so-called
Higgs mechanism [3.27]. The historical Yang–Mills theory with gauge
symmetry proceeds on the assumption of the unlimited range of all
the forces it describes. But, except for the photons of the electro-
magnetic force and the gravitons of gravitation, no massless parti-
cles occur in nature, with which interaction could be transmitted
over unlimited ranges.
Therefore, the Higgs mechanism describes
a procedure of spontaneous symmetry breaking which results in the
desired massive gauge particles. For a uniﬁcation of the SU(2)×U(1)
symmetry, four gauge ﬁeld quanta are necessary. According to the
Higgs mechanism, three of them are required to become massive for
weak interaction, while the fourth gauge particle is the photon of
electromagnetic interaction, which is massless and transmitted with
the speed of light.

150
Symmetry and Complexity
A uniﬁcation of strong, weak and electromagnetic forces with
SU(3), SU(2) and U(1) symmetries is mathematically described by
a SU(5) symmetry. If this symmetry of strong-weak-electromagnetic
force is spontaneously broken, then the intermediate particles of in-
teraction (analogous to the gauge particles of the weak interaction)
take on large masses. At ﬁrst, only the strong SU(3) interactions with
the quarks could be distinguished from the electro-weak SU(2)×U(1)
interactions of the leptons. During further expansion of the universe
with decreasing temperature, these symmetries were also broken, and
the forces act in the manner currently observed. It would be obvi-
ous, for the conﬁrmation of the SU(5) uniﬁcation to generate the
X-particles at high energy in the laboratory, as was done previously
for the intermediate vector bosons of the SU(2) × U(1) uniﬁcation.
Since such a process requires energies which are approximately 13 or-
ders of magnitude greater than the energies required to generate the
SU(2)×U(1) vector bosons (approximately 100 GeV), this method of
testing the theory remains hypothetical. Analogous to the β-decay
of the weak interaction, we still hope to observe a virtual X-particle
during an elementary particle process. Such a process is predicted
by the SU(5) theory for the decay of the proton, when a quark is
transformed into a lepton.
During the ﬁrst stage of symmetry breaking at about the Planck-
time, three of the curled-up spatial dimensions are singled out for
expansion, while all others retain their initial Planck-scale size. The
question arises why only three of the space dimensions have expanded
to observably large size. If we imagine two point particles moving
with diﬀerent velocity along a 1-dimensional line, they will sooner
or later collide. If they are randomly rolling around a 2-dimensional
plane, it is likely that they will never collide. In three or higher num-
ber of dimensions, a meeting of the two particles gets increasingly
unlikely. An analogous idea holds if the point particles are replaced
with loops of string, wrapped around spatial dimensions. The rapid
expansion in three dimensions is explained by the so-called inﬂation-
ary period of the universe. During a tiny window of time, around

Symmetry and Complexity in Physical Sciences
151
10−36 to 10−34 seconds after the Big Bang, the universe expanded
by a colossal factor of at least 1030.
The quantum theory of the inﬂationary period assumes an early
state of the universe with small size, but very high energy (“quan-
tum vacuum”) that expands very rapidly to macroscopic dimensions
driven by a repulsive force of the quantum vacuum state (“anti-
gravity”) [3.28]. This cosmic phase transition allows one to explain
some well-known properties of the observed universe such as the rel-
atively homogeneous distribution of stars and matter. During the
inﬂationary period, some tiny deviations from symmetry and uni-
formity would have been ampliﬁed until they were big enough to
account for the observed structures of the universe. In the expand-
ing universe the density of matter varied slightly from place to place.
Thus, gravity would have caused the denser regions to slow down
their expansion and start contracting. These local events led to the
formation of stars and galaxies.
According to A. Linde, the brief but crucial burst of inﬂationary expansion
may not have been a unique event. Instead, the conditions for inﬂationary expan-
sion may happen repeatedly in isolated regions, which then undergo their own
inﬂationary expansions, evolving into new, separate universes. Linde suggests
a multiuniverse, generating a never ending web of ballooning cosmic expanses.
Separating universes mean bifurcation and symmetry breaking. Thus, a multiu-
niverse is the ultimate version of cosmic symmetry breaking: In the beginning
there was endless symmetry breaking. Whereas we assume a consistent and uni-
form physics in our universe, this may have no bearing on the physical attributes
in these other universes. The list of elementary particles and forces may be com-
pletely distinct from ours. If we assume superstring theories, even the number of
extended dimensions may diﬀer with diﬀerent possibilities of interacting strings
and particles. If our universe is not alone but is instead interwined with a fractal
“multiverse”, along with many other bifurcating universes, then we could think
about “interuniversal” routes between the universes. According to Heisenberg’s
principle of uncertainty, quantum ﬂuctuations could open short-lived wormholes
in space-time. So, the laws of quantum dynamics make it at least conceivable that
wormholes can be employed as links between separated and bifurcating universes.
Only upon cooling did the early symmetry of the universe break
apart into increasingly partial symmetries, and the individual parti-
cles were crystallized in stages. For example, it would be conceiv-

152
Symmetry and Complexity
able in terms of physics that after the end of the ﬁrst epoch, the
original symmetry had dissolved into the local subsymmetry of grav-
itation and the symmetry of the other forces [3.29]. In the SU(5)
symmetry of the weak, strong and electromagnetic forces, quarks
and leptons are still being transformed. The intermediate particles
of interaction play the most important role. Ultimately, the SU(5)
symmetry decays into the SU(3) symmetry of the strong forces and
the SU(2) × U(1) symmetry of the weak and electromagnetic forces.
Quarks and leptons thus become identiﬁable particles. Ultimately,
the SU(2)×U(1) symmetry also decays into the SU(2) subsymmetry
of the weak interaction and the U(1) subsymmetry of the electro-
magnetic interaction. The atomic nuclei of electrons, neutrinos etc.
become identiﬁable particles.
Below certain temperatures that correspond to certain average
distances, the coupling constants of the various interactions became
distinguishable. As a result of related, gradual and spontaneous sym-
metry breaking, the universe became asymmetrical and manifold.
Finally, we should note a few “fossils” of these past symmetry break-
ings. The parity violation, i.e. the preference for one direction in
space, like that which occurs during the β-decay of the weak inter-
action, as explained above, is a relic of the SU(2) × U(1) symmetry
breaking.
An additional remarkable asymmetry of the current universe is
the surplus of matter over antimatter [3.30]. This fact can now be
understood as a consequence of the breaking of the SU(5) symme-
try. After the collapse of the SU(5) symmetry, more quarks than
antiquarks might have been formed during the exchange of the inter-
mediate particles, because the quarks decayed somewhat more slowly
than the antiquarks. Later, after matter and antimatter had been
mutually annihilated, there was a small surplus of protons and elec-
trons, from which the stars, the earth and life on earth evolved. In a
future stage of development of the universe, however, this temporary
“surplus” of matter, on which our existence depends, could disappear
again, speciﬁcally if the protons are annihilated. Of course, given the
estimated lower bound for the average life of a proton, which is 1031

Symmetry and Complexity in Physical Sciences
153
years, the decay period of matter seems enormously long, but it is
still physically conceivable and experimentally veriﬁable.
It is remarkable that with the SU(5) symmetry breaking, the dis-
crete CP symmetry must also be violated. Of course, the CP sym-
metry says that all physical laws remain valid in a reﬂected world if,
in addition to the reﬂection (P), all the particles are replaced by their
antiparticles (C). If CP symmetry were to be always valid, then from
an initial equilibrium of matter and antimatter, a predominance of
one of the two parts could never have developed. For each origin of
a particle, there would then be an equally probable reﬂected process
in which the corresponding antiparticle would be formed. As noted
above, violations of CP symmetry can be experimentally veriﬁed
during the decay of the K◦meson.
Early cosmic evolution was a ﬁrst example of phase transitions in
which matter transforms from one structural state to another. We al-
ready emphasized the analogies of the early cosmic phase transitions
with the familiar condensation of gases and the freezing of liquids.
The diﬀerent order of the molecules on the microlevel is a cause of
a new feature of the material on the macroscopic level. Condensa-
tion and freezing relate to a complex state of molecules and cannot be
reduced to a single molecule. In this sense, phase transitions are con-
nected with the emergence of new macroscopic features of a system.
Consider, for example, a ferromagnet losing its magnetization, when
it is heated beyond a critical value. Magnetization is a macroscopic
feature that can be explained by changing the degrees of freedom
at the microscopic level. The ferromagnet consists of many atomic
magnets. At elevated temperature, the elementary magnets point
in random directions. If the corresponding magnetic moments are
added up, they cancel each other. Then, on the macroscopic level,
no magnetization can be observed. Below a critical temperature, the
atomic magnets are lined up in a macroscopic order, giving rise to
the macroscopic feature of magnetization.
In these kinds of phase transition, the emergence of macroscopic
order was caused by lowering temperature, but by maintaining a ﬂux
of energy and matter through them. Familiar examples are living sys-

154
Symmetry and Complexity
tems like plants and animals that are fed by biochemical energy. The
processing of this energy may result in the formation of macroscopic
patterns like the growth of plants, locomotion of animals, and so
on. But this emergence of order is by no means reserved to living
systems. It is a kind of dissipative (irreversible) self-organization far
from thermal equilibrium that can be found in physics and chemistry
as well as in biology.
Emergence of order seems to contradict the second law of ther-
modynamics. According to that famous law, closed systems without
any exchange of energy and matter with their environment develop
to disordered states near thermal equilibrium. The degree of dis-
order is measured by a quantity called “entropy.” The second law
says that in closed systems the entropy always increases to its max-
imal value. For instance, when a cold body is brought into contact
with a hot body, then heat is exchanged so that both bodies acquire
the same temperature, i.e. a disordered and homogeneous order of
molecules. When a drop of milk is put into coﬀee, the milk spreads
out to a ﬁnally disordered and homogeneous mixture of milky coﬀee.
The reverse processes are never observed [3.31].
In this sense, processes according to the second law of thermo-
dynamics are irreversible with a unique direction of time. But the
symmetry of time is only broken on the macrolevel without contra-
diction to the time reversibility of other physical laws (e.g. quantum
mechanics).
The second law of thermodynamics refers to macro-
scopic distributions of particles (e.g. molecules of a gas) and their
time-depending development that is irreversible with high probabil-
ity.
On the microlevel, the equations of the particles are still re-
versible (microreversibility). Basically, the thermodynamic arrow of
time is explained by the global expansion of the whole universe lead-
ing from states of symmetry to symmetry breaking and diversity with
increasing entropy [3.32]. But, in a global sea of entropy, local islands
of new order like, e.g. stars, planets and life emerge and disappear.
How is that possible?
The emergence of order is made possible by phase transitions of
open systems interacting with their environment. In hydrodynamics,

Symmetry and Complexity in Physical Sciences
155
the formation of weather and turbulences are classical examples. The
earth, warmed by the sun, heats the atmosphere from below. Outer
space, which is always cold, absorbs heat from the outer shell of the
atmosphere.
The lower layer of air tries to rise, while the upper
layer tries to drop.
This traﬃc of layers was modeled in several
experiments by H. B´enard. The air currents in the atmosphere can be
visualized as cross-sections of the layers. The traﬃc of the competing
warm and cold air masses is represented by circulation vortices, called
B´enard cells. In three dimensions, a vortex may have warm air rising
in a ring, and cold air descending in the center. Thus, the atmosphere
consists of a sea of 3-dimensional B´enard cells, closely packed as a
hexagonal lattice. A footprint of such a sea of atmospheric vortices
can be observed in the regular patterns of hills and valleys in deserts,
snowﬁelds or icebergs.
In a typical B´enard experiment, a ﬂuid layer is heated from below
in a gravitational ﬁeld (Fig. 43a). The heated ﬂuid at the bottom
tries to rise, while the cold liquid at the top tries to fall.
These
motions are opposed by viscous forces. For small temperature dif-
ferences ∆T, viscosity wins, the liquid remains at rest, and heat is
transported by uniform heat conduction. The external control pa-
rameter of the system is the so-called Rayleigh number Ra of velocity,
which is proportional to ∆T. At a critical value of Ra, the state of
the ﬂuid becomes unstable, and a pattern of stationary convection
rolls develops (Fig. 43b). Beyond a greater critical value of Ra, a
transition to chaotic turbulence is observed [3.33].
Another example from ﬂuid dynamics is the ﬂow of ﬂuid round a
cylinder. The external control parameter is the Reynolds number Re
(a)
(b)
Fig. 43.
Phase transition and symmetry breaking of a B´enard experiment

156
Symmetry and Complexity
of ﬂuid velocity. At low speed the ﬂow happens in a homogeneous
manner (Fig. 44a).
At higher speeds, a new macroscopic pattern
with two vortices appears (Fig. 44b). With yet higher speeds the
vortices start to oscillate (Fig. 44c–d). At a certain critical value,
the irregular and chaotic pattern of a turbulence ﬂow arises behind
the cylinder (Fig. 44e).
Fig. 44.
Phase transitions of ﬂuid dynamics [3.34]

Symmetry and Complexity in Physical Sciences
157
(a)
(b)
Fig. 45.
Phase transitions of a laser [3.35]
A famous example from modern physics and technology is the
laser. A solid state laser consists of a rod of material in which spe-
ciﬁc atoms are embedded.
Each atom may be excited by energy
from outside leading it to the emission of light pulses. Mirrors at
the end faces of the rod serve to select these pulses. If the pulses
run in the axial direction, then they are reﬂected several times and
stay longer in the laser, while pulses in diﬀerent directions leave it.
At small pump power the laser operates like a lamp, because the
atoms emit independently of each other light pulses (Fig. 45a). At
a certain pump power, the atoms oscillate in phase, and a single
ordered pulse of gigantic length emerges (Fig. 45b). The laser is an
example of macroscopic order emerging from phase transitions. With
exchange and processing of energy, the laser is obviously a dissipative
system.
Phase transitions in dissipative systems generate a bifurcation
tree with emerging structures of increasing complexity. In this con-
text, the degrees of increasing complexity are deﬁned by the increas-
ing bifurcations that lead to chaos as the most complex and fractal
scenario. Each bifurcation illustrates a possible branch of solution
for the nonlinear equation. Physically, they denote phase transitions
from a state of equilibrium to new possible states of equilibria. If
equilibrium is understood as a state of symmetry, then phase transi-
tion means symmetry breaking being caused by ﬂuctuational forces.

158
Symmetry and Complexity
Mathematically, symmetry is deﬁned by the invariance of certain
laws with respect to several transformations between the correspond-
ing reference systems of an observer. The hydrodynamical laws de-
scribing a ﬂuid layer heated from below (Fig. 43a) are invariant with
respect to all horizontal translations. Nevertheless, these highly sym-
metric laws allow phase transitions to states with less symmetry. For
example, in the case of a B´enard experiment, the heated ﬂuid layer
becomes unstable, and the state of stationary convection rolls de-
velops (Fig. 43b). This phase transition means symmetry breaking,
because tiny ﬂuctuations cause the rolls to prefer one of two possible
directions. Our examples show that phase transition and symme-
try breaking is caused by a change of external parameters and leads
eventually to a new macroscopic spatio-temporal pattern of the sys-
tem and emergence of order. Obviously, thermal ﬂuctuations bear in
themselves an uncertainty, or more precisely speaking, probabilities.
A particle that is randomly pushed back or forth (Brownian motion)
can be described by a stochastic equation governing the change of
the probability distribution as a function of time. Fluctuations are
caused by a huge number of randomly moving particles. An example
is a ﬂuid with its molecules. Therefore, a bifurcation of a stochastic
process can only be determined by a change of probabilistic distri-
bution and stochastic symmetry breaking. In general, the emergence
of structures in the universe is made possible by decreasing symme-
try (“symmetry breaking”) and increasing complexity during phase
transitions.
3.3
Complexity, Attractors and Dynamical Systems
Emerging structures and entities in nature correspond to solutions of
nonlinear diﬀerential equations modeling the time-depending evolu-
tion of dynamical systems. Why is nonlinearity a (necessary) reason
for the emergence of new structures in dynamical systems? In the
case of a linear equation, the sum of two solutions is also a solution
of the equation. This property is often expressed with the statement:
the whole is equal to the sum of its parts. Thus, the task of ﬁnding

Symmetry and Complexity in Physical Sciences
159
the general solution for a linear diﬀerential equations can be bro-
ken up into a collection of simpler problems. The threads of causal
developments can more easily be separated and sorted out. In non-
linear systems, such a resolution is not possible because the sum of
two solutions is in general not a solution of the nonlinear equation:
the whole is often greater than the sum of its parts. The whole is
a new dynamic entity and not only a collection of elements. Thus
nonlinearity becomes a source of emergent phenomena.
An example of hydrodynamics is the emergence of solitary waves
from the nonlinear dynamics of water waves. In an experiment, a
solitary wave can be created in a water tank [3.36].
We consider
a column of water that is accumulated at one end of the tank.
Release of this water by lifting a sliding panel generates a solitary
wave that travels to the other end of the tank with the same speed
and amplitude. The traveling wave corresponds to an exact solution
of a nonlinear diﬀerential equation modeling the wave dynamics in
the tank. The equation depends on the speed of amplitude waves
and their dispersion that is determined by, for example, surface ten-
sion and the density of water.
The shape of the solitary wave is
made possible, because its eﬀects of dispersion are in balance with
those of nonlinearity. The eﬀect of dispersion is to spread out the
energy of the traveling pulse and the eﬀect of nonlinearity is to draw
it together.
Spreading out and drawing together of energy forms a causal loop
that generates a new dynamic entity.
Causal loops correspond to
nonlinear dynamics that cannot be separated into their parts. It is
their dynamic interaction that produces emerging phenomena. Soli-
tary waves are examples of Einstein’s vision that the emergence of
entities in nature can be explained by exact solutions of nonlinear
diﬀerential equations. There is an arbitrary number of solitary waves
with varying speeds and amplitudes which even undergo a collective
collision. In this case, they leave the interaction region of space-time
with the same speeds and amplitudes that they had upon entry.
Therefore, solitary waves are now called solutions, emphasizing their
particle-like character.

160
Symmetry and Complexity
Hydrodynamic solitary waves are examples of dynamical entities
conserving their energy. But there are also solitary waves that are
generated by a dynamic balance between nonlinear and dissipative
eﬀects. An example is the emergence of the ﬂame of a candle. In
a lighted candle, heat generated by the ﬂame diﬀuses into the solid
wax, causing the release of a vapor that carries energy upward into
the ﬂame. Combustion of the vaporized wax provides the heat. The
closed causal loop between thermal diﬀusion and nonlinear energy
release generates a traveling-wave, moving down the candle at a ﬁxed
speed. This kind of causal loop is an example of nonlinear reaction–
diﬀusion process that cannot only be observed in physics, but also
in chemistry and biology.
Roughly speaking, we distinguish conservative (“closed”) and dis-
sipative (“open”) dynamical systems. More precisely, conservative
as well as dissipative systems are characterized by time-depending
nonlinear diﬀerential equations depending on an external control pa-
rameter that can be decreased and increased to critical values. As
we mentioned in previous sections, Hamiltonian-like equations can be
used to characterize any conservative dynamical system. Its fruitful
idea is to characterize a conservative system by a Hamiltonian func-
tion (or operator), which is the expression for the total energy (which
is the sum of kinetic and potential energy) of the system in terms of
all the position and momentum variables.
The corresponding state spaces allow us the evolution of the dy-
namical systems in each “phase.” Thus, they are called phase spaces.
For systems with n particles, phase spaces have 3n+3n = 6n dimen-
sions. A single point of a phase space represents the entire state of
a perhaps complex system with n particles. The Hamiltonian equa-
tions determine the trajectory of a phase point in a phase space.
Globally, they describe the rates of change at every phase point, and
therefore deﬁne a vector ﬁeld on the phase space, determining the
whole dynamics of the corresponding system.
It is a well-known fact from empirical applications that states
of dynamical models cannot be measured with arbitrary exactness.
The measured values of a quantity may diﬀer by tiny intervals being

Symmetry and Complexity in Physical Sciences
161
caused by the measuring apparatus, constraints of the environment,
and so on. The corresponding phase points are concentrated in some
small regions of a neighborhood. Now, the crucial question arises if
trajectories starting with neighboring initial states are locally stable
in the sense that they have neighboring ﬁnal states. In this case,
similar initial states lead to similar ﬁnal states. This assumption is
nothing else than a classical principle of causality in the language of
Hamiltonian dynamics: similar causes lead to similar eﬀects.
Due to a theorem of the French mathematician J. Liouville, the
volume of any region of the phase space must remain constant under
any Hamiltonian dynamics, and thus for any conservative dynamical
system. But its conservation does not exclude that the shape of the
initial region is distorted and stretched out to great distances in the
phase space. We may imagine a drop of ink spreading through a
large volume of water in a container. That possible spreading eﬀect
in phase spaces means that the local stability of trajectories is by
no means secured by Liouville’s theorem. A very tiny change in the
initial data may still give rise to a large change in the outcome [3.37].
Nevertheless, Liouville’s theorem implies some general conse-
quences concerning the regions which can be displayed by Hamilto-
nian dynamics, and thus by conservative systems. The mathematical
pendulum without friction is a perfect conservative system without
any loss of energy. As there is no friction, moving the pendulum a
little to the left causes it to swing back and forth indeﬁnitely. The
full trajectory in the state space, corresponding to this oscillating
motion, is a cycle or closed loop around a vortex point of equilib-
rium which is not an attractor (Fig. 46b). If the system is not closed
and the eﬀects of friction are included as in physical reality, then the
equilibrium point at the origin is no longer a vortex motion of the
point (Fig. 46a). It has become a spiraling type of point attractor.
As any motion of the pendulum will come to rest because of friction,
any trajectory representing a slow motion of the pendulum near the
bottom approaches this limit point asymptotically.
In Fig. 46a, trajectories are attracted to a ﬁeld point, and the
volume of an initial area shrinks. In Fig. 46b, the trajectories rotate

162
Symmetry and Complexity
Fig. 46a.
Fixed point attractor
Fig. 46b.
Vortex point of oscillation
around a vortex point, and the volume of an initial area is conserved.
Thus, due to Liouville’s theorem, we can generally conclude that in
any conservative system attracting points must be excluded. The
eﬀect of shrinking initial areas can easily be visualized for the tra-
jectories of limit cycles, too. Therefore, limit cycles as attractors are
also not possible in conservative systems for the same mathematical
(a priori) reasons [3.38].
A further mathematical result of Hamiltonian (conservative) sys-
tems says that there are irregular and chaotic trajectories. In the
18th and 19th centuries, physicists and philosophers were convinced
that nature is determined by Newtonian- or Hamiltonian-like equa-
tions of motion, and thus future and past states of the universe can be
calculated at least in principle if the initial states of present events are
well known. Philosophically, this belief was visualized by Laplace’s
demon, which like a huge computer without physical limitations can
store and calculate all necessary states. Mathematically, the belief in
Laplace’s demon must presume that systems in classical mechanics
are integrable, and, thus are solvable.
In 1892, Poincar´e was al-
ready aware that the non-integrable three-body problem of classical
mechanics can lead to completely chaotic trajectories [3.39]. About
sixty years later, A.N. Kolmogorov (1954), V.I. Arnold (1963) and
J. Moser (1967) proved with their famous KAM theorem that motion
in the phase space of classical mechanics is neither completely regu-

Symmetry and Complexity in Physical Sciences
163
lar nor completely irregular, but that the type of trajectory depends
sensitively on the chosen initial conditions [3.40].
Since Poincar´e’s celestial mechanics (1892), it was mathemati-
cally known that some mechanical systems whose time evolution is
governed by nonlinear Hamiltonian equations could display chaotic
motion. But as long as scientists did not have suitable tools to deal
with non-integrable systems, deterministic chaos was considered as
a mere curiosity. During the ﬁrst decades of the 20th century, many
numerical procedures were developed to deal with the mathemati-
cal complexity of nonlinear diﬀerential equations at least approxi-
mately. The calculating power of modern high-speed computers and
reﬁned experimental techniques have supported the recent successes
of the nonlinear complex system approach in natural and social sci-
ences. The visualizations of nonlinear models by computer-assisted
techniques promote interdisciplinary applications with far-reaching
consequences in many branches of science. In this scientiﬁc scenario
(1963), the meteorologist Lorenz a student of the famous mathemati-
cian Birkhoﬀ[3.41], observed that a dynamical system with three
coupled ﬁrst-order nonlinear diﬀerential equations can lead to com-
pletely chaotic trajectories. Mathematically, nonlinearity is a nec-
essary, but not suﬃcient condition of chaos. It is a necessary con-
dition, because linear diﬀerential equations can be solved by well-
known mathematical procedures (Fourier transformations) and do
not lead to chaos. The system Lorenz used to model the dynamics of
weather diﬀers from Hamiltonian systems `a la Poincar´e, mainly by its
dissipativity.
Lorenz’s discovery of a deterministic model of turbulence occurred
during simulation of global weather patterns. The diﬀerential equa-
tions describing the B´enard experiment (Fig. 43) were simpliﬁed by
Lorenz to obtain the three nonlinear diﬀerential equations of his fa-
mous model. Each diﬀerential equation describes the rate of change
for a variable x proportional to the circulatory ﬂuid ﬂow velocity,
a variable y characterizing the temperature diﬀerence between as-
cending and descending ﬂuid elements, and a variable z propor-
tional to the deviation of the vertical temperature proﬁle from its

164
Symmetry and Complexity
Fig. 47.
Strange attractor of Lorenz [3.42]
equilibrium value.
From these equations, it can be derived that
an arbitrary volume element of some surface in the corresponding
phase space contracts exponentially in time. Thus, the Lorenz model
is dissipative.
This can be visualized by computer-assisted calculations of the
trajectories generated by the three equations of the Lorenz model.
Under certain conditions, a particular region in the 3-dimensional
phase space is attracted by the trajectories, making one loop to the
right, then a few loops to the left, then to the right again, etc.
(Fig. 47).
The paths of these trajectories depend very sensitively
on the initial conditions. Tiny deviations of their values may lead to
paths which soon deviate from the old one with diﬀerent numbers of
loops. Because of its strange image, which looks like the two eyes
of an owl, the attracting region of the Lorenz phase was called a
“strange attractor.” Obviously, the strange attractor is chaotic with
fractal dimension. If the attractor is a point (Fig. 46a), the fractal
dimension is zero.
For a stable limit circle (Fig. 46b) the fractal
dimension is one. But for chaotic systems the fractal dimension is
not an integer. In general, the fractal dimension can be calculated

Symmetry and Complexity in Physical Sciences
165
only numerically. For the Lorenz model, the strange attractor has
the fractal dimension D ≈2.06 ± 0.01.
Phase transitions of complex dynamical systems are associated
with the emergence of new structures. Mathematically, they are so-
lutions of nonlinear equations corresponding to a bifurcation tree of
diﬀerent attractors. Thus, we distinguish a hierarchy of structures
with increasing complexity from ﬁxed point attractors, periodic and
quasi-periodic limit cycles up to chaotic attractors. In former days
of history, scientists would have postulated certain demons or mystic
forces leading the elements of these systems to new patterns of order.
In the mathematical approach of complex systems, the emergence of
macroscopic patterns is explained by the interactions of their micro-
scopic elements. Their sometimes mystic “self-organization” happens
in critical situations of the system during phase transitions which
can mathematically exactly be analyzed. We distinguish phase tran-
sitions in thermal equilibrium and in nonequilibrium (“dissipative”)
systems.
An example of a phase transition in thermal equilibrium is real-
ized by a ferromagnet that passes from a disordered state into an
ordered state of its elements if the system is cooled down below a
critical point. To characterize the variation between the macrostates,
L.D. Landau introduced order parameters as macroscopic variables
whose values are ﬁnite in the ordered state and zero in the disordered
state [3.43]. The ordered state occurs in low temperatures in which
the system exhibits a certain macroscopic structure indicated by a
ﬁnite order parameter. When the macroscopic structure is destroyed
by the random motion of the elements at increased temperatures,
then the order parameter will vanish. In the case of the ferromagnet,
the order parameter is the average magnetization, which vanishes in a
state above the Curie-point of temperature. Below the Curie-point,
the atomic dipoles arrange in a regular pattern on the microlevel
corresponding to the state of magnetization on the macrolevel. In
this case, the ferromagnet is in an equilibrium state corresponding
to a ﬁxed point attractor. For the gas–liquid transition, the order
parameter is the diﬀerence in the densities of the gas and the liquid.

166
Symmetry and Complexity
Landau distinguishes discontinuous and continuous phase transitions. In dis-
continuous phase transitions, the order parameter jumps at the transition point
with a ﬁnite diﬀerence of the new and past state. In continuous phase transitions,
the order parameter decreases continuously to zero and the diﬀerence between the
two phases becomes inﬁnitesimal small at the transition point. The transition of a
system can be discontinuous or continuous under diﬀerent conditions. For exam-
ple, the condensation of gases is a discontinuous phase transition at low pressures
and a continuous transition at the critical point. At one atmospheric pressure
and 100 degrees Celsius, the densities of steam and water diﬀer by a large factor.
As the pressure increases, the density diﬀerence decreases and ﬁnally vanishes at
the critical point of 217 atmospheres and 374 degrees Celsius. At pressures above
the critical point there are no distinct gas and liquid phases. A ferromagnet is an
example of continuous phase transition.
Pattern formation in dissipative systems can also be explained
by the concept of order parameters [3.44].
We start with an old
structure, for instance, a homogeneous ﬂuid or randomly emitting
laser. In an open system the instability of an old structure is caused
by an increasing input of energy (e.g. increasing velocity of a ﬂuid
or increasing energy pumping of a laser [3.45]). The old structure
breaks down and the system takes a new equilibrium point of sta-
bility which is associated with the emergence of a new macroscopic
pattern of order. With increasing input of energy the system is driven
to new bifurcations of equilibria with the emergence of new macro-
scopic patterns of order with increasing complexity from ﬁxed points
to limit cycles and chaos attractors [3.46]. That is the usual bifurca-
tion tree of nonequilibrium dynamics in open (dissipative) systems
(Fig. 48).
How does the concept of order parameters come in?
Close to
an instability point we can distinguish between elements with sta-
ble and unstable behavior (modes) on the microlevel of the system.
The few unstable modes grow to amplitudes of macroscopic scale and
inﬂuence the stable ones. They become macroscopic order param-
eters dominating the whole macrodynamics of the complex system
(Fig. 49). Thus, it is suﬀcient to analyze some few order parameters
to understand the macrodynamics of a complex system with many
elements.

Symmetry and Complexity in Physical Sciences
167
Fig. 48.
Bifurcation and emergence of order
Fig. 49.
Self-organization and order parameters
Mathematically, the nonequilibrium dynamics of order param-
eters can be modeled by the well established method of a linear-
stability analysis (Fig. 49) [3.47]. On the microlevel, we start with a
nonlinear equation dx/dt = F(x, α) + f(t) of evolution with a non-
linear function F of the microstates x = (x1, . . . , xn) of the elements
and a control parameter α at time t. The function f(t) represents
small stochastic forces with additional external eﬀects on the sys-

168
Symmetry and Complexity
tem which will be ignored in the following. The behavior of stability
is mainly determined by the reaction of a system to perturbations.
Therefore, we consider any well-known state for a given value α0 of
the control parameter and analyze the dynamic behavior of the sys-
tem in the vicinity of an instability after a small shift of the control
parameter from α0 to α. In this case, the behavior of the system cor-
respond to a solution x(t) = x0 + w(t) with the stationary solution
x0 (which means F(x0, α) = 0) and a small deviation w(t) from the
stationary solution x0.
In order to analyze the question of whether x0 remains a sta-
ble solution of the microscopic evolution equation or whether there
evolves another dynamics after the shift from α0 to α, the solu-
tion x(t) = x0 + w(t) is inserted into dx/dt = F(x, α).
In a
next step, we expand the evolution equation F(x0 + w(t), α) into a
Taylor series with respect to the deviation w(t). As F(x0, α) = 0, we
obtain the equation dw/dt = L(x0, α)w + N(x0, α, w) with the term
L for all linear terms and N for all nonlinear terms with second and
higher expansion terms. As long as the deviations w(t) are small,
one can neglect the higher terms and only analyze the approximate
linearized equation dw/dt = L(x0, α)w. The problem of stability is
now reduced to a linear equation which can be solved by elementary
methods.
By analyzing the corresponding eigenvalue equation, the linear-
stability analysis allows to distinguish between unstable and stable
elements on the microscopic level. Their unstable modes grow ex-
ponentially with time so that the linearized equation of evolution
becomes invalid. The stationary solution becomes unstable and the
corresponding linearized term of deviation must be substituted by
an equation distinguishing between the amplitudes of the unstable
modes and those of the stable ones. While the amplitudes of unsta-
ble modes begin to increase exponentially, the stable modes decrease
exponentially. The unstable amplitudes grow to macroscopic order
and thus become order parameters of the system.
H. Haken called this process a “slaving principle” because the
stable modes are “enslaved” by the unstable modes.
Mathemati-

Symmetry and Complexity in Physical Sciences
169
cally, the adaption behavior of the stable modes to the unstable ones
can in a ﬁrst approximation be described by a so-called adiabatic
elimination.
In this case, the stable amplitudes can be expressed
by the unstable ones and in this sense eliminated.
It is suﬃcient
to analyze the macroscopic order parameters of some few unstable
modes to understand the whole dynamics of the system. An immense
reduction of complexity has taken place: instead of dealing with bil-
lions of microscopic equations for all molecules in a ﬂuid or atoms
and photons in a laser it is now suﬃcient to treat the equations for
a few macrovariables or order parameters characterizing collective
patterns of a ﬂuid or light modes and collective atomic behavior in
a laser. The mathematical formalism of linear-stability analysis and
adiabatic elimination can be generalized for huge classes of complex
systems with nonequilibrium dynamics. Thus, order parameters are
a universal instrument to model the emergence of complex structures
in nature.

This page intentionally left blank

Chapter 4
Symmetry and Complexity in
Chemical Sciences
Physics, chemistry and biology have become intimately intertwined.
Theoretical boundaries that historically were once assumed to exist
between inanimate and animate world have turned out to be un-
tenable.
A uniﬁed theory of the natural sciences is beginning to
develop, in which the classical disciplines investigate more or less
complex subsystems having emerged in cosmic evolution. Examples
of increasing complexity and decreasing symmetry are strings, ele-
mentary particles, atomic nuclei, atoms, molecules, crystals, genes
and cells. On the scale of complexity, chemistry is a bridge between
the microworld and macroworld. Chemistry is not just the science
of electrons, atoms and molecules, but also of macroscopic objects
such as crystals and gas clouds. Nevertheless, molecular structures
are a key concept of chemistry with fascinating features of symmetry
and complexity. Molecules have more or less symmetric and com-
plex structures that can be deﬁned in the mathematical framework
of topology, group theory, dynamical systems theory and quantum
mechanics. But symmetry and complexity are by no means only the-
oretical concepts of research. Modern computer aided visualizations
show real forms of matter that nevertheless depend on the techni-
cal standards of observation, computation and representation. Their
symmetries often have aesthetical qualities that seem to be inspired
by the platonic idea of beauty.
4.1
Symmetry in Chemistry
Chemical symmetries depend on molecular structures. The molecu-
lar structure hypothesis states that a molecule is a collection of atoms
171

172
Symmetry and Complexity
linked by a network of bonds. Since the 19th century the molecular
structure hypothesis has been a successful concept of ordering and
classifying the observations of chemistry. But this hypothesis cannot
directly be derived from the physical laws governing the motions of
the nuclei and electrons that make up the atoms and the bonds. It
must be justiﬁed that all atoms exist in molecules as separate deﬁn-
able pieces of the 3-dimensional (“real”) space with properties that
can be predicted and computed by the laws of quantum mechanics.
The well-known models of molecules with diﬀerent information for a
chemist are derived from the molecular structure hypothesis: (1) The
3-dimensional ball-and-stick model with balls for the atomic nuclei,
sticks for the atomic bonds and their angles, (2) its 2-dimensional
representation as structural formula, and (3) its 1-dimensional repre-
sentation as linguistic name which can be derived from the structural
formula.
Graphic models are applications of mathematical graph
theory that is a part of combinatorical topology. This mathemati-
cal theory became fundamental for chemistry, when in the midst of
the last century the molecular structure of chemical substances were
discovered [4.1]. Pasteur recognized that the relationship between
symmetry of reﬂection and optical activity is not a function of the
crystal structure of a substance. With certain water-soluble crystals,
for example, the symmetry of reﬂection can be demonstrated both
in the solid state and in the liquid state. Pasteur investigated tar-
taric acid and found a counterclockwise and a clockwise form, which
are called L-tartaric acid and D-tartaric acid (D = dextro = right)
respectively. He also isolated a third form of tartaric acid (meso-
tartaric acid), which cannot be separated into one of the other forms.
To explain the optical activity, it was therefore necessary to inves-
tigate more fundamental structures than crystals or even molecules
and the orientation of atoms. R.J. Ha¨uy had already suspected that
the form of crystals and their constituent components were images
of one another. Pasteur therefore inferred the symmetric form of the
crystal’s components from the crystal reﬂections [4.2].
Another important step was Kekul´e’s investigation of quadriva-
lent carbon atoms, for whose multiple bonds he also introduced a
structural formula notation being still used in today’s organic chem-

Symmetry and Complexity in Chemical Sciences
173
istry [4.3]. An essential advance occurred in 1864, when the Edin-
burgh chemist A. Crum Brown introduced his version of the graphic
notation. Each atom was shown separately, represented by a letter
enclosed in a circle, and all single and multiple bonds were marked
by lines joining the circles. Crum Brown’s system is more or less the
one in use today, except that the circles are now usually omitted. His
notation was soon accepted everywhere, after some resistance from
Kekul´e and others. Its acceptance was partly due to its success in ex-
plaining the strange fact that there are pairs of substances that have
the same chemical composition, although their physical properties
are diﬀerent. The graphic notation made it clear that this is because
the atoms are arranged in diﬀerent ways in the diﬀerent substances.
This well-known chemical phenomenon is called isomerism, and in
many cases there are more than two isomers with the same constitu-
tional formula. In 1874, the great British mathematician A. Cayley
wrote a paper “On the mathematical theory of isomers” inspired by
the fusion of chemical and mathematical ideas. But the experiments
of J.H. van’t Hoﬀand J.A. Le Bel were decisive for the assumption
of a 3-dimensional molecular structure [4.4]. In 1874, independently
of one another, they established a relationship between optical activ-
ity and 3-dimensional orientation of atoms. The initial example was
the carbon atom, whose four valences were arranged in the form of
a tetrahedron. A tetrahedral conﬁguration with the carbon atom in
the center makes possible the existence of two diﬀerent arrangements
being mirror images of each other (Fig. 50a). Tartaric acid has two
carbon atoms which are each connected to the atoms or groups of
atoms H, C, OH and COOH. For this combination, there are two
arrangements (L- and D-tartaric acid) being mirror images of each
other and one arrangement (meso-tartaric acid) which is reﬂective
symmetric in itself (Fig. 50b).
Van’t Hoﬀ’s stereochemistry regarding the 3-dimensional struc-
ture of the atom must initially have appeared to a highly speculative
idea, which betrayed a certain proximity to Platonic forms. Kekul´e
may have been particularly adept at 3-dimensional visualization as a
result of his prior study of architecture. Simultaneously with stere-
ochemistry, geometry and algebra were also undergoing a fruitful

174
Symmetry and Complexity
Fig. 50a.
Symmetry of carbon atom with tetrahedral structure
Fig. 50b.
Symmetry of L-, D-, and meso-tartaric acid

Symmetry and Complexity in Chemical Sciences
175
development [4.5]. Van’t Hoﬀ’s success in experimental explanation
and prediction made his geometry and algebra of the molecules soon
a method accepted by chemists. But it lacked any deﬁnitive physical
justiﬁcation. At this stage of development, stereochemistry remains
a successful heuristic approach meeting chemists’ need for a means
by which they can visualize their structural analyses.
From an experimental point of view the shape of molecules can be
illustrated by an outer envelope of their electronic charge distribu-
tions. These representations are similar to the pictures of atoms that
we can today obtain experimentally by the scattering of electrons in
super microscopes or from the scanning tunnelling electron micro-
scope. It is the distribution of charge that scatters the X-rays or
electrons in these experiments. Thus, it is the distribution of charge
that determines the form of molecular matter in 3-dimensional space.
Mathematical methods of diﬀerential topology enable us to iden-
tify atoms in terms of the morphology of the charge distribution. The
charge density p(r) is a scalar ﬁeld over 3-dimensional space with
a deﬁnite value at each point. Positions of extrema in the charge
density with maxima, minima or saddles where the ﬁrst derivatives
of p(r) vanish can be studied in the associated gradient vector ﬁeld
∇p(r). Whether an extremum is a maximum or a minimum, is deter-
mined by the sign of the second derivative or curvature at this point.
The gradient vector ﬁeld makes visible the molecular graph with a
set of lines linking certain pairs of nuclei in the charge distribution.
Local maxima of electronic charge distribution are found only at
the positions of nuclei. This is an observation based on experimental
results obtained from X-ray diﬀractions and on theoretical calcula-
tions on a large number of molecular systems. Thus, a nucleus seems
to have the special role of an attractor in the gradient vector ﬁeld of
the charge density. In short: the topology of the measurable charge
density deﬁnes the corresponding molecular structure.
In the mathematical framework of dynamical systems theory the
global arrangements of molecular forces can be represented by phase
portraits with attractors as nuclei and trajectories representing the
vector ﬁeld. For example, Fig. 51 shows maps with nuclei and the
symmetric structure of the ethylene molecule. Only those trajecto-

176
Symmetry and Complexity
ries are shown which terminate at the position of the nuclei. They
deﬁne the basins of the nuclear attractors. In Fig. 51a only those
trajectories are shown which terminate at the position of the nuclei.
They deﬁne the basins of the nuclear attractors. Fig. 51b includes
the trajectories terminating and originating at certain critical points
(denoted by full circles) in the charge distribution. The pair of tra-
jectories terminating at these critical points mark the intersection
of an interatomic surface with the plane of the ﬁgure. The gradient
paths originating at these critical points and deﬁne the bond paths
are shown by the heavy lines. Fig. 51c shows a superposition of the
trajectories associated with these critical points on a contour map of
the charge density. These trajectories deﬁne the boundaries of the
atoms in the nuclear graph.
In general: the molecular graph is the network of bond paths link-
ing pairs of neighboring nuclear attractors. An atom, free or bound,
is deﬁned as the union of an attractor and its basin. Atoms, bonds
and structure are topological consequences of a measurable molecu-
lar charge distribution. In a next step, it is necessary to demonstrate
that the topological atom and its properties have a basis in quan-
tum mechanics.
Topological atoms and bonds have a meaning in
real 3-dimensional space. But this structure is not reﬂected in the
properties of the abstract inﬁnite-dimensional Hilbert space of the
molecular state function. The state function ψ contains all of the in-
formation that can be known about a nuclear quantum system. From
an operational point of view, there is too much and redundant in-
formation in the state function because of the indistinguishability of
the electrons or because of the symmetry of their interactions. Some
of it is unnecessary as a result of the two-body nature of the Coulom-
bic interaction. Thus, there is a reduction of information in passing
from the state function in the inﬁnite-dimensional Hilbert space to
the charge distribution function in real 3-dimensional space. But, on
the other hand, we get a description of the molecular structure in
the observable and measurable space.
Quantum chemistry uses several mathematical procedures of ap-
proximation to achieve this kind of reduction [4.7]. A well-known
approximation is the Born–Oppenheimer procedure allowing a sepa-

Symmetry and Complexity in Chemical Sciences
177
(a)
(b)
(c)
Fig. 51.
Phase portraits with symmetric structure of the ethylene molecule
rate consideration of the electrons and nuclei of a molecule. We get
the nuclear structure of a molecule beng represented by its struc-
tural formula. In order to distinguish the electrons as quasi-classical
objects in orbitals, the Hartree-Fock method is sometimes an appro-
priate approximation for the electronic state function. The electronic
charge density p(r, X) with the space vector r of an electron and the
collection of nuclear coordinates X can be derived as the quantum
mechanical probability density of ﬁnding any of the electrons in a
particular elemental volume.
In the case of molecules in station-

178
Symmetry and Complexity
ary states, the probability density is deﬁned by the stationary-state
function ψ(x, X) depending on the collection x of electronic space
and spin coordinates and the collection X of nuclear coordinates
[4.8]. This state function is a solution of Schr¨odinger’s stationary
state equation for a ﬁxed arrangement of nuclei. The coincidence of
the topological deﬁnition and the quantum deﬁnition of an atom in a
molecular structure means that the topological atom is an open quan-
tum subsystem of the molecular quantum system, free to exchange
charge and momentum with its environment across boundaries which
are deﬁned in 3-dimensional real space. In this sense, symmetries of
molecules referring to their topological structure are real forms of
matter that can be calculated by quantum chemistry.
Quantum chemistry and mathematical group theory are the mod-
ern bases of symmetry considerations in stereochemistry [4.9].
In
quantum chemistry the symmetries of molecular systems are rep-
resented by the symmetries of the corresponding molecular Hamil-
tonian operators. In stereochemistry the structure of molecules is
classiﬁed by the symmetry transformations of point groups.
The symmetries of a free molecule (Fig. 52) can be completely
deﬁned by a few types of symmetry transformations. In general, the
selection of the three coordinates axes x, y, z is arbitrary. The triv-
ial symmetry transformation is identity I leaving each molecule un-
changed. An additional symmetry element is the axis of rotation Cn
around which a molecule can be rotated by the angle 2π/n without
changing its position. Linear molecules, in which all atomic nuclei
lie on a straight line (e.g. nitrogen N N or carbon monoxide C O),
can be rotated around the connecting axis by arbitrarily small angles
and have a continuous axis of rotation with inﬁnite fold symmetry
n →∞.
An additional symmetry element is the reﬂection CT on a plane
in which the molecule does not change its position. For example, if
the xy-plane is the plane of reﬂection, then replacing all the atomic
z-coordinates by −z does not change the position of the molecule.
Depending on the selection of the plane of reﬂection, a distinction is
made between a vertical plane of reﬂection σn and a horizontal plane
of reﬂection σh.

Symmetry and Complexity in Chemical Sciences
179
Fig. 52.
Symmetries of a free molecule
The next symmetry element is inversion in which a molecule re-
mains unchanged during a reﬂection of all atomic coordinates (x, y, z)
at the point of inversion to (−x, −y, −z). An additional symmetry
element is rotary reﬂection Sn = σhCn in which a molecule is ﬁrst ro-
tated by an angle 2π/n around the rotary reﬂection axis Cn and then
reﬂected on the plane σh perpendicular to Cn through the center of
the molecule, without changing its position.
The remaining symmetry element is rotary inversion in which a
molecule does not change its position in spite of rotation followed
by inversion. It should also be noted that the compound symme-
try transformations of rotary reﬂection and rotary inversion do not
presuppose the partial transformations of rotation, reﬂection or in-
version as symmetry elements of the same molecule. The symmetry
transformations of a molecule, when executed one by one, produce
symmetry transformations.
In general, mathematical symmetries are deﬁnied by automor-
phisms that means self-mappings of ﬁgures or structures whereby

180
Symmetry and Complexity
the structure remains invariant (example: rotation or reﬂection of
polygons in the plane). The composition of automorphisms satisﬁes
the axioms of a mathematical group. So the symmetry of a molecular
structure is deﬁned by its group of automorphisms. There are con-
tinuous groups of symmetries (for instance, circles and spirals) and
discrete groups (for instance, regular polygons, ornaments, Platonic
bodies).
On account of the ﬁnite number of combinations of symmetry el-
ements, it is clear that there can only be a ﬁnite number of point
groups. Thereby many diﬀerent molecules can belong to the same
point group, i.e. they can have the same symmetry structure. The
classiﬁcation of point groups also makes it possible to explain the
relationship of optical activity and molecular structure in terms of
group theory. According to Pasteur a compound had optical activity,
if the molecule in question could not be made to coincide with its
reﬂection. In that case, Pasteur spoke of dissymmetry [4.10]. Other
terms are “enantiomery,” which in the Greek translation means op-
posite shape, or “chirality,” which alludes to the left and right-
handedness of the reﬂective orientation. In terms of group theory,
it is a matter of determining the elements of symmetry leading to
optical activity. In general, (1) a molecule with any axis of reﬂection
Sn cannot be optically active, and (2) a molecule without an axis of
reﬂection is optically active.
Point groups describe the symmetries of stationary molecules in
the equilibrium state. Reduced symmetries may be present in the
non-stationary case of translation, rotational motions, oscillations
etc.
Scalar characteristics such as mass, volume or temperature,
which have only an amount but no direction, are apparently inde-
pendent of the symmetry operations. But characteristics having not
only an amount but also a direction can aﬀect the symmetry.
So far we have discussed the symmetries of the structures of molec-
ular nuclei. What symmetries do determine the electron orbitals of
the molecules?
Molecular orbitals ψ are frequently introduced by
approximation as linear combinations of the atomic orbitals χi, of
the individual atoms of the molecule (Linear Combination of Atomic
Orbitals = LCAO method) with ψ = 
i
ciχi. Kekul´e’s famous ring

Symmetry and Complexity in Chemical Sciences
181
structure of benzene provides a clear example of orbital symmetry.
The ﬂat molecule C6H6 consists of six carbon atoms which form a
regular hexagon, and each of which is bonded to a single H atom.
Each carbon atom has six electrons, two of which are in closed s-
shells, while the others are distributed into s and p orbitals.
In
Fig. 53a, one valence electron of the carbon is required to bond an
H atom. Two valence electrons are required for the σ bond between
the carbon atoms. The σ bonds are produced by a suitable mixing
(hybridization) of the s, px and py atomic orbitals of the carbon.
The fourth valence electron corresponds to the pz orbital, which
is above and below the plane with its two dumb-bells, each perpen-
dicular in the nodes of the carbon atom. The pz orbitals overlap
with their respective neighbors and form a π bond. Fig. 51b shows
a π orbital of benzene. In contrast to the σ bond, the π bond is
weak, so that the π electrons can easily be inﬂuenced by extremal
forces, and thus determine many of the spectroscopic characteristics
of benzene. σ and π orbitals of benzene can be distinguished by their
symmetry behavior in a reﬂection on the xy-plane. While σ orbitals
ϕσ do not change their sign during the reﬂection z →−z and are
therefore symmetric, antisymmetry occurs with the π orbitals ϕπ:
ϕσ(x, y, −z) = ϕσ(x, y, z)
ϕπ(x, y, −z) = −ϕπ(x, y, z)
The system of π electrons oﬀers a simpliﬁed way to calculate
the energy levels of the benzene molecule.
In the H¨uckel model
[4.11], we ﬁrst consider π electrons, since it is assumed that the π
molecule orbitals are signiﬁcantly higher in energy than σ orbitals
and can therefore be considered separately. Calculating ψ orbitals
according to the LCAO method is therefore restricted in the H¨uckel
model to the atomic orbitals χi which form π molecular orbitals.
That is another major simpliﬁcation, of course, but one which has
proven valuable in actual practice, e.g. in the calculation of benzene
orbitals.
The π orbitals of benzene are eigenfunctions of a Hamilton oper-
ator of the π electrons, which is invariant with respect to symmetry

182
Symmetry and Complexity
(a)
(b)
Fig. 53.
Symmetries of electron orbitals
operations of point group D6h of the regular hexagon with horizon-
tal reﬂection σh. Physically, therefore, the potential energy of the n
electrons is not changed when the benzene molecule is rotated, e.g.,
by 60◦around the center. The H¨uckel model and the orbital sym-
metries thereby assumed are also used to predict chemical reactions,
as expressed in the Woodward–Hoﬀmann rules.
One requirement
is that the orbital symmetry is conserved during reactions, i.e., the
symmetry of all occupied orbitals remains unchanged during the re-
action with respect to each symmetry element shared by the reacting
and resulting molecules [4.12].
In contrast to low-molecular chemistry, high-molecular or macro-
molecular chemistry is concerned with compounds which are com-
posed of a great many atoms, and therefore have high molecular
masses [4.13].
From the standpoint of symmetry, polymerizations
are nothing more than polyadditions of monomers, the structural
formulas of which form certain chains like those known from the
frieze groups.
These structural formulas recall the artful friezes
in mosques, “structures of altogether unusual simplicity, unity and

Symmetry and Complexity in Chemical Sciences
183
beauty” (W. Heisenberg) [4.14]. But with regard to the symmetries
of the friezes of chemical structural formulas, we have to consider
that these are only 2-dimensional projections of 3-dimensional struc-
tures. For crystal polymers in particular, X-ray diﬀraction spectra
reveal stable conformations with well-deﬁned symmetries.
The signiﬁcance of macromolecules in nature becomes clear when
we investigate the structure and metabolism of living organisms.
For example, their high molecular masses make it possible to con-
struct solid and simultaneously ﬂexible structures.
On the other
hand, their complex atomic structure makes it possible to regulate
metabolic processes and to store information. From the standpoint
of symmetry, proteins are of fundamental interest [4.15]. These are
macromolecules of many amino acids of 20 diﬀerent types in nature.
Protein analysis shows that amino acids have an antisymmetrical car-
bon atom and occur only in the left-handed conﬁguration in nature.
If we investigate the 3-dimensional conformation of various amino
acid units in the protein, we encounter a characteristic antisymme-
try of the protein, in which the antisymmetry of its components
is continued.
L. Pauling, who detected a spiral structure in certain crystal pro-
tein ﬁbers, called it α-helix.
The α-helix consists of 18 monomer
units on 5 revolutions each, which, among other things, are stabi-
lized by intramolecular hydrogen bonds. One of the characteristic
symmetry breakings of biopolymers is therefore the fact that pro-
teins in nature form only left-handed spirals. Of course, reﬂections
of the protein components also occur, but they cannot be ﬁtted into
Fig. 54.
Antisymmetry of protein

184
Symmetry and Complexity
the molecular chains of proteins. Certain proteins diﬀer from the reg-
ular helix structure. One well-known example is hemoglobin, whose
stereochemical structure was reconstructed by the Nobel Prize win-
ner M. Perutz, among others. To be precise, hemoglobin consists
of a spherical protein (globin) and a complicated compound of iron
(heme), which is not a protein. Hemoglobin is characterized by the
double axis of rotation of its molecular chains [4.16].
X-ray crystallography now makes it possible to systematically an-
alyze the symmetry structures of crystallized proteins and to explain
them in terms of group theory. The mathematical structure of crys-
tals is altogether independent of their physical or chemical interpre-
tation. In biochemistry, atoms are not selected as structural units,
but molecules. Since amino acids naturally occur in proteins only
as left-handed conﬁgurations, certain symmetry elements of crystals
requiring an equal number of left-handed and right-handed conﬁg-
urations, such as the plane of reﬂection, glide reﬂection and center
of inversion, are a priori excluded. Mathematically speaking, from
the 230 possible crystal groups only the ﬁrst 65 ones with intrinsic
movements remain. These 65 discrete intrinsic motion space groups
in which biological macromolecules such as proteins can crystallize
are therefore also called “biological” space groups [4.17]. They are
used in the investigation of enzymes, for example.
4.2
Symmetry Breaking and Chirality
The fundamental symmetries of physics are at the origin of conserved
quantities or constants of molecular processes, permanent and im-
mutable for eternity. But, small violations of these symmetries lead
to slight disturbances in this static world and introduce some possi-
bilities for the emergence of new chemical phenomena. In traditional
quantum molecular and particle physics it was assumed that the
Hamiltonian of a molecular or particle quantum system is invariant
under the following fundamental three operations: (1) P-operation
of parity, i.e. the inversion of all particle coordinates in the center
of mass with x →−x, y →−y, z →−z; (2) T-operation of time,
i.e. time reversal t →−t ; (3) C-operation of charge, i.e. the exchange

Symmetry and Complexity in Chemical Sciences
185
of all particles by their antiparticles. In elementary particle physics,
these three symmetries are all more or less inexact or violated, while
the combined operation CPT is still assumed to be an exact sym-
metry.
Parity-violation has immediate consequences in molecular
chemistry with perhaps even eﬀects on the origin and evolution of
life.
In general, the symmetry of reﬂection (inversion) means that
right-handed and left-handed structures of chiral molecules can be
distinguished in space. But energetically they seem to be completely
equivalent. It was van’t Hoﬀwho found the geometrical explanation
of chiral and optically active molecules. Mathematically, we can use
coordinate systems with right and left orientation to distinguish both
forms of chirality. In quantum chemistry the symmetry of chirality
is represented by a quantum number (“parity”) with two possible
values +1 for positive parity and −1 for negative parity.
But the symmetry of chirality is violated by observations and mea-
surements in the laboratories of biochemists. Macromolecules like,
for instance, L-amino acids or D-sugars which are building blocks of
living systems possess a characteristic homochirality or dissymmetry.
Sometimes the enantiomers (i.e. the reﬂections of isomers) can be dis-
tinguished by simple tests of taste: S-asparagin has a bitter taste,
while R-asparagin has a sweet taste. We can perceive this kind of
symmetry breaking, because our body is a handed (chiral) biochemi-
cal system. In the 19th century Pasteur already presumed that living
systems are characterized by typical dissymmetries of their molecu-
lar building blocks having emerged during biological evolution. Then
the handed receptor molecules of our taste organs ﬁt the chiral forms
of the tasted molecules such as the right or left hand ﬁts the right or
left glove. But it cannot be explained why the actual molecular form
of symmetry breaking was realized during the evolution and why the
other form was unable to survive.
As usual in classical physics, the two stable enantiomers can be
illustrated by two minima of a symmetric potential curve V (q) where
q is the reaction coordinate for the chemical transformation of the
molecular substituents. Mathematically the potential curve of the
reaction equation is assumed to be completely symmetric with re-

186
Symmetry and Complexity
spect to inversion. There are three solutions as equilibrium points
with the two stable minima of the left- and right-handed forms and
an unstable solution of a symmetric achiral form. The symmetry is
broken by the actually realized stable form with respect to peculiar
supplementary conditions. In quantum chemistry the framework of
classical physics must be replaced by the principles of quantum me-
chanics. Molecular states are described by wave functions that can
be superposed as pure entangled states according to the superposi-
tion principle. Thus for every temperature and energy there is not
only the possibility of chiral molecules with either a left-handed or
right-handed form, but also a third possible form which is both left-
handed and right-handed. Spontaneous symmetry breaking in quan-
tum chemistry can be introduced by superselection rules forbidding
the symmetric achiral superposition states that can be realized by a
special physico-chemical environment (e.g. certain radiation ﬁelds).
The classical and quantum mechanical concept of spontaneous
symmetry breaking can only explain that a chiral molecule must
emerge under some supplementary conditions. But it cannot explain
why the actual form was realized instead of the other possibility.
Therefore, the question arises if a selection happens by chance or
by the necessity of a natural law.
An explanation has been sug-
gested with respect to the parity violating weak interaction that
can be evaluated at least numerically in chiral molecules. In case
of parity (P)-symmetry the right- and left-handed forms would be
energetically exactly equivalent, transformed into each other by in-
version. But parity was violated by the symmetry breaking of weak
interaction during the cosmic evolution. Thus, if the parity viola-
tion can be measured by a small energy diﬀerence ∆Epv, we get
the non-equivalence of the two isomers or enantiomers which are
no longer simple mirror images of each other. The corresponding
potential curve is no longer symmetric, but the two minima diﬀer
with the energy diﬀerence ∆Epv. Obviously the chemical law itself
is no longer symmetric [4.18]. Then the actually realized forms of
chiral biomolecules can be explained by their greater stability with
respect to the parity violating energy. The emergence of a chemical
phenomenon is reduced to a physical symmetry breaking.

Symmetry and Complexity in Chemical Sciences
187
Fig. 55.
Parity violation by small energy diﬀerence
As these energy diﬀerences are extremely small, they have so far
not been measured in laboratories although schemes for such exper-
iments have been proposed [4.19]. Nevertheless, such experiments
in combination with accurate calculations provide insight in a fun-
damental link between cosmology, particle physics, molecular chem-
istry, and evolution. Even if these tiny energy diﬀerences increase
proportionally during polymerization they still remain very small
under laboratory conditions. But in evolution, nature itself was the
laboratory [4.20]. For amino acids, for example, we can accurately
calculate the prebiotic evolutionary conditions in which homochiral-
ity can be selected, e.g. in a lake with a certain volume of water and
over a certain period of time. These calculations are based on an ab
initio method (Hartree method) of numerical quantum chemistry,
which currently has the best claim to accuracy. Therefore homochi-
ral biochemistry can be interpreted as a direct result of the parity
violation of weak interaction.
Pasteur’s suspicion of a universal dissymmetrical force in nature
is therefore reasonable, at least in terms of quantum chemistry. We
could go even further and classify the chirality of biomolecules in a
sequence of symmetry breakings that took place in the cosmologi-
cal growth of the universe. Elementary particle physics intends to
unify all the known physical interactions by deriving them from one
interaction scheme based on a single symmetry group.
Physicists
expect to arrive at the actually observed and measured symmetries

188
Symmetry and Complexity
of fundamental forces and their elementary particles of interaction
by spontaneous symmetry breaking processes. Electromagnetic and
weak forces could already be uniﬁed by very high energies in the lab-
oratories of high energy physics (for instance the accelerator ring of
CERN). That means that at a state of very high energy the particles
of weak interaction (electrons, neutrinos, etc.) and electromagnetic
interaction cannot be distinguished any longer.
They can be de-
scribed by the same symmetry group U(1) × SU(2). At a particular
critical value of lower energy the symmetry breaks down in two par-
tial symmetries U(l) and SU(2) corresponding to the electromagnetic
and weak force. The emergence of weak interaction with its particu-
lar violation of parity would be a result of cosmic symmetry breaking
during the expansion of the universe. “C’est la dissym´etrie qui cr´ee
le ph´enom`ene,” said P. Curie in 1894 [4.21].
Molecular dissymmetry, asymmetry and time irreversibility seem
to be consequences of cosmic evolution with decreasing symmetry
and simplicity and increasing complexity and variety [4.22]. Obvi-
ously, biopolymers of life are made of L-amino acids and D-sugars and
not L-sugars and D-amino acids. We live in a world of matter and not
of antimatter, which occurs only in small amounts as an exception
such as with positrons from β-decay. Time seems to exclusively run
forward, never exactly backwards in the molecular and macroscopic
world. Parity, charge and time violation seem to result from early
phase transitions of the universe. Symmetry breaking of time starts
with the cosmic expansion of the tiny early quantum universe. C-
violation of matter and antimatter happens after symmetry breaking
of the uniﬁed strong-weak-electromagnetic force. A tiny surplus of
matter had become the stuﬀof future galaxies, our earth and life.
Symmetry breaking of the uniﬁed weak-electromagnetic force caused
parity-violation with the selection of biomolecules.
This apparent symmetry breaking in the molecular world should
be related to the fundamental CPT-symmetry of quantum chem-
istry.
It turns out that chiral molecules provide an ideal test of
CPT-symmetry.
Tests of CPT-symmetry have been concerned
with comparing the mass of proton and antiproton, proving equiva-

Symmetry and Complexity in Chemical Sciences
189
lence and thus CPT-symmetry at a level of precision measured by
∆m/m ≈10−9 of mass m and mass diﬀerence ∆m. Further on, it has
been suggested to compare the optical spectra of, for example, hy-
drogen and antihydrogen atoms with an accuracy in the test of about
∆m/m ≈10−18. Spectroscopic experiments on chiral clusters and
their antimatter equivalents are planned for testing the validity of
CPT-symmetry at about 10−30 relative precision. They include the
synthesis of chiral antimatter molecules. Tiny diﬀerences in these ex-
periments between spectra of left-handed and right-handed molecules
and clusters could lead to a complete revision of the traditional be-
lief in fundamental symmetries. These observations of matter versus
antimatter, left and right handedness of space and time directions
forward and backward would not be granted with CPT-symmetry
being valid.
Besides spatial symmetries chemists are involved in the fundamen-
tal problems of time symmetry. While the laws of classical physics
and quantum chemistry assume symmetry with respect of time inver-
sion, the factual chemical reactions in the laboratories proceed only
in one direction to the chemical equilibrium. Chemical processes are
irreversible.
Their reversion seems to be unnatural.
Since Boltz-
mann’s statistical interpretation of the second law of thermodynam-
ics irreversible processes have been discussed for complex molecular
systems like gases, ﬂuids, etc.
The second law states that closed
systems irreversibly approach the thermal equilibrium of maximal
entropy. It is remarkable that Prigogine explains the irreversibility
of dissipative processes far from thermal equilibrium by a universal
symmetry breaking of time. Time has now the status of a mathe-
matical operator only allowing physically asymmetric states. While
the spontaneous symmetry breaking of elementary particles in high
energy physics assumes the symmetry of its laws with respect to uni-
tary (gauge) groups, Prigogine’s time operator delivers (non-unitary)
semi-groups representing both directions of time [4.23]. The second
law of thermodynamics is a kind of selection principle for the real-
ized symmetry breaking process. In short: the law itself has become
asymmetric.

190
Symmetry and Complexity
4.3
Complexity, Dissipation and Nanosystems
Complex structures in nature are generated by conservative and dis-
sipative self-organization.
Dissipative systems are not closed like
conservative systems, but open with interacting exchange of energy
and matter with their environment. Thus, living organisms are typ-
ical examples of dissipative systems. But even in physics and chem-
istry, we can study dissipative self-organization. The emergence of
dissipative structures far from thermal equilibrium is an irreversible
process of symmetry breaking which can be geometrically illustrated
by a bifurcation scheme. In other words: the bifurcation tree of a
dissipative system represents the growth of forms in an irreversible
time direction.
In physics, ﬂuid dynamics provide an example of pattern forma-
tion with increasing complexity if the system is driven away from
equilibria by increasing velocities of ﬂow. In chemistry, a dissipative
system in which chaotic motion has been studied experimentally is
the BZ-reaction. In this chemical process an organic molecule is oxi-
dized by bromate ions, the oxidation being catalyzed by a redox sys-
tem. The rates of change for the concentrations of the reactants in a
system of chemical reactions are again described by a system of non-
linear diﬀerential equations with a nonlinear function. The variable
signaling chaotic behavior in the BZ-reaction is the concentration of
the ions in the redox system. Experimentally, irregular oscillations
of these concentrations are observed with a suitable combination of
the reactants. The oscillations are indicated by separated colored
rings (Fig. 56). This separation is a ﬁne visualization of nonlinear-
ity. Linear evolutions would satisfy the superposition principle. In
Fig. 56.
Oscillation of Belousov–Zhabotinsky reaction

Symmetry and Complexity in Chemical Sciences
191
this case the oscillating rings would penetrate each other in superpo-
sition. Analogously to ﬂuid dynamics or laser systems, the pattern
of oscillation is destroyed and transformed to chaos if the input rate
of energetic substances surpasses certain thresholds of a control pa-
rameter [4.24].
The class of oscillatory, metal ion catalyzed oxidation of organic compounds
by ionic bromate is an example of autocatalytic diﬀusion-reaction processes. This
class of reactions involves the nonlinear diﬀusion of both excitatory and inhibitory
molecules supporting self-exciting ring waves on the macroscopic level. In the
language of chemistry, the autocatalytic process in a simpliﬁed case is modeled
by reaction schemes with variable substances X = HBrO2, Y = Br−, Z = Ce4+,
P = HOBr and constant substances A = BrO−
3 and B = BrMS:
A + X →X + P
A + Y →2P
A + X →2X + Z
2X →A + P
B + Z →fY
A chemical autocatalytic term, e.g., in the third reaction rule, corresponds to a
mathematical nonlinearity. Thus, in the language of mathematics, we get three
diﬀerential equations of chemical concentrations cX, cY and cZ with constants ki
of velocity of the i-th chemical reaction equation:
dcX/dt = k1cAcY −k2cXcY + k3cAcX −2k4cX
2
dcY /dt = −k1cAcY −k2cXcY + fk5cBcZ
dcZ/dt = k3cAcX −k5cBcZ
The phase transition of the BZ-reaction is represented by typical patterns of
time series analysis from periodicity to chaos. Chemical oscillations can also be
represented by trajectories running into a limit cycle or chaos attractor of the
corresponding phase space.
The phase transitions of the BZ-reaction are associated with sym-
metry breaking of spatial patterns. While the homogeneous surface
of the chemical liquid in the equilibrium state has full symmetry, the
emergence of ring waves and ﬁnally fractal chaos break the spatial
symmetry, phase by phase. Again, decreasing symmetry is accompa-
nied with increasing variety of complex structures. In the framework

192
Symmetry and Complexity
(a)
(b)
Fig. 57.
Molecular self-organization of complex crystals with symmetric atoms
[4.25]
of dynamical systems theory, this kind of space and time symmetry
breaking refers to phase transitions of complex open (dissipative) sys-
tems far from thermal equilibrium. Macroscopic patterns (“attrac-
tors”) arise from the nonlinear interactions of microscopic elements
(i.e. atoms, molecules) when the energetic and material interaction
of the dissipative (open) system with its environment reaches some
critical value (“dissipative self-organization”). Phase transitions of
closed systems near to thermal equilibrium are called conservative
self-organization creating ordered structures with low energy at low
temperature. An example at the boarderline of physics and chem-
istry is the growth of crystals by annealing the system to a critical
value of temperature.
Fig. 57a shows the molecular growth of complex crystals with
translation symmetry from highly symmetrical metallic atoms. In
Fig. 57b, the growth of crystals starts with molecular building blocks
having the shape of Platonic bodies. Under more extreme conditions
after the input of acid, they arrange themselves in complex crystals
of metallic oxide. Their periodicity seems to be typical for the inan-

Symmetry and Complexity in Chemical Sciences
193
imate molecular world. In the biosphere, we will ﬁnd non-periodic
structures with symmetry breaking which inspired E. Schr¨odinger
to introduce his famous concept of “aperiodic crystals” for living
organisms.
In supramolecular chemistry, conservative self-organization plays
a tremendous role. In this case molecular self-organization means the
spontaneous association of molecules under equilibrium conditions
into stable and structurally well-deﬁned aggregates with dimensions
of 1–100 nanometers (1 nm = 10−9 m = 10 ˚A). Nanostructures
may be considered as small, familiar or large, depending on the view
point of the disciplines concerned. To chemists, nanostructures are
molecular assemblies of atoms numbering from 103 to 109 and of
molecular weights of 104 to 1010 daltons.
Thus, they are chemi-
cally large supramolecules. To molecular biologists, nanostructures
have the size of familiar objects from proteins to viruses and cel-
lular organelles. But to material scientists and electrical engineers,
nanostructures are the current limit of microfabrication and thus are
rather small [4.26].
Nanostructures are complex systems that evidently lie at the in-
terface between solid-state physics, supramolecular chemistry and
molecular biology. It follows that the exploration of nanostructures
may provide hints about both the emergence of life and the fabrica-
tion of new materials. But engineering of nanostructures cannot be
mastered in the traditional way of mechanical construction. There
are no man-made tools or machines for putting together their build-
ing blocks like the elements of a clock, motor or computer chip. Thus,
we must understand the principles of self-organization used by nanos-
tructures in nature. Then, we only need to arrange the appropriate
constraints under which the atomic elements of nanostructures as-
sociate themselves in a spontaneous self-construction: the elements
adjust their own positions to reach a thermodynamic minimum with-
out any manipulation by a human engineer.
In the beginning of nanoscience there was the vision of an inge-
nious physicist. In an article entitled “There’s Plenty of Room at
the Bottom”, Feynman declared that the principles of physics do not
speak against the possibility of maneuvering things atom by atom

194
Symmetry and Complexity
[4.27]. Feynman proclaimed his physical ideas of the nanoworld in
the late 1950s. The belief in a new world needs new instruments of
observation and measurement for conﬁrmation. Since the start of the
1980s, the nanoworld could actually be explored using the scanning
tunnel microscope. At the end of the 1980s, E. Drechsler described a
revolutionary vision of technological applications [4.28]. With nan-
otechnology, atoms will be speciﬁcally placed and connected in a
fashion similar to processes found in living organisms.
Historically, the idea of a supramolecular interaction dates back
to the famous metaphor of E. Fischer (1894), who described a selec-
tive interaction of molecules as the lock and key principle. Today,
supramolecular chemistry has by far surpassed its original focus.
Molecular self-assemblies combine several features of covalent and
non-covalent synthesis to make large and structurally well-deﬁned
assemblies of atoms. Single van der Waals interactions and hydrogen
bonds are weak relative to typical covalent bonds and comparable to
thermal energies. Therefore, many of these weak non-covalent inter-
actions are necessary in order to achieve molecular stability in self-
assembled aggregates. In biology, there are many complex systems
of nanoscale structures such as proteins and viruses formed by self-
assembly. Living systems sum up many weak interactions between
chemical entities to make large ones. How can one make structures
of the size and complexity of biological structures, but without using
biological catalysts or the informational devices coded in genes?
Many non-biological systems also display self-organizing behavior
and furthermore provide examples of useful interactions.
Molecu-
lar crystals are self-organizing structures. Liquid crystals are self-
organized phases intermediates between crystals and liquids with re-
gard to order. Micelles, emulsions and lipids display a broad variety
of self-organizing behavior. An example is the generation of cascade
polymers yielding molecular bifurcacional superstructures of fractal
order [4.29]. Their synthesis is based on the architectural design of
trees. Thus, these supramolecules are called dendrimers (from the
Greek word “dendron” for tree and “polymer”). The construction of
dendrimers follows two basic procedures of monomer addition. Di-
vergent construction begins at the core and builds outward via an

Symmetry and Complexity in Chemical Sciences
195
increasing number of repeating bifurcations. Convergent construc-
tion begins at the periphery and builds inward via a constant number
of transformations. The divergent construction displaces the chem-
ical reaction centers from the center to the periphery, generating a
network of bifurcating branches around the center. The bifurcations
increase exponentially up to a critical state of maximal size. They
yield fractal structures such as molecular sponges which can absorb
smaller molecules, which can then be dispersed in a controlled way,
e.g., for medical applications.
Examples of cave-like supramolecules are the Buckminster-
fullerenes, forming great balls of carbon atoms [4.30]. The stabil-
ity of these complex clusters is supported by their high geometric
symmetry. The Buckminsterfullerenes are named after the geodesic
networks of ball-like halls constructed by the American architect
R. Buckminster Fuller (1895–1983). The cluster C60 of 60 carbon
atoms has a highly Platonic symmetry of atomic pentagons forming
a completely closed spheroid.
Cave-like supramolecules can be arranged using chemical tem-
plates and matrices to produce complex molecular structures. Sev-
eral giant clusters comparable in size to small proteins have been ob-
tained by self-assembly. Giant clusters may have exceptional novel
structural and electronic properties: there are planes of diﬀerent
magnetization being typical for special solid-state structures and
of great signiﬁcance for material sciences. A remarkable structural
property is the nanometer-sized cavity inside the giant cluster. The
use of templates and the selection of appropriate molecular arrange-
ments may well remind us of Fischer’s lock and key principle [4.31].
Molecular cavities can be used as containers for other chemicals
or even for medicaments needing to be transported within the hu-
man organism. An iron-storage protein that occurs in many higher
organisms is ferritin. It is an unusual host-guest system consisting
of an organic host (an aprotein) and a variable inorganic guest (an
iron core). Depending on the external demand, iron can either be
removed from this system or incorporated into it. Complex chemi-
cal aggregates like polyoxometalates are frequently discovered being
based upon regular convex polyhedra, such as Platonic solids. But

196
Symmetry and Complexity
their collective electronic and/or magnetic properties cannot be de-
duced from the known properties of these building blocks. According
to the catch-phrase “from molecules to materials” supramolecular
chemistry applies the “blue-prints” of conservative self-organization
to build up complex materials on the nanometer scale with novel cat-
alytic, electronic, electrochemical, optical, magnetic and photochem-
ical properties. Multi-property materials are extremely interesting.
The exploration of the nanoworld and applications in nanotech-
nology depend on better instruments of observation and measure-
ment. The scanning force microscope is a further development of
the scanning tunnel microscope and can be used like a fountain pen
to write down molecular structures of nano size.
A thin ﬁlm of
thiolmolecules is used as “nano ink”. In a tiny drop of water the
thiolmolecules organize themselves as monolayer.
Nanocrystals of
a few hundred atoms can organize themselves with cadmium ions,
selen ions and organic molecules into a ball-like structure (Fig. 58).
In ultraviolet light they ﬂuoresce with a certain color. Thus, they
could be used as markers (“quantum dots”) of molecules, cells, and
substances in medicine, for example.
Complex systems of carbon
molecules can organize themselves as tiny tubes of 1 nm diameter
according to certain catalysts and templates. Their symmetric order
of bonding results in great hardness and toughness. Carbon nan-
otubes might be used as conductors for miniaturized chips beyond
the limits of silicon technology.
Supramolecular transistors are an example that may stimulate
a revolutionary new step in the development of chemical comput-
Fig. 58.
Self-organization of complex nanocrystals [4.32]

Symmetry and Complexity in Chemical Sciences
197
ers.
Actually, there is a strong trend towards nanostructures in
electronic systems which may realize small, fast devices and high-
density information storage. But one can also imagine nonelectronic
applications of nanostructures. They could be used as components
in microsensors or as catalysts and recognition elements in analogy
to enzymes and receptors in living systems.
In natural evolution
very large complex molecular systems are also produced by step-
wise gene-directed processes. The conservative self-organization pro-
cesses of nanomolecular chemistry are non-gene-controlled reactions.
Only a clever combination of conservative and non-conservative self-
organization could have initiated prebiotic evolution before genes
emerged. But even during the evolution of complex organisms, con-
servative self-organization must have occurred. Open (“dissipative”)
physical and chemical systems lose their structure when the input of
energy and matter is stopped or changed (e.g. laser, BZ-reaction).
Organismic systems (like cells) are able to conserve much of their
structure at least for a relatively long time. On the other hand, they
need energy and matter within a certain interval of time to keep their
structure more or less far from thermal equilibrium. In the technical
evolution of mankind, the principles of conservative and dissipative
self-organization have once more been discovered and open new av-
enues of technical applications.

This page intentionally left blank

Chapter 5
Symmetry and Complexity in
Life Sciences
Biochemistry and molecular biology are the bases of modern biology
and thus serve as the bases for explanations of life processes of or-
ganisms such as bacteria, plants and animals. But organisms are not
merely complex aggregates of atoms and molecules. Some character-
istics of symmetry are determined by the building blocks, of course
(e.g. the dissymmetry of proteins). On the higher level of organiza-
tion of organisms, however, new characteristics of symmetry, dissym-
metry and asymmetry arise, which become necessary as a result of
functional requirements (e.g. adaptation to the environment, preser-
vation of the species, metabolism). The whole, i.e. the organism, is
therefore more than the sum of its parts. It is more correct to say that
the parts of the organism and the environment are connected to one
another by a number of functions which, when separated, lead to the
death of the organism. Mathematically, the wholeness of an organism
corresponds to the nonlinearity of its functional structure. Thus, the
emergence of new forms of life with increasing complexity has been
made possible by the nonlinear dynamics of self-organization. In the
ﬁrst section of this chapter, we analyze the functional symmetries
of organisms. Then, in the following two sections, their evolution
is explained by biological phase transitions and symmetry breaking,
generating the complexity and diversity of life.
5.1
Symmetry in Biology
There are apparent symmetries in the living world. They all seem
to be distinguished by special functions of an organism.
But in
199

200
Symmetry and Complexity
contrast to elementary subatomic particles, atoms and molecules,
the organism as a new and complex living unit cannot be so easily
and clearly deﬁned. All that can be indicated are a few necessary
and by no means suﬃcient characteristics such as metabolism, self-
reproduction, selection and mutation [5.1].
Viruses show how diﬃcult it is to deﬁne life. They are organisms
to the extent that they consist of complicated organic molecules such
as nucleic acids and proteins, and possess genetic information for self-
reproduction. On the other hand, they are constructed too simply
to live and reproduce independently. A virus particle can only repro-
duce in the context of a living cell. Its short nucleic acid molecules
can only carry the information of a few types of proteins. Therefore,
the outer shell of the virus particle must be constructed from these
few protein molecules.
Fig. 59 shows the molecule of an adeno-virus [5.2]. Externally, the
252 capsomeres and 1500 identical protomers form a regular Platonic
body (icosahedron) with 20 equilateral triangles, but where the cap-
someres are not completely identical to one another. The extensions
projecting from the 12 corners infect the host cells. On account of
this extremely symmetrical structure, virus particles can coagulate
to form crystals and thus assume a form of organization like that
found in non-living matter. If we are aware of the eﬀect of the virus
particles in mammals (infection and cancer), the model illustrated
in Fig. 59 has a certain ghostly beauty and recalls an ominous space
ship from an alien microworld.
The virus particle is a clear example of the fact that the dynamics
of life processes require symmetry breakings. As a Platonic body in
Fig. 59, for example, it is quite lifeless. To participate in the life
of the host cell and reproduce, the virus particle must trigger an
infection and thus give up its symmetry.
In the sense of structural symmetry, an organism such as the
amoeba is altogether asymmetrical. But it is an almost perfect sur-
vival system, in which the functions such as metabolism, motion,
nutrient transport etc. are optimally harmonized with one another.
But mathematically, the concept of symmetry is not bound to the
geometric shape. A structure whose elements are functionally har-

Symmetry and Complexity in Life Sciences
201
 
Fig. 59.
Symmetry of a virus
monized with one another and which remains conserved (invariant)
during self-reproduction in the sense of a mathematical mapping in
itself also forms a symmetry. In contrast to a geometric, structural
symmetry, we therefore speak of a functional symmetry [5.3].
If we establish a scale of aggregates between maximum symme-
try and chaos, for example, from crystals through paracrystals, liq-
uid crystals, gels and real ﬂuids up to ideal ﬂuids and gases, then
living organisms are obviously classiﬁed somewhere in the middle.
Their symmetries are of an altogether statistical nature, since in self-
reproduction invariant patterns of characteristics of course recur, but
more or less random changes also occur, and thus make possible the
variety and individuality of living nature. The sudden changes in the
genome (mutations) are typically local symmetry breaking which is
part of evolution.

202
Symmetry and Complexity
No two leaves are exactly alike. All that exists is the type of a cer-
tain leaf, around which the real leaves are statistically scattered. Sta-
tistical symmetries are therefore scattered around an average value
with a standard deviation. The patterns of complex cell wall pores
or muscle ﬁbers are microscopic examples while, for example, the
pattern of veins in a leaf or the arrangement of blades of grass in
a meadow is directly visible to the eye. But perfect symmetry in
these cases is merely a human ﬁction that is projected on nature by
abstraction.
These are rather the structures of biological growth
programs which are realized in the context of certain statistical
deviations.
Fig. 60.
Cellular symmetries of self-reproduction
Among these restrictions, we shall ﬁrst examine the geometric
symmetries of more or less complex organisms, from single-cell organ-
isms through the higher plants up to the animals. Spherical bacteria
and algae can be broken down through many planes into symmetri-
cally equal halves. Single-cell organisms such as the single-cell green
algae frequently have a main axis. Vegetative reproduction then cus-
tomarily takes place by longitudinal and diagonal division of the cell
(Fig. 60).
In other bacteria and algae, depending on the variety,
there is a regular division in one, two or all three 3-dimensional di-
rections, which can lead to diﬀerent associations of cells, for example,
chains of streptococci which look like strings of pearls, threads like
the thread-forming conjugatae or colonies which feature a division of
labor among the individual cells [5.4].
In the higher plants, it becomes possible to distinguish the ele-
ments of symmetry such as translation, rotation and reﬂection. Sel-
dom is there a pure translation symmetry, in which the leaves grow

Symmetry and Complexity in Life Sciences
203
isometrically along with axis of the branch with the same translation
length (e.g. the leaﬂets of the ailanthus tree (Ailanthus altissima)
illustrated in Fig. 61a). More frequently, growth is related to a reg-
ular increase of the translation units, such as in the leaﬂets of the
mountain ash in Fig. 61b.
In addition to longitudinal symmetry,
these two examples also exhibit a lateral symmetry, since the left
and right halves of the leaf are symmetrical to one another.
On
the other hand, the elm branch in Fig. 61c is generated by a glide
reﬂection, in which a translation and a reﬂection form a combined
symmetry operation.
In the positions of leaves, helical symmetries also occur, in which
the translation of the growth motion is connected with a unit of
rotation.
One example is the helical pattern of the leaves of the
branch of a variety of stonecrop, on which each leaf diﬀers from the
preceding leaf by a certain angle.
In a helical motion, in general, every point of the space not laid
on the helical axis describes a helix. The positions that the moving
Fig. 61.
Symmetries of leaves

204
Symmetry and Complexity
point assumes at uniform moments of an interval of time are uni-
formly distributed over this helix, analogous to the steps of a spiral
staircase. It is apparent that the ratios µ/v with which the helix-
like arrangements of leaves are represented are frequently elements
of the Fibonacci sequence (1/1, 1/2, 2/3, 3/5, 5/8, 8/13,. . . ). This
consequence results from the expansion into a continued fraction of
the irrational number (
√
5 −1)/2, i.e. the proportional ratio of the
Golden Section.
If we replace the cylinder on which the helix moves with a sphere,
we get a symmetry operation in which in addition to translation and
rotation, a dilatation also occurs. One example is the arrangement of
the scales on a pine cone. If we check the Fibonacci numbers on the
scales of the pine cone, we ﬁnd frequent deviations, so that in the best
case, we can only speak of a statistical symmetry of the phyllotaxy.
When the giant sunﬂower (Helianthus maximus) is in bloom, the
Fig. 62a–d.
Symmetries of inﬂuorescenes

Symmetry and Complexity in Life Sciences
205
 
Fig. 62e.
Spiral tendency of nature
small blossoms are arranged in logarithmic spirals, whereby two sets
of spirals occur with opposite directions of rotation (Fig. 62e).
Both Bonnet and in particular Goethe noted the “spiral tendency
of nature” in the latter’s theory of the metamorphosis of plants. For
Goethe, however, the decisive factor was not the arithmetic law of
the Fibonacci sequence, but the regular pattern in which a temporal
rhythm of growth is revealed in three dimensions, and which contains
clues to the shape of an ancestral plant. Spirals of plants occur as
right-hand and left-hand rotations. There is no parity-violation.
A high degree of symmetries of rotation and reﬂection can be
demonstrated in many inﬂorescenes [5.5]. In Fig. 62a, the symmetry
of a geranium is completely deﬁned by the dihedral group D5, which
in addition to the rotations by the angle n·360◦/5 with 1 ≤n ≤5 also
contains the possible reﬂections. On the other hand, Vinca herbacea

206
Symmetry and Complexity
is a realization of pure symmetry of rotation C5. The narrow-leafed
wild rose in Fig. 62c therefore has only the symmetry D4, since its
growth was inﬂuenced by artiﬁcial manipulations of gravity. In na-
ture, there is the bilaterally symmetrical shape (Fig. 62d), which was
prevented by gravity from becoming symmetry of rotation.
As a rule, functional requirements are the reason for the struc-
tural symmetries of animals, the purpose of which is to guarantee
viability and which cannot be explained by molecular reasons alone.
These are of course characteristics that only occur at a certain stage
of evolution on account of new life circumstances (“emergent charac-
teristics”). But we need not assume any “vitalistic” forces of zoology
to explain them. One of the most frequent symmetries in animal bod-
ies is reﬂectional symmetry. More than 95% of all types of animals
are included among the Bilateralia with simply symmetry of reﬂec-
tion [5.6]. Forward motion in a direction at right angles to gravity
is certainly an important objective for crawling, walking, swimming
and ﬂying Bilateralia such as snakes, lizards, ﬁsh, insects and birds.
Since Antiquity, philosophers have speculated whether the bodies of
human beings and animals are designed according to a certain law
of proportion (e.g., the Golden Section). For example, Fig. 63 shows
the proportions of a butterﬂy (b) and a ﬁsh (c). The ratio of the
Golden Section, which occurs in the context of statistical symme-
tries, is determined by the ﬂow conditions of the respective medium
(air or water) in which the motions of ﬂight or the ﬂight-like motions
of swimming must be executed. In place of the Platonic assumption
of an ideal form deﬁned by nature, the theory of evolution suggests
a selection advantage by means of which a certain symmetry is pre-
ferred over another.
Rotational symmetry has advantages in terms of natural selec-
tion for free-ﬂoating or stationary animals.
Examples of station-
ary animals (Fig. 64), which must spread their snares in all di-
rections, are sponges (a), rotifers (b), the pterobranchia (c) and
echinoderms (d). The anthozoae, a group which includes the water
lilies and coral polyps, also have almost exclusively rotational sym-
metry. Jellyﬁsh also have rotational symmetry, as recorded in minute
detail by E. Haeckel in his book “Artistic Forms of Nature” (1899)

Symmetry and Complexity in Life Sciences
207
a
b
c
Fig. 63.
Bilateral symmetry of animals [5.7]
[5.8]. Fig. 64f shows an octagonal symmetry D8. With a pronounced
Platonic slant, D’Arcy Thompson, in “On Growth and Form” de-
scribes the geometric symmetry of the jellyﬁsh [5.9].
There is also the approximately spherical shape of organisms that
ﬂoat freely in the water. Physically, the sphere always presents the
same resistance to the water.
Organisms frequently inﬂate them-
selves with water to achieve a spherical external shape, such as
plankton organisms or marine larvae. The interior of these organ-
isms is in no way constructed centrally symmetrically, but only the

208
Symmetry and Complexity
Fig. 64.
Rotational symmetry of Radiolaria
outer shell, as a result of the above-mentioned physical environmental
conditions.
The Radiolaria have fascinating sphere-like shapes, and Haeckel
and D’Arcy Thompson have already described their siliceous skele-
tons and cell body with extreme precision. The sphere-like symmetry

Symmetry and Complexity in Life Sciences
209
of the Radiolaria also corresponds to the centric symmetry of the cell.
Fig. 64g shows the skeleton of a Periphylina Radiolaria, whose spher-
ical skeleton is equipped with spines in three planes of reﬂection/lines
of intersection at right angles to one another. The Radiolaria Acan-
tharia in Fig. 64h acts exactly like a space satellite. Haeckel drew
skeletons of various Radiolaria, the symmetries of which are intended
to recall Platonic bodies such as octahedron, icosahedron and dodec-
ahedron. But there is some question about the extent to which his
pen was guided by his desire to stylize the “artistic forms of nature”.
In the animal kingdom, spiral symmetry is found among the
snails. In the shell of the “Turitelle duplicata” (Fig. 64i), the sym-
metry is deﬁned by a continuous group whose symmetry elements
consist of a combination of translation, rotation and dilatation of
the radius of rotation. The dilatation of the size of the successive
helical rotations satisﬁes with approximate accuracy the mathemat-
ical law of a geometric sequence. The snail’s shell holds the animal’s
intestinal cavity which, with increasing age, is wound in a spiral
fashion. The symmetry of this shell can be disrupted by growth and
environmental conditions. Examples are a thickening of the intestine
as the snail ages or the growth of the sexual organs when the animal
reaches sexual maturity, but also changes by deposits of coralline
limestone.
From the standpoint of structural symmetry, therefore, simpler
forms of life such as jellyﬁsh, Radiolaria, snails etc. exhibit a signiﬁ-
cantly higher degree of symmetry than the Bilateralia of ﬁsh, birds,
mammals etc. Apparently, gravity is a central requirement for the
bilaterality of organisms. Gravity makes it possible for the respec-
tive body to be designed as a vector with a pronounced direction
of motion at right angles to gravity.
The work of motion on two
reﬂectively symmetrical sides of the animal can itself be bilateral, as
with the simultaneous ﬂapping of wings, in the form of sliding re-
ﬂections as during the walking of two-legged or four-legged animals
(e.g. horses and human beings), helical as with serpents, crawling
animals, etc. In any case, the tendency of organisms to bilaterality,
from the crawling of amphibians to the upright stance of the human
being, is a remarkable symmetry characteristic in evolution.

210
Symmetry and Complexity
The increasing complexity of types of motion is also character-
istic. A human being does not move in short jerks like a robot or
jumping jack. Only at ﬁrst glance do such mechanical motions have
a greater symmetry than the natural motions of primates. Human
motor skills are characterized by a high degree of ﬂexibility and a
complex coordination of many sequences of motion, which express
high proportionality and thus also symmetry.
The bilaterality of the human body seems to have enforced the
reﬂection symmetry of the two halves of the brain. In general, the
bilaterally symmetrical structure of many animals extends to a cor-
responding structure of the nervous system (Fig. 72). Actually, there
are some neural functions distributed symmetrically on both halves
of the brain. But higher animals also exhibit a symmetry breaking
in that the two halves of the brain do not always retain the same
function: that is, copying the left or right domain of the external
world via organs of touch, sight and hearing.
The two halves of
the brain are locally specialized, not only in perception, but also in
higher functions of human intelligence. The cerebral asymmetry as-
sociated with this specialization is now considered to be a result of
evolution. As mirror-image duplication was increasingly dispensed
with, the freed-up capacity could be used by the right and left halves
of the brain for new specializations. Brains are distinguished by high
ﬂexibility. If a local part of one half is damaged, the failing function
can often be compensated by some neural part on the other half of
the brain. Rigid symmetric domains are surpassed in order to guar-
antee the highly complex coordination of the organism. The question
of what role symmetry plays in perception and knowledge involves
cognitive science and philosophy, and is examined in Sec. 8.1.
5.2
Symmetry Breaking and Evolution
In the framework of nonlinear complex systems, the emergence of
new phenomena is made possible by phase transitions in critical
states of a system.
The symmetry breaking of phase transitions
can be illustrated by a tree of bifurcation points where old equilib-
ria become unstable and new branches are generated with new local

Symmetry and Complexity in Life Sciences
211
points of equilibria and the emerging phenomena as leaves (Fig. 48).
In nonequilibrium dynamics, a bifurcation tree spread out with in-
creasing complexity when the dynamical system is driven further
and further away from its initial equilibrium to local equilibria, be-
coming unstable under changing conditions.
Mathematically, the
emerging structures at the branches of the bifurcation tree are rep-
resented by order parameters of diﬀerential equations, modeling the
time-depending evolution of the dynamical system. Order param-
eters of complex systems are selected at critical points of instabil-
ity when unstable modes of microscopic elements dominate stable
ones and determine the emergence of new macroscopic phenomena
(Fig. 49).
In short: decreasing symmetry (“symmetry breaking”)
and increasing complexity are the ingredients of nonlinear dynam-
ics. That was true in physics and chemistry for reaction-diﬀusion
processes and self-exciting media. It is also true for biological evo-
lution if the mathematical terms of the formalism are interpreted in
an appropriate manner.
In the framework of nonlinear complex systems, many models
have already been suggested to simulate the molecular origin of life.
Complexity on the molecular scale is characterized by a large po-
tential number of states which could be populated given realistic
limits of time and space. Certain microstates may strongly inﬂuence
macroscopic behavior. Such ﬂuctuations may amplify and cause a
breakdown of formerly stable states. Nonlinearity comes in through
processes far from the thermal equilibrium. Classical and only nec-
essary conditions for life demand: (1) self-reproduction (in order to
preserve a species, despite steady destruction), (2) variability and
selection (in order to enlarge and perfect the possibility of a species,
biased by certain value criteria), and (3) metabolism (in order to
compensate for the steady production of entropy) [5.10].
These criteria can be realized by a mathematical optimization
process. In this model, the nucleation of a self-reproducing and fur-
ther evolving system occurs with a ﬁnite expectation value among
any distribution of random sequences of macromolecules such as pro-
teins and nucleic acids. The initial copy choice for self-reproduction
is accidental, but the subsequent evolutionary optimization to a level

212
Symmetry and Complexity
of unique eﬃciency is guided by physical principles. In this model,
life should be found wherever the physical and chemical conditions
are favorable, although some molecular structures should show only
slight similarity with the systems known to us.
The ﬁnal outcome will be a unique structure, for example, an
optimized molecular sequence. Darwin’s principle of the survival of
the ﬁttest is mathematized by an optimization principle for possible
microstates of molecular sequences. It is assumed that in simple cases
biomolecules multiply by autocatalysis. For instance, two kinds of
biomolecules A and B from ground substances GS are multiplied
by autocatalysis, but in addition the multiplication of one kind is
assisted by that of the other kind and vice versa (Fig. 65a).
In
more complicated cases with more kinds of biomolecules, the latter
are assumed to multiply by cyclic catalysis (Eigen’s “hypercycles”)
(Fig. 65b).
This mechanism combined with mutations is able to
realize an evolutionary process.
Fig. 65a–b.
Cyclic catalysis
According to M. Eigen and P. Schuster (1979), a hypercycle is a
cycle of cycles of cycles [5.11]. The phase transitions of prebioic evo-
lution start at the microlevel with molecular microdynamics driven
by a basic catalytic cycle. An example is the citric acid cycle, which
uses a molecule of oxaloacetate over and over again to extract the
energy from acetic acid, driving a variety of higher level cycles that

Symmetry and Complexity in Life Sciences
213
Fig. 66.
Emergence of prebiotic life by self-organization
require consumption of energy. At a higher macrolevel of organiza-
tion (Fig. 66), several such basic cycles can comprise an autocatalytic
cycle that is able to instruct its own reproduction. The new emerg-
ing macroscopic phenomena are, for example, DNA-protein struc-
tures that can reproduce itself. Several of these autocatalytic cycles
can be organized at yet a higher macrolevel into a catalytic hyper-
cycle (Fig. 66). An example of a new emerging entity at this second
macrolevel is a virus. In Sec. 5.1, a virus was explained as a system
at the threshold of life from a “dead” crystal to a “living organism.”
It is a ﬁrst example of a complex adaptive system [5.12].
Obviously, we get a hierarchy of macrolevels with new emerging
entities of increasing complexity. According to the general scheme of
Fig. 49, each level can be modeled by appropriate diﬀerential equa-
tions. The order parameters of the macrodynamics characterize the
new emerging entities. In the biological context, order parameters
are mainly interpreted as ﬁtness degrees or selection values of molec-
ular species. A simpliﬁed model of an appropriate complex molecular
system is a so-called evolution reactor [5.13]. In the reactor there are
macromolecules such as nucleic acids, which are continuously con-
structed and broken down.
Nucleic acids consist of four diﬀerent
building blocks. The population consists of i alternative sequences
or concentrations of uniform chain length. The chain length of the
macromolecules is ν, their coeﬃcient of occupation ni, the total num-

214
Symmetry and Complexity
bers of all sequences z = 
i
ni. It is assumed that the number 4ν of
all combinatorially possible alternative sequences is very small in re-
lation to the total population z. In that case, the expectation value
for the occurrence of a certain sequence of molecules is also very
small and is equivalent to the condition which can be assumed to
have existed at the origin of life.
High-energy molecules are continuously fed to the reactor from
outside to construct the nucleic acids. For that purpose, autocat-
alytic processes of self-reproduction are assumed, which Eigen and
Schuster described in their models of hypercycles. The low-energy
byproducts are continuously removed. A constant total population
can be established and maintained by appropriate regulation from
outside. The construction and destruction of macromolecules takes
place as in independent organisms.
Let the construction parameter of the molecule type ni be γi, and the de-
struction parameter δi. Both can be a function of the concentrations nj of other
types. As a result of mutations, only a certain fraction of copies of a sequence
will be error-free. The proportion of correct copies is designated by a quality pa-
rameter λi, which is a fraction 0 < λi < 1. The rates of evolution of the changes
of ni over time are then dni/dt = (γiλi −δi)ni −e(t)ni (“evolution equations”),
in which e(t) = 
i
(γi −δi)ni/z is then the average generation rate of all types of
molecules [5.14]. Then e(t)ni in the evolution equations is a destruction quantity
which can be used to designate the proportion of ni in the conservation of the
constancy of z.
From the evolution equations, the following necessary characteristics of living
systems can be derived: (1) The metabolism of the open system is measured by
the reaction terms 
i
yini and 
i
δini of high-energy and low-energy molecules.
(2) The self-reproduction is expressed in the evolution equations by the fact that
the evolution rate of a molecule type ni is proportional to its concentration. Thus
the potential dependence of the construction and destruction parameter γi and
δi on the other concentrations is not aﬀected. (3) The capacity for mutations is
taken into consideration by the quality parameter λi. The evolution equations
thus indeed satisfy the characteristics of molecular Darwinism.
The quantity
wi = γiλi −δi is interpreted as the selection value of the type of molecule.
This interpretation is justiﬁed because the equations of evolution are written as
dni/dt = (wi −e(t))ni.

Symmetry and Complexity in Life Sciences
215
An evolution equation can be understood as an extremal prin-
ciple, according to which the types of molecules are optimized on
the basis of selection values. If the selection value wi of one type is
less than the average production rate e(t) of all types, then negative
growth rates occur, and the type dies out. In the other case, there are
positive growth rates. Thus e is constantly pushed upward, while si-
multaneously an increasing number of types have lower selection val-
ues and thus die out. This selection process is stabilized only when
e has reached the maximum selection value wmax of the production
e →wmax and the system is in selection equilibrium. But this equi-
librium state is only preliminary. As soon as a new mutant ni+1 oc-
curs which is more favorable in terms of selection than the dominant
type, the equilibrium collapses. Again, a new selection equilibrium is
then established, which is deﬁned by the now dominant type ni+1. A
system of molecules optimizing itself (“evolution reactor”) therefore
runs through a series of selection evolutions, which correspond to an
ascending series of maximum selection values which belong respec-
tively to the currently dominant type wmax 1 < wmax 2 < · · · < wopt.
According to S. Wright and Eigen, this optimization path, on
which the system climbs to increasingly higher “peaks” of selection
values, can also be represented in three dimensions [5.15]. For that
purpose, a sequence of molecules is deﬁned with ν positions as a point
in the ν-dimensional sequence space. With 4 possible components,
the ν-dimensional sequence space has 4ν points. For simpliﬁcation,
we will limit ourselves to the binary case with two symbols 0 and
1, by means of which, theoretically, the 4 molecular letters A, T, G
and C can also be codiﬁed. The binary system also facilitates the
calculations on a computer. In this case, the ν-dimensional sequence
space has 2ν points. Each point has ν neighbor points, each of which
represents a single-error mutant, i.e. mutants which diﬀer by only
one position.
Between the two extreme points of a pure 0 and 1
sequence, there are ν! possible connections. Fig. 67 shows examples
of ν-dimensional sequential spaces in the binary case.
The major advantage of this 3-dimensional representation is the
very short distances involved and the dense network of possible con-
nections. For example, the longest distance in the 1000-dimensional

216
Symmetry and Complexity
Fig. 67.
ν-dimensional sequential spaces
space is only 1000 length units (“meters”). In the 23-dimensional
space with 1014 points, it is only 23 “meters”.
Moreover, the 23-dimensional sequence space is suﬃcient to rep-
resent all points on the surface of the earth at an interval of 1 meter.
In this space, optimal strategies can be pursued to ﬁnd the highest
mountains on the earth. To do that, a value function is used to assign
an “altitude” to each point. On a hike, the strategy is to go uphill as
much as possible, and to lose as little altitude as possible. Therefore
we are looking for a local peak, so that we can then climb to an
adjacent, higher peak, etc. Mathematically, therefore, the gradient
of the hike is “uphill”, and we can make local decisions regarding
which of the next peaks should be climbed next.

Symmetry and Complexity in Life Sciences
217
On the surface of the earth, therefore, the hiker will try to reach
as many peaks as possible along a 1-dimensional grade or col, with-
out losing too much altitude in between. But the hiker is severely
restricted by the 1-dimensionality of his path. In the 23-dimensional
space, the hiker could go toward each position in 23 diﬀerent direc-
tions, of which k ≤23 lead upward and 23-k lead downward. The
probability of ﬁnding maximum peaks in the immediate vicinity is
therefore very great.
In the ν-dimensional space of molecule sequences, the points are
assigned selection values instead of altitudes. Analogous to the al-
titudes of the mountainous landscape, the selection values in the
molecular sequence space are not distributed randomly, but are as-
sembled in regions, so that “mountains” and “plains” can be local-
ized, for example. In this model, the origin of life is a successive
self-optimization of a molecular system which is achieved by means
of a series of intermediate selection steps. It is not a one-time, ran-
dom event, a unique singularity in which, on account of a random
ﬂuctuation of the phase state, the inanimate matter becomes unsta-
ble and spontaneously changes into a new equilibrium state that we
call life. According to nonequilibrium dynamics, life does not arise
as the result of a one-time, spontaneous symmetry breaking but in
a series of local symmetry breakings, in which selection equilibri-
ums that have become unstable are replaced by new and higher-level
equilibria.
The emergence of proteins and DNA-structure would have not
been possible without self-optimizing phase transitions of nonlinear
dynamics [5.16].
Throughout the evolution of life on earth, only
a small fraction of all possible proteins have been generated.
In
general, a protein is a polymer of amino acids, coupled by valence
bonds. Because 20 distinct amino acids are available to biological
organisms, there are some 20200 possible protein molecules that are
composed of 200 amino acids each. There is not enough matter in
the entire universe to construct a single molecule of each possible
protein. Another calculation provides a similar result: the length of
a gene is seldom more than 1000 sequential positions. Thus, for four
symbols, there are 41000 alternative genes (“mutations”) of length

218
Symmetry and Complexity
1000, which means about 10600 possibilities. We should recall that
the content of matter in the whole universe corresponds to 1074 genes
and that the age of the universe is less than 1018 seconds.
Selection values have been recorded in the genetic codes of liv-
ing organisms. The nucleic acids, which are primarily responsible
for transmitting characteristics through generations of living sys-
tems, show characteristic symmetry breakings.
Nucleic acids are
macromolecules formed by linear polymerization of certain units (nu-
cleotides). According to the double helix model of J.D. Watson and
F.C. Crick, the DNA molecule consists of two strands of DNA inter-
twined in a regular double helix around a common axis [5.17]. The
two strands are parallel, but in opposite directions. The sequence
of the bases in the one strand determines the sequence in the other
strand, so that an A is always opposite to a T and a G is always
opposite to a C. Antisymmetry is of fundamental importance for the
transmission of genetic characteristics, which can be explained on
the molecular level of DNA helix.
The genetic information of an organism is encoded in its set of
chromosomes (genome) in the form of DNA (Fig. 68). The mecha-
nism of reproduction, which makes possible a clear duplication (repli-
cation or reduplication), can be illustrated very clearly: an enzyme
allows the hydrogen bridges to open and the double helices to sepa-
rate into two strands. Each strand reproduces its exact opposite to
which it is reconnected by hydrogen bonds, thereby forming a new
double helix. On account of the complementary base pair formation
of A-T and C-G, which is expressed in three dimensions in the twist-
ing of the double helix, the accuracy of the copy is guaranteed even
after many reproductions. If the two strands were orientated paral-
lel and symmetric to one another like a ladder, then the accuracy of
the reproductive process would not be guaranteed, with disastrous
consequences for the respective organisms. This case demonstrates
that antisymmetry or parity violation can have a decisive biological
function.
In general, an evolutionary process is expected to produce new
kinds of species [5.18]. A species may be considered as a population
of biomolecules, bacteria, plants or animals. These populations are

Symmetry and Complexity in Life Sciences
219
Fig. 68.
Antisymmetry of DNA
characterized by genes, which undergo mutations producing new fea-
tures. Although mutations occur at random, they may be inﬂuenced
by external factors in the environment, such as changing tempera-
ture or chemical agents. At a certain critical mutation pressure new

220
Symmetry and Complexity
kinds of individuals of a population come into existence. Genetic self-
organization generates Darwin’s evolutionary tree with local points
of instability and bifurcating branches where new species emerge
(Fig. 69). Obviously, the biological bifurcation tree can be compared
with the bifurcation tree of nonequilibrium dynamics (Fig. 48). In
case of Darwin’s evolutionary tree, ﬂuctuations at the critical points
of bifurcation are interpreted as mutations and biological random
events.
Selection is the driving force in the bifurcating branches.
(The numbers at the branches in Fig. 69 measure the substitutions
of nucleotids in the DNA of a species.) Instead of dissipative pattern
formation in, for example, liquids or gas we observe the emergence
of new forms of organisms.
Of course, there are main diﬀerences between pattern formation
in physics, chemistry, and biology. While, for example, physical and
chemical systems lose their structure when the ﬂux of energy and
matter is switched oﬀ, much of the structure of biological systems
is still preserved for a certain time. The reason is that biological
systems do not only consist of dissipative processes, but also con-
servative structures like, for example, the skeleton of human body,
which decay on a longer scale of time than organs or liquids. Further
on, biological systems satisfy certain functions and tasks in a living
organism. But, in the biological context, this kind of purposes is
explained by selection values or ﬁtness degrees which, in nonequilib-
rium dynamics, can be represented by order parameters of nonlinear
diﬀerential equations. When at a critical point of mutation pressure
new kinds of individuals of a population emerge, then the rate of
change of these individuals is described by an evolution equation.
As these individuals have new features, their growth and death fac-
tors diﬀer. A change (mutation) is only possible when ﬂuctuations
occur in the population and the environment. Thus, the evolution
equation determines the rate of change as the sum of ﬂuctuations
and the diﬀerence of growth and death factors.
A selection pressure can be modeled when diﬀerent subspecies
compete for the same living conditions (e.g. the same food supply).
If the mutation rate for a special mutant is small, only that mutant
survives which has the highest gain factor and the smallest loss fac-

Symmetry and Complexity in Life Sciences
221
Fig. 69.
Bifurcation tree of evolution
tor and is thus the ﬁttest. The competition at a critical point of
instability can be formalized by a linear-stability analysis and adi-
abatic elimination: unstable mutants begin to dominate the stable
ones. They determine macroscopic features, which become order pa-
rameters of the new organism and species.

222
Symmetry and Complexity
Biological organisms function on many levels of dynamic activ-
ities that have emerged step by step during cosmic and biological
evolution [5.19]. The lowest are that of physics and chemistry. The
diagram of Fig. 70 is not deﬁnitive or complete in an ontological
sense. But, from a methological point of view, it represents a formal
scheme of research to explore the hierarchical structure of biological
organisms and, in general, biological systems. There may be further
hierarchical levels between the indicated ones. The hierarchy may
bifurcate for diﬀerent evolutionary trends. New levels may emerge
and disappear under changing circumstances. Thus, the hierarchy
is not static and ﬁxed for ever in the sense of Aristotle’s philosophy
of nature. On the other side, it is not only a mere ordering scheme
which has been invented by human mind for pragmatic concerns,
but a dynamical principle of biological organization which is well
conﬁrmed by observation.
According to the general scheme of nonequilibrium dynamics
(Fig. 49), we start with the microdynamics of a complex system.
It is a question of granulation how “deep” we like to lay the initial
layer of microdynamics. As far as we know at least atomic dynamics
inﬂuence states of living organisms. From the nonlinear dynamics at
each level, there emerge new entities that are characterized by order
parameters. The macrodynamics of these order parameters deter-
mine the microdynamics of the new entities, providing the basis of
macrodynamics on the following level. In principle, the dynamics
of each level could be modeled by appropriate nonlinear diﬀerential
equations.
In this case, the succeding hierarchical level could be
mathematically derived from the previous one by a linear-stability
analysis and adiabatic elimination. Actually, in many cases, we only
have simpliﬁed models that may inspire future research.
In some
cases there are already well established procedures encouraging the
use of the hierarchical scheme [5.20].
The hierarchical diagram of Fig. 70 is a scheme of self-organization
at several levels in a biological system. According to the laws of quan-
tum dynamics, atoms organize themselves into molecules.
Out of
the nonlinear interactions of molecules emerge the proteins acting as
catalysts in biochemical cycles. Biochemical cycles support the repli-

Symmetry and Complexity in Life Sciences
223
Fig. 70.
Emergent structures of life by self-organization
cation of biomolecules. Now, cellular dynamics come in. In the next
step, cells arrange themselves in organs, interacting in organisms.
Their nonlinear interactions determine the population dynamics of a
species, which is embedded in the environmental dynamics of nature.
Each level determines the following one. But sometimes, there are
not only direct feedbacks to the immediately preceding level, but also
to deeper ones. It is a well known fact of medicine that, for exam-
ple, physiology and cytology of our body are inﬂuenced by nutrition,
depending on the conditions of environment. The whole of our body
is more than the sum of its parts.
5.3
Complexity and Biodiversity of Life
The spontaneous emergence of organic forms has seemed to be a
miracle of life. Thus, in the history of science, morphogenesis was a

224
Symmetry and Complexity
prominent counterexample against physical reductionism in biology.
Today, morphogenesis is a prominent example for modeling biologi-
cal growth by complex dynamical systems. In this context, pattern
formation is understood as a complex process wherein identical cells
become diﬀerentiated and give rise to a well-deﬁned spatial struc-
ture. The ﬁrst dynamic models of morphogenesis were suggested by
N. Rashevsky, Turing, and others [5.21].
In the complex systems
approach, the emergence of cellular patterns is explained by com-
peting interactions of activator and inhibitor molecules. In a math-
ematical model due to A. Gierer and H. Meinhardt, two evolution
equations were suggested, describing the rate of change of activator
and inhibitor concentrations, which depend on the space-time coor-
dinates [5.22]. The change of rates is due to a production rate, decay
rate and diﬀusion term. Obviously, inhibitor and activator must be
able to diﬀuse in some regions in order to inﬂuence the neighboring
cells of some transplant. Furthermore, the eﬀect of hindering auto-
catalysis by the inhibitor must be modeled. The interplay between
activator and inhibitor can even lead to growing periodic and sym-
metric patterns, satisfying functional tasks (compare Figs. 61–63 in
Sec. 5.1).
To derive such patterns, it is essential that the inhibitor diﬀuses
more easily than the activator.
Long range inhibition and short
range activation are required for a non-oscillating pattern. By meth-
ods of mathematical analysis, the evolving patterns described by the
evolution equations of Gierer and Meinhardt can be determined. A
control parameter allows one to distinguish the stable ones in the
sense of a linear-stability analysis. According to the mathematical
procedure of an adiabatic elimination, the stable modes can be elim-
inated, and the unstable ones deliver order parameters determining
the actual pattern.
Thus, actual patterns come into existence by
competition and selection of some unstable solution. Selection ac-
cording to linear-stability analysis and adiabatic elimination means
reduction of complexity that stems from the huge number of degrees
of freedom in a complex system. Thus, evolution does not only mean
increasing complexity as H. Spencer proclaimed. The evolution of or-
der parameters requires reduction of complexity.

Symmetry and Complexity in Life Sciences
225
Fig. 71.
Phase transition of activator and inhibitor concentrations
Biochemically, this kind of modeling of morphogenesis is based on
the idea that a morphogenetic ﬁeld is formed by diﬀusion and reac-
tion of certain chemicals. This ﬁeld switches genes on to cause cell
diﬀerentiations. Independently of the particular biochemical mecha-
nism, morphogenesis seemes to be governed by a general scheme of
pattern formation in physics and biology. We start with a popula-
tion of totipotent cells corresponding to a system with full symmetry.
Then, cell diﬀerentation is eﬀected by changing a control parameter
that corresponds to symmetry breaking. The consequence is an ir-
reversible phase transition far from thermal equilibrium. In Fig. 71,
the phase transition of activator and inhibitor concentration is illus-
trated in a computer simulation [5.23].

226
Symmetry and Complexity
Since Antiquity, living systems were assumed to serve certain pur-
poses and tasks. Organs of animals and humans are typical examples
of functional structures that are explored by physiology and anatomy.
The complex bifurcations of vessel networks are examples of fractal
structures. The form of trees, ferns, corals and other growing sys-
tems are well described by fractals. Trees branching into open space
have room to expand. But hearts, lungs and other organs occupy a
limited space. The networks of nerves or vessels that penetrate them
are servants to the principal occupants of the space. The structure
of the microvascular network is virtually completely deﬁned by the
cells of the organ.
In skeletal and cardiac muscles the capillaries
are arrayed parallel to the muscle cells, with some cross-branches.
The system is guided in its growth by the need for the nerve or the
vascular system to follow the lines of least resistance.
Fractal illustrations of a bronchial network are an inspiration for
physicians to apply these approaches to the lung. Physical systems,
from galactic clusters to diﬀusing molecules, often show fractal be-
havior. Obviously, living systems might often be well described by
fractal algorithms. The vascular network and the processes of diﬀu-
sion and transmembrane transport might be fractal features of the
heart [5.24].
These fractal features provide a basis which enables
physicians to understand more global behavior such as atrial or ven-
tricular ﬁbrillation and perfusion heterogeneity.
Nonlinear dynamics allows us to describe the emergence of tur-
bulence, which is a great medical problem for blood ﬂow in arteries.
Turbulence can be the basis of limit cycling, as can be shown with
water ﬂowing through a cylindrical pipe. A variety of control systems
produce oscillations. It might also be expected that some oscillating
control systems show chaotic behavior.
Atrial and ventricular ﬁbrillation are the classic phenomena that
appear chaotic. The clinical statement on the heart rate in atrial ﬁb-
rillation is that it is completely irregular. The observations are that
the surface of the atrium is pulsing in an apparently chaotic fashion.
However, the studies of reentry phenomena and of ventricular ﬁbrilla-
tion show that there are patterns of excitation, again illustrating that
this is organized (“mathematical”) chaos [5.25]. Fractal and chaotic

Symmetry and Complexity in Life Sciences
227
algorithms for this have been described. Nevertheless, chaotic states
cannot generally be identiﬁed with illness, while regular states do
not always represent health. There are limited chaotic oscillations
protecting the organism from a dangerous inﬂexibility. Organs must
be able to react in ﬂexible ways, when circumstances change rapidly
and unexpectedly. The rates of heart beat and respiration are by no
means ﬁxed like the mechanical model of an idealized pendulum.
The coordination of the complex cellular and organic interactions
in an organism needs a new kind of self-organizing controlling. That
was made possible by the evolution of nervous systems that also en-
abled organisms to adapt to changing living conditions and to learn
from experiences with its environment. In Fig. 72 the levels of or-
ganization in the nervous system of the human body are illustrated
[5.26]. The hierarchy of anatomical organizations varies over diﬀer-
ent scales of magnitude, from molecular dimensions to that of the
entire central nervous system (CNS).
The scales consider molecules, membranes, synapses, neurons, nu-
clei, circuits, networks, layers, maps, systems and the entire nervous
system. On the right side of the ﬁgure, a chemical synapse is shown
at the bottom, in the middle a network model of how ganglion cells
could be connected to simple cells in visual cortex, at the top a sub-
set of visual areas in visual cortex, and on the left side the entire
CNS.
The research perspectives on these hierarchical levels may con-
cern questions, for example, of how signals are integrated in den-
drites, how neurons interact in a network, how networks interact in
a system like vision, how systems interact in the CNS, or how the
CNS interact with its environment. Each stratum may be character-
ized by some order parameters determining its particular structure,
which is caused by complex interactions of subelements with respect
to the particular level of hierarchy. Beginning at the bottom we may,
for instance, distinguish the orders of ion movement, channel conﬁg-
urations, action potentials, potential waves, locomotion, perception,
behavior, feeling and reasoning.
The neurons of animal organisms have been generated by evolu-
tion to carry impulses of electric voltage from one to another along

228
Symmetry and Complexity
Fig. 72.
Emergent structures of the nervous system
interconnecting ﬁbers or axons. Axons can be considered as tubes
of membrane which are semipermeable to ions of sodium (Na+) and
potassium (K+). In the early 1950s, A. Hodgkin and A. Huxley mea-
sured the sodium and potassium components of membrane ionic cur-
rent for several squid axons [5.27]. From these data they formulated
phenomenological expressions for the ion current ﬂowing out the cell
per unit area of the membrane. Furthermore, they introduced vari-
ables to represent the opening and closing of ionic channels across
the membrane. These empirically measured activities were modeled
by a nonlinear diﬀusion–reaction equation with an exact solution of
a traveling wave (Fig. 73), giving a precise prediction of the speed
and shape of the impulse of electric voltage.
On a ﬁber with x-direction, V (x, t) is the transverse voltage across the
cell membrane and i(x, t) the electric current, ﬂowing through the tube.
Ap-

Symmetry and Complexity in Life Sciences
229
plying Kirchoﬀ’s voltage and current laws delivers the diﬀerential equations
∂V/∂x = −ri and ∂i/∂x = −c∂V/∂t −ji with the longitudinal resistance r
per unit length of the ﬁber, the membrane capacitance c per unit length, and
the total ionic current ji ﬂowing across the membrane per unit length. The term
c∂V/∂t represents a displacement current ﬂowing through the membrane capaci-
tance. The ionic current is carried across the membrane through protein pores or
channels. The combination of these two equations delivers the Hodgkin–Huxley
equation ∂2V/∂x2 −rc∂V/∂t = rji. A nerve impulse as solution of this equation
is transmitted in the x-direction without attenuation because of the nonlinearities
in the representation of the ionic current [5.30].
Although the large amplitude impulse in Fig. 73 is a stable solitary
wave, moving with ﬁxed shape and speed, it diﬀers essentially from
solitons. A collision between two nerve impulses destroys both of
them. The Hodgkin–Huxley equation is no Hamiltonian with conser-
vation of energy, but a nonlinear diﬀusion equation. A linear-stability
analysis conﬁrms empirical evidence that impulses of greater speed
and amplitude are stable, whereas the slower and smaller travelling-
wave solution is unstable. The unstable wave in Fig. 73 determines
Fig. 73.
Emergence of a nerve impulse [5.28]

230
Symmetry and Complexity
threshold conditions for igniting the stable impulse. In general, nerve
impulses emerge as exact solutions of nonlinear diﬀerential equations.
Thus, they are new dynamical entities like ring waves in BZ-reactions
or ﬂuid patterns in nonequilibrium dynamics. They are the units of
neural interactions which provide the dynamics of neural pattern
formation, representing all kinds of motor, sensory or cognitive ac-
tivities of the brain. In short: they are the “atoms” of the complex
neural dynamics.
In order to model the brain and its complex abilities, it is quite
adequate to distinguish the following categories. In neuronal-level
models, studies are concentrated on the dynamic and adaptive prop-
erties of each nerve cell or neuron, in order to describe the neuron as
a unit. In network-level models, identical neurons are interconnected
to exhibit emergent system functions. In nervous-system-level mod-
els, several networks are combined to demonstrate more complex
functions of sensory perception, motor functions, stability control,
etc. In mental-operation-level models, the basic processes of cogni-
tion, thinking, problem-solving, etc. are described.
According to the complex systems approach, we have to deﬁne the
state variables and their dynamical equations generating the patterns
of interaction for each hierarchical level.
On the neural basis, we
distinguish neurons and synapses between them. Neurons have two
possible microstates, ﬁring and non-ﬁring a nerve impulse. In the
ﬁring state, the axon of a neuron opens small caves (vesicles) in its
end, ﬁlled with chemical substances (neurotransmitters) which are
transmitted into the synapses in order to activate a further neuron.
A neuron receives several input signals from a dendritic tree of input
channels. It ﬁres a nerve impulse if the weighted sum of its inputs
exceeds some threshold.
In 1949, D. Hebb already emphasized that to comprehend the
activity of the brain one should not only focus attention on isolated
neurons, but on cell assemblies [5.30]. He suggested that the brain
functions not merely by ﬁring and non-ﬁring neurons, but by acti-
vating assemblies of neurons. As in the evolution of living organisms,
the belief in organizing “demons” is dropped and replaced by self-
organizing procedures of the complex system approach.
Roughly

Symmetry and Complexity in Life Sciences
231
speaking, Hebb’s synaptic rule demands that the synaptic connec-
tion between two neurons should be strengthened if both neurons
ﬁred at the same time. Thus, the complex system approach oﬀers a
view of self-organizing networks changing their synaptic connections,
which are induced by synaptic activation and depend on the degree
of activation.
In the framework of neural complex systems, the microscopic level
of interacting neurons is distinguished from the macroscopic level
of global patterns produced as cell assemblies by self-organization.
Neural self-organization means that an assembly is formed by syn-
chronous activation according to a Hebb-like rule. C. von der Mals-
burg modiﬁed Hebb’s hypothesis by demanding that assembly for-
mation is produced by rapid synaptic changes [5.31]. Thus, there
is no “mother neuron” that can feel, think, or, at least, coordinate
the appropriate neurons. The binding problem of pixels and features
in perception is explained by cell assemblies of synchronously ﬁr-
ing neurons dominated by learnt attractors of brain dynamics. The
binding problem asked: How can the perception of entire objects
be conceived without decaying into millions of unconnected pixels
and signals of ﬁring neurons? H.B. Barlow’s theory assumed sin-
gle neurons for each property of a perceived object, other neurons
for clusters of properties, and, ﬁnally, a neuron for the entire object
(“grandmother neuron”) [5.32]. Thus, the brain needs an exploding
number of specialized neurons which must be postulated in ad hoc hy-
potheses for every new perception of changing situations. W. Singer
and others conﬁrmed von der Malsburg’s concept of synchronously
ﬁring neurons through observations and measurements [5.33].
In the complex systems approach, the microscopic level of inter-
acting neurons should be modeled by coupled diﬀerential equations
modeling the transmission of nerve impulses by each neuron. On
the macroscopic level, they generate a cell assembly whose macrody-
namics is characterized by some dominating order parameters. For
example, a synchronously ﬁring cell-assembly represents some visual
perception of a plant which is not only the sum of its perceived
pixles, but characterized by some typical macroscopic features like
form, background or foreground. On the next level, cell assemblies

232
Symmetry and Complexity
of several perceptions could interact in a complex scenario. In this
case, each cell-assembly is a ﬁring unit, generating a cell assembly of
cell assemblies whose macrodynamics is characterized by some order
parameters. The order parameters could represent similar proper-
ties between the perceived objects. By that, we get a classiﬁcation
of similar objects. For example, several similar plants may belong to
the same botanic category. In a next step, we may reﬂect on botanic
categories in general, and on categories of categories, and so on.
In Fig. 74, we distinguish a hierarchy of emerging levels of cogni-
tion, starting with the microdynamics of ﬁring neurons. Analogous
to Fig. 70, the diagram is not deﬁnitive or complete in an ontological
sense. But, from a methological point of view, it represents a for-
mal scheme of research to explore the hierarchical structure of neural
and cognitive dynamics of the brain. The dynamics of each level is
assumed to be characterized by diﬀerential equations with order pa-
rameters. For example, on the ﬁrst level of macrodynamics, order pa-
rameters characterize a visual perception. On the following level, the
observer becomes conscious of the perception. Then the cell assembly
of perception is connected with the neural area that is responsible for
states of consciousness. In a next step, a conscious perception can be
the goal of planning activities. In this case, cell assemblies of cell as-
semblies are connected with neural areas in the planning cortex, and
so on. Even high-level concepts like self-consciousness or historical
consciousness can be explained by self-reﬂections of self-reﬂections,
connected with a personal or public memory which is represented in
corresponding cell assemblies of the brain [5.34].
Neural states and the macrostates of cell assemblies that interact
to give brain function, generate a variety of pattern formation that is
well known from nonequilibrium dynamics. Brains undergo repeated
phase transitions. For example, locomotion is a state, within which
walking is a rhythmic pattern of activity that involves large parts
of the brain, spinal cord, muscles and bones. The entire neuromus-
cular system changes instantly with the transition to a pattern of
jogging or running. Brains undergo repeated transitions from wak-
ing to sleeping and back again, but still, giving the same persons as
the night before. Personal identity is an example of stability, equilib-

Symmetry and Complexity in Life Sciences
233
 
Fig. 74.
Emergent cognitive structures of the brain
rium and symmetry of brain states: The state of identity is invariant
with respect to time translation, although there may be local changes
with increasing aging. Brain states emerge, persist for a small frac-
tion of a second, then disappear and are replaced by other states. It
is the ﬂexibility and creativeness of this process that makes a brain
so successful in animals for their adaptation to rapidly changing and
unpredictable environments.
According to nonequilibrium dynamics, we can distinguish three
kinds of attractors.
The simplest is the ﬁxed point attractor.
In
this case, the system is at rest unless perturbed, and it returns to
rest when allowed to do so. Examples of neural point attractors are
silent neurons or cell assemblies that have been isolated from the
brain. A system that gives periodic behavior is said to have a limit
cycle attractor. When periodic activity of cell assemblies does occur,
it is either intentional, as in rhythmic drumming, clapping and danc-
ing, or it is pathological as in the periodic oscillations of the eyes in

234
Symmetry and Complexity
nystagmus, or of the limbs during Parkinsonian tremor. The third
type of attractor gives aperiodic and chaotic irregularities of the kind
that is observed in recordings of EEGs. Chaotic dynamics sensitively
depends on initial states. Therefore, the system behavior is unpre-
dictable in the long run, although a deterministic evolution equation
may be deﬁned explicitly. In the case of deterministic chaos, when the
systems only have a small number of components and a few degrees
of freedom, the attractors are mathematically well known. They can
be derived from the corresponding nonlinear diﬀerential equations or
by time-series analysis. They are mainly low-dimensional, stationary
and noisy-free.
Large and complex real-world systems, which include neurons
and neural populations, are noisy, nearly inﬁnite-dimensional, non-
stationary and non-autonomous.
These brain states are called
“stochastic chaos” by W. Freeman [5.35]. The source is postulated
to be the synaptic interaction of millions of neurons, which create
local ﬁelds of microscopic noise in the cortex. These activities are
revealed by spatial patterns of amplitude modulation (AM patterns)
of a spatially coherent aperiodic carrier wave in the gamma range of
the EGG. AM patterns play an essential role for perceptions, which
has been discovered in the olfactory brain by Freeman [5.36]. Percep-
tions are not only passive sensory mappings of the external world like
the pictures of a camera. Perceptions begin with selections according
to goals, motivations and preferences. They are goal-directed actions
through the participation of the limbic system with the neurochem-
ical nuclei in the brain stem that express and directly control the
state of the organism, body and brain. The limbic system is the neu-
ral part that provide emotional and motivational states of the brain.
AM patterns represent the intentionality of an individual, guiding
the brain to selected perceptions. In this sense, they can be consid-
ered as order parameters constraining and determining neurons and
cell assemblies for the selected features and context of a perception.
The discovery that brain dynamics operates in chaotic domains
has profound implications for the study of higher brain function.
A chaotic system has the capacity to create novel and unexpected
patterns of activity. Phase transitions between chaotic states consti-

Symmetry and Complexity in Life Sciences
235
tute the dynamics that we need to understand how brains perform
such remarkable feats as abstraction of the essentials of ﬁgures from
complex, unknown and unpredictable backgrounds, and constant up-
dating by learning. Stochastic chaos attractors are aperiodic with
limitations of long-term predictions and local islands of noise, but
still highly complex correlated mathematical structures. Complete
global noise is a stochastic state without any correlation between its
components. If the brain of an individual is at rest with no evidence
of overt behavior, then it is in a state of noise. The neurons ﬁre con-
tinually, but not in concert with each other. Any correlation between
neurons and assemblies has decayed. Therefore, the state of noise
has continual activity with no history of how it started and without
chance of prediction of when the next pulse and which next state will
occur. Nevertheless, noise is the substrate from which chaos and all
the other attractors emerge. Noise is essential for maintaining the
health of neurons, because they must stay active in order to survive.
Brains of animals are no isolated monads, but embedded in the
social dynamics of their species. Animal populations can be charac-
terized on a scale of greater or lesser complexity of social behavior.
There are populations of insects with a complex social structure,
which is rather interesting for sociobiology.
The interactions be-
tween individuals are physically realized by sound, vision, touch and
the transmission of chemical signals. The complex order of the sys-
tem is determined by functional structures like the regulation of the
castes, nest construction, formation of paths, the transport of materi-
als or prey, etc. Ants synthesize chemical substances, which regulate
their behavior. They have a tendency to follow the same direction
at the place where the density of the chemical molecules reaches a
maximum. Collective and macroscopic movements of the animals are
regulated by these chemical concentrations.
In order to model the collective movements, two equations are
suggested, considering the rate of change for the concentrations of
insects and chemical substances. There is a critical value of an order
parameter (“chemicotactic coeﬃcient”) for which a stationary ho-
mogeneous solution becomes unstable. The system then evolves to
an inhomogeneous stationary state. Accordingly, diﬀerent branching

236
Symmetry and Complexity
Fig. 75.
Bifurcation tree and attractors of ant population
structures will appear, as observed in diﬀerent ant societies. Fig. 75
shows the collective movement of ants with two types of structure
characteristic of two diﬀerent species [5.37].
The social complexity of insects can also be characterized by such
coordinated behavior as nest construction. This activity has been
well observed and explored by experimental studies. A typical ob-
servation is that the existence of a deposit of building material at
a speciﬁc point stimulates the insects to accumulate more building
material there.
This is an autocatalytic reaction which, together
with the random displacement of insects, can be modeled by three
diﬀerential equations. These equations refer to the observation that
the termites, in manipulating the construction material, give it the
scent of particular chemical substance, which diﬀuses in the atmo-

Symmetry and Complexity in Life Sciences
237
sphere and attracts the insects to the points of highest density, where
deposits of building material have already been made.
Thus, the ﬁrst equation describes the rate of change of the con-
centration of building material, which is proportional to the concen-
tration of insects. A second evolution equation refers to the rate of
change of the scent with a certain diﬀusion coeﬃcient. A third evo-
lution equation describes the rate of change of the concentration of
insects including the ﬂow of insects, diﬀusion and motion directed
toward the sources of the scent.
The complex social activity of nest construction corresponds to
the solutions of these equations. Thus, an uncoordinated phase of
activity in the beginning corresponds to the homogeneous solution
of these equations. If a suﬃciently large ﬂuctuation with a larger
deposit of building material is realized somewhere, then a pillar or
wall can appear. The emergence of macroscopic order, visualized in
the insect’s architecture of nests, has been caused by ﬂuctuations
of microscopic interactions.
There is no insect as commander-in-
chief with a master plan in its brain, but a chemical diﬀusion ﬁeld,
guiding the local activities of individuals. The guiding ﬁeld can be
represented by an order parameter, which is sometimes called “swarm
intelligence”: the swarm knows more than its individuals. Again, the
whole is more than the sum of its parts.
Insect colonies are only examples of populations in complex
ecosystems that have been generated during evolution. Ecosystems
are the results of physical, chemical and biotic components of na-
ture acting together in a structurally and functionally organized sys-
tem. Ecology is the science of how these living and nonliving com-
ponents function together in nature. Obviously, in the framework of
the complex system approach, ecology has to deal with dissipative
and conservative structures of very high complexity depending on
the complexity of the individual physical, chemical and biotic sys-
tems involved in them and the complexity of their interactions [5.38].
Since the co-evolution of human civilization, the ecological equilibria
on earth have become highly critical. It is a challenge of complexity
research to support a sustainable future of ecological dynamics on
earth.

This page intentionally left blank

Chapter 6
Symmetry and Complexity in
Economic and Social Sciences
Sociodynamics of human societies have emerged from population dy-
namics during the evolution of life on earth. After thermodynamic,
genetic, and neural self-organization, we have to explore a new kind
of complex systems dynamics. The self-organization of social and
economic structures is explored in social and economic sciences. In
this context, symmetry is a functional principle that is associated
with basic ideas of social organization. Justice in law, equality of
people in constitutions, human welfare, social and economic stability
have been founded by principles of symmetry. In early cultures, so-
cial symmetry was ontologically identiﬁed with the symmetry of the
universe. In modern societies, it is a dynamical principle that can be
modeled in the framework of nonequilibrium dynamics. Symmetry
breaking and socio-economic transitions are related to critical insta-
bilities and shifts of historical, economic, and political developments.
In the age of globalization, local regions, nations and industries com-
pete in global markets and political conﬂicts of high instability. The
increasing complexity of social, economic, political and cultural prob-
lems is a challenge of global governance, which means the decision
on the order parameters of human future.
6.1
Symmetry, Social Balance, and Economic Equilibrium
In all early cultures of mankind, the stability of a society has been
associated with ideas of symmetry.
For example, justice means a
state of completion if the society is arranged in its harmonic propor-
239

240
Symmetry and Complexity
tions in equilibrium, like the static balance of a scale. In a picture of
ancient Egypt (2nd century B.C.), Gods arrange the “last judgment
of Osiris” with a divine scale (Fig. 76). According to Confucian, as
well as Greek philosophers, the rules of justice are founded on the
cosmic laws of harmony (compare Sec. 1.1).
Fig. 76.
Divine balance in the last judgment of Osiris
In modern times, symmetry and equilibrium of societies have been
conceived in the framework of classical physics. Since the religious
and political unity had been destroyed in Europe in long civil wars,
people longed for security and peace. T. Hobbes (1588–1679), for
example, projected a mechanistic model of society and state at the
end of the Middle Ages and the beginning of modern times [6.1]. In
order to guarantee the “law of peace”, all citizens have to transfer
their natural right of power to an absolute sovereign (“Leviathan”)
who is alone legitimated to apply political power and to rule the
state. Thus, Hobbes’ social contract legitimates the state’s monopoly
of power in order to keep society in an absolute equilibrium. The
“phase transition” from the natural state of chaos to political order
and equilibrium is realized by a social contract of all citizens.
In

Symmetry and Complexity in Economic and Social Sciences
241
the same manner, the economic system was modeled by the physio-
cratic economists as a mechanistic clockwork of cog wheels, springs,
and weights [6.2]. A clock is a sequentially operating system with
programmed functions. Analogously, the physiocratic economy can-
not regulate itself. Advances in agriculture, which are the driving
forces of the physiocratic economy, are compared with the weights
and springs of a clock.
Economic production was referred to the
composed movements in a clock. Consequently, economic prosperity
is only guaranteed by a regular economic circulation like a clock-
work.
Its causal determinism without any kind of self-regulation
or individual freedom corresponds completely to the political sys-
tem of absolutism during the 17th and 18th century.
The citi-
zens are reduced to functioning elements in a political and economic
machine.
While the physiocrats designed their economic model against the
Cartesian background of a mechanistic clockwork, Smith referred to
Newton’s classical physics. In Newton’s celestial mechanics, material
bodies move in a system of dynamical equilibrium that is determined
by the invisible forces of gravitation. The physical concept of freely
moving individuals in dynamical equilibrium corresponds to the lib-
eral ideas of a free economy and society with the division of indepen-
dent political powers. Contrary to the liberal ideas, the Cartesian
clockwork of nature seems to accord with the state machinery of
absolutism with its citizens as cog wheels. Locke’s liberal ideas of
democracy with division and balance of power mainly inﬂuenced the
American and French constitutions.
In his famous “Inquiry into the Nature and Causes of the Wealth
of Nations” (1776) [6.3], Smith emphasized that human self-interest
is not a theoretical construction of economists, but an empirical fact
of experience. Self-interest is a strong and natural impulse of single
human beings, and therefore a human right. But the interactions
of several single micro-interests achieve the common macro-eﬀect of
welfare by the mechanism of the market.
The mechanism of the
market is regulated by supply and demand, driving the competing
micro-interests to the macro-eﬀect of welfare and the “wealth of the
nation” in the equilibrium of the market. In the mechanistic view, the

242
Symmetry and Complexity
micro-interests seem to be drawn to the common macrostate of equi-
librium by an “economic demon” or mechanical spring. According
to the Newtonian method, Smith prefers the picture of an “invisible
hand” directing the micro-interests like the “invisible” long-distance
force of gravitation in astronomy.
Obviously, Smith describes an
economy as a complex system of many competing micro-interests
[6.4]. The dynamics of their interactions is a self-organizing process
of competition with a ﬁnal state of equilibrium between supply and
demand.
Smith provided the ﬁrst model of an economic equilibrium theory
that has become the hard core of classical and neo-classical eco-
nomics.
In the 19th century, predecessors of modern mathemati-
cal economics propagated the use of the mathematical methods of
physics in economics [6.5]. They spoke of a more or less rough corre-
spondence between the play of economic forces and mechanical equi-
librium. Actually, much of their vocabulary was borrowed from me-
chanics and thermodynamics, for instance, equilibrium, balance, sta-
bility, elasticity, expansion, inﬂation, contraction, ﬂow, force, pres-
sure, resistance, reaction, movement, friction and so on. A market
exists for a commodity if the commodity can be transferred from
any individual to any other without cost.
A market clears when,
at a certain price, the demand and supply of its commodity are in
balance. The price that clears the market is called the equilibrium
price of the commodity.
Idealized equilibrium models assume the
existence and clearance of markets for all commodities like physical
equilibrium models without friction.
In order to understand general ideas of economic equilibrium the-
ory, some more economic terminology must be introduced: an econ-
omy is perfectly competitive if all individuals are passive price tak-
ers that cannot inﬂuence prices. Thus, monopolists and oligopolists,
which can inﬂuence prices, are failures of perfectly competitive mar-
kets. The commodities are the resource of an economy. The resource
is allocated through the transformation of commodities in produc-
tion and the transfer of ownership in exchange. The microstates of
these transformations and transfers are called resource allocation. A
competitive equilibrium is a resource allocation in which all markets

Symmetry and Complexity in Economic and Social Sciences
243
clear. Classical and neo-classical theorists have tried to ﬁnd the con-
ditions under which competitive equilibria exist for perfectly compet-
itive markets. If all engaged individuals of a market are completely
self-interested without any cooperation, all competitive equilibria are
asserted to be Pareto-optimal. An allocation is Pareto-optimal if any
alteration will make at least one individual worse oﬀ.
In the 20th century, economists gave up physical analogies and
tried to found their own mathematical instruments.
A milestone
for mathematical equilibrium theory has been von Neumann’s and
Morgenstern’s game theory [6.6]. Game theory aims to understand
situations in which decision-makers interact.
Examples are chess
as well as ﬁrms competing for business, politicians competing for
votes, nations competing for dominance or armies in wars [6.7]. A
game is a mathematical description of a strategic interaction. Any
strategic interaction involves two or more decision makers (players),
each with two or more ways of acting (strategies).
The outcome
depends on the strategy choices of all the players. Each player has
well deﬁned preferences among all the possible outcomes. A formal
representation of a game makes explicit the rules of interaction, the
players’ strategies, and their preferences over outcomes.
A possible representation of a game is in normal form. A normal-
form game is completely deﬁned by a list of players Pi (i = 1, . . . , n),
a ﬁnite set of pure strategies si for each player Pi, and a utility
function ui that gives player Pi’s payoﬀui(s1, . . . , sn) for each n-
tuple of strategies. Simple applications are the so-called zero-sum
games of two persons. In this case, the gain of a player P1 is the loss
of the other player P2 and vice versa, i.e. u1 = −u2. If each player has
two possible strategies, the possible strategic interactions with their
corresponding payoﬀs are represented in a 2×2 matrix (Fig. 77a). If,
for example, player P1 chooses strategy s11 and player P2 strategy
s21, then player P1 gets payoﬀ4 and player P2 the corresponding
loss −4.
Whereas
normal-form
games
are
represented
by
matrices,
extensive-form games are represented by trees. A matrix descrip-
tion shows the outcomes, represented in terms of players’ payoﬀs for
every possible combination of strategies the players might choose. A

244
Symmetry and Complexity
(a)
(b)
(c)
Fig. 77.
Matrices of strategies in normal-form games
tree representation is sequential, because it shows the order in which
actions are taken by the players. In Fig. 78, the nodes of a game
tree represent events of decisions. The branches are the alternative
decisions. The name of each player P1 and P2 is indicated besides
the nodes. After their choices of strategies, the players arrive at the
ﬁnal nodes and get their payoﬀs, which corresponds to the matrix in
Fig. 77a.
A game tree looks like a bifurcation tree of events in nonequilib-
rium dynamics. But, there is a main diﬀerence. What is important,
is not the temporal order of events, but whether players know about
other players’ actions when they have to choose their own. Thus,
the information a player has when he/she is choosing an action is
explicitly represented in a game tree by an information set (closed
curve in Fig. 78). If an information set contains more than one node,
the player who has to make a choice at that information set will
be uncertain as to which node he/she is at. Not knowing at which
node one is means that the player does not know which action was
chosen by the preceding player. If a game tree has information sets
with more than one node, the corresponding game is one of imperfect
knowledge.
Because of its uncertainty, each player tries to minimize the max-
imal disadvantage of its actions.
Therefore, player 1 chooses the
maximin-strategy si, for which the minimum minj ui(si, sj) among
all alternatives is maximal. If the corresponding maximum is min-
imal, the strategy is called minimax-strategy.
In Fig. 77a player
P1 will prefer strategy s12 and player P2 strategy s22.
For all

Symmetry and Complexity in Economic and Social Sciences
245
Fig. 78.
Bifurcation tree of strategies in extensive-form games
strategies s1 of player P1, it follows u1(s1, s22) ≤u1(s12, s22) and
u2(s12, s2) ≤u2(s12, s22) for all strategies s2 of player P2.
Thus,
point (s12, s22) is called the equilibrium point of this game. No player
can improve his/her situation by changing its strategy. But these in-
equalities of utilities are not true in general. In Fig. 77b, again, player
P1 will prefer strategy s12 and player P2 strategy s22. But contrary
to the game in Fig. 77a, the ﬁrst inequality is violated: player P1 can
improve his/her situation with respect to point (s12, s22) by choosing
s11. Nevertheless, a rational decision is possible if the players change
from pure strategies to mixed strategies.
A mixed strategy s∗
i of player i is a probability distribution over its pure
strategies si. For mixed strategies the utility functions of payoﬀs must be ex-
tended to the concept of expected utility. Let us assume that the mixed strategy
s∗
1 of player P1 means to use his/her pure strategies s1k with probabilities pk.
The mixed strategy s∗
2 of player P2 may be a randomization over his/her pure
strategies s2m with probabilities pm. In this case, the function u∗
i of expected
utility is deﬁned by u∗
i (s∗
1, s∗
2) = Σk,mpkpmui(s1k, s2m) with i, k, m = 1, 2. Von
Neumann proved a fundamental theorem for zero-sum games of two persons: for
each game of this kind, the mixed extension has maximin-solutions s∗
1 and s∗
2
with (s∗
1, s∗
2) as equilibrium point. Under this condition, it is useful to choose a
pure strategy by a procedure of randomization. Appropriate mixed strategies are
found by procedures of linear optimization.

246
Symmetry and Complexity
If players are allowed to enter into binding agreements before
the game is played, we say that the game is cooperative. Nonco-
operative games instead make no allowance for the existence of an
enforcement mechanism that would make the terms of the agree-
ment binding on the players. The concept of equilibrium points was
extended to noncooperative games by J.F. Nash [6.8]. According to
the central dogma of game theory, rational players will always jointly
maximize their expected utilities. In this sense a Nash equilibrium
speciﬁes players’ actions and beliefs such that (1) each player’s ac-
tion is optimal given his/her beliefs about other players’ choices, and
(2) players’ beliefs are correct. Thus, an outcome that is not a Nash
equilibrium requires either that a player chooses a suboptimal strat-
egy, or that some players misperceive the situation. More formally,
a Nash equilibrium is a vector of strategies (s1, . . . , sn), one for each
of the n players Pi in the game, such that si (i = 1, . . . , n) is a best
reply to s−i. (All players other than some player Pi are customarily
denoted as −i). Note that optimality is only conditional on a ﬁxed
s−i, not on all possible s−i. A strategy that is a best reply to a given
combination of the opponent’s strategies may fare poorly vis-`a-vis
another strategy combination.
A pure-strategy Nash equilibrium is a speciﬁcation of a strategy
for each player, such that no single player can increase his/her payoﬀ
by changing his/her strategy if the rest of the players stick to their
strategies [6.9]. Fig. 77c illustrates a noncooperative game with the
payoﬀs for player P1 as ﬁrst number and the payoﬀs for player P2 as
second number. The strategy interaction (s12, s22) is a Nash equi-
librium point. For player P1 the situation is like this: if player P2
adopts the strategy s21, then s12 is the better reply. If player P2
adopts s22, the strategy s12 is better. Therefore s12 is the sure-win
choice. Player P2 reasons similarly. So they end up with the pay-
oﬀ(s12, s22). But the obviously better strategy interaction (s11, s21)
with payoﬀ(3,3) is not a Nash equilibrium, for if either player sticks
to it, the other can proﬁt by defecting.
The game is an example
of the prisoner’s dilemma. In these situations, the isolated rational
behavior of a player does not provide the socially desired result that
can only be realized by the cooperation of the players.

Symmetry and Complexity in Economic and Social Sciences
247
A pure-strategy Nash equilibrium does not always exist. But Nash
proved that at least one mixed-strategy Nash equilibrium exists for
any ﬁnite noncooperative game. An example is the so-called battle
of the sexes.
A man and a woman engage in a game of deciding
whether to attend a football game or a concert. The man prefers the
game, the woman the concert, but each prefers having the company
of the other to being alone in the preferred activity. They settle in
a Nash equilibrium by ﬂipping a coin to decide where both will go.
Nash’s result generalizes von Neumann’s theorem that every game
with ﬁnitely many strategies has an equilibrium in mixed strategies.
Often a game has a variety of Nash equilibria. Therefore more re-
strictive solution concepts with a reﬁnement of the Nash equilibrium
has been explored [6.10].
A Nash equilibrium needs not be inter-
preted as a unique event. If we think of it as an observed regularity,
we want to know by what process such equilibrium is reached and
what accounts for its stability.
When multiple equilibria are pos-
sible, we want to know why players converged to one in particular
and then stayed there. An alternative way of dealing with multiple
equilibria is to suppose that the selection process is made by nature.
An example is the evolutionary stable strategy in biology, in order
to ﬁnd the stable equilibrium composition of a population. In social
sciences, the formalism can also be applied to human populations or
ethnic groups.
In evolutionary game theory, a kind of organism is represented by
a player, biological actions or reactions by strategies, the interactions
of organisms displaying various behaviors by matching various strate-
gies [6.11]. The ﬁtness of a behavior may be the relative growth rate
of the fraction of organisms in the population. With the knowledge
of the ﬁtness, the composition of the population changes in succes-
sive generations can be determined. The game aims to ﬁnd a stable
composition of the population. J. Maynard Smith introduced the
solution of an evolutionary stable strategy (ESS). An ESS is a Nash
equilibrium that is robust or stable in the sense that slight deviations
damp out and the population returns to its equilibrium state [6.12].
In the framework of complex systems, ESS are stable ﬁxed point
attractors of evolutionary dynamics. Thus, the game-theoretical ap-

248
Symmetry and Complexity
proach can be embedded into the theory of equilibrium dynamics.
But modeling social and evolutionary dynamics needs more than the
analysis of these special attractors of equilibrium: it needs the whole
framework of nonequilibrium dynamics.
6.2
Symmetry Breaking and Socio-economic Transitions
In cultural and social history, symmetry has been associated with
balance and stability of a society.
But, actually, as we all know,
phases of stability change with phases of instability and sometimes
chaos. New political and social order emerges and old ones decay
and disappear. Some philosophers (e.g. A.J. Toynbee) suggested a
life cycle theory of civilizations and compared their quasi-cyclic de-
velopment with the stages of childhood, adolescence, maturity, and
old stage of an organism. But metaphoric analogies are no explana-
tions. Critical situations lead to phase transitions of global events
like wars and revolutions, fashions and life styles. Symmetry break-
ing is obviously the driving force of political, economic, and cultural
development [6.13]. How can it be explained in the framework of
complex dynamical systems?
In the complex system approach we distinguish the microscopic
and the macroscopic point of view. On the microscopic level, indi-
viduals interact und generate patterns of behavior, social structures,
order or disorder on the macroscopic level of groups, institutions,
and societies. Collective social order emerges by contributions of in-
dividuals to the macrostate of a society. In a causal feedback loop,
the individuals are also inﬂuenced by the collective order achieved by
themselves. Consider, for example, the voting behavior of people be-
fore a political election. Emerging clusters of individual opinions are
represented by political parties, which are the “order parameters” of
the voting dynamics inﬂuencing the individual behavior [6.14]. This
is the general scheme of emergence and self-organization of order in
complex dynamical systems, which was conﬁrmed in physical, chem-
ical, and biological examples.
Although these systems diﬀer in their microdynamics of atoms,
molecules, cells, or neurons, they have surprising similarities in their

Symmetry and Complexity in Economic and Social Sciences
249
macrodynamics of attractors. Therefore, we distinguished, for ex-
ample, thermodynamic, genetic, and neural self-organization in the
previous chapters. In these cases, the individual interactions of sys-
tem elements can be modeled by nonlinear equations. The emerging
macroscopic structures correspond to solutions of these equations.
Thus, at least in principle, the macrodynamics can be explained
by the microdynamics of the system.
But, in contrast to physi-
cal, chemical, and biological systems, no equations of motion on the
microlevel are available for social systems. People are not atoms or
molecules, but human beings with intentions, motivations, and emo-
tions.
In principle, their individual behavior and decision-making
could be explained by their brain dynamics.
Cognitive and emo-
tional dynamics are determined by order parameters characterizing
individual thoughts, decisions, and motivations (Fig. 74). But this
is only a theoretical option, because the corresponding neural equa-
tions are not yet known. Furthermore, they would be too complex
to solve them and predict the future behavior of people.
In economics, new classical theorists assume the microeconomic
model of perfectly competitive markets [6.15]. Perfect competition
or perfect market coordination means, for example, perfect wage
and price ﬂexibility. People should behave with economic rational-
ity (“homo economicus”) optimizing their utilities under constraints.
Then, wages and prices should always adjust themselves to clear all
markets.
If they are displaced from their equilibrium path by an
exogenous shock (e.g. unemployment), wage and price adjustment
rapidly returns it to equilibrium with a cleared labor market. In this
microeconomic model, people seem to behave like the constituents of
a spin-glass which separately attain their individual optimal states
of lowest energy.
Obviously, the new classical economists believe
in equilibrium dynamics.
But, the question arises whether wages
and prices always adjust themselves in a suﬃciently short time and
not only “in the long run when we are all dead”, as J.M. Keynes
emphasized. Actually, human agents act neither completely rational
nor completely irrational. They deviate from game-theoretically pre-
dicted equilibria. Complexity, chaos, randomness, and incomplete-
ness of information enforce them to decide and act under conditions

250
Symmetry and Complexity
of bounded rationality. Bounded rationality results from limitations
on our knowledge, cognitive capabilities, and time [6.16]. Our per-
ceptions are selective, our knowledge of the real world is incomplete,
our mental models are simpliﬁed, our powers of logical deduction
are weak and fallible. Emotional and subconscious factors aﬀect our
behavior. Deliberation takes time and we must often make decisions
before we are ready.
Therefore an alternative approach is suggested which gets along
without microscopic equations, but nevertheless takes into account
the decisions and actions of individuals with probabilistic methods in
order to derive the macrodynamics of social systems. The modeling
design consists of three steps: In the ﬁrst step appropriate variables of
social systems must be introduced to describe the states and attitudes
of individuals. The second step deﬁnes the change of behavior by
probabilistic phase transitions of individual states. The third step
derives equations for the global dynamics of the system by stochastic
methods [6.17].
In a society we can distinguish several sectors and sub-sectors that
are denoted by variables. There are variables for material states, ex-
tensive and intensive personal states. The socioconﬁguration of a so-
cial system is characterized by these material and personal macrovari-
ables. They are measured by usual methods of demoscopy, sociology,
or economics. Like in thermodynamics, there are intensive economic
variables that are independent of the size of a system.
Examples
are prices, productivity, and the density of commodities. Extensive
variables are proportional to the size of a system and concern, for
example, the extent of production and investment, or the size and
number of buildings. Collective material variables are measurable.
Their values are inﬂuenced by the individual activities of agents,
which are often not directly measurable.
The social and political
climate of a ﬁrm is connected to socio-psychological processes, which
are inﬂuenced by the attitudes, opinions, or actions of individuals and
their subgroups. Thus, in order to introduce the socioconﬁguration of
collective personal variables, we must consider the states of individu-
als, expressed by their attitudes, opinions, or actions. Furthermore,
there are subgroups with constant characteristics (e.g. sections or

Symmetry and Complexity in Economic and Social Sciences
251
departments of a ﬁrm or an institution), so that each individual is a
member of one subgroup. The number of members of a certain state
is a measurable macrovariable. The socioconﬁguration of, for exam-
ple, a company is a set of macrovariables describing the distribution
of attitudes, opinions, and actions among its subgroups at a partic-
ular time. The total macroconﬁguration is given by the multiple of
material conﬁguration and socioconﬁguration.
If all macrovariables of a macroconﬁguration remain constant over
time, the social system is in a stationary macroscopic equilibrium,
which can be compared to thermodynamic equilibrium. If there are
dynamics, we must consider the transition rate between macrocon-
ﬁgurations by either increasing or decreasing macrovariables.
In
the case of material conﬁguration, an elementary change consists
of the increase or decrease of one macrovariable (e.g. the price of
commodities) by one appropriately chosen unit.
The elementary
change in the socioconﬁguration takes place if one individual of a
subgroup changes its state, leading to an increase or decrease in the
number of a subgroup by one unit.
For example, the variable of
employment is diminished or enlarged by one person or a political
voter changes his preferred party in a certain period of time. These
transitions of individual states should be described by a probabilis-
tic process, because the individual freedom of decision and action
should not be restricted. People are not molecules with determin-
istic microdynamics. Nevertheless, the phase transitions must take
into account running trends and motivations in order to get a re-
alistic estimate of the probabilities. These aspects provide the link
between the microlevel of individual decisions and the macrolevel of
collective behavior. There are well-known statistical procedures of
data-mining to measure probabilistic trends, motivations, and atti-
tudes of people belonging to certain sections and subsections of a
society.
The probabilistic phase transitions can be used for setting up
the macroevolution equation of a social system. The probabilistic
macrobehavior of a society is described by a probability distribution
function over its possible socioconﬁgurations at a certain time. The
distribution function P(m, n; t) can be interpreted as the probability

252
Symmetry and Complexity
of ﬁnding a certain macroconﬁguration of material conﬁguration m
and socioconﬁguration n at time t. The evolution of the social sys-
tem is the time-depending change of its probabilistic macrobehavior,
i.e. the time derivative of the probability function dP(m, n; t)/dt.
Thus, we get a stochastic nonlinear diﬀerential equation which is
well-known in thermodynamics as master equation [6.18]. In natural
science (e.g. thermodynamics), the evolution of a whole ensemble of
millions of equally prepared but probabilistically evolving systems
(e.g. gas, ﬂuids) can often be measured. Therefore, the master equa-
tion with its probabilistic distribution function of macrostates is ap-
propriate in natural sciences, although only numerical solutions are
in general available.
This method of modeling macrodynamics is
called ensemble approach.
But social sciences (e.g. economics, politics, sociology) only dis-
pose of one or at best of a few comparable systems [6.19]. There-
fore, the probability distribution of the master equation contains too
much information in comparison to the available empirical data. So-
ciodynamics focuses on the stochastic evolution of a single system in
which it traverses probabilistically a sequence of system states. In the
corresponding state space of socioconﬁgurations, we get stochastic
trajectories describing the probabilistic dynamics of social systems.
The stochastic evolution of a single social system is determined by
autonomous nonlinear diﬀerential equations for the stochastic trajec-
tories of material, extensive and intensive personal variables. In this
sense, the emergence of social structures and patterns of behavior
can again be modeled by solutions of nonlinear equations.
In the framework of nonlinear dynamics, we can consider phase
transitions as examples of social symmetry breaking [6.20]. An eco-
nomic example is the following model of two competing ﬁrms pro-
viding a bifurcation into winner and loser at a critical value of com-
petition (Fig. 79). In nonlinear dynamics, order parameters of the
macrodynamics of a system are introduced by linear-stability anal-
ysis. The idea of our model is that quality is the order parameter
of competition dominating all other economic aspects.
Thus, pa-
rameters of, for example, prices, supply, or purchase activities of
customers can be neglected, and we get an macroevolution equation

Symmetry and Complexity in Economic and Social Sciences
253
of quality. The evolution of the quality variables qi for ﬁrm i = 1
and ﬁrm i = 2 can be investigated numerically. In Fig. 79, their (sta-
tionary) solutions qi(φ) are depicted as a function of the competition
parameter φ. It turns out that both ﬁrms have the same stationary
quality q(φ) of their products and also the same stationary market
share, as long as the competition value φ is smaller than a critical
value φc. At φc, a bifurcation occurs and for φ > φc there exist two
stable quality values q+(φ) and q−(φ). The winning ﬁrm, say i = 1,
will have reached the quality q+(φ), whereas the losing ﬁrm, i = 2,
arrives at quality q−(φ) with corresponding market shares.
Another example of social phase transitions and symmetry break-
ing is provided by world-wide migration processes. The behavior and
the decisions of people to stay or to leave a region are illustrated by
spatial distributions of populations and their change [6.22].
The
models may concern regional migration within a country, motivated
by diﬀerent economic and urban developments, or even the dramatic
worldwide migration between poor and rich countries in the age of
globalization. The migration interaction of two human populations
Fig. 79.
Bifurcation tree of economic symmetry breaking [6.21]

254
Symmetry and Complexity
may cause several macro-phenomena, such as the emergence of a
stable mixture, the emergence of two separated, but stable ghettos,
or the emergence of a restless migration process [6.23]. In numeri-
cal simulations and phase portraits of the migration dynamics, the
macro-phenomena can be identiﬁed with corresponding attractors.
The empirical administrative data can be used to test the models.
In the case of a stable mixture, the integration of, for example,
two ethnic groups, was successful. The phase portrait of the ”melt-
ing pot” shows a stable point of equilibrium and the corresponding
master equation has a stationary solution with a centralized prob-
abilistic distribution. If two isolated ghettos emerge in the region,
the phase portrait shows two stationary ﬁxed points corresponding
to solutions with separated probabilistic distributions (Fig. 80a,b).
The situation seems to be symmetric, but like scales highly sensible
to tiny ﬂuctuations. In reality, there are not only two subsystems,
but an environment with nonlinear dynamics. Thus, the balance can
break down and end in chaos.
Fig.
81 corresponds to a restless
migration process with a strong asymmetric interaction between the
populations. The phase portrait Fig. 81a shows a limit cycle with
unstable origin. The stationary probabilistic distribution of Fig. 81b
has four maximum values with connecting ridges along the limit cy-
cle. This case may be interpreted as sequential erosion of regions by
asymmetric invasion and emigration of the populations. Mathemati-
cally, the limit cycle with unstable origin is similar to the destroying
dynamics of a hurricane.
If we consider more than two populations, deterministic chaos can
emerge in unstable situations. Numerical simulations lead to strange
attractors as ﬁnal states of trajectories. In other cases, a successive
bifurcation becomes more and more complex with a ﬁnal transition
to chaos.
Another challenge of global phase transitions is urbanisation
which means pattern formation of new metropolitan areas [6.26].
Historically, urban evolution started with simple closed patterns of
settlements. In Antiquity, early plans of cities and buildings were
symmetric according to ancient theories of proportionality.
Cap-
itals were considered as mirrors of an eternal cosmic order with

Symmetry and Complexity in Economic and Social Sciences
255
(a) phase portrait with ﬂux lines
(b) probabilistic distribution
Fig. 80a–b.
Fixed point attractors of migration dynamics [6.24]
(a) phase portrait with ﬂux lines
(b) probabilistic distribution
Fig. 81a–b.
Unstable limit cycle of migration dynamics [6.25]
temples, churches, or palaces of emperors in the symmetric center.
Thus, they were planned and built for eternity. In Renaissance and
baroque time, the geometric symmetry of a city, settlement or gar-
den (e.g. French garden) was a symbol of “cartesian” rationality that
was demanded by Descartes, a leading philosopher and mathemati-
cian of the 17th century. Administration and organization of human
life should become completely computable like celestial mechanics.

256
Symmetry and Complexity
In the 19th century, symmetries of cities became an expression of
the Laplacian spirit of linearity, perfect calculation and centralized
administration. Cities with their rectangular or centralized nets of
streets and avenues were constructed by architects like closed systems
of sub-modules which should be in absolute equilibrium.
But, actually, we observe a historical evolution of cities from sim-
plicity and symmetry to complexity, diversity, and fractality [6.27].
The initial symmetric structures had been broken by urban phase
transitions.
Fig. 82 shows the complex dynamics of metropolitan
areas from closed settlements in Antiquity to fractal attractors in
the age of globalization, self-organizing during centuries [6.28]. Gen-
erations of people had been engaged in the global dynamics with
their local activities without a centralized master plan. Even if there
are historical settlements with symmetric regularity, they are nowa-
days embedded and encapsulated as local areas in the complex ur-
ban structure of a metropolis like tissue in a growing cellular or-
ganism.
Cities can be considered as complex urban systems with
pattern formation on a square lattice of plots and sociodynamics of
socioconﬁgurations, depending on material variables with, for exam-
ple, numbers of lodgings, factories, or greens, economic capacity of a
plot, extensive personal variables with population of regions, utility
functions and distance-depending transition rates of city conﬁgura-
tion. The distribution of ﬁrms, residential or shopping areas on the
macroscopic level interacts with the material, intellectual, political
and social life of the inhabitants on the microlevel.
With given transition rates between the plots coupled equations
for city and population evolution can be set up. They provide a mas-
ter equation for the probability distribution over city and population
conﬁguration, and equations for stochastic trajectories of the sys-
tems. According to the complex system approach, solutions of these
equations correspond to the emergence of urban substructures. In
computer simulations, the emergence of distributation patterns is vi-
sualized by phase transitions and symmetry breaking. The computer-
drawn pictures show the evolution of the population distribution of a
region that starts oﬀinitially an area with no interaction between lo-
cal centers. The urbanization process is revealed in phase transitions

Symmetry and Complexity in Economic and Social Sciences
257
 
Fig. 82.
Phase transition and attractors of urban dynamics
with changing local attractors.
For example, the urban structure
may start to solidify around some main centers.
Finally, a basic
structure may be found which is stable for some time. But, suddenly
by local ﬂuctuations, a center can undergo a process of decays and
new attractors of lodgings, shopping centers, or industrial regions
emerge.
It is remarkable that urban regions change from small to large
ones, and their evolution speed from fast to slow. Actually, we ob-
serve industrial regions with rapidly changing architecture according
to changing economic markets and technical progress. Lodging re-
gions may depend on changing fashions or the attractivity of neigh-
boring regions. Historical centers change very slowly. In this sense,
urban regions may have their own internal time and age. For prac-
tical reasons, computer simulations of urban dynamics help to fore-
cast the future and to support decisions for desired developments. In
computer experiments, diﬀerent scenarios can be tested with chang-
ing data [6.29]. One can trace back the simulation results to special
choices of values and parameters under changing initial conditions,
in order to learn and to optimize one’s decisions.
Phase transitions and symmetry breaking of urban dynamics is
visible in the distribution of real settlements. The dynamics of social

258
Symmetry and Complexity
groups is mainly invisible, but can nevertheless be studied by ana-
lytical and computer-assisted methods [6.30]. A social group may be
led by ideas and interests of its members with respect to common
or controversial purposes and objectives. Interacting forces between
individuals with diﬀerent material, emotional, and mental needs and
desires lead to a self-organization of social structures, customs and
practices in a society. In the complex system approach, their emer-
gence corresponds to solutions of appropriate equations of sociody-
namics. Norms, rules, and laws of social behavior have the function
of order parameters determining the microdynamics of individuals.
According to the usual methods of sociodynamics, material and
personal variables must at ﬁrst be deﬁned in order to get the so-
cioconﬁgurations of a social group. In a next step, the transition
rates between socioconﬁgurations are estimated with consideration
for motivation potentials and trends in a group. Distribution func-
tions can describe the emergence of, for example, the hierarchical
structure of a group. In this case, the points of a plane represent
the individuals of the population. But their position in this abstract
space has nothing to do with their location in the real space. The
space between the groups represents the crowd of the more or less
leading members of the group. The opinion leaders are in the center
and the other members are distributed in rings of subgroups with
decreasing degree of social inﬂuence.
States of balance and equi-
librium may undergo phase transitions with the emergence of new
hierarchical structures.
Political phase transitions relate to changes of very large-scale
events of whole political systems. Political revolutions can be under-
stood as symmetry breaking and phase transition. Social asymme-
tries between poor majorities without rights and rich minorities in
power have often been the driver of political change. For example,
with the assault on the Bastille in the end of the 18th century, the
system of absolutism in France collapsed. A local event made global
history in the sense of the butterﬂy eﬀect. I. Kant and other philoso-
phers celebrated the age of republican freedom as an attractor of civil
history. The Russian revolution in 1917 was also initiated by local
events and local groups in St. Petersburg in the sense of a butterﬂy

Symmetry and Complexity in Economic and Social Sciences
259
eﬀect. Each of such large-scale phase transitions is a unique event,
because it will never recur in exactly the same way. In each event
of this kind, however, there appear universal structures of human
behavior under special conditions which play a driving role in phase
transitions.
This is the motivation to study historical events and
processes from the point of view of sociodynamics.
Obviously, liberal democratic systems have higher degrees of free-
dom than totalitarian ones. In an open society with a democratic
constitution, the freedom of citizens ﬁnds its limitation in the free-
dom of the other individuals. In this framework, the formation of
competing political parties with diﬀerent socio-political concepts is
possible.
Power is organized in a complex system of checks and
balances with the fundamental division in legislative, executive and
judicative. The government is approved temporally in elections by
a majority of the people. Contrary to totalitarian systems, democ-
racies need more eﬀorts and time for decisions.
Further on, the
balance of social and political equilibrium is more endangered in a
complex open democratic system than in a closed totalitarian sys-
tem with rigid regulations. On the other hand, democracies are self-
organizing systems with higher degrees of tolerance to perturbations
not totally depending on the decisions and regulations of a dictorial
center. Historical experiences show that phase transitions from to-
talitarian regimes to democracies are possible as well as the reversel
process from democracies to dictatorships. There are also limit cy-
cles with repeating change from one totalitarian system to another.
In this case a country is caught in a cyclic attractor with tragic
consequences for its political and economic development (e.g. some
countries in South America in the 1950s and 1960s). It is a chal-
lenge of political science to ﬁnd the indicators of political crises in
the sense of warning systems. Models of complex dynamic systems
provide tools for these activities.
6.3
Complexity and Sociodiversity of Globalization
The dynamics of globalization is surely the most important politi-
cal challenge of complexity in the history of mankind [6.31]. After

260
Symmetry and Complexity
the Second World War, the confrontation of the Soviet system under
the leadership of the Soviet Union and western democracies under
the leadership of the United States generates a bilateral, but highly
dangerous equilibrium of two political, economic, and military sys-
tems with nuclear weapons. Therefore, the symmetry of power in
the world from 1945 until 1989 was sometimes called the “equilib-
rium of fright.” After increasing economical and political ﬂuctua-
tions and instabilities at the end of the 1980s, the equilibrium system
imploded peacefully, and nonequilibrium dynamics of a worldwide,
multi-centered system started. But there was not only freedom of
the people, but the emergence of many local ethnical and religious
conﬂicts with dangerous butterﬂy eﬀects which are obvious in the
international networks of terrorism.
Thus, in the historical phase
transition after 1989, the equilibrium of fright has been replaced by
the fright of nonequilibrium [6.32].
In nonequilibrium dynamics after 1989, the order parameters of
market systems have dominated the political and economic develop-
ment of post-communist states. These phase transitions are com-
plex with states of instability and ﬂuctuations. The national tra-
jectories of European nations run into the strong political and eco-
nomic attractor of the European Union (EU) that has become one
of the powerful economic centers of the world [6.33]. China, India
and other Asian states with dramatically growing populations and
technological-economic power will become dominating centers of the
world, while Africa is in a state of socio-economic stagnation.
In
the age of globalization, mankind is in an unstable phase transi-
tion of high complexity, depending on local ﬂuctuations of economic
crises, social tensions, and cultural conﬂicts. Because of the world-
wide nonlinear feedbacks, globalization is no zero-sum game that
can be won by one nation with the loss of the other ones. Sociodi-
versity, with many interests and strategies, opens chances of better
solutions like biodiversity in biological evolution.
But we cannot
trust in the self-organization of socio-economic dynamics leading au-
tomatically to welfare and the wealth of nations. It is well-known
that the self-organization of biological evolution generates failures
and sometimes ends in catastrophes with the loss of giant biocapi-

Symmetry and Complexity in Economic and Social Sciences
261
tal. Human rights demand the realization of a sustainable future for
mankind. Thus, the nonlinear dynamics of globalization need order
parameters of global governance. What do we know about the laws of
globalization?
According to Smith, the “Wealth of Nations” is made possible by
two essential principles [6.34]. At ﬁrst, free markets should organize
themselves under the conditions of the unrestricted competition of
nations. Smith was obviously the ﬁrst prophet of globalization. In
the sense of complex systems, the competition of free markets is a
procedure of economic selection, corresponding to the biological pro-
cess of selection.
C. Darwin proclaimed that selection could only
lead to optimally adapted species if there was also a great variety of
organisms (“biodiversity”). In economy, the wealth and welfare of
nations is analogously explained by Smith with the division of labor
relating to an increasing variety of highly specialized jobs. Division
of labor means reduction of incompetence by increasing specialized
know-how and better adaptation to changing conditions. Biodiver-
sity in evolution corresponds to sociodiversity in societies.
Smith
analyzed the division of labor during the beginning of the Industrial
Revolution in the end of the 18th century. Another example is the
progress in medicine. Since the 19th century the health of people had
been essentially improved by the specialization of competent experts.
The modernization of the world is a process of increasing granulation
in the division of labor. Eﬃciency by professionalization is the slogan
of the modern world. Obviously, sociodiversity and the division of
labor mean the emergence of a new macroscopic order in a society.
In the sense of complex dynamics, people of similar intelligence and
abilities specialize themselves in diﬀerent classes of jobs. An orig-
inally uniform system is divided into diﬀerent equivalence classes,
symmetry is broken, and order emerges.
Besides selection and diversity, ﬂuctuations are needed as causes
of change. In biological evolution, mutations are random events lead-
ing to new organisms that must survive the biological competition
of selection [6.35].
In economy, technical inventions and scientiﬁc
discoveries are more or less random events leading to innovations
that must become successful products in the economic competition

262
Symmetry and Complexity
of markets. It is obvious that diversity, self-organizing competition,
and innovation are basic principles of complex dynamical systems in
general. Therefore, globalization is not a political ideology we may
like or dislike. It is a lawful, nonlinear process that we should ana-
lyze in order to handle it and to ﬁnd solutions according to human
interests.
In open complex dynamical systems there are dissipative forces
as drivers of change and conservative forces stabilizing the system.
Only the balance of dissipation and conservation guarantees the ex-
istence of complex systems during the phase transitions of nonlinear
dynamics. In the process of globalization, economy, technology and
science are the driving forces of change, while the national states have
the tendency to conserve the status quo in order to protect the in-
terests of their people. With a dense network of regulations, modern
democracies try to organize the economic welfare for the majority
of their people [6.36]. Social symmetry is no result of competition,
but by regulation of the state.
Competition needs asymmetry as
motivation for economic activities. On the other hand, dissipation
of free markets without any social network could lead to social ruin
and destabilize the whole system by a dangerous asymmetry between
the majority of poor people and a minority of rich ones, which was
already prophesied by K. Marx [6.37] in the 19th century.
Thus,
modern states tried to stabilize the social balance by a welfare sys-
tem that has been paid by a complex system of direct and indirect
taxes. But over-regulation is a handicap for economic competitors
who try to maximize their proﬁts. They prefer markets with less
regulations and low taxes. Finally national states with highly devel-
oped welfare systems lose jobs necessary to earn the money in order
to ﬁnance their welfare systems.
Therefore, overregulated welfare
systems produce high costs of complexity by a feedback cycle which
can also destabilize the whole system. In short and simpliﬁed: one
can accept social asymmetry and get employment, or one can oppose
social asymmetry and get unemployment. It is a challenge of mod-
ern politics to ﬁnd the right balance of dissipative and conservative
forces in socioeconomic systems.

Symmetry and Complexity in Economic and Social Sciences
263
Under the conditions of nonlinear dynamics, it is not suﬃcient to
have good intentions, which could lead to undesired side-eﬀects in
the long run. Thus, for decisions in nonlinear dynamics, one must
consider an appropriate window of time. Dynamical systems in na-
ture and society have diﬀerent scales of time [6.38]. In democracies,
politicians prefer to take into account short-term eﬀects only, be-
cause they want to be elected again in the next election. Political
power in democracies means power for an elected period. This is the
reason why political decisions with short-term beneﬁts may lead to
disadvantages in the economic system with longer periods of causal
eﬀects [6.39]. If, for example, the central bank of a state enlarges
the set of money, the ﬁrst eﬀect is an expansion of the gross national
product and employment, which is followed by increasing prices and
wages with a contractive eﬀect. On the other hand, the restriction
of money at ﬁrst has a contractive eﬀect on the gross national prod-
uct and employment, which is later on followed by stabilized prices,
wages, and an increasing gross national product. As politicians pre-
fer the short-term beneﬁts, there is permanent inﬂationary tendency
endangering the value of money.
Political and economic systems have their own characteristic dy-
namics and time-scaling.
Therefore, they should not be mixed in
order to guarantee the welfare of a nation. In democracies, politi-
cal power is justiﬁed by the principle of majority and consensus. In
economies, the value of products is decided by the competition of free
markets. If an economy is based on democratic majorities, diﬀerent
interests and intentions must be harmonized, competition reduced,
and innovation restricted. The eﬀect is stagnation, administration of
the status quo and ﬁnally pauperization, because no surplus value is
produced. On the other hand, political systems must not be dictated
by the innovation cycles of products. Free markets are not interested
in the social security of people, but in high proﬁts and less burden
by taxes [6.40].
Globalization enlarges free markets from nations to the whole
world.
In international competition, the industry of a country is
only competitive as long as the costs of production and services are
not higher than the prices that can be gained for its goods on interna-

264
Symmetry and Complexity
tional markets. The most important part of costs are the labor costs.
Therefore, the labor costs of a country must not be too high. The
wages generated by international competition are called competitive
wages. They are a critical control parameter for the international
competitiveness of a country. If competitive wages are surpassed by
a country for a longer time, then the economy will decrease with
high unemployment, dramatically diminished exports and enlarged
imports. Finally, the wages must be decreased again. The contrary
eﬀect happens if, on the other hand, the actual wages are massively
lower than the competitive wages. There is a boom with increasing
exports, decreasing imports, growing proﬁts and increasing employ-
ment. With the increasing demand for labor the wages also increase
and adjust themselves to the competitive wages.
Wages consist of the individual wages paid cash and the collective
wages paid to public institutions in order to support people in the
case of illness, unemployment, etc. It is a decision of national social
politics as to how the parts of individual and collective wages should
be weighted. If the welfare system of a country is developed too much
with high costs of collective wages, the will of its people to work and
to produce is diminished. Therefore, the individual wages must not
be reduced too much in order to give suﬃcient stimulus for work. In
the age of globalization there is international competition between
many countries in trying to attract ﬁrms and industries from abroad
[6.41]. They compete with their diﬀerent forms of welfare systems,
taxes, and other local conditions. Again, sociodiversity is a feature of
complex social and economic dynamics. In complex systems, nobody
knows the best solutions. It is a question of learning steps and ex-
perience by trial and error. According to F. von Hayek, competition
is a procedure of discovering the best solutions [6.42]. In the age of
globalization, the discovering process of competition is generalized
for countries and nations. They emerge as global attractors in the
worldwide dynamics of free markets.
On the national level, countries organize themselves with their
political and economic systems. National governance is realized by
national governments legitimated by democratic elections in the best
case.
Governance needs power to enforce laws, regulations, and

Symmetry and Complexity in Economic and Social Sciences
265
norms. How should global governance be made possible in the age
of globalization [6.43]?
After the Second World War the General
Agreement on Tariﬀs and Trade (GATT) was the ﬁrst step in this
direction. GATT was a global, political framework of nations that
wanted to take part in free markets.
After 1989, GATT was im-
proved by the World Trade Organization (WTO) with free trade of
further products and services [6.44]. With respect to the increasing
importance of inventions and their protection by patents, the WTO
was supplemented by an agreement on Trade Related Aspects of In-
tellectual Property Rights (TRIPS). The WTO enforce its national
members to satisfy the global rules of their agreement. Otherwise a
country is excluded from the privileges of free markets by the other
members. But the attraction of free markets is very strong and sup-
ports the national interest of a country. Therefore, any member tries
to avoid such a situation voluntarily. In this sense the WTO has
an eﬀective system of sanctions that are applied by an international
court of trade. It is remarkable that for the ﬁrst time in history a
political-economic system is able to enforce sanctions without mil-
itary power. Military power is even excluded, because otherwise a
country loses the economic beneﬁts of the free WTO-market. The
dream of Smith that war could be avoided by free trade has now a
realistic perspective, at least in the long term.
Mankind’s urgent global problems like war, poverty, and ecologi-
cal pollution cannot be solved, because there are no eﬀective systems
of sanctions. Good intentions are not suﬃcient. The WTO with its
eﬀective sanctions could be a model for successful global governance.
Less developed countries have obviously less chance to compete suc-
cessfully with highly developed countries on the monetary market.
They need help to improve their ﬁnancial systems.
Nevertheless
many of them can already compete with their human capital, i.e. the
know-how of their people. Thus the best help is to open the markets
of wealthy OECD countries for these people. There is no better way
to gain the knowledge of competitors than by competing with them.
A sustainable future for mankind depends basically on the solu-
tions for our environmental problems. How can the nonlinear dy-
namics of globalization be harmonized with the complex system of

266
Symmetry and Complexity
the natural environment on earth? Today, there are 6 billion people
living on earth. Human population will increase to 8 billions in 2025
and 9,4 billions in 2050. These giant numbers are a dramatic burden
on natural resources and climate. On the other hand, it is an empir-
ical fact that the growth of a population can only be stabilized by an
increasing wealth of its people. But increasing wealth needs growing
economies which exhaust natural resources. Therefore, thirty years
ago, the Club of Rome asked for the “Limits to Growth” and tried
to determine a global equilibrium state of economy and environment
[6.45].
Obviously population, industries, capital, services, natural
resources and environment interact in a complex nonlinear system
which needs careful analysis of causal dependencies. Fig. 83 illus-
trates some feedback loops, although they are not complete. In a
further step of modeling the coupled equations of these interacting
quantities must be formulated in order to ﬁnd appropriate solutions
of equilibrium.
Even if there is a strategy of zero-growth, there is no chance of
application without an eﬀective system of sanctions. Wealthy na-
tions will not renounce their welfare systems that need ﬂourishing
economies. Poor nations will try to increase their industrial produc-
tion in order to improve their living standards. Thus, the question
arises as to whether there is an ecologically sustainable strategy of
economic growth accepted by the majority of countries? According
to the WTO, the common agreement must be of urgent national
interest for its members combined with an eﬀective system of sanc-
tions. An economic sanction would be a price mechanism evaluating
natural resources (e.g. climate) as limited goods [6.46]. In an interna-
tional agreement on climate protection, emission rights of hothouse
gas could get a market price used by the countries with respect to
their national interests. Excessive emissions of hothouse gas cause
ﬁnes on single countries to the favor of a world fund. With that a
price is determined for the limited rights of emission. The price can
also be used as reward for renouncing the usage of emission rights.
The reward is paid by the same fund getting the ﬁnes. The agree-
ment demands that the price must be adjusted if the total emission
surpasses or remains under some critical value of a control parame-

Symmetry and Complexity in Economic and Social Sciences
267
population
annual births
(+)
industrial production
per capita
(+)
birth rate
education and
family planning
annual deaths
death rate
(-)
(-)
public health welfare
services per capita
(+)
capital of
services
industrial production
industrial capital
non-regeneratable
ressources
efficiency
of capital
(-)
investments
investments rate
wear of capital
average using duration of capital
Fig. 83.
Nonlinearity of global social, economic, and ecological dynamics
ter. In order to get a growing and ecologically sustainable economy,
price and sanctions of emission rights must be combined with new
innovations and proﬁtable markets. If the price reaches an appropri-
ate value, then it is assumed that new ecologically sustainable tech-
nologies will emerge and produce the same or an even larger gross
national product with essentially less coal, oil, and gas. Agreements
without sanctions (e.g. the Kyoto agreement) and impulses to new
proﬁtable markets only have moral importance.
Globalization does not only mean ecological and economic prob-
lems.
After the fall of the Berlin wall, politicians believed in the
linear assumption that coupling the dynamics of free markets and
democracy would automatically lead to a community of modernized,
peace-loving nations with civic-minded citizens and consumers. This
was a terrible error in a complex world! From our point of view,

268
Symmetry and Complexity
complexity is driven by multi-component dynamics. Politicians and
economists forgot that there is also the sociodiversity of ethnic and
religious groups dominating the whole dynamics of a nation at a crit-
ical point of instability [6.47]. As we all know from complex dynam-
ical systems, we must not forget the initial and secondary conditions
of dynamics. Instability emerges if free markets and elections are
implemented under conditions of underdevelopment.
Recent studies demonstrate that in many countries of Southeast
Asia, South America, Africa, Southeast Europe, and the Middle East
the coupling of laissez-faire economics and electoral freedom did not
automatically lead to more justice, welfare, and peace, but tipped
the balance in these regions toward disintegration and strife [6.48].
One reason is that these countries mainly do not have a broad major-
ity of well-educated people. Thus, minorities of clever ethnic groups,
tribes, and clans come to power and dominate the dynamics of mar-
kets and politics. In the terminology of complex dynamics, they are
the order parameters dominating (“enslaving”) the whole dynam-
ics of a nation. Again, the good intentions of democracy and free
markets are not suﬃcient. We must consider the local conditions of
countries and regions.
In classical philosophy, the transition from an intended develop-
ment to a development contrary to the spirit of the philosophy has
become famous as a contradiction of dialectics (e.g. G.W.F. Hegel).
Good intentions may lead to bad eﬀects.
But human agents are
sometimes driven by history to good eﬀects without their subjective
intentions. Hegel called it a “stratagem of reason” (“List der Ver-
nunft”). Actually, it is a well-known eﬀect of nonlinear dynamics.
Therefore, market-dominant minorities are not a priori evil. Minori-
ties are also the driving forces of activity. If they are open-minded
and ﬂexible, they prevent narrow-minded “enslaving” which may be
successful only for a short time. In their own interest, they must
try to stabilize the whole system in the long run. Therefore they
should help dampening the social eﬀects of free markets, bridging
social cleavages, and transcending class division during a phase tran-
sition to democracy and welfare for the majority of the people. But
these phase transitions may be diﬀerent from region to region in the

Symmetry and Complexity in Economic and Social Sciences
269
world. Responsible decisions require sensitivity to local conditions
in the light of the butterﬂy eﬀect.
There are not only local minorities in regions and countries. Dur-
ing the process of globalization, a minority of nations, institutions,
and companies can come to power and dominate the whole dynamics
of global economics and politics. Recent discussions on globalization
show that a lot of people are not happy with the results of global-
ization. But it is necessary to understand that globalization means
nothing more than the global dynamics of political and economic
systems in the world. Therefore at ﬁrst, it is neither good nor evil
like the dynamics of weather. But contrary to weather, the dynam-
ics of globalization is generated by the interactions of humans and
their institutions. Thus, there will be a chance to inﬂuence global-
ization if we take into account the dynamical laws of complexity and
nonlinearity.
It is a hard fact that the order parameters of globalization have
been deﬁned by a minority of nations. They are the world’s preemi-
nent political, economic, military, and technological powers whether
we like it or not. Philosophers, mathematicians, and systems scien-
tists have no power. But, again, we should use Hegel’s “stratagem of
reason”: minorities are also the centers of driving power that enable
chances for change. Concepts and ideas without political power have
no chance. If the dominating minorities of globalization are open-
minded and ﬂexible, they will prevent narrow-minded “enslaving”
which may be successful only for a short time. In their own interest,
they must try to stabilize the whole system in the long run. There-
fore they should help in dampening the social eﬀects of global free
markets, bridging social cleavages, and transcending class division
during a phase transition to global democracy and welfare for the
majority of the people.
Globalization means the critical phase transition to global gover-
nance in the world. We need new global structures to manage the
political, economic, military, and technological power in the world
according to the interests of the majority of people on earth. Global
structures emerge from the nonlinear interactions of peoples, nations,
and systems. At the end of the 18th century, Kant had already de-

270
Symmetry and Complexity
manded a law of nations leading “To Eternal Peace” (1795) [6.49].
After the First World War, President W. Wilson of the United States
strongly inﬂuenced the foundation of the League of Nations. After
the Second World War, the United Nations (UN) presented a new
chance to handle international conﬂicts, but they often fail because
of their lack of power. The dilemma of international law is that law
needs power to enforce rights and ethical norms. Therefore nations
have to give up parts of their sovereignty, in order to be dominated
by commonly accepted “order parameters”.
Since September 11,
2001, a global network of terrorism has been threatening the preem-
inent political and economic nations of the world. This is the reason
why, especially the United States, which historically helped found
the League of Nations as well as the UN, now hesitates to restrict its
national sovereignty and prefers to organize its own national security
through global military defense.
Clearly it is a long way to global governance among autonomous
nations [6.50]. On the other hand, we must not forget the practical
progress made by new social and humanitarian institutions of the
UN. New economic, technological, and cultural networks of coopera-
tion emerge and let people grow slowly together in spite of reactions
and frictions in political reality. On the way to “eternal peace,” Kant
described a federal (multi-component) community of autonomous na-
tions self-organizing their political, economic, and cultural aﬀairs
without military conﬂicts. But an eminent working condition of his
model is the demand that states organize their internal aﬀairs ac-
cording to the civil laws of freedom. It is a hard fact of historical
experience that civic-mindedness and humanization have sometimes
not only been defended, but also enforced by military power. As
long as the demand for civil laws of freedom is not internationally
fulﬁlled, the organization of military power is an urgent challenge to
globalization.
Globalization and international cooperation is accelerated by the
growth of global information and computational networks like the
internet and wireless mobile communication systems [6.51]. On the
other hand, the electronic vision of a global village implies a severe
threat to personal freedom.
If information about citizens can be

Symmetry and Complexity in Economic and Social Sciences
271
easily gained and evaluated in large communication networks, then
the danger of misuse by interested institutions must to be taken in
earnest.
As in the traditional economy of goods, there may arise
information monopolies, acting as dominating minorities prejudicing
other people, classes, and countries. For instance, consider the for-
mer “Third World” or the “South” with its less developed systems
for information services that would have no fair chance against the
“North” in a global communication village.
Are there consequences of symmetry, complexity, and nonlinear
dynamics for management systems in the age of globalization [6.52]?
Linear decision behavior can obviously lead to desired results only
under the conditions of complete information in an environment with
linear dynamics. In complex situations, agents must consider positive
and negative feedback by side eﬀects of their own nonlinear decisions
and by goals and actions of other agents. Short-term thinking is dan-
gerous in a world with delayed and long-term side eﬀects. Learning in
complex organizations means a change of mental models, strategies
and decisions. It requires nonlinear information feedback. Thus, we
should aim at improving complexity in management systems with
respect to structural complexity (e.g. ﬂat hierarchies, short length
of decision processes, appropriate number of controlling units), with
respect to information complexity (e.g. eﬀective knowledge manage-
ment, information symmetry and transparency), and ﬁnally with re-
spect to the individual complexity of co-workers and the diversity of
their diﬀerent creative potentials.
But diversity and complexity do not automatically lead to the
emergence of self-organizing fruitful eﬀects.
In ﬁrms, administra-
tions, and other kinds of organizations, we can measure costs of
complexity inﬂuencing their position in economic competition. Di-
rect costs of complexity are distinguished as single direct costs for
too complex products with new expensive materials, tools, and fea-
tures, and permanent direct costs for service and administration of
these products. Indirect costs of complexity are hidden in the or-
ganizational structure of a ﬁrm or administration. An example is
the time of a manager or co-worker not being optimally used. Costs
of complexity inﬂuence all steps of the value chain during an indus-

272
Symmetry and Complexity
trial production. There are, for instance, the costs of suppliers for
various units of products. Furthermore, costs of complexity emerge
in purchase and logistic, production and construction, marketing,
and administration. If dangerous drivers and traps (“attractors”) of
complexity arise, the capital of a ﬁrm decreases and the energy of
co-workers and managers are dissipated. Examples are oﬀers of ﬁrms
with a too much variety, over-engineering and defects in quality.
Thus, complex nonlinear organizational structures can lead to
increasing butterﬂy eﬀects, spreading to the whole organization
(e.g. costs of complexity) like an epidemic.
In complex organiza-
tions, nonlinear processes cannot be forecast in the long run. Early
controlling is necessary to prevent chaotic attractors, i.e. the traps of
complexity. In the competition of globalization, complex organiza-
tions only survive as learning, rapidly adapting, and ﬂexible systems.
In complex organizations, varieties of competent co-workers recog-
nize problems better and react faster than central controlling in an
over-regulated hierarchy. Therefore, we should deregulate and sup-
port self-regulating autonomy. Complex organizations are nonlinear
social systems of people with diﬀerent abilities, attitudes, emotions
and interests. The sociodiversity of people is the human capital for
a sustainable progress, not only in single organizations, but in the
evolutionary process of globalization.

Chapter 7
Symmetry and Complexity in
Computer Science
The evolution from symmetry to complexity has been analyzed in
the physical, chemical, biological, cognitive, and social sciences. In
all these contexts, the emergence of order and structure is explained
by self-organization with symmetry breaking and phase transition of
complex dynamical systems. The increasing power of modern com-
puter technology allows new insights into their nonlinear dynamics,
which can often not be solved by analytical methods. On the other
hand, the principles of physical, chemical, biological, cognitive and
social self-organization have become the blueprints of computer and
information technologies. Life and computer science are growing to-
gether into a new kind of complex engineering, changing the basic
conditions of human life and society. There is a fundamental reason
for this obvious tendency: according to the principle of computa-
tional equivalence, every nonlinear dynamical system corresponds to
an appropriate computational system. In this sense, atomic, molec-
ular, cellular, organic, and social systems are computational systems
with phase transitions as information processes.
Symmetry, sym-
metry breaking and complexity are explained by the principles of
information and computation.
7.1
Symmetry and Complexity in Information Dynamics
According to Shannon’s information theory [7.1], a message from a
sender (e.g. phone, PC) is sent to a recipient by coding the sign of
the message into binary digits (“bits”), representing binary technical
273

274
Symmetry and Complexity
signals (e.g. electrical pulses), and decoding them when the message
arrives. Communication means the exchange of information. The
information content of a symbol is the number of binary decisions
leading to it. For example, a storage with four symbols a, b, c, d
allows 4 = 22 selecting procedures with two binary decisions which
can be represented by a bifurcation tree (Fig. 84).
In this sense,
information is generated by digital symmetry breaking.
Fig. 84.
Digital bifurcation of information
For N symbols, there are N = 2I selecting procedures with I
binary decisions, i.e. I = ld N bits. If the symbols si (1 < i < N)
occurs with diﬀerent probabilities pi, then their information content
is I(si) = ld p−1
i
= −ld pi bits. A more probable symbol has less
information content than an improbable one. In this sense, the in-
formation content of a symbol can be considered a measure of news
for the receiver.
The mean information content of a sender with symbols si is the
expectation value of the information contents I(si) of its symbols
si, i.e. H = c 
i piI(si) = −
i pi ld pi with 
i pi = 1. The mean
information content H can be considered a measure of uncertainty for
the probabilistic distribution of the symbols of a source. The reason
being that in the case of the uniform distribution of probabilities,
the mean information content Hmax of a source is maximal, i.e. the

Symmetry and Complexity in Computer Sciences
275
uncertainty of a symbol is maximal. For H = 0 is pi = 1, i.e. symbol
si is determined by the source.
Information storage and information ﬂow in matter, life, the
brain, and societies depend on the dynamics of complex systems.
The basic concept linking information dynamics with complex sys-
tems is entropy. According to Boltzmann, entropy S is a measure of
the probable distribution of microstates of elements (e.g. molecules
of a gas) in a complex dynamical system, generating a macrostate
(e.g. temperature of a gas), i.e. S = kB ln W with kB Boltzmann-
constant and W number of probabilistic distributions of microstates,
generating a macrostate [7.2]. According to the second law of ther-
modynamics, entropy is a measure of increasing disorder in isolated
systems. The reversible process is extremely improbable. In infor-
mation theory, entropy can be introduced as measure of uncertainty
of random variables.
Random variables are not restricted to ran-
domly produced symbols of a sender. A random variable X denotes
states x which can be generated by any kind of complex system.
The information which is necessary to determine the probabilistic
distributions of microstates, generating the macrostate of a com-
plex system, is given by information entropy. Mathematically, the
information entropy H(X) of random variable X is deﬁned as the
expectation value of the probabilistic distribution of its values x,
i.e. H(X) = −
x
p(x) log p(x). In complex systems, H(X) is the ex-
pectation value of the probabilistic distribution of their microstates.
For H(X) = 0, the process X is deterministic. For H(X) maximal,
there is uniform distribution with maximal uncertainty of x.
In-
formation entropy is obviously considered a measure of uncertainty.
Actually, information is the diminution of uncertainty concerning the
state of a complex system [7.3].
In thermodynamical applications, the random variable X of in-
formation entropy is related to the microstates of, for example, the
molecules of a gas. In this case, the entropy of a macrostate cor-
responds to the information which is necessary to determine the
microstates, generating the macrostate, i.e. S = kBH [7.4].
Ac-
cording to the second law of thermodynamics, entropy increases in

276
Symmetry and Complexity
closed systems. Increasing entropy means an increasing number of
probabilistic distributions of microstates, generating a macrostate.
Therefore, the information which is necessary to determine the mi-
crostates, generating a macrostate of a system, also increases.
In
this sense, information entropy is sometimes considered a measure of
potential information evolving in dynamical systems [7.5]. How can
we determine potential information in the diﬀerent complex systems
of cosmic, biological, and social evolution? In information theory, in-
formation is reduced to bits, the smallest units of binary alternative
states, which are denoted by the binary digits 0 and 1. In this case,
a state is characterized by a bifurcation tree of binary alternatives
which must be decided for its determination. The alternatives are de-
cided when the corresponding events happen. The evolving potential
information in closed systems can be represented by the spreading
bifurcation tree of alternatives for determining a macrostate.
The basic physical theory of cosmic evolution is quantum me-
chanics. In quantum theory, elementary particles (e.g. photons) have
binary spin-states ↑(up) and ↓(down) that can be superposed in co-
herent states. Thus, quantum information theory analyzes quantum
information with superposed quantum bits.
Again, any quantum
state could be characterized by the number of quantum alternatives
which must be decided for its determination. The quantum alter-
natives are decided when the corresponding quantum events happen
[7.6]. In this sense, each state of matter can be considered a kind of
potential quantum information.
Quantum bits correspond to the binary alternatives on which the state spaces
of quantum theory can be based. According to C.F. von Weizs¨acker [7.7] the quan-
tum alternatives deﬁne a symmetry group that is isomorphic to the transforma-
tion group of special relativity. In this ﬁrst step, quantum information theory
leads to both the existence of a 3-dimensional real space and the validity of special
relativity theory. Until now, however, the derivation of actual particles and ﬁelds
remains just a program. Its goal is to deduce their existence directly from quan-
tum information theory, while avoiding the divergences of quantum ﬁeld theories
that must presently be evaded by ad hoc renormalization techniques. The gauge
symmetries of the fundamental physical forces and their particles would have
foundations of quantum information theory. In the context of the uniﬁcation of
physics there remains, furthermore, the open problem of the quantum theoretical

Symmetry and Complexity in Computer Sciences
277
reconstruction of the gravitational ﬁelds of general relativity theory, in which the
linearity and delocalization of quantum theory collide with the nonlinearity and
localization of Einstein’s gravitational equations. If the problems of uniﬁcation
are solved, then quantum information is the original potentiality of the world. In
the beginning there was quantum information with high symmetry.
In previous chapters, the cosmic evolution was described by sym-
metry breaking and phase transitions from early states of high sym-
metry and uniformity to complexity and diversity. According to the
second law of thermodynamics, global cosmic expansion is character-
ized by increasing entropy which means increasing disorder. Local
order of complex structures emerges by self-organization.
In this
case, a system takes a local state of higher order resp. lower sym-
metry than its environment. Therefore, local order corresponds to
local diminution of entropy with respect to the equilibrium state. In
this sense, complex structures have less potential information than
states of maximal entropy. But, that is not a contradiction to our
intuition. We must not forget that potential information relates to
the information which is necessary to determine a state. If potential
information increases, then the need for actual information increases
and that means increasing uncertainty. Local order of complex struc-
tures correspond locally to more actual information than the globally
increasing entropy.
The universe, with expanding cosmic dust and background-
radiation, is a global sea of increasing disorder with emerging and
disappearing local islands of order such as galaxies, stars, and plan-
ets. Our earth, for instance, exports entropy by absorption of ra-
diation of a high temperature and re-emission of radiation of a low
temperature. The export of entropy is a necessary condition for the
emergence of structure. In order to prevent the system from run-
ning into the equilibrium state of maximal entropy, the irreversibly
generated entropy in the system must steadily export to abroad. An
example is illustrated by the B´enard-eﬀect (Fig. 43). A stream of
heat of a high temperature is imported from below and a stream of
heat of low temperature is exported from above. The gradient of
temperature is responsible for the pattern formation of macroscopic
convection cells. In the chemical BZ-reaction (Fig. 56) the export of

278
Symmetry and Complexity
entropy is realized by an autocatalytic diﬀusion-reaction process. In
biology, genotypical uniform cells diﬀerentiate themselves into phe-
notypical diﬀerent tissues during the ontogenesis of organisms. The
growth of an organism is made possible by the import of nutrition
with high structural order and the export of output with less struc-
ture. In sociodynamics, people with similar intelligence and abilities
specialize themselves in diﬀerent classes of jobs.
In this case, ex-
port of entropy means reduction of incompetence by specialization,
professionalism, and division of labor. In all these examples, an orig-
inally uniform system is divided into diﬀerent equivalence classes,
symmetry is broken, and order emerges by reduction of entropy and
uncertainty.
Reduction of entropy and uncertainty means loss of potential
information, but gain of actual information.
Information systems
reduce uncertainty and enlarge actual information.
In this sense,
even clouds, stars, and galaxies with their locally emerging order
and decreasing entropy can be understood as information systems.
Gain of information is by no means restricted to information sys-
tems in exchange with human beings. A molecule combining itself
with other molecules in a new chemical structure reduces entropy
and uncertainty. Therefore, chemists do right to call it “molecular
pattern recognition,” when a molecular structure is “recognized” or
“selected” by a molecule as appropriate compound. These kinds of
information systems need neither sensory perception nor conscious-
ness or biological mechanisms of selection. Nevertheless, in thermo-
dynamic systems, gain of information happens in molecular exchange
of matter and energy.
The laws of thermodynamics are not suﬃcient for an explana-
tion of living systems. After thermodynamic self-organization, the
emergence of life is made possible by genetic self-organization. The
genetic information of an organism is coded by the four chemical
compounds Dadenine (A), cytosine (C), guanine (G) and uracil (U).
With binary coding A = 00, U = 11, G = 01, and C = 10, we get a
genetic code in bits. Structure and function of living organisms need
giant sets of information. For a virus, one gets 104 bits, 106 bits for
a bactarium, 108 bits for a single-celled organism, and 1012 bits for

Symmetry and Complexity in Computer Sciences
279
a mammal. Genetic information of a cell is transferred to proteins
with hereditary dispositions. Information processing is realized by
highly complex molecular pattern recognition. During the evolution
of life, the capacity of information processing was not restricted to
genetic information systems. In higher developed organisms, popu-
lations, and social systems, information processing of nerve systems
and brains play a dominant role. They enabled organisms to learn
and to adapt to changing environments during life time.
Learn-
ing and adapting during life time increase the survival of the ﬁttest
and have a great advantage to genetic procedures which only allow
adapting to ecological niches in sequential generations [7.9]. Three
or four billion years ago, genetic information systems emerged and
generated a giant biodiversity of cellular organisms. The increasing
capacity of information storage can be estimated by the growth of
genetic information during evolution [7.10].
In general the information capacity of storage is measured by the logarithm of
its number of diﬀerent possible states. For nucleotide sequences of length n which
consists of four building blocks, there are 4n diﬀerent possibilities of ordering. For
bit-units in the binary system, the information capacity is Ic = ln 4n/ ln 2 = 2n.
For polypeptide with twenty diﬀerent building blocks, storage capacity is Ic =
ln 20n/ ln 2 = n · 4.3219 bits. For chromosomes with 109 nucleotides the storage
capacity has double length with 2 · 109 bits. Information capacity is independent
of the material form of storage.
Therefore, diﬀerent information systems can
be compared with, for example, human storage systems like books or libraries.
For one of the 32 letters in the Latin alphabet ln 32/ ln 2 = 5 bits are needed.
Therefore, in a DNA-sequence, 2 · 109 bits/5bits = 4 · 108 letters could be stored.
For an average length of words with 6 letters, one gets 6 · 107 words. If a printed
page has 300 words, then one will gets 2 · 105 printed pages. A DNA-sequence of
109 nucleotides corresponds to a storage capacity of 400 books with 500 pages.
Biological evolution on earth produced an exponential growth of
genetic information which reached at a maximum of 1010 bits with
the emergence of human beings after the development of bacteria,
algae, reptiles, and mammals (Fig. 85).
A new strategy of infor-
mation systems was initiated by nerve systems and brains. They
started with specialization of few cells for signal transfer. Therefore,
the information sets which could be stored by early nerve systems

280
Symmetry and Complexity
Fig. 85.
Phase transition of genetic information on earth
were essentially smaller than the information sets in genetic informa-
tion systems (Fig. 85). With the emergence of complex organisms
like reptiles, neural information systems surpassed the capacity of
genetic systems. With increasing complexity, all necessary informa-
tion of survival could no longer be stored in organisms, but it had to
be be learnt by experience [7.11].
Sensorial stimuli of the human organism are analogous signals
(e.g. mechanical pressure of skin or muscles, acoustic waves in the
ear, electromagnetic waves of the retina, chemical stimuli in the nose)
which are received by sensorial cells, coded into digital action poten-
tials, and sent as binary codes (ﬁring and non-ﬁring of neurons) in the
central nervous system (CNS) to the brain. Speciﬁc nervous signals
(neural information) are decoded as sensorial perceptions, emotions,
imaginations, or thoughts by speciﬁc areas of the brain. A mechani-
cal stimulus (e.g. stretch of a muscle) is received by a sensorial cell as
an analogous signal and transformed into digital action potentials.
The intensity of the stimulus is coded by the number of equal action
potentials which correspond to bits of digital information.

Symmetry and Complexity in Computer Sciences
281
Information processing of the human brain is made possible by at
least 1011 neurons. Each neuron has on average 1000 synaptic con-
nections. Thus, there are 1014 synaptic connections in a brain which
is a number larger than the set of stars in our galaxy.
Informa-
tion is stored in neural networks of synaptic connections [7.12]. The
steadily ﬁring cells produce a global sea of neural ﬂuctuations, noise
and entropy which can be compared with the background radiation of
the universe. Our thoughts, feelings, and perceptions correspond to
neural cell-assemblies which are the emerging and disappearing local
islands of order such as galaxies, stars, and planets in the global sea
of cosmic entropy. In this sense, thoughts, feelings, and perceptions
mean reduction of uncertainty and gain of information.
In general, the concept of information is not restricted to human
information processing with brains and nerve systems. The DNA-
code is understood by proteins on the molecular level, but in general
not by human beings on the level of brains (which nevertheless try to
reconstruct its meaning by scientiﬁc methods). The meaning of our
e-mails is understood otherwise by their human recipients, but not
by molecular pattern recognition of cells. Understanding the codes
of information depends on contexts. That aspect is sometimes called
semantic information. Human brains generate complex cognitive hi-
erarchies of meaning (Fig. 74). Information is represented by signs
like letters of texts, numbers of quantities, symbols of mathematical
relations, notes of music, etc. Visual perception only can recognize
formal (“syntactic”) patterns of signs by the well-known procedures
of sensory cells and ﬁring cell-assemblies. The meaning (“semantics”)
of, for example, a melody represented by notes, needs the neural ac-
tivity of further cell assemblies of acoustic areas and memory which
are linked with the visual areas.
If someone is an expert of mu-
sic, she/he will associate the recognized melody with her/his whole
knowledge.
Thus, the coding and decoding process of meaning is
based on complex interactions of cell-assemblies. Cognitive hierar-
chies of meaning emerge by neural self-organization. Diﬀerent codes
of knowledge representation are transformed into one another. Be-
sides the syntactic and semantic aspects of information, pragmatic
information is a measure of the eﬀect of information on its recipi-

282
Symmetry and Complexity
ent. Our intentions are related to eﬀects and changes in the external
world, generating pragmatic information.
Information processing of evolution does not end with brains and
nerve systems of organisms. Even populations of animals such as, for
example, colonies of ants and termites develop collective information
and communication systems for transport nets and arch formation.
In sociobiology, these populations are called superorganisms with
swarm intelligence [7.13]. Animals communicate with chemical dif-
fusion ﬁelds in a self-organizing manner. They specialize themselves
for diﬀerent tasks of labor, transport, and nutrition. Sociodiversity is
represented by diﬀerent clusters of social order. They are the islands
of order and collective information in a sea of uncorrelated activi-
ties, ﬂuctuations and noise. There is no single termite as architect
with a master plan for constructing an arch. The collective infor-
mation of termites for the construction of arch formation is stored
in the chemical diﬀusion ﬁeld of communication like in the neural
cell-assemblies of a brain. Analogously, there is no neuron which can
think, feel, or perceive. Cognitive abilities are generated by popu-
lations of neurons in a certain area of the brain. Besides chemical
hints, traces and signs of nature are understood by higher developed
animals.
In populations, collective information is not stored in a
single organism, but in extrasomatic ﬁelds of chemical and visual
communication.
In human societies, brains are not isolated, but communicate by
complex systems of visual and acoustic signs, gestures, and lan-
guages. In early cultures, the collective memory was orally trans-
ferred by traditions from generation to generation. After the inven-
tion of writing, the memory of a society could be stored in libraries as
examples of extrasomatic information storage. After Gutenberg’s in-
vention of printing, information storage in libraries began to surpass
the capacity of information storage in single brains (Fig. 85). Net-
works of telephone, broadcasting and television are further examples
of social information systems with increasing capacities. In the age
of globalization, the internet and other computer networks are giant
information storage systems with exponential growth. Mankind has
initiated a technical co-evolution of extrasomatic information pro-

Symmetry and Complexity in Computer Sciences
283
cessing in order to manage their worldwide societies of increasing
complexity and sociodiversity.
Obviously, the cosmic, biological, and social evolution from sym-
metry and simplicity to complexity and diversity can be explained by
cosmic, biological and social information dynamics [7.14]. In the be-
ginning there was quantum information with high symmetry and less
entropy. Cosmic expansion is characterized by symmetry breaking
and globally increasing information entropy (potential information).
But thermodynamic, genetic, neural and social self-organization al-
low the emergence of local islands of higher order, less entropy, and
more actual information than global entropy. Galaxies, brains and
societies are examples of information systems generating local or-
der and actual information in the cosmic sea of increasing entropy.
But memories can also be forgotten for ever. Information disappears
in brains when people become older and suﬀer from, for example,
Alzheimer’s disease. Holes of information spread over the whole or-
gan which, in the end, forgets how to live. Dead bodies are relics
of disappeared information systems. Black holes are examples of ex-
treme loss of information, structure and order by dying stars and
imploding matter. Radiating black holes lose energy and mass. In
time, they will disintegrate and, with them, the information of their
original stars will disappear in the surrounding universe. In their
place, memory gaps will appear in the universe. With the collapse of
its galactic structures, a featureless universe expanding into a void
is heading for a “cosmic Alzheimer’s disease” [7.15].
From a physical point of view, it may be comforting to know that
information cannot disappear totally because of symmetry. The ar-
row of time is only a macroscopic phenomenon according to the cos-
mic arrow of expansion and the 2nd law of thermodynamics.
On
the microlevel, the laws of quantum dynamics demand symmetry
of time. The physical question arises: is information lost in black
hole evaporation or not? If it is, the dynamics is no longer reversible
(“symmetric”) or, in terms of quantum mechanics, unitary. If a book
is thrown into the ﬁreside, its information seems to be hopeless lost.
Is there a method to reconstruct its letter from the radiation and
atomic paths of smoke?
Analogously, if a body falls into a black

284
Symmetry and Complexity
hole, the information of its material structure seems to be lost in
the center of extreme gravitation and high entropy. Quantum eﬀects
cause a black hole to radiate at a steady state. If the radiation from
the black hole is completely thermal, then it cannot carry any in-
formation. What would happen to all the information of died stars
and bodies locked inside a black hole, that evaporated away, and
dissappeared completely? It seemed the only way the information
could come out would be if the radiation was not exactly thermal,
but had subtle correlations of information preserving. Hawking uses
Feynman’s sum over all histories of a black hole: mathematically, he
takes the path integral over metrics of all possible topologies. Thus,
he ﬁnds a reversible process with correlation functions that do not
decay. In general, quantum gravity is conﬁrmed to be unitary and in-
formation is preserved in black hole formation and evaporation: the
symmetry of quantum laws is saved. If a body falls into a black hole,
its mass-energy will be returned to our universe, but in a mangled
form, which contains the information about what it was like, but,
perhaps, in an unrecognisable state [7.16]. Information comes back
in our universe, although we are not always able to recognize it. In
principle, information is conserved as long as the quantum laws of
symmetry are valid. But the economist Keynes was also right with
his famous quotation that in the long run we are all dead. There-
fore, from a human point of view, the conservation of information by
symmetry seems to be a hope for eternity.
7.2
Symmetry and Complexity in Computational
Dynamics
Information processing can be simulated by computers. In this sense,
atomic, molecular, cellular, organic and social systems are considered
computational systems with information processes as phase transi-
tions. Symmetry, symmetry breaking and complexity are explained
by the principles of computation. What do computation and com-
putability mean? Turing’s concept of a computer does not depend
on changing standards of technical development, but it is a general,
logical-mathematical deﬁnition of computation and computability
[7.17].

Symmetry and Complexity in Computer Sciences
285
A Turing machine consists of
(1) a control box in which a ﬁnite program is placed,
(2) a potentially inﬁnite tape, divided lengthwise into squares,
(3) a device for scanning, or printing on one square of the tape at a
time, and for moving along the tape or stopping, all under the
command of the control box.
If the symbols used by a Turing machine are restricted to a stroke
| and a blank ∗, then every natural number x can be represented by
a sequence of x strokes (e.g. 3 by |||), each stroke on a square of
the Turing tape. The blank ∗is used to denote that the square is
empty (or the corresponding number is zero). In particular, a blank
is necessary to separate sequences of strokes representing numbers.
Thus, a Turing machine computing a function f with arguments
x1, . . . , xn starts with tape · · · ∗x1 ∗x2 ∗· · · ∗xn ∗· · · and stops with
· · · ∗x1 ∗x2 ∗· · · ∗xn ∗f(x1, . . . , xn) ∗· · · on the tape.
From a logical point of view, a general purpose computer — as
constructed by associates of von Neumann in America and inde-
pendently by K. Zuse in Germany — is a technical realization of
a universal Turing machine which can simulate any kind of Turing
program. Besides Turing machines, there are many other mathemat-
ically equivalent procedures for deﬁning computable functions. All
these deﬁnitions of computability can be proved to be mathemati-
cally equivalent. Each of these concepts deﬁnes a procedure which is
intuitively eﬀective like a Turing machine.
Thus, A. Church postulated his famous thesis that the infor-
mal intuitive notion of an eﬀective procedure is identical with one
of these equivalent precise concepts, such as that of a Turing ma-
chine. Church’s thesis cannot be proved, of course, because mathe-
matically precise concepts are compared with an informal intuitive
notion. Nevertheless, the mathematical equivalence of several pre-
cise concepts of computability which are intuitively eﬀective conﬁrms
Church’s thesis. Consequently, we can speak about computability,
eﬀectiveness and computable functions without referring to particu-
lar eﬀective procedures (“algorithms”). According to Church’s the-
sis, we may say in particular that every computational procedure

286
Symmetry and Complexity
(algorithm) can be calculated by a Turing machine. So every com-
putable function, as a kind of machine program, can be calculated
by a general purpose computer.
If a physical, biological, or social process can be represented by a
computable function, then by Church’s thesis it can be represented
by a Turing program which can be computed by a universal Turing
machine.
Thus, these processes (if they are computable) can be
simulated by a technically eﬃcient general purpose computer. Turing
computability is a theoretical limit of computability according to
Church’s thesis. There are processes with a degree of computational
complexity both below and beyond this limit. Below this limit there
are many practical procedures concerning certain limitations on how
much the speed of an algorithm can be increased. Thus, there are
degrees of computability for Turing machines which can be made
precise in the complexity theory of computer science [7.18].
Complexity classes of functions can be characterized by complex-
ity degrees, which give the order of functions describing the com-
putational time (or number of elementary computational steps) of
algorithms (or computational programs) depending on the length of
their inputs. The length of inputs may be measured by the number
of decimal digits. According to the machine language of a computer
it is convenient to codify decimal numbers into their binary codes
with only binary numbers 0 and 1 and to deﬁne their length by the
number of binary digits.
For instance, 3 has the binary code 11
with the length 2. A function f has linear computational time if
the computational time of f is not greater than c · n for all inputs
with length n and a constant c. A function f has quadratic com-
putational time if the computational time of f is not greater than
c · n2 for all inputs with length n and a constant c. A function f has
polynominal computational time if the computational time of f is
not greater than c · nk, which is assumed to be the leading term of a
polynomial p(n). A function f has exponential computational time
if the computational time of f is not greater than c · 2p(n). Many
practical and theoretical problems belong to the complexity class P
of all functions which can be computed by a deterministic Turing
machine in polynomial time. Sometimes it is more convenient to use

Symmetry and Complexity in Computer Sciences
287
a non-deterministic computer which is allowed to choose a computa-
tional procedure at random among a ﬁnite number of possible cases
instead of performing them step by step in a serial way.
In general, NP means the complexity class of functions which can be computed
by a non-deterministic Turing machine in polynomial time. By deﬁnition every
P-procedure is a NP-procedure. But it is a crucial question of complexity theory
whether P = NP or, in other words, whether procedures which are solved by
non-deterministic computers in polynomial time can be solved by a deterministic
computer in polynomial time. A NP-complete procedure means that any other
NP-procedure can be converted into it in polynomial time.
Consequently, if
an NP-complete procedure is actually proved to be a P-procedure, then it would
follow that all NP-procedures are actually in P. Otherwise if P ̸= NP, then no NP-
complete procedure can be solved with a deterministic algorithm in polynomial
time.
How far can we go with Turing’s concept of computability? The
dynamics of physical, biological or social systems could, in princi-
ple, be formalized by axiomatic systems. In this case, mathematical
theorems are represented by formulas. True formulas are proven by
formal derivation from the assumed axioms with logical rules. The
steps of a formal proof correspond to a computer program. Is it pos-
sible to build a computer which can decide for any formula if it is
true or not? Is there a computer which can completely derive all the
truths of a formalized axiomatic theory? It was Turing who, in 1936,
proved that there cannot be such a universal deciding machine. The
reason is that it would be able to determine whether an arbitrary
computer program stops after ﬁnite steps. But Turing proved that
the so-called halting problem is in principle unsolvable.
Turing started his proof with the question, are real numbers computable? A
real number like π = 3.1415926 . . . has an inﬁnite number of digits that seem to
be randomly distributed behind the decimal point. Nevertheless, there are simple
ﬁnite programs for calculating the digits step by step with increasing precision of
π. In this sense, p is called a computable real number. In the ﬁrst step, Turing
constructed an uncomputable real number. Remember that a computer program
of a Turing machine, for example, consists of a ﬁnite list of symbols. Thus, it
can be coded by a natural number called the program number. Imagine a list
of all possible computer programs that are ordered according to their increasing
program numbers p1, p2, p3, . . . . If a program computes a real number with an
inﬁnite number of digits behind the decimal point (e.g. π), then they should be

288
Symmetry and Complexity
written down behind the corresponding program number. Otherwise, there is a
blank line in the list:
p1
−.d11d12d13d14d15d16d17 . . .
p2
−.d21d22d23d24d25d26d27 . . .
p3
−.d31d32d33d34d35d36d37 . . .
p4
p5
−.d51d52d53d54d55d56d57 . . .
...
Following Cantor’s diagonal procedure, Turing changed the underlined digits on
the diagonal of the list and put these changed digits together into a new number
with a decimal point in front:
−. ̸= d11 ̸= d22 ̸= d33 ̸= d44 ̸= d55 . . .
This new number cannot be in the list because it diﬀers from the ﬁrst digit of
the ﬁrst number behind p1, the second digit of the second number behind p2, etc.
Therefore, it is an uncomputable real number. With this number Turing got the
unsolvability of the halting problem. If we could solve the halting problem, then
we could decide if the nth computer program ever puts out an nth digit behind
the decimal point. In this case, we could actually carry out Cantor’s diagonal
procedure and compute a real number, which, by its deﬁnition, has to diﬀer from
any computable real.
The unsolvability of the halting problem refutes the idea of a uni-
versal deciding computer. But what can be said about a universal
machine which should derive all the truth of an axiomatic theory
completely? In the case of a uniﬁed theory, all physical truths could
be derived by such a machine automatically. But if there is a com-
plete formal axiomatic system from which all mathematical truth
follows, then it would give us a procedure to decide if a computer
program will ever halt. We just run through all the possible proofs
until we either ﬁnd a proof that the program halts, or we ﬁnd a proof
that it never halts. So if a complete formalization is possible, then
by running through all possible proofs while checking which ones are
correct, we would be able to decide if the computer program halts.
But that is impossible using Turing’s result.
This argument con-
ﬁrms G¨odel’s famous incompleteness theorem with the unsolvability

Symmetry and Complexity in Computer Sciences
289
of the halting problem. There is no omnipotent computer to decide
all problems and to prove all truths. But below these theoretical
limitations many automatical decisions and proofs with more or less
degree of computational complexity are possible.
A formal axiomatic theory which describes a physical, biological,
or social system has the great advantage of compressing a lot of theo-
rems into a set of a few axioms. Thus, it delivers a shorter description
of mathematical truth. Even a physical theory can be understood as
a shorter description of many empirical data. In general, a formal
theory can be considered a computer program that calculates true
theorems or data. The smaller the program is, relative to the output,
the better the theory. Obviously, besides running time, the size of a
computer program is an important measure of computational com-
plexity. As a program is a ﬁnite list of symbols, its length can be
measured by its number of symbols in binary coding. For example,
consider the following sequences of binary digits:
s1 = 111111111111111111
s2 = 010101010101010101
s3 = 011010001101110100
For s1 and s2, there are shorter descriptions or printing programs
than the actual output: “14 times 1” for s1 and “8 times 01” for
s2. But for s3, there seems to be no shorter description than the
actual output itself.
G.J. Chaitin and Kolmogorov came up with
the idea that the algorithmic complexity of a symbolic s sequence
should be deﬁned by the length of the shortest computer program
for generating s (measured in bits) [7.19]. Algorithmic complexity is
sometimes called the algorithmic information content of a symbolic
sequence, which is the subject of the algorithmic information theory.
As random sequences have no regularities, they cannot be described
by shorter programs. They are incompressible with an algorithmic
complexity equivalent to their length. But, again, we are confronted
with incompleteness and undecidability. The reason is that we can
never decide if an individual string of digits satisﬁes this deﬁnition
of randomness and incompressibility.
We can never calculate the

290
Symmetry and Complexity
program-size complexity, because, in general, it is not decidable if a
certain program is the shortest one. If we have a program generating
a sequence, its size is only an upper bound on the program-size com-
plexity of the sequence. But we can never prove lower bounds. For
practical applications we can at least refer to standard procedures
for detecting regularities in a sequence. If we are not successful, a
sequence is called random with respect to these algorithms [7.20].
The theory of computational complexity provides tools to analyze
the dynamics of physical, biological and social systems. A Turing ma-
chine can be interpreted in the framework of classical physics. Such
a computing machine is a physical system the dynamical evolution
of which takes it from one of a set of input states to one of a set
of output states.
The states are labeled in some serial way.
The
machine is prepared in a state with a given input level and then, fol-
lowing some deterministic motion, the output state is measured. For
a classical deterministic system the measured output label is a deﬁ-
nite function f of the prepared input label. In principle, the value of
that label can be measured by an outside observer, and the machine
is said to compute the function f. If decimal numbers are coded in
binary ones, then the digits 0 and 1 can be considered alternative
states of a machine representing bits of information. But stochastic
computing machines and quantum computing machines do not com-
pute functions in the above sense. The output state of a stochastic
machine is random, with only a probability distribution function for
the possible outputs depending on the input state. The output state
of a quantum machine, although fully determined by the input state,
is not an observable and so the observer cannot in general discover
its label.
What is the reason for this? We must remember some
basic concepts of quantum mechanics which were already introduced
in Sec. 3.1.
Quantum computing relates to the smallest units of matter de-
pending on Planck’s constant and the velocity of light [7.21]. The
classical laws of physics are restricted in these dimensions. Contrary
to classical physics, matter is no longer continuous, but divided into
elementary particles like photons or electrons. Atoms change into
discrete states. Thus, for instance, a hydrogen atom could be con-

Symmetry and Complexity in Computer Sciences
291
sidered a processor for quantum information in quantum bits. The
ground state corresponds to 0 and the excited state to 1. Even pho-
tons could be used for quantum information processing, because they
have two quantum states of horizontal and vertical polarization, rep-
resented by 0 and 1. Contrary to classical physics, there are also
intermediate states as superpositions of both states 0 and 1. Such a
quantum bit is half 0 and 1. A classical bit is either 0 or 1. According
to quantum mechanics, the two possible states 0 and 1 of a super-
position remain undetermined until it is measured by an observer.
But a superposition can also collapse by a material interaction which
is not intended by the human user. This kind of instability is one
of the technical problems which must be solved in constructions of
practical quantum computers.
In physical terms, classical systems described by a Hamiltonian function are
replaced by quantum systems, e.g. electrons or photons described by a Hamilto-
nian operator. States of a quantum system are described by vectors of a Hilbert
space spanned by the eigenvectors of its Hamiltonian operator. The causal dy-
namics f of quantum states is determined by a partial diﬀerential equation called
the Schr¨odinger equation. While classical observables (e.g. localization or impulse
of a particle) always have deﬁnite values, non-classical observables (operators) of
quantum systems in general have no common eigenvector and consequently no
deﬁnite eigenvalue. A superposition with 0 and 1 is causally determined by the
Schr¨odinger equation. But the two possible states 0 and 1 remain undetermined
until it is measured by an observer.
The superposition of quantum states opens new avenues of com-
putational parallelism, because myriads of input bits could be super-
posed in a quantum state. Thus, a quantum computer could deliver
the superposition of perhaps billions of parallel computations in a
rather short time, overcoming the eﬃciency of classical computing
systems, working in a serial manner step by step. But quantum com-
puters would still work in an algorithmic way, because their dynamics
would be deterministic. The non-deterministic aspect comes in via
the act of measurement and the collapse of superposition.
Thus,
it cannot be expected that quantum computers will perform non-
algorithmic operations beyond the power of a Turing machine [7.22].
But quantum computers will be extremely interesting for computa-

292
Symmetry and Complexity
tional complexity theory and for overcoming practical constraints of
computation.
The superposition of quantum states also opens new perspectives of quantum
communication [7.23]. According to the EPR-experiments, pairs of elementary
particles (e.g. photons) which are emitted from a central source into opposite
directions remain correlated in the superposition of an entangled quantum state.
If one of two entangled quantum bits is measured at one location of a particle,
then the value of the other quantum bit is instantly determined at the location of
the other particle in opposite distance. Quantum teleporting which is sometimes
used in science ﬁction movies is at least possible. In order to transport a body
from one location to another one, the quantum information of the body’s structure
could be transferred by a kind of EPR-experiment. In order to reconstruct the
body at the distant location, it is necessary to have its materials at this place. In
any case, quantum information could be transported by a new kind of quantum
communication technology.
Quantum computing does not only mean exponential growth of
computational capacity and communication technology. Any kind of
matter stores quantum information. Therefore, any elementary par-
ticle is a processor of quantum information. The computational rules
of these processors are symmetric according to the principles of quan-
tum symmetry. Any computational step is especially reversible ac-
cording to the quantum symmetry of time (microreversibility). Phase
transitions of matter are quantum information processing. The uni-
verse is an expanding quantum computer producing quantum infor-
mation of giant complexity. Furthermore, it is an immense database
conserving all quantum information because of symmetry. We must
not forget that the concept of a computing machine is not restricted
to human technology with symbolic dynamics of data. Symbols only
represent states of dynamical systems for human purposes. Informa-
tion processing does not depend on human purposes and interests.
Human knowledge only relates to a tiny part of the information in
the world. In principle, quantum information does not depend on an
observer or measurement process. Observing and measuring quan-
tum systems is only a special example of an interaction of a quantum
system with another system [7.24].
Cosmic evolution from symmetry to complexity is characterized
by the emergence of new structures. After elementary particles and

Symmetry and Complexity in Computer Sciences
293
atoms, molecules arrange themselves in more or less complex clusters,
solids, ﬂuids and gases. The emergence of new structures is combined
with the gain of information. Thus, any molecular structure is a kind
of molecular computer with phase transitions as information process-
ing. That is the reason why molecular computing of nature also be-
comes a standard for modern computer technology besides quantum
computing. For a molecular computer billions of molecular building
blocks must be switched to one another. According to nanotechnol-
ogy single atoms molecules can actually be manipulated by scanning
tunnel microscopes. But this technology is not always suﬃcient in
order to arrange millions and billions in certain distances. The the-
ory of complex dynamical systems oﬀers new possibilities. Molecular
building blocks of complex systems can arrange themselves according
to the laws of molecular self-organization and templates of desired
patterns. In Chapter 4 many examples of symmetric structures are
discussed which could be used for molecular computing. All kinds of
smart and intelligent materials could be understood as information
processing systems with molecular computer devices. Symbolic rep-
resentations of molecular computing are only necessary for human
understanding.
The next evolutionary step after quantum and molecular comput-
ing is DNA-computing [7.25]. During evolution genetic information
systems have emerged by DNA-ruled genetic self-organization.
In
electronic computers information is coded by sequences of bits 0 or
1. DNA-systems used DNA-sequences of nucleotides which are sym-
bolically represented by the letters A, C, G, T. Information process-
ing in DNA-systems happens by chemical reactions which generate,
divide or recombine DNA-strands. DNA-replication is realized by
a molecule which can be understood as a tiny nano-machine.
It
moves along a DNA-strand, recognizes its bases step by step and
generates a complementary DNA-strand according to the DNA-law
of asymmetry. In a mathematical model it is a Turing machine which
implements a sequence of symbols A, C, G, T and prints its com-
plement by rules of simple operations.
As a Turing machine is a
universal concept of computability according to Church’s thesis, the
DNA-replication corresponds to a special Turing machine with a cer-

294
Symmetry and Complexity
tain degree of computability. The biological evolution on earth has
generated billions of nano-machines for particular tasks.
But the fascinating perspective of DNA-computing is less moti-
vated by single nano machines, but by biochemical systems with bil-
lions of simultaneously interacting DNA-strands. They are a complex
system with information processing of massive parallelity. Parallel
computers enable solutions of highly complex problems, which fail
to be solved by serially working von Neumann computers. Because
of their great packing density and high-speed (e.g. 6 gramm DNA
for 1 million tera-operation per second) DNA-computers could be
applied for special computational tasks of high complexity. Nature
only generated special examples of DNA-computers. According to
the laws of genetic self-organization we could develop new types for
human purposes and interests.
After quantum, molecular and DNA-computing, the emergence
of cellular organisms provides the next protype of information and
computing systems. Von Neumann’s concept of cellular automata
gave the ﬁrst hints of mathematical models of living organisms con-
ceived as self-reproducing networks of cells [7.26]. The state space is
a homogeneous lattice which is divided into equal cells like a chess
board. An elementary cellular automaton is a cell which can have
diﬀerent states, for instance “occupied” (by a mark), “free”, or “col-
ored.” An aggregation of elementary automata is called a composite
automaton or conﬁguration. Each automaton is characterized by its
environment, i.e. the neighboring cells which may have a symmetric
form like a square or cross:
Fig. 86.
Symmetric environments in cellular automata
The dynamics of cellular automata are determined by syn-
chronous transformation rules. Von Neumann already proved that
the typical feature of living systems, their tendency to reproduce

Symmetry and Complexity in Computer Sciences
295
themselves, can be simulated by particular cellular automata.
In
Conway’s game of life, cellular automata are complex systems gener-
ating patterns of black or colored cells which remind us of growing,
changing, and dying populations of living systems. Even all kinds
of 2-dimensional symmetries can be generated by 2-dimensional cel-
lular automata. But cellular automata are not only nice computer
games. They have turned out to be discrete and quantized models
of complex systems with nonlinear diﬀerential equations describing
their evolution dynamics. Imagine a chessboard-like plane with cells,
again. A state of a 1-dimensional cellular automaton consists of a
ﬁnite string of cells, each of which can take one of two states (“black”
(0) or “white” (1)) and is connected only to its two nearest neighbors,
with which it exchanges information about its state. The following
(later) states of a 1-dimensional automaton are the following strings
on the space-time plane, each of which consists of cells taking one
of two states, depending on their preceding (earlier) states and the
states of their two nearest neighbors. Figs. 87b–e illustrates the time
evolution of four automata. Thus, the dynamics of an 1-dimensional
cellular automaton is determined by a Boolean function of three vari-
ables, each of which can take either the value 0 or 1.
For three variables and two values, there are 23 = 8 possibilities
for three nearest neighbor sites. In Fig. 87a, they are ordered accord-
ing to the corresponding three-digit binary number. For each of the
three nearest neighbor sites, there must be a rule determining the
following state of the middle cell. For eight sequences and two pos-
sible states, there are 28 = 256 possible combinations. One of these
rule combinations, determining the dynamics of a 1-dimensional cel-
lular automaton, is shown in Fig. 87a. Each rule is characterized
by the eight-digit binary number of the states which each cell of the
following string can take. These binary numbers can be ordered by
their corresponding decimal numbers [7.27].
The time evolution of these simple rules, characterizing the dy-
namics of a 1-dimensional cellular automaton, produces very diﬀer-
ent cellular patterns, starting from simple or random initial condi-
tions. According to S. Wolfram, computer experiments give rise to
the following classes of attractors the cellular patterns of evolution

296
Symmetry and Complexity
(a)
0
000
1
001
0
010
1
011
1
100
0
101
1
110
0
111
(b)
(c)
(d)
( e )
Fig. 87a–e.
Phase transitions and attractors of cellular automata
are aiming at. After a few steps, systems of class 1 reach a homo-
geneous state of equilibrium independently of the initial conditions.
This ﬁnal state of equilibrium is visualized by a totally white plane
and corresponds to a ﬁxed point as attractor (Fig. 87b). Systems of
class 2, after a few time steps, show a constant or periodic pattern
of evolution which is relatively independent of the initial conditions.
Speciﬁc positions of the pattern may depend on the initial condi-
tions, but not on the global pattern structure itself (Fig. 87c). In
a 3rd class, cellular automata produce patterns that seem to spread
randomly and irregularly over a grid (Fig. 87d). In a 4th class, evo-
lutionary patterns with occasional quasi-organic and locally complex
structures can be observed (Fig. 87e). Contrary to 1st and 2nd class
automata, patterns in the 3rd and 4th class sensitively depend on
their initial conditions. Obviously, these four classes of cellular au-
tomata model attractor behavior of nonlinear complex systems, a

Symmetry and Complexity in Computer Sciences
297
fact well-known from self-organizing processes [7.28]. They remind
us of the familiar classiﬁcations of materials into solids, liquids, and
gases, or living organisms, such as plants and animals. In general,
the cellular automata approach conﬁrms the intuitive idea that com-
plex systems lie somewhere between regular order (like ice crystals
and Buckminsterfullerenes) and complete irregularity or noise (like
molecules in a heated gas). Organisms and brains are highly com-
plex, but they are neither completely ordered nor completely random
and disordered.
Obviously, these four classes of cellular automata model the at-
tractor behavior of nonlinear complex systems, which is well known
from self-organizing processes. In the preceding chapters, we have
seen many examples in physical, biological and social dynamics. In
general, self-organization has been understood as a phase transition
in a complex system. Macroscopic patterns arise from complex non-
linear interactions of microscopic elements. There are diﬀerent ﬁnal
patterns of phase transitions, corresponding to mathematically dif-
ferent attractors.
Predictions of future development are easy for cellular automata
of the ﬁrst two classes. In the 1st class, cellular automata always
evolve after ﬁnite steps to a uniform pattern of rest, which is re-
peated for all further steps in the sense of a ﬁxed point attractor.
As they preserve no information about the arrangement of cells on
earlier steps, the evolution is irreversible: we have no chance to go
backwards and reconstruct the initial conditions from which the au-
tomata actually started. In the 2nd class, the development of re-
peated patterns is obviously reversible and symmetric for all future
developments. It preserves suﬃcient information to allow one to go
backwards or forwards from any particular step. In random patterns
of the 3rd class, all correlations have decayed, and, therefore, the
evolution is irreversible. For localized complex structures of the 4th
class, we perhaps have a chance to recognize strange or chaotic at-
tractors, which are highly complex and correlated patterns, contrary
to the complete loss of structure in the case of randomness.
Of the 256 simplest 1-dimensional cellular automata with nearest
neighbors and binary cellular states (or two colors), only six have

298
Symmetry and Complexity
symmetric (reversible) behavior. They only generate simple repet-
itive changes in the initial conditions. In these cases, it is always
possible to reproduce the conﬁgurations of all previous steps, start-
ing from any given conﬁguration. In other words, it is possible to
interchange the past and future. The computational system has sym-
metry of time. If we increase the number of cellular states to three,
instead of two, colors, we get 33 = 27 possibilities for three nearest
neighbor sites and the gigantic number of 327 = 7 625 597 484 987
1-dimensional cellular automata. Among them, there are 1800 re-
versible automata, so starting from any conﬁguration of cells, it is
possible to generate the conﬁgurations of all previous steps.
But
some of these 1800 reversible 1-dimensional automata no longer only
deduce simple repetitive transformations of initial conditions, but
show complex, scrambled patterns.
Thus, microreversibility with
symmetric microrules can generate complex macro-behavior.
We can construct reversible rules that remain the same even when
turned upside-down. Therefore, the rules of a 1-dimensional cellu-
lar automaton are aﬀected by the dependence on colors two steps
back. In Fig. 88, we take rule 122 of the 256 simplest 1-dimensional
automata with nearest neighbors and binary cellular states (or two
colors). We add the restriction that the new state (color) of a cell
should be inverted if the cell is black (1) two steps back.
With
knowledge of not one but two successive steps, it is always possible
to determine the cellular conﬁgurations of future or past steps.
0
1
0
1
1
1
1
0
000
001
010
011
100
101
110
111
0
0
0
0
0
0
0
0
1
0
1
0
0
0
0
1
000
001
010
011
100
101
110
111
1
1
1
1
1
1
1
1
Fig. 88.
Rule of the reversible cellular automaton 122R
The symmetry and asymmetry of time are an important topic of
natural science. All fundamental laws of classical, relativistic, and
quantum physics are reversible: they are invariant with respect to
the two possible directions of time, t or −t. Our everyday experience

Symmetry and Complexity in Computer Sciences
299
Fig. 89.
Computational simulation of the second law of thermodynamics by a
reversible cellular automaton [7.29]
seems to support an irreversible development with one direction of
time. According to the second law of thermodynamics, increasing
disorder and randomness (“entropy”) is generated from simple and
ordered initial conditions of closed dynamical systems. Irreversibil-
ity is highly probable in spite of the symmetry (microreversibility)
of molecular laws. Some cellular automata with reversible rules gen-
erate patterns of increasing randomness, starting from simple and
ordered initial conditions. In Fig. 89, the reversible cellular automa-
ton of rule 122R can start from an initial condition in which all black
cells or particles lie in a completely ordered pattern at the center of
a box. Running downwards, the distribution seems to become more
and more random and irreversible, in accordance with the second
law.
In principle, symmetry of time (reversibility) is possible, analo-
gous to Poincar´e’s famous theorem of reversibility in statistical me-
chanics, but extremely improbable. By starting with a simple state
and tracing the actual evolution, one can ﬁnd initial conditions that
will lead toward to decreasing randomness (Fig. 89). But for cellu-

300
Symmetry and Complexity
lar automata, the computational amount to go backwards and ﬁnd
these conditions cannot be reduced to the actual evolution from sim-
ple to random patterns: computational irreducibility corresponds to
temporal irreducibility and improbability. Thus, in computer exper-
iments with cellular automata, we get a computational equivalence
of the second law of thermodynamics. Diﬀerent increasingly complex
and random patterns can be generated by the same simple rules of
cellular automata with diﬀerent initial conditions. In many cases,
there is no ﬁnite program to forecast the development of complex
and random patterns. The algorithmic complexity is incompressible
due to its computational irreducibility.
In this case, the question
of how the system will behave in the future is undecidable, because
there can be no ﬁnite computation that will decide it. Obviously,
computational irreducibility is connected with Turing’s fundamental
problem of undecidability. Whether a pattern of a cellular automa-
ton ever dies out, can be considered analogous to the halting problem
of Turing machines.
Computational irreducibility means that there is no ﬁnite method
of predicting how a system will behave except by going through
nearly all the steps of actual development. In the history of science,
one assumes that the precise knowledge of laws allows for precise
forecasting of the future. Even in the case of chaos theory, there are
methods of time series analysis that determine, at least, future trends
and attractors of behavior. But in the case of randomness, there is
no short cut to the actual evolution.
Wolfram supposes that the
sciences of complexity are basically characterized by computational
irreducibility [7.30]. Even if we know all the laws of behavior on the
microlevel, we cannot predict the development of a random system
on the macrolevel. The brain, as a complex system, is determined by
simple synaptic rules (e.g. Hebb’s rule) on the microlevel of neurons
that are more or less well-known. Nevertheless, there is no chance
of computing pattern formation of neural cell assemblies in all its
details. In a philosophical sense, computational irreducibility seems
to support personal individuality: our personal life is inﬂuenced by
many unexpected and random events. The pattern of our way of life
is highly nonlinear, complex, and random. Thus, there is no short

Symmetry and Complexity in Computer Sciences
301
cut to predicting life: if we want to experience our life, we have to
live it.
From a methodological point of view, a 1-dimensional cellular au-
tomaton delivers a discrete and quantized model of the phase portrait
which describes the dynamical behavior of a complex system with a
nonlinear diﬀerential equation of evolution, depending on one space
variable. There are many reasons for restricting oneself to discrete
models. The complexity of nonlinear systems is often too great to
calculate numerical approximations within a reasonable computation
time. In that case, computer experiments with discrete models give,
at least, a rough idea and feeling of what is going on, similar to
laboratory experiments.
2-dimensional cellular automata, which have been used in Con-
way’s game of life, can be interpreted as discrete models of complex
systems with nonlinear evolution, depending on two space variables.
Obviously, cellular automata are a very ﬂexible and eﬀective model-
ing instrument when the complexity of nonlinear systems increases
and the possibility of determining their behavior by solving diﬀer-
ential equations, or even by calculating numerical approximations,
becomes more and more hopeless.
In short: all complex dynamical systems are computational, but
they are not always computable.
The principle of computational
equivalence requires that there is always a computational model of
a complex dynamical system. For example, in the case of cellular
automata, we can always program the simple rules of interacting
cells on the microlevel.
Therefore, every cellular automaton is a
computational system. But, on the macrolevel, an automaton may
nevertheless generate complex patterns which cannot be decided in
the sense of Turing’s halting problem or which cannot be forcast
in the sense of chaos theory. Thus, cellular automata may not be
computable in principle or by practical reasons, because the degrees
of computational complexity increase exponentially with forcasts in
the long term. According to the principle of computational equiv-
alence, the universe could be considered a computational system, if
the basic rules of interacting elementary particles on the microlevel
are well known. Nevertheless, on the macrolevel, the emergence of

302
Symmetry and Complexity
patterns, clusters and other new phenomena may not be computable
in all cases.
The next evolutionary step after thermodynamic, genetic and cel-
lular self-organization was neural self-organization of nerve systems
and brains.
Brains have the possibility to learn and to adapt to
changing conditions of an environment. Therefore, after quantum,
molecular, DNA- and cellular computing the emergence of learning
and cognitive systems in nature is the next standard for new infor-
mation and computing systems.
In the ﬁrst logical model of the
brain, which was oﬀered by the McCulloch-Pitt network, the func-
tion of an artiﬁcial neuron is ﬁxed for all time [7.31]. But in order
to make a neural computer capable of complex tasks, it is necessary
to ﬁnd mechanisms of self-organization which allow the network to
learn. In 1949, Hebb suggested the ﬁrst neurophysiological learn-
ing rule which has become important for the development of neural
computers. Synapses of neurons do not always have the same sen-
sitivity, but modify themselves in order to favor the repetition of
ﬁring patterns which have frequently occurred in the past. In 1958,
F. Rosenblatt designed the ﬁrst learning neural computer, which has
become famous under the name “Perceptron” [7.32].
Rosenblatt’s neural computer is a feedforward network with binary threshold
units and three layers.
The ﬁrst layer is a sensory surface called a “retina”
which consists of stimulus cells (S-units). The S-units are connected with the
intermediate layer by ﬁxed weights which do not change during the learning
process. The elements of the intermediate layer are called associator cells (A-
units). Each A-unit has a ﬁxed weighted input of some S-units. In other words,
some S-units project their output onto an A-unit. An S-unit may also project
its output onto several A-units. The intermediate layer is completely connected
with the output layer, the elements of which are called response cells (R-units).
The weights between the intermediate layer and the output layer are variable and
thus able to learn.
The Perceptron is viewed as a neural computer which can classify
a perceived pattern in one of several possible groups. In the case of
two groups, each R-unit learns to distinguish the input patterns by
activation and de-activation. The learning procedure of a Perceptron
is supervised. Thus, the desired state (active or not) of each R-unit,
corresponding to a pattern to be learnt, must be well known. The

Symmetry and Complexity in Computer Sciences
303
patterns to be learnt are oﬀered to the network, and the weights
between the intermediate and output layer are adapted according
to the learning rule. The procedure is repeated until all patterns
produce the correct output. But some simple problems show that
Perceptrons are not universal. For instance, a Perceptron is not able
to distinguish between even and odd numbers. Its limitation depends
on the particular architecture of Perceptron [7.33].
A network of supervised learning which solves the problems of
Perceptron is the Hopﬁeld system [7.34].
It works with feedback
and Hebb-type learning which is practised by biological brains, too.
In the case of a homogeneous network of boolean neurons, the two
states of the neurons can be associated with the two possible values of
electron spin in an external magnetic ﬁeld. A Hopﬁeld model is a dy-
namical system which, by analogy with annealing processes in metals,
admits an energy function. As it is a non-increasing monotonic func-
tion, the system relaxes into a local energy minimum, corresponding
to a locally stable stationary state (ﬁxed point attractor).
Thus, the dynamical evolution of a Hopﬁeld system may corre-
spond to mental recognition. For example, an initial state represent-
ing a noisy picture of the letter “A” evolved towards a ﬁnal state
representing the correct picture, which was trained into the system
by several examples. The physical explanation is given in terms of
phase transition in equilibrium thermodynamics. The correct pat-
tern is connected to the ﬁxed point or ﬁnal state of equilibrium. A
more ﬂexible generation is the Boltzmann machine with a stochas-
tic network architecture of non-deterministic processor elements and
with a distributed knowledge representation, mathematically corre-
sponding to an energy function.
The general idea of relaxation is that a network converges to a
more or less global state of equilibrium on the basis of local interac-
tions. By iterative modiﬁcation of the local connections (for instance,
by a Hebb learning strategy in the case of a Hopﬁeld system) the net-
work as a whole eventually relaxes into a stable and optimal state.
We may say that local interactions lead to a cooperative search which
is not supervised, but self-organized. There are networks which use
the strategy of cooperative search for mental activities like, for in-

304
Symmetry and Complexity
stance, seeking a probable hypothesis. Imagine that a certain range
of competing hypotheses are represented by neural units which may
activate or inhibit themselves. The system thus moves away from
the less probable hypotheses toward more probable hypotheses.
In 1986, J.L. McClelland and D. Rumelhart used this cognitive
interpretation to simulate the recognition of ambivalent ﬁgures with
two symmetric views in gestalt-psychology. Fig. 90a shows a net-
work for cooperative search simulating the recognition of one of the
two symmetric orientations of a Necker cube. Each unit is a hypoth-
esis concerning a vertex of the Necker cube. Abbreviations are B
(back), F (front), Le (left), R (right), U (upper), Lo (lower). The
network of hypotheses consists of two interconnected subnetworks,
one corresponding to each of the two symmetric interpretations. The
recognition of one of the two views happens by symmetry breaking
[7.35].
Incompatible hypotheses are negatively connected, and consilient hypotheses
are positively connected.
Weights are assigned such that two negative inputs
balance three positive inputs. Each unit has three neighbors connected positively
and two competitors connected negatively. Each unit receives one positive input
from the stimulus. The subnet of hypotheses to ﬁnd is the one which best ﬁts the
input. Tiny initial ﬂuctuations (which means a small detail in the special view
of an observer) may decide which orientation is seen in the long run. Obviously,
the decision happens by symmetry breaking of an ambivalent situation.
To visualize the dynamics of symmetry breaking, suppose that all units are
oﬀ. Then one unit receives an input of positive value at random. The network
will evolve toward a state where all units of one subnetwork are activated and
all units of the other network are turned oﬀ. In the cognitive interpretation we
may say that the system has relaxed into one of the two interpretations of the
ambivalent ﬁgure of either a right-facing or a left-facing Necker cube.
Fig. 90b shows three diﬀerent evolution patterns, depending sensitively on
diﬀerent initial conditions. The size of the circles indicates the activation degree
of each unit. In the third run, an undecided ﬁnal state is reached which is never-
theless in equilibrium. Obviously, the architectural principles of this network are
cooperative computation, distributed representation, and relaxation procedure,
which are well known in the dynamics of complex systems.
Pattern recognition is interpreted as a kind of phase transition
by analogy with the evolution equations which are used for pattern
emergence in physics, chemistry, and biology. We get an interdis-

Symmetry and Complexity in Computer Sciences
305
(a)
(b)
Fig. 90a–b.
Symmetry breaking of pattern recognition (Example: Necker cube)

306
Symmetry and Complexity
ciplinary research program that should allow us to explain neuro-
computational self-organization as a natural consequence of physical,
chemical, and neurobiological evolution by common principles. As in
the case of pattern formation, a speciﬁc pattern of recognition (for
instance a prototype face) is described by order parameters to which
a speciﬁc set of features belongs.
Once some of the features which belonging to the order param-
eter are given (for instance, a part of a face), the order parameter
will complement these with other features so that the whole system
acts as an associative memory (for instance, the reconstruction of a
stored prototype face from an initially given part of that face). The
features of a recognized pattern correspond to the subsystems which
are dominated by the order parameter of the whole pattern.
A new technical approach to model symmetry and complexity of
nature is the concept of cellular neural networks (CNN) [7.36]. The
emergence of CNN has been made possible by the sensor revolution of
the late 1990s. Cheap sensor and MEMS (micro-electro-mechanical
system) arrays are proliferating in all technical infrastructures and
human environments. They have become popular as artiﬁcial eyes,
noses, ears, tastes, and somatosensor devices. An immense number
of generic analog signals have been processed. Thus, a new kind of
chip technology, similar to signal processing in natural organisms, is
needed. Analogic cellular computers are the technical response to the
sensor revolution, mimicking the anatomy and physiology of sensory
and processing organs. A CNN chip is their hard core, because it is
an array of analog dynamic processors or cells.
The CNN was invented by L.O. Chua and L. Yang at Berkeley
in 1988 [7.37]. The main idea behind the CNN paradigm is Chua’s
so-called “local activity principle”, which asserts that no complex
phenomena can arise in any homogeneous media without local ac-
tivity. Obviously, local activity is a fundamental property in micro-
electronics.
For example, vacuum tubes and, later on, transistors
became the locally active devices in the electronic circuits of radios,
televisions, and computers. The demand for local activity in neu-
ral networks was motivated by the practical needs of technology. In
1985, J.J. Hopﬁeld suggested his theoretical neural network, which,

Symmetry and Complexity in Computer Sciences
307
in principle, could overcome the failures of pattern recognition in
Rosenblatt’s “Perceptron”. But its globally connected architecture
was highly impractical for technical applications in the VLSI (very-
large-scale-integrated) circuits of micro-electronics: the number of
wires in a fully connected Hopﬁeld network grows exponentially with
the size of the array. A CNN only needs electrical interconnections in
a prescribed sphere of inﬂuence [7.38]. An immense increase in com-
puting speed, combined with signiﬁcantly less electrical power in the
ﬁrst CNN chips, has led to the current intensive research activities
on CNN since Chua and Yang’s proposal in 1988.
In general, a CNN is a nonlinear analog circuit that processes
signals in real time.
It is a multi-component system of regularly
spaced identical (“cloned”) units, called cells, that communicate di-
rectly with each other only through their nearest neighbors. But the
locality of direct connections allows for global information process-
ing. Communication between remotely connected units are achieved
through other units. The idea that complex and global phenomena
can emerge from local activities in a network dates back to von Neu-
mann’s earlier paradigm of cellular automata (CA). In this sense,
the CNN paradigm is an advancement of the CA paradigm under
the new conditions of information processing and chip technology.
Unlike conventional cellular automata, CNN host processors accept
and generate analog signals in continuous time with real numbers as
interaction values. But, actually, discreteness of CA is no principle
diﬀerence to CNN. We can introduce continuous cellular automata
(CCA) as a generalization of CA in which each cell is not just, for
example, black or white, but instead can have any of a continuous
range of grays. A possible rule of a CCA may require that the new
gray level of each cell be the average of its own gray level, and that
of its immediate neighbors. It turns out that in continuous cellu-
lar automata simple rules of interaction can generate patterns of
increasing complexity, chaos, and randomness, which are not essen-
tially diﬀerent to the behavior of discrete CA. Thus, they are useful
in approximating the dynamics of systems that are determined by
partial diﬀerential equations (PDE).

308
Symmetry and Complexity
Mathematically, a CNN is deﬁned by (1) a spatially discrete set of
continuous nonlinear systems (“cells” or “neuron”) where informa-
tion is processed in each cell via three independent variables (“input,”
“threshold,” and “initial state”) and (2) a coupling law relating rele-
vant variables of each cell to all neighbor cells within a pre-described
sphere of inﬂuence. Many CNN applications use space-invariant stan-
dard CNNs with a cellular neighborhood of 3 × 3 cells and no varia-
tion of synaptic weights and cellular thresholds in the cellular space.
A 3 × 3 sphere of inﬂuence at each node of the grid contains nine
cells with eight neighbor cells, and the cell in its center.
In this
case, the contributions of the output (feedback) and input (feedfor-
ward) weights can be reduced to two ﬁxed 3 × 3 matrices, which are
called feedback (output) cloning template A and feedforward (in-
put) cloning template B. Thus, each CNN is uniquely deﬁned by
the two cloning templates A, B, and a threshold z, which consist
of 3 × 3 + 3 × 3 + 1 = 19 real numbers. They can be ordered as a
string of 19 scalars with a uniform threshold, nine feedforward and
nine feedback synaptic weights. This string is called a “CNN gene”,
because it completely determines the dynamics of the CNN. Conse-
quently, the universe of all CNN genes is called the “CNN genome”.
With respect to the human genome project, steady progress can be
made by isolating and analyzing various classes of CNN genes and
their inﬂuences on CNN genomes. A successful application is visual
computing which generates nice models of symmetries, symmetry
breaking and complexity.
Concerning visual computing, the triple {A, B, z}, and its 19 real numbers
can be considered a CNN macro instruction of how to transform an input image
into an output image. Simple examples are subclasses of CNNs with practical
relevance, such as the class C(A, B, z) of space-invariant CNNs with excitatory
and inhibitory synaptic weights; the zero-feedback (feedforward) class C(0, B, z)
of CNNs without cellular feedback; the zero-input (autonomous) class C(A, 0, z)
of CNNs without cellular input; and the uncoupled class C(A◦, B, z) of CNNs
without cellular coupling. In A0 all weights are zero except for the weight of the
cell in the center of the matrix. Their signal ﬂow and system structure can be
illustrated in diagrams that can easily be applied to electronic circuits, as well as
to typical living neurons.

Symmetry and Complexity in Computer Sciences
309
CNN templates are extremely useful for standards in visual computing. An
example of symmetry and symmetry breaking is the visual illusion where some
images can be perceived in an ambiguous way, depending on the initial thought
or attention. One of the examples of this phenomenon is the face-vase illusion
(Fig. 91), where the image can be interpreted either as two symmetric faces, or
as a vase. Initial attention is implemented by specifying, via a second binary
pattern, one of the two ambiguously interpreted regions. Thus, initial attention
initiates symmetry breaking between two possible solutions in an equilibrium
system.
Symmetry breaking of pattern recognition corresponds to symmetry
breaking of pattern formation in nature which was illustrated in Fig. 43 by the
emergence of two kinds of convection rolls with opposite orientation. In Fig. 91,
the pictures consist of 200 × 400 pixels. Feedback-, feedforward-templates and
threshold have the following values:
A =
0
1
0
1
2
1
0
1
0
B =
0
1
0
0
−5
0
0
0
0
z = 0
The emergence of complex structures in nature can be explained
by the nonlinear dynamics and attractors of complex systems. They
result from the collective behavior of interacting elements in a com-
plex system. The diﬀerent paradigms of complexity research promise
to explain pattern formation and pattern recognition in nature by
their speciﬁc mechanisms. From the CNN point of view, it is conve-
nient to study the subclass of autonomous CNNs that cells have no
inputs. These systems can explain how patterns arise, evolve, and
Fig. 91.
Symmetry breaking of pattern recognition by a CNN (Example: face-
vase-illusion) [7.39]

310
Symmetry and Complexity
sometimes converge to an equilibrium by diﬀusion-reaction processes.
Pattern formation starts with an initial uniform pattern in an un-
stable equilibrium that is disturbed by small, random displacements.
Thus, in the initial state, the symmetry of the unstable equilibrium
is broken, leading to rather complex patterns. Obviously, in these
applications, cellular networks do not only refer to neural activities
in nerve systems, but also to pattern formation in general. Thus,
the abbreviation CNN is now understood as “Cellular Nonlinear
Network”.
A CNN is deﬁned by the state equations of isolated cells and
the cell coupling laws. For simulating diﬀusion–reaction processes,
the coupling law describes a discrete version of diﬀusion (with a
discrete Laplacian operator). CNN state equations and CNN cou-
pling laws can be combined in a CNN diﬀusion-relation equation to
determine the dynamics of autonomous CNNs. If we replace their
discrete functions and operators by their limiting continuum ver-
sion, we get the well-known continuous partial diﬀerential equations
of diﬀusion–reaction processes, which have been studied in the com-
plexity paradigms of, for example, Prigogine’s non-equilibrium chem-
istry and Haken’s synergetics. Chua’s version of the CNN diﬀusion–
reaction equation delivers computer simulations of these pattern for-
mations in chemistry and biology (e.g. concentric, auto- and spiral
waves). On the other hand, many appropriate CNN equations can be
associated with any nonlinear partial diﬀerential equation. In many
cases, it is suﬃcient to study the computer simulations of associ-
ated CNN equations in order to understand the nonlinear dynam-
ics of these complex systems.
Sometimes, the autonomous CNNs
(like digital cellular automata) are only considered approximations
of nonlinear partial diﬀerential equations for the practical purpose of
computer simulations. But, Chua claims nonlinear partial diﬀeren-
tial equations are limiting forms of autonomous CNNs. Thus, only a
subclass of CNNs has a limiting representation of partial diﬀerential
equations. In short, the CNN paradigm of complexity is more than
the conventional approach with diﬀerential equations.
Pattern recognition is understood in relation to pattern forma-
tion. Coupled CNNs with linear synaptic weights open avenues to

Symmetry and Complexity in Computer Sciences
311
much richer visual computing applications than uncoupled CNNs. In
coupled CNNs, there are couplings from the outputs of the surround-
ing cells to a cell in the center. Thus, at least one element of the
feedback (output) template A (which is diﬀerent from the coeﬃcient
of the cell in the center) is not zero. Coupled CNNs are, for example,
able to detect holes (i.e. a set of adjacent pixels) on a surrounding
background. In particular, it turns out that the famous connectivity
problem can be solved by a simple coupled CNN of this kind. This
problem is not only important for practical reasons, but also has a
long tradition in the history of cognitive science. How can we recog-
nize connected patterns (“gestalt”), such as shapes, ﬁgures, or faces
from a set of pixels? In a famous proof, M. Minsky demonstrated
that the connectivity of certain patterns could not be recognized by
neural networks like Rosenblatt’s “Perceptron”.
In the case of linear synaptic weights, the characteristics of a
synapse or template element are linear. But in technical applications
(e.g. with voltage- controlled current sources) or living cells with
synaptic communication by neurotransmitter, they are never com-
pletely linear. If we use nonlinear templates for modeling synaptic
dynamics, the analysis becomes more complex. Thus, a compromise
of modeling is the application of uncoupled CNNs with nonlinear,
space-invariant weights.
Besides visual computing, other functions of behavior are also
modeled by neural networks. In nature, complex patterns of move-
ments are not computed and controlled by a central processor, but
by self-organizing learning algorithms of feedback nets. An example
is a grasshopper with six legs and diﬀerent motor modules of lifting,
swinging, and coordinating.
External information of an unknown
environment is learned and stored implicitly by the distribution of
synaptic weights in neural nets. During evolution, decentralized net-
work modules could be used as building blocks for diﬀerent organisms
according to changing conditions. These biological insights into mo-
tor information processing are already being applied to robotics and
chip technology (embodied cognition).
Soft computing uses fuzzy
logic, genetic and learning algorithms for ﬂexibility, adaptive and
human-like information systems. Aﬀective computing aims at rec-

312
Symmetry and Complexity
ognizing and modeling emotional states of the brain as information
processing. Cyborgs (cybernetic organisms) represent the vision of a
brain with implanted chips of neural computers. Neural nets could
recognize patterns of brain activities (e.g. EEG signals) correlating to
states of cognition and consciousness. In a next step, patterns of neu-
ral activities could be scanned and downloaded to a supercomputer.
Then, of course, a dramatic ethical problem arises: Could human
personality (not only the DNA-genotype) be cloned and inﬂuenced
by computational systems?
In Sec. 5.3, the brain was introduced as a complex cellular system.
If its motoric, sensory, emotional, and cognitive dynamics are well
understood, then, according to the principle of computational equiv-
alence, they can be modeled by computational systems. Thoughts,
emotions, and even consciousness correspond to complex patterns of
neural cell-assemblies (Fig. 74) emerging from basic synaptic rules
of neural interaction (e.g. Hebb’s rule). But even in the simpliﬁed
case of cellular automata, local rules of cellular interaction can gen-
erate undecidable and chaotic patterns. Thus, the patterns of cell-
assemblies may be too complex to be forecast in all details by ﬁnite
programs. The brain would be a computional system, because its
basic neural rules could be programmed. But, nevertheless, its dy-
namics would not be computable.
Actually, the brain is a stochastic system with global noise of un-
correlated neural ﬁring. Cognitive or emotional states correspond
to locally correlated patterns of synchronously ﬁring cell-assemblies
emerging like islands in a sea of noise and entropy. To forecast a
speciﬁc feeling or thought would be as improbable as forecasting the
emergence of a little wave on the wide ocean. Therefore, people are
characterized by their particular nonlinear dynamics and develop-
ment. They have their own history, personality, and intimacy. In
this sense, robots with artiﬁcial minds like humans could develop
their own identity and emotions, although their basic rules are pro-
grammed by human engineers. In short, to be a computational sys-
tem is no contradiction to the concept of free will. The reason is the
complexity and nonlinearity of computational systems [7.40].

Symmetry and Complexity in Computer Sciences
313
(a) star
(b) ring
(c) bus
(d) tree
(e) completely meshed
net
(f) partially meshed
net
Fig. 92a–f.
Symmetries of network typologies [7.41]
Human brains and artiﬁcial minds are only speciﬁc models of
computational networks with diﬀerent degrees of complexity. Their
topologies and dynamics are a challenge of present and future re-
search.
Diﬀerent principles of symmetry are applied in network
topologies determining the physical shape or the layout of compu-
tational networks (Fig. 92). In star topologies (Fig. 92a), all cells
are connected to a central cell. All traﬃc emanates from the central
cell. The advantage of the star topology is that if one cell fails, then
only the failed cell is unable to send or receive data. The star net-
works are relatively easy to install, but have potential bottlenecks
and failure problems at the central cell because all data must pass
through this central cell. In ring topologies (Fig. 92b), all cells are
connected to one another in the shape of a closed loop, so that each
cell is connected directly to two other cells. In most cases, data ﬂows
in one direction only, with one cell receiving the signal and relaying
it to the next cell on the ring. In bus topologies (Fig. 92c), all cells

314
Symmetry and Complexity
are connected to a central backbone, called the bus. The structure
has a translational symmetry. The bus permits all cells to receive ev-
ery transmission. It is relatively simple to control traﬃc ﬂow among
cells. The main drawback stems from the fact that only one com-
munication channel exists to service all cells of the network.
If a
channel between two cells fails, then the entire network is lost. In
tree topologies (Fig. 92d) characteristics of bus and star topologies
are combined. It consists of groups of star-conﬁgured cells connected
to a bus. Tree topologies allow for the expansion of an existing net-
work. In mesh topologies (Fig. 92e), each cell is connected to every
other cell by a separate wire. This conﬁguration provides redundant
path through the network, so if one cell blows up, we do not lose
the network. Thus, the full symmetry oﬀers high security. But it
demands a high amount of technical eﬀort. Fig. 92f shows a ring
Fig. 93a.
Fully-contracted CNN with 25 cells [7.43]

Symmetry and Complexity in Computer Sciences
315
Fig. 93b.
Star CNN with 26 cells [7.43]
topology with less symmetry, because it is only partially meshed.
Only critical cells are secured by multiple connections.
A star topology can also be applied to neural networks like CNNs
[7.42]. A star cellular neural network is a new dynamic nonlinear
system deﬁned by connecting N identical dynamical systems, called
local cells, with a central system in the shape of a star. All local
cells communicate with each other through a central system. Thus,
a Star CNN has only N connections from the N local cells to a cen-
tral system. Since a fully-connected CNN has a mesh topology and
self loops, it needs N(N + 1)/2 connections. Fig. 93 shows a fully-
connected CNN with N = 25 cells and a Star CNN with N = 26 cells.
The Star CNN has the same bottleneck as that of the star topology.

316
Symmetry and Complexity
However, the Star CNN can be easily implemented in hardware us-
ing only N connections, except that a central cell has to supply
complicated signals.
A Star CNN can store and retrieve complex
oscillatory patterns in the forms of synchronized chaotic states like
associative memories. Furthermore, the Star CNN can function as
dynamic memories. In this case, its output pattern can occasionally
travel around the stored patterns, their reserved patterns and new
emerging patterns. It is motivated by the observation that a human
being’s associative memory is not always static, but sometimes wan-
ders from a certain memory to another memory, one after another.
New patterns can emerge like a ﬂash of inspiration which is impor-
tant for known memories. Changes of memories also sometimes seem
to be chaotic.
An information storage device is called an associative memory if it
permits the recall of information on the basis of a partial knowledge
of its contents, but without knowing its storage location. A Star CNN
for associative memories usually converges to a stored pattern or to
a new one which spontaneously emerge in a ﬂash of inspiration with
relation to known memories. The emergence of new patterns can be
interpreted as a form of creative activity which is well-known from
the human brain. New patterns are usually made up of combinations
of stored patterns. Figs. 94a–b shows two new symmetric patterns on
the left which are made up of combinations of (right) basic patterns
of symmetry. These results are related to the fact that we generally
solve problems and generate new ideas by combining various notions,
ideas, or memories in our mind, and sometimes have a sudden ﬂash
of inspiration [7.44]. Thus, these combinations of symmetric patterns
are often used in IQ-tests to measure human intelligence. Without
spontaneous memories, the brain would not be capable of learning
anything new, and furthermore it would become obsessed with its
own strongest memories. Spontaneous memories help the brain avoid
this problem and learn something new, albeit similar in some respect
to what is already stored in the network.
According to the principle of computational equivalence, the evo-
lution of complex dynamical systems in nature and society can be
considered evolving computational systems. Actually, computational

Symmetry and Complexity in Computer Sciences
317
(a)
(b)
Fig. 94a–b.
(Left) Spurious patterns which are made up of combinations of
(right) basic symmetric patterns [7.45]
networks describe a wide range of dynamical systems in nature and
society. For example, a cell is best modeled as a complex network
of chemicals connected by chemical reactions. Fads and ideas spread
on social networks, whose nodes are human beings whose edges rep-
resent various social relationships. Their topology and evolution is
governed by principles of self-organization. The development of tech-
nical networks seem to continue the evolution of natural and social
networks in a kind of technical co-evolution. Evolving computational
networks are also characterized by a tendency from symmetry and
simplicity to complexity and diversity. Self-organization is a strat-
egy to handle an increasing complexity of data and information which
can no longer be programmed, monitored and controlled in all details
step by step.
Natural evolution has not focused on single organisms with in-
creasing intelligence based on neural information processing.
In
species and populations, we observe increasing degrees of ﬁtness en-
abled by increasing capacities of swarm, collective and distributed
intelligence with extrasomatic information processing.
In sociobi-
ology, populations of ants and termites organize complex transport,
information and communication systems through swarm intelligence.
There is no central supervisor over the construction of complex net-
works of paths between their bivouacs. The ordering of the system

318
Symmetry and Complexity
is self-organizing according to chemical signals between thousands of
animals. In human history, complex transport and information net-
works have emerged with more or less self-organizing behavior. Tele-
phone and railway networks are supervised by global control stations,
while car traﬃc in networks of streets depends on the local behavior
of drivers. Thus, auto traﬃc can be considered a complex dynam-
ical system with typical phenomena of oscillation (“stop-and-go”),
congestion, and chaos.
The capacity to manage the complexity of modern societies de-
pends decisively on an eﬀective communication network. Like the
neural nets of biological brains, this network determines the learn-
ing capability that can help mankind to survive. In the framework
of complex systems, we have to model the dynamics of information
technologies spreading in their economic and cultural environment.
Thus, we speak of informational and computational ecologies. There
are actually realized examples, like those used in airline reservation,
bank connections, or research laboratories, which include networks
containing many diﬀerent kinds of computers.
Traditionally, complex networks have been studied by graph the-
ory. While graph theory focused on regular and symmetric graphs,
large-scale networks with no apparent design principles have been
described as random graphs [7.46]. According to the Erd¨os-R´enyi
model, a random network starts with N nodes and connect every
pair of nodes with probability p, creating a graph with approximately
pN(N −1)/2 edges distributed randomly. But observations of real
complex networks clearly indicate that, for example, the Internet
and World Wide Web are neither completely regular and symmetric
nor completely random. They are complex systems, and the ques-
tion arises which principles of self-organization are hidden behind
their observed dynamics. Observations lead to the three spectacular
quantities of average path length, clustering coeﬃcient, and degree
distribution which play a key role in the recent development of com-
plex computational networks.
The small-world concept in simple terms describes the fact that,
despite their often large size, in most networks there is a relatively
short path between any two nodes [7.47].
The distance between

Symmetry and Complexity in Computer Sciences
319
two nodes is deﬁned as the number of edges along the shortest path
connecting them.
A popular manifestation of small worlds is the
“six degrees of separation” concept, assuming that there is a path of
acquaintances with a typical length of about six between most pairs
of people in the United States. The average path length of a network
is deﬁned as the distance between two nodes, averaged over all pairs
of nodes. The diameter of a network is the maximal distance between
any pair of its nodes.
The emergence of clusters in networks was also at ﬁrst observed
in social systems [7.48]. Cliques organize themselves, representing
circles of acquaintances in which every member knows every other
member. A selected node i in the network have ki edges which con-
nect it to ki other nodes. If the nearest neighbors of the original
node were part of a cluster, there would be ki (ki −1)/2 edges be-
tween them.
The ratio between the number Ei of edges between
these ki nodes and the total number ki (ki −1)/2 gives the value of
the clustering coeﬃcient of node i, which is Ci = 2Ei/ki (ki −1).
The clustering coeﬃcient of the whole network is the average of all
individual Ci’s. In a random network, since the edges are distributed
randomly, the clustering coeﬃcient is C = p. In most real complex
networks the clustering coeﬃcient is typically much larger than it
is in a comparable random network which has the same number of
nodes and edges as the real network.
The degree distribution is motivated by the observation that not
all nodes in a network have the same number of edges (node degree).
The spread in the node degrees is characterized by a distribution
function P(k), which gives the probability that a randomly selected
node has exactly k edges. Since in a random graph the edges are
placed randomly, the majority of nodes has approximately the same
degree ⟨k⟩of the network. The degree distribution of a random graph
is a Poisson distribution with a peak at P(⟨k⟩). But for most large
networks the degree distribution deviates from a Poisson distribu-
tion. Actually, the degree distribution of, for example, the Internet
and the World Wide Web has a power law tail P(k) ∼k−γ. Since
power laws are free of a characteristic scale, such networks are called
scale free.

320
Symmetry and Complexity
One of the ﬁrst examples of large networks in modern civilization
was phone call networks. A large directed graph was constructed
from long-distance telephone call patterns, where nodes are phone
numbers and every completed phone call is an edge, directed from the
caller to the receiver. In call graph of long-distance telephone calls
made during a single day, the degree distributions of the outgoing and
incoming egdes followed a power law with exponent γout = γin = 2.1.
The sustained, explosive growth of the Internet and the World Wide
Web over the past decade has made them a part of globalization.
They have changed the way we do business, communication, enter-
tainment, education and culture. In an increasing ﬂood of informa-
tion, information retrieval is a challenge of information and computer
technology.
The Internet is a network of physical links between computers and other
telecommunication devices (Fig. 95a).
The topology of the Internet has been
studied at two diﬀerent levels.
At the router level the nodes are the routers,
and edges are the physical connections between them. At the interdomain (or
autonomous system) level, each domain, composed of hundreds of routers and
computers, is represented by a single node, and the edge is drawn between two
domains if there is at least one route that connects them. In each case, the de-
gree distribution follows a power law. The interdomain topology of the Internet,
captured on three diﬀerent days between 1997 and the end of 1998, resulted in a
degree exponent γd
I ≈2.2. A 1995 survey of Internet topology at the router level,
containing 3888 nodes, found γr
I ≈2.48. In a 2000 investigation with a connec-
tivity of nearly 150 000 router interfaces and nearly 200 000 router adjacencies,
the power law scaling was conﬁrmed with γr
I ≈2.3. Furthermore, the Internet
as a computational network displays clustering and small path length as well.
Between 1997 and 1999, the clustering coeﬃcient of the Internet ranged between
CI = 0.18 and CI = 0.3, to compare with Crand ≈0.001 for random networks of
similar parameters. The average path length of the Internet at the domain level
was found to be about 4, compared to Lrand ≈10 for the corresponding random
graph. At the router level, it was around 9, indicating its small-world character.
The Internet is designed to operate over diﬀerent underlying com-
munication technologies, to support multiple and evolving applica-
tions and services. Thus, it is a computational network of vast diver-
sity, combining diﬀerent kinds of networks. In order to communicate
across diﬀerent kinds of networks, an Internet Protocol (IP) was in-
troduced. The IP number codes the networks which an information

Symmetry and Complexity in Computer Sciences
321
(a)
(b)
Fig. 95.
Typology of the Internet (a) and the World Wide Web (b) [7.49]
packet has to pass through. The Internet is a computational network
of routers that navigate information packets from one computer to
another. Contrary to phone call networks, there is no ﬁxed connec-
tion between a sender and receiver. Communication is divided into
information packets of byte size that are transported in the networks
of routers by packet switching. The routers are the nodes of the net-
work determining the local path of each packet by using local routing
tables with cost metrics for neighboring routers. A router forwards
each packet to a neighboring router, at the lowest cost, to the des-
tination [7.50].
In the sense of the CA and CNN paradigms, the
local routing tables can be considered “templates” of local nonlinear
information processing.
As a router can only deal with one packet at a time, other arriv-
ing packets must be stored in a buﬀer. If more packets arrive than a
buﬀer can store, the router discards the overﬂowing packets. Senders
of packets wait for a conﬁrmation message from the destination host.
These buﬀering and resending activities of routers can cause conges-
tion in the Internet. Fluctuations of information packet congestions
can be indirectly observed through echo experiments of control mes-
sages between neighboring routers. A monitoring host between two
routers periodically sends a series of echo packets to both routers.
The packets take a round-trip time (RTT) to the destination and
back. Congestion is associated with higher RTT values. RTT ﬂuctu-
ations increase with the sequence of routers in the Internet network
[7.51].
In automobile traﬃc systems, a phase transition from non-
jamming to jamming depends on the average car density as the con-

322
Symmetry and Complexity
trol parameter. At a critical value, ﬂuctuations with self-similarity
and power law distribution can be observed. From this analogy, a
control parameter of data density is deﬁned by the propagation of
congestion from a router to neighboring routers and the dissolution
of the congestion at each router. The cumulative distribution of con-
gestion duration is an order parameter of pattern formation [7.52].
There are phase transitions between spare and congestion phases.
The spare phase corresponds to a case in which the mean input of
the information system is smaller than the maximum output. The
critical point condition is when the mean input rate is equal to the
maximum rate.
At a critical point, when the congestion propagation rate is equal
to congestion dissolution, fractal and chaotic features can be ob-
served in data ﬂow. On diﬀerent scales of time series analysis, we
can analyze the self-similarity of the information packet’s ﬂuctua-
tions, which is a necessary (not suﬃcient) condition of strange at-
tractors (Fig. 96). Symmetry as self-similarity is hidden behind the
diversity and heterogeneity of the Internet.
The World Wide Web (WWW) is the largest computational net-
work for which topological information is currently available. The
nodes of the network are the documents (web pages) and the edges
are the hyperlinks (URLs) that point from one document to another
(Fig. 95b). The size of this network was close to one billion nodes at
the end of 1999. The degree distribution of the web pages follows a
power law over several orders of magnitude. Since the edges of the
World Wide Web are directed, the network is characterized by two
degree distributions. The distribution of outgoing edges, Pout(k), sig-
niﬁes the probability that a document has k outgoing hyperlinks, and
the distribution of incoming edges, Pin(k), is the probability that k
hyperlinks point to a certain document. Both the in- and out-degree
distributions are found to be in a power law form: Pin(k) ∼k−γin and
Pout(k) ∼k−γout. Studies with diﬀerent subsets of the WWW have
showed that the in-degree distribution of the WWW is γin ≈2.1,
while its out-degree distribution is ranged somewhere in between
γout ≈2.38 and γout ≈2.72.

Symmetry and Complexity in Computer Sciences
323
Fig. 96.
Self-similarity of data traﬃc [7.53]
The directed graph of the WWW does not allow to measure the
clustering coeﬃcient. One way to avoid the diﬃculty is to let the
network be undirected, making each edge bidirectional. It was found
that the clustering coeﬃcient is much higher than that of a random

324
Symmetry and Complexity
graph of the same sizes and edges, although it is still signiﬁcantly
less than 1.
Despite the large number of nodes, the World Wide
Web also displays the small world property. The network structure
plays a crucial role in determining the spread of ideas, innovations,
or computer viruses. In this light, spreading and diﬀusion has been
studied on several types of complex networks regular, random, small-
world and scale-free. It was shown that while for random networks
a local infection (“butterﬂy eﬀect”) spreads to the whole network
only if the spreading rate is larger than a critical value, for scale-
free networks any spreading rate leads to the infection of the whole
network. That is to say, for scale-free networks the critical spreading
rate reduces to zero.
The information ﬂood in the more or less chaotic World Wide
Web is a challenge for intelligent information retrieval [7.54]. Infor-
mation Retrieval (IR) in the WWW can be considered a decisive
procedure for evaluating and selecting the most relevant documents
and information according to certain constraints. Procedures of IR
are also inspired by natural evolution.
There are applications of,
for example, genetic algorithms, in order to improve information re-
trieval.
Genetic algorithms optimize populations of chromosomes
in sequential generations by reproduction, mutation, and selection.
In information retrieval, they are used for optimizing the queries of
documents. Information retrieval is also realized by neural networks
adapting with synaptic plasticity to the information preferences of
human users.
In sociobiology, we can learn from populations of ants and ter-
mites how to organize traﬃc and information processing through
swarm intelligence.
From a technical point of view, we need in-
telligent programs distributed throughout the nets.
There are al-
ready more or less intelligent virtual organisms (agents), learning,
self-organizing, and adapting to our individual preferences of infor-
mation, to select our e-mails, to prepare economic transactions, or
to defend against the attacks of hostile computer viruses, like the
human immune system. Virtual agents are designed with diﬀerent
degrees of autonomy, mobility, reactivity, and learning capabilities

Symmetry and Complexity in Computer Sciences
325
for communicating.
They communicate and cooperate with their
virtual environment as local spheres of inﬂuence.
Global networking is becoming one of the exciting challenges
of complexity research. Understanding complex systems in nature
and society supports the eﬀective management of communication
networks.
In the 21st century, information, communication, and
biotechnology are growing together. Therefore, information process-
ing requires learning from nature.
Information can be generated,
transmitted, stored, processed, and represented in nature by sense
organs, the nervous system, and the brain. Cognitive processes like
learning and thinking, language, motorics, perception, and communi-
cation, are simulated using technology by physical, chemical, and bi-
ological sensors, light-wave conductors, electronic, optical stores, mi-
croprocessors, neural nets, robotics, virtual reality, ubiquitous com-
puting, artiﬁcial life and intelligence [7.55]. Together they aim at
producing learning, adapting, and self-organizing evolutionary com-
plex systems. Therefore, this approach is called organic computing
[7.56].
An exciting example of organic computing is the evolutionary
architecture of future automobiles, integrating all aspects of com-
plexity and self-organization. The automobile industry is still one
of the driving and dominating engines of the global economy. Thus,
complexity research ﬁnds a realistic application in the production
of future cars as learning, adapting, and self-organizing evolution-
ary complex systems. A challenge of the automobile industry is the
increasing complexity of electronic systems. If we consider the elec-
tronic cable systems of automobiles from the beginning through to
today, there will be a surprising similarity to neural networks of or-
ganisms which increase in complexity during evolution.
Contrary
to biological evolution, electronic systems of today are rigid, com-
pact, and inﬂexible. So tiny failures can lead to a collapse of the
whole system. In an evolutionary architecture (EvoArch) the nervous
system of an automobile is divided into autonomous units (carlets)
which can conﬁgurate themselves in cooperative functions in order
to solve intelligent tasks. Examples of this are the complex functions
of motor, brake and light, wireless guide systems like GPS, smart de-

326
Symmetry and Complexity
vices for information processing, and the electronic infrastructure of
entertainment.
According to the complex systems approach, the functions of a car
are considered as macro-features which emerge from self-organizing
interactions and the cooperation of autonomous units on the micro-
level. Examples of autonomous units of a car (carlets) are: switches,
lamps, tuners, controllers, regulators, horns.
A car function like
“air conditioning”, “turn signal” or “hazard warning” needs one or
more switches which must be selected from among more than a hun-
dred candidates. Actually, a car function like “turn signal” needs
carlets for a turn signal switch, a terminal switch, turn signal ﬂash-
ing, and several turn signal lamps. In an evolutionary architecture,
cooperations are realized in the EvoArch-arena (Fig. 97), where ac-
tive autonomous units ask for cooperation with passive autonomous
units which have the appropriate features to execute a car function.
Each unit (carlet) has an ID-number for self-identiﬁcation. It can
declare its property (e.g. turn signal) and its intention (e.g. search
for a switch).
The interaction of units (carlets) is made possible
by a communication system (carCom) with information retrieval
procedures, protocols, and contracts of cooperation which are well-
known in the Internet like RMI (Remote Method Invocation) and
RPC (Remote Procedure Call).
As in the Internet, the network-
management is based on the middleware of routing-procedures with
routing-protocols and routing-tables.
According to the principle of computational equivalence, a car is
an example of a dynamical system which can be considered an in-
formation and computational system. The increasing diversity and
complexity of electronics must be managed by self-organization like
in organisms.
Cars have been typical products of classical indus-
tries. In industrial societies, economies have been characterized by
the steps of production, logistics, distribution, marketing and sale
of material goods. In computer-assisted information societies, there
is an oﬀer and demand of virtual information products and services
with steps of information collection, information systematization, in-
formation retrieval, production and trade of information-based sys-
tems. Therefore, economists distinguish material chains of value in

Symmetry and Complexity in Computer Sciences
327
Fig. 97.
Self-organization of car functions in an evolutionary architecture [7.57]
industrial societies and virtual chains of value in information soci-
eties.
According to Shannon, the content of information goods is
measured by the degree of news for a receiver. But it is not suﬃ-
cient to be well informed in order to handle our aﬀairs. In the next
step, information of high value must be evaluated and applied to
solve problems. Information must be transformed to knowledge in
the sense of know-how for problem solving.
Besides matter and life, the chief ingredients of the 21st century
are in- formation and knowledge. In a knowledge society, science is
a productive power of economic and social growth which needs new
strategies of cooperation with economy and politics. The “wealth of
nations” (Smith) is the knowledge of their people. Therefore in the
process of globalization with competing nations and societies, edu-
cation must secure the sustainable future of the knowledge society.
The technical evolution of computational systems for information
and knowledge processing is the fundamental challenge of mankind
in the 21st century. Humans will no longer be only products of a
blind evolution, but will try to inﬂuence their development by use of
computational tools.

This page intentionally left blank

Chapter 8
Symmetry and Complexity in
Philosophy and Arts
The message of this book is easy to understand: cosmic evolution
leads from symmetry to complexity by symmetry breaking and phase
transitions. The emergence of new order and structure is explained
by physical, chemical, biological and social self-organization, accord-
ing to the laws of nonlinear dynamics. All these dynamical systems
are considered computational systems processing information and
entropy. Because of symmetry, no information is lost, although it
is sometimes hidden from us. From a philosophical point of view,
the question arises as to whether symmetry and complexity are only
epistemic projections and models of science or whether they can be
understood as universals of reality. In the Platonic tradition, symme-
try was even uniﬁed with truth and beauty. In modern civilizations,
the unity is broken and has been transformed into diversity and het-
erogeneity. Therefore, in the last chapter, the development of arts
from symmetry to complexity is considered in the spirit of nonlinear
science.
8.1
The Philosophy of Symmetry and Complexity
Philosophy is the mother of science. It deals with the origin, princi-
ples, and universals of knowledge. Since the days of Plato and Aris-
totle knowledge has expanded into complexity and diversity. Science
has split oﬀand specialized in a manifold of disciplines and subdisci-
plines. Obviously science follows the tendency of professionalization
which we discussed in the context of globalization. The growth of
329

330
Symmetry and Complexity
knowledge is embedded in the dynamics of information.
But the
children seem to forget the origin from their mother. Philosophy is
sometimes only a historical relic reminding scientists of their com-
mon origin, like background radiation as cosmic trace of the big bang
and common origin of the universe’s diversity.
Specialization is a necessary tendency of modern science.
But
the splitting of knowledge endangers the common orientation and
overview of scientists. Actually, since antique philosophy, mankind
has generated a subtle web of knowledge with meshes of increasing
granulation. Even today all knowledge is connected, although the
connections are often hidden and not easy to ﬁnd, like on a com-
plex map of streets and paths in a modern city. The map models a
landscape of knowledge with valleys, hills and high mountains. In
the valleys, there are the fruitful greens of experience, data, and lab-
oratories, near to the bottom of reality.
The hills and mountains
represent more or less abstract concepts and theories with more or
less distance to reality. More or less applied disciplines are linked
like the summits of diﬀerent heights in a mountain-range. On the
top of high mountains, with very general principles and universals,
we have a wide view over-looking many other disciplines and their
network of connections, but in the thin and clear air of abstraction.
This is the area where philosophers feel at home.
Philosophers are specialists for principles and universals of knowl-
edge.
In this sense, they are part of science, on the top of some
hills and mountains, sometimes wandering into the valleys to test
their general view and to study concrete models. But philosophy
should not be in the clouds without connection to experience and
science. On the other hand, science should not be encapsulated in
some deep valleys without orientation and connection to the rest of
the world. Aristotle was one of the ﬁrst engineers of knowledge who
designed classiﬁcations of more or less abstract concepts in hierar-
chies of knowledge. On the top of his tree-like hierarchies, there are
the general principles of entities which are divided into less abstract
subconcepts which lead to the concrete concepts of observation and
applied sciences. The Aristotelean taxonomies are called ontology
which is still a term of informatics for knowledge classiﬁcations in,

Symmetry and Complexity in Philosophy and Arts
331
for example, databases [8.1]. In modern times, knowledge has spe-
cialized, but, nevertheless, deals with general principles.
Newton
called his main book “Philosophiae naturalis principia mathemat-
ica” (Mathematical Principles of Natural Philosophy). He analyzed
the general principles of force and mass with mathematical methods
and founded the physical theory of dynamics. It is noteworthy that
he had a chair for natural philosophy. His famous countryman Smith
had a chair for moral philosophy and established the economic the-
ory of sociodynamics. Einstein founded the principles of space-time,
and physicists like Bohr, Dirac or Schr¨odinger analyzed the quan-
tum principles of matter and energy. Today, thousands of scientists
are engaged in more or less theoretical research and search for the
principles of matter, life, the mind, economies and societies. There-
fore, they all are connected with philosophical principles in the web
of knowledge. Symmetry and complexity are general universals of
structures and systems.
It is amazing that it is not only our image of nature that is de-
scribed by means of ever more complex structures, but human culture
and society as well. In the course of modern time institutions, indus-
tries, markets, social roles, etc., have achieved such complexity and
interconnectedness that the resulting profusion of information can
scarcely be mastered any more. Just as reductions in complexity are
often what make knowledge about nature possible, our social and
political behavior require that we make simpliﬁcations and reduc-
tions so that the complexity of political, economic and social reality
will not render us helpless. Goethe said: to take action one must be
without a conscience. To know anything, one must leave out a piece
of the truth.
Our contemporary image of nature is based on abstract struc-
tural species that are linked by a complicated net of pre-theories,
observations, instruments of observation and work in laboratories.
Structures are mathematical concepts of, for example, abstract sets
or spaces which are characterized by relations, transformations or
operations. Thus, a question arises as to whether they are merely
tools for thought based on axioms for ordering measurement data,
or whether they in any way provide information about structures

332
Symmetry and Complexity
of nature. In the history of philosophy this question as to the sta-
tus of structures and symmetries is clearly in the tradition of the
quarrel of the universals that was carried out on the eve of modern
philosophy and has subliminally determined the discussions on the
foundations of logic, mathematics and the natural sciences ever since
[8.2]. The example of the concept of structure and symmetry shows
the scale of possible positions in the quarrel of the universals —
from heavily realistic-ontological presuppositions to nominalism and
positivism.
Platonic ontology makes the most ambitious claim. With regard
to the problem of universals one could summarize it in the expres-
sion: “Symmetria est ante res” (symmetry is behind the things). It
holds that symmetrical structures are the real realities, and that we
perceive breaks of symmetry as appearances and “shadows”. Plato
presupposes that perfect and ideal regular bodies are the building
blocks of matter, not approximative models as they occur in some
crystals, for example. In the Christian-Augustinian tradition the Pla-
tonic ideas become the thoughts of God, which give nature its laws.
The ontological-Platonic conception of natural laws is also found in
the early mathematical physicists such as Galileo and Kepler. The
physical world is conceived of as a second scripture (book of nature)
side by side with the Holy Scriptures; God reveals himself to human
beings through both. The book of nature is written in the language
of mathematics, so that in consequence the laws of nature can be
grasped only by one who masters this language.
By contrast, the point of view of the Aristotelian philosophy of
nature can be summarized in the expression: “Symmetria est in re-
bus” (symmetry is in the things). The multifariousness of being is
actualized in the Aristotelian hierarchy of substantial forms. The
pure possibility of matter becomes actuality via intermediate stages.
According to Aristotle, the distinction between matter and form is
only an abstraction we employ to describe the motion of matter.
If one conceives of structures as Aristotelian forms, they are “in
things,” (ﬁguratively speaking). Thus they do not exist separately
from matter. Instead it is in the motions of matter that structures,
as potentialities, are actualized.

Symmetry and Complexity in Philosophy and Arts
333
In the age of mechanics the Aristotelian doctrine of forms was
often misunderstood and was vehemently attacked as an obstacle
on the way to mathematical physics. Leibniz is an exception. He
interpreted substantial forms as the new mathematical laws of na-
ture. Heisenberg interpreted the operators of quantum mechanics as
potentialities and related them to the Aristotelian doctrine of forms.
Weyl oﬀers an epistemic interpretation of symmetry: the invari-
ance of natural laws shows that their validity is independent of the
diﬀerent frames of reference of diﬀerent observers.
In this sense
invariance shows the intersubjective validity of natural laws (cate-
gories): “symmetria est in mente” (symmetry is in mind). According
to Kant, the forms of natural laws (categories) are already pregiven
through our subjective constitution of cognition. Only in this way
is it possible for us to formulate natural laws at all.
In speaking
of natural laws Kant uses a typically political metaphor of the En-
lightenment: we human beings do not recognize ontologically alleged
natural laws as thoughts of God. Instead, we ourselves are “law-
givers of nature” in the framework of the constitution of our reason.
Besides making our own laws within the framework of our politi-
cal constitutions, we also achieve autonomy vis-a-vis nature. Thus
structures are products of reason, intuition and imagination and are
applied according to categorial schemata for the purpose of giving
order to the diversity of perceptual phenomena by means of physical
“images” (sic Kant!).
The nominalistic view appears in a philosophically sharper form in
the conventionalistic and instrumentalistic orientations. In these ori-
entations symmetry assumptions, characterized mathematically only
by their simple and transparent formula, must prove their worth
physically in the explanation of measurement data or for purposes
of prognosis. Regarded this way, they are at best appropriate for-
mulas of mathematical formalisms.
At ﬁrst glance the advantage
of this position seems to be that mathematical symmetry structures
are not associated with symmetrical entities. Therefore symmetry
is not bought at a high price of ontological assumptions. To some
extent instrumentalism wants to shop for the advantages of sym-
metry assumptions at an ontological discount: “symmetria est vox”

334
Symmetry and Complexity
(symmetry is sound [of a word, symbol or formula]), one might add
a characterization of nominalism (from Latin “nomen” for name) in
the Middle Ages.
Philosophically, the situation has not changed since the days of
the controversy about universals. Yet today the logical-mathematical
methods are sharper, the results of measurement more exact. For
that reason symmetry can be made mathematically precise as a
canonical universal (“invariance property”). This is a matter of au-
tomorphism groups, as we have seen from many examples in this
book.
After that, however, the philosophical discussion begins again.
Is this structural species a separate immaterial identity “before [all]
things” as is assumed in Platonic tradition?
Is it a structure of
reality (“in things”), which we must presuppose in order to be able
to speak mathematically about symmetry in nature? Should we use
Occam’s razor to cut oﬀthe superﬂuous Platonic creation of entities
and conﬁne ourselves to introducing mathematical structures only as
useful and simple instruments for mastering nature?
Now physicists do establish relationships between empirical mea-
sured data (for instance time and position coordinates) by means
of transformations. Consequently the following objection was soon
raised to traditional nominalism which claimed only concrete mea-
surements and observations as statements about reality: individual
measured values cannot be thought of without presupposing a “gen-
eral” one, namely their relationship to other measured values. From
the standpoint of mathematics this objection views what is assumed
to be “general” as a mathematical function or relation. In quantum
mechanics the situation is even more complicated. There the mea-
sured quantities (“observables”) are already abstract mathematical
objects, namely operators over a Hilbert space (thus a function space
and not a number space).
What is the origin of mathematical structures? Structures are fa-
miliar to us from everyday life. In perception we register a ﬁgure as a
totality. In geometry we decompose it into a set of points; for exam-
ple, we distinguish straight lines and curves as subsets of the whole
point set and particular sections, angles, parallels, etc., as relations

Symmetry and Complexity in Philosophy and Arts
335
between these objects, by establishing their characteristics in axioms
and deﬁnitions. Such a system of sets, subsets and relations is a sim-
ple example of a structure. A population of living organisms can also
be grasped as a structure that is determined by a relational system
of kinship relationships, functional tasks, etc. Likewise an ecosystem
such as a forest consists of a system of organisms and populations
that are structured by a complicated network of relations such as
food chains. As we have seen, a molecule or a crystal is described by
a structure that consists of a set of elements (atoms) among which
relations of sequence, spacing, etc. are deﬁned. Diﬀerent objects can
be examples of the same structure, as is demonstrated by the group
structure of molecules.
Thus structures provide the possibility of
classifying the complex variety of appearances into units and wholes
and of making them easy to overview.
In the logical set-theoretical language of modern mathematics
there is, in principle at least, no diﬃculty in deﬁning and classi-
fying structures. On the basis of an axiomatic set theory (for exam-
ple, according to Zermelo–Fraenkel = ZF), structures are introduced
through sets or systems of sets and relations are deﬁned for their
elements [8.3]. Relations are themselves sets of ordered pairs or gen-
eral n-tuples of the basic elements.
Thus the 2-tupel relationship
“being married” consists of the set of all couples in the assumed set
of persons who are married to each other.
Likewise the 3-tupel group relationship consists of a set of ordered
triples of elements that fulﬁll the axiomatically deﬁned group charac-
teristics. As has been shown, we can imagine these elements as being
actualized in completely diﬀerent ways, for example, as two rotations
in space that are carried out in succession and that together result
in a third rotation, but also, for example, as two numbers that are
added and provide the result of addition as the third number.
On the basis of an axiomatic set theory (e.g. ZF), mathematics
as a whole can be understood as the theory of abstract structures.
The basic set-theoretical relation x ∈X denotes that an element x
is element of a set X. Mathematical theories are concerned with the
various kinds of structures that are introduced in set theory and can
be classiﬁed in a coherent manner. That is related to the fact that set

336
Symmetry and Complexity
theory, together with a standard logic, also postulates strong non-
logical axioms about sets, for instance, that for every set X there
exists also the power set Pot(X) as the set of all subsets of X and
that there are inﬁnitely many sets. For a set X the Cartesian product
X2 = X × X can be deﬁned as the set of all pairs of elements of X
(in general the set Xn as the set of all n-tuples of elements of X).
In general a structure is a ﬁnite system of sets whose type and
their species are determined axiomatically. Thus a group (G, g) is
a structure with a basis set G (e.g. real numbers) and a 3-tupel
relation g on G, with the typiﬁcation g ∈Pot(X3).
(If g is an
element of the set of all subsets of X3, then it is by deﬁnition a 3-
tupel relation.) The structural species is deﬁned by the group axiom
α(G, g) according to which, for example, the operation on G deﬁned
by g fulﬁlls the axiom of the inverse element [8.4]. A set fulﬁlling
the conditions of a certain structure (e.g. real numbers of a group)
is called a model of the structure.
What seems so abstract at a ﬁrst glance provides us with a deci-
sive advantage for the theory of science. Namely, we obtain a single
linguistic framework for formulating with logical precision the enor-
mous multiplicity of all thinkable structures, theories, models, and
their dependencies. This makes available a coherent framework of all
mathematized theories. If it is also possible to connect these struc-
tures by means of appropriate mapping principles with experiments
and measurements, then even a general framework of the empirical
sciences would be at hand.
At ﬁrst this program in philosophy of science seems to recall log-
ical empirism. In the view of logical empiricists like R. Carnap, a
scientiﬁc theory is a set of sentences, deﬁned as the class of logical
consequences of a smaller set, the axioms, laws or hypotheses of that
theory, which are assumed to be true. Thus, a language of formal
logic is needed to formulate a theory [8.5]. Actually, mathematicians,
natural and social scientists are not interested in their language, but
in the speciﬁc objects, structures and models of their theories. In or-
der to present a theory of a speciﬁc symmetry, we deﬁne the mathe-
matical structure of the symmetry and analyze the class of its models
in, for example, physics, chemistry, biology, or social sciences with an

Symmetry and Complexity in Philosophy and Arts
337
informal natural language [8.6]. In short: a scientiﬁc theory is iden-
tiﬁed with its structure or class of models. Therefore, this approach
is called structuralism or semantic view [8.7].
As an example, consider Newton’s theory of gravitation. Its basic sets are
a set T of points of Newton’s absolute time, a set M of points of Newton’s ab-
solute space and a set P of bodies. These sets are each individually structured
by time metrics and space metrics or functions of masses. In kinematics a con-
nection between points of time, space points, and bodies is produced in such a
way that at a speciﬁc time a speciﬁc body assumes a speciﬁc location. There-
fore, kinematics can be typiﬁed as the structural element kin ∈Pot(T × M × P).
Its structural species is determined by the dynamic law of Newton’s theory of
gravitation, the equations of gravitation. The gravitational equations constitute
a system of diﬀerential equations for real functions, i.e. the motions of bodies
in space and time are mapped onto coordinate systems in real numbers. The
place of physical structure is taken by an isomorphic structure of number sets in
which the physical relationships are mapped. Therefore the corresponding axiom
α(T, M, P;. . . kin. . . ) about the structural species would express that there is a
real coordinate system f in which the basis sets T of time, M of space, P of the
set of solids, and the structure elements such as kin are mapped and the corre-
sponding diﬀerential equations with secondary conditions hold. Obviously this
type of structure diﬀers from group structure only in its greater complexity [8.8].
In order to classify structures by features of symmetry, we subdi-
vide structures (X, s) into basic sets X (abbreviation for X1, . . . , Xn)
and stuctural elements s (abbreviation for s1, . . . , sm). The struc-
tural type s ∈σ(X) is established by a ladder set on X, i.e. a set
that comes from X by iteration of the operation power set of a Carte-
sian product. The structural species of (X, s) is established by an
axiom α(X, s), which determines the structure uniquely with respect
to an isomorphism: if (X, s) is isomorphic to (X′, s′), then α(X, s)
and α(X′, s′) are logically equivalent. This requirement imposed on
the structural species says that the axiom α does not change its truth
value if one replaces the structure (X, s) with an arbitrary structure
(X′, s′) that is isomorphic to it. Isomorphisms deﬁne an equivalence
relation.
Thus, the class of structures is divided into equivalence
classes with respect to isomorphisms.
For example, the group axioms are valid for the rotations of an
equilateral triangle as well as for the real numbers. The axioms of the

338
Symmetry and Complexity
Newtonian theory of gravitation are valid for artiﬁcial satellite orbits
as well as for planetary orbits of the solar system. Isomorphisms are
one-to-one (“bijective”) mappings of the basis sets X onto the basis
sets X′, whereby the typiﬁed set s is mapped onto the corresponding
set s′. The typiﬁcation in that case remains unchanged by this, since
the corresponding copy is given by the ladder set σ(X).
Obviously, the general deﬁnition of a structure with respect to
isomorphisms implies an invariance postulate, which we shall char-
acterize in the following as the canonical invariance of a structure.
It can be shown in detail that the various symmetry characteristics
that we elucidated in previous chapters, using examples from natu-
ral and social science, can be generally derived from the canonical
invariance of a structure.
On that subject, let us remember F. Klein’s characterization of geometry
by means of group theory.
Let M be the space of the geometry in question
and G a transformation group of the real number space Rn. Then (M, F) is a
structure with a typiﬁed set F ∈Pot2(M × Rn) of cooordinate systems and the
structural species αG(M, F) wherein the axiom αG formulates that F is a set
of global coordinate systems of M over Rn that is complete with respect to G.
The canonical invariance can easily be proven. Now one can set up a hierarchy
of transformation groups of Rn and investigate the corresponding geometrical
structures.
Many physical theories can be introduced as an extension of ge-
ometric structures. Thus the Poisson–Newtonian theory of gravita-
tion is an extension of Euclidean geometry, in which a gravitational
ﬁeld and a mass density which satisfy the Poisson–Newtonian grav-
itational equation are added to space and its Euclidean coordinate
systems. Likewise relativistic ﬁeld theory can be considered as an
extension of Minkowski geometry. In each case the extensions are
achieved by the speciﬁcation of supplemental structural types and
axioms for structural species. For example, planetary orbits or el-
ementary particles appear as new structural types in the examples
mentioned. The canonical invariance of the extended structure must
be guaranteed.
Analogously, quantum mechanics can also be introduced by means
of stepwise structural extensions in which the Schr¨odinger equation

Symmetry and Complexity in Philosophy and Arts
339
is only the ﬁnal step. For that purpose one begins with an Abelian
group G with an addition which is expanded into a complex vec-
tor space by adding a scalar multiplication.
Introducing a metric
turns it into a Hilbert space. Next comes a self-adjoint linear oper-
ator ˆH (“Hamiltonian”) over the Hilbert space and the ψ-functions
(“states”) with ψ : R →G, which satisfy the Schr¨odinger equation.
The structural species introduced in this way is canonically invariant.
The familiar invariance of the Schr¨odinger equation with respect to
the unitary transformation U with ψ′(t) = Uψ(t) and ˆH′ = U ˆHU−1
is a special case of it.
Symmetries are examples of invariant structures with respect to
automorphism groups. They are one-to-one functions mapping struc-
tures onto their own domain and leaving all relevant structure intact.
In the sense of canonical invariance, automorphisms deﬁne equiva-
lence relations dividing structures and their models into equivalence
classes of partitions with the same symmetric structure. In the pre-
vious chapters we analyzed several structures of symmetry with dif-
ferent models in science, which are collected in Fig. 98: we started
with the (assumed) structure of a supersymmetry with models of
strings and p-branes which until now is only sketched in M-theory
and not yet completely known.
The theory of relativity is char-
acterized by space-time symmetries with models of manifolds and
trajectories of photons and gravitons. Conservation laws are conse-
quences of space-time symmetries. Quantum ﬁeld theories provide
dynamical gauge symmetries (e.g. electroweak SU(2)×U(1)-force) as
substructures of the uniﬁed supersymmetry with models of diﬀerent
elementary particles. Therefore, in a bottom up resp. top down ap-
proach of Fig. 98, we get symmetry reduction resp. symmetry break-
ing. Chemistry is characterized by structures of symmetry with mod-
els of atoms, molecules and crystals. In biochemistry, at the board-
erline of life, we found typical structures of asymmetry with models
of DNA. In thermodynamics, the emergence of symmetric patterns
by phase transitions and symmetry breaking provides models of sym-
metric structures. Structures of functional symmetries characterize
models of organisms in biology. Ecological, economic and social bal-
ance deliver models of symmetry in ecology, economics and sociology.

340
Symmetry and Complexity
models
symmetries
theories
string theories
theory of relativity
quantum field theories
chemistry
biochemistry
thermodynamics
biology
ecology
economics
sociology
strings, -branes
gravitons, photons
hadrons, leptons, etc.
atoms, molecules, etc.
proteins, DNA, etc.
open systems with
metabolism
organisms
populations
economies, markets
societies
p
supersymmetry
space-time symmetries
dynamical symmetries
(e.g., SU(3)xSU(2)xU(1)-forces)
nuclear-, orbital-, crystal symmetries
chirality
dissipative structures of symmetry
functional symmetries
ecological balance
economic balance, economic
equilibrium
social balance, social equilibrium
theory reduction
symmetry breaking
Fig. 98.
Theories and models of symmetries in science
But, symmetry breaking of balance is also a characteristic struc-
tural process in these disciplines. In a bottom up approach, Fig. 98
seems to suggest a theory reduction of the social and biological sci-
ences to physics. But, that is only true in the sense that the emer-
gence of social, biological, and physical structures is embedded in
cosmic evolution which started with a supersymmetry, according to
M-symmetry.
Canonical invariance and symmetries of structures do not only
help to classify scientiﬁc theories, but they also support problem solv-
ing in science and situations of the everyday world. If two situations
are isomorphic with respect to their essential features and if we were
successful in one of these situations with a certain strategy, then we
should apply this strategy in the other situation again. Isolating the
relevant structures is equivalent to deﬁning the set of transformations
that leave the problem essentially the same. These transformations
are the symmetries of the problem. Therefore, problems which are
essentially the same must have essentially the same solution. In this
sense, symmetry is a successful principle of methodology.
With specialization of science, theories depend on one another in
a network of increasing complexity. The belief of logical empirism
that isolated theories are tested by “naked” facts of reality becomes
an illusion. There is no absolute empirical basis with sensory and
measured data, propositions of protocol in a language of observa-
tion which would be linked to the theory by rules of correspon-

Symmetry and Complexity in Philosophy and Arts
341
dence. Measurements and observations already depend on theoretical
assumptions. The domain of reality and the rules of application of
a mathematical theory generally depend on the theory itself. The
part of a domain of reality that is independent of the concerning
theory and its rules of application is called the basic domain of the
theory. However, this basic domain is not independent of all science
and experience.
For example, current does not belong to the basic domain of elec-
trodynamics, since it was ﬁrst deﬁned in this theory. But mechanical
forces are introduced in mechanics and belong in the basic domain
of electrodynamics. For that reason mechanics is called a pre-theory
of electrodynamics [8.9]. For the Newtonian theory of gravitation
the orbit of a satellite belongs to the basic domain. It can be deter-
mined by a pre-theory that includes geometrical optics and terres-
trial geometry and is independent of gravitational theory. Therefore,
a pre-history is pre-given a priori relative to its theory. In this sense
it is the task of philosophy of science to reconstruct the network of
relative dependencies of theories. As all theories depend more or less
on one another, the whole network of knowledge is always faced with
reality.
We have to decide on the restrictions and constraints for
concrete observations, tests and experiments.
If a mathematical theory is applied to a domain of reality, then
mathematical models are mapped on data of measurements. An ex-
ample is the results of measurement of planetary orbits according to
which a planet is at a particular location at a particular time. Fac-
tual samples of measurement data provide data models which are
mapped on the mathematical model of an elliptic curve. The ellip-
tic model of planets belongs to the Newtonian theory of gravitation.
A theory is conﬁrmed if those real systems like the planets belong
to the class of models of the theory. Even in Newtonian time, the
theory of gravitation contained a well-known class of real models
like the planetary system, high tide and low tide of the ocean, and
Galileo’s free fall of bodies on earth. But, the mathematical struc-
ture of a theory obviously contains many more models than possible
worlds. Thus, theory construction should be done from two points
of view: the construction of suﬃciently rich models to allow for the

342
Symmetry and Complexity
possibility of described phenomena, and the narrowing down of the
system of models so as to give the theory greater empirical content.
In theory constructing, there must be a steady interplay between the
theoreticians and experimenters.
A structural analysis reveals the conditions under which one the-
ory provides more information than another about a domain of re-
ality, and thereby also more solutions to problems. These criteria
do not depend upon whether a research group ﬁnds a theoretical
development to be “better” or “worse”.
Rather it is a matter of
exactly deﬁning when a structure and the theory characterizing it,
is more information-rich and more comprehensive than another one.
In scientiﬁc practice a case can deﬁnitely occur in which one chooses
the theory that is structurally poorer because under certain research
constraints it provides adequate and fast problem solutions.
A structure is called richer than another if both structures possess
the same basic set and the same typiﬁcation, but the axioms of the
richer structural species include those of the poorer structural species
[8.10]. A mathematical example is the transition from an ordered set
to a lattice structure. Both have the same underlying basic set and
order relation as their structural type. The structural species of the
lattice structure requires more axioms for this structural type than
the usual axioms of order.
A structure is more comprehensive than another if, in addition,
new basic sets, structural types and structural species are added to it.
An example of that is the above-mentioned step-by-step development
of quantum mechanics, which ﬁnally extends from an Abelian group
over Hilbert spaces to the self-adjoint operators of the Schr¨odinger
equation.
Correspondingly, one theory is called richer in structure than an-
other if the ﬁrst is determined by a richer structure than the other,
but both have the same principal basic domain and the same mapping
instructions for the application of the mathematical theory. Thus,
the more structurally rich theory makes it possible to make more
statements and thereby to provide more information about the same
facts than the other theory does. The structurally richer theory is
therefore a special case of a more comprehensive theory.

Symmetry and Complexity in Philosophy and Arts
343
Further operations known from mathematical structural analysis
can be carried over without modiﬁcation. Thus, one speaks of one
structure being “embedded” in another one by means of correspond-
ing mappings. In the same way one structure can be “restricted”
to another one by means of corresponding rules. Two theories are
called equivalent if they refer to the same principal basic domain and
if both can be called reciprocally more comprehensive.
Examples from the history of science are at hand.
Thus, the
transition from the Newtonian space-time theory to Einstein’s is ob-
viously a transition from a less comprehensive theory to a more com-
prehensive theory. Sometimes the assumption of absolute simultane-
ity in Newtonian space-time and its negation in Minkowski geometry
is depicted as an unbridgeable contradiction that evokes the impres-
sion of erratic theoretical progress. But, from the point of view of
a mathematical structural analysis, this is misleading. In fact, New-
tonian space-time is not false (from the point of view of Minkowski
geometry). Einstein’s theory, namely, can be restricted to a space-
time theory with inertial systems that move slowly, compared with
the speed of light, with respect to the Newtonian inertial system of
the planetary system. Moreover, these subsets of inertial systems
are not, in any case, spread out over too much of the cosmos. Thus
restricted, Einstein’s space-time theory can now be embedded in the
Newtonian theory. Besides, there is at least an approximate region
of absolute simultaneity in which the sun does not move, or moves
only very slowly.
The fact that one theory structure is richer or even more compre-
hensive than another one thus proves to be an objective relationship
between theories that is precisely deﬁneable in logical-mathematical
terms. Such a theoretical transition is therefore just as cumulative
in natural science (such as physics) as in mathematics, as far as in-
crease in complexity, information content and capacity for problem
solving are concerned.
Thus, one can talk about “upheaval” and
“revolution” in psychological, sociological and ideological contexts
only where such structural expansions have historically taken place.
This applies to the Copernican change as well as to the histori-
cal, philosophical discussion that has been going on since Einstein’s

344
Symmetry and Complexity
introduction of the relativity theory in the twenties of the last cen-
tury. Indeed, after the First World War many people felt that Ein-
stein’s relativistic revision of the Newtonian conception of space-time
was the collapse of an old world that had had absolute standards:
“everything is relative” was a popular slogan in an era of disintegrat-
ing values and may have furnished the ideology for a greater accep-
tance of Einstein’s theory by some people or increased reservations
and rejection by others. Even today “postmodern” philosophers de-
mand “relativism” and “destruction” of scientiﬁc objectivity [8.11].
But again, that is a psychological expression of critical feelings in an
era of sceptical attitudes against scientiﬁc and technological progress.
“Postmodern relativism” does not contradict the structural analysis
of mathematical and mathematized theories [8.12].
However, the examples also show that a more comprehensive the-
ory is not necessarily a better one. In many areas of technology —
such as automobiles — where we look at slow speeds compared to the
speed of light, we are working successfully using classical mechanics.
For other areas — such as high-energy — that is no longer true. A
uniﬁed theory of all physical forces promises spectacular insights into
the ultimate solutions of our problems of energy.
The analysis of theoretical structures seems to suggest a static
view of science. Therefore, a model of elements developing in time
(e.g. atoms, planets, people) is called a dynamical system [8.13].
But from a mathematical point of view, a dynamical system is, of
course, a model of a speciﬁc structure with parameters or operators
of time. A dynamical model consists of a multi-component set of
time-depending elements with local states. Their local interactions
determine a global state.
The structure of the dynamical models
is characterized by a common state space. Their dynamics, i.e. the
change of system’s states depending on time, are represented by lin-
ear or nonlinear diﬀerential equations. In the case of nonlinearity,
several feedback activities take place between the elements of the
system. These many-bodies problems correspond to nonlinear and
non-integrable equations with instabilities and sometimes chaos. The
emergence of new order and attractors of complex systems corre-
spond to solutions of these equations. Thus, emergence is no mys-

Symmetry and Complexity in Philosophy and Arts
345
tery, but can be explained by structural analysis. Nevertheless, the
emerging order cannot be reduced to the features of single elements
in a nonlinear dynamical model. Separation of a system into its parts
means mathematically linearization. The emergence of an attractor
of ﬂuid dynamics cannot be explained by the single molecules of the
ﬂuid. The life of an organism cannot be reduced to the sum of its
cells. The emergence of cognitive abilities cannot be explained by
the sum of neural cells in a brain. The famous slogan of philosophers
“The whole is more than the sum of its parts” is true with respect to
the nonlinearity of a dynamical system. In this book, we introduced
the principles of nonlinear dynamical systems. They belong to the
most general theoretical structures of human knowledge which can be
applied in models of physical, chemical, biological, neural, cognitive
and social dynamics. The mathematical structures of these models
do not depend on special, e.g., physical laws. Thus, we demand no
kind of physicalism, but structural analysis of dynamical models in
nature and society.
Another fundamental phenomenon of symmetry and symmetry
breaking can also be explained by structural analysis. On the mi-
crolevel, physical laws are symmetric with respect to time (microre-
versibility), but not at the macrolevel. According to the second law of
thermodynamics distributions of, for example, molecules develop on
the average with irreversibility. For example, elementary particles
are reversible with respect to time. Organisms, people, and social
groups become elder without a chance of reversibility. But from a
structural point of view, microreversibility and macro-irreversibility
are no contradiction. We have to distinguish between the reversible
“exterior” time of a complex dynamical system and its “interior”
time, or its “age”. While the “exterior time” is the usual real time
parameter t that is registered by a clock, the “interior time” is de-
ﬁned as an operator that takes into account the irreversible changes
in the system’s states. As a real parameter, the exterior time appears
merely as an index in a set of trajectories (in classical physics) or in
a wave equation (in quantum mechanics). As an operator, the inte-
rior time permits statements about the temporal development of a
complex ensemble of trajectories or distribution function that serve

346
Symmetry and Complexity
mathematically as eigenfunctions of the time operator.
The con-
nection with the external time rests on the eigenvalues of the time
operators being real lengths of time as registered by a normal clock.
The distribution is graphical representations of the diﬀerent interior
“ages” of a complex system [8.14]. For example, the diﬀerent organs
of a complex system like the human organism wear out at diﬀerent
rates. The time operator assigns a “mean age” to each state of the
system, which increases at the same rate as the exterior clock time.
Thus, “age” is a structural property of complex dynamical systems
and does not depend on special models of, for example, biological sys-
tems. For example, it is not only a metaphor to speak about “old”
and “young” cities, organizations or societies. The phase transition
in political systems may diﬀer according to the periods of election.
Each dynamical system has its own characteristic interior time.
From the viewpoint of the history of philosophy this is reminiscent
of Aristotle, who distinguished between time as “movement” (
and time as “coming into being, growth, and decay” 	
This
connection can be connected to the concepts of reversible time in me-
chanics and of irreversible time in thermodynamics. Irreversible pro-
cesses are explained according to the second law of thermodynamics
as internal breakings of symmetry (based on the time operator) that
violate time reversal symmetry. The time operator has the remark-
able property that the past and future are separated by an interval
that is quantiﬁable in terms of a characteristic time. Traditionally,
the present is represented as a point on the time axis in which past
and future can come inﬁnitely close. Prigogine therefore speaks of
the “duration” of the present, which he compares to the concept
of duration introduced by the French philosopher H. Bergson [8.15].
The time operator is, however, a mathematically deﬁned functional
operating on distribution functions and not on single elements. It
must not be confused with subjectively experienced time.
There is a precise relation between dynamical systems and com-
putational systems. The dynamics of nonlinear systems is given by
diﬀerential equations with continuous variables and a continuous pa-
rameter of time. Sometimes, diﬀerence equations with discrete time
points are suﬃcient. If even the continuous variables are replaced by

Symmetry and Complexity in Philosophy and Arts
347
discrete (e.g. binary) variables, we get functional schemes of compu-
tational systems (“automata”) with functional arguments as inputs
and functional values as outputs. Operators (e.g. time-operator of
interior time) can also be digitalized. The structural features of the
systems are represented in programs (“algorithms”). Their degrees
of computational complexity can be determined according to their
size (“algorithmic complexity”) or time length.
In Chapter 7, we
explained which degrees of computability can be distinguished and
why computational systems are not necessary computable. Like dy-
namical systems, they can develop all kinds of more or less com-
putable patterns and attractors of nonlinear dynamics. Degrees of
computability and decidability can even depend on procedures which
are unknown and therefore called “oracle”.
A so-called ψ-oracle
Turing machine uses the usual rules of a Turing program and an
operation ψ (e.g., “replace the content x of a register by ψ(x)”)
whose computability is unknown.
The operation generates values
(“answers”) like an oracle. Functions or functionals which are com-
putable by ψ-oracle Turing machines are called relatively computable
(with respect to the oracle ψ) [8.16]. Actually, many processes in the
world are modeled by tools which are computable or only assumed
without knowing their degree of computability.
In this sense, all
kinds of mathematical structures of dynamical models correspond
to degrees of at least relative computability. But they are not all
(Turing-)computable.
These arguments lead us to the fundamental principle of com-
putational equivalence: every dynamical system corresponds to a
computational system. If the world is considered a complex dynam-
ical system, then it can also be considered a computational system.
Quantum-, molecular-, nano-, DNA-, cellular-, neural-, and cogni-
tive computing are only special models of computational structures,
generating diﬀerent kinds of information. There are natural dynam-
ical systems (e.g. quantum-, molecular-, cellular-, neural systems),
which have been generated by cosmic and biological evolution. But
they are also only special models of general structures. Therefore, a
task of science and technology is to ﬁnd and to construct new mod-
els fulﬁlling the principles of computational systems. In this sense,

348
Symmetry and Complexity
a technical co-evolution was initiated and implemented by humans,
leading to systems with growing capabilities of artiﬁcial life and arti-
ﬁcial intelligence. Scientiﬁc knowledge consists of theories, structures
and models corresponding to computational systems. Thus, the ex-
pansion of science and growth of knowledge can be considered a part
of information dynamics in a world with increasing complexity.
A challenge of complexity is the knowledge representation of all
kinds of theories, structures, models, dynamical and computional
systems. Knowledge representation, which is today used in database
applications, artiﬁcial intelligence, software engineering and many
other disciplines of computer science, has deep roots in logic and phi-
losophy. In the beginning, there was Aristotle who developed logic
as a precise method for reasoning about knowledge. Syllogisms were
introduced as formal patterns for representing special ﬁgures of logi-
cal deductions. According to Aristotle, the subject of ontology is the
study of categories of things that exist or may exist in some domain.
Aristotle distinguished basic categories for classifying anything that
may be said or predicated about anything. Many of these categories
(e.g. substance, quality, quantity, relation, spatiality, and temporal-
ity) are today applied in, for example, data bases. In the Middle
Ages, knowledge representation was illustrated by graphic diagrams
and pictures. In Peter of Spain’s “summulae logicales” (1239), an
ontological hierarchy with Aristotelian categories represented knowl-
edge by genus (supertype) and species (subtype) [8.17]. The features
that distinguished diﬀerent species of the same genus were called
“diﬀerentiae”. R. Lullus (13th century) illustrated an ontological hi-
erarchy by a tree with branches for categories. Leaves corresponded
to questions or to answers which should automatically be found by a
system of rotating disks for combining features of things. Actually,
Lullus applied a kind of British Museum algorithm, the ﬁrst attempt
to develop mechanical aids for problem solving and information
retrieval.
There is a close correspondence between categories, theories and
structures of ontologies and hierarchies of types or classes in object-
oriented programming languages. An object-oriented programming
language (e.g. C++, Java) combines a declarative style for specify-

Symmetry and Complexity in Philosophy and Arts
349
ing objects with a procedural style for deﬁning the action by and
upon those objects [8.18].
Object-oriented declarations deﬁne the
same kind of information as frames or classes with certain attributes
which are instantiated as particular objects for speciﬁc data. For
example, the class or type of an automobile is characterized by cer-
tain attributes.
A particular car is a speciﬁc object of this class.
In this sense, a theory or structure can also be considered a class
of an object-oriented language. A model of a theory is a concrete
speciﬁcation which corresponds to an object of an object-oriented
language. Theories or structures with their models can be classiﬁed
in hierarchies like plants and animals in biological taxonomies. By
the way, Aristotle designed the ﬁrst botanic taxonomies in the his-
tory of biology. An ontology is organized in a class or type hierarchy
that supports inheritance of properties from supertypes to subtypes.
Fig. 99 shows the ontology of symmetries as mathematical structures
which have been analyzed in this book. Contrary to the traditional
belief of antique philosophers, ontology in the sense of informatics
only means the organization and representation of knowledge and is
not necessarily identical with the actual order of reality [8.19]. An-
other example is the ontology of complexity in Fig. 100, which was
explained in Chapter 7 and previous remarks on computational sys-
tems. Again, properties of supertypes are inherited to subtypes in
the following branches of the tree-like hierarchy.
Object-oriented programming languages have advantages with re-
spect to traditional declarative or procedural languages. Instead of
separating the declarations that deﬁne an object from the procedures
that operate on them, the object-oriented programming languages in-
tegrate the declarations and the methods for each type of object in
a single information packet. By encapsulating objects in this man-
ner, object-oriented programming languages provide a way of distin-
guishing the external behavior of objects from their internal structure
and dynamics. For example, a particular car is an object instance
of a class or type of automobiles with attributes (e.g. color, size,
weight) and methods determining the internal processes (e.g. motor
dynamics, electronic equipment). Furthermore, there may be rules
describing external behavior of cars in interaction with traﬃc lights,

350
Symmetry and Complexity
canonical invariance of structure
symmetry (= invariance
with respect to automorphism groups)
discrete symmetry
plane
symmetry
spatial
symmetry
PCT-
symmetry
ornamentic
symmetries
crystal
symmetries
parity
continuous symmetry
space-time
symmetries
gauge
symmetries
Galilean
invariance
(= classical
physics)
Lorentz
invariance
(= special
relativity)
covariance
(= general
relativity)
supersymmetry
(= M-theory)
U(1)xSU(2)xSU(3)-
symmetry
Poincaré
symmetry
(gravitation)
U(1)xSU(2)-
symmetry
SU(3)-
symmetry
(strong force)
U(1)-
symmetry
(electromagnetic force)
SU(2)-
symmetry
(weak force)
charge time
Fig. 99.
Ontology of symmetries
warehouses and dispatchers. Thus, each object instance is an au-
tonomous entity whose behavior is determined by its class methods
and the inputs it receives from other objects.
The advantages of encapsulation and inheritance in object-
oriented languages can also be applied to knowledge representation
of theories and structures. In the beginning of this chapter, we il-
lustrated the complex network of theories, structures and their mod-
els as a landscape of knowledge. This metaphor can now be made
precise in object-oriented programming languages. In order to rep-
resent the complex network of knowledge by diagrams, ontologies
of theories, structures and models are enlarged by Entity-Relation
(ER)-diagrams and semantic webs. A class is conceived as an en-
tity which is represented by a box (Fig. 101). The attributes and
methods of the class are written in ovals which are related to its box.
In ER-diagrams, the subordination of classes in ontologies is only a
special relationship. In semantic webs, there are further relations be-
tween entities indicated by edges and rhombuses between the boxes
(Fig. 101). Besides hierarchical relations of subordination (s), there

Symmetry and Complexity in Philosophy and Arts
351
complexity
dynamical complexity
fixed point
attractor
compressible
size
deterministic
computability
periodic
attractor
incompressible
size (=random)
non-deterministic
computability
quasi-periodic
attractor
NP-time
exponential time
polynomial time (P)
quadratic time
linear time
computational complexity
relative computability
Turing-compatibility
computational time
program size
(= algorithmic information)
chaos
attractor
randomness
Fig. 100.
Ontology of complexity
are relations of parts (p), instantiation (i) of objects from classes,
inheritance (h), etc. In Fig. 101, a small section of the knowledge
landscape is represented by a semantic web. A physical theory is
characterized as a class with only a few attributes (e.g. name, pa-
rameters, constants) and methods (e.g. operators, measuring meth-
ods). Models of theories (e.g. elementary particles with high speed
near the velocity of light as a model of the theory of special relativ-
ity) are considered object instances of classes [8.20]. For example,
conservation laws are parts of the theory of relativity.
ER-diagrams and semantic webs are illustrations of structures
and objects which are deﬁned in mathematical and natural lan-
guage. For implementation on computing systems, the axiomatic-
mathematical representation must be transformed into a computer
language. These steps of transformation from diagrams with nat-
ural language to mathematical and computational representations
are used in software-engineering.
They have great advantages for
programming complex structures and networks.
Axiomatic repre-
sentations allow us to control complex processes step by step with
mathematical proof methods. Correct programs must satisfy the ax-

352
Symmetry and Complexity
physical theory
Fig. 101.
Entity-Relationship (ER)-diagram of theories
iomatic conditions of the corresponding structures. Carnap’s idea
to represent scientiﬁc theories in formal languages is now realized in
informatics for all kinds of structures and objects. Leibniz’ old vi-
sion of computing systems for all tasks in everyday life is a challenge
of modern software-engineering. In software-engineering, the struc-
ture of, for example, a bank, ﬁrm, or traﬃc system is represented by
ER-diagrams, transformed to axiomatic deﬁnitions of relations and
functions, translated into an object-oriented programming language,
in order to implement the structure on a computer.
The formal implementation of structures on computers needs formal labels
and types, in order to identify all symbols and their meaning uniquely. The label
of a structure (e.g. a group) consists of a set T of notations for types, a set F
of notations for constants and functions, and a mapping relating each notation
from F to a type. The type of a constant c is a type M from T. “c has type M”
is denoted by c : M. The type of a function f : X1 × X2 × · · · × Xn →Xn+1
is denoted by the types of the arguments X1, X2, . . . , Xn and the values Xn+1,
i.e., f : M1, M2, . . . , Mn →Mn+1, with M1, M2, . . . , Mn+1 from T. The labels
can be enlarged for functionals with functions as arguments and values, too.
In a formal language, terms can be constructed with functions, constants, and

Symmetry and Complexity in Philosophy and Arts
353
variables. Variables and constants are terms of certain types. If f is a function
from F with type f : M1, M2, . . . , Mn →Mn+1 and t1, t2, . . . , tn are terms of type
M1, M2, . . . , Mn, then f(t1, t2, . . . , tn) is a term of type Mn+1. Terms are used to
construct equations. With equations and logical constants (e.g. ∧, ∨, ¬, →, ∀,
∃for “and,” “or,” “not,” “if-then,” all-, existence-quantiﬁer), we can construct
propositions to represent the axiomatic deﬁnitions of a structure. In Fig. 101,
the axiomatic deﬁnition of, for example, general relativity is given by Einstein’s
ﬁeld equation with certain preconditions. Models are speciﬁc interpretations of
the formal propositions of the axiomatic deﬁnitions. In, for example, the theory
of general relativity, the formal tensor of curvature is interpreted by a notation
representing the curvature of a light ray in the vicinity of the sun.
ER-diagrams and semantic webs seem only to illustrate static as-
pects of a structure. In complex dynamical systems, time-depending
processes and histories are described by phase transitions of states
with the emergence of new entities. Discrete processes can be sim-
ulated by digital computers, but continuous processes are more nat-
urally simulated by analog computers. Yet if the time step is small
enough, the granularity of a digital simulation might not be no-
ticeable. Movies and television, for instance, represent continuous
motion by a sequence of discrete frames. In software-engineering,
state-transition diagrams are used to illustrate all kinds of processes
which, after axiomatic deﬁnition of transition rules, must be trans-
lated into an object-oriented programming language in order to im-
plement them on a computer.
The structure of a dynamical sys-
tem is deﬁned by a state space S, a set of control parameters α,
and the axiomatic equation (e.g. diﬀerential equation) of a function
f. In a simpliﬁed form the axiom is represented by the equation
st+1 = f(α, st) with the input-state at time t, the output-state at
time t+1, a control parameter α and a certain condition of an initial
state so.
State-transition diagrams enlarge ER-diagrams and semantic
webs for illustrating dynamic processes. They represent states by
boxes and transitions between them by arrows. Fig. 102 is a state-
transition diagram of a phase transition (“symmetry breaking”) in
a complex dynamical system with the emergence of new order. The
transition rules are indicated at the transition arrows. The phase
transition is initialized by an initial state. The control parameter

354
Symmetry and Complexity
Fig. 102.
State-transition diagrams of phase transition (“symmetry breaking”)
with emergence of new entities (“self-organization”)
α is written in a rhomb with a feedback loop. If the transition is
below a critical value of α, the old order is stabilized. If it surpasses
the critical value, the old order is destabilized. Unstable and stable
modes of the system elements compete with one another in a compet-
itive state, depending on an order parameter. Unstable modes start
to dominate (“enslave”) stable ones, until a new macroscopic order
emerges according to the order parameter. An order parameter de-
termines the emergence of a new order. Therefore, it is indicated in
a rhomb of the state-transition system. The feedback loop describes
the causal connection between the microlevel and the macrolevel of a
complex system (e.g. Fig. 49). In the case of symmetry breaking, the
state-transition system generates a bifurcation tree (e.g. Fig. 48).
Again, the state-transition diagram can be transformed into a
mathematical representation of a complex dynamical system with
equations and logical deductions. The transition rules “initialize,”
“stabilize,” “destabilize,” “dominate,” and “emerge” correspond to
the steps of a linear-stability analysis (compare Sec. 3.3). The new
order is derived from the equations of microstates as solution of an
appropriate macroscopic equation depending on the order parame-
ter. The transition rules can also be translated into a programming
language to implement the system to a computer.

Symmetry and Complexity in Philosophy and Arts
355
State-transition diagrams are a common representation for
discrete (and approximately continuous) processes.
Finite-state
machines are the simplest and most widely used version of state-
transition diagrams.
Petri nets are a generalization of state-
transition diagrams for representing concurrent processes [8.21]. For
object-oriented design, Petri nets have been adopted as the basis for
activity diagrams in the Uniﬁed Modeling Language (UML). Petri
nets are especially convenient for representing cause and eﬀect: each
transition represents a possible event, the input states of a transition
represent the causes, and the output states represent the eﬀects. By
executing the Petri net interpretively, a computer can simulate the
processes and causal dependencies.
From a philosophical point of view, we get a pragmatic method-
ology of knowledge representation which is more than software engi-
neering. There is a broad variety of formal tools to represent data,
information, and knowledge for diﬀerent purposes and diﬀerent steps
of development. In the ﬁrst step, we can use diagram languages for il-
lustrations of complex networks with, for example, ER-diagrams, se-
mantic webs, state-transition diagrams or Petri nets. In our method-
ology of knowledge representation, there is no dogmatic distinction
of any method or language.
They are tools with advantages and
disadvantages in diﬀerent contexts of application which should be
correlated in a kind of patchwork to get a ﬂexible methodology of
problem solving.
For example, ER-diagrams focus on the entities
and their relations in a domain. Ontologies only represent hierarchi-
cal levels. State-transition diagrams underline the dynamic point of
systems. In the next step, diagrams are axiomatically described as
structures and dynamical systems in mathematical language. They
can be transformed into programming languages in order to imple-
ment the structures and systems on a computer. Translations into
formal predicative logic are used to check the correctness of computer
programs by formal proofs.
Representations of complex knowledge need experts from diﬀerent
disciplines. Therefore, in requirements engineering of informatics, in-
terdisciplinary teams consist of experts of informatics and the domain
of application, as well as experts of cognitive science, economics and

356
Symmetry and Complexity
management, in order to get a useful product of knowledge repre-
sentation. They start with the identiﬁcation and limitation of their
issue. From diﬀerent points of view, they correlate diﬀerent tools
of analysis, harmonize diﬀerent interests pragmatically and develop
a common plan of modeling their issue. According to a catalogue
of criteria, their results of modeling and representation are evalu-
ated and veriﬁed. Analogously, in the philosophy of science, we need
interdisciplinary teams to analyze the growth of knowledge and to
explore the complex landscape of scientiﬁc theories, structures, and
models.
Obviously, the chosen tools of representation inﬂuence our view of
a problem, structure or system. But, on the other hand, structural
properties are invariant with respect to particular representations of
knowledge. Especially, symmetry and complexity are invariant uni-
versals of knowledge which are conﬁrmed in diﬀerent contexts and
models.
Nevertheless, the old question of philosophy arises as to
whether these principles are only abstract classiﬁcations of knowl-
edge or real structures of the world. In modern epistemology after
Kant, the question for reality seems to be beyond the limitations
of human experience. Our knowledge of the world depends on the
conditions of human experience. Even our sensory data, as immedi-
ate signals of the world, are represented in data models of knowledge.
Knowledge processing is generated by the dynamics of human brains.
Our models of the world are constructions of the human mind as cog-
nitive states of the brain.
But we must not forget that the validity of mathematical struc-
tures and proofs is independent of brain research and cognitive sci-
ence, although it is generated by brain dynamics. A neural or cogni-
tive scientist who can explain brain and cognitive dynamics of math-
ematical thinking is not able to ﬁnd a mathematical proof. Euclid
proved his theorems without being aware of his brain activity. The
same is true for music and arts.
In short: brain research cannot
replace, for example, mathematicians or artists.
The theorem of
Pythagoras is mathematically true in all models of Euclidean geom-
etry, independent of possible applications. Some Euclidean models
were even veriﬁed with antique measurements and technical con-

Symmetry and Complexity in Philosophy and Arts
357
structions and conﬁrmed Euclidean geometry empirically.
In this
sense, symmetry and complexity are invariant properties of mathe-
matical structures containing models of reality. In the case of com-
prehensive and general theories like quantum mechanics, evolution-
ary dynamics, or sociodynamics, single models may be less convinc-
ing. But embedded in general structures with diﬀerent models of
application and conﬁrmation, the degree of conﬁrmation increases.
Veriﬁed models connect the network of knowledge with reality. It is
always the whole network of our knowledge which is confronted with
experience.
In general, structures of scientiﬁc theories are containers of infor-
mation with actual and potential models of the world. Actual models
are conﬁrmed by observations and measurements. Potential models
satisfy the structural conditions of a theory, but they are not yet
realized in nature or society [8.22]. For example, the ﬂight of a bird
as well as the ﬂight of an aeroplane satisfy the laws of aerodynamics,
but only the ﬂight of birds was an actual model of the laws which was
realized by nature. The model of a jet was potential, as long as it
was not invented by human technology. In Chapter 5, we emphasized
that the biological evolution of life on earth was only one possible ac-
tualization of evolutionary laws. In Chapter 6, we discussed actual
and possible developments of sociodynamics. In this sense, struc-
tures of theories may contain more information than is actualized in
the world. One may argue that the information of structures and
models is generated in our brains. That is obviously right. There-
fore, structures of our theories are not static and may change with
new experiences. But the whole network of our present knowledge
tells us that our brain is a product of cosmic and biological evolution.
In short: the universe is elder than the human cognition of it. The
information production of our brain is embedded in the information
dynamics of the universe. Our concepts of symmetry and complexity
are traces of its universals.
8.2
The Beauty of Symmetry and Complexity
In Platonic tradition, symmetry was a universal law for truth, justice,
and beauty in the world. The last chapter considers the evolution

358
Symmetry and Complexity
from symmetry to complexity from an aesthetical point of view. Our
thesis is that art is another kind of representation with relation to
scientiﬁc views even in modern times. In many early cultures, as with
Greek philosophy, Taoism or Hinduism, nature was interpreted as a
harmonious organism whose parts and movements are proportion-
ately matched to each other. The human life-world with its familiar
living beings and cyclical natural events became the measure of, and
the model for interpreting, the strange and unknown world. This in-
terpretation of the world applies, not only to the Antique-Medieval
philosophy of nature, but also to early art. Proportional relationships
of the human body are found in the architecture of those times and,
correspondingly, in the dimensional relationships that were assumed
for the cosmos. What came into play here seems to have been an
early, intuitive kind of human knowledge, not at all based on a highly
developed geometry and astronomy like those of the Egyptians and
Greeks.
An example is the Golden Section which is even applied in early
cultures without mathematical geometry.
Thorough psychological
investigations have been made into the harmonious eﬀect of the
Golden Section.
Various factors play a role here: along with in-
tuitively familiar proportional ratios of the human body, probably
also the perception that in the Golden Section two parts of diﬀerent
sizes form a unity; the smaller part is related to the larger one as
the larger one is to the whole, and thereby the unequal parts are
harmonized in the whole. Thus, we ﬁnd this proportional relation
in objects of everyday use, in architectural monuments and on to
contemporary standard sizes [8.23].
Various authors discern the Golden Section not only in the Clas-
sical Greek and Egyptian vases, but also in Chinese pottery or prod-
ucts of the Cretan and Mycenaean culture from the end of the Bronze
Age, thus ca. a thousand years before Greek mathematics. It is con-
jectured that the Golden Section is present in the pyramid of Cheops
and in Aztec examples. But the situation of the historical sources
is obscure and is evaluated in thoroughly divergent ways [8.24]. The
Greeks were the ﬁrst to try to provide a mathematical basis, a geo-
metrical doctrine of proportions, for the intuitive ideas of prehistory,

Symmetry and Complexity in Philosophy and Arts
359
for familiar proportions of the life-world in art, architecture, technol-
ogy, and for the interpretation of nature. The Greek architect Hip-
podemos, a contemporary of Anaximander, drew up plans for Greek
metropolises of his time, in which streets were laid out crossing at
right angles along the compass directions, in the service of better ori-
entation and hygiene. That did please politicians like Pericles. But,
then as now, cold architectural rationalism provoked the scorn and
the anger of citizens who were aﬀected by it, and therefore Aristo-
phanes too, in one of his comedies has the famous architect appear
armed with a compass and a ruler to lay out cities mathematically
[8.25].
A canon of proportions for the visual arts was ﬁrst mentioned by
Polykletus [8.26], who, however, presumably had Egyptian predeces-
sors. He created his famous spear-bearer (Doryphoros) in accordance
with this canon of proportions. The historical sources and references
have come down only fragmentarily and through interpretations into
later centuries. Presumably Polykletus derived his proportions from
his studies of nature and then reworked them into an idealized form.
Thus he was not trying to project into his statues presupposed cos-
mological or philosophically interpreted proportions as, for instance,
the Golden Section. Likewise, symmetry is understood as “balance,”
thus proportional relationships adjusted to each other that evoke
the impression of harmony. Greek philosophers and mathematicians
shared the belief in a well-ordered world that could be expressed in
proportions and harmonies.
Later, Vitruvius named nine additional artists who were said to
have authored the “praecepta symmetriarum”. In all variations of
these early authors, Vitruvius’ core idea provides the standard: he
began his ten books about architecture (25 B.C.) by recommending
that temples be built analogously to human anatomy, which, in his
view, possesses a perfect harmony of its parts [8.27]. As a physician
in the 2nd century A.D., Galenus observed about symmetry “that
health depends on the symmetry of the elements and beauty depends
on the symmetry of the limbs . . . as is written in the canon of Poly-
cleteus”. An understanding of art was delineated here in which man
was literally the measure of all things. In the Platonic tradition the

360
Symmetry and Complexity
Logos of nature was based on a geometric doctrine of proportions.
Certain proportional relationships were singled out as particularly
“compatible to the measure of man.” They were supposed to recur
in art objects, everyday objects and buildings in order to make them
compatible to the measure of man.
From this point of view the frequently discussed question of
whether the Golden Section is “really” a natural law of human pro-
portions, is secondary. Modern statistical studies do lead to conclu-
sions about such laws of proportion in the growth patterns of humans,
animals, and plants. But it will not have escaped the Greeks either,
that aesthetic and erotic charm frequently originates from the small
“symmetry breakings”. Of course, standards have to be presupposed
if such deviations are to be experienced as attractive tensions.
As an example, consider the Aphrodite of Cyrene, which was
celebrated for its perfected harmonious proportions in later epochs as
well. Fig. 103 displays Golden Sections, for example, for the knee and
the breast, the navel and the vulva, or the breast and the neck. Here
the historical question of whether the Antique artist was consciously
patterning his work on the Golden Section is not relevant. Even if
we, today, project these or other proportions onto Antique statues,
their charm inheres precisely in the slight deviations from whatever
the norms of proportion were, that is, in the symmetry breakings.
The posture of the Aphrodite deviates from narrow standards, by
contrast with rigid archaic statues. Thus, the right breast exhibits
a changed proportion to the navel, and likewise the vulva and the
right knee. In an overarching integrated frame of reference, however,
such local deviations are incorporated, and are superimposed on one
another into a perfect overall impression that was brought forth again
and again.
The attraction we feel to the beauty of actual living women is
not based merely on their being made of ﬂesh and blood. Here too
the small deviations and symmetry breakings, in comparison with
idealizing concepts of proportion, play no inconsequential role. The
boredom induced by many modern “beauty queens” and pin-up girls
with their “ideal” measurements, may be evidence of that. Symme-
try breakings are needed to create individuality and — if you like

Symmetry and Complexity in Philosophy and Arts
361
Fig. 103.
Golden sections of the Aphrodite of Cyrene
— “personality.”
Yet this charm of the particular is felt in real-
ity only because it is viewed in reference to standard proportional
relationships.
Natural, proportional relationships may have the character of laws
of nature, and in this sense they may be immutable. But if such
proportions are elevated to norms in a canon of art, then, like all
aesthetic categories, they are subject to historic changes and can at
any time be felt to be restrictive and obsolete, or be rediscovered.
This was the fate of the Greco-Roman conception of art. However,
in judging it one should not cling to the entranced idealizations that
later centuries linked with this conception of art. What is funda-
mental is not the “letter” of the Greek canon of art, but its “spirit”.
What was decisive was the idea of carrying over into art and architec-

362
Symmetry and Complexity
ture standards of proportion drawn from the measure of man, that
is, organic ones, and not doing it subjectively, arbitrarily, but in the
framework of a shared understanding of nature.
For example, Vitruvius recommended that the length of a temple
should correspond to twice the width and that the proportions of
the open entrance hall (pronaos) and the closed interior space (cella)
should amount to 3:4:5 (the depth of the entrance hall being 3, its
breadth 4, and the depth of the interior hall 5). In this way one
derives musical harmonies such as the octave, 1:2, fourth, 3:4, and
ﬁfth, 3:5, which in the Pythagorean conception are determinative for
the cosmos [8.28]. Along with proportional relations drawn from the
measure of man, however, standards for size that have that basis are
also of interest. We in the 21st century A.D. are especially aware
of that, having experienced how megalomaniac dictators and cynical
ideologies consciously apply the means of the “enormous” to oppress
the individual person by means of a brutal architecture, designed to
be imposing. The signiﬁcance of an architecture based on the mea-
sure of man is apparent today in the monotony and vacuity of many
tenement houses, justiﬁed by technical constraints of practicality and
economy.
The Greeks were not the only ones to have investigated the math-
ematical proportions that became the basis for the Antique–Medieval
concept of symmetry (although they were the ﬁrst to propose an ex-
act geometrical basis). The Hindu, Buddhist and Islamic cultures,
as well, had at their disposal not only highly developed mathemat-
ics, but also a canon of art consisting of geometrical proportions and
symmetries.
In Hindu thought, as in the Pythagorean tradition, number has
cosmic signiﬁcance and is considered to be a means of establishing a
reciprocal relation between the universe and man. A common deno-
tation of the temple “vimana” means that which is “well measured”
or “well proportioned”. The central symmetry of the Hindu temple
[8.29] is striking, with the image of the divinity at the center of the
sanctuary.
In Hinduism as well as in the Taoist or Stoic philoso-
phy of nature, ideas of energy waves and ﬁelds of force play a great
role. Thus, the radiation of energy from the center of the sanctu-

Symmetry and Complexity in Philosophy and Arts
363
ary decreases outwards in rings — in stepped walls and intermediate
courtyards. The degrees of eﬃcacy that are manifested as a result,
determine the hierarchy of variously placed images of the Gods, ris-
ing toward the center. The temporal cycles and repetitions of cosmic
ages also ﬁnd expression in the forms that are part of the temple,
in which, for example, motifs emerge repeatedly in varying sizes at
diﬀerent locations.
In Buddhist architecture there are centrally-symmetrical shrines
like the Borobudur-Stuba on Java, which consists of eight balustrades
ascending like steps, with bas-reliefs and shrines in niches and the
largest Buddha ﬁgure in the center, on the spire of a tower. This
structure symbolizes the diﬀerent stages of enlightenment. The ﬁve
lower terraces are square, the three upper ones are circular, and 3, 5
and 8 are numbers in the Fibonacci sequence. The Golden Section
and other harmonious proportions can be pointed out here just as
with Chinese and Japanese pagodas [8.30].
In Islamic architecture we encounter a culture with highly de-
veloped mathematics (especially algebra and number theory) that
stands on the shoulders of Alexandrian–Hellenistic and Indian tradi-
tions. Islamic ornamentation is so skillful and complex that we can
do justice to it only with respect to the modern algebraic concept of
symmetry. Islam, like Judaism, is a religion of law. This may have
provided a supplementary motivation for not depicting God in (for-
bidden) anthropomorphic statues, but instead in the mathematical
symmetry laws of nature.
In the architecture of the mosques [8.31] a mathematical com-
prehension of symmetry and the particularities of Islamic religion
underwent a symbiosis. Some typical ground plans of the space of
an Islamic mosque are represented in Fig. 104a–d. The ground plan
of the Arab buttressed hall (Fig. 104a) and the pillared mosque of
Asia Minor (Fig. 104b) have square grids without a particular center.
This is a clear expression of the pragmatic character of the mosque.
It is not a shrine in the Hindu or Buddhist sense, and not a house
of God in the Christian sense, in which it is assumed that God (a
personal God) is present. It is a gathering-place (dschami) and a
place of prayer or prostrating oneself (masdchid).

364
Symmetry and Complexity
(a)
(b)
(c)
(d)
Fig. 104a–d.
Symmetric ground plans of Islamic mosques
By contrast, the Persian four-iwan court mosque (Fig. 104c) and
the Osmanic central-dome mosque (Fig. 104d) are centrally symmet-
rical. Cosmological aspects are assimilated into the architecture, the
dome arching over the believers like the spherical dome of the sky.
From the ground plan on, there is complete equivalence of the axes
and compass directions — thus, isotropy.
The believers have ac-
cess from all sides. But, as is known, Islam makes provision for one
symmetry breaking, namely honoring the direction toward Mecca.
Islamic architecture has always had to strive for a compromise be-
tween its orientation toward Mecca and its preference for mathe-
matical symmetry. The pre-eminence of regular geometrical bodies
is striking here, especially that of the cube and the (hemi)sphere.
Again, the synthesis of the Hellenistic–Neoplatonic and the Islamic
tradition is clear: the cube is both the form of the Kaaba and a Pla-
tonic body. The Persian mosques, especially, appear on the basis of
their symmetrical forms and splendid mosaics as solidiﬁed crystalline
structures — absolute, immovable, and of unalterable beauty [8.32].
The Christian Middle Ages owe their knowledge of Aristotelian
philosophy to their encounter with the Islamic culture. The combi-
nation of Neoplatonic and Christian ideas comes to light already in
the Romanesque. Gothic can be mentioned here, as an expression
of Christian symmetry, since it manifests a new concept of unity
against the background of Aristotelian-Thomistic philosophy. The
Gothic cathedral is, like the Summa of Thomas Aquinas, a coherent
system which comprehends all levels of life and of the cosmic order of
this world and the next [8.33]. It is the architectural representation
of an eternal ontology from the universals in the top of the gothic

Symmetry and Complexity in Philosophy and Arts
365
tower to the basic stones of application. Here the problem of unity
in variety was central. Thus, the scholastics concerned themselves,
in the framework of this hierarchy of the world, with the founda-
tion of a harmoniously organized society in which, for example, the
conﬂicting interest of church (sacerdotium) and state (imperium) are
reconciled.
The arts were to mirror the proportional relationships of this co-
herent universe. According to the Platonic conception, the elements
of the universe were transmitted through the ﬁve regular bodies,
which were based on the equilateral and isosceles triangles and the
pentagon, as excellent forms of the elementary particles (compare
Sec. 1.1). If the divine architect employed these forms to construct
the universe, then they had to be used for the cathedrals as well, as
symbols of the universe. It is not surprising that in the Neoplatonic
tradition even the stability of buildings, that is, a physical matter,
was based on appropriate geometric forms. Thus, H. Parler, a Ger-
man adviser for the construction of the cathedral of Milan (1392)
recommended giving the ground plan the form of a square since a
structure ad quadratum is in accord with the laws of the cosmos,
which guarantee it an unshakeable cohesion [8.34].
The regular pentagon also yielded the Golden Section and was
occasionally used for the rosettes of the cathedrals (e.g. in the cathe-
dral of Amiens). This proportion frequently appears in churches of
the 12th and 13th century (e.g. Chartres) as an approximate num-
ber ratio, as in 5:8.
The number ratio 5:8 is at the same time a
musical harmony, namely the minor sixth. Augustine had already
characterized music and architecture as “sisters of number,” in the
Neoplatonic and Pythagorean tradition. One example of the use of
musical harmonies is the ground plan of a Cistercian church which
was found in the sketchbook of an architect of the 13th century [8.35].
The ﬁfth (2:3) determines the proportion of the width of the transept
to the total length; the octave (1:2), the proportion of the side aisle
to the middle aisle and of the length and breadth of the transept;
the fourth (3:4), the proportions of the choir; while the intersection
of the nave and transepts, as the liturgical midpoint of the church,
is based on the most perfect number ratio of unison (1:1). Rose win-

366
Symmetry and Complexity
Fig. 105.
Central symmetry of a rose window (cathedral of Chartres)
dows are typical attributes of gothic cathedrals. Fig. 105 shows a
drawing of the west rose window by Villar de Honnecourt from his
sketchbook. Its central symmetry with the peripheral wheel symme-
tries expresses the Gothic Medieval idea of unity as no other example
does [8.36].
It was not the Renaissance that ﬁrst dictated that “ars sine sci-
entia nihil est” (art without science is nothing). The great Medieval
architects did not depend on their predecessors’ experimentation
or rules of thumb and empirical formulas alone, but instead tried
to base their designs on mathematics and, indeed, on the philoso-
phy of nature. However, the theological substantiation of symmetry
faded into the background in the Renaissance. As the Antique sci-
entiﬁc authors became increasingly known, the classical texts of the
Antique art canon were studied again. In short, in the Renaissance,
symmetry was based again on the proportions of man and nature.
Thus, L.B. Alberti [8.37] argued in “De re aediﬁcatoria” (1485),
that beauty is a correspondence and cohesion of parts according to a
speciﬁc number, proportionality and order. He asserted that an art

Symmetry and Complexity in Philosophy and Arts
367
form that is designed in this way (concinnitas) is the absolute and
highest law of nature (absoluta primariaque ratio naturae). Alberti
also pointed to reﬂection symmetry as the natural law in the case of
humans and animals, and concluded that therefore it must be applied
in architecture.
But reﬂection symmetry is not a discovery of the Renaissance.
Villar de Honnecourt had used reﬂection symmetry economically in
his sketches. In one such case he carefully executed only one reﬂection
half of a building in his sketch of it.
In reﬂection symmetry, the
second half has the same forms and proportions; only the direction
is reversed.
Even Leonardo da Vinci was to use this economy of
drawing reﬂective symmetry in his architectural sketch books.
Many sources show that laws of reﬂection in architecture had to
be oriented to man and nature. Another example is G. Vasari, who
adopted his concept of symmetry (disegno) almost literally from Vit-
ruvius and then wrote: “. . . thus it is that it [the sketch] takes in the
proportion of the whole to its parts as well as the proportion of the
parts to each other and to the whole, not only in human and ani-
mal bodies, but also in plants, buildings, paintings and sculptures.”
[8.38]
The intentions of the Renaissance were crystallized in one person:
Leonardo. He embodies the universality of the Renaissance artist,
integrating the architect with the painter, engineer, inventor, nature
researcher and philosopher. In the Pythagorean tradition symmetry
spans all of these realms: “Proportion is to be found not only in
numbers and dimensions, but also in tones, weights, time intervals,
and positions as well as in every dynamic force that there is.” [8.39]
Moreover, his conception of the philosophy of nature was by no means
original, but remained inside the conﬁnes of Medieval–Aristotelian
and Neoplatonist–Pythagorean deliberations. Leonardo was not a
second Galileo. His accomplishments in architecture, painting and
engineering are works of genius — the ﬁnished works of art as well
as the sketches and visions [8.40].
One aspect of Leonardo’s architecture should be emphasized be-
cause it became signiﬁcant for the development of the concept of
symmetry: Leonardo emphasized central symmetry, and he system-

368
Symmetry and Complexity
atically worked out the possibilities of central structures such as
churches, castles and other buildings. His octagonal ﬂoor plans are
especially noteworthy. They articulated the possibilities of optimally
ﬁlling a building with octagonal rooms [8.41]. Naturally, the central
symmetry, with its emphasis on the center, humored the new self-
awareness of the princes and their requirements for display. They are
in the center, and they want to be able to radiate in all directions,
and to be seen. Leonardo’s studies of architectonic central symmetry
stand in mathematically close connection to his interest in regular
polygons, regular (Platonic) and semi-regular bodies.
He asserted that all the arts, not only architecture, should have
a scientiﬁc basis and be derived from natural laws. In his “Trattato
della pittura” Leonardo also tried to provide painting with a scientiﬁc
basis so that it would no longer belong to the “artes mechanicae”, but
would be added to the “artes liberales.” [8.42] This gave a particular
importance to the study of the human body and its proportions in
anatomy.
In a famous study of proportions [8.43], which has become an
icon of the modern age (Fig. 106) Leonardo related the human body
to the circle and the square. This brought in Platonic-mythological
allusions: the square as the symbol of the earth, the circle as the
symbol of the sky, and, in the center, man as the conjunction and
proprietor of both. Mathematically, Leonardo emphasized the pro-
portional ratios (especially that of the Golden Section). Then the
inscribed Pythagorean triangle emerges of necessity.
With all the
Renaissance artists, harmonious proportions constituted the basis of
art in natural law. It was Leonardo also who illustrated the book
“De divina proportione” (1509) by L. Pacioli: “Every part is so con-
stituted that it can form a unity with the whole and can thereby free
itself from its incompleteness.” [8.44]
The perception of symmetries also presupposes an analysis of the
sense of sight.
Here the geometrical concepts of perspective and
projection are basic. Although important groundwork was laid in
the optics and cartography of Antiquity and the Middle Ages, the
technical practice of perspective and projection became central in

Symmetry and Complexity in Philosophy and Arts
369
Fig. 106.
Symmetry of man (Leonardo da Vinci)
Renaissance painting for the ﬁrst time.
The philosophical back-
ground of this development is clear: reality is perceived through
the senses. This raises the question of whether the world is repre-
sented by the senses as it is, or whether it is changed in any way
by the sense of sight, as might be inferred from the sensory illusions
that had been much discussed ever since Antiquity. This raised the
question of whether symmetry is changed by the central projection
that takes place when an object is seen. This problem contained the
germ cell of a new discipline in geometry, namely projective geom-
etry, which was to gain great signiﬁcance in modern mathematics.
It is noteworthy, for instance, that central projections do not change
any similarity relationships, yet do change representations of size
[8.45].

370
Symmetry and Complexity
Leonardo’s interest in these questions [8.46] was shared especially
by A. D¨urer, who, in his “Underweysung der messung mit dem zirckel
un richtscheyt . . . ”
(1525/1538) [Instructions for Measuring with
the Compasses and the Ruler], wanted to give painting a scientiﬁc
basis in geometrical and optical laws.
D¨urer prescribed technical
transposition for the painter in great detail: the bundle of visual
rays is made concrete by means of a ﬁrmly anchored cord, the end of
which is to be conducted to various characteristic points of the object
to be represented.
The penetration point of the cord through an
imaginary picture plane is recorded by coordinates and transcribed
onto a sketch sheet. If a suﬃciently large number of picture points
of the object to be represented are available, the scientiﬁc framework
for the artist’s work is laid. Sighting tubes for enlargement of the
depth of vision also came into use [8.47].
To a Renaissance artist it was completely self-understood that
the proportions recorded in this way were not only valid for painting,
optics and symmetry, but could also be transposed into acoustic har-
monies as tone proportions. However, this unitary concept of symme-
try based on a geometric doctrine of proportions in the Pythagorean
tradition was no longer understood by the time of the early modern
era. The Antique and Renaissance doctrine of harmony, which was
held to be evident in geometric proportions, calculable in numeri-
cal proportions, observable in astronomical proportions and audible
in musical proportions, was soon felt to be ridiculous. Increasingly
it became the object of mythical, cabbalistic, astrological and al-
chemistic speculations, as, perhaps, in the fantastic drawings and
allegories of R. Fludd. The painter W. Hogarth, ﬁnally, considered
it “strange” and an object of derision that the same laws should ap-
ply to optical images and acoustical harmonies. For the philosopher
D. Hume, beauty is reduced entirely to the subjective perception
and sensibility of the observer [8.48]. So the unity of Antique sym-
metry appears to be broken. Science, technology and aesthetics have
become independent and have gone their own ways. But, in fact,
at least the natural sciences have not broken with the early history
of the concept of symmetry. On the contrary, modern mathemat-
ics has created a new, expanded concept of symmetry in which the

Symmetry and Complexity in Philosophy and Arts
371
old symmetry concept of Antiquity is only a special case, and which
has ﬁnally developed into a new ordering and unifying idea for the
natural sciences.
The old Pythagorean conception included music in the quadriv-
ium of the exact sciences as part of their doctrine of harmony along
with geometry, arithmetic and astronomy. For the Pythagoreans mu-
sical harmonies had the character of natural laws, that is, they were
expressions of symmetry laws of nature such as the harmony of the
spheres. In other early cultures, also, we have found that musical
harmony, nature, and life are identiﬁed with each other. In the occi-
dental tradition this unity was broken by the end of the Renaissance
at the latest. Aesthetic interpretations and research in the natural
sciences developed their own unmistakably distinct categories and
laws; in fact Antique standards of art were explicitly criticized by
later periods, and their ontological grounding, as in the Pythagorean
tradition, was called into question.
On the other hand, we have noticed that representational art
and mathematics have areas that overlap. In music one immediately
thinks of the Baroque, of course, and especially of Bach with his
elaborate fugues [8.49]. However, as long as the concept of symme-
try is limited to Antique ideas of proportion, or even — as occurs
frequently in modern theory of the arts — to reﬂection symmetry
— symmetries in music must seem more or less accidental and spo-
radic. In actual fact it was the new revolutionary breakthroughs in
music in the 20th century such as 12-tone music and electronic mu-
sic that made the connections with the encompassing mathematical
concept of symmetry clear. However, it is not a matter of forcing
another “canon of proportions” onto music. On the contrary, it is
apparent that all the fundamental concepts of music theory can be
translated into the group theory language of modern mathematical
symmetry theory and that this makes it possible to analyze exam-
ples of music from the Medieval modes through J.S. Bach, L. van
Beethoven, A. Sch¨onberg and on to K. Stockhausen. This common
language of mathematical, scientiﬁc and artistic subjects not only
fosters the unity of the “two cultures”, a unity which was thought
to be lost. Group theory permits new methods of studying music

372
Symmetry and Complexity
such as computer analysis, since the language of group theory is very
easily translatable into computer languages.
Yet this new unity of methods in mathematics, art and natural
science is sustained by fundamentally diﬀerent intentions than those
that obtained for the Pythagorean quadrivium. It is no longer pos-
sible to consider tone scales and harmonies to be the expression of
particular natural laws. In philosophical terms what we are looking
at now is a unity of methods, not an ontologically based unity like
that of the Pythagoreans. Although the modern concept of symme-
try at ﬁrst seems to make less of a claim, it actually opens up new
possibilities and applications.
History shows us not only diﬀerent
periods in cultural evolution, but also a variety of diﬀerent cultural
traditions and approaches, with diﬀerent aesthetic standards, that
frequently seem “strange” to each other. The new methods facili-
tate intercultural comparison for working out the structures held in
common and the diﬀerence, analogously to the study of diﬀerent na-
tive languages in linguistics. Music is an international language of
cultural globalization.
Music theory demonstrates that pieces of music can be consid-
ered models of mathematical structures in the formal representation
of a particular symbolic language. Laws of symmetry in musical tone
scales and harmonics have been pointed out ever since the Pythagore-
ans [8.50]. In the modern era J.P. Rameau based melody on laws of
harmony in his “Trait´e de l’harmonie” (1722), and they played a rˆole
on into the late Romantic period [8.51]. D’Alembert, the Encyclope-
dist, mathematician and philosopher, tried to make aesthetic taste
an objective matter, in keeping with Rameau. It was Sch¨onberg who
ﬁrst broke with the classical canon of harmony totally in order to al-
low for greater potentialities of form in the 12-tone technique [8.52].
The symmetries of tone scales and harmonics can be described as
cyclical groupings and thus traced back to rotation symmetries.
Thus, for example, the 12-step semi-tone scale constitutes a group
C12 with the half tones C, C#, D, D#, E, . . . etc. as rotations 0 ·
π/6, 1 · π/6, 2 · π/6, 3 · π/6, . . . (Fig. 107, (1)) [8.53].
The two
possible whole-tone scales are deﬁned by two cyclical subgroups of
C12, namely those that result from rotations by an angle n·2π/6 (2).

Symmetry and Complexity in Philosophy and Arts
373
Fig. 107.
Group-theoretical symmetries of tone scales

374
Symmetry and Complexity
Rotations by n · π/4 produce three cyclical subgroups for the three
types of diminished seventh chords (3), whole rotations of n · 2π/3
analogously produce four cyclical subgroups for the four diﬀerent
triads (4).
It is noteworthy that rotations of n · 5π/6 = n · 150◦starting
clockwise from C convert the half-tone circle into the circle of fourths,
and counterclockwise into a circle of ﬁfths. In harmonics, triads can
be represented by (non-equilateral) triangles in a half-tone circle.
An interesting thing about this is that major and minor triads form
congruent, but reﬂection-symmetrical, triangles (5). Further studies
of cyclical groups in harmonics can be carried over to other tone
scales and permit intercultural comparisons of diﬀerent conceptions
of harmony.
The possible symmetry characteristics of concrete examples of
composition are especially interesting [8.54]. For the sake of inter-
preting symmetry operations compositionally, let us ﬁrst elucidate
the concept of a musical space by analogy to geometrical ornamenta-
tion and crystallography. Since the 19th century, the dimensions of
n-dimensional spaces are interpreted and applied in musically diﬀer-
ent ways. For that reason it seems useful, as an example, to interpret
the temporal course of a composition (notationally from left to right),
using the division into measures as metrics, as a dimension or a coor-
dinate axis. The pitch (frequency) which is measureable by the staﬀ
lines, provides a second dimension. The volume (dynamics) provides
a third. For more precise analyses one could draw on the timbre
(tone color) as a fourth dimension. What is decisive for the concept
of space is, simply, to agree on an appropriate metric [8.55].
Now individual symmetry operations such as translation, reﬂec-
tion or rotation can be examined in the musical space that is deﬁned
by the dimensions of time, frequency and dynamics. Thus transla-
tions in the dimension of time are interpreted as repetition of tones;
translations in the dimension of frequency are interpreted as the par-
allel direction of voices; translations in dynamics are interpreted as
crescendo or diminuendo. Rotations such as C2 can be examined on
the axis of dynamics, that is on the notational plane of time and
frequency. Reﬂections in the plane of time and frequency correspond

Symmetry and Complexity in Philosophy and Arts
375
Fig. 108.
Symmetry of reﬂection in Sch¨onberg’s Waltz Number 5
to an increase or decrease in the volume. Reﬂections in the plane
of dynamics and time are possible, that is, on the horizontal plane
of the notation.
Reﬂections along the vertical, that is, the plane
of frequency-dynamics, are more familiar. This is the so-called ret-
rogression which appears frequently in the 15th and 16th century
and in classical pieces by Bach (“Musical Sacriﬁce”) and is employed
systematically in the serial music of Sch¨onberg’s 12-tone technique.
Fig. 108 shows the four prototypes of the Sch¨onberg series from
his Waltz Number 5 (“Five Piano Pieces,” Op. 23), which emerges
from the normal form by reﬂection on the horizontal, the vertical (=
retrogression) and the combination of both reﬂections. Because the
intervals of semitones were written in an inhomogeneous manner, the
symmetries are not shown uniformly [8.56].
The question as to whether the combination of symmetry opera-
tions is applicable to musical “ornaments,” marks a highpoint in this
kind of group theory analysis. Examples of notation in the works
of Bach can be systematically cited for the seven one-sided stripe
ornaments in the notational plane [8.57]. An example of a sequence
of ornament symmetries is measures 27–29 of the ﬁrst movement of
the piano sonata, Op. 53 (the “Waldstein Sonata”) of van Beethoven
(Fig. 109). What comes into consideration here are the stripe or-
naments of the frieze groups Fig. 18 a (5), (2), and (1) in Fig. 109.
This sequence of ornament clearly presents a reduction in complex-
ity of symmetry if one stops to consider that group (1) consists only
of translation, group (2) of translation and reﬂection, yet group (5)

376
Symmetry and Complexity
Fig. 109.
Ornament symmetries in Beethoven’s Waldstein sonata [5.58]
consists of a combination of the symmetry operations of the frieze
groups (1), (2), (3) and (4).
Reductions in the complexity of symmetry can be interpreted psy-
chologically as a relaxation of tension that takes place in the listener
while the piece of music is being played. This gives an indication of
how to objectify even subjective eﬀects of music by analyses of sym-
metry. Symmetry breakings in music, which also have great psycho-
logical charm, can of course be recognized only when the structures
of symmetry from which they deviate are well-known. “The heart
and the brain in music” (Sch¨onberg) [8.59] are therefore not oppo-
sites but instead diﬀerent aspects of a work of art that correspond
to diﬀerent human abilities.
Obviously, the old Pythagorean idea of the quadrivium can be
directly transformed into modern mathematical considerations. A
piece of music is a model of a mathematical structure in the formal
language of musical notations. Therefore, it can be translated into
formal and programming languages in order to implement it on a
computer. As formal logic is a universal language allowing all kinds
of translations, it can be used as another representation of musical
information. Fig. 110 shows the representation of a sample melody
(“Fr`ere Jacques” or “Brother John” in English) in predicative logic.
At the beginning of the ﬁrst line in Fig. 110, the key signature indicates one
sharp for the key of G. The time signature 4/4 indicates 4 beats per measure with
the quarter note having a duration of one time unit. The vertical bars divide the
melody in 8 measures, with a total of 32 notes. The vertical position of each note
on the staﬀindicates a tone, designated by a letter from A through G. (The letter
may be qualiﬁed by a sharp or ﬂat sign or by a number that indicates the octave.)
The shape of the note indicates duration: one time unit or beat for a quarter note,

Symmetry and Complexity in Philosophy and Arts
377
 ∃x1 ∃x2 ∃x3 ... ∃x32 : 
     (tone(x1, G) ∧ dur(x1, 1) ∧ next(x1, x2) ∧
       tone(x2, A) ∧ dur(x2, 1) ∧ next(x2, x3) ∧
       tone(x3, B) ∧ dur(x3, 1) ∧ next(x3, x4)
       ∧ ... ∧ tone(x32,G) ∧ dur(x32,2)) 
Fig. 110.
Representation of musical information in musical notation and formal
logic [8.60]
two units for a half note, or half a unit for an eight note. The horizontal position
of each note indicates that it is sounded after the one on the left and before the
one on the right. These features, which represent the elements of an ontology for
music, can be translated to logic supplemented with three predicates: tone(x, t)
(“note x has tone t”), dur(x, d) (“note x has duration d”), next(x, y) (“the next
note after x is y”). To represent all 32 notes in the melody, the corresponding
formula in predicative logic would require 32 variables, each with an existential
quantiﬁer. For each note, there would be three predicates to indicate its tone,
duration, and successor. The complete formula would start with 32 existential
quantiﬁers and continue with 32 lines of predicates. The last line is shorter than
the others because the last note does not have a successor.
A piece of music has not only a static structure, but it is a time-
depending model of a dynamical system. Thus, it can also be rep-
resented by all kinds of state-transition systems.
Finally, it is a
pragmatic question of intention and purpose, which kind of repre-
sentation for musical information should be preferred in diﬀerent
contexts. Structural properties like symmetry are invariant with re-
spect to diﬀerent representations.
A fundamental revolution in art took place during the ﬁrst decade
of the 20th century in the rise of abstract art. Its goal was to work out
a method of representation that would allow the painter to express his
view of the world without having to copy reality in the boundaries of
our visual experience. There is an amazing parallel to the problems of

378
Symmetry and Complexity
abstract quantum mechanical formalism, which was to be developed
beyond the boundaries of human intuition in classical mechanics.
Whether artists like P. Picasso and G. Braque studied M. Planck,
Einstein or other physicists, is still an open question. Nevertheless,
their abstract art expressed the spirit of their cultural and scientiﬁc
epoch.
Actually, their cubism followed C´ezanne’s pronouncement
that objects are made of geometrical forms such as spheres, cones
and cylinders. In addition there is the recourse to archaic art. The
object represented in the picture is broken up into stereometric atoms
and then reassembled in a new way for the purpose of making the
basic and archetypal forms of the world vivid. In 1912 a theory of
cubism was formulated [8.61].
While modern painting has remained limited to pictorial repre-
sentation, in the twenties of the 20th century the Bauhaus set about
giving artistic form to the technical-industrial life-world in a synthe-
sis of the arts of architecture, painting, sculpture and functional art.
Here, as in Antiquity, it was a matter of comprehending the human
being and his life-world as a unity, but now it was from the point
of view of science, technology and industry. Corresponding to the
paradigm shift in science there was thus an artistic upheaval and
structural change striving towards a new measure of things.
The
standard is a purpose-oriented functionalism that aims to compre-
hend the human being in his new life-world. The words “new” and
“modern” became the fashion in the twenties, which saw the political
and social collapse of old world orders. The use of the word “new”
ranged from the “Neues Bauen” (new constructions) and “Neues
Wohnen” (new dwelling) by way of the “Neue Sachlichkeit” (new
practicality) to Huxley’s “brave new world,” with its disillusionment
and irony. Interrupted by war, many projects of modernism were
not actualized or further developed until the ﬁfties and sixties. They
started with the cultural globalization of a technical-industrial life-
world. Artists like P. Klee applied the ideas of symmetry and law to
abstract art in order to probe the structure and dynamics of forms
[8.62]. Klee particularily pointed out the parallel with mathematical
natural science. In his study “Exact Experiments in the Realm of

Symmetry and Complexity in Philosophy and Arts
379
Art,” he wrote:
Art has also been given enough space for exact research, and the gates have
been open to it for some time. What was done for music before, until the end of
the 18th century, is at least beginning in the ﬁeld of sculpture. Mathematics and
physics are providing the opportunity, in the form of rules for persistence and for
alteration.
This compulsion to concern oneself ﬁrst with the functions instead of be-
ginning with the ﬁnished form, is a wholesome one. Algebraic, geometric and
mechanical tasks provide training toward the essential, the functional, in con-
trast to the impressive.
One learns to see behind the facades and to grasp a
thing by its roots. One learns to recognize what is ﬂowing underneath it — the
prehistory of the visible — and to dig into the depths and to expose substantiate
and analyze. [8.63]
The essay culminates in the demand “learn logic, learn the or-
ganism.” The organism, art and mathematical natural science are
no longer regarded as antithetical. Instead they are related to each
other.
In Kandinsky’s book “Point and Line to Surface” [8.64] the ele-
ments of form are elucidated in their tensions and harmonious com-
positions by examples from mathematics and natural science. Con-
centric star clusters from astronomy, variational possibilities of phys-
ical curves, line formations of lightning, structures of animal tissues,
swimming movements of microscopic organisms, etc., alternate with
constructions of modern technology. Abstraction is no longer “arti-
ﬁcial” and “strange,” but corresponds to the newly discovered and
created world of forms in nature and technology.
In his “theory
of sounds” W. Kandinsky demanded an art of rhythms and math-
ematically abstract constructions beyond traditional conﬁguration
like Sch¨onberg’s 12-tone music: “Every work emerges technically like
the universe emerged — from catastrophes generating a symphony
from the chaotic roaring of instruments, which is called music of the
spheres. Creation of a work is creation of a world.” [8.65]
Kandinsky and Klee taught in the Bauhaus in the twenties. Klee
was also a practising musician (violinist) who tried to transform mu-
sical structures into compositions of pictures. The main challenge
of the structural analogy between music and painting is the repre-
sentation of time. In his “Artistic Doctrine of Forms”, Klee devel-

380
Symmetry and Complexity
oped a kind of graphic state-transition system to represent the phase
transitions of rhythms according to fugues of Bach [8.66]. Actually,
it should be his “UML” (Universal Modeling Language) providing
graphic structures of musical rhythms which he realized in several
paintings. In this sense, his paintings can be considered visual mod-
els of invariant structures of dynamics [8.67]. With respect to Bach’s
polyphony of fugues, Klee called his approach “polyphonic paint-
ing,” representing the parallel development of simultaneous voices
with tools of painting. From a mathematical point of view, the par-
allel voices of a fugue illustrate simultaneity, multi-threading and
nonlinear interaction.
A beautiful example is Klee’s painting “Pastorale (Rhythms)”
from 1927 (Fig. 111). The painting has a microstructure with sub-
tle conﬁgurations of lines and a macroscopic structure with col-
ored squares which seem to emerge from the microscopic network
of meshed lines. The parallel lines with their rich vocabulary of mi-
croscopic formal segments remind us of the interacting tones in a
polyphonic fugue. The colored squares are the emerging sounds of
parallel voices. They are colored, because it is the whole sound which
eﬀects our emotions. The microscopic conﬁgurations are generated
by a variety of symmetries like translation, reﬂection or rotation in
the sense of ornamentics. Similar microscopic segments of lines dis-
Fig. 111.
Klee: Pastorale (Rhythms) 1927/20 (K 10) [The Museum of Modern
Art, New York. Abby Alderich Rockefeller Fund and Exchange. Inv. No. 157-45]

Symmetry and Complexity in Philosophy and Arts
381
play macroscopic clusters and patterns. They seem to emerge one
after another from left to right in phase transitions of time-depending
dynamics. The colours of the squares are harmonized with the warm
brown of earth generating the mood of “Pastorale.”
According to the Bauhaus, painting is only one representation of
art. The whole environment is to be shaped architectonically, cor-
responding to the technical-industrial conditions of life. As Gropius
wrote “the challenge is to master organizationally the gigantic tasks
of our time — the whole traﬃc, all human work, material and intel-
lectual” [8.68]. Form, function and economic requirements had to be
reduced to a common denominator as a task of optimization.
One of the central representatives of modernism was, without
question, Le Corbusier, who not only achieved magniﬁcent ediﬁces,
but also came onto the scene as a theorist. In his guiding principles,
“Toward an Architecture” (1920), he says this about the engineer’s
aesthetics and architecture [8.69]:
The engineer’s aesthetics, architecture: at the deepest level the same, one
deriving from the other, the one full-blown, the other secretly developing. The
engineer, guided by the law of economy and led by calculations, transposes us
into accord with the laws of the universe. He attains harmony.
By means of his handling of forms, the architect brings into reality an order
that is the pure creation of his spirit: by means of the forms he stirs our senses
and awakens our feeling for form. The interconnections that he produces give rise
to a deep echo in us: he shows us the standard for an order that we feel to be in
accord with the world order. He brings about manifold motions of our mind and
our heart: thus beauty becomes experience for us. [8.69]
The outlook on architectural and social problems is striking. Sym-
metry in construction is required to correspond to the “balance of
the social order.” In this context Le Corbusier developed the concept
of “mass-produced houses” for which “spiritual preconditions must
be created”. A passage follows which elevates Le Corbusier outright
to the Platonist of modern architecture:
Geometry is the means we ourselves have created for ourselves so that we can
overcome our surroundings and express ourselves.
Geometry is the foundation.
It is at the same time the material bearer of the symbols that signify perfection
and the divine. It bestows on us the sublime satisfactions of mathematics. The

382
Symmetry and Complexity
machine proceeds from geometry; its dreams set out to ﬁnd the joys of geometry.
The modern arts and modern thinking, after a century of analysis, seek their
salvation beyond accidental facts, and geometry conducts them to a mathematical
order, to a more and more generalized posture . . .
Such passion ensouls deeds, brings forth actions, drenches them in its color,
gives them direction.
The name of this passion today is: exactitude. An exactitude carried to great
length and elevated to the ideal: the striving for perfection . . . [8.70]
However, the Platonic emphasis on geometry and harmony in the
architecture of modernism is by no means associated with elitist-
aristocratic tendencies. In a paper by F. Schumacher about “Social
City Planning”, (1919), he wrote:
A contemporary metropolis can become harmonious only when its structures,
at deﬁning points, conform to certain rhythms that run through the whole. Their
sizes and their arrangement must be regulated to express a sense of unity. Inside
this elastically planned framework the particular and individual can unfold all
the more freely then, undisturbed by any contingencies. [8.71]
Social and artistic harmony is seen in a unity in which social and
cultural politics and economics are to be coordinated with each other:
One can see that bringing about social and artistic harmony requires many
kinds of laws and therefore all these questions lead directly into politics. Not that
it would be possible to actualize a social or artistic idea just with laws — the
creative act is required; laws clear a path for it.
Meanwhile the combined functionalism of modernism has gotten
on into years and is worse for wear. These “breakings of symmetry”
are most noticeable in architecture. Functionalism became debased,
in part, into an “international style” of desolate and unimaginative
structures that concreted shut the metropolises of a global world,
veered into the opposite of its original intentions and single handedly
reduced the cities to uninhabitable exhaust- and noise-plagued knots
of traﬃc, municipal administration, banks and business. The idea of
the city as an antiform to nature, as modernism presented it again
and again, had taken on a life of its own and had turned against
human nature [8.72].
In architecture the critique of modernism has used the catch-
word postmodern for years, and has expanded into a general cul-
tural criticism using catchwords like “post-industrial society,” “post-

Symmetry and Complexity in Philosophy and Arts
383
structuralism,” “postmodern scientiﬁc theory,” etc. [8.73]. A thread
running through this sometimes brilliant discussion is that it does
not complain of the “loss of the center” and “modernism’s symme-
try breaking” as a cultural decline, but, rather, as an achievement
that oﬀers new opportunities.
Now, the ironic treatment of “unity” and “Logos” in modernism
from the beginning of this century is not new: in Dadaism, mod-
ernism was, to a degree, keeping its own court fool, one that had
substituted the principle of “accident” for the “Logos” and that in
artists’ happenings constantly reminded the protagonists of mod-
ernism of the consequences of a “falling away from the center” —
just like once the court fools in the Medieval world of divine order.
By contrast, postmodern cultural criticism doubts the possibility
of a “unity” and a “center” in principle and criticizes them as exces-
sive demands on human reason. Reason is taking dangerous paths
in centralization, rationalization and bureaucratization and can shift
into totalitarianism, as proven by the most recent historical exam-
ples. Adorno’s critique of positivism and rationalism should be un-
derstood against the background of such a “dialectics of Enlighten-
ment.” Nevertheless, Adorno emphasizes that critique does not cause
“categories such as unity and self-harmony” to disappear without a
trace.
Rather, “the principle of harmony remains in play, trans-
formed beyond recognition”.
Besides, according to T.W. Adorno,
“the logicity of art” consists of “the balance of the coordinated, of
that homeostasis in the concept of which aesthetic harmony is sub-
limated as the ultimate.” Again asymmetry is comprehensible only
against the background of a hidden symmetry [8.72].
Here it is important for modernism to emphasize again that its
“center” and “symmetry” are not to be confused with external sim-
ple symmetry characteristics such as reﬂection symmetry or axial
symmetry. In modern natural science as well, the external geomet-
rical symmetry characteristics of individual bodies emphasized since
Antiquity, play a rather subordinate role. What is decisive are the
uniform, comprehensive (but abstract) symmetry characteristics that
are expressed in the mathematical structures of scientiﬁc theories.
Analogously, the concept of symmetry that is intended in the archi-

384
Symmetry and Complexity
tecture of modernism should be seen as a characteristic of a uniform
structuralism and functionalism.
In this sense the architecture of postmodernism comes to “break-
ings of symmetry.” Uniform functionalism is broken up. Ornament
and decoration are permitted again, and we ﬁnd in one and the same
postmodern building diverse historical styles quoted in partly ironic
alienation — from the small oriel with its Medieval eﬀect, to the
Baroque stucco work above the window to the Ionic pillar by the en-
trance. For many a contemporary it is here that the paucity of ideas
of an epigonal era becomes visible, characterized by eclecticism and
historicism. Others refer to the ironic breaking of history that allows
for playfully ﬁshing in old boxes of building blocks for the styles of
former eras. Throughout postmodernism, reﬂection symmetry and
the Golden Section appear as historical quotations of external sym-
metry which nevertheless are included as set pieces and do not de-
termine the uniform structure of the building — neither in the sense
of Antiquity nor of modernism.
Where successful postmodern architecture appears, it is charac-
terized by a loosening up of the strict purism, openness and “pointil-
lism” of the styles that seem to come together by chance, but at a
second glance, at the latest, prove to be a successful and original en-
semble of styles. The emphasis on the “selective,” the “casual” and
the “individual” versus “unity” and “generality” mirrors a postmod-
ern outlook on life that — on the basis of relevant experiences —
reacts rather skeptically and at best ironically to the claims of being
the only true technical reason and the belief that modern rationalism
will result in universal feasibility and solution to problems.
With a new ecological awareness of the environment, old ideas of
natural philosophy come into play again: the living space that a city
oﬀers is really liveable only when it is in ecological balance with na-
ture as its environment. The requirements of a natural environment
extend from nearby recreational areas to oxygen providers (“green
lungs”). On closer examination, however, that does not constitute
a rift with modernism, whose functionalism was directly intended to
produce a livable environment. But an industrial monstrosity in the
landscape does not exactly fulﬁll these functional requirements.

Symmetry and Complexity in Philosophy and Arts
385
Ecological, social, economic, political, cultural and religious prob-
lems are common challenges for mankind. In the age of globalization,
mankind is growing together, but, on the other hand, the complex
dynamics of development generate diversity and heterogeneity with
great tensions and conﬂicts. In short: globalization also means sym-
metry breaking. Nevertheless, people, regions, nations, and conti-
nents depend on one another in complex networks. Thus, we need
intercultural understanding and tolerance, because no one can dom-
inate the other without endangering the balance (“symmetry”) of
the whole network. Peace and tolerance are enforced by the com-
mon interests of mankind in order to realize welfare and a sustain-
able future. Peace, tolerance and welfare are common universals of
mankind. Cultural diversity is a source of human creativity which
is expressed in art, music and science. In this sense, globalization
demands unity in diversity.
The age of globalization is also the age of computers, because the
just-in-time society of a global world is only possible by computa-
tional networks. In the age of computers, the old slogan of Renais-
sance “ars sine scientia nihil est” (art without science is nothing) gets
new relevance. How is art with computers possible? The commercial
design of products, advertising and publicity are mainly generated
by computational tools. Computer-assisted movies generate a vir-
tual world of artiﬁcal life and culture. Obviously, computer programs
open new views on actual and possible worlds. Attractors of complex
systems can only be visualized by computational means. The beauty
of fractals results from endless iterations of self-similar computational
forms and colors. Fig. 112 shows iterated fractal structures in Julia
sets of the Mandelbrot set (Fig. 30). Computers discover symme-
try of invariant structures hidden behind the appearance of chaotic
attractors. Symmetry is still related to complexity.
We may be fascinated by the insights into a perfect Platonic world
of inﬁnity, symmetry and complexity. But do computers generate
art [8.76]? As far as we know symmetry and complexity of fractals
are also generated by nature.
People like the symmetry of leaves
and ﬂowers. In time-series analysis of complex dynamical systems
(e.g. EEG-data of brain, data ﬂow of the Internet (Fig. 86)), we de-

386
Symmetry and Complexity
Fig. 112.
The beauty of computational symmetry [8.75]
tect self-similarity of patterns on diﬀerent scales. Because of stochas-
tic ﬂuctuations and natural or technical boundaries, they are not as
perfect and inﬁnite as the Mandelbrot set. Nevertheless, people are
fascinated by the regularities in a world of diversity. Regularities in
patterns are models of mathematical structures which people may
like or dislike. Thus, beauty depends on our sensation and cognition
of forms, patterns and structures. There may be local (“subjective”)
diﬀerences of our estimation, but there are also global invariants of
beauty.
Man, nature and computers generate structures which we feel to
be beautiful. But art needs creativity. Are nature and computers
creative?
A necessary condition of creativity is the emergence of
new structures, patterns and ideas. At the end of this book we all
know: emergence is no mystery, but a result of phase transitions in
complex systems like the universe and the brain. Even if an artist’s
idea seems to be a random ﬂash of inspiration, it needs the back-
ground knowledge and know-how of an artist to create an artistic

Symmetry and Complexity in Philosophy and Arts
387
work. Thus, in the case of brains, creativity also means intentional-
ity. Contrary to cosmic and biological evolution, human minds try to
realize goals and intentions which we may like or dislike. In this sense,
cosmic expansion and biological evolution are emergent, but not
creative.
Creativity is an ability of complex cognitive systems like human
beings.
According to the principle of computational equivalence,
artiﬁcial systems with cognition, emotion and intentions are not im-
possible (compare Sec. 7.2). Therefore, in a technical co-evolution,
artiﬁcial minds could emerge, creating their own artistic work. But
because of their nonlinear dynamics, they would have their own in-
timacy of feelings and artistic estimation which might be completely
strange to us or not. The same may be true for aliens which may
develop on foreign planets elsewhere in the universe. Like humans,
they are children of the same universe.
As they all, natural and
 
Fig. 113.
Symmetry and symmetry breaking in complex cognitive systems
[Montage based on a ﬁgure (left) from Descartes’ “Treatise of Man”: The mir-
rored portrait (right) shows a brain map of the EEG during perception of virtual
shapes. Both portraits together make up the vase-face ambiguity (Fig. 91)] [8.77]

388
Symmetry and Complexity
artiﬁcial minds, evolve according to the laws of cosmic and biological
evolution, they also could be fascinated by the invariant structures
of symmetry and complexity.

References
Chapter 1
1.1
Reichard, G.: Navaho Religion. A Study of Symbolism. 2 vols.
Pantheon Books: New York (1950).
1.2
Nowotny, K.A.: Beitr¨age zur Geschichte des Weltbildes. Farben
und Weltrichtungen. Berger: Horn/Vienna (1970), p. 195.
1.3
Witherspoon, G.: Language and Art in the Navajo Universe.
University of Michigan Press: Ann Arbor (1977), p. 154.
1.4
Brown, W.N.:
A Descriptive and Illustrated Catalogue of
Miniature Paintings of the Jaina Kalpasutra. Freer Gallery of
Art: Washington (1934).
1.5
Gopinatha Rao, T.A.: Elements of Hindu Iconography. Vol. 1.
The Law Printing House: Madras (1914), Inanarnavatantra X
39. Cf. also Nowotny [1.2], p. 100.
1.6
I Ching — The Book of Changes.
Ed.
by R. Wilhelm.
Diederichs: Jena (1924), repr. D¨usseldorf/Cologne (1973).
1.7
The 13 Books of Euclid’s Elements. Transl. from the Text of
Heiberg with Introduction and Commentary by T.L. Heath. 3
vols. Dover Publications: New York (1956).
1.8
Mainzer, K.: Geschichte der Geometrie. B.I. Wissenschaftsver-
lag: Mannheim/Vienna/Z¨urich (1980).
1.9
Kepler, J.: Collected Works. Vol. 6: Harmonice Mundi. Transl.
and introduced by M. Caspar.
C.H. Beck:
Munich/Berlin
(1939).
1.10 On the Pythagoreans’ doctrine of harmony, cf. van der Waer-
389

390
Symmetry and Complexity
den, B.L.: Die Harmonielehre der Pythagoreer. In: Hermes 78
(1943), pp. 163–199.
1.11 Cf. Mainzer [1.8] and Mainzer, K.: Real Numbers. In: Ebbing-
haus, H.-D. Hermes, H. Hirzebruch, F. Koecher, M. Mainzer,
K. Neukirch, J. Prestel, A. Remmert, R.: Numbers. Springer:
Berlin/Heidelberg/New York (1990), pp. 28–30.
1.12 Leonardo of Pisa:
Scritti de Leonardo Pisano.
Vol.
1:
Il liber abbaci (liber abaci 1202/1228).
Ed.
B. Boncom-
pagni. Tipograﬁa delle Scienze Matematiche e Fisiche: Rome
(1857), chapt.
XII; also cf.
Archibald, R.C.:
Golden Sec-
tion. In: American Mathematical Monthly 25 (1918), pp. 232–
238; Coxeter, H.S.M.: Unverg¨angliche Geometrie. Birkh¨auser:
Basel/Stuttgart (1963), p. 206.
1.13 Aristotle: Nikomachische Ethik. Translated by F. Dirlmeier,
notes by E.A. Schmidt.
Reclam:
Stuttgart (1969), 1131 b
9–32.
1.14 Sachs, A.: Babylonian observational astronomy. In: Philosoph-
ical Transactions of the Royal Society of London A 276 (1974),
pp. 43–50; cf. also van der Waerden, B.L.: Geometry and Alge-
bra in Ancient Civilizations. Springer: Berlin/Heidelberg/New
York (1983); Neugebauer, O.: The Exact Sciences in Antiquity.
Brown University Press: Providence (2nd ed. 1957).
1.15 Cf.
also Needham, J.: Astronomy in Ancient and Medieval
China. In: Philosophical Transactions of the Royal Society of
London A 276 (1974), pp. 67–82.
1.16 J. Mittelstraß: Die Rettung der Ph¨anomene.
Ursprung und
Geschichte eines antiken Forschungsprinzips.
De Gruyter:
Berlin (1962);
Mainzer,
K.:
Grundlagenprobleme in der
Geschichte der exakten Wissenschaften.
Universit¨atsverlag:
Constance (1981), p. 8.
1.17 Cf. also Hanson, N.R.: Constellations and Conjectures. Reidel:
Dordrecht/Boston (1973), p. 101.
1.18 Bruins, E.M.: La chimie du Tim´ee. In: Revue de M´etaphysique
et de Morale LVI (1951), pp. 269–282.
1.19 Diels, H.: Die Fragmente der Vorsokratiker. 6th ed., revised
by W. Kranz.
3 vols.
Weidmannsche Verlagsbuchhandlung:

References
391
Berlin (1960/1961) (abbrev.: Diels-Kranz), 12 A 10 (Pseudo-
Plutarch).
1.20 Diels-Kranz [1.19], 13 A 5, B 1.
1.21 Diels-Kranz [1.19], 22 B 64, B 30.
1.22 Heisenberg, W.: Physik und Philosophie. Ullstein: Frankfurt
(1970), p. 44.
1.23 Diels-Kranz [1.19], 22 B 8.
1.24 Diels-Kranz [1.19], 31 B 8.
1.25 Here one should recall the writings of Aristotle in natural sci-
ence, the Physics, consisting of 8 books, De caelo (4 books), Me-
teorologica (4 books), De generatione et corruptione (2 books),
a series of biological and physiological writings, above all, His-
toria animalium, a natural history of animals (to be sure, not
exclusively written by Aristotle), De partibus animalium, De
motu animalium, as well as De respiratione.
1.26 Aristotle, Physics I.1, 184 a.
1.27 Aristotle, Physics III, 202 a 10–15.
1.28 Aristotle, Physics II, 3.
1.29 Aristotle, Physics VII.
1.30 Feng Yu-Lan: A History of Chinese Philosophy. Vol. 2: The Pe-
riod of Classical Learning. Princeton University Press: Prince-
ton (1953), p. 120.
Chapter 2
2.1
Leibniz, G.W.: Zur Analysis der Lage. In: Hauptschriften zur
Grundlegung der Philosophie.
Vol.
1.
Ed.
by E. Cassirer,
transl. by A. Buchenau. Felix Meiner: Leipzig (1904), p. 73.
2.2
Van der Waerden, B.L.:
Algebra.
Vol.
1.
Springer:
Berlin/Heidelberg/New York (1966), §9.
2.3
Veblen, O./Young, J.W.: Projective Geometry. Vol. 1. Ginn:
Boston (1918), pp. 61 ﬀ.
2.4
Weyl, H.: Symmetry. Princeton University Press: Princeton
(1952).
2.5
Cf. also Speiser, A.: Die Theorie der Gruppen von endlicher
Ordnung. Birkh¨auser: Basel/Stuttgart (4th ed. 1956), §4.
2.6
Shubnikov, A.V. Koptsik, V.A.:
Symmetry in Science and

392
Symmetry and Complexity
Art.
Plenum Press: New York/London (1974), pp.
79 ﬀ.;
cf.
also Wolf, K.L. Wolﬀ, R.: Symmetrie.
Vol.
2.
B¨ohlau:
M¨unster/Cologne (1956), pp. 132 f.
2.7
Shubnikov [2.6], p. 157; Wolf [2.6], pp. 142.
2.8
Cf. also Coxeter [1.12]; Weyl [2.4].
2.9
Mainzer [1.8], p. 55.
2.10 Speiser [2.5], §33.
2.11 Burckhardt, J.J.: Die Symmetrie der Kristalle.
Birkh¨auser:
Basel/Boston/Berlin (1988).
2.12 Klein, F.: Das Erlanger Programm.
In: Gesammelte Math-
ematische Abhandlungen.
Vol.
1.
Springer: Berlin (1921),
p. 463.
2.13 Lie, S.: Abhandlungen. Vol. 5. Teubner: Leipzig/Kristiana
(1924), p. 586.
2.14 Gauss, C.F.: Disquisitiones generales circa superﬁcies curvas.
In: Werke.
Vol.
4.
Teubner: Leipzig (1880), pp.
217 ﬀ.;
Mainzer [1.8], pp.157 ﬀ.
2.15 Riemann, B.: ¨Uber die Hypothesen, welche der Geometrie zu-
grunde liegen. Springer: Berlin (1919). See also: Gesammelte
mathemematische Werke. N. XIII Habilitations-Vortrag (2nd
ed. 1893); reprinted (with notes by H. Weyl) in the collection
Weyl, H. et al.: Das Kontinuum und andere Monographien.
Chelsea: New York (1973).
2.16 Eisenhart, L.P.: Riemannian Geometry. Princeton University
Press: Princeton (1926).
2.17 Lie, S. Engel, F.: Theorie der Transformationsgruppen. 3 vols.
Teubner: Leipzig (1888–1893).
2.18 Freudenthal, H.: Lie groups in the foundations of geometry. In:
Advances in Mathematics 1 (1965), pp. 145–190.
2.19 Cartan, E.: Les espaces riemanniens sym´etriques.
In: Verh.
Intern. Mathem.-Kongr.
I. Z¨urich (1932), pp. 152–161; see
also Helgason, S.: Diﬀerential Geometry and Symmetric Spaces.
Academic Press: New York (1962).
2.20 Elliott, J.P. Dawber, P.G.:
Symmetry in Physics.
Vol.
1:
Principles and Simple Applications.
Macmillan:
London/
Basingstoke (1979), chapt. 4.

References
393
2.21 Kaplan, D. Glass, L.:
Understanding Dynamics.
Springer:
Berlin/Heidelberg/New York (1995), p. 210; Haken, H.: Syn-
ergetics. An Introduction. Springer: Berlin/Heidelberg/New
York (3rd ed. 1983), pp. 106 ﬀ.
2.22 Cf. also Haken [2.21], pp. 108 ﬀ.
2.23 Cf. also Haken [2.21], pp. 110 ﬀ.
2.24 Arnold, V.I.: Ordinary Diﬀerential Equations. M.I.T. Press:
Cambridge Mass. (1978); Hirsch, M.W. Smale, S.: Diﬀerential
Equations, Dynamical Systems, and Linear Algebra. Academic
Press: New York (1974).
2.25 Nicolis, G. Prigogine, I.:
Die Erforschung des Komplexen.
Piper: M¨unchen (1987), Fig. 3.18–3.19.
2.26 Nicolis [2.25], Fig. 3.26–3.27.
2.27 Abraham, R.H. Shaw, C.D.: Dynamics — The Geometry of
Behavior. Part 4: Bifurcation Behavior. Aerial Press: Santa
Cruz (1984), p. 179.
2.28 Thom, R.: Structural Stability and Morphogenesis. Benjamin/
Cummings: Reading Mass. (1975).
2.29 Abraham [2.27], p. 46.
2.30 Cf. [2.28].
2.31 Cf. also Mandelbrot, B.B.: The Fractal Geometry of Nature.
Freeman: San Francisco (1982).
2.32 Fatou, P.: Sur les ´equations fonctionelles. In: Bull. Soc. Math.
Fr.
47 (1919/1920), pp.
161–271, 48, pp.
208–314; Julia,
G.: Sur l’iteration des fonctions rationelles.
In: Journal des
Math´ematique Pure et Appliqu´ee 8 (1918), pp. 47–245.
2.33 Peitgen, H.-O. Richter, P.H.:
The Beauty of Fractals.
Im-
ages of Complex Dynamical Systems.
Springer:
Berlin/
Heidelberg/New York (1986), p. 10.
2.34 Douady, A. Hubbard, J.H. Iteration des polynomes quadra-
tiques complexes. In: CRASH Paris 294 (1982), pp. 123–126.
Chapter 3
3.1
Cf. also Mainzer, K.: Thinking in Complexity. The Compu-
tational Dynamics of Matter, Mind, and Mankind. Springer:
Berlin/Heidelberg/New York (4th ed. 2004), chapt. 2.6; Abar-

394
Symmetry and Complexity
banel, H.D.I.: Analysis of Observed Data. Springer: New York
(1996); Kanz, H. Schreiber, T.: Nonlinear Time Series Analysis.
Cambridge University Press: Cambridge (1997).
3.2
For proofs, see also Hamermesh, M.: Group Theory and its
Application to Physical Problems. Addison-Wesley: Reading
Mass. (1962).
3.3
Schmutzer, E.: Symmetrien und Erhaltungss¨atze der Physik.
Akademie-Verlag: Berlin/Oxford/Braunschweig (1972), p. 56
ﬀ.
3.4
Noether, E.: Invariante Variationsprobleme. I. Nachrichten der
Gesellschaft der Wissenschaften zu G¨ottingen. Mathematisch-
Physikalische Klasse (1918), pp. 235–257.
3.5
Minkowski, H.: Raum und Zeit (Lecture 1908). In: Lorentz,
H.A. Einstein, A. Minkowski, H.:
Das Relativit¨atsprinzip.
Eine Sammlung von Abhandlungen. Teubner: Leipzig/Berlin
(1913), repr.
Wissenschaftliche Buchgesellschaft: Darmstadt
(8th ed. 1982), pp. 54–66; cf. also Pension, L.: H. Minkowski
and Einstein’s Theory of Relativity. In: Archiv for History of
Exact Sciences 17 (1977), pp. 71–95; Einstein, A.: The Mean-
ing of Relativity. Princeton University Press: Princeton (1988).
3.6
Cf. also Jackson, J.D.: Classical Electrodynamics. John Wiley:
New York (1975), pp. 515 ﬀ.
3.7
Weyl, H.:
Raum, Zeit, Materie.
Vorlesungen ¨uber allge-
meine Relativit¨atstheorie. Springer: Berlin (1923), repr. Wis-
senschaftliche Buchgesellschaft:
Darmstadt (1961); Philoso-
phy of Mathematics and Natural Science. Princeton Univer-
sity Press: Princeton (1949); see also Ehlers, J.: The Nature
and Structure of Spacetime. In: Mehra, J. (ed.): The Physi-
cist’s Conception of Nature. Reidel: Dordrecht/Boston (1973),
pp. 94 ﬀ.; Mainzer [1.8], chapt. 5.35.
3.8
Cf.
also Wigner, E.P.:
Symmetry and Conservation Laws.
In: Symmetries and Reﬂections.
Scientiﬁc Esays of Eugene
P. Wigner, Indiana University Press:
Bloomington/London
(1967), pp. 22 ﬀ.; Fock, V.: The Theory of Space, Time and
Gravitation. Pergamon Press: New York (1959).
3.9
Weinberg, S.: Gravitation and Cosmology. Principles and Ap-

References
395
plications of the General Theory of Relativity.
John Wiley:
New York (1972), pp. 25 ﬀ.; Hawking, S.W. Ellis G.F.R.: The
Large Scale Structure of Space-Time.
Cambridge University
Press: New York (1973); Hawking, S.W.: A Brief History of
Time. Bantam Books: New York (1988); Hawking, S.W. Pen-
rose, R.: The Nature of Space and Time. Princeton University
Press: Princeton (1996).
3.10 Mie, G. Grundlagen einer Theorie der Materie (I). In: Annalen
der Physik 37 (1912), pp. 511–534; (II). 39 (1912), pp. 1–40;
(III). 40 (1913), pp. 1–66.
3.11 Hilbert, D.:
Die Grundlagen der Physik.
In:
Nachrichten
der K¨oniglichen Gesellschaft der Wissenschaften zu G¨ottingen
(1915), pp. 395–407; (1917), p. 201; Mathematische Annalen
92 (1924), p. 1; cf. also Mehra, J.: Einstein, Hilbert, and the
Theory of Gravitation. In: Mehra [3.7], pp. 137 ﬀ.
3.12 See also Hund, F.: Geschichte der Quantentheorie. B.I. Wis-
senschaftsverlag: Mannheim/Vienna/Z¨urich (2nd ed. 1975).
3.13 Historically, the group theory concept of symmetry in quan-
tum mechanics was ﬁrst applied in the texbooks of Weyl,
H.: Gruppentheorie und Quantenmechanik.
Hirzel: Leipzig
(1931); Wigner, E.P.:
Gruppentheorie und ihre Anwendung
auf die Quantenmechanik der Atomspektren. Vieweg: Braun-
schweig (1931); van der Waerden, B.L.: Die gruppentheoretis-
che Methode in der Quantenmechanik. Springer: Berlin (1932).
For modern textbook representations see also Boardman, A.D.
O’Connor, D.E. Young, P.A.: Symmetry and its Application
in Science. MacGraw-Hill: London/New York (1973), chapt.
9; Elliott, J.P. Dawber, P.G.: Symmetry in Physics. Vol. 5.
Macmillan: London (1979), chapt. 5; Greiner, W. M¨uller, B.:
Theoretische Physik.
Vol.
5: Quantenmechanik II: Symme-
trien. Harri Deutsch: Thun/Frankfurt (1985).
3.14 For a modern textbook explanation, see also Itzykson, C. Zuber,
J.-B.: Quantum Field McGraw-Hill: Theory. New York (1980),
chapt. 2; Elliott [3.13], vol. 2, pp. 380 ﬀ.
3.15 Marshak, R.E. Riazuddin/Ryan, C.P.: Theory of Weak Inter-
action in Particle Physics. John Wiley: New York (1969).

396
Symmetry and Complexity
3.16 Lee, T.D. Yang, C.N.:
Questions of Parity Conservation in
Weak Interaction.
In: Physical Review 104 (1956), p.
254;
Wu, C.S. Amber, E. Heyward, R.W. Hoppes, D.D. Hudson,
R.P.: Experimental Test of Parity Conservation in Beta-Decay.
In: Physical Review 105 (1957), pp. 1413–1415.
3.17 See also Abers, E.S. Lee, B.W.: Gauge Theories. In: Physics
Reports 9 C (1973), p.
1; Rollnik, H.:
Ideen und Experi-
mente f¨ur eine einheitliche Theorie der Materie. In: Rheinisch-
Westf¨alische Akademie der Wissenschaften Vortrag N 296.
Opladen (1979), pp. 18 ﬀ.
3.18 Salam,
A.:
Weak and electromagnetic interactions.
In:
Svartholm,
N.:
Elementary Particle Theory:
Relativistic
Groups and Analyticity (Nobel Symposium No. 8). Almqvist
and Wiksells: Stockholm (1968), p. 367.
3.19 For a historical overview on quantum chromodynamics cf.
Mainzer, K.: Symmetries of Nature. De Gruyter: Berlin/New
York (1996), chapt. 4.33 and, of course, the pioneer of quarks
and complex systems Gell-Mann, M.:
The Quark and the
Jaguar. Freeman: New York (1994).
3.20 Bernstein, J.: Spontaneous Symmetry Breaking, Gauge Theo-
ries, the Higgs Mechanism and all that. In: Revise Reports of
Modern Physics 46 (1974), pp. 7–48; Davies, P.C.W.: Super-
force. Simon & Schuster: New York (1984); Georgi, H.: Why
Unify?
In: Nature 288 (Dec.
1980), pp.
649–651; Georgi,
H. Glashow, S.L.:
Unity of all Elementary-Particle Forces.
In: Physical Review Letters 32 vol.
8 (1974), pp.
438–441;
Glashow, S.L.: Interactions. Time-Warner Books: New York
(1988); Weinberg, S.: The search for unity. Notes for a his-
tory of quantum ﬁeld theory. In: Daedalus 106 (4) (1977), pp.
17–35.
3.21 Wheeler, J.A.: A Journey into Gravity and Spacetime. Scien-
tiﬁc American Library: New York (1990).
3.22 Greene, B.: The Elegant Universe. Superstrings, Hidden Di-
mensions, and the Quest for the Ultimate Theory. W.W. Nor-
ton: New York/London (1999), p. 144, Fig. 6.2.
3.23 Davies, P.C.W./Brown, J. (eds.): Superstrings: A Theory of

References
397
Everything?
Cambridge University Press:
Cambridge Eng.
(1988).
3.24 Kaluza, T.:
Zum Unit¨atsproblem der Physik.
Sitzungs-
berichte der preußischen Akadademie der Wissenschenschaften
zu Berlin (1921), pp. 966–972; Klein, O.: Quantentheorie und
f¨unfdimensionale Relativit¨atstheorie. Zeitschrift f¨ur Physik 37
(1926), pp.
895–906; Zur f¨unfdimensionalen Darstellung der
Relativit¨atstheorie. Zeitschrift f¨ur Physik 36 (1926), pp. 188–
208; J. Phys. Rad. 8 (1927), p. 24; for a generalization see also
Veblen, O. Hoﬀmann, D.: Projective Relativity. In: Physical
Review 36 (1930), p. 810.
3.25 Cf. Greene [3.22], Part IV.
3.26 Audretsch, J. Mainzer, K.: Vom Anfang der Welt. C.H. Beck:
M¨unchen (2nd ed. 1990), p. 98.
3.27 Cf. also Bernstein [3.20].
3.28 Weinberg, S.: The First Three Minutes.
Basic Books: New
York (1993).
3.29 Guth, A.H.:
The Inﬂationary Universe.
Addison-Wesley:
Reading Mass. (1997).
3.30 Steigman, G.: Observational tests of antimatter cosmologies.
In: Annual Review of Astronomy and Astrophysics 14 (1976),
pp.
339–372; Toussaint, D. Treiman, S.B. Wilczek, F. Zee,
A.: Matter-antimatter accounting, thermodynamics, and black-
hole radiation.
In:
Physical Review D 19 (Febr.
1979),
pp. 1036–1045.
3.31 Prigogine, I.: From Being to Becoming — Time and Complex-
ity in Physical Sciences. Freemann: San Franciso (1980); Intro-
duction to Thermodynamics of Irreversible Processes. John Wi-
ley: New York (1961); Boccara, N. (ed.): Symmetries and Bro-
ken Symmetries in Condensed Matter Physics. IDSET: Paris
(1981).
3.32 Mainzer, K.: The Little Book of Time. Copernicus: New York
(2002), chapt. 5.
3.33 Lorenz, E.N.: Deterministic ﬂow. In: J. Atmos. Sci. 20 (1963),
p. 130; Schuster, H.G.: Deterministic Chaos. An Introduction.
Physik-Verlag: Weinheim (1984), p. 9.

398
Symmetry and Complexity
3.34 Fig. 44 from Feynman, R.P. Leighton, R.B. Sands, M.: The
Feynman Lectures of Physics. Vol. II. Addison-Wesley: Read-
ing Mass. (1965).
3.35 Haken [2.21], p. 5.
3.36 The experiment dates back to J. Scott Russell:
Report on
waves. 14th meeting of the British Asociation for the Advance-
ment of Science (BAAS) (1844) and is described by Scott, A.:
Nonlinear Science.
Oxford University Press: Oxford (2003),
p. 2.
3.37 Arnold, V.I.: Mathematical Methods of Classical Mechanics.
Springer: Berlin (1978); Davies, P.C.W.: The Physics of Time
Asymmetry. Surrey University Press: London (1974); Penrose
R.: The Emperor’s New Mind. Oxford University Press: Ox-
ford (1989), p. 181.
3.38 Lichtenberg, A.J. Libermann, M.A.: Regular and Stochastic
Motion. Springer: Berlin (1982); Schuster [3.33], p. 137.
3.39 Poincar´e, H.: Les M´ethodes Nouvelles de la M´ecanique C´eleste.
Gauthier-Villars: Paris (1892).
3.40 Arnold, V.I.: Small denominators II. Proof of a theorem of A.N.
Kolmogorov on the the preservation of conditionally-periodic
motions under a small perturbation of the Hamiltonian.
In:
Russian Mathematical Surveys 18 (1963) p.
5; Kolmogorov,
A.N.: On conservation of conditionally-periodic motions for a
small change in Hamiltonian function. In: Doklady Akademy
Nauk USSR 98 (1954), p.
525; Moser, J.:
Convergent se-
ries expansions of quasi-periodic motions. In: Mathematische
Annalen 169 (1967), p. 163.
3.41 Birkhoﬀ, G.D.:
Nouvelles recherches sur les syst`eme dy-
namiques. In: Mem. Pont. Acad. Sci. Novi Lyncaei 1 (1935),
p. 85.
3.42 Eckmann, J.P.: Roads to turbulence in dissipative dynamical
systems. In: Rev. Mod. Phys. 53 (1981), p. 643; computer
simulation of Fig. 47 from Lanford, O.E.: Turbulence Seminar.
In: Bernard, P. Rativ, T. (eds.): Lecture Notes in Mathematics
615. Springer: Berlin (1977), p. 114.
3.43 Landau, L.D. Lifshitz, I.M.: Course of Theoretical Physics. Vol.

References
399
5: Statistical Physics. Pergamon Press: London/Paris 1959.
Landau only considered phase transitions in thermal equilib-
rium; cf. also Brout, R.: Phase Transitions. Benjamin: New
York (1965); Domb, C. Green, M.S. (eds.): Phase Transitions
and Critical Phenomena.
5 vols.
Academic Press: London
(1972–1976).
3.44 Cf. Haken [2.21].
3.45 Haken, H.: Encyclopedia of Physics. Vol XXV/2c. Light and
Matter. Springer: Berlin (1970).
3.46 Cf. also Satter, D.: Topics in Stability and Bifurcation Theory.
Springer: Berlin (1973).
3.47 For linear-stability analysis cf. also Guggenheimer, J. Holmes,
P.: Nonlinear Oscillations, Dynamical Systems, and Bifurca-
tions of Vector Fields.
Springer: Berlin (1983); Nicolis, G.
Prigogine, I.: Self-Organization in Non-Equilibrium Systems.
John Wiley: New York (1977).
Chapter 4
4.1
Biggs, N.L. Loyd, E.K. Wilson, R.J.: Graph-Theory 1736–1936.
Clarendon: Oxford (1990), p. 55.
4.2
Partington, J.R.: A Short History of Chemistry. Macmillan:
London (1965), pp. 300 ﬀ.
4.3
K´ekul´e, A.: Lehrbuch der organischen Chemie. Enke: Erlangen
(1859a).
4.4
Cf. Le Bel, J.A. van’t Hoﬀ, J.H.: Die Lagerung der Atome im
Raume. Vieweg: Braunschweig (1877).
4.5
Cf. Mainzer [1.8], p. 135.
4.6
Bader, R.F.W.:
Atoms in Molecules.
A Quantum Theory.
Clarendon Press: Oxford (1990), p. 30.
4.7
Primas, H.: Chemistry, Quantum Mechanics and Reduction-
ism. Springer: Berlin (2nd ed. 1983).
4.8
Bader [4.6], p. 6.
4.9
Cf. also Flurry, R.L.: Symmetry Groups. Theory and Chemical
Applications. Englewood Cliﬀs: New Jersey (1980); Donald-
son, J.S. Ross, S.D.: Symmetry and Stereochemistry.
Inter-

400
Symmetry and Complexity
text Books: London (1972); Hollas, J.M.: Die Symmetrie von
Molek¨ulen. De Gruyter: Berlin/New York (1975).
4.10 Pasteur, L.: Lecons sur la dissym]’etrie mol´eculaire. Hachette:
Paris (1861); P. Curie also spoke of “dissym´etrie” in: Sur la
sym´etrie dans les ph´enom`enes physiques, sym´etrie d’un champ
´electrique et d’un champ magn´etique. In: Journal de Physique 3
(1894), p. 393. “Chirality” goes back to Lord Kelvin: Baltimore
Lectures (1884/1893), Clay ans Sons: London (1904).
4.11 H¨uckel, E.:
Zur Quantentheorie der Doppelbindung.
In:
Zeitschrift f¨ur Physik 60 (1930), pp.
423–456; Die Elek-
tronenﬁguration des Benzols und verwandter Verbindungen.
In:
Zeitschrift f¨ur Physik 70 (1931), pp.
204–286; Quan-
tentheoretische Beitr¨age zum Problem der aromatischen und
unges¨attigten Verbindungen.
In:
Zeitschrift f¨ur Physik 76
(1932), pp. 628–648.
The H¨uckel model is the prototype of
a semi-empirical method. In this case, the Hamiltonian oper-
ator is assigned free parameters which do not necessarily have
any physical signiﬁcance and are determined empirically. It is
therefore not deﬁned by ﬁrst principles of physics, so that there
is no strict reductionism to quantum mechanics.
4.12 Woodward, R.B. Hoﬀmann, R.: The Conservation of Orbital
Symmetry. Verlag Chemie: Weinheim (1970).
4.13 Mandelkern, L.: Introduction to Macromolecules.
Springer:
New York (1983).
4.14 Heisenberg,
W.:
Die
Plancksche
Entdeckung
und
die
philosophischen Grundlagen der Atomlehre.
In: Heisenberg,
W.: Wandlungen in den Grundlagen der Naturwissenschaft.
Hirzel: Stuttgart (1959), p. 183. Heisenberg speaks about the
symmetries of arabic friezes with regard to the structure of the
elementary particles. But they become immediately apparent
in the illustrated structures of polymerization.
4.15 Sund, H.:
Evolution und Struktur der Proteine.
Univer-
sit¨atsverlag: Konstanz (1968); Fasold, H.: Die Struktur der
Proteine. Verlag Chemie: Weinheim (1973); Dickerson, R.E.
Geis, I.: Struktur und Funktion der Proteine. Verlag Chemie:
Weinheim (1975).

References
401
4.16 Ingram, V.M.: The Hemoglobins in Genetics and Evolution.
Columbia University Press: New York/London (1975).
4.17 See also Eisenberg, D.:
X-ray crystallography and enzyme
structure.
In: Boyer, P.H. (ed.): The Enzymes.
Structures
and Control I. Academic Press:
New York/London (1970),
pp. 7 ﬀ.
4.18 Cf. also Quack, M.: Die Symmetrie von Zeit und Raum und ihre
Verletzung in molekularen Prozessen. In: Akademie der Wis-
senschaften (Berlin) Jahrbuch 1990–1992. De Gruyter: Berlin
(1993), p. 469; Quack, M.: Molecular spectra, reaction dynam-
ics, symmetries and life. In: Chimia 57 (2003), pp. 147–160.
4.19 Quack, M.: On the measurement of parity violating energy dif-
ference between enantiomers. In: Chemical Physics Letters 132
No. 2 (1986), pp. 147–153.
4.20 See also Morozov, L.L. Goldanskii, V.I.: Violation of symmetry
and self-orgranization in prebiological evolution. In: Krinsky,
V.I. (ed.): Self-Organization.
Autowaves and Structures far
from Equilibrium. Springer: Berlin (1984), pp. 224–232.
4.21 Curie [4.10], p. 393.
4.22 Mainzer, K.: Symmetry and complexity — fundamental con-
cepts of research in chemistry.
In: Hyle.
An International
Journal for the Philosophy of Chemistry 3 (1997), pp. 29–49.
4.23 Prigogine (1980) [3.31]. Prigogine’s work on the time operator
and irreversibility is based on research of Misra, B.: Nonequi-
librium Entropy, Lyapunov Variables, and Ergodic Properties
of Classical Systems. Proceedings of the National Academy of
Sciences of the United States of America 75 (1978), pp. 1627–
1631; Misra, B. Prigogine, I. Courbage, M.: P.N.A.S. (1979),
pp. 4768–4772; B. Misra, M. Courbage (1978): Physica 104A
(1980), pp. 359–377; B. Misra, I. Prigogine: Letters Mathe.
Phys. 7 (1983), pp. 421–428.
4.24 Cf.
Scott, S.C.: Chemical Chaos.
Oxford University Press:
Oxford (1961); Schneider, F.W. M¨unster, A.F.: Nichtlineare
Dynamik in der Chemie. Spektrum Akademischer Verlag: Hei-
delberg/Berlin/Oxford (1996).
4.25 M¨uller, A.: Struktur-Vielfalt im Nanokosmos. In: Akademie-

402
Symmetry and Complexity
Journal. Magazin der Union der deutschen Akademien der Wis-
senschaften 1 (2003), p. 20; cf also M¨uller, A. Shah, S.Q.N.
B¨ogge, H. Schmidtmann, M.: Molecular growth from a Mo176
to a Mo248 cluster. In: Nature 48 (1999), p. 397.
4.26 Whitesides, G.M. Mathias, J.P. Seto, C.T.:
Molecular self-
asembly and nanochemistry: A chemical strategy for the syn-
thesis of nanostructures. In: Science 254 (1991), pp. 1312–1319.
4.27 Feynman, R.: There’s plenty of room at the bottom. In: Minia-
turization 282 (1961), pp. 295–296.
4.28 Drexler, K.E.: Nanotechnology summary.
In: Encyclopedia
Britannica’s Science and the Future Yearbook 162 (1990); cf.
also Drexler, K.E.: Nanosystems Molecular Machinery, Manu-
facturing, and Computation. John Wiley & Sons: New York
(1992).
4.29 Newcome, G.R. (ed.): Advances in Dendritic Macromolecules
JAI Press: Greenweech Conn. (1994).
4.30 Curl, R.F. Smalley, R.E.: Probing C60. In: Science 242 (1988),
pp.
1017–1022; Smalley, R.W.: Great balls of carbon: The
story of Buckminsterfullerene.
In:
The Sciences 31 (1991),
pp. 22–28.
4.31 M¨uller, A.: Supramolecular inorganic species: An expedition
into a fascinating rather unknown land mesoscopia with in-
terdisciplinary expectations and discoveries. In: J. Molecular
Structure 325 (1994), p.
24; M¨uller, A. Mainzer, K.: From
molecular systems to more complex ones. In: M¨uller, A. Dress,
A. V¨ogtle, F. (eds.): From Simplicity to Complexity in Chem-
istry — and Beyond. Vieweg: Wiesbaden (1995), pp. 1–11.
4.32 Fig. 58 with drawings of Christie, B.:
Spektrum der Wis-
senschaft Spezial 2 (2002), p. 22.
Chapter 5
5.1
Monod, J.: On symmetry and function in biological systems.
In: Engstr¨om, A. Strandberg, B. (eds.): Symmetry and Func-
tion of Biological Systems at the Macromolecular Level. Pro-
ceedings of the 11th Nobel Symposium 1968.
Almqvist and
Wiksell: Stockholm (1968), pp. 15–27. Cf. also Jenken, M.:

References
403
The biological and philosophical deﬁnitions of life. In: Acta
biotheoretica 24 (1975), pp. 14–21.
5.2
See Sitte, P.: Symmetrien bei Organismen.
In: Biologie in
unserer Zeit 6 (1884), p. 165; Klug, A.: Point groups and the
design of aggregates. In: Engstr¨om [5.1], p. 427.
5.3
Cf. also Gierer, A.: Physik der biologischen Gestaltbildung. In:
Naturwissenschaften 68 (1981), pp. 245–251.
5.4
Weberling, F.: Symmetrie der Pﬂanzen. In: Stork, H. (ed.):
Symmetrie. Aulis: Cologne (1985), pp. 175 ﬀ.; cf. the older
publications, e.g., Frey, A.: Geometrische Symmetriebetrach-
tungen.
In: Flora 120 (1926), pp.
87–98; Troll, W.: Sym-
metriebetrachtungen in der Biologie. In: Studium generale 2
(1949), pp. 240–259.
5.5
See also Weberling, F.:
Morphologie der Bl¨uten und der
Bl¨utenst¨ande. Eugen Ulmer: Stuttgart (1981).
5.6
Steiner, G.: Spiegelsymmetrie der Tierk¨orper. In: Naturwis-
senschaftliche Rundschau 32 (1979), pp.
481–485; ¨Uber die
Symmetrie bei Tieren. In: Stork [5.4], pp. 187–211.
5.7
See also Doczi, C.: The Power of Limits. Shambhala Publica-
tions: Boulder Colorado (1981).
5.8
Haeckel, E.: Kunstformen der Natur. Verlag des Bibliographis-
chen Instituts: Leipzig/Vienna (1899).
5.9
Thompson, D.W.: On Growth and Form. Birkh¨auser: Basel
(1973).
5.10 For a survey cf. Depew, D.J. Weber, B.H. (eds.): Evolution
at a Crossroads. The New Biology and the New Philosophy
of Science. M.I.T. Press: Cambridge Mass. (1985); Eberling,
W. Feistel, R.: Physik der Selbstorganisation und Evolution.
Akademischer Verlag: Berlin (1982); Haken, H. Haken-Krell,
M.:
Entstehung von biologischer Information und Ordnung.
Wissenschaftliche Buchgesellschaft:
Darmstadt (1989); Hof-
bauer, L.: Evolutionstheorie und dynamische Systeme. Mathe-
matische Aspekte der Selektion. Springer: Berlin (1984).
5.11 Eigen, M. Schuster, P.: The Hypercycle: A Principle of Natural
Self-Organization. Springer: Berlin (1979).
5.12 Levin, S.A.: Complex adaptive systems: Exploring the known,

404
Symmetry and Complexity
the unknown and the unknowable. In: Bulletin of the Amer-
ican Mathematical Society 40 (2002), pp. 3–19; Scott [3.36],
chapt. 4.7.4.
5.13 Eigen. M. Winkler, R.: Das Spiel. Naturgesetze steuern den
Zufall.
Piper: Munich/Z¨urich (1975), pp.
272 ﬀ.; cf.
also
K¨uppers, B.-O.: Der Ursprung biologischer Information. Piper:
Munich/Z¨urich (1986), pp. 214 ﬀ.
5.14 Eigen, M.: Self-organization of matter and the evolution of bi-
ological macromolecules.
In: Naturwissenschaften 58 (1971),
p.
465; K¨uppers [5.13], pp.
216 ﬀ.
For simpliﬁcation the
sum term 
j ϕijxj has been left.
It designates the popula-
tion contribution made by all species xj̸=i on account of reverse
mutations to the original sequence xi.
5.15 Wright, S.: “Surfaces” of selection value. In: Proceedings of the
National Academy of Sciences of the United States of America
58 (1967), p. 165; Die Entstehung des Lebens. In: Natur 3
(1983), p. 68; Eigen, M.: Homunculus im Zeitalter der Biotech-
nologie — Physikochemische Grundlagen der Lebensvorg¨ange.
In: Gross, R. (ed.): Geistige Grundlagen der Medizin. Springer:
Berlin (1985), pp. 24 ﬀ.
5.16 For a survey on nonlinear models of DNA cf.
Yakushevich,
L.V.:
Nonlinear Physics of DNA. John Wiley:
Chichester
(1998); Krumhansl, J.A.: The intersection of nonlinear science,
molecular biology, and condensed matter physics. Viewpoints.
In: Peyrard, M. (ed.): Nonlinear Excitations in Biomolecules.
Springer: Berlin (1995), pp. 1–9.
5.17 Watson, J.D.: Molecular Biology of the Gene. Benjamin: New
York (1970).
5.18 For a survey cf.
Kauﬀmann, A.S.: Origins of Order.
Self-
Organization and Selection in Evolution.
Oxford University
Press: Oxford (1992).
5.19 Baas, N.A.: Emergence, Hierarchies, and Hyperstructures. In:
Langton, C.G. (ed.): Artiﬁcial Life III. Addison-Wesley: Read-
ing Mass. (1994).
5.20 Cf. also Nicolis, J.S.: Dynamics of Hierarchical Systems. An
Evolutionary Approach.
Springer: Berlin (1986); Voorhees,

References
405
B.H.: Axiomatic theory of hierarchical systems. In: Behavioral
Science 28 (1983), pp. 24–34; Scott [3.36], p. 427.
5.21 Cf.
also Rosen, R.:
Dynamical System Theory in Biology.
Wiley-Interscience: New York (1970).
5.22 Meinhardt, M.: Models of Biological Pattern Formation. Aca-
demic Press: London (1982).
5.23 Meinhardt, H. Gierer, A.: Application of a theory of biological
pattern formation based on lateral inhibition. In. Journal of
Cell Science 15 (1974), p. 321.
5.24 Bassingthwaite, J.B. van Beek, J.H.G.M.: Lightning and the
heart: Fractal behavior in cardiac function. In: Proceedings of
the IEEE 76 (1988), p. 696.
5.25 Actually, heart research was one of the ﬁrst medical applica-
tions of chaos theory. Cf. also Goldberger, A.L. Bhargava, V.
West, B.J.: Nonlinear dynamics of the heartbeat. In: Physica
17D (1985), pp. 207–214; Winfree, A.T.: When Time Breaks
Down: The Three-Dimensional Dynamics of Electrochemical
Waves and Cardiac Arrhythmias. Princeton University Press:
Princeton (1987).
5.26 Churchland, P.S. Sejnowski, T.J.: Perspectives in cognitive neu-
roscience. In: Science 242 (1988), pp. 741–745. The subset of
visual cortex is adapted from van Essen, D. Maunsell, J.H.R.:
Two-dimensional maps of the cerebral cortex. In: Comparative
Neurobiology 191 (1980), pp.
255–281.
The network model
of ganglion cells is given in Hubel, D.H. Wiesel, T.N.: Recep-
tive ﬁelds, binocular interaction and functional architecture in
the cat’s visual cortex. In: Journal of Physiology 160 (1962),
pp.
106–154.
An example of chemical synapses is shown in
Kandel, E.R. Schwartz, J.: Principles of Neural Science. Else-
vier: New York (1985).
5.27 Hodgekin, A.L. Huxley, A.F.:
A quantitative description of
membrane current and its application to conduction and ex-
citation in nerve.
In:
Journal of Physiology 117 (1952),
pp. 500–544.
5.28 Hodgekin [5.27];
Huxley, A.F.:
Can a nerve propagate a

406
Symmetry and Complexity
subthreshold disturbance?
In:
Journal of Physiology 148
(1959), pp. 80P–81P; cf. also Scott [3.36], p. 126.
5.29 Cf.
Scott, A.C.:
Neuroscience.
A Mathematical Primer.
Springer: New York (2002).
5.30 Hebb, D.O.: The Organization of Behavior. John Wiley: New
York (1949).
5.31 von der Malsburg, C.:
Self-Organization of orientation sen-
sitive cells in the striate cortex.
In: Kybernetik 14 (1973),
pp. 85–100; Wilshaw, D.J. von der Malsburg, C.: How pat-
terned neural connections can be set up by self-organization.
In.
Proceedings of the Royal Society series B 194 (1976),
pp. 431–445.
5.32 Barlow, H.B.: Single units and sensatioperceptual psychology.
In: Perception 1 (1972), p. 371.
5.33 Singer, W.: The role of synchrony in neocortical processing and
synaptic plasticity. In: Domany, E. van Hemmen, L. Schulten,
K. (eds.): Model of Neural Networks II. Springer: Berlin (1994).
5.34 For the emergence of consciousness cf.
Mainzer, K.: Philo-
sophical concepts of computational neuroscience.
In:
Eck-
miller, R. Hartmann, G. Hauske, G. (eds.): Parallel Processing
in Neural Systems and Computers.
North-Holland: Amster-
dam/New York (1990), pp.
9–12; Gehirn, Computer, Kom-
plexit¨at. Springer: Berlin (1997); Flohr, H.: Brain processes
and phenomenal consciousness. A new and speciﬁc hypothe-
sis. In: Theory & Psychology 1 (1991), p. 248; Scott, A.C.:
Stairway to the Mind. Copernicus: New York (1995).
5.35 Freeman, W.:
Noise-induced ﬁrst-order phase transitions in
chaotic brain activity.
In: International Journal of Bifurca-
tion and Chaos 9 No. 11 (1999), pp. 2215–2218; A proposed
name for aperiodic brain activity: stochastic chaos. In: Neural
Networks 13 (2000), pp. 11–13.
5.36 Freeman, W. et al.: A neurobiological theory of meaning in
perception I–V. In: International Journal of Bifurcation and
Chaos 13 (2003); How Brains make up their Minds. Columbia
University Press: New York (2001).
5.37 Rettenmeyer, C.W.: Behavioral studies of army ants. In: Uni-

References
407
versity of Kansas Science Bulletin 44 (1963), p. 281; Prigogine,
I.: Order through ﬂuctuation: Self-organization and social sys-
tem. In: Jantsch, E. Waddington, C.H. (eds.): Evolution and
Consciousness. Human systems in transition. Addison-Wesley:
London (1976), p. 108.
5.38 Cf. Johnson, L.: The thermodynamic origin of ecosystems: A
tale of broken symmetry. In Weber, B.H. Depew, D.J. Smith,
J.D. (eds.): Entropy, Information, and Evolution.
New Per-
spectives on Physical and Biological Evolution. M.I.T. Press:
Cambridge Mass. (1988), pp. 75–105; Schneider, E.D.: Ther-
modynamics, ecological succession, and natural selection: A
common thread. In: Weber [5.38], pp. 107–138.
Chapter 6
6.1
Hobbes, T.: The Elements of Law Natural and Politic (1640).
Ed.
by F. T¨onnies.
Simpkin, Marshall, and Co.:
London
(1889); Leviathan, or the Matter, Form and Power of a Com-
monwealth, Ecclesiastical and Civil (1651).
Ed.
by C.B.
MacPherson. Penguin: Harmondsworth (1968); Gough, J.W.:
The Social Contract.
A Critical Study of its Development.
Clarendon Press: Oxford (1957).
6.2
Meek, R.L.: The interpretation of the “Tableau ´economique”.
In: Economica 27 (1960), pp. 322–347.
6.3
Smith, A.: An Inquiry into the Nature and Causes of the Wealth
of Nations.
Ed. By E. Cannan. The University of Chicago
Press: Chicago (1976).
6.4
Mayr, O.:
Adam Smith und das Konzept der Regelung.
In:
Troitzsch, U. Wohlauf, G. (eds.):
Technikgeschichte.
Suhrkamp: Frankfurt (1980), p. 245.
6.5
Cf.
Walras, L.:
Principe d’une th´eorie math´ematique de
l’echange. In: Journal des Economistes 33 (1874), pp. 1–21;
Hicks, J.: L´eon Walras. In: Classics and Moderns. Collected
Essays on Economic Theory. Vol. III. Basil Blackwell: Oxford
(1983), pp. 85–95.
6.6
von Neuman, J. Morgenstern, O.: Theory of Games and Eco-
nomic Behavior. Princeton University Press: Princeton (1943).

408
Symmetry and Complexity
6.7
Shubik, M.: Game Theory and Related Approaches to Social
Behavior. John Wiley: New York (1964).
6.8
Nash, J.: Noncooperative games. In: Annals of Mathematics
54 (1951), pp. 289–295.
6.9
Cf.
also van Damme, E.: Stability and Perfection of Nash
Equlibrium.
Springer:
Berlin (1987); Bicchieri, C.:
Game
theory: Nash equilibrium.
In: Floridi, L. (ed.): Philosophy
of Computing and Information.
Blackwell:
Oxford (2004),
pp. 289–304.
6.10 Harsanyi, J. Selten, R.:
A General Theory of Equilibrium
Selction in Games. M.I.T. Press: Cambridge Mass. (1987).
6.11 Hofbauer, J. Sigmund, K.: Evolutionary Games and Population
Dynamics. Cambridge University Press: Cambridge (1998).
6.12 Maynard Smith, J.: Evolution and the Theory of Games. Cam-
bridge University Press: Cambridge (1982).
6.13 Cf. Mainzer [3.32], chapt. 8.
6.14 Weidlich, W.: Synergetic modelling concepts for sociodynamics
with application to collective political opinion formation. In:
Journal of Mathematical Sociology 18 (1994), pp. 267–291.
6.15 Henderson, J.M. Quandt, R.E.: Microeconomic Theory — A
Mathematical Approach. McGraw-Hill: London (1980); Nichol-
son, W.: Microeconomic Theory — Basic Principles and Exten-
sions. The Dryden Press: Fort Worth Texas (1992); Varain,
H.R.:
Microeconomic Analysis.
W.W. Norton:
New York
(1992).
6.16 The concept of “bounded rationality” was introduced by Simon,
H.A.: Models of Bounded Rationality. 2 vols. M.I.T. Press:
Cambridge Mass. (1982).
6.17 Cf.
Sterman, J.D.: Business Dynamics.
Systems Thinking
and Modeling for a Complex World.
McGraw-Hill:
Boston
(2000); Weidlich, W.: Sociodynamics. A Systematic Approach
to Mathematical Modelling in the Social Sciences.
Taylor
& Francis:
London (2002); Auyang, S.Y.:
Complex-System
Theories in Economics, Evolutionary Biology, and Statistical
Physics. Cambridge University Press: Cambridge (1998); Wei-
Bin Zhang: Synergetic Economics — Time and Change in Non-

References
409
linear Economics.
Springer: Berlin (1991); Goodwin, R.M.:
Chaotic Economic Dynamics. Oxford University Press: New
York (1990); Anderson, P.W. Pines, D. (eds.): The Economy
as an Eolving Complex System.
Addison-Wesley: Redwood
City (1988).
6.18 Weidlich, W. Braun, M.: The master equation approach to
nonlinear economics. In: Journal of Evolutionary Economics 2
(1992), pp. 233–265.
6.19 Mayntz, R.: The inﬂuence of natural science theories on con-
temporary social science. In: Dierkes, M. Bievert, B. (eds.):
European Social Science in Transition.
Campus: Frankfurt
(1992), pp. 27–79.
6.20 T¨onu, P.: Nonlinear Economic Dynamics.
Springer: Berlin
(1992); Barnett, W.A. Geweke, J. Shell, K. (eds.): Economic
Complexity.
Chaos, Sunspots, Bubbles, and Nonlinearity.
Cambridge University Press: Cambridge (1990); Brian Arthur,
W. Durlauf, N.S. Lane, D.L. (eds.), The Economy as an Evolv-
ing Complex System II. Proceedings Volume of the Santa F´e In-
stitute. Vol. XXVII. Addison-Wesley: Reading Mass. (1997);
Lorenz, H.-W.: Nonlinear Dynamical Economics and Chaotic
Motion. Springer: Berlin (1989).
6.21 Weidlich [6.17], p. 224, Fig. 7.1.
6.22 Dendrinos, D.S. Sonis, M.: Chaos and Socio-Spatial Dynam-
ics.
Springer:
Berlin (1990); Pumain, D.:
Spatial Analy-
sis and Population Dynamics.
John Libbey Eurotext: Mon-
trouge/London/Wien (1991); Lee, E.S.: A theory of migration.
In: Demography (1966), pp. 47–57.
6.23 Haag, G. Dendrinos, D.S.: Toward a stochastic dynamical the-
ory of location: (A) A nonlinear migration process. In: Geo-
graphical Analysis 15 (1983), pp. 269–286.
6.24 Weidlich, W. Haag, G. (eds.): Interregional Migration — Dy-
namic Theory and Comparative Analysis.
Springer:
Berlin
(1988); Weidlich [6.17], p. 92, Fig. 4.2.
6.25 Weidlich [6.17], p. 95, Fig. 4.4.
6.26 Allen, P.M.: Self-organization in the urban system. In: Schieve,
W.C. Allen, P.M. (eds.):
Self-Organization and Dissipative

410
Symmetry and Complexity
Structures. Applications in the Physical and Social Sciences.
University of Texas Press: Austin (1982), pp. 142–146.
6.27 Batty, M. Longley, P.A.: Fractal Cities. Academic Press: Lon-
don (1994); Frankhauser, P.: La fractalit´e des structures ur-
baines. Anthropos: Paris (1994).
6.28 Frankhauser, P. Sadler, R.: Fractal analysis of urban structures.
In: Natural Structures — Principles, Strategies and Models in
Architecture and Nature. Proceedings of the Internernational
Symposium SFB 230. Vol. II. (1992), pp. 57–65.
6.29 White, R. Engelen, G.: Cellular automata and fractal urban
form. A cellular modelling approach to the evolution of urban
land-use oatterns. In: Environment and Planning A 25 (1993),
pp. 1175–1199; Cellular automata as the basis of integrated dy-
namic regional modelling. In: Environment and Planning B 24
(1997), pp. 235–246; The use of constrained cellular automata
of high-resolution modelling of urban land-use dynamics. In:
Environment and Planning B. Planning and Design 24 (1997),
pp. 323–343.
6.30 Helbing, D.: Quantitative Sociodynamics. Stochastic Methods
and Models of Social Interaction Processes. Kluwer Academic
Publishers: Dordrecht (1995).
6.31 Beynon, J. Dunkerley, D. (eds.): Globalization: The Reader.
Athlone: London (2000); O’Rourke, K. Williamson, J.: Glob-
alization and History. M.I.T. Press: Cambridge Mass. (1999);
Lechner, F. Boli, J. (eds.): The Globalization Reader. Black-
well: Oxford (2000).
6.32 Cf.
also Boswell, T.:
Hegemony and Bifurcation Points in
World History. In: Bornschier, V. Chase-Dum, C. (eds.): The
Future of Global Conﬂict. Sage: London (1999), pp. 263–284.
6.33 Therborn, G.: European Modernity and Beyond. The Trajec-
tory of European Societies 1945–2000. Sage: London (1995).
6.34 Cf. Smith [6.3].
6.35 Cf.
also Kaufmann, S.A.:
The Origins of Order — Self-
Organization and Selection in Evolution.
Oxford University
Press: Oxford (1993).

References
411
6.36 Deacon, B.: Global Social Policy: International Organizations
and the Future of Welfare. Sage: London (1997).
6.37 Marx, K. Engels, F.: Das Kommunistische Manifest. Studien-
texte 4. Fink: Munich (1969).
6.38 Mainzer [6.13], chapt. 8; Novotny, H.: Eigenzeit. Entstehung
und Strukturierung eines Zeitgef¨uhls.
Suhrkamp: Frankfurt
(1989).
6.39 Cf. also Friedman, M.: A Theory of the Consumption Function.
Princeton University Press: Princeton (1957).
6.40 Cf. also von Weizs¨acker, C.C.: Logik der Globalisierung. Van-
denhoeck & Ruprecht: G¨ottingen (2003).
6.41 Dunning, J.H.: The Globalization of Business. Routledge: Lon-
don (1993).
6.42 Von Hayek, F.A.: Notes on the evolution of systems of rules
of conduct. In: von Hayek, F.A.: Studies in Philosophy and
Economics. Routledge: London (1967), pp. 66–81; The Road
of Serfdom. Routledge: London (1945).
6.43 O’Briek, R. Goetz, A.M. Scholte, J.A. Williams, M.: Consulting
Global Governance. Cambridge University Press: Cambridge
Mass. (2000); Weiss, T.G.: Governance, good governance and
global governance. Conceptual and actual challenges. In: Third
World Quarterly 21 (2000), pp. 795–814.
6.44 Easterly, W.: The Eﬀect of IMF and World Bank Programs on
Poverty. Oxford University Press: Oxford (2001); Dunkley, G.:
The Free Trade Adventure: The WTO, GATT and Globalism.
A Critique. Zed: London (1999).
6.45 Meadows, D.H. et al.: The Limits to Growth. Universe Books:
New York (1972); Randers, J. Meadows, D.: System Simula-
tion to Test Environmental Policy I: A Sample Study of DDT
Movement in the Environment. M.I.T. Press: Cambridge Mass.
(1971).
6.46 Siebert,
H.:
¨Okonomische Theorie der Umwelt.
Mohr:
T¨ubingen
(1978);
Mainzer,
K.
(ed.):
¨Okonomie
und
¨Okologie/Economie et Ecologie. Haupt: Bern (1993).
6.47 Castles, F.G.:
Ethnicity and Globalization.
Sage:
London
(2000).

412
Symmetry and Complexity
6.48 Chua, A.: World on Fire. Doubleday: New York (2003).
6.49 Kant, I: Zum ewigen Frieden (1795).
In: Kants gesammelte
Schriften.
Ed.
by K¨oniglich Preußische Akademie der Wis-
senschaften. Bd. VIII. De Gruyter: Berlin (1912/1923).
6.50 Cf. also Holden, B. (ed.): Global Democracy: Key Debates.
Routledge:
London (2000); Beck, U.:
World Risk Society.
Polity Press: Cambridge Mass. (2000).
6.51 Cf. also chapt. 7.1 of this book.
6.52 Dierkes, M. Berthoin Antal, A. Child, J. Nonaka. I.: Hand-
book of Organizational Learning & Knowledge. Oxford Uni-
versity Press: Oxford (2001); Mainzer, K.: Vom Komplexit¨ats-
zum Kreativit¨atsmanagement. Auf Talentsuche in der Wissens-
gesellschaft. In: G¨otz, K. (ed.): Personalarbeit der Zukunft.
Managementkonzepte DaimlerChrysler. Vol. 27. Hampp Ver-
lag: Munich (2002), pp.13–25.
Chapter 7
7.1
Shannon, C.E. Weaver, W.: The Mathematical Theory of Com-
munication.
University of Illinois Press: Chicago (1949); cf.
also Cover T. Thomas, J.: Elements of Information Theory.
John Wiley & Sons: New York (1991).
7.2
Cf. also Carrington, G.: Basic Thermodynamics. Oxford Uni-
versity Press: Oxford (1994).
7.3
Cf. Deco, G. Sch¨urmann, B.: Information Dynamics. Founda-
tions and Applications. Springer: Berlin (2001), chapt. 3.
7.4
Cf. the early analysis of Jaynes, E.T.: Information theory and
statistical mechanics. In: Physical Review 106 (1957), p. 620.
7.5
Cf. Ebeling, W. Freund, J. Schweitzer, F.: Komplexe Struk-
turen: Entropie und Information. Teubner: Stuttgart/Leipzig
(1998).
7.6
Benett, C.H.:
Quantum information and computation.
In:
Physics Today 10 (1995), pp. 24–30.
7.7
von Weizs¨acker, C.F.: Aufbau der Physik. Dtv: Munich (3rd
ed. 1994).
7.8
Cf.
also Feistel, R. Eberling, W.:
Evolution of Complex

References
413
Systems. Kluwer: Dordrecht (1989); Klimontovich, Y.: Statis-
tical Theory of Open Systems. Kluwer: Dordrecht (1995).
7.9
Adamii,
C.:
Learning and Complexity in Genetic Auto-
Adaptive Systems. In: Physica D 80 (1995), pp. 154–170.
7.10 Eberling, W. Volkenstein, M.V.: Entropy and the evolution of
biological information. In: Physica A 163 (1990), p. 398.
7.11 Sagan, C.:
Die Drachen von Eden.
Das Wunder der men-
schlichen Intelligenz. Droemer Knaur: Munich/Zurich (1978):
cf. also Gould, S.J.: The Book of Life. W.W. Norton: New
York (1993).
7.12 Churchland, P.S. Sejnowski, T.J.: The Computational Brain.
M.I.T. Press: Cambridge Mass. (1992); Mainzer [5.34].
7.13 Cf.
H¨olldobler, B.: Vom Verhalten zum Gen.
Die Soziobi-
ologie eines Superorganismus. In: Nova Acta Leopoldina NF
76303 (1997), pp.
205–223.
Historically, the concept of a
“superorganism” was introduced by Wheeler, W.M.: The ant-
colony as an organism. In: Journal of Morphology 22 (1911),
pp. 307–325.
7.14 Cf. Mainzer, K.: KI — K¨unstliche Intelligenz. Grundlagen in-
telligenter Systeme. Wissenschaftliche Buchgesellschaft: Darm-
stadt (2003).
7.15 Mainzer [6.13], p. 81.
7.16 Hawking, S.W.: The Universe in a Nutshell. Bantam Books:
New York (2001). The path integral was suggested in a paper of
Hawking during the 17th International Conference on General
Relativity and Gravitation: July 25, 2004 at Dublin.
7.17 Turing, A.M.: On computable numbers, with an application
to the “Entscheidungsproblem.” In: Proceedings of the Lon-
don Mathematical Society Series 2 42 (1936), pp.
103–105;
Teuscher, C. (ed.): Alan Turing: The Life and Legacy of a
Great Thinker. Springer: Berlin (2004).
7.18 Wegener, I.: Complexity Theory. Limiting Factors on the Ef-
ﬁciency of Algorithms.
Springer: Berlin (2004); Hromkovic,
J.:
Theoretical Computer Science.
Introduction to Au-
tomata, Computability, Complexity, Algorithmics, Randamiza-
tion, Communication, and Cryptography.
Springer:
Berlin

414
Symmetry and Complexity
(2004); Homer, S. Selman, A.L.: Computability and Complex-
ity Theory. Springer: New York (2001).
7.19 Chaitin, G.J.: On the length of programs for computing ﬁnite
binary sequences. In: Journal of the ACM 13 (1966), pp. 547–
569; On the length of programs for computing ﬁnite binary
sequences: statistical considerations. In: Journal of the ACM
16 (1969), pp. 145–159.
7.20 Chaitin, G.J.: The Limits of Mathematics: A Course on Infor-
mation Theory and the Limits of Formal Reasoning. Springer:
New York (1998); Calude, C.S.: Information and Randomness.
An Algorithmic Perspective.
Springer:
New York (2nd ed.
2002).
7.21 Cf.
Bennett [7.6]; Hirvensalo, M.:
Quantum Computing.
Springer: New York (2nd ed. 2004).
7.22 Deutsch, D.: Quantum theory, the Church-Turing principle and
the universal quantum computer. In: Proc. Roy. Soc. A 400
(1985). pp. 97–117.
7.23 Bouwmeester, A.E. Zeilinger, A. (eds.): The Physics of Quan-
tum Information.
Springer:
Berlin (2000); Nielsen, M.A.
Chuang, I.L.: Quantum Computation and Quantum Informa-
tion. Cambridge University Press: Cambridge (2001); Lo, H.-K.
Popesku, S. Spiller, T. (eds.): Introduction to Quantum Com-
putation and Information. World Scientiﬁc: Singapore (1998).
7.24 Audretsch,
J.
Mainzer,
K.
(eds.):
Wieviele
Leben
hat
Schr¨odingers Katze?
Zur Physik und Philosophie der Quan-
tenmechanik. Spektrum: Heidelberg (1996).
7.25 Adleman, L.M.: Molecular computation of solutions to com-
binatorical problems. In: Science 266 (1994), pp. 1021–1024;
Lipton, R.J.: DNA solutions of hard computational problems.
In: Science 268 (1995), pp. 542–545.
7.26 von Neumann, J.: The Computer and the Brain.
Yale Uni-
versity Press: New Haven (1958); Burks, A.W. (ed.): Essays
on Cellular Automata.
University of Illinois Press: Urbana-
Champaign Ill. (1970).
7.27 Wolfram, S.: Universality and complexity in cellular automata.
In: Farmer, D. Toﬀoli, T. Wolfram, S. (eds.): Proceedings of

References
415
an Interdisciplinary Workshop.
North-Holland:
Amsterdam
(1984).
7.28 Mainzer, K.:
Komplexit¨at in der Natur.
In:
Nova Acta
Leopoldina NF 76 No. 303 (1997), pp. 165–189.
7.29 Wolfram, S.: A New Kind of Science.
Wolfram Media Inc.:
Champaign, Ill. (2002), p. 443.
7.30 Wolfram [7.29], p. 737.
7.31 McCulloch, W.S. Pitts, W.: A logical calculus of the ideas im-
manent in nervous activity. In: Bulletin of Mathematical Bio-
physics 5 (1943), pp. 115–133.
7.32 Rosenblatt, F.: The perceptron: A probabilistic model for infor-
mation storage and organization in the brain. In: Psychological
review 65 (1958), pp. 386–408.
7.33 Minsky, M. Papert, S.A.: Perceptrons. M.I.T Press: Cambridge
Mass. (1969) (expanded ed. 1988).
7.34 Hopﬁeld, J.J.: Neural Network and physical systems with emer-
gent collective computational abilities. In: Proceedings of the
National Academy of Sciences 79 (1982), pp. 2554–2558.
7.35 Rummelhart, D.E. Smolensky, P. McClelland, J.L. Hinton,
G.E.: Schemata and sequential thought processes. In: McClel-
land, J.L. Rumelhart, D.E. (eds.): Parallel Distributed Process-
ing: Explorations in the Microstructure of Cognition.
Vol.2:
Applications. M.I.T Press: Cambridge Mass. (1986); Church-
land, P.S.: Neurophilosophy. Toward a Uniﬁed Science of the
Mind-Brain. M.I.T. Press: Cambridge Mass. (1988), p. 465.
7.36 Chua, L.O.: CNN: A Paradigm for Complexity. World Scien-
tiﬁc: Singapore (1998); Mainzer, K.: CNN and the evolution of
complex information systems in nature and society. In: Tetzlaﬀ,
R. (ed.): Cellular neural networks and their applications. Pro-
ceedings of the 7th IEEE International CNN Workshop. World
Scientiﬁc: Singapore (2002), pp. 483–497.
7.37 Chua, L.O. Yang, L.: Cellular neural networks: Theory. In:
IEEE Transactions on Circuits and Systems 35 (1988), pp.
1257–1272; Cellular neural networks: Applications. In: IEEE
Transactions on Circuits and Systems 35 (1988), pp. 1273–1290.
7.38 Chua, L.O. Roska, T.: Cellular Neural Networks and Visual

416
Symmetry and Complexity
Computing: Foundations and Applications.
Cambridge Uni-
versity Press: Cambridge (2002), p. 7 (Fig. 2.1), p. 8 (Fig.
2.2); Mainzer, K.: Cellular neural networks and visual com-
puting: Foundations and applications according to the book of
Leon O. Chua and Tam´a Roska. In: International Journal of
Bifurcation and Chaos in Applied Sciences and Engineering 13
1 (2003), pp. 1–6.
7.39 Chua [7.36], Fig. 2.6.24, p. 74.
7.40 Mainzer
[7.14];
Mainzer,
K.:
Computerphilosophie
zur
Einf¨uhrung. Junius Verlag: Hamburg (2003).
7.41 Dadam, P.: Verteilte Datenbanken und Client/Server-Systeme.
Springer: Berlin (1996), p. 26; Mainzer, K.: Computernetze
und virtuelle Realit¨at. Springer: Berlin (1999), p. 31.
7.42 Itoh, M. Chua, L.O.: Star cellular neural networks for asso-
ciative and dynamic memories.
In: International Journal of
Bifurcation and Chaos in Applied Sciences and Engineering 14
5 (2004), pp. 1725–1772.
7.43 Itoh [7.42], Fig. 3, p. 1730.
7.44 Christos, G.: Memory and Dreams. Rutgers University Press:
New Brunswic/New Jersey/London (2003).
7.45 Itoh [7.42], Fig. 19, p. 1754.
7.46 Bollob´as, B.:
Random Graphs.
Academic Press:
London
(1985); Albert, R. Barab´asi, A.-L.: Statistical mechanics of
complex networks. In: Reviews of Modern Physics 74 1(2002),
pp. 47–97.
7.47 Watts, D.J.: Small Worlds: The Dynamics of Networks between
Order and Randomness. Princeton University Press: Princeton
NJ (1999).
7.48 Wasserman, S. Faust, K.: Social Network Analysis: Methods
and Applications.
Cambridge University Press:
Cambridge
(1994).
7.49 Albert [7.46], Fig. 1, p. 51.
7.50 Halabi, B.: Internet-Routing-Architekturen: Grundlagen, De-
sign und Implementierung. Carl Hanser Verlag: Munich (1998);
Calvert, K.M. Doar, M.B. Zegura, E.W.: Modeling Internet

References
417
topology.
In: IEEE Transactions Communication 1 (1997),
p. 160.
7.51 Fukuda, K. Takayasu, H. Takayasu, M.: Spatial and tempo-
ral behavior of congestion in internet traﬃc. In: Fractals 7 1
(1999), p. 67.
7.52 Mainzer, K. B¨uchs, M. Kundish, D. Pyrka, P.: Physical and
virtual mobility: Analogies between traﬃc and virtual high-
ways. In: Mayinger, F. (ed.): Mobility and Traﬃc in the 21st
Century. Springer: Berlin (2001), pp. 243–318.
7.53 Takayasu, M. Takayasu, H. Sato, T.: Critical behaviors and 1/f
noise in information traﬃc. In: Physica A 233 (1996), Fig. 1,
p. 825.
7.54 Crestani, F. Pasi, G. (eds.):
Soft Computing in Informa-
tion Retrieval: Techniques and Applications. Physica Verlag
(Springer): Heidelberg (2000).
7.55 Weiser, T.: The computer for the 21st century. In: Scientiﬁc
American 9 (1999), p. 66; Norman, D.A.: The Invisible Com-
puter. Cambridge University Press: Cambridge (1998).
7.56 Mainzer, K.: Self-organization and emergence in complex dy-
namical systems.
Interdisciplinary perspectives for organic
computing. In: 34. Jahrestagung der Gesellschaft f¨ur Infor-
matik. INFORMATIK 2004 Ulm.
7.57 Hofmann, P.E.H. et al.: Evolution¨are E/E-Architekturen. Vi-
sion einer neuartigen Elektronik-Architektur f¨ur Fahrzeuge.
DaimlerChrysler: Esslingen (2002).
Chapter 8
8.1
Aristotle: The Categories, On Interpretation, Prior Analytics.
Harvard University Press: Cambridge Mass. (1938).
8.2
Cf. Bochenski, I.M. Church, A. Goodman, N.: The Problem of
Universals. A Symposium. Notre Dame, Indiana (1956); Quine,
W.V.O.: Ontological Relativity and other Essays. Columbia
University Press: New York/London (1969).
8.3
Bourbaki, N.:
Elements of Mathematics:
Theory of Sets.
[´El´ements de Math´ematique:
Th´eorie des Ensembles].
Her-
mann: Paris (1968); Ebbinghaus [1.11].

418
Symmetry and Complexity
8.4
Cf. Bourbaki [8.3], note 61, chapt. IV; Scheibe, E.: Invariance
and covariance.
In: Agassi, J. Cohen, R.S. (eds.): Scientiﬁc
Philosophy Today. Kluwer: Boston (1981), pp. 311–331.
8.5
Carnap, R.: Der logische Aufbau der Welt. Weltkreis: Berlin
(1928), repr. Meiner: Hamburg (1974).
8.6
For the structuralistic view of symmetry cf. van Fraassen, B.C.:
Laws and Symmetry.
Clarendon Press:
Oxford (1989) and
Mainzer, K.: Symmetry of Nature. De Gruyter: Berlin/New
York (1996) [German: 1988], chapt. 5.3.
8.7
The semantic view dates back to P. Suppes [e.g., What is a
scientiﬁc theory?
In: Morgenbesser, S. (ed.): Philosophy of
Science Today. Basic Books: New York (1967)] and decribes
the mathematical practise of modeling.
Cf.
also Suppe, F.:
The Semantic Conception of Theories and Scientiﬁc Realism.
University of Illinois Press: Urbana Ill. (1988); Giere, R.: Un-
derstanding Scientiﬁc Reasoning.
Holt, Rinehart, and Win-
ston: New York (1979). Stegm¨uller emphasized structuralism
as “non-statement view” in Stegm¨uller, W.: The Structuralistic
View of Theories. Springer: Berlin (1979); cf. also Moulines,
C.U.: Approximate application of theories. In: Erkenntnis 10
(1976), pp. 201–227.
8.8
Cf.
also Scheibe, E.:
Struktur und Theorie in der Physik.
In: Audretsch, J. Mainzer, K. (eds.): Philosophie und Physik
der Raum-Zeit. B.I. Wissenschaftsverlag: Mannheim (2nd ed.
1996), pp. 103–120.
8.9
Ludwig, G.: Die Grundstrukturen einer physikalischen Theorie.
Springer: Berlin (1978), §10, §12.
8.10 Ludwig [8.9], §8.
8.11 Cf., e.g., Derrida, J. Rorty, R.: Objectivity, Relativism and
Truth.
Philosophical Papers I. Cambridge University Press:
Cambridge (1991).
8.12 Mainzer [8.6], chapt.
5.3 and chapt.
5.42; cf.
also Emch,
G.G.: Mathematical and Conceptual Foundations of 20th Cen-
tury Physics. North-Holland: New York/Oxford (1984).
8.13 Mainzer, K.: System. An introduction to systems science. In:

References
419
Floridi, L. (ed.): Philosophy of Computing and Information.
Blackwell Publishing: Oxford (2004), pp. 28–39.
8.14 Cf. Mainzer [3.32].
8.15 Bergson, H.: Dur´ee et simultan´et´e.
A propos de la th´eorie
d’Einstein.
F´elix Alcan:
Paris (1922).
Bergson related his
concept of duration to Einstein’s concept of relativity which
is misleading. Prigogine interpreted Bergson’s “dur´ee” for his
operator approach in Prigogine (1980) [3.31].
8.16 The concept of relative computability is analyzed in my Ph.D.
thesis “Mathematical Constructivism” (University of M¨unster
1973) and later in Mainzer [7.40], chapt. 3.
8.17 Peter of Spain [Petrus Hispanus]: Summulae Logicales. Ed. by
I.M. Bochenski. Marietti: Turin (1947).
8.18 Mainzer [7.41], chapt. 3.
8.19 Sowa, J.F.: Knowledge Representation. Logical, Philosophical,
and Computational Foundations. Brooks/Cole: Paciﬁc Grove
(2000).
8.20 Broy, M./Steinbr¨uggen, R.: Modellbildung in der Informatik.
Springer: Berlin (2004).
8.21 Petri, C.A.: Kommunikation mit Automaten. [Diss. University
of Bonn]. Bonn (1962); Best, E. Devillers, R. Koutny, M.: Petri
Net Algebra. Springer: Berlin (2001).
8.22 My deﬁnition of actual and potential models is logical-
mathematical and depends on theoretical structures. But, in a
heuristical sense, it can also be related to Leibniz’s distinction of
“possible worlds” and Aristotle’s distinction of “actualization”
and “potentiality”.
8.23 Cf. also Huntley, H.E.: The Devine Proportion: A Study in
Mathematical Beauty. Dover: New York (1970).
8.24 Cf. Hambidge, J.: Dynamic Symmetry. The Greek Vase. Yale
University Press: New Haven (1920); for pyramid construction
cf. Stecchini, L.C.: Notes on the relation of ancient measure
to the great pyramid. In: Tomkins, P.S. (ed.): The Secrets of
the Great Pyramid. Harper & Row: New York (1978), p. 368;
Dominguez, M.A.: La Architectura Precolumbina en Mexico.
Mexico D.F., Orion (1956).

420
Symmetry and Complexity
8.25 Diels-Kranz [1.19], I 293 c. 27; Diels, H.: Antike Technik. Teub-
ner: Leipzig/Berlin (1924), pp. 15f.
8.26 von Steuben, H.: Der Kanon des Polyklet.
Doryphoros und
Amazone: T¨ubingen (1973).
8.27 Vitruvius: De architectura.
Ed.
by C. Fensterbusch.
Wis-
senschaftliche Buchgesellschaft: Darmstadt (1964), I, 2.4; cf.
also Knell, H.: Grundz¨uge der griechischen Architektur. Wis-
senschaftliche Buchgesellschaft: Darmstadt (1980).
8.28 In that connection also Kepes, G. (ed.): Symmetry, Rhythm.
George Braziller: New York (1966).
8.29 Michell, G.: Der Hindu-Tempel. Bauformen und Bedeutung.
DuMont: Cologne (1979), p. 71 ﬀ.; likewise Brown, P.: Indian
Architecture.
Vol.
1: Buddhist and Hindu Periods.
Tara-
porevala: Bombay (5th ed.
1965); for Indian sacral geome-
try, cf.
also Michaels, A.: Beweisverfahren in der vedischen
Sakralgeometrie.
Ein Beitrag zur Entstehungsgeschichte von
Wissenschaft. Franz Steiner: Wiesbaden (1978).
8.30 Cf. also Doczi, G.: The Power of Limits. Shambhala: Boulder
Colorado (1981), pp. 134 ﬀ.
8.31 Vogt-G¨ognil,
U.:
Die
Moschee-Grundformen
sakraler
Baukunst. Artemis: Zurich (1978), pp. 111 f.
8.32 In that connection also, Golvin, L.: Essai sur l’architecture
religieuse Musulmane. 3 vols. Klincksieck: Paris (1970–1974).
8.33 Panofsky, E.: Architecture and Scholasticism. Faber and Faber:
Latrobe (1951).
8.34 Cf. Siebenh¨uhner, H.: Deutsche K¨unstler am Mail¨ander Dom.
Bruckmann: Munich (1944); Bascape, G. Mezzanotte, P.: Il
Duomo di Milano.
Bramante: Milan (1965); likewise Acker-
mann, J.S.: Ars sine scientia nihil est. In: The Art Bulletin
XXXI (1949), pp. 84–111.
8.35 Cf. de Bruyne, E.: Etudes d’esth´etique m´edi´evale. 3 vols. De
Tempel: Brugge (1946).
8.36 Cf. Willis, R. (transl. and ed.): Fascimile of the Sketchbook
of Villard de Honnecourt. John Henry and James Parker: Lon-
don (1859). The original west rose window is portrayed, e.g., in

References
421
Swaan, W.: Die großen Kathedralen. DuMont: Cologne (1969),
p. 97.
8.37 Alberti, L.B.: De re aedicatoria. Nicolaus Laurentii Alamani:
Florence (1485), IX, p. 5.
8.38 Vasari, G.: Le vite de pi`u eccelenti pittori scultori ed architet-
tori. Florence (1550). Ed. by G. Milanesi. Sansoni: Florence
(1878), I, pp. 168 f.
8.39 L¨ucke, Th.: Leonardo da Vinci. Tageb¨ucher und Aufzeichnun-
gen. Asmus: Leipzig (1940), p. 480.
8.40 Cf.
also Steiner, R.A.: Theorie und Wirklichkeit der Kunst
bei Leonardo da Vinci. Fink: Munich (1979); on Leonardo’s
accomplishments as scientist, engineer and inventor, cf., e.g.,
Clagett, M.: Leonardo da Vinci and the Medieval Archimedes.
In: Physis 11 (1969), pp. 100–151; Feldhaus, F.M.: Leonardo
der Techniker und Erﬁnder.
Eugen Diederichs:
Jena (2nd
ed.
1922);
Giustini, P.A.:
Da Leonardo a Leibniz.
La
rivoluzione scientiﬁca. Trevisini: Milan (1976); Mittelstraß, J.:
Leonardo-Welt. ¨Uber Wissenschaft, Forschung und Verantwor-
tung. Suhrkamp: Frankfurt (1992).
8.41 Pedretti, C.: A Chronology of Leonardo da Vinci’s Architec-
tural Studies after 1500. E. Droz: Geneva (1962), pp. 143 ﬀ.
8.42 Leonardo da Vinci: Trattato della pittura. Ed. by R. du Fresne.
Jacques Langlois: Paris (1651). Milan (1939).
8.43 Sketch of a human anatomy in the canon of ideal proportions
(Royal Library).
8.44 Pacioli, L.: De divina proportione. Venice (1509), repr. Oﬃcina
Bodoni: Milan (1956).
8.45 Cf. Mainzer [1.8], pp. 70 ﬀ., pp. 134 ﬀ.
8.46 Cf. also Pirenne, M.H.: The Scientiﬁc Basis of Leonardo da
Vinci’s Theory of Perspective. In: British Journal for the Phi-
losophy of Science 3 (1952), pp. 169–185.
8.47 Cf. Schr¨oder, E.: Kunst und Geometrie. D¨urers k¨unstlerisches
Schaﬀen aus der Sicht seiner “Underweysung”.
Akademie-
Verlag: Berlin (1980), pp. 34 ﬀ.
8.48 For the break-up of the artistic canon after the Renaissance,
cf. Wittkower, R.: Architectural Principles in the Age of Hu-

422
Symmetry and Complexity
manism.
Alec Tiranti: London (1962); likewise, Kambartel,
W.: Symmetrie und Sch¨onheit. ¨Uber m¨ogliche Voraussetzun-
gen des neueren Kunstbewußtseins in der Architekturtheorie
Claude Perraults. Fink: Munich (1972).
8.49 Cf. Werker, W.: Studien ¨uber Symmetrie im Bau der Fugen
und die motivische Zusammengeh¨origkeit der Pr¨aludien und Fu-
gen des “Wohltemperierten Klaviers” von J.S. Bach. Breitkopf
& H¨artel: Leipzig (1922).
8.50 Cf. also Werner, E.: Grunds¨atzliche Betrachtungen ¨uber Sym-
metrie in der Musik des Westens. In: Studia Musicologia 11
(1969), p. 486; Mehner, K.: Beitr¨age zum Symmetriebegriﬀ
in der Musik. In: Beitr¨age der Musikwissenschaft 13 (1971),
p. 11.
8.51 Rameau, J.P.: Trait´e de l’harmonie. Ballard: Paris (1722) [En-
glish: Dover: New York 1971].
8.52 Cf.
for the following exposition, Eimert, H.: Lehrbuch der
Zw¨olftontechnik. Breitkopf & H¨artel: Wiesbaden (1966).
8.53 Cf. Budden, F.J.: The Fascination of Groups. Cambridge Uni-
versity Press: Cambridge (1972); Claus, R.: Symmetrie in der
Musik. Zur Anwendung gruppentheoretischer Methoden. In:
Preisinger, A. (ed.): Symmetrie. Springer: Vienna/New York
(1980), p. 70, p. 76.
8.54 Cf. also Solomon, L.J.: Symmetry as a Determinant of Musical
Composition [Diss. West Virginia State University]. Morgan-
town West Virginia (1973).
8.55 In that connection, Claus [8.53], pp. 31 ﬀ.
8.56 Cf. also the discussion by M. Eigen in Eigen [5.13], p. 357.
8.57 Cf. also Claus [8.53], pp. 101 ﬀ.
8.58 van Beethoven, L.: Klaviersonate op. 53. 1st movement, mea-
sures 27–29; in that connection also Claus [8.53], p. 109.
8.59 Sch¨onberg, A.: Herz und Hirn in der Musik. In: Sch¨onberg, A.:
Gesammelte Schriften. Ed. by I. Voitech. Vol. 1. Suhrkamp:
Frankfurt (1976), pp. 104–122.
8.60 Sowa [8.19], p. 15
8.61 Cf. Metzinger, J.: Le cubisme ´etait n´e. Souvenirs. Pr´esance:
Paris (1972): Apollinaire, G.: Le peinture cubiste. Paris (1913).

References
423
The C´ezanne memorial exhibition of 1907 inﬂuenced Picasso
and Braque. The theory of cubism was developed by Metzinger
and Gleizes in their 1912 essay “Du cubisme”.
8.62 Klee, P.: Das bildnerische Denken. Schriften zur Form- und
Gestaltlehre. Ed. by J. Spiller. Schwabe: Basel (1964), p. 79.
8.63 Klee, P.: Exakte Versuche im Bereich der Kunst. In: Bauhaus.
Zeitschrift f¨ur Bau und Gestaltung 2 No. 2/3 (1928).
8.64 Kandinsky, W.: Punkt und Linie zu Fl¨ache. Beitrag zur Anal-
yse der malerischen Elemente. Bauhaus Book No. 9. Albert
Langen: Munich (1926), repr. Benteli: Bern-B¨umplitz (7th ed.
1973).
8.65 Kandinsky, W.:
R¨uckblicke.
Klein:
Baden-Baden (1955),
p. 25.
8.66 Klee, P.: Beitr¨age zur bildnerischen Formlehre.
Ed.
by J.
Glaesemer.
Paul Klee-Stiftung [Kunstmuseum Bern]:
Basel
(1979).
8.67 Cf. also Kagan, A.: Paul Klee: Art and Music. Cornell Uni-
versity Press: Ithaca N.Y. (1983); D¨uchting, H.: Paul Klee.
Malerei und Musik. Prestel: Munich (2001).
8.68 Gropius, W.: Der stilbildende Wert industrieller Bauformen.
In: Jahrbuch des Deutschen Werkbundes (1914), p. 29.
8.69 Le Corbusier: Vers une Architecture. In: Conrads, U. (ed.):
Programme und Manifeste zur Architektur des 20. Jahrhun-
derts. Bauwelt Fundamente. Vol. 1. Berlin (1964).
8.70 Le Corbusier: Urbanisme. In: Conrads [8.69].
8.71 Schumacher, F.: Sozialer St¨adtebau. In: Kulturpolitik. Jena
(1919).
8.72 Cf. also Frampton, K.: Die Architektur der Moderne. Deutsche
Verlagsanstalt: Stuttgart (1983), Jencks, C.: Die Sprache der
postmodernen Architektur. Deutsche Verlagsanstalt: Stuttgart
(1978).
8.73 Cf.
Lyotard, J.-F.: Das postmoderne Wissen.
Ein Bericht.
Impuls & Association:
Bremen (1982); Habermas, J.:
Die
Moderne — ein unvollendetes Projekt.
Theodor W. Adorno
Preis 1980. In: Habermas, J.: Kleine politische Schriften I–IV.
Suhrkamp: Frankfurt (1981).

424
Symmetry and Complexity
8.74 Adorno, T.W.:
¨Asthetische Theorie.
Suhrkamp:
Frankfurt
(1970), p. 237.
8.75 Peitgen [2.32], map 33, p. 80.
8.76 Cf.
also Steller, E.: Computer und Kunst.
Programmierte
Gestaltung: Wurzeln und Tendenzen neuer ¨Asthetik. B.I. Wis-
senschaftsverlag: Mannheim (1992).
8.77 Picture of the theme issue “Cognition and Complex Brain Dy-
namics” (ed. by P. beim Graben, D. Saddy, J. Kurths) in: In-
ternational Journal of Bifurcation and Chaos 14 No. 2 (2004).

Subject Index
α-helix, 183
absolute space, 337
absolute time, 337
activator, 224, 225
actual information, 277, 283
aerodynamics, 357
aesthetics, 370, 381
agents, 324
algebra, 173
algorithmic complexity, 289, 347
algorithmic information theory, 289
algorithms, 285, 347
anharmonic oscillator, 86, 87
antigravity, 151
antimatter, 152
Antique-Medieval philosophy, 358
Antique-Medieval astronomy, 3, 38, 46
Antique-Medieval mathematics, 2
Antiquity, 22, 368, 371
antisymmetry, 181, 183, 218, 219
aperiodic crystals, 193
Aphrodite of Cyrene, 360, 361
architecture, 1
Aristotelian-Thomistic philosophy, 364
artiﬁcial intelligence, 348
artiﬁcial life, 325, 348
arts, 1, 21, 76, 329
associative memory, 316
astronomy, 4
asymmetry, 14, 135, 152, 188, 199,
210, 262
atomic model, 128–130
atoms, 47, 53, 54
attractors, 4, 13, 16, 17, 19, 158, 162,
192, 236, 254, 257, 272, 296, 345,
385
autocatalytic reaction, 236
automobile traﬃc, 321
automorphism, 64, 72, 180, 339
automorphism group, 4, 8, 66
autonomous nonlinear diﬀerential
equations, 252
axiomatic set theory, 335
β-decay, 140, 152
B´enard experiment, 155, 158, 163
B´enard-eﬀect, 277
balance, 1, 13, 18, 54, 359, 381
Bauhaus, 21, 378, 379, 381
beauty, 1, 2, 20, 21, 25, 357, 360, 386
bifurcation, 5, 13, 83, 88, 95, 97, 99,
167, 195, 252, 254
bifurcation tree, 87, 190, 211, 220,
221, 236, 253, 274, 354
Big Bang, 126, 148, 151
Big Picture, 97, 98
bilateral symmetry, 16, 210
bilateralia, 206
biochemistry, 199, 339
biodiversity, 223, 260
biological evolution, 347
biology, 1, 15, 154, 171, 247, 273, 283,
329
bits, 273, 290
black holes, 12, 283
Boltzmann machine, 303
Boltzmann-constant, 275
425

426
Symmetry and Complexity
Born–Oppenheimer procedure, 176
bosons, 143
bounded rationality, 250
brain, 17, 210, 281
brain dynamics, 234
Buckminsterfullerenes, 195, 297
Buddhist, 362, 363
Buddhist diagrams, 26
bus topologies, 313
butterﬂy eﬀect, 272, 324
BZ-reaction, 190, 191, 230, 277
Calabi–Yau spaces, 145
canon of proportions, 371
canonical invariance, 338, 340
Cantor set, 101, 106
Cantor’s diagonal procedure, 288
Cartesian geometry, 78, 111
categories, 348
causa eﬃciens, 55
causa ﬁnalis, 55
causa formalis, 55
causa materials, 55
causal loop, 160, 248
cell-assemblies, 231, 232, 281
cellular automata (CA), 20, 294, 296,
297, 307, 312
cellular neural networks (CNN),
306–308
cellular nonlinear networks (CNN), 20,
310
cellular self-organization, 302
cellular symmetries, 202
central nervous system (CNS), 227
central symmetry, 26
chaos, 1, 2, 12, 13, 19, 20, 48, 157,
163, 191, 249, 254, 307
chaos attractor, 98, 191, 297
chaos theory, 105
charge, 188
charge conjugation, 135
chemistry, 1, 14, 154, 171, 273, 306,
329, 339
China, 260
Chinese astronomy, 39
Chinese mirrors, 26
Chinese philosophy, 52, 60
chirality, 15, 138, 180, 184, 185
Christian Middle Ages, 364
Church’s thesis, 285, 293
classical mechanics, 118, 378
classical physics, 5, 240
cognitive hierarchies, 281
commensurability, 38
communication, 274, 282, 320, 321
competition, 261, 263
complex dynamical systems, 1, 13, 14,
17, 20, 148, 222, 224, 266, 268, 275,
282, 385
complexity, 48, 96, 99, 158, 163, 166,
188, 190, 199, 249, 256, 269, 271,
307, 313, 318, 337
complexity classes, 286
complexity theory, 286
computability, 287
computational complexity, 289, 290
computational dynamics, 284
computational ecologies, 318
computational irreducibility, 300
computational mathematics, 20
computational network, 320
computational parallelism, 291
computational symmetry, 386
computational systems, 2, 20, 312, 316
computer experiments, 20
computer science, 286
congestion, 322
consciousness, 312
conservation quantity, 116
conservative self-organization, 12, 196,
197
constructibility, 31
continuous groups, 4, 6, 75, 107, 118
continuous phase transitions, 166
control parameter, 13, 87–89, 96, 98,
167, 168, 264
Copernican revolution, 123
cortex, 227, 234
cosmic arrow of time, 12
cosmological principle, 124, 125, 127
CP-symmetry, 153
CPT-symmetry, 140, 143, 185, 188

Subject Index
427
CPT-theorem, 11, 139
creativity, 387
crystallography, 4, 15, 54, 63, 374
cube, 34
cultural symmetry, 22
Curie-point, 165
curvature, 7, 78, 79, 126
cyclic groups, 66
D-tartaric acid, 172–174
data traﬃc, 323
deferents, 41
democracies, 263
deterministic chaos, 5, 163, 234, 254
dialectics, 268
diﬀerential geometry, 4, 77
diﬀerential topology, 175
diﬀusion-reaction processes, 191, 277,
310
digital information, 280
dihedral group, 67, 205
discrete group, 66
dissipation, 13, 57, 154, 190
dissipative self-organization, 13, 16,
190, 192, 197
dissipative system, 157, 190
dissymmetry, 14, 180, 185, 188, 199
distributed intelligence, 317
distribution functions, 251, 258, 319,
345, 346
diversity, 48, 154, 199, 256, 261, 329
DNA, 15, 213, 217, 218, 220, 281, 293
dodecahedron, 34, 46, 71
Doppler eﬀect, 123
double helix, 218
duration, 346
dynamical systems, 5, 20, 158, 317,
344
dynamical systems theory, 175
ecological balance, 384
ecological dynamics, 267
ecological equilibria, 237
ecological systems, 17, 237
ecology, 237, 339
economic equilibrium, 239, 242
economic order, 18
economic self-organization, 19
economics, 252, 267, 339
EEGs, 234
Egypt, 240
eigenvalue equation, 14, 168, 346
Einstein’s space-time, 343
Eleatic philosophy, 51
electrodynamics, 6, 9, 107, 118
electromagnetic ﬁeld, 6, 10
electron, 7
elementary particle physics, 48
elementary particles, 1, 7
emergence, 2, 5, 15–18, 88, 99, 127,
128, 153, 154, 158, 159, 167, 169,
213, 252, 256, 260, 261, 279, 309,
319, 344, 353, 386
emergent cognitive structures, 233
emergent structures, 223, 228
enantiomers, 180, 185
energy, 51, 153
enlightenment, 363, 383
Entity-Relationship (ER)-diagram,
350, 352, 353, 355
entropy, 154, 275, 277, 278, 283, 284,
299
epicycle-deferent technique, 41–45, 58
EPR-experiment, 292
equilibrium, 54, 88, 240, 241, 296
equilibrium of fright, 260
ethics, 38
Euclidean geometry, 2, 4, 5, 32, 46, 65,
73, 74, 81, 110, 111, 121, 338, 356
Euclidean group, 112, 113
Europe, 240
evolution, 17
evolutionary architecture, 325, 327
evolutionary game theory, 247
evolutionary stable strategy (ESS),
247
evolutionary tree, 220
exponential computational time, 286
extensive variables, 250, 252
extremal principle, 215
face-vase illusion, 309

428
Symmetry and Complexity
feedback loops, 266
Feigenbaum-constant, 95
Fermat prime numbers, 31
fermions, 143
ferromagnet, 12, 153, 165
Fibonacci sequence, 37, 204, 205, 363
ﬁeld equations, 144
ﬁtness degrees, 220, 247
ﬁxed point attractor, 13, 19, 162, 233,
296, 297, 303
ﬂuctuations, 257, 260, 261, 321
ﬂuid dynamics, 13
form invariance, 64
fractal dimension, 101, 164
fractal geometry, 5, 106
fractals, 5, 99, 256
frieze groups, 67, 68, 182, 375
fright of nonequilibrium, 260
functional symmetry, 201
functionalism, 382
Galilean invariance, 5, 108, 121, 133
Galileo group, 112, 114, 117, 118
Galois theory, 4, 76
game of life, 295, 301
game theory, 243, 246
game tree, 244
gauge ﬁelds, 6, 139
gauge groups, 141, 189
gauge invariance, 108
gauge symmetries, 276, 339
General Agreement on Tariﬀs and
Trade (GATT), 265
general relativity theory, 9, 121, 277
genetic algorithms, 324
genetic information, 239, 279, 280,
283, 302
genetic information systems, 280
genetic self-organization, 220, 278,
293, 294
geometry, 173, 382
gestalt-psychology, 304
global governance, 239, 265
global Lorentz invariance, 123
global networking, 325
global symmetry, 6, 7, 135, 136
globalization, 239, 259, 260, 263, 264,
267, 269, 272, 329, 372, 385
Golden Rectangle, 36, 37
Golden Section, 35–37, 46, 204, 206,
358–360, 363, 365, 368, 384
Golden Spiral, 36, 75
GPS, 325
gravitation, 11, 284, 337
gravitational ﬁeld, 121, 122
graviton, 11, 143
Greek astronomy, 40
Greek mathematics, 29, 358
Greek philosophy, 60, 358
group theory, 76, 178, 338, 371
groups, 5, 336
H¨uckel model, 181
hadrons, 10
halting problem, 287, 288
Hamiltonian dynamics, 161
Hamiltonian function, 160, 291
Hamiltonian mechanics, 130, 131
Hamiltonian operator, 131, 133, 139,
181, 291
harmonic oscillator, 84
harmony, 1, 2, 23, 25, 34, 36, 38, 40,
51, 127, 240, 371, 382
Hartree-Fock method, 177
Hebb-type learning, 303
Helmholtz–Lie requirement, 81
Heraclitean philosophy, 51
hierarchy, 18, 222, 330, 348, 365
Higgs mechanism, 149
Hilbert space, 8, 82, 83, 108, 131, 176,
291, 334, 339
Hinduism, 358, 362, 363
Hodgkin–Huxley equation, 229
homo economicus, 249
homogeneity, 53, 79, 110, 111, 117, 123
Hooke’s law, 84, 85
Hopf-bifurcation, 89, 97
Hopﬁeld system, 303
hydrodynamics, 159
hypercycles, 15, 212–214
I Ching, 27

Subject Index
429
icosahedron, 34, 46, 71
incommensurable, 36
incompleteness theorem, 288, 289
India, 260
Indian, 26, 67
inertial system, 5, 112, 343
inﬂationary period, 150, 151
information, 2, 244, 274, 284, 316, 357
information content, 274
information dynamics, 273
information entropy, 275, 276
information ﬂow, 275
information packet, 321
information processing, 317
information retrieval (IR), 324
information symmetry, 271
information systems, 278, 279, 311,
322
information theory, 273, 275
inhibitor, 224, 225
instability, 1, 5, 239, 248, 260, 268
intelligence, 325
intensive personal variables, 252
intentionality, 234, 387
Internet, 20, 320, 321, 385
invariance, 5, 72, 74, 338
inversion, 68, 179
invisible hand, 242
irreducibility, 300
irreversibility, 188, 189, 345, 346
Islamic culture, 362–364
Islamic ornaments, 67
isomerism, 173
isometry group, 81, 125
isospin symmetry, 10
isotropic space, 111
isotropy, 53, 58, 79, 110, 123
Judaism, 363
Julia sets, 103, 105, 385
KAM theorem, 162
knowledge representation, 350, 355
knowledge society, 327
L-tartaric acid, 172–174
Lagrangian operator, 114, 115, 144
laissez-faire economics, 268
Laplacian spirit, 162, 256
laser, 157
Lausanne school, 19
LCAO method, 180, 181
learning algorithms, 311
left-right symmetry, 10, 15
Leibniz-Pauli-principle, 8
leptons, 11
Leviathan, 240
Lie groups, 4
life sciences, 15, 199
limbic system, 234
limit cycle, 17, 88, 90, 96, 98, 106,
162, 191, 233, 254, 259
linear computational time, 286
linear decision, 271
linear diﬀerential equations, 85, 159,
163, 168
linear system, 2, 85
linear-stability analysis, 14, 167, 169,
221, 222, 229, 252, 354
linearity, 84, 256, 277
Liouville’s theorem, 161, 162
Lobachevski geometry, 126
local activity principle, 306
local equilibria, 211
local Lorentz invariance, 123
local symmetries, 6, 7, 127, 135, 136
lock and key principle, 195
logarithmic spiral, 75
logos, 22, 35, 51, 360, 383
longitudinal symmetry, 203
Lorentz group, 6, 114, 120
Lorentz invariance, 6, 108, 120, 121,
128, 135
M-theory, 110, 146–148, 339
macro-irreversibility, 345
macro-molecular chemistry, 182
macrocosm, 3
macrodynamics, 166, 222, 231, 232,
249, 250
macrolevel, 18, 213, 345
macromolecules, 184

430
Symmetry and Complexity
macroscopic order, 153, 237
macroscopic patterns, 13, 166, 297
macroscopic point of view, 248
macrostate, 18, 232, 242, 252, 275
macrovariables, 19, 250, 251
Mandelbrot set, 19, 104, 105, 385
many-bodies problems, 344
markets, 19, 242, 263
master equation, 19, 252
mathematics, 3, 4, 63, 335, 369
matter, 152, 252
maximin-strategy, 244
Maya, 39
McCulloch-Pitt network, 302
mechanics, 242
MEMS (micro-electro-mechanical
system), 306
Meru diagram, 26
mesh topologies, 314, 315
meso-tartaric acid, 174
mesocosm, 3
metabolism, 200, 214
metamorphosis, 205
meteorology, 17, 60
microcosm, 3
microdynamics, 222, 232, 248, 258
microeconomic model, 249
microlevel, 18, 212, 345
microreversibility, 12, 154, 292, 298,
299, 345
microstates, 18, 242, 275
Middle Ages, 21, 31, 55, 240, 368
migration dynamics, 19, 254, 255
mind, 18
minimax-strategy, 244
Minkowski geometry, 338, 343
Minkowskian geometry, 6, 118, 121
mixed strategy, 245, 247
models, 341, 349, 351, 353, 356, 357
modernism, 382
molecular computer, 293
molecular self-organization, 293
morphogenesis, 225
morphological symmetries, 16
multiuniverse, 151
music, 371–377
12-tone music, 371, 372, 379
mutation, 200, 220
mythologies, 21, 24, 39
nanocrystals, 193, 196
nanosystems, 190
nanotechnology, 293
Nash equilibrium, 246
natural philosophy, 2–4, 6, 127, 331
nature, 1, 21, 55
Navajo Indians, 23, 24
Navier–Stokes equation, 96
neo-classical economics, 242
nervous systems, 17
network typologies, 313
networks, 231, 294
neural information, 280
neural networks, 325
neural self-organization, 231, 239, 302
neurobiological evolution, 306
neurotransmitter, 311
neutrons, 10
Newtonian space-time, 343
Noether theorem, 118
noise, 12, 235
nominalism, 332–334
non-equilibrium chemistry, 310
non-Euclidean geometry, 74
noncooperative games, 246
nonequilibrium dynamics, 165–167,
169, 211, 217, 222, 230, 232, 239,
244, 248, 260
nonlinear complex systems, 2, 88, 210,
296, 301
nonlinear decisions, 271
nonlinear diﬀerential equations, 222,
230, 295
nonlinear diﬀusion equation, 229
nonlinear diﬀusion–reaction equation,
228
nonlinear dynamics, 18–20, 105, 199,
217, 222, 226, 252, 254, 263, 265,
268, 271, 273
nonlinear equations, 89, 159, 249, 252
nonlinear partial diﬀerential equation,
310

Subject Index
431
nonlinearity, 13, 99, 128, 158, 163,
190, 199, 211, 267, 269, 344
normal-form games, 243, 244
NP-problem, 287
object-oriented programming,
348–350, 352, 353
octahedron, 32, 34, 71
OECD, 265
ontogenesis, 16
ontology, 330, 332, 348, 349, 351
operator, 160
optical activity, 172
optimization, 212
orbital symmetry, 181, 182
order parameters, 13, 14, 16, 18, 165,
166, 167, 169, 220, 231, 239, 248,
252, 258, 261, 268, 306, 354
ornament groups, 69, 72
ornament symmetries, 376
ornaments, 1, 180, 375
oscillations, 19, 162, 180
P, 286
parabolic manifolds, 81
Pareto-optimal, 243
parity, 10, 188
parity violating weak interaction, 15,
152, 185–187
partial diﬀerential equations (PDE),
12–14, 18, 307
particle–antiparticle symmetry, 134,
135
pattern formation, 309, 310
pattern recognition, 278, 304, 305, 309
pentagons, 33
pentagram, 65
Perceptron, 302, 307, 311
period doubling bifurcation tree, 95,
96, 105
permutation group, 8, 76
Petri nets, 355
phase portraits, 177, 254, 255, 301
phase space, 162
phase transition, 1, 12, 13, 16, 20–22,
109, 147–149, 153, 155–157, 165,
192, 199, 210, 212, 217, 225, 234,
240, 250–254, 257, 260, 268, 269,
273, 280, 293, 296, 303, 304, 321,
353, 381, 386
philosophy, 23, 36, 329, 330, 332, 356
philosophy of science, 336, 341
photon, 9, 11
phyllotaxis, 37, 204
phylogenesis, 16
physics, 1, 4, 7, 154, 171, 273, 306, 329
physiocratic economy, 241
Planck’s constant, 142, 290
Planck’s length, 142
Planck-time, 148, 150
Platonic bodies, 33, 64, 71, 74, 180,
192, 195, 200
Poincar´e group, 120
Poincar´e maps, 91–94, 106
point groups, 178
Poisson distribution, 319
political equilibrium, 259
political phase transitions, 258
political systems, 263
politics, 18, 252
polygons, 29, 71
polyhedron, 33, 74
polymerization, 182, 218
polynominal computational time, 286
polyphony, 380
population dynamics, 239
positivism, 332, 383
positron, 9
postmodernism, 384
potential information, 276, 277, 283
pragmatic information, 281
pre-established harmony, 6
prebiotic evolution, 212
predicative logic, 355
presocratic philosophy, 4, 116
principle of computational
equivalence, 20, 301, 326, 387
principle of relativity, 5
probabilistic distributions, 245, 252,
254, 255, 275
program-size complexity, 290
projective geometry, 74, 369

432
Symmetry and Complexity
protein analysis, 183, 184
protons, 10
Pythagorean quadrivium, 2, 38, 46,
372
Pythagorean theorem, 119
Pythagoreans, 29, 31, 32, 34, 36, 372
quadratic computational time, 286
quantum bits, 21, 276, 291
quantum chemistry, 176, 178, 185, 187
quantum chromodynamics, 10
quantum computer, 21, 291
quantum dynamics, 283
quantum electrodynamics, 108, 134,
135, 141
quantum ﬁeld theory, 134
quantum gravity, 284
quantum information, 21, 276, 277,
291, 292
quantum machine, 290
quantum mechanics, 7–9, 82, 83, 108,
128, 130–133, 137, 172, 290, 333,
338, 345, 357
quantum physics, 12, 298
quantum systems, 8, 9, 82, 131, 176,
184
quantum teleporting, 292
quantum theory, 276
quantum universe, 21
quantum vacuum, 151
quarks, 10, 11, 140
R¨ossler attractor, 93, 94
Radiolaria, 208
random network, 318, 319, 320
random variables, 275
randomness, 1, 48, 249, 297, 299, 307
Rayleigh number, 155
reaction-diﬀusion processes, 211
recursion, 101
reﬂection, 5, 67, 69, 179, 202, 374
reﬂection symmetry, 24, 26, 66, 210
regular polygons, 30, 31, 180
regular solids, 4, 46, 59
relative computability, 347
relativistic cosmology, 123
religion, 21
Renaissance, 21, 60, 255, 366, 367,
370, 385
representation of knowledge, 349
reversibility, 299, 345
reversible cellular automaton, 298, 299
reversible structures, 12
Reynolds number, 155
Riemannian manifolds, 78, 79, 81, 122
ring topologies, 313
Robertson–Walker metric, 125
rotation, 5, 202, 374
rotation groups, 72, 111
rotational symmetry, 24, 66, 89, 208
routers, 321
scholastics, 365
Schr¨odinger equation, 8, 131, 291, 338
second law of thermodynamics, 12,
154, 189, 275, 277, 299
selection, 200, 214, 261
self-consciousness, 232
self-organization, 12, 110, 154, 165,
167, 193, 213, 248, 258, 260, 277,
302, 326, 327
self-regulation, 241
self-similarity, 5, 99, 103, 106, 322, 323
semantic webs, 350, 351, 353, 355
sequence space, 215
similarity group, 64, 73
simplicity, 1, 58
singularity, 126, 217
small-world concept, 318, 320
social balance, 239, 262, 339
social evolution, 283
social self-organization, 273, 283, 329
social symmetry, 19, 239, 262
society, 18, 19, 259, 267, 381
socio-economic dynamics, 260
socio-economic transition, 248
sociobiology, 235, 317, 324
socioconﬁguration, 19, 250–252, 258
sociodiversity, 259–261, 264
sociodynamics, 239, 252, 258, 278, 357
socioeconomic systems, 262
sociology, 18, 252

Subject Index
433
software-engineering, 352, 353
solitary waves, 159, 160, 229
space groups, 184
space-time, 344
space-time symmetry, 6, 8, 114, 116,
124
special relativity theory, 6, 108, 121,
276
spectroscopy, 63
spherical symmetry, 41, 129
spiral symmetry, 209
spontaneous symmetry breaking, 186,
217
stability, 239
stable modes, 354
star topology, 313, 315
state space, 96, 344
state-transition diagrams, 354, 355
state-transition systems, 354, 377
stereochemistry, 4, 15, 173, 178
stochastic chaos, 234
stochastic machine, 290
stochastic nonlinear diﬀerential
equation, 252
Stoic philosophy of nature, 61, 362
strange attractor, 164
strategy, 243
string theory, 143, 144
strong interactions, 10
structural species, 342
structural types, 342
structures, 331, 332, 334, 341, 349, 357
SU(2) × U(1) symmetry, 11, 109, 140,
149, 152, 188
SU(2) symmetry, 10, 139, 140, 150,
188
SU(3) symmetry, 10, 109, 140, 150
SU(5) symmetry, 11, 109, 152, 153
superposition, 9, 21, 291, 292
superselection rules, 9
superspace, 99
superstring theories, 11, 145, 147
supersymmetry, 12, 109, 142, 144, 339,
340
superuniﬁcation, 140
supramolecular chemistry, 193, 194
sustainable, 266, 267
swarm intelligence, 317
symmetrical spaces, 7, 82, 124
symmetry breaking, 2, 12, 14–17, 21,
49, 83, 84, 86, 88, 90, 96, 97, 99,
110, 147, 149, 150, 154, 155, 158,
184, 185, 187, 199, 201, 210, 248,
253, 256, 257, 273, 274, 284, 304,
305, 308, 309, 329, 340, 345, 353,
354, 360, 361, 382
symmetry groups, 67, 68, 107, 144
symmetry of time, 12
synergetics, 310
systems, 165
Tao, 60
Taoist philosophy, 60, 358, 362
telecommunication, 320
teleology, 16
tetrahedron, 34, 46, 71
theorema egregium, 78
thermal equilibrium, 12, 13, 16, 189,
192, 197, 211, 225
thermodynamic self-organization, 278
thermodynamical arrow of time, 12
thermodynamics, 239, 242, 283, 302,
339, 346
three-body problem, 162
time operator, 346
time reversibility, 132, 133
time violation, 188
time-series analysis, 385
topology, 74
Trade Related Aspects of Intellectual
Property Rights (TRIPS), 265
trajectories, 161, 164, 176, 345
transformation groups, 73, 338
translation, 5, 67, 68, 180, 202, 374
translation group, 111, 112
translation symmetries, 67
tree topologies, 314
Turing machine, 285–287, 290, 291,
293, 300
ψ-oracle Turing machines, 347
U(1) symmetry, 9, 108, 140, 188

434
Symmetry and Complexity
ubiquitous computing, 325
UN, 270
uncertainty, 244, 275, 278, 281
uncertainty principle, 142
undecidability, 289, 300
uniﬁcation, 141
Uniﬁed Modeling Language (UML),
355
universal Turing machine, 285
universals, 332
unsolvability, 288
unstable modes, 354
urban dynamics, 257
urbanisation, 254
utility function, 243
virtual reality, 325
virus, 200
von Neumann computers, 294
weak interaction, 10
welfare, 262
wholeness, 199
Woodward–Hoﬀmann rules, 182
World Trade Organization (WTO),
265, 266
World Wide Web (WWW), 318–323
yang, 27, 60
Yang–Mills theory, 149
yin, 27, 60
zero-sum games, 243, 245, 260

Name Index
Abel, N.H., 76
Adorno, T.W., 383
Alberti, L.B., 366
Alembert, J. d’, 76, 114, 372
Anaxagoras, 52, 53
Anaximander, 49, 50, 359
Anaximenes, 50
Andronov, A., 99
Apollonius of Perga, 41, 42
Archimedes, 75
Aristophanes, 359
Aristotle, 3–5, 16, 38, 54–57, 60, 61, 222,
329, 330, 332, 346, 348, 349
Arnold, V.I., 162
Augustine, 365
Bach, J.S., 371, 375, 380
Barlow, H.B., 231
Barlow, W., 72
Beltrami, E., 80
B´enard, H., 155
Bergson, H., 346
Bernoulli, J., 75
Birkhoﬀ, G., 89, 163
Bohr, N., 7, 8, 128–130, 331
Boltzmann, L., 12, 189, 275
Bonnet, C., 37, 205
Bonnet, O., 78
Born, M., 130
Braque, G., 378
Broglie, L. de, 130
Bruno, G., 123
Buckminster Fuller, R., 195
Cantor, G., 288
Carnap, R., 336, 352
Cartan, E., 7, 77, 81, 82, 108, 124
Cayley, A., 173
C´ezanne, P., 378
Chaitin, G.J., 289
Chua, L.O., 306, 307, 310
Church, A., 285, 286
Conway, J.H., 295, 301
Copernicus, 58, 59
Copernicus, N., 3, 42
Crick, F.C., 218
Crum Brown, A., 173
Curie, P., 188
Darwin, C., 212, 220, 261
Democritus, 53
Descartes, R., 53, 255, 387
Dirac, P.A.M., 9, 108, 134, 331
Douady, A., 105
Drechsler, E., 194
D¨urer, A., 370
Eddington, A.S., 121
Eigen, M., 212, 214, 215
Einstein, A., 7, 77, 108, 118, 120, 121,
125, 127, 128, 141, 144, 145, 159, 277,
331, 343, 344, 353, 378
Empedocles, 46, 52, 60
Euclid, 20, 30, 32, 35, 40, 65, 71, 74, 356
Eudemus, 41
Eudoxus of Knidos, 3, 41
Euler, L., 74, 114
Fatou, P., 103
Fedorov, E.S., 68, 72
Feynman, R.P., 9, 193, 194, 284
Fischer, E., 194, 195
Fludd, R., 370
Freeman, W., 234
435

436
Symmetry and Complexity
Galenus, 359
Galilei, G., 57, 122, 332, 341
Galois, E., 76
Gauss, C.F., 30, 31, 76–78, 102, 104, 105,
108
Gerisch, G., 16
Gierer, A., 224
Glashow, S., 11, 109
G¨odel, K., 288
Goethe, J.W. von, 37, 205, 331
Gropius, W., 21, 381
Ha¨uy, R.J., 172
Haeckel, E., 206, 208, 209
Haken, H., 168, 310
Hamilton, W.R., 117
Hawking, S.W., 284
Hayek, F. von, 264
Hebb, D., 230, 300, 302, 312
Hegel, G.W.F., 268, 269
Heisenberg, W., 10, 48, 50, 142, 151, 183,
333
Helmholtz, H. von, 7, 65, 79–81
Heraclitus of Ephesus, 50, 51, 53, 55, 116
Hermes, J., 31
Hertz, H., 6
Hilbert, D., 7, 82, 100, 127
Hippasus of Metapontum, 36
Hippodemus , 359
Hobbes, T., 240
Hodgkin, A., 228
Hogarth, W., 370
Honnecourt, V. de, 366, 367
Hopf, E., 89
Hopﬁeld, J.J., 306
Hubbard, J.H., 105
Hubble, E.P., 123, 124
Hume, D., 370
Huxley, A., 228, 378
Julia, G., 103, 105
Kaluza, T., 144, 146
Kandinsky, W., 379
Kant, I., 53, 258, 269, 270, 333, 356
Kekul´e, A., 172, 173, 180
Kepler, J., 31, 34, 37, 41, 43, 58–60, 68,
141, 332
Keynes, J.M., 249, 284
Kirchner, A., 31
Klee, P., 378–380
Klein, F., 6, 72, 73, 107, 112, 117, 338
Klein, O., 144
Koch, H. von, 100
Kolmogorov, A.N., 162, 289
Lagrange, J.L., 76, 114
Landau, L.D., 165, 166
Laplace, P.S., 53, 162
Le Bel, J.A., 173
Le Corbusier, 381
Lee, T.D., 138
Leibniz, G.W., 6, 8, 64, 79, 333, 352
Leonardo da Vinci, 367–369
Leonardo of Pisa, 37
Lie, S., 7, 76, 80, 81, 107, 108, 113
Linde, A., 151
Liouville, J., 161
Locke, J., 241
Lorenz, E.N., 17, 163, 164
Lotka, A.J., 17
Lullus, R., 348
Malsburg, C. von der, 231
Mandelbrot, B.B., 5, 19, 100, 102–104
Mann, T., 15
Marx, K., 262
Maxwell, J.C., 6, 7, 9, 107, 128, 141, 144
Maynard Smith, J., 247
McClelland, J.L., 304
Meinhardt, H., 16, 224
Mie, G., 7, 127, 128
Minkowski, H., 118, 343
Minsky, M., 311
Morgenstern, O., 243
Moser, J., 162
Nash, J.F., 246, 247
Neumann, J. von, 8, 9, 108, 243, 245, 247,
285, 294, 307
Newton, I., 9, 65, 112, 114, 120, 141, 145,
241, 331, 337
Noether, E., 6, 117, 118
Occam, W., 334
Pacioli, L., 368
Parler, H., 365
Parmenides of Elea, 51, 53, 55, 116
Pasteur, L., 15, 172, 180, 185, 187

Name Index
437
Pauli, W., 8
Pauling, L., 183
Pericles, 359
Perutz, M., 184
Peter of Spain, 348
Picasso, P., 378
Planck, M., 129, 142, 146, 378
Plato, 3, 20, 29, 30, 40–42, 46–48, 51, 54,
91, 99, 329, 332
Poincar´e, H., 5, 77, 89, 91, 93, 162, 163,
299
Polykletus, 359
Prigogine, I., 189, 310, 346
Ptolemy, 30, 41, 43, 58
Pythagoras, 35, 111, 127, 356
Rameau, J.P., 372
Rashevsky, N., 224
Richelot, F.J., 31
Riemann, B., 7, 77, 78, 82, 108
Robertson, H.P., 125
Rosenblatt, F., 302, 307, 311
Rumelhart, D., 304
Salam, A., 11, 109
Sch¨onberg, A., 371, 372, 375, 376
Schoenﬂies, A., 72
Schr¨odinger, E., 130, 178, 193, 331, 339,
342
Schumacher, F., 382
Schuster, P., 212, 214
Schwinger, J.S., 9
Shannon, C.E., 273, 327
Simon, R., 37
Singer, W., 231
Smith, A., 19, 241, 242, 261, 265, 327, 331
Spencer, H., 16, 224
Stockhausen, K., 371
Thales of Miletus, 49
Theaetetus, 32
Thom, R., 97–99
Thomas Aquinas, 364
Thompson D’Arcy, 207, 208
Toynbee, A.J., 248
Turing, A.M., 16, 224, 284, 287, 288, 300,
301
van Beethoven, L., 371, 375
van’t Hoﬀ, J.H., 173, 175, 185
Vasari, G., 367
Vitruvius, 359, 362, 367
Volterra, V., 17
Walker, H.G., 125
Watson, J.D., 218
Weinberg, S., 11, 109
Weizs¨acker, C.F. von, 276
Weyl, H., 6, 8, 11, 81, 108, 135, 333
Wheeler, J.A., 142
Wigner, E.P., 8, 108, 133
Wilson, W., 270
Witten, E., 148
Wolfram, S., 295, 300
Wright, S., 215
Wu, C.S., 138
Yang, C.N., 138
Yang, L., 306
Zarathustra, 35
Zuse, K., 285

