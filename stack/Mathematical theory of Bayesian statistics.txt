
Mathematical Theory 
of Bayesian Statistics


Mathematical Theory 
of Bayesian Statistics
Sumio Watanabe

CRC Press
Taylor & Francis Group
6000 Broken Sound Parkway NW, Suite 300
Boca Raton, FL 33487-2742
© 2018 by Taylor & Francis Group, LLC
CRC Press is an imprint of Taylor & Francis Group, an Informa business
No claim to original U.S. Government works
Printed on acid-free paper
Version Date: 20180402
International Standard Book Number-13: 978-1-482-23806-8 (Hardback)
This book contains information obtained from authentic and highly regarded sources. Reasonable 
efforts have been made to publish reliable data and information, but the author and publisher cannot 
assume responsibility for the validity of all materials or the consequences of their use. The authors and 
publishers have attempted to trace the copyright holders of all material reproduced in this publication 
and apologize to copyright holders if permission to publish in this form has not been obtained. If any 
copyright material has not been acknowledged please write and let us know so we may rectify in any 
future reprint.
Except as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, 
transmitted, or utilized in any form by any electronic, mechanical, or other means, now known or 
hereafter invented, including photocopying, microfilming, and recording, or in any information 
storage or retrieval system, without written permission from the publishers.
For permission to photocopy or use material electronically from this work, please access 
www.copyright.com (http://www.copyright.com/) or contact the Copyright Clearance Center, Inc. 
(CCC), 222 Rosewood Drive, Danvers, MA 01923, 978-750-8400. CCC is a not-for-profit organization 
that provides licenses and registration for a variety of users. For organizations that have been granted 
a photocopy license by the CCC, a separate system of payment has been arranged.
Trademark Notice: Product or corporate names may be trademarks or registered trademarks, and 
are used only for identification and explanation without intent to infringe.
Visit the Taylor & Francis Web site at
http://www.taylorandfrancis.com
and the CRC Press Web site at
http://www.crcpress.com

Contents
Preface
ix
1
Deﬁnition of Bayesian Statistics
1
1.1
Bayesian Statistics . . . . . . . . . . . . . . . . . . . . . . . .
2
1.2
Probability Distribution . . . . . . . . . . . . . . . . . . . . .
4
1.3
True Distribution . . . . . . . . . . . . . . . . . . . . . . . . .
7
1.4
Model, Prior, and Posterior . . . . . . . . . . . . . . . . . . .
9
1.5
Examples of Posterior Distributions
. . . . . . . . . . . . . .
11
1.6
Estimation and Generalization
. . . . . . . . . . . . . . . . .
17
1.7
Marginal Likelihood or Partition Function . . . . . . . . . . .
21
1.8
Conditional Independent Cases . . . . . . . . . . . . . . . . .
25
1.9
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
2
Statistical Models
35
2.1
Normal Distribution . . . . . . . . . . . . . . . . . . . . . . .
35
2.2
Multinomial Distribution
. . . . . . . . . . . . . . . . . . . .
41
2.3
Linear Regression . . . . . . . . . . . . . . . . . . . . . . . . .
48
2.4
Neural Network . . . . . . . . . . . . . . . . . . . . . . . . . .
53
2.5
Finite Normal Mixture . . . . . . . . . . . . . . . . . . . . . .
56
2.6
Nonparametric Mixture
. . . . . . . . . . . . . . . . . . . . .
59
2.7
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
63
3
Basic Formula of Bayesian Observables
67
3.1
Formal Relation between True and Model . . . . . . . . . . .
67
3.2
Normalized Observables . . . . . . . . . . . . . . . . . . . . .
77
3.3
Cumulant Generating Functions . . . . . . . . . . . . . . . . .
80
3.4
Basic Bayesian Theory . . . . . . . . . . . . . . . . . . . . . .
85
3.5
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
v

vi
CONTENTS
4
Regular Posterior Distribution
99
4.1
Division of Partition Function . . . . . . . . . . . . . . . . . .
99
4.2
Asymptotic Free Energy . . . . . . . . . . . . . . . . . . . . . 107
4.3
Asymptotic Losses . . . . . . . . . . . . . . . . . . . . . . . . 111
4.4
Proof of Asymptotic Expansions
. . . . . . . . . . . . . . . . 118
4.5
Point Estimators . . . . . . . . . . . . . . . . . . . . . . . . . 123
4.6
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
5
Standard Posterior Distribution
135
5.1
Standard Form . . . . . . . . . . . . . . . . . . . . . . . . . . 136
5.2
State Density Function . . . . . . . . . . . . . . . . . . . . . . 146
5.3
Asymptotic Free Energy . . . . . . . . . . . . . . . . . . . . . 152
5.4
Renormalized Posterior Distribution . . . . . . . . . . . . . . 154
5.5
Conditionally Independent Case . . . . . . . . . . . . . . . . . 162
5.6
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171
6
General Posterior Distribution
177
6.1
Bayesian Decomposition . . . . . . . . . . . . . . . . . . . . . 177
6.2
Resolution of Singularities . . . . . . . . . . . . . . . . . . . . 181
6.3
General Asymptotic Theory . . . . . . . . . . . . . . . . . . . 190
6.4
Maximum A Posteriori Method . . . . . . . . . . . . . . . . . 196
6.5
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203
7
Markov Chain Monte Carlo
207
7.1
Metropolis Method . . . . . . . . . . . . . . . . . . . . . . . . 207
7.1.1
Basic Metropolis Method
. . . . . . . . . . . . . . . . 209
7.1.2
Hamiltonian Monte Carlo . . . . . . . . . . . . . . . . 211
7.1.3
Parallel Tempering . . . . . . . . . . . . . . . . . . . . 215
7.2
Gibbs Sampler
. . . . . . . . . . . . . . . . . . . . . . . . . . 217
7.2.1
Gibbs Sampler for Normal Mixture . . . . . . . . . . . 218
7.2.2
Nonparametric Bayesian Sampler . . . . . . . . . . . . 221
7.3
Numerical Approximation of Observables
. . . . . . . . . . . 225
7.3.1
Generalization and Cross Validation Losses . . . . . . 225
7.3.2
Numerical Free Energy . . . . . . . . . . . . . . . . . . 226
7.4
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229
8
Information Criteria
231
8.1
Model Selection . . . . . . . . . . . . . . . . . . . . . . . . . . 231
8.1.1
Criteria for Generalization Loss . . . . . . . . . . . . . 232
8.1.2
Comparison of ISCV with WAIC . . . . . . . . . . . . 240

CONTENTS
vii
8.1.3
Criteria for Free Energy . . . . . . . . . . . . . . . . . 245
8.1.4
Discussion for Model Selection
. . . . . . . . . . . . . 250
8.2
Hyperparameter Optimization . . . . . . . . . . . . . . . . . . 251
8.2.1
Criteria for Generalization Loss . . . . . . . . . . . . . 253
8.2.2
Criterion for Free Energy
. . . . . . . . . . . . . . . . 257
8.2.3
Discussion for Hyperparameter Optimization
. . . . . 259
8.3
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264
9
Topics in Bayesian Statistics
267
9.1
Formal Optimality . . . . . . . . . . . . . . . . . . . . . . . . 267
9.2
Bayesian Hypothesis Test
. . . . . . . . . . . . . . . . . . . . 270
9.3
Bayesian Model Comparison . . . . . . . . . . . . . . . . . . . 275
9.4
Phase Transition . . . . . . . . . . . . . . . . . . . . . . . . . 277
9.5
Discovery Process . . . . . . . . . . . . . . . . . . . . . . . . . 282
9.6
Hierarchical Bayes
. . . . . . . . . . . . . . . . . . . . . . . . 286
9.7
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291
10 Basic Probability Theory
293
10.1 Delta Function . . . . . . . . . . . . . . . . . . . . . . . . . . 293
10.2 Kullback-Leibler Distance . . . . . . . . . . . . . . . . . . . . 294
10.3 Probability Space . . . . . . . . . . . . . . . . . . . . . . . . . 296
10.4 Empirical Process . . . . . . . . . . . . . . . . . . . . . . . . . 302
10.5 Convergence of Expected Values
. . . . . . . . . . . . . . . . 303
10.6 Mixture by Dirichlet Process
. . . . . . . . . . . . . . . . . . 306
References
309
Index
317


Preface
The purpose of this book is to establish a mathematical theory of Bayesian
statistics.
In practical applications of Bayesian statistical inference, we need to pre-
pare a statistical model and a prior for a given sample, then estimate the
unknown true distribution. One of the most important problems is devising
a method how to construct a pair of a statistical model and a prior, although
we do not know the true distribution. The answer based on mathematical
theory to this problem is given by the following procedures.
(1) Firstly, we construct the universal and mathematical laws between Bayesian
observables which hold for an arbitrary triple of a true distribution, a sta-
tistical model, and a prior.
(2) Secondly, by using such laws, we can evaluate how appropriate a set of
a statistical model and a prior is for the unknown true distribution.
(3) And lastly, the most suitable pair of the statistial model and the prior
is employed.
The conventional approach to such a purpose has been based on the
assumption that the posterior distribution can be approximated by some
normal distribution. However, the new statistical theory introduced by this
book holds for arbitrary posterior distribution, demonstrating that the ap-
plication ﬁeld will be extended. The author expects that also new statistical
methodology which enables us to manupulate complex and hierarchical sta-
tistical models such as normal mixtures or hierarhical neural networks will
be based on the new mathematical theory.
Sumio Watanabe
ix


Chapter 1
Deﬁnition of Bayesian
Statistics
In the ﬁrst chaper, we introduce basic concepts in Bayesian statistics. In
this book, we assume that there exists an unknown true distribution or
unknown information source from which random variables are generated.
Also we assume that an arbitrary set of a statistical model and a prior is
prepared by a statistician who does not know the true distribution. Hence,
from the mathematical point of view, the theory proposed in this book holds
for an arbitrary set of a true distribution, a statistical model, and a prior.
The contents of this chaper include:
(1) In statistical estimation, we prepare a statistical model and a prior,
though a true distribution is unknown. Hence evaluation of a statistical
model and a prior is necessary.
(2) Several examples of probability distributions are introduced.
(3) It is assumed that an information source is represented by a probability
distribution, which is called a true distribution.
(4) The posterior and the predicitive distributions are deﬁned for a given
statistical model and a prior.
(5) Two examples of posterior distributions are illustrated.
In a simple
estimation problem, the posterior distribution can be approximated by a
normal distribution, whereas in a complex or hierarchical model, the result
is far from any normal distribution.
In this book we establish Bayesian
theory which holds for both cases.
(6) The generalization loss is estimated by the cross validation loss and the
widely applicable information criterion (WAIC).
(7) The marginal likelihood and the free energy of statistical estimation are
1

2
CHAPTER 1. DEFINITION OF BAYESIAN STATISTICS
introduced.
(8) Statistical estimation in a conditional independent case is studied, in
which the cross validation loss can not be used but WAIC can be.
For readers who are new to probability theory, chapter 10 will be helpful.
1.1
Bayesian Statistics
In this book, we assume that a sample {x1, x2, ..., xn} is taken from some
true probability distribution q(x),
{x1, x2, ..., xn} ∼q(x).
This process is represented by a conditional probability distribution of a
sample {x1, x2, ..., xn} for a given true distribution q(x),
P(x1, x2, ..., xn|q).
If we knew both P(x1, x2, ..., xn|q) and P(q), where P(q) is an a priori
probability distribution of a true distribution, then by Bayes’ theorem,
P(q|x1, x2, ..., xn) =
P(x1, x2, ..., xn|q)P(q)
P
q P(x1, x2, ..., xn|q)P(q),
which would give the statistical inference of q(x) from a sample {x1, x2, ...,
xn}. However, in the real world, we do not have any information about
either of them, showing that P(q|x1, x2, ..., xn) cannot be obtained.
A problem whose answer cannot be uniquely determined because of the
lack of the information is called an ill-posed problem. Statistical inferences
in the real world are ill-posed. In an ill-posed problem, we cannot deter-
mine a uniquely optimal method by which a correct answer is automatically
obtained, which leads us to propose a new way:
Choose method →Result →Evaluate chosen method.
It might seem that such an evaluation is impossible because we do not
have any information about the true distribution.
However, in Bayesian
statistics, there are mathematical laws which hold for an arbitrary set of a
true distribution, a statistical model, and a prior. By using formulas derived
from the mathematical laws, we can evaluate the appropriateness of the set
of a statistical model and a prior even if a true distribution is unknown. The
purpose of this book is to establish such mathematical laws.

1.1. BAYESIAN STATISTICS
3
In Bayesian statistics, we set a statistical model p(x|w) and a prior ϕ(w),
where p(x|w) is a conditional probability density of x for a given parameter
w and ϕ(w) is a probability density of w. Both p(x|w) and ϕ(w) are prepared
by a statistician who does not know a true distribution. Hence they may be
quite diﬀerent from or inappropriate for the true distribution. If a sample
{x1, x2, ..., xn} consists of independent sample points from a true distribution
q(x), then the posterior probability density function of w is deﬁned by
p(w|x1, x2, ..., xn) =
n
Y
i=1
p(xi|w)ϕ(w)
Z
n
Y
i=1
p(xi|w)ϕ(w)dw
.
This is the deﬁnition of the posterior distribution. The estimated probability
density function of x is deﬁned by
ˆp(x) =
Z
p(x|w)p(w|x1, x2, ..., xn)dw.
This is also the deﬁnition of the predictive distribution. A statistician esti-
mates unknown q(x) by ˆp(x). For an arbitrary triple (q(x), p(x|w), ϕ(w)),
we can deﬁne the Bayesian inference by this procedure, however, we need
to examine whether a statistical model and a prior are appropriate for the
unknown true distribution. Figure 1.1 shows the process of Bayesian esti-
mation.
Remark 1. If we knew the true prior ϕ0(w) to which a parameter as a ran-
dom variable is subject, and if a sample {x1, x2, ..., xn} was independently
taken from the true conditional probability density p0(x|w), then the pre-
dictive distribution ˆp(x) using p0(x|w) and ϕ0(w) would be the uniquely
best inference. This is called the formal optimality of the Bayesian infer-
ence. See Section 9.1. However, in the real world, we do not know either
p0(x|w) or ϕ0(x), indicating that we need evaluation because ˆp(x) may be
quite diﬀerent from q(x).
The candidate set p(x|w) and ϕ(w) is prepared by a statistician without
any information about the true distribution. If the modeling (p(x|w), ϕ(w))
is appropriate for the unknown true q(x), then it is expected that ˆp(x) ≈
q(x). However, if otherwise then ˆp(x) ̸= q(x). Hence we need a method
to evaluate the appropriateness of the modeling (p(x|w), ϕ(w)) without any
information about q(x). In this book, we show such a method can be made
based on mathematical laws which hold for arbitrary (q(x), p(x|w), ϕ(w)).

4
CHAPTER 1. DEFINITION OF BAYESIAN STATISTICS
Figure 1.1: Framework of Bayesian inference. The procedure of Bayesian
estimation is shown. A sample Xn is taken from unknown true distribution
q(x). A statistician sets a statistical model and a prior, then the posterior
density p(w|Xn) is obtained. The true distribution q(x) is estimated by a
predictive density p(x|Xn), whose accuracy is evaluated by using mathe-
matical laws.
1.2
Probability Distribution
Let us introduce a basic probability theory. For a reader who needs mathe-
matical probability theory, Chapter 10 may be of help.
Let x = (x1, x2, ..., xN) be a vector contained in the N dimensional real
Euclidean space RN. A real valued function
q(x) = q(x1, x2, ..., xN)
is said to be a probability density function if it satisﬁes
• For arbitrary x ∈RN, q(x) ≥0,
•
Z
q(x)dx =
Z Z
· · ·
Z
q(x1, x2, ..., xN)dx1dx2 · · · dxN = 1.
Let A be a subset of RN which has an ﬁnite integral value
Z
A
q(x)dx.

1.2. PROBABILITY DISTRIBUTION
5
A function Q of a set A deﬁned by
Q(A) ≡
Z
A
q(x)dx
is called a probability distribution. Note that Q(RN) = 1 and Q(∅) = 0,
where ∅is the empty set.
If the probability that a variable X is in a set A is equal to Q(A), then X
is called a random variable and q(x) and Q are called the probability density
function and the probability distribution of a random variable X, respec-
tively. Also it is said that a random variable X is subject to a probability
density q(x) or a probability distribution Q.
Example 1. (1) Let N = 1. A probability density function of a uniform
distribution on [a0, b0] (a0 < b0) is given by
q(x) =

1
b0−a0
(a0 < x ≤b0)
0
(otherwise)
.
(2) Let S be an N × N positive deﬁnite matrix and m ∈RN. A normal
distribution which has an average m and a covariance S is deﬁned by
q(x) = 1
C exp

−1
2(x −m, S−1(x −m))

,
where ( , ) is the inner product in RN and
C = (2π)N/2p
det(S).
(3) Let H(x) be a function of x ∈RN and β > 0. If
Z(β) =
Z
exp(−βH(x))dx
is ﬁnite, then a probability density function
q(x) =
1
Z(β) exp(−βH(x))
is called an equilibrium state of a Hamilton function H(x) with the inverse
temperature β.
The delta function δ(x) is characterized by two conditions,
δ(x) =
 +∞
(if x = 0)
0
(if x ̸= 0) ,

6
CHAPTER 1. DEFINITION OF BAYESIAN STATISTICS
and
Z
δ(x)dx = 1.
The delta function can be understood as the probability density function of
a random variable X = 0. Its probability distribution is given by
Q(A) =
 1
(if 0 ∈A)
0
(if 0 /∈A) .
If a random variable X satisﬁes that X = 1 and X = 2 with probabilities
1/3 and 2/3 respectively, then its probability density function is
q(x) = 1
3δ(x −1) + 2
3δ(x −2).
If X is a random variable which is subject to q(x) and Q, then Y = f(X) is
also a random variable which is subject to
p(y)
=
Z
δ(y −f(x))q(x)dx,
P(A)
=
Z
f(x)∈A
q(x)dx.
These equations hold even if f(x) is not one-to-one.
Remark 2. The function δ(x) is not an ordinary function of x. However,
it is mathematically well-deﬁned by Schwartz distribution theory and Sato
hyperfunction theory. In this book, the delta function is necessary to study
posterior distributions which cannot be approximated by any normal distri-
bution.
Assume that a random variable X is subject to a probability density
q(x). The expected value, the average, or the mean of a random variable X
on RN is deﬁned by
E[X] =
Z
x q(x)dx,
if the right hand side is ﬁnite. The expectated value of Y = f(X) is
E[Y ]
=
Z
y p(y)dy =
Z
y
Z
δ(y −f(x))q(x)dxdy
=
Z
f(x)q(x)dx.

1.3. TRUE DISTRIBUTION
7
The covariance matrix of X is deﬁned by
V[X]
=
E[(X −E[X])(X −E[X])T ]
=
E[XXT ] −E[X]E[XT ],
if the right hand side is ﬁnite, where (
)T shows the transposed matrix.
If N = 1, then V[X] and V[X]1/2 are called the variance and the standard
deviation, respectively.
Let (X, Y ) be a pair of random variables which is subject to a probability
density q(x, y) on RM ×RN. Here q(x, y) is called a simultaneous probability
density of (X, Y ). Then X and Y are subject to the probability densities
q(x)
=
Z
q(x, y)dy,
q(y)
=
Z
q(x, y)dx,
where q(x) and q(y) are called marginal probability densities of X and Y ,
respectively.
The conditional probability density of Y for a given X is
deﬁned by
q(y|x) = q(x, y)
q(x) .
If q(x) = 0, then q(y|x) is not deﬁned, however, we deﬁne 0·q(y|x) = 0. The
conditional probability density function q(x|y) is also deﬁned by q(x, y)/q(y).
Then it follows that
q(x, y) = q(y|x)q(x) = q(x|y)q(y).
This equation is sometimes referred to as Bayes’ theorem.
1.3
True Distribution
In this book, it is mainly assumed that a sample is a set of random variables
taken from a true distribution.
Let n be a positive integer. A set of RN-valued random variables X1,
X2, ..., Xn is sometimes denoted by
Xn = (X1, X2, ..., Xn).

8
CHAPTER 1. DEFINITION OF BAYESIAN STATISTICS
Throughout this book, the notation n is used for the number of random
variables. Sometimes Xn and n are referred to as a sample and a sample
size, respectively. A realized value of Xn in a trial is denoted by
xn = (x1, x2, ..., xn).
If Xn is subject to a probability density function,
q(x1)q(x2) · · · q(xn)
then Xn is called a set of independent random variables which are subject
to the same probability density q(x). Here q(x) is sometimes referred to as a
true probability density. In the practical applications, we do not know q(x),
but we assume there exists such a density q(x).
For an arbitrary function f : xn 7→f(xn) ∈R, the expected value of
f(Xn) over Xn is denoted by E[ ]. That is to say,
E[f(Xn)] =
Z Z
· · ·
Z
f(xn)
n
Y
i=1
q(xi)dx1dx2 · · · dxn.
The variance of f(Xn) is denoted by
V[f(Xn)] = E[f(Xn)2] −E[f(Xn)]2.
The average and empirical entropies of the true distribution are respectively
deﬁned by
S
=
−
Z
q(x) log q(x)dx,
(1.1)
Sn
=
−1
n
n
X
i=1
log q(Xi).
(1.2)
Then by the deﬁnition,
E[Sn]
=
S,
(1.3)
V[Sn]
=
1
n
hZ
q(x)(log q(x))2dx −S2i
.
(1.4)
Remark 3. (The number n) In statistics, xi and xn are referred to as a
sample point and a sample, respectively. The number n is called a sample
size. In machine learning, xi and xn are referred to as a datum and a set of
training data. The number n is called the number of training data or the
number of examples. In this book, the notation n is used for the number
of random variables, which is equal to the sample size in statistics and the
number of training data in machine learning.

1.4. MODEL, PRIOR, AND POSTERIOR
9
If a set of RM × RN-valued random variables (Xn, Y n) is subject to a
probability density function,
q(x1, y1)q(x2, y2) · · · q(xn, yn),
then (Xn, Y n) is a set of independent random variables. The average and
empirical entropies are repsectively given by
S
=
−
Z
q(x, y) log q(x, y)dxdy,
(1.5)
Sn
=
−1
n
n
X
i=1
log q(Xi, Yi).
(1.6)
These are referred to as the simlutaneous average and empirical entropies.
We often need to estimate the conditional probability density function q(y|x)
under the condition that (Xn, Y n) is obtained. The average and the em-
pirical entropies of the true conditional distribution are respectively deﬁned
by
S
=
−
Z
q(x, y) log q(y|x)dxdy,
(1.7)
Sn
=
−1
n
n
X
i=1
log q(Yi|Xi).
(1.8)
Then by the deﬁnition,
E[Sn]
=
S,
V[Sn]
=
1
n
hZ
q(x, y)(log q(y|x))2dxdy −S2i
.
Sometimes we need to study cases when (Xn, Y n) is not independent, but
Y n for a given Xn is independent. Such a case is explained in Sections 1.8
and 5.5.
1.4
Model, Prior, and Posterior
Let W be a set of parameters which is a subset of d dimensional real Eu-
clidean space Rd. A statistical model or a learning machine is deﬁned by
p(x|w) which is a conditional probability density of x ∈RN for a given
parameter w ∈W.
A prior ϕ(w) is a probability density of w ∈W.

10
CHAPTER 1. DEFINITION OF BAYESIAN STATISTICS
Let Xn = (X1, X2, ..., Xn) be a set of random variables which are inde-
pendently subject to a probability density function q(x). For an arbitrary
pair (p(x|w), ϕ(w)), the posterior probability density is deﬁned by
p(w|Xn) =
1
Z(Xn)ϕ(w)
n
Y
i=1
p(Xi|w),
where Z(Xn) is deﬁned by
Z(Xn) =
Z
ϕ(w)
n
Y
i=1
p(Xi|w)dw,
which is called the partition function or the marginal likelihood.
The
posterior average or the expected value over the posterior distribution is
denoted by Ew[ ]. For an arbitrary function f(w),
Ew[f(w)]
=
Z
f(w)p(w|Xn)dw
=
1
Z(Xn)
Z
f(w)ϕ(w)
n
Y
i=1
p(Xi|w)dw.
The posterior variance is also deﬁned by
Vw[f(w)] = Ew[f(w)2] −Ew[f(w)]2.
Remark that the expectation operator Ew[ ] depends on a set Xn, hence
Ew[f(w)] is not a constant but a random variable. The predictive density
function is deﬁned by
p(x|Xn) = Ew[p(x|w)] =
Z
p(x|w)p(w|Xn)dw.
For a given sample Xn, the Bayesian estimation of the true distribution is
deﬁned by p(x|Xn).
Remark 4. Sometimes a prior function which satisﬁes
Z
ϕ(w)dw = ∞
is employed. If
R
ϕ(w)dw < ∞, it is called proper, because it is normalized
so that
R
ϕ(w)dw = 1. If ϕ(w) is not proper, then it is called improper. Even
for an improper prior, the posterior and predictive probability densities can
be deﬁned by the same equation if Z(Xn) (n ≥1) is ﬁnite and they are
well-deﬁned.

1.5. EXAMPLES OF POSTERIOR DISTRIBUTIONS
11
Let (Xn, Y n) be a set of random variables which are independently sub-
ject to a probability density q(x, y) = q(y|x)q(x).
For an arbitrary pair
(p(y|x, w), ϕ(w)), the posterior probability density is deﬁned by
p(w|Xn, Y n) =
1
Z(Xn, Y n)ϕ(w)
n
Y
i=1
p(Yi|Xi, w),
(1.9)
where Z(Xn, Y n) is deﬁned by
Z(Xn, Y n) =
Z
ϕ(w)
n
Y
i=1
p(Yi|Xi, w)dw.
The posterior average is also denoted by Ew[ ]. For an arbitrary function
f(w),
Ew[f(w)]
=
Z
f(w)p(w|Xn, Y n)dw
=
1
Z(Xn, Y n)
Z
f(w)ϕ(w)
n
Y
i=1
p(Yi|Xi, w)dw.
The posterior variance is also deﬁned by
Vw[f(w)] = Ew[f(w)2] −Ew[f(w)]2.
The predictive density function is deﬁned by
p(y|x, Xn, Y n) = Ew[p(y|x, w)] =
Z
p(y|x, w)p(w|Xn, Y n)dw.
(1.10)
For the case when Y n is independent for a given Xn, see Sections 1.8 and
5.5.
1.5
Examples of Posterior Distributions
Let us illustrate several posterior distributions. In a simple statistical model,
the posterior distribution can be approximated by a normal distribution, but
not in a complex model. One of the main purposes of this book is to establish
the universal mathematical theory which holds in both cases.
Example 2. (Normal Distribution) A normal distribution whose average and
standard deviation are (a, σ) is deﬁned by
p(x|a, σ) =
1
√
2πσ2 exp

−(x −a)2
2σ2

.
(1.11)

12
CHAPTER 1. DEFINITION OF BAYESIAN STATISTICS
0
1
2
-1
0
1
0
1
2
-1
0
1
0
1
2
-1
0
1
0
1
2
-1
0
1
0
1
2
-1
0
1
0
1
2
-1
0
1
0
1
2
-1
0
1
0
1
2
-1
0
1
0
1
2
-1
0
1
0
1
2
-1
0
1
0
1
2
-1
0
1
0
1
2
-1
0
1
Figure 1.2:
Posterior distributions of a statistical model eq.(1.11) with
n = 10 are shown. The white square is the true parameter. Even for an iden-
tical true probability density, posterior distributions ﬂuctuate depending on
samples.
Let us study a case when a prior is set
ϕ(a, σ) =
 1/4
(|a| < 1, 0 < σ < 2)
0
(otherwise)
.
Assume that a true distribution is q(x) = p(x|0, 1) and the number of inde-
pendent random variables is n. In this case, the parameter that attains the
true density is unique,
q(x) = p(x|a, σ) ⇐⇒(a, σ) = (1, 0).
In Figure 1.5, posterior distributions for 12 diﬀerent samples with n = 10
are shown using gray scale. The white square is the position of the true
parameter (0, 1). Even if a true probability density function is identical, the
posterior distribution has ﬂuctuations according to a sample.
In Figure 1.3, posterior distributions for 12 diﬀerent samples with n =
50 are shown.
In this case, the posterior distributions concentrate in a

1.5. EXAMPLES OF POSTERIOR DISTRIBUTIONS
13
0
1
2
-1
0
1
0
1
2
-1
0
1
0
1
2
-1
0
1
0
1
2
-1
0
1
0
1
2
-1
0
1
0
1
2
-1
0
1
0
1
2
-1
0
1
0
1
2
-1
0
1
0
1
2
-1
0
1
0
1
2
-1
0
1
0
1
2
-1
0
1
0
1
2
-1
0
1
Figure 1.3: Posterior distributions of a statistical model eq.(1.11) with n =
50. The white square is the true parameter. Posterior distributions can be
approximated by some normal distribution.
neighborhood of the true parameter when n becomes large. It seems that
the posterior distribution can be approximated by some normal distribution,
hence we expect that a conventional statistical theory using the posterior
normality can be applied to evaluation of statistical modeling.
Example 3. (Normal Mixture) One might think that a posterior distribution
can be approximated by some normal distribution if d/n is suﬃciently small,
where n and d are the number of random variables and the dimension of
the parameter, respectively. However, such consideration often fails even in
unspecial statistical models. Let N(x) be the standard normal distribution,
N(x) =
1
√
2π
exp

−x2
2

.
A normal mixture which has a parameter (a, b) is deﬁned by
p(x|a, b) = (1 −a)N(x) + aN(x −b),
(1.12)

14
CHAPTER 1. DEFINITION OF BAYESIAN STATISTICS
where 0 ≤a ≤1 and b ∈R. Let us set a prior by
ϕ(a, σ) =
 1
(0 < a, b < 1)
0
(otherwise)
.
Assume that a true probability density is q(x) = p(x|0.5, 0.3). Then
q(x) = p(x|a, b) ⇐⇒(a, b) = (0.5, 0.3),
by which one might expect that the posterior distribution will concentrate
on the neighborhood of the true parameter (0.5, 0.3).
The real posterior
distributions for n = 100, n = 1000, and n = 10000 are shown in Figures
1.4, 1.5, and 1.6, respectively.
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
Figure 1.4: Postrior distributions of a statistical model eq.(1.12) with n =
100. The white square is the true parameter. The posterior distributions
are far from any normal distribution and their ﬂuctuations are very large.
The statistical theory in this book enables us to estimate the generalization
loss even in this case.
Even when n = 10000, the posterior distribution cannot be approxi-
mated by any normal distribution.
The regular statistical theory, which

1.5. EXAMPLES OF POSTERIOR DISTRIBUTIONS
15
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
Figure 1.5: Postrior distributions of a statistical model eq.(1.12) with n =
1000. The white square is the true parameter. The number n = 1000 seems
to be suﬃciently large, however, the posterior distributions are far from any
normal distribution and their ﬂuctuations are very large.
assumes that the posterior distribution can be approximated by a normal
distribution, cannot be applied to this case. Therefore, in order to use the
regular asymptotic theory, the condition n >> 10000 is necessary, if oth-
erwise it has been diﬃcult to establish a statistical hypothesis test or a
statistical model selection. In this book, we show a new statistical theory
which holds even if n = 100 can be established by a mathematical base.
Both statistical models given by eq.(1.11) and eq.(1.12) are employed
in many statistical inferences.
In the former model, p(x|m, s) represents
one normal distribution for an arbitrary (m, s), whereas in the latter model,
p(x|a, b) represents one or two normal distributions, depending on the pa-
rameter. In fact, if ab = 0, then p(x|a, b) is a standard normal distribution.
Hence the parameter (a, b) is not a simple parameter but aﬀects the struc-
ture of a statistical model. In general, if a statistical model has hierarchical
structure or a hidden variable such as the latter model, then the posterior
distribution cannot be approximated by a normal distribution in general.

16
CHAPTER 1. DEFINITION OF BAYESIAN STATISTICS
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
0
0.5
1
Figure 1.6: Postrior distributions of a statistical model eq.(1.12) with n =
10000. The white square is the true parameter. In this case, n = 10000 and
the number of parameters is 2, however, the posterior distributions can not
be approximated by any normal distribution.
In this book, in Chapter 4, we study the former statistical models, and in
Chapters 5 and 6, we derive a new mathematical theory for both models.
From the mathematical point of view, the statistical model of eq.(1.11)
does not have singularities, whereas that of eq.(1.12) does. The true pa-
rameter (0.5, 0.3) in eq.(1.12) is a nonsingular point but lies near singularity
(0, 0). In fact, the function from a parameter to a statistical model is not
one-to-one,
{(a, b); p(x|a, b) = p(x|0, 0)} = {(a, b); ab = 0},
and (a, b) = (0, 0) is a singularity of this set. It should be empasized that
a singularity aﬀects the posterior distribution even if the true parameter is
not a singularity. Moereover, several statistical models used in infromation
processing such as artiﬁcial neural networks and mixture models have many
singularities. In general, if a statistical model has singularities, then the
Bayesian estimation has better generalization performance than the maxi-
mum likelihood method, hence we need new statistical theory for the purpose

1.6. ESTIMATION AND GENERALIZATION
17
of constructing hypothesis testing, model selection, and hyperparameter op-
timization for such singular statistical models.
1.6
Estimation and Generalization
In order to evaluate how accurate the predictive density is, we need an
objective measure which indicates the diﬀerence between the true and the
estimated probability density.
Deﬁnition 1. (Generalization and Training Losses) Let Xn be a sample
which is independently taken from a true distribution q(x) and p(x|Xn) be
a predictive density using a statistical model p(x|w) and a prior ϕ(w). The
training and generalization losses are respectively deﬁned by
Tn
=
−1
n
n
X
i=1
log p(Xi|Xn),
(1.13)
Gn
=
−
Z
q(x) log p(x|Xn)dx.
(1.14)
Note that both Gn and Tn are random variables. Let S be the entropy
of a true distribution given by eq.(1.1). Then it immediately follows that
Gn −S
=
−
Z
q(x) log p(x|Xn)dx +
Z
q(x) log q(x)dx
=
Z
q(x) log
q(x)
p(x|Xn)dx
=
K(q(x)||p(x|Xn)),
(1.15)
where K(q(x)||p(x|Xn)) is the Kullback-Leibler distance from q(x) to p(x|Xn).
For the deﬁnition of Kullback-Leibler distance, see Section 10.2. In general,
(1) K(q(x)||p(x|Xn)) ≥0.
(2) K(q(x)||p(x|Xn)) = 0 if and only if K(q(x)||p(x|Xn)) = 0.
Hence
(1) Gn ≥S.
(2) Gn −S = 0 if and only if q(x) = p(x|Xn).
That is to say, the smaller Gn is, the more precise estimation is obtained
according to Kullback-Leibler distance. The random variables Gn −S and
Tn −Sn are called generalization and training errors respectively.
Remark 5. Assume that we have two sets of statistical models and priors,
(p1(x|w), ϕ1(w)),
(p2(x|w), ϕ2(w)).

18
CHAPTER 1. DEFINITION OF BAYESIAN STATISTICS
Let p1(x|Xn) and p2(x|Xn) be predictive densities of two pairs respectively,
and Gn(1) and Gn(2) be their generalization losses. Since the entropy S
does not depend on either a model or a prior,
Gn(1) > Gn(2) ⇐⇒K(q(x)||p1(x|Xn)) > K(q(x)||p2(x|Xn)),
which shows that the smaller generalization loss is equivalent to the smaller
Kullback-Leibler distance. Two training losses Tn(1) and Tn(2) can be de-
ﬁned for both sets, but they do not have such properties. In other words,
the smaller training loss does not mean a smaller generalization error.
Deﬁnition 2. Assume n ≥2. Let Xn \Xi be a set of random variables X1,
X2, ..., Xn which does not contain Xi and p(x|Xn \ Xi) be the predictive
density using Xn \ Xi. The cross validation loss is deﬁned by
Cn = −1
n
n
X
i=1
log p(Xi|Xn \ Xi).
(1.16)
Also Cn −Sn is called a cross validation error.
Remark 6. The deﬁnition eq.(1.16) is called the leave-one-out cross valida-
tion loss. There are several kinds of cross validation losses, however, we
mainly study the leave-one-out one in this book, because it is most accuate
as an estimator of the generalization loss. The cross validation loss can be
deﬁned even if Xn is dependent. However, if Xn is dependent, then it is not
an appropriate estimator of the generalization loss. In fact, the following
theorem needs independence.
Theorem 1. Assume that Xn is independent. Then the following holds.
(1) Assume that the expectation values of Gn and Cn are ﬁnite. Then
E[Cn] = E[Gn−1].
(1.17)
(2) The cross validation loss satisﬁes the relation,
Cn
=
1
n
n
X
i=1
log Ew
h
1
p(Xi|w)
i
.
(3) For an arbitrary set of random variables Xn,
Cn ≥Tn.
The equality Cn = Tn holds if and only if p(Xi|w) (i = 1, 2, ..., n) is a
constant function of w on {w ∈W; p(w|Xn) > 0}.

1.6. ESTIMATION AND GENERALIZATION
19
Proof. (1) The set Xn \ Xi does not contain Xi, hence
E[Cn]
=
−E
h 1
n
n
X
i=1
log p(Xi|Xn \ Xi)
i
=
−1
n
n
X
i=1
E
hZ
q(x) log p(x|Xn \ Xi)dx
i
=
E[Gn−1].
(2) For an arbitrary i,
n
Y
j=1
p(Xj|w) = p(Xi|w)
Y
j̸=i
p(Xj|w).
By the deﬁnition of the cross validation loss,
Cn
=
−1
n
n
X
i=1
log
R
p(Xi|w)ϕ(w) Q
j̸=i p(Xj|w)dw
R
ϕ(w) Q
j̸=i p(Xi|w)dw
=
1
n
n
X
i=1
log
R
(1/p(Xi|w))ϕ(w) Qn
j=1 p(Xi|w)dw
R
ϕ(w) Qn
j=1 p(Xi|w)dw
,
which shows (2) of the lemma.
(3) By using the result (2),
Cn −Tn
=
1
n
n
X
i=1
log

Ew[p(Xi|w)]Ew[1/p(Xi|w)]

.
From Cauchy-Schwarz inequality, it follows that
Ew[p(Xi|w)]Ew[1/p(Xi|w)] ≥Ew[p(Xi|w)1/2p(Xi|w)−1/2]2 = 1.
The equality Cn = Tn holds if and only if p(Xi|w)1/2 ∝p(Xi|w)−1/2 as a
function of w, which concludes (3).
Remark 7. (1) The conditional probability density p(Xi|Xn \Xi) is the pre-
dictive density of Xi based on a sample Xn leaving Xi out. Thus the average
cross validation loss is naturally an unbiased estimator of the generalization
loss for n−1. In the real world, the generalization loss cannot be calculated
because we do not know the true distribution q(x), whereas the cross vali-
dation loss can be obtained using only a sample Xn. There are two issues
about the cross validation.

20
CHAPTER 1. DEFINITION OF BAYESIAN STATISTICS
• Although the averages of Cn and Gn−1 are equal to each other, their
variances are not directly derived from their deﬁnitions. In the follow-
ing chapter, we prove that the standard deviations Gn−S and Cn−Sn
are asymptotically equal to each other, in proportion to 1/n.
• If the average by the posterior distribution is numerically approxi-
mated, then
ISCV
=
1
n
n
X
i=1
log Ew
h
1
p(Xi|w)
i
,
is called the importance sampling cross validation loss. Note that the
approximated cross validation loss
CV
=
−1
n
n
X
i=1
log E(−i)
w
[p(Xi|w)],
where E(−i)
w
[ ] shows the posterior average for Xn\Xi, is diﬀerent from
the importance sampling cross validation loss if the posterior density
is not precisely approximated.
Deﬁnition 3. Assume n ≥1. Let Xn be a set of random variables. The
widely applicable information criterion (WAIC) is deﬁned by
Wn = Tn + 1
n
n
X
i=1
Vw[log p(Xi|w)],
(1.18)
where Vw[ ] shows the posterior variance. Also Wn −Sn is called a WAIC
error.
In the following chapters, we show that, if Xn is independent, then WAIC
is asymptotically equivalent to the cross validation loss,
Wn = Cn + Op(1/n2),
(1.19)
and
E[Wn] = E[Cn] + O(1/n2).
(1.20)
Moreover, there are several cases even if Xn is dependent,
E[Wn] = E[Gn] + o(1/n).
(1.21)
For example, the formula E[Cn] = E[Gn−1] does not hold in conditional
independent cases such as regression problems of ﬁxed inputs or time series
prediction, whereas E[Wn] = E[Gn] + o(1/n) holds even for such cases.

1.7. MARGINAL LIKELIHOOD OR PARTITION FUNCTION
21
Remark 8. The cross validation loss and WAIC can be employed for evalu-
ation of a statistical model and a prior even if a prior is improper.
Remark 9. (Loss and error) The generalization, cross validation, and WAIC
errors are deﬁned by
Gn −S,
Cn −Sn,
Wn −Sn,
where S and Sn are the average and empirical entropies of a true distribution,
respectively. In practical applications, we do not know the true distribution,
resulting that S and Sn are unknown. However, neither S nor Sn depends
on a statistical model and a prior. In model selection and hyperparameter
optimization, minimizing losses are equivalent to minimizing errors. On the
other hand, errors have smaller variances than losses, hence in numerical
experiments, we often compare errors instead of losses.
1.7
Marginal Likelihood or Partition Function
If a prior ϕ(w) satisﬁes
R
ϕ(w)dw = 1, then the marginal likelihood or the
partition function Z(Xn) = Z(X1, X2, ..., Xn) satisﬁes
Z
Z(x1, x2, ..., xn)dx1dx2 · · · dxn
=
Z
dw ϕ(w)
Z
dx1dx2 · · · dxn
n
Y
i=1
p(xi|w) = 1.
Therefore Z(xn) can be understood as an estimated probability density func-
tion of Xn by using a statistical model p(x|w) and a prior ϕ(w). Therefore
Z(xn) is sometimes written as p(xn).
The free energy or the minus log marginal likelihood is deﬁned by
Fn = −log Z(Xn).
(1.22)
Then by using notations q(xn) = Qn
i=1 q(xi) and p(xn) = Z(xn),
E[Fn] −nS =
Z
q(xn) log q(xn)
p(xn)dxn,
which shows that E[Fn] −nS is equal to the Kullback-Leibler distance from
the true density q(xn) to the estimated density p(xn). The smaller E[Fn] is
equivalent to the smaller Kullback-Leibler distance between them. Note that
E[Gn] −S is the average Kullback-Leibler distance from q(x) to p(x|Xn),
whereas E[Fn] −nS is their sum.

22
CHAPTER 1. DEFINITION OF BAYESIAN STATISTICS
Theorem 2. Let n ≥1. The average generalization loss is equal to the
increase of the free energy,
E[Gn] = E[Fn+1] −E[Fn].
(1.23)
Therefore the average free energy is the sum of the generalization loss.
E[Fn] =
n−1
X
i=1
E[Gi] + E[F1].
(1.24)
Proof. Let Xn+1 be a random variable which is independent of Xn and
subject to the same probability density function q(x). Then for an arbitrary
function f(x),
Z
q(x)f(x)dx = EXn+1[f(Xn+1)].
By using this notation,
Gn
=
−
Z
q(x) log p(x|Xn)dx
=
−EXn+1[log p(Xn+1|Xn)]
=
−EXn+1
h
log
Z
p(Xn+1|w)ϕ(w)
n
Y
i=1
p(Xi|w)dw
Z
ϕ(w)
n
Y
i=1
p(Xi|w)dw
i
=
−EXn+1[log Z(Xn+1)] + log Z(Xn).
The expected values over Xn of this equation show eq.(1.23). Therefore,
E[Fn]
=
E[Gn−1] + E[Fn−1]
=
E[Gn−1] + E[Gn−2] + E[Fn−2]
=
n−1
X
i=1
E[Gi] + E[F1],
which shows eq.(1.24).
Remark 10. (Marginal likelihood and free energy) By the deﬁnition Fn =
−log Z(Xn), the correspondence between the free energy and the marginal
likelihood is one-to-one. Hence one of them is obtained, and the other can
be easily derived. However, in general, the asymptotic order of the marginal

1.7. MARGINAL LIKELIHOOD OR PARTITION FUNCTION
23
likelihood as a random variable is not equal to its average, whereas that of
the free energy is equal to its average. Therefore, in studying asymptotic
statistics, the free energy is the more convenient random variable than the
marginal likelihood. Let us illustrate this fact. A marginal likelihood ratio
function r(xn) is deﬁned by
r(xn) = Z(xn)
q(xn) .
Let Xn be a set of random variables which are independently subject to
q(x). Then
E[r(Xn)] =
Z
r(xn)q(xn)dxn = 1.
Therefore the average of r(Xn) is always equal to one. However,
r(Xn) →0
in probability.
For example, for x, a ∈R, a statistical model and a prior are deﬁned by
p(x|a)
=
1
√
2π exp(−1
2(x −a)2),
ϕ(a)
=
1
√
2π exp(−a2
2 ),
and a true distribution is set as q(x) = p(x|0), then
r(Xn) =
r
2π
n + 1 exp
n
n
2(n + 1)
 1
√n
n
X
i=1
Xi
o
.
Since (1/√n) Pn
i=1 Xi is a random variable which is subject to the standard
normal distribution, r(Xn) →0 in probability. Therefore the order of r(Xn)
is not equal to its average. On the other hand, the order of the random
variable −log r(Xn) is equal to its average, because
−log r(Xn) = 1
2 log(n + 1) −1
2 log(2π) −
n
2(n + 1)
 1
√n
n
X
i=1
Xi

.
Remark 11. (Simultaneous prediction) Let us compare Bayesian estimation
and the other estimation from the simultaneous prediction point of view.
Let X1, X2, ..., Xn, Xn+1, ..., Xn+m be independent random variables which
are subject to the same distribution. The simultaneous estimation of
Xn+m \ Xn = (Xn+1, Xn+2, ..., Xn+m)

24
CHAPTER 1. DEFINITION OF BAYESIAN STATISTICS
for a given sample Xn is
p(Xn+m \ Xn|Xn) = Z(Xn+m)
Z(Xn) .
Hence
p(Xn+m \ Xn|Xn) =
m
Y
j=1
 Z(Xn+j)
Z(Xn+j−1)

,
resulting that
−log p(Xn+m \ Xn|Xn) = −
m
X
j=1
log
 Z(Xn+j)
Z(Xn+j−1)

.
The average of this equation is given by
E[Gn] + E[Gn+1] + · · · + E[Gn+m−1].
(1.25)
On the other hand, let ˆw be an estimator such as the maximum likelihood
or the maximum a posteriori method determined by Xn. Then the general-
ization loss of Xn+m \ Xn for a given Xn is
−
m
X
j=1
log p(Xn+j| ˆw),
whose expected value is
−m × E[log p(X| ˆw)].
(1.26)
By eq.(1.25), it is shown that, in Bayesian estimation, the predicted sam-
ple point is automatically used, recursively. However, by eq.(1.26), in other
methods, that is not the case. In ordinary cases, the average generalization
loss E[Gn] is a decreasing function of n, hence, from the simultaneous pre-
diction point of view, Bayesian estimation is better than the other methods.
By the same reason, in the prediction of high dimensional X, it is expected
that the Bayesian estimation has the better performance than the other
methods.
Remark 12. (Predictive measure and marginal likelihood) The cross valida-
tion loss measures the predictive loss which is deﬁned by Kullback-Leibler
distance between q(x) and p(x|Xn), whereas the free energy indicates the
cumulative loss which is deﬁned by Kullback-Leibler distance between q(Xn)

1.8. CONDITIONAL INDEPENDENT CASES
25
and p(Xn). Both measures are important but diﬀerent in Bayesian statis-
tics. If they are used as criteria for choosing the best model or the best
hyperparameter, then the chosen model or hyperparameter is diﬀerent ac-
cording to the criteria. In Chapter 8, we study mathematical properties of
both measures.
Remark 13. (Meaning of the marginal likelihood) Assume that P0(p, ϕ) is
the prior distribution of a model p(x|w) and a prior ϕ(w). Then the proba-
bility density of Xn for a given (p, ϕ) is
P(Xn|p, ϕ) =
Z
n
Y
i=1
p(Xi|w)ϕ(w)dw = Z(Xn).
By Bayes’ theorem, the posterior probability density of (p, ϕ) for a given
sample Xn is
P(p, ϕ|Xn) = P(Xn|p, ϕ)P0(p, ϕ)
P(Xn)
.
Although Z(Xn) is not strictly equivalent to the maximization of the pos-
terior probability P(p, ϕ|Xn), if n is suﬃciently large, the maximization of
Z(Xn) becomes equivalent to the maximization of the posterior probability.
Remark 14. (Asymptotic expansions of free energy and generalization loss)
Let f(n) = E[Fn] and g(n) = E[Gn]. Assume that there exist constants
{Ai} and {Bi} such that asymptotic expansions
f(n)
=
A1n + A2
√n + A3 log n + A4 log log n + O(1),
(1.27)
g(n)
=
B1 + B2
2√n + B3
n +
B4
n log n + o(
1
n log n),
(1.28)
hold for n →∞. Then by eq.(1.23), Ai = Bi (i = 1, 2, 3, 4). It is important
that the constant order term of the free energy f(n) does not aﬀect the
generalization loss g(n). Sometimes minimization of the free energy changes
the constant order term but does not minimize the generalization loss. See
Chapter 8. Also note that, mathematically speaking, even if f(n) has an
asymptotic expansion, g(n) may not have any asymptotic expansion, how-
ever, if g(n) has an asymptotic expansion, then its coeﬃcients are uniquely
determined by the asymptotic expansion of f(n).
1.8
Conditional Independent Cases
In several practical applications, we need to study cases when Xn is de-
pendent. In this section, let us assume that Xn is dependent but Y n is

26
CHAPTER 1. DEFINITION OF BAYESIAN STATISTICS
conditionally independent, in other words, Y n is independent for a given
Xn. If a set of RN-valued random variables Y n = (Y1, Y2, ..., Yn) is subject
to a probability density function,
q(y1|x1)q(y2|x2) · · · q(yn|xn)
for some ﬁxed xn = (x1, x2, ..., xn), then Y n is called a conditionally indepen-
dent random variables subject to a conditional probability density function
n
Y
i=1
q(yi|xi). For an arbitrary function f : (xn, yn) 7→f(xn, yn) ∈R, the
expected value of f(xn, Y n) over Y n is denoted by E[ ]. That is to say
E[f(xn, Y n)] =
Z Z
· · ·
Z
f(xn, yn)
n
Y
i=1
q(yi|xi)dy1dy2 · · · dyn,
which is a function of xn. The average and the empirical entropies of the
true distribution are respectively deﬁned by
S
=
−1
n
n
X
i=1
Z
q(y|xi) log q(y|xi)dy,
(1.29)
Sn
=
−1
n
n
X
i=1
log q(Yi|xi).
(1.30)
Note that both posterior and predictive probability densities are given by
the same equations as eq.(1.9) and eq.(1.10), respectively.
p(w|xn, Y n)
=
1
Z(xn, Y n)ϕ(w)
n
Y
i=1
p(Yi|xi, w),
(1.31)
p(y|x, xn, Y n)
=
Z
p(y|x, w)p(w|xn, Y n)dw.
(1.32)
In conditional independent cases, the generalization error is deﬁned by the
given xn, because the expected value over x is not deﬁned,
Gn
=
−1
n
n
X
i=1
Z
dy q(y|xi) log p(y|xi, xn, Y n),
Tn
=
−1
n
n
X
i=1
log p(Yi|xi, xn, Y n).

1.8. CONDITIONAL INDEPENDENT CASES
27
Also the generalization and training errors are deﬁned by
Gn −S
=
1
n
n
X
i=1
Z
q(y|Xi) log
q(y|xi)
p(y|xi, xn, Y n)dy,
Tn −Sn
=
1
n
n
X
i=1
log
q(Yi|xi)
p(Yi|xi, xn, Y n).
Both the cross validation loss and WAIC can be deﬁned by the same forms
as the independent case.
Cn
=
1
n
n
X
i=1
log Ew[1/p(Yi|xi, w)],
Wn
=
Tn + 1
n
n
X
i=1
Vw[log p(Yi|xi, w)].
However, in this case,
E[Cn] ̸= E[Gn−1],
whereas, in Section 5.5, we show
E[Wn]
=
E[Gn] + o(1/n).
Hence, even if xn is dependent, if Cn is asymptotically equivalent to Wn,
E[Cn]
=
E[Gn] + o(1/n)
also holds, whereas if otherwise, then the cross validation loss is can not be
applied to estimating the generalization loss.
Example 4. (1) In some applications, regression problems of {Yi} for a given
ﬁxed set {xi; i = 1, 2, ..., n} are studied, then the cross validation loss cannot
be employed.
(2) A time series prediction problem,
Zt = a1 Zt−1 + a2 Zt−2 + a3 Zt−3 + Gaussian noise,
can be understood as a regression problem,
(Zt−1, Zt−2, Zt−3) = xt 7→Yt = Zt.
Therefore xt is dependent, resulting that the cross validation loss cannot be
employed, whereas WAIC can be.

28
CHAPTER 1. DEFINITION OF BAYESIAN STATISTICS
1.9
Problems
1. Let w0 = (1, 1, 1, ..., 1) ∈R10 and W be a random variable on R10 which
is subject to
p(w) = C{exp(−||w||2) + 100 exp(−10||w −w0||2)},
where ∥w∥2 = P
i w2
i and C is a constant. Show the following:
(1) Let ˆw be the maximum point of p(w). Then ˆw ≈w0.
(2) E[W] ≈0.
Hence E[W] is far from ˆw. Assume that p(w) is a posterior distribution
of some statistical model.
Discuss the diﬀerence between the maximum
likelihood or a posteriori estimator and Bayesian estimation.
2. (Fluctuation-dissipation theorem) Let β > 0 and H(x) be a function
from RN to R. Assume that a random variable X ∈RN is subject to a
probability density function,
p(x|β) =
1
Z(β) exp(−βH(x)),
where Z(β) is a constant
Z(β) =
Z
exp(−βH(x))dx.
Then prove the equation,
∂E[H(X)]
∂β
= −V[H(X)].
It is well known that this equation demonstrates several important laws in
physics.
3. (Coin toss) Let p(x|a) be a statistical model of x ∈{0, 1} which is deﬁned
by
p(x|a)
=
ax(1 −a)1−x,
where a is a parameter (0 ≤a ≤1). See Figure 1.9. Let us study a prior
ϕ(a) which is deﬁned by
ϕ(a)
=
1,

1.9. PROBLEMS
29
on 0 ≤a ≤1. Let Xn be a set of random variables which are independently
subject to p(x|a0). Also let n1 and n2 be
n1 =
n
X
i=1
Xi,
n2 = n −n1.
Then show the following equations.
(1) The maximum likelihood estimator is ˆa = n1/n and the estimated prob-
ability distribution p(x|ˆa) by the maximum likelihood method is given by
p(1|ˆa) = n1 + ε
n + 2ε,
p(0|ˆa) = n2 + ε
n + 2ε,
where ε = 0.
(2) The Bayesian predictive distribution p(x|Xn) is
p(1|Xn) = n1 + 1
n + 2 ,
p(0|Xn) = n2 + 1
n + 2 .
(3) The generalization error of the maximum likelihood method is deﬁned
by Kullback-Leibler information from p(x|a0) to p(x|ˆa),
KML
=
−a0 log((n1 + ε)/(n + 2ε)) −(1 −a0) log((n2 + ε)/(n + 2ε))
+a0 log a0 + (1 −a0) log(1 −a0),
where ε > 0 is a suﬃciently small positive value.
Note that, if ε = 0,
0 < a0 < 1, and n1n2 = 0, then KML = ∞. That of Bayesian method is
deﬁned by Kullback-Leibler distance from p(x|a0) to p(x|Xn),
KBayes
=
−a0 log((n1 + 1)/(n + 2)) −(1 −a0) log((n2 + 1)/(n + 2))
+a0 log a0 + (1 −a0) log(1 −a0).
(4) By using numerical calculation, the expected values of E[KML] and
E[KBayes] for n = 20, a0 = 0.05, 0.10, ..., 0.50, and ε = 0.0001 are shown in
Figure 1.9. If a0 = 0, then E[KML] = 0 and E[KBayes] > 0. Discuss the
diﬀerence between the maximum likelihood and Bayesian methods from the
veiwpoint of the generalization errors.
4. (Simple normal distribution) Let p(x|a) and ϕ(a) be a statistical model
of x ∈R for a given parameter a ∈R and a prior of a respectively,
p(x|a)
=
1
(2π)1/2 exp

−1
2(x −a)2
,
ϕ(a)
=
 A
2π
1/2
exp

−A
2 a2
.

30
CHAPTER 1. DEFINITION OF BAYESIAN STATISTICS
0
0.1
0.2
0.3
0.4
0.5
0
0.05
0.1
0.15
True probability
Generalization Error
 
 
Maximum Likelihood
Bayes
Figure 1.7: Comparison of Bayes with maximum likelihood in coin toss.
The averages of the generalization errors by the maximum likelihood and
Bayesian methods are compared in a coin toss problem for n = 20. The
standard deviations of the maximum likelihood method are larger than that
of Bayes for every a0.
Let Xn be a set of independent random variables which are subject to p(x|0).
Then prove the following equations.
S
=
C0 + 1
2,
Sn
=
C0 + 1
2n
n
X
i=1
x2
i ,
where C0 = (1/2) log(2π). The losses are
Gn
=
C0 + 1
2 log(1 + 1
n1
) +
n1
2(n1 + 1) +
n1
2(n1 + 1)(x∗)2
Cn
=
C0 −1
2 log(1 −1
n1
) +
n1
2(n1 −1)
1
n
n
X
j=1
(xj −x∗)2
Tn
=
C0 + 1
2 log(1 + 1
n1
) +
n1
2(n1 + 1)
1
n
n
X
j=1
(xj −x∗)2
Wn
=
C0 + 1
2 log(1 + 1
n1
) +
1
2n2
1
+ n2
1 + 2n1 + 2
2n1(n1 + 1)
1
n
n
X
j=1
(xj −x∗)2,

1.9. PROBLEMS
31
-0.02
-0.01
0
0.01
0.02
0
200
400
600
800
1000
1200
¦gn-cn¦ - ¦gn-wn¦
Figure 1.8: Cross validation and WAIC. This ﬁgure shows the histogram of
|gn −cn| −|gn −wn|. If |gn −cn| −|gn −wn| > 0 then WAIC is a better
approximator of the generalization loss than the cross validation.
where n1 = n + A and
x∗= 1
n1
n
X
i=1
xi.
The free energy is
Fn
=
nC0 + 1
2 log(n1/A) −n1
2 (x∗)2 + 1
2(
n
X
i=1
x2
i ).
It follows that Cn −Wn = Op(1/n3). Let
gn
=
Gn −S,
cn
=
Cn −Sn,
wn
=
Wn −Sn.
Then the histogram of |gn −cn| −|gn −wn| for n = 5 is given by Figure
1.8. In this model, Bayesian observables can be explicitly calculated without
numerical approximation, hence it is easy to compare the cross validation
loss and WAIC as estimators of the generalization loss.
5. (Normal mixture) The Fisher information matrix Ijk(w) of a statistical

32
CHAPTER 1. DEFINITION OF BAYESIAN STATISTICS
model p(x|w) is deﬁned by
Ijk(w) =
Z
∂j log p(x|w) ∂k log p(x|w) p(x|w) dx
where ∂j = ∂/∂wj. Show that the Fisher information matrix of a statistical
model
p(x|a, b) = (1 −a)N(x) + aN(x −b)
(1.33)
where N(x) is the standard normal distribution at (a0, b0) = (0.5, 0.3) is
numerically approximated by
I(a0, b0) ≈
 0.0881
0.1467
0.1467
0.2552

,
whose minimum and maximum eigenvalues are
0.0029 << 0.3405.
Note that the minimum value is far smaller than the maximum value. If a
sample Xn is independently subject to p(x|a0, b0) and if regular asymptotic
theory held, then the asymptotic posterior distribution would be approxi-
mated by the normal distribution whose average is (a0, b0) and covariance
matrix is (nI(a0, b0))−1. By comparing Figures 1.4, 1.5, and 1.6 with the
minimum eigenvalue, discuss the suﬃciently large n by which regular asymp-
totic theory holds. Compare its result with the fact that singular asymptotic
theory holds even when n is smaller than 100.
6. (Conditional dependent case) A simple linear regression model of y ∈R
for given x ∈R and paramater a ∈R is deﬁned by
p(y|x, a) =
1
√
2π exp

−1
2(y −ax)2
.
Assume that p(y|x, a0) is a true conditional probability density of y ∈R. Let
{xi; i = 1, 2, ..., n} and {ξi; i = 1, 2, ..., N} be sets of ﬁxed input data used
in estimation (training) and trial (test), respectively. The set of conditional
independent data is {(xi, Yi); i = 1, 2, ..., n}.
For simple calculation, we
employ an improper prior ϕ(a) = 1 on R. Then the posterior and predictive
distributions are respectively given by
p(a|xn, Y n)
=
1
Z
n
Y
i=1
p(Yi|xi, a),
p∗(y|x)
=
Ea[p(y|x, a)],

1.9. PROBLEMS
33
where Z is a constant. The generalization error is deﬁned by using the test
set,
Gn
=
−1
N
N
X
j=1
Z
p(y|ξj, a0) log p∗(y|ξj)dy,
which is a random variable because the predictive distribution is a function
of Y n. The leave-one-out cross validation loss and the widely applicable
information criterion for a set are respectively deﬁned by using the training
set,
Cn
=
1
n
n
X
i=1
log Ea
h
1
p(Yi|xi, a)
i
,
Wn
=
−1
n
n
X
i=1
log p∗(Yi|xi) + 1
n
n
X
i=1
Va[log p(Yi|xi, a)].
The conditional true entropy is
S
=
−1
n
n
X
i=1
Z
p(y|xi, a0) log p(y|xi, a0)dy = 1
2 log(2π) + 1
2.
Then show the following equations.
E[Gn] −S
=
1
2N
N
X
j=1
log

1 +
ξ2
j
Pn
i=1 x2
i

,
E[Cn] −S
=
−1
2n
n
X
j=1
log

1 −
x2
j
Pn
i=1 x2
i

,
E[Wn] −S
=
1
2n
n
X
j=1
log

1 +
x2
j
Pn
i=1 x2
i

+ 1
2n
n
X
j=1
1 −sj
1 + sj
s2
j,
where
sj =
x2
j
Pn
i=1 x2
i
.
Prove that, if n = N and ξi = xi for all i,
E[Gn] ≤E[Wn] ≤E[Cn],
where equalities hold if and only if xi = 0 for all i.


Chapter 2
Statistical Models
In this chapter, we introduce several concrete examples of statistical models.
The main purpose of this book is to establish the mathematically univer-
sal theory in Bayesian statistics which holds even for nonregular statistical
models. However, before studying the general formulas, concrete examples
are prepared for understanding them. We introduce
(1) Normal distribution
(2) Multinomial distribution
(3) Linear regression
(4) Neural network
(5) Finite normal mixture
(6) Nonparametric mixture
and then examine the behaviors of the free energy or the minus log marginal
likelihood, and the generalization, training, cross validation losses, and WAIC.
The statistical models (1), (2), and (3) are regular, whereas (4), (5), and
(6) are nonregular. If a reader has software for numerical calculation, then
it will be easy to realize them.
2.1
Normal Distribution
Firstly, we study a normal distribution. Let us use a probability density
function of x ∈R for a given parameter w = (m, s) ∈R2, (s > 0).
p(x|m, s)
=
r s
2π exp

−s
2(x −m)2
.
(2.1)
The probability distribution represented by this density function is denoted
by N(m, 1/s), where m is the average and 1/s is the variance. It can be
35

36
CHAPTER 2. STATISTICAL MODELS
rewritten as
p(x|m, s)
=
1
√
2π
exp

−s
2x2 + msx −m2s
2
+ 1
2 log s

.
The conjugate prior ϕ(m, s|φ1, φ2, φ3) of the normal distribution is the same
function of a parameter as the statistical model, by replacing (x2, x, 1) by a
hyperparameter φ = (φ1, φ2, φ3),
ϕ(w|φ)
=
ϕ(m, s|φ1, φ2, φ3)
=
1
Y (φ) exp

−s
2φ1 + msφ2 −1
2(m2s −log s)φ3

,
(2.2)
where w = (m, s). It follows that
ϕ(w|φ)
=
1
Y (φ) exp

−s
2(φ1 −φ2
2
φ3
)

s1/2 exp(−s
2(m −φ2
φ3
)2)
φ3.
The constant Y (φ) is determined by the condition
R
ϕ(w|φ)dw = 1. By
using integral formulas,
Z ∞
−∞
exp(−ax2)dx
=
p
π/a,
(2.3)
Z ∞
0
xa−1 exp(−x/b)dx
=
ba Γ(a),
(2.4)
where Γ(a) is the gamma function, the function Y (φ) is given by
Y (φ) =
2√π(2φ3)φ3/2
(φ1φ3 −φ2
2)(φ3+1)/2 Γ
φ3 + 1
2

.
(2.5)
To ensure 0 < Y (φ) < ∞, the hyperparameter should satisfy φ3 > 0 and
φ1φ3−φ2
2 > 0. Since the conjugate prior has the same form of the parameter
as the statistical model, the posterior simultaneous density of (w, Xn) is
given by
Ω(w, Xn)
≡
ϕ(w)
n
Y
i=1
p(Xi|w)
=
1
Y (φ)(2π)n/2 exp

−s
2
ˆφ1 + ms ˆφ2 −1
2(m2s −log s) ˆφ3

,

2.1. NORMAL DISTRIBUTION
37
where
ˆφ1
=
n
X
i=1
X2
i + φ1,
(2.6)
ˆφ2
=
n
X
i=1
Xi + φ2,
(2.7)
ˆφ3
=
n + φ3.
(2.8)
The partition function is given by
Z(Xn) =
Z
Ω(w, Xn)dw =
Y (ˆφ)
Y (φ)(2π)n/2 ,
and the posterior distribution, which is equal to Ω(w, Xn)/Z(Xn), is given
by
p(w|Xn) = ϕ(m, s|ˆφ1, ˆφ2, ˆφ3).
Hence the minus log marginal likelihood or the free energy F = −log Z(Xn)
is
Fn = n
2 log(2π) + log Y (φ) −log Y (ˆφ).
(2.9)
See Figure 2.1. The predictive density is also given by
Ew[p(x|w)]
=
Z
p(x|w)ϕ(w|ˆφ)dw
=
1
√
2π
Y (ˆφ1 + x2, ˆφ2 + x, ˆφ3 + 1)
Y (ˆφ1, ˆφ2, ˆφ3)
∝
1
[(x −ˆφ2/ˆφ3)2 + C1](ˆφ3+1)/2 ,
(2.10)
where C1 = (ˆφ1 ˆφ3 −ˆφ2
2)(ˆφ3 + 1)/ˆφ2
3. The predictive density is diﬀerent from
any normal distribution. However, when n →∞, it converges to a normal
distribution. See Figure 2.2. The training loss is
Tn
=
−1
n
n
X
i=1
log Ew[p(Xi|w)]
=
1
2 log(2π) + log Y (ˆφ1, ˆφ2, ˆφ3)
−1
n
n
X
i=1
log Y (ˆφ1 + X2
i , ˆφ2 + Xi, ˆφ3 + 1).
(2.11)

38
CHAPTER 2. STATISTICAL MODELS
Since
Ew[1/p(x|w)] =
√
2π Y (ˆφ1 −x2, ˆφ2 −x, ˆφ3 −1)
Y (ˆφ1, ˆφ2, ˆφ3)
,
the cross validation loss is equal to
Cn
=
1
n
n
X
i=1
log Ew[1/p(Xi|w)]
=
1
2 log(2π) −log Y (ˆφ1, ˆφ2, ˆφ3)
+ 1
n
n
X
i=1
log Y (ˆφ1 −X2
i , ˆφ2 −Xi, ˆφ3 −1).
(2.12)
Let f(α, x) be a function
f(α, x)
=
log
Z
p(x|w)αϕ(w|ˆφ)dw
=
log
h
1
(2π)α/2
Y (ˆφ1 + αx2, ˆφ2 + αx, ˆφ3 + α)
Y (ˆφ1, ˆφ2, ˆφ3)
i
.
Since the posterior distribution is equal to ϕ(w|ˆφ),
∂2f
∂α2 (0, x)
=
Vw[log p(x|w)]
=
∂2
∂α2
h1
2(ˆφ3 + α) log(2(ˆφ3 + α))
−1
2(ˆφ3 + α + 1) log{(ˆφ1 + αx2)(ˆφ3 + α) −(ˆφ2 + αx)2}
+ log Γ((ˆφ3 + α + 1)/2)
i
α=0
=
1
4ψ′ ˆφ3 + 1
2

+
1
2ˆφ3
−u(x) + (ˆφ3 + 1)u(x)2
2
,
where ψ′(x) = (log Γ(x))′′ is the trigamma function and
u(x) =
ˆφ3x2 −2ˆφ2x + ˆφ1
ˆφ1 ˆφ3 −(ˆφ2)2
.
Therefore WAIC is given by
Wn = Tn + 1
n
n
X
i=1
∂2f
∂α2 (0, Xi).

2.1. NORMAL DISTRIBUTION
39
0
200
400
600
800
1000
-2
0
2
4
6
8
Fn -n Sn : Free Energy - n*Entropy
n : Sample Size
Figure 2.1: Free energy for n = 1, 2, ..., 1000. The free energy or the minus
log marginal likeihood of a normal distribution Fn −nSn is shown for n =
1, 2, ..., 1000. Its asymptotic behavior is given by log n.
By using the function Y (φ) in eq.(2.5), we can calculate Fn, Tn, and Cn
using Xn, based on eqs.(2.9), (2.11), and (2.12).
Let us assume that a true
distribution is q(x) = p(x|m0, s0). Then the entropy and empirical entropy
of the true distribution are respectively given by
S
=
−
Z
q(x){1
2 log( s0
2π ) −s0
2 (x −m0)2}dx
=
−1
2 log( s0
2π ) + 1
2,
Sn
=
−1
2 log( s0
2π ) + s0
2n
n
X
i=1
(Xi −m0)2.
The training and cross validation errors are respectively given by Tn −Sn
and Cn −Tn. The generalization loss is given by
Gn
=
S +
Z
q(x) log
q(x)
Ew[p(x|w)]dx
=
1
2 log(2π) + log Y (ˆφ1, ˆφ2, ˆφ3)
−
Z
q(x) log Y (ˆφ1 + x2, ˆφ2 + x, ˆφ3 + 1)dx.
Unfortunately, the integration over q(x) cannot be done analytically.

40
CHAPTER 2. STATISTICAL MODELS
-0.5
0
0.5
0
500
1000
1500
(1) Training Error (Tn-Sn)
-0.5
0
0.5
0
500
1000
1500
(4) Generalization Error (Gn-S)
-0.5
0
0.5
0
500
1000
1500
(2) Cross Validation Error (Cn-Sn)
Cross Validation Error
0
0.5
1
-1
-0.5
0
0.5
1
(3) (Generalization, CV)
-0.5
0
0.5
0
500
1000
1500
(5) WAIC (Wn-Sn)
0
0.5
1
-1
-0.5
0
0.5
1
WAIC
(6) (Generalization, WAIC)
Figure 2.2: Bayesian observables in normal distribution are shown in the
case n = 10. Histograms of (1) training error Tn −Sn, (2) cross validation
error Cn−Sn, (4) generalization error Gn −S, and (5) WAIC error Wn −Sn.
Distributions of (3) (Gn −S, Cn −Sn), and (6) (Gn −S, Wn −Sn). Note
that WAIC error has smaller variance than cross validation error.
Example 5. A numerical experiment was conducted by setting (m0, s0) =
(1, 1) and (φ1, φ2, φ3) = (0.5, 0, 0.5). In Figure 2.1 the horizontal and ver-
tical axes show the sample size n and the free energy or the minus log
marginal likelihood minus empirical entropy Fn −nSn for n = 1, 2, ..., 1000,
respectively.
In the following sections, we will show that Fn −nSn =
(d/2) log n + Op(1) (d is the dimension of the parameter space), which is
consistent with the ﬁgure. In Figure 2.2, experimental results of 10000 ind-
pendent trials for n = 10 are shown.
(1) Histogram of the training error, Tn −Sn
(2) Cross validation error, Cn −Sn
(3) Generalization error and the cross validation error
(4) Histogram of generalization error, G −S
(5) Histogram of WAIC error, Wn −Sn
(6) Generalization error and WAIC

2.2. MULTINOMIAL DISTRIBUTION
41
The averages and standard deviations of Gn −S, Cn −Sn, and Wn −Sn are
numerically approximated by
Average:
0.0901, 0.1017, 0.0860,
Standard deviation:
0.0978, 0.1211, 0.1136.
The variance of the cross validation error is larger than WAIC error. More-
over,
E|(Gn −S) −(Cn −Sn)|
=
0.153,
E|(Gn −S) −(Wn −Sn)|
=
0.146.
Therefore, WAIC is the better estimator of the generalization error than the
cross validation error in this case. The inequality
E|(Gn −S) −(Cn −Sn)| > E|(Gn −S) −(Wn −Sn)|
holds for n = 1, 2, 3, 4, 5. In the following chapters, we show the higher order
asymptotic equivalence of the cross validation and WAIC as n →∞. For the
ﬁnite and smaller n, WAIC is the better approximator of the generalization
loss than the cross validation loss in many statistical models.
2.2
Multinomial Distribution
A multinomial distribution is examined. Let N be a positive integer. An N
dimensional variable
x = (x(1), x(2), ..., x(N))
is said to be competitive if only one element is equal to one, x(j) = 1,
and others are equal to zero, x(k) = 0 (k ̸= j). The set of N dimensional
competitive variables is denoted by
CN ≡{x = (x(1), x(2), · · · , x(N)); x is competitive}.
By the deﬁnition, the number of elements of the set CN is equal to N. This
set is used in classiﬁcation problems where N is the number of categories.
In a coin toss problem, N = 2, whereas in a dice throw problem, N = 6.
The N dimensional multinomial distribution of one trial x ∈CN for a given
parameter w is deﬁned by
p(x|w) =
N
Y
j=1
(wj)xj,
(2.13)

42
CHAPTER 2. STATISTICAL MODELS
where we determine 00 = 1 and a set of all parameters is
W = {w = (w1, w2, · · · , wN) ;
N
X
j=1
wj = 1, wi ≥0}.
If a random variable X = (X(1,)X(2), ..., X(N)) is subject to p(x|w), then for
an arbitrary j, the probability X(j) = 1 is equal to
Prob(X(j) = 1) = wj.
The Dirichlet distribution on W is often employed as a prior,
ϕ(w|a) =
1
C(a)
N
Y
j=1
(wj)aj−1 δ
 N
X
j=1
wj −1

,
(2.14)
where a hyperparameter a is an N dimensional vector,
a = (a1, a2, ..., aN),
which satisﬁes aj > 0 (j = 1, 2, ..., N) and
C(a)
=
 N
Y
j=1
Z 1
0
dwj (wj)aj−1
δ
 N
X
j=1
wj −1

.
Lemma 1. The normalizing term of Dirichlet distribution is
C(a)
=
N
Y
j=1
Γ(aj)
Γ(
N
X
j=1
aj)
.
(2.15)
Proof. Let λ > 0 and
f(λ)
=
 N
Y
j=1
Z ∞
0
dwj (wj)aj−1
δ
 N
X
j=1
aj −λ

.

2.2. MULTINOMIAL DISTRIBUTION
43
Then f(1) = C(a). The Laplace transform of f(λ) is
Z ∞
0
f(λ)e−βλdλ
=
N
Y
j=1
Z ∞
0
(wj)aj−1 exp(−βwj)dwj
=
N
Y
j=1
1
(β)aj
Z ∞
0
(wj)aj−1 exp(−wj)dwj
=
1
(β)
P
j aj
N
Y
j=1
Γ(aj)
=
Q
j Γ(aj)
Γ(P
j aj)
Z ∞
0
λ
P
j aj−1e−βλdλ.
Therefore, by using the inverse Laplace transform of this equation, f(λ) is
obtained,
f(λ) =
Q
j Γ(aj)
Γ(P
j aj)λ
P
j aj−1.
Then f(1) gives eq.(2.15).
Let us make the posterior distribution for a multinomial distribution and
Dirichlet prior. Let Xn be a set of n random variables on CN,
Xn = {Xi = (X(1)
i
, ..., X(N)
i
) ; i = 1, 2, ..., n}.
A random variable nj is deﬁned by
nj
=
n
X
i=1
X(j)
i
,
which is the number of sample points classiﬁed into the jth category. Then
P
j nj = n and the posterior distribution is
p(w|Xn)
=
1
Z(Xn)
1
C(a)
N
Y
j=1
(wj)aj−1
n
Y
i=1
(wj)X(j)
i
δ
 N
X
j=1
wj −1

=
1
Z(Xn)
1
C(a)
N
Y
j=1
(wj)nj+aj−1 δ
 N
X
j=1
wj −1

.
By using a notation n = (n1, n2, ..., nN), eq. (2.15), and
R
p(w|Xn)dw = 1,
the marginal likelihood or the partition function satisﬁes
Z(Xn)C(a) = C(n + a).

44
CHAPTER 2. STATISTICAL MODELS
Therefore
Z(Xn) =
QN
j=1 Γ(nj + aj)
Γ(n + PN
j=1 aj)
·
Γ(PN
j=1 aj)
QN
j=1 Γ(aj)
.
Thus the minus log marginal likelihood or the free energy is given by
Fn
=
log Γ(n +
N
X
j=1
aj) −
N
X
j=1
log Γ(nj + aj)
−log Γ(
N
X
j=1
aj) +
N
X
j=1
log Γ(aj).
(2.16)
The predictive distribution p(x|Xn) of x = (x(1), x(2), ..., x(N)) is given by
p(x|Xn)
=
Ew[p(x|w)] =
Z
p(x|w)p(w|Xn)dw
=
Z(Xn+1)
Z(Xn)
=
QN
j=1 Γ(x(j) + nj + aj)
Γ(n + 1 + PN
j=1 aj)
·
Γ(n + PN
j=1 aj)
QN
j=1 Γ(nj + aj)
,
where we used a notation Xn+1 = (Xn, x). By using Γ(x + 1) = xΓ(x) for
an arbitrary x > 0, it follows that
p(x|Xn) =
QN
j=1(nj + aj)x(j)
n + PN
j=1 aj
.
Thus the training loss is
Tn
=
−1
n
n
X
i=1
log p(Xi|Xn)
=
log(n +
N
X
j=1
aj) −1
n
n
X
i=1
N
X
j=1
Xij log(nj + aj)
=
log(n +
N
X
j=1
aj) −
N
X
j=1
nj
n log(nj + aj).

2.2. MULTINOMIAL DISTRIBUTION
45
A part of the cross validation loss is
Ew[1/p(Xi|w)]
=
Z(Xn \ Xi)
Z(Xn)
=
QN
j=1 Γ(−X(j)
i
+ nj + aj)
Γ(n −1 + PN
j=1 aj)
·
Γ(n + PN
j=1 aj)
QN
j=1 Γ(nj + aj)
=
n −1 + PN
j=1 aj
QN
j=1(nj + aj −1)X(j)
i
.
Hence the cross validation loss is given by
Cn
=
1
n
n
X
i=1
log Ew[1/p(Xi|Xn)]
=
log(n −1 +
N
X
j=1
aj) −1
n
n
X
i=1
N
X
j=1
X(j)
i
log(nj + aj −1)
=
log(n −1 +
N
X
j=1
aj) −
N
X
j=1
nj
n log(nj −1 + aj).
(2.17)
The above equations for Fn, Tn, Cn, and Wn can be applicable in any
sample Xn. However, if we adopt the hyperparameter a = (a1, a2, ..., aN) as
0 < aj ≤1, and if at least one of nj (j = 1, 2, ..., N) is equal to zero, then
the cross validation loss diverges. In practical applications, we had better
remark that, if N is large or n is small, the data contains nj = 0. Then by
using
Z
p(x|w)αp(w|Xn)dw =
Γ(n + P
j aj) Q
j Γ(αx(j) + nj + aj)
Γ(n + α + P
j aj) Q
j Γ(nj + aj)
,
(2.18)
where P
j and Q
j represent the sum and the product for j = 1, 2, 3, ...N
respectively, we can derive
Vw[log p(x|w)]
=
∂2
∂α2
h
log
Z
p(x|w)αp(w|Xn)dw
i
α=0
=
N
X
j=1
(x(j))2ψ′(nj + aj) −ψ′(n +
N
X
j=1
aj)
where ψ′(x) = (log Γ(x))′′ is the trigamma function. Therefore WAIC is
given by
Wn = Tn + Vn,

46
CHAPTER 2. STATISTICAL MODELS
where
Vn =
N
X
j=1
nj
n ψ′(nj + aj) −ψ′(n +
N
X
j=1
aj).
Assume that p(x|w0) is the true distribution, where
w0 = (w01, w02, ..., w0N).
The generalization loss is explicitly given by
Gn
=
−
X
x
p(x|w0) log p(x|Xn)
=
−
X
x
log
QN
j=1(nj + aj)x(j)
n + PN
j=1 aj
 N
Y
j=1
(w0j)x(j)
=
log(n +
N
X
j=1
aj) −
X
x
{
n
X
j=1
x(j) log(nj + aj)}
N
Y
j=1
(w0j)x(j)
=
log(n +
N
X
j=1
aj) −
N
X
j=1
w0j log(nj + aj).
(2.19)
The entropy and the empirical entropy of the true distribution are respec-
tively given by
S
=
−
X
x
p(x|w0) log p(x|w0)
=
−
X
x
n
Y
j=1
(w0j)x(j) log(
n
Y
j=1
(w0j)x(j))
=
−
N
X
j=1
w0j log w0j,
(2.20)
Sn
=
−1
n
n
X
i=1
log p(Xi|w0)
=
−
N
X
j=1
nj
n log w0j.
(2.21)
Hence the generalization error can be calculated.
Example 6. An experiment was conducted for the case N = 5, w0 =
(0.1, 0.15, 0.2, 0.25, 0.3), and a = (1.1, 1.1, 1.1, 1.1, 1.1).
Figure 2.3 shows

2.2. MULTINOMIAL DISTRIBUTION
47
0
200
400
600
800
1000
-4
-2
0
2
4
6
8
10
12
Fn -n Sn : Free Energy - n*Entropy
Sample size n
Figure 2.3: Fn −nSn for n = 1, 2, ..., 1000.
The free energy or the mi-
nus log marginal likelihood of the multinomial distribution is shown. The
asymptotic behavior of the random variable Fn −nSn is in proportion to
log n.
experimental results of Fn −nSn n = 1, 2, 3, .., 1000. Figure 2.4 shows ex-
perimental results for n = 20.
(1) Histogram of the training error, Tn −Sn
(2) Cross validation error, Cn −Sn
(3) Generalization error and the cross validation error
(4) Histogram of the generalization error, G −S
(5) Histogram of WAIC error, Wn −Sn
(6) Generalization error and WAIC
The averages and standard deviations of Gn −S, Cn −Sn, and Wn −Sn are
numerically approximated by 10000 independent trials.
Average:
0.0684, 0.0700, 0.0672,
Standard deviation:
0.0502, 0.0749, 0.0749.
The variance of the cross validation error is almost same as the WAIC error.
Moreover,
E|(Gn −S) −(Cn −Sn)|
=
0.0948,
E|(Gn −S) −(Wn −Sn)|
=
0.0943.
Therefore, in this case the cross validation error is almost same as the WAIC
error.

48
CHAPTER 2. STATISTICAL MODELS
-0.5
0
0.5
0
500
1000
1500
(1) Training Error (Tn-Sn)
-0.5
0
0.5
0
500
1000
1500
(4) Generalization Error (Gn-S)
-0.5
0
0.5
0
500
1000
1500
(2) Cross Validation Error (Cn-Sn)
Cross Validation Error
0
0.5
-0.5
0
0.5
(3) (Generalization, CV)
-0.5
0
0.5
0
500
1000
1500
(5) WAIC (Wn-Sn)
0
0.5
-0.5
0
0.5
WAIC
(6) (Generalization, WAIC)
Figure 2.4: Bayesian observables of multinomial distribution for n = 20.
Bayesian observables of multinomial distribution are shown with n = 20.
Histograms of (1) training error Tn −Sn, (2) cross validation error Cn −Sn,
(4) generalization error Gn −S, and (5) WAIC error Wn −Sn. Distributions
of (3) (Gn −S, Cn −Sn), and (6) (Gn −S, Wn −Sn).
2.3
Linear Regression
In the foregoing two models, the posterior averaging could be done analyti-
cally. In this section, we study a linear regression model, where the posterior
averaging is numerically approximated by random sampling. Let us study
a statistical model and a prior which are deﬁned for x, y, a ∈R1, s > 0 by
p(y|x, a, s)
=
r s
2π exp(−s
2(y −ax)2),
ϕ(a, s|r)
=
1
Y (0, 1, 1) sr exp(−s
2(a2 + 1)),
where r is a hyperparameter. This prior is proper if and only if r > −1/2.
The normalizing constant Y (ℓ, µ, ρ) is given by
Y (ℓ, µ, ρ)
=
Z ∞
−∞
da
Z ∞
0
ds sr+ℓ/2 exp(−s
2(µa2 + ρ)).

2.3. LINEAR REGRESSION
49
Lemma 2. The normalizing constant Y (ℓ, µ, ρ) is equal to
Y (ℓ, µ, ρ)
=
(2π/µ)1/2(2/ρ)r+(ℓ+1)/2Γ(r + (ℓ+ 1)/2).
Proof. By the deﬁnition,
Y (ℓ, µ, ρ)
=
Z ∞
−∞
da
Z ∞
0
ds sr+ℓ/2 exp(−s
2(µa2 + ρ))
=
Z ∞
0
ds sr+ℓ/2(2π/sµ)1/2 exp(−sρ
2 )
=
(2π/µ)1/2
Z ∞
0
ds sr+ℓ/2−1/2 exp(−sρ
2 )
=
(2π/µ)1/2(2/ρ)r+ℓ/2+1/2
Z ∞
0
ds sr+ℓ/2−1/2 exp(−s)
=
(2π/µ)1/2(2/ρ)(1+2r+ℓ)/2Γ((ℓ+ 2r + 1)/2),
which completes the lemma.
Let (Xn, Y n) = {(Xi, Yi); i = 1, 2, ..., n} be a sample which is inde-
pendently taken from a true probability density q(x, y). The simultaneous
distribution Ω(a, s, Y n|Xn) for given Xn using the statistical model is given
by
Ω(a, s, Y n|Xn)
≡
ϕ(a, s|r)
n
Y
i=1
p(Yi|Xi, a, s)
=
sn/2+r
Y (0, 1, 1)(2π)n/2 exp(−s
2(
n
X
i=1
(Yi −aXi)2 + 1 + a2))
=
sn/2+r
Y (0, 1, 1)(2π)n/2 exp[−s
2{A(a −B)2 + C}],
where A, B, and C are constant functions of the parameter,
A
=
X
i
X2
i + 1,
B
=
P
i XiYi
P
i X2
i + 1,
C
=
{−(P
i XiYi)2
P
i X2
i + 1 +
X
i
Y 2
i + 1}.

50
CHAPTER 2. STATISTICAL MODELS
Note that, even if a prior is improper, the posterior distribution is well-
deﬁned if (n −1)/2 + r > −1. As a result, the posterior density is
p(a, s|Xn, Y n) =
1
Z(Xn, Y n)Ω(a, s, Y n|Xn),
where the partition function or the marginal likelihood is
Z(Xn, Y n) =
Z
Ω(a, s, Y n|Xn)dads =
Y (n, A, C)
(2π)n/2Y (0, 1, 1).
The free energy or the minus log marginal likelihood is
Fn = n
2 log(2π) + log Y (0, 1, 1) −log Y (n, A, C).
Then the posterior density can be decomposed as
p(a, s|Xn, Y n)
=
p(a|s, Xn, Y n) p(s|Xn),
(2.22)
p(a|s, Xn, Y n)
∝
exp(−sA
2 (a −B)2),
(2.23)
p(s|Xn)
∝
s(n−1)/2+r exp(−Cs
2 ).
(2.24)
Thus a set of parameters {(at, st); t = 1, 2, ..., T} which is independently
subject to the posterior density can be obtained by the following procedure.
Firstly each variable in {st} is independently taken from p(s|Xn), then each
variable in {at} is independently taken from p(a|s, Xn, Y n). Then the pos-
terior average of a function f(a, s) can be numerically approximated by
E(a,s)[f(a, s)] ≈1
T
T
X
t=1
f(at, st).
(2.25)
The generalization, training, and cross validation losses and WAIC are ap-
proximated respectively by
Gn
≈
−
Z
q(y|x)q(x) log
 1
T
T
X
t=1
p(y|x, at, st)

dxdy,
Tn
≈
−1
n
n
X
i=1
log
 1
T
T
X
t=1
p(Yi|Xi, at, st)

,
Cn
≈
1
n
n
X
i=1
log
 1
T
T
X
t=1
1/p(Yi|Xi, at, st)

,
Wn
≈
Tn + Vn,

2.3. LINEAR REGRESSION
51
where Vn is the sum of the posterior variance,
Vn
=
1
n
n
X
i=1
n 1
T
T
X
t=1
(log p(Yi|Xi, at, st))2
−
 1
T
T
X
t=1
(log p(Yi|Xi, at, st))
2o
.
Note that replacement of Vn by VnT/(T −1) gives the unbiased estimation
of the posterior variance. If a true distribution q(x, y) = q(x)q(y|x) is equal
to
q(x)
=
1
√
2π exp(−x2
2 ),
q(y|x)
=
p(y|x, a0, s0),
then the entropy and the empirical entropy are respectively given by
Sn
=
1
2 log(π/2) + s0
2
n
X
i=1
(Yi −a0Xi)2,
S
=
1
2 log(π/2) + 1
2.
Remark 15. Let us deﬁne the Akaike information criterion in Bayes (AICb)
and deviance information criterion DIC by the following equations.
AICb
=
Tn + d
n,
DIC
=
−2
n
n
X
i=1
1
T
T
X
t=1
log p(Yi|Xi, at, st)
+ 1
n
n
X
i=1
log p(Yi|Xi, a, s),
where d is the number or dimension of parameters and (a, s) is the empirical
mean of the posterior parameters {(at st)}.
The criteria AICb and DIC
can be understood as estimators of the generalization loss. Note that the
conventional AIC is deﬁned by using the maximum likelihood estimator,
whereas AICb is by the Bayesian predictive density. Hence AIC ̸= AICb in
general. If a true distribution is realizable by a statistical model and if the
posterior distribution can be approximated by some normal distribution,
then AIC, AICb, and DIC are the asymptotically unbiased estimators of the
generalization loss. If otherwise, the statement does not apply.

52
CHAPTER 2. STATISTICAL MODELS
200
400
600
800
1000
0
1
2
3
4
5
6
7
8
9
x 10
-3
Number of Parameters
Standard Deviation
 
 
Generalization
CV
WAIC
AIC
DIC
Figure 2.5: Standard deviations caused by posterior sampling. In a simple
linear regression problem, standard deviations of the generalization, cross
validation, WAIC, AICb, and DIC errors are compared as a function of the
number of the posterior parameters.
Example 7. For a case when r = 1, (a0, s0) = (0.3, 0.5), and n = 30, an
experiment was conducted. The true distribution of X was set as the stan-
dard normal distribution and that of Y is a0X + N(0, 1/s0). Firstly, let
us examine the ﬂuctuation caused by posterior sampling.
The standard
deviations of these observables for a ﬁxed sample (Xn, Y n) in the cases
T = 100, 200, ..., 1000 are shown in Figure 2.5. The posterior standard devi-
ation of the cross validation errors are larger than other errors. The standard
deviations were
σ(AICb) < σ(DIC) < σ(WAIC) < σ(cross validation).
Note that this order is not yet mathematically proved, and it may depend
on the conditions about the true distribution and a statistical model. In
fact, if the posterior distribution can not be approximated by any normal
distribution, the variance of DIC becomes far larger than others. Secondly,
we study the averages by comparing them as functions of hyperparameters,
r = −3, −1, 1, 3, 5. For r < −1/2, the prior is improper. However, the pos-
terior is well deﬁned and the cross validation loss and WAIC can estimate
the generalization loss. In Figure 2.6 the averages of the generalization er-
ror, the cross validation error, WAIC error, AICb error, and DIC error are
compared. In this experiment their averages were numerically calculated

2.4. NEURAL NETWORK
53
-2
0
2
4
0.02
0.03
0.04
0.05
0.06
0.07
0.08
Hyperparameter r
Error
 
 
Generalization
CV
WAIC
AIC
DIC
Figure 2.6: Information Criteria as a function of a hyperparameter. In a
simple linear regression problem, the averages of the generalization, cross
validation, WAIC, AICb, and DIC are compared as a function of a hyper
parameter r. These are averages over 1000 independent samples with n = 30.
Both the cross validation error and WAIC error exhibited the same behaviors
of the generalization error, whereas neither AICb nor DIC did.
using 1000 independent samples of (Xn, Y n), n = 30. As estimators of the
generalization error, neither AICb nor DIC gave an appropriate function of
the hyperparameter, whereas both the cross validation and WAIC did. In
the following chapters, we show that the averages of the cross validation loss
and WAIC have the same higher order asymptotic behavior as the general-
ization loss, resulting that they can be employed in evaluation of the average
generalization loss as a function of a hyperparameter.
2.4
Neural Network
In many statistical models, the posterior average cannot be calculated an-
alytically, hence the Markov chain Monte Carlo method is necessary (see
Chapter 7). Moreover, in statistical models which have hierarchical struc-
tures or hidden variables, the posterior distribution cannot be approximated
by any normal distribution. An example of such statistical model is an ar-
tiﬁcial neural network. It is a function f(x, w) = {fj(x, w)} from x ∈RM

54
CHAPTER 2. STATISTICAL MODELS
to RN which is deﬁned by
fj(x, w) = σ
 K
X
k=1
ujkσ(
L
X
ℓ=1
wkℓxℓ+ θk) + φj

,
(2.26)
where σ(t) is a sigmoidal function of t,
σ(t) =
1
1 + exp(−t)
and a parameter w is
w = {ujk, wkℓ, φj, θk},
where ujk and wkℓare called weight parameters and φj and θk bias param-
eters. This function is called a three-layer neural network. Recently statis-
tical models which have deeper layers are being applied to many practical
problems. The statistical model for a regression problem using a three-layer
neural network is a conditional probability density
p(y|x, w) =
1
(2πs2)N/2 exp

−1
2s2 ∥y −f(x, w)∥2
.
(2.27)
A neural network can be used also for classiﬁcation problem. For the case
y ∈{0, 1} its statistical model is represented by
p(y|x, w) = f(x, w)y(1 −f(x, w))1−y.
In this model, f(x, w) is used for estimating the conditional probability of
y for a given x. By setting a prior on the parameter w, the posterior and
predictive distributions are numerically.
Since the posterior distribution
cannot be approximated by any normal distribution, neither AIC nor BIC
can be used for evaluation of a model and a prior. However, WAIC and
ISCV can be used.
Example 8. An experiment was conducted about a neural network which had
no bias parameters. An input sample {xi ∈R2; i = 1, 2, ..., n} (n = 200)
was taken from the uniform distribution in [−2, 2]2. The true conditional
distribution was made by p(y|x, w0) where p(y|x, w0) was a neural network
with three hidden units H = 3. A prior was set by the normal distribution
N(0, 102) on each ujk and wkℓ. The posterior distribution was approximated
by a Metropolis method (see Chapter 7.1). We prepared ﬁve candidate neu-
ral networks which have H = 1, 2, 3, 4, 5 hidden units. Figure 2.7 shows the
results of 20 trials of:

2.4. NEURAL NETWORK
55
1
2
3
4
5
0
0.05
0.1
0.15
0.2
0.25
Hidden Units
WAIC
1
2
3
4
5
0
0.05
0.1
0.15
0.2
0.25
ISCV
Hidden Units
1
2
3
4
5
0
0.05
0.1
0.15
0.2
0.25
Hidden Units
AIC
1
2
3
4
5
0
0.05
0.1
0.15
0.2
0.25
Hidden Units
GE
Figure 2.7: Classiﬁcation problem. Model comparison of neural networks
is studied. The true number of the hidden units was three. Both ISCV
and WAIC errors correctly estimated the generalization error. AIC overes-
timated the generalization error, and DIC did not work appropriately.
(1) Upper, left: G −S for H = 1, 2, 3, 4, 5
(2) Upper, right: AICb −Sn for H = 1, 2, 3, 4, 5
(3) Lower, left: ISCV −Sn for H = 1, 2, 3, 4, 5
(4) Lower, left: WAIC −Sn for H = 1, 2, 3, 4, 5
where G, ISCV, AICb, and WAIC are calculated by using the Markov chain
Monte Carlo method. In this problem the values of DIC were quite dif-
ferent from others, which are not appropriate for evaluation of hierarchical
statistical models. Note that in a neural network the posterior average of
the parameter has no meaning. In Bayesian estimation, the generalization
errors of a neural network did not so increase even if the statistical model
was larger than a true model. This is the general property of Bayesian in-

56
CHAPTER 2. STATISTICAL MODELS
ference in hierarchical models, whose mathematical reason will be clariﬁed
by Chapter 5. Even in the case H = 3, in which the statistical model is
just equal to the true distribution, the generalization error was sometimes
not minimized. Such a phenomenon was caused by the local minima of the
Metropolis method in neural networks. Both ISCV and WAIC correctly es-
timated the generalization errors, whereas AICb overestimated. Note that,
in Bayesian estimation, the increase of the generalization error is very small
even if a statistical model is redundant for a true model, resulting that the
increases of both ISCV and WAIC are also small. In selection of hierarchical
models, a statistician should understand this point.
2.5
Finite Normal Mixture
Another example of nonregular statistical models is a normal mixture. Let
N(x|b) be a normal distribution of x ∈RM whose average is b ∈RM,
N(x|b) =
1
(2π)M/2 exp

−∥x −b∥2
2

.
A normal mixture on RM is deﬁned by
p(x|a, b) =
K
X
k=1
akN(x|bk),
(2.28)
where a = (a1, a2, ..., aK) and b = (b1, b2, ..., bK) are parameters of a normal
mixture, which satisﬁes P aj = 1 and aj ≥0, and bk ∈Rd. The ﬁnite
positive integer K is called the number of components. For the prior, we
adopt
ϕ(a)
=
1
z1
K
Y
k=1
(ak)βk−1,
ϕ(b)
=
1
z2
K
Y
k=1
exp

−1
2σ2 ∥bk∥2
,
where ϕ(a) and ϕ(b) are the Dirichlet distribution with index {βk} and the
normal distribution, respectively. Here βk, σ2 > 0 are hyperparameters and
z1, z2 > 0 are constants.

2.5. FINITE NORMAL MIXTURE
57
A variable y = (y1, y2, ..., yK) is competitive if yk = 1 for some k and if
yℓ= 0 for other ℓ̸= k. A statistical model on (x, y) is deﬁned by
p(x, y|a, b) =
K
Y
k=1

akN(x|bk)
yk.
(2.29)
Then
p(x|a, b) =
X
y
p(x, y|a, b),
where the summation is taken over all competitive y. In a normal mixture,
by understanding Y n = {Yi} as hidden or latent variables of a statistical
model p(x, y|a, b), the posterior distribution of (a, b, Y n) is given by
p(a, b, Y n|Xn) ∝ϕ(a)ϕ(b)
n
Y
i=1
p(Xi, Yi|a, b).
By using the Gibbs sampler, which is explained in Chapter 7, we obtain the
posterior samples {at, bt, Y n
t }. Hence by using {at, bt}, the posterior and
predictive distributions are numerically approximated.
Example 9. Let us study a case M = 2,n = 100, where a true distribution
was set as:
q(x) = 1
3N(x|(−2, −2)) + 1
3N(x|(0, 0)) + 1
3N(x|(2, 2)).
(2.30)
The hyperparameters of the prior distribution were α = 0.5 and σ = 10.
Fifty independent trials were collected and the generalization and cross val-
idation losses were observed. The candidate statistical models were K =
1, 2, 3, 4, 5. The posterior distribution was numerically approximated by the
Gibbs sampler. We calculated G −S, CV −Sn, AICb −Sn, DIC −Sn,
and WAIC −Sn. Figure 2.8 shows their averages and standard deviations.
The generalization loss does not so increase even if the statistical model is
redundant for the true distribution. In fact the generalization loss in Figure
2.8 does not increase as AIC. This is the advantage of the Bayesian estima-
tion. However, the increases of the cross validation and WAIC are too small
compared to random ﬂuctuations. In practical applications, if the increases
of the cross validation and WAIC are far smaller than d/n (d is the number
of paramters and n is the sample size) even if the model becomes more com-
plex, then the minimal model in the set of the models which gives almost
same cross validation and WAIC should be selected.

58
CHAPTER 2. STATISTICAL MODELS
1
2
3
4
5
-0.05
0
0.05
0.1
0.15
0.2
Number of Components
Loss and Criteria
 
 
GE
CV
WAIC
DIC
AIC
Figure 2.8: Model comparison of normal mixture. Model comparison of a
normal mixture is studied. The true density corresponds to K = 3. The
averages of ISCV and WAIC errors were equal to that of the generalization
error, whereas those of DIC and AIC not.

2.6. NONPARAMETRIC MIXTURE
59
2.6
Nonparametric Mixture
A nonparametric normal mixture is deﬁned by
p(x|a, b) = lim
K→∞
n K
X
k=1
akN(x|bk)
o
,
where a = (a1, a2, ..., ) and b = (b1, b2, ...) are inﬁnite dimensional parame-
ters, which satisfy P ak = 1, and ak ≥0. The prior distributions are set
by
ϕ(a|α)
=
lim
K→∞
n
1
z1(α)
K
Y
k=1
(ak)α/K−1o
,
ϕ(b|σ)
=
lim
K→∞
n
1
z2(σ)
K
Y
k=1
exp(−1
2σ2 ∥bk∥2)
o
,
where z1(α) and z2(σ) are normalizing constants. From the mathematical
point of view, this model is deﬁned by using Dirichlet process theory [22, 23],
by which it is shown that p(x|a, b) is given by the discrete summation with
probability one. See Section 10.6.
Although the parameter belongs to the inﬁnite dimensional space, we can
construct Markov chain Monte Carlo method by manupulating essentially
ﬁnite dimentional parameters, resulting that the posterior and predictive
distributions are numerically appoximated [21][32]. For example, a Chinese
restraurant process [47] and Stick-breaking process [39] are proposed. In [39],
it is also proved that nonparametric Bayesian estimation can be accurately
approximated by a ﬁnite mixture model.
Let y = (y1, y2, ..., yk, ...) be an inﬁnite dimensional competitive variable.
Only one k, yk = 1 and others are zero. A statistical model on (x, y) is
deﬁned by
p(x, y|a, b) = lim
K→∞
n K
Y
k=1

akN(x|bk)
yko
.
(2.31)
Then
p(x|a, b) =
X
y
p(x, y|a, b).
By using the hidden or latent variable Y n = {Yi}, the posterior distribution
of (a, b, Y n) is given by
p(a, b, Y n|Xn) ∝ϕ(a)ϕ(b)
n
Y
i=1
p(Xi, Yi|a, b).

60
CHAPTER 2. STATISTICAL MODELS
-5
0
5
-6
-4
-2
0
2
4
6
(2) Sample, n = 100
(1) True Distribution
-5
0
5
-6
-4
-2
0
2
4
6
(3) Nonpara,alpha=1.G=0.089362
-5
0
5
-6
-4
-2
0
2
4
6
(4) Finite,K=10,alpha=10.G =0.085421
-5
0
5
-6
-4
-2
0
2
4
6
Figure 2.9: Nonparametric and ﬁnite mixture. (1) The true distribution
cannot be represented by any ﬁnite mixture. (2) A sample from the true
distribution, n = 100. (3) An estimated result by nonparametric Bayes α =
1. The generalization error was 0.893. (4) An estimated result by a ﬁnite
mixture. The generalization error was 0.854. Even if a true distribution
is represented by a nonparametric model, the nonparametric method is not
always appropriate for statistical estimation.

2.6. NONPARAMETRIC MIXTURE
61
-2
0
2
4
6
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
0.2
Hyperparameter log alpha
(2) Hyperparameter Optimization
 
 
Generalization error
WAIC error
ISCV error
-2
0
2
4
6
0
10
20
30
40
50
Hyperparameter log alpha
(1) Average number of components
 
 
Average Components
Figure 2.10: Hyperparameter optimization in nonparametric Bayes. (1) The
horizontal and vertical lines show the log hyperparameter and the average
number of the components. If the hyperparameter increases, then the num-
ber of components becomes larger. (2) Generalization error, WAIC error,
and ISCV error are compared with respect to the hyperparameter log α.
By using the Gibbs sampler, which is explained in Chapter 7, we obtain the
posterior samples {at, bt, Y n
t } which consist of ﬁnite dimensional parameters
such that the posterior distribution is numerically approximated.
Hence
we obtain the posterior and predictive densities, resulting that information
criteria can be calculated. Sometimes one might think that neither model
selection nor hyperparameter optimization could be necessary in the non-
parametric method because they should be automatically estimated. How-
ever, such consideration is wrong. In general, estimation of something needs
its prior. In other words, estimation of a model and a hyperparmeter recur-
sively requires new priors on them. Thus we need the evaluation procedure
for preventing the inﬁnite preparation of priors.
Example 10. A true distribution on x ∈R2 was set as
q(x) =
lim
K0→∞
n K0
X
k=1
a0kN(x|b0k)
o
,
where N(x|b0k) is the normal distribution on R2 and b0k = (b01k, b02k) is

62
CHAPTER 2. STATISTICAL MODELS
-2
0
2
4
6
0
0.05
0.1
0.15
0.2
0.25
Hyperparameter log alpha
(1) Cross validation error
-2
0
2
4
6
0
0.05
0.1
0.15
0.2
0.25
Hyperparameter log alpha
(2) WAIC error
-2
0
2
4
6
0.05
0.1
0.15
0.2
Hyperparameter log alpha
(3) Generalization eror
Figure 2.11: Fluctuations of Bayesian observables. Fluctuations of observ-
ables in nonparametric Bayesian estimation are shown for 100 independent
samples.
The horizontal lines are log α.
The vertical lines are (1) cross
validation, (2) WAIC, and (3) generalization errors. The lines connect the
results of the same sample.
The optimal α could be found by the cross
validation and WAIC. If α was made smaller then the standard deviation of
the generalization error became larger.
deﬁned by
a0k
=
1/K0,
b01k
=
3 cos(2πk/K0),
b02k
=
3 sin(2πk/K0).
The density function of q(x) is shown in Figure 2.9 (1).
Note that the
true density is not realizable by any ﬁnite mixture. (2) A sample n = 100
independently taken from q(x) is shown. (3) shows an estimated result by
nonparametric method with α = 1. The generalization error was 0.0893. (4)
An estimated result by a ﬁnite mixture with α = 10 and K = 10 is shown.
The generalization error was 0.0824.
If we employ the nonparametric Bayes method, the hyperparameter α
should be controlled appropriately, because it strongly aﬀects the estimated
result. If α is close to zero, then the average number of components be-
comes too small. If otherwse, too large. In Figure 2.10 (1), the average
number of the components for a given α is shown. One might think that
the optimal model selection could be done by the nonparametric method,
but such consideration is wrong, because the model selection problem is
replaced by the hyperparameter optimization. Also one might think that
the hyperparameter α could be optimized by its posterior distribution by

2.7. PROBLEMS
63
preparing its prior, but such consideration is also wrong, because the prob-
lem is also replaced by the optimal setting of the hyperprior of α. In other
words, the nonparametric Bayes method does not realize the automatic con-
trol. On the other hand, even in nonparametric Bayes cases, the optimal
hyperparameter can be found by the generalization loss. In Figure 2.10 (2),
the average and standard deviation of generalization, cross validation, and
WAIC errors are compared for 100 independent trials with n = 100. Their
ﬂuctuations are shown in Figure 2.11 In this case, the optimal hyperparam-
eter was α = exp(2), because the true distribution q(x) cannot be realized
by any ﬁnite mixtures. If the true distribution can be realized by some ﬁnite
mixtures, then the optimal α would be smaller.
2.7
Problems
1.
The predictive density of the normal distribution eq.(2.1) is given by
eq.(2.10),
p(x|Xn)
∝
1
[(x −C2)2 + C1]C3 ,
(2.32)
where
C1
=
(ˆφ1 ˆφ3 −ˆφ2
2)(ˆφ3 + 1)/ˆφ2
3,
(2.33)
C2
=
ˆφ2/ˆφ3,
(2.34)
C3
=
(ˆφ3 + 1)/2.
(2.35)
Prove that the average and variance of this predictive distribution are given
by
Z
x p(x|Xn)dx
=
C2,
(2.36)
Z
(x −C2)2p(x|Xn)dx
=
C1
2(C3 −3/2),
(2.37)
by using a formula
Z ∞
−∞
dx
[(x −C2)2 + C1]C3 = C1/2−C3
1
Γ(C3 −1/2)Γ(1/2)
Γ(C3)
.

64
CHAPTER 2. STATISTICAL MODELS
Let us deﬁne two estimators of the variance,
Vbayes
=
C1
2(C3 −3/2),
Vml
=
1
n
n
X
i=1
X2
i −
 1
n
n
X
i=1
Xi
2
.
Prove that, if φ1φ3 > φ2
2, then Vbayes > Vml holds.
2. In the prior of the multinomial distribution eq.(2.13), let us assume that
PN
j=1 aj = A, where A > 0 is a constant. Then the cross validation loss Cn
in eq.(2.17) as a function of the hyperparameter a = {aj} is minimized if
and only if
N
X
j=1
(nj/n) log
(nj/n)
(nj −1 + aj)/(n −N + A)
(2.38)
is minimized. Also prove that Cn is minimized if and only if
aj = ˆaj,
where
ˆaj ≡1 + (A −N)nj
n
,
by using the fact that eq.(2.38) is Kullback-Leibler divergence between two
probability distributions. On the other hand, prove that the generalization
error using eq.(2.19) and the true entropy,
Gn −S =
N
X
j=1
w0j log
w0j
(nj + aj)/(n + A)
(2.39)
are minimized if and only if a∗
j = w0j(n + A) −nj. Note that ˆaj and a∗
j are
the hyperparameters that minimize the cross validation and generalization
losses, respectively. The standard deviations of ˆaj and a∗
j are in proportion to
1/√n and √n, respectively, resulting that ˆaj →1+(A−N)w0j in probability,
whereas, a∗
j does not converge even if n →∞. Note that the random variable
Gn −S is diﬀerent from the average generalization error E[Gn] −S.
3. In the linear regression problem, two approximation methods of eq.(2.25)

2.7. PROBLEMS
65
for a given function f(a, s) are deﬁned by
E1[f]
=
1
K
K
X
k=1
f(ak, sk),
E2[f]
=
1
K
K
X
k=1
Z
f(a, sk)p(a|sk, Xn, Y n)da,
where {ak} and {sk} are independently taken from eq.(2.23) and eq.(2.24)
respectively. Prove that E1[f] and E2[f] have the same average and that
the variance of E1[f] is not smaller than E2[f]. In other words, the partial
posterior integration makes the variance smaller.
4. Let f(x, w) be a function of a neural network given in eq.(2.26). Then
a function w 7→f(x, w) is not one-to-one, showing that the posterior dis-
tribution does not concentrate on any local parameter region. Therefore,
even if the posterior distribution is precisely obtained, the average param-
eter Ew[w] is not an appropriate estimator. Discuss the reason why DIC
cannot be applied to such statistical models.
5.
Let us study model selection problems of a normal mixture given by
eq.(2.28).
Let K(n) be the optimal number of components in the set
{1, 2, ..., ∞} that minimizes E[Gn] for a given sample size n. Discuss the
behavior of K(n) if the true distribution is one of the following densities.
q1(x)
=
1
2N(x|(0.2, 0.2)) + 1
2N(x|(0.4, 0.4)),
q2(x)
=
99
100N(x|(−1, −1)) +
1
100N(x|(1, 1)),
q3(x)
=
∞
X
k=1
1
2k N(x|(0.2k, 0.2k)).
The probability density functions q1(x) and q2(x) consist of two normal
distributions. However, they are almost same as one normal distribution,
hence K(n) = 1 for not so large n. If n is suﬃciently large, then K(n) = 2.
In the case q3(x), the true distribution is not contained in any ﬁnite mixture
of normal distributions. In this case K(n) slowly becomes larger when n
increases.


Chapter 3
Basic Formula of Bayesian
Observables
In this chapter, we introduce the basic Bayesian theory. For an arbitrary
triple of a true distribution, a statistical model, and a prior, the behaviors of
the free energy or the minus log marginal likelihood, the generalization loss,
cross validation loss, training loss, and WAIC are derived by the following
procedure.
(1) Firstly, we deﬁne the formal relation between a true distribution and a
statistical model.
(2) Secondly, deﬁnitions of Bayesian observables and their normalized ones
are introduced.
(3) Thirdly, the cumulant generating function of the Bayesian prediction is
deﬁned.
(4) And lastly, the basic theory of Bayesian statistics is proved by using the
cumulant generating function.
At the end of this chapter, we show the recipe for the Bayesian theory
construction and its application. In this chaper, we assume that a sample is
taken from an unknown true distribution and that a statistical model and a
prior are arbitrarily ﬁxed.
3.1
Formal Relation between True and Model
In this section, we deﬁne several formal relations between a true probability
density q(x) and a statistical model p(x|w).
Deﬁnition 4. (Realizability) Let W ⊂Rd be a set of all parameters. If
67

68
CHAPTER 3. BASIC FORMULA OF BAYESIAN OBSERVABLES
there exists w0 ∈W such that q(x) = p(x|w0), then q(x) is said to be
realizable by a statistical model p(x|w). If otherwise, q(x) is unrealizable.
For a given pair q(x) and p(x|w), the set of true parameters is deﬁned by
W00 = {w ∈W ; q(x) = p(x|w) for arbitrary x s.t. q(x) > 0}.
By the deﬁnition, q(x) is realizable by p(x|w) if and only if W00 is not the
empty set. The set W00 is equal to the set of zeros of the Kullback-Leibler
distance,
W00 = {w ∈W ;
Z
q(x) log
q(x)
p(x|w)dx = 0}.
If W00 is not the empty set, then for an arbitrary w0 ∈W00, p(x|w0) repre-
sents the same probability density function q(x). However, derived functions
 ∂
∂wj
k
log p(x|w)

w=w0
may depend on the parameter w0 in W00.
For a true probability density function q(x) and a statistical model
p(x|w), the average log loss function is deﬁned by
L(w) = −
Z
q(x) log p(x|w)dx.
(3.1)
It follows that
L(w)
=
−
Z
q(x) log q(x)dx +
Z
q(x) log
q(x)
p(x|w)dx
=
S + K(q(x)||p(x|w)),
where S is the entropy of the true distribution and K(q(x)||p(x|w)) is the
Kullback-Leibler distance from q(x) to p(x|w).
If q(x) is realizable by a
statistical model, then the average log loss function is minimized if and only
if w ∈W00, and its minimum value is equal to the entropy of the true
distribution.
Deﬁnition 5. (Regularity) For a given pair of q(x) and p(x|w), let W0 be
the set of minimum points of the average log loss function L(w),
W0 = {w ∈W ; L(w) = min
w′ L(w′)},

3.1. FORMAL RELATION BETWEEN TRUE AND MODEL
69
which is called the set of optimal parameters for the minimum average log
loss function. If W0 consists of a single element w0 and there exists an open
set U such that w0 ∈U ⊂W and if the Hessian matrix ∇2L(w0) at w0
deﬁned by

∇2L(w0)

ij =

∂2L
∂wi∂wj

(w0)
(3.2)
is positive deﬁnite, then q(x) is said to be regular for p(x|w).
By the deﬁnition, W0 is equal to the set of minimum points of the
Kullback-Leibler distance K(q(x)||p(x|w)).
If W is a compact set and if
L(w) is a continuous function, then L(w) has a minimum point, hence W0
is not the empty set.
A true probability density q(x) is realizable by a
statistical model p(x|w) if and only if
W00 = W0.
In general, W0 may contain multiple elements. If a true density is unrealiz-
able by p(x|w), then there may exist w1, w2 ∈W0 which satisfy p(x|w1) ̸=
p(x|w2).
Deﬁnition 6. (Essential uniqueness) Assume that W0 is not the empty set.
If there exists a unique probability density function p0(x) such that,
for arbitrary w0 ∈W0,
p(x|w0) = p0(x),
then it is said that the optimal probability density function is essentially
unique.
If q(x) is realizable by p(x|w), then the optimal probability density func-
tion is essentially unique, because p0(x) = q(x). If W0 consists of a single
element, then the optimal probability density function is unique and essen-
tially unique.
Let us study several cases using examples from the viewpoints of realiz-
ability, regularity, and uniqueness.
Example 11. (Realizable, regular, and unique) A true probability density
function q(x) and a statistical model p(x|a) are deﬁned by
q(x)
=
1
√
2π
exp(−1
2x2),
p(x|a)
=
1
√
2π exp(−1
2(x −a)2).

70
CHAPTER 3. BASIC FORMULA OF BAYESIAN OBSERVABLES
In this case, the Kullback-Leibler distance is given by
K(a) = 1
2a2.
If W = {a; −1 ≤a ≤1}, then
W00 = W0 = {a ; a = 0}
and the Hessian matrix of the average log loss function is
∇2L(a)|a=0 = ∇2K(a)|a=0 = 1.
Hence q(x) is realizable by and regular for a statistical model p(x|a).
If
W = {a ; 1 ≤a ≤2}, then
W00 = ∅,
W0 = {a ; a = 1}.
Hence q(x) is unrealizable by and nonregular for a statistical model p(x|a).
Example 12. (Realizable, nonregular, and essentially unique) A true proba-
bility density function q(y|x)q(x) and a statistical model p(y|x, a, b)q(x) are
deﬁned by
q(x)
=
 1
(|x| ≤1)
0
(|x| > 1) ,
q(y|x)
=
1
√
2π
exp(−1
2y2),
p(y|x, a, b)
=
1
√
2π exp(−1
2(y −a sin(bx))2).
The set of parameters is deﬁned by
W = {(a, b) ; |a| ≤1, |b| ≤π/2}.
Then the Kullback-Leibler distance is given by
K(a, b) = a2
2
Z 1
0
sin(bx)2dx.
Therefore
W00 = W0 = {(a, b) ∈W ; ab = 0}.
The sets W00 and W0 consist of multiple elements.
Hence q(y|x)q(x) is
realizable by and nonregular for
p(y|x, a, b)q(x). In this case we also say that the conditional density q(y|x)
is realizable by and nonregular for p(y|x, a, b).

3.1. FORMAL RELATION BETWEEN TRUE AND MODEL
71
Example 13. (Unrealizable, regular, and essentially unique) A true proba-
bility density function q(y|x)q(x) and a statistical model p(y|x, a, b)q(x) are
deﬁned by
q(x)
=
 1
(0 ≤x ≤1)
0
(otherwise) ,
q(y|x)
=
1
√
2π
exp(−1
2(y −x2)2),
p(y|x, a, b)
=
1
√
2π
exp(−1
2(y −ax)2).
The set of all parameters is deﬁned by
W = {(a, b) ; |a|, |b| ≤1}.
Then the Kullback-Leibler distance is equal to
K(a, b) = 1
2
Z 1
0
(ax −x2)2dx = a2
6 −a
4 + 1
10.
Therefore
W00 = ∅, W0 = {a ; a = 3/4}.
and
∇2L(a)|a=3/4 = ∇2K(a)|a=3/4 = 1/3.
Hence q(x)q(y|x) is unrealizable by and regular for q(x)p(y|x, a, b).
Also
q(y|x) is unrealizable by and regular for p(y|x, a, b).
Example 14. : (Unrealizable, nonregular, and essentially unique) A true
probability density function q(x, y) = q(x)q(y|x) and a statistical model
p(x, y|a, b) are deﬁned by
q(x, y)
=
1
2π exp(−1
2{x2 + y2}),
p(x, y|a, b)
=
1
2π exp(−1
2{(x −1)2 + (y −a sin(bx))2}),
where the set of all parameters is
W = {(a, b) ; |a| ≤1, |b| ≤π/2}.
Then
K(a, b) = 1
2 + a2
2
Z ∞
−∞
sin(bx)2q(x)dx.

72
CHAPTER 3. BASIC FORMULA OF BAYESIAN OBSERVABLES
Hence
W00 = ∅, W0 = {(a, b) ; ab = 0}.
It follows that q(x, y) is unrealizable by and nonregular for a statistical
model p(x, y|w), however, the optimal model is essentially unique.
Example 15. (Unrealizable, nonregular, and essentially nonunique) A true
probability density function q(x, y) and a statistical model p(x, y|a, b) are
deﬁned by
q(x, y)
=
1
2π exp(−1
2{x2 + y2}),
p(x, y|θ)
=
1
2π exp(−1
2{(x −cos θ)2 + (y −sin θ)2}),
where the set of all parameters is
W = {θ ; −π ≤θ < π}.
Then K(θ) is a constant function of θ,
K(θ) = 1
2.
Therefore
W00 = ∅, W0 = {θ ; −π ≤θ < π} = W.
For an arbitrary θ0 ∈W0, the Kullback-Leibler distance K(q(x)||p(x|θ)) is
equal to a constant 1/2, however, if θ1 ̸= θ2 then p(x, y|θ1) ̸= p(x, y|θ2).
Therefore q(x) is unrealizable by and nonregular for a statistical model.
Moreover, the optimal density is essentially nonunique.
Deﬁnition 7. (Relatively ﬁnite variance of log density ratio function) Let
W and W0 be sets of parameters and optimal parameters for the minimum
average log loss function, respectively. For a given pair w0 ∈W0 and w ∈W,
the log density ratio function is deﬁned by
f(x, w0, w) = log p(x|w0)
p(x|w) .
(3.3)
If there exists c0 > 0 such that, for an arbitrary pair w0 ∈W0 and w ∈W,
EX[f(X, w0, w)] ≥c0EX[f(X, w0, w)2],
(3.4)
then it is said that the log density ratio function f(x, w0, w) has a relatively
ﬁnite variance.

3.1. FORMAL RELATION BETWEEN TRUE AND MODEL
73
Remark 16. The function f(x, w0, w) has a relatively ﬁnite variance if and
only if
sup
w /∈W0
EX[f(X, w0, w)2]
EX[f(X, w0, w)] < ∞.
(3.5)
If W and W0 are compact sets and if EX[f(X, w0, w)] and EX[f(X, w0, w)2]
are continuous functions, then both functions have ﬁnite values.
Hence
the condition w /∈W0 in the supremum of eq.(3.5) can be replaced by the
condition that w is contained in a neighborhood of of EX[f(X, w0, w)] = 0.
In other words, the condition w /∈W0 can be replaced by
w ∈{w /∈W0; EX[f(X, w0, w)] < ǫ},
for an arbitrarily small ǫ > 0.
Example 16. Let us study a case given in Example.12. The log density ratio
function is
f(x, y, a, b) = −ya sin(bx) + a2 sin2(bx)
2
.
Therefore
E(X,Y )[f(x, y, a, b)]
=
a2b2
2
Z 1
0
S2(bx)x2dx,
E(X,Y )[f(x, y, a, b)2]
=
a2b2
Z 1
0
S2(bx)x2dx + a4b4
4
Z 1
0
S4(bx)x4dx,
where S(x) = sin(x)/x with S(0) = 1.
It follows that, in the neigh-
borhood of ab = 0, there exists c0 > 0 such that E(X,Y )[f(x, y, a, b)] >
c0E(X,Y )[f(x, y, a, b)2]. Hence f(x, y, a, b) has a relatively ﬁnite variance.
Lemma 3. Assume that w0 ∈W0 and w ∈W. If f(x, w0, w) has a relatively
ﬁnite variance, then the optimal probability density is essentially unique.
Proof. Assume that w1 and w2 are arbitrary elements of W0. Then
0 = L(w2) −L(w1)
=
Z
q(x)f(x, w1, w2)dx
≥
c0
Z
q(x)f(x, w1, w2)2dx.
Hence f(x, w1, w2) = 0 for an arbitrary x, resulting that p(x|w1)−p(x|w2) =
0 as a function of x.

74
CHAPTER 3. BASIC FORMULA OF BAYESIAN OBSERVABLES
By Lemma 3, if f(x, w0, w) has a relatively ﬁnite variance, then the
optimal probability density function is essentially unique and f(x, w0, w)
does not depend on w0. In such a case, we use a simple notation
f(x, w) = f(x, w0, w).
By the deﬁnition of f(x, w), it follows that
p(x|w) = p0(x) exp(−f(x, w)).
Note that if the optimal probability density is not essentially unique, then
the log density ratio function does not have a relatively ﬁnite variance. The
following lemma shows that if a true density is realizable by a statistical
model and if the tail probability satisﬁes a condition, then the log density
ratio function has relatively ﬁnite variance.
Lemma 4. Assume that W is a compact set and that q(x) is realizable by
p(x|w) and that the log density ratio function f(x, w) = log(q(x)/p(x|w)) is
a continuous function of (x, w). If there exists c1, c2 > 0 such that for an
arbitrary w ∈W,
Z
|x|>c1
q(x)f(x, w)2dx ≤c2
Z
|x|≤c1
q(x)f(x, w)2dx,
then f(x, w) has a relatively ﬁnite variance.
Proof. Since q(x) is realizable by p(x|w), the optimal probability density is
uniquely equal to q(x). A function F(t) (−∞< t < ∞) is deﬁned by
F(t) = t + e−t −1.
Then F ′(t) = 1 −e−t and F ′′(t) = e−t > 0, resulting that F(t) ≥0 and
F(t) = 0 if and only if t = 0. The constants c3 and c4 are deﬁned by
c3
=
sup
w∈W
sup
|x|≤c1
|f(x, w)|,
c4
=
inf
|t|≤c3
F(t)/t2.
Then c3 and c4 are positive and ﬁnite values. Since
q(x)F

log
q(x)
p(x|w)

= q(x) log
q(x)
p(x|w) + p(x|w) −q(x),

3.1. FORMAL RELATION BETWEEN TRUE AND MODEL
75
it follows that
Z
q(x) log
q(x)
p(x|w)dx
=
Z
q(x)F(f(x, w))dx
≥
Z
|x|≤c1
q(x)F(f(x, w))dx
≥
c4
Z
|x|≤c1
q(x)f(x, w)2dx
≥
c4
1 + c2
Z
q(x)f(x, w)2dx,
which completes the lemma.
The following lemma shows that, if a true density is regular for a statis-
tical model, then the log density ratio function has relatively ﬁnite variance.
Lemma 5. Assume that W is a compact set and that for an arbitrary pair
w0 ∈W0 and w ∈W, the second derivatives of
Z
q(x)f(x, w0, w)dx,
Z
q(x)f(x, w0, w)2dx
are continuous functions. If q(x) is regular for p(x|w), then the log density
ratio function f(x, w0, w) has a relatively ﬁnite variance.
Proof. Since W is a compact set, both functions
Z
q(x)f(x, w0, w)dx,
Z
q(x)f(x, w0, w)2dx
have nonnegative values. By the deﬁnition,
L(w) −L(w0) =
Z
q(x)f(x, w0, w)dx.
By the assumption that q(x) is regular for p(x|w), L(w) −L(w0) = 0 if and
only if w = w0. Hence it is suﬃcient to prove that there exists ǫ > 0 such
that, in the region |w −w0| < ǫ,
Z
q(x)f(x, w0, w)dx > c1
Z
q(x)f(x, w0, w)2dx
for some c1 > 0. By the regularity condition and the mean value theorem,
there exists x∗such that
L(w) −L(w0) = 1
2(w −w0)T ∇2L(w∗)(w −w0)

76
CHAPTER 3. BASIC FORMULA OF BAYESIAN OBSERVABLES
in a neighborhood of w = w0, hence there exists µ1 > 0 such that
Z
q(x)f(x, w0, w)dx ≥µ1∥w −w0∥2
in a neighborhood of w0. On the other hand,
Z
q(x)f(x, w0, w)2dx
is a nonnegative function and is equal to zero at w = w0. Therefore, there
exists µ2 > 0 such that
Z
q(x)f(X, w0, w)2dx
≤
µ2∥w −w0∥2
in a neighborhood of w0. It follows that
sup
w /∈W0
EX[f(X, w0, w)2]
EX[f(X, w0, w)] < ∞,
which completes the lemma.
Summary Assume that the set of all parameters W is compact. Then the
above lemmas show the following relations,
{Regular}
⊂
{Relatively Finite Variance},
{Realizable}
⊂
{Relatively Finite Variance},
and
{Relatively Finite Variance} ⊂{Essentially Unique}.
In this book, we mainly study cases when the log density ratio functions have
relatively ﬁnite variances. It should be emphasized that such cases include
nonregular cases, hence the conventional statistical asymptotic theory does
not hold in general.
Example 17. The foregoing examples are classiﬁed into the following cases.
• Example 11: Realizable and regular →Relatively ﬁnite variance.
• Example 12: Realizable →Relatively ﬁnite variance.
• Example 13: Regular →Relatively ﬁnite variance.

3.2. NORMALIZED OBSERVABLES
77
• Example 14: Nonregular, nonrealizable, but relatively ﬁnite variance.
• Example 15: Essentially nonunique →Relatively inﬁnite variance.
In this book, we show that if a log density ratio function has a relatively
ﬁnite variance, the free energy or the minus log density ratio function Fn,
the generalization loss Gn, the cross validation loss Cn, the training loss Tn,
and WAIC Wn are subject to the universal statistical laws. That is to say,
there exist constants λ, ν, m > 0 such that
Fn
=
nLn(w0) + λ log n + (m −1)Op(log log n) + Op(1),
E[Gn]
=
L(w0) + λ/n + o(1/n),
E[Cn]
=
L(w0) + λ/n + o(1/n),
E[Wn]
=
L(w0) + λ/n + o(1/n),
E[Tn]
=
L(w0) + (λ −2ν)/n + o(1/n).
Moreover, by deﬁning
Ln(w0) = −1
n
n
X
i=1
log p(Xi|w0),
the behaviors of random variables satisfy
Gn −L(w0) + Cn −Ln(w0)
=
2λ/n + op(1/n),
Gn −L(w0) + Wn −Ln(w0)
=
2λ/n + op(1/n).
Note that these mathematical laws hold even if the posterior distribution
is quite diﬀerent from any normal distribution. However, if the log density
ratio function does not have a relatively ﬁnite variance, then such statistical
laws do not hold in general.
3.2
Normalized Observables
In this section, we introduce normalized observables.
A triple of a true
probability density, a statistical model, and a prior, (q(x), p(x|w), ϕ(w)), is
ﬁxed.
Let Xn = (X1, X2, ..., Xn) be a set of random variables which are inde-
pendently subject to a true probability density function q(x). Also let X be
a random variable which is subject to the same density q(x). Assume that

78
CHAPTER 3. BASIC FORMULA OF BAYESIAN OBSERVABLES
X and Xn are independent of each other. The average and empirical log
loss functions are
L(w)
=
−EX[log p(X|w)],
(3.6)
Ln(w)
=
−1
n
n
X
i=1
log p(Xi|w).
(3.7)
Let W0 be the set of optimal parameters for the minimum average log loss
function L(w). That is to say, W0 is the set of all parameters which make
L(w) smallest. We assume that the log density ratio function of w0 ∈W0
and w ∈W
f(x, w0, w) = log p(x|w0)
p(x|w)
has a relatively ﬁnite variance.
By Lemma 3 the log density ratio func-
tion f(x, w0, w) does not depend on w0, hence we simply write f(x, w) =
f(x, w0, w).
The normalized average and empirical log loss functions are
respectively deﬁned by
K(w)
=
EX[f(X, w)],
(3.8)
Kn(w)
=
1
n
n
X
i=1
f(Xi, w).
(3.9)
By the deﬁnition, −log p(x|w) = −log p0(x) + f(x, w), hence
L(w)
=
L(w0) + K(w),
Ln(w)
=
Ln(w0) + Kn(w),
and K(w) ≥0. Moreover,
K(w) = 0 ⇐⇒w ∈W0.
The normalized partition function or the normalized marginal likelihood is
deﬁned by
Z(0)
n
=
Z
exp(−nKn(w))ϕ(w)dw.
Then
n
Y
i=1
p(Xi|w) =
 n
Y
i=1
p(Xi|w0)
!
exp(−nKn(w))
and
Zn = exp(−nLn(w0)) · Z(0)
n .

3.2. NORMALIZED OBSERVABLES
79
Since Ln(w0) is a constant function of w, the posterior distribution can be
rewritten as
p(w|Xn) =
1
Z(0)
n
exp(−nKn(w))ϕ(w).
The normalized free energy or the normalized minus log marginal likelihood
is deﬁned by
F (0)
n
= −log
Z
exp(−nKn(w))ϕ(w)dw.
The normalized generalization, cross validation, and the training losses and
normalized WAIC are also deﬁned by
G(0)
n
=
−EX[log Ew[exp(−f(X, w))],
C(0)
n
=
1
n
n
X
i=1
log Ew[exp(f(Xi, w))],
T (0)
n
=
−1
n
n
X
i=1
log Ew[exp(−f(Xi, w))],
W (0)
n
=
T (0)
n
+ 1
n
n
X
i=1
Vw[f(Xi, w)],
where Ew[ ] and Vw[ ] are the posterior average and variance, respectively.
Here G(0)
n , C(0)
n , T (0)
n , and W (0)
n
are sometimes called generalization, cross
validation, training, and WAIC errors, respectively.
Lemma 6. The Bayesian observables and the normalized observables have
relations,
Fn
=
nLn(w0) + F (0)
n ,
Gn
=
L(w0) + G(0)
n ,
Cn
=
Ln(w0) + C(0)
n ,
Tn
=
Ln(w0) + T (0)
n ,
Wn
=
Ln(w0) + W (0)
n .
Proof. By the deﬁnition and
−log p(x|w) = −log p0(x) + f(x, w),
this lemma is derived.

80
CHAPTER 3. BASIC FORMULA OF BAYESIAN OBSERVABLES
Remark 17. The Bayesian observables are used in analysis in practical ap-
plications, whereas the normalized observables are useful in Bayesian theory
construction, because they are mathematically essential quantities.
In the following chapters, we will show that, if a log density ratio function
has a relatively ﬁnite variance, then F (0)
n /n, G(0)
n , C(0)
n , T (0)
n , and W (0)
converge to zero in probability, therefore
Fn/n
=
Ln(w0) + Op(log n/n),
Gn
=
L(w0) + Op(1/n),
Cn
=
Ln(w0) + Op(1/n),
Tn
=
Ln(w0) + Op(1/n),
Wn
=
Ln(w0) + Op(1/n).
By the central limit theorem,
Ln(w0) −L(w0) = Op(1/√n).
Neither Ln(w0) nor L(wp) depends on a prior. Fn/n, Gn, Cn, and Tn con-
verge to L(w0) when n →∞.
If a true distribution is realizable by a
statistical model, then p(x|w0) = q(x) and
Fn/n
=
Sn + Op(log n/n),
Gn
=
S + Op(1/n),
Cn
=
Sn + Op(1/n),
Tn
=
Sn + Op(1/n),
Wn
=
Sn + Op(1/n),
where S and Sn are the entropy and the empirical entropy of the true dis-
tribution respectively. Neither S nor Sn depends on a statistical model and
a prior. Thus the main purpose of the mathematical theory is to clarify the
random behaviors of the normalized observables.
3.3
Cumulant Generating Functions
In order to study the asymptotic behaviors of the generalization loss, the
cross validation loss, the training loss, and WAIC, the cumulant generating
functions are useful.

3.3. CUMULANT GENERATING FUNCTIONS
81
Deﬁnition 8. Let α be a real value. The cumulant generating functions of
generalization and training losses are respectively deﬁned by
Gn(α)
=
EX[log Ew[p(X|w)α]],
(3.10)
Tn(α)
=
1
n
n
X
i=1
log Ew[p(Xi|w)α].
(3.11)
The kth cumulants are deﬁned by
 d
dα
k
Gn(0),
 d
dα
k
Tn(0).
Remark 18. Since the deﬁnition of the posterior average Ew[ ] depends on
Xn, the average operations E and Ew do not commute, EEw ̸= EwE. Hence
E[Gn(α)] ̸= E[Tn(α)].
By the deﬁnition,
Gn(0) = Tn(0) = 0
and the generalization, cross validation, training losses and WAIC are given
by
Gn
=
−Gn(1),
Cn
=
Tn(−1),
Tn
=
−Tn(1),
Wn
=
−Tn(1) + T ′′
n (0).
If we obtain cumulant generating functions as functions of α, then it is easy
to calculate the generalization loss, the cross validation loss, the training loss,
and WAIC. By using Taylor expansion, the cumulant generating functions
are reconstructed by kth cumulants,
Gn(α)
=
αG′
n(0) + α2
2 G′′
n(0) + α3
6 G′′′
n (0) + · · · ,
Tn(α)
=
αT ′
n(0) + α2
2 T ′′
n (0) + α3
6 T ′′′
n (0) + · · · ,
if these expansions converge absolutely. Even if these series do not converge
absolutely, the asymptotic expansions of Gn(α) and Tn(α) can be derived in
many cases by the higher order mean value theorem.

82
CHAPTER 3. BASIC FORMULA OF BAYESIAN OBSERVABLES
Deﬁnition 9. Let α be a real value. By using the log density ratio func-
tion f(x, w) which satisﬁes p(x|w) = p0(x) exp(−f(x, w)), the normalized
cumulant generating functions of generalization and training losses are re-
spectively deﬁned by
G(0)
n (α)
=
EX[log Ew[exp(−αf(X, w))]],
T (0)
n
(α)
=
1
n
n
X
i=1
log Ew[exp(−αf(Xi, w))].
From this deﬁnition, simple relations between cumulant generating func-
tions and normalized ones are derived. By using p(x|w) = p0(x) exp(−f(x, w)),
where p0(x) does not depend on w,
log Ew[p(X|w)α] = α log p0(X|w) + log Ew[exp(−αf(X, w))].
Therefore,
Gn(α)
=
−αL(w0) + G(0)
n (α),
(3.12)
Tn(α)
=
−αLn(w0) + T (0)
n
(α).
(3.13)
Hence, for k = 0, 2, 3, 4, ... (k ̸= 1) the kth cumulants satisfy
 d
dα
k
Gn(0)
=
 d
dα
k
G(0)
n (0),
 d
dα
k
Tn(0)
=
 d
dα
k
T (0)
n
(0).
For k = 1,
 d
dα

Gn(0)
=
−L(w0) +
 d
dα

G(0)
n (0),
 d
dα

Tn(0)
=
−Ln(w0) +
 d
dα

T (0)
n
(0).
Deﬁnition 10. Let α be a real value. For a given random variable A, we
use notations,
ℓk(A)
=
Ew[(log p(A|w))kp(A|w)α]
Ew[p(A|w)α]
,
ℓ(0)
k (A)
=
Ew[(−f(A, w))k exp(−αf(A, w))]
Ew[exp(−αf(A, w)]
.
If α = 0, these are equal to the posterior averages of kth power,
ℓk(A)
=
Ew[(log p(A|w))k],
ℓ(0)
k (A)
=
Ew[(−f(A, w))k].

3.3. CUMULANT GENERATING FUNCTIONS
83
Lemma 7. The cumulant generating functions satisfy
G′
n(α)
=
EX[ℓ1(X)],
G′′
n(α)
=
EX[ℓ2(X) −ℓ1(X)2],
T ′
n(α)
=
1
n
n
X
i=1
{ℓ1(Xi)},
T ′′
n (α)
=
1
n
n
X
i=1
{ℓ2(Xi) −ℓ1(Xi)2}.
The same equations hold for normalized functions,
G(0)
n
′(α)
=
EX[ℓ(0)
1 (X)],
G(0)
n
′′(α)
=
EX[ℓ(0)
2 (X) −ℓ(0)
1 (X)2],
T (0)
n
′(α)
=
1
n
n
X
i=1
{ℓ(0)
1 (Xi)},
T (0)
n
′′(α)
=
1
n
n
X
i=1
{ℓ(0)
2 (Xi) −ℓ(0)
1 (Xi)2}.
Proof. For an arbitrary function g(α), let ∂kg(α) be the kth order derived
function of g(α). Then
∂log g(α) = ∂g(α)
g(α) ,
and
∂
∂kg(α)
g(α)

=
∂k+1g(α)
g(α)

−
∂kg(α)
g(α)
∂g(α)
g(α)

.
By using this equation recursively, the lemma is obtained.
Remark 19. By the same method, the higher order cumulants can be derived.
For example,
G′′′
n (α)
=
EX[ℓ3(X) −3ℓ2(X)ℓ1(X) + 2ℓ1(X)3],
G′′′′
n (α)
=
EX[ℓ4(X) −4ℓ3(X)ℓ1(X) −3ℓ2(X)2
+12ℓ2(X)ℓ1(X)2 −6ℓ1(X)4].
T ′′′
n (α)
=
1
n
n
X
i=1
{ℓ3(Xi) −3ℓ2(Xi)ℓ1(Xi) + 2ℓ1(Xi)3},
T ′′′′
n (α)
=
1
n
n
X
i=1
{ℓ4(Xi) −4ℓ3(Xi)ℓ1(Xi) −3ℓ2(X)2
+12ℓ2(Xi)ℓ1(Xi)2 −6ℓ1(Xi)4}.

84
CHAPTER 3. BASIC FORMULA OF BAYESIAN OBSERVABLES
For the normalized case, the same equations hold by replacing ℓk(A) by
ℓ(0)
k (A).
By using these equations, cumulants are given by follows. For k = 1.
G′(0)
=
EX[Ew[log p(X|w)]]
=
−L(w0) −Ew[K(w)],
(3.14)
T ′(0)
=
1
n
n
X
i=1
Ew[log p(Xi|w)]
=
−Ln(w0) −Ew[Kn(w)].
(3.15)
For k = 2,
G′′(0)
=
EX[Ew[(log p(X|w))2] −Ew[log p(X|w)]2]
=
EX[Ew[f(X, w)2] −Ew[f(X, w)]2],
=
EX[Vw[f(X, w)]],
(3.16)
T ′′(0)
=
1
n
n
X
i=1
{Ew[log p(Xi|w))2] −Ew[log p(Xi|w)]2}
=
1
n
n
X
i=1
{Ew[f(Xi, w)2] −Ew[f(Xi, w)]2}
=
1
n
n
X
i=1
Vw[f(Xi, w)],
(3.17)
where Vw[f(w)] is the variance of f(w) in the posterior distribution.
Lemma 8. Let c2 = 2, c3 = 6, c4 = 26. Then for k = 2, 3, 4,

 d
dα
k
Gn(α)

≤
ckEX
hEw[|f(X, w)|k exp(−αf(X, w))]
Ew[exp(−αf(X, w))]
i
,

 d
dα
k
Tn(α)

≤
ck
1
n
n
X
i=1
Ew[|f(Xi, w)|k exp(−αf(Xi, w))]
Ew[exp(−αf(Xi, w))]
.
Proof. For an arbitrary random variable A and an arbitrary function g(A, w),
an expectation operator E(α)
w [ ] is deﬁned by
E(α)
w [g(A, w)] ≡Ew[g(A, w) exp(−αf(A, w))]
Ew[exp(−αf(A, w))]
.

3.4. BASIC BAYESIAN THEORY
85
Let us prove the ﬁrst inequality for k = 3.
 d
dα
3
Gn(α)
=
EX
h
E(α)
w [f(X, w)3]
−3E(α)
w [f(X, w)2]E(α)
w [f(X, w)] + 2E(α)
w [f(X, w)]3i
.
Then by using H¨older’s inequality, for arbitrary 1 ≤j ≤k,
E(α)
w [|f(A, w)|j] ≤E(α)
w [|f(A, w)|k]j/k.
By applying this inequality, it follows that

 d
dα
3
Gn(α)

≤
6EX
h
E(α)
w [|f(x, w)|3]
i
.
For the other cases, the same method can be applied, which completes the
lemma.
3.4
Basic Bayesian Theory
By combining the foregoing observables, we obtain the basic theorem of
Bayesian statistics.
Theorem 3. (Basic theorem) Let G′(0), T ′(0), G′′(0), and T ′′(0) be random
variables deﬁned by eq.(3.14), ...,eq.(3.17). Assume that
sup
|α|≤1

 d
dα
3
Gn(α)

=
op( 1
n),
(3.18)
sup
|α|≤1

 d
dα
3
Tn(α)

=
op( 1
n).
(3.19)
Then the generalization loss, the cross validation loss, the training loss, and
WAIC are given by
Gn
=
−Gn(1) = −G′
n(0) −1
2G′′
n(0) + op( 1
n),
(3.20)
Tn
=
−Tn(1) = −T ′
n(0) −1
2T ′′
n (0) + op( 1
n).
(3.21)
Cn
=
Tn(−1) = −T ′
n(0) + 1
2T ′′
n (0) + op( 1
n).
(3.22)
Wn
=
−Tn(1) + T ′′
n (0) = −T ′
n(0) + 1
2T ′′
n (0) + op( 1
n).
(3.23)

86
CHAPTER 3. BASIC FORMULA OF BAYESIAN OBSERVABLES
Assume that
E[ sup
|α|≤1

 d
dα
3
Gn(α)
]
=
o( 1
n),
(3.24)
E[ sup
|α|≤1

 d
dα
3
Tn(α)
]
=
o( 1
n).
(3.25)
Then the averages of the generalization loss, the cross validation loss, the
training loss, and WAIC are given by
E[Gn]
=
−E[G′
n(0)] −1
2E[G′′
n(0)] + o( 1
n),
(3.26)
E[Tn]
=
−E[T ′
n(0)] −1
2E[T ′′
n (0)] + o( 1
n).
(3.27)
E[Cn]
=
−E[T ′
n(0)] + 1
2E[T ′′
n (0)] + o( 1
n),
(3.28)
E[Wn]
=
−E[T ′
n(0)] + 1
2E[T ′′
n (0)] + o( 1
n).
(3.29)
Proof. By using the mean value theorem, for a given α there exists α∗such
that |α∗| ≤|α| and that
Gn(α) = Gn(0) + αG′
n(0) + 1
2α2G′′
n(0) + 1
6α3G(3)
n (α∗).
The case α = 1 gives the ﬁrst half of the theorem. The latter half is derived
by the same method for Tn(α) and α = ±1.
The conditions given by eqs.(3.18), (3.19), (3.24), and (3.25) are proved
in the following chapters for several circumstances. Moreover, we will prove
that if the log density ratio function has a relatively ﬁnite variance, there
exist constants λ, ν > 0 such that
G(0)
n
′(0) + T (0)
n
′(0)
=
−2λ
n + op( 1
n),
G(0)
n
′′(0)
=
ν
n + op( 1
n),
T (0)
n
′′(0)
=
ν
n + op( 1
n),
and that their averages satisfy the equation
E
h
G(0)
n
′(0) + G(0)
n
′′(0)
2
i
=
E
h
T (0)
n
′(0) −T (0)
n
′′(0)
2
i
+ o( 1
n).

3.4. BASIC BAYESIAN THEORY
87
It is very important that these equations hold even if the posterior distri-
bution cannot be approximated by any normal distribution. These equa-
tions are universal laws in Bayesian statistics. Also these equations except
eq.(3.22) and eq.(3.28) hold even if a sample consists of conditionally inde-
pendent random variables. Note that if a sample consists of independent
random variables, then
E[Cn] = E[Gn−1].
However, this equation does hold without independency. The cross valida-
tion can be employed in the case when a sample is independent.
Based on the above theorem, for a given triple (q(x), p(x|w), ϕ(w)),
Bayesian theory can be derived by the following recipe.
The theoretical
behaviors of the free energy or the minus log marginal likelihood, the gen-
eralization loss, the cross validation loss, the training losses, and WAIC are
clariﬁed by the following procedures.
Recipe for Bayesian Theory Construction
1. An arbitrary triple of a true distribution, a statistical model, and a
prior (q(x), p(x|w), ϕ(w)) is chosen and ﬁxed. The set of all parameters
is denoted by W.
Assume that Xn is a sample which consists of
independent random variables subject to q(x).
2. The empirical and average log loss functions are deﬁned by
Ln(w)
=
−1
n
n
X
i=1
log p(Xi|w),
L(w)
=
−
Z
q(x) log p(x|w)dx.
Find the set of optimal parameters which minimize L(w),
W0 = {w ∈W ; L(w) = min
w′∈W L(w′)}.
3. Check that the log density ratio function made of q(x) and p(x|w) has
a relatively ﬁnite variance. Then
f(x, w) = log p(x|w0)
p(x|w)
does not depend on a choice of w0 ∈W0.

88
CHAPTER 3. BASIC FORMULA OF BAYESIAN OBSERVABLES
4. Deﬁne the average and empirical log likelihood ratio functions
K(w)
=
Z
f(x, w)q(x)dx,
Kn(w)
=
1
n
n
X
i=1
f(Xi, w).
The normalized partition function or the normalized marginal likeli-
hood is given by
Z(0)
n
=
Z
exp(−nKn(w))ϕ(w)dw.
Then the free energy or the minus log marginal likelihood is given by
Fn = nLn(w0) −log Z(0)
n .
5. The average by the posterior distribution is equal to
Ew[ ] =
R
(
) exp(−nKn(w))ϕ(w)dw
R
exp(−nKn(w))ϕ(w)dw
.
Calculate Ew[f(x, w)] and Vw[f(x, w)]. Then
Ew[K(w)] = EXEw[f(X, w)],
Ew[Kn(w)] = 1
n
n
X
i=1
Ew[f(Xi, w)],
EXVw[f(X, w)],
1
n
n
X
i=1
Vw[f(Xi, w)]
are obtained.
6. Based on the basic Theorem 3, the generalization, cross validation,
and training losses are given by
Gn
=
L(w0) + Ew[K(w)] −1
2EXVw[f(X, w)] + op( 1
n),
Cn
=
Ln(w0) + Ew[Kn(w)] + 1
2n
n
X
i=1
Vw[f(Xi, w)] + op( 1
n),
Tn
=
Ln(w0) + Ew[Kn(w)] −1
2n
n
X
i=1
Vw[f(Xi, w)] + op( 1
n).
Note that WAIC, Wn, has the same expansion as Cn.

3.4. BASIC BAYESIAN THEORY
89
Example 18. Let us apply the recipe to a simple case.
1. Let A > 0 be a constant and W = {w ∈R; |w| ≤A}. Let us derive the
Bayesian statistical theory for the case when a triple (q(x), p(x|w), ϕ(w))
is given by
q(x)
=
1
√
2πσ2 exp

−x2
2σ2

,
p(x|w)
=
1
√
2π
exp

−(x −w)2
2

,
ϕ(w)
=
1
2A,
where σ2 > 0 is not a parameter but a constant. Note that this true
distribution is realizable by a statistical model if and only if σ2 = 1.
2. The empirical and average log loss functions are respectively given by
Ln(w)
=
1
2 log(2π) + 1
2(σ2
n + w2 −
2
√nwξn),
L(w)
=
1
2 log(2π) + 1
2(σ2 + w2),
where
σ2
n
=
1
n
n
X
i=1
X2
i ,
ξn
=
1
√n
n
X
i=1
Xi.
The random variance σ2
n converges to σ2 in probability. The random
variable ξn is subject to the normal distribution whose average and
variance are zero and σ2 respectively. The average log loss function
L(w) is minimized if and only if w = 0, resulting that W0 = {0}.
3. The log density ratio function is
f(x, w)
=
log p(x|w0)
p(x|w) = w2
2 −wx,
where we used w0 = 0. It follows that
EX[f(X, w)]
=
w2
2 ,
EX[f(X, w)2]
=
w4
4 + w2σ2.

90
CHAPTER 3. BASIC FORMULA OF BAYESIAN OBSERVABLES
Thus f(x, w) has a relatively ﬁnite variance by using eq.(3.5) and
|w| ≤A.
4. The average and empirical log likelihood ratio functions are respec-
tively given by
K(w)
=
Z
f(x, w)q(x)dx = w2
2 ,
Kn(w)
=
1
n
n
X
i=1
f(Xi, w) = w2
2 −wξn
√n .
The normalized partition function or the normalized marginal likeli-
hood is equal to
Z(0)
n
=
1
2A
Z A
−A
exp(−n w2
2
+ √n w ξn)dw
=
1
2A
Z ∞
−∞
exp(−n(w −ξn/√n)2
2
+ ξ2
n
2 )dw + Op(e−n)
=
√
2π
2A√n exp(ξ2
n/2) + Op(e−n).
Therefore the theoretical behavior of the free energy or the minus log
marginal likelihood is derived as
Fn
=
nLn(w0) −log Z(0)
n
=
n −1
2
log(2π) + nσ2
n −ξ2
n
2
+ 1
2 log n + log(2A) + op(1).
Its average is given by
E[Fn] = n −1
2
log(2π) + 1
2(nσ2 + log n −1) + log(2A) + o(1).
5. The above calculation for Z(0)
n
shows that the posterior distribution is
asymptotically given by
p(w|Xn) =
r n
2π exp

−n
2(w −ξn
√n)2
+ Op(e−n).
Let E∗
w[ ] and V∗[ ] be the average and variance operators using the
normal distribution whose average and variance are ξn/√n and 1/n,

3.4. BASIC BAYESIAN THEORY
91
respectively. Then
E∗
w[w]
=
ξn
√n,
E∗
w[w2]
=
1 + ξ2
n
n
,
E∗
w[wk]
=
Op( 1
nk/2 )
(k ≥3),
resulting that
Ew[f(x, w)]
=
E∗
w[f(x, w)] + Op(e−n)
=
1 + ξ2
n
2n
−xξn
√n + op(1/n),
Vw[f(x, w)]
=
V∗
w[f(x, w)] + Op(e−n) = x2
n + Op(1/n3/2).
Hence
Ew[K(w)] = EXEw[f(X, w)] = 1 + ξ2
n
2n
+ op(1/n),
Ew[Kn(w)] = 1
n
n
X
i=1
Ew[f(Xi, w)] = 1 −ξ2
n
2n
+ op(1/n),
EXVw[f(X, w)] = σ2
n + op(1/n),
1
n
n
X
i=1
Vw[f(Xi, w)] = σ2
n
n + op(1/n).
6. By using the results above, and σ2
n = σ2 + Op(1/√n), we obtain the
Bayesian statistical theory,
Gn
=
1
2 log(2π) + σ2
2 + 1 + ξ2
n −σ2
2n
+ op( 1
n),
Cn
=
1
2 log(2π) + σ2
n
2 + 1 −ξ2
n + σ2
2n
+ op( 1
n),
Tn
=
1
2 log(2π) + σ2
n
2 + 1 −ξ2
n −σ2
2n
+ op( 1
n).
Note that
(Gn −L(w0)) + (Cn −Ln(w0)) = 1
n + op(1/n)

92
CHAPTER 3. BASIC FORMULA OF BAYESIAN OBSERVABLES
holds. Since E[ξ2
n] = σ2, their averages are
E[Gn]
=
1
2 log(2π) + σ2
2 + 1
2n + o( 1
n),
E[Cn]
=
1
2 log(2π) + σ2
2 + 1
2n + o( 1
n),
E[Tn]
=
1
2 log(2π) + σ2
2 + 1 −2σ2
2n
+ o( 1
n).
The random variable WAIC and its expected value, Wn and E[Wn],
have the same asymptotic expansions as Cn and E[Cn], respectively.
The average generalization loss is a decreasing function of n, whereas
the average training loss is increasing. In the following chapters, we
show that if a log density ratio function has a relatively ﬁnite variance,
then the generalization loss, the cross validation loss, the training loss,
and WAIC have the same asymptotic behaviors as this case.
Example 19. If a log density ratio function does not have a relatively ﬁnite
variance, then asymptotic behaviors are diﬀerent in general. Let us study the
case given in Example 15. In this case, we cannot employ the above recipe
for theory construction.
Let (Xi, Yi) (i = 1, 2, ..., n) be pairs of random
variables which are subject to q(x, y) in Example 15. We use notations,
r2
n
=
1
n
n
X
i=1
{X2
i + Y 2
i },
ξn
=
1
√n
n
X
i=1
Xi,
ηn
=
1
√n
n
X
i=1
Yi.
The empirical entropy is
Sn = −1
n
n
X
i=1
log q(Xi, Yi) = log(2π) + r2
n
2 .

3.4. BASIC BAYESIAN THEORY
93
The partition function is
Zn
=
Z π
−π
1
(2π)n exp(−1
2
n
X
i=1
{(Xi −cos θ)2 + (Yi −sin θ)2}) dθ
2π
=
exp(−n(r2
n + 1)/2)
(2π)n+1
Z π
−π
exp(√nξn cos θ + √nηn sin θ)dθ
=
exp(−n(r2
n + 1)/2 + √nγn)
(2π)n+1
Z π
−π
exp(√nγn(cos θ −1)))dθ
where we used γn =
p
ξ2n + η2n and the cyclic condition of θ. If n is suﬃ-
ciently large, then the main part of integration [−π, π] is the neighborhood
of the origin. By using
1 −cos θ = −θ2/2 + O(θ4),
and
Z π
−π
exp(−√nγnθ2/2)dθ =
s
2π
n1/2γn
+ op(exp(−√nγn)),
The free energy is
Fn
=
n(r2
n + 1)/2 −√nγn + (n + 1/2) log(2π)
+1
4 log n + log γn + op(1).
Since both ξn and yn are subject to the normal distribution with average 0
and variance 1, γ2
n is subject to the chi-squared distribution with 2 degrees
of the freedom. Therefore,
E[γn]
=
1
2Γ(1)
Z ∞
0
x1/2e−x/2dx =
√
2Γ(3/2),
E[γ2
n]
=
1
2Γ(1)
Z ∞
0
xe−x/2dx = 2.
The average free energy is given by
E[Fn] = (3/2 + log(2π))n −
√
2Γ(3/2)√n + 1
4 log n + O(1).
By Remark 14 and E[Fn] = E[Gn+1] −E[Gn], if E[Gn] has an asymptotic
expansion, then it is equal to
E[Gn] = (3/2 + log(2π)) −Γ(3/2)
√
2n
+ 1
4n + o(1/n).

94
CHAPTER 3. BASIC FORMULA OF BAYESIAN OBSERVABLES
This equation shows that the average generalization loss is an increasing
function of n. In this model, the distance from the true distribution to each
model is constant, hence, if n is small, the posterior distribution is spread
over all parameters. However, if n is large, then it concentrates on some
parameter region by the random ﬂuctuation. Such a phenomenon is called
spontaneous symmetry breaking.
Remark 20. In this book, we mainly study the case when the log density
ratio function has a relatively ﬁnite variance and show that the free energy
and several losses are subject to the universal law. It may seem that Example
19 is a special or pathological exception, but, complicated and hierarchical
statistical models used in deep learning may reveal the same phenomenon.
For example, in some regression problem if a true distribution of Z
Z = exp(−X2 −Y 2) + N(0, 1)
is statistically estimated by a neural network
Z =
H
X
h=1
ahσ(bhX + chY + dh) + N(0, 1),
where σ is a sigmoidal function and {ah, bh, ch, dh} is a parameter, then the
true distribution is unrealizable by and singular for a statistical model. In
this case, the same phenomenon shown by Example 19 occurs. Spontaneous
symmetry breaking will be an important theme in Bayesian statistics in the
future.
3.5
Problems
1. Let x ∈R and {ek(x); k = 1, 2, ...} be a set of functions which satisfy
Z
ek(x)eℓ(x)q(x)dx = δkℓ,
where if k = ℓthen δkℓ= 1, and if k ̸= ℓthen δkℓ= 0. Let X be a random
variable which is subject to a probability density q(x) and {ak ̸= 0} be a set
of nonzero real values which satisfy
∞
X
k=1
(ak)2 = 1.

3.5. PROBLEMS
95
Assume that a conditional density q(y|x) and a statistical model p(y|x, w)
are respectively deﬁned by
Y
=
∞
X
k=1
akek(X) + N(0, 12),
Y
=
K
X
k=1
wkek(X) + N(0, 12).
Then prove that q(x)q(y|x) is unrealizable by and regular for q(x)p(y|x, w).
2. Let β > 0 be a positive constant. For a given statistical model p(x|w),
a prior ϕ(w), and a set of random variables Xn, a generalized posterior
distribution of the inverse temperature β is deﬁned by
p(w|Xn) =
1
Zn(β)ϕ(w)
n
Y
i=1
p(Xi|w)β,
where
Zn(β) =
Z
ϕ(w)
n
Y
i=1
p(Xi|w)βdw.
Let Eβ
w[
] be the averaged value over p(β)(w|Xn). Then the generalized
predictive density is deﬁned by
p(β)(x|Xn) = Eβ
w[p(x|w)].
Therefore, β = 1 results in the ordinary Bayesian estimation.
The gen-
eralization loss, the training loss, the cross validation loss, and WAIC are
respectively generalized by
Gβ
n
=
−EX[log p(β)(X|Xn)],
T β
n
=
−1
n
n
X
i=1
log p(β)(Xi|Xn),
Cβ
n
=
−1
n
n
X
i=1
log Eβ
w[p(Xi|w)1−β]
Eβ
w[p(Xi|w)−β]
,
W β
n
=
T β
n + β
n
n
X
i=1
Vβ
w[log p(x|w)],

96
CHAPTER 3. BASIC FORMULA OF BAYESIAN OBSERVABLES
where Vβ
w[
] is the variance over p(β)(w|Xn).
The cumulant generating
functions are also generalized by
Gβ
n(α)
=
EX[log Eβ
w[p(X|w)α]],
(3.30)
T β
n (α)
=
1
n
n
X
i=1
log Eβ
w[p(Xi|w)α].
(3.31)
Assume that eqs.(3.24) and (3.25) hold for Gβ
n(α) and T β
n (α) instead of Gn(α)
and Tn(α). Then prove the following equations.
Gβ
n
=
−(Gβ
n)′(0) −1
2(Gβ
n)′′(0) + op( 1
n),
(3.32)
T β
n
=
−(T β
n )′(0) −1
2(T β
n )′′(0) + op( 1
n),
(3.33)
Cβ
n
=
−(T β
n )′(0) + 2β −1
2
(T β
n )′′(0) + op( 1
n),
(3.34)
W β
n
=
−(T β
n )′(0) + 2β −1
2
(T β
n )′′(0) + op( 1
n).
(3.35)
These equations show that the universal law of the Bayesian statistics holds
even if the posterior distribution is given by the inverse temperature β > 0.
3. Let us study the multinomial distribution and its prior deﬁned by eq.(2.13)
and eq.(2.14). Then by using.(2.18), it follows that
log Ew[p(x|w)α] = log
Z
p(x|w)αp(w|Xn)dw
=
N
X
j=1
log Γ(αx(j) + nj + aj) −log Γ(n + α +
N
X
j=1
aj) + c1,
where c1 is a constant function of α. Assume that a true distribution is
given by p(x|w0). Prove that the kth (k ≥1) cumulants are given by
G(k)
n (0)
=
N
X
j=1
w0jψ(k−1)(nj + aj) −ψ(k−1)(n +
N
X
j=1
aj),
T (k)
n
(0)
=
N
X
j=1
(nj/n)ψ(k−1)(nj + aj) −ψ(k−1)(n +
N
X
j=1
aj),
where ψ(k−1)(x) is the (k −1)th derivative of ψ(x) = (log Γ(x))′. Then by
using the asymptotic expansion
ψ(k−1)(x) = O(1/xk−1),
(k ≥2),

3.5. PROBLEMS
97
prove that if k ≥2,
G(k)
n (0) = Op(1/nk−1),
T (k)
n
(0) = Op(1/nk−1).


Chapter 4
Regular Posterior
Distribution
In this chapter, we study a special case when a true distribution q(x) is
regular for a statistical model p(x|w) and the sample size n is large enough
to ensure
Posterior Distribution ≈Normal Distribution
holds in the neighborhood of the optimal parameter w0. In such a case, the
asymptotic behaviors of the free energy or the minus log marginal likelihood
are derived, and the generalization loss, the training losses, the cross vali-
dation loss, and WAIC are clariﬁed.
(1) At ﬁrst, we explain that the posterior distribution is divided into the
essential and nonessential parts.
(2) Asymptotic expansion of the free energy is shown.
(3) Asymptotic expansions of the generalization loss, the training loss, the
cross validation loss, and WAIC are proved.
(4) The mathematical proof is given for a basic Bayesian treatment.
(5) Point estimators such as the maximum likelihood or a priori are intro-
duced.
A statistician who knows the conventional asymptotic theory can skip this
section.
4.1
Division of Partition Function
In Bayesian theory, the parameter set is divided into the essential part and
the nonessential part. The essential one is the set of the neighborhood of
the optimal parameter, whereas the nonessential one is its complement.
99

100
CHAPTER 4. REGULAR POSTERIOR DISTRIBUTION
Let (q(x), p(x|w), ϕ(w)) be a triple of a true probability density, a sta-
tistical model, and a prior. The average log loss function is deﬁned by
L(w) = −
Z
q(x) log p(x|w)dx.
We use a notation, ∇= (∂/∂w), then ∇L(w0) and ∇2L(w0) are a d-
dimensional vector and a d × d matrix, respectively. The matrix ∇2L(w0)
is sometimes referred to as Hesse matrix of L(w0) at w0. In this section, it
is assumed that the set of all parameters W is a compact subset of Rd and
that there exist both a unique parameter w0 and an open subset U such that
w0 ∈U ⊂W ⊂Rd and that w0 minimizes L(w). It is not assumed that the
true density is realizable by a statistical model, in general. The probability
density function of the optimal parameter is denoted by
p0(x) = p(x|w0).
Therefore q(x) = p(x|w0) does not hold in general. Also it is assumed that
∇ϕ(w) is a continuous function and that ϕ(w0) > 0. The log density ratio
function is
f(x, w) = log p0(x)
p(x|w) = log p(x|w0)
p(x|w) .
Hence f(x, w0) ≡0. By using the average log density ratio function K(w) =
EX[f(X, w)],
L(w) = K(w) + L(w0).
Therefore K(w) ≥0 and K(w) takes the minimum value zero if and only if
w = w0. The log likelihood ratio function is deﬁned by
Kn(w) = 1
n
n
X
i=1
f(Xi, w),
which satisﬁes Kn(w0) = 0. For simple proof, we assume that f(x, w) has
a relatively ﬁnite variance and is a Cℓclass function for suﬃciently large ℓ,
that is to say,
∇ℓf(x, w)
is a continuous function of w. Further, it is assumed that, for a suﬃciently
large k,
EX[ sup
w∈W
∥∇ℓf(X, w)∥k] < ∞.
(4.1)

4.1. DIVISION OF PARTITION FUNCTION
101
Then K(w) is also a Cℓclass function. The main assumption of regularity
is that
J ≡∇2K(w0)
is a positive deﬁnite matrix. By the assumption that f(x, w) has a relatively
ﬁnite variance, there exists c0 > 0 such that
EX[f(X, w)2] ≤c0K(w),
resulting that a function
a(x, w) = K(w) −f(Xi, w)
p
K(w)
is well deﬁned for w ̸= w0 and
sup
w̸=w0
EX
h
a(X, w)2i
< ∞.
(4.2)
Remark 21. In the neighborhood of w0,
K(w) = 1
2(w −w0)J(w −w0) + o(∥w −w0∥3).
By the condition that f(x, w) has a relatively ﬁnite variance, there exists
c1 > 0 such that
EX[f(X, w)2] ≤c1∥w −w0∥2.
Hence eq.(4.2) holds. The function a(x, w) is bounded but may be discon-
tinuous at w = w0. However, it can be made well-deﬁned as a function of
the generalized polar coordinate (w −w0) = rΘ, where r = ∥w −w0∥and
Θ = (w −w0)/r.
Example 20. In order to illustrate functions deﬁned in the foregoing state-
ment, we study a simple case,
p(x, y|u, v) = 1
2π exp

−1
2((x −u)2 + (y −v)2)

and q(x, y) = p(x, y|0, 0). Then w0 = (0, 0). The log density ratio function,
and its average function are respectively given by
f(x, y, u, v)
=
1
2(u2 + v2 −2ux −2vy),
K(u, v)
=
1
2(u2 + v2).

102
CHAPTER 4. REGULAR POSTERIOR DISTRIBUTION
The log likelihood ratio function is
Kn(u, v) = 1
2(u2 + v2) −u
 1
√n
n
X
i=1
Xi

−v
 1
√n
n
X
i=1
Yi

.
The function a(x, y, a, b) is
a(x, y, u, v) =
√
2 (ux + vy)
√
u2 + v2
.
For a given (x, y) ̸= (0, 0), a(x, y, u, v) is a bounded but discontinuous func-
tion of (u, v) in the neighborhood of (u, v) = (0, 0). However, by using
u = r cos θ,
v = r sin θ,
it follows that
a(x, y, r, θ) =
√
2 (x cos θ + y sin θ)
is a well-deﬁned function. Note that (u, v) = (0, 0) corresponds to r = 0
and θ = free. If a true density is regular for a statistical model, then the
same transform is always employed. In the following chapters, we show that,
even if a true density is not regular for a statistical model, the generalized
procedure called resolution of singularities made by algebraic geometry can
be applied.
We deﬁne a function
γn(w) =
1
√n
n
X
i=1
a(Xi, w),
and assume that it satisﬁes the asymptotic expectation condition with index
k. For the asymptotic expectation condition, see Section 10.5. That is to
say, we assume that
γn = sup
w̸=w0
|γn(w)|
satisﬁes E[(γn)k+ε0] < ∞for some ε0 > 0. Firstly, we analyze the normalized
partition function deﬁned by
Z(0)
n
=
Z
exp(−nKn(w))ϕ(w)dw.

4.1. DIVISION OF PARTITION FUNCTION
103
For a given positive value ǫ > 0, we deﬁne
W1
=
{w ∈W; ∥w −w0∥< ǫ},
W2
=
{w ∈W; ∥w −w0∥≥ǫ}.
Then by deﬁning
Z(1)
n
=
Z
W1
exp(−nKn(w))ϕ(w)dw,
Z(2)
n
=
Z
W2
exp(−nKn(w))ϕ(w)dw,
the normalized partition function is equal to
Z(0)
n
= Z(1)
n
+ Z(2)
n .
(4.3)
Here Z(1)
n
and Z(2)
n
are the integrations of parameters in a neighborhood of
the optimal parameter w0 and in its complement respectively.
In regular theory, the posterior distribution becomes to be accumulated
on a neighborhood of the optimal parameters when n →∞. In this chapter,
we deﬁne a positive real value ǫ as a function of n,
ǫ =
1
n2/5 .
Then
lim
n→∞ǫ = 0,
lim
n→∞
√nǫ = ∞.
In the following, we show that, when n →∞,
Z(1)
n
>> Z(2)
n ,
hence Z(1)
n
and Z(2)
n
are called the essential and nonessential parts of the
normalized partition function respectively.
Firstly we study the nonessential part Z(2)
n .
Lemma 9. Let J1 > 0 be the minimum eigenvalue of the matrix J =
∇2K(w0) and K1 be the maximum value of K(w) in W. If n is suﬃciently
large,
Z(2)
n
≤
exp(−(J1/4)n1/5 + γ2
n/2),
Z(2)
n
≥
exp(−2K1n −γ2
n/2).
Hence for arbitrary k ≥0, the convergence in probability nkZ(2)
n
→0 holds.

104
CHAPTER 4. REGULAR POSTERIOR DISTRIBUTION
Proof. By the deﬁnition of γn(w),
nKn(w) = nK(w) −
p
nK(w) γn(w).
By using
p
nK(w) γn(w) ≤1
2(nK(w) + γn(w)2),
it follows that
nKn(w)
≥
nK(w)/2 −γ2
n/2,
nKn(w)
≤
3nK(w)/2 + γ2
n/2.
In the neighborhood of the origin,
nK(w) = n
2∥J1/2(w −w0)∥2 + O(n∥w −w0∥3).
Hence, in ∥w −w0∥> n−2/5, for suﬃciently large n,
(J1/4)n1/5
≤
nK(w) ≤nK1,
and
exp(−nK1/2)
≤
Z
W2
ϕ(w)dw.
Then by the deﬁnition,
Z(2)
n
=
Z
∥w−w0∥≥n−2/5 exp(−nKn(w))ϕ(w)dw,
Lemma 9 is obtained.
Secondly, we study the essential part of the normalized partition function
which is the integration on the set, ∥w −w0∥< n−2/5. An empirical process
ηn(w) is deﬁned by
ηn(w)
=
1
√n
n
X
i=1
{K(w) −f(Xi, w)}.
(4.4)
Then
nKn(w) = nK(w) −√nηn(w).

4.1. DIVISION OF PARTITION FUNCTION
105
We assume that ∇ηn(w) and ∇2ηn(w) satisfy the asymptotic expectation
condition with suﬃciently large index k. Two random variables are deﬁned
by
η(2)
n
=
1
2 sup
w∈W1
∥∇2ηn(w)∥,
ξn
=
J−1/2∇ηn(w0).
Then E[η(2)
n ] < ∞and ξn →ξ in distribution hold where ξ is the random
variable that is subject to the normal distribution. Also we deﬁne a function
δn(w) by
δn(w)
=
n{K(w) −1
2∥J1/2(w −w0)∥2}
+√n{ηn(w) −∇ηn(w0) · (w −w0)}.
(4.5)
By the deﬁnition, it follows that
nKn(w) = n
2 ∥J1/2(w −w0)∥2 −√n∇ηn(w0) · (w −w0) + δn(w).
By the assumption that ∇3K(w) is a continuous function,
k(3)
≡
1
6 sup
w∈W1
∥∇3K(w)∥< ∞.
Lemma 10. The following inequalities hold.
sup
w∈W1
|δn(w)|
≤
n−1/5k(3) + n−3/5η(2)
n ,
(4.6)
sup
w∈W1
∥∇δn(w)∥
≤
3n1/5k(3) + 2n−1/5η(2)
n .
(4.7)
Proof. By applying the mean value theorem to K(w) and ηn(w), there exist
w∗, w∗∗∈W1 such that
K(w)
=
1
2∥J1/2(w −w0)∥2 + 1
6∇3K(w∗)(w −w0)3,
ηn(w)
=
∇ηn(w0) · (w −w0) + 1
2∇2ηn(w∗∗)(w −w0)2,
hence eq.(4.6) is derived.
Also by applying the mean value theorem to
∇K(w) and ∇ηn(w), there exist w′, w′′ ∈W1 such that
∇K(w)
=
J(w −w0) + 1
2∇3K(w′)(w −w0)2,
∇ηn(w)
=
∇ηn(w0) + ∇2ηn(w′′)(w −w0),
hence eq.(4.7) is derived.

106
CHAPTER 4. REGULAR POSTERIOR DISTRIBUTION
We assume that a prior ϕ(w) is a C1 class function and that ϕ(w0) > 0.
Then
ϕ(1) ≡sup
w∈W1
∥∇ϕ(w)∥< ∞.
The following lemma shows the asymptotic behavior of the essential part.
Lemma 11. The essential part of the normalized partition function satisﬁes
inequalities,
Z(1)
n
≤
(2π)d/2
nd/2(det J)1/2 (ϕ(w0) + ϕ(1)
n2/5 )
× exp(1
2∥ξn∥2 + k(3)
n1/5 + η(2)
n
n3/5 ),
Z(1)
n
≥
(2π)d/2
nd/2(det J)1/2 (ϕ(w0) −ϕ(1)
n2/5 )
× exp(1
2∥ξn∥2 −k(3)
n1/5 −η(2)
n
n3/5 ) Φn(ξn),
where
Φn(ξn) ≡
1
(2π)d/2
Z
∥J1/2w∥<n3/5 exp(−∥w −ξn∥2/2)dw,
(4.8)
which satsiﬁes
Φn(ξn) ≥exp(−∥ξn∥2)
2(2π)d/2
for suﬃciently large n. Therefore the convergence in probability holds,
nd/2Z(1)
n
exp(−∥ξn∥2/2) →
(2π)d/2
(det J)1/2 ϕ(w0).
Proof. In the region W1 = {w ∈W; ∥w −w0∥< n−2/5}, by the mean value
theorem,
ϕ(w)
≤
ϕ(w0) + n−2/5ϕ(1),
ϕ(w)
≥
ϕ(w0) −n−2/5ϕ(1).
Also in the region W1,
nKn(w)
≤
1
2∥(nJ)1/2(w −w0) −ξn∥2 −∥ξn∥2
2
+ k(3)
n1/5 + η(2)
n
n3/5 ,
nKn(w)
≥
1
2∥(nJ)1/2(w −w0) −ξn∥2 −∥ξn∥2
2
−k(3)
n1/5 −η(2)
n
n3/5 .

4.2. ASYMPTOTIC FREE ENERGY
107
By putting w′ = (nJ)1/2(w −w0),
Z
w∈W1
exp(−1
2∥(nJ)1/2(w −w0) −ξn∥2)dw = (2π)d/2Φn(ξn)
nd/2(det J)1/2 .
Since Φn(
) is the probability of the set ∥J−1/2w′∥< n3/5, Φn(ξn) < 1.
Moreover,
Φn(ξn) ≥exp(−∥ξn∥2)
(2π)d/2
Z
∥J1/2w′∥<n3/5 exp(−∥w′∥2)dw′
which completes Lemma.
In this section we proved that the essential and nonessential normalized
partition functions satisfy
Z(1)
n
∝
1/nd/2,
Z(2)
n
≤
exp(−n1/5),
as random variables.
4.2
Asymptotic Free Energy
In this section, we derive the asymptotic expansion of the free energy or the
minus log marginal likelihood Fn. A matrix I is deﬁned by
I = EX[∇f(x, w0)(∇f(x, w0))T ].
Then by the deﬁnition,
E[ 1
n
n
X
i=1
∇f(Xi, w0)(∇f(Xi, w0))T ] = I,
and by the central limit theorem,
1
n
n
X
i=1
∇f(Xi, w0)(∇f(Xi, w0))T = I + Op(1/n3/2).
If q(x) is realizable by p(x|w), then I is called the Fisher information matrix
at w0 and I = J. However, in general, I ̸= J. By the deﬁnition of I, it
is positive semideﬁnite. In the regularity condition of Bayesian theory, the
eigenvalue of J positive, but I may contain a zero eigenvalue.

108
CHAPTER 4. REGULAR POSTERIOR DISTRIBUTION
Theorem 4. If the regularity condition holds, then the Bayesian free energy
Fn satisﬁes
Fn
=
nLn(w0) + d
2 log n −log ϕ(w0) −d
2 log(2π)
+1
2 log det J −1
2∥ξn∥2 + op(1).
(4.9)
E[Fn]
=
nL(w0) + d
2 log n −log ϕ(w0) −d
2 log(2π)
+1
2 log det J −1
2tr(J−1I) + o(1).
(4.10)
Proof. By the assumption, ξn and ∇2ηn(w) converge in distribution and
their expectation values also converge. By the deﬁnition,
Fn = F (0)
n
+ nLn(w0),
where F (0)
n
is a normalized free energy, which is given by the essential and
nonessential parts,
F (0)
n
=
−log Z(0)
n
=
−log(Z(1)
n
+ Z(2)
n ).
When n →∞, convergence in probability Φn(ξn) →1 holds, where Φn(ξn)
is deﬁned by eq.(4.8). By Lemma 9 and 11, covergences in probability
nd/2Z(1)
n
exp(−1
2∥ξn∥2)
→
(2π)d/2
(det J)1/2 ϕ(w0),
nd/2Z(2)
n
→
0,
hold.
It follows that eq.(4.9) holds.
Let us prove eq.(4.10).
Let ξ be a
random variable which is subject to the normal distribution whose average
and covariance are equal to those of ξn. Then by the central limit theorem,
ξn →ξ in distribution holds. By the convergence in distribution,
nd/2Z(1)
n
→
(2π)d/2
(det J)1/2 ϕ(w0) exp(1
2∥ξ∥2),
and convergence in probability nd/2Z(2)
n
→0, the convergence in distribution
nd/2Z(0)
n
→
(2π)d/2
(det J)1/2 ϕ(w0) exp(1
2∥ξ∥2)

4.2. ASYMPTOTIC FREE ENERGY
109
holds. Hence F (0)
n
−(d/2) log n also converges in distribution. In order to
prove the convergence of the expected value E[(F (0)
n
−(d/2) log n)], it is suf-
ﬁcient to prove that the sequence of random variables (F (0)
n
−(d/2) log n) is
uniformly asymptotically integrable. To prove it is uniformly asymptotically
intgerable, it is suﬃcient to prove E[|F (0)
n
−(d/2) log n|1+ε] < ∞for some
ε > 0. (See Section 10.5). We deﬁne two random variables,
An
=
log(nd/2Z(1)
n ),
Bn
=
log(nd/2Z(2)
n ).
Then
(d/2) log n −F (0)
n
= log(eAn + eBn).
For arbitrary real numbers x, y,
x ≤log(ex + ey) ≤max(x, y) + log 2.
Hence
| log(ex + ey)| ≤max(|x|, | max(x, y)| + log 2).
Therefore
| log(eAn + eBn)| ≤max(|An|, | max(An, Bn)|) + log 2.
By Lemma 9 and 11, and
Φn(ξn) ≥exp(−∥ξn∥2)
Z
∥w−w0∥<1
exp(−∥w∥2)dw,
there exists constants c1, c2, c3 such that
An
≤
c1 + ∥ξn∥2/2 + η(2)
n /n3/5,
An
≥
c2 −∥ξn∥2/2 −η(2)
n /n3/5,
max(An, Bn)
≤
c3 + ∥ξn∥2/2 + η(2)
n /n3/5 + γ2
n/2.
Then by
max(An, Bn)
≥
An,
there exists c4 > 0 such that
|(d/2) log n −F (0)
n | ≤∥ξn∥2/2 + η(2)
n /n3/5 + c4.

110
CHAPTER 4. REGULAR POSTERIOR DISTRIBUTION
By the assumption ξn and η(2)
n
have the asymptotic expectation condition
with index k, E[|F (0)
n
−(d/2) log n|1+ǫ] < ∞for some ǫ > 0. Lastly, since
E[∇ηn(w0)(∇ηn(w0))T ] =
Z
(∇f(x, w0))(∇f(x, w0))T q(x)dx,
it follows that
E[∥ξn∥2]
=
E[tr(J−1∇ηn(w0)(∇ηn(w0))T )]
=
tr(J−1E[∇ηn(w0)(∇ηn(w0))T ]),
which completes the theorem.
Remark 22. In this section, on the regularity condition, J > 0 and ϕ(w0) >
0, we proved that
Fn
=
nLn(w0) + d
2 log n −log ϕ(w0) −d
2 log(2π)
+1
2 log det J −1
2∥ξn∥2 + op(1)
and
E[∥ξn∥2] = tr(IJ−1) + o(1).
If det J = 0, det J = ∞, ϕ(w0) = 0, or ϕ(w0) = ∞, then this asymptotic
expansion does not hold because
log det J,
log ϕ(w0)
are not ﬁnite. For the case when the regularity condition is not satisﬁed,
see the following sections.
Example 21. Let x, w ∈RM and y ∈R, and a statistical model is
p(y|x, w) =
1
(2π)1/2 exp(−1
2(y −w · x)2).
(4.11)
Assume that X is subject to some density q(x). The matrix J of the statis-
tical model eq.(4.11) is
Jjk =
Z
xjxkq(x)dx.
The support of q(x) is deﬁned by
supp q ≡{x ∈RM ; q(x) > 0},

4.3. ASYMPTOTIC LOSSES
111
where A of a set A ⊂RM is the closure of A. If the support of q(x) is
contained in a subspace of RM whose dimension is smaller than M, then
det J = 0. In real world problems which are deﬁned on high dimensional
space, the support of q(x) is sometimes contained in a low dimensional sub-
space. In such cases, the regular asymptotic theory does not hold. However,
such cases can be analyzed by the general theory.
Example 22. Let p(x|w) be a statistical model and assume that the optimal
parameter w0 = 0. In statistical estimation, sometimes a prior
ϕ(w) ∝|w|α−1
is employed, where α > 0 is a hyperparameter. Then the regularity condition
is satisﬁed if and only if α = 1. The cases α ̸= 1 can be analyzed by the
general theory.
4.3
Asymptotic Losses
In this section, we show asymptotic behaviors of the generalization, cross
validation, and training losses when n →∞, based on the regularity condi-
tion. The following lemma is necessary in this section.
Lemma 12. Assume the regularity condition. Let k (k ≥2) be an integer
and g(x, w) be a function which satisﬁes g(x, w0) = 0 and assume that, for
a suﬃciently large integer ℓ,
EX[ sup
w∈W
|g(X, w)|ℓ]
<
∞,
EX[ sup
w∈W
∥∇g(X, w)∥ℓ]
<
∞.
We use a notation,
L(X, α) ≡Ew[|g(X, w)|k exp(−αf(X, w))]
Ew[exp(−αf(X, w))]
.
Then, there exists ε > 0 such that
E
h
nk/2 sup
|α|≤1
EX[L(X, α)]
1+εi
<
∞
(4.12)
E
h
nk/2 sup
|α|≤1
1
n
n
X
i=1
L(Xi, α)
1+εi
<
∞.
(4.13)

112
CHAPTER 4. REGULAR POSTERIOR DISTRIBUTION
The proof of this lemma is given in the following section. In this section,
we employ Lemma 12 and prove asymptotic expansions of the generalization,
cross validation, and training losses.
Remark 23. The special case α = 0 and g(X, w) = g(w) shows that
Ew[nk/2|g(w)|k] is asymptotically uniformly integrable.
Therefore, if the
random variable Ew[nk/2g(w)k] converges in distribution, then a sequence
E Ew[nk/2g(w)k] also converges.
Firstly, the basic Theorem 3 in the foregoing chapter is proved in regular
cases.
Theorem 5. Based on the regularity condition, the assumptions of the basic
Theorem 3 are satisﬁed,
sup
|α|≤1

 d
dα
k
Gn(α)

≤
Op( 1
nk/2 ),
(4.14)
sup
|α|≤1

 d
dα
k
Tn(α)

≤
Op( 1
nk/2 ),
(4.15)
E[ sup
|α|≤1

 d
dα
k
Gn(α)
]
≤
O( 1
nk/2 ),
(4.16)
E[ sup
|α|≤1

 d
dα
k
Tn(α)
]
≤
O( 1
nk/2 ).
(4.17)
Proof. By applying Lemma 8 and Lemma 12 to the case g(x, w) = f(x, w),
where f(x, w) is the log density ratio function, eq.(4.16) and eq.(4.17) are
immediately derived. By Lemma 12, the random variables
nk/2 sup
|α|≤1
EX[L(X, α)],
nk/2 sup
|α|≤1
1
n
n
X
i=1
L(Xi, α)
are asymptotically uniformly integrable, resulting that they are also uni-
formly tight. Hence eq.(4.14) and eq.(4.15) are obtained.
Deﬁnition 11. Let (i1, i2, ..., it) be a set of integers and wj be the jth
element of the vector w. The constant Φ(i1, i2, ..., it) is deﬁned by
Φ(i1, i2, ..., it) =
1
(2π)d/2
Z
wi1wi2 · · · wit exp(−∥w∥2
2
)dw,

4.3. ASYMPTOTIC LOSSES
113
which is the expected value of wi1wi2 · · · wit with respect to the normal
distribution. In other words, if X is subject to the d dimensional normal
distribution whose average and covariance matrix are zero and identity re-
spectively, then
Φ(i1, i2, ..., it) = EX[Xi1Xi2 · · · Xit].
By using this deﬁnition, in oder to derive the asymptotic behaviors of
the generalization, cross validation, and training losses, we ﬁrst show the
correlations of parameters in the posterior distribution.
Lemma 13. let w0 be the optimal parameter and ξn = J−1/2∇ηn(w0). For
an arbitrary i1, i2, ..., it, a function Σn(w) is deﬁned by
Σn(w) = {((nJ)1/2(w −w0) −ξn)i1} · · · {((nJ)1/2(w −w0) −ξn)it}.
Then their averages by the posterior distribution converge in probability,
Ew[Σn(w)] →Φ(i1, i2, ..., it).
Proof. For the essential and nonessential sets of parameters W1 and W2, we
deﬁne
Z(1)
n (i1, ..., it)
=
Z
W1
Σn(w) exp(−nKn(w))ϕ(w)dw,
Z(2)
n (i1, ..., it)
=
Z
W2
Σn(w) exp(−nKn(w))ϕ(w)dw.
By the same way as Lemma 9 and 11, the convergences in probability can
be derived,
nd/2Z(1)
n (i1, ..., it) exp(−1
2∥ξn∥2)
→
(2π)d/2
(det J)1/2 Φ(i1, i2, ..., it)ϕ(w0),
nd/2Z(2)
n (i1, ..., it) exp(−1
2∥ξn∥2)
→
0.
Note that for the case (i1, i2, ..., it) is the empty set, we deﬁne Z(1)
n
= Z(1)
n (∅)
and Z(2)
n
= Z(2)
n (∅). Then
Ew[Σn(w)]
=
Z(1)
n (i1, ..., it) + Z(2)
n (i1, ..., it)
Z(1)
n
+ Z(2)
n
,
→
Φ(i1, i2, ..., it),
which completes the lemma.

114
CHAPTER 4. REGULAR POSTERIOR DISTRIBUTION
Lemma 14. The following hold.
Ew[(w −w0)]
=
(nJ)−1/2ξn + op(1/√n),
Ew[(w −w0)(w −w0)T ]
=
1
n(J−1 + J−1/2ξnξT
n J−1/2) + op(1/n),
E Ew[(w −w0)(w −w0)T ]
=
1
n(J−1 + J−1/2IJ−1/2) + o(1/n).
Proof. By Lemma 13, if t = 1 then Φ(i1) = 0, hence
(nJ)1/2Ew[(w −w0)] −ξn →0,
(4.18)
which shows the ﬁrst equation. By Lemma 13, if t = 2 and Φ(i, j) = δij, the
convergence in probability holds,
Ew[{((nJ)1/2(w −w0) −ξn)}{((nJ)1/2(w −w0) −ξn)}T ] →Id,
where Id is the d × d identity matrix.
By eq.(4.18) and convergence in
distribution of ξn,
nJ1/2Ew[(w −w0)(w −w0)T ]J1/2 −ξnξT
n →Id.
By Lemma 12,
nJ1/2E Ew[(w −w0)(w −w0)T ]J1/2 −I →Id,
which completes the lemma.
Lemma 15. The cumulants satisfy the relations,
G′
n(0)
=
−L(w0) −d + ∥ξn∥2
2n
+ op(1/n),
(4.19)
G′′
n(0)
=
tr(IJ−1)
n
+ op(1/n),
(4.20)
T ′
n(0)
=
−Ln(w0) + −d + ∥ξn∥2
2n
+ op(1/n),
(4.21)
T ′′
n (0)
=
tr(IJ−1)
n
+ op(1/n).
(4.22)
Proof. By the mean value theorem and Lemma 14,
Ew[K(w)]
=
Ew[1
2∥J1/2(w −w0)∥2] + op(1/n)
=
1
2Ew[tr(J(w −w0)(w −w0)T )] + op(1/n)
=
1
2n(d + ∥ξn∥2) + op(1/n).

4.3. ASYMPTOTIC LOSSES
115
Also by the mean value theorem,
f(x, w)
=
(w −w0) · ∇f(x, w0)
+1
2tr

∇2f(x, w0)(w −w0)(w −w0)T 
+O(∥w −w0∥3).
Hence,
Ew[f(x, w)]
=
Ew[(w −w0)] · ∇f(x, w0)
+1
2tr

∇2f(x, w0)Ew[(w −w0)(w −w0)T ]

+op(1/n)
=
1
√n J−1/2ξn · ∇f(x, w0)
+ 1
2ntr

∇2f(x, w0)(J−1 + J−1/2ξnξT
n J−1/2)

+o(1/n)
and
Ew[f(x, w)2]
=
Ew[((w −w0) · ∇f(Xi, w0))2] + op(1/n)
=
tr

Ew[(w −w0)(w −w0)T ]∇f(x, w0)(∇f(x, w0))T 
+op(1/n)
=
1
ntr

(J−1 + J−1/2ξnξT
n J−1/2)∇f(x, w0)∇f(x, w)T 
+op(1/n).
Then by using
1
√n
n
X
i=1
∇f(Xi, w0)
=
−J1/2ξn,
(4.23)
1
n
n
X
i=1
∇2f(Xi, w0)
=
J + op(1)
(4.24)
EX[∇2f(X, w0)]
=
J.
(4.25)

116
CHAPTER 4. REGULAR POSTERIOR DISTRIBUTION
It follows that
1
n
n
X
i=1
Ew[f(Xi, w)]
=
−∥ξn∥2
n
+ tr(J(J−1 + J−1/2ξnξT
n J−1/2))
2n
+op(1/n)
=
d −∥ξn∥2
2n
+ op(1/n).
By using the results above,
1
n
n
X
i=1
Ew[f(Xi, w)]2 = 1
n2
n
X
i=1
(J−1/2ξn · ∇f(Xi, w0))2 + op(1/n)
= 1
n2
n
X
i=1
tr

(J−1/2ξnξT
n J−1/2)∇f(Xi, w0)∇f(Xi, w0)T 
+ op(1/n)
= 1
ntr

(J−1/2ξnξT
n J−1/2)I

+ op(1/n)
and
1
n
n
X
i=1
Ew[f(Xi, w)2]
= 1
n2
n
X
i=1
tr

(J−1 + J−1/2ξnξT
n J−1/2)∇f(Xi, w0)∇f(Xi, w0)T 
+op(1/n)
= 1
ntr

(J−1 + J−1/2ξnξT
n J−1/2)I

+ op(1/n)
Then by using eq.(3.14) through eq.(3.17), the lemma is derived.
Theorem 6. (Regular asymptotic theory) Assume that a true distribution
is regular for a statistical model.
Then the generalization loss, the cross
validation loss, the training loss, and WAIC are asymptotically equal to
Gn
=
L(w0) + d + ∥ξn∥2 −tr(IJ−1)
2n
+ op(1/n),
(4.26)
Tn
=
Ln(w0) + d −∥ξn∥2 −tr(IJ−1)
2n
+ op(1/n),
(4.27)
Cn
=
Ln(w0) + d −∥ξn∥2 + tr(IJ−1)
2n
+ op(1/n),
(4.28)
Wn
=
Ln(w0) + d −∥ξn∥2 + tr(IJ−1)
2n
+ op(1/n).
(4.29)

4.3. ASYMPTOTIC LOSSES
117
Proof. This theorem is obtained by combining Theorem 3 and Lemma 4.19.
Theorem 7. (Expectation of regular asymptotic theory) The asymptotic
expansions of the generalization loss, the training loss, the cross validation
loss, and WAIC are given by
E[Gn]
=
L(w0) + d
2n + o(1/n),
(4.30)
E[Tn]
=
L(w0) + d −2tr(IJ−1)
2n
+ o(1/n),
(4.31)
E[Cn]
=
L(w0) + d
2n + o(1/n),
(4.32)
E[Wn]
=
L(w0) + d
2n + o(1/n).
(4.33)
Proof. Since E[Gn−1] = E[Cn], E[∥ξn∥2] = tr(IJ−1)+o(1). Then by Lemma
12, we obtain Theorem 7.
Remark 24. The equation E[∥ξn∥2] = tr(IJ−1) + o(1) can be proved by two
methods. The ﬁrst proof is derived from the deﬁnition
ξn = J−1/2 1
√n
n
X
i=1
∇f(Xi, w0).
The second is given by
E[Gn−1] = E[Cn].
If X1, X2, ..., Xn are independent, then both methods can be used. However,
if they are not independent, then the second method cannot be used. In such
a case, the ﬁrst proof can be applied.
Remark 25. (1) By the theorem, the convergence in probability holds,
n(Gn −L(w0)) + n(Cn −Ln(w0)) →d,
where d is the dimension of the parameter. That is to say, for a given triple
(q(x), p(x|w), ϕ(w)), if (Cn−Ln(w0)) is smaller then (Gn−Ln(w0)) is larger.
(2) In regular asymptotic theory, the functional variance Vn is given by
Vn
=
1
n
n
X
i=1
Vw[log p(Xi|w)]
=
tr(IJ−1)
n
+ op(1/n).

118
CHAPTER 4. REGULAR POSTERIOR DISTRIBUTION
4.4
Proof of Asymptotic Expansions
In this section, we prove Lemma 12, which is the base of the asymptotic
expansion. The random variable we study is
Y = sup
|α|≤1
EX
hnk/2 Ew[|g(X, w)|k exp(−αf(X, w))]
Ew[exp(−αf(X, w))]
i
.
Then it is suﬃcient to prove that E[|Y |1+ε] < ∞for an arbitrary ε > 0. Let
W1 = {w; ∥w −w0∥< n−2/5} and W2 = W \ W1, and
Y1
=
Ew[exp(−αf(X, w))]{W1},
(4.34)
Y2
=
Ew[exp(−αf(X, w))]{W2},
(4.35)
Y3
=
nk/2Ew[|g(X, w)|k exp(−αf(X, w))]{W1},
(4.36)
Y4
=
nk/2Ew[|g(X, w)|k exp(−αf(X, w))]{W2},
(4.37)
where E[f(X)]{S} is the expected value with restriction a set S. Then Y
can be rewritten as
Y = sup
|α|≤1
EX
hY3 + Y4
Y1 + Y2
i
.
Since Y1, Y2, Y3, Y4 > 0,
0 < Y3 + Y4
Y1 + Y2
≤Y3
Y1
+ min
nY4
Y1
, Y4
Y2
o
.
Firstly, let us study Y3/Y1.
Lemma 16. Let a, c, D, n > 0 and d ≥0 be arbitrary real constants, and
f1(u) and f2(u) be real-valued continuous functions of u ∈[0, D] ⊂R which
are diﬀerentiable in (0, D). For nonnegative integer m ≥0, Zm is deﬁned
by
Zm =
Z D
0
(au2c)m/2ud exp(−nau2c + √naucf1(u) + f2(u))du.
Then
Zm
Z0
≤2m/2Am + 2mBm/2
nm/2
,
where, by using a deﬁnition q = (m −2)c + d + 1,
A
=
(c sup
u |f1(u)| + D sup
u |f ′
1(u)|)/(2c),
(4.38)
B
=
(q + D sup
u |f ′
2(u)|)/(2c).
(4.39)

4.4. PROOF OF ASYMPTOTIC EXPANSIONS
119
Proof. For the proof we deﬁne
H(u)
=
exp(√naucf1(u) + f2(u)).
(4.40)
Note that (2c −1) + q = cm + d. By using partial integral,
Zm
=
Z D
0
{au2c−1 exp(−nau2c)}{uqH(u)}du
=
−1
2cn
Z D
0
∂u{exp(−nau2c)}{uqH(u)}du
=
−1
2cn
h
exp(−nau2c){uqH(u)}
iD
0
+ 1
2cn
Z D
0
{exp(−nau2c)}∂u{uqH(u)}du
≤
1
2cn
Z D
0
exp(−nau2c)∂u{uqH(u)}du.
(4.41)
Then by the assumption,
∂u{uqH(u)}
=
uq−1H(u){q + uf ′
2(u)
+c√naucf1(u) + √nauc+1f ′
1(u)}
≤
uq−1H(u){q + D sup |f ′
2|
+√nauc(c sup |f1| + D sup |f ′
1|)}.
(4.42)
By applying eq.(4.42) to eq.(4.41) and using deﬁnition of Zm−2 and Zm−1,
Zm
≤
Zm−2
2cn (q + D sup |f ′
2|) + Zm−1
2c√n(c sup |f1| + D sup |f ′
1|).
By using deﬁnitions of eq.(4.38) and eq.(4.39), we obtain an inequality,
Zm
Z0
≤A
√n
Zm−1
Z0
+ B
n
Zm−2
Z0
.
By Cauchy-Schwarz inequality,
Zm−1
Z0
≤
Zm
Z0
Zm−2
Z0
1/2
.
Hence
Zm
Z0
≤
A
√n
Zm
Z0
Zm−2
Z0
1/2
+ B
n
Zm−2
Z0
=
Zm
Z0
· A2
n
Zm−2
Z0
1/2
+ B
n
Zm−2
Z0
≤
1
2
Zm
Z0
+ A2
n
Zm−2
Z0

+ B
n
Zm−2
Z0
.

120
CHAPTER 4. REGULAR POSTERIOR DISTRIBUTION
It follows that
Zm
Z0
≤
A2 + 2B
n
Zm−2
Z0
.
Hence
Zm
Z0
≤(A2 + 2B)m/2
nm/2
≤2m/2Am + 2mBm/2
nm/2
,
which completes the lemma.
Lemma 17. Let Y1 and Y3 be random variables deﬁned by eq.(4.34) and
eq.(4.36) respectively. We deﬁne
T(X) = sup
w∈W1
∥J−1/2∇g(X, w)∥.
Then
Y3
Y1
≤T(X)k(2kA2k + 22kBk),
where
A
≤
c1∥∇ηn(w0)∥
(4.43)
B
≤
q + c2n−2/5(sup
w |∇wf(X, w)| + sup
w |∇wδn(w)|).
(4.44)
Here by using q = (2k −2) + d, and c1, c2 > 0 are constants determined by
J. Hence E[(Y3/Y1)1+ε] < ∞.
Proof. By the deﬁnitions,
Y3
Y1
= nk/2
R
W1 |f(X, w)|k exp(−nKn(w) −αf(X, w))ϕ(w)dw
R
W1 exp(−nKn(w) −αf(X, w))ϕ(w)dw
where
nKn(w) = n
2 ∥J1/2(w −w0)∥2 −∇ηn(w0) · (w −w0) + δn(w).
By J1/2(w −w0) = rθ where θ is the generalized polar coordinate with
|θ| = 1. Then
∥J1/2(w −w0)∥2 = r2.

4.4. PROOF OF ASYMPTOTIC EXPANSIONS
121
By
T(X) = sup
w∈W1
∥J−1/2∇f(X, w)∥
it follows that
|f(X, w)| ≤rT(X).
Hence
Y3
Y1
≤T(X)k
R
W1(nr2)k/2 exp(−nr2 + √nrf1(θ) + f2(r, θ))rd−1drdθ
R
W1 exp(−nr2 + √nrf1(θ) + f2(r, θ))rd−1drdθ
,
where
f1(θ)
=
J−1/2∇ηn(w0) · θ
f2(r, θ)
=
−αf(X, r, θ) + log ϕ(r, θ) −δn(r, θ)
By applying Lemma 16,
Y3
Y1
≤T(X)k(2kA2k + 22kBk),
where, by using q = (2k −2) + d, D = ∥J1/2∥n−2/5
A
=
sup
θ
|f1(θ)|/2
B
=
(q + D sup
(ℓ,θ)
|∂rf2(r, θ)|)/2,
where we used the inequality
∂f
∂r
 =
 ∂f
∂w · ∂w
∂r
 ≤|∇f∥∥J−1/2∥.
Lemma 18. Let
f(X) = sup
w∈W
|f(X, w)|,
g(X) = sup
w∈W
|g(X, w)|.
Then
Y4
Y1
≤
g(X)k exp(2αf(X)) exp(−(J1/4)n1/5 + (k/2) log n + γn),
Y4
Y2
≤
nk/2g(X)k.

122
CHAPTER 4. REGULAR POSTERIOR DISTRIBUTION
Proof. Then by deﬁnition,
Y1
≥
exp(−αf(X))Z(1)
n .
Y4
≤
nk/2g(X)k exp(αf(X))Z(2)
n .
Hence
Y4/Y1
≤
nk/2g(X)k exp(2αf(X))Z(2)
n /Z(1)
n ,
≤
nk/2g(X)k exp(2αf(X)) exp(−(J1/4)n1/5 + γn).
On the other hand,
Y4/Y2
≤
nk/2g(X)k
is derived from the deﬁnition of f(X).
Lemma 19. Let An and Bn be random variables. Assume that
M = sup
n E[(|An| + |Bn|)m+ℓ] < ∞
and that {an > 0} is an increasing sequence of real values. Then
E[|An|m min{exp(An + Bn −an), nm/2}]
≤E[|An|m] + Mnm/2/(an)ℓ.
(4.45)
Proof. By the assumption
M = E[(|An| + |Bn|)m+ℓ]
is ﬁnite. Hence
M
≥
(an)ℓE[(|An|| + |Bn|)m]{|An|+|Bn|≥an}.
Let En be the left hand side of eq.(4.45).
En
≤
E[|An|m]{|An|+|Bn|<an} + E[nk/2|An|m]{|An|+|Bn|≥an}
≤
E[|An|m] + Mnm/2/(an)ℓ,
which completes the lemma.
Let us prove Lemma 12
Proof. (Proof of Lemma 12 ). By Lemma 17, E[|Y3/Y1|1+ε] < ∞. In Lemma
19, by putting m = k + ε, An = supw |f(X, w)|, Bn = γn, and an =
(J1/4)n1/5 −(k/2) log n, and ℓ= 5m/2,
E
h
min
nY4
Y1
, Y4
Y2
o1+εi
< ∞,
which completes the lemma.

4.5. POINT ESTIMATORS
123
4.5
Point Estimators
In this section, we study other statistical estimation methods when a true
distribution is regular for a statistical model.
Deﬁnition 12. The maximum likelihood estimator wML, the maximum
a posteriori estimator wMAP, and the posterior mean estimator wP M are
deﬁned by
wML
=
arg max
w∈W
n
Y
i=1
p(Xi|w),
(4.46)
wMAP
=
arg max
w∈W ϕ(w)
n
Y
i=1
p(Xi|w),
(4.47)
wP M
=
Ew[w],
(4.48)
where
“arg max
w∈W f(w)”
is the parameter that maximizes f(w).
The
procedures in which a true distribution q(x) is estimated by p(x|wML),
p(x|wMAP ), and p(x|wP M) are respectively called the maximum likelihood,
maximum a posteriori, and the posterior mean methods.
If a true distribution is regular for a statistical model, by using
nKn(w) = n
2∥J1/2(w −w0)∥2 −∇n(w0) · (w −w0) + op(1),
these three estimators are asymptotically equivalent,
wML
=
w0 + J−1/2ξn
√n
+ op( 1
√n),
wMAP
=
w0 + J−1/2ξn
√n
+ op( 1
√n),
wP M
=
w0 + J−1/2ξn
√n
+ op( 1
√n).
Remark 26. (1) Even if a same prior distribution is employed, p(x|wMAP )
and p(x|wP M) are diﬀerent from the Bayesian estimation Ew[p(x|w)]. In
some books and papers, p(x|wMAP ) and p(x|wP M) may be called ‘Bayesian
estimation’ and Ew[p(x|w)] is called ‘fully Bayesian estimation’.
(2) If a true distribution is not regular for a statistical model, then wML,
wMAP, and wP M are not equivalent even asymptotically.

124
CHAPTER 4. REGULAR POSTERIOR DISTRIBUTION
Lemma 20. The generalization and training losses of the maximum likeli-
hood method are deﬁned by
Gn(ML)
=
L(wML),
(4.49)
Tn(ML)
=
Ln(wML).
(4.50)
If a true model is regular for a statistical model,
Gn(ML)
=
L(w0) + ∥ξn∥2
2n
+ op( 1
n),
(4.51)
Tn(ML)
=
Ln(w0) −∥ξn∥2
2n
+ op( 1
n).
(4.52)
The generalization and training losses of the maximum a posteriori method
and posterior mean method are asymptotically equivalent to those of the
maximum likelihood method.
Proof. The generalization and training losses by the maximum likelihood
method are given by
Gn(ML)
=
L(w0) + K(wML),
(4.53)
Tn(ML)
=
Ln(w0) + Kn(wML).
(4.54)
By J = ∇2K(w0),
K(wML)
=
1
2(w0 −wML) · ∇2K(w0)(w0 −wML) + op( 1
n)
=
∥ξn∥2
2n
+ op( 1
n)
and by ∇Kn(w0) = −(1/√n)∇ηn(w0) = −(1/√n)J1/2ξn, and
∇2Kn(w0) = ∇2K(w0) + op(1),
it follows that
Kn(wML)
=
(w0 −wML) · ∇Kn(w0)
+1
2(w0 −wML) · ∇2Kn(w0)(w0 −wML) + op( 1
n)
=
−∥ξn∥2
2n
+ op( 1
n).

4.5. POINT ESTIMATORS
125
The generalization and training losses of the maximum it a posteriori
and the posterior mean methods have the same asymptotic behaviors as
the maximum likelihood method. If a true distribution is realizable by a
statistical model, then I = J, resulting that these asymptotic losses are
equivalent to those of Bayesian estimation in Theorem 6.
Remark 27. (Deviance and functional variance) In Bayesian estimation, the
deviance Dev and functional variance V are deﬁned by
Dev
=
−2
n
n n
X
i=1
Ew[log p(Xi|w)] −
n
X
i=1
log p(Xi|Ew[w])
o
,
V
=
1
n
n
X
i=1
n
E[(log p(Xi|w))2] −E[log p(Xi|w)]2o
.
If a true distribution is regular for a statistical model and if n is suﬃciently
large,
Dev
=
2{Ew[Kn(w)] −Kn(Ew[w])}
=
2{d −∥ξn∥2
2n
−−∥ξn∥2
2n
} + op( 1
n)
=
d
n + op( 1
n),
(4.55)
and
V
=
T ′′
n (0) = tr(IJ−1)
n
+ op(1/n).
(4.56)
Note that eq.(4.55) and eq.(4.56) hold even if a true distribution is not
realizable by a statistical model.
In practical applications, we do not know the true distribution, hence
the optimal parameter w0 is unknown. Let ˆw be the MAP estimator. Let
us introduce a numerical calculation method for the free energy,
Fn
=
−log
Z
exp(−nL(w))dw.
Here L(w) is the sum of the log likelihood function and log prior,
L(w) = nLn(w) −log ϕ(w).
By the regularity condition,
nL(w) ≈nLn( ˆw) + n
2(w −ˆw)Jn(w −ˆw) + op(1),

126
CHAPTER 4. REGULAR POSTERIOR DISTRIBUTION
where we used a notation, Jn = ∇2Ln( ˆw). It follows that
Fn = nLn( ˆw) + d
2 log n −d
2 log(2π) + 1
2 log det Jn −log ϕ( ˆw) + op(1). (4.57)
The information criterion BIC is deﬁned by
BIC = nLn(ˆw) + d
2 log n.
(4.58)
The cross validation and training losses are
Cn
≈
Ln( ˆw) + d + tr(InJ−1
n )
2n
+ op(1/n),
(4.59)
Tn
≈
Ln( ˆw) + d −tr(InJ−1
n )
2n
+ op(1/n),
(4.60)
where
In = 1
n
n
X
i=1
∇f(Xi, ˆw)(∇f(Xi, ˆw))T .
4.6
Problems
1. Let p(x|m, s) and ϕ(m, s|φ) be a statistical model and a prior given by
eq.(2.1) and eq.(2.2), respectively. Show that the MAP estimator ( ˆm, ˆs) is
ˆm
=
ˆφ2/ˆφ3,
ˆs
=
ˆφ2
3/(ˆφ1 ˆφ3 −ˆφ2
2),
where ˆφ1, ˆφ2, and ˆφ3 are given by eq.(2.6), (2.7), and (2.8). The log loss
function is given by
Ln(w) = 1
2 log(2π) −log s
2
+ s
2n
n
X
i=1
(Xi −m)2.
Show that the matrix In(m, s) is given by
(In)11(m, s)
=
s2
n
n
X
i=1
(Xi −m)2,
(In)12(m, s)
=
1
2n
n
X
i=1
(1 −s(Xi −m)2)(Xi −m),
(In)22(m, s)
=
1
4n
n
X
i=1
(1/s −(Xi −m)2)2,

4.6. PROBLEMS
127
0
5
10
15
20
25
30
-0.5
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
sample size n
 
 
F - n*Sn
Asymptotic F - n*Sn
BIC - n*Sn
Figure 4.1: Free energy and its asymptotic form in normal distribution.
Values Fn −nSn are compared with the asymptotic form and BIC. In a
normal distribution, Fn −nSn can be approximated by its asymptotic form
when n ≥10. The diﬀerence between Fn and BIC is a constant order term.
and (In)21(m, s) = (In)12(m, s). Also the matrix Jn(m, s) is given by
(Jn)11(m, s)
=
s,
(Jn)12(m, s)
=
m −1
n
n
X
i=1
Xi,
(Jn)22(m, s)
=
1/(2s2),
and (Jn)21(m, s) = (Jn)12(m, s). A true parameter w0 and a hyperparamter
φ are determined as Example 5. The free energy or the minus log marginal
likelihood Fn and the empirical entropy are given by eq.(2.9) and Ln(w0),
respectively. The asymptotic form of Fn and BIC are given by eq.(4.57)
and eq.(4.58), respectively. In Figure 4.1, Fn −nSn is compared with its
asymptotic form and BIC, by using the numerical calculation. In a normal
distribution, the free energy can be approximated by its asymptotic form
when n ≥10. The diﬀerence between Fn and BIC is a constant order term.
In Figure 4.2, tr(In( ˆw)J−1
n ( ˆw)) is compared with nV and n(Cn −Tn), where

128
CHAPTER 4. REGULAR POSTERIOR DISTRIBUTION
×
×
Figure 4.2: Comparison of tr(IJ−1) with V in normal distribution. Values
tr(In( ˆw)J−1
n ( ˆw)) are compared with nV , and n(CV −TE), where V is the
functional variance, CV −TE is the diﬀerence between the cross validation
error and the training error in a simple normal distribution.
V and Cn −Tn are the functional variance and the diﬀerence between the
cross validation and training loss. In this case, the variance of the n(Cn−Tn)
is larger than the others. The values n(Cn −Tn) and nV are approximated
by tr(InJ−1
n ) when n ≥40. From the numerical point of view, the precise
approximation of the free energy does not ensure that of the generalization
loss.
2. A statistical model is deﬁned by
p(x|a, b) = (1 −a)N(x) + aN(x −b),
where N(x) is the probability density of the standard normal distribution.
A true density is set as q(x) = p(x|0.5, 1) and the uniform prior for (a, b)
is given by [0, 1] × [0, 2]. Then the true distribution is realizable by and
regular for a statistical model and the maximum a posteriori estimator is
equal to the maximum likelihood estimator. The free energy or the minus

4.6. PROBLEMS
129
0
100
200
300
400
500
600
-2
-1
0
1
2
3
4
5
6
7
sample size n
 
 
F - n*Sn
Asymptotic F - n*Sn
BIC - n*Sn
Figure 4.3: Free energy and its asymptotic form in a normal mixture. Values
Fn −nSn are compared with its asymptotic form and BIC. In a normal
mixture, Fn −nSn can be approximated by its asymptotic form when n ≥
200. The diﬀerence between Fn and BIC is a constant order term.
log marginal likelihood Fn and the empirical entropy are given by eq.(2.9)
and Ln(w0), respectively. The asymptotic form of Fn and BIC are given by
eq.(4.57) and eq.(4.58), respectively. In this experiment, the integration of a
function f(a, b) over the parameter (a, b) is performed by the Riemann sum
Z 1
0
da
Z 2
0
f(a, b)dadb =
1
2N 2
N
X
j=1
N
X
k=1
f(j/N −1/2, 2k/N −1).
In Figure 4.3, Fn −nSn is compared with its asymptotic form and BIC, by
using the numerical calculation. In a normal mixture, the free energy can be
approximated by its asymptotic form when n ≥200. The diﬀerence between
Fn and BIC is a constant order term. In Figure 4.4, ntr(In( ˆw)J−1
n ( ˆw)) is
numerically compared with nV where V is the functional variance. The hor-
izontal and vertical axes show the sample size and the average and standard
deviation for 100 sample sets Xn, respectively. The true parameter is the
regular point for the statistical model. Let M(x) = N(x) −N(x −b) and

130
CHAPTER 4. REGULAR POSTERIOR DISTRIBUTION
×
×
Figure 4.4: Comparison with tr(IJ−1) with V in normal mixture. Values for
tr(In( ˆw)J−1
n ( ˆw)) are compared with nV , and n(CV −GE), where V is the
functional variance, CV is the cross validation error, and TE is the training
error in a normal mixture.
p(x) = p(x|a, b). Show that
(In)11(a, b)
=
1
n
n
X
i=1
M(Xi)2/p(Xi)2,
(In)12(a, b)
=
1
n
n
X
i=1
aM(Xi)N ′(x −b)/p(Xi)2,
(In)22(a, b)
=
1
n
n
X
i=1
{aN ′(x −b)}2/p(Xi)2,
and (In)21(a, b) = (In)12(a, b). Also show that the matrix Jn(a, b) is given

4.6. PROBLEMS
131
by
(Jn)11(a, b)
=
1
n
n
X
i=1
M(Xi)2/p(Xi)2,
(Jn)12(a, b)
=
1
n
n
X
i=1
N ′(x −b){p(Xi) + aM(Xi)}/p(Xi)2,
(Jn)22(a, b)
=
1
n
n
X
i=1
{−aN ′′(Xi −b)/p + (aN ′(Xi −b))2/p2},
and (Jn)21(a, b) = (Jn)12(a, b). The varinace of tr(In( ˆw)J−1
n ( ˆw)) is larger
than those of nV and n(Cn −Tn). The dimension of the parameter space
is two, and the true parameter is a regular point for the log loss function.
However, the regular theory needs n ≥500. From the numerical point of
view, the precise approximation of the free energy does not ensure that of
the generalization loss.
3. A neural network is deﬁned by a conditional density
p(y|x, a, b) =
1
√
2π
exp(−1
2(y −a tanh(bx))2).
A probability density of x is set as the uniform distribution of [−2, 2]. A
true conditional density is set as p(y|x, 1, 1), and the uniform prior for (a, b)
is given by [0, 2] × [0, 2]. Then the true distribution is realizable by and
regular for a statistical model and the maximum a posteriori estimator is
equal to the maximum likelihood estimator. The value ntr(In( ˆw)J−1
n ( ˆw))
is numerically compared with nV where V is the functional variance. The
experimental result is shown in Figure 4.5. The horizontal and vertical axes
show the sample size and the average and standard deviation for 100 sample
sets (Xn, Y n), respectively. In this case the true parameter is the regular
point for the statistical model. Let
Z0(x)
=
tanh(bx),
Z1(x)
=
(1 −Z0(x)2)x,
Z2(x)
=
−2Z0(x)Z1(x)x.

132
CHAPTER 4. REGULAR POSTERIOR DISTRIBUTION
×
×
Figure 4.5: Comparison with tr(IJ−1) with V in neural network. Values for
tr(In( ˆw)J−1
n ( ˆw)) are compared with nV , and n(CV −GE), where V is the
functional variance, CV is the cross validation error, and TE is the training
error in a neural network.
(In)11(a, b)
=
1
n
n
X
i=1
(aZ0(Xi) −Yi)2Z0(Xi)2,
(In)12(a, b)
=
1
n
n
X
i=1
a(aZ0(Xi) −Yi)2Z0(Xi)Z1(Xi),
(In)22(a, b)
=
1
n
n
X
i=1
a2(aZ0(Xi) −Yi)2Z1(Xi)2,
and (In)21(a, b) = (In)12(a, b). Also show that the matrix Jn(a, b) is given

4.6. PROBLEMS
133
by
(Jn)11(a, b)
=
1
n
n
X
i=1
Z0(Xi)2,
(Jn)12(a, b)
=
1
n
n
X
i=1
{2aZ0(Xi)Z1(Xi) −YiZ1(Xi)},
(Jn)22(a, b)
=
1
n
n
X
i=1
{a2Z1(Xi)2 + a(aZ0(Xi) −Yi)Z2(Xi)},
and (Jn)21(a, b) = (Jn)12(a, b). The varinace of tr(In( ˆw)J−1
n ( ˆw)) is largar
than those of nV and n(Cn −Tn). Tthe dimension of the parameter space
is two, and the true parameter is a regular point for the log loss function,
however, the regular theory needs n ≥1000. In practical applications, neu-
ral networks which have many parameters are employed, hence the regular
theory does not hold in all cases. However, the general theory introduced in
the following chapters holds.


Chapter 5
Standard Posterior
Distribution
If a true distribution is regular for a statistical model and if the posterior
distribution can be approximated by a normal distribution, the diﬀerence
between Bayesian and maximum likelihood estimations is not so large. How-
ever, the posterior distributions are often far from any normal distribution,
showing that Bayesian estimation gives the more accurate inference than
other estimation methods. In this chapter we study the case when the pos-
terior density p(w) is asymptotically given by
p(w) ∝exp

−n w2k1
1
w2k2
2
· · · w2kd
d

.
It might seem that such a posterior density appears in a special case. How-
ever, in the next chapter, we show that most posterior densities are mathe-
matically equivalent to this function. Therefore, the results of this chapter
are the universal laws of Bayesian statistics.
This chapter consists of the following parts.
(1) A standard form is introduced and the real log canonical threshold is
deﬁned.
(2) Asymptotic property of a state density function is derived.
(3) Asymptotic behavior of the free energy or the minus log marginal like-
lihood is represented by the real log canonical threshold.
(4) By using the renormalized posterior distribution, mathematical laws
among the generalization loss, cross validation loss, training loss, and WAIC
are established.
(5) If random variables are conditionally independent, the relation between
the generalization and cross validation losses does not hold. However, the
135

136
CHAPTER 5. STANDARD POSTERIOR DISTRIBUTION
mathematical theorem which connects the generalization loss and WAIC can
be proved.
5.1
Standard Form
In order to deﬁne a standard form, we need a representation of a multi-index.
Deﬁnition 13. (Multi-index) A d-dimensional multi-index k is deﬁned by
k = (k1, k2, ..., kd).
For a multi-index k, notations k > 0 and k ≥0 are deﬁned as follows.
k ≥0 ⇐⇒k1 ≥0, k2 ≥0, ..., kd ≥0.
and
k > 0 ⇐⇒k ≥0, there exists j such that kj > 0.
Let k ≥0. For a given variable w = (w1, w2, ..., wd) ∈Rd we deﬁne
wk = wk1
1 wk2
2 · · · wkd
d ,
where 00 = 1.
Example 23. Let d = 5. For multi-indexes,
k
=
(3, 6, 7, 0, 0),
h
=
(1, 0, 0, 8, 0),
and a variable w = (w1, w2, w3, w4, w5),
wk
=
w3
1w6
2w7
3,
wh
=
w1w8
4.
Note that, if h = (0, 0, 0, 0, 0), then
wh = 1.
The following deﬁnition is the concept of the standard form. Let q(x)
and p(x|w) be a true distribution and a statistical model, respectively.

5.1. STANDARD FORM
137
Deﬁnition 14. (Standard form) Let x ∈RN and w ∈W ⊂Rd. We study
a statistical model p(x|w) of x for a given parameter w. Assume that W is
a compact set which is a closure of some open set. Also we assume that W
contains the origin and that W0 is the set of parameters which minimizes
the average log loss function. The log density ratio function and its average
are respectively denoted by
f(x, w)
=
log p(x|w0)
p(x|w) ,
(5.1)
K(w)
=
Z
q(x)f(x, w)dx.
(5.2)
We assume that the log density ratio function has relatively ﬁnite variance,
hence f(x, w) does not depend on the choice of w0 ∈W0. A set of statistical
model p(x|w) and a prior ϕ(w) is said to be a standard form if there exist
functions a(x, w) and b(w) which satisfy
f(x, w)
=
wka(x, w),
(5.3)
K(w)
=
w2k,
(5.4)
ϕ(w)
=
|wh| b(w),
(5.5)
where both k > 0 and h ≥0 are multi-indexes and b(w) > 0 in a neighbor-
hood of the origin.
Remark 28. (Normal crossing function) If an average log density ratio func-
tion K(w) is represented by w2k, then it is called normal crossing. It might
seem that a very special set of a statistical model and a prior has a standard
form. However, in the next section, we show almost all statistical models
and priors such as a normal mixture and a neural network can be made to
be standard forms by using an algebraic geometrical transform of the pa-
rameter set. Therefore the statistical theory of this chapter holds for such
statistical models and priors.
By the deﬁnition and
K(w) =
Z
q(x)f(x, w)dx,
it follows that
wk =
Z
q(x)a(x, w)dx.
The set of optimal parameters W0 = {w ∈W; K(w) = 0} is
W0 = {w ∈W; w2k = 0},

138
CHAPTER 5. STANDARD POSTERIOR DISTRIBUTION
which is equal to
W0 =
[
j:kj>0
{w ∈W ; wj = 0},
where S
j:kj>0 shows the union of sets for all j such that kj > 0.
Example 24. Let x, w ∈R1 and W = [−1, 1]. A statistical model and a prior
are
p(x|w)
=
1
√π exp(−(x −w)2),
ϕ(w)
=
|w|2.
Assume that q(x) = p(x|0). Then w0 = 0 and
f(x, w)
=
w(w −x),
(5.6)
K(w)
=
w2.
(5.7)
Therefore the set of a model and a prior is a standard form with k = 1, h = 2
and
a(x, w)
=
w −x,
(5.8)
b(w)
=
1.
(5.9)
Example 25. Let −1 ≤x ≤1, y ∈R, and W = {(s, t) ∈R2; −1 ≤s, t ≤1}.
A statistical model and a prior are deﬁned by
p(x, y|s, t)
=
1
2
√
2π
exp
n
−1
2(y −sF(x, t))2o
,
ϕ(s, t)
=
1/4,
where
F(x, t) =
√
2
√
3x + t
√
t2 + 1
.
Therefore p(x|s, t) is the uniform distribution on [−1, 1].
Assume that
q(x, y) = p(x, y|0, 0). Then
f(x, s, t)
=
s2F(x, t)2/2 −syF(x, t),
(5.10)
K(s, t)
=
s2.
(5.11)
Hence
a(x, s, t)
=
sF(x, t)2/2 −yF(x, t),
(5.12)
b(s, t)
=
1/4.
(5.13)
Therefore the set of a model and a prior is a standard form with k = (1, 0),
h = (0, 0).

5.1. STANDARD FORM
139
Example 26. Let x = (y, z), w = (s, t) ∈R2 and
W = {w = (s, t) ; s2 + t2 ≤1}.
A statistical model and a prior are
p(y, z|s, t)
=
1
π exp(−(y −s)2 −(z −t)2),
ϕ(s, t)
=
1
π .
Assume that q(x) = p(x|0, 0). Then w0 = (0, 0) and
f(x, w)
=
s2 + t2 −2ys −2zt,
K(w)
=
s2 + t2.
This is not a standard form. By using a polar coordinate (r, θ),
s
=
r cos θ,
t
=
r sin θ,
where 0 ≤r ≤1 and 0 ≤θ < 2π, the model and prior are rewritten as
f(x, r, θ)
=
r(r −2y cos θ −2z sin θ),
K(r, θ)
=
r2,
ϕ(w)dw
=
r
πdrdθ.
Therefore the pair of a model and a prior is a standard form with k =
(1, 0), h = (1, 0) and
a(x, r, θ)
=
r −2y cos θ −2z sin θ,
b(r, θ)
=
1
π.
In this case, a true distribution q(x) is regular for a statistical model p(x|s, t),
but not for p(x|r, θ).
Lemma 21. Assume that a statistical model p(x|w) has a relatively ﬁnite
variance and that there exists a C1-class function K0(w) > 0 which satisﬁes
f(x, w)
=
wka(x, w),
(5.14)
K(w)
=
w2kK0(w),
(5.15)
ϕ(w)
=
|wh| b(w),
(5.16)

140
CHAPTER 5. STANDARD POSTERIOR DISTRIBUTION
where k > 0 and h ≥0 are multi-indexes and b(w) > 0 in a neighborhood of
the origin. Since k > 0, we can assume k1 > 0 without loss of generality.
Also we assume that
W(dK0) = {w ∈W ; K0(w)1/2k1 + w1
2k1
K0(w)1/2k1−1 ∂K0(w)
∂w1
= 0}
is a measure zero subset in W. Then by using
u1
=
K0(w)1/(2k1)w1,
u2
=
w2,
· · ·
ud
=
wd,
the pair of a model and a prior is a standard form of u.
Proof. The absolute value of the determinant of the Jacobian matrix |∂u/∂w|
is equal to |∂u1/∂w1| and
∂u1
∂w1
= K0(w)1/2k1 + w1
2k1
K0(w)1/2k1−1 ∂K0(w)
∂w1
.
Since K0(w) > 0 is a C1-class function and W is compact, there exist
constants A, B > 0 such that
min
w∈W K0(w)
>
A,
max
w∈W
∂K0(w)
∂w1

<
B.
Therefore, in a neighborhood of the origin, |∂u1/∂w1| > 0. The map w 7→u
is one-to-one in the set W \ W(∂u1/∂w1), where W(∂u1/∂w1) is the set
of all zero points of |∂u1/∂w1|. Thus its inverse function is well-deﬁned in
W \ W(∂u1/∂w1), which is denoted by w = g(u). Then
f(x, g(u))
=
uka(x, g(u))/K0(g(u))1/2,
Z
q(x)f(x, g(u))dx
=
u2k,
ϕ(g(u))|g′(u)|
=
|uh|b(g(u))|g′(u)|,
which shows the pair of a model and a prior is a standard form, where |g′(u)|
is the determinant of the Jacobian matrix of w = g(u).

5.1. STANDARD FORM
141
Example 27. Let 0 ≤x ≤1, y ∈R, and W = {(s, t) ∈R2; 0 ≤s, t ≤1}. A
statistical model and a prior are deﬁned by
p(x, y|s, t)
=
1
√
2π exp(−1
2(y −s tanh(tx))2),
ϕ(s, t)
=
1.
Therefore p(x|s, t) is the uniform distribution on [0, 1]. Assume that q(x, y) =
p(x, y|0, 0). Then
K(s, t) = s2t2
2 K0(t),
where
K0(t) =
Z 1
0
tanh(tx)
t
2
dx.
By the above lemma, the pair of a model and a prior is made to be a standard
form by
s′
=
s,
t′
=
t(K0(t)/2)1/2.
In this case, a true distribution cannot be regular for a statistical model by
any transform of parameters.
Example 28. Let N(x) be a probability density function of the normal distri-
bution whose average and standard deviation are zero and one respectively,
N(x) =
1
√
2π exp(−x2
2 ).
Let x ∈R and W = {(s, t); 0 ≤s ≤1, |t| < 1}. A statistical model and a
prior are deﬁned by
p(x|s, t)
=
(1 −s)N(x) + sN(x −t),
ϕ(s, t)
=
1/2.
Assume that a true distribution is N(x). Then the set of optimal parameters
is
W0 = {(s, t) ∈W ; s = 0, or t = 0}.
The log density ratio function is
f(x, s, t)
=
log
N(x)
(1 −s)N(x) + sN(x −t)
=
−log[1 + s{etx−t2/2 −1}]
=
−st (x −t/2) T(tx −t2/2) S(s(etx−t2/2 −1)),

142
CHAPTER 5. STANDARD POSTERIOR DISTRIBUTION
where two analytic functions are deﬁned by
S(x)
=
log(1 + x)/x,
T(x)
=
(ex −1)/x,
with T(0) = S(0) = 1. Hence by
a(x, s, t) = −(x −t/2) T(tx −t2/2) S(s(etx−t2/2 −1)),
the pair of a model and a prior is a standard form. Note that
K(s, t)
=
Z
N(x){f(x, s, t) + exp(−f(x, s, t)) −1}dx
=
Z
N(x)f(x, s, t)2U(f(x, s, t))dx
=
(st)2
Z
N(x)a(x, s, t)2U(f(x, s, t))dx,
where
U(x) = (x + e−x −1)
x2
is an analytic function by deﬁning U(0) = 1/2. In this case, a true distri-
bution N(x) cannot be regular for a statistical model by any transform of
parameters.
Example 29. Let 0 ≤x1, x2 ≤1, y ∈R, and W = {(s, t1, t2) ∈R3; 0 ≤s ≤
1, t2
1 + t2
2 ≤1}. A statistical model and a prior are deﬁned by
p(x1, x2, y|s, t)
=
1
√
2π exp(−1
2(y −s tanh(t1x1 + t2x2))2),
ϕ(s, t1, t2)
=
1/π.
Therefore p(x1, x2|s, t1, t2) is the uniform distribution on [0, 1]2.
Assume
that q(x1, x2, y) = p(x1, x2, y|0, 0, 0). By using
s
=
s,
t1
=
r cos θ,
t2
=
r sin θ,
where 0 ≤r ≤1, −π ≤θ < π,
K(s, r, θ)
=
s2r2
2 K0(r, θ),
(1/π)dsdt1dt2
=
(r/π)dsdrdθ,

5.1. STANDARD FORM
143
where
K0(r, θ) =
Z 1
0
Z 1
0
tanh{r(x1 cos θ + x2 sin θ)}
r
2
dx1dx2.
The pair of a model and a prior is made a standard form.
Example 30. A neural network which has H hidden units is deﬁned by
p(x, y|{sh, th})
=
1
√
2π exp(−1
2(y −
H
X
h=1
sh tanh(thx))2).
In this case, in order to ﬁnd a transform which makes the model a standard
form, we need the method explained in the next chapter.
Remark 29. Almost all statistical models and priors used in practical ap-
plications can be made to be standard forms by choosing an appropriate
function,
w = g(u).
Then a statistical model and a prior are rewritten as
p(x|w)
=
p(x|g(u)),
ϕ(w)dw
=
ϕ(u)|g′(u)|du,
where |g′(u)| is the absolute value of the determinant of the Jacobian matrix,
|g′(u)| =
det
∂w
∂u
.
From the view point of Bayesian statistics, (p(x|w), ϕ(w)) is equivalent to
(p(x|g(u)), ϕ(w)|g′(u)|). In other words, the free energy and generalization,
cross validation, and training losses are invariant by w = g(u). A method
to ﬁnd the appropriate function w = g(u) is discussed in the next chapter.
In order to study statistical estimation, we need additional mathematical
conditions.
Deﬁnition 15. (Mathematical condition) (1) The set of parameters W is
a compact set in Rd and the closure of its largest open set is equal to W.
(2) A statistical model is a standard form and a(x, w) deﬁned in eq.(5.3)
satisﬁes that for an arbitrary s > 0 and arbitrary multi-index k ≥0,
Z
sup
w∈W
|(∂/∂w)ka(x, w)|sq(x)dx < ∞.

144
CHAPTER 5. STANDARD POSTERIOR DISTRIBUTION
To construct statistical theory for a standard form, we need stochastic
process because W0 is not a single element.
Deﬁnition 16. Assume that a statistical model is a standard form.
A
stochastic process ξn(w) is deﬁned by
ξn(w) =
1
√n
n
X
i=1
{wk −a(Xi, w)}.
(5.17)
By this deﬁnition and the assumption that a statistical model is a stan-
dard form, it follows that
E[ξn(w)]
=
0,
(5.18)
E[ξn(w)ξn(u)]
=
EX[a(X, w)a(X, u)] −wkuk.
(5.19)
On the other hand, the Gaussian process ξ(w) on W that satisﬁes
Eξ[ξ(w)]
=
0,
(5.20)
Eξ[ξ(w)ξ(u)]
=
Eξ[a(X, w)a(X, u)] −wkuk,
(5.21)
is uniquely determined. If ξn(w) satisﬁes conditions of Deﬁnition 15,
lim
n→∞E[F(ξn)] = Eξ[F(ξ)]
holds for an arbitrary continuous and bounded functional F( ), where F is
a function from a set of functions
{f(w) ; sup
w∈W
|f(w)| < ∞}
to R. Moreover, for an arbitrary s > 0,
lim
n→∞E[ sup
w∈W
|ξn(w)|s] = Eξ[ sup
w∈W
|ξ(w)|s].
The mathematical background of these properties is explained in Section
10.4.
Example 31. Let {Xi; i = 1, 2, ..., n} be a set of independent random vari-
ables which are subject to the uniform distribution on [−1, 1]. For a param-
eter a (0 ≤a ≤2π), an empirical process ξn(a) is deﬁned by
ξn(a) =
1
√n
n
X
i=1
sin(axi).

5.1. STANDARD FORM
145
ξ
ξ
Figure 5.1: Examples of empirical processes are illustrated for n = 10 and
n = 100. In the standard theory, the set of the optimal parameters W0
consists of a union of several manifolds, empirical process theory is necessary.
For each a, ξn(a) converges to a normal distribution whose average is zero
and variance is EX[sin(aX)2]. See Figure 5.1. Moreover, ξn(a) converges
to a Gaussian process as a random process. Here a random process is a
function-valued random variable.
Theorem 8. Assume that a set of a statistical model and a prior is a stan-
dard form. The log likelihood ratio function is deﬁned by
Kn(w) = 1
n
n
X
i=1
f(Xi, w).
Then
nKn(w) = n w2k −√n wk ξn(w),
(5.22)
where ξn(w) satisﬁes the convergence in distribution ξn(w) →ξ(w).
Proof. This theorem is shown by applying deﬁnitions f(x, w) = wka(x, w),
K(w) = w2k, and eq.(5.17) to
nKn(w) = nK(w) −n(K(w) −Kn(w)).
Then by using the empirical process theory in Section 10.4, we obtain the
theorem.

146
CHAPTER 5. STANDARD POSTERIOR DISTRIBUTION
Example 32. For a nonregular case in Example 25, ξn(s, t) is given by
ξn(s, t) =
1
√n
n
X
i=1
{s −sF(Xi, t)2/2 + YiF(Xi, t)}.
Then
nKn(s, t) = ns2 −√n s ξn(s, t).
5.2
State Density Function
Let K(w) and ϕ(w) be the average log density ratio function and a prior of
w ∈W ⊂Rd respectively. The posterior distribution has a form
exp(−nK(w)) ϕ(w),
which is the Laplace transform of the state density function
δ(t −K(w)) ϕ(w),
where t > 0. The asymptotic behavior for n →∞corresponds to t →+0,
hence in this section we study the state density funciton and its asymptotic
behavior.
Assume that a pair of a statistical model and a prior is a standard form.
Then on the positive region of parameters,
w1, w2, ..., wd ≥0,
(5.23)
the state density function is
δ(t −K(w))ϕ(w) = δ(t −w2k)|wh|b(w)χ(w),
where χ(w) is the characteristic function of the positive region of parameters,
χ(w) =
 1
(w1, w2, ..., wd ≥0)
0
(otherwise)
.
(5.24)
For general cases other than eq.(5.23), δ(t −K(w))ϕ(w) can be treated by
using this case. See Remark 33.
Let us show that the asymptotic bahavior of the state density function
is determined by the real log canonical threshold and its multiplicity deter-
mined by the multi-indexes k and h by the following deﬁnition.

5.2. STATE DENSITY FUNCTION
147
Deﬁnition 17. (Real log canonical threshold and its multiplicity) Let k > 0
and h ≥0 be d dimensional multi-indexes. Without loss of generality, we
can assume that
nhi + 1
2ki
; i = 1, 2, ..., d
o
is a nondecreasing sequence of i, where, if ki = 0, we deﬁne
hi + 1
2ki
= +∞.
Then by deﬁnition, there exist a positive real value λ > 0 and a positive
integer m (1 ≤m ≤d) such that
λ = h1 + 1
2k1
= h2 + 1
2k2
= · · · = hm + 1
2km
and
λ < hj + 1
2kj
(m + 1 ≤j ≤d).
Then the constants λ and m constitute a real log canonical threshold and
its multiplicity. The redundant multi-index µ = (µm+1, ..., µd) ∈Rd−m is
deﬁned by
µj = −2λkj + hj
(j = m + 1, ..., d).
(5.25)
By the deﬁnition, µj > −1. If m = d, then µ is the empty set.
Example 33. For the case
k
=
(3, 1, 4, 1, 2, 0, 0),
h
=
(2, 0, 3, 1, 5, 0, 1),
elements of the set {(hi + 1)/(2ki)} are given by
2 + 1
6
, 0 + 1
2
, 3 + 1
8
, 1 + 1
2
, 5 + 1
4
, 0 + 1
0
, 1 + 1
0
,
which is a nondecreasing sequence. Therefore λ = 1/2 and m = 3, resulting
that
(µ4, µ5, µ6, µ7) = (0, 3, 0, 1).
Deﬁnition 18. Let k > 0 and h ≥0 be arbitrary multi-indexes. Let λ and
m be the real log canonical threshold and its multiplicity, respectively. The
constant C(k, m) is deﬁned by
C(k, m)
=
2m(m −1)!
m
Y
j=1
kj.
(5.26)

148
CHAPTER 5. STANDARD POSTERIOR DISTRIBUTION
We use a notation,
w = (wα, wβ),
where
wα
=
(w1, w2, ..., wm),
wβ
=
(wm+1, wm+2, ..., wd).
Then a function f(w) is rewritten as f(w) = f(wα, wβ). A function (hyper-
function or distribution) D(w) is deﬁned by
D(w) =
1
C(k, m) δ(wα) |wµ
β| b(w)χ(w),
(5.27)
where µ is the redundant multi-index deﬁned by eq.(5.25) and δ(wα) is
deﬁned by
δ(wα) =
m
Y
j=1
δ(wj).
If a function ψ(wj) is not continuous at wj = 0, then
Z
δ(wj)ψ(wj)dwj
is not deﬁned. In such a case, we adopt a generalized delta function
Z
δ(wj)ψ(wj)dwj = lim
ǫ→+0 ψ(ǫ),
in the deﬁnition of D(w).
Example 34. For k and m in Example 33, the constant C(k, m) is
C(k, m) = 23(3 −1)! 3 · 1 · 4 = 192.
By m = 3,
wα
=
(w1, w2, w3),
wβ
=
(w4, w5, w6, w7).
Then a function f(w) is rewritten as f(w) = f(wα, wβ). A function (hyper-
function or distribution) D(w) is given by
D(w) =
1
192 δ(w1)δ(w2)δ(w3)|(w4)0(w5)3(w6)0(w7)1|b(w)χ(w).
Since µj > −1,
R
W D(w)dw is a ﬁnite value if W is compact.

5.2. STATE DENSITY FUNCTION
149
Theorem 9. Assume that a pair of a statistical model and a prior is a
standard form and that λ and m are the real log canonical threshold and its
multiplicity. Then the following asymptotic expansion holds for t →+0,
δ(t −w2k)|wh|b(w)χ(w)
=
tλ−1(−log t)m−1D(w)
+o(tλ−1(−log t)m−1),
(5.28)
where χ(w) and D(w) are deﬁned in eq.(5.24) and (5.27) respectively.
Proof. For an arbitrary C∞-class function ψ(w), we deﬁne
v(t) =
Z
W
δ(t −w2k)|wh|b(w)χ(w)ψ(w)dw.
The Mellin transform of v(t) is deﬁned by
(Mv)(z) =
Z ∞
0
v(t)tzdt,
where z ∈C. Then by the deﬁnition,
(Mv)(z) =
Z
W
w2kz|wh|b(w)χ(w)ψ(w)dw.
Since W is compact, there exists D > 0 such that
(Mv)(z) =
Z
[0,D]d w2kz|wh|b(w)ψ(w)dw.
By the mean value theorem, there exists w∗such that |w∗| ≤|w| and
b(w)ψ(w) = b(0, wβ)ψ(0, wβ) +
m
X
j=1
wj(∂/∂wj)(b(w∗)ψ(w∗)).
(5.29)
A complex function of z ∈C deﬁned by
Z
[0,D]m w2kz
α |wh
α|dwα
=
m
Y
j=1
D2kjz+hj+1
2kjz + hj + 1
=
1
(z + λ)m
m
Y
j=1
1 + (D2kj(z+λ) −1)
2kj

150
CHAPTER 5. STANDARD POSTERIOR DISTRIBUTION
has a pole at z = −λ with the order m. Therefore by using eq.(5.29),
(Mv)(z)
=
1
(z + λ)m
 m
Y
j=1
1
2kj
 Z
[0,D]d−m wµ
βb(0, wβ)ψ(0, wβ)dwβ
+O

1
(z + λ)m−1

.
Note that the integration of the ﬁrst term in the right hand side is ﬁnite
because the redundant index satisﬁes µj > −1. Then by using the inverse
Mellin transform shown in Remark 30,
v(t)
=
tλ−1(−log t)m−1
(m −1)!
 m
Y
j=1
1
2kj
 Z
[0,D]d−m wµ
βb(0, wβ)ψ(0, wβ)dwβ
+O

tλ−1(−log t)m−2
,
which completes Theorem 9.
Remark 30. The Mellin transform of
y(t) =
 tλ−1(−log t)m−1
(0 < t < 1)
0
(otherwise)
is given by
(My)(z) = (m −1)!
(z + λ)m ,
which can be derived by the recursive partial integration.
Remark 31. Theorem 9 shows the following fact. The state density function
δ(t −w2k)|wh| is not a well-deﬁned hyperfunction when t →+0. However,
it is asymptotically given by the well-deﬁned hyperfunction D(w),
δ(t −w2k)|wh|b(w)χ(w) ∼= tλ−1(−log t)m−1D(w),
and its asymptotic behavior as a function of t is determined by the real log
canonical threshold λ and its multiplicity m.
Example 35. Let us study a state density function
δ(t −x6)|x|2b(x)χ(x),
where b(x) > 0. This case corresponds to k = 3 and h = 2 in the above
theorem. Hence λ = (h + 1)/(2k) = 1/2 and m = 1. The redundant index
is empty.
C(k, m) = 2m(m −1)!k = 6.

5.2. STATE DENSITY FUNCTION
151
By Theorem 9, as t →+0,
δ(t −x6)|x2|b(x)χ(x) = t−1/2
6
δ(x)b(0) + o(t−1/2).
Example 36. Let us study a state density function on
δ(t −x4y6z8)|x1y2z6|b(x, y, z)χ(x, y, z),
where b(x, y, z) > 0. The multi-indexes are k = (2, 3, 4) and h = (1, 2, 6),
hence
λ = min
n1 + 1
4
, 2 + 1
6
, 6 + 1
8
o
,
which shows λ = 1/2 and m = 2, resulting that
C(k, m) = 2m(m −1)!k1 · k2 = 22 · (2 −1) · 2 · 3 = 24.
The redundant multi-index is µ3 = −2 · (1/2) · 4 + 6 = 2. By Theorem 9, as
t →0,
δ(t −x4y6z8)|x1y2z6|b(x, y, z)χ(x, y, z)
∼= 1
24t−1/2(−log t) δ(x)δ(y)z2b(0, 0, z).
Remark 32. Let K(w) and ϕ(w) be an average log density ratio function
and a prior, respectively. The zeta function is deﬁned by
ζ(z) =
Z
K(w)zϕ(w)dw
(z ∈C),
which is equal to the Mellin transform of the state density function. Then
K(w) is an analytic function on Re(z) > 0, which can be analytically contin-
ued to a meromorphic function whose poles are all real and negative values.
Let the largest pole of ζ(z) be (−λ) and its order be m. Then λ and m are
equal to the real log canonical threshold and its multiplicity, respectively.
Remark 33. In the above deﬁnitions, it is assumed that W is contained in
[0, D]d for some D > 0. For the other cases, we can use the same procedures.
Let σ = (σ1, σ2, ..., σd), where σi = 1 or σi = −1. The set of all such variables
is denoted by Σd. For σ ∈Σd, We deﬁne
σw = (σ1w1, σ2w2, ..., σdwd).
Note that for an arbitrary σ, σ2w = w and |σwk| = |wk|. Also we deﬁne a
set of parameters σ(S) by
σ(S) = {σw ; w ∈S}.

152
CHAPTER 5. STANDARD POSTERIOR DISTRIBUTION
If W ⊂σ([0, D]d), we deﬁne a generalized version of D(w) by
Dσ(w) =
1
C(k, m) δ(σwα) |wµ
β| b(w)χ(σw).
(5.30)
Then
δ(t −w2k)|wh|b(w)χ(σw)
=
δ(t −(σw)2k)|(σw)h|b(w)χ(σw)
=
tλ−1(−log t)m−1Dσ(w) + o(tλ−1(−log t)m−1).
Therefore, the asymptotic form of the state density function for the case
σW ⊂[0, D]d results in Theorem 9. If W ⊂[−D, D]d, the state density
function is the sum of the
δ(t −w2k)|wh|b(w)
=
X
σ∈Σd
δ(t −w2k)|wh|b(w)χ(σw)
= tλ−1(−log t)m−1 X
σ∈Σd
Dσ(w)

+ o(tλ−1(−log t)m−1).
By applying Theorem 9, the state density function is represented by the sum
of σ ∈Σd. Note that
wk δ(t −w2k)|wh|b(w)χ(σw)
= (σk) tλ−1/2(−log t)m−1Dσ(w) + o(tλ−1/2(−log t)m−1).
5.3
Asymptotic Free Energy
In this section, we study the asymptotic behavior of the free energy or the
minus log marginal likelihood. The normalized posterior function Ω(w) is
deﬁned by
Ω(w)
=
ϕ(w)
n
Y
i=1
p(Xi|w)
n
Y
i=1
p(Xi|w0)
.
(5.31)
This function is in proportion to the posterior density as a function of the
parameter w. The posterior density is an exponential function of n, whereas
the normalized posterior function is in proportion to (log n)m−1/nλ, where λ
and m are the real log canonical threshold and its multiplicity respectively.

5.3. ASYMPTOTIC FREE ENERGY
153
Theorem 10. Assume that a pair of a statistical model and a prior has a
standard form and that λ and m are the real log canonical threshold and its
multiplicity, respectively. If the set of parameters W is contained in [0, D]d,
then
Ω(w)
=
(log n)m−1
nλ
D(w)
Z ∞
0
dt tλ−1 exp(−t +
√
t ξn(w))
+op
(log n)m−1
nλ

,
(5.32)
where ξn(w) and D(w) are functions deﬁned by eqs.
(5.17) and (5.27),
respectively.
Proof. If w ∈W ⊂[0, D]d, by using eq.(5.22),
Ω(w)
=
exp(−nKn(w))ϕ(w)
=
exp(−nw2k + √nwkξn(w))|wh|b(w)
=
Z ∞
0
δ(t −w2k)|wh| exp(−nt +
√
nt ξn(w))b(w)dt.
By replacing t := t/n and by Theorem 9, it follows that
Ω(w)
=
Z ∞
0
dt
n δ
 t
n −w2k
|wh| exp(−t +
√
t ξn(w)) b(w)
=
Z ∞
0
dt
n
 t
n
λ−1
log
n
t
m−1
D(w) exp(−t +
√
t ξn(w))
+op((log n)m−1/nλ).
Since

log
n
t
m−1
= (log n)m−1 + O((log n)m−2),
we obtain Theorem 10.
Theorem 11. Assume the same condition as in Theorem 10. Then the free
energy or the minus log marginal likelihood
Fn = −log
Z
ϕ(w)
n
Y
i=1
p(Xi|w)dw
has the asymptotic expansion
Fn
=
nLn(w0) + λ log n −(m −1) log log n
−log
Z
dwD(w)
Z ∞
0
dt tλ−1 exp(−t +
√
t ξn(w))

+ op(1),

154
CHAPTER 5. STANDARD POSTERIOR DISTRIBUTION
where
Ln(w0) = −1
n
n
X
i=1
log p(Xi|w0).
Proof. By the deﬁnition of Ω(w) in eq.(5.31),
Fn
=
−log
Z
Ω(w)
n
Y
i=1
p(Xi|w0)dw

=
nLn(w0) −log
Z
Ω(w)dw

.
Combining this equation and Theorem 10 completes the theorem.
Remark 34. If W is contained in [−D, D]d, then by Remark 33,
δ(t −w2k)|wh|b(w)
= tλ−1(−log t)m−1 X
σ∈Σd
Dσ(w)

+ o(tλ−1(−log t)m−1).
Therefore,
Fn = nLn(w0) + λ log n −(m −1) log log n
−log
 X
σ∈Σd
Z
dwDσ(w)
Z ∞
0
dt tλ−1 exp(−t +
√
t σk ξn(w))

+ op(1).
In other words, the main order terms are same as in Theorem 11, whereas
the constant order term is diﬀerent.
Example 37. For a triple of a statistical model, a true distribution, and
a prior given in Example 27, λ = 1 and m = 2.
A numerical result of
Fn −nLn(w0) is shown in Figure 5.4. In general, λ and m depend on a
true distribution, hence the Theorem 11 cannot be employed if we do not
know the true distribution. However, by using the mathematical property
of Fn, we can derive the information criterion WBIC by which Fn can be
estimated without information of the true distribution (Chapter 8).
5.4
Renormalized Posterior Distribution
In this section, we derive the asymptotic behaviors of the generalization,
training, and cross validation losses and WAIC. By using Ω(w) in eq.(5.31),

5.4. RENORMALIZED POSTERIOR DISTRIBUTION
155
the posterior expected value of an arbitrary function y(w) is rewritten as
Ew[y(w)] =
Z
y(w)Ω(w)dw
Z
Ω(w)dw
.
(5.33)
This is the deﬁnition of the posterior average. However, the behavior for n →
∞cannot be derived directly from this deﬁnition. By using the standard
form, the posterior distribution can be represented by a product of a function
of n and the ﬂuctuation function. The renormalized posterior distribution
is neceswary for the ﬂuctuation part.
Deﬁnition 19. (Renormalized posterior distribution) Assume the same
condition as Theorem 10. For an arbitrary function z(t, w), the renormalized
posterior distribution is deﬁned by
⟨z(t, w)⟩=
Z
dwD(w)
Z ∞
0
dt z(t, w) tλ−1 exp(−t +
√
t ξn(w))
Z
dwD(w)
Z ∞
0
dt tλ−1 exp(−t +
√
t ξn(w))
.
(5.34)
For a given function f(w), the expectation operator ⟨f(w)⟩depends on
ξn(w). If the function ξn(w) must be explicitly represented, a notation
⟨f(w)⟩= ⟨f(w)⟩ξn
(5.35)
is used. Note that ⟨f(w)⟩is a random variable.
Remark 35. By using notation w = (wα, wβ) in Deﬁnition 18,
D(w) = D(wa, wb) ∝δ(wa)wµ
b ,
the posterior average can be rewritten as
⟨z(t, w)⟩=
Z
dwβ wµ
β
Z ∞
0
dt z(t, 0, wβ) tλ−1 e−t+
√
t ξn(0,wβ)
Z
dwβ wµ
β
Z ∞
0
dt tλ−1 e−t+
√
t ξn(0,wβ)
.
(5.36)
Hence, the renormalized posterior distribution does not depend on the set
of values {z(t, wα, wβ); |wα| > 0}. The set {(0, wβ)} is contained in the set
of the optimal parameters W0. In other words, the renormalized posterior
distribution is the probability distribution on W0.

156
CHAPTER 5. STANDARD POSTERIOR DISTRIBUTION
Remark 36. The renormalized posterior distribution is deﬁned for the case
when W ⊂[0, D]d for some D > 0. For general cases in Remark 33 it is
deﬁned by replacing
Z
dw D(w) 7→
X
σ∈Σd
Z
dwDσ(w).
The same theorems and lemmas hereafter hold.
Theorem 12. The renormalized posterior distribution satisﬁes
⟨t⟩= λ + 1
2⟨
√
t ξn(w)⟩.
(5.37)
Proof. By the deﬁnition,
⟨t⟩=
Z
dwD(w)
Z ∞
0
dt tλ e−t+
√
t ξn(u)
Z
dwD(w)
Z ∞
0
dt tλ−1 e−t+
√
t ξn(u)
.
(5.38)
By applying the partial integration over t and using λ > 0,
Z ∞
0
e−ttλe
√
tξn(w)dt
= −
h
e−ttλe
√
tξn(w)i∞
0 +
Z ∞
0
e−t d
dt(tλe
√
tξn(w))dt
= λ
Z ∞
0
e−ttλ−1e
√
tξn(w)dt
+
Z ∞
0
e−ttλe
√
tξn(w)ξn(w)/(2
√
t)dt.
By applying this equation to eq.(5.38), we obtain Theorem 12.
There are asymptotic relations between the posterior distribution and
the renormalized one, by which the behaviors of the log density ratio function
and its average
f(x, w)
=
log p(x|w0)
p(x|w) = wka(x, w),
(5.39)
K(w)
=
Z
f(x, w)q(x)dx,
(5.40)
are clariﬁed.

5.4. RENORMALIZED POSTERIOR DISTRIBUTION
157
Theorem 13. (Scaling law) Assume the same condition as used in The-
orem 10. For an arbitrary positive integer s,
Ew[f(x, w)s]
=
1
ns/2 ⟨(
√
t a(x, w))s ⟩+ op( 1
ns/2 ),
(5.41)
Ew[K(w)s]
=
1
ns⟨ts ⟩+ op( 1
ns ).
(5.42)
Proof. Let us prove the ﬁrst half. The latter half can be proved in the same
way.
Ew[f(x, w)s] =
Z
wska(x, w)sΩ(w)dw
Z
Ω(w)dw
.
Let N(s) be the numerator of this equation.
Then N(0) is equal to the
denominator and
N(s) =
Z
dw wska(x, w)s exp(−nw2k + √nwkξn(w))whb(w)
=
Z ∞
0
dt
Z
dw ts/2a(x, w)sb(w)δ(t −nw2k)wh exp(−t +
√
tξn(w))
= (log n)m−1
nλ+s/2
Z ∞
0
dt
Z
dwD(w)a(x, w)stλ+s/2−1 exp(−t +
√
t ξn(w))
+op
(log n)m−1
nλ+s/2

,
where we used eq.(5.32) in Theorem 10. Therefore N(s)/N(0) satisﬁes the
ﬁrst half.
Remark 37. Let ℓ≥2. Assume that a statistical model and a prior have
the standard form. Then we can prove
sup
|α|≤1

 d
dα
ℓ
Gn(α)

=
Op( 1
nℓ/2 )
sup
|α|≤1

 d
dα
ℓ
Tn(α)

=
Op( 1
nℓ/2 )
in the same way as we proved Theorem 5. In fact,
f(x, w) = wka(x, w).

158
CHAPTER 5. STANDARD POSTERIOR DISTRIBUTION
Hence
|f(x, w)| ≤|wk||a(x, w)|.
By using Lemma 8,

 d
dα
ℓ
Gn(α)

≤
ckEX
hEw[|f(X, w)|ℓexp(−αf(X, w))]
Ew[exp(−αf(X, w))]
i
=
ckEX
h
{sup
w |a(X, w)|}Ew[|wk|ℓexp(−αf(X, w))]
Ew[exp(−αf(X, w))]
i
=
Op(1/nℓ/2).
In the same way,

 d
dα
ℓ
Tn(α)

≤
ck
1
n
n
X
i=1
Ew[|f(Xi, w)|ℓexp(−αf(Xi, w))]
Ew[exp(−αf(Xi, w))]
=
Op(1/nℓ/2).
Therefore, we can apply the basic Theorem 3 also to this case.
Deﬁnition 20. By using the renormalized posterior distribution, the ﬂuc-
tuation of the renormalized posterior distribution Fluc(ξn) is deﬁned by
Fluc(ξn)
=
EX[⟨ta(X, w)2⟩−⟨
√
ta(X, w)⟩2].
Here Fluc(ξn) is a functional of ξn, because the expected value using the
renormalized posterior distribution ⟨⟩depends on ξn.
Theorem 14. Assume the same condition as in Theorem 10. Then
Gn
=
L(w0) + 1
n

λ + 1
2⟨
√
tξn(w)⟩−1
2Fluc(ξn)

+ op( 1
n),
(5.43)
Tn
=
Ln(w0) + 1
n

λ −1
2⟨
√
tξn(w)⟩−1
2Fluc(ξn)

+ op( 1
n), (5.44)
Cn
=
Ln(w0) + 1
n

λ −1
2⟨
√
tξn(w)⟩+ 1
2Fluc(ξn)

+ op( 1
n), (5.45)
Wn
=
Ln(w0) + 1
n

λ −1
2⟨
√
tξn(w)⟩+ 1
2Fluc(ξn)

+ op( 1
n), (5.46)
Proof. By the Theorem 3 and the above lemma, the generalization, cross val-
idation, and training losses are obtained by calculating G′
n(0), G′′
n(0), T ′
n(0),
and T ′′
n (0), by applying the scaling law. Using eq.(5.37),
G′
n(0)
=
L(w0) + Ew[K(w)]
=
L(w0) + 1
n⟨t⟩+ op(1/n)
=
L(w0) + 1
n

λ + 1
2⟨
√
tξn(w)⟩

+ op(1/n),

5.4. RENORMALIZED POSTERIOR DISTRIBUTION
159
and
G′′
n(0)
=
EX[Ew[f(X, w)2] −Ew[f(X, w)]2]
=
1
nEX[⟨ta(X, w)2⟩−⟨
√
ta(X, w)⟩2] + op(1/n)
=
1
nFluc(ξn) + op(1/n).
Hence we obtained eq.(5.43).
T ′
n(0)
=
Ln(w0) + Ew[Kn(w)]
=
Ln(w0) + 1
n⟨t −
√
tξn(w)⟩+ op(1/n)
=
Ln(w0) + 1
n

λ −⟨1
2
√
tξn(w)⟩

+ op(1/n),
and
T ′′
n (0)
=
1
n
n
X
i=1
n
Ew[f(Xi, w)2] −Ew[f(Xi, w)]2o
=
1
n2
n
X
i=1
n
⟨ta(Xi, w)2⟩−⟨
√
ta(Xi, w)⟩2o
+ op(1/n).
By using the law of large numbers for a functional case,
sup
w,v
 1
n
n
X
i=1
a(Xi, w)a(Xi, v) −EX[a(X, w)a(X, v)]
 = op(1),
the diﬀerence between nG′′
n(0) and nT ′′
n (0) goes to zero in probability when
n →∞. Thus eq.(5.44) is obtained.
Remark 38. The standard deviations of Tn, Cn, and Wn are Op(1/√n),
because the standard deviation of Ln(w0) is Op(1/√n). The averages and
standard deviations of the four random variables Gn −L(w0), Tn −Ln(w0),
Cn −Ln(w0), and Wn −Ln(w0) are Op(1/n). They are asymptotically given
by the linear combination of two random variables ⟨
√
tξn(w)⟩and Fluc(ξn).
It should be emphasized that Theorem 14 holds even if the true distribution
is not realizable by and singular for a statistical model.
Remark 39. By Theorem 14, the convergences in probability hold,
n(Gn −L(w0)) + n(Cn −Ln(w0)) →2λ,
n(Gn −L(w0)) + n(Wn −Ln(w0)) →2λ,

160
CHAPTER 5. STANDARD POSTERIOR DISTRIBUTION
where λ is the real log canonical threshold.
That is to say, for a given
triple (q(x), p(x|w), ϕ(w)), if (Cn −Ln(w0)) is smaller then (Gn −Ln(w0)) is
larger. Wn has the same property as Cn. This is the generalized version of
Remark 25 in regular theory. These properties are very important when we
employ the cross validation loss and WAIC in statistical model selection and
hyperparameter optimization. If a sample consists of independent random
variables, then it automatically follows that E[Cn] = E[Gn−1] by the deﬁni-
tion of the cross validation loss. However in order to derive the variance of
the cross validation error Cn −Ln(w0), we need mathematical theory.
Lemma 22. Let ξ(w) be the Gaussian process which is uniquely character-
ized by eq.(5.20) and eq.(5.21). Then
Eξ[⟨
√
tξ(w)⟩] = Eξ[Fluc(ξ)].
Proof. Since E[Gn−1] = E[Cn], by the above theorem,
Eξn[⟨
√
tξn(w)⟩] = Eξn[Fluc(ξn)] + o(1).
As n →∞, ξn(u) →ξ(u) in distribution, which completes the lemma.
Remark 40. Lemma 22 is shown by the relation between expected values
of generalization and cross validation losses, based on the assumption that
X1, X2, ..., Xn are independent. However, the condition of independent ran-
dom variables is not necessary for Lemma 22. In fact, it holds in some cases
when X1, X2, ..., Xn are not independent. See the next section.
Deﬁnition 21. The constant
2ν = Eξ[⟨
√
tξ(w)⟩] = Eξ[Fluc(ξ)]
is called the singular ﬂuctuation.
Theorem 15. Let λ and ν be the real log canonical threshold and the sin-
gular ﬂuctuation.
Then the averages of the generalization loss, the cross
validation loss, the training loss, and WAIC are asymptotically given by
E[Gn]
=
L(w0) + λ
n + o( 1
n),
(5.47)
E[Tn]
=
L(w0) + 1
n(λ −2ν) + o( 1
n),
(5.48)
E[Cn]
=
L(w0) + λ
n + o( 1
n),
(5.49)
E[Wn]
=
L(w0) + λ
n + o( 1
n).
(5.50)

5.4. RENORMALIZED POSTERIOR DISTRIBUTION
161
Proof. By Theorem 14 and Lemma 22, we obtain Theorem 15.
Deﬁnition 22. The functional variance is deﬁned by
Vn = 1
n
n
X
i=1
n
Ew[(log p(Xi|w)2] −Ew[log p(Xi|w)]2o
.
Lemma 23. When n →∞, nE[Vn] →2ν.
Proof. Since log p(Xi|w0) is a constant function of a parameter w, the ran-
dom variable Vn can be represented by
Vn = 1
n
n
X
i=1
n
Ew[f(Xi, w)2] −Ew[f(Xi, w)]2o
.
The asymptotic equivalence of Vn and Fluc(ξn) was shown in the part T ′′
n (0)
in Theorem 14.
Theorem 16. iEquations of states in Bayesian statisticsj Assume that
a statistical model has a standard form.
E[Gn]
=
E
h
Cn
i
+ o( 1
n)
(5.51)
E[Gn]
=
E
h
Wn
i
+ o( 1
n).
(5.52)
These equations hold even if a true distribution is singular for or unrealizable
by a statistical model.
Proof. This theorem is immediately derived from Theorem 15.
Remark 41. If the true distribution is regular for a statistical model, then
the higher order equivalence can be derived. See Chapter 8.
Remark 42. Both Cn and Wn are estimators of Gn. In typical statistical
inferences, the diﬀerence of them is very small. If X1, X2, ..., Xn are indepen-
dent, then both eq.(5.51) and eq.(5.52) hold. If X1, X2, ..., Xn are dependent,
then it is not ensured that eq.(5.51) hold. Under some conditions such as
conditonal independence, eq.(5.52) holds. Therefore, even if X1, X2, ..., Xn
are dependent, if eq.(5.52) holds and Cn is asymptotically equivalent to Wn,
then also eq.(5.51) holds. See the next section.

162
CHAPTER 5. STANDARD POSTERIOR DISTRIBUTION
5.5
Conditionally Independent Case
In this book, we mainly study a case when a sample Xn consists of random
variables which are independently subject to the same probability distribu-
tion. However, there are several important cases when such an assumption
does not hold. In this section, we study a conditionally independent case. In
this situation, the diﬀerences between the cross validation and information
criteria are clariﬁed.
In this section, we study a case when
xn = (x1, x2, ..., xn)
is ﬁxed or may be dependent. The random variables Y n = (Y1, Y2, ..., Yn)
are independently subject to a true conditional distribution
n
Y
i=1
q(yi|xi).
Then (Y1, Y2, ..., Yn) are independent, but ((x1, Y1), (x2, Y2), ..., (xn, Yn)) are
dependent.
Remark 43. The conditionally independent condition allows the following
cases.
1. The set (x1, x2, ..., xn) consists of ﬁxed points.
2. The set (x1, x2, ..., xn) is a time sequence.
3. The set (x1, x2, ..., xn) is not independent.
Note that, in such cases, prediction and estimation are diﬀerent from each
other. In general, prediction for a new point xn+1 has no meaning, whereas
the estimation of q(y|xi) using p(y|xi, w) is well-deﬁned.
We deﬁne a statistical model and a prior by
p(yi|xi, w),
ϕ(w).
For a given sample (xn, Y n), a posterior density is deﬁned by
p(w|xn, Y n) = 1
Zn
ϕ(w)
n
Y
i=1
p(Yi|xi, w),

5.5. CONDITIONALLY INDEPENDENT CASE
163
where Zn is a partition function or the marginal likelihood,
Zn =
Z
ϕ(w)
n
Y
i=1
p(Yi|xi, w)dw,
which can be understood as the estimated probability density function of
Y n. Also we deﬁne a Bayesian estimation of the conditional distribution by
p(y|xi, xn, Y n) = Ew[p(y|xi, w)].
This predictive distribution is not a prediction for a new point but an esti-
mation of Y at the trained point xi. A prediction for a new point x can be
deﬁned by the same equation,
p(y|x, xn, Y n) = Ew[p(y|x, w)],
however, its generalization loss cannot be deﬁned because there does not
exist a probability distribution of x. The generalization loss, the cross vali-
dation loss, the training loss, and WAIC are deﬁned by
Gn
=
−1
n
n
X
i=1
Z
q(y|xi) log p(y|xi, xn, Y n)dy,
Tn
=
−1
n
n
X
i=1
log p(Yi|xi, xn, Y n),
Cn
=
−1
n
n
X
i=1
log p(Yi|xi, xn \ xi, Y n \ Yi),
Wn
=
Tn + 1
n
n
X
i=1
Vw[log p(Yi|xi, w)].
Also in this case we can construct Bayesian theory for both regular and
standard cases. For example, eq.(3.20), eq.(3.21), and eq.(3.23) in Theo-
rem 3 hold, resulting that eq.(5.43), eq(5.44), and eq.(5.46) in Theorem 14
hold. However, there are several diﬀerent points from the independent case.
Because xn is not subject to the same probability distribution, the average
generalization loss is not equal to the cross validation loss,
E[Gn−1] ̸= E[Cn].
In other words, if xn is dependent, then we lost the relation between the
generalization loss and the cross validation loss. Moreover, the asymptotic

164
CHAPTER 5. STANDARD POSTERIOR DISTRIBUTION
expansion of Cn in eq.(3.22) in Theorem 3 does not hold in general,
Cn = Tn(−1) ̸= −T ′
n(0) + 1
2T ′′
n (0) + op( 1
n).
Consequently, eq.(5.45) in Theorem 14 does not hold.
Cn ̸= Ln(w0) + 1
n

λ −1
2⟨
√
tξn(w)⟩+ 1
2Fluc(ξn)

+ op( 1
n).
Remark 44. (Numerical problem of importance samping cross validation)
In conditionally independent cases, the cross validation loss has the other
problem. Even in a conditionally independent case, the cross validaiton loss
Cn satisﬁes
Cn = 1
n
n
X
i=1
log Ew[1/p(Yi|xi, w)],
which can be numerically calculated by using posterior parameters, hence
it is called the importance sampling cross validation. However, if a leverage
sample point (xi, Yi) is contained, in other words, if p(Yi|xi, w) is very small
for a posterior parameter w, then the posterior average Ew[1/p(Yi|xi, w)]
diverges. Therefore eq.(3.22) in Theorem 3 does not hold in general.
Since E[Gn−1] ̸= E[Cn], Lemma 22 cannot be derived via the cross val-
idation loss.
However, we can prove the following Lemma 24, by which
eq.(5.47), eq.(5.48), and eq.(5.49) in Theorem 15 and eq.(5.52) in Theorem
16 hold. However, neither eq.(5.49) in Theorem 15 nor eq.(5.51) in Theorem
16 holds. In other words, the cross validation loss cannot be employed in
conditionally independent cases whereas WAIC can be.
Let us show theoretical strcutures of the conditionally independent cases.
Let W0 be the set of parameters which minimize
L(w) = −1
n
n
X
i=1
Z
q(y|xi) log p(y|xi, w)dy,
and w0 be a parameter contained in W0. Two functions f(xi, y, w) and K(w)
are deﬁned by
f(xi, y, w)
=
log p(y|xi, w0)
p(y|xi, w) ,
K(w)
=
1
n
n
X
i=1
Z
q(y|xi)f(xi, y, w)dy.

5.5. CONDITIONALLY INDEPENDENT CASE
165
If a set of a statistical model and a prior is a standard form, there exist
a(xi, y, w) and b(w) such that
f(xi, y, w)
=
wka(xi, y, w),
K(w)
=
w2k,
ϕ(w)
=
|wh| b(w),
where both k > 0 and h ≥0 are multi-indexes and b(w) > 0 in a neighbor-
hood of the origin. A stochastic process ξn(w) is deﬁned by
ξn(w) =
1
√n
n
X
i=1
{wk −a(xi, Yi, w)}.
Note that ξn(w) is an empirical process composed of dependent random
variables in general. It follows that
E[ξn(w)]
=
0,
E[ξn(w)ξn(u)]
=
1
n
n
X
i=1
EY [a(xi, Y, w)a(xi, Y, u)] −wkuk.
A Gaussian process ξ(w) which satisﬁes the following conditions is uniquely
determined.
Eξ[ξ(w)]
=
0,
Eξ[ξ(w)ξ(u)]
=
1
n
n
X
i=1
EY [a(xi, Y, w)a(xi, Y, u)] −wkuk.
Then ⟨
√
tξn(w)⟩, ⟨
√
tξ(w)⟩, Fluc(ξn), and Fluc(ξ) are deﬁned in the same
way. We can derive the following lemma without using the cross validation
loss.
Lemma 24. The same statement as Lemma 22 holds,
Eξ[⟨
√
tξ(w)⟩] = Eξ[Fluc(ξ)].
Proof. In this proof we use a notation Eξ[ ] = E[ ]. Let us use a decompo-
sition of the Gaussian process,
ξ(w) =
∞
X
j=1
gjξj(w),

166
CHAPTER 5. STANDARD POSTERIOR DISTRIBUTION
where {gj} is a set of random variables which are independently subject to
the standard normal distribution N(0, 1). If K(g(w)) = 0 then wk = 0 and
E[ξ(w)ξ(v)] = 1
n
n
X
i=1
EY [a(xi, Y, w)a(xi, Y, u)] =
∞
X
j=1
ξj(w)ξj(v).
(5.53)
A Gaussian process satisﬁes
E[gjF(gj)] = E
h ∂
∂gj
F(gj)
i
for an arbitrary integrable function F( ). Let S be the integration operator
deﬁned by
S[ ] =
Z
dwD(w)
Z ∞
0
dt tλ−1 exp(−t)[ ].
Then
E[⟨
√
tξ(w)⟩] = E
hS[
√
tξ exp(
√
tξ)]
S[exp(
√
tξ)]
i
=
∞
X
j=1
E
h ∂
∂gj
S[
√
tξj exp(
√
tξ)]
S[exp(
√
tξ)]
i
=
∞
X
j=1
n
E
hS[tξ2
j exp(
√
tξ)]
S[exp(
√
tξ)]
i
−E
hS[
√
tξj exp(
√
tξ)]
S[exp(
√
tξ)]
i2o
.
The last equation is equal to Fluct(ξ), which completes the lemma.
Remark 45. For a ﬁnite n, if the convergence in distribution ξn(w) →ξ(w)
holds, then
Eξn[⟨
√
tξn(w)⟩] = Eξn[Fluc(ξn)] + o(1).
Therefore, the above equation also holds asymptotically.
In the proof of
Lemma 24, the partial integration over the functional space is eﬀectively
employed. Therefore, we understand that in independent cases, the cross
validation is mathematically equivalent to the partial integration over the
functional space.
Example 38. Let us illustrate an example in which the convergence ξn(w) →
ξ(w) holds in a conditionally independent case. Let y ∈R, x ∈RN, and
w ∈Rd. We study a case when a statistical model p(y|x, w) is given by
p(y|x, w, s)
=
r s
2π exp(−(s/2)(y −F(x, w))2),

5.5. CONDITIONALLY INDEPENDENT CASE
167
where F(x, w) is a function from RN × Rd to R. Assume that xn is a set of
ﬁxed points and Y n is taken from p(y|xi, w0, s0) for some true w0 and s0.
Then
f(xi, y, w, s)
=
(s/2)(y −F(xi, w))2 + (1/2) log s
−(s0/2)(y −F(xi, w0))2 + (1/2) log s0,
and
K(w, s)
=
1
n
n
X
i=1
Z
p(y|xi, w0, s0)f(xi, y, w, s)dy.
Hence if a statistical model is a standard form,
wkξn(w, s)
=
s0 −s
2√n
n
X
i=1
{(Yi −F(xi, w0))2 −1/s}
+ s
√n
n
X
i=1
(Yi −F(xi, w))(F(xi, w) −F(xi, w0)),
which converges to a Gaussian process as n →∞, because {Yi −F(xi, w0)}
is a set of independent random variables which are subject to the same
probability distribution.
Example 39. (Inﬂuential observation) A statistical model and a prior are
deﬁned by
p(y|x, a, s)
=
r s
2π exp(−(s/2)(y −ax)2),
ϕ(a, s)
∝
s exp(−(s/2)(ρ + µa2)),
where hyperparameters are set as µ = ρ = 0.01.
The true conditional
density is deﬁned by q(y|x) = p(y|x, w0, s0), where w0 = 0.2 and s0 = 100.
The set of inputs is given by
xi
=
0.1i
(i = 1, 2, ..., n −1),
xn
=
R,
where n = 10 and Y n are independently taken from q(y|xi). The inputs
of data 0 < xi < 1 for i = 1, 2, .., n −1, whereas the last input xn is
a leverage sample point because it is set as R = 1, 2, 3, 4, 5.
Figure 5.2
shows the generalization, the cross validation, and WAIC errors for given R,

168
CHAPTER 5. STANDARD POSTERIOR DISTRIBUTION
1
2
3
4
5
-0.1
0
0.1
0.2
0.3
0.4
Place of the leverage sample
 
 
Generalization Error
CV Error
WAIC error
Figure 5.2: Inﬂuential observation.
The generalization, cross validation,
and WAIC errors are compared for the case when a leverage sample point
is contained.
The horizontal line shows the place of the leverage sample
point whereas other sample points are in the interval [0, 1]. If the leverage
sample point is far from others, then the variance of the cross validation
error becomes large.
respectively. Here the generalization error is measured not by the average of
any probability distribution but by the emprical average of xn. As the value
R is larger, the eﬀect of the leverage sample point becomes larger, resulting
that the average of the cross validation error becomes diﬀerent from that of
the generalization error, and the variance becomes larger.
Example 40. (High dimensional case) Let us study a statistical model of
y ∈R for a given x ∈Rd with a parameter (a, s) (a ∈Rd, s > 0),
p(y|x, a, s) =
r s
2π exp(−s
2(y −a · x)2)
and a prior
ϕ(a, s) ∝sr exp(−s
2(ρ + µ∥a∥2),

5.5. CONDITIONALLY INDEPENDENT CASE
169
where r = d/2 and ρ = 0.005, and µ = 0.005 are hyperparameters. In this
example, we studied cases when d = 20, or 50, and n = 100. A true density
was set as q(y|x) = p(y|x, a0, s0), where a0 = (0.5, 0.5, ..., 0.5) and s0 = 100.
Then the posterior density of (s, a) is given by
p(s|Xn, Y n)
∝
sn/2+r−d/2 exp(−Cs/2),
p(a|s, Xn, Y n)
=
Nd(B, A−1/s),
where Nd(b, S) is the d dimensional normal distribution whose average is b
and covariance matrix is S and
A
=
n
X
i=1
XiXT
i + µ,
B
=
A−1 n
X
i=1
XiYi,

C
=
−tr(ABBT ) +
n
X
i=1
Y 2
i + ρ.
Therefore by using the simple Monte Carlo method, we approximated the
generalization loss Gn, the cross validation loss Cn, and WAIC Wn.
(1) d = 20, n = 100. Firstly, let Xn consist of independent random variables
which are subject to the normal distribution Nd(0, I) where I is the identity
matrix. Then Gn is mesured by the average over this distribution. The
experimental averages and standard deviations for 1000 independent trials
were
Cn −Sn = 0.130, 0.034,
Wn −Sn = 0.123, 0.033,
Gn −S = 0.129, 0.030,
and the estimated errors were
E[ |Gn −S −(Cn −Sn)| ] = 0.0462,
E[ |Gn −S −(Wn −Sn)| ] = 0.0456.
(2) d = 20, n = 100. Secondly, Xn was generated from Nd(0, I) and then
ﬁxed, and Gn was deﬁned by empirical mean over the ﬁxed Xn. The exper-
imental averages and standard deviations of Cn −Sn and Wn −Sn for 1000
independent trials were same as (1), whereas those of Gn −S were
Gn −S = 0.108, 0.024

170
CHAPTER 5. STANDARD POSTERIOR DISTRIBUTION
and the estimated errors were
E[ |Gn −S −(Cn −Sn)| ] = 0.047,
E[ |Gn −S −(Wn −Sn)| ] = 0.044.
(3) d = 40, n = 100. The experimental averages and standard deviations
for 1000 independent trials were
Gn −S = 0.425, 0.030,
Cn −Sn = 0.428, 0.047,
Wn −Sn = 0.402, 0.047,
and the estimated errors were
E[ |Gn −S −(Cn −Sn)| ] = 0.056,
E[ |Gn −S −(Wn −Sn)| ] = 0.058.
(4) d = 40, n = 100. Secondly, Xn was generated from Nd(0, I) and then
ﬁxed. The experimental averages and standard deviations of Cn −Sn and
Wn −Sn for 1000 independent trials were same as (3), whereas those of
Gn −S were
Gn −S = 0.336, 0.021,
and the estimated errors were
E[ |Gn −S −(Cn −Sn)| ] = 0.098,
E[ |Gn −S −(Wn −Sn)| ] = 0.078.
If d/n is not so large, Wn−Sn is the better estimator of Gn−S than Cn−Sn,
for both indepedent and ﬁxed xn. If d/n is larger, then statistical estimation
is not accurate. If xn is independent, Cn −Sn is the better estimator of
Gn −S than Wn −Sn. If xn is ﬁxed, Wn −Sn is the better estimator of
Gn −S than Cn −Sn.
Our recommendation in practical problems is as
follows. If either the cross validation loss or WAIC can be calculated by the
Markov Chain Monte Carlo method, then the other can also be calculated
by almost the same computational time.
Therefore, we recommend that
both of them would be calculated and compared. If they are diﬀerent, xn
may be dependent or contains the leverage sample point.

5.6. PROBLEMS
171
Example 41. (Time sequence) In time series analysis, we sometimes use a
statistical model
Yi = aYi−1 + bYi−2 + cYi−3 + noise.
This model is represented by
p(Yi|Yi−1, Yi−2, Yi−3, a, b, c),
which is equivalent to
p(Yi|xi, a, b, c),
where
xi = (Yi−1, Yi−2, Yi−3) ∈R3.
The sample point xi depends on Yj (j ̸= i). However, this model is equiva-
lent to the model in which {Yi} are independent under the condition that xn
are given. If we adopt the assumption that a true probability distribution
satisﬁes the same conditional independence as the statistical model, WAIC
can be applied to evaluation of estimating accuracy at the set of empiri-
cal points xn. Moreover, if the cross validation loss has almost the same
value as WAIC, then the cross validation loss also can be employed as an
approximated value of WAIC.
5.6
Problems
1. Let k be a positive integer and λ = 1/k. Prove the following equations.
Z 1
0
exp(−nxk)dx
=
λ
nλ
Z n
0
exp(−y) yλ−1 dy

,
Z 1
0
δ(t −xk)dx
=
λ tλ−1,
Z 1
0
(xk)zdx
=
λ
z + λ,
where n > 0, 0 < t < 1, and Re(z) > −λ.
2. Let k be a positive integer and λ = 1/k. Assume that ϕ(x) is a C1 class

172
CHAPTER 5. STANDARD POSTERIOR DISTRIBUTION
function on (−ε, 1], where ε > 0. Then prove that
Z 1
0
exp(−nxk)ϕ(x)dx
=
λΓ(λ)
nλ
ϕ(0) + o(1/nλ),
Z 1
0
δ(t −xk)ϕ(x)dx
=
λ tλ−1ϕ(0) + o(tλ−1),
Z 1
0
(xk)zϕ(x)dx
=
λ
z + λϕ(0) + g(z),
as n →∞, t →+0, and g(z) is an analytic function on Re(z) > −λ which
can be analytically continued to an analytic function on Re(z) > −2λ.
3. Let f(x, y) and g(x, y) be polynomials of (x, y) which satisfy f(0, 0) = 0.
Let U be an open set which contains (0, 0) and U ∗= U \{(x, y); f(x, y) = 0}.
(1) Make an example of a set f(x, y) and g(x, y) which satisﬁes
sup
(x,y)∈U∗
 g(x, y)
f(x, y)
 < 1,
when g(x, y)/f(x, y) is not a polynomial.
(2) Assume that f(x, y) = x2y2. Prove that if
sup
(x,y)∈U∗
 g(x, y)
f(x, y)
 < 1,
then g(x, y)/f(x, y) is a polynomial.
Explain the mathematical diﬀerence between (1) and (2).
4. A neural network is deﬁned by a conditional density of x, y ∈R,
p(y|x, a, b) =
1
√
2π
exp(−1
2(y −a tanh(bx))2).
We study a case when a probability density of x is the uniform distribution
of [−2, 2]. A true conditional density is set as p(y|x, 0, 0), and the uniform
prior for (a, b) on [−1, 1] × [−1, 1] is adopted. Then the true distribution
is realizable by and singular for a statistical model. Figure 5.3 shows the
posterior distributions for six independent sets of (Xn, Y n), where n = 100.
Even if the true parameter (a0, b0) = (0.1, 0.1), the posterior distributions
have almost the same shapes as the case (a0, b0) = (0, 0). In statistical model
selection and hypothesis testing, we often have to determine (a0, b0) = (0, 0)

5.6. PROBLEMS
173
-1
0
1
-1
-0.5
0
0.5
1
-1
0
1
-1
-0.5
0
0.5
1
-1
0
1
-1
-0.5
0
0.5
1
-1
0
1
-1
-0.5
0
0.5
1
-1
0
1
-1
-0.5
0
0.5
1
-1
0
1
-1
-0.5
0
0.5
1
Figure 5.3: Fluctuation of posterior distribution in neural network. Pos-
terior distributions of six independent sets of Xn are shown for the case
n = 100. The set of the true parameters is {(a, b); ab = 0}.
or (a0, b0) ̸= (0, 0) based on a sample. Discuss whether we can apply regular
statistical theory to neural networks or not.
5. The statistical model, the true density, and the prior are set as in the
above neural network. Hence the posterior distribution cannot be approx-
imated by any normal distribution. Note that λ and m, which depend on
the true distribution, are λ = 1/2 and m = 2. Let (ˆa,ˆb) be the maximum a
posteriori estimator. Since the uniform prior of (a, b) on [−1, 1] × [−1, 1] is
adopted, it is equal to the maximum likelihood estimator in this case. The
log loss function is
Ln(a, b) = −1
n
n
X
i=1
log p(Yi|Xi, a, b).
The free energy Fn is equal to
Fn
=
−log
Z
n
Y
i=1
exp(−nLn(w))ϕ(a, b)dadb.

174
CHAPTER 5. STANDARD POSTERIOR DISTRIBUTION
0
50
100
150
200
250
-2
-1
0
1
2
3
4
5
6
n: sample size
 
 
Fn-n*Sn
BIC-n*Sn
BIC
rclt -n*Sn
WBIC-n*Sn
Figure 5.4: Free energy and its estimators in neural network. Free energy,
BIC, BIC using RLCT, and WBIC are compared in a simple neural network.
BIC is larger than the free energy. Both BIC using RLCT and WBIC can
approximate the free energy.
In general, it is diﬃcult to calculate the integration over the parameter set
in Fn. However, in this case, it can be approximiated by the Riemann sum
because the dimension of the parameter space is small (2). Its estimators,
BIC, BIC using RLCT, and WBIC are given by
BIC
=
nLn(ˆa,ˆb) + (d/2) log n,
BICrclt
=
nLn(ˆa,ˆb) + λ log n −(m −1) log log n,
WBIC
=
E(β)
(a,b)[nLn(a, b)],
where d = 2 and E(β)
(a,b)[ ] shows the expectation value by the posterior distri-
bution with the inverse temperature β = 1/ log n. The empirical entropy Sn
is equal to Ln(0, 0). Figure 5.4 shows Fn −nSn, BIC−Sn, BICrclt−Sn, and
WBIC −Sn. Both BIC using RLCT and WBIC can approximate the free
energy, whereas BIC not. Discuss the diﬀerence of BIC, BIC using RLCT,
and WBIC from the viewpoint of estimators of the free energy for n →∞.

5.6. PROBLEMS
175
×
×
×
×
×
Figure 5.5: Generalization error and its estimators in neural network. The
generalization error, the cross validation error, the WAIC error, the theoreti-
cal value, and the regular theoretical value are compared. The generalization
error can be approximated by the cross validation and WAIC, but not by
the regular theory.
6. The statistical model, the true density, and the prior are set as in the
above neural network. Figure 5.5 shows n(Gn−S), n(Cn−Sn), n(Wn−Sn),
the theoretical value by standard theory, and that by regular theory. Regular
theory cannot be employed in this case. Since the generalization error (Gn−
S) and the cross validation error (Cn −Sn) have the asymptotically inverse
correlation,
n(Gn −S) + n(Cn −Sn) = 2λ
n + op(1/n),
where λ = 1/2 in this case. Hence it needs many sets of (Xn, Y n) to numer-
ically show
E[Gn −S] = E[Cn −Sn] + o(1/n).
In this experiment, the results by 1000 independent trials are shown. Discuss
the diﬀerence of standard theory and regular theory for n →∞.


Chapter 6
General Posterior
Distribution
In the previous chapter, we introduced a standard form of a statistical model
and a prior, based on which mathematical laws of the free energy and the
generalization loss were proved. In this chapter, we explain that many mod-
els and priors can be made into standard forms by using the algebraic geo-
metric transform. Then the posterior distribution is represented as a ﬁnite
mixture of locally standard forms,
p(w) =
X
Standard form.
As a result, the same theorems of the previous chapter also hold in many sta-
tistical models and priors. Also we show the diﬀerence between the Bayesian
and the maximum a posteriori methods. This chapter consists of the fol-
lowing sections.
(1) In Bayesian estimation, the set of parameters can be understood as a
union of local parameter sets.
(2) Resolution theorem in algebraic geometry makes an arbitrary statistical
model a locally standard form.
(3) General theory of Bayesian statistics is established.
(4) The generalization losses of the maximum likelihood and a posteriori
methods are derived.
6.1
Bayesian Decomposition
In Bayesian statistics, the posterior distribution can be decomposed as a sum
of local distributions. Let (p(x|w), ϕ(w)) be a pair of a statistical model and
177

178
CHAPTER 6. GENERAL POSTERIOR DISTRIBUTION
Figure 6.1: Division of parameter set. Bayesian posterior distribution can
be understood as the mixture of several distributions.
a prior. A decomposition of a prior ϕ(w) is
ϕ(w) =
X
j
ϕj(w),
where ϕj(w) ≥0. Then the partition function or the marginal likelihood is
given by
Zn =
X
j
Z
ϕj(w)
n
Y
i=1
p(Xi|w)dw.
The function Xn 7→Zn is a probability density of Xn according to the pair
of the statistical model p(x|w) and a prior ϕ(w), hence
Zn(j) =
Z
ϕj(w)
n
Y
i=1
p(Xi|w)dw
deﬁnes a probability distribution on the pairs {p(x|w), ϕj(w)}. The posterior
average of an arbitrary function f(w) is also given by
Ew[f(w)] =
X
j
Z
f(w)ϕj(w)
n
Y
i=1
p(Xi|w)dw
X
j
Z
ϕj(w)
n
Y
i=1
p(Xi|w)dw
.

6.1. BAYESIAN DECOMPOSITION
179
Therefore Bayesian estimation can be studied from the viewpoint of the local
parameter sets.
The support of ϕj(w) is deﬁned as the closure of nonzero set of ϕj(w),
supp ϕj = {w ∈W; ϕj(w) > 0}.
Let W0 be the set of all parameters that attain the minimum of the average
log loss function L(w),
W0 = {w ∈W; L(w) = min
w′ L(w)}.
If {supp ϕj} ∩W0 is the empty set, then Zn(j) converges to zero faster
than the others. If {supp ϕj} ∩W0 is not the empty set, and if a statistical
model and a prior have a standard form in each local subset, then by using
the local real log canonical threshold λj and its multiplicty mj, the local
partition function can be rewritten as
Zn(j) = cj
(log n)mj−1
nλj
n
Y
i=1
p(Xi|w0),
where cj is a constant order random variable and w0 ∈W0. Let us deﬁne
λ
=
min{λj; j},
m
=
max #{mj; λj = λ},
where #{mj; λj = λ} is the maximum number of j that attains λ = λj.
Then asymptotically
Zn ≈
X
j
cj
(log n)m−1
nλ
n
Y
i=1
p(Xi|w0),
where P
j is the summation over {j; λ = λj, mj = m}, resulting that the
free enegy or the minus log marginal likelihood has the same asymptotic
form as the theorems of previous chapters.
Example 42. In Figure 6.1, the circle shows the true distribution and the
curved line is a set of statistical models. The posterior distribution is made
of local parameters (1), (2), and (3). In such a case, the parameter set can be
divided into three parts, and the posterior distribution can be represented
by their summation.

180
CHAPTER 6. GENERAL POSTERIOR DISTRIBUTION
Posterior (a,b)
-2
0
2
-1
0
1
Posterior (a,b)
-2
0
2
-1
0
1
Posterior (a,b)
-2
0
2
-1
0
1
Posterior (a,b)
-2
0
2
-1
0
1
Figure 6.2: Artiﬁcial examples of posterior distributions. The set of true pa-
rameters is b(a−1)(a+1) = 0. The posterior distribution can be understood
as a mixture of local standard forms.

6.2. RESOLUTION OF SINGULARITIES
181
Example 43. Let a statistical model and a prior be
p(y|x, a, b)
=
1
√
2π
exp(−1
2{y −b tanh((a −1)x) tanh((a + 1)x)}2),
ϕ(a, b)
=
 1/8
(|a| ≤2, |b| ≤1)
0
(otherwise
,
where the set of all parameters is
W = {(a, b); |a| ≤2, |b| ≤1}.
Also let (Xn, Y n) be a set of random variables which are independently
taken from a true distribution q(x)p(y|x, 0, 0), where q(x) is the uniform
distribution on [−2, 2].
Then the set of true parameters is {(a, b); b(a −
1)(a + 1) = 0}. Figure 6.2 shows four posterior distributions for diﬀerent
independent sets (Xn, Y n). By dividing parameter set
W = {(a, b) ∈W; a ≤0} ∪{(a, b) ∈W; a ≥0},
the posterior distribution is represented as a mixture of standard forms. To
each distribution, we can apply the theory in the previous chapter because
b(a−1) and b(a+1) can be made standard form by a1 = a−1 and a2 = a+1.
6.2
Resolution of Singularities
Even if the posterior distribution cannot be approximated by any normal
distribution, there exists division of parameter set such that the average log
density ratio function can be normal crossing in each local parameter set.
The resolution theorem in algebraic geometry is the mathematical base for
statistical analysis of general Bayesian statistics.
Theorem 17 (Hironaka theorem). Let W be a compact which is the
closure of an open set in Rd. Assume that K(w) ≥0 is a nonzero analytic
function on W and that the set {w ∈W; K(w) = 0} is not empty. Then
there exist ǫ > 0, {Wℓ; Wℓ⊂W}, and {Uℓ; Uℓ⊂Rd} which satisfy
{w ∈W ; K(w) ≤ǫ} =
[
ℓ
Wℓ,
and, in each pair Wℓand Uℓ, there exists an analytic map g : Uℓ→Wℓ
which satisﬁes
K(g(u))
=
u2k,
(6.1)
|g′(u)|
=
b(u)|uh|,
(6.2)

182
CHAPTER 6. GENERAL POSTERIOR DISTRIBUTION
where |g′(u)| is the absolute value of the determinant of the Jacobian matrix
of w = g(u),
|g′(u)| =
det
∂wi
∂uj
,
and k, h (k > 0, h ≥0) are d-dimensional multi-indexes, and b(u) > 0.
Example 44. Let a parameter set be [−0.5, 0.5]2. A statistical model and a
prior are deﬁned by
p(y|x, a, b)
=
1
(2πσ2)1/2 exp(−1
2σ2 (y −(a4 −a2b + b3)x)2),
ϕ(a, b)
=
1,
where σ = 0.01. Let a true distribution be q(y|x) = p(y|x, 0, 0) and n = 100.
The average log density ratio function is
K(a, b) =
1
2σ2 (a4 −a2b + b3)2.
Hence the set of true parameters is
a4 −a2b + b3 = 0.
We deﬁne a blowing-up by
a
=
a′,
b
=
3a′b′.
It follows that
a4 −a2b + b3 = a′3(a′ −3b′ + 27b′3).
Figure 6.3 shows the set of true parameters on (a, b) plane, its blown-up on
(a′, b′) plane, the posterior distribution of (a, b) and the blown-up posterior
distribution of (a′, b′). Note that the determinant of Jacobian matrix of this
blowing-up is
|g′(a′, b′)| = 3|a′|,
hence the blown-up posterior distribution is deﬁned using this equation. On
the (a, b) plane, the origin is a not normal crossing singularity, whereas, on
the (a′, b′) plane, (0, 0), (0, 1/3) and (0, −1/3) are normal crossing singular-
ities. Hence on the (a′, b′) plane, the posterior distribution is a mixture of
standard forms.

6.2. RESOLUTION OF SINGULARITIES
183
True parameters (a,b)
-0.5
0
0.5
-0.5
0
0.5
Blowed-up true parameters (a,b)
-0.5
0
0.5
-0.5
0
0.5
Posterior (a,b)
-0.5
0
0.5
-0.5
0
0.5
Posterior (a,b)
-0.5
0
0.5
-0.5
0
0.5
Figure 6.3: Example of resolution theorem. The set of true parameters on
(a, b), its blown-up on (a′, b′), the posterior distribution of (a, b) and the
blown-up posterior distribution of (a′, b′). By using the resolution of singu-
larities, any singularity can be understood as an image of normal crossing
singularities. By using resoluion theorem, most statistical models can be-
come standard forms, to which the theorems in the previous chapter can be
applied.

184
CHAPTER 6. GENERAL POSTERIOR DISTRIBUTION
Deﬁnition 23. In the resolution theorem, g(u), k, h, and b(u) depend
on Uℓ, although such dependence is not explicitly represented because of
simple description.
If such dependence is necessary for description, then
representations gℓ(u), kℓ, hℓ, and bℓ(u) are used.
The real log canonical
threshold λℓand its multiplicity mℓare determined in each Uℓ. Then the
real log canonical threshold and its multiplicity of K(w) and ϕ(w) are deﬁned
by
λ
=
min{λℓ; ℓ},
m
=
max{mℓ; λℓ= λ}.
By the deﬁnition, λ is a positive real number and m is a positive integer
which is not larger than d.
Remark 46. Let us explain several points about Hironaka Theorem.
(1) In this book, knowledge about algebraic geometry is not necessary. How-
ever, a reader who is not a mathematician may see an introductive book to
nonmathematicians [82], in whicn many statistical models and learning ma-
chines are studied. A book [69] is written for mathematicians who are not
majoring in algebraic geometry. A book [51] is basic and famous in alge-
braic geometry. From a computational point of view, [14] is recommended
for students. The resolution of singularities is proved by [37] and studied as
one of the main themes in algebraic geometry [42]. Mathematical relation
to algebraic analysis is introduced by [9] and [41].
(2) The number of elements of {Wℓ}, which is equal to that of {Uℓ}, is ﬁnite.
(3) Since k > 0 and h ≥0 are multi-indices, if eq(6.1) and eq.(6.2) can be
more explicitly written,
K(g(u))
=
(u1)2k1(u2)2k2 · · · (ud)2kd,
|g′(u)|
=
b(u)|(u1)h1(u2)h2 · · · (ud)hd|.
Note that |g′(u)| = 0 if and only if uh = 0, the map w = g(u) is one-to-one
if and only if |uh| > 0. Such a function w = g(u) is called a birational map.
(4) In this book, manifold theory is not required, but if a reader already
studied manifold theory, then ∪ℓWℓand ∪ℓUℓare compact subsets of mani-
folds and g(u) = {gℓ(u)} is a map from a manifold to a manifold. In other
words, gℓ(u) can be understood as a restriction to a local coordinate of a
map from a manifold to another manifold.
(5) In general, for a given function K(w), neither {Uℓ} nor w = g(u) is
unique. Neither k nor h is unique. However, the real log canonical thresh-
old λ and its multiplicity m are uniquely determined and do not depend

6.2. RESOLUTION OF SINGULARITIES
185
on the choice of w = g(u).
Such values are called birational invariants.
The real log canonical threshold is an important birational invariant in high
dimensional algebraic geometry, whereas it is also important in Bayesian
statistics. All Bayesian observables are automatically birational invariants,
because they do not depend on the choice of parameter representations.
(6) If K(g(u)) = K0(u)u2k for some K0(u) > 0 and k1 > 0, then by
u′
1
=
K0(u)1/2k1u1,
u′
2
=
u2,
· · ·
u′
d
=
ud,
eq(6.1) and eq.(6.2) are satisﬁed about u′, because ǫ > 0 can be suﬃciently
small.
(7) This theorem is called Hironaka’s resolution of singularities, which is
the fundamental theorem in algebraic geometry. It holds for an arbitrary
analytic function K(w). Note that this theorem can be employed even if
one does not know the deﬁnition of singularities. If K(w) is an analytic
function, then it holds even if K(w) = 0 does not contain singularities.
(8) Even if K(w) is not an analytic function, there are several cases to
which this theorem can be applied. For example, if K(w) is a piecewise
analytic function, then this theorem can be applied to each parameter set.
If K(w) = K0(w)K1(w), where K0(w) > 0 may not be analytic and K1(w)
is analytic, then the resolution theorem can be applied to K1(w) and the
same statistical theory can be derived.
(9) If a prior has a hyperparameter, then {λℓ} and {mℓ} are functions of the
hyperparameter. In general they may be discontinuous or nondiﬀerentiable,
which is the main reason for phase transition of the posterior distribution.
See Section 9.4.
(10) For a given function K(w), the Hironaka theorem gives the algebraic
algorithm by which the resolution map can be found. However, in general,
it is not easy to ﬁnd the resolution map w = g(u).
For several statisti-
cal models, the complete resolution maps were found. For others, partial
resolution maps were found by which the upper bounds of the real log canon-
ical thresholds were derived. Even if the complete resolution map cannot
be founded, its existence enables us to prove universal formula in Bayesian
statistics. For example, we have methods by which the generalization loss
and the minus log marginal likelihood are estimated without information
about the resolution map.

186
CHAPTER 6. GENERAL POSTERIOR DISTRIBUTION
Example 45. (Resolution by projective space) Let x = (y, z), w = (s, t) ∈R2
and
W = {w = (s, t) ; 0 ≤s, t ≤1}.
A statistical model and a prior are
p(y, z|s, t)
=
1
π exp(−(y −s)2 −(z −t)2),
ϕ(s, t)
=
1.
Assume that q(x) = p(x|0, 0). Then the optimal parameter that minimizes
the average log loss function is w0 = (0, 0). The log density ratio function
and its average are respectively equal to
f(x, w)
=
s2 + t2 −2ys −2zt,
K(w)
=
s2 + t2.
This is not a standard form. In Example 26, we showed it can be made
a standard form by using a polar coordinate system (r, θ). Here we give
another transform.
W
=
W1 ∪W2,
W1
=
{(s, t) ∈W ; s ≥t},
W2
=
{(s, t) ∈W ; s ≤t}.
Then we prepare two other parameter sets,
U1 = {(s1, t1) ; 0 ≤s1, t1 ≤1},
U2 = {(s2, t2) ; 0 ≤s2, t2 ≤1}.
Then by using two maps,
s = s1 = s2t2,
t = s1t1 = t2.
The log density ratio function and its average are respectively given by
f(y, z, s, t)
=
s1(s1 + s1t2
1 −2y −2zt1),
K(s, t)
=
s2
1(1 + t2
1),
and
f(y, z, s, t)
=
t2(s2
2t2 + t2 −2ys2 −2z),
K(s, t)
=
t2
2(s2
2 + 1),

6.2. RESOLUTION OF SINGULARITIES
187
both of which are standard forms. The set U1 ∪U2 is called a projective
space. The integration of an arbitrary function f(s, t) can be divided,
Z
W
f(s, t) ds dt
=
Z
W1
f(s, t) ds dt +
Z
W2
f(s, t) ds dt
=
Z
U1
f(s1, s1t1) t1 ds1 dt1
+
Z
U2
f(s2, s2t2) s2 ds2 dt2,
where we used the absolute values of the Jacobian determinant are t1 and s2
respectively. Therefore, we can apply the standard theory to this case, and
the real log canonical threshold and its multiplicity are λ = 1 and m = 1.
Remark 47. (1) By the same method as Example 45, a regular posterior
distribution can be made standard.
Hence the regular statistical theory
which requires the positive deﬁniteness of the Fisher information matrix
is a very special case of general statistics.
In general theory, the Fisher
information matrix may contain the eigenvalue zero and the transform from
the parameter set to another parameter set may not be diﬀeomorphism. It
is well known that Bayesian statistics gives the better estimation than the
maximum likelihood one in the case when the Fisher information matrix is
degenerate. Such a fact can be mathematically proved by using algebraic
geometry.
(2) If a statistical model has a relatively ﬁnite variance, there exist c0 > 0
such that
Z
q(x)f(x, w)2dx ≤c0
Z
a(x)f(x, w)dx = c0K(w).
Hence if both f(x, w) and K(w) are analytic functions of w and if
K(w) = w2k,
then there exists a function a(x, w) such that
f(x, w) = wk a(x, w).
Therefore, the form of the log density ratio function is automatically derived
from its average function.
(3) If ϕ(w) = 0 on the set {w; K(w) = 0}, then by applying resolution
theorem to K(w)ϕ(w), there exists a function w = g(u) such that
K(g(u))
=
u2k,
ϕ(g(u))|g′(u)|
=
|uh|b(u),

188
CHAPTER 6. GENERAL POSTERIOR DISTRIBUTION
where b(u) > 0. Such a method is called simultaneous resolution of singu-
larities in algebraic geometry. Algebraic geometry is known as one of the
most abstract mathematics, however, its concrete version gives the essential
base of Bayesian statistics.
Example 46. Let (x, y) ∈R2, w = (a, b, c) ∈R3, and
W = {w = (a, b, c) ; |a|, |b|, |c| ≤1}.
A statistical model and a prior are
q(x)
=
 1/2
(|x| ≤1)
0
(|x| > 1) ,
(6.3)
p(x, y|a, b, c)
=
q(x)
√
2π
exp(−1
2(y −aS(bx) −cx)2),
(6.4)
ϕ(a, b, c)
=
1/8,
(6.5)
where S(x) = x + x2. If a true distribution is q(x, y|0, 0, 0), then the log
density ratio function and its average are
f(x, y|a, b, c)
=
1
2{(aS(bx) + cx)2 −2y(a(S(bx) + cx)},
K(a, b, c)
=
1
2(ab + c)2 + 1
6a2b4.
Let us divide the parameter sets by
W1
=
{|a| ≤|c|},
W2
=
{|a| ≥|c|, |ab| ≤|ab + c|},
W3
=
{|a| ≥|c|, |ab + c| ≤|ab2|},
W4
=
{|a| ≥|c|, |ab2| ≤|ab + c| ≤|ab|}.
Then W = ∪jWj. The function w = g(u) is deﬁned by
a = a1c1,
b = b1,
c = c1,
a = a2,
b = b2c2,
c = a2(1 −b2)c2,
a = a3,
b = b3,
c = a3b3(b3c3 −1),
a = a4,
b = b4c4,
c = a4b4c4(c4 −1).
The corresponding Uj = {(aj, bj, cj)}
(j = 1, 2, 3, 4) are deﬁned by
Uj = g−1((Wj)o),

6.2. RESOLUTION OF SINGULARITIES
189
where (Wj)o is the maximum open set that is contained in Wj and g−1((Wj)o)
is the minimum closed set that contains g−1((Wj)o). Note that the function
w = g(u) is one-to-one on (Wj)o, hence g−1 is well-deﬁned on such a set.
The average log density ratio function is given by
K(a, b, c)
=
c2
1
1
2(a1b1 + 1)2 + 1
6a2
1b4
1

,
=
a2
2c2
2
1
2 + 1
6b2
2c2
2

,
=
a2
3b4
3
1
2c2
3 + 1
6

,
=
a2
4b2
4c4
4
1
2 + 1
6b2
4

.
Hence K(a, b, c) is normally crossing in each local coordinate. The absolute
value of the determinant of the Jacobian matrix is
|g′(u)|
=
|c1|
=
|a2c2|
=
|a3b2
3|
=
|a4b4c4|2.
The real log canonical threshold λj and its multiplicity mj for each Uj are
λ1 = 1,
m1 = 1,
λ2 = 1,
m2 = 2,
λ3 = 3/4,
m3 = 1,
λ4 = 3/4,
m4 = 1.
Hence the real log canonical threshold and its multiplicity of (K(w), ϕ(w))
are λ = 3/4 and m = 1 respectively.
Remark 48. For a given average log density ratio function and a prior, there
exists a recursive and algebraic algorithm by which an analytic map w =
g(u) is found in a ﬁnite procedures.
Example 47. By using the example above, we investigate the phase transition
of Bayesian statistics. Instead of the prior given in eq.(6.5), let us study the
prior which has a hyperparameter α > 0,
ϕ(a, b, c|α) = α
8 |a|α−1.

190
CHAPTER 6. GENERAL POSTERIOR DISTRIBUTION
Then in each Uj,
ϕ(g(u))
=
(α/8)|(a1c1)α−1|
=
(α/8)|aα−1
2
|
=
(α/8)|aα−1
3
|
=
(α/8)|aα−1
4
|.
Therefore,
ϕ(g(u))|g′(u)|
=
(α/8)|aα−1
1
cα
1 |
=
(α/8)|aα
2 c2|
=
(α/8)|aα
3 b2
3|
=
(α/8)|aα
4 b2
4c2
4|.
The real log canonical threshold λj for each Uj is
λ1
=
(α + 1)/2,
λ2
=
min{(α + 1)/2, 1},
λ3
=
min{(α + 1)/2, 3/4},
λ4
=
min{(α + 1)/2, 3/4},
If α ̸= 1/2 and α ̸= 1, then mj = 1. Therefore
λ =
 (α + 1)/2
(α ≤1/2)
3/4
(α > 1/2) .
If α = 1/2, then m = 2, otherwise m = 1. Note that λ is a continuous func-
tion of α, but not diﬀerentiable at α = 1/2. The posterior distributions for
α > 1/2 and α < 1/2 are quite diﬀerent from each other. The hyperparme-
ter α = 1/2 is called the critical point of the phase transition. Because the
real log canonical threshold determines the asymptotic properties of the free
energy and the generalization loss, hyperparameter control is important for
nonregular statistical models.
6.3
General Asymptotic Theory
By using the resolution theorem, in the parameter set {w ∈W ; K(w) ≤ǫ},
the pair of a statistical model and a prior can be made a standard form. Here

6.3. GENERAL ASYMPTOTIC THEORY
191
ǫ > 0 is a suﬃciently small constant in resolution theorem. The normalized
partition function is represented by the sum
Z(0)
n
= Z(1)
n
+ Z(2)
n .
(6.6)
By using the constant ǫ > 0,
Z(1)
n
=
Z
K(w)<ǫ
exp(−nKn(w))ϕ(w)dw,
Z(2)
n
=
Z
K(w)≥ǫ
exp(−nKn(w))ϕ(w)dw.
Here Z(1)
n
and Z(2)
n
are the integrations of parameters in a neighborhood of
the optimal parameter set W0 and the outside respectively.
The nonessential part Z(2)
n
can be bounded by the following procedures.
By the same deﬁnition used in Section 4.1,
γn(w) =
1
√n
n
X
i=1
K(w) −f(Xi, w)
p
K(w)
and
γn = sup
w∈W0
|γn(w)|,
the following inequality is derived,
nKn(w)
=
nK(w) −
p
nK(w)γn(w),
≥
nK(w)/2 −γ2
n/2.
Therefore
Z(2)
n
≤
exp(γ2
n/2)
Z
K(w)≥ǫ
exp(−nK(w)/2)ϕ(w)dw
≤
exp(−nǫ/2 + γ2
n/2).
Hence Z(2)
n
= op(exp(−nǫ/3)). Let us study the essential part Z(1)
n . By the
resolution theorem, there exists w = g(u) such that
{w ; K(w) < ǫ} ⊂
[
j
g(Uj),
where, in each Uj,
K(g(u))
=
u2kj,
ϕ(g(u))
=
|uhj|bj(u),

192
CHAPTER 6. GENERAL POSTERIOR DISTRIBUTION
where multi-indexes kj and hj, and a function bj(u) depend on Uj. In each
Uj, the local real log canonical threshold λj, its multiplicity mj, and local
redundant index µj are determined by the same method used in the previous
chapter. Then Dj(u) is deﬁned by the same manner as eq.(5.27),
Dj(u) =
1
C(kj, mj)δ(uα)|uµj
β |bj(u)χ(u).
The normalized posterior function on Uj is
Ω(g(u))
=
ϕ(g(u))|g′(u)|
n
Y
i=1
p(Xi|g(u))
n
Y
i=1
p(Xi|w0)
=
exp(−nKn(g(u)))b(u)|uh|
=
(log n)mj−1
nλj
Dj(u)
Z ∞
0
dt tλj−1 exp(−t +
√
t ξn(u))
+op
(log n)mj−1
nλj

.
This equation shows the asymptotic form of the posterior distribution. When
n tends to inﬁnity, only the sets {Uj} that maximize
(log n)mj−1
nλj
aﬀect the asymptotic form, and are called essential local coordinates. In
other words, the ratio of Ω(g(u)) of a set {Uj} whose (log n)mj−1/nλj is
smaller than the essential local coordinate goes to zero in probability. By
the Deﬁnition 23, a set Uj is an essential local coordinate if and only if
λj = λ and mj = m. Let ELC be the set of all suﬃxes j such that Uj is an
essential local coordinates. Then the general theory can be established by
the same procedure as the standard theory with the replacement,
D(w) 7→
X
j∈ELC
Dj(u).
Let us summarize the general asymptotic theory. The asymptotic free energy

6.3. GENERAL ASYMPTOTIC THEORY
193
is
Fn
=
nLn(w0) + λ log n −(m −1) log log n
−log
 X
j∈ELC
Z
duDj(u)
Z ∞
0
dt tλ−1 exp(−t +
√
t ξn(u))

+op(1).
The renormalized posterior distribution is deﬁned for an arbitrary function
z(t, u),
⟨z(t, u)⟩=
X
j∈ELC
Z
dwDj(u)
Z ∞
0
dt z(t, u) tλ−1 exp(−t +
√
t ξn(u))
X
j∈ELC
Z
duDj(u)
Z ∞
0
dt tλ−1 exp(−t +
√
t ξn(u))
.
Then, the renormalized posterior distribution satisﬁes
⟨t⟩= λ + 1
2⟨
√
t ξn(u)⟩.
The scaling law which connects the original posterior of w and the renor-
malized one of u is given for an arbitrary positive integer s,
Ew[f(x, w)s]
=
1
ns/2 ⟨(
√
t a(x, u))s ⟩+ op( 1
ns/2 ),
Ew[K(w)s]
=
1
ns ⟨ts ⟩+ op( 1
ns ).
By using the renormalized posterior distribution, Fluc(ξn) is deﬁned by
Fluc(ξn)
=
EX[⟨ta(X, u)2⟩−⟨
√
ta(X, u)⟩2.
Then the singular ﬂuctuation is deﬁned by
2ν = Eξ[⟨
√
tξ(w)⟩] = Eξ[Fluc(ξ)].
Asymptotic behaviors of the generalization loss, training loss, cross valida-
tion loss, and WAIC are given by
Gn
=
L(w0) + 1
n

λ + 1
2⟨
√
tξn(u)⟩−1
2Fluc(ξn)

+ op( 1
n),
(6.7)
Tn
=
Ln(w0) + 1
n

λ −1
2⟨
√
tξn(u)⟩−1
2Fluc(ξn)

+ op( 1
n),
(6.8)
Cn
=
Ln(w0) + 1
n

λ −1
2⟨
√
tξn(u)⟩+ 1
2Fluc(ξn)

+ op( 1
n),
(6.9)
Wn
=
Ln(w0) + 1
n

λ −1
2⟨
√
tξn(u)⟩+ 1
2Fluc(ξn)

+ op( 1
n), (6.10)

194
CHAPTER 6. GENERAL POSTERIOR DISTRIBUTION
respectively, whose expectations are
E[Gn]
=
L(w0) + λ
n + o( 1
n),
E[Tn]
=
L(w0) + 1
n(λ −2ν) + o( 1
n),
E[Cn]
=
L(w0) + λ
n + o( 1
n),
E[Wn]
=
L(w0) + λ
n + o( 1
n),
respectively. Note that the convergence in probability holds,
n(Gn −L(w0)) + n(Cn −Ln(w0)) →2λ,
n(Gn −L(w0)) + n(Wn −Ln(w0)) →2λ.
In other words, the generalization error and the cross validation and WAIC
errors have the inverse correlation. The functional variance is deﬁned by
Vn = 1
n
n
X
i=1
n
Ew[(log p(Xi|w)2] −Ew[log p(Xi|w)]2o
.
Then nE[Vn] →2ν. The universal laws of Bayesian statistics hold,
E[Gn]
=
E
h
Cn
i
+ o( 1
n),
(6.11)
E[Gn]
=
E
h
Wn
i
+ o( 1
n).
(6.12)
If a sample is not independent, eq.(6.11) does not hold in general, whereas
eq.(6.12) holds in the cases discussed in Section 5.5.
Remark 49. Let W0 be the set of parameters which minimize the average log
density ratio function K(w). The posterior distribution is the summation of
local distributions near W0. However, when n →∞, the posterior parame-
ters are not to distributed on all neighborhoods of W0 but restricted on the
essential local coordinates. Recall that the essential local coordinates are
characterized by the phenomenon that the local real log canonical thresh-
old is minimized. In other words, only the local parameters that have the
smallest local real log canonical thresholds are realized by the posterior dis-
tribution if n is suﬃciently large. If a prior has a hyperparameter, then the
essential local coordinates are changed by controlling the hyperparameter
(phase transition), which aﬀects the free energy and the generalization loss.

6.3. GENERAL ASYMPTOTIC THEORY
195
0
0.1
0.2
0
5
10
15
20
25
30
35
Gn-S
0
0.1
0.2
0
5
10
15
20
25
30
35
Cn-Sn
0
0.1
0.2
0
5
10
15
20
25
30
35
Wn-Sn
Figure 6.4: For a reduced rank regression model, the generalization, cross
validation, and WAIC errors are compared, Gn −S, Cn −Sn and Wn −Sn.
Averages are asymptotically equal to λ/n. Resolution theorem gives the
mathematical prediction of the generalization error whose average can be
estimated by cross validation and WAIC errors.
It is remarkable that the Bayesian posterior distribution automatically mini-
mizes the free energy and the generalization loss for a given hyperparameter.
This is the fundamental mathematical structure of Bayesian statistics.
Example 48. Let M > 0, N > 0, H > 0, and H0 ≥0 be integers. The
reduced rank regression is deﬁned by the statistical model of y ∈RN for a
given x ∈RM
p(y|x, A, B) =
1
(2π)N/2 exp(−1
2∥y −BAx∥2),
where A = (Ajk) and B = (Bkℓ) are N ×H and H ×M matrices which have
real coeﬃcients respectively. A prior is set
ϕ(A, B) ∝exp(−1
2(
X
j,k
(Ajk)2 +
X
k,ℓ
(Bkℓ)2)).
Assume a true distribution q(y|x) = p(y|A0, B0) which satisﬁes H0 =
rank(B0A0), H0 ≤H. The complete resolution map was given by [5].
(1) If N + H0 < M + H, M + H0 < N + H, H + H0 < M + N, and
M + N + H + H0 is an even integer, then m = 1 and
λ = (1/8){2(H + H0)(M + N) −(M −N)2 −(H + H0)2}.
(2) If N + H0 < M + H, M + H0 < N + H, H + H0 < M + N, and
M + N + H + H0 is an odd integer, m = 2 and
λ = (1/8){2(H + H0)(M + N) −(M −N)2 −(H + H0)2 + 1}.

196
CHAPTER 6. GENERAL POSTERIOR DISTRIBUTION
(3) If N + H0 > M + H, then m = 1 and
λ = (1/2){HM −HH0 + NH0}.
(4) If M + H0 > N + H, then m = 1 and
λ = (1/2){HN −HH0 + MH0}.
(5) If H + H0 > M + N, then m = 1 and
λ = (MN/2).
Note that if a prior satisﬁes ϕ(A, B) > 0, then λ and m are same as above.
Figure 6.4 shows experimental results for the generalization, cross validation,
and WAIC errors for M = N = H = 5, H0 = 3.
Then, for n = 100,
λ/n = 0.12. The experimental averages and standard deviations were
Gn −S
=
0.126, 0.035,
Cn −Sn
=
0.127, 0.034,
Wn −Sn
=
0.126, 0.034.
It seems that the sample size n = 100 is not suﬃciently large, however,
the theoretical value coincides with the numerical results. From the math-
ematical point of view, the general theory needs the condition that n is
suﬃciently large, however, it holds even for smaller n in many concrete
statistical models. Hence the real log canonical threshold can be used for
checking whether the posterior distribution is accurately approximated by
Markov chain Monte Carlo or not.
6.4
Maximum A Posteriori Method
In this section we study the asymptotic property of the maximum a poste-
riori method in nonregular cases. If a prior is deﬁned by the uniform distri-
bution, then it is equivalent to that of the maximum likelihood method. In
general, their results are very diﬀerent from Bayesian estimation, because
a single parameter is chosen. In statistical inferences, a single parameter is
far from a distribution on a parameter. For example, see Example 60. The
average and empirical log loss functions are
L(w)
=
−
Z
q(x) log p(x|w)dx,
Ln(w)
=
−1
n
n
X
i=1
log p(Xi|w),

6.4. MAXIMUM A POSTERIORI METHOD
197
where w ∈W. In this section, we study the case that W is a compact set.
Let ˆw be the parameter that minimizes
L(w) = L(w) −1
n log ϕ(w),
which is called the maximum a posteriori (MAP) estimator. If log ϕ(w) is
a constant for all w, then ˆw is the maximum likelihood estimator (MLE).
The generalization and training losses are respectively deﬁned by
Gn(MAP)
=
L( ˆw),
Tn(MAP)
=
Ln( ˆw).
The set of optimal parameters W0 is deﬁned by
W0 = {w ∈W ; L(w) is minimized}.
We assume that the parameter set W0 is compact and the convergence in
probability holds,
min
w0∈W0 ∥ˆw −w0∥→0.
Hence we can restrict the parameter set in the union of the neighborhoods
of W0. By using the resolution theorem in each local neighborhood Uj,
nKn(g(u))
=
−
n
X
i=1
log p(Xi|g(u))
=
nu2k −√nukξn(u),
where we can assume u ∈[0, 1]d without loss of generality and k =
(k1, k2, ..., kd).
In this section, the integer r (1 ≤r ≤d) is deﬁned so
that k1, k2, ..., kr > 0 and
u2k = u2k1
1
u2k2
2
· · · u2kr
r
.
In other words, {kr} does not contain zero. For a given u, let a (1 ≤a ≤r)
be the positive integer which satisﬁes
u2
a
ka
≤u2
i
ki
(i = 1, 2, ..., r).
(6.13)
A map
[0, 1]d ∋u 7→(t, v) = (t, (v1, v2, ..., vd)) ∈R1 × [0, 1]d

198
CHAPTER 6. GENERAL POSTERIOR DISTRIBUTION
is deﬁned by
t
=
u2k,
vi
=
( q
u2
i −(ki/ka)u2a
(1 ≤i ≤r)
ui
(r < i ≤d)
.
By the deﬁnition, va = 0, hence v is contained in the set,
V ≡{x = (x1, x2, ..., xd) ∈[0, 1]d ; x1x2 · · · xr = 0}.
Moreover, the map
[0, 1]d ∋u 7→(t, v) ∈T × V
is one-to-one.
Example 49. Let us illustrate a case when u2k = u2
1u4
2. Then (k1, k2) = (1, 2),
t
=
u2
1u4
2,
v1
=
q
u2
1 −(1/2)u2
2
(if u2
2/2 ≤u2
1),
v2
=
q
u2
2 −2u2
1
(if otherwise).
Figure 6.5 shows the coodinate (t, v1) and (t, v2). The coordinate (t, v1) is
used if u2
2/2 ≤u2
1 whereas (t, v2) if otherwise.
By using the coordinate (t, v) and Theorem 8, L(g(u)), L(g(u)), and
Ln(g(u)) are represented as the functions of (t, v),
L(t, v)
=
Ln(w0) + t −
p
t/n ξn(t, v) −1
n log ϕ(t, v),
(6.14)
L(t, v)
=
L(w0) + t,
(6.15)
Ln(t, v)
=
Ln(w0) + t −
p
t/n ξn(t, v).
(6.16)
By using these representations, we can derive the average and empirical log
losses. Before the theorem, we prepare a lemma.
Lemma 25. Let f(u) be a C1-class function of u. There exists C > 0 such
that
|f(t, v) −f(0, v)| ≤C t1/(2|k|)|∇f|
(0 ≤t < 1),
where 2|k| = 2(k1 + · · · + kr) and
|∇f| =
sup
u∈[0,1]d max
1≤j≤d
 ∂f
∂uj
(u)
.

6.4. MAXIMUM A POSTERIORI METHOD
199
0
0.2
0.4
0.6
0.8
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
u1
u2
Coordinate u and (t,v)
Figure 6.5: Coordinates for MAP and ML. The coordinate for analyzing the
maximum a posterior estimator in the case u2k = u2
1u4
2. Coordinates are
t = u2
1u4
2, v1 = (u2
1 −u2
2/2)1/2, and v2 = (u2
2 −2u2
1)1/2. The coordinate (t, v1)
is used if u2
2/2 ≤u2
1 whereas (t, v2) is used if otherwise.
Proof. For u = (t, v) and u′ = (0, v),
|f(t, v) −f(0, v)|
=
|f(u) −f(u′)| ≤∥u −u′∥|∇f|
≤
√r max
j
|uj −u′
j| |∇f|
≤
C|u2k|1/(2|k|) |∇f|,
where the last inequality is proved as follows. If j = a then |uj −u′
j| = ua,
else if j ̸= a then u2
a/ka ≤u2
j/kj. Hence
|uj −u′
j|
=
|uj −(u2
j −(kj/ka)u2
a)1/2|
=
(kj/ka)u2
a
uj + (u2
j −(kj/ka)u2a)1/2
=
(kj/ka)u2
a
uj
≤
q
kj/ka ua.
There exists C′ > 0 such that
(ua)2|k| ≤C′ u2k,
which completes the lemma.

200
CHAPTER 6. GENERAL POSTERIOR DISTRIBUTION
The asymptotic behaviors of average and empirical log loss functions for
the MAP method are derived by the following theorem. Let us deﬁne
ψ(u) = −log ϕ(g(u)).
Let u∗be the parameter that minimizes the following function,
u∗= arg
min
K(g(u))=0
n
−1
4 min{0, ξn(u)}2 + ψ(u)
o
.
(6.17)
Then we obtain the following theorem.
Theorem 18. The average and empirical log loss functions of the MAP
method satisfy
L( ˆw)
=
L(w0) + 1
4n max{0, ξn(u∗)}2 + op( 1
n),
Ln( ˆw)
=
Ln(w0) −1
4n max{0, ξn(u∗)}2 + op( 1
n).
Proof. By applying Lemma 25 to ξn(t, v), if t →0, then
ξn(t, v) −ξn(0, v) = op(1).
The eq.(6.14) is equal to
L(t, v) =
√
t −ξn(t, v)
2√n
2
−ξn(t, v)2
4n
+ ψ(t, v)
n
+ Ln(w0).
(6.18)
Let (ˆt, ˆv) be the set of parameters that minimizes L(t, v). Firstly we study
the case ξn(ˆt, ˆv) ≤0. Then there exists t∗= Op(1) such that
p
ˆt = t∗
√n,
because, if this equation holds, the order of L(ˆt, ˆv) −Ln(w0) is not larger
than (1/n), if otherwise, it is larger than 1/n. Then
L(ˆt, ˆv)
=
1
n
n
(t∗−ξn(0, ˆv)
2
)2 −ξn(0, ˆv)2
4
+ ψ(0, ˆv)
o
+Ln(w0) + op( 1
n).
Since ξn(ˆt, ˆv) ≤0 and ˆt = Op(1/n), ξn(0, ˆv) < op(1). Therefore L(ˆt, ˆv) is
minimized by t∗= op(1) and
ˆv = argminvψ(0, v) + op(1).

6.4. MAXIMUM A POSTERIORI METHOD
201
Thus ˆt = op(1/n) and eqs.(6.15) and (6.16),
L( ˆw)
=
L(w0) + op(1/n),
Ln( ˆw)
=
Ln(w0) + op(1/n).
Secondly, we study the case ξn(ˆt, ˆv) > 0. There exists t∗= Op(1) such that
p
ˆt =
1
2√n(ξn(ˆt, ˆv) + t∗) =
1
2√n(ξn(0, ˆv) + t∗) + op(1/√n),
because, if otherwise, the order of L(ˆt, ˆv) is larger than (1/n) by eq.(6.18).
Then also by eq.(6.18) and ˆt = op(1),
L(ˆt, ˆv) = (t∗)2
4n −ξn(0, ˆv)2
4n
+ ψ(0, ˆv)
n
+ Ln(w0) + op(1/n).
(6.19)
Hence t∗= op(1) and
ˆv = argminv(−ξn(0, v)2 + 4ψ(0, v)) + op(1).
Therefore,
L( ˆw)
=
L(w0) + 1
4nξn(0, ˆv)2 + op(1/n),
Ln( ˆw)
=
Ln(w0) −1
4nξn(0, ˆv)2 + op(1/n).
By integrating the above two cases, the theorem is obtained.
Theorem 19. There exists µ > 0 such that
E[L( ˆw)]
=
L(w0) + µ
n + o( 1
n),
E[Ln( ˆw)]
=
Ln(w0) −µ
n + o( 1
n).
Proof. The parameter u∗is deﬁned by minimization,
u∗= argminu
n
−1
4
min
K(g(u))=0{0, ξn(u)}2 + ψ(u)
o
.
(6.20)
By using the convergence of the empirical process ξn(u) →ξ(u), and its
average in Sections 10.4 and 10.5, this theorem is obtained by
µ = lim
n→∞E[max{0, ξn(u∗)}2]/4.

202
CHAPTER 6. GENERAL POSTERIOR DISTRIBUTION
a
b
Trajectory of the Steepest Descent
0.2
0.4
0.6
0.8
1
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Figure 6.6: Trajectory of steepest descent. The contour of the square error of
a simple neural network and trajectory by the steepsest descent are shown.
The parameter has two representations (a, b) and (t, v), where t = a2b2.
Optimization about t makes the generalization error smaller, whereas that
about v larger.
Example 50. (Over-training) Let us study a simple neural network of x, y, a, b ∈
R,
p(y|x, a, b) =
1
√
2πσ2 exp

−1
2σ2 (y −a tanh(bx))2
,
where σ = 0.1. The random variable X is subject to the uniform distribution
on [−2, 2] and the true conditional density q(y|x) = p(y|x, 0, 0). The contour
of the square error
E(a, b) = 1
n
n
X
i=1
(Yi −a tanh(bXi))2
and the trajectory by the steepest descent are shown in Figure 6.6. In this
case t = a2b2. The parameter can be represented by (a, b) and (t, v). In the
steepest descent, the parameter t is rapidly optimized, whereas v is searched
very slowly. Optimization about v gives the over-training, that is to say, the
generalization error is made smaller by optimization about t, but larger
about v. If Bayesian estimation is employed, then the posterior distribution
is spread over {v} and t is optimized, which makes the generalization smaller.
This is the main diﬀerence between MAP or ML and Bayesian estimation.

6.5. PROBLEMS
203
Remark 50. (1) The constant µ depends on the prior ϕ(w). In the maximum
likelihood method, it is given by the average of the maximum value of the
Gaussian process. If W is compact, it is ﬁnite but not small in general. If
W is not compact, the maximum value of the Gaussian process is not ﬁnite
in general, hence the asymptotic properties of the above theorem do not
hold. The maximum likelihood method is not appropriate if the likelihood
function cannot be approximated by normal distribution.
(2) In the above theorems, we study the maximum a posteriori (MAP)
method on the parameter w ∈W.
In order to study MAP method on
u ∈∪Uj, then ϕ(g(u)) should be replaced by ϕ(g(u))|g′(u)|.
Note that
MAP depends on the transform of the parameter. In other words, MAP is
not invariant about parameter representation, whereas ML and Bayes are
invariant.
(3) In general, the average parameter Ew[w] does not converge to W0 in
normal mixture and neural networks. Hence
L(Ew[w]) = nL(w0) + nC + Op(1).
In other words, the posterior mean estimator is not appropriate if the pos-
terior distribution cannot be approximated by a normal distribution.
6.5
Problems
1. For a given analytic funciton K(w) ≥0 and a prior ϕ(w), the partition
function, the state density function, and the zeta function are deﬁned by
Z(n)
=
Z
exp(−nK(w))ϕ(w)dw
(n > 0),
v(t)
=
Z
δ(t −K(w))ϕ(w)dw
(t > 0),
ζ(z)
=
Z
K(w)zϕ(w)dw
(z ∈C).
Show that the following are equivalent.
(1) If n →∞, then log Z(n) + λ log n →0.
(2) If t →+0, then v(t)/tλ−1 →c > 0 for some c.
(3) ζ(z) is holomorphic in the region Re(z) > −λ and has a pole at z = −λ
with the order 1.
2. Assume that two sets of analytic functions and priors (K1(w), ϕ1(w))
and (K2(w), ϕ2(w)) have the real log canonical thresholds λ1 and λ2, re-

204
CHAPTER 6. GENERAL POSTERIOR DISTRIBUTION
spectively. Also assume that K1(w) ≥cK2(w) for some c1 > 0 and that
ϕ1(w) ≤c2ϕ2(w) for some c2 > 0. Then prove that λ1 ≥λ2.
3. Assume that two sets of analytic functions and priors (K1(w1), ϕ1(w1))
and (K2(w2), ϕ2(w2)) have the real log canonical thresholds λ1 and λ2, re-
spectively, where w1 and w2 are diﬀerent variables. Then prove the following.
(1) The real log canonical threshold of (K1(w1) + K2(w2), ϕ1(w1)ϕ2(w2)) is
λ1 + λ2.
(2) The real log canonical threshold of (K1(w1)K2(w2), ϕ1(w1)ϕ2(w2)) is
min{λ1, λ2}.
4. Assume that two sets of functions {fj(w); j = 1, 2, ..., J} and {gk(w); k =
1, 2, ..., K} satisfy
n J
X
j=1
aj(w)fj(w); aj(w) ∈R
o
=
n K
X
k=1
bk(w)gk(w); bj(w) ∈R
o
,
(6.21)
where R = R[w1, w2, ..., wd] is the polynomial ring generated by 1, w1, w2,
...,wd with the real coeﬃcients. Then prove that the following two functions
have the same real log canonical thresold if the same prior is employed.
J
X
j=1
(fj(w))2,
K
X
k=1
(gk(w))2.
Note that if eq.(6.21) holds, it is said that the ideal generated by {fj(w)} is
equal to that of {gj(w)}.
5. Let us deﬁne a function F n by
F n = −log
Z
exp(−nL(w))ϕ(w),
(6.22)
where L(w) is the average log loss function. Then prove that
F n = nL(w0) + λ log n −(m −1) log log n + O(1).
Hence the diﬀerence between Fn and F n is a constant order random variable.

6.5. PROBLEMS
205
6. For a general random variable X, E[exp(X)] ≥exp E[X] holds, which is
called Jensen’s inequality. Prove that for a general random variables X and
Y and a general function f(X, Y ),
EX[ −log EY [exp(f(X, Y ))] ] ≤−log EY [ exp(EX[f(X, Y )]) ]
by using Jensen’s inequality. By using this inequality, prove that
Fn ≤F n,
where F n is deﬁned by eq.(6.22).


Chapter 7
Markov Chain Monte Carlo
The Markov chain Monte Carlo method (MCMC) enables us to numerically
approximate the posterior average for an arbitrary statistical model and
prior. If a posterior distribution is spread on some local parameter region,
then MCMC approximation is accurate, otherwise it is still not so easy. In
many important statistical models such as a normal mixtture or an artiﬁcial
neural network, the Bayesian inference attains much more precise estima-
tion, hence it becomes more important to construct the MCMC algorithm
which works even in singular posterior distributions. In this chaper, we in-
troduce the basic foundations of MCMC process.
(1) The Metropolis method is explained. The Hamiltonian Monte Carlo and
the parallel tempering are its advanced versions.
(2) The Gibbs sampler is introduced. Nonparametric Bayesian sampler is
its advanced version.
(3) Numerical approximation methods of the generalization loss and the free
energy using MCMC method are explained.
In order to check how accurate MCMC approximates the posterior distri-
bution in singular cases, the real log canonical threshold would be a good
index for a given set of a true distribution, a statistical model, and a prior.
7.1
Metropolis Method
Let p(x|w) and ϕ(w) be a statistical model and a prior, where x ∈RN, w ∈
W ⊂Rd. The Hamiltonian function H(w) is deﬁned by
H(w) = −
n
X
i=1
log p(Xi|w) −log ϕ(w).
207

208
CHAPTER 7. MARKOV CHAIN MONTE CARLO
Then the posterior distribution is represented by
p(w)
=
1
Zn
ϕ(w)
n
Y
i=1
p(Xi|w)
=
1
Zn
exp(−H(w)),
where Zn is a partition function or the marginal likelihood,
Zn =
Z
exp(−H(w))dw.
The probability density function p(w), which is equal to the posterior distri-
bution in Bayesian statistics, is called the equilibrium state of the Hamilto-
nian H(w). Our purpose in this chapeter is to generate {wk}K
k=1 such that,
for an arbitrary function f(w),
Z
f(w)p(w)dw ≈1
K
K
X
k=1
f(wk),
(7.1)
when K →∞. In most cases in statistical applications, n is large, hence
the parameter set
{w ∈W; p(w) > ǫ}
for some ǫ > 0 is very a narrow subset of W, resulting that Riemann sum of
the integral on the parameter space does not give eﬀective approximation.
Remark 51. (1) (Curse of dimensionality) If d = 1, then the integral can be
approximated by Reimann sum,
Z 1
0
f(w)p(w)dw ≈1
K
K
X
k=1
f(k/K)p(k/K),
(7.2)
which is more accurate than MCMC. However, if d = 2, 3, 4, ..., then the
number Kd necessary for approximation becomes too large to be calculated
numerically. This diﬃculty is called “curse of dimensionality”.
(2) (Importance sampling) If a function H0(w) exists such that {wk} can be
easily generated from p0(w) ∝exp(−H0(w)), then
Z
f(w)p(w)dw ≈
K
X
k=1
f(wk) exp(−H(wk) + H0(wk))
K
X
k=1
exp(−H(wk) + H0(wk))
.
(7.3)

7.1. METROPOLIS METHOD
209
This method is called the importance sampling, which works well if H(w) ≈
H0(w).
(3) In almost all cases, H(w) is given explicitly, however, Zn not. It is more
diﬃcult to calculate Zn than estimating the average.
In the Markov chain Monte Carlo (MCMC) method, a sequence {w1, w2,
w3, ...} is generated by a conditional probability p(wk+1|wk) iteratively. It
is known that (1) and (2) below are suﬃcient conditions for eq.(7.1) to hold.
(1) (Detailed Balance Condition). For arbitrary parameters wa, wb ∈
W,
p(wb|wa)p(wa) = p(wa|wb)p(wb).
(2) (Irreducible Condition). For an arbitrary w ∈W, the probability
that a parameter of {wk} is contained in the neighborhood of w is not equal
to zero.
Note that the detailed balance condition is not necessary for eq.(7.1),
however, there are several MCMC algorithms which satisfy the detailed
balance condition. Firstly, we study Metropolis method.
7.1.1
Basic Metropolis Method
Let r(w1|w2) be a conditional probability density which satisﬁes
∀(w1, w2),
r(w1|w2) = r(w2|w1).
(7.4)
In Metropolis method, the set of parameters {w(t) ∈Rd; t = 1, 2, 3, ...} is
generated as follows.
Metropolis Method.
(1) Initialize w(1) and t = 1.
(2) A candidate w′ is generated by r(w′|w(t)).
(3) By using ∆H ≡H(w′)−H(w(t)), the probability P = min{1, exp(−∆H)}
is determined. Then set w(t+1) = w′ with probability P, or w(t+1) =
w(t) with 1 −P.
(4) t := t + 1, and return to (2).
We can prove that this procedure satisﬁes the detailed balance condition.
Theorem 20. Metropolis method satisﬁes the detailed balance condition.

210
CHAPTER 7. MARKOV CHAIN MONTE CARLO
Proof. Let p(w(t + 1)|w(t)) be the conditional probability which is used in
one step of the Metropolis method. To show the detailed balance condition,
it is suﬃcient to prove
p(wa|wb) exp(−H(wb)) = p(wb|wa) exp(−H(wa))
(7.5)
for an arbitrary set (wa, wb). For a given w(t), the simultaneous probability
that w′ is generated from w(t) and that w(t + 1) = w′ is
r(w′|w(t))min{1, exp(−H(w′) + H(w(t)))}.
Therefore, for a given w(t), the probability that the new candidate place is
chosen is given by marginalization about w′,
Q(w(t)) =
Z
r(w′|w(t))min{1, exp(−H(w′) + H(w(t)))}dw′.
Hence the probability that w(t + 1) = w(t) is 1 −Q(w(t)), resulting that
p(wa|wb)
=
r(wa|wb)min{1, exp(−H(wa) + H(wb))}
+δ(wa −wb)(1 −Q(wb)).
By using this relation, r(wa|wb) = r(wb|wa), and the property of the delta
function, it follows that
p(wa|wb) exp(−H(wb))
=
r(wa|wb)min{exp(−H(wb), exp(−H(wa))}
+δ(wa −wb)(1 −Q(wb)) exp(−H(wb))
=
r(wb|wa)min{exp(−H(wb), exp(−H(wa))}
+δ(wb −wa)(1 −Q(wa)) exp(−H(wa))
=
p(wb|wa) exp(−H(wa)),
which completes the theorem.
Remark 52. (Metropolis-Hasting method) Metropolis method can be gener-
alized for the case r(wa|wb) ̸= r(wb|wa). For such a case, the probability P
is replaced by
P = min
n
1, r(w(t)|w′) exp(−H(w′))
r(w′|w(t)) exp(−H(w(t)))
o
.
Then the detailed balance condition is satisﬁed.

7.1. METROPOLIS METHOD
211
Remark 53. Theoretically speaking, Metropolis method gives the set of pa-
rameter which ensures eq.(7.1), if K →∞. However, in practical applica-
tions, there are several issues.
(1) The parameters in the period which is aﬀected by the initial point should
be removed from the obtained parameter set. Such a period is called ‘burn-
in’.
(2) The obtained parameters are not independent if MCMC is used. For
the eﬀective approximation of the posterior distribution, the dependency
between parameters had better be reduced. Hence {w(m∗t); t = 1, 2, ...} for
some m is chosen. If m is large, then dependency of the obtained parameters
is made small, but it needs a computational cost. In this book, m is called
a ‘sampling interval’.
(3) If a probability distribution p(w) has several distant peaks, then the
probability from a peak to another peak becomes very small, hence the ir-
reducibility of MCMC often fails. This is called the problem of a ‘potential
barrier’.
(4) Let w0 be the parameter that minimizes H(w). If the set {w ∈W; H(w)−
H(w0) < ǫ} is connected but not contained in some local region, then
MCMC process sometimes fails because the probability from a place to a
distant place is very small. This is called the problem of ‘entropy barrier’.
(5) The probability that the candidate parameter w′ is chosen is called the
acceptance probability. If the variance of r(w1|w2) is small, then the ac-
ceptance probability becomes high, but the candidate parameter is chosen
in the narrow local region. If it is large, then the acceptance probability
becomes small, but the candidate parameter is chosen from the wide range.
In the Metropolis method, optimization of the acceptance probability by
controlling r(w1|w2), is one of the most important processes for construct-
ing MCMC.
(6) Several criteria which judge whether the parameters could be understood
as taken from the equilibrium state or not are proposed [29, 30, 33].
7.1.2
Hamiltonian Monte Carlo
In the original Metropolis method, in order to ensure the acceptance proba-
bility is not small, the dependency of w(t) and w(t + 1) becomes large. The
following method was devised to improve this property.
Let w ∈Rd. A new variable v ∈Rd is introduced and the total Hamil-
tonian of (w, v) is deﬁned by
H(w, v) = 1
2∥v∥2 + H(w).

212
CHAPTER 7. MARKOV CHAIN MONTE CARLO
If {(wk, vk)} which is subject to the equilibrium state exp(−H(u, v)) of the
total Hamiltonian, then {wk} is subject to the equilibrium state exp(−H(u))
of the Hamiltonian H(w). Thus we make {(wk, vk)} subject to the equilib-
rium state of the total Hamiltonian.
Hamiltonian Monte Carlo.
(1) Initialize w(1) and t = 1.
(2) The elements of v ∈Rd are independently generated by the standard
normal distribution.
(3) The following diﬀerential equation with respect to the time parameter
τ is solved with the initial condition that (w(t), v) at τ = 0. Here τ is
a variable which has no relation to MCMC time t.
dw
dτ
=
v,
dv
dτ
=
−∇H(w).
This is known as the Hamilton equation which describes the dynamics
of the canonical coordinate (u, v). Then (w′, v′) (w′ = w(τ), u′ = u(τ))
is obtained for a given time τ. It is permissible that the numerical
solution of the diﬀerential equation contains errors. However, it should
satisfy the invariance condition of the time reverse and the volume
conservation condition of the phase space. It is known that leap frog
method in Remark 54 satisﬁes both conditions.
(4) By deﬁning ∆H = H(w′, v′) −H(w(t), v), then w(t + 1) = w′ with
P = max{1, exp(−∆H)}, or w(t + 1) = w(t) with probability 1 −P.
(5) t = t + 1. Return to (2).
This method satisﬁes the detailed balance condition for exp(−H(w, p)).
Note that the rigorous solution of the diﬀerential equation satisﬁes dH/dt =
0, hence it is expected that the numerical solution gives ∆H ≈0, thus the
acceptance probability can be made higher and w′ can be generated at the
distant place from w(t).
Remark 54. (Leap frog method) The diﬀerential equation
dw
dt = v,
dv
dt = f(w)

7.1. METROPOLIS METHOD
213
is numerically solved by the iteration,
v(n + 1/2)
=
v(n) + ǫ
2 f(w(n)),
w(n + 1)
=
w(n) + ǫ v(n + 1/2),
v(n + 1)
=
v(n + 1/2) + ǫ
2 f(w(n + 1)),
where ǫ > 0 is a small constant.
If ǫ is made very small, then the diﬀerential equation is solved with
high accuracy but the computational costs also become high.
In Hamil-
tonian Monte Carlo, the controlling the balanace between ǫ and the ac-
ceptance probability is necessary.
Recently, an improved algorithm was
proposed which determines them automatically by using non-U-turn Hamil-
tonian Monte Carlo [38].
Example 51. For a probability density
p(x, y) ∝exp(−Nx2y2 −Mx2 −My2),
where N = 50, M = 0.005, random variables {(Xi, Yi)} (i = 1, 2, ..., 300) are
generated by Metropolis method, Gibbs sampling, and Hamiltonian Monte
Carlo. (See Figure 7.1.) For the Gibbs sampler, see the following subsection.
Note that, if M = 0, then
R
exp(−Nx2y2)dxdy = ∞, hence p(x, y) is not
a probability density.
The origin is a singularity of X2y2.
In a normal
mixture or an artiﬁcial neural network, such a singular posterior distribution
on higher parameter space is necessary. By an experiment in which 10000
random variables are generated, the empirical averages are compared,
EMET[X]
=
0.076,
EMET[Y ]
=
0.4528,
EGIB[X]
=
0.0289,
EGIB[Y ]
=
−0.017,
EHAM[X]
=
0.091,
EHAM[Y ]
=
0.089,
where EMET, EGIB, and EHAM mean the empirical averages oy the Metropo-
lis method, Gibbs sampler, and Hamiltonian Monte Carlo. The true averages
of X and Y are equal to zero. In the Metropolis and Hamiltonian methods,
one sampling process consists of 100 trials and 100 dynamical calculations,
respectively. In this case, the Hamiltonian has the form for which Gibbs
sampler can be employed. However, in general it is not applied. In the cases
when Gibbs sampling cannot be employed, Hamiltonian Monte Carlo gives
the more accurate MCMC expectations.

214
CHAPTER 7. MARKOV CHAIN MONTE CARLO
Probability Density
-5
0
5
-5
0
5
-5
0
5
-5
0
5
Metropolis Monte Carlo
-5
0
5
-5
0
5
Gibbs Sampler
-5
0
5
-5
0
5
Hamiltonian Monte Carlo
Figure 7.1: Comparison of a probability distribution, Metropolis method,
Gibbs Sampler, and Hamiltonian method for p(x, y) ∝exp(−Nx2y2−Mx2−
My2). In many statistical models, the posterior distribution contains sin-
gularities, hence MCMC processes for such cases are very important.

7.1. METROPOLIS METHOD
215
7.1.3
Parallel Tempering
If the posterior distribution does not concentrate in some local region, the
parallel tempering or replica Monte Carlo is sometimes employed.
Let
nLn(w) = −
n
X
i=1
log p(Xi|w).
Note that this function does not contain the prior information, in other
words,
H(w) = nLn(w) −log ϕ(w).
The equilibrium state of the inverse temperature β > 0 is deﬁned by
p(w|β) =
1
Z(β) exp(−nβLn(w))ϕ(w).
Then the posterior distribution is equal to p(w|1).
Let the sequence of
inverse termperatures be
0 = β1 < β2 < · · · < βJ = 1.
The target probability distribution of the parallel tempering is
J
Y
j=1
p(wj|βj),
(7.6)
which is a probability density function of (w1, w2, ..., wJ). If parameters are
taken from this distribution, then the set {wJ(t)} can be used for posterior
distribution, because p(wJ|βJ) = p(w|1). The parallel tempering consists of
two MCMC processes.
Parallel Tempering.
(1) One is the independent MCMC process for each p(wj|βj).
w11 →w12 →w13 →· · ·
w21 →w22 →w23 →· · ·
· · ·
wJ1 →wJ2 →wJ3 →· · ·
In this process, arbitrary MCMC method can be used.

216
CHAPTER 7. MARKOV CHAIN MONTE CARLO
(2) The other is the exchange process between wj and wj+1 with some
interval in each MCMC process. The probability of the exchange is
given by
min{1, exp{(βj+1 −βj)(nLn(wj+1) −nLn(wj))},
(7.7)
which satisﬁes the detailed balance condition for the probability den-
sity of eq.(7.6).
Note that the prior does not aﬀect the exchange
probability.
Even if p(wj|βJ) have many peaks, p(wj|βj) for small βj does not, hence the
equilibrium state can be more easily realized by exchanging parameters.
Theorem 21. Parallel tempering using the exchange probability of eq.(7.7)
satisﬁes the detailed balance condition.
Proof. Let us use (u, v) for (wi, wj+1) and (α, β) for (βj, βj+1). The target
probability distribution is
P(u, v)
∝
exp(−αnLn(u))ϕ(u) exp(−βnLn(v)ϕ(v))
=
exp(−f(x, y)),
where
f(u, v) = αnLn(u) + βnLn(v) −log ϕ(u) −log ϕ(v).
By the exchange (u, v) →(v, u),
∆f
=
f(v, u) −f(u, v)
=
αnLn(v) + βnLn(u) −αnLn(u) −βnLn(v)
=
(β −α)(nLn(u) −nLn(v)).
Therefore the exchange process whose probability is deﬁned by
min{1, exp(−∆f)}
satisﬁes the detailed balance condition.
Remark 55. Assume that the posterior distribution has the real log canon-
ical threshold λ.
The exchange probability between β1, β2, (β2 > β1) is
asymptotically (for n →∞) given by the following formula, [52].
P(β1, β2) = 1 −1
√π
β2 −β1
β1
Γ(λ + 1/2)
Γ(λ)
.
If the sequence {βj} is set as a geometric progression, the exchange proba-
bility becomes a constant for a suﬃciently large n.

7.2. GIBBS SAMPLER
217
7.2
Gibbs Sampler
Metropolis method can be applied to any Hamiltonian function, however,
it is not easy to generate parameters globally. Hamiltonian Monte Carlo
improved that diﬃculty. Although the Gibbs sampler can be used in the
special posterior distributions, if it can be employed, it is rather easy to
generate parameters globally.
In the Gibbs sampler, a parameter w ∈Rd is divided as w = (w1, w2).
Let the posterior distribution be p(w1, w2). Then two conditional probability
distributions p(w1|w2) and p(w2|w1) are deﬁned from p(w1, w2). The set of
parameters {w(t) = (w1(t), w2(t)) ∈Rd; t = 1, 2, 3, ...} is generated by the
following procedure.
Gibbs Sampler.
(1) Initialize w(1) = (w1(1), w2(t)). t = 1.
(2) One of (A) or (B) is chosen with probability 1/2.
(A) w′
2 is generated by p(w′
2|w1(t)), then w′
1 is generated by p(w′
1|w′
2).
(B) w′
1 is generated by p(w′
1|w2(t)), then w′
2 is generated by p(w′
2|w′
1).
(3) Set wt+1 = (w′
1, w′
2) and t := t + 1. Return to (2).
Theorem 22. Gibbs sampler satisﬁes the detailed balance condition.
Proof. The probability density of (w′
1, w′
2) for a given set (w1, w2) is given
by
p(w′
1, w′
2|w1, w2) = 1
2{p(w′
2|w′
1)p(w′
1|w2) + p(w′
1|w′
2)p(w′
2|w1)}.
Let us prove the detailed balance condition,
p(w′
1, w′
2|w1, w2)p(w1, w2) = p(w1, w2|w′
1, w′
2)p(w′
1, w′
2).
By using the deﬁnition of the conditional probability,
p(w′
2|w′
1)p(w′
1|w2)p(w1, w2)
=
p(w′
1, w′
2)
p(w′
1)
p(w′
1, w2)
p(w2)
p(w1, w2)
=
p(w′
1, w′
2)p(w′
1, w2)
p(w′
1)
p(w1, w2)
p(w2)
=
p(w′
1, w′
2)p(w2|w′
1)p(w1|w2)
By the same method,
p(w′
1|w′
2)p(w′
2|w1)p(w1, w2)
=
p(w′
1, w′
2)p(w1|w′
2)p(w2|w1).
By the sum of these equations, this theorem is completed.

218
CHAPTER 7. MARKOV CHAIN MONTE CARLO
Remark 56. (1) In the above deﬁnition, the order of sampling w1 and w2 is
chosen by the same probabilities 1/2. If the order is ﬁxed, then the detailed
balance condition is not satisﬁed, however, the same equilibrium state can
be obtained.
(2) If one of two procedures p(w′
1|w2) and p(w′
1|w2) is chosen with the same
probability, then the conditional probability is given by
p(w′
1, w′
2|w1, w2) = 1
2{p(w′
1|w2)δ(w′
2 −w2) + p(w′
2|w1)δ(w′
1 −w1)},
which also satisﬁes the detailed balance condition.
7.2.1
Gibbs Sampler for Normal Mixture
Gibbs sampler is often employed in the mixture models. Let us derive an
algorithm by Gibbs sampler for a normal mixture.
In this subsection, a
normal distribution of x ∈RM for a given b ∈RM is denoted by
N(x|b) =
1
(2π)M/2 exp(−∥x −b∥2
2
).
Then a normal mixture is deﬁned by
p(x|a, b) =
K
X
k=1
akN(x|bk),
where a = (a1, a2, ..., aK) and b = (b1, b2, ..., bK) are parameters of a normal
mixture, which satisﬁes P aj = 1 and aj ≥0, and bk ∈Rd. For the prior,
we adopt
ϕ(a)
=
1
z1
K
Y
k=1
(ak)αk−1,
ϕ(b)
=
1
z2
K
Y
k=1
exp(−1
2σ2 ∥bk∥2),
where ϕ(a) and ϕ(b) are the Dirichlet distribution with index {αk} and the
normal distribution respectively. Here {αk} and σ2 > 0 are hyperparameters
and z1, z2 > 0 are constants. Let y = (y(1), y(2), ..., y(K)) be a competitive
variable, in other words, y takes value on the following set,
CK = {(1, 0, ..., 0), (0, 1, 0, ..., 0), ...(0, 0, 0, ..., 1)}.

7.2. GIBBS SAMPLER
219
Then a statistical model for the simultaneous probability density of (x, y) is
deﬁned by
p(x, y|a, b) =
K
Y
k=1
n
akN(x|bk)
oy(k)
.
It follows that
p(x|a, b) =
X
y∈CK
p(x, y|a, b).
Therefore a normal mixture p(x|a, b) can be understood as a statistical model
p(x, y|a, b) which has a latent or hidden variable y ∈CK.
Let xn = {x1, x2, ..., xn} be an independent sample and yi ∈CK be
the competitive variable which corresponds to a sample point xi. We use
a notation yn = {y1, y2, ..., yn}. The kth element of yi is denoted by y(k)
i
.
Then Bayesian simultaneous probability is
p(a, b, xn, yn) = ϕ(a)ϕ(b)
n
Y
i=1
p(xi, yi|a, b)
(7.8)
=
1
z1z2
K
Y
k=1
h
aαk−1
k
exp(−∥bk∥2
2σ2 )
n
Y
i=1
n
akN(xi|bk)
oy(k)
i i
(7.9)
= 1
Z
h K
Y
k=1
aαk−1+nk
k
ih K
Y
k=1
exp(−Hk(bk))
i
,
(7.10)
where Z is a normalizing constant and
nk
=
n
X
i=1
y(k)
i
,
Hk(bk)
=
∥bk∥2
2σ2 +
n
X
i=1
y(k)
i
2 ∥xi −bk∥2.
In Bayesian estimation, we need the posterior parameters {(a, b)} which
are subject to p(a, b|xn). If {(a, b, yn)} are subject to p(a, b, yn|xn), then
{(a, b)} of them can be used for numerical approximation of the posterior
distribution.
Therefore it is suﬃcient to make a Gibbs sampler for (a, b) and yn, in
which the conditional probabilities we need are
p(yn|a, b, xn),
p(a, b|xn, yn).

220
CHAPTER 7. MARKOV CHAIN MONTE CARLO
In fact, by using these conditional probabilities, we can make a Gibbs sam-
pler for (a, b) 7→yn and yn 7→(a, b). By eq.(7.9), under the probability
distribution p(yn|a, b, xn), y1, y2, ..., yn are independent and, for each i,
p(y(k)
i
|a, b, xi)
∝
h
akN(xi|bk)
iy(k)
i .
In other words,
p(y(k)
i
= 1|a, b, xi) = akN(xi|bk)
p(xi|a, b) .
(7.11)
On the other hand, if (a, b1, b2, ..., bK) is subject to the probability distribu-
tion p(a, b|xn, yn), they are independent by eq.(7.10). Hence
p(a, b|xn, yn) = p(a|xn, yn)
k
Y
k=1
p(bk|xn, yn).
The variable a is subject to the Dirichlet distribution with index αk + nk.
p(a|xn, yn)
=
1
Z
h K
Y
k=1
aαk+nk−1
k
i
.
(7.12)
By using
Hk(bk)
=
1
2( 1
σ2 + nk)∥bk∥2 −
X
i
y(k)
i
xi

bk + Const.
=
1
2( 1
σ2 + nk)
bk −
X
i
y(k)
i
xi

/( 1
σ2 + nk)

2
+ Const.,
the variable bk is subject to the normal distribution with average b∗
k and
variance (σ∗
k)2,
p(bk|xn, yn) = N(b∗
k, (σ∗
k)2),
(7.13)
where
b∗
k
=
X
i
y(k)
i
xi

/( 1
σ2 + nk),
(σ∗
k)2
=
1/( 1
σ2 + nk).
Hence we obtained the Gibbs sampler from eqs.(7.11), (7.12), and (7.13).

7.2. GIBBS SAMPLER
221
Gibbs Sampler for Normal Mixture.
(1) A parameter set {(ak, bk); k = 1, 2, ..., K} is initialized.
(2) A set of hidden variables {yi = {y(k)
i
}} is determined by the probabil-
ity,
p(y(k)
i
= 1|a, b, xi) = akN(xi|bk)
p(xi|a, b) .
(3) Using nk = Pn
i=1 y(k)
i
, a parameter a = {ak} is generated by using
Dirichlet distribution,
p(a|xn, yn) = 1
Z
h K
Y
k=1
aαk+nk−1
k
i
.
(4) A parameter {bk} is generated by the normal distribution N(b∗
k, (σ∗
k)2)
where
b∗
k
=
X
i
y(k)
i
xi

/( 1
σ2 + nk),
(σ∗
k)2
=
1/( 1
σ2 + nk).
(5) Return to (2).
Example 52. An experiment is conducted for the case M = 2, K = 2,
αk = 1, and n = 100. In Figure 7.2, for the four diﬀerent true distribu-
tions, the posterior parameter sample points of b1 = (b11, b12) and b2 =
(b21, b22) are displayed. The centers of the true distributions (0.2B, 0.2B)
and (−0.2B, −0.2B) for B = 4, 3, 2, 1 are shown by the white circles. The
true paramater of a is a0 = 0.5. For B ≥3, the posterior distributions are
localized, whereas for B ≤2, they are singular. Both the cross validation
loss and WAIC can be applied to all cases, because both criteria can be used
without normality of the posterior distribution.
7.2.2
Nonparametric Bayesian Sampler
The Gibbs sampler for mixture models can be extended as a nonparametric
Bayesian sampler.
Firstly, we derive an MCMC method for a mixture model which is mathe-
matically equivalent to the Gibbs sampler. The marginal probability density
function of (b, yn) is given by
p(b, yn|xn) =
Z
p(a, b, y|xn)da.

222
CHAPTER 7. MARKOV CHAIN MONTE CARLO
-2
0
2
-2
-1
0
1
2
Posterior. o : true parameter
-2
0
2
-2
-1
0
1
2
Posterior. o : true parameter
-2
0
2
-2
-1
0
1
2
Posterior. o : true parameter
-2
0
2
-2
-1
0
1
2
Posterior. o : true parameter
Figure 7.2: Posterior distributions of normal mixtures (n = 100) are dis-
played.
The true distribution is a normal mixture which consists of two
normal distributions with centers are indicated by the white circles.
As
the distance between two circles is made smaller, the posterior distribution
becomes singular.

7.2. GIBBS SAMPLER
223
If we obtain the MCMC sample from P(b, yn|xn), then the posterior distri-
bution of {a} or its average can be obtained by eq.(7.12). Therefore it is
suﬃcient to make a Gibbs sampler for p(b, yn|xn), which requires p(b|xn, yn)
and p(yn|b, xn). The former is equal to the direct product of eq.(7.13). To
derive the latter, by using
Z
K
Y
k=1
(ak)nkϕ(a)da =
QK
k=1 Γ(αk + nk)
Γ(n + PK
k=1 αk)
Γ(PK
k=1 αk)
QK
k=1 Γ(αk)
and eq.(7.9),
p(b, yn|xn) ∝
hQK
k=1 Γ(nk + αk)
Γ(n + P
j αj)
i
ϕ(b)
h K
Y
k=1
n
Y
i=1
N(xi|bk)y(k)
i
i
.
Hence
p(yn|b, xn) ∝
K
Y
k=1
h
Γ(nk + αk)
n
Y
i=1
N(xi|bk)y(k)
i
i
.
Let Nk(i) be the sum of y(k)
i
whose sample point number is not larger than
i. That is to say,
Nk(i) =
i
X
j=1
y(k)
j .
Then Nk(n) = nk and
Γ(nk + αk)
=
Γ(αk)
n
Y
i=1
(αk + Nk(i) −1)y(k)
i .
Since Γ(αk) is a constant function of y(k)
i
,
p(yn|b, xn) ∝
n
Y
i=1
h K
Y
k=1
{(αk + Nk(i) −1)N(xi|bk)}y(k)
i
i
.
By using
p(y1)
∝
K
Y
k=1
{(αk + y(k)
1
−1)N(xi|bk)}y(k)
1 ,
(7.14)
p(yi|yi−1)
∝
K
Y
k=1
{(αk + Nk(i) −1)N(xi|bk)}y(k)
i .
(7.15)

224
CHAPTER 7. MARKOV CHAIN MONTE CARLO
The random variable (y1, y2, ..., yn) can be generated by iteration,
P(yn|b, xn) = p(y1) p(y2|y1) p(y3|y1, y2) · · · p(yn|yn−1).
Note that eq.(7.15) means
p(y(k)
1
= 1)
=
αkN(x1|bk)
P
k′ αk′N(x1|bk′),
(7.16)
p(y(k)
i
= 1|yi−1)
=
(αk + Nk(i −1))N(xi|bk)
P
k′(αk′ + Nk′(i −1))N(xi|bk′).
(7.17)
That is to say, yi is determined by Nk(i −1) which is the cumulative sum
of y1, y2, ..., yi−1. If Nk(i −1) is large, then the probability that y(k)
i
= 1
is also large. This stochastic procedure is called “the Chinese restaurant
process”, where i is a guest of a resaurant and k is the number of a table.
The ith guest determines a table according to the numbers of persons sitting
at tables.
If K →∞and αk = α/K, then this Gibbs sampler determined by
eqs.(7.13), (7.16), and (7.17) gives the statistical estimation of the nonpara-
metric Bayesian method. We obtained the following algorithm.
Nonparametric Bayesian Sampler for Normal Mixture.
(1) A parameter set {(ak, bk); k = 1, 2, ..., K} is initialized.
(2) A set of hidden variables {yi = {y(k)
i
}} is iteratively determined by
the probability,
p(y(k)
1
= 1)
=
αkN(x1|bk)
P
k αkN(x1|bk),
p(y(k)
i
= 1|yi−1)
=
(αk + Nk(i −1))N(xi|bk)
P
k(αk + Nk(i −1))N(xi|bk),
where Nk(i) = Pi
j=1 y(k)
j .
(3) A parameter {bk} is generated by the normal distribution N(b∗
k, (σ∗
k)2)
where
b∗
k
=
X
i
y(k)
i
xi

/( 1
σ2 + nk),
(σ∗
k)2
=
1/( 1
σ2 + nk).
(4) Return to (2).

7.3. NUMERICAL APPROXIMATION OF OBSERVABLES
225
Remark 57. (1) This algorithm is a Gibbs sampler for (b, yn), whereas the
previous one was applied to (a, b, yn). The expectation operation over a is
analytically performed.
(2) In statistics, a nonparametric estimation of a density function of X for
a given Xn is usually deﬁned by
ˆp(x) = 1
n
n
X
i=1
ρ
x −Xi
nα

,
where ρ(x) is some kernel function such as a normal distribution, and α is
an optimized controlling parameter. In this method, the estimated density
is a mixture of n functions. The nonparametric Bayesian method is formally
deﬁned by the mixture of the inﬁnite number of functions, however, it re-
quires the very small {αk = α/K}, so that the number K essentially used
in MCMC is ﬁnite. The optimal hyerparameter α that minimizes the gener-
alization loss can be evaluated by the cross validation and WAIC. In order
to ensure the generalization loss is smaller, inﬁnite components should be
controlled close to zero, therefore the prior eﬀect should be made stronger.
The generalization error by the mixture model with the appropriate ﬁnite
number of components is smaller than that from the mixture of inﬁnite
components.
7.3
Numerical Approximation of Observables
By using the Markov chain Monte Carlo method, we can numerically calcu-
late Bayesian observables.
7.3.1
Generalization and Cross Validation Losses
Let {wk; k = 1, 2, ..., K} be a set of posterior parameters. The generalization
loss is numerically approximated by
Gn = −1
T
T
X
t=1
log
 1
K
K
X
k=1
1
p(Xt|wk)

,
where {Xt} is a set of random variables which are independent of the sample
used in the posterior distribution. In general T should be very large, T >>
n, in order to minimize the ﬂuctuation. ISCV indexISCV and WAIC can

226
CHAPTER 7. MARKOV CHAIN MONTE CARLO
also be approximated numerically.
ISCV
=
1
n
n
X
i=1
log
 1
K
K
X
k=1
1
p(Xi|wk)

,
WAIC
=
−1
n
n
X
i=1
log
 1
K
K
X
k=1
p(Xi|wk)

+ Vn,
Vn
=
1
n
n
X
i=1
h 1
K
K
X
k=1

log p(Xi|wk)
2
−
 1
K
K
X
k=1
log p(Xi|wk)
2i
,
where, in calculation of Vn, (K/(K −1))Vn is more appropriate than Vn, be-
cause it estimates the sum of the variances of log p(Xi|wk) over the posterior
distribution.
Remark 58. In order to calculate the above observables, we need
{p(Xi|wk); i = 1, 2, ..., n, k = 1, 2, ..., K}.
Several softwares have parallel computation architectures. In such a case,
for every parameter wk, the set
p(X1|wk),
p(X2|wk),
· · ·
p(Xn|wk)
can be simultaneously calculated. Also for every Xi, the set
p(Xi|w1),
p(Xi|w2),
· · ·
p(Xi|wK)
can be simultaneously calculated. Once {p(Xi|wk)} is obtained, then the
above computation is not so heavy in general. For neural networks and nor-
mal mixtures, this method is recommended for reducing the computational
costs.
7.3.2
Numerical Free Energy
Even if the posterior parameters {wk} are obtained, it is not enough to
numerically estimate the free energy or the minus log marginal likelihood.
Here we study a method to calculate them.
Deﬁnition 24. Let β > 0. The average of an arbitrary function f(w) over
the generalized posterior distribution is deﬁned by
E(β)
w [f(w)] =
Z
f(w)ϕ(w)
n
Y
i=1
p(Xi|w)βdw
Z
ϕ(w)
n
Y
i=1
p(Xi|w)βdw
.

7.3. NUMERICAL APPROXIMATION OF OBSERVABLES
227
Then the case β = 1 is equal to the posterior average, E(1)
w [ ] = Ew[ ].
Theorem 23. By using the minus log likelihood function,
Ln(w) = −1
n
n
X
i=1
log p(Xi|w).
The free energy or the minus log marginal likelihood is given by
Fn =
Z 1
0
E(β)
w [nLn(w)]dβ.
Proof. Let us deﬁne a function F(β)
Fn(β) = −log
Z
ϕ(w)
n
Y
i=1
p(Xi|w)βdw.
Then Fn(0) = 0 and
Fn = Fn(1).
By using,
∂
∂β
 n
Y
i=1
p(Xi|w)
β
= log
 n
Y
i=1
p(Xi|w)
 n
Y
i=1
p(Xi|w)
β
,
it follows that
Fn(1)
=
Z 1
0
dβ ∂F
∂β (β)
=
Z 1
0
dβ
Z
(nLn(w)) ϕ(w)
n
Y
i=1
p(Xi|w)βdw
Z
ϕ(w)
n
Y
i=1
p(Xi|w)βdw
,
which shows the theorem.
A calculation method of the free energy is derived by the same method
as the above theorem.
Let {βk; k = 0, 1, ..., J} be a sequence,
0 = β0 < β1 < · · · < βJ = 1.

228
CHAPTER 7. MARKOV CHAIN MONTE CARLO
Since Zn(0) = 1,
Zn(1)
=
J−1
Y
j=0
Zn(βk+1)
Zn(βk)

=
J−1
Y
j=0
E(βk)
w
h
e−(βk+1−βk)nLn(w)i
,
(7.18)
The free energy is given by
Fn(1)
=
−log Zn(1)
=
−
J−1
X
j=0
log E(βk)
w
h
e−(βk+1−βk)nLn(w)i
.
(7.19)
Here we need the posterior distribution for β1, ..., βJ−1
E(β1)[ ], E(β2)[ ], ..., E(βJ−1)[ ]
which can be obtained by the parallel tempering.
Remark 59. This method sometimes involves heavy computational costs. If
the posterior distribution can be approximated by some normal distribution,
then eq.(4.57) can be applied, otherwise WBIC can be employed, however,
the diﬀerence between the free energy and WBIC is log log n or constant
order. If minimizing the free energy according to a hyperparameter, then
the derivative of Fn by the hyperparameter can be calculated for the smaller
computational cost.
Remark 60. By using a probability density function,
p(w) = 1
Z ϕ(w) exp(−nLn(w)),
the expectation Ew[
] is deﬁned by p(w), Then
Z =
1
Ew[exp(nLn(w))].
However, this method is not appropriate for calculating Z because exp(nLn(w))
takes the large values at the small p(w).

7.4. PROBLEMS
229
-2
-1
0
1
2
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
o: Start, *:end
-2
-1
0
1
2
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
o: Start, *:end
Figure 7.3: Examples of trajectories by Hamiltonian equation. The trajec-
tories depend on initial conditions. The label ‘o’ and ‘*’ show the start and
end points respectively.
7.4
Problems
1. Let us study a probability density on W = [−2, 2] × [−1, 1] deﬁned by
p(u, v) ∝exp(−nv2(u + 1)2(u −1)4).
Then the set of all points which attain the maximum of p(u, v) is
W0 = {(u, v) ∈W v(u + 1)(u −1) = 0}.
Prove that, when n →∞, this distribution coverges to δ(u−1)δ(v). Explain
why it does not coverge to the all neighborhoods of W0.
2. For the same Hamiltonian function used in Example 51, the trajectories
of Hamiltonian equation are shown in Figure 7.3. Explain the reason why
Hamiltonian Monte Carlo can cover the entire parameter set.
3. In Example 52, the posterior distributions of the parameter a are not
displayed. For each case, explain the shape of the posterior distribution of
a. Also answer whether it is localized or not.


Chapter 8
Information Criteria
In the foregoing chapters, we derived the theoretical behaviors of Bayesian
observables for a given set of a true distribution, a statistical model, and
a prior, (q(x), p(x|w), ϕ(w)). In the real world, we do not know the true
distribution q(x), hence we need methods to estimate observables without
any information about q(x). Information criteria are made to overcome such
problems. In this section we explain several information criteria from the
two viewpoints, model selection and hyperparameter optimization. In each
viewpoint, the properties of the generalization loss and the free energy or
the minus log marginal likelihood are investigated. This chapter consists of
the following contents.
• Model Selection
– Generalization Loss: CV, AIC, TIC, DIC, WAIC
– Free Energy: F, BIC, WBIC
• Hyperparameter optimization
– Generalization Loss: CV, WAIC
– Free Energy: F, DF
8.1
Model Selection
In this section we study a model selection problem. When we have sev-
eral candidate models and need to select one of them, the model selection
problem occurs. There are two methods in model selection, minimizing the
231

232
CHAPTER 8. INFORMATION CRITERIA
generalization loss and the free energy. The aim of minimizing the general-
ization loss is equivalent to minimizaing the Kullback-Leibler distance from
the true density and the predictive one, whereas that of the minimizing the
free energy is to maximize the posterior probability of a statistical model
and a prior for a given set of data.
8.1.1
Criteria for Generalization Loss
Let us introduce the deﬁnitions of several information criteria which are used
for estimation of the generalization loss. Since the generalization losses for
Bayesian, maximum likelihood, maximum a posteriori, and posterior mean
methods are diﬀerent, we have to understand which generalization loss an
information criterion estimates.
Remark 61. In this book, the information criteria are deﬁned as estimators
of the generalization loss
−EX[log ˆp(X)],
(8.1)
where ˆp(x) is the estimated probability density of x by a statistical esti-
mation method. Since the original Akaike information criterion AIC was
deﬁned to estimate
−2n × EX[log ˆp(X)],
(8.2)
resulting that many information criteria were normalized so that they es-
timate the same scale loss as AIC. If one needs information criteria which
have the same scale loss as AIC, 2n times values shown in this book should
be used. If eq.(8.1) is used, then the diﬀerence between candidate models is
measured by the scale according to the Kullback-Leibler distance, whereas,
if eq.(8.2) is used, then it is measured by the scale according to the number
of parameters.
Deﬁnition 25. The leave-one-out cross validation criterion CV and the
importance sampling cross validation criterion ISCV are respectively deﬁned
by
CV
=
−1
n
n
X
i=1
log E(−i)
w
[p(Xi|w)],
(8.3)
ISCV
=
1
n
n
X
i=1
log Ew[1/p(Xi|w)],
(8.4)
where Ew[ ] and E(−i)
w
[ ] show the ordinary posterior average and the poste-
rior average leaving Xi out, respectively. Both criteria estimate the Bayesian

8.1. MODEL SELECTION
233
generalization loss, if {Xi} are independent. If the posterior distributions in
the above deﬁnitions are exactly realized and the averages are ﬁnite, then
CV = ISCV. However, if they are numerically approximated, for example
by Markov Chain Monte Carlo, then CV ̸= ISCV. In order to calculate
CV, all posterior distributions using Xn \ Xi for i = 1, 2, ...n are necessary,
whereas ISCV can be calculated by one posterior distribution using Xn.
Deﬁnition 26. The Akaike information criteria (AIC) and that for Bayes
(AICb) are deﬁned for the maximum likelihood and Bayesian methods re-
spectively,
AIC
=
−1
n
n
X
i=1
log p(Xi| ˆw) + d
n,
(8.5)
AICb
=
−1
n
n
X
i=1
log Ew[p(Xi|w)] + d
n,
(8.6)
where ˆw is the maximum likelihood estimator. The Takeuchi information
criteria (TIC) and that for Bayes (TICb) are deﬁned for the maximum like-
lihood and Bayesian methods, respectively,
TIC
=
−1
n
n
X
i=1
log p(Xi| ˆw) + 1
ntr(I( ˆw)J( ˆw)−1),
(8.7)
TICb
=
−1
n
n
X
i=1
log Ew[p(Xi|w)] + 1
ntr(I(w)J(w)−1),
(8.8)
where w = Ew[w] and
I(w)
=
1
n
n
X
i=1
∇log p(Xi|w)(∇log p(Xi|w))T ,
(8.9)
J(w)
=
−1
n
n
X
i=1
∇2 log p(Xi|w).
(8.10)
Note that the original AIC and TIC are criteria for the generalization loss of
the maximum likelihood method, whereas AICb and TICb are their modiﬁ-
cations for Bayesian estimation. In general, the generalization loss of Bayes
is diﬀerent from that of the maximum likelihood method and AIC ̸= AICb
and TIC ̸= TICb.

234
CHAPTER 8. INFORMATION CRITERIA
Deﬁnition 27. The deviance information criterion (DIC) is deﬁned by
DIC
=
1
n
n
X
i=1
log p(Xi|w) −2
n
n
X
i=1
Ew[log p(Xi|w)],
(8.11)
where w = Ew[w]. It seems that DIC is made for estimating the gener-
alization loss of p(x|w) rather than the predictive distribution Ew[p(x|w)].
However, it might be employed for Bayesian or the maximum a posteriori
method. The widely applicable information criterion (WAIC) is deﬁned by
WAIC
=
−1
n
n
X
i=1
log Ew[p(Xi|w)] + 1
n
n
X
i=1
Vw[log p(Xi|w)], (8.12)
which estimates the generalization loss of the predicitive density.
The behaviors of information criteria depend on the condition of a true
distribution q(x), a statistical model p(x|w), and a prior ϕ(w). Let us con-
sider (A) a regular and realizable case, (B) a egular and unrealizable case,
and (C) a nonregular case.
(A) Regular and Realizable Case
If a true distribution is realizable by and regular for a statistical model,
and if the posterior distribution can be approximated by some normal distri-
bution, the generalization and training losses by Bayes, maximum a poste-
riori, posterior mean, and the maximum likelihood methods have the same
asymptotic expansion as
E[Gn]
=
L(w0) + d
2n + o(1/n),
E[Tn]
=
L(w0) −d
2n + o(1/n),
where d is the dimension of the parameter. In this case an arbitrary criterion
of CV, ISCV, AIC, AICb, TIC, TICb, DIC, and WAIC satisﬁes
E[Criterion]
=
L(w0) + d
2n + o(1/n).
(8.13)
Hence arbitrary information criteria can be employed. The asymptotic stan-
dard deviations of all criteria are also equal to each other.
(B) Regular and Unrealizable Case

8.1. MODEL SELECTION
235
If a true distribution is regular for but unrealizable by a statistical model,
we deﬁne
ν0 = 1
2tr(I0J−1
0 ),
where
I0
=
Z
∇log p(Xi|w0)(∇log p(Xi|w0)T dx,
J0
=
−
Z
∇2 log p(Xi|w0)dx.
If a true distribution is realizable by a statistical model, then ν0 = d/2. If
the posterior distribution can be approximated by some normal distribu-
tion, then the average generalization and training losses of Bayes and the
maximum likelihood methods are
E[Gn]
=
L(w0) + d
2n + o(1/n),
(8.14)
E[Tn]
=
L(w0) + d −4ν0
2n
+ o(1/n),
(8.15)
E[Gn(ML)]
=
L(w0) + ν0
n + o(1/n),
(8.16)
E[Tn(ML)]
=
L(w0) −ν0
n + o(1/n),
(8.17)
where Gn(ML) and Tn(ML) are the generalization and training losses of the
maximum likelihood method, respectively. The generalization and training
losses of the maximum a posteriori and posterior mean methods are asymp-
totically equal to those of the maximum likelihood.
The averages of the cross validations are equal to the generalization loss
asymptotically,
E[CV]
=
L(w0) + d
2n + o(1/n),
(8.18)
E[ISCV]
=
L(w0) + d
2n + o(1/n).
(8.19)
Since E[Tn] = L(w0) + (d −4ν0)/(2n),
E[AIC]
=
L(w0) + d −ν0
n
+ o(1/n),
(8.20)
E[AICb]
=
L(w0) + 3d −4ν0
2n
+ o(1/n).
(8.21)

236
CHAPTER 8. INFORMATION CRITERIA
By the deﬁnitions of TIC and TICb,
E[TIC]
=
L(w0) + ν0
2n + o(1/n),
(8.22)
E[TICb]
=
L(w0) + d
2n + o(1/n).
(8.23)
By using eq.(4.55) and eq.(4.56),
E[DIC]
=
L(w0) + 3d −4ν0
2n
+ o(1/n),
(8.24)
E[WAIC]
=
L(w0) + d
2n + o(1/n).
(8.25)
Therefore, CV, ISCV, TICb, and WAIC can be used for estimating the
Bayesian generalization loss. To estimate the generalization loss of the max-
imum likelihood method, TIC is available.
(C) Nonregular Case
If a true distribution is not regular for a statistical model, let λ and ν
be the real log canonical threshold and a singular ﬂuctuation deﬁned by
λ
=
Real Log Canonical Threshold,
(8.26)
ν
=
1
2Eξ[Fluc(ξ)].
(8.27)
Also let µ be a constant deﬁned by Theorem 19. Then
E[Gn]
=
L(w0) + λ
n + o(1/n),
(8.28)
E[Tn]
=
L(w0) + λ −2ν
n
+ o(1/n),
(8.29)
E[Gn(ML)]
=
L(w0) + µ
n + o(1/n),
(8.30)
E[Tn(ML)]
=
L(w0) −µ
n + o(1/n).
(8.31)
In general, µ >> λ, hence Bayesian estimation attains the smaller gen-
eralization loss than the maximum likelihood, maximum a posteriori, and
posterior mean methods. In this case, the average cross validation loss is
equal to the generalization loss,
E[CV]
=
L(w0) + λ
n + o(1/n),
(8.32)
E[ISCV]
=
L(w0) + λ
n + o(1/n).
(8.33)

8.1. MODEL SELECTION
237
By the deﬁnition of AIC and AICb,
E[AIC]
=
L(w0) + d −µ
n
+ o(1/n),
(8.34)
E[AICb]
=
L(w0) + λ −2ν + d
n
+ o(1/n).
(8.35)
Since TIC and TICb are undeﬁned because J(w) is not invertible,
E[TIC]
=
Undeﬁned,
(8.36)
E[TICb]
=
Undeﬁned.
(8.37)
The posterior average parameter Ew[w] is not in the neighborhood of the
optimal parameter set, hence there exists C > 0 such that
E[DIC]
=
L(w0) + C + o(1),
(8.38)
E[WAIC]
=
L(w0) + λ
n + o(1/n).
(8.39)
In this case, the Bayes generalization loss is estimated by the cross valida-
tion and WAIC. Note that in nonregular cases, any information criterion is
not yet known which can estimate the generalization loss of the maximum
likelihood, maximum a posteriori, and posterior mean methods, because the
posterior distribution is far from any normal distribution. It seems that the
constant µ cannot be estimated because it depends on the optimal parameter
w0.
Remark 62. The above results hold for the assumption that a sample Xn
consists of independent sample points. For a case when {Y n} is condition-
ally independent for a given xn, then information criteria can estimate the
generalization loss if it can in independent cases, whereas the cross vali-
dation criterion cannot. For example, the cross validation loss cannot be
employed in a linear prediction of time series, whereas information criteria
can be.
Remark 63. From the mathematical point of view, the information criteria
need asymptotic condition n →∞. In fact, AIC, AICb, TIC, TICb, and DC
require the asymptotic normality, resulting that the sample size n should be
large enough. However, WAIC does not require the asymptotic normality,
hence it can estimate the generalization loss even if n is not so large. In
many singular statistical models, WAIC can estimate the generalization loss
even if n is small experimentally.

238
CHAPTER 8. INFORMATION CRITERIA
Example 53. Let x ∈R2 and N(x) be a normal distribution on R2 whose
average is zero and covariance matrix is the 2 × 2 identity matrix.
N(x) = 1
2π exp(−1
2∥x∥2).
We study a statistical model
p(x|a, b, c) = aN(x −b) + (1 −a)N(x −c),
where 0 ≤a ≤1 and b, c ∈R2 are parameters. For a prior of a, we adopt a
Dirichlet distribution,
ϕ1(a) ∝(a(1 −a))α−1,
where α > 0 is a hyperparameter. For a prior of (b, c),
ϕ2(b, c) ∝exp(−∥b∥2 + ∥c∥2
2B2
),
where B is a hyperparameter. Several cases are studied experimentally.
(1) Regular and realizable case.
q(x) = p(x|a0, b0, c0),
where a0 = 0.5, b0 = (2, 2), and c = (−2, −2).
(2) Regular and unrealizable case.
q(x) = a0N((x −b0)/σ)/σ + (1 −a0)N((x −c0)/σ)/σ,
where a0 = 0.5, σ = 0.8, b0 = (2, 2), and c0 = (−2, −2).
(3) Nonregular and realizable case.
q(x) = p(x|a0, b0, c0),
where a0 = 0, b0 = (0, 0), and c = (0, 0).
(4) Nonregular and unrealizable case.
q(x) = a0N((x −b0)/σ)/σ + (1 −a0)N((x −c0)/σ)/σ,
where a0 = 0, σ = 0.8, b0 = (0, 0), and c = (0, 0).
(5) Delicate case.
q(x) = a0N((x −b0)/σ)/σ + (1 −a0)N((x −c0)/σ)/σ,

8.1. MODEL SELECTION
239
Cases
G
ISCV
AICb
DIC
WAIC
(1) Regular
Ave
0.0254
0.0254
0.0251
0.0247
0.0254
Realizable
Std
0.0169
0.0162
0.0164
0.0162
0.0162
(2) Regular
Ave
0.1089
0.1043
0.1184
0.1110
0.1043
Unrealizable
Std
0.0124
0.0362
0.0381
0.0372
0.0362
(3) Nonreg.
Ave
0.0129
0.0160
0.0418
0.0034
0.0158
Realizable
Std
0.0085
0.0088
0.0118
0.0283
0.0088
(4) Nonreg.
Ave
0.0983
0.1036
0.1409
0.1049
0.1036
Unreal.
Std
0.0067
0.0399
0.0412
0.0455
0.0399
(5) Delicate
Ave
0.0384
0.0384
0.0479
0.0001
0.0387
Std
0.0175
0.0239
0.0232
0.0537
0.0241
(6) Unbal.
Ave
0.0276
0.0255
0.0343
-0.1618
0.0225
Std
0.0169
0.0267
0.0156
0.3568
0.0235
Table 8.1: Experimental results in Example 53. In the table, averages and
standard deviations of normalized values G-S, ISCV-Sn, AICb -Sn, DIC -Sn,
and WAIC-Sn are displayed.
where a0 = 0.5, σ = 0.95, b0 = (0.5, 0.5), and c = (−0.5, −0.5).
(6) Unbalanced case.
q(x) = a0N(x −b0) + (1 −a0)N(x −c0),
where a0 = 0.01, b0 = (2, 2), and c = (−2, −2).
In each case, the average and empirical entropies of the true distributions
are deﬁned by
S0
=
−
Z
q(x) log q(x)dx,
S0n
=
−1
n
n
X
i=1
log q(Xi).
For the case n = 100, the posterior distributions were built by the Gibbs
sampler, in which the burn-in was 200 and the number of posterior param-
eters were 1000. Hyperparameters were set as α = 0.5 and B = 10. We
conducted 100 independent experiments for each condition. In Table 53,
‘Ave’ and ‘Std’ show their averages and standard deviations of Gn −S,
ISCV −Sn, AICb −Sn, DIC −Sn, and WAIC−Sn.
(1) If a true distribution was realizable by and regular for a statistical model,
then all information criteria estimated the generalization loss well.

240
CHAPTER 8. INFORMATION CRITERIA
(2) If a true distribution was unrealizable by and regular for a statistical
model, then AIC overestimated the generalization loss.
(3) through (5) In nonregular and delicate cases, ISCV and WAIC were more
accurate than AIC and DIC.
(6) In an unbalanced case, ISCV, WAIC, and AIC were more accurate than
DIC. Note that a few sample points were generated from the ﬁrst component.
As an unbiased estimator, ISCV was better than WAIC and AIC, however,
the variance of ISCV was larger than WAIC and AIC. AIC had the smallest
variance. Their intervals [m −2σ, m + 2σ] where m and σ are averages and
standard deviations were
G −S
:
[−0.0062, 0.614]
ISCV −Sn
:
[−0.0279, 0.0789]
AIC −Sn
:
[0.0031, 0.0655]
DIC −Sn
:
[−0.8754, 0.5518]
WAIC −Sn
:
[−0.0245, 0.0695]
Therefore, not only the cross validation loss but also information criteria
contain important information.
Example 54. Examples of model selections are shown in sections 2.4 and 2.5.
If a statistical model has hierarchical structure or hidden variables, then the
posterior distribution cannot be approximated by any normal distribution
in general, hence we can apply the cross validation and WAIC, but not
AIC or DIC. If we need a neural network with many hidden units or a
normal mixture with many components, the MCMC process sometimes fails
because of local minima. If such models have a few redundant hidden parts,
the MCMC rather easily attains the posterior distribution.
If Bayesian
estimation is applied to such statistical models, the generalization losses do
not increase much, hence we recommend a model which has a few redundant
parts.
8.1.2
Comparison of ISCV with WAIC
In typical experiments, ISCV is almost equal to WAIC. First, we show that
if a sample consists of independent random variables, then ISCV and WAIC
are asymptotically equivalent as random variables. Let Tn(α) be a function
deﬁned in eq.(3.11) in Deﬁnition 8.
Theorem 24. Assume that X1, X2, ..., Xn are independent and that
sup
|α|≤1

 d
dα
4
Tn(α)

=
Op( 1
n2 ).
(8.40)

8.1. MODEL SELECTION
241
Then the following equation holds,
ISCV = WAIC + Op( 1
n2 ).
(8.41)
Proof. ISCV is deﬁned by
ISCV = 1
n
n
X
i=1
log Ew[ 1/p(Xi|w) ].
By the deﬁnition of Tn(α) in eq.(3.11)
ISCV = Tn(−1).
By using the mean value theorem, there exists |β∗| < 1 such that
Tn(−1)
=
−T ′
n(0) + 1
2T ′′
n (0) −1
6T (3)
n
(0) + 1
24T (4)
n
(β∗).
On the other hand WAIC is deﬁned by
WAIC
=
Tn + Vn = −Tn(1) + T ′′
n (0).
By using the mean value theorem, there exists |β∗∗| < 1 such that
−Tn(1)
=
−T ′
n(0) −1
2T ′′
n (0) −1
6T (3)
n
(0) −1
24T (4)
n
(β∗∗).
Hence
WAIC = −T ′
n(0) + 1
2T ′′
n (0) −1
6T (3)
n
(0) −1
24T (4)
n
(β∗∗),
which completes the theorem.
Remark 64. (1) This theorem holds, even if the posterior distribution cannot
be approximated by any normal distribution. By the proof, it is also derived
that
ISCV = WAIC + 1
12T (4)
n
(0) + op(n−2).
By Theorem 26, if the posterior distribution can be approximated by some
normal distribution, then T (4)
n
(0) = op(n−2), resulting that the diﬀerence
between ISCV and WAIC is smaller than Op(n−2).
(2) Assume that there exist constants g1 and g2 which satisfy
E[Gn]
=
g1 + g2
n + o(1/n).

242
CHAPTER 8. INFORMATION CRITERIA
8
10
12
14
10
15
20
25
Figure
8.1:
The
horizontal
and
vertical
lines
show
the
pairs
of
(log(radius), log(mass)) in the solar system. The circle corresponds to the
sun, which is the leverage sample point. In fact, the regression line esti-
mated by including the sun is given by the dotted line, whereas regression
by not including it is shown by the solid line.
By the deﬁnition
E[CV] = E[Gn−1].
Hence
E[CV] −E[Gn] = E[Gn−1] −E[Gn] = O(1/n2).
By the above theorem
E[WAIC] −E[Gn] = O(1/n2).
Therefore, CV and WAIC have asymptotically the same approximators of
the generalization loss, if a sample consists of independent random variables.
Remark 65. (Comparison of ISCV and WAIC) In the numerical experiments,
the diﬀerence between ISCV and WAIC is very small in many cases, how-
ever, sometimes they are diﬀerent. First, if a sample {(Xi, Yi)} is dependent,
then the averages of CV and ISCV are diﬀerent from that of the general-
ization loss. On the other hand, the averages of WAIC are asymptotically
equal to those of the generalization loss if a sample consists of conditionally
independent variables. Second, in statistical estimation of the conditional

8.1. MODEL SELECTION
243
probability q(y|x), if n is not enough large to ensure
q(x) ≈1
n
n
X
i=1
δ(x −Xi),
then ISCV is diﬀerent from WAIC. Thirdly, if a sample contains a leverage
sample point, then variance of ISCV diverges which is diﬀerent from WAIC.
The third sample can be understood as a special case of the second one. If a
leverage sample point is contained in a sample, then the data analyst should
reconsider whether such a point should be included in a sample. A leverage
sample point can be found by the following procedure. If ISCV is not equal
to WAIC, then for every sample point Xi, the partial functional variance
Vw[log p(Yi|Xi, w)]
is calculated. If it is larger than the others, then Xi is a leverage sample
point.
Remark 66. The importance sampling cross validation loss diverges if a
leverage sample point is contained [57] [20]. Recently, a new method for nu-
merical approximation of the cross validation was devised in which the pos-
terior distribution is replaced by the Pareto distribution [76]. This method
gives the approximation of the cross validaiton loss. WAIC is not an approx-
imation of the cross validation loss but is an estimator of the generalization
loss. If a sample is dependent, then the cross validation loss is not an esti-
mator of the generalization loss.
Example 55. (Leverage sample point) Let {Xi} be the {log(radius)} of stars
in the solar system, Mercury, Venus, Earth,.., and {Yi} be {log(mass)}. If
we study a simple regression problem, Y = aX + b + noise, then the datum
of the sun is a leverage sample point. In Figure 8.1, the circle shows the
datum of the sun. A regression line without the sun is shown by the solid
line whereas regression with the sun is shown by the dotted line. The (X, Y )
of the sun may not be estimated from other data, hence the cross validation
fails. Even in such a case, information criteria AIC and WAIC can be used
to estimate the statistical estimation error.
Example 56. (Classiﬁcation problem) Let us study a classiﬁcation problem
q(z|x, y) using a neural network, where (x, y) ∈R2 and the true output z is
set by a function,
z =
 1
y > sin(πx/2)
0
otherwise
.

244
CHAPTER 8. INFORMATION CRITERIA
-2
0
2
-2
-1
0
1
2
o  
o02
o  
*04
*  
o  
*  
o  
*  
*  
o  
o  
*  
o  
o  
o  
*  
o  
*  
*  
*  
o  
o  
*  
o  
o  
*  
o28
*  
*30
*  
*  
*33
o  
o  
*  
o  
*  
*  
o  
o  
*  
*  
o  
*45
o  
*  
*  
o  
*  
o
o
o
*
*
o
*
o
*
*
o
o
*
o
o
o
*
o
*
*
*
o
o
*
o
o
*
o
*
*
*
*
*
o
o
*
o
*
*
o
o
*
*
o
*
o
*
*
o
*
-2
0
2
-2
-1
0
1
2
Figure 8.2: Classiﬁcation problem. Two categories in two dimensinal space
are classiﬁed by a neural network. The letters ’o’ and ’*’ show sample points
classiﬁed as one and zero. The solid and dotted lines show the estimated
and true boundaries. The sample points near the boundary are leverage
sample points.
A sample of 50 points is shown in Figure 8.2. The solid and dotted lines show
the estimated and true classiﬁcation boundary respectively. The letters ‘o’
and ‘*’ are sample points classiﬁed as one and zero by the true rule respec-
tively. A three-layered neural network which has input units M = 2, hidden
units H = 5, and an output unit N = 1 was employed for learn the classi-
ﬁcation rule. The posterior distribution is approximated by the Metropolis
method explained in the previous chapter.
In the classiﬁcation problem,
sample points near the boundary strongly aﬀect the statistical inference:
in fact, the classiﬁcation result for such a point is not estimated from the
other sample points. In Figure 8.2, several points which are displayed with
numbers are leverage sample points. The partial functional variance of the
ith sample point
Vi = Vw[log p(Xi|w)]
shows the strength of the sample point’s eﬀect. Figure 8.3 shows such {Vi}
for each i. The larger Vi shows that the ith sample point exerts more of
an eﬀect on the result. In Figure 8.3, samples 2, 4, 28, 30, 33, and 45 are
leverage samples.
Practical Advice. If one has a posterior parameter set generated by an
MCMC method, then it is easy to numerically calculate ISCV, AIC, DIC,
and WAIC. Hence the author recommends that all of them are calculated.

8.1. MODEL SELECTION
245
10
20
30
40
50
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Data Number
Functional Variance
Figure 8.3: Functional variance for each sample point. The horizontal line
shows the number of sample point in Figure 8.2. The vertical line shows
the partial functional variance Vi of each sample point. The leverage sample
points have large partial functional variances.
(1) If they are all equal, then they can be employed.
(2) If a statistical model has a hierarchical structure such as a normal mix-
ture and a neural network, and if ISCV = WAIC >> DIC, then the posterior
distribution is not localized. In this case, DIC is not appropriate.
(3) If ISCV ̸= WAIC, then there may exist a leverage sample point. A data
analyst had better reconsider whether such leverage sample point should
be included or not. In conditional independent problems such as time series
analysis, ISCV does not correspond to the generalization loss whereas WAIC
does.
8.1.3
Criteria for Free Energy
In this subsection, we study the model selection problem by the free energy
or the minus log marginal likelihood. If we know the true distribution q(x)
and the real log canonical threshold and its multiplicity (λ, m), then the
asymptotic free energy is given by
Fn = nLn(w0) + λ log n −(m −1) log log n + Op(1),
where w0 is the optimal prameter. However, w0, λ, and m depend on the
true distribution q(x), this asymptotic expansion cannot be used directly for
estimating Fn.

246
CHAPTER 8. INFORMATION CRITERIA
Deﬁnition 28. The free energy that is numerically calculated by eq.(7.19)
is denoted by F(MCMC).
F(MCMC)
=
−
J−1
X
j=0
log E(βk)
w
h
e−(βk+1−βk)nLn(w)i
.
The free energy calculated by using the regular assumption and eq.(4.57) is
denoted by F(REG),
F(REG)
=
−
n
X
i=1
log p(Xi| ˆw) + d
2 log n
+1
2 log det J( ˆw) −log ϕ( ˆw) −1
2 log(2π),
(8.42)
where ˆw is the maximum likelihood estimator. The Schwarz BIC is obtained
by removing the constant order term from F(REG),
BIC = −
n
X
i=1
log p(Xi| ˆw) + d
2 log n.
The widely applicable Bayesian information criterion WBIC is
WBIC = −E(1/ log n)
w
h n
X
i=1
log p(Xi|w)
i
,
where E(1/ log n)
w
[ ] is the posterior average using β = 1/ log n,
E(β)
w [f(w)] =
Z
n
Y
i=1
f(w) p(Xi|w)βϕ(w)dw
Z
n
Y
i=1
p(Xi|w)βϕ(w)dw
.
Comparison of F(MCMC), F(REG), BIC, and WBIC. If a true model is
regular for a statistical model, then all criteria can be employed. In such a
case,
F(MCMC)
=
Fn + ε,
F(REG)
=
Fn + op(1),
BIC
=
Fn + Op(1),
WBIC
=
Fn + Op(1),
WBIC
=
BIC + op(1),

8.1. MODEL SELECTION
247
where ε depends on numerical calculation. If a true model is not regular for
a statistical model, then
F(MCMC)
=
Fn + ε,
WBIC
=
Fn + Op((log n)1/2),
(8.43)
where the second equation is proved in [85]. The mathematical structure is
explained in Theorem 25. Note that in Thereom 25, the function H(w) has
no random ﬂuctuation. In the case when H(w) is a stochastic process, then
the reﬁned proof shows eq.(8.43).
Theorem 25. Assume that H(w) is an analystic function of w and ϕ(w)
is a C∞class function. Let F1 and F2 be
F1
=
−log
Z
exp(−nH(w))ϕ(w)dw,
F2
=
Z
nH(w) exp(−(n/ log n)H(w))ϕ(w)dw
Z
exp(−(n/ log n)H(w))ϕ(w)dw
.
Then, even if the Hessian matrix ∇2H(w0) at a minimum point w0 is sin-
gular,
F1 −F2 = o(log n).
Proof. If the minimum value of H(w) is H0, and H1(w) = H(w) −H0,
F1
=
nH0 −log
Z
exp(−nH1(w))ϕ(w)dw,
F2
=
nH0 +
Z
nH1(w) exp(−(n/ log n)H1(w))ϕ(w)dw
Z
exp(−(n/ log n)H1(w))ϕ(w)dw
.
Hence we can assume H0 = 0 without loss of generality. The zeta function
of H(w) is deﬁned by
ζ(z) =
Z
H(w)zϕ(w)dw
(z ∈C).
Then we can derive
(1) In the region Re(z) > 0, ζ(z) is an analytic function of a complex variable
z.

248
CHAPTER 8. INFORMATION CRITERIA
(2) ζ(z) can be analytically continued to a unique meromorphic function
whose poles (−λ1) > (−λ2) >, ..., are all real and negative values. We deﬁne
mk as the order of the pole (−λk). Then ζ(z) has the Laurent expansion as
ζ(z) =
∞
X
k=1
mk
X
m=1
Ckm
(z + λk)m ,
where Ckm ∈C. The state density and partition functions are respectively
deﬁned by
v(t)
=
Z
δ(t −f(x))ϕ(x)dx
(0 < t < 1),
Z(n)
=
Z
exp(−nf(x))ϕ(x)dx
(n > 0).
Then it follows that
ζ(z)
=
Z 1
0
tz v(t) dt,
Z(n)
=
Z 1
0
exp(−nt) v(t) dt.
In other words, ζ(z) and Z(n) are the Mellin and Laplace transforms of
v(t), respectively. The following equation can be derived by mathematical
induction about m = 1, 2, ...
1
(z + λ)m =
1
(m −1)!
Z 1
0
tλ−1(log t)m−1 tz dt.
By using this equation and the Laurent expansion of ζ(z), we obtain the
asymptotic expansion,
v(t) =
∞
X
k=1
mk
X
m=1
Ckm
(m −1)!tλk−1(log t)m−1.
Therefore, the asymptotic expansion of Z(n) holds,
Z(n)
=
∞
X
k=1
mk
X
m=1
Ckm
(m −1)!
Z 1
0
tλk−1(log t)m−1 exp(−nt) dt
=
∞
X
k=1
mk
X
m=1
Ckm
(m −1)!
Z n
0
(t/n)λk−1(log(t/n))m−1 exp(−t) dt
n .

8.1. MODEL SELECTION
249
In the case n →∞, the largest order term is
Z(n) ∼= C11Γ(λ1)
(m −1)! · (log n)m1−1
nλ1
.
Hence
F1 = λ1 log n −(m1 −1) log log n + Const. + · · ·
On the other hand, by using β = n/ log n, we deﬁne
F21
=
Z 1
0
exp(−βt) nt v(t) dt,
F22
=
Z 1
0
exp(−βt) v(t) dt.
Then F2 = F21/F22. By using the same method as F1,
F21
∼=
C11Γ(λ1 + 1)
(m −1)!
· n(log β)m1−1
βλ1+1
,
F22
∼=
C11Γ(λ1)
(m −1)! · (log β)m1−1
βλ1
.
Then by Γ(λ1 + 1) = λ1Γ(λ1), it follows that
F2 ∼= λ1 log n,
which completes the theorem.
Example 57. A simple model selection experiment using WBIC was con-
ducted. Let x ∈R2, y ∈R. The input Xi was generated from the uniform
distribution of [−2, 2]2. The true distribution of Yi was set as p(y|x, w0)
where p(y|x, w0) was made by a neural network deﬁned by eq.(2.27) with
three hidden units H = 3. From this true distribution, n = 500 sample
points were generated. A prior was set by the normal distribution N(0, 102)
for each ujk and wkℓ. The 1000 posterior parameters were approximated
by a Metropolis method with the burn-in 1000 and sampling interval 200.
Figure 8.4 shows WBICs for a neural network with H = 1, 2, 3, 4, 5. As in a
ﬁgure, a true model could be chosen by WBIC.
Remark 67. In general, the asymptotic form of the free energy or the mi-
nus log marginal likelihood depends on a true distribution, since the real
log canonical threshold depends on the true distribution. Recently, a new
method was devised by which both the true distribution and the free energy
can estimated simultaneously using the real log canonical threshold [19].

250
CHAPTER 8. INFORMATION CRITERIA
0
2
4
6
3
3.5
4
4.5
5
5.5
6
Hidden Units
 
 
log(WBIC)
Figure 8.4: WBIC of neural networks. The horizontal line shows the number
of hidden units in a neural network, and the vertical line WBIC. By using
WBIC, a model selection according to the asymptotic free energy can be
realized.
8.1.4
Discussion for Model Selection
Let us study model selection problems from two diﬀerent points of view.
This discussion is based on Professor Akaike’s argument.
Artiﬁcial case. Assume that a true distribution is realizable by a statistical
model which is contained in the ﬁnite set of candidate models. Since such
a case is rare in the real world, it is called an artiﬁcial case. In the artiﬁcial
case, the minimal model by which a true distribution is realizable is called
the true model.
A model selection algorithm is called consistent, if the
probability that the selected model is equal to the true model converges to
one for n →∞. In general, model selection algorithms which employ the
cross validation loss, AIC, DIC, and WAIC are not consistent. The reason
why they are inconsistent is that random ﬂuctuation according to a sample
is in proportion to the diﬀerence of the generalization loss. On the other
hand, the model selection algorithm which is based on the free energy is
consistent, because the main order part log n is not a random variable but
a constant which is larger than the random ﬂuctuation. Therefore, in an
artiﬁcial case, the free energy is better than the generalization loss.
Natural case. Assume that we have candidate models, but, a true distri-

8.2. HYPERPARAMETER OPTIMIZATION
251
bution is not realizable by any statistical model whose parameter has ﬁnite
dimension. Almost all statistical problems in the real world are classiﬁed
into this case, hence are called the natural cases. In a natural case, if the
number of random variables increases, then the best model also becomes
more complex. Consistency has no meaning. A model selection algorithm
is called eﬃcient, if the average generalization loss of the selected model is
minimized among the candidate models. From the view point of eﬃciency,
the generalization loss is better than the free energy.
When we compare several model selection problems by computer simulation,
we often set a true distribution as an artiﬁcial case.
However, such an
experiment may be diﬀerent from the natural cases.
8.2
Hyperparameter Optimization
A parameter of a prior distribution is called a hyperparameter.
In this
section, we study several problems in hyperparameter optimization.
Remark 68. If a set of a statistical model p(x|w) and a prior ϕ(w|θ) is
prepared, one might think the hyperparameter θ could be automatically
optimized by intoducing the hyperprior distribution ϕ1(θ). However, it is
not true. If the hyperprior distribution is employed, then it strongly aﬀects
the optimal hyperparameter, resulting that the chosen hyperparameter is
not optimized but detemined by the choice of the hyperprior. In such a case
a prior
R
ϕ(w|θ)ϕ1(θ)dθ should be evaluated as a prior. Hence we need a
method how to evaluate (p(x|w), ϕ(w)). For example, in a nonparametric
Bayesian estimation, the Dirichlet hyperparameter α might be determined
by using the hyperprior, but it is not the automatically optimal one. Even
in nonparametric cases, the cross validation and WAIC can be employed to
evaluate the hyperparameter.
In this section, we study the general case
ϕ(w) ≥0,
but
Z
ϕ(w)dw
may be inﬁnite.
Even in such cases, we can use the same deﬁnition of the posterior distribu-

252
CHAPTER 8. INFORMATION CRITERIA
tion as the case
R
ϕ(w)dw = 1,
p(w|Xn) =
ϕ(w)
n
Y
i=1
p(Xi|w)
Z
ϕ(w)
n
Y
i=1
p(Xi|w)dw
,
because this deﬁnition does not require any normalizing condition of ϕ(w).
Hence the deﬁnitions of the generalization, cross validation, and training
losses are also invariant. However, the free energy should be redeﬁned by
Fn = −log
Z
n
Y
i=1
p(Xi|w)ϕ(w)dw + log
Z
ϕ(w)dw,
because, without the second term in the right hand side, Fn is an unbounded
function of ϕ.
Remark 69. (1) In the hyperparameter optimization problem about the
generalization loss, we admit cases when
R
ϕ(w)dw = ∞.
For example,
ϕ(w) = 1 on the unbounded parameter set W can be used in this section.
On the other hand, for the free energy,
R
ϕ(w)dw < ∞is necessary for ﬁnite
Fn.
That is to say, the generalization loss and the free energy have the
essential diﬀerence in preparing the set of priors.
(2) Let ˆw be the maximum likelihood estimator. Then, for an arbitrary w
n
Y
i=1
p(Xi|w) ≤
n
Y
i=1
p(Xi| ˆw).
Hence if there exists a sequence of priors {ϕk(w)} such that ϕk(w) →δ(w −
ˆw), then the inﬁmum value of Fn is attained by such a sequence, which
converges to the maximum likelihood method.
Therefore, when the free
energy is applied to the prior optimization, the set of candidate priors should
be set so as that such a sequence is not contained.
Example 58. The Dirichlet distribution
ϕ(a) ∝aα−1(1 −a)β−1,
converges to δ(a −a0) by
αk
=
ka0
βk
=
k(1 −a0)
and k →∞. Hence α and β should be bounded by some constant.

8.2. HYPERPARAMETER OPTIMIZATION
253
8.2.1
Criteria for Generalization Loss
In the model selection problem according to the generalization loss, we stud-
ied the cross validation, AIC, TIC, DIC, and WAIC. Since the eﬀect of the
prior choice to the generalization loss is weaker than that of the statistical
model, we need a precise tool to observe the diﬀerence of the small order. In
fact, neither AIC, TIC, nor DIC can be applied to prior evaluation. In this
subsection, we study the hyperparameter optimization by the cross valida-
tion and WAIC. If a true distribution is regular for a statistical model, then
we have the following theorem even if a true distribution is not realizable
by a statistical model.
Regular case. In regular cases, the eﬀect of the hyperparameter optimiza-
tion by the cross validation and WAIC are mathematically clariﬁed. Let
ϕ0(w) and ϕ(w) be arbitrary ﬁxed and candidate priors respectively. As a
typical case, ϕ0(w) ≡1 for all w ∈W can be chosen. The empirical log loss
function and the maximum a posteriori (MAP) estimator ˆw using ϕ0(w) are
respectively deﬁned by
Ln(w)
=
−1
n
n
X
i=1
log p(Xi|w) −1
n log ϕ0(w),
(8.44)
ˆw
=
arg min
w∈W Ln(w),
(8.45)
where either Ln(w) or ˆw does not depend on the candidate prior ϕ(w). If
ϕ0(w) ≡1, then ˆw is equal to the maximum likelihood estimator (MLE). The
average log loss function and the parameter that minimizes it are respectively
deﬁned by
L(w)
=
−
Z
q(x) log p(x|w)dx,
(8.46)
w0
=
arg min
w∈W L(w).
(8.47)
In this section, we use the following notations for simple description.
(1) A parameter is denoted by w = (w1, w2, ..., wk, ..., wd) ∈Rd.
(2) For an arbitrary function f(w) and nonnegative integers k1, k2, ..., km,
we deﬁne
(f)k1k2···km(w) =
∂m(f)
∂wk1∂wk2 · · · ∂wkm (w).
(8.48)
(3) We adopt Einstein’s summation convention and k1, k2, k3, ... are used for

254
CHAPTER 8. INFORMATION CRITERIA
such suﬃxes. For example,
Xk1k2Y k2k3 =
d
X
k2=1
Xk1k2Y k2k3.
In other words, if a suﬃx ki appears upper and lower, it means automatic
summation over ki = 1, 2, ..., d.
In this section, for each k1, k2, Xk1k2 =
Xk1
k2 = Xk1k2.
Deﬁnition. (Empirical mathematical relations between priors) For a ﬁxed
and candidate priors ϕ0(w) and ϕ(w), the prior ratio function is deﬁned by
φ(w) = ϕ(w)/ϕ0(w).
The empirical mathematical relation between two priors at a parameter w
is deﬁned by
M(φ, w)
=
Ak1k2(log φ)k1(log φ)k2 + Bk1k2(log φ)k1k2
+Ck1(log φ)k1,
(8.49)
where
Jk1k2(w)
=
Inverse matrix of (Ln)k1k2(w),
(8.50)
Ak1k2(w)
=
1
2Jk1k2(w),
(8.51)
Bk1k2(w)
=
1
2(Jk1k2(w) + Jk1k3(w)Jk2k4(w)Fk3,k4(w)),
(8.52)
Ck1(w)
=
Jk1k2(w)Jk3k4(w)Fk2k4,k3(w)
−1
2Jk1k2(w)Jk3k4(w)(Ln)k2k3k4(w)
−1
2Jk1k2(w)Jk3k4(w)Jk5k6(w)
×(Ln)k2k3k5(w)Fk4,k6(w),
(8.53)
and
Fk1,k2(w)
=
1
n
n
X
i=1
(log p(Xi|w))k1(log p(Xi|w))k2,
(8.54)
Fk1k2,k3(w)
=
1
n
n
X
i=1
(log p(Xi|w))k1k2(log p(Xi|w))k3.
(8.55)

8.2. HYPERPARAMETER OPTIMIZATION
255
Remark. Note that neither Ak1k2(w), Bk1k2(w), nor Ck1(w) depends on a
candidate prior ϕ(w). Therefore M(φ, w) is determined by only logφ as a
function of the candidate prior.
Deﬁnition. (Average mathematical relations of priors) The average math-
ematical relation M(φ, w) is deﬁned by the same manner as eq.(8.49) by
replacement
Jk1k2(w)
7→
Inverse matrix of E[(Ln)k1k2(w)],
(8.56)
(Ln)k1k2(w)
7→
E[(Ln)k1k2(w)],
(8.57)
(Ln)k1k2k3(w)
7→
E[(Ln)k1k2k3(w)],
(8.58)
Fk1,k3(w)
7→
E[Fk1k2(w)],
(8.59)
Fk1k2,k3(w)
7→
E[Fk1k2,k3(w)].
(8.60)
The following theorem shows the eﬀect of the choice of the candidate prior
by comparison of the ﬁxed prior.
Theorem 26. Let ϕ0(w) and ϕ(w) be ﬁxed and candidate priors respec-
tively. The prior ratio function is deﬁned by
φ(w) = ϕ(w)/ϕ0(w).
Let M(φ, w) and M(φ, w) be the empirical and average mathematical rela-
tions between ϕ(w) and ϕ0(w). As random variables,
CV(ϕ)
=
CV(ϕ0) + M(φ, ˆw)
n2
+ Op( 1
n3 ),
(8.61)
WAIC(ϕ)
=
WAIC(ϕ0) + M(φ, ˆw)
n2
+ Op( 1
n3 ),
(8.62)
CV(ϕ)
=
WAIC(ϕ) + Op( 1
n3 ).
(8.63)
Their expected values satisfy
E[CV(ϕ)]
=
E[CV(ϕ0)] + M(φ, w0)
n2
+ O( 1
n3 ),
(8.64)
E[WAIC(ϕ)]
=
E[WAIC(ϕ0)] + M(φ, w0)
n2
+ O( 1
n3 ),
(8.65)
where
M(φ, ˆw)
=
M(φ, w0) + Op( 1
n1/2 ),
(8.66)
E[M(φ, ˆw)]
=
M(φ, w0) + O( 1
n).
(8.67)

256
CHAPTER 8. INFORMATION CRITERIA
On the other hand, the generalization loss satisiﬁes
G(ϕ)
=
G(ϕ0) + 1
n( ˆwk1 −(w0)k1)(log φ)k1( ˆw) + Op( 1
n2 )
=
G(ϕ0) + Op( 1
n3/2 ),
(8.68)
E[G(ϕ)]
=
E[G(ϕ0)] + M(φ, w0)
n2
+ O( 1
n3 ).
(8.69)
For the proof of this theorem, see [86]. If a candidate prior has a hy-
perparameter θ, which is written as ϕ(w) = ϕ(w|θ), the following facts are
derived by this theorem.
(1) The hyperparameters that minimize E[CV], E[WAIC], and E[Gn] are
symptotically equal to each other.
(2) The hyperparameters that minimize CV, WAIC, and E[Gn] are asymp-
totically equal to each other. Hence by minimizing CV or WAIC, we can
ﬁnd the optimal hyperparameter that minimizes E[Gn] asymptotically.
(3) [Important point]. The hyperparameters that minimize the random
variable Gn and the average E[Gn] are not equal to each other even asymp-
totically. In general they are far from each other and one does not converge
to the other even if n tends to inﬁnity. By minimizing CV or WAIC, we can
ﬁnd the optimal hyperparameter that minimizes E[Gn], but we cannot ﬁnd
the optimal hyperparameter that minimizes Gn.
Hence by determining the hyperparameter by minimizing the cross val-
idation or WAIC, E[Gn] is asymptotically minimized but Gn is not. (see
Example. 59). It is strongly conjectured that there is no observable which
can estimate the random variable Gn for an arbitrary true distribution, be-
cause we do not know the true distribution. This is the conjecture about
the limit of statistical estimation.
Remark 70. Since E[CV(ϕ0)] of Xn is equal to E[G(ϕ0)] of Xn−1 and
1
n −1 −1
n = 1
n2 + o( 1
n2 ),
it immediately follows from Theorem 26 that
E[G(ϕ)]
=
E[G(ϕ0)] + M(φ, w0)
n2
+ o( 1
n2 ),
(8.70)
E[CV(ϕ)]
=
E[G(ϕ0)] + d/2 + M(φ, w0)
n2
+ o( 1
n2 ),
(8.71)
E[WAIC(ϕ)]
=
E[G(ϕ0)] + d/2 + M(φ, w0)
n2
+ o( 1
n2 ).
(8.72)

8.2. HYPERPARAMETER OPTIMIZATION
257
Nonregular case. In nonregular cases, determination of the hyperparame-
ter is the essential procedure of Bayesian inference. However, mathematical
analysis for this case is still diﬃcult, because nonregular statistical models
have phase transitions according to the hyperparameter controlling. For es-
timating the averages, the cross validation and WAIC can be employed. See
Example 67.
8.2.2
Criterion for Free Energy
For the purpose of the minimization of the free energy, neither BIC nor
WBIC can be applied, because they do not estimate the constant order
term. The values F(REG) and F(MCMC) can be used in regular and all
cases, respectively. If F(REG) is employed, then the hyperparameter that
minimizes the F(REG) is equal to the one that maximizes ϕ( ˆw). In other
words, the hyperparameter is optimized so that the prior at the maximum
likelihood estimator is maximized.
For the hyperparameter optimization, there is an another method. Let
Fn(α) be the free energy for a prior ϕ(w|α), where α is a hyperparameter.
Then
dFn
dα
=
Z 
−∂
∂α log ϕ(w|α)

ϕ(w|α)
n
Y
i=1
p(Xi|w)dw
Z
ϕ(w|α)
n
Y
i=1
p(Xi|w)dw
=
−Ew
h ∂
∂α log ϕ(w|α)
i
.
Hence using the increase and decrease table, the hyperparameter that min-
imizes Fn(α) can be found. In order to calculate Fn(MCMC), we need all
posterior distributions for many inverse temperatures, whereas dFn/dα can
be calculated by one MCMC process.
Example 59. By using a statistical model which enables us to exactly cal-
culate the generalization and cross validation losses and the free energy, let
us study the hyperparameter optimization problem numerically. We use the
normal distribution and its conjugate prior deﬁned by eqs.(2.1) and (2.2).
Let n = 200. The hyperparameter (φ1, φ2, φ3) in the region
0 < φ1 < 10
is examined, where φ2 = 0 and φ3 = 1. We conducted 100 independent
experiments. In Figure 8.5, the horizontal line shows the value φ1.

258
CHAPTER 8. INFORMATION CRITERIA
0
5
10
0
2
4
6
x 10
-3
Hyperparameter
Generalization Error 
0
5
10
0
1
2
3
4
x 10
-4
Hyperparameter
Cross Validation
0
5
10
0
1
2
3
Hyperparameter
Free Energy
0
5
10
5.25
5.3
5.35
5.4
5.45
x 10
-3
Hyperparameter
Average Generalization Error
Figure 8.5: Hyperparameter optimization. The horizontal lines in all ﬁgures
show the value of the hyperparameter. The vertical lines show the average
generalization error, the generalization error, the cross validation error, and
the free energy. The minimum points of the free energy is not equal to that
of the average generalization error. The minimum point of the generalization
error has very large variance, and thus it is not equal to that of the average
generalization error. The minimum point of the cross validation error is
asymptotically equal to that of the average generalization error.

8.2. HYPERPARAMETER OPTIMIZATION
259
(1) Upper left: The average generalization error for a given hyperparameter.
(2) Upper right: Generalization errors for a given hyperparameter.
(3) Lower left: Cross validation losses for a given hyperparameter.
(4) Lower right: Free energies for a given hyperparameter.
In (2), (3), and (4), each function of a hyperparameter is displayed by cali-
bration that the minimum value is equal to zero. The hyperparameter that
minimizes the average generalization loss is almost equal to φ1 = 5. Each
hyperparameter that minimizes each generalization loss strongly depends on
a sample Xn. It almost always lies on the outside of 0 < φ1 < 10. Note that
it sometimes lies in φ1 < 0. The hyperparameter that minimizes the cross
validation loss is in the neighborhood of φ1 = 5. The hyperparameter that
minimizes the free energy is in the neighborhood of φ1 = 2. These results
show the case n = 200. If n is smaller, the variance of the chosen hyperpa-
rameter is larger, hence too much optimization of the hyperparameter may
be dangerous. Note that if all of (φ1, φ2, φ3) are optimized simultaneously,
then the hyperparameter diverges.
8.2.3
Discussion for Hyperparameter Optimization
Regular case. Assume a true distribution is regular for a statistical model,
then:
(1) If a hyperparameter is optimized by minimization of the cross validation
or WAIC, then the average generalization loss is minimized asymptotically.
However, the generalization loss itself is not minimized. Moreover the ran-
dom ﬂuctuation of the optimized hyperparameter is not small.
(2) If a hyperparameter is optimized by minimizing the free energy, then
it is asymptotically equivalent to maximizing the value of the prior at the
maximum likelihood estimator. The random ﬂuctuation of the optimized
hyperparameter may be smaller than the cross validation, however, it does
not minimize the generalization loss.
Therefore, even if the prior is optimized, its eﬀect to the accurate prediction
is small. Moreover, the random ﬂuctuation may make the variance of the
optimized parameter larger. Therefore, too much optimization is not neces-
sary. However, choosing the appropriate prior among several candidates by
the cross validation or WAIC may be useful.
Singular case. Assume that a true distribution is singular for a statisti-
cal model. Then both the generalization loss and the free energy have the
phase transitions for hyperparameter controlling (for the deﬁnition of the
phase transition, see the following chapter). If the real log canonical thresh-
old is minimized by appropriate hyperparameter choosing, then it makes

260
CHAPTER 8. INFORMATION CRITERIA
the generalization loss smaller.
However, in singular cases, the eﬀect of
control hyperparameter to the precise prediction is not suﬃciently clariﬁed
mathematically. This is an important problem for the future study.
Example 60. (LASSO) Let us study LASSO (least absolute shrinkage and
selection operator). Let x ∈RM, y ∈RN. A model and a prior are deﬁned
by
p(y|x, w)
∝
exp(−1
2σ2 ∥y −wx∥2),
ϕ(w|ℓ)
∝
exp(−ℓ
X
jk
|wjk|),
where w = {wjk} is a N ×M matrix, σ is a constant, and ℓis a hyperparam-
eter. The purpose of using this prior is to make the estimated parameter
sparse. In fact, the maximum a posteriori (MAP) estimator by using this
prior becomes sparse by choosing ℓappropriately. Let us study the Bayesian
case. Assume that the true distribution is q(y|x, w0). Then the Bayesian
generalization error is
E[Gn] = nS + λ
n + o(1/n),
where S is the entropy of p(y|x, w0) and λ is the real log canonical threshold.
The value (−λ) is equal to the maximum pole of the zeta function,
ζ(z) =
Z
∥w −w0∥2z exp(−ℓ
X
jk
|wjk|)dw.
Even if almost all elements of w0 are equal to zero, the largest pole of the zeta
function is equal to −d/2, where d = MN is the dimension of the parameter,
since ϕ(w0|ℓ) > 0. In other words, λ = d/2 does not depend on the choice
of ℓ. Therefore, in Bayesian estimation, the prior exp(−ℓP
jk |wjk|) is not
appropriate for sparse representation of the parameter. In LASSO, Bayesian
estimation is very diﬀerent from MAP estimation.
Example 61. (Bayesian LASSO) Let x ∈RM, y ∈R, w ∈RM. We study a
statistical model
p(y|x, w) =
1
(2πσ2)1/2 exp

−1
2σ2 (y −w · x)2
,
where σ > 0 is not a parameter but a constant, and a prior
ϕ(w) = C
M
Y
j=1
1
|wj|a exp(−εw2
j),

8.2. HYPERPARAMETER OPTIMIZATION
261
α
Figure 8.6: Generalization error by Bayesian LASSO. The horizontal line
shows the hyperparameter α. The generalization error, the cross validation
error, and WAIC error are compared with the theoretical value. By using
Bayesian LASSO, the generalization error can be made smaller, if the true
parameter is sparse.
where C(a, ǫ) is a constant
C(a, ǫ) =

ε(1−a)/2
Γ((1 −a)/2)
M
,
for a given hyperparameter a < 1 and ε > 0.
Note that as a becomes
large, the posterior distribution concetrates on the neighborhood of the ori-
gin. Assume that the true distribution is p(y|x, w0), where the number of
the nonzero elements of w0 is equal to M0. The true distribution q(x) is
the direct product of the standard normal distribution. Then the real log
canonical threshold is
λ(a) = 1
2{M0 + (1 −a)(M −M0)},
(8.73)
resulting that the asymptotic generalization error is
E[Gn] −S = λ(a)
n
+ o(1/n).

262
CHAPTER 8. INFORMATION CRITERIA
For a given sample (Xn, Y n), the posterior distribution is
p(w|Xn, Y n) ∝
M
Y
j=1
1
|wj|a exp

−1
2σ2
n
X
i=1
(Yi −w · Xi)2 −ε
M
X
j=1
w2
j

.
By using a formula,
Z ∞
0
ua/2−1 exp(−w2u)du
=
Γ(a/2)
|w|a ,
the posterior distribution can be represented by
p(w|Xn, Y n)
∝
 M
Y
j=1
Z
duj (uj)a/2−1
× exp

−1
2σ2
n
X
i=1
(Yi −w · Xi)2 −
M
X
j=1
(wj)2uj −ε
M
X
j=1
w2
j

.
Hence a Gibbs sampler for (w, u) can be constructed. In fact p(w|u) is the
normal distribution whose average is
m = S−1 1
σ2
n
X
i=1
YiXi

and covariance matrix is S−1. Here
S = 1
σ2
n
X
i=1
Xi(Xi)T + 2Diag(ε + u1, ε + u2, ..., ε + uM),
where Diag(u1, u2, ..., uM) is the diagonal matrix whose diagonal coeﬃcients
are (u1, u2, ..., uM). On the other hand, p(u|w) is the direct product of the
gamma distribution G(uj|a/2, 1/(wj)2), where
G(x|a, b) =
1
baΓ(a)xa−1 exp(−x
b ).
(8.74)
Figure 8.6 shows an experimental result for the case M = 40, M0 = 10,
and n = 200. In order to make the posterior distribution stable, if |uj| ≥
umax = 1000000, then it is replaced by ±umax. The horizontal line shows the
hyperparamater α and the generalization error, the cross validaiton error,
and WAIC error are compared with the theoretical value. In this case the
true parameter is sparse, hence the generalization error is made smaller by
using Bayesian LASSO.

8.3. PROBLEMS
263
0
0.5
1
1.5
2
-0.05
0
0.05
0.1
0.15
0.2
Distance between 0 and true
 
 
Selected by ISCV
Selected by WAIC
No selection
Figure 8.7: Generalization errors by the minimum cross validation.
The
solid line shows the generalization error by the model selection with respect
to the minimum cross validation loss. The dotted line shows that of the
unselected larger model.
In this experiment, WAIC and CV resulted in
the same model selection. Note that the model selection does not always
minimize the generalization error. In fact, in the delicate case when two
models are almost balanced, the generalization error becomes larger.

264
CHAPTER 8. INFORMATION CRITERIA
8.3
Problems
1. Let Un be a random variable which is deﬁned by
Un
=
1
n
n
X
i=1
log Ew[p(Xi|w)]
−2
n
n
X
i=1
Ew[log p(Xi|w)].
Then prove that Un has the same second order asymptotic expansion as
WAIC.
2. Let x, a ∈Rd. A statistical model and a prior are deﬁned by
p(x|a)
=
1
(2π)d/2 exp(−1
2∥x −a∥2),
ϕ(a)
=
1
(2π)d/2 exp(−1
2∥a∥2).
Let a true distribution be p(x|a0).
We study a model selection between
statistical models p(x|a) and p(x|0). That is to say, the predictive density
ˆp(x) by the minimum cross validation loss is deﬁned by
ˆp(x) =
(
Ew[p(x|w)]
(if C(1)
n
≤C(0)
n )
p(x|0)
(otherwise
,
(8.75)
where C(1)
n
is the cross validation loss of p(x|a) and
C(0)
n
= −1
n
n
X
i=1
log p(Xi|0).
The generalization error of the minimum cross validation loss is deﬁned by
Z
p(x|a0) log p(x|a0)
ˆp(x) dx.
Then this is a function of the distance between 0 and a0.The solid line
in Figure 8.7 shows its behavior as such a function in the case d = 5. The
horizontal line shows the distance between the origin and the true parameter.
The dotted line shows the generalization error of the predicitive density of

8.3. PROBLEMS
265
p(x|a) without model selection. Discuss the eﬀect of the model selection on
the generalization error.
3. If the posterior distribution can be approximated by some normal distri-
bution, then the diﬀerence between BIC and the free energy is a constant
order term. If otherwise, the diﬀerence between WBIC and the free energy
is at most a log log n order term. Discuss how much such diferences aﬀect
the selected models.
4. Assume that the posterior distribution can be approximated by some
normal distribution. Then the hyperparameter that minimizes the gener-
alization loss does not converge to the hyperparameter that minimizes the
average generalization loss. On the other hand, the hyperparameter that
minimizes the cross validation loss or WAIC converges to one which min-
imizes the average generalization loss. Discuss the best procedure that a
statistician can follow to ﬁnd the minimum generalization error.
5. A neural network which has a deep hierarchical structure has many pa-
rameters and the posterior distribution can seldom be approximated by any
normal distribution. For such statistical models, Bayesian estimation makes
the generalization loss very small. However, it is diﬃcult to approximate
the posterior distribution by MCMC. Discuss the best procedure that a
statistician can follow for deep learning.
6. Prove eq.(8.73).


Chapter 9
Topics in Bayesian Statistics
In this chapter we research mathematical bases of several topics in Bayesian
statistics.
(1) The formal optimality of the Bayesian estimation is explained.
(2) A method how to construct the Bayesian hypothesis test is explained.
(3) The Bayesian model comparison method which is diﬀerent from the
Bayesian hypothesis test is examined,
(4) The concept of the phase transition of the posterior distribution is in-
troduced.
(5) In a statatistical model which has singularities in the parameter space,
if the sample size n is small, the posterior distribution is singular, whereas,
if n becomes large, it becomes regular. This phenomenon is a kind of phase
transition called the discovery process.
(6) In hierarchical Bayesian estimation, we ﬁnd several diﬀerent kinds of pre-
dictions. There are diﬀerent cross validation losses and information criteria
according to the diﬀerent predictive losses.
9.1
Formal Optimality
If we know the true prior and the true model, then Bayesian inference is
optimal. In this section we conﬁrm this fact.
Assume that Φ(w) is the true prior density of the parameter w and that
P(x|w) is the true conditional density of x. In this book, we assume that the
true distribution is unknown, however, in this section, we study the special
case that a random parameter W is generated from Φ(w), then a sample
267

268
CHAPTER 9. TOPICS IN BAYESIAN STATISTICS
Xn = (X1, X2, ..., Xn) is independently generated from P(x|w).
W
∼
Φ(w),
X1, X2, ..., Xn
∼
P(x|w).
The simultaneous probability density function of (W, Xn) is equal to
P(w, xn) = Φ(w)
n
Y
i=1
P(xi|w).
Therefore a conditional probability density of w for a given sample xn is
equal to
P(w|xn) =
Φ(w)
n
Y
i=1
P(xi|w)
Z
dw′ Φ(w′)
n
Y
i=1
P(xi|w′)
.
(9.1)
This is equal to the Bayesian posterior distribution for the case when Φ(w)
and P(x|w) are chosen as a prior and a statistical model. The probability
distribution of a new x is given by
P(x|xn) =
Z
dw Φ(w)P(x|w)
n
Y
i=1
P(xi|w)
Z
dw′ Φ(w′)
n
Y
i=1
P(xi|w′)
.
(9.2)
Also this is equal to the Bayesian predictive distribution for the case when
Φ(w) and P(x|w) are chosen as a prior and a statistical model. Let us prove
that this prediction minimizes the average Kullback-Leibler distance under
the circumstance P(w, xn).
Let f(x|Xn) be an arbitrary conditional density function of x for Xn.
For a given (w, xn), the Kullback-Leibler distance from P(x|w) to f(x|xn)
is equal to
G(f|w, xn) =
Z
dxP(x|w) log P(x|w)
f(x|xn).
Let us deﬁne an average functional loss of f be
G(f)
=
Z
dw Φ(w)
h n
Y
i=1
Z
P(xi|w)dxi
i
G(f|w, xn).

9.1. FORMAL OPTIMALITY
269
Then the function f that minimizes G(f) gives the optimal inference un-
der the circumstance P(w, xn). The following theorem shows that such a
function is the Bayesian predictive distribution.
Theorem 27. The average functional loss G(f) is minimized if and only if
f(x|Xn) = P(x|Xn).
Proof. The function G(f) is minimized if and only if
G0(f)
=
−
Z
dwΦ(w)
n
Y
i=1
Z
P(xi|w)dxi
Z
dxP(x|w) log f(x|xn)
=
−
n
Y
i=1
Z
dxi
Z
dxP(x, xn) log f(x|xn)
is minimized, where P(x, xn) is the simultaneous density of (x, xn).
Let
P(xn) be the mariginal distribution of xn deﬁned by the denominator of
eq.(9.1). Then
G0(f)
=
−
n
Y
i=1
Z
dxi
Z
dxP(xn)P(x|xn) log f(x|xn)
=
n
Y
i=1
Z
dxi
Z
dxP(xn)P(x|xn) log P(x|xn)
f(x|xn)
−
n
Y
i=1
Z
dxi
Z
dxP(xn)P(x|xn) log P(x|xn).
The ﬁrst term of the right hand side is the average Kullbaclk-Leiber distance
from P(x|xn) to f(x|xn), and the second term is a constant function of
f(x|xn). Therefore G0(f) is minimized if and only if P(x|xn) = f(x|xn).
Remark 71. (1) By this theorem, if we knew the true prior and the true
statistical model, there is no statistical inference that attains the smaller
average loss than Bayesian predictive inference using the true prior and the
true statistical model.
(2) In the real world, we do not know the true distribution. It may seem
that the formal optimality theorem does not give any methodology to the
real world. However, by the theorem, we can mathematically conclude that
the question for ﬁnding the optimal statistical inference without information
about a prior and a statistical model does not have any answer. In other
words, the nature of the statistical estimation is ill-deﬁned, therefore we
need the evaluation process of a statistical model and a prior.

270
CHAPTER 9. TOPICS IN BAYESIAN STATISTICS
Example 62. The same theorems can be proved.
(1) Let f(xn) be a function from xn to the parameter space.
The error
function
E(w) =
Z
dw
Z
dxnP(w, xn)∥w −f(xn)∥2,
where ∥∥is the norm on the parameter space, is minimized if and only if
f(xn) =
R
dw w P(w, xn)
R
dwP(w, xn) ,
which is the posterior average of the parameter using the true prior and the
true statistical model. If we knew the true prior and the true statistical
model, there is no other function which makes the square error smaller. In
practical problems, we do not know the true prior and the true statisti-
cal model, thus determining the optimal prior and model is the ill-deﬁned
problem.
9.2
Bayesian Hypothesis Test
Assume that Xi is an RN-valued random variable.
If a parameter w is
subject to a prior ϕ(w) and if X1, X2, ..., Xn are independently subject to a
probability density p(xi|w), then such a condition is denoted by
w
∼
ϕ(w),
X1, X2, ..., Xn
∼
p(x|w).
In this section, we study a Bayesian hypothesis test about a null hypothesis
(N.H.) versus an alternative one (A.H.),
N.H.
:
w0 ∼ϕ0(w0), Xi ∼p0(x|w0),
A.H.
:
w1 ∼ϕ1(w1), Xi ∼p1(x|w1).
Note that w0 and w1 may be contained in diﬀerent sets, for example, w0 ∈
Rd0 and w1 ∈Rd1.
Let us study the hypothesis test for the above hypotheses. In order to
make a hypothesis test, we need two probabilities for both hypotheses. Let
an event Θ be a subset of RNn. In other words,
Θ ⊂{xn = (x1, x2, ..., xn) ; xi ∈RN}.

9.2. BAYESIAN HYPOTHESIS TEST
271
Let Prob(Θ|N.H.) and Prob(Θ|A.H.) be conditional probabilities of a set
Θ where the conditions are deﬁned by the null and alternative hypothe-
ses respectively.
The conditional probability density function of Xn =
(X1, X2, ..., Xn) under the condition that w ∼ϕ(w), Xi ∼p(x|w) is given
by
P(xn|p, ϕ) ≡
Z
ϕ(w)
n
Y
i=1
p(xi|w)dw.
(9.3)
Then
Prob(Θ|N.H.)
=
Z
Θ
P(xn|p0, ϕ0)dxn,
(9.4)
Prob(Θ|A.H.)
=
Z
Θ
P(xn|p1, ϕ1)dxn.
(9.5)
A hypothesis test is deﬁned by an arbitrary pair (T(xn), t), where T(xn) is
a real-valued function of xn and t is a real value. Once a hypothesis test is
ﬁxed, the decision for a given xn is determined by
If
T(xn) ≤t
⇒
Null hypothesis is chosen,
Else
⇒
Alternative hypothesis is chosen.
Any pair (T(xn), t) gives a test, but we want the better or best one, hence we
need an evaluation method of a given test (T(xn), t). The level and power
for a test are respectively deﬁned by
Level(T, t)
=
Prob(A.H. is chosen. |N.H.),
(9.6)
Power(T, t)
=
Prob(A.H. is chosen. |A.H.),
(9.7)
which are respectively equal to
Level(T, t)
=
Prob(T(Xn) > t|N.H.),
(9.8)
Power(T, t)
=
Prob(T(Xn) > t|A.H.).
(9.9)
That is to say, the level is the probability that A.H. is chosen when N.H. is
true, whereas the power is the probability that A.H. is chosen when A.H. is
true. A hypothesis test which has a smaller level and a higher power gives
the better procedure for decision.
In practical applications, the hypothesis test procedure is conducted as
follows.
1. The function for the test T(xn) is ﬁxed.

272
CHAPTER 9. TOPICS IN BAYESIAN STATISTICS
2. The level probability is determined. Sometimes 0.05, 0.01, or 0.005 is
chosen.
3. For the ﬁxed level probability, the real value t is determined such that
Level(T, t) is equal to the level probability.
4. The reject region {xn ; T(xn) > t} is determined.
5. If a sample xn is contained in the reject region, then the alternative
hypothesis is chosen, otherwise the null hypothesis is chosen.
If two hypothesis tests (T(xn), t) and (U(xn), u) satisfy the condition
that
Level(T, t) = Level(U, u) ⇒Power(T, t) ≥Power(U, u),
then (T, t) is said to be more powerful than (U, u). This deﬁnition gives a
partial order on the set of all hypothesis tests. In general, it is not a total
order. If there exists a test which is more powerful than any other test,
then it is called the most powerful test. In a Bayesian hypothesis test, it is
explicitly given by the partition function.
Theorem 28. Assume that null and alternative hypotheses are given by
N.H.
:
w0 ∼ϕ0(w0), Xi ∼p0(x|w0),
A.H.
:
w1 ∼ϕ1(w1), Xi ∼p1(x|w1).
Then the hypothesis test (L(xn), ℓ) deﬁned by
L(xn) =
Z
ϕ1(w1)
n
Y
i=1
p1(xn|w1)dw1
Z
ϕ0(w0)
n
Y
i=1
p0(xn|w0)dw0
(9.10)
is the most powerful test.
Proof. Let (T(xn), t) be an arbitrary hypothesis test. Assume that a real
value ℓis set such that both levels are equal to each other,
Level(L, ℓ) = Level(T, t).
(9.11)
To prove the theorem, it is suﬃcient to show
∆P ≡Power(L, ℓ) −Power(T, t)

9.2. BAYESIAN HYPOTHESIS TEST
273
is not smaller than zero. Two events are deﬁned by
A
=
{xn ; T(xn) −t > 0},
B
=
{xn ; L(xn) −ℓ> 0}.
Here, by the deﬁntion of L(xn), we can assume ℓ≥0. Then by the deﬁnition
of eq.(9.8), eq.(9.11) is equivalent to
Z
B
P(xn|p0, ϕ0)dxn −
Z
A
P(xn|p0, ϕ0)dxn = 0.
(9.12)
On the other hand by eq.(9.9),
∆P
=
Prob(L(Xn) > ℓ|A.H.) −Prob(T(Xn) > t|A.H.)
=
Z
B
P(xn|p1, ϕ1)dxn −
Z
A
P(xn|p1, ϕ1)dxn
=
Z
B∩Ac P(xn|p1, ϕ1)dxn −
Z
A∩Bc P(xn|p1, ϕ1)dxn,
where Ac and Bc are complementary sets of A and B respectively. Note
that B ∩Ac ⊂B and A ∩Bc ⊂Bc. By eq.(9.10), the condition xn ∈B is
equivalent to
Z
P(xn|p1, ϕ1)dxn > ℓ
Z
P(xn|p0, ϕ0)dxn.
Therefore
∆P
≥
ℓ
Z
B∩Ac P(xn|p0, ϕ0)dxn −ℓ
Z
A∩Bc P(xn|p0, ϕ0)dxn
=
ℓ
Z
B
P(xn|p0, ϕ0)dxn −ℓ
Z
A
P(xn|p0, ϕ0)dxn = 0,
where the last equation is derived by eq.(9.12).
Remark 72. For the most powerful test L(xn), for a given level ε > 0, the
reject region L(xn) > t is determined by choosing t such that
Level(L, t) = Prob(L(xn) > t|N.H.) = ε.
Therefore, in order to make a hypothesis test, we need the probability den-
sity function of the random variable L(xn) when the null hypothesis holds.

274
CHAPTER 9. TOPICS IN BAYESIAN STATISTICS
Example 63. Let us study a case in which a common statistical model is
used and two priors are compared,
p0(x|a)
=
p1(x|a) =
1
√
2π exp(−1
2(x −a)2),
(9.13)
ϕ0(a)
=
δ(a),
(9.14)
ϕ1(a)
=
1
√
2π exp(−1
2a2).
(9.15)
By Theorem 28, the most powerful test is
L(xn)
=
Z
ϕ1(a)
n
Y
i=1
p1(xn|a)da
Z
ϕ0(a)
n
Y
i=1
p0(xn|a)da
(9.16)
=
r
2π
n + 1 exp
(Pn
i=1 xi)2
2(n + 1)

.
(9.17)
Let us make a hypothesis test for the level 0.01. The real value t is deter-
mined such that
Prob(L(Xn) > t|N.H.) = 0.01,
where the null hypothesis is
xn = (x1, x2, ..., xn) ∼
n
Y
i=1
1
√
2π exp(−1
2x2
i ).
By eq.(9.17), the condition L(xn) > t is equivalent to |(Pn
i=1 xi)/√n| > t∗,
where
t∗=
p
(1 + 1/n){2 log t −log(2π/(n + 1))}.
Under the null hypothesis, the random variable (Pn
i=1 Xi)/√n is subject to
the standard normal distribution N(x). Since
Z
|x|>2.58
N(x)dx = 0.01,
the reject region for the level 0.01 is
{xn ;

n
X
i=1
xi
/√n > 2.58}.
In other words, if | Pn
i=1 xi|/√n > 2.58, then the alternative hypothesis is
chosen, if otherwise, the null hypothesis is the choice.

9.3. BAYESIAN MODEL COMPARISON
275
9.3
Bayesian Model Comparison
In this section we study a Bayesian model comparison using the posterior
distribution. This decision rule is diﬀerent from the hypothesis test.
Let the prior probabilities a0 and a1 satisfy 0 < a0, a1 < 1, a0 + a1 = 1.
We assume that Xn are generated by the following process.
Firstly the
random variable Y is determined by
Y = 0
(with probability a0),
(9.18)
Y = 1
(with probability a1).
(9.19)
Then Xn is generated by
If Y=0
=⇒
w ∼ϕ0(w), Xn ∼
n
Y
i=1
p0(xi|w),
(9.20)
If Y=1
=⇒
w ∼ϕ1(w), Xn ∼
n
Y
i=1
p1(xi|w).
(9.21)
In this case the simultaneous probability density function of (Y, Xn) is given
by
p(y, xn) =

a0P(xn|ϕ0, p0)
1−y
a1P(xn|ϕ1, p1)
y
,
(9.22)
where the deﬁnition of P(xn|ϕ, p) is given in eq.(9.3). The posterior proba-
bility of Y = 1 for a given Xn is
p(1|xn)
=
p(1, xn)
p(0, xn) + p(1, xn),
(9.23)
which gives the posterior model decision. Let us study the decision rule by
which the random variable Y is estimated by the following random variable
Z,
p(1|xn) > α
=⇒
Z = 1,
(9.24)
p(1|xn) ≤α
=⇒
Z = 0,
(9.25)
where 0 < α < 1 is a constant. Then the condition p(1|xn) > α is equivalent
to
p(1|xn)
p(0|xn) > 1 −α
α
.
By eq.(9.22), it is equivalent to
a1P(xn|ϕ1, p1)
a0P(xn|ϕ0, p0) > 1 −α
α
.

276
CHAPTER 9. TOPICS IN BAYESIAN STATISTICS
By eq.(9.3), also it is equivalent to
Z
ϕ1(w1)
n
Y
i=1
p1(xn|w1)dw1
Z
ϕ0(w0)
n
Y
i=1
p0(xn|w0)dw0
> a0
a1
· 1 −α
α
.
(9.26)
This inequality would be equal to the most powerful test if a0(1−α)/(a1α) =
t. Note that, if a0 = a1 = α = 1/2, then the right hand side of this inequality
is equal to 1.
Example 64. Let us compare the most powerful test with the posterior model
comparison. Let us adopt the same case as Example 63,
p0(x|a)
=
p1(x|a) =
1
√
2π exp(−1
2(x −a)2),
(9.27)
ϕ0(a)
=
δ(a),
(9.28)
ϕ1(a)
=
1
√
2π exp(−1
2a2).
(9.29)
Then by eq.(9.17),
r
2π
n + 1 exp
(Pn
i=1 xi)2
2(n + 1)

> a0
a1
· 1 −α
α
.
Hence
| Pn
i=1 xi|
√n
>
hn + 1
n
log
n + 1
2π

+ 2(n + 1)
n
log
a0
a1
· 1 −α
α
i1/2
∼=
p
log n.
(9.30)
If n is suﬃciently large, then the right hand side is approximated by √log n,
whereas the most powerful test for the level 0.01 is 2.58. That is to say, in
the hypothesis test
| Pn
i=1 xi|
√n
< 2.58 =⇒Model 0 is chosen,
whereas in the posterior model comparison,
| Pn
i=1 xi|
√n
<
p
log n =⇒Model 0 is chosen.

9.4. PHASE TRANSITION
277
There is no mathematical contradiction because the hypothesis test and
the posterior model comparison are diﬀerent procedures based on diﬀerent
assumptions. However, this diﬀerence is sometimes referred to as a paradox.
The former has the same decision order as the model selection by the cross
validation or information criteria, whereas the latter does that by the free
energy.
9.4
Phase Transition
Let us deﬁne a phase transition in Bayesian statistics.
Deﬁnition 29. (Phase transition) If a statistical model p(x|w) or a prior
ϕ(w) is determined by a value θ which is not the parameter, then it is written
as p(x|w, θ) or ϕ(w|θ). Therefore, the posterior distribution is also written
as p(w|Xn, θ). Such a value θ is called a generalized hyperparameter. If a
posterior distribution for a suﬃciently large n changes drastically at θ = θc,
then it is said that the posterior distribution has a phase transition, and θc
is called a critical point. At a critical point, the free energy Fn(β, θ) is often
discontinuous or nondiﬀerentiable.
If a log density ratio function f(x, w) = log(q(x)/p(x|w)) has relatively
ﬁnite variance, then
Fn −Sn = −log
Z
exp

−
n
X
i=1
f(Xi, w)

ϕ(w)dw
and
F n −S = −log
Z
exp

−nEX[f(X, w)]

ϕ(w)dw
have the same asymptotic expansions according to the order that is larger
than O(1).
Hence we can analyze the phase transition by studying F n
instead of Fn.
Example 65. Firstly, we study a case when the log density ratio function
has a generalized hyperparameter. Let w = (x, y) and
F n(θ) = −log
Z 1
0
dx
Z 1
0
dy exp(−nx2yθ).
Let K(x, y) = x2yθ (θ > 0). Then K(x, y) ≥0 and the set of all zero points
of K(x, y) is {(x, y); xy = 0}. It can be rewritten as
F n(θ) = −log
Z n
0
dt
n
Z 1
0
dx
Z 1
0
dy exp(−t) δ(t/n −K(x, y)).

278
CHAPTER 9. TOPICS IN BAYESIAN STATISTICS
Since K(x, y) is a normal crossing function whose multi-indexes are k =
(2, θ) and h = (0, 0), the behavior of the free energy can be analyzed by
using the zeta function.
ζ(z) =
Z 1
0
dx
Z 1
0
dy(x2yθ)z =
1
(2z + 1)(θz + 1).
Hence the state density function is equal to
δ(t −K(x, y)) ∼=



1/(2θ) · t−1/2δ(x)y−θ/2
(θ < 2)
1/4 · t−1/2(−log t)δ(x)δ(y)
(θ = 2)
1/(2θ) · t1/θ−1x−2/θδ(y)
(θ > 2).
Therefore, the critical point is θ = 2, where the posterior distribution dras-
tically changes from δ(x) to δ(y) between (2−ǫ) →(2+ ǫ). The asymptotic
behavior of the free energy is given by
F n(θ) ∼=



(1/2) log n + O(1)
(θ < 2)
(1/2) log n −log log n + O(1)
(θ = 2)
(1/θ) log n + O(1)
(θ > 2)
,
which shows that the coeﬃcient of log n is a continuous function of θ but
not diﬀerentiable at θ = 2.
In Bayesian statistics, the following concepts are all mathematically con-
nected. In order to analyze the phase transition, we can choose the most
convenient one.
(1) Partition function
(2) Free energy or the minus log marginal likelihood
(4) State density function
(5) Zeta function
(6) Posterior distribution
Example 66. Secondly, let us study a case when the prior has a hyperpa-
rameter. Assume that w = (x, y), x ∈R1, and y ∈RM. Let us study a free
energy,
F n(θ) = −log
Z 1
0
dx
Z
∥y∥<1
dy exp(−nx2∥y∥2)xθ−1.
The zeta function is equal to
ζ(z) =
Z 1
0
dx
Z
∥y∥<1
dy x2z+θ−1∥y∥2z.

9.4. PHASE TRANSITION
279
By using the generalized polar system (r, ψ) such that y = rψ, then dy =
rM−1drdψ, resulting that
ζ(z)
=
Z 1
0
dx
Z 1
0
dr
Z
dψ x2z+θ−1 r2z+M−1
=
1
(2z + θ)(2z + M)
Z
dψ

.
Hence by using Ψ =
R
dψ, it follows that the state density function is
δ(t −x2∥y∥2)xθ−1 ∼=
 (1/4)Ψ · tθ/2−1δ(x)yM−θ−1
(θ < M)
(1/4)Ψ · tM/2−1xθ−M−1δ(y)
(θ > M).
Therefore the posterior distribution drastically changes from δ(x) to δ(y) at
the critical point θ = M. Then the free energy is
F n(θ) ∼=
 (θ/2) log n + O(1)
(θ < M)
(M/2) log n + O(1)
(θ > M) ,
which shows that the coeﬃcient of log n of the free energy is continuous at
θ = M but not diﬀerentiable.
Example 67. Let us study a normal mixture of x ∈R2 for a given parameter
a (0 ≤a ≤1) and b ∈R2,
p(x|a, b) = aN(x|0) + (1 −a)N(x|b).
For a prior, we use the Dirichlet distribution with index α > 0,
ϕ(a)
∝
(a(1 −a))α−1,
ϕ(b)
∝
exp(−∥b∥2
2σ2 ),
where α and σ are hyperparameters. We set σ = 10, and study the phase
transition according to the hyperparameter α. Assume that the true distri-
bution is
q(x) = N(x|0).
Then the zeta function is
ζ(z) =
Z
K(a, b)zϕ(a)ϕ(b)dadb,
where
K(a, b) =
Z
q(x) log
q(x)
p(x|a, b)dx.

280
CHAPTER 9. TOPICS IN BAYESIAN STATISTICS
Then in the neighborhood of (a, b) = 0, there exists c1, c2 > 0 such that
c1a2∥b∥2 < K(a, b) < c2a2∥b∥2.
Hence the real log canonical threshold is
λ = min{α/2, 1},
which shows that there exists a phase transition at the critical point α = 2.
Thus the average generalization and cross validation errors are given by
E[Gn]
=
min{α/2, 1}/n + o(1/n),
E[Cn]
=
min{α/2, 1}/n + o(1/n).
Moreover, if α < 2, then a is in the neighborhood of the origin but b is free,
whereas, if α > 2, then b is in the neighborhood of the origin but a is free.
Therefore, the posterior distribution drastically changes at the critical point.
Moreover, at the critical point α = 2, the posterior distribution is unstable,
hence MCMC processes may have large variance. Let us observe the phase
transition by an experiment. The number of independent random variables
was set as n = 100. The hyperparameters α of the prior distribution were
controlled in 0 < α < 6. Figures 9.1 and 9.2 show the distributions of the
generalization errors and cross validation errors for a given hyperparameter
respectively. The circles in both ﬁgures show their averages. Note that, by
the equation
(Gn −S) + (Cn −Sn) = 2λ
n + op(1/n),
if Gn−S is larger than the average, then Cn−Sn is smaller than the average.
Remark 73. (1) In this section, we study the cases where we can derive the
poles of the zeta functions. In general, in order to ﬁnd them, resolution of
singularities is necessary, which may often be diﬃcult. That is to say, it is
not easy to ﬁnd the critical point rigorously.
(2) If we apply the mean ﬁeld approximation, or equivalently the variational
Bayes, to statistical estimation, then the posterior distribution made by
the mean ﬁeld approximation shrinks or becomes localized.
As a result,
the free energy becomes larger, and the phase transition structure changes.
Sometimes a spurious phase transition can be observed in the mean ﬁeld
approximation which does not exist in the true posterior distribution. The
critical points of the mean ﬁeld approximation and the true posterior do not
coincide in general.

9.4. PHASE TRANSITION
281
0
1
2
3
4
5
6
7
0
0.005
0.01
0.015
0.02
0.025
0.03
0.035
0.04
 
 
GE
GE Mean
Figure 9.1: Phase transition of generalization error in a normal mixture.
The horizontal and vertical lines show Dirichlet hyperparameter α and the
generalization error respectivelly. α = 2 is the critical point.
0
1
2
3
4
5
6
7
-0.025
-0.02
-0.015
-0.01
-0.005
0
0.005
0.01
0.015
0.02
0.025
 
 
CV
CV Mean
Figure 9.2: Phase transition of cross validation error in a normal mixture.
The horizontal and vertical lines show Dirichlet hyperparameter α and the
cross validation error respectivelly. α = 2 is the critical point.

282
CHAPTER 9. TOPICS IN BAYESIAN STATISTICS
9.5
Discovery Process
Hierarchical statistical models such as neural networks and normal mixtures
have several phases which are determined by the complexity of models K
and the number of independent random variables n. In general, a true dis-
tribution cannot be represented by any ﬁnite statistical model. However, if
n is small, the true distribution seems to be almost realizable by a statistical
model. If n is large, it seems to be unrealizable. Figure 9.3 shows the phase
diagram of such statistical models. The horizontal and vertical lines show n
and K respectively. The bold line shows the critical line. The upper side of
the critical line is the phase in which a true distribution is realizable by and
singular for a statistical model, and the lower side indicates the reverse. If
n is ﬁxed and K is controlled, then it is a model selection process. If K is
ﬁxed and n is controlled, then it is a discovery process. In discovery process,
if n is small, a true distribution seems to be singular for and realizable by a
statistical model, otherwise, it seems to be regular and unrealizable. In this
section we study a discovery process.
Let us consider a normal mixture of x ∈R2 for a given parameter a
(0 ≤a ≤1) and b, c ∈R2,
p(x|a, b, c) = aN(x|b) + (1 −a)N(x|c).
For a prior, we use the Dirichlet distribution with index α > 0,
ϕ(a)
∝
(a(1 −a))α−1,
ϕ(b, c)
∝
exp(−∥b∥2 + ∥c∥2
2σ2
)
where α = 0.3 and σ = 10 are hyperparameters. The number of random
variables is set as n = 5, 10, 20, ..., 1280. Three experiments were conducted.
(1) A case when q(x) = p(x|a, b, c) where a = 0.5, b = (2, 2), c = (−2, −2)
was investigated. In this case, a true distribution is realizable by and regular
for a statistical model for every n, and 200 independent experiments were
used for computing the averages and standard deviations. In Figure 9.4,
n(Gn −S), n(ISCV −Sn), n(WAIC −Sn), n(AIC −Sn), and n(DIC −Sn)
are displayed. In this case the n times averages converged to d/2 = 2.5
where d is the dimenson of the parameter. If n ≥20, every criterion could
estimate the generalization error. In this case, there was no phase transition.
(2) A case when q(x) = p(x|a, b, c) where a = 0.5, b = (0, 0), c = (0, 0) was
investigated. In this case, a true distribution was realizable by but nonreg-
ular for a statistical model for every n. In this case the n times average of

9.5. DISCOVERY PROCESS
283
Figure 9.3: Phase diagram. Statistical models such as neural networks and
normal mixtures have phase transitions according to the number of compo-
nents and the sample size. If n is small, then a true distribution seems to
be realizable and singular. If n is large, then it seems to be unrealizable and
regular.
the generalization error converged to λ = 1.5 where λ is the real log canon-
ical threshold. In Figure 9.5, n(Gn −S), n(ISCV −Sn), n(WAIC −Sn),
n(AIC −Sn), and n(DIC −Sn) are displayed, which shows that both ISCV
and WAIC could estimate the generalization losses, whereas neither AIC
nor DIC could. In this case, there was no phase transition.
(3) A case when q(x) = p(x|a, b, c) where a = 0.5, b = (0.5, 0.5), c =
(−0.5, −0.5) was investigated.
In Figure 9.6, n(Gn −S), n(ISCV −Sn),
n(WAIC −Sn), n(AIC −Sn), and n(DIC −Sn) are displayed. In the region
n ≤20, the generalization loss was almost equal to the case when the true
distribution is singular for a statistical model, which is the case (1). In the
region n ≥320, it was almost equal to the case when the true distribution
is regular for a statistical model, which is the case (2). And in the region
40 ≤n ≤160, the generalization errors were larger than in the other cases,
which were on the critical point. Both ISCV and WAIC could estimate the
generalization losses, whereas neither AIC nor DIC could. In this case, there
was a phase transition according to knowledge discovery process.
By using the same model as above (3), let us study the statistical esti-
mation problem of the hidden variable. A hidden variable y is introduced

284
CHAPTER 9. TOPICS IN BAYESIAN STATISTICS
10
1
10
2
10
3
0
1
2
3
4
5
n = DATA
n*Errors
 
 
AIC
DIC
WAIC
ISCV
GE
Figure 9.4: Strict regular case. The horizontal and vertical lines show the
sample size and errors respectively. A true distribution is set as realizable
by and regular for a statistical model. No phase transition occurs.
10
1
10
2
10
3
0
1
2
3
4
5
n = DATA
n*Errors
 
 
AIC
DIC
WAIC
ISCV
GE
Figure 9.5: Strict singular case. The horizontal and vertical lines show the
sample size and errors respectively. A true distribution is set as realizable
by and singular for a statistical model. No phase transition occurs.

9.5. DISCOVERY PROCESS
285
10
1
10
2
10
3
0
1
2
3
4
5
n = DATA
n*Errors
 
 
AIC
DIC
WAIC
ISCV
GE
Figure 9.6: Discovery process. The horizontal and vertical lines show the
sample size and errors respectively.
As n increases the true structure is
discovered by a statistical model. A phase transition occurs.
by the following equation,
p(x, y|a, b, c) = [aN(x|b)]y · [(1 −a)N(x|c)]1−y.
That is to say,
p(x, 0|a, b, c)
=
aN(x −b),
p(x, 1|a, b, c)
=
(1 −a)N(x −c),
By marginalizing y this model results in a normal mixture,
p(x|a, b, c) = aN(x −b) + (1 −a)N(x −c).
The likelihood function of (xn, yn) is given by
p(xn, yn|a, b, c) =
n
Y
i=1
[aN(xi −b)]yi · [(1 −a)N(xi −c)]1−yi.
Figures 9.7, 9.8, and 9.9 show the true distribution q(x) at left, and estimated
hidden variables for n = 10, 100, 1000 at right. If the hidden variable of a
sample point xi was estimated yi < 0.5, xi is shown by a point, if otherwise,
a white square. For n = 10, it seems that a true distribution consists of one
normal distribution, whereas for n = 1000, two distributions. For the case
n = 100, it is on a critical point, hence the estimated results were unstable.

286
CHAPTER 9. TOPICS IN BAYESIAN STATISTICS
-5
0
5
-5
0
5
-5
0
5
-5
0
5
Figure 9.7: Estimated hidden variables n = 10. A true distribution and
estimated latent variables in n = 10. Although the true distribution consists
of two components, only one component is found since n is too small.
Remark 74. (1) In the above experiment, the hidden variable y = (0, 1) can
be replaced by y = (1, 0), because of symmetry. However, MCMC naturally
made this symmetry break down, which was used for distinguishing 0 and
1.
(2) The phase transition aﬀects the estimation of hidden variables.
The
phase transition also aﬀects the MCMC process.
Hierarchical statistical
models such as neural networks and normal mixtures have the same phase
transition as this case, hence a statistician must know its structure before
applying statistical models to the real world problems.
9.6
Hierarchical Bayes
In this section, hierarchical Bayesian estimation is studied. A typical case
is explained by using an example.
Example 68. (Hierarchical Bayesian inference) In a high school, there are
m = 10 classes, and each class has n = 30 students. One day, an examination
of mathematics was done, and mn = 300 scores {xki; 1 ≤k ≤m, 1 ≤i ≤n}
were obtained. We would like to analyze the following statistical model.
(1) The average wk of kth class’ scores are subject N(µ, 12).
(2) The score xki of the ith student in the kth class is subject to N(wk, 102).
That is to say, the model is made by
wk
∼
N(µ, 12),
xki
∼
N(wk, 102).

9.6. HIERARCHICAL BAYES
287
-5
0
5
-5
0
5
-5
0
5
-5
0
5
Figure 9.8: Estimated hidden variables n = 100. A true distribution and
estimated latent variables in n = 100. The posterior distribution is unsta-
ble, because it lies on the critical point between one component and two
components.
-5
0
5
-5
0
5
-5
0
5
-5
0
5
Figure 9.9: Estimated hidden variables n = 1000. A true distribution and
estimated latent variables in n = 1000. Two components were found.

288
CHAPTER 9. TOPICS IN BAYESIAN STATISTICS
We would like to evaluate this model according to the obtained data.
Statistical Model
(1) Let µ be the hyperparameter.
(2) {wk}m
k=1 are independently taken from the prior distribution ϕ(w|µ).
(3) (xk)n ≡{xki}n
i=1 are independently taken from p(x|wk).
From the predictive point, there are at least two diﬀerent types of prediction.
(1) (New student prediction) If a new student is added to the k class, we
predict a new score.
(2) (New class prediction) If a new class which has 30 students is added to
the high school, we predict new scores.
The evaluation of the statistical model depends on the type of prediction.
New Student Prediction. For given all data {(xk)n}, the posterior dis-
tribution of all classes (w1, w2, ..., wm) is
p(w1, w2, ..., wm|(x1)n, (x2)n, ..., (xm)n) ∝
m
Y
k=1

ϕ(wk|µ)
n
Y
i=1
p(xki|wk)

.
This distribution shows that (w1, w2, ..., wm) are independent of each other,
hence
p(wk|xn
k) ∝ϕ(wk|µ)
n
Y
i=1
p(xki|wk).
Let Ewk[ ] and Vwk[ ] be the average and variance operators of this distribu-
tion. The predictive distribution y of the kth class is equal to Ewk[p(y|wk)],
resulting that ISCV and WAIC for the kth class are
ISCVk
=
1
n
n
X
i=1
log Ewk[1/p(xik|wk)],
(9.31)
WAICk
=
−1
n
n
X
i=1
log Ewk[p(xik|wk)]
+ 1
n
n
X
i=1
Vwk[log p(xik|wk)].
(9.32)
If a student is added to every class, then
X
k
ISCVk,
X
k
WAICk

9.6. HIERARCHICAL BAYES
289
are equal to ISCV and WAIC, respectively. Therefore, the model evaluation
can be done by using this value.
New Class Prediction. In the second problem, one sample point is (xk)n
and we have a sample which consists of (x1)n, (x2)n, ...,(xm)n. The statis-
tical model is
P((xk)n|µ) =
Z
ϕ(w|µ)
n
Y
i=1
p(xki|w)dw.
In this case, the hyperparameter is parameter of this model. By setting a
posterior distribution ψ(µ) of µ, the posterior distribution is given by
p(µ|(x1)n, (x2)n, ..., (xm)n) ∝ψ(µ)
m
Y
k=1
P((xk)n|µ).
Let Eµ[ ] and Vµ[ ] be average and variance operators by this distribution.
The predictive distribution of yn is equal to Eµ[P(yn|µ)], resulting that
ISCV
=
1
m
m
X
k=1
log Eµ[1/P((xk)n|µ)],
(9.33)
WAIC
=
−1
m
m
X
k=1
log Eµ[P((xk)n|µ)]
+ 1
m
m
X
k=1
Vµ[log P((xk)n|µ)].
(9.34)
In the second problem, µ is estimated by the posterior distribution.
In
general, it is rather diﬃcult to numerically calculate the cross validation
and WAIC in the second case.
Remark 75. Cross validation and information criteria are deﬁned for eval-
uation of the predictive behavior of the statistical estimation. A complex
statistical model such as hierarchical Bayes methods may yield several dif-
ferent predictions.
To make an evaluation method, a statistician should
determine which prediction would be evaluated.
Example 69. (Hierarchical Bayes in linear regression) Assume that x, y ∈R
and ak, bk, s ∈R.
Let K be the number of the groups.
For each k, a
statistical model p(y|x, ak, bk, s) and a prior ϕ(ak, bk|ma, mb, t)φ(s|r, ε) are

290
CHAPTER 9. TOPICS IN BAYESIAN STATISTICS
deﬁned by
p(y|x, ak, bk, s)
=
r s
2π exp(−s
2(y −akx −bk)2),
ϕ(ak, bk|ma, mb)
=
t
2π exp(−t
2{(ak −ma)2 + (bk −mb)2}),
φ(s|r)
=
εr
Γ(r)sr−1 exp(−εs),
where (ma, mb) and r are hyperparameters. Note that (ma, mb) is the com-
mon average of the prior which is estimated by using the uniform and im-
proper prior, and r is optimized by the cross validation and WAIC. Let
t = 1/0.22 and ε = 0.01 be ﬁxed. Assume that the true distribution is given
by the common conditional density p(y|x, a0, b0, s0) where a0 = 1, b0 = 0,
and s0 = 0.1. Let {(xki, yki)}nk
i=1 be a sample for the kth group whose sample
size is nk. The posterior distribution for (s, ak, bk, ma, mb) is in proportion
to
φ(s|r)
K
Y
k=1
ϕ(ak, bk|ma, mb)
nk
Y
i=1
p(yki|xki, ak, bk, s),
which is also in proportion to
sr−1 exp(−εs)
K
Y
k=1
t
2π exp(−t
2{(ak −ma)2 + (bk −mb)2})
×
nk
Y
i=1
r s
2π exp(−s
2(yki −akxki −bk)2).
This posterior density can be approximated by a Gibbs sampler,
p(ma|s, ak, bk)
=
N( (1/K)
K
X
k=1
ak,
p
1/(tK) ),
p(mb|s, ak, bk)
=
N( (1/K)
K
X
k=1
bk,
p
1/(tK) ),
p(s|ak, bk)
=
G( r + (1/2)
K
X
k=1
nk, 1/B),
p(ak, bk|ma, mb, s)
=
N(A−1v, A−1/2),

9.7. PROBLEMS
291
r
-3
-2
-1
0
1
2
3
4
CV
0.96
0.87
0.77
0.70
0.66
0.66
0.70
0.76
WAIC
0.61
0.53
0.46
0.43
0.42
0.45
0.51
0.58
Table 9.1: Hyperparameters, cross validation error, and WAIC error. Cross
validation and WAIC errors are compared as a function of hyperparameter
in hierarchical Bayes. In this case r = 1 is chosen which minimizes both
cross validaiton and WAIC errors.
(Table)
where N(m, S) is the normal distribution whose average and covariance
are m and S, respectively and G(a, b) is the gamma distribution deﬁned by
eq.(8.74), and
A
=
 (t + s Pnk
i=1 x2
ki)
(s Pnk
i=1 xki)
(s Pnk
i=1 xki)
(t + snk)

v
=
 tma + s Pnk
i=1 ykixki
tmb + s Pnk
i=1 yki

B
=
ε + (1/2)
K
X
k=1
nk
X
i=1
(yki −akxki −bk)2}
For K = 6, nk = 5 + k, the cross validation and WAIC errors for the ﬁrst
case are compared. See Table 69. In this case, r = 1 which minimizes both
errors is chosen as the best hyperparameter.
9.7
Problems
1. Assume that w is taken from Φ(w), and then (Xn+1, Y n+1) are indepen-
dently taken from P(x, y|w). For function f(x|xn, yn) from x to y, which is
determined by (xn, yn), the square error is deﬁned by
E(f)
=
Z
dwΦ(w)
Z
dxn+1dyn+1P(xn+1, yn+1|w)
×||yn+1 −f(xn+1|xn, yn)||2,
where ∥y∥is the norm of y. Prove that this square error is minimized if and
only if
f(xn+1|xn, yn) =
R
dwΦ(w)
R
dyn+1 yn+1 P(xn+1, yn+1|w)
R
dwΦ(w)
R
dyn+1P(xn+1, yn+1|w)
,

292
CHAPTER 9. TOPICS IN BAYESIAN STATISTICS
which is the regression function made from the predictive distribution.
2. Let x, a ∈Rd. A statistical model and a prior are deﬁned by
p(x|a)
=
1
(2π)d/2 exp(−1
2∥x −a∥2),
ϕ(a)
=
1
(2π)d/2 exp(−1
2∥a∥2).
Devise a hypothesis test for the null hypothesis (p(x|a), δ(a)) versus the
alternative one (p(x|a), ϕ(a)).
Then compare it with the minimum cross
validation loss estimation deﬁned by eq.(8.75).
3. Let x, b ∈Rd and y, a ∈R. For a statistical model and a prior,
p(y|x, a, b)
=
1
(2π)d/2 exp(−1
2∥y −a tanh(b · x)∥2),
ϕ(a, b)
∝
|a|α−1,
clarify the phase transition structure according to the hyperparameter α >
0.
4. Let a = (a1, a2, ..., aK) satisfy P ak = 1 and ak ≥0. Also let bk ∈R. A
statistical model of x ∈RN
p(x|a, b)
=
K
X
k=1
ak
√
2π exp(−(x −bk)2
2
)
is called a normal mixture. Let the prior be a constant on (a, b). Assume
that a true distribution is given by
q(x) =
∞
X
k=1
1
2k exp

−(x −k)2
2

.
Then explain the discovery process of this case.

Chapter 10
Basic Probability Theory
In this chapter, we summarize the basic probability theory which is an im-
portant component in this book.
(1) Delta function is deﬁned.
(2) Kullback-Leibler distance is introduced and its mathematical property
is proved.
(3) The deﬁnitions of the probability space and the random variable are
described.
(4) An empirical process is a random variable on a function space.
In
Bayesian theory construction, we need its convergence in distribution. The
basic deﬁnitions and essential theorems are introduced.
(5) Even if a sequence of random variables converges in distribution, the
sequence of its expected values may not converge.
To prove the conver-
gence of the expected values, we need the additional condition such as the
asymptotically uniformly integrablility.
10.1
Delta Function
The delta function δ(x) is deﬁned to be a generalized function of x ∈R
which satisﬁes, for an arbitrary continuous function f(x),
Z
δ(x)f(x)dx = f(0).
The delta function is not an ordinary function but a kind of a distribution,
which formally satisﬁes
δ(0) = ∞,
Z
δ(x)dx = 1.
293

294
CHAPTER 10. BASIC PROBABILITY THEORY
We can understand that δ(x) is the probability density function of the ran-
dom variable X that is X = 0 almost surely. For x = (x1, x2, ..., xN) ∈RN,
the multi-dimensional delta function δ(x) is deﬁned by
δ(x) = δ(x1)δ(x2) · · · δ(xN).
Example 70. Assume a > 0. Then
aδ(ax + b) = δ(x + b/a).
(10.1)
Let us show this equality. Let f(x) be an arbitrary continuous function. By
the transform y = ax + b, dy = adx and
Z
aδ(ax + b)f(x)dx =
Z
δ(y)f((y −b)/a)dy = f(−b/a).
On the other hand,
Z
δ(x + b/a)f(x)dx = f(−b/a).
10.2
Kullback-Leibler Distance
Let q(x) and p(x) be probability density functions on RN. Then the Kullback-
Leibler distance or the relative entropy is deﬁned by
D(q||p) =
Z
q(x) log q(x)
p(x)dx.
The Kullback-Leibler distance indicates the diﬀerence between q(x) and p(x)
by the following lemma.
Lemma 26. Assume that q(x) and p(x) are continuous functions.
1. For arbitrary q(x) and p(x), D(q||p) ≥0.
2. D(q||p) = 0 if and only if q(x) = p(x) for all x such that q(x) > 0.
Proof. Let us deﬁne a function U(t) for t > 0 by
U(t) = 1/t + log t −1.
Then
D(q||p) =
Z
q(x)U
q(x)
p(x)

dx.

10.2. KULLBACK-LEIBLER DISTANCE
295
Note that U(t) ≥0 for arbitrary t > 0. Since q(x) ≥0, the ﬁrst half of
thelemma was proved. Let us prove the second half. If q(x) = p(x) for
arbitrary x such that q(x) > 0, then D(q||p) = 0. Assume D(q||p) = 0. U(t)
is a continuous function of t, hence U(q(x)/p(x)) is a continuous function
of x. Thus U(q(x)/p(x)) = 0 for arbitrary x such that q(x) > 0. Hence
q(x) = p(x), because U(t) = 0 is equivalent to t = 1.
The log loss function of p(x) is deﬁned by
L(p) = −
Z
q(x) log p(x)dx.
Then by the deﬁnition of Kullback-Leibler distance,
L(p)
=
Z
q(x) log(q(x)/p(x))dx −
Z
q(x) log q(x)dx
=
D(q||p) + S.
(10.2)
In this equation, S is the entropy of q(x) which does not depend on p(x)
and D(q||p) ≥0. That is to say,
L(p) is small ⇐⇒D(q||p) is small.
(10.3)
In other words, minimization of KL distance is equivalent to minimization
of L(p).
Remark 76. (Calculation of generalization error) As is shown in the above
proof,
Z
q(x) log q(x)
p(x)dx =
Z
q(x)U
q(x)
p(x)

dx,
where U(x) ≥0. There are two diﬀerent ways to approximate the Kullback-
Leibler distance. Let {Xi} be a set of random variables which are indepen-
dently subject to the probability density function q(x). Then D(q||p) can
be approximated by
D1
≈
1
n
n
X
i=1
log q(Xi)
p(Xi),
D2
≈
1
n
n
X
i=1
U
q(Xi)
p(Xi)

.
Sometimes variance of D2 is smaller than D1.

296
CHAPTER 10. BASIC PROBABILITY THEORY
10.3
Probability Space
Deﬁnition 30. (Metric space) Let Ωbe a set. A function D
D : Ω× Ω∋(x, y) 7→D(x, y) ∈R
is called a metric if it satisﬁes the following three conditions.
(1) For arbitrary x, y ∈Ω, D(x, y) = D(y, x) ≥0.
(2) D(x, y) = 0 if and only if x = y.
(3) For arbitrary x, y, z ∈Ω, D(x, y) + D(y, z) ≥D(x, z).
A set Ωwith a metric is called a metric space. The set of open neighborhoods
of a point x ∈Ωis deﬁned by {Uǫ(x); ǫ > 0} where
Uǫ(x) = {y ∈Ω; D(x, y) < ǫ}.
A metric space Ωis called separable if there exists a countable and dense
subset {xi; i = 1, 2, 3, ...}. A set {xi; i = 1, 2, 3, ...} is said to be a Cauchy
sequence if, for arbitrary δ > 0, there exists M such that
i, j > M =⇒D(xi, xj) < δ.
If any Cauchy sequence in a metric space Ωconverges in Ω, then Ωis called
a complete metric space.
Example 71. (1) Finite dimensional real Euclidean space Rd is a separable
and complete metric space with the metric
D(x, y) = |x −y| ≡
 d
X
i=1
(xi −yi)21/2
,
where x = (xi), y = (yi), and | · | is a norm of Rd.
(2) Let K be a compact subset in Rd. The set of all continuous function
from Rd to Rd′
Ω= {f ; f : Rd →Rd′}
is a metric space with the metric
D(f, g) = ∥f −g∥≡max
x∈K |f(x) −g(x)|,
where | · | is the norm of Rd′. By the compactness of K in Rd, it is proved
that Ωis a complete and separable metric space.

10.3. PROBABILITY SPACE
297
Deﬁnition 31. (Probability space)
Let Ωbe a separable and complete
metric space.
A set B made of subsets contained in Ωis called a sigma
algebra or a completely additive family if it satisﬁes the following conditions.
(1) If A1, A2 ∈B, then A1 ∩A2 ∈B.
(2) If A ∈B, then Ac ∈B (Ac is the complementary set of A).
(3) If A1, A2, A3.., ∈B, then the countable union ∪∞
k=1Ak ∈B.
A pair of a metric space and a sigma algebra (Ω, B) is called a measurable
space. A function P
P : B ∋A 7→0 ≤P(A) ≤1
is called a probability measure if it satisﬁes
(1) P(Ω) = 1.
(2) For {Bk} which satisﬁes Bk∩Bk′ = ∅(k ̸= k′), P(∪∞
k=1Bk) =
∞
X
k=1
P(Bk).
A triple of a metric space, a sigma algebra, and a probability measure
(Ω, B, P) is called a probability space. If (Ω, B, P) satisﬁes the condition
that an arbitrary subset of a measure zero set is contained in B, then it
is called a complete probability space. In this book, we assume that the
probability space is complete.
Remark 77. Any probability space can be made complete by extending the
sigma algebra and the probability measure so that any subset contained in
a measure zero set belongs to the extended algebra. The smallest sigma
algebra that contains all open subsets of Ωis called the Borel ﬁeld.
In
general the Borel ﬁeld is not complete but it can be made complete by such
completion procedure.
Remark 78. Let (RN, B, P) be a probability space, where RN is the N di-
mensional real Euclidean space, B the completion of the Borel ﬁeld, and P
a probability distribution. If P is deﬁned by a function p(x) ≥0,
P(A) =
Z
A
p(x)dx
(A ∈B),
then p(x) is called a probability density function.
Deﬁnition 32. (Random variable) Let (Ω, B, P) be a complete probability
space and (Ω1, B1) a measurable space. A function
X : Ω∋ω 7→X(ω) ∈Ω1

298
CHAPTER 10. BASIC PROBABILITY THEORY
is said to be measurable if X−1(B1) ∈B for arbitrary B1 ∈B1. A measurable
function X on a probability space is called a random variable. Sometimes
X is said to be an Ω1-valued random variable. By the deﬁnition
µ(B1) = P(X−1(B1)),
(10.4)
µ is a probability measure on (Ω1, B1), hence (Ω1, B1, µ) is a probability
space. The probability measure µ is called a probability distribution of the
random variable X. Then X is said to be subject to µ. Note that µ is the
probability distribution on the image space of a function of X. The equation
(10.4) can be rewritten as
Z
B1
µ(dx) =
Z
X−1(B1)
P(da).
Remark 79. (1) In probability theory, the simpliﬁed notation
P(f(X) > 0) ≡P({ω ∈Ω; f(X(ω)) > 0})
is often used. Then by deﬁnition, P(f(X) > 0) = µ({x ∈Ω1; f(x) > 0}).
(2) In descriptions of deﬁnitions and theorems, sometimes we need only the
information of the image space of a random variable X and the probability
distribution PX. In other words, there are some deﬁnitions and theorems
in which the explicit statement of the probability space (Ω, B, P) is not
needed.
In such cases, the explicit deﬁnition of the probability space is
omitted, resulting in the statement such as “for Ω1-valued random variable
X which is subject to a probability distribution PX satisﬁes the following
equality....”
Deﬁnition 33. (Expected value)
Let X be a random variable from the
probability space (Ω, B, P) to (Ω1, B1) which is subject to the probability
distribution PX. If the integration
E[X] =
Z
X(ω)P(dω) =
Z
x PX(dx)
is well deﬁned and ﬁnite in Ω1, E[X] ∈Ω1 is called the expected value, the
average, or the mean of X. Let S be a subset of Ω1. The expected value
with restriction S is deﬁned by
E[X]{S} =
Z
X(ω)∈S
X(ω)P(dω) =
Z
x∈S
PX(dx).

10.3. PROBABILITY SPACE
299
Remark 80. The following are elemental remarks.
(1) Let (Ω1, B1) and X be the same as in Deﬁnition 33 and (Ω2, B2) be
a measurable space. If f : Ω1 →Ω2 is a measurable function, f(X) is a
random variable on (Ω, B, P). The expected value of f(X) is equal to
E[f(X)] =
Z
f(X(ω))P(dω) =
Z
f(x) PX(dx).
This expected value is often denoted by EX[f(X)].
(2) Two random variables which have the same probability distribution have
the same expected value.
Hence if X and Y have the same probability
distribution, we can predict E[Y ] based on the information of E[X].
Deﬁnition 34. (Convergence of random variable) Let {Xn} and X be a
sequence of random variables and a random variable on a probability space
(Ω, B, P), respectively.
(1) It is said that Xn →X almost surely (almost everywhere), if
P

{ω ∈Ω; lim
n→∞Xn(ω) = X(ω)}

= 1.
(2) It is said that Xn →X in the mean of order p > 0, if E[|Xn|p] < ∞and
if
lim
n→∞E[(Xn −X)p] = 0.
(3) It is said that Xn →X in probability, if
lim
n→∞P(D(Xn, X) > ǫ) = 0
for an arbitrary ǫ > 0, where D(·, ·) is the metric of the image space of X.
(4) It is said that Xn →X in distribution or in law, if
lim
n→∞E[F(Xn)] = E[F(X)]
for an arbitrary bounded and continuous function F.
Deﬁnition 35. (1) It is said that {Xn} is uniformly tight or bounded in
probability, if
lim
M→∞sup
n
P(|Xn| > M) = 0.
(2) It is said that {Xn} is asymptotically uniformly integrable, if
lim
M→∞sup
n E[|Xn|]{|Xn|>M} = 0.
If {Xn} is asymptotically uniformly integrable, then it is uniformly bounded.

300
CHAPTER 10. BASIC PROBABILITY THEORY
The following mathematical relations are important and useful.
Lemma 27. (Relation between several convergences)
(1) If Xn →X almost surely, then Xn →X in probability.
(2) If Xn →X in the mean of order p > 0, then Xn →X in probability.
(3) If Xn →X in the mean of order p > 1 and p > q ≥1, then Xn →X in
the mean of order q.
(4) If Xn →X in probability, then Xn →X in distribution.
(5) If Xn →a in distribution where a is a constant, then Xn →a in
probability.
(6) If Xn →X in distribution, then {Xn} is uniformly tight.
(7) If {Xn} is uniformly tight, then there exists a subsequence of {Xn} which
converges in distribution.
In probability theory, many theorems between random variables are de-
rived. The following are main results which we use in this book.
Lemma 28. (Continuous mapping theorem) Assume that f is a continuous
function from a metric space to a metric space. Then by the continuous
mapping theorem, the following hold.
(1) If Xn →X almost surely, then f(Xn) →f(X) almost surely.
(2) If Xn →X in probability, then f(Xn) →f(X) in probability.
(3) If Xn →X in distribution, then f(Xn) →f(X) in distribution.
Note that these results hold even if the set of discontinuous points of f is a
measure zero subset.
Lemma 29. (Convergences of synthesized random variables)
(1) If both Xn →X and Yn →Y almost surely, then both Xn +Yn →X +Y
and XnYn →XY almost surely.
(2) If both Xn →X and Yn →Y in the mean of order p, then Xn + Yn →
X + Y in the mean of order p.
(3) If both Xn →X and Yn →Y in probability, then both Xn +Yn →X +Y
and XnYn →XY in probability.
(4) If both Xn →X and Yn →a in distribution where a is a constant, then
Xn + Yn →X + a and XnYn →aX in distribution. Moreover if a ̸= 0, then
Xn/Yn →X/a in distribution.
Remark 81. Even if both Xn →X and Yn →Y in distribution, neither
Xn + Yn →X + Y nor XnYn →XY in distribution, in general.
Lemma 30. (Convergences of expected values) In order to prove the con-
vergence of expected values, the following theorems are employed.

10.3. PROBABILITY SPACE
301
(1) If Xn →X in the mean of order p, then E[Xp] < ∞and E[(Xn)p] →
E[Xp].
(2) If Xn →X almost surely, and if there exists a random variable Y such
that |Xn| < Y and E[Y ] < ∞, then E[Xn] →E[X].
(3) Assume that E[Xn] and E[X] are ﬁnite. If Xn →X in distribution and
if {Xn} is asymptotically uniformly integrable, then E[Xn] →E[X].
(4) If supn E[|Xn|1+ǫ] < ∞for some ǫ > 0, then {Xn} is asymptotically
uniformly integrable.
For a short description, we adopt the following deﬁnition.
Deﬁnition 36. Let k > 0 be a positive real value and let X and {Xn} be
random variables. It is said that {Xn} satisﬁes the asymptotic expectation
condition with index k, if the convergence in distribution Xn →X holds
and if there exists ε > 0 such that E[|X|k+ε] < ∞and
sup
n
E[|Xn|k+ε < ∞.
If {Xn} satisﬁes the asymptotic expectation condition with index k, then
E[(Xn)k] →E[Xk].
The following notations are often used in statistics.
Deﬁnition 37. Let {an; an > 0} and {xn} be sequences of real values.
(1) The notation
xn = o(an)
means that xn/an →0.
(2) The notation
xn = O(an)
means that supn |Xn/an| < ∞.
Deﬁnition 38. Let {an; an > 0} and {Xn} be sequences of real values and
random variables respectively.
(1) The notation
Xn = op(an)
means that Xn/an →0 in probability.
(2) The notation
Xn = Op(an)
means that {Xn/an} is uniformly tight.

302
CHAPTER 10. BASIC PROBABILITY THEORY
10.4
Empirical Process
In this section we explain empirical process theory which is necessary in
statistics. Let q(x) be a probability density function on RM and f(x, w) be
an RN-valued function of x ∈RM and w ∈W ⊂Rd which satisﬁes
Z
f(x, w)q(x)dx = 0.
Let X1, X2, ..., Xn be random variables which are independently subject to
the probability density function q(x). The emprical process ξn(w) is deﬁned
by
ξn(w) =
1
√n
n
X
i=1
f(Xi, w).
(10.5)
We assume that each element of the covariance matrix
S(w) ≡
Z
f(x, w)f(x, w)T q(x)dx
is ﬁnite for an arbitrary w ∈W. Let ξ(w) (w ∈W) be a random process
whose average and covariance matrix are zero and S(w). By the central limit
theorem, for each w, ξn(w) converges to ξ(w) in distribution. In statistics,
we need stronger results than the convergence in distribution ξn(w) →ξ(w)
for each w. For example, convergences in distribution
sup
w∈W
∥ξn(w)∥→sup
w∈W
∥ξ(w)∥
(10.6)
and
Z
W
ξn(w)kdw →
Z
W
ξ(w)kdw
(10.7)
for some k > 0 are necessary in statistical theory. The empirical process
theory enables us to prove such convergences.
Let ∥g∥∞be the supremum norm of a function g(w),
∥g∥∞≡sup
w∈W
∥g(w)∥,
and C(W) be a set of all continuous functions on a compact set W,
C(W) = {g(w) is continuous on W}.

10.5. CONVERGENCE OF EXPECTED VALUES
303
Then C(W) is a complete and separable metric space with the norm ∥∥∞.
Both functions
g 7→sup
w∈W
∥g(w)∥
and
g 7→
Z
W
g(w)kdw
are continuous on C(W). Hence in order to prove eq.(10.6) and eq.(10.7), it
is suﬃcient to prove the convergence in distriution ξn →ξ on C(W) holds.
There are several mathematically suﬃcient conditions which ensure ξn →
ξ in distriution on C(W) holds. The following are examples of such suﬃcient
conditions.
(1) If f(x, w) is represented by
f(x, w) =
∞
X
j=1
cj(w)fj(x)
where P
j |cj(w)| < M for some M and E[fj(X)] = 0 and P
j E[|fj(X)|2] <
∞, then ξn →ξ in distribution on C(W) holds.
(2) Assume that E[f(X, w)] = 0 and E[|f(X, w)|2] < ∞and w ∈W ∈Rd.
If f(x, w) is suﬃciently smooth, for example,
max
|k|≤d/2+1 sup
w∈W
∥∂kf(x, w)/∂wk∥< ∞
for an arbitrary x, where |k| = k1 + k2 + · · · + Kd for k = (k1, k2, .., kd), then
ξn →ξ in distribution on C(W) holds.
10.5
Convergence of Expected Values
Let ξn(w) be an empirical process deﬁned by eq.(10.5). We often need the
convergence
E[F(ξn)] →Eξ[F(ξ)],
(10.8)
for a given function F on C(W), where E[ ] and Eξ[ ] show the expected val-
ues over X1, X2, ..., Xn and ξ respectively. If F is a bounded and continuous
function on C(W), then eq.(10.8) is derived from the deﬁnition of conver-
gence in distribution ξn →ξ. Even if F is unbounded, if F is continuous
and if there exists ε > 0 such that
sup
n E[|F(ξn)|1+ε] < ∞,
(10.9)

304
CHAPTER 10. BASIC PROBABILITY THEORY
then eq.(10.8) holds. If ξn →ξ in distribution on C(W) and if there exists
ε > 0 such that
E[ sup
w∈W
∥ξn(w)∥k+ε] < ∞,
(10.10)
then it is said that ξn(w) satisﬁes the asymptotic expectation condition with
index k. If such a condition is satisﬁed, then
E[ sup
w∈W
∥ξn(w)∥k] →Eξ[ sup
w∈W
∥ξ(w)∥k].
(10.11)
The following lemma shows a suﬃcient condition for the asymptotic expec-
tation condition with index k.
Lemma 31. Let x ∈RN, w ⊂W ⊂Rd. Assume that a function f(x, w) is
represented by
f(x, w) =
∞
X
j=1
cj(w)fj(x).
Let k ≥2 be a postive integer. The sequences {cj} and {tj} are deﬁned by
cj
=
sup
w∈W
|cj(w)|,
tj
=
E[|fj(X)|k+1].
If E[fj(X)] = 0 (j = 1, 2, 3, ...), if ξn(w) →ξ(w) in distribution on C(W),
and if
X
cj < ∞,
X
cjtj < ∞,
then the sequence
sup
w |ξn(w)| = sup
w
 1
√n
n
X
i=1
f(Xi, w)

satisﬁes the asymptotic expectation condition with index k.
Proof. Let ℓ= k+1. Since xℓ(ℓ> 2) is a convex function of x, for arbitrary
{aj} and {bj},
P |aj||bj|
P |aj|
ℓ
≤
P |aj||bj|ℓ
P |aj|
.
Hence
(
X
ajbj)ℓ≤(
X
|aj|)ℓ−1(
X
|aj||bj|ℓ).

10.5. CONVERGENCE OF EXPECTED VALUES
305
By using this inequality,
E[sup
w |ξn(w)|ℓ]
=
E sup
w

X
j
cj(w)
 1
√n
n
X
i=1
fj(Xi)

ℓ
≤
X
j
cj
ℓ−1X
j
cjE
 1
√n
n
X
i=1
fj(Xi)

ℓ
≤
(
X
cj)ℓ−1ℓℓ−1(
X
cjE[|fj(X)|ℓ]) < ∞
where we used the following Lemma 32.
Lemma 32. Let X1, X2, ..., Xn be independent random variables which
are subject to the same probability distribution. Let k ≥2 be an integer.
Assume that
E[|Xi|k] < ∞,
E[Xi] = 0.
Then
Yn =
1
√n
n
X
i=1
Xi
satisﬁes that, for an arbitrary positive integer n,
E[(Yn)k] ≤kk−1E[|X|k].
Proof. Let i = √−1 and
φ(t) = E[exp(itX/√n)].
Then
E[(Yn)r] = (φ(t)n)(r)|t=0,
where (φ(t)n)(r) = (d/dt)r(φ(t)n). In order to prove this lemma, it is suﬃ-
cient to prove that, for an arbitrary integer r (r = 1, 2, ..., k),
(φ(t)n)(r)|t=0
 ≤rr−1Ar,
(10.12)
where A = E[|X|k]1/k. Let us prove eq.(10.12) by mathematical induction.
For the case r = 1, eq.(10.12) holds. For k, assume that eq.(10.12) holds for
1 ≤r ≤k −1.
(φ(t)n)(k)
=
(nφ(t)n−1φ(t)′)(k−1)
=
k−1
X
r=0
k −1
r

n(φ(t)n−1)(r)(φ(t)′)(k−1−r).

306
CHAPTER 10. BASIC PROBABILITY THEORY
Hence
(φ(t)n)(k)
=
k−1
X
r=0
k −1
r
(φ(t)n−1)(r)n
(φ(t))(k−r)
By using E[X] = 0,
n(φ(t))(k−r)|t=0
=
n1−(k−r)/2E[Xk−r]
≤
n1−(k−r)/2Ak−r ≤Ak−r,
for r = 0, 1, 2, ..., k −2, and the assumptions of the mathematical induction
(φ(t)n)(k)
≤
Ak
k−1
X
r=0
k −1
r

(k −1)r = Akkk−1,
where we used rr−1 ≤(k −1)r−1 for r = 1, 2, ..., k −1.
10.6
Mixture by Dirichlet Process
In this section, we introduce an iniﬁnite mixture using Dirichlet process.
Firstly, the ﬁnite mixture of normal distributions is deﬁned as follows. In
this section, if a random variable X is subject to a probability distribution
P, it is denoted by
X ∼P.
Let N(x|b) be a normal distribution of x ∈RM whose average is b ∈RM,
N(x|b) =
1
(2π)M/2 exp

−∥x −b∥2
2

.
Firstly we represent the normal mixture deﬁned by eq.(2.28) as a sample-
generating model. For a ﬁnite positive integer K, let a = (a1, a2, ..., aK) be a
parameter which satisﬁes P aj = 1 and aj ≥0, and bk ∈Rd. The Dirichlet
distribution with index β = {βk}
Dir(a|β)
=
1
z1
K
Y
k=1
(ak)βk−1.

10.6. MIXTURE BY DIRICHLET PROCESS
307
Let ψ(bk) be some prior of bk.
The normal mixture is represented as a
generating model of (X1, X2, ..., Xn),
a
∼
ϕ(a|β),
k
∼
Multi(a),
bi
∼
ψ(bk),
xi
∼
N(x|bi),
where k ∼Multi(a) shows that an integer k (1 ≤k ≤K) is subject to the
one-time multinomial distribution with probability a = (a1, a2, ..., aK).
Deﬁnition 39. (Dirichlet process) Let (RM, B) be a measurable space of
RM, α > 0 be a constant, and G0 be a measure on (RM, B). A family of a
measurable sets {Bj ∈B; j = 1, 2, ..., m} which satisﬁes
Bj ∩Bk = ∅(j ̸= k),
∪jBj = RM,
is called a disjoint partition of RM. A probability measure-valued random
variable G is said to be subject to the Dirichlet process if, for an arbitrary
disjoint partition,
(G(B1), G(B2), ..., G(Bm)) ∼Dir(a|αG0(B1), αG0(B2), ..., αG0(Bm)).
The probability distribution of G is denoted by DP(α, G0).
Then the inﬁnite mixture model, which is formally given by K →∞and
βk = α/K, is represented by
G
∼
DP(α, ψ),
bi
∼
G,
xi
∼
N(x|bi).
It is known that the Dirichlet process gives the discrete sum with probability
one.


References
[1] H. Akaike. A new look at the statistical model identiﬁcation. IEEE
Trans. on Automatic Control, Vol. 19, pp. 716-723, 1974.
[2] H. Akaike. Likelihood and Bayes procedure. Bayesian Statistics,
(Bernald J.M. eds.) University Press, Valencia, Spain, pp.143-166.
1980.
[3] S. Amari, H. Nagaoka. Methods of information geometry. AMS and
Oxford University Press, Oxford, UK, 2000.
[4] H. Araki. Mathematical theory of quantum ﬁelds. International Series
of Monographs on Physics, Oxford University Press, 1999.
[5] M. Aoyagi, S. Watanabe. Stochastic complexities of reduced rank
regression in Bayesian estimation. Neural Networks, Vol.18, No.7,
pp.924-933, 2005.
[6] M. Aoyagi. Log canonical threshold of Vandermonde matrix type sin-
gularities and generalization error of a three-layered neural network
in Bayesian estimation. International Journal of Pure and Applied
Mathematics. Vol. 52, pp.177-204, 2009.
[7] M. Aoyagi. A Bayesian learning coeﬃcient of generalization error and
Vandermonde matrix-type singularities. Communications in Statistics
Theory and Methods. Vol. 39, pp.2667-2687, 2010.
[8] M. Aoyagi. Stochastic complexity and generalization error of a re-
stricted Boltzmann machine in Bayesian estimation. Journal of Ma-
chine Learning Research. Vol.11, pp.1243-1272, 2010.
[9] M. F. Atiyah. Resolution of singularities and division of distributions.
Communications of Pure and Applied Mathematics, Vol.13, pp.145-
150. 1970.
309

310
REFERENCES
[10] I. N. Bernstein. The analytic continuation of generalized functions
with respect to a parameter. Functional Analysis and Applications,
Vol.6, pp.26-40, 1972.
[11] P. Billingsley. Probability and Measure. John Wiley & Sons, Hoboken,
2012.
[12] J. E. Bj¨ork. Rings of Diﬀerential Operators. North Holland, 1970.
[13] G. Bodn´ar, J. Schicho, A computer program for the resolution of sin-
gularities. Progress in Mathematics, Vol. 181, pp. 231-238, Birkh¨auser,
1997.
[14] D. A. Cox, J. B. Little, D. O’sea. Ideals, Varieties, and Algorithms,
Third Edition. Springer, 2007.
[15] D. Dacunha-Castelle, E. Gassiat. Testing in locally conic models, and
application to mixture models. Probability and Statistics, Vol. 1, pp.
285-317, 1997.
[16] M. Drton, B. Sturmfels, and S. Sullivant. Algebraic factor analysis:
tetrads, pentads and beyond. Probability Theory and Related Fields,
Vol. 138, pp. 463-493, 2007.
[17] M. Drton, B. Sturmfels, S. Sullivant. Lectures on Algebraic Statistics.
Birkh¨auser, Basel-Boston-Berlin, 2009.
[18] M. Drton. Likelihood ratio tests and singularities. Annals of Statis-
tiscs, Vol. 37, pp. 979-1012, 2009.
[19] M. Drton, M. Plummer. A Bayesian information criterion for singular
models. J. Royal Statist. Soc. B, Vol. 79, Part 2, pp. 1-38, 2017.
[20] I. Epifani, S. N. MacEachern, M. Peruggia. Case-deletion importance
sampling estimators: Central limit theorems and related results. Elec-
tric Journal of Statistics, Vol. 2, pp. 774-806, 2008.
[21] M. D. Escobar, Estimating normal means with a Dirichlet process
prior. Journal of the American Statistical Association Vol. 89, pp.
268-277, 1994.
[22] T. S. Ferguson. A Bayesian analysis of some nonparametric problems.
Annals of Statistics, Vol. 1, pp. 209-230, 1973.

REFERENCES
311
[23] T. S. Ferguson. Prior distributions on spaces of probability measures.
Annals of Statistics, Vol. 2, pp .615-629, 1974.
[24] K. Fukumizu. Likelihood ratio of unidentiﬁable models and multilayer
neural networks. Annals of Statistics, Vol. 31. No. 3, pp. 833-851, 2003.
[25] S. Geisser. The predictive sample reuse method with applications.
Journal of the American Statistical Association, Vol. 70, No. 350, pp.
320-328, 1975.
[26] I. M. Gelfand and G. E. Shilov. Generalized Functions. Academic
Press, San Diego, 1964.
[27] A. E. Gelfand, D. K. Dey, H. Chang. Model determination using pre-
dictive distributions with implementation via sampling-based meth-
ods. Bayesian Statistics, Vol. 4, pp. 147-167, 1992.
[28] A. E. Gelfand, D. K. Dey. Bayesian Model Choice: Asymptotics and
Exact Calculations. Journal of the Royal Statistical Society Series B,
Vol. 56, pp. 501-514, 1994.
[29] A. Gelman, D. B. Rubin. Inference from iterative simulation using
multiple sequences. Statistical Science, Vol. 7, pp. 457-511, 1992.
[30] A. Gelman, J. B. Carlin, H. S. Stern, D. B. Dunson, A. Vehtari, D.
B. Rubin. Bayesian Data Analysis, third edition. CRC Press Taylor &
Francis Group, Boca Raton, 2014.
[31] A. Gelman, J. Hwang, A. Vehtari, Understanding predictive informa-
tion criteria for Bayesian models. Statistics and Computing, Vol. 24,
pp. 997-1016, 2014.
[32] S. J. Gershman, D. M. Blei, A tutorial on Bayesian nonparametric
models. Jounal of Mathematical Psychology, Vol. 56, pp. 1-12, 2012.
[33] J. Geweke, Evaluating the accuracy of sampling-based approaches to
the calculation of posterior moments. Bayesian Statistics, Vol.4, pp.
169-193. Oxford University Press, 1992.
[34] I. J. Good. Rational Decisions. Journal of the Royal Statistical Society,
Series B, Vol. 14, pp. 107-114, 1952.
[35] J. A. Hartigan. A failure of likelihood asymptotics for normal mixtures.
Proceedings of Barkeley Conference in Honor of J. Neyman and J.
Kiefer, Vol. 2, pp. 807-810, 1985.

312
REFERENCES
[36] P. Heidelberger, P. D. Welch. A spectral method for conﬁdence interval
generation and run length control in simulations. Communications of
ACM, Vol. 24, pp. 233-245, 1981.
[37] H. Hironaka. Resolution of singularities of an algebraic variety over a
ﬁeld of characteristic zero. Annals of Mathematics, Vol. 79, pp. 109-
326, 1964.
[38] M. D. Hoﬀman, A. Gelman. The No-U-Turn sampler: adaptively set-
ting path lengths in Hamiltonian Monte Carlo. Journal of Machine
Learning Research, Vol. 15, pp. 1593-1623, 2014.
[39] H. Ishwaran, L. F. James. Gibbs Sampling Methods for Stick-Breaking
Priors. Journal of the American Statistical Association, Vol. 96, pp.
161-173, 2001.
[40] S. Janson, Gaussian Hilbert Spaces. Cambridge University Press,
Cambridge, 1997.
[41] M. Kashiwara. B-functions and holonomic systems. Inventiones Math-
ematicae, Vol. 38, pp. 33-53, 1976.
[42] J. Koll´ar. Lectures on Resolution of Singularities. Princeton University
Press, USA, 2007.
[43] S. Konishi and G. Kitagawa, G. Information Criteria and Statistical
Modeling. Springer, 2008.
[44] F. Komaki. On asymptotic properties of predictive distributions.
Biometrika, Vol. 83, No. 2, pp. 299-313, 1996.
[45] S. Lin. Asymptotic approximation of marginal likelihood integrals.
arXiv:1003.5338v2, 2011.
[46] R. McElreath. Statistical Rethinking: A Bayesian Course with Exam-
ples in R and Stan. Chapman & Hall/CRC Texts in Statistical Science,
2015.
[47] S. N. MacEachern, Estimating normal means with a conjugate style
Dirichlet process prior. Communications in Statistics - Simulation and
Computation. Vol. 23, pp. 727-741, 1994
[48] G. McLachlan, D. Peel. Finite Mixture Models. John Wiley & Sons,
New York, 2000.

REFERENCES
313
[49] N. Metropolis, A. W. Rosenbluth, M. N. Rosenbluth, A. H. Teller,;
E. Teller, Equations of state calculations by fast computing machines.
Journal of Chemical Physics, Vol. 21, pp. 1087-1092, 1953.
[50] F. Mosteller, D. L. Wallace. Inference in an authorship problem. Jour-
nal of the American Statistical Association, Vol. 58, pp. 275-309. 1963.
[51] D. Mumford. The red book of varieties and schemes (2nd Edition).
Springer-Verlag, Berlin, 1999.
[52] K. Nagata, S. Watanabe, Asymptotic behavior of exchange ratio in
exchange Monte Carlo method. Neural Networks, Vol. 21, No. 7, pp.
980-988, 2008.
[53] S. Nakajima, S. Watanabe. Variational Bayes solution of linear neu-
ral networks and its generalization performance. Neural Computation.
Vol. 19, No.4, pp. 1112-1153, 2007.
[54] R. M. Neal. MCMC Using Hamiltonian Dynamics. Handbook of
Markov Chain Monte Carlo, Chapman and Hall/CRC. 2011.
[55] T. Oaku. Algorithms for b-functions, restrictions, and algebraic local
cohomology groups of D-modules. Advances in Applied Mathematics,
Vol. 19, pp. 61-105, 1997.
[56] T. Oaku. Algorithms for the b-function and D-modules associated with
a polynomial. Journal of Pure Applied Algebra, Vol. 117-118, pp. 495-
518, 1997.
[57] M. Peruggia. On the variability of case-deletion importance sampling
weights in the Bayesian linear model. Journal of the American Statis-
tical Association, Vol. 92, pp. 199-207. 1997.
[58] M. Plummer, N.Best, K. Cowles, K. Vines. CODA : convergence diag-
nosis and output anlaysis for MCMC. R News, Vol.6, No.1, pp. 7-11,
2006.
[59] M. Plummer. Penalized loss functions for Bayesian model comparison.
Biostatistics, Vol.9, pp. 523-539, 2008.
[60] A. Raftery, S. Lewis. How many iterations in the Gibbs sampler? Vol.
Bayesian Statistics-4, pp. 763-773. Oxford University Press, 1992.
[61] D. Ruelle. Thermodynamic Formalism. Addison Wesley, 1978.

314
REFERENCES
[62] D. Rusakov, D. Geiger. Asymptotic model selection for naive Bayesian
networks. Journal of Machine Learning Research. Vol. 6, pp. 1-35,
2005.
[63] M. Saito. On real log canonical thresholds.arXiv:0707.2308v1, 2007.
[64] M. Sato, T. Shintani. On zeta functions associated with prehomoge-
neous vector space. Annals of Mathematics, Vol. 100, pp. 131-170,
1974.
[65] G. Schwarz. Estimating the dimension of a model. Annals of Statistics,
Vol. 6, No. 2, pp. 461-464. 1978.
[66] J. Sethuraman. A constructive deﬁnition of Dirichlet priors. Statistica
Sinica, Vol. 4, pp. 639-650, 1994.
[67] D. Simon, A. D. Kennedy, B. J. Pendleton, D. Roweth. Hybrid Monte
Carlo. Physics Letters B, Vol. 195, pp. 216-222, 1987.
[68] R. Shibata. An optimal model selection of regression variables.
Biometrika, Vol. 68, pp. 45-54, 1981.
[69] K. E. Smith, L. Kahanp¨aa, P. Kek¨al¨ainen, W. Traves. An Invitation
to Algebraic Geometry. Springer, New York, 2000.
[70] D. J. Spiegelhalter, N. G. Best, B. P. Carlin, A. van der Linde.
Bayesian measures of model complexity and ﬁt. Journal of the Royal
Statistical Society, Series B, Vol. 64, pp. 583-639, 2002.
[71] D. J. Spiegelhalter, N. G. Best, B. P. Carlin, A. van der Linde. The
deviance information criterion: 12 years on. Journal of the Royal Sta-
tistical Society, Series B. Vol. 76, pp. 485-493, 2014.
[72] M. Stone. Cross-validatory choice and assessment of statistical predic-
tions. Journal of the Royal Statistical Society, Series B, Vol. 36, pp.
111-147, 1974.
[73] R. H. Swendsen, J.S. Wang. Replica Monte Carlo simulation of spin
glasses. Physical Review Letters, Vol. 57, pp. 2607-2609, 1986.
[74] A. Vehtari, J. Lampinen. Bayesian model assessment and compari-
son using cross-validation predictive densities. Neural Computation.
Vol.14, pp. 2439-2468, 2002.

REFERENCES
315
[75] A. Vehtari, J. Ojanen. A survey of Bayesian predictive methods for
model assessment, selection and comparison. Statistics Surveys, Vol.
6, pp. 142-228, 2012.
[76] A. Vehtari, A. Gelman, J. Gabry. Practical Bayesian model evaluation
using leave-one-out cross-validation and WAIC. J. Stat Comput, 2016.
doi:10.1007/s11222-016-9696-4.
[77] A. W. van der Vaart, J. A. Wellner. Weak Convergence and Empirical
Processes. Springer, New York, 1996.
[78] A. W. van der Vaart. Asymptotic statistics. Cambridge University
Press, Cambridge, 1998.
[79] K. Watanabe, S. Watanabe. Stochastic complexities of Gaussian mix-
tures in variational Bayesian approximation Journal of Machine Learn-
ing Research. Vol. 7, pp. 625-643, 2006.
[80] S. Watanabe. Algebraic analysis for nonidentiﬁable learning machines.
Neural Computation, Vol. 13, No. 4, pp. 899-933, 2001.
[81] S. Watanabe. Algebraic geometrical methods for hierarchical learning
machines. Neural Networks, Vol. 14, No. 8, pp. 1049-1060, 2001.
[82] S. Watanabe. Algebraic Geometry and Statistical Learning Theory.
Cambridge University Press, Cambridge, 2009.
[83] S. Watanabe. Equations of states in singular statistical estimation.
Neural Networks, Vol. 23, No. 1, pp. 20-34, 2010.
[84] S. Watanabe. Asymptotic equivalence of Bayes cross validation and
widely applicable information criterion in sngular learning theory.
Journal of Machine Learning Research, Vol. 11, pp. 3571-3591, 2010.
[85] S. Watanabe. A widely applicable Bayesian information criterion.
Journal of Machine Learning Research, Vol. 14, pp. 867-897, 2013.
[86] S. Watanabe. Bayesian cross Validation and WAIC for predictive prior
design in regular asymptotic theory. arXiv:1503.07970, 2015.
[87] S. Watanabe. Theory and method of Bayes statistics. Corona publish-
ing, Tokyo, 2012 (In Japanese).

316
REFERENCES
[88] K. Yamazaki, S. Watanabe. Singularities in mixture models and upper
bounds of stochastic complexity. Neural Networks. Vol. 16, No. 7, pp.
1029-1038, 2003.
[89] K. Yamazaki, S. Watanabe. Algebraic geometry and stochastic com-
plexity of hidden Markov models. Neurocomputing. Vol. 69, pp. 62-84,
2005.
[90] K. Yamazaki, S. Watanabe. Singularities in complete bipartite graph-
type Boltzmann machines and upper bounds of stochastic complexi-
ties. IEEE Transactions on Neural Networks,Vol. 16, No .2, pp. 312-
324, 2005.
[91] K. Yamazaki, M. Aoyagi, S. Watanabe. Asymptotic analysis of
Bayesian generalization error with Newton diagram. Neural Networks.
Vol. 23, No.1, pp. 35-43, 2010.
[92] P. Zwiernik. An asymptotic behaviour of the marginal likelihood for
general Markov models. Journal of Machine Learning Research. Vol.
12, pp. 3283-3310, 2011.

Index
acceptance probability, 211
AIC, 233
AICb, 233
almost surely convergence, 299
alternative hypothesis, 270
average, 6, 298
average log loss function, 68
Bayes’ theorem, 7
Bayesian LASSO, 260
Bayesian model comparison, 275
BIC, 246
Borel ﬁeld, 297
burn-in, 211
consistency of model selection, 250
convergence in mean, 299
convergence in probability, 299
covariance matrix, 7
critical point, 277
cross validation, 232
cross validation error, 18
cross validation loss, 18
cumulant generating function, 80
curse of dimensionality, 208
CV, 232
deep learning, 265
delicate case, 238
delta function, 5, 293
detailed balance condition, 209
DIC, 234
eﬃciency of model selection, 250
entropy, 68
entropy barrier, 211
equilibrium state, 5, 208
essentially unique, 69
expected value, 6
F(MCMC), 246
F(REG), 246
formal optimality, 3, 267
free energy, 21
gamma distribution, 262
generalization error, 17
generalization loss, 17
Hamiltonian, 207
Hamiltonian Monte Carlo, 211
hierarchical Bayes, 286
Hironaka theorem, 181
hypothesis test, 271
ill-posed problem, 2
importance sampling, 208
importance sampling cross validation,
20
improper, 10
inﬂuential observation, 167
irreducible condition, 209
ISCV, 20, 232
Kullback-Leibler distance, 294
LASSO, 260
317

318
INDEX
leverage sample point, 167, 243
linear regression, 48
log density ratio function, 72
loss and error, 21
MAP estimator, 197
MAP loss, 235
marginal likelihood, 10, 21
Markov chain Monte Carlo, 209
mathematical relation of priors, 254
mean, 6
measurable function, 297
measurable space, 297
metric, 296
metric space, 296
metropolis method, 209
Metropolis-Hasting Method, 210
minus log marginal likelihood, 21
ML estimator, 197
ML loss, 235
most powerful test, 272
multi-index, 136
multinomial distribution, 41
multiplicity, 147
neural networks, 53
normal crossing, 137
normal distribution, 5, 35
normal mixture, 56
normalized observable, 77
null hypothesis, 270
parallel tempering, 215
partition function, 10, 21
phase transition, 277
posterior average, 10
posterior probability density, 10
posterior variance, 10
potential barrier, 211
predictive density function, 10, 11
prior, 3, 9
probability density function, 4, 297
probability distribution, 5, 297
probability measure, 297
probability space, 297
projective space, 187
random variable, 5, 297
real log canonical threshold, 147, 184
realizable, 67
reduced rank regression, 195
redundant multi-index, 147
regular, 68
relatively ﬁnite variance, 72
replica Monte Carlo, 215
resolution of singularities, 181
sample size, 8
sampling interval, 211
separable metric space, 296
set-valued random variable, 297
sigma algebra, 297
simultaneous resolution, 188
singular ﬂuctuation, 160
spontaneous symmetry breaking, 94
standard form, 137
statistical model, 3, 9
TIC, 233
TICb, 233
time series analysis, 171
training error, 17
training loss, 17
true distribution, 8
unbalanced case, 239
uniform distribution, 5
variance, 7
WAIC, 20, 225, 234

INDEX
319
WAIC error, 20
WBIC, 246
widely applicable information crite-
rion, 20
zeta function, 151


