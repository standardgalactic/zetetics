Intuitive Expertise and Perceptual Templates
Michael Harre´ • Allan Snyder
Received: 29 August 2011 / Accepted: 1 December 2011 / Published online: 14 December 2011
 Springer Science+Business Media B.V. 2011
Abstract
We provide the ﬁrst demonstration of an artiﬁcial neural network
encoding the perceptual templates that form an important component of the high
level strategic understanding developed by experts. Experts have a highly reﬁned
sense of knowing where to look, what information is important and what infor-
mation to ignore. The conclusions these experts reach are of a higher quality and
typically made in a shorter amount of time than those of non-experts. Understanding
the manifestation of such abilities in terms of both the psychology of expert per-
formance and the underlying neural mechanisms constitutes one of the most chal-
lenging problems in the cognitive sciences. Using perceptual templates we show
how the amount of contextual information can change signiﬁcantly even within a
given task, the relationship between local and non-local contexts and ﬁnally why
there is very little correlation between measures of intelligence and level of
expertise in many of the most complex tasks performed by humans.
Keywords
Expertise  Neural networks  Decision theory  Perceptual learning
Introduction
Capablanca was the chess world champion from 1921 to 1927 and is considered one
of the greatest players of all time. It has been reported (Ross 2006) that he could
assess a game within seconds and then make a move that was often the best
available. When asked about this astonishing ability he replied: ‘‘I see only one
move ahead, but it is always the correct one.’’ This remarkable ability, replicated to
some extent by most experts in many ﬁelds, is referred to as ‘thin-slicing’ (Ambady
and Rosenthal 1992) or ‘intuition’ (Khaneman 2003) and forms a signiﬁcant part of
M. Harre´ (&)  A. Snyder
Centre for the Mind, The University of Sydney, Sydney 2006, Australia
e-mail: michael.harre@sydney.edu.au
123
Minds & Machines (2012) 22:167–182
DOI 10.1007/s11023-011-9264-9

current research into learning and decision based expertise. Two important
questions in this area are addressed by the current work: What is the relationship
between the different types of cognitive processes employed by experts and is it
possible to replicate some of these processes in an artiﬁcial neural network? This
work shows how artiﬁcial neural networks can be used to recover the information
used by experts and how this information can be used to answer questions regarding
human performance.
The critical role played by perception in chess, as opposed to deliberate
cognition, has been conjectured at least since 1907 (Cleveland 1907). In this article
Cleveland also sums up a second important skill in chess: ‘‘... the quickness and the
accuracy of his solution will depend upon his ability to seize upon the salient and
essential features and to neglect those which have no meaning for that particular
situation.’’ More recently, Simon raised the issue in the late 60s (Simon and
Barenfeld 1969; Chase and Simon 1973), a line of work that would later result in the
template theory of expertise (Simon and Gobet 1996). Despite the long conjectured
existence of such templates there has been little progress in either ﬁnding them or
analysing them (although see Gobet et al. 2001 for a complete discussion). The goal
of this work is to demonstrate that perceptual templates, frequently co-occurring
individual elements in a visual scene (a board game), can be extracted and analysed
using currently available techniques. This enables us to discuss the cognitive role
such templates play in terms of the work on individual differences studies, such as
IQ, Kahneman’s work on fast and slow mental processes (Khaneman 2003) and
expertise in general. This is the ﬁrst time such an analysis has been carried out.
In order to make concrete our notions of intuition we use decisions made during a
game of Go as our task. The rules of Go are reasonably simple and the pieces are all
perfectly homogeneous, consequently the complexity of the game is more an
emergent property of the simple relationships between pieces and their spatial
conﬁgurations than is the case for chess. This complexity of Go (Tromp and
Farneba¨ck 2007) is considerably greater than that of chess (Shannon 1950) and
building a strong computer player has so far proved too difﬁcult a task for even the
strongest artiﬁcial intelligence (AI) systems.
The basis of this study is that for each move in Go there are frequently recurring
patterns of stones that act as a context in which that move is made. While there are
only 361 locations in which a move can be made, the number of possible board
conﬁgurations in which each of these moves can theoretically occur is exceptionally
high, there are approximately 2 9 10170 legal board positions (Tromp and
Farneba¨ck 2007). This number is too large for either humans or our fastest
computers to contend with directly; in order for experienced players to manage in
such a task they take advantage of useful recurring patterns while ignoring game
pieces that are not relevant to the choice of next move. This is similar to the way in
which we comprehend the ‘gist’ of a natural scene (Oliva and Torralba 2006)
despite the essentially inﬁnite possible scene variations, no two scenes are ever
exactly the same, and the cluttered detail that does not contribute to our overall
comprehension. Hence Go is an ideal test case for the study of the cognitive
strategies we have developed for a cluttered, noisy and ambiguous world.
168
M. Harre´, A. Snyder
123

Go is a two player game played on a 19 9 19 board. Much like chess, Go
requires many years of experience in order to play well and has remarkable strategic
complexity that has encouraged psychological (Reitman 1976), neuroscientiﬁc
(Chen et al. 2003) and computational (Bouzy and Cazenave 2001) research. While
the details of the game are not critical to an understanding of our results1, we note
that the goal in Go is to surround more territory than your opponent using stones
(game pieces) connected to form chains (stones linked together by their adjacency
to one another). Completely surrounded opponent pieces are captured and removed.
As such Go is a game of spatial conﬁgurations with simple local interactions
between the game pieces whose inﬂuence can extend over relatively large areas of
the board. Comprehension of these local-to-global relationships is vital to strong
play and is a signiﬁcant impediment to developing a strong AI for Go.
AI researchers face two confounding problems in Go. First, unlike chess there is
no known evaluation function for intermediate game positions. Second, while the
Go study literature describes many frequently recurring board patterns that players
need to learn to associate with certain moves, in practice the board is cluttered with
both relevant and irrelevant stones, where some relevant stones are close to where a
move needs to be made and some quite distant. The ﬁrst problem has led to Go AI
algorithms that use Monte-Carlo techniques (Hoock et al. 2010) to sample the entire
game tree to the very end of the game, and then score the ﬁnal position, the score is
then used to evaluate the original move. This is computationally inefﬁcient and it is
quite unlike human reasoning where highly reﬁned ﬁrst estimates are used to guide
our move selection. The second problem restricts the applicability of exact pattern
matching (e.g. see Stern et al. 2006; Harre´ et al. 2011) as small variations in the
location or the presence or absence of ‘nuisance’ stones can make even local
conﬁgurations of stones look unique, even though much of this local information
might be irrelevant to move selection.
We address these difﬁculties by extracting high-level visual information from the
state of the game when each move is made. Each choice of move is made within a
recognisable context, the learning of which does not require an evaluation function,
and this context guides a players attention to regions of the board in which good
moves are likely to be found, such methods are often studied in contextual scene
analysis (Chun and Jiang 1998). We call the resultant patterns of frequently co-
occurring stones templates. These templates act as a preprocessing step that cues the
rapid categorisation of the board and reﬁnes the target regions to which players need
to attend in order to search more carefully for good moves.
We chose to use the Self-Organizing Map (SoM) (Kohonen 1982, 1990) to
extract these high-level features, a suitably realistic representation of the brain
capable of encoding templates. SoMs are a theoretical neural network architecture
for the learning and representation of abstract information in the cerebral cortex.
Used principally as a data-mining technique, SoMs have recently come to be
thought of as a realistic model of certain types of learning. Kohonen (1993) has
described some biological mechanisms SoMs model and this has been followed by
1 See http://senseis.xmp.net/ for an introduction to the game.
Intuitive Expertise and Perceptual Templates
169
123

work on the spatial order of feature sensitive neurons (Kohonen and Hari 1999) and
as a model of maps in the visual cortex (Swindale 2000).
A SoM is a neural network used to extract low dimensional regularities from high
dimensional data while preserving the topological relationships of the original data.
The ‘neurons’ are arranged on a regular 2-dimensional grid (50 9 50 throughout
this work) and each neuron is a vectorial representation of the input space. Initially
all neurons ni, i 2 f1; . . .; 2; 500g2, are randomly assigned weights within a suitable
range, for this work the range is [-1,1]. In the learning phase, an example vector of
the input space is presented to the SoM and the ‘distance’ between the input vector
and all SoM neurons is computed, this is generally the Euclidean distance. The SoM
neuron that minimises this distance is selected and the weights of this neuron as
well as those of other topologically local neurons are updated. After training on
many different samples from the input space, the neurons are clustered according
to the similarities between their learned positional weights. For a training vector
xi (a vectorial representation of a Go game with game pieces on the board) the
mathematical steps are:
dðxi; ncÞ ¼
min
j2f1;...;Ngðdðxi; njÞÞ
ð1Þ
nafter
k
¼ nbefore
k
þ j  a  dðxi; nkÞ
ð2Þ
where dð; Þ is the Euclidean distance, j is a neighbourhood function and a is a
learning rate (Kohonen 1990). The k indexes the neurons nk that are considered
‘local’ to neuron nc via the neighbourhood function j. Despite the apparent sim-
plicity of the algorithm, there are many subtleties associated with convergence rates
using SoMs, all of which have been addressed in the literature and the net result is
the Matlab SoM toolbox developed by the Helsinki group used in this work
(Vesanto et al. 2000).
The key features of the SoM architecture are that 1. It is an unsupervised
learning technique needing no evaluation function, 2. It exhibits non-linear
learning behaviour that approximates the way in which biological neural networks
learn, 3. It preserves the underlying structure of the environment and 4. It acts to
reduce the dimensionality of the problem. These factors combine to provide an
effective model for the abstract learning and representation of Go board positions.
Results
In order to study decisions made during play and the context in which they occurred
we took 22,524 game records of professional Go players3 that have many years of
experience and encoded them in a large database of sequences of moves. With
approximately 200 moves per game this provides us with around 4.5 million
2 There are 19 9 19 = 361 positions on the board, the training vectors and the neurons represent a board
as a vector of 361 elements and there are 50 9 50 = 2,500 neurons in each SoM. There is one SoM
trained for each of the 361 positions.
3 Taken from the commercial GoGod database, Winter 2009 version.
170
M. Harre´, A. Snyder
123

individual decisions made by some of the best players in the world. For each
position on the board the database was searched for when that move was made,
taking account of stones that needed to be removed due to being captured. When
each move was made the current board conﬁguration was encoded in a 1 9 361
vector composed of the state of each of the 361 positions, either white (1), black
(-1) or empty (0). The last step in the data pre-processing was to multiply the
conﬁguration vector by -1 if the move being made was black. The result is that
each move is essentially a white move and all stone colours in each board
conﬁguration are relative colours with respect to the move being made.
This results in i 2 f1; . . .; 361g matrices, one for each possible move on the board,
each matrix is labelled Mi where i is the linear counterpart to the two dimensional
board co-ordinate where a move was made. The dimensions of the Mi are 361 9 Ni
where the 361 rows correspond to the state of each position on the board when move
i was made, position i itself is always 0 as it needs to be empty in order for a move to be
made there, and Ni is the number of games in which move i was actually made. The
maximum value of Ni = 22,524, i.e. the total number of game records, however
sometimes a speciﬁc move might not have been made in a given game leading to fewer
game records. We view each Mi as a database of Ni images, visual snapshots of the
board when move i was made. It is these images of the board state that is then passed to
the SoM and we processed each Mi separately, leading to 361 separate SoMs, i.e. a
50 9 50 neural network for every move on the board.
The parameters used for training the SoMs are not changed throughout our
reported results, but prior experimentation did not result in signiﬁcant qualitative
variation in outputs. We used no masking of the board and we did not differentially
weight any part of the input vectors so that the entire unweighted board state was
used to train the SoMs. Each of the 361 SoMs contained 50 9 50 = 2,500 neurons
resulting in a total of 902,500 trained neurons. Figure 1 shows an example neural
network for a speciﬁc move i = 41, which translated into board co-ordinates is a
move at position [3,3], a single neuron that has encoded the board position weights
and the board layout that results from translating the neuron weights into the
corresponding 19 9 19 board conﬁguration. We label each trained SoM Si.
We deﬁne a template as a set of learned weights of co-occurring stones encoded
by a single neuron where each absolute weight is greater than a threshold value Ti.
We require that the stones to be consistently co-occurring as it is the perceptual
constancy of such patterns that represents the learned context for each move, this is
a necessary component for perceptual learning (Garrigan and Kellman 2008).
Consider the particular neuron for SoM S41 shown in the middle plot of Fig. 1. With
T41 = 0.5 the template encoded by this neuron contains 12 stones, nine of which
form a very common pattern near the move the SoM was trained for (a white stone
placed at position [3,3]) of which four are white and ﬁve are black. This template
would also include two other white stones, one in the bottom right corner and one in
the bottom left corner and a black stone in the top right corner.
In practice we deﬁned the Ti in terms of the mean of the elements of each
Si : Ti ¼
C
2;500361
P
j;k jSiðj; kÞj where j is the neuron index, k is the board position
of a learned weight and C is a constant multiple. We experimented with various
Intuitive Expertise and Perceptual Templates
171
123

-
-
-
-
-
172
M. Harre´, A. Snyder
123

values 2 B C B 6 and while quantitatively different results were achieved the
qualitative differences were not appreciable. We set C = 3 throughout. In this
setting, the notion of templates is only meaningful if they encode information about
the co-occurrence of stones, i.e. a template is a learned pattern of co-occurring stone
weights above a threshold. Note that this thresholding leads to a single SoM
possibly encoding more than one instance of a given template. The information
content of an Si can be quantiﬁed by measuring the amount of information encoded
in each unique template and comparing it with the amount of information encoded
by a model of each position being independent of every other, we show how we did
this next.
A naive estimate of the total number of possible images of the board is
2 9 10170, i.e. the total number of board conﬁgurations. This is an overestimate of
the number of images we are likely to observe in practice because some board
positions are more likely to be in one state than in either of the other two, this is true
even if we consider each board position to be independent (de-coupled) from every
other. On the other hand some positions are also more likely to co-occur in one of
the three possible states than we should expect assuming positions are de-coupled,
these coupled board positions further reduce the number of board images we are
likely to observe. We next introduce the necessary notation from information theory
in order to measure the difference between observing a board image assuming
positions are de-coupled versus being coupled.
We label each of the k 2 f1; . . .; 361g positions encoded by a single neuron j as
rj,k. We view this as a stochastic variable with three states rj;k 2 f1; 0; 1g where
rj,k = 1 if the learned weight for position k is greater than Ti, rj,k = -1 if the
weight is \ -Ti and 0 otherwise. We index the unique templates in Si with u and
label each template in Si for a given Ti as su, the probability of each template is:
piðsuÞ ¼ nðsuÞ
2;500 where n(su) is the number of times su occurs in Si. The independent
probabilities for each position k are piðrkÞ ¼ njðrj;kÞ
2;500 where nj(rj,k) is the total number
of neurons in Si that, after thresholding, are either 1, -1 or 0 (depending on the
stochastic variable rk on the left hand side) for board position j and the independent
distribution
across
all
positions
is
the
product
of
these
probabilities:
piðrÞ ¼ Q
k piðrkÞ.
The information content of a single outcome i for any probability distribution is
 log
1
pðriÞ


. However, we are interested in the difference between the amount of
information in one distribution p(r) compared to that of a second distribution
qðrÞ : log
1
qðriÞ


 log
1
pðriÞ


¼ log
pðriÞ
qðriÞ


. Using this notion, the weighted amount
of information template su contributes over and above the independent case for Si is
given by:
Fig. 1 An example SoM trained for a move at position [3,3] (top left corner of the board in the bottom
plot) Top a plot of the weights for all 2,500 trained neurons (SoM S41, see main text). Middle the plot of a
single neuron’s learned weights. Bottom the weights from the middle plot translated into the original
board coordinates. Note that the move at [3,3] (top left corner) that this SoM was trained for is a common
move given the cluster of stone in the top left corner (the cluster is called the ‘large avalanche’)
b
Intuitive Expertise and Perceptual Templates
173
123

KLðpiðsuÞjpiðrÞÞ ¼ piðsuÞ log piðsuÞ
piðrÞ


ð3Þ
This is a single term from the summation used for the Kullback-Liebler divergence
(Lin 1991) between two distributions. It measures in bits (we use base 2 logs
throughout) the difference in information encoded in template u compared to an
independent interpretation of stone occurrences where the individual stones are not
thought of as being coupled together, i.e. it is a measure of how much SoM Si has
learned about the co-occurrence of stones when move i is made. In order to plot the
total information content provided by all templates for each location i on the board
we attribute the value of KL(pi(su)|pi(r)) to the position of each stone in template su,
then for each move i we summed the contributions across all unique templates
u within Si, providing a single number quantiﬁcation for each i about how much
information Si has encoded in all of its templates, this is plotted in Fig. 2. The data
in this ﬁgure has been symmetrised.
Finally, we wish to measure the relationship between localised and non-localised
contextual information. This provides an insight into how much of the template
information encoded in each Si is local with respect to where each move was made.
We deﬁne ‘local’ for three different distances from where each move i is made. The
metric we use for the distance between two points k1 and k2 is the Manhattan metric
M(k1,k2) as this distance reﬂects the strategic distance implicit in the connection of
two stones. If M(k1,k2) = 1 then two stones located at k1 and k2 are connected in a
chain, if M(k1,k2) = 2 then these two stones can be connected within one move etc.
Fig. 2 When a move is made on the board, a player uses information from other positions on the board,
this ﬁgure shows how much information the templates for each move use, measured in bits. The 4,4
position (and it’s symmetries) use the most and the sides and middle use the least amount of information.
The results have been averaged across the board symmetries
174
M. Harre´, A. Snyder
123

For a given move made at position i, the three deﬁnitions of local we use is the
information content of the positions for each k in which these inequalities are true:
M(i,k) B 1, M(i,k) B 2 and M(i,k) B 3. Within these regions we summed the
information content across the local k positions in the same way as we did
previously for the entire board. We then report the proportion of local to non-local
information content for each move on the board by dividing the local information
content by the total information content of the board calculated previously. The
results are shown in Fig. 3.
Discussion and Conclusions
This work centres on the learning of perceptual templates in a complex, cluttered
decision task using techniques not previously applied to strategic game decisions.
We developed a cognitive model for the extraction of a type of contextual
information, the templates of a strategic decision task. Templates are important as
they provide for complex decisions the same type of information usually studied in
scene analysis and perceptual learning: A method for rapid analysis that quickly
extracts the most important features, directing attention to speciﬁc regions and
providing a global context in which more localised and deliberate analysis such as
forward search and planning can be focused. This enables us to recover the
contextual information of a game position without the need of prohibitively large
databases for exact pattern matching or an evaluation function, both of which are
often lacking in many important applications of complex decision tasks.
We have also shown that this context can be extracted by an artiﬁcial neural
network that encodes the contextual templates as the weights of different board
positions that represent the relevant cues for decisions. Such templates are critical to
the ability of world class players to very rapidly understand the current state of the
game and to generate estimates of good next moves. In order to do so we used Self-
organising Maps trained on a database of games played by professionals of rank 5
dan or greater, a level typically requiring at least ten or more years of diligent study
and so satisfying Ericsson’s estimate (Ericsson et al. 1993) of the minimum effort
required to acquire expertise. We discuss the details of these results and the broader
implications below.
Discussion of Results
Our principal result is shown in Fig. 2. This is the total information learned by each
SoM (each Si, i 2 f1; . . .; 361g) and is related to the probability of stones co-
occurring when move i is made as compared with each stone being independent of
every other. The most striking feature is the role played by the corner position [4,4]
and its symmetries. These positions play an important role in Go strategy, but here
we have shown that their signiﬁcance stems in part from the fact that a move played
on one of these points requires more contextual learning than any other position on
the board. This is in sharp contrast to all of the edge positions, for example, but
especially the [1,1] position and its symmetries that learn one tenth the amount of
Intuitive Expertise and Perceptual Templates
175
123

176
M. Harre´, A. Snyder
123

information of the [4,4] positions. The inhomogeneous nature of contextual
information learned in different regions of the board highlights the variation in
template learning and the contextual cues they provide to players.
We have also shown in Fig. 3 using three different deﬁnitions of ‘local
information’ that the ratio of local to total information content of the templates
varies considerably across the board. We show that the ﬁrst ﬁve diagonal points
radiating inwards from the corners, the [1,1], [2,2], [3,3], [4,4] and [5,5] points and
their symmetries, have more local information content than any other positions
where local is deﬁned as within one position of these moves (M(i,k) B 1). However,
as we increase the deﬁnition of local the moves immediately around these diagonals
integrate the information content of these diagonal positions while the diagonals
themselves increase only very slightly suggesting they do not integrate very much of
the immediately local positions. As the deﬁnition of local increases to include the
whole board the ratio will tend to 1.0 for every position, so we conclude that the
diagonal positions integrate much more information from other parts of the board
while off diagonal positions access this global information by incorporating the
diagonal positions within their local templates.
Taking these results together we see that the [4,4] points act as a hub in a network
of contextual templates that allow local positions to access global information
content via these hubs, demonstrating the subtlety of the interaction between local
and non-local contextual information. This analysis is signiﬁcant as it informs the
debate regarding the degree to which local and non-local contextual information
informs our perceptual comprehension (Brockmole et al. 2006). That is to say that
the context of a board scene can have both a local and a non-local component and
the degree of the non-local information changes depending on the move that is
being made.
Beyond these immediate results we also draw some conclusions regarding the
speciﬁc cognitive strategies employed in complex tasks and where there is some
overlap in current artiﬁcial intelligence and cognitive studies research. Speciﬁcally
we address certain key points in the role of deliberate and implicit reasoning, the
roles played by different facets of learning and cognition for complex tasks and the
role of individual-differences measures in game performance.
Two Systems for Reasoning, At Least
Recently there has been a great deal of work addressing the many different types of
reasoning, their strengths and weaknesses and their underlying neural mechanisms.
The two forms of reasoning of interest in this work are the implicit and explicit
reasoning systems as discussed by Kahneman in his Nobel Prize lecture (Khaneman
2003) and recently reviewed by Evans (2008). While Evans ultimately cautions
against the overuse of dual-process theories there is a consistent and important result
Fig. 3 Similar to Fig. 2 these ﬁgures show the percentage of local information to total information each
move uses. The vertical axis in each plot is a measure of how much information (for each move) comes
from local game pieces and how much comes from non-local game pieces, for three different deﬁnitions
of local: M(i,k) B 1, M(i,k) B 2, M(i,k) B 3. The results have been symmetrised as in Fig. 2
b
Intuitive Expertise and Perceptual Templates
177
123

he and Kahneman point to: there is a slow, deliberative and conscious reasoning
process (system 2) that is inﬂuenced by a fast, preconscious process that
contextualises and shapes deliberative reasoning (system 1). Evans points out that
one of the strongest bases on which a dual-process model may be argued for is that
controlled cognitive processes correlate with individual differences in general
intelligence while automatic processes do not.
System 2 is most strongly identiﬁed with working memory capacity, ﬂuid
intelligence (Gf) and executive attention in the prefrontal cortex (PfC) (Kane and
Engle 2002). Strong correlations have been found between measures of Gf and
working memory (Engle et al. 1999) and the underlying neural structures have been
shown to co-vary with Gf (Gray et al. 2003). The PfC has also been implicated in
conscious strategic reasoning where the depth of such reasoning correlates with
strategic IQ (Coricelli and Nagel 2009), deﬁned as the ability to win a competitive
game of strategy. While system 2 mechanisms are vital to our everyday reasoning,
playing a signiﬁcant part in our inductive and deductive reasoning and the conscious
control of our attentional resources, it has signiﬁcant capacity restrictions as ﬁrst
studied by Miller (1956) and explored extensively since.
On the other hand system 1 has been identiﬁed with slowly acquired, rapidly
executed, sub- or pre-conscious processes that are not capacity constrained and are
not available to our conscious (system 2) processes (Evans 2008). Such processes
have been conjectured to extend even to higher cognitive processes such as social
cognition (Bargh and Ferguson 2000). There is considerable debate regarding the
involvement of system 2 in the acquisition of system 1 knowledge. While
perceptual automaticity is known to occur in simple decision tasks (Bargh and
Chartrand 1999), it has also been reported in complex domains such as chess
(Reingold et al. 2001). Some studies have suggested that activities start out as being
consciously controlled and effortful and only after extensive practice become
automated and no longer part of conscious awareness (Aarts and Dijksterhuis 2000).
Other studies point to the way in which we implicitly learn visual cues that lie below
the threshold of conscious awareness and that these cues inﬂuence future decisions
(Chun and Jiang 1998). While we offer no particular opinion regarding the way in
which system 1 knowledge is acquired, we present arguments in favour of the
templates we have studied belonging to a system 1 type of reasoning.
Perhaps the most striking point regarding system 1 processes, and that which has
most signiﬁcance for the generalisation of our results, is that it is exceptionally
ﬂexible in that it can be applied in any situation. Aside from some minor technical
aspects to the preprocessing of our data, which could just as readily be implemented
at a very early stage in a biological brain, the relationships discovered by the SoM
algorithm used here, based on suitably encoded input vectors, could be related to
any complex task requiring the uncovering of non-linear relations between co-
occurring perceptual elements. Extending the task to chess, for example, would
require a different and probably more sophisticated encoding of the board, more
sophisticated because chess contains inhomogeneous game pieces with different
rules relating the spatial relationships between the different pieces. But in principle
there is no reason to doubt similar success in recovering chess templates. More
178
M. Harre´, A. Snyder
123

generally, any statistically correlated percepts can be expected to be combined if
they co-occur frequently enough by a SoM similar to that used in this study.
Perceptual Cues and the Integration of Global Information
The study of visual learning provides rich support for the learning of subtle
perceptual cues and the role they play in comprehension and decision making. It has
been shown that such learning plays an important role in global scene analysis
(Oliva and Torralba 2006; Brockmole et al. 2006), scene categorisation (Torralba
et al. 2006), contextually conditioned attention (Chun and Jiang 1998; Chun 2000),
eye-movement guidance (Neider and Zelinsky 2006) and search improvement
(Chun and Jiang 1999; Bar 2004) in complex and cluttered natural scenes. It has
also been noted that some types of visual learning affect more than the visual cortex,
inﬂuencing decision making regions in the parietal lobe as well (Petrov et al. 2005;
Dosher and Lu 1998). Other studies have suggested that such memory also has an
almost unlimited capacity even for detailed representations of visual images (Brady
et al. 2008).
We interpret these visual studies in terms of the key properties of expertise in
complex tasks such as Go and chess. Rapid and effective visual recognition and
global processing of information have previously been argued for as an alternative
to pure forward search in explaining chess expertise (Gobet and Simon 1996;
Bukach et al. 2006). The notion that this might be an unconscious process has also
been explored recently (Kiesel et al. 2009; Reingold et al. 2001) as has the
underlying neural basis of such skills in both chess (Atherton et al. 2003) and Go
(Chen et al. 2003). There has also been recent work on the implicit learning of local
game strategies and the associated neural correlates in Go (Itoh et al. 2008). These
studies provide exceptionally strong support for the role of fast, implicit and sub- or
pre-conscious processes that enable the remarkable abilities of experts to make
exceptional ‘intuitive guesses’. Our work is the ﬁrst example of the explicit
extraction of these perceptual templates from expert games showing how they might
be encoded directly in a neural network.
It has also been shown that tests of an individual’s intelligence has little or no
correlation with their level of chess skill except at the very early stages of learning
(see Bilalic et al. 2007 and references therein). Given the intellectually demanding
characteristics of strong chess playing these results are surprising. They do however
support the idea that perceptual learning dominates player strategy as skill increases.
General intelligence is associated with System 2 types of reasoning (slow, capacity
limited and conscious) and contributes signiﬁcantly to any novice’s reasoning in a
new environment. On the other hand as skill increases the opportunity for perceptual
learning increases and System 1 plays a more signiﬁcant role. Such perceptual
learning of the templates shown in this study enables large amounts of task speciﬁc
information to be gradually acquired over time and then rapidly deployed. We have
shown that the perceptual cues captured by these templates are global in their extent,
forming a network of relationships between the local and non-local aspects of the
game.
Intuitive Expertise and Perceptual Templates
179
123

With this in mind we reconsider the prodigious abilities of Capablanca and other
chess masters. A recent analysis (Guid and Bratko 2006) of Capablanca’s games has
shown that he preferred to play a ‘simple’ style of chess, a style in which
progressive deepening of the search for good moves does not often result in any new
moves being found. Contrast this with a ‘wild’ style in which progressive deepening
of search typically yields new information that changes the initial estimate of
whether a move is good or not. Such strategies tend to illicit more errors though,
even in very strong players. So in light of the discussion above, Capablanca played
in such a way that meant deep search was less signiﬁcant and so could rely on
highly reﬁned perceptual templates to formulate strategies, whereas a player who
favours more complex positions such as Fischer or Lasker (Guid and Bratko 2006)
would need to search many moves ahead to ensure that as many surprises as
possible are accounted for. In doing so such players engage the limited capacity of
their working memory for the task. Such insights allow us to better understand how
such talented players are able to carry out these incredible feats despite the apparent
shortcomings of our attention and working memory. Such insights will also allow us
to implement more effective AI systems through the use of effective psychological
and perceptual strategies.
Acknowledgments
This work was supported by ARC grant DP0881829 and by US Air Force grant
AOARD104116.
References
Aarts, H., & Dijksterhuis, A. (2000). Habits as knowledge structures: Automaticity in goal-directed
behavior. Journal of Personality and Social Psychology, 78(1), 53.
Ambady, N., & Rosenthal, R. (1992). Thin slices of expressive behavior as predictors of interpersonal
consequences: A meta-analysis. Psychological Bulletin, 111(2), 256.
Atherton, M., Zhuang, J., Bart, W., Hu, X., & He, S. (2003). A functional MRI study of high-level
cognition: I. The game of chess. Cognitive Brain Research, 16(1), 26–31.
Bar, M. (2004). Visual objects in context. Nature Reviews Neuroscience, 5(8), 617–629.
Bargh, J., & Chartrand, T. (1999). The unbearable automaticity of being. American Psychologist, 54(7), 462.
Bargh, J., & Ferguson, M. (2000). Beyond behaviorism: On the automaticity of higher mental processes.
Psychological Bulletin, 126(6), 925.
Bilalic, M., McLeod, P., & Gobet, F. (2007). Does chess need intelligence?—A study with young chess
players. Intelligence, 35(5), 457–470.
Bouzy, B., & Cazenave, T. (2001). Computer go: An AI oriented survey. Artiﬁcial Intelligence, 132(1),
39–103.
Brady, T., Konkle, T., Alvarez, G., & Oliva, A. (2008). Visual long-term memory has a massive storage
capacity for object details. Proceedings of the National Academy of Sciences, 105(38), 14,325.
Brockmole, J., Castelhano, M., & Henderson, J. (2006). Contextual cueing in naturalistic scenes: Global and
local contexts. Journal of Experimental Psychology: Learning, Memory, and Cognition, 32(4), 699.
Bukach, C., Gauthier, I., & Tarr, M. (2006). Beyond faces and modularity: The power of an expertise
framework. Trends in Cognitive Sciences, 10(4), 159–166.
Chase, W., & Simon, H. (1973). Perception in chess. Cognitive psychology, 4(1), 55–81.
Chen, X., Zhang, D., Zhang, X., Li, Z., Meng, X., He, S., et al. (2003). A functional MRI study of high-
level cognition: II. The game of go. Cognitive Brain Research, 16(1), 32–37.
Chun, M. (2000). Contextual cueing of visual attention. Trends in Cognitive Sciences, 4(5), 170–178.
Chun, M., & Jiang, Y. (1998). Contextual cueing: Implicit learning and memory of visual context guides
spatial attention. Cognitive Psychology, 36(1), 28–71.
180
M. Harre´, A. Snyder
123

Chun, M., & Jiang, Y. (1999). Top-down attentional guidance based on implicit learning of visual
covariation. Psychological Science, 10(4), 360.
Cleveland, A. (1907). The psychology of chess and of learning to play it. The American Journal of
Psychology, 18(3), 269–308.
Coricelli, G., & Nagel, R. (2009). Neural correlates of depth of strategic reasoning in medial prefrontal
cortex. Proceedings of the National Academy of Sciences, 106(23), 9163.
Dosher, B., & Lu, Z. (1998). Perceptual learning reﬂects external noise ﬁltering and internal noise
reduction through channel reweighting. Proceedings of the National Academy of Sciences, 95(23),
13,988.
Engle, R., Tuholski, S., Laughlin, J., & Conway, A. (1999). Working memory, short-term memory, and
general ﬂuid intelligence: A latent-variable approach. Journal of Experimental Psychology:
General, 128(3), 309.
Ericsson, K., Krampe, R., & Tesch-Ro¨mer, C. (1993). The role of deliberate practice in the acquisition of
expert performance. Psychological Review, 100(3), 363.
Evans, J. (2008). Dual-processing accounts of reasoning, judgment, and social cognition. Annual Review
of Psychology, 59, 255–278.
Garrigan, P., & Kellman, P. (2008). Perceptual learning depends on perceptual constancy. Proceedings of
the National Academy of Sciences, 105(6), 2248.
Gobet, F., & Simon, H. A. (1996). The roles of recognition processes and look-ahead search in time-
constrained expert problem solving: Evidence from grand-master-level chess. Psychological
Science, 7, 52–55.
Gobet, F., Lane, P., Croker, S., Cheng, P., Jones, G., Oliver, I., et al. (2001). Chunking mechanisms in
human learning. Trends in Cognitive Sciences, 5(6), 236–243.
Gray, J., Chabris, C., & Braver, T. (2003). Neural mechanisms of general ﬂuid intelligence. Nature
Neuroscience, 6(3), 316–322.
Guid, M., & Bratko, I. (2006). Computer analysis of world chess champions. ICGA Journal, 29(2), 65–73.
Harre´, M., Bossomaier, T., & Snyder, A. (2011). The development of human expertise in a complex
environment. Minds and Machines, 21(3), 449–464.
Hoock, J., Lee, C., Rimmel, A., Teytaud, F., Wang, M., & Teytaud, O. (2010). Intelligent agents for the
game of Go. Computational Intelligence Magazine, IEEE, 5(4), 28–42.
Itoh, K., Kitamura, H., Fujii, Y., & Nakada, T. (2008). Neural substrates for visual pattern recognition
learning in Igo. Brain Research, 1227, 162–173.
Kane, M., & Engle, R. (2002). The role of prefrontal cortex in working-memory capacity, executive
attention, and general ﬂuid intelligence: An individual-differences perspective. Psychonomic
Bulletin and Review, 9(4), 637–671.
Khaneman, D. (2003). A perspective on judgement and choice. American Psychologist, 58, 697–720.
Kiesel, A., Kunde, W., Pohl, C., Berner, M., & Hoffmann, J. (2009). Playing chess unconsciously.
Journal of Experimental Psychology: Learning, Memory, and Cognition, 35(1), 292.
Kohonen, T. (1982). Clustering, taxonomy, and topological maps of patterns. In Proceedings of 6IPCR:
International conference on pattern recognition.
Kohonen, T. (1990). The self-organizing map. Proceedings of the IEEE, 78(9), 1464–1480.
Kohonen, T. (1993). Physiological interpretation of the self-organizing map algorithm. Neural Networks,
6(7), 895–905.
Kohonen, T., & Hari, R. (1999). Where the abstract feature maps of the brain might come from. Trends in
Neurosciences, 22(3), 135–139.
Lin, J. (1991). Divergence measures based on the shannon entropy. IEEE Transactions on Information
Theory, 37(1), 145–151.
Miller, G. (1956). The magical number seven, plus or minus two: Some limits on our capacity for
processing information. Psychological Review, 63(2), 81.
Neider, M., & Zelinsky, G. (2006). Scene context guides eye movements during visual search. Vision
Research, 46(5), 614–621.
Oliva, A., & Torralba, A. (2006). Building the gist of a scene: The role of global image features in
recognition. Progress in Brain Research, 155, 23–36.
Petrov, A., Dosher, B., & Lu, Z. (2005). The dynamics of perceptual learning: an incremental reweighting
model. Psychological Review, 112(4), 715.
Reingold, E., Charness, N., Schultetus, R., & Stampe, D. (2001). Perceptual automaticity in expert chess
players: Parallel encoding of chess relations. Psychonomic Bulletin and Review, 8(3), 504–510.
Intuitive Expertise and Perceptual Templates
181
123

Reitman, J. (1976). Skilled perception in go: Deducing memory structures from inter-response times.
Cognitive Psychology, 8(3), 336–356.
Ross, P. (2006). The expert mind. Scientiﬁc American, 295(2), 64–71.
Shannon, C. (1950). Programming a computer for playing chess. Philosophical Magazine, 41(7),
256–275.
Simon, H., & Barenfeld, M. (1969). Information-processing analysis of perceptual processes in problem
solving. Psychological Review, 76(5), 473.
Simon, H. A., & Gobet, F. (1996). Templates in chess memory: A mechanism for recalling several
boards. Cognitive Psychology, 31, 1–40.
Stern, D., Herbrich, R., & Graepel, T. (2006). Bayesian pattern ranking for move prediction in the game
of Go. In Proceedings of the 23rd international conference on machine learning, ACM (pp.
873–880).
Swindale, N. (2000). How many maps are there in visual cortex?. Cerebral Cortex, 10(7), 633.
Torralba, A., Oliva, A., Castelhano, M., & Henderson, J. (2006). Contextual guidance of eye movements
and attention in real-world scenes: The role of global features in object search. Psychological
Review, 113(4), 766.
Tromp, J., & Farneba¨ck, G. (2007). Combinatorics of Go. Computers and Games, 84–99).
Vesanto, J., Himberg, J., Alhoniemi, E., Parhankangas, J., Team, S., & Oy, L. (2000). SOM toolbox for
matlab. Techn Ber, Helsinki University of Technology.
182
M. Harre´, A. Snyder
123

