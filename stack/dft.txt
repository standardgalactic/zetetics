Feedback Control Theory
John Doyle, Bruce Francis, Allen Tannenbaum
c‚ÉùMacmillan Publishing Co., 1990

Contents
Preface
iii
1
Introduction
1
1.1
Issues in Control System Design
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
What Is in This Book
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
2
Norms for Signals and Systems
13
2.1
Norms for Signals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13
2.2
Norms for Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
2.3
Input-Output Relationships . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
18
2.4
Power Analysis (Optional) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
2.5
Proofs for Tables 2.1 and 2.2 (Optional) . . . . . . . . . . . . . . . . . . . . . . . . .
21
2.6
Computing by State-Space Methods (Optional) . . . . . . . . . . . . . . . . . . . . .
24
3
Basic Concepts
31
3.1
Basic Feedback Loop . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
3.2
Internal Stability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
3.3
Asymptotic Tracking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
3.4
Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
40
4
Uncertainty and Robustness
45
4.1
Plant Uncertainty
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
45
4.2
Robust Stability
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
50
4.3
Robust Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
4.4
Robust Performance More Generally . . . . . . . . . . . . . . . . . . . . . . . . . . .
58
4.5
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
59
5
Stabilization
63
5.1
Controller Parametrization: Stable Plant . . . . . . . . . . . . . . . . . . . . . . . . .
63
5.2
Coprime Factorization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
65
5.3
Coprime Factorization by State-Space Methods (Optional) . . . . . . . . . . . . . . .
69
5.4
Controller Parametrization: General Plant . . . . . . . . . . . . . . . . . . . . . . . .
71
5.5
Asymptotic Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
5.6
Strong and Simultaneous Stabilization . . . . . . . . . . . . . . . . . . . . . . . . . .
75
5.7
Cart-Pendulum Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
i

6
Design Constraints
87
6.1
Algebraic Constraints
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
87
6.2
Analytic Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
88
7
Loopshaping
101
7.1
The Basic Technique of Loopshaping . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
7.2
The Phase Formula (Optional)
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
7.3
Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108
8
Advanced Loopshaping
117
8.1
Optimal Controllers
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
8.2
Loopshaping with C . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
8.3
Plants with RHP Poles and Zeros . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
8.4
Shaping S, T, or Q . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
8.5
Further Notions of Optimality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138
9
Model Matching
149
9.1
The Model-Matching Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
9.2
The Nevanlinna-Pick Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150
9.3
Nevanlinna‚Äôs Algorithm
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154
9.4
Solution of the Model-Matching Problem
. . . . . . . . . . . . . . . . . . . . . . . . 158
9.5
State-Space Solution (Optional) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
10 Design for Performance
163
10.1 P ‚àí1 Stable
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163
10.2 P ‚àí1 Unstable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168
10.3 Design Example: Flexible Beam
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
10.4 2-Norm Minimization
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
11 Stability Margin Optimization
181
11.1 Optimal Robust Stability
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
11.2 Conformal Mapping
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185
11.3 Gain Margin Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187
11.4 Phase Margin Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192
12 Design for Robust Performance
195
12.1 The ModiÔ¨Åed Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195
12.2 Spectral Factorization
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196
12.3 Solution of the ModiÔ¨Åed Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
12.4 Design Example: Flexible Beam Continued
. . . . . . . . . . . . . . . . . . . . . . . 204
References
209

Preface
Striking developments have taken place since 1980 in feedback control theory. The subject has be-
come both more rigorous and more applicable. The rigor is not for its own sake, but rather that even
in an engineering discipline rigor can lead to clarity and to methodical solutions to problems. The
applicability is a consequence both of new problem formulations and new mathematical solutions
to these problems. Moreover, computers and software have changed the way engineering design is
done. These developments suggest a fresh presentation of the subject, one that exploits these new
developments while emphasizing their connection with classical control.
Control systems are designed so that certain designated signals, such as tracking errors and
actuator inputs, do not exceed pre-speciÔ¨Åed levels.
Hindering the achievement of this goal are
uncertainty about the plant to be controlled (the mathematical models that we use in representing
real physical systems are idealizations) and errors in measuring signals (sensors can measure signals
only to a certain accuracy). Despite the seemingly obvious requirement of bringing plant uncertainty
explicitly into control problems, it was only in the early 1980s that control researchers re-established
the link to the classical work of Bode and others by formulating a tractable mathematical notion
of uncertainty in an input-output framework and developing rigorous mathematical techniques to
cope with it. This book formulates a precise problem, called the robust performance problem, with
the goal of achieving speciÔ¨Åed signal levels in the face of plant uncertainty.
The book is addressed to students in engineering who have had an undergraduate course in
signals and systems, including an introduction to frequency-domain methods of analyzing feedback
control systems, namely, Bode plots and the Nyquist criterion. A prior course on state-space theory
would be advantageous for some optional sections, but is not necessary. To keep the development
elementary, the systems are single-input/single-output and linear, operating in continuous time.
Chapters 1 to 7 are intended as the core for a one-semester senior course; they would need
supplementing with additional examples. These chapters constitute a basic treatment of feedback
design, containing a detailed formulation of the control design problem, the fundamental issue
of performance/stability robustness tradeoÔ¨Ä, and the graphical design technique of loopshaping,
suitable for benign plants (stable, minimum phase).
Chapters 8 to 12 are more advanced and
are intended for a Ô¨Årst graduate course.
Chapter 8 is a bridge to the latter half of the book,
extending the loopshaping technique and connecting it with notions of optimality. Chapters 9 to
12 treat controller design via optimization. The approach in these latter chapters is mathematical
rather than graphical, using elementary tools involving interpolation by analytic functions. This
mathematical approach is most useful for multivariable systems, where graphical techniques usually
break down. Nevertheless, we believe the setting of single-input/single-output systems is where this
new approach should be learned.
There are many people to whom we are grateful for their help in this book: Dale Enns for
sharing his expertise in loopshaping; Raymond Kwong and Boyd Pearson for class testing the book;
iii

and Munther Dahleh, Ciprian Foias, and Karen Rudie for reading earlier drafts. Numerous Caltech
students also struggled with various versions of this material: Gary Balas, Carolyn Beck, Bobby
Bodenheimer, and Roy Smith had particularly helpful suggestions. Finally, we would like to thank
the AFOSR, ARO, NSERC, NSF, and ONR for partial Ô¨Ånancial support during the writing of this
book.
iv

Chapter 1
Introduction
Without control systems there could be no manufacturing, no vehicles, no computers, no regulated
environment‚Äîin short, no technology. Control systems are what make machines, in the broadest
sense of the term, function as intended. Control systems are most often based on the principle
of feedback, whereby the signal to be controlled is compared to a desired reference signal and the
discrepancy used to compute corrective control action. The goal of this book is to present a theory
of feedback control system design that captures the essential issues, can be applied to a wide range
of practical problems, and is as simple as possible.
1.1
Issues in Control System Design
The process of designing a control system generally involves many steps. A typical scenario is as
follows:
1. Study the system to be controlled and decide what types of sensors and actuators will be used
and where they will be placed.
2. Model the resulting system to be controlled.
3. Simplify the model if necessary so that it is tractable.
4. Analyze the resulting model; determine its properties.
5. Decide on performance speciÔ¨Åcations.
6. Decide on the type of controller to be used.
7. Design a controller to meet the specs, if possible; if not, modify the specs or generalize the
type of controller sought.
8. Simulate the resulting controlled system, either on a computer or in a pilot plant.
9. Repeat from step 1 if necessary.
10. Choose hardware and software and implement the controller.
11. Tune the controller on-line if necessary.
1

2
CHAPTER 1. INTRODUCTION
It must be kept in mind that a control engineer‚Äôs role is not merely one of designing control
systems for Ô¨Åxed plants, of simply ‚Äúwrapping a little feedback‚Äù around an already Ô¨Åxed physical
system. It also involves assisting in the choice and conÔ¨Åguration of hardware by taking a system-
wide view of performance. For this reason it is important that a theory of feedback not only lead
to good designs when these are possible, but also indicate directly and unambiguously when the
performance objectives cannot be met.
It is also important to realize at the outset that practical problems have uncertain, non-
minimum-phase plants (non-minimum-phase means the existence of right half-plane zeros, so the
inverse is unstable); that there are inevitably unmodeled dynamics that produce substantial un-
certainty, usually at high frequency; and that sensor noise and input signal level constraints limit
the achievable beneÔ¨Åts of feedback.
A theory that excludes some of these practical issues can
still be useful in limited application domains. For example, many process control problems are so
dominated by plant uncertainty and right half-plane zeros that sensor noise and input signal level
constraints can be neglected. Some spacecraft problems, on the other hand, are so dominated by
tradeoÔ¨Äs between sensor noise, disturbance rejection, and input signal level (e.g., fuel consumption)
that plant uncertainty and non-minimum-phase eÔ¨Äects are negligible. Nevertheless, any general
theory should be able to treat all these issues explicitly and give quantitative and qualitative results
about their impact on system performance.
In the present section we look at two issues involved in the design process: deciding on perfor-
mance speciÔ¨Åcations and modeling. We begin with an example to illustrate these two issues.
Example A very interesting engineering system is the Keck astronomical telescope, currently
under construction on Mauna Kea in Hawaii. When completed it will be the world‚Äôs largest. The
basic objective of the telescope is to collect and focus starlight using a large concave mirror. The
shape of the mirror determines the quality of the observed image. The larger the mirror, the more
light that can be collected, and hence the dimmer the star that can be observed. The diameter of
the mirror on the Keck telescope will be 10 m. To make such a large, high-precision mirror out of
a single piece of glass would be very diÔ¨Écult and costly. Instead, the mirror on the Keck telescope
will be a mosaic of 36 hexagonal small mirrors. These 36 segments must then be aligned so that
the composite mirror has the desired shape.
The control system to do this is illustrated in Figure 1.1.
As shown, the mirror segments
are subject to two types of forces: disturbance forces (described below) and forces from actuators.
Behind each segment are three piston-type actuators, applying forces at three points on the segment
to eÔ¨Äect its orientation. In controlling the mirror‚Äôs shape, it suÔ¨Éces to control the misalignment
between adjacent mirror segments. In the gap between every two adjacent segments are (capacitor-
type) sensors measuring local displacements between the two segments. These local displacements
are stacked into the vector labeled y; this is what is to be controlled. For the mirror to have the
ideal shape, these displacements should have certain ideal values that can be pre-computed; these
are the components of the vector r. The controller must be designed so that in the closed-loop
system y is held close to r despite the disturbance forces. Notice that the signals are vector valued.
Such a system is multivariable.
Our uncertainty about the plant arises from disturbance sources:
‚Ä¢ As the telescope turns to track a star, the direction of the force of gravity on the mirror
changes.
‚Ä¢ During the night, when astronomical observations are made, the ambient temperature changes.

1.1. ISSUES IN CONTROL SYSTEM DESIGN
3
controller
actuators
mirror
segments
sensors
-
-
-
?

6
r
u
y
disturbance forces
Figure 1.1: Block diagram of Keck telescope control system.
‚Ä¢ The telescope is susceptible to wind gusts.
and from uncertain plant dynamics:
‚Ä¢ The dynamic behavior of the components‚Äîmirror segments, actuators, sensors‚Äîcannot be
modeled with inÔ¨Ånite precision.
Now we continue with a discussion of the issues in general.
Control Objectives
Generally speaking, the objective in a control system is to make some output, say y, behave in a
desired way by manipulating some input, say u. The simplest objective might be to keep y small
(or close to some equilibrium point)‚Äîa regulator problem‚Äîor to keep y ‚àír small for r, a reference
or command signal, in some set‚Äîa servomechanism or servo problem. Examples:
‚Ä¢ On a commercial airplane the vertical acceleration should be less than a certain value for
passenger comfort.
‚Ä¢ In an audio ampliÔ¨Åer the power of noise signals at the output must be suÔ¨Éciently small for
high Ô¨Ådelity.
‚Ä¢ In papermaking the moisture content must be kept between prescribed values.
There might be the side constraint of keeping u itself small as well, because it might be constrained
(e.g., the Ô¨Çow rate from a valve has a maximum value, determined when the valve is fully open)
or it might be too expensive to use a large input. But what is small for a signal? It is natural to
introduce norms for signals; then ‚Äúy small‚Äù means ‚Äú‚à•y‚à•small.‚Äù Which norm is appropriate depends
on the particular application.
In summary, performance objectives of a control system naturally lead to the introduction of
norms; then the specs are given as norm bounds on certain key signals of interest.

4
CHAPTER 1. INTRODUCTION
Models
Before discussing the issue of modeling a physical system it is important to distinguish among four
diÔ¨Äerent objects:
1. Real physical system: the one ‚Äúout there.‚Äù
2. Ideal physical model: obtained by schematically decomposing the real physical system into
ideal building blocks; composed of resistors, masses, beams, kilns, isotropic media, Newtonian
Ô¨Çuids, electrons, and so on.
3. Ideal mathematical model: obtained by applying natural laws to the ideal physical model;
composed of nonlinear partial diÔ¨Äerential equations, and so on.
4. Reduced mathematical model: obtained from the ideal mathematical model by linearization,
lumping, and so on; usually a rational transfer function.
Sometimes language makes a fuzzy distinction between the real physical system and the ideal
physical model. For example, the word resistor applies to both the actual piece of ceramic and
metal and the ideal object satisfying Ohm‚Äôs law. Of course, the adjectives real and ideal could be
used to disambiguate.
No mathematical system can precisely model a real physical system; there is always uncertainty.
Uncertainty means that we cannot predict exactly what the output of a real physical system will
be even if we know the input, so we are uncertain about the system. Uncertainty arises from two
sources: unknown or unpredictable inputs (disturbance, noise, etc.) and unpredictable dynamics.
What should a model provide? It should predict the input-output response in such a way that
we can use it to design a control system, and then be conÔ¨Ådent that the resulting design will work
on the real physical system. Of course, this is not possible. A ‚Äúleap of faith‚Äù will always be required
on the part of the engineer. This cannot be eliminated, but it can be made more manageable with
the use of eÔ¨Äective modeling, analysis, and design techniques.
Mathematical Models in This Book
The models in this book are Ô¨Ånite-dimensional, linear, and time-invariant. The main reason for this
is that they are the simplest models for treating the fundamental issues in control system design.
The resulting design techniques work remarkably well for a large class of engineering problems,
partly because most systems are built to be as close to linear time-invariant as possible so that they
are more easily controlled. Also, a good controller will keep the system in its linear regime. The
uncertainty description is as simple as possible as well.
The basic form of the plant model in this book is
y = (P + ‚àÜ)u + n.
Here y is the output, u the input, and P the nominal plant transfer function. The model uncertainty
comes in two forms:
n:
unknown noise or disturbance
‚àÜ:
unknown plant perturbation

1.1. ISSUES IN CONTROL SYSTEM DESIGN
5
Both n and ‚àÜwill be assumed to belong to sets, that is, some a priori information is assumed
about n and ‚àÜ. Then every input u is capable of producing a set of outputs, namely, the set of
all outputs (P + ‚àÜ)u + n as n and ‚àÜrange over their sets. Models capable of producing sets of
outputs for a single input are said to be nondeterministic. There are two main ways of obtaining
models, as described next.
Models from Science
The usual way of getting a model is by applying the laws of physics, chemistry, and so on. Consider
the Keck telescope example. One can write down diÔ¨Äerential equations based on physical principles
(e.g., Newton‚Äôs laws) and making idealizing assumptions (e.g., the mirror segments are rigid). The
coeÔ¨Écients in the diÔ¨Äerential equations will depend on physical constants, such as masses and
physical dimensions. These can be measured. This method of applying physical laws and taking
measurements is most successful in electromechanical systems, such as aerospace vehicles and robots.
Some systems are diÔ¨Écult to model in this way, either because they are too complex or because
their governing laws are unknown.
Models from Experimental Data
The second way of getting a model is by doing experiments on the physical system. Let‚Äôs start
with a simple thought experiment, one that captures many essential aspects of the relationships
between physical systems and their models and the issues in obtaining models from experimental
data. Consider a real physical system‚Äîthe plant to be controlled‚Äîwith one input, u, and one
output, y. To design a control system for this plant, we must understand how u aÔ¨Äects y.
The experiment runs like this. Suppose that the real physical system is in a rest state before
an input u is applied (i.e., u = y = 0). Now apply some input signal u, resulting in some output
signal y. Observe the pair (u, y). Repeat this experiment several times. Pretend that these data
pairs are all we know about the real physical system. (This is the black box scenario. Usually, we
know something about the internal workings of the system.)
After doing this experiment we will notice several things. First, the same input signal at diÔ¨Äerent
times produces diÔ¨Äerent output signals. Second, if we hold u = 0, y will Ô¨Çuctuate in an unpredictable
manner. Thus the real physical system produces just one output for any given input, so it itself
is deterministic. However, we observers are uncertain because we cannot predict what that output
will be.
Ideally, the model should cover the data in the sense that it should be capable of producing
every experimentally observed input-output pair. (Of course, it would be better to cover not just
the data observed in a Ô¨Ånite number of experiments, but anything that can be produced by the real
physical system. Obviously, this is impossible.) If nondeterminism that reasonably covers the range
of expected data is not built into the model, we will not trust that designs based on such models
will work on the real system.
In summary, for a useful theory of control design, plant models must be nondeterministic, having
uncertainty built in explicitly.
Synthesis Problem
A synthesis problem is a theoretical problem, precise and unambiguous. Its purpose is primarily
pedagogical: It gives us something clear to focus on for the purpose of study. The hope is that

6
CHAPTER 1. INTRODUCTION
the principles learned from studying a formal synthesis problem will be useful when it comes to
designing a real control system.
The most general block diagram of a control system is shown in Figure 1.2. The generalized plant
generalized
plant
controller
-
-
-

w
z
u
y
Figure 1.2: Most general control system.
consists of everything that is Ô¨Åxed at the start of the control design exercise: the plant, actuators
that generate inputs to the plant, sensors measuring certain signals, analog-to-digital and digital-
to-analog converters, and so on. The controller consists of the designable part: it may be an electric
circuit, a programmable logic controller, a general-purpose computer, or some other such device.
The signals w, z, y, and u are, in general, vector-valued functions of time. The components of w
are all the exogenous inputs: references, disturbances, sensor noises, and so on. The components of
z are all the signals we wish to control: tracking errors between reference signals and plant outputs,
actuator signals whose values must be kept between certain limits, and so on. The vector y contains
the outputs of all sensors. Finally, u contains all controlled inputs to the generalized plant. (Even
open-loop control Ô¨Åts in; the generalized plant would be so deÔ¨Åned that y is always constant.)
Very rarely is the exogenous input w a Ô¨Åxed, known signal. One of these rare instances is where
a robot manipulator is required to trace out a deÔ¨Ånite path, as in welding. Usually, w is not Ô¨Åxed
but belongs to a set that can be characterized to some degree. Some examples:
‚Ä¢ In a thermostat-controlled temperature regulator for a house, the reference signal is always
piecewise constant: at certain times during the day the thermostat is set to a new value. The
temperature of the outside air is not piecewise constant but varies slowly within bounds.
‚Ä¢ In a vehicle such as an airplane or ship the pilot‚Äôs commands on the steering wheel, throttle,
pedals, and so on come from a predictable set, and the gusts and wave motions have amplitudes
and frequencies that can be bounded with some degree of conÔ¨Ådence.
‚Ä¢ The load power drawn on an electric power system has predictable characteristics.
Sometimes the designer does not attempt to model the exogenous inputs. Instead, she or he
designs for a suitable response to a test input, such as a step, a sinusoid, or white noise. The
designer may know from past experience how this correlates with actual performance in the Ô¨Åeld.
Desired properties of z generally relate to how large it is according to various measures, as discussed
above.

1.2. WHAT IS IN THIS BOOK
7
Finally, the output of the design exercise is a mathematical model of a controller. This must
be implementable in hardware.
If the controller you design is governed by a nonlinear partial
diÔ¨Äerential equation, how are you going to implement it? A linear ordinary diÔ¨Äerential equation
with constant coeÔ¨Écients, representing a Ô¨Ånite-dimensional, time-invariant, linear system, can be
simulated via an analog circuit or approximated by a digital computer, so this is the most common
type of control law.
The synthesis problem can now be stated as follows: Given a set of generalized plants, a set
of exogenous inputs, and an upper bound on the size of z, design an implementable controller to
achieve this bound. How the size of z is to be measured (e.g., power or maximum amplitude)
depends on the context. This book focuses on an elementary version of this problem.
1.2
What Is in This Book
Since this book is for a Ô¨Årst course on this subject, attention is restricted to systems whose models
are single-input/single-output, Ô¨Ånite-dimensional, linear, and time-invariant. Thus they have trans-
fer functions that are rational in the Laplace variable s. The general layout of the book is that
Chapters 2 to 4 and 6 are devoted to analysis of control systems, that is, the controller is already
speciÔ¨Åed, and Chapters 5 and 7 to 12 to design.
Performance of a control system is speciÔ¨Åed in terms of the size of certain signals of interest. For
example, the performance of a tracking system could be measured by the size of the error signal.
Chapter 2, Norms for Signals and Systems, looks at several ways of deÔ¨Åning norms for a signal u(t);
in particular, the 2-norm (associated with energy),
Z ‚àû
‚àí‚àû
u(t)2dt
1/2
,
the ‚àû-norm (maximum absolute value),
max
t
|u(t)|,
and the square root of the average power (actually, not quite a norm),

lim
T‚Üí‚àû
1
2T
Z T
‚àíT
u(t)2dt
1/2
.
Also introduced are two norms for a system‚Äôs transfer function G(s): the 2-norm,
‚à•G‚à•2 :=
 1
2œÄ
Z ‚àû
‚àí‚àû
|G(jœâ)|2dœâ
1/2
,
and the ‚àû-norm,
‚à•G‚à•‚àû:= max
œâ
|G(jœâ)|.
Notice that ‚à•G‚à•‚àûequals the peak amplitude on the Bode magnitude plot of G. Then two very
useful tables are presented summarizing input-output norm relationships. For example, one table
gives a bound on the 2-norm of the output knowing the 2-norm of the input and the ‚àû-norm of the

8
CHAPTER 1. INTRODUCTION
C
P






-
-
-
-
-

?
?
6
r
u
y
d
n
‚àí
e
Figure 1.3: Single-loop feedback system.
transfer function. Such results are very useful in predicting, for example, the eÔ¨Äect a disturbance
will have on the output of a feedback system.
Chapters 3 and 4 are the most fundamental in the book. The system under consideration is
shown in Figure 1.3, where P and C are the plant and controller transfer functions. The signals are
as follows:
r
reference or command input
e
tracking error
u
control signal, controller output
d
plant disturbance
y
plant output
n
sensor noise
In Chapter 3, Basic Concepts, internal stability is deÔ¨Åned and characterized. Then the system is
analyzed for its ability to track a single reference signal r‚Äîa step or a ramp‚Äîasymptotically as
time increases. Finally, we look at tracking a set of reference signals. The transfer function from
reference input r to tracking error e is denoted S, the sensitivity function. It is argued that a useful
tracking performance criterion is ‚à•W1S‚à•‚àû< 1, where W1 is a transfer function which can be tuned
by the control system designer.
Since no mathematical system can exactly model a physical system, we must be aware of how
modeling errors might adversely aÔ¨Äect the performance of a control system. Chapter 4, Uncertainty
and Robustness, begins with a treatment of various models of plant uncertainty. The basic technique
is to model the plant as belonging to a set P. Such a set can be either structured‚Äîfor example,
there are a Ô¨Ånite number of uncertain parameters‚Äîor unstructured‚Äîthe frequency response lies in
a set in the complex plane for every frequency. For us, unstructured is more important because it
leads to a simple and useful design theory. In particular, multiplicative perturbation is chosen for
detailed study, it being typical. In this uncertainty model there is a nominal plant P and the family
P consists of all perturbed plants ÀúP such that at each frequency œâ the ratio ÀúP(jœâ)/P(jœâ) lies in a
disk in the complex plane with center 1. This notion of disk-like uncertainty is key; because of it
the mathematical problems are tractable.
Generally speaking, the notion of robustness means that some characteristic of the feedback
system holds for every plant in the set P. A controller C provides robust stability if it provides
internal stability for every plant in P. Chapter 4 develops a test for robust stability for the multi-
plicative perturbation model, a test involving C and P. The test is ‚à•W2T‚à•‚àû< 1. Here T is the

1.2. WHAT IS IN THIS BOOK
9
complementary sensitivity function, equal to 1 ‚àíS (or the transfer function from r to y), and W2
is a transfer function whose magnitude at frequency œâ equals the radius of the uncertainty disk at
that frequency.
The Ô¨Ånal topic in Chapter 4 is robust performance, guaranteed tracking in the face of plant
uncertainty. The main result is that the tracking performance spec ‚à•W1S‚à•‚àû< 1 is satisÔ¨Åed for all
plants in the multiplicative perturbation set if and only if the magnitude of |W1S| + |W2T| is less
than 1 for all frequencies, that is,
‚à•|W1S| + |W2T|‚à•‚àû< 1.
(1.1)
This is an analysis result: It tells exactly when some candidate controller provides robust perfor-
mance.
Chapter 5, Stabilization, is the Ô¨Årst on design. Most synthesis problems can be formulated like
this: Given P, design C so that the feedback system (1) is internally stable, and (2) acquires some
additional desired property or properties, for example, the output y asymptotically tracks a step
input r. The method of solution presented here is to parametrize all Cs for which (1) is true and
then to Ô¨Ånd a parameter for which (2) holds. In this chapter such a parametrization is derived; it
has the form
C = X + MQ
Y ‚àíNQ ,
where N, M, X, and Y are Ô¨Åxed stable proper transfer functions and Q is the parameter, an
arbitrary stable proper transfer function. The usefulness of this parametrization derives from the
fact that all closed-loop transfer functions are very simple functions of Q; for instance, the sensitivity
function S, while a nonlinear function of C, equals simply MY ‚àíMNQ. This parametrization
is then applied to three problems: achieving asymptotic performance specs, such as tracking a
step; internal stabilization by a stable controller; and simultaneous stabilization of two plants by a
common controller.
Before we see how to design control systems for the robust performance speciÔ¨Åcation, it is
important to understand the basic limitations on achievable performance: Why can‚Äôt we achieve
both arbitrarily good performance and stability robustness at the same time? In Chapter 6, Design
Constraints, we study design constraints arising from two sources: from algebraic relationships that
must hold among various transfer functions and from the fact that closed-loop transfer functions
must be stable, that is, analytic in the right half-plane. The main conclusion is that feedback control
design always involves a tradeoÔ¨Äbetween performance and stability robustness.
Chapter 7, Loopshaping, presents a graphical technique for designing a controller to achieve
robust performance. This method is the most common in engineering practice. It is especially
suitable for today‚Äôs CAD packages in view of their graphics capabilities. The loop transfer function
is L := PC.
The idea is to shape the Bode magnitude plot of L so that (1.1) is achieved, at
least approximately, and then to back-solve for C via C = L/P. When P or P ‚àí1 is not stable, L
must contain Ps unstable poles and zeros (for internal stability of the feedback loop), an awkward
constraint. For this reason, it is assumed in Chapter 7 that P and P ‚àí1 are both stable.
Thus Chapters 2 to 7 constitute a basic treatment of feedback design, containing a detailed
formulation of the control design problem, the fundamental issue of performance/stability robustness
tradeoÔ¨Ä, and a graphical design technique suitable for benign plants (stable, minimum-phase).
Chapters 8 to 12 are more advanced.

10
CHAPTER 1. INTRODUCTION
Chapter 8, Advanced Loopshaping, is a bridge between the two halves of the book; it extends the
loopshaping technique and connects it with the notion of optimal designs. Loopshaping in Chapter 7
focuses on L, but other quantities, such as C, S, T, or the Q parameter in the stabilization results
of Chapter 5, may also be ‚Äúshaped‚Äù to achieve the same end. For many problems these alternatives
are more convenient. Chapter 8 also oÔ¨Äers some suggestions on how to extend loopshaping to handle
right half-plane poles and zeros.
Optimal controllers are introduced in a formal way in Chapter 8. Several diÔ¨Äerent notions of
optimality are considered with an aim toward understanding in what way loopshaping controllers
can be said to be optimal.
It is shown that loopshaping controllers satisfy a very strong type
of optimality, called self-optimality.
The implication of this result is that when loopshaping is
successful at Ô¨Ånding an adequate controller, it cannot be improved upon uniformly.
Chapters 9 to 12 present a recently developed approach to the robust performance design prob-
lem. The approach is mathematical rather than graphical, using elementary tools involving interpo-
lation by analytic functions. This mathematical approach is most useful for multivariable systems,
where graphical techniques usually break down. Nevertheless, the setting of single-input/single-
output systems is where this new approach should be learned. Besides, present-day software for
control design (e.g., MATLAB and Program CC) incorporate this approach.
Chapter 9, Model Matching, studies a hypothetical control problem called the model-matching
problem: Given stable proper transfer functions T1 and T2, Ô¨Ånd a stable transfer function Q to
minimize ‚à•T1 ‚àíT2Q‚à•‚àû. The interpretation is this: T1 is a model, T2 is a plant, and Q is a cascade
controller to be designed so that T2Q approximates T1. Thus T1‚àíT2Q is the error transfer function.
This problem is turned into a special interpolation problem: Given points {ai} in the right half-
plane and values {bi}, also complex numbers, Ô¨Ånd a stable transfer function G so that ‚à•G‚à•‚àû< 1
and G(ai) = bi, that is, G interpolates the value bi at the point ai. When such a G exists and how
to Ô¨Ånd one utilizes some beautiful mathematics due to Nevanlinna and Pick.
Chapter 10, Design for Performance, treats the problem of designing a controller to achieve the
performance criterion ‚à•W1S‚à•‚àû< 1 alone, that is, with no plant uncertainty. When does such a
controller exist, and how can it be computed? These questions are easy when the inverse of the
plant transfer function is stable. When the inverse is unstable (i.e., P is non-minimum-phase), the
questions are more interesting. The solutions presented in this chapter use model-matching theory.
The procedure is applied to designing a controller for a Ô¨Çexible beam. The desired performance is
given in terms of step response specs: overshoot and settling time. It is shown how to choose the
weight W1 to accommodate these time domain specs. Also treated in Chapter 10 is minimization
of the 2-norm of some closed-loop transfer function, e.g., ‚à•W1S‚à•2.
Next, in Chapter 11, Stability Margin Optimization, is considered the problem of designing a
controller whose sole purpose is to maximize the stability margin, that is, performance is ignored.
The maximum obtainable stability margin is a measure of how diÔ¨Écult the plant is to control.
Three measures of stability margin are treated: the ‚àû-norm of a multiplicative perturbation, gain
margin, and phase margin. It is shown that the problem of optimizing these stability margins can
also be reduced to a model-matching problem.
Chapter 12, Design for Robust Performance, returns to the robust performance problem of
designing a controller to achieve (1.1).
Chapter 7 proposed loopshaping as a graphical method
when P and P ‚àí1 are stable. Without these assumptions loopshaping can be awkward and the
methodical procedure in this chapter can be used. Actually, (1.1) is too hard for mathematical

1.2. WHAT IS IN THIS BOOK
11
analysis, so a compromise criterion is posed, namely,
‚à•|W1S|2 + |W2T|2‚à•‚àû< 1/2.
(1.2)
Using a technique called spectral factorization, we can reduce this problem to a model-matching
problem. As an illustration, the Ô¨Çexible beam example is reconsidered; besides step response specs
on the tip deÔ¨Çection, a hard limit is placed on the plant input to prevent saturation of an ampliÔ¨Åer.
Finally, some words about frequency-domain versus time-domain methods of design. Horowitz
(1963) has long maintained that ‚Äúfrequency response methods have been found to be especially
useful and transparent, enabling the designer to see the tradeoÔ¨Äbetween conÔ¨Çicting design factors.‚Äù
This point of view has gained much greater acceptance within the control community at large
in recent years, although perhaps it would be better to stress the importance of input-output or
operator-theoretic versus state-space methods, instead of frequency domain versus time domain.
This book focuses almost exclusively on input-output methods, not because they are ultimately
more fundamental than state-space methods, but simply for pedagogical reasons.
Notes and References
There are many books on feedback control systems. Particularly good ones are Bower and Schultheiss
(1961) and Franklin et al. (1986). Regarding the Keck telescope, see Aubrun et al. (1987, 1988).

12
CHAPTER 1. INTRODUCTION

Chapter 2
Norms for Signals and Systems
One way to describe the performance of a control system is in terms of the size of certain signals
of interest. For example, the performance of a tracking system could be measured by the size of
the error signal. This chapter looks at several ways of deÔ¨Åning a signal‚Äôs size (i.e., at several norms
for signals). Which norm is appropriate depends on the situation at hand. Also introduced are
norms for a system‚Äôs transfer function. Then two very useful tables are developed summarizing
input-output norm relationships.
2.1
Norms for Signals
We consider signals mapping (‚àí‚àû, ‚àû) to R. They are assumed to be piecewise continuous. Of
course, a signal may be zero for t < 0 (i.e., it may start at time t = 0).
We are going to introduce several diÔ¨Äerent norms for such signals. First, recall that a norm
must have the following four properties:
(i) ‚à•u‚à•‚â•0
(ii) ‚à•u‚à•= 0 ‚áîu(t) = 0,
‚àÄt
(iii) ‚à•au‚à•= |a|‚à•u‚à•,
‚àÄa ‚ààR
(iv) ‚à•u + v‚à•‚â§‚à•u‚à•+ ‚à•v‚à•
The last property is the familiar triangle inequality.
1-Norm The 1-norm of a signal u(t) is the integral of its absolute value:
‚à•u‚à•1 :=
Z ‚àû
‚àí‚àû
|u(t)|dt.
2-Norm The 2-norm of u(t) is
‚à•u‚à•2 :=
Z ‚àû
‚àí‚àû
u(t)2dt
1/2
.
13

14
CHAPTER 2. NORMS FOR SIGNALS AND SYSTEMS
For example, suppose that u is the current through a 1 ‚Ñ¶resistor. Then the instantaneous power
equals u(t)2 and the total energy equals the integral of this, namely, ‚à•u‚à•2
2. We shall generalize this
interpretation: The instantaneous power of a signal u(t) is deÔ¨Åned to be u(t)2 and its energy is
deÔ¨Åned to be the square of its 2-norm.
‚àû-Norm The ‚àû-norm of a signal is the least upper bound of its absolute value:
‚à•u‚à•‚àû:= sup
t
|u(t)|.
For example, the ‚àû-norm of
(1 ‚àíe‚àít)1(t)
equals 1. Here 1(t) denotes the unit step function.
Power Signals The average power of u is the average over time of its instantaneous power:
lim
T‚Üí‚àû
1
2T
Z T
‚àíT
u(t)2dt.
The signal u will be called a power signal if this limit exists, and then the squareroot of the average
power will be denoted pow(u):
pow(u) :=

lim
T‚Üí‚àû
1
2T
Z T
‚àíT
u(t)2dt
1/2
.
Note that a nonzero signal can have zero average power, so pow is not a norm. It does, however,
have properties (i), (iii), and (iv).
Now we ask the question: Does Ô¨Åniteness of one norm imply Ô¨Åniteness of any others? There are
some easy answers:
1. If ‚à•u‚à•2 < ‚àû, then u is a power signal with pow(u) = 0.
Proof Assuming that u has Ô¨Ånite 2-norm, we get
1
2T
Z T
‚àíT
u(t)2dt ‚â§1
2T ‚à•u‚à•2
2.
But the right-hand side tends to zero as T ‚Üí‚àû. ‚ñ†
2. If u is a power signal and ‚à•u‚à•‚àû< ‚àû, then pow(u) ‚â§‚à•u‚à•‚àû.
Proof We have
1
2T
Z T
‚àíT
u(t)2dt ‚â§‚à•u‚à•2
‚àû
1
2T
Z T
‚àíT
dt = ‚à•u‚à•2
‚àû.
Let T tend to ‚àû. ‚ñ†

2.2. NORMS FOR SYSTEMS
15
pow
2
‚àû
1
Figure 2.1: Set inclusions.
3. If ‚à•u‚à•1 < ‚àûand ‚à•u‚à•‚àû< ‚àû, then ‚à•u‚à•2 ‚â§(‚à•u‚à•‚àû‚à•u‚à•1)1/2, and hence ‚à•u‚à•2 < ‚àû.
Proof
Z ‚àû
‚àí‚àû
u(t)2dt =
Z ‚àû
‚àí‚àû
|u(t)||u(t)|dt ‚â§‚à•u‚à•‚àû‚à•u‚à•1 ‚ñ†
A Venn diagram summarizing the set inclusions is shown in Figure 2.1. Note that the set labeled
‚Äúpow‚Äù contains all power signals for which pow is Ô¨Ånite; the set labeled ‚Äú1‚Äù contains all signals of
Ô¨Ånite 1-norm; and so on. It is instructive to get examples of functions in all the components of this
diagram (Exercise 2). For example, consider
u1(t) =
Ô£±
Ô£≤
Ô£≥
0,
if t ‚â§0
1/
‚àö
t,
if 0 < t ‚â§1
0,
if t > 1.
This has Ô¨Ånite 1-norm:
‚à•u1‚à•1 =
Z 1
0
1
‚àö
tdt = 2.
Its 2-norm is inÔ¨Ånite because the integral of 1/t is divergent over the interval [0, 1]. For the same
reason, u1 is not a power signal. Finally, u1 is not bounded, so ‚à•u1‚à•‚àûis inÔ¨Ånite. Therefore, u1 lives
in the bottom component in the diagram.
2.2
Norms for Systems
We consider systems that are linear, time-invariant, causal, and (usually) Ô¨Ånite-dimensional. In the
time domain an input-output model for such a system has the form of a convolution equation,
y = G ‚àóu,

16
CHAPTER 2. NORMS FOR SIGNALS AND SYSTEMS
that is,
y(t) =
Z ‚àû
‚àí‚àû
G(t ‚àíœÑ)u(œÑ)dœÑ.
Causality means that G(t) = 0 for t < 0.
Let ÀÜG(s) denote the transfer function, the Laplace
transform of G. Then ÀÜG is rational (by Ô¨Ånite-dimensionality) with real coeÔ¨Écients. We say that ÀÜG
is stable if it is analytic in the closed right half-plane (Re s ‚â•0), proper if ÀÜG(j‚àû) is Ô¨Ånite (degree
of denominator ‚â•degree of numerator), strictly proper if ÀÜG(j‚àû) = 0 (degree of denominator >
degree of numerator), and biproper if ÀÜG and ÀÜG‚àí1 are both proper (degree of denominator = degree
of numerator).
We introduce two norms for the transfer function ÀÜG.
2-Norm
‚à•ÀÜG‚à•2 :=
 1
2œÄ
Z ‚àû
‚àí‚àû
| ÀÜG(jœâ)|2dœâ
1/2
‚àû-Norm
‚à•ÀÜG‚à•‚àû:= sup
œâ | ÀÜG(jœâ)|
Note that if ÀÜG is stable, then by Parseval‚Äôs theorem
‚à•ÀÜG‚à•2 =
 1
2œÄ
Z ‚àû
‚àí‚àû
| ÀÜG(jœâ)|2dœâ
1/2
=
Z ‚àû
‚àí‚àû
|G(t)|2dt
1/2
.
The ‚àû-norm of ÀÜG equals the distance in the complex plane from the origin to the farthest point
on the Nyquist plot of ÀÜG. It also appears as the peak value on the Bode magnitude plot of ÀÜG. An
important property of the ‚àû-norm is that it is submultiplicative:
‚à•ÀÜG ÀÜH‚à•‚àû‚â§‚à•ÀÜG‚à•‚àû‚à•ÀÜH‚à•‚àû.
It is easy to tell when these two norms are Ô¨Ånite.
Lemma 1 The 2-norm of ÀÜG is Ô¨Ånite iÔ¨ÄÀÜG is strictly proper and has no poles on the imaginary
axis; the ‚àû-norm is Ô¨Ånite iÔ¨ÄÀÜG is proper and has no poles on the imaginary axis.
Proof
Assume that ÀÜG is strictly proper, with no poles on the imaginary axis. Then the Bode
magnitude plot rolls oÔ¨Äat high frequency. It is not hard to see that the plot of c/(œÑs+1) dominates
that of ÀÜG for suÔ¨Éciently large positive c and suÔ¨Éciently small positive œÑ, that is,
|c/(œÑjœâ + 1)| ‚â•| ÀÜG(jœâ)|,
‚àÄœâ.
But c/(œÑs + 1) has Ô¨Ånite 2-norm; its 2-norm equals c/
‚àö
2œÑ (how to do this computation is shown
below). Hence ÀÜG has Ô¨Ånite 2-norm.
The rest of the proof follows similar lines. ‚ñ†

2.2. NORMS FOR SYSTEMS
17
How to Compute the 2-Norm
Suppose that ÀÜG is strictly proper and has no poles on the imaginary axis (so its 2-norm is Ô¨Ånite).
We have
‚à•ÀÜG‚à•2
2
=
1
2œÄ
Z ‚àû
‚àí‚àû
| ÀÜG(jœâ)|2dœâ
=
1
2œÄj
Z j‚àû
‚àíj‚àû
ÀÜG(‚àís) ÀÜG(s)ds
=
1
2œÄj
I
ÀÜG(‚àís) ÀÜG(s)ds.
The last integral is a contour integral up the imaginary axis, then around an inÔ¨Ånite semicircle in
the left half-plane; the contribution to the integral from this semicircle equals zero because ÀÜG is
strictly proper. By the residue theorem, ‚à•ÀÜG‚à•2
2 equals the sum of the residues of ÀÜG(‚àís) ÀÜG(s) at its
poles in the left half-plane.
Example 1 Take ÀÜG(s) = 1/(œÑs + 1), œÑ > 0. The left half-plane pole of ÀÜG(‚àís) ÀÜG(s) is at s = ‚àí1/œÑ.
The residue at this pole equals
lim
s‚Üí‚àí1/œÑ

s + 1
œÑ

1
‚àíœÑs + 1
1
œÑs + 1 = 1
2œÑ .
Hence ‚à•ÀÜG‚à•2 = 1/
‚àö
2œÑ.
How to Compute the ‚àû-Norm
This requires a search. Set up a Ô¨Åne grid of frequency points,
{œâ1, . . . , œâN}.
Then an estimate for ‚à•ÀÜG‚à•‚àûis
max
1‚â§k‚â§N | ÀÜG(jœâk)|.
Alternatively, one could Ô¨Ånd where | ÀÜG(jœâ)| is maximum by solving the equation
d| ÀÜG|2
dœâ (jœâ) = 0.
This derivative can be computed in closed form because ÀÜG is rational. It then remains to compute
the roots of a polynomial.
Example 2 Consider
ÀÜG(s) = as + 1
bs + 1
with a, b > 0. Look at the Bode magnitude plot: For a ‚â•b it is increasing (high-pass); else, it is
decreasing (low-pass). Thus
‚à•ÀÜG‚à•‚àû=
 a/b,
a ‚â•b
1,
a < b.

18
CHAPTER 2. NORMS FOR SIGNALS AND SYSTEMS
2.3
Input-Output Relationships
The question of interest in this section is: If we know how big the input is, how big is the output
going to be? Consider a linear system with input u, output y, and transfer function ÀÜG, assumed
stable and strictly proper. The results are summarized in two tables below. Suppose that u is the
unit impulse, Œ¥. Then the 2-norm of y equals the 2-norm of G, which by Parseval‚Äôs theorem equals
the 2-norm of ÀÜG; this gives entry (1,1) in Table 2.1. The rest of the Ô¨Årst column is for the ‚àû-norm
and pow, and the second column is for a sinusoidal input. The ‚àûin the (1,2) entry is true as long
as ÀÜG(jœâ) Ã∏= 0.
u(t) = Œ¥(t)
u(t) = sin(œât)
‚à•y‚à•2
‚à•ÀÜG‚à•2
‚àû
‚à•y‚à•‚àû
‚à•G‚à•‚àû
| ÀÜG(jœâ)|
pow(y)
0
1
‚àö
2| ÀÜG(jœâ)|
Table 2.1: Output norms and pow for two inputs
Now suppose that u is not a Ô¨Åxed signal but that it can be any signal of 2-norm ‚â§1. It turns
out that the least upper bound on the 2-norm of the output, that is,
sup{‚à•y‚à•2 : ‚à•u‚à•2 ‚â§1},
which we can call the 2-norm/2-norm system gain, equals the ‚àû-norm of ÀÜG; this provides entry
(1,1) in Table 2.2. The other entries are the other system gains. The ‚àûin the various entries is
true as long as ÀÜG Ã∏‚â°0, that is, as long as there is some œâ for which ÀÜG(jœâ) Ã∏= 0.
‚à•u‚à•2
‚à•u‚à•‚àû
pow(u)
‚à•y‚à•2
‚à•ÀÜG‚à•‚àû
‚àû
‚àû
‚à•y‚à•‚àû
‚à•ÀÜG‚à•2
‚à•G‚à•1
‚àû
pow(y)
0
‚â§‚à•ÀÜG‚à•‚àû
‚à•ÀÜG‚à•‚àû
Table 2.2: System Gains
A typical application of these tables is as follows. Suppose that our control analysis or design
problem involves, among other things, a requirement of disturbance attenuation: The controlled
system has a disturbance input, say u, whose eÔ¨Äect on the plant output, say y, should be small. Let
G denote the impulse response from u to y. The controlled system will be required to be stable, so
the transfer function ÀÜG will be stable. Typically, it will be strictly proper, too (or at least proper).
The tables tell us how much u aÔ¨Äects y according to various measures. For example, if u is known
to be a sinusoid of Ô¨Åxed frequency (maybe u comes from a power source at 60 Hz), then the second
column of Table 2.1 gives the relative size of y according to the three measures. More commonly,
the disturbance signal will not be known a priori, so Table 2.2 will be more relevant.

2.4. POWER ANALYSIS (OPTIONAL)
19
Notice that the ‚àû-norm of the transfer function appears in several entries in the tables. This
norm is therefore an important measure for system performance.
Example A system with transfer function 1/(10s + 1) has a disturbance input d(t) known to have
the energy bound ‚à•d‚à•2 ‚â§0.4. Suppose that we want to Ô¨Ånd the best estimate of the ‚àû-norm of
the output y(t). Table 2.2 says that the 2-norm/‚àû-norm gain equals the 2-norm of the transfer
function, which equals 1/
‚àö
20. Thus
‚à•y‚à•‚àû‚â§0.4
‚àö
20.
The next two sections concern the proofs of the tables and are therefore optional.
2.4
Power Analysis (Optional)
For a power signal u deÔ¨Åne the autocorrelation function
Ru(œÑ) := lim
T‚Üí‚àû
1
2T
Z T
‚àíT
u(t)u(t + œÑ)dt,
that is, Ru(œÑ) is the average value of the product u(t)u(t + œÑ). Observe that
Ru(0) = pow(u)2 ‚â•0.
We must restrict our deÔ¨Ånition of a power signal to those signals for which the above limit exists
for all values of œÑ, not just œÑ = 0. For such signals we have the additional property that
|Ru(œÑ)| ‚â§Ru(0).
Proof The Cauchy-Schwarz inequality implies that

Z T
‚àíT
u(t)v(t)dt
 ‚â§
Z T
‚àíT
u(t)2dt
1/2 Z T
‚àíT
v(t)2dt
1/2
.
Set v(t) = u(t + œÑ) and multiply by 1/(2T) to get

1
2T
Z T
‚àíT
u(t)u(t + œÑ)dt
 ‚â§
 1
2T
Z T
‚àíT
u(t)2dt
1/2  1
2T
Z T
‚àíT
u(t + œÑ)2dt
1/2
.
Now let T ‚Üí‚àûto get the desired result. ‚ñ†
Let Su denote the Fourier transform of Ru. Thus
Su(jœâ)
=
Z ‚àû
‚àí‚àû
Ru(œÑ)e‚àíjœâœÑdœÑ,
Ru(œÑ)
=
1
2œÄ
Z ‚àû
‚àí‚àû
Su(jœâ)ejœâœÑdœâ,
pow(u)2
=
Ru(0) = 1
2œÄ
Z ‚àû
‚àí‚àû
Su(jœâ)dœâ.

20
CHAPTER 2. NORMS FOR SIGNALS AND SYSTEMS
From the last equation we interpret Su(jœâ)/2œÄ as power density. The function Su is called the
power spectral density of the signal u.
Now consider two power signals, u and v. Their cross-correlation function is
Ruv(œÑ) := lim
T‚Üí‚àû
1
2T
Z T
‚àíT
u(t)v(t + œÑ)dt
and Suv, the Fourier transform, is called their cross-power spectral density function.
We now derive some useful facts concerning a linear system with transfer function ÀÜG, assumed
stable and proper, and its input u and output y.
1. Ruy = G ‚àóRu
Proof Since
y(t) =
Z ‚àû
‚àí‚àû
G(Œ±)u(t ‚àíŒ±)dŒ±
(2.1)
we have
u(t)y(t + œÑ) =
Z ‚àû
‚àí‚àû
G(Œ±)u(t)u(t + œÑ ‚àíŒ±)dŒ±.
Thus the average value of u(t)y(t + œÑ) equals
Z ‚àû
‚àí‚àû
G(Œ±)Ru(œÑ ‚àíŒ±)dŒ±. ‚ñ†
2. Ry = G ‚àóGrev ‚àóRu where Grev(t) := G(‚àít)
Proof Using (2.1) we get
y(t)y(t + œÑ) =
Z ‚àû
‚àí‚àû
G(Œ±)y(t)u(t + œÑ ‚àíŒ±)dŒ±,
so the average value of y(t)y(t + œÑ) equals
Z ‚àû
‚àí‚àû
G(Œ±)Ryu(œÑ ‚àíŒ±)dŒ±
(i.e., Ry = G ‚àóRyu). Similarly, you can check that Ryu = Grev ‚àóRu. ‚ñ†
3. Sy(jœâ) = | ÀÜG(jœâ)|2Su(jœâ)
Proof From the previous fact we have
Sy(jœâ) = ÀÜG(jœâ) ÀÜGrev(jœâ)Su(jœâ),
so it remains to show that the Fourier transform of Grev equals the complex-conjugate of ÀÜG(jœâ).
This is easy. ‚ñ†

2.5. PROOFS FOR TABLES 2.1 AND 2.2 (OPTIONAL)
21
2.5
Proofs for Tables 2.1 and 2.2 (Optional)
Table 2.1
Entry (1,1) If u = Œ¥, then y = G, so ‚à•y‚à•2 = ‚à•G‚à•2. But by Parseval‚Äôs theorem, ‚à•G‚à•2 = ‚à•ÀÜG‚à•2.
Entry (2,1) Again, since y = G.
Entry (3,1)
pow(y)2
=
lim 1
2T
Z T
0
G(t)2dt
‚â§
lim 1
2T
Z ‚àû
0
G(t)2dt
=
lim 1
2T ‚à•G‚à•2
2
=
0
Entry (1,2) With the input u(t) = sin(œât), the output is
y(t) = | ÀÜG(jœâ)| sin[œât + arg ÀÜG(jœâ)].
(2.2)
The 2-norm of this signal is inÔ¨Ånite as long as ÀÜG(jœâ) Ã∏= 0, that is, the system‚Äôs transfer function
does not have a zero at the frequency of excitation.
Entry (2,2) The amplitude of the sinusoid (2.2) equals | ÀÜG(jœâ)|.
Entry (3,2) Let œÜ := arg ÀÜG(jœâ). Then
pow(y)2
=
lim 1
2T
Z T
‚àíT
| ÀÜG(jœâ)|2 sin2(œât + œÜ)dt
=
| ÀÜG(jœâ)|2 lim 1
2T
Z T
‚àíT
sin2(œât + œÜ)dt
=
| ÀÜG(jœâ)|2 lim
1
2œâT
Z œâT+œÜ
‚àíœâT+œÜ
sin2(Œ∏)dŒ∏
=
| ÀÜG(jœâ)|2 1
œÄ
Z œÄ
0
sin2(Œ∏)dŒ∏
=
1
2| ÀÜG(jœâ)|2.
Table 2.2
Entry (1,1) First we see that ‚à•ÀÜG‚à•‚àûis an upper bound on the 2-norm/2-norm system gain:
‚à•y‚à•2
2
=
‚à•ÀÜy‚à•2
2
=
1
2œÄ
Z ‚àû
‚àí‚àû
| ÀÜG(jœâ)|2|ÀÜu(jœâ)|2dœâ
‚â§
‚à•ÀÜG‚à•2
‚àû
1
2œÄ
Z ‚àû
‚àí‚àû
|ÀÜu(jœâ)|2dœâ
=
‚à•ÀÜG‚à•2
‚àû‚à•ÀÜu‚à•2
2
=
‚à•ÀÜG‚à•2
‚àû‚à•u‚à•2
2.

22
CHAPTER 2. NORMS FOR SIGNALS AND SYSTEMS
To show that ‚à•ÀÜG‚à•‚àûis the least upper bound, Ô¨Årst choose a frequency œâo where | ÀÜG(jœâ)| is
maximum, that is,
| ÀÜG(jœâo)| = ‚à•ÀÜG‚à•‚àû.
Now choose the input u so that
|ÀÜu(jœâ)| =
 c,
if |œâ ‚àíœâo| < «´ or |œâ + œâo| < «´
0,
otherwise,
where «´ is a small positive number and c is chosen so that u has unit 2-norm (i.e., c =
p
œÄ/2«´).
Then
‚à•ÀÜy‚à•2
2
‚âà
1
2œÄ
h
| ÀÜG(‚àíjœâo)|2œÄ + | ÀÜG(jœâo)|2œÄ
i
=
| ÀÜG(jœâo)|2
=
‚à•ÀÜG‚à•2
‚àû.
Entry (2,1) This is an application of the Cauchy-Schwarz inequality:
|y(t)|
=

Z ‚àû
‚àí‚àû
G(t ‚àíœÑ)u(œÑ)dœÑ

‚â§
Z ‚àû
‚àí‚àû
G(t ‚àíœÑ)2dœÑ
1/2 Z ‚àû
‚àí‚àû
u(œÑ)2dœÑ
1/2
=
‚à•G‚à•2‚à•u‚à•2
=
‚à•ÀÜG‚à•2‚à•u‚à•2.
Hence
‚à•y‚à•‚àû‚â§‚à•ÀÜG‚à•2‚à•u‚à•2.
To show that ‚à•ÀÜG‚à•2 is the least upper bound, apply the input
u(t) = G(‚àít)/‚à•G‚à•2.
Then ‚à•u‚à•2 = 1 and |y(0)| = ‚à•G‚à•2, so ‚à•y‚à•‚àû‚â•‚à•G‚à•2.
Entry (3,1) If ‚à•u‚à•2 ‚â§1, then the 2-norm of y is Ô¨Ånite [as in entry (1,1)], so pow(y) = 0.
Entry (1,2) Apply a sinusoidal input of unit amplitude and frequency œâ such that jœâ is not a
zero of ÀÜG. Then ‚à•u‚à•‚àû= 1, but ‚à•y‚à•2 = ‚àû.
Entry (2,2) First, ‚à•G‚à•1 is an upper bound on the ‚àû-norm/‚àû-norm system gain:
|y(t)|
=

Z ‚àû
‚àí‚àû
G(œÑ)u(t ‚àíœÑ)dœÑ

‚â§
Z ‚àû
‚àí‚àû
|G(œÑ)u(t ‚àíœÑ)| dœÑ
‚â§
Z ‚àû
‚àí‚àû
|G(œÑ)| dœÑ‚à•u‚à•‚àû
=
‚à•G‚à•1‚à•u‚à•‚àû.

2.5. PROOFS FOR TABLES 2.1 AND 2.2 (OPTIONAL)
23
That ‚à•G‚à•1 is the least upper bound can be seen as follows. Fix t and set
u(t ‚àíœÑ) := sgn(G(œÑ)),
‚àÄœÑ.
Then ‚à•u‚à•‚àû= 1 and
y(t)
=
Z ‚àû
‚àí‚àû
G(œÑ)u(t ‚àíœÑ)dœÑ
=
Z ‚àû
‚àí‚àû
|G(œÑ)|dœÑ
=
‚à•G‚à•1.
So ‚à•y‚à•‚àû‚â•‚à•G‚à•1.
Entry (3,2) If u is a power signal and ‚à•u‚à•‚àû‚â§1, then pow(u) ‚â§1, so
sup{pow(y) : ‚à•u‚à•‚àû‚â§1} ‚â§sup{pow(y) : pow(u) ‚â§1}.
We will see in entry (3,3) that the latter supremum equals ‚à•ÀÜG‚à•‚àû.
Entry (1,3) If u is a power signal, then from the preceding section,
Sy(jœâ) = | ÀÜG(jœâ)|2Su(jœâ),
so
pow(y)2 = 1
2œÄ
Z ‚àû
‚àí‚àû
| ÀÜG(jœâ)|2Su(jœâ)dœâ.
(2.3)
Unless | ÀÜG(jœâ)|2Su(jœâ) equals zero for all œâ, pow(y) is positive, in which case its 2-norm is inÔ¨Ånite.
Entry (2,3) This case is not so important, so a complete proof is omitted. The main idea is this:
If pow(u) ‚â§1, then pow(y) is Ô¨Ånite but ‚à•y‚à•‚àûis not necessarily (see u8 in Exercise 2). So for a
proof of this entry, one should construct an input with pow(u) ‚â§1, but such that ‚à•y‚à•‚àû= ‚àû.
Entry (3,3) From (2.3) we get immediately that
pow(y) ‚â§‚à•ÀÜG‚à•‚àûpow(u).
To achieve equality, suppose that
| ÀÜG(jœâo)| = ‚à•ÀÜG‚à•‚àû
and let the input be
u(t) =
‚àö
2 sin(œâot).
Then Ru(œÑ) = cos(œâoœÑ), so
pow(u) = Ru(0) = 1.

24
CHAPTER 2. NORMS FOR SIGNALS AND SYSTEMS
Also,
Su(jœâ) = œÄ [Œ¥(œâ ‚àíœâo) + Œ¥(œâ + œâo)] ,
so from (2.3)
pow(y)2
=
1
2| ÀÜG(jœâo)|2 + 1
2| ÀÜG(‚àíjœâo)|2
=
| ÀÜG(jœâo)|2
=
‚à•ÀÜG‚à•2
‚àû.
2.6
Computing by State-Space Methods (Optional)
This book is on classical control, which is set in the frequency domain. Current widespread practice,
however, is to do computations using state-space methods. The purpose of this optional section is
to illustrate how this is done for the problem of computing the 2-norm and ‚àû-norm of a transfer
function. The derivation of the procedures is brief.
Consider a state-space model of the form
Àôx(t)
=
Ax(t) + Bu(t),
y(t)
=
Cx(t).
Here u(t) is the input signal and y(t) the output signal, both scalar-valued. In contrast, x(t) is a
vector-valued function with, say, n components. The dot in Àôx means take the derivative of each
component. Then A, B, C are real matrices of sizes
n √ó n,
n √ó 1,
1 √ó n.
The equations are assumed to hold for t ‚â•0. Take Laplace transforms with zero initial conditions
on x:
sÀÜx(s)
=
AÀÜx(s) + BÀÜu(s),
ÀÜy(s)
=
CÀÜx(s).
Now eliminate ÀÜx(s) to get
ÀÜy(s) = C(sI ‚àíA)‚àí1BÀÜu(s).
We conclude that the transfer function from ÀÜu to ÀÜy is
ÀÜG(s) = C(sI ‚àíA)‚àí1B.
This transfer function is strictly proper. [Try an example: start with some A, B, C with n = 2,
and compute ÀÜG(s).]
Going the other way, from a strictly proper transfer function to a state-space model, is more
profound, but it is true that for every strictly proper transfer function ÀÜG(s) there exist (A, B, C)
such that
ÀÜG(s) = C(sI ‚àíA)‚àí1B.

2.6. COMPUTING BY STATE-SPACE METHODS (OPTIONAL)
25
From the representation
ÀÜG(s) =
1
det(sI ‚àíA)C adj(sI ‚àíA)B
it should be clear that the poles of ÀÜG(s) are included in the eigenvalues of A. We say that A is
stable if all its eigenvalues lie in Re s < 0, in which case ÀÜG is a stable transfer function.
Now start with the representation
ÀÜG(s) = C(sI ‚àíA)‚àí1B
with A stable. We want to compute ‚à•ÀÜG‚à•2 and ‚à•ÀÜG‚à•‚àûfrom the data (A, B, C).
The 2-Norm
DeÔ¨Åne the matrix exponential
etA := I + tA + t2
2!A2 + ¬∑ ¬∑ ¬∑
just as if A were a scalar (convergence can be proved). Let a prime denote transpose and deÔ¨Åne the
matrix
L :=
Z ‚àû
0
etABB‚Ä≤etA‚Ä≤dt
(the integral converges because A is stable). Then L satisÔ¨Åes the equation
AL + LA‚Ä≤ + BB‚Ä≤ = 0.
Proof Integrate both sides of the equation
d
dtetABB‚Ä≤etA‚Ä≤ = AetABB‚Ä≤etA‚Ä≤ + etABB‚Ä≤etA‚Ä≤A‚Ä≤
from 0 to ‚àû, noting that exp(tA) converges to 0 because A is stable, to get
‚àíBB‚Ä≤ = AL + LA‚Ä≤. ‚ñ†
In terms of L a simple formula for the 2-norm of ÀÜG is
‚à•ÀÜG‚à•2 = (CLC‚Ä≤)1/2.
Proof The impulse response function is
G(t) = CetAB,
t > 0.

26
CHAPTER 2. NORMS FOR SIGNALS AND SYSTEMS
Calling on Parseval we get
‚à•ÀÜG‚à•2
2
=
‚à•G‚à•2
2
=
Z ‚àû
0
CetABB‚Ä≤etA‚Ä≤C‚Ä≤dt
=
C
Z ‚àû
0
etABB‚Ä≤etA‚Ä≤dtC‚Ä≤
=
CLC‚Ä≤. ‚ñ†
So a procedure to compute the 2-norm is as follows:
Step 1 Solve the equation
AL + LA‚Ä≤ + BB‚Ä≤ = 0
for the matrix L.
Step 2
‚à•ÀÜG‚à•2 = (CLC‚Ä≤)1/2
The ‚àû-Norm
Computing the ‚àû-norm is harder; we shall have to be content with a search procedure. DeÔ¨Åne the
2n √ó 2n matrix
H :=

A
BB‚Ä≤
‚àíC‚Ä≤C
‚àíA‚Ä≤

.
Theorem 1 ‚à•ÀÜG‚à•‚àû< 1 iÔ¨ÄH has no eigenvalues on the imaginary axis.
Proof The proof of this theorem is a bit involved, so only suÔ¨Éciency is considered, and it is only
sketched.
It is not too hard to derive that
1/[1 ‚àíÀÜG(‚àís) ÀÜG(s)] = 1 +

0
B‚Ä≤ 
(sI ‚àíH)‚àí1
 B
0

.
Thus the poles of [1 ‚àíÀÜG(‚àís) ÀÜG(s)]‚àí1 are contained in the eigenvalues of H.
Assume that H has no eigenvalues on the imaginary axis. Then [1‚àíÀÜG(‚àís) ÀÜG(s)]‚àí1 has no poles
there, so 1 ‚àíÀÜG(‚àís) ÀÜG(s) has no zeros there, that is,
| ÀÜG(jœâ)| Ã∏= 1,
‚àÄœâ.
Since ÀÜG is strictly proper, this implies that
| ÀÜG(jœâ)| < 1,
‚àÄœâ
(i.e., ‚à•ÀÜG‚à•‚àû< 1). ‚ñ†
The theorem suggests this way to compute an ‚àû-norm: Select a positive number Œ≥; test if
‚à•ÀÜG‚à•‚àû< Œ≥ (i.e., if ‚à•Œ≥‚àí1 ÀÜG‚à•‚àû< 1) by calculating the eigenvalues of the appropriate matrix; increase
or decrease Œ≥ accordingly; repeat. A bisection search is quite eÔ¨Écient: Get upper and lower bounds
for ‚à•ÀÜG‚à•‚àû; try Œ≥ midway between these bounds; continue.

2.6. COMPUTING BY STATE-SPACE METHODS (OPTIONAL)
27
Exercises
1. Suppose that u(t) is a continuous signal whose derivative Àôu(t) is continuous too. Which of the
following qualiÔ¨Åes as a norm for u?
sup
t
| Àôu(t)|
|u(0)| + sup
t
| Àôu(t)|
max{sup
t
|u(t)|, sup
t
| Àôu(t)|}
sup
t
|u(t)| + sup
t
| Àôu(t)|
2. Consider the Venn diagram in Figure 2.1. Show that the functions u1 to u9, deÔ¨Åned below,
are located in the diagram as shown in Figure 2.2. All the functions are zero for t < 0.
u1
u7
u3
u9
u4
u5
u6
u2
u8
Figure 2.2: Figure for Exercise 2.
u1(t)
=

1/
‚àö
t,
if t ‚â§1
0,
if t > 1
u2(t)
=

1/t1/4,
if t ‚â§1
0,
if t > 1
u3(t)
=
1
u4(t)
=
1/(1 + t)
u5(t)
=
u2(t) + u4(t)
u6(t)
=
0
u7(t)
=
u2(t) + 1
For u8, set
vk(t) =
 k,
if k < t < k + k‚àí3
0,
otherwise

28
CHAPTER 2. NORMS FOR SIGNALS AND SYSTEMS
and then
u8(t) =
‚àû
X
1
vk(t).
Finally, let u9 equal 1 in the intervals
[22k, 22k+1],
k = 0, 1, 2, . . .
and zero elsewhere.
3. Suppose that ÀÜG(s) is a real-rational, stable transfer function with ÀÜG‚àí1 stable, too (i.e., neither
poles nor zeros in Re s ‚â•0). True or false: The Bode phase plot, ‚à†ÀÜG(jœâ) versus œâ, can be
uniquely constructed from the Bode magnitude plot, | ÀÜG(jœâ)| versus œâ. (Answer: false!)
4. Recall that the transfer function for a pure timedelay of œÑ time units is
ÀÜD(s) := e‚àísœÑ.
Say that a norm ‚à•‚à•on transfer functions is time-delay invariant if for every transfer function
ÀÜG (such that ‚à•ÀÜG‚à•< ‚àû) and every œÑ > 0,
‚à•ÀÜD ÀÜG‚à•= ‚à•ÀÜG‚à•.
Is the 2-norm or ‚àû-norm time-delay invariant?
5. Compute the 1-norm of the impulse response corresponding to the transfer function
1
œÑs + 1,
œÑ > 0.
6. For ÀÜG stable and strictly proper, show that ‚à•G‚à•1 < ‚àûand Ô¨Ånd an inequality relating ‚à•ÀÜG‚à•‚àû
and ‚à•G‚à•1.
7. This concerns entry (2,2) in Table 2.2. The given entry assumes that ÀÜG is stable and strictly
proper. When ÀÜG is stable but only proper, it can be expressed as
ÀÜG(s) = c + ÀÜG1(s)
with c constant and ÀÜG1 stable and strictly proper. Show that the correct (2,2)-entry is
|c| + ‚à•G1‚à•1.
8. Show that entries (2,2) and (3,2) in Table 2.1 and entries (1,1), (3,2), and (3,3) in Table 2.2
hold when ÀÜG is stable and proper (instead of strictly proper).
9. Let ÀÜG(s) be a strictly proper stable transfer function and G(t) its inverse Laplace transform.
Let u(t) be a signal of Ô¨Ånite 1-norm. True or false:
‚à•G ‚àóu‚à•1 ‚â§‚à•G‚à•1‚à•u‚à•1?

2.6. COMPUTING BY STATE-SPACE METHODS (OPTIONAL)
29
10. Consider a system with transfer function
œâ2
n
s2 + 2Œ∂œâns + œâ2n
,
Œ∂, œân > 0,
and input
u(t) = sin 0.1t,
‚àí‚àû< t < ‚àû.
Compute pow of the output.
11. Consider a system with transfer function
s + 2
4s + 1
and input u and output y. Compute
sup
‚à•u‚à•‚àû=1
‚à•y‚à•‚àû
and Ô¨Ånd an input achieving this supremum.
12. For a linear system with input u(t) and output y(t), prove that
sup
‚à•u‚à•‚â§1
‚à•y‚à•= sup
‚à•u‚à•=1
‚à•y‚à•
where the norm is, say, the 2-norm.
13. Show that the 2-norm for transfer functions is not submultiplicative.
14. Write a MATLAB program to compute the ‚àû-norm of a transfer function using the grid
method. Test your program on the function
1
s2 + 10‚àí6s + 1
and compare your answer to the exact solution computed by hand using the derivative method.
Notes and References
The material in this chapter belongs to the Ô¨Åeld of mathematics called functional analysis. Tools
from functional analysis were introduced into the subject of feedback control around 1960 by G.
Zames and I. Sandberg. Some references are Desoer and Vidyasagar (1975), Holtzman (1970), Mees
(1981), and Willems (1971). The state-space procedure for the ‚àû-norm is from Boyd et al. (1989).

30
CHAPTER 2. NORMS FOR SIGNALS AND SYSTEMS

Chapter 3
Basic Concepts
This chapter and the next are the most fundamental. We concentrate on the single-loop feedback
system. Stability of this system is deÔ¨Åned and characterized.
Then the system is analyzed for
its ability to track certain signals (i.e., steps and ramps) asymptotically as time increases.
Fi-
nally, tracking is addressed as a performance speciÔ¨Åcation. Uncertainty is postponed until the next
chapter.
Now a word about notation. In the preceding chapter we used signals in the time and frequency
domains; the notation was u(t) for a function of time and ÀÜu(s) for its Laplace transform. When the
context is solely the frequency domain, it is convenient to drop the hat and write u(s); similarly for
an impulse response G(t) and the corresponding transfer function ÀÜG(s).
3.1
Basic Feedback Loop
The most elementary feedback control system has three components: a plant (the object to be
controlled, no matter what it is, is always called the plant), a sensor to measure the output of the
plant, and a controller to generate the plant‚Äôs input. Usually, actuators are lumped in with the
plant. We begin with the block diagram in Figure 3.1. Notice that each of the three components
controller
sensor
plant
-
-
-
?

6
6
r
u
y
d
n
v
Figure 3.1: Elementary control system.
has two inputs, one internal to the system and one coming from outside, and one output. These
31

32
CHAPTER 3. BASIC CONCEPTS
signals have the following interpretations:
r
reference or command input
v
sensor output
u
actuating signal, plant input
d
external disturbance
y
plant output and measured signal
n
sensor noise
The three signals coming from outside‚Äîr, d, and n‚Äîare called exogenous inputs.
In what follows we shall consider a variety of performance objectives, but they can be summarized
by saying that y should approximate some prespeciÔ¨Åed function of r, and it should do so in the
presence of the disturbance d, sensor noise n, with uncertainty in the plant. We may also want to
limit the size of u. Frequently, it makes more sense to describe the performance objective in terms
of the measurement v rather than y, since often the only knowledge of y is obtained from v.
The analysis to follow is done in the frequency domain. To simplify notation, hats are omitted
from Laplace transforms.
Each of the three components in Figure 3.1 is assumed to be linear, so its output is a linear
function of its input, in this case a two-dimensional vector. For example, the plant equation has
the form
y = P
 d
u

.
Partitioning the 1 √ó 2 transfer matrix P as
P =

P1
P2

,
we get
y = P1d + P2u.
We shall take an even more specialized viewpoint and suppose that the outputs of the three
components are linear functions of the sums (or diÔ¨Äerence) of their inputs; that is, the plant, sensor,
and controller equations are taken to be of the form
y
=
P(d + u),
v
=
F(y + n),
u
=
C(r ‚àív).
The minus sign in the last equation is a matter of tradition. The block diagram for these equations
is in Figure 3.2. Our convention is that plus signs at summing junctions are omitted.
This section ends with the notion of well-posedness. This means that in Figure 3.2 all closed-
loop transfer functions exist, that is, all transfer functions from the three exogenous inputs to all
internal signals, namely, u, y, v, and the outputs of the summing junctions. Label the outputs of
the summing junctions as in Figure 3.3. For well-posedness it suÔ¨Éces to look at the nine transfer
functions from r, d, n to x1, x2, x3. (The other transfer functions are obtainable from these.) Write
the equations at the summing junctions:
x1
=
r ‚àíFx3,
x2
=
d + Cx1,
x3
=
n + Px2.

3.1. BASIC FEEDBACK LOOP
33
C
P
F






-
-
-
-
-


?
?
6
r
u
y
d
n
v
‚àí
Figure 3.2: Basic feedback loop.
C
P
F






-
-
-
-
-


?
?
6
r
u
y
d
n
v
‚àí
x1
x2
x3
Figure 3.3: Basic feedback loop.
In matrix form these are
Ô£Æ
Ô£∞
1
0
F
‚àíC
1
0
0
‚àíP
1
Ô£π
Ô£ª
Ô£´
Ô£≠
x1
x2
x3
Ô£∂
Ô£∏=
Ô£´
Ô£≠
r
d
n
Ô£∂
Ô£∏.
Thus, the system is well-posed iÔ¨Äthe above 3 √ó 3 matrix is nonsingular, that is, the determinant
1 + PCF is not identically equal to zero. [For instance, the system with P(s) = 1, C(s) = 1,
F(s) = ‚àí1 is not well-posed.] Then the nine transfer functions are obtained from the equation
Ô£´
Ô£≠
x1
x2
x3
Ô£∂
Ô£∏=
Ô£Æ
Ô£∞
1
0
F
‚àíC
1
0
0
‚àíP
1
Ô£π
Ô£ª
‚àí1 Ô£´
Ô£≠
r
d
n
Ô£∂
Ô£∏,
that is,
Ô£´
Ô£≠
x1
x2
x3
Ô£∂
Ô£∏=
1
1 + PCF
Ô£Æ
Ô£∞
1
‚àíPF
‚àíF
C
1
‚àíCF
PC
P
1
Ô£π
Ô£ª
Ô£´
Ô£≠
r
d
n
Ô£∂
Ô£∏.
(3.1)
A stronger notion of well-posedness that makes sense when P, C, and F are proper is that
the nine transfer functions above are proper. A necessary and suÔ¨Écient condition for this is that
1 + PCF not be strictly proper [i.e., PCF(‚àû) Ã∏= ‚àí1].

34
CHAPTER 3. BASIC CONCEPTS
One might argue that the transfer functions of all physical systems are strictly proper: If a
sinusoid of ever-increasing frequency is applied to a (linear, time-invariant) system, the amplitude
of the output will go to zero. This is somewhat misleading because a real system will cease to
behave linearly as the frequency of the input increases. Furthermore, our transfer functions will be
used to parametrize an uncertainty set, and as we shall see, it may be convenient to allow some of
them to be only proper. A proportional-integral-derivative controller is very common in practice,
especially in chemical engineering. It has the form
k1 + k2
s + k3s.
This is not proper, but it can be approximated over any desired frequency range by a proper one,
for example,
k1 + k2
s +
k3s
œÑs + 1.
Notice that the feedback system is automatically well-posed, in the stronger sense, if P, C, and
F are proper and one is strictly proper. For most of the book, we shall make the following standing
assumption, under which the nine transfer functions in (3.1) are proper:
P is strictly proper, C and F are proper.
However, at times it will be convenient to require only that P be proper. In this case we shall always
assume that |PCF| < 1 at œâ = ‚àû, which ensures that 1 + PCF is not strictly proper. Given that
no model, no matter how complex, can approximate a real system at suÔ¨Éciently high frequencies,
we should be very uncomfortable if |PCF| > 1 at œâ = ‚àû, because such a controller would almost
surely be unstable if implemented on a real system.
3.2
Internal Stability
Consider a system with input u, output y, and transfer function ÀÜG, assumed stable and proper. We
can write
ÀÜG = G0 + ÀÜG1,
where G0 is a constant and ÀÜG1 is strictly proper.
Example:
s
s + 1 = 1 ‚àí
1
s + 1.
In the time domain the equation is
y(t) = G0u(t) +
Z ‚àû
‚àí‚àû
G1(t ‚àíœÑ)u(œÑ) dœÑ.
If |u(t)| ‚â§c for all t, then
|y(t)| ‚â§|G0|c +
Z ‚àû
‚àí‚àû
|G1(œÑ)| dœÑc.

3.2. INTERNAL STABILITY
35
The right-hand side is Ô¨Ånite. Thus the output is bounded whenever the input is bounded. [This
argument is the basis for entry (2,2) in Table 2.2.]
If the nine transfer functions in (3.1) are stable, then the feedback system is said to be internally
stable. As a consequence, if the exogenous inputs are bounded in magnitude, so too are x1, x2, and
x3, and hence u, y, and v. So internal stability guarantees bounded internal signals for all bounded
exogenous signals.
The idea behind this deÔ¨Ånition of internal stability is that it is not enough to look only at
input-output transfer functions, such as from r to y, for example. This transfer function could be
stable, so that y is bounded when r is, and yet an internal signal could be unbounded, probably
causing internal damage to the physical system.
For the remainder of this section hats are dropped.
Example In Figure 3.3 take
C(s) = s ‚àí1
s + 1,
P(s) =
1
s2 ‚àí1,
F(s) = 1.
Check that the transfer function from r to y is stable, but that from d to y is not. The feedback
system is therefore not internally stable. As we will see later, this oÔ¨Äense is caused by the cancellation
of the controller zero and the plant pole at the point s = 1.
We shall develop a test for internal stability which is easier than examining nine transfer func-
tions. Write P, C, and F as ratios of coprime polynomials (i.e., polynomials with no common
factors):
P = NP
MP
,
C = NC
MC
,
F = NF
MF
.
The characteristic polynomial of the feedback system is the one formed by taking the product of
the three numerators plus the product of the three denominators:
NP NCNF + MPMCMF .
The closed-loop poles are the zeros of the characteristic polynomial.
Theorem 1 The feedback system is internally stable iÔ¨Äthere are no closed-loop poles in Res ‚â•0.
Proof For simplicity assume that F = 1; the proof in the general case is similar, but a bit messier.
From (3.1) we have
Ô£´
Ô£≠
x1
x2
x3
Ô£∂
Ô£∏=
1
1 + PC
Ô£Æ
Ô£∞
1
‚àíP
‚àí1
C
1
‚àíC
PC
P
1
Ô£π
Ô£ª
Ô£´
Ô£≠
r
d
n
Ô£∂
Ô£∏.
Substitute in the ratios and clear fractions to get
Ô£´
Ô£≠
x1
x2
x3
Ô£∂
Ô£∏=
1
NPNC + MPMC
Ô£Æ
Ô£∞
MP MC
‚àíNP MC
‚àíMP MC
MPNC
MP MC
‚àíMPNC
NP NC
NPMC
MP MC
Ô£π
Ô£ª
Ô£´
Ô£≠
r
d
n
Ô£∂
Ô£∏.
(3.2)

36
CHAPTER 3. BASIC CONCEPTS
Note that the characteristic polynomial equals NP NC + MP MC. SuÔ¨Éciency is now evident; the
feedback system is internally stable if the characteristic polynomial has no zeros in Res ‚â•0.
Necessity involves a subtle point. Suppose that the feedback system is internally stable. Then
all nine transfer functions in (3.2) are stable, that is, they have no poles in Re s ‚â•0. But we cannot
immediately conclude that the polynomial NP NC + MP MC has no zeros in Res ‚â•0 because this
polynomial may conceivably have a right half-plane zero which is also a zero of all nine numerators
in (3.2), and hence is canceled to form nine stable transfer functions. However, the characteristic
polynomial has no zero which is also a zero of all nine numerators, MP MC, NP MC, and so on.
Proof of this statement is left as an exercise. (It follows from the fact that we took coprime factors
to start with, that is, NP and MP are coprime, as are the other numerator-denominator pairs.) ‚ñ†
By Theorem 1 internal stability can be determined simply by checking the zeros of a polynomial.
There is another test that provides additional insight.
Theorem 2 The feedback system is internally stable iÔ¨Äthe following two conditions hold:
(a) The transfer function 1 + PCF has no zeros in Res ‚â•0.
(b) There is no pole-zero cancellation in Res ‚â•0 when the product PCF is formed.
Proof Recall that the feedback system is internally stable iÔ¨Äall nine transfer functions
1
1 + PCF
Ô£Æ
Ô£∞
1
‚àíPF
‚àíF
C
1
‚àíCF
PC
P
1
Ô£π
Ô£ª
are stable.
(‚áí) Assume that the feedback system is internally stable. Then in particular (1 + PCF)‚àí1 is
stable (i.e., it has no poles in Res ‚â•0). Hence 1 + PCF has no zeros there. This proves (a).
To prove (b), write P, C, F as ratios of coprime polynomials:
P = NP
MP
,
C = NC
MC
,
F = NF
MF
.
By Theorem 1 the characteristic polynomial
NP NCNF + MPMCMF
has no zeros in Res ‚â•0. Thus the pair (NP , MC) have no common zero in Res ‚â•0, and similarly
for the other numerator-denominator pairs.
(‚áê) Assume (a) and (b). Factor P, C, F as above, and let s0 be a zero of the characteristic
polynomial, that is,
(NP NCNF + MP MCMF )(s0) = 0.
We must show that Res0 < 0; this will prove internal stability by Theorem 1. Suppose to the
contrary that Res0 ‚â•0. If
(MP MCMF )(s0) = 0,

3.3. ASYMPTOTIC TRACKING
37
then
(NP NCNF )(s0) = 0.
But this violates (b). Thus
(MP MCMF )(s0) Ã∏= 0,
so we can divide by it above to get
1 + NP NCNF
MP MCMF
(s0) = 0,
that is,
1 + (PCF)(s0) = 0,
which violates (a). ‚ñ†
Finally, let us recall for later use the Nyquist stability criterion. It can be derived from Theorem 2
and the principle of the argument. Begin with the curve D in the complex plane: It starts at the
origin, goes up the imaginary axis, turns into the right half-plane following a semicircle of inÔ¨Ånite
radius, and comes up the negative imaginary axis to the origin again:
D
As a point s makes one circuit around this curve, the point P(s)C(s)F(s) traces out a curve called
the Nyquist plot of PCF. If PCF has a pole on the imaginary axis, then D must have a small
indentation to avoid it.
Nyquist Criterion Construct the Nyquist plot of PCF, indenting to the left around poles on the
imaginary axis. Let n denote the total number of poles of P, C, and F in Res ‚â•0. Then the feedback
system is internally stable iÔ¨Äthe Nyquist plot does not pass through the point -1 and encircles it
exactly n times counterclockwise.

38
CHAPTER 3. BASIC CONCEPTS
ÀÜC
ÀÜP






-
-
-
-
-

?
?
6
r
u
y
d
n
‚àí
e
Figure 3.4: Unity-feedback loop.
3.3
Asymptotic Tracking
In this section we look at a typical performance speciÔ¨Åcation, perfect asymptotic tracking of a
reference signal.
Both time domain and frequency domain occur, so the notation distinction is
required.
For the remainder of this chapter we specialize to the unity-feedback case, ÀÜF = 1, so the block
diagram is as in Figure 3.4. Here e is the tracking error; with n = d = 0, e equals the reference
input (ideal response), r, minus the plant output (actual response), y.
We wish to study this system‚Äôs capability of tracking certain test inputs asymptotically as time
tends to inÔ¨Ånity. The two test inputs are the step
r(t) =
 c,
if t ‚â•0
0,
if t < 0
and the ramp
r(t) =
 ct,
if t ‚â•0
0,
if t < 0
(c is a nonzero real number). As an application of the former think of the temperature-control
thermostat in a room; when you change the setting on the thermostat (step input), you would like
the room temperature eventually to change to the new setting (of course, you would like the change
to occur within a reasonable time). A situation with a ramp input is a radar dish designed to track
orbiting satellites. A satellite moving in a circular orbit at constant angular velocity sweeps out an
angle that is approximately a linear function of time (i.e., a ramp).
DeÔ¨Åne the loop transfer function ÀÜL := ÀÜP ÀÜC. The transfer function from reference input r to
tracking error e is
ÀÜS :=
1
1 + ÀÜL
,
called the sensitivity function‚Äîmore on this in the next section. The ability of the system to track
steps and ramps asymptotically depends on the number of zeros of ÀÜS at s = 0.
Theorem 3 Assume that the feedback system is internally stable and n = d = 0.

3.3. ASYMPTOTIC TRACKING
39
(a) If r is a step, then e(t) ‚àí‚Üí0 as t ‚àí‚Üí‚àûiÔ¨ÄÀÜS has at least one zero at the origin.
(b) If r is a ramp, then e(t) ‚àí‚Üí0 as t ‚àí‚Üí‚àûiÔ¨ÄÀÜS has at least two zeros at the origin.
The proof is an application of the Ô¨Ånal-value theorem: If ÀÜy(s) is a rational Laplace transform
that has no poles in Res ‚â•0 except possibly a simple pole at s = 0, then limt‚Üí‚àûy(t) exists and it
equals lims‚Üí0 sÀÜy(s).
Proof (a) The Laplace transform of the foregoing step is ÀÜr(s) = c/s. The transfer function from r
to e equals ÀÜS, so
ÀÜe(s) = ÀÜS(s)c
s.
Since the feedback system is internally stable, ÀÜS is a stable transfer function. It follows from the
Ô¨Ånal-value theorem that e(t) does indeed converge as t ‚àí‚Üí‚àû, and its limit is the residue of the
function ÀÜe(s) at the pole s = 0:
e(‚àû) = ÀÜS(0)c.
The right-hand side equals zero iÔ¨ÄÀÜS(0) = 0.
(b) Similarly with ÀÜr(s) = c/s2. ‚ñ†
Note that ÀÜS has a zero at s = 0 iÔ¨ÄÀÜL has a pole there. Thus, from the theorem we see that if
the feedback system is internally stable and either ÀÜP or ÀÜC has a pole at the origin (i.e., an inherent
integrator), then the output y(t) will asymptotically track any step input r.
Example To see how this works, take the simplest possible example,
ÀÜP(s) = 1
s,
ÀÜC(s) = 1.
Then the transfer function from r to e equals
1
1 + s‚àí1 =
s
s + 1.
So the open-loop pole at s = 0 becomes a closed-loop zero of the error transfer function; then this
zero cancels the pole of ÀÜr(s), resulting in no unstable poles in ÀÜe(s). Similar remarks apply for a
ramp input.
Theorem 3 is a special case of an elementary principle: For perfect asymptotic tracking, the
loop transfer function ÀÜL must contain an internal model of the unstable poles of ÀÜr.
A similar analysis can be done for the situation where r = n = 0 and d is a sinusoid, say
d(t) = sin(œât)1(t) (1 is the unit step). You can show this: If the feedback system is internally
stable, then y(t) ‚àí‚Üí0 as t ‚àí‚Üí‚àûiÔ¨Äeither ÀÜP has a zero at s = jœâ or ÀÜC has a pole at s = jœâ
(Exercise 3).

40
CHAPTER 3. BASIC CONCEPTS
3.4
Performance
In this section we again look at tracking a reference signal, but whereas in the preceding section
we considered perfect asymptotic tracking of a single signal, we will now consider a set of reference
signals and a bound on the steady-state error. This performance objective will be quantiÔ¨Åed in
terms of a weighted norm bound.
As before, let L denote the loop transfer function, L := PC. The transfer function from reference
input r to tracking error e is
S :=
1
1 + L,
called the sensitivity function. In the analysis to follow, it will always be assumed that the feedback
system is internally stable, so S is a stable, proper transfer function. Observe that since L is strictly
proper (since P is), S(j‚àû) = 1.
The name sensitivity function comes from the following idea. Let T denote the transfer function
from r to y:
T =
PC
1 + PC .
One way to quantify how sensitive T is to variations in P is to take the limiting ratio of a relative
perturbation in T (i.e., ‚àÜT/T) to a relative perturbation in P (i.e., ‚àÜP/P). Thinking of P as a
variable and T as a function of it, we get
lim
‚àÜP ‚Üí0
‚àÜT/T
‚àÜP/P = dT
dP
P
T .
The right-hand side is easily evaluated to be S. In this way, S is the sensitivity of the closed-loop
transfer function T to an inÔ¨Ånitesimal perturbation in P.
Now we have to decide on a performance speciÔ¨Åcation, a measure of goodness of tracking. This
decision depends on two things: what we know about r and what measure we choose to assign to
the tracking error. Usually, r is not known in advance‚Äîfew control systems are designed for one
and only one input. Rather, a set of possible rs will be known or at least postulated for the purpose
of design.
Let‚Äôs Ô¨Årst consider sinusoidal inputs. Suppose that r can be any sinusoid of amplitude ‚â§1 and
we want e to have amplitude < «´. Then the performance speciÔ¨Åcation can be expressed succinctly
as
‚à•S‚à•‚àû< «´.
Here we used Table 2.1: the maximum amplitude of e equals the ‚àû-norm of the transfer function.
Or if we deÔ¨Åne the (trivial, in this case) weighting function W1(s) = 1/«´, then the performance
speciÔ¨Åcation is ‚à•W1S‚à•‚àû< 1.
The situation becomes more realistic and more interesting with a frequency-dependent weighting
function. Assume that W1(s) is real-rational; you will see below that only the magnitude of W1(jœâ)
is relevant, so any poles or zeros in Res > 0 can be reÔ¨Çected into the left half-plane without changing
the magnitude. Let us consider four scenarios giving rise to an ‚àû-norm bound on W1S. The Ô¨Årst
three require W1 to be stable.

3.4. PERFORMANCE
41
1. Suppose that the family of reference inputs is all signals of the form r = W1rpf, where rpf, a
pre-Ô¨Åltered input, is any sinusoid of amplitude ‚â§1. Thus the set of rs consists of sinusoids
with frequency-dependent amplitudes. Then the maximum amplitude of e equals ‚à•W1S‚à•‚àû.
2. Recall from Chapter 2 that
‚à•r‚à•2
2 = 1
2œÄ
Z ‚àû
‚àí‚àû
|r(jœâ)|2 dœâ
and that ‚à•r‚à•2
2 is a measure of the energy of r. Thus we may think of |r(jœâ)|2 as energy spectral
density, or energy spectrum. Suppose that the set of all rs is
{r : r = W1rpf, ‚à•rpf‚à•2 ‚â§1},
that is,

r : 1
2œÄ
Z ‚àû
‚àí‚àû
|r(jœâ)/W1(jœâ)|2 dœâ ‚â§1

.
Thus, r has an energy constraint and its energy spectrum is weighted by 1/|W1(jœâ)|2. For
example, if W1 were a bandpass Ô¨Ålter, the energy spectrum of r would be conÔ¨Åned to the
passband. More generally, W1 could be used to shape the energy spectrum of the expected
class of reference inputs. Now suppose that the tracking error measure is the 2-norm of e.
Then from Table 2.2,
sup
r ‚à•e‚à•2 = sup{‚à•SW1rpf‚à•2 : ‚à•rpf‚à•2 ‚â§1} = ‚à•W1S‚à•‚àû,
so ‚à•W1S‚à•‚àû< 1 means that ‚à•e‚à•2 < 1 for all rs in the set above .
3. This scenario is like the preceding one except for signals of Ô¨Ånite power. We see from Table 2.2
that ‚à•W1S‚à•‚àûequals the supremum of pow(e) over all rpf with pow(rpf) ‚â§1. So W1 could
be used to shape the power spectrum of the expected class of rs.
4. In several applications, for example aircraft Ô¨Çight-control design, designers have acquired
through experience desired shapes for the Bode magnitude plot of S. In particular, suppose
that good performance is known to be achieved if the plot of |S(jœâ)| lies under some curve.
We could rewrite this as
|S(jœâ)| < |W1(jœâ)|‚àí1,
‚àÄœâ,
or in other words, ‚à•W1S‚à•‚àû< 1.
There is a nice graphical interpretation of the norm bound ‚à•W1S‚à•‚àû< 1. Note that
‚à•W1S‚à•‚àû< 1
‚áî

W1(jœâ)
1 + L(jœâ)
 < 1,
‚àÄœâ
‚áî
|W1(jœâ)| < |1 + L(jœâ)|,
‚àÄœâ.
The last inequality says that at every frequency, the point L(jœâ) on the Nyquist plot lies outside
the disk of center -1, radius |W1(jœâ)| (Figure 3.5).

42
CHAPTER 3. BASIC CONCEPTS
&%
'$
r
r
6
|W1|
‚àí1
L
Figure 3.5: Performance speciÔ¨Åcation graphically.
Other performance problems could be posed by focusing on the response to the other two
exogenous inputs, d and n. Note that the transfer functions from d, n to e, u are given by
 e
u

= ‚àí
 PS
S
T
CS
  d
n

,
where
T := 1 ‚àíS =
PC
1 + PC ,
called the complementary sensitivity function.
Various performance speciÔ¨Åcations could be made using weighted versions of the transfer func-
tions above. Note that a performance spec with weight W on PS is equivalent to the weight WP on
S. Similarly, a weight W on CS = T/P is equivalent to the weight W/P on T. Thus performance
specs that involve e result in weights on S and performance specs on u result in weights on T.
Essentially all problems in this book boil down to weighting S or T or some combination, and the
tradeoÔ¨Äbetween making S small and making T small is the main issue in design.
Exercises
1. Consider the unity-feedback system [F(s) = 1]. The deÔ¨Ånition of internal stability is that all
nine closed-loop transfer functions should be stable. In the unity-feedback case, it actually
suÔ¨Éces to check only two of the nine. Which two?
2. In this problem and the next, there is a mixture of the time and frequency domains, so theÀÜ
-convention is in force.
Let
ÀÜP(s) =
1
10s + 1,
ÀÜC(s) = k,
ÀÜF(s) = 1.
Find the least positive gain k so that the following are all true:
(a) The feedback system is internally stable.
(b) |e(‚àû)| ‚â§0.1 when r(t) is the unit step and n = d = 0.

3.4. PERFORMANCE
43
(c) ‚à•y‚à•‚àû‚â§0.1 for all d(t) such that ‚à•d‚à•2 ‚â§1 when r = n = 0.
3. For the setup in Figure 3.4, take r = n = 0, d(t) = sin(œât)1(t). Prove that if the feedback
system is internally stable, then y(t) ‚Üí0 as t ‚Üí‚àûiÔ¨Äeither ÀÜP has a zero at s = jœâ or ÀÜC has
a pole at s = jœâ.
4. Consider the feedback system with plant P and sensor F. Assume that P is strictly proper
and F is proper. Find conditions on P and F for the existence of a proper controller so that
The feedback system is internally stable.
y(t) ‚àír(t) ‚Üí0 when r is a unit step.
y(t) ‚Üí0 when d is a sinusoid of frequency 100 rad/s.
Notes and References
The material in Sections 3.1 to 3.3 is quite standard. However, Section 3.4 reÔ¨Çects the more recent
viewpoint of Zames (1981), who formulated the problem of optimizing W1S with respect to the
‚àû-norm, stressing the role of the weight W1. Additional motivation for this problem is oÔ¨Äered in
Zames and Francis (1983).

44
CHAPTER 3. BASIC CONCEPTS

Chapter 4
Uncertainty and Robustness
No mathematical system can exactly model a physical system. For this reason we must be aware
of how modeling errors might adversely aÔ¨Äect the performance of a control system. This chapter
begins with a treatment of various models of plant uncertainty. Then robust stability, stability in
the face of plant uncertainty, is studied using the small-gain theorem. The Ô¨Ånal topic is robust
performance, guaranteed tracking in the face of plant uncertainty.
4.1
Plant Uncertainty
The basic technique is to model the plant as belonging to a set P. The reasons for doing this were
presented in Chapter 1. Such a set can be either structured or unstructured.
For an example of a structured set consider the plant model
1
s2 + as + 1.
This is a standard second-order transfer function with natural frequency 1 rad/s and damping ratio
a/2‚Äîit could represent, for example, a mass-spring-damper setup or an R-L-C circuit. Suppose
that the constant a is known only to the extent that it lies in some interval [amin, amax]. Then the
plant belongs to the structured set
P =

1
s2 + as + 1 : amin ‚â§a ‚â§amax

.
Thus one type of structured set is parametrized by a Ô¨Ånite number of scalar parameters (one
parameter, a, in this example). Another type of structured uncertainty is a discrete set of plants,
not necessarily parametrized explicitly.
For us, unstructured sets are more important, for two reasons. First, we believe that all models
used in feedback design should include some unstructured uncertainty to cover unmodeled dynamics,
particularly at high frequency.
Other types of uncertainty, though important, may or may not
arise naturally in a given problem. Second, for a speciÔ¨Åc type of unstructured uncertainty, disk
uncertainty, we can develop simple, general analysis methods. Thus the basic starting point for an
unstructured set is that of disk-like uncertainty. In what follows, multiplicative disk uncertainty
is chosen for detailed study. This is only one type of unstructured perturbation. The important
point is that we use disk uncertainty instead of a more complicated description. We do this because
45

46
CHAPTER 4. UNCERTAINTY AND ROBUSTNESS
it greatly simpliÔ¨Åes our analysis and lets us say some fairly precise things. The price we pay is
conservativeness.
Multiplicative Perturbation
Suppose that the nominal plant transfer function is P and consider perturbed plant transfer func-
tions of the form ÀúP = (1 + ‚àÜW2)P. Here W2 is a Ô¨Åxed stable transfer function, the weight, and
‚àÜis a variable stable transfer function satisfying ‚à•‚àÜ‚à•‚àû< 1. Furthermore, it is assumed that no
unstable poles of P are canceled in forming ÀúP. (Thus, P and ÀúP have the same unstable poles.)
Such a perturbation ‚àÜis said to be allowable.
The idea behind this uncertainty model is that ‚àÜW2 is the normalized plant perturbation away
from 1:
ÀúP
P ‚àí1 = ‚àÜW2.
Hence if ‚à•‚àÜ‚à•‚àû‚â§1, then

ÀúP(jœâ)
P(jœâ) ‚àí1
 ‚â§|W2(jœâ)|,
‚àÄœâ,
so |W2(jœâ)| provides the uncertainty proÔ¨Åle. This inequality describes a disk in the complex plane:
At each frequency the point ÀúP/P lies in the disk with center 1, radius |W2|. Typically, |W2(jœâ)|
is a (roughly) increasing function of œâ: Uncertainty increases with increasing frequency. The main
purpose of ‚àÜis to account for phase uncertainty and to act as a scaling factor on the magnitude of
the perturbation (i.e., |‚àÜ| varies between 0 and 1).
Thus, this uncertainty model is characterized by a nominal plant P together with a weighting
function W2. How does one get the weighting function W2 in practice? This is illustrated by a few
examples.
Example 1 Suppose that the plant is stable and its transfer function is arrived at by means of
frequency-response experiments: Magnitude and phase are measured at a number of frequencies,
œâi, i = 1, . . . , m, and this experiment is repeated several, say n, times. Let the magnitude-phase
measurement for frequency œâi and experiment k be denoted (Mik, œÜik). Based on these data select
nominal magnitude-phase pairs (Mi, œÜi) for each frequency œâi, and Ô¨Åt a nominal transfer function
P(s) to these data. Then Ô¨Åt a weighting function W2(s) so that

MikejœÜik
MiejœÜi
‚àí1
 ‚â§|W2(jœâi)|,
i = 1, . . . , m; k = 1, . . . , n.
Example 2 Assume that the nominal plant transfer function is a double integrator:
P(s) = 1
s2 .
For example, a dc motor with negligible viscous damping could have such a transfer function. You
can think of other physical systems with only inertia, no damping. Suppose that a more detailed
model has a time delay, yielding the transfer function
ÀúP(s) = e‚àíœÑs 1
s2 ,

4.1. PLANT UNCERTAINTY
47
and suppose that the time delay is known only to the extent that it lies in the interval 0 ‚â§œÑ ‚â§0.1.
This time-delay factor exp(‚àíœÑs) can be treated as a multiplicative perturbation of the nominal
plant by embedding ÀúP in the family
{(1 + ‚àÜW2)P : ‚à•‚àÜ‚à•‚àû‚â§1}.
To do this, the weight W2 should be chosen so that the normalized perturbation satisÔ¨Åes

ÀúP(jœâ)
P(jœâ) ‚àí1
 ‚â§|W2(jœâ)|,
‚àÄœâ, œÑ,
that is,
e‚àíœÑjœâ ‚àí1
 ‚â§|W2(jœâ)|,
‚àÄœâ, œÑ.
A little time with Bode magnitude plots shows that a suitable Ô¨Årst-order weight is
W2(s) =
0.21s
0.1s + 1.
Figure 4.1 is the Bode magnitude plot of this W2 and exp(‚àíœÑs) ‚àí1 for œÑ = 0.1, the worst value.
10-3
10-2
10-1
100
101
10-1
100
101
102
103
Figure 4.1: Bode plots of W2 (dash) and exp(‚àí0.1s) ‚àí1 (solid).
To get a feeling for how conservative this is, compare at a few frequencies œâ the actual uncertainty
set
( ÀúP(jœâ)
P(jœâ) : 0 ‚â§œÑ ‚â§0.1
)
=

e‚àíœÑjœâ : 0 ‚â§œÑ ‚â§0.1
	

48
CHAPTER 4. UNCERTAINTY AND ROBUSTNESS
with the covering disk
{s : |s ‚àí1| ‚â§|W2(jœâ)|}.
Example 3 Suppose that the plant transfer function is
ÀúP(s) =
k
s ‚àí2,
where the gain k is uncertain but is known to lie in the interval [0.1, 10]. This plant too can be
embedded in a family consisting of multiplicative perturbations of a nominal plant
P(s) =
k0
s ‚àí2.
The weight W2 must satisfy

ÀúP(jœâ)
P(jœâ) ‚àí1
 ‚â§|W2(jœâ)|,
‚àÄœâ, k,
that is,
max
0.1‚â§k‚â§10

k
k0
‚àí1
 ‚â§|W2(jœâ)|,
‚àÄœâ.
The left-hand side is minimized by k0 = 5.05, for which the left-hand side equals 4.95/5.05. In this
way we get the nominal plant
P(s) = 5.05
s ‚àí2
and constant weight W2(s) = 4.95/5.05.
The multiplicative perturbation model is not suitable for every application because the disk
covering the uncertainty set is sometimes too coarse an approximation. In this case a controller
designed for the multiplicative uncertainty model would probably be too conservative for the original
uncertainty model.
The discussion above illustrates an important point. In modeling a plant we may arrive at a
certain plant set. This set may be too awkward to cope with mathematically, so we may embed it in
a larger set that is easier to handle. Conceivably, the achievable performance for the larger set may
not be as good as the achievable performance for the smaller; that is, there may exist‚Äîeven though
we cannot Ô¨Ånd it‚Äîa controller that is better for the smaller set than the controller we design for
the larger set. In this sense the latter controller is conservative for the smaller set.
In this book we stick with plant uncertainty that is disk-like. It will be conservative for some
problems, but the payoÔ¨Äis that we obtain some very nice theoretical results. The resulting theory
is remarkably practical as well.

4.1. PLANT UNCERTAINTY
49
Other Perturbations
Other uncertainty models are possible besides multiplicative perturbations, as illustrated by the
following example.
Example 4 As at the start of this section, consider the family of plant transfer functions
1
s2 + as + 1,
0.4 ‚â§a ‚â§0.8.
Thus
a = 0.6 + 0.2‚àÜ,
‚àí1 ‚â§‚àÜ‚â§1,
so the family can be expressed as
P(s)
1 + ‚àÜW2(s)P(s),
‚àí1 ‚â§‚àÜ‚â§1,
where
P(s) :=
1
s2 + 0.6s + 1,
W2(s) := 0.2s.
Note that P is the nominal plant transfer function for the value a = 0.6, the midpoint of the interval.
The block diagram corresponding to this representation of the plant is shown in Figure 4.2. Thus
P
‚àÜ
W2


-
-
-


?
‚àí
Figure 4.2: Example 4.
the original plant has been represented as a feedback uncertainty around a nominal plant.
The following list summarizes the common uncertainty models:
(1 + ‚àÜW2)P
P + ‚àÜW2
P/(1 + ‚àÜW2P)
P/(1 + ‚àÜW2)
Appropriate assumptions would be made on ‚àÜand W2 in each case. Typically, we can relax the
assumption that ‚àÜbe stable; but then the theorems to follow would be harder to prove.

50
CHAPTER 4. UNCERTAINTY AND ROBUSTNESS
4.2
Robust Stability
The notion of robustness can be described as follows. Suppose that the plant transfer function P
belongs to a set P, as in the preceding section. Consider some characteristic of the feedback system,
for example, that it is internally stable. A controller C is robust with respect to this characteristic
if this characteristic holds for every plant in P.
The notion of robustness therefore requires a
controller, a set of plants, and some characteristic of the system. For us, the two most important
variations of this notion are robust stability, treated in this section, and robust performance, treated
in the next.
A controller C provides robust stability if it provides internal stability for every plant in P. We
might like to have a test for robust stability, a test involving C and P. Or if P has an associated
size, the maximum size such that C stabilizes all of P might be a useful notion of stability margin.
The Nyquist plot gives information about stability margin. Note that the distance from the
critical point -1 to the nearest point on the Nyquist plot of L equals 1/‚à•S‚à•‚àû:
distance from -1 to Nyquist plot
=
inf
œâ | ‚àí1 ‚àíL(jœâ)|
=
inf
œâ |1 + L(jœâ)|
=

sup
œâ
1
|1 + L(jœâ)|
‚àí1
=
‚à•S‚à•‚àí1
‚àû.
Thus if ‚à•S‚à•‚àû‚â´1, the Nyquist plot comes close to the critical point, and the feedback system is
nearly unstable. However, as a measure of stability margin this distance is not entirely adequate
because it contains no frequency information. More precisely, if the nominal plant P is perturbed
to ÀúP, having the same number of unstable poles as has P and satisfying the inequality
| ÀúP(jœâ)C(jœâ) ‚àíP(jœâ)C(jœâ)| < ‚à•S‚à•‚àí1
‚àû,
‚àÄœâ,
then internal stability is preserved (the number of encirclements of the critical point by the Nyquist
plot does not change). But this is usually very conservative; for instance, larger perturbations could
be allowed at frequencies where P(jœâ)C(jœâ) is far from the critical point.
Better stability margins are obtained by taking explicit frequency-dependent perturbation mod-
els: for example, the multiplicative perturbation model, ÀúP = (1 + ‚àÜW2)P. Fix a positive number
Œ≤ and consider the family of plants
{ ÀúP : ‚àÜis stable and ‚à•‚àÜ‚à•‚àû‚â§Œ≤}.
Now a controller C that achieves internal stability for the nominal plant P will stabilize this entire
family if Œ≤ is small enough. Denote by Œ≤sup the least upper bound on Œ≤ such that C achieves internal
stability for the entire family. Then Œ≤sup is a stability margin (with respect to this uncertainty
model). Analogous stability margins could be deÔ¨Åned for the other uncertainty models.
We turn now to two classical measures of stability margin, gain and phase margin. Assume
that the feedback system is internally stable with plant P and controller C. Now perturb the plant
to kP, with k a positive real number. The upper gain margin, denoted kmax, is the Ô¨Årst value of
k greater than 1 when the feedback system is not internally stable; that is, kmax is the maximum
number such that internal stability holds for 1 ‚â§k < kmax. If there is no such number, then set

4.2. ROBUST STABILITY
51
kmax := ‚àû.
Similarly, the lower gain margin, kmin, is the least nonnegative number such that
internal stability holds for kmin < k ‚â§1. These two numbers can be read oÔ¨Äthe Nyquist plot of L;
for example, ‚àí1/kmax is the point where the Nyquist plot intersects the segment (‚àí1, 0) of the real
axis, the closest point to ‚àí1 if there are several points of intersection.
Now perturb the plant to e‚àíjœÜP, with œÜ a positive real number. The phase margin, œÜmax, is the
maximum number (usually expressed in degrees) such that internal stability holds for 0 ‚â§œÜ < œÜmax.
You can see that œÜmax is the angle through which the Nyquist plot must be rotated until it passes
through the critical point, ‚àí1; or, in radians, œÜmax equals the arc length along the unit circle from
the Nyquist plot to the critical point.
Thus gain and phase margins measure the distance from the critical point to the Nyquist plot
in certain speciÔ¨Åc directions. Gain and phase margins have traditionally been important measures
of stability robustness: if either is small, the system is close to instability. Notice, however, that the
gain and phase margins can be relatively large and yet the Nyquist plot of L can pass close to the
critical point; that is, simultaneous small changes in gain and phase could cause internal instability.
We return to these margins in Chapter 11.
Now we look at a typical robust stability test, one for the multiplicative perturbation model.
Assume that the nominal feedback system (i.e., with ‚àÜ= 0) is internally stable for controller C.
Bring in again the complementary sensitivity function
T = 1 ‚àíS =
L
1 + L =
PC
1 + PC .
Theorem 1 (Multiplicative uncertainty model) C provides robust stability iÔ¨Ä‚à•W2T‚à•‚àû< 1.
Proof (‚áê) Assume that ‚à•W2T‚à•‚àû< 1. Construct the Nyquist plot of L, indenting D to the left
around poles on the imaginary axis. Since the nominal feedback system is internally stable, we know
this from the Nyquist criterion: The Nyquist plot of L does not pass through -1 and its number
of counterclockwise encirclements equals the number of poles of P in Res ‚â•0 plus the number of
poles of C in Res ‚â•0.
Fix an allowable ‚àÜ. Construct the Nyquist plot of ÀúPC = (1+‚àÜW2)L. No additional indentations
are required since ‚àÜW2 introduces no additional imaginary axis poles.
We have to show that
the Nyquist plot of (1 + ‚àÜW2)L does not pass through -1 and its number of counterclockwise
encirclements equals the number of poles of (1 + ‚àÜW2)P in Re s ‚â•0 plus the number of poles of C
in Re s ‚â•0; equivalently, the Nyquist plot of (1 + ‚àÜW2)L does not pass through -1 and encircles
it exactly as many times as does the Nyquist plot of L. We must show, in other words, that the
perturbation does not change the number of encirclements.
The key equation is
1 + (1 + ‚àÜW2)L = (1 + L)(1 + ‚àÜW2T).
(4.1)
Since
‚à•‚àÜW2T‚à•‚àû‚â§‚à•W2T‚à•‚àû< 1,
the point 1 + ‚àÜW2T always lies in some closed disk with center 1, radius < 1, for all points s on D.
Thus from (4.1), as s goes once around D, the net change in the angle of 1 + (1 + ‚àÜW2)L equals
the net change in the angle of 1 + L. This gives the desired result.

52
CHAPTER 4. UNCERTAINTY AND ROBUSTNESS
(‚áí) Suppose that ‚à•W2T‚à•‚àû‚â•1. We will construct an allowable ‚àÜthat destabilizes the feedback
system. Since T is strictly proper, at some frequency œâ,
|W2(jœâ)T(jœâ)| = 1.
(4.2)
Suppose that œâ = 0. Then W2(0)T(0) is a real number, either +1 or ‚àí1. If ‚àÜ= ‚àíW2(0)T(0), then
‚àÜis allowable and
1 + ‚àÜW2(0)T(0) = 0.
From (4.1) the Nyquist plot of (1 + ‚àÜW2)L passes through the critical point, so the perturbed
feedback system is not internally stable.
If œâ > 0, constructing an admissible ‚àÜtakes a little more work; the details are omitted. ‚ñ†
The theorem can be used eÔ¨Äectively to Ô¨Ånd the stability margin Œ≤sup deÔ¨Åned previously. The
simple scaling technique
{ ÀúP = (1 + ‚àÜW2)P : ‚à•‚àÜ‚à•‚àû‚â§Œ≤}
=
{ ÀúP = (1 + Œ≤‚àí1‚àÜŒ≤W2)P : ‚à•Œ≤‚àí1‚àÜ‚à•‚àû‚â§1}
=
{ ÀúP = (1 + ‚àÜ1Œ≤W2)P : ‚à•‚àÜ1‚à•‚àû‚â§1}
together with the theorem shows that
Œ≤sup = sup{Œ≤ : ‚à•Œ≤W2T‚à•‚àû< 1} = 1/‚à•W2T‚à•‚àû.
The condition ‚à•W2T‚à•‚àû< 1 also has a nice graphical interpretation. Note that
‚à•W2T‚à•‚àû< 1
‚áî

W2(jœâ)L(jœâ)
1 + L(jœâ)
 < 1,
‚àÄœâ
‚áî
|W2(jœâ)L(jœâ)| < |1 + L(jœâ)|,
‚àÄœâ.
The last inequality says that at every frequency, the critical point, -1, lies outside the disk of center
L(jœâ), radius |W2(jœâ)L(jœâ)| (Figure 4.3).
&%
'$
r
r - |W2L|
L
‚àí1
Figure 4.3: Robust stability graphically.
There is a simple way to see the relevance of the condition ‚à•W2T‚à•‚àû< 1. First, draw the block
diagram of the perturbed feedback system, but ignoring inputs (Figure 4.4). The transfer function
from the output of ‚àÜaround to the input of ‚àÜequals ‚àíW2T, so the block diagram collapses to
the conÔ¨Åguration shown in Figure 4.5. The maximum loop gain in Figure 4.5 equals ‚à•‚àí‚àÜW2T‚à•‚àû,
which is < 1 for all allowable ‚àÜs iÔ¨Äthe small-gain condition ‚à•W2T‚à•‚àû< 1 holds.
The foregoing discussion is related to the small-gain theorem, a special case of which is this: If
L is stable and ‚à•L‚à•‚àû< 1, then (1 + L)‚àí1 is stable too. An easy proof uses the Nyquist criterion.

4.3. ROBUST PERFORMANCE
53
‚àíC
P
W2
‚àÜ


-
-
-
-
?
6
Figure 4.4: Perturbed feedback system.
‚àíW2T
‚àÜ
-

Figure 4.5: Collapsed block diagram.
Summary of Robust Stability Tests
Table 4.1 summarizes the robust stability tests for the other uncertainty models.
Perturbation
Condition
(1 + ‚àÜW2)P
‚à•W2T‚à•‚àû< 1
P + ‚àÜW2
‚à•W2CS‚à•‚àû< 1
P/(1 + ‚àÜW2P)
‚à•W2PS‚à•‚àû< 1
P/(1 + ‚àÜW2)
‚à•W2S‚à•‚àû< 1
Table 4.1
Note that we get the same four transfer functions‚ÄîT, CS, PS, S‚Äîas we did in Section 3.4. This
should not be too surprising since (up to sign) these are the only closed-loop transfer functions for
a unity feedback SISO system.
4.3
Robust Performance
Now we look into performance of the perturbed plant. Suppose that the plant transfer function
belongs to a set P. The general notion of robust performance is that internal stability and per-
formance, of a speciÔ¨Åed type, should hold for all plants in P. Again we focus on multiplicative
perturbations.

54
CHAPTER 4. UNCERTAINTY AND ROBUSTNESS
Recall that when the nominal feedback system is internally stable, the nominal performance
condition is ‚à•W1S‚à•‚àû< 1 and the robust stability condition is ‚à•W2T‚à•‚àû< 1. If P is perturbed to
(1 + ‚àÜW2)P, S is perturbed to
1
1 + (1 + ‚àÜW2)L =
S
1 + ‚àÜW2T .
Clearly, the robust performance condition should therefore be
‚à•W2T‚à•‚àû< 1 and

W1S
1 + ‚àÜW2T

‚àû
< 1,
‚àÄ‚àÜ.
Here ‚àÜmust be allowable. The next theorem gives a test for robust performance in terms of the
function
s 7‚Üí|W1(s)S(s)| + |W2(s)T(s)|,
which is denoted |W1S| + |W2T|.
Theorem 2 A necessary and suÔ¨Écient condition for robust performance is
‚à•|W1S| + |W2T|‚à•‚àû< 1.
(4.3)
Proof (‚áê) Assume (4.3), or equivalently,
‚à•W2T‚à•‚àûand

W1S
1 ‚àí|W2T|

‚àû
< 1.
(4.4)
Fix ‚àÜ. In what follows, functions are evaluated at an arbitrary point jœâ, but this is suppressed to
simplify notation. We have
1 = |1 + ‚àÜW2T ‚àí‚àÜW2T| ‚â§|1 + ‚àÜW2T| + |W2T|
and therefore
1 ‚àí|W2T| ‚â§|1 + ‚àÜW2T|.
This implies that

W1S
1 ‚àí|W2T|

‚àû
‚â•

W1S
1 + ‚àÜW2T

‚àû
.
This and (4.4) yield

W1S
1 + ‚àÜW2T

‚àû
< 1.
(‚áí) Assume that
‚à•W2T‚à•‚àû< 1 and

W1S
1 + ‚àÜW2T

‚àû
< 1,
‚àÄ‚àÜ.
(4.5)

4.3. ROBUST PERFORMANCE
55
Pick a frequency œâ where
|W1S|
1 ‚àí|W2T|
is maximum. Now pick ‚àÜso that
1 ‚àí|W2T| = |1 + ‚àÜW2T|.
The idea here is that ‚àÜ(jœâ) should rotate W2(jœâ)T(jœâ) so that ‚àÜ(jœâ)W2(jœâ)T(jœâ) is negative
real. The details of how to construct such an allowable ‚àÜare omitted. Now we have

W1S
1 ‚àí|W2T|

‚àû
=
|W1S|
1 ‚àí|W2T|
=
|W1S|
|1 + ‚àÜW2T|
‚â§

W1S
1 + ‚àÜW2T

‚àû
.
So from this and (4.5) there follows (4.4). ‚ñ†
Test (4.3) also has a nice graphical interpretation. For each frequency œâ, construct two closed
disks: one with center ‚àí1, radius |W1(jœâ)|; the other with center L(jœâ), radius |W2(jœâ)L(jœâ)|.
Then (4.3) holds iÔ¨Äfor each œâ these two disks are disjoint (Figure 4.6).
&%
'$
r
&%
'$
r -
6
|W2L|
|W1|
L
‚àí1
Figure 4.6: Robust performance graphically.
The robust performance condition says that the robust performance level 1 is achieved. More
generally, let‚Äôs say that robust performance level Œ± is achieved if
‚à•W2T‚à•‚àû< 1 and

W1S
1 + ‚àÜW2T

‚àû
< Œ±,
‚àÄ‚àÜ.
Noting that at every frequency
max
|‚àÜ|‚â§1

W1S
1 + ‚àÜW2T
 =
|W1S|
1 ‚àí|W2T|
we get that the minimum Œ± equals

W1S
1 ‚àí|W2T|

‚àû
.
(4.6)

56
CHAPTER 4. UNCERTAINTY AND ROBUSTNESS
Alternatively, we may wish to know how large the uncertainty can be while the robust perfor-
mance condition holds. To do this, we scale the uncertainty level, that is, we allow ‚àÜto satisfy
‚à•‚àÜ‚à•‚àû< Œ≤. Application of Theorem 1 shows that internal stability is robust iÔ¨Ä‚à•Œ≤W2T‚à•‚àû< 1.
Let‚Äôs say that the uncertainty level Œ≤ is permissible if
‚à•Œ≤W2T‚à•‚àû< 1 and

W1S
1 + ‚àÜW2T

‚àû
< 1,
‚àÄ‚àÜ.
Again, noting that
max
|‚àÜ|‚â§1

W1S
1 + Œ≤‚àÜW2T
 =
|W1S|
1 ‚àíŒ≤|W2T|,
we get that the maximum Œ≤ equals

W2T
1 ‚àí|W1S|

‚àí1
‚àû
.
Now we turn brieÔ¨Çy to some related problems.
Robust Stability for Multiple Perturbations
Suppose that a nominal plant P is perturbed to
ÀúP = P 1 + ‚àÜ2W2
1 + ‚àÜ1W1
with W1, W2 both stable and ‚àÜ1, ‚àÜ2 both admissible. The robust stability condition is
‚à•|W1S| + |W2T|‚à•‚àû< 1,
which is just the robust performance condition in Theorem 2. A sketch of the proof goes like this:
From the fourth entry in Table 4.1, for Ô¨Åxed ‚àÜ2 the robust stability condition for varying ‚àÜ1 is
W1
1
1 + (1 + ‚àÜ2W2)L

‚àû
< 1.
Then from Theorem 2 this holds for all admissible ‚àÜ2 iÔ¨Ä
‚à•|W1S| + |W2T|‚à•‚àû< 1.
This illustrates a more general point: Robust performance with one perturbation is equivalent
to robust stability with two perturbations, provided that performance is in terms of the ‚àû-norm
and the second perturbation is chosen appropriately.
Robust Command Response
Consider the block diagram shown in Figure 4.7. Shown are a plant P and two controller compo-
nents, C1 and C2. This is known as a two-degree-of-freedom controller because the plant input is
allowed to be a function of the two signals r and y independently, not just r ‚àíy. We will not go
into details about such controllers or about the appropriate deÔ¨Ånition of internal stability.

4.3. ROBUST PERFORMANCE
57
C1
C2
P


-
-
-
-

6
r
y
‚àí
Figure 4.7: Two-degree-of-freedom controller.
DeÔ¨Åne
S :=
1
1 + PC2
,
T := 1 ‚àíS.
Then the transfer function from r to y, denoted Tyr, is
Tyr = PSC1.
Let M be a transfer function representing a model that we want the foregoing system to emulate.
Denote by e the diÔ¨Äerence between y and the output of M. The error transfer function, that from
r to e, is
Ter = Tyr ‚àíM = PSC1 ‚àíM.
The ideal choice for C1, the one making Ter = 0, would therefore be
C1 = M
PS .
This choice may violate the internal stability constraint, but let‚Äôs suppose that in order to continue
that it does not (this places some limitations on M).
Consider now a multiplicative perturbation of the plant: P becomes ÀúP = (1 + ‚àÜW2)P, ‚àÜ
admissible. Then Ter becomes
ÀúTer
=
ÀúPC1
1 + ÀúPC2
‚àíM
=
ÀúP
1 + ÀúPC2
M
PS ‚àíM
=
‚àÜW2MS
1 + ‚àÜW2T (after some algebra).
DeÔ¨Åning W1 := W2M, we Ô¨Ånd that the maximum ‚àû-norm of the error transfer function, over all
admissible ‚àÜ, is
max
‚àÜ‚à•ÀúTec‚à•‚àû=

W1S
1 ‚àí|W2T|

‚àû
.
The right-hand side we have already seen in (4.6).

58
CHAPTER 4. UNCERTAINTY AND ROBUSTNESS
Note that we convert the problem of making the closed-loop response from r to y match some
desired response by subtracting oÔ¨Äthat desired response and forming an error signal e which we seek
to keep small. In some treatments of the command response problem, the performance speciÔ¨Åcation
is taken to be: make |Tyr| close to a desired model. The problem with this speciÔ¨Åcation is that two
transfer functions can be close in magnitude but diÔ¨Äer substantially in phase. Surprisingly, this can
occur even when both transfer functions are minimum phase. The interested reader may want to
investigate this further using the gain-phase relation developed in Chapter 7.
4.4
Robust Performance More Generally
Theorem 2 gives the robust performance test under the following conditions:
Perturbation model:
(1 + ‚àÜW2)P
Nominal performance condition:
‚à•W1S‚à•‚àû< 1
Table 4.2 gives tests for the four uncertainty models and two nominal performance conditions.
Nominal Performance Condition
Perturbation
‚à•W1S‚à•‚àû< 1
‚à•W1T‚à•‚àû< 1
(1 + ‚àÜW2)P
‚à•|W1S| + |W2T|‚à•‚àû< 1
messy
P + W2‚àÜ
‚à•|W1S| + |W2CS|‚à•‚àû< 1
messy
P/(1 + ‚àÜW2P)
messy
‚à•|W1T| + |W2PS|‚à•‚àû< 1
P/(1 + ‚àÜW2)
messy
‚à•|W1T| + |W2S|‚à•‚àû< 1
Table 4.2
The entries marked messy are just that.
The diÔ¨Éculty is the way in which ‚àÜenters.
For
example, consider the case where
Perturbation model:
(1 + ‚àÜW2)P
Nominal performance condition:
‚à•W1T‚à•‚àû< 1
The perturbed T is
(1 + ‚àÜW2)PC
1 + (1 + ‚àÜW2)PC = (1 + ‚àÜW2)T
1 + ‚àÜW2T ,
so the perturbed performance condition is equivalent to
|W1(1 + ‚àÜW2)T| < |1 + ‚àÜW2T|,
‚àÄœâ.
Now for each Ô¨Åxed œâ
|W1(1 + ‚àÜW2)T| ‚â§|W1T|(1 + |W2|)
and
1 ‚àí|W2T| ‚â§|1 + ‚àÜW2T|.
So a suÔ¨Écient condition for robust performance is

W1T(1 + |W2|)
1 ‚àí|W2T|

‚àû
< 1.

4.5. CONCLUSION
59
4.5
Conclusion
The nominal feedback system is assumed to be internally stable. Then the nominal performance
condition is ‚à•W1S‚à•‚àû< 1 and the robust stability condition (with respect to multiplicative pertur-
bations) is ‚à•W2T‚à•‚àû< 1.
The condition for simultaneously achieving nominal performance and robust stability is
‚à•max (|W1S|, |W2T|)‚à•‚àû< 1.
(4.7)
The robust performance condition is
‚à•W2T‚à•‚àû< 1 and

W1S
1 + ‚àÜW2T

‚àû
< 1,
‚àÄ‚àÜ
and the test for this is
‚à•|W1S| + |W2T|‚à•‚àû< 1.
(4.8)
Since
max (|W1S|, |W2T|) ‚â§|W1S| + |W2T| ‚â§2 max (|W1S|, |W2T|)
(4.9)
conditions (4.7) and (4.8) are not too far apart. For instance, if nominal performance and robust
stability are obtained with a safety factor of 2, that is,
‚à•W1S‚à•‚àû< 1/2,
‚à•W2T‚à•‚àû< 1/2,
then robust performance is automatically obtained.
A compromise condition, which we shall treat in Chapters 8 and 12, is
‚à•(|W1S|2 + |W2T|2)1/2‚à•‚àû< 1.
(4.10)
Simple plane geometry shows that
max (|W1S|, |W2T|) ‚â§(|W1S|2 + |W2T|2)1/2 ‚â§|W1S| + |W2T|
(4.11)
and
1
‚àö
2(|W1S| + |W2T|) ‚â§(|W1S|2 + |W2T|2)1/2 ‚â§
‚àö
2 max (|W1S|, |W2T|).
(4.12)
Thus (4.10) is a reasonable approximation to both (4.7) and (4.8).
To elaborate on this point, let‚Äôs consider
x =
 x1
x2

=
 |W1S|
|W2T|

as a vector in R2. Then (4.7), (4.8), and (4.10) correspond, respectively, to the three diÔ¨Äerent norms
max (|x1|, |x2|),
|x1| + |x2|,
(|x1|2 + |x2|2)1/2.
The third is the Euclidean norm and is the most tractable. The point being made here is that
choice of these spatial norms is not crucial: The tradeoÔ¨Äs between |W1S| and |W2T| inherent in
control problems mean that although the norms may diÔ¨Äer by as much as a factor of 2, the actual
solutions one gets by using the diÔ¨Äerent norms are not very diÔ¨Äerent.

60
CHAPTER 4. UNCERTAINTY AND ROBUSTNESS
Exercises
1. Consider a unity-feedback system. True or false: If a controller internally stabilizes two plants,
they have the same number of poles in Res ‚â•0.
2. Unity-feedback problem. Let PŒ±(s) be a plant depending on a real parameter Œ±. Suppose
that the poles of PŒ± move continuously as Œ± varies over the interval [0, 1]. True or false: If a
controller internally stabilizes PŒ± for every Œ± in [0, 1], then PŒ± has the same number of poles
in Re s ‚â•0 for every Œ± in [0, 1].
3. For the unity-feedback system with P(s) = k/s, does there exist a proper controller C(s) such
that the feedback system is internally stable for both k = +1 and k = ‚àí1?
4. Suppose that
P(s) =
œâ2
n
s(s + 2Œ∂œân),
C(s) = 1
with œân, Œ∂ > 0. Note that the characteristic polynomial is the standard second-order one.
Find the phase margin as a function of Œ∂. Sketch the graph of this function.
5. Consider the unity-feedback system with
P(s) =
1
(s + 1)(s + Œ±),
C(s) = 1
s.
For what range of Œ± (a real number) is the feedback system internally stable? Find the upper
and lower gain margins as functions of Œ±.
6. This problem studies robust stability for real parameter variations.
Consider the unity-
feedback system with C(s) = 10 and plant
1
s ‚àía,
where a is real.
(a) Find the range of a for the feedback system to be internally stable.
(b) For a = 0 the plant is P(s) = 1/s. Regarding a as a perturbation, we can write the
plant as
ÀúP =
P
1 + ‚àÜW2P
with W2(s) = ‚àía. Then ÀúP equals the true plant when ‚àÜ(s) = 1. Apply robust stability
theory to see when the feedback system with plant ÀúP is internally stable for all ‚à•‚àÜ‚à•‚àû‚â§1.
You will get a smaller range for a than in part (a).
(c) Repeat with the nominal plant P(s) = 1/(s + 100).

4.5. CONCLUSION
61
7. This problem concerns robust stability of the unity-feedback system. Suppose that P and C
are nominal transfer functions for which the feedback system is internally stable. Instead of
allowing perturbations in just P, this problem allows perturbations in C too. Suppose that
P may be perturbed to
(1 + ‚àÜ1W)P
and C may be perturbed to
(1 + ‚àÜ2V )C.
The transfer functions W and V are Ô¨Åxed, while ‚àÜ1 and ‚àÜ2 are variable transfer functions
having ‚àû-norms no greater than 1. Making appropriate additional assumptions, Ô¨Ånd a suÔ¨É-
cient condition, depending only on the four functions P, C, W, V , for robust stability. Prove
suÔ¨Éciency. (A weak suÔ¨Écient condition is the goal; for example, the condition W = V = 0
would be too strong.)
8. Assume that the nominal plant transfer function is a double integrator,
P(s) = 1
s2 .
The performance requirement is that the plant output should track reference inputs over the
frequency range [0, 1].
The performance weight W1 could therefore be chosen so that its
magnitude is constant over this frequency range and then rolls oÔ¨Äat higher frequencies. A
common choice for W1 is a Butterworth Ô¨Ålter, which is maximally Ô¨Çat over its bandwidth.
Choose a third-order Butterworth Ô¨Ålter for W1 with cutoÔ¨Äfrequency 1 rad/s. Take the weight
W2 to be
W2(s) =
0.21s
0.1s + 1.
(a) Design a proper C to achieve internal stability for the nominal plant.
(b) Check the robust stability condition ‚à•W2T‚à•‚àû< 1. If this does not hold, redesign C
until it does. It is not necessary to get a C that yields good performance.
(c) Compute the robust performance level Œ± for your controller from (4.6).
9. Consider the class of perturbed plants of the form
P
1 + ‚àÜW2P ,
where W2 is a Ô¨Åxed stable weighting function with W2P strictly proper and ‚àÜis a variable
stable transfer function with ‚à•‚àÜ‚à•‚àû‚â§1. Assume that C is a controller achieving internal
stability for P. Prove that C provides internal stability for the perturbed plant if ‚à•W2PS‚à•‚àû<
1.
10. Suppose that the plant transfer function is
ÀúP(s) = [1 + ‚àÜ(s)W2(s)] P(s),

62
CHAPTER 4. UNCERTAINTY AND ROBUSTNESS
where
W2(s) =
2
s + 10,
P(s) =
1
s ‚àí1,
and the stable perturbation ‚àÜsatisÔ¨Åes ‚à•‚àÜ‚à•‚àû‚â§2. Suppose that the controller is the pure
gain C(s) = k. We want the feedback system to be internally stable for all such perturbations.
Determine over what range of k this is true.
Notes and References
The basis for this chapter is Doyle and Stein (1981). This paper emphasized the importance of
explicit uncertainty models such as multiplicative and additive. Theorem 1 is stated in that paper,
but a complete proof is due to Chen and Desoer (1982). The suÔ¨Éciency part of this theorem is a
version of the small-gain theorem, due to Sandberg and Zames [see, e.g., Desoer and Vidyasagar
(1975)].

Chapter 5
Stabilization
In this chapter we study the unity-feedback system with block diagram shown in Figure 5.1. Here
C
P




-
-
-
-
-
?
6
r
u
y
d
‚àí
e
Figure 5.1: Unity-feedback system.
P is strictly proper and C is proper.
Most synthesis problems can be formulated in this way: Given P, design C so that the feedback
system (1) is internally stable, and (2) acquires some additional desired property; for example, the
output y asymptotically tracks a step input r. The method of solution is to parametrize all Cs for
which (1) is true, and then to see if there exists a parameter for which (2) holds. In this chapter such
a parametrization is derived and then applied to two problems: achieving asymptotic performance
specs and internal stabilization by a stable controller.
5.1
Controller Parametrization: Stable Plant
In this section we assume that P is already stable, and we parametrize all Cs for which the feedback
system is internally stable.
Introduce the symbol S for the family of all stable, proper, real-
rational functions. Notice that S is closed under addition and multiplication: If F, G ‚ààS, then
F + G, FG ‚ààS. Also, 1 ‚ààS. (Thus S is a commutative ring with identity.)
Theorem 1 Assume that P ‚ààS. The set of all Cs for which the feedback system is internally
stable equals

Q
1 ‚àíPQ : Q ‚ààS

.
63

64
CHAPTER 5. STABILIZATION
Proof (‚äÇ) Suppose that C achieves internal stability. Let Q denote the transfer function from r
to u, that is,
Q :=
C
1 + PC .
Then Q ‚ààS and
C =
Q
1 ‚àíPQ.
(‚äÉ) Conversely, suppose that Q ‚ààS and deÔ¨Åne
C :=
Q
1 ‚àíPQ.
(5.1)
According to the deÔ¨Ånition in Section 3.2, the feedback system is internally stable iÔ¨Äthe nine
transfer functions
1
1 + PC
Ô£Æ
Ô£∞
1
‚àíP
‚àí1
C
1
‚àíC
PC
P
1
Ô£π
Ô£ª
all are stable and proper. After substitution from (5.1) and clearing of fractions, this matrix becomes
Ô£Æ
Ô£∞
1 ‚àíPQ
‚àíP(1 ‚àíPQ)
‚àí(1 ‚àíPQ)
Q
1 ‚àíPQ
‚àíQ
PQ
P(1 ‚àíPQ)
1 ‚àíPQ
Ô£π
Ô£ª.
Clearly, these nine entries belong to S. ‚ñ†
Note that all nine transfer functions above are aÔ¨Éne functions of the free parameter Q; that is,
each is of the form T1 + T2Q for some T1, T2 in S. In particular the sensitivity and complementary
sensitivity functions are
S
=
1 ‚àíPQ,
T
=
PQ.
Let us look at a simple application. Suppose that we want to Ô¨Ånd a C so that the feedback
system is internally stable and y asymptotically tracks a step r (when d = 0). Parametrize C as in
the theorem. Then y asymptotically tracks a step iÔ¨Äthe transfer function from r to e (i.e., S) has
a zero at s = 0, that is,
P(0)Q(0) = 1.
This equation has a solution Q in S iÔ¨ÄP(0) Ã∏= 0. Conclusion: The problem has a solution iÔ¨Ä
P(0) Ã∏= 0; when this holds, the set of all solutions is

C =
Q
1 ‚àíPQ : Q ‚ààS, Q(0) =
1
P(0)

.

5.2. COPRIME FACTORIZATION
65
Observe that Q inverts P at dc. Also, you can check that a controller of the latter form has a pole
at s = 0, as it must by Theorem 3 of Chapter 3.
Example For the plant
P(s) =
1
(s + 1)(s + 2)
suppose that it is desired to Ô¨Ånd an internally stabilizing controller so that y asymptotically tracks
a ramp r. Parametrize C as in the theorem. The transfer function S from r to e must have (at
least) two zeros at s = 0, where r has two poles. Let us take
Q(s) = as + b
s + 1 .
This belongs to S and has two variables, a and b, for the assignment of the two zeros of S. We have
S(s)
=
1 ‚àí
as + b
(s + 1)2(s + 2)
=
s3 + 4s2 + (5 ‚àía)s + (2 ‚àíb)
(s + 1)2(s + 2)
,
so we should take a = 5, b = 2. This gives
Q(s)
=
5s + 2
s + 1 ,
C(s)
=
(5s + 2)(s + 1)(s + 2)
s2(s + 4)
.
The controller is internally stabilizing and has two poles at s = 0.
5.2
Coprime Factorization
Now suppose that P is not stable and we want to Ô¨Ånd an internally stabilizing C. We might try as
follows. Write P as the ratio of coprime polynomials,
P = N
M .
By Euclid‚Äôs algorithm (reviewed below) we can get two other polynomials X, Y satisfying the
equation
NX + MY = 1.
Remembering Theorem 3.1 (the feedback system is internally stable iÔ¨Äthe characteristic polynomial
has no zeros in Re s ‚â•0), we might try to make the left-hand side equal to the characteristic
polynomial by setting
C = X
Y .
The trouble is that Y may be 0; even if not, this C may not be proper.

66
CHAPTER 5. STABILIZATION
Example 1
For P(s) = 1/s, we can take N(s) = 1, M(s) = s. One solution to the equation
NX + MY = 1 is X(s) = 1, Y (s) = 0, for which X/Y is undeÔ¨Åned. Another solution is X(s) =
‚àís + 1, Y (s) = 1, for which X/Y is not proper.
The remedy is to arrange that N, M, X, Y are all elements of S instead of polynomials. Two
functions N and M in S are coprime if there exist two other functions X and Y also in S and
satisfying the equation
NX + MY = 1.
Notice that for this equation to hold, N and M can have no common zeros in Res ‚â•0 nor at the
point s = ‚àû‚Äîif there were such a point s0, there would follow
0 = N(s0)X(s0) + M(s0)Y (s0) Ã∏= 1.
It can be proved that this condition is also suÔ¨Écient for coprimeness.
Let G be a real-rational transfer function. A representation of the form
G = N
M ,
N, M ‚ààS,
where N and M are coprime, is called a coprime factorization of G over S. The purpose of this
section is to present a method for the construction of four functions in S satisfying the two equations
G = N
M ,
NX + MY = 1.
The construction of N and M is easy.
Example 2 Take G(s) = 1/(s ‚àí1). To write G = N/M with N and M in S, simply divide the
numerator and denominator polynomials, 1 and s ‚àí1, by a common polynomial with no zeros in
Res ‚â•0, say (s + 1)k:
1
s ‚àí1 = N(s)
M(s),
N(s) =
1
(s + 1)k ,
M(s) =
s ‚àí1
(s + 1)k .
If the integer k is greater than 1, then N and M are not coprime‚Äîthey have a common zero at
s = ‚àû. So
N(s) =
1
s + 1,
M(s) = s ‚àí1
s + 1
suÔ¨Éce.
More generally, to get N and M we could divide the numerator and denominator polynomials
of G by (s + 1)k, where k equals the maximum of their degrees. What is not so easy is to get the
other two functions, X and Y , and this is why we need Euclid‚Äôs algorithm.
Euclid‚Äôs algorithm computes the greatest common divisor of two given polynomials, say n(Œª)
and m(Œª). When n and m are coprime, the algorithm can be used to compute polynomials x(Œª),
y(Œª) satisfying
nx + my = 1.

5.2. COPRIME FACTORIZATION
67
Procedure A: Euclid‚Äôs Algorithm
Input: polynomials n, m
Initialize: If it is not true that degree (n) ‚â•degree (m), interchange n and m.
Step 1 Divide m into n to get quotient q1 and remainder r1:
n = mq1 + r1,
degree r1 < degree m.
Step 2 Divide r1 into m to get quotient q2 and remainder r2:
m = r1q2 + r2,
degree r2 < degree r1.
Step 3 Divide r2 into r1:
r1 = r2q3 + r3,
degree r3 < degree r2.
Continue.
Stop at Step k when rk is a nonzero constant.
Then x, y are obtained as illustrated by the following example for k = 3. The equations are
n = mq1 + r1,
m = r1q2 + r2,
r1 = r2q3 + r3,
that is,
Ô£Æ
Ô£∞
1
0
0
q2
1
0
‚àí1
q3
1
Ô£π
Ô£ª
Ô£Æ
Ô£∞
r1
r2
r3
Ô£π
Ô£ª=
Ô£Æ
Ô£∞
1
‚àíq1
0
1
0
0
Ô£π
Ô£ª
 n
m

.
Solve for r3 by, say, Gaussian elimination:
r3 = (1 + q2q3)n + [‚àíq3 ‚àíq1(1 + q2q3)]m.
Set
x
=
1
r3
(1 + q2q3),
y
=
1
r3
[‚àíq3 ‚àíq1(1 + q2q3)].

68
CHAPTER 5. STABILIZATION
Example 3 The algorithm for n(Œª) = Œª2, m(Œª) = 6Œª2 ‚àí5Œª + 1 goes like this:
q1(Œª)
=
1
6,
r1(Œª)
=
5
6Œª ‚àí1
6,
q2(Œª)
=
36
5 Œª ‚àí114
25 ,
r2(Œª)
=
6
25.
Since r2 is a nonzero constant, we stop after Step 2. Then the equations are
n
=
mq1 + r1,
m
=
r1q2 + r2,
yielding
r2 = (1 + q1q2)m ‚àíq2n.
So we should take
x = ‚àíq2
r2
,
y = 1 + q1q2
r2
,
that is,
x(Œª) = ‚àí30Œª + 19,
y(Œª) = 5Œª + 1.
Next is a procedure for doing a coprime factorization of G.
The main idea is to transform
variables, s ‚ÜíŒª, so that polynomials in Œª yield functions in S.
Procedure B
Input: G
Step 1 If G is stable, set N = G, M = 1, X = 0, Y = 1, and stop; else, continue.
Step 2 Transform G(s) to ÀúG(Œª) under the mapping s = (1 ‚àíŒª)/Œª. Write ÀúG as a ratio of
coprime polynomials:
ÀúG(Œª) = n(Œª)
m(Œª).
Step 3 Using Euclid‚Äôs algorithm, Ô¨Ånd polynomials x(Œª), y(Œª) such that
nx + my = 1.
Step 4
Transform n(Œª), m(Œª), x(Œª), y(Œª) to N(s), M(s), X(s), Y (s) under the mapping
Œª = 1/(s + 1).

5.3. COPRIME FACTORIZATION BY STATE-SPACE METHODS (OPTIONAL)
69
The mapping used in this procedure is not unique; the only requirement is that polynomials n, and
so on, map to N, and so on, in S.
Example 4 For
G(s) =
1
(s ‚àí1)(s ‚àí2)
the algorithm gives
ÀúG(Œª)
=
Œª2
6Œª2 ‚àí5Œª + 1,
n(Œª)
=
Œª2,
m(Œª)
=
6Œª2 ‚àí5Œª + 1,
x(Œª)
=
‚àí30Œª + 19,
y(Œª)
=
5Œª + 1 (from Example 3),
N(s)
=
1
(s + 1)2 ,
M(s)
=
(s ‚àí1)(s ‚àí2)
(s + 1)2
,
X(s)
=
19s ‚àí11
s + 1
,
Y (s)
=
s + 6
s + 1.
5.3
Coprime Factorization by State-Space Methods (Optional)
This optional section presents a state-space procedure for computing a coprime factorization over
S of a proper G. This procedure is more eÔ¨Écient than the polynomial method in the preceding
section.
We start with a new data structure. Suppose that A, B, C, D are real matrices of dimensions
n √ó n,
n √ó 1,
1 √ó n,
1 √ó 1.
The transfer function going along with this quartet is
D + C(sI ‚àíA)‚àí1B.
Note that the constant D equals the value of the transfer function at s = ‚àû; if the transfer function
is strictly proper, then D = 0. It is convenient to write
 A
B
C
D

instead of
D + C(sI ‚àíA)‚àí1B.

70
CHAPTER 5. STABILIZATION
Beginning with a realization of G,
G(s) =
 A
B
C
D

,
the goal is to get state-space realizations for four functions N, M, X, Y , all in S, such that
G = N
M ,
NX + MY = 1.
First, we look at how to get N and M. If the input and output of G are denoted u and y,
respectively, then the state model of G is
Àôx
=
Ax + Bu,
(5.2)
y
=
Cx + Du.
(5.3)
Choose a real matrix F, 1 √ó n, such that A + BF is stable (i.e., all eigenvalues in Res < 0). Now
deÔ¨Åne the signal v := u ‚àíFx. Then from (5.2) and (5.3) we get
Àôx
=
(A + BF)x + Bv,
u
=
Fx + v,
y
=
(C + DF)x + Dv.
Evidently from these equations, the transfer function from v to u is
M(s) :=
 A + BF
B
F
1

,
(5.4)
and that from v to y is
N(s) :=
 A + BF
B
C + DF
D

.
(5.5)
Therefore,
u = Mv,
y = Nv,
so that y = NM‚àí1u, that is, G = N/M. Clearly, N and M are proper, and they are stable because
A + BF is. Thus N, M ‚ààS. Suggestion: Test the formulas above for the simplest case, G(s) = 1/s
(A = 0, B = 1, C = 1, D = 0).
The theory behind the formulas for X and Y is beyond the scope of this book. The procedure
is to choose a real matrix H, n √ó 1, so that A + HC is stable, and then set
X(s)
:=
 A + HC
H
F
0

,
(5.6)
Y (s)
:=
 A + HC
‚àíB ‚àíHD
F
1

.
(5.7)
In summary, the procedure to do a coprime factorization of G is this:
Step 1 Get a realization (A, B, C, D) of G.
Step 2 Compute matrices F and H so that A + BF and A + HC are stable.
Step 3 Using formulas (5.4) to (5.7), compute the four functions N, M, X, Y .

5.4. CONTROLLER PARAMETRIZATION: GENERAL PLANT
71
5.4
Controller Parametrization: General Plant
The transfer function P is no longer assumed to be stable. Let P = N/M be a coprime factorization
over S and let X, Y be two functions in S satisfying the equation
NX + MY = 1.
(5.8)
Theorem 2 The set of all Cs for which the feedback system is internally stable equals
X + MQ
Y ‚àíNQ : Q ‚ààS

.
It is useful to note that Theorem 2 reduces to Theorem 1 when P ‚ààS. To see this, recall from
Section 5.2 (Step 1 of Procedure B) that we can take
N = P,
M = 1,
X = 0,
Y = 1
when P ‚ààS. Then
X + MQ
Y ‚àíNQ =
Q
1 ‚àíPQ.
The proof of Theorem 2 requires a preliminary result.
Lemma 1 Let C = NC/MC be a coprime factorization over S. Then the feedback system is inter-
nally stable iÔ¨Ä
(NNC + MMC)‚àí1 ‚ààS.
The proof of this lemma is almost identical to the proof of Theorem 3.1, and so is omitted.
Proof of Theorem 2 (‚äÉ) Suppose that Q ‚ààS and
C := X + MQ
Y ‚àíNQ .
To show that the feedback system is internally stable, deÔ¨Åne
NC := X + MQ,
MC := Y ‚àíNQ.
Then from the equation
NX + MY = 1
it follows that
NNC + MMC = 1.
Therefore, C = NC/MC is a coprime factorization, and from Lemma 1 the feedback system is
internally stable.

72
CHAPTER 5. STABILIZATION
(‚äÇ) Conversely, let C be any controller achieving internal stability. We must Ô¨Ånd a Q in S such
that
C = X + MQ
Y ‚àíNQ .
Let C = NC/MC be a coprime factorization over S and deÔ¨Åne
V := (NNC + MMC)‚àí1
so that
NNCV + MMCV = 1.
(5.9)
By Lemma 1, V ‚ààS. Let Q be the solution of
MCV = Y ‚àíNQ.
(5.10)
Substitute (5.10) into (5.9) to get
NNCV + M(Y ‚àíNQ) = 1.
(5.11)
Also, add and subtract NMQ in (5.8) to give
N(X + MQ) + M(Y ‚àíNQ) = 1.
(5.12)
Comparing (5.11) and (5.12), we see that
NCV = X + MQ.
(5.13)
Now (5.10) and (5.13) give
C = NCV
MCV = X + MQ
Y ‚àíNQ .
It remains to show that Q ‚ààS. Multiply (5.10) by X and (5.13) by Y , then subtract and switch
sides:
(NX + MY )Q = Y NCV ‚àíXMCV.
But the left-hand side equals Q by (5.8), while the right-hand side belongs to S. So we are done. ‚ñ†
Theorem 2 gives an automatic way to stabilize a plant.
Example Let
P(s) =
1
(s ‚àí1)(s ‚àí2).

5.5. ASYMPTOTIC PROPERTIES
73
Apply Procedure B to get
N(s)
=
1
(s + 1)2 ,
M(s)
=
(s ‚àí1)(s ‚àí2)
(s + 1)2
,
X(s)
=
19s ‚àí11
s + 1
,
Y (s)
=
s + 6
s + 1.
According to the theorem, the controller
C(s) = X(s)
Y (s) = 19s ‚àí11
s + 6
achieves internal stability.
As before, when P was stable, all closed-loop transfer functions are aÔ¨Éne functions of Q if
C is parametrized as in the theorem statement. For example, the sensitivity and complementary
sensitivity functions are
S
=
M(Y ‚àíNQ),
T
=
N(X + MQ).
Finally, it is sometimes useful to note that Lemma 1 suggests another way to solve the equation
NX + MY = 1 given coprime N and M. First, Ô¨Ånd a controller C achieving internal stability for
P = N/M‚Äîthis might be easier than solving for X and Y . Next, write a coprime factorization of
C: C = NC/MC. Then Lemma 1 says that
V := NNC + MMC
is invertible in S. Finally, set X = NCV ‚àí1 and Y = MCV ‚àí1.
5.5
Asymptotic Properties
How to Ô¨Ånd a C to achieve internal stability and asymptotic properties simultaneously is perhaps
best shown by an example.
Let
P(s) =
1
(s ‚àí1)(s ‚àí2).
The problem is to Ô¨Ånd a proper C so that
1. The feedback system is internally stable.
2. The Ô¨Ånal value of y equals 1 when r is a unit step and d = 0.
3. The Ô¨Ånal value of y equals zero when d is a sinusoid of 10 rad/s and r = 0.

74
CHAPTER 5. STABILIZATION
The Ô¨Årst step is to parametrize all stabilizing Cs. Suitable N, M, X, Y are given in the example
of the preceding section. From Theorem 2 C must have the form
C = X + MQ
Y ‚àíNQ
(5.14)
for some Q in S in order to satisfy (1).
For such C the transfer function from r to y equals
N(X + MQ). By the Ô¨Ånal-value theorem (2) holds iÔ¨Ä
N(0)[X(0) + M(0)Q(0)] = 1.
(5.15)
Similarly, the transfer function from d to y equals N(Y ‚àíNQ), so (3) holds iÔ¨Ä
N(10j)[Y (10j) ‚àíN(10j)Q(10j)] = 0.
(5.16)
So the problem reduces to the purely algebraic one of Ô¨Ånding a function Q in S satisfying (5.15)
and (5.16), which reduce to
Q(0)
=
6,
(5.17)
Q(10j)
=
(6 + 10j)(1 + 10j) = ‚àí94 + 70j.
This last equation is really two real equations:
Re Q(10j)
=
‚àí94,
(5.18)
Im Q(10j)
=
70.
(5.19)
So we must Ô¨Ånd a function Q in S satisfying (5.17), (5.18), and (5.19).
A method that will certainly work is to let Q be a polynomial in (s + 1)‚àí1 with enough variable
coeÔ¨Écients. This guarantees that Q ‚ààS. Since we need to satisfy three equations, we should allow
three coeÔ¨Écients. So take Q in the form
Q(s) = x1 + x2
1
s + 1 + x3
1
(s + 1)2 .
The three equations (5.17)-(5.19) lead to one of the form Ax = b, where
x =
Ô£´
Ô£≠
x1
x2
x3
Ô£∂
Ô£∏.
Solve for x. In this case the solution is
x1 = ‚àí79,
x2 = ‚àí723,
x3 = 808.
This gives
Q(s) = ‚àí79s2 ‚àí881s + 6
(s + 1)2
.
Finally, we get C from (5.14):
C(s) = ‚àí60s4 ‚àí598s3 + 2515s2 ‚àí1794s + 1
s(s2 + 100)(s + 9)
.
In summary, the procedure consists of four steps:

5.6. STRONG AND SIMULTANEOUS STABILIZATION
75
1. Parametrize all internally stabilizing controllers.
2. Reduce the asymptotic specs to interpolation constraints on the parameter.
3. Find (if possible) a parameter to satisfy these constraints.
4. Back-substitute to get the controller.
5.6
Strong and Simultaneous Stabilization
Practicing control engineers are reluctant to use unstable controllers, especially if the plant itself is
stable. System integrity is the motivation: For example, if a sensor or actuator fails, or is deliberately
turned oÔ¨Äduring start-up or shutdown, and the feedback loop opens, overall stability is maintained
if both plant and controller individually are stable. If the plant itself is unstable, the argument
against using an unstable controller is less compelling.
However, knowledge of when a plant is
or is not stabilizable with a stable controller is useful for another problem, namely, simultaneous
stabilization, meaning stabilization of several plants by the same controller.
The issue of simultaneous stabilization arises when a plant is subject to a discrete change, such
as when a component burns out. Simultaneous stabilization of two plants can also be viewed as
an example of a problem involving highly structured uncertainty. A set of plants with exactly two
elements is the most extreme example of highly structured uncertainty, standing at the opposite
end of the spectrum from the unstructured disk-like uncertainty, which is the type of uncertainty
focused on in this book.
Say that a plant is strongly stabilizable if internal stabilization can be achieved with C itself a
stable transfer function. We start with an example of a plant that is not strongly stabilizable.
Example 1 Consider the plant transfer function
P(s) =
s ‚àí1
s(s ‚àí2).
Every C achieving internal stability is itself unstable. To prove this, start with a coprime factor-
ization of P:
N(s)
=
s ‚àí1
(s + 1)2 ,
M(s)
=
s(s ‚àí2)
(s + 1)2 ,
X(s)
=
14s ‚àí1
s + 1 ,
Y (s)
=
s ‚àí9
s + 1.
According to Theorem 2, all stabilizing controllers have the form
C = X + MQ
Y ‚àíNQ
for some Q in S. Since X + MQ and Y ‚àíNQ too are coprime‚Äîthey satisfy the equation
N(X + MQ) + M(Y ‚àíNQ) = 1

76
CHAPTER 5. STABILIZATION
‚Äîthey have no common zero in Res ‚â•0. So to show that all such Cs are unstable, it suÔ¨Éces to
show that Y ‚àíNQ has a zero in Res ‚â•0 for every Q in S. Now
N(1) = 0,
N(‚àû) = 0,
so for every Q in S
(Y ‚àíNQ)(1)
=
Y (1)
=
‚àí4,
(Y ‚àíNQ)(‚àû)
=
Y (‚àû)
=
1.
Notice that the two numbers on the right-hand side have opposite sign. Thus as s moves along the
positive real axis, the function (Y ‚àíNQ)(s) changes sign. By continuity, it must equal zero at some
such point, that is, Y ‚àíNQ has a real zero somewhere on the positive real axis.
The poles and zeros of P must share a certain property in order for P to be strongly stabilizable.
In the following theorem, the point at s = ‚àûis included among the real zeros of P.
Theorem 3 P is strongly stabilizable iÔ¨Äit has an even number of real poles between every pair of
real zeros in Res ‚â•0.
To illustrate, continue with the example above. The zeros, including the point at inÔ¨Ånity, are
at s = 1, ‚àû. Between this pair is a single pole, at s = 2. This plant therefore fails the test.
As another example, consider
P(s) = (s ‚àí1)2(s2 ‚àís + 1)
(s ‚àí2)2(s + 1)3
.
On the positive real axis, including ‚àû, P has three zeros, two at s = 1 and one at s = ‚àû. It has
two other zeros in Res ‚â•0, which, not being real, are irrelevant. In counting poles between pairs of
zeros we only have to consider distinct zeros (there are no poles between coincident zeros). Between
zeros at s = 1, ‚àûlie two poles, at s = 2. So this P is strongly stabilizable.
Proof of Theorem 3, Necessity The proof is just as in Example 1. Assume that the pole-zero
test fails. To show that every stabilizing controller is unstable, start with a coprime factorization
of P,
P = N
M ,
NX + MY = 1,
and some stabilizing controller,
C = X + MQ
Y ‚àíNQ ,
Q ‚ààS.
It suÔ¨Éces to show that Y ‚àíNQ has a zero in Res ‚â•0.
By assumption, there is some pair of real zeros of N in Res ‚â•0, at s = œÉ1, œÉ2, say, with an odd
number of zeros of M in between. It follows that M(œÉ1) and M(œÉ2) have opposite sign; then so do

5.6. STRONG AND SIMULTANEOUS STABILIZATION
77
Y (œÉ1) and Y (œÉ2), since MY = 1 at the right half-plane zeros of N. Hence the function Y ‚àíNQ
has a real zero somewhere between s = œÉ1 and s = œÉ2. ‚ñ†
The proof of suÔ¨Éciency is Ô¨Årst illustrated by means of an example.
Example 2 Take the plant transfer function
P(s) =
s ‚àí1
(s ‚àí2)2 .
This has two poles, at s = 2, between the two zeros at s = 1, ‚àû, so P is strongly stabilizable. To
get a stable, stabilizing C, we should get a Q in S such that the inverse of U := Y ‚àíNQ belongs
to S. Equivalently, we should get a U in S such that U‚àí1 ‚ààS and U = Y at the two zeros of N,
namely, s = 1, ‚àû. For this P we have
N(s) =
s ‚àí1
(s + 1)2 ,
M(s) = (s ‚àí2)2
(s + 1)2 .
Now
Y (1) =
1
M(1) = 4,
Y (‚àû) =
1
M(‚àû) = 1.
So the problem reduces to constructing a U in S such that
U‚àí1 ‚ààS,
U(1) = 4,
U(‚àû) = 1.
The latter problem can be solved in two steps. First, get a U1 in S such that
U‚àí1
1
‚ààS,
U1(1) = 4.
The easiest choice is the constant U1(s) = 4. Now we look for U of the form
U = (1 + aF)lU1,
where a is a constant, l an integer, and F ‚ààS. To guarantee that U(1) = U1(1) we should arrange
that F(1) = 0, for example,
F(s) = s ‚àí1
s + 1.
Then for U(‚àû) = 1 we need (1 + a)l4 = 1, that is,
a =
1
4
1/l
‚àí1,
(5.20)
and for U‚àí1 ‚ààS it suÔ¨Éces to have ‚à•aF‚à•‚àû< 1 (i.e., |a| < 1/‚à•F‚à•‚àû= 1). So suitable l and a can be
obtained by Ô¨Årst choosing l large enough that

1
4
1/l
‚àí1
 < 1

78
CHAPTER 5. STABILIZATION
and then getting a from (5.20), for example, l = 1, a = ‚àí3/4. This gives
U(s) =

1 ‚àí3
4
s ‚àí1
s + 1

4 = s + 7
s + 1.
Finally, U, M, N uniquely determine C, as follows:
U = Y ‚àíNQ =‚áíQ = Y ‚àíU
N
=‚áíC = X + MQ
Y ‚àíNQ = 1 ‚àíMU
NU
.
For this example we get C(s) = 27/(s + 7). Notice that we did not actually have to construct X
and Y .
Now for the constructive procedure that proves suÔ¨Éciency in Theorem 3. The general proce-
dure is fairly involved, so a simplifying assumption will be made that Ps unstable poles and zeros
(including ‚àû) are all real and distinct. (Of course, Theorem 3 holds without this assumption.)
Procedure
Step 0 Write P = N/M with N, M coprime. Arrange the non-negative real zeros of N as
follows:
0 ‚â§œÉ1 < œÉ2 < ¬∑ ¬∑ ¬∑ < œÉm = ‚àû.
DeÔ¨Åne ri := 1/M(œÉi), i = 1, . . . , m. Then P is strongly stabilizable iÔ¨Är1, . . . , rm all have the
same sign. If this is true, continue.
Step 1 Set U1(s) = r1.
Continue. Assume that Uk has been constructed to satisfy
Uk, U‚àí1
k
‚ààS,
Uk(œÉi) = ri,
i = 1, . . . , k.
Step k + 1 Choose F in S to have zeros at s = œÉ1, . . . , œÉk. Choose l ‚â•1 and a so that
[1 + aF(œÉk+1)]l Uk(œÉk+1) = rk+1,
|a| <
1
‚à•F‚à•‚àû
.
Set Uk+1 = (1 + aF)lUk.
Continue to Step m.
Step m + 1 Set U = Um and C = (1 ‚àíMU)/(NU).
Now we return to the problem of simultaneous stabilization and see that it can be reduced to
one of strong stabilization. Two plants P1 and P2 are simultaneously stabilizable if internal stability
is achievable for both by a common controller. Bring in coprime factorizations:
Pi = Ni
Mi
,
NiXi + MiYi = 1,
i = 1, 2

5.6. STRONG AND SIMULTANEOUS STABILIZATION
79
and deÔ¨Åne
N = N2M1 ‚àíN1M2,
M = N2X1 + M2Y1,
P = N
M .
For example, if P1 is already stable, we may take
N1 = P1,
M1 = 1,
X1 = 0,
Y1 = 1,
in which case
N = N2 ‚àíP1M2,
M = M2,
so P = P2 ‚àíP1.
Theorem 4 P1 and P2 are simultaneously stabilizable iÔ¨ÄP is strongly stabilizable.
Proof The controllers stabilizing Pi are
Xi + MiQi
Yi ‚àíNiQi
,
Qi ‚ààS.
Thus P1 and P2 are simultaneously stabilizable iÔ¨Äthere exist Q1, Q2 in S such that
X1 + M1Q1
Y1 ‚àíN1Q1
= X2 + M2Q2
Y2 ‚àíN2Q2
.
Since these two fractions both have coprime factors, this equation holds iÔ¨Äthere exists U in S such
that
U‚àí1
‚àà
S,
X1 + M1Q1
=
U(X2 + M2Q2),
Y1 ‚àíN1Q1
=
U(Y2 ‚àíN2Q2).
To simplify the bookkeeping, write these last two equations in matrix form:

1
Q1
  X1
Y1
M1
‚àíN1

= U

1
Q2
  X2
Y2
M2
‚àíN2

.
Postmultiply this equation by
 N2
Y2
M2
‚àíX2

to get

1
Q1
  X1
Y1
M1
‚àíN1
  N2
Y2
M2
‚àíX2

= U

1
Q2

.
Now the Ô¨Årst column of the matrix
 X1
Y1
M1
‚àíN1
  N2
Y2
M2
‚àíX2


80
CHAPTER 5. STABILIZATION
is
 M
N

;
denote the second column by
 X
Y

.
Then the previous matrix equation is equivalent to the two equations
M + NQ1
=
U,
X + Y Q1
=
UQ2.
To recap, P1 and P2 are simultaneously stabilizable iÔ¨Äthere exist Q1, Q2, U in S such that
U‚àí1
‚àà
S,
M + NQ1
=
U,
X + Y Q1
=
UQ2.
Clearly, this is equivalent to the condition, there exist Q1, U in S such that
U‚àí1
‚àà
S,
M + NQ1
=
U
[because we can get Q2 via (X + Y Q1)/U]. But it can be checked that N and M are coprime.
Thus from Lemma 1 the previous condition is equivalent to, P can be stabilized by some stable
controller, namely, Q1. ‚ñ†
Example 3 Consider
P1(s) =
1
s + 1,
P2(s) =
as + b
(s + 1)(s ‚àí1),
where a and b are real constants with a Ã∏= 1. Since P1 is stable, we have
P(s) = P2(s) ‚àíP1(s) = ‚àí(1 ‚àía)s ‚àí(1 + b)
(s + 1)(s ‚àí1)
.
This has zeros at
s = 1 + b
1 ‚àía, ‚àû
and a simple unstable pole at s = 1. So P is strongly stabilizable, or P1 and P2 are simultaneously
stabilizable, iÔ¨Äeither the zero (1 + b)/(1 ‚àía) is negative or it lies to the right of the unstable pole,
that is,
either 1 + b
1 ‚àía < 0 or
1 + b
1 ‚àía > 1.
Simultaneous stabilization for more than two plants is still an unsolved problem.

5.7. CART-PENDULUM EXAMPLE
81


l
u
y
x
Œ∏
d
m
M
-

-

@
@
R
-









Figure 5.2: Cart-pendulum example.
5.7
Cart-Pendulum Example
An interesting stabilization problem is aÔ¨Äorded by the cart-pendulum example, a common toy
control system. The setup is shown in Figure 5.2. The system consists of a cart of mass M that
slides in one dimension x on a horizontal surface, with a ball of mass m at the end of a rigid massless
pendulum of length l. The cart and ball are treated as point masses, with the pivot at the center of
the cart. There is assumed to be no friction and no air resistance. Shown as inputs are a horizontal
force u on the cart and a force d on the ball perpendicular to the pendulum. The other signals
shown are the angle Œ∏ and the position of the ball y = x + l sin Œ∏.
Elementary dynamics yields the following equations of motion:
(M + m)¬®x + ml(¬®Œ∏ cos Œ∏ ‚àíÀôŒ∏2 sin Œ∏)
=
u + d cos Œ∏,
(5.21)
m

¬®x cos Œ∏ + l¬®Œ∏ ‚àíg sin Œ∏

=
d.
(5.22)
These are nonlinear equations which can be linearized about an equilibrium position, of which there
are two: (x, Œ∏) = (0, 0) and (x, Œ∏) = (0, œÄ) (i.e., the pendulum either up or down).
Linearization About Pendulum Up
The two linearized equations are
(M + m)¬®x + ml¬®Œ∏
=
u + d,
¬®x + l¬®Œ∏ ‚àígŒ∏
=
1
md.
Take Laplace transforms to get
 (M + m)s2
mls2
s2
ls2 ‚àíg
  ÀÜx
ÀÜŒ∏

=
Ô£Æ
Ô£∞ÀÜu + ÀÜd
1
m
ÀÜd
Ô£π
Ô£ª.

82
CHAPTER 5. STABILIZATION
Thus
 ÀÜx
ÀÜŒ∏

=
1
D(s)
" ls2 ‚àíg
‚àíg
‚àís2
M
m s2
#  ÀÜu
ÀÜd

,
where
D(s) = s2[Mls2 ‚àí(M + m)g].
Finally,
ÀÜy = ÀÜx + lÀÜŒ∏ =
1
D(s)

‚àíg
M
m ls2g
  ÀÜu
ÀÜd

.
In particular, the transfer functions from u to x and y are, respectively,
ls2 ‚àíg
D(s) ,
‚àíg
D(s).
These are both unstable, having right half-plane poles at
s = 0, 0,
r
(M + m)g
Ml
.
Also, the transfer function from u to x has a right half-plane zero at s =
p
g/l.
Linearization About Pendulum Down
Replacing Œ∏ by œÄ + Œ∏ in equations (5.21) and (5.22) and linearizing, we get
(M + m)¬®x ‚àíml¬®Œ∏
=
u ‚àíd,
‚àí¬®x + l¬®Œ∏ + gŒ∏
=
1
md,
so
 ÀÜx
ÀÜŒ∏

=
1
D(s)
" ls2 + g
‚àíg
s2
M
m s2
#  ÀÜu
ÀÜd

,
and
ÀÜy = ÀÜx ‚àílÀÜŒ∏ =
1
D(s)

g
‚àíM
m ls2g
  ÀÜu
ÀÜd

,
where
D(s) = s2[Mls2 + (M + m)g].
The transfer functions from u to x and y are now, respectively,
ls2 + g
D(s) ,
g
D(s).

5.7. CART-PENDULUM EXAMPLE
83
Let us look at the problem of stabilizing the u-to-x transfer function with the pendulum in the
up position. The transfer function is
ls2 ‚àíg
s2[Mls2 ‚àí(M + m)g].
Since this has an unstable pole, namely,
r
(M + m)g
Ml
,
between two real zeros at s =
p
g/l, ‚àû, from the preceding section this transfer function is not
strongly stabilizable. Having no Ô¨Ånite zeros, the u-to-y transfer function is, however.
Is the cart-pendulum stabilizable if we measure x and control d? First of all, what does this
mean? The cart-pendulum as conÔ¨Ågured is really a multivariable system: It has two inputs, u and
d, and two outputs, x and Œ∏ (y is a linear combination of these two). So really there are four loops
we could close: from x to u and d and from Œ∏ to u and d. Let us contemplate closing just from x
to d. We would like all closed-loop transfer functions to be stable, for example, u-to-Œ∏, x-to-Œ∏, and
so on. Is this possible?
(This analysis applies only to the linearized system. Since there are poles on the imaginary
axis, the stability of the linear system does not determine even the local stability of the nonlinear
system.)
We shall return to this example in the next chapter.
Exercises
1. Compute a coprime factorization over S of
G(s) =
s3
s2 ‚àís + 1.
2. For
P(s) =
3
s ‚àí4
compute a controller C so that the feedback system is internally stable and the tracking error
e goes to 0 when r is a ramp and d = 0.
3. For
P(s) =
1
s(s2 + 0.2s + 1)
Ô¨Ånd an internally stabilizing C so that the Ô¨Ånal value of r ‚àíy equals zero when r is a unit
ramp and d is a sinusoid of frequency 2 rad/s.
4. Suppose that P(s) = 1/s and C = Q/(1 ‚àíPQ), where Q is a proper real-rational function.
Characterize those functions Q for which the feedback system is internally stable.

84
CHAPTER 5. STABILIZATION
5. Suppose that N, M are coprime functions in S. Prove that if NM‚àí1 ‚ààS, then M‚àí1 ‚ààS. Is
this true without the coprimeness assumption?
6. The problem is to Ô¨Ånd an internally stabilizing C so that e tends to zero asymptotically when
r is a step and d = 0. When is the problem solvable? Characterize all solutions. (Do not
assume P is stable.)
7. Let
P(s) =
s
(s ‚àí1)(10s + 1).
Find a C to achieve internal stability. What are the closed-loop poles? What is the dc gain
from d to y?
8. For formulas (5.4) to (5.7), verify that NX + MY = 1.
9. Consider the feedback system with plant P and controller C.
Assume internal stability.
Consider a coprime factorization of P over S, P = N/M. Suppose that P is perturbed to
P = N + ‚àÜ1
M + ‚àÜ2
,
where
‚àÜ1, ‚àÜ2
‚àà
S,
‚à•‚àÜ1‚à•‚àû, ‚à•‚àÜ2‚à•‚àû
‚â§
Œ≥.
Find a bound on Œ≥ for robust stability.
10. Compute a stable, stabilizing controller for
P(s) =
(s ‚àí1)(s2 + s + 1)
(s ‚àí2)(s ‚àí3)(s + 1)2 .
11. Study simultaneous stabilization of the cart-pendulum system in the up and down conÔ¨Ågura-
tions.
Notes and References
The idea behind Theorem 1 is due to Newton et al. (1957). They observed that while the transfer
function from r to y is nonlinear in C, it is linear in Q, the transfer function from r to u. So
they proposed to design Q to achieve desired performance and then obtain C by back-substitution.
Theorem 1 itself is due to Zames (1981).
The controller parametrization in Theorem 1 is used
in the Ô¨Åeld of process control, where it is called internal model control [because the controller
C = Q/(1 ‚àíPQ) contains a model of the plant P] (Morari and ZaÔ¨Åriou, 1989).
The original form of Theorem 2 is due independently to Youla et al. (1976) and Kucera (1979).
Its present form is due to Desoer et al. (1980), who saw the advantage of doing coprime factorization
over S instead of the ring of polynomials. This idea in turn is due to Vidyasagar (1972). State-
space formulas for coprime factorization were Ô¨Årst derived by Khargonekar and Sontag (1982).

5.7. CART-PENDULUM EXAMPLE
85
The formulas in Section 5.3 are from Nett et al. 1984. Section 5.5 is adapted from Francis and
Vidyasagar (1983). The algebraic point of view has been explored in detail by Desoer and co-workers
(e.g., Desoer and Gustafson, 1984) and by Vidyasagar (1985). The notion of strong stabilization
and Theorem 3 are due to Youla et al. (1974). Simultaneous stabilization was Ô¨Årst treated by
Saeks and Murray (1982). The simple proofs of Theorems 3 and 4 given here are borrowed from
Vidyasagar (1985).
The controller parametrization of Theorem 2 has been exploited in a CAD
method for controller design (Boyd et al., 1988).

86
CHAPTER 5. STABILIZATION

Chapter 6
Design Constraints
Before we see how to design control systems for the robust performance speciÔ¨Åcation, it is useful
to determine the basic limitations on achievable performance.
In this chapter we study design
constraints arising from two sources: from algebraic relationships that must hold among various
transfer functions; from the fact that closed-loop transfer functions must be stable (i.e., analytic in
the right half-plane). It is assumed throughout this chapter that the feedback system is internally
stable.
6.1
Algebraic Constraints
There are three items in this section.
1. The identity S + T = 1 always holds. This is an immediate consequence of the deÔ¨Ånitions
of S and T. So in particular, |S(jœâ)| and |T(jœâ)| cannot both be less than 1/2 at the same
frequency œâ.
2. A necessary condition for robust performance is that the weighting functions satisfy
min{|W1(jœâ)|, |W2(jœâ)|} < 1,
‚àÄœâ.
Proof Fix œâ and assume that |W1| ‚â§|W2| (the argument jœâ is suppressed). Then
|W1|
=
|W1(S + T)|
‚â§
|W1S| + |W1T|
‚â§
|W1S| + |W2T|.
So robust performance (see Theorem 4.2), that is,
‚à•|W1S| + |W2T|‚à•‚àû< 1,
implies that |W1| < 1, and hence
min{|W1|, |W2|} < 1.
The same conclusion can be drawn when |W2| ‚â§|W1|. ‚ñ†
87

88
CHAPTER 6. DESIGN CONSTRAINTS
So at every frequency either |W1| or |W2| must be less than 1. Typically, |W1(jœâ)| is monoton-
ically decreasing‚Äîfor good tracking of low-frequency signals‚Äîand |W2(jœâ)| is monotonically
increasing‚Äîuncertainty increases with increasing frequency.
3. If p is a pole of L in Res ‚â•0 and z is a zero of L in the same half-plane, then
S(p) = 0,
S(z) = 1,
(6.1)
T(p) = 1,
T(z) = 0.
(6.2)
These interpolation constraints are immediate from the deÔ¨Ånitions of S and T. For example,
S(p) =
1
1 + L(p) = 1
‚àû= 0.
6.2
Analytic Constraints
In this section we derive some constraints concerning achievable performance obtained from analytic
function theory. The Ô¨Årst subsection presents some mathematical preliminaries.
Preliminaries
We begin with the following fundamental facts concerning complex functions: the maximum mod-
ulus theorem, Cauchy‚Äôs theorem, and Cauchy‚Äôs integral formula. These are stated here for conve-
nience.
Maximum Modulus Theorem Suppose that ‚Ñ¶is a region (nonempty, open, connected set) in
the complex plane and F is a function that is analytic in ‚Ñ¶. Suppose that F is not equal to a
constant. Then |F| does not attain its maximum value at an interior point of ‚Ñ¶.
A simple application of this theorem, with ‚Ñ¶equal to the open right half-plane, shows that for
F in S
‚à•F‚à•‚àû= sup
Res>0
|F(s)|.
Cauchy‚Äôs Theorem Suppose that ‚Ñ¶is a bounded open set with connected complement and D is a
non-self-intersecting closed contour in ‚Ñ¶. If F is analytic in ‚Ñ¶, then
I
D
F(s)ds = 0.
Cauchy‚Äôs Integral Formula Suppose that F is analytic on a non-self-intersecting closed contour
D and in its interior ‚Ñ¶. Let s0 be a point in ‚Ñ¶. Then
F(s0) =
1
2œÄj
I
D
F(s)
s ‚àís0
ds.
We shall also need the Poisson integral formula, which says that the value of a bounded analytic
function at a point in the right half-plane is completely determined by the coordinates of the point
together with the values of the function on the imaginary axis.

6.2. ANALYTIC CONSTRAINTS
89
Lemma 1 Let F be analytic and of bounded magnitude in Res ‚â•0 and let s0 = œÉ0 +jœâ0 be a point
in the complex plane with œÉ0 > 0. Then
F(s0) = 1
œÄ
Z ‚àû
‚àí‚àû
F(jœâ)
œÉ0
œÉ2
0 + (œâ ‚àíœâ0)2 dœâ.
Proof Construct the Nyquist contour D in the complex plane taking the radius, r, large enough
so that the point s0 is encircled by D.
Cauchy‚Äôs integral formula gives
F(s0) =
1
2œÄj
I
D
F(s)
s ‚àís0
ds.
Also, since ‚àís0 is not encircled by D, Cauchy‚Äôs theorem gives
0 =
1
2œÄj
I
D
F(s)
s + s0
ds.
Subtract these two equations to get
F(s0) =
1
2œÄj
I
D
F(s)
s0 + s0
(s ‚àís0)(s + s0)ds.
Thus
F(s0) = I1 + I2,
where
I1
:=
1
œÄ
Z r
‚àír
F(jœâ)
œÉ0
(s0 ‚àíjœâ)(s0 + jœâ)dœâ
=
1
œÄ
Z r
‚àír
F(jœâ)
œÉ0
œÉ2
0 + (œâ ‚àíœâ0)2 dœâ,
I2
:=
1
œÄj
Z œÄ/2
‚àíœÄ/2
F(rejŒ∏)
œÉ0
(rejŒ∏ ‚àís0)(rejŒ∏ + s0)rjejŒ∏dŒ∏.
As r ‚Üí‚àû
I1 ‚Üí1
œÄ
Z ‚àû
‚àí‚àû
F(jœâ)
œÉ0
œÉ2
0 + (œâ ‚àíœâ0)2 dœâ.
So it remains to show that I2 ‚Üí0 as r ‚Üí‚àû.
We have
I2 ‚â§œÉ0
œÄ ‚à•F‚à•‚àû
1
r
Z œÄ/2
‚àíœÄ/2
1
|ejŒ∏ ‚àís0r‚àí1||ejŒ∏ + s0r‚àí1|dŒ∏.
The integral
Z œÄ/2
‚àíœÄ/2
1
|ejŒ∏ ‚àís0r‚àí1||ejŒ∏ + s0r‚àí1|dŒ∏
converges as r ‚Üí‚àû. Thus
I2 ‚â§constant √ó 1
r ,
which gives the desired result. ‚ñ†

90
CHAPTER 6. DESIGN CONSTRAINTS
Bounds on the Weights W1 and W2
Suppose that the loop transfer function L has a zero z in Res ‚â•0. Then
‚à•W1S‚à•‚àû‚â•|W1(z)|.
(6.3)
This is a direct consequence of the maximum modulus theorem and (6.1):
|W1(z)| = |W1(z)S(z)| ‚â§sup
Res‚â•0
|W1(s)S(s)| = ‚à•W1S‚à•‚àû.
So a necessary condition that the performance criterion ‚à•W1S‚à•‚àû< 1 be achievable is that the
weight satisfy |W1(z)| < 1. In words, the magnitude of the weight at a right half-plane zero of P or
C must be less than 1.
Similarly, suppose that L has a pole p in Res ‚â•0. Then
‚à•W2T‚à•‚àû‚â•|W2(p)|,
(6.4)
so a necessary condition for the robust stability criterion ‚à•W2T‚à•‚àû< 1 is that the weight W2 satisfy
|W2(p)| < 1.
All-Pass and Minimum-Phase Transfer Functions
Two types of transfer functions play a critical role in the rest of this book: all-pass and minimum-
phase. A function in S is all-pass if its magnitude equals 1 at all points on the imaginary axis.
The terminology comes from the fact that a Ô¨Ålter with an all-pass transfer function passes without
attenuation input sinusoids of all frequencies. It is not diÔ¨Écult to show that such a function has
pole-zero symmetry about the imaginary axis in the sense that a point s0 is a zero iÔ¨Äits reÔ¨Çection,
‚àís0, is a pole. Consequently, the function being stable, all its zeros lie in the right half-plane. Thus
an all-pass function is, up to sign, the product of factors of the form
s ‚àís0
s + s0
,
Res0 > 0.
Examples of all-pass functions are
1,
s ‚àí1
s + 1,
s2 ‚àís + 2
s2 + s + 2.
A function in S is minimum-phase if it has no zeros in Res > 0. This terminology can be
explained as follows. Let G be a minimum-phase transfer function. There are many other transfer
functions having the same magnitude as G, for example FG where F is all-pass. But all these other
transfer functions have greater phase. Thus, of all the transfer functions having Gs magnitude, the
one with the minimum phase is G. Examples of minimum-phase functions are
1,
1
s + 1,
s
s + 1,
s + 2
s2 + s + 1.
It is a useful fact that every function in S can be written as the product of two such factors: for
example
4(s ‚àí2)
s2 + s + 1 =
s ‚àí2
s + 2
  4(s + 2)
s2 + s + 1

.

6.2. ANALYTIC CONSTRAINTS
91
Lemma 2 For each function G in S there exist an all-pass function Gap and a minimum-phase
function Gmp such that G = GapGmp. The factors are unique up to sign.
Proof Let Gap be the product of all factors of the form
s ‚àís0
s + s0
,
where s0 ranges over all zeros of G in Res > 0, counting multiplicities, and then deÔ¨Åne
Gmp =
G
Gap
.
The proof of uniqueness is left as an exercise. ‚ñ†
For technical reasons we assume for the remainder of this section that L has no poles on the
imaginary axis. Factor the sensitivity function as
S = SapSmp.
Then Smp has no zeros on the imaginary axis (such zeros would be poles of L) and Smp is not
strictly proper (since S is not). Thus S‚àí1
mp ‚ààS.
As a simple example of the use of all-pass functions, suppose that P has a zero at z with z > 0, a
pole at p with p > 0; also, suppose that C has neither poles nor zeros in the closed right half-plane.
Then
Sap(s) = s ‚àíp
s + p,
Tap(s) = s ‚àíz
s + z .
It follows from the preceding section that S(z) = 1, and hence
Smp(z) = Sap(z)‚àí1 = z + p
z ‚àíp.
Similarly,
Tmp(p) = Tap(p)‚àí1 = p + z
p ‚àíz .
Then
‚à•W1S‚à•‚àû= ‚à•W1Smp‚à•‚àû‚â•|W1(z)Smp(z)| =
W1(z)z + p
z ‚àíp

and
‚à•W2T‚à•‚àû‚â•
W2(p)p + z
p ‚àíz
 .
Thus, if there are a pole and zero close to each other in the right half-plane, they can greatly amplify
the eÔ¨Äect that either would have alone.

92
CHAPTER 6. DESIGN CONSTRAINTS
Example
These inequalities are eÔ¨Äectively illustrated with the cart-pendulum example of Sec-
tion 5.7. Let P(s) be the u-to-x transfer function for the up position of the pendulum, that is,
P(s) =
ls2 ‚àíg
s2[Mls2 ‚àí(M + m)g].
DeÔ¨Åne the ratio r := m/M of pendulum mass to cart mass. The zero and pole of P in Res > 0 are
z =
rg
l ,
p = z
‚àö
1 + r.
Note that for r Ô¨Åxed, a larger value of l means a smaller value of p, and this in turn means that
the system is easier to stabilize (the time constant is slower). The foregoing two inequalities on
‚à•W1S‚à•‚àûand ‚à•W2T‚à•‚àûapply. Since the cart-pendulum is a stabilization task, let us focus on
‚à•W2T‚à•‚àû‚â•
W2(p)p + z
p ‚àíz
 .
(6.5)
The robust stabilization problem becomes harder the larger the value of the right-hand side of
(6.5). The scaling factor in this inequality is
p + z
p ‚àíz =
‚àö1 + r + 1
‚àö1 + r ‚àí1.
(6.6)
This quantity is always greater than 1, and it approaches 1 only when r approaches ‚àû, that is, only
when the pendulum mass is much larger than the cart mass. There is a tradeoÔ¨Ä, however, in that a
large value of r means a large value of p, the unstable pole; for a typical W2 (high-pass) this in turn
means a relatively large value of |W2(p)| in (6.5). So at least for small uncertainty, the worst-case
scenario is a short pendulum with a small mass m relative to the cart mass M.
In contrast, the u-to-y transfer function has no zeros, so the constraint there is simply
‚à•W2T‚à•‚àû‚â•|W2(p)| .
If robust stabilization were the only objective, we could achieve equality by careful selection of
the controller. Note that for this case there is no apparent tradeoÔ¨Äin making m/M large. The
diÔ¨Äerence between the two cases, measuring x and measuring y, again highlights the important fact
that sensor location can have a signiÔ¨Åcant eÔ¨Äect on the diÔ¨Éculty of controlling a system or on the
ultimate achievable performance.
Some simple experiments can be done to illustrate the points made in this example. Obtain
several sticks of various lengths and try to balance them in the palm of your hand. You will notice
that it is easier to balance longer sticks, because the dynamics are slower and p above is smaller. It
is also easier to balance the sticks if you look at the top of the stick (measuring y) rather than at
the bottom (measuring x). In fact, even for a stick that is easily balanced when looking at the top,
it will be impossible to balance it while looking only at the bottom. There is also feedback from
the forces that your hand feels, but this is similar to measuring x.
The interested reader may repeat the analysis for the down position of the pendulum. At this
point it is useful to include the following lemma which will be used subsequently.

6.2. ANALYTIC CONSTRAINTS
93
Lemma 3 For every point s0 = œÉ0 + jœâ0 with œÉ0 > 0,
log |Smp(s0)| = 1
œÄ
Z ‚àû
‚àí‚àû
log |S(jœâ)|
œÉ0
œÉ2
0 + (œâ ‚àíœâ0)2 dœâ.
Proof Set F(s) := ln Smp(s). Then F is analytic and of bounded magnitude in Res ‚â•0. (This
follows from the properties Smp, S‚àí1
mp ‚ààS; the idea is that since Smp has no poles or zeros in the
right half-plane, ln Smp is well-behaved there.) Apply Lemma 1 to get
F(s0) = 1
œÄ
Z ‚àû
‚àí‚àû
F(jœâ)
œÉ0
œÉ2
0 + (œâ ‚àíœâ0)2 dœâ.
Now take real parts of both sides:
ReF(s0) = 1
œÄ
Z ‚àû
‚àí‚àû
ReF(jœâ)
œÉ0
œÉ2
0 + (œâ ‚àíœâ0)2 dœâ.
(6.7)
But
Smp = eF = eReFejImF ,
so
|Smp| = eReF ,
that is,
ln |Smp| = ReF.
Thus from (6.7)
ln |Smp(s0)| = 1
œÄ
Z ‚àû
‚àí‚àû
ln |Smp(jœâ)|
œÉ0
œÉ2
0 + (œâ ‚àíœâ0)2 dœâ,
or since |S| = |Smp| on the imaginary axis,
ln |Smp(s0)| = 1
œÄ
Z ‚àû
‚àí‚àû
ln |S(jœâ)|
œÉ0
œÉ2
0 + (œâ ‚àíœâ0)2 dœâ.
Finally, since log x = log e ln x, the result follows upon multiplying the last equation by log e. ‚ñ†
The Waterbed EÔ¨Äect
Consider a tracking problem where the reference signals have their energy spectra concentrated in
a known frequency range, say [œâ1, œâ2]. This is the idealized situation where W1 is a bandpass Ô¨Ålter.
Let M1 denote the maximum magnitude of S on this frequency band,
M1 :=
max
œâ1‚â§œâ‚â§œâ2 |S(jœâ)|,
and let M2 denote the maximum magnitude over all frequencies, that is, ‚à•S‚à•‚àû. Then good tracking
capability is characterized by the inequality M1 ‚â™1. On the other hand, we cannot permit M2

94
CHAPTER 6. DESIGN CONSTRAINTS
to be too large: Remember (Section 4.2) that 1/M2 equals the distance from the critical point to
the Nyquist plot of L, so large M2 means small stability margin (a typical upper bound for M2
is 2). Notice that M2 must be at least 1 because this is the value of S at inÔ¨Ånite frequency. So
the question arises: Can we have M1 very small and M2 not too large? Or does it happen that
very small M1 necessarily means very large M2?
The latter situation might be compared to a
waterbed: As |S| is pushed down on one frequency range, it pops up somewhere else. It turns out
that non-minimum-phase plants exhibit the waterbed eÔ¨Äect.
Theorem 1 Suppose that P has a zero at z with Rez > 0. Then there exist positive constants c1
and c2, depending only on œâ1, œâ2, and z, such that
c1 log M1 + c2 log M2 ‚â•log |Sap(z)‚àí1| ‚â•0.
Proof
Since z is a zero of P, it follows from the preceding section that S(z) = 1, and hence
Smp(z) = Sap(z)‚àí1. Apply Lemma 3 with
s0 = z = œÉ0 + jœâ0
to get
log |Sap(z)‚àí1| = 1
œÄ
Z ‚àû
‚àí‚àû
log |S(jœâ)|
œÉ0
œÉ2
0 + (œâ ‚àíœâ0)2 dœâ.
Thus
log |Sap(z)‚àí1| ‚â§c1 log M1 + c2 log M2,
where c1 is deÔ¨Åned to be the integral of
1
œÄ
œÉ0
œÉ2
0 + (œâ ‚àíœâ0)2
over the set
[‚àíœâ2, ‚àíœâ1] ‚à™[œâ1, œâ2]
and c2 equals the same integral but over the complementary set.
It remains to observe that |Sap(z)| ‚â§1 by the maximum modulus theorem, so
log |Sap(z)‚àí1| ‚â•0. ‚ñ†
Example As an illustration of the theorem consider the plant transfer function
P(s) =
s ‚àí1
(s + 1)(s ‚àíp),
where p > 0, p Ã∏= 1. As observed in the preceding section, S must interpolate zero at the unstable
poles of P, so S(p) = 0. Thus the all-pass factor of S must contain the factor
s ‚àíp
s + p.

6.2. ANALYTIC CONSTRAINTS
95
that is,
Sap(s) = s ‚àíp
s + pG(s)
for some all-pass function G. Since |G(1)| ‚â§1 (maximum modulus theorem), there follows
|Sap(1)| ‚â§

1 ‚àíp
1 + p
 .
So the theorem gives
c1 log M1 + c2 log M2 ‚â•log

1 + p
1 ‚àíp
 .
Note that the right-hand side is very large if p is close to 1. This example illustrates again a general
fact: The waterbed eÔ¨Äect is ampliÔ¨Åed if the plant has a pole and a zero close together in the right
half-plane. We would expect such a plant to be very diÔ¨Écult to control.
It is emphasized that the waterbed eÔ¨Äect applies to non-minimum-phase plants only. In fact,
the following can be proved (Section 10.1): If P has no zeros in Res > 0 nor on the imaginary axis
in the frequency range [œâ1, œâ2], then for every «´ > 0 and Œ¥ > 1 there exists a controller C so that
the feedback system is internally stable, M1 < «´, and M2 < Œ¥. As a very easy example, take
P(s) =
1
s + 1.
The controller C(s) = k is internally stabilizing for all k > 0, and then
S(s) =
s + 1
s + 1 + k.
So ‚à•S‚à•‚àû= 1 and, for every «´ > 0 and œâ2, if k is large enough, then
|S(jœâ)| < «´,
‚àÄœâ ‚â§œâ2.
The Area Formula
Herein is derived a formula for the area bounded by the graph of |S(jœâ)| (log scale) plotted as a
function of œâ (linear scale). The formula is valid when the relative degree of L is large enough.
Relative degree equals degree of denominator minus degree of numerator.
Let {pi} denote the set of poles of L in Res > 0.
Theorem 2 Assume that the relative degree of L is at least 2. Then
Z ‚àû
0
log |S(jœâ)|dœâ = œÄ(log e)(
X
Repi).
Proof In Lemma 3 take œâ0 = 0 to get
log |Smp(œÉ0)| = 1
œÄ
Z ‚àû
‚àí‚àû
log |S(jœâ)|
œÉ0
œÉ2
0 + œâ2 dœâ,

96
CHAPTER 6. DESIGN CONSTRAINTS
or equivalently,
Z ‚àû
0
log |S(jœâ)|
œÉ0
œÉ2
0 + œâ2 dœâ = œÄ
2 log |Smp(œÉ0)|.
Multiply by œÉ0:
Z ‚àû
0
log |S(jœâ)|
œÉ2
0
œÉ2
0 + œâ2 dœâ = œÄ
2 œÉ0 log |Smp(œÉ0)|.
It can be shown that the left-hand side converges to
Z ‚àû
0
log |S(jœâ)|dœâ
as œÉ0 ‚Üí‚àû. [The idea is that for very large œÉ0 the function
œÉ2
0
œÉ2
0 + œâ2
equals nearly 1 up to large values of œâ. On the other hand, log |S(jœâ)| tends to zero as œâ tends to
‚àû.] So it remains to show that
lim
œÉ‚Üí‚àû
œÉ
2 log |Smp(œÉ)| = (log e)(
X
Repi).
(6.8)
We can write
S = SapSmp,
where
Sap(s) =
Y
i
s ‚àípi
s + pi
.
It is claimed that
lim
œÉ‚Üí‚àûœÉ ln S(œÉ) = 0.
To see this, note that since L has relative degree at least 2 we can write
L(œÉ) ‚âàc
œÉk as œÉ ‚Üí‚àû
for some constant c and some integer k ‚â•2. Thus as œÉ ‚Üí‚àû
œÉ ln S(œÉ) = ‚àíœÉ ln[1 + L(œÉ)] ‚âà‚àíœÉ ln

1 + c
œÉk

.
Now use the Maclaurin‚Äôs series
ln(1 + x) = x ‚àíx2
2 + ¬∑ ¬∑ ¬∑
(6.9)

6.2. ANALYTIC CONSTRAINTS
97
to get
œÉ ln S(œÉ) ‚âà‚àíœÉ
 c
œÉk ‚àí¬∑ ¬∑ ¬∑

.
The right-hand side converges to zero as œÉ tends to ‚àû. This proves the claim.
In view of the claim, to prove (6.8) it remains to show that
lim
œÉ‚Üí‚àû
œÉ
2 ln
[Sap(œÉ)‚àí1]
 =
X
Repi.
(6.10)
Now
ln(Sap(œÉ)‚àí1) = ln
Y
i
œÉ + pi
œÉ ‚àípi
=
X
i
ln œÉ + pi
œÉ ‚àípi
,
so to prove (6.10) it suÔ¨Éces to prove
lim
œÉ‚Üí‚àû
œÉ
2 ln

œÉ + pi
œÉ ‚àípi
 = Repi.
(6.11)
Let pi = x + jy and use (6.9) again as follows:
œÉ
2 ln

œÉ + pi
œÉ ‚àípi

=
œÉ
2 ln

1 + piœÉ‚àí1
1 ‚àípiœÉ‚àí1

=
œÉ
4 ln (1 + xœÉ‚àí1)2 + (yœÉ‚àí1)2
(1 ‚àíxœÉ‚àí1)2 + (yœÉ‚àí1)2
=
œÉ
4

ln[(1 + xœÉ‚àí1)2 + (yœÉ‚àí1)2] ‚àíln[(1 ‚àíxœÉ‚àí1)2 + (yœÉ‚àí1)2]
	
=
œÉ
4
n
2x
œÉ + 2x
œÉ + ¬∑ ¬∑ ¬∑
o
=
x + ¬∑ ¬∑ ¬∑
=
Repi + ¬∑ ¬∑ ¬∑ .
Letting œÉ ‚Üí‚àûgives (6.11). ‚ñ†
Example Take the plant and controller
P(s) =
1
(s ‚àí1)(s + 2),
C(s) = 10.
The feedback system is internally stable and L has relative degree 2. The plot of |S(jœâ)|, log scale,
versus œâ, linear scale, is shown in Figure 6.1.
The area below the line |S| = 1 is negative, the area
above, positive. The theorem says that the net area is positive, equaling
œÄ(log e)(
X
Repi) = œÄ(log e).
So the negative area, required for good tracking over some frequency range, must unavoidably be
accompanied by some positive area.
The waterbed eÔ¨Äect applies to non-minimum-phase systems, whereas the area formula applies
in general (except for the relative degree assumption). In particular, the area formula does not

98
CHAPTER 6. DESIGN CONSTRAINTS
10-1
100
101
0
1
2
3
4
5
6
7
8
9
10
+
-
Figure 6.1: |S(jœâ)|, log scale, versus œâ, linear scale.
itself imply a peaking phenomenon, only an area conservation. However, one can infer a type of
peaking phenomenon from the area formula when another constraint is imposed, namely, controller
bandwidth, or more precisely, the bandwidth of the loop transfer function PC. For example, suppose
that the constraint is
|PC| < 1
œâ2 ,
‚àÄœâ ‚â•œâ1,
where œâ1 > 1. This is one way of saying that the loop bandwidth is constrained to be ‚â§œâ1. Then
for œâ ‚â•œâ1
|S| ‚â§
1
1 ‚àí|PC| <
1
1 ‚àíœâ‚àí2 =
œâ2
œâ2 ‚àí1.
Hence
Z ‚àû
œâ1
log |S(jœâ)|dœâ ‚â§
Z ‚àû
œâ1
log
œâ2
œâ2 ‚àí1dœâ.

6.2. ANALYTIC CONSTRAINTS
99
The latter integral‚Äîdenote it by I‚Äîis Ô¨Ånite. This is proved by the following computation:
I
=
1
ln 10
Z ‚àû
œâ1
ln
1
1 ‚àíœâ‚àí2 dœâ
=
‚àí
1
ln 10
Z ‚àû
œâ1
ln(1 ‚àíœâ‚àí2)dœâ
=
1
ln 10
Z ‚àû
œâ1

œâ‚àí2 + 1
2œâ‚àí4 + 1
3œâ‚àí6 + ¬∑ ¬∑ ¬∑

dœâ
=
1
ln 10

œâ‚àí1
1
+
1
2 √ó 3œâ‚àí3
1
+
1
3 √ó 5œâ‚àí5
1
+ ¬∑ ¬∑ ¬∑

<
‚àû.
Hence the possible positive area over the interval [œâ1, ‚àû) is limited. Thus if |S| is made smaller and
smaller over some subinterval of [0, œâ1], incurring a larger and larger debt of negative area, then |S|
must necessarily become larger and larger somewhere else in [0, œâ1]. Roughly speaking, with a loop
bandwidth constraint the waterbed eÔ¨Äect applies even to minimum-phase plants.
Exercises
1. Prove the statement about uniqueness in Lemma 2.
2. True or false: For every Œ¥ > 1 there exists an internally stabilizing controller such that
‚à•T‚à•‚àû< Œ¥.
3. Regarding inequality (6.3), the implication is that good tracking is impossible if P has a right
half-plane zero where |W1| is not small. This problem is an attempt to see this phenomenon
more precisely by studying |W1(z)| as a function of z for a typical weighting function. Take
W1 to be a third-order Butterworth Ô¨Ålter with cutoÔ¨Äfrequency 1 rad/s. Plot
|W1(0.1 + jœâ)| versus œâ
for œâ going from 0 up to where |W1| < 0.01. Repeat for abscissae of 1 and 10.
4. Let
P(s) = 4 s ‚àí2
(s + 1)2 .
Suppose that C is an internally stabilizing controller such that
‚à•S‚à•‚àû= 1.5.
Give a positive lower bound for
max
0‚â§œâ‚â§0.1 |S(jœâ)|.
5. DeÔ¨Åne «´ := ‚à•W1S‚à•‚àûand Œ¥ := ‚à•CS‚à•‚àû. So «´ is a measure of tracking performance, while
Œ¥ measures control eÔ¨Äort; note that CS equals the transfer function from reference input r

100
CHAPTER 6. DESIGN CONSTRAINTS
to plant input. In a design we would like «´ < 1 and Œ¥ not too large. Derive the following
inequality, showing that «´ and Œ¥ cannot both be very small in general: For every point s0 with
Res0 ‚â•0,
|W1(s0)| ‚â§«´ + |W1(s0)P(s0)|Œ¥.
6. Let œâ be a frequency such that jœâ is not a pole of P. Suppose that
«´ := |S(jœâ)| < 1.
Derive a lower bound for |C(jœâ)| that blows up as «´ ‚Üí0. Conclusion: Good tracking at a
particular frequency requires large controller gain at this frequency.
7. Suppose that the plant transfer function is
P(s) =
1
s2 ‚àís + 4.
We want the controller C to achieve the following:
internal stability,
|S(jœâ)| ‚â§«´ for 0 ‚â§œâ < 0.1,
|S(jœâ)| ‚â§2 for 0.1 ‚â§œâ < 5,
|S(jœâ)| ‚â§1 for 5 ‚â§œâ < ‚àû.
Find a (positive) lower bound on the achievable «´.
Notes and References
This chapter is in the spirit of Bode‚Äôs book (Bode, 1945) on feedback ampliÔ¨Åers. Bode showed
that electronic ampliÔ¨Åers must have certain inherent properties simply by virtue of the fact that
stable network functions are analytic, and hence have certain strong properties. Bode‚Äôs work was
generalized to control systems by Bower and Schultheiss (1961) and Horowitz (1963).
The interpolation conditions (6.1) and (6.2) were obtained by Raggazini and Franklin (1958).
These constraints on S and T are essentially equivalent to the controller parametrization in Theo-
rem 5.2. Inequality (6.3) was noted, for example, by Zames and Francis (1983). The waterbed eÔ¨Äect,
Theorem 1, was proved by Francis and Zames (1984), but the derivation here is due to Freudenberg
and Looze (1985). The area formula, Theorem 2, was proved by Bode (1945) in case L is stable,
and by Freudenberg and Looze (1985) in the general case. An excellent discussion of performance
limitations may be found in Freudenberg and Looze (1988).

Chapter 7
Loopshaping
This chapter presents a graphical technique for designing a controller to achieve robust performance
for a plant that is stable and minimum-phase.
7.1
The Basic Technique of Loopshaping
Recall from Section 4.3 that the robust performance problem is to design a proper controller C so
that the feedback system for the nominal plant is internally stable and the inequality
‚à•|W1S| + |W2T|‚à•‚àû< 1
(7.1)
is satisÔ¨Åed. Thus the problem input data are P, W1, and W2; a solution of the problem is a controller
C achieving robust performance.
We saw in Chapter 6 that the robust performance problem is not always solvable‚Äîthe tracking
objective may be too stringent for the nominal plant and its associated uncertainty model. Un-
fortunately, constructive (necessary and suÔ¨Écient) conditions on P, W1, and W2 for the robust
performance problem to be solvable are unknown.
In this chapter we look at a graphical method that is likely to provide a solution when one exists.
The idea is to construct the loop transfer function L to achieve (7.1) approximately, and then to get
C via C = L/P. The underlying constraints are internal stability of the nominal feedback system
and properness of C, so that L is not freely assignable. When P or P ‚àí1 is not stable, L must
contain P‚Äôs unstable poles and zeros (Theorem 3.2), an awkward constraint. For this reason, we
assume in this chapter that P and P ‚àí1 are both stable.
In terms of W1, W2, and L the robust performance inequality is
Œì(jœâ) :=

W1(jœâ)
1 + L(jœâ)
 +

W2(jœâ)L(jœâ)
1 + L(jœâ)
 < 1.
(7.2)
This must hold for all œâ. The idea in loopshaping is to get conditions on L for (7.2) to hold, at
least approximately. It is convenient to drop the argument jœâ.
We are interested in alternative conditions under which (7.2) holds. Recall from Section 6.1 that
a necessary condition is
min{|W1|, |W2|} < 1,
101

102
CHAPTER 7. LOOPSHAPING
so we will assume this throughout. Thus at each frequency, either |W1| < 1 or |W2| < 1. We will
consider these two cases separately and derive conditions comparable to (7.2).
We begin by noting the following inequalities, which follow from the deÔ¨Ånition of Œì:
(|W1| ‚àí|W2|)|S| + |W2| ‚â§Œì ‚â§(|W1| + |W2|)|S| + |W2|,
(7.3)
(|W2| ‚àí|W1|)|T| + |W1| ‚â§Œì ‚â§(|W2| + |W1|)|T| + |W1|,
(7.4)
|W1| + |W2L|
1 + |L|
‚â§Œì ‚â§|W1| + |W2L|
|1 ‚àí|L||
.
(7.5)
‚Ä¢ Suppose that |W2| < 1. Then from (7.3)
Œì < 1
‚áê=
|W1| + |W2|
1 ‚àí|W2|
|S| < 1,
(7.6)
Œì < 1
=‚áí
|W1| ‚àí|W2|
1 ‚àí|W2|
|S| < 1.
(7.7)
Or, in terms of L, from (7.5)
Œì < 1
‚áê=
|L| > |W1| + 1
1 ‚àí|W2|,
(7.8)
Œì < 1
=‚áí
|L| > |W1| ‚àí1
1 ‚àí|W2|.
(7.9)
When |W1| ‚â´1, the conditions on the right-hand sides of (7.6) and (7.7) approach each other,
as do those in (7.8) and (7.9), and we may approximate the condition Œì < 1 by
|W1|
1 ‚àí|W2||S| < 1
(7.10)
or
|L| >
|W1|
1 ‚àí|W2|.
(7.11)
Notice that (7.10) is like the nominal performance condition |W1S| < 1 except that the
weight W1 is increased by dividing it by 1‚àí|W2|: Robust performance is achieved by nominal
performance with a larger weight.
‚Ä¢ Now suppose that |W1| < 1. We may proceed similarly to obtain from (7.4)
Œì < 1
‚áê=
|W2| + |W1|
1 ‚àí|W1|
|T| < 1,
Œì < 1
=‚áí
|W2| ‚àí|W1|
1 ‚àí|W1|
|T| < 1

7.1. THE BASIC TECHNIQUE OF LOOPSHAPING
103
or from (7.5)
Œì < 1
‚áê=
|L| < 1 ‚àí|W1|
|W2| + 1,
Œì < 1
=‚áí
|L| < 1 ‚àí|W1|
|W2| ‚àí1.
When |W2| ‚â´1, we may approximate the condition Œì < 1 by
|W2|
1 ‚àí|W1||T| < 1
(7.12)
or
|L| < 1 ‚àí|W1|
|W2|
.
(7.13)
Inequality (7.12) says that robust performance is achieved by robust stability with a larger
weight.
The discussion above is summarized as follows:
|W1| ‚â´1 > |W2|
|L| >
|W1|
1 ‚àí|W2|
|W1| < 1 ‚â™|W2|
|L| < 1 ‚àí|W1|
|W2|
For example, the Ô¨Årst row says that over frequencies where |W1| ‚â´1 > |W2| the loopshape should
satisfy
|L| >
|W1|
1 ‚àí|W2|.
Let‚Äôs take the typical situation where |W1(jœâ)| is a decreasing function of œâ and |W2(jœâ)| is an
increasing function of œâ. Typically, at low frequency
|W1| > 1 > |W2|
and at high frequency
|W1| < 1 < |W2|.
A loopshaping design goes very roughly like this:
1. Plot two curves on log-log scale, magnitude versus frequency: Ô¨Årst, the graph of
|W1|
1 ‚àí|W2|
over the low-frequency range where |W1| > 1 > |W2|; second, the graph of
1 ‚àí|W1|
|W2|
over the high-frequency range where |W1| < 1 < |W2|.

104
CHAPTER 7. LOOPSHAPING
2. On this plot Ô¨Åt another curve which is going to be the graph of |L|: At low frequency let it lie
above the Ô¨Årst curve and also be ‚â´1; at high frequency let it lie below the second curve and
also be ‚â™1; at very high frequency let it roll oÔ¨Äat least as fast as does |P| (so C is proper);
do a smooth transition from low to high frequency, keeping the slope as gentle as possible
near crossover, the frequency where the magnitude equals 1 (the reason for this is described
below).
3. Get a stable, minimum-phase transfer function L whose Bode magnitude plot is the curve just
constructed, normalizing so that L(0) > 0.
Typical curves are as in Figure 7.1.
Such a curve for |L| will satisfy (7.11) and (7.13), and hence
10-3
10-2
10-1
100
101
102
103
10-2
10-1
100
101
102
103
104
Figure 7.1: Bode plots of |L| (solid), |W1|/(1 ‚àí|W2|) (dash), and (1 ‚àí|W1|)/|W2| (dot).
(7.2) at low and high frequencies. But (7.2) will not necessarily hold at intermediate frequencies.
Even worse, L may not result in nominal internal stability. If L(0) > 0 and |L| is as just pictured
(i.e., a decreasing function), then the angle of L starts out at zero and decreases (this follows from
the phase formula to be derived in the next section). So the Nyquist plot of L starts out on the
positive real axis and begins to move clockwise. By the Nyquist criterion, nominal internal stability
will hold iÔ¨Äthe angle of L at crossover is greater than 180‚ó¶(i.e., crossover occurs in the third or
fourth quadrant). But the greater the slope of |L| near crossover, the smaller the angle of L (proved
in the next section).
So internal instability is unavoidable if |L| drops oÔ¨Ätoo rapidly through
crossover, and hence in our loopshaping we must maintain a gentle slope; a rule of thumb is that
the magnitude of the slope should not be more than 2. After doing the three steps above we must
validate the design by checking that internal stability and (7.2) both hold. If not, we must go back
and try again. Loopshaping therefore is a craft requiring experience for mastery.

7.2. THE PHASE FORMULA (OPTIONAL)
105
7.2
The Phase Formula (Optional)
It is a fundamental fact that if L is stable and minimum-phase and normalized so that L(0) > 0,
then its magnitude Bode plot uniquely determines its phase plot. The normalization is necessary,
for
1
s + 1 and
‚àí1
s + 1
are stable, minimum-phase, and have the same magnitude plot, but they have diÔ¨Äerent phase plots.
Our goal in this section is a formula for ‚à†L in terms of |L|.
Assume that L is proper, L and L‚àí1 are analytic in Res ‚â•0, and L(0) > 0. DeÔ¨Åne G := ln L.
Then
ReG = ln |L|,
ImG = ‚à†L,
and G has the following three properties:
1. G is analytic in some right half-plane containing the imaginary axis. Instead of a formal proof,
one way to see why this is true is to look at the derivative of G:
G‚Ä≤ = L‚Ä≤
L .
Since L is analytic in the right half-plane, so is L‚Ä≤. Then since L has no zeros in the right
half-plane, G‚Ä≤ exists at all points in the right half-plane, and hence at points a bit to the left
of the imaginary axis.
2. ReG(jœâ) is an even function of œâ and ImG(jœâ) is an odd function of œâ.
3. s‚àí1G(s) tends to zero uniformly on semicircles in the right half-plane as the radius tends to
inÔ¨Ånity, that is,
lim
R‚Üí‚àû
sup
‚àíœÄ/2‚â§Œ∏‚â§œÄ/2

G(RejŒ∏)
RejŒ∏
 = 0.
Proof Since
G(RejŒ∏) = ln |L(RejŒ∏)| + j‚à†L(RejŒ∏)
and ‚à†L(RejŒ∏) is bounded as R ‚Üí‚àû, we have

G(RejŒ∏)
RejŒ∏
 ‚Üí| ln |L(RejŒ∏)||
R
.
Now L is proper, so for some c and k ‚â•0,
L(s) ‚âàc
sk as |s| ‚Üí‚àû.

106
CHAPTER 7. LOOPSHAPING
Thus

G(RejŒ∏)
RejŒ∏

‚Üí
| ln |c/Rk||
R
=
| ln |c| ‚àík ln |R||
R
‚Üí
kln R
R
‚Üí
0. ‚ñ†
Next, we obtain an expression for the imaginary part of G in terms of its real part.
Lemma 1 For each frequency œâ0
Im G(jœâ0) = 2œâ0
œÄ
Z ‚àû
0
ReG(jœâ) ‚àíReG(jœâ0)
œâ2 ‚àíœâ2
0
dœâ.
Proof DeÔ¨Åne the function
F(s)
:=
G(s) ‚àíReG(jœâ0)
s ‚àíjœâ0
‚àíG(s) ‚àíReG(jœâ0)
s + jœâ0
=
2jœâ0
G(s) ‚àíReG(jœâ0)
s2 + œâ2
0
.
(7.14)
Then F is analytic in the right half-plane and on the imaginary axis, except for poles at ¬±jœâ0.
Bring in the usual Nyquist contour: Go up the imaginary axis, indenting to the right at the points
‚àíjœâ0 and jœâ0 along semicircles of radius r, then close the contour by a large semicircle of radius
R in the right half-plane. The integral of F around this contour equals zero (Cauchy‚Äôs theorem).
This integral equals the sum of six separate integrals corresponding to the three intervals on the
imaginary axis, the two smaller semicircles, and the larger semicircle. Let I1 denote the sum of
the three integrals along the intervals on the imaginary axis, I2 the integral around the lower small
semicircle, I3 around the upper small semicircle, and I4 around the large semicircle. We show that
lim
R‚Üí‚àû,r‚Üí0 I1
=
2œâ0
Z ‚àû
‚àí‚àû
ReG(jœâ) ‚àíReG(jœâ0)
œâ2 ‚àíœâ2
0
dœâ,
(7.15)
lim
r‚Üí0 I2
=
‚àíœÄIm G(jœâ0),
(7.16)
lim
r‚Üí0 I3
=
‚àíœÄIm G(jœâ0),
(7.17)
lim
R‚Üí‚àûI4
=
0.
(7.18)
The lemma follows immediately from these four equations and the fact that ReG(jœâ) is even.
First,
I1 =
Z
jF(jœâ)dœâ,
where the integral is over the set
[‚àíR, ‚àíœâ0 ‚àír] ‚à™[‚àíœâ0 + r, œâ0 ‚àír] ‚à™[œâ0 + r, R].
(7.19)

7.2. THE PHASE FORMULA (OPTIONAL)
107
As R ‚Üí‚àûand r ‚Üí0, this set becomes the interval (‚àí‚àû, ‚àû). Also, from (7.14)
jF(jœâ) = 2œâ0
G(jœâ) ‚àíReG(jœâ0)
œâ2 ‚àíœâ2
0
.
Since
Im G(jœâ)
œâ2 ‚àíœâ2
0
is an odd function, its integral over set (7.19) equals zero, and we therefore get (7.15).
Second,
I2
=
Z œÄ/2
‚àíœÄ/2
G(‚àíjœâ0 + rejŒ∏) ‚àíReG(jœâ0)
‚àíjœâ0 + rejŒ∏ ‚àíjœâ0
jrejŒ∏dŒ∏
‚àí
Z œÄ/2
‚àíœÄ/2
G(‚àíjœâ0 + rejŒ∏) ‚àíReG(jœâ0)
‚àíjœâ0 + rejŒ∏ + jœâ0
jrejŒ∏dŒ∏.
As r ‚Üí0, the Ô¨Årst integral tends to 0 while the second tends to
[G(‚àíjœâ0) ‚àíReG(jœâ0)]j
Z œÄ/2
‚àíœÄ/2
dŒ∏ = œÄIm G(jœâ0).
This proves (7.16). VeriÔ¨Åcation of (7.17) is similar.
Finally,
I4 = ‚àí
Z œÄ/2
‚àíœÄ/2
F(RejŒ∏)jRejŒ∏dŒ∏,
so
|I4| ‚â§
sup
‚àíœÄ
2 ‚â§Œ∏ ‚â§œÄ
2

2œâ0[G(RejŒ∏) ‚àíReG(jœâ0)]
(RejŒ∏)2 + œâ2
0
 RœÄ.
Thus
|I4| ‚Üí(const) sup
Œ∏
|G(RejŒ∏)|
R
‚Üí0.
This proves (7.18). ‚ñ†
Rewriting the formula in the lemma in terms of L we get
‚à†L(jœâ0) = 2œâ0
œÄ
Z ‚àû
0
ln |L(jœâ)| ‚àíln |L(jœâ0)|
œâ2 ‚àíœâ2
0
dœâ.
(7.20)
This is now manipulated to get the phase formula.
Theorem 1 For every frequency œâ0
‚à†L(jœâ0) = 1
œÄ
Z ‚àû
‚àí‚àû
d ln |L|
dŒΩ
ln coth |ŒΩ|
2 dŒΩ,
where the integration variable ŒΩ = ln(œâ/œâ0).

108
CHAPTER 7. LOOPSHAPING
Proof Change variables of integration in (7.20) to get
‚à†L(jœâ0) = 1
œÄ
Z ‚àû
‚àí‚àû
ln |L| ‚àíln |L(jœâ0)|
sinh ŒΩ
dŒΩ.
Note that in this integral ln |L| is really ln |L(jœâ0eŒΩ)| considered as a function of ŒΩ. Now integrate
by parts, from ‚àí‚àûto 0 and from 0 to ‚àû:
‚à†L(jœâ0)
=
‚àí1
œÄ
h
(ln |L| ‚àíln |L(jœâ0)|) ln coth ŒΩ
2
i‚àû
0
+ 1
œÄ
Z ‚àû
0
d ln |L|
dŒΩ
ln coth ŒΩ
2dŒΩ
+ 1
œÄ[(ln |L| ‚àíln |L(jœâ0)|) ln coth ‚àíŒΩ
2 ]‚àû
0
+ 1
œÄ
Z 0
‚àí‚àû
d ln |L|
dŒΩ
ln coth ‚àíŒΩ
2 dŒΩ.
The Ô¨Årst and third terms sum to zero. ‚ñ†
Example Suppose that ln |L| has constant slope,
d ln |L|
dŒΩ
= ‚àíc.
Then
‚à†L(jœâ0) = ‚àíc
œÄ
Z ‚àû
‚àí‚àû
ln coth |ŒΩ|
2 dŒΩ = ‚àícœÄ
2 ;
that is, the phase shift is constant at ‚àí90c degrees.
In the phase formula, the slope function d ln |L|/dŒΩ is weighted by the function
ln coth |ŒΩ|
2 = ln

œâ + œâ0
œâ ‚àíœâ0
 .
This function is symmetric about œâ = œâ0 (ln scale on the horizontal axis), positive, inÔ¨Ånite at
œâ = œâ0, increasing from œâ = 0 to œâ = œâ0, and decreasing from œâ = œâ0 to œâ = ‚àû. In this way, the
values of d ln |L|/dŒΩ are more heavily weighted near œâ = œâ0. We conclude, roughly speaking, that
the steeper the graph of |L| near the frequency œâ0, the smaller the value of ‚à†L.
7.3
Examples
This section presents three simple examples of loopshaping.
Example 1 In principle the only information we need to know about P right now is its relative
degree, degree of denominator minus degree of numerator. This determines the high-frequency slope
on its Bode magnitude plot. We have to let L have at least equal relative degree or else C will not
be proper. Assume that the relative degree of P equals 1. The actual plant transfer function enters
into the picture only at the very end when we get C from L via C = L/P.

7.3. EXAMPLES
109
Take the weighting function W2 to be
W2(s) =
s + 1
20(0.01s + 1).
See Figure 7.2 for the Bode magnitude plot. Remember (Section 4.2) that |W2(jœâ)| is an upper
bound on the magnitude of the relative plant perturbation at frequency œâ. For this example, |W2|
starts at 0.05 and increases monotonically up to 5, crossing 1 at 20 rad/s.
Let the performance objective be to track sinusoidal reference signals over the frequency range
from 0 to 1 rad/s. Let‚Äôs not say at the start what maximum tracking error we will tolerate; rather,
let‚Äôs see what tracking error is incurred for a couple of loopshapes. Ideally, we would take W1
to have constant magnitude over the frequency range [0, 1] and zero magnitude beyond. Such a
magnitude characteristic cannot come from a rational function. Nevertheless, you can check that
Theorem 4.2 continues to be valid for such W1; that is, if the nominal feedback system is internally
stable, then
‚à•W2T‚à•‚àû< 1 and

W1S
1 + ‚àÜW2T

‚àû
< 1,
‚àÄ‚àÜ
iÔ¨Ä
‚à•|W1S| + |W2T|‚à•‚àû< 1.
With this justiÔ¨Åcation, we can take
|W1(jœâ)| =
 a,
if 0 ‚â§œâ ‚â§1
0,
else,
where a is as yet unspeciÔ¨Åed.
Let‚Äôs Ô¨Årst try a Ô¨Årst-order, low-pass loop transfer function, that is, of the form
L(s) =
b
cs + 1.
It is reasonable to take c = 1 so that |L| starts rolling oÔ¨Änear the upper end of the operating band
[0, 1]. We want b as large as possible for good tracking. The largest value of b so that
|L| ‚â§1 ‚àí|W1|
|W2|
=
1
|W2|,
œâ ‚â•20
is 20. So we have
L(s) =
20
s + 1.
See Figure 7.2. For this L the nominal feedback system is internally stable.
It remains to check what robust performance level we have achieved. For this we choose the
largest value of a so that
|L| ‚â•
a
1 ‚àí|W2|,
œâ ‚â§1.

110
CHAPTER 7. LOOPSHAPING
The function
a
1 ‚àí|W2(jœâ)|
is increasing over the range [0, 1], while |L(jœâ)| is decreasing. So a can be got by solving
|L(j1)| =
a
1 ‚àí|W2(j1)|.
This gives a = 13.15.
Now to verify robust performance, graph the function
|W1(jœâ)S(jœâ)| + |W2(jœâ)T(jœâ)|
(Figure 7.2).
Its maximum value is about 0.92.
Since this is less than 1, robust performance
is veriÔ¨Åed. (We could also have determined as in Section 4.3 the largest a for which the robust
performance condition holds.)
Let‚Äôs recap. For the performance weight
|W1(jœâ)| =
 13.15,
if 0 ‚â§œâ ‚â§1
0,
else,
we can take L(s) = 20/(s+1) to achieve robust performance. The tracking error is then ‚â§1/13.15 =
7.6%.
10-2
10-1
100
101
102
10-2
10-1
100
101
102
103
Figure 7.2: Bode plots of |L| (solid), |W2| (dash), and |W1S| + |W2T| (dot).
Suppose that a 7.6% tracking error is too large. To reduce the error make |L| larger over the
frequency range [0, 1]. For example, we could try
L(s) = s + 10
s + 1
20
s + 1.

7.3. EXAMPLES
111
The new factor, (s + 10)/(s + 1), has magnitude nearly 10 over [0, 1] and rolls oÔ¨Äto about 1 above
10 rad/s. See Figure 7.3. Again, the nominal feedback system is internally stable. If we take W1
as before and compute a again we get a = 93.46. The robust performance inequality is checked
graphically (Figure 7.3). Now the tracking error is ‚â§1/93.46 = 1.07%.
10-2
10-1
100
101
102
103
10-2
10-1
100
101
102
103
Figure 7.3: Bode plots of |L| (solid), |W2| (dash), and |W1S| + |W2T| (dot).
The problem above is quite easy because |W2| is small on the operating band [0, 1]; the require-
ments of performance and robust stability are only weakly competitive.
Example 2 This example examines the pitch rate control of an aircraft. The signals are
r pitch rate command (by pilot)
u elevator deÔ¨Çection
y pitch rate of the aircraft
Suppose that the Ô¨Årst approximation of the plant is
P(s) =
s + 1
s2 + 2 √ó 0.7 √ó 5s + 52 .
This would model the rigid motion of the aircraft (i.e., ignoring bending). The natural frequency
is 5 rad/s and the damping ratio 0.7.
Again, rather than specify a performance weight W1, common practice is to specify a desired
loopshape. The simplest decent loop transfer function is
L(s) = œâc
s ,

112
CHAPTER 7. LOOPSHAPING
where œâc, a positive constant, is the crossover frequency, where |L| = 1. The loopshape |L(jœâ)|
versus œâ is a straight line (log-log scale) of slope -1.
This is the simplest loopshape having the following features:
1. Good tracking and disturbance rejection (i.e., |S| small) at low frequency.
2. Good robustness (i.e., |T| small) at high frequency.
3. Internal stability.
In principle, the larger œâc, the better the performance, for then |S| is smaller over a wider frequency
range; note that
S(s) =
s
s + œâc
.
For such L with œâc = 10, the controller is
C(s) = 10s2 + 2 √ó 0.7 √ó s + 52
s(s + 1)
.
In actuality, there is a limitation on how large œâc can be because of high-frequency uncertainty:
remember that we modeled only the rigid body, whereas the actual aircraft is Ô¨Çexible and has
bending modes just as a Ô¨Çexible beam has. Suppose that the Ô¨Årst bending mode (the fundamental)
is known to be at approximately 45 rad/s. If we included this mode in the transfer function P,
there would be a pole in the left half-plane near the point s = 45j on the imaginary axis. This
would mean in turn that |P(jœâ)| would be relatively large around œâ = 45. For the controller above,
the loopshape could then take the form in Figure 7.4.
Since the magnitude is greater than 1 at 45
rad/s, the feedback system is potentially unstable, depending on the phase at 45 rad/s.
The typical way to accommodate such uncertainty is to ensure for the nominal plant model
that |L| is suÔ¨Éciently small, starting at the frequency where appreciable uncertainty begins. For
example, we might demand that
|L(jœâ)| ‚â§0.5,
‚àÄœâ ‚â•45.
(We have implicitly just deÔ¨Åned a weight W2.) The largest value of œâc satisfying this condition is
œâc = 45/2.
Example 3 Consider the plant transfer function
P(s) =
s + 1
s2 + 2 √ó 0.7 √ó 5s + 52
s2 + 2 √ó 0.05 √ó 30s + 302
s2 + 2 √ó 0.01 √ó 45s + 452 .
This is an extension of the model of Example 2, with the Ô¨Årst bending mode at 45 rad/s included.
This mode is very lightly damped, with damping ratio 0.01. This frequency and damping ratio will
have associated uncertainty, typically 2 to 3%. Also included in P is an additional pair of lightly
damped zeros. The magnitude Bode plot of P is in Figure 7.5.
Suppose that the desired loop
transfer function is again L(s) = œâc/s. This would require that C = L/P have the factor
s2 + 2 √ó 0.01 √ó 45s + 452

7.3. EXAMPLES
113
10-2
10-1
100
101
102
10-1
100
101
102
Figure 7.4: Loopshape, Example 2.
10-4
10-3
10-2
10-1
100
10-1
100
101
102
103
104
Figure 7.5: Bode plot of |P|, Example 3.

114
CHAPTER 7. LOOPSHAPING
in its numerator, that is, C would be like a notch Ô¨Ålter with a very deep notch. But since, as stated
above, the numbers 45 and 0.01 are uncertain, a more prudent approach is to have a shallower notch
by setting L to be, say,
L(s) = œâc
s
s2 + 2 √ó 0.03 √ó 45s + 452
s2 + 2 √ó 0.01 √ó 45s + 452 .
With the same rationale as in Example 2, we now maximize œâc such that
|L(jœâ)| ‚â§0.5,
‚àÄœâ ‚â•45.
This yields œâc ‚âà8 and the loopshape in Figure 7.6.
The controller is
10-2
10-1
100
101
102
Figure 7.6: Loopshape, Example 3.
C(s) = 8s2 + 2 √ó 0.7 √ó 5s + 52
s(s + 1)
s2 + 2 √ó 0.03 √ó 45s + 452
s2 + 2 √ó 0.05 √ó 30s + 302 .
Exercises
1. This problem concerns the plant in Example 2 in Section 4.1‚Äîthe double integrator with an
uncertain time delay. Take
P(s) =
1
(s + 0.01)2 .
(This is supposed to be a stable approximation to the double integrator.) The time delay was
accommodated by embedding the plant in a multiplicative perturbation with weight
W2(s) =
0.1s
0.05s + 1.

7.3. EXAMPLES
115
To get good tracking over the frequency range [0, 1], a typical choice for W1 would be a
Butterworth Ô¨Ålter with cutoÔ¨Äof 1 rad/s. To get at most 10% tracking error on the operating
band, we would take the gain of the Ô¨Ålter to be 10. A third-order such Ô¨Ålter is
W1(s) =
10
s3 + 2s2 + 2s + 1.
For these data, design a controller to achieve robust performance.
2. Repeat the design in Example 1, Section 7.3, but with
W2(s) =
10s + 1
20(0.01s + 1).
This is more diÔ¨Écult because |W2| is fairly substantial on the operating band.
See what
performance level a you can achieve.
3. Consider the plant transfer function
P(s) =
‚àís + 16
(s ‚àí6)(s + 11).
This is unstable and non-minimum-phase, and loopshaping is consequently diÔ¨Écult for it. But
try the loop transfer function
L(s) = œâc
s
‚àís + 16
16
s + 6
s ‚àí6
1
0.001s + 1.
This contains the unstable pole and zero of P, as it must for internal stability; it has relative
degree 1, as it must for C to be proper; and it equals approximately ‚àíœâc/s for low frequency.
Compute œâc to minimize ‚à•S‚à•‚àû. Compute the resulting magnitude Bode plot of S and T.
Notes and References
The technique of loopshaping was developed by Bode for the design of feedback ampliÔ¨Åers (Bode,
1945), and subsequently Bower and Schultheiss (1961) and Horowitz (1963) adapted it for the
design of control systems. The latter two references concentrate on particularly simple loopshaping
techniques, namely, lead and lag compensation. Loopshaping and the root-locus method are the
primary ones used today in practice for single-loop feedback systems. The phase formula is due to
Bode. Exercise 3 is based on a simpliÔ¨Åed analysis of the X-29 experimental airplane (Enns 1986).

116
CHAPTER 7. LOOPSHAPING

Chapter 8
Advanced Loopshaping
In Chapter 7 we saw how to convert performance speciÔ¨Åcations on S and T into speciÔ¨Åcations on the
loop transfer function L. For a stable, minimum-phase plant and L having at least the same relative
degree as P, the controller was obtained from C = L/P. In this chapter we discuss extensions to
this basic idea by doing loopshaping directly with C or other quantities and by considering plants
with right half-plane (RHP) poles or zeros. Finally, we introduce several optimal control problems
and explore in what sense loopshaping designs can be said to be optimal. Our aim is to extend
and deepen our understanding of loopshaping, to provide an introduction to optimal design, and to
establish some connections between the two approaches. Much of this chapter is closely related to
what has traditionally been called classical control, particularly the work of Bode.
8.1
Optimal Controllers
Recall from Section 4.5 that in general the norm
‚à•(|W1S|2 + |W2T|2)1/2‚à•‚àû
is a reasonable performance measure, a compromise norm for the robust performance problem.
Throughout this chapter we consider problems where P, W1, and W2 are Ô¨Åxed but C is variable,
so it is convenient to indicate the functional dependence of this norm on C by deÔ¨Åning
œà(C) := ‚à•(|W1S|2 + |W2T|2)1/2‚à•‚àû.
(8.1)
Throughout this chapter we refer to the optimal C, the controller that minimizes œà, for the purpose
of comparing it to controllers obtained via other methods in order to help evaluate their eÔ¨Äective-
ness. A procedure for determining the optimal C given P and weights W1 and W2 is developed in
Chapter 12.
We shall treat the unity-feedback loop of Figure 8.1. Suppose that we focus on the response of e
and u to the two inputs d and n (r has the same eÔ¨Äect as n), and recall that the transfer functions
from d and n to e and u are given as follows:
 e
u

= ‚àí
 PS
S
T
CS
  d
n

.
117

118
CHAPTER 8. ADVANCED LOOPSHAPING
C
P






-
-
-
-
-

?
?
6
r
u
y
d
n
‚àí
e
Figure 8.1: Unity-feedback loop.
If we introduce weights We on e, Wu on u, Wd on d, and Wn on n, then we could make our
performance speciÔ¨Åcation to keep the matrix
 We
0
0
Wu
  PS
S
T
CS
  Wd
0
0
Wn

=

WeS
WuCS
 
WdP
Wn

small in some sense. A convenient speciÔ¨Åcation is
(|WeS|2 + |WuCS|2)1/2(|WdP|2 + |Wn|2)1/2
‚àû< 1,
which is equivalent to
(|W1S|2 + |W2T|2)1/2
‚àû< 1,
where
|W1| = |We|(|WdP|2 + |Wn|2)1/2,
|W2| = |Wu|(|Wn|2|P|‚àí2 + |Wd|2)1/2.
(8.2)
Thus this problem Ô¨Åts the type of performance speciÔ¨Åcation in (8.1).
We will use this setup throughout this chapter, as it makes a useful ‚Äústandard‚Äù problem for
a number of reasons. First, it leads to some very interesting control problems, even when simple
constant weights are used. Second, there is a rich theory available for this problem, although it will
only be hinted at in this chapter. Third, it is easy to motivate problems in this framework that
greatly stretch the loopshaping methods. Finally, despite its simplicity, the problem setup is easy
to relate to what might arise in many practical situations.
8.2
Loopshaping with C
The loopshaping procedure developed in Chapter 7 involved converting performance speciÔ¨Åcations
on S and T into speciÔ¨Åcations on the loop transfer function L, and then constructing an L to
satisfy the resulting speciÔ¨Åcations and have reasonable crossover characteristics. Assuming that the
plant had neither RHP poles nor zeros, and that L had at least the same relative degree as P, the
controller was obtained from C = L/P. In this section we consider a slightly diÔ¨Äerent approach
that focuses more directly on C. Rather than construct L without regard to P, we could begin with

8.2. LOOPSHAPING WITH C
119
a very simple controller, say C = 1, and compare the resulting L with the speciÔ¨Åcation. It is often
easy then to add simple dynamics to C to meet the speciÔ¨Åcation.
In some instances it is more convenient to do loopshaping directly in terms of C rather than L.
This will typically occur when the weights on S and T share substantial dynamics with P, as in
(8.2). If we put a constant weight of 1 on d and n and a constant weight of 0.5 on u and e, then
the weights from (8.2) become
We = Wu = 0.5,
Wd = Wn = 1,
(8.3)
|W1| = 0.5(|P|2 + 1)1/2,
|W2| = 0.5(|P|‚àí2 + 1)1/2.
(8.4)
With W1 and W2 so deÔ¨Åned, for the performance speciÔ¨Åcation to be met the loopshape will usually
be very similar to P, so that the controller C will have |C| ‚âà1. We can get some insight into why
this is so by interpreting the weights in terms of the requirements they place on |C| as follows.
For L = PC
|W1S|2 = 0.25|P|2 + 1
|L + 1|2 ,
|W2T|2 = 0.25 |P|‚àí2 + 1
|L‚àí1 + 1|2 ,
and
|W2T|
|W1S| = |C|.
Assuming that œà(C) < 1, at frequencies for which |P| ‚â´1 we have that
|W1| ‚âà0.5|P|,
|W2| ‚âà0.5,
|W1S| ‚âà0.5|T|
|C|,
|W2T| ‚âà0.5|T|,
and when |P| ‚â™1,
|W1| ‚âà0.5,
|W2| ‚âà0.5 1
|P|,
|W1S| ‚âà0.5|S|,
|W2T| ‚âà0.5|CS|.
The crossover region can occur wherever |P| ‚âà1. When |P| = 1, we have
|W1| = |W2| =
‚àö
2
2 .
Viewing this as a standard loopshaping problem, we would expect that |L| ‚âà|P| and |C| = 1.
Example 1 Consider P given by
P(s) = 0.5
s +
4
X
i=1
0.2s
s2 + 2Œ∂iœâis + œâ2
i
,
where œâ1 = 0.2, œâ2 = 0.5, œâ3 = 2, œâ4 = 10, Œ∂i = 0.02. The Bode magnitude plot of P is shown in
Figure 8.2, and the resulting weights W1 and W2 on S and T are shown in Figure 8.3.
The complicated weights would appear to make this a tricky loopshaping problem, but in fact
the controller C = 1 meets the speciÔ¨Åcation. The quantity
(|W1S|2 + |W2T|2)1/2
(8.5)

120
CHAPTER 8. ADVANCED LOOPSHAPING
10-2
10-1
100
101
102
10-2
10-1
100
101
102
Figure 8.2: Bode plot of |P|.
10-1
100
101
102
10-2
10-1
100
101
102
Figure 8.3: Bode plots of |W1| (solid) and |W2| (dash).

8.2. LOOPSHAPING WITH C
121
0.5
0.55
0.6
0.65
0.7
0.75
10-2
10-1
100
101
102
frequency
magnitude
Figure 8.4: (|W1S|2 + |W2T|2)1/2 for C = 1 (solid) and optimal C (dash).
for C = 1 is plotted in Figure 8.4. The optimal œà for this problem is approximately 0.69, so C = 1
is very close to optimal.
This example illustrates the point that loopshaping directly using C can often be much simpler
than loopshaping with L and solving for C. While the example is somewhat contrived, similar things
can happen quite naturally. In particular, this example exhibits some characteristics of plants that
arise in the control of Ô¨Çexible structures.
Example 2
We will now use the same setup but with a slightly simpler plant P which we will
motivate with a simple mechanical analog of a two-mode Ô¨Çexible structure (Figure 8.5). Shown is a
one-dimensional rigid beam of mass M, length 2l, and moment of inertia I connected to a Ô¨Åxed base
by two springs, each with spring constant k. We assume that the beam undergoes small vertical
deÔ¨Çections x of the center of mass and small rotations Œ∏ about the center of mass. If we apply a
vertical force u at position lu from the center of mass, the linearized equations of motion are
M ¬®x + 2kx
=
u,
I ¬®Œ∏ + 2kl2Œ∏
=
luu.
Taking M = 2, I = 0.5, l = 2, k = 0.25, and lu = 1, we get that the transfer functions from u to x
and Œ∏ are respectively
0.5
s2 + 0.52 ,
2
s2 + 22 .
We will now measure y := Àôx ¬± ÀôŒ∏, the vertical velocity of the beam at the position ¬±1 from the
center of mass. For +1, the measurement is at the same location as the force input u; this is called

122
CHAPTER 8. ADVANCED LOOPSHAPING
M, I
lu
Œ∏
l
k
k
x
m
U
6
-

-
6
  @@
    @@
  Figure 8.5: Mechanical structure, Example 2.
collocated. In the ‚àí1 case the measurement is at the other side of the beam, noncollocated. The
resulting transfer function from u to y is then
P(s) =
0.5s
s2 + 0.52 ¬±
2s
s2 + 22 = (2 ¬± 0.5)s(1 ¬± s2)
(s2 + 0.52)(s2 + 22).
(8.6)
A plot of |P| is shown in Figure 8.6.
The collocated system has zeros at ¬±j and the noncollocated
system has zeros at ¬±1. As expected, we shall see that the noncollocated system is more diÔ¨Écult
to control. For the collocated case it turns out that the optimal controller for the weights (8.3)
is exactly C = 1, which is again much simpler than the resulting loopshape. It also turns out
that this result holds for all positive values of M, I, l, lu, and k, excluding those for which the
system is not mechanically possible. In each case, the optimal controller is C = 1 and the optimal
œà =
‚àö
2/2 ‚âà0.707. A proof of this, along with a discussion of the noncollocated case, is given in
the last section of this chapter.
It is interesting to note that both examples above have multiple crossover frequencies, that
is, several distinct frequencies at which |L| = 1. By contrast, most previous examples had only
one crossover frequency. Indeed, most problems considered in classical control texts have a single
crossover, and this might be considered typical. There are, however, certain application domains,
such as the control of Ô¨Çexible structures, where multiple crossovers are common. It turns out that
such systems have some interesting characteristics which may appear counterintuitive to readers
unfamiliar with them. These issues will be explored more fully in the last section of this chapter.
It is not unusual for a reasonable controller to be much simpler than the resulting loopshape
even when the problem setup is diÔ¨Äerent from the one considered in the examples above. It often
makes sense to begin the loopshaping design process with L equal to some constant times P and
then add dynamic elements to try to get the right loopshape.
Example 3 As a slightly diÔ¨Äerent example, consider the same setup as in Example 1 but with
P(s) =
1
s + 1 +
0.1s
s2 + 2Œ∂œâ1s + œâ2
1
,

8.2. LOOPSHAPING WITH C
123
10-1
100
101
102
10-1
100
101
Figure 8.6: Bode plots of |P| for + (solid) and ‚àí(dash).
where Œ∂ = 0.02 and œâ1 = 0.5. Suppose also that the weight on the error e is
We(s) = 0.5 s + 0.5
s + 0.01,
with Wu = 0.5 and Wd = Wn = 1 as before. This gives us the performance objective as in (8.1),
(8.2), and (8.4) except that now
|W1| = |We|(|P|2 + 1)1/2,
|W2| = 0.5(|P|‚àí2 + 1)1/2.
The Bode magnitude plot of P is shown in Figure 8.7 and the resulting weights W1 and W2 on S
and T are shown in Figure 8.8.
If we compare the loopshaping constraints in Figure 8.9 with the Bode plot of P in Figure 8.7
we see immediately that C = 1 will not work because there is not enough gain at low frequency.
Adding the simple lag compensator
C(s) =
s + 1
s + 0.01
gives the loopshape shown in Figure 8.9 and (|W1S|2 + |W2T|2)1/2 as shown in Figure 8.10. Fig-
ure 8.10 also shows the optimal level for this problem. The simple controller found here is very
close to optimal.

124
CHAPTER 8. ADVANCED LOOPSHAPING
10-2
10-1
100
101
10-2
10-1
100
101
102
Figure 8.7: Bode plot of |P|.
10-1
100
101
102
10-2
10-1
100
101
102
Figure 8.8: Bode plots of |W1| (solid) and |W2| (dash).

8.2. LOOPSHAPING WITH C
125
10-2
10-1
100
101
102
10-2
10-1
100
101
102
Figure 8.9: Loopshaping constraints and |L| (solid) for C = (s + 1)/(s + 0.01).
0.5
0.55
0.6
0.65
0.7
0.75
0.8
0.85
10-2
10-1
100
101
102
Figure 8.10: (|W1S|2 + |W2T|2)1/2 for C = (s + 1)/(s + 0.01) (solid) and optimal C (dash).

126
CHAPTER 8. ADVANCED LOOPSHAPING
8.3
Plants with RHP Poles and Zeros
Plants with RHP Zeros
Suppose that we begin a loopshaping problem with a plant P0, controller C0, and loop transfer
function L0 = P0C0 with neither RHP poles nor zeros and a single crossover. Now consider the
eÔ¨Äect of adding a single RHP zero at s = z to the plant by multiplying by the all-pass function
Pz(s) = z ‚àís
z + s,
where the sign of Pz is chosen so that Pz(0) = 1. This also adds the same factor to the loop transfer
function, which becomes
L(s) = L0(s)z ‚àís
z + s.
From the results of Chapter 6 we would expect problems unless z is larger than the crossover
frequency: Recall that
‚à•W1S‚à•‚àû‚â•|W1(z)|,
so that |W1| must not be large at z.
We may also consider the eÔ¨Äect of the RHP zero in terms of the gain-phase relations from
Section 7.2. The phase at crossover will be the original phase of L0 plus the phase of Pz:
‚à†L(jœâ)
=
‚à†L0(jœâ) + ‚à†Pz(jœâ),
‚à†Pz(jœâ)
=
2‚à†(‚àíjœâ + z).
The phase from Pz is negative and can be substantial as œâ approaches z, with ‚à†Pz(jz) = ‚àíœÄ/2.
Again, we see that if z approaches the crossover frequency, the additional phase will degrade the
closed-loop system performance or even lead to instability. Thus RHP zeros make the problem
worse for systems with one crossover. As an example, let the initial loopshape be L0(s) = 1/s with
L as above. The crossover frequency is œâ = 1 and the closed-loop system is stable if z > 1 and
unstable if z ‚â§1.
If Pz has a complex pair of RHP zeros, then
Pz(s) = œâ2
z ‚àí2Œ∂zœâzs + s2
œâ2z + 2Œ∂zœâzs + s2
and
‚à†Pz(jœâ) = 2‚à†(‚àí2Œ∂zœâzjœâ + œâ2
z ‚àíœâ2).
Observe that for lightly damped zeros where Œ∂z is small, the phase changes abruptly near œâ = œâz.
Otherwise, the same remarks apply here as in the case of one RHP zero. The simplest strategy to
adopt in doing loopshaping designs for systems with RHP zeros is to proceed as usual while keeping
track of the extra phase.
It would seem from this discussion that RHP zeros are always undesirable, that we would always
avoid them if possible, and that we would never deliberately introduce them in our controllers. It
is clearly true that all other things being equal, there is no advantage in having RHP zeros in the
plant, because we could always add them in the controller if they were desirable. The issue of using
RHP zeros in the controller is more subtle. Basically, they are clearly undesirable when there is only
one crossover, but may be useful when there are multiple crossovers. This issue will be considered
more fully in later sections on optimality.

8.3. PLANTS WITH RHP POLES AND ZEROS
127
Plants with RHP Poles
The problems created by RHP poles are similar to those created by RHP zeros, but there are
important diÔ¨Äerences. Suppose that we begin again with a loopshaping problem with a plant P0,
controller C0, and loop transfer function L0 = P0C0 with neither RHP poles nor zeros and a single
crossover. Now consider the eÔ¨Äect of adding a single RHP pole at s = p to the plant by multiplying
it by the all-pass function
Pp(s) = s + p
s ‚àíp.
This also adds the same factor to the loop transfer function L. The sign of Pp is chosen so that
Pp(0) = ‚àí1. For p small, this gives the right number of encirclements for L to give closed-loop
stability. Now we expect that we will have problems unless p is smaller than the crossover frequency:
Recall that
‚à•W2T‚à•‚àû‚â•|W2(p)|,
so that |W2| must not be large at p.
We may also consider the eÔ¨Äect of the RHP pole in terms of the gain-phase relations. The phase
at crossover will be the original phase of L0 plus the phase of Pp:
‚à†L(jœâ)
=
‚à†L0(jœâ) + ‚à†Pp(jœâ),
‚à†Pp(jœâ)
=
2‚à†(jœâ + p).
We may illustrate this with the same example. Let the initial loopshape be L0(s) = 1/s with L as
above. The crossover frequency is œâ = 1 and the closed-loop system is stable if p < 1 and unstable
if p ‚â•1. Similar eÔ¨Äects hold when there is more than one RHP pole.
All things being equal, we would prefer to avoid RHP poles in our plants. Even though they
can be stabilized by feedback, there is a price to pay in terms of closed-loop performance. Recall
that there are times when we must add RHP poles in our compensator just to stabilize the system.
Are there other times when we would want to add RHP poles? Clearly no if we have only one
crossover, but if there are multiple crossovers it might be advantageous. This will be discussed in a
later section on optimality.
Including RHP Poles and Zeros in Uncertainty Description
A somewhat more formal strategy for handling RHP poles and zeros is to include them in the
uncertainty description as follows. Suppose that we have a RHP zero at z. Then we can factor P
as
P(s) = P0(s)z ‚àís
z + s = P0(s)

1 + ‚àí2s
z + s

and cover this with a multiplicative perturbation to get
P = P0 (1 + Wz‚àÜ) ,
Wz(s) =
2s
z + s.

128
CHAPTER 8. ADVANCED LOOPSHAPING
A somewhat tighter cover is given by
P(s)
=
P0(s)

z
z + s ‚àí
s
z + s

=
P0(s)
z
z + s [1 + Wz(s)‚àÜ(s)] ,
Wz(s)
=
s
z .
Robust stability for uncertainty in this form would involve a test on ‚à•WzT‚à•‚àû.
Why would we want to do this? If we put all the RHP zeros into the plant uncertainty, then
we can use any design technique for plants with no RHP zeros, provided that we account for the
extra uncertainty. Basically, one makes sure that T is small enough where necessary. The way we
have covered the RHP zero above makes the model have little uncertainty at low frequencies and
considerable uncertainty at high frequencies. The transition occurs at frequencies near z. It is also
easy to cover the all-pass part with an uncertainty that is large at low frequencies and small at high
frequencies.
We can model RHP poles similarly. Care must be taken, however, because RHP poles don‚Äôt
naturally go into multiplicative uncertainty. Suppose that we have a RHP pole at p. Then we can
factor P as
P(s) = P0(s)s + p
s ‚àíp = P0(s)

1 + ‚àí2p
s + p
‚àí1
and cover this with a perturbation to get
P = P0
1
1 + Wp‚àÜ,
Wp(s) =
2p
s + p.
This introduces an additional weight on S. A somewhat tighter cover is given by
P(s)
=
P0(s)

s
s + p ‚àí
p
s + p
‚àí1
=
P0(s)s + p
s
1
1 + Wp(s)‚àÜ(s),
Wp(s)
=
p
s.
How conservative is this covering method? For most problems with a single crossover and for
which the performance objectives are achievable, this approach will work well. Basically, we need to
make sure that S is small enough where there are RHP poles and T is small enough where there are
RHP zeros. There are more complicated problems, particularly those involving multiple crossovers,
where the impact of RHP poles and zeros might be quite diÔ¨Äerent. This issue will be considered
again in the Ô¨Ånal section of this chapter.
Examples
We will now consider several examples that illustrate loopshaping for systems with RHP zeros and
poles.

8.3. PLANTS WITH RHP POLES AND ZEROS
129
Example 1 Consider
P(s) = P0(s)z ‚àís
z + s,
P0(s) = 1
s.
As in Section 8.2,
|W1| = 0.5(|P|2 + 1)1/2,
|W2| = 0.5(|P|‚àí2 + 1)1/2,
(8.7)
or
W1(s) = 0.5

1 + 1
s

,
W2(s) = 0.5(s + 1).
(8.8)
The obvious controller for P0 is C = 1, which is also optimal with |W1S| = |W2T| = 0.5 and
œà(C) =
‚àö
2/2. This simple controller will work Ô¨Åne for z ‚â´1, but deteriorates as z approaches 1
and does not stabilize for z ‚â§1 because of the additional phase lag caused by the all-pass factor.
Recall that for any controller
‚à•W1S‚à•‚àû‚â•|W1(z)| = 0.5

1 + 1
z

,
but it is possible to improve substantially on C = 1 as z gets close to 1.
We will now focus on z = 2. For C = 1 the loopshape constraints and the loopshape L = CP are
shown in Figure 8.11. The closed-loop performance is shown in Figure 8.12. Note that œà(C) > 2,
with both |W1S| and |W2T| exceeding the speciÔ¨Åcation at low and high frequencies, with a large
peak in the middle. This is due to too much phase lag in L at crossover (œâ = 1). Recall from
the gain-phase formula in Section 7.2 that we may improve the phase at crossover by reducing the
low-frequency gain, reducing the crossover frequency, and increasing the high-frequency gain. A
simple controller that does this is of the form
C(s) = k(s + 2)
(s + 2k2),
k > 1.
(8.9)
It turns out that the optimal C has k = 1.78, which yields an optimal œà(C) = 1.02. A value of
k very close to optimal is also easily arrived at by a little trial and error. The loopshape for the
optimal C is shown in Figure 8.13 and the closed-loop performance is shown in Figure 8.14. The
controller reduces the low-frequency gain and the crossover frequency and raises the high-frequency
gain of L, as expected.
Next we will try an alternative design by covering the RHP zero with uncertainty and then
loopshaping with the resulting minimum-phase nominal plant. For general z write
P(s) = 1
s

z
z + s ‚àí
s
z + s

= P0(s) [1 + Wz(s)‚àÜ(s)] ,
where
P0(s) = 1
s
z
z + s,
Wz(s) = s
z .
(8.10)
We now have two weights on T: W2 and Wz. We need to Ô¨Ånd a weight that covers both of these.
A reasonable approximation is
|Wtot| = |W2| + |Wz| + |W2||Wz|.

130
CHAPTER 8. ADVANCED LOOPSHAPING
10-2
10-1
100
101
102
10-2
10-1
100
101
102
Figure 8.11: Loopshaping constraints (dash and dot) and |L| (solid) for C = 1.
0
0.5
1
1.5
2
2.5
10-2
10-1
100
101
102
Figure 8.12: (|W1S|2 + |W2T|2)1/2 (solid), |W1S| and |W2T| (both dash) for C = 1.

8.3. PLANTS WITH RHP POLES AND ZEROS
131
10-2
10-1
100
101
102
10-2
10-1
100
101
102
Figure 8.13: Loopshaping constraints (dash and dot) and |L| (solid) for optimal C.
0
0.5
1
1.5
2
2.5
10-2
10-1
100
101
102
Figure 8.14: (|W1S|2 + |W2T|2)1/2 (solid), |W1S| (dash), and |W2T| (dot), optimal C.

132
CHAPTER 8. ADVANCED LOOPSHAPING
It is routine to show that

(1 + ‚àÜWz)W2T
1 + ‚àÜWzT
 ‚â§|W2T|(1 + |Wz|)
1 ‚àí|WzT|
and
|W2T|(1 + |Wz|)
1 ‚àí|WzT|
< 1
iÔ¨Ä
|WtotT| < 1,
so using Wtot is a safe, but possibly conservative approximation. As an alternative way of thinking
about this in terms of uncertainty descriptions, note that
{(1 + |W2|‚àÜ1)(1 + |Wz|‚àÜ2) : |‚àÜ1| ‚â§1, |‚àÜ2| ‚â§1} ‚äÇ{1 + |Wtot|‚àÜ: |‚àÜ| ‚â§1} .
If z ‚â´1, this additional ‚Äúuncertainty‚Äù will be negligible and the controller C = 1 will be Ô¨Åne.
10-3
10-2
10-1
100
101
102
103
104
10-2
10-1
100
101
102
Figure 8.15: |W2| (dash), |Wz| (dot), and |Wtot| (solid).
Again, for the case z = 2 the plot for |Wtot| is shown in Figure 8.15, together with plots of |W2|
and |Wz|. To help us understand how conservative we have been by these approximations, we can
compare
(|W1S|2 + |W2T|2)1/2
(8.11)
for P with RHP zero at s = 2 with

|W1S|2 + (1 + |Wz|)2|W2T|21/2
1
1 ‚àí|WzT|
(8.12)

8.3. PLANTS WITH RHP POLES AND ZEROS
133
0
0.5
1
1.5
2
2.5
10-2
10-1
100
101
102
Figure 8.16: Plots of (8.11) (solid), (8.12) (dash), and (8.13) (dot).
and
(|W1S|2 + |WtotT|2)1/2,
(8.13)
where in (8.12) and (8.13) we use the plant P0 from (8.10). By construction, we have that (8.11) ‚â§
(8.12), but (8.13) is not necessarily an upper bound for (8.11). All three quantities are plotted in
Figure 8.16.
For P = P0 and C = 1, the loopshape L = CP is shown in Figure 8.17, along with the
loopshaping constraints.
As before, there is too much phase lag in the crossover region, which
is veriÔ¨Åed in Figure 8.18.
As before, we may improve the phase at crossover by reducing the
low-frequency gain, reducing the crossover frequency, and increasing the high-frequency gain. The
optimal controller should once again be adequate, as is veriÔ¨Åed in Figures 8.19 and 8.20.
This example illustrates how the simple loopshaping ideas from this chapter and the preceding
one can be extended to handle plants with RHP zeros.
Example 2 Now consider the problem of stabilizing the plant
P(s) = Œ±s ‚àí1
Œ± ‚àís ,
Œ± ‚àà(0, 1).
(8.14)
It is easily checked that a constant controller C = k stabilizes this system iÔ¨Äk ‚àà(Œ±, 1/Œ±). We may
compare this with the conclusions we would arrive at if we were to cover the RHP zero and pole
with uncertainty about a nominally stable, minimum-phase plant. For example, we may write
Œ±s ‚àí1
Œ± ‚àís = 1
s
 1 + Œ±s‚àÜ1(s)
1 + Œ±/s‚àÜ2(s)

.
(8.15)

134
CHAPTER 8. ADVANCED LOOPSHAPING
10-3
10-2
10-1
100
101
102
10-2
10-1
100
101
102
Figure 8.17: Loopshaping constraints (dash and dot) and |L| (solid), C = 1.
0
0.5
1
1.5
2
2.5
10-2
10-1
100
101
102
Figure 8.18: (|W1S|2 + |WtotT|2)1/2 (solid), |W1S| (dash), and |WtotT| (dot), C = 1.

8.4. SHAPING S, T, OR Q
135
10-3
10-2
10-1
100
101
102
10-2
10-1
100
101
102
Figure 8.19: Loopshaping constraints (dash and dot) and |L| (solid) for optimal C.
We can pose this in the standard form of œà(C) in (8.1) with plant P(s) = 1/s and weights
W1(s) = Œ±/s and W2(s) = Œ±s. If we now consider loopshaping for this problem, we will meet this
speciÔ¨Åcation with a constant controller C = k roughly if k ‚àà(Œ±, 1/Œ±), as before. Thus for this
problem with both a RHP pole and zero, the approximation of covering the RHP pole and zero
with uncertainty produces very little conservatism.
8.4
Shaping S, T, or Q
It is possible to do designs directly in terms of S and T rather than translate the speciÔ¨Åcations into
constraints on the loopshape. This is especially useful when P is either stable or minimum-phase,
or both. Then the stability constraints on S and T are particularly simple. For example, if there
are only RHP zeros, these must appear in T, but T is otherwise unconstrained. The performance
objective due to weights on T can be directly handled by the choice of T, but S is not as easy. Since
S = 1 ‚àíT, we can make S small by making T close to 1. Although this can sometimes be a bit
awkward, it is often the case that by looking at T and S directly in addition to L, we can arrive at
a design more quickly.
Another alternative to loopshaping is to use Q, appearing in the parametrization of all stabilizing
controllers. To summarize this, recall (Section 5.1) that if we have a stable P, we can parametrize
the set of all stabilizing controllers as
C =
Q
1 ‚àíPQ,
where Q is any stable transfer function. In terms of this free parameter Q, we have that S = 1‚àíPQ

136
CHAPTER 8. ADVANCED LOOPSHAPING
0
0.5
1
1.5
2
2.5
10-2
10-1
100
101
102
Figure 8.20: (|W1S|2 + |WtotT|2)1/2 (solid), |W1S| (dash), and |WtotT| (dot), optimal C.
and T = PQ. As Q approaches 1/P, then S approaches 0 and C approaches ‚àû. Thus for minimum-
phase P, we can make S arbitrarily small, as expected. For non-minimum-phase P, recall that we
can factor P = PapPmp where Pap is all-pass and Pmp is minimum-phase. We can approximately
invert the minimum-phase part by letting Q = F/Pmp, where F is a low-pass Ô¨Ålter so that Q
is proper. We can then shape the low-pass F to trade oÔ¨Äbetween S and T. This approach is
essentially shaping T since T = FPap.
Example Take
P(s) = 1
s
2 ‚àís
2 + s

.
(8.16)
Consider directly shaping T and look at tradeoÔ¨Äs between S and T and the limitations imposed
by the RHP zero at s = 2. For internal stability we must have T(2) = 0 and T(0) = 1, so we can
parametrize a family of allowable Ts with
T(s)
=
2 ‚àís
2 + s

1
1 + œÑs,
S(s)
=
1 ‚àíT(s)
=
s
s + 2
œÑs + 2œÑ + 2
œÑs + 1

.

8.4. SHAPING S, T, OR Q
137
This gives
L(s)
=
T(s)
S(s)
=
2 ‚àís
s(œÑs + 2œÑ + 2),
C(s)
=
s + 2
œÑs + 2œÑ + 2.
For this parametrization, 1/œÑ is roughly the closed-loop bandwidth, so we are pushing the bandwidth
up by making œÑ small. This is shown in Figures 8.21 and 8.22, where S, T, and L are plotted for
œÑ = 0.01, 0.1, 1, 10, and 100. There are negligible changes in S, T, and L at low frequency as œÑ is
decreased from 0.1 to 0.01, although the high-frequency characteristics change substantially. This
illustrates another way the limits are imposed by RHP zeros.
10-2
10-1
100
101
10-3
10-2
10-1
100
101
102
103
Figure 8.21: |T| (solid) and |S| (dash) for 0.01 ‚â§œÑ ‚â§100.
If we take limits as œÑ ‚Üí0, we get
T ‚Üí2 ‚àís
2 + s,
S ‚Üí
2s
s + 2,
L ‚Üí2 ‚àís
2s ,
C ‚Üí2 + s
2
.
(8.17)
Thus even at the expense of an inÔ¨Ånite bandwidth controller, we cannot get disturbance rejection
much above œâ = 1. Recall that if we take the weight
W1(s) = s + 2
2s ,
then for any stabilizing controller
‚à•W1S‚à•‚àû‚â•s + 2
2s

s=2
= 1,

138
CHAPTER 8. ADVANCED LOOPSHAPING
10-2
10-1
100
101
102
10-3
10-2
10-1
100
101
102
103
Figure 8.22: |L| for 0.01 ‚â§œÑ ‚â§100.
so the S in (8.17) cannot be uniformly improved on. For very low bandwidths (i.e., for œÑ ‚â´1 and
œâ ‚â™1), the RHP zero has negligible impact as
T ‚âà
1
œÑs + 1,
S ‚âà
œÑs
œÑs + 1,
L ‚âà1
œÑs,
C ‚âà1
œÑ .
This example illustrates how we may easily explore the tradeoÔ¨Äs between S and T for P with
RHP zeros by putting the zeros in T and then exploring a one-parameter family of T and hence S.
Similar tradeoÔ¨Äs may be explored for plants with RHP poles by parametrizing a family of S. For
plants with both RHP poles and zeros, it is necessary to use the more complicated parametrization
developed in Chapter 5.
8.5
Further Notions of Optimality
Each of the design methods presented so far‚Äîshaping L, S, T, or Q‚Äîgives the designer something
handy to manipulate to obtain a controller.
In each case, the resulting controller will have to
be examined in the closed-loop system to see if it is satisfactory‚Äîevery controller results in some
tradeoÔ¨Äbetween S and T, and the designer must decide if that tradeoÔ¨Ämakes sense for a particular
problem. However, some controllers are intrinsically poor. In particular, we would like to avoid
design techniques that yield controllers that can be uniformly improved upon, that is, where both
|S| and |T| can be reduced at every frequency. Such controllers clearly do a poor job on the tradeoÔ¨Ä
between S and T.
In this section we deÔ¨Åne several notions of optimality which we will use to help understand
the notion of an intrinsically poor controller. In what follows, all controllers are assumed to be

8.5. FURTHER NOTIONS OF OPTIMALITY
139
internally stabilizing and all weights are assumed to be stable and not identically zero; Co is a Ô¨Åxed
controller, and So and To its corresponding sensitivity and complementary sensitivity functions; C
is some generic, variable controller and S and T its corresponding functions.
The Ô¨Årst type of optimality we will consider is Pareto optimality. A controller Co is Pareto
(Par.) optimal if there is no C such that at every frequency |S| < |So| and |T| < |To|; equivalently,
for every C, at some frequency either |S| ‚â•|So| or |T| ‚â•|To|. A controller Co is strongly Pareto
(str. Par.) optimal if there is no C Ã∏= Co such that at every frequency |S| ‚â§|So| and |T| ‚â§|To|;
equivalently, for every C Ã∏= Co, at some frequency either |S| > |So| or |T| > |To|. The class of
strongly Pareto optimal controllers is quite large: some of them give good S and T tradeoÔ¨Äs, some
do not. But controllers that are not strongly Pareto optimal, that is, are outside this class, are
evidently poor because they can be improved uniformly.
Our primary objective in this section and the next is to show that loopshaping generally yields
strongly Pareto optimal controllers. Unfortunately, we must take a circuitous route to establish
this, introducing several intermediate notions of optimality. There are added beneÔ¨Åts, however, in
that these additional notions of optimality have some independent interest, and we shall see that
optimal controllers, the subject of Chapter 12, are also Pareto optimal.
We have argued that the norm
‚à•(|W1S|2 + |W2T|2)1/2‚à•‚àû
is a reasonable performance measure, a compromise norm for the robust performance problem.
Recall that for Ô¨Åxed P with C variable, we deÔ¨Åned
œà(C) := ‚à•(|W1S|2 + |W2T|2)1/2‚à•‚àû.
Using œà(C), we can deÔ¨Åne two additional notions of optimality, together with strengthened versions
involving uniqueness that are analogous to strongly Pareto optimal.
1. For given weights W1 and W2, Co is optimal if œà(Co) ‚â§œà(C) for every C, and uniquely optimal
if œà(Co) < œà(C) for every C Ã∏= Co.
2. Co is potentially (pot.) optimal if there exist weights W1, W2 such that Co is optimal for these
weights and potentially uniquely (pot. uni.) optimal if there exist weights W1, W2 such that
Co is uniquely optimal for these weights.
These notions, along with Pareto optimal, are related according to the Venn diagram shown
in Figure 8.23, which is easily veriÔ¨Åed. Potentially uniquely optimal is the strongest of the four
notions.
Self-Optimality
In this subsection an even stronger type of optimality is introduced whose signiÔ¨Åcance is due to
three features:
1. It is easy to characterize.
2. Loopshaping generally produces controllers with this type of optimality.
3. It implies all the notions above, and in particular, strong Pareto optimality.

140
CHAPTER 8. ADVANCED LOOPSHAPING
pot.
Par.
pot. uni.
str. Par.
Figure 8.23: Notions of optimality.
Fix a controller Co, deÔ¨Åne Lo := PCo, and deÔ¨Åne weights as follows: W ‚àí1
1
is the minimum-phase
factor of So and W ‚àí1
2
is the minimum-phase factor of To. Thus the weights are deÔ¨Åned in terms
of the controller itself. Observe that W ‚àí1
2
may be strictly proper, and that both W ‚àí1
1
and W ‚àí1
2
may have zeros on the imaginary axis. Thus the weights W1 and W2 may not be bounded on the
imaginary axis. Since W1So equals the all-pass factor of So, it has constant magnitude 1 on the
imaginary axis. Similarly for W2To. Thus
|W1So|2 + |W2To|2 = 2,
‚àÄœâ.
Given W1 and W2 so deÔ¨Åned, Co is called self-optimal if it is optimal with respect to these weights.
Similarly, it is uniquely self-optimal if it is uniquely optimal with respect to these weights. It will be
shown below that for almost all controllers, a self-optimal controller is uniquely self-optimal. The
Venn diagram, including uniquely self-optimal is shown in Figure 8.24.
It is convenient to introduce the following notation. For a transfer function G having no poles
on the imaginary axis, let
#p(G)
:=
number of open RHP poles of G,
#z(G)
:=
number of open RHP zeros of G,
#i(G)
:=
number of imaginary axis zeros of G.
The main result is as follows.
Theorem 1 If #i(Lo ‚àí1) = 0, Co is self-optimal iÔ¨ÄCo is uniquely self-optimal iÔ¨Ä
#z(Lo ‚àí1) > #p(Co) + #z(Co).
(8.18)
We are restricting attention to the case #i(Lo ‚àí1) = 0 primarily for technical reasons, as
it simpliÔ¨Åes the development with a negligible loss of generality.
Note that #i(Lo ‚àí1) = 0 iÔ¨Ä

8.5. FURTHER NOTIONS OF OPTIMALITY
141
uni. self
pot.
Par.
pot. uni.
str. Par.
Figure 8.24: Notions of optimality.
Lo(jœâ) Ã∏= 1, ‚àÄœâ. This would hold for almost all controllers, because if #i(Lo ‚àí1) Ã∏= 0, then a small
change, say by a constant gain, in Lo would make #i(Lo ‚àí1) = 0. It can easily be shown that
if #i(Lo ‚àí1) ‚â•1, then Co is always self-optimal, but characterizing uniquely self-optimal is more
diÔ¨Écult.
Observe from the principle of the argument that in terms of the Nyquist plot of Lo,
#z(Lo ‚àí1)
=
#p(Lo ‚àí1) + (no. clockwise enc. of + 1)
=
#p(Lo) + (no. clockwise enc. of + 1)
=
#p(P) + #p(Co) + (no. clockwise enc. of + 1).
So condition (8.18) is equivalent to
#p(P) + (no. clockwise enc. of + 1) > #z(Co).
A typical loopshaping controller for a stable plant will have #z(Co) = 0 and
(no. clockwise enc. of + 1) > 0,
and will thus be self-optimal.
Example For a simple illustration, suppose that
P(s) =
s + 1
100s + 1.
The controller Co(s) = 10 yields
Lo(s) = 10
s + 1
100s + 1.

142
CHAPTER 8. ADVANCED LOOPSHAPING
The Nyquist plot of Lo has one clockwise encirclement of +1, so Co is self-optimal. So is Co(s) = K
for any K in (1, 100). In particular, such controllers cannot be improved upon uniformly over all
frequencies.
It can be shown using the phase formula (Section 7.2) that any controller that is minimum-phase
and for which Lo has a single gain crossover is self-optimal.
Proof of Theorem 1 DeÔ¨Åne
Œìo(jœâ) := |W1(jœâ)So(jœâ)|2 + |W2(jœâ)To(jœâ)|2,
so that
œà(Co)2 = sup
œâ Œìo(jœâ).
As we have already seen, Œìo(jœâ) = 2. Similarly, for another controller C, deÔ¨Åne
Œì(jœâ) := |W1(jœâ)S(jœâ)|2 + |W2(jœâ)T(jœâ)|2,
so that
œà(C)2 = sup
œâ Œì(jœâ).
Thus Co is self-optimal
‚áê‚áí
(‚àÄC) œà(Co) ‚â§œà(C)
‚áê‚áí
(‚àÄC)(‚àÉœâ) 2 ‚â§Œì(jœâ)
‚áê‚áí
it is not true that (‚àÉC)(‚àÄœâ) 2 > Œì(jœâ)
and Co is uniquely self-optimal
‚áê‚áí
it is not true that (‚àÉC Ã∏= Co)(‚àÄœâ) 2 ‚â•Œì(jœâ).
So the theorem statement is equivalent to
(‚àÉC)(‚àÄœâ) 2 > Œì(jœâ)
‚áê‚áí
(‚àÉC Ã∏= Co)(‚àÄœâ) 2 ‚â•Œì(jœâ)
‚áê‚áí
#z(Lo ‚àí1) ‚â§#p(Co) + #z(Co).
It is convenient to turn this statement into one in terms of So rather than Co. As we saw in
Chapter 6, the constraints placed on So by the requirement that Co achieve internal stability are
So
‚àà
S,
So
=
0 at RHP poles of P,
So
=
1 at RHP zeros of P,
with appropriate multiplicity. Then S satisÔ¨Åes these constraints too iÔ¨Äit has the form
S = So + AY,
where A is the all-pass factor formed from the RHP poles and zeros of P, and Y is an arbitrary
element of S. It is convenient Ô¨Årst to assume that P and Co are biproper and have no poles or

8.5. FURTHER NOTIONS OF OPTIMALITY
143
zeros on the imaginary axis, so that neither So nor To have imaginary axis zeros, and the weights
are stable and biproper. Then (8.19) is equivalent to
(‚àÉY ‚ààS)(‚àÄœâ) 2 > |W1(So + AY )|2 + |W2(To ‚àíAY )|2 ‚áê‚áí
(‚àÉY ‚ààS, Y Ã∏= 0)(‚àÄœâ) 2 ‚â•|W1(So + AY )|2 + |W2(To ‚àíAY )|2 ‚áê‚áí
#z(Lo ‚àí1) ‚â§#p(Co) + #z(Co)
(8.19)
(jœâ has been dropped to simplify the notation). Recall that
|W1| =
1
|So|,
|W2| =
1
|To|,
so
|W1(So + AY )|2 + |W2(To ‚àíAY )|2
=
1 + AY
So

2
+
1 ‚àíAY
To

2
=
2 + 2Re
 1
So
‚àí1
To

AY

(8.20)
+

1
|So|2 +
1
|To|2

|AY |2.
(8.21)
Thus (8.19) is equivalent to the condition
(‚àÉY ‚ààS)(‚àÄœâ)0
>
2Re (XY ) + W|Y |2
(8.22)
iÔ¨Ä
(‚àÉY ‚ààS, Y Ã∏= 0)(‚àÄœâ)0
‚â•
2Re (XY ) + W|Y |2
(8.23)
iÔ¨Ä
#z(Lo ‚àí1)
‚â§
#p(Co) + #z(Co),
(8.24)
where
X :=
 1
So
‚àí1
To

A
is biproper with no imaginary poles or zeros and
W :=

1
|So|2 +
1
|To|2

|A|2 > 0
is bounded for all œâ. That (8.22) implies (8.23) is immediate by inspection. We will complete the
proof by Ô¨Årst showing that (8.24) is equivalent to
#z(X) ‚â§#p(X)
(8.25)
and then that (8.23) =‚áí(8.25) and (8.25) =‚áí(8.22).
To see that (8.24) ‚áê‚áí(8.25) holds, note that
X
=

Lo + 1 ‚àíLo + 1
Lo

A = (Lo + 1)(Lo ‚àí1)
Lo
A
=
[num(PCo) + den(PCo)][num(PCo) ‚àíden(PCo)]
num(PCo)den(PCo)
A.

144
CHAPTER 8. ADVANCED LOOPSHAPING
Now the polynomial num(PCo) + den(PCo) has all its zeros in the left half-plane, by internal
stability; and the numerator of A cancels the zeros in num(PCo)den(PCo) coming from the RHP
poles and zeros of P. Thus
#z(X) = #z[num(PCo) ‚àíden(PCo)] = #z(Lo ‚àí1)
and
#p(X) = #p(Co) + #z(Co).
For (8.23) =‚áí(8.25), note that if the Nyquist plot of XY lies in the closed left half-plane, then
in particular it does not encircle the origin. Since XY is not identically zero, by the principle of
the argument
#z(XY ) = #p(XY ).
But #z(X) ‚â§#z(XY ) and #p(XY ) ‚â§#p(X).
For (8.25) =‚áí(8.22), note that (8.22) is equivalent to
(‚àÉY ‚ààS)(‚àÄœâ) 0 > 2Re (XY ) ,
since we can scale Y so that the quadratic term W|Y |2 is negligible. We will construct a Y ‚ààS
such that Re(XY ) < 0,
‚àÄœâ. If #z(X) ‚â§#p(X), we can write X = X1X2, where X1 has only
RHP poles and zeros with #z(X) = #z(X1) = #p(X1), and X2 has #z(X2) = 0 and #p(X2) =
#p(X) ‚àí#p(X1). Thus both X1 and X2 are biproper. If
Y (s) = X1(‚àís)
X2(s) ,
then Y ‚ààS and is biproper and
X(jœâ)Y (jœâ) = X1(jœâ)X1(‚àíjœâ) = |X1(jœâ)|2 > 0,
‚àÄœâ.
To complete the proof, we must drop the restriction that Lo is biproper and has no imaginary
axis poles or zeros. This means that So and To may have imaginary zeros, and thus W1 and W2 may
have imaginary poles. In order for (8.21) to be bounded, we must have AY share the imaginary
zeros of So and To, including those at ‚àû.
The simplest way to proceed is to assume that A is no longer all-pass but has in addition the
imaginary zeros of So and To and enough LHP poles so that A has the appropriate behavior at ‚àû.
The location of the LHP poles is unimportant. Then
S = So + AY
still parametrizes all S that can arise from internally stabilizing controllers and produce a Ô¨Ånite Œì.
The proof can now proceed exactly as before. Observe that X is still biproper and has no imaginary
poles or zeros, because of the construction of A. ‚ñ†

8.5. FURTHER NOTIONS OF OPTIMALITY
145
Example and Implications
In the preceding subsection it was remarked that loopshaping produces self-optimal controllers.
In particular, for stable plants and loopshapes with a single crossover, where #z(Lo ‚àí1) =
(# clockwise enc. of + 1) = 1, then the controller is self-optimal iÔ¨Äit has no RHP poles or ze-
ros. For #z(Lo ‚àí1) > 1, controllers with no RHP poles or zeros are also always self-optimal. This
helps make clear the conventional wisdom about why RHP controller poles and zeros are undesir-
able. Similar insight comes from the results on performance limitations due to RHP zeros and the
integral gain-phase relations from earlier chapters.
Are there ever times when it would make sense to introduce RHP controller poles or zeros
deliberately? Theorem 1 leaves open this possibility for situations where #z(Lo ‚àí1) > 1, which
can occur when there are multiple crossovers.
Example To illustrate this we will reconsider the simple beam, Example 2 from Section 8.2, with
P given in (8.6) and with weights from (8.3). Recall that for the noncollocated case the plant has
a RHP zero at s = 1. Consider the controller
C‚àí(s) = 2.4
s ‚àí1
s + 1
 
s2 ‚àís + 1
(s + 0.1)(s + 10)

.
(8.26)
A Bode plot of C‚àíis shown in Figure 8.25. The resulting closed-loop performance for C‚àíis shown
in Figure 8.26, along with the performance for the optimal controller. Observe that C‚àíis nearly
optimal. (It was actually obtained by rounding coeÔ¨Écients in the optimal controller to convenient
values.) Also, the optimal performance of œà ‚âà1.26 is poorer than the optimal performance of
œà =
p
(2)/2 ‚âà0.707 for the collocated case.
10-1
100
101
10-1
100
101
-200
-100
0
100
200
10-1
100
101
magnitude
phase
Figure 8.25: Bode plots of |C‚àí| (upper) and ‚à†C‚àí(lower).

146
CHAPTER 8. ADVANCED LOOPSHAPING
0
0.2
0.4
0.6
0.8
1
1.2
1.4
10-1
100
101
Figure 8.26: œà for optimal C (solid) and C‚àí(dash).
The controller C‚àíhas no RHP poles and three RHP zeros, so that the loop transfer function
PC‚àíhas a total of four RHP zeros. Since #z(PC‚àí‚àí1) = 4, we have from Theorem 1 that this
controller is also self-optimal. It is possible to give a loopshaping interpretation of this controller,
which is not much diÔ¨Äerent than an all-pass. Intuitively, a good controller for this problem must
have the appropriate phase at the two resonant frequencies (œâ = 0.5, 2) for stability, and from the
arguments in Section 8.2 its gain should not deviate too greatly from 1. Thus a controller which is
nearly all-pass would seem appropriate.
The ideas on dealing with RHP zeros presented in Section 8.3 are not terribly useful in this
example.
Since there are necessarily crossover frequencies both above and below the frequency
œâ = 1 where the zero occurs, it is not clear how to cover this with uncertainty. The controller C‚àí
actually places an additional three RHP zeros near this frequency. While a loopshaping methodology
could potentially still apply to this example, the actual details of this controller are hardly obvious.
The loopshaping methods developed in this book always involve some trial and error, but this
example seems to require a great deal. This would also be true for many other problems of this
complexity with RHP zeros at frequencies between multiple crossover frequencies.
This example illustrates how RHP controller zeros can be eÔ¨Äective for problems with multiple
crossovers. What about poles? Theorem 1 appears to be symmetric in the controller RHP poles and
zeros, but this is somewhat misleading since RHP poles have an impact on the need for encirclements
of ‚àí1 and hence on the number #z(PC ‚àí1).
Nevertheless, in the problem considered in this
section, with perhaps slightly diÔ¨Äerent weights, there will typically be multiple crossovers and
#z(PC ‚àí1) ‚â•4, so C can have up to a total of three RHP poles and zeros and still be self-optimal.
Thus we would expect that relatively small changes in the weights could lead to controllers with a
variety of RHP poles and zeros. Recall also that certain plants can only be stabilized with unstable

8.5. FURTHER NOTIONS OF OPTIMALITY
147
controllers, so any problem with such a plant would necessarily have controllers with RHP poles.
On the other hand, the vast majority of feedback control problems in engineering applications have
a single crossover, and controller RHP poles and zeros would clearly be undesirable.
Now we return to the collocated version of this problem and use the characterization of self-
optimality from the preceding subsection to prove that the controller C = 1 is optimal for all
physically possible values of the parameters M, I, l, lu, and k. This is a remarkable robust perfor-
mance result and does not hold in the more general noncollocated case. It illustrates why collocated
control problems are so popular among researchers in control of Ô¨Çexible structures. We have not
focused on this type of parametric uncertainty in this book, because the available results tend not
to be very general. For example, the optimality of C = 1 for this problem depends not only on
the special structure of P but also on the special structure of the performance speciÔ¨Åcation. Nev-
ertheless, the methods developed in this book can be useful in studying speciÔ¨Åc problems involving
parametric uncertainty, as illustrated by this example.
To prove the optimality of C = 1, note that for all values of the parameters
P(s) =
s
Ms2 + 2k +
l2
us
Is2 + 2kl2 = s

(I + Ml2
u)s2 + 2k(1 + l2)

(Ms2 + 2k)(Is2 + 2kl2)
has all its poles and zeros on the imaginary axis, with poles at
s = ¬±j
r
2k
M , ¬±j
r
2kl2
I
and zeros at
s = 0, ¬±j
s
2k(1 + l2)
(I + Ml2u).
To be physically meaningful, all the parameters must be positive, and the geometry of the problem
restricts the moment of inertia such that
0 < I < Ml2,
so we have that
0 <
r
2k
M <
s
2k(1 + l2)
(I + Ml2u) <
r
2kl2
I
.
Thus the zeros and poles alternate on the imaginary axis and
ReP(jœâ) = 0,
‚àÄœâ.
It is clear from the Nyquist diagram of P that
#z(P + 1) = 0
and
#z(P ‚àí1) = 4,
so the controller C = 1 is both stabilizing and self-optimal for all parameter values. Recall that the
weights W1 and W2 that are used to deÔ¨Åne self-optimality are those that make |W1S| and |W2T|

148
CHAPTER 8. ADVANCED LOOPSHAPING
all-pass. Clearly, we could use weights that are a constant multiple of these as well. Thus to use
self-optimality to show that C = 1 is optimal for
œà(C) := ‚à•(|W1S|2 + |W2T|2)1/2‚à•‚àû
with
|W1| = 0.5(|P|2 + 1)1/2,
|W2| = 0.5(|P|‚àí2 + 1)1/2,
we must verify that |W1S| and |W2T| are all-pass. But since ReP(jœâ) = 0, ‚àÄœâ, we have that
|P + 1|2 = |P|2 + 1,
‚àÄs = jœâ,
and thus
|W1S|2 = 0.25|P|2 + 1
|P + 1|2 = 0.25,
|W2T|2 = 0.25 |P|‚àí2 + 1
|P ‚àí1 + 1|2 = 0.25,
as desired. This completes the proof.
What are the implications of this example and the results on self-optimality for loopshaping?
Each of the design methods presented so far‚Äîshaping L, S, T, or Q‚Äîgives the designer something
handy to manipulate to obtain a controller. In each case, the resulting controller will have to be ex-
amined in the closed-loop system to see if it is satisfactory‚Äîevery controller results in some tradeoÔ¨Ä
between S and T, and the designer must decide if that tradeoÔ¨Ämakes sense for a particular problem.
If a reasonable tradeoÔ¨Äbetween S and T can be found by any method, and the resulting controller
is self-optimal, then there is no other controller that can uniformly improve on the tradeoÔ¨Ä‚Äîany
other controller just achieves some other tradeoÔ¨Ä. What makes self-optimality so useful is that it
is very easily checked, and the loopshaping methods introduced so far generally yield self-optimal
controllers.
Unfortunately, the designer may Ô¨Ånd that for some problems loopshaping does not easily lead
to a reasonable tradeoÔ¨Äbetween competing performance objectives. It is for these problems that
directly solving for an optimal controller is most useful. Optimal controllers are the subject of the
remainder of this book.
Exercises
1. Verify the Venn diagrams in Section 8.5.
2. Prove that if #i(Lo ‚àí1) ‚â•1, then Co is self-optimal.
3. Develop notions of self-optimality that involving S and T separately, and prove results anal-
ogous to Theorem 1.
Notes and References
The problem setup in Section 8.1 is studied in much greater depth in McFarlane and Glover (1990),
who develop an interesting theory of control design using a combination of loopshaping and opti-
mality. For a recent treatment of the control of Ô¨Çexible structures, see Joshi (1989). Controller
design by shaping Q, known in the process control literature as internal model control (IMC), is
developed in detail in Morari and ZaÔ¨Åriou (1989). Section 8.5 is based on Lenz et al. (1988).

Chapter 9
Model Matching
This chapter studies a hypothetical control problem called the model-matching problem which will
be used in later chapters for control system design. The mathematics of interpolation theory is used
to solve the model-matching problem.
9.1
The Model-Matching Problem
Let T1(s) and T2(s) be stable proper transfer functions (i.e., functions in S). The model-matching
problem is to Ô¨Ånd a stable transfer function Q(s) to minimize the ‚àû-norm of T1 ‚àíT2Q.
The
interpretation is this: T1 is a model, T2 is a plant, and Q is a cascade controller to be designed so
that T2Q approximates T1. Thus T1 ‚àíT2Q is the error transfer function. The transfer function Q
is required to be stable but not necessarily proper (this makes the problem easier). We will assume
that T2 has no zeros on the imaginary axis. DeÔ¨Åne the minimum model-matching error
Œ≥opt := min ‚à•T1 ‚àíT2Q‚à•‚àû,
where the minimum is taken over all stable Qs. It turns out that the minimum is achieved by virtue
of the assumption on T2; a Q achieving the minimum is said to be optimal.
The trivial case of the problem is when T1/T2 is stable, for then the unique optimal Q is
Q = T1/T2 and Œ≥opt = 0. The simplest nontrivial case is when T2 has only one zero in the right
half-plane, say at s = s0. If Q is stable and T2Q has Ô¨Ånite ‚àû-norm (i.e., T2Q ‚ààS), then by the
maximum modulus theorem
‚à•T1 ‚àíT2Q‚à•‚àû‚â•|T1(s0)|,
so Œ≥opt ‚â•|T1(s0)|. On the other hand, the function
Q = T1 ‚àíT1(s0)
T2
(9.1)
is stable and yields the value |T1(s0)| for the model-matching error. The conclusion is that Œ≥opt =
|T1(s0)| and (9.1) is an optimal Q, in fact, the unique optimal Q.
Example For
T1(s) =
4
s + 3,
T2(s) =
s ‚àí2
(s + 1)3
149

150
CHAPTER 9. MODEL MATCHING
Œ≥opt = T1(2) = 4/5 and the optimal Q is
Q(s) = ‚àí4(s + 1)3
5(s + 3) .
To solve the problem in the general case we will need the mathematics developed in the next
two sections.
9.2
The Nevanlinna-Pick Problem
Recall that S stands for the space of stable, proper, real-rational functions. Let Sc stand for the
space of stable, proper, complex-rational functions (i.e., the coeÔ¨Écients are permitted to be complex
numbers). For example, the function
(1 ‚àíj)s + (2 + 3j)
(0.1 + j)s + (‚àí3 + j)
is in Sc because it is proper and its pole is at s = ‚àí0.6931 ‚àí3.0693j in the left half-plane. The
‚àû-norm, maximum magnitude on the imaginary axis, is deÔ¨Åned for such functions too.
Let {a1, . . . , an} be a set of points in the open right half-plane, Res > 0, and {b1, . . . , bn} a
set of points in C. For simplicity we shall assume that the points a1, . . . , an are distinct.
The
Nevanlinna-Pick interpolation problem, or the NP problem for short, is to Ô¨Ånd a function G in Sc
satisfying the two conditions
‚à•G‚à•‚àû‚â§1,
G(ai) = bi,
i = 1, . . . , n.
The latter equation says that G is to interpolate the value bi at the point ai, or in other words the
graph of G is to pass through the point (ai, bi). The constraints are important: G must be stable,
proper, and satisfy ‚à•G‚à•‚àû‚â§1. The NP problem is said to be solvable if such a function G exists.
It will be convenient to write the problem data as an array, like this:
a1
¬∑ ¬∑ ¬∑
an
b1
¬∑ ¬∑ ¬∑
bn
In fact, the NP problem is not solvable for all data. An obvious necessary condition for solvability
is |bi| ‚â§1, i = 1, . . . , n. This follows from the maximum modulus theorem: If G belongs to Sc and
satisÔ¨Åes G(ai) = bi, then its magnitude equals |bi| at the point s = ai, so its maximum magnitude
in the right half-plane is ‚â•|bi| (i.e., ‚à•G‚à•‚àû‚â•|bi|); but if it is also true that ‚à•G‚à•‚àû‚â§1, then |bi| ‚â§1.
To state precisely when the NP problem is solvable, we need some elementary concepts and facts
about complex matrices. Let M be a square complex matrix. Its complex-conjugate transpose is
denoted by M‚àó. If M = M‚àó, M is said to be a Hermitian matrix. If M is real, it is Hermitian
iÔ¨Äit is symmetric. It can be shown that the eigenvalues of a Hermitian matrix are all real. If
M is Hermitian, it is said to be positive semideÔ¨Ånite if x‚àóMx ‚â•0 for all complex vectors x, and
positive deÔ¨Ånite if x‚àóMx > 0 for all nonzero complex vectors x. The notation is M ‚â•0 and M > 0,
respectively. It is a fact that M ‚â•0 (respectively, M > 0) iÔ¨Äall its eigenvalues are ‚â•0 (respectively,
> 0).

9.2. THE NEVANLINNA-PICK PROBLEM
151
Example 1 The matrix

2
1 + j
1 ‚àíj
4

is Hermitian; notice that the diagonal elements must be real. The eigenvalues are 1.2679 and 4.7321.
Since these are both positive, the matrix is positive deÔ¨Ånite.
Associated with the NP problem data
a1
¬∑ ¬∑ ¬∑
an
b1
¬∑ ¬∑ ¬∑
bn
is the n √ó n matrix Q, whose ijth element is
1 ‚àíbibj
ai + aj
.
This is called the Pick matrix. Notice that Q is Hermitian.
Example 2 For the data
6 + j
6 ‚àíj
0.1 ‚àí0.1j
0.1 + 0.1j
the Pick matrix is

0.0817
0.0814 ‚àí0.0119j
0.0814 + 0.0119j
0.0817

,
whose eigenvalues are ‚àí0.0005 and 0.1639. Since one is negative, it turns out that the NP problem
is not solvable for these data.
Solvability of the NP problem is completely determined by the Pick matrix. The result is Pick‚Äôs
famous theorem:
Theorem 1 The NP problem is solvable iÔ¨ÄQ ‚â•0.
Pick‚Äôs theorem shows that it is an easy matter to check solvability of the NP problem by
computer: Input the data
a1
¬∑ ¬∑ ¬∑
an
b1
¬∑ ¬∑ ¬∑
bn
form the Pick matrix; compute its eigenvalues; see if the smallest one is nonnegative.
We saw above that a necessary condition for solvability is |bi| ‚â§1 for all i. So it must be that
this condition is implied by the condition Q ‚â•0. This is indeed the case: If Q ‚â•0, then each
diagonal element of Q is ‚â•0, that is,
1 ‚àí|bi|2
2Reai
‚â•0.

152
CHAPTER 9. MODEL MATCHING
Since Reai > 0, this implies that
1 ‚àí|bi|2 ‚â•0
(i.e., |bi| ‚â§1).
In the next section is given a procedure for constructing a solution to the NP problem when it
is solvable. The remainder of this section contains a proof of the necessity part of Pick‚Äôs theorem, a
proof that illustrates in system-theoretic terms how the Pick matrix arises. A system is said to be
dissipative if it dissipates energy‚Äîthe outgoing energy (2-norm squared) is less than or equal to the
incoming energy. The following proof shows that Pick‚Äôs theorem says something about dissipative
systems.
Since both time and frequency domains appear, the ÀÜ-convention is in force.
Also, complex-
valued signals and complex-rational transfer functions are used. There is no obstacle to extending
the material of Chapter 2 to the complex case.
The proof is separated into three lemmas.
Lemma 1 Consider a linear system with input signal u(t) of Ô¨Ånite 2-norm, output signal y(t), and
transfer function ÀÜG(s) in Sc. If ‚à•ÀÜG‚à•‚àû‚â§1, then
Z 0
‚àí‚àû
|y(t)|2dt ‚â§
Z 0
‚àí‚àû
|u(t)|2dt.
Proof DeÔ¨Åne a new input
u1(t) :=
 u(t),
if t ‚â§0
0,
if t > 0
and let the corresponding output be y1(t). It follows from entry (1,1) in Table 2.2 that
Z ‚àû
‚àí‚àû
|y1(t)|2dt ‚â§
Z ‚àû
‚àí‚àû
|u1(t)|2dt.
Since u1 = 0 for positive time, this implies that
Z ‚àû
‚àí‚àû
|y1(t)|2dt ‚â§
Z 0
‚àí‚àû
|u1(t)|2dt
and hence that
Z 0
‚àí‚àû
|y1(t)|2dt ‚â§
Z 0
‚àí‚àû
|u1(t)|2dt.
But y = y1 and u = u1 for negative time. ‚ñ†
The second lemma shows that complex exponentials are eigenfunctions for linear systems.
Lemma 2 Consider a linear system with transfer function ÀÜG(s) in Sc. Apply the input signal
u(t) = eat,
‚àí‚àû< t ‚â§0
with Rea > 0. Then the output signal is
y(t) = ÀÜG(a)u(t),
‚àí‚àû< t ‚â§0.

9.2. THE NEVANLINNA-PICK PROBLEM
153
Proof Use the convolution equation: For every t ‚â§0,
y(t)
=
Z ‚àû
0
G(œÑ)u(t ‚àíœÑ)dœÑ
=
Z ‚àû
0
G(œÑ)ea(t‚àíœÑ)dœÑ
=
ÀÜG(a)eat. ‚ñ†
The Ô¨Ånal lemma is the necessity part of Pick‚Äôs theorem.
Lemma 3 If the NP problem is solvable, then Q ‚â•0.
Proof To simplify notation, assume there are only two interpolation points (i.e., n = 2). Let ÀÜG be
a solution to the NP problem. For arbitrary complex numbers c1 and c2 apply the input signal
u(t) = c1ea1t + c2ea2t,
‚àí‚àû< t ‚â§0
to the system with transfer function ÀÜG. By Lemma 2 and linearity the output signal is
y(t)
=
c1 ÀÜG(a1)ea1t + c2 ÀÜG(a2)ea2t
=
c1b1ea1t + c2b2ea2t.
Starting with Lemma 1, we get in succession
Z 0
‚àí‚àû
|y(t)|2dt
‚â§
Z 0
‚àí‚àû
|u(t)|2dt,
Z 0
‚àí‚àû
|c1b1ea1t + c2b2ea2t|2dt
‚â§
Z 0
‚àí‚àû
|c1ea1t + c2ea2t|2dt,
and thus
Z 0
‚àí‚àû
h
c1c1(1 ‚àíb1b1)e(a1+a1)t + c1c2(1 ‚àíb1b2)e(a1+a2)t
+c2c1(1 ‚àíb2b1)e(a2+a1)t + c2c2(1 ‚àíb2b2)e(a2+a2)ti
dt ‚â•0.
This integral can be evaluated to give
c1c1
1 ‚àíb1b1
a1 + a1
+ c1c2
1 ‚àíb1b2
a1 + a2
+ c2c1
1 ‚àíb2b1
a2 + a1
+ c2c2
1 ‚àíb2b2
a2 + a2
‚â•0,
which is equivalent to
x‚àóQx ‚â•0,
where
x :=
 c1
c2

.
Since c1 and c2 were arbitrary, it must be that Q ‚â•0. ‚ñ†

154
CHAPTER 9. MODEL MATCHING
9.3
Nevanlinna‚Äôs Algorithm
This section presents a procedure to construct a solution of the NP problem when it is solvable.
The procedure is developed inductively: First, the case n = 1 is solved; then the case of n points is
reduced to the case of n ‚àí1 points.
Let us begin by letting D denote the open unit disk, |z| < 1, and D the closed unit disk, |z| ‚â§1.
A M¬®obius function has the form
Mb(z) = z ‚àíb
1 ‚àízb,
where |b| < 1. Following is a list of some properties of M¬®obius functions (you should check these):
1. Mb has a zero at z = b and a pole at z = 1/b. Thus Mb is analytic in D.
2. The magnitude of Mb equals 1 on the unit circle.
3. Mb maps D onto D and the unit circle onto the unit circle.
4. The inverse map is
M‚àí1
b
(z) = z + b
1 + zb
(i.e., M‚àí1
b
= M‚àíb). So the inverse map is a M¬®obius function too.
We will also need the all-pass function
Aa(s) := s ‚àía
s + a,
Rea > 0.
With the aid of these functions we can solve the NP problem for the data
a1
b1
There are two cases.
Case 1 |b1| = 1
A solution is G(s) = b1. By the maximum modulus theorem this solution is
unique.
Case 2 |b1| < 1 There are an inÔ¨Ånite number of solutions:
Lemma 4 The set of all solutions is
{G : G(s) = M‚àíb1[G1(s)Aa1(s)], G1 ‚ààSc, ‚à•G1‚à•‚àû‚â§1} .
If G1 is an all-pass function, so is G.

9.3. NEVANLINNA‚ÄôS ALGORITHM
155
Proof Let G1 ‚ààSc, ‚à•G1‚à•‚àû‚â§1, and deÔ¨Åne G as
G(s) = M‚àíb1[G1(s)Aa1(s)].
Thus G equals the composition of the two functions
s
7‚Üí
G1(s)Aa1(s),
z
7‚Üí
M‚àíb1(z).
The Ô¨Årst is analytic in the closed right half-plane and maps it into the closed disk D; the second is
analytic in D and maps it back into D. It follows that G ‚ààSc and ‚à•G‚à•‚àû‚â§1. Also, G interpolates
b1 at a1:
G(a1) = M‚àíb1[G1(a1)Aa1(a1)] = M‚àíb1(0) = b1.
Thus G solves the NP problem. Moreover, if G1 is an all-pass function, then so is G1Aa1, hence so
is G (because M‚àíb1 maps the unit circle onto itself).
Conversely, suppose that G solves the NP problem. DeÔ¨Åne G1 so that
G(s) = M‚àíb1[G1(s)Aa1(s)],
that is,
G1(s) = Mb1[G(s)]
Aa1(s)
.
The function Mb1[G(s)] belongs to Sc, has ‚àû-norm ‚â§1, and has a zero at s = a1. Therefore,
G1 ‚ààSc and ‚à•G1‚à•‚àû‚â§1. ‚ñ†
Example 1 For the interpolation data
2
0.6
the formula in the lemma gives
G(s) =
G1(s)s ‚àí2
s + 2 + 0.6
1 + 0.6G1(s)s ‚àí2
s + 2
.
The all-pass function G1(s) = (s ‚àí1)/(s + 1) results in
G(s) = s2 ‚àí0.75s + 2
s2 + 0.75s + 2.
Now we turn to the NP problem with n data points, the problem being assumed solvable, and
see how to reduce it to the case of n ‚àí1 points. Again, there are two cases.
Case 1 |b1| = 1 Since the problem is solvable, by the maximum modulus theorem it must be that
G(s) = b1 is the unique solution (and hence that b1 = ¬∑ ¬∑ ¬∑ = bn).

156
CHAPTER 9. MODEL MATCHING
Case 2 |b1| < 1 Pose a new problem, labeled the NP‚Ä≤ problem, with the n ‚àí1 data points
a2
¬∑ ¬∑ ¬∑
an
b‚Ä≤
2
¬∑ ¬∑ ¬∑
b‚Ä≤
n
where b‚Ä≤
i := Mb1(bi)/Aa1(ai).
Lemma 5 The set of all solutions to the NP problem is given by the formula
G(s) = M‚àíb1[G1(s)Aa1(s)],
where G1 ranges over all solutions to the NP‚Ä≤ problem. If G1 is all-pass, so is G.
Proof G solves the NP problem iÔ¨Ä
G ‚ààSc, ‚à•G‚à•‚àû‚â§1, G(a1) = b1, and G(ai) = bi,
i = 2, . . . , n.
From Lemma 4, the set of all Gs satisfying the Ô¨Årst three conditions is
{G : G(s) = M‚àíb1[G1(s)Aa1(s)], G1 ‚ààSc, ‚à•G1‚à•‚àû‚â§1} .
Then G satisÔ¨Åes the fourth condition iÔ¨Ä
G1(ai) = Mb1(bi)
Aa1(ai),
i = 2, . . . , n
(i.e., G1 solves the NP‚Ä≤ problem). ‚ñ†
It follows by induction that the NP problem always has an all-pass solution.
Example 2 Consider the NP problem for the data
a1
a2
a3
b1
b2
b3
=
1
2
3
1
2
1
3
1
4
The Pick matrix is
Ô£Æ
Ô£∞
0.3750
0.2778
0.2188
0.2778
0.2222
0.1833
0.2188
0.1833
0.1563
Ô£π
Ô£ª.
The smallest eigenvalue equals 0.0004. Since this is positive, the NP problem is solvable.
A solution can be obtained by reduction to one interpolation point by applying Lemma 5 twice.
First, reduce to the NP‚Ä≤ problem with two points:
a2
a3
b‚Ä≤
2
b‚Ä≤
3
=
2
3
‚àí0.6
‚àí0.5714
Here b‚Ä≤
i := Mb1(bi)/Aa1(ai), i = 2, 3. Second, reduce to the NP‚Ä≤‚Ä≤ problem with only one point:
a3
b‚Ä≤‚Ä≤
3
=
3
0.2174

9.3. NEVANLINNA‚ÄôS ALGORITHM
157
Here b‚Ä≤‚Ä≤
3 := Mb‚Ä≤
2(b‚Ä≤
3)/Aa2(a3).
Now solve the problems in reverse order. By Lemma 4 the solution of the NP‚Ä≤‚Ä≤ problem is
G2(s) = M‚àíb‚Ä≤‚Ä≤
3 [G3(s)Aa3(s)],
where G3 is an arbitrary function in Sc of ‚àû-norm ‚â§1. Let‚Äôs take G3(s) = 1, the simplest all-pass
function. Then
G2(s) = 1.2174s ‚àí2.3478
1.2174s + 2.3478.
The induced solution to the NP‚Ä≤ problem is
G1(s) = M‚àíb‚Ä≤
2[G2(s)Aa2(s)] = 0.4870s2 ‚àí7.6522s + 1.8783
0.4870s2 + 7.6522s + 1.8783.
Finally, the solution to the NP problem is
G(s) = M‚àíb1[G1(s)Aa1(s)] = 0.7304s3 ‚àí4.0696s2 + 14.2957s ‚àí0.9391
0.7304s3 + 4.0696s2 + 14.2957s + 0.9391.
Notice that the degree of the numerator and denominator of G equals 3, the number of data points.
In general, there always exists an all-pass solution of degree ‚â§n.
In our application of NP theory to the model-matching problem, the data
a1
¬∑ ¬∑ ¬∑
an
b1
¬∑ ¬∑ ¬∑
bn
will have conjugate symmetry; that is, if (ai, bi) appears, so will the conjugate pair (ai, bi). Then
we will want the solution G to be real-rational instead of complex. Suppose that the data do have
conjugate symmetry and that G is a solution in Sc. It can be written uniquely as
G(s) = GR(s) + jGI(s),
where GR and GI both are real-rational. Then GR belongs to S and is also a solution to the NP
problem (the proof is left as an exercise).
Example 3 For the data
5 + 2j
5 ‚àí2j
0.1 ‚àí0.1j
0.1 + 0.1j
the NP problem is solvable (the smallest eigenvalue of the Pick matrix equals 0.0051). Starting
from the all-pass function 1, Nevanlinna‚Äôs algorithm produces the all-pass solution
G(s) = (0.5268 + 0.1213j)s2 ‚àí(9 + j)s + (47.1073 + 1.1410j)
(0.5268 ‚àí0.1213j)s2 + (9 ‚àíj)s + (47.1073 ‚àí1.1410j).
Let G denote the function obtained from G by conjugating all coeÔ¨Écients. The function GR is then
GR = 1
2(G + G),
that is,
GR(s) =
0.2628s4 ‚àí30.6418s2 + 2217.7975
0.2923s4 + 9.7255s3 + 131.9119s2 + 850.2137s + 2220.4012.
This solution is not all-pass.

158
CHAPTER 9. MODEL MATCHING
9.4
Solution of the Model-Matching Problem
Now let‚Äôs see how to use NP theory to solve the model-matching problem. For simplicity we will
assume that T2 has no repeated zeros in the right half-plane. The minimum model-matching error,
Œ≥opt, equals the minimum Œ≥ such that
‚à•T1 ‚àíT2Q‚à•‚àû‚â§Œ≥
for some stable Q. Fix Œ≥ > 0 and consider the mapping Q 7‚ÜíG deÔ¨Åned by
G = 1
Œ≥ (T1 ‚àíT2Q).
If Q is stable, so is G, but the converse is not always true. A stable function G must satisfy certain
conditions in order that Q be stable. To see what they are, let {zi : i = 1, . . . , n} denote the zeros
of T2 in Res > 0. If Q is stable, then G satisÔ¨Åes the interpolation conditions
G(zi) = 1
Œ≥ T1(zi),
i = 1, . . . , n.
You can check that, conversely, if G is stable and satisÔ¨Åes these interpolation conditions, then Q is
stable.
Therefore, Œ≥opt equals the minimum Œ≥ so that there exists a function G in S satisfying the
conditions
‚à•G‚à•‚àû‚â§1,
G(zi) = 1
Œ≥ T1(zi),
i = 1, . . . , n.
This is precisely a Nevanlinna-Pick problem with data
a1
¬∑ ¬∑ ¬∑
an
Œ≥‚àí1b1
¬∑ ¬∑ ¬∑
Œ≥‚àí1bn
where ai := zi and bi := T1(zi). The associated Pick matrix equals
A ‚àíŒ≥‚àí2B,
where the ijth elements of A and B are, respectively,
1
ai + aj
,
bibj
ai + aj
.
From Pick‚Äôs theorem we can now conclude that Œ≥opt equals the minimum Œ≥ such that A‚àíŒ≥‚àí2B ‚â•0.
Both A and B are Hermitian. Furthermore, it can be proved that A is positive deÔ¨Ånite because
the ais are distinct. Such a matrix has a positive deÔ¨Ånite squareroot (i.e., a matrix A1/2 satisfying
A1/2A1/2 = A). The inverse of this squareroot is denoted A‚àí1/2.
The next lemma, a simple result in matrix theory, gives an explicit way to compute Œ≥opt.
Lemma 6 Œ≥opt equals the squareroot of the largest eigenvalue of the matrix A‚àí1/2BA‚àí1/2.

9.4. SOLUTION OF THE MODEL-MATCHING PROBLEM
159
Tracing backwards, we get the following procedure for solving the model-matching problem.
Procedure
Input: T1, T2
Step 1 Determine {zi : i = 1, . . . , n}, the zeros of T2 in Res > 0.
Step 2 DeÔ¨Åne
bi := T1(zi),
i = 1, . . . , n
and form the matrices
A :=

1
zi + zj

,
B :=
 bibj
zi + zj

.
Step 3 Compute Œ≥opt as the squareroot of the largest eigenvalue of A‚àí1/2BA‚àí1/2.
Step 4 Solve the NP problem with data
z1
¬∑ ¬∑ ¬∑
zn
Œ≥‚àí1
optb1
¬∑ ¬∑ ¬∑
Œ≥‚àí1
optbn
Denote the solution by G.
Step 5 Set
Q := T1 ‚àíŒ≥optG
T2
.
The NP problem in Step 4 has a unique, all-pass solution. Thus, for the optimal Q the error
transfer function T1 ‚àíT2Q equals Œ≥opt times an all-pass function.
Example 4 The procedure applied to
T1(s) =
s + 1
10s + 1,
T2(s) = (s ‚àí1)(s ‚àí5)
(s + 2)2
goes like this:
Step 1
z1 = 1,
z2 = 5
Step 2
b1 = 2
11,
b2 = 2
17
A =

0.5
0.1667
0.1667
0.1

,
B =
 0.0165
0.0036
0.0036
0.0014


160
CHAPTER 9. MODEL MATCHING
Step 3
Œ≥opt = 0.2021
Step 4
z1
z2
Œ≥‚àí1
optb1
Œ≥‚àí1
optb2
=
1
5
0.8997
0.5821
G(s) = ‚àí1.0035s + 18.9965
1.0035s + 18.9965
Step 5
Q(s) = 0.3021s2 + 1.2084s + 1.2084
s2 + 19.0308s + 1.8931
9.5
State-Space Solution (Optional)
For completeness, this section presents a state-space procedure for solving the model-matching
problem. The underlying theory is beyond the scope of this book.
Step 1 Factor T2 as the product of an all-pass factor and a minimum-phase factor:
T2 = T2apT2mp.
Step 2 DeÔ¨Åne
R := T1
T2ap
,
factor R as R = R1 + R2 with R1 strictly proper and all poles in Res > 0 and R2 ‚ààS, and
Ô¨Ånd a minimal realization
R1(s) =
 A
B
C
0

.
Step 3 Solve the Lyapunov equations
ALc + LcA‚Ä≤
=
BB‚Ä≤,
A‚Ä≤Lo + LoA
=
C‚Ä≤C.
Step 4 Find the maximum eigenvalue Œª2 of LcLo and a corresponding eigenvector w.
Step 5 DeÔ¨Åne
f(s)
=
 A
w
C
0

,
g(s)
=
 ‚àíA‚Ä≤
Œª‚àí1Low
B‚Ä≤
0

,
X
=
R ‚àíŒªf
g .

9.5. STATE-SPACE SOLUTION (OPTIONAL)
161
Step 6 Then Œ≥opt = Œª and the optimal Q = X/T2mp.
Example For the same data as in Example 4 in the preceding section, the procedure yields the
following results.
Step 1
T2ap(s) = (s ‚àí1)(s ‚àí5)
(s + 1)(s + 5),
T2mp(s) = (s + 1)(s + 5)
(s + 1)2
Step 2
R(s) =
(s + 1)2(s + 5)
(10s + 1)(s ‚àí1)(s ‚àí5)
A =
 1
0
0
5

,
B =
 ‚àí6
11
30
17

,
C =

1
1

Step 3
Lc =

0.1488
‚àí0.1604
‚àí0.1604
0.3114

,
Lo =

0.5
0.1667
0.1667
0.1

Step 4
Œª = 0.2021,
w =

1
‚àí0.7769

Step 5
f(s) = 0.2231s ‚àí4.223
(s ‚àí1)(s ‚àí5) ,
g(s) = ‚àí0.2231s ‚àí4.223
(s + 1)(s + 5)
X(s) = 3.021
(s + 1)(s + 5)
(10s + 1)(s + 18.93)
Step 6
Œ≥opt = 0.2021,
Q(s) = 3.021
(s + 2)2
(10s + 1)(s + 18.93)
Exercises
1. Solve the model-matching problem for
T1(s) =
s
s + 10,
T2(s) =
s ‚àí1
s2 + s + 1.

162
CHAPTER 9. MODEL MATCHING
2. For the data
1
1 ‚àíj
j
‚àí1 + 2j
form the Pick matrix and compute its eigenvalues.
3. Find the minimum Œ≥ for which there exists a function G in Sc such that
‚à•G‚à•‚àû‚â§Œ≥,
G(1) = 2,
G(2) = 10.
4. Solve the model-matching problem for
T1(s) =
1
s + 1,
T2(s) = s2 ‚àís + 1
(s + 2)3 .
5. Compute a real-rational solution to the NP problem for the data
1
1 ‚àíj
1 + j
0.1
0.2j
‚àí0.2j
6. Let A and B be n √ó n complex Hermitian matrices with A > 0. Prove that A ‚àíŒ≥‚àí2B ‚â•0 iÔ¨Ä
Œ≥2 is ‚â•the largest eigenvalue of A‚àí1/2BA‚àí1/2. (This proves Lemma 6.)
Notes and References
The NP problem is named after the mathematicians R. Nevanlinna and G. Pick, whose work dates
from 1916-1919. For a complete proof of Pick‚Äôs theorem together with additional references, see
Garnett (1981).
In the model-matching problem, zeros of T2 on the imaginary axis lead to boundary interpolation
in the NP problem (i.e., some of ais are on the imaginary axis). This complicates the NP problem;
a reference for this case is Khargonekar and Tannenbaum (1985).
The proof of necessity in Section 9.2 is from Youla and Saito (1967), and Nevanlinna‚Äôs algo-
rithm is taken from Walsh (1969). NP theory was Ô¨Årst used in the context of control problems by
Tannenbaum (1980, 1981). The state-space procedure in Section 9.5 is from Francis (1987), which
in turn is adapted from Sarason (1967) and Silverman and Bettayeb (1980).

Chapter 10
Design for Performance
The performance criterion ‚à•W1S‚à•‚àû< 1 was introduced in Section 3.4.
The associated design
problem is to Ô¨Ånd a proper C for which the feedback system is internally stable and ‚à•W1S‚à•‚àû< 1.
When does such a C exist and how can it be computed?
These questions are easy when the
inverse of the plant transfer function is stable. When the inverse is unstable, the questions are more
interesting. The solutions presented in this chapter use model-matching theory.
10.1
P ‚àí1 Stable
We assume in this section that P has no zeros in Res ‚â•0, or in other words, P ‚àí1 is stable. The
weighting function W1 is assumed to be stable and strictly proper. The latter condition is not too
serious a loss of generality. We will see that under these conditions it is always possible, indeed
quite easy, to design a proper C which is internally stabilizing and makes ‚à•W1S‚à•‚àû< 1.
Let k be a positive integer and œÑ a positive real number, and consider the transfer function
J(s) :=
1
(œÑs + 1)k .
Sketch the Bode plot of J: The magnitude starts out at 1, is relatively Ô¨Çat out to the corner
frequency œâ = 1/œÑ, and then rolls oÔ¨Äto ‚àí‚àûwith slope ‚àík; the phase starts out at 0, is relatively
Ô¨Çat up to, say, œâ = 0.1/œÑ, and then rolls oÔ¨Äto ‚àíkœÄ/2 radians. So for low frequency, J(jœâ) ‚âà1.
This function has the useful property that it approximates 1 beside a strictly proper function.
Lemma 1 If G is stable and strictly proper, then
lim
œÑ‚Üí0 ‚à•G(1 ‚àíJ)‚à•‚àû= 0.
Proof Let «´ > 0 and œâ1 > 0. By the argument above regarding the Bode plot of J, if œÑ is suÔ¨Éciently
small, then the Nyquist plot of J lies in the disk with center 1, radius «´ for œâ ‚â§œâ1, and in the disk
with center 0, radius 1 for œâ > œâ1. Now ‚à•G(1 ‚àíJ)‚à•‚àûequals the maximum of
max
œâ‚â§œâ1 |G(jœâ)[1 ‚àíJ(jœâ)]|
and
max
œâ>œâ1 |G(jœâ)[1 ‚àíJ(jœâ)]|.
163

164
CHAPTER 10. DESIGN FOR PERFORMANCE
The Ô¨Årst of these is bounded above by «´‚à•G‚à•‚àû, and the second by
‚à•1 ‚àíJ‚à•‚àûmax
œâ>œâ1 |G(jœâ)|.
Since
‚à•1 ‚àíJ‚à•‚àû‚â§‚à•1‚à•‚àû+ ‚à•J‚à•‚àû= 2,
we have
‚à•G(1 ‚àíJ)‚à•‚àû‚â§max

«´‚à•G‚à•‚àû, 2 max
œâ>œâ1 |G(jœâ)|

.
This holds for œÑ suÔ¨Éciently small. But the right-hand side can be made arbitrarily small by suitable
choice of «´ and œâ1 because
lim
œâ1‚Üí‚àûmax
œâ>œâ1 |G(jœâ)| = |G(j‚àû)| = 0.
We conclude that for every Œ¥ > 0, if œÑ is small enough, then
‚à•G(1 ‚àíJ)‚à•‚àû‚â§Œ¥.
This is the desired conclusion. ‚ñ†
We‚Äôll develop the design procedure Ô¨Årst with the additional assumption that P is stable. By
Theorem 5.1 the set of all internally stabilizing Cs is parametrized by the formula
C =
Q
1 ‚àíPQ,
Q ‚ààS.
Then W1S is given in terms of Q by
W1S = W1(1 ‚àíPQ).
To make ‚à•W1S‚à•‚àû< 1 we are prompted to set Q = P ‚àí1. This is indeed stable, by assumption, but
not proper, hence not in S. So let‚Äôs try Q = P ‚àí1J with J as above and the integer k just large
enough to make P ‚àí1J proper (i.e., k equals the relative degree of P). Then
W1S = W1(1 ‚àíJ),
whose ‚àû-norm is < 1 for suÔ¨Éciently small œÑ, by Lemma 1.
In summary, the design procedure is as follows.
Procedure: P and P ‚àí1 Stable
Input: P, W1
Step 1 Set k = the relative degree of P.

10.1. P ‚àí1 STABLE
165
Step 2 Choose œÑ so small that
‚à•W1(1 ‚àíJ)‚à•‚àû< 1,
where
J(s) :=
1
(œÑs + 1)k .
Step 3 Set Q = P ‚àí1J.
Step 4 Set C = Q/(1 ‚àíPQ).
When P is unstable, the parametrization in Theorem 5.2 is used.
Procedure: P ‚àí1 Stable
Input: P, W1
Step 1 Do a coprime factorization of P: Find four functions in S satisfying the equations
P = N
M ,
NX + MY = 1.
Step 2 Set k = the relative degree of P.
Step 3 Choose œÑ so small that
‚à•W1MY (1 ‚àíJ)‚à•‚àû< 1,
where
J(s) :=
1
(œÑs + 1)k .
Step 4 Set Q = Y N‚àí1J.
Step 5 Set C = (X + MQ)/(Y ‚àíNQ).
Example Consider the unstable plant and weighting function
P(s) =
1
(s ‚àí2)2 ,
W1(s) = 100
s + 1.
This weight has bandwidth 1 rad/s, so it might be used to get good tracking (i.e., approximately
1% tracking error, up to this frequency). The previous procedure for these data goes as follows:

166
CHAPTER 10. DESIGN FOR PERFORMANCE
Step 1 First, do a coprime factorization of P over S:
N(s)
=
1
(s + 1)2 ,
M(s)
=
(s ‚àí2)2
(s + 1)2 ,
X(s)
=
27s ‚àí1
s + 1,
Y (s)
=
s + 7
s + 1.
Step 2 k = 2
Step 3 Choose œÑ so that the ‚àû-norm of
100(s ‚àí2)2(s + 7)
(s + 1)4

1 ‚àí
1
(œÑs + 1)2

is < 1. The norm is computed for decreasing values of œÑ:
œÑ
‚àû-Norm
10‚àí1
199.0
10‚àí2
19.97
10‚àí3
1.997
10‚àí4
0.1997
So take œÑ = 10‚àí4.
Step 4
Q(s) = (s + 1)(s + 7)
(10‚àí4s + 1)2
Step 5
C(s) = 104
(s + 1)3
s(s + 7)(10‚àí4s + 2)
This section concludes with a result stated but not proved in Section 6.2.
It concerns the
performance problem where the weight W1 satisÔ¨Åes
|W1(jœâ)| =
Ô£±
Ô£¥
Ô£≤
Ô£¥
Ô£≥
1
«´ ,
œâ1 ‚â§œâ ‚â§œâ2
1
Œ¥ ,
else.
Thus the criterion ‚à•W1S‚à•‚àû< 1 is equivalent to the conditions
|S(jœâ)| < «´,
œâ1 ‚â§œâ ‚â§œâ2
|S(jœâ)| < Œ¥,
else.
(10.1)

10.1. P ‚àí1 STABLE
167
Lemma 2 If P ‚àí1 is stable, then for every «´ > 0 and Œ¥ > 1, there exists a proper C such that the
feedback system is internally stable and (10.1) holds. 1
Proof The idea is to approximately invert P over the frequency range [0, œâ2] while rolling oÔ¨Äfast
enough at higher frequencies. From Theorem 5.2 again, the formula for all internally stabilizing
proper controllers is
C = X + MQ
Y ‚àíNQ ,
Q ‚ààS.
For such C
S = M(Y ‚àíNQ).
(10.2)
Now Ô¨Åx «´ > 0 and Œ¥ > 1. We may as well suppose that «´ < 1. Choose c > 0 so small that
c‚à•MY ‚à•‚àû< «´,
(10.3)
(1 + c)2 < Œ¥.
(10.4)
Since P is strictly proper, so is N. This fact together with the equation
NX + MY = 1
shows that
M(j‚àû)Y (j‚àû) = 1.
Since |M(jœâ)Y (jœâ)| is a continuous function of œâ, it is possible to choose œâ3 ‚â•œâ2 such that
|M(jœâ)Y (jœâ)| ‚â§1 + c,
‚àÄœâ ‚â•œâ3.
(10.5)
The assumption on P implies that N ‚àí1 is stable (but not proper). Choose a function V in S
with the following three properties:
1. V N ‚àí1 is proper.
2. |1 ‚àíV (jœâ)| ‚â§c,
‚àÄœâ ‚â§œâ3.
3. ‚à•1 ‚àíV ‚à•‚àû‚â§1 + c.
The idea behind the choice of V can be explained in terms of its Nyquist plot: It should lie in the
disk with center 1, radius c up to frequency œâ3 (property 2) and in the disk with center 1, radius
1 + c thereafter (property 3). In addition, V should roll oÔ¨Äfast enough so that V N ‚àí1 is proper. It
is left as an exercise to convince yourself that such a V exists‚Äîa function of the form
1
(œÑ1s + 1)(œÑ2s + 1)k
will work.
1The assumption on P in Lemma 2 is slightly stronger than necessary; see the statement in Section 6.2.

168
CHAPTER 10. DESIGN FOR PERFORMANCE
Finally, take Q to be
Q := V N ‚àí1Y.
Substitution into (10.2) gives
S = MY (1 ‚àíV ).
Thus for œâ ‚â§œâ3
|S(jœâ)|
‚â§
c‚à•MY ‚à•‚àû
from proprty 2
<
«´
from (10.3)
and for œâ > œâ3
|S(jœâ)|
‚â§
(1 + c)|M(jœâ)Y (jœâ)|
from property 3
‚â§
(1 + c)2
from (10.5)
<
Œ¥
from (10.4). ‚ñ†
10.2
P ‚àí1 Unstable
We come now to the Ô¨Årst time in this book that we need a nonclassical method, namely, interpolation
theory. To simplify matters we will assume in this section that
‚Ä¢ P has no poles or zeros on the imaginary axis, only distinct poles and zeros in the right
half-plane, and at least one zero in the right half-plane (i.e., P ‚àí1 is unstable).
‚Ä¢ W1 is stable and strictly proper.
It would be possible to relax these assumptions, but the development would be messier.
To motivate the procedure to follow, let‚Äôs see roughly how the design problem of Ô¨Ånding an
internally stabilizing C so that ‚à•W1S‚à•‚àû< 1 can be translated into an NP problem. The deÔ¨Ånition
of S is
S =
1
1 + PC .
For C to be internally stabilizing it is necessary and suÔ¨Écient that S ‚ààS and PC have no right
half-plane pole-zero cancellations (Theorem 3.2). Thus, S must interpolate the value 1 at the right
half-plane zeros of P and the value 0 at the right half-plane poles (see also Section 6.1); that is, S
must satisfy the conditions
S(z)
=
1 for z a zero of P in Res > 0,
S(p)
=
0 for p a pole of P in Res > 0.
The weighted sensitivity function G := W1S must therefore satisfy
G(z)
=
W1(z) for z a zero of P in Res > 0,
G(p)
=
0 for p a pole of P in Res > 0.

10.2. P ‚àí1 UNSTABLE
169
So the requirement of internal stability imposes interpolation constraints on G. The performance
spec ‚à•W1S‚à•‚àû< 1 translates into ‚à•G‚à•‚àû< 1. Finally, the condition S ‚ààS requires that G be
analytic in the right half-plane.
One approach to the design problem might be to Ô¨Ånd a function G satisfying these conditions,
then to get S, and Ô¨Ånally to get C by back-substitution. This has a technical snag because the
requirement that C be proper places an additional constraint on G not handled by our NP theory
of the Chapter 9. For this reason we proceed via controller parametrization.
Bring in again a coprime factorization of P:
P = N
M ,
NX + MY = 1.
The controller parametrization formula is
C = X + MQ
Y ‚àíNQ ,
Q ‚ààS,
and for such C the weighted sensitivity function is
W1S = W1M(Y ‚àíNQ).
The parameter Q must be both stable and proper. Our approach is Ô¨Årst to drop the properness
requirement and Ô¨Ånd a suitable parameter, say, Qim, which is improper but stable, and then to get a
suitable Q by rolling Qim oÔ¨Äat high frequency. The reason this works is that W1 is strictly proper,
so there is no performance requirement at high frequency. The method is outlined as follows:
Procedure
Input: P, W1
Step 1 Do a coprime factorization of P: Find four functions in S satisfying the equations
P = N
M ,
NX + MY = 1.
Step 2 Find a stable function Qim such that
‚à•W1M(Y ‚àíNQim)‚à•‚àû< 1.
Step 3 Set
J(s) :=
1
(œÑs + 1)k ,
where k is just large enough that QimJ is proper and œÑ is just small enough that
‚à•W1M(Y ‚àíNQimJ)‚à•‚àû< 1.
Step 4 Set Q = QimJ.

170
CHAPTER 10. DESIGN FOR PERFORMANCE
Step 5 Set C = (X + MQ)/(Y ‚àíNQ).
That Step 3 is feasible follows from the equation
W1M(Y ‚àíNQimJ) = W1M(Y ‚àíNQim)J + W1MY (1 ‚àíJ).
The Ô¨Årst term on the right-hand side has ‚àû-norm less than 1 from Step 2 and the fact that
‚à•J‚à•‚àû‚â§1, while the ‚àû-norm of the second term goes to 0 as œÑ goes to 0 by Lemma 1.
Step 2 is the model-matching problem, Ô¨Ånd a stable function Qim to minimize
‚à•T1 ‚àíT2Qim‚à•‚àû,
where T1 := W1MY and T2 := W1MN. Step 2 is feasible iÔ¨ÄŒ≥opt, the minimum model-matching
error, is < 1.
10.3
Design Example: Flexible Beam
This section presents an example to illustrate the procedure of the preceding section. The example
is based on a real experimental setup at the University of Toronto.
The control system, depicted in Figure 10.1, has the following components: a Ô¨Çexible beam, a
high-torque dc motor at one end of the beam, a sonar position sensor at the other end, a digital
computer as the controller with analog-to-digital interface hardware, a power ampliÔ¨Åer to drive the
motor, and an antialiasing Ô¨Ålter. The objective is to control the position of the sensed end of the
beam.
PC
D/A
amp
motor
beam
A/D
Ô¨Ålter
sensor
-
-
-
-
-



6
Figure 10.1: Flexible beam setup.
A plant model was obtained as follows. The beam is pinned to the motor shaft and is free at the
sensed end. First the beam itself was modeled as an ideal Euler-Bernoulli beam with no damping;
this yielded a partial diÔ¨Äerential equation model, reÔ¨Çecting the fact that the physical model of the
beam has an inÔ¨Ånite number of modes. The model is therefore linear but inÔ¨Ånite-dimensional. The
corresponding transfer function from torque input at the motor end to tip deÔ¨Çection at the sensed
end has the form
‚àû
X
i=0
ci
s2 + œâ2
i
.

10.3. DESIGN EXAMPLE: FLEXIBLE BEAM
171
Then damping was introduced, yielding the form
‚àû
X
i=0
ci
s2 + 2Œ∂iœâis + œâ2
i
.
The Ô¨Årst term is c0/s2 and corresponds to the rigid-body slewing motion about the pinned end.
The second term,
c1
s2 + 2Œ∂1œâ1s + œâ2
1
,
corresponds to the Ô¨Årst Ô¨Çexible mode. And so on. The motion was found to be adequately modeled
by the Ô¨Årst four Ô¨Çexible modes. Then the damping ratios and natural frequencies were determined
experimentally.
Finally, the ampliÔ¨Åer, motor, and sensor were introduced into the model. The
antialiasing Ô¨Ålter was ignored for the purpose of design.
For simplicity we shall take the plant transfer function to be
P(s) =
‚àí6.4750s2 + 4.0302s + 175.7700
s(5s3 + 3.5682s2 + 139.5021s + 0.0929).
The poles are
0, ‚àí0.0007, ‚àí0.3565 ¬± 5.2700j.
The Ô¨Årst two poles correspond to the rigid-body motion; the one at s = ‚àí0.0007 has been perturbed
away from the origin by the back EMF in the motor. The two complex poles correspond to the Ô¨Årst
Ô¨Çexible mode, the damping ratio being 0.0675. The zeros are
‚àí4.9081, 5.5308.
Because of the zero at s = 5.5308 the plant is non-minimum phase, reÔ¨Çecting the fact that the
actuator (the motor) and the sensor are not located at the same point on the beam. The procedure
of the preceding section requires no poles on the imaginary axis, so the model is (harmlessly)
perturbed to
P(s) =
‚àí6.4750s2 + 4.0302s + 175.7700
5s4 + 3.5682s3 + 139.5021s2 + 0.0929s + 10‚àí6 .
A common way to specify desired closed-loop performance is by a step response test. For this
Ô¨Çexible beam the spec is that a step reference input (r) should produce a plant output (y) satisfying
settling time
‚âà
8s,
overshoot
‚â§
10%.
We will accomplish this by shaping T(s), the transfer function from r to y, so that it approximates
a standard second-order system: The ideal T(s) is
Tid(s) :=
œâ2
n
s2 + 2Œ∂œâns + œâ2n
.

172
CHAPTER 10. DESIGN FOR PERFORMANCE
A settling time of 8 s requires
4.6
Œ∂œân
‚âà8
and an overshoot of 10% requires
exp
 
‚àíŒ∂œÄ
p
1 ‚àíŒ∂2
!
= 0.1.
The solutions are Œ∂ = 0.5912 and œân = 0.9583. Let‚Äôs round to Œ∂ = 0.6 and œân = 1. So the ideal
T(s) is
Tid(s) =
1
s2 + 1.2s + 1.
Then the ideal sensitivity function is
Sid(s) := 1 ‚àíTid(s) =
s(s + 1.2)
s2 + 1.2s + 1.
Now take the weighting function W1(s) to be Sid(s)‚àí1, that is,
W1(s) = s2 + 1.2s + 1
s(s + 1.2)
.
The rationale for this choice is a rough argument that goes as follows.
Consider Step 2 of the
procedure in the preceding section; from it the function
F := W1M(Y ‚àíNQim)
equals a constant times an all-pass function. The procedure then rolls oÔ¨ÄQim to result in the
weighted sensitivity function
W1S := W1M(Y ‚àíNQimJ).
So W1S ‚âàF except at high frequency, that is,
S ‚âàFSid.
Now F behaves approximately like a time delay except at high frequency (this is a property of
all-pass functions). So we arrive at the rough approximation
S ‚âà(time delay) √ó Sid.
Hence our design should produce
actual step response ‚âàdelayed ideal step response.
One further adjustment is required in the problem setup: W1 must be stable and strictly proper,
so the function above is modiÔ¨Åed to
W1(s) =
s2 + 1.2s + 1
(s + 0.001)(s + 1.2)(0.001s + 1).
The procedure can now be applied.

10.3. DESIGN EXAMPLE: FLEXIBLE BEAM
173
Step 1 Since P ‚ààS we take N = P, M = 1, X = 0, Y = 1.
Step 2 The model-matching problem is to minimize
‚à•W1M(Y ‚àíNQim)‚à•‚àû= ‚à•W1(1 ‚àíPQim)‚à•‚àû.
Since P has only one right half-plane zero, at s = 5.5308, we have from Section 9.1
min ‚à•W1(1 ‚àíPQim)‚à•‚àû= |W1(5.5308)| = 1.0210.
Thus the spec ‚à•W1S‚à•‚àû< 1 is not achievable for this P and W1. Let us scale W1 as
W1 ‚Üê
0.9
1.0210W1.
Then |W1(5.5308)| = 0.9 and the optimal Qim is
Qim = W1 ‚àí0.9
W1P
,
that is,
Qim(s) = s(0.0008s5 + 0.0221s4 + 0.1768s3 + 0.7007s2 + 3.8910s + 0.0026)
s3 + 6.1081s2 + 6.8897s + 4.9801
.
Step 3 Set
J(s) :=
1
(œÑs + 1)3 .
Compute ‚à•W1(1 ‚àíPQimJ)‚à•‚àûfor decreasing values of œÑ until the norm is < 1:
œÑ
‚àû-Norm
0.1
1.12
0.05
1.01
0.04
0.988
Take œÑ = 0.04.
Step 4 Q = QimJ
Step 5 C = Q/(1 ‚àíPQ)
A Bode magnitude plot of the resulting sensitivity function is shown in Figure 10.2.
Figure 10.3
shows the step response of the plant output together with the ideal step response (i.e., that of Tid).
The performance specs are met.
The design above, while achieving the step response goal, may not be satisfactory for other
reasons; for example, internal signals may be too large (in fact, for this design the input to the
power ampliÔ¨Åer would saturate during the step response test). The problem is that we have placed
no limits on controller gain or bandwidth. We return to this example and see how to correct this
deÔ¨Åciency in Chapter 12.
Another disadvantage of the design above is that C is of high order.
The common way to
alleviate this is to approximate Q by a lower-order transfer function (it is diÔ¨Écult to reduce C
directly because of the internal stability constraint, whereas Q only has to be stable and proper).

174
CHAPTER 10. DESIGN FOR PERFORMANCE
10-3
10-2
10-1
100
101
10-5
10-4
10-3
10-2
10-1
100
101
102
103
104
Figure 10.2: Bode plot of |S|.
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
0
1
2
3
4
5
6
7
8
9
10
Figure 10.3: Actual (solid) and ideal (dash) step responses.

10.4. 2-NORM MINIMIZATION
175
10.4
2-Norm Minimization
The subject of this section is minimization of the 2-norm of some designated closed-loop transfer
function. As a typical case, we consider the transfer function from d to y, namely, PS. Motivation
for considering the 2-norm was presented in Section 2.3. For example, if d(t) is the unit impulse,
then the 2-norm of y(t) equals ‚à•PS‚à•2. Or, ‚à•PS‚à•2 equals the 2-norm to ‚àû-norm gain from d to y.
To make the problem more Ô¨Çexible, bring in a weighting function W‚Äîappropriate assumptions
on W will be introduced as required. The problem for consideration is: Given P and W, design an
internally stabilizing C to minimize ‚à•WPS‚à•2. The method of solution is again to parametrize all
internally stabilizing Cs and then to select an optimal parameter, but now optimal for the 2-norm.
We need some preliminaries. First, let S0 denote the subset of S of all strictly proper stable
transfer functions, S‚ä•
0 the set of strictly proper transfer functions analytic in Res ‚â§0, and S0 + S‚ä•
0
the set of all sums. Thus S0 + S‚ä•
0 consists precisely of all strictly proper transfer functions with
no poles on the imaginary axis. By Lemma 2.1 the 2-norm is Ô¨Ånite for all functions in S0 + S‚ä•
0 .
Furthermore, every function F in S0 + S‚ä•
0 can be uniquely expressed as
F = Fst + Fun,
Fst ‚ààS0, Fun ‚ààS‚ä•
0 ,
for example, by partial fraction expansion (Fst is stable, Fun is unstable).
Pythagoras‚Äôs theorem holds in this setting.
Lemma 3 If F ‚ààS0 and G ‚ààS‚ä•
0 , then
‚à•F + G‚à•2
2 = ‚à•F‚à•2
2 + ‚à•G‚à•2
2.
Proof
‚à•F + G‚à•2
2
=
1
2œÄ
Z
|F(jœâ) + G(jœâ)|2dœâ
=
‚à•F‚à•2
2 + ‚à•G‚à•2
2 + 2Re
 1
2œÄ
Z
F(jœâ)G(jœâ)dœâ

.
So it suÔ¨Éces to show the last integral equals zero. Convert it into a contour integral by closing the
imaginary axis with an inÔ¨Ånite-radius semicircle in the left half-plane:
1
2œÄ
Z
F(jœâ)G(jœâ)dœâ =
1
2œÄj
I
F(‚àís)G(s)ds.
But the right-hand side equals zero by Cauchy‚Äôs theorem. ‚ñ†
For the usual representations
P
=
N
M ,
NX + MY = 1,
C
=
X + MQ
Y ‚àíNQ ,
Q ‚ààS,
we have
WPS = WNY ‚àíWN 2Q.

176
CHAPTER 10. DESIGN FOR PERFORMANCE
So the problem reduces to: Obtain Q in S to minimize
‚à•WNY ‚àíWN 2Q‚à•2.
Evidently, this is a 2-norm model-matching problem. It is much easier than the ‚àû-norm version.
Let us now assume that W ‚ààS. The idea is to factor U := WN 2 as U = UapUmp. So that
the minimum-phase factor Ump has a stable inverse (so that we can back-solve for Q), assume in
addition that W and P have no zeros on the imaginary axis. Now we shall use the fact that Uap
has unit magnitude on the imaginary axis as follows. For Ô¨Åxed Q in S we have
‚à•WNY ‚àíWN 2Q‚à•2
2
=
‚à•WNY ‚àíUapUmpQ‚à•2
2
=
‚à•Uap(U‚àí1
ap WNY ‚àíUmpQ)‚à•2
2
=
‚à•U‚àí1
ap WNY ‚àíUmpQ‚à•2
2
=
‚à•(U‚àí1
ap WNY )un + (U‚àí1
ap WNY )st ‚àíUmpQ‚à•2
2
=
‚à•(U‚àí1
ap WNY )un‚à•2
2 + ‚à•(U‚àí1
ap WNY )st ‚àíUmpQ‚à•2
2.
Lemma 3 was used in the last equality. It is now clear that the unique optimal, generally improper
Q is
Qim = U‚àí1
mp(U‚àí1
ap WNY )st = (WN 2)‚àí1
mp

(WN 2)‚àí1
ap WNY

st
and the consequent minimum value of ‚à•WNY ‚àíWN 2Q‚à•2 equals ‚à•(U‚àí1
ap WNY )un‚à•2. This Qim must
be rolled oÔ¨Äat high frequency to get a proper suboptimal Q, just as in Section 10.1; the details are
routine and are therefore omitted.
Example In this example the 2-norm of the plant output y is minimized for a unit step disturbance
d. Thus W(s) = 1/s. A modiÔ¨Åcation of the derivation above is required because this W is unstable.
Take
P(s) =
1 ‚àís
s2 + s + 2.
This being stable, we should take
C =
Q
1 ‚àíPQ,
Q ‚ààS.
Temporarily relax the requirement that Q be proper. The function whose 2-norm is to be minimized
is
WPS = WP(1 ‚àíPQ).
(10.6)
For this to have Ô¨Ånite 2-norm we must guarantee that P(1 ‚àíPQ) has a zero at s = 0 to cancel the
pole of W; this requires 1 ‚àíPQ to have a zero at s = 0, that is, Q(0) = 1/P(0) = 2. The set of all
stable Qs satisfying Q(0) = 2 is
Q(s) = 2 + sQ1(s),
Q1 stable.
Substitute this into (10.6) to get
WPS = T ‚àíUQ1,

10.4. 2-NORM MINIMIZATION
177
where
T(s)
:=
W(s)P(s)[1 ‚àí2P(s)]
=
(1 ‚àís)(s + 3)
(s2 + s + 2)2 ,
U(s)
:=
P(s)2
=
(1 ‚àís)2
(s2 + s + 2)2 .
Then as above, the optimal improper Q1 equals U‚àí1
mp(U‚àí1
ap T)st, that is,
Q1im(s) = (s2 + s + 2)2
(s + 1)2
(s + 1)2
1 ‚àís
(1 ‚àís)(s + 3)
(s2 + s + 2)2

st
= s3 + 2s2 + 2s ‚àí1
(s + 1)2
.
To get a proper Q, this should be made strictly proper, so set
Q1(s) = s3 + 2s2 + 2s ‚àí1
(œÑs + 1)2(s + 1)2 .
Then
Q(s) = 2 + ss3 + 2s2 + 2s ‚àí1
(œÑs + 1)2(s + 1)2 .
As œÑ ‚Üí0, this Q recovers optimality of ‚à•WPS‚à•2.
Exercises
1. Design a controller to achieve ‚à•W1S‚à•‚àû< 1 for
P(s)
=
s ‚àí1
(s + 1)2 ,
W1(s)
=
0.62
s2 + 1.2s + 1
(s + 0.001)(s + 1.2)(0.001s + 1).
Plot the resulting step response of the plant output.
2. Take
P(s) = (s ‚àí1)(s ‚àí2)
(s + 1)3
,
W1(s) =
a
100s + 1.
Design a controller to achieve ‚à•W1S‚à•‚àû< 1. You‚Äôll have to adjust the parameter a so that
the spec is achievable. Sketch Bode plots of |S|, |W1|, and |CS|.
3. Repeat with
P(s) =
s ‚àí1
(s ‚àí2)(s + 1).

178
CHAPTER 10. DESIGN FOR PERFORMANCE
4. This problem looks at performance design with P minimum phase but having a pole on the
imaginary axis. Take
P(s) = 1
s,
W1(s) = 100
s + 1.
(a) Perturb P to P(s) = 1/(s + «´), «´ > 0. Find a controller C (internally stabilizing) so that
‚à•W1S‚à•‚àû< 1. Let «´ go to zero in the coeÔ¨Écients of C. Does the resulting C solve the
performance design problem for the original P?
(b) Factor P as
P = P1P2,
P1(s) =
1
s + 1,
P2(s) = s + 1
s
.
Solve the performance design problem for P1; let C1 be the solution. Set C = C1/P2.
Does the resulting C solve the performance design problem for the original P? If so,
explain why.
5. Take
P(s) =
s ‚àí1
(s ‚àí2)(s + 1).
Let S and T denote the sensitivity and complementary sensitivity functions. Prove that
inf ‚à•S‚à•‚àû= inf ‚à•T‚à•‚àû,
(10.7)
where both inÔ¨Åma are over all proper controllers which internally stabilize the feedback system.
Hint to save you some work: The result can be proved without actually computing a coprime
factorization of P.
6. Take P(s) = 1/s2. By the method in the proof of Lemma 2, design an internally stabilizing
C such that
|S(jœâ)|
<
0.05,
‚àÄœâ ‚â§1,
‚à•S‚à•‚àû
<
1.4.
7. Prove that if G is stable and strictly proper, then
lim
œÑ‚Üí0 ‚à•G(1 ‚àíJ)‚à•2 = 0.
8. Take
P(s) =
10
(s ‚àí1)(s + 2).
Compute an internally stabilizing C to minimize the 2-norm of the tracking error y ‚àír for r
the unit step.

10.4. 2-NORM MINIMIZATION
179
Notes and References
The material in Section 10.1 is drawn from Zames (1981), Bensoussan (1984), Francis and Zames
(1984), and Francis (1987).
In the literature the problem of minimizing ‚à•W1S‚à•‚àûis called the
weighted sensitivity problem. Lemma 2 is from Bensoussan (1984) for P stable and Francis (1987)
for the general case. Section 10.2 is based on Zames and Francis (1983), Francis and Zames (1984),
and Khargonekar and Tannenbaum (1985).
There is a way to design for performance which yields a proper Q directly, but it involves
boundary NP interpolation.
The technique in Section 10.4, 2-norm minimization, is also known as minimum variance control:
If d is a zero-mean stationary random signal with power spectral density W(‚àís)W(s), the variance
of y equals exactly ‚à•WPS‚à•2
2. A good treatment of this subject is given in Morari and ZaÔ¨Åriou
(1989).

180
CHAPTER 10. DESIGN FOR PERFORMANCE

Chapter 11
Stability Margin Optimization
In Section 4.2 we looked at several measures of stability margin (e.g., gain and phase margin). In
this chapter we pose the problem of designing a controller whose sole purpose is to maximize the
stability margin. The maximum obtainable stability margin is a measure of how diÔ¨Écult the plant
is to control; for example, a plant with a right half-plane pole near a zero has a relatively small
optimal stability margin, and hence is relatively diÔ¨Écult to control.
Three measures of stability margin are treated, namely, the ‚àû-norm of a multiplicative pertur-
bation, gain margin, and phase margin. It is shown that the problem of optimizing these stability
margins can be reduced to a model-matching problem, as studied in Chapter 9. The reduction for
gain and phase margins requires some conformal mappings, presented in Section 11.2.
11.1
Optimal Robust Stability
To establish our point of view, we begin with a general statement of the robust stability problem.
Consider the usual unity-feedback system with plant transfer function P and controller transfer
function C. It is hypothesized that P is not Ô¨Åxed but belongs to some set P. The robust stability
problem is to Ô¨Ånd, if one exists, a controller C that achieves internal stability for every P in P. We
would like to know two things: conditions on P for C to exist and a procedure to construct such
C. In this generality the robust stability problem remains unsolved.
We concentrate in this section on the special case where P consists of multiplicative perturbations
of a nominal plant P. Following Section 4.1, let P be the family of plants of the form (1 + ‚àÜW2)P,
where
1. P and (1 + ‚àÜW2)P have the same number of poles in Res ‚â•0.
2. ‚à•‚àÜ‚à•‚àû‚â§«´. (In Section 4.1 we took «´ = 1.)
Here W2 is a Ô¨Åxed stable proper weighting function and «´ > 0. We write P«´ to show the explicit
dependence on «´. Let «´sup denote the least upper bound on «´ such that some C stabilizes every
plant in P«´. So «´sup is the maximum stability margin for this model of uncertainty.
The key result in Section 4.2 (Theorem 4.1) was that a controller C achieves internal stability
for every plant in P«´ iÔ¨Äit achieves internal stability for P and ‚à•W2T‚à•‚àû< 1/«´, where T is the
nominal complementary sensitivity function,
T =
PC
1 + PC .
(11.1)
181

182
CHAPTER 11. STABILITY MARGIN OPTIMIZATION
DeÔ¨Åne
Œ≥inf := inf
C ‚à•W2T‚à•‚àû,
(11.2)
the inÔ¨Åmum being over all internally stabilizing controllers. Then «´sup = 1/Œ≥inf.
Proof If «´ < «´sup, there exists a C internally stabilizing all of P«´, and therefore
‚à•W2T‚à•‚àû< 1
«´ .
This implies that Œ≥inf < 1/«´. Since «´ could have been arbitrarily close to «´sup, it must be that
Œ≥inf ‚â§1/«´sup. The reverse inequality is proved in a similar way. ‚ñ†
We would like to compute «´sup, equivalently, Œ≥inf. Computing Œ≥inf reduces to a model-matching
problem in the following way. As in Section 5.2, do a coprime factorization of P:
P = N
M ,
NX + MY = 1.
By Theorem 5.2 the formula
C = X + MQ
Y ‚àíNQ ,
Q ‚ààS
expresses all controllers achieving internal stability for the nominal plant P. Substitution of these
formulas into (11.1) gives
T = N(X + MQ),
so that
W2T = W2N(X + MQ),
and hence
Œ≥inf = inf
Q‚ààS ‚à•W2N(X + MQ)‚à•‚àû.
(11.3)
Equation (11.3) suggests the model-matching problem of Section 9.1:
Œ≥opt =
min
Qim stable ‚à•T1 ‚àíT2Qim‚à•‚àû.
(11.4)
Evidently, T1 = W2NX, T2 = ‚àíW2NM.
So that T2 has no zeros on the imaginary axis (an
assumption in Section 9.1), we will assume that P has neither poles nor zeros on the imaginary axis
and W2 has no zeros on the imaginary axis. The diÔ¨Äerence between the two problems is that Q
must be stable and proper in (11.3), but Qim need only be stable in (11.4); the inÔ¨Åmum in (11.3) is
not achieved, while the minimum in (11.4) is achieved. Nevertheless, Œ≥inf equals Œ≥opt, the minimum
model-matching error, a consequence of the fact that N, hence W2N, is strictly proper (Exercise 7).
The optimization problem deÔ¨Åned by (11.3) is very much like the performance design problem
in Section 10.2. The procedure there can be easily adapted to give the following one for computing
«´sup together with a controller C which, for any «´ < «´sup, achieves internal stability for all plants in
P«´.

11.1. OPTIMAL ROBUST STABILITY
183
Procedure
Input: P, W2
Step 1 Do a coprime factorization of P: Find four functions in S satisfying the equations
P = N
M ,
NX + MY = 1.
Step 2 Solve the model-matching problem for T1 = W2NX, T2 = ‚àíW2NM. Let Qim denote
its solution and let Œ≥opt denote the minimum model-matching error. Then «´sup = 1/Œ≥opt.
Step 3 Let «´ be an arbitrary number < «´sup. Set
J(s) :=
1
(œÑs + 1)k ,
where k is just large enough that QimJ is proper and œÑ is just small enough that
‚à•W2N(X + MQimJ)‚à•‚àû< 1
«´ .
Step 4 Set Q = QimJ.
Step 5 Set C = (X + MQ)/(Y ‚àíNQ).
Example Consider the plant
P(s) =
s ‚àí1
(s + 1)(s ‚àíp),
0 < p Ã∏= 1
with an unstable pole at s = p and a zero at s = 1. We might anticipate some diÔ¨Éculty if p ‚âà1.
Suppose that the uncertainty weight is the high-pass function
W2(s) = s + 0.1
s + 1 .
The procedure above goes like this:
Step 1
N(s)
=
s ‚àí1
(s + 1)2
M(s)
=
s ‚àíp
s + 1
X(s)
=
(p + 1)2
p ‚àí1
Y (s)
=
s ‚àí(p + 3)/(p ‚àí1)
s + 1

184
CHAPTER 11. STABILITY MARGIN OPTIMIZATION
Step 2 Factor N as N = NapNmp with
Nap(s) = s ‚àí1
s + 1,
Nmp(s) =
1
s + 1.
Then
‚à•W2N(X + MQ)‚à•‚àû= ‚à•W2Nmp(X + MQ)‚à•‚àû,
so an equivalent model-matching problem has T1 = W2NmpX, T2 = ‚àíW2NmpM, that is,
T1(s) = (p + 1)2(s + 0.1)
(p ‚àí1)(s + 1)2 ,
T2(s) = ‚àí(s + 0.1)(s ‚àíp)
(s + 1)3
.
Since T2 has only one zero in the right half-plane, namely, at s = p, the minimum model-
matching error is (see Section 9.1)
Œ≥opt = |T1(p)| =

p + 0.1
p ‚àí1
 ,
so
«´sup =

p ‚àí1
p + 0.1
 .
The graph of «´sup versus p decreases monotonically as p approaches 1 from above or below.
Thus less and less uncertainty can be tolerated as p approaches 1.
To proceed, let‚Äôs take a particular value for p, say p = 0.5, for which «´sup = 0.8333. The
solution of the model-matching problem, Qim, satisÔ¨Åes
T1 ‚àíT2Qim = T1(p),
which yields
Qim(s) = ‚àí1.2(s + 1)(s ‚àí1.25)
s + 0.1
.
Step 3 Set «´ = 0.8 (arbitrary) and
J(s) =
1
œÑs + 1.
The value œÑ = 0.01 gives
‚à•W2N(X + MQimJ)‚à•‚àû= 1.2396 < 1
«´ = 1.25.
Step 4
Q(s) = ‚àí1.2 (s + 1)(s ‚àí1.25)
(s + 0.1)(0.01s + 1)
Step 5
C(s) = ‚àí(s + 1)(124.5s2 + 240.45s + 120)
s3 + 227.1s2 + 440.7s + 220

11.2. CONFORMAL MAPPING
185
11.2
Conformal Mapping
For our treatment of optimal gain and phase margins, we need some preliminaries on conformal
mapping.
Let D denote the open unit disk. Also, let H+ denote the open right half-plane. A well-known
technique in signals and systems is to map H+ onto D. One such mapping is
s 7‚Üí1 ‚àís
1 + s.
This is a conformal mapping; that is, it is analytic in H+ and its inverse,
z 7‚Üí1 ‚àíz
1 + z ,
is analytic in D. Because such a mapping exists, H+ and D are said to be conformally equivalent.
What proper subsets of C are conformally equivalent to D? It turns out that the subsets need
only be open and simply connected (i.e., have no holes)‚Äîfor example, an annulus is not simply
connected. This fact is known as the Riemann mapping theorem.
Example 1 Let G1 be the complement of the negative real axis,
{s ‚ààC : s is real and ‚â§0}.
It is easy to see that G1 is open and simply connected. We construct a conformal mapping œÜ1 :
G1 ‚ÜíD as the composition of two mappings:
œà1 : G1 ‚ÜíH+,
œà1(s) = ‚àös
and
œà2 : H+ ‚ÜíD,
œà2(s) = 1 ‚àís
1 + s.
Then
œÜ1(s) := œà2(œà1(s)) = 1 ‚àí‚àös
1 + ‚àös.
It is worth pointing out that conformal mappings are not unique, so the function œÜ1 is just one
possibility.
Example 2 Let a be a positive real number and let G2 be the complement of the horizontal ray
from ‚àía left, that is, the complement of
{s ‚ààC : s is real and ‚â§‚àía}.
The function
s 7‚Üí1 + sa‚àí1

186
CHAPTER 11. STABILITY MARGIN OPTIMIZATION
maps G2 conformally onto G1. Composing it with œÜ1 gives
œÜ2(s) := 1 ‚àí
‚àö
1 + sa‚àí1
1 +
‚àö
1 + sa‚àí1 ,
a conformal mapping from G2 onto D, taking 0 to 0.
Example 3 Let a = a1 +ja2 be a complex number in the Ô¨Årst quadrant (i.e., a1, a2 > 0). Consider
the two rays from a vertically up and from a vertically down; their union is the set
{a + jœâ : œâ ‚â•0} ‚à™{a ‚àíjœâ : œâ ‚â•0}.
Let G3 denote the complement of this set. We construct a conformal mapping œÜ3 from G3 onto
D in several steps. First, the function œà1(s) := s ‚àía1 translates the rays to the imaginary axis.
Second, œà2(s) := js rotates them onto the real axis. Thus, œà2 ‚ó¶œà1 maps G3 conformally onto the
complement of the set
{s : s ‚ààR, |s| ‚â•a2}.
Third,
œà3(s) :=
s
1 ‚àís/a2
1 + s/a2
maps the latter set conformally onto H+.
Now let‚Äôs pause and see where 0 is mapped under
œà3 ‚ó¶œà2 ‚ó¶œà1:
0 7‚Üí‚àía1 7‚Üí‚àíja1 7‚Üíc,
where
c :=
s
1 + ja1/a2
1 ‚àíja1/a2
.
Finally,
œà4(s) := s ‚àíc
s + c
maps H+ onto D. So a suitable œÜ3 is
œÜ3 := œà4 ‚ó¶œà3 ‚ó¶œà2 ‚ó¶œà1.
It too takes 0 to 0.
The conformal mappings in Examples 2 and 3 both take 0 to 0, a property that will be needed in
the applications to follow. This property makes them unique up to rotation. More precisely, suppose
that G is an open, simply connected subset of C, and œÜ1 and œÜ2 are two conformal mappings from
G onto D taking 0 to 0; then there exists an angle Œ± such that
œÜ1 = ejŒ±œÜ2
(i.e., œÜ1 is a rotation of œÜ2). Consequently, œÜ1 and œÜ2 have equal magnitudes at points of evaluation
in G; that is, for z in G, |œÜi(z)| does not depend on the particular conformal mapping.

11.3. GAIN MARGIN OPTIMIZATION
187
11.3
Gain Margin Optimization
This section continues with the robust stability problem, but now
P = {kP : 1 ‚â§k ‚â§k1}.
Here P is the nominal plant transfer function and k is a real gain that is uncertain and may lie
anywhere in the interval [1, k1]. (The family
P = {kP : k0 ‚â§k ‚â§k1},
0 < k0 < k1
is only superÔ¨Åcially more general; it can be reduced to the case k0 = 1 by scaling.) We ask the
question: How large can k1 be but yet there exists a controller achieving internal stability for
every plant in P? Let ksup denote the supremum such k1. We‚Äôll get a formula for ksup under the
simplifying assumption that P has neither poles nor zeros on the imaginary axis.
It turns out that ksup is closely related to the inÔ¨Åmum norm of the (unweighted) complementary
sensitivity function [see (11.2)],
Œ≥inf := inf
C ‚à•T‚à•‚àû.
Of course, as in Section 11.1 this can be converted to a model-matching problem, an analysis of
which will show that
1. Œ≥inf = 0 if P is stable.
2. Œ≥inf = 1 if P is unstable but minimum phase.
3. Œ≥inf > 1 if P is unstable and non-minimum phase.
Theorem 1 If P is stable or minimum phase, then ksup = ‚àû. Otherwise,
ksup =
Œ≥inf + 1
Œ≥inf ‚àí1
2
.
Partial Proof A complete proof is fairly long, so parts will be omitted.
That ksup = ‚àûwhen P is stable is trivial: Take the zero controller, C = 0. So we proceed under
the assumption that P is unstable.
It suÔ¨Éces to show that there exists a C stabilizing kP for all 1 ‚â§k ‚â§k1 iÔ¨Ä
k1 <
Œ≥inf + 1
Œ≥inf ‚àí1
2
or equivalently iÔ¨Ä
Œ≥inf <
‚àök1 + 1
‚àök1 ‚àí1.
(11.5)
We will prove necessity, in three steps. Assume that such C exists.

188
CHAPTER 11. STABILITY MARGIN OPTIMIZATION
Step 1 Since C stabilizes the nominal plant, P, it must have the form
C = X + MQ
Y ‚àíNQ
for some Q in S. Fix 1 < k ‚â§k1 and invoke Lemma 5.1: Since C stabilizes kP,
M(Y ‚àíNQ) + kN(X + MQ) is invertible in S.
This leads in turn to the following chain:
MY + kNX + (k ‚àí1)MNQ is invertible in S
‚áí
(1 ‚àíNX) + kNX + (k ‚àí1)MNQ is invertible in S
‚áí
1 + (k ‚àí1)N(X + MQ) is invertible in S
‚áí
1
k ‚àí1 + N(X + MQ) is invertible in S.
Let H+ denote the closed right half-plane together with the point at inÔ¨Ånity. We conclude that
the function N(X + MQ) maps H+ into the complement of the single point ‚àí1/(k ‚àí1). Since this
holds for all 1 < k ‚â§k1, N(X + MQ) maps H+ into the complement of the set
{s ‚ààC : s is real and ‚â§‚àía},
a :=
1
k1 ‚àí1.
Let G denote this complement.
Note that N(X + MQ) equals T, the complementary sensitivity function corresponding to P
and C. It follows that T satisÔ¨Åes certain interpolation conditions [see equation (6.2)]. Let {pi}
and {zi} denote the right half-plane poles and zeros of P; for simplicity, these are assumed to be
distinct. Then
T(pi) = 1,
T(zi) = 0.
Step 2 As in Example 2 of the preceding section, bring in a conformal mapping from G onto the
open unit disk, D:
œÜ(s) := 1 ‚àí
‚àö
1 + sa‚àí1
1 +
‚àö
1 + sa‚àí1 .
DeÔ¨Åne the function G = œÜ ‚ó¶T. From the properties of T we get that G maps H+ into D and
G(pi) = œÜ(1),
G(zi) = œÜ(0) = 0.
Step 3 The Ô¨Ånal step is to scale G: DeÔ¨Åne
H :=
1
œÜ(1)G.
Then H maps H+ into the disk of radius 1/|œÜ(1)| [i.e., ‚à•H‚à•‚àû< 1/|œÜ(1)|] and
H(pi) = 1,
H(zi) = 0.

11.3. GAIN MARGIN OPTIMIZATION
189
The function H is analytic in H+, but not necessarily real-rational because œÜ does not preserve
rationality. Nevertheless, it can be proved that there exists a function, say K, which is real-rational
and has the foregoing properties of H.
We can conclude that there exists a function K in S having the properties
‚à•K‚à•‚àû<
1
|œÜ(1)|,
(11.6)
K(pi) = 1,
K(zi) = 0.
These properties in turn imply that K is a complementary sensitivity function for some controller;
that is, K = N(X + MQ1) for some Q1 in S. But then from (11.6)
Œ≥inf <
1
|œÜ(1)|.
It remains to compute that
œÜ(1) = 1 ‚àí‚àök1
1 + ‚àök1
.
This proves (11.5).
Notice that ksup equals the value of k1 satisfying the equation
Œ≥inf =
1
|œÜ(1)|. ‚ñ†
The following procedure gives a way to compute a controller that achieves an upper gain margin
of k1, any number less than ksup. The idea is to reverse the argument in the proof above. At a high
level, the procedure is as follows:
1. Solve the model-matching problem corresponding to inf ‚à•T‚à•‚àû; let the solution be Qim.
2. Get a suitable roll-oÔ¨Äfunction J.
3. Let K be the complementary sensitivity function corresponding to the controller parameter
QimJ.
4. Set G = œÜ(1)K.
5. Solve G = œÜ ‚ó¶T for T, which will be the resulting complementary sensitivity function.
6. Solve T = N(X + MQ) for Q.
7. Set C = (X + MQ)/(Y ‚àíNQ).
Procedure: P Unstable, Non-minimum Phase, No Imaginary Axis Poles or Zeros
Input: P

190
CHAPTER 11. STABILITY MARGIN OPTIMIZATION
Step 1 Do a coprime factorization of P:
P = N
M ,
NX + MY = 1.
Step 2 Solve the model-matching problem for T1 = NX, T2 = ‚àíNM. Let Qim denote its
solution and let Œ≥opt denote the minimum model-matching error. Then
ksup =
Œ≥opt + 1
Œ≥opt ‚àí1
2
.
Step 3 Let k1 be arbitrary with 1 < k1 < ksup. Set
J(s) :=
1
(œÑs + 1)k ,
where k is just large enough that QimJ is proper and œÑ is just small enough that
‚à•N(X + MQimJ)‚à•‚àû<
‚àök1 + 1
‚àök1 ‚àí1.
Step 4 Set
K
=
N(X + MQimJ),
G
=
1 ‚àí‚àök1
1 + ‚àök1
K,
T
=
1
k1 ‚àí1
"1 ‚àíG
1 + G
2
‚àí1
#
,
Q
=
T ‚àíNX
NM
.
Step 5 Set C = (X + MQ)/(Y ‚àíNQ).
Example Consider the plant
P(s) =
s ‚àí1
(s + 1)(s ‚àíp),
0 < p Ã∏= 1,
which was studied in Section 11.1. The procedure above goes like this:
Step 1
N(s)
=
s ‚àí1
(s + 1)2
M(s)
=
s ‚àíp
s + 1
X(s)
=
(p + 1)2
p ‚àí1
Y (s)
=
s ‚àí(p + 3)/(p ‚àí1)
s + 1

11.3. GAIN MARGIN OPTIMIZATION
191
Step 2 Factor N as N = NapNmp with
Nap(s) = s ‚àí1
s + 1,
Nmp(s) =
1
s + 1.
Then
‚à•N(X + MQ)‚à•‚àû= ‚à•Nmp(X + MQ)‚à•‚àû,
so an equivalent model-matching problem has T1 = NmpX, T2 = ‚àíNmpM, that is,
T1(s) =
(p + 1)2
(p ‚àí1)(s + 1),
T2(s) = ‚àís ‚àíp
(s + 1)2 .
Thus
Œ≥opt = |T1(p)| =

p + 1
p ‚àí1

and
ksup =
p + 1 + |p ‚àí1|
p + 1 ‚àí|p ‚àí1|
2
=
 p2,
p ‚â•1
p‚àí2,
p < 1.
As with «´sup, this function has its minimum at p = 1.
To proceed, let‚Äôs take p = 2 (arbitrary), for which ksup = 4.
The solution of the model-
matching problem, Qim, satisÔ¨Åes
T1 ‚àíT2Qim = T1(p),
which yields
Qim(s) = 3(s + 1).
Step 3 Set k1 = 3.5 (arbitrary) and
J(s) =
1
œÑs + 1.
The value œÑ = 0.01 gives
‚à•N(X + MQimJ)‚à•‚àû= 3.0827 <
‚àök1 + 1
‚àök1 ‚àí1 = 3.2967.
Step 4
K(s)
=
3 (s ‚àí1)(1.03s + 1)
(s + 1)2(0.01s + 1)
G(s)
=
‚àí0.9100 (s ‚àí1)(1.03s + 1)
(s + 1)2(0.01s + 1)
T(s)
=
0.0375s5 + 3.8231s4 + 7.3882s3 ‚àí0.1831s2 ‚àí7.4257s ‚àí3.64
0.0003s6 + 0.0041s5 + 0.1190s4 + 0.9378s3 + 11.1662s2 + 19.4563s + 9.1204
Q(s)
=
0.0352s4 + 3.9357s3 + 22.1648s2 + 59.8368s + 41.5724
0.0003s4 + 0.0036s3 + 0.1116s2 + 0.7175s + 9.6670

192
CHAPTER 11. STABILITY MARGIN OPTIMIZATION
11.4
Phase Margin Optimization
Now the family of plants to be stabilized is
P =
n
e‚àíjŒ∏P : ‚àíŒ∏1 ‚â§Œ∏ ‚â§Œ∏1
o
,
where P is the nominal plant transfer function and Œ∏ is an uncertain phase lying anywhere in the
interval [‚àíŒ∏1, Œ∏1]; Œ∏1 is an angle in (0, œÄ]. Let Œ∏sup denote the supremum Œ∏1 for which there exists
a stabilizing controller. Under the assumption that P has neither poles nor zeros on the imaginary
axis, a formula can be derived for Œ∏sup in terms of Œ≥inf := inf ‚à•T‚à•‚àûjust as in the preceding section.
Theorem 2 If P is stable or minimum phase, then Œ∏sup = œÄ. Otherwise,
Œ∏sup = 2 sin‚àí1
1
Œ≥inf
.
Proof The proof of Theorem 1 can be adapted with a few alterations by starting with k = e‚àíjŒ∏.
Again, the case that P is stable is trivial.
First, in Step 1 the appropriate set G is the complement of

‚àí
1
k ‚àí1 : k = e‚àíjŒ∏, ‚àíŒ∏1 ‚â§Œ∏ ‚â§Œ∏1

.
The latter set is the union of the vertical rays from
a = a1 + ja2 := 1
2 + j
sin Œ∏1
1 ‚àícos Œ∏1
up and from a down. Second, in Step 2, from Example 3 of the preceding section a conformal
mapping from G onto D is
œÜ = œà4 ‚ó¶œà3 ‚ó¶œà2 ‚ó¶œà1,
where
œà1(s)
=
s ‚àí1
2,
œà2(s)
=
js,
œà3(s)
=
s
1 ‚àís/a2
1 + s/a2
,
œà4(s)
=
s ‚àíc
s + c,
c
=
s
1 + j/(2a2)
1 ‚àíj/(2a2).
Finally, as in the last sentence in the proof of Theorem 1, Œ∏sup equals the value of Œ∏1 satisfying the
equation
Œ≥inf =
1
|œÜ(1)|.

11.4. PHASE MARGIN OPTIMIZATION
193
So it remains to show that
|œÜ(1)| = sin Œ∏1
2 .
Elementary computations give
œÜ(1) = ‚àíImc
c ,
|œÜ(1)| = sin Œ∏1
2 . ‚ñ†
Example Consider once again the plant
P(s) =
s ‚àí1
(s + 1)(s ‚àíp),
0 < p Ã∏= 1.
We found in the preceding section that
Œ≥inf =

p + 1
p ‚àí1
 .
Therefore,
Œ∏sup = 2 sin‚àí1

p ‚àí1
p + 1
 .
Exercises
1. Compute «´sup for
P(s) =
s ‚àí1
(s ‚àí2)(s ‚àí3),
W2(s) =
s + 1
s + 100.
Select some «´ < «´sup and compute a robust controller.
2. Take
P(s) =
1
s ‚àí1,
W2(s) =
as
0.01s + 1,
with a a positive number. Compute the least upper bound on a for which robust stability is
achievable. Pick some a less than this upper bound and design a robust controller.
3. With Œ≥inf = inf ‚à•T‚à•‚àûand P having neither poles nor zeros on the imaginary axis, prove
Œ≥inf = 0 if P is stable,
Œ≥inf = 1 if P is unstable but minimum phase,
Œ≥inf > 1 if P is unstable and non-minimum phase.
4. Compute the maximum gain margin ksup for
P(s) =
s ‚àí1
(s ‚àí2)(s ‚àí3).
Select some k1 < ksup and compute a robust controller.

194
CHAPTER 11. STABILITY MARGIN OPTIMIZATION
5. Repeat the Exercise 4 but for phase margin.
6. Recall from Section 4.2 that 1/‚à•S‚à•‚àûequals the distance from the critical point ‚àí1 to the
nearest point on the Nyquist plot of PC, and in this way qualiÔ¨Åes as a stability margin. The
smaller ‚à•S‚à•‚àû, the larger the stability margin. Compute inf ‚à•S‚à•‚àûfor the plant in Exercise 4.
7. Using the equation
W2N(X + MQJ) = W2N(X + MQ)J + W2NX(1 ‚àíJ),
prove that Œ≥inf in (11.3) and Œ≥opt in (11.4) are equal.
Notes and References
The problem in Section 11.1 was Ô¨Årst solved by Kimura (1984). The gain margin problem was Ô¨Årst
solved by Tannenbaum (1980, 1981) using Nevanlinna-Pick theory. Khargonekar and Tannenbaum
(1985) showed the mathematical equivalence of the problems of gain margin optimization, sensitivity
minimization, and robust stabilization. Yan and Anderson (1990) considered a problem that mixes
performance and gain margin.

Chapter 12
Design for Robust Performance
This chapter presents a mathematical technique for designing a controller to achieve robust per-
formance. Chapter 7 proposed loopshaping as a graphical method when P and P ‚àí1 are stable.
Without these assumptions loopshaping is very awkward and the methodical procedure in this
chapter can be used.
12.1
The ModiÔ¨Åed Problem
As deÔ¨Åned in Section 4.3, the robust performance problem is to design a proper controller C so that
the feedback system for the nominal plant is internally stable and the inequality
‚à•|W1S| + |W2T|‚à•‚àû< 1
(12.1)
holds. Also as mentioned in Chapter 7, the exact problem as just stated remains unsolved. So we
look for a nearby problem that is solvable.
We seek to replace inequality (12.1) with a tractable one. Fix a frequency and deÔ¨Åne x := |W1S|
and y := |W2T|. The region in the (x, y)-plane where x + y < 1 is the right-angle triangle shown
here:
@
@
@
@
@
@
1
1
By imagining the circle with center 0, radius 1/
‚àö
2 you can see that
x2 + y2 < 1/2
‚áí
x + y < 1.
Thus a suÔ¨Écient condition for (12.1) is
‚à•|W1S|2 + |W2T|2‚à•‚àû< 1
2.
(12.2)
195

196
CHAPTER 12. DESIGN FOR ROBUST PERFORMANCE
In this way we arrive at the modiÔ¨Åed robust performance problem: Find a proper, internally sta-
bilizing C so that (12.2) holds. This problem is a compromise; it is not exactly the problem we
would like to solve, but it is nearby and has the desirable feature of being solvable without too
much diÔ¨Éculty.
We will solve the modiÔ¨Åed problem under the following assumptions:
1. P is strictly proper and has neither poles nor zeros on the imaginary axis.
2. W1 and W2 are stable and proper.
3. W1 and W2 have no common zeros on the imaginary axis.
Some of these assumptions could be relaxed, but with an increase in messiness.
We‚Äôll need an additional tool, covered in the next section.
12.2
Spectral Factorization
For a rational function F(s) with real coeÔ¨Écients, let F denote the function F(‚àís). Thus
F(jœâ) = F(‚àíjœâ) = F(jœâ).
We saw in Lemma 6.2 that, provided F ‚ààS, it has a factorization of the form F = FapFmp.
All the right half-plane zeros go into the all-pass factor, and the ones in the left half-plane or
on the imaginary axis go into the minimum-phase factor.
The all-pass factor has the property
Fap(s)Fap(s) = 1.
There is a related factorization if F has the property F = F and no zeros or poles on the
imaginary axis. This means that the zeros of F form a pattern that is symmetrical with respect
to both the real and imaginary axes. To see this, simply note that if z is a zero, so is ‚àíz because
F(s) = F(‚àís). It follows that for every zero z in the right half-plane, the numerator of F is divisible
by
(z ‚àís)(z + s).
Similarly for the poles. Hence we can write F in terms of its gain, poles, and zeros like this:
F(s) = cF1(s),
F1(s) =
Q(zi ‚àís)(zi + s)
Q(pi ‚àís)(pi + s).
Note that {zi} and {pi} are the right half-plane zeros and poles. Note also that F1(0) > 0. From
F1 form a function G by selecting only the factors corresponding to zeros and poles in Res < 0,
that is,
G(s) :=
Q(zi + s)
Q(pi + s).
Then G and G‚àí1 are stable. The zeros and poles of F1 in the right half-plane are absorbed into the
function G and we have the factorization
F = GcG with G, G‚àí1 stable.

12.2. SPECTRAL FACTORIZATION
197
Finally, if c > 0, we deÔ¨Åne Fsf as
Fsf(s) := ‚àöc
Q(zi + s)
Q(pi + s)
to get F = FsfFsf. Since F1(0) > 0, c > 0 iÔ¨ÄF(0) > 0.
The function Fsf‚Äîwhich is like a square root of F(s)‚Äîtherefore has the properties
F = FsfFsf with Fsf, F ‚àí1
sf stable
and is called a spectral factor of F. This factorization of F is called a spectral factorization.
An alternative characterization of the condition F = F is this: F = F iÔ¨ÄF is a rational function
in s2.
The above is summarized as follows.
Lemma 1 If the real-rational function F has the properties F = F, no zeros or poles on the
imaginary axis, and F(0) > 0, then it has a spectral factorization.
Example 1 The function
F(s) =
1
1 ‚àís2
can be factored as
F(s) =
1
1 ‚àís
1
1 + s,
so a suitable spectral factor is Fsf(s) = 1/(1 + s). So is ‚àí1/(1 + s).
Example 2 Consider the function
F(s) = 10
4 ‚àís2
25 + 6s2 + s4 .
Its poles are ¬±1 ¬± 2j and its zeros are ¬±2. The function G is therefore
G(s) =
2 + s
(1 + 2j + s)(1 ‚àí2j + s) =
2 + s
5 + 2s + s2 .
So a spectral factor is
Fsf(s) =
‚àö
10
2 + s
5 + 2s + s2 .
Example 3 The function
F(s) =
2s2 ‚àí1
s4 ‚àís2 + 1
has no spectral factorization because F(0) < 0.

198
CHAPTER 12. DESIGN FOR ROBUST PERFORMANCE
12.3
Solution of the ModiÔ¨Åed Problem
The solution of the modiÔ¨Åed problem involves transforming it into the model-matching problem of
Chapter 9. Since this transformation is a little involved, it is worth describing it Ô¨Årst on a high
level, as follows.
1. We use the by now familiar factorization of all internally stabilizing controllers from Theo-
rem 5.2. Factorize P:
P = N
M ,
NX + MY = 1,
N, M, X, Y ‚ààS.
The formula for C is
C = X + MQ
Y ‚àíNQ ,
Q ‚ààS.
In terms of Q we have
S = M(Y ‚àíNQ),
T = N(X + MQ).
So the modiÔ¨Åed problem reduces to this: Ô¨Ånd Q in S such that
‚à•|W1M(Y ‚àíNQ)|2 + |W2N(X + MQ)|2‚à•‚àû< 1
2.
(12.3)
Let‚Äôs simplify notation by deÔ¨Åning
R1 := W1MY,
S1 := W2NX,
R2 := W1MN,
S2 := ‚àíW2MN.
so that (12.3) becomes
‚à•|R1 ‚àíR2Q|2 + |S1 ‚àíS2Q|2‚à•‚àû< 1
2.
(12.4)
2. Inequality (12.4) involves the sum of two squares in Q. To get closer to the model-matching
problem we shall transform (12.4) so that only one square in Q appears, that is, transform it
into
‚à•|U1 ‚àíU2Q|2 + U3‚à•‚àû< 1
2
(12.5)
for suitable functions Ui, i = 1, 2, 3. The Ô¨Årst two, U1 and U2, will belong to S, while U3 will
be real-rational with the property U3 = U3.
3. In what follows we shall drop jœâ and also introduce U4, a spectral factor of 1
2 ‚àíU3:
(12.5)
‚áî
|U1 ‚àíU2Q|2 + U3 < 1
2,
‚àÄœâ
‚áî
|U1 ‚àíU2Q|2 < 1
2 ‚àíU3,
‚àÄœâ
‚áî
|U1 ‚àíU2Q|2 < |U4|2,
‚àÄœâ
‚áî
|U‚àí1
4 U1 ‚àíU‚àí1
4 U2Q|2 < 1,
‚àÄœâ
‚áî
‚à•U‚àí1
4 U1 ‚àíU‚àí1
4 U2Q‚à•‚àû< 1.

12.3. SOLUTION OF THE MODIFIED PROBLEM
199
So the Ô¨Ånal model-matching problem is to Ô¨Ånd a Q in S satisfying
‚à•U‚àí1
4 U1 ‚àíU‚àí1
4 U2Q‚à•‚àû< 1.
Now for the details. For equivalence of (12.4) and (12.5) it suÔ¨Éces to have the following equation
hold:
(R1 ‚àíR2Q)(R1 ‚àíR2Q) + (S1 ‚àíS2Q)(S1 ‚àíS2Q) = (U1 ‚àíU2Q)(U1 ‚àíU2Q) + U3.
Multiply all factors out and collect terms. The result is an identity in Q provided that the following
three equations hold:
R2R2 + S2S2
=
U2U2,
(12.6)
R2R1 + S2S1
=
U2U1,
(12.7)
R1R1 + S1S1
=
U1U1 + U3.
(12.8)
The idea is to get U1 and U2 satisfying (12.6) and (12.7), and then to get U3 from (12.8). In fact,
we can solve for U3 right away:
U3 =
W1W1W2W2
W1W1 + W2W2
.
(12.9)
Proof From (12.7) we have
U1 = R2R1 + S2S1
U2
and hence
U1U1 = (R1R2 + S1S2)(R1R2 + S1S2)
U2U2
.
Substituting from (12.6) in the denominator gives
U1U1 = (R1R2 + S1S2)(R1R2 + S1S2)
R2R2 + S2S2
.
Using this in (12.8) gives
U3 = R1R1 + S1S1 ‚àí(R1R2 + S1S2)(R1R2 + S1S2)
R2R2 + S2S2
.
Finally, substitute into this the deÔ¨Ånitions of Ri and Si and simplify to get (12.9). ‚ñ†
Now we turn to the solution of (12.6) and (12.7). We want solutions U1 and U2 in S. To see
what is involved, let us look at an example.
Example 1 Suppose that
R1(s) =
1
2 + s,
S1(s) = 0,
R2(s) =
1
1 + s,
S2(s) = 1.

200
CHAPTER 12. DESIGN FOR ROBUST PERFORMANCE
Then equations (12.6) and (12.7) are
(
‚àö
2 ‚àís)(
‚àö
2 + s)
(1 ‚àís)(1 + s)
=
U2(s)U2(s),
(12.10)
1
(1 ‚àís)(2 + s)
=
U2(s)U1(s).
(12.11)
To satisfy (12.10), an obvious choice is the spectral factor
U2(s) =
‚àö
2 + s
1 + s .
But then (12.11) has the unique solution
U1(s) =
1
(2 + s)(
‚àö
2 ‚àís)
,
which is unsatisfactory, not being in S. So as a solution of (12.10) let us take
U2(s) =
‚àö
2 + s
1 + s V (s),
where V is an all-pass function, as yet unknown. Again, the solution of (12.11) is
U1(s) =
1
(2 + s)(
‚àö
2 ‚àís)V (s).
So to get U1 in S we should let V have a zero at s =
‚àö
2, for example,
V (s) =
‚àö
2 ‚àís
‚àö
2 + s
.
The following procedure yields functions U1 and U2 in S satisfying (12.6) and (12.7).
Procedure A
Input: R1, R2, S1, S2
Step 1 Set F := R2R2 + S2S2. Comment: F has no zeros or poles on the imaginary axis,
F = F, and F(0) > 0.
Step 2 Compute a spectral factor Fsf of F.
Step 3 Choose an all-pass function V such that
R2R1 + S2S1
Fsf
V ‚ààS.

12.3. SOLUTION OF THE MODIFIED PROBLEM
201
Step 4 Set
U1 := R2R1 + S2S1
Fsf
V,
U2 := FsfV.
Finally, the following procedure solves the modiÔ¨Åed robust performance problem.
Procedure B
Input: P, W1, W2
Step 1 Compute
U3 =
W1W1W2W2
W1W1 + W2W2
.
Check if ‚à•U3‚à•‚àû< 1
2, that is,

|W1W2|2
|W1|2 + |W2|2

‚àû
< 1
2.
If so, continue. If not, the problem is not solvable; stop.
Step 2 Coprime factorization of P:
P = N
M ,
NX + MY = 1.
Step 3 Set
R1 := W1MY,
S1 := W2NX,
R2 := W1MN,
S2 := ‚àíW2MN.
Step 4 Apply Procedure A to get U1 and U2.
Step 5 Compute a spectral factor U4 of 1
2 ‚àíU3.
Step 6 Set T1 := U‚àí1
4 U1 and T2 := U‚àí1
4 U2. Comment: T1, T2 ‚ààS and T2 has no zeros on
the imaginary axis.
Step 7 Compute Œ≥opt, the minimum model-matching error. If Œ≥opt < 1, continue. If Œ≥opt ‚â•1,
the modiÔ¨Åed robust performance problem is not solvable; stop.
Step 8 Compute Q, the solution to the model-matching problem. If Q is not proper, roll it
oÔ¨Äat a suÔ¨Éciently high frequency while maintaining ‚à•T1 ‚àíT2Q‚à•‚àû< 1.
Step 9 Set
C = X + MQ
Y ‚àíNQ .

202
CHAPTER 12. DESIGN FOR ROBUST PERFORMANCE
The purpose of the next example is solely to illustrate the procedures above.
It should be
emphasized that the plant is very simple and the design could more easily be done using loopshaping.
Example 2 Take
P(s) =
1
s + 1,
W1(s) =
a
s + 1,
W2(s) =
0.02s
0.01s + 1.
The positive constant a is left unspeciÔ¨Åed at this point. In fact we will Ô¨Ånd the largest a for which
the modiÔ¨Åed robust performance problem is solvable.
Step 1
U3(s) = ‚àí
0.0004a2s2
a2 ‚àí(0.0001a2 + 0.0004)s2 + 0.0004s4
The ‚àû-norm of U3 is computed for selected values of a:
a
Norm
50
0.4444
52
0.4601
54
0.4757
56
0.4912
58
0.5064
60
0.5217
By interpolation, the supremum value of a for which ‚à•U3‚à•‚àû< 1/2 is about 57.2.
Step 2 N = P, M = 1, X = 0, Y = 1
Step 3
R1(s) =
a
s + 1,
R2(s) =
a
(s + 1)2 ,
S1(s) = 0,
S2(s) = ‚àí
0.02s
(s + 1)(0.01s + 1)
Step 4 Procedure A:
Step 1
F(s) = a2 ‚àí(0.0001a2 + 0.0004)s2 + 0.0004s4
(1 ‚àís)2(1 + s)2(1 ‚àí0.01s)(1 + 0.01s)
Step 2
Fsf(s) =
a + bs + 0.02s2
(1 + s)2(1 + 0.01s)
b := (0.0001a2 + 0.04a + 0.0004)1/2

12.3. SOLUTION OF THE MODIFIED PROBLEM
203
Step 3
V (s) = a ‚àíbs + 0.02s2
a + bs + 0.02s2
Step 4
U1(s) = a2
1 ‚àí0.01s
(1 + s)(a + bs + 0.02s2),
U2(s) =
a ‚àíbs + 0.02s2
(1 + s)2(1 + 0.01s)
Step 5
U4(s) =
a + cs + 0.02s2
‚àö
2(a + bs + 0.02s2)
c := (‚àí0.0007a2 + 0.04a + 0.0004)1/2
Step 6
T1(s)
=
‚àö
2a2
1 ‚àí0.01s
(1 + s)(a + cs + 0.02s2)
T2(s)
=
‚àö
2 (a + bs + 0.02s2)(a ‚àíbs + 0.02s2)
(a + cs + 0.02s2)(1 + s)2(1 + 0.01s)
Step 7 Œ≥opt is computed for selected values of a:
a
Œ≥opt
36
0.9381
37
0.9560
38
0.9742
39
0.9928
40
1.0118
So a = 39 is feasible, while a = 40 is not. Let‚Äôs proceed with a = 36.
Step 8 The solution to the model-matching problem is
Qim(s) = 0.3317s4 + 55.19s3 + 2838s2 + 64215s + 61432
s3 + 97.42s2 + 3978s + 62585
.
This must be rolled oÔ¨Ä: Set
Q(s) = Qim(s)
1
œÑs + 1.
The value œÑ = 0.0009 yields ‚à•T1 ‚àíT2Q‚à•‚àû= 0.9996, and is therefore satisfactory.
Step 9 C = Q/(1 ‚àíPQ).
The resulting Bode plots are displayed in Figure 12.1.

204
CHAPTER 12. DESIGN FOR ROBUST PERFORMANCE
10-3
10-2
10-1
100
101
102
10-1
100
101
102
103
104
Figure 12.1: Bode plot of |S| (solid), |T| (dash), |W1| (dot), and |W2| (dot-dash).
12.4
Design Example: Flexible Beam Continued
In the preceding section we presented a procedure for designing a controller to achieve a tradeoÔ¨Ä
between S and T. The procedure has some appeal pedagogically, being elementary and based in
the frequency domain.
However, it must be admitted that it would not be suitable even for a
medium-sized problem because computations with rational functions are clumsy and numerically
sensitive. Modern software for control system design is based on state-space methods, the theory
behind which is beyond the scope of this book. One such software package is MATLAB with the
¬µ-Tools Toolbox. In this section we continue the Ô¨Çexible beam example begun in Section 10.3. The
actual computations were performed using MATLAB, so only the results are reported. Our main
purpose in including this example is to discuss further the issue of weights selection, in particular,
the choice of weights for time-domain specs.
Recall that the transfer function for the plant is
P(s) =
‚àí6.4750s2 + 4.0302s + 175.7700
s(5s3 + 3.5682s2 + 139.5021s + 0.0929).
The plant input is a voltage to a power ampliÔ¨Åer and the output is the tip deÔ¨Çection of the beam.
The performance specs in Section 10.3 were in terms of the unit step response:
settling time
‚âà
8 s,
overshoot
‚â§
10%.
Using the performance weight
W1(s) =
0.9
1.0210
s2 + 1.2s + 1
(s + 0.001)(s + 1.2)(0.001s + 1),

12.4. DESIGN EXAMPLE: FLEXIBLE BEAM CONTINUED
205
we designed a controller achieving these two specs.
In this section we place an additional constraint, namely, an amplitude constraint on the plant
input:
|u(t)| ‚â§0.5,
‚àÄt.
(12.12)
This reÔ¨Çects the fact that the power ampliÔ¨Åer will saturate if its input is outside this range. The Sec-
tion 10.3 design violates this spec, the signal u(t) exhibiting a very large surge over the time interval
[0, 0.03]. No frequency-domain design procedure can treat a speciÔ¨Åcation like (12.12) precisely: An
amplitude bound in the time domain does not translate over precisely to anything tractable in the
frequency domain. So we have to be content with a trial-and-error procedure.
Intuitively, we may have to relax the step-response spec in order to achieve (12.12); this means
decreasing the gain of W1. So let us take
W1(s) = a
s2 + 1.2s + 1
(s + 0.001)(s + 1.2)(0.001s + 1),
where a is a design parameter.
The transfer function from reference input r to plant input u is CS (not T). So to achieve
(12.12) it makes sense to introduce a new weight, W3, and associated modiÔ¨Åed criterion,
‚à•|W1S|2 + |W3CS|2‚à•‚àû< 1.
(12.13)
Although this is diÔ¨Äerent from the criterion in Section 12.3, it can be handled in exactly the same
way‚Äîthe changes are obvious; for example, whereas in Section 12.3 we had
W2T = W2N(X + MQ),
we now have
W3CS = W3M(X + MQ).
The observation above, that u(t) exhibits an initial large surge, suggests penalizing high-
frequency control actuation by taking W3 to be a high-pass Ô¨Ålter, of the form
W3(s) = bs + 0.01c
s + c
.
The constant c was taken to be c = 1/0.03 = 33.3 rad/s, corresponding to the surge interval [0, 0.03].
We are left with the two parameters a and b in the weights: The larger the value of a, the better
the step response; the larger the value of b, the larger the penalty on control. These parameters
were determined by the following iterative procedure:
1. Set a = 0.9/1.0210, the value for the previous design.
2. Decrease b from some starting value until (12.13) is achievable by some controller. Obtain
such a controller and do a step-response simulation. Check if the specs are satisÔ¨Åed.
3. If necessary, decrease a and repeat Step 2.

206
CHAPTER 12. DESIGN FOR ROBUST PERFORMANCE
The values a = 0.8, b = 1 were obtained, and the corresponding controller has numerator
1.424s7 + 9.076 √ó 102s6 + 3.141 √ó 104s5 + 1.117 √ó 105s4 + 9.073 √ó 105s3
+1.961 √ó 106s2 + 1.306 √ó 103s + 0.01406
and denominator
s8 + 1.013 √ó 103s7 + 1.326 √ó 104s6 + 1.129 √ó 105s5 + 6.326 √ó 105s4
+2.348 √ó 106s3 + 4.940 √ó 106s2 + 3.440 √ó 106s + 3.435 √ó 103.
The order of the controller (8) equals the sum of the orders of P, W1, and W3. Figure 12.2 shows
the resulting Bode plots and Figure 12.3 the step responses. The specs have been met.
10-7
10-6
10-5
10-4
10-3
10-2
10-1
100
101
102
103
10-3
10-2
10-1
100
101
102
Figure 12.2: Bode plot of |S| (solid), |CS| (dash), |W1| (dot), and |W3| (dot-dash).
It is interesting to compare the step response of y in Figure 12.3 with the step response in
Figure 10.3, where the control input was unconstrained: The former exhibits a pronounced initial
time lag, evidently the price paid for constrained control.
Exercises
1. This exercise seeks to illustrate why minimization of the performance measure
‚à•|W1S| + |W2T|‚à•‚àû
(12.14)
is harder than minimization of
‚à•|W1S|2 + |W2T|2‚à•‚àû.
(12.15)

12.4. DESIGN EXAMPLE: FLEXIBLE BEAM CONTINUED
207
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
0
1
2
3
4
5
6
7
8
9
10
Figure 12.3: Step response of y (solid) and u (dash).
Consider the space R2 of 2-vectors x = (x1, x2). There are many possible norms on this space;
let us focus on
‚à•x‚à•1 := |x1| + |x2| and ‚à•x‚à•2 := (|x1|2 + |x2|2)1/2,
which are analogous to (12.14) and (12.15), respectively. Note that ‚à•‚à•2 is the usual Euclidean
norm. Sketch the two unit balls,
{x : ‚à•x‚à•1 ‚â§1},
{x : ‚à•x‚à•2 ‚â§1}.
To illustrate that ‚à•‚à•1 is harder to work with than ‚à•‚à•2, we will look at an approximation
problem. Let M denote the subspace spanned by (1, 2), that is, the straight line through this
point and the origin. For x = (4, 1), compute the vector y in M which is closest to x in that it
minimizes ‚à•x‚àíy‚à•2. Note that y equals the orthogonal projection of x onto M. Now compute
y to minimize ‚à•x ‚àíy‚à•1. Observe that y and x ‚àíy are not orthogonal.
2. Prove directly that a necessary condition for solvability of the modiÔ¨Åed robust performance
problem is

|W1W2|2
|W1|2 + |W2|2

‚àû
< 1
2.
3. Show that
‚à•|W1S| + |W2T|‚à•‚àû< 1 ‚áí‚à•|W1S|2 + |W2T|2‚à•‚àû< 1.

208
CHAPTER 12. DESIGN FOR ROBUST PERFORMANCE
4. Consider the example in Section 12.3. Let asup denote the supremum value of a for which the
robust performance problem is solvable. It was shown that the value a = 39 is feasible for the
modiÔ¨Åed robust performance problem, and hence asup ‚â•39. Using Exercise 3, Ô¨Ånd an upper
bound for asup.
5. Do a loopshape design for the example in Section 12.3, trying to make a as large as possible.
Notes and References
This chapter is based on Doyle (1983) and Francis (1983). In the literature the problem of mini-
mizing
‚à•|W1S|2 + |W2T|2‚à•‚àû
over all internally stabilizing controllers is called the mixed sensitivity problem. It was solved (for
the more general case of multivariable plants) by Kwakernaak (1985) and Verma and Jonckheere
(1984). The mixed sensitivity problem is a special case of a more general ‚àû-norm optimization
problem that is treated in Doyle (1984), Francis (1987), and Foias and Tannenbaum (1988).

References
Aubrun, J.N., K.R. Lorell, T.S. Mast, and J.E. Nelson (1987). ‚ÄúDynamic analysis of the actively
controlled segmented mirror of the W.M. Keck ten-meter telescope,‚Äù IEEE Control Syst. Mag., vol.
7, no. 6, pp. 3-10.
Aubrun, J.N., K.R. Lorell, T.W. Havas, and W.C. Henninger (1988). ‚ÄúPerformance analysis of the
segmented alignment control system for the ten-meter telescope,‚Äù Automatica, vol. 24, pp. 437-454.
Bensoussan, D. (1984). ‚ÄúSensitivity reduction in single-input single-output systems,‚Äù Int. J. Con-
trol, vol. 39, pp. 321-335.
Bode, H.W. (1945). Network Analysis and Feedback AmpliÔ¨Åer Design, D. Van Nostrand, Princeton,
N.J.
Bower, J.L. and P. Schultheiss (1961). Introduction to the Design of Servomechanisms, Wiley, New
York.
Boyd, S.P., V. Balakrishnan, C.H. Barratt, N.M. Khraishi, X. Li, D.G. Meyer, and S.A. Norman
(1988).
‚ÄúA new CAD method and associated architectures for linear controllers,‚Äù IEEE Trans.
Auto. Control, vol. AC-33, pp. 268-283.
Boyd, S.P., V. Balakrishnan, and P. Kabamba (1989). ‚ÄúA bisection method for computing the H‚àû
norm of a transfer matrix and related problems,‚Äù Math. Control Signals Syst., vol. 2, pp. 207-219.
Chen, M.J. and C.A. Desoer (1982). ‚ÄúNecessary and suÔ¨Écient condition for robust stability of linear
distributed feedback systems,‚Äù Int. J. Control, vol. 35, pp. 255-267.
Desoer, C.A. and C.L. Gustafson (1984). ‚ÄúAlgebraic theory of linear multivariable systems,‚Äù IEEE
Trans. Auto. Control, vol. AC-29, pp. 909-917.
Desoer, C.A. and M. Vidyasagar (1975). Feedback Systems: Input-Output Properties, Academic
Press, New York.
Desoer, C.A., R.W. Liu, J. Murray, and R. Saeks (1980). ‚ÄúFeedback system design: the fractional
representation approach to analysis and synthesis,‚Äù IEEE Trans. Auto. Control, vol. AC-25, pp.
399-412.
Doyle, J.C. (1983). ‚ÄúSynthesis of robust controllers and Ô¨Ålters,‚Äù Proc. 22nd IEEE. Conf. Decision
and Control.
209

210
CHAPTER 12. DESIGN FOR ROBUST PERFORMANCE
Doyle, J.C. (1984). Lecture Notes in Advances in Multivariable Control, ONR/Honeywell Workshop,
Minneapolis, Minn.
Doyle, J.C. and G. Stein (1981). ‚ÄúMultivariable feedback design: concepts for a classical modern
synthesis,‚Äù IEEE Trans. Auto. Control, vol. AC-26, pp. 4-16.
Enns, D. (1986). Limitations to the Control of the X-29, Technical Report, Honeywell Systems and
Research Center, Minneapolis, Minn.
Foias, C. and A. Tannenbaum (1988). ‚ÄúOn the four block problem, II: the singular system,‚Äù Integral
Equations and Operator Theory, vol. 11, pp. 726-767.
Francis, B.A. (1983). Notes on H‚àû-Optimal Linear Feedback Systems, Lectures given at Linkoping
University.
Francis, B.A. (1987). A Course in H‚àûControl Theory, vol. 88 in Lecture Notes in Control and
Information Sciences, Springer-Verlag, New York.
Francis, B.A. and M. Vidyasagar (1983). ‚ÄúAlgebraic and topological aspects of the regulator problem
for lumped linear systems,‚Äù Automatica, vol. 19, pp. 87-90.
Francis, B.A. and G. Zames (1984). ‚ÄúOn H‚àû-optimal sensitivity theory for siso feedback systems,‚Äù
IEEE Trans. Auto. Control, vol. AC-29, pp. 9-16.
Franklin, G.F., J.D. Powell, and A. Emami-Naeini (1986). Feedback Control of Dynamic Systems,
Addison-Wesley, Reading, Mass.
Freudenberg, J.S. and D.P. Looze (1985). ‚ÄúRight half-plane poles and zeros and design trade-oÔ¨Äs
in feedback systems,‚Äù IEEE Trans. Auto. Control, vol. AC-30, pp. 555-565.
Freudenberg, J.S. and D.P. Looze (1988). Frequency Domain Properties of Scalar and Mulivariable
Feedback Systems, vol. 104 in Lecture Notes in Control and Information Sciences, Springer-Verlag,
New York.
Garnett, J.B. (1981). Bounded Analytic Functions, Academic Press, New York.
Holtzman, J.M. (1970). Nonlinear System Theory, Prentice-Hall, Englewood CliÔ¨Äs, N.J .
Horowitz, I.M. (1963). Synthesis of Feedback Systems, Academic Press, New York.
Joshi, S.M. (1989). Control of Large Flexible Space Structures, vol. 131 in Lecture Notes in Control
and Information Sciences, Springer-Verlag, New York.
Khargonekar, P. and E. Sontag (1982). ‚ÄúOn the relation between stable matrix fraction factor-
izations and regulable realizations of linear systems over rings,‚Äù IEEE Trans. Auto. Control, vol.
AC-27, pp. 627-638.
Khargonekar, P. and A. Tannenbaum (1985). ‚ÄúNoneuclidean metrics and the robust stabilization
of systems with parameter uncertainty,‚Äù IEEE Trans. Auto. Control, vol. AC-30, pp. 1005-1013.

12.4. DESIGN EXAMPLE: FLEXIBLE BEAM CONTINUED
211
Kimura, H. (1984). ‚ÄúRobust stabilization for a class of transfer functions,‚Äù IEEE Trans. Auto.
Control, vol. AC-29, pp. 788-793.
Kucera, V. (1979). Discrete Linear Control: The Polynomial Equation Approach, Wiley, New York.
Kwakernaak, H. (1985). ‚ÄúMinimax frequency domain performance and robustness optimization of
linear feedback systems,‚Äù IEEE Trans. Auto. Control, vol. AC-30, pp. 994-1004.
Lenz, K.E., P.P. Khargonekar, and J.C. Doyle (1988). ‚ÄúWhen is a controller H‚àû-optimal,‚Äù Math.
Control Signals Syst., vol. 1, pp. 107-122.
McFarlane, D.C. and K. Glover (1990). Robust Controller Design Using Normalized Coprime Factor
Plant Descriptions, vol. 138 in Lecture Notes in Control and Information Sciences, Springer-Verlag,
New York.
Mees, A.I. (1981). Dynamics of Feedback Systems, Wiley, New York.
Morari, M. and E. ZaÔ¨Åriou (1989). Robust Process Control, Prentice-Hall, Englewood CliÔ¨Äs, N.J.
Nett, C.N., C.A. Jacobson, and M.J. Balas (1984). ‚ÄúA connection between state-space and doubly
coprime fractional representations,‚Äù IEEE Trans. Auto. Control, vol. AC-29, pp. 831-832.
Newton, G.C., L.A. Gould, and J.F. Kaiser (1957). Analytic Design of Linear Feedback Controls,
Wiley, New York.
Raggazini, J.R. and G.F. Franklin (1958). Sampled-Data Control Systems, McGraw-Hill, New York.
Saeks, R. and J. Murray (1982).‚ÄúFractional representation, algebraic geometry, and the simultaneous
stabilization problem,‚Äù IEEE Trans. Auto. Control, vol. AC-27, pp. 895-903.
Sarason, D. (1967). ‚ÄúGeneralized interpolation in H‚àû,‚Äù Trans. AMS, vol. 127, pp. 179-203.
Silverman, L. and M. Bettayeb (1980). ‚ÄúOptimal approximation of linear systems,‚Äù Proc. JACC.
Tannenbaum, A. (1980). ‚ÄúFeedback stabilization of linear dynamical plants with uncertainty in the
gain factor,‚Äù Int. J. Control, vol. 32, pp. 1-16.
Tannenbaum, A. (1981). Invariance and System Theory: Algebraic and Geometric Aspects, vol.
845 in Lecture Notes in Mathematics, Springer-Verlag, Berlin.
Verma, M. and E. Jonckheere (1984). ‚ÄúL‚àû-compensation with mixed sensitivity as a broadband
matching problem,‚Äù Syst. Control Lett., vol. 4, pp. 125-129.
Vidyasagar, M. (1972). ‚ÄúInput-output stability of a broad class of linear time-invariant multivariable
systems,‚Äù SIAM J. Control, vol. 10, pp. 203-209.
Vidyasagar, M. (1985). Control System Synthesis: A Factorization Approach, MIT Press, Cam-
bridge, Mass.

212
CHAPTER 12. DESIGN FOR ROBUST PERFORMANCE
Walsh, J.L. (1969). Interpolation and Approximation by Rational Functions in the Complex Domain,
5th ed., American Mathematical Society, Providence, R.I.
Willems, J.C. (1971). The Analysis of Feedback Systems, MIT Press, Cambridge, Mass.
Yan, W. and B.D.O. Anderson (1990). ‚ÄúThe simultaneous optimization problem for sensitivity and
gain margin,‚Äù IEEE Trans. Auto. Control, vol. AC-35, pp. 558-563.
Youla, D.C., J.J. Bongiorno, Jr., and C.N. Lu (1974). ‚ÄúSingle-loop feedback stabilization of linear
multivariable dynamical plants,‚Äù Automatica, vol. 10, pp. 159-173.
Youla, D.C., H.A. Jabr, and J.J. Bongiorno, Jr., (1976). ‚ÄúModern Wiener-Hopf design of optimal
controllers, part II: the multivariable case,‚Äù IEEE Trans. Auto. Control, vol. AC-21, pp. 319-338.
Youla, D.C. and M. Saito, (1967). ‚ÄúInterpolation with positive-real functions,‚Äù J. Franklin Inst.,
vol. 284, no. 2, pp. 77-108.
Zames, G. (1981). ‚ÄúFeedback and optimal sensitivity: model reference transformations, multiplica-
tive seminorms, and approximate inverses,‚Äù IEEE Trans. Auto. Control, vol. AC-26, pp. 301-320.
Zames, G. and B.A. Francis (1983). ‚ÄúFeedback, minimax sensitivity, and optimal robustness,‚Äù IEEE
Trans. Auto. Control, vol. AC-28, pp. 585-601.

Index
1-norm, 13
2-norm, 13, 16
2-norm minimization, 183
aÔ¨Éne function, 66
algebraic constraints, 89
allowable perturbation, 46
all-pass function, 92
analytic constraints, 90
area formula, 98
asymptotic tracking, 38
autocorrelation function, 19
average power, 14
biproper, 16
Cauchy‚Äôs integral formula, 90
Cauchy‚Äôs theorem, 90
characteristic polynomial, 36
closed-loop poles, 36
collocated, 126
command response, 57
complementary sensitivity function, 42
computing the 2-norm, 17, 25
computing the ‚àû-norm, 17, 27
conformal mapping, 193
conformally equivalent, 193
conservativeness, 49
controller parametrization, 73
coprime factorization, 68
coprime functions, 68
cross-correlation function, 20
cross-power spectral density function, 20
dissipative system, 158
energy, 14
energy spectral density, 41
Euclid‚Äôs algorithm, 69
exogenous input, 31
Ô¨Ånal-value theorem, 39
Ô¨Çexible beam, 178, 214
frequency-response experiment, 46
gain margin, 51
gain margin optimization, 195
Hermitian matrix, 157
‚àû-norm, 14, 16
instantaneous power, 14
internal model control, 88
internal stability, 35
interpolation constraints, 90
loop transfer function, 39
loopshaping, 105
M 0
maximum modulus theorem, 90
maximum stability margin, 189
minimum variance control, 187
minimum-phase function, 93
mixed sensitivity problem, 218
model matching, 155
model-matching error, 155
modiÔ¨Åed robust performance problem, 206
multiplicative perturbation, 46
Nevanlinna-Pick problem, 156
Nevanlinna‚Äôs algorithm, 160
nominal performance, 54
noncollocated, 126
norm, 13
Nyquist criterion, 38
Nyquist plot, 38
optimal Q, 155
optimal robust stability, 189
213

214
INDEX
Pareto optimal, 144
phase formula, 109
phase margin, 51
phase margin optimization, 200
Pick matrix, 157
Pick‚Äôs theorem, 157
Poisson integral formula, 91
positive deÔ¨Ånite, 157
positive semideÔ¨Ånite, 157
potentially optimal, 144
potentially uniquely optimal, 144
power signal, 14
power spectral density, 20
proper, 16
Pythagoras‚Äôs theorem, 184
ramp input, 39
relative degree, 98
Riemann mapping theorem, 193
robust controller, 50
robust performance, 54
robust stability, 50
robust stability problem, 189
self-optimal, 145
sensitivity function, 39-40
small-gain theorem, 53
spectral factor, 207
spectral factorization, 207
squareroot of a matrix, 165
stability margin, 50
stable, 16, 25
step input, 39
strictly proper, 16
strong stabilization, 78
strongly Pareto optimal, 144
structured uncertainty, 45
submultiplicative, 16
system gain, 18
total energy, 14
two-degree-of-freedom controller, 57
uniquely optimal, 144
uniquely self-optimal, 145
unity-feedback, 38
unstructured uncertainty, 45
waterbed eÔ¨Äect, 96
weighted sensitivity problem, 187
well-posedness, 33

