Feedback Control Theory
John Doyle, Bruce Francis, Allen Tannenbaum
c⃝Macmillan Publishing Co., 1990

Contents
Preface
iii
1
Introduction
1
1.1
Issues in Control System Design
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
What Is in This Book
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
2
Norms for Signals and Systems
13
2.1
Norms for Signals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13
2.2
Norms for Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
2.3
Input-Output Relationships . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
18
2.4
Power Analysis (Optional) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
2.5
Proofs for Tables 2.1 and 2.2 (Optional) . . . . . . . . . . . . . . . . . . . . . . . . .
21
2.6
Computing by State-Space Methods (Optional) . . . . . . . . . . . . . . . . . . . . .
24
3
Basic Concepts
31
3.1
Basic Feedback Loop . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
3.2
Internal Stability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
3.3
Asymptotic Tracking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
3.4
Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
40
4
Uncertainty and Robustness
45
4.1
Plant Uncertainty
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
45
4.2
Robust Stability
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
50
4.3
Robust Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
4.4
Robust Performance More Generally . . . . . . . . . . . . . . . . . . . . . . . . . . .
58
4.5
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
59
5
Stabilization
63
5.1
Controller Parametrization: Stable Plant . . . . . . . . . . . . . . . . . . . . . . . . .
63
5.2
Coprime Factorization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
65
5.3
Coprime Factorization by State-Space Methods (Optional) . . . . . . . . . . . . . . .
69
5.4
Controller Parametrization: General Plant . . . . . . . . . . . . . . . . . . . . . . . .
71
5.5
Asymptotic Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
5.6
Strong and Simultaneous Stabilization . . . . . . . . . . . . . . . . . . . . . . . . . .
75
5.7
Cart-Pendulum Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
i

6
Design Constraints
87
6.1
Algebraic Constraints
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
87
6.2
Analytic Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
88
7
Loopshaping
101
7.1
The Basic Technique of Loopshaping . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
7.2
The Phase Formula (Optional)
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
7.3
Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108
8
Advanced Loopshaping
117
8.1
Optimal Controllers
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
8.2
Loopshaping with C . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
8.3
Plants with RHP Poles and Zeros . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
8.4
Shaping S, T, or Q . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
8.5
Further Notions of Optimality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138
9
Model Matching
149
9.1
The Model-Matching Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
9.2
The Nevanlinna-Pick Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150
9.3
Nevanlinna’s Algorithm
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154
9.4
Solution of the Model-Matching Problem
. . . . . . . . . . . . . . . . . . . . . . . . 158
9.5
State-Space Solution (Optional) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
10 Design for Performance
163
10.1 P −1 Stable
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163
10.2 P −1 Unstable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168
10.3 Design Example: Flexible Beam
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
10.4 2-Norm Minimization
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
11 Stability Margin Optimization
181
11.1 Optimal Robust Stability
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
11.2 Conformal Mapping
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185
11.3 Gain Margin Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187
11.4 Phase Margin Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192
12 Design for Robust Performance
195
12.1 The Modiﬁed Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195
12.2 Spectral Factorization
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196
12.3 Solution of the Modiﬁed Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
12.4 Design Example: Flexible Beam Continued
. . . . . . . . . . . . . . . . . . . . . . . 204
References
209

Preface
Striking developments have taken place since 1980 in feedback control theory. The subject has be-
come both more rigorous and more applicable. The rigor is not for its own sake, but rather that even
in an engineering discipline rigor can lead to clarity and to methodical solutions to problems. The
applicability is a consequence both of new problem formulations and new mathematical solutions
to these problems. Moreover, computers and software have changed the way engineering design is
done. These developments suggest a fresh presentation of the subject, one that exploits these new
developments while emphasizing their connection with classical control.
Control systems are designed so that certain designated signals, such as tracking errors and
actuator inputs, do not exceed pre-speciﬁed levels.
Hindering the achievement of this goal are
uncertainty about the plant to be controlled (the mathematical models that we use in representing
real physical systems are idealizations) and errors in measuring signals (sensors can measure signals
only to a certain accuracy). Despite the seemingly obvious requirement of bringing plant uncertainty
explicitly into control problems, it was only in the early 1980s that control researchers re-established
the link to the classical work of Bode and others by formulating a tractable mathematical notion
of uncertainty in an input-output framework and developing rigorous mathematical techniques to
cope with it. This book formulates a precise problem, called the robust performance problem, with
the goal of achieving speciﬁed signal levels in the face of plant uncertainty.
The book is addressed to students in engineering who have had an undergraduate course in
signals and systems, including an introduction to frequency-domain methods of analyzing feedback
control systems, namely, Bode plots and the Nyquist criterion. A prior course on state-space theory
would be advantageous for some optional sections, but is not necessary. To keep the development
elementary, the systems are single-input/single-output and linear, operating in continuous time.
Chapters 1 to 7 are intended as the core for a one-semester senior course; they would need
supplementing with additional examples. These chapters constitute a basic treatment of feedback
design, containing a detailed formulation of the control design problem, the fundamental issue
of performance/stability robustness tradeoﬀ, and the graphical design technique of loopshaping,
suitable for benign plants (stable, minimum phase).
Chapters 8 to 12 are more advanced and
are intended for a ﬁrst graduate course.
Chapter 8 is a bridge to the latter half of the book,
extending the loopshaping technique and connecting it with notions of optimality. Chapters 9 to
12 treat controller design via optimization. The approach in these latter chapters is mathematical
rather than graphical, using elementary tools involving interpolation by analytic functions. This
mathematical approach is most useful for multivariable systems, where graphical techniques usually
break down. Nevertheless, we believe the setting of single-input/single-output systems is where this
new approach should be learned.
There are many people to whom we are grateful for their help in this book: Dale Enns for
sharing his expertise in loopshaping; Raymond Kwong and Boyd Pearson for class testing the book;
iii

and Munther Dahleh, Ciprian Foias, and Karen Rudie for reading earlier drafts. Numerous Caltech
students also struggled with various versions of this material: Gary Balas, Carolyn Beck, Bobby
Bodenheimer, and Roy Smith had particularly helpful suggestions. Finally, we would like to thank
the AFOSR, ARO, NSERC, NSF, and ONR for partial ﬁnancial support during the writing of this
book.
iv

Chapter 1
Introduction
Without control systems there could be no manufacturing, no vehicles, no computers, no regulated
environment—in short, no technology. Control systems are what make machines, in the broadest
sense of the term, function as intended. Control systems are most often based on the principle
of feedback, whereby the signal to be controlled is compared to a desired reference signal and the
discrepancy used to compute corrective control action. The goal of this book is to present a theory
of feedback control system design that captures the essential issues, can be applied to a wide range
of practical problems, and is as simple as possible.
1.1
Issues in Control System Design
The process of designing a control system generally involves many steps. A typical scenario is as
follows:
1. Study the system to be controlled and decide what types of sensors and actuators will be used
and where they will be placed.
2. Model the resulting system to be controlled.
3. Simplify the model if necessary so that it is tractable.
4. Analyze the resulting model; determine its properties.
5. Decide on performance speciﬁcations.
6. Decide on the type of controller to be used.
7. Design a controller to meet the specs, if possible; if not, modify the specs or generalize the
type of controller sought.
8. Simulate the resulting controlled system, either on a computer or in a pilot plant.
9. Repeat from step 1 if necessary.
10. Choose hardware and software and implement the controller.
11. Tune the controller on-line if necessary.
1

2
CHAPTER 1. INTRODUCTION
It must be kept in mind that a control engineer’s role is not merely one of designing control
systems for ﬁxed plants, of simply “wrapping a little feedback” around an already ﬁxed physical
system. It also involves assisting in the choice and conﬁguration of hardware by taking a system-
wide view of performance. For this reason it is important that a theory of feedback not only lead
to good designs when these are possible, but also indicate directly and unambiguously when the
performance objectives cannot be met.
It is also important to realize at the outset that practical problems have uncertain, non-
minimum-phase plants (non-minimum-phase means the existence of right half-plane zeros, so the
inverse is unstable); that there are inevitably unmodeled dynamics that produce substantial un-
certainty, usually at high frequency; and that sensor noise and input signal level constraints limit
the achievable beneﬁts of feedback.
A theory that excludes some of these practical issues can
still be useful in limited application domains. For example, many process control problems are so
dominated by plant uncertainty and right half-plane zeros that sensor noise and input signal level
constraints can be neglected. Some spacecraft problems, on the other hand, are so dominated by
tradeoﬀs between sensor noise, disturbance rejection, and input signal level (e.g., fuel consumption)
that plant uncertainty and non-minimum-phase eﬀects are negligible. Nevertheless, any general
theory should be able to treat all these issues explicitly and give quantitative and qualitative results
about their impact on system performance.
In the present section we look at two issues involved in the design process: deciding on perfor-
mance speciﬁcations and modeling. We begin with an example to illustrate these two issues.
Example A very interesting engineering system is the Keck astronomical telescope, currently
under construction on Mauna Kea in Hawaii. When completed it will be the world’s largest. The
basic objective of the telescope is to collect and focus starlight using a large concave mirror. The
shape of the mirror determines the quality of the observed image. The larger the mirror, the more
light that can be collected, and hence the dimmer the star that can be observed. The diameter of
the mirror on the Keck telescope will be 10 m. To make such a large, high-precision mirror out of
a single piece of glass would be very diﬃcult and costly. Instead, the mirror on the Keck telescope
will be a mosaic of 36 hexagonal small mirrors. These 36 segments must then be aligned so that
the composite mirror has the desired shape.
The control system to do this is illustrated in Figure 1.1.
As shown, the mirror segments
are subject to two types of forces: disturbance forces (described below) and forces from actuators.
Behind each segment are three piston-type actuators, applying forces at three points on the segment
to eﬀect its orientation. In controlling the mirror’s shape, it suﬃces to control the misalignment
between adjacent mirror segments. In the gap between every two adjacent segments are (capacitor-
type) sensors measuring local displacements between the two segments. These local displacements
are stacked into the vector labeled y; this is what is to be controlled. For the mirror to have the
ideal shape, these displacements should have certain ideal values that can be pre-computed; these
are the components of the vector r. The controller must be designed so that in the closed-loop
system y is held close to r despite the disturbance forces. Notice that the signals are vector valued.
Such a system is multivariable.
Our uncertainty about the plant arises from disturbance sources:
• As the telescope turns to track a star, the direction of the force of gravity on the mirror
changes.
• During the night, when astronomical observations are made, the ambient temperature changes.

1.1. ISSUES IN CONTROL SYSTEM DESIGN
3
controller
actuators
mirror
segments
sensors
-
-
-
?

6
r
u
y
disturbance forces
Figure 1.1: Block diagram of Keck telescope control system.
• The telescope is susceptible to wind gusts.
and from uncertain plant dynamics:
• The dynamic behavior of the components—mirror segments, actuators, sensors—cannot be
modeled with inﬁnite precision.
Now we continue with a discussion of the issues in general.
Control Objectives
Generally speaking, the objective in a control system is to make some output, say y, behave in a
desired way by manipulating some input, say u. The simplest objective might be to keep y small
(or close to some equilibrium point)—a regulator problem—or to keep y −r small for r, a reference
or command signal, in some set—a servomechanism or servo problem. Examples:
• On a commercial airplane the vertical acceleration should be less than a certain value for
passenger comfort.
• In an audio ampliﬁer the power of noise signals at the output must be suﬃciently small for
high ﬁdelity.
• In papermaking the moisture content must be kept between prescribed values.
There might be the side constraint of keeping u itself small as well, because it might be constrained
(e.g., the ﬂow rate from a valve has a maximum value, determined when the valve is fully open)
or it might be too expensive to use a large input. But what is small for a signal? It is natural to
introduce norms for signals; then “y small” means “∥y∥small.” Which norm is appropriate depends
on the particular application.
In summary, performance objectives of a control system naturally lead to the introduction of
norms; then the specs are given as norm bounds on certain key signals of interest.

4
CHAPTER 1. INTRODUCTION
Models
Before discussing the issue of modeling a physical system it is important to distinguish among four
diﬀerent objects:
1. Real physical system: the one “out there.”
2. Ideal physical model: obtained by schematically decomposing the real physical system into
ideal building blocks; composed of resistors, masses, beams, kilns, isotropic media, Newtonian
ﬂuids, electrons, and so on.
3. Ideal mathematical model: obtained by applying natural laws to the ideal physical model;
composed of nonlinear partial diﬀerential equations, and so on.
4. Reduced mathematical model: obtained from the ideal mathematical model by linearization,
lumping, and so on; usually a rational transfer function.
Sometimes language makes a fuzzy distinction between the real physical system and the ideal
physical model. For example, the word resistor applies to both the actual piece of ceramic and
metal and the ideal object satisfying Ohm’s law. Of course, the adjectives real and ideal could be
used to disambiguate.
No mathematical system can precisely model a real physical system; there is always uncertainty.
Uncertainty means that we cannot predict exactly what the output of a real physical system will
be even if we know the input, so we are uncertain about the system. Uncertainty arises from two
sources: unknown or unpredictable inputs (disturbance, noise, etc.) and unpredictable dynamics.
What should a model provide? It should predict the input-output response in such a way that
we can use it to design a control system, and then be conﬁdent that the resulting design will work
on the real physical system. Of course, this is not possible. A “leap of faith” will always be required
on the part of the engineer. This cannot be eliminated, but it can be made more manageable with
the use of eﬀective modeling, analysis, and design techniques.
Mathematical Models in This Book
The models in this book are ﬁnite-dimensional, linear, and time-invariant. The main reason for this
is that they are the simplest models for treating the fundamental issues in control system design.
The resulting design techniques work remarkably well for a large class of engineering problems,
partly because most systems are built to be as close to linear time-invariant as possible so that they
are more easily controlled. Also, a good controller will keep the system in its linear regime. The
uncertainty description is as simple as possible as well.
The basic form of the plant model in this book is
y = (P + ∆)u + n.
Here y is the output, u the input, and P the nominal plant transfer function. The model uncertainty
comes in two forms:
n:
unknown noise or disturbance
∆:
unknown plant perturbation

1.1. ISSUES IN CONTROL SYSTEM DESIGN
5
Both n and ∆will be assumed to belong to sets, that is, some a priori information is assumed
about n and ∆. Then every input u is capable of producing a set of outputs, namely, the set of
all outputs (P + ∆)u + n as n and ∆range over their sets. Models capable of producing sets of
outputs for a single input are said to be nondeterministic. There are two main ways of obtaining
models, as described next.
Models from Science
The usual way of getting a model is by applying the laws of physics, chemistry, and so on. Consider
the Keck telescope example. One can write down diﬀerential equations based on physical principles
(e.g., Newton’s laws) and making idealizing assumptions (e.g., the mirror segments are rigid). The
coeﬃcients in the diﬀerential equations will depend on physical constants, such as masses and
physical dimensions. These can be measured. This method of applying physical laws and taking
measurements is most successful in electromechanical systems, such as aerospace vehicles and robots.
Some systems are diﬃcult to model in this way, either because they are too complex or because
their governing laws are unknown.
Models from Experimental Data
The second way of getting a model is by doing experiments on the physical system. Let’s start
with a simple thought experiment, one that captures many essential aspects of the relationships
between physical systems and their models and the issues in obtaining models from experimental
data. Consider a real physical system—the plant to be controlled—with one input, u, and one
output, y. To design a control system for this plant, we must understand how u aﬀects y.
The experiment runs like this. Suppose that the real physical system is in a rest state before
an input u is applied (i.e., u = y = 0). Now apply some input signal u, resulting in some output
signal y. Observe the pair (u, y). Repeat this experiment several times. Pretend that these data
pairs are all we know about the real physical system. (This is the black box scenario. Usually, we
know something about the internal workings of the system.)
After doing this experiment we will notice several things. First, the same input signal at diﬀerent
times produces diﬀerent output signals. Second, if we hold u = 0, y will ﬂuctuate in an unpredictable
manner. Thus the real physical system produces just one output for any given input, so it itself
is deterministic. However, we observers are uncertain because we cannot predict what that output
will be.
Ideally, the model should cover the data in the sense that it should be capable of producing
every experimentally observed input-output pair. (Of course, it would be better to cover not just
the data observed in a ﬁnite number of experiments, but anything that can be produced by the real
physical system. Obviously, this is impossible.) If nondeterminism that reasonably covers the range
of expected data is not built into the model, we will not trust that designs based on such models
will work on the real system.
In summary, for a useful theory of control design, plant models must be nondeterministic, having
uncertainty built in explicitly.
Synthesis Problem
A synthesis problem is a theoretical problem, precise and unambiguous. Its purpose is primarily
pedagogical: It gives us something clear to focus on for the purpose of study. The hope is that

6
CHAPTER 1. INTRODUCTION
the principles learned from studying a formal synthesis problem will be useful when it comes to
designing a real control system.
The most general block diagram of a control system is shown in Figure 1.2. The generalized plant
generalized
plant
controller
-
-
-

w
z
u
y
Figure 1.2: Most general control system.
consists of everything that is ﬁxed at the start of the control design exercise: the plant, actuators
that generate inputs to the plant, sensors measuring certain signals, analog-to-digital and digital-
to-analog converters, and so on. The controller consists of the designable part: it may be an electric
circuit, a programmable logic controller, a general-purpose computer, or some other such device.
The signals w, z, y, and u are, in general, vector-valued functions of time. The components of w
are all the exogenous inputs: references, disturbances, sensor noises, and so on. The components of
z are all the signals we wish to control: tracking errors between reference signals and plant outputs,
actuator signals whose values must be kept between certain limits, and so on. The vector y contains
the outputs of all sensors. Finally, u contains all controlled inputs to the generalized plant. (Even
open-loop control ﬁts in; the generalized plant would be so deﬁned that y is always constant.)
Very rarely is the exogenous input w a ﬁxed, known signal. One of these rare instances is where
a robot manipulator is required to trace out a deﬁnite path, as in welding. Usually, w is not ﬁxed
but belongs to a set that can be characterized to some degree. Some examples:
• In a thermostat-controlled temperature regulator for a house, the reference signal is always
piecewise constant: at certain times during the day the thermostat is set to a new value. The
temperature of the outside air is not piecewise constant but varies slowly within bounds.
• In a vehicle such as an airplane or ship the pilot’s commands on the steering wheel, throttle,
pedals, and so on come from a predictable set, and the gusts and wave motions have amplitudes
and frequencies that can be bounded with some degree of conﬁdence.
• The load power drawn on an electric power system has predictable characteristics.
Sometimes the designer does not attempt to model the exogenous inputs. Instead, she or he
designs for a suitable response to a test input, such as a step, a sinusoid, or white noise. The
designer may know from past experience how this correlates with actual performance in the ﬁeld.
Desired properties of z generally relate to how large it is according to various measures, as discussed
above.

1.2. WHAT IS IN THIS BOOK
7
Finally, the output of the design exercise is a mathematical model of a controller. This must
be implementable in hardware.
If the controller you design is governed by a nonlinear partial
diﬀerential equation, how are you going to implement it? A linear ordinary diﬀerential equation
with constant coeﬃcients, representing a ﬁnite-dimensional, time-invariant, linear system, can be
simulated via an analog circuit or approximated by a digital computer, so this is the most common
type of control law.
The synthesis problem can now be stated as follows: Given a set of generalized plants, a set
of exogenous inputs, and an upper bound on the size of z, design an implementable controller to
achieve this bound. How the size of z is to be measured (e.g., power or maximum amplitude)
depends on the context. This book focuses on an elementary version of this problem.
1.2
What Is in This Book
Since this book is for a ﬁrst course on this subject, attention is restricted to systems whose models
are single-input/single-output, ﬁnite-dimensional, linear, and time-invariant. Thus they have trans-
fer functions that are rational in the Laplace variable s. The general layout of the book is that
Chapters 2 to 4 and 6 are devoted to analysis of control systems, that is, the controller is already
speciﬁed, and Chapters 5 and 7 to 12 to design.
Performance of a control system is speciﬁed in terms of the size of certain signals of interest. For
example, the performance of a tracking system could be measured by the size of the error signal.
Chapter 2, Norms for Signals and Systems, looks at several ways of deﬁning norms for a signal u(t);
in particular, the 2-norm (associated with energy),
Z ∞
−∞
u(t)2dt
1/2
,
the ∞-norm (maximum absolute value),
max
t
|u(t)|,
and the square root of the average power (actually, not quite a norm),

lim
T→∞
1
2T
Z T
−T
u(t)2dt
1/2
.
Also introduced are two norms for a system’s transfer function G(s): the 2-norm,
∥G∥2 :=
 1
2π
Z ∞
−∞
|G(jω)|2dω
1/2
,
and the ∞-norm,
∥G∥∞:= max
ω
|G(jω)|.
Notice that ∥G∥∞equals the peak amplitude on the Bode magnitude plot of G. Then two very
useful tables are presented summarizing input-output norm relationships. For example, one table
gives a bound on the 2-norm of the output knowing the 2-norm of the input and the ∞-norm of the

8
CHAPTER 1. INTRODUCTION
C
P






-
-
-
-
-

?
?
6
r
u
y
d
n
−
e
Figure 1.3: Single-loop feedback system.
transfer function. Such results are very useful in predicting, for example, the eﬀect a disturbance
will have on the output of a feedback system.
Chapters 3 and 4 are the most fundamental in the book. The system under consideration is
shown in Figure 1.3, where P and C are the plant and controller transfer functions. The signals are
as follows:
r
reference or command input
e
tracking error
u
control signal, controller output
d
plant disturbance
y
plant output
n
sensor noise
In Chapter 3, Basic Concepts, internal stability is deﬁned and characterized. Then the system is
analyzed for its ability to track a single reference signal r—a step or a ramp—asymptotically as
time increases. Finally, we look at tracking a set of reference signals. The transfer function from
reference input r to tracking error e is denoted S, the sensitivity function. It is argued that a useful
tracking performance criterion is ∥W1S∥∞< 1, where W1 is a transfer function which can be tuned
by the control system designer.
Since no mathematical system can exactly model a physical system, we must be aware of how
modeling errors might adversely aﬀect the performance of a control system. Chapter 4, Uncertainty
and Robustness, begins with a treatment of various models of plant uncertainty. The basic technique
is to model the plant as belonging to a set P. Such a set can be either structured—for example,
there are a ﬁnite number of uncertain parameters—or unstructured—the frequency response lies in
a set in the complex plane for every frequency. For us, unstructured is more important because it
leads to a simple and useful design theory. In particular, multiplicative perturbation is chosen for
detailed study, it being typical. In this uncertainty model there is a nominal plant P and the family
P consists of all perturbed plants ˜P such that at each frequency ω the ratio ˜P(jω)/P(jω) lies in a
disk in the complex plane with center 1. This notion of disk-like uncertainty is key; because of it
the mathematical problems are tractable.
Generally speaking, the notion of robustness means that some characteristic of the feedback
system holds for every plant in the set P. A controller C provides robust stability if it provides
internal stability for every plant in P. Chapter 4 develops a test for robust stability for the multi-
plicative perturbation model, a test involving C and P. The test is ∥W2T∥∞< 1. Here T is the

1.2. WHAT IS IN THIS BOOK
9
complementary sensitivity function, equal to 1 −S (or the transfer function from r to y), and W2
is a transfer function whose magnitude at frequency ω equals the radius of the uncertainty disk at
that frequency.
The ﬁnal topic in Chapter 4 is robust performance, guaranteed tracking in the face of plant
uncertainty. The main result is that the tracking performance spec ∥W1S∥∞< 1 is satisﬁed for all
plants in the multiplicative perturbation set if and only if the magnitude of |W1S| + |W2T| is less
than 1 for all frequencies, that is,
∥|W1S| + |W2T|∥∞< 1.
(1.1)
This is an analysis result: It tells exactly when some candidate controller provides robust perfor-
mance.
Chapter 5, Stabilization, is the ﬁrst on design. Most synthesis problems can be formulated like
this: Given P, design C so that the feedback system (1) is internally stable, and (2) acquires some
additional desired property or properties, for example, the output y asymptotically tracks a step
input r. The method of solution presented here is to parametrize all Cs for which (1) is true and
then to ﬁnd a parameter for which (2) holds. In this chapter such a parametrization is derived; it
has the form
C = X + MQ
Y −NQ ,
where N, M, X, and Y are ﬁxed stable proper transfer functions and Q is the parameter, an
arbitrary stable proper transfer function. The usefulness of this parametrization derives from the
fact that all closed-loop transfer functions are very simple functions of Q; for instance, the sensitivity
function S, while a nonlinear function of C, equals simply MY −MNQ. This parametrization
is then applied to three problems: achieving asymptotic performance specs, such as tracking a
step; internal stabilization by a stable controller; and simultaneous stabilization of two plants by a
common controller.
Before we see how to design control systems for the robust performance speciﬁcation, it is
important to understand the basic limitations on achievable performance: Why can’t we achieve
both arbitrarily good performance and stability robustness at the same time? In Chapter 6, Design
Constraints, we study design constraints arising from two sources: from algebraic relationships that
must hold among various transfer functions and from the fact that closed-loop transfer functions
must be stable, that is, analytic in the right half-plane. The main conclusion is that feedback control
design always involves a tradeoﬀbetween performance and stability robustness.
Chapter 7, Loopshaping, presents a graphical technique for designing a controller to achieve
robust performance. This method is the most common in engineering practice. It is especially
suitable for today’s CAD packages in view of their graphics capabilities. The loop transfer function
is L := PC.
The idea is to shape the Bode magnitude plot of L so that (1.1) is achieved, at
least approximately, and then to back-solve for C via C = L/P. When P or P −1 is not stable, L
must contain Ps unstable poles and zeros (for internal stability of the feedback loop), an awkward
constraint. For this reason, it is assumed in Chapter 7 that P and P −1 are both stable.
Thus Chapters 2 to 7 constitute a basic treatment of feedback design, containing a detailed
formulation of the control design problem, the fundamental issue of performance/stability robustness
tradeoﬀ, and a graphical design technique suitable for benign plants (stable, minimum-phase).
Chapters 8 to 12 are more advanced.

10
CHAPTER 1. INTRODUCTION
Chapter 8, Advanced Loopshaping, is a bridge between the two halves of the book; it extends the
loopshaping technique and connects it with the notion of optimal designs. Loopshaping in Chapter 7
focuses on L, but other quantities, such as C, S, T, or the Q parameter in the stabilization results
of Chapter 5, may also be “shaped” to achieve the same end. For many problems these alternatives
are more convenient. Chapter 8 also oﬀers some suggestions on how to extend loopshaping to handle
right half-plane poles and zeros.
Optimal controllers are introduced in a formal way in Chapter 8. Several diﬀerent notions of
optimality are considered with an aim toward understanding in what way loopshaping controllers
can be said to be optimal.
It is shown that loopshaping controllers satisfy a very strong type
of optimality, called self-optimality.
The implication of this result is that when loopshaping is
successful at ﬁnding an adequate controller, it cannot be improved upon uniformly.
Chapters 9 to 12 present a recently developed approach to the robust performance design prob-
lem. The approach is mathematical rather than graphical, using elementary tools involving interpo-
lation by analytic functions. This mathematical approach is most useful for multivariable systems,
where graphical techniques usually break down. Nevertheless, the setting of single-input/single-
output systems is where this new approach should be learned. Besides, present-day software for
control design (e.g., MATLAB and Program CC) incorporate this approach.
Chapter 9, Model Matching, studies a hypothetical control problem called the model-matching
problem: Given stable proper transfer functions T1 and T2, ﬁnd a stable transfer function Q to
minimize ∥T1 −T2Q∥∞. The interpretation is this: T1 is a model, T2 is a plant, and Q is a cascade
controller to be designed so that T2Q approximates T1. Thus T1−T2Q is the error transfer function.
This problem is turned into a special interpolation problem: Given points {ai} in the right half-
plane and values {bi}, also complex numbers, ﬁnd a stable transfer function G so that ∥G∥∞< 1
and G(ai) = bi, that is, G interpolates the value bi at the point ai. When such a G exists and how
to ﬁnd one utilizes some beautiful mathematics due to Nevanlinna and Pick.
Chapter 10, Design for Performance, treats the problem of designing a controller to achieve the
performance criterion ∥W1S∥∞< 1 alone, that is, with no plant uncertainty. When does such a
controller exist, and how can it be computed? These questions are easy when the inverse of the
plant transfer function is stable. When the inverse is unstable (i.e., P is non-minimum-phase), the
questions are more interesting. The solutions presented in this chapter use model-matching theory.
The procedure is applied to designing a controller for a ﬂexible beam. The desired performance is
given in terms of step response specs: overshoot and settling time. It is shown how to choose the
weight W1 to accommodate these time domain specs. Also treated in Chapter 10 is minimization
of the 2-norm of some closed-loop transfer function, e.g., ∥W1S∥2.
Next, in Chapter 11, Stability Margin Optimization, is considered the problem of designing a
controller whose sole purpose is to maximize the stability margin, that is, performance is ignored.
The maximum obtainable stability margin is a measure of how diﬃcult the plant is to control.
Three measures of stability margin are treated: the ∞-norm of a multiplicative perturbation, gain
margin, and phase margin. It is shown that the problem of optimizing these stability margins can
also be reduced to a model-matching problem.
Chapter 12, Design for Robust Performance, returns to the robust performance problem of
designing a controller to achieve (1.1).
Chapter 7 proposed loopshaping as a graphical method
when P and P −1 are stable. Without these assumptions loopshaping can be awkward and the
methodical procedure in this chapter can be used. Actually, (1.1) is too hard for mathematical

1.2. WHAT IS IN THIS BOOK
11
analysis, so a compromise criterion is posed, namely,
∥|W1S|2 + |W2T|2∥∞< 1/2.
(1.2)
Using a technique called spectral factorization, we can reduce this problem to a model-matching
problem. As an illustration, the ﬂexible beam example is reconsidered; besides step response specs
on the tip deﬂection, a hard limit is placed on the plant input to prevent saturation of an ampliﬁer.
Finally, some words about frequency-domain versus time-domain methods of design. Horowitz
(1963) has long maintained that “frequency response methods have been found to be especially
useful and transparent, enabling the designer to see the tradeoﬀbetween conﬂicting design factors.”
This point of view has gained much greater acceptance within the control community at large
in recent years, although perhaps it would be better to stress the importance of input-output or
operator-theoretic versus state-space methods, instead of frequency domain versus time domain.
This book focuses almost exclusively on input-output methods, not because they are ultimately
more fundamental than state-space methods, but simply for pedagogical reasons.
Notes and References
There are many books on feedback control systems. Particularly good ones are Bower and Schultheiss
(1961) and Franklin et al. (1986). Regarding the Keck telescope, see Aubrun et al. (1987, 1988).

12
CHAPTER 1. INTRODUCTION

Chapter 2
Norms for Signals and Systems
One way to describe the performance of a control system is in terms of the size of certain signals
of interest. For example, the performance of a tracking system could be measured by the size of
the error signal. This chapter looks at several ways of deﬁning a signal’s size (i.e., at several norms
for signals). Which norm is appropriate depends on the situation at hand. Also introduced are
norms for a system’s transfer function. Then two very useful tables are developed summarizing
input-output norm relationships.
2.1
Norms for Signals
We consider signals mapping (−∞, ∞) to R. They are assumed to be piecewise continuous. Of
course, a signal may be zero for t < 0 (i.e., it may start at time t = 0).
We are going to introduce several diﬀerent norms for such signals. First, recall that a norm
must have the following four properties:
(i) ∥u∥≥0
(ii) ∥u∥= 0 ⇔u(t) = 0,
∀t
(iii) ∥au∥= |a|∥u∥,
∀a ∈R
(iv) ∥u + v∥≤∥u∥+ ∥v∥
The last property is the familiar triangle inequality.
1-Norm The 1-norm of a signal u(t) is the integral of its absolute value:
∥u∥1 :=
Z ∞
−∞
|u(t)|dt.
2-Norm The 2-norm of u(t) is
∥u∥2 :=
Z ∞
−∞
u(t)2dt
1/2
.
13

14
CHAPTER 2. NORMS FOR SIGNALS AND SYSTEMS
For example, suppose that u is the current through a 1 Ωresistor. Then the instantaneous power
equals u(t)2 and the total energy equals the integral of this, namely, ∥u∥2
2. We shall generalize this
interpretation: The instantaneous power of a signal u(t) is deﬁned to be u(t)2 and its energy is
deﬁned to be the square of its 2-norm.
∞-Norm The ∞-norm of a signal is the least upper bound of its absolute value:
∥u∥∞:= sup
t
|u(t)|.
For example, the ∞-norm of
(1 −e−t)1(t)
equals 1. Here 1(t) denotes the unit step function.
Power Signals The average power of u is the average over time of its instantaneous power:
lim
T→∞
1
2T
Z T
−T
u(t)2dt.
The signal u will be called a power signal if this limit exists, and then the squareroot of the average
power will be denoted pow(u):
pow(u) :=

lim
T→∞
1
2T
Z T
−T
u(t)2dt
1/2
.
Note that a nonzero signal can have zero average power, so pow is not a norm. It does, however,
have properties (i), (iii), and (iv).
Now we ask the question: Does ﬁniteness of one norm imply ﬁniteness of any others? There are
some easy answers:
1. If ∥u∥2 < ∞, then u is a power signal with pow(u) = 0.
Proof Assuming that u has ﬁnite 2-norm, we get
1
2T
Z T
−T
u(t)2dt ≤1
2T ∥u∥2
2.
But the right-hand side tends to zero as T →∞. ■
2. If u is a power signal and ∥u∥∞< ∞, then pow(u) ≤∥u∥∞.
Proof We have
1
2T
Z T
−T
u(t)2dt ≤∥u∥2
∞
1
2T
Z T
−T
dt = ∥u∥2
∞.
Let T tend to ∞. ■

2.2. NORMS FOR SYSTEMS
15
pow
2
∞
1
Figure 2.1: Set inclusions.
3. If ∥u∥1 < ∞and ∥u∥∞< ∞, then ∥u∥2 ≤(∥u∥∞∥u∥1)1/2, and hence ∥u∥2 < ∞.
Proof
Z ∞
−∞
u(t)2dt =
Z ∞
−∞
|u(t)||u(t)|dt ≤∥u∥∞∥u∥1 ■
A Venn diagram summarizing the set inclusions is shown in Figure 2.1. Note that the set labeled
“pow” contains all power signals for which pow is ﬁnite; the set labeled “1” contains all signals of
ﬁnite 1-norm; and so on. It is instructive to get examples of functions in all the components of this
diagram (Exercise 2). For example, consider
u1(t) =



0,
if t ≤0
1/
√
t,
if 0 < t ≤1
0,
if t > 1.
This has ﬁnite 1-norm:
∥u1∥1 =
Z 1
0
1
√
tdt = 2.
Its 2-norm is inﬁnite because the integral of 1/t is divergent over the interval [0, 1]. For the same
reason, u1 is not a power signal. Finally, u1 is not bounded, so ∥u1∥∞is inﬁnite. Therefore, u1 lives
in the bottom component in the diagram.
2.2
Norms for Systems
We consider systems that are linear, time-invariant, causal, and (usually) ﬁnite-dimensional. In the
time domain an input-output model for such a system has the form of a convolution equation,
y = G ∗u,

16
CHAPTER 2. NORMS FOR SIGNALS AND SYSTEMS
that is,
y(t) =
Z ∞
−∞
G(t −τ)u(τ)dτ.
Causality means that G(t) = 0 for t < 0.
Let ˆG(s) denote the transfer function, the Laplace
transform of G. Then ˆG is rational (by ﬁnite-dimensionality) with real coeﬃcients. We say that ˆG
is stable if it is analytic in the closed right half-plane (Re s ≥0), proper if ˆG(j∞) is ﬁnite (degree
of denominator ≥degree of numerator), strictly proper if ˆG(j∞) = 0 (degree of denominator >
degree of numerator), and biproper if ˆG and ˆG−1 are both proper (degree of denominator = degree
of numerator).
We introduce two norms for the transfer function ˆG.
2-Norm
∥ˆG∥2 :=
 1
2π
Z ∞
−∞
| ˆG(jω)|2dω
1/2
∞-Norm
∥ˆG∥∞:= sup
ω | ˆG(jω)|
Note that if ˆG is stable, then by Parseval’s theorem
∥ˆG∥2 =
 1
2π
Z ∞
−∞
| ˆG(jω)|2dω
1/2
=
Z ∞
−∞
|G(t)|2dt
1/2
.
The ∞-norm of ˆG equals the distance in the complex plane from the origin to the farthest point
on the Nyquist plot of ˆG. It also appears as the peak value on the Bode magnitude plot of ˆG. An
important property of the ∞-norm is that it is submultiplicative:
∥ˆG ˆH∥∞≤∥ˆG∥∞∥ˆH∥∞.
It is easy to tell when these two norms are ﬁnite.
Lemma 1 The 2-norm of ˆG is ﬁnite iﬀˆG is strictly proper and has no poles on the imaginary
axis; the ∞-norm is ﬁnite iﬀˆG is proper and has no poles on the imaginary axis.
Proof
Assume that ˆG is strictly proper, with no poles on the imaginary axis. Then the Bode
magnitude plot rolls oﬀat high frequency. It is not hard to see that the plot of c/(τs+1) dominates
that of ˆG for suﬃciently large positive c and suﬃciently small positive τ, that is,
|c/(τjω + 1)| ≥| ˆG(jω)|,
∀ω.
But c/(τs + 1) has ﬁnite 2-norm; its 2-norm equals c/
√
2τ (how to do this computation is shown
below). Hence ˆG has ﬁnite 2-norm.
The rest of the proof follows similar lines. ■

2.2. NORMS FOR SYSTEMS
17
How to Compute the 2-Norm
Suppose that ˆG is strictly proper and has no poles on the imaginary axis (so its 2-norm is ﬁnite).
We have
∥ˆG∥2
2
=
1
2π
Z ∞
−∞
| ˆG(jω)|2dω
=
1
2πj
Z j∞
−j∞
ˆG(−s) ˆG(s)ds
=
1
2πj
I
ˆG(−s) ˆG(s)ds.
The last integral is a contour integral up the imaginary axis, then around an inﬁnite semicircle in
the left half-plane; the contribution to the integral from this semicircle equals zero because ˆG is
strictly proper. By the residue theorem, ∥ˆG∥2
2 equals the sum of the residues of ˆG(−s) ˆG(s) at its
poles in the left half-plane.
Example 1 Take ˆG(s) = 1/(τs + 1), τ > 0. The left half-plane pole of ˆG(−s) ˆG(s) is at s = −1/τ.
The residue at this pole equals
lim
s→−1/τ

s + 1
τ

1
−τs + 1
1
τs + 1 = 1
2τ .
Hence ∥ˆG∥2 = 1/
√
2τ.
How to Compute the ∞-Norm
This requires a search. Set up a ﬁne grid of frequency points,
{ω1, . . . , ωN}.
Then an estimate for ∥ˆG∥∞is
max
1≤k≤N | ˆG(jωk)|.
Alternatively, one could ﬁnd where | ˆG(jω)| is maximum by solving the equation
d| ˆG|2
dω (jω) = 0.
This derivative can be computed in closed form because ˆG is rational. It then remains to compute
the roots of a polynomial.
Example 2 Consider
ˆG(s) = as + 1
bs + 1
with a, b > 0. Look at the Bode magnitude plot: For a ≥b it is increasing (high-pass); else, it is
decreasing (low-pass). Thus
∥ˆG∥∞=
 a/b,
a ≥b
1,
a < b.

18
CHAPTER 2. NORMS FOR SIGNALS AND SYSTEMS
2.3
Input-Output Relationships
The question of interest in this section is: If we know how big the input is, how big is the output
going to be? Consider a linear system with input u, output y, and transfer function ˆG, assumed
stable and strictly proper. The results are summarized in two tables below. Suppose that u is the
unit impulse, δ. Then the 2-norm of y equals the 2-norm of G, which by Parseval’s theorem equals
the 2-norm of ˆG; this gives entry (1,1) in Table 2.1. The rest of the ﬁrst column is for the ∞-norm
and pow, and the second column is for a sinusoidal input. The ∞in the (1,2) entry is true as long
as ˆG(jω) ̸= 0.
u(t) = δ(t)
u(t) = sin(ωt)
∥y∥2
∥ˆG∥2
∞
∥y∥∞
∥G∥∞
| ˆG(jω)|
pow(y)
0
1
√
2| ˆG(jω)|
Table 2.1: Output norms and pow for two inputs
Now suppose that u is not a ﬁxed signal but that it can be any signal of 2-norm ≤1. It turns
out that the least upper bound on the 2-norm of the output, that is,
sup{∥y∥2 : ∥u∥2 ≤1},
which we can call the 2-norm/2-norm system gain, equals the ∞-norm of ˆG; this provides entry
(1,1) in Table 2.2. The other entries are the other system gains. The ∞in the various entries is
true as long as ˆG ̸≡0, that is, as long as there is some ω for which ˆG(jω) ̸= 0.
∥u∥2
∥u∥∞
pow(u)
∥y∥2
∥ˆG∥∞
∞
∞
∥y∥∞
∥ˆG∥2
∥G∥1
∞
pow(y)
0
≤∥ˆG∥∞
∥ˆG∥∞
Table 2.2: System Gains
A typical application of these tables is as follows. Suppose that our control analysis or design
problem involves, among other things, a requirement of disturbance attenuation: The controlled
system has a disturbance input, say u, whose eﬀect on the plant output, say y, should be small. Let
G denote the impulse response from u to y. The controlled system will be required to be stable, so
the transfer function ˆG will be stable. Typically, it will be strictly proper, too (or at least proper).
The tables tell us how much u aﬀects y according to various measures. For example, if u is known
to be a sinusoid of ﬁxed frequency (maybe u comes from a power source at 60 Hz), then the second
column of Table 2.1 gives the relative size of y according to the three measures. More commonly,
the disturbance signal will not be known a priori, so Table 2.2 will be more relevant.

2.4. POWER ANALYSIS (OPTIONAL)
19
Notice that the ∞-norm of the transfer function appears in several entries in the tables. This
norm is therefore an important measure for system performance.
Example A system with transfer function 1/(10s + 1) has a disturbance input d(t) known to have
the energy bound ∥d∥2 ≤0.4. Suppose that we want to ﬁnd the best estimate of the ∞-norm of
the output y(t). Table 2.2 says that the 2-norm/∞-norm gain equals the 2-norm of the transfer
function, which equals 1/
√
20. Thus
∥y∥∞≤0.4
√
20.
The next two sections concern the proofs of the tables and are therefore optional.
2.4
Power Analysis (Optional)
For a power signal u deﬁne the autocorrelation function
Ru(τ) := lim
T→∞
1
2T
Z T
−T
u(t)u(t + τ)dt,
that is, Ru(τ) is the average value of the product u(t)u(t + τ). Observe that
Ru(0) = pow(u)2 ≥0.
We must restrict our deﬁnition of a power signal to those signals for which the above limit exists
for all values of τ, not just τ = 0. For such signals we have the additional property that
|Ru(τ)| ≤Ru(0).
Proof The Cauchy-Schwarz inequality implies that

Z T
−T
u(t)v(t)dt
 ≤
Z T
−T
u(t)2dt
1/2 Z T
−T
v(t)2dt
1/2
.
Set v(t) = u(t + τ) and multiply by 1/(2T) to get

1
2T
Z T
−T
u(t)u(t + τ)dt
 ≤
 1
2T
Z T
−T
u(t)2dt
1/2  1
2T
Z T
−T
u(t + τ)2dt
1/2
.
Now let T →∞to get the desired result. ■
Let Su denote the Fourier transform of Ru. Thus
Su(jω)
=
Z ∞
−∞
Ru(τ)e−jωτdτ,
Ru(τ)
=
1
2π
Z ∞
−∞
Su(jω)ejωτdω,
pow(u)2
=
Ru(0) = 1
2π
Z ∞
−∞
Su(jω)dω.

20
CHAPTER 2. NORMS FOR SIGNALS AND SYSTEMS
From the last equation we interpret Su(jω)/2π as power density. The function Su is called the
power spectral density of the signal u.
Now consider two power signals, u and v. Their cross-correlation function is
Ruv(τ) := lim
T→∞
1
2T
Z T
−T
u(t)v(t + τ)dt
and Suv, the Fourier transform, is called their cross-power spectral density function.
We now derive some useful facts concerning a linear system with transfer function ˆG, assumed
stable and proper, and its input u and output y.
1. Ruy = G ∗Ru
Proof Since
y(t) =
Z ∞
−∞
G(α)u(t −α)dα
(2.1)
we have
u(t)y(t + τ) =
Z ∞
−∞
G(α)u(t)u(t + τ −α)dα.
Thus the average value of u(t)y(t + τ) equals
Z ∞
−∞
G(α)Ru(τ −α)dα. ■
2. Ry = G ∗Grev ∗Ru where Grev(t) := G(−t)
Proof Using (2.1) we get
y(t)y(t + τ) =
Z ∞
−∞
G(α)y(t)u(t + τ −α)dα,
so the average value of y(t)y(t + τ) equals
Z ∞
−∞
G(α)Ryu(τ −α)dα
(i.e., Ry = G ∗Ryu). Similarly, you can check that Ryu = Grev ∗Ru. ■
3. Sy(jω) = | ˆG(jω)|2Su(jω)
Proof From the previous fact we have
Sy(jω) = ˆG(jω) ˆGrev(jω)Su(jω),
so it remains to show that the Fourier transform of Grev equals the complex-conjugate of ˆG(jω).
This is easy. ■

2.5. PROOFS FOR TABLES 2.1 AND 2.2 (OPTIONAL)
21
2.5
Proofs for Tables 2.1 and 2.2 (Optional)
Table 2.1
Entry (1,1) If u = δ, then y = G, so ∥y∥2 = ∥G∥2. But by Parseval’s theorem, ∥G∥2 = ∥ˆG∥2.
Entry (2,1) Again, since y = G.
Entry (3,1)
pow(y)2
=
lim 1
2T
Z T
0
G(t)2dt
≤
lim 1
2T
Z ∞
0
G(t)2dt
=
lim 1
2T ∥G∥2
2
=
0
Entry (1,2) With the input u(t) = sin(ωt), the output is
y(t) = | ˆG(jω)| sin[ωt + arg ˆG(jω)].
(2.2)
The 2-norm of this signal is inﬁnite as long as ˆG(jω) ̸= 0, that is, the system’s transfer function
does not have a zero at the frequency of excitation.
Entry (2,2) The amplitude of the sinusoid (2.2) equals | ˆG(jω)|.
Entry (3,2) Let φ := arg ˆG(jω). Then
pow(y)2
=
lim 1
2T
Z T
−T
| ˆG(jω)|2 sin2(ωt + φ)dt
=
| ˆG(jω)|2 lim 1
2T
Z T
−T
sin2(ωt + φ)dt
=
| ˆG(jω)|2 lim
1
2ωT
Z ωT+φ
−ωT+φ
sin2(θ)dθ
=
| ˆG(jω)|2 1
π
Z π
0
sin2(θ)dθ
=
1
2| ˆG(jω)|2.
Table 2.2
Entry (1,1) First we see that ∥ˆG∥∞is an upper bound on the 2-norm/2-norm system gain:
∥y∥2
2
=
∥ˆy∥2
2
=
1
2π
Z ∞
−∞
| ˆG(jω)|2|ˆu(jω)|2dω
≤
∥ˆG∥2
∞
1
2π
Z ∞
−∞
|ˆu(jω)|2dω
=
∥ˆG∥2
∞∥ˆu∥2
2
=
∥ˆG∥2
∞∥u∥2
2.

22
CHAPTER 2. NORMS FOR SIGNALS AND SYSTEMS
To show that ∥ˆG∥∞is the least upper bound, ﬁrst choose a frequency ωo where | ˆG(jω)| is
maximum, that is,
| ˆG(jωo)| = ∥ˆG∥∞.
Now choose the input u so that
|ˆu(jω)| =
 c,
if |ω −ωo| < ǫ or |ω + ωo| < ǫ
0,
otherwise,
where ǫ is a small positive number and c is chosen so that u has unit 2-norm (i.e., c =
p
π/2ǫ).
Then
∥ˆy∥2
2
≈
1
2π
h
| ˆG(−jωo)|2π + | ˆG(jωo)|2π
i
=
| ˆG(jωo)|2
=
∥ˆG∥2
∞.
Entry (2,1) This is an application of the Cauchy-Schwarz inequality:
|y(t)|
=

Z ∞
−∞
G(t −τ)u(τ)dτ

≤
Z ∞
−∞
G(t −τ)2dτ
1/2 Z ∞
−∞
u(τ)2dτ
1/2
=
∥G∥2∥u∥2
=
∥ˆG∥2∥u∥2.
Hence
∥y∥∞≤∥ˆG∥2∥u∥2.
To show that ∥ˆG∥2 is the least upper bound, apply the input
u(t) = G(−t)/∥G∥2.
Then ∥u∥2 = 1 and |y(0)| = ∥G∥2, so ∥y∥∞≥∥G∥2.
Entry (3,1) If ∥u∥2 ≤1, then the 2-norm of y is ﬁnite [as in entry (1,1)], so pow(y) = 0.
Entry (1,2) Apply a sinusoidal input of unit amplitude and frequency ω such that jω is not a
zero of ˆG. Then ∥u∥∞= 1, but ∥y∥2 = ∞.
Entry (2,2) First, ∥G∥1 is an upper bound on the ∞-norm/∞-norm system gain:
|y(t)|
=

Z ∞
−∞
G(τ)u(t −τ)dτ

≤
Z ∞
−∞
|G(τ)u(t −τ)| dτ
≤
Z ∞
−∞
|G(τ)| dτ∥u∥∞
=
∥G∥1∥u∥∞.

2.5. PROOFS FOR TABLES 2.1 AND 2.2 (OPTIONAL)
23
That ∥G∥1 is the least upper bound can be seen as follows. Fix t and set
u(t −τ) := sgn(G(τ)),
∀τ.
Then ∥u∥∞= 1 and
y(t)
=
Z ∞
−∞
G(τ)u(t −τ)dτ
=
Z ∞
−∞
|G(τ)|dτ
=
∥G∥1.
So ∥y∥∞≥∥G∥1.
Entry (3,2) If u is a power signal and ∥u∥∞≤1, then pow(u) ≤1, so
sup{pow(y) : ∥u∥∞≤1} ≤sup{pow(y) : pow(u) ≤1}.
We will see in entry (3,3) that the latter supremum equals ∥ˆG∥∞.
Entry (1,3) If u is a power signal, then from the preceding section,
Sy(jω) = | ˆG(jω)|2Su(jω),
so
pow(y)2 = 1
2π
Z ∞
−∞
| ˆG(jω)|2Su(jω)dω.
(2.3)
Unless | ˆG(jω)|2Su(jω) equals zero for all ω, pow(y) is positive, in which case its 2-norm is inﬁnite.
Entry (2,3) This case is not so important, so a complete proof is omitted. The main idea is this:
If pow(u) ≤1, then pow(y) is ﬁnite but ∥y∥∞is not necessarily (see u8 in Exercise 2). So for a
proof of this entry, one should construct an input with pow(u) ≤1, but such that ∥y∥∞= ∞.
Entry (3,3) From (2.3) we get immediately that
pow(y) ≤∥ˆG∥∞pow(u).
To achieve equality, suppose that
| ˆG(jωo)| = ∥ˆG∥∞
and let the input be
u(t) =
√
2 sin(ωot).
Then Ru(τ) = cos(ωoτ), so
pow(u) = Ru(0) = 1.

24
CHAPTER 2. NORMS FOR SIGNALS AND SYSTEMS
Also,
Su(jω) = π [δ(ω −ωo) + δ(ω + ωo)] ,
so from (2.3)
pow(y)2
=
1
2| ˆG(jωo)|2 + 1
2| ˆG(−jωo)|2
=
| ˆG(jωo)|2
=
∥ˆG∥2
∞.
2.6
Computing by State-Space Methods (Optional)
This book is on classical control, which is set in the frequency domain. Current widespread practice,
however, is to do computations using state-space methods. The purpose of this optional section is
to illustrate how this is done for the problem of computing the 2-norm and ∞-norm of a transfer
function. The derivation of the procedures is brief.
Consider a state-space model of the form
˙x(t)
=
Ax(t) + Bu(t),
y(t)
=
Cx(t).
Here u(t) is the input signal and y(t) the output signal, both scalar-valued. In contrast, x(t) is a
vector-valued function with, say, n components. The dot in ˙x means take the derivative of each
component. Then A, B, C are real matrices of sizes
n × n,
n × 1,
1 × n.
The equations are assumed to hold for t ≥0. Take Laplace transforms with zero initial conditions
on x:
sˆx(s)
=
Aˆx(s) + Bˆu(s),
ˆy(s)
=
Cˆx(s).
Now eliminate ˆx(s) to get
ˆy(s) = C(sI −A)−1Bˆu(s).
We conclude that the transfer function from ˆu to ˆy is
ˆG(s) = C(sI −A)−1B.
This transfer function is strictly proper. [Try an example: start with some A, B, C with n = 2,
and compute ˆG(s).]
Going the other way, from a strictly proper transfer function to a state-space model, is more
profound, but it is true that for every strictly proper transfer function ˆG(s) there exist (A, B, C)
such that
ˆG(s) = C(sI −A)−1B.

2.6. COMPUTING BY STATE-SPACE METHODS (OPTIONAL)
25
From the representation
ˆG(s) =
1
det(sI −A)C adj(sI −A)B
it should be clear that the poles of ˆG(s) are included in the eigenvalues of A. We say that A is
stable if all its eigenvalues lie in Re s < 0, in which case ˆG is a stable transfer function.
Now start with the representation
ˆG(s) = C(sI −A)−1B
with A stable. We want to compute ∥ˆG∥2 and ∥ˆG∥∞from the data (A, B, C).
The 2-Norm
Deﬁne the matrix exponential
etA := I + tA + t2
2!A2 + · · ·
just as if A were a scalar (convergence can be proved). Let a prime denote transpose and deﬁne the
matrix
L :=
Z ∞
0
etABB′etA′dt
(the integral converges because A is stable). Then L satisﬁes the equation
AL + LA′ + BB′ = 0.
Proof Integrate both sides of the equation
d
dtetABB′etA′ = AetABB′etA′ + etABB′etA′A′
from 0 to ∞, noting that exp(tA) converges to 0 because A is stable, to get
−BB′ = AL + LA′. ■
In terms of L a simple formula for the 2-norm of ˆG is
∥ˆG∥2 = (CLC′)1/2.
Proof The impulse response function is
G(t) = CetAB,
t > 0.

26
CHAPTER 2. NORMS FOR SIGNALS AND SYSTEMS
Calling on Parseval we get
∥ˆG∥2
2
=
∥G∥2
2
=
Z ∞
0
CetABB′etA′C′dt
=
C
Z ∞
0
etABB′etA′dtC′
=
CLC′. ■
So a procedure to compute the 2-norm is as follows:
Step 1 Solve the equation
AL + LA′ + BB′ = 0
for the matrix L.
Step 2
∥ˆG∥2 = (CLC′)1/2
The ∞-Norm
Computing the ∞-norm is harder; we shall have to be content with a search procedure. Deﬁne the
2n × 2n matrix
H :=

A
BB′
−C′C
−A′

.
Theorem 1 ∥ˆG∥∞< 1 iﬀH has no eigenvalues on the imaginary axis.
Proof The proof of this theorem is a bit involved, so only suﬃciency is considered, and it is only
sketched.
It is not too hard to derive that
1/[1 −ˆG(−s) ˆG(s)] = 1 +

0
B′ 
(sI −H)−1
 B
0

.
Thus the poles of [1 −ˆG(−s) ˆG(s)]−1 are contained in the eigenvalues of H.
Assume that H has no eigenvalues on the imaginary axis. Then [1−ˆG(−s) ˆG(s)]−1 has no poles
there, so 1 −ˆG(−s) ˆG(s) has no zeros there, that is,
| ˆG(jω)| ̸= 1,
∀ω.
Since ˆG is strictly proper, this implies that
| ˆG(jω)| < 1,
∀ω
(i.e., ∥ˆG∥∞< 1). ■
The theorem suggests this way to compute an ∞-norm: Select a positive number γ; test if
∥ˆG∥∞< γ (i.e., if ∥γ−1 ˆG∥∞< 1) by calculating the eigenvalues of the appropriate matrix; increase
or decrease γ accordingly; repeat. A bisection search is quite eﬃcient: Get upper and lower bounds
for ∥ˆG∥∞; try γ midway between these bounds; continue.

2.6. COMPUTING BY STATE-SPACE METHODS (OPTIONAL)
27
Exercises
1. Suppose that u(t) is a continuous signal whose derivative ˙u(t) is continuous too. Which of the
following qualiﬁes as a norm for u?
sup
t
| ˙u(t)|
|u(0)| + sup
t
| ˙u(t)|
max{sup
t
|u(t)|, sup
t
| ˙u(t)|}
sup
t
|u(t)| + sup
t
| ˙u(t)|
2. Consider the Venn diagram in Figure 2.1. Show that the functions u1 to u9, deﬁned below,
are located in the diagram as shown in Figure 2.2. All the functions are zero for t < 0.
u1
u7
u3
u9
u4
u5
u6
u2
u8
Figure 2.2: Figure for Exercise 2.
u1(t)
=

1/
√
t,
if t ≤1
0,
if t > 1
u2(t)
=

1/t1/4,
if t ≤1
0,
if t > 1
u3(t)
=
1
u4(t)
=
1/(1 + t)
u5(t)
=
u2(t) + u4(t)
u6(t)
=
0
u7(t)
=
u2(t) + 1
For u8, set
vk(t) =
 k,
if k < t < k + k−3
0,
otherwise

28
CHAPTER 2. NORMS FOR SIGNALS AND SYSTEMS
and then
u8(t) =
∞
X
1
vk(t).
Finally, let u9 equal 1 in the intervals
[22k, 22k+1],
k = 0, 1, 2, . . .
and zero elsewhere.
3. Suppose that ˆG(s) is a real-rational, stable transfer function with ˆG−1 stable, too (i.e., neither
poles nor zeros in Re s ≥0). True or false: The Bode phase plot, ∠ˆG(jω) versus ω, can be
uniquely constructed from the Bode magnitude plot, | ˆG(jω)| versus ω. (Answer: false!)
4. Recall that the transfer function for a pure timedelay of τ time units is
ˆD(s) := e−sτ.
Say that a norm ∥∥on transfer functions is time-delay invariant if for every transfer function
ˆG (such that ∥ˆG∥< ∞) and every τ > 0,
∥ˆD ˆG∥= ∥ˆG∥.
Is the 2-norm or ∞-norm time-delay invariant?
5. Compute the 1-norm of the impulse response corresponding to the transfer function
1
τs + 1,
τ > 0.
6. For ˆG stable and strictly proper, show that ∥G∥1 < ∞and ﬁnd an inequality relating ∥ˆG∥∞
and ∥G∥1.
7. This concerns entry (2,2) in Table 2.2. The given entry assumes that ˆG is stable and strictly
proper. When ˆG is stable but only proper, it can be expressed as
ˆG(s) = c + ˆG1(s)
with c constant and ˆG1 stable and strictly proper. Show that the correct (2,2)-entry is
|c| + ∥G1∥1.
8. Show that entries (2,2) and (3,2) in Table 2.1 and entries (1,1), (3,2), and (3,3) in Table 2.2
hold when ˆG is stable and proper (instead of strictly proper).
9. Let ˆG(s) be a strictly proper stable transfer function and G(t) its inverse Laplace transform.
Let u(t) be a signal of ﬁnite 1-norm. True or false:
∥G ∗u∥1 ≤∥G∥1∥u∥1?

2.6. COMPUTING BY STATE-SPACE METHODS (OPTIONAL)
29
10. Consider a system with transfer function
ω2
n
s2 + 2ζωns + ω2n
,
ζ, ωn > 0,
and input
u(t) = sin 0.1t,
−∞< t < ∞.
Compute pow of the output.
11. Consider a system with transfer function
s + 2
4s + 1
and input u and output y. Compute
sup
∥u∥∞=1
∥y∥∞
and ﬁnd an input achieving this supremum.
12. For a linear system with input u(t) and output y(t), prove that
sup
∥u∥≤1
∥y∥= sup
∥u∥=1
∥y∥
where the norm is, say, the 2-norm.
13. Show that the 2-norm for transfer functions is not submultiplicative.
14. Write a MATLAB program to compute the ∞-norm of a transfer function using the grid
method. Test your program on the function
1
s2 + 10−6s + 1
and compare your answer to the exact solution computed by hand using the derivative method.
Notes and References
The material in this chapter belongs to the ﬁeld of mathematics called functional analysis. Tools
from functional analysis were introduced into the subject of feedback control around 1960 by G.
Zames and I. Sandberg. Some references are Desoer and Vidyasagar (1975), Holtzman (1970), Mees
(1981), and Willems (1971). The state-space procedure for the ∞-norm is from Boyd et al. (1989).

30
CHAPTER 2. NORMS FOR SIGNALS AND SYSTEMS

Chapter 3
Basic Concepts
This chapter and the next are the most fundamental. We concentrate on the single-loop feedback
system. Stability of this system is deﬁned and characterized.
Then the system is analyzed for
its ability to track certain signals (i.e., steps and ramps) asymptotically as time increases.
Fi-
nally, tracking is addressed as a performance speciﬁcation. Uncertainty is postponed until the next
chapter.
Now a word about notation. In the preceding chapter we used signals in the time and frequency
domains; the notation was u(t) for a function of time and ˆu(s) for its Laplace transform. When the
context is solely the frequency domain, it is convenient to drop the hat and write u(s); similarly for
an impulse response G(t) and the corresponding transfer function ˆG(s).
3.1
Basic Feedback Loop
The most elementary feedback control system has three components: a plant (the object to be
controlled, no matter what it is, is always called the plant), a sensor to measure the output of the
plant, and a controller to generate the plant’s input. Usually, actuators are lumped in with the
plant. We begin with the block diagram in Figure 3.1. Notice that each of the three components
controller
sensor
plant
-
-
-
?

6
6
r
u
y
d
n
v
Figure 3.1: Elementary control system.
has two inputs, one internal to the system and one coming from outside, and one output. These
31

32
CHAPTER 3. BASIC CONCEPTS
signals have the following interpretations:
r
reference or command input
v
sensor output
u
actuating signal, plant input
d
external disturbance
y
plant output and measured signal
n
sensor noise
The three signals coming from outside—r, d, and n—are called exogenous inputs.
In what follows we shall consider a variety of performance objectives, but they can be summarized
by saying that y should approximate some prespeciﬁed function of r, and it should do so in the
presence of the disturbance d, sensor noise n, with uncertainty in the plant. We may also want to
limit the size of u. Frequently, it makes more sense to describe the performance objective in terms
of the measurement v rather than y, since often the only knowledge of y is obtained from v.
The analysis to follow is done in the frequency domain. To simplify notation, hats are omitted
from Laplace transforms.
Each of the three components in Figure 3.1 is assumed to be linear, so its output is a linear
function of its input, in this case a two-dimensional vector. For example, the plant equation has
the form
y = P
 d
u

.
Partitioning the 1 × 2 transfer matrix P as
P =

P1
P2

,
we get
y = P1d + P2u.
We shall take an even more specialized viewpoint and suppose that the outputs of the three
components are linear functions of the sums (or diﬀerence) of their inputs; that is, the plant, sensor,
and controller equations are taken to be of the form
y
=
P(d + u),
v
=
F(y + n),
u
=
C(r −v).
The minus sign in the last equation is a matter of tradition. The block diagram for these equations
is in Figure 3.2. Our convention is that plus signs at summing junctions are omitted.
This section ends with the notion of well-posedness. This means that in Figure 3.2 all closed-
loop transfer functions exist, that is, all transfer functions from the three exogenous inputs to all
internal signals, namely, u, y, v, and the outputs of the summing junctions. Label the outputs of
the summing junctions as in Figure 3.3. For well-posedness it suﬃces to look at the nine transfer
functions from r, d, n to x1, x2, x3. (The other transfer functions are obtainable from these.) Write
the equations at the summing junctions:
x1
=
r −Fx3,
x2
=
d + Cx1,
x3
=
n + Px2.

3.1. BASIC FEEDBACK LOOP
33
C
P
F






-
-
-
-
-


?
?
6
r
u
y
d
n
v
−
Figure 3.2: Basic feedback loop.
C
P
F






-
-
-
-
-


?
?
6
r
u
y
d
n
v
−
x1
x2
x3
Figure 3.3: Basic feedback loop.
In matrix form these are


1
0
F
−C
1
0
0
−P
1




x1
x2
x3

=


r
d
n

.
Thus, the system is well-posed iﬀthe above 3 × 3 matrix is nonsingular, that is, the determinant
1 + PCF is not identically equal to zero. [For instance, the system with P(s) = 1, C(s) = 1,
F(s) = −1 is not well-posed.] Then the nine transfer functions are obtained from the equation


x1
x2
x3

=


1
0
F
−C
1
0
0
−P
1


−1 

r
d
n

,
that is,


x1
x2
x3

=
1
1 + PCF


1
−PF
−F
C
1
−CF
PC
P
1




r
d
n

.
(3.1)
A stronger notion of well-posedness that makes sense when P, C, and F are proper is that
the nine transfer functions above are proper. A necessary and suﬃcient condition for this is that
1 + PCF not be strictly proper [i.e., PCF(∞) ̸= −1].

34
CHAPTER 3. BASIC CONCEPTS
One might argue that the transfer functions of all physical systems are strictly proper: If a
sinusoid of ever-increasing frequency is applied to a (linear, time-invariant) system, the amplitude
of the output will go to zero. This is somewhat misleading because a real system will cease to
behave linearly as the frequency of the input increases. Furthermore, our transfer functions will be
used to parametrize an uncertainty set, and as we shall see, it may be convenient to allow some of
them to be only proper. A proportional-integral-derivative controller is very common in practice,
especially in chemical engineering. It has the form
k1 + k2
s + k3s.
This is not proper, but it can be approximated over any desired frequency range by a proper one,
for example,
k1 + k2
s +
k3s
τs + 1.
Notice that the feedback system is automatically well-posed, in the stronger sense, if P, C, and
F are proper and one is strictly proper. For most of the book, we shall make the following standing
assumption, under which the nine transfer functions in (3.1) are proper:
P is strictly proper, C and F are proper.
However, at times it will be convenient to require only that P be proper. In this case we shall always
assume that |PCF| < 1 at ω = ∞, which ensures that 1 + PCF is not strictly proper. Given that
no model, no matter how complex, can approximate a real system at suﬃciently high frequencies,
we should be very uncomfortable if |PCF| > 1 at ω = ∞, because such a controller would almost
surely be unstable if implemented on a real system.
3.2
Internal Stability
Consider a system with input u, output y, and transfer function ˆG, assumed stable and proper. We
can write
ˆG = G0 + ˆG1,
where G0 is a constant and ˆG1 is strictly proper.
Example:
s
s + 1 = 1 −
1
s + 1.
In the time domain the equation is
y(t) = G0u(t) +
Z ∞
−∞
G1(t −τ)u(τ) dτ.
If |u(t)| ≤c for all t, then
|y(t)| ≤|G0|c +
Z ∞
−∞
|G1(τ)| dτc.

3.2. INTERNAL STABILITY
35
The right-hand side is ﬁnite. Thus the output is bounded whenever the input is bounded. [This
argument is the basis for entry (2,2) in Table 2.2.]
If the nine transfer functions in (3.1) are stable, then the feedback system is said to be internally
stable. As a consequence, if the exogenous inputs are bounded in magnitude, so too are x1, x2, and
x3, and hence u, y, and v. So internal stability guarantees bounded internal signals for all bounded
exogenous signals.
The idea behind this deﬁnition of internal stability is that it is not enough to look only at
input-output transfer functions, such as from r to y, for example. This transfer function could be
stable, so that y is bounded when r is, and yet an internal signal could be unbounded, probably
causing internal damage to the physical system.
For the remainder of this section hats are dropped.
Example In Figure 3.3 take
C(s) = s −1
s + 1,
P(s) =
1
s2 −1,
F(s) = 1.
Check that the transfer function from r to y is stable, but that from d to y is not. The feedback
system is therefore not internally stable. As we will see later, this oﬀense is caused by the cancellation
of the controller zero and the plant pole at the point s = 1.
We shall develop a test for internal stability which is easier than examining nine transfer func-
tions. Write P, C, and F as ratios of coprime polynomials (i.e., polynomials with no common
factors):
P = NP
MP
,
C = NC
MC
,
F = NF
MF
.
The characteristic polynomial of the feedback system is the one formed by taking the product of
the three numerators plus the product of the three denominators:
NP NCNF + MPMCMF .
The closed-loop poles are the zeros of the characteristic polynomial.
Theorem 1 The feedback system is internally stable iﬀthere are no closed-loop poles in Res ≥0.
Proof For simplicity assume that F = 1; the proof in the general case is similar, but a bit messier.
From (3.1) we have


x1
x2
x3

=
1
1 + PC


1
−P
−1
C
1
−C
PC
P
1




r
d
n

.
Substitute in the ratios and clear fractions to get


x1
x2
x3

=
1
NPNC + MPMC


MP MC
−NP MC
−MP MC
MPNC
MP MC
−MPNC
NP NC
NPMC
MP MC




r
d
n

.
(3.2)

36
CHAPTER 3. BASIC CONCEPTS
Note that the characteristic polynomial equals NP NC + MP MC. Suﬃciency is now evident; the
feedback system is internally stable if the characteristic polynomial has no zeros in Res ≥0.
Necessity involves a subtle point. Suppose that the feedback system is internally stable. Then
all nine transfer functions in (3.2) are stable, that is, they have no poles in Re s ≥0. But we cannot
immediately conclude that the polynomial NP NC + MP MC has no zeros in Res ≥0 because this
polynomial may conceivably have a right half-plane zero which is also a zero of all nine numerators
in (3.2), and hence is canceled to form nine stable transfer functions. However, the characteristic
polynomial has no zero which is also a zero of all nine numerators, MP MC, NP MC, and so on.
Proof of this statement is left as an exercise. (It follows from the fact that we took coprime factors
to start with, that is, NP and MP are coprime, as are the other numerator-denominator pairs.) ■
By Theorem 1 internal stability can be determined simply by checking the zeros of a polynomial.
There is another test that provides additional insight.
Theorem 2 The feedback system is internally stable iﬀthe following two conditions hold:
(a) The transfer function 1 + PCF has no zeros in Res ≥0.
(b) There is no pole-zero cancellation in Res ≥0 when the product PCF is formed.
Proof Recall that the feedback system is internally stable iﬀall nine transfer functions
1
1 + PCF


1
−PF
−F
C
1
−CF
PC
P
1


are stable.
(⇒) Assume that the feedback system is internally stable. Then in particular (1 + PCF)−1 is
stable (i.e., it has no poles in Res ≥0). Hence 1 + PCF has no zeros there. This proves (a).
To prove (b), write P, C, F as ratios of coprime polynomials:
P = NP
MP
,
C = NC
MC
,
F = NF
MF
.
By Theorem 1 the characteristic polynomial
NP NCNF + MPMCMF
has no zeros in Res ≥0. Thus the pair (NP , MC) have no common zero in Res ≥0, and similarly
for the other numerator-denominator pairs.
(⇐) Assume (a) and (b). Factor P, C, F as above, and let s0 be a zero of the characteristic
polynomial, that is,
(NP NCNF + MP MCMF )(s0) = 0.
We must show that Res0 < 0; this will prove internal stability by Theorem 1. Suppose to the
contrary that Res0 ≥0. If
(MP MCMF )(s0) = 0,

3.3. ASYMPTOTIC TRACKING
37
then
(NP NCNF )(s0) = 0.
But this violates (b). Thus
(MP MCMF )(s0) ̸= 0,
so we can divide by it above to get
1 + NP NCNF
MP MCMF
(s0) = 0,
that is,
1 + (PCF)(s0) = 0,
which violates (a). ■
Finally, let us recall for later use the Nyquist stability criterion. It can be derived from Theorem 2
and the principle of the argument. Begin with the curve D in the complex plane: It starts at the
origin, goes up the imaginary axis, turns into the right half-plane following a semicircle of inﬁnite
radius, and comes up the negative imaginary axis to the origin again:
D
As a point s makes one circuit around this curve, the point P(s)C(s)F(s) traces out a curve called
the Nyquist plot of PCF. If PCF has a pole on the imaginary axis, then D must have a small
indentation to avoid it.
Nyquist Criterion Construct the Nyquist plot of PCF, indenting to the left around poles on the
imaginary axis. Let n denote the total number of poles of P, C, and F in Res ≥0. Then the feedback
system is internally stable iﬀthe Nyquist plot does not pass through the point -1 and encircles it
exactly n times counterclockwise.

38
CHAPTER 3. BASIC CONCEPTS
ˆC
ˆP






-
-
-
-
-

?
?
6
r
u
y
d
n
−
e
Figure 3.4: Unity-feedback loop.
3.3
Asymptotic Tracking
In this section we look at a typical performance speciﬁcation, perfect asymptotic tracking of a
reference signal.
Both time domain and frequency domain occur, so the notation distinction is
required.
For the remainder of this chapter we specialize to the unity-feedback case, ˆF = 1, so the block
diagram is as in Figure 3.4. Here e is the tracking error; with n = d = 0, e equals the reference
input (ideal response), r, minus the plant output (actual response), y.
We wish to study this system’s capability of tracking certain test inputs asymptotically as time
tends to inﬁnity. The two test inputs are the step
r(t) =
 c,
if t ≥0
0,
if t < 0
and the ramp
r(t) =
 ct,
if t ≥0
0,
if t < 0
(c is a nonzero real number). As an application of the former think of the temperature-control
thermostat in a room; when you change the setting on the thermostat (step input), you would like
the room temperature eventually to change to the new setting (of course, you would like the change
to occur within a reasonable time). A situation with a ramp input is a radar dish designed to track
orbiting satellites. A satellite moving in a circular orbit at constant angular velocity sweeps out an
angle that is approximately a linear function of time (i.e., a ramp).
Deﬁne the loop transfer function ˆL := ˆP ˆC. The transfer function from reference input r to
tracking error e is
ˆS :=
1
1 + ˆL
,
called the sensitivity function—more on this in the next section. The ability of the system to track
steps and ramps asymptotically depends on the number of zeros of ˆS at s = 0.
Theorem 3 Assume that the feedback system is internally stable and n = d = 0.

3.3. ASYMPTOTIC TRACKING
39
(a) If r is a step, then e(t) −→0 as t −→∞iﬀˆS has at least one zero at the origin.
(b) If r is a ramp, then e(t) −→0 as t −→∞iﬀˆS has at least two zeros at the origin.
The proof is an application of the ﬁnal-value theorem: If ˆy(s) is a rational Laplace transform
that has no poles in Res ≥0 except possibly a simple pole at s = 0, then limt→∞y(t) exists and it
equals lims→0 sˆy(s).
Proof (a) The Laplace transform of the foregoing step is ˆr(s) = c/s. The transfer function from r
to e equals ˆS, so
ˆe(s) = ˆS(s)c
s.
Since the feedback system is internally stable, ˆS is a stable transfer function. It follows from the
ﬁnal-value theorem that e(t) does indeed converge as t −→∞, and its limit is the residue of the
function ˆe(s) at the pole s = 0:
e(∞) = ˆS(0)c.
The right-hand side equals zero iﬀˆS(0) = 0.
(b) Similarly with ˆr(s) = c/s2. ■
Note that ˆS has a zero at s = 0 iﬀˆL has a pole there. Thus, from the theorem we see that if
the feedback system is internally stable and either ˆP or ˆC has a pole at the origin (i.e., an inherent
integrator), then the output y(t) will asymptotically track any step input r.
Example To see how this works, take the simplest possible example,
ˆP(s) = 1
s,
ˆC(s) = 1.
Then the transfer function from r to e equals
1
1 + s−1 =
s
s + 1.
So the open-loop pole at s = 0 becomes a closed-loop zero of the error transfer function; then this
zero cancels the pole of ˆr(s), resulting in no unstable poles in ˆe(s). Similar remarks apply for a
ramp input.
Theorem 3 is a special case of an elementary principle: For perfect asymptotic tracking, the
loop transfer function ˆL must contain an internal model of the unstable poles of ˆr.
A similar analysis can be done for the situation where r = n = 0 and d is a sinusoid, say
d(t) = sin(ωt)1(t) (1 is the unit step). You can show this: If the feedback system is internally
stable, then y(t) −→0 as t −→∞iﬀeither ˆP has a zero at s = jω or ˆC has a pole at s = jω
(Exercise 3).

40
CHAPTER 3. BASIC CONCEPTS
3.4
Performance
In this section we again look at tracking a reference signal, but whereas in the preceding section
we considered perfect asymptotic tracking of a single signal, we will now consider a set of reference
signals and a bound on the steady-state error. This performance objective will be quantiﬁed in
terms of a weighted norm bound.
As before, let L denote the loop transfer function, L := PC. The transfer function from reference
input r to tracking error e is
S :=
1
1 + L,
called the sensitivity function. In the analysis to follow, it will always be assumed that the feedback
system is internally stable, so S is a stable, proper transfer function. Observe that since L is strictly
proper (since P is), S(j∞) = 1.
The name sensitivity function comes from the following idea. Let T denote the transfer function
from r to y:
T =
PC
1 + PC .
One way to quantify how sensitive T is to variations in P is to take the limiting ratio of a relative
perturbation in T (i.e., ∆T/T) to a relative perturbation in P (i.e., ∆P/P). Thinking of P as a
variable and T as a function of it, we get
lim
∆P →0
∆T/T
∆P/P = dT
dP
P
T .
The right-hand side is easily evaluated to be S. In this way, S is the sensitivity of the closed-loop
transfer function T to an inﬁnitesimal perturbation in P.
Now we have to decide on a performance speciﬁcation, a measure of goodness of tracking. This
decision depends on two things: what we know about r and what measure we choose to assign to
the tracking error. Usually, r is not known in advance—few control systems are designed for one
and only one input. Rather, a set of possible rs will be known or at least postulated for the purpose
of design.
Let’s ﬁrst consider sinusoidal inputs. Suppose that r can be any sinusoid of amplitude ≤1 and
we want e to have amplitude < ǫ. Then the performance speciﬁcation can be expressed succinctly
as
∥S∥∞< ǫ.
Here we used Table 2.1: the maximum amplitude of e equals the ∞-norm of the transfer function.
Or if we deﬁne the (trivial, in this case) weighting function W1(s) = 1/ǫ, then the performance
speciﬁcation is ∥W1S∥∞< 1.
The situation becomes more realistic and more interesting with a frequency-dependent weighting
function. Assume that W1(s) is real-rational; you will see below that only the magnitude of W1(jω)
is relevant, so any poles or zeros in Res > 0 can be reﬂected into the left half-plane without changing
the magnitude. Let us consider four scenarios giving rise to an ∞-norm bound on W1S. The ﬁrst
three require W1 to be stable.

3.4. PERFORMANCE
41
1. Suppose that the family of reference inputs is all signals of the form r = W1rpf, where rpf, a
pre-ﬁltered input, is any sinusoid of amplitude ≤1. Thus the set of rs consists of sinusoids
with frequency-dependent amplitudes. Then the maximum amplitude of e equals ∥W1S∥∞.
2. Recall from Chapter 2 that
∥r∥2
2 = 1
2π
Z ∞
−∞
|r(jω)|2 dω
and that ∥r∥2
2 is a measure of the energy of r. Thus we may think of |r(jω)|2 as energy spectral
density, or energy spectrum. Suppose that the set of all rs is
{r : r = W1rpf, ∥rpf∥2 ≤1},
that is,

r : 1
2π
Z ∞
−∞
|r(jω)/W1(jω)|2 dω ≤1

.
Thus, r has an energy constraint and its energy spectrum is weighted by 1/|W1(jω)|2. For
example, if W1 were a bandpass ﬁlter, the energy spectrum of r would be conﬁned to the
passband. More generally, W1 could be used to shape the energy spectrum of the expected
class of reference inputs. Now suppose that the tracking error measure is the 2-norm of e.
Then from Table 2.2,
sup
r ∥e∥2 = sup{∥SW1rpf∥2 : ∥rpf∥2 ≤1} = ∥W1S∥∞,
so ∥W1S∥∞< 1 means that ∥e∥2 < 1 for all rs in the set above .
3. This scenario is like the preceding one except for signals of ﬁnite power. We see from Table 2.2
that ∥W1S∥∞equals the supremum of pow(e) over all rpf with pow(rpf) ≤1. So W1 could
be used to shape the power spectrum of the expected class of rs.
4. In several applications, for example aircraft ﬂight-control design, designers have acquired
through experience desired shapes for the Bode magnitude plot of S. In particular, suppose
that good performance is known to be achieved if the plot of |S(jω)| lies under some curve.
We could rewrite this as
|S(jω)| < |W1(jω)|−1,
∀ω,
or in other words, ∥W1S∥∞< 1.
There is a nice graphical interpretation of the norm bound ∥W1S∥∞< 1. Note that
∥W1S∥∞< 1
⇔

W1(jω)
1 + L(jω)
 < 1,
∀ω
⇔
|W1(jω)| < |1 + L(jω)|,
∀ω.
The last inequality says that at every frequency, the point L(jω) on the Nyquist plot lies outside
the disk of center -1, radius |W1(jω)| (Figure 3.5).

42
CHAPTER 3. BASIC CONCEPTS
&%
'$
r
r
6
|W1|
−1
L
Figure 3.5: Performance speciﬁcation graphically.
Other performance problems could be posed by focusing on the response to the other two
exogenous inputs, d and n. Note that the transfer functions from d, n to e, u are given by
 e
u

= −
 PS
S
T
CS
  d
n

,
where
T := 1 −S =
PC
1 + PC ,
called the complementary sensitivity function.
Various performance speciﬁcations could be made using weighted versions of the transfer func-
tions above. Note that a performance spec with weight W on PS is equivalent to the weight WP on
S. Similarly, a weight W on CS = T/P is equivalent to the weight W/P on T. Thus performance
specs that involve e result in weights on S and performance specs on u result in weights on T.
Essentially all problems in this book boil down to weighting S or T or some combination, and the
tradeoﬀbetween making S small and making T small is the main issue in design.
Exercises
1. Consider the unity-feedback system [F(s) = 1]. The deﬁnition of internal stability is that all
nine closed-loop transfer functions should be stable. In the unity-feedback case, it actually
suﬃces to check only two of the nine. Which two?
2. In this problem and the next, there is a mixture of the time and frequency domains, so theˆ
-convention is in force.
Let
ˆP(s) =
1
10s + 1,
ˆC(s) = k,
ˆF(s) = 1.
Find the least positive gain k so that the following are all true:
(a) The feedback system is internally stable.
(b) |e(∞)| ≤0.1 when r(t) is the unit step and n = d = 0.

3.4. PERFORMANCE
43
(c) ∥y∥∞≤0.1 for all d(t) such that ∥d∥2 ≤1 when r = n = 0.
3. For the setup in Figure 3.4, take r = n = 0, d(t) = sin(ωt)1(t). Prove that if the feedback
system is internally stable, then y(t) →0 as t →∞iﬀeither ˆP has a zero at s = jω or ˆC has
a pole at s = jω.
4. Consider the feedback system with plant P and sensor F. Assume that P is strictly proper
and F is proper. Find conditions on P and F for the existence of a proper controller so that
The feedback system is internally stable.
y(t) −r(t) →0 when r is a unit step.
y(t) →0 when d is a sinusoid of frequency 100 rad/s.
Notes and References
The material in Sections 3.1 to 3.3 is quite standard. However, Section 3.4 reﬂects the more recent
viewpoint of Zames (1981), who formulated the problem of optimizing W1S with respect to the
∞-norm, stressing the role of the weight W1. Additional motivation for this problem is oﬀered in
Zames and Francis (1983).

44
CHAPTER 3. BASIC CONCEPTS

Chapter 4
Uncertainty and Robustness
No mathematical system can exactly model a physical system. For this reason we must be aware
of how modeling errors might adversely aﬀect the performance of a control system. This chapter
begins with a treatment of various models of plant uncertainty. Then robust stability, stability in
the face of plant uncertainty, is studied using the small-gain theorem. The ﬁnal topic is robust
performance, guaranteed tracking in the face of plant uncertainty.
4.1
Plant Uncertainty
The basic technique is to model the plant as belonging to a set P. The reasons for doing this were
presented in Chapter 1. Such a set can be either structured or unstructured.
For an example of a structured set consider the plant model
1
s2 + as + 1.
This is a standard second-order transfer function with natural frequency 1 rad/s and damping ratio
a/2—it could represent, for example, a mass-spring-damper setup or an R-L-C circuit. Suppose
that the constant a is known only to the extent that it lies in some interval [amin, amax]. Then the
plant belongs to the structured set
P =

1
s2 + as + 1 : amin ≤a ≤amax

.
Thus one type of structured set is parametrized by a ﬁnite number of scalar parameters (one
parameter, a, in this example). Another type of structured uncertainty is a discrete set of plants,
not necessarily parametrized explicitly.
For us, unstructured sets are more important, for two reasons. First, we believe that all models
used in feedback design should include some unstructured uncertainty to cover unmodeled dynamics,
particularly at high frequency.
Other types of uncertainty, though important, may or may not
arise naturally in a given problem. Second, for a speciﬁc type of unstructured uncertainty, disk
uncertainty, we can develop simple, general analysis methods. Thus the basic starting point for an
unstructured set is that of disk-like uncertainty. In what follows, multiplicative disk uncertainty
is chosen for detailed study. This is only one type of unstructured perturbation. The important
point is that we use disk uncertainty instead of a more complicated description. We do this because
45

46
CHAPTER 4. UNCERTAINTY AND ROBUSTNESS
it greatly simpliﬁes our analysis and lets us say some fairly precise things. The price we pay is
conservativeness.
Multiplicative Perturbation
Suppose that the nominal plant transfer function is P and consider perturbed plant transfer func-
tions of the form ˜P = (1 + ∆W2)P. Here W2 is a ﬁxed stable transfer function, the weight, and
∆is a variable stable transfer function satisfying ∥∆∥∞< 1. Furthermore, it is assumed that no
unstable poles of P are canceled in forming ˜P. (Thus, P and ˜P have the same unstable poles.)
Such a perturbation ∆is said to be allowable.
The idea behind this uncertainty model is that ∆W2 is the normalized plant perturbation away
from 1:
˜P
P −1 = ∆W2.
Hence if ∥∆∥∞≤1, then

˜P(jω)
P(jω) −1
 ≤|W2(jω)|,
∀ω,
so |W2(jω)| provides the uncertainty proﬁle. This inequality describes a disk in the complex plane:
At each frequency the point ˜P/P lies in the disk with center 1, radius |W2|. Typically, |W2(jω)|
is a (roughly) increasing function of ω: Uncertainty increases with increasing frequency. The main
purpose of ∆is to account for phase uncertainty and to act as a scaling factor on the magnitude of
the perturbation (i.e., |∆| varies between 0 and 1).
Thus, this uncertainty model is characterized by a nominal plant P together with a weighting
function W2. How does one get the weighting function W2 in practice? This is illustrated by a few
examples.
Example 1 Suppose that the plant is stable and its transfer function is arrived at by means of
frequency-response experiments: Magnitude and phase are measured at a number of frequencies,
ωi, i = 1, . . . , m, and this experiment is repeated several, say n, times. Let the magnitude-phase
measurement for frequency ωi and experiment k be denoted (Mik, φik). Based on these data select
nominal magnitude-phase pairs (Mi, φi) for each frequency ωi, and ﬁt a nominal transfer function
P(s) to these data. Then ﬁt a weighting function W2(s) so that

Mikejφik
Miejφi
−1
 ≤|W2(jωi)|,
i = 1, . . . , m; k = 1, . . . , n.
Example 2 Assume that the nominal plant transfer function is a double integrator:
P(s) = 1
s2 .
For example, a dc motor with negligible viscous damping could have such a transfer function. You
can think of other physical systems with only inertia, no damping. Suppose that a more detailed
model has a time delay, yielding the transfer function
˜P(s) = e−τs 1
s2 ,

4.1. PLANT UNCERTAINTY
47
and suppose that the time delay is known only to the extent that it lies in the interval 0 ≤τ ≤0.1.
This time-delay factor exp(−τs) can be treated as a multiplicative perturbation of the nominal
plant by embedding ˜P in the family
{(1 + ∆W2)P : ∥∆∥∞≤1}.
To do this, the weight W2 should be chosen so that the normalized perturbation satisﬁes

˜P(jω)
P(jω) −1
 ≤|W2(jω)|,
∀ω, τ,
that is,
e−τjω −1
 ≤|W2(jω)|,
∀ω, τ.
A little time with Bode magnitude plots shows that a suitable ﬁrst-order weight is
W2(s) =
0.21s
0.1s + 1.
Figure 4.1 is the Bode magnitude plot of this W2 and exp(−τs) −1 for τ = 0.1, the worst value.
10-3
10-2
10-1
100
101
10-1
100
101
102
103
Figure 4.1: Bode plots of W2 (dash) and exp(−0.1s) −1 (solid).
To get a feeling for how conservative this is, compare at a few frequencies ω the actual uncertainty
set
( ˜P(jω)
P(jω) : 0 ≤τ ≤0.1
)
=

e−τjω : 0 ≤τ ≤0.1
	

48
CHAPTER 4. UNCERTAINTY AND ROBUSTNESS
with the covering disk
{s : |s −1| ≤|W2(jω)|}.
Example 3 Suppose that the plant transfer function is
˜P(s) =
k
s −2,
where the gain k is uncertain but is known to lie in the interval [0.1, 10]. This plant too can be
embedded in a family consisting of multiplicative perturbations of a nominal plant
P(s) =
k0
s −2.
The weight W2 must satisfy

˜P(jω)
P(jω) −1
 ≤|W2(jω)|,
∀ω, k,
that is,
max
0.1≤k≤10

k
k0
−1
 ≤|W2(jω)|,
∀ω.
The left-hand side is minimized by k0 = 5.05, for which the left-hand side equals 4.95/5.05. In this
way we get the nominal plant
P(s) = 5.05
s −2
and constant weight W2(s) = 4.95/5.05.
The multiplicative perturbation model is not suitable for every application because the disk
covering the uncertainty set is sometimes too coarse an approximation. In this case a controller
designed for the multiplicative uncertainty model would probably be too conservative for the original
uncertainty model.
The discussion above illustrates an important point. In modeling a plant we may arrive at a
certain plant set. This set may be too awkward to cope with mathematically, so we may embed it in
a larger set that is easier to handle. Conceivably, the achievable performance for the larger set may
not be as good as the achievable performance for the smaller; that is, there may exist—even though
we cannot ﬁnd it—a controller that is better for the smaller set than the controller we design for
the larger set. In this sense the latter controller is conservative for the smaller set.
In this book we stick with plant uncertainty that is disk-like. It will be conservative for some
problems, but the payoﬀis that we obtain some very nice theoretical results. The resulting theory
is remarkably practical as well.

4.1. PLANT UNCERTAINTY
49
Other Perturbations
Other uncertainty models are possible besides multiplicative perturbations, as illustrated by the
following example.
Example 4 As at the start of this section, consider the family of plant transfer functions
1
s2 + as + 1,
0.4 ≤a ≤0.8.
Thus
a = 0.6 + 0.2∆,
−1 ≤∆≤1,
so the family can be expressed as
P(s)
1 + ∆W2(s)P(s),
−1 ≤∆≤1,
where
P(s) :=
1
s2 + 0.6s + 1,
W2(s) := 0.2s.
Note that P is the nominal plant transfer function for the value a = 0.6, the midpoint of the interval.
The block diagram corresponding to this representation of the plant is shown in Figure 4.2. Thus
P
∆
W2


-
-
-


?
−
Figure 4.2: Example 4.
the original plant has been represented as a feedback uncertainty around a nominal plant.
The following list summarizes the common uncertainty models:
(1 + ∆W2)P
P + ∆W2
P/(1 + ∆W2P)
P/(1 + ∆W2)
Appropriate assumptions would be made on ∆and W2 in each case. Typically, we can relax the
assumption that ∆be stable; but then the theorems to follow would be harder to prove.

50
CHAPTER 4. UNCERTAINTY AND ROBUSTNESS
4.2
Robust Stability
The notion of robustness can be described as follows. Suppose that the plant transfer function P
belongs to a set P, as in the preceding section. Consider some characteristic of the feedback system,
for example, that it is internally stable. A controller C is robust with respect to this characteristic
if this characteristic holds for every plant in P.
The notion of robustness therefore requires a
controller, a set of plants, and some characteristic of the system. For us, the two most important
variations of this notion are robust stability, treated in this section, and robust performance, treated
in the next.
A controller C provides robust stability if it provides internal stability for every plant in P. We
might like to have a test for robust stability, a test involving C and P. Or if P has an associated
size, the maximum size such that C stabilizes all of P might be a useful notion of stability margin.
The Nyquist plot gives information about stability margin. Note that the distance from the
critical point -1 to the nearest point on the Nyquist plot of L equals 1/∥S∥∞:
distance from -1 to Nyquist plot
=
inf
ω | −1 −L(jω)|
=
inf
ω |1 + L(jω)|
=

sup
ω
1
|1 + L(jω)|
−1
=
∥S∥−1
∞.
Thus if ∥S∥∞≫1, the Nyquist plot comes close to the critical point, and the feedback system is
nearly unstable. However, as a measure of stability margin this distance is not entirely adequate
because it contains no frequency information. More precisely, if the nominal plant P is perturbed
to ˜P, having the same number of unstable poles as has P and satisfying the inequality
| ˜P(jω)C(jω) −P(jω)C(jω)| < ∥S∥−1
∞,
∀ω,
then internal stability is preserved (the number of encirclements of the critical point by the Nyquist
plot does not change). But this is usually very conservative; for instance, larger perturbations could
be allowed at frequencies where P(jω)C(jω) is far from the critical point.
Better stability margins are obtained by taking explicit frequency-dependent perturbation mod-
els: for example, the multiplicative perturbation model, ˜P = (1 + ∆W2)P. Fix a positive number
β and consider the family of plants
{ ˜P : ∆is stable and ∥∆∥∞≤β}.
Now a controller C that achieves internal stability for the nominal plant P will stabilize this entire
family if β is small enough. Denote by βsup the least upper bound on β such that C achieves internal
stability for the entire family. Then βsup is a stability margin (with respect to this uncertainty
model). Analogous stability margins could be deﬁned for the other uncertainty models.
We turn now to two classical measures of stability margin, gain and phase margin. Assume
that the feedback system is internally stable with plant P and controller C. Now perturb the plant
to kP, with k a positive real number. The upper gain margin, denoted kmax, is the ﬁrst value of
k greater than 1 when the feedback system is not internally stable; that is, kmax is the maximum
number such that internal stability holds for 1 ≤k < kmax. If there is no such number, then set

4.2. ROBUST STABILITY
51
kmax := ∞.
Similarly, the lower gain margin, kmin, is the least nonnegative number such that
internal stability holds for kmin < k ≤1. These two numbers can be read oﬀthe Nyquist plot of L;
for example, −1/kmax is the point where the Nyquist plot intersects the segment (−1, 0) of the real
axis, the closest point to −1 if there are several points of intersection.
Now perturb the plant to e−jφP, with φ a positive real number. The phase margin, φmax, is the
maximum number (usually expressed in degrees) such that internal stability holds for 0 ≤φ < φmax.
You can see that φmax is the angle through which the Nyquist plot must be rotated until it passes
through the critical point, −1; or, in radians, φmax equals the arc length along the unit circle from
the Nyquist plot to the critical point.
Thus gain and phase margins measure the distance from the critical point to the Nyquist plot
in certain speciﬁc directions. Gain and phase margins have traditionally been important measures
of stability robustness: if either is small, the system is close to instability. Notice, however, that the
gain and phase margins can be relatively large and yet the Nyquist plot of L can pass close to the
critical point; that is, simultaneous small changes in gain and phase could cause internal instability.
We return to these margins in Chapter 11.
Now we look at a typical robust stability test, one for the multiplicative perturbation model.
Assume that the nominal feedback system (i.e., with ∆= 0) is internally stable for controller C.
Bring in again the complementary sensitivity function
T = 1 −S =
L
1 + L =
PC
1 + PC .
Theorem 1 (Multiplicative uncertainty model) C provides robust stability iﬀ∥W2T∥∞< 1.
Proof (⇐) Assume that ∥W2T∥∞< 1. Construct the Nyquist plot of L, indenting D to the left
around poles on the imaginary axis. Since the nominal feedback system is internally stable, we know
this from the Nyquist criterion: The Nyquist plot of L does not pass through -1 and its number
of counterclockwise encirclements equals the number of poles of P in Res ≥0 plus the number of
poles of C in Res ≥0.
Fix an allowable ∆. Construct the Nyquist plot of ˜PC = (1+∆W2)L. No additional indentations
are required since ∆W2 introduces no additional imaginary axis poles.
We have to show that
the Nyquist plot of (1 + ∆W2)L does not pass through -1 and its number of counterclockwise
encirclements equals the number of poles of (1 + ∆W2)P in Re s ≥0 plus the number of poles of C
in Re s ≥0; equivalently, the Nyquist plot of (1 + ∆W2)L does not pass through -1 and encircles
it exactly as many times as does the Nyquist plot of L. We must show, in other words, that the
perturbation does not change the number of encirclements.
The key equation is
1 + (1 + ∆W2)L = (1 + L)(1 + ∆W2T).
(4.1)
Since
∥∆W2T∥∞≤∥W2T∥∞< 1,
the point 1 + ∆W2T always lies in some closed disk with center 1, radius < 1, for all points s on D.
Thus from (4.1), as s goes once around D, the net change in the angle of 1 + (1 + ∆W2)L equals
the net change in the angle of 1 + L. This gives the desired result.

52
CHAPTER 4. UNCERTAINTY AND ROBUSTNESS
(⇒) Suppose that ∥W2T∥∞≥1. We will construct an allowable ∆that destabilizes the feedback
system. Since T is strictly proper, at some frequency ω,
|W2(jω)T(jω)| = 1.
(4.2)
Suppose that ω = 0. Then W2(0)T(0) is a real number, either +1 or −1. If ∆= −W2(0)T(0), then
∆is allowable and
1 + ∆W2(0)T(0) = 0.
From (4.1) the Nyquist plot of (1 + ∆W2)L passes through the critical point, so the perturbed
feedback system is not internally stable.
If ω > 0, constructing an admissible ∆takes a little more work; the details are omitted. ■
The theorem can be used eﬀectively to ﬁnd the stability margin βsup deﬁned previously. The
simple scaling technique
{ ˜P = (1 + ∆W2)P : ∥∆∥∞≤β}
=
{ ˜P = (1 + β−1∆βW2)P : ∥β−1∆∥∞≤1}
=
{ ˜P = (1 + ∆1βW2)P : ∥∆1∥∞≤1}
together with the theorem shows that
βsup = sup{β : ∥βW2T∥∞< 1} = 1/∥W2T∥∞.
The condition ∥W2T∥∞< 1 also has a nice graphical interpretation. Note that
∥W2T∥∞< 1
⇔

W2(jω)L(jω)
1 + L(jω)
 < 1,
∀ω
⇔
|W2(jω)L(jω)| < |1 + L(jω)|,
∀ω.
The last inequality says that at every frequency, the critical point, -1, lies outside the disk of center
L(jω), radius |W2(jω)L(jω)| (Figure 4.3).
&%
'$
r
r - |W2L|
L
−1
Figure 4.3: Robust stability graphically.
There is a simple way to see the relevance of the condition ∥W2T∥∞< 1. First, draw the block
diagram of the perturbed feedback system, but ignoring inputs (Figure 4.4). The transfer function
from the output of ∆around to the input of ∆equals −W2T, so the block diagram collapses to
the conﬁguration shown in Figure 4.5. The maximum loop gain in Figure 4.5 equals ∥−∆W2T∥∞,
which is < 1 for all allowable ∆s iﬀthe small-gain condition ∥W2T∥∞< 1 holds.
The foregoing discussion is related to the small-gain theorem, a special case of which is this: If
L is stable and ∥L∥∞< 1, then (1 + L)−1 is stable too. An easy proof uses the Nyquist criterion.

4.3. ROBUST PERFORMANCE
53
−C
P
W2
∆


-
-
-
-
?
6
Figure 4.4: Perturbed feedback system.
−W2T
∆
-

Figure 4.5: Collapsed block diagram.
Summary of Robust Stability Tests
Table 4.1 summarizes the robust stability tests for the other uncertainty models.
Perturbation
Condition
(1 + ∆W2)P
∥W2T∥∞< 1
P + ∆W2
∥W2CS∥∞< 1
P/(1 + ∆W2P)
∥W2PS∥∞< 1
P/(1 + ∆W2)
∥W2S∥∞< 1
Table 4.1
Note that we get the same four transfer functions—T, CS, PS, S—as we did in Section 3.4. This
should not be too surprising since (up to sign) these are the only closed-loop transfer functions for
a unity feedback SISO system.
4.3
Robust Performance
Now we look into performance of the perturbed plant. Suppose that the plant transfer function
belongs to a set P. The general notion of robust performance is that internal stability and per-
formance, of a speciﬁed type, should hold for all plants in P. Again we focus on multiplicative
perturbations.

54
CHAPTER 4. UNCERTAINTY AND ROBUSTNESS
Recall that when the nominal feedback system is internally stable, the nominal performance
condition is ∥W1S∥∞< 1 and the robust stability condition is ∥W2T∥∞< 1. If P is perturbed to
(1 + ∆W2)P, S is perturbed to
1
1 + (1 + ∆W2)L =
S
1 + ∆W2T .
Clearly, the robust performance condition should therefore be
∥W2T∥∞< 1 and

W1S
1 + ∆W2T

∞
< 1,
∀∆.
Here ∆must be allowable. The next theorem gives a test for robust performance in terms of the
function
s 7→|W1(s)S(s)| + |W2(s)T(s)|,
which is denoted |W1S| + |W2T|.
Theorem 2 A necessary and suﬃcient condition for robust performance is
∥|W1S| + |W2T|∥∞< 1.
(4.3)
Proof (⇐) Assume (4.3), or equivalently,
∥W2T∥∞and

W1S
1 −|W2T|

∞
< 1.
(4.4)
Fix ∆. In what follows, functions are evaluated at an arbitrary point jω, but this is suppressed to
simplify notation. We have
1 = |1 + ∆W2T −∆W2T| ≤|1 + ∆W2T| + |W2T|
and therefore
1 −|W2T| ≤|1 + ∆W2T|.
This implies that

W1S
1 −|W2T|

∞
≥

W1S
1 + ∆W2T

∞
.
This and (4.4) yield

W1S
1 + ∆W2T

∞
< 1.
(⇒) Assume that
∥W2T∥∞< 1 and

W1S
1 + ∆W2T

∞
< 1,
∀∆.
(4.5)

4.3. ROBUST PERFORMANCE
55
Pick a frequency ω where
|W1S|
1 −|W2T|
is maximum. Now pick ∆so that
1 −|W2T| = |1 + ∆W2T|.
The idea here is that ∆(jω) should rotate W2(jω)T(jω) so that ∆(jω)W2(jω)T(jω) is negative
real. The details of how to construct such an allowable ∆are omitted. Now we have

W1S
1 −|W2T|

∞
=
|W1S|
1 −|W2T|
=
|W1S|
|1 + ∆W2T|
≤

W1S
1 + ∆W2T

∞
.
So from this and (4.5) there follows (4.4). ■
Test (4.3) also has a nice graphical interpretation. For each frequency ω, construct two closed
disks: one with center −1, radius |W1(jω)|; the other with center L(jω), radius |W2(jω)L(jω)|.
Then (4.3) holds iﬀfor each ω these two disks are disjoint (Figure 4.6).
&%
'$
r
&%
'$
r -
6
|W2L|
|W1|
L
−1
Figure 4.6: Robust performance graphically.
The robust performance condition says that the robust performance level 1 is achieved. More
generally, let’s say that robust performance level α is achieved if
∥W2T∥∞< 1 and

W1S
1 + ∆W2T

∞
< α,
∀∆.
Noting that at every frequency
max
|∆|≤1

W1S
1 + ∆W2T
 =
|W1S|
1 −|W2T|
we get that the minimum α equals

W1S
1 −|W2T|

∞
.
(4.6)

56
CHAPTER 4. UNCERTAINTY AND ROBUSTNESS
Alternatively, we may wish to know how large the uncertainty can be while the robust perfor-
mance condition holds. To do this, we scale the uncertainty level, that is, we allow ∆to satisfy
∥∆∥∞< β. Application of Theorem 1 shows that internal stability is robust iﬀ∥βW2T∥∞< 1.
Let’s say that the uncertainty level β is permissible if
∥βW2T∥∞< 1 and

W1S
1 + ∆W2T

∞
< 1,
∀∆.
Again, noting that
max
|∆|≤1

W1S
1 + β∆W2T
 =
|W1S|
1 −β|W2T|,
we get that the maximum β equals

W2T
1 −|W1S|

−1
∞
.
Now we turn brieﬂy to some related problems.
Robust Stability for Multiple Perturbations
Suppose that a nominal plant P is perturbed to
˜P = P 1 + ∆2W2
1 + ∆1W1
with W1, W2 both stable and ∆1, ∆2 both admissible. The robust stability condition is
∥|W1S| + |W2T|∥∞< 1,
which is just the robust performance condition in Theorem 2. A sketch of the proof goes like this:
From the fourth entry in Table 4.1, for ﬁxed ∆2 the robust stability condition for varying ∆1 is
W1
1
1 + (1 + ∆2W2)L

∞
< 1.
Then from Theorem 2 this holds for all admissible ∆2 iﬀ
∥|W1S| + |W2T|∥∞< 1.
This illustrates a more general point: Robust performance with one perturbation is equivalent
to robust stability with two perturbations, provided that performance is in terms of the ∞-norm
and the second perturbation is chosen appropriately.
Robust Command Response
Consider the block diagram shown in Figure 4.7. Shown are a plant P and two controller compo-
nents, C1 and C2. This is known as a two-degree-of-freedom controller because the plant input is
allowed to be a function of the two signals r and y independently, not just r −y. We will not go
into details about such controllers or about the appropriate deﬁnition of internal stability.

4.3. ROBUST PERFORMANCE
57
C1
C2
P


-
-
-
-

6
r
y
−
Figure 4.7: Two-degree-of-freedom controller.
Deﬁne
S :=
1
1 + PC2
,
T := 1 −S.
Then the transfer function from r to y, denoted Tyr, is
Tyr = PSC1.
Let M be a transfer function representing a model that we want the foregoing system to emulate.
Denote by e the diﬀerence between y and the output of M. The error transfer function, that from
r to e, is
Ter = Tyr −M = PSC1 −M.
The ideal choice for C1, the one making Ter = 0, would therefore be
C1 = M
PS .
This choice may violate the internal stability constraint, but let’s suppose that in order to continue
that it does not (this places some limitations on M).
Consider now a multiplicative perturbation of the plant: P becomes ˜P = (1 + ∆W2)P, ∆
admissible. Then Ter becomes
˜Ter
=
˜PC1
1 + ˜PC2
−M
=
˜P
1 + ˜PC2
M
PS −M
=
∆W2MS
1 + ∆W2T (after some algebra).
Deﬁning W1 := W2M, we ﬁnd that the maximum ∞-norm of the error transfer function, over all
admissible ∆, is
max
∆∥˜Tec∥∞=

W1S
1 −|W2T|

∞
.
The right-hand side we have already seen in (4.6).

58
CHAPTER 4. UNCERTAINTY AND ROBUSTNESS
Note that we convert the problem of making the closed-loop response from r to y match some
desired response by subtracting oﬀthat desired response and forming an error signal e which we seek
to keep small. In some treatments of the command response problem, the performance speciﬁcation
is taken to be: make |Tyr| close to a desired model. The problem with this speciﬁcation is that two
transfer functions can be close in magnitude but diﬀer substantially in phase. Surprisingly, this can
occur even when both transfer functions are minimum phase. The interested reader may want to
investigate this further using the gain-phase relation developed in Chapter 7.
4.4
Robust Performance More Generally
Theorem 2 gives the robust performance test under the following conditions:
Perturbation model:
(1 + ∆W2)P
Nominal performance condition:
∥W1S∥∞< 1
Table 4.2 gives tests for the four uncertainty models and two nominal performance conditions.
Nominal Performance Condition
Perturbation
∥W1S∥∞< 1
∥W1T∥∞< 1
(1 + ∆W2)P
∥|W1S| + |W2T|∥∞< 1
messy
P + W2∆
∥|W1S| + |W2CS|∥∞< 1
messy
P/(1 + ∆W2P)
messy
∥|W1T| + |W2PS|∥∞< 1
P/(1 + ∆W2)
messy
∥|W1T| + |W2S|∥∞< 1
Table 4.2
The entries marked messy are just that.
The diﬃculty is the way in which ∆enters.
For
example, consider the case where
Perturbation model:
(1 + ∆W2)P
Nominal performance condition:
∥W1T∥∞< 1
The perturbed T is
(1 + ∆W2)PC
1 + (1 + ∆W2)PC = (1 + ∆W2)T
1 + ∆W2T ,
so the perturbed performance condition is equivalent to
|W1(1 + ∆W2)T| < |1 + ∆W2T|,
∀ω.
Now for each ﬁxed ω
|W1(1 + ∆W2)T| ≤|W1T|(1 + |W2|)
and
1 −|W2T| ≤|1 + ∆W2T|.
So a suﬃcient condition for robust performance is

W1T(1 + |W2|)
1 −|W2T|

∞
< 1.

4.5. CONCLUSION
59
4.5
Conclusion
The nominal feedback system is assumed to be internally stable. Then the nominal performance
condition is ∥W1S∥∞< 1 and the robust stability condition (with respect to multiplicative pertur-
bations) is ∥W2T∥∞< 1.
The condition for simultaneously achieving nominal performance and robust stability is
∥max (|W1S|, |W2T|)∥∞< 1.
(4.7)
The robust performance condition is
∥W2T∥∞< 1 and

W1S
1 + ∆W2T

∞
< 1,
∀∆
and the test for this is
∥|W1S| + |W2T|∥∞< 1.
(4.8)
Since
max (|W1S|, |W2T|) ≤|W1S| + |W2T| ≤2 max (|W1S|, |W2T|)
(4.9)
conditions (4.7) and (4.8) are not too far apart. For instance, if nominal performance and robust
stability are obtained with a safety factor of 2, that is,
∥W1S∥∞< 1/2,
∥W2T∥∞< 1/2,
then robust performance is automatically obtained.
A compromise condition, which we shall treat in Chapters 8 and 12, is
∥(|W1S|2 + |W2T|2)1/2∥∞< 1.
(4.10)
Simple plane geometry shows that
max (|W1S|, |W2T|) ≤(|W1S|2 + |W2T|2)1/2 ≤|W1S| + |W2T|
(4.11)
and
1
√
2(|W1S| + |W2T|) ≤(|W1S|2 + |W2T|2)1/2 ≤
√
2 max (|W1S|, |W2T|).
(4.12)
Thus (4.10) is a reasonable approximation to both (4.7) and (4.8).
To elaborate on this point, let’s consider
x =
 x1
x2

=
 |W1S|
|W2T|

as a vector in R2. Then (4.7), (4.8), and (4.10) correspond, respectively, to the three diﬀerent norms
max (|x1|, |x2|),
|x1| + |x2|,
(|x1|2 + |x2|2)1/2.
The third is the Euclidean norm and is the most tractable. The point being made here is that
choice of these spatial norms is not crucial: The tradeoﬀs between |W1S| and |W2T| inherent in
control problems mean that although the norms may diﬀer by as much as a factor of 2, the actual
solutions one gets by using the diﬀerent norms are not very diﬀerent.

60
CHAPTER 4. UNCERTAINTY AND ROBUSTNESS
Exercises
1. Consider a unity-feedback system. True or false: If a controller internally stabilizes two plants,
they have the same number of poles in Res ≥0.
2. Unity-feedback problem. Let Pα(s) be a plant depending on a real parameter α. Suppose
that the poles of Pα move continuously as α varies over the interval [0, 1]. True or false: If a
controller internally stabilizes Pα for every α in [0, 1], then Pα has the same number of poles
in Re s ≥0 for every α in [0, 1].
3. For the unity-feedback system with P(s) = k/s, does there exist a proper controller C(s) such
that the feedback system is internally stable for both k = +1 and k = −1?
4. Suppose that
P(s) =
ω2
n
s(s + 2ζωn),
C(s) = 1
with ωn, ζ > 0. Note that the characteristic polynomial is the standard second-order one.
Find the phase margin as a function of ζ. Sketch the graph of this function.
5. Consider the unity-feedback system with
P(s) =
1
(s + 1)(s + α),
C(s) = 1
s.
For what range of α (a real number) is the feedback system internally stable? Find the upper
and lower gain margins as functions of α.
6. This problem studies robust stability for real parameter variations.
Consider the unity-
feedback system with C(s) = 10 and plant
1
s −a,
where a is real.
(a) Find the range of a for the feedback system to be internally stable.
(b) For a = 0 the plant is P(s) = 1/s. Regarding a as a perturbation, we can write the
plant as
˜P =
P
1 + ∆W2P
with W2(s) = −a. Then ˜P equals the true plant when ∆(s) = 1. Apply robust stability
theory to see when the feedback system with plant ˜P is internally stable for all ∥∆∥∞≤1.
You will get a smaller range for a than in part (a).
(c) Repeat with the nominal plant P(s) = 1/(s + 100).

4.5. CONCLUSION
61
7. This problem concerns robust stability of the unity-feedback system. Suppose that P and C
are nominal transfer functions for which the feedback system is internally stable. Instead of
allowing perturbations in just P, this problem allows perturbations in C too. Suppose that
P may be perturbed to
(1 + ∆1W)P
and C may be perturbed to
(1 + ∆2V )C.
The transfer functions W and V are ﬁxed, while ∆1 and ∆2 are variable transfer functions
having ∞-norms no greater than 1. Making appropriate additional assumptions, ﬁnd a suﬃ-
cient condition, depending only on the four functions P, C, W, V , for robust stability. Prove
suﬃciency. (A weak suﬃcient condition is the goal; for example, the condition W = V = 0
would be too strong.)
8. Assume that the nominal plant transfer function is a double integrator,
P(s) = 1
s2 .
The performance requirement is that the plant output should track reference inputs over the
frequency range [0, 1].
The performance weight W1 could therefore be chosen so that its
magnitude is constant over this frequency range and then rolls oﬀat higher frequencies. A
common choice for W1 is a Butterworth ﬁlter, which is maximally ﬂat over its bandwidth.
Choose a third-order Butterworth ﬁlter for W1 with cutoﬀfrequency 1 rad/s. Take the weight
W2 to be
W2(s) =
0.21s
0.1s + 1.
(a) Design a proper C to achieve internal stability for the nominal plant.
(b) Check the robust stability condition ∥W2T∥∞< 1. If this does not hold, redesign C
until it does. It is not necessary to get a C that yields good performance.
(c) Compute the robust performance level α for your controller from (4.6).
9. Consider the class of perturbed plants of the form
P
1 + ∆W2P ,
where W2 is a ﬁxed stable weighting function with W2P strictly proper and ∆is a variable
stable transfer function with ∥∆∥∞≤1. Assume that C is a controller achieving internal
stability for P. Prove that C provides internal stability for the perturbed plant if ∥W2PS∥∞<
1.
10. Suppose that the plant transfer function is
˜P(s) = [1 + ∆(s)W2(s)] P(s),

62
CHAPTER 4. UNCERTAINTY AND ROBUSTNESS
where
W2(s) =
2
s + 10,
P(s) =
1
s −1,
and the stable perturbation ∆satisﬁes ∥∆∥∞≤2. Suppose that the controller is the pure
gain C(s) = k. We want the feedback system to be internally stable for all such perturbations.
Determine over what range of k this is true.
Notes and References
The basis for this chapter is Doyle and Stein (1981). This paper emphasized the importance of
explicit uncertainty models such as multiplicative and additive. Theorem 1 is stated in that paper,
but a complete proof is due to Chen and Desoer (1982). The suﬃciency part of this theorem is a
version of the small-gain theorem, due to Sandberg and Zames [see, e.g., Desoer and Vidyasagar
(1975)].

Chapter 5
Stabilization
In this chapter we study the unity-feedback system with block diagram shown in Figure 5.1. Here
C
P




-
-
-
-
-
?
6
r
u
y
d
−
e
Figure 5.1: Unity-feedback system.
P is strictly proper and C is proper.
Most synthesis problems can be formulated in this way: Given P, design C so that the feedback
system (1) is internally stable, and (2) acquires some additional desired property; for example, the
output y asymptotically tracks a step input r. The method of solution is to parametrize all Cs for
which (1) is true, and then to see if there exists a parameter for which (2) holds. In this chapter such
a parametrization is derived and then applied to two problems: achieving asymptotic performance
specs and internal stabilization by a stable controller.
5.1
Controller Parametrization: Stable Plant
In this section we assume that P is already stable, and we parametrize all Cs for which the feedback
system is internally stable.
Introduce the symbol S for the family of all stable, proper, real-
rational functions. Notice that S is closed under addition and multiplication: If F, G ∈S, then
F + G, FG ∈S. Also, 1 ∈S. (Thus S is a commutative ring with identity.)
Theorem 1 Assume that P ∈S. The set of all Cs for which the feedback system is internally
stable equals

Q
1 −PQ : Q ∈S

.
63

64
CHAPTER 5. STABILIZATION
Proof (⊂) Suppose that C achieves internal stability. Let Q denote the transfer function from r
to u, that is,
Q :=
C
1 + PC .
Then Q ∈S and
C =
Q
1 −PQ.
(⊃) Conversely, suppose that Q ∈S and deﬁne
C :=
Q
1 −PQ.
(5.1)
According to the deﬁnition in Section 3.2, the feedback system is internally stable iﬀthe nine
transfer functions
1
1 + PC


1
−P
−1
C
1
−C
PC
P
1


all are stable and proper. After substitution from (5.1) and clearing of fractions, this matrix becomes


1 −PQ
−P(1 −PQ)
−(1 −PQ)
Q
1 −PQ
−Q
PQ
P(1 −PQ)
1 −PQ

.
Clearly, these nine entries belong to S. ■
Note that all nine transfer functions above are aﬃne functions of the free parameter Q; that is,
each is of the form T1 + T2Q for some T1, T2 in S. In particular the sensitivity and complementary
sensitivity functions are
S
=
1 −PQ,
T
=
PQ.
Let us look at a simple application. Suppose that we want to ﬁnd a C so that the feedback
system is internally stable and y asymptotically tracks a step r (when d = 0). Parametrize C as in
the theorem. Then y asymptotically tracks a step iﬀthe transfer function from r to e (i.e., S) has
a zero at s = 0, that is,
P(0)Q(0) = 1.
This equation has a solution Q in S iﬀP(0) ̸= 0. Conclusion: The problem has a solution iﬀ
P(0) ̸= 0; when this holds, the set of all solutions is

C =
Q
1 −PQ : Q ∈S, Q(0) =
1
P(0)

.

5.2. COPRIME FACTORIZATION
65
Observe that Q inverts P at dc. Also, you can check that a controller of the latter form has a pole
at s = 0, as it must by Theorem 3 of Chapter 3.
Example For the plant
P(s) =
1
(s + 1)(s + 2)
suppose that it is desired to ﬁnd an internally stabilizing controller so that y asymptotically tracks
a ramp r. Parametrize C as in the theorem. The transfer function S from r to e must have (at
least) two zeros at s = 0, where r has two poles. Let us take
Q(s) = as + b
s + 1 .
This belongs to S and has two variables, a and b, for the assignment of the two zeros of S. We have
S(s)
=
1 −
as + b
(s + 1)2(s + 2)
=
s3 + 4s2 + (5 −a)s + (2 −b)
(s + 1)2(s + 2)
,
so we should take a = 5, b = 2. This gives
Q(s)
=
5s + 2
s + 1 ,
C(s)
=
(5s + 2)(s + 1)(s + 2)
s2(s + 4)
.
The controller is internally stabilizing and has two poles at s = 0.
5.2
Coprime Factorization
Now suppose that P is not stable and we want to ﬁnd an internally stabilizing C. We might try as
follows. Write P as the ratio of coprime polynomials,
P = N
M .
By Euclid’s algorithm (reviewed below) we can get two other polynomials X, Y satisfying the
equation
NX + MY = 1.
Remembering Theorem 3.1 (the feedback system is internally stable iﬀthe characteristic polynomial
has no zeros in Re s ≥0), we might try to make the left-hand side equal to the characteristic
polynomial by setting
C = X
Y .
The trouble is that Y may be 0; even if not, this C may not be proper.

66
CHAPTER 5. STABILIZATION
Example 1
For P(s) = 1/s, we can take N(s) = 1, M(s) = s. One solution to the equation
NX + MY = 1 is X(s) = 1, Y (s) = 0, for which X/Y is undeﬁned. Another solution is X(s) =
−s + 1, Y (s) = 1, for which X/Y is not proper.
The remedy is to arrange that N, M, X, Y are all elements of S instead of polynomials. Two
functions N and M in S are coprime if there exist two other functions X and Y also in S and
satisfying the equation
NX + MY = 1.
Notice that for this equation to hold, N and M can have no common zeros in Res ≥0 nor at the
point s = ∞—if there were such a point s0, there would follow
0 = N(s0)X(s0) + M(s0)Y (s0) ̸= 1.
It can be proved that this condition is also suﬃcient for coprimeness.
Let G be a real-rational transfer function. A representation of the form
G = N
M ,
N, M ∈S,
where N and M are coprime, is called a coprime factorization of G over S. The purpose of this
section is to present a method for the construction of four functions in S satisfying the two equations
G = N
M ,
NX + MY = 1.
The construction of N and M is easy.
Example 2 Take G(s) = 1/(s −1). To write G = N/M with N and M in S, simply divide the
numerator and denominator polynomials, 1 and s −1, by a common polynomial with no zeros in
Res ≥0, say (s + 1)k:
1
s −1 = N(s)
M(s),
N(s) =
1
(s + 1)k ,
M(s) =
s −1
(s + 1)k .
If the integer k is greater than 1, then N and M are not coprime—they have a common zero at
s = ∞. So
N(s) =
1
s + 1,
M(s) = s −1
s + 1
suﬃce.
More generally, to get N and M we could divide the numerator and denominator polynomials
of G by (s + 1)k, where k equals the maximum of their degrees. What is not so easy is to get the
other two functions, X and Y , and this is why we need Euclid’s algorithm.
Euclid’s algorithm computes the greatest common divisor of two given polynomials, say n(λ)
and m(λ). When n and m are coprime, the algorithm can be used to compute polynomials x(λ),
y(λ) satisfying
nx + my = 1.

5.2. COPRIME FACTORIZATION
67
Procedure A: Euclid’s Algorithm
Input: polynomials n, m
Initialize: If it is not true that degree (n) ≥degree (m), interchange n and m.
Step 1 Divide m into n to get quotient q1 and remainder r1:
n = mq1 + r1,
degree r1 < degree m.
Step 2 Divide r1 into m to get quotient q2 and remainder r2:
m = r1q2 + r2,
degree r2 < degree r1.
Step 3 Divide r2 into r1:
r1 = r2q3 + r3,
degree r3 < degree r2.
Continue.
Stop at Step k when rk is a nonzero constant.
Then x, y are obtained as illustrated by the following example for k = 3. The equations are
n = mq1 + r1,
m = r1q2 + r2,
r1 = r2q3 + r3,
that is,


1
0
0
q2
1
0
−1
q3
1




r1
r2
r3

=


1
−q1
0
1
0
0


 n
m

.
Solve for r3 by, say, Gaussian elimination:
r3 = (1 + q2q3)n + [−q3 −q1(1 + q2q3)]m.
Set
x
=
1
r3
(1 + q2q3),
y
=
1
r3
[−q3 −q1(1 + q2q3)].

68
CHAPTER 5. STABILIZATION
Example 3 The algorithm for n(λ) = λ2, m(λ) = 6λ2 −5λ + 1 goes like this:
q1(λ)
=
1
6,
r1(λ)
=
5
6λ −1
6,
q2(λ)
=
36
5 λ −114
25 ,
r2(λ)
=
6
25.
Since r2 is a nonzero constant, we stop after Step 2. Then the equations are
n
=
mq1 + r1,
m
=
r1q2 + r2,
yielding
r2 = (1 + q1q2)m −q2n.
So we should take
x = −q2
r2
,
y = 1 + q1q2
r2
,
that is,
x(λ) = −30λ + 19,
y(λ) = 5λ + 1.
Next is a procedure for doing a coprime factorization of G.
The main idea is to transform
variables, s →λ, so that polynomials in λ yield functions in S.
Procedure B
Input: G
Step 1 If G is stable, set N = G, M = 1, X = 0, Y = 1, and stop; else, continue.
Step 2 Transform G(s) to ˜G(λ) under the mapping s = (1 −λ)/λ. Write ˜G as a ratio of
coprime polynomials:
˜G(λ) = n(λ)
m(λ).
Step 3 Using Euclid’s algorithm, ﬁnd polynomials x(λ), y(λ) such that
nx + my = 1.
Step 4
Transform n(λ), m(λ), x(λ), y(λ) to N(s), M(s), X(s), Y (s) under the mapping
λ = 1/(s + 1).

5.3. COPRIME FACTORIZATION BY STATE-SPACE METHODS (OPTIONAL)
69
The mapping used in this procedure is not unique; the only requirement is that polynomials n, and
so on, map to N, and so on, in S.
Example 4 For
G(s) =
1
(s −1)(s −2)
the algorithm gives
˜G(λ)
=
λ2
6λ2 −5λ + 1,
n(λ)
=
λ2,
m(λ)
=
6λ2 −5λ + 1,
x(λ)
=
−30λ + 19,
y(λ)
=
5λ + 1 (from Example 3),
N(s)
=
1
(s + 1)2 ,
M(s)
=
(s −1)(s −2)
(s + 1)2
,
X(s)
=
19s −11
s + 1
,
Y (s)
=
s + 6
s + 1.
5.3
Coprime Factorization by State-Space Methods (Optional)
This optional section presents a state-space procedure for computing a coprime factorization over
S of a proper G. This procedure is more eﬃcient than the polynomial method in the preceding
section.
We start with a new data structure. Suppose that A, B, C, D are real matrices of dimensions
n × n,
n × 1,
1 × n,
1 × 1.
The transfer function going along with this quartet is
D + C(sI −A)−1B.
Note that the constant D equals the value of the transfer function at s = ∞; if the transfer function
is strictly proper, then D = 0. It is convenient to write
 A
B
C
D

instead of
D + C(sI −A)−1B.

70
CHAPTER 5. STABILIZATION
Beginning with a realization of G,
G(s) =
 A
B
C
D

,
the goal is to get state-space realizations for four functions N, M, X, Y , all in S, such that
G = N
M ,
NX + MY = 1.
First, we look at how to get N and M. If the input and output of G are denoted u and y,
respectively, then the state model of G is
˙x
=
Ax + Bu,
(5.2)
y
=
Cx + Du.
(5.3)
Choose a real matrix F, 1 × n, such that A + BF is stable (i.e., all eigenvalues in Res < 0). Now
deﬁne the signal v := u −Fx. Then from (5.2) and (5.3) we get
˙x
=
(A + BF)x + Bv,
u
=
Fx + v,
y
=
(C + DF)x + Dv.
Evidently from these equations, the transfer function from v to u is
M(s) :=
 A + BF
B
F
1

,
(5.4)
and that from v to y is
N(s) :=
 A + BF
B
C + DF
D

.
(5.5)
Therefore,
u = Mv,
y = Nv,
so that y = NM−1u, that is, G = N/M. Clearly, N and M are proper, and they are stable because
A + BF is. Thus N, M ∈S. Suggestion: Test the formulas above for the simplest case, G(s) = 1/s
(A = 0, B = 1, C = 1, D = 0).
The theory behind the formulas for X and Y is beyond the scope of this book. The procedure
is to choose a real matrix H, n × 1, so that A + HC is stable, and then set
X(s)
:=
 A + HC
H
F
0

,
(5.6)
Y (s)
:=
 A + HC
−B −HD
F
1

.
(5.7)
In summary, the procedure to do a coprime factorization of G is this:
Step 1 Get a realization (A, B, C, D) of G.
Step 2 Compute matrices F and H so that A + BF and A + HC are stable.
Step 3 Using formulas (5.4) to (5.7), compute the four functions N, M, X, Y .

5.4. CONTROLLER PARAMETRIZATION: GENERAL PLANT
71
5.4
Controller Parametrization: General Plant
The transfer function P is no longer assumed to be stable. Let P = N/M be a coprime factorization
over S and let X, Y be two functions in S satisfying the equation
NX + MY = 1.
(5.8)
Theorem 2 The set of all Cs for which the feedback system is internally stable equals
X + MQ
Y −NQ : Q ∈S

.
It is useful to note that Theorem 2 reduces to Theorem 1 when P ∈S. To see this, recall from
Section 5.2 (Step 1 of Procedure B) that we can take
N = P,
M = 1,
X = 0,
Y = 1
when P ∈S. Then
X + MQ
Y −NQ =
Q
1 −PQ.
The proof of Theorem 2 requires a preliminary result.
Lemma 1 Let C = NC/MC be a coprime factorization over S. Then the feedback system is inter-
nally stable iﬀ
(NNC + MMC)−1 ∈S.
The proof of this lemma is almost identical to the proof of Theorem 3.1, and so is omitted.
Proof of Theorem 2 (⊃) Suppose that Q ∈S and
C := X + MQ
Y −NQ .
To show that the feedback system is internally stable, deﬁne
NC := X + MQ,
MC := Y −NQ.
Then from the equation
NX + MY = 1
it follows that
NNC + MMC = 1.
Therefore, C = NC/MC is a coprime factorization, and from Lemma 1 the feedback system is
internally stable.

72
CHAPTER 5. STABILIZATION
(⊂) Conversely, let C be any controller achieving internal stability. We must ﬁnd a Q in S such
that
C = X + MQ
Y −NQ .
Let C = NC/MC be a coprime factorization over S and deﬁne
V := (NNC + MMC)−1
so that
NNCV + MMCV = 1.
(5.9)
By Lemma 1, V ∈S. Let Q be the solution of
MCV = Y −NQ.
(5.10)
Substitute (5.10) into (5.9) to get
NNCV + M(Y −NQ) = 1.
(5.11)
Also, add and subtract NMQ in (5.8) to give
N(X + MQ) + M(Y −NQ) = 1.
(5.12)
Comparing (5.11) and (5.12), we see that
NCV = X + MQ.
(5.13)
Now (5.10) and (5.13) give
C = NCV
MCV = X + MQ
Y −NQ .
It remains to show that Q ∈S. Multiply (5.10) by X and (5.13) by Y , then subtract and switch
sides:
(NX + MY )Q = Y NCV −XMCV.
But the left-hand side equals Q by (5.8), while the right-hand side belongs to S. So we are done. ■
Theorem 2 gives an automatic way to stabilize a plant.
Example Let
P(s) =
1
(s −1)(s −2).

5.5. ASYMPTOTIC PROPERTIES
73
Apply Procedure B to get
N(s)
=
1
(s + 1)2 ,
M(s)
=
(s −1)(s −2)
(s + 1)2
,
X(s)
=
19s −11
s + 1
,
Y (s)
=
s + 6
s + 1.
According to the theorem, the controller
C(s) = X(s)
Y (s) = 19s −11
s + 6
achieves internal stability.
As before, when P was stable, all closed-loop transfer functions are aﬃne functions of Q if
C is parametrized as in the theorem statement. For example, the sensitivity and complementary
sensitivity functions are
S
=
M(Y −NQ),
T
=
N(X + MQ).
Finally, it is sometimes useful to note that Lemma 1 suggests another way to solve the equation
NX + MY = 1 given coprime N and M. First, ﬁnd a controller C achieving internal stability for
P = N/M—this might be easier than solving for X and Y . Next, write a coprime factorization of
C: C = NC/MC. Then Lemma 1 says that
V := NNC + MMC
is invertible in S. Finally, set X = NCV −1 and Y = MCV −1.
5.5
Asymptotic Properties
How to ﬁnd a C to achieve internal stability and asymptotic properties simultaneously is perhaps
best shown by an example.
Let
P(s) =
1
(s −1)(s −2).
The problem is to ﬁnd a proper C so that
1. The feedback system is internally stable.
2. The ﬁnal value of y equals 1 when r is a unit step and d = 0.
3. The ﬁnal value of y equals zero when d is a sinusoid of 10 rad/s and r = 0.

74
CHAPTER 5. STABILIZATION
The ﬁrst step is to parametrize all stabilizing Cs. Suitable N, M, X, Y are given in the example
of the preceding section. From Theorem 2 C must have the form
C = X + MQ
Y −NQ
(5.14)
for some Q in S in order to satisfy (1).
For such C the transfer function from r to y equals
N(X + MQ). By the ﬁnal-value theorem (2) holds iﬀ
N(0)[X(0) + M(0)Q(0)] = 1.
(5.15)
Similarly, the transfer function from d to y equals N(Y −NQ), so (3) holds iﬀ
N(10j)[Y (10j) −N(10j)Q(10j)] = 0.
(5.16)
So the problem reduces to the purely algebraic one of ﬁnding a function Q in S satisfying (5.15)
and (5.16), which reduce to
Q(0)
=
6,
(5.17)
Q(10j)
=
(6 + 10j)(1 + 10j) = −94 + 70j.
This last equation is really two real equations:
Re Q(10j)
=
−94,
(5.18)
Im Q(10j)
=
70.
(5.19)
So we must ﬁnd a function Q in S satisfying (5.17), (5.18), and (5.19).
A method that will certainly work is to let Q be a polynomial in (s + 1)−1 with enough variable
coeﬃcients. This guarantees that Q ∈S. Since we need to satisfy three equations, we should allow
three coeﬃcients. So take Q in the form
Q(s) = x1 + x2
1
s + 1 + x3
1
(s + 1)2 .
The three equations (5.17)-(5.19) lead to one of the form Ax = b, where
x =


x1
x2
x3

.
Solve for x. In this case the solution is
x1 = −79,
x2 = −723,
x3 = 808.
This gives
Q(s) = −79s2 −881s + 6
(s + 1)2
.
Finally, we get C from (5.14):
C(s) = −60s4 −598s3 + 2515s2 −1794s + 1
s(s2 + 100)(s + 9)
.
In summary, the procedure consists of four steps:

5.6. STRONG AND SIMULTANEOUS STABILIZATION
75
1. Parametrize all internally stabilizing controllers.
2. Reduce the asymptotic specs to interpolation constraints on the parameter.
3. Find (if possible) a parameter to satisfy these constraints.
4. Back-substitute to get the controller.
5.6
Strong and Simultaneous Stabilization
Practicing control engineers are reluctant to use unstable controllers, especially if the plant itself is
stable. System integrity is the motivation: For example, if a sensor or actuator fails, or is deliberately
turned oﬀduring start-up or shutdown, and the feedback loop opens, overall stability is maintained
if both plant and controller individually are stable. If the plant itself is unstable, the argument
against using an unstable controller is less compelling.
However, knowledge of when a plant is
or is not stabilizable with a stable controller is useful for another problem, namely, simultaneous
stabilization, meaning stabilization of several plants by the same controller.
The issue of simultaneous stabilization arises when a plant is subject to a discrete change, such
as when a component burns out. Simultaneous stabilization of two plants can also be viewed as
an example of a problem involving highly structured uncertainty. A set of plants with exactly two
elements is the most extreme example of highly structured uncertainty, standing at the opposite
end of the spectrum from the unstructured disk-like uncertainty, which is the type of uncertainty
focused on in this book.
Say that a plant is strongly stabilizable if internal stabilization can be achieved with C itself a
stable transfer function. We start with an example of a plant that is not strongly stabilizable.
Example 1 Consider the plant transfer function
P(s) =
s −1
s(s −2).
Every C achieving internal stability is itself unstable. To prove this, start with a coprime factor-
ization of P:
N(s)
=
s −1
(s + 1)2 ,
M(s)
=
s(s −2)
(s + 1)2 ,
X(s)
=
14s −1
s + 1 ,
Y (s)
=
s −9
s + 1.
According to Theorem 2, all stabilizing controllers have the form
C = X + MQ
Y −NQ
for some Q in S. Since X + MQ and Y −NQ too are coprime—they satisfy the equation
N(X + MQ) + M(Y −NQ) = 1

76
CHAPTER 5. STABILIZATION
—they have no common zero in Res ≥0. So to show that all such Cs are unstable, it suﬃces to
show that Y −NQ has a zero in Res ≥0 for every Q in S. Now
N(1) = 0,
N(∞) = 0,
so for every Q in S
(Y −NQ)(1)
=
Y (1)
=
−4,
(Y −NQ)(∞)
=
Y (∞)
=
1.
Notice that the two numbers on the right-hand side have opposite sign. Thus as s moves along the
positive real axis, the function (Y −NQ)(s) changes sign. By continuity, it must equal zero at some
such point, that is, Y −NQ has a real zero somewhere on the positive real axis.
The poles and zeros of P must share a certain property in order for P to be strongly stabilizable.
In the following theorem, the point at s = ∞is included among the real zeros of P.
Theorem 3 P is strongly stabilizable iﬀit has an even number of real poles between every pair of
real zeros in Res ≥0.
To illustrate, continue with the example above. The zeros, including the point at inﬁnity, are
at s = 1, ∞. Between this pair is a single pole, at s = 2. This plant therefore fails the test.
As another example, consider
P(s) = (s −1)2(s2 −s + 1)
(s −2)2(s + 1)3
.
On the positive real axis, including ∞, P has three zeros, two at s = 1 and one at s = ∞. It has
two other zeros in Res ≥0, which, not being real, are irrelevant. In counting poles between pairs of
zeros we only have to consider distinct zeros (there are no poles between coincident zeros). Between
zeros at s = 1, ∞lie two poles, at s = 2. So this P is strongly stabilizable.
Proof of Theorem 3, Necessity The proof is just as in Example 1. Assume that the pole-zero
test fails. To show that every stabilizing controller is unstable, start with a coprime factorization
of P,
P = N
M ,
NX + MY = 1,
and some stabilizing controller,
C = X + MQ
Y −NQ ,
Q ∈S.
It suﬃces to show that Y −NQ has a zero in Res ≥0.
By assumption, there is some pair of real zeros of N in Res ≥0, at s = σ1, σ2, say, with an odd
number of zeros of M in between. It follows that M(σ1) and M(σ2) have opposite sign; then so do

5.6. STRONG AND SIMULTANEOUS STABILIZATION
77
Y (σ1) and Y (σ2), since MY = 1 at the right half-plane zeros of N. Hence the function Y −NQ
has a real zero somewhere between s = σ1 and s = σ2. ■
The proof of suﬃciency is ﬁrst illustrated by means of an example.
Example 2 Take the plant transfer function
P(s) =
s −1
(s −2)2 .
This has two poles, at s = 2, between the two zeros at s = 1, ∞, so P is strongly stabilizable. To
get a stable, stabilizing C, we should get a Q in S such that the inverse of U := Y −NQ belongs
to S. Equivalently, we should get a U in S such that U−1 ∈S and U = Y at the two zeros of N,
namely, s = 1, ∞. For this P we have
N(s) =
s −1
(s + 1)2 ,
M(s) = (s −2)2
(s + 1)2 .
Now
Y (1) =
1
M(1) = 4,
Y (∞) =
1
M(∞) = 1.
So the problem reduces to constructing a U in S such that
U−1 ∈S,
U(1) = 4,
U(∞) = 1.
The latter problem can be solved in two steps. First, get a U1 in S such that
U−1
1
∈S,
U1(1) = 4.
The easiest choice is the constant U1(s) = 4. Now we look for U of the form
U = (1 + aF)lU1,
where a is a constant, l an integer, and F ∈S. To guarantee that U(1) = U1(1) we should arrange
that F(1) = 0, for example,
F(s) = s −1
s + 1.
Then for U(∞) = 1 we need (1 + a)l4 = 1, that is,
a =
1
4
1/l
−1,
(5.20)
and for U−1 ∈S it suﬃces to have ∥aF∥∞< 1 (i.e., |a| < 1/∥F∥∞= 1). So suitable l and a can be
obtained by ﬁrst choosing l large enough that

1
4
1/l
−1
 < 1

78
CHAPTER 5. STABILIZATION
and then getting a from (5.20), for example, l = 1, a = −3/4. This gives
U(s) =

1 −3
4
s −1
s + 1

4 = s + 7
s + 1.
Finally, U, M, N uniquely determine C, as follows:
U = Y −NQ =⇒Q = Y −U
N
=⇒C = X + MQ
Y −NQ = 1 −MU
NU
.
For this example we get C(s) = 27/(s + 7). Notice that we did not actually have to construct X
and Y .
Now for the constructive procedure that proves suﬃciency in Theorem 3. The general proce-
dure is fairly involved, so a simplifying assumption will be made that Ps unstable poles and zeros
(including ∞) are all real and distinct. (Of course, Theorem 3 holds without this assumption.)
Procedure
Step 0 Write P = N/M with N, M coprime. Arrange the non-negative real zeros of N as
follows:
0 ≤σ1 < σ2 < · · · < σm = ∞.
Deﬁne ri := 1/M(σi), i = 1, . . . , m. Then P is strongly stabilizable iﬀr1, . . . , rm all have the
same sign. If this is true, continue.
Step 1 Set U1(s) = r1.
Continue. Assume that Uk has been constructed to satisfy
Uk, U−1
k
∈S,
Uk(σi) = ri,
i = 1, . . . , k.
Step k + 1 Choose F in S to have zeros at s = σ1, . . . , σk. Choose l ≥1 and a so that
[1 + aF(σk+1)]l Uk(σk+1) = rk+1,
|a| <
1
∥F∥∞
.
Set Uk+1 = (1 + aF)lUk.
Continue to Step m.
Step m + 1 Set U = Um and C = (1 −MU)/(NU).
Now we return to the problem of simultaneous stabilization and see that it can be reduced to
one of strong stabilization. Two plants P1 and P2 are simultaneously stabilizable if internal stability
is achievable for both by a common controller. Bring in coprime factorizations:
Pi = Ni
Mi
,
NiXi + MiYi = 1,
i = 1, 2

5.6. STRONG AND SIMULTANEOUS STABILIZATION
79
and deﬁne
N = N2M1 −N1M2,
M = N2X1 + M2Y1,
P = N
M .
For example, if P1 is already stable, we may take
N1 = P1,
M1 = 1,
X1 = 0,
Y1 = 1,
in which case
N = N2 −P1M2,
M = M2,
so P = P2 −P1.
Theorem 4 P1 and P2 are simultaneously stabilizable iﬀP is strongly stabilizable.
Proof The controllers stabilizing Pi are
Xi + MiQi
Yi −NiQi
,
Qi ∈S.
Thus P1 and P2 are simultaneously stabilizable iﬀthere exist Q1, Q2 in S such that
X1 + M1Q1
Y1 −N1Q1
= X2 + M2Q2
Y2 −N2Q2
.
Since these two fractions both have coprime factors, this equation holds iﬀthere exists U in S such
that
U−1
∈
S,
X1 + M1Q1
=
U(X2 + M2Q2),
Y1 −N1Q1
=
U(Y2 −N2Q2).
To simplify the bookkeeping, write these last two equations in matrix form:

1
Q1
  X1
Y1
M1
−N1

= U

1
Q2
  X2
Y2
M2
−N2

.
Postmultiply this equation by
 N2
Y2
M2
−X2

to get

1
Q1
  X1
Y1
M1
−N1
  N2
Y2
M2
−X2

= U

1
Q2

.
Now the ﬁrst column of the matrix
 X1
Y1
M1
−N1
  N2
Y2
M2
−X2


80
CHAPTER 5. STABILIZATION
is
 M
N

;
denote the second column by
 X
Y

.
Then the previous matrix equation is equivalent to the two equations
M + NQ1
=
U,
X + Y Q1
=
UQ2.
To recap, P1 and P2 are simultaneously stabilizable iﬀthere exist Q1, Q2, U in S such that
U−1
∈
S,
M + NQ1
=
U,
X + Y Q1
=
UQ2.
Clearly, this is equivalent to the condition, there exist Q1, U in S such that
U−1
∈
S,
M + NQ1
=
U
[because we can get Q2 via (X + Y Q1)/U]. But it can be checked that N and M are coprime.
Thus from Lemma 1 the previous condition is equivalent to, P can be stabilized by some stable
controller, namely, Q1. ■
Example 3 Consider
P1(s) =
1
s + 1,
P2(s) =
as + b
(s + 1)(s −1),
where a and b are real constants with a ̸= 1. Since P1 is stable, we have
P(s) = P2(s) −P1(s) = −(1 −a)s −(1 + b)
(s + 1)(s −1)
.
This has zeros at
s = 1 + b
1 −a, ∞
and a simple unstable pole at s = 1. So P is strongly stabilizable, or P1 and P2 are simultaneously
stabilizable, iﬀeither the zero (1 + b)/(1 −a) is negative or it lies to the right of the unstable pole,
that is,
either 1 + b
1 −a < 0 or
1 + b
1 −a > 1.
Simultaneous stabilization for more than two plants is still an unsolved problem.

5.7. CART-PENDULUM EXAMPLE
81


l
u
y
x
θ
d
m
M
-

-

@
@
R
-









Figure 5.2: Cart-pendulum example.
5.7
Cart-Pendulum Example
An interesting stabilization problem is aﬀorded by the cart-pendulum example, a common toy
control system. The setup is shown in Figure 5.2. The system consists of a cart of mass M that
slides in one dimension x on a horizontal surface, with a ball of mass m at the end of a rigid massless
pendulum of length l. The cart and ball are treated as point masses, with the pivot at the center of
the cart. There is assumed to be no friction and no air resistance. Shown as inputs are a horizontal
force u on the cart and a force d on the ball perpendicular to the pendulum. The other signals
shown are the angle θ and the position of the ball y = x + l sin θ.
Elementary dynamics yields the following equations of motion:
(M + m)¨x + ml(¨θ cos θ −˙θ2 sin θ)
=
u + d cos θ,
(5.21)
m

¨x cos θ + l¨θ −g sin θ

=
d.
(5.22)
These are nonlinear equations which can be linearized about an equilibrium position, of which there
are two: (x, θ) = (0, 0) and (x, θ) = (0, π) (i.e., the pendulum either up or down).
Linearization About Pendulum Up
The two linearized equations are
(M + m)¨x + ml¨θ
=
u + d,
¨x + l¨θ −gθ
=
1
md.
Take Laplace transforms to get
 (M + m)s2
mls2
s2
ls2 −g
  ˆx
ˆθ

=

ˆu + ˆd
1
m
ˆd

.

82
CHAPTER 5. STABILIZATION
Thus
 ˆx
ˆθ

=
1
D(s)
" ls2 −g
−g
−s2
M
m s2
#  ˆu
ˆd

,
where
D(s) = s2[Mls2 −(M + m)g].
Finally,
ˆy = ˆx + lˆθ =
1
D(s)

−g
M
m ls2g
  ˆu
ˆd

.
In particular, the transfer functions from u to x and y are, respectively,
ls2 −g
D(s) ,
−g
D(s).
These are both unstable, having right half-plane poles at
s = 0, 0,
r
(M + m)g
Ml
.
Also, the transfer function from u to x has a right half-plane zero at s =
p
g/l.
Linearization About Pendulum Down
Replacing θ by π + θ in equations (5.21) and (5.22) and linearizing, we get
(M + m)¨x −ml¨θ
=
u −d,
−¨x + l¨θ + gθ
=
1
md,
so
 ˆx
ˆθ

=
1
D(s)
" ls2 + g
−g
s2
M
m s2
#  ˆu
ˆd

,
and
ˆy = ˆx −lˆθ =
1
D(s)

g
−M
m ls2g
  ˆu
ˆd

,
where
D(s) = s2[Mls2 + (M + m)g].
The transfer functions from u to x and y are now, respectively,
ls2 + g
D(s) ,
g
D(s).

5.7. CART-PENDULUM EXAMPLE
83
Let us look at the problem of stabilizing the u-to-x transfer function with the pendulum in the
up position. The transfer function is
ls2 −g
s2[Mls2 −(M + m)g].
Since this has an unstable pole, namely,
r
(M + m)g
Ml
,
between two real zeros at s =
p
g/l, ∞, from the preceding section this transfer function is not
strongly stabilizable. Having no ﬁnite zeros, the u-to-y transfer function is, however.
Is the cart-pendulum stabilizable if we measure x and control d? First of all, what does this
mean? The cart-pendulum as conﬁgured is really a multivariable system: It has two inputs, u and
d, and two outputs, x and θ (y is a linear combination of these two). So really there are four loops
we could close: from x to u and d and from θ to u and d. Let us contemplate closing just from x
to d. We would like all closed-loop transfer functions to be stable, for example, u-to-θ, x-to-θ, and
so on. Is this possible?
(This analysis applies only to the linearized system. Since there are poles on the imaginary
axis, the stability of the linear system does not determine even the local stability of the nonlinear
system.)
We shall return to this example in the next chapter.
Exercises
1. Compute a coprime factorization over S of
G(s) =
s3
s2 −s + 1.
2. For
P(s) =
3
s −4
compute a controller C so that the feedback system is internally stable and the tracking error
e goes to 0 when r is a ramp and d = 0.
3. For
P(s) =
1
s(s2 + 0.2s + 1)
ﬁnd an internally stabilizing C so that the ﬁnal value of r −y equals zero when r is a unit
ramp and d is a sinusoid of frequency 2 rad/s.
4. Suppose that P(s) = 1/s and C = Q/(1 −PQ), where Q is a proper real-rational function.
Characterize those functions Q for which the feedback system is internally stable.

84
CHAPTER 5. STABILIZATION
5. Suppose that N, M are coprime functions in S. Prove that if NM−1 ∈S, then M−1 ∈S. Is
this true without the coprimeness assumption?
6. The problem is to ﬁnd an internally stabilizing C so that e tends to zero asymptotically when
r is a step and d = 0. When is the problem solvable? Characterize all solutions. (Do not
assume P is stable.)
7. Let
P(s) =
s
(s −1)(10s + 1).
Find a C to achieve internal stability. What are the closed-loop poles? What is the dc gain
from d to y?
8. For formulas (5.4) to (5.7), verify that NX + MY = 1.
9. Consider the feedback system with plant P and controller C.
Assume internal stability.
Consider a coprime factorization of P over S, P = N/M. Suppose that P is perturbed to
P = N + ∆1
M + ∆2
,
where
∆1, ∆2
∈
S,
∥∆1∥∞, ∥∆2∥∞
≤
γ.
Find a bound on γ for robust stability.
10. Compute a stable, stabilizing controller for
P(s) =
(s −1)(s2 + s + 1)
(s −2)(s −3)(s + 1)2 .
11. Study simultaneous stabilization of the cart-pendulum system in the up and down conﬁgura-
tions.
Notes and References
The idea behind Theorem 1 is due to Newton et al. (1957). They observed that while the transfer
function from r to y is nonlinear in C, it is linear in Q, the transfer function from r to u. So
they proposed to design Q to achieve desired performance and then obtain C by back-substitution.
Theorem 1 itself is due to Zames (1981).
The controller parametrization in Theorem 1 is used
in the ﬁeld of process control, where it is called internal model control [because the controller
C = Q/(1 −PQ) contains a model of the plant P] (Morari and Zaﬁriou, 1989).
The original form of Theorem 2 is due independently to Youla et al. (1976) and Kucera (1979).
Its present form is due to Desoer et al. (1980), who saw the advantage of doing coprime factorization
over S instead of the ring of polynomials. This idea in turn is due to Vidyasagar (1972). State-
space formulas for coprime factorization were ﬁrst derived by Khargonekar and Sontag (1982).

5.7. CART-PENDULUM EXAMPLE
85
The formulas in Section 5.3 are from Nett et al. 1984. Section 5.5 is adapted from Francis and
Vidyasagar (1983). The algebraic point of view has been explored in detail by Desoer and co-workers
(e.g., Desoer and Gustafson, 1984) and by Vidyasagar (1985). The notion of strong stabilization
and Theorem 3 are due to Youla et al. (1974). Simultaneous stabilization was ﬁrst treated by
Saeks and Murray (1982). The simple proofs of Theorems 3 and 4 given here are borrowed from
Vidyasagar (1985).
The controller parametrization of Theorem 2 has been exploited in a CAD
method for controller design (Boyd et al., 1988).

86
CHAPTER 5. STABILIZATION

Chapter 6
Design Constraints
Before we see how to design control systems for the robust performance speciﬁcation, it is useful
to determine the basic limitations on achievable performance.
In this chapter we study design
constraints arising from two sources: from algebraic relationships that must hold among various
transfer functions; from the fact that closed-loop transfer functions must be stable (i.e., analytic in
the right half-plane). It is assumed throughout this chapter that the feedback system is internally
stable.
6.1
Algebraic Constraints
There are three items in this section.
1. The identity S + T = 1 always holds. This is an immediate consequence of the deﬁnitions
of S and T. So in particular, |S(jω)| and |T(jω)| cannot both be less than 1/2 at the same
frequency ω.
2. A necessary condition for robust performance is that the weighting functions satisfy
min{|W1(jω)|, |W2(jω)|} < 1,
∀ω.
Proof Fix ω and assume that |W1| ≤|W2| (the argument jω is suppressed). Then
|W1|
=
|W1(S + T)|
≤
|W1S| + |W1T|
≤
|W1S| + |W2T|.
So robust performance (see Theorem 4.2), that is,
∥|W1S| + |W2T|∥∞< 1,
implies that |W1| < 1, and hence
min{|W1|, |W2|} < 1.
The same conclusion can be drawn when |W2| ≤|W1|. ■
87

88
CHAPTER 6. DESIGN CONSTRAINTS
So at every frequency either |W1| or |W2| must be less than 1. Typically, |W1(jω)| is monoton-
ically decreasing—for good tracking of low-frequency signals—and |W2(jω)| is monotonically
increasing—uncertainty increases with increasing frequency.
3. If p is a pole of L in Res ≥0 and z is a zero of L in the same half-plane, then
S(p) = 0,
S(z) = 1,
(6.1)
T(p) = 1,
T(z) = 0.
(6.2)
These interpolation constraints are immediate from the deﬁnitions of S and T. For example,
S(p) =
1
1 + L(p) = 1
∞= 0.
6.2
Analytic Constraints
In this section we derive some constraints concerning achievable performance obtained from analytic
function theory. The ﬁrst subsection presents some mathematical preliminaries.
Preliminaries
We begin with the following fundamental facts concerning complex functions: the maximum mod-
ulus theorem, Cauchy’s theorem, and Cauchy’s integral formula. These are stated here for conve-
nience.
Maximum Modulus Theorem Suppose that Ωis a region (nonempty, open, connected set) in
the complex plane and F is a function that is analytic in Ω. Suppose that F is not equal to a
constant. Then |F| does not attain its maximum value at an interior point of Ω.
A simple application of this theorem, with Ωequal to the open right half-plane, shows that for
F in S
∥F∥∞= sup
Res>0
|F(s)|.
Cauchy’s Theorem Suppose that Ωis a bounded open set with connected complement and D is a
non-self-intersecting closed contour in Ω. If F is analytic in Ω, then
I
D
F(s)ds = 0.
Cauchy’s Integral Formula Suppose that F is analytic on a non-self-intersecting closed contour
D and in its interior Ω. Let s0 be a point in Ω. Then
F(s0) =
1
2πj
I
D
F(s)
s −s0
ds.
We shall also need the Poisson integral formula, which says that the value of a bounded analytic
function at a point in the right half-plane is completely determined by the coordinates of the point
together with the values of the function on the imaginary axis.

6.2. ANALYTIC CONSTRAINTS
89
Lemma 1 Let F be analytic and of bounded magnitude in Res ≥0 and let s0 = σ0 +jω0 be a point
in the complex plane with σ0 > 0. Then
F(s0) = 1
π
Z ∞
−∞
F(jω)
σ0
σ2
0 + (ω −ω0)2 dω.
Proof Construct the Nyquist contour D in the complex plane taking the radius, r, large enough
so that the point s0 is encircled by D.
Cauchy’s integral formula gives
F(s0) =
1
2πj
I
D
F(s)
s −s0
ds.
Also, since −s0 is not encircled by D, Cauchy’s theorem gives
0 =
1
2πj
I
D
F(s)
s + s0
ds.
Subtract these two equations to get
F(s0) =
1
2πj
I
D
F(s)
s0 + s0
(s −s0)(s + s0)ds.
Thus
F(s0) = I1 + I2,
where
I1
:=
1
π
Z r
−r
F(jω)
σ0
(s0 −jω)(s0 + jω)dω
=
1
π
Z r
−r
F(jω)
σ0
σ2
0 + (ω −ω0)2 dω,
I2
:=
1
πj
Z π/2
−π/2
F(rejθ)
σ0
(rejθ −s0)(rejθ + s0)rjejθdθ.
As r →∞
I1 →1
π
Z ∞
−∞
F(jω)
σ0
σ2
0 + (ω −ω0)2 dω.
So it remains to show that I2 →0 as r →∞.
We have
I2 ≤σ0
π ∥F∥∞
1
r
Z π/2
−π/2
1
|ejθ −s0r−1||ejθ + s0r−1|dθ.
The integral
Z π/2
−π/2
1
|ejθ −s0r−1||ejθ + s0r−1|dθ
converges as r →∞. Thus
I2 ≤constant × 1
r ,
which gives the desired result. ■

90
CHAPTER 6. DESIGN CONSTRAINTS
Bounds on the Weights W1 and W2
Suppose that the loop transfer function L has a zero z in Res ≥0. Then
∥W1S∥∞≥|W1(z)|.
(6.3)
This is a direct consequence of the maximum modulus theorem and (6.1):
|W1(z)| = |W1(z)S(z)| ≤sup
Res≥0
|W1(s)S(s)| = ∥W1S∥∞.
So a necessary condition that the performance criterion ∥W1S∥∞< 1 be achievable is that the
weight satisfy |W1(z)| < 1. In words, the magnitude of the weight at a right half-plane zero of P or
C must be less than 1.
Similarly, suppose that L has a pole p in Res ≥0. Then
∥W2T∥∞≥|W2(p)|,
(6.4)
so a necessary condition for the robust stability criterion ∥W2T∥∞< 1 is that the weight W2 satisfy
|W2(p)| < 1.
All-Pass and Minimum-Phase Transfer Functions
Two types of transfer functions play a critical role in the rest of this book: all-pass and minimum-
phase. A function in S is all-pass if its magnitude equals 1 at all points on the imaginary axis.
The terminology comes from the fact that a ﬁlter with an all-pass transfer function passes without
attenuation input sinusoids of all frequencies. It is not diﬃcult to show that such a function has
pole-zero symmetry about the imaginary axis in the sense that a point s0 is a zero iﬀits reﬂection,
−s0, is a pole. Consequently, the function being stable, all its zeros lie in the right half-plane. Thus
an all-pass function is, up to sign, the product of factors of the form
s −s0
s + s0
,
Res0 > 0.
Examples of all-pass functions are
1,
s −1
s + 1,
s2 −s + 2
s2 + s + 2.
A function in S is minimum-phase if it has no zeros in Res > 0. This terminology can be
explained as follows. Let G be a minimum-phase transfer function. There are many other transfer
functions having the same magnitude as G, for example FG where F is all-pass. But all these other
transfer functions have greater phase. Thus, of all the transfer functions having Gs magnitude, the
one with the minimum phase is G. Examples of minimum-phase functions are
1,
1
s + 1,
s
s + 1,
s + 2
s2 + s + 1.
It is a useful fact that every function in S can be written as the product of two such factors: for
example
4(s −2)
s2 + s + 1 =
s −2
s + 2
  4(s + 2)
s2 + s + 1

.

6.2. ANALYTIC CONSTRAINTS
91
Lemma 2 For each function G in S there exist an all-pass function Gap and a minimum-phase
function Gmp such that G = GapGmp. The factors are unique up to sign.
Proof Let Gap be the product of all factors of the form
s −s0
s + s0
,
where s0 ranges over all zeros of G in Res > 0, counting multiplicities, and then deﬁne
Gmp =
G
Gap
.
The proof of uniqueness is left as an exercise. ■
For technical reasons we assume for the remainder of this section that L has no poles on the
imaginary axis. Factor the sensitivity function as
S = SapSmp.
Then Smp has no zeros on the imaginary axis (such zeros would be poles of L) and Smp is not
strictly proper (since S is not). Thus S−1
mp ∈S.
As a simple example of the use of all-pass functions, suppose that P has a zero at z with z > 0, a
pole at p with p > 0; also, suppose that C has neither poles nor zeros in the closed right half-plane.
Then
Sap(s) = s −p
s + p,
Tap(s) = s −z
s + z .
It follows from the preceding section that S(z) = 1, and hence
Smp(z) = Sap(z)−1 = z + p
z −p.
Similarly,
Tmp(p) = Tap(p)−1 = p + z
p −z .
Then
∥W1S∥∞= ∥W1Smp∥∞≥|W1(z)Smp(z)| =
W1(z)z + p
z −p

and
∥W2T∥∞≥
W2(p)p + z
p −z
 .
Thus, if there are a pole and zero close to each other in the right half-plane, they can greatly amplify
the eﬀect that either would have alone.

92
CHAPTER 6. DESIGN CONSTRAINTS
Example
These inequalities are eﬀectively illustrated with the cart-pendulum example of Sec-
tion 5.7. Let P(s) be the u-to-x transfer function for the up position of the pendulum, that is,
P(s) =
ls2 −g
s2[Mls2 −(M + m)g].
Deﬁne the ratio r := m/M of pendulum mass to cart mass. The zero and pole of P in Res > 0 are
z =
rg
l ,
p = z
√
1 + r.
Note that for r ﬁxed, a larger value of l means a smaller value of p, and this in turn means that
the system is easier to stabilize (the time constant is slower). The foregoing two inequalities on
∥W1S∥∞and ∥W2T∥∞apply. Since the cart-pendulum is a stabilization task, let us focus on
∥W2T∥∞≥
W2(p)p + z
p −z
 .
(6.5)
The robust stabilization problem becomes harder the larger the value of the right-hand side of
(6.5). The scaling factor in this inequality is
p + z
p −z =
√1 + r + 1
√1 + r −1.
(6.6)
This quantity is always greater than 1, and it approaches 1 only when r approaches ∞, that is, only
when the pendulum mass is much larger than the cart mass. There is a tradeoﬀ, however, in that a
large value of r means a large value of p, the unstable pole; for a typical W2 (high-pass) this in turn
means a relatively large value of |W2(p)| in (6.5). So at least for small uncertainty, the worst-case
scenario is a short pendulum with a small mass m relative to the cart mass M.
In contrast, the u-to-y transfer function has no zeros, so the constraint there is simply
∥W2T∥∞≥|W2(p)| .
If robust stabilization were the only objective, we could achieve equality by careful selection of
the controller. Note that for this case there is no apparent tradeoﬀin making m/M large. The
diﬀerence between the two cases, measuring x and measuring y, again highlights the important fact
that sensor location can have a signiﬁcant eﬀect on the diﬃculty of controlling a system or on the
ultimate achievable performance.
Some simple experiments can be done to illustrate the points made in this example. Obtain
several sticks of various lengths and try to balance them in the palm of your hand. You will notice
that it is easier to balance longer sticks, because the dynamics are slower and p above is smaller. It
is also easier to balance the sticks if you look at the top of the stick (measuring y) rather than at
the bottom (measuring x). In fact, even for a stick that is easily balanced when looking at the top,
it will be impossible to balance it while looking only at the bottom. There is also feedback from
the forces that your hand feels, but this is similar to measuring x.
The interested reader may repeat the analysis for the down position of the pendulum. At this
point it is useful to include the following lemma which will be used subsequently.

6.2. ANALYTIC CONSTRAINTS
93
Lemma 3 For every point s0 = σ0 + jω0 with σ0 > 0,
log |Smp(s0)| = 1
π
Z ∞
−∞
log |S(jω)|
σ0
σ2
0 + (ω −ω0)2 dω.
Proof Set F(s) := ln Smp(s). Then F is analytic and of bounded magnitude in Res ≥0. (This
follows from the properties Smp, S−1
mp ∈S; the idea is that since Smp has no poles or zeros in the
right half-plane, ln Smp is well-behaved there.) Apply Lemma 1 to get
F(s0) = 1
π
Z ∞
−∞
F(jω)
σ0
σ2
0 + (ω −ω0)2 dω.
Now take real parts of both sides:
ReF(s0) = 1
π
Z ∞
−∞
ReF(jω)
σ0
σ2
0 + (ω −ω0)2 dω.
(6.7)
But
Smp = eF = eReFejImF ,
so
|Smp| = eReF ,
that is,
ln |Smp| = ReF.
Thus from (6.7)
ln |Smp(s0)| = 1
π
Z ∞
−∞
ln |Smp(jω)|
σ0
σ2
0 + (ω −ω0)2 dω,
or since |S| = |Smp| on the imaginary axis,
ln |Smp(s0)| = 1
π
Z ∞
−∞
ln |S(jω)|
σ0
σ2
0 + (ω −ω0)2 dω.
Finally, since log x = log e ln x, the result follows upon multiplying the last equation by log e. ■
The Waterbed Eﬀect
Consider a tracking problem where the reference signals have their energy spectra concentrated in
a known frequency range, say [ω1, ω2]. This is the idealized situation where W1 is a bandpass ﬁlter.
Let M1 denote the maximum magnitude of S on this frequency band,
M1 :=
max
ω1≤ω≤ω2 |S(jω)|,
and let M2 denote the maximum magnitude over all frequencies, that is, ∥S∥∞. Then good tracking
capability is characterized by the inequality M1 ≪1. On the other hand, we cannot permit M2

94
CHAPTER 6. DESIGN CONSTRAINTS
to be too large: Remember (Section 4.2) that 1/M2 equals the distance from the critical point to
the Nyquist plot of L, so large M2 means small stability margin (a typical upper bound for M2
is 2). Notice that M2 must be at least 1 because this is the value of S at inﬁnite frequency. So
the question arises: Can we have M1 very small and M2 not too large? Or does it happen that
very small M1 necessarily means very large M2?
The latter situation might be compared to a
waterbed: As |S| is pushed down on one frequency range, it pops up somewhere else. It turns out
that non-minimum-phase plants exhibit the waterbed eﬀect.
Theorem 1 Suppose that P has a zero at z with Rez > 0. Then there exist positive constants c1
and c2, depending only on ω1, ω2, and z, such that
c1 log M1 + c2 log M2 ≥log |Sap(z)−1| ≥0.
Proof
Since z is a zero of P, it follows from the preceding section that S(z) = 1, and hence
Smp(z) = Sap(z)−1. Apply Lemma 3 with
s0 = z = σ0 + jω0
to get
log |Sap(z)−1| = 1
π
Z ∞
−∞
log |S(jω)|
σ0
σ2
0 + (ω −ω0)2 dω.
Thus
log |Sap(z)−1| ≤c1 log M1 + c2 log M2,
where c1 is deﬁned to be the integral of
1
π
σ0
σ2
0 + (ω −ω0)2
over the set
[−ω2, −ω1] ∪[ω1, ω2]
and c2 equals the same integral but over the complementary set.
It remains to observe that |Sap(z)| ≤1 by the maximum modulus theorem, so
log |Sap(z)−1| ≥0. ■
Example As an illustration of the theorem consider the plant transfer function
P(s) =
s −1
(s + 1)(s −p),
where p > 0, p ̸= 1. As observed in the preceding section, S must interpolate zero at the unstable
poles of P, so S(p) = 0. Thus the all-pass factor of S must contain the factor
s −p
s + p.

6.2. ANALYTIC CONSTRAINTS
95
that is,
Sap(s) = s −p
s + pG(s)
for some all-pass function G. Since |G(1)| ≤1 (maximum modulus theorem), there follows
|Sap(1)| ≤

1 −p
1 + p
 .
So the theorem gives
c1 log M1 + c2 log M2 ≥log

1 + p
1 −p
 .
Note that the right-hand side is very large if p is close to 1. This example illustrates again a general
fact: The waterbed eﬀect is ampliﬁed if the plant has a pole and a zero close together in the right
half-plane. We would expect such a plant to be very diﬃcult to control.
It is emphasized that the waterbed eﬀect applies to non-minimum-phase plants only. In fact,
the following can be proved (Section 10.1): If P has no zeros in Res > 0 nor on the imaginary axis
in the frequency range [ω1, ω2], then for every ǫ > 0 and δ > 1 there exists a controller C so that
the feedback system is internally stable, M1 < ǫ, and M2 < δ. As a very easy example, take
P(s) =
1
s + 1.
The controller C(s) = k is internally stabilizing for all k > 0, and then
S(s) =
s + 1
s + 1 + k.
So ∥S∥∞= 1 and, for every ǫ > 0 and ω2, if k is large enough, then
|S(jω)| < ǫ,
∀ω ≤ω2.
The Area Formula
Herein is derived a formula for the area bounded by the graph of |S(jω)| (log scale) plotted as a
function of ω (linear scale). The formula is valid when the relative degree of L is large enough.
Relative degree equals degree of denominator minus degree of numerator.
Let {pi} denote the set of poles of L in Res > 0.
Theorem 2 Assume that the relative degree of L is at least 2. Then
Z ∞
0
log |S(jω)|dω = π(log e)(
X
Repi).
Proof In Lemma 3 take ω0 = 0 to get
log |Smp(σ0)| = 1
π
Z ∞
−∞
log |S(jω)|
σ0
σ2
0 + ω2 dω,

96
CHAPTER 6. DESIGN CONSTRAINTS
or equivalently,
Z ∞
0
log |S(jω)|
σ0
σ2
0 + ω2 dω = π
2 log |Smp(σ0)|.
Multiply by σ0:
Z ∞
0
log |S(jω)|
σ2
0
σ2
0 + ω2 dω = π
2 σ0 log |Smp(σ0)|.
It can be shown that the left-hand side converges to
Z ∞
0
log |S(jω)|dω
as σ0 →∞. [The idea is that for very large σ0 the function
σ2
0
σ2
0 + ω2
equals nearly 1 up to large values of ω. On the other hand, log |S(jω)| tends to zero as ω tends to
∞.] So it remains to show that
lim
σ→∞
σ
2 log |Smp(σ)| = (log e)(
X
Repi).
(6.8)
We can write
S = SapSmp,
where
Sap(s) =
Y
i
s −pi
s + pi
.
It is claimed that
lim
σ→∞σ ln S(σ) = 0.
To see this, note that since L has relative degree at least 2 we can write
L(σ) ≈c
σk as σ →∞
for some constant c and some integer k ≥2. Thus as σ →∞
σ ln S(σ) = −σ ln[1 + L(σ)] ≈−σ ln

1 + c
σk

.
Now use the Maclaurin’s series
ln(1 + x) = x −x2
2 + · · ·
(6.9)

6.2. ANALYTIC CONSTRAINTS
97
to get
σ ln S(σ) ≈−σ
 c
σk −· · ·

.
The right-hand side converges to zero as σ tends to ∞. This proves the claim.
In view of the claim, to prove (6.8) it remains to show that
lim
σ→∞
σ
2 ln
[Sap(σ)−1]
 =
X
Repi.
(6.10)
Now
ln(Sap(σ)−1) = ln
Y
i
σ + pi
σ −pi
=
X
i
ln σ + pi
σ −pi
,
so to prove (6.10) it suﬃces to prove
lim
σ→∞
σ
2 ln

σ + pi
σ −pi
 = Repi.
(6.11)
Let pi = x + jy and use (6.9) again as follows:
σ
2 ln

σ + pi
σ −pi

=
σ
2 ln

1 + piσ−1
1 −piσ−1

=
σ
4 ln (1 + xσ−1)2 + (yσ−1)2
(1 −xσ−1)2 + (yσ−1)2
=
σ
4

ln[(1 + xσ−1)2 + (yσ−1)2] −ln[(1 −xσ−1)2 + (yσ−1)2]
	
=
σ
4
n
2x
σ + 2x
σ + · · ·
o
=
x + · · ·
=
Repi + · · · .
Letting σ →∞gives (6.11). ■
Example Take the plant and controller
P(s) =
1
(s −1)(s + 2),
C(s) = 10.
The feedback system is internally stable and L has relative degree 2. The plot of |S(jω)|, log scale,
versus ω, linear scale, is shown in Figure 6.1.
The area below the line |S| = 1 is negative, the area
above, positive. The theorem says that the net area is positive, equaling
π(log e)(
X
Repi) = π(log e).
So the negative area, required for good tracking over some frequency range, must unavoidably be
accompanied by some positive area.
The waterbed eﬀect applies to non-minimum-phase systems, whereas the area formula applies
in general (except for the relative degree assumption). In particular, the area formula does not

98
CHAPTER 6. DESIGN CONSTRAINTS
10-1
100
101
0
1
2
3
4
5
6
7
8
9
10
+
-
Figure 6.1: |S(jω)|, log scale, versus ω, linear scale.
itself imply a peaking phenomenon, only an area conservation. However, one can infer a type of
peaking phenomenon from the area formula when another constraint is imposed, namely, controller
bandwidth, or more precisely, the bandwidth of the loop transfer function PC. For example, suppose
that the constraint is
|PC| < 1
ω2 ,
∀ω ≥ω1,
where ω1 > 1. This is one way of saying that the loop bandwidth is constrained to be ≤ω1. Then
for ω ≥ω1
|S| ≤
1
1 −|PC| <
1
1 −ω−2 =
ω2
ω2 −1.
Hence
Z ∞
ω1
log |S(jω)|dω ≤
Z ∞
ω1
log
ω2
ω2 −1dω.

6.2. ANALYTIC CONSTRAINTS
99
The latter integral—denote it by I—is ﬁnite. This is proved by the following computation:
I
=
1
ln 10
Z ∞
ω1
ln
1
1 −ω−2 dω
=
−
1
ln 10
Z ∞
ω1
ln(1 −ω−2)dω
=
1
ln 10
Z ∞
ω1

ω−2 + 1
2ω−4 + 1
3ω−6 + · · ·

dω
=
1
ln 10

ω−1
1
+
1
2 × 3ω−3
1
+
1
3 × 5ω−5
1
+ · · ·

<
∞.
Hence the possible positive area over the interval [ω1, ∞) is limited. Thus if |S| is made smaller and
smaller over some subinterval of [0, ω1], incurring a larger and larger debt of negative area, then |S|
must necessarily become larger and larger somewhere else in [0, ω1]. Roughly speaking, with a loop
bandwidth constraint the waterbed eﬀect applies even to minimum-phase plants.
Exercises
1. Prove the statement about uniqueness in Lemma 2.
2. True or false: For every δ > 1 there exists an internally stabilizing controller such that
∥T∥∞< δ.
3. Regarding inequality (6.3), the implication is that good tracking is impossible if P has a right
half-plane zero where |W1| is not small. This problem is an attempt to see this phenomenon
more precisely by studying |W1(z)| as a function of z for a typical weighting function. Take
W1 to be a third-order Butterworth ﬁlter with cutoﬀfrequency 1 rad/s. Plot
|W1(0.1 + jω)| versus ω
for ω going from 0 up to where |W1| < 0.01. Repeat for abscissae of 1 and 10.
4. Let
P(s) = 4 s −2
(s + 1)2 .
Suppose that C is an internally stabilizing controller such that
∥S∥∞= 1.5.
Give a positive lower bound for
max
0≤ω≤0.1 |S(jω)|.
5. Deﬁne ǫ := ∥W1S∥∞and δ := ∥CS∥∞. So ǫ is a measure of tracking performance, while
δ measures control eﬀort; note that CS equals the transfer function from reference input r

100
CHAPTER 6. DESIGN CONSTRAINTS
to plant input. In a design we would like ǫ < 1 and δ not too large. Derive the following
inequality, showing that ǫ and δ cannot both be very small in general: For every point s0 with
Res0 ≥0,
|W1(s0)| ≤ǫ + |W1(s0)P(s0)|δ.
6. Let ω be a frequency such that jω is not a pole of P. Suppose that
ǫ := |S(jω)| < 1.
Derive a lower bound for |C(jω)| that blows up as ǫ →0. Conclusion: Good tracking at a
particular frequency requires large controller gain at this frequency.
7. Suppose that the plant transfer function is
P(s) =
1
s2 −s + 4.
We want the controller C to achieve the following:
internal stability,
|S(jω)| ≤ǫ for 0 ≤ω < 0.1,
|S(jω)| ≤2 for 0.1 ≤ω < 5,
|S(jω)| ≤1 for 5 ≤ω < ∞.
Find a (positive) lower bound on the achievable ǫ.
Notes and References
This chapter is in the spirit of Bode’s book (Bode, 1945) on feedback ampliﬁers. Bode showed
that electronic ampliﬁers must have certain inherent properties simply by virtue of the fact that
stable network functions are analytic, and hence have certain strong properties. Bode’s work was
generalized to control systems by Bower and Schultheiss (1961) and Horowitz (1963).
The interpolation conditions (6.1) and (6.2) were obtained by Raggazini and Franklin (1958).
These constraints on S and T are essentially equivalent to the controller parametrization in Theo-
rem 5.2. Inequality (6.3) was noted, for example, by Zames and Francis (1983). The waterbed eﬀect,
Theorem 1, was proved by Francis and Zames (1984), but the derivation here is due to Freudenberg
and Looze (1985). The area formula, Theorem 2, was proved by Bode (1945) in case L is stable,
and by Freudenberg and Looze (1985) in the general case. An excellent discussion of performance
limitations may be found in Freudenberg and Looze (1988).

Chapter 7
Loopshaping
This chapter presents a graphical technique for designing a controller to achieve robust performance
for a plant that is stable and minimum-phase.
7.1
The Basic Technique of Loopshaping
Recall from Section 4.3 that the robust performance problem is to design a proper controller C so
that the feedback system for the nominal plant is internally stable and the inequality
∥|W1S| + |W2T|∥∞< 1
(7.1)
is satisﬁed. Thus the problem input data are P, W1, and W2; a solution of the problem is a controller
C achieving robust performance.
We saw in Chapter 6 that the robust performance problem is not always solvable—the tracking
objective may be too stringent for the nominal plant and its associated uncertainty model. Un-
fortunately, constructive (necessary and suﬃcient) conditions on P, W1, and W2 for the robust
performance problem to be solvable are unknown.
In this chapter we look at a graphical method that is likely to provide a solution when one exists.
The idea is to construct the loop transfer function L to achieve (7.1) approximately, and then to get
C via C = L/P. The underlying constraints are internal stability of the nominal feedback system
and properness of C, so that L is not freely assignable. When P or P −1 is not stable, L must
contain P’s unstable poles and zeros (Theorem 3.2), an awkward constraint. For this reason, we
assume in this chapter that P and P −1 are both stable.
In terms of W1, W2, and L the robust performance inequality is
Γ(jω) :=

W1(jω)
1 + L(jω)
 +

W2(jω)L(jω)
1 + L(jω)
 < 1.
(7.2)
This must hold for all ω. The idea in loopshaping is to get conditions on L for (7.2) to hold, at
least approximately. It is convenient to drop the argument jω.
We are interested in alternative conditions under which (7.2) holds. Recall from Section 6.1 that
a necessary condition is
min{|W1|, |W2|} < 1,
101

102
CHAPTER 7. LOOPSHAPING
so we will assume this throughout. Thus at each frequency, either |W1| < 1 or |W2| < 1. We will
consider these two cases separately and derive conditions comparable to (7.2).
We begin by noting the following inequalities, which follow from the deﬁnition of Γ:
(|W1| −|W2|)|S| + |W2| ≤Γ ≤(|W1| + |W2|)|S| + |W2|,
(7.3)
(|W2| −|W1|)|T| + |W1| ≤Γ ≤(|W2| + |W1|)|T| + |W1|,
(7.4)
|W1| + |W2L|
1 + |L|
≤Γ ≤|W1| + |W2L|
|1 −|L||
.
(7.5)
• Suppose that |W2| < 1. Then from (7.3)
Γ < 1
⇐=
|W1| + |W2|
1 −|W2|
|S| < 1,
(7.6)
Γ < 1
=⇒
|W1| −|W2|
1 −|W2|
|S| < 1.
(7.7)
Or, in terms of L, from (7.5)
Γ < 1
⇐=
|L| > |W1| + 1
1 −|W2|,
(7.8)
Γ < 1
=⇒
|L| > |W1| −1
1 −|W2|.
(7.9)
When |W1| ≫1, the conditions on the right-hand sides of (7.6) and (7.7) approach each other,
as do those in (7.8) and (7.9), and we may approximate the condition Γ < 1 by
|W1|
1 −|W2||S| < 1
(7.10)
or
|L| >
|W1|
1 −|W2|.
(7.11)
Notice that (7.10) is like the nominal performance condition |W1S| < 1 except that the
weight W1 is increased by dividing it by 1−|W2|: Robust performance is achieved by nominal
performance with a larger weight.
• Now suppose that |W1| < 1. We may proceed similarly to obtain from (7.4)
Γ < 1
⇐=
|W2| + |W1|
1 −|W1|
|T| < 1,
Γ < 1
=⇒
|W2| −|W1|
1 −|W1|
|T| < 1

7.1. THE BASIC TECHNIQUE OF LOOPSHAPING
103
or from (7.5)
Γ < 1
⇐=
|L| < 1 −|W1|
|W2| + 1,
Γ < 1
=⇒
|L| < 1 −|W1|
|W2| −1.
When |W2| ≫1, we may approximate the condition Γ < 1 by
|W2|
1 −|W1||T| < 1
(7.12)
or
|L| < 1 −|W1|
|W2|
.
(7.13)
Inequality (7.12) says that robust performance is achieved by robust stability with a larger
weight.
The discussion above is summarized as follows:
|W1| ≫1 > |W2|
|L| >
|W1|
1 −|W2|
|W1| < 1 ≪|W2|
|L| < 1 −|W1|
|W2|
For example, the ﬁrst row says that over frequencies where |W1| ≫1 > |W2| the loopshape should
satisfy
|L| >
|W1|
1 −|W2|.
Let’s take the typical situation where |W1(jω)| is a decreasing function of ω and |W2(jω)| is an
increasing function of ω. Typically, at low frequency
|W1| > 1 > |W2|
and at high frequency
|W1| < 1 < |W2|.
A loopshaping design goes very roughly like this:
1. Plot two curves on log-log scale, magnitude versus frequency: ﬁrst, the graph of
|W1|
1 −|W2|
over the low-frequency range where |W1| > 1 > |W2|; second, the graph of
1 −|W1|
|W2|
over the high-frequency range where |W1| < 1 < |W2|.

104
CHAPTER 7. LOOPSHAPING
2. On this plot ﬁt another curve which is going to be the graph of |L|: At low frequency let it lie
above the ﬁrst curve and also be ≫1; at high frequency let it lie below the second curve and
also be ≪1; at very high frequency let it roll oﬀat least as fast as does |P| (so C is proper);
do a smooth transition from low to high frequency, keeping the slope as gentle as possible
near crossover, the frequency where the magnitude equals 1 (the reason for this is described
below).
3. Get a stable, minimum-phase transfer function L whose Bode magnitude plot is the curve just
constructed, normalizing so that L(0) > 0.
Typical curves are as in Figure 7.1.
Such a curve for |L| will satisfy (7.11) and (7.13), and hence
10-3
10-2
10-1
100
101
102
103
10-2
10-1
100
101
102
103
104
Figure 7.1: Bode plots of |L| (solid), |W1|/(1 −|W2|) (dash), and (1 −|W1|)/|W2| (dot).
(7.2) at low and high frequencies. But (7.2) will not necessarily hold at intermediate frequencies.
Even worse, L may not result in nominal internal stability. If L(0) > 0 and |L| is as just pictured
(i.e., a decreasing function), then the angle of L starts out at zero and decreases (this follows from
the phase formula to be derived in the next section). So the Nyquist plot of L starts out on the
positive real axis and begins to move clockwise. By the Nyquist criterion, nominal internal stability
will hold iﬀthe angle of L at crossover is greater than 180◦(i.e., crossover occurs in the third or
fourth quadrant). But the greater the slope of |L| near crossover, the smaller the angle of L (proved
in the next section).
So internal instability is unavoidable if |L| drops oﬀtoo rapidly through
crossover, and hence in our loopshaping we must maintain a gentle slope; a rule of thumb is that
the magnitude of the slope should not be more than 2. After doing the three steps above we must
validate the design by checking that internal stability and (7.2) both hold. If not, we must go back
and try again. Loopshaping therefore is a craft requiring experience for mastery.

7.2. THE PHASE FORMULA (OPTIONAL)
105
7.2
The Phase Formula (Optional)
It is a fundamental fact that if L is stable and minimum-phase and normalized so that L(0) > 0,
then its magnitude Bode plot uniquely determines its phase plot. The normalization is necessary,
for
1
s + 1 and
−1
s + 1
are stable, minimum-phase, and have the same magnitude plot, but they have diﬀerent phase plots.
Our goal in this section is a formula for ∠L in terms of |L|.
Assume that L is proper, L and L−1 are analytic in Res ≥0, and L(0) > 0. Deﬁne G := ln L.
Then
ReG = ln |L|,
ImG = ∠L,
and G has the following three properties:
1. G is analytic in some right half-plane containing the imaginary axis. Instead of a formal proof,
one way to see why this is true is to look at the derivative of G:
G′ = L′
L .
Since L is analytic in the right half-plane, so is L′. Then since L has no zeros in the right
half-plane, G′ exists at all points in the right half-plane, and hence at points a bit to the left
of the imaginary axis.
2. ReG(jω) is an even function of ω and ImG(jω) is an odd function of ω.
3. s−1G(s) tends to zero uniformly on semicircles in the right half-plane as the radius tends to
inﬁnity, that is,
lim
R→∞
sup
−π/2≤θ≤π/2

G(Rejθ)
Rejθ
 = 0.
Proof Since
G(Rejθ) = ln |L(Rejθ)| + j∠L(Rejθ)
and ∠L(Rejθ) is bounded as R →∞, we have

G(Rejθ)
Rejθ
 →| ln |L(Rejθ)||
R
.
Now L is proper, so for some c and k ≥0,
L(s) ≈c
sk as |s| →∞.

106
CHAPTER 7. LOOPSHAPING
Thus

G(Rejθ)
Rejθ

→
| ln |c/Rk||
R
=
| ln |c| −k ln |R||
R
→
kln R
R
→
0. ■
Next, we obtain an expression for the imaginary part of G in terms of its real part.
Lemma 1 For each frequency ω0
Im G(jω0) = 2ω0
π
Z ∞
0
ReG(jω) −ReG(jω0)
ω2 −ω2
0
dω.
Proof Deﬁne the function
F(s)
:=
G(s) −ReG(jω0)
s −jω0
−G(s) −ReG(jω0)
s + jω0
=
2jω0
G(s) −ReG(jω0)
s2 + ω2
0
.
(7.14)
Then F is analytic in the right half-plane and on the imaginary axis, except for poles at ±jω0.
Bring in the usual Nyquist contour: Go up the imaginary axis, indenting to the right at the points
−jω0 and jω0 along semicircles of radius r, then close the contour by a large semicircle of radius
R in the right half-plane. The integral of F around this contour equals zero (Cauchy’s theorem).
This integral equals the sum of six separate integrals corresponding to the three intervals on the
imaginary axis, the two smaller semicircles, and the larger semicircle. Let I1 denote the sum of
the three integrals along the intervals on the imaginary axis, I2 the integral around the lower small
semicircle, I3 around the upper small semicircle, and I4 around the large semicircle. We show that
lim
R→∞,r→0 I1
=
2ω0
Z ∞
−∞
ReG(jω) −ReG(jω0)
ω2 −ω2
0
dω,
(7.15)
lim
r→0 I2
=
−πIm G(jω0),
(7.16)
lim
r→0 I3
=
−πIm G(jω0),
(7.17)
lim
R→∞I4
=
0.
(7.18)
The lemma follows immediately from these four equations and the fact that ReG(jω) is even.
First,
I1 =
Z
jF(jω)dω,
where the integral is over the set
[−R, −ω0 −r] ∪[−ω0 + r, ω0 −r] ∪[ω0 + r, R].
(7.19)

7.2. THE PHASE FORMULA (OPTIONAL)
107
As R →∞and r →0, this set becomes the interval (−∞, ∞). Also, from (7.14)
jF(jω) = 2ω0
G(jω) −ReG(jω0)
ω2 −ω2
0
.
Since
Im G(jω)
ω2 −ω2
0
is an odd function, its integral over set (7.19) equals zero, and we therefore get (7.15).
Second,
I2
=
Z π/2
−π/2
G(−jω0 + rejθ) −ReG(jω0)
−jω0 + rejθ −jω0
jrejθdθ
−
Z π/2
−π/2
G(−jω0 + rejθ) −ReG(jω0)
−jω0 + rejθ + jω0
jrejθdθ.
As r →0, the ﬁrst integral tends to 0 while the second tends to
[G(−jω0) −ReG(jω0)]j
Z π/2
−π/2
dθ = πIm G(jω0).
This proves (7.16). Veriﬁcation of (7.17) is similar.
Finally,
I4 = −
Z π/2
−π/2
F(Rejθ)jRejθdθ,
so
|I4| ≤
sup
−π
2 ≤θ ≤π
2

2ω0[G(Rejθ) −ReG(jω0)]
(Rejθ)2 + ω2
0
 Rπ.
Thus
|I4| →(const) sup
θ
|G(Rejθ)|
R
→0.
This proves (7.18). ■
Rewriting the formula in the lemma in terms of L we get
∠L(jω0) = 2ω0
π
Z ∞
0
ln |L(jω)| −ln |L(jω0)|
ω2 −ω2
0
dω.
(7.20)
This is now manipulated to get the phase formula.
Theorem 1 For every frequency ω0
∠L(jω0) = 1
π
Z ∞
−∞
d ln |L|
dν
ln coth |ν|
2 dν,
where the integration variable ν = ln(ω/ω0).

108
CHAPTER 7. LOOPSHAPING
Proof Change variables of integration in (7.20) to get
∠L(jω0) = 1
π
Z ∞
−∞
ln |L| −ln |L(jω0)|
sinh ν
dν.
Note that in this integral ln |L| is really ln |L(jω0eν)| considered as a function of ν. Now integrate
by parts, from −∞to 0 and from 0 to ∞:
∠L(jω0)
=
−1
π
h
(ln |L| −ln |L(jω0)|) ln coth ν
2
i∞
0
+ 1
π
Z ∞
0
d ln |L|
dν
ln coth ν
2dν
+ 1
π[(ln |L| −ln |L(jω0)|) ln coth −ν
2 ]∞
0
+ 1
π
Z 0
−∞
d ln |L|
dν
ln coth −ν
2 dν.
The ﬁrst and third terms sum to zero. ■
Example Suppose that ln |L| has constant slope,
d ln |L|
dν
= −c.
Then
∠L(jω0) = −c
π
Z ∞
−∞
ln coth |ν|
2 dν = −cπ
2 ;
that is, the phase shift is constant at −90c degrees.
In the phase formula, the slope function d ln |L|/dν is weighted by the function
ln coth |ν|
2 = ln

ω + ω0
ω −ω0
 .
This function is symmetric about ω = ω0 (ln scale on the horizontal axis), positive, inﬁnite at
ω = ω0, increasing from ω = 0 to ω = ω0, and decreasing from ω = ω0 to ω = ∞. In this way, the
values of d ln |L|/dν are more heavily weighted near ω = ω0. We conclude, roughly speaking, that
the steeper the graph of |L| near the frequency ω0, the smaller the value of ∠L.
7.3
Examples
This section presents three simple examples of loopshaping.
Example 1 In principle the only information we need to know about P right now is its relative
degree, degree of denominator minus degree of numerator. This determines the high-frequency slope
on its Bode magnitude plot. We have to let L have at least equal relative degree or else C will not
be proper. Assume that the relative degree of P equals 1. The actual plant transfer function enters
into the picture only at the very end when we get C from L via C = L/P.

7.3. EXAMPLES
109
Take the weighting function W2 to be
W2(s) =
s + 1
20(0.01s + 1).
See Figure 7.2 for the Bode magnitude plot. Remember (Section 4.2) that |W2(jω)| is an upper
bound on the magnitude of the relative plant perturbation at frequency ω. For this example, |W2|
starts at 0.05 and increases monotonically up to 5, crossing 1 at 20 rad/s.
Let the performance objective be to track sinusoidal reference signals over the frequency range
from 0 to 1 rad/s. Let’s not say at the start what maximum tracking error we will tolerate; rather,
let’s see what tracking error is incurred for a couple of loopshapes. Ideally, we would take W1
to have constant magnitude over the frequency range [0, 1] and zero magnitude beyond. Such a
magnitude characteristic cannot come from a rational function. Nevertheless, you can check that
Theorem 4.2 continues to be valid for such W1; that is, if the nominal feedback system is internally
stable, then
∥W2T∥∞< 1 and

W1S
1 + ∆W2T

∞
< 1,
∀∆
iﬀ
∥|W1S| + |W2T|∥∞< 1.
With this justiﬁcation, we can take
|W1(jω)| =
 a,
if 0 ≤ω ≤1
0,
else,
where a is as yet unspeciﬁed.
Let’s ﬁrst try a ﬁrst-order, low-pass loop transfer function, that is, of the form
L(s) =
b
cs + 1.
It is reasonable to take c = 1 so that |L| starts rolling oﬀnear the upper end of the operating band
[0, 1]. We want b as large as possible for good tracking. The largest value of b so that
|L| ≤1 −|W1|
|W2|
=
1
|W2|,
ω ≥20
is 20. So we have
L(s) =
20
s + 1.
See Figure 7.2. For this L the nominal feedback system is internally stable.
It remains to check what robust performance level we have achieved. For this we choose the
largest value of a so that
|L| ≥
a
1 −|W2|,
ω ≤1.

110
CHAPTER 7. LOOPSHAPING
The function
a
1 −|W2(jω)|
is increasing over the range [0, 1], while |L(jω)| is decreasing. So a can be got by solving
|L(j1)| =
a
1 −|W2(j1)|.
This gives a = 13.15.
Now to verify robust performance, graph the function
|W1(jω)S(jω)| + |W2(jω)T(jω)|
(Figure 7.2).
Its maximum value is about 0.92.
Since this is less than 1, robust performance
is veriﬁed. (We could also have determined as in Section 4.3 the largest a for which the robust
performance condition holds.)
Let’s recap. For the performance weight
|W1(jω)| =
 13.15,
if 0 ≤ω ≤1
0,
else,
we can take L(s) = 20/(s+1) to achieve robust performance. The tracking error is then ≤1/13.15 =
7.6%.
10-2
10-1
100
101
102
10-2
10-1
100
101
102
103
Figure 7.2: Bode plots of |L| (solid), |W2| (dash), and |W1S| + |W2T| (dot).
Suppose that a 7.6% tracking error is too large. To reduce the error make |L| larger over the
frequency range [0, 1]. For example, we could try
L(s) = s + 10
s + 1
20
s + 1.

7.3. EXAMPLES
111
The new factor, (s + 10)/(s + 1), has magnitude nearly 10 over [0, 1] and rolls oﬀto about 1 above
10 rad/s. See Figure 7.3. Again, the nominal feedback system is internally stable. If we take W1
as before and compute a again we get a = 93.46. The robust performance inequality is checked
graphically (Figure 7.3). Now the tracking error is ≤1/93.46 = 1.07%.
10-2
10-1
100
101
102
103
10-2
10-1
100
101
102
103
Figure 7.3: Bode plots of |L| (solid), |W2| (dash), and |W1S| + |W2T| (dot).
The problem above is quite easy because |W2| is small on the operating band [0, 1]; the require-
ments of performance and robust stability are only weakly competitive.
Example 2 This example examines the pitch rate control of an aircraft. The signals are
r pitch rate command (by pilot)
u elevator deﬂection
y pitch rate of the aircraft
Suppose that the ﬁrst approximation of the plant is
P(s) =
s + 1
s2 + 2 × 0.7 × 5s + 52 .
This would model the rigid motion of the aircraft (i.e., ignoring bending). The natural frequency
is 5 rad/s and the damping ratio 0.7.
Again, rather than specify a performance weight W1, common practice is to specify a desired
loopshape. The simplest decent loop transfer function is
L(s) = ωc
s ,

112
CHAPTER 7. LOOPSHAPING
where ωc, a positive constant, is the crossover frequency, where |L| = 1. The loopshape |L(jω)|
versus ω is a straight line (log-log scale) of slope -1.
This is the simplest loopshape having the following features:
1. Good tracking and disturbance rejection (i.e., |S| small) at low frequency.
2. Good robustness (i.e., |T| small) at high frequency.
3. Internal stability.
In principle, the larger ωc, the better the performance, for then |S| is smaller over a wider frequency
range; note that
S(s) =
s
s + ωc
.
For such L with ωc = 10, the controller is
C(s) = 10s2 + 2 × 0.7 × s + 52
s(s + 1)
.
In actuality, there is a limitation on how large ωc can be because of high-frequency uncertainty:
remember that we modeled only the rigid body, whereas the actual aircraft is ﬂexible and has
bending modes just as a ﬂexible beam has. Suppose that the ﬁrst bending mode (the fundamental)
is known to be at approximately 45 rad/s. If we included this mode in the transfer function P,
there would be a pole in the left half-plane near the point s = 45j on the imaginary axis. This
would mean in turn that |P(jω)| would be relatively large around ω = 45. For the controller above,
the loopshape could then take the form in Figure 7.4.
Since the magnitude is greater than 1 at 45
rad/s, the feedback system is potentially unstable, depending on the phase at 45 rad/s.
The typical way to accommodate such uncertainty is to ensure for the nominal plant model
that |L| is suﬃciently small, starting at the frequency where appreciable uncertainty begins. For
example, we might demand that
|L(jω)| ≤0.5,
∀ω ≥45.
(We have implicitly just deﬁned a weight W2.) The largest value of ωc satisfying this condition is
ωc = 45/2.
Example 3 Consider the plant transfer function
P(s) =
s + 1
s2 + 2 × 0.7 × 5s + 52
s2 + 2 × 0.05 × 30s + 302
s2 + 2 × 0.01 × 45s + 452 .
This is an extension of the model of Example 2, with the ﬁrst bending mode at 45 rad/s included.
This mode is very lightly damped, with damping ratio 0.01. This frequency and damping ratio will
have associated uncertainty, typically 2 to 3%. Also included in P is an additional pair of lightly
damped zeros. The magnitude Bode plot of P is in Figure 7.5.
Suppose that the desired loop
transfer function is again L(s) = ωc/s. This would require that C = L/P have the factor
s2 + 2 × 0.01 × 45s + 452

7.3. EXAMPLES
113
10-2
10-1
100
101
102
10-1
100
101
102
Figure 7.4: Loopshape, Example 2.
10-4
10-3
10-2
10-1
100
10-1
100
101
102
103
104
Figure 7.5: Bode plot of |P|, Example 3.

114
CHAPTER 7. LOOPSHAPING
in its numerator, that is, C would be like a notch ﬁlter with a very deep notch. But since, as stated
above, the numbers 45 and 0.01 are uncertain, a more prudent approach is to have a shallower notch
by setting L to be, say,
L(s) = ωc
s
s2 + 2 × 0.03 × 45s + 452
s2 + 2 × 0.01 × 45s + 452 .
With the same rationale as in Example 2, we now maximize ωc such that
|L(jω)| ≤0.5,
∀ω ≥45.
This yields ωc ≈8 and the loopshape in Figure 7.6.
The controller is
10-2
10-1
100
101
102
Figure 7.6: Loopshape, Example 3.
C(s) = 8s2 + 2 × 0.7 × 5s + 52
s(s + 1)
s2 + 2 × 0.03 × 45s + 452
s2 + 2 × 0.05 × 30s + 302 .
Exercises
1. This problem concerns the plant in Example 2 in Section 4.1—the double integrator with an
uncertain time delay. Take
P(s) =
1
(s + 0.01)2 .
(This is supposed to be a stable approximation to the double integrator.) The time delay was
accommodated by embedding the plant in a multiplicative perturbation with weight
W2(s) =
0.1s
0.05s + 1.

7.3. EXAMPLES
115
To get good tracking over the frequency range [0, 1], a typical choice for W1 would be a
Butterworth ﬁlter with cutoﬀof 1 rad/s. To get at most 10% tracking error on the operating
band, we would take the gain of the ﬁlter to be 10. A third-order such ﬁlter is
W1(s) =
10
s3 + 2s2 + 2s + 1.
For these data, design a controller to achieve robust performance.
2. Repeat the design in Example 1, Section 7.3, but with
W2(s) =
10s + 1
20(0.01s + 1).
This is more diﬃcult because |W2| is fairly substantial on the operating band.
See what
performance level a you can achieve.
3. Consider the plant transfer function
P(s) =
−s + 16
(s −6)(s + 11).
This is unstable and non-minimum-phase, and loopshaping is consequently diﬃcult for it. But
try the loop transfer function
L(s) = ωc
s
−s + 16
16
s + 6
s −6
1
0.001s + 1.
This contains the unstable pole and zero of P, as it must for internal stability; it has relative
degree 1, as it must for C to be proper; and it equals approximately −ωc/s for low frequency.
Compute ωc to minimize ∥S∥∞. Compute the resulting magnitude Bode plot of S and T.
Notes and References
The technique of loopshaping was developed by Bode for the design of feedback ampliﬁers (Bode,
1945), and subsequently Bower and Schultheiss (1961) and Horowitz (1963) adapted it for the
design of control systems. The latter two references concentrate on particularly simple loopshaping
techniques, namely, lead and lag compensation. Loopshaping and the root-locus method are the
primary ones used today in practice for single-loop feedback systems. The phase formula is due to
Bode. Exercise 3 is based on a simpliﬁed analysis of the X-29 experimental airplane (Enns 1986).

116
CHAPTER 7. LOOPSHAPING

Chapter 8
Advanced Loopshaping
In Chapter 7 we saw how to convert performance speciﬁcations on S and T into speciﬁcations on the
loop transfer function L. For a stable, minimum-phase plant and L having at least the same relative
degree as P, the controller was obtained from C = L/P. In this chapter we discuss extensions to
this basic idea by doing loopshaping directly with C or other quantities and by considering plants
with right half-plane (RHP) poles or zeros. Finally, we introduce several optimal control problems
and explore in what sense loopshaping designs can be said to be optimal. Our aim is to extend
and deepen our understanding of loopshaping, to provide an introduction to optimal design, and to
establish some connections between the two approaches. Much of this chapter is closely related to
what has traditionally been called classical control, particularly the work of Bode.
8.1
Optimal Controllers
Recall from Section 4.5 that in general the norm
∥(|W1S|2 + |W2T|2)1/2∥∞
is a reasonable performance measure, a compromise norm for the robust performance problem.
Throughout this chapter we consider problems where P, W1, and W2 are ﬁxed but C is variable,
so it is convenient to indicate the functional dependence of this norm on C by deﬁning
ψ(C) := ∥(|W1S|2 + |W2T|2)1/2∥∞.
(8.1)
Throughout this chapter we refer to the optimal C, the controller that minimizes ψ, for the purpose
of comparing it to controllers obtained via other methods in order to help evaluate their eﬀective-
ness. A procedure for determining the optimal C given P and weights W1 and W2 is developed in
Chapter 12.
We shall treat the unity-feedback loop of Figure 8.1. Suppose that we focus on the response of e
and u to the two inputs d and n (r has the same eﬀect as n), and recall that the transfer functions
from d and n to e and u are given as follows:
 e
u

= −
 PS
S
T
CS
  d
n

.
117

118
CHAPTER 8. ADVANCED LOOPSHAPING
C
P






-
-
-
-
-

?
?
6
r
u
y
d
n
−
e
Figure 8.1: Unity-feedback loop.
If we introduce weights We on e, Wu on u, Wd on d, and Wn on n, then we could make our
performance speciﬁcation to keep the matrix
 We
0
0
Wu
  PS
S
T
CS
  Wd
0
0
Wn

=

WeS
WuCS
 
WdP
Wn

small in some sense. A convenient speciﬁcation is
(|WeS|2 + |WuCS|2)1/2(|WdP|2 + |Wn|2)1/2
∞< 1,
which is equivalent to
(|W1S|2 + |W2T|2)1/2
∞< 1,
where
|W1| = |We|(|WdP|2 + |Wn|2)1/2,
|W2| = |Wu|(|Wn|2|P|−2 + |Wd|2)1/2.
(8.2)
Thus this problem ﬁts the type of performance speciﬁcation in (8.1).
We will use this setup throughout this chapter, as it makes a useful “standard” problem for
a number of reasons. First, it leads to some very interesting control problems, even when simple
constant weights are used. Second, there is a rich theory available for this problem, although it will
only be hinted at in this chapter. Third, it is easy to motivate problems in this framework that
greatly stretch the loopshaping methods. Finally, despite its simplicity, the problem setup is easy
to relate to what might arise in many practical situations.
8.2
Loopshaping with C
The loopshaping procedure developed in Chapter 7 involved converting performance speciﬁcations
on S and T into speciﬁcations on the loop transfer function L, and then constructing an L to
satisfy the resulting speciﬁcations and have reasonable crossover characteristics. Assuming that the
plant had neither RHP poles nor zeros, and that L had at least the same relative degree as P, the
controller was obtained from C = L/P. In this section we consider a slightly diﬀerent approach
that focuses more directly on C. Rather than construct L without regard to P, we could begin with

8.2. LOOPSHAPING WITH C
119
a very simple controller, say C = 1, and compare the resulting L with the speciﬁcation. It is often
easy then to add simple dynamics to C to meet the speciﬁcation.
In some instances it is more convenient to do loopshaping directly in terms of C rather than L.
This will typically occur when the weights on S and T share substantial dynamics with P, as in
(8.2). If we put a constant weight of 1 on d and n and a constant weight of 0.5 on u and e, then
the weights from (8.2) become
We = Wu = 0.5,
Wd = Wn = 1,
(8.3)
|W1| = 0.5(|P|2 + 1)1/2,
|W2| = 0.5(|P|−2 + 1)1/2.
(8.4)
With W1 and W2 so deﬁned, for the performance speciﬁcation to be met the loopshape will usually
be very similar to P, so that the controller C will have |C| ≈1. We can get some insight into why
this is so by interpreting the weights in terms of the requirements they place on |C| as follows.
For L = PC
|W1S|2 = 0.25|P|2 + 1
|L + 1|2 ,
|W2T|2 = 0.25 |P|−2 + 1
|L−1 + 1|2 ,
and
|W2T|
|W1S| = |C|.
Assuming that ψ(C) < 1, at frequencies for which |P| ≫1 we have that
|W1| ≈0.5|P|,
|W2| ≈0.5,
|W1S| ≈0.5|T|
|C|,
|W2T| ≈0.5|T|,
and when |P| ≪1,
|W1| ≈0.5,
|W2| ≈0.5 1
|P|,
|W1S| ≈0.5|S|,
|W2T| ≈0.5|CS|.
The crossover region can occur wherever |P| ≈1. When |P| = 1, we have
|W1| = |W2| =
√
2
2 .
Viewing this as a standard loopshaping problem, we would expect that |L| ≈|P| and |C| = 1.
Example 1 Consider P given by
P(s) = 0.5
s +
4
X
i=1
0.2s
s2 + 2ζiωis + ω2
i
,
where ω1 = 0.2, ω2 = 0.5, ω3 = 2, ω4 = 10, ζi = 0.02. The Bode magnitude plot of P is shown in
Figure 8.2, and the resulting weights W1 and W2 on S and T are shown in Figure 8.3.
The complicated weights would appear to make this a tricky loopshaping problem, but in fact
the controller C = 1 meets the speciﬁcation. The quantity
(|W1S|2 + |W2T|2)1/2
(8.5)

120
CHAPTER 8. ADVANCED LOOPSHAPING
10-2
10-1
100
101
102
10-2
10-1
100
101
102
Figure 8.2: Bode plot of |P|.
10-1
100
101
102
10-2
10-1
100
101
102
Figure 8.3: Bode plots of |W1| (solid) and |W2| (dash).

8.2. LOOPSHAPING WITH C
121
0.5
0.55
0.6
0.65
0.7
0.75
10-2
10-1
100
101
102
frequency
magnitude
Figure 8.4: (|W1S|2 + |W2T|2)1/2 for C = 1 (solid) and optimal C (dash).
for C = 1 is plotted in Figure 8.4. The optimal ψ for this problem is approximately 0.69, so C = 1
is very close to optimal.
This example illustrates the point that loopshaping directly using C can often be much simpler
than loopshaping with L and solving for C. While the example is somewhat contrived, similar things
can happen quite naturally. In particular, this example exhibits some characteristics of plants that
arise in the control of ﬂexible structures.
Example 2
We will now use the same setup but with a slightly simpler plant P which we will
motivate with a simple mechanical analog of a two-mode ﬂexible structure (Figure 8.5). Shown is a
one-dimensional rigid beam of mass M, length 2l, and moment of inertia I connected to a ﬁxed base
by two springs, each with spring constant k. We assume that the beam undergoes small vertical
deﬂections x of the center of mass and small rotations θ about the center of mass. If we apply a
vertical force u at position lu from the center of mass, the linearized equations of motion are
M ¨x + 2kx
=
u,
I ¨θ + 2kl2θ
=
luu.
Taking M = 2, I = 0.5, l = 2, k = 0.25, and lu = 1, we get that the transfer functions from u to x
and θ are respectively
0.5
s2 + 0.52 ,
2
s2 + 22 .
We will now measure y := ˙x ± ˙θ, the vertical velocity of the beam at the position ±1 from the
center of mass. For +1, the measurement is at the same location as the force input u; this is called

122
CHAPTER 8. ADVANCED LOOPSHAPING
M, I
lu
θ
l
k
k
x
m
U
6
-

-
6
  @@
    @@
  Figure 8.5: Mechanical structure, Example 2.
collocated. In the −1 case the measurement is at the other side of the beam, noncollocated. The
resulting transfer function from u to y is then
P(s) =
0.5s
s2 + 0.52 ±
2s
s2 + 22 = (2 ± 0.5)s(1 ± s2)
(s2 + 0.52)(s2 + 22).
(8.6)
A plot of |P| is shown in Figure 8.6.
The collocated system has zeros at ±j and the noncollocated
system has zeros at ±1. As expected, we shall see that the noncollocated system is more diﬃcult
to control. For the collocated case it turns out that the optimal controller for the weights (8.3)
is exactly C = 1, which is again much simpler than the resulting loopshape. It also turns out
that this result holds for all positive values of M, I, l, lu, and k, excluding those for which the
system is not mechanically possible. In each case, the optimal controller is C = 1 and the optimal
ψ =
√
2/2 ≈0.707. A proof of this, along with a discussion of the noncollocated case, is given in
the last section of this chapter.
It is interesting to note that both examples above have multiple crossover frequencies, that
is, several distinct frequencies at which |L| = 1. By contrast, most previous examples had only
one crossover frequency. Indeed, most problems considered in classical control texts have a single
crossover, and this might be considered typical. There are, however, certain application domains,
such as the control of ﬂexible structures, where multiple crossovers are common. It turns out that
such systems have some interesting characteristics which may appear counterintuitive to readers
unfamiliar with them. These issues will be explored more fully in the last section of this chapter.
It is not unusual for a reasonable controller to be much simpler than the resulting loopshape
even when the problem setup is diﬀerent from the one considered in the examples above. It often
makes sense to begin the loopshaping design process with L equal to some constant times P and
then add dynamic elements to try to get the right loopshape.
Example 3 As a slightly diﬀerent example, consider the same setup as in Example 1 but with
P(s) =
1
s + 1 +
0.1s
s2 + 2ζω1s + ω2
1
,

8.2. LOOPSHAPING WITH C
123
10-1
100
101
102
10-1
100
101
Figure 8.6: Bode plots of |P| for + (solid) and −(dash).
where ζ = 0.02 and ω1 = 0.5. Suppose also that the weight on the error e is
We(s) = 0.5 s + 0.5
s + 0.01,
with Wu = 0.5 and Wd = Wn = 1 as before. This gives us the performance objective as in (8.1),
(8.2), and (8.4) except that now
|W1| = |We|(|P|2 + 1)1/2,
|W2| = 0.5(|P|−2 + 1)1/2.
The Bode magnitude plot of P is shown in Figure 8.7 and the resulting weights W1 and W2 on S
and T are shown in Figure 8.8.
If we compare the loopshaping constraints in Figure 8.9 with the Bode plot of P in Figure 8.7
we see immediately that C = 1 will not work because there is not enough gain at low frequency.
Adding the simple lag compensator
C(s) =
s + 1
s + 0.01
gives the loopshape shown in Figure 8.9 and (|W1S|2 + |W2T|2)1/2 as shown in Figure 8.10. Fig-
ure 8.10 also shows the optimal level for this problem. The simple controller found here is very
close to optimal.

124
CHAPTER 8. ADVANCED LOOPSHAPING
10-2
10-1
100
101
10-2
10-1
100
101
102
Figure 8.7: Bode plot of |P|.
10-1
100
101
102
10-2
10-1
100
101
102
Figure 8.8: Bode plots of |W1| (solid) and |W2| (dash).

8.2. LOOPSHAPING WITH C
125
10-2
10-1
100
101
102
10-2
10-1
100
101
102
Figure 8.9: Loopshaping constraints and |L| (solid) for C = (s + 1)/(s + 0.01).
0.5
0.55
0.6
0.65
0.7
0.75
0.8
0.85
10-2
10-1
100
101
102
Figure 8.10: (|W1S|2 + |W2T|2)1/2 for C = (s + 1)/(s + 0.01) (solid) and optimal C (dash).

126
CHAPTER 8. ADVANCED LOOPSHAPING
8.3
Plants with RHP Poles and Zeros
Plants with RHP Zeros
Suppose that we begin a loopshaping problem with a plant P0, controller C0, and loop transfer
function L0 = P0C0 with neither RHP poles nor zeros and a single crossover. Now consider the
eﬀect of adding a single RHP zero at s = z to the plant by multiplying by the all-pass function
Pz(s) = z −s
z + s,
where the sign of Pz is chosen so that Pz(0) = 1. This also adds the same factor to the loop transfer
function, which becomes
L(s) = L0(s)z −s
z + s.
From the results of Chapter 6 we would expect problems unless z is larger than the crossover
frequency: Recall that
∥W1S∥∞≥|W1(z)|,
so that |W1| must not be large at z.
We may also consider the eﬀect of the RHP zero in terms of the gain-phase relations from
Section 7.2. The phase at crossover will be the original phase of L0 plus the phase of Pz:
∠L(jω)
=
∠L0(jω) + ∠Pz(jω),
∠Pz(jω)
=
2∠(−jω + z).
The phase from Pz is negative and can be substantial as ω approaches z, with ∠Pz(jz) = −π/2.
Again, we see that if z approaches the crossover frequency, the additional phase will degrade the
closed-loop system performance or even lead to instability. Thus RHP zeros make the problem
worse for systems with one crossover. As an example, let the initial loopshape be L0(s) = 1/s with
L as above. The crossover frequency is ω = 1 and the closed-loop system is stable if z > 1 and
unstable if z ≤1.
If Pz has a complex pair of RHP zeros, then
Pz(s) = ω2
z −2ζzωzs + s2
ω2z + 2ζzωzs + s2
and
∠Pz(jω) = 2∠(−2ζzωzjω + ω2
z −ω2).
Observe that for lightly damped zeros where ζz is small, the phase changes abruptly near ω = ωz.
Otherwise, the same remarks apply here as in the case of one RHP zero. The simplest strategy to
adopt in doing loopshaping designs for systems with RHP zeros is to proceed as usual while keeping
track of the extra phase.
It would seem from this discussion that RHP zeros are always undesirable, that we would always
avoid them if possible, and that we would never deliberately introduce them in our controllers. It
is clearly true that all other things being equal, there is no advantage in having RHP zeros in the
plant, because we could always add them in the controller if they were desirable. The issue of using
RHP zeros in the controller is more subtle. Basically, they are clearly undesirable when there is only
one crossover, but may be useful when there are multiple crossovers. This issue will be considered
more fully in later sections on optimality.

8.3. PLANTS WITH RHP POLES AND ZEROS
127
Plants with RHP Poles
The problems created by RHP poles are similar to those created by RHP zeros, but there are
important diﬀerences. Suppose that we begin again with a loopshaping problem with a plant P0,
controller C0, and loop transfer function L0 = P0C0 with neither RHP poles nor zeros and a single
crossover. Now consider the eﬀect of adding a single RHP pole at s = p to the plant by multiplying
it by the all-pass function
Pp(s) = s + p
s −p.
This also adds the same factor to the loop transfer function L. The sign of Pp is chosen so that
Pp(0) = −1. For p small, this gives the right number of encirclements for L to give closed-loop
stability. Now we expect that we will have problems unless p is smaller than the crossover frequency:
Recall that
∥W2T∥∞≥|W2(p)|,
so that |W2| must not be large at p.
We may also consider the eﬀect of the RHP pole in terms of the gain-phase relations. The phase
at crossover will be the original phase of L0 plus the phase of Pp:
∠L(jω)
=
∠L0(jω) + ∠Pp(jω),
∠Pp(jω)
=
2∠(jω + p).
We may illustrate this with the same example. Let the initial loopshape be L0(s) = 1/s with L as
above. The crossover frequency is ω = 1 and the closed-loop system is stable if p < 1 and unstable
if p ≥1. Similar eﬀects hold when there is more than one RHP pole.
All things being equal, we would prefer to avoid RHP poles in our plants. Even though they
can be stabilized by feedback, there is a price to pay in terms of closed-loop performance. Recall
that there are times when we must add RHP poles in our compensator just to stabilize the system.
Are there other times when we would want to add RHP poles? Clearly no if we have only one
crossover, but if there are multiple crossovers it might be advantageous. This will be discussed in a
later section on optimality.
Including RHP Poles and Zeros in Uncertainty Description
A somewhat more formal strategy for handling RHP poles and zeros is to include them in the
uncertainty description as follows. Suppose that we have a RHP zero at z. Then we can factor P
as
P(s) = P0(s)z −s
z + s = P0(s)

1 + −2s
z + s

and cover this with a multiplicative perturbation to get
P = P0 (1 + Wz∆) ,
Wz(s) =
2s
z + s.

128
CHAPTER 8. ADVANCED LOOPSHAPING
A somewhat tighter cover is given by
P(s)
=
P0(s)

z
z + s −
s
z + s

=
P0(s)
z
z + s [1 + Wz(s)∆(s)] ,
Wz(s)
=
s
z .
Robust stability for uncertainty in this form would involve a test on ∥WzT∥∞.
Why would we want to do this? If we put all the RHP zeros into the plant uncertainty, then
we can use any design technique for plants with no RHP zeros, provided that we account for the
extra uncertainty. Basically, one makes sure that T is small enough where necessary. The way we
have covered the RHP zero above makes the model have little uncertainty at low frequencies and
considerable uncertainty at high frequencies. The transition occurs at frequencies near z. It is also
easy to cover the all-pass part with an uncertainty that is large at low frequencies and small at high
frequencies.
We can model RHP poles similarly. Care must be taken, however, because RHP poles don’t
naturally go into multiplicative uncertainty. Suppose that we have a RHP pole at p. Then we can
factor P as
P(s) = P0(s)s + p
s −p = P0(s)

1 + −2p
s + p
−1
and cover this with a perturbation to get
P = P0
1
1 + Wp∆,
Wp(s) =
2p
s + p.
This introduces an additional weight on S. A somewhat tighter cover is given by
P(s)
=
P0(s)

s
s + p −
p
s + p
−1
=
P0(s)s + p
s
1
1 + Wp(s)∆(s),
Wp(s)
=
p
s.
How conservative is this covering method? For most problems with a single crossover and for
which the performance objectives are achievable, this approach will work well. Basically, we need to
make sure that S is small enough where there are RHP poles and T is small enough where there are
RHP zeros. There are more complicated problems, particularly those involving multiple crossovers,
where the impact of RHP poles and zeros might be quite diﬀerent. This issue will be considered
again in the ﬁnal section of this chapter.
Examples
We will now consider several examples that illustrate loopshaping for systems with RHP zeros and
poles.

8.3. PLANTS WITH RHP POLES AND ZEROS
129
Example 1 Consider
P(s) = P0(s)z −s
z + s,
P0(s) = 1
s.
As in Section 8.2,
|W1| = 0.5(|P|2 + 1)1/2,
|W2| = 0.5(|P|−2 + 1)1/2,
(8.7)
or
W1(s) = 0.5

1 + 1
s

,
W2(s) = 0.5(s + 1).
(8.8)
The obvious controller for P0 is C = 1, which is also optimal with |W1S| = |W2T| = 0.5 and
ψ(C) =
√
2/2. This simple controller will work ﬁne for z ≫1, but deteriorates as z approaches 1
and does not stabilize for z ≤1 because of the additional phase lag caused by the all-pass factor.
Recall that for any controller
∥W1S∥∞≥|W1(z)| = 0.5

1 + 1
z

,
but it is possible to improve substantially on C = 1 as z gets close to 1.
We will now focus on z = 2. For C = 1 the loopshape constraints and the loopshape L = CP are
shown in Figure 8.11. The closed-loop performance is shown in Figure 8.12. Note that ψ(C) > 2,
with both |W1S| and |W2T| exceeding the speciﬁcation at low and high frequencies, with a large
peak in the middle. This is due to too much phase lag in L at crossover (ω = 1). Recall from
the gain-phase formula in Section 7.2 that we may improve the phase at crossover by reducing the
low-frequency gain, reducing the crossover frequency, and increasing the high-frequency gain. A
simple controller that does this is of the form
C(s) = k(s + 2)
(s + 2k2),
k > 1.
(8.9)
It turns out that the optimal C has k = 1.78, which yields an optimal ψ(C) = 1.02. A value of
k very close to optimal is also easily arrived at by a little trial and error. The loopshape for the
optimal C is shown in Figure 8.13 and the closed-loop performance is shown in Figure 8.14. The
controller reduces the low-frequency gain and the crossover frequency and raises the high-frequency
gain of L, as expected.
Next we will try an alternative design by covering the RHP zero with uncertainty and then
loopshaping with the resulting minimum-phase nominal plant. For general z write
P(s) = 1
s

z
z + s −
s
z + s

= P0(s) [1 + Wz(s)∆(s)] ,
where
P0(s) = 1
s
z
z + s,
Wz(s) = s
z .
(8.10)
We now have two weights on T: W2 and Wz. We need to ﬁnd a weight that covers both of these.
A reasonable approximation is
|Wtot| = |W2| + |Wz| + |W2||Wz|.

130
CHAPTER 8. ADVANCED LOOPSHAPING
10-2
10-1
100
101
102
10-2
10-1
100
101
102
Figure 8.11: Loopshaping constraints (dash and dot) and |L| (solid) for C = 1.
0
0.5
1
1.5
2
2.5
10-2
10-1
100
101
102
Figure 8.12: (|W1S|2 + |W2T|2)1/2 (solid), |W1S| and |W2T| (both dash) for C = 1.

8.3. PLANTS WITH RHP POLES AND ZEROS
131
10-2
10-1
100
101
102
10-2
10-1
100
101
102
Figure 8.13: Loopshaping constraints (dash and dot) and |L| (solid) for optimal C.
0
0.5
1
1.5
2
2.5
10-2
10-1
100
101
102
Figure 8.14: (|W1S|2 + |W2T|2)1/2 (solid), |W1S| (dash), and |W2T| (dot), optimal C.

132
CHAPTER 8. ADVANCED LOOPSHAPING
It is routine to show that

(1 + ∆Wz)W2T
1 + ∆WzT
 ≤|W2T|(1 + |Wz|)
1 −|WzT|
and
|W2T|(1 + |Wz|)
1 −|WzT|
< 1
iﬀ
|WtotT| < 1,
so using Wtot is a safe, but possibly conservative approximation. As an alternative way of thinking
about this in terms of uncertainty descriptions, note that
{(1 + |W2|∆1)(1 + |Wz|∆2) : |∆1| ≤1, |∆2| ≤1} ⊂{1 + |Wtot|∆: |∆| ≤1} .
If z ≫1, this additional “uncertainty” will be negligible and the controller C = 1 will be ﬁne.
10-3
10-2
10-1
100
101
102
103
104
10-2
10-1
100
101
102
Figure 8.15: |W2| (dash), |Wz| (dot), and |Wtot| (solid).
Again, for the case z = 2 the plot for |Wtot| is shown in Figure 8.15, together with plots of |W2|
and |Wz|. To help us understand how conservative we have been by these approximations, we can
compare
(|W1S|2 + |W2T|2)1/2
(8.11)
for P with RHP zero at s = 2 with

|W1S|2 + (1 + |Wz|)2|W2T|21/2
1
1 −|WzT|
(8.12)

8.3. PLANTS WITH RHP POLES AND ZEROS
133
0
0.5
1
1.5
2
2.5
10-2
10-1
100
101
102
Figure 8.16: Plots of (8.11) (solid), (8.12) (dash), and (8.13) (dot).
and
(|W1S|2 + |WtotT|2)1/2,
(8.13)
where in (8.12) and (8.13) we use the plant P0 from (8.10). By construction, we have that (8.11) ≤
(8.12), but (8.13) is not necessarily an upper bound for (8.11). All three quantities are plotted in
Figure 8.16.
For P = P0 and C = 1, the loopshape L = CP is shown in Figure 8.17, along with the
loopshaping constraints.
As before, there is too much phase lag in the crossover region, which
is veriﬁed in Figure 8.18.
As before, we may improve the phase at crossover by reducing the
low-frequency gain, reducing the crossover frequency, and increasing the high-frequency gain. The
optimal controller should once again be adequate, as is veriﬁed in Figures 8.19 and 8.20.
This example illustrates how the simple loopshaping ideas from this chapter and the preceding
one can be extended to handle plants with RHP zeros.
Example 2 Now consider the problem of stabilizing the plant
P(s) = αs −1
α −s ,
α ∈(0, 1).
(8.14)
It is easily checked that a constant controller C = k stabilizes this system iﬀk ∈(α, 1/α). We may
compare this with the conclusions we would arrive at if we were to cover the RHP zero and pole
with uncertainty about a nominally stable, minimum-phase plant. For example, we may write
αs −1
α −s = 1
s
 1 + αs∆1(s)
1 + α/s∆2(s)

.
(8.15)

134
CHAPTER 8. ADVANCED LOOPSHAPING
10-3
10-2
10-1
100
101
102
10-2
10-1
100
101
102
Figure 8.17: Loopshaping constraints (dash and dot) and |L| (solid), C = 1.
0
0.5
1
1.5
2
2.5
10-2
10-1
100
101
102
Figure 8.18: (|W1S|2 + |WtotT|2)1/2 (solid), |W1S| (dash), and |WtotT| (dot), C = 1.

8.4. SHAPING S, T, OR Q
135
10-3
10-2
10-1
100
101
102
10-2
10-1
100
101
102
Figure 8.19: Loopshaping constraints (dash and dot) and |L| (solid) for optimal C.
We can pose this in the standard form of ψ(C) in (8.1) with plant P(s) = 1/s and weights
W1(s) = α/s and W2(s) = αs. If we now consider loopshaping for this problem, we will meet this
speciﬁcation with a constant controller C = k roughly if k ∈(α, 1/α), as before. Thus for this
problem with both a RHP pole and zero, the approximation of covering the RHP pole and zero
with uncertainty produces very little conservatism.
8.4
Shaping S, T, or Q
It is possible to do designs directly in terms of S and T rather than translate the speciﬁcations into
constraints on the loopshape. This is especially useful when P is either stable or minimum-phase,
or both. Then the stability constraints on S and T are particularly simple. For example, if there
are only RHP zeros, these must appear in T, but T is otherwise unconstrained. The performance
objective due to weights on T can be directly handled by the choice of T, but S is not as easy. Since
S = 1 −T, we can make S small by making T close to 1. Although this can sometimes be a bit
awkward, it is often the case that by looking at T and S directly in addition to L, we can arrive at
a design more quickly.
Another alternative to loopshaping is to use Q, appearing in the parametrization of all stabilizing
controllers. To summarize this, recall (Section 5.1) that if we have a stable P, we can parametrize
the set of all stabilizing controllers as
C =
Q
1 −PQ,
where Q is any stable transfer function. In terms of this free parameter Q, we have that S = 1−PQ

136
CHAPTER 8. ADVANCED LOOPSHAPING
0
0.5
1
1.5
2
2.5
10-2
10-1
100
101
102
Figure 8.20: (|W1S|2 + |WtotT|2)1/2 (solid), |W1S| (dash), and |WtotT| (dot), optimal C.
and T = PQ. As Q approaches 1/P, then S approaches 0 and C approaches ∞. Thus for minimum-
phase P, we can make S arbitrarily small, as expected. For non-minimum-phase P, recall that we
can factor P = PapPmp where Pap is all-pass and Pmp is minimum-phase. We can approximately
invert the minimum-phase part by letting Q = F/Pmp, where F is a low-pass ﬁlter so that Q
is proper. We can then shape the low-pass F to trade oﬀbetween S and T. This approach is
essentially shaping T since T = FPap.
Example Take
P(s) = 1
s
2 −s
2 + s

.
(8.16)
Consider directly shaping T and look at tradeoﬀs between S and T and the limitations imposed
by the RHP zero at s = 2. For internal stability we must have T(2) = 0 and T(0) = 1, so we can
parametrize a family of allowable Ts with
T(s)
=
2 −s
2 + s

1
1 + τs,
S(s)
=
1 −T(s)
=
s
s + 2
τs + 2τ + 2
τs + 1

.

8.4. SHAPING S, T, OR Q
137
This gives
L(s)
=
T(s)
S(s)
=
2 −s
s(τs + 2τ + 2),
C(s)
=
s + 2
τs + 2τ + 2.
For this parametrization, 1/τ is roughly the closed-loop bandwidth, so we are pushing the bandwidth
up by making τ small. This is shown in Figures 8.21 and 8.22, where S, T, and L are plotted for
τ = 0.01, 0.1, 1, 10, and 100. There are negligible changes in S, T, and L at low frequency as τ is
decreased from 0.1 to 0.01, although the high-frequency characteristics change substantially. This
illustrates another way the limits are imposed by RHP zeros.
10-2
10-1
100
101
10-3
10-2
10-1
100
101
102
103
Figure 8.21: |T| (solid) and |S| (dash) for 0.01 ≤τ ≤100.
If we take limits as τ →0, we get
T →2 −s
2 + s,
S →
2s
s + 2,
L →2 −s
2s ,
C →2 + s
2
.
(8.17)
Thus even at the expense of an inﬁnite bandwidth controller, we cannot get disturbance rejection
much above ω = 1. Recall that if we take the weight
W1(s) = s + 2
2s ,
then for any stabilizing controller
∥W1S∥∞≥s + 2
2s

s=2
= 1,

138
CHAPTER 8. ADVANCED LOOPSHAPING
10-2
10-1
100
101
102
10-3
10-2
10-1
100
101
102
103
Figure 8.22: |L| for 0.01 ≤τ ≤100.
so the S in (8.17) cannot be uniformly improved on. For very low bandwidths (i.e., for τ ≫1 and
ω ≪1), the RHP zero has negligible impact as
T ≈
1
τs + 1,
S ≈
τs
τs + 1,
L ≈1
τs,
C ≈1
τ .
This example illustrates how we may easily explore the tradeoﬀs between S and T for P with
RHP zeros by putting the zeros in T and then exploring a one-parameter family of T and hence S.
Similar tradeoﬀs may be explored for plants with RHP poles by parametrizing a family of S. For
plants with both RHP poles and zeros, it is necessary to use the more complicated parametrization
developed in Chapter 5.
8.5
Further Notions of Optimality
Each of the design methods presented so far—shaping L, S, T, or Q—gives the designer something
handy to manipulate to obtain a controller.
In each case, the resulting controller will have to
be examined in the closed-loop system to see if it is satisfactory—every controller results in some
tradeoﬀbetween S and T, and the designer must decide if that tradeoﬀmakes sense for a particular
problem. However, some controllers are intrinsically poor. In particular, we would like to avoid
design techniques that yield controllers that can be uniformly improved upon, that is, where both
|S| and |T| can be reduced at every frequency. Such controllers clearly do a poor job on the tradeoﬀ
between S and T.
In this section we deﬁne several notions of optimality which we will use to help understand
the notion of an intrinsically poor controller. In what follows, all controllers are assumed to be

8.5. FURTHER NOTIONS OF OPTIMALITY
139
internally stabilizing and all weights are assumed to be stable and not identically zero; Co is a ﬁxed
controller, and So and To its corresponding sensitivity and complementary sensitivity functions; C
is some generic, variable controller and S and T its corresponding functions.
The ﬁrst type of optimality we will consider is Pareto optimality. A controller Co is Pareto
(Par.) optimal if there is no C such that at every frequency |S| < |So| and |T| < |To|; equivalently,
for every C, at some frequency either |S| ≥|So| or |T| ≥|To|. A controller Co is strongly Pareto
(str. Par.) optimal if there is no C ̸= Co such that at every frequency |S| ≤|So| and |T| ≤|To|;
equivalently, for every C ̸= Co, at some frequency either |S| > |So| or |T| > |To|. The class of
strongly Pareto optimal controllers is quite large: some of them give good S and T tradeoﬀs, some
do not. But controllers that are not strongly Pareto optimal, that is, are outside this class, are
evidently poor because they can be improved uniformly.
Our primary objective in this section and the next is to show that loopshaping generally yields
strongly Pareto optimal controllers. Unfortunately, we must take a circuitous route to establish
this, introducing several intermediate notions of optimality. There are added beneﬁts, however, in
that these additional notions of optimality have some independent interest, and we shall see that
optimal controllers, the subject of Chapter 12, are also Pareto optimal.
We have argued that the norm
∥(|W1S|2 + |W2T|2)1/2∥∞
is a reasonable performance measure, a compromise norm for the robust performance problem.
Recall that for ﬁxed P with C variable, we deﬁned
ψ(C) := ∥(|W1S|2 + |W2T|2)1/2∥∞.
Using ψ(C), we can deﬁne two additional notions of optimality, together with strengthened versions
involving uniqueness that are analogous to strongly Pareto optimal.
1. For given weights W1 and W2, Co is optimal if ψ(Co) ≤ψ(C) for every C, and uniquely optimal
if ψ(Co) < ψ(C) for every C ̸= Co.
2. Co is potentially (pot.) optimal if there exist weights W1, W2 such that Co is optimal for these
weights and potentially uniquely (pot. uni.) optimal if there exist weights W1, W2 such that
Co is uniquely optimal for these weights.
These notions, along with Pareto optimal, are related according to the Venn diagram shown
in Figure 8.23, which is easily veriﬁed. Potentially uniquely optimal is the strongest of the four
notions.
Self-Optimality
In this subsection an even stronger type of optimality is introduced whose signiﬁcance is due to
three features:
1. It is easy to characterize.
2. Loopshaping generally produces controllers with this type of optimality.
3. It implies all the notions above, and in particular, strong Pareto optimality.

140
CHAPTER 8. ADVANCED LOOPSHAPING
pot.
Par.
pot. uni.
str. Par.
Figure 8.23: Notions of optimality.
Fix a controller Co, deﬁne Lo := PCo, and deﬁne weights as follows: W −1
1
is the minimum-phase
factor of So and W −1
2
is the minimum-phase factor of To. Thus the weights are deﬁned in terms
of the controller itself. Observe that W −1
2
may be strictly proper, and that both W −1
1
and W −1
2
may have zeros on the imaginary axis. Thus the weights W1 and W2 may not be bounded on the
imaginary axis. Since W1So equals the all-pass factor of So, it has constant magnitude 1 on the
imaginary axis. Similarly for W2To. Thus
|W1So|2 + |W2To|2 = 2,
∀ω.
Given W1 and W2 so deﬁned, Co is called self-optimal if it is optimal with respect to these weights.
Similarly, it is uniquely self-optimal if it is uniquely optimal with respect to these weights. It will be
shown below that for almost all controllers, a self-optimal controller is uniquely self-optimal. The
Venn diagram, including uniquely self-optimal is shown in Figure 8.24.
It is convenient to introduce the following notation. For a transfer function G having no poles
on the imaginary axis, let
#p(G)
:=
number of open RHP poles of G,
#z(G)
:=
number of open RHP zeros of G,
#i(G)
:=
number of imaginary axis zeros of G.
The main result is as follows.
Theorem 1 If #i(Lo −1) = 0, Co is self-optimal iﬀCo is uniquely self-optimal iﬀ
#z(Lo −1) > #p(Co) + #z(Co).
(8.18)
We are restricting attention to the case #i(Lo −1) = 0 primarily for technical reasons, as
it simpliﬁes the development with a negligible loss of generality.
Note that #i(Lo −1) = 0 iﬀ

8.5. FURTHER NOTIONS OF OPTIMALITY
141
uni. self
pot.
Par.
pot. uni.
str. Par.
Figure 8.24: Notions of optimality.
Lo(jω) ̸= 1, ∀ω. This would hold for almost all controllers, because if #i(Lo −1) ̸= 0, then a small
change, say by a constant gain, in Lo would make #i(Lo −1) = 0. It can easily be shown that
if #i(Lo −1) ≥1, then Co is always self-optimal, but characterizing uniquely self-optimal is more
diﬃcult.
Observe from the principle of the argument that in terms of the Nyquist plot of Lo,
#z(Lo −1)
=
#p(Lo −1) + (no. clockwise enc. of + 1)
=
#p(Lo) + (no. clockwise enc. of + 1)
=
#p(P) + #p(Co) + (no. clockwise enc. of + 1).
So condition (8.18) is equivalent to
#p(P) + (no. clockwise enc. of + 1) > #z(Co).
A typical loopshaping controller for a stable plant will have #z(Co) = 0 and
(no. clockwise enc. of + 1) > 0,
and will thus be self-optimal.
Example For a simple illustration, suppose that
P(s) =
s + 1
100s + 1.
The controller Co(s) = 10 yields
Lo(s) = 10
s + 1
100s + 1.

142
CHAPTER 8. ADVANCED LOOPSHAPING
The Nyquist plot of Lo has one clockwise encirclement of +1, so Co is self-optimal. So is Co(s) = K
for any K in (1, 100). In particular, such controllers cannot be improved upon uniformly over all
frequencies.
It can be shown using the phase formula (Section 7.2) that any controller that is minimum-phase
and for which Lo has a single gain crossover is self-optimal.
Proof of Theorem 1 Deﬁne
Γo(jω) := |W1(jω)So(jω)|2 + |W2(jω)To(jω)|2,
so that
ψ(Co)2 = sup
ω Γo(jω).
As we have already seen, Γo(jω) = 2. Similarly, for another controller C, deﬁne
Γ(jω) := |W1(jω)S(jω)|2 + |W2(jω)T(jω)|2,
so that
ψ(C)2 = sup
ω Γ(jω).
Thus Co is self-optimal
⇐⇒
(∀C) ψ(Co) ≤ψ(C)
⇐⇒
(∀C)(∃ω) 2 ≤Γ(jω)
⇐⇒
it is not true that (∃C)(∀ω) 2 > Γ(jω)
and Co is uniquely self-optimal
⇐⇒
it is not true that (∃C ̸= Co)(∀ω) 2 ≥Γ(jω).
So the theorem statement is equivalent to
(∃C)(∀ω) 2 > Γ(jω)
⇐⇒
(∃C ̸= Co)(∀ω) 2 ≥Γ(jω)
⇐⇒
#z(Lo −1) ≤#p(Co) + #z(Co).
It is convenient to turn this statement into one in terms of So rather than Co. As we saw in
Chapter 6, the constraints placed on So by the requirement that Co achieve internal stability are
So
∈
S,
So
=
0 at RHP poles of P,
So
=
1 at RHP zeros of P,
with appropriate multiplicity. Then S satisﬁes these constraints too iﬀit has the form
S = So + AY,
where A is the all-pass factor formed from the RHP poles and zeros of P, and Y is an arbitrary
element of S. It is convenient ﬁrst to assume that P and Co are biproper and have no poles or

8.5. FURTHER NOTIONS OF OPTIMALITY
143
zeros on the imaginary axis, so that neither So nor To have imaginary axis zeros, and the weights
are stable and biproper. Then (8.19) is equivalent to
(∃Y ∈S)(∀ω) 2 > |W1(So + AY )|2 + |W2(To −AY )|2 ⇐⇒
(∃Y ∈S, Y ̸= 0)(∀ω) 2 ≥|W1(So + AY )|2 + |W2(To −AY )|2 ⇐⇒
#z(Lo −1) ≤#p(Co) + #z(Co)
(8.19)
(jω has been dropped to simplify the notation). Recall that
|W1| =
1
|So|,
|W2| =
1
|To|,
so
|W1(So + AY )|2 + |W2(To −AY )|2
=
1 + AY
So

2
+
1 −AY
To

2
=
2 + 2Re
 1
So
−1
To

AY

(8.20)
+

1
|So|2 +
1
|To|2

|AY |2.
(8.21)
Thus (8.19) is equivalent to the condition
(∃Y ∈S)(∀ω)0
>
2Re (XY ) + W|Y |2
(8.22)
iﬀ
(∃Y ∈S, Y ̸= 0)(∀ω)0
≥
2Re (XY ) + W|Y |2
(8.23)
iﬀ
#z(Lo −1)
≤
#p(Co) + #z(Co),
(8.24)
where
X :=
 1
So
−1
To

A
is biproper with no imaginary poles or zeros and
W :=

1
|So|2 +
1
|To|2

|A|2 > 0
is bounded for all ω. That (8.22) implies (8.23) is immediate by inspection. We will complete the
proof by ﬁrst showing that (8.24) is equivalent to
#z(X) ≤#p(X)
(8.25)
and then that (8.23) =⇒(8.25) and (8.25) =⇒(8.22).
To see that (8.24) ⇐⇒(8.25) holds, note that
X
=

Lo + 1 −Lo + 1
Lo

A = (Lo + 1)(Lo −1)
Lo
A
=
[num(PCo) + den(PCo)][num(PCo) −den(PCo)]
num(PCo)den(PCo)
A.

144
CHAPTER 8. ADVANCED LOOPSHAPING
Now the polynomial num(PCo) + den(PCo) has all its zeros in the left half-plane, by internal
stability; and the numerator of A cancels the zeros in num(PCo)den(PCo) coming from the RHP
poles and zeros of P. Thus
#z(X) = #z[num(PCo) −den(PCo)] = #z(Lo −1)
and
#p(X) = #p(Co) + #z(Co).
For (8.23) =⇒(8.25), note that if the Nyquist plot of XY lies in the closed left half-plane, then
in particular it does not encircle the origin. Since XY is not identically zero, by the principle of
the argument
#z(XY ) = #p(XY ).
But #z(X) ≤#z(XY ) and #p(XY ) ≤#p(X).
For (8.25) =⇒(8.22), note that (8.22) is equivalent to
(∃Y ∈S)(∀ω) 0 > 2Re (XY ) ,
since we can scale Y so that the quadratic term W|Y |2 is negligible. We will construct a Y ∈S
such that Re(XY ) < 0,
∀ω. If #z(X) ≤#p(X), we can write X = X1X2, where X1 has only
RHP poles and zeros with #z(X) = #z(X1) = #p(X1), and X2 has #z(X2) = 0 and #p(X2) =
#p(X) −#p(X1). Thus both X1 and X2 are biproper. If
Y (s) = X1(−s)
X2(s) ,
then Y ∈S and is biproper and
X(jω)Y (jω) = X1(jω)X1(−jω) = |X1(jω)|2 > 0,
∀ω.
To complete the proof, we must drop the restriction that Lo is biproper and has no imaginary
axis poles or zeros. This means that So and To may have imaginary zeros, and thus W1 and W2 may
have imaginary poles. In order for (8.21) to be bounded, we must have AY share the imaginary
zeros of So and To, including those at ∞.
The simplest way to proceed is to assume that A is no longer all-pass but has in addition the
imaginary zeros of So and To and enough LHP poles so that A has the appropriate behavior at ∞.
The location of the LHP poles is unimportant. Then
S = So + AY
still parametrizes all S that can arise from internally stabilizing controllers and produce a ﬁnite Γ.
The proof can now proceed exactly as before. Observe that X is still biproper and has no imaginary
poles or zeros, because of the construction of A. ■

8.5. FURTHER NOTIONS OF OPTIMALITY
145
Example and Implications
In the preceding subsection it was remarked that loopshaping produces self-optimal controllers.
In particular, for stable plants and loopshapes with a single crossover, where #z(Lo −1) =
(# clockwise enc. of + 1) = 1, then the controller is self-optimal iﬀit has no RHP poles or ze-
ros. For #z(Lo −1) > 1, controllers with no RHP poles or zeros are also always self-optimal. This
helps make clear the conventional wisdom about why RHP controller poles and zeros are undesir-
able. Similar insight comes from the results on performance limitations due to RHP zeros and the
integral gain-phase relations from earlier chapters.
Are there ever times when it would make sense to introduce RHP controller poles or zeros
deliberately? Theorem 1 leaves open this possibility for situations where #z(Lo −1) > 1, which
can occur when there are multiple crossovers.
Example To illustrate this we will reconsider the simple beam, Example 2 from Section 8.2, with
P given in (8.6) and with weights from (8.3). Recall that for the noncollocated case the plant has
a RHP zero at s = 1. Consider the controller
C−(s) = 2.4
s −1
s + 1
 
s2 −s + 1
(s + 0.1)(s + 10)

.
(8.26)
A Bode plot of C−is shown in Figure 8.25. The resulting closed-loop performance for C−is shown
in Figure 8.26, along with the performance for the optimal controller. Observe that C−is nearly
optimal. (It was actually obtained by rounding coeﬃcients in the optimal controller to convenient
values.) Also, the optimal performance of ψ ≈1.26 is poorer than the optimal performance of
ψ =
p
(2)/2 ≈0.707 for the collocated case.
10-1
100
101
10-1
100
101
-200
-100
0
100
200
10-1
100
101
magnitude
phase
Figure 8.25: Bode plots of |C−| (upper) and ∠C−(lower).

146
CHAPTER 8. ADVANCED LOOPSHAPING
0
0.2
0.4
0.6
0.8
1
1.2
1.4
10-1
100
101
Figure 8.26: ψ for optimal C (solid) and C−(dash).
The controller C−has no RHP poles and three RHP zeros, so that the loop transfer function
PC−has a total of four RHP zeros. Since #z(PC−−1) = 4, we have from Theorem 1 that this
controller is also self-optimal. It is possible to give a loopshaping interpretation of this controller,
which is not much diﬀerent than an all-pass. Intuitively, a good controller for this problem must
have the appropriate phase at the two resonant frequencies (ω = 0.5, 2) for stability, and from the
arguments in Section 8.2 its gain should not deviate too greatly from 1. Thus a controller which is
nearly all-pass would seem appropriate.
The ideas on dealing with RHP zeros presented in Section 8.3 are not terribly useful in this
example.
Since there are necessarily crossover frequencies both above and below the frequency
ω = 1 where the zero occurs, it is not clear how to cover this with uncertainty. The controller C−
actually places an additional three RHP zeros near this frequency. While a loopshaping methodology
could potentially still apply to this example, the actual details of this controller are hardly obvious.
The loopshaping methods developed in this book always involve some trial and error, but this
example seems to require a great deal. This would also be true for many other problems of this
complexity with RHP zeros at frequencies between multiple crossover frequencies.
This example illustrates how RHP controller zeros can be eﬀective for problems with multiple
crossovers. What about poles? Theorem 1 appears to be symmetric in the controller RHP poles and
zeros, but this is somewhat misleading since RHP poles have an impact on the need for encirclements
of −1 and hence on the number #z(PC −1).
Nevertheless, in the problem considered in this
section, with perhaps slightly diﬀerent weights, there will typically be multiple crossovers and
#z(PC −1) ≥4, so C can have up to a total of three RHP poles and zeros and still be self-optimal.
Thus we would expect that relatively small changes in the weights could lead to controllers with a
variety of RHP poles and zeros. Recall also that certain plants can only be stabilized with unstable

8.5. FURTHER NOTIONS OF OPTIMALITY
147
controllers, so any problem with such a plant would necessarily have controllers with RHP poles.
On the other hand, the vast majority of feedback control problems in engineering applications have
a single crossover, and controller RHP poles and zeros would clearly be undesirable.
Now we return to the collocated version of this problem and use the characterization of self-
optimality from the preceding subsection to prove that the controller C = 1 is optimal for all
physically possible values of the parameters M, I, l, lu, and k. This is a remarkable robust perfor-
mance result and does not hold in the more general noncollocated case. It illustrates why collocated
control problems are so popular among researchers in control of ﬂexible structures. We have not
focused on this type of parametric uncertainty in this book, because the available results tend not
to be very general. For example, the optimality of C = 1 for this problem depends not only on
the special structure of P but also on the special structure of the performance speciﬁcation. Nev-
ertheless, the methods developed in this book can be useful in studying speciﬁc problems involving
parametric uncertainty, as illustrated by this example.
To prove the optimality of C = 1, note that for all values of the parameters
P(s) =
s
Ms2 + 2k +
l2
us
Is2 + 2kl2 = s

(I + Ml2
u)s2 + 2k(1 + l2)

(Ms2 + 2k)(Is2 + 2kl2)
has all its poles and zeros on the imaginary axis, with poles at
s = ±j
r
2k
M , ±j
r
2kl2
I
and zeros at
s = 0, ±j
s
2k(1 + l2)
(I + Ml2u).
To be physically meaningful, all the parameters must be positive, and the geometry of the problem
restricts the moment of inertia such that
0 < I < Ml2,
so we have that
0 <
r
2k
M <
s
2k(1 + l2)
(I + Ml2u) <
r
2kl2
I
.
Thus the zeros and poles alternate on the imaginary axis and
ReP(jω) = 0,
∀ω.
It is clear from the Nyquist diagram of P that
#z(P + 1) = 0
and
#z(P −1) = 4,
so the controller C = 1 is both stabilizing and self-optimal for all parameter values. Recall that the
weights W1 and W2 that are used to deﬁne self-optimality are those that make |W1S| and |W2T|

148
CHAPTER 8. ADVANCED LOOPSHAPING
all-pass. Clearly, we could use weights that are a constant multiple of these as well. Thus to use
self-optimality to show that C = 1 is optimal for
ψ(C) := ∥(|W1S|2 + |W2T|2)1/2∥∞
with
|W1| = 0.5(|P|2 + 1)1/2,
|W2| = 0.5(|P|−2 + 1)1/2,
we must verify that |W1S| and |W2T| are all-pass. But since ReP(jω) = 0, ∀ω, we have that
|P + 1|2 = |P|2 + 1,
∀s = jω,
and thus
|W1S|2 = 0.25|P|2 + 1
|P + 1|2 = 0.25,
|W2T|2 = 0.25 |P|−2 + 1
|P −1 + 1|2 = 0.25,
as desired. This completes the proof.
What are the implications of this example and the results on self-optimality for loopshaping?
Each of the design methods presented so far—shaping L, S, T, or Q—gives the designer something
handy to manipulate to obtain a controller. In each case, the resulting controller will have to be ex-
amined in the closed-loop system to see if it is satisfactory—every controller results in some tradeoﬀ
between S and T, and the designer must decide if that tradeoﬀmakes sense for a particular problem.
If a reasonable tradeoﬀbetween S and T can be found by any method, and the resulting controller
is self-optimal, then there is no other controller that can uniformly improve on the tradeoﬀ—any
other controller just achieves some other tradeoﬀ. What makes self-optimality so useful is that it
is very easily checked, and the loopshaping methods introduced so far generally yield self-optimal
controllers.
Unfortunately, the designer may ﬁnd that for some problems loopshaping does not easily lead
to a reasonable tradeoﬀbetween competing performance objectives. It is for these problems that
directly solving for an optimal controller is most useful. Optimal controllers are the subject of the
remainder of this book.
Exercises
1. Verify the Venn diagrams in Section 8.5.
2. Prove that if #i(Lo −1) ≥1, then Co is self-optimal.
3. Develop notions of self-optimality that involving S and T separately, and prove results anal-
ogous to Theorem 1.
Notes and References
The problem setup in Section 8.1 is studied in much greater depth in McFarlane and Glover (1990),
who develop an interesting theory of control design using a combination of loopshaping and opti-
mality. For a recent treatment of the control of ﬂexible structures, see Joshi (1989). Controller
design by shaping Q, known in the process control literature as internal model control (IMC), is
developed in detail in Morari and Zaﬁriou (1989). Section 8.5 is based on Lenz et al. (1988).

Chapter 9
Model Matching
This chapter studies a hypothetical control problem called the model-matching problem which will
be used in later chapters for control system design. The mathematics of interpolation theory is used
to solve the model-matching problem.
9.1
The Model-Matching Problem
Let T1(s) and T2(s) be stable proper transfer functions (i.e., functions in S). The model-matching
problem is to ﬁnd a stable transfer function Q(s) to minimize the ∞-norm of T1 −T2Q.
The
interpretation is this: T1 is a model, T2 is a plant, and Q is a cascade controller to be designed so
that T2Q approximates T1. Thus T1 −T2Q is the error transfer function. The transfer function Q
is required to be stable but not necessarily proper (this makes the problem easier). We will assume
that T2 has no zeros on the imaginary axis. Deﬁne the minimum model-matching error
γopt := min ∥T1 −T2Q∥∞,
where the minimum is taken over all stable Qs. It turns out that the minimum is achieved by virtue
of the assumption on T2; a Q achieving the minimum is said to be optimal.
The trivial case of the problem is when T1/T2 is stable, for then the unique optimal Q is
Q = T1/T2 and γopt = 0. The simplest nontrivial case is when T2 has only one zero in the right
half-plane, say at s = s0. If Q is stable and T2Q has ﬁnite ∞-norm (i.e., T2Q ∈S), then by the
maximum modulus theorem
∥T1 −T2Q∥∞≥|T1(s0)|,
so γopt ≥|T1(s0)|. On the other hand, the function
Q = T1 −T1(s0)
T2
(9.1)
is stable and yields the value |T1(s0)| for the model-matching error. The conclusion is that γopt =
|T1(s0)| and (9.1) is an optimal Q, in fact, the unique optimal Q.
Example For
T1(s) =
4
s + 3,
T2(s) =
s −2
(s + 1)3
149

150
CHAPTER 9. MODEL MATCHING
γopt = T1(2) = 4/5 and the optimal Q is
Q(s) = −4(s + 1)3
5(s + 3) .
To solve the problem in the general case we will need the mathematics developed in the next
two sections.
9.2
The Nevanlinna-Pick Problem
Recall that S stands for the space of stable, proper, real-rational functions. Let Sc stand for the
space of stable, proper, complex-rational functions (i.e., the coeﬃcients are permitted to be complex
numbers). For example, the function
(1 −j)s + (2 + 3j)
(0.1 + j)s + (−3 + j)
is in Sc because it is proper and its pole is at s = −0.6931 −3.0693j in the left half-plane. The
∞-norm, maximum magnitude on the imaginary axis, is deﬁned for such functions too.
Let {a1, . . . , an} be a set of points in the open right half-plane, Res > 0, and {b1, . . . , bn} a
set of points in C. For simplicity we shall assume that the points a1, . . . , an are distinct.
The
Nevanlinna-Pick interpolation problem, or the NP problem for short, is to ﬁnd a function G in Sc
satisfying the two conditions
∥G∥∞≤1,
G(ai) = bi,
i = 1, . . . , n.
The latter equation says that G is to interpolate the value bi at the point ai, or in other words the
graph of G is to pass through the point (ai, bi). The constraints are important: G must be stable,
proper, and satisfy ∥G∥∞≤1. The NP problem is said to be solvable if such a function G exists.
It will be convenient to write the problem data as an array, like this:
a1
· · ·
an
b1
· · ·
bn
In fact, the NP problem is not solvable for all data. An obvious necessary condition for solvability
is |bi| ≤1, i = 1, . . . , n. This follows from the maximum modulus theorem: If G belongs to Sc and
satisﬁes G(ai) = bi, then its magnitude equals |bi| at the point s = ai, so its maximum magnitude
in the right half-plane is ≥|bi| (i.e., ∥G∥∞≥|bi|); but if it is also true that ∥G∥∞≤1, then |bi| ≤1.
To state precisely when the NP problem is solvable, we need some elementary concepts and facts
about complex matrices. Let M be a square complex matrix. Its complex-conjugate transpose is
denoted by M∗. If M = M∗, M is said to be a Hermitian matrix. If M is real, it is Hermitian
iﬀit is symmetric. It can be shown that the eigenvalues of a Hermitian matrix are all real. If
M is Hermitian, it is said to be positive semideﬁnite if x∗Mx ≥0 for all complex vectors x, and
positive deﬁnite if x∗Mx > 0 for all nonzero complex vectors x. The notation is M ≥0 and M > 0,
respectively. It is a fact that M ≥0 (respectively, M > 0) iﬀall its eigenvalues are ≥0 (respectively,
> 0).

9.2. THE NEVANLINNA-PICK PROBLEM
151
Example 1 The matrix

2
1 + j
1 −j
4

is Hermitian; notice that the diagonal elements must be real. The eigenvalues are 1.2679 and 4.7321.
Since these are both positive, the matrix is positive deﬁnite.
Associated with the NP problem data
a1
· · ·
an
b1
· · ·
bn
is the n × n matrix Q, whose ijth element is
1 −bibj
ai + aj
.
This is called the Pick matrix. Notice that Q is Hermitian.
Example 2 For the data
6 + j
6 −j
0.1 −0.1j
0.1 + 0.1j
the Pick matrix is

0.0817
0.0814 −0.0119j
0.0814 + 0.0119j
0.0817

,
whose eigenvalues are −0.0005 and 0.1639. Since one is negative, it turns out that the NP problem
is not solvable for these data.
Solvability of the NP problem is completely determined by the Pick matrix. The result is Pick’s
famous theorem:
Theorem 1 The NP problem is solvable iﬀQ ≥0.
Pick’s theorem shows that it is an easy matter to check solvability of the NP problem by
computer: Input the data
a1
· · ·
an
b1
· · ·
bn
form the Pick matrix; compute its eigenvalues; see if the smallest one is nonnegative.
We saw above that a necessary condition for solvability is |bi| ≤1 for all i. So it must be that
this condition is implied by the condition Q ≥0. This is indeed the case: If Q ≥0, then each
diagonal element of Q is ≥0, that is,
1 −|bi|2
2Reai
≥0.

152
CHAPTER 9. MODEL MATCHING
Since Reai > 0, this implies that
1 −|bi|2 ≥0
(i.e., |bi| ≤1).
In the next section is given a procedure for constructing a solution to the NP problem when it
is solvable. The remainder of this section contains a proof of the necessity part of Pick’s theorem, a
proof that illustrates in system-theoretic terms how the Pick matrix arises. A system is said to be
dissipative if it dissipates energy—the outgoing energy (2-norm squared) is less than or equal to the
incoming energy. The following proof shows that Pick’s theorem says something about dissipative
systems.
Since both time and frequency domains appear, the ˆ-convention is in force.
Also, complex-
valued signals and complex-rational transfer functions are used. There is no obstacle to extending
the material of Chapter 2 to the complex case.
The proof is separated into three lemmas.
Lemma 1 Consider a linear system with input signal u(t) of ﬁnite 2-norm, output signal y(t), and
transfer function ˆG(s) in Sc. If ∥ˆG∥∞≤1, then
Z 0
−∞
|y(t)|2dt ≤
Z 0
−∞
|u(t)|2dt.
Proof Deﬁne a new input
u1(t) :=
 u(t),
if t ≤0
0,
if t > 0
and let the corresponding output be y1(t). It follows from entry (1,1) in Table 2.2 that
Z ∞
−∞
|y1(t)|2dt ≤
Z ∞
−∞
|u1(t)|2dt.
Since u1 = 0 for positive time, this implies that
Z ∞
−∞
|y1(t)|2dt ≤
Z 0
−∞
|u1(t)|2dt
and hence that
Z 0
−∞
|y1(t)|2dt ≤
Z 0
−∞
|u1(t)|2dt.
But y = y1 and u = u1 for negative time. ■
The second lemma shows that complex exponentials are eigenfunctions for linear systems.
Lemma 2 Consider a linear system with transfer function ˆG(s) in Sc. Apply the input signal
u(t) = eat,
−∞< t ≤0
with Rea > 0. Then the output signal is
y(t) = ˆG(a)u(t),
−∞< t ≤0.

9.2. THE NEVANLINNA-PICK PROBLEM
153
Proof Use the convolution equation: For every t ≤0,
y(t)
=
Z ∞
0
G(τ)u(t −τ)dτ
=
Z ∞
0
G(τ)ea(t−τ)dτ
=
ˆG(a)eat. ■
The ﬁnal lemma is the necessity part of Pick’s theorem.
Lemma 3 If the NP problem is solvable, then Q ≥0.
Proof To simplify notation, assume there are only two interpolation points (i.e., n = 2). Let ˆG be
a solution to the NP problem. For arbitrary complex numbers c1 and c2 apply the input signal
u(t) = c1ea1t + c2ea2t,
−∞< t ≤0
to the system with transfer function ˆG. By Lemma 2 and linearity the output signal is
y(t)
=
c1 ˆG(a1)ea1t + c2 ˆG(a2)ea2t
=
c1b1ea1t + c2b2ea2t.
Starting with Lemma 1, we get in succession
Z 0
−∞
|y(t)|2dt
≤
Z 0
−∞
|u(t)|2dt,
Z 0
−∞
|c1b1ea1t + c2b2ea2t|2dt
≤
Z 0
−∞
|c1ea1t + c2ea2t|2dt,
and thus
Z 0
−∞
h
c1c1(1 −b1b1)e(a1+a1)t + c1c2(1 −b1b2)e(a1+a2)t
+c2c1(1 −b2b1)e(a2+a1)t + c2c2(1 −b2b2)e(a2+a2)ti
dt ≥0.
This integral can be evaluated to give
c1c1
1 −b1b1
a1 + a1
+ c1c2
1 −b1b2
a1 + a2
+ c2c1
1 −b2b1
a2 + a1
+ c2c2
1 −b2b2
a2 + a2
≥0,
which is equivalent to
x∗Qx ≥0,
where
x :=
 c1
c2

.
Since c1 and c2 were arbitrary, it must be that Q ≥0. ■

154
CHAPTER 9. MODEL MATCHING
9.3
Nevanlinna’s Algorithm
This section presents a procedure to construct a solution of the NP problem when it is solvable.
The procedure is developed inductively: First, the case n = 1 is solved; then the case of n points is
reduced to the case of n −1 points.
Let us begin by letting D denote the open unit disk, |z| < 1, and D the closed unit disk, |z| ≤1.
A M¨obius function has the form
Mb(z) = z −b
1 −zb,
where |b| < 1. Following is a list of some properties of M¨obius functions (you should check these):
1. Mb has a zero at z = b and a pole at z = 1/b. Thus Mb is analytic in D.
2. The magnitude of Mb equals 1 on the unit circle.
3. Mb maps D onto D and the unit circle onto the unit circle.
4. The inverse map is
M−1
b
(z) = z + b
1 + zb
(i.e., M−1
b
= M−b). So the inverse map is a M¨obius function too.
We will also need the all-pass function
Aa(s) := s −a
s + a,
Rea > 0.
With the aid of these functions we can solve the NP problem for the data
a1
b1
There are two cases.
Case 1 |b1| = 1
A solution is G(s) = b1. By the maximum modulus theorem this solution is
unique.
Case 2 |b1| < 1 There are an inﬁnite number of solutions:
Lemma 4 The set of all solutions is
{G : G(s) = M−b1[G1(s)Aa1(s)], G1 ∈Sc, ∥G1∥∞≤1} .
If G1 is an all-pass function, so is G.

9.3. NEVANLINNA’S ALGORITHM
155
Proof Let G1 ∈Sc, ∥G1∥∞≤1, and deﬁne G as
G(s) = M−b1[G1(s)Aa1(s)].
Thus G equals the composition of the two functions
s
7→
G1(s)Aa1(s),
z
7→
M−b1(z).
The ﬁrst is analytic in the closed right half-plane and maps it into the closed disk D; the second is
analytic in D and maps it back into D. It follows that G ∈Sc and ∥G∥∞≤1. Also, G interpolates
b1 at a1:
G(a1) = M−b1[G1(a1)Aa1(a1)] = M−b1(0) = b1.
Thus G solves the NP problem. Moreover, if G1 is an all-pass function, then so is G1Aa1, hence so
is G (because M−b1 maps the unit circle onto itself).
Conversely, suppose that G solves the NP problem. Deﬁne G1 so that
G(s) = M−b1[G1(s)Aa1(s)],
that is,
G1(s) = Mb1[G(s)]
Aa1(s)
.
The function Mb1[G(s)] belongs to Sc, has ∞-norm ≤1, and has a zero at s = a1. Therefore,
G1 ∈Sc and ∥G1∥∞≤1. ■
Example 1 For the interpolation data
2
0.6
the formula in the lemma gives
G(s) =
G1(s)s −2
s + 2 + 0.6
1 + 0.6G1(s)s −2
s + 2
.
The all-pass function G1(s) = (s −1)/(s + 1) results in
G(s) = s2 −0.75s + 2
s2 + 0.75s + 2.
Now we turn to the NP problem with n data points, the problem being assumed solvable, and
see how to reduce it to the case of n −1 points. Again, there are two cases.
Case 1 |b1| = 1 Since the problem is solvable, by the maximum modulus theorem it must be that
G(s) = b1 is the unique solution (and hence that b1 = · · · = bn).

156
CHAPTER 9. MODEL MATCHING
Case 2 |b1| < 1 Pose a new problem, labeled the NP′ problem, with the n −1 data points
a2
· · ·
an
b′
2
· · ·
b′
n
where b′
i := Mb1(bi)/Aa1(ai).
Lemma 5 The set of all solutions to the NP problem is given by the formula
G(s) = M−b1[G1(s)Aa1(s)],
where G1 ranges over all solutions to the NP′ problem. If G1 is all-pass, so is G.
Proof G solves the NP problem iﬀ
G ∈Sc, ∥G∥∞≤1, G(a1) = b1, and G(ai) = bi,
i = 2, . . . , n.
From Lemma 4, the set of all Gs satisfying the ﬁrst three conditions is
{G : G(s) = M−b1[G1(s)Aa1(s)], G1 ∈Sc, ∥G1∥∞≤1} .
Then G satisﬁes the fourth condition iﬀ
G1(ai) = Mb1(bi)
Aa1(ai),
i = 2, . . . , n
(i.e., G1 solves the NP′ problem). ■
It follows by induction that the NP problem always has an all-pass solution.
Example 2 Consider the NP problem for the data
a1
a2
a3
b1
b2
b3
=
1
2
3
1
2
1
3
1
4
The Pick matrix is


0.3750
0.2778
0.2188
0.2778
0.2222
0.1833
0.2188
0.1833
0.1563

.
The smallest eigenvalue equals 0.0004. Since this is positive, the NP problem is solvable.
A solution can be obtained by reduction to one interpolation point by applying Lemma 5 twice.
First, reduce to the NP′ problem with two points:
a2
a3
b′
2
b′
3
=
2
3
−0.6
−0.5714
Here b′
i := Mb1(bi)/Aa1(ai), i = 2, 3. Second, reduce to the NP′′ problem with only one point:
a3
b′′
3
=
3
0.2174

9.3. NEVANLINNA’S ALGORITHM
157
Here b′′
3 := Mb′
2(b′
3)/Aa2(a3).
Now solve the problems in reverse order. By Lemma 4 the solution of the NP′′ problem is
G2(s) = M−b′′
3 [G3(s)Aa3(s)],
where G3 is an arbitrary function in Sc of ∞-norm ≤1. Let’s take G3(s) = 1, the simplest all-pass
function. Then
G2(s) = 1.2174s −2.3478
1.2174s + 2.3478.
The induced solution to the NP′ problem is
G1(s) = M−b′
2[G2(s)Aa2(s)] = 0.4870s2 −7.6522s + 1.8783
0.4870s2 + 7.6522s + 1.8783.
Finally, the solution to the NP problem is
G(s) = M−b1[G1(s)Aa1(s)] = 0.7304s3 −4.0696s2 + 14.2957s −0.9391
0.7304s3 + 4.0696s2 + 14.2957s + 0.9391.
Notice that the degree of the numerator and denominator of G equals 3, the number of data points.
In general, there always exists an all-pass solution of degree ≤n.
In our application of NP theory to the model-matching problem, the data
a1
· · ·
an
b1
· · ·
bn
will have conjugate symmetry; that is, if (ai, bi) appears, so will the conjugate pair (ai, bi). Then
we will want the solution G to be real-rational instead of complex. Suppose that the data do have
conjugate symmetry and that G is a solution in Sc. It can be written uniquely as
G(s) = GR(s) + jGI(s),
where GR and GI both are real-rational. Then GR belongs to S and is also a solution to the NP
problem (the proof is left as an exercise).
Example 3 For the data
5 + 2j
5 −2j
0.1 −0.1j
0.1 + 0.1j
the NP problem is solvable (the smallest eigenvalue of the Pick matrix equals 0.0051). Starting
from the all-pass function 1, Nevanlinna’s algorithm produces the all-pass solution
G(s) = (0.5268 + 0.1213j)s2 −(9 + j)s + (47.1073 + 1.1410j)
(0.5268 −0.1213j)s2 + (9 −j)s + (47.1073 −1.1410j).
Let G denote the function obtained from G by conjugating all coeﬃcients. The function GR is then
GR = 1
2(G + G),
that is,
GR(s) =
0.2628s4 −30.6418s2 + 2217.7975
0.2923s4 + 9.7255s3 + 131.9119s2 + 850.2137s + 2220.4012.
This solution is not all-pass.

158
CHAPTER 9. MODEL MATCHING
9.4
Solution of the Model-Matching Problem
Now let’s see how to use NP theory to solve the model-matching problem. For simplicity we will
assume that T2 has no repeated zeros in the right half-plane. The minimum model-matching error,
γopt, equals the minimum γ such that
∥T1 −T2Q∥∞≤γ
for some stable Q. Fix γ > 0 and consider the mapping Q 7→G deﬁned by
G = 1
γ (T1 −T2Q).
If Q is stable, so is G, but the converse is not always true. A stable function G must satisfy certain
conditions in order that Q be stable. To see what they are, let {zi : i = 1, . . . , n} denote the zeros
of T2 in Res > 0. If Q is stable, then G satisﬁes the interpolation conditions
G(zi) = 1
γ T1(zi),
i = 1, . . . , n.
You can check that, conversely, if G is stable and satisﬁes these interpolation conditions, then Q is
stable.
Therefore, γopt equals the minimum γ so that there exists a function G in S satisfying the
conditions
∥G∥∞≤1,
G(zi) = 1
γ T1(zi),
i = 1, . . . , n.
This is precisely a Nevanlinna-Pick problem with data
a1
· · ·
an
γ−1b1
· · ·
γ−1bn
where ai := zi and bi := T1(zi). The associated Pick matrix equals
A −γ−2B,
where the ijth elements of A and B are, respectively,
1
ai + aj
,
bibj
ai + aj
.
From Pick’s theorem we can now conclude that γopt equals the minimum γ such that A−γ−2B ≥0.
Both A and B are Hermitian. Furthermore, it can be proved that A is positive deﬁnite because
the ais are distinct. Such a matrix has a positive deﬁnite squareroot (i.e., a matrix A1/2 satisfying
A1/2A1/2 = A). The inverse of this squareroot is denoted A−1/2.
The next lemma, a simple result in matrix theory, gives an explicit way to compute γopt.
Lemma 6 γopt equals the squareroot of the largest eigenvalue of the matrix A−1/2BA−1/2.

9.4. SOLUTION OF THE MODEL-MATCHING PROBLEM
159
Tracing backwards, we get the following procedure for solving the model-matching problem.
Procedure
Input: T1, T2
Step 1 Determine {zi : i = 1, . . . , n}, the zeros of T2 in Res > 0.
Step 2 Deﬁne
bi := T1(zi),
i = 1, . . . , n
and form the matrices
A :=

1
zi + zj

,
B :=
 bibj
zi + zj

.
Step 3 Compute γopt as the squareroot of the largest eigenvalue of A−1/2BA−1/2.
Step 4 Solve the NP problem with data
z1
· · ·
zn
γ−1
optb1
· · ·
γ−1
optbn
Denote the solution by G.
Step 5 Set
Q := T1 −γoptG
T2
.
The NP problem in Step 4 has a unique, all-pass solution. Thus, for the optimal Q the error
transfer function T1 −T2Q equals γopt times an all-pass function.
Example 4 The procedure applied to
T1(s) =
s + 1
10s + 1,
T2(s) = (s −1)(s −5)
(s + 2)2
goes like this:
Step 1
z1 = 1,
z2 = 5
Step 2
b1 = 2
11,
b2 = 2
17
A =

0.5
0.1667
0.1667
0.1

,
B =
 0.0165
0.0036
0.0036
0.0014


160
CHAPTER 9. MODEL MATCHING
Step 3
γopt = 0.2021
Step 4
z1
z2
γ−1
optb1
γ−1
optb2
=
1
5
0.8997
0.5821
G(s) = −1.0035s + 18.9965
1.0035s + 18.9965
Step 5
Q(s) = 0.3021s2 + 1.2084s + 1.2084
s2 + 19.0308s + 1.8931
9.5
State-Space Solution (Optional)
For completeness, this section presents a state-space procedure for solving the model-matching
problem. The underlying theory is beyond the scope of this book.
Step 1 Factor T2 as the product of an all-pass factor and a minimum-phase factor:
T2 = T2apT2mp.
Step 2 Deﬁne
R := T1
T2ap
,
factor R as R = R1 + R2 with R1 strictly proper and all poles in Res > 0 and R2 ∈S, and
ﬁnd a minimal realization
R1(s) =
 A
B
C
0

.
Step 3 Solve the Lyapunov equations
ALc + LcA′
=
BB′,
A′Lo + LoA
=
C′C.
Step 4 Find the maximum eigenvalue λ2 of LcLo and a corresponding eigenvector w.
Step 5 Deﬁne
f(s)
=
 A
w
C
0

,
g(s)
=
 −A′
λ−1Low
B′
0

,
X
=
R −λf
g .

9.5. STATE-SPACE SOLUTION (OPTIONAL)
161
Step 6 Then γopt = λ and the optimal Q = X/T2mp.
Example For the same data as in Example 4 in the preceding section, the procedure yields the
following results.
Step 1
T2ap(s) = (s −1)(s −5)
(s + 1)(s + 5),
T2mp(s) = (s + 1)(s + 5)
(s + 1)2
Step 2
R(s) =
(s + 1)2(s + 5)
(10s + 1)(s −1)(s −5)
A =
 1
0
0
5

,
B =
 −6
11
30
17

,
C =

1
1

Step 3
Lc =

0.1488
−0.1604
−0.1604
0.3114

,
Lo =

0.5
0.1667
0.1667
0.1

Step 4
λ = 0.2021,
w =

1
−0.7769

Step 5
f(s) = 0.2231s −4.223
(s −1)(s −5) ,
g(s) = −0.2231s −4.223
(s + 1)(s + 5)
X(s) = 3.021
(s + 1)(s + 5)
(10s + 1)(s + 18.93)
Step 6
γopt = 0.2021,
Q(s) = 3.021
(s + 2)2
(10s + 1)(s + 18.93)
Exercises
1. Solve the model-matching problem for
T1(s) =
s
s + 10,
T2(s) =
s −1
s2 + s + 1.

162
CHAPTER 9. MODEL MATCHING
2. For the data
1
1 −j
j
−1 + 2j
form the Pick matrix and compute its eigenvalues.
3. Find the minimum γ for which there exists a function G in Sc such that
∥G∥∞≤γ,
G(1) = 2,
G(2) = 10.
4. Solve the model-matching problem for
T1(s) =
1
s + 1,
T2(s) = s2 −s + 1
(s + 2)3 .
5. Compute a real-rational solution to the NP problem for the data
1
1 −j
1 + j
0.1
0.2j
−0.2j
6. Let A and B be n × n complex Hermitian matrices with A > 0. Prove that A −γ−2B ≥0 iﬀ
γ2 is ≥the largest eigenvalue of A−1/2BA−1/2. (This proves Lemma 6.)
Notes and References
The NP problem is named after the mathematicians R. Nevanlinna and G. Pick, whose work dates
from 1916-1919. For a complete proof of Pick’s theorem together with additional references, see
Garnett (1981).
In the model-matching problem, zeros of T2 on the imaginary axis lead to boundary interpolation
in the NP problem (i.e., some of ais are on the imaginary axis). This complicates the NP problem;
a reference for this case is Khargonekar and Tannenbaum (1985).
The proof of necessity in Section 9.2 is from Youla and Saito (1967), and Nevanlinna’s algo-
rithm is taken from Walsh (1969). NP theory was ﬁrst used in the context of control problems by
Tannenbaum (1980, 1981). The state-space procedure in Section 9.5 is from Francis (1987), which
in turn is adapted from Sarason (1967) and Silverman and Bettayeb (1980).

Chapter 10
Design for Performance
The performance criterion ∥W1S∥∞< 1 was introduced in Section 3.4.
The associated design
problem is to ﬁnd a proper C for which the feedback system is internally stable and ∥W1S∥∞< 1.
When does such a C exist and how can it be computed?
These questions are easy when the
inverse of the plant transfer function is stable. When the inverse is unstable, the questions are more
interesting. The solutions presented in this chapter use model-matching theory.
10.1
P −1 Stable
We assume in this section that P has no zeros in Res ≥0, or in other words, P −1 is stable. The
weighting function W1 is assumed to be stable and strictly proper. The latter condition is not too
serious a loss of generality. We will see that under these conditions it is always possible, indeed
quite easy, to design a proper C which is internally stabilizing and makes ∥W1S∥∞< 1.
Let k be a positive integer and τ a positive real number, and consider the transfer function
J(s) :=
1
(τs + 1)k .
Sketch the Bode plot of J: The magnitude starts out at 1, is relatively ﬂat out to the corner
frequency ω = 1/τ, and then rolls oﬀto −∞with slope −k; the phase starts out at 0, is relatively
ﬂat up to, say, ω = 0.1/τ, and then rolls oﬀto −kπ/2 radians. So for low frequency, J(jω) ≈1.
This function has the useful property that it approximates 1 beside a strictly proper function.
Lemma 1 If G is stable and strictly proper, then
lim
τ→0 ∥G(1 −J)∥∞= 0.
Proof Let ǫ > 0 and ω1 > 0. By the argument above regarding the Bode plot of J, if τ is suﬃciently
small, then the Nyquist plot of J lies in the disk with center 1, radius ǫ for ω ≤ω1, and in the disk
with center 0, radius 1 for ω > ω1. Now ∥G(1 −J)∥∞equals the maximum of
max
ω≤ω1 |G(jω)[1 −J(jω)]|
and
max
ω>ω1 |G(jω)[1 −J(jω)]|.
163

164
CHAPTER 10. DESIGN FOR PERFORMANCE
The ﬁrst of these is bounded above by ǫ∥G∥∞, and the second by
∥1 −J∥∞max
ω>ω1 |G(jω)|.
Since
∥1 −J∥∞≤∥1∥∞+ ∥J∥∞= 2,
we have
∥G(1 −J)∥∞≤max

ǫ∥G∥∞, 2 max
ω>ω1 |G(jω)|

.
This holds for τ suﬃciently small. But the right-hand side can be made arbitrarily small by suitable
choice of ǫ and ω1 because
lim
ω1→∞max
ω>ω1 |G(jω)| = |G(j∞)| = 0.
We conclude that for every δ > 0, if τ is small enough, then
∥G(1 −J)∥∞≤δ.
This is the desired conclusion. ■
We’ll develop the design procedure ﬁrst with the additional assumption that P is stable. By
Theorem 5.1 the set of all internally stabilizing Cs is parametrized by the formula
C =
Q
1 −PQ,
Q ∈S.
Then W1S is given in terms of Q by
W1S = W1(1 −PQ).
To make ∥W1S∥∞< 1 we are prompted to set Q = P −1. This is indeed stable, by assumption, but
not proper, hence not in S. So let’s try Q = P −1J with J as above and the integer k just large
enough to make P −1J proper (i.e., k equals the relative degree of P). Then
W1S = W1(1 −J),
whose ∞-norm is < 1 for suﬃciently small τ, by Lemma 1.
In summary, the design procedure is as follows.
Procedure: P and P −1 Stable
Input: P, W1
Step 1 Set k = the relative degree of P.

10.1. P −1 STABLE
165
Step 2 Choose τ so small that
∥W1(1 −J)∥∞< 1,
where
J(s) :=
1
(τs + 1)k .
Step 3 Set Q = P −1J.
Step 4 Set C = Q/(1 −PQ).
When P is unstable, the parametrization in Theorem 5.2 is used.
Procedure: P −1 Stable
Input: P, W1
Step 1 Do a coprime factorization of P: Find four functions in S satisfying the equations
P = N
M ,
NX + MY = 1.
Step 2 Set k = the relative degree of P.
Step 3 Choose τ so small that
∥W1MY (1 −J)∥∞< 1,
where
J(s) :=
1
(τs + 1)k .
Step 4 Set Q = Y N−1J.
Step 5 Set C = (X + MQ)/(Y −NQ).
Example Consider the unstable plant and weighting function
P(s) =
1
(s −2)2 ,
W1(s) = 100
s + 1.
This weight has bandwidth 1 rad/s, so it might be used to get good tracking (i.e., approximately
1% tracking error, up to this frequency). The previous procedure for these data goes as follows:

166
CHAPTER 10. DESIGN FOR PERFORMANCE
Step 1 First, do a coprime factorization of P over S:
N(s)
=
1
(s + 1)2 ,
M(s)
=
(s −2)2
(s + 1)2 ,
X(s)
=
27s −1
s + 1,
Y (s)
=
s + 7
s + 1.
Step 2 k = 2
Step 3 Choose τ so that the ∞-norm of
100(s −2)2(s + 7)
(s + 1)4

1 −
1
(τs + 1)2

is < 1. The norm is computed for decreasing values of τ:
τ
∞-Norm
10−1
199.0
10−2
19.97
10−3
1.997
10−4
0.1997
So take τ = 10−4.
Step 4
Q(s) = (s + 1)(s + 7)
(10−4s + 1)2
Step 5
C(s) = 104
(s + 1)3
s(s + 7)(10−4s + 2)
This section concludes with a result stated but not proved in Section 6.2.
It concerns the
performance problem where the weight W1 satisﬁes
|W1(jω)| =





1
ǫ ,
ω1 ≤ω ≤ω2
1
δ ,
else.
Thus the criterion ∥W1S∥∞< 1 is equivalent to the conditions
|S(jω)| < ǫ,
ω1 ≤ω ≤ω2
|S(jω)| < δ,
else.
(10.1)

10.1. P −1 STABLE
167
Lemma 2 If P −1 is stable, then for every ǫ > 0 and δ > 1, there exists a proper C such that the
feedback system is internally stable and (10.1) holds. 1
Proof The idea is to approximately invert P over the frequency range [0, ω2] while rolling oﬀfast
enough at higher frequencies. From Theorem 5.2 again, the formula for all internally stabilizing
proper controllers is
C = X + MQ
Y −NQ ,
Q ∈S.
For such C
S = M(Y −NQ).
(10.2)
Now ﬁx ǫ > 0 and δ > 1. We may as well suppose that ǫ < 1. Choose c > 0 so small that
c∥MY ∥∞< ǫ,
(10.3)
(1 + c)2 < δ.
(10.4)
Since P is strictly proper, so is N. This fact together with the equation
NX + MY = 1
shows that
M(j∞)Y (j∞) = 1.
Since |M(jω)Y (jω)| is a continuous function of ω, it is possible to choose ω3 ≥ω2 such that
|M(jω)Y (jω)| ≤1 + c,
∀ω ≥ω3.
(10.5)
The assumption on P implies that N −1 is stable (but not proper). Choose a function V in S
with the following three properties:
1. V N −1 is proper.
2. |1 −V (jω)| ≤c,
∀ω ≤ω3.
3. ∥1 −V ∥∞≤1 + c.
The idea behind the choice of V can be explained in terms of its Nyquist plot: It should lie in the
disk with center 1, radius c up to frequency ω3 (property 2) and in the disk with center 1, radius
1 + c thereafter (property 3). In addition, V should roll oﬀfast enough so that V N −1 is proper. It
is left as an exercise to convince yourself that such a V exists—a function of the form
1
(τ1s + 1)(τ2s + 1)k
will work.
1The assumption on P in Lemma 2 is slightly stronger than necessary; see the statement in Section 6.2.

168
CHAPTER 10. DESIGN FOR PERFORMANCE
Finally, take Q to be
Q := V N −1Y.
Substitution into (10.2) gives
S = MY (1 −V ).
Thus for ω ≤ω3
|S(jω)|
≤
c∥MY ∥∞
from proprty 2
<
ǫ
from (10.3)
and for ω > ω3
|S(jω)|
≤
(1 + c)|M(jω)Y (jω)|
from property 3
≤
(1 + c)2
from (10.5)
<
δ
from (10.4). ■
10.2
P −1 Unstable
We come now to the ﬁrst time in this book that we need a nonclassical method, namely, interpolation
theory. To simplify matters we will assume in this section that
• P has no poles or zeros on the imaginary axis, only distinct poles and zeros in the right
half-plane, and at least one zero in the right half-plane (i.e., P −1 is unstable).
• W1 is stable and strictly proper.
It would be possible to relax these assumptions, but the development would be messier.
To motivate the procedure to follow, let’s see roughly how the design problem of ﬁnding an
internally stabilizing C so that ∥W1S∥∞< 1 can be translated into an NP problem. The deﬁnition
of S is
S =
1
1 + PC .
For C to be internally stabilizing it is necessary and suﬃcient that S ∈S and PC have no right
half-plane pole-zero cancellations (Theorem 3.2). Thus, S must interpolate the value 1 at the right
half-plane zeros of P and the value 0 at the right half-plane poles (see also Section 6.1); that is, S
must satisfy the conditions
S(z)
=
1 for z a zero of P in Res > 0,
S(p)
=
0 for p a pole of P in Res > 0.
The weighted sensitivity function G := W1S must therefore satisfy
G(z)
=
W1(z) for z a zero of P in Res > 0,
G(p)
=
0 for p a pole of P in Res > 0.

10.2. P −1 UNSTABLE
169
So the requirement of internal stability imposes interpolation constraints on G. The performance
spec ∥W1S∥∞< 1 translates into ∥G∥∞< 1. Finally, the condition S ∈S requires that G be
analytic in the right half-plane.
One approach to the design problem might be to ﬁnd a function G satisfying these conditions,
then to get S, and ﬁnally to get C by back-substitution. This has a technical snag because the
requirement that C be proper places an additional constraint on G not handled by our NP theory
of the Chapter 9. For this reason we proceed via controller parametrization.
Bring in again a coprime factorization of P:
P = N
M ,
NX + MY = 1.
The controller parametrization formula is
C = X + MQ
Y −NQ ,
Q ∈S,
and for such C the weighted sensitivity function is
W1S = W1M(Y −NQ).
The parameter Q must be both stable and proper. Our approach is ﬁrst to drop the properness
requirement and ﬁnd a suitable parameter, say, Qim, which is improper but stable, and then to get a
suitable Q by rolling Qim oﬀat high frequency. The reason this works is that W1 is strictly proper,
so there is no performance requirement at high frequency. The method is outlined as follows:
Procedure
Input: P, W1
Step 1 Do a coprime factorization of P: Find four functions in S satisfying the equations
P = N
M ,
NX + MY = 1.
Step 2 Find a stable function Qim such that
∥W1M(Y −NQim)∥∞< 1.
Step 3 Set
J(s) :=
1
(τs + 1)k ,
where k is just large enough that QimJ is proper and τ is just small enough that
∥W1M(Y −NQimJ)∥∞< 1.
Step 4 Set Q = QimJ.

170
CHAPTER 10. DESIGN FOR PERFORMANCE
Step 5 Set C = (X + MQ)/(Y −NQ).
That Step 3 is feasible follows from the equation
W1M(Y −NQimJ) = W1M(Y −NQim)J + W1MY (1 −J).
The ﬁrst term on the right-hand side has ∞-norm less than 1 from Step 2 and the fact that
∥J∥∞≤1, while the ∞-norm of the second term goes to 0 as τ goes to 0 by Lemma 1.
Step 2 is the model-matching problem, ﬁnd a stable function Qim to minimize
∥T1 −T2Qim∥∞,
where T1 := W1MY and T2 := W1MN. Step 2 is feasible iﬀγopt, the minimum model-matching
error, is < 1.
10.3
Design Example: Flexible Beam
This section presents an example to illustrate the procedure of the preceding section. The example
is based on a real experimental setup at the University of Toronto.
The control system, depicted in Figure 10.1, has the following components: a ﬂexible beam, a
high-torque dc motor at one end of the beam, a sonar position sensor at the other end, a digital
computer as the controller with analog-to-digital interface hardware, a power ampliﬁer to drive the
motor, and an antialiasing ﬁlter. The objective is to control the position of the sensed end of the
beam.
PC
D/A
amp
motor
beam
A/D
ﬁlter
sensor
-
-
-
-
-



6
Figure 10.1: Flexible beam setup.
A plant model was obtained as follows. The beam is pinned to the motor shaft and is free at the
sensed end. First the beam itself was modeled as an ideal Euler-Bernoulli beam with no damping;
this yielded a partial diﬀerential equation model, reﬂecting the fact that the physical model of the
beam has an inﬁnite number of modes. The model is therefore linear but inﬁnite-dimensional. The
corresponding transfer function from torque input at the motor end to tip deﬂection at the sensed
end has the form
∞
X
i=0
ci
s2 + ω2
i
.

10.3. DESIGN EXAMPLE: FLEXIBLE BEAM
171
Then damping was introduced, yielding the form
∞
X
i=0
ci
s2 + 2ζiωis + ω2
i
.
The ﬁrst term is c0/s2 and corresponds to the rigid-body slewing motion about the pinned end.
The second term,
c1
s2 + 2ζ1ω1s + ω2
1
,
corresponds to the ﬁrst ﬂexible mode. And so on. The motion was found to be adequately modeled
by the ﬁrst four ﬂexible modes. Then the damping ratios and natural frequencies were determined
experimentally.
Finally, the ampliﬁer, motor, and sensor were introduced into the model. The
antialiasing ﬁlter was ignored for the purpose of design.
For simplicity we shall take the plant transfer function to be
P(s) =
−6.4750s2 + 4.0302s + 175.7700
s(5s3 + 3.5682s2 + 139.5021s + 0.0929).
The poles are
0, −0.0007, −0.3565 ± 5.2700j.
The ﬁrst two poles correspond to the rigid-body motion; the one at s = −0.0007 has been perturbed
away from the origin by the back EMF in the motor. The two complex poles correspond to the ﬁrst
ﬂexible mode, the damping ratio being 0.0675. The zeros are
−4.9081, 5.5308.
Because of the zero at s = 5.5308 the plant is non-minimum phase, reﬂecting the fact that the
actuator (the motor) and the sensor are not located at the same point on the beam. The procedure
of the preceding section requires no poles on the imaginary axis, so the model is (harmlessly)
perturbed to
P(s) =
−6.4750s2 + 4.0302s + 175.7700
5s4 + 3.5682s3 + 139.5021s2 + 0.0929s + 10−6 .
A common way to specify desired closed-loop performance is by a step response test. For this
ﬂexible beam the spec is that a step reference input (r) should produce a plant output (y) satisfying
settling time
≈
8s,
overshoot
≤
10%.
We will accomplish this by shaping T(s), the transfer function from r to y, so that it approximates
a standard second-order system: The ideal T(s) is
Tid(s) :=
ω2
n
s2 + 2ζωns + ω2n
.

172
CHAPTER 10. DESIGN FOR PERFORMANCE
A settling time of 8 s requires
4.6
ζωn
≈8
and an overshoot of 10% requires
exp
 
−ζπ
p
1 −ζ2
!
= 0.1.
The solutions are ζ = 0.5912 and ωn = 0.9583. Let’s round to ζ = 0.6 and ωn = 1. So the ideal
T(s) is
Tid(s) =
1
s2 + 1.2s + 1.
Then the ideal sensitivity function is
Sid(s) := 1 −Tid(s) =
s(s + 1.2)
s2 + 1.2s + 1.
Now take the weighting function W1(s) to be Sid(s)−1, that is,
W1(s) = s2 + 1.2s + 1
s(s + 1.2)
.
The rationale for this choice is a rough argument that goes as follows.
Consider Step 2 of the
procedure in the preceding section; from it the function
F := W1M(Y −NQim)
equals a constant times an all-pass function. The procedure then rolls oﬀQim to result in the
weighted sensitivity function
W1S := W1M(Y −NQimJ).
So W1S ≈F except at high frequency, that is,
S ≈FSid.
Now F behaves approximately like a time delay except at high frequency (this is a property of
all-pass functions). So we arrive at the rough approximation
S ≈(time delay) × Sid.
Hence our design should produce
actual step response ≈delayed ideal step response.
One further adjustment is required in the problem setup: W1 must be stable and strictly proper,
so the function above is modiﬁed to
W1(s) =
s2 + 1.2s + 1
(s + 0.001)(s + 1.2)(0.001s + 1).
The procedure can now be applied.

10.3. DESIGN EXAMPLE: FLEXIBLE BEAM
173
Step 1 Since P ∈S we take N = P, M = 1, X = 0, Y = 1.
Step 2 The model-matching problem is to minimize
∥W1M(Y −NQim)∥∞= ∥W1(1 −PQim)∥∞.
Since P has only one right half-plane zero, at s = 5.5308, we have from Section 9.1
min ∥W1(1 −PQim)∥∞= |W1(5.5308)| = 1.0210.
Thus the spec ∥W1S∥∞< 1 is not achievable for this P and W1. Let us scale W1 as
W1 ←
0.9
1.0210W1.
Then |W1(5.5308)| = 0.9 and the optimal Qim is
Qim = W1 −0.9
W1P
,
that is,
Qim(s) = s(0.0008s5 + 0.0221s4 + 0.1768s3 + 0.7007s2 + 3.8910s + 0.0026)
s3 + 6.1081s2 + 6.8897s + 4.9801
.
Step 3 Set
J(s) :=
1
(τs + 1)3 .
Compute ∥W1(1 −PQimJ)∥∞for decreasing values of τ until the norm is < 1:
τ
∞-Norm
0.1
1.12
0.05
1.01
0.04
0.988
Take τ = 0.04.
Step 4 Q = QimJ
Step 5 C = Q/(1 −PQ)
A Bode magnitude plot of the resulting sensitivity function is shown in Figure 10.2.
Figure 10.3
shows the step response of the plant output together with the ideal step response (i.e., that of Tid).
The performance specs are met.
The design above, while achieving the step response goal, may not be satisfactory for other
reasons; for example, internal signals may be too large (in fact, for this design the input to the
power ampliﬁer would saturate during the step response test). The problem is that we have placed
no limits on controller gain or bandwidth. We return to this example and see how to correct this
deﬁciency in Chapter 12.
Another disadvantage of the design above is that C is of high order.
The common way to
alleviate this is to approximate Q by a lower-order transfer function (it is diﬃcult to reduce C
directly because of the internal stability constraint, whereas Q only has to be stable and proper).

174
CHAPTER 10. DESIGN FOR PERFORMANCE
10-3
10-2
10-1
100
101
10-5
10-4
10-3
10-2
10-1
100
101
102
103
104
Figure 10.2: Bode plot of |S|.
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
0
1
2
3
4
5
6
7
8
9
10
Figure 10.3: Actual (solid) and ideal (dash) step responses.

10.4. 2-NORM MINIMIZATION
175
10.4
2-Norm Minimization
The subject of this section is minimization of the 2-norm of some designated closed-loop transfer
function. As a typical case, we consider the transfer function from d to y, namely, PS. Motivation
for considering the 2-norm was presented in Section 2.3. For example, if d(t) is the unit impulse,
then the 2-norm of y(t) equals ∥PS∥2. Or, ∥PS∥2 equals the 2-norm to ∞-norm gain from d to y.
To make the problem more ﬂexible, bring in a weighting function W—appropriate assumptions
on W will be introduced as required. The problem for consideration is: Given P and W, design an
internally stabilizing C to minimize ∥WPS∥2. The method of solution is again to parametrize all
internally stabilizing Cs and then to select an optimal parameter, but now optimal for the 2-norm.
We need some preliminaries. First, let S0 denote the subset of S of all strictly proper stable
transfer functions, S⊥
0 the set of strictly proper transfer functions analytic in Res ≤0, and S0 + S⊥
0
the set of all sums. Thus S0 + S⊥
0 consists precisely of all strictly proper transfer functions with
no poles on the imaginary axis. By Lemma 2.1 the 2-norm is ﬁnite for all functions in S0 + S⊥
0 .
Furthermore, every function F in S0 + S⊥
0 can be uniquely expressed as
F = Fst + Fun,
Fst ∈S0, Fun ∈S⊥
0 ,
for example, by partial fraction expansion (Fst is stable, Fun is unstable).
Pythagoras’s theorem holds in this setting.
Lemma 3 If F ∈S0 and G ∈S⊥
0 , then
∥F + G∥2
2 = ∥F∥2
2 + ∥G∥2
2.
Proof
∥F + G∥2
2
=
1
2π
Z
|F(jω) + G(jω)|2dω
=
∥F∥2
2 + ∥G∥2
2 + 2Re
 1
2π
Z
F(jω)G(jω)dω

.
So it suﬃces to show the last integral equals zero. Convert it into a contour integral by closing the
imaginary axis with an inﬁnite-radius semicircle in the left half-plane:
1
2π
Z
F(jω)G(jω)dω =
1
2πj
I
F(−s)G(s)ds.
But the right-hand side equals zero by Cauchy’s theorem. ■
For the usual representations
P
=
N
M ,
NX + MY = 1,
C
=
X + MQ
Y −NQ ,
Q ∈S,
we have
WPS = WNY −WN 2Q.

176
CHAPTER 10. DESIGN FOR PERFORMANCE
So the problem reduces to: Obtain Q in S to minimize
∥WNY −WN 2Q∥2.
Evidently, this is a 2-norm model-matching problem. It is much easier than the ∞-norm version.
Let us now assume that W ∈S. The idea is to factor U := WN 2 as U = UapUmp. So that
the minimum-phase factor Ump has a stable inverse (so that we can back-solve for Q), assume in
addition that W and P have no zeros on the imaginary axis. Now we shall use the fact that Uap
has unit magnitude on the imaginary axis as follows. For ﬁxed Q in S we have
∥WNY −WN 2Q∥2
2
=
∥WNY −UapUmpQ∥2
2
=
∥Uap(U−1
ap WNY −UmpQ)∥2
2
=
∥U−1
ap WNY −UmpQ∥2
2
=
∥(U−1
ap WNY )un + (U−1
ap WNY )st −UmpQ∥2
2
=
∥(U−1
ap WNY )un∥2
2 + ∥(U−1
ap WNY )st −UmpQ∥2
2.
Lemma 3 was used in the last equality. It is now clear that the unique optimal, generally improper
Q is
Qim = U−1
mp(U−1
ap WNY )st = (WN 2)−1
mp

(WN 2)−1
ap WNY

st
and the consequent minimum value of ∥WNY −WN 2Q∥2 equals ∥(U−1
ap WNY )un∥2. This Qim must
be rolled oﬀat high frequency to get a proper suboptimal Q, just as in Section 10.1; the details are
routine and are therefore omitted.
Example In this example the 2-norm of the plant output y is minimized for a unit step disturbance
d. Thus W(s) = 1/s. A modiﬁcation of the derivation above is required because this W is unstable.
Take
P(s) =
1 −s
s2 + s + 2.
This being stable, we should take
C =
Q
1 −PQ,
Q ∈S.
Temporarily relax the requirement that Q be proper. The function whose 2-norm is to be minimized
is
WPS = WP(1 −PQ).
(10.6)
For this to have ﬁnite 2-norm we must guarantee that P(1 −PQ) has a zero at s = 0 to cancel the
pole of W; this requires 1 −PQ to have a zero at s = 0, that is, Q(0) = 1/P(0) = 2. The set of all
stable Qs satisfying Q(0) = 2 is
Q(s) = 2 + sQ1(s),
Q1 stable.
Substitute this into (10.6) to get
WPS = T −UQ1,

10.4. 2-NORM MINIMIZATION
177
where
T(s)
:=
W(s)P(s)[1 −2P(s)]
=
(1 −s)(s + 3)
(s2 + s + 2)2 ,
U(s)
:=
P(s)2
=
(1 −s)2
(s2 + s + 2)2 .
Then as above, the optimal improper Q1 equals U−1
mp(U−1
ap T)st, that is,
Q1im(s) = (s2 + s + 2)2
(s + 1)2
(s + 1)2
1 −s
(1 −s)(s + 3)
(s2 + s + 2)2

st
= s3 + 2s2 + 2s −1
(s + 1)2
.
To get a proper Q, this should be made strictly proper, so set
Q1(s) = s3 + 2s2 + 2s −1
(τs + 1)2(s + 1)2 .
Then
Q(s) = 2 + ss3 + 2s2 + 2s −1
(τs + 1)2(s + 1)2 .
As τ →0, this Q recovers optimality of ∥WPS∥2.
Exercises
1. Design a controller to achieve ∥W1S∥∞< 1 for
P(s)
=
s −1
(s + 1)2 ,
W1(s)
=
0.62
s2 + 1.2s + 1
(s + 0.001)(s + 1.2)(0.001s + 1).
Plot the resulting step response of the plant output.
2. Take
P(s) = (s −1)(s −2)
(s + 1)3
,
W1(s) =
a
100s + 1.
Design a controller to achieve ∥W1S∥∞< 1. You’ll have to adjust the parameter a so that
the spec is achievable. Sketch Bode plots of |S|, |W1|, and |CS|.
3. Repeat with
P(s) =
s −1
(s −2)(s + 1).

178
CHAPTER 10. DESIGN FOR PERFORMANCE
4. This problem looks at performance design with P minimum phase but having a pole on the
imaginary axis. Take
P(s) = 1
s,
W1(s) = 100
s + 1.
(a) Perturb P to P(s) = 1/(s + ǫ), ǫ > 0. Find a controller C (internally stabilizing) so that
∥W1S∥∞< 1. Let ǫ go to zero in the coeﬃcients of C. Does the resulting C solve the
performance design problem for the original P?
(b) Factor P as
P = P1P2,
P1(s) =
1
s + 1,
P2(s) = s + 1
s
.
Solve the performance design problem for P1; let C1 be the solution. Set C = C1/P2.
Does the resulting C solve the performance design problem for the original P? If so,
explain why.
5. Take
P(s) =
s −1
(s −2)(s + 1).
Let S and T denote the sensitivity and complementary sensitivity functions. Prove that
inf ∥S∥∞= inf ∥T∥∞,
(10.7)
where both inﬁma are over all proper controllers which internally stabilize the feedback system.
Hint to save you some work: The result can be proved without actually computing a coprime
factorization of P.
6. Take P(s) = 1/s2. By the method in the proof of Lemma 2, design an internally stabilizing
C such that
|S(jω)|
<
0.05,
∀ω ≤1,
∥S∥∞
<
1.4.
7. Prove that if G is stable and strictly proper, then
lim
τ→0 ∥G(1 −J)∥2 = 0.
8. Take
P(s) =
10
(s −1)(s + 2).
Compute an internally stabilizing C to minimize the 2-norm of the tracking error y −r for r
the unit step.

10.4. 2-NORM MINIMIZATION
179
Notes and References
The material in Section 10.1 is drawn from Zames (1981), Bensoussan (1984), Francis and Zames
(1984), and Francis (1987).
In the literature the problem of minimizing ∥W1S∥∞is called the
weighted sensitivity problem. Lemma 2 is from Bensoussan (1984) for P stable and Francis (1987)
for the general case. Section 10.2 is based on Zames and Francis (1983), Francis and Zames (1984),
and Khargonekar and Tannenbaum (1985).
There is a way to design for performance which yields a proper Q directly, but it involves
boundary NP interpolation.
The technique in Section 10.4, 2-norm minimization, is also known as minimum variance control:
If d is a zero-mean stationary random signal with power spectral density W(−s)W(s), the variance
of y equals exactly ∥WPS∥2
2. A good treatment of this subject is given in Morari and Zaﬁriou
(1989).

180
CHAPTER 10. DESIGN FOR PERFORMANCE

Chapter 11
Stability Margin Optimization
In Section 4.2 we looked at several measures of stability margin (e.g., gain and phase margin). In
this chapter we pose the problem of designing a controller whose sole purpose is to maximize the
stability margin. The maximum obtainable stability margin is a measure of how diﬃcult the plant
is to control; for example, a plant with a right half-plane pole near a zero has a relatively small
optimal stability margin, and hence is relatively diﬃcult to control.
Three measures of stability margin are treated, namely, the ∞-norm of a multiplicative pertur-
bation, gain margin, and phase margin. It is shown that the problem of optimizing these stability
margins can be reduced to a model-matching problem, as studied in Chapter 9. The reduction for
gain and phase margins requires some conformal mappings, presented in Section 11.2.
11.1
Optimal Robust Stability
To establish our point of view, we begin with a general statement of the robust stability problem.
Consider the usual unity-feedback system with plant transfer function P and controller transfer
function C. It is hypothesized that P is not ﬁxed but belongs to some set P. The robust stability
problem is to ﬁnd, if one exists, a controller C that achieves internal stability for every P in P. We
would like to know two things: conditions on P for C to exist and a procedure to construct such
C. In this generality the robust stability problem remains unsolved.
We concentrate in this section on the special case where P consists of multiplicative perturbations
of a nominal plant P. Following Section 4.1, let P be the family of plants of the form (1 + ∆W2)P,
where
1. P and (1 + ∆W2)P have the same number of poles in Res ≥0.
2. ∥∆∥∞≤ǫ. (In Section 4.1 we took ǫ = 1.)
Here W2 is a ﬁxed stable proper weighting function and ǫ > 0. We write Pǫ to show the explicit
dependence on ǫ. Let ǫsup denote the least upper bound on ǫ such that some C stabilizes every
plant in Pǫ. So ǫsup is the maximum stability margin for this model of uncertainty.
The key result in Section 4.2 (Theorem 4.1) was that a controller C achieves internal stability
for every plant in Pǫ iﬀit achieves internal stability for P and ∥W2T∥∞< 1/ǫ, where T is the
nominal complementary sensitivity function,
T =
PC
1 + PC .
(11.1)
181

182
CHAPTER 11. STABILITY MARGIN OPTIMIZATION
Deﬁne
γinf := inf
C ∥W2T∥∞,
(11.2)
the inﬁmum being over all internally stabilizing controllers. Then ǫsup = 1/γinf.
Proof If ǫ < ǫsup, there exists a C internally stabilizing all of Pǫ, and therefore
∥W2T∥∞< 1
ǫ .
This implies that γinf < 1/ǫ. Since ǫ could have been arbitrarily close to ǫsup, it must be that
γinf ≤1/ǫsup. The reverse inequality is proved in a similar way. ■
We would like to compute ǫsup, equivalently, γinf. Computing γinf reduces to a model-matching
problem in the following way. As in Section 5.2, do a coprime factorization of P:
P = N
M ,
NX + MY = 1.
By Theorem 5.2 the formula
C = X + MQ
Y −NQ ,
Q ∈S
expresses all controllers achieving internal stability for the nominal plant P. Substitution of these
formulas into (11.1) gives
T = N(X + MQ),
so that
W2T = W2N(X + MQ),
and hence
γinf = inf
Q∈S ∥W2N(X + MQ)∥∞.
(11.3)
Equation (11.3) suggests the model-matching problem of Section 9.1:
γopt =
min
Qim stable ∥T1 −T2Qim∥∞.
(11.4)
Evidently, T1 = W2NX, T2 = −W2NM.
So that T2 has no zeros on the imaginary axis (an
assumption in Section 9.1), we will assume that P has neither poles nor zeros on the imaginary axis
and W2 has no zeros on the imaginary axis. The diﬀerence between the two problems is that Q
must be stable and proper in (11.3), but Qim need only be stable in (11.4); the inﬁmum in (11.3) is
not achieved, while the minimum in (11.4) is achieved. Nevertheless, γinf equals γopt, the minimum
model-matching error, a consequence of the fact that N, hence W2N, is strictly proper (Exercise 7).
The optimization problem deﬁned by (11.3) is very much like the performance design problem
in Section 10.2. The procedure there can be easily adapted to give the following one for computing
ǫsup together with a controller C which, for any ǫ < ǫsup, achieves internal stability for all plants in
Pǫ.

11.1. OPTIMAL ROBUST STABILITY
183
Procedure
Input: P, W2
Step 1 Do a coprime factorization of P: Find four functions in S satisfying the equations
P = N
M ,
NX + MY = 1.
Step 2 Solve the model-matching problem for T1 = W2NX, T2 = −W2NM. Let Qim denote
its solution and let γopt denote the minimum model-matching error. Then ǫsup = 1/γopt.
Step 3 Let ǫ be an arbitrary number < ǫsup. Set
J(s) :=
1
(τs + 1)k ,
where k is just large enough that QimJ is proper and τ is just small enough that
∥W2N(X + MQimJ)∥∞< 1
ǫ .
Step 4 Set Q = QimJ.
Step 5 Set C = (X + MQ)/(Y −NQ).
Example Consider the plant
P(s) =
s −1
(s + 1)(s −p),
0 < p ̸= 1
with an unstable pole at s = p and a zero at s = 1. We might anticipate some diﬃculty if p ≈1.
Suppose that the uncertainty weight is the high-pass function
W2(s) = s + 0.1
s + 1 .
The procedure above goes like this:
Step 1
N(s)
=
s −1
(s + 1)2
M(s)
=
s −p
s + 1
X(s)
=
(p + 1)2
p −1
Y (s)
=
s −(p + 3)/(p −1)
s + 1

184
CHAPTER 11. STABILITY MARGIN OPTIMIZATION
Step 2 Factor N as N = NapNmp with
Nap(s) = s −1
s + 1,
Nmp(s) =
1
s + 1.
Then
∥W2N(X + MQ)∥∞= ∥W2Nmp(X + MQ)∥∞,
so an equivalent model-matching problem has T1 = W2NmpX, T2 = −W2NmpM, that is,
T1(s) = (p + 1)2(s + 0.1)
(p −1)(s + 1)2 ,
T2(s) = −(s + 0.1)(s −p)
(s + 1)3
.
Since T2 has only one zero in the right half-plane, namely, at s = p, the minimum model-
matching error is (see Section 9.1)
γopt = |T1(p)| =

p + 0.1
p −1
 ,
so
ǫsup =

p −1
p + 0.1
 .
The graph of ǫsup versus p decreases monotonically as p approaches 1 from above or below.
Thus less and less uncertainty can be tolerated as p approaches 1.
To proceed, let’s take a particular value for p, say p = 0.5, for which ǫsup = 0.8333. The
solution of the model-matching problem, Qim, satisﬁes
T1 −T2Qim = T1(p),
which yields
Qim(s) = −1.2(s + 1)(s −1.25)
s + 0.1
.
Step 3 Set ǫ = 0.8 (arbitrary) and
J(s) =
1
τs + 1.
The value τ = 0.01 gives
∥W2N(X + MQimJ)∥∞= 1.2396 < 1
ǫ = 1.25.
Step 4
Q(s) = −1.2 (s + 1)(s −1.25)
(s + 0.1)(0.01s + 1)
Step 5
C(s) = −(s + 1)(124.5s2 + 240.45s + 120)
s3 + 227.1s2 + 440.7s + 220

11.2. CONFORMAL MAPPING
185
11.2
Conformal Mapping
For our treatment of optimal gain and phase margins, we need some preliminaries on conformal
mapping.
Let D denote the open unit disk. Also, let H+ denote the open right half-plane. A well-known
technique in signals and systems is to map H+ onto D. One such mapping is
s 7→1 −s
1 + s.
This is a conformal mapping; that is, it is analytic in H+ and its inverse,
z 7→1 −z
1 + z ,
is analytic in D. Because such a mapping exists, H+ and D are said to be conformally equivalent.
What proper subsets of C are conformally equivalent to D? It turns out that the subsets need
only be open and simply connected (i.e., have no holes)—for example, an annulus is not simply
connected. This fact is known as the Riemann mapping theorem.
Example 1 Let G1 be the complement of the negative real axis,
{s ∈C : s is real and ≤0}.
It is easy to see that G1 is open and simply connected. We construct a conformal mapping φ1 :
G1 →D as the composition of two mappings:
ψ1 : G1 →H+,
ψ1(s) = √s
and
ψ2 : H+ →D,
ψ2(s) = 1 −s
1 + s.
Then
φ1(s) := ψ2(ψ1(s)) = 1 −√s
1 + √s.
It is worth pointing out that conformal mappings are not unique, so the function φ1 is just one
possibility.
Example 2 Let a be a positive real number and let G2 be the complement of the horizontal ray
from −a left, that is, the complement of
{s ∈C : s is real and ≤−a}.
The function
s 7→1 + sa−1

186
CHAPTER 11. STABILITY MARGIN OPTIMIZATION
maps G2 conformally onto G1. Composing it with φ1 gives
φ2(s) := 1 −
√
1 + sa−1
1 +
√
1 + sa−1 ,
a conformal mapping from G2 onto D, taking 0 to 0.
Example 3 Let a = a1 +ja2 be a complex number in the ﬁrst quadrant (i.e., a1, a2 > 0). Consider
the two rays from a vertically up and from a vertically down; their union is the set
{a + jω : ω ≥0} ∪{a −jω : ω ≥0}.
Let G3 denote the complement of this set. We construct a conformal mapping φ3 from G3 onto
D in several steps. First, the function ψ1(s) := s −a1 translates the rays to the imaginary axis.
Second, ψ2(s) := js rotates them onto the real axis. Thus, ψ2 ◦ψ1 maps G3 conformally onto the
complement of the set
{s : s ∈R, |s| ≥a2}.
Third,
ψ3(s) :=
s
1 −s/a2
1 + s/a2
maps the latter set conformally onto H+.
Now let’s pause and see where 0 is mapped under
ψ3 ◦ψ2 ◦ψ1:
0 7→−a1 7→−ja1 7→c,
where
c :=
s
1 + ja1/a2
1 −ja1/a2
.
Finally,
ψ4(s) := s −c
s + c
maps H+ onto D. So a suitable φ3 is
φ3 := ψ4 ◦ψ3 ◦ψ2 ◦ψ1.
It too takes 0 to 0.
The conformal mappings in Examples 2 and 3 both take 0 to 0, a property that will be needed in
the applications to follow. This property makes them unique up to rotation. More precisely, suppose
that G is an open, simply connected subset of C, and φ1 and φ2 are two conformal mappings from
G onto D taking 0 to 0; then there exists an angle α such that
φ1 = ejαφ2
(i.e., φ1 is a rotation of φ2). Consequently, φ1 and φ2 have equal magnitudes at points of evaluation
in G; that is, for z in G, |φi(z)| does not depend on the particular conformal mapping.

11.3. GAIN MARGIN OPTIMIZATION
187
11.3
Gain Margin Optimization
This section continues with the robust stability problem, but now
P = {kP : 1 ≤k ≤k1}.
Here P is the nominal plant transfer function and k is a real gain that is uncertain and may lie
anywhere in the interval [1, k1]. (The family
P = {kP : k0 ≤k ≤k1},
0 < k0 < k1
is only superﬁcially more general; it can be reduced to the case k0 = 1 by scaling.) We ask the
question: How large can k1 be but yet there exists a controller achieving internal stability for
every plant in P? Let ksup denote the supremum such k1. We’ll get a formula for ksup under the
simplifying assumption that P has neither poles nor zeros on the imaginary axis.
It turns out that ksup is closely related to the inﬁmum norm of the (unweighted) complementary
sensitivity function [see (11.2)],
γinf := inf
C ∥T∥∞.
Of course, as in Section 11.1 this can be converted to a model-matching problem, an analysis of
which will show that
1. γinf = 0 if P is stable.
2. γinf = 1 if P is unstable but minimum phase.
3. γinf > 1 if P is unstable and non-minimum phase.
Theorem 1 If P is stable or minimum phase, then ksup = ∞. Otherwise,
ksup =
γinf + 1
γinf −1
2
.
Partial Proof A complete proof is fairly long, so parts will be omitted.
That ksup = ∞when P is stable is trivial: Take the zero controller, C = 0. So we proceed under
the assumption that P is unstable.
It suﬃces to show that there exists a C stabilizing kP for all 1 ≤k ≤k1 iﬀ
k1 <
γinf + 1
γinf −1
2
or equivalently iﬀ
γinf <
√k1 + 1
√k1 −1.
(11.5)
We will prove necessity, in three steps. Assume that such C exists.

188
CHAPTER 11. STABILITY MARGIN OPTIMIZATION
Step 1 Since C stabilizes the nominal plant, P, it must have the form
C = X + MQ
Y −NQ
for some Q in S. Fix 1 < k ≤k1 and invoke Lemma 5.1: Since C stabilizes kP,
M(Y −NQ) + kN(X + MQ) is invertible in S.
This leads in turn to the following chain:
MY + kNX + (k −1)MNQ is invertible in S
⇒
(1 −NX) + kNX + (k −1)MNQ is invertible in S
⇒
1 + (k −1)N(X + MQ) is invertible in S
⇒
1
k −1 + N(X + MQ) is invertible in S.
Let H+ denote the closed right half-plane together with the point at inﬁnity. We conclude that
the function N(X + MQ) maps H+ into the complement of the single point −1/(k −1). Since this
holds for all 1 < k ≤k1, N(X + MQ) maps H+ into the complement of the set
{s ∈C : s is real and ≤−a},
a :=
1
k1 −1.
Let G denote this complement.
Note that N(X + MQ) equals T, the complementary sensitivity function corresponding to P
and C. It follows that T satisﬁes certain interpolation conditions [see equation (6.2)]. Let {pi}
and {zi} denote the right half-plane poles and zeros of P; for simplicity, these are assumed to be
distinct. Then
T(pi) = 1,
T(zi) = 0.
Step 2 As in Example 2 of the preceding section, bring in a conformal mapping from G onto the
open unit disk, D:
φ(s) := 1 −
√
1 + sa−1
1 +
√
1 + sa−1 .
Deﬁne the function G = φ ◦T. From the properties of T we get that G maps H+ into D and
G(pi) = φ(1),
G(zi) = φ(0) = 0.
Step 3 The ﬁnal step is to scale G: Deﬁne
H :=
1
φ(1)G.
Then H maps H+ into the disk of radius 1/|φ(1)| [i.e., ∥H∥∞< 1/|φ(1)|] and
H(pi) = 1,
H(zi) = 0.

11.3. GAIN MARGIN OPTIMIZATION
189
The function H is analytic in H+, but not necessarily real-rational because φ does not preserve
rationality. Nevertheless, it can be proved that there exists a function, say K, which is real-rational
and has the foregoing properties of H.
We can conclude that there exists a function K in S having the properties
∥K∥∞<
1
|φ(1)|,
(11.6)
K(pi) = 1,
K(zi) = 0.
These properties in turn imply that K is a complementary sensitivity function for some controller;
that is, K = N(X + MQ1) for some Q1 in S. But then from (11.6)
γinf <
1
|φ(1)|.
It remains to compute that
φ(1) = 1 −√k1
1 + √k1
.
This proves (11.5).
Notice that ksup equals the value of k1 satisfying the equation
γinf =
1
|φ(1)|. ■
The following procedure gives a way to compute a controller that achieves an upper gain margin
of k1, any number less than ksup. The idea is to reverse the argument in the proof above. At a high
level, the procedure is as follows:
1. Solve the model-matching problem corresponding to inf ∥T∥∞; let the solution be Qim.
2. Get a suitable roll-oﬀfunction J.
3. Let K be the complementary sensitivity function corresponding to the controller parameter
QimJ.
4. Set G = φ(1)K.
5. Solve G = φ ◦T for T, which will be the resulting complementary sensitivity function.
6. Solve T = N(X + MQ) for Q.
7. Set C = (X + MQ)/(Y −NQ).
Procedure: P Unstable, Non-minimum Phase, No Imaginary Axis Poles or Zeros
Input: P

190
CHAPTER 11. STABILITY MARGIN OPTIMIZATION
Step 1 Do a coprime factorization of P:
P = N
M ,
NX + MY = 1.
Step 2 Solve the model-matching problem for T1 = NX, T2 = −NM. Let Qim denote its
solution and let γopt denote the minimum model-matching error. Then
ksup =
γopt + 1
γopt −1
2
.
Step 3 Let k1 be arbitrary with 1 < k1 < ksup. Set
J(s) :=
1
(τs + 1)k ,
where k is just large enough that QimJ is proper and τ is just small enough that
∥N(X + MQimJ)∥∞<
√k1 + 1
√k1 −1.
Step 4 Set
K
=
N(X + MQimJ),
G
=
1 −√k1
1 + √k1
K,
T
=
1
k1 −1
"1 −G
1 + G
2
−1
#
,
Q
=
T −NX
NM
.
Step 5 Set C = (X + MQ)/(Y −NQ).
Example Consider the plant
P(s) =
s −1
(s + 1)(s −p),
0 < p ̸= 1,
which was studied in Section 11.1. The procedure above goes like this:
Step 1
N(s)
=
s −1
(s + 1)2
M(s)
=
s −p
s + 1
X(s)
=
(p + 1)2
p −1
Y (s)
=
s −(p + 3)/(p −1)
s + 1

11.3. GAIN MARGIN OPTIMIZATION
191
Step 2 Factor N as N = NapNmp with
Nap(s) = s −1
s + 1,
Nmp(s) =
1
s + 1.
Then
∥N(X + MQ)∥∞= ∥Nmp(X + MQ)∥∞,
so an equivalent model-matching problem has T1 = NmpX, T2 = −NmpM, that is,
T1(s) =
(p + 1)2
(p −1)(s + 1),
T2(s) = −s −p
(s + 1)2 .
Thus
γopt = |T1(p)| =

p + 1
p −1

and
ksup =
p + 1 + |p −1|
p + 1 −|p −1|
2
=
 p2,
p ≥1
p−2,
p < 1.
As with ǫsup, this function has its minimum at p = 1.
To proceed, let’s take p = 2 (arbitrary), for which ksup = 4.
The solution of the model-
matching problem, Qim, satisﬁes
T1 −T2Qim = T1(p),
which yields
Qim(s) = 3(s + 1).
Step 3 Set k1 = 3.5 (arbitrary) and
J(s) =
1
τs + 1.
The value τ = 0.01 gives
∥N(X + MQimJ)∥∞= 3.0827 <
√k1 + 1
√k1 −1 = 3.2967.
Step 4
K(s)
=
3 (s −1)(1.03s + 1)
(s + 1)2(0.01s + 1)
G(s)
=
−0.9100 (s −1)(1.03s + 1)
(s + 1)2(0.01s + 1)
T(s)
=
0.0375s5 + 3.8231s4 + 7.3882s3 −0.1831s2 −7.4257s −3.64
0.0003s6 + 0.0041s5 + 0.1190s4 + 0.9378s3 + 11.1662s2 + 19.4563s + 9.1204
Q(s)
=
0.0352s4 + 3.9357s3 + 22.1648s2 + 59.8368s + 41.5724
0.0003s4 + 0.0036s3 + 0.1116s2 + 0.7175s + 9.6670

192
CHAPTER 11. STABILITY MARGIN OPTIMIZATION
11.4
Phase Margin Optimization
Now the family of plants to be stabilized is
P =
n
e−jθP : −θ1 ≤θ ≤θ1
o
,
where P is the nominal plant transfer function and θ is an uncertain phase lying anywhere in the
interval [−θ1, θ1]; θ1 is an angle in (0, π]. Let θsup denote the supremum θ1 for which there exists
a stabilizing controller. Under the assumption that P has neither poles nor zeros on the imaginary
axis, a formula can be derived for θsup in terms of γinf := inf ∥T∥∞just as in the preceding section.
Theorem 2 If P is stable or minimum phase, then θsup = π. Otherwise,
θsup = 2 sin−1
1
γinf
.
Proof The proof of Theorem 1 can be adapted with a few alterations by starting with k = e−jθ.
Again, the case that P is stable is trivial.
First, in Step 1 the appropriate set G is the complement of

−
1
k −1 : k = e−jθ, −θ1 ≤θ ≤θ1

.
The latter set is the union of the vertical rays from
a = a1 + ja2 := 1
2 + j
sin θ1
1 −cos θ1
up and from a down. Second, in Step 2, from Example 3 of the preceding section a conformal
mapping from G onto D is
φ = ψ4 ◦ψ3 ◦ψ2 ◦ψ1,
where
ψ1(s)
=
s −1
2,
ψ2(s)
=
js,
ψ3(s)
=
s
1 −s/a2
1 + s/a2
,
ψ4(s)
=
s −c
s + c,
c
=
s
1 + j/(2a2)
1 −j/(2a2).
Finally, as in the last sentence in the proof of Theorem 1, θsup equals the value of θ1 satisfying the
equation
γinf =
1
|φ(1)|.

11.4. PHASE MARGIN OPTIMIZATION
193
So it remains to show that
|φ(1)| = sin θ1
2 .
Elementary computations give
φ(1) = −Imc
c ,
|φ(1)| = sin θ1
2 . ■
Example Consider once again the plant
P(s) =
s −1
(s + 1)(s −p),
0 < p ̸= 1.
We found in the preceding section that
γinf =

p + 1
p −1
 .
Therefore,
θsup = 2 sin−1

p −1
p + 1
 .
Exercises
1. Compute ǫsup for
P(s) =
s −1
(s −2)(s −3),
W2(s) =
s + 1
s + 100.
Select some ǫ < ǫsup and compute a robust controller.
2. Take
P(s) =
1
s −1,
W2(s) =
as
0.01s + 1,
with a a positive number. Compute the least upper bound on a for which robust stability is
achievable. Pick some a less than this upper bound and design a robust controller.
3. With γinf = inf ∥T∥∞and P having neither poles nor zeros on the imaginary axis, prove
γinf = 0 if P is stable,
γinf = 1 if P is unstable but minimum phase,
γinf > 1 if P is unstable and non-minimum phase.
4. Compute the maximum gain margin ksup for
P(s) =
s −1
(s −2)(s −3).
Select some k1 < ksup and compute a robust controller.

194
CHAPTER 11. STABILITY MARGIN OPTIMIZATION
5. Repeat the Exercise 4 but for phase margin.
6. Recall from Section 4.2 that 1/∥S∥∞equals the distance from the critical point −1 to the
nearest point on the Nyquist plot of PC, and in this way qualiﬁes as a stability margin. The
smaller ∥S∥∞, the larger the stability margin. Compute inf ∥S∥∞for the plant in Exercise 4.
7. Using the equation
W2N(X + MQJ) = W2N(X + MQ)J + W2NX(1 −J),
prove that γinf in (11.3) and γopt in (11.4) are equal.
Notes and References
The problem in Section 11.1 was ﬁrst solved by Kimura (1984). The gain margin problem was ﬁrst
solved by Tannenbaum (1980, 1981) using Nevanlinna-Pick theory. Khargonekar and Tannenbaum
(1985) showed the mathematical equivalence of the problems of gain margin optimization, sensitivity
minimization, and robust stabilization. Yan and Anderson (1990) considered a problem that mixes
performance and gain margin.

Chapter 12
Design for Robust Performance
This chapter presents a mathematical technique for designing a controller to achieve robust per-
formance. Chapter 7 proposed loopshaping as a graphical method when P and P −1 are stable.
Without these assumptions loopshaping is very awkward and the methodical procedure in this
chapter can be used.
12.1
The Modiﬁed Problem
As deﬁned in Section 4.3, the robust performance problem is to design a proper controller C so that
the feedback system for the nominal plant is internally stable and the inequality
∥|W1S| + |W2T|∥∞< 1
(12.1)
holds. Also as mentioned in Chapter 7, the exact problem as just stated remains unsolved. So we
look for a nearby problem that is solvable.
We seek to replace inequality (12.1) with a tractable one. Fix a frequency and deﬁne x := |W1S|
and y := |W2T|. The region in the (x, y)-plane where x + y < 1 is the right-angle triangle shown
here:
@
@
@
@
@
@
1
1
By imagining the circle with center 0, radius 1/
√
2 you can see that
x2 + y2 < 1/2
⇒
x + y < 1.
Thus a suﬃcient condition for (12.1) is
∥|W1S|2 + |W2T|2∥∞< 1
2.
(12.2)
195

196
CHAPTER 12. DESIGN FOR ROBUST PERFORMANCE
In this way we arrive at the modiﬁed robust performance problem: Find a proper, internally sta-
bilizing C so that (12.2) holds. This problem is a compromise; it is not exactly the problem we
would like to solve, but it is nearby and has the desirable feature of being solvable without too
much diﬃculty.
We will solve the modiﬁed problem under the following assumptions:
1. P is strictly proper and has neither poles nor zeros on the imaginary axis.
2. W1 and W2 are stable and proper.
3. W1 and W2 have no common zeros on the imaginary axis.
Some of these assumptions could be relaxed, but with an increase in messiness.
We’ll need an additional tool, covered in the next section.
12.2
Spectral Factorization
For a rational function F(s) with real coeﬃcients, let F denote the function F(−s). Thus
F(jω) = F(−jω) = F(jω).
We saw in Lemma 6.2 that, provided F ∈S, it has a factorization of the form F = FapFmp.
All the right half-plane zeros go into the all-pass factor, and the ones in the left half-plane or
on the imaginary axis go into the minimum-phase factor.
The all-pass factor has the property
Fap(s)Fap(s) = 1.
There is a related factorization if F has the property F = F and no zeros or poles on the
imaginary axis. This means that the zeros of F form a pattern that is symmetrical with respect
to both the real and imaginary axes. To see this, simply note that if z is a zero, so is −z because
F(s) = F(−s). It follows that for every zero z in the right half-plane, the numerator of F is divisible
by
(z −s)(z + s).
Similarly for the poles. Hence we can write F in terms of its gain, poles, and zeros like this:
F(s) = cF1(s),
F1(s) =
Q(zi −s)(zi + s)
Q(pi −s)(pi + s).
Note that {zi} and {pi} are the right half-plane zeros and poles. Note also that F1(0) > 0. From
F1 form a function G by selecting only the factors corresponding to zeros and poles in Res < 0,
that is,
G(s) :=
Q(zi + s)
Q(pi + s).
Then G and G−1 are stable. The zeros and poles of F1 in the right half-plane are absorbed into the
function G and we have the factorization
F = GcG with G, G−1 stable.

12.2. SPECTRAL FACTORIZATION
197
Finally, if c > 0, we deﬁne Fsf as
Fsf(s) := √c
Q(zi + s)
Q(pi + s)
to get F = FsfFsf. Since F1(0) > 0, c > 0 iﬀF(0) > 0.
The function Fsf—which is like a square root of F(s)—therefore has the properties
F = FsfFsf with Fsf, F −1
sf stable
and is called a spectral factor of F. This factorization of F is called a spectral factorization.
An alternative characterization of the condition F = F is this: F = F iﬀF is a rational function
in s2.
The above is summarized as follows.
Lemma 1 If the real-rational function F has the properties F = F, no zeros or poles on the
imaginary axis, and F(0) > 0, then it has a spectral factorization.
Example 1 The function
F(s) =
1
1 −s2
can be factored as
F(s) =
1
1 −s
1
1 + s,
so a suitable spectral factor is Fsf(s) = 1/(1 + s). So is −1/(1 + s).
Example 2 Consider the function
F(s) = 10
4 −s2
25 + 6s2 + s4 .
Its poles are ±1 ± 2j and its zeros are ±2. The function G is therefore
G(s) =
2 + s
(1 + 2j + s)(1 −2j + s) =
2 + s
5 + 2s + s2 .
So a spectral factor is
Fsf(s) =
√
10
2 + s
5 + 2s + s2 .
Example 3 The function
F(s) =
2s2 −1
s4 −s2 + 1
has no spectral factorization because F(0) < 0.

198
CHAPTER 12. DESIGN FOR ROBUST PERFORMANCE
12.3
Solution of the Modiﬁed Problem
The solution of the modiﬁed problem involves transforming it into the model-matching problem of
Chapter 9. Since this transformation is a little involved, it is worth describing it ﬁrst on a high
level, as follows.
1. We use the by now familiar factorization of all internally stabilizing controllers from Theo-
rem 5.2. Factorize P:
P = N
M ,
NX + MY = 1,
N, M, X, Y ∈S.
The formula for C is
C = X + MQ
Y −NQ ,
Q ∈S.
In terms of Q we have
S = M(Y −NQ),
T = N(X + MQ).
So the modiﬁed problem reduces to this: ﬁnd Q in S such that
∥|W1M(Y −NQ)|2 + |W2N(X + MQ)|2∥∞< 1
2.
(12.3)
Let’s simplify notation by deﬁning
R1 := W1MY,
S1 := W2NX,
R2 := W1MN,
S2 := −W2MN.
so that (12.3) becomes
∥|R1 −R2Q|2 + |S1 −S2Q|2∥∞< 1
2.
(12.4)
2. Inequality (12.4) involves the sum of two squares in Q. To get closer to the model-matching
problem we shall transform (12.4) so that only one square in Q appears, that is, transform it
into
∥|U1 −U2Q|2 + U3∥∞< 1
2
(12.5)
for suitable functions Ui, i = 1, 2, 3. The ﬁrst two, U1 and U2, will belong to S, while U3 will
be real-rational with the property U3 = U3.
3. In what follows we shall drop jω and also introduce U4, a spectral factor of 1
2 −U3:
(12.5)
⇔
|U1 −U2Q|2 + U3 < 1
2,
∀ω
⇔
|U1 −U2Q|2 < 1
2 −U3,
∀ω
⇔
|U1 −U2Q|2 < |U4|2,
∀ω
⇔
|U−1
4 U1 −U−1
4 U2Q|2 < 1,
∀ω
⇔
∥U−1
4 U1 −U−1
4 U2Q∥∞< 1.

12.3. SOLUTION OF THE MODIFIED PROBLEM
199
So the ﬁnal model-matching problem is to ﬁnd a Q in S satisfying
∥U−1
4 U1 −U−1
4 U2Q∥∞< 1.
Now for the details. For equivalence of (12.4) and (12.5) it suﬃces to have the following equation
hold:
(R1 −R2Q)(R1 −R2Q) + (S1 −S2Q)(S1 −S2Q) = (U1 −U2Q)(U1 −U2Q) + U3.
Multiply all factors out and collect terms. The result is an identity in Q provided that the following
three equations hold:
R2R2 + S2S2
=
U2U2,
(12.6)
R2R1 + S2S1
=
U2U1,
(12.7)
R1R1 + S1S1
=
U1U1 + U3.
(12.8)
The idea is to get U1 and U2 satisfying (12.6) and (12.7), and then to get U3 from (12.8). In fact,
we can solve for U3 right away:
U3 =
W1W1W2W2
W1W1 + W2W2
.
(12.9)
Proof From (12.7) we have
U1 = R2R1 + S2S1
U2
and hence
U1U1 = (R1R2 + S1S2)(R1R2 + S1S2)
U2U2
.
Substituting from (12.6) in the denominator gives
U1U1 = (R1R2 + S1S2)(R1R2 + S1S2)
R2R2 + S2S2
.
Using this in (12.8) gives
U3 = R1R1 + S1S1 −(R1R2 + S1S2)(R1R2 + S1S2)
R2R2 + S2S2
.
Finally, substitute into this the deﬁnitions of Ri and Si and simplify to get (12.9). ■
Now we turn to the solution of (12.6) and (12.7). We want solutions U1 and U2 in S. To see
what is involved, let us look at an example.
Example 1 Suppose that
R1(s) =
1
2 + s,
S1(s) = 0,
R2(s) =
1
1 + s,
S2(s) = 1.

200
CHAPTER 12. DESIGN FOR ROBUST PERFORMANCE
Then equations (12.6) and (12.7) are
(
√
2 −s)(
√
2 + s)
(1 −s)(1 + s)
=
U2(s)U2(s),
(12.10)
1
(1 −s)(2 + s)
=
U2(s)U1(s).
(12.11)
To satisfy (12.10), an obvious choice is the spectral factor
U2(s) =
√
2 + s
1 + s .
But then (12.11) has the unique solution
U1(s) =
1
(2 + s)(
√
2 −s)
,
which is unsatisfactory, not being in S. So as a solution of (12.10) let us take
U2(s) =
√
2 + s
1 + s V (s),
where V is an all-pass function, as yet unknown. Again, the solution of (12.11) is
U1(s) =
1
(2 + s)(
√
2 −s)V (s).
So to get U1 in S we should let V have a zero at s =
√
2, for example,
V (s) =
√
2 −s
√
2 + s
.
The following procedure yields functions U1 and U2 in S satisfying (12.6) and (12.7).
Procedure A
Input: R1, R2, S1, S2
Step 1 Set F := R2R2 + S2S2. Comment: F has no zeros or poles on the imaginary axis,
F = F, and F(0) > 0.
Step 2 Compute a spectral factor Fsf of F.
Step 3 Choose an all-pass function V such that
R2R1 + S2S1
Fsf
V ∈S.

12.3. SOLUTION OF THE MODIFIED PROBLEM
201
Step 4 Set
U1 := R2R1 + S2S1
Fsf
V,
U2 := FsfV.
Finally, the following procedure solves the modiﬁed robust performance problem.
Procedure B
Input: P, W1, W2
Step 1 Compute
U3 =
W1W1W2W2
W1W1 + W2W2
.
Check if ∥U3∥∞< 1
2, that is,

|W1W2|2
|W1|2 + |W2|2

∞
< 1
2.
If so, continue. If not, the problem is not solvable; stop.
Step 2 Coprime factorization of P:
P = N
M ,
NX + MY = 1.
Step 3 Set
R1 := W1MY,
S1 := W2NX,
R2 := W1MN,
S2 := −W2MN.
Step 4 Apply Procedure A to get U1 and U2.
Step 5 Compute a spectral factor U4 of 1
2 −U3.
Step 6 Set T1 := U−1
4 U1 and T2 := U−1
4 U2. Comment: T1, T2 ∈S and T2 has no zeros on
the imaginary axis.
Step 7 Compute γopt, the minimum model-matching error. If γopt < 1, continue. If γopt ≥1,
the modiﬁed robust performance problem is not solvable; stop.
Step 8 Compute Q, the solution to the model-matching problem. If Q is not proper, roll it
oﬀat a suﬃciently high frequency while maintaining ∥T1 −T2Q∥∞< 1.
Step 9 Set
C = X + MQ
Y −NQ .

202
CHAPTER 12. DESIGN FOR ROBUST PERFORMANCE
The purpose of the next example is solely to illustrate the procedures above.
It should be
emphasized that the plant is very simple and the design could more easily be done using loopshaping.
Example 2 Take
P(s) =
1
s + 1,
W1(s) =
a
s + 1,
W2(s) =
0.02s
0.01s + 1.
The positive constant a is left unspeciﬁed at this point. In fact we will ﬁnd the largest a for which
the modiﬁed robust performance problem is solvable.
Step 1
U3(s) = −
0.0004a2s2
a2 −(0.0001a2 + 0.0004)s2 + 0.0004s4
The ∞-norm of U3 is computed for selected values of a:
a
Norm
50
0.4444
52
0.4601
54
0.4757
56
0.4912
58
0.5064
60
0.5217
By interpolation, the supremum value of a for which ∥U3∥∞< 1/2 is about 57.2.
Step 2 N = P, M = 1, X = 0, Y = 1
Step 3
R1(s) =
a
s + 1,
R2(s) =
a
(s + 1)2 ,
S1(s) = 0,
S2(s) = −
0.02s
(s + 1)(0.01s + 1)
Step 4 Procedure A:
Step 1
F(s) = a2 −(0.0001a2 + 0.0004)s2 + 0.0004s4
(1 −s)2(1 + s)2(1 −0.01s)(1 + 0.01s)
Step 2
Fsf(s) =
a + bs + 0.02s2
(1 + s)2(1 + 0.01s)
b := (0.0001a2 + 0.04a + 0.0004)1/2

12.3. SOLUTION OF THE MODIFIED PROBLEM
203
Step 3
V (s) = a −bs + 0.02s2
a + bs + 0.02s2
Step 4
U1(s) = a2
1 −0.01s
(1 + s)(a + bs + 0.02s2),
U2(s) =
a −bs + 0.02s2
(1 + s)2(1 + 0.01s)
Step 5
U4(s) =
a + cs + 0.02s2
√
2(a + bs + 0.02s2)
c := (−0.0007a2 + 0.04a + 0.0004)1/2
Step 6
T1(s)
=
√
2a2
1 −0.01s
(1 + s)(a + cs + 0.02s2)
T2(s)
=
√
2 (a + bs + 0.02s2)(a −bs + 0.02s2)
(a + cs + 0.02s2)(1 + s)2(1 + 0.01s)
Step 7 γopt is computed for selected values of a:
a
γopt
36
0.9381
37
0.9560
38
0.9742
39
0.9928
40
1.0118
So a = 39 is feasible, while a = 40 is not. Let’s proceed with a = 36.
Step 8 The solution to the model-matching problem is
Qim(s) = 0.3317s4 + 55.19s3 + 2838s2 + 64215s + 61432
s3 + 97.42s2 + 3978s + 62585
.
This must be rolled oﬀ: Set
Q(s) = Qim(s)
1
τs + 1.
The value τ = 0.0009 yields ∥T1 −T2Q∥∞= 0.9996, and is therefore satisfactory.
Step 9 C = Q/(1 −PQ).
The resulting Bode plots are displayed in Figure 12.1.

204
CHAPTER 12. DESIGN FOR ROBUST PERFORMANCE
10-3
10-2
10-1
100
101
102
10-1
100
101
102
103
104
Figure 12.1: Bode plot of |S| (solid), |T| (dash), |W1| (dot), and |W2| (dot-dash).
12.4
Design Example: Flexible Beam Continued
In the preceding section we presented a procedure for designing a controller to achieve a tradeoﬀ
between S and T. The procedure has some appeal pedagogically, being elementary and based in
the frequency domain.
However, it must be admitted that it would not be suitable even for a
medium-sized problem because computations with rational functions are clumsy and numerically
sensitive. Modern software for control system design is based on state-space methods, the theory
behind which is beyond the scope of this book. One such software package is MATLAB with the
µ-Tools Toolbox. In this section we continue the ﬂexible beam example begun in Section 10.3. The
actual computations were performed using MATLAB, so only the results are reported. Our main
purpose in including this example is to discuss further the issue of weights selection, in particular,
the choice of weights for time-domain specs.
Recall that the transfer function for the plant is
P(s) =
−6.4750s2 + 4.0302s + 175.7700
s(5s3 + 3.5682s2 + 139.5021s + 0.0929).
The plant input is a voltage to a power ampliﬁer and the output is the tip deﬂection of the beam.
The performance specs in Section 10.3 were in terms of the unit step response:
settling time
≈
8 s,
overshoot
≤
10%.
Using the performance weight
W1(s) =
0.9
1.0210
s2 + 1.2s + 1
(s + 0.001)(s + 1.2)(0.001s + 1),

12.4. DESIGN EXAMPLE: FLEXIBLE BEAM CONTINUED
205
we designed a controller achieving these two specs.
In this section we place an additional constraint, namely, an amplitude constraint on the plant
input:
|u(t)| ≤0.5,
∀t.
(12.12)
This reﬂects the fact that the power ampliﬁer will saturate if its input is outside this range. The Sec-
tion 10.3 design violates this spec, the signal u(t) exhibiting a very large surge over the time interval
[0, 0.03]. No frequency-domain design procedure can treat a speciﬁcation like (12.12) precisely: An
amplitude bound in the time domain does not translate over precisely to anything tractable in the
frequency domain. So we have to be content with a trial-and-error procedure.
Intuitively, we may have to relax the step-response spec in order to achieve (12.12); this means
decreasing the gain of W1. So let us take
W1(s) = a
s2 + 1.2s + 1
(s + 0.001)(s + 1.2)(0.001s + 1),
where a is a design parameter.
The transfer function from reference input r to plant input u is CS (not T). So to achieve
(12.12) it makes sense to introduce a new weight, W3, and associated modiﬁed criterion,
∥|W1S|2 + |W3CS|2∥∞< 1.
(12.13)
Although this is diﬀerent from the criterion in Section 12.3, it can be handled in exactly the same
way—the changes are obvious; for example, whereas in Section 12.3 we had
W2T = W2N(X + MQ),
we now have
W3CS = W3M(X + MQ).
The observation above, that u(t) exhibits an initial large surge, suggests penalizing high-
frequency control actuation by taking W3 to be a high-pass ﬁlter, of the form
W3(s) = bs + 0.01c
s + c
.
The constant c was taken to be c = 1/0.03 = 33.3 rad/s, corresponding to the surge interval [0, 0.03].
We are left with the two parameters a and b in the weights: The larger the value of a, the better
the step response; the larger the value of b, the larger the penalty on control. These parameters
were determined by the following iterative procedure:
1. Set a = 0.9/1.0210, the value for the previous design.
2. Decrease b from some starting value until (12.13) is achievable by some controller. Obtain
such a controller and do a step-response simulation. Check if the specs are satisﬁed.
3. If necessary, decrease a and repeat Step 2.

206
CHAPTER 12. DESIGN FOR ROBUST PERFORMANCE
The values a = 0.8, b = 1 were obtained, and the corresponding controller has numerator
1.424s7 + 9.076 × 102s6 + 3.141 × 104s5 + 1.117 × 105s4 + 9.073 × 105s3
+1.961 × 106s2 + 1.306 × 103s + 0.01406
and denominator
s8 + 1.013 × 103s7 + 1.326 × 104s6 + 1.129 × 105s5 + 6.326 × 105s4
+2.348 × 106s3 + 4.940 × 106s2 + 3.440 × 106s + 3.435 × 103.
The order of the controller (8) equals the sum of the orders of P, W1, and W3. Figure 12.2 shows
the resulting Bode plots and Figure 12.3 the step responses. The specs have been met.
10-7
10-6
10-5
10-4
10-3
10-2
10-1
100
101
102
103
10-3
10-2
10-1
100
101
102
Figure 12.2: Bode plot of |S| (solid), |CS| (dash), |W1| (dot), and |W3| (dot-dash).
It is interesting to compare the step response of y in Figure 12.3 with the step response in
Figure 10.3, where the control input was unconstrained: The former exhibits a pronounced initial
time lag, evidently the price paid for constrained control.
Exercises
1. This exercise seeks to illustrate why minimization of the performance measure
∥|W1S| + |W2T|∥∞
(12.14)
is harder than minimization of
∥|W1S|2 + |W2T|2∥∞.
(12.15)

12.4. DESIGN EXAMPLE: FLEXIBLE BEAM CONTINUED
207
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
0
1
2
3
4
5
6
7
8
9
10
Figure 12.3: Step response of y (solid) and u (dash).
Consider the space R2 of 2-vectors x = (x1, x2). There are many possible norms on this space;
let us focus on
∥x∥1 := |x1| + |x2| and ∥x∥2 := (|x1|2 + |x2|2)1/2,
which are analogous to (12.14) and (12.15), respectively. Note that ∥∥2 is the usual Euclidean
norm. Sketch the two unit balls,
{x : ∥x∥1 ≤1},
{x : ∥x∥2 ≤1}.
To illustrate that ∥∥1 is harder to work with than ∥∥2, we will look at an approximation
problem. Let M denote the subspace spanned by (1, 2), that is, the straight line through this
point and the origin. For x = (4, 1), compute the vector y in M which is closest to x in that it
minimizes ∥x−y∥2. Note that y equals the orthogonal projection of x onto M. Now compute
y to minimize ∥x −y∥1. Observe that y and x −y are not orthogonal.
2. Prove directly that a necessary condition for solvability of the modiﬁed robust performance
problem is

|W1W2|2
|W1|2 + |W2|2

∞
< 1
2.
3. Show that
∥|W1S| + |W2T|∥∞< 1 ⇒∥|W1S|2 + |W2T|2∥∞< 1.

208
CHAPTER 12. DESIGN FOR ROBUST PERFORMANCE
4. Consider the example in Section 12.3. Let asup denote the supremum value of a for which the
robust performance problem is solvable. It was shown that the value a = 39 is feasible for the
modiﬁed robust performance problem, and hence asup ≥39. Using Exercise 3, ﬁnd an upper
bound for asup.
5. Do a loopshape design for the example in Section 12.3, trying to make a as large as possible.
Notes and References
This chapter is based on Doyle (1983) and Francis (1983). In the literature the problem of mini-
mizing
∥|W1S|2 + |W2T|2∥∞
over all internally stabilizing controllers is called the mixed sensitivity problem. It was solved (for
the more general case of multivariable plants) by Kwakernaak (1985) and Verma and Jonckheere
(1984). The mixed sensitivity problem is a special case of a more general ∞-norm optimization
problem that is treated in Doyle (1984), Francis (1987), and Foias and Tannenbaum (1988).

References
Aubrun, J.N., K.R. Lorell, T.S. Mast, and J.E. Nelson (1987). “Dynamic analysis of the actively
controlled segmented mirror of the W.M. Keck ten-meter telescope,” IEEE Control Syst. Mag., vol.
7, no. 6, pp. 3-10.
Aubrun, J.N., K.R. Lorell, T.W. Havas, and W.C. Henninger (1988). “Performance analysis of the
segmented alignment control system for the ten-meter telescope,” Automatica, vol. 24, pp. 437-454.
Bensoussan, D. (1984). “Sensitivity reduction in single-input single-output systems,” Int. J. Con-
trol, vol. 39, pp. 321-335.
Bode, H.W. (1945). Network Analysis and Feedback Ampliﬁer Design, D. Van Nostrand, Princeton,
N.J.
Bower, J.L. and P. Schultheiss (1961). Introduction to the Design of Servomechanisms, Wiley, New
York.
Boyd, S.P., V. Balakrishnan, C.H. Barratt, N.M. Khraishi, X. Li, D.G. Meyer, and S.A. Norman
(1988).
“A new CAD method and associated architectures for linear controllers,” IEEE Trans.
Auto. Control, vol. AC-33, pp. 268-283.
Boyd, S.P., V. Balakrishnan, and P. Kabamba (1989). “A bisection method for computing the H∞
norm of a transfer matrix and related problems,” Math. Control Signals Syst., vol. 2, pp. 207-219.
Chen, M.J. and C.A. Desoer (1982). “Necessary and suﬃcient condition for robust stability of linear
distributed feedback systems,” Int. J. Control, vol. 35, pp. 255-267.
Desoer, C.A. and C.L. Gustafson (1984). “Algebraic theory of linear multivariable systems,” IEEE
Trans. Auto. Control, vol. AC-29, pp. 909-917.
Desoer, C.A. and M. Vidyasagar (1975). Feedback Systems: Input-Output Properties, Academic
Press, New York.
Desoer, C.A., R.W. Liu, J. Murray, and R. Saeks (1980). “Feedback system design: the fractional
representation approach to analysis and synthesis,” IEEE Trans. Auto. Control, vol. AC-25, pp.
399-412.
Doyle, J.C. (1983). “Synthesis of robust controllers and ﬁlters,” Proc. 22nd IEEE. Conf. Decision
and Control.
209

210
CHAPTER 12. DESIGN FOR ROBUST PERFORMANCE
Doyle, J.C. (1984). Lecture Notes in Advances in Multivariable Control, ONR/Honeywell Workshop,
Minneapolis, Minn.
Doyle, J.C. and G. Stein (1981). “Multivariable feedback design: concepts for a classical modern
synthesis,” IEEE Trans. Auto. Control, vol. AC-26, pp. 4-16.
Enns, D. (1986). Limitations to the Control of the X-29, Technical Report, Honeywell Systems and
Research Center, Minneapolis, Minn.
Foias, C. and A. Tannenbaum (1988). “On the four block problem, II: the singular system,” Integral
Equations and Operator Theory, vol. 11, pp. 726-767.
Francis, B.A. (1983). Notes on H∞-Optimal Linear Feedback Systems, Lectures given at Linkoping
University.
Francis, B.A. (1987). A Course in H∞Control Theory, vol. 88 in Lecture Notes in Control and
Information Sciences, Springer-Verlag, New York.
Francis, B.A. and M. Vidyasagar (1983). “Algebraic and topological aspects of the regulator problem
for lumped linear systems,” Automatica, vol. 19, pp. 87-90.
Francis, B.A. and G. Zames (1984). “On H∞-optimal sensitivity theory for siso feedback systems,”
IEEE Trans. Auto. Control, vol. AC-29, pp. 9-16.
Franklin, G.F., J.D. Powell, and A. Emami-Naeini (1986). Feedback Control of Dynamic Systems,
Addison-Wesley, Reading, Mass.
Freudenberg, J.S. and D.P. Looze (1985). “Right half-plane poles and zeros and design trade-oﬀs
in feedback systems,” IEEE Trans. Auto. Control, vol. AC-30, pp. 555-565.
Freudenberg, J.S. and D.P. Looze (1988). Frequency Domain Properties of Scalar and Mulivariable
Feedback Systems, vol. 104 in Lecture Notes in Control and Information Sciences, Springer-Verlag,
New York.
Garnett, J.B. (1981). Bounded Analytic Functions, Academic Press, New York.
Holtzman, J.M. (1970). Nonlinear System Theory, Prentice-Hall, Englewood Cliﬀs, N.J .
Horowitz, I.M. (1963). Synthesis of Feedback Systems, Academic Press, New York.
Joshi, S.M. (1989). Control of Large Flexible Space Structures, vol. 131 in Lecture Notes in Control
and Information Sciences, Springer-Verlag, New York.
Khargonekar, P. and E. Sontag (1982). “On the relation between stable matrix fraction factor-
izations and regulable realizations of linear systems over rings,” IEEE Trans. Auto. Control, vol.
AC-27, pp. 627-638.
Khargonekar, P. and A. Tannenbaum (1985). “Noneuclidean metrics and the robust stabilization
of systems with parameter uncertainty,” IEEE Trans. Auto. Control, vol. AC-30, pp. 1005-1013.

12.4. DESIGN EXAMPLE: FLEXIBLE BEAM CONTINUED
211
Kimura, H. (1984). “Robust stabilization for a class of transfer functions,” IEEE Trans. Auto.
Control, vol. AC-29, pp. 788-793.
Kucera, V. (1979). Discrete Linear Control: The Polynomial Equation Approach, Wiley, New York.
Kwakernaak, H. (1985). “Minimax frequency domain performance and robustness optimization of
linear feedback systems,” IEEE Trans. Auto. Control, vol. AC-30, pp. 994-1004.
Lenz, K.E., P.P. Khargonekar, and J.C. Doyle (1988). “When is a controller H∞-optimal,” Math.
Control Signals Syst., vol. 1, pp. 107-122.
McFarlane, D.C. and K. Glover (1990). Robust Controller Design Using Normalized Coprime Factor
Plant Descriptions, vol. 138 in Lecture Notes in Control and Information Sciences, Springer-Verlag,
New York.
Mees, A.I. (1981). Dynamics of Feedback Systems, Wiley, New York.
Morari, M. and E. Zaﬁriou (1989). Robust Process Control, Prentice-Hall, Englewood Cliﬀs, N.J.
Nett, C.N., C.A. Jacobson, and M.J. Balas (1984). “A connection between state-space and doubly
coprime fractional representations,” IEEE Trans. Auto. Control, vol. AC-29, pp. 831-832.
Newton, G.C., L.A. Gould, and J.F. Kaiser (1957). Analytic Design of Linear Feedback Controls,
Wiley, New York.
Raggazini, J.R. and G.F. Franklin (1958). Sampled-Data Control Systems, McGraw-Hill, New York.
Saeks, R. and J. Murray (1982).“Fractional representation, algebraic geometry, and the simultaneous
stabilization problem,” IEEE Trans. Auto. Control, vol. AC-27, pp. 895-903.
Sarason, D. (1967). “Generalized interpolation in H∞,” Trans. AMS, vol. 127, pp. 179-203.
Silverman, L. and M. Bettayeb (1980). “Optimal approximation of linear systems,” Proc. JACC.
Tannenbaum, A. (1980). “Feedback stabilization of linear dynamical plants with uncertainty in the
gain factor,” Int. J. Control, vol. 32, pp. 1-16.
Tannenbaum, A. (1981). Invariance and System Theory: Algebraic and Geometric Aspects, vol.
845 in Lecture Notes in Mathematics, Springer-Verlag, Berlin.
Verma, M. and E. Jonckheere (1984). “L∞-compensation with mixed sensitivity as a broadband
matching problem,” Syst. Control Lett., vol. 4, pp. 125-129.
Vidyasagar, M. (1972). “Input-output stability of a broad class of linear time-invariant multivariable
systems,” SIAM J. Control, vol. 10, pp. 203-209.
Vidyasagar, M. (1985). Control System Synthesis: A Factorization Approach, MIT Press, Cam-
bridge, Mass.

212
CHAPTER 12. DESIGN FOR ROBUST PERFORMANCE
Walsh, J.L. (1969). Interpolation and Approximation by Rational Functions in the Complex Domain,
5th ed., American Mathematical Society, Providence, R.I.
Willems, J.C. (1971). The Analysis of Feedback Systems, MIT Press, Cambridge, Mass.
Yan, W. and B.D.O. Anderson (1990). “The simultaneous optimization problem for sensitivity and
gain margin,” IEEE Trans. Auto. Control, vol. AC-35, pp. 558-563.
Youla, D.C., J.J. Bongiorno, Jr., and C.N. Lu (1974). “Single-loop feedback stabilization of linear
multivariable dynamical plants,” Automatica, vol. 10, pp. 159-173.
Youla, D.C., H.A. Jabr, and J.J. Bongiorno, Jr., (1976). “Modern Wiener-Hopf design of optimal
controllers, part II: the multivariable case,” IEEE Trans. Auto. Control, vol. AC-21, pp. 319-338.
Youla, D.C. and M. Saito, (1967). “Interpolation with positive-real functions,” J. Franklin Inst.,
vol. 284, no. 2, pp. 77-108.
Zames, G. (1981). “Feedback and optimal sensitivity: model reference transformations, multiplica-
tive seminorms, and approximate inverses,” IEEE Trans. Auto. Control, vol. AC-26, pp. 301-320.
Zames, G. and B.A. Francis (1983). “Feedback, minimax sensitivity, and optimal robustness,” IEEE
Trans. Auto. Control, vol. AC-28, pp. 585-601.

Index
1-norm, 13
2-norm, 13, 16
2-norm minimization, 183
aﬃne function, 66
algebraic constraints, 89
allowable perturbation, 46
all-pass function, 92
analytic constraints, 90
area formula, 98
asymptotic tracking, 38
autocorrelation function, 19
average power, 14
biproper, 16
Cauchy’s integral formula, 90
Cauchy’s theorem, 90
characteristic polynomial, 36
closed-loop poles, 36
collocated, 126
command response, 57
complementary sensitivity function, 42
computing the 2-norm, 17, 25
computing the ∞-norm, 17, 27
conformal mapping, 193
conformally equivalent, 193
conservativeness, 49
controller parametrization, 73
coprime factorization, 68
coprime functions, 68
cross-correlation function, 20
cross-power spectral density function, 20
dissipative system, 158
energy, 14
energy spectral density, 41
Euclid’s algorithm, 69
exogenous input, 31
ﬁnal-value theorem, 39
ﬂexible beam, 178, 214
frequency-response experiment, 46
gain margin, 51
gain margin optimization, 195
Hermitian matrix, 157
∞-norm, 14, 16
instantaneous power, 14
internal model control, 88
internal stability, 35
interpolation constraints, 90
loop transfer function, 39
loopshaping, 105
M 0
maximum modulus theorem, 90
maximum stability margin, 189
minimum variance control, 187
minimum-phase function, 93
mixed sensitivity problem, 218
model matching, 155
model-matching error, 155
modiﬁed robust performance problem, 206
multiplicative perturbation, 46
Nevanlinna-Pick problem, 156
Nevanlinna’s algorithm, 160
nominal performance, 54
noncollocated, 126
norm, 13
Nyquist criterion, 38
Nyquist plot, 38
optimal Q, 155
optimal robust stability, 189
213

214
INDEX
Pareto optimal, 144
phase formula, 109
phase margin, 51
phase margin optimization, 200
Pick matrix, 157
Pick’s theorem, 157
Poisson integral formula, 91
positive deﬁnite, 157
positive semideﬁnite, 157
potentially optimal, 144
potentially uniquely optimal, 144
power signal, 14
power spectral density, 20
proper, 16
Pythagoras’s theorem, 184
ramp input, 39
relative degree, 98
Riemann mapping theorem, 193
robust controller, 50
robust performance, 54
robust stability, 50
robust stability problem, 189
self-optimal, 145
sensitivity function, 39-40
small-gain theorem, 53
spectral factor, 207
spectral factorization, 207
squareroot of a matrix, 165
stability margin, 50
stable, 16, 25
step input, 39
strictly proper, 16
strong stabilization, 78
strongly Pareto optimal, 144
structured uncertainty, 45
submultiplicative, 16
system gain, 18
total energy, 14
two-degree-of-freedom controller, 57
uniquely optimal, 144
uniquely self-optimal, 145
unity-feedback, 38
unstructured uncertainty, 45
waterbed eﬀect, 96
weighted sensitivity problem, 187
well-posedness, 33

