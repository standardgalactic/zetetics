See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/285607756
Neural Network for Dynamic Human Motion Prediction
Article  in  Expert Systems with Applications · December 2015
DOI: 10.1016/j.eswa.2015.11.020
CITATIONS
25
READS
1,767
4 authors:
Some of the authors of this publication are also working on these related projects:
Clinical Pedictive Models View project
book: human motion simulation View project
Mohammad Bataineh
HUMANA Inc.
10 PUBLICATIONS   75 CITATIONS   
SEE PROFILE
R. Timothy Marler
RAND Corporation
89 PUBLICATIONS   5,530 CITATIONS   
SEE PROFILE
Karim Abdel-Malek
University of Iowa
253 PUBLICATIONS   3,859 CITATIONS   
SEE PROFILE
Jasbir Singh Arora
University of Iowa
314 PUBLICATIONS   14,761 CITATIONS   
SEE PROFILE
All content following this page was uploaded by Mohammad Bataineh on 26 January 2018.
The user has requested enhancement of the downloaded file.

Expert Systems With Applications 48 (2016) 26–34
Contents lists available at ScienceDirect
Expert Systems With Applications
journal homepage: www.elsevier.com/locate/eswa
Neural network for dynamic human motion prediction
Mohammad Bataineh∗, Timothy Marler, Karim Abdel-Malek, Jasbir Arora
Virtual Soldier Research Program – Center for Computer-Aided Design, The University of Iowa, Iowa City, IA, USA
a r t i c l e
i n f o
Keywords:
Digital human modeling
Artiﬁcial neural networks
Motion prediction
General regression neural network
a b s t r a c t
Digital human models (DHMs) are critical for improved designs, injury prevention, and a better understand-
ing of human behavior. Although many capabilities in the ﬁeld are maturing, there are still opportunities
for improvement, especially in motion prediction. Thus, this work investigates the use of an artiﬁcial neural
network (ANN), speciﬁcally a general regression neural network (GRNN), to provide real-time computation
of DHM motion prediction, where the underlying optimization problems are large and computationally com-
plex. In initial experimentation, a GRNN is used successfully to simulate walking and jumping on a box while
using physics-based human simulations as training data. Compared to direct computational simulations of
dynamic motion, use of GRNN reduces the calculation time for each predicted motion from 1–40 min to a
fraction of a second with no noticeable reduction in accuracy. This work lays the foundation for studying the
effects of changes to training regiments on human performance.
© 2015 Elsevier Ltd. All rights reserved.
1. Introduction
The use of digital humans is becoming more prevalent with the
upstream design of any product or process that involves human inter-
action or human systems integration. In order to enhance the design
process as effectively as possible, computationally fast human simu-
lation and analysis become critical. The faster one can simulate and
obtain feedback concerning human performance, the faster one can
evaluate and reﬁne designs. A cornerstone of human performance is
simulated motion, which often requires dynamic analysis (consider-
ation of forces, acceleration, and inertia, not just kinematics). How-
ever, accurate dynamic simulation and analysis can be computation-
ally demanding, depending on the task being simulated. Therefore,
this work presents the use of an artiﬁcial neural network (ANN) to
provide fast motion simulation.
Whether the motion tasks are simulated using data-based meth-
ods (Chaﬃn, 2002; Moeslund, Hilton, & Krüger, 2006), which depend
on motion capture systems to track, record, and reproduce human
motion during various tasks, or using physics-based methods (Xiang
et al., 2010), which primarily entail using optimization to predict
motion, techniques for capturing one’s history and the consequent
strategy for completing the task continue to be a challenge. Why
do different people with similar capabilities and size, for instance,
enter the same vehicle in different ways? Although various human
∗Corresponding author. Tel.: +1 319 331 5454.
E-mail addresses: bataineh.moe@gmail.com (M. Bataineh), tmarler@engineering.
uiowa.edu (T. Marler), amalek@engineering.uiowa.edu (K. Abdel-Malek),
jasbir-arora@uiowa.edu (J. Arora).
modeling methods can capture the nuances of one’s motion or the
cause and effect demonstrated with changes in parameters, few
methods offer the ability to capture one’s strategy in approaching a
task without signiﬁcant input from the user. Hence, there is a need
for an algorithm that produces real-time motion prediction and can
incorporate a history of experience.
Motion-capture-based methods are limited in terms of their abil-
ity to produce different motions that correspond to changes in the
task parameters, because the underlying algorithm depends on pre-
recorded data that cannot be changed due to the change in the task
conditions. In addition, these methods do not incorporate dynam-
ics; they do not capture effects of loads and inertia. Alternatively,
physics-based methods like predictive dynamics (PD), which is an
optimization-based motion prediction algorithm (Xiang et al., 2010),
tend to be more ﬂexible in showing the effects of changes in task
parameters, especially with respect to dynamics. In addition, these
methods are predictive; they predict human performance with min-
imal dependence on prerecorded data. Computational speed, how-
ever, can be a limiting factor with PD, when real-time performance
feedback is needed. Depending on the task being simulated and its
settings, PD can require up to 40 min (the PD algorithm is run on a
Windows 7 computer with an Intel® Core
TM i3 processor and 8 GB
of RAM), even with small changes in the conﬁguration. A variety of
techniques are being explored to address this challenge, and the use
of an ANN is especially promising.
An ANN can be used for real-time motion prediction and can be
integrated with the physics-based motion simulation method, PD, in
order to improve the computational speed when predicting a mo-
tion task. An ANN also provides a platform for incorporating al-
ternative sources for real-time motion prediction, such as motion
http://dx.doi.org/10.1016/j.eswa.2015.11.020
0957-4174/© 2015 Elsevier Ltd. All rights reserved.

M. Bataineh et al. / Expert Systems With Applications 48 (2016) 26–34
27
capture data, if desired. Unlike other simulation tools, ANNs are ca-
pable of providing acceptable simulations for a problem without
the need for complex time-consuming algorithms. This work (1)
demonstrates the feasibility and advantages of using ANNs for di-
rect motion prediction, and (2) presents the use of one of the ANN
types as an appropriate network for successful simulation of such
problems.
An ANN is a mathematical model for predicting system output,
inspired by the structure and function of human biological neural
networks. Compared to other simulation and statistical tools, ANN
is fast and produces relatively accurate and acceptable simulations
for complex systems. ANNs entail two steps or processes. First
they are trained using some form of pre-existing data. Essentially,
optimization is used to set model parameters. After its training
process is completed, it is then run and provides relatively fast
output given various input conditions. ANNs can be powerful tools
for generalizing, which means providing accurate and acceptable
results for all inputs conditions, many practical problems (Coit,
Jackson, & Smith, 1998; Twomey & Smith, 1998), and hence have
been used successfully in many digital human model (DHM)-related
problems (Bataineh, 2015; Bataineh & Marler, 2013; Bataineh, Marler,
& Abdel-Malek, 2013; Bu, Okamoto, & Tsuji, 2009; Kang, Kim, Park,
& Kim, 2007; Li, Li, & Song, 2007; Zhang, Horváth, Molenbroek,
& Snijders, 2010; Zhao, Zheng, & Wen, 2010). Motion-related ap-
plications include, but are not limited to, robotics and controller
system motion, motion analysis, reconstruction of dynamic objects,
and time-series dynamic prediction and classiﬁcation. In general,
the main use of ANNs has been focused on human model posture
prediction (Jung & Park, 1994; Zhang et al., 2010) and motion pre-
diction of robotics and dynamics systems (Frank, Davey, & Hunt,
2001; Stakem & AlRegib, 2008). One approach proposed the use
of multiple ANNs in controlling a robot manipulator (Y. H. Kim &
Lewis, 1999). The system was evaluated successfully on a two-link
robot manipulator, demonstrating the ANN’s ability to handle the
nonlinear unknown parameters in the system manipulator. More-
over, the feedforward-backpropagation network, which was trained
by gaits of various people, is used to recognize humans automati-
cally (Yoo, Hwang, Moon, & Nixon, 2008). In other motion-related
applications, ANNs have been used as an indirect source that led to
providing improved motion predictions. Lung tumor motion during
respiration was predicted in advance using ANNs (Isaksson, Jalden,
& Murphy, 2005). Most of the preceding scholars use feedforward-
backpropagation ANNs with single or few outputs to preserve
accuracy.
So far, ANNs have been applied only to very speciﬁc scenar-
ios in DHM problems and have not been developed for robust use
with complex problems like whole-body dynamic motion predic-
tion. In general, ANNs have been used to solve conﬁned systems
with a relatively small number of inputs and outputs. Most applica-
tions have involved feedforward-backpropagation networks, which
have memory and accuracy issues when used with a large num-
ber of inputs and outputs. Thus, this work explores using other
types of ANNs for relatively large and complex human-modeling
problems.
The overarching hypothesis is that if designed/selected properly,
ANNs can in fact be used to simulate human motion quickly and
accurately, despite a relatively large number of outputs. We con-
tend that a radial-basis network (RBN) is most appropriate, because
it has the smallest number of parameters to be set when simu-
lating a problem with a large number of outputs. In addition, it
provides a global solution when optimizing the network parame-
ter values (during the training process). Speciﬁcally, we propose us-
ing a general regression neural network (GRNN), which is a type
of RBN. The work integrates GRNN with PD to increase the com-
putational speed of PD with minimal detriment to accuracy. This
is shown using two different simulated tasks with a large number
of outputs (on the order of hundreds), both of which run in un-
der one second. Eventually, PD can be replaced by GRNN, which is
trained to provide a standalone instant motion simulation. The next
section describes the necessary parameters (inputs and outputs) of
the PD simulated tasks, as well as details of the underlying ANN
architecture.
2. Methods
2.1. Digital human model and physics-based motion prediction
As a foundation for the proposed method, this section summa-
rizes the digital human model as well as PD. This work capitalizes
on and adds to a foundation of virtual human modeling capabili-
ties, housed within a human model called Santos (Abdel-Malek et
al., 2006; Abdel-Malek et al., 2007). Santos, as shown in Fig. 1, is a
highly realistic, biomechanical computer-based human that predicts,
among other things, static posture, dynamic motion, joint strength,
and development of fatigue. Such capabilities can be used to predict
and assess human function, providing task performance measures
and ergonomic analysis. Thus, in a virtual world, Santos can help de-
sign and analyze various products and processes. In addition, Santos
can help study and evaluate various restrictions and impediments,
such as fatigue, reduced range of motion, environmental obstacles,
etc.
A key aspect of any virtual human is the ability to simulate hu-
man posture and motion realistically and quickly while considering
external and internal loads/forces. With respect to motion, there are
traditionally two types of dynamics problems that need to be ad-
dressed. In the ﬁrst problem, called forward dynamics, the exter-
nal forces and torques on the system are known and the motion of
the system is desired. The problem is solved by integrating the gov-
erning equations of motion forward in time using a numerical algo-
rithm. In the second problem, called inverse dynamics, the motion
of the system is known (i.e., from motion capture), and the forces
and torques causing the motions are calculated using the equations
of motion. Both of these problems can be solved using traditional
multi-body dynamics software. The problem of predictive dynam-
ics arises when one wants to simulate the human motion for any
task. In this problem, both the joint torques and the motion of the
joint are unknown. Therefore, the problem becomes more diﬃcult
to solve. With the PD approach, the joint angles (one for each de-
gree of freedom, or DOF) essentially provide design variables that are
determined through optimization. The objective function(s) is one
or more human performance measure, such as energy consumption,
discomfort, and joint displacement. Including the dynamic equations
of motion as constraints then ensures that the laws of physics are
satisﬁed.
The speciﬁcs of PD (Xiang, Arora, Rahmatalla, & Abdel-Malek,
2009; Xiang et al., 2010) are summarized as follows. In general,
predicting dynamic human motion is approached as an optimization
problem (Arora, 2004), as shown in Eq. 1. This formulation provides
the context for the discussion of inputs and outputs used with the
proposed neural network. Joint angle proﬁles over time are repre-
sented as B-spines, and the control points, which dictate the shape
of the proﬁle curve, serve as design variables in an optimization
problem. The problem entails determining design variables q, which
represent the control points (i.e., joint angle proﬁles) of all body
DOFs, in order to minimize the objective function, f(q), subject to the
physical equality (hi(q)) and inequality (gj(q)) constraints. The control
points (q) form B-splines for all DOFs that simulate the motion of the
DHM. Having more control points in a B-spline leads to more accu-
rate motion simulation but increases the number of design variables
and can thus increase computational complexity. qMoCap is a vector

28
M. Bataineh et al. / Expert Systems With Applications 48 (2016) 26–34
Fig. 1. Schematic of the skeleton model for the virtual human model Santos.
that represents the reference motion provided by motion capture.
Find :
q(control points for 55 −DOFs)
Minimize :
f(q) = f
q −qMoCap

+ fDOFs
1
joint torque
Subject to :
hi(q) = 0, i = 1, . . . , m
gj(q) ≤0, j = 1, . . . , k
Equations of motion, including reaction forces
(1)
The objective function f(q) can vary slightly depending on the task
being simulated, but it generally includes two components. First, the
difference between the predicted motion q and a seed motion based
on experimental motion capture is minimized ( f(q −qMoCap)). This
component helps represent one’s overall strategy when performing
a task, as opposed to kinematic and dynamic nuances. The second
component includes the tendency to minimize the joint torque being
used to complete a task and thus minimize the energy being used
( f(DOFs
1
joint torque)).
The constraints, which represent hi(q) and gj(q), include the fol-
lowing: contact points (between the avatar and the environment),
joint-angle limits that represent one’s range of motion (Marler et al.,
2008), torque limits that represent one’s strength limits, restriction

M. Bataineh et al. / Expert Systems With Applications 48 (2016) 26–34
29
Fig. 2. General regression neural network architecture.
on the zero moment point (responsible for balance), ground reaction
forces, and equations of motion.
Since its development, PD has been used to simulate different mo-
tion tasks and scenarios (Kim et al., 2008; Kim, Xiang, Yang, Arora, &
Abdel-Malek, 2010; Kwon et al., 2014; Xiang, Arora, & Abdel-Malek,
2010, 2012; Xiang et al., 2010). The inputs for each simulation take
two forms: avatar-based and task-based. Avatar-based inputs include
anthropometric parameters (i.e., skeletal link lengths, mass for body
segments, etc.), joint ROMs, torque limits, which represent strength
limits, and loads applied to the avatar as a result of external factors.
Task-based inputs include parameters that deﬁne the characteristics
of a task (i.e., step size in a walking task, box height in a jumping-
on-the-box task, etc.). Each newly developed PD task/simulation is
validated using motion capture and force plates (Rahmatalla, Xiang,
Smith, Meusch, & Bhatt, 2011).
Creating a large number of different task conditions (thousands)
is diﬃcult, because it can be time consuming. The running time for
each case, even with minor condition changes, can take minutes to
hours in order to complete and produce the simulation. The long
running time is due to the large size of the PD problem with respect
to the number of outputs. The number of outputs in a PD task is
approximately 500–700 outputs (i.e., the outputs represent q for all
55 DOFs, which are the design variables), depending on the number
of control points in each task, which can slow down the optimization.
In addition, this process cannot be automated completely, because
the simulations require some post-processing before considering
the case acceptable and usable. Hence, the time-cost issue leads to
a PD problem with a limited number of simulations available to be
used by pattern recognition tools like ANN to be trained to provide
real-time PD simulations. Therefore, a carefully selected type of
ANN that is capable of being trained well with a limited number of
simulations needs to be employed to provide the most acceptable
simulation results. The following section illustrates the architecture
of the proposed ANN for successful real-time simulation of a PD
problem that has a limited number of training cases.
2.2. General regression neural network (GRNN)
This work proposes the use of a GRNN for simulating motion
prediction in DHM. Among the types of RBN, which is known to be
powerful when simulating large-scale and complex problems like
motion, GRNN has the fewest parameters to be set among RBN types
for successful use in DHM applications with relatively large problems
(Bataineh, 2012). ANNs consist of three main parts (Fig. 2): (1) an
input layer, (2) a hidden layer, and (3) an output layer. The input and
output layers consist of the system’s inputs and outputs, respectively.
The hidden layer represents the core of the ANN and consists of units
called neurons. Inside the hidden neurons, which are also called
the basis functions, the main mathematical calculations occur while
processing the inputs and providing the proper outputs.
The network input is represented by x = [x1, x2, . . . ., xR] and pro-
vides the input for each neuron in the hidden layer. R is the num-
ber of inputs, Q is the number of training cases as well as the hidden
neurons [1, 2, . . . , Q], and N is the number of outputs. The hidden
neuron in the ANN receives input(s) from the input layer, completes a
mathematical transformation/calculation, and sends the result to the
neuron(s) of the output layer.
Inside each hidden neuron, there is a radial transfer function
that produces outputs depending on the provided input (Wasserman,
1993). Once the ith hidden neuron receives the input x, the Euclidian
norm of the difference between x and the hidden neuron’s center UI
i
is calculated to produce Ai (Eq. 2). Then, the value Ai is multiplied by
the bias constant B to provide ai, which is called the radial distance
(Eq. 3). The radial function output hi is then calculated as a function
of ai, (Eq. 4).
Ai =
R
j=1 uI
ij −x j
(2)
ai = Ai ∗B
(3)
hi = rad(ai)
(4)
Each output neuron receives the hidden neuron’s output hi as its
input. The output neuron essentially combines the output of all hid-
den neurons in a weighted sum to provide the ﬁnal network output
(Eq. 5). The vector W O
k in the kth output neuron represents the weight
associated with that neuron necessary to provide the proper value
for the kth output yk. The output layer has N neurons, where N is the
number of outputs [y1, y2, . . . , yN].
yk =
Q
q=1 hq. wo
kq
Q
q=1 hq
(5)
The training process in a GRNN involves determining the most
appropriate value of each hidden neuron center UI
i and each output
weight vector W O
k . The training cases are used as the hidden neu-
ron centers, where the number of hidden neurons equals the number
of training cases Q. The weighting vector is set as the outputs of the
training cases. More details regarding the GRNN architecture are pro-
vided in the literature (Specht, 1991).
2.3. GRNN for motion simulation
The crux of the proposed method entails using an ANN to approx-
imate dynamic motion prediction. In essence, an ANN is used to cre-
ate a meta-model or hyper response surface of the PD computational
model. Combining these two elements provides two modes of use.
First, given that PD entails running a gradient-based optimization
model, and ANN can be used to provide an initial guess for the
optimization problem. With this mode, PD is run ﬁrst, regardless of
the computational demands, and is used to create a library of base
simulations. These simulations are then used to train an ANN. With
subsequent PD simulations, the ANN is used to provide an initial
guess based on simulation parameters (i.e., avatar anthropometry,
loads applied to the avatar from equipment, etc.). This initial guess
then helps increase the speed of the optimization problem and thus
the simulation. On the other hand, even with an appropriate (i.e.,
close to optimal) initial guess that is provided from the ANN, the
complex nonconvex optimization in the PD algorithm is not always
guaranteed to run faster.

30
M. Bataineh et al. / Expert Systems With Applications 48 (2016) 26–34
We contend that the results of the ANN can actually be used di-
rectly as a ﬁnal solution in and of itself, and subsequent results prove
this hypothesis. This process in inherently faster than running PD,
training an ANN, and then running PD again. Alternatively, PD is run
off line to produce training data, and the ANN is run to produce ﬁnal
results. Task characteristics (i.e. walking speed, jumping height, etc.)
and avatar characteristics provide the input for a GRNN. Joint-angle
proﬁles, joint-torque proﬁles, and ground reaction forces are the out-
put (see Eq. 1). These parameters are ﬁrst used to train a GRNN (one
for each task). Then, conceivably, any set of input values can be used
to run the GRNN and extract associated output values (simulation re-
sults). This in turn provides a new and relatively fast method for hu-
man motion prediction. Details regarding the inputs and outputs for
the tasks of walking and jumping on a box are provided in the subse-
quent section.
3. Results
The use of GRNN to simulate dynamic human motion quickly is
applied and tested on two tasks: walking forward with a backpack,
and jumping up on a box. The approximate results provided by the
GRNN are compared to, and veriﬁed with those provided from the
source predictive-dynamics models. The work of developing/running
the training cases, training the network, and then executing/running
the trained network is completed on a Windows 7 computer with
an Intel® Core
TM 2 processor and 8 GB of RAM. Since there is no opti-
mization procedures in the GRNN training process, it is trained within
approximately 2–5 s, where that includes setting the network param-
eters to their appropriate values (as indicated in Section 2.2). With
the presented tasks, the run time for PD ranges between 1 and 40 min.
The network-predicted (approximated) motion outputs, which are all
produced in a fraction of a second, are presented, evaluated, and com-
pared with those exact (true) outputs from PD. After the network is
trained with cases produced from PD, the network can simulate mo-
tions instantly for new conditions (i.e., test cases) that had never been
used to train the network. To evaluate the network results of the test
cases, all the produced motions from the GRNN and PD are compared
visually and objectively.
3.1. Example 1: walking
The ﬁrst simulated task is walking forward with a backpack (Xiang
et al., 2009). The inputs for the task include: walking velocity, back-
pack weight, four lower-body link lengths (spine to hip, hip to knee,
knee to ankle, and ankle to football), and three body joint ROMs. ROM
is speciﬁed as upper and lower limits for the hip, knee, and ankle,
each at ﬂexion and extension. These speciﬁc joint ROMs are used
(note that many others are stipulated as detailed by Marler et al.,
2008), because changing their limits has signiﬁcant effects on the re-
sulting motion, whereas other ROMs have a relatively small effect on
the task. Table 1 shows a typical range of values, for each input param-
eter, that reﬂect various scales of human anthropometric data. The
training cases are formed as various combinations of these values, al-
though not all permutations are used simply to reduce complexity.
Velocity represents the speed of walking for Santos and is measured
in m/sec. Value 1 and Value 2, respectively, typical minimum and
maximum speeds for a person of average height. Each training case
(set of input values) represents a point on a training grid. The con-
sequent trained ANN can then be run using any set of inputs. Input
values that do not mimic any training case represent what is called a
test case (i.e., off-grid point).
Thus, for the ﬁrst training case, the velocity is set to Value 1, the
backpack weight is set to Value 1, the group of avatar inputs corre-
spond to the link lengths (the four inputs for body segments’ lengths)
are set to Value 1, and the group of avatar inputs correspond to the
joint limits (the six inputs for upper and lower joint limits) are set
Table 1
Input parameters for training the walking-forward task.
Input parameter
Value 1
Value 2
Value 3
Velocity (m/s)
0.8
–
1.6
Backpack weight (N)
0
175
315
Link1 (Spine to Hip) (cm)
7.8
8.8
9.8
Link2 (Hip to Knee) (cm)
43.5
44.5
45.6
Link3 (Knee to Ankle) (cm)
39.5
42.4
45.4
Link4 (Ankle to Football) (cm)
11.3
11.7
12.1
Joint1 (Hip)- lower limit (degrees)
–123.3
–105
–90
Joint1 (Hip)- upper limit (degrees)
8.7
5
2
Joint2 (Knee)- lower limit (degrees)
5
10
20
Joint2 (Knee)- upper limit (degrees)
149.7
130
110
Joint3 (Ankle)- lower limit (degrees)
7.3
15
20
Joint3 (Ankle)- upper limit
71.6
60
50
Table 2
Input variables for two test cases.
Input parameter
Case 1
Case 2
Velocity (m/s)
1.4
0.9
Backpack weight (N)
220
63
Link1 (Spine to Hip) (cm)
9
8
Link2 (Hip to Knee) (cm)
44
43
Link3 (Knee to Ankle) (cm)
41.4
45
Link4 (Ankle to Football) (cm)
12
11.3
Joint1 (Hip)- lower limit (degrees)
–98.6
–111
Joint1 (Hip)- upper limit (degrees)
2.2
6.5
Joint2 (Knee)- lower limit (degrees)
8
16
Joint2 (Knee)- upper limit (degrees)
146
127.2
Joint3 (Ankle)- lower limit (degrees)
12
7
Joint3 (Ankle)- upper limit
57
70
to Value 1. The next training case is created by keeping the backpack
weight, the velocity, and the group of inputs correspond to the link
lengths ﬁxed at Value 1, and moving the group of avatar joint limits
to Value 2. Then, the avatar joint limits are set to Value 3 to create the
third training case. The same process is applied to create the next 3
training cases by setting velocity and backpack weight to Value 1, link
lengths to Value 2, and using joint limits iteratively from Value 1 to
Value 3. The following 3 training cases are created using the previous
settings, except the link lengths are set to Value 3. By the end of this
step, nine training cases have been produced so far. Next, the velocity
is set to Value 1, the backpack weight is set to Value 2, and the pre-
vious steps are repeated to create the next new nine training cases.
Then, another nine training cases are created using Value 3 for the
backpack weight. Thus far, 27 training cases have been produced af-
ter all the input values are used with ﬁxed velocity at Value 1. Setting
the velocity to Value 2 and repeating all the aforementioned proce-
dures produces another set of 27 cases. Finally, after a manual post-
processing of the resulting 54 training cases, two training cases are
removed because they are subjectively unacceptable due to visually
odd motions. This results in 52 training cases in total.
The network’s outputs in a PD task include control points for San-
tos’s joint-angle proﬁles for all 55 DOFs, as well as values for joint
torques at speciﬁed time steps for certain speciﬁed DOFs. With the
walking task, each joint proﬁle consists of six control points that rep-
resent joint values at different times over the task. Hence, there are
330 outputs representing the joint angle proﬁles. Joint torques are
considered for the six lower-joint DOFs (three for the hip, one for the
knee, and two for the ankle), because these are the most highly artic-
ulated DOFs during the walking task. Assuming symmetry, the joint
torques are evaluated at ten time steps during the walking task. This
results in 60 additional output values. Thus, to summarize, the task
is deﬁned with 12 inputs and 390 outputs in total, and there are 52
training cases.
Once the ANN has been trained, the ANN model for the walking
task is tested using the conditions shown in Table 2. Each of these

M. Bataineh et al. / Expert Systems With Applications 48 (2016) 26–34
31
Fig. 3. Visual walking task results for test Case 1 and Case 2.
testing cases is analyzed by comparing the predicted network out-
puts and the exact PD results. The test cases include two off-grid
points. Note that these cases are not used to train the network, so
they help evaluate the general performance of the network predic-
tion for off-grid (i.e., new unseen) test cases. These cases are chosen
to cover different input combinations and with input values that are
completely different from the values in the training cases (Table 1).
The results of the test case are evaluated based on subjective motion,
and on objective evaluation of joint angle proﬁles and joint torques.
As a basic subjective analysis, the visual motion results for Case
1 and Case 2 are presented in Fig. 3. For this and all following cases,
snapshots are taken at three different time frames of the total task
time. The visual results for Case 1 show accurate network prediction
of all joint proﬁles when compared to PD results; the motion pro-
duced from the network is visually comparable to that from the PD.
With Case 2, Santos’s back is almost straight, which is a reﬂection of
the input backpack weight of just 63 N. The relatively short step size
reﬂects the relatively low walking velocity. Generally speaking, the
visual subjective results are all realistic.
As mentioned earlier, 330 of the network’s outputs represent joint
angle proﬁles for the 55 DOFs. Statistical comparison is performed on
these outputs for both testing cases. The mean-absolute error (MAE)
values are calculated for joint angle proﬁles between the predicted
values from the GRNN and the exact ones from the PD. The MAE are
0.029 and 0.033 for Case 1 and Case 2, respectively, which are rela-
tively small, thus indicating agreement between the ANN results and
the physics-based results (using predictive dynamics).
As another objective test for the results, adjusted R-square val-
ues are calculated between the predicted GRNN results and the ex-
act PD ones (Fig. 4). In both cases, accurate results are achieved;
the R-squared values are above 0.99, and the visual results show
minimal discrepancies. The slight increase in R-squared for Case 1
is simply the result of the neural-network hypersurface providing
slightly more accurate results for different points (sets of inputs).
Interestingly, the scatter plot for Case 1 appears to suggest a de-
crease in accuracy. However, the MAE result for this case provides
the evidence for that accuracy level that matches the resulting R-
squared value. Both results conﬁrm the high correlation between
the predicted and exact results. In addition, given that there are 330
data points, the number of points that visually deviate from the line
in Case 1 is relatively small and numerically insigniﬁcant. In other
words, in Case 1, the network produces different solutions for some
of the joint angles that have minimal effect on the total motion
behavior.
As with joint angle proﬁles, the MAEs are calculated for the pro-
duced joint-torque proﬁles. The results are 10.01 for Case 1 and 9.16
for Case 2. The adjusted R-square values are also plotted and calcu-
lated (see Fig. 5). Recall that 60 of the output values relate to torque
proﬁles for speciﬁed DOFs. The values are approximately 0.96 and
0.88 for Cases 1 and 2, respectively. These calculated values are rela-
tively high and generally acceptable. They are slightly different from
those in Fig. 4, in part because the scale of the output is different,
which can affect the accuracy of results produced from the network.
Although inputs are already scaled, future work might include inves-
tigating the effects of normalizing output values during the training
process.
On the other hand, these MAEs and R-square results are not
quite as accurate as those for the joint angles, because each joint
has a large range of torque values compared to the joint angle
values. Moreover, there are many ranges for torque values at dif-
ferent joints, while the joint angles were all measured in radian
(rad) and fell between +6.28 rad to -6.28 rad. Therefore, the net-
work can predict the joint angle values, which are consistent for all
DOFs, with less error compared to the variety joint torque range of
values.
Fig. 4. Statistical plots and adjusted R-square values for the produced joint angle proﬁles in test Case 1 and Case 2 in the task of walking forward.
Fig. 5. Statistical plots and adjusted R-square values for the produced joint torque proﬁles in test Case 1 and Case 2 in the task of walking forward.

32
M. Bataineh et al. / Expert Systems With Applications 48 (2016) 26–34
Fig. 6. Task of jumping up on a box.
Table 3
Input parameters and training values for the task of jumping
up on a box.
Input parameter
Minimum
Maximum
Box height (cm)
50
100
Link1 (Spine to Hip) (cm)
7.8
9
Link2 (Hip to Knee) (cm)
38
43
Link3 (Knee to Ankle) (cm)
39
39
Link4 (Ankle to Football) (cm)
9
12
Table 4
Input variables for two test cases.
Input parameter
Case 1
Case 2
Box height (cm)
0.68
0.92
Link1 (Spine to Hip) (cm)
8.2
8.8
Link2 (Hip to Knee) (cm)
40
42
Link3 (Knee to Ankle) (cm)
39
39
Link4 (Ankle to Football) (cm)
10
11
3.2. Example 2: jumping on a box
The second example task for evaluating GRNN performance is
jumping up on a box (Fig. 6). This is a relatively complex task that
has many constraints (i.e., feet and hands should be located at speciﬁc
places) and requires highly accurate results. Box height is the primary
task-based input, because it has the greatest effect on the resulting
motion proﬁle. When training the GRNN, the box height ranges be-
tween 0.5 m and 1 m. Avatar-based inputs include four link lengths:
spine-hip, hip-knee, knee-ankle, and ankle-football. Minimum and
maximum values for these inputs are shown in Table 3. In order to
generate training cases, ﬁrst input values are set at their minima, and
box height is increased in increments of 5 cm with all other parame-
ters ﬁxed. Then, input values are set at their maxima, and box height
is decreased in increments of 5 cm. This results in 22 training cases.
The jumping task has two types of outputs: joint splines and
ground reaction forces (GRF) for both feet. The total number of out-
puts is 370, with 330 outputs for joint splines and 40 outputs for GRFs.
As with the walking example, two off-grid testing cases (Table 4)
are evaluated and analyzed visually and statistically. The visual re-
sults for Case 1 and Case 2 are compared in Fig. 7: the left and right
parts in each case represent motion segments over the task time for
PD and GRNN, respectively. In Case 1, even though there were some
differences for both motions due to the recording procedures of the
snapshots, the motions had the same behavior over the task time, in-
cluding the height of the feet and the hand positions. In Case 2, San-
tos’s hands and feet from the network’s predicted motion were also
at the exact locations that the PD results provided.
With respect to statistical evaluation, comparison between pre-
dicted GRNN outputs and exact PD ones is performed for both testing
cases. The MAE values are calculated, and the results show small val-
ues with 0.017 and 0.015 for Case 1 and Case 2, respectively.
In terms of adjusted R-square values, the results are shown in
Fig. 8. The R-square values for angle proﬁles are approximately 1 for
both testing cases, which suggests high accuracy of motion prediction
produced from the GRNN.
In terms of the GRNN prediction results for the GRFs, the results
comparison with those provided from the PD show high R-square val-
ues for both Case 1 and Case 2 (Fig. 9). In addition, the MAE results for
the GRF are calculated and the results are 0.38 and 0.53 for Case 1 and
Case 2, respectively. In general, the statistical results suggest accept-
able network-predicted solutions for the GRFs, and such results are
enhanced by the relatively small simulation errors.
4. Discussion
This work has demonstrated the successful use of ANNs for sim-
ulating dynamic human motion in real time, based on a library of
physics-based simulations. The use of an ANN is shown to provide
real-time motion prediction for a full-body DHM, using various tasks.
The GRNN, in particular, is applied successfully as a powerful tool that
can be trained quickly and without any memory problems, regardless
of the size of the problem. This provides a new variant of physics-
based human simulation with increased computational speed, which
in turn allows one to conduct trade-off analyses more eﬃciently for
evaluating products and processes form a human system integration
perspective.
As with any regression analysis or meta-model, the approximate
solution is expected to deviate at least some minimal amount from
the source model. We show that this deviations is acceptable when
evaluated both objectively and subjectively. As is often the case
with digital human modeling, although subjective results may seem
identical when compared, quantitative results may differ slightly.
Nonetheless, the ANN model performed well when compared to the
predictive-dynamics source model.
With the use of ANNs for motion prediction, the main issue that
was successfully addressed is the computational time of producing
PD outputs. The time is decreased from minutes to a fraction of a
second. Even with a task that requires highly accurate results like
the jumping on a box one, the simulation accuracy, as demonstrated,
was preserved. Accuracy in such task is critical, especially where the
hands and feet should be in contact with the box at some point dur-
ing the task, and network results showed visual satisfaction of such
constraints.
Conceptually, the proposed process reﬂects how people actually
learn and perform tasks. One’s reaction to speciﬁc scenarios is an in-
terpolation, in part, of previously experienced scenarios. To be sure,
rational thought and cognitive extrapolation play a role. However, the
proposed method demonstrates a model for incorporating a learned
history into task simulation. In fact, it provides a platform with which
one can study how various experiences can affect performance and
how variations in one’s learning set can alter a simulation. This has
practical applications to the study and design of training regiments
and education.
This initial investigation into the use of GRNN for human mod-
eling has presented some opportunities for future work. First, as is
the case with most ANN applications, work is needed to determine
the optimal number of training cases for a task. In order to ensure
contact constraints are satisﬁed, future work should include adding

M. Bataineh et al. / Expert Systems With Applications 48 (2016) 26–34
33
Fig. 7. Visual results for test Case 1 and Case 2 in the task of jumping up on a box.
Fig. 8. Statistical plots and adjusted R-square values for the produced joint angle proﬁles in test Case 1 and Case 2 in the task of jumping up on a box.
Fig. 9. Statistical plots and adjusted R-square values for the produced ground reaction forces in test Case 1 and Case 2 in the task of jumping up on a box.
constraints to the network construction. In addition, we propose
training the network to predict joint-center locations instead of joint
angles, in order to produce more accurate results. Predicting joint
angles with even small errors can sometimes produce inaccurate
results, whereas predicting joint centers with small error should still
provide acceptable results. Although the network is trained using
simulations (predictive dynamics) that are presumably validated, and
although this work presents the feasibility of the proposed method
based on subjective validation, predictions from the actual ANN
should be validated directly and objectively. Finally, as suggested
with respect to joint torques, further work is needed to investigate
the beneﬁts of normalizing outputs during the training process.
Acknowledgments
This work is funded by the Oﬃce of Naval Research (ONR) (Grant
no. N00014-11-C-0154). The authors would also like to thank the
team at The University of Iowa’s Virtual Soldier Research (VSR)
Program.
References
Abdel-Malek, K., Arora, J., Yang, J., Marler, T., Beck, S., Swan, C., et al. (2006). Santos: a
physics-based digital human simulation environment. In Proceedings of the Hu-
man Factors and Ergonomics Society Annual Meeting: Vol. 50 (pp. 2279–2283).
SAGE Publications.
Abdel-Malek, K., Yang, J., Kim, J. H., Marler, T., Beck, S., Swan, C., et al. (2007). Devel-
opment of the virtual-human SantosTM. Digital human modeling (pp. 490–499).
Springer.
Arora, J. S. (2004). Intriduction to optimum design (2nd Edition). Amsterdam: Elsevier
Academic Press.
Bataineh, M. (2012). Artiﬁcial neural network for studying human performance. Univer-
sity of Iowa M.S. thesis.
Bataineh, M. (2015). New neural network for real-time human dynamic motion prediction.
University of Iowa Ph.D. thesis.
Bataineh, M., & Marler, T. (2013). Neural networks for performance-measure selection.
In Proceeding of the 2nd International Digital Human Modeling Symposium. Ann Ar-
bor, MI-USA.
Bataineh, M., Marler, T., & Abdel-Malek, K. (2013). Artiﬁcial neural network-based pre-
diction of human posture. Digital human modeling and applications in health, safety,
ergonomics, and risk management. human body modeling and ergonomics p. 305.
Springer.
Bu, N., Okamoto, M., & Tsuji, T. (2009). A hybrid motion classiﬁcation approach for
EMG-based human–robot interfaces using bayesian and neural networks. Trans-
actions on Robotics, IEEE, 25, 502–511.
Chaﬃn,
D.
B.
(2002).
On
simulating
human
reach
motions
for
ergonomics
analyses. Human Factors and Ergonomics in Manufacturing & Service Industries, 12,
235–247.
Coit, D. W., Jackson, B. T., & Smith, A. E. (1998). Static neural network process models:
considerations and case studies. International Journal of Production Research, 36,
2953–2967.
Frank, R. J., Davey, N., & Hunt, S. P. (2001). Time series prediction and neural networks.
Journal of Intelligent and Robotic Systems, 31, 91.
Isaksson, M., Jalden, J., & Murphy, M. J. (2005). On using an adaptive neural network to
predict lung tumor motion during respiration for radiotherapy applications. Medi-
cal physics, 32, 3801.
Jung, E. S., & Park, S. (1994). Prediction of human reach posture using a neural
network for ergonomic man models. Computers & industrial engineering, 27, 369–
372.

34
M. Bataineh et al. / Expert Systems With Applications 48 (2016) 26–34
Kang, B., Kim, B., Park, S., & Kim, H. (2007). Modeling of artiﬁcial neural network for
the prediction of the multi-joint stiffness in dynamic condition. In Proceedings of
International Conference on Intelligent Robots and Systems, 2007. IROS 2007. IEEE/RSJ
(pp. 1840–1845). IEEE.
Kim, J. H., Xiang, Y., Bhatt, R., Yang, J., Chung, H.-J., Patrick, A., et al. (2008). Eﬃcient
ZMP formulation and effective whole-body motion generation for a human-like
mechanism. In Proceedings of ASME 2008 International Design Engineering Technical
Conferences and Computers and Information in Engineering Conference (pp. 1073–
1084). American Society of Mechanical Engineers.
Kim, J. H., Xiang, Y., Yang, J., Arora, J. S., & Abdel-Malek, K. (2010). Dynamic motion
planning of overarm throw for a biped human multibody system. Multibody System
Dynamics, 24, 1–24.
Kim, Y. H., & Lewis, F. L. (1999). Neural network output feedback control of robot ma-
nipulators. Robotics and Automation, IEEE Transactions on, 15, 301.
Kwon, H.-J., Xiang, Y., Bhatt, R., Rahmatalla, S., Arora, J. S., & Abdel-Malek, K. (2014).
Backward walking simulation of humans using optimization. Structural and Multi-
disciplinary Optimization, 50, 169–179.
Li, Y., Li, C., & Song, R. (2007). A new hybrid algorithm of dynamic obstacle avoidance
based on dynamic rolling planning and RBFNN. In Proceedings of International Con-
ference on Robotics and Biomimetics, 2007. ROBIO 2007. IEEE (pp. 2064–2068). IEEE.
Marler, T., Arora, J., Beck, S., Lu, J., Mathai, A., Patrick, A., et al. (2008). Computational
Approaches in DHM. In Vincent G. Duffy (Ed.), Handbook of Digital Human Modeling
for Human Factors and Ergonomics. London, England: Taylor and Francis Press.
Moeslund, T. B., Hilton, A., & Krüger, V. (2006). A survey of advances in vision-based
human motion capture and analysis. Computer vision and image understanding, 104,
90–126.
Rahmatalla, S., Xiang, Y., Smith, R., Meusch, J., & Bhatt, R. (2011). A validation framework
for predictive human models. International journal of human factors modelling and
simulation, 2, 67–84.
Specht, D. F. (1991). A general regression neural network. Neural Networks, IEEE Trans-
actions on, 2, 568.
Stakem, F., & AlRegib, G. (2008). Neural networks for human arm movement prediction
in CVEs. In Proceedings of 3DPVT.
Twomey, J. M., & Smith, A. E. (1998). Bias and variance of validation methods for func-
tion approximation neural networks under conditions of sparse data. Transactions
on Systems, Man, and Cybernetics, Part C: Applications and Reviews, IEEE, 28, 417–
430.
Wasserman, P. D. (1993). Advanced methods in neural computing. John Wiley & Sons Inc.
Xiang, Y., Arora, J. S., & Abdel-Malek, K. (2010). Physics-based modeling and simulation
of human walking: a review of optimization-based and other approaches. Struc-
tural and Multidisciplinary Optimization, 42, 1–23.
Xiang, Y., Arora, J. S., & Abdel-Malek, K. (2012). Hybrid predictive dynamics: a new
approach to simulate human motion. Multibody System Dynamics, 28, 199–224.
Xiang, Y., Arora, J. S., Rahmatalla, S., & Abdel-Malek, K. (2009). Optimization-based dy-
namic human walking prediction: one step formulation. International Journal for
Numerical Methods in Engineering, 79, 667–695.
Xiang, Y., Arora, J. S., Rahmatalla, S., Marler, T., Bhatt, R., & Abdel-Malek, K. (2010). Hu-
man lifting simulation using a multi-objective optimization approach. Multibody
System Dynamics, 23, 431–451.
Xiang, Y., Chung, H.-J., Kim, J. H., Bhatt, R., Rahmatalla, S., Yang, J., et al. (2010). Predic-
tive dynamics: an optimization-based novel approach for human motion simula-
tion. Structural and Multidisciplinary Optimization, 41, 465.
Yoo, J.-H., Hwang, D., Moon, K.-Y., & Nixon, M. S. (2008). Automated human recognition
by gait using neural network. In Proceedings of Image Processing Theory, Tools and
Applications, 2008. IPTA 2008. (p. 1). IEEE.
Zhang, B., Horváth, I., Molenbroek, J. F., & Snijders, C. (2010). Using artiﬁcial neural
networks for human body posture prediction. International Journal of Industrial Er-
gonomics, 40, 414–424.
Zhao, H., Zheng, G., & Wen, W. (2010). Human-machine posture prediction and working
eﬃciency evaluation of virtual human using radial basis function neural network.
In International Conference on Intelligent Computing and Intelligent Systems (ICIS),
2010 IEEE: Vol. 1 (pp. 406–410). IEEE.
View publication stats
View publication stats

