Francesca Biagini
Massimo Campanino
Elements 
of Probability 
and Statistics
UNITEXT
UNITEXT
An Introduction to Probability 
with de Finetti‚Äôs Approach 
and to Bayesian Statistics

UNITEXT - La Matematica per il 3+2
Volume 98
Editor-in-chief
A. Quarteroni
Series editors
L. Ambrosio
P. Biscari
C. Ciliberto
M. Ledoux
W.J. Runggaldier

More information about this series at http://www.springer.com/series/5418

Francesca Biagini
‚Ä¢ Massimo Campanino
Elements of Probability
and Statistics
An Introduction to Probability
with de Finetti‚Äôs Approach
and to Bayesian Statistics
123

Francesca Biagini
Department of Mathematics
Ludwig-Maximilians-Universit√§t
Munich
Germany
Massimo Campanino
Department of Mathematics
Universit√† di Bologna
Bologna
Italy
ISSN 2038-5722
ISSN 2038-5757
(electronic)
UNITEXT - La Matematica per il 3+2
ISBN 978-3-319-07253-1
ISBN 978-3-319-07254-8
(eBook)
DOI 10.1007/978-3-319-07254-8
Library of Congress Control Number: 2015958841
Translation from the Italian language edition: Elementi di Probabilit√† e Statistica di Francesca Biagini e
Massimo Campanino, ¬© Springer-Verlag Italia, Milano 2006. All rights reserved.
¬© Springer International Publishing Switzerland 2016
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part
of the material is concerned, speciÔ¨Åcally the rights of translation, reprinting, reuse of illustrations,
recitation, broadcasting, reproduction on microÔ¨Ålms or in any other physical way, and transmission
or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar
methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this
publication does not imply, even in the absence of a speciÔ¨Åc statement, that such names are exempt from
the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this
book are believed to be true and accurate at the date of publication. Neither the publisher nor the
authors or the editors give a warranty, express or implied, with respect to the material contained herein or
for any errors or omissions that may have been made.
Cover design: Simona Colombo, Giochi di GraÔ¨Åca, Milano, Italy
Printed on acid-free paper
This Springer imprint is published by SpringerNature
The registered company is Springer International Publishing AG Switzerland

Nous ne poss√©dons une ligne, un surface,
un volume que si notre amour l‚Äôoccupe.
M. Proust

To Thilo and Oskar
Francesca Biagini
To my brother Vittorio
Massimo Campanino

Preface
This book is based on the lectures notes for the course, Probability and
Mathematical Statistics, taught for many years by one of the authors (M.C.) and
then, divided into two sections, by both authors at the University of Bologna (Italy).
We follow the approach of de Finetti, see de Finetti [1] for a complete detailed
exposition. Although de Finetti [1] was conceived as a textbook of probability for
mathematics students, it was also meant to illustrate the point of view of the author
on the foundations of probability and mathematical statistics and discuss it in
relation to prevalent approaches, resulting often of difÔ¨Åcult access for beginners.
This was the main reason that prompted us to arrange the lectures notes of our
courses into a more organic way and to write a textbook for an initial class on
probability and mathematical statistics.
The Ô¨Årst Ô¨Åve chapters are devoted to elementary probability. After that in the
next three chapters we develop some elements of Markov chains in discrete and
continuous time also in connection with queueing processes, and introduce basic
concepts in mathematical statistics in the Bayesian approach. Then we propose six
chapters of exercises, which cover most of the topics treated in the theoretical
part. In the appendices we have inserted summary schemes and complementary
topics (two proofs of Stirling formula). We also informally recall some elements of
calculus, as this has often proved useful for the students.
This book offers a comprehensive but concise introduction to probability and
mathematical statistics without requiring notions of measure theory; hence it can be
used in basic classes on probability for mathematics students and is particularly
suitable for computer science, physics and engineering students.
ix

We are grateful to Springer for allowing us to publish the English version of the
book. We wish to thank Elisa Canova, Alessandra Cretarola, Nicola Mezzetti and
Quirin Vogel for their fundamental help with latex, for both the Italian and the
English version.
Munich
Francesca Biagini
Bologna
Massimo Campanino
June 2015
x
Preface

Contents
Part I
Probability
1
Random Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.1
Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.2
Events . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.3
Expectation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
1.4
Probability of Events . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10
1.5
Uniform Distribution on Partitions . . . . . . . . . . . . . . . . . . . . .
12
1.6
Conditional Probability and Expectation . . . . . . . . . . . . . . . . .
14
1.7
Formula of Composite Expectation and Probability. . . . . . . . . .
15
1.8
Formula of Total Expectation and Total Probability . . . . . . . . .
16
1.9
Bayes Formula. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16
1.10
Correlation Between Events. . . . . . . . . . . . . . . . . . . . . . . . . .
17
1.11
Stochastic Independence and Constituents . . . . . . . . . . . . . . . .
20
1.12
Covariance and Variance. . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
1.13
Correlation CoefÔ¨Åcient . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
1.14
Chebychev‚Äôs Inequality. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
1.15
Weak Law of Large Numbers . . . . . . . . . . . . . . . . . . . . . . . .
25
2
Discrete Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
2.1
Random Numbers with Discrete Distribution . . . . . . . . . . . . . .
27
2.2
Bernoulli Scheme. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
2.3
Binomial Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
2.4
Geometric Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
2.5
Poisson Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
30
2.6
Hypergeometric Distribution . . . . . . . . . . . . . . . . . . . . . . . . .
31
2.7
Independence of Partitions. . . . . . . . . . . . . . . . . . . . . . . . . . .
32
2.8
Generalized Bernoulli Scheme . . . . . . . . . . . . . . . . . . . . . . . .
33
2.9
Multinomial Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . .
33
2.10
Stochastic Independence for Random Numbers
with Discrete distribution . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
2.11
Joint Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
xi

2.12
Variance of Discrete Distributions . . . . . . . . . . . . . . . . . . . . .
36
2.13
Non-correlation and Stochastic Independence. . . . . . . . . . . . . .
38
2.14
Generating Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
3
One-Dimensional Absolutely Continuous Distributions . . . . . . . . . .
43
3.1
Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
3.2
Cumulative Distribution Function. . . . . . . . . . . . . . . . . . . . . .
43
3.3
Absolutely Continuous Distributions. . . . . . . . . . . . . . . . . . . .
44
3.4
Uniform Distribution in ¬Ω0; 1. . . . . . . . . . . . . . . . . . . . . . . . .
46
3.5
Uniform Distribution on an Arbitrary Interval ¬Ωa; b . . . . . . . . .
47
3.6
Exponential Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
3.7
A Characterization of Exponential Distribution. . . . . . . . . . . . .
49
3.8
Normal Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
50
3.9
Normal Tail Estimate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
51
3.10
Gamma Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
3.11
œá2-Distribution. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
54
3.12
Cauchy Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
55
3.13
Mixed Cumulative Distribution Functions . . . . . . . . . . . . . . . .
55
4
Multi-dimensional Absolutely Continuous Distributions . . . . . . . . .
57
4.1
Bidimensional Distributions. . . . . . . . . . . . . . . . . . . . . . . . . .
57
4.2
Marginal Cumulative Distribution Functions . . . . . . . . . . . . . .
58
4.3
Absolutely Continuous Joint Distributions . . . . . . . . . . . . . . . .
58
4.4
The Density of Z ¬º X √æ Y. . . . . . . . . . . . . . . . . . . . . . . . . . .
60
4.5
Beta Distribution B√∞Œ±; Œ≤√û . . . . . . . . . . . . . . . . . . . . . . . . . . .
62
4.6
Student Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
63
4.7
Multi-dimensional Distributions . . . . . . . . . . . . . . . . . . . . . . .
64
4.8
Absolutely Continuous Multi-dimensional Distributions . . . . . .
65
4.9
Multi-dimensional Gaussian Distribution . . . . . . . . . . . . . . . . .
66
5
Convergence of Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
5.1
Convergence of Cumulative Distribution Functions. . . . . . . . . .
73
5.2
Convergence of Geometric Distribution to Exponential
Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
75
5.3
Convergence of Binomial Distribution
to Poisson Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
76
5.4
De Moivre-Laplace Theorem . . . . . . . . . . . . . . . . . . . . . . . . .
77
6
Discrete Time Markov Chains . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
6.1
Homogeneous Discrete Time Markov Chains
with Finite State Space . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
6.2
Transition Probability in n Steps . . . . . . . . . . . . . . . . . . . . . .
83
6.3
Equivalence Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
84
6.4
Ergodic Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
86
xii
Contents

7
Continuous Time Markov Chains . . . . . . . . . . . . . . . . . . . . . . . . .
89
7.1
Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
89
7.2
Homogeneous Continuous Time Markov Chains
with Countable State Space . . . . . . . . . . . . . . . . . . . . . . . . . .
90
7.3
Poisson Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
7.4
Queueing Processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
7.5
M=M=1 Queueing Systems . . . . . . . . . . . . . . . . . . . . . . . . .
95
7.6
M=M=1 Queueing Systems . . . . . . . . . . . . . . . . . . . . . . . . . .
97
7.7
M=M=n Queueing Systems . . . . . . . . . . . . . . . . . . . . . . . . . .
98
7.8
Queueing Systems in Stationary Regime
and Little‚Äôs Formulas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
8
Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
8.1
Bayesian Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
8.2
Conditional Density for Two Random Numbers . . . . . . . . . . . . 104
8.3
Statistical Induction on Bernoulli Distribution . . . . . . . . . . . . . 105
8.4
Statistical Induction on Expectation of Normal Distribution . . . . 107
8.5
Statistical Induction on Variance of Normal Distribution . . . . . . 108
8.6
Improper Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
8.7
Statistical Induction on Expectation and Variance
of Normal Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
8.8
Bayesian ConÔ¨Ådence Intervals and Hypotheses' Testing . . . . . . 111
8.9
Comparison of Expectations for Normal Distribution . . . . . . . . 111
Part II
Exercises
9
Combinatorics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
Exercise 9.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
Exercise 9.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
Exercise 9.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
Exercise 9.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
Exercise 9.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
Exercise 9.6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
10
Discrete Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127
Exercise 10.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127
Exercise 10.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129
Exercise 10.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
Exercise 10.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
Exercise 10.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
Exercise 10.6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
Exercise 10.7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
Contents
xiii

11
One-Dimensional Absolutely Continuous Distributions . . . . . . . . . . 143
Exercise 11.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
Exercise 11.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
Exercise 11.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
Exercise 11.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148
12
Absolutely Continuous and Multivariate Distributions . . . . . . . . . . 151
Exercise 12.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
Exercise 12.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
Exercise 12.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156
Exercise 12.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
Exercise 12.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
Exercise 12.6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
Exercise 12.7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174
Exercise 12.8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176
13
Markov Chains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
Exercise 13.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
Exercise 13.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184
Exercise 13.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188
Exercise 13.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192
14
Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197
Exercise 14.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197
Exercise 14.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199
Exercise 14.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202
Exercise 14.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205
Exercise 14.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207
Exercise 14.6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208
Exercise 14.7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210
Exercise 14.8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211
Appendix A: Elements of Combinatorics . . . . . . . . . . . . . . . . . . . . . . . 213
Appendix B: Relations Between Discrete and Absolutely Continuous
Distributions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217
Appendix C: Some Discrete Distributions . . . . . . . . . . . . . . . . . . . . . . 219
Appendix D: Some One-Dimensional Absolutely
Continuous Distributions . . . . . . . . . . . . . . . . . . . . . . . . 221
Appendix E: The Normal Distribution. . . . . . . . . . . . . . . . . . . . . . . . . 223
Appendix F: Stirling‚Äôs Formula. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
xiv
Contents

Appendix G: Elements of Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . 231
Appendix H: Bidimensional Integrals . . . . . . . . . . . . . . . . . . . . . . . . . 235
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245
Contents
xv

Part I
Probability

Chapter 1
Random Numbers
1.1
Introduction
Probability Theory deals with the quantiÔ¨Åcation of our degree of uncertainty. Its main
object of interest are random entities and, in particular, random numbers. What is
meant by random number?
A random number is a well deÔ¨Åned number, whose value is not necessarily known.
For example we can use random numbers to describe the result of a determined exper-
iment, or the value of an option at a preÔ¨Åxed time, or the value of a meteorological
magnitude at a given time. All these quantities have a well deÔ¨Åned value, but may
not be known either because they refer to the future and there are no means to predict
their values with certainty or, even if they refer to the past, there is no available
information at the moment.
We shall denote random numbers with capital letters. Even if the value of a random
number is in general not known, we can speak about the set of its possible values,
that will be denoted by I (X). Certain numbers can be considered as particular cases
of random numbers, whose set of possible values consists of a single element.
Example 1.1.1 Let the random numbers X, Y represent respectively the results of
throwing a coin and a die. If we denote head and tail by 0 and 1 and the sides of the
die with the numbers from 1 to 6, we have:
I (X) = {0, 1} ,
I (Y) = {1, 2, 3, 4, 5, 6} .
The random number X is:
‚Ä¢ upper bounded if I(X) is upper bounded (sup I (X) < +‚àû);
‚Ä¢ lower bounded if I(X) is lower bounded (inf I (X) > ‚àí‚àû);
‚Ä¢ bounded if I(X) is both upper and lower bounded (sup I (X) < +‚àû, inf I (X) >
‚àí‚àû).
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_1
3

4
1
Random Numbers
Given two random numbers X and Y, we denote by I (X, Y) the set of pairs of
values that (X, Y) can attain. In general given n random numbers X1, . . . , Xn, we
denote by I (X1, . . . , Xn) the set of possible values that (X1, . . . , Xn) can attain.
The random numbers X and Y are said to be logically independent if
I (X, Y) = I (X) √ó I (Y) ,
where I (X) √ó I (Y) denotes the Cartesian product of I (X) and I (Y).
Similarly the random numbers (X1 . . . , Xn) are said to be logically independent
if I (X1, . . . , Xn) = I (X1) √ó ¬∑ ¬∑ ¬∑ √ó I (Xn).
Example 1.1.2 In a lottery two balls are consecutively drawn without substitution
from an urn that contains 90 balls numerated from 1 to 90. Let X and Y represent
the random numbers corresponding respectively to the Ô¨Årst and the second drawing.
The set of possible pairs is then
I (X, Y) = {(i, j)|1 ‚â§i ‚â§90, 1 ‚â§j ‚â§90, i Ã∏= j}.
Clearly I (X, Y) Ã∏= I (X) √ó I (Y) as I (X, Y) does not contain pairs of the type (i, i),
with i ‚àà{1, . . . , 90}. The random numbers X and Y therefore are not logically
independent.
By using random numbers we can perform usual arithmetic operations, obtaining
again random numbers. We introduce the following operations that we will apply to
random numbers. For real x and y
1. x ‚à®y := max(x, y);
2. x ‚àßy := min(x, y);
3. Àúx := 1 ‚àíx.
As it is easy to verify, these operations satisfy the following properties:
1. distributive property
x ‚à®(y ‚àßz) = (x ‚à®y) ‚àß(x ‚à®z),
(1.1)
x ‚àß(y ‚à®z) = (x ‚àßy) ‚à®(x ‚àßz);
(1.2)
2. associative property
x ‚à®(y ‚à®z) = (x ‚à®y) ‚à®z,
(1.3)
x ‚àß(y ‚àßz) = (x ‚àßy) ‚àßz;
(1.4)
3. commutative property
x ‚à®y = y ‚à®x,
(1.5)
x ‚àßy = y ‚àßx;
(1.6)

1.1 Introduction
5
4. furthermore
ÀúÀúx = x,
(1.7)
(x ‚à®y)Àú = Àúx ‚àßÀúy,
(1.8)
(x ‚àßy)Àú = Àúx ‚à®Àúy .
(1.9)
These properties are easily extended to operations to n real numbers x1, . . . , xn.
1.2
Events
Events are a particular case of random numbers. An event E is a random number
such that I (E) ‚äÜ{0, 1}. In the case of two events E and F, E ‚à®F is called logical
sum and E ‚àßF logical product. It is easy to verify that:
1. E ‚à®F = E + F ‚àíE F;
2. E ‚àßF = E F.
Given an event E, one deÔ¨Ånes the complementary event E by
ÀúE = 1 ‚àíE.
From (1.7) we have ÀúÀúE = E. From (1.8) we have
(E ‚à®F)Àú = ÀúE ‚àßÀúF = (1 ‚àíE)(1 ‚àíF) = 1 ‚àíE ‚àíF + E F,
so that
E ‚à®F = E + F ‚àíE F.
Analogously
(E ‚à®F ‚à®G)Àú = ÀúE ‚àßÀúF ‚àßÀúG = (1 ‚àíE)(1 ‚àíF)(1 ‚àíG)
= 1 ‚àíE ‚àíF ‚àíG + E F + EG + FG ‚àíE FG,
so that
E ‚à®F ‚à®G = E + F + G ‚àíE F ‚àíEG ‚àíFG + E FG.
Other two operations on events are:
1. Difference of E and F: E \ F = E ‚àíE F.
2. Symmetric difference of E and F: E ‚ñ≥F = (E \ F) ‚à®(F \ E) = E + F(mod 2).
From now on we shall use the symbol ‚ä¢to indicate that what follows is certainly
true. For example, ‚ä¢X ‚â§Y indicates that I (X, Y) ‚äÇ{(x, y)| x ‚â§y}.

6
1
Random Numbers
We use the notation
E ‚äÇF for ‚ä¢E ‚â§F,
and
‚ä¢E = F for E ‚â°F
that is equivalent to E ‚äÇF and F ‚äÇE. When an event E is equal to 1 we say that
E happens, when E is equal to 0 we say that it does not happen. The logical sum
E ‚à®F happens if and only if at least one of the events E and F takes place, whereas
the logical product E ‚àßF = E F happens if and only if both E and F take place. The
complementary event ÀúE happens if and only if E does not happen. Note that E ‚äÇF
means that E implies F, i.e. when E takes place also F does.
DeÔ¨Ånition 1.2.1 We deÔ¨Åne the following relations for events:
1. incompatibility: E, F are said to be incompatible if ‚ä¢E F = 0;
2. exhaustivity: E1,‚Ä¶, En are said to be exhaustive if ‚ä¢E1 + ¬∑ ¬∑ ¬∑ + En ‚â•1;
3. partition: E1,‚Ä¶, En are said to be a partition if ‚ä¢E1 + ¬∑ ¬∑ ¬∑ + En = 1 (i.e. they
are exhaustive and two by two incompatible).
Example 1.2.2 An event E and its complementary ÀúE are a partition.
Given n events E1, . . . , En, we can always build up a partition combining them
and their complementary sets. This partition is called partition of constituents. We
introduce the following notation. Given an event E, we put
E‚àó
i =
 Ei
ÀúEi .
A constituent of E1, . . . , En is a product
Q = E‚àó
1 ¬∑ ¬∑ ¬∑ E‚àó
n .
It easy to check that the set of all constituents are a partition.
In general, not all constituents are possible. If I (Ei) = {0, 1} for i = 1, . . . , n,
all constituents are possible if and only if E1, . . . , En are logically independent. The
possible constituents are a partition. Indeed
1 = (E1 + ÀúE1) . . . (En + ÀúEn) =

Q constituent
Q .
Impossible constituents can be obviously skipped in the sum.

1.2 Events
7
If E1, . . . , En are already a partition, then the possible constituents are:
E1 ÀúE2 . . . ÀúEn,
ÀúE1E2 ÀúE3 . . . ÀúEn,
¬∑ ¬∑ ¬∑ ,
ÀúE1 . . . ÀúEn‚àí1En,
in this case the constituents can be identiÔ¨Åed with the events themselves.
Let us now introduce the concept of logical dependence and independence of an
event E from n given events E1, . . . , En. The constituents Q of E1, . . . , En can be
classiÔ¨Åed in the following way with respect to a given event E:
(i) constituent of I type if Q ‚äÇE;
(ii) constituent of II type if Q ‚äÇÀúE;
(iii) constituent of III type otherwise.
We say that the event E is:
‚Ä¢ logically dependent from E1,‚Ä¶,En if all constituents of E1,‚Ä¶,En are of I or II
type;
‚Ä¢ logically independent from E1,‚Ä¶,En if all constituents of E1,‚Ä¶,En are of the III
type;
‚Ä¢ logically semidependent from E1,‚Ä¶,En otherwise.
If E is logically dependent from E1,‚Ä¶,En, then we can write
E =

Q of I type
Q‚äÇE
Q .
Example 1.2.3 Let us consider two events E1, E2. The logical sum (E1 ‚à®E2) can
be written as
E1 ‚à®E2 = E1E2 + ÀúE1E2 + E1 ÀúE2 .
In general an event E is logically dependent from E1,‚Ä¶,En if and only if E can be
written as E = Œ¶(E1, . . . , En) for some function Œ¶.
Example 1.2.4 Let us throw Ô¨Åve times a coin. Let Ei be the event that we get head
at the ith trial, i.e. Ei = 1. Set Y = E1 + E2 + E3 + E4 + E5 (Y is the total number
of heads in the Ô¨Åve throws) and consider the event
E = (Y ‚â•3).

8
1
Random Numbers
Then E is logically semidependent from E1E2E3. Indeed there are constituents of
the
I type: E1E2E3 ‚äÇE;
II type: ÀúE1 ÀúE2 ÀúE3 ‚äÇÀúE;
III type: ÀúE1E2 ÀúE3.
1.3
Expectation
Given a random number X, we look for a non-random number that expresses our
evaluation of X. We call this quantity expectation of X. In economic terms, if we
think of the expectation of X as a non-random gain that we judge equivalent to X.
Following de Finetti [1] the expectation P(X) assigned to the random number X
can be deÔ¨Åned in an operative way as follows.
Two equivalent operative deÔ¨Ånitions can be used to deÔ¨Åne the expectation:
1. Bet method: we think of X as a random gain (or loss, if it is negative). We have
to choose a value P(X) (non-random) that we judge equivalent to X.
After this choice is made, we must accept any bet with gain (or loss) given by
Œª(X ‚àí¬Øx),
where Œª ‚ààR is a constant. The corresponding coherence principle is that no
choice is allowed for which there is a bet giving a certain loss. The chosen value
¬Øx is our evaluation for the expectation of X.
2. Penalty method: in this case we choose a value X ‚àí¬Ø¬Øx and we accept to pay a
penalty given by
‚àíŒª(X ‚àí¬Ø¬Øx)2,
where Œª ‚ààR+ is a proportionality coefÔ¨Åcient. In this case the coherence principle
is that ¬Ø¬Øx‚Ä≤ is not allowed if there exits a different value X ‚àí¬Ø¬Øx‚Ä≤ such that Œª(X ‚àí¬Ø¬Øx‚Ä≤)2
is certainly less than Œª(X ‚àí¬Ø¬Øx)2. The value ¬Ø¬Øx that we can choose is our evaluation
of the expectation P(X).
It can be shown that these two operative deÔ¨Ånitions are equivalent (see [1]).
Proposition 1.3.1 (Properties of the expectation) Given a random number X, the
expectation P(X) has the following properties:
1. monotonicity: inf I (X) ‚â§P(X) ‚â§sup I (X);
2. linearity: if X = Œ±1X1 + ¬∑ ¬∑ ¬∑ + Œ±n Xn, then P(X) = Œ±1P(X1) + ¬∑ ¬∑ ¬∑ + Œ±nP(Xn).
Proof
1. Monotonicity: Assume that ¬Øx < inf I (X), then for Œª < 0:
‚ä¢Œª(X ‚àí¬Øx) < 0.

1.3 Expectation
9
If ¬Øx > sup I (X), then for Œª > 0 we again get:
‚ä¢Œª(X ‚àí¬Øx) < 0 ,
i.e. a certain loss. It follows that these choices are not coherent according to the
Ô¨Årst criterium. If
inf I (X) ‚â§¬Øx ‚â§sup I (X),
then ‚ä¢

X ‚àí¬Ø¬Øx
2 < (X ‚àíinf I (x)) or ‚ä¢

X ‚àí¬Ø¬Øx
2 < (X ‚àísup I (x)) respec-
tively. In this case these choices are not coherent according to the second cri-
terium.
2. Linearity: Let Z = X + Y. Assume that we choose ¬Øz = P(Z), ¬Øx = P(X), ¬Øy =
P(Y), then according to the bet method we are ready to accept any combination
of bets on X, Y and Z that gives a total gain
G = c1(X ‚àí¬Øx) + c2(Y ‚àí¬Øy) + c3(Z ‚àí¬Øz)
= (c1 + c3)X + (c2 + c3)Y ‚àíc1 ¬Øx ‚àíc2 ¬Øy ‚àíc3¬Øz
where c1, c2, c3 are arbitrary constants. If we choose
c1 = c2 = ‚àíc3,
(so that the random part of G cancels), then we have that the total gain is: G =
c3(¬Øx + ¬Øy ‚àí¬Øz). Then if ¬Øx + ¬Øy ‚àí¬Øz = 0, one can choose c3 so that ‚ä¢G < 0. In this
case this choice is not coherent according to the Ô¨Årst criterium. On the other side
if we follow the penalty method we will pay a penalty proportional to
‚àí[(X ‚àí¬Øx)2 +(Y ‚àí¬Øy)2 +(Z ‚àí¬Øz)2] = ‚àí[(X ‚àí¬Øx)2 +(Y ‚àí¬Øy)2 +(X +Y ‚àí¬Øz)2].
The orthogonal projection P‚Ä≤ of P = (¬Øx, ¬Øy, ¬Øz) on the plane z = x + y has a
distance less or equal to the distance of P from every possible (X, Y, Z), that lies
on the plane, with a strict inequality if P does not lie on the plane. Therefore by
the second criterium we obtain ¬Øz = ¬Øx + ¬Øy. The proof that Z = Œ±X, Œ± ‚ààR, by
the Ô¨Årst or the second criterium is completely analogous.
In general, if X = Œ±1X1 + ¬∑ ¬∑ ¬∑ + Œ±n Xn, it follows that
P(X) = Œ±1P(X1) + ¬∑ ¬∑ ¬∑ + Œ±nP(Xn).
‚ñ°
The monotonicity of expectation implies that:
‚ä¢X ‚â•c =‚áíP(X) ‚â•c;
If c1 ‚â§c2, ‚ä¢c1 ‚â§X ‚â§c2 =‚áíc1 ‚â§P(X) ‚â§c2;
‚ä¢X = c =‚áíP(X) = c.

10
1
Random Numbers
Remark 1.3.2 For unbounded random numbers X (for which inf I (X) = ‚àí‚àû, or
sup I (X) = ‚àû, or both) an evaluation of P(X) is not necessarily Ô¨Ånite or even may
not exist. We refer to [1] for a discussion on the deÔ¨Ånition of the expectation for
unbounded random numbers.
1.4
Probability of Events
If E is an event, i.e. a random number such that I (E) ‚äÇ{1, 0}, then its expectation
P(E) is also called probability of E. From monotonicity it follows that:
1. the probability of an event E is a number between 0 and 1, 0 ‚â§P(E) ‚â§1;
2. E ‚â°0 =‚áíP(E) = 0;
3. E ‚â°1 =‚áíP(E) = 1.
When E ‚â°1, E is called certain event. If E ‚â°0, E is called impossible event.
Furthermore for any given events E1, E2 we have that
P(E1 ‚à®E2) = P(E1 + E2 ‚àíE1E2) ‚â§P(E1 + E2)
and that
P(E1 + E2) = P(E1) + P(E2).
In general for a partition E1, . . . , En, i.e. if ‚ä¢E1 + ¬∑ ¬∑ ¬∑ + En = 1, we have
n

i=1
P(Ei) = 1.
The function that assigns to the events of a partition their probabilities is called
probability distribution of the partition. If E is logically dependent from the events
{E1, . . . , En} of a partition, then we can express the probability of E in terms of the
probabilities of E1, . . . , En. Indeed we have
E =

Ei‚äÇE
Ei
so that
P(E) =

Ei‚äÇE
P(Ei).
Let us now compute the expectation of a random number X with a Ô¨Ånite number of
possible values I (X) = {x1, . . . , xn} in terms of the probabilities of events Ei :=
(X = xi). We use the convention that some proposition within brackets represents a
quantity which is 1 when the proposition is true and 0 when it is false. We have:

1.4 Probability of Events
11
P(X) =
n

i=1
xiP(X = xi).
(1.10)
Indeed
P(X) = P(X(E1 + ¬∑ ¬∑ ¬∑ + En))
= P(X E1) + ¬∑ ¬∑ ¬∑ + P(X En)
=
n

i=1
P(X Ei) =
n

i=1
P(xi Ei)
=
n

i=1
xiP(Ei) =
n

i=1
xiP(X = xi),
where we have used the fact that X Ei is a random number that is equal to xi when
Ei = 1 and to 0 when Ei = 0, i.e. X Ei = xi Ei.
In general, if œÜ is any function œÜ : R ‚ÜíR, we have
P(œÜ(X)) =
n

i=1
œÜ(xi)P(X = xi).
(1.11)
Theproofiscompletelyanalogoustotheoneof (1.10),whichdealswiththeparticular
case œÜ(x) = x.
Example 1.4.1 Let X be a random number representing the result of throwing a
symmetric die with faces numbered from 1 to 6. By symmetry it is natural to assign
the same probability (that must be 1
6) to all possible values. In this case:
P(X) = 1
6
6

i=1
i = 6 ¬∑ 7
6 ¬∑ 2 = 7
2 .
Note that in this case the expectation does not coincide with one of the possible
values of X.
Example 1.4.2 Let us throw a symmetric coin. Let X = 1 if the result is head and
X = 0 if we obtain tail. Also in this case by symmetry it is natural to assign the same
probability (that must be equal to 1
2) to both values. In this case
P(X) = 1
2 ¬∑ 0 + 1
2 ¬∑ 1 = 1
2.

12
1
Random Numbers
1.5
Uniform Distribution on Partitions
In some situations, for reasons of symmetry, it is natural to assign the same prob-
ability to all events of a partition. This is the case of hazard games. If the events
E1, . . . , En are assigned the same probability, we say that the partition has the
uniform distribution. Since the probabilities of a partition add up to 1, we have then
P(Ei) = 1
n .
Let E an event which depends logically from the partition E1, . . . , En, then the
probability of E is given by:
P(E) = P
‚éõ
‚éù
Ei‚äÇE
Ei
‚éû
‚é†= ‚ôØ{i|Ei ‚äÇE}
n
.
In the case of uniform distribution on the partition, we have
P(E) = {i| Ei ‚äÇE}
n
.
This formula is commonly expressed by saying that the probability is given by the
number of favorable cases (i.e. the elements Ei contained in E), divided by the
number of possible cases (i.e. the total number of Ei), as shown below:
P(E) = ‚ôØf avorable cases
‚ôØpossible cases .
(1.12)
This identity is valid only if the events of the partition are judged equiprobable.
Example 1.5.1 A symmetric coin is thrown n times. Let X be the random number
that counts the number of heads in the n throws and let Ei be the event that the ith
throw gives head. We consider the event
E := (X = k) =

Q‚äÇE
Q,
where Q ranges over all constituents E‚àó
1 . . . E‚àó
n of E1, . . . , En. The symmetry of
the coin leads to assign the same probability to all constituents. The probability of
E is then obtained by formula (1.12). The possible cases are 2n since a constituent
is determined by n two-valued choices.

1.5 Uniform Distribution on Partitions
13
The favorable cases are

n
k

, since they are determined by choosing k elements
out of n where the result head is obtained. Therefore
P(E) =

 n
k
 1
2n .
It follows from the properties of binomial coefÔ¨Åcients that when n is even, the largest
value for P(E) is obtained for k = n
2. If n is odd, the largest value for P(E) is obtained
for k = n‚àí1
2
and k = n+1
2 .
Example 1.5.2 We perform n drawings with replacement from an urn containing N
identical balls. In the urn there are H white balls and (N ‚àíH) black balls. Let X
be the random number of white balls which is obtained after n drawings. The set
I (x) of possible values of X is clearly {0, . . . , n}. In order to compute P(X = k) for
0 ‚©Ωk ‚©Ωn we can use formula (1.12), provided that we assign by symmetry reasons
the same probability to the N n sequences of length n that have exactly k white balls;
their number is

n
k

H k(N ‚àíH)n‚àík,
since the position of the k white balls can be chosen in

 n
k

ways and after that we
must choose a sequence of length k from the set of H white balls and one of lenght
n ‚àík from the set of N ‚àíH black balls. We have therefore
P(X = k) =

n
k
 H k(N ‚àíH)n‚àík
N n
.
Let us now consider the same problem, in the case when the drawings are made
without replacement. In this case n must be less than or equal to N, as we cannot
perform more than N drawings without replacement. Also X has some extra con-
straints, as the number X of the extracted white balls must be less than or equal to H
and the number n ‚àíX of extracted black balls must be less than or equal to N ‚àíH.
Therefore
I (X) = {0 ‚à®(n ‚àí(N ‚àíH)), . . . , n ‚àßH}.
In this case the possible cases are represented by all possible sets of extracted balls.
An event corresponds to a set of extracted balls. The number of possible cases is then

 N
n

.

14
1
Random Numbers
Also here by symmetry it is natural to assign the same probability to all events. If
we do so, we can apply formula (1.12) and get
P(X = k) =

 H
k
 
 N ‚àíH
n ‚àík


 N
n

,
for k ‚ààI (X), as the favorable cases are determined by a choice of k elements from
the H white balls and n ‚àík from the N ‚àíH black balls.
We could instead consider as possible cases the set of sequences of length n with
distinct elements, i.e. we can take into account the order of the drawings. Of course
in this case we have to take into account the order also when we count the favorable
cases. The Ô¨Ånal result is the same.
1.6
Conditional Probability and Expectation
Conditional expectation and probability are very important concepts of probability.
We now introduce the deÔ¨Ånition of expectation and probability under the condition
that an event takes place. Let X be a random number and H an event. Conditional
expectation can be deÔ¨Åned in an operative way as ordinary expectation using bets or
penalties.
1. Bet method: we have to choose a quantity with the agreement that we must be
ready to accept any bet with gain
G = cH(X ‚àí¬Øx) ,
where c is a constant (positive or negative). The chosen value is then our evaluation
of the conditional expectation of X given by H and denoted by P(X|H).
2. Penalty method: Here we have to choose a value ¬Ø¬Øx with the condition that we
accept to pay a penalty.
P = ŒªH(X ‚àí¬Ø¬Øx)2 ,
where Œª is a positive constant. Note that the penalty is null when the event H
does not take place, similarly as in the deÔ¨Ånition based on bets. According to this
deÔ¨Ånition ¬Ø¬Øx is our evaluation of the conditional expectation P(X|H) of X.
It can be shown, as in the case of ordinary expectation, that the two deÔ¨Ånitions are
equivalent.
In the particular case when we consider an event E we speak about the conditional
probability P(E|H) of E given H.

1.6 Conditional Probability and Expectation
15
Let I (X|H) ‚äÜI (X) denote the set of possible values of X when H takes place.
Conditional expectation enjoys the same properties as ordinary expectation, i.e. for
X, Y random numbers, Œª a constant and H an event, we have:
‚Ä¢ inf I (X|H) ‚â§P(X|H) ‚â§sup I (X|H);
‚Ä¢ P(X + Y|H) = P(X|H) + P(Y|H);
‚Ä¢ P(ŒªX|H) = ŒªP(X|H),
as it is easily obtained from the coherence principles.
1.7
Formula of Composite Expectation and Probability
Let X be a random number and H an event, then
P(X H) = P(H)P(X|H).
(1.13)
We call (1.13) the formula of composite expectation. If X is also an event, (1.13)
is said to be the formula of composite probability. In order to show that it follows
from the coherence principle, let us put z = P(X H), x = P(H) and y = P(X|H).
Following the deÔ¨Ånition based on bets, this means that we are willing to accept any
combination of bets with total gain:
G = c1(H ‚àíx) + c2H(X ‚àíy) + c3(X H ‚àíz)
= H(c1 + (c2 + c3)X ‚àíc2y) ‚àíc1x ‚àíc3z ,
where c1, c2 and c3 are arbitrary constants. As in previous cases, let us Ô¨Åx c1, c2 and
c3 in such a way that the random part of G cancels: c2 = ‚àíc3 and c1 = c2y. Then
G = ‚àíc1x ‚àíc3z = c2(z ‚àíxy).
If z Ã∏= xy, then it is possible to choose c2 so that ‚ä¢G < 0. Therefore by coherence
principle
z = xy.
Analogously this equality follows by using the deÔ¨Ånition based on penalty. If P(H) >
0, then
P(X|H) = P(X H)
P(H) .
In the case of an event E the formula
P(E|H) = P(E H)
P(H)

16
1
Random Numbers
has a logical meaning, as E H is the logical product of E and H, i.e. the event that
both E and H take place. In particular:
1. E ‚äÇH
‚áí
P(E|H) = P(E)
P(H);
2. H ‚äÇE, that means I (E|H) = {1}
‚áí
P(E|H) = 1;
3. H ‚äÇÀúE, that means I (E|H) = {0}
‚áí
P(E|H) = 0.
1.8
Formula of Total Expectation and Total Probability
Given X a random number and H1, . . . , Hn a partition, then
P(X) =
n

i=1
P(X|Hi)P(Hi) .
(1.14)
We call (1.14) the fomula of total expectation. If X is also an event, (1.14) is said to
be the formula of total probability. Indeed,
P(X) = P(X ¬∑ 1) = P(X(H1 + . . . + Hn))
= P(X H1 + X H2 + ¬∑ ¬∑ ¬∑ + X Hn)
=
n

i=1
P(X Hi) =
n

i=1
P(X|Hi)P(Hi).
1.9
Bayes Formula
Let E, H beevents withP(H) > 0. Byapplyingtwicetheformulaof total probability
we obtain Bayes‚Äô formula:
P(E|H) = P(E H)
P(H) = P(H|E)P(E)
P(H)
.
This formula is a fundamental tool in statistical inference.
Example 1.9.1 Consider an urn contain N identical balls of which some are white
and some are black. Let Y be the random number of the white balls present in the
urn (the composition of the urn is unknown).
The events Hi = (Y = i), for i = 0, . . . , N form a partition. Let E be the event
that we obtain a white ball in a drawing from the urn. Using the formula of total
probability (1.14) we obtain:

1.9 Bayes Formula
17
P(E) =
N

i=0
P(E|Hi)P(Hi) =
N

i=0
i
N P(Hi) .
Indeed if the composition of the urn is known, i.e. if we condition with respect to Hi
for some i, we can apply usual symmetry considerations and get P(E|Hi) =
i
N .
In the case we assign to the partition H0, . . . , HN the uniform distribution
P(Hi) =
1
N + 1, i = 0, . . . , N
we get
P(E) =
N

i=0
i
N(N + 1) = 1
2 .
Wenowevaluatetheprobabilitythat theurncontainsi whiteballs if wehaveextracted
a white ball. This question is answered by Bayes‚Äô formula:
P(Hi|E) = P(E|Hi)P(Hi)
P(E)
=
i
N
1
N+1
1
2
=
2i
N(N + 1) .
We see that distribution on the partition conditional to the event that a white ball is
drawn is no longer uniform, but it gives higher probabilities to compositions with a
large number of white balls.
1.10
Correlation Between Events
An event E is said to be positively correlated with the the event H if
P(E|H) > P(E).
Analogously E is said to be negatively correlated with H if
P(E|H) < P(E).
If P(E|H) = P(E), we say that E is non-correlated with H.
If E is positively (resp. negatively) correlated with H, the information that H
takes place increases (resp. decreases) our evaluation of the probability of E. When
E is not correlated with H, our evaluation does not change.
When P(H) > 0 and P(E) > 0, one can give a symmetric formulation of
correlation as it follows from the formula of composite probability. E and H are said
to be:

18
1
Random Numbers
‚Ä¢ positively correlated if P(E H) > P(E)P(H);
‚Ä¢ negatively correlated if P(E H) < P(E)P(H);
‚Ä¢ non-correlated if P(E H) = P(E)P(H).
If E is positively correlated with H, so is ÀúE. Indeed in this case
P( ÀúE|H) = 1 ‚àíP(E|H) < 1 ‚àíP(E) = P( ÀúE).
In the same way, if E is non-correlated with H, so is ÀúE.
Example 1.10.1 We consider an urn with H white balls and N ‚àíH black balls. We
perform two drawings. Let Ei be the event that a white ball is extracted at the ith
extraction, i = 1, 2. For drawings with replacement we have
P(E1) = P(E2) = H
N .
Indeed the urn composition in the two drawings is the same. In this case E1 and E2
are non-correlated, as by (1.12)
P(E1E2) = H 2
N 2 = P(E1)P(E2) .
Let us now consider the case of drawings without replacement. We use again formula
(1.12) to compute probabilities and conditional probabilities. We have P(E1) = H
N
and by the formula of total probability (1.14) applied to the event E2 and the partition
E1, ÀúE1 we get
P(E2) = P(E2|E1)P(E1) + P(E2| ÀúE1)P( ÀúE1)
= H ‚àí1
N ‚àí1
H
N +
H
N ‚àí1(1 ‚àíH
N ) = H
N .
Here P(E1) and P(E2) are both equal to H
N and P(E1), P(E2) are negatively corre-
lated, as
P(E2|E1) = H ‚àí1
N ‚àí1 < H
N = P(E2)
if 0 < H < N.
We say that two events are stochastically independent if
P(E1E2) = P(E1)P(E2) .
When P(E1) > 0 and P(E2) > 0 this deÔ¨Ånition coincides with non-correlation.
When one or both of E1 and E2 have 0 probability, then E1 and E2 are stochastically
independent, as in this case P(E1)P(E2) = 0 and

1.10 Correlation Between Events
19
P(E1E2) ‚â§P(E1) ‚àßP(E2) = 0.
The deÔ¨Ånition of stochastic independence extends to the case of an arbitrary number
of events.
DeÔ¨Ånition 1.10.2 The events E1, . . . , En are said to be stochastically independent
if for every subset {i1, . . . , ik} in {1, . . . , n} we have
P(Ei1 ¬∑ ¬∑ ¬∑ Eik) = P(Ei1) ¬∑ ¬∑ ¬∑ P(Eik).
(1.15)
We remark that in general n events are not stochastically independent if the events
are only pairwise stochastically independent.
We shall see that if the events E1, . . . , En are stochastically independent, then
the events E‚àó
1, . . . , E‚àó
n are stochastically independent for every possible choice of
E‚àó
i between Ei and ÀúEi, for i = 1, . . . , n.
DeÔ¨Ånition 1.10.3 Let H = {H1, . . . , Hn} be a partition. The events E1, E2 are said
to be stochastically independent conditionally to the partition H if
P(E1E2|Hi) = P(E1|Hi)P(E2|Hi) for all i = 1, . . . n .
Example 1.10.4 Let us consider an urn with unknown composition containing N
identical balls, of which some are white and some are black. Let Y be the random
number of white balls in the urn. We perform two drawings with replacement. Let
Ei, i = 1, 2, be the event that in the ith drawing we extract a white ball.
Consider the partition
Hi = (Y = i)
i = 0, . . . N.
It is easy to see that the events E1 and E2 are stochastically independent conditionally
to the partition H. We want to see whether E1 and E2 are stochastically independent,
assuming that we assign the uniform distribution to H, i.e. P(Hi) =
1
N+1 for i =
0, 1, . . . , N. We compute:
1. the probability of the Ô¨Årst drawing:
P(E1) =
N

i=0
P(E1|Hi)P(Hi)
=
1
N + 1
N

i=0
i
N
=
1
N + 1
N(N + 1)
2N
= 1
2 ;

20
1
Random Numbers
2. the probability of the second drawing:
P(E2) = P(E1) = 1
2;
3. the probability that we draw a white ball in both drawings:
P(E1E2) =
N

i=0
P(E1E2|Hi)P(Hi)
=
1
N + 1
N

i=0
P(E1|Hi)P(E2|Hi)
=
1
N + 1
N

i=0
i2
N 2 .
Using the fact that
(i + 1)3 ‚àíi3 = 3i2 + 3i + 1
we have
N

i=0
i2 =
N

i=0
(i + 1)3 ‚àíi3
3
‚àí
N

i=0
i ‚àí
N

i=0
1
3 = (N + 1)3
3
‚àíN(N + 1)
2
‚àíN
3 ,
and
P(E1E2) = (N + 1)2
3N 2
‚àí1
2N ‚àí
1
3N(N + 1).
For N ‚Üí+‚àû, P(E1E2) tends to 1
3. Therefore at least for large N, E1 and E2
are positively correlated. This shows that stochastic independence conditionally
to a partition does not imply stochastic independence.
1.11
Stochastic Independence and Constituents
Proposition 1.11.1 The events E1, . . . , En are stochastically independent if and
only if
P(Q) = P(E‚àó
1) ¬∑ ¬∑ ¬∑ P(E‚àó
n)
(1.16)
for every constituent Q = E‚àó
1 ¬∑ ¬∑ ¬∑ E‚àó
n of E1, . . . , En.

1.11 Stochastic Independence and Constituents
21
Proof
‚áí) Let Q = E‚àó
1 ¬∑ ¬∑ ¬∑ E‚àó
n be a constituent of E1, . . . , En. Developing the
products, we can express Q as a polynomial œÜ of E1, . . . , En where the degree in
every variable is 1:
E‚àó
1 ¬∑ ¬∑ ¬∑ E‚àó
n = œÜ(E1, . . . , En).
For example, consider the constituent Q of the events E1, E2, E3 given by
Q = ÀúE1E2E3 = (1 ‚àíE1)E2E3 = E2E3 ‚àíE1E2E3 .
Here œÜ(x1, x2, x3) = x2x3 ‚àíx1x2x3 = (1 ‚àíx1)x2x3.
If the events E1, . . . , En are stochastically independent, the probabilities of prod-
ucts factorize into products of probabilities so that
P(Q) = P (œÜ(E1, . . . , En))
= œÜ (P(E1), . . . , P(En))
= P(E‚àó
1) ¬∑ ¬∑ ¬∑ P(E‚àó
n),
where the last equality is obtained by collecting terms in œÜ and using that P( ÀúEi) =
1 ‚àíP(Ei). In the example Q = ÀúE1E2E3. We have
P(Q) = P

ÀúE1E2E3

= P (E2E3 ‚àíE1E2E3)
= P(E2)P(E3) ‚àíP(E1)P(E2)P(E3) = œÜ(P(E1), P(E2), P(E3))
= (1 ‚àíP(E1))P(E2)P(E3) = P( ÀúE1)P(E2)P(E3).
‚áê) We assume that (1.16) holds for all constituents of the events E1, . . . , En. Let
{i1, . . . , ik} ‚äÇ{1, . . . , n} and { j1, . . . , jn‚àík} = {1, . . . , n} \ {i1, . . . , ik}. Then
P(Ei1 ¬∑ ¬∑ ¬∑ Eik) = P
‚éõ
‚éù

Q‚äÇEi1¬∑¬∑¬∑Eik
Q
‚éû
‚é†
= P(Ei1) ¬∑ ¬∑ ¬∑ P(Eik)

P(E‚ãÜ
j1 . . . E‚ãÜ
jn‚àík)
where the sum ranges over all possible choices of E‚ãÜ
jl for l = 1, . . . , n ‚àík. By
collecting terms we get:
P(Ei1 . . . Eik) = P(Ei1) . . . P(Eik)[(P(E j1) + P( ÀúE j1)] . . . [P(E jn‚àík) + P( ÀúE jn‚àík)]
= P(Ei1) . . . P(Eik),
since the last n ‚àík factors are all equal to 1.
‚ñ°

22
1
Random Numbers
1.12
Covariance and Variance
Given two random numbers X and Y, the covariance between X and Y is deÔ¨Åned by
cov(X, Y) = P ((X ‚àíP(X))(Y ‚àíP(Y))) .
X and Y are said to be:
‚Ä¢ positively correlated if cov(X, Y) > 0;
‚Ä¢ negatively correlated if cov(X, Y) < 0;
‚Ä¢ non-correlated if cov(X, Y) = 0.
By developing the product in the deÔ¨Ånition of the covariance, we obtain:
cov(X, Y) = P(XY ‚àíP(X)Y ‚àíXP(Y) + P(X)P(Y)) = P(XY) ‚àíP(X)P(Y).
The variance of a random number X is deÔ¨Åned by
œÉ2(X) = cov(X, X).
Other notations for the variance of X are var(X) and D(X). From the two expressions
for the covariance we get two expressions for the variance: œÉ2(X) = P(X2)‚àíP(X)2
and œÉ2(X) = P

(X ‚àíP(X))2
. From the second expression we see that
œÉ2(X) ‚â•0,
as it is the expectation of a non-negative random number. We also deÔ¨Åne:
‚Ä¢ quadratic expectation:
PQ(X) =

P(X2);
‚Ä¢ standart deviation:
œÉ(X) =

œÉ2(X) = PQ(X ‚àíP(X)).
Proposition 1.12.1 (Properties of covariance and variance) Covariance and vari-
ance satisfy the following properties:
1. bilinearity:
cov(X + Y, Z) = cov(X, Z) + cov(Y, Z);
(1.17)
2. behavior with respect to linear transformations:
cov(aX + b, cY + d) = ac cov(X, Y),
(1.18)
œÉ2(aX + b) = a2œÉ2(X).
(1.19)

1.12 Covariance and Variance
23
Proof
1. From the deÔ¨Ånition of covariance we have
cov(X + Y, Z) = P((X + Y) ‚àíP(X + Y), Z ‚àíP(Z)
= P((X + Y) ‚àíP(X) ‚àíP(Y))(Z ‚àíP(Z))
= P(((X ‚àíP(X))(Z ‚àíP(Z))) + P(((Y ‚àíP(Y))(Z ‚àíP(Z)))
= cov(X, Z) + cov(Y, Z) .
2. Again from the deÔ¨Ånition of covariance and the linearity of the expectation we
have:
cov(aX + b, cY + d) = P ((aX + b ‚àíP(aX + b)) (cY + d ‚àíP(cY + d)))
= P ((aX + b ‚àíaP(X) ‚àíb) (cY + d ‚àícP(Y) ‚àíd))
= P (a (X ‚àíP(X)) c (Y ‚àíP(Y)))
= ac cov(X, Y).
‚ñ°
Proposition 1.12.2 (Variance of the sum of random numbers) Let X1, . . . , Xn n be
random numbers, then:
œÉ2(X1 + ¬∑ ¬∑ ¬∑ + Xn) =
n

i=1
œÉ2(Xi) +

i, j
iÃ∏= j
cov(Xi, X j)
=
n

i=1
œÉ2(Xi) + 2

i< j
cov(Xi, X j).
Proof By the bilinearity property (1.17) we have:
œÉ2(X1 + ¬∑ ¬∑ ¬∑ + Xn) = cov(X1 + ¬∑ ¬∑ ¬∑ + Xn, X1 + ¬∑ ¬∑ ¬∑ + Xn)
=
n

i=1
cov(Xi, Xi) +

iÃ∏= j
cov(Xi, X j)
=
n

i=1
œÉ2(Xi) +

i, j
iÃ∏= j
cov(Xi, X j).
‚ñ°
1.13
Correlation CoefÔ¨Åcient
It is useful to introduce an index of the correlation of two random numbers X, Y,
called correlation coefÔ¨Åcient. As we shall see, it has the property that if X and Y
correspond to observed quantities, it does not depend on the units of measure of X
and Y.

24
1
Random Numbers
DeÔ¨Ånition 1.13.1 For X, Y random numbers with œÉ(X) > 0, œÉ(Y) > 0 the corre-
lation coefÔ¨Åcient of X and Y is deÔ¨Åned by
œÅ(X, Y) = cov(X, Y)
œÉ(X) œÉ(Y).
Let us state two important properties of the correlation coefÔ¨Åcient:
1. If X, Y are random numbers with œÉ(X) > 0, œÉ(Y) > 0 and a, b, c, d are con-
stants with a Ã∏= 0 and c Ã∏= 0, we have
œÅ(aX + b, cY + d) = sgn(ac) œÅ(X, Y),
where sgn(x) = 1 for x > 0 and sgn(x) = ‚àí1 for x < 0.
Proof By using the properties (1.18) and (1.19) we get
œÅ(aX + b, cY + d) =
cov(aX + b, cY + d)

œÉ2(aX + b) œÉ2(cY + d)
=
ac cov(X, Y)
|ac|

œÉ2(X) œÉ2(Y)
= sgn(ac) œÅ(X, Y).
‚ñ°
2. ‚àí1 ‚â§œÅ(X, Y) ‚â§1.
Let
X‚àó= X ‚àíP(X)
œÉ(X)
,
Y ‚àó= Y ‚àíP(Y)
œÉ(Y)
.
These are the so-called standardized random numbers: they are obtained from
X, Y by means of suitable linear transformation such that P(X‚àó) = 0, P(Y ‚àó) = 0
and œÉ2(X‚àó) = 1, œÉ2(Y ‚àó) = 1 by using linearity of the expectation and (1.19).
By (1.18) we get
cov(X‚àó, Y ‚àó) = P (X‚àóY ‚àó)
œÉ(X) œÉ(Y) = œÅ(X, Y).
Computing the variance of X‚àó+ Y ‚àóusing Proposition 1.12.1 we get:
0 ‚â§œÉ2(X‚àó+ Y ‚àó) = œÉ2(X‚àó) + œÉ2(Y ‚àó) + 2 cov(X‚àó, Y ‚àó)
= 2 + 2œÅ(X, Y),

1.13 Correlation CoefÔ¨Åcient
25
so that œÅ(X, Y) ‚â•‚àí1. Similarly computing the variance of X‚àó‚àíY ‚àó, we obtain
0 ‚â§œÉ2(X‚àó‚àíY ‚àó) = œÉ2(X‚àó) + œÉ2(‚àíY ‚àó) + 2 cov(X‚àó, ‚àíY ‚àó)
= 2 ‚àí2œÅ(X, Y).
so that œÅ(X, Y) ‚â§1.
1.14
Chebychev‚Äôs Inequality
The Chebychev‚Äôs inequality allows to estimate the probability that a random number
takes value far from its expectation. It can be formulated in two ways:
1. Let X be a random number with PQ(X) > 0. For every t > 0
P

|X| ‚â•t PQ(X)

‚â§1
t2 .
2. Let X be a random number with œÉ2(X) > 0. Let m = P(X), ‚àÄt > 0:
P (|X ‚àím| ‚â•œÉ(X)t) ‚â§1
t2 .
Proof
1. Let E be the event E =

|X| ‚â•t PQ(X)

. We compute P

X2
using the
formula of total expectation with respect to the partition E, ÀúE:
P

X2
= P

X2|E

P(E) + P

X2| ÀúE

P

ÀúE

.
Since X2 is non-negative, the last term on the right-hand side is non-negative.
Moreover inf I (X2|E) ‚â•t2. Then PQ(X)2 = t2P(X)2 in force of the deÔ¨Ån-
ition of E. Therefore we have P(X)2 ‚â•t2P(X2)P(E). This implies the Ô¨Årst
inequality.
2. The second inequality follows from the Ô¨Årst by applying it to the random number
Y = X ‚àím and using that PQ(Y) = œÉ(X).
‚ñ°
1.15
Weak Law of Large Numbers
Theorem 1.15.1 (Weak law of large numbers). Let (Xn)n=1,2,... be a sequence of
random numbers such that all have the same expectation, P(Xi) = m, the same
variance œÉ2(Xi) = œÉ2 and cov(Xi, X j) = 0, ‚àÄi, j with i Ã∏= j. If we put Sn =
X1 + ¬∑ ¬∑ ¬∑ + Xn, we have that for all Œª > 0

26
1
Random Numbers
lim
n‚Üí+‚àûP

| Sn
n ‚àím| ‚â•Œª

= 0 .
Proof The proof is based on the second form of Chebychev‚Äôs inequality. First we
compute the expectation of Sn
n :
P

 Sn
n

= 1
n (P(X1) + ¬∑ ¬∑ ¬∑ + P(Xn)) = m
and its variance
œÉ2

 Sn
n

= 1
n2 œÉ2(Sn) = 1
n2 (œÉ2(X1) + ¬∑ ¬∑ ¬∑ + œÉ2(Xn)) = œÉ2
n ,
where we have used Proposition 1.12.2 and the fact that random numbers of the
sequence are pairwise uncorrelated. From the second form of Chebychev‚Äôs inequality
we get
P

| Sn
n ‚àím| ‚â•œÉ
‚àön t

‚â§1
t2 .
Putting Œª = œÉ
‚àön t, we obtain 1
t2 = œÉ2
nŒª2 . Therefore
P

| Sn
n ‚àím| ‚â•Œª

‚â§œÉ2
nŒª2 ,
that tends to 0 as n ‚Üí+‚àû.
‚ñ°
The quantity Sn
n = E1 + ¬∑ ¬∑ ¬∑ + En
n
is called frequence. In this case the weak law
of large numbers shows that for a large sequence of trials (events) the frequence of
success is close to the probability of a single event with large probability.
Example 1.15.2 In particular one can apply the weak law of large numbers to the
case of a sequence of uncorrelated events (Ei)i=1,2,... with the same probability
P(Ei) = p. Note that for an event Ei,
œÉ2(Ei) = P(E2
i ) ‚àíP(Ei)2 = P(Ei) ‚àíP(Ei)2 = p(1 ‚àíp)
so the Ei‚Äôs have automatically the same variance. Hence for all Œª > 0 we have
P

| Sn
n ‚àíp| ‚â•Œª

‚Üí0
for n ‚Üí‚àû.

Chapter 2
Discrete Distributions
2.1
Random Numbers with Discrete Distribution
The distribution of a random number X is said to be discrete if there is a Ô¨Ånite or
enumerable set A ‚äÇI (X) such that P(X ‚ààA) = 1. This is obviously the case
when I (X) is itself Ô¨Ånite or enumerable, since in this case we may take A = I (X).
Let A = {x1, x2, . . .} and deÔ¨Åne p(xi) = P(X = xi). In the examples of discrete
distributions that we shall consider, we always have
‚àû

i=1
p(xi) = 1 .
This property is not a consequence of the basic properties of expectation that
we have derived from the coherence principles (from linearity and monotonicity we
only get that ‚àû
i=1 p(xi) ‚â§1). It can be considered as a regularity property of the
expectation. See [dF] for a thorough discussion of this problem. In the following we
introduce some of the most common discrete distributions.
2.2
Bernoulli Scheme
A simple and useful model from which some discrete distributions can be derived is
the Bernoulli scheme. It can be thought of as a potentially inÔ¨Ånite sequence of trials,
each of them with two possible outcomes called success and failure. Each trial is
performed in the same known conditions and we assume that there is no inÔ¨Çuence
between different trials. Formally a Bernoulli scheme with parameter p, 0 < p < 1,
is a sequence E1, E2, . . . of stochastically independent equiprobable events with
P(E1) = p.
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_2
27

28
2
Discrete Distributions
Example 2.2.1 A concrete example for which one can use as a model a Bernoulli
scheme with p = 1
2 is a sequence of throws of a symmetric coin, where Ei is the
event that one gets head at the ith throw.
2.3
Binomial Distribution
Given a Bernoulli scheme (Ei)i‚ààN with P(Ei) = p, let Sn the random number of
successes in the Ô¨Årst n trials. Sn can be written as
Sn = E1 + ¬∑ ¬∑ ¬∑ + En.
The set of possible values of Sn is I (Sn) = {0, . . . , n}.
Let us compute, using the constituents of the events E1, . . . , En, the probability
distribution of Sn:
P(Sn = k) =

Q‚äÇ(Sn=k)
P(Q) .
We must determine the probability of a constituent of I type with respect to the event
(Sn = k). An example of such a constituent is
Q = E1 . . . Ek ÀúEk+1 . . . ÀúEn,
(2.1)
that is the event that k successes are obtained in the Ô¨Årstk trials, whereas the remaining
n ‚àík trials yield failures.
Analogously,anyotherconstituentof I typewillbeaproductofthesamekindasin
(2.1). Since the events are stochastically independent, in force of Proposition 1.11.1,
every constituent Q of I type has the same probability, given by
P(Q) = p ¬∑ ¬∑ ¬∑ p
  
k times
(1 ‚àíp) ¬∑ ¬∑ ¬∑ (1 ‚àíp)



(n‚àík) times
= pk(1 ‚àíp)n‚àík .
In order to compute P(Sn = k) we must therefore multiply this value times the
number of constituents of I type. This is equal to
n
k
	
, that is the number of ways
of choosing a subset of k elements out of n trials. Therefore we have
P(Sn = k) =
n
k
	
pk(1 ‚àíp)n‚àík .
Sn is said to have binomial distribution Bn(n, p) with parameters n, p.
It is easy to check that n
k=0 P(Sn = k) = 1, as it must be since the events
(Sn = k), k = 0, . . . , n, make up a partition. Indeed, using Newton‚Äôs formula, we
have:

2.3 Binomial Distribution
29
1 = (p + 1 ‚àíp)n =
n

k=0
n
k
	
pk(1 ‚àíp)n‚àík .
The simplest way to compute the expectation of Sn is through the linearity of expec-
tation:
P(Sn) = P(E1 + ¬∑ ¬∑ ¬∑ + En) =
n

i=1
P(Ei) = np .
Example 2.3.1 Consider an urn containing N identical balls, of which H are white
and N ‚àíH are black. We perform a sequence of n drawings with replacement.
It is easy to check that by symmetry the sequence of events (Ei)i = 1, 2, ... where
Ei = (a white ball is drawn at the ith drawing) makes up a Bernoulli scheme, with
parameters p = H
N . Indeed for 1 ‚â§i1 < i2 < . . . < ik
P(Ei1 . . . Ein) = H k
N k =
 H
N
	k
,
where the possible cases correspond to the N k sequences of balls that may be drawn in
the drawings i1, . . . , ik, whereas the favorable cases correspond to the H k sequences
where white balls are drawn.
2.4
Geometric Distribution
Let (Ei)i = 1, 2, ... be a Bernoulli scheme; let T be the random number representing
the number of the trial when the Ô¨Årst success is obtained, i.e. T = min{n | En = 1}.
The set of possible values of T is given by:
I (T ) = N \ {0} ‚à™{‚àû} .
It is easy to see that P(T = ‚àû) = 0 since for all n > 0, (T = ‚àû) ‚äÜÀúE1 . . . ÀúEn
so that P(T = ‚àû) ‚â§P( ÀúE1 . . . ÀúEn) = (1 ‚àíp)n for every n. Let us compute the
probability distribution of T for Ô¨Ånite values:
P (T = i) = P

ÀúE1 . . . ÀúEi‚àí1Ei

= P

ÀúE1

. . . P

ÀúEi‚àí1

P (Ei) = (1 ‚àíp)i‚àí1 p .
T is said to have geometric distribution with parameter p. Using the formula for the
sum of geometric series (see Appendix G.1), one veriÔ¨Åes that
+‚àû

i=1
P(T = i) =
+‚àû

i=1
(1 ‚àíp)i‚àí1 p = p
+‚àû

k=0
(1 ‚àíp)k = p ¬∑
1
1 ‚àí(1 ‚àíp) = 1.

30
2
Discrete Distributions
The expectation of T can be computed by an extension of formula (1.10) to the case
of enumerable set of values. This can be justiÔ¨Åed (providing that the series converges)
as a regularity property, thinking that T can be approximated with random numbers
with a Ô¨Ånite but arbitrarily large number of values. We then get
P(T ) =
+‚àû

i=1
iP(T = i) =
+‚àû

i=1
i(1 ‚àíp)i‚àí1 p = p
+‚àû

i=1
i(1 ‚àíp)i‚àí1 = p
p2 = 1
p ,
where we used that for |x| < 1
+‚àû

i=1
ixi‚àí1 =
+‚àû

i=1
d
dx [xi] = d
dx
+‚àû

i=0
xi

= d
dx

1
1 ‚àíx
	
=
1
(1 ‚àíx)2 .
The geometric distribution is said to be ‚Äúmemoryless‚Äù. Indeed for m > 0, n > 0
P(T > m + n | T > n) = P(T > m),
i.e. the conditional probability of no success up and including the (m+n)th trial given
that there was no success up and including the nth trial is equal to the probability
of no success up and including the m trial: everything starts from scratch. We have
namely that
P(T > m + n | T > n) = P(T > m + n, T > n)
P(T > n)
= P(T > m + n)
P(T > n)
.
But P(T > n) = (1 ‚àíp)n since (T > n) = ÀúE1 ‚àíÀúEn. Hence
P(T > m + n | T > n) = (1 ‚àíp)m+n
(1 ‚àíp)n
= (1 ‚àíp)m = P(T > m) .
2.5
Poisson Distribution
A random number X is said to have Poisson distribution with parameters Œª, Œª ‚ààR+,
if I (X) = N and
P(X = i) = Œªi
i! e‚àíŒª .
As in the case of a geometric distribution +‚àû
i=0 P(X = i) = 1. Indeed
+‚àû

i=0
P(X = i) =
+‚àû

i=0
Œªi
i! e‚àíŒª = e‚àíŒª
+‚àû

i=0
Œªi
i! = e‚àíŒªeŒª = 1 .

2.5 Poisson Distribution
31
In order to compute the expectation, we use the extension of the formula for random
numbers with a Ô¨Ånite number of possible values to the case of a enumerable set of
possible values as we did for geometric distribution and as we will do in similar cases
(provided that the series is convergent). We obtain
P(X) =
+‚àû

i=0
iP(X = i) =
+‚àû

i=0
i Œªi
i! e‚àíŒª = Œªe‚àíŒª
+‚àû

i=1
Œªi‚àí1
(i ‚àí1)!
= Œªe‚àíŒª
+‚àû

k=0
Œªk
k! = Œªe‚àíŒªeŒª = Œª .
2.6
Hypergeometric Distribution
Consider an urn containing N balls of which H are white and N ‚àíH black, where
0 < H < N. We perform n drawings without replacement from the urn with n ‚â§N.
Let X be the random number that counts the number of white balls in the sample
that we draw.
Since we perform drawings without replacement, X is less than or equal to H and
n ‚àíX, the number of black balls in the sample, is less than or equal to N ‚àíH. From
this it follows that the set of possible values of X is given by
I (X) = {0 ‚à®n ‚àí(N ‚àíH), . . . , n ‚àßH} .
Let i ‚ààI (X). Due to the symmetry of the situation with respect to interchange of
balls, we evaluate P(X = i) using formula (1.12). When deÔ¨Åning possible cases and
consequently favorable cases, we can consider the set of the n drawn balls, i.e. we
can avoid to consider the order of drawings, as the event does not involve the order.
In this way the possible cases correspond to the subset of size n from a set of N
elements:
‚ôØpossible cases =
 N
n
	
.
A sample with i white balls contains (n ‚àíi) black balls. The number of favorable
cases that correspond to such samples is therefore given by:
‚ôØf avorable cases =
 H
i
	  N ‚àíH
n ‚àíi
	
.
The random number X is said to have hypergeometric distribution with parameters
n, H, N. By the former discussion we have:

32
2
Discrete Distributions
P(X = i) =
 H
i
	  N ‚àíH
n ‚àíi
	
 N
n
	
.
In order to compute the expectation of X, it is convenient to decompose it as
X =
n

i=1
Ei
where Ei is the event that a white ball is chosen at ith drawing. Therefore by the
linearity of the expectation
P(X) = P(E1) + ¬∑ ¬∑ ¬∑ + P(En).
In the evaluation of P(Ei) we can still use symmetry by interchange of balls, but when
deÔ¨Åning possible cases we must take into account the order, since the event depends
on the order of the drawings. Possible cases correspond to sequences of length n
of distinct elements from a set of N elements. Their number is DN
n
= (N)n =
N(N ‚àí1) ‚àí(N ‚àín + 1). Favorable cases correspond to those sequences that have
a white ball at the ith place. This ball can be chosen in H ways. The remaining balls
form a sequence of lenght n ‚àí1 of distinct elements from a set of N ‚àí1 elements.
Therefore
P(Ei) = ‚ôØf avorable cases
‚ôØpossible cases
= H DN‚àí1
n‚àí1
DNn
= H
N
and
P(X) = n H
N .
2.7
Independence of Partitions
Two partitions H = (H1, . . . , Hm), L = (L1, . . . , Ln) are said to be stochastically
independent if for every i, j with 1 ‚â§i ‚â§m, 1 ‚â§j ‚â§n
P

Hi L j

= P (Hi) P

L j

.
Stochastic independence can be extended to the case of r partitions H1, . . . , Hr.
Consider the partitions
Hl = (H (l)
1 , . . . , H (l)
nl )
for 1 ‚â§l ‚â§r. H1, . . . , Hr are said to be stochastically independent if for every
i1, . . . , ir with 1 ‚â§il ‚â§nl, . . . , 1 ‚â§l ‚â§r

2.7 Independence of Partitions
33
P

H (1)
i1 . . . H (r)
ir

= P

H (1)
i1

. . . P

H (r)
ir

.
Partitions can be thought as pluri-events, with a certain number of possible results,
such as in the case of drawings from an urn containing balls of several colors. In the
case of partitions with two events, one can select an event from each partition. In this
case stochastic independence of partitions is equivalent to stochastic independence
of the selected events.
2.8
Generalized Bernoulli Scheme
Let H1, H2, . . . be a sequence of partitions, each composed by r events, Hi =

E(i)
1 , . . . , E(i)
r

for i ‚â•1. We assume that H1, . . . , Hn are stochastically inde-
pendent for every n and that P(E(i)
k ) = pk, k = 1, . . . ,r, for all i ‚â•1, with
p1 + ¬∑ ¬∑ ¬∑ + pr = 1. The sequence H1, H2, . . . is called a generalized Bernoulli
scheme. In the case r = 2 a generalized Bernoulli scheme is equivalent to the ordi-
nary Bernoulli scheme (F1, F2, . . .) where Fi = E(i)
1
with parameter p = p1. We
can represent a generalized Bernoulli scheme in an array:
E(1)
1 , . . . , E(1)
r
E(2)
1 , . . . , E(2)
r
... , . . . ,
...
... , . . . ,
...
E(n)
1 , . . . , E(n)
r ,
where the events belonging to the same column are equiprobable, whereas the events
of each row constitute stochastically independent partitions.
2.9
Multinomial Distribution
Starting from a generalized Bernoulli scheme, as deÔ¨Åned in Sect.2.2, we can now
deÔ¨Åne the multinomial distribution in the same way as the binomial distribution can
be deÔ¨Åned starting from an ordinary Bernoulli scheme. Given n > 0, let us consider
the random numbers Y1, . . . , Yr deÔ¨Åned by
Yl =
n

i=1
E(i)
l
, l = 1, . . . ,r .

34
2
Discrete Distributions
In the array of the previous section, the Yl‚Äôs are obtained by adding up the events
along the columns. We have
r

l=1
Yl =
r

l=1
n

i=1
E(i)
l
=
n

i=1
r

l=1
E(i)
l
  
1
= n .
The idea of constituents can be extended in a natural fashion from events to partitions.
A constituent of the partition H1, . . . , Hn is an event of the form
Q = n
i=1Hi
‚àó,
where Hi
‚àóis an event of the partition Hi. If H1, . . . , Hn are stochastically independent
(as in the case of generalized Bernoulli scheme) we have:
P(Q) = P(H 1
‚àó) . . . P(H n
‚àó) .
We want to compute
P (Y1 = k1, . . . , Yr = kr)
for k1 ‚â•0, kr ‚â•0 such that k1 + ¬∑ ¬∑ ¬∑ + kr = n. We can decompose this probability
in terms of constituents of I type:
P(Y1 = k1, . . . , Yr = kr) =

Q
P(Q),
where Q varies among the constituents of I type contained in the event (Y1 =
k1, . . . , Yr = kr). In the product deÔ¨Åning a constituent of I type there will be kl
events of index l with 1 ‚â§l ‚â§r. Therefore since the partitions are stochastically
independent, the probability of a constituent of I type is given by:
P(Q) = pk1
1 , . . . , pkr
r .
The number of constituents of I type is equal to the way of partitioning a set of n
elements into r subsets with k1, . . . , kr elements, i.e.
n!
k1! . . . kr!. We have therefore:
P (Y1 = k1, . . . , Yr = kr) =

Q I type
P(Q) =
n!
k1! . . . kr!



number of constituents
pk1
1 . . . pkr
r



P(Q)
.
The multinomial distribution depends on the parameters r, p1, . . . , pr‚àí1, since pr =
1 ‚àír‚àí1
i=1 pi. For r = 2 the multinomial distribution reduces to the binomial one.

2.10 Stochastic Independence for Random Numbers ‚Ä¶
35
2.10
Stochastic Independence for Random Numbers
with Discrete distribution
Let X and Y be two random numbers with I (X) = {x1, . . . , xm} and I (Y) =
{y1, . . . , yn}. We consider the partitions H and K generated by the events Hi =
(X = xi), for i = 1, . . . , m, and K j = (Y = y j), for j = 1, . . . , n.
The random numbers X and Y are said to be stochastically independent if the
partitions H and K are stochastically independent.
2.11
Joint Distribution
Let us consider two random numbers X and Y, that we can look at as a random vector
(X, Y), assuming a Ô¨Ånite number of possible values I (X, Y). If I (X) = {x1, . . . , xm}
and I (Y) = {y1, . . . , yn} we deÔ¨Åne the joint distribution of X and Y. This is the
function
p(xi, y j) = P(X = xi, Y = y j)
deÔ¨Åned on I (X) √ó I (Y). We can associate to it the matrix
‚éõ
‚éú‚éù
p(x1, y1) . . . p(x1, yn)
...
...
...
p(xm, y1) . . . p(xm, yn)
‚éû
‚éü‚é†.
The marginal distribution of X is the function
p1(xi) = P(X = xi)
for i = 1, . . . , m. The marginal distribution can be obtained from the joint distribu-
tion:
p1(xi) = P(X = xi) =
n

j=1
P(Xi, Y j) =
n

j=1
p(xi, y j),
i.e. adding up the elements on the rows of the matrix. It is called marginal because it
is customarily written at the margin of the matrix. Similarly the marginal distribution
of Y is deÔ¨Åned by:
p2(y j) = P(Y = y j) =
m

i=1
p(xi, y j) .

36
2
Discrete Distributions
It follows that two random numbers X and Y are stochastically independent if and
only if
p(xi, y j) = p1(xi)p2(y j)
(2.2)
for i = 1, . . . , m and j = 1, . . . , n. Given œà : R2 ‚àí‚ÜíR, the expectation of the
random number Z = œà(X, Y) can be obtained from the joint distribution of X, Y:
P(Z) = P(œà(X, Y)) =
m

i=1
n

j=1
œà(xi, y j)p(xi, y j) .
(2.3)
The proof is completely analogous to that one in the case of a single random number.
For example, we can compute P(XY):
P(XY) =
m

i=1
n

j=1
xi y j p(X = xi, Y = y j).
If X and Y are stochastically independent and œÜ1, œÜ2 are two real functions œÜi :
R ‚àí‚ÜíR with i = 1, 2, we have that
P(œÜ1(X)œÜ2(Y)) = P(œÜ1(X))P(œÜ2(Y)).
(2.4)
Indeed
P(œÜ1(X)œÜ2(Y)) =
m

i=1
n

j=1
œÜ1(xi)œÜ2(y j)P(X = xi, Y = y j)
=

(xi,y j)‚ààI (X)√óI (Y)
œÜ1(xi)œÜ2(y j)p1(xi)p2(y j)
=

xi‚ààI (X)
œÜ1(xi)p1(xi)

y j‚ààI (Y)
œÜ2(y j)p2(y j)
= P(œÜ1(X))P(œÜ2(Y)) .
2.12
Variance of Discrete Distributions
We compute the variances of the distributions that we have previously introduced.
1. Variance of an event:
œÉ2(E) = P

E2
‚àíP (E)2 = P(E) ‚àíP(E)2 = P(E)(1 ‚àíP(E)) ,
where we use that for an event E2 = E since E can take only values 0 and 1.

2.12 Variance of Discrete Distributions
37
2. Binomial distribution: For X with binomial distribution with parameters nx and
p, we use the representation X = E1+. . . + En, where the Ei‚Äôs are stochastically
independent and hence pairwise uncorrelated. We get:
œÉ2(E1 + . . . + En) =
n

i=1
œÉ2(Ei) = np(1 ‚àíp) .
3. Geometric distribution: we need to compute P(X2) as we have already computed:
P(X) =
+‚àû

i=1
ip(1 ‚àíp)i‚àí1 = 1
p .
Hence
P(X2) = p
+‚àû

i=1
i2(1 ‚àíp)i‚àí1 =

p
+‚àû

i=1
i(i ‚àí1)(1 ‚àíp)i‚àí1

+ p
+‚àû

i=1
i(1 ‚àíp)i‚àí1
= p(1 ‚àíp)
+‚àû

i=2
i(i ‚àí1)(1 ‚àíp)i‚àí2 + 1
p
= p(1 ‚àíp) d2
d2 p
+‚àû

i=2
(1 ‚àíp)i

+ 1
p
= p(1 ‚àíp)
 d2
d2 p
	 
1
1 ‚àí(1 ‚àíp) ‚àí1 ‚àí(1 ‚àíp)
	
+ 1
p
= 2(1 ‚àíp)
p2
+ 1
p
=
2
p2 ‚àí1
p .
Therefore the variance of the geometric distribution is given by
œÉ2(X) = P[X2] ‚àíP(X)2 = (1 ‚àíp)
p2
.
4. Poisson distribution: if X has Poisson distribution with parameter Œª, we have:
P(X2) =
+‚àû

i=0
i2P(X = i) =
+‚àû

i=0
i2 Œªi
i! e‚àíŒª = e‚àíŒª
+‚àû

i=0
i(i ‚àí1)Œªi
i! + Œªe‚àíŒª
+‚àû

i=0
Œªi
i!
= Œª2e‚àíŒª
+‚àû

i=2
Œªi‚àí2
(i ‚àí2)! + Œª = Œª2e‚àíŒª
+‚àû

k=0
Œªk
k! + Œª = Œª2 + Œª
where we have used the computation of the expectation of the Poisson distribution.

38
2
Discrete Distributions
We have then
œÉ2(X) = P(X2) ‚àíP(X)2 = Œª2 + Œª ‚àíŒª2 = Œª .
5. Hypergeometric distribution: with the notation of Sect.2.6, we use the represen-
tation X = E1+¬∑ ¬∑ ¬∑ + En. The events Ei‚Äôs in this case are not stochastically inde-
pendent and are actually pairwise negatively correlated. Indeed, for 0 < H < N
for every pair i, j with i Ã∏= j, we have:
cov(Ei, E j) = P(Ei E j) ‚àíP(Ei)P(E j) = H
N 2
H ‚àíN
N ‚àí1 < 0
as
P(Ei E j) = H(H ‚àí1)DN‚àí2
n‚àí2
DNn
= H(H ‚àí1)
N(N ‚àí1)
DN‚àí2
n‚àí2
DN‚àí2
n‚àí2
= H(H ‚àí1)
N(N ‚àí1) .
Here we have used formula (1.12); possible cases are sequences with no repetition
of length n from a set of N elements, whereas in counting favorable cases we
Ô¨Årst select two different white balls for the ith and the jth drawings and then the
remaining n ‚àí2 balls from a set of N ‚àí2 elements.
The variance of X is then obtained by means of the formula for the variance of
the sum of n random numbers:
œÉ2(X) =
n

i=1
œÉ2(Ei) +

i, j
iÃ∏= j
cov(Ei, E j)
= n H
N (1 ‚àíH
N ) + n(n ‚àí1) H
N 2
H ‚àíN
N ‚àí1 = n N ‚àín
N ‚àí1
H
N (1 ‚àíH
N ) ,
where n(n ‚àí1) is the number of ordered pairs i, j, with i Ã∏= j, which can be chosen
out of {1, . . . , n}.
2.13
Non-correlation and Stochastic Independence
Let us consider two random numbers X and Y with discrete joint distribution given
by:
p(Xi, Y j) = P(X = xi, Y = y j) = pi, j
and marginal distributions given by:
p1(xi) = P(X = xi) = pi
i = 1, . . . , m ,
p2(y j) = P(Y = y j) = q j
j = 1, . . . , n .

2.13 Non-correlation and Stochastic Independence
39
X and Y are non-correlated if
P(XY) = P(X)P(Y)
i.e. if

i

j
xi y j pi, j =

i
xi pi

j
y jq j .
Moreover, the following relations are satisÔ¨Åed:

i pi = 1 and 
j pi, j = pi for i = 1, . . . , m ,

j q j = 1 and 
i pi, j = q j for j = 1, . . . , n ,

i

j
pi, j = 1 .
Assume that we want to Ô¨Ånd values pi, j of the joint distribution, such that X and Y are
non-correlated and have two Ô¨Åxed marginal distributions {pi}i=1,...,m and

q j

j=1,...,n.
We observe Ô¨Årst of all that pi, j must satisfy the relation 
i, j pi, j = 1. In order to
determine the marginal distributions we must verify other additional (m‚àí1)+(n‚àí1)
linear relations. We have (m‚àí1)+(n‚àí1) and not m+n, since once (m‚àí1)+(n‚àí1)
relations are satisÔ¨Åed, the last two follow from the fact that 
i, j pi, j = 1, 
i pi = 1,

j q j = 1. Finally in order to impose non-correlation, an extra linear relation must
be veriÔ¨Åed on the pi, j‚Äôs:

i

j
pi, jxi y j = m1m2,
where m1 = m
i xi pi and m2 = n
j y jq j. We have therefore a system of 1 +
(m ‚àí1) + (n ‚àí1) + 1 = m + n linear equations for mn unknowns. This system has
the solution pi, j = piq j, for which X and Y are stochastically independent. This will
be the only solution if the number of linearly independent equations is equal to the
number of the unknowns, i.e. if m + n = mn, or mn‚àím‚àín = (m‚àí1)(n‚àí1)‚àí1 = 0.
This happens only if m = n = 2. It follows that non-correlation does not imply in
general stochastic independence. If m = n = 2, then there is just one solution so
that non-correlation and stochastic independence coincide. This is the case of events:
two events are non-correlated if and only if they are stochastically independent.
In Sect.2.11 we have shown that stochastic independence implies non-correlation
and that in fact it implies non-correlation of any two functions of the random numbers.
2.14
Generating Function
Let X be a random number with discrete distribution on a subset of N. The generating
function of X is deÔ¨Åned for u ‚ààC, |u| ‚â§1, by

40
2
Discrete Distributions
œÜX(u) := P(u X) =

k‚ààI (X)
ukP(X = k).
(2.5)
The expectation of a complex random variable is deÔ¨Åned as the expectation of the
real part plus i times the expectation of the imaginary part. The condition |u| ‚â§1
guarantees that the series (2.5) is convergent in the case of inÔ¨Ånitely many possible
values. We will use characteristic functions just for real values of u. We have that
œÜX(0) = P(X = 0).
In general, computing the nth derivative of (2.5) in u = 0, we obtain
P(X = n) = 1
n!
dnœÜX(u)
dxn

u=0,
for every n ‚ààN. This shows that the probability distribution of X can be obtained
from its generating function.
Proposition 2.14.1 If P(X) = 
k‚ààI (X) kP(X
= k) < ‚àû, then P(X) =
limu‚Üí1‚àíœÜ‚Ä≤
X(u). Moreover P(X) = 
k‚ààI (X) kP(X = k) = +‚àûif and only if
limu‚Üí1 œÜ‚Ä≤
X(u)= ‚àû.
This is a particular case of the following result.
Proposition 2.14.2 If P(X(X ‚àí1) . . . (X ‚àík + 1)) = 
k‚ààI (X)(k(k ‚àí1) . . . (k ‚àí
n + 1))P(X = k) < ‚àû, then
P(X(X ‚àí1) . . . (X ‚àík + 1)) = lim
u‚Üí1‚àíœÜ(n)
X (u) .
Furthermore 
k‚ààI (X)(k(k ‚àí1) . . . (k ‚àín + 1))P(X = k) = ‚àûif and only if
limu‚Üí1‚àíœÜ(n)
X (u) = ‚àû.
Previous results are easily obtained by taking the derivatives of the generating func-
tion. In particular the variance of X can be obtained from the generating function:
œÉ2(X) = P(X2) ‚àíP(X)2 = lim
u‚Üí1‚àí

œÜ‚Ä≤‚Ä≤
X(u) + œÜ‚Ä≤
X(u) ‚àí

œÜ‚Ä≤
X(u)
2
,
where œÜ‚Ä≤
X and œÜ‚Ä≤‚Ä≤
X denote respectively the Ô¨Årst and the second derivatives of œÜX.
Generating functions of some common discrete distributions are easily obtained:
1. Event E with probability p
œÜE(u) = up + (1 ‚àíp).

2.14 Generating Function
41
2. Binomial distribution Bn(n, p) with parameters n, p:
œÜX(u) =
n

k=0
uk
n
k
	
pk(1 ‚àíp)n‚àík
=
n

k=0
 n
k
	
(up)k(1 ‚àíp)n‚àík = (up + (1 ‚àíp))n ,
where Newton‚Äôs binomial formula has been used.
3. Geometric distribution with parameter p:
œÜX(u) =
‚àû

k=1
uk p(1 ‚àíp)k‚àí1
= up
‚àû

k=1
[u(1 ‚àíp)]k‚àí1 =
up
(1 ‚àíu(1 ‚àíp)),
where the formula for the sum of geometric series has been used.
4. Poisson distribution with parameter Œª:
œÜX(u) =
‚àû

k=0
uk Œªk
k! e‚àíŒª
= e‚àíŒª
‚àû

k=0
(uŒª)k
k!
= e‚àíŒª(1‚àíu).
If X and Y are two stochastically independent random numbers with values in N, i.e.
P(X = i, Y = j) = P(X = i)P(Y = j) for all i, j ‚ààI (X) √ó I (Y), then it is easy
to show that
œÜX+Y(u) = œÜX(u)œÜY(u).
Indeed:
œÜX+Y(u) = P(u X+Y) = P(u XuY)
=

i

j
uiu jP(X = i, Y = j)
=

i

j
uiu jP(X = i)P(Y = j)
=

i
uiP(X = i)
 ‚éõ
‚éù
j
u jP(Y = j)
‚éû
‚é†
= œÜX(u)œÜY(u) .

42
2
Discrete Distributions
Of course if we have n stochastically independent random numbers we obtain sim-
ilarly: œÜX1+¬∑¬∑¬∑+Xn(u) = œÜX1(u) . . . œÜXn(u). One can also consider the case of the
sum of a random number N of stochastically independent random numbers. Let
X1, X2, . . . be an inÔ¨Ånite sequence of stochastically independent random numbers
with values in N. This means that if we take any Ô¨Ånite number of them, they are
stochastically independent. We assume that X1, X2, . . . are identically distributed.
Let N be a random number with values in N, such that
N, X1, X2, . . .
are stochastically independent. Let SN be deÔ¨Åned by
SN = X1 + ¬∑ ¬∑ ¬∑ + X N.
We now compute the generating function of SN:
œÜSN (u) = P(uSN ) =

k‚ààI (N)
P(uSN |N = k)P(N = k)
=

k‚ààI (N)
P(uSk)P(N = k)
=

k‚ààI (N)
P(N = k)P(u X1+¬∑¬∑¬∑+Xk)
=

k‚ààI (N)
P(N = k)œÜX1(u) . . . œÜXk(u)
=

k‚ààI (N)
P(N = k)œÜX1(u)k
= œÜN

œÜX1(u)

,
where œÜN is the generating function of X and we have used the fact that the random
numbers Xi have the same distribution and hence the same generating function. See
e.g. [3] or [6] for a more complete treatment of generating functions.

Chapter 3
One-Dimensional Absolutely Continuous
Distributions
3.1
Introduction
For random numbers with discrete distribution, the distribution is completely spec-
iÔ¨Åed by the probabilities of taking single values. If we want to introduce random
numbers that take values on intervals or on the whole line, then the speciÔ¨Åcation
of the probabilities of taking single values is no longer sufÔ¨Åcient to determine their
distributions. For example for a random number corresponding to a random choice
in an interval [a, b], the probabilities of taking single values must be clearly equal
to 0, but that in no way speciÔ¨Åes the probability of taking value in a subinterval of
[a, b]. In the following we will see how it is possible to describe the distribution of
a random number in general.
3.2
Cumulative Distribution Function
Given a random number X, its cumulative distribution function (c.d.f) is deÔ¨Åned by:
F(x) = P(X ‚â§x), for x ‚ààR.
The cumulative distribution function F(x) veriÔ¨Åes the following properties:
1. 0 ‚â§F(x) ‚â§1 since it is the probability of an event.
2. It is non-decreasing: for a < b we have F(b) ‚àíF(a) = P(a < X ‚â§b) ‚â•0, so
that F(a) ‚â§F(b).
We introduce now some further properties that are usually assumed to be veriÔ¨Åed
by cumulative distribution function. They can be thought of as regularity properties,
as they state that the probability of an event E is equal to the limit of the sequence
P(En), where En is a monotonic sequence converging to E. In particular:
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_3
43

44
3
One-Dimensional Absolutely Continuous Distributions
1. continuity from the right: F(x) = lim
y‚Üíx+ F(y);
2. limit from the left: lim
y‚Üíx‚àíF(y) = P(X < x);
3.
lim
x‚Üí+ ‚àûF(x) = 1;
4.
lim
x‚Üí‚àí‚àûF(x) = 0.
In all examples of p.d.f.‚Äôs these extra properties will be satisÔ¨Åed, even if it is
possible to consider cases where they do not hold true. It follows from 1 and 2 that
P(X = x0) = P((X ‚â§x0) ‚àí(X < x0)) = F(x0) ‚àíF(x‚àí
0 )
where F(x‚àí
0 ) denotes limx‚Üíx‚àí
0 F(x). This limit always exists as F(x) is bounded
non-decreasing.
Example 3.2.1 (Discrete case) In the case of a random number X with discrete
distribution I (X) = {x1, x2, . . .} one has:
F(x) = P(X ‚â§x) =

xi‚â§x
P(X = xi).
The probability that a random number X takes value in an interval (a, b] can be
obtained from its c.d.f. F by:
P(a < X ‚â§b) = P((X ‚â§b) ‚àí(X ‚â§a))
= P(X ‚â§b) ‚àíP(X ‚â§a)
= F(b) ‚àíF(a).
3.3
Absolutely Continuous Distributions
Let X be a random number. We say that X has absolutely continuous distribution
if there exists a function f : R ‚ÜíR+ with such that the c.d.f. F(x) of X can be
written as:
F(x) =
 x
‚àí‚àû
f (t)dt.
The function f is the called a probability density function (p.d.f.) of X. Note that
f is not unique. Indeed if the values of f are changed on a Ô¨Ånite set of points, the
new function is still a density of X, as its integrals are the same. It follows from
fundamental theorem of calculus that if x is a continuity point of f , then
f (x) = F‚Ä≤(x).

3.3 Absolutely Continuous Distributions
45
Since limx‚Üí‚àûF(x) = 1, then if f is a p.d.f. of X we have
 ‚àû
‚àí‚àû
f (x)dx = lim
x‚Üí‚àû
 x
‚àí‚àû
f (y)dy = lim
x‚Üí‚àûF(x) = 1.
If x is a continuity point of f , then f (x) ‚â•0. Indeed assume that f (x) < 0, then by
continuity there would be a neighborhood (a, b) of x where f is still strictly negative
but then
F(b) = F(a) +
 b
a
f (x)dx < F(a),
so that F would not be non-decreasing. We have that for a < b
P(a < X ‚â§b) = F(b) ‚àíF(a) =
 b
‚àí‚àû
f (x)dx ‚àí
 a
‚àí‚àû
f (x)dx =
 b
a
f (x)dx.
Let us now see how to compute the expectation of X from the p.d.f. f . We consider
the particular case when I (X) is contained in some interval [a, b] and the p.d.f.
f is continuous (and zero outside [a, b]). We subdivide [a, b] into n intervals Ii,
i = 1, . . . , n of length b‚àía
n . It is not important that the extremes are included: we
assume that the intervals are closed on the r.h.s. and open on the l.h.s. except for I1
that is closed on both sides. We deÔ¨Åne two random numbers with discrete distribution
X(n)
‚àíand X(n)
+ : if X takes value in Ii, then X(n)
‚àíis equal to the left endpoint of Ii,
X(n)
+ is equal to the right endpoint. Since X(n)
‚àíand X(n)
+ have discrete distribution
with a Ô¨Ånite number of possible values, we can compute their expectations using the
formula (1.10). They are given by:
P(X(n)
‚àí) =
n‚àí1

j=0

a + j b ‚àía
n
  a+( j+1) b‚àía
n
a+ j b‚àía
n
f (x)dx;
P(X(n)
+ ) =
n‚àí1

j=0

a + ( j + 1)b ‚àía
n
  a+( j+1) b‚àía
n
a+ j b‚àía
n
f (x)dx.
Since X(n)
‚àí‚â§X ‚â§X(n)
+ , then
P(X(n)
‚àí) ‚â§P(X) ‚â§P(X(n)
+ ).
It is easy to see, using the continuity of f (x), that as n ‚Üí‚àûboth P(X(n)
‚àí) and
P(X(n)
+ ) converge to
 b
a
x f (x)dx =

R
x f (x)dx,

46
3
One-Dimensional Absolutely Continuous Distributions
that is hence the value of P(X). Approximation arguments lead to extend this formula
to the case of a general X with absolutely continuous distribution with probability
density f (x) provided that

R
|x| f (x)dx < ‚àû,
(3.1)
i.e. one assume that, when (3.1) holds true, the expectation of X in the absolutely
continuous case is given by:
P(X) =
 +‚àû
‚àí‚àû
x f (x)dx.
Analogously if œà : R ‚ÜíR is a real function such that œà(x) f (x) is integrable, we
are lead to assign to P(œà(X)) the value
P(œà(X)) =
 +‚àû
‚àí‚àû
œà(x) f (x)dx.
(3.2)
It follows that the variance can be obtained by:
œÉ2(X) = P(X2) ‚àíP(X)2
=
 +‚àû
‚àí‚àû
x2 f (x) dx ‚àí
 +‚àû
‚àí‚àû
x f (x) dx
2
,
provided that the integrals exist. In the following sections we shall introduce some
of the most common one-dimensional absolutely continuous distributions.
3.4
Uniform Distribution in [0, 1]
A random number X has uniform distribution in [0, 1] if its c.d.f. is given by:
F(x) =
‚éß
‚é®
‚é©
0 x ‚â§0,
x 0 < x < 1,
1 x ‚â•1.
It is a continuous distribution since
P(X = x) = F(x) ‚àíF(x‚àí) = 0
for every x ‚ààR. Indeed it is easy to check that it is an absolutely continuous distri-
bution with p.d.f. f (x) given by:

3.4 Uniform Distribution in [0,1]
47
f (x) =
‚éß
‚é®
‚é©
0 x ‚â§0,
1 0 < x < 1,
0 x ‚â•1.
As in the following examples the values of the p.d.f. in discontinuity points can be
chosen in an arbitrary way. The expectation is given by
P(X) =

R
x f (x) dx =
 1
0
x dx =
	x2
2

1
0
= 1
2,
and the variance by
œÉ2(X) =
 1
0
x2 dx ‚àí1
4 =
	x3
3

1
0
‚àí1
4 = 1
12.
3.5
Uniform Distribution on an Arbitrary Interval [a, b]
A random number X has uniform distribution in [a, b] if its c.d.f. is given by:
F(x) =
‚éß
‚é®
‚é©
0
x ‚â§a,
c(x ‚àía) a < x < b,
1
x ‚â•1.
In order to compute the constant c, we impose the continuity in the point x = b and
get c(b ‚àía) = 1, that is:
c =
1
b ‚àía .
The expectation is given by:
P(X) =
 b
a
x
b ‚àía dx =
	
x2
2(b ‚àía)

b
a
= a + b
2
,
and the variance by:
œÉ2(X) = P((X ‚àíP(X))2 =
 b
a
1
b ‚àía

x ‚àía + b
2
2
dx
=
1
b ‚àía
1
3

x ‚àía + b
2
3b
a
= (b ‚àía)2
12
.

48
3
One-Dimensional Absolutely Continuous Distributions
3.6
Exponential Distribution
A random number X has exponential distribution with parameter Œª if its c.d.f. is
given by:
F(x) =
1 ‚àíe‚àíŒªx x ‚â•0,
0
x < 0.
If X is the time when a certain fact happens (for example when the atom of some
isotope decays), the exponential distribution has the property of absence of memory.
Given x, y ‚â•0 we have:
P(X > x + y | X > y) = P(X > x).
(3.3)
i.e. the probability that the fact does not occur for an extra amount of time x, given
that has not occurred up to time y, is the same as the probability starting from the
initial time. We obtain (3.3) by using the formula of composite probability:
P(X > x + y | X > y) = P(X > x + y, X > y)
P(X > y)
= P(X > x + y)
P(X > y)
= e‚àíŒª(x+y)
e‚àíŒªy
= e‚àíŒªx
= P(X > x).
In the following we shall see that the exponential distribution can be obtained as
limit of suitably rescaled geometric distributions. Geometric distribution has also the
property of absence of memory for discrete times, as we have remarked in Sect.2.4.
The expectation of exponential distribution with parameter Œª is equal to
P(X) =
 +‚àû
0
Œªxe‚àíŒªx dx =

‚àíxe‚àíŒªx+‚àû
0
+
 +‚àû
0
e‚àíŒªx dx = 1
Œª.
The variance is equal to
œÉ2(X) = P(X2) ‚àíP(X)2
=
 +‚àû
0
Œªx2e‚àíŒªx dx ‚àí1
Œª2
=

‚àíx2e‚àíŒªx+‚àû
0
+ 2
 +‚àû
0
xe‚àíŒªx dx ‚àí1
Œª2
= 2
Œª2 ‚àí1
Œª2
= 1
Œª2 .

3.7 A Characterization of Exponential Distribution
49
3.7
A Characterization of Exponential Distribution
The exponential distribution can be characterized in terms of its hazard rate.
Given a non-negative random variable with absolutely continuous distribution
that describes the time of occurence of some fact, its hazard rate h(x) at time x is
deÔ¨Åned by:
h(x) = lim
h‚Üí0
P(x < X < x + h|X > x)
h
.
We can express h(x) in terms of the probability density. Let
F(x) = P(X ‚â§x) =
 x
‚àí‚àû
f (y)dy.
Then
lim
h‚Üí0
P(x < X < x + h)
hP(X > x)
=
f (x)
1 ‚àíF(x) = ‚àíd
dx log(1 ‚àíF(x)).
For exponential distribution with parameter Œª, it is easy to see that the hazard rate is
equal to Œª for all x. Indeed:
h(x) =
f (x)
1 ‚àíF(x) = Œªe‚àíŒªx
e‚àíŒªx
= Œª.
Exponential distribution can be characterized as the unique distribution with constant
hazard rate. To see that, we Ô¨Årst show that c.d.f. can be obtained from the hazard
rate.
Since X is assumed to be non-negative and with absolutely continuous distribu-
tion, we have: F(0) = P(X ‚â§0) = 0. Using that
h(x) = ‚àíd
dx log(1 ‚àíF(x)),
we have that for x ‚â•0
log(1 ‚àíF(x)) = ‚àí
 x
0
h(y)dy
(3.4)
= 1 ‚àíF(x) = exp

‚àí
 x
0
h(y)dy

(3.5)
= F(x) = 1 ‚àíexp

‚àí
 x
0
h(y)dy

.
(3.6)
If the hazard rate is constant equal to Œª > 0, then
F(x) = 1 ‚àíe‚àíŒªx,
x > 0,

50
3
One-Dimensional Absolutely Continuous Distributions
since X is non-negative, F(x) = 0 for x < 0. Therefore X has exponential distribu-
tion with parameter Œª.
3.8
Normal Distribution
A random number X has standard normal distribution N(0, 1) if its probability
density function is:
n(x) = Ke‚àíx2
2 , x ‚ààR.
Although the indeÔ¨Ånite integral of e‚àíx2
2 cannot be expressed in terms of elementary
functions, it can still be computed over the whole line and so the constant K. We
have:
 +‚àû
‚àí‚àû
e‚àíx2
2 dx
2
=
 +‚àû
‚àí‚àû
 +‚àû
‚àí‚àû
e‚àíx2
2 e‚àíy2
2 dxdy
=
 
e‚àíx2+y2
2
dxdy
=
 2œÄ
0
 +‚àû
0
e‚àír2
2 r drdŒ∏
= 2œÄ
 +‚àû
0
e‚àír2
2 r dr
= 2œÄ

‚àíe‚àír2
2
+‚àû
0
= 2œÄ,
where a change to polar coordinates x = r cos Œ∏, y = r sin Œ∏ has been used. The
Jacobian determinant of this change of variable is r (see Appendix H).
It follows that
 +‚àû
‚àí‚àûe‚àíx2
2 =
‚àö
2œÄ and so
K =
1
‚àö
2œÄ
.
The cumulative distribution function will be denoted by N(x):
N(x) :=
 x
‚àí‚àû
n(t) dt.
Since n is an even function and its integral over the whole line is equal to 1, we
have:
N(‚àíx) = 1 ‚àíN(x).

3.8 Normal Distribution
51
Therefore in tables of N(x), only values for positive values of x are usually tabulated.
The expectation of standard normal distribution is
P(X) =
 +‚àû
‚àí‚àû
x n(x) dx = 0,
as it follows immediately since f (x) = ‚àíf (x), where f (x) = xn(x), x ‚ààR. The
variance of standard normal distribution is obtained by integration by parts, using
the fact that n‚Ä≤(x) = ‚àíxn(x):
œÉ2(X) = P(X2) =
 +‚àû
‚àí‚àû
x2n(x) dx = [‚àíxn(x)]+‚àû
‚àí‚àû+
 +‚àû
‚àí‚àû
n(x) dx = 1.
We introduce now the general normal distribution which has two parameters m, œÉ2
and will be denoted by N(m, œÉ2). We start with X ‚àºN(0, 1) and consider Y =
m + œÉX, where œÉ > 0. Then Y has normal distribution N(m, œÉ2). The c.d.f. of Y is
given by:
FY(y) = P(Y ‚â§y)
= P(m + œÉX ‚â§y)
= P

X ‚â§y ‚àím
œÉ

= N
 y ‚àím
œÉ

.
The probability density function of Y is obtained by chain rule for the derivative of
a composite function:
fY(y) = d
dy N
 y ‚àím
œÉ

= 1
œÉ n
 y ‚àím
œÉ

=
1
œÉ
‚àö
2œÄ
e‚àí(y‚àím)2
2œÉ2 .
The expectation and the variance of Y are obtained as follows:
P(Y) = P(œÉX + m) = œÉP(X) + m = m
œÉ2(Y) = œÉ2(œÉX + m) = œÉ2œÉ2(X) = œÉ2.
3.9
Normal Tail Estimate
As we have said, there is no formula in terms of elementary functions for N(x) and
therefore for the probability that a random number X ‚àºN(0, 1) is greater than some
x > 0. It is however possible to give asymptotic estimates for this probability as x
tends to inÔ¨Ånity.

52
3
One-Dimensional Absolutely Continuous Distributions
Proposition 3.9.1 Let X be a random number with standard normal distribution.
For every x > 0, we have:
n(x)
x
‚àín(x)
x3
< P(X ‚â•x) < n(x)
x
,
where n(x) :=
1
‚àö
2œÄ
e‚àíx2
2 .
The upper bound is obtained by integration by parts:
P(X ‚â•x) =
 +‚àû
x
n(t) dt =
 +‚àû
x
t n(t)
t
dt
=
	
‚àín(t)
t

+‚àû
x



n(x)
x
‚àí
 +‚àû
x
n(t)
t2

>0
dt < n(x)
x
.
A second integration by parts gives the lower bound:
P(X ‚â•x) = n(x)
x
‚àí
 +‚àû
x
t n(t)
t3 dt
= n(x)
x
‚àí
	
‚àín(t)
t3

+‚àû
x



n(x)
x3
+
 +‚àû
x
3n(t)
t4
  
>0
dt > n(x)
x
‚àín(x)
x3 .
3.10
Gamma Distribution
Let Œ± and Œª be strictly positive real numbers. The random number X is said to have
gamma distribution Œì (Œ±, Œª) if its probability density function is given by
gŒ±,Œª(x) =
 K xŒ±‚àí1 e‚àíŒªx x > 0,
0
x ‚â§0.
Note that exponential distribution is a particular case of gamma distribution corre-
sponding to the choice Œ± = 1.
The normalizing constant K can be expressed in terms of Euler‚Äôs gamma function
Œì (Œ±):
Œì (Œ±) =
 +‚àû
0
xŒ±‚àí1 e‚àíx dx

3.10 Gamma Distribution
53
for Œ± > 0. The function Œì satisÔ¨Åes the recursive property:
1. Œì (Œ± + 1) = Œ±Œì (Œ±), since
Œì (Œ± + 1) =
 +‚àû
0
xŒ± e‚àíx dx
=

‚àíxŒ± e‚àíx+‚àû
0
+
 +‚àû
0
Œ±xŒ±‚àí1 e‚àíx dx
= Œ± Œì (Œ±).
2. It follows by iteration that for integer Œ± > 0
Œì (Œ±) = (Œ± ‚àí1)!
since Œì (1) =
 +‚àû
0
e‚àíxdx = 1.
Now for the p.d.f. gŒ±,Œª we have
1 =
 +‚àû
‚àí‚àû
gŒ±,Œª(x) dx = K
 +‚àû
0
xŒ±‚àí1 e‚àíŒªxdx = K
ŒªŒ±
 +‚àû
0
yŒ±‚àí1e‚àíy dy = K
ŒªŒ± Œì (Œ±).
Hence
K =
ŒªŒ±
Œì (Œ±).
The expectation and the variance of the gamma distribution can be computed
using the recurrence property of gamma function:
P(X) =
 +‚àû
‚àí‚àû
xgŒ±,Œª(x) dx
=
ŒªŒ±
Œì (Œ±)
 +‚àû
0
xŒ± e‚àíŒªx dx
=
ŒªŒ±
Œì (Œ±)
Œì (Œ± + 1)
ŒªŒ±+1
= Œ±
Œª .
It follows that:
œÉ2(X) = P(X2) ‚àíP(X)2 = Œ±(Œ± + 1)
Œª2
‚àíŒ±2
Œª2 = Œ±2
Œª2 .

54
3
One-Dimensional Absolutely Continuous Distributions
3.11
œá2-Distribution
From the normal distribution we can derive another distribution of wide use in sta-
tistics, the œá2-distribution. In this section we introduce the œá2-distribution with
parameter ŒΩ = 1. In Chap.4 we shall consider general œá2-distributions with parame-
ter ŒΩ ‚ààN \ {0}.
Let X be a random number with standard normal distribution N(0, 1) and let
Y = X2. We Ô¨Årst consider the c.d.f. of Y. If y < 0
FY(y) = P(Y ‚â§y) = 0
since Y is non-negative. If y ‚â•0, then
FY(y) = P(Y ‚â§y) = P(X2 ‚â§y)
= P(‚àí‚àöy ‚â§X ‚â§‚àöy)
= N(‚àöy) ‚àíN(‚àí‚àöy)
= N(‚àöy) ‚àí(1 ‚àíN(‚àöy))
= 2N(‚àöy) ‚àí1.
The c.d.f. of Y is therefore
FY(y) =
0
for y < 0,
2N(‚àöy) ‚àí1 for y ‚â•0.
Let us compute the p.d.f. fY of Y (for y > 0):
fY(y) = F‚Ä≤
Y(y) = 2n(y) 1
‚àöy
=
1
‚àö
2œÄ
1
‚àöy e‚àíy
2 =
1
‚àö
2œÄ
y
1
2 ‚àí1e‚àí1
2 y,
where the derivative has been computed by using chain rule for the derivative of
composite functions. The density fY(y) is of course zero for negative y. It follows
that Y has distribution Œì ( 1
2, 1
2). Moreover by comparing the normalizing constants,
we get
1
‚àö
2
1
‚àöœÄ =
1
2
 1
2
1
Œì
 1
2
,
so that
Œì
1
2

= ‚àöœÄ.

3.11 œá2-Distribution
55
By using the recurrence formula Œì (Œ± + 1) = Œ±Œì (Œ±), we have:
Œì
2k + 1
2

= (2k ‚àí1)(2k ‚àí3) ¬∑ ¬∑ ¬∑ 1
2k
‚àöœÄ
2
for k = 1, 2, . . ..
3.12
Cauchy Distribution
We now consider a distribution for which the expectation deÔ¨Åned in Sect.3.3 does not
exist. This is the Cauchy distribution. This is the distribution of a random number
Y = tan Œò, where the random number Œò has uniform distribution in the interval
[‚àíœÄ
2 , œÄ
2 ]. We have for y ‚ààR that:
FY(y) = P(Y ‚â§y) = P(tan Œò ‚â§y)
= P(Œò ‚â§arctan y).
The p.d.f. of Y fY is obtained by deriving FY:
fY(y) =
1
œÄ

1 + y2.
The formula for the expectation of Y gives an integral

y
œÄ

1 + y2dy
which is undeÔ¨Åned, as the integrand behaves like 1
y for y ‚Üí‚àû.
3.13
Mixed Cumulative Distribution Functions
In addition to discrete and absolutely continuous c.d.f.‚Äôs, there are continuous but
not absolutely continuous c.d.f.‚Äôs. These will be not considered in this elementary
book. Here we brieÔ¨Çy speak about mixed c.d.f.‚Äôs that are convex linear combinations
of discrete and absolutely continuous c.d.f.‚Äôs.
For 0 < p < 1, let F1 be a discrete c.d.f. and F2 be an absolutely continuous c.d.f.
Then we can consider a c.d.f. F(x):
F(x) = pF1(x) + (1 ‚àíp)F2(x),

56
3
One-Dimensional Absolutely Continuous Distributions
which is neither of discrete nor of absolutely continuous type. F(x) is said to be
a mixed c.d.f. If X is a random number with c.d.f. F(x), it is easy to see that the
expectation of a function œÜ(X) is given by
P(œÜ(X)) = pP(œÜ(X1)) + (1 ‚àíp)P(œÜ(X2)),
where X1 and X2 are random numbers with c.d.f. F1 and F2 respectively, provided
that the terms on the right-hand side both make sense. The Ô¨Årst term is expressed by
a sum or a series, while the second by an integral.
An example of random number with mixed c.d.f is the time T of function of some
device, for example a lamp, when there is a positive probability p that the device
does not work already at the initial time and otherwise the distribution is absolutely
continuous, for example exponential with parameter Œª. The c.d.f of T is then given
by:
FT (t) =

0
for t < 0,
p + (1 ‚àíp)(1 ‚àíe‚àíŒªt) for t ‚â•0.
It is easy to check that P(T ) = 1 ‚àíp
Œª
.

Chapter 4
Multi-dimensional Absolutely Continuous
Distributions
4.1
Bidimensional Distributions
Let X, Y be two random numbers that we can consider as a random vector (X, Y).
The joint cumulative distribution function ( j.c.d.f.) is deÔ¨Åned as:
F(x, y) = P(X ‚â§x, Y ‚â§y).
Then F is a map from R2 to [0, 1]:
F : R2 ‚àí‚Üí[0, 1].
The probability that (X, Y) belong to the rectangle (a1, b1] √ó (a2, b2] is given by:
P(a1 < X ‚â§b1, a2 < Y ‚â§b2) = P [((X ‚â§b1) ‚àí(X ‚â§a1)) ((Y ‚â§b2) ‚àí(Y ‚â§a2))]
= P(X ‚â§b1, Y ‚â§b2) ‚àíP(X ‚â§a1, Y ‚â§b2)
‚àíP(X ‚â§b1, Y ‚â§a2) + P(X ‚â§a1, Y ‚â§a2)
= F(b1, b2) ‚àíF(a1, b2) ‚àíF(b1, a2) + F(a1, a2).
(4.1)
We shall always assume that the following continuity properties are veriÔ¨Åed:
1.
lim
x‚Üí+‚àû
y‚Üí+‚àû
F(x, y) = 1;
2.
lim
x‚Üí‚àí‚àûF(x, y) =
lim
y‚Üí‚àí‚àûF(x, y) = 0;
3.
lim
x‚Üíx+
0
y‚Üíy+
0
F(x, y) = F(x0, y0);
4. P(X = x0, Y = y0) = F(x0, y0) ‚àíF(x‚àí
0 , y0) ‚àíF(x0, y‚àí
0 ) + F(x‚àí
0 , y‚àí
0 ),
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_4
57

58
4
Multi-dimensional Absolutely Continuous Distributions
where F(x‚àí
0 , y0) := limx‚Üíx‚àí
0 F(x, y0), F(x0, y‚àí
0 ) := limy‚Üíy‚àí
0 F(x0, y) and F(x‚àí
0 ,
y‚àí
0 ) := lim
x‚Üíx‚àí
0
y‚Üíy‚àí
0
F(x, y).
Other analogous properties will also be assumed. We shall quote them when they
will be needed.
4.2
Marginal Cumulative Distribution Functions
Given two random numbers X, Y with j.c.d.f. F(x, y), the c.d.f.‚Äôs F1, F2 of X and
Y are called marginal cumulative distribution functions (m.c.d.f.‚Äôs).
The m.c.d.f. of X is obtained from the j.c.d.f. by taking the limit:
F1(x) = P(X1 ‚â§x) =
lim
y‚Üí+‚àûF(x, y),
as follows by usual continuity hypothesis. Similarly the m.c.d.f. of Y is obtained by:
F2(y) = P(Y ‚â§y) =
lim
x‚Üí+‚àûF(x, y).
Two numbers are said to be stochastically independent if:
F(x, y) = F1(x)F2(y)
for every (x, y) ‚ààR2.
4.3
Absolutely Continuous Joint Distributions
Two random numbers X, Y or equivalently the random vector (X, Y) has an
absolutely continuous distribution if there exists a function f
f : R2 ‚àí‚ÜíR
such that the j.c.d.f. F of X, Y can be expressed as:
f (X, Y) =
 x
‚àí‚àû
 y
‚àí‚àû
f (s, t) dsdt.
Such function f is called joint probability density (j.p.d.). Applying formula (4.1)
for the probability that (X, Y) belong to a rectangle (a, b] √ó (c, d], we get:

4.3 Absolutely Continuous Joint Distributions
59
P(a < X ‚â§b, c < Y ‚â§d) = F(b, d) ‚àíF(a, d) ‚àíF(c, b) + F(a, c)
=
 b
‚àû
 d
‚àû
f (s, t) dsdt ‚àí
 a
‚àû
 d
‚àû
f (s, t) dsdt
‚àí
 b
‚àû
 c
‚àû
f (s, t) dsdt +
 a
‚àû
 c
‚àû
f (s, t) dsdt
=
 b
a
 d
c
f (s, t) dsdt.
By usual limiting procedure one gets that the probability that a random vector
(X, Y) belongs to a sufÔ¨Åciently regular region A of R2 is given by the integral of the
j.p.d.f. over A, i.e.
P((X, Y) ‚ààA) =
 
A
f (s, t) dsdt.
Moreover, if œà : R2 ‚ÜíR is a sufÔ¨Åciently regular function such that the function œà f
is integrable, then, as in the one-dimensional case, we have that for Z = œà(X, Y)
P(Z) =
 
R2 œà(s, t) f (s, t) dsdt.
(4.2)
For example, if Z = XY we get
P(XY) =
 
R2 st f (s, t) dsdt,
if the integrand function st f (s, t) is integrable. In order to derive probability densities
of X and Y, that are called marginal probability densities, we start by deriving their
c.d.f.‚Äôs:
FX(x) = P(X ‚â§x) =
 +‚àû
‚àí‚àû
 x
‚àí‚àû
f (s, t) dsdt.
It follows that the marginal probability density of X is given by:
fX(x) =
 +‚àû
‚àí‚àû
f (x, t) dt.
Analogously fY, the marginal probability density of Y, is given by
fY(y) =
 +‚àû
‚àí‚àû
f (s, y) ds.
It is easy to check out that, if f (X, Y) can be expressed as a product of two functions,
f (x, y) = u(x)v(y),

60
4
Multi-dimensional Absolutely Continuous Distributions
then X and Y are stochastically independent and their marginal probability densities
are proportional to u(x) and v(y). Conversely if X and Y are stochastically indepen-
dent and their joint distribution is absolutely continuous, then their joint probability
density can be expressed as the product of their marginal probability densities:
f (x, y) = fX(x) fY(y).
(4.3)
As in the case of discrete distributions, it follows from (4.3) that if X, Y are
stochastically independent and œÜ1, œÜ2 are real functions such that œÜ1 fX and œÜ2 fY are
integrable, then by Fubini‚Äôs theorem we obtain:
P(œÜ1(X)œÜ2(Y)) = P(œÜ1(X))P(œÜ2(Y)).
4.4
The Density of Z = X + Y
Let X and Y be two random numbers with joint probability density f (x, y). We want
to determine the density of
Z = X + Y.
First we compute the c.d.f. of Z:
FZ(z) = P(Z ‚â§z) = P(X + Y ‚â§z) =
 +‚àû
‚àí‚àû
 z‚àíx
‚àí‚àû
f (x, y) dydx
=
 +‚àû
‚àí‚àû
 z
‚àí‚àû
f (x, t ‚àíx) dtdx =
 z
‚àí‚àû
 +‚àû
‚àí‚àû
f (x, t ‚àíx) dxdt,
where we have made the change of variable t = x + y for Ô¨Åxed x, that allows then
to exchange the order of integration in the Ô¨Ånal equality. It follows from the last
expression that
fZ(z) =
 z
‚àí‚àû
fz(t) dt
with
fZ(z) =
 +‚àû
‚àí‚àû
f (x, z ‚àíx) dx,
i.e. fZ is the density of Z. In particular when X and Y are stochastically independent
and f (x, y) = fX(x) fY(y), then
fZ(z) =
 +‚àû
‚àí‚àû
fX(x) fY(z ‚àíx) dx.

4.4 The Density of Z = X + Y
61
Hence fZ is obtained by the convolution of fX and fY and is denoted by fX ‚àófY. An
example of application of this formula is the sum of two stochastically independent
gamma distributed random numbers with parameters respectively Œ±, Œª and Œ≤, Œª.
Using the previous formula we obtain the probability density of Z = X + Y:
fZ(z) =
 +‚àû
‚àí‚àû
fX(x) fY(z ‚àíx) dx
=
 +‚àû
‚àí‚àû
ŒªŒ±
Œì (Œ±) xŒ±‚àí1 e‚àíŒªx I{x > 0}
ŒªŒ≤
Œì (Œ≤) (z ‚àíx)Œ≤‚àí1 e‚àíŒª(z‚àíx) I{(z‚àíx) > 0} dx,
where IA denotes the indicator function of the set A. The integral can be written as
ŒªŒ±+Œ≤
Œì (Œ±)Œì (Œ≤) e‚àíŒªz
 z
0
xŒ±‚àí1(z ‚àíx)Œ≤‚àí1dx
if z > 0 and it is equal to 0 if z ‚â§0. For z > 0 we make the change of variable
dx = zdt and obtain
fZ(z) =
ŒªŒ±+Œ≤
Œì (Œ±)Œì (Œ≤) e‚àíŒªz
 z
0
xŒ±‚àí1(z ‚àíx)Œ≤‚àí1 dx
=
ŒªŒ±+Œ≤
Œì (Œ±)Œì (Œ≤) e‚àíŒªz
 1
0
(zt)Œ±‚àí1(z ‚àízt)Œ≤‚àí1z dt
=
ŒªŒ±+Œ≤
Œì (Œ±)Œì (Œ≤) zŒ±+Œ≤‚àí1e‚àíŒªz
 1
0
tŒ±‚àí1 (1 ‚àít)Œ≤‚àí1 dt
=
ŒªŒ±+Œ≤
Œì (Œ±)Œì (Œ≤)
 1
0
tŒ±‚àí1 (1 ‚àít)Œ≤‚àí1 dt zŒ±+Œ≤‚àí1e‚àíŒªz
= K zŒ±+Œ≤‚àí1e‚àíŒªz,
with
K =
ŒªŒ±+Œ≤
Œì (Œ±) Œì (Œ≤)
 1
0
tŒ±‚àí1 (1 ‚àít)Œ≤‚àí1 dt.
(4.4)
It follows that Z has distribution Œì (Œ± + Œ≤, Œª).
Remark 4.4.1 Since the constant K must be equal to the normalizing constant of the
distribution Œì (a + b, Œª), by (4.4) we obtain
K =
ŒªŒ±+Œ≤
Œì (Œ± + Œ≤)
 1
0
tŒ±‚àí1 (1 ‚àít)Œ≤‚àí1 dt =
ŒªŒ±+Œ≤
Œì (Œ± + Œ≤),
so that
 1
0
tŒ±‚àí1 (1 ‚àít)Œ≤‚àí1 dt = Œì (Œ±) Œì (Œ≤)
Œì (Œ± + Œ≤) .

62
4
Multi-dimensional Absolutely Continuous Distributions
4.5
Beta Distribution B(Œ±, Œ≤)
Let Œ± > 0 and Œ≤ > 0. A random number X is said to have beta distribution B(Œ±, Œ≤)
if its density f (x) is given by
f (x) =
‚éß
‚é®
‚é©
K xŒ±‚àí1 (1 ‚àíx)Œ≤‚àí1 x ‚àà[0, 1],
0
otherwise.
It follows from the computation at the end of the previous section that
K =
1
 1
0 xŒ±‚àí1 (1 ‚àíx)Œ≤‚àí1 dx
= Œì (Œ± + Œ≤)
Œì (Œ±) Œì (Œ≤).
(4.5)
The expectation can be obtained from the recursion property of Euler‚Äôs gamma
function. If X has B(Œ±, Œ≤) distribution, then
P(X) = Œì (Œ± + Œ≤)
Œì (Œ±) Œì (Œ≤)
 1
0
x f (x) dx.
The value of the integral is obtained by (4.5) by replacing Œ± with Œ± + 1 so that
P(X) = Œì (Œ± + Œ≤)
Œì (Œ±) Œì (Œ≤)
Œì (Œ± + 1)Œì (Œ≤)
Œì (Œ± + Œ≤ + 1) = Œ±Œì (Œ±)
Œì (Œ±)
Œì (Œ± + Œ≤)
(Œ± + Œ≤)Œì (Œ± + Œ≤) =
Œ±
Œ± + Œ≤ .
Similarly we can compute P(X2):
P(X2) = Œì (Œ± + Œ≤)
Œì (Œ±) Œì (Œ≤)
 1
0
xŒ±+1 (1 ‚àíx)Œ≤‚àí1 dx
= Œì (Œ± + Œ≤)
Œì (Œ±) Œì (Œ≤)
Œì (Œ± + 2) Œì (Œ≤)
Œì (Œ± + Œ≤ + 2) ,
where the integral is obtained by replacing Œ± with Œ± + 2 in formula (4.4). By using
the recursion property of the Gamma function we get
Œì (Œ± + 2) = (Œ± + 1)Œ± Œì (Œ±)
Œì (Œ± + Œ≤ + 2) = (Œ± + Œ≤ + 1) (Œ± + Œ≤) Œì (Œ± + Œ≤)
so that
P(X2) =
Œ±(Œ± + 1)
(Œ± + Œ≤) (Œ± + Œ≤ + 1)

4.5 Beta Distribution B(Œ±, Œ≤)
63
and
œÉ2(X) = P(X2) ‚àíP(X)2
=
(Œ± + 1) Œ±
(Œ± + Œ≤ + 1) (Œ± + Œ≤) ‚àí
Œ±2
(Œ± + Œ≤)2 =
Œ±Œ≤
(Œ± + Œ≤)2 (Œ± + Œ≤ + 1).
4.6
Student Distribution
We now introduce the Student distribution of parameter ŒΩ. Let Z and U be sto-
chastically independent random numbers. We assume that Z has standard normal
distribution and U has gamma distribution Œì
ŒΩ
2 , 1
2

where ŒΩ ‚ààN. The latter dis-
tribution is called œá2-distribution with ŒΩ degrees of freedom and plays an important
role in statistics. Let T = Z
U
ŒΩ
‚àí1
2
. In order to obtain the probability density of
T , we Ô¨Årst derive its c.d.f.
FT (t) = P(T ‚â§t) = P(Z ‚â§t
	
U
ŒΩ ) =
 ‚àû
0
 ‚àöu
ŒΩ
‚àí‚àû
f (z, u)dzdu,
where
f (z, u) =
1
2
ŒΩ
2 ‚àö
2œÄŒì

 ŒΩ
2
e‚àíz2
2 u
ŒΩ
2 ‚àí1e‚àíu
2 .
By taking the derivative of FT (t) with respect to t, it follows from the fundamental
calculus theorem that for density of the Student distribution is given for t > 0 by
fT (t) = F‚Ä≤
T (t) =
 ‚àû
0
f (t
	u
ŒΩ , u)
	u
ŒΩ du
=
1
2
ŒΩ
2 ‚àö
2œÄŒΩŒì

 ŒΩ
2

 ‚àû
0
u
ŒΩ+1
2 ‚àí1e‚àíu
2 (1+ t2
ŒΩ )du
=
Œì

 ŒΩ+1
2

‚àöœÄŒΩŒì

 ŒΩ
2
(1 + t2
ŒΩ )‚àíŒΩ+1
2 ,
where the integral has been computed by using the formula for the normalizing
constant of the gamma distribution. Note that for ŒΩ = 1 the Student distribution
coincides with the Cauchy distribution. Since
 +‚àû
‚àí‚àû
|t|
(1 + t2
ŒΩ )
ŒΩ+1
2 dt

64
4
Multi-dimensional Absolutely Continuous Distributions
must be Ô¨Ånite for the existence of P(T ), we have that P(T ) exists and is Ô¨Ånite if and
only if ŒΩ > 1. We have that
P(T ) =
Œì

 ŒΩ+1
2

‚àöœÄŒΩŒì

 ŒΩ
2

 +‚àû
‚àí‚àû
t(1 + t2
ŒΩ )‚àíŒΩ+1
2 dt = 0,
since the integrand is an odd function.To compute the variance, we calculate
œÉ(T ) = P(T 2) = P
ŒΩZ2
U

= ŒΩP(Z2)P
 1
U

= ŒΩP
 1
U

=
ŒΩ
2
ŒΩ
2 Œì

 ŒΩ
2

 ‚àû
0
1
u u
ŒΩ
2 ‚àí1e‚àíu
2 du =
ŒΩ
2
ŒΩ
2 Œì

 ŒΩ
2

 ‚àû
0
u
ŒΩ‚àí2
2 ‚àí1e‚àíu
2 du
=
ŒΩ
2
ŒΩ
2 Œì

 ŒΩ
2
2
ŒΩ‚àí2
2 Œì
ŒΩ ‚àí2
2

=
ŒΩ
ŒΩ ‚àí2.
Hence the variance exists Ô¨Ånitely if ŒΩ > 2.
4.7
Multi-dimensional Distributions
Let (X1, X2, . . . , Xn) be an n-dimensional random vector. The function
F : Rn ‚àí‚Üí[0, 1]
deÔ¨Åned by:
F(x1, x2, . . . , xn) = P(X1 ‚â§x1, X2 ‚â§x2, . . . , Xn ‚â§xn)
is called joint cumulative distribution function (j.c.d.f.) of (X1, X2, . . . , Xn). In the
following we shall always assume that the following continuity properties are satis-
Ô¨Åed by j.c.d.f.‚Äôs:
1.
lim
x1,...,xn‚Üí+‚àûF(x1, x2, . . . , xn) = 1;
2.
lim
xi‚Üí‚àí‚àûF(x1, x2, . . . , xn) = 0
3. If {i1, . . . , ik} ‚äÇ{1, 2, . . . , n} and { j1, . . . , jn‚àík} = {1, 2, . . . , n}\{i1, . . . , ik}
then
lim
x j1,...,x jn‚àík ‚Üí+‚àûF(x1, . . . , xn) = P(Xi1 ‚â§xi1,...,Xik ‚â§xik).
Here Fi1,...,ik(xi1, . . . , xik) := P(Xi1 ‚â§xi1, . . . , Xik ‚â§xik), xi1, . . . , xik ‚ààR, is
called the marginal cumulative distribution function (m.c.d.f.) of Xi1, . . . , Xik. As in
the two-dimensional case the probability that X1, . . . , Xn belongs to some intervals
(a1, b1], . . . , (an, bn] can be computed using the j.c.d.f. Precisely:
P(a1 < X1 ‚â§b1, . . . , an < Xn ‚â§bn) =

c
(‚àí1)œµ(c) F(c1, . . . , cn)

4.7 Multi-dimensional Distributions
65
with c = (c1, . . . , cn), where ci can be ai or bi, and œµ(c) is equal to the number of
i‚Äôs such that ci = ai. The proof of this formula is completely analogous to the one
for (4.1) in the two-dimensional case.
The random numbers X1, . . . , Xn are said to be stochastically independent if
F(x1, . . . , xn) = F1(x1) . . . Fn(xn),
where Fi is the m.c.d.f. of Xi for i = 1, . . . , n. If X1, . . . , Xn are stochastically
independent, then
P(a1 < X1 ‚â§b1, . . . , an < X1 ‚â§bn) =

c
(‚àí1)œµ(c)F1(c1) . . . Fn(cn)
= Œ†n
i = 1(Fi(bi) ‚àíFi(ai))
= Œ†n
i = 1P(ai < Xi ‚â§bi).
4.8
Absolutely Continuous Multi-dimensional
Distributions
The random vector (X1, . . . , Xn) has an absolutely continuous distribution if there
exists a function
f : Rn ‚àí‚ÜíR
such that the j.c.d.f. F of (X1, X2, . . . , Xn) is given by:
F(x1, . . . , xn) =
 x1
‚àí‚àû
 x2
‚àí‚àû
¬∑ ¬∑ ¬∑
 xn
‚àí‚àû
f (t1, t2, . . . , tn) dt1dt2 . . . dtn.
It follows from Property 1 of Sect.4.7 that
 +‚àû
‚àí‚àû
¬∑ ¬∑ ¬∑
 +‚àû
‚àí‚àû
f (t1, . . . , tn) dt1 . . . dtn = 1.
Moreover it can be shown that one can always choose a non-negative f . The function
f is called joint probability density ( j.p.d.) of (X1, . . . , Xn). What we have said
about two-dimensional joint probability density generalizes in a natural way to the
n-dimensional case.
If A is a sufÔ¨Åciently regular region A ‚äÇRn then
P((X1, . . . , Xn) ‚ààA) =

¬∑ ¬∑ ¬∑

A
f (t1, . . . , tn)dt1 ¬∑ ¬∑ ¬∑ dtn.

66
4
Multi-dimensional Absolutely Continuous Distributions
If œà is a function œà : Rn ‚àí‚ÜíR such that œà f is integrable, then
P(œà(X1, . . . , Xn)) =
 +‚àû
‚àí‚àû
¬∑ ¬∑ ¬∑
 +‚àû
‚àí‚àû
œà(t1, . . . , tn)dt1 . . . dtn.
If f (t1, . . . , tn) = g1(t1) ¬∑ ¬∑ ¬∑ gn(tn), then X1, . . . , Xn are stochastically independent
and the marginal density of Xi can be taken proportional to gi for i = 1, . . . , n.
Conversely if X1, . . . , Xn are stochastically independent with absolutely continuous
distribution,thej.p.d.of X1, . . . , Xn canbetakenas f (t1, . . . , tn) = f1(t1) . . . fn(tn),
where f1, . . . , fn are marginal probability density functions of X1, X2, . . . , Xn.
4.9
Multi-dimensional Gaussian Distribution
A random vector (X1, X2, . . . , Xn) has n-dimensional Gaussian distribution if its
density has the form:
f (x1, x2, . . . , xn) = Ke‚àí1
2 Ax¬∑x+b¬∑x
where x = (x1, x2, . . . , xn)t ‚ààRn, b = (b1, b2, . . . , bn)t ‚ààRn and A ‚ààRn √ó n is a
symmetric positive deÔ¨Ånite matrix.1 The symbol At denotes the transpose matrix of
A, with elements
[At]i, j = [A] j,i.
We remind that b ¬∑ x is the scalar product of b and x, given by
b ¬∑ x =
n

i=1
bixi
and that Ax is the vector with elements
[Ax]i =

j
ai jx j.
Let ai, j denote [A]i, j. The expression Ax ¬∑ x is a quadratic form

i, j
ai jxix j.
1Recall that a matrix A ‚ààRn √ó n is
‚Ä¢ symmetric if At = A, i.e. ai j = a ji,
‚Ä¢ positive deÔ¨Ånite if Ax ¬∑ x > 0 for all x Ã∏= 0, x ‚ààR.

4.9 Multi-dimensional Gaussian Distribution
67
If we have a quadratic form
Bx ¬∑ x =

i, j
bi jxix j
we can always replace the matrix B with a symmetric matrix A such that
Ax ¬∑ x =

i, j
ai jxix j = Bx ¬∑ x,
where ai j is deÔ¨Åned by
ai j =
‚éß
‚é®
‚é©
bii
for i = j,
(bi j + b ji)/2 for i Ã∏= j.
We consider Ô¨Årst the simplest case:
Case 1: A diagonal and b = 0
Let
A =
‚éõ
‚éú‚éú‚éú‚éú‚éù
Œª1 0 ¬∑ ¬∑ ¬∑ 0
0 Œª2
... ...
... ... ... 0
0 ¬∑ ¬∑ ¬∑ 0 Œªn
‚éû
‚éü‚éü‚éü‚éü‚é†
and b = 0. We obtain2
f (x1, x2, . . . , xn) = K exp

‚àí

Œª1
x2
1
2 + Œª2
x2
2
2 + ¬∑ ¬∑ ¬∑ + Œªn
x2
n
2

.
By computing the marginal densities, it is easy to get
f (x1, x2, . . . , xn) = fX1(x1) fX2(x2) ¬∑ ¬∑ ¬∑ fXn(xn)
where
fXi(xi) =
	
Œªi
2œÄ exp

‚àíŒªi x2
i
2

2Here the notation exp (x) is introduced to denote the exponential function ex.

68
4
Multi-dimensional Absolutely Continuous Distributions
is the marginal density of Xi. It follows that
1. X1, . . . , Xn are stochastically independent;
2. Xi has gaussian density N

0, 1
Œªi

;
3. the normalizing constant is given by:
K =
	
Œª1
2œÄ
	
Œª2
2œÄ ¬∑ ¬∑ ¬∑
	
Œªn
2œÄ =

det A
(2œÄ)n .
The expectation vector is given by
(P(X1), . . . , P(Xn)) = (0, . . . , 0)
and the covariance matrix is:
C =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù
œÉ2(X1)
cov(X1, X2)
¬∑ ¬∑ ¬∑
cov(X1, Xn)
cov(X2, X1)
œÉ2(X2)
...
...
...
...
...
cov(Xn‚àí1, Xn)
cov(Xn, X1)
¬∑ ¬∑ ¬∑
cov(Xn, Xn‚àí1)
œÉ2(Xn)
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†
=
‚éõ
‚éú‚éú‚éú‚éú‚éù
1
Œª1
0 ¬∑ ¬∑ ¬∑ 0
0
1
Œª2
... ...
... ... ... 0
0 ¬∑ ¬∑ ¬∑ 0
1
Œªn
‚éû
‚éü‚éü‚éü‚éü‚é†
= A‚àí1.
Case 2: Computation of the expectation vector in the general case
Let now A be symmetric and positive deÔ¨Ånite and b Ã∏= 0. By making a translation
we can reduce the density to the case b = 0. Let U = X ‚àíc with c ‚ààR. The j.c.d.f.
of the random vector U can be expressed in terms of that of X:
FU(u) = P(U ‚â§u) = P(X ‚àíc ‚â§u) = P(X ‚â§u + c) = FX(u + c).

4.9 Multi-dimensional Gaussian Distribution
69
It follows that the joint probability density can be similarly obtained from that
of X:
fU(u1, u2, . . . , un) = fX(u1 + c1, u2 + c2, . . . , un + cn)
= K ‚Ä≤ exp

‚àí1
2 A(u + c) ¬∑ (u + c) + b ¬∑ (u + c)

= K ‚Ä≤ exp

‚àí1
2 Au ¬∑ u ‚àí1
2 Au ¬∑ c ‚àí1
2 Ac ¬∑ u ‚àí1
2 Ac ¬∑ c + b ¬∑ u + b ¬∑ c

= K ‚Ä≤ exp

‚àí1
2 Ac ¬∑ c + b ¬∑ c




constant
exp

‚àí1
2 Au ¬∑ u + (b ‚àíAc) ¬∑ u

,
where we have used the fact that
Ac ¬∑ u = Au ¬∑ c,
since A is symmetric. In order to reduce the density to the case b = 0, we must
choose c so that the Ô¨Årst degree part cancels, i.e.:
b ‚àíAc = 0.
We choose therefore
c = A‚àí1b.
Note that A is invertible since it is positive deÔ¨Ånite. For this choice of c the density
fU(u1, u2, . . . , un) is given by:
fU(u1, u2, . . . , un) = fX(u1 + c1, u2 + c2, . . . , un + cn)
= K ‚Ä≤ exp

A‚àí1b ¬∑ b ‚àíA(A‚àí1b) ¬∑ A‚àí1b
2

exp

‚àí1
2 Au ¬∑ u

= K exp
1
2 A‚àí1b ¬∑ b




K ‚Ä≤
exp

‚àí1
2 Au ¬∑ u

= K ‚Ä≤ exp

‚àí1
2 Au ¬∑ u

.
It is easy to see that P(Ui) = 0 for i = 1, 2, . . . , n, since the density of ‚àíU and U
are the same. Using previous results, we obtain that
P(Xi) = P(Ui + ci) = P(Ui) + ci = ci = (A‚àí1b)i,
i.e. in vectorial notation:
P(X) = A‚àí1b ;

70
4
Multi-dimensional Absolutely Continuous Distributions
where the expectation of a random vector is deÔ¨Åned as the vector of the expectations
of its components. The normalizing constant is
K = K ‚Ä≤ exp
1
2 A‚àí1b ¬∑ b

,
where K ‚Ä≤ is the normalizing constant for the case with b = 0. The covariance matrix
of X is equal to one ofU, as a translation leaves variances and covariances unchanged:
C =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù
œÉ2(X1)
cov(X1, X2)
¬∑ ¬∑ ¬∑
cov(X1, Xn)
cov(X2, X1)
œÉ2(X2)
...
...
...
...
...
cov(Xn‚àí1, Xn)
cov(Xn, X1)
¬∑ ¬∑ ¬∑
cov(Xn, Xn‚àí1)
œÉ2(Xn)
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†
=
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù
œÉ2(U1)
cov(U1,U2)
¬∑ ¬∑ ¬∑
cov(U1,Un)
cov(U2,U1)
œÉ2(U2)
...
...
...
...
...
cov(Un‚àí1,Un)
cov(Un,U1)
¬∑ ¬∑ ¬∑
cov(Un,Un‚àí1)
œÉ2(Un)
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†
.
Case 3: computation of covariance matrix and normalization constant in the
general case
As it is shown we can reduce to the case b = 0 by making a translation. Since A
is symmetric, there exists an orthogonal matrix O, i.e. such that Ot AO = D, where
D is diagonal.
If U is the random vector U = O‚àí1X, its density is given by
f (u1, . . . , un) = K exp

‚àí1
2 A Ou ¬∑ Ou

= K exp

‚àí1
2 Ot AOu ¬∑ u

= K exp

‚àí1
2 Du ¬∑ u

.

4.9 Multi-dimensional Gaussian Distribution
71
Now for U we are in the situation of a diagonal matrix that we have already consid-
ered. The covariance matrix of X, is given by:
C = P(X Xt) = P(OU (OU)t)
= O P(U U t) Ot = O D‚àí1 Ot = A‚àí1.
Here the expectation of a random matrix denotes a matrix whose entries are the
expectations of the corresponding entries. We have used the easily veriÔ¨Åable fact
that if Z is a random matrix and A, B are constant matrices, such that the product
AZ B is deÔ¨Åned, then P(AZ B) = AP(Z)B.
We have found that in the general case
1. the normalization constant is
K =

det A
(2œÄ)n e‚àí1
2 A‚àí1b¬∑b ;
2. the expectation is
P(X) = A‚àí1b ;
3. the covariance matrix is
C = A‚àí1.
Remark 4.9.1 It is easy to check that the marginal distribution of the Xi‚Äôs and of
subsets of the Xi‚Äôs are gaussian. In particular, if cov(Xi, X j) = 0 for some i, j i Ã∏= j,
thenthecovariancematrixof(Xi, X j)isdiagonal,sothat Xi and X j arestochastically
independent as it is shown in the next remark.
Remark 4.9.2 When n = 2, the covariance matrix is given by:
C =
‚éõ
‚éù
œÉ2
1
œÅ œÉ1œÉ2
œÅ œÉ1œÉ2
œÉ2
2
‚éû
‚é†
where œÉ2
1 = œÉ2(X1), œÉ2
2 = œÉ2(X2) and œÅ = œÅ(X1, X2). The matrix A can be
obtained as:
A = C‚àí1 =
1
det C
‚éõ
‚éù
œÉ2
2
‚àíœÅ œÉ1œÉ2
‚àíœÅ œÉ1œÉ2
œÉ2
1
‚éû
‚é†
=
1
œÉ2
1œÉ2
2 ‚àíœÅ2œÉ2
1œÉ2
2
‚éõ
‚éù
œÉ2
2
‚àíœÅ œÉ1œÉ2
‚àíœÅ œÉ1œÉ2
œÉ2
1
‚éû
‚é†

72
4
Multi-dimensional Absolutely Continuous Distributions
=
1
1 ‚àíœÅ2
‚éõ
‚éú‚éú‚éú‚éú‚éù
1
œÉ2
1
‚àí
œÅ
œÉ1œÉ2
‚àí
œÅ
œÉ1œÉ2
1
œÉ2
2
‚éû
‚éü‚éü‚éü‚éü‚é†
.
The density of two-dimensional gaussian distribution with parameters m1 = P(X1),
m2 = P(X2), œÉ2
1 = œÉ2(X1), œÉ2
2 = œÉ2(X2), œÅ = œÅ(X1, X2) is therefore given by:
f (x, y) =
1
2œÄœÉ1œÉ2

1 ‚àíœÅ2 ¬∑
exp

‚àí
1
2(1 ‚àíœÅ2)
(x ‚àím1)2
œÉ2
1
‚àí2œÅ(x ‚àím1)(y ‚àím2)
œÉ1œÉ2
+ (y ‚àím2)2
œÉ2
2

.

Chapter 5
Convergence of Distributions
5.1
Convergence of Cumulative Distribution Functions
It is natural to introduce a notion of convergence for sequences of cumulative dis-
tribution functions, i.e. to give a meaning to the expression Fn ‚ÜíF. One possible
meaning could be pointwise convergence, i.e.: Fn(x) ‚ÜíF(x) for every x ‚ààR. How-
ever this notion of convergence turns out to be too restrictive. For example consider
the sequence Fn(x) deÔ¨Åned as:
Fn(x) =

1 for x ‚â•1
n ,
0 for x < 0.
If the random number Xn has c.d.f. Fn, then P(Xn =
1
n ) = 1. For a reasonable
convergence notion we should have Fn ‚ÜíF, where
F(x) =

1 for x ‚â•0,
0 for x < 0.
However it is not true in this case that Fn(x) ‚ÜíF(x) for every x ‚ààR. Indeed
Fn(0) = 0 for every n, whereas F(0) = 1. Therefore it is natural to introduce a
weaker deÔ¨Ånition of convergence.
DeÔ¨Ånition 5.1.1 We say that Fn ‚ÜíF for every x if for every œµ > 0 there exists N
such that for n ‚â•N
F(x ‚àíœµ) ‚àíœµ < Fn(x) < F(x + œµ) + œµ.
If x is a continuity point of F, this deÔ¨Ånition implies that
lim
n‚Üí‚àûFn(x) = F(x).
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_5
73

74
5
Convergence of Distributions
Conversely if for every continuity point x of F lim
n‚Üí‚àûFn(x) = F(x), then Fn ‚ÜíF.
For a cumulative distribution, continuity points make up an everywhere dense set
since discontinuity points are denumerable. Indeed there cannot be more than n
discontinuity points with jump larger than or equal to 1
n because F is bounded by 1
from above. Let then x ‚ààR and œµ > 0. There exist two continuity points x0, x of F
such that x ‚àíœµ < x0 < x < x1 < x + œµ. We have then
F(x ‚àíœµ) ‚â§lim
n‚Üí‚àûFn(x0) = F(x0)
and also
lim
n‚Üí‚àûFn(x1) = F(x1) ‚â§F(x + œµ).
On the other side for every n
Fn(x0) ‚â§Fn(x) ‚â§Fn(x1).
Therefore for n sufÔ¨Åciently large we have
F(x ‚àíœµ) ‚àíœµ < Fn(x) < F(x + œµ) + œµ.
It is easy to build up examples of sequences of absolutely continuous c.d.f.‚Äôs con-
verging to a discrete (pure jump) c.d.f. For example if Fn(x) = N(‚àönx), the c.d.f.
of normally distributed Xn with P(X) = 0 and œÉ2(Xn) = 1
n , then Fn ‚ÜíF with
F(x) =

1 for x ‚â•0,
0 for x < 0.
Conversely we can build up examples of discrete c.d.f‚Äôs converging to an absolutely
continuous c.d.f. For example if
Fn(x) =
‚éß
‚é™‚é®
‚é™‚é©
0
for x ‚â§0,
[nx]
n
for 0 < x ‚â§1,
1
for x > 1,
where [x] denotes the integer part of x, then Fn ‚ÜíF, where F is the c.d.f. of the
uniform distribution in [0, 1]:
F(x) =
‚éß
‚é™‚é®
‚é™‚é©
0
for x ‚â§0,
x
for 0 < x ‚â§1,
1
for x > 1.

5.2 Convergence of Geometric Distribution to Exponential Distribution
75
5.2
Convergence of Geometric Distribution to Exponential
Distribution
We have seen that geometric and exponential distributions share the property of
absence of memory, the former among discrete distributions, the latter among ab-
solutely continuous distributions. Let us now consider a sequence (Xn)n‚ààN of random
numbers with geometric distributions with parameters pn:
P(Xn = k) = pn(1 ‚àípn)k‚àí1,
‚àÄk ‚â•1.
We assume that npn converges to Œª > 0, as n ‚Üí‚àû. We put Yn = Xn
n and denote by
FYn the c.d.f. of Yn. We have that
FYn ‚ÜíF,
where F is the c.d.f. of exponential distribution with parameter Œª > 0, i.e.:
F(x) =

0
for x < 0,
1 ‚àíe‚àíŒªx
for x ‚â•0.
Indeed for x < 0, FYn ‚â°0, as ‚ä¢Yn ‚â•0. For x ‚â•0
FYn(x) = P(Yn ‚â§x) = P(Xn ‚â§nx)
= 1 ‚àí
‚àû

k=[nx]+1
pn(1 ‚àípn)k‚àí1
= 1 ‚àípn(1 ‚àípn)[nx]
‚àû

i=0
(1 ‚àípn)i
= 1 ‚àípn(1 ‚àípn)[nx]
1
1 ‚àí(1 ‚àípn)
= 1 ‚àí(1 ‚àípn)[nx],
where we have used the formula for the sum of geometric series. We write
nx = [nx] + Œ¥n,
with 0 ‚â§Œ¥n < 1.
We obtain therefore
FYn(x) = 1 ‚àí(1 ‚àípn)nx‚àíŒ¥n,

76
5
Convergence of Distributions
which tends to 1 ‚àíe‚àíŒªx for n ‚Üí‚àû, since
log (1 ‚àípn)nx = nx log (1 ‚àípn) = ‚àíxnpn + o(npn)
which tends to ‚àíŒªx for n ‚Üí‚àû, whereas
(1 ‚àípn)Œ¥n ‚àí‚àí‚àí‚Üí
n‚Üí‚àû1,
as 0 ‚â§Œ¥n < 1 and pn ‚àí‚àí‚àí‚Üí
n‚Üí‚àû0.
5.3
Convergence of Binomial Distribution to Poisson
Distribution
We now provide an approximation of the binomial distribution when we consider
the number of successes in a large number of trials.
Let (Xn)n‚ààN be a sequence of binomially distributed random numbers with para-
meters n, pn such that npn ‚ÜíŒª with Œª > 0 as n ‚Üí‚àû. For example Xn represent
the number of successes in n Bernoulli trials with parameter pn. As the number of
trials grows to inÔ¨Ånity we send to 0 the probability of success in a single trial. For
0 ‚â§k ‚â§n:
P(Xn = k) =
n
k
	
pk
n(1 ‚àípn)n‚àík
=
n!
k!(n ‚àík)! pk
n(1 ‚àípn)n‚àík nk
nk



multiplication and division by nk
= 1
k!

1 ‚àí1
n
	
¬∑ ¬∑ ¬∑

1 ‚àík ‚àí1
n
	
(npn)k(1 ‚àípn)n‚àík.
We observe that:
‚Ä¢

1 ‚àí1
n
	
¬∑ ¬∑ ¬∑

1 ‚àík ‚àí1
n
	
tends to 1 as n ‚Üí‚àû;
‚Ä¢ (npn)k tends to Œªk for n ‚Üí‚àû;
‚Ä¢ (1 ‚àípn)‚àík tends to 1 for n ‚Üí‚àû;
‚Ä¢ (1 ‚àípn)n tends to e‚àíŒª for n ‚Üí‚àûas
log(1 ‚àípn)n = nlog(1 ‚àípn) = ‚àínpn + o(npn)
tends to ‚àíŒª.

5.3 Convergence of Binomial Distribution to Poisson Distribution
77
It follows that for k ‚ààN
P(Xn = k) ‚àí‚àí‚àí‚Üí
n‚Üí‚àû
Œªk
k! e‚àíŒª,
and therefore the sequence of binomial c.d.f.‚Äôs with parameters n, pn tends to Poisson
c.d.f. with parameter Œª.
5.4
De Moivre-Laplace Theorem
We consider now another type of convergence for sequences of binomial c.d.f‚Äôs. We
send the number of trials to inÔ¨Ånity but this time we keep Ô¨Åxed the probability of
success in a single trial. In order to obtain convergence we need to perform a linear
rescaling.
Theorem 5.4.1 Let (Xn)n‚ààN be a sequence of random numbers with binomial dis-
tribution Bn(n, p) with 0 < p < 1 and let X‚àó
n be the corresponding standardized
random numbers given by
X‚àó
n = Xn ‚àíP(Xn)
œÉ(Xn)
= Xn ‚àínp

np Àúp
for n ‚ààN \ {0}. Where Àúp = 1 ‚àíp. Then we have for all n ‚ààN \ {0}
P(X‚àó
n = x) =
hn
‚àö
2œÄ
e‚àíx2
2 eEn(x) ,
where hn =
1

np Àúp
and the error En(x) tends uniformly to 0 when x ranges on
I (X‚àó
n) [‚àíK, K] for any Ô¨Åxed constant K.
Proof The set I (Xn) of the possible values of Xn is I (Xn) = {0, 1, . . . , n}. Therefore
I (X‚àó
n) = {hn(‚àínp), hn(1 ‚àínp), . . . , hn(n ‚àínp)}
where hn =
1

np Àúp
is the spacing between possible values of X‚àó
n.
We deÔ¨Åne œÜn(x) = log P(X‚àó
n = x) for x ‚ààI (X‚àó
n) and consider its incremental
ratio:
œÜn(x + hn) ‚àíœÜn(x)
hn
= 1
hn
log P(X‚àó
n = x + hn)
P(X‚àón = x)
.

78
5
Convergence of Distributions
Putting k = np + x

np Àúp, we obtain
1
hn
log P(X‚àó
n = x + hn)
P(X‚àón = x)
= 1
hn
log P(Xn = k + 1)
P(Xn = k)
= 1
hn
log (n ‚àík)p
(k + 1) Àúp
=

np Àúplog
n Àúp ‚àíx

np Àúp
n + 1 + x

np Àúp
p
Àúp
=

np Àúplog
1 ‚àíx
 p
n Àúp
1 + 1
np + x

Àúp
np
.
Using the 1-order expansion of the logarithm log(1 + x) = x + O(x2), we obtain

np Àúplog
1 ‚àíx
 p
n Àúp
1 + 1
np + x

Àúp
np
=

np Àúp

‚àíx
 p
n Àúp + O(x2
n ) ‚àíx
 p
n Àúp + O(x2 + 1
n
)

= ‚àíxp ‚àíx Àúp + O(x2 + 1
‚àön
)
‚àíx + O(x2 + 1
‚àön
) .
The function œÜn(x) is not deÔ¨Åned everywhere, but only for x in I (X‚àó
n). We can extend
it to values between two elements of I (X‚àó
n) by linear interpolation. In this way we
can write
œÜn(x) = œÜn(0) +
 x
0
œÜ‚Ä≤
n(y)dy .
If x ‚â§y ‚â§x +hn, then œÜ‚Ä≤
n(y) = hnœÜn(x) = ‚àíx +O(x2 + 1
‚àön
) = ‚àíy+O(x2 + 1
‚àön
)
so that:
œÜn(x) = œÜn(0) +
 x
0
œÜ‚Ä≤
n(y)dy
= œÜn(0) +
 x
0
(‚àíy)dy + O(|x|3 + |x|
‚àön
)
= œÜn(0) ‚àíx2
2 + O(|x|3 + |x|
‚àön
) .

5.4 De Moivre-Laplace Theorem
79
Since œÜn(x) = log P(X‚àó
n = x), we obtain
log P(X‚àó
n = x) = eœÜn(0)e‚àíx2
2 eEn(x)
where En(x) = O
|x|3 + |x|
‚àön
	
.
We can estimate eœÜn(0) in the following way: X‚àó
n is a standardized random number,
i.e. P(X‚àó
n) = 0 and œÉ2(X‚àó
n) = 1. By the Chebychev inequality, we have that:
P(|X‚àó
n| ‚â•K) ‚â§1
K 2 .
K can be chosen so that this probability is arbitrary small, that is for every œµ > 0
there is K such that:
1 ‚àíœµ = 1 ‚àí1
K 2 ‚â§P(|X‚àó
n| < K) ‚â§1.
Since P(|X‚àó
n| < K) = 
x,|x|<K P(|X‚àó
n| = x), it follows that:
1 ‚àíœµ ‚â§

x,|x|<K
P(X‚àó
n = x) ‚â§1 .
Moreover
P(|X‚àó
n| < K) =

x,|x|<K
P(|X‚àó
n| = x) =

x,|x|<K
hne‚àíx2
2 .
Since En(X) tends uniformly to 0 on bounded interval and 
x,|x|<K hne‚àíx2
2 is the
Riemann sum for the function e‚àíx2
2 and tends to
 K
‚àíK e‚àíx2
2 dx, we have for n sufÔ¨Å-
ciently large that:
1 ‚àí2œµ ‚â§eœÜn(0)
hn
 K
‚àíK
e‚àíx2
2 dx ‚â§1 .
Let K tending to inÔ¨Ånity, we obtain
1 ‚àí3œµ ‚â§eœÜn(0)
hn
‚àö
2œÄ ‚â§1
so that
eœÜn(0)
hn
‚àö
2œÄ ‚àí‚àí‚àí‚Üí
n‚Üí‚àû1 .

80
5
Convergence of Distributions
It follows that
P(|X‚àó
n| = x) =
hn
‚àö
2œÄ
e‚àíx2
2 eEn(x) ,
where En(x) is an error that tends uniformly to 0 for x ranging on the possible values
of X‚àó
n in a bounded interval.
As application of the theorem, one obtains an approximation of the c.d.f. of the
binomial distribution. Given a, b, a < b:
P(a ‚â§X‚àó
n ‚â§b) =

a‚â§x‚â§b
P(X‚àó
n = x) =

a‚â§x‚â§b
hn
‚àö
2œÄ
e‚àíx2
2 eEn(x) .
This is the Riemann sum of n(x) =
1
‚àö
2œÄ
e‚àíx2
2 , therefore it converges to
1
‚àö
2œÄ
 b
a
e‚àíx2
2 dx = N(b) ‚àíN(a) ,
where N(x) is the c.d.f. of standard Gaussian distribution. The c.d.f. Fn(x) of X‚àó
n
converges to N(x) since
Fn(x) = P(X‚àó
n ‚â§x) = P(‚àík < X‚àó
n ‚â§x) + P(X‚àó
n ‚â§‚àík)
= N(x) ‚àíN(‚àík) + P(X‚àó
n ‚â§‚àík) + E‚Ä≤
n(x)
with lim
n‚Üí‚àûE‚Ä≤
n(x) = 0. The Chebychev inequality states that P(X‚àó
n ‚â§‚àík) can be
made arbitrarily small. Also N(‚àík) tends to 0 for k ‚àí‚Üí‚àû. Therefore the c.d.f. of
standardized binomial distributions tend to N.

Chapter 6
Discrete Time Markov Chains
6.1
Homogeneous Discrete Time Markov Chains
with Finite State Space
We deÔ¨Åne a homogeneous Markov chain with Ô¨Ånite state space S ‚äÇR as a sequence
of random numbers (Xi)i‚ààN ‚äÇS for i ‚ààN such that:
P(X0 = s0, X1 = s1, . . . , Xn = sn) = œÅs0 ps0,s1 ps1,s2 ¬∑ ¬∑ ¬∑ psn‚àí1,sn,
where
1. œÅsi, si ‚ààS, is called initial distribution:
œÅsi = P(X0 = si)
and

s‚ààS
œÅs = 1 .
2. ps,s‚Ä≤ = [P]s,s‚Ä≤, are called transition probabilities and satisfy:
‚Ä¢ 0 ‚â§pi j ‚â§1;
‚Ä¢ 
s‚Ä≤‚ààS ps,s‚Ä≤ = 1
for every s ‚ààS.
They can be arranged in a matrix P called transition probability matrix of entries
[P]s,s‚Ä≤ =: ps,s‚Ä≤.
The Markov chain (Xi)i‚ààN can be seen as representing the evolution of a system that
moves from one state to another in a random fashion. We have assumed that S ‚äÇR,
but it may be convenient to consider in some situations a general Ô¨Ånite set S. In this
case Xi are not random numbers, but random entities. However what follows goes
through without any change.
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_6
81

82
6
Discrete Time Markov Chains
We show now that ps,s‚Ä≤ is the probability to go from state s to state s‚Ä≤. Moreover
we show that the probability that Xr+1 = s‚Ä≤ conditional to all previous history
X0 = s0, . . . , Xr‚àí1 = sr‚àí1, Xr = s depends just on s and is equal to ps,s‚Ä≤ (Markov
property). Indeed:
P(Xr+1 = s‚Ä≤|Xr = s, Xr‚àí1 = sr‚àí1, . . . , X0 = s0)
= P(Xr+1 = s‚Ä≤, Xr = s, Xr‚àí1 = sr‚àí1, . . . , X0 = s0)
P(Xr = s, Xr‚àí1 = sr‚àí1, . . . , X0 = s0)
=
œÅs0 ps0,s1 ¬∑ ¬∑ ¬∑ psr‚àí1,Ps,s‚Ä≤
œÅs0 ps0,s1 ¬∑ ¬∑ ¬∑ psr‚àí1,s, ps,s‚Ä≤
= ps,s‚Ä≤,
provided that the probability of the conditioning event, which is at denominator, is
positive (this is required to compute the conditional probability).
Example 6.1.1 (Random walk). A random walk in an integer interval [a, b] ‚äÇZ,
with absorbing boundary conditions is a Markov chain with state space S = [a, b]
and transition probability matrix:
P =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù
1
0
0
¬∑ ¬∑ ¬∑
¬∑ ¬∑ ¬∑ 0
1 ‚àíp 0
p
...
...
0
... ...
...
... ...
...
... ...
...
... 0
...
... 1 ‚àíp 0
p
0
¬∑ ¬∑ ¬∑ ¬∑ ¬∑ ¬∑
0
0
1
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†
,
where 0 < p < 1. Boundary conditions are determined by the transition probabil-
ities from state a and b. Other boundary conditions can be considered: reÔ¨Çecting,
mixed, ‚Ä¶In the case p = 1
2 we speak of symmetric random walk.
Example 6.1.2 (Bernoulli-Laplace chain). Let us consider two urns A and B, each
containing N balls. The balls are assumed to be identical apart from their colors.
Among the balls there are N white balls and N black balls. At each integer time we
choose one ball from each urn and exchanges them.
Let Xi be the random number of white balls in A at time i. The state space is
S = {0, 1, . . . , N}.
The transition probability from state k to state l is given by:
pk,k = P(two white balls or two black balls are drawn)
= k
N
N ‚àík
N
+ N ‚àík
N
k
N = 2 k
N
N ‚àík
N
;
(6.1)

6.1 Homogeneous Discrete Time Markov Chains with Finite State Space
83
pk,k+1 = P(1 black ball from urn A and 1 white ball from B )
= N ‚àík
N
N ‚àík
N
= (N ‚àík)2
N 2
;
(6.2)
pk,k‚àí1 = P(1 white ball from A and 1 black ball from B )
= k
N
k
N = k2
N 2 .
(6.3)
The transition probabilities to other states are zero. This applies also to the case k = 0
and k = N. The transition matrix is therefore:
P =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éù
0
1
0
0
¬∑ ¬∑ ¬∑ 0
1
N 2
2(N‚àí1)
N 2

 N‚àí1
N
2
0
¬∑ ¬∑ ¬∑ 0
0
4
N 2
4(N‚àí2)
N 2

 N‚àí2
N
2 ¬∑ ¬∑ ¬∑ 0
...
...
0
¬∑ ¬∑ ¬∑
0
¬∑ ¬∑ ¬∑
1 0
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚é†
.
6.2
Transition Probability in n Steps
By using composite probability formula we can compute the probability for a Markov
chain to go from state s to state s‚Ä≤ in n steps. Let s0, s1, . . . , sm‚àí1, s be a sequence of
states such that œÅs0 ps0,s1 ps1,s2 ¬∑ ¬∑ ¬∑ psm‚àí1,s are strictly positive. We have:
P(Xm+n = s‚Ä≤|Xm = s, Xm‚àí1 = sm‚àí1, . . . , X0 = s0)
= P(Xm+n = s‚Ä≤, Xm = s, Xm‚àí1 = sm‚àí1, . . . , X0 = s0)
P(Xm = s, Xm‚àí1 = sm‚àí1, . . . , X0 = s0)
=

sm+1,...,sm+n‚àí1
P(Xm+n = s‚Ä≤, Xm+n‚àí1 = sm+n‚àí1, . . . , X0 = s0)
P(Xm = s, Xm‚àí1 = sm‚àí1, . . . , X0 = s0)
=

sm+1,...,sm+n‚àí1
œÅs0 ps0,s1 ¬∑ ¬∑ ¬∑ psm‚àí1,s ps,sm+1 ¬∑ ¬∑ ¬∑ psm+n‚àí1,s‚Ä≤
œÅs0 ps0,s1 ps1,s2 ¬∑ ¬∑ ¬∑ psm‚àí1,s
=

sm+1,...,sm+n‚àí1
ps,sm+1 ¬∑ ¬∑ ¬∑ psm+n‚àí1,s‚Ä≤
=

Pn
s,s‚Ä≤ .

84
6
Discrete Time Markov Chains
Thisprobabilitydoesnot dependonm,butjustonn,thatisthenumberofintermediate
steps. It is obtained as the element with coordinates s, s‚Ä≤ of the n-th power of the
transition matrix P. In the following we will use the common notation p(n)
s,s‚Ä≤ for this
probability:
p(n)
s,s‚Ä≤ := P(Xm+n = s‚Ä≤|Xm = s) =

Pn
s,s‚Ä≤ .
By convention one deÔ¨Ånes:
p(0)
s,s‚Ä≤ := ps,s‚Ä≤ =
‚éß
‚é®
‚é©
1 if s = s‚Ä≤,
0 otherwise.
6.3
Equivalence Classes
Let (Xi)i‚ààN be a homogeneous Markov chain. We say that the state s communicates
with the state s‚Ä≤ if there exists n > 0 such that
p(n)
s,s‚Ä≤ > 0,
that is if there exists a path s, s1, . . . , sn‚àí1, s‚Ä≤ such that all transition probabilities
ps,s1, ps1,s2, . . . , psn‚àí1,sn are strictly positive. We will use the notation s ‚â∫s‚Ä≤ to
indicate that s communicates with s‚Ä≤.
Two states s, s‚Ä≤, are said to be equivalent if s ‚â∫s‚Ä≤ and s‚Ä≤ ‚â∫s. This is an equivalence
relation, i.e. it is reÔ¨Çexive, symmetric and transitive. The Ô¨Årst two properties are
evident. Transitivity follows from transitivity of communication. Assume that s ‚â∫s‚Ä≤
and s‚Ä≤ ‚â∫s‚Ä≤‚Ä≤. Then there are n1, n2 such that pn1
s,s‚Ä≤ > 0 and pn2
s‚Ä≤,s‚Ä≤‚Ä≤ > 0. It follows that
s ‚â∫s‚Ä≤‚Ä≤. Indeed:
p(n1+n2)
s,s‚Ä≤‚Ä≤
=

Pn1+n2
s,s‚Ä≤‚Ä≤ =

s1
p(n1)
s,s1 p(n2)
s1,s‚Ä≤‚Ä≤ ‚â•p(n1)
s,s‚Ä≤

>0
p(n2)
s‚Ä≤,s‚Ä≤‚Ä≤

>0
> 0 .
The communication relation ‚â∫between states can be extended without ambiguity
to equivalence classes. We indicate with [s] the equivalence class of the state s, i.e.
the set of all states s‚Ä≤ equivalent to s according to the previously introduced relation.
When s ‚â∫s‚Ä≤ we say that s‚Ä≤ follows s. We say that [s] communicates with [s‚Ä≤] and
write [s] ‚â∫[s‚Ä≤] if s ‚â∫s‚Ä≤. Using the transitivity property it is easy to check that this is
a well-posed deÔ¨Ånition, i.e. it does not depend on the choices of the representatives
in the equivalence classes.
An equivalence class is said to be maximal if it is not followed by any other
class with respect to the communication relation. If a Markov time is in a state of
a maximal equivalence class, then at all subsequent times, it will be in states of the
same class with probability 1.

6.3 Equivalence Classes
85
Another characteristic of a state of a Markov chain is its period. Let s ‚ààS be a
state of a Markov chain and let:
A+
s = { n > 0 |p(n)
s,s > 0} .
If A+
s Ã∏= ‚àÖ, we deÔ¨Åne the period of s as the greatest common divisor (GCD) of the
elements of A+
s . If the period of s is 1, we say that s is an aperiodic state. For example,
in the random walk on the interval [a,b] with absorbing boundary conditions all states
s with a < s < b have period 2.
All states of an equivalence class have the same period. Therefore one can speak
of the period of an equivalence class.
Proof Let us consider two equivalent states s ‚àºs‚Ä≤, and q, q‚Ä≤ their periods. It is
enough to show that q‚Ä≤ divides every n ‚ààA+
s . In force of the equivalence, there is n1
such that p(n1)
s,s‚Ä≤ > 0 and there is n2 such that p(n2)
s‚Ä≤,s > 0. Then (n1 + n2) ‚ààA+
s since
p(n1+n2)
s,s
=

s1
p(n1)
s,s1
(n2)
s1,s ‚â•p(n1)
s,s‚Ä≤ p(n2)
s‚Ä≤,s > 0.
Similarly (n1 + n2) ‚ààA+
s‚Ä≤; hence q and q‚Ä≤ both divide (n1 + n2). Moreover for all
n ‚ààA+
s , (n + n1 + n2) ‚ààA+
s‚Ä≤, since
p(n+n1+n2)
s‚Ä≤,s‚Ä≤
‚â•p(n2)
s‚Ä≤,s p(n)
s,s p(n1)
s,s‚Ä≤ > 0 .
Hence, q and q‚Ä≤ divide (n + n1 + n2) for all n ‚ààA+
s and for all n ‚ààA+
s‚Ä≤. Since n1, n2
are divisible by q and by q‚Ä≤, q and q‚Ä≤ are both common divisors of A+
s and of A+
s‚Ä≤, so
that
q = q‚Ä≤ .
An equivalence class C of period q < ‚àûcan be decomposed in q subsets:
C = C0 ‚à™C1 ‚à™¬∑ ¬∑ ¬∑ ‚à™Cq‚àí1
with the property that if s ‚ààCi, s‚Ä≤ ‚ààC j and p(n)
s,s‚Ä≤ > 0 then
n ‚â°( j ‚àíi) (mod q) .
If a maximal equivalence class C has period q, C0, C1, . . . , Cq‚àí1 are cyclically visited
by the Markov chain: i.e. if X0 ‚ààCi, then X1 ‚ààC[i+1]modq, X2 ‚ààC[i+2]modq with
probability 1, where we use the notation [k]q for the element of the set {0, . . . , q ‚àí1}
that is equivalent to k modulo q.

86
6
Discrete Time Markov Chains
6.4
Ergodic Theorem
We want to study the behavior of a Markov chain as time proceeds.
An important result states that a Markov chain with Ô¨Ånite state space and a sin-
gle aperiodic equivalence class has the property that the distribution on state space
converges to a limit that does not depend on the initial state. This is the result of the
following theorem called ergodic theorem (see e.g. Gnedenko (1997) for a proof).
Theorem 6.4.1 (Ergodic theorem) Let (Xi)i‚ààN be a homogeneous Markov chain
with a Ô¨Ånite state space. If the chain is irreducible (i.e. there is a unique equivalence
class) and aperiodic (i.e. the period is 1), then there is a probability distribution
Œ† = (œÄs)s‚ààS on the state space and constants C > 0 and 0 ‚â§Œ¥ < 1 such that for
all s‚Ä≤, s ‚ààS :
|p(n)
s‚Ä≤,s ‚àíœÄs| ‚â§CŒ¥n .
In other words there are œÄs, s ‚ààS, such that:
1. 0 ‚â§œÄs ‚â§1;
2. 
s‚ààS œÄs = 1,
and ‚àÄs‚Ä≤ ‚ààS
lim
n‚Üí+‚àûp(n)
s‚Ä≤,s = œÄs
with exponential speed.
This theorem can be used also in the case when the period q is strictly larger than 1,
by considering the Markov chain with transition matrix Pq. Indeed, the restriction of
this chain to each of the subsets C0, C1, . . . , Cq‚àí1 satisÔ¨Åes the hypothesis of ergodic
theorem.
The probability distribution Œ† that appears in the statement of the ergodic theorem
is an invariant (or stationary) distribution for the Markov chain: this means that if
we take it as initial distribution, so that P(X0 = s) = œÄs for every s ‚ààS, then for
every s ‚ààS and for every n ‚â•0
P(Xn = s) = œÄs .
This property allows us to compute œÄs as the solution of a system of linear equations.
Indeed:
œÄs = P(X1 = s)
=

s‚Ä≤ ‚ààS
P(X0 = s‚Ä≤) ps‚Ä≤,s
=

s‚Ä≤ ‚ààS
œÄs‚Ä≤ ps‚Ä≤,s .

6.4 Ergodic Theorem
87
Moreover, since œÄs is a probability distribution, we have

s‚ààS
œÄs = 1 .
Under the hypothesis of the ergodic theorem one can show that there is one and
only one solution for this system of |S| + 1 equations in |S| unknowns; one of the
equations, in this case one of the Ô¨Årst |S| equations, is a linear combination of the
others and therefore it can be skipped in the solution of the system:
Œ†t = Œ†t P

œÄs‚ààS œÄs = 1 ,
(6.4)
where we have represented Œ† as |S|-dimensional vector. The ergodic theorem tells
us that as time advances the Markov chain forgets the initial state and reaches an
equilibrium. We show now the uniqueness of the invariant measure.
Proof Let us assume that (Œºs)s‚ààS is another probability distribution on the state space
satisfying system (6.4). We have
Œºt = Œºt P

s‚ààS Œºs = 1 ,
where we have represented the distribution (Œºs)s‚ààS as the |S|-dimensional column
vector Œº. We have
Œºt = Œºt P
‚áí
Œºt = Œºt P = Œºt P2 = ¬∑ ¬∑ ¬∑ = Œºt Pn .
If n tends to inÔ¨Ånity, by ergodic theorem Pn converges to the matrix:
‚éõ
‚éú‚éú‚éú‚éù
œÄ1 œÄ2 ¬∑ ¬∑ ¬∑ œÄn
œÄ1 œÄ2 ¬∑ ¬∑ ¬∑ œÄn
...
...
...
œÄ1 œÄ2 ¬∑ ¬∑ ¬∑ œÄn
‚éû
‚éü‚éü‚éü‚é†
therefore for s ‚ààS
Œºs =

s‚Ä≤
Œºs‚Ä≤ ps‚Ä≤,s =

s‚Ä≤
Œºs‚Ä≤ p(n)
s‚Ä≤,s .
By taking the limit limn‚Üí+‚àûp(n)
s‚Ä≤,s = œÄs, we have
Œºs =

s‚Ä≤
Œºs‚Ä≤œÄs = œÄs

s‚Ä≤
Œºs‚Ä≤
  
1
= œÄs .

Chapter 7
Continuous Time Markov Chains
7.1
Introduction
In this chapter we shall introduce some simple queueing systems. For further reading,
we refer to [7, 8].
A queueing system can be described in terms of servers and a Ô¨Çow of clients
who access servers and are served according to some pre-established rules. The
clients after service can either stay in the system or leave it, also according to some
established rules.
The simplest case is when there is a single set of servers and a Ô¨Çow of clients
accessing to it. If there is at least one free server, then an incoming client is served
right away. Otherwise, i.e. if all servers are engaged, he is put in a queue and waits
for his turn. Once a client is served, he leaves the system.
Usual hypotheses are that service times are stochastically independent, identically
distributed, and moreover that they are stochastically independent from the Ô¨Çow of
clients‚Äô arrivals. One would like to obtain the probabilities that, at given times, there
are some numbers of clients in the system. For this one needs to introduce a random
number for each time t; this leads us to introduce the notion of stochastic process.
DeÔ¨Ånition 7.1.1 A stochastic process (Xt)t‚ààI with I interval of R, is a family of
random numbers with index varying in some interval I of R.
Speaking of stochastic processes therefore one refers to continuous index space,
where the index is usually interpreted as time. Markov chains, introduced in previous
chapter, can be considered as discrete time stochastic processes.
We model the Ô¨Çow of incoming clients by a stochastic process Nt, representing
the number of clients arrived before time t, which is assumed to be stochastically
independent from service times. For Ô¨Åxed t, Xt represents the random number of the
clients who are present in the system at time t.
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_7
89

90
7
Continuous Time Markov Chains
In order to characterize a system such as that we have described, one needs to
specify:
1. the stochastic process ruling the Ô¨Çow of incoming clients;
2. the distribution of service times;
3. the number of servers.
It is customary to adopt the following notation to indicate the speciÔ¨Åcations of a
given queueing system:
1. M denotes the Poisson process for the Ô¨Çow of incoming clients or exponential
distribution for service times;
2. Er denotes the Erlang distribution with parameter r for the inter-arrival times
of clients (that are supposed to be stochastically independent and identically
distributed) or for service times. The Erlang distribution with parameter r is the
distribution of a sum ofr stochastically independent exponential random numbers
with the same parameter;
3. D denotes deterministic (non-random) inter-arrival times or service times;
4. G indicates that one does not make any particular hypothesis on the inter-arrival
times or service times (that however are always assumed to be stochastically
independent).
A process of the type we have described will be indicated by three symbols separated
by two slashes. The Ô¨Årst symbol refers to the distribution of inter-arrival times, always
assumed to be stochastically independent and identically distributed (i.i.d.). The
second symbol refers to the distribution of service times. The third symbol indicates
the number of servers; it can possibly take the value ‚àû.
We shall consider three examples of queueing systems and precisely the systems
M/M/1, M/M/n with n > 1 and M/M/‚àû. Before that we shall speak about
continuoustimeMarkovchainswithcountablestatespace,andinparticularintroduce
the Poisson process Nt, t ‚â•0, that for these queueing systems represents the number
of clients who entered the system before time t.
7.2
Homogeneous Continuous Time Markov Chains
with Countable State Space
An homogeneous continuous time Markov chain is a stochastic process (Xt)t‚â•0 with
I (Xt) = N characterized by the initial distribution (œÅs)s‚ààN, and for every t > 0 a
transition matrix p(t)s,s‚Ä≤ = [Œ†]ss‚Ä≤ (t). As in the case of discrete time case they must
respectively satisfy
0 ‚â§œÅs ‚â§1,

s‚ààN
œÅs = 1,
0 ‚â§p(t)s,s‚Ä≤ ‚â§1,

s‚Ä≤‚ààN
p(t)s,s‚Ä≤ = 1,

7.2 Homogeneous Continuous Time Markov Chains with Countable State Space
91
for every t > 0. If 0 = t0 < t1 < ¬∑ ¬∑ ¬∑ < tn‚àí1 < tn, then
P(X0 = s, Xt1 = s1, . . . , Xtn = sn)
= œÅs0 ps0,s1(t1)ps1,s2(t2 ‚àít1) . . . psn‚àí1,sn(tn ‚àítn‚àí1).
It follows from conditions of compatibility that transition matrices are related by
Chapman-Kolmogorov equations that can be expressed in synthetic form by:
Œ†(t + t‚Ä≤) = Œ†(t) Œ†(t‚Ä≤)
‚àÄt, t‚Ä≤ ‚â•0
or explicitly:
ps,s‚Ä≤(t + t‚Ä≤) =

s‚Ä≤‚Ä≤
ps,s‚Ä≤‚Ä≤(t) ps‚Ä≤‚Ä≤,s‚Ä≤(t‚Ä≤).
In order to treat interesting examples, such as those arising from queueing theory,
we need to consider the case of strictly denumerable state spaces. In this case Œ†(t)
is a matrix with inÔ¨Ånitely many rows and columns with non-negative entries, such
that the sum of the series of the elements of each row is equal to 1.
The product of two matrices of this kind can be deÔ¨Åned according to the usual row
times column rule, where the Ô¨Ånite sum is replaced by a series. It is easy to check
that the result is still a matrix of this kind.
Inthecaseofdiscretetimethetransitionprobabilitiesinmorestepscanbeobtained
from those in one step. In the case of continuous time analogously transition prob-
abilities in a Ô¨Ånite time t can be obtained starting from their behavior as t becomes
inÔ¨Ånitely small. The simplest case is the Poisson process.
7.3
Poisson Process
A Poisson process is a continuous time Markov chain with state space S = N. In the
following we shall use a Poisson process as a model for the Ô¨Çow of clients entering a
queueing system. For the quantities that we shall consider the order in which clients
are served does not matter. A Poisson process N = (Nt)t‚â•0 with parameter Œª, where
Œª > 0, is characterized by the following properties:
1. ps,s(h) = 1 ‚àíŒªh + o(h);
2. ps,s+1(h) = Œªh + o(h);
3. ps,s‚Ä≤(h) = o(h) for s‚Ä≤ /‚àà{s, s + 1},
where o(h) is inÔ¨Ånitesimal of order larger than h, uniformly in s and s‚Ä≤.
Starting from this hypothesis we can obtain the Kolmogorov forward equations,
a system of inÔ¨Ånitely many differential equations for transition probabilities. Let us
Ô¨Åx ¬Øs = 0 and the initial distribution œÅ0 = 1, œÅs = 0 for s Ã∏= 0, i.e. P(N0 = 0) = 1.

92
7
Continuous Time Markov Chains
We put:
Œºs(t) = p0,s(t) for s ‚ààN
and denote by Œº‚Ä≤
s the Ô¨Årst derivative of Œºs. The functions Œºs verify the system of
equations:
Œº‚Ä≤
0(t) = ‚àíŒªŒº0(t)
Œº‚Ä≤
s(t) = ‚àíŒªŒºs(t) + ŒªŒºs‚àí1(t) for s ‚â•1,
(7.1)
as we now show. Consider for s > 0 the incremental ratio Œºs(t + h) ‚àíŒºs(t)
h
for
h > 0. We have:
Œºs(t + h) ‚àíŒºs(t)
h
= p0,s(t + h) ‚àíp0,s(t)
h
=

j p0, j(t)p j,s(h) ‚àíp0,s(t)
h
= 1
h ((1 ‚àíŒªh + o(h))p0,s(t) + (Œªh + o(h))p0,s‚àí1(t))
+ 1
h
‚éõ
‚éú‚éú‚éú‚éù

j
jÃ∏=s, jÃ∏=s‚àí1
p0, j(t)p j,s(h) ‚àíp0,s(t)
‚éû
‚éü‚éü‚éü‚é†
= ‚àíŒªp0,s(t) + Œªp0,s‚àí1(t) + o(h)
h
= ‚àíŒªŒºs(t) + ŒªŒºs‚àí1(t) + o(h)
h
.
By taking the limit h ‚Üì0, we obtain an equation for the right derivative:
Œº‚Ä≤
s(t) = ‚àíŒªŒºs(t) + ŒªŒºs‚àí1(t) for s ‚â•1 ,
where we have used the notation for the derivative since it is easy to show that it
exists. For s = 0, we obtain for h > 0:
Œº0(t + h) ‚àíŒº0(t)
h
= p0,0(t + h) ‚àíp0,0(t)
h
=

j p0, j(t)p j,0(h) ‚àíp0,0(t)
h
=
(1 ‚àíŒªh + o(h))p0,0(t) + 
jÃ∏=0 p0, j(t)p j,0(h) ‚àíp0,0(t)
h
= ‚àíŒªp0,0(t) + o(h)
h
= ‚àíŒªŒº0(t) + o(h)
h

7.3 Poisson Process
93
that in the limit h ‚Üì0 converges to the equation
Œº‚Ä≤
0(t) = ‚àíŒªŒº0(t).
As we show below the solution of the system is given by
Œºs(t) = p0,s(t) = (Œªt)s
s!
e‚àíŒªt ,
i.e. for each t we have that Nt has Poisson distribution with parameter Œªt.
If we take œÅ¬Øs = 1 and œÅs = 0 for s Ã∏= ¬Øs i.e. assume that P(N0 = ¬Øs) for some
arbitrary state ¬Øs, then we obtain the transition probabilities starting from ¬Øs:
‚éß
‚é®
‚é©
p¬Øs,s(t) = 0
for s < ¬Ø¬Øs,
p¬Øs,s(t) = (Œªt)s‚àí¬Øs
(s ‚àí¬Øs)! e‚àíŒªt for s ‚â•¬Ø¬Øs.
(7.2)
Let us prove that (7.2) provides a solution for the system with initial state ¬Øs. Let us
consider the generating function:
Œ¶(z, t) =

s
p¬Øs,s(t)zs.
We derive Œ¶(z, t) with respect to t. It is easy to see that the derivative can be
exchanged with the series. By applying the system of equation for Œºs(t) = p¬Øs,s(t),
we obtain
‚àÇ
‚àÇt Œ¶(z, t) =

s
Œº‚Ä≤
s(t)zs = ‚àíŒª
‚àû

s=0
Œºs(t)zs + Œª
‚àû

s=1
Œºs‚àí1(t)zs = Œª(z ‚àí1)Œ¶(z, t).
Therefore
1
Œ¶(z, t)
‚àÇ
‚àÇt Œ¶(z, t) = ‚àÇ
‚àÇt log Œ¶(z, t) = Œª(z ‚àí1),
so that
log Œ¶(z, t) = Œª(z ‚àí1)t + K,
that is Œ¶(z, t) = eKeŒª(z‚àí1)t. Since Œº¬Øs(0) = 1 and Œºs(0) = 0 for s Ã∏= ¬Øs, we have
Œ¶(z, 0) = z¬Øs. We have therefore:
Œ¶(z, t) = z¬ØseŒª(z‚àí1)t = e‚àíŒªtz¬ØseŒªzt = e‚àíŒªt 
k
z¬Øs+k (Œªt)k
k! .

94
7
Continuous Time Markov Chains
Fig. 7.1 Scheme of Poisson
process with parameter Œª
0
1
2
3
Œª
Œª
Œª
Œª
It follows that p¬Øs,s(t) = 0 for s < ¬Øs, p¬Øs,s(t) = (Œªt)s‚àí¬Øs
(s ‚àí¬Øs)!e‚àíŒªt for s ‚â•¬Øs. The Poisson
process is non-decreasing with probability 1. It can be represented as in Fig.7.1,
when an arrow connecting two states with superscript Œª indicates that the transition
intensity from one state to the other one is equal to Œª. We observe that an arrow
enters every state s with s ‚â•1. These two arrows, one in-coming and one exiting,
correspond to two terms, one with plus sign and one with minus sign, on the right-
hand side of the differential equation. For s = 0 there is just an out-coming arrow,
corresponding to the single term, with minus sign, on the right-hand side of the
differential equation.
If we indicate with Ps(t) = P(Nt = s) the probability that Poisson process at
time t is in the state s, then we have
Ps(t) =

s‚ààN
œÅ¬Øs p¬Øs,s(t) ,
where œÅs is the initial distribution. It follows that for every initial distribution the
functions (Ps(t))s‚ààN satisfy the same system of differential equations.
 P‚Ä≤
0(t) = ‚àíŒªP0(t)
P‚Ä≤
s(t) = ‚àíŒªPs(t) + ŒªPs‚àí1(t) for s ‚â•1.
The functions (p¬Øs,s(t))s‚ààN can be considered as particular cases in which œÅ¬Øs = 1
and œÅs = 0 for s Ã∏= ¬Øs.
7.4
Queueing Processes
We now consider some examples of continuous time Markov chains that serve as
models of queueing processes. As we have said in Sect.7.1, in queueing theory there
is a symbolic notation to indicate the type of a queueing system. In the examples we
consider the Ô¨Çow of incoming clients follows a Poisson process with parameter Œª.
Clients who Ô¨Ånd a free server start a service time and after service leave the system.
When an arriving client Ô¨Ånds all servers engaged, he is put in a queue. When a server
becomes free, if there are clients waiting in queue, one of them starts its service time.
For what we are interested in, the order in which clients access the service does
not matter; we can assume, for example, that the order is randomly chosen, but
other possible choices would not change the results. We assume that service times

7.4 Queueing Processes
95
are stochastically independent, identically distributed and stochastically independent
from the Poisson process ruling the Ô¨Çow of arrivals. We also assume that service times
are exponentially distributed with some parameter Œº.
A process of this type will be indicated with the symbol M/M/n. The Ô¨Årst M
means that the Ô¨Çow of arrivals is Poisson, the second M means that service times are
exponentially distributed, while n denotes the number of servers and can vary from
1 to ‚àû(‚àûis an admissible value).
7.5
M/M/‚àûQueueing Systems
We consider an idealized situation in which there are inÔ¨Ånitely many servers. The
Ô¨Çow of arrivals is ruled by a Poisson process with parameter Œª and service times are
exponentially distributed with parameter Œº.
Let X = (Xt)t‚â•0 be the process indicating the number of clients who are in the
system at time t. As initial distribution we assume that:
 P(X0 = 0) = 1 ,
P(X0 = i) = 0
for i > 0,
i.e. no client is present in the system at time 0. As stated in previous section, ser-
vice times are stochastically independent between themselves and from the arrivals‚Äô
process. In order to compute the intensity of service process, we obtain the probabil-
ity that a client is served in time interval (t, t + h), given that he has not been served
up to time t. If T is service time for a client, we have:
P(T ‚â§t + h|T > t) = P(t < T ‚â§t + h)
P(T > t)
= e‚àíŒºt ‚àíe‚àíŒº(t+h)
e‚àíŒºt
= 1 ‚àíe‚àíŒºh
= 1 ‚àí(1 ‚àíŒºh + o(h))
= Œºh + o(h),
where we have used Ô¨Årst order expansion of the exponential e‚àíŒºh = 1 ‚àíŒºh + o(h)
for small h. Assume that there are n clients in the system. If no one of them has been
served up to time t, the probability that at least one of them is served in time interval
(t, t + h) is then:
1 ‚àíP(T1 > t + h, . . . , Tn > t + h|T1 > t, . . . , Tn > t)
= 1 ‚àíP(T > t + h|T > t)n = 1 ‚àíe‚àínŒºh = nŒºh + o(h) ,

96
7
Continuous Time Markov Chains
Fig. 7.2 Graphical
representation of a M/M/‚àû
queueing system
0
1
2
3
Œª
Œº
2Œº
Œª
Œª
3Œº
Œª
4Œº
where T1, . . . , Tn denote the service times of the clients and we have used the fact
that they are stochastically independent and identically distributed. Therefore a client
exits the system with an intensity which is proportional to the number of clients
present in the system. The process can be represented as in Fig.7.2.
Putting p0,s(t) = Œºs(t), we can write forward Kolmogorov equations by using
the rule described in Sect.7.3:
Œº‚Ä≤
0(t) = ŒºŒº1(t) ‚àíŒªŒº0(t)
Œº‚Ä≤
i(t) = ‚àí(Œª + iŒº) Œºi(t) + Œª Œºi‚àí1(t) + (i + 1)Œº Œºi+1(t)
for i ‚â•1, where Œº‚Ä≤
i(t) denotes the derivative of Œºi.
We have seen that n-steps transition probabilities of discrete time Markov chains
satisfying the hypothesis of ergodic theorem converge as n ‚Üí‚àûto the stationary
distribution. Analogous results hold for continuous time Markov chains. Therefore
we look for a stationary solution (pi)i‚â•0 of the system of equations, that is a solution
which does not depend on the time. We impose Œº‚Ä≤
i(t) = 0 so that Œºi(t) = pi and
obtain:
‚éß
‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é©
0 = Œºp1 ‚àíŒªp0
0 = ‚àí(Œª + iŒº)pi + Œªpi‚àí1 + (i + 1)Œºpi+1,
for i ‚â•1
+‚àû

i=0
pi = 1 .
By adding up the equations up to the i-th one, we obtain the recursive formula:
pi = Œª
iŒº pi‚àí1 = 1
i!
Œª
Œº
i
p0 .
By imposing the condition
+‚àû

i=0
1
i!
Œª
Œº
i
p0 = 1, we obtain:
p0
+‚àû

i=0
1
i!
Œª
Œº
i
= 1.

7.5
M/M/‚àûQueueing Systems
97
Since
+‚àû

i=0
1
i!
Œª
Œº
i
= e
Œª
Œº , therefore
pi = e‚àíŒª
Œº
and
pi = 1
i!
Œª
Œº
i
e‚àíŒª
Œº ,
which is Poisson distribution with parameter Œª
Œº. We come to the conclusion that for
M/M/‚àûthe queueing system stationary distribution exists for all values of Œª and Œº.
7.6
M/M/1 Queueing Systems
Also for M/M/1 service times are assumed to be stochastically independent and
identically distributed with exponential distribution with parameter Œº. The arrival
Ô¨Çow of clients is ruled by a Poisson process with parameter Œª which is stochastically
independent from service times.
For this system there is just one server. Therefore the intensity for a client to
exit the system is equal to Œº independently from the number of clients present in
the system. M/M/1 queueing system can be graphically represented as shown in
Fig.7.3.
The system of differential equations for the function Œºs(t) = p¬Øs,s(t), where ¬Øs is
some Ô¨Åxed state, is then:
 Œº‚Ä≤
0(t) = ŒºŒº1(t) ‚àíŒªŒº0(t)
Œº‚Ä≤
1(t) = ‚àí(Œª + Œº) Œº1(t) .
Also in this case we look for a stationary solution, i.e. such that Œº‚Ä≤
i(t) = 0 for i ‚ààN
with Œºi(t) = pi, where pi is a probability distribution. We obtain then the system of
linear equations:
‚éß
‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é©
0 = Œºp1 ‚àíŒªp0
0 = ‚àí(Œª + Œº)pi + Œªpi‚àí1 + Œºpi+1
+‚àû

i=0
pi = 1 .
Fig. 7.3 Scheme of M/M/1
queueing system
0
1
2
3
Œª
Œº
Œª
Œª
Œª
Œº
Œº
Œº

98
7
Continuous Time Markov Chains
From this system we obtain, by adding up the Ô¨Årst n equations, the recursive relation
pn = Œª
Œº pn‚àí1 =
Œª
Œº
n
p0 .
By imposing the condition +‚àû
i=0 pi = 1, we obtain
 ‚àû

i=0
Œª
Œº
i 
p0 = 1.
This series is convergent if Œª
Œº < 1. In this case we get
p0 = 1 ‚àíŒª
Œº.
The stationary probability distribution is then
pi =
Œª
Œº
i 
1 ‚àíŒª
Œº

,
for i = Œª
Œº.
The stationary probability distribution is a shifted geometric distribution with para-
meter Œª
Œº (the set of possible values is N instead of N \ {0}). It exists if and only if
Œª
Œº < 1 or Œª < Œº, i.e. if the intensity of arrivals of clients is strictly less than the
parameter of the exponential distribution of service times.
7.7
M/M/n Queueing Systems
We Ô¨Ånally consider M/M/n queueing systems with n ‚â•2, i.e. with a Ô¨Ånite number
of servers larger than 1. From considerations similar to those developed for the
other cases we obtain the following system of equations for transition probabilities
Œº‚Ä≤
s(t) = p¬Øs,s(t), where ¬Øs is some Ô¨Åxed state:
‚éß
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é©
Œº‚Ä≤
0(t) = ŒºŒº1(t) ‚àíŒªŒº0(t)
Œº‚Ä≤
1(t) = ‚àí(Œª + Œº) Œº1(t) + Œª Œº0(t) + 2Œº Œº2(t)
¬∑ ¬∑ ¬∑
Œº‚Ä≤
n‚àí1(t) = ‚àí(Œª + (n ‚àí1)Œº) Œºn‚àí1(t) + Œª Œºn‚àí1(t) + nŒº Œºn(t)
Œº‚Ä≤
n(t) = ‚àí(Œª + nŒº) Œºn(t) + Œª Œºn‚àí1(t) + nŒº Œºn+1(t)
Œº‚Ä≤
n+1(t) = ‚àí(Œª + nŒº) Œºn+1(t) + Œª Œºn(t) + nŒº Œºn+2(t)
. . . ,

7.7
M/M/n Queueing Systems
99
Œª
Œº
Œº
Œª
Œª
Œº
0
1
2
3
Œª
Œº
2Œº
Œª
Œª
3Œº
n
n+2
n+1
n‚àí1
n
n
n
Fig. 7.4 Scheme of a M/M/n queueing system with initial state in 0
where Œª and Œº are, as in previous cases, respectively the parameter of the Poisson
process ruling the arrival of clients and of the exponential distribution of service
times. The system is graphically represented in Fig.7.4.
Let us now look for the stationary distribution by imposing Œº‚Ä≤
i(t) = 0 for all
i ‚ààN. If we denote pi ‚â°Œºi(t), we obtain the following system of linear equations:
‚éß
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é©
0 = Œºp1 ‚àíŒªp0
0 = 2Œºp2 ‚àíŒªp1
¬∑ ¬∑ ¬∑
0 = (n ‚àí1)Œºpn‚àí1 ‚àíŒªpn‚àí2
0 = nŒºpn ‚àíŒªpn‚àí1
0 = nŒºpn+1 ‚àíŒªpn
¬∑ ¬∑ ¬∑
+‚àû

i=0
pi = 1 .
We obtain the following recursive equations:
pi = Œª
iŒº pi‚àí1
for i = 1, . . . , n;
pi = Œª
nŒº pi‚àí1
for i ‚â•n + 1.
Therefore we have:
pi =
Œª
Œº
i 1
i! p0
for i = 0, . . . , n,
pi =
Œª
Œº
i
1
n!ni‚àín p0
for i ‚â•n + 1.
A solution of the system exists if
n‚àí1

i=0
Œª
Œº
i 1
i! +
‚àû

i=n
Œª
Œº
i
1
n!ni‚àín < +‚àû.

100
7
Continuous Time Markov Chains
The Ô¨Årst term on the left-hand side is a Ô¨Ånite sum. The series of the second term can
be rewritten by putting j = i ‚àín as
1
n!
Œª
Œº
n
‚àû

j=0
 Œª
nŒº
 j
.
The condition of convergence is therefore Œª
nŒº < 1, i.e. Œª < nŒº. This result answers
the problem of how many servers are needed for a queueing system with some Ô¨Åxed
Poisson Ô¨Çow of incoming clients so that the queue stabilizes (so that a stationary
distribution exists). For Œª < nŒº we have:
p0 =
n‚àí1

i=0
Œª
Œº
i 1
i! + 1
n!
Œª
Œº
n
1
1 ‚àíŒª
nŒº
‚àí1
(7.3)
pi =
Œª
Œº
i 1
i! p0
for i = 1, . . . , n,
(7.4)
pi =
Œª
Œº
i
1
n!ni‚àín p0
for i ‚â•n + 1.
(7.5)
7.8
Queueing Systems in Stationary Regime and Little‚Äôs
Formulas
For Markov queueing systems introduced in the previous sections the existence of
an invariant distribution allows us to consider a stationary regime for the process X
representing the number of clients present in the system. In the stationary regime
probabilistic characteristics of the process don‚Äôt vary in time. The stationary regime
is obtained by taking as initial distribution the stationary distribution.
It can be shown that, when a stationary distribution exists, these queueing systems
evolve towards stationary regime and moreover temporal averages of observables
tend, as the length of the temporal interval tends to inÔ¨Ånity, to the expectations of
the observables computed in stationary regime. All this should be precisely stated
and supported with proofs. We limit ourselves to accept it and to reason at intuitive
level. We now consider some quantities or observables, which are relevant for the
study of queueing systems and their efÔ¨Åciency, and establish some useful relations.
From now on we shall always refer to queueing systems in stationary regime.
In order to evaluate the efÔ¨Åciency of a queueing system, we introduce the utiliza-
tion factor œÅ. This quantity is deÔ¨Åned as the client‚Äôs average arrival rate Œª times the
average service time ¬ØT divided by the number m of servers. It can be shown that the
utilization factor is equal to the average percentage rate of utilization of servers. For
a non-deterministic system in stationary regime it is known that œÅ < 1, see also [12],

7.8 Queueing Systems in Stationary Regime and Little‚Äôs Formulas
101
i.e. that with probability one servers do not work full time. A server will be free for
a positive percentage of time. Other interesting quantities are:
1. the average number L of clients present in the system;
2. the average number Lq of clients waiting in queues;
3. the average time W that a client spends in the system;
4. the average time Wq that a client spends waiting in queues.
The last two quantities are related by the equation
W = Wq + ¬ØT ,
where ¬ØT is the equation of service time.
Let us assume that every client pays an amount equal to the time he spends in the
system. In a time interval of length t the expectation of the amount paid by clients is
given, apart from quantities of order smaller than t, by Œªt (expectation of the number
of clients entering the system in a time interval of length t) times W (expectation
of the time a client spends in the system). Alternatively the same quantity is given
by Lt. By equating the expressions and letting t tend to inÔ¨Ånity, we get Ô¨Årst Little‚Äôs
formula L = ŒªW.
Analogously if we assume that a client pays an amount equal to the time he spends
in queue, we get the second Little‚Äôs formula Lq = ŒªWq.
Little‚Äôs formulas apply to a large class of queueing systems in stationary regime.
Let us consider the case of M/M/1 queueing system. As we have seen, this system
has an invariant distribution if and only if Œª < Œº, where Œª is the parameter of Poisson
process of incoming clients and Œº is the parameter of the exponential distribution of
service time. In this case the stationary distribution for the number of clients present
in the system is given by:
œÅk =
Œª
Œº
k 
1 ‚àíŒª
Œº

.
We have therefore
L =
‚àû

k=1
kœÅk =
‚àû

k=1
k
Œª
Œº
k 
1 ‚àíŒª
Œº

=
Œª
Œº ‚àíŒª
and
Lq =
‚àû

k=2
(k ‚àí1)œÅk =
‚àû

k=1
(k ‚àí1)
Œª
Œº
k 
1 ‚àíŒª
Œº

=
Œª2
Œº(Œº ‚àíŒª) .
Therefore by using Little‚Äôs formulas we have:
W =
1
Œº ‚àíŒª,
Wq =
Œª
Œº(Œº ‚àíŒª) ,

102
7
Continuous Time Markov Chains
that satisfy the equation W = Wc + ¬ØT , where ¬ØT = 1
Œº (expectation of exponential
distribution with parameter Œº).
In this case the utilization factor is Œª
Œº. We observe that, as œÅ tends to 1, the average
number of clients present in the system and waiting in queue, as well as the average
time spent by a client in the system, all tend to inÔ¨Ånity. This is a general characteristics
of random queueing systems. If one tries to increase utilization factor, one has to pay
the price of an increase of the number of clients in queue and of their typical waiting
times. Value 1 for the utilization factor is not reachable by a random queueing system
in stationary regime, but it can be obtained by a deterministic system with one server
where clients arrive at regular time intervals equal to the service time.

Chapter 8
Statistics
We now introduce some basic notions in Bayesian statistics. For further reading, we
refer to [5, 9, 10].
8.1
Bayesian Statistics
Assume that we know the value xi of some characteristics, for example the height for
every individual i of a population i = 1, . . . , N. We can then build up a cumulative
distribution function F(x) deÔ¨Åned by
F(x) = ‚ôØ{i| xi ‚â§x}
N
.
F(x) can be interpreted as the c.d.f. of a random number X, where X is the height of
an individual randomly chosen from the population (every individual is chosen with
equal probability 1
N ). Some relevant quantities can be extracted from F(x), such as
the expectation, the variance, the median and others.
F(x) (called empirical c.d.f.) will always be of discrete type, but for large N it is
possible that it is well approximated by an absolutely continuous c.d.f. Similarly for
two quantities xi, yi for example height and weight relative to each individual, we
can obtain the joint c.d.f. F(x, y) deÔ¨Åned by
F(x, y) = ‚ôØ{i| xi ‚â§x, yi ‚â§y}
N
.
F(x, y) is the joint c.d.f. of the random vector (X, Y), where X and Y are respectively
the height and the weight of a randomly chosen individual in the population. Also
in this case relevant indices such as covariance, correlation coefÔ¨Åcient, etc. can be
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_8
103

104
8
Statistics
extracted from F(x, y). The study of empirical c.d.f.‚Äôs is part of descriptive statistics
and is obviously related to the study of probability distributions.
Often the data about the entire population we are interested in are not available. In
this case one tries to form an evaluation of the distributions of quantities in the whole
population starting from results obtained by sampling (that is by randomly extracting
a subset of individuals of the population). These methods are part of what is called
statistical inference or statistical induction, in the Bayesian approach, that we shall
follow in this chapter. They are an application of Bayes‚Äô Formula and therefore are
part of Probability Theory. We deal here just with a few relevant examples in which
a model based on some distribution is assumed to be Ô¨Åxed and one makes inference
on one or a certain number of unknown parameters, that in Bayesian approach are
treated as random numbers.
8.2
Conditional Density for Two Random Numbers
We now introduce the conditional density of a random number Y given another
random number X. Let f (x, y) be the joint probability density function of (X, Y)
and fX, fY the probability density functions of X, Y, respectively. The conditional
probability of the event (a ‚â§Y ‚â§b) given (x ‚àíh ‚â§X ‚â§x + h) is then given by
P(a ‚â§Y ‚â§b| x ‚àíh < X < x + h) =
 x+h
x‚àíh
 b
a f (s, t)dsdt
P(x ‚àíh < X < x + h).
In order to give a meaning to the conditional probability given (X = x), we let h
tend to 0. Assume that f (x, y) satisÔ¨Åes the following conditions:
1. f (x, y) is continuous;
2. fX(x) is continuous.
Then it is easy to see that if fX(x) > 0
lim
h‚Üí0 P(a ‚â§Y ‚â§b| x ‚àíh < X < x + h) =
 b
a
f (x, t)
fX(x) dt.
Previous argument justiÔ¨Åes the deÔ¨Ånition of conditional density fX(y|x) of Y given
X = x under the condition fX(x) > 0 as given by
fY|X(y|x) = f (x, y)
fX(x)
We obtain then Bayes‚Äô formula for densities. From
f (x, y) = fY|X(y|x) fX(x)

8.2 Conditional Density for Two Random Numbers
105
and
f (x, y) = fX|Y(x|y) fY(y),
we get
fY|X(y|x) = fY(y) fX|Y(x|y)
fX(x)
.
These formulas generalize to the n-dimensional case. Let X1, . . . , Xn be random
numberswithjointprobabilitydensity f (x1, . . . , xn).Let{i1, . . . , ik}beapropersub-
set of {1, . . . , n} and assume that the marginal density function fi1,...,ik(xi1, . . . , xik)
of Xi1, . . . , Xik is strictly positive at the point (xi1, . . . , xik). Let { j1, . . . , jn‚àík} =
{1, . . . , n}\{i1, . . . , ik}. Then the conditional density of X j1, . . . , Xn‚àík given (Xi1 =
xi1, . . . , Xik = xik), provided that fi1,...,xik (xi1, . . . , xik) > 0, is deÔ¨Åned by
f j1,..., jn‚àík|i1,...,ik(x j1, . . . , x jn‚àík|xi1, . . . , xik)
=
f (x1, . . . , xn)
fi1,...,ik(xi1, . . . , xik).
As in the two-dimensional case we get Bayes‚Äô formula for densities
f j1,..., jn‚àík|i1,...,ik(x j1, . . . , x jn‚àík|xi1, . . . , xik)
= fi1,...,ik| j1,..., jn‚àít(xi1, . . . , xik|x j1, . . . , x jn‚àík) f j1,..., jn‚àík(x j1, . . . , x jn‚àík)
fi1,...,ik(xi1, . . . , xik)
This formula is applied to statistical inference in the Bayesian approach that will be
treated in following sections.
8.3
Statistical Induction on Bernoulli Distribution
Let us consider a sequence of events (Ei)i=1,2,... stochastically independent condi-
tionally on the knowledge of a parameter Œò such that
P(Ei = 1|Œò = Œ∏) = Œ∏
where 0 < Œ∏ < 1.
The events Ei can be thought of as the result of experiments; their stochastic
independence conditionally on the knowledge of the value of Œò means that
P(E1 = œµ1, . . . , En = œµn|Œò = Œ∏) =
n
i=1
P(Ei = œµi|Œò = Œ∏)
for any œµi ‚àà{0, 1} for i = 1, . . . , n.

106
8
Statistics
Let Œò have an a priori probability density. We want to Ô¨Ånd out how the distribution
of Œò changes after n experiments are performed. Assume that the results are E1 =
œµ1, . . . , En = œµn. The conditional density of Œò given E1 = œµ1, . . . , En = œµn is
denoted by
œÄn(Œ∏|E1 = œµ1, . . . , En = œµn)
and it is called a posteriori density. By the composite probability law we have, given
0 ‚â§a < b ‚â§1 that
P(Œ∏ ‚àà[a, b]|E1 = œµ1, . . . , En = œµn) = P(Œ∏ ‚àà[a, b], E1 = œµ1, . . . , En = œµn)
P(E1 = œµ1, . . . , En = œµn)
.
(8.1)
By using the formula of total probabilities, that can be easily extended to this
continuous case, and the conditional independence of E1, . . . , En given Œò = Œ∏ we
can rewrite the right-hand side of (8.1) as
 b
a Œ∏œµ1+¬∑¬∑¬∑+œµn (1 ‚àíŒ∏)n‚àí(œµ1+¬∑¬∑¬∑+œµn) œÄ0(Œ∏)dŒ∏
 1
0 Œ∏œµ1+¬∑¬∑¬∑+œµn (1 ‚àíŒ∏)n‚àí(œµ1+¬∑¬∑¬∑+œµn) œÄ0(Œ∏)dŒ∏
.
Therefore we have
œÄn(Œ∏|E1 = œµ1, . . . , En = œµn)
= 1
c œÄ0(Œ∏)Œ∏œµ1+¬∑¬∑¬∑+œµn (1 ‚àíŒ∏)n‚àíœµ1‚àí¬∑¬∑¬∑‚àíœµn
for 0 ‚â§Œ∏ ‚â§1 where
c = P(E1 = œµ1, . . . , En = œµn) =
 1
0
Œ∏œµ1+¬∑¬∑¬∑+œµn (1 ‚àíŒ∏)n‚àíœµ1‚àí¬∑¬∑¬∑‚àíœµn œÄ0(Œ∏) d(Œ∏).
In particular, if a priori distribution of Œò is beta B(Œ±, Œ≤) with parameters Œ± and Œ≤,
the a posteriori distribution will also be beta B(Œ±‚Ä≤, Œ≤‚Ä≤) with parameters
Œ±‚Ä≤ = Œ± +
n

i=1
œµi
and
Œ≤‚Ä≤ = Œ≤ + n ‚àí
n

i=1
œµi
where n
i=1 œµi and n ‚àín
i=1 œµi are respectively the number of events that have and
have not taken place. Therefore
œÄn(Œ∏|E1 = œµ1, . . . , En = œµn) =
‚éß
‚é®
‚é©
Œì (Œ±‚Ä≤+Œ≤‚Ä≤)
Œì (Œ±‚Ä≤) Œì (Œ≤‚Ä≤) Œ∏ Œ±‚Ä≤‚àí1 (1 ‚àíŒ∏)Œ≤‚Ä≤‚àí1 Œ∏ ‚àà[0, 1],
0
otherwise.

8.4 Statistical Induction on Expectation of Normal Distribution
107
8.4
Statistical Induction on Expectation of Normal
Distribution
Let (Xi)i = 1,2,... be a sequence of random numbers that are stochastically independent
given the knowledge of a parameter Œò with conditional probability density
f (x|Œ∏) =
1
œÉ
‚àö
2œÄ
exp

‚àí(x ‚àíŒ∏)2
2œÉ2

for some œÉ > 0.
By using Bayes‚Äô formula for densities on X1, . . . , Xn, Œò we get an expression for
the a posteriori density of Œò, i.e. the conditional density given X1 = x1, . . . , Xn =
xn:
œÄn(Œ∏|x1, . . . , xn) = œÄ0(Œ∏) n
i = 1 f (xi|Œ∏) pn(x1, . . . , xn)
= K œÄ0(Œ∏)
n
i = 1
f (xi|Œ∏),
where pn(x1, . . . , xn) is the marginal density of X1, . . . , Xn and we have denoted by a
constant K the quantity pn(x1, . . . , xn)‚àí1, since it does not depend on Œ∏ and can there-
fore thought of as a normalizing constant for the probability density œÄn(Œ∏|x1, . . . , xn).
In the future we shall denote any normalization constant by K, even if its value
changes from one formula to the other, in order not to introduce too many constants.
If the a priori distribution of Œò is Gaussian N(Œº0, œÉ2
0), we obtain
œÄn(Œ∏|x1, . . . , xn) :=
= KœÄ0(Œ∏)
n
i=1
f (xi|Œ∏)
= Ke
‚àí(Œ∏ ‚àíŒº0)2
2œÉ2
0
exp

‚àí
n

i=1
(xi ‚àíŒ∏)2
2œÉ2

= K exp

‚àí1
2

 1
œÉ2
0
+ n
œÉ2

Œ∏2 ‚àí2Œ∏

Œº0
œÉ2
0
+
n
i=1 xi
œÉ2
 
= K exp

‚àí1
2
(Œ∏ ‚àímn)2
œÉ2n

,
where

108
8
Statistics
mn =
Œº0
œÉ2
0
+
n
i=1 xi
œÉ2
1
œÉ2
0
+ n
œÉ2
,
œÉ2
n =

 1
œÉ2
0
+ n
œÉ2
‚àí1
and K is the normalizing constant. If ¬Øx denotes the sample average ¬Øx = x1+¬∑¬∑¬∑+xn
n
,
the a posteriori distribution of Œò is Gaussian
N

Œº0œÉ‚àí2
0
+ ¬ØxnœÉ‚àí2
œÉ‚àí2
0
+ nœÉ‚àí2
,
1
œÉ‚àí2
0
+ nœÉ‚àí2

.
The expectation can be thought of as a weighted average of Œº0 and ¬Øx with weights
œÉ‚àí2
0
and nœÉ‚àí2.
8.5
Statistical Induction on Variance of Normal
Distribution
We consider now statistical induction on the variance of normal distribution. It is
convenient to use as parameter the inverse of the variance, called precision; it is
clear that precision carries the same amount of information as the variance. The
term precision is related to the interpretation of random numbers as measurements
of some quantity. Let (Xn)n=1,2,... be a sequence of random numbers stochastically
independent conditionally on the knowledge of the value of the parameter Œ¶.
Assume that the conditional probability density of each of the Xi, given that
(Œ¶ = œÜ), is equal to
f (x|œÜ) = f (xi|œÜ) =
œÜ
1
2
‚àö
2œÄ
exp

‚àíœÜ
2 (x ‚àíŒº)2

,
where Œº is some constant. The conditional density of X1, . . . , Xn given (Œ¶ = œÜ)
called the likelihood factor is given by
n
i=1
f (xi|œÜ) = KœÜ
n
2 exp

‚àíœÜ
2
n

i=1
(xi ‚àíŒº)2

= KœÜ
n
2 exp

‚àínS2œÜ
2

,
where
S2 :=
n
i=1(xi ‚àíŒº)2
n

8.5 Statistical Induction on Variance of Normal Distribution
109
is the average of the squares of the deviations of the xi‚Äôs from Œº. If we assume that
the a priori distribution of Œ¶ is Œì (Œ±0, Œª0), then the a posteriori density of Œ¶, given
that X1 = x1, . . . , Xn = xn, is given by:
œÄn(œÜ|x1, . . . , xn) = KœÜ
n
2 +Œ±0‚àí1 exp

‚àíœÜ(Œª0 + nS2
2 )

for œÜ > 0 and 0 otherwise. That is the a posteriori distribution of Œ¶ is gamma
Œì (Œ±0 + n
2, Œª0 + nS2
2 ).
8.6
Improper Distributions
Let us go back to the induction on the expectation of normal distribution. We want
to describe a vague initial state of information. This can be achieved by choosing an
a priori distribution with large variance. We can let the variance tend to inÔ¨Ånity. In
the limit we do not get a probability distribution.
Nonetheless we observe that the corresponding a posteriori distributions converge.
The limiting a posteriori distribution can be alternatively obtained by introducing as
a priori distribution the so called uniform improper distribution density œÄ0(Œ∏) = K.
This œÄ0 does not correspond to a probability distribution, but it must be interpreted
in terms of the limiting procedure we have just described.
8.7
Statistical Induction on Expectation and Variance
of Normal Distribution
Let us now consider the case of statistical induction on both expectation and variance
of a normal distribution. Assume that we are in a state of vague information, that, as
we have said, can be described by means of an improper distribution. We have now
two unknown parameters Œò and Œ¶, respectively the expectation and the precision,
that is the inverse of the variance. Since Œ¶ can take only positive values, we con-
sider as a priori distribution an improper uniform distribution for Œò and log Œ¶. This
corresponds to the improper density:
œÄ0(Œ∏, œÜ) = KœÜ‚àí1,
(œÜ > 0).
Assume that we have a sequence of random numbers that are stochastically indepen-
dent conditionally on the event that Œò and Œ¶ take some deÔ¨Ånite values Œ∏ and œÜ and
that their conditional density is:
f (x|Œ∏, œÜ) =
1
‚àö
2œÄ
œÜ
1
2 exp

‚àíœÜ
2 (x ‚àíŒ∏)2

.

110
8
Statistics
The conditional joint density of X1, . . . , Xn, given Œò = Œ∏, Œ¶ = œÜ, which is called
likelihood factor, is then
f (x1, . . . , xn|Œ∏, œÜ) = KœÜ
n
2 exp

‚àíœÜ
2
n

i=1
(xi ‚àíŒ∏)2

= KœÜ
n
2 exp

‚àíœÜ
2

(¬Øx ‚àíŒ∏)2 + ŒΩs2
,
where ¬Øx =
n
i=1 xi
n
, ŒΩ = n ‚àí1, s2 =
n
i=1(xi ‚àí¬Øx)2
ŒΩ
. The joint a posteriori density
of Œò, Œ¶ is obtained by Bayes‚Äô formula for densities and is given by:
œÄn(Œ∏, œÜ|x1, . . . , xn) = KœÜ
n
2 ‚àí1 exp

‚àíœÜ
2

(¬Øx ‚àíŒ∏)2 + ŒΩs2
.
From joint a posteriori probability density of Œò and Œ¶ we can get their marginal
densities by integrating with respect to the other variable. The integral with respect
to œÜ reduces to the integral of the gamma function. After collecting in the constant
K all factors that do not depend on Œ∏, we obtain
œÄn(Œ∏|x1, . . . , xn) =
 +‚àû
0
œÄn(Œ∏, œÜ|x1, . . . , xn)dœÜ =
K

(¬Øx ‚àíŒ∏)2 + ŒΩs2.
From this it follows that the random number T = ¬Øx ‚àíŒ∏
s‚àöŒΩ has Student t density with
ŒΩ degrees of freedom
fT (t) = K

1 + t2
ŒΩ
‚àíŒΩ + 1
2
.
Analogously we obtain the a posteriori density of Œ¶ by integrating the conditional
density œÄn(Œ∏, œÜ|x1, . . . , xn) with respect to Œ∏. It is a Gaussian integral that, apart from
constant factors, gives a factor œÜ‚àí1
2 . The a posteriori marginal probability density of
Œ¶ is
œÄn(œÜ|x1, . . . , xn) =
 +‚àû
0
œÄn(Œ∏, œÜ|x1, . . . , xn)dŒ∏ = KœÜ
ŒΩ
2 ‚àí1 exp

‚àíŒΩs2œÜ
2

,
with œÜ > 0. By making a linear change of variable we see that the random number
ŒΩs2Œ¶ has a posteriori distribution with density
Ku
ŒΩ
2 ‚àí1 exp

‚àíu
2

,
with u > 0, i.e. is œá2-distribution with ŒΩ degrees of freedom. The normalizing
constant is therefore given by K =
1
2
ŒΩ
2 Œì ( ŒΩ
2).

8.8 Bayesian ConÔ¨Ådence Intervals and Hypotheses‚Äô Testing
111
8.8
Bayesian ConÔ¨Ådence Intervals and Hypotheses‚Äô Testing
A synthetic description of a posteriori distribution can be achieved by means of
conÔ¨Ådence intervals or, in the multidimensional case, conÔ¨Ådence regions. Given
0 < Œ± < 1, an Œ±-level conÔ¨Ådence interval or conÔ¨Ådence region is an interval
or respectively a region whose a posteriori probability is 1 ‚àíŒ±. The choice of an
interval or a region with this property is clearly arbitrary. In concrete situations one
can base the choice on symmetry criteria if the a posteriori density is symmetric or
alternatively one can choose the region with minimal volume in parameters‚Äô space.
In the Bayesian approach to statistics, hypotheses‚Äô testing can be related to the
deÔ¨Ånitions of conÔ¨Ådence intervals or regions. The hypotheses that parameters have
a given value is rejected if the value does not belong to the conÔ¨Ådence interval or
region. This procedure, it must be stressed, is arbitrary, since, as we have said, the
interval or region can be arbitrarily chosen. Nevertheless, since in many situations
there is a preferential choice, the use of hypotheses‚Äô testing in Bayesian approach
can be accepted as a shortened and less precise form of induction with respect to the
complete analysis based on a posteriori distribution.
8.9
Comparison of Expectations for Normal Distribution
Assume that we have two samples of size respectively n1 and n2 that, conditionally
on the knowledge that the parameters Œò1 and Œò2 are equal respectively to Œ∏1 and
Œ∏2, are stochastically independent samples with Gaussian distribution N(Œ∏1, œÉ2
1) and
N(Œ∏2, œÉ2
2) respectively. If the a priori density of Œò1 and Œò2 is uniform improper,
Œò1 and Œò2 are stochastically independent a posteriori with Gaussian distribution
N(¬Øx1, œÉ2
1
n ) and N(¬Øx2, œÉ2
2
n ) respectively, where ¬Øx1, ¬Øx2 are the sample averages of the
samples.
Indeed, since the samples are stochastically independent and Œò1 and Œò2 are sto-
chastically independent in the a priori distribution, we can separately apply to the
samples the results on the induction on the expectation of normal distribution in the
case of uniform improper a priori distribution. If we deÔ¨Åne Œò = Œò2 ‚àíŒò1, then the
a posteriori distribution of Œò is in N(¬Øx2 ‚àí¬Øx1, œÉ2
2
n2
+ œÉ2
1
n1
).
Let us now consider the case when there is an extra parameter Œ¶ such that con-
ditionally on the knowledge that Œ¶ = œÜ and Œò1 = Œ∏1, Œò2 = Œ∏2, the two sam-
ples are stochastically independent with distributions respectively N(Œ∏1, œÜ‚àí1) and
N(Œ∏2, œÜ‚àí1). The conditional probability densities of the random numbers of the Ô¨Årst
and the second sample are then respectively

112
8
Statistics
f1(x|Œ∏1, Œ∏2, œÜ) =
1
‚àö
2œÄ
œÜ
1
2 exp

‚àíœÜ
2 (x ‚àíŒ∏1)2

,
f2(x|Œ∏1, Œ∏2, œÜ) =
1
‚àö
2œÄ
œÜ
1
2 exp

‚àíœÜ
2 (x ‚àíŒ∏2)2

.
Also here we consider the case of improper a priori distribution and precisely we
assume that Œò1, Œò2, log Œ¶ are stochastically independent with uniform improper
distribution on R. This corresponds for Œò1, Œò2, Œ¶ to an a priori improper density
œÄ0(Œ∏1, Œ∏2, œÜ) = KœÜ‚àí1
(œÜ > 0).
Consider Ô¨Årst statistical induction for Œ¶. Here we can apply without any essential
change what we have seen about the induction for normal distributions with two
unknown parameters and obtain that the a posteriori density of Œ¶ is given by:
KœÜ
ŒΩ1+ŒΩ2
2
‚àí1 exp

‚àís2œÜ
2

,
where s2 = ŒΩ1s2
1 + ŒΩ2s2
1 with ŒΩi = ni ‚àí1, i = 1, 2,
s2
i =
ni
j=1(xi, j ‚àí¬Øxi)2
vi
,
and xi, j is the j-th value of the i-th sample. By combining these results we can obtain
the a posteriori probability density of Œò = Œò2 ‚àíŒò1 in the case when Œ¶ is unknown.
Indeed we have:
œÄ(Œ∏|x1, x2) = K

R+ œÜ
1
2 exp
‚éõ
‚éù‚àí
œÜ
2

1
n1 + 1
n2
 (Œ∏ ‚àí(¬Øx2 ‚àí¬Øx1))2
‚éû
‚é†œÜ
ŒΩ1 + ŒΩ2
2
‚àí1 exp

‚àís2œÜ
2

dœÜ
= K2
ŒΩ1 + ŒΩ2 + 1
2
‚é°
‚é£(Œ∏ ‚àí(¬Øx2 ‚àí¬Øx1))2

1
n1 +
1
n2

+ s2
‚é§
‚é¶
‚àíŒΩ1 + ŒΩ2 + 1
2

R+ y
ŒΩ1 + ŒΩ2 + 1
2
‚àí1e‚àíydy
= K2
ŒΩ1 + ŒΩ2 + 1
2
Œì (ŒΩ1 + ŒΩ2 + 1
2
)
‚é°
‚é£(Œ∏ ‚àí(¬Øx2 ‚àí¬Øx1))2

1
n1 + 1
n2

+ s2
‚é§
‚é¶
‚àíŒΩ1 + ŒΩ2 + 1
2
,
= K(2/s2)
ŒΩ1+ŒΩ2+1
2
Œì (ŒΩ1 + ŒΩ2 + 1
2
)
‚é°
‚é£(Œ∏ ‚àí(¬Øx2 ‚àí¬Øx1))2
s2

1
n1 + 1
n2

+ 1
‚é§
‚é¶
‚àíŒΩ1 + ŒΩ2+1
2

8.9 Comparison of Expectations for Normal Distribution
113
where we have used the change of variable y = 1
2

(Œ∏‚àí(¬Øx2‚àí¬Øx1))2

1
n1 + 1
n2

+ s2

œÜ to express
the integral in terms of a Gamma function. We obtain
œÄ(Œ∏|¬Øx1, ¬Øx2) = K
‚é°
‚é£(Œ∏ ‚àí(¬Øx2 ‚àí¬Øx1))2
ŒΩs2

1
n1 + 1
n2
 + 1
‚é§
‚é¶
‚àíŒΩ + 1
2
,
where ŒΩ = ŒΩ1 + ŒΩ2 and K is now a suitable normalization constant. If we deÔ¨Åne
T = Œ∏ ‚àí(¬Øx2 ‚àí¬Øx1)
s

1
n1 + 1
n2
 1
2 ,
we see that the a posteriori distribution of T is Student with ŒΩ = ŒΩ1 + ŒΩ2 degrees
of freedom. This allows us to use Student distribution‚Äôs table to obtain conÔ¨Ådence
intervals for Œò.

Part II
Exercises

Chapter 9
Combinatorics
Exercise 9.1 The game of bridge is played with 52 cards. Compute:
1. The number of different ways a player can receive an handful of 13 cards.
2. The number of different ways the cards can be distributed among 4 players.
3. The number of different ways a player can receive an handful of 13 cards all
different in values. Which is the number of different ways in which all 4 players
receive cards all different in values?
4. The number of different ways a player can receive Ô¨Çush number cards of the same
sign. In how many ways can a player obtain at least 2 cards with equal value?
Solution 9.1
1. The number of different ways a player can receive an handful of
13 cards is given by the simple combinations
52
13

.
Namely one has to choose 13 elements out of 52 without repetitions and without
taking in account of the order.
2. For the Ô¨Årst player we have already computed the number of different ways she
can receive an handful of 13 cards. For the second player we can choose 13 cards
out of the 52 ‚àí13 = 39 remaining ones. Analogously for the third player. The
fourth player receives the remaining 13 cards. The number of different ways in
which all 4 players receive cards all different in values is then
 52
13
 39
13
 26
13
 13
13

=
52!
(13!)4 .
The multinomial coefÔ¨Åcient counts the number of ways of making 4 groups of
13 elements each out of a set of 52 cards.
3. Since the cards are all different in values, we can think that they are in increasing
order. For the Ô¨Årst card, we can choose one of the four aces. For the second one,
one of the 4 twos, and so on. The number of different ways a player can receive
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_9
117

118
9
Combinatorics
an handful of 13 cards all different in values is then in
4 ¬∑ 4 ¬∑ ¬∑ ¬∑ ¬∑ ¬∑ 4



13 times
= 413
different ways. If we consider all 4 players, we have that for the second player
the choices for each card will reduce to
3 ¬∑ 3 ¬∑ ¬∑ ¬∑ ¬∑ ¬∑ 3



13 times
= 313
different ways. Then the 4 players receive cards all different in values in
413 ¬∑ 313 ¬∑ 213 ¬∑ 113 = (4!)13
different ways.
4. A player can receive Ô¨Çush number cards of the same sign in 4 different ways,
since there exist Ô¨Çush number cards of 4 different signs. If we consider 4 players,
the number of ways of assigning them Ô¨Çush number cards of the same sign is
given by the number of permutations of the 4 signs, i.e.
4 ¬∑ 3 ¬∑ 2 ¬∑ 1 = 4!.
The number of ways in which a player can obtain at least 2 cards with equal
value is equal to
52
13

‚àí413
that is the number of all possible choices minus the number of ways of obtaining
an handful of all different cards.
‚äì‚äî
Exercise 9.2 At the ticket counter of a theatre there are available tickets with num-
bers from 1 to 100. The tickets are randomly distributed among the buyers. Four
friends A, B, C, D buy separately a ticket each.
1. Which is the probability that they have received the tickets with numbers
31, 32, 33 and 34?
2. Which is the probability that they have received the tickets 31, 32, 33 and 34 in
this order?
3. Which is the probability that they have received tickets with 4 consecutive num-
bers?
4. Which is the probability that A, B, C receive tickets with a number greater than
50?

9
Combinatorics
119
Solution 9.2
1. To compute this probability we use the formula
‚ôØfavorable cases
‚ôØpossible cases .
The possible cases are all the ways of choosing 4 numbers out of 100, i.e.
100
4

.
There exists only 1 favorable case, i.e. to choose the numbers 31, 32, 33 and
34. Hence the probability that the three friends have received the tickets with
numbers 31, 32, 33, 34 is given by
p =
1
100
4
.
2. Here the number of possible cases is given by
D100
4
= 100!
96! .
The probability that the 4 friends receive the tickets 31, 32, 33, 34 in this order
is then
p =
1
D100
4
=
96!
100!.
3. One can obtain tickets with consecutive numbers in
100 ‚àí3 = 97
different ways. We need also to consider the case {97, 98, 99, 100}. The proba-
bility of receiving 4 consecutive tickets is then
97
100
4
 = 97!4!
100! .
4. The probability that A, B and C receive tickets with numbers greater than 50 is
p =
50
100
49
99
48
98.
For the Ô¨Årst case the are 50 favorable cases (all tickets with number from 51
up to 100) out of 100. For the second ticket there are 49 possibilities out of the
99 tickets left. And so on.

120
9
Combinatorics
Exercise 9.3 A credit card PIN consists of 5 numbers. We assume that every
sequence of 5 digits is generated with the same probability. Compute:
1. The probability that the numbers composing the PIN are all different.
2. The probability that the PIN contains at least 2 numbers which are equal.
3. The probability that the numbers composing the PIN are all different if the Ô¨Årst
digit is different from 0.
4. The probability that the PIN contains exactly 2 numbers which are equal, if the
Ô¨Årst digit is different from 0.
Solution 9.3
1. A PIN differs from another one if the digits are in different order.
The possible cases are given by
105.
The favorable cases, when all digits are different, are
D10
5
= 10!
5! .
The probability that the numbers composing the PIN are all different is then
p1 = D10
5
105 .
2. The probability that the PIN contains at least 2 numbers which are equal is
p = 1 ‚àíp1 = 1 ‚àí
10!
5! 105 ,
where p1 is the probability that the numbers composing the PIN are different.
3. In this case the number of possible cases is
9 ¬∑ 10 ¬∑ 10 ¬∑ 10 ¬∑ 10.
For the Ô¨Årst digit we have 9 possibilities (all numbers from 1 to 9). We need to
choose the remaining digits without repetitions and taking in account the order:
we have D9
4 ways. The number of favorable cases is then
9 ¬∑ 9 ¬∑ 8 ¬∑ 7 ¬∑ 6 = 9 ¬∑ D9
4.
The probability that the numbers composing the PIN are all different if the Ô¨Årst
digit is different from 0 is then
9 ¬∑ D9
4
9 ¬∑ 104 = D9
4
104 .

9
Combinatorics
121
4. The possible cases are still given by
9 ¬∑ 104.
In order to compute the number of ways in which the PIN contains exactly 2
numbers which are equal, if the Ô¨Årst digit is different from 0, we can proceed as
follows:
(a) For the digit that is repeated: without loss of generality we can think that
it is equal to the Ô¨Årst digit in the string. There are 9 ways of choosing it
(remember: the 0 is now excluded).
(b) We choose the place of the repeated digit in the string: there are
4
1

positions where it can be placed.
(c) The other digits must be different from the Ô¨Årst one. They can be placed in
D9
3
different ways in the string.
In total we have
9 ¬∑
 4
1

¬∑ D9
3
possibilities. The procedure illustrated in (a),(b), and (c) will be called in
the sequel the string rule.
(d) If the repeated digit is different from the Ô¨Årst one, we have
‚Ä¢ 9 ways of choosing the Ô¨Årst digit;
‚Ä¢ 9 ways of choosing the repeated digit;
‚Ä¢
 4
2

ways of choosing the place in the string;
‚Ä¢ D8
2 ways of placing the remaining digits.
Totally we have
9 ¬∑ 9 ¬∑ D8
2 ¬∑
 4
2

.
The total number of favorable cases is then
9 ¬∑
4
1

¬∑ D9
3 + 9 ¬∑ 9 ¬∑ D8
2 ¬∑
 4
2

= 9 ¬∑
 4
1

+
 4
2
	
¬∑ D9
3 = 9 ¬∑
 5
2

¬∑ D9
3 ,

122
9
Combinatorics
where we have used the formula
n
r

=
n ‚àí1
r

+
n ‚àí1
r ‚àí1

.
‚äì‚äî
Exercise 9.4 Four fair dice are thrown at the same time. Their faces are numbered
from 1 to 6. Compute:
(a) The probability of obtaining four different faces.
(b) The probability of obtaining at least 2 equal faces.
(c) The probability of obtaining exactly 2 equal faces.
(d) The probability that the sum of the faces is equal to 5.
(e) We throw only 2 dice. Compute the probability that the sum of the faces is an
odd number.
Solution 9.4 (a) To compute the probability we use the formula
p = ‚ôØfavorable cases
‚ôØpossible cases .
(9.1)
The possible cases are given by
possible cases = 6 ¬∑ 6 ¬∑ 6 ¬∑ 6 = 64.
This is given by the number of all possible dispositions of 4 elements out of 6.
The favorable cases are given by the simple dispositions of 4 elements out of 6,
since the faces are required to be different from each other:
favorable cases = 6 ¬∑ 5 ¬∑ 4 ¬∑ 3 = D6
4.
The probability of obtaining four different faces is then
P(all the thrown dies have different faces) = D6
4
64 = 5
18.
(b) The probability of obtaining at least 2 equal faces can be computed by using the
probability obtained above, since:
P(the thrown dice have at least 2 same faces)
= 1 ‚àíP(all the thrown dice have different faces)
= 1 ‚àíD6
4
64 = 13
18.

9
Combinatorics
123
c) Also in this case we use the string rule as in Exercise 9.3. The number of the
ways of obtaining exactly 2 equal faces is then:
 4
2

¬∑ 6 ¬∑ D5
2,
where
 4
2

= ‚ôØways of choosing 2 dice with equal faces,
6 = ‚ôØways of choosing the face which is repeated,
D5
2 = ‚ôØways of choosing the remaining faces.
Recall that the remaining faces must be different among each other and with
respect to the one which is repeated.
(d) In order to have the sum of the faces equal to 5, the only possibility is that 3
faces present the number 1 and one the number 2, since we are dealing with 4
dice. We compute Ô¨Årst the favorable cases. After having chosen the places for
the number 1, it remains only one possibility for the number 2, i.e. we have
4
3

¬∑ 1 = 4
favorablecases.Thepossiblecasesaregivenby64 waysofhavingaconÔ¨Åguration
of 4 dice. Hence the probability that the sum of the faces is equal to 5 is given
by
p = 4
64 .
(e) The sum of the faces is odd if one of the faces presents an odd number and the
other one an even number. Hence
‚ôØfavorable cases =
2
1

¬∑ 3 ¬∑ 3 = 18,
where
2
1

counts the number of ways for a die to come out with an even face.
Hence
P(the sum of the faces is given by an odd number) = 2 ¬∑ 32
62
= 1
2.
More simply, one can consider that the sum of the faces can be either odd or
even. Hence:

124
9
Combinatorics
‚ôØpossible cases = 2
‚ôØfavorable cases = 1,
and consequently
P(the sum of the faces is given by an odd number) = 1
2.
‚äì‚äî
Exercise 9.5 Two factories A and B produce garments for the same trademark Y.
For the factory A, 5% of the garments present some production defect; for the
factory B, 7% of the garments present some production defect. Furthermore 75%
of the garments sold by Y derive from the the factory A, while the remaining 25%
comes from the factory B. We suppose that a garment is chosen randomly with equal
probability among all the garments on sale. Compute:
1. The probability of purchasing a garment of the trademark Y which presents some
production defect.
2. The probability that the garment comes from the factory A, subordinated to the
fact that it presents some production defect.
Solution 9.5 We denote by:
‚Ä¢ with A the event
A = {the garment comes from the factory A};
‚Ä¢ with B the event
B = {the garment comes from the factory B};
‚Ä¢ with D the event
D = {the garment presents some production defect}.
1. The probability of purchasing a garment of the trademark Y which presents some
production defect can be computed with the formula of the total probabilities,
since we do not know whether it comes from factory A or B. Hence
P(D) = P(D|A) P(A) + P(D|B) P(B)
=
5
100
75
100 +
7
100
25
100 = 11
200.

9
Combinatorics
125
2. The probability that the garment comes from the factory A, if it presents some
production defect, is given by:
P(A|D) = P(D|A) P(A)
P(D)
= 15
22.
This subordinated probability has been computed with Bayes‚Äô Formula.
‚äì‚äî
Exercise 9.6 We consider 3 different elementary schools E, M, S. The percentage
of pupils wearing glasses is 10% in the school E, 25% in the school M and 40% in
the school S. Compute:
1. The probability that by choosing randomly 3 pupils, one out of each school, at
least one of them wears glasses.
2. The probability that a pupil wears glasses, if we randomly choose her or him out
of the three schools (each school can be picked up with the same probability).
3. The probability that the pupil belongs to school E, if she wears glasses.
Solution 9.6
1. The quickest method to compute the probability that by choosing
by chance 3 pupils, one out of each school, at least one of them wears glasses, is
to evaluate the probability that none of them wears glasses. If B is the event that
at least one of the 3 pupils wears glasses, then
P(B) = 1 ‚àíP

ÀúB

.
In this case P

ÀúB

= 90
100
75
100
60
100 = 81
200, from which
P(B) = 1 ‚àí81
200 = 119
200.
2. Let O be the event
O = {the pupil wears glasses}.
Theprobabilityof O canbecomputedbyusingtheformulaofthetotalprobability,
since we do not know which school the pupil belongs to. We set
‚Ä¢ E = {the pupil belongs to school E};
‚Ä¢ M = {the pupil belongs to school M};
‚Ä¢ S = {the pupil belongs to school S}.
We then have:
P(O) = P(O|E) P(E) + P(O|M) P(M) + P(O|S) P(S)
= 1
10
1
3 + 1
4
1
3 + 2
5
1
3 = 1
4.

126
9
Combinatorics
Note that we have assumed that each school can be picked up with the same
probability.
3. The probability that the pupil belongs to school E, if she wears glasses, can be
computed by using Bayes‚Äô formula:
P(E|O) = P(O|E) P(E)
P(O)
= 2
15 .
‚äì‚äî

Chapter 10
Discrete Distributions
Exercise 10.1 Two friends A and B are playing with a deck of cards consisting of
52 cards, 13 for each sign. They choose out 2 cards each. Player A starts. In order to
win, the player has to be the Ô¨Årst to extract the ace of spade or 2 cards of diamonds.
After having chosen the 2 cards, they put the 2 cards back in the deck and mix it.
Compute the probability that:
(a) Player A wins after 3 trials (i.e. after each player has done 2 extractions).
(b) Player A wins, player B wins, nobody wins.
(c) Let T be the random number representing the number of the trial, when one of
the player Ô¨Årst wins. Compute the expectation of T .
(d) Which is the probability distribution of T ?
Solution 10.1 (a) The trials of the 2 players can be represented as a sequence of
stochastically independent and equally distributed random trials. The probability
that player A wins after 3 trials (i.e. after each player has done 2 extractions) is
then equal to the probability of Ô¨Årst success after
2 + 2 + 1 = 5
trials. The player A wins if she extracts the ace of spade or 2 cards of diamonds.
The probability of this event is given by
p =
51
52
2
 +
13
2

52
2

(10.1)
where we have used the fact that the events are incompatible and that:
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_10
127

128
10
Discrete Distributions
1. The probability of extracting the ace of spade, is given by
1¬∑
‚éõ
‚éù51
1
‚éû
‚é†
‚éõ
‚éù52
2
‚éû
‚é†
.
2. The probability of extracting 2 cards of diamonds, is given by
‚éõ
‚éù13
2
‚éû
‚é†
‚éõ
‚éù52
2
‚éû
‚é†
.
Let T be the random number representing the Ô¨Årst time of success. The proba-
bility that A wins at the third trial is
P(T = 5) = p(1 ‚àíp)4 ,
where p is given by (10.1).
(b) If A wins, the game stops with an odd trial. The probability that A wins is then
P(A wins) =
‚àû

k=0
P(T = 2k + 1)
=
‚àû

k=0
p(1 ‚àíp)2k = p
1
1 ‚àí(1 ‚àíp)2 .
If B wins, the game stops with an even trial. The probability that B wins is then
P(B wins) =
‚àû

k=1
P(T = 2k)
= p
‚àû

k=1
(1 ‚àíp)2k‚àí1
=
p
1 ‚àíp

1
1 ‚àí(1 ‚àíp)2 ‚àí1

=
p
1 ‚àíp
(1 ‚àíp)2
1 ‚àí(1 ‚àíp)2
=
p(1 ‚àíp)
1 ‚àí(1 ‚àíp)2 = 1 ‚àíp
2 ‚àíp .
The probability that nobody wins is given by

10
Discrete Distributions
129
P(nobody wins) = 1 ‚àíP(A wins) ‚àíP(B wins)
= 1 ‚àí
‚àû

k=0
P(T = 2k + 1) ‚àí
‚àû

k=1
P(T = 2k)
= 1 ‚àí
‚àû

k=1
P(T = k)
= 0 .
(c)‚Äì(d) The random number T that represents the time when the game is decided,
has a geometric distribution of parameter p since it denotes the Ô¨Årst time of
success in a sequence of stochastically independent and identically distrib-
uted trials. Hence the expectation of T is given by:
P(T ) = 1
p =
52
2

1 +
13
2
 .
‚äì‚äî
Exercise 10.2 Let X, Y be two stochastically independent random numbers with
Poisson distribution with parameters Œº and œÉ, respectively.
1. Let Z = X + Y. Compute the expectation and the variance of Z.
2. What is the set I (Z) of possible values for Z?
3. Compute P(Z = i), for i ‚ààI (Z).
4. Compute cov(Z, X,).
5. Let u > 0; compute the generating function œÜZ(u) = P(uZ) of Z.
Solution 10.2
1. By the linearity of the expectation we obtain
P(Z) = P(X + Y) = P(X) + P(Y) = Œº + œÉ .
To compute the variance, we use the formula of the variance of the sum
œÉ2(X + Y) = œÉ2(X) + œÉ2(Y) + 2 cov(X, Y) .
Since X, Y are stochastically independent, we have
cov(X, Y) = 0 .
Hence
œÉ2(X + Y) = œÉ2(X) + œÉ2(Y) = Œº + Œª .

130
10
Discrete Distributions
2. The set I (Z) of possible values for Z is given by
I (Z) = N = {inf(X) + inf(Y), . . . } .
3. We now compute the probability distribution of Z. The event {Z = i} can be
written as
{Z = i} = {X = 0, Y = i} + {X = 1, Y = i ‚àí1} + ¬∑ ¬∑ ¬∑ + {X = i, Y = 0}
=
i
k=0
{X = k, Y = i ‚àík},
since the events {X = k, Y = i ‚àík} are disjoint for k = 0, . . . , i. By the linearity
of the expectation we obtain
P(Z = i) =
i
k=0
P(X = k, Y = i ‚àík) .
Furthermore X, Y are stochastically independent, hence
P(X = k, Y = i ‚àík) = P(X = k) P(Y = i ‚àík),
so that
P(Z = i) =
i
k=0
P(X = k) P(Y = i ‚àík)
=
i
k=0
Œºk
k! e‚àíŒº œÉ(i‚àík)
(i ‚àík)! e‚àíœÉ
= e‚àí(Œº+œÉ)
i!
i
k=0
i!
k! (i ‚àík)! Œºk œÉ(i‚àík)
= (Œº + œÉ)i
i!
e‚àí(Œº+œÉ) ,
where we have used Newton‚Äôs binomial formula. Therefore Z has Poisson distri-
bution with parameter Œº + Œª.
4. In order to compute the covariance between Z and X, we proceed as follows:
cov(Z, X) = P(Z X) ‚àíP(Z) P(X)
= P ((X + Y)X) ‚àí(P(X) + P(Y)) P(X)
= P(X2) + P(XY) ‚àíP(X)2 ‚àíP(Y)P(X)
= œÉ2(X)
= Œº .

10
Discrete Distributions
131
5. For Œº > 0, the generating function of Z is given by
œÜZ(u) = P(uZ) = P(u X+Y) .
Since X, Y are stochastically independent, we have
P(u X+Y) = P(u X ¬∑ uY) = P(u X) ¬∑ P(uY) .
We now compute P(u X) by using the formula for the expectation of a function
of X:
P(u X) =
+‚àû

i=0
uiP(X = i)
= e‚àíŒº
+‚àû

i=0
(uŒº)i
i!
= e(u‚àí1) Œº,
where in the last step we have used the series:
+‚àû

i=0
xi
i! = ex.
It follows that
œÜZ(u) = P(u X) ¬∑ P(uY)
= e(u‚àí1) Œº e(u‚àí1) œÉ
= e(u‚àí1) (Œº+œÉ).
Since the generating function uniquely identiÔ¨Åes the distribution, this proves that
Z has Poisson distribution with the parameter Œº + œÉ.
‚äì‚äî
Exercise 10.3 In a small village with 200 inhabitants, 5 inhabitants are affected by
a particular genetic disease. A sample of 3 individuals is chosen randomly among
the population (all subsets have the same probability of being chosen). Let X be the
number of individuals in the sample who are affected by the disease.
1. Determine the set I (X) of possible values for X.
2. Determine the probability distribution of X.
3. Compute the expectation and the variance of X.

132
10
Discrete Distributions
Solution 10.3
1. The possible values of X are 0, 1, 2 and 3, i.e. the minimum
number of people affected by the disease in the sample is 0 and the maximum
number is 3.
2. Consider the event {X = i}, i ‚ààI (X). To determine the probability distribution
of X, we need to compute
P(X = i),
i ‚ààI (X) .
To this purpose we use the formula
‚ôØfavorable cases
‚ôØpossible cases .
The number of possible cases is given by the number of ways of choosing 3
people out of 200 inhabitants, i.e.
200
3

.
The number of favorable cases is given by the number of ways of choosing i
people out of the group of inhabitants affected by the disease and (3 ‚àíi) people
out of the group of ‚Äòhealthy‚Äô people, i.e.
 5
i
  195
3 ‚àíi

.
We obtain
P(X = i) =
 5
i
  195
3 ‚àíi

 200
3

.
The distribution of X is then hypergeometric.
3. We can compute directly the expectation of X, since I (X) consists only of 4
values:
P(X) =
3

i=0
i P(X = i)
=
1
 200
3


5
195
2

+ 20
195
1

+ 30

= 3
40 .

10
Discrete Distributions
133
For the variance the computations is analogous. It is sufÔ¨Åcient to apply the
formula
œÉ2(X) = P(X2) ‚àíP(X)2
and to compute P(X2) =
3

i=0
i2 P(X = i).
‚äì‚äî
Exercise 10.4 At a horse race there are 10 participants. Gamblers can win if they
correctly predict the Ô¨Årst 3 horses in order of arrival. We suppose that all the orders
have the same probability of occurrence and that the gamblers choose independently
of each other and with the same probability the 3 horses on which to bet.
1. Compute the probability that one of the gamblers wins.
2. If the gamblers are 100 in total, let X be the random numbers counting the number
of gamblers who win. Determine I (X) and P(X = i) for i = 1, 2, 3.
3. Compute expectation and variance of X.
4. Suppose that the gamblers are numbered from 1 to 100. Compute the probability
that there is at least one winner and that the winner with the minimal number has
a number greater or equal to 50.
Solution 10.4
1. The probability that a gambler wins can be computed with
the formula
‚ôØfavorable cases
‚ôØpossible cases .
In this case, the possible cases are given by the simple dispositions of 3 elements
out of 10. They represent the number of ways of assuming the Ô¨Årst 3 positions for
the 10 horses. Only one is the winning triplet, hence the probability of winning
for a gambler is given by
p =
1
D10
3
=
7!
10! =
1
720 .
2. If X is the random numbers counting the number of gamblers who win, we can
write
X = E1 + E2 + ¬∑ ¬∑ ¬∑ + E100,
where the event Ei is veriÔ¨Åed if the i-th gambler wins. The events Ei, i =
1, . . . , 100, are stochastically independent and identically distributed since the
gamblers choose independently of each other and with the same probability the 3
horses on which to bet. Hence X has binomial distribution Bn(n, p) of parameters
n = 100 and p =
1
720. The set of possible values is then

134
10
Discrete Distributions
I (X) = {0, 1, . . . , 100}
and
P(X = i) =
 100
i
  1
720
i 
1 ‚àí
1
720
100‚àíi
.
In particular, we obtain:
i = 1
P(X = 1) = 100 ¬∑
1
720 ¬∑
719
720
99
.
i = 2
P(X = 2) =
100
2
  1
720
2
¬∑
719
720
98
.
i = 3
P(X = 3) =
 100
3
  1
720
3
¬∑
719
720
97
.
3. The expectation of X is given by linearity by
P(X) = P(E1 + ¬∑ ¬∑ ¬∑ + E100)
=
100

i=1
P(Ei) = 100 ¬∑
1
720 = 5
36 .
Analogously by the formula of the variance of the sum of n random numbers, we
have:
œÉ2(X) = œÉ2(E1 + ¬∑ ¬∑ ¬∑ + E100)
=
100

i=1
œÉ2(Ei) +
100

i, j=1
cov(Ei, E j)
	



0
= 100 ¬∑
1
720 ¬∑

1 ‚àí
1
720

.
Here we have used that the events Ei are stochastically independent.
4. In order to have a winner with minimal number greater than or equal to 50, we
need that the Ô¨Årst 49 gamblers do not win and that at least one of the gamblers
with number from 50 to 100 wins. Let E be the event that all the all the gamblers
with number from 1 to 49 lose and F the event that at least one of the gamblers

10
Discrete Distributions
135
with number from 50 to 100 wins. The probability that there is at least one winner
and that the winner with the minimal number has a number greater than or equal
to 50 is then
P(E F) = P(E)P(F) =
719
720
49 
1 ‚àí
719
720
51
,
where P(F) = 1 ‚àíP(F) and F is the event that no gambler with number from
50 to 100 wins.
‚äì‚äî
Exercise 10.5 In an opinion poll 100 people are asked to answer a questionnaire
with 5 questions. Each question can be answered only yes or no. For each person the
probability of all possible answers is the same and their choices are stochastically
independent. Let N be the number of interviewed people that answer yes to the Ô¨Årst
questions or answer yes at least to 4 questions.
1. Which is the probability distribution of N?
2. Compute the expectation, the variance and the generating function of N.
Solution 10.5
1. Let Ei be the event that the i-th interviewed person has answered
yes to the Ô¨Årst questions or yes at least to 4 questions. We can rewrite N as
N = E1 + E2 + ¬∑ ¬∑ ¬∑ + E100 .
The events are stochastically independent and identically distributed since every
person answers independently of the other ones. Furthermore we have assumed
that the probability of all possible answers is the same. It is sufÔ¨Åcient to compute
the probability of each Ei. We put:
‚Ä¢ Fi= {the i-th interviewed person answers yes to the Ô¨Årst question};
‚Ä¢ Gi= {the i-th interviewed person answers yes at least to 4 questions}.
We obtain that Ei = Fi ‚à®Gi e
P(Ei) = P(Fi) + P(Gi) ‚àíP(Fi ‚àßGi) .
The probability of Fi, Gi e Fi ‚àßGi are given by:
(a)
P(Fi) = 1
2 ¬∑ 1
2 = 1
4 .
For all question we have 2 possible cases (yes and no), while for the Ô¨Årst
question we have only one possible choice (yes).
(b)
P(Gi) =
 5
4
 1
2
5
+
5
5
 1
2
5
.

136
10
Discrete Distributions
A person answers yes at least to 4 questions if she answers yes to exactly 4
questions or to exactly 5 questions.
(c)
P(Fi ‚àßGi) =
 3
2
 1
2
5
+
3
3
 1
2
5
.
In the case the events happen at the same time, we need to choose only the
other 2, respectively 3 questions to which the candidate answer yes.
Finally
P(Ei) = 1
4 +
 5
4
 1
25 + 1
25 ‚àí3
25 ‚àí1
25 =
1
22 + 1
24 =
5
16 .
We obtain that I (N) = {0, . . . , 100} and
P(N = i) =
100
i
  5
16
i 
1 ‚àí5
16
100‚àíi
,
i.e. N has binomial distribution Bn(100, 5
16).
2. The expectation of N is given by
P(N) =
100

i=1
iP(Ei) = 100 ¬∑ 5
16 = 125
4 .
The variance of N is given by
œÉ2(N) =
100

i=1
œÉ2(Ei) +
100

i, j=1
cov(Ei, E j)
	



0
= 100 ¬∑ 5
16 ¬∑

1 ‚àí5
16

.
The generating function of N is given by
œÜN(t) = P(t N)
=
100

i=0
 100
i

¬∑
 5t
16
i
¬∑

1 ‚àí5
16
100‚àíi
=
 5t
16 + 1 ‚àí5
16
100
,
where we have used Newton‚Äôs binomial formula.
‚äì‚äî

10
Discrete Distributions
137
Exercise 10.6 A box contains 8 balls: 4 white and 4 black. We draw 4 balls. Let Ei
be the event that the i-th ball extracted is white. Let X = E1 + E2, Y = E3 + E4.
(a) Compute the joint distribution of X and Y.
(b) Compute P(X), P(Y), œÉ2(X), œÉ2(Y).
(c) Compute cov(X, Y), the correlation coefÔ¨Åcient œÅ(X, Y). Are X and Y stochas-
tically independent?
Solution 10.6 (a) Consider the random vector (X, Y). The set of possible values
for (X, Y) is given by
I (X, Y) = {(i, j)| i = 0, 1, 2, j = 0, 1, 2} .
To compute the joint distribution of (X, Y), we need to calculate
P(X = i, Y = j) = P(Y = j| X = i)P(X = i)
for all (i, j) ‚ààI (X, Y). The probability of extracting a white ball in the Ô¨Årst 2
extractions is given by
P(X = i) =
4
i
 
4
2 ‚àíi

 8
2

.
Here the possible cases are
 8
2

since we consider only the Ô¨Årst 2 extractions.
Moreover
P(Y = j| X = i) =
4 ‚àíi
j
 4 ‚àí(2 ‚àíi)
2 ‚àíj

 6
2

=
4 ‚àíi
j
  2 + i
2 ‚àíj

 6
2

.
After the Ô¨Årst 2 extractions, only 6 balls are left in the box. We have to draw 2
more balls, j among the remaining white ones (4 ‚àíi) and (2 ‚àíj) among the
remaining black ones 4 ‚àí(2 ‚àíi) = 2 + i. The joint distribution of X and Y
is then

138
10
Discrete Distributions
P(X = i, Y = j) =
4 ‚àíi
j
  2 + i
2 ‚àíj

 6
2

¬∑
 4
i
 
4
2 ‚àíi

 8
2

.
(b) To compute P(X) and P(Y) we use the fact that the events Ei have equal prob-
ability (but they are not stochastically independent!), hence
P(X) = P(E1) + P(E2) = 2 ¬∑ 4
8 = 1
and
P(X) = P(Y) = 1 .
The events E1 and E2 (and consequently also E3 e E4) are negatively correlated
with covariance:
cov(E1, E2) = P(E1E2) ‚àíP(E1)P(E2)
= P(E2|E1)P(E1) ‚àíP(E1)P(E2)
= ‚àí1
28 .
The variance of X is then
œÉ2(X) = œÉ2(E1 + E2) = œÉ2(E1) + œÉ2(E2) + 2cov(E1, E2)
= 1
4 + 1
4 ‚àí1
28 = 13
28 .
Also in this case œÉ2(Y) = œÉ2(X) = 13
28.
(c) We have:
cov(X, Y) = cov(E1 + E2, E3 + E4)
= cov(E1, E3) + cov(E1, E4) + cov(E2, E3) + cov(E2, E4)
= 4 ¬∑

‚àí1
28

= ‚àí1
7 .
Here we have used that fact that the covariance is a bilinear function. Finally,
the coefÔ¨Åcient of correlation between X and Y is equal to:
œÅ(X, Y) = cov(X, Y)
œÉ(X)œÉ(Y) =
‚àí1
7

13
28 ¬∑

13
28
= ‚àí4
13 .
‚äì‚äî

10
Discrete Distributions
139
Exercise 10.7 Let E1, E2, F1, F2 bestochasticallyindependenteventswithP(E1) =
P(E2) = 1
4, P(F1) = P(F2) = 1
3. Let X = E1 + E2, Y = F1 + F2.
(a) Compute the set of possible values and the probability distributions of X and Y.
(b) Compute P(X + Y), œÉ2(X + Y).
(c) Compute P(X = Y), P(X = ‚àíY).
Solution 10.7 (a) Since E1, E2 are events, i.e. random numbers that can assume
only the values 0 and 1, we have that the set of possible values of X is given by
I (X) = {0, 1, 2} .
Analogously for Y
I (Y) = {0, 1, 2} .
To compute the probability distribution of X means that we have to calculate
with which probability X assumes each of the possible values. For example, we
have that
P(X = 0) = P(E1 + E2 = 0)
= P(E1 = E2 = 0) = P( ÀúE1)P( ÀúE2) = 9
16 .
Since X is equal to the sum of 2 stochastically independent events with the
same probability, we can immediately say that the distribution of X is binomial
Bn(n, p) with parameters n = 2 and p = 1
4. Analogously Y has binomial
distribution Bn(2, 1
3) and we have that
P(X = i) =
 2
i
 1
4
i 3
4
2‚àíi
,
i = 0, 1, 2
P(Y = j) =
 2
j
 1
3
 j 2
3
2‚àíj
,
j = 0, 1, 2 .
(b) To compute the expectation, we can use the linearity
P(X + Y) = P(E1 + E2 + F1 + F2)
= P(E1) + P(E2) + P(F1) + P(F2)
= 2 ¬∑ 1
4 + 2 ¬∑ 1
3 = 7
6 .
For the variance, we use the formula of the variance of a sum:
œÉ2(X + Y) = œÉ2(X) + œÉ2(Y) + 2 cov(X, Y).

140
10
Discrete Distributions
Since X and Y have binomial distribution, we have
œÉ2(X) = 2 ¬∑ 1
4 ¬∑ 3
4 = 3
8,
œÉ2(Y) = 2 ¬∑ 1
3 ¬∑ 2
3 = 4
9 .
To compute the covariance between X and Y we use the fact that the events
E1, E2, F1, F2 are stochastically independent in the following way:
cov(X, Y) = cov(E1 + E2, F1 + F2)
= cov(E1, F1) + cov(E1, F2) + cov(E2, F1) + cov(E2, F2)
= 0 .
Hence
œÉ2(X + Y) = 3
8 + 4
9 = 59
72 .
(c) To compute P(X = Y) we note that the event
(X = Y)
is given by
(X = Y) = (X = 0, X = 0) + (X = 1, Y = 1) + (X = 2, Y = 2) .
Hence
P(X = Y) =
2

i=0
P(X = i, Y = i)
=
2

i=0
P(X = i)P(Y = i)
=
2

i=0
2
i
 1
4
i 3
4
2‚àíi 2
i
 1
3
i 2
3
2‚àíi
=
2

i=0
2
i
2  1
12
i 1
2
2‚àíi
= 1
4
2

i=0
2
i
2 1
6
i
= 61
144 .

10
Discrete Distributions
141
On the other side the event
(X = ‚àíY)
is veriÔ¨Åed only if
(X = ‚àíY) = (X = 0, Y = 0) .
Hence
P(X = ‚àíY) = P(X = 0, Y = 0) = P(X = 0)P(Y = 0) = 1
4 .
‚äì‚äî

Chapter 11
One-Dimensional Absolutely Continuous
Distributions
Exercise 11.1 The random numbers X, Y and Z are stochastically independent with
exponential distribution of parameter Œª = 2.
(a) Compute the density of the probability of X + Y and of X + Y + Z.
(b) Let E, F, G be the events E = (X ‚â§2), F = (X + Y > 2), G = (X + Y +
Z ‚â§3). Compute P(E), P(F), P(G) e P(E F).
(c) Determine if E, F and G are stochastically independent.
Solution 11.1 (a) The exponential distribution is a particular case of the gamma
distribution with parameter 1, Œª. If X, Y and Z are stochastically independent
random numbers with exponential distribution of parameter Œª = 2, i.e. Gamma
distribution Œì (1, 2), we can use the following property of the the sum of sto-
chastically independent random numbers with Gamma distribution
Œì (Œ±, Œª) + Œì (Œ≤, Œª) ‚àºŒì (Œ± + Œ≤, Œª).
Hence W1 = X + Y has distribution Œì (2, 2). We can iterate this procedure and
obtain that
W2 = X + Y + Z = W1 + Z
has distribution Œì (3, 2).
(b) We have:
P(E) = P(X ‚â§2) =
 2
0
2e‚àí2xdx
= 1 ‚àíe‚àí4 ;
P(F) = P(X + Y > 2) =
 +‚àû
2
4xe‚àí2xdx
=

‚àí2xe‚àí2x+‚àû
2
+ 2
 +‚àû
2
e‚àí2xdx
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_11
143

144
11
One-Dimensional Absolutely Continuous Distributions
= 4e‚àí4 +

‚àíe‚àí2x+‚àû
2
= 5e‚àí4 ;
P(G) = P(X + Y + Z ‚â§3) =
 3
0
4x2e‚àí2xdx
= 1 ‚àí
 +‚àû
3
4x2e‚àí2xdx
= 1 ‚àí

‚àí2x2e‚àí2x+‚àû
3
+ 4
 +‚àû
3
xe‚àí2xdx

= 1 ‚àí25e‚àí6,
and
P(E F) = P(X ‚â§2, X + Y > 2)
= P(X ‚â§2, Y > 2 ‚àíX) = P(X ‚â§2, Y > 0)
= P(X ‚â§2)P(Y > 0) = P(X ‚â§2) .
Here we have used the fact that X and Y are assumed to be stochastically inde-
pendent, as well as that the product of 2 events denotes that both conditions must
be simultaneously satisÔ¨Åed.
(c) To determine if E, F, G are stochastically independent, we need to verify all the
following conditions:
P(E F) = P(E)P(F);
P(EG) = P(E)P(G);
P(FG) = P(F)P(G);
P(E FG) = P(E)P(F)P(G) .
If one of them is not veriÔ¨Åed, then the events are not stochastically independent.
We can immediately see that
P(E F) Ã∏= P(E)P(F)
by using the results above. Hence the three events are not stochastically inde-
pendent.
‚ñ°
Exercise 11.2 Let X be a random number with standard normal distribution. Let
Y = 3X + 2 and Z = X2.
1. Compute the c.d.f. and the density of Y.
2. Estimate P(Y ‚â•y), where y > 0.
3. Compute the expectation and the variance of Z.
4. Compute the c.d.f. and the density of Z.

11
One-Dimensional Absolutely Continuous Distributions
145
Solution 11.2
1. Put
n(t) =
1
‚àö
2 œÄ
e‚àít2
2
We compute the c.d.f. FY of Y = 3X + 2. Given y ‚ààR
FY(y) = P(Y ‚â§y) = P(3X + 2 ‚â§y) =
P

X ‚â§y ‚àí2
3

=

y‚àí2
3
‚àí‚àû
n(t)dt =
 y
‚àí‚àû
1
3
‚àö
2œÄ
e‚àí(z‚àí2)2
18 dz ,
where we have used the change of variable t = z ‚àí2
3
. The density fY of Y is
obtained by the derivation of FY:
fY(y) = d
dy FY(y) = 1
3
1
‚àö
2 œÄ
e‚àí(y‚àí2)2
2¬∑9
.
It follows that Y has normal distribution N(2, 9).
2. To estimate the probability P(Y ‚â•y), y > 0, we use that
1
‚àö
2 œÄ
e‚àíx2
2
1
x ‚àí1
x3

‚â§P(X ‚â•x) ‚â§1
x
1
‚àö
2 œÄ
e‚àíx2
2 ,
if X has standard normal distribution. Since P(Y ‚â•y) = P
	
X ‚â•y‚àí2
3

for
y > 0, we obtain
1
‚àö
2 œÄ
e‚àí(y‚àí2)2
2¬∑9

3
y ‚àí2 ‚àí
27
(y ‚àí2)3

‚â§P(Y > y) ‚â§
3
y ‚àí2
1
‚àö
2 œÄ
e‚àí(y‚àí2)2
2¬∑9
.
3. The expectation of Z is given by:
P(Z) = P(X2) =
 +‚àû
‚àí‚àû
x2
1
‚àö
2 œÄ
e‚àíx2
2 dx = œÉ2(X) = 1,
where we have used the formula P(œà(x)) =

œà(x) fX(x) dx. To compute the
variance of Z, we use the formula
œÉ2(Z) = P(Z2) ‚àíP(Z)2 .
It remains to compute

146
11
One-Dimensional Absolutely Continuous Distributions
P(Z2) = P((X2)2) = P(X4)
=
 +‚àû
‚àí‚àû
x4
1
‚àö
2 œÄ
e‚àíx2
2 dx
=

‚àíx3
1
‚àö
2 œÄ
e‚àíx2
2
+‚àû
‚àí‚àû
+ 3
 +‚àû
‚àí‚àû
x2
1
‚àö
2 œÄ
e‚àíx2
2 dx
= 3.
4. To compute the c.d.f. FZ of Z, we proceed as above, i.e.
FZ(z) = P(Z ‚â§z) = P(X2 ‚â§z) .
Since Z = X2 is a non negative random number, we can distinguish 2 cases:
(a) for z < 0 we have that FZ(z) = 0;
(b) if z ‚â•0
FZ(z) = P

X2 ‚â§z

= P

‚àí‚àöz ‚â§X ‚â§‚àöz

= P

X ‚â§‚àöz

‚àíP

X ‚â§‚àí‚àöz

=
 ‚àöz
‚àí‚àû
1
‚àö
2 œÄ
e‚àít2
2 dt ‚àí
 ‚àí‚àöz
‚àí‚àû
1
‚àö
2 œÄ
e‚àít2
2 dt
=
 ‚àöz
‚àí‚àöz
1
‚àö
2 œÄ
e‚àít2
2 dt .
Finally we get
FZ(z) =
‚éß
‚é™‚é™‚é®
‚é™‚é™‚é©
0
z < 0 ,
 ‚àöz
‚àí‚àöz
1
‚àö
2 œÄ
e‚àít2
2 dt
z ‚â•0.
To compute the density fZ, we can take the derivative of the c.d.f.. For z ‚â•0
fZ(z) = d
dz
 ‚àöz
‚àí‚àû
1
‚àö
2 œÄ
e‚àít2
2 dt ‚àí
 ‚àí‚àöz
‚àí‚àû
1
‚àö
2 œÄ
e‚àít2
2 dt

= 1
2z‚àí1
2 n(‚àöz) ‚àí

‚àí1
2z‚àí1
2

n(‚àí‚àöz)
= z‚àí1
2 ¬∑ n(‚àöz)
= z‚àí1
2
1
‚àö
2 œÄ
e‚àíz
2 .

11
One-Dimensional Absolutely Continuous Distributions
147
We obtain
fZ(z) =
‚éß
‚é™‚é™‚é®
‚é™‚é™‚é©
0
z < 0 ,
1
‚àö
2 œÄ
z‚àí1
2 e‚àíz
2
z ‚â•0.
Hence Z has Gamma distribution of parameters Œì ( 1
2, 1
2), i.e. œá2-distribution of
parameter 1.
‚ñ°
Exercise 11.3 Let X be a random number with exponential distribution with para-
meter Œª = 2.
1. Compute the moments of order n of X, i.e. P(Xn), n ‚ààN.
2. Consider the family of random numbers Zu = euX, u < Œª. Given a Ô¨Åxed u < Œª,
compute the expectation Œ®X(u) = P(euX) of Zu. The function Œ®X(u) is called
moment generating function of X.
Solution 11.3
1. The moment of order n ‚ààN for X can be computed with the
formula
P(Œ® (x)) =

Œ® (x) fX(x) dx ,
for a given function Œ® : R ‚àí‚ÜíR such that the integral above exists and is Ô¨Ånite.
In this case Œ® (x) = xn. We then obtain
P(Xn) =
 +‚àû
0
xn Œª e‚àíŒªx dx
= Œª
 +‚àû
0
xne‚àíŒªx dx = ŒªŒì (n + 1)
Œªn+1
= n!
Œªn .
In particular for n = 1 we have that P(X) = 1
Œª.
2. We compute the expectations of Zu = euX, u ‚ààR.
P(Zu) = P(euX)
=
 +‚àû
0
Œª eux e‚àíŒªx dx
=
 +‚àû
0
Œª e(u‚àíŒª)x dx .

148
11
One-Dimensional Absolutely Continuous Distributions
Note that here u is a given parameter. The integral is well-deÔ¨Åned since u < Œª.
We obtain that
P(Zu) =
Œª
u ‚àíŒª

e(u‚àíŒª)x+‚àû
0
=
Œª
u ‚àíŒª .
‚ñ°
Exercise 11.4 The random number X has uniform distribution on the interval
[‚àí1, 1].
(a) Write the density of X.
Let Z = log |X|.
(b) Compute I (Z) e P(Z).
(c) Compute the c.d.f. and the density of Z.
(d) Calculate P(Z < ‚àí1
2|X > ‚àí1
2).
Solution 11.4 (a) The density of X is equal to
f (x) =
 1
2 per x ‚àà(‚àí1, 1),
0 otherwise.
(b) The random number X has as set of possible values
I (X) = [‚àí1, 1],
hence the set of possible values for Z = log |X| is given by
I (Z) = (‚àí‚àû, 0] .
The random number Z is not deÔ¨Åned if X assumes the value 0 ‚ààI (X). To
compute the expectation we can proceed as follows:
P(Z) = P(Z|X > 0)P(X > 0) + P(Z|X < 0)P(X < 0)
= P(log X|X > 0) ¬∑ 1
2 + P(log(‚àíX)|X < 0) ¬∑ 1
2 ,
where we have used the fact that
P(X > 0) = P(X < 0) = 1
2 .
Verify this by direct computation!

11
One-Dimensional Absolutely Continuous Distributions
149
We need only to calculate
P(log X|X > 0) =
 1
0
log xdx
(11.1)
= [x log x ‚àíx]1
0 = ‚àí1 ,
P(log(‚àíX)|X < 0) =
 0
‚àí1
log(‚àíx)dx
(11.2)
=
 1
0
log ydy = ‚àí1,
hence
P(Z) = P(log X) = ‚àí1 .
(c) To compute the c.d.f. of Z, we need to exclude again the value 0. We have
FZ(z) = P(Z ‚â§z)
= P(Z ‚â§z, X > 0) + P(Z ‚â§z, X < 0) .
If z ‚â•0, then FZ(z) = 1. Let z < 0. We obtain:
FZ(z) = P(log X ‚â§z, X > 0) + P(log(‚àíX) ‚â§z, X < 0) .
We now compute
P(log X ‚â§z, X > 0) = P(X ‚â§ez, X > 0)
(11.3)
= P(0 < X ‚â§ez)
=
 ez
0
1
2dx = 1
2ez
and
P(log(‚àíX) ‚â§z, X < 0) = P(X ‚â•‚àíez, X < 0)
(11.4)
= P(‚àíez ‚â§X < 0)
=
 0
‚àíez
1
2dx = 1
2ez .
Hence
FZ(z) = ez
if z < 0 .

150
11
One-Dimensional Absolutely Continuous Distributions
The density of Z is given by
fZ(z) =
ez for z < 0,
0 otherwise .
(d) We evaluate P(Z < ‚àí1
2|X > ‚àí1
2) by using the formula of the conditional prob-
ability:
P

Z < ‚àí1
2
X > ‚àí1
2

= P

Z < ‚àí1
2, X > ‚àí1
2

P

X > ‚àí1
2

,
where
P

Z < ‚àí1
2, X > ‚àí1
2

= P

log |X| < ‚àí1
2, X > ‚àí1
2

=
P

log X < ‚àí1
2, X > 0

+ P

log(‚àíX) < ‚àí1
2, ‚àí1
2 < X < 0

,
Here we have used that

X > ‚àí1
2

= (X > 0) +

‚àí1
2 < X < 0

.
It follows that
P

log X < ‚àí1
2, X > 0

= P
	
0 < X < e‚àí1
2

= e‚àí1
2
2
and furthermore
P

log(‚àíX) < ‚àí1
2, ‚àí1
2 < X < 0

= P

X > ‚àíe‚àí1
2 , ‚àí1
2 < X < 0

= P

‚àí1
2 < X < 0

=
 0
‚àí1
2
1
2dx = 1
4 .
Finally
P

Z < ‚àí1
2|X > ‚àí1
2

= 1
2
 1
‚àöe + 1
2

.
‚ñ°

Chapter 12
Absolutely Continuous and Multivariate
Distributions
Exercise 12.1 Let X be the random number with density
f (x) =
 K x2 for ‚àí1 ‚â§x ‚â§1,
0
otherwise.
(a) Compute K.
(b) Compute the c.d.f., the expectation and the variance of X.
(c) Let Y be a random number which is stochastically independent and has expo-
nential distribution with parameter Œª = 2. Write the joint density function and
the joint c.d.f. of (X, Y).
Solution 12.1 (a) The normalization constant K is such that
 1
‚àí1
K x2dx = 1 .
Hence
K =
1
 1
‚àí1 x2dx
= 3
2 .
(b) The c.d.f. of X is given by
F(x) = P(X ‚â§x) =
 x
‚àí‚àû
f (t)dt .
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_12
151

152
12
Absolutely Continuous and Multivariate Distributions
Hence
F(x) =
‚éß
‚é™‚é™‚é®
‚é™‚é™‚é©
0
for x ‚â§1,
 x
‚àí1
3
2t2dt = 1
2(x3 + 1) for x ‚àà[‚àí1, 1]
1
for x ‚â•1.
Furthermore the expectation of X is equal to
P(X) =

R
t f (t)dt =
 1
‚àí1
3
2 x3dx = 0 .
The variance is given by
œÉ2(X) = P(X2) ‚àíP(X)2
= P(X2) =
 1
‚àí1
x2 ¬∑ 3
2 x2dx
= 3
2
 1
‚àí1
x4dx = 3
5 .
(c) The density of Y is given by
g(y) =
‚éß
‚é®
‚é©
2e‚àí2y for y ‚â•0,
0
otherwise.
If X and Y are stochastically independent, then the joint density is given by the
product of the marginal densities:
f (x, y) = fX(x)gY(y) =
‚éß
‚é™‚é®
‚é™‚é©
2e‚àí2y 3
2 x2 = 3e‚àí2yx2 for x ‚àà[‚àí1, 1] and y ‚â•0,
0
otherwise.
Analogously the joint c.d.f. coincides with the product of the marginal distribu-
tion functions:
F(x, y) = FX(x)FY(y) =
‚éß
‚é™‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é™‚é©
(1 ‚àíe‚àí2y)x3 + 1
2
for x ‚àà[‚àí1, 1] and y ‚â•0,
1 ‚àíe‚àí2y
for x > 1 and y ‚â•0,
0
otherwise.
‚ñ°

12
Absolutely Continuous and Multivariate Distributions
153
Exercise 12.2 Let (X, Y) be a random vector with uniform distribution on the disk
of radius 1 and center at the origin of the axes.
1. Compute the joint density function f (x, y) of (X, Y).
2. What is the marginal density fX of X?
3. Let Z = X2 + Y 2, compute P(1
4 ‚â§Z ‚â§1).
4. Compute the c.d.f. and the density of Z.
Solution 12.2
1. Since (X, Y) have uniform distribution on the disk
D1 =
	
(x, y) : x2 + y2 ‚â§1

.
the joint density f (x, y) is constant on D1 and 0 outside. We obtain that
f (x, y) =
‚éß
‚é™‚é®
‚é™‚é©
1
area D1 = 1
œÄ for (x, y) ‚ààD1 ,
0
otherwise.
The density domain is shown in Fig.12.1.
The value of the density f on D1 can be determined by imposing that
1 =
 
R2 f (x, y) dx dy =
 
D1
c dx dy,
i.e.
c =
1
 
D1 dx dy =
1
area D1
= 1
œÄ .
2. To compute the marginal density of X, we distinguish 4 cases as follows.
Fig. 12.1 Representation of
the area D1 on the plane
x
y
O
D1

154
12
Absolutely Continuous and Multivariate Distributions
Fig. 12.2 Case 0 ‚â§x ‚â§1
x
y
O
x
Fig. 12.3 Case ‚àí1 ‚â§x ‚â§0
x
y
O
x
‚Ä¢ Case x > 1: fX(x) = 0.
‚Ä¢ Case 1 ‚â•x ‚â•0: set the x coordinate; y varies along the line orthogonal to
the x-axis and passing through (x, 0). The extremes are the points where this
line intersects the graph of D1 as shown in Fig.12.2. We obtain:
fX(x) =
 ‚àö
1‚àíx2
‚àí
‚àö
1‚àíx2 f (x, t) dt =
 ‚àö
1‚àíx2
‚àí
‚àö
1‚àíx2
1
œÄ dt = 2
‚àö
1 ‚àíx2
œÄ
.
‚Ä¢ Case ‚àí1 ‚â§x < 0: by symmetry, we obtain as shown in Fig.12.3, that
fX(x) = 2
‚àö
1 ‚àíx2
œÄ
.
‚Ä¢ Case x < ‚àí1: also here we have fX(x) = 0.

12
Absolutely Continuous and Multivariate Distributions
155
Summing up:
fX(x) =
‚éß
‚é®
‚é©
2
‚àö
1‚àíx2
œÄ
for x ‚àà[‚àí1, 1]
0
otherwise.
3. Let Z = X2 + Y 2; to compute P
 1
4 ‚â§Z ‚â§1

is equivalent to calculate the prob-
ability that the random vector (X, Y) belongs to the region A of the plane between
the disk with center O and radius 1
2 and the disk with center O and radius 1, i.e.
P
1
4 ‚â§Z ‚â§1

= P
1
4 ‚â§X2 + Y 2 ‚â§1

.
Hence
P
1
4 ‚â§X2 + Y 2 ‚â§1

=
 
A
f (x, y) dx dy .
We can compute this integral by passing to the polar coordinates
x = œÅ cos Œ∏,
y = œÅ sin Œ∏ .
To perform the change of variables in the integral, we need to take account of
the absolute value of the Jacobian determinant (Fig.12.4). In the case of polar
coordinates, this is equal to
|J| = œÅ .
Fig. 12.4 Area of the region
	
(x, y)| 1
4 ‚â§x2 + y2 ‚â§1

x
y
O
A

156
12
Absolutely Continuous and Multivariate Distributions
It follows that
 
A(x,y)
f (x, y) dx dy =
 
A(œÅ,Œ∏)
f (œÅ, Œ∏) dœÅ dŒ∏
=
 2œÄ
0
dŒ∏
 1
1
2
1
œÄ dœÅ =
 1
1
2
2œÅ dœÅ =

œÅ21
1
2 = 3
4 .
4. To compute the c.d.f. FZ(z) of Z we use again spherical symmetry.
‚Ä¢ z < 0: In this case FZ(z) = 0.
‚Ä¢ 1 ‚â•z ‚â•0:
FZ(z) = P(Z ‚â§z)
= P(X2 + Y 2 ‚â§z)
=
 
Dz
f (x, y) dx dy,
where Dz = {(x, y) : x2 + y2 ‚â§z}. It follows that
FZ(z) =
 2œÄ
0
 ‚àöz
0
1
œÄ œÅ dœÅ dŒ∏ =
 ‚àöz
0
2œÅ dœÅ =

œÅ2‚àöz
0
= z .
‚Ä¢ z > 1: In this case FZ(z) = P

X2 + Y 2 ‚â§z

= 1.
Summing up:
FZ(z) =
‚éß
‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é©
0
for z < 0,
z for 0 ‚â§z < 1,
1
for z > 1 .
The density function of Z is given by
fZ(z) =
‚éß
‚é®
‚é©
1 for 0 ‚â§z ‚â§1,
0
otherwise.
The random number Z has therefore a uniform density in [0, 1].
‚ñ°
Exercise 12.3 Let (X, Y) be a random vector with joint density
f (x, y) =
‚éß
‚é®
‚é©
k xy (x, y) ‚ààT,
0
otherwise.

12
Absolutely Continuous and Multivariate Distributions
157
where T = {(x, y) ‚ààR2| 0 ‚â§y ‚â§‚àíx + 2, 0 < x < 2}.
1. Compute the normalization constant k.
2. ComputetheprobabilityP(X > 1, Y < 1
2)andtheconditionalprobabilityP(X >
1|Y < 1
2).
3. Let Z = X + Y. Compute the probability that P(0 < Z < 1).
4. Compute the p.d.f. and the density of Z.
Solution 12.3
1. To compute the normalization constant k we impose that
 
R2 f (x, y) dx dy = 1 .
The integral of f can be computed by using Fubini-Tonelli Theorem:
 
R2 f (x, y) dx dy = k
 2
0
x
 ‚àíx+2
0
y dy dx
= k
 2
0
x
 y2
2
‚àíx+2
0
dx = k
 2
0
x 1
2 (2 ‚àíx)2 dx
= k
2
 2
0
(4x ‚àí4x2 + x3) dx = k
2

2x2 ‚àí4
3x3 + 1
4x4
2
0
= 2
3 k .
It follows that
k = 3
2 .
2. The probability P(X > 1, Y < 1
2) is given by the integral of the joint density on
the region D given by the intersection
D = {(x, y) ‚ààR2 | x > 1, y < 1
2} ‚à©T ,
see Figs.12.5 and 12.6.
To Ô¨Ånd the extremes, it is easier this time to Ô¨Åx y and let x vary. The extremes
are given by the intersection of the border of D with the line passing in (0, y)
which is parallel to the x-axis, as we can see in Fig.12.7.

158
12
Absolutely Continuous and Multivariate Distributions
Fig. 12.5 Representation of
the area T on the plane
x
y
O
T
Fig. 12.6 Representation of
the area D on the plane
y
O
x
T
E = {(x,y)| x>1, y<1/2}
D
Fig. 12.7 Extremes of
variation of x
y
O
x
y

12
Absolutely Continuous and Multivariate Distributions
159
P(X > 1, Y < 1
2) =
 
D
f (x, y) dx dy
=

1
2
0

y
 ‚àíy+2
1
3
2 x dx

dy
=

1
2
0
y
3
4 x2
‚àíy+2
1
dy
= 3
4

1
2
0
y (3 ‚àí4y + y2) dy
= 3
4
3
2 y2 ‚àí4
3 y3 + 1
4 y4
 1
2
0
= 43
256 .
The conditional probability P(X > 1|Y < 1
2) can be obtained as follows:
P(X > 1|Y < 1
2) = P(X > 1, Y < 1
2)
P(Y < 1
2)
.
We simply need to compute P(Y < 1
2). To this purpose we do not necessarily
need to know the marginal density of Y. This probability is given by the integral
of the joint probability f (x, y) on the domain D1 given by the intersection of
E1 = {(x, y) ‚ààR2| y < 1
2} and of T , i.e.
D1 = E1 ‚à©T ,
see Fig.12.8.
We can obtain the probability that Y is less than 1
2 by computing the joint prob-
ability that there are no restrictions on X and that Y is less than 1
2. We obtain:
P(Y < 1
2) =
 
D1
f (x, y) dx dy
=

1
2
0
3
2 y
 ‚àíy+2
0
x dx dy = 3
4

1
2
0
y (4 ‚àí4y + y2) dy
= 3
4

2y2 ‚àí4
3 y3 + 1
4 y4
 1
2
0
= 67
256 .
The conditional probability is then given by
P(X > 1|Y < 1
2) = P(X > 1, Y < 1
2)
P(Y < 1
2)
= 43
67 .

160
12
Absolutely Continuous and Multivariate Distributions
Fig. 12.8 Representation of
the area D1 on the plane
y
O
x
E1
D1
T
3. We now consider the random number Z = X + Y. To compute the probability
P(0 < Z < 1) we can use the joint density of (X, Y). We obtain
P(0 < Z < 1) = P(0 < X + Y < 1)
= P(‚àíY < X < 1 ‚àíY)
= P(0 < X < 1 ‚àíY).
Note that in this case X and Y are both positive, hence the condition X > ‚àíY
reduces to X > 0. In Fig.12.9 we represent the region where the integral of the
joint density of X, Y must be calculated to obtain P(0 < Z < 1).
Fig. 12.9 Region where
0 < Z < 1
y
O
x
D
X+Y=1

12
Absolutely Continuous and Multivariate Distributions
161
P(0 < X < 1 ‚àíY) =
 1
0
3
2 y
 1‚àíy
0
x dx dy
= 3
4
 1
0
y (1 ‚àíy)2 dy
= 3
4
 1
0
(y ‚àí2y2 + y3) dy
= 3
4
1
2 y2 ‚àí2
3 y3 + 1
4 y4
1
0
= 1
16 .
4. The m.d.f. of Z is given by
FZ(z) = P(Z ‚â§z) = P(X + Y ‚â§z) = P(X ‚â§z ‚àíY) .
If we consider the line x + y ‚àíz = 0, the distribution function of Z is given by
the integral of the joint density of X, Y on the region R delimited by this line on
T , as shown by Fig.12.10.
We obtain:
‚Ä¢ for z < 0: P(Z < z) = 0;
‚Ä¢ for z > 2: P(Z < z) = 1;
‚Ä¢ for 0 ‚â§z ‚â§2:
Fig. 12.10 Region R
y
O
x
D
X+Y=Z

162
12
Absolutely Continuous and Multivariate Distributions
P(Z < z) =
 z
0
3
2 y
 z‚àíy
0
x dx dy
= 3
4
 z
0
y (z ‚àíy)2 dy
= 3
4
 z
0
(z2y ‚àí2zy2 + y3) dy
= 3
4
1
2 z2y2 ‚àí2
3 zy3 + 1
4 y4
z
0
= 3
4
1
2 z4 ‚àí2
3 z4 + 1
4 z4

= z4
16 .
Summing up:
FZ(z) =
‚éß
‚é™‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é™‚é©
0
for z < 0,
z4
16 for 0 ‚â§z ‚â§2,
1
for z > 2 .
The density can be obtained by deriving the distribution function
fZ(z) =
‚éß
‚é™‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é™‚é©
0
for z < 0,
z3
4
for 0 ‚â§z ‚â§2,
0
for z > 2,
or by means of the formula
fZ(z) =

R
f (x, z ‚àíx)dx .
‚ñ°
Exercise 12.4 Let X, Y be two random numbers with joint distribution function
f (x, y) =
 K x for y ‚â§x ‚â§y + 1,
0 ‚â§y ‚â§2,
0
otherwise.
(a) Compute K.
(b) Compute the m.d.f. and the expectation of X.

12
Absolutely Continuous and Multivariate Distributions
163
‚àí1
2
2
1
Fig. 12.11 Region R of deÔ¨Ånition of the density
(c) Compute cov(X, Y).
(d) Compute P(0 < X ‚àíY < 1).
Solution 12.4 (a) As in previous exercises, Ô¨Årst we draw the picture of the region
R of deÔ¨Ånition of the joint density, as shown by Fig.12.11.
Since the integral of a density must be equal 1, the constant of normalization is
given by
K =
1
 
R2 xdxdy ,
where
 
R2 xdxdy =
 2
0
dy
 y+1
y
xdx
=
 2
0
x2
2
y+1
y
dy
=
 2
0
(y + 1)2
2
‚àíy2
2

dy
= 1
6

(y + 1)3 ‚àíy32
0 = 3 .

164
12
Absolutely Continuous and Multivariate Distributions
x
Fig. 12.12 Extremes of variation y
We conclude that K = 1
3.
(b) To compute the marginal density of X we apply the formula
fX(x) =

R
f (x, y)dy .
To Ô¨Ånd the extremes of integration, we apply the general method as shown in
Fig.12.1.
We have to pay attention, since the expressions for the extremes of integration
vary if 0 < x < 1, 1 < x < 2, 2 < x < 3 (see Fig.12.12).
We have that if 0 < x < 1, then y varies between the lines
y = 0 e
y = x .
If 1 < x < 2, then y varies between the lines
y = x ‚àí1 e
y = x .
If 2 < x < 3, then y varies between
y = x ‚àí1 and
y = 2.

12
Absolutely Continuous and Multivariate Distributions
165
‚Ä¢ For 0 < x < 1:
fX(x) =
 x
0
1
3xdy = 1
3x2 .
‚Ä¢ For 1 < x < 2:
fX(x) =
 x
x‚àí1
1
3xdy = 1
3x .
‚Ä¢ For 2 < x < 3:
fX(x) =
 2
x‚àí1
1
3xdy = 1
3x(3 ‚àíx) .
Summing up:
fX(x) =
‚éß
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é©
1
3x2
for 0 < x < 1,
1
3x
for 1 < x < 2,
1
3x(3 ‚àíx) for 2 < x < 3,
0
otherwise.
We now verify that fX(x) is a probability density. We need to have that

R
fX(x)dx = 1,
Indeed
 1
0
1
3x2dx +
 2
1
1
3xdx +
 3
2
1
3x(3 ‚àíx)dx =
=
1
9x3
1
0
+
1
6x2
2
1
+
x2
2 ‚àíx3
9
3
2
= 1 .
The expectation of X is given by:

166
12
Absolutely Continuous and Multivariate Distributions
P(X) =

R
x f (x)dx
=
 1
0
x 1
3x2dx +
 2
1
x 1
3xdx +
 3
2
x 1
3x(3 ‚àíx)dx
=
 1
12 x4
1
0
+
1
9x3
2
1
+
x3
3 ‚àíx4
12
3
2
= 16
9 .
(c) The covariance cov(X, Y) is given by:
cov(X, Y) = P(XY) ‚àíP(X)P(Y),
where
P(XY) =
 
R2 xy f (x, y)dxdy =
=
 2
0
dy
 y+1
y
xy 1
3xdx =
 2
0
1
9 y

(y + 1)3 ‚àíy3
dy
=
 1
12 y4 + 1
9 y3 + 1
18 y2
2
0
= 22
9 .
To compute the expectation of Y, we do not need to compute the marginal
distribution of Y. In fact it holds that
P(Y) =

R
y fY(y)dy
=

R

y

R
f (x, y)dx

dy
=
 
R
y f (x, y)dxdy .
Hence
P(Y) =
 
R
y f (x, y)dxdy
=
 2
0
dy
 y+1
y
1
3xydx
=
 2
0
y 1
6

(y + 1)2 ‚àíy2
dy
=
 y3
6 + y2
12
2
0
= 5
3 .

12
Absolutely Continuous and Multivariate Distributions
167
R1
R
Fig. 12.13 The region R1
We obtain
cov(X, Y) = 22
9 ‚àí11
12 √ó 5
3 = 11
12 ,
i.e. X and Y are positively correlated.
(d) To compute P(0 < X ‚àíY < 1), we note that
P(0 < X ‚àíY < 1) = P(Y < X < Y + 1) = 1 ,
since the region
R1 = {(x, y)| y < x < y + 1}
contains entirely the domain of deÔ¨Ånition of the density, see Fig.12.13.
‚ñ°
Exercise 12.5 Let X, Y be two stochastically independent random numbers with
the following marginal density:
f (x) =
 K(x3 ‚àí1) for 1 ‚â§x ‚â§2,
0
otherwise.
(a) Compute K.
(b) Compute the joint c.d.f., the expectation, the variance and the covariance of X
and Y.

168
12
Absolutely Continuous and Multivariate Distributions
(c) Let Z = X2. Compute the c.d.f., the expectation and the variance of Z.
(d) Compute the correlation coefÔ¨Åcients œÅ(X, Z), œÅ(X + Y, Z).
Solution 12.5 (a) Since K is the normalization constant, we obtain
K =
1
 2
0 (x3 ‚àí1)dx
=
1

x4
4 ‚àíx
2
1
= 4
11 .
(b) Since the random numbers X and Y are stochastically independent, their joint
c.d.f. is given by the product of the marginal c.d.f.‚Äôs:
F(x, y) = P(X ‚â§x, Y ‚â§y) = FX(x)FY(y) .
It is sufÔ¨Åcient to compute
F(x) = P(X ‚â§x) =
 x
‚àí‚àû
f (t)dt .
We obtain
FX(x) =
‚éß
‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é©
0
x < 1 ,
 x
1
4
11(t3 ‚àí1)dt = 4
11
x4
4 ‚àíx + 3
4

x ‚àà[1, 2],
1
x ‚â•2.
Hence
F(x, y) =
‚éß
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é©
0
for x < 1 or y < 1,
 4
11
2 (x4 ‚àíx + 3
4)(y4 ‚àíy + 3
4) for (x, y) ‚àà[1, 2] √ó [1, 2],
4
11(x4 ‚àíx + 3
4)
for x ‚àà[1, 2], y > 2,
4
11(y4 ‚àíy + 3
4)
for x > 2, y ‚àà[1, 2],
1
for x > 2, y > 2 .
Since X and Y are stochastically independent, we have immediately
cov(X, Y) = 0 .

12
Absolutely Continuous and Multivariate Distributions
169
Finally, we compute the expectation and the variance as follows:
1. Expectation
P(X) = P(Y) =

R
t f (t)dt
= 4
11
 2
1
t(t3 ‚àí1)dt = 4
11
t5
5 ‚àít2
2
2
1
= 94
55 .
2. For the variance, we need Ô¨Årst to calculate
P(X2) = P(Y 2) = 4
11
 2
1
t2(t3 ‚àí1)dt
= 4
11
t6
6 ‚àít3
3
2
1
= 98
33 .
Hence
œÉ2(X) = P(X2) ‚àíP(X)2 = 98
33 ‚àí
94
55
2
.
(c) We now compute the c.d.f. of Z = X2:
FZ(z) = P(Z ‚â§z) = P(X2 ‚â§z) .
For z < 1, we have immediately FZ(z) = 0. For 1 ‚â§z < 4, i.e. for 1 ‚â§‚àöz < 2,
we have
FZ(z) = P(Z ‚â§z) = P(X2 ‚â§z) = P(‚àí‚àöz ‚â§X ‚â§‚àöz) =
4
11
 ‚àöz
1
(t3 ‚àí1)dt = 4
11
t4
4 ‚àít
‚àöz
1
= 1
11(z2 ‚àí4‚àöz + 3) .
For z ‚â•4, FZ(z) = 1. Summing up:
FZ(z) =
‚éß
‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é©
0
for z < 1,
1
11(z2 ‚àí4‚àöz + 3) for z ‚àà[1, 4],
1
for z ‚â•4.
The expectation of Z coincides with the expectation of X2, i.e.
P(Z) = P(X2) = 98
33 .

170
12
Absolutely Continuous and Multivariate Distributions
To compute the variance, we note that
P(Z2) = P(X4) =
 2
1
4
11t4(t3 ‚àí1)dt =
4
11
t8
8 ‚àít5
5
2
1
= 1027
110 .
Hence the variance is given by
œÉ2(Z) = P(Z2) ‚àíP(Z)2 = 1027
110 ‚àí
98
33
2
.
(d) We now compute the correlation coefÔ¨Åcient œÅ(X, Z):
œÅ(X, Z) = cov(X, Z)
œÉ(X)œÉ(Z) .
SincewehavealreadydeterminedœÉ2(X), œÉ2(Z),wehaveimmediatelythemean
square deviations œÉ(X), œÉ(Z). It remains to compute
cov(X, Z) = P(X Z) ‚àíP(X)P(Z)
= P(X3) ‚àíP(X)P(Z)
= 4
11
 2
1
t3(t3 ‚àí1)dt ‚àí94
55 √ó 98
33
= 4
11
t7
7 ‚àít4
4
2
1
‚àí94
55 √ó 98
33 = 403
77 ‚àí94
55 √ó 98
33 .
Finally to obtain the correlation coefÔ¨Åcient œÅ(X + Y, Z) we simply note that
œÅ(X + Y, Z) = œÅ(X, Z) + œÅ(Y, Z) = œÅ(X, Z) ,
since X and Y (hence Z and Y) are stochastically independent.
‚ñ°
Exercise 12.6 The random numbers X and Y are stochastically independent. The
probability density fX(x) of X is given by:
fX(x) =
2x for 0 ‚â§1,
0
otherwise,
while the probability density of Y is given by
fY(y) =
e‚àíy for y ‚â•0,
0
otherwise .

12
Absolutely Continuous and Multivariate Distributions
171
(a) Compute P(X), P(Y), œÉ2(X), œÉ2(Y).
(b) Determine the joint c.d.f. and the joint density of (X, Y).
(c) Let Z = X + Y. Compute P(Z), œÉ2(Z) the c.d.f. and the density of Z.
Solution 12.6 (a) We compute the Ô¨Årst moments of X and Y:
P(X) =

R
x fX(x)dx =
 1
0
2x2dx = 2
3 ;
œÉ2(X) = P(X2) ‚àíP(X)2 =
 1
0
2x3dx ‚àí4
9 = 1
18 .
The random number Y has exponential density of parameter Œª = 1, hence we
can immediately write
P(Y) = 1
Œª = 1,
œÉ2(Y) = 1
Œª2 = 1 .
(b) The random numbers X and Y are stochastically independent, hence their joint
density is equal to
f (x, y) = fX(x) fY(y),
i.e.
f (x, y) =
2xe‚àíy for 0 ‚â§x ‚â§1 and y ‚â•0,
0
otherwise.
We compute the joint c.d.f.
F(x, y) =
 x
‚àí‚àû
 y
‚àí‚àû
f (s, t)dsdt
after having identiÔ¨Åed the domain D of deÔ¨Ånition of the joint density as shown
in Fig.12.14.
We obtain that
F(x, y) =
‚éß
‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é©
 x
0
 y
0 2se‚àítdsdt = x2(1 ‚àíe‚àíy) for 0 ‚â§x ‚â§1 e y ‚â•0,
 1
0
 y
0 2se‚àítdsdt = 1 ‚àíe‚àíy
for x > 1 e y ‚â•0,
0
otherwise.
(c) Consider now Z = X + Y. To compute P(Z) e œÉ2(Z) we use:
(i) the linearity property of the expectation:
P(Z) = P(X) + P(Y) = 2
3 + 1 = 5
3 ;

172
12
Absolutely Continuous and Multivariate Distributions
Fig. 12.14 The domain D of
deÔ¨Ånition of the joint density
0
1
(ii) the formula for the variance of the sum of 2 random numbers:
œÉ2(Z) = œÉ2(X + Y) = œÉ2(X) + œÉ2(Y) + 2cov(X, Y)
= œÉ2(X) + œÉ2(Y) = 19
18 .
To compute the distribution function of Z = X + Y, we use the fact that
FZ(z) = P(Z ‚â§z) = P(X + Y ‚â§z)
= P(Y ‚â§z ‚àíX)
=
 
Dz
f (s, t)dsdt ,
where for all Ô¨Åxed z, Dz is the region of the plane determined by the intersection
of the domain D of deÔ¨Ånition of the density and of the semi-plane
Sz = {(x, y)|y ‚â§z ‚àíx}.
Figures12.15 and 12.16 show the region intersected by Sz on D when z varies.
We obtain that:
(i) for z < 0, Fz(z) = 0;
(ii) for 0 < z < 1,
FZ(z) =
 z
0
2x
 z‚àíx
0
e‚àíydydx
=
 z
0
2x

1 ‚àíe‚àí(z‚àíx)
dx = z2 + 2(1 ‚àíz) ‚àí2e‚àíz ;

12
Absolutely Continuous and Multivariate Distributions
173
1
0
Fig. 12.15 Case 0 < z < 1
Fig. 12.16 Case z > 1
0
1

174
12
Absolutely Continuous and Multivariate Distributions
(iii) for z > 1
FZ(z) =
 1
0
 z‚àíx
0
2xe‚àíydydx =
 1
0
2x

1 ‚àíe‚àí(z‚àíx)
dx = 1 ‚àí2e‚àíz .
We obtain the density of Z by deriving the c.d.f. of Z, i.e.:
fZ(z) =
‚éß
‚é®
‚é©
2z ‚àí2 + 2e‚àíz for 0 ‚â§z < 1,
2e‚àíz
for z > 1,
0
otherwise.
‚ñ°
Exercise 12.7 The random numbers X and Y have bidimensional Gaussian density
p(x, y) =
1
2œÄ e‚àí1
2 (x2+y2) .
Let U = 2X + 3Y and V = X ‚àíY. Compute:
1. The covariance matrix of U and V .
2. The joint density of U and V .
Solution 12.7
1. We compute the covariance matrix of U and V :
C =
‚éõ
‚éù
œÉ2(U)
cov(U, V )
cov(U, V )
œÉ2(V )
‚éû
‚é†.
In order to compute C we use the formula of the variance of the sum of 2 random
numbers and the bilinearity of the covariance:
‚Ä¢ œÉ2(U)
œÉ2(U) = œÉ2(2X + 3Y)
= 4 œÉ2(X) + 9 œÉ2(Y) + 2 √ó 6 cov(X, Y)
= 13 ;
‚Ä¢ œÉ2(V )
œÉ2(V ) = œÉ2(X ‚àíY)
= œÉ2(X) + œÉ2(Y) ‚àí2 cov(X, Y)
= 2 ;

12
Absolutely Continuous and Multivariate Distributions
175
‚Ä¢ cov(U, V )
cov(U, V ) = cov(2X + 3Y, X ‚àíY)
= 2 œÉ2(X) ‚àí2 cov(X, Y) + 3 cov(X, Y) ‚àí3 œÉ2(Y)
= ‚àí1 .
The covariance matrix is
C =
‚éõ
‚éù
13
‚àí1
‚àí1
2
‚éû
‚é†.
2. To compute the joint density of (U, V ), we Ô¨Årst compute the joint c.d.f. of (U, V )
given by
F(u, v) = P(U ‚â§u, V ‚â§v) = P(2X + 3Y ‚â§u, X ‚àíY ‚â§v) .
This probability is given by the integral of the joint density on the domain Du,v
of R2 where
Du,v = {(x, y) ‚ààR2 | 2x + 3y ‚â§u, x ‚àíy ‚â§v} .
We obtain
F(u, v) =
 
Du,v
f (x, y) dx dy.
To solve the integral, we perform the change of variables
z = 2x + 3y,
t = x ‚àíy ,
to transform the domain Du,v into the region
ÀÜDu,v = {(x, y) ‚ààR2 | z ‚â§u, t ‚â§v} .
with sides which are parallel to the axes. If we now compute x, y as function of
z and t, we obtain
x = 1
5 (z + 3t),
y = 1
5 (z ‚àí2t) .
It follows that the Jacobian matrix is equal to
JŒ® =
‚éõ
‚éù
‚àÇŒ®1
‚àÇz
‚àÇŒ®1
‚àÇt
‚àÇŒ®2
‚àÇz
‚àÇŒ®2
‚àÇt
‚éû
‚é†=
‚éõ
‚éù
1
5
3
5
1
5 ‚àí2
5
‚éû
‚é†,

176
12
Absolutely Continuous and Multivariate Distributions
where (x, y) = Œ® (z, t) = (Œ®1(z, t), Œ®2(z, t)) =
z + 3t
5
, z ‚àí2t
5

, with
determinant
|det JŒ® | = 1
5 .
We obtain:
F(u, v) =
 
Du,v
f (x, y) dx dy
=
 
ÀÜDu,v
f (œà(z, t)) |det JŒ® | dz dt
=
 u
‚àí‚àû
 v
‚àí‚àû
1
2œÄ e
‚àí1
2

( z+3t
5 )
2+( z‚àí2t
5 )
2 1
5 dz dt
=
 u
‚àí‚àû
 v
‚àí‚àû
1
10œÄ e‚àí1
2 ¬∑ 1
25 (2z2+13t2+2zt) dz dt .
The joint density of (U, V ) is then
1
10œÄ e‚àí1
50 (2z2+13t2+2zt), z, t ‚ààR2 .
Note that (U, V ) have again joint Gaussian distribution with covariance matrix
equal to C.
To verify these results, compute the inverse matrix of A, where
A =
‚éõ
‚éù
2
25
1
25
1
25
13
25
‚éû
‚é†.
‚ñ°
Exercise 12.8 A random vector (X, Y, Z) has joint density given by
f (x, y, z) = k e‚àí1
2 (2x2‚àí2xy+y2+z2+2x‚àí6y) .
1. Compute k.
2. Compute the expectations P(X), P(Y) and P(Z).
3. Compute the density of the random vector (X, Z).
4. Compute the correlation coefÔ¨Åcient between X and Z and between X and Y.
5. Let W = X + Z; compute the probability density of W.

12
Absolutely Continuous and Multivariate Distributions
177
Solution 12.8
1. If we write the density in the standard form
f (x, y, z) = k e‚àí1
2 Av¬∑v+b¬∑v
where A is the symmetric matrix
A =
‚éõ
‚éú‚éú‚éú‚éú‚éù
2
‚àí1
0
‚àí1
1
0
0
0
1
‚éû
‚éü‚éü‚éü‚éü‚é†
,
b is the vector in R3
b =
‚éõ
‚éù
‚àí1
3
0
‚éû
‚é†,
and v is given by
v =
‚éõ
‚éù
x
y
z
‚éû
‚é†.
We can compute the normalization constant k as follows:
k =

det A
(2œÄ)3 e‚àí1
2 A‚àí1b¬∑b .
It is now sufÔ¨Åcient to calculate the determinant and the inverse matrix of A. We
obtain:
det A = 1,
A‚àí1 =
‚éõ
‚éú‚éú‚éú‚éú‚éù
1
1
0
1
2
0
0
0
1
‚éû
‚éü‚éü‚éü‚éü‚é†
from which
A‚àí1b =
‚éõ
‚éù
2
5
0
‚éû
‚é†

178
12
Absolutely Continuous and Multivariate Distributions
and
k = e‚àí1
2 A‚àí1b¬∑b

det A
(2œÄ)3 = e‚àí13
2

1
(2œÄ)3 .
2. The expectations of X, Y, Z are given respectively by
P(X) =

A‚àí1b

1 = 2 ,
P(Y) =

A‚àí1b

2 = 5 ,
P(Z) =

A‚àí1b

3 = 0 .
3. The random vector (X, Z) has bidimensional Gaussian density of covariance
matrix D given by
D =
‚éõ
‚éù

A‚àí1
11

A‚àí1
13

A‚àí1
31

A‚àí1
33
‚éû
‚é†=
‚éõ
‚éù
1
0
0
1
‚éû
‚é†
and vector d of expectations
d =
 2
0

.
To prove this, we derive the joint density fX,Z(x, z) from f (x, y, z) as follows:
fX,Z(x, z) =

R
f (x, y, z) dy
=

R
k e‚àí1
2 (2x2‚àí2xy+y2+z2+2x‚àí6y) dy
= e‚àí1
2 (2x2+z2+2x)

R
k e‚àí1
2 (y2‚àí2xy)+3y dy
= e‚àí1
2 (2x2+z2)‚àíx

R
k e‚àí1
2 y2+(3+x)y dy .
Here we can consider
I =

R
k e‚àí1
2 y2+(3+x)y dy
as the integral of a one-dimensional Gaussian distribution with coefÔ¨Åcients
depending on the parameter x. In the same notation as above, we obtain
A = 1
and
b = 3 + x ,

12
Absolutely Continuous and Multivariate Distributions
179
from which we obtain

R
k e‚àí1
2 y2+(3+x)y dy =

2œÄ
det Ae
1
2 A‚àí1b¬∑b
=
‚àö
2œÄe
1
2 (3+x)2 .
We can obtain the same result also by completing the square
‚àí1
2 y2 + (3 + x)y
in the integral I. It follows that
fX,Z(x, z) = k e‚àí1
2 (2x2+z2)‚àíx ¬∑
‚àö
2œÄ e
1
2 (3+x)2
= e‚àí13
2 + 9
2
2œÄ
e‚àí1
2 (x2+z2)+2x
= e‚àí2
2œÄ e‚àí1
2 (x2+z2)+2x .
4. The correlation coefÔ¨Åcient between X and Z can be obtained by the formula
œÅ(X, Z) = cov(X, Z)
œÉ(X) œÉ(Z) .
From the covariance matrix we have that
cov(X, Z) = 0 ,
hence
œÅ(X, Y) =
1
‚àö
2
‚àö
1
=
‚àö
2
2 .
5. The probability density of W can be computed via the formula
fW(w) =

R
fX,Z(x, w ‚àíx) dx .

180
12
Absolutely Continuous and Multivariate Distributions
Hence with the same method used above:
fW(w) =

R
e‚àí2
2œÄ e‚àí1
2 (x2+(w‚àíx)2)+2x dx
= e‚àí2
2œÄ e‚àí1
2 w2 
R
e‚àí1
2 (2x2)+(2+w)x dx
= e‚àí2
2œÄ e‚àí1
2 w2 ‚àöœÄe
1
2 √ó 1
2 (2+w)2
= e‚àí2+1
2‚àöœÄ e‚àí1
4 w2+w
=
1
2‚àöœÄ e‚àí1
4 (w‚àí2)2 .
The random number W has normal density with expectation
P(W) = P(X) + P(Z) = 2
and variance
œÉ2(W) = œÉ2(X) + œÉ2(Z) + 2cov(X, Z) = 2 .
‚ñ°

Chapter 13
Markov Chains
Exercise 13.1 A Markov chain (Xn)n ‚ààN with states S = {1, 2, 3, 4} has the
following transition matrix
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù
1
4
3
4 0 0
0 0
2
3
1
3
1
4 0
3
4 0
0
1
3 0
2
3
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†
and initial distribution
Œº(1) = Œº(2) = Œº(3) = Œº(4) = 1
4.
(a) Determine the equivalence classes of the states and their periods.
(b) Compute p(2)
2,1, p(2)
1,4, p(2)
1,1.
(c) Check the existence of the following limits and compute them, if they exist:
lim
n‚Üí‚àûp(n)
1,3
and
lim
n‚Üí‚àûP(Xn = 2).
Solution 13.1 (a) To determine equivalence classes of the states, we can draw a
graph of the transition probabilities by using the matrix P. We Ô¨Årst represent
the states (see Fig.13.1) and then connect with an arrow two states such that
the transition probability from one to the other is strictly positive. For example,
since
[P]1,2 = 3
4,
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_13
181

182
13
Markov Chains
Fig. 13.1 The states
4
1
2
3
Fig. 13.2 The chain has
positive probability of going
from 1 to 2
1
2
Fig. 13.3 The chain have
positive probability of
remaining in the state 1
1
Fig. 13.4 Graph of the
relations among the states
4
1
2
3
the chain has positive probability to go from the state 1 to the state 2 in one step.
We represent this on the graph by connecting 1 and 2 with an arrow going from
1 to 2, see Fig.13.2.
Analogously, [P]1,1 = 1
4 means that the chain has positive probability of remain-
ing in the state 1. This can be represented as illustrated in Fig.13.3.
By using this procedure we can construct the graph of Fig.13.4.
From the graph we deduce that all elements can communicate with each other,
i.e. there exists paths that connect each state to all the other ones with positive
probability. We conclude that there exists only one equivalence class [1].
Furthermore we can deduce from the graph that the period of the chain is 1, since
there exists a path of length 1 from state 1 to itself, i.e.
1 ‚àà{n | p(n)
1,1 > 0}.
(b) To compute p(2)
2,1, i.e. the probability of going in 2 steps from the state 2 to the
state 1, we write
p(2)
2,1 =

i‚ààS
p(1)
2,i p(1)
i,1 .
This formula shows how the probability of going in 2 steps from the state 2 to
the state 1 can be computed as the sum of the probabilities of all possible paths
from 2 to 1.
From the graph relative to the matrix P we obtain
p(2)
2,1 = p(1)
2,3 p(1)
3,1 = 2
3 ¬∑ 1
4 = 1
6.

13
Markov Chains
183
Note that we can compute p(2)
2,1 by taking the product of the matrix column with
the matrix row
p(2)
2,1 = P2 ¬∑ P1
where P2 denotes the second row and P1 the Ô¨Årst column of the matrix P.
Analogously we compute p(2)
1,4 and p(2)
1,1.
(c) Since the chain is irreducible and aperiodic, the ergodic theorem guarantees the
existence of the limit
lim
n‚Üí‚àûp(n)
1,3 = œÄ3,
where œÄ3 can be obtained by the solution of the linear system
œÄ =
tœÄ P
‚éß
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é©
œÄ1 =  œÄi pi,1
œÄ2 =  œÄi pi,2
œÄ3 =  œÄi pi,3
œÄ1 + œÄ2 + œÄ3 + œÄ4 = 1.
In this case
‚éß
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é©
œÄ1 = 1
4œÄ1 + 1
4œÄ3
œÄ2 = 3
4œÄ1 + 1
3œÄ4
œÄ3 = 2
3œÄ2 + 3
4œÄ3
4

i=1
œÄi = 1.
By using standard methods for the solution of linear systems of equations, we
obtain:
œÄ3 = 12
25.
Hence
lim
n‚Üí‚àûp(n)
1,3 = 12
25.

184
13
Markov Chains
To compute lim
n‚Üí‚àûP(Xn = 2), we note that
P(Xn = 2) =
4

i=1
P(Xn = 2|X0 = i)P(X0 = i) = 1
4
4

i=1
p(n)
i,2 .
Since for all i
lim
n‚Üí‚àûp(n)
i,2 = œÄ2,
we have
lim
n‚Üí‚àûP(Xn = 2) = lim
n‚Üí‚àû
1
4
4

i=1
p(n)
i,2 = 1
4 ¬∑ 4œÄ2 = œÄ2,
where œÄ2 = 9
50.
‚äì‚äî
Exercise 13.2 A Markov chain Xn, n = 0, 1, 2 . . . with states
S = {1, 2, 3, 4, 5, 6}
has the following transition matrix
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éù
0
1
3 0
1
3 0
1
3
1
2 0
1
2 0 0 0
0
1
3 0
2
3 0 0
0 0
2
3 0
1
3 0
0 0 0
1
2 0
1
2
1
3 0
1
3 0
1
3 0
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚é†
and initial distribution
Œº(1) = 1
3, Œº(2) = 2
3, Œº(3) = Œº(4) = Œº(5) = Œº(6) = 0.
1. Determine the equivalence classes of the states and their periods.
2. Check the existence of the following limits and compute them, if they exist:
lim
n‚Üí‚àûp(2n)
1,5 , lim
n‚Üí‚àûp(n)
3,5, lim
n‚Üí‚àûp(2n)
2,5 and lim
n‚Üí‚àûP(Xn = 5).
3. Compute P(X2 < 3).
Solution 13.2
1. As in the previous exercise, we draw the graph of the states as
in Fig.13.5, in order to determine the equivalence classes of the states and their
periods. We connect the states with an arrow in the case there exists a positive

13
Markov Chains
185
Fig. 13.5 Graph of the states
1
2
4
5
6
3
Fig. 13.6 Graph of the
probabilities of transition
1
2
4
5
6
3
probability to pass from the state, where the arrow starts, to the state where the
arrow ends.
By using the transition matrix P we obtain the graph shown in Fig.13.6, where
we can see that there exists only one equivalence class. We note that the number
of steps needed to come back to the state from where we started is always even.
Furthermore p(2)
1,1 > 0, hence it follows that the period of the equivalence class is
2. Namely
2 = MCD A+
s
where A+
s
= {n| p(n)
s,s > 0}.
2. Tostudythelimits,weconsidertheequivalenceclassesofthematrix P2;weobtain
two equivalence classes, each of period 1. To derive the equivalence classes, it
is not necessary to compute the whole matrix P2; for example, the equivalence
class of 1 will be given by all states that communicate with 1 with an even number
of steps. We obtain
[1] = {1, 3, 5},
[2] = {2, 4, 6}.
Since 2 and 5 do not communicate with an even number of steps, we immediately
have that
p(2n)
2,5
= 0
for all n, hence
lim
n‚Üí‚àûp(2n)
2,5
= 0.

186
13
Markov Chains
The state 5 belongs to the class [1] calculated with respect to P2. Hence we can
apply the ergodic theorem to that class, since it has period 1 with respect to P2.
The submatrix of P2 relative to [1] is given by:
‚éõ
‚éú‚éú‚éú‚éú‚éù
5
18
9
18
2
9
1
6
11
18
2
9
1
6
1
2
1
3
‚éû
‚éü‚éü‚éü‚éü‚é†
.
By the ergodic theorem we have that
lim
n‚Üí‚àûp(2n)
1,5
= œÄ5
where œÄ5 is the solution of the system
‚éß
‚é™‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é™‚é©
œÄ1 =
5
18œÄ1 + 1
6œÄ3 + 1
6œÄ5
œÄ3 =
9
18œÄ1 + 11
18œÄ3 + 1
2œÄ5
œÄ1 + œÄ3 + œÄ5 = 1.
We obtain
œÄ1 =
3
16
œÄ3 =
9
16
œÄ5 = 1
4.
Hence
lim
n‚Üí‚àûP(2n)
1,5
= 1
4.
To obtain the asymptotic behavior of p(n)
3,5 for n going to inÔ¨Ånity, we note that
(a) on the even steps, i.e. for n = 2k, we have
p(2k)
3,5 ‚àí‚àí‚àí‚Üí
k‚Üí‚àûœÄ5;
(b) on the odd steps, i.e. for n = 2k + 1, we have
p(2k+1)
3,5
= 0
since the probability of going from the state 3 to the state 5 in an odd number of
steps is zero. Since the limit on two subsequences is different, we can conclude
that
lim
n‚Üí‚àûp(n)
3,5

13
Markov Chains
187
does not exist. To compute
lim
n‚Üí‚àûP(Xn = 5),
we use the formula of total probability:
P(Xn = 5) =
6

i=1
P(Xn = 5|X0 = i) P(X0 = i)
6

i=1
p(n)
i,5 Œºi = 1
3 p(n)
1,5 + 2
3 p(n)
2,5.
We need to distinguish the following 2 cases:
(a) what happens on the even steps, i.e. for n = 2k. We have:
1
3 p(2k)
1,5 + 2
3 p(2k)
2,5
= 1
3 p(2k)
1,5
‚àí‚àí‚àí‚Üí
k‚Üí‚àû
œÄ5
3 ;
(b) what happens on the odd steps, i.e. for n = 2k + 1. We have:
1
3 p(2k+1)
1,5
+ 2
3 p(2k+1)
2,5
= 2
3 p(2k+1)
2,5
= 2
3
6

i=1
p(1)
2,i p(2k)
i,5 ,
that tends to 2
3 œÄ5
6

i=1
p(1)
2,i = 2
3œÄ5 for k ‚Üí‚àû, since we have that p(1)
2,i Ã∏= 0
for the i such that we have lim
k‚Üí‚àûp(2k)
i,5 = œÄ5.
Since we obtain different limits, we can conclude that the limit
lim
n‚Üí‚àûP(Xn = 5)
does not exist.
3. To compute P(X2 < 3) we note that
P(X2 < 3) =
2

i=1
P(X2 = i),
since the event (X2 < 3) = (X2 = 1) + (X2 = 2). It is then sufÔ¨Åcient to compute

188
13
Markov Chains
P(X2 = 1) =
6

i=1
P(X2 = 1|X0 = i) P(X0 = i)
=
6

i=1
p(2)
i,1 Œºi
= 1
3 p(2)
1,1 + 2
3 p(2)
2,1 = 5
54
and
P(X2 = 2) =
6

i=1
P(X2 = 2|X0 = i) P(X0 = i)
=
6

i=1
p(2)
i,2 Œºi
= 1
3 p(2)
1,2 + 2
3 p(2)
2,2 = 2
9.
Finally, P(X2 < 3) = 17
54.
‚äì‚äî
Exercise 13.3 A Markov chain Xn, n = 0, 1, 2 . . . with states
S = {1, 2, 3, 4}
has the following transition matrix
P =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù
0
1
2
1
2 0
2
3 0 0
1
3
1
6 0 0
5
6
0
3
4
1
4 0
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†
and initial distribution
Œº(1) = 1
3, Œº(2) = 1
3, Œº(3) = 1
3, Œº(4) = 0.
1. Determine the equivalence classes of the states and their periods.
2. Compute P(X5 = 2|X2 = 3), p(2)
1,4 and P(X2).
3. Check the existence of the following limits and compute them, if they exist:
lim
n‚Üí‚àûp(2n)
1,3 , lim
n‚Üí‚àûp(2n)
1,4 , lim
n‚Üí‚àûp(n)
2,3 and lim
n‚Üí‚àûP(Xn = 2).

13
Markov Chains
189
Fig. 13.7 Graph of the states
1
2
4
3
Solution 13.3
1. To Ô¨Ånd the equivalence classes we draw the graph of the states
as shown in Fig.13.7.
Since we can reach all other states by starting from the state 1 and the state 1
can be reached from all other states, there exists only one equivalence class.
Furthermore by starting from 1, we return to it always with only an even number
of steps and p(2)
1,1 > 0. We conclude that the period of the class is equal to 2.
2. To compute the conditional probability P(X5 = 2|X2 = 3) we use the fact that
the chain is homogeneous. It holds that
P(X5 = 2|X2 = 3) = p(3)
3,2 = [P3]3,2 = 0.
To compute this probability, we need to calculate the element on the row 3 and
column 2 of the matrix P3, We can obtain this element by multiplicating the third
row of P2 with the second column of P.
Anyways without any computation we can immediately state that the probability
of going from the state 3 to the state 2 in a odd number of steps is 0!
Furthermore
p(2)
1,4 = [P2]1,4 =
7
12.
We now compute the expectation of the state of the chain at time t = 2 by using
the formulas of the expectation of a random number with discrete distribution
and of the total probabilities:
P(X2) =
4

i=1
i P(X2 = i)
=
4

i=1
i
4

j=1
P(X2 = i|X0 = j) P(X0 = j)
=
4

i=1
i
3 (P(X2 = i|X0 = 1) + P(X2 = i|X0 = 2) + P(X2 = i|X0 = 3))
=
4

i=1
i
3

[P2]1,i + [P2]2,i + [P2]3,i

.

190
13
Markov Chains
The matrix of P2 is given by:
P2 =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù
5
12
0
0
7
12
0
7
12
5
12
0
0
17
24
7
24
0
13
24
0
0
11
24
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†
.
Hence the expectation of X2 is then:
P(X2) = 1
3
 5
12 + 2
 7
12 + 17
24

+ 3
 5
12 + 7
24

= 41
24.
3. We now compute the limits. The Markov chain observed on the even steps can
be considered as a Markov chain with transition matrix equal to P2. We can
immediately see that the state 3 cannot be reached from the state 1 with an even
number of steps. In fact, the equivalence classes relative to P2 are given by
[1] = {1, 4},
[2] = {2, 3}.
It follows that
lim
n‚Üí‚àûp(2n)
1,3
= 0.
The state 4 belongs to the equivalence class [1] relative to P2. This class has
period 1. Hence we can apply the ergodic theorem to this irreducible aperiodic
subchain to compute
lim
n‚Üí‚àûp(2n)
1,4 .
If we put œÄ4 =
lim
n‚Üí‚àûp(2n)
1,4 and œÄ1 =
lim
n‚Üí‚àûp(2n)
1,1 , by the ergodic theorem we
obtain
‚éß
‚é®
‚é©
œÄ1 + œÄ4 = 1
5
12 œÄ1 + 13
24 œÄ4 = œÄ1.

13
Markov Chains
191
The solution of the system is
œÄ1 = 13
27,
œÄ4 = 14
27.
It follows that
lim
n‚Üí‚àûp(2n)
1,4
= 14
27.
To compute lim
n‚Üí‚àûp(n)
2,3 we observe the behavior of the chain on the even steps and
on the odd ones.
(a) First we note that 2 ‚àà[3] relative to P2.
By the ergodic theorem we have that on the even steps (i.e. if n = 2k)
p(2k)
2,3
‚àí‚àí‚àí‚Üí
k‚Üí‚àûœÄ3
where œÄ3 is the solution of the system
‚éß
‚é®
‚é©
œÄ2 + œÄ3 = 1
5
12 œÄ2 + 7
24 œÄ3 = œÄ3.
(b) There exists no path with an odd number of steps from the state 2 to the state
3, hence
p2,3(2k + 1) = 0
‚àÄk.
We can obtain the same result by computing
p(2k+1)
2,3
=

j
p(2k)
2, j p j,3(1)
= p(2k)
2,1 p1,3(1) + p(2k)
2,4 p4,3(1) = 0.
Summing up
p(2k)
2,3 ‚àí‚àí‚àí‚Üí
k‚Üí‚àûœÄ3 > 0
p(2k+1)
2,3
‚àí‚àí‚àí‚Üí
k‚Üí‚àû0.
Hence the limit lim
n‚Üí‚àûp(n)
2,3 does not exist.

192
13
Markov Chains
Finally, to compute lim
n‚Üí‚àûP(Xn = 2) we proceed as in the previous case. First we
use the formula of the total probability to compute P(Xn = 2):
P(Xn = 2) =
4

i=1
P(Xn = 2|X0 = i) P(X0 = i)
= 1
3 (P(Xn = 2|X0 = 1) + P(Xn = 2|X0 = 2) + P(Xn = 2|X0 = 3))
= 1
3

p(n)
1,2 + p(n)
2,2 + p(n)
3,2

.
By using the results above, we obtain
(a) if n = 2k
1
3

p(2k)
1,2 + p(2k)
2,2 + p(2k)
3,2

= 1
3

p(2k)
2,2 + p(2k)
3,2

which tends to 2
3œÄ2 for k ‚Üí‚àû;
(b) if n = 2k + 1
1
3

p(2k+1)
1,2
+ p(2k+1)
2,2
+ p(2k+1)
3,2

= 1
3 p(2k+1)
1,2
= 1
3
4

i=1
p(1)
1,i p(2k)
i,2
= 1
3

p(1)
1,2 p(2k)
2,2 + p(1)
1,3 p(2k)
3,2

which tends to 1
3 œÄ2

p(1)
1,2 + p(1)
1,3

= 1
3 œÄ2 for k ‚Üí‚àû.
Summing up, if we put pn = P(Xn = 2), we have that
p2n ‚àí‚àí‚àí‚Üí
n‚Üí‚àû
2
3œÄ2,
p2n+1 ‚àí‚àí‚àí‚Üí
n‚Üí‚àû
1
3 œÄ2,
i.e. the limit lim
n‚Üí‚àûP(Xn = 2) does not exist.
‚äì‚äî
Exercise 13.4 A Markov chain (Xn)n ‚ààN with states S = {1, 2, 3, 4, 5} has the fol-
lowing transition matrix

13
Markov Chains
193
Fig. 13.8 Graph of states
5
1
2
3
4
P =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù
0 1
2
1
2 0 0
1
2 0 1
2 0 0
0 2
3 0 1
3 0
0 0 2
3 0 1
3
2
3 0 0 1
3 0
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†
and initial distribution
Œº(1) = 0, Œº(2) = 2
3, Œº(3) = 1
3, Œº(4) = Œº(5) = 0.
(a) Determine the equivalence classes of the states and their periods.
(b) Check the existence of the following limits and, if they exist, compute them:
lim
n‚Üí‚àûp(n)
1,5, lim
n‚Üí‚àûp(n)
3,5, lim
n‚Üí‚àû(p(n)
2,3 + p(n)
3,5), lim
n‚Üí‚àûP(Xn = 5).
(c) Compute P(X1 ‚â§2) and P(X2 = 5).
Solution 13.4 (a) To determine the equivalence classes of the states and their peri-
ods we draw the graph of the states, see Fig.13.8.
We Ô¨Årst note that all the states comunicate among each other. Consider the set
A+
1 = {n| p(n)
11 > 0}
i.e. the set of the lengths of the paths that starts and ends in 1. We note that there
exists a path of length 2 (for example, from 1 to 2 and from 2 to 1) and of length
3 (from 1 to 3, from 3 to 2, from 2 to 1). We have
2, 3 ‚ààA+
1 .
The period d of the equivalence class [1] is given by
d = MC D(A+
1 ),

194
13
Markov Chains
hence d must be equal to 1 since it must divide 2 and 3. We conclude that there
exists only one equivalence class of period 1.
(b) By the ergodic theorem it follows that all the limits exist since the chain has a
unique equivalence class of period 1. First we note that
lim
n‚Üí‚àûp(n)
1,5 = lim
n‚Üí‚àûp(n)
3,5 = œÄ5
since the starting state (1 to 3) does not count. Furthermore
lim
n‚Üí‚àû(p(n)
2,3 + p(n)
3,5) = lim
n‚Üí‚àûp(n)
2,3 + lim
n‚Üí‚àûp(n)
3,5
= œÄ3 + œÄ5
and Ô¨Ånally
lim
n‚Üí‚àûP(Xn = 5) = lim
n‚Üí‚àû
5

i=1
P(Xn = 5|X0 = i)P(X0 = i)
= lim
n‚Üí‚àû
5

i=1
Œº(i)p(n)
i,5
= œÄ5
5

i=1
Œº(i) = œÄ5 ¬∑ 1 = œÄ5,
since lim
n‚Üí‚àûp(n)
i,5 = œÄ5, ‚àÄi = 1, . . . , 5 and 5
i=1 Œº(i) = 1. To obtain œÄi, it is suf-
Ô¨Åcient to solve the system
œÄ = œÄt P
5
i=1 œÄi = 1
i.e.
‚éß
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é©
œÄ1 = 1
2œÄ2 + 2
3œÄ5
œÄ2 = 1
2œÄ1 + 2
3œÄ3
œÄ4 = 1
3œÄ3 + 1
3œÄ5
œÄ5 = 1
3œÄ4
5
i=1 œÄi = 1.
In this system we have already taken out a redundant equation. We obtain
œÄ3 =
7
540
e œÄ5 = 14
135.

13
Markov Chains
195
Hence, summing up
lim
n‚Üí‚àûp(n)
1,5 = lim
n‚Üí‚àûp(n)
3,5 = lim
n‚Üí‚àûP(Xn = 5) = œÄ5 = 14
135,
lim
n‚Üí‚àû

p(n)
2,3 + p(n)
3,5

= œÄ3 + œÄ5 =
7
540 + 14
135 = 7
60.
(c) To compute the probabilities, we note that
P(X1 ‚â§2) = P(X1 = 1) + P(X1 = 2)
=
5

i=1
P(X1 = 1|X0 = i)Œº(i) +
5

i=1
P(X1 = 2|X0 = i)Œº(i)
= 2
3 p2,1 + 1
3 p3,1 + 2
3 p2,2 + 1
3 p3,2
= 1
3 + 2
9 = 5
9.
The second probability can be computed by using the formula of the total prob-
ability:
P(X2 = 5) =
5

i=1
P(X2 = 5|X0 = i)Œº(i)
= 2
3 p(2)
2,5 + 1
3 p(2)
3,5
= 2
3[P2]2,5 + 1
3[P2]3,5
= 1
3 ¬∑ 1
9 = 1
27.
‚äì‚äî

Chapter 14
Statistics
Exercise 14.1 The events E1, E2, . . . are stochastically independents subordinately
to the random parameter Œò with P(Ei|Œò = Œ∏) = Œ∏. The a priori density of Œò is
given by
œÄ0 =
‚éß
‚é®
‚é©
3 Œ∏2 0 ‚â§Œ∏ ‚â§1,
0
otherwise.
We observe the values of the Ô¨Årst 4 events:
E1 = 0, E2 = 1, E3 = 1, E4 = 1.
1. Compute the a posteriori density œÄ4(Œò|E1 = 0, E2 = 1, E3 = 1, E4 = 1) of Œò.
2. Compute the a priori probability that Œò belongs to the interval
1
2, 1

.
3. Compute the a posteriori probability that Œò belongs to the interval
1
2, 1

.
4. Compute arg max œÄ4(Œò|E1 = 0, E2 = 1, E3 = 1, E4 = 1).1
5. Compute the a posteriori expectation of E = E5 ‚àßE6.
Solution 14.1
1. The a posteriori density can be computed by using the formula
œÄ4(Œò|E1 = 0, E2 = 1, E3 = 1, E4 = 1)
= kP(E1 = 0, E2 = 1, E3 = 1, E4 = 1|Œò = Œ∏)œÄ0(Œ∏).
1Here and in the sequel, for a given function f we denote by arg max( f ) the points where f achieves
its maximum.
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_14
197

198
14
Statistics
Since the events Ei are stochastically independent subordinately to the random
parameter Œò, the probability
P(E1 = 0, E2 = 1, E3 = 1, E4 = 1|Œò = Œ∏)
can be factorized in
P(E1 = 0, E2 = 1, E3 = 1, E4 = 1|Œò = Œ∏)
= P(E1 = 0|Œò = Œ∏) ¬∑ P(E2 = 1|Œò = Œ∏)P(E3 = 1|Œò = Œ∏) ¬∑ P(E4 = 1|Œò = Œ∏)
= (1 ‚àíŒ∏) ¬∑ Œ∏ ¬∑ Œ∏ ¬∑ Œ∏.
Hence the a posteriori density is given by
œÄ4(Œò|E1 = 0, E2 = 1, E3 = 1, E4 = 1) = kŒ∏5(1 ‚àíŒ∏),
where k is a normalization constant. Since the a posteriori density œÄ4 corresponds
to a beta distribution B(6, 2), we have
k =
Œì (6 + 2)
Œì (6)Œì (2) = 7!
5! = 42.
2. The a priori probability that Œò belongs to the interval
1
2, 1

is given by:
P(1
2 ‚â§Œò ‚â§1) =
 1
1
2
œÄ0(Œ∏) dŒ∏
=
 1
1
2
3 Œ∏2 dŒ∏ =

Œ∏3	1
1
2 = 7
8.
3. The a posteriori probability that Œò belongs to the interval
1
2, 1

is given by:
P(1
2 ‚â§Œò ‚â§1|E1 = 0, E2 = E3 = E4 = 1)
=
 1
1
2
œÄ4(Œ∏|E1 = 0, E2 = E3 = E4 = 1) dŒ∏
= 42
 1
1
2
(Œ∏5 ‚àíŒ∏6) dŒ∏ = 42
Œ∏6
6 ‚àíŒ∏7
7
1
1
2
= 15
16.
4. By calculating the derivative
d
dŒ∏œÄ4(Œ∏|E1 = 0, E2 = 1, E3 = 1, E4 = 1) = 42 Œ∏4(5 ‚àí6Œ∏),

14
Statistics
199
we have that it is equal 0 in ¬ØŒ∏ = 5
6. Since
d2
d2Œ∏œÄ4


Œ∏= 5
6 = 42 Œ∏3(20 ‚àí30Œ∏)


Œ∏= 5
6 < 0,
we can conclude that arg max œÄ4(Œò|E1 = 0, E2 = 1, E3 = 1, E4 = 1) = 5
6.
5. The a posteriori expectation of the event
E = E5 ‚àßE6 = min(E5, E6) = E5E6
coincides with its a posteriori probability
P(E5E6|E1 = 0, E2 = E3 = E4 = 1)
=
 1
0
P(E5E6|Œ∏)P(Œ∏|E1 = 0, E2 = E3 = E4 = 1) dŒ∏
=
 1
0
P(E5E6|Œ∏)œÄ4(Œ∏|E1 = 0, E2 = E3 = E4 = 1) dŒ∏
=
 1
0
P(E5|Œ∏)P(E6|Œ∏) ¬∑ 42 Œ∏5 (1 ‚àíŒ∏) dŒ∏
=
 1
0
Œ∏2 42 Œ∏5 (1 ‚àíŒ∏) dŒ∏
= 42
 1
0
Œ∏7 (1 ‚àíŒ∏) dŒ∏
=
Œì (8)
Œì (6) Œì (2) ¬∑ Œì (8) Œì (2)
Œì (10)
= Œì (8)
Œì (6) ¬∑ 7 ¬∑ 6 ¬∑ Œì (6)
9 ¬∑ 8 ¬∑ Œì (8)
= 7
12.
Here we have used the following formula2
 1
0
Œ∏Œ±‚àí1(1 ‚àíŒ∏)Œ≤‚àí1 dŒ∏ = Œì (Œ±) Œì (Œ≤)
Œì (Œ± + Œ≤) .
‚äì‚äî
Exercise 14.2 The events E1, E2, . . . are stochastically independents subordinately
to Œò with P(Ei|Œò = Œ∏) = Œ∏. The a priori density Œò is given by
2For this, see the proof for the density of the sum of Œì (Œ±, Œª) + Œì (Œ≤, Œª), where Œì (Œ±, Œª), Œì (Œ≤, Œª)
are stochastically independent.

200
14
Statistics
œÄ0 =
‚éß
‚é®
‚é©
K Œ∏2 (1 ‚àíŒ∏) 0 ‚â§Œ∏ ‚â§1,
0
otherwise.
We observe the values of the Ô¨Årst 5 events:
E1 = 0, E2 = 1, E3 = 1, E4 = 0, E5 = 1.
1. Compute the normalization constant K.
2. Compute the a posteriori density of the event Œò and the a posteriori probability
of (Œò < 1
2).
3. Compute the a posteriori expectation of X
=
E6 + E7 and the a posteriori
probabilities of E = E6E7 and F = E6 ‚à®E7.
Solution 14.2
1. To compute the constant k, we impose that the integral of the
density is equal to 1, i.e.
 1
0
œÄ0(Œ∏) dŒ∏ = 1.
It follows that
k =
1
 1
0 Œ∏2 (1 ‚àíŒ∏) dŒ∏
.
The value of this integral is well-known and equal to:
 1
0
Œ∏2 (1 ‚àíŒ∏) dŒ∏ = Œì (3) Œì (2)
Œì (3 + 2) ,
hence
k =
Œì (3 + 2)
Œì (3) Œì (2) =
4!
2! ¬∑ 1! = 12.
2. The a posteriori density is given by
œÄ5(Œò|E1 = 0, E2 = E3 = 1, E4 = 0, E5 = 1)
= œÄ0(Œ∏)P(E1 = 0, E2 = E3 = 1, E4 = 0, E5 = 1|Œ∏)
= œÄ0(Œ∏)P(E1 = 0|Œ∏)P(E2 = 1|Œ∏)P(E3 = 1|Œ∏)P(E4 = 0|Œ∏)P(E5 = 1|Œ∏)
= c ¬∑ Œ∏2 (1 ‚àíŒ∏) ¬∑ (1 ‚àíŒ∏)2 Œò3
= c ¬∑ Œ∏5 (1 ‚àíŒ∏)3.
Here we denote with c the normalization constant of the a posteriori density. In
this case the a posteriori probability distribution is a beta B(6, 4). It follows that

14
Statistics
201
c =
Œì (6 + 4)
Œì (6) Œì (4) =
9!
5! 3! = 7 ¬∑ 8 ¬∑ 9 = 504.
If we put W =
ÀúE1 E2 E3 ÀúE4 E5, the a posteriori density is given by
œÄ5(Œ∏) =
‚éß
‚é®
‚é©
504 Œ∏5 (1 ‚àíŒ∏)3 0 ‚â§Œ∏ ‚â§1,
0
otherwise.
To Ô¨Ånd the a posteriori probability of the event (Œò < 1
2) it is sufÔ¨Åcient to integrate
the a posteriori density between 0 and 1
2:
P(Œò < 1
2) = 504

1
2
0
Œ∏5 (1‚àíŒ∏)3dŒ∏ = 504

1
2
0
(Œ∏5 +3Œ∏7 ‚àí3Œ∏6 ‚àíŒ∏8)dŒ∏ = 65
256.
3. The a posteriori expectation of X = E6 + E7 is given by
P(X|W) =
2

i=0
i P(X = i|W)
= P(X = 1|W) + 2 P(X = 2|W).
We obtain:
P(X = 1|W) = P(E6 = 1, E7 = 0|W) + P(E6 = 0, E7 = 1|W)
= 2
 1
0
P(E6 = 0, E7 = 1|Œò = Œ∏)œÄ5(Œò = Œ∏|W) dŒ∏
= 2
 1
0
Œì (10)
Œì (6) Œì (4)Œ∏ ¬∑ (1 ‚àíŒ∏) ¬∑ Œ∏5 ¬∑ (1 ‚àíŒ∏)3 dŒ∏
= 2
Œì (10)
Œì (6) Œì (4)
 1
0
Œ∏6(1 ‚àíŒ∏)4 dŒ∏
= 2
Œì (10)
Œì (6) Œì (4)
Œì (7) Œì (5)
Œì (12)
= 24
55
and
P(X = 2|W) = P(E6 = 1, E7 = 1|W)
=
 1
0
P(E6 = 1, E7 = 1|Œ∏ = Œò)œÄ5(Œò = Œ∏|W) dŒ∏

202
14
Statistics
=
Œì (10)
Œì (6) Œì (4)
 1
0
Œ∏2 ¬∑ Œ∏5 ¬∑ (1 ‚àíŒ∏)3 dŒ∏
=
Œì (10)
Œì (6) Œì (4)
 1
0
Œ∏7(1 ‚àíŒ∏)3 dŒ∏
=
Œì (10)
Œì (6) Œì (4)
Œì (8) Œì (4)
Œì (12)
= 21
55.
The a posteriori expectation of X is equal to
P(X|W) = 2 ¬∑ 21
55 + 24
55 = 6
5.
Note that X = E6 + E7 is a random number, but not an event since it can assume
3 possible values: 0, 1 or 2.
The a posteriori probability of the events E = E6 E7 e F = E6 ‚à®E7 can be
calculated in the same way:
P(E|W) = P(E6E7 = 1|W) = P(E6 = E7 = 1|W) = 21
55
and
P(F|W) = P(E6 ‚à®E7 = 1|W)
= P(E6 = 1, E7 = 0|W)
+ P(E6 = 0, E7 = 1|W)
+ P(E6 = 1 = E7 = 1|W)
= 9
11.
‚äì‚äî
Exercise 14.3 The events E1, E2, . . . are stochastically independents subordinately
to Œò with P(Ei|Œò = Œ∏) = Œ∏. The a prior density Œò is given by
œÄ0(Œ∏) =
 KŒ∏2(1 ‚àíŒ∏)2 for 0 ‚â§Œ∏ ‚â§1,
0
otherwise.
We observe the values of the Ô¨Årst 4 events: E1 = 0, E2 = 1, E3 = E4 = 1.
(a) Compute the normalization constant K.
(b) Compute the a posteriori density and the a posteriori expectation of Œò.
(c) Compute the a posteriori probability of the event F = E2
5 and the a posteriori
variance of expectation of ÀúE6.

14
Statistics
203
Solution 14.3 (a) To compute K we impose that
 1
0
œÄ0(Œ∏)dŒ∏ = 1
i.e.
K =
1
 1
0 Œ∏2(1 ‚àíŒ∏)2dŒ∏
,
since the integral of a probability density must be equal to 1. The integral appear-
ing at the denominator is well-known and equal to
 1
0
Œ∏2(1 ‚àíŒ∏)2dŒ∏ = Œì (3)2
Œì (6)
hence
K = Œì (6)
Œì (3)2 =
5!
(2!)2 = 30.
(b) The a posteriori density of Œò given the events E1 = 0, E2 = E3 = E4 = 1 is
given by the formula
œÄ4(Œ∏|E1 = 0, E2 = 1, E3 = 1, E4 = 1)
= KœÄ0(Œ∏)P(E1 = 0, E2 = 1, E3 = 1, E4 = 1|Œ∏)
= P(E1 = 0|Œ∏) ¬∑ P(E2 = 1|Œ∏) ¬∑ P(E3 = 1|Œ∏) ¬∑ P(E4 = 1|Œ∏)
= KŒ∏5(1 ‚àíŒ∏)3,
where K =
Œì (10)
Œì (6)Œì (4) = 504 and Œ∏ ‚àà[0, 1]. For Œ∏ /‚àà[0, 1], the a posteriori
density is equal to 0. To compute the a posteriori expectation of Œò, we apply the
formula of the expectation for absolutely continuous distributions, i.e.
P(Œò|E1 = 0, E2 = E3 = E4 = 1)
=
 1
0
Œ∏œÄ4(Œ∏|E1 = 0, E2 = 1, E3 = 1, E4 = 1)dŒ∏
=
Œì (10)
Œì (6)Œì (4)
 1
0
Œ∏6(1 ‚àíŒ∏)3dŒ∏
=
Œì (10)
Œì (6)Œì (4) ¬∑ Œì (7)Œì (4)
Œì (11)
= 3
5.

204
14
Statistics
(c) The event F = E2
5 coincides with E5 since it assumes only the value 0 or 1. The
a posteriori probability of F is given by
P(F|E1 = 0, E2 = 1, E3 = 1, E4 = 1)
= P(E2
5|E1 = 0, E2 = 1, E3 = 1, E4 = 1)
= P(E5|E1 = 0, E2 = 1, E3 = 1, E4 = 1)
=
 1
0
Œ∏œÄ4(Œ∏|E1 = 0, E2 = 1, E3 = 1, E4 = 1)dŒ∏ = 3
5.
To compute the a posteriori variance of ÀúE6, we consider the usual formula for
the variance. To simplify the notations, we put A = E1E2E3E4. We obtain
œÉ2( ÀúE6|E1E2E3E4)
= P( ÀúE2
6|E1E2E3E4) ‚àíP( ÀúE6|E1E2E3E4)2
= P( ÀúE6|E1E2E3E4) ‚àíP( ÀúE6|E1E2E3E4)2
= P( ÀúE6|E1E2E3E4)(1 ‚àíP( ÀúE6|E1E2E3E4)),
where we have used that
ÀúE2
6 = ÀúE6.
We need only to compute the a posteriori expectation of ÀúE6. For this purpose we
apply the formula of the total probabilities. Hence
P( ÀúE2
6|E1E2E3E4) = P( ÀúE6|E1E2E3E4)
= P( ÀúE6E5|E1E2E3E4)
+ P( ÀúE6 ÀúE5|E1E2E3E4)
=
 1
0
P( ÀúE6E5|Œ∏)œÄ4(Œ∏|E1E2E3E4)dŒ∏
+
 1
0
P( ÀúE6 ÀúE5|Œ∏)œÄ4(Œ∏|E1E2E3E4)dŒ∏
=
 1
0
Œ∏(1 ‚àíŒ∏)œÄ4(Œ∏|E1E2E3E4)dŒ∏
+
 1
0
(1 ‚àíŒ∏)(1 ‚àíŒ∏)œÄ4(Œ∏|E1E2E3E4)dŒ∏
=
 1
0
(1 ‚àíŒ∏)[Œ∏ + 1 ‚àíŒ∏]œÄ4(Œ∏|E1E2E3E4)dŒ∏
=
 1
0
(1 ‚àíŒ∏)œÄ4(Œ∏|E1E2E3E4)dŒ∏

14
Statistics
205
= 1 ‚àí
 1
0
Œ∏œÄ4(Œ∏|E1E2E3E4)dŒ∏
= 2
5.
Note that the a posteriori probabilities of E5 and E6 coincide.
‚äì‚äî
Exercise 14.4 The events E1, E2, . . . are stochastically independent subordinately
to Œò with P(Ei|Œò = Œ∏) = Œ∏. The a priori density of Œò is given by
œÄ0(Œ∏) =

KŒ∏2‚àö
1 ‚àíŒ∏ for 0 ‚â§Œ∏ ‚â§1,
0
otherwise.
We observe the values of the Ô¨Årst 4 events: E1 = 1, E2 = 0, E3 = 0, E4 = 1.
(a) Compute the normalization constant K.
(b) Compute the a posteriori density œÄ4(Œ∏|E1 = 1, E2 = E3 = 0, E4 = 1) of Œò
and arg max œÄ4(Œ∏|E1 = 1, E2 = E3 = 0, E4 = 1).
(c) Compute the a posteriori covariance of the events E6 and E7.
Solution 14.4 (a) The normalization constant K makes the integral of the density
equal to 1, hence
K =
1
 1
0 Œ∏2(1 ‚àíŒ∏)
1
2 dŒ∏
.
We know that
 1
0
Œ∏2(1 ‚àíŒ∏)
1
2 dŒ∏ = Œì (3)Œì
 3
2

Œì

3 + 3
2
 ,
hence
K =
Œì
 9
2

Œì (3)Œì
 3
2
 =
7
2 ¬∑ 5
2 ¬∑ 3
2 ¬∑ Œì
 3
2

2!Œì
 3
2

= 105
16 .
(b) We compute the a posteriori density by using the fact that the events are stochas-
tically independent subordinately to Œò. We have
œÄ4(Œ∏|E1 = 1, E2 = E3 = 0, E4 = 1)
= KP(E1 = 1, E2 = E3 = 0, E4 = 1|Œ∏)œÄ0(Œ∏)
= KP(E1 = 1|Œ∏) ¬∑ P(E2 = 0|Œ∏) ¬∑ P(E3 = 0|Œ∏) ¬∑ P(E4 = 1|Œ∏)œÄ0(Œ∏)
= KŒ∏4(1 ‚àíŒ∏)
5
2 ,

206
14
Statistics
where
K = Œì

5 + 7
2

Œì (5)Œì
 7
2
 =
15
2 ¬∑ 13
2 ¬∑ 11
2 ¬∑ 9
2Œì
 7
2

Œì (5)Œì
 7
2

= 6435
128 .
Hence
œÄ4(Œ∏|E1 = 1, E2 = E3 = 0, E4 = 1) =
‚éß
‚é™‚é®
‚é™‚é©
6435
128 Œ∏4(1 ‚àíŒ∏)
5
2 Œ∏ ‚àà[0, 1],
0
otherwise.
The arg max can be computed by Ô¨Ånding the zeros of the Ô¨Årst derivative. We
have
œÄ‚Ä≤
4(Œ∏|E1 = 1, E2 = E3 = 0, E4 = 1) = K

4Œ∏3(1 ‚àíŒ∏)
5
2 ‚àí5
2Œ∏4(1 ‚àíŒ∏)
3
2

= KŒ∏3(1 ‚àíŒ∏)
3
2

4(1 ‚àíŒ∏) ‚àí5
2Œ∏

= K Œ∏3
2 (1 ‚àíŒ∏)
3
2 [8 ‚àí13Œ∏].
The derivative is equal to 0 in the extremes of the interval as well in
¬ØŒ∏ = 8
13.
Since œÄ‚Ä≤
4 > 0 for Œ∏ ‚àà

0, 8
13

and œÄ‚Ä≤
4 < 0 for Œ∏ ‚àà
 8
13, 1

, we have that
arg max œÄ4(Œ∏|E1 = 1, E2 = E3 = 0, E4 = 1) = 8
13.
(c) The a posteriori covariance of the events E6 and E7 is given by
cov(E6, E7|E1 = 1, E2 = E3 = 0, E4 = 1)
= P(E6E7|E1 = 1, E2 = E3 = 0, E4 = 1)
‚àíP(E6|E1 = 1, E2 = E3 = 0, E4 = 1)P(E7|E1 = 1, E2 = E3 = 0, E4 = 1).
In Exercise 14.3 we have proved that
P(E6|E1 = 1, E2 = E3 = 0, E4 = 1)
= P(E7|E1 = 1, E2 = E3 = 0, E4 = 1)
=
 1
0
Œ∏œÄ4(Œ∏|E1 = 1, E2 = E3 = 0, E4 = 1)dŒ∏ = 10
17.

14
Statistics
207
Analogously
P(E6E7|E1 = 1, E2 = E3 = 0, E4 = 1)
=
 1
0
Œ∏2œÄ4(Œ∏|E1 = 1, E2 = E3 = 0, E4 = 1)dŒ∏ = 120
323.
We conclude that
cov(E6, E7|E1 = 1, E2 = E3 = 0, E4 = 1) = 120
323 ‚àí
10
17
2
.
‚äì‚äî
Exercise 14.5 The random numbers X1, X2, . . . are stochastically independents
subordinately to Œò with the same conditional marginal density given by
f (x|Œ∏) =
1
‚àö
2œÄ
exp

‚àí(x ‚àíŒ∏)2
2

,
x ‚ààR.
We assume that Œò has standard normal distribution. We observe the values of the
Ô¨Årst 4 experiments:
x1 = 0.1,
x2 = 2,
x3 = ‚àí1,
x4 = 0.5.
(a) Write the a priori density of Œò.
(b) Compute the a posteriori density œÄ4(Œ∏| x1 = 0.1, x2 = 2, x3 = ‚àí1, x4 = 0.5)
of Œò and arg max œÄ4(Œ∏| x1 = 0.1, x2 = 2, x3 = ‚àí1, x4 = 0.5).
(c) Compute the a posteriori expectation and variance of Œò.
Solution 14.5 (a) SinceŒò hasastandardnormaldistributionasaprioridistribution,
we can write immediately the a priori density
œÄ0(Œ∏) =
1
‚àö
2œÄ
e‚àíŒ∏2
2 ,
Œ∏ ‚ààR.
(b) We compute the a posteriori density by using the fact that the random numbers
are stochastically independent subordinately to Œò:
œÄ4(Œ∏| x1 = 0.1, x2 = 2, x3 = ‚àí1, x4 = 0.5)
= k f (x1, x2, x3, x4|Œ∏)œÄ0(Œ∏)
= k4
i=1 f (xi|Œ∏)œÄ0(Œ∏) = k exp

‚àí
4
i=1(xi ‚àíŒ∏)2 + Œ∏2
2

= k exp

‚àí5
2(Œ∏ ‚àí8
25)2

,

208
14
Statistics
NotethatallfactorswhichareindependentofŒ∏ arenowincludedintheconstantk.
We obtain that the a posteriori distribution is Gaussian N( 8
25, 1
5), hence
k =
‚àö
5
‚àö
2œÄ
.
The graph of the a posteriori density is bell shaped with symmetry axis x = 8
25.
Then arg max œÄ4(Œ∏| x1 = 0.1, x2 = 2, x3 = ‚àí1, x4 = 0.5) =
8
25. Verify this by
computing the derivatives of the density function.
(c) The parameters of the a posteriori density provide us with:
1. the a posteriori expectation
P(Œò| x1 = 0.1, x2 = 2, x3 = ‚àí1, x4 = 0.5) = 8
25;
2. the a posteriori variance
œÉ2(Œò| x1 = 0.1, x2 = 2, x3 = ‚àí1, x4 = 0.5) = 1
5.
‚äì‚äî
Exercise 14.6 The random numbers X1, X2, . . . are stochastically independent sub-
ordinately to Œò with the same conditional marginal density given by
f (x|Œ∏) =
1
2
‚àö
2œÄ
exp

‚àí(x ‚àíŒ∏)2
8

,
x ‚ààR.
The a priori distribution of Œò is given by
œÄ0(Œ∏) =
1
‚àö
4œÄ
exp

‚àí(Œ∏ ‚àí1)2
4

,
Œ∏ ‚ààR.
We observe the values of the Ô¨Årst 3 experiments:
x1 = 1,
x2 = 0.5,
x3 = ‚àí1.
(a) Compute the likelihood factor.
(b) Compute the a posteriori density of Œò.
(c) Estimate the a posteriori probability of the event (Œò > 1000).

14
Statistics
209
Solution 14.6 (a) By deÔ¨Ånition, the likelihood factor is given by
f (x1, x2, x3|Œ∏) = 3
i=1 f (xi|Œ∏)
=
1
8

(2œÄ)3 exp

‚àí
3
i=1(xi ‚àíŒ∏)2
8

=
1
8

(2œÄ)3 exp

‚àí1
8

3Œ∏2 ‚àíŒ∏ + 9
4

.
(b) By the computations for the likelihood factor, we immediately obtain the a
posteriori density as follows
œÄ3(Œ∏| x1 = 1, x2 = 0.5, x3 = ‚àí1)
= k f (x1, x2, x3, x4|Œ∏)œÄ0(Œ∏)
= k exp

‚àí1
8

3Œ∏2 ‚àíŒ∏ + 9
4

‚àí(Œ∏ ‚àí1)2
4

= k exp

‚àí5
8(Œ∏ ‚àí1
2)2

,
where we have put in the constant k all terms which are independent of Œ∏. We
obtain that the a posteriori distribution is a normal distribution N(1
2, 4
5) with
normalization constant k =
‚àö
5
2
‚àö
2œÄ
.
(c) To estimate the a posteriori probability of the event (Œò > 1000) we use the
tail estimation for the Gaussian distribution. To this purpose we need Ô¨Årst to
express Œò as function of a random variable Y with distribution N(0, 1). Since
the a posteriori distribution of Œò is Gaussian N(1
2, 4
5), we have
Œò = 2
‚àö
5
5 Y + 1
2,
where Y ‚àºN(0, 1). Hence
P(Œò > 1000) = P(2
‚àö
5
5 Y + 1
2 > 1000) = P(Y >
‚àö
5
2 ¬∑ 999, 5).
By the tail estimation of the standard normal distribution, we obtain that
n(x)
x
‚àín(x)
x3
< P(Y > x) < n(x)
x
,

210
14
Statistics
where x > 0, n(x) =
1
‚àö
2œÄ
e‚àíx2
2 . To obtain an upper bound for P(Œò > 1000)
we can compute n(x)
x
in the point
x =
‚àö
5
2 ¬∑ 999, 5.
‚äì‚äî
Exercise 14.7 The random numbers X1, X2, . . . are stochastically independent sub-
ordinately to Œ¶ with the same conditional marginal density given by
f (x|œÜ) =
1
‚àö
2œÄ
œÜ
1
2 exp

‚àíœÜ(x ‚àí1)2
2

,
x ‚ààR.
The a priori distribution of Œ¶ is given by a Gamma distribution Œì (2, 1). We observe
the values of the Ô¨Årst 3 experiments:
x1 = 1.5,
x2 = 0.5,
x3 = 2.
(a) Write the a priori density of Œ¶.
(b) Compute the a posteriori density œÄ3(œÜ| x1 = 1.5, x2 = 0.5, x3 = 2) of Œ¶ and
arg max œÄ3(œÜ| x1 = 1.5, x2 = 0.5, x3 = 2).
(c) Compute the a posteriori expectation and variance of Œ¶.
Solution 14.7 (a) Since the a priori distribution of Œ¶ is given by a Gamma distri-
bution Œì (2, 1), we can write immediately the a priori density:
œÄ0(œÜ) =
œÜ e‚àíœÜ œÜ ‚â•0,
0
œÜ < 0.
(b) The a posteriori density is given by
œÄ3(œÜ| x1 = 1.5, x2 = 0.5, x3 = 2)
= k f (x1, x2, x3|œÜ)œÄ0(œÜ)
= kœÜ
5
2 exp

‚àí
3
i=1(xi ‚àí1)2
2
+ 1

œÜ

= kœÜ
5
2 e‚àí7
4 œÜ
for œÜ ‚â•0, 0 otherwise. Note that we have put in the constant k all factors which
are independent of œÜ. The a posteriori distribution is then a Gamma distribution
Œì (7
2, 7
4) with normalization constant

14
Statistics
211
k =
7
4
 7
2
1
Œì ( 7
2) =
‚àö
77
240‚àöœÄ .
Furthermore we have that
d
dœÜœÄ3(œÜ| x1 = 1.5, x2 = 0.5, x3 = 2) = kœÜ
3
2 e‚àí7
4 œÜ(5
2 ‚àí7
4œÜ) = 0
if œÜ = 10
7 . We immediately obtain that arg max œÄ3(œÜ| x1 = 1.5, x2 = 0.5, x3 =
2) = 10
7 by analyzing the sign of the Ô¨Årst derivative.
(c) The parameters of the a posteriori density provide us with
1. the a posteriori expectation
P(Œ¶| x1 = 1.5, x2 = 0.5, x3 = 2) = 2 ;
2. the a posteriori variance
œÉ2(Œò| x1 = 0.1, x2 = 2, x3 = ‚àí1, x4 = 0.5) = 8
7.
‚äì‚äî
Exercise 14.8 The random numbers X1, X2, . . . are stochastically independent sub-
ordinately to Œ¶ with the same conditional marginal density given by
f (x|œÜ) =
1
‚àö
2œÄ
œÜ
1
2 exp

‚àíœÜx2
2

,
x ‚ààR.
The a priori distribution of Œ¶ is given by an exponential distribution with parameter
Œª = 2. We observe the values of the Ô¨Årst 4 experiments:
x1 = 1,
x2 = 2,
x3 = 0.5,
x4 =
‚àö
2.
(a) Write the a priori density of Œ¶ and the a priori probability of the event (Œ¶ > 2).
(b) Compute the a posteriori density of Œ¶ and the a posteriori probability of the
event (Œ¶ > 2).
(c) Compute the a posteriori expectation of Z = Œ¶2.
Solution 14.8 (a) Since the a priori distribution of Œ¶ is given by an exponential
distribution with parameter Œª = 2, i.e. a Gamma distribution Œì (1, 2), we can
write immediately the a priori density:
œÄ0(œÜ) =
2e‚àí2œÜ œÜ ‚â•0,
0
œÜ < 0.

212
14
Statistics
The a priori probability of the event (Œ¶ > 2) is given by
P(Œ¶ > 2) =
 +‚àû
2
2e‚àí2œÜdœÜ = e‚àí4.
(b) The a posteriori density is given by
œÄ4(œÜ| x1 = 1, x2 = 2, x3 = 0.5, x4 =
‚àö
2)
= k f (x1, x2, x3, x4|œÜ)œÄ0(œÜ)
= kœÜ2 exp

‚àí
4
i=1 x2
i
2
+ 2

œÜ

= kœÜ2e‚àí45
8 œÜ
for œÜ ‚â•0, 0 otherwise. Note that we have put in the constant k all factors which
are independent of œÜ. The a posteriori distribution is then a Gamma distribution
Œì (Œ±4, Œª4) = Œì (3, 45
8 ) with normalization constant
k =
45
8
3
1
Œì (3) = 453
210 .
The a posteriori probability of the event (Œ¶ > 2) is given by
P(Œ¶ > 2| x1 = 1, x2 = 2, x3 = 0.5, x4 =
‚àö
2)
=
 +‚àû
2
œÄ4(œÜ| x1 = 1, x2 = 2, x3 = 0.5, x4 =
‚àö
2)dœÜ
= k
 +‚àû
2
œÜ2e‚àí45
8 œÜdœÜ
= k 8
45

‚àí

œÜ2 + 2œÜ + 2

e‚àí45
8 œÜ+‚àû
2
= 3453
26 e‚àí45
4 .
(c) To compute the a posteriori expectation of Z = Œ¶2 it is sufÔ¨Åcient to note that
P(Œ¶2| x1 = 1, x2 = 2, x3 = 0.5, x4 =
‚àö
2)
= œÉ2(Œ¶| x1 = 1, x2 = 2, x3 = 0.5, x4 =
‚àö
2)
+ P(Œ¶| x1 = 1, x2 = 2, x3 = 0.5, x4 =
‚àö
2)
= Œ±4
Œª2
4
+ Œ±2
4
Œª2
4
= 256
675.
‚äì‚äî

Appendix A
Elements of Combinatorics
Consider a set Œ© = {a1, . . . , an} of n elements. We recall that the symbol
n
r

is
called binomial coefÔ¨Åcient and that
n
r

=
n!
r!n ‚àír!.
A.1
Dispositions
We count the number of ways of choosing r elements out of a set of n elements with
repetitions and taking in account of their order, i.e. the number of dispositions of r
elements out of n. We have:
1st element ‚àí‚Üín choices,
2nd elements ‚àí‚Üín choices,
¬∑
¬∑
¬∑
¬∑
¬∑
¬∑
rth elements ‚àí‚Üín choices .
Totally, the dispositions are n ¬∑ n . . . n = nr. They count the number of functions
from a set of r elements to a set of n elements.
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8
213

214
Appendix A: Elements of Combinatorics
A.2
Simple Dispositions
We count the number of ways of choosing r elements out of a set of n elements
without repetitions and taking in account of their order, i.e. the number of simple
dispositions of r elements out of n. We have:
1o element ‚àí‚Üín choices,
2o elements ‚àí‚Üí(n ‚àí1) choices,
3o elements ‚àí‚Üí(n ‚àí2) choices,
¬∑
¬∑
¬∑
¬∑
¬∑
¬∑
ro elements ‚àí‚Üí(n ‚àír + 1) choices .
Totally, the simple dispositions are n ¬∑ (n ‚àí1) . . . (n ‚àír + 1) =
n!
(n ‚àír)! and are
denoted by the symbol Dn
r or (n)r. They count the number of injective functions from
a set of r elements to a set of n elements. If r = n, they are called permutations.
A.3
Simple Combinations
We count the number of ways of choosing r elements out of a set of n elements
without repetitions and without taking in account of their order, i.e. the number of
simple combinations ofr elements out of n. Given a simple combination ofr elements
out of n, we obtain r! dispositions by permutating the r elements. The number of
simple combinations is then
1
r! Dn
r =
n!
r!(n ‚àír)! =
n
r

.
They count the number of injective functions from a set of r elements to a set of n
elements which have a different image.

Appendix A: Elements of Combinatorics
215
A.4
Combinations
Wecountthenumberofwaysofchoosingr elementsoutofasetofn elementswithout
taking in account of their order, i.e. the number of combinations of r elements out
of n. Given a combination {a1, . . . , ar}, without loss of generality, we can suppose
that a1 ‚â§¬∑ ¬∑ ¬∑ ‚â§ar. Starting from this combination, we now construct a simple
combination of r elements out of n + r ‚àí1 elements in the following way:
b1 = a1 ,
b2 = a2 + 1 ,
¬∑
¬∑
¬∑
¬∑
¬∑
¬∑
br = ar + r ‚àí1 .
On the other way round, we can always associate a combination to a simple com-
bination. Hence the r-combinations are as many as the r-simple combinations in
n + r ‚àí1, elements, i.e.
n + r ‚àí1
r

.
A.5
Multinomial CoefÔ¨Åcient
The number of ways of forming k groups of r1, . . . ,rk elements respectively, where
r1 + ¬∑ ¬∑ ¬∑ + rk = n is given by the multinomial coefÔ¨Åcient
n!
r1!r2! . . .rk! .
To form the Ô¨Årst group of r1 elements, we have
 n
r1

possibilities. For the second
group, we have
n ‚àír1
r2

ways. Analogously we proceed for the remaining groups.
We obtain
 n
r1
 n ‚àír1
r2

¬∑ ¬∑ ¬∑
 n ‚àír1 ‚àí¬∑ ¬∑ ¬∑ ‚àírk‚àí1
rk

=
n!
r1!r2! . . .rk! .

Appendix B
Relations Between Discrete and Absolutely
Continuous Distributions
In TableB.1 we summarize some analogies between discrete and absolutely contin-
uous distributions.
Table B.1 Some analogies between discrete and absolutely continuous distributions
C. Discrete
C. Abs. Continuous
Probability
Density
P(X = x)
‚àí‚Üí
f (x)
Cumulative
distribution function
P(X ‚â§x)

i‚ààI (X),i‚â§x
P(X = i)
‚àí‚Üí
 x
‚àí‚àûf (s) ds
Expectation of X

i‚ààI (X)
i P(X = i)
‚àí‚Üí
 +‚àû
‚àí‚àûs f (s) ds
Expectation of
Y = Œ® (X)

i‚ààI (X)
Œ® (i) P(X = i)
‚àí‚Üí
 +‚àû
‚àí‚àûŒ® (s) f (s) ds
P(X ‚ààA)

i‚ààI (X),i‚ààA
P(X = i)
‚àí‚Üí

A f (s) ds
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8
217

Appendix C
Some Discrete Distributions
We present in Table C.1 an overview of the discrete distributions presented in Chap.2.
Table C.1 Some discrete distributions
Distribution
I (X)
P(X = k)
P(X)
œÉ2(X)
Bernoulli p
{0, 1}
P(X = 1) = p
p
p(1 ‚àíp)
Binomial
Bn(n, p)
{0, . . . , n}

n
k

pk (1 ‚àíp)n‚àík
np
np (1 ‚àíp)
Geometric p
{1, 2, . . . }
p (1 ‚àíp)k‚àí1
1
p
1‚àíp
p2
Hypergeometric
(n, N, b)
{0 ‚à®(n ‚àí(N ‚àí
b)), . . . , n ‚àßb}
‚éõ
‚éùb
k
‚éû
‚é†
‚éõ
‚éùN ‚àíb
n ‚àík
‚éû
‚é†
‚éõ
‚éùN
n
‚éû
‚é†
n b
N
n

N‚àín
N‚àí1

b
N

1 ‚àíb
N

Poisson Œª
N
Œªk
k! e‚àíŒª
Œª
Œª
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8
219

Appendix D
Some One-Dimensional Absolutely
Continuous Distributions
We recall in Table D.1 the most common one-dimensional absolutely continuous
distributions.
Table D.1 Some one-dimensional absolutely continuous distributions
Distribution
I (X)
Density
P(X)
œÉ2(X)
Uniform [a, b]
[a, b]a
1
b‚àía I[a,b]
a+b
2
(b‚àía)2
12
Exponential Œª
R+
Œª e‚àíŒªx I{x‚â•0}
1
Œª
1
Œª2
Std. normal N(0, 1)
R
1
‚àö
2œÄ e‚àíx2
2
0
1
Gen. normal N(Œº, œÉ2)
R
1
‚àö
2œÄœÉ2 e‚àí(x‚àíŒº)2
2œÉ2
Œº
œÉ2
Gamma Œì (Œ±, Œ≤)
R+
ŒªŒ±
Œì (Œ±) xŒ±‚àí1e‚àíŒªx I{x‚â•0}
Œ±
Œª
Œ±
Œª2
Beta B(Œ±, Œ≤)
[0, 1]
Œì (Œ±+Œ≤)
Œì (Œ±)Œì (Œ≤) xŒ±‚àí1 (1‚àíx)Œ≤‚àí1
Œ±
Œ±+Œ≤
Œ±Œ≤
(Œ±+Œ≤)2 (Œ±+Œ≤+1)
ab > a
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8
221

Appendix E
The Normal Distribution
We present in Table E.1 a summary on the normal distribution.
Table E.1 The normal distribution in a nutshell
Density
f (x1, . . . , xn) = k e(‚àí1
2 Ax¬∑x+b¬∑x)
x =
‚éõ
‚éú‚éú‚éù
x1
...
xn
‚éû
‚éü‚éü‚é†, A ‚ààS(n), b =
‚éõ
‚éú‚éú‚éù
b1
...
bn
‚éû
‚éü‚éü‚é†
Normalization constant
k =

det A
(2œÄ)n e‚àí1
2 A‚àí1b¬∑b
Expectation
P(X) = A‚àí1b ‚áíP(Xi) = (A‚àí1b)i
Variance and covariance matrix
C = A‚àí1
Marginal distribution of Xi
Xi ‚àºN

(A‚àí1b)i, [A‚àí1]ii

¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8
223

Appendix F
Stirling‚Äôs Formula
Inthis chapter wepresentStirling‚Äôs formula, whichdescribes theasymptoticbehavior
of n! with n increasing. It holds that:
Stirling‚Äôs formula: n! =
‚àö
2œÄ nn+ 1
2 e‚àín(1 + O(n‚àí1)) .
Different kinds of proofs can be used to prove this formula. Here we present the
classical proof and a more general result, of which the Stirling‚Äôs formula represents
a particular case.
We start with the classical proof which can be found in [2]. Here we recall it for
reader‚Äôs convenience.
F.1
First Proof
Here we obtain Stirling‚Äôs formula modulo a multiplicative constant. This value can
be shown to be equal to
‚àö
2œÄ, as a consequence of Theorem 5.4.1 by approximating
the probability that a random number with binomial distribution Bn(2n, 1
2) assumes
the value n.
The Stirling‚Äôs formula is equivalent to
lim
n‚Üí‚àû
n!
‚àö
2œÄ nn+ 1
2 e‚àín = 1.
In order to compute this limit, we look for an estimation of
log n! = log(1 ¬∑ 2 ¬∑ . . . n) = log 1 + log 2 + ¬∑ ¬∑ ¬∑ + log n .
Since log x is an increasing function, it can be approximated as follows:
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8
225

226
Appendix F: Stirling‚Äôs Formula
 k
k‚àí1
log xdx < log k ¬∑ 1 <
 k+1
k
log xdx .
Hence summing up
n

k=1
 k
k‚àí1
log xdx <
n

k=1
log k <
n

k=1
 k+1
k
log xdx,
we have
n log n ‚àín < log n! < (n + 1) log(n + 1) ‚àín .
This inequality suggests to use log n! to approximate
(n + 1
2) log n ‚àín .
We can namely think that (n + 1
2) log n represents a sort of average. If we put
dn = log n! ‚àí

n + 1
2

log n ‚àín = log

n!
nn+ 1
2 e‚àín

,
we have
dn ‚àídn+1 =

n + 1
2

log
n + 1
n

‚àí1,
(F.1)
however
n + 1
n
=
1 +
1
2n + 1
1 ‚àí
1
2n + 1
and
log(x + 1) =
‚àû

n=1
(‚àí1)n+1 xn
n .
(F.2)
Since
log
n + 1
n

= log
‚éõ
‚éú‚éù
1 +
1
2n + 1
1 ‚àí
1
2n + 1
‚éû
‚éü‚é†= log

1 +
1
2n + 1

‚àílog

1 ‚àí
1
2n + 1

,
using (F.2) with x = ¬±
1
2n + 1 we obtain

Appendix F: Stirling‚Äôs Formula
227
dn ‚àídn+1 = 1
2(2n + 1)

log

1 +
1
2n + 1

‚àílog

1 ‚àí
1
2n + 1

‚àí1
= 1
2(2n + 1)

2
(2n + 1) +
2
3(2n + 1)3 +
2
5(2n + 1)5 + ¬∑ ¬∑ ¬∑

‚àí1
=
1
3(2n + 1)2 +
1
5(2n + 1)4 + ¬∑ ¬∑ ¬∑ ,
from which it follows
dn ‚àídn+1 > 0 .
Hence dn is decreasing. It follows that the limit of dn exists (Ô¨Ånite or inÔ¨Ånite). To
prove that the limit is Ô¨Ånite, we note that
0 < dn ‚àídn+1 < 1
3
‚àû

k=1

1
2n + 1
2k
= 1
3
‚é°
‚é¢‚é¢‚é£
1
1 ‚àí
1
(2n + 1)2
‚àí1
‚é§
‚é•‚é•‚é¶
= 1
3
1
(2n + 1)2 ‚àí1 =
1
12n ‚àí
1
12(n + 1),
i.e. the sequence
an = dn ‚àí
1
12n
is increasing. Since
an ‚â§dn
‚àÄn ‚ààN, n Ã∏= 0,
and it holds that
lim
n‚Üí‚àûan = lim
n‚Üí‚àû

dn ‚àí
1
12n

= lim
n‚Üí‚àûdn,
we obtain that the limit of dn exists Ô¨Ånite since the two sequences an e dn are bounded
by each other.
F.2
Proof by Using the Gamma Function
Consider the Gamma function given by
Œì (Œ±) =
 +‚àû
0
xŒ±e‚àíxdx ,
where Œ± > 0. It represents a generalization of factorial n, since for all Œ± > 0 it holds
that

228
Appendix F: Stirling‚Äôs Formula
Œì (Œ± + 1) = Œ±Œì (Œ±).
This can be easily veriÔ¨Åed by integration by parts. If Œ± is a natural number, by iteration
we obtain
Œì (n + 1) = n!.
To prove Stirling‚Äôs formula we show the more general result that
Œì (Œ± + 1) =
‚àö
2œÄ Œ±Œ±+ 1
2 e‚àíŒ±(1 + O(Œ±‚àí1)) .
We consider logarithm of œÜ(x) = log (xŒ±e‚àíx) = Œ± log x ‚àíx. We compute the Taylor
expansion of œÜ(x) at the maximum point Œ±:
œÜ(x) = Œ± log Œ± ‚àíŒ± ‚àí1
2Œ±(x ‚àíŒ±)2 +
n

k=3
(‚àí1)k‚àí1
k
(x ‚àíŒ±)k
Œ±k‚àí1
+Œ±(‚àí1)n
n + 1
(x ‚àíŒ±)n+1
Œæn+1
,
where Œæ ‚àà[Œ±, x]. In the integral we perform the change of variable
u = x ‚àíŒ±
‚àöŒ± ,
dx = ‚àöŒ±du .
We obtain
Œì (Œ± + 1) = Œ±Œ±+ 1
2 e‚àíŒ±
 +‚àû
‚àí‚àöŒ±
e‚àíu2
2 +œà(u)du,
where
œà(u) =
n

k=3
(‚àí1)k‚àí1
k
uk
Œ±
k
2 ‚àí1 + Œ±
n+3
2 (‚àí1)n
n + 1
un+1
(Œ± + Œæ‚àöŒ±)n+1
with Œæ ‚àà[0, u]. We divide the integral in three parts:
I1 = [‚àí‚àöŒ±, ‚àíŒ±Œ¥],
I2 = [‚àíŒ±Œ¥, Œ±Œ¥],
I3 = [Œ±Œ¥, +‚àû],
where Œ¥ > 0 s sufÔ¨Åciently small constant. For what concerns I1, I3 we note that œÜ(u)
is a concave function. Hence we obtain that also the function
Œ∏(u) = ‚àíu2
2 + œà(u),
obtained by œÜ by adding a constant and by a linear transformation of the underlying
variable, is concave. For u ‚â§‚àíŒ±Œ¥ we have
Œ∏(u) ‚â§‚àíu
Œ±Œ¥ Œ∏(‚àíŒ±Œ¥)

Appendix F: Stirling‚Äôs Formula
229
and for u ‚â•Œ±Œ¥
Œ∏(u) ‚â§u
Œ±Œ¥ Œ∏(Œ±Œ¥).
By the expansion of œà(u) with n = 2 we note that for Œ± sufÔ¨Åciently big and Œ¥ < 1
6
we have Œ∏(‚àíŒ±Œ¥) < ‚àíŒ±2Œ¥
4 , Œ∏(Œ±Œ¥) < ‚àíŒ±2Œ¥
4
Hence for |u| ‚â•Œ±Œ¥ it holds that
Œ∏(u) ‚â§‚àí|u| Œ±Œ¥
4 .
It follows that

I1
eŒ∏(u)du +

I3
eŒ∏(u)du ‚â§

|u|‚â•Œ±Œ¥ e‚àí|u| Œ±Œ¥
4 du
=

‚àí8
Œ±Œ¥ e‚àí|u| Œ±Œ¥
4
+‚àû
Œ±Œ¥
= 8
Œ±Œ¥ e‚àíŒ±2Œ¥
4 .
We now consider I2. If we choose n = 3 we obtain
eœà(u) = exp
1
3
u3
Œ±
1
2 ‚àí1
4
Œ±3u4
(Œ± + Œæ‚àöŒ±)4

= 1 + 1
3
u3
Œ±
1
2 + O(u4
Œ± )
with Œæ ‚àà[0, u] ‚äÇI2 and for |u| < Œ±Œ¥. It follows that

I2
e‚àíu2
2 +œà(u)du =

e‚àíu2
2 du ‚àí

I c
2
e‚àíu2
2 du + Œ±‚àí1
2
3
+

I2
u3e‚àíu2
2 du + O(Œ±‚àí1)
=
‚àö
2œÄ + O(Œ±‚àí1)
and hence
Œì (Œ± + 1) =
‚àö
2œÄ Œ±Œ±+ 1
2 e‚àíŒ±(1 + O(Œ±‚àí1)) .

Appendix G
Elements of Analysis
In this appendix we recall some deÔ¨Ånitions and results of analysis in one variable to
facilitate the theoretical comprehension and the execution of the exercises.
G.1
Limit of a Sequence
Let (an)n ‚ààN
be a sequence of real numbers. This is called
1. convergent if
lim
n‚Üí‚àûan = L < ‚àû,
i.e. if for all œµ > 0 there exists N = N(œµ)
such that for all n > N
|an ‚àíL| < œµ ;
2. divergent if
lim
n‚Üí‚àûan = +‚àû,
i.e. if for all M > 0 there exists N = N(M)
such that for all n > N
an > M ,
or limn‚Üí‚àûan = ‚àí‚àûrespectively, i.e. if for all M > 0 there exists N =
N(M)
such that for all n > N
an < M .
A sequence may neither be convergent nor divergent. For example, the sequence
an = (‚àí1)n oscillates between 1 and ‚àí1.
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8
231

232
Appendix G: Elements of Analysis
G.2
Limit of Functions
A function f : R ‚àí‚ÜíR has:
1. Ô¨Ånite limit in x if
lim
y‚Üíx f (y) = L < ‚àû,
i.e. if for all œµ > 0 there exists Œ¥ = Œ¥(œµ)
such that for all y with |y ‚àíx| < Œ¥
| f (y) ‚àíL| < œµ ;
2. inÔ¨Ånite limit in x if
lim
y‚Üíx f (y) = +‚àû,
i.e. if for all M > 0 there exists Œ¥ = Œ¥(M)
such that for all y with |y ‚àíx| < Œ¥
f (y) > M ,
or limy‚Üíx f (y)
=
‚àí‚àûmeaning that, for all M > 0 there exists Œ¥ =
Œ¥(M)
such that for all y with |y ‚àíx| < Œ¥
f (y) < M .
G.3
Limits of Special Interest
We recall the following limits of special interest:
1.
lim
n‚Üí‚àû

1 + 1
n
n
= e ;
2. ‚àÄx ‚ààR
lim
n‚Üí‚àû

1 + x
n
n
= ex ;
3.
lim
x‚Üí0
log(1 + x)
x
= 1 .

Appendix G: Elements of Analysis
233
G.4
Series
We recall the following series:
1. the geometric series
‚àû

n=0
xn =
1
1 ‚àíx
for all |x| < 1;
2. the series
‚àû

n=1
nxn‚àí1 =
1
(1 ‚àíx)2
for all |x| < 1, which is obtained as derivative of the geometric series;
3. the exponential series
‚àû

n=0
xn
n! = ex
for all x ‚ààR.
G.5
Continuity
A function is said to be continuous in the point x0 if
lim
x‚Üíx‚àí
0
f (x) = lim
x‚Üíx+
0
f (x) = f (x0) ,
where lim
x‚Üíx‚àí
0
f (x), lim
x‚Üíx+
0
f (x) are called left limit and right limit respectively. The
left limit is taken over x < x0, the right limit is taken over x > x0.
G.6
Table of the Principal Rules of Derivation
We summarize the most common derivatives as well as the principal rules of deriva-
tion in Table G.1 and in Table G.2, respectively.

234
Appendix G: Elements of Analysis
Table G.1 Derivatives
Function f (x)
Derivative f ‚Ä≤(x)
xn
n xn‚àí1
ex
ex
log x
1
x
sin x
cos x
cos x
‚àísin x
e‚àíx2
2
‚àíx e‚àíx2
2
Table G.2 Rules of
derivation
d
dx [ f (x) + g(x)]
f ‚Ä≤(x) + g‚Ä≤(x)
d
dx [ f (x) g(x)]
f ‚Ä≤(x) g(x) + f (x) g‚Ä≤(x)
d
dx

f (x)
g(x)

f ‚Ä≤(x) g(x)‚àíf (x) g‚Ä≤(x)
g2(x)
d
dx [ f (g(x))]
f ‚Ä≤(g(x)) ¬∑ g‚Ä≤(x)
G.7
Integrals
1. Integration by parts formula
 b
a
f (x) g‚Ä≤(x) dx = [ f (x) g(x)]b
a ‚àí
 b
a
f ‚Ä≤(x) g(x) dx .
2. Change of variable
x = g(y) ‚áídx = g‚Ä≤(y) dy,
 b
a
f (x) dx =
 g‚àí1(b)
g‚àí1(a)
f (g(y)) g‚Ä≤(y) dy .

Appendix H
Bidimensional Integrals
In this appendix we recall some notions of analysis in several variables to facilitate
the comprehension of the text and the execution of the exercises.
H.1
Areas of Bidimensional Regions
Let A be a region of the plane (Fig.H.1). The area of A is given by
area A =
 
A
dxdy .
This is analogous to the one-dimensional case, where the length of a segment [a, b]
is given by
l([a, b]) =
 b
a
dx .
H.2
Integrals of Functions of Two Variables
Let f : R2 ‚ÜíR and put z = f (x, y). A function in two variables describes a surface
in R3 of coordinates (x, y, f (x, y)). We want to calculate the volume between the
surface described by the function and the plane xy. This volume is given by the
double integral
 
R2 f (x, y) dxdy ,
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8
235

236
Appendix H: Bidimensional Integrals
Fig. H.1 A region of the
plane
x
y
O
if f is sufÔ¨Åciently regular (for example, if f is continuous). We can compute a double
integral as two nested one-dimensional integrals, i.e.

dx

f (x, y) dy =

dy

f (x, y) dx =
 
f (x, y) dxdy .
This result holds for sufÔ¨Åciently regular functions f (for example, if f is continuous)
and is known as Fubini-Tonelli theorem. We refer to [11] for further details.
Example H.2.1 Let A = {1 < x < 2, 3 < y < 4}. We compute the following
integral on A.
 
A
x2y dxdy =
 2
1
dx
 4
3
x2y dy

 !
"
x is a parameter!
=
 2
1
x2
 4
3
y dy

dx
=
 2
1
x2
1
2 y2
4
3
dx
= 7
2
 2
1
x2 dx
= 49
6 .

Appendix H: Bidimensional Integrals
237
Fig. H.2 The region B
x
y
O
B
Example H.2.2 Let B = {0 < x < 1, x ‚àí1 < y < x + 1}, see Fig.H.2.
We calculate the following integral on B.
 
B
e‚àíy dxdy =
 1
0
dx
 x+1
x‚àí1
e‚àíy dy
=
 1
0
#
e‚àíy$x+1
x‚àí1 dx
=
 1
0

e‚àí(x+1) ‚àíe‚àí(x‚àí1)
dx
=
 1
0

e‚àí1 ‚àíe

e‚àíxdx
=

e‚àí1 ‚àíe
 
1 ‚àíe‚àí1
.
Example H.2.3 To perform a double integral, it is convenient to divide the domain
of integration in a suitable way. Consider the example of Fig.H.3, where D = {0 <
y < 1, y ‚àí1 < x < ‚àíy + 1}.
We compute the integral of a function f (x, y), which is assumed to be sufÔ¨Åciently
regular, on D:
 
D
f (x, y) dxdy =
 1
0
dy
 ‚àíy+1
y‚àí1
f (x, y) dx
=
 1
0
dx
 ‚àíx+1
0
f (x, y) dy +
 0
‚àí1
dx
 x+1
0
f (x, y) dy.

238
Appendix H: Bidimensional Integrals
Fig. H.3 Region D
x
y
O
‚àí1
1
1
y=x+1
y=‚àíx+1
In the Ô¨Årst passage the extremes of integration can be found by drawing the parallels
to the x-axis and Ô¨Ånding the intersections with the border of the domain D. In the
second step the integral has been split in two parts and the extremes have been found
by drawing the parallels to the y-axis.
H.3
Partial Derivatives with Respect to a Single Variable
Let f : R2 ‚ÜíR, z = f (x, y). We call partial derivative of f with respect to the
variable x and write ‚àÇf
‚àÇx the derivative of f obtained by considering the function as
depending only by the variable x and considering the other variables as parameters.
Analogously we can deÔ¨Åne the partial derivatives of a function with respect to the
other variables.
Example H.3.1 (Partial derivatives)
1.
f (x, y) = x2y:
‚àÇf
‚àÇx = 2xy , ‚àÇf
‚àÇy = x2 ;
2.
f (x, y) = log(xy):
‚àÇf
‚àÇx = 1
x , ‚àÇf
‚àÇy = 1
y .
H.4
Change of Variables
Let Œ® : R2 ‚ÜíR2, (x, y) = (Œ®1(x, y), Œ®2(x, y)). We call Jacobian Jœà of the
function œà the matrix

Appendix H: Bidimensional Integrals
239
JŒ® =
‚éõ
‚éú‚éù
‚àÇŒ®1
‚àÇx
‚àÇŒ®1
‚àÇy
‚àÇŒ®2
‚àÇx
‚àÇŒ®2
‚àÇy
‚éû
‚éü‚é†.
A change of coordinates in R2 is given by a function
Œ® : R2 ‚ÜíR2
(u, v) ‚àí‚Üí(x, y)
with particular regularity properties (diffeomorphismus). To change the variables in
an integral, we use then the following rule:
 
A
f (x, y) dxdy =
 
Œ® ‚àí1(A)
f (Œ® (u, v)) |det JŒ® | dxdy
with the help of the following diagram:
R2
(u,v)
f ‚ó¶Œ®









Œ®
 R2
(x,y)
f

R
Example H.4.1 In this example we consider the computation of the normalization
constant for the standard normal distribution in 2 dimension. To this purpose we need
Fig. H.4 Extremes of
integration as x varies
x
O
y

240
Appendix H: Bidimensional Integrals
Fig. H.5 Extremes of
integration as y varies
x
O
y
to use a change of variable (Figs.H.4 and H.5). Consider
 
R2 e‚àí1
2 (x2+y2) dxdy .
To compute this integral, we use the polar coordinates:
x = œÅ cos Œ∏,
y = œÅ sin Œ∏
(Œ∏, œÅ)
Œ®‚Üí(x, y) = (œÅ cos Œ∏, œÅ sin Œ∏) .
The Jacobian of this transformation is given by
JŒ® =
‚éõ
‚éù
‚àÇ
‚àÇŒ∏ œÅ cos Œ∏
‚àÇ
‚àÇœÅ œÅ cos Œ∏
‚àÇ
‚àÇŒ∏ œÅ sin Œ∏
‚àÇ
‚àÇœÅ œÅ sin Œ∏
‚éû
‚é†=
‚éõ
‚éù
‚àíœÅ sin Œ∏
cos Œ∏
œÅ cos Œ∏
sin Œ∏
‚éû
‚é†.
The Jacobian determinant is then
det JŒ® = ‚àíœÅ (sin2 Œ∏ + cos2 Œ∏) = ‚àíœÅ,
i.e.
| det JŒ® | = œÅ .

Appendix H: Bidimensional Integrals
241
It follows that
 
R2 e‚àí1
2 (x2+y2) dxdy =
 +‚àû
0
dœÅ
 2œÄ
0
œÅ e‚àí1
2 œÅ2 dŒ∏
=
 +‚àû
0
œÅ e‚àí1
2 œÅ2 dœÅ
 2œÄ
0
dŒ∏
= 2œÄ

‚àíe‚àí1
2 œÅ2+‚àû
0

 !
"
1
= 2œÄ .
Hence
 +‚àû
‚àí‚àû
e‚àíx2
2 dx
2
=
 +‚àû
‚àí‚àû
e‚àíx2
2 dx
 +‚àû
‚àí‚àû
e‚àíY2
2 dy
=
 
R2 e‚àí1
2 (x2+y2) dxdy = 2œÄ .
Finally
 +‚àû
‚àí‚àû
e‚àíx2
2 dx =
‚àö
2œÄ .

References
1. de Finetti, B.: Theory of Probability. A Critical Introduction Treatment, vol. 1, 2. Wiley,
New York (1974, 1975)
2. Feller, W.: An Introduction to Probability Theory and Its Applications, vol. 1. Wiley, New York
(1957)
3. Foat√†, D., Fuchs, A.: Calcul des probabilit√©s, 2nd edn. Dunod, Paris (1998)
4. Gnedenko, B.: The Theory of Probability. Gordon and Breach Science Publishers, Amsterdam
(1997)
5. Hogg, R.V., Tanis, E.A.: Probability and Statistical Inference. Prentice Hall, New York (2001)
6. Jacod, J., Protter, P.: Probability Essentials. Springer, Berlin (2003)
7. Kleinrock, L.: Queueing Systems 1. Wiley, New York (1975)
8. Kleinrock, L., Gail, R.: Queueing Systems: Problems and Solutions. Wiley, New York (1996)
9. Lee, P.M.: Bayesian Statistics: An Introduction. Edward Arnold, London (1994)
10. Lindley, D.V.: Introduction to Probability and Statistics, vol. 1, 2. Cambridge University Press,
New York (1965)
11. Munkres, J.R.: Analysis On Manifolds. Advanced Books Classics. Westview Press, Boulder
(1997)
12. Ross, S.M.: Introduction to Probability Models. Elsevier, New York (2010)
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8
243

Index
A
Absolutely continuous distribution, 44
Absorbing boundary conditions, 82
Area, 235
B
Bayes‚Äô formula, 16
Bernoulli scheme, 27
Bet, 8
Binomial distribution, 28
Bounded, 3
C
Change of variables, 239
Client, 89
CoefÔ¨Åcient
binomial, 213
multinomial, 215
Coherence, 8
Combinations, 215
Complementary, 5
Conditional probability, 14
ConÔ¨Ådence
intervals, 111
region, 111
Constituent, 6
Continuity, 233
Convergence for sequences of cumulative
distribution functions, 73
Covariance, 22
Cumulative distribution function, 43
D
Density
a posteriori, 106
conditional, 104
joint probability, 58
marginal probability, 59
Derivative, 234
Discrete distribution, 27
Dispositions, 213
simple, 214
Distribution
a priori, 106
beta, 62
Cauchy, 55
œá2, 54
exponential, 48
gamma, 52
Gaussian n-dimensional, 66
initial, 81
normal, 50
stationary, 96
Student, 63
Double integral, 235
E
Equations
Chapman-Kolmogorov, 91
Kolmogorov forward, 91
Event, 5
Exhaustivity, 6
Expectation, 8
F
Formula
of composite expectation, 15
Stirling‚Äôs, 225
Function
¬© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8
245

246
Index
joint cumulative distribution, 57
marginal cumulative distribution, 58
G
Generating function, 39
Geometric distribution, 29
H
Homogeneous Markov chain, 81
Hypergeometric distribution, 31
I
Incompatibility, 6
J
Jacobian, 238
Joint distribution, 35
L
Law of large numbers, 25
Likelihood factor, 108
Limit, 231
Linearity, 8
Little‚Äôs formula, 101
Logical
product, 5
sum, 5
Logically
dependent event, 7
independent event, 7
semidependent event, 7
Lower bounded, 3
M
Marginal distribution, 35
Memoryless, 30
Monotonicity, 8
Multinomial distribution, 33
N
Negatively
correlated, 22
Non-correlated, 22
P
Partial derivatives, 238
Partition, 6
Penalty, 8
Permutations, 214
Pluri-events, 33
Poisson distribution, 30
Polar coordinates, 240
Positively
correlated, 22
Possible values, 3
Precision, 108
Process
Poisson, 91
stochastic, 89
Q
Queueing system, 89
R
Random
number, 3
vector, 35
walk, 82
S
Series, 233
Server, 89
Service times, 89
Simple combinations, 214
State space, 81
Stationary regime, 100
Statistical
induction, 104
inference, 104
Successes, 28
T
Theorem
De Moivre-Laplace, 77
Transition probability matrix, 81
U
Uniform distribution, 46
Upper bounded, 3

