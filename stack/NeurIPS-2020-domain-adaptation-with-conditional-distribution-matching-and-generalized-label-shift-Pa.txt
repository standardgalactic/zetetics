Domain Adaptation with Conditional Distribution
Matching and Generalized Label Shift
Remi Tachet des Combes∗
Microsoft Research Montreal
Montreal, QC, Canada
retachet@microsoft.com
Han Zhao∗
D. E. Shaw & Co.
New York, NY, USA
han.zhao@cs.cmu.edu
Yu-Xiang Wang
UC Santa Barbara
Santa Barbara, CA, USA
yuxiangw@cs.ucsb.edu
Geoff Gordon
Microsoft Research Montreal
Montreal, QC, Canada
ggordon@microsoft.com
Abstract
Adversarial learning has demonstrated good performance in the unsupervised
domain adaptation setting, by learning domain-invariant representations. However,
recent work has shown limitations of this approach when label distributions differ
between the source and target domains. In this paper, we propose a new assumption,
generalized label shift (GLS), to improve robustness against mismatched label
distributions. GLS states that, conditioned on the label, there exists a representation
of the input that is invariant between the source and target domains. Under GLS,
we provide theoretical guarantees on the transfer performance of any classiﬁer.
We also devise necessary and sufﬁcient conditions for GLS to hold, by using
an estimation of the relative class weights between domains and an appropriate
reweighting of samples. Our weight estimation method could be straightforwardly
and generically applied in existing domain adaptation (DA) algorithms that learn
domain-invariant representations, with small computational overhead. In particular,
we modify three DA algorithms, JAN, DANN and CDAN, and evaluate their
performance on standard and artiﬁcial DA tasks. Our algorithms outperform the
base versions, with vast improvements for large label distribution mismatches. Our
code is available at https://tinyurl.com/y585xt6j.
1
Introduction
In spite of impressive successes, most deep learning models [22] rely on huge amounts of labelled
data and their features have proven brittle to distribution shifts [39, 55]. Building more robust models,
that learn from fewer samples and/or generalize better out-of-distribution is the focus of many recent
works [2, 5, 53]. The research direction of interest to this paper is that of domain adaptation, which
aims at learning features that transfer well between domains. We focus in particular on unsupervised
domain adaptation (UDA), where the algorithm has access to labelled samples from a source domain
and unlabelled data from a target domain. Its objective is to train a model that generalizes well to
the target domain. Building on advances in adversarial learning [23], adversarial domain adaptation
(ADA) leverages the use of a discriminator to learn an intermediate representation that is invariant
between the source and target domains. Simultaneously, the representation is paired with a classiﬁer,
trained to perform well on the source domain [20, 32, 49, 60]. ADA is rather successful on a variety
∗The ﬁrst two authors contributed equally to this work. Work done while HZ was at Carnegie Mellon
University.
34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.

of tasks, however, recent work has proven an upper bound on the performance of existing algorithms
when source and target domains have mismatched label distributions [62]. Label shift is a property
of two domains for which the marginal label distributions differ, but the conditional distributions of
input given label stay the same across domains [48, 58].
In this paper, we study domain adaptation under mismatched label distributions and design methods
that are robust in that setting. Our contributions are the following. First, we extend the upper bound
by Zhao et al. [62] to k-class classiﬁcation and to conditional domain adversarial networks, a recently
introduced domain adaptation algorithm [37]. Second, we introduce generalized label shift (GLS), a
broader version of the standard label shift where conditional invariance between source and target
domains is placed in representation rather than input space. Third, we derive performance guarantees
for algorithms that seek to enforce GLS via learnt feature transformations, in the form of upper
bounds on the error gap and the joint error of the classiﬁer on the source and target domains. Those
guarantees suggest principled modiﬁcations to ADA to improve its robustness to mismatched label
distributions. The modiﬁcations rely on estimating the class ratios between source and target domains
and use those as importance weights in the adversarial and classiﬁcation objectives. The importance
weights estimation is performed using a method of moment by solving a quadratic program, inspired
from Lipton et al. [31]. Following these theoretical insights, we devise three new algorithms based
on learning importance-weighted representations, DANNs [20], JANs [36] and CDANs [37]. We
apply our variants to artiﬁcial UDA tasks with large divergences between label distributions, and
demonstrate signiﬁcant performance gains compared to the algorithms’ base versions. Finally, we
evaluate them on standard domain adaptation tasks and also show improved performance.
2
Preliminaries
Notation We focus on the general k-class classiﬁcation problem. X and Y denote the input and
output space, respectively. Z stands for the representation space induced from X by a feature
transformation g : X 7→Z. Accordingly, we use X, Y, Z to denote random variables which take
values in X , Y, Z. Domain corresponds to a joint distribution on the input space X and output space
Y, and we use DS (resp. DT) to denote the source (resp. target) domain. Noticeably, this corresponds
to a stochastic setting, which is stronger than the deterministic one previously studied [6, 7, 62]. A
hypothesis is a function h : X →[k]. The error of a hypothesis h under distribution DS is deﬁned as:
εS(h) := PrDS(h(X) ̸= Y), i.e., the probability that h disagrees with Y under DS.
Domain Adaptation via Invariant Representations For source (DS) and target (DT) domains, we
use DX
S , DX
T , DY
S and DY
T to denote the marginal data and label distributions. In UDA, the algorithm
has access to n labeled points {(xi, yi)}n
i=1 ∈(X × Y)n and m unlabeled points {xj}m
j=1 ∈X m
sampled i.i.d. from the source and target domains. Inspired by Ben-David et al. [7], a common
approach is to learn representations invariant to the domain shift. With g : X 7→Z a feature
transformation and h : Z 7→Y a hypothesis on the feature space, a domain invariant representa-
tion [20, 49, 59] is a function g that induces similar distributions on DS and DT. g is also required to
preserve rich information about the target task so that εS(h ◦g) is small. The above process results
in the following Markov chain (assumed to hold throughout the paper):
X
g
−→Z
h
−→bY,
(1)
where bY = h(g(X)). We let DZ
S , DZ
T, D bY
S and D bY
T denote the pushforwards (induced distributions)
of DX
S and DX
T by g and h ◦g. Invariance in feature space is deﬁned as minimizing a distance or
divergence between DZ
S and DZ
T.
Adversarial Domain Adaptation
Invariance is often attained by training a discriminator d : Z 7→
[0, 1] to predict if z is from the source or target. g is trained both to maximize the discriminator
loss and minimize the classiﬁcation loss of h ◦g on the source domain (h is also trained with the
latter objective). This leads to domain-adversarial neural networks [20, DANN], where g, h and
d are parameterized with neural networks: gθ, hφ and dψ (see Algo. 1 and App. ??). Building on
DANN, conditional domain adversarial networks [37, CDAN] use the same adversarial paradigm.
However, the discriminator now takes as input the outer product, for a given x, between the predictions
of the network h(g(x)) and its representation g(x). In other words, d acts on the outer product:
h ⊗g(x) := (h1(g(x)) · g(x), . . . , hk(g(x)) · g(x)) rather than on g(x). hi denotes the i-th element
of vector h. We now highlight a limitation of DANNs and CDANs.
2

Table 1: Common assumptions in the domain adaptation literature.
Covariate Shift
Label Shift
DX
S ̸= DX
T
DY
S ̸= DY
T
∀x ∈X , DS(Y | X = x) = DT(Y | X = x)
∀y ∈Y, DS(X | Y = y) = DT(X | Y = y)
An Information-Theoretic Lower Bound
We let DJS denote the Jensen-Shanon divergence be-
tween two distributions (App. ??), and eZ correspond to Z (for DANN) or to bY ⊗Z (for CDAN). The
following theorem lower bounds the joint error of the classiﬁer on the source and target domains:
Theorem 2.1. Assuming that DJS(DY
S ∥DY
T) ≥DJS(D eZ
S ∥D eZ
T), then:
εS(h ◦g) + εT(h ◦g) ≥1
2
q
DJS(DY
S ∥DY
T) −
q
DJS(D eZ
S ∥D eZ
T)
2
.
Remark The lower bound is algorithm-independent. It is also a population-level result and holds
asymptotically with increasing data. Zhao et al. [62] prove the theorem for k = 2 and eZ = Z.
We extend it to CDAN and arbitrary k (it actually holds for any eZ s.t. bY = eh(eZ) for some eh, see
App. ??). Assuming that label distributions differ between source and target domains, the lower
bound shows that: the better the alignment of feature distributions, the worse the joint error. For an
invariant representation (DJS(D ˜Z
S , D ˜Z
T) = 0) with no source error, the target error will be larger than
DJS(DY
S , DY
T)/2. Hence algorithms learning invariant representations and minimizing the source
error are fundamentally ﬂawed when label distributions differ between source and target domains.
Common Assumptions to Tackle Domain Adaptation
Two common assumptions about the data
made in DA are covariate shift and label shift. They correspond to different ways of decomposing
the joint distribution over X × Y, as detailed in Table 1. From a representation learning perspective,
covariate shift is not robust to feature transformation and can lead to an effect called negative
transfer [62]. At the same time, label shift clearly fails in most practical applications, e.g. transferring
knowledge from synthetic to real images [51]. In that case, the input distributions are actually disjoint.
3
Main Results
In light of the limitations of existing assumptions, (e.g. covariate shift and label shift), we propose
generalized label shift (GLS), a relaxation of label shift that substantially improves its applicability.
We ﬁrst discuss some of its properties and explain why the assumption is favorable in domain
adaptation based on representation learning. Motivated by GLS, we then present a novel error
decomposition theorem that directly suggests a bound minimization framework for domain adaptation.
The framework is naturally compatible with F-integral probability metrics [40, F-IPM] and generates
a family of domain adaptation algorithms by choosing various function classes F. In a nutshell,
the proposed framework applies a method of moments [31] to estimate the importance weight w of
the marginal label distributions by solving a quadratic program (QP), and then uses w to align the
weighted source feature distribution with the target feature distribution.
3.1
Generalized Label Shift
Deﬁnition 3.1 (Generalized Label Shift, GLS). A representation Z = g(X) satisﬁes GLS if
DS(Z | Y = y) = DT(Z | Y = y), ∀y ∈Y.
(2)
First, when g is the identity map, the above deﬁnition of GLS reduces to the original label shift
assumption. Next, GLS is always achievable for any distribution pair (DS, DT): any constant
function g ≡c ∈R satisﬁes the above deﬁnition. The most important property is arguably that,
unlike label shift, GLS is compatible with a perfect classiﬁer (in the noiseless case). Precisely, if
there exists a ground-truth labeling function h∗such that Y = h∗(X), then h∗satisﬁes GLS. As a
comparison, without conditioning on Y = y, h∗does not satisfy DS(h∗(X)) = DT(h∗(X)) if the
marginal label distributions are different across domains. This observation is consistent with the
lower bound in Theorem 2.1, which holds for arbitrary marginal label distributions.
3

GLS imposes label shift in the feature space Z instead of the original input space X . Conceptually,
although samples from the same classes in the source and target domain can be dramatically different,
the hope is to ﬁnd an intermediate representation for both domains in which samples from a given
class look similar to one another. Taking digit classiﬁcation as an example and assuming the feature
variable Z corresponds to the contour of a digit, it is possible that by using different contour extractors
for e.g. MNIST and USPS, those contours look roughly the same in both domains. Technically, GLS
can be facilitated by having separate representation extractors gS and gT for source and target [9, 49].
3.2
An Error Decomposition Theorem based on GLS
We now provide performance guarantees for models that satisfy GLS, in the form of upper bounds
on the error gap and on the joint error between source and target domains. It requires two concepts:
Deﬁnition 3.2 (Balanced Error Rate). The balanced error rate (BER) of predictor bY on DS is:
BERDS(bY ∥Y) := max
j∈[k] DS(bY ̸= Y | Y = j).
(3)
Deﬁnition 3.3 (Conditional Error Gap). Given a joint distribution D, the conditional error gap of a
classiﬁer bY is ∆CE(bY) := maxy̸=y′∈Y2 |DS(bY = y′ | Y = y) −DT(bY = y′ | Y = y)|.
When GLS holds, ∆CE(bY) is equal to 0. We now give an upper bound on the error gap between
source and target, which can also be used to obtain a generalization upper bound on the target risk.
Theorem 3.1. (Error Decomposition Theorem) For any classiﬁer bY = (h ◦g)(X),
|εS(h ◦g) −εT(h ◦g)| ≤∥DY
S −DY
T∥1 · BERDS(bY ∥Y) + 2(k −1)∆CE(bY),
where ∥DY
S −DY
T∥1 := ∑k
i=1 |DS(Y = i) −DT(Y = i)| is the L1 distance between DY
S and DY
T.
Remark
The upper bound in Theorem 3.1 provides a way to decompose the error gap between
source and target domains. It also immediately gives a generalization bound on the target risk
εT(h ◦g). The bound contains two terms. The ﬁrst contains ∥DY
S −DY
T∥1, which measures the
distance between the marginal label distributions across domains and is a constant that only depends
on the adaptation problem itself, and BER, a reweighted classiﬁcation performance on the source
domain. The second is ∆CE(bY) measures the distance between the family of conditional distributions
bY | Y. In other words, the bound is oblivious to the optimal labeling functions in feature space.
This is in sharp contrast with upper bounds from previous work [7, Theorem 2], [62, Theorem 4.1],
which essentially decompose the error gap in terms of the distance between the marginal feature
distributions (DZ
S , DZ
T) and the optimal labeling functions (f Z
S , f Z
T ). Because the optimal labeling
function in feature space depends on Z and is unknown in practice, such decomposition is not very
informative. As a comparison, Theorem 3.1 provides a decomposition orthogonal to previous results
and does not require knowledge about unknown optimal labeling functions in feature space.
Notably, the balanced error rate, BERDS(bY ∥Y), only depends on samples from the source domain
and can be minimized. Furthermore, using a data-processing argument, the conditional error gap
∆CE(bY) can be minimized by aligning the conditional feature distributions across domains. Putting
everything together, the result suggests that, to minimize the error gap, it sufﬁces to align the
conditional distributions Z | Y = y while simultaneously minimizing the balanced error rate. In fact,
under the assumption that the conditional distributions are perfectly aligned (i.e., under GLS), we
can prove a stronger result, guaranteeing that the joint error is small:
Theorem 3.2. If Z = g(X) satisﬁes GLS, then for any h : Z →Y and letting bY = h(Z) be the
predictor, we have εS(bY) + εT(bY) ≤2BERDS(bY ∥Y).
3.3
Conditions for Generalized Label Shift
The main difﬁculty in applying a bound minimization algorithm inspired by Theorem 3.1 is that we
do not have labels from the target domain in UDA, so we cannot directly align the conditional label
distributions. By using relative class weights between domains, we can provide a necessary condition
for GLS that bypasses an explicit alignment of the conditional feature distributions.
4

Deﬁnition 3.4. Assuming DS(Y = y) > 0, ∀y ∈Y, we let w ∈Rk denote the importance weights
of the target and source label distributions:
wy := DT(Y = y)
DS(Y = y) ,
∀y ∈Y.
(4)
Lemma 3.1. (Necessary condition for GLS) If Z = g(X) satisﬁes GLS, then DT(eZ) = ∑y∈Y wy ·
DS(eZ, Y = y) =: Dw
S (eZ) where eZ veriﬁes either eZ = Z or eZ = bY ⊗Z.
Compared to previous work that attempts to align DT(Z) with DS(Z) (using adversarial discrim-
inators [20] or maximum mean discrepancy (MMD) [34]) or DT( ˆY ⊗Z) with DS( ˆY ⊗Z) [37],
Lemma 3.1 suggests to instead align DT(eZ) with the reweighted marginal distribution Dw
S (eZ).
Reciprocally, the following two theorems give sufﬁcient conditions to know when perfectly aligned
target feature distribution and reweighted source feature distribution imply GLS:
Theorem 3.3. (Clustering structure implies sufﬁciency) Let Z = g(X) such that DT(Z) = Dw
S (Z).
Assume DT(Y = y) > 0, ∀y ∈Y. If there exists a partition of Z = ∪y∈YZy such that ∀y ∈Y,
DS(Z ∈Zy | Y = y) = DT(Z ∈Zy | Y = y) = 1, then Z = g(X) satisﬁes GLS.
Remark
Theorem 3.3 shows that if there exists a partition of the feature space such that instances
with the same label are within the same component, then aligning the target feature distribution with
the reweighted source feature distribution implies GLS. While this clustering assumption may seem
strong, it is consistent with the goal of reducing classiﬁcation error: if such a clustering exists, then
there also exists a perfect predictor based on the feature Z = g(X), i.e., the cluster index.
Theorem 3.4. Let bY = h(Z), γ := miny∈Y DT(Y = y) and wM := maxy∈Y wy. For eZ = Z or
eZ = ˆY ⊗Z, we have:
max
y∈Y dTV(DS(Z | Y = y), DT(Z | Y = y)) ≤
wMεS(bY) + εT(bY) +
q
8DJS(Dw
S (eZ)∥DT(eZ))
γ
.
Theorem 3.4 conﬁrms that matching DT(eZ) with Dw
S (eZ) is the proper objective in the context of
mismatched label distributions. It shows that, for matched feature distributions and a source error
equal to zero, successful domain adaptation (i.e. a target error equal to zero) implies that GLS holds.
Combined with Theorem 3.2, we even get equivalence between the two.
Remark
Thm. 3.4 extends Thm. 3.3 by incorporating the clustering assumption in the joint error
achievable by a classiﬁer bY based on a ﬁxed Z. In particular, if the clustering structure holds, the
joint error is 0 for an appropriate h, and aligning the reweighted feature distributions implies GLS.
3.4
Estimating the Importance Weights w
Inspired by the moment matching technique to estimate w under label shift from Lipton et al. [31],
we propose a method to get w under GLS by solving a quadratic program (QP).
Deﬁnition 3.5. We let C ∈R|Y|×|Y| denote the confusion matrix of the classiﬁer on the source
domain and µ ∈R|Y| the distribution of predictions on the target one, ∀y, y′ ∈Y:
Cy,y′ := DS(bY = y, Y = y′),
µy := DT(bY = y).
Lemma 3.2. If GLS is veriﬁed, and if the confusion matrix C is invertible, then w = C−1µ.
The key insight from Lemma 3.2 is that, to estimate the importance vector w under GLS, we do not
need access to labels from the target domain. However, matrix inversion is notoriously numerically
unstable, especially with ﬁnite sample estimates ˆC and ˆµ of C and µ. We propose to solve instead the
following QP (written as QP( ˆC, ˆµ)), whose solution will be consistent if ˆC →C and ˆµ →µ:
minimize
w
1
2 ∥ˆµ −ˆCw∥2
2,
subject to
w ≥0, wTDS(Y) = 1.
(5)
The above program (5) can be efﬁciently solved in time O(|Y|3), with |Y| small and constant; and by
construction, its solution is element-wise non-negative, even with limited amounts of data to estimate
C and µ.
5

Algorithm 1 Importance-Weighted Domain Adaptation
1: Input: source and target data (xS, yS), xT; gθ, hφ and dψ; epochs E, batches per epoch B
2: Initialize w1 = 1
3: for t = 1 to E do
4:
Initialize ˆC = 0, ˆµ = 0
5:
for b = 1 to B do
6:
Sample batches (xi
S, yi
S) and (xi
T) of size s
7:
Maximize Lwt
DA w.r.t. θ, minimize Lwt
DA w.r.t. ψ and minimize Lwt
C w.r.t. θ and φ
8:
for i = 1 to s do
9:
ˆC·yi
S ←ˆC·yi
S + hφ(gθ(xi
S)) (yi
S-th column)
and
ˆµ ←ˆµ + hφ(gθ(xi
T))
10:
ˆC ←ˆC/sB and ˆµ ←ˆµ/sB;
then
wt+1 = λ · QP( ˆC, ˆµ) + (1 −λ)wt
Lemma 3.3. If the source error εS(h ◦g) is zero and the source and target marginals verify
DJS(D ˜w
S (Z), DT(Z)) = 0, then the estimated weight vector w is equal to ˜w.
Lemma 3.3 shows that the weight estimation is stable once the DA losses have converged, but it does
not imply convergence to the true weights (see Sec. 4.2 and App. ?? for more details).
3.5
F-IPM for Distributional Alignment
To align the target feature distribution and the reweighted source feature distribution as suggested by
Lemma 3.1, we now provide a general framework using the integral probability metric [40, IPM].
Deﬁnition 3.6. With F a set of real-valued functions, the F-IPM between distributions D and D′ is
dF(D, D′) := sup
f ∈F
|EX∼D[ f (X)] −EX∼D′[ f (X)]|.
(6)
By approximating any function class F using parametrized models, e.g., neural networks, we obtain
a general framework for domain adaptation by aligning reweighted source feature distribution and
target feature distribution, i.e. by minimizing dF(DT(eZ), Dw
S (eZ)). Below, by instantiating F to
be the set of bounded norm functions in a RKHS H [25], we obtain maximum mean discrepancy
methods, leading to IWJAN (cf. Section 4.1), a variant of JAN [36] for UDA.
4
Practical Implementation
4.1
Algorithms
The sections above suggest simple algorithms based on representation learning: (i) estimate w on
the ﬂy during training, (ii) align the feature distributions eZ of the target domain with the reweighted
feature distribution of the source domain and, (iii) minimize the balanced error rate. Overall, we
present the pseudocode of our algorithm in Alg. 1.
To compute w, we build estimators ˆC and ˆµ of C and µ by averaging during each epoch the predictions
of the classiﬁer on the source (per true class) and target (overall). This corresponds to the inner-most
loop of Algorithm 1 (lines 8-9). At epoch end, w is updated (line 10), and the estimators reset to
0. We have found empirically that using an exponential moving average of w performs better. Our
results all use a factor λ = 0.5. We also note that Alg. 1 implies a minimal computational overhead
(see App. ?? for details): in practice our algorithms run as fast as their base versions.
Using w, we can deﬁne our ﬁrst algorithm, Importance-Weighted Domain Adversarial Network
(IWDAN), that aligns Dw
S (Z) and DT(Z)) using a discriminator. To that end, we modify the DANN
losses LDA and LC as follows. For batches (xi
S, yi
S) and (xi
T) of size s, the weighted DA loss is:
Lw
DA(xi
S, yi
S, xi
T; θ, ψ) = −1
s
s
∑
i=1
wyi
S log(dψ(gθ(xi
S))) + log(1 −dψ(gθ(xi
T))).
(7)
We verify in App. ??, that the standard ADA framework applied to Lw
DA indeed minimizes
DJS(Dw
S (Z)∥DT(Z)). Our second algorithm, Importance-Weighted Joint Adaptation Networks
6

0.02
0.04
0.06
0.08
jsd
0.0
2.5
5.0
7.5
10.0
12.5
15.0
17.5
20.0
% improvement
IWDAN
IWDAN fit
IWDAN-O
IWDAN-O fit
0.02
0.04
0.06
0.08
jsd
0
2
4
6
8
10
% improvement
IWCDAN
IWCDAN fit
IWCDAN-O
IWCDAN-O fit
Figure 1: Gains of our algorithms vs their base versions (the horizontal grey line) for 100 tasks. The
x-axis is DJS(DY
S , DY
T). The mean improvements for IWDAN and IWDAN-O (resp. IWCDAN and
IWCDAN-O) are 6.55% and 8.14% (resp. 2.25% and 2.81%).
(IWJAN) is based on JAN [36] and follows the reweighting principle described in Section 3.5 with
F a learnt RKHS (the exact JAN and IWJAN losses are speciﬁed in App. ??). Finally, our third
algorithm is Importance-Weighted Conditional Domain Adversarial Network (IWCDAN). It matches
Dw
S ( ˆY ⊗Z) with DT( ˆY ⊗Z) by replacing the standard adversarial loss in CDAN with Eq. 7, where
dψ takes as input (hφ ◦gθ) ⊗gθ instead of gθ. The classiﬁer loss for our three variants is:
Lw
C (xi
S, yi
S; θ, φ) = −1
s
s
∑
i=1
1
k · DS(Y = y) log(hφ(gθ(xi
S))yi
S).
(8)
This reweighting is suggested by our theoretical analysis from Section 3, where we seek to minimize
the balanced error rate BERDS(bY ∥Y). We also deﬁne oracle versions, IWDAN-O, IWJAN-O
and IWCDAN-O, where the weights w are the true weights. It gives an idealistic version of the
reweighting method, and allows to assess the soundness of GLS. IWDAN, IWJAN and IWCDAN
are Alg. 1 with their respective loss functions, the oracle versions use the true weights instead of wt.
4.2
Experiments
We apply our three base algorithms, their importance weighted versions, and the oracles to 4 standard
DA datasets generating 21 tasks: Digits (MNIST ↔USPS [18, 29]), Visda [51], Ofﬁce-31 [45] and
Ofﬁce-Home [50]. All values are averages over 5 runs of the best test accuracy throughout training
(evaluated at the end of each epoch). We used that value for fairness with respect to the baselines (as
shown in the left panel of Figure 2, the performance of DANN decreases as training progresses, due
to the inappropriate matching of representations showcased in Theorem 2.1). For full details, see
App. ?? and ??.
Performance vs DJS We artiﬁcially generate 100 tasks from MNIST and USPS by considering
various random subsets of the classes in either the source or target domain (see Appendix ?? for
details). These 100 DA tasks have a DJS(DY
S , DY
T) varying between 0 and 0.1. Applying IWDAN
and IWCDAN results in Fig. 1. We see a clear correlation between the improvements provided by
our algorithms and DJS(DY
S , DY
T), which is well aligned with Theorem 2.1. Moreover, IWDAN
outperfoms DANN on the 100 tasks and IWCDAN bests CDAN on 94. Even on small divergences,
our algorithms do not suffer compared to their base versions.
Original Datasets The average results on each dataset are shown in Table 2 (see App.?? for the
per-task breakdown). IWDAN outperforms the basic algorithm DANN by 1.75%, 1.64%, 1.16% and
2.65% on the Digits, Visda, Ofﬁce-31 and Ofﬁce-Home tasks respectively. Gains for IWCDAN are
more limited, but still present: 0.18%, 0.89%, 0.07% and 1.07% respectively. This might be explained
by the fact that CDAN enforces a weak form of GLS (App. ??). Gains for JAN are 0.58%, 0.19%
and 0.19%. We also show the fraction of times (over all seeds and tasks) our variants outperform the
original algorithms. Even for small gains, the variants provide consistent improvements. Additionally,
the oracle versions show larger improvements, which strongly supports enforcing GLS.
7

Table 2: Average results on the various domains (Digits has 2 tasks, Visda 1, Ofﬁce-31 6 and Ofﬁce-
Home 12). The preﬁx s denotes the experiment where the source domain is subsampled to increase
DJS(DY
S , DY
T). Each number is a mean over 5 seeds, the subscript denotes the fraction of times (out
of 5 seeds × #tasks) our algorithms outperform their base versions. JAN is not available on Digits.
METHOD
DIGITS
sDIGITS
VISDA
sVISDA
O-31
sO-31
O-H
sO-H
NO DA
77.17
75.67
48.39
49.02
77.81
75.72
56.39
51.34
DANN
93.15
83.24
61.88
52.85
82.74
76.17
59.62
51.83
IWDAN
94.90100% 92.54100% 63.52100% 60.18100% 83.9087% 82.60100% 62.2797% 57.61100%
IWDAN-O
95.27100% 94.46100% 64.19100% 62.10100% 85.3397% 84.41100% 64.68100% 60.87100%
CDAN
95.72
88.23
65.60
60.19
87.23
81.62
64.59
56.25
IWCDAN
95.9080% 93.22100% 66.4960% 65.83100% 87.3073% 83.88100% 65.6670% 61.24100%
IWCDAN-O 95.8590% 94.81100% 68.15100% 66.85100% 88.1490% 85.47100% 67.6498% 63.73100%
JAN
N/A
N/A
56.98
50.64
85.13
78.21
59.59
53.94
IWJAN
N/A
N/A
57.56100% 57.12100% 85.3260%
82.6197%
59.7863% 55.89100%
IWJAN-O
N/A
N/A
61.48100% 61.30100% 87.14100% 86.24100% 60.7392% 57.36100%
0
10
20
30
40
training epoch
20
40
60
80
100
accuracy on target domain
DANN
IWDAN
IWDAN-O
No DA
0
10
20
30
40
training epoch
0.5
1.0
1.5
2.0
2.5
distance to true weights
DANN
IWDAN
IWDAN-O
No DA
Figure 2: Left Accuracy on sDigits. Right Euclidian distance between estimated and true weights.
Subsampled datasets The original datasets have fairly balanced classes, making the JSD between
source and target label distributions DJS(DY
S ∥DY
T) rather small (Tables ??, ?? and ?? in App. ??).
To evaluate our algorithms on larger divergences, we arbitrarily modify the source domains above
by considering only 30% of the samples coming from the ﬁrst half of their classes. This results in
larger divergences (Tables ??, ?? and ??). Performance is shown in Table 2 (datasets preﬁxed by
s). For IWDAN, we see gains of 9.3%, 7.33%, 6.43% and 5.58% on the digits, Visda, Ofﬁce-31
and Ofﬁce-Home datasets respectively. For IWCDAN, improvements are 4.99%, 5.64%, 2.26% and
4.99%, and IWJAN shows gains of 6.48%, 4.40% and 1.95%. Moreover, on all seeds and tasks but
one, our variants outperform their base versions.
Importance weights While our method demonstrates gains empirically, Lemma 3.2 does not guaran-
tee convergence of w to the true weights. In Fig. 2, we show the test accuracy and distance between
estimated and true weights during training on sDigits. We see that DANN’s performance gets worse
after a few epoch, as predicted by Theorem 2.1. The representation matching objective collapses
classes that are over-represented in the target domain on the under-represented ones (see App. ??).
This phenomenon does not occur for IWDAN and IWDAN-O. Both monotonously improve in accu-
racy and estimation (see Lemma 3.3 and App. ?? for more details). We also observe that IWDAN’s
weights do not converge perfectly. This suggests that ﬁne-tuning λ (we used λ = 0.5 in all our
experiments for simplicity) or updating w more or less often could lead to better performance.
Ablation Study Our algorithms have two components, a weighted adversarial loss Lw
DA and a
weighted classiﬁcation loss Lw
C . In Table 3, we augment DANN and CDAN using those losses
separately (with the true weights). We observe that DANN beneﬁts essentially from the reweighting
of its adversarial loss Lw
DA, the classiﬁcation loss has little effect. For CDAN, gains are essentially
seen on the subsampled datasets. Both losses help, with a +2% extra gain for Lw
DA.
8

Table 3: Ablation study on the Digits tasks.
Method
Digits
sDigits
Method
Digits
sDigits
DANN
93.15
83.24
CDAN
95.72
88.23
DANN + Lw
C
93.27
84.52
CDAN + Lw
C
95.65
91.01
DANN + Lw
DA
95.31
94.41
CDAN + Lw
DA
95.42
93.18
IWDAN-O
95.27
94.46
IWCDAN-O
95.85
94.81
5
Related Work
Covariate shift has been studied and used in many adaptation algorithms [1, 3, 24, 28, 44, 49, 61].
While less known, label shift has also been tackled from various angles over the years: applying EM to
learn DY
T [13], placing a prior on the label distribution [48], using kernel mean matching [19, 42, 57],
etc. Schölkopf et al. [46] cast the problem in a causal/anti-causal perspective corresponding to
covariate/label shift. That perspective was then further developed [4, 21, 31, 57]. Numerous domain
adaptation methods rely on learning invariant representations, and minimize various metrics on the
marginal feature distributions: total variation or equivalently DJS [20, 32, 49, 60], maximum mean
discrepancy [25, 33–36], Wasserstein distance [14–16, 30, 47], etc. Other noteworthy DA methods
use reconstruction losses and cycle-consistency to learn transferable classiﬁers [27, 52, 63]. Recently,
Liu et al. [32] have introduced Transferable Adversarial Training (TAT), where transferable examples
are generated to ﬁll the gap in feature space between source and target domains, the datasets is then
augmented with those samples. Applying our method to TAT is a future research direction.
Other relevant settings include partial ADA, i.e. UDA when target labels are a strict subset of the
source labels / some components of w are 0 [10–12]. Multi-domain adaptation, where multiple
source or target domains are given, is also very studied [17, 26, 38, 41, 43, 59]. Recently, Binkowski
et al. [8] study sample reweighting in the domain transfer to handle mass shifts between distributions.
Prior work on combining importance weight in domain-invariant representation learning also exists
in the setting of partial DA [56]. However, the importance ratio in these works is deﬁned over the
features Z, rather than the class label Y. Compared to our method, this is both statistically inefﬁcient
and computationally expensive, since the feature space Z is often a high-dimensional continuous
space, whereas the label space Y only contains a ﬁnite number (k) of distinct labels. In a separate
work, Yan et al. [54] proposed a weighted MMD distance to handle target shift in UDA. However,
their weights are estimated based on pseudo-labels obtained from the learned classiﬁer, hence it is not
clear whether the pseudo-labels provide accurate estimation of the importance weights even in simple
settings. As a comparison, under GLS, we show that our weight estimation by solving a quadratic
program converges asymptotically.
6
Conclusion and Future Work
We have introduced the generalized label shift assumption, GLS, and theoretically-grounded vari-
ations of existing algorithms to handle mismatched label distributions. On tasks from classic
benchmarks as well as artiﬁcial ones, our algorithms consistently outperform their base versions.
The gains, as expected theoretically, correlate well with the JSD between label distributions across
domains. In real-world applications, the JSD is unknown, and might be larger than in ML datasets
where classes are often purposely balanced. Being simple to implement and adding barely any
computational cost, the robustness of our method to mismatched label distributions makes it very
relevant to such applications.
Extensions The framework we deﬁne in this paper relies on appropriately reweighting the domain
adversarial losses. It can be straightforwardly applied to settings where multiple source and/or target
domains are used, by simply maintaining one importance weights vector w for each source/target
pair [43, 59]. In particular, label shift could explain the observation from Zhao et al. [59] that too
many source domains hurt performance, and our framework might alleviate the issue. One can also
think of settings (e.g. semi-supervised domain adaptation) where estimations of DY
T can be obtained
via other means. A more challenging but also more interesting future direction is to extend our
framework to domain generalization, where the learner has access to multiple labeled source domains
but no access to (even unlabelled) data from the target domain.
9

Acknowledgements
The authors thank Romain Laroche and Alessandro Sordoni for useful feedback and helpful dis-
cussions. HZ and GG would like to acknowledge support from the DARPA XAI project, contract
#FA87501720152 and a Nvidia GPU grant. YW would like acknowledge partial support from NSF
Award #2029626, a start-up grant from UCSB Department of Computer Science, as well as generous
gifts from Amazon, Adobe, Google and NEC Labs.
Broader Impact
Our work focuses on domain adaptation and attempts to properly handle mismatches in the label dis-
tributions between the source and target domains. Domain Adaptation as a whole aims at transferring
knowledge gained from a certain domain (or data distribution) to another one. It can potentially be
used in a variety of decision making systems, such as spam ﬁlters, machine translation, etc.. One
can also potentially think of much more sensitive applications such as recidivism prediction, or loan
approvals.
While it is unclear to us to what extent DA is currently applied, or how it will be applied in the future,
the bias formalized in Th. 2.1 and veriﬁed in Table ?? demonstrates that imbalances between classes
will result in poor transfer performance of standard ADA methods on a subset of them, which is
without a doubt a source of potential inequalities. Our method is actually aimed at counter-balancing
the effect of such imbalances. As shown in our empirical results (for instance Table ??) it is rather
successful at it, especially on signiﬁcant shifts. This makes us rather conﬁdent in the algorithm’s
ability to mitigate potential effects of biases in the datasets. On the downside, failure in the weight
estimation of some classes might result in poor performance on those. However, we have not observed,
in any of our experiments, our method performing signiﬁcantly worse than its base version. Finally,
our method is a variation over existing deep learning algorithms. As such, it carries with it the
uncertainties associated to deep learning models, in particular a lack of interpretability and of formal
convergence guarantees.
References
[1] Tameem Adel, Han Zhao, and Alexander Wong. Unsupervised domain adaptation with a relaxed
covariate shift assumption. In Thirty-First AAAI Conference on Artiﬁcial Intelligence, 2017.
[2] Martin Arjovsky, Léon Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk mini-
mization, 2019. URL http://arxiv.org/abs/1907.02893. cite arxiv:1907.02893.
[3] Jordan T Ash, Robert E Schapire, and Barbara E Engelhardt. Unsupervised domain adaptation
using approximate label matching. arXiv preprint arXiv:1602.04889, 2016.
[4] Kamyar Azizzadenesheli, Anqi Liu, Fanny Yang, and Animashree Anandkumar.
Reg-
ularized learning for domain adaptation under label shifts.
In ICLR (Poster). OpenRe-
view.net, 2019.
URL http://dblp.uni-trier.de/db/conf/iclr/iclr2019.
html#Azizzadenesheli19.
[5] Philip Bachman, R. Devon Hjelm, and William Buchwalter. Learning representations by maxi-
mizing mutual information across views. CoRR, abs/1906.00910, 2019. URL http://dblp.
uni-trier.de/db/journals/corr/corr1906.html#abs-1906-00910.
[6] Shai Ben-David, John Blitzer, Koby Crammer, Fernando Pereira, et al. Analysis of represen-
tations for domain adaptation. Advances in neural information processing systems, 19:137,
2007.
[7] Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jen-
nifer Wortman Vaughan. A theory of learning from different domains. Machine learning, 79
(1-2):151–175, 2010.
[8] Mikolaj Binkowski, R. Devon Hjelm, and Aaron C. Courville. Batch weight for domain
adaptation with mass shift. CoRR, abs/1905.12760, 2019. URL http://dblp.uni-trier.
de/db/journals/corr/corr1905.html#abs-1905-12760.
[9] Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman, Dilip Krishnan, and Dumitru
Erhan. Domain separation networks. In Advances in Neural Information Processing Systems,
pages 343–351, 2016.
10

[10] Zhangjie Cao, Mingsheng Long, Jianmin Wang, and Michael I. Jordan. Partial transfer learn-
ing with selective adversarial networks. In CVPR, pages 2724–2732. IEEE Computer Soci-
ety, 2018. URL http://dblp.uni-trier.de/db/conf/cvpr/cvpr2018.html#
CaoL0J18.
[11] Zhangjie Cao, Lijia Ma, Mingsheng Long, and Jianmin Wang. Partial adversarial domain
adaptation. In Vittorio Ferrari, Martial Hebert, Cristian Sminchisescu, and Yair Weiss, ed-
itors, ECCV (8), volume 11212 of Lecture Notes in Computer Science, pages 139–155.
Springer, 2018. ISBN 978-3-030-01237-3. URL http://dblp.uni-trier.de/db/
conf/eccv/eccv2018-8.html#CaoMLW18.
[12] Zhangjie Cao, Kaichao You, Mingsheng Long, Jianmin Wang, and Qiang Yang. Learning to
transfer examples for partial domain adaptation. In CVPR, pages 2985–2994. Computer Vi-
sion Foundation / IEEE, 2019. URL http://dblp.uni-trier.de/db/conf/cvpr/
cvpr2019.html#CaoYLW019.
[13] Yee Seng Chan and Hwee Tou Ng. Word sense disambiguation with distribution estimation. In
Leslie Pack Kaelbling and Alessandro Safﬁotti, editors, IJCAI, pages 1010–1015. Professional
Book Center, 2005. ISBN 0938075934. URL http://dblp.uni-trier.de/db/conf/
ijcai/ijcai2005.html#ChanN05.
[14] Qingchao Chen, Yang Liu, Zhaowen Wang, Ian Wassell, and Kevin Chetty. Re-weighted
adversarial adaptation network for unsupervised domain adaptation. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition, pages 7976–7985, 2018.
[15] Nicolas Courty, Rémi Flamary, Amaury Habrard, and Alain Rakotomamonjy. Joint distribution
optimal transportation for domain adaptation. In Advances in Neural Information Processing
Systems, pages 3730–3739, 2017.
[16] Nicolas Courty, Rémi Flamary, Devis Tuia, and Alain Rakotomamonjy. Optimal transport for
domain adaptation. IEEE transactions on pattern analysis and machine intelligence, 39(9):
1853–1865, 2017.
[17] Hal Daumé III. Frustratingly easy domain adaptation. arXiv preprint arXiv:0907.1815, 2009.
[18] Dua Dheeru and EﬁKarra. UCI machine learning repository, 2017. URL http://archive.
ics.uci.edu/ml.
[19] Marthinus Christoffel du Plessis and Masashi Sugiyama.
Semi-supervised learning of
class balance under class-prior change by distribution matching. Neural Networks, 50:110–
119, 2014. URL http://dblp.uni-trier.de/db/journals/nn/nn50.html#
PlessisS14.
[20] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, François
Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural
networks. Journal of Machine Learning Research, 17(59):1–35, 2016.
[21] Mingming Gong, Kun Zhang, Tongliang Liu, Dacheng Tao, Clark Glymour, and Bernhard
Schölkopf. Domain adaptation with conditional transferable components. In International
conference on machine learning, pages 2839–2848, 2016.
[22] Ian Goodfellow,
Yoshua Bengio,
and Aaron Courville.
Deep learning.
2017.
ISBN 9780262035613 0262035618.
URL https://www.worldcat.org/title/
deep-learning/oclc/985397543&referer=brief_results.
[23] Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil
Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial networks, 2014. URL
http://arxiv.org/abs/1406.2661. cite arxiv:1406.2661.
[24] Arthur Gretton, Alex Smola, Jiayuan Huang, Marcel Schmittfull, Karsten Borgwardt, and
Bernhard Schölkopf. Covariate shift by kernel mean matching. Dataset shift in machine
learning, 3(4):5, 2009.
[25] Arthur Gretton, Karsten M Borgwardt, Malte J Rasch, Bernhard Schölkopf, and Alexander
Smola. A kernel two-sample test. Journal of Machine Learning Research, 13(Mar):723–773,
2012.
[26] Jiang Guo, Darsh J Shah, and Regina Barzilay. Multi-source domain adaptation with mixture of
experts. arXiv preprint arXiv:1809.02256, 2018.
11

[27] Judy Hoffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu, Phillip Isola, Kate Saenko, Alexei A
Efros, and Trevor Darrell. Cycada: Cycle-consistent adversarial domain adaptation. arXiv
preprint arXiv:1711.03213, 2017.
[28] Jiayuan Huang, Arthur Gretton, Karsten M Borgwardt, Bernhard Schölkopf, and Alex J Smola.
Correcting sample selection bias by unlabeled data. In Advances in neural information process-
ing systems, pages 601–608, 2006.
[29] Yann
LeCun
and
Corinna
Cortes.
MNIST
handwritten
digit
database.
http://yann.lecun.com/exdb/mnist/, 2010.
URL http://yann.lecun.com/exdb/
mnist/.
[30] Jaeho Lee and Maxim Raginsky. Minimax statistical learning with wasserstein distances. In
Advances in Neural Information Processing Systems, pages 2692–2701, 2018.
[31] Zachary Lipton, Yu-Xiang Wang, and Alexander Smola. Detecting and correcting for label shift
with black box predictors. In International Conference on Machine Learning, pages 3128–3136,
2018.
[32] Hong Liu, Mingsheng Long, Jianmin Wang, and Michael I. Jordan.
Transferable adver-
sarial training: A general approach to adapting deep classiﬁers. In Kamalika Chaudhuri
and Ruslan Salakhutdinov, editors, ICML, volume 97 of Proceedings of Machine Learning
Research, pages 4013–4022. PMLR, 2019. URL http://dblp.uni-trier.de/db/
conf/icml/icml2019.html#LiuLWJ19.
[33] Mingsheng Long, Jianmin Wang, Guiguang Ding, Jiaguang Sun, and Philip S Yu. Transfer
joint matching for unsupervised domain adaptation. In Proceedings of the IEEE conference on
computer vision and pattern recognition, pages 1410–1417, 2014.
[34] Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable features
with deep adaptation networks. In International Conference on Machine Learning, pages
97–105, 2015.
[35] Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan. Unsupervised domain
adaptation with residual transfer networks. In Advances in Neural Information Processing
Systems, pages 136–144, 2016.
[36] Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan. Deep transfer learning with
joint adaptation networks. In Proceedings of the 34th International Conference on Machine
Learning-Volume 70, pages 2208–2217. JMLR, 2017.
[37] Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael I. Jordan. Conditional adversarial
domain adaptation. In Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman,
Nicolò Cesa-Bianchi, and Roman Garnett, editors, NeurIPS, pages 1647–1657, 2018. URL
http://dblp.uni-trier.de/db/conf/nips/nips2018.html#LongC0J18.
[38] Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh. Domain adaptation with multiple
sources. In Advances in neural information processing systems, pages 1041–1048, 2009.
[39] R. Thomas McCoy, Ellie Pavlick, and Tal Linzen. Right for the wrong reasons: Diagnosing
syntactic heuristics in natural language inference. Proceedings of the ACL, 2019.
[40] Alfred Müller. Integral probability metrics and their generating classes of functions. Advances
in Applied Probability, 29(2):429–443, 1997.
[41] Hyeonseob Nam and Bohyung Han. Learning multi-domain convolutional neural networks for
visual tracking. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
June 2016.
[42] Tuan Duong Nguyen, Marthinus Christoffel du Plessis, and Masashi Sugiyama. Continuous
target shift adaptation in supervised learning. In ACML, volume 45 of JMLR Workshop and Con-
ference Proceedings, pages 285–300. JMLR.org, 2015. URL http://dblp.uni-trier.
de/db/conf/acml/acml2015.html#NguyenPS15.
[43] Xingchao Peng, Zijun Huang, Ximeng Sun, and Kate Saenko. Domain agnostic learning with
disentangled representations. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, ICML,
volume 97 of Proceedings of Machine Learning Research, pages 5102–5112. PMLR, 2019. URL
http://dblp.uni-trier.de/db/conf/icml/icml2019.html#PengHSS19.
12

[44] Ievgen Redko, Nicolas Courty, Rémi Flamary, and Devis Tuia. Optimal transport for multi-
source domain adaptation under target shift. In 22nd International Conference on Artiﬁcial
Intelligence and Statistics (AISTATS) 2019, volume 89, 2019.
[45] Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Darrell. Adapting visual category models to
new domains. In Kostas Daniilidis, Petros Maragos, and Nikos Paragios, editors, ECCV (4), vol-
ume 6314 of Lecture Notes in Computer Science, pages 213–226. Springer, 2010. ISBN 978-3-
642-15560-4. URL http://dblp.uni-trier.de/db/conf/eccv/eccv2010-4.
html#SaenkoKFD10.
[46] Bernhard Schölkopf, Dominik Janzing, Jonas Peters, Eleni Sgouritsa, Kun Zhang, and Joris M.
Mooij. On causal and anticausal learning. In ICML. icml.cc / Omnipress, 2012. URL http://
dblp.uni-trier.de/db/conf/icml/icml2012.html#ScholkopfJPSZM12.
[47] Jian Shen, Yanru Qu, Weinan Zhang, and Yong Yu. Wasserstein distance guided representation
learning for domain adaptation. In Thirty-Second AAAI Conference on Artiﬁcial Intelligence,
2018.
[48] Amos Storkey. When training and test sets are different: Characterising learning transfer.
Dataset shift in machine learning., 2009.
[49] Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell. Adversarial discriminative domain
adaptation. arXiv preprint arXiv:1702.05464, 2017.
[50] Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan.
Deep hashing network for unsupervised domain adaptation. In (IEEE) Conference on Computer
Vision and Pattern Recognition (CVPR), 2017.
[51] Visda.
Visual domain adaptation challenge, 2017.
URL http://ai.bu.edu/
visda-2017/.
[52] Shaoan Xie, Zibin Zheng, Liang Chen, and Chuan Chen. Learning semantic representations
for unsupervised domain adaptation. In Jennifer G. Dy and Andreas Krause, editors, ICML,
volume 80 of Proceedings of Machine Learning Research, pages 5419–5428. PMLR, 2018. URL
http://dblp.uni-trier.de/db/conf/icml/icml2018.html#XieZCC18.
[53] Yadollah Yaghoobzadeh, Remi Tachet des Combes, Timothy J. Hazen, and Alessandro
Sordoni.
Robust natural language inference models with example forgetting.
CoRR,
abs/1911.03861, 2019. URL http://dblp.uni-trier.de/db/journals/corr/
corr1911.html#abs-1911-03861.
[54] Hongliang Yan, Yukang Ding, Peihua Li, Qilong Wang, Yong Xu, and Wangmeng Zuo. Mind the
class weight bias: Weighted maximum mean discrepancy for unsupervised domain adaptation.
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages
2272–2281, 2017.
[55] Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson. How transferable are features in
deep neural networks? In Advances in neural information processing systems, pages 3320–3328,
2014.
[56] Jing Zhang, Zewei Ding, Wanqing Li, and Philip Ogunbona. Importance weighted adversarial
nets for partial domain adaptation. In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, pages 8156–8164, 2018.
[57] Kun Zhang, Bernhard Schölkopf, Krikamol Muandet, and Zhikun Wang. Domain adaptation
under target and conditional shift. In International Conference on Machine Learning, pages
819–827, 2013.
[58] Xu Zhang, Felix X. Yu, Shih-Fu Chang, and Shengjin Wang. Deep transfer network: Unsuper-
vised domain adaptation. CoRR, abs/1503.00591, 2015. URL http://dblp.uni-trier.
de/db/journals/corr/corr1503.html#ZhangYCW15.
[59] Han Zhao, Shanghang Zhang, Guanhang Wu, Geoffrey J Gordon, et al. Multiple source domain
adaptation with adversarial learning. In International Conference on Learning Representations,
2018.
[60] Han Zhao, Shanghang Zhang, Guanhang Wu, José MF Moura, Joao P Costeira, and Geoffrey J
Gordon. Adversarial multiple source domain adaptation. In Advances in Neural Information
Processing Systems, pages 8568–8579, 2018.
13

[61] Han Zhao, Junjie Hu, Zhenyao Zhu, Adam Coates, and Geoff Gordon. Deep generative and
discriminative domain adaptation. In Proceedings of the 18th International Conference on
Autonomous Agents and MultiAgent Systems, pages 2315–2317. International Foundation for
Autonomous Agents and Multiagent Systems, 2019.
[62] Han Zhao, Remi Tachet des Combes, Kun Zhang, and Geoffrey J. Gordon. On learning
invariant representations for domain adaptation. In Kamalika Chaudhuri and Ruslan Salakhut-
dinov, editors, ICML, volume 97 of Proceedings of Machine Learning Research, pages
7523–7532. PMLR, 2019.
URL http://dblp.uni-trier.de/db/conf/icml/
icml2019.html#0002CZG19.
[63] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A. Efros. Unpaired image-to-image
translation using cycle-consistent adversarial networks. In ICCV, pages 2242–2251. IEEE
Computer Society, 2017. ISBN 978-1-5386-1032-9. URL http://dblp.uni-trier.
de/db/conf/iccv/iccv2017.html#ZhuPIE17.
14

