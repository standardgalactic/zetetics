QLSD: Quantised Langevin stochastic dynamics for
Bayesian federated learning
Maxime Vono
Lagrange Mathematics and Computing Research Center, Huawei
75007 Paris, France
maxime.vono@huawei.com
Vincent Plassier
CMAP, École Polytechnique
Institut Polytechnique de Paris
Lagrange Mathematics and Computing Research Center, Huawei
vincent.plassier@polytechnique.edu
Alain Durmus
Université Paris-Saclay
ENS Paris-Saclay, CNRS
Centre Borelli, F-91190 Gif-sur-Yvette, France
alain.durmus@ens-paris-saclay.fr
Aymeric Dieuleveut
CMAP, École Polytechnique
Institut Polytechnique de Paris
aymeric.dieuleveut@polytechnique.edu
Éric Moulines
CMAP, École Polytechnique
Institut Polytechnique de Paris
eric.moulines@polytechnique.edu
Abstract
Federated learning aims at conducting inference when data are decentralised
and locally stored on several clients, under two main constraints: data owner-
ship and communication overhead. In this paper, we address these issues under
the Bayesian paradigm. To this end, we propose a novel Markov chain Monte
Carlo algorithm coined QLSD built upon quantised versions of stochastic gradient
Langevin dynamics. To improve performance in a big data regime, we intro-
duce variance-reduced alternatives of our methodology referred to as QLSD⋆and
QLSD++. We provide both non-asymptotic and asymptotic convergence guaran-
tees for the proposed algorithms and illustrate their beneﬁts on several federated
learning benchmarks.
1
Introduction
In the modern big data era, it has become commonplace to acquire and process a large amount of
data at the edge nodes of a network. These nodes are typically devices (coined clients), such as
IoT sensors or mobiles, coordinated by a central server [21, 26, 30, 37, 41]. This rapid progress in
data acquisition and storage has contributed to bring out new paradigms regarding the access to the
data and their use in machine learning. First, communication overhead is limited in many scenarios.
For example, upload bandwidth is in most cases limited to 1 MB/s or less [35]. This is in contrast
to traditional distributed machine learning where computational costs dominate. A second prime
Preprint. Under review.
arXiv:2106.00797v1  [cs.LG]  1 Jun 2021

concern in this context is data ownership [1] which presupposes a restricted access to the data stored
on each client.
Federated learning (FL) is a particular branch of machine learning which aims at addressing these
new challenges [30]. Similarly to traditional machine learning, the current FL paradigm consid-
ers the minimisation of an empirical risk function deﬁned over the entire dataset gathered from
each client.
As such, many methods derived from stochastic gradient descent techniques have
been proposed in the literature to meet the speciﬁc FL constraints [5, 25, 31, 33, 35, 40]. Whilst
these approaches have successfully solved some issues associated to FL, they are unable to capture
and quantify epistemic predictive uncertainty which is essential in many applications such as au-
tonomous driving or precision medicine [20, 27]. The Bayesian paradigm [45] stands for a natural
candidate to quantify uncertainty and as such has become ubiquitous in the machine learning com-
munity [6]. Many recent proposals have focused on scaling serial workhorses Bayesian methods
such as variational and Markov chain Monte Carlo (MCMC) algorithms to distributed architectures
[3, 11, 29, 42, 49, 53–55]; but very few have tried to address the challenges inherent in FL [19, 32].
In this paper, we address this problem by proposing a novel Bayesian FL approach based on stochas-
tic Langevin dynamics. The posterior distribution is assumed to admit a probability density function
which stands for the product of local posterior densities associated to each client. At each iteration
of the algorithm, each client computes a stochastic gradient oracle of its associated negative log
posterior density. However, under the considered FL framework, the upload period has a very sig-
niﬁcant practical impact [30, Section 3.5]. This communication bottleneck is addressed by making
each client sending lossy compression of their stochastic gradient oracles to the central server, so
that the number of communicated bits during the upload period is signiﬁcantly reduced [2, 15]. This
approach coined quantised Langevin stochastic dynamics and referred to as QLSD can be interest-
ingly seen as a MCMC counterpart of the QSGD approach in FL [5], as stochastic gradient Langevin
dynamics (SGLD) is for stochastic gradient descent (SGD) [56]. Because of the use of stochastic
gradients, the proposed methodology has the same drawbacks as SGLD. Notably, the invariant dis-
tribution associated with QLSD might depart from the target distribution and become similar to the
invariant measure of SGD when the number of observations is large [9]. We overcome this issue
by deriving two variance-reduced versions of QLSD referred to as QLSD⋆and QLSD++ which both
involve control variates that are either ﬁxed or iteratively updated.
Contributions. Our contribution is three-folded. (1) We propose a general MCMC algorithm coined
QLSD especially designed for Bayesian inference under the FL paradigm along with two variance-
reduced alternatives. We also highlight the impact of the discrepancy between local posterior distri-
butions and propose to mitigate its impact on convergence by either using biased stochastic gradients
or introducing a memory mechanism similar to the one used in traditional risk-based FL [25]. (2)
We provide a non-asymptotic convergence analysis of the proposed algorithms. This theoretical
analysis is complemented by a consistency study in a big data regime. In particular, we show that
variance reduction indeed allows the proposed MCMC algorithm to converge towards the target
posterior distribution when the number of observations becomes large. (3) We illustrate the beneﬁts
of the proposed methodology on several FL benchmarks involving both synthetic and real datasets.
Remarkably, we show that the proposed methodology allows the number of exchanged bits to be
signiﬁcantly reduced while keeping similar performances as its non-compressed counterpart.
Notations and conventions. The Euclidean norm on Rd is denoted by ∥·∥and we set N∗= N\{0}.
For n ∈N∗, we refer to {1, . . . , n} with the notation [n]. For N ∈N∗, we use ℘N to denote
the power set of [N] and deﬁne ℘N,n = {x ∈℘N
: card(x) = n} for any n ∈[N]. We
denote by N(m, Σ) the Gaussian distribution with mean vector m and covariance matrix Σ. We
deﬁne the signum function, for any x ∈R, as sign(x) = 1{x ≥0} −1{x < 0}. We deﬁne the
Wasserstein distance of order 2 for any probability measures µ, ν on Rd with ﬁnite 2-moment by
W2(µ, ν) = (infζ∈T (µ,ν)
R
Rd×Rd ∥θ −θ′∥2dζ(θ, θ′))1/2, where T (µ, ν) is the set of transference
plans of µ and ν.
2
Quantised Langevin stochastic dynamics
This section presents the considered Bayesian FL framework and introduces the proposed method-
ology called QLSD along with two speciﬁc variance-reduced instances.
2

Problem statement.
We are interested in carrying out Bayesian inference about a parameter θ ∈
Rd based on a dataset D. The posterior distribution of interest is assumed to admit a product-form
density with respect to the d-dimensional Lebesgue measure, i.e.
π (θ | D) = Z−1
π
b
Y
i=1
e−Ui(θ) ,
(1)
where b ∈N∗and Zπ =
R
Rd
Qb
i=1 e−Ui(θ) dθ is a normalisation constant. This framework natu-
rally encompasses the considered Bayesian FL problem. In this context, {e−Ui}i∈[b] stand for the
unnormalised local posterior density functions associated to b clients, where each client i ∈[b] is
assumed to own a local dataset Di such that D = ⊔b
i=1Di. For the sake of brevity, the dependency
of Ui : Rd →R on the local dataset Di is notationally omitted.
A popular approach to sample from a target distribution with density π deﬁned in (1) is based on
Langevin dynamics, i.e.
dϑt = −∇U(ϑt)dt +
√
2dBt ,
where U = Pb
i=1 Ui and (Bt)t≥0 is a d-dimensional Brownian motion. Indeed, this stochastic
differential equation deﬁnes a strong Markov semigroup (Pt)t≥0 which is ergodic with respect to
π and converges in various metrics under mild assumptions on the potential U [8, 47]. However,
sampling Langevin dynamics is not an option in most cases and discretisation schemes have to be
used in place. The simpler and most popular choice is the Euler-Maruyama scheme which, starting
from an initial point θ0, deﬁnes a Markov chain (θk)k∈N by the recursion for any k ∈N,
θk+1 = θk −γ∇U(θk) +
p
2γZk+1 ,
where γ ∈(0, ¯γ], for some ¯γ > 0, is a discretisation time-step and (Zk)k∈N∗is a sequence of
independent and identically distributed (i.i.d.) standard Gaussian random variables [23, 38, 47].
The corresponding scheme is referred to as the unadjusted Langevin algorithm (ULA). In machine
learning applications, evaluating ∇U can be either a computational bottleneck or not even feasible.
To circumvent this issue, a common solution is to replace ∇U by statistical estimators [39, 44].
More precisely, ∇U is approximated by a function H : Rd ×X1 →Rd deﬁned on some measurable
space (X1, X1) endowed with a probability measure ν1 such that ∇U(θ) =
R
X1 H(θ, x(1))dν1(x(1)).
The associated recursion writes
θk+1 = θk −γH(θk, X(1)
k+1) +
p
2γZk+1 ,
k ∈N .
(2)
In a serial setting involving a single client which owns a dataset of size N ∈N∗, the potential
U writes U = U1 = PN
j=1 U1,j for some functions U1,j : Rd →R, and a popular instance of
this framework is SGLD [56]. This algorithm consists in the recursion (2) with the speciﬁc choice
H(θ, X(1)
k+1) = (N/n) P
j∈X(1)
k+1 ∇U1,j(θ), where (X(1)
k )k∈N∗is a sequence of i.i.d. uniform ran-
dom subsets of [N] of cardinal n. Here, X1 = [N] and ν1 is the uniform distribution over ℘N,n.
In the considered FL framework where the clients can perform parallel computations, we assume
that the i-th client has access to a stochastic gradient oracle Hi : Rd × X1 →Rd associated to its
local negative log. posterior density Ui so that Hi only depends on Di. Therefore, H = Pb
i=1 Hi is
itself a stochastic gradient oracle of U and admits a similar decomposition. Note that we do not nec-
essarily assume in what follows that {Hi}i∈[b] stand for unbiased estimators of {∇Ui}i∈[b] but only
constrain H to be unbiased. This will allow us to consider biased local stochastic gradient oracles
with better convergence guarantees, see Section 3 for more details. A straightforward adaptation of
SGLD deﬁned in (2) to the considered FL framework is given by the recursion
θk+1 = θk −γ
b
X
i=1
Hi(θk, X(1,i)
k+1 ) +
p
2γZk+1 ,
k ∈N ,
(3)
where (X(1,1)
k
, . . . , X(1,b)
k
)k∈N∗is a sequence of i.i.d. random variables distributed according to
ν⊗b
1 . When, for any i ∈[b], each potential function Ui also admits a ﬁnite-sum expression i.e.
Ui = PN
j=1 Ui,j where Ui,j : Rd →R, similarly to SGLD, we may consider for example the local
stochastic gradient oracles Hi(θ, X(1,i)
k+1 ) = (N/n) P
j∈X(1,i)
k+1 ∇Ui,j(θ) where (X(i,1)
k+1 )k∈N∗, i∈[b]
3

stand for i.i.d. uniform random subsets of [N] of cardinal n. However, considering the MCMC
algorithm associated with the recursion (3) is not adapted to the FL context. Indeed, this algo-
rithm would suffer from the same issues as SGD in a risk-based minimisation context, especially a
prohibitive communication overhead [22].
Proposed methodology. To address this problematic, we propose to reduce the number of bits
communicated during the upload period by performing lossy compressions of {Hi}i∈[b] [2, 15].
This method has been extensively used in the risk-based FL literature [5, 24, 34, 48] but, up to the
authors’ knowledge, has interestingly never been considered from a Bayesian perspective. To this
purpose, we introduce a compression operator C : Rd × X2 →Rd deﬁned on some measurable
space (X2, X2) endowed with a probability measure ν2 which is unbiased, i.e. for any v ∈Rd,
v =
R
X2 C (v, x(2))dν2(x(2)). Numerous compression operators have been proposed over the past
few years ranging from quantisation operators [5, 50] to sparsiﬁcation ones [4, 51]. As an example,
the seminal QSGD approach proposed in [5] is based on stochastic quantisation. More speciﬁcally, [5]
considers for C a component-wise quantisation operator parametrised by a number of quantisation
levels s ≥1 deﬁned, for any j ∈[d] and v = (v1, . . . , vd) ∈Rd, by
C (s)
j
(v, ξj) = ∥v∥· sign(vj) · (⌊s|vj|/ ∥v∥⌋+ 1{ξj ≤s|vj|/ ∥v∥−⌊s|vj|/ ∥v∥⌋}) /s ,
(4)
where {ξj}j∈[d] is a sequence of i.i.d. uniform random variables on [0, 1]. In this particular case,
we will denote the quantisation of v via (4) by C (s)(v, x(2)) = {C (s)
j
(v, x(2)
j )}j∈[d] with x(2) =
{x(2)
j }j∈[d] ∈[0, 1]d.
The proposed general methodology, coined quantised Langevin stochastic dynamics (QLSD) stands
for a compressed version of the speciﬁc instance of SGLD deﬁned in (3). More precisely, QLSD is a
MCMC algorithm associated with the Markov chain (θk)k∈N starting from θ0 and deﬁned by
θk+1 = θk −γ
b
X
i=1
C
h
Hi(θk, X(1,i)
k+1 ), X(2,i)
k+1
i
+
p
2γZk+1 ,
k ∈N ,
(5)
where (X(2,1)
k
, . . . , X(2,b)
k
)k∈N∗is a sequence of i.i.d. random variables distributed according to
ν⊗b
2 . The derivation of the QLSD in the considered Bayesian FL context is detailed in Algorithm 1.
Note that key challenges associated to FL are addressed: each client does not broadcast its own data
and the communication bottleneck is overcome thanks to the compression step. In the particular case
of the ﬁnite-sum setting, i.e. for the choice Hi(θ, x(1,i)) = (N/n) P
j∈x(1,i) ∇Ui,j(θ) for θ ∈Rd,
x(1,i) ∈X1 = ℘N,n and ν1 being the uniform distribution on ℘N,n, we refer to the corresponding
instance of QLSD as QLSD#.
Algorithm 1 Quantised Langevin stochastic dynamics (QLSD)
Input: number of iterations K, compression operator C , stochastic gradient oracles {Hi}i∈[b],
step-size γ ∈(0, ¯γ] and initial point θ0.
for k = 0 to K −1 do
for i = 1 to b // In parallel on the b clients do
Draw X(1,i)
k+1 ∼ν1 and X(2,i)
k+1 ∼ν2.
Compute and send gi,k+1 = C
h
Hi(θk, X(1,i)
k+1 ), X(2,i)
k+1
i
to the central server.
end for
// On the central server
Compute gk+1 = Pb
i=1 gi,k+1.
Draw Zk+1 ∼N(0d, Id)
Compute and send θk+1 = θk −γgk+1 + √2γZk+1 to the b clients.
end for
Output: samples {θk}K
k=0.
Variance-reduced alternatives.
Consider the ﬁnite-sum setting i.e.
for any i ∈[b], Ui =
PN
j=1 Ui,j, set X1 = [N] and ν1 the uniform distribution over ℘N,n. In that case, as highlighted
4

in Section 1, SGLD-based approaches including Algorithm 1 are associated with an invariant distri-
bution which might depart from the target posterior distribution as N goes to inﬁnity because of
the use of stochastic gradients with large variance [7, 9]. We cope with this problem by propos-
ing two variance-reduced alternatives of QLSD# detailed in Algorithm 2 which make use of control
variates. The most simple variance-reduced approach referred to as QLSD⋆considers a ﬁxed-point
approach which uses a minimiser θ⋆of the potential U [7, 9]. In this scenario, the stochastic
gradient oracles {Hi}i∈[b] write, for any i ∈[b], θ ∈Rd and x(1,i) ∈℘N,n, Hi(θ, x(1,i)) =
(N/n) P
j∈x(1,i)[∇Ui,j(θ) −∇Ui,j(θ⋆)]. Although
R
Xb
1 H(·, x(1))dν⊗b
1 (x(1)) = ∇U(·), note that
for any i ∈[b],
R
Xb
1 Hi(·, x(1,i))dν1(x(1,i)) ̸= ∇Ui(·) so that {Hi}i∈[b] are not unbiased estimates
of {Ui}i∈[b]. We show in Section 3 that introducing this bias improves the convergence properties
of QLSD# with respect to the discrepancy between local posterior distributions.
Since the estimation of θ⋆in a FL context might add a computational burden to the sampling pro-
cedure, we propose another variance-reduced version of QLSD# coined QLSD++ which builds upon
stochastic variance reduced gradient (SVRG) and uses control variates (ζk)k∈N that are updated ev-
ery l ∈N∗iterations [28]. In addition, we consider for {Hi}b
i=1 stochastic gradient oracles which
are updated through the scheme based on (ζk)k∈N. More precisely, at each iteration k ∈N and
for i ∈[b], the stochastic gradient oracle Hi is deﬁned, for any θ ∈Rd and x(1,i) ∈℘N,n, by
Hi(θ, x(1,i)) = (N/n) P
j∈x(1,i)[∇Ui,j(θ) −∇Ui,j(ζk)] + ∇Ui(ζk). In order to reduce the impact
of local posterior discrepancy on convergence, we take inspiration from the risk-based FL literature
and consider a memory term (η(i)
k )k∈N on each client i ∈[b] [16, 25]. Instead of directly compress-
ing {Hi}i∈[b] at each iteration k, we compress the difference Hi(θ, X(1,i)
k+1 ) −η(i)
k , store it in gi,k+1,
and then compute the global stochastic gradient gk+1 = Pb
i=1 gi,k+1 + η(i)
k . The memory term
(η(i)
k )k∈N is then updated on each client by the recursion η(i)
k+1 = η(i)
k
+ αgi,k+1 where α ∈(0, ¯α],
for some ¯α > 0. The beneﬁts of using this memory mechanism will be assessed theoretically in
Section 3 and illustrated numerically in Section 4.
3
Theoretical analysis
This section provides a detailed theoretical analysis of the proposed methodology. We will show
the impact of the use of stochastic gradients and compression by deriving quantitative convergence
bounds for QLSD detailed in Algorithm 1. Then, we will derive non-asymptotic convergence bounds
for QLSD⋆and QLSD++ and show explicitly that these variance-reduced algorithms indeed man-
age to reduce both the variance brought by stochastic gradients and the impact of local posterior
discrepancy in the bounds we get for QLSD#.
We consider the following set of assumptions on the potential U and the compression operator C .
H1. For any i ∈[b], Ui is continuously differentiable. In addition, suppose that the following hold.
(i) U is m-strongly convex, i.e. for any θ1, θ2 ∈Rd, ⟨∇U(θ1) −∇U(θ2), θ1 −θ2⟩≥m ∥θ1 −θ2∥2.
(ii) U is L-Lipschitz, i.e. for any θ1, θ2 ∈Rd, ∥∇U (θ1) −∇U (θ2)∥≤L ∥θ1 −θ2∥.
Note that H1-(i) implies that U admits a unique minimiser denoted by θ⋆∈Rd. Moreover, for any
(θ1, θ1) ∈Rd, H1-(i)-(ii) combined with [36, Equation 2.1.24] shows that
⟨∇U(θ2) −∇U(θ1), θ2 −θ1⟩≥
mL
m + L ∥θ2 −θ1∥2 +
1
m + L ∥∇U(θ2) −∇U(θ1)∥2 .
(6)
H2. There exists a probability measure ν2 on a measurable space (X2, X2) and a measurable func-
tion C : Rd × X2 →Rd such that the following conditions hold.
(i) For any v ∈Rd,
R
X2 C (v, x(2)) ν2(dx(2)) = v.
(ii) There exists ω ∈R+, such that for any v ∈Rd,
R
X2
C (v, x(2)) −v
2 ν2(dx(2)) ≤ω ∥v∥2.
As an example, the assumption on the variance of the compression operator detailed in H2-(ii) is
veriﬁed for the quantisation operator C (s) deﬁned, for s ≥1, in (4) with ω = min(d/s2,
√
d/s) [5,
Lemma 3.1].
5

Algorithm 2 Variance-reduced quantised Langevin stochastic dynamics (QLSD⋆and QLSD++)
Input: minibatch size n, number of iterations K, compression operator C , step-size γ ∈(0, ¯γ]
with ¯γ > 0, initial point θ0 and α ∈(0, ¯α] with ¯α > 0 for QLSD++, or θ⋆for QLSD⋆.
// Memory mechanism initialisation
Initialise {η(1)
0 , . . . , η(b)
0 } and η0 = Pb
i=1 η(i)
0
(for QLSD⋆, set η(i)
0
= 0 for any i ∈[b]).
for k = 0 to K −1 do
// Update of the control variates
Set ζk = θ⋆. // For QLSD⋆
if k ≡0 (mod l) then // For QLSD++
Set ζk = θk.
else
Set ζk = ζk−1
end if
for i = 1 to b // In parallel on the b clients do
Draw X(1,i)
k+1 ∼Uniform (℘N,n) and X(2,i)
k+1 ∼ν2.
Set hi,k+1 = 0d (for QLSD⋆) or hi,k+1 = ∇Ui(ζk) (for QLSD++).
Compute Hi(θk, X(1,i)
k+1 ) = (N/n) P
j∈X(1,i)
k+1 [∇Ui,j(θk) −∇Ui,j(ζk)] + hi,k+1.
Compute gi,k+1 = C

Hi(θk, X(1,i)
k+1 ) −η(i)
k , X(2,i)
k+1

.
Send gi,k+1 to the central server.
Set η(i)
k+1 = η(i)
k + αgi,k+1 (for QLSD⋆) or η(i)
k+1 = η(i)
k
(for QLSD++).
end for
// On the central server
Compute gk+1 = ηk + Pb
i=1 gi,k+1.
Set ηk+1 = ηk + α Pb
i=1 gi,k+1.
Draw Zk+1 ∼N(0d, Id).
Compute and send θk+1 = θk −γgk+1 + √2γZk+1 to the b clients.
end for
Output: samples {θk}K
k=0.
Non-asymptotic convergence analysis for Algorithm 1. We consider the following assumptions
on the family {Hi : Rd × X1 →Rd}i∈[b].
H3. There exists a probability measure ν1 on a measurable space (X1, X1) and a family of measur-
able functions {Hi : Rd × X1 →Rd}i∈[b] such that the following conditions hold.
(i) For any θ ∈Rd, Pb
i=1
R
X1 Hi(θ, x(1))ν1(dx(1)) = ∇U (θ).
(ii) There exists M > 0, such that for any i ∈[b], θ1, θ2 ∈Rd,
Z
X1
Hi(θ1, x(1)) −Hi(θ2, x(1))
2 ν1(dx(1)) ≤M ⟨θ1 −θ2, ∇Ui (θ1) −∇Ui (θ2)⟩.
(iii) There exists σ⋆, B⋆∈R+ such that for any θ ∈Rd, we have
Z
X1
Hi(θ⋆, x(1))
2 ν1(dx(1)) ≤B⋆/b ,
Z
Xb
1

b
X
i=1
Hi(θ⋆, x(1,i))

2
ν⊗b
1 (dx(1,1:b)) ≤σ2
⋆.
We can notice that H3-(ii) implies that ∇Ui is M-Lipschitz continuous since by the Cauchy-
Schwarz inequality, for any i
∈
[b] and any θ1, θ2
∈
Rd, ∥∇Ui (θ1) −∇Ui (θ2)∥2
≤
M ⟨θ1 −θ2, ∇Ui (θ1) −∇Ui (θ2)⟩.
Conversely, in the ﬁnite-sum setting, H3-(ii) is satisﬁed by
QLSD# with M = N¯M if for any i ∈[b] and j ∈[N], Ui,j is convex and ∇Ui,j is ¯M-Lipschitz contin-
uous, for ¯M ≥0 by [36, Theorem 2.1.5]. In addition, it is worth mentioning that the ﬁrst inequality
in H3-(iii) is also required for our derivation in the deterministic case where Hi = ∇Ui due to the
compression operator. In this particular case, B⋆stands for an upper-bound on Pb
i=1 ∥∇Ui(θ⋆)∥2
and corresponds to some discrepancy between local posterior density functions meaning that
6

Table 1: Order of the asymptotic biases {B¯γ, B⃝⋆,¯γ, B⊕,¯γ}, associated to the three proposed MCMC
algorithms, in squared 2-Wasserstein distance for two types of asymptotic. In the ﬁnite-sum set-
ting and asymptotic scenario N →∞, we set γ = η/N for some η ∈(0, N ¯η] and assume that
lim infN→∞m/N > 0 and lim supN→∞A/N > 0 for A ∈{L, M, σ⋆}.
Algorithm,
asymp. bias
Dependencies of the
asymp. bias when ¯γ ↓0
Dependencies of the
asymp. bias as N →∞
d
{Hi}i∈[b]
B⋆
ω
QLSD, B¯γ
d
σ2
⋆
B⋆
ω
O(N)
QLSD#, B¯γ
d
N 2
Pb
i=1 ∥∇Ui(θ⋆)∥2
ω
O(N)
QLSD⋆, B⃝⋆,¯γ
d
N
-
ω
d O (1)
QLSD++, B⊕,¯γ
d
N
-
ω
d O (1)
∇Ui ̸= ∇U for i ∈[b]. This phenomenon, referred to as data heterogeneity in risk-based liter-
ature [25, 31], is ubiquitous in the FL context [30]. Under the above assumptions and by denoting
Qγ the Markov kernel associated to Algorithm 1, the following convergence result holds.
Theorem 1. Assume H1, H2 and H3. Then, there exists ¯γ∞such that for ¯γ < ¯γ∞, there exist
A¯γ, B¯γ > 0 (explicitly given in Appendix S1.3) satisfying for any probability measure µ ∈P2
 Rd
,
any step size γ ∈(0, ¯γ] and k ∈N,
W 2
2
 µQk
γ, π

≤(1 −γm/2)k · W 2
2 (µ, π) + γB¯γ + γ2A¯γ(1 −mγ/2)k−1k ·
Z
Rd ∥θ −θ⋆∥2µ(dθ) .
Proof. The proof is postponed to Appendix S1.3.
Similarly to ULA [13, 17] and SGLD [14, 18], the upper bound given in Theorem 1 involves a con-
tracting term depending on the initialisation and a bias term γB¯γ which does not vanish as k →∞
because of the use of a ﬁxed step-size γ. In the asymptotic scenario, i.e. ¯γ ↓0, Table 1 gives
the dependencies of B¯γ for QLSD and its particular instance QLSD#, with respect to key quantities
associated to the setting we consider. Similarly to SGLD, we can notice that the use of stochastic
gradients brings a bias term of the order σ2
⋆O(γ). On the other hand, compared to SGLD, the use of
the compression operator leads to an additional bias of the order ω(mB⋆+ LMd) O(γ) which notably
involves B⋆corresponding to the impact of local posterior discrepancy on convergence.
Non-asymptotic convergence results for Algorithm 2. We assume here that the potential functions
{Ui}i∈[b] admit, for any i ∈[b], the ﬁnite-sum decomposition Ui = PN
j=1 Ui,j, where N ∈N∗, and
consider the following set of assumptions.
H4. For any i ∈[b], j ∈[N], Ui,j is continuously differentiable and the following holds.
(i) There exists M
>
0 such that, for any θ1, θ2
∈
Rd, ∥∇Ui(θ2) −∇Ui(θ1)∥2
≤
M ⟨θ2 −θ1, ∇Ui(θ2) −∇Ui(θ1)⟩.
(ii) There exists ¯M
≥
0 such that, for any θ1, θ2
∈
Rd, ∥∇Ui,j(θ2) −∇Ui,j(θ1)∥2
≤
¯M ⟨∇Ui,j(θ2) −∇Ui,j(θ1), θ2 −θ1⟩.
As mentioned previously, H4 is satisﬁed if for any i ∈[b] and j ∈[N], Ui,j is convex and ∇Ui,j is ¯M-
Lipschitz continuous. Under these additional conditions, the following non-asymptotic convergence
results hold for the two variance-reduced MCMC algorithms detailed in Algorithm 2. Denote by
Q⃝⋆,γ the Markov kernel associated with QLSD⋆with a step-size γ ∈(0, ¯γ].
Theorem 2. Assume H1, H2 and H4. Then, there exists ¯γ⃝⋆,∞such that for ¯γ < ¯γ⃝⋆,∞, there
exist A⃝⋆,¯γ, B⃝⋆,¯γ > 0 (explicitly given in Appendix S2.1) satisfying for any probability measure
µ ∈P2
 Rd
, any step size γ ∈(0, ¯γ] and k ∈N,
W 2
2
 µQk
⃝⋆,γ, π

≤(1 −γm/2)k · W 2
2 (µ, π) + γ2A⃝⋆,¯γ(1 −mγ/2)k−1k ·
Z
Rd ∥θ −θ⋆∥2µ(dθ)
+ γB⃝⋆,¯γ .
Proof. The proof is postponed to Appendix S2.1.
7

Compared to QLSD and QLSD⋆, QLSD++ only deﬁnes an inhomogeneous Markov chain, see Ap-
pendix S3.3 for more details. For a step-size γ ∈(0, ¯γ] and an iteration k ∈N, we denote by µQ(k)
⊕,γ
the distribution of θk deﬁned by QLSD++ starting from θ0 with distribution µ.
Theorem 3. Assume H1, H2 and H4, and let l ∈N∗and α ∈(0, 1/(ω + 1)]. Then, there exists
¯γ⊕,∞such that for ¯γ < ¯γ⊕,∞, there exist A⊕,¯γ, B⊕,¯γ, C⊕,¯γ > 0 (explicitly given in Appendix S3.3
and independent of α) satisfying for any probability measure µ ∈P2
 Rd
, any step size γ ∈(0, ¯γ]
and k ∈N,
W 2
2 (µQ(k)
⃝
+,γ, π) ≤(1 −γm/2)k · W 2
2 (µ, π) + γ2A⊕,¯γ(1 −γm/2)⌊k/l⌋·
Z
Rd ∥θ −θ⋆∥2µ(dθ)
+ γB⊕,¯γ + γC⊕,¯γ[(1 −α)k ∧(1 −γm/2)⌊k/l⌋]
b
X
i=1
∇Ui(θ⋆) −η(i)
0

2
.
Proof. The proof is postponed to Appendix S3.3.
Table 1 provides the dependencies of the asymptotic bias terms B⃝⋆,¯γ, B⊕,¯γ as ¯γ ↓0 with respect
to key quantities associated to the problem we consider. For comparison, we do the same regard-
ing the speciﬁc instance of Algorithm 1, QLSD#. Remarkably, thanks to biased local stochastic
gradients for QLSD⋆and the memory mechanism for QLSD++, we can notice that their associated
asymptotic biases do not depend on local posterior discrepancy in contrast to QLSD#. This is in line
with non-asymptotic convergence results in risk-based FL which also show that the impact of data
heterogeneity can be alleviated using such a memory mechanism [40]. The impact of stochastic
gradients is discussed in further details in the next paragraph.
Consistency analysis in the big data regime. It has been shown in [9] that ULA and SGLD deﬁne
homogeneous Markov chains, each of which admits a unique stationary distribution. However, while
the invariant distribution of ULA becomes closer to π as N increases, on the opposite, the invariant
measure of SGLD never comes close to π and is in fact very similar to the invariant measure of SGD.
In addition, the non-compressed counterpart of QLSD⋆has been shown not to suffer from this issue
and has been theoretically proven to be a a viable alternative to ULA in the big data setting.
Since QLSD is a generalisation of SGLD, the conclusions of [9] apply. On the other hand, we show that
the variance-reduced alternatives to QLSD that we have introduced provide more accurate estimates
for π as N increases. Based on their explicit expressions (see the Appendices), we analyse in
Table 1 the asymptotic as N →∞of the bias terms {B¯γ, B⃝⋆,¯γ, B⊕,¯γ} where, similarly to [9], we
set γ = η/N with η ∈(0, N ¯η] and assume that lim infN→∞m/N > 0 and lim supN→∞A/N > 0
for A ∈{L, M, σ⋆}. Detailed calculations are postponed to Appendix S4.
4
Numerical experiments
This section illustrates our methodology on three numerical experiments involving both synthetic
and real FL benchmarks. For all experiments, we consider the ﬁnite-sum setting and use the stochas-
tic quantisation operator C (s) for s ≥1 deﬁned in (4) to perform the compression step. In this case,
recall that H2-(ii) is veriﬁed with ω = min(d/s2,
√
d/s).
Toy Gaussian example. This ﬁrst experiment aims at illustrating the general behavior of Algo-
rithm 1 and Algorithm 2 with respect to the discretisation time-step γ and the compression param-
eter ω. To this purpose, we set b = 20 and d = 50 and consider a Gaussian posterior distribution
with density deﬁned in (1) where, for any i ∈[b] and θ ∈Rd, Ui(θ) = PN
j=1 ∥θ −yi,j∥2/2,
{yi,j}i∈[b],j∈[N] being a set of synthetic independent but not identically distributed observations
across clients and N = 200.
Note that in this speciﬁc case, θ⋆has a closed form given by
θ⋆= Pb
i=1
PN
j=1 yi,j/(bN). For all the algorithms, we set the step-size to γ = 4.9 × 10−4
and choose a minibatch size n = ⌊N/10⌋. First, we compare QLSD# and QLSD⋆using s ∈{24, 216}
referred to as 4-bits and 16-bits instances of these MCMC algorithms, respectively. Then, we com-
pare QLSD⋆and its non-compressed counterpart referred to as LSD⋆for s ∈{24, 28, 216}. Figure 1
shows the behavior of the mean squarred error (MSE) associated to the test function f : θ 7→∥θ∥,
computed using 30 independent runs of each algorithm, with respect to both the number of com-
munication rounds and number of bits transmitted. We can notice that QLSD⋆always outperforms
8

0
10000
20000
30000
40000
50000
Nb. of communication rounds
10−5
10−4
10−3
10−2
MSE for test function f : θ 7→∥θ∥
QLSD⋆4 bits
QLSD⋆16 bits
QLSD# 4 bits
QLSD# 16 bits
0
10000
20000
30000
40000
50000
Nb. of communication rounds
10−5
10−4
10−3
MSE for test function f : θ 7→∥θ∥
QLSD⋆4 bits
QLSD⋆8 bits
QLSD⋆16 bits
LSD⋆
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
1.6
Nb. of communicated bits during upload
×109
10−5
10−4
10−3
10−2
MSE for test function f : θ 7→∥θ∥
QLSD⋆4 bits
QLSD⋆8 bits
QLSD⋆16 bits
LSD⋆
QLSD# 4 bits
QLSD# 16 bits
10−5
10−3
10−1
101
Compression parameter ω
10−2
10−1
100
MSE for test function f : θ 7→∥θ∥
slope = 1.09 ± 0.07
10−5
10−4
10−3
γ
0
20000
40000
60000
80000
100000
Nb. of communication rounds
0.00012
0.00013
0.00014
0.00015
0.00016
0.00017
0.00018
0.00019
0.00020
0.00021
Error in variance estimation
QLSD+ +  1 bit with memory
QLSD+ +  1 bit
0
20000
40000
60000
80000
100000
Nb. of communication rounds
0.00012
0.00013
0.00014
0.00015
0.00016
0.00017
0.00018
0.00019
0.00020
0.00021
Error in variance estimation
QLSD+ +  2 bits with memory
QLSD+ +  2 bits
Figure 1: Toy Gaussian example (top row and very right ﬁgure on bottom row) and Bayesian logistic
regression on synthetic data (the two ﬁgures on the bottom row starting from the right).
QLSD#and that decreasing the value of ω does not signiﬁcantly reduce the bias associated to QLSD⋆.
This illustrates the impact of the variance of the stochastic gradients and supports our theoretical
analysis summarised in Table 1. On the other hand, QLSD⋆with s = 216 achieves a similar MSE as
LSD⋆while requiring roughly 2.5 times less number of bits. As shown on the very right ﬁgure (bot-
tom row), this saving in number of transmitted bits can be further improved by decreasing the value
of γ. This numerical ﬁnding illustrates our theory which in particular shows that the asymptotic bias
associated to QLSD⋆is of the order ω O(γ), see Table 1.
Table 2: Logistic regression on real data.
QLSD++
99% HPD error
Rel. efﬁciency
4 bits
6.1e-3
7.6
8 bits
4.3e-3
6.7
16 bits
6.9e-4
3.1
Bayesian logistic regression. Since θ⋆is not
easily available, we implement Algorithm 2 us-
ing QLSD++.
For all experiments, we adopt
a zero-mean Gaussian prior with covariance
matrix 2 · 10−2Id.
Synthetic data.
For the
ﬁrst sub-experiment, we consider the SYN-
THETIC(α, β) dataset [33] with α = β = 1,
d = 2 and b = 50. To this end, we run this al-
gorithm with and without memory terms using
l = 100, α = 1/(ω + 1), γ = 10−5 and for
huge compression parameters, namely s ∈{21, 22}. In order to have access to some ground truth,
we also implement the Metropolis-adjusted Langevin algorithm (MALA) [46]. Figure 1 shows the Eu-
clidean norm of the error between the true variance under π estimated with MALA and the empirical
variance computed using samples generated by QLSD++. As expected, we can notice that the mem-
ory mechanism reduces the impact of the compression on the asymptotic bias of QLSD++ when ω is
large. Real data. For this second sub-experiment, we use the FEMNIST dataset [10]. We launch
QLSD++ for s ∈{24, 28, 216} and using the same hyperparameter values as before. Under the
Bayesian paradigm, we are interested in performing uncertainty quantiﬁcation by estimating highest
posterior density (HPD) regions. For any α ∈(0, 1), we deﬁne Cα = {θ ∈Rd; −log π(θ|D) ≤ηα}
where ηα ∈R is chosen such that
R
Cα π(θ|D)dθ = 1 −α. We compute the relative HPD error
based on the scalar summary ηα, i.e. |ηα −ηLSD
α |/ηLSD
α
where ηLSD
α
has been estimated using the
non-compressed counterpart of QLSD++, referred to as LSD++. Table 2 gives this relative HPD error
for α = 0.01 and provides the relative efﬁciency of QLSD++ corresponding to the savings in terms
of transmitted bits per iteration. One can notice that the proposed approach provides similar results
as its non-compressed counterpart while being 3 to 7 times more efﬁcient. Figure 2 completes this
empirical study by showing that the predictive distributions of the most probable label given by
QLSD++ and LSD++ almost coincide for eight test examples.
Bayesian neural networks. In our third experiment, we consider a classiﬁcation problem on the
MNIST dataset [12] involving 10 classes and bN = 60, 000 observations {xi, yi}i∈[bN], and
such that for any i ∈[bN], k ∈[10], P(yi = k | θ, xi) = βk where βk is the k-th element
of σ1(W2 · σ2(W1xi + a1) + a2) where σ1(·) is the softmax function, σ2(·) the sigmoid func-
9

0.0
0.2
0.4
0.6
0.8
1.0
Credibility threshold 
0.92
0.94
0.96
0.98
1.00
Test accuracy on D( )
pred
QLSD# 2 bits
QLSD# 1 bits
LSD#
0.0
0.2
0.4
0.6
0.8
1.0
Predictive entropy on MNIST
0.0
0.5
1.0
1.5
2.0
Density
QLSD# 1 bits
QLSD# 2 bits
LSD#
0
2
4
6
8
10
12
Predictive entropy on Fashion-MNIST
0.00
0.02
0.04
0.06
0.08
0.10
0.12
0.14
0.16
Density
QLSD# 2 bits
QLSD# 1 bits
LSD#
Figure 2: Bayesian logistic regression and neural networks on real data.
tion, xi are covariates and a1, a2, W1, W2 are matrices of size 128 × 1, 10 × 10, 128 × 784 and
10 × 128, respectively. We adopt a zero-mean Gaussian prior for θ = (a1, a2, W1, W2) with
covariance matrix 5 · 10−2Id, set b = 100, γ = 10−4 and n = ⌊N/7.5⌋, and launch QLSD#
for s ∈{21, 22}.
For comparison, we also run LSD# using the same hyperparameters.
De-
note by Dx
test the set of covariates x belonging to Dtest.
We conduct two sub-experiments for
which we use the posterior mean estimate of θ to predict the label ypred(x) associated to each
example x ∈Dx
test.
For our ﬁrst sub-experiment, we consider, for any τ
∈[0, 1], the set
D(τ)
pred = {x ∈Dx
test :
R
Rd p(ypred(x)|x, θ)π(θ | D)dθ ≥τ} of classiﬁed data with credibility greater
than τ. Figure 2 shows the evolution of the test accuracy on D(τ)
pred with respect to the credibility
threshold τ that is given by Card({x ∈D(τ)
pred : ytrue(x) = ypred(x)})/Card(D(τ)
pred). In our sec-
ond sub-experiment, we study the behavior of our proposed algorithms in the out-of-distribution
framework.
To this purpose, in Figure 2 we display a kernel density estimate of the condi-
tional predicitve density associated with {log(
R
θ p(ypred(x) | x, θ)π(θ | D)dθ) : x ∈Dx
test} for
Dtest ∈{MNIST, FASHION-MNIST}. For both sub-experiments, we can notice that QLSD# pro-
vides similar results as its non-compressed counterpart while requiring far less transmitted bits.
5
Conclusion
In this paper, a general methodology based on stochastic Langevin dynamics has been introduced for
Bayesian FL. In particular, we addressed the communication bottleneck by assuming that each client
sent compressed versions of their local stochastic gradient oracles to the central server. In addition,
it has been established that the proposed methodology inherits favorable convergence properties
which have been supported by numerical illustrations. One limitation of this work is that the pro-
posed methodology does not target the initial posterior distribution because of the use of a ﬁxed
discretisation time-step. As such, this work paves the path for more advanced Bayesian FL ap-
proaches, e.g. based on Metropolis-Hastings schemes to remove asymptotic bias or accounting for
partial device participation.
Acknowledgments
The authors acknowledge support of the Lagrange Mathematics and Computing Research Center.
References
[1] White House Report. Consumer data privacy in a networked world: A framework for protect-
ing privacy and promoting innovation in the global digital economy. Journal of Privacy and
Conﬁdentiality, 2013.
[2] Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu
Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, Manjunath Kudlur, Josh Levenberg,
Rajat Monga, Sherry Moore, Derek G. Murray, Benoit Steiner, Paul Tucker, Vijay Vasudevan,
Pete Warden, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. Tensorﬂow: A system for large-
scale machine learning. In Proceedings of the 12th USENIX Conference on Operating Systems
Design and Implementation, OSDI’16, page 265–283, USA, 2016. USENIX Association.
10

[3] Sungjin Ahn, Babak Shahbaba, and Max Welling. Distributed Stochastic Gradient MCMC.
In Eric P. Xing and Tony Jebara, editors, Proceedings of the 31st International Conference on
Machine Learning, volume 32 of Proceedings of Machine Learning Research, pages 1044–
1052, 2014.
[4] Alham Fikri Aji and Kenneth Heaﬁeld. Sparse Communication for Distributed Gradient De-
scent. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language
Processing, pages 440–445, September 2017.
[5] Dan Alistarh, Demjan Grubic, Jerry Li, Ryota Tomioka, and Milan Vojnovic.
QSGD:
Communication-Efﬁcient SGD via Gradient Quantization and Encoding. In I. Guyon, U. V.
Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Ad-
vances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017.
[6] Christophe Andrieu, Nando de Freitas, Arnaud Doucet, and Michael I. Jordan. An introduction
to MCMC for machine learning. Machine Learning, 50(1–2):5–43, 2003. doi: 10.1023/A:
1020281327116.
[7] Jack Baker, Paul Fearnhead, Emily B. Fox, and Christopher Nemeth. Control variates for
stochastic gradient MCMC. Statistics and Computing, 29(3):599–615, 2019. doi: 10.1007/
s11222-018-9826-2.
[8] Dominique Bakry, Ivan Gentil, and Michel Ledoux. Analysis and Geometry of Markov Diffu-
sion operators. Grundlehren der mathematischen Wissenschaften, Vol. 348. Springer, 2014.
[9] Nicolas Brosse, Alain Durmus, and Eric Moulines. The promises and pitfalls of stochastic
gradient langevin dynamics. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-
Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems, vol-
ume 31. Curran Associates, Inc., 2018. URL https://proceedings.neurips.cc/paper/
2018/file/335cd1b90bfa4ee70b39d08a4ae0cf2d-Paper.pdf.
[10] Sebastian Caldas, Sai Meher Karthik Duddu, Peter Wu, Tian Li, Jakub Konecny, H. Brendan
McMahan, Virginia Smith, and Ameet Talwalkar. LEAF: A Benchmark for Federated Settings.
arXiv preprint arXiv:1812.01097, 2018.
[11] Arkabandhu Chowdhury and Christopher Jermaine. Parallel and Distributed MCMC via Shep-
herding Distributions. In Proceedings of the Twenty-First International Conference on Artiﬁ-
cial Intelligence and Statistics, volume 84, pages 1819–1827, 2018.
[12] Gregory Cohen, Saeed Afshar, Jonathan Tapson, and André van Schaik. Emnist: Extend-
ing mnist to handwritten letters. In 2017 International Joint Conference on Neural Networks
(IJCNN), pages 2921–2926, 2017. doi: 10.1109/IJCNN.2017.7966217.
[13] Arnak S. Dalalyan. Theoretical guarantees for approximate sampling from smooth and log-
concave densities. Journal of the Royal Statistical Society, Series B, 79(3):651–676, 2017. doi:
10.1111/rssb.12183.
[14] Arnak S. Dalalyan and Avetik Karagulyan. User-friendly guarantees for the langevin monte
carlo with inaccurate gradient. Stochastic Processes and Their Applications, 129(12):5278–
5311, 2019. doi: 10.1016/j.spa.2019.02.016.
[15] Jeffrey Dean, Greg Corrado, Rajat Monga, Kai Chen, Matthieu Devin, Mark Mao, Marc Au-
relio Ranzato, Andrew Senior, Paul Tucker, Ke Yang, Quoc Le, and Andrew Ng. Large Scale
Distributed Deep Networks. In F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger,
editors, Advances in Neural Information Processing Systems, volume 25. Curran Associates,
Inc., 2012.
[16] Aymeric Dieuleveut, Alain Durmus, and Francis Bach. Bridging the gap between constant step
size stochastic gradient descent and Markov chains. Annals of Statistics, 48(3):1348–1382, 06
2020. doi: 10.1214/19-AOS1850.
[17] Alain Durmus and Eric Moulines. High-dimensional Bayesian inference via the unadjusted
Langevin algorithm. Bernoulli, 25(4A):2854–2882, 2019. doi: 10.3150/18-BEJ1073.
11

[18] Alain Durmus, Szymon Majewski, and Bla˙zej Miasojedow. Analysis of Langevin Monte Carlo
via convex optimization. Journal of Machine Learning Research, 20(73):1–46, 2019. Available
at http://www.jmlr.org/papers/volume20/18-173/18-173.pdf.
[19] Khaoula El Mekkaoui, Diego Mesquita, Paul Blomstedt, and Samuel Kaski.
Distributed
stochastic gradient MCMC for federated learning. arXiv preprint arXiv:2004.11231, 2020.
[20] Gianni Franchi, Andrei Bursuc, Emanuel Aldea, Severine Dubuisson, and Isabelle Bloch. En-
coding the latent posterior of Bayesian Neural Networks for uncertainty quantiﬁcation. arXiv
preprint arXiv:2012.02818, 2020.
[21] Daniel Garcia-Gonzalez, Daniel Rivero, Enrique Fernandez-Blanco, and Miguel R. Luaces. A
Public Domain Dataset for Real-Life Human Activity Recognition Using Smartphone Sensors.
Sensors, 20(8), 2020.
[22] Antonious M Girgis, Deepesh Data, Suhas Diggavi, Peter Kairouz, and Ananda Theertha
Suresh. Shufﬂed model of federated learning: Privacy, communication and accuracy trade-
offs. arXiv preprint arXiv:2008.07180, 2020.
[23] Ulf Grenander and Michael I. Miller.
Representations of knowledge in complex systems.
Journal of the Royal Statistical Society. Series B (Methodological), 56(4):549–603, 1994. ISSN
00359246.
[24] Farzin Haddadpour, Mohammad Mahdi Kamani, Aryan Mokhtari, and Mehrdad Mahdavi.
Federated Learning with Compression: Uniﬁed Analysis and Sharp Guarantees. arXiv preprint
arXiv:2007.01154, 2020.
[25] Samuel Horváth, Dmitry Kovalev, Konstantin Mishchenko, Sebastian Stich, and Peter
Richtárik. Stochastic Distributed Learning with Gradient Quantization and Variance Reduction
. arXiv preprint arXiv:1904.05115, 2019.
[26] Li Huang, Yifeng Yin, Zeng Fu, Shifa Zhang, Hao Deng, and Dianbo Liu. LoAdaBoost:
Loss-based AdaBoost federated machine learning with reduced computational complexity
on IID and non-IID intensive care data. PLOS ONE, 15(4):1–16, 04 2020. doi: 10.1371/
journal.pone.0230706.
[27] David J. Hunter. Uncertainty in the Era of Precision Medicine. New England Journal of
Medicine, 375(8):711–713, 2016.
[28] Rie Johnson and Tong Zhang.
Accelerating Stochastic Gradient Descent Using Predictive
Variance Reduction. In Neural Information Processing Systems, page 315–323, 2013.
[29] Michael I. Jordan, Jason D. Lee, and Yun Yang. Communication-Efﬁcient Distributed Statisti-
cal Inference. Journal of the American Statistical Association, 114(526):668–681, 2019. doi:
10.1080/01621459.2018.1429274.
[30] Peter Kairouz, H. Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis, Ar-
jun Nitin Bhagoji, K. A. Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings,
Rafael G.L. D’Oliveira, Salim El Rouayheb, David Evans, Josh Gardner, Zachary Garrett,
Adrià Gascón, Badih Ghazi, Phillip B. Gibbons, Marco Gruteser, Zaid Harchaoui, Chaoyang
He, Lie He, Zhouyuan Huo, Ben Hutchinson, Justin Hsu, Martin Jaggi, Tara Javidi, Gauri
Joshi, Mikhail Khodak, Jakub Konevcný, Aleksandra Korolova, Farinaz Koushanfar, Sanmi
Koyejo, Tancrède Lepoint, Yang Liu, Prateek Mittal, Mehryar Mohri, Richard Nock, Ayfer
Özgür, Rasmus Pagh, Mariana Raykova, Hang Qi, Daniel Ramage, Ramesh Raskar, Dawn
Song, Weikang Song, Sebastian U. Stich, Ziteng Sun, Ananda Theertha Suresh, Florian
Tramèr, Praneeth Vepakomma, Jianyu Wang, Li Xiong, Zheng Xu, Qiang Yang, Felix X. Yu,
Han Yu, and Sen Zhao. Advances and Open Problems in Federated Learning. arXiv preprint
arXiv:1912.04977, 2019.
[31] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and
Ananda Theertha Suresh. SCAFFOLD: Stochastic controlled averaging for federated learning.
In Hal Daumé III and Aarti Singh, editors, Proceedings of the 37th International Conference on
Machine Learning, volume 119 of Proceedings of Machine Learning Research, pages 5132–
5143. PMLR, 13–18 Jul 2020.
12

[32] Rahif Kassab and Osvaldo Simeone. Federated Generalized Bayesian Learning via Distributed
Stein Variational Gradient Descent. arXiv preprint arXiv:2009.06419, 2020.
[33] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia
Smith. Federated Optimization in Heterogeneous Networks. In I. Dhillon, D. Papailiopoulos,
and V. Sze, editors, Proceedings of Machine Learning and Systems, volume 2, pages 429–450,
2020.
[34] Yujun Lin, Song Han, Huizi Mao, Yu Wang, and Bill Dally. Deep Gradient Compression: Re-
ducing the Communication Bandwidth for Distributed Training. In International Conference
on Learning Representations, 2018.
[35] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Ar-
cas. Communication-Efﬁcient Learning of Deep Networks from Decentralized Data. In Aarti
Singh and Jerry Zhu, editors, Proceedings of the 20th International Conference on Artiﬁcial
Intelligence and Statistics, volume 54 of Proceedings of Machine Learning Research, pages
1273–1282, Fort Lauderdale, FL, USA, 20–22 Apr 2017. PMLR.
[36] Yurii Nesterov. Introductory lectures on convex optimization: A basic course, volume 87.
Springer Science & Business Media, 2003.
[37] Alexandros Pantelopoulos and Nikolaos G. Bourbakis. A Survey on Wearable Sensor-Based
Systems for Health Monitoring and Prognosis.
IEEE Transactions on Systems, Man, and
Cybernetics, 40(1):1–12, 2010.
[38] G. Parisi. Correlation functions and computer simulations. Nuclear Physics B, 180(3):378–
384, 1981. ISSN 0550-3213. doi: https://doi.org/10.1016/0550-3213(81)90056-0.
[39] Mariane Pelletier. On the almost sure asymptotic behaviour of stochastic algorithms. Stochastic
Processes and their Applications, 78(2):217–244, 1998. ISSN 0304-4149. doi: https://doi.org/
10.1016/S0304-4149(98)00029-5.
[40] Constantin Philippenko and Aymeric Dieuleveut. Bidirectional compression in heterogeneous
settings for distributed or federated learning with partial participation: tight convergence guar-
antees . arXiv preprint arXiv:2006.14591, 2020.
[41] Parisa Rashidi and Diane J. Cook. Keeping the Resident in the Loop: Adapting the Smart
Home to the User. IEEE Transactions on Systems, Man, and Cybernetics, 39(5):949–959,
2009.
[42] L. J. Rendell, A. M. Johansen, A. Lee, and N. Whiteley. Global consensus Monte Carlo.
Journal of Computational and Graphical Statistics, 2020.
[43] Daniel Revuz and Marc Yor. Continuous martingales and Brownian motion, volume 293.
Springer Science & Business Media, 2013.
[44] Herbert Robbins and Sutton Monro. A stochastic approximation method. Annals of Mathe-
matical Statistics, 22(3):400–407, 09 1951. doi: 10.1214/aoms/1177729586.
[45] C. P. Robert. The Bayesian Choice: from decision-theoretic foundations to computational
implementation. Springer, New York, 2 edition, 2001.
[46] C. P. Robert and G. Casella. Monte Carlo Statistical Methods. Springer, Berlin, 2 edition,
2004.
[47] Gareth O. Roberts and Richard L. Tweedie. Exponential convergence of Langevin distributions
and their discrete approximations. Bernoulli, 2(4):341–363, 12 1996.
[48] Felix Sattler, Simon Wiedemann, Klaus-Robert Müller, and Wojciech Samek. Robust and
Communication-Efﬁcient Federated Learning From Non-i.i.d. Data. IEEE Transactions on
Neural Networks and Learning Systems, 31(9):3400–3413, 2020.
13

[49] Steven L. Scott, Alexander W. Blocker, Fernando V. Bonassi, Hugh A. Chipman, Edward I.
George, and Robert E. McCulloch. Bayes and Big Data: The Consensus Monte Carlo Al-
gorithm. International Journal of Management Science and Engineering Management, 11:
78–88, 2016.
[50] Frank Seide, Hao Fu, Jasha Droppo, Gang Li, and Dong Yu. 1-Bit Stochastic Gradient Descent
and Application to Data-Parallel Distributed Training of Speech DNNs. In Interspeech 2014,
September 2014.
[51] Sebastian U Stich, Jean-Baptiste Cordonnier, and Martin Jaggi. Sparsiﬁed SGD with Memory.
In Advances in Neural Information Processing Systems, volume 31, 2018.
[52] Cédric Villani. Optimal Transport: Old and New. Springer Berlin Heidelberg, 2008.
[53] Maxime Vono, Daniel Paulin, and Arnaud Doucet. Efﬁcient MCMC sampling with dimension-
free convergence rate using ADMM-type splitting. arXiv preprint arXiv:1905.11937, 2019.
[54] Xiangyu Wang and David B. Dunson. Parallelizing MCMC via Weierstrass sampler. arXiv
preprint arXiv:1312.4605, 2013.
[55] Xiangyu Wang, Fangjian Guo, Katherine A. Heller, and David B. Dunson.
Parallelizing
MCMC with random partition trees. In Advances in Neural Information Processing Systems,
2015.
[56] Max Welling and Yee Whye Teh. Bayesian learning via stochastic gradient langevin dynamics.
In International Conference on International Conference on Machine Learning, page 681–688,
2011.
14

S1
Proof of Theorem 1
This section aims at proving Theorem 1.
S1.1
Generalised quantised Langevin stochastic dynamics
We show that QLSD deﬁned in Algorithm 1 can be cast into a more general framework that we refer
to as generalised quantised Langevin stochastic dynamics. Then, the guarantees for QLSD will be
a simple consequence of the ones that we will establish for generalised QLSD. For ease of reading,
we recall ﬁrst the setting and the assumptions that we consider all along the paper. Recall that
the dataset D is assumed to be partitioned into b shards {Di}b
i=1 such that ⊔b
i=1Di = D and the
posterior distribution of interest is assumed to admit a density with respect to the d-dimensional
Lebesgue measure which factorises across clients, i.e. for any θ ∈Rd,
π(θ) = exp {−U(θ)} /
Z
Rd e−U(θ) dθ ,
U(θ) =
b
X
i=1
Ui(θ) .
For k ≥1, consider (X(1,1)
k
, . . . , X(1,b)
k
)k∈N and (X(2,1)
k
, . . . , X(2,b)
k
)k∈N two independent se-
quences of i.i.d. random variables distributed according to ν⊗b
1
and ν⊗b
2 , respectively. Given a
step-size γ ∈(0, ¯γ] for some ¯γ > 0 and starting from θ0 ∈Rd, QLSD recursively deﬁnes (θk)k∈N,
for any k ∈N, as
θk+1 = θk −γ Pb
i=1 C (Hi(θk, X(1,i)
k+1 ), X(2,i)
k+1 ) + √2γZk+1 ,
(S1)
where (Zk+1)k∈N is a sequence of standard Gaussian random variables. Note that (S1) can be
written of the form
θk+1 = θk −γ
b
X
i=1
˜Hi(θk, X(i)
k+1) +
p
2γZk+1 ,
k ∈N ,
(S2)
where for any i ∈[b], we denote X(i)
k+1 = (X(1,i)
k+1 , X(2,i)
k+1 ) and for any θ ∈Rd, x(1) ∈X1, x(2) ∈X2,
˜Hi
 θ, (x(1), x(2))

= C

Hi(θ, x(1)), x(2)
.
(S3)
With this notation and setting ˜X = X1 × X2, ˜
X = X1 ⊗X2 and ˜ν = ν1 ⊗ν2, the Markov kernel
associated with (S1) is given for any (θ, A) ∈Rd × B(Rd) by
Qγ(θ, A) =
Z
A×˜Xb exp

−∥˜θ −θ + γ Pb
i=1 ˜Hi(θ, x(i))∥2/(4γ)
 d˜θ ˜ν⊗b(dx(1:b))
(4πγ)d/2
.
(S4)
The following result establishes an essential property of { ˜Hi}i∈[b] under H2 and H3.
Lemma S4. Assume H2 and H3. Then, for any θ ∈Rd, we have
Pb
i=1
R
˜X ˜Hi(θ, x) d˜ν⊗b(x) = ∇U(θ) ,
(S5)
Z
˜Xb
Pb
i=1 ˜Hi(θ, x(i)) −∇U(θ)

2
˜ν⊗b(dx(1:b)) ≤2(ω + 1)M ⟨θ −θ⋆, ∇U(θ)⟩+ 2(ωB⋆+ σ2
⋆) ,
(S6)
where for any i ∈[b], ˜Hi is deﬁned in (S3).
Proof. The ﬁrst identity (S5) is straightforward using H3-(i) and H2-(i). We now show the inequal-
ity (S6). Let θ ∈Rd. Using H2-(i) or H3-(i), we get
Z
˜Xb

b
X
i=1
˜Hi(θ, x(i)) −∇U(θ)

2
˜ν⊗b(dx(1:b))
15

=
Z
˜Xb

b
X
i=1
h
˜Hi(θ, x(i)) −Hi(θ, x(1,i))
i
2
˜ν⊗b(dx(1:b))
+
Z
Xb
1

b
X
i=1
Hi(θ, x(1,i)) −∇U(θ)

2
ν⊗b
1 (dx(1,1:b)) .
(S7)
In addition, by H2-(i) and H2-(ii), we obtain
Z
˜Xb

b
X
i=1
h
˜Hi(θ, x(i)) −Hi(θ, x(1,i))
i
2
˜ν⊗b(dx(1:b))
=
b
X
i=1
Z
˜X
 ˜Hi(θ, x(i)) −Hi(θ, x(1,i))

2
ν1(dx(1,i))ν2(dx(2))
≤ω
b
X
i=1
Z
X1
Hi(θ, x(1))

2
ν1(dx(1)) .
(S8)
Using ∥a∥2 ≤2∥a −b∥2 + 2∥b∥2 and H3-(ii)-(iii), for any i ∈[b], we obtain
Z
X1
Hi(θ, x(1))

2
ν1(dx(1)) ≤2M ⟨θ −θ⋆, ∇Ui(θ) −∇Ui(θ⋆)⟩
(S9)
+ 2
Z
X1
Hi(θ⋆, x(1))

2
ν1(dx(1))
≤2M ⟨θ −θ⋆, ∇Ui(θ) −∇Ui(θ⋆)⟩+ 2B⋆/b .
Therefore, combining this result and (S8) gives
Z
˜Xb

b
X
i=1
h
˜Hi(θ, x(i)) −Hi(θ, x(1,i))
i
2
˜ν⊗b(dx(1:b)) ≤2ωM ⟨θ −θ⋆, ∇U(θ) −∇U(θ⋆)⟩+2ωB⋆.
(S10)
Similarly, since for any a, b ∈Rd, ∥a + b∥2 ≤2 ∥a∥2 + 2 ∥b∥2, we have by H3-(i)
Z
Xb
1

b
X
i=1
Hi(θ, x(1,i)) −∇U(θ)

2
ν⊗b
1 (dx(1,1) · · · dx(1,b))
=
Z
Xb
1

b
X
i=1

Hi(θ, x(1,i)) −
Z
X1
Hi(θ, x(1))ν1(dx(1))

2
ν⊗b
1 (dx(1,1) · · · dx(1,b))
=
b
X
i=1
Z
X1
Hi(θ, x(1)) −
Z
X1
Hi(θ, x(1))ν1(dx(1))

2
ν1(dx(1))
≤2
b
X
i=1
Z
X1
Hi(θ, x(1)) −Hi(θ⋆, x(1)) −
Z
X1
Hi(θ, x(1)) −Hi(θ⋆, x(1))ν1(dx(1))

2
ν1(dx(1))
+ 2
b
X
i=1
Z
X1
Hi(θ⋆, x(1)) −
Z
X1
Hi(θ⋆, x(1))ν1(dx(1))

2
ν1(dx(1))
≤2M ⟨∇U(θ), θ −θ⋆⟩+ 2σ2
⋆.
Finally, the last inequality combined with (S7) and (S10) completes the proof.
In view of Lemma S4, it sufﬁces to study the recursion speciﬁed in (S2) under the following as-
sumption on ( ˜Hi)i∈[b] gathered in H5. Indeed, Lemma S4 shows that Condition H5 below holds
with X = ˜X = X1 × X2, X = ˜
X = X1 ⊗X2, ˜ν = ν1 ⊗ν2, { ˜Hi}b
i=1 = {Fi}b
i=1, ˜M = 2(ω + 1)M
and ˜B⋆= 2(ωB⋆+ σ2
⋆)
16

H5. There exists a probability measure ν on a measurable space (˜X, ˜
X) and a family of measurable
functions {Fi : Rd × X →Rd}i∈[b] such that the following conditions hold.
(i) For any θ ∈Rd, we have
b
X
i=1
Z
˜X
Fi(θ, x(i))ν(dx(i)) = ∇U(θ) .
(ii) There exists (˜M, ˜B⋆) ∈R2
+ such that for any θ ∈Rd, we have
Z
˜Xb

b
X
i=1
Fi(θ, x(i)) −∇U(θ)

2
ν⊗b(dx(1:b)) ≤˜M ⟨θ −θ⋆, ∇U(θ) −∇U(θ⋆)⟩+ ˜B⋆.
Then under H5, consider (X(1)
k , . . . , X(b)
k )k∈N∗an i.i.d. sequence distributed according to ν⊗b.
Deﬁne the general recursion
˜θk+1 = ˜θk −γ
b
X
i=1
Fi(˜θk, X(i)
k+1) +
p
2γZk+1 ,
k ∈N .
(S11)
and the corresponding the Markov kernel given for any γ ∈R∗
+, θ ∈Rd, A ∈B(Rd) by
˜Qγ(θ, A) = (4πγ)−d/2
Z
A×˜Xb exp(−(4γ)−1∥¯θ −θ + γ Pb
i=1 Fi(θ, x(i))∥2) d¯θ dν⊗b(x(1:b)) .
(S12)
We refer to this Markov kernel as the generalised QLSD kernel. In our next section, we establish
quantitative bounds between the iterates of this kernel and π in W2. We then apply this result to
QLSD and QLSD⋆as particular cases.
S1.2
Quantitative bounds for the generalised QLSD kernel
Deﬁne
¯γ = ¯γ1 ∧¯γ2 ∧¯γ3 ,
¯γ1 = 2/[5(m + L)] ,
¯γ2 = (m + L + ˜M)−1 ,
¯γ3 = (10m)−1 .
(S13)
Theorem S5. Assume H1 and H5. Then, for any probability measure µ ∈P2(Rd), any step size
γ ∈(0, ¯γ], any k ∈N, we have
W 2
2 (µ ˜Qk
γ, π) ≤(1 −γm/2)kW 2
2 (µ, π) + γ ˜B¯γ + γ2 ˜A¯γ(1 −mγ/2)k−1k
Z
Rd ∥θ −θ⋆∥2µ(dθ) ,
where ˜Qγ is deﬁned in (S12) and
˜B¯γ = (2d/m)(m−1 + 5¯γ)

1 + ¯γL2/(2m) + ¯γ2L2/12

+ 2˜B⋆/m + L˜M(2d + ¯γ˜B⋆)/m2
˜A¯γ = L˜M .
Let ξ ∈P2(R2d) be a probability measure on (R2d, B(R2d)) with marginals ξ1 and ξ2, i.e. ξ(A ×
Rd) = ξ1(A) and ξ(A × Rd) = ξ2(A) for any A ∈B(Rd). Note that under H1, the Langevin
diffusion deﬁnes a Markov semigroup (Pt)t≥0 satisfying πPt = π for any t ≥0, see e.g. [47,
Theorem 2.1]. We introduce a synchronous coupling (ϑkγ, θk) between ξ1Pkγ and ξ2 ˜Qk
γ for any k ∈
N based on a d-dimensional standard Brownian motion (Bt)t≥0 and a couple of random variables
(θ0, ϑ0) with distribution ξ independent of (Bt)t≥0. Consider (ϑt)t≥0 the strong solution of the
Langevin stochastic differential equation (SDE)
dϑt = −∇U(ϑt)dt +
√
2 dBt ,
(S14)
starting from ϑ0. Note that under H1-(i), this SDE admits a unique strong solution [43, Theorem
(2.1) in Chapter IX]. In addition, deﬁne (θk)k∈N starting from θ0 and satisfying the recursion: for
k ≥0,
θk+1 = θk −γ
b
X
i=1
Fi(θk, x(i)
k+1) +
√
2(Bγ(k+1) −Bγk) ,
(S15)
17

where (x(1)
j , . . . , x(b)
j )j∈N∗is an i.i.d. sequence of random variable with distribution ν⊗b. Then, by
deﬁnition, (ϑkγ, θk) is a coupling between ξ1Pkγ and ξ2 ˜Qk
γ for any k ∈N and therefore
W2(ξ1Pkγ, ξ2 ˜Qk
γ) ≤E

∥ϑγk −θk∥21/2 .
(S16)
We can now give the proof of Theorem S5.
Proof. By [52, Theorem 4.1], for any couple of probability measures on Rd, there exists an optimal
transference plan ξ⋆between ν and π since π ∈P2(Rd) by the strong convexity assumption H1-(i).
Let (ϑ0, θ0) be a corresponding coupling which therefore satisﬁes W2(µ, π) = E1/2[∥ϑ0 −θ0∥2].
Consider then (ϑk)k∈N, (θk)k∈N deﬁned in (S14)-(S15) starting from (ϑ0, θ0). Note that since
πPt = π by [47, Theorem 2.1] for any t ≥0 and θ0 has distribution π, we get by [17, Propo-
sition 1] that for any k ∈N, E[∥ϑkγ −θ⋆∥2] ≤d/m and then Lemma S7 below shows that for any
k ∈N,
E[
ϑ(k+1)γ −θk+1
2] ≤κγE[∥ϑkγ −θk∥2] + γ2L˜M E

∥θ0 −θ⋆∥2
˜κk
γ + γ2Dγ ,
where we have set
κγ = 1 −γm(1 −5γm) ,
˜κγ = 1 −γm

2 −γ(m + ˜M)

.
A straightforward induction shows that
E[∥ϑkγ −θk∥2] ≤κk
γW 2
2 (µ, π) + γ2L˜M E

∥θ0 −θ⋆∥2 k−1
X
l=0
κl
γ˜κk−1−l
γ
+ γ2Dγ/(1 −κγ) .
Using κγ ∧˜κγ ≤1 −mγ/2 since γ ≤¯γ, (S16) and πPt = π for any t ≥0 completes the proof.
S1.2.1
Supporting Lemmata
In this subsection, we derived two lemmas.
Taking (θk)k∈N deﬁned by the recursion (S15),
Lemma S6 aims to upper bound the squared deviation between θk and the minimiser of U denoted
θ⋆, for any k ∈N.
Lemma S6. Assume H1 and H5. Let γ ∈
 0, 2/(m + L + ˜M)

. Then, for any k ∈N, θ0 ∈Rd, we
have
Z
Rd ∥θ −θ⋆∥2 ˜Qk
γ(θ0, dθ) ≤(1 −γm

2 −γ(m + ˜M)

)k∥θ0 −θ⋆∥2 +
2d + γ˜B⋆
m

2 −γ(m + ˜M)
 ,
where ˜Qγ is deﬁned in (S12).
Proof. For any θ0 ∈Rd, by deﬁnition (S12) of ˜Qγ and using H5-(i), we obtain
Z
Rd ∥θ −θ⋆∥2 ˜Qγ(θ0, dθ) = ∥θ0 −θ⋆∥2 −2γ ⟨θ0 −θ⋆, ∇U(θ0)⟩
+ γ2
Z
˜Xb
Pb
i=1 Fi(θ0, x(i))

2
ν⊗b(dx(1:b)) + 2γd .
(S17)
Moreover, using H1, H5 and (6), it follows that
Z
˜Xb
Pb
i=1 Fi(θ0, x(i))

2
ν⊗b(dx(1:b)) =
Z
˜Xb
Pb
i=1 Fi(θ0, x(i)) −∇U(θ0)

2
ν⊗b(dx(1:b))
+ ∥∇U(θ0)∥2
≤˜M ⟨θ0 −θ⋆, ∇U(θ0)⟩+ ˜B⋆+ ∥∇U(θ0) −∇U(θ⋆)∥2
≤[m + L + ˜M] ⟨θ0 −θ⋆, ∇U(θ0)⟩+ ˜B⋆−Lm ∥θ0 −θ⋆∥2 .
(S18)
Plugging (S18) in (S17) implies
18

Z
Rd ∥θ −θ⋆∥2 ˜Qγ(θ0, dθ) ≤(1 −γ2mL)∥θ0 −θ⋆∥2 −γ{2 −γ[m + L + ˜M]} ⟨θ0 −θ⋆, ∇U(θ0)⟩
+ γ2˜B⋆+ 2γd .
Using H1-(i), we have ⟨θ0 −θ⋆, ∇U(θ0)⟩≥m∥θ0 −θ⋆∥2 which, combined with the condition
γ ≤1/(m + L + ˜M), gives
Z
Rd ∥θ −θ⋆∥2 ˜Qγ(θ0, dθ) ≤(1 −γm[2 −γ(m + ˜M)])∥θ0 −θ⋆∥2 + γ(2d + γ˜B⋆) .
Using 0 < γ < 2/(m + ˜M) and the Markov property combined with a straightforward induction
completes the proof.
For any k ∈N, the following lemma gives an explicit upper bound on the expected squared norm
between ϑk+1 and θk+1 in function of ϑk, θk. The purpose of this lemma is to derive a contraction
property involving a contracting term and a bias term which is easy to control.
Lemma S7. Assume H1 and H5.
Consider (ϑt)t≥0 and (θk)k∈N deﬁned in (S14) and
(S15), respectively, for some initial distribution ξ ∈P2(R2d).
For any k ∈N and γ ∈
 0, 2/[(5(m + L)) ∨(m + ˜M + L)]

, we have
E
hϑγ(k+1) −θk+1
2i
≤{1 −γm(1 −5γm)}E

∥ϑk −θk∥2
+ γ2D0,γ
+ γ2L˜M(1 −γm

2 −γ(m + ˜M)

)kE[∥θ0 −θ⋆∥2]
+ γ3(m−1 + 5γ)L2E

∥ϑkγ −θ⋆∥2
/2 ,
where
D0,γ = d(m−1 + 5γ)

1 + γ2L2/12

+ ˜B⋆+
L˜M(2d + γ˜B⋆)
m

2 −γ(m + ˜M)
 .
Proof. Let k ∈N. By (S14) and (S15), we have
ϑγ(k+1) −θk+1 = ϑγk −θk −γ [∇U(ϑγk) −∇U(θk)]
−
Z γ
0
[∇U(ϑγk+s) −∇U(ϑγk)] ds + γ
b
X
i=1
h
Fi(θk, X(i)
k+1) −∇Ui(θk)
i
.
Deﬁne the ﬁltration (F˜k)˜k∈N as F0 = σ(ϑ0, θ0) and for ˜k ∈N∗,
F˜k = σ(ϑ0, θ0, (X(1)
l
, . . . , X(b)
l
)1≤l≤˜k, (Bt)0≤t≤γ˜k) .
Note that since (ϑt)t≥0 is a strong solution of (S14), then is easy to see that (ϑγ˜k, θ˜k)˜k∈N is (F˜k)˜k∈N-
adapted. Taking the squared norm and the conditional expectation with respect to Fk, we obtain
using H5-(i) that
EFk
hϑγ(k+1) −θk+1
2i
= ∥ϑγk −θk∥2 −2γ ⟨ϑγk −θk, ∇U(ϑγk) −∇U(θk)⟩
+ 2γ
Z γ
0

∇U(ϑγk) −∇U(θk), EFk [∇U(ϑγk+s) −∇U(ϑγk)]

ds
−2
Z γ
0

ϑγk −θk, EFk [∇U(ϑγk+s) −∇U(ϑγk)]

ds
+ γ2 ∥∇U(ϑγk) −∇U(θk)∥2
+ EFk
"
Z γ
0
[∇U(ϑγk+s) −∇U(ϑγk)] ds

2#
+ γ2EFk



b
X
i=1
Fi(θk, X(i)
k+1) −∇U(θk)

2
.
(S19)
19

First, using Jensen inequality and the fact that for any a, b ∈Rd, |⟨a, b⟩| ≤2 ∥a∥2 + 2 ∥b∥2, we get
Z γ
0

∇U(ϑγk) −∇U(θk), EFk [∇U(ϑγk+s) −∇U(ϑγk)]

ds
≤2γ ∥∇U(ϑγk) −∇U(θk)∥2 + 2
Z γ
0
EFk
h
∥∇U(ϑγk+s) −∇U(ϑγk)∥2i
ds ,
(S20)
EFk
"
Z γ
0
[∇U(ϑγk+s) −∇U(ϑγk)] ds

2#
≤γ
Z γ
0
EFk
h
∥∇U(ϑγk+s) −∇U(ϑγk)∥2i
ds .
In addition, given that for any ε > 0, a, b ∈Rd, |⟨a, b⟩| ≤ε ∥a∥2 + (4ε)−1 ∥b∥2, we get

Z γ
0

θk −ϑγk, EFk [∇U(ϑγk+s) −∇U(ϑγk)]

ds
 ≤γε ∥ϑγk −θk∥2
+ (4ε)−1
Z γ
0
EFk
h
∥∇U(ϑγk+s) −∇U(ϑγk)∥2i
ds .
(S21)
By H1, for k ∈N we get by (6)
∥∇U(ϑγk) −∇U(θk)∥2 ≤(m + L) ⟨ϑγk −θk, ∇U(ϑγk) −∇U(θk)⟩−mL ∥ϑγk −θk∥2 . (S22)
Lastly, H5-(ii) yields
EFk



b
X
i=1
Fi(θk, X(i)
k+1) −∇U(θk)

2
≤˜M ⟨θk −θ⋆, ∇U(θk) −∇U(θ⋆)⟩+ ˜B⋆.
(S23)
Combining (S20), (S21), (S22) and (S23) into (S19), for k ∈N we get for any ε > 0,
EFk
hϑγ(k+1) −θk+1
2i
≤(1 + 2γε −5γ2mL) ∥ϑγk −θk∥2
−γ [2 −5γ(m + L)] ⟨ϑγk −θk, ∇U(ϑγk) −∇U(θk)⟩
+ (5γ + (2ε)−1)
Z γ
0
EFk
h
∥∇U(ϑγk+s) −∇U(ϑγk)∥2i
ds
+ γ2˜M ⟨θk −θ⋆, ∇U(θk) −∇U(θ⋆)⟩+ γ2˜B⋆.
Next, we use that under H1, ⟨ϑγk −θk, ∇U(ϑγk) −∇U(θk)⟩≥m∥ϑγk −θk∥2 and |⟨θk −
θ⋆, ∇U(θk)−∇U(θ⋆)⟩| ≤L∥θk −θ⋆∥2, which implies taking ε = m/2 and since 2−5γ(m+L) ≥0,
EFk
hϑγ(k+1) −θk+1
2i
≤(1 −γm(1 −5γm)) ∥ϑγk −θk∥2
+ (5γ + m−1)
Z γ
0
EFk
h
∥∇U(ϑγk+s) −∇U(ϑγk)∥2i
ds
+ γ2˜ML ∥θk −θ⋆∥2 + γ2˜B⋆.
(S24)
Further, for any s ∈R+, using [17, Lemma 21] we have
EFk
h
∥∇U(ϑγk+s) −∇U(ϑγk)∥2i
≤ds
 2 + s2L2/3

+ 3s2L2/2 ∥ϑγk −θ⋆∥2 .
Integrating the previous inequality on [0, γ], for k ≥0 we obtain
Z γ
0
EFk
h
∥∇U(ϑγk+s) −∇U(ϑγk)∥2i
ds ≤dγ2 + dγ4L2/12 + γ3L2/2 ∥ϑγk −θ⋆∥2 .
Plugging this bound in (S24), taking expectation and using Lemma S7 conclude the proof.
20

S1.3
Proof of Theorem 1
Based on Theorem S5, the next corollary explicits an upper bound in Wasserstein distance between
π and µQk
γ, where we consider (θk)k∈N deﬁned in (S1) and starting from ˜θ following µ ∈P2(Rd).
Theorem S8. Assume H1, H2 and H3. Then, for any probability measure µ ∈P2(Rd), any step
size γ ∈(0, ¯γ] where ¯γ is deﬁned in (S13), any k ∈N, we have
W 2
2 (µQk
γ, π) ≤(1 −γm/2)kW 2
2 (µ, π) + γB¯γ + γ2A¯γ(1 −mγ/2)k−1k
Z
Rd ∥θ −θ⋆∥2µ(dθ) ,
where Qγ is deﬁned in (S4) and
B¯γ = (2d/m) (1/m + 5¯γ)

1 + ¯γL2/(2m) + ¯γ2L2/12

+ 4(ωB⋆+ σ2
⋆)/m
+ 4(ω + 1)LM

d + ¯γ(ωB⋆+ σ2
⋆)

/m2
(S25)
A¯γ = 2(ω + 1)LM .
Proof. By Lemma S4, the assumption H5 is satiﬁed for a choice of ˜M = 2(ω + 1)M and ˜B⋆=
2(ωB⋆+ σ2
⋆). Therefore, applying Theorem S5 completes the proof.
S2
Proof of Theorem 2
We assume here that {Ui}i∈[b] are deﬁned, for any i ∈[b] and θ ∈Rd, by
Ui(θ) =
N
X
j=1
Ui,j(θ) ,
N ∈N∗.
In all this section, we assume that n ∈N∗, n ≤N is ﬁxed. Recall that ℘N denotes the power set of
[N] and
℘N,n = {x ∈℘N : card(x) = n} .
We set in this section ν1 as the uniform distribution on ℘N,n. We consider the family of measurable
functions {F ⋆
i : Rd × Rd × ℘N →Rd}i∈[b], deﬁned for any i ∈[b], θ ∈Rd, x ∈℘N,n by
F ⋆
i (θ, x) = N
n
N
X
j=1
1x(j) [∇Ui,j(θ) −∇Ui,j(θ⋆)] .
(S26)
Let (X(1,1)
k
, . . . , X(1,b)
k
)k∈N∗and (X(2,1)
k
, . . . , X(2,b)
k
)k∈N∗be two independent i.i.d. sequences with
distribution ν⊗b
1
and ν⊗b
2 . Let (Zk)k∈N∗be an i.i.d. sequence of d-dimensional standard Gaussian
random variables independent of (X(1,1)
k
, . . . , X(1,b)
k
)k∈N∗and (X(2,1)
k
, . . . , X(2,b)
k
)k∈N∗. For ease
of notation, denote for any k ∈N∗, X(1)
k
= (X(1,1)
k
, . . . , X(1,b)
k
), X(2)
k
= (X(2,1)
k
, . . . , X(2,b)
k
) and
Xk = (X(1)
k , X(2)
k ).
Note that with this notation and under H2, QLSD⋆can be cast into the framework of the generalised
QLSD scheme deﬁned in (S1) since the recursion associated to QLSD⋆can be written as
˜θk+1 = ˜θk −γ
b
X
i=1
C

F ⋆
i (˜θk, X(1,i)
k+1 ), X(2,i)
k+1
 p
2γZk+1 ,
k ∈N .
(S27)
Therefore, we only need to verify that H5 is satisﬁed with X = ˜X = X1 × X2, X = ˜
X = X1 ⊗X2,
˜ν = ν1 ⊗ν2 and {Fi}b
i=1 = {F ⋆
i }b
i=1. This is done in Appendix S2.2.
S2.1
Proof of Theorem 2
The Markov kernel associated with (S27) is given for any (θ, A) ∈Rd × B(Rd) by
Q⃝⋆,γ(θ, A) = (4πγ)−d/2
Z
A×˜Xb exp

−∥˜θ −θ + γ Pb
i=1 F ⋆
i (θ, x(i))∥2/(4γ)

d˜θ ˜ν⊗b(dx(1:b)) .
(S28)
Then, the following non-asymptotic convergence result holds for QLSD⋆.
21

Theorem S9. Assume H1, H2, H4. Then, for any probability measure µ ∈P2(Rd), any step size
γ ∈(0, ¯γ] where ¯γ is deﬁned in (S13), any k ∈N, we have
W 2
2 (µQk
⃝⋆,γ, π) ≤(1 −γm/2)kW 2
2 (µ, π) + γB⃝⋆,¯γ + γ2A⃝⋆,¯γ(1 −mγ/2)k−1k
Z
Rd ∥θ −θ⋆∥2µ(dθ) ,
where Q⃝⋆,γ is deﬁned in (S28) and
B⃝⋆,¯γ = (2d/m) (1/m + 5¯γ)

1 + ¯γL2/(2m) + ¯γ2L2/12

+ 2Ld[Nω + (ω + 1)An,N]¯M/m2
(S29)
A⃝⋆,¯γ = 2(ω + 1)LM ,
An,N being deﬁned in (S30).
Proof. Using Lemma S11, H5 is satisﬁed and applying Theorem S5 completes the proof.
S2.2
Supporting Lemmata
In this subsection, we derive two key lemmata in order to prove Theorem S9.
Lemma S10. For any sequence {aj}N
j=1 ∈(Rd)⊗N where N ≥2, we have
Z
X1

N
X
j=1
h
1x(1)(j) −n
N
i
aj

2
ν1(dx(1)) ≤n(N −n)
N(N −1)
N
X
j=1
∥aj∥2 .
Proof. Let X(1) distributed according to ν1. Since PN
j=1 1X(1)(j) = n, we have
N
X
l=1
1X(1)(l) +
X
j̸=j′
1X(1)(j)1X(1)(j′) = n2 .
Integrating this equality over X1 gives
N × n
N + N(N −1) ×
Z
X1
[1x(1)(1)1x(1)(2)] ν1(dx(1)) = n2 .
Thus, we deduce that
R
X1[1x(1)(1)1x(1)(2)]ν1(dx(1)) = n(n −1) [N(N −1)]−1. In addition, using
that
Z
X1

1x(1)(j) −n
N
 
1x(1)(j′) −n
N

ν1(dx(1)) =
Z
X1
[1x(1)(1)1x(1)(2)]ν1(dx(1)) −n2
N 2 ,
we obtain
Z
X1

N
X
j=1
h
1x(1)(j) −n
N
i
aj

2
ν1(dx(1)) = n(N −n)
N 2


N
X
l=1
∥al∥2 −
X
j̸=j′
⟨aj, aj′⟩
N −1


= n(N −n)
N 2(N −1)

N
N
X
l=1
∥al∥2 −

N
X
l=1
al

2
.
Denote
An,N = N(N −n)
n(N −1) .
(S30)
The next lemma aims at controlling the variance of the global stochastic gradient considered in
QLSD⋆, required to apply Theorem S5.
22

Lemma S11. Assume H2 and H4. Then, for any θ ∈Rd, we have
Z
Xb
Pb
i=1 C
 F ⋆
i (θ, x(1,i)), x(2,i)
−∇U(θ)

2
ν⊗b(dx(1:b))
≤[Nω + (ω + 1)An,N] ¯M ⟨θ −θ⋆, ∇U(θ) −∇U(θ⋆)⟩,
where {F ⋆
i }i∈[b] and An,N are deﬁned in (S26) and (S30), respectively. Hence H5 is satiﬁed with
˜B⋆= 0 and ˜M = [Nω + (ω + 1)An,N]¯M.
Proof. Let θ ∈Rd, using H2 gives
Z
Xb

b
X
i=1
C

F ⋆
i (θ, x(1,i)), x(2,i)
−∇U(θ)

2
ν⊗b(dx(1:b))
=
Z
Xb

b
X
i=1
C

N
n
N
X
j=1
1x(1,i)(j) [∇Ui,j(θ) −∇Ui,j(θ⋆)] , x(2,i)


−
b
X
i=1
N
n
N
X
j=1
1x(1,i)(j) [∇Ui,j(θ) −∇Ui,j(θ⋆)]

2
ν⊗b(dx(1:b))
+
Z
Xb
1

b
X
i=1
N
n
N
X
j=1

1x(1,i)(j) −n
N

[∇Ui,j(θ) −∇Ui,j(θ⋆)]

2
ν⊗b
1 (dx(1,1:b))
≤ω
N
n
2
b
X
i=1
Z
X1

N
X
j=1
1x(1,i)(j) [∇Ui,j(θ) −∇Ui,j(θ⋆)]

2
ν1(dx(1,i))
+
N
n
2
b
X
i=1
Z
X1

N
X
j=1

1x(1,i)(j) −n
N

∇Ui,j(θ) −∇Ui,j(θ⋆)

2
ν1(dx(1,i))
= ω
b
X
i=1
∥∇Ui(θ) −∇Ui(θ⋆)∥2
+ (ω + 1)
N
n
2
b
X
i=1
Z
Xb
1

N
X
j=1

1x(1,i)(j) −n
N

[∇Ui,j(θ) −∇Ui,j(θ⋆)]

2
ν1(dx(1,i)) . (S31)
Using Lemma S10 combined with H4 yields, for any i ∈[b],
Z
X1
PN
j=1 (1x(1,i)(j) −n/N) [∇Ui,j(θ) −∇Ui,j(θ⋆)]

2
ν1(dx(1,i))
≤n(N −n)
N(N −1)
¯M ⟨θ −θ⋆, ∇Ui(θ) −∇Ui(θ⋆)⟩.
(S32)
In addition, Jensen inequality implies, for any i ∈[b], that
∥∇Ui(θ) −∇Ui(θ⋆)∥2 ≤N
N
X
j=1
∥∇Ui,j(θ) −∇Ui,j(θ⋆)∥2 ,
and therefore, using H4, we have for any i ∈[b],
∥∇Ui(θ) −∇Ui(θ⋆)∥2 ≤¯MN ⟨∇Ui(θ) −∇Ui(θ⋆), θ −θ⋆⟩.
(S33)
Injecting (S32) and (S33) into (S31) concludes the proof.
23

S3
Proof of Theorem 3
S3.1
Problem formulation.
We assume here that U is still of the form (1) and that there exists N ∈N∗such that for any i ∈[b],
there exists N functions {Ui,j : θ ∈Rd →R}j∈[N] such that for any θ ∈Rd,
Ui(θ) =
N
X
j=1
Ui,j(θ) .
In all this section, we assume that n ∈N∗, n ≤N is ﬁxed. Recall that ℘N denotes the power set of
[N] and
℘N,n = {x ∈℘N : card(x) = n} .
In addition, we set in this section ν1 as the uniform distribution on ℘N,n. We consider the family of
measurable functions {Gi : Rd × Rd × ℘N →Rd}i∈[b], deﬁned for any i ∈[b], θ ∈Rd, ζ ∈Rd,
x ∈℘N,n by
Gi(θ, ζ; x) = N
n
N
X
j=1
1x(j) [∇Ui,j(θ) −∇Ui,j(ζ)] + ∇Ui(ζ) .
(S34)
For ease of reading, we formalise more precisely the recursion associated with QLSD++ under
H2.
Let (X(1,1)
k
, . . . , X(1,b)
k
)k∈N∗and (X(2,1)
k
, . . . , X(2,b)
k
)k∈N∗be two independent i.i.d. se-
quences with distribution ν⊗b
1
and ν⊗b
2 , respectively.
Let (Zk)k∈N∗be an i.i.d. sequence of
d-dimensional standard Gaussian random variables independent of (X(1,1)
k
, . . . , X(1,b)
k
)k∈N∗and
(X(2,1)
k
, . . . , X(2,b)
k
)k∈N∗.
Denote for any k ∈N∗, X(1)
k
= (X(1,1)
k
, . . . , X(1,b)
k
), X(2)
k
=
(X(2,1)
k
, . . . , X(2,b)
k
) and Xk = (X(1)
k , X(2)
k ). Let l ∈N∗, γ ∈(0, ¯γ] and α ∈(0, ¯α] for ¯γ, ¯α > 0.
Given Θ0 = (θ0, ζ0, {η(i)
0 }i∈[b]) ∈Rd×Rd×Rdb, with ζ0 = θ0, we recursively deﬁne the sequence
(Θk)k∈N = (θk, ζk, {η(i)
k }i∈[b])k∈N, for any k ∈N as
θk+1 = θk −γ ˜G(Θk; Xk+1) +
p
2γZk+1 ,
(S35)
where
˜G(Θk; Xk+1) =
b
X
i=1
h
C
n
Gi

θk, ζk; X(1,i)
k+1

−η(i)
k ; X(2,i)
k+1
o
+ η(i)
k
i
,
(S36)
ζk+1 =
θk+1 , if k + 1 ≡0
(mod l) ,
ζk , otherwise ,
(S37)
and for any i ∈[b],
η(i)
k+1 = η(i)
k + αC
n
Gi

θk, ζk; X(1,i)
k+1

−η(i)
k ; X(2,i)
k+1
o
.
(S38)
Since QLSD++ involves auxiliary variables gathered with (θk)k∈N in (Θk)k∈N, we cannot follow
the same proof as for QLSD⋆by verifying H5 and then applying Theorem S5. Instead, we will
adapt the proof Theorem S5 and in particular Lemma S6 and bound the variance associated to the
stochastic gradient deﬁned in (S36). Once this variance term will be tackled, the proof of Theorem 3
will follow the same lines as the proof of Theorem S5 upon using speciﬁc moment estimates for
QLSD++. In the next section, we focus on these two goals: we provide uniform bounds in the number
of iterations k on the variance of the sequence of stochastic gradients associated with QLSD++,
(E[∥˜Gi(Θk, Xk+1) −∇U(θk)∥2])k∈N for any i ∈[b], and (E[∥θk −θ⋆∥2])k∈N, see Proposition S18
and Corollary S17. To this end, a key ingredient is the design of an appropriate Lyapunov function
deﬁned in (S50).
24

S3.2
Uniform bounds on the stochastic gradients and moment estimates
Consider the ﬁltration associated with (Θk)k∈N deﬁned by G0 = σ(Θ0) and for k ∈N∗,
Gk = σ(Θ0, (X˜k)˜k≤k, (Z˜k)˜k≤k) .
We denote for any i ∈[b], θ, ζ ∈Rd,
∆i(θ, ζ) = ∇Ui(θ) −∇Ui(ζ) .
(S39)
Similarly, we consider, for any i ∈[b], j ∈[N], θ, ζ ∈Rd,
∆i,j(θ, ζ) = ∇Ui,j(θ) −∇Ui,j(ζ) .
(S40)
The following lemma provides a ﬁrst upper bound on the variance of the stochastic gradients used
in QLSD++.
Lemma S12. Assume H1, H2 and H4 and let γ ∈(0, ¯γ], α ∈(0, ¯α] for some ¯γ, ¯α > 0. Then, for
any s ∈N, r ∈{0, . . . , l −1}, we have
EGsl+r
 ˜G(Θsl+r; Xsl+r+1) −∇U(θsl+r)

2
≤

2(ω + 1)An,N¯ML + 2ωbM2
∥θsl+r −θ⋆∥2
+ 2ω
b
X
i=1
∇Ui(θ⋆) −η(i)
sl+r

2
+ 2(ω + 1)An,N¯ML ∥θsl −θ⋆∥2 ,
where (Θ˜k)˜k∈N = (θ˜k, ζ˜k, {η(i)
˜k }i∈[b])˜k∈N, ˜G and An,N are deﬁned in (S35), (S37), (S38), (S36)
and (S30), respectively.
Proof. Let s ∈N and r ∈{0, . . . , l −1}. Using H2, (S39) and (S40), we have
EGsl+r
 ˜G(Θsl+r; Xsl+r+1) −∇U(θsl+r)

2
≤ω
b
X
i=1
EGsl+r



N
n
N
X
j=1
n
1X(1,i)
sl+r+1(j)∆i,j(θsl+r, ζsl+r)
o
+ ∇Ui(ζsl+r) −η(i)
sl+r

2

+
b
X
i=1
EGsl+r



N
n
N
X
j=1
n
1X(1,i)
sl+r+1(j)∆i,j(θsl+r, ζsl+r)
o
−∆i(θsl+r, ζsl+r)

2

≤(ω + 1)
b
X
i=1
EGsl+r



N
n
N
X
j=1
n
1X(1,i)
sl+r+1(j)∆i,j(θsl+r, ζsl+r)
o
−∆i(θsl+r, ζsl+r)

2

+ ω
b
X
i=1
∇Ui(θsl+r) −η(i)
sl+r

2
≤(ω + 1)N(N −n)
n(N −1)
¯M⟨θsl+r −ζsl+r, ∇U(θsl+r) −∇U(ζsl+r)⟩
+ ω
b
X
i=1
∇Ui(θsl+r) −η(i)
sl+r

2
,
where the last line follows from H4 and Lemma S10. The proof is concluded by using the Cauchy-
Schwarz inequality, H1 and ζsl+r = θsl.
The two following lemmas aim at controlling the terms that appear in Lemma S12.
25

Lemma S13. Assume H1, H2 and H4, and let γ ∈(0, ¯γ], α ∈(0, ¯α] for some ¯γ, ¯α > 0. Then, for
any s ∈N and r ∈[l], we have
EGsl+r−1
h
∥θsl+r −θ⋆∥2i
≤
 1 −2γm + γ2Bn,N

∥θsl+r−1 −θ⋆∥2
+ 2γ2ω
b
X
i=1
∇Ui(θ⋆) −η(i)
sl+r−1

2
+ 2γ2(ω + 1)An,N¯ML ∥θsl −θ⋆∥2 + 2γd ,
where
Bn,N = 2

(ω + 1)An,N¯ML + ωbM2 + L2
,
(S41)
(Θ˜k)˜k∈N = (θ˜k, ζ˜k, {ηi
˜k}i∈[b])˜k∈N and An,N are deﬁned in (S35), (S37), (S38) and (S30) respec-
tively.
Proof. Let s ∈N and r ∈[l]. Using (S35) and H2, it follows
EGsl+r−1
h
∥θsl+r −θ⋆∥2i
= ∥θsl+r−1 −θ⋆∥2 + 2γd −2γ⟨∇U(θsl+r−1), θsl+r−1 −θ⋆⟩
+ γ2EGsl+r−1
 ˜G(Θsl+r; Xsl+r+1)

2
.
(S42)
Using H2 and (S34)-(S36), we have
EGsl+r−1
 ˜G(Θsl+r; Xsl+r+1)

2
≤ω
b
X
i=1
EGsl+r−1



N
n
N
X
j=1
n
1X(1,i)
sl+r(j)∆i,j(θsl+r−1, ζsl+r−1)
o
+ ∇Ui(ζsl+r−1) −η(i)
sl+r−1

2

+
b
X
i=1
EGsl+r−1



N
n
N
X
j=1
n
1X(1,i)
sl+r(j)∆i,j(θsl+r−1, ζsl+r−1)
o
−∆i(θsl+r−1, ζsl+r−1)

2

+ ∥∇U(θsl+r−1)∥2
≤(ω + 1)
b
X
i=1
EGsl+r−1



N
n
N
X
j=1
n
1X(1,i)
sl+r(j)∆i,j(θsl+r−1, ζsl+r−1)
o
−∆i(θsl+r−1, ζsl+r−1)

2

+ ∥∇U(θsl+r−1)∥2 + ω
b
X
i=1
∇Ui(θsl+r−1) −η(i)
sl+r−1

2
≤(ω + 1)N(N −n)
n(N −1)
¯M⟨θsl+r−1 −ζsl+r−1, ∇U(θsl+r−1) −∇U(ζsl+r−1)⟩
+ ∥∇U(θsl+r−1)∥2 + ω
b
X
i=1
∇Ui(θsl+r−1) −η(i)
sl+r−1

2
,
(S43)
where the last line follows from H4 and Lemma S10. The proof is concluded by injecting (S43) into
(S42), using the Cauchy-Schwarz inequality, ∇U(θ⋆) = 0, H1 and ζsl+r−1 = θsl.
Lemma S14. Assume H1, H2 and H4. Let γ ∈(0, ¯γ] for some ¯γ > 0 and α ∈(0, 1/(ω + 1)].
Then, for any s ∈N and r ∈[l], we have
b
X
i=1
EGsl+r−1
∇Ui(θ⋆) −η(i)
sl+r

2
≤(1 −α)
b
X
i=1
∇Ui(θ⋆) −η(i)
sl+r−1

2
+ αCn,N ∥θsl+r−1 −θ⋆∥2 + 2αAn,N¯ML ∥θsl −θ⋆∥2 ,
26

where
Cn,N =

2An,N¯ML + bM2
,
(S44)
(Θ˜k)˜k∈N = (θ˜k, ζ˜k, {ηi
˜k}i∈[b])˜k∈N and An,N are deﬁned in (S35), (S37), (S38) and (S30), respec-
tively.
Proof. Let s ∈N and r ∈[l]. Then, it follows
b
X
i=1
EGsl+r−1
∇Ui(θ⋆) −η(i)
sl+r

2
=
b
X
i=1
∇Ui(θ⋆) −η(i)
sl+r−1

2
+
b
X
i=1
EGsl+r−1
η(i)
sl+r −η(i)
sl+r−1

2
+ 2
b
X
i=1
⟨EGsl+r−1
h
η(i)
sl+r −η(i)
sl+r−1
i
, η(i)
sl+r−1 −∇Ui(θ⋆)⟩.
(S45)
Using (S38) and H2, we have for any i ∈[b],
EGsl+r−1
η(i)
sl+r −η(i)
sl+r−1

2
≤α2(ω + 1)EGsl+r−1
Gi

θsl+r−1, ζsl+r−1; X(1,i)
sl+r

−η(i)
sl+r−1

2
,
(S46)
EGsl+r−1
h
η(i)
sl+r −η(i)
sl+r−1
i
= αEGsl+r−1
h
Gi

θsl+r−1, ζsl+r−1; X(1,i)
sl+r

−η(i)
sl+r−1
i
.
(S47)
Plugging (S46) and (S47) into (S45) yields
b
X
i=1
EGsl+r−1
∇Ui(θ⋆) −η(i)
sl+r

2
≤
b
X
i=1
∇Ui(θ⋆) −η(i)
sl+r−1

2
+ α2(ω + 1)
b
X
i=1
EGsl+r−1
Gi

θsl+r−1, ζsl+r−1; X(1,i)
sl+r

−η(i)
sl+r−1

2
+ 2α
b
X
i=1
⟨EGsl+r−1
h
Gi

θsl+r−1, ζsl+r−1; X(1,i)
sl+r

−η(i)
sl+r−1
i
, η(i)
sl+r−1 −∇Ui(θ⋆)⟩.
Using α(1 + ω) ≤1 and the fact, for any a, b, c ∈Rd, that ∥a −c∥2 + 2⟨(a −c), (c −b)⟩=
∥a −b∥2 −∥c −b∥2, we have
b
X
i=1
EGsl+r−1
∇Ui(θ⋆) −η(i)
sl+r

2
≤(1 −α)
b
X
i=1
∇Ui(θ⋆) −η(i)
sl+r−1

2
+ α
b
X
i=1
EGsl+r−1
Gi

θsl+r−1, ζsl+r; X(1,i)
sl+r

−∇Ui(θ⋆)

2
.
(S48)
Using (S34), H4 and Lemma S10, it follows
b
X
i=1
EGsl+r−1
Gi

θsl+r−1, ζsl+r−1; X(1,i)
sl+r

−∇Ui(θ⋆)

2
≤N(N −n)
n(N −1)
¯M⟨θsl+r−1 −ζsl+r−1, ∇U(θsl+r−1) −∇U(ζsl+r−1)⟩
+
b
X
i=1
∥∇Ui(θsl+r−1) −∇Ui(θ⋆)∥2 .
(S49)
The proof is concluded by plugging (S49) into (S48), using the Cauchy-Schwarz inequality, H1 and
ζsl+r−1 = θsl.
27

Lemma S13 and Lemma S14 involve two dependent terms which prevents us from using a straight-
forward induction. To cope with this issue, we consider a Lyapunov function ψ : Rd × Rbd →R
deﬁned, for any θ ∈Rd and η = (η(1), . . . , η(b))⊤∈Rbd by
ψ(θ, η) = ∥θ −θ⋆∥2 + (3ω/α)γ2
b
X
i=1
∇Ui(θ⋆) −η(i)
2
.
(S50)
The following lemma provides an upper bound on this Lyapunov function. Deﬁne for α > 0,
¯γα,1 = m−1[{m2(Bn,N + 3ωCn,N)−1} ∧{α/3}] ,
(S51)
where Bn,N and Cn,N are deﬁned in (S41) and (S44) respectively.
Lemma S15. Assume H1, H2 and H4. Let α ∈(0, 1/(ω + 1)], γ ∈(0, ¯γα,1]. Then, for any s ∈N
and r ∈[l], we have
EGsl+r−1 [ψ(θsl+r, ηsl+r)] ≤(1 −γm) ψ(θsl+r−1, ηsl+r−1)
+ 2An,N¯MLγ2 [4ω + 1] ∥θsl −θ⋆∥2 + 2γd ,
where ψ is deﬁned in (S50) and (Θ˜k)˜k∈N = (θ˜k, ζ˜k, {ηi
˜k}i∈[b])˜k∈N and An,N are deﬁned in (S35),
(S37), (S38) and (S30), respectively.
Proof. Let s ∈N and r ∈[l]. Using Lemma S13 and Lemma S14, we have
EGsl+r−1 [ψ(θsl+r, ηsl+r)]
≤
 1 −2γm + γ2 [Bn,N + 3ωCn,N]

∥θsl+r−1 −θ⋆∥2
+ [3α + (1 −α)] (3ω/α)γ2
b
X
i=1
∇Ui(θ⋆) −η(i)
sl+r−1

2
+ 2An,N¯MLγ2 [4ω + 1] ∥θsl −θ⋆∥2 + 2γd .
Since γ ≤¯γα,1 with ¯γα,1 given in (S51), it follows that
1 −2γm + [Bn,N + 3ωCn,N] ≤1 −γm
3α + (1 −α) ≤1 −γm .
Therefore, we have
EGsl+r−1 [ψ(θsl+r, ηsl+r)] ≤(1 −γm) ψ(θsl+r−1, ηsl+r−1)
+ 2An,N¯MLγ2 [4ω + 1] ∥θsl −θ⋆∥2 + 2γd .
Lemma S16. Let p ∈N∗and ﬁx γ > 0 such that
γ ≤
m
4An,N¯MLp(4ω + 1) ∧1
m .
Then,
(1 −γm)p + 2An,N¯MLp[4ω + 1]γ2 ≤1 −γm/2 ,
where An,N is deﬁned in (S30).
Proof. The proof is straightforward using (1 −γm)p ≤1 −γm.
We have the following corollary regarding the Lyapunov function deﬁned in (S50).
Denote for α > 0,
¯γα,2 = ¯γα,1 ∧[m/{4An,N¯MLl(4ω + 1)}] ,
(S52)
where ¯γα,1 is given in (S51).
28

Corollary S17. Assume H1, H2 and H4. Let α ∈(0, 1/(ω + 1)] and γ ∈(0, ¯γα,2]. Then, for any
s ∈N and r ∈{0, . . . , l −1} we have
EGsl 
ψ(θ(s+1)l−r, η(s+1)l−r

≤(1 −γm/2) ψ(θsl, ηsl) + 2γ(l −r)d ,
where ψ is deﬁned in (S50) and (Θ˜k)˜k∈N = (θ˜k, ζ˜k, {ηi
˜k}i∈[b])˜k∈N is deﬁned in (S35), (S37), (S38).
Proof. The proof follows from a straightforward induction of Lemma S15 combined with
Lemma S16.
We are now ready to control explicitly the variance of the stochastic gradient deﬁned in (S36).
Proposition S18. Assume H1, H2 and H4. Let α ∈(0, 1/(ω + 1)] and γ ∈(0, ¯γα,2], where ¯γα,2
is deﬁned in (S52). Then, for any k = sl + r with s ∈N, r ∈{0, . . . , l −1}, θ0 ∈Rd and
η0 = (η(1)
0 , . . . , η(b)
0 )⊤∈Rdb, we have
E
 ˜G(Θsl+r; Xsl+r+1) −∇U(θk)

2
≤(1 −γm/2)sDn,Nψ(θ0, η0) + 4ldDn,N/m
+ 2ω(1 −α)k
b
X
i=1
E
∇Ui(θ⋆) −η(i)
0

2
,
where
Dn,N = 4(ω + 1)An,N¯ML + 2bωM2 + 4ωCn,N ,
(S53)
An,N and Cn,N are deﬁned in (S30) and (S44) respectively, ψ is deﬁned in (S50), and (Θ˜k)˜k∈N =
(θ˜k, ζ˜k, {ηi
˜k}i∈[b])˜k∈N is deﬁned in (S35), (S37), (S38).
Proof. Let k ∈N and write k = sl + r with s ∈N, r ∈{0, . . . , l −1} Then, using Lemma S12, we
have
E
 ˜G(Θsl+r; Xsl+r+1) −∇U(θk)

2
≤

2(ω + 1)An,N¯ML + 2ωbM2
E
h
∥θk −θ⋆∥2i
+ 2ω
b
X
i=1
E
∇Ui(θ⋆) −η(i)
k

2
+ 2(ω + 1)An,N¯MLE
h
∥θsl −θ⋆∥2i
.
(S54)
We now use our previous results to upper bound the three expectations at the right-hand side of
(S54). First, using Corollary S17 and a straightforward induction gives
E
h
∥θsl −θ⋆∥2i
≤(1 −γm/2)sψ(θ0, η0) + 2γld
s−1
X
j=0
(1 −γm/2)j
≤(1 −γm/2)sψ(θ0, η0) + 4ld/m .
(S55)
Similarly, we have
E
h
∥θk −θ⋆∥2i
≤(1 −γm/2)s+1ψ(θ0, η0) + 2γld
s
X
j=0
(1 −γm/2)j
≤(1 −γm/2)sψ(θ0, η0) + 4ld/m .
(S56)
Finally, using Lemma S14 combined with (S55) and (S56), we obtain
b
X
i=1
E
∇Ui(θ⋆) −η(i)
k

2
≤(1 −α)
b
X
i=1
E
∇Ui(θ⋆) −η(i)
k−1

2
+ 2αCn,N(1 −γm/2)sψ(θ0, η0) + 8ldαCn,N/m .
Then, a straightforward induction leads to
b
X
i=1
E
∇Ui(θ⋆) −η(i)
k

2
≤(1 −α)k
b
X
i=1
∇Ui(θ⋆) −η(i)
0

2
+ 2Cn,N(1 −γm/2)sψ(θ0, η0) + 8ldCn,N/m .
(S57)
Combining (S55), (S56) and (S57) in (S54) concludes the proof.
29

S3.3
Proof of Theorem 3
Note that γ ∈(0, ¯γ], α ∈(0, ¯α] and l ∈N∗, (Θ˜k)˜k∈N = (θ˜k, ζ˜k, {η(i)
˜k }i∈[b])˜k∈N deﬁned in (S35),
(S37), (S38) is a inhomogeneous Markov chain associated with the sequence of Markov kernel
(Q(k)
γ,α,l)k∈N deﬁned by as follows. Deﬁne for any (θ, ζ, η) ∈Rd × Rd × Rd, and x(1) ∈℘N,n and
x(2) ∈X2,
Fi((θ, ζ, η); (x(1), x(2))) = C
n
Gi

θ, ζ; x(1)
−η; x(2)o
Gi((θ, ζ, η); (x(1), x(2))) = η + αFi((θ, ζ, η); (x(1), x(2))) .
and for ˜θ ∈Rd, {η(i)}b
i=1 ∈Rdb, {x(1,i)}b
i=1 ∈℘b
N,n, {x(2,i)}b
i=1 ∈Xb
2, setting x(1:b) =
{(x(1,i), x(2,i))}b
i=1,
ϕγ((˜θ, θ, ζ, {η(i)}b
i=1); x(1:b))
= (4πγ)−d/2 exp

−∥˜θ −θ + γ Pb
i=1 Fi((θ, ζ, η(i)); x(i))∥2/(4γ)

.
Denote ˜X = ℘N,n × X2 and ˜ν = ν1 × ν2. Set Q(0)
γ,α,l = Id and for k ≥0, k = ls + r, s ∈N,
r ∈{0, . . . , l −1}, (θ, ζ, η) ∈Rd × Rd × Rdb and A ∈B(Rd × Rd × Rdb),
if r = 0
Q(k+1)
γ,α,l ((θ, ζ, η), A) =
R
˜Xb 1A(˜θ, ˜ζ, ˜η)ϕγ((˜θ, θ, ζ, {η(i)}b
i=1); x(1:b)){Qb
i=1 δGi((θ,ζ,η);x(i))(d˜η(i))}δθ(d˜ζ) d˜θ ˜ν⊗b(dx(1:b))
otherwise
Q(k+1)
γ,α,l ((θ, ζ, η), A) =
R
˜Xb 1A(˜θ, ˜ζ, ˜η)ϕγ((˜θ, θ, ζ, {η(i)}b
i=1); x(1:b)){Qb
i=1 δGi((θ,ζ,η);x(i))(d˜η(i))}δζ(d˜ζ) d˜θ ˜ν⊗b(dx(1:b)) .
Consider then, the Markov kernel on Rd × B(Rd),
R(k)
γ,α,l,η0(θ0, A) = Q(k)
γ,α,l((θ0, θ0, η0), A × Rd × Rdb) .
(S58)
Deﬁne
¯γα = ¯γα,2 ∧¯γ4 ,
¯γ4 = 1/(10m) ,
(S59)
where ¯γα,2 is deﬁned in (S52). The following theorem provides a non-asymptotic convergence
bound for the QLSD++ kernel.
Theorem S19. Assume H1, H2 and H4. and let l ∈N∗. Then, for any probability measure
µ ∈P2(Rd), η0 ∈Rdb, α ∈(0, 1/(1 + ω)], γ ∈(0, ¯γα], and k = sl + r ∈N with s ∈N,
r ∈{0, . . . , l −1}, we have
W 2
2 (µR(k)
γ,α,l,η0, π) ≤(1 −γm/2)kW 2
2 (µ, π) + (2γ/m)(1 −γm/2)sDn,N
Z
Rd ψ(θ0, η0)dµ(θ0)
+ (4γ/m)ω(1 −α)k
b
X
i=1
∇Ui(θ⋆) −η(i)
0

2
+ γB⊕,¯γα ,
where R(k)
γ,α,l,η0 is deﬁned in (S58), ψ is deﬁned in (S50), Dn,N in (S53) and
B⊕,¯γα = 2d(m−1 + 5¯γα)

1 + ¯γαL2/(2m) + ¯γ2
αL2/12

/m + 8ld(4An,N¯ML + 2bM2)(3ω + 1)/m2 .
(S60)
Proof. Let k ∈N. The proof follows from the same lines as Theorem S8. By (S14) and (S35), we
have
ϑγ(k+1) −θk+1 = ϑγk −θk −γ [∇U(ϑγk) −∇U(θk)]
30

−
Z γ
0
[∇U(ϑγk+s) −∇U(ϑγk)] ds + γ
h
˜G(Θk; Xk+1) −∇U(θk)
i
.
Deﬁne the ﬁltration (H˜k)˜k∈N as H0 = σ(ϑ0, Θ0) and for ˜k ∈N∗,
H˜k = σ(ϑ0, Θ0, (X(1)
l
, . . . , X(b)
l
)1≤l≤˜k, (Bt)0≤t≤γ˜k) .
Note that since (ϑt)t≥0 is a strong solution of (S14), then is easy to see that (ϑγ˜k, Θ˜k)˜k∈N is
(H˜k)˜k∈N-adapted. Taking the squared norm and the conditional expectation with respect to Hk,
we obtain using H5-(i) that
EHk
hϑγ(k+1) −θk+1
2i
= ∥ϑγk −θk∥2 −2γ ⟨ϑγk −θk, ∇U(ϑγk) −∇U(θk)⟩
+ 2γ
Z γ
0

∇U(ϑγk) −∇U(θk), EHk [∇U(ϑγk+u) −∇U(ϑγk)]

du
−2
Z γ
0

ϑγk −θk, EHk [∇U(ϑγk+u) −∇U(ϑγk)]

du
+ γ2 ∥∇U(ϑγk) −∇U(θk)∥2
+ EHk
"
Z γ
0
[∇U(ϑγk+u) −∇U(ϑγk)] du

2#
+ γ2EHk
 ˜G(Θk; Xk+1) −∇U(θk)

2
.
(S61)
Using Proposition S18, we obtain
E
 ˜G(Θk; Xk+1) −∇U(θk)

2
≤(1 −γm/2)⌊k/l⌋Dn,Nψ(θ0, η0) + 4ldDn,N/m
+ 2ω(1 −α)k
b
X
i=1
∇Ui(θ⋆) −η(i)
0

2
.
(S62)
Then, we control the remaining terms in (S61) using (S20), (S21) and (S22). Combining these
bounds and (S62) into (S61), for any ε > 0, yields
E
hϑγ(k+1) −θk+1
2i
≤(1 + 2γε −5γ2mL)E
h
∥ϑγk −θk∥2i
−γ [2 −5γ(m + L)] E [⟨ϑγk −θk, ∇U(ϑγk) −∇U(θk)⟩]
+ (5γ + (2ε)−1)
Z γ
0
E
h
∥∇U(ϑγk+u) −∇U(ϑγk)∥2i
du
+ γ2(1 −γm/2)⌊k/l⌋Dn,NE [ψ(θ0, η0)] + 4ldDn,N/m
+ 2γ2ω(1 −α)k
b
X
i=1
∇Ui(θ⋆) −η(i)
0

2
.
(S63)
Next, we use that under H1, ⟨ϑγk −θk, ∇U(ϑγk) −∇U(θk)⟩≥m∥ϑγk −θk∥2 and |⟨θk −
θ⋆, ∇U(θk)−∇U(θ⋆)⟩| ≤L∥θk −θ⋆∥2, which implies taking ε = m/2 and since 2−5γ(m+L) ≥0,
E
hϑγ(k+1) −θk+1
2i
≤(1 −γm(1 −5γm))E
h
∥ϑγk −θk∥2i
+ (5γ + m−1)
Z γ
0
E
h
∥∇U(ϑγk+u) −∇U(ϑγk)∥2i
du
+ γ2(1 −γm/2)⌊k/l⌋Dn,NE [ψ(θ0, η0)] + 4ldDn,N/m
+ 2γ2ω(1 −α)k
b
X
i=1
∇Ui(θ⋆) −η(i)
0

2
.
(S64)
31

Further, for any u ∈R+, using [17, Lemma 21] we have
E
h
∥∇U(ϑγk+u) −∇U(ϑγk)∥2i
≤du
 2 + u2L2/3

+ 3u2L2/2E
h
∥ϑγk −θ⋆∥2i
.
Integrating the previous inequality on [0, γ], we obtain
Z γ
0
E
h
∥∇U(ϑγk+u) −∇U(ϑγk)∥2i
du ≤dγ2 + dγ4L2/12 + γ3L2/2E
h
∥ϑγk −θ⋆∥2i
.
Plugging this bounds in (S64) and using Lemma S7 conclude the proof.
S4
Consistency analysis in the big data regime
In this section, we provide upper bounds on the asymptotic bias associated to each algorithm when
the number of observations on each client N tends towards inﬁnity.
S4.1
Asymptotic analysis for Algorithm 1
The following corollary is associated with QLSD deﬁned in Algorithm 1.
Corollary S20. Assume H1, H2 and H3. In addition, assume that lim infN→∞m/N > 0 and
lim supN→∞A/N > 0 for A ∈{L, M, B⋆, σ⋆}. Then, we have ¯γ = ¯η/N where ¯η > 0 and ¯γ is
deﬁned in (S13). In addition,
B¯γ = (ω + 1) O(N) ,
where B¯γ is deﬁned in (S25).
Proof. Since we assume that lim infN→∞m/N
> 0 and lim supN→∞A/N
> 0 for A ∈
{L, M, B⋆, σ⋆}, there exist Cm, CL, CM, CB⋆and Cσ⋆> 0 such that m ≥CmN, L ≤CLN, M ≤CMN,
B⋆≤CB⋆N and σ⋆≤Cσ⋆N. Under these assumptions, it is straightforward from (S13) to see that
there exists ¯η > 0 such that ¯γ = ¯η/N. In addition, it follows from (S25) that
B¯γ ≤
2d
CmN 2 (1/Cm + 5¯η)

1 + ¯ηC2
L/(2Cm) + ¯η2C2
L/12

+ 4(ωCB⋆+ C2
σ⋆N)/Cm
+ 4(ω + 1)CLCM

d + ¯η(ωCB⋆+ C2
σ⋆N)

/C2
m .
The proof is concluded by letting N tend towards inﬁnity.
Regarding the speciﬁc instance QLSD# of Algorithm 1, a similar result holds. Indeed, by using
Lemma S10, we can notice that H3-(iii) is veriﬁed with σ⋆= Cσ⋆N for some Cσ⋆> 0 and we can
apply Corollary S20.
S4.2
Asymptotic analysis for Algorithm 2
The following corollary is associated with QLSD⋆deﬁned in Algorithm 2.
Corollary S21. Assume H1, H2 and H4. In addition, assume that lim infN→∞m/N > 0 and
lim supN→∞A/N > 0 for A ∈{L, M}. Then, we have ¯γ = ¯η/N where ¯η > 0 and ¯γ is deﬁned in
(S13). In addition,
B⃝⋆,¯γ = d(ω + 1) O(1) ,
where B⃝⋆,¯γ is deﬁned in (S29).
Proof. Since we assume that lim infN→∞m/N > 0 and lim supN→∞A/N > 0 for A ∈{L, M},
there exist Cm, CL and CM > 0 such that m ≥CmN, L ≤CLN and M ≤CMN. Under these
assumptions, it is straightforward from (S13) to see that there exists ¯η > 0 such that ¯γα = ¯η/N. In
addition, it follows from (S16) that
B⃝⋆,¯γ ≤
2d
CmN 2 (1/Cm + 5¯η)

1 + ¯ηC2
L/(2Cm) + ¯η2C2
L/12

+ 2CLd

ω + (ω + 1) ·
N −n
n(N −1)

¯M/C2
m .
The proof is concluded by letting N tend towards inﬁnity.
32

Lastly, we have the following asymptotic convergence result regarding QLSD++ deﬁned in Algo-
rithm 2.
Corollary S22. Assume H1, H2 and H4. In addition, assume that lim infN→∞m/N > 0 and
lim supN→∞A/N > 0 for A ∈{L, M}. Then, we have ¯γα = ¯η/N where ¯η > 0 and ¯γα is deﬁned in
(S59). In addition,
B⊕,¯γα = d(ω + 1) O(1) ,
where B⊕,¯γα is deﬁned in (S60).
Proof. Since we assume that lim infN→∞m/N > 0 and lim supN→∞A/N > 0 for A ∈{L, M},
there exist Cm, CL and CM > 0 such that m ≥CmN, L ≤CLN and M ≤CMN. Under these
assumptions, it is straightforward from (S59) to see that there exists ¯η > 0 such that ¯γα = ¯η/N. In
addition, it follows from (S60) that
B⊕,¯γα ≤
2d
CmN 2 (1/Cm + 5¯η)

1 + ¯ηC2
L/(2Cm) + ¯η2C2
L/12

+ 8ld
4(N −n)
n(N −1)
¯MCL + 2bC2
M

(3ω + 1)/C2
m .
The proof is concluded by letting N tend towards inﬁnity.
33

