
Advanced Information and Knowledge Processing
Series Editors
Professor Lakhmi Jain
Xindong Wu
Also in this series
Gregoris Mentzas, Dimitris Apostolou, Andreas Abecker and Ron Young
Knowledge Asset Management
1-85233-583-1
Michalis Vazirgiannis, Maria Halkidi and Dimitrios Gunopulos
Uncertainty Handling and Quality Assessment in Data Mining
1-85233-655-2
Asuncio´n Go´mez-Pe´rez, Mariano Ferna´ndez-Lo´pez, Oscar Corcho
Ontological Engineering
1-85233-551-3
Arno Scharl (Ed.)
Environmental Online Communication
1-85233-783-4
Shichao Zhang, Chengqi Zhang and Xindong Wu
Knowledge Discovery in Multiple Databases
1-85233-703-6
Jason T.L. Wang, Mohammed J. Zaki, Hannu T.T. Toivonen and Dennis Shasha (Eds)
Data Mining in Bioinformatics
1-85233-671-4
C.C. Ko, Ben M. Chen and Jianping Chen
Creating Web-based Laboratories
1-85233-837-7
Manuel Gran˜a, Richard Duro, Alicia d’Anjou and Paul P. Wang (Eds)
Information Processing with Evolutionary Algorithms
1-85233-886-0

Colin Fyfe
Hebbian Learning and Negative Feedback Networks
1-85233-883-0
Yun-Heh Chen-Burger and Dave Robertson
Automating Business Modelling
1-85233-835-0
Dirk Husmeier, Richard Dybowski and Stephen Roberts (Eds)
Probabilistic Modeling in Bioinformatics and Medical Informatics
1-85233-778-8
K.C. Tan, E.F. Khor and T.H. Lee
Multiobjective Evolutionary Algorithms and Applications
1-85233-836-9
Ajith Abraham, Lakhmi Jain and Robert Goldberg (Eds)
Evolutionary Multiobjective Optimization
1-85233-787-7

Miroslav Ka´rny´ (Ed.)
with Josef Bo¨hm, Tatiana V. Guy, Ladislav Jirsa, Ivan Nagy, Petr Nedoma, Ludvı´k Tesarˇ
Optimized Bayesian
Dynamic Advising
Theory and Algorithms

Miroslav Ka´rny´, Ing DrSc
Department of Adaptive Systems, Institute of Information Theory and Automation,
Academy of Sciences of the Czech Republic, Prague, Czech Republic
British Library Cataloguing in Publication Data
A catalogue record for this book is available from the British Library
Library of Congress Control Number: 2005923319
Apart from any fair dealing for the purposes of research or private study, or criticism or review, as
permitted under the Copyright, Designs and Patents Act 1988, this publication may only be repro-
duced, stored or transmitted, in any form or by any means, with the prior permission in writing of
the publishers, or in the case of reprographic reproduction in accordance with the terms of licences
issued by the Copyright Licensing Agency. Enquiries concerning reproduction outside those terms
should be sent to the publishers.
AI&KP ISSN 1610-3947
ISBN-10: 1-85233-928-4
ISBN-13: 978-1-85233-928-9
Springer Science+Business Media
springeronline.com
© Springer-Verlag London Limited 2006
The use of registered names, trademarks, etc. in this publication does not imply, even in the absence
of a specific statement, that such names are exempt from the relevant laws and regulations and
therefore free for general use.
The publisher makes no representation, express or implied, with regard to the accuracy of the infor-
mation contained in this book and cannot accept any legal responsibility or liability for any errors
or omissions that may be made.
Typesetting: Electronic text files prepared by editor
Printed in the United States of America
(MVY)
34-543210
Printed on acid-free paper

Miroslav K´arn´y, Josef B¨ohm, Tatiana V. Guy,
Ladislav Jirsa, Ivan Nagy, Petr Nedoma,
Ludv´ık Tesaˇr
Optimized Bayesian Dynamic
Advising
SPIN Springer’s internal project number, if known
Theory and Algorithms
June 22, 2005
Springer
Berlin Heidelberg NewYork
Hong Kong London
Milan Paris Tokyo

This book compiles the results of three years of focused team work.
Such a time span would be too short without a ﬁrm foundation.
We therefore dedicate this text to
V´aclav Peterka, Alena Halouskov´a and Rudolf Kulhav´y
prominent representatives of the Department of Adaptive Systems,
Institute of Information Theory and Automation, Academy of Sci-
ences of the Czech Republic who helped both professionally and
personally with the basis of the presented solution.

Preface
This work summarizes the theoretical and algorithmic basis of optimized prob-
abilistic advising. It developed from a series of targeted research projects sup-
ported both by the European Commission and Czech grant bodies.
The source text has served as a common basis of communication for the
research team. When accumulating and reﬁning the material we found that
the text could also serve as
•
a grand example of the strength of dynamic Bayesian decision making,
•
a practical demonstration that computational aspects do matter,
•
a reference to ready particular solutions in learning and optimization of
decision-making strategies,
•
a source of open and challenging problems for postgraduate students,
young as well as experienced researchers,
•
a departure point for a further systematic development of advanced opti-
mized advisory systems, for instance, in multiple participant setting.
These observations have inspired us to prepare this book.
Prague, Czech Republic
Miroslav K´arn´y
October 2004
Josef B¨ohm
Tatiana V. Guy
Ladislav Jirsa
Ivan Nagy
Petr Nedoma
Ludv´ık Tesaˇr

Contents
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
State of the art . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.2.1
Operator supports . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.2.2
Mainstream multivariate techniques . . . . . . . . . . . . . . . . .
4
1.2.3
Probabilistic dynamic optimized decision-making . . . . . .
6
1.3
Developed advising and its role in computer support . . . . . . . . .
6
1.4
Presentation style, readership and layout . . . . . . . . . . . . . . . . . . .
7
1.5
Acknowledgements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
2
Underlying theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
2.1
General conventions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
2.2
Basic notions and notations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
2.3
Decision making under uncertainty . . . . . . . . . . . . . . . . . . . . . . . . 16
2.3.1
Complete ordering of decision rules . . . . . . . . . . . . . . . . . . 17
2.3.2
Calculus with pdfs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
2.3.3
Basic decision-making lemma . . . . . . . . . . . . . . . . . . . . . . . 24
2.4
Dynamic design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
2.4.1
Dynamic programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
2.4.2
Fully probabilistic design . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
2.4.3
Asymptotic of the design . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
2.5
Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
2.5.1
Bayesian ﬁltration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
2.5.2
Bayesian estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
2.5.3
Asymptotic of estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
3
Approximate and feasible learning . . . . . . . . . . . . . . . . . . . . . . . . . 43
3.1
Estimation with forgetting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
3.2
Exponential family . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
3.3
Structure estimation in the nested exponential family . . . . . . . . 49
3.4
Equivalence approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50

X
Contents
3.4.1
Recursively feasible representation . . . . . . . . . . . . . . . . . . . 51
3.4.2
Approximation as a point estimation . . . . . . . . . . . . . . . . . 53
3.4.3
Speciﬁcation of E[ft(Ψ)|gt] . . . . . . . . . . . . . . . . . . . . . . . . . . 54
4
Approximate design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57
4.1
Adaptive systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57
4.2
Suboptimal design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58
4.2.1
Strategies examining reduced space . . . . . . . . . . . . . . . . . . 58
4.2.2
Strategies simplifying models . . . . . . . . . . . . . . . . . . . . . . . 60
4.3
Decomposition of decision-making . . . . . . . . . . . . . . . . . . . . . . . . . 62
4.3.1
Oﬄine phase. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
4.3.2
Online phase. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
5
Problem formulation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
5.1
Design principle and design conditions . . . . . . . . . . . . . . . . . . . . . 67
5.1.1
Systems and data spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . 68
5.1.2
Basic scenario and design principle . . . . . . . . . . . . . . . . . . 69
5.1.3
Reduction of surplus data of the operator . . . . . . . . . . . . 71
5.1.4
Construction of a true user’s ideal pdf . . . . . . . . . . . . . . . 72
5.1.5
Extension of a true user’s ideal pdf to
the surplus p-data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
5.2
Learning conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74
5.3
Mixtures as approximate models and predictors . . . . . . . . . . . . . 79
5.4
Design of advisory systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82
5.4.1
Types of advisory systems . . . . . . . . . . . . . . . . . . . . . . . . . . 82
5.4.2
Advices as actions of the p-system . . . . . . . . . . . . . . . . . . . 83
5.4.3
Unguided and guided models for respective designs . . . . 84
5.4.4
Academic design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
5.4.5
Industrial design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
5.4.6
Simultaneous academic and industrial design. . . . . . . . . . 88
5.5
Interactions with the operator. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
5.5.1
Assigning priorities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
5.5.2
Stimulating the operator . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
5.6
Design summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92
5.6.1
Inﬂuence of advices on the o-system . . . . . . . . . . . . . . . . . 92
5.6.2
Overall scenario and design subtasks . . . . . . . . . . . . . . . . . 93
6
Solution and principles of its approximation: learning part . 95
6.1
Common tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
6.1.1
Prediction and model selection . . . . . . . . . . . . . . . . . . . . . . 97
6.1.2
Likelihood on variants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98
6.1.3
Branch-and-bound techniques . . . . . . . . . . . . . . . . . . . . . . . 100
6.2
Data preprocessing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
6.2.1
Data transformation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
6.2.2
Outlier removal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104

Contents
XI
6.2.3
Filtering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
6.2.4
Filters generating factors in an exponential family . . . . . 110
6.2.5
Statistics for the exponential family. . . . . . . . . . . . . . . . . . 112
6.2.6
Prediction in EF with statistics gained by ﬁltering . . . . . 113
6.3
Use of prior knowledge at the factor level . . . . . . . . . . . . . . . . . . . 114
6.3.1
Internally consistent ﬁctitious data blocks . . . . . . . . . . . . 114
6.3.2
Translation of input-output characteristics into data . . . 115
6.3.3
Merging of knowledge pieces . . . . . . . . . . . . . . . . . . . . . . . . 117
6.4
Construction of the prior estimate . . . . . . . . . . . . . . . . . . . . . . . . . 120
6.4.1
Iterative construction of the prior pdf . . . . . . . . . . . . . . . . 120
6.4.2
Common bounding mapping . . . . . . . . . . . . . . . . . . . . . . . . 122
6.4.3
Flattening mapping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
6.4.4
Geometric mean as branching mapping . . . . . . . . . . . . . . . 134
6.4.5
Random branching of statistics . . . . . . . . . . . . . . . . . . . . . . 136
6.4.6
Prior-posterior branching . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
6.4.7
Branching by forgetting . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138
6.4.8
Branching by factor splitting. . . . . . . . . . . . . . . . . . . . . . . . 140
6.4.9
Techniques applicable to static mixtures . . . . . . . . . . . . . . 148
6.5
Approximate parameter estimation . . . . . . . . . . . . . . . . . . . . . . . . 154
6.5.1
Quasi-Bayes estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155
6.5.2
EM estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
6.5.3
Batch quasi-Bayes estimation . . . . . . . . . . . . . . . . . . . . . . . 162
6.6
Structure estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164
6.6.1
Estimation of factor structure . . . . . . . . . . . . . . . . . . . . . . . 165
6.6.2
Structure estimation in factor splitting . . . . . . . . . . . . . . . 166
6.6.3
Estimation of component structure . . . . . . . . . . . . . . . . . . 166
6.6.4
Merging and cancelling of components . . . . . . . . . . . . . . . 167
6.7
Model validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184
6.7.1
Test of data homogeneity . . . . . . . . . . . . . . . . . . . . . . . . . . . 185
6.7.2
Learning results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187
6.7.3
Forgetting-based validation . . . . . . . . . . . . . . . . . . . . . . . . . 190
6.7.4
Inspection by a human designer . . . . . . . . . . . . . . . . . . . . . 191
6.7.5
Operating modes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191
7
Solution and principles of its approximation: design part . . 193
7.1
Common tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194
7.1.1
Model projections in design . . . . . . . . . . . . . . . . . . . . . . . . . 194
7.1.2
Dynamic predictors in advising. . . . . . . . . . . . . . . . . . . . . . 197
7.1.3
Advices and their inﬂuence . . . . . . . . . . . . . . . . . . . . . . . . . 199
7.1.4
Fully probabilistic design in advising . . . . . . . . . . . . . . . . . 202
7.1.5
Approximations of the KL divergence . . . . . . . . . . . . . . . . 204
7.2
Design of advising strategies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210
7.2.1
Academic design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210
7.2.2
Choice of user ideal on pointers . . . . . . . . . . . . . . . . . . . . . 217
7.2.3
Industrial design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222

XII
Contents
7.2.4
Simultaneous academic and industrial design. . . . . . . . . . 225
7.3
Interaction with an operator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229
7.3.1
Assigning priorities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229
7.3.2
Stimulating the operator . . . . . . . . . . . . . . . . . . . . . . . . . . . 236
7.4
Design validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241
8
Learning with normal factors and components . . . . . . . . . . . . . 243
8.1
Common tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244
8.1.1
Selected matrix operations. . . . . . . . . . . . . . . . . . . . . . . . . . 244
8.1.2
L′DL decomposition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245
8.1.3
GiW pdf as a conjugate prior . . . . . . . . . . . . . . . . . . . . . . . 251
8.1.4
KL divergence of normal pdfs . . . . . . . . . . . . . . . . . . . . . . . 258
8.1.5
Estimation and prediction with normal factors . . . . . . . . 259
8.1.6
Estimation and prediction with log-normal factors . . . . . 261
8.1.7
Relationships of a component to its factors . . . . . . . . . . . 262
8.1.8
Prediction and model selection . . . . . . . . . . . . . . . . . . . . . . 264
8.1.9
Likelihood on variants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 265
8.1.10 Branch-and-bound techniques . . . . . . . . . . . . . . . . . . . . . . . 265
8.2
Data preprocessing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266
8.2.1
Use of physical boundaries . . . . . . . . . . . . . . . . . . . . . . . . . . 266
8.2.2
Removal of high-frequency noise . . . . . . . . . . . . . . . . . . . . . 266
8.2.3
Suppression of outliers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266
8.3
Use of prior knowledge at the factor level . . . . . . . . . . . . . . . . . . . 266
8.3.1
Internally consistent ﬁctitious data blocks . . . . . . . . . . . . 267
8.3.2
Translation of input–output characteristics into data . . . 267
8.3.3
Merging of knowledge pieces . . . . . . . . . . . . . . . . . . . . . . . . 269
8.4
Construction of the prior estimate . . . . . . . . . . . . . . . . . . . . . . . . . 270
8.4.1
Common bounding mapping . . . . . . . . . . . . . . . . . . . . . . . . 270
8.4.2
Flattening mapping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271
8.4.3
Geometric mean as branching mapping . . . . . . . . . . . . . . . 272
8.4.4
Random branching of statistics . . . . . . . . . . . . . . . . . . . . . . 273
8.4.5
Prior-posterior branching . . . . . . . . . . . . . . . . . . . . . . . . . . . 275
8.4.6
Branching by forgetting . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
8.4.7
Branching by factor splitting. . . . . . . . . . . . . . . . . . . . . . . . 279
8.4.8
Hierarchical and optimization-based splitting . . . . . . . . . 285
8.4.9
Techniques applicable to static mixtures . . . . . . . . . . . . . . 289
8.5
Approximate parameter estimation . . . . . . . . . . . . . . . . . . . . . . . . 289
8.5.1
Quasi-Bayes estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289
8.5.2
EM estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291
8.5.3
Batch quasi-Bayes estimation . . . . . . . . . . . . . . . . . . . . . . . 293
8.6
Structure estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 295
8.6.1
Estimation of factor structure . . . . . . . . . . . . . . . . . . . . . . . 295
8.6.2
Structure estimation in factor splitting . . . . . . . . . . . . . . . 297
8.6.3
Estimation of component structure . . . . . . . . . . . . . . . . . . 298
8.6.4
Merging and cancelling of components . . . . . . . . . . . . . . . 299

Contents
XIII
8.7
Model validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 303
8.7.1
Test of data homogeneity . . . . . . . . . . . . . . . . . . . . . . . . . . . 303
8.7.2
Learning results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305
8.7.3
Forgetting-based validation . . . . . . . . . . . . . . . . . . . . . . . . . 306
8.7.4
Inspection by a human designer . . . . . . . . . . . . . . . . . . . . . 307
8.7.5
Operating modes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307
9
Design with normal mixtures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309
9.1
Common tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 311
9.1.1
Model projections in design . . . . . . . . . . . . . . . . . . . . . . . . . 311
9.1.2
Dynamic predictors in advising. . . . . . . . . . . . . . . . . . . . . . 318
9.1.3
Advices and their inﬂuence . . . . . . . . . . . . . . . . . . . . . . . . . 324
9.1.4
Practical presentation aspects . . . . . . . . . . . . . . . . . . . . . . . 324
9.1.5
Quadratic forms in a fully probabilistic design . . . . . . . . 329
9.2
Design of the advising strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . 338
9.2.1
Academic design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 338
9.2.2
Industrial design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349
9.2.3
Simultaneous academic and industrial design. . . . . . . . . . 356
9.3
Interaction with an operator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 366
9.3.1
Assigning priorities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 366
9.3.2
Stimulating the operator . . . . . . . . . . . . . . . . . . . . . . . . . . . 371
10
Learning with Markov-chain factors and components . . . . . . 377
10.1 Common tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 378
10.1.1 Dirichlet pdf as a conjugate prior . . . . . . . . . . . . . . . . . . . . 378
10.1.2 Estimation and prediction with Markov-chain factors . . 381
10.1.3 Likelihood on variants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 382
10.1.4 Branch-and-bound techniques . . . . . . . . . . . . . . . . . . . . . . . 382
10.2 Data preprocessing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 383
10.2.1 Use of physical boundaries . . . . . . . . . . . . . . . . . . . . . . . . . . 383
10.2.2 Removal of high-frequency noise . . . . . . . . . . . . . . . . . . . . . 385
10.2.3 Suppression of outliers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 385
10.2.4 Coding of regression vectors . . . . . . . . . . . . . . . . . . . . . . . . 385
10.2.5 Coding of signal values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 386
10.3 Use of prior knowledge at the factor level . . . . . . . . . . . . . . . . . . . 387
10.3.1 Internally consistent ﬁctitious data blocks . . . . . . . . . . . . 387
10.3.2 Translation of input-output characteristics into data . . . 387
10.3.3 Merging of knowledge pieces . . . . . . . . . . . . . . . . . . . . . . . . 389
10.4 Construction of the prior estimate . . . . . . . . . . . . . . . . . . . . . . . . . 389
10.4.1 Iterative construction of prior pdf . . . . . . . . . . . . . . . . . . . 390
10.4.2 Common bounding mapping . . . . . . . . . . . . . . . . . . . . . . . . 390
10.4.3 Flattening mapping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 390
10.4.4 Geometric mean as branching mapping . . . . . . . . . . . . . . . 391
10.4.5 Random branching of statistics . . . . . . . . . . . . . . . . . . . . . . 392
10.4.6 Prior-posterior branching . . . . . . . . . . . . . . . . . . . . . . . . . . . 393

XIV
Contents
10.4.7 Branching by forgetting . . . . . . . . . . . . . . . . . . . . . . . . . . . . 396
10.4.8 Branching by factor splitting. . . . . . . . . . . . . . . . . . . . . . . . 397
10.4.9 Hierarchical selection of split factors . . . . . . . . . . . . . . . . . 398
10.4.10Techniques applicable to static mixtures . . . . . . . . . . . . . . 400
10.5 Approximate parameter estimation . . . . . . . . . . . . . . . . . . . . . . . . 400
10.5.1 Quasi-Bayes estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 400
10.5.2 EM estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 401
10.5.3 Batch quasi-Bayes estimation . . . . . . . . . . . . . . . . . . . . . . . 403
10.6 Structure estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 404
10.6.1 Estimation of factor structure . . . . . . . . . . . . . . . . . . . . . . . 404
10.6.2 Estimation of component structure . . . . . . . . . . . . . . . . . . 406
10.6.3 Merging and cancelling of components . . . . . . . . . . . . . . . 406
10.7 Model validation with Markov-chain components . . . . . . . . . . . . 409
10.7.1 Test of data homogeneity . . . . . . . . . . . . . . . . . . . . . . . . . . . 409
10.7.2 Learning results and forgetting-based validation . . . . . . . 410
10.7.3 Other indicators of model validity . . . . . . . . . . . . . . . . . . . 410
11
Design with Markov-chain mixtures . . . . . . . . . . . . . . . . . . . . . . . 411
11.1 Common tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 411
11.1.1 Model projections in design . . . . . . . . . . . . . . . . . . . . . . . . . 411
11.1.2 Basic operations for fully probabilistic design . . . . . . . . . 415
11.1.3 Dangerous components . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 418
11.2 Design of the advising strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . 419
11.2.1 Academic design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 419
11.2.2 Industrial design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 424
11.2.3 Simultaneous academic and industrial design. . . . . . . . . . 427
11.3 Interaction with an operator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 432
11.3.1 Assigning priorities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 432
11.3.2 Stimulating the operator . . . . . . . . . . . . . . . . . . . . . . . . . . . 434
12
Sandwich BMTB for mixture initiation . . . . . . . . . . . . . . . . . . . . 437
12.1 Common tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 438
12.1.1 Properties of the MT factor. . . . . . . . . . . . . . . . . . . . . . . . . 438
12.1.2 KL divergence of MT factors. . . . . . . . . . . . . . . . . . . . . . . . 439
12.1.3 Estimation and prediction with MT factors . . . . . . . . . . . 440
12.2 Conceptual BMTB algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 441
12.3 B-step: preparation of MT parameters . . . . . . . . . . . . . . . . . . . . . 443
12.3.1 Simple choice of box width . . . . . . . . . . . . . . . . . . . . . . . . . 444
12.3.2 Centers and box widths via shadow cancelling. . . . . . . . . 446
12.4 MT step: make the MT algorithm feasible . . . . . . . . . . . . . . . . . . 453
12.4.1 Initialization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 453
12.4.2 Merging and cancelling of centers . . . . . . . . . . . . . . . . . . . . 454
12.4.3 Recognition of a false local maximum . . . . . . . . . . . . . . . . 454
12.4.4 Improved MT algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . 455
12.5 -B step: MT results as initial mixture . . . . . . . . . . . . . . . . . . . . . . 458

Contents
XV
12.5.1 Position and noise covariance . . . . . . . . . . . . . . . . . . . . . . . 458
12.5.2 Remaining statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 458
12.5.3 Conversion of static components to dynamic factors. . . . 458
13
Mixed mixtures. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 463
13.1 Learning with factors on mixed-type quantities . . . . . . . . . . . . . . 464
13.1.1 Factors in EF with a discrete regressor . . . . . . . . . . . . . . . 464
13.1.2 MT normal factors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 465
13.2 An approximate estimation of mixture ratios . . . . . . . . . . . . . . . . 468
13.2.1 Mixture modelling of stationary pdf . . . . . . . . . . . . . . . . . 468
13.2.2 Extended quasi-Bayes estimation . . . . . . . . . . . . . . . . . . . . 470
14
Applications of the advisory system . . . . . . . . . . . . . . . . . . . . . . . 481
14.1 Operation of a rolling mill . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 481
14.1.1 Problem description . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 481
14.1.2 Problem and its solution . . . . . . . . . . . . . . . . . . . . . . . . . . . 483
14.1.3 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 489
14.1.4 Results. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 489
14.1.5 Conclusions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 491
14.2 Treatment of thyroid gland cancer . . . . . . . . . . . . . . . . . . . . . . . . . 492
14.2.1 Problem description . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 492
14.2.2 Problem and its solution . . . . . . . . . . . . . . . . . . . . . . . . . . . 494
14.2.3 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 497
14.2.4 Results. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 498
14.2.5 Conclusions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 499
14.3 Prediction of traﬃc quantities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 499
14.3.1 Problem description . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 499
14.3.2 Problem and its solution . . . . . . . . . . . . . . . . . . . . . . . . . . . 500
14.3.3 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 503
14.3.4 Results. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 504
14.3.5 Conclusions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 505
14.4 Conclusions on the applications . . . . . . . . . . . . . . . . . . . . . . . . . . . 505
14.4.1 Lessons learned . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 505
14.4.2 Other application areas . . . . . . . . . . . . . . . . . . . . . . . . . . . . 506
15
Concluding remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 507
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 511
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 523

1
Introduction
This work summarizes the theoretical and algorithmic basis of optimized prob-
abilistic advising. The proposed tool set will help the user to preserve and
permanently improve the best practice in maintenance of complex systems.
The presented advisory system is intended to support operators of complex
technological processes. The developed probabilistic mining of information
hidden within the acquired data and the subsequent optimization of dynamic
decision-making strategy are, however, applicable elsewhere, for instance, in
medicine, traﬃc control, economy, society, etc.
This introductory chapter
•
characterizes the motivating domain of operator control, Section 1.1,
•
relates the proposed advisory system to the state of the art, Section 1.2,
•
puts the advisory system into a decision support context, Section 1.3,
•
classiﬁes the target readers, usage of the book and its layout, Section 1.4.
1.1 Motivation
The following outline of the original target application clariﬁes the purpose
and applicability domains of the advisory system.
Automation of a production line improves the achieved quality of produc-
tion and decreases its costs. It is applied to increasingly complex production
tasks while exploiting the ever-increasing power of contemporary computers.
The complexity of real-life problems, however, makes optimal global solutions
of these tasks unfeasible. This induces a hierarchically organized automation.
The lowest hierarchical levels deal typically with low-dimensional, but highly
dynamical phenomena. At these levels, the solutions are often used repeatedly.
Thus, it pays to spend substantial energy on a careful modelling and control
(dynamic decision-making) design. This area is nowadays well matured; see,
e.g., [1, 2, 3, 4].

2
1 Introduction
At the upper levels of the hierarchy,
•
addressed design problems become multivariate,
•
(almost) static relationships dominate,
•
a detailed modelling is too expensive to be performed.
The automation of the upper hierarchic levels is far from being stabilized and
substantial research and development eﬀort is focused on it.
The book content falls into this research stream dealing with problems
related to the optimized support of the upper level, where management (both
supervision and maintenance) are carried out by an operator. The importance
of such support follows from the strong inﬂuence of the operator’s perfor-
mance on the resulting product. In spite of the common awareness of this
inﬂuence, the operators are still often insuﬃciently supported when facing
complex situations that require their actions. The performance is predomi-
nantly determined then by the operator’s experience, whose accumulation is
costly, and his personal state, which may vary substantially. Thus, eﬃcient
computer support is badly needed. The decisive features of a good system are
summarized below for reference purposes.
Desirable operator’s support
The operator’s support under consideration should
1. help the operator to follow the best available practice and allow him to
improve it gradually,
2. warn the operator against potential undesirable behavior modes of the man-
aged system and direct his operations in order to achieve the desired state
of the system,
3. enable the operator to cope with large-scale complex problems.
Such support has to avoid excessive eﬀort for development, tailoring and learn-
ing how to use it. Thus, it has to
4. be as generic as possible while allowing simple tailoring to the speciﬁc
problem at hand,
5. keep the knowledge and information load on the operator at a low level,
i.e. provide easy-to-understand advice, ideally in a graphical form.
Conditions for the design of the operator’s support
The operator’s support that guides his actions makes sense if the operator
really inﬂuences the behavior of the managed system. As we have to rely
predominantly on data-based information, this inﬂuence has to be suﬃciently
reﬂected in the available data records.
Each inspected multivariate data record contains a combination of sensor
readings. Under similar working conditions, similar readings of the sensors

1.2 State of the art
3
can be expected. The diﬀerent operating modes can be distinguished if they
are reﬂected in observed data, if diﬀerent clusters of data points arise when
collecting them over a period of time.
We suppose that such clusters exist or, more generally, that the closed
loop — formed by the managed system and operator — exhibits multimodal
behavior.
1.2 State of the art
To our best knowledge none of the existing systems meets the ambitious but
highly desirable requirements formulated above. At the same time, there are a
lot of particular results and tools that have some of the required features. In
fact, the amount of results related to the inspected topic is overwhelming [5].
Even yesterday’s overview is necessarily incomplete and obsolete. The given
reference samples are intended to justify this claim about the lack of such
an advisory system. Moreover, scanning the available results conﬁrms that
consideration of multivariate and dynamic relationships is inevitable. It also
indicates why the Bayesian decision-making paradigm [6] was chosen as the
underlying methodological tool.
1.2.1 Operator supports
Attempts towards meeting industrial technological needs have ranged from
simple expert systems based on acquiring and storing the knowledge and
experiences of the operators [7] to a more systematic approach of knowledge
extraction — labelled as data mining — from process data [8]. With the
construction of expert systems often experiencing bottleneck problems [9] and
with the availability of vast amounts of data, the data mining methods have
started to dominate.
In the industrial sector, statistical process control (SPC) is widely used
whereby control charts such as X, Range and Cumsum charts are indepen-
dently computed for each individual process quantity. Sometimes, the relia-
bility of these charts is questioned [10]. However, their major drawback stems
from the fact that the simultaneously displayed charts are mostly evaluated
visually. This overloads the operators, puts a priori bounds on the feasible
complexity and, to a signiﬁcant extent, hides mutual relationships between
the quantities.
While SPC software manufacturers admit that the multivariate SPC anal-
ysis is yet to be realized, both practical and theoretical attempts have been
made towards it. Scanning of extensive databases reveals that the operator
support is
•
mostly connected with the chemical industry and nuclear power plants
[11],

4
1 Introduction
•
bringing substantial improvements to production [12],
•
oriented usually to highly qualiﬁed operators [13],
•
prepared for applications, where the expensive tuning pays back [14],
•
concerned signiﬁcantly with the abilities of graphical user interface and
software architecture [15], while standard algorithmic toolkits are taken
from neural networks (NN) [16], fuzzy logic [12], multivariate statistics
[17], ﬁltering [18], and partially from artiﬁcial intelligence [19],
•
intended to ﬁnd a balance between centralized and distributed data pro-
cessing [20],
•
interpreted as a blend of
–
integrated information systems [21],
–
computerized operator’s guides [22],
–
fault detection and isolation modules [23],
–
simple and multivariate statistical procedures [24],
–
specialized knowledge-based system [19],
–
tailored combination of grey-box [25] and black box [26] models,
–
multivariate predictors [16],
–
multivariate advanced controllers [27],
–
information ﬁlters and transformers allowing intelligent dialogue [28].
1.2.2 Mainstream multivariate techniques
The need to exploit mutual relationships of the inspected quantities leads us
to the rich area of multivariate data analysis. This has a long tradition [29], a
large number of results and strong persistent research. The latter statements
are illustrated by an incomplete list of common techniques relevant to the
addressed technical aim.
Principal component analysis
Principal component analysis (PCA) [17] dominates among multivariate sta-
tistical techniques used in the given context. Essentially, eigenvalues and eigen-
vectors of the covariance matrix made from data records are analyzed. PCA
serves both for dimensionality reduction and recognition of nonstandard sit-
uations (faults). Novel variants try, for instance,
•
to make data processing robust by eliminating outliers that are known to
signiﬁcantly spoil its results [30],
•
to cope with dynamic character of data [31] by including lagged data
into the data records whose covariance matrix is analyzed; moving-window
PCA [32] is another approach to the same problem,
•
to face multiscale processes requiring adaptive models [33],
•
to combine NN with PCA to grasp nonlinear relationships among data
[34],
•
to support a decentralized treatment of local problems [35].

1.2 State of the art
5
Bayesian versions of PCA are mostly based on functional approximation of
parametric distributions [36] via minimization of the Kullback–Leibler diver-
gence [37]. It provides a guaranteed lower bound on the predictive probability.
For the treated topic, it is important that the idea also be applied in the con-
text of probabilistic mixtures [38].
Neural networks
Modelling of multivariate and dynamic relationships is a speciﬁc case of mod-
elling of multivariate, generally nonlinear, mappings. Neural networks serve as
universal approximations of such mappings [39]. As such, they provide nonlin-
ear black-box dynamic models used in various decision-supporting modules,
for instance, as standards in fault detection or as predictors [16]. They are ex-
tensively used so that their advantages and limitations can be studied on real
cases [40]. Conclusions are cautiously optimistic, reﬂecting the well-known,
but rarely reported instability of results with NN. Speciﬁc tasks related to
NN are permanently studied, for instance,
•
coding of control charts for pattern recognition [22],
•
facing reliability and safety issues under a time stress using blended, NN-
centered, techniques [41].
Clustering, mixtures and local models
The assumed existence of multiple modes of behavior leads naturally to mod-
elling and estimation tools that can cope with them. The NASA stimulated
tool AutoClass [42] is still a prominent example of the implemented algorithm
searching for multiple modes. The concern with initialization [43] together
with structure estimation [44, 45] is the main research topic addressed at
present. The achieved results are interesting but their use in high dimensions
is still very limited.
The descriptive power of multivariate models increases substantially if at
least short-term history of data record is taken into account. To cope with dy-
namics, nonlinear stochastic state-space models and related ﬁltering [46] are
applied to specialized supporting systems. It seems that the general “technol-
ogy” labelled as hidden Markov chains [47] is the most promising direction in
obtaining feasible estimates of models reﬂecting multimodal dynamics. It is
not matured enough yet, but it is expected to bring widely applicable results
after a suﬃciently long development period.
Often, both static and dynamic clusters can be assumed to emerge from
a mixture of normal (Gaussian) multivariate distributions. This observation
has led to the study of normal mixtures [48, 49, 50] and probability density
estimation [51, 52], to name but a few. The established methods of clustering
diﬀer widely across the diverse applications that utilize it, both in interpreta-
tion terms and algorithm design [53, 54, 55, 56, 57, 58].

6
1 Introduction
Use of local models is another emerging area. It searches in extensive
databases of historical records and ﬁts local statistical models to past data
similar to the current ones [59, 60].
1.2.3 Probabilistic dynamic optimized decision-making
The discussed multivariate techniques bring a substantial insight into mutual,
possibly dynamic, relationships among inspected quantities. The extraction
of knowledge from data deﬁnitely helps the operator but it remains an open-
ended story without systematic guidance in the subsequent decision-making.
Thus, the data mining is to be complemented by decision-making theory that
can cope with uncertainty and incomplete knowledge inherent to the addressed
problem. It singles out the framework of Bayesian decision-making [6], [61],
[62] (see also Chapter 2) as the only available theory that has a potential
to make a systematic step towards the optimized advising that meets the
formulated requirements about it. Speciﬁcally (the numbering corresponds
with that used for the particular requirement in Section 1.1):
1. The best available practice can be ﬁxed by basing the optimized advising
on the model learned from historical data. Improvements are reachable
by repetitive batch, or even online, correction of this model followed by
redesign of the advising strategy.
2. Warning against undesirable modes and guiding to desired states can be
reached via dynamic optimization of optional elements in the closed loop
formed by the operator and the managed system.
3. The scale of the feasible problems seems to be of a practical interest, in
spite of the fact that this aspect is still the bottleneck of the approach. It
is, however, partially removed by results of this book.
4. The generic nature is guaranteed when the probabilistic description is
systematically used both in the learning and design part of the advisory
system [63, 64]. The probabilistic description is rather universal and simple
to tailor when the development of the relevant knowledge-transforming
tools, like [65], is not neglected.
5. The knowledge and information load can be controlled by oﬀering the
operator suitable projections of high-dimensional models of the system
and decision strategies. The basic projection operations with probabilities
— conditioning and marginalization — open a straightforward way of
presentation in a low-dimensional, graphically treatable way. The selection
of the shown projections can be optimized, too.
1.3 Developed advising and its role in computer support
The need for an advisory system with the named features, the state of the art
and our know-how resulted in the following ambitious aim.

1.4 Presentation style, readership and layout
7
Design a generic optimized dynamic advising based on black-box modelling
and Bayesian decision-making theory. Simple tailoring to a speciﬁc instance of a
managed system and a permanent adaptation possibility are to be supported. The
oﬀered advices have to be understood by operators who have no background on
the advising principles.
Such a still incomplete but functioning system is described in the book. It
covers both theory and algorithm of probabilistic clustering and subsequent
design of optimal strategies within a uniﬁed framework of data mining and
operator’s guidance.
The adopted probabilistic interpretation of clusters and the probabilistic
design provide a rich set of formal and algorithmic tools that help us to keep
the overall solution internally consistent. The solution tries to capture and
inﬂuence dynamic properties of a good operator. This makes it unique but
rather diﬃcult and speciﬁc. Thus, it is reasonable to exploit the signiﬁcant
overlap with achievements of our predecessors.
The adopted approach relies on black-box modelling. This focus on building
universal data-based models is driven by the problem addressed: the modelled
processes are so complex that grey-box or white-box modelling would be too
expensive. Whenever possible, the grey-box approaches should, however, be
used to complement the advocated approach. They can strengthen it, for
instance, by providing prior “physical” information about parts of the overall
model.
Black-box modelling and feedback control as well as advising rely on the
availability of informative data. In this respect, we have to use information
systems provided by leading ﬁrms specializing in them. Systems of this type
usually care not only about sensor quality but also about the testing and
checking of data integrity. They employ various signal processing and visual-
ization techniques. There is a wide range of commercial products of this type.
Their generality varies but some products integrate the information systems
up to the plant level.
Many ﬁrms and products also support advanced multivariate analysis of
data. Some of them even rely on the Bayesian paradigm adopted here. But
to the best of our knowledge none of them covers uniﬁed data mining and
dynamic optimized advising. Often, they provide tools inherently oriented to
low-dimensional problems.
1.4 Presentation style, readership and layout
This text has arisen from the communication amongst the research team try-
ing to create a uniﬁed, internally consistent, engineering product. The style of
the presentation has been driven by the communication purpose of the text. It
is structured so that developers of particular algorithms and their implemen-
tations can ﬁnd all necessary information in a small subpart of this extensive
text.

8
1 Introduction
Moreover, real implementation requires solution of all minor steps includ-
ing selection of defaults on various optional parameters. It makes us care about
them too in spite of the fact they make the depth of the presentation a bit
unbalanced. This concern with detail helps us also to decrease the number of
manually tuned knobs. This aspect is often overlooked in academic solutions
of complex problems and inhibits a practical use of otherwise sophisticated
solutions. Simply put, it can hardly be expected that users will be willing and
able to tune tens or more such knobs.
Ideally, the text should play its original role by serving as a communication
tool to a virtual research team of readers. Experts on various aspects, including
adjacent research domains, should be able to ﬁnd relatively self-contained
parts pertaining to their interest in order to complement and improve them.
The purpose, the text is expected to serve, dictates presentation style,
which introduces a ﬁne structure via ”agreement/proposition/proof/remark”
framework. This lets the reader focus on speciﬁc topics of interest and use the
rest as a sort of reference.
The solution presented has many aspects that remain to be solved, in-
spected and improved. The most important ones are explicitly formulated
throughout the text as open problems. Consequently, they will not be for-
gotten, and, moreover, they may serve as the basis of typically postgraduate
research projects.
Obviously, this is not a textbook. It may, however, serve as an advanced
text on Bayesian dynamic decision-making and its algorithmic realization.
Chapter 5 provides an example of how to formalize a real-life nontrivial
decision-making problem. General learning techniques are “illustrated” by
non-trivial speciﬁc cases. The design methodology is illustrated similarly. Sam-
ples of real-life applications complete the overall picture.
Methodologically, the text is an example of a successful way of solving an
important complex engineering problem. The solution
•
is developed in a top-down way starting from abstract ideas and formula-
tions — as is usual in advanced mathematics — and is elaborated on in
detailed algorithms — as is usual in engineering;
•
relies on the availability of a team of experts who are able to communicate
with their “neighbors” in a common language.
This style goes against that of traditional education (i.e., bottom-up approach
with individualistic attention on problem grasping and solving). Consequently,
it can be painful reading but it reaches much farther in much shorter time
than usual, and hopefully brings a new quality to the solution found.
We believe that patient readers may beneﬁt much from the material orga-
nized in this way.
The attached disk with examples illustrating the most important and the
most complex aspects of the material presented in the book tries to rectify at
least partially the neglected educational features of the basic text.

1.4 Presentation style, readership and layout
9
Knowledge of standard university courses in matrix algebra, analysis and
elementary probability theory should be suﬃcient for reading the text.
Knowledge of basic statistics and control theory simpliﬁes the reading, but
the text does not rely on it and tries to be as self-contained as possible.
The underlying Bayesian decision-making under uncertainty is discussed
in Chapter 2. The chapter motivates our claim about the unique suitability
of the adopted tool. Furthermore, the vast majority of subproblems solved is
then formulated and solved within the simple structure of this methodology.
Basically, the chapter serves as reference for the basic notions, operations and
results exploited in the text. It can be just brieﬂy scanned and consulted when
necessary.
Chapters 3 and 4 summarize the established results related to algorith-
mic implementation of the Bayesian paradigm. Chapter 3 focuses on learning,
and, Chapter 4 on the design of decision-making strategies. This separation
has been found useful in the presentation and is adopted in subsequent chap-
ters, too. Chapters 3, and 4 can be skipped during the ﬁrst reading and con-
sulted only when need be.
Chapter 5 provides a speciﬁc problem formulation, with extensions nec-
essary for applying the Bayesian decision-making to the construction of the
advisory system. Methodologically, this chapter is central to the book.
General techniques describing algorithmic solution of the learning part of
the advisory system form the content of Chapter 6. Chapters 8 and 10
specialize these techniques for normal (Gaussian) and Markov-chain mixtures,
respectively. These chapters form the basis of the practically implemented ad-
visory system [66]. They serve also as examples of general techniques described
in Chapter 6.
The general solution of the design part of the advisory system is presented
in Chapter 7. Its normal and Markov-chain counterparts are in Chapters 9
and 11. They form the basis of practically implemented advisory system [66].
At the same time, they serve as examples of general techniques proposed in
Chapter 7.
Chapters 5–11 form the core of the book. Chapters dealing with speciﬁc
aspects of the addressed problem complement this core.
Chapter 12 deepens the solution of the vital problem of learning ini-
tialization. At the same time, it improves substantially the so-called mean
tracking (MT) algorithm [67] that was at the birth of the reported research.
Chapter 13 complements information on the treatment of mixed mixtures
that blend models and data of diﬀerent types.
Chapter 14 refers on applications we have been involved in. It
•
illustrates the developed tool set on practical cases,
•
conﬁrms that the created tool is indeed of a generic nature.
Chapter 15 concludes by summarizing the status of the research achieved
and names some problems to be addressed in future.

10
1 Introduction
1.5 Acknowledgements
Any complex research relies on the support of various institutions and persons
who are directly or indirectly involved. We want to conﬁrm that without such
support the present research would be impossible or, at least, its outcomes
would be much weaker.
Institutions
European Commission sponsored the project ProDaCTool IST-99-12058.
GA ˇCR sponsored the projects RECiAS 102/99/1564 and further develop-
ment of the theory within the project GA ˇCR 102/03/0049.
AV ˇCR supported applications of the advisory system by the grants AV ˇCR
S1075351, 1ET100750401.
´UTIA AV ˇCR, University of Reading, Trinity College Dublin, provided in-
stitutional support to the academic ProDaCTool partners and ´UTIA AV
ˇCR supports the further development.
Compureg Plzeˇn s.r.o., Kovohutˇe Rokycany a.s., Department of Nuclear
Medicine, FNM, and Eltodo, a.s. have participated as application part-
ners. They invested their skills, energy, and served us as strong practical-
feedback providers.
People
EC experts: Pekka Karp, Francois Arlabosse, Kauko Leivisk¨a, Colin Pidding-
ton, ˚Asbjorn Rolstadas gave us strong and useful feedback during the
solution of ProDaCTool project.
ProDaCTool team members: (except authors) who contributed informally to
this text are
Dean Parry, Matthew Maisey, Rak Pattel, Kevin Warwick (University of
Reading)
Anthony Quinn, V´aclav ˇSm´ıdl (Trinity College Dublin)
Josef Andr´ysek, Jan Krac´ık, Bohumil Kov´aˇr, Mark´eta Valeˇckov´a, Milan
Tich´y (´UTIA AV ˇCR)
Pavel Ettler, Frantiˇsek Jirkovsk´y, Jaroslav Kˇren, Jiˇr´ı ˇStika and Ivan
Puchr (Compureg Plzeˇn, s.r.o.)
V´aclav Nejdl, Frantiˇsek ˇSulc (Kovohutˇe Rokycany, a.s.)
Jindˇriˇska Heˇrmansk´a, Nenad Medi´c, Petr Vlˇcek, Jaroslav Zim´ak (De-
partment of Nuclear Medicine, University Hospital Motol)
ProDaCTool project co-founders: Elmawatti L. Sutanto and Jiˇr´ı Kadlec who
started the research with us.
Experts: that helped us with speciﬁc problems are Jindˇrich B˚ucha, Jiˇr´ı Grim,
Dani Juriˇci´c, Jozef Nagy, Andrej Rakar, Evgenia Suzdaleva, Jan ˇSindel´aˇr,
Igor Vajda.
Technical support: was provided by Kate Darby, Jiˇr´ı Fidler, Jaroslava Hrad-
cov´a, Roman Kytka, Matthew Taylor.

2
Underlying theory
Decision-making theory should help the decision maker — typically, human
being — to select one of the available options (actions ≡decisions). These
options concern a description of a system (a part of the world) and (or) an
inﬂuence on it.
This chapter summarizes design principles and tools exploited later in our
discussion of a particular decision-making task, i.e., advising to operators of
complex systems.
A similarly formulated design of controllers, which is a speciﬁc decision-
making problem, is in [68]. For a detailed explanation of Bayesian learning
see [69], and our overall view of the complete Bayesian decision-making can
be found in [70].
The chapter starts with conventions and notions used throughout — Sec-
tions 2.1 and 2.2. The framework considered covers a broad range of problems.
Inevitably, the adopted symbols and notions can have speciﬁc meanings in
speciﬁc application ﬁelds. The reader is asked to be patient especially in this
respect.
The adopted principle of optimal decision making under uncertainty, in-
spected in Section 2.3, implies that incomplete knowledge and randomness
have the same operational consequences for decision-making. They should be
treated in the same way, labelled as Bayesian decision making. In the same
section, the design of optimal decision rules is presented.
In Section 2.4 the design of the optimal strategies is derived. The design
works with models that are obtained through Bayesian learning described in
Section 2.5.
2.1 General conventions
The conventions listed here are mostly followed in this work. If some exception
is necessary it is introduced at the place of its validity. If some verbal notions
are introduced within Propositions, Remarks, etc., then they are emphasized.

12
2 Underlying theory
Moreover, they appear in the Index. Sometimes, important parts of sentences
are stressed by underlining them.
f is the letter reserved for probability (density) functions (p(d)f).
The meaning of the p(d)f is given through the name of its argument.
x∗denotes the range of
x, x ∈x∗.
˚x denotes the number of members in the countable set
x∗or the number of
entries in the vector x.
≡means the equality by deﬁnition.
xt is a quantity x at the discrete time instant labelled by t ∈t∗≡{1, . . . ,˚t}.
˚t ≤∞is called (decision, learning, prediction, control, advising) horizon.
xi;t is an ith entry of the array x at time t.
The semicolon in the subscript stresses that the symbol following it is a
time index.
x(k · · · l) denotes the sequence xk, . . . , xl, i.e., x(k · · · l) ≡xk, . . . , xl for k ≤l.
x(k · · · l) is an empty sequence and reﬂects just the prior information if l < k
x(t) ≡x(1 · · · t) ≡x1, . . . , xt is the sequence from the initial time moment till
time instance t.
xk···lc ≡xkc···lc denotes the sequence xkc, . . . , xlc.
supp [ f(x)] is the support of the pdf f : x∗→[0, ∞], i.e., the subset of x∗on
which f(x) > 0.
\ is the set subtraction or an omission of a term from a sequence.
Agreement 2.1 (Interface of decision making and reality)
Physical connections of the decision-making elements to the real world —
sensors, transmission lines, actuators, etc. — are taken here as a part of
the physical system dealt with. Consequently, all considered quantities and
mappings are mathematical entities living in an abstract calculating machine.
2.2 Basic notions and notations
The notions introduced here specify elements occurring in dynamic decision-
making; see Fig. 2.1.
A brief characterization of the introduced notion is complemented by ex-
planatory comments.
Quantity is a multivariate mapping.
The domain and form of the quantity are mostly unused and unspeciﬁed.
The introduced notion corresponds with random variable used in proba-
bility theory. The use of the alternative term should stress that probability
serves us as the tool adopted for decision-making under uncertainty. The
term “quantity” stresses our orientation on numerical values that arise
mostly by observing physical quantities. However, quantities with a dis-
crete range that do not need numerical meaning are also considered.

2.2 Basic notions and notations
13
communication leading to 
acceptable feasible design 
external influence
SYSTEM:
part of the World that is of interest; includes sensors and actuators
DESIGN: 
offline or online transformation of experience, 
aims and constraints to strategy and system model 
taken from a set “indexed” by internal quantities 
algorithm 
observed data 
actions=decisions 
STRATEGY: 
mapping of nondecreasing experience on actions 
DESIGNER 
theory, algorithms, software 
and designer experience 
aims, constraints and expert 
(application domain) knowledge 
USER
Fig. 2.1. Basic decision-making scenario and notions used.
Realization is a value of the quantity for its ﬁxed argument.
Often, the quantity and its realization are not distinguished. The proper
meaning is implied by the context.
Decision maker is a person or mechanism who has to select among several
options called decisions or actions.
A group of persons or mechanisms may form a single decision maker.
System is the part of the world that is of interest for a decision maker who
should either describe or inﬂuence it.

14
2 Underlying theory
The system is speciﬁed with respect to the aim that the decision maker
wants to reach and with respect to the tools the decision maker has avail-
able. In other words, the penetrable boundaries of the system are implied
by the decision task.
Decision ≡Action a ∈a∗is the value of a quantity that can be directly chosen
by the decision maker for reaching decision-maker’s aims.
The terms “decision” and “action” are here used as synonyms.
A decision task arises iﬀthere are several options available, i.e., iﬀ˚a > 1.
(Decision) experience Pa∗∈P∗
a∗is knowledge about the system available to
the decision maker for the selecting the decision a ∈a∗.
For example, if just data values D are available for constructing the esti-
mate ˆΘ of an unknown quantity Θ ∈Θ∗then the experience is P ˆ
Θ∗≡D.
Often, experience includes the past data observed.
(Decision) ignorance Fa∗∈F∗
a∗is knowledge about the system unavailable to
the decision maker for the choice of the decision a ∈a∗.
An estimated quantity Θ belongs to the ignorance F ˆ
Θ∗of the estimate ˆΘ.
Often, ignorance contains future, still unobserved data.
(System) behavior Q∗consists of all possible realizations (of trajectories) Q,
i.e., values of all quantities considered by the decision maker within the
time span determined by the horizon of interest and related to the system.
Any decision a ∈a∗splits each realization Q into the corresponding ex-
perience Pa∗and ignorance Fa∗. Formally, Q = (Pa∗, a, Fa∗). A single
realization Q splits diﬀerently with respect to decisions a ∈a∗, ˜a ∈˜a∗
with diﬀerent experience Pa∗̸= P˜a∗and, consequently, diﬀerent ignorance
Fa∗̸= F˜a∗. Q = (Pa∗, a, Fa∗) = (P˜a∗, ˜a, F˜a∗).
(System) input u ∈u∗is a decision, which is supposed to inﬂuence the igno-
rance part Fu∗of the (system) behavior.
For instance, a manipulated valve position inﬂuencing a ﬂuid ﬂow is the
(system) input. On the other hand, an estimate ˆΘ of an unknown (real-
ization of) quantity Θ is an instance of the decision that is not the input.
The estimate describes the system but has no direct inﬂuence on it.
(System) output y ∈y∗is an observable quantity that provides the decision
maker information about the (system) behavior.
To be or not to be output or input is a relative property. The input is
always directly manipulated. For instance, a pressure measured in a heated
system is an instance of the output. A pressure applied to the system is
an instance of the input.
Innovation ∆t ∈∆∗
t contains quantities included in the ignorance Fa∗
t and in
Pa∗
t+1 \ at.
Often, ∆t = yt = the system output at time t.
Decision rule R : Q∗→a∗is a mapping that assigns a decision a ∈a∗to the
behavior Q ∈Q∗.
Causal decision rule R : P∗
a∗→a∗is a mapping that assigns the decision
a ∈a∗to its experience Pa∗∈P∗
a∗.

2.2 Basic notions and notations
15
In other words, the decision a made by a causal decision rule is uninﬂu-
enced by the related ignorance Fa∗. We deal with the causal decision rules
so that the term “causal” is mostly dropped. Estimator is an instance of
the causal decision rule R : P∗
ˆ
Θ∗→ˆΘ∗that assigns an estimate ˆΘ of the
unknown quantity Θ ∈Θ∗to the available experience P ˆ
Θ∗.
Strategy is a sequence of decision rules {Rt : Q∗→a∗
t }t∈t∗.
Causal strategy {Rt : P∗
a∗
t →a∗
t }t∈t∗is a sequence made of causal decision
rules.
Again, we deal with causal strategies so that the term “causal” is mostly
dropped.
Controller is a causal strategy assigning inputs ut to experience Pu∗
t , ∀t ∈t∗.
For instance, the controller given by the proportionality constant C is an
example of the causal control strategy {y∗
t−1 →u∗
t : ut = −Cyt−1}t∈t∗if
y∗
t−1 ⊂Pu∗
t . The same controller is not causal if, for instance, Pu∗
t = ∅.
Design selects the decision rule or strategy.
The design selecting a single rule is called static design. The choice of
the strategy is called dynamic design. The person (group) who makes the
selection is the designer. Authors and readers of this text are supposed
to be designers. In that sense, the term we used within the text should
mostly be read: we designers. The designers work for the users whose aims
should be reached by using the strategy designed.
Uncertain behavior (related to static design) is a behavior whose realizations
Q can be decomposed into
•
QR ≡the part that is unambiguously determined by the considered
decision rule R ∈R∗,
•
uncertainty Υ that is deﬁned as the part of the behavior that belongs
to the ignorance FR∗(P) of decisions R(P) generated by the admissible
rules R ∈R∗and uninﬂuenced by them, even indirectly.
With an abuse of notation, we write the corresponding decomposition of
the realization Q = (QR, Υ). By deﬁnition, incomplete knowledge of (the
realization of) a considered quantity Θ ∈Θ∗makes the behavior uncer-
tain. Also, external unobserved noise inﬂuencing the system makes its
behavior uncertain.
Uncertainty expresses both incomplete knowledge and randomness. Uncer-
tain behavior related to dynamic design is encountered if any of its rules
faces uncertainty.
Decision-making means design and application of a decision rule (strategy).
Admissible strategy is a strategy {Rt}t∈t∗that
•
is causal, i.e., {Rt}t∈t∗≡{Rt : P∗
a∗
t →a∗
t }t∈t∗and
•
meets physical constraints, i.e., the ranges of its decision rules are in
prespeciﬁed subsets of respective sets of decisions.
Loss function, Z : Q∗→[0, ∞], quantiﬁes the degree of achievement of the
design aim.
The loss function measures the quality of the realizations Q. The smaller
the value of Z(Q) is, the better. The loss function orders indirectly, but

16
2 Underlying theory
only partially, admissible strategies inﬂuencing the behavior. Those lead-
ing to the smaller loss are taken as better ones. The important case of
multivalued loss function [71] is beyond the scope of this text, but the ap-
proach discussed in Section 2.3 could be relatively simply extended to the
case by embedding the index of entries of the loss values into uncertainty.
“Expected” loss ˜E(Z) ≡˜ER(Z) assigns to the considered loss function Z and
strategy R a value in [0, ∞]. The value is to be independent of the realiza-
tion of the involved uncertainty.
The quotation marks and the sign ˜ are used temporarily. They serve us
in the discussion, which shows that, under widely acceptable conditions,
we have to deal with expectation in a mathematical sense. Then they are
not used any more.
Optimal design selects an admissible strategy that leads to the smallest value
of the “expected” loss function.
Practically admissible strategy is an admissible strategy that respects con-
straints limiting the complexity of the decision-making.
The complexity is considered with respect to the computational resources
available at the design and application stages. The majority of discussed
problems in which the complexity constraints play a role are computa-
tionally hard in terms of computer sciences. An intuitive understanding
of the computational complexity is suﬃcient to our purposes.
Practically optimal design selects a practically admissible strategy giving the
smallest values of the “expected” loss.
The presented optimal design provides optimal admissible strategies and
can be simply adapted to provide strategies of a prespeciﬁed complexity
by optimizing over a set of simple decision rules, for instance, over pro-
portional controllers only. Operational formal tools for practically optimal
design are not available. It is not known how to make the optimal design of
a prespeciﬁed complexity.
We never know whether the selection of the constant determining propor-
tional controller made with use of, say, ten algebraic operations is really
the best one possible among all selections that are allowed to perform
ten algebraic operations. This is the main barrier of the applicability of
the theory describing the optimal design. The optimal design becomes
a practical tool by employing sound engineering heuristics. The practi-
cal optimum is not guaranteed. This fact is stressed by using the term
suboptimal design giving suboptimal strategy.
2.3 Decision making under uncertainty
Here, we describe a general way how to understand and face uncertainty that
causes incomplete ordering of strategies. In order to avoid a cumbersome nota-
tion, we formulate the adopted design principle, related requirements and their

2.3 Decision making under uncertainty
17
consequences for the static design, i.e., the design of a single, not necessar-
ily causal, decision rule. The obtained conclusions apply also to the dynamic
design, i.e., to the choice of decision strategies.
Agreement 2.2 (Uncertainty in decision making)
Decision making
under uncertainty arises if the optimal decision-making is to be performed and
•
at least a pair of diﬀerent decisions can be made, ˚a > 1,
•
the considered loss function Z(Q) ≡Z(QR, Υ) depends on a non-void set
Υ ∗of uncertainties.
The loss ZR(Υ) ≡Z(QR, Υ) is a function of uncertainty Υ, i.e., that part of
the realization belonging to ignorance and being uninﬂuenced by the rule R.
The function ZR(·) is assigned to each considered decision rule R ∈R∗≡set
of admissible rules. The set of such functions is denoted ZR∗
ZR∗≡{ZR : Υ ∗→[0, ∞], ZR(Υ) ≡Z(QR, Υ)}R∈R∗.
(2.1)
Under uncertainty, the loss function is insuﬃcient for a complete ordering
(comparing) of admissible rules in spite of the fact that its values are in
the fully ordered interval: due to the uncertainty, not a single number but a
function on the set (2.1) is assigned to each decision rule R.
For instance, let two estimators give a pair of estimates ˆΘ1 ̸= ˆΘ2 of an
unknown scalar quantity Θ ∈Θ∗≡(−∞, ∞). The better one cannot be
unambiguously chosen using the quadratic loss function (Θ −ˆΘ)2: we do not
know whether Θ ∈F ˆ
Θ∗is in that part of Θ∗where (Θ −ˆΘ1)2 ≤(Θ −ˆΘ2)2
or in its complement.
2.3.1 Complete ordering of decision rules
This section inspects conditions under which the compared decision rules can
be completely ordered. The adopted conditions try to make the ordering as ob-
jective as possible, i.e., as little dependent as possible on the subject ordering
them.
Any systematic choice of an optimal decision rule can be reduced to the
following principle.
Agreement 2.3 (“Expectation”-minimization design principle)
•
A functional ˜ER, called “expectation”, is selected by the designer. It as-
signs to functions in (2.1) — determined by the loss function Z and com-
pared decision rules R ∈R∗— an “expected loss” ˜ER[Z]
˜ER : ZR∗→[0, ∞].
(2.2)
•
The minimizer of ˜E[ZR] ≡˜ER[Z(QR, Υ)] found in R∗is taken as the
optimal decision rule.

18
2 Underlying theory
The outcome of this design depends on the “expectation” ˜ER. Its choice has
to at least guarantee that unequivocally bad rules are avoided. Such bad rules
are identiﬁed here.
Agreement 2.4 (Dominated rules; strictly isotonic expectation) Let
a loss function Z measure the quality of the behavior. The decision rule
R : Q∗→a∗is called
dominated iﬀ(if and only if) there is another de-
cision rule ˜R : Q∗→a∗such that
ZR(Υ) ≥Z ˜
R(Υ) ⇔Z(QR, Υ) ≥Z(Q ˜
R, Υ), ∀Υ ∈Υ ∗.
(2.3)
The decision rule is called strictly dominated iﬀthere is a nontrivial subset
of Υ ∗on which the inequality (2.3) is strict.
The “expectation” ˜ER (2.2) is said to be strictly isotonic if for a decision
rule R, strictly dominated by a decision rule ˜R, it holds
˜ER[ZR] > ˜E ˜
R[Z ˜
R].
We take the dominated decision rules as those to be surely avoided.
Requirement 2.1 (Inadmissibility of strictly dominated rules) The
considered “expectation”-minimization design, Agreement 2.3, must not lead
to a strictly dominated decision rule.
The “expectation” ˜ER allows us to order the decision rules in spite of the
inﬂuence of uncertainty. Thus, it characterizes uncertainty and neither the
ordered set of decision rules nor the speciﬁc loss function Z. Consequently, in
the quest for objectivity of the constructed complete ordering, the “natural”
requirement on the “expectation” ˜ER can be formulated as follows.
Requirement 2.2 (Independence of R∗) The design, Agreement 2.3, with
the chosen “expectation” must not take a strictly dominated rule as the opti-
mal one (i.e., must meet Requirement 2.1) even if the set of possible decision
rules R∗is reduced to its nontrivial subset.
A subset of R∗is taken as nontrivial if it contains at least two diﬀerent
rules while at least one of them gives a ﬁnite “expected” loss.
Proposition 2.1 (Isotonic ordering) Assume that there is a rule in R∗
for which the “expected” loss is ﬁnite. Then, Requirement 2.2 is fulﬁlled iﬀ
the “expectation” is strictly isotonic; see Agreement 2.4.
Proof.
1. We prove by contradiction that — with strictly isotonic “expectation”
˜ER — the minimizer cannot be strictly dominated. Let ˜ER[Z] be strictly
isotonic on its domain ZR∗(2.2) and Ro ∈R∗be a minimizer of the
“expected” loss. The minimizer gives necessarily a ﬁnite value of the cor-
responding ˜ER[Z]. Let Rd ∈R∗dominate it strictly. Then, because of the

2.3 Decision making under uncertainty
19
construction of Ro, the strict dominance and strictly isotonic nature of
˜ER, we get the following contradictory inequality
˜ERo[Z(QRo, Υ)]
≤

minimum
˜ERd[Z(QRd, Υ)]
<

strictly isotonic
˜ERo[Z(QRo, Υ)].
2. We prove by contradiction that use of an “expectation” ˜ER that is not
strictly isotonic leads to violation of Requirement 2.1 when Requirement
2.2 holds. If ˜ER[Z] is not strictly isotonic on its domain ZR∗(2.2) then
there is a rule R1 ∈R∗strictly dominated by the decision rule Rd ∈R∗
such that
˜ERd[Z(QRd, Υ)] ≥˜ER1[Z(QR1, Υ)].
If we restrict the set of decision rules R∗to the pair {Rd, R1} then R1 can
always be taken as the optimal decision rule. Thus, under Requirement
2.2, Requirement 2.1 is not met with the “expectation” ˜ER.
Requirement 2.2 guarantees suitability of the “expectation” to a wide range
of decision rules. It remains to guarantee that the “expectation” ˜ER serves as
an objective tool for ordering strategies for any loss function Z from a rich
set Z∗.
We adopt rather technical conditions on the set Z∗. Essentially, applica-
bility to a very smooth functions and a restricted version of “linearity” of ˜ER
are required.
Requirement 2.3 (Independence of loss function) Let us consider vari-
ous loss functions Z ∈Z∗. The “expectation” ˜E acts on the union Z∗
R∗of the
sets of functions ZR∗(2.1) with a common uncertainty set Υ ∗
Z∗
R∗≡∪Z∈Z∗ZR∗.
(2.4)
The set Z∗
R∗is required to contain a subset of test loss functions. The test
functions are zero out of a compact nonempty subset Ωof Υ ∗and continuous
on Ω(supremum norm deﬁnes the corresponding topology).
The “expectation” is assumed to be an isotonic, sequentially continuous,
and uniformly continuous functional on Z∗
R∗. It is, moreover, additive on loss
functions with nonoverlapping supports
˜E[Z1 + Z2] = ˜E[Z1] + ˜E[Z2] if Z1Z2 = 0, Z1, Z2 ∈Z∗
R∗.
Technical Requirement 2.3 allows us to get an integral representation of
the “expectation” searched for. Its proof, as well as deﬁnitions of the adopted
noncommon terms, can be found in Chapter 9 of the book [72]; see Theorem
5 there.

20
2 Underlying theory
Proposition 2.2 (Integral form of “expectation”) Under Requirement
2.3, the “expectation” ˜E has the form
˜E[Z] =

Ω
U(Z(Υ), Υ) µ(dΥ),
where
(2.5)
µ is a ﬁnite regular nonnegative Borel measure on Ω. The utility function U
satisﬁes U(0, Υ) = 0. It is continuous in values of Z(·) almost everywhere
(a.e.) on Ω, bounded a.e. on Ωfor each Z in the set of the test loss functions.
Remark(s) 2.1
1. The test loss functions are widely applicable and their consideration im-
plies no practical restriction. The continuity requirements on ˜E are also
widely acceptable.
2. The linearity of ˜E on functions with nonoverlapping support seems to be
sound. Any loss function Z ∈Z∗
R∗can be written as Z = Zχω + Z(1 −
χω) ≡Z1 +Z2, Z1Z2 = 0 with χω denoting an indicator of a set ω ⊂Ω⊂
Υ ∗. The indicator χω equals 1 on ω and it is zero outside of it.
The loss “expected” on the set ω and its complement should sum to the
loss “expected” on the whole set of arguments.
3. The utility function U allows the designer to express his/her attitude to-
ward the design consequences: the decision maker might be risk aware, risk
prone, or risk indiﬀerent [71].
4. The utility function U and the nonnegative measure µ are universal for the
whole set of test functions. U and µ are (almost) “objective”, i.e., suitable
for a wide range of decision tasks facing the same uncertainty.
We formulate now our ﬁnal objectivity-oriented requirement. Hereafter,
we use the fact that the behavior Q is uniquely determined by the decision
rule R and uncertainty Υ. Thus, we can work with the nonreduced behavior
Q without explicit separation of the uncertainty Υ.
Requirement 2.4 (Indiﬀerence of the designer)
•
The designer is risk indiﬀerent, which means that U(Z(·), ·) = Z(·).
•
The “expectation” preserves any constant loss ˜E[constant] = constant.
•
The involved measure µ has Radon–Nikod´ym derivative f(Q) with respect
to a dominating measure denoted dQ, [72]. In the treated cases, dQ is
either Leb`esgue or counting measure.
Adopting Requirement 2.4, we get the basic representation Proposition that
introduces objective expectation.
Proposition 2.3 (Objective expectation) Under Requirement 2.4,
the “expectation” ˜E (2.5) is formally identical with a mathematical expecta-
tion. The Radon–Nikod´ym’s derivative f has all the properties of the joint
probability (density) function (p(d)f) on Q∗.

2.3 Decision making under uncertainty
21
Proof. It is suﬃcient to observe that the preservation of constants implies
that µ is a probabilistic measure, i.e., µ ≥0, µ(Q∗) = 1.
Remark(s) 2.2
1. The (mathematical) “expectation” is singled out by dropping the sign ˜ as
well as the quotation symbols “ ”
E[Z] ≡

Z(Q)f(Q) dQ.
(2.6)
2. The ﬁrst item in Requirement 2.4 has clear meaning: objective, emotion-
ally indiﬀerent, designers are supported here.
3. The last item in Requirement 2.4 is unnecessary but it helps us to deal
with simpler objects, namely, with probability density functions (pdf) or
probability functions (pf).
4. The pdf deﬁning the objective expectation is referred to as the objective
pdf.
5. Mostly, we use notation related to pdfs even to pfs. Only when necessary,
we underline that we deal with a pf and write integrals as sums.
6. We have arrived to the unconditional expectation. Its values are inde-
pendent of the uncertainty realization and are determined by our prior
experience only. When dealing with dynamic design, the observed part of
the realization becomes a part of experience. The uncertainty changes with
changing experience. Consequently, we always deal with conditional ex-
pectation E[•|available experience]. Rigorous deﬁnition of the conditional
expectation can be found in [72]. Here, it is treated in a naive way as the
integral

•(α)f(α|available experience) dα weighted by the conditional pdf
f(α|available experience).
2.3.2 Calculus with pdfs
The joint pdf f on Q ≡(α, β, γ) is analyzed and synthesized using several
pdfs related to it. Let us recall the meaning of pdfs derived from f(Q).
Agreement 2.5 (Nomenclature of pdfs; Independence)
Basic pdfs dealt with are
Name
Meaning
joint pdf f(α, β|γ) of α, β
conditioned on γ
a pdf on (α, β)∗restricting f(Q) on the cross-
section of Q∗given by a ﬁxed γ
marginal pdf f(α|γ) of α
conditioned on γ
a pdf on α∗restricting f(Q) on the cross-section
of Q∗given by a ﬁxed γ with no information on
β
marginal pdf f(β|α, γ) of β
conditioned on α, γ
a pdf on β∗restricting f(Q) on the cross-section
of Q∗given by a ﬁxed α, γ
The conditioning symbol | is dropped if just trivial conditions are considered.

22
2 Underlying theory
The pdf f(α, β) is the lower dimensional joint pdf of the pdf f(α, β, γ) and
f(β) is its marginal pdf. Quantities α and β are conditionally independent
under the condition γ iﬀ
f(α, β|γ) = f(α|γ)f(β|γ).
(2.7)
Our manipulations with the introduced pdfs rely on the following calculus.
Proposition 2.4 (Calculus with pdfs) For any (α, β, γ) ∈(α, β, γ)∗, the
following relationships between pdfs hold.
Non-negativity
f(α, β|γ), f(α|β, γ), f(β|α, γ), f(β|γ) ≥0.
Normalization

f(α, β|γ) dαdβ =

f(α|β, γ) dα =

f(β|α, γ) dβ = 1.
Chain rule
f(α, β|γ) = f(α|β, γ)f(β|γ) = f(β|α, γ)f(α|γ).
Marginalization
f(β|γ) =

f(α, β|γ) dα, f(α|γ) =

f(α, β|γ) dβ.
Bayes rule
f(β|α, γ) =
= f(α|β, γ)f(β|γ)
f(α|γ)
=
f(α|β, γ)f(β|γ)

f(α|β, γ)f(β|γ) dβ ∝f(α|β, γ)f(β|γ).
(2.8)
The proportion sign, ∝, means that the factor, independent of β and
uniquely determined by the normalization, is not explicitly written in the equal-
ity represented.
The conditional independence (2.7) can be expressed equivalently
f(α, β|γ) = f(α|γ)f(β|γ) ⇔f(α|β, γ) = f(α|γ) or f(β|α, γ) = f(β|γ).
(2.9)
Proof. For motivation see [69], a more precise and more technical treatment
exploits the measure theory [72]. Technically, an intermediate insight can be
gained by considering loss functions dependent only on a part of Q or with
some parts of Q “ﬁxed by the condition”, [68].
Remark(s) 2.3
1. Alternative presentations of formulas stress their symmetry.
2. The technically correct statements that the identities, like (2.9), are valid
only almost everywhere is mostly omitted in the subsequent explanations.
3. The Bayes rule (2.8) is a simple consequence of previous formulas. Its
importance in this text cannot be exaggerated, cf. Propositions 2.13, 2.14.
4. The symmetric identities (2.9) say that β does not inﬂuence the descrip-
tion of α (and vice versa) if α and β are conditionally independent for a
given γ.
Often, we need the pdf of a quantity β that is the image of other multivari-
ate quantity α, i.e., T : α∗→β∗≡T(α∗), whose pdf is known. The desired
pdf is found by simply respecting the need to preserve the expectation.

2.3 Decision making under uncertainty
23
Proposition 2.5 (Pdfs of transformed quantities)
Let the expectation
ET , acting on functions B : β∗→(−∞, ∞), be speciﬁed by the pdf fT (β), i.e.
ET [B] =

B(β)fT (β) dβ.
Then, this functional expresses the same expectation as
E[B] =

B(T(α))f(α) dα
iﬀ

T (A)
fT (T(α)) dT(α) =

A
f(α) dα,
(2.10)
for all measurable sets A ⊂α∗.
Let α be a real vector , α ≡[α1, . . . , α˚
α] and T = [T1, . . . , T˚
α] bijection
(one-to-one mapping) with ﬁnite continuous partial derivatives a.e. on α∗
Jij(α) ≡∂Ti(α)
∂αj
, i, j = 1, . . . ,˚α,
(2.11)
for all entries Ti of T and entries αj of α. Then,
fT (T(α))|J(α)| = f(α),
where
(2.12)
| · | denotes absolute value of the determinant of the matrix in its argument.
Proof. Proposition describes substitutions in multivariate integrals; see, for
instance, [72, 73].
It is useful to summarize basic properties of expectation, which help us to
simplify formal manipulations. Its conditional version E[·|γ] is considered. For
this text, it is suﬃcient to take it in a naive way as an integral weighted by
the conditional pdf f(·|γ). The textbook [72] can be consulted for a rigorous
treatment.
Proposition 2.6 (Basic properties of E) For arbitrary functions Z1(·),
Z2(·) on which the conditional expectation E[·|γ] is well deﬁned, E[·|γ] has
the following properties.
Isotonic nature of E[·|γ]:
Z1 ≤Z2, cf.(2.3), ⇒E[Z1|γ] ≤E[Z2|γ].
Linearity of E[·|γ]:
E[A(γ)Z1+B(γ)Z2|γ] = A(γ)E[Z1|γ]+B(γ)E[Z2|γ]
for arbitrary coeﬃcients A, B depending at most on the condition γ.
Chain rule for expectation: E [E[·|γ, ζ]|γ] = E[·|γ] for an arbitrary additional
condition ζ.
Conditional covariance of a vector α cov[α|γ] ≡E [(α −E[α|γ])(α −E[α|γ])′|γ]
is related to the noncentral moments through the formula
cov[α|γ] = E[αα′|γ] −E[α|γ]E[α′|γ],
′ is transposition.
(2.13)

24
2 Underlying theory
Jensen inequality bounds expectation of a convex function Tγ : α∗→(−∞, ∞)
E[Tγ(α)|γ] ≥Tγ (E[α|γ]) .
(2.14)
Proof. All statements can be veriﬁed by using the integral expression (2.6) of
the expectation. Proof of the Jensen inequality can be found, e.g., in [74].
Remark(s) 2.4
1. The proposition is formulated for the conditional expectation. The uncon-
ditional case is formally obtained by omitting the condition used.
2. Note that whenever the expectation is applied to an array function V it
should be understood as the array of expectations [E(V )]i ≡E(Vi).
2.3.3 Basic decision-making lemma
The optimal choice of admissible decision rules relies on the key proposition
that reduces minimization over mappings to an “ordinary” minimization.
Proposition 2.7 (Basic decision-making lemma) The optimal admissi-
ble decision rule ⌊oR
⌊oR(Pa∗) ≡⌊oa(Pa∗), ∀Pa∗∈P∗
a∗
minimizing the expected loss (2.6) can be constructed valuewise as follows.
To each Pa∗∈P∗
a∗, a minimizing argument ⌊oa(Pa∗) in
min
a∈a∗E[Z(Pa∗, a, Fa∗)|a, Pa∗]
(2.15)
is assigned as the value of the optimal decision rule corresponding to the con-
sidered argument. The minimum reached is
min
{R: P∗
a∗→a∗} E[Z(Pa∗, a, Fa∗)] = E

min
a∈a∗E[Z(Pa∗, a, Fa∗)|a, Pa∗]

.
(2.16)
Proof. Let us ﬁx an arbitrary Pa∗∈P∗
a∗. The deﬁnition of minimum implies
that for all a ∈a∗
E
	
Z

Pa∗, ⌊oR(Pa∗), Fa∗

| ⌊oR(Pa∗), Pa∗

≤E[Z(Pa∗, a, Fa∗)|a, Pa∗].
Let an admissible rule R : P∗
a∗→a∗assign a decision a ∈a∗to the considered
Pa∗. Then, the previous inequality can be written
E[Z(Pa∗, ⌊oR(Pa∗), Fa∗)| ⌊oR(Pa∗), Pa∗]
≤E[Z(Pa∗, R(Pa∗), Fa∗)|R(Pa∗), Pa∗].
Let us apply unconditional expectation E[·] acting on functions of Pa∗to this
inequality. Due to the isotonic nature of E[·], the inequality is preserved. The

2.4 Dynamic design
25
the chain rule for expectations — see Proposition 2.6 — implies that on the
right-hand side of the resulting inequality we get the unconditional expected
loss corresponding to an arbitrarily chosen R : P∗
a∗→a∗. On the left-hand
side the unconditional expected loss for ⌊oR arises. Thus, ⌊oR that assigns to
each Pa∗∈P∗
a∗the decision ⌊oa(Pa∗) is the optimal decision rule.
The proposition and its proof imply no preferences if there are several
globally minimizing arguments ⌊oa(Pa∗). We can use any of them or switch
between them in a random manner whenever the pdf f(at|Pa∗
t ) has its support
concentrated on them. This is an example where a randomized causal strategy
may occur. We specify it formally as it is extensively used later on.
Agreement 2.6 (Outer model of randomized strategy) The pdf f(a|Pa∗)
is called the outer model of the decision rule. The pdfs

f(at|Pa∗
t )

t∈t∗form
the outer model of the decision strategy.
A decision rule f(a|Pa∗) is called a randomized decision rule if its support
contains at least two diﬀerent values of at. The strategy is called a randomized
strategy if some of its rules are randomized.
Remark(s) 2.5
1. We do not enter the technical game with ε-optimum: the existence of the
various minimizing arguments is implicitly supposed.
2. It is worth repeating that the optimal decision rule is constructed val-
uewise. Formally, the minimization should be performed for all possible
instances of experience Pa∗∈P∗
a∗in order to get the decision rule. Often,
we are interested in the optimal decision for a given ﬁxed, say observed,
experience. Then, just a single minimization is necessary. This is typi-
cally the case of the estimation problem. This possibility makes the main
distinction from the dynamic design, when optimal strategy, a sequence
of decision rules, is searched for. In this case, discussed in next section,
the construction of decision rules is necessary. This makes the dynamic
design substantially harder and, mostly, exactly infeasible [75, 76].
2.4 Dynamic design
We are searching for the optimal admissible strategy assuming that each rule
has at least the same experience as its predecessor. This extending experience
models an increasing number of data available for the decision-making.
2.4.1 Dynamic programming
The optimal admissible strategy can be found by using a stochastic version of
celebrated dynamic programming [77]. It is nothing but a repetitive application
of Proposition 2.7 evolving an auxiliary function V(Pa∗
t ) and determining
actions of the constructed optimal strategy.

26
2 Underlying theory
Proposition 2.8 (Stochastic dynamic programming)
Optimal causal
strategy ⌊o{Rt : P∗
a∗
t →a∗
t }t∈t∗∈{Rt : P∗
a∗
t →a∗
t }∗
t∈t∗with extending experi-
ence Pa∗
t ⊂Pa∗
t+1 and minimizing the expected loss function E[Z(Q)] can be
constructed in a valuewise way.
For every t ∈t∗and Pa∗
t ∈P∗
a∗
t , it is suﬃcient to take a minimizing
argument ⌊oa(Pa∗
t ) of
V(Pa∗
t ) = min
at∈a∗
t
E[V(Pa∗
t+1)|at, Pa∗
t ], t ∈t∗
(2.17)
as the action generated by the tth rule of the optimal strategy, i.e., ⌊oa(Pa∗
t ) =
⌊oRt(Pa∗
t ).
The functional recursion (2.17) is evaluated in the backward manner
against the course given by the extending experience. It starts with
V(Pa∗
˚
t+1) ≡E[Z(Q)|Pa∗
˚
t+1],
(2.18)
where Pa∗
˚
t+1 contains all information available up to and including time ˚t. The
reached minimum has the value
E[V(Pa∗
1)] =
min
{Rt: P∗
a∗
t
→a∗
t }∗
t∈t∗
E[Z(Q)].
Proof. Let us deﬁne Pa∗
˚
t+1 as all information available at time˚t. The the chain
rule for expectations and deﬁnition (2.18) imply
E[Z(Q)] = E[E[Z(Q)|Pa∗
˚
t+1]] ≡E[V(Pa∗
˚
t+1)].
This identity allows us to get a uniform notation. Note that the deﬁnition of
Pa∗
˚
t+1 is legitimate as a˚t+1 is not optimized.
The deﬁnition of minimum and Proposition 2.7 imply
min
{Rt: P∗
a∗
t
→a∗
t }∗
t∈t∗
E[V(Pa∗
˚
t+1)]
=
min
{Rt: P∗
a∗
t
→a∗
t }∗
t<˚
t
⎧
⎨
⎩
min
{R˚
t: P∗
a∗
˚
t
→a∗
˚
t } E[V(Pa∗
˚
t+1)]
⎫
⎬
⎭
=

(2.16)
min
{Rt: P∗
a∗
t
→a∗
t }∗
t<˚
t
E

min
a˚
t∈a∗
˚
t
E[V(Pa∗
˚
t+1)|a˚t, Pa∗
˚
t ]

.
Denoting V(Pa∗
˚
t ) ≡mina˚
t∈a∗
˚
t E[V(Pa∗
˚
t+1)|a˚t, Pa∗
˚
t ], we proved the ﬁrst step of
the recursion and speciﬁed the start (2.18). The following step becomes
min
{Rt: P∗
a∗
t
→a∗
t }∗
t<˚
t
E
	
V(Pa∗
˚
t )

.

2.4 Dynamic design
27
We face the identical situation as above with the horizon decreased by one.
Thus, the procedure can be repeated until the initial optimal rule
⌊oR1 is
constructed.
The optimization relies on our ability to evaluate the expectations
E[V(Pa∗
t+1)|at, Pa∗
t ] =

V(Pa∗
t , at, ∆t)f(∆t|at, Pa∗
t ) d∆t, ∀t ∈t∗.
The introduced innovation ∆t contains those observable quantities that can be
used for the choice at+1 but not for the choice of at. They belong to Pa∗
t+1 \at
but not to Pa∗
t . The pdfs

f(∆t|at, Pa∗
t )

t∈t∗model the relationships of ∆t
to at and Pa∗
t .
Agreement 2.7 (Outer model of the system) The collection of pdfs

f(∆t|at, Pa∗
t )

t∈t∗,
(2.19)
needed for the optimal design, is called the outer model of the system.
Remark(s) 2.6
1. The term outer model of the system is shortened to the model of the system
or even to the model. The exact meaning is clear from the speciﬁc context.
2. Often, the innovation ∆t = yt = observable output of the system.
3. The set-point st to which the output should be driven by the chosen input
ut has to be included into ∆ut if its values are uncertain, i.e., if st ∈
Pu∗
t+1 \ Pu∗
t \ ut.
The following agreement is used in a presentation of the most common
version of dynamic programming.
Agreement 2.8 (Internal quantities; data-driven design) The behavior
Q consists generally of potentially observable innovations ∆(˚t), optional ac-
tions a(˚t), and internal quantities Θ(˚t) in Q that are never observed directly,
i.e., Θ(˚t) ∈Fa∗
τ , τ ∈t∗.
The design is called data driven iﬀthe involved loss function depends on
optional and potentially observable quantities, i.e., with ignorance consisting
only of unobserved data
Z(Q) ≡Z(∆(˚t), a(˚t)) ≡Z(Pa∗, a, Fa∗).
(2.20)
Note that in the general case the loss function may depend also on inter-
nal quantities that are never observed by decision maker. Then, the evalua-
tion of the conditional expectation of the terminal condition (2.18) requires
the additional pdf f(Θ(˚t)|Pa∗
˚
t+1). The discussion how to construct this pdf is
postponed to Section 2.5 after presenting specialized data-driven versions of
dynamic programming.

28
2 Underlying theory
Proposition 2.9 (Dynamic programming for additive loss) Let us
consider data-driven design and search for the optimal admissible strategy

⌊oRt : P∗
a∗
t →a∗
t

t∈t∗acting on an extending experience {Pa∗
t }t∈t∗, Pa∗
t ⊂
Pa∗
t+1. Then, the optimal strategy

⌊oRt : P∗
a∗
t →a∗
t

t∈t∗minimizing the ex-
pected additive loss function, determined by the partial loss z(∆(t), a(t)) ≥0,
E

Z

∆(˚t), a(˚t)

≡E

t∈t∗
z(∆(t), a(t))

,
(2.21)
can be constructed in the following valuewise way.
For all t ∈t∗and Pa∗
t ∈P∗
a∗
t , a minimizing argument ⌊oa(Pa∗
t ) of
V(Pa∗
t ) = min
at∈a∗
t
E[z(∆(t), a(t)) + V(Pa∗
t+1)|at, Pa∗
t ], t ∈t∗
(2.22)
is taken as the optimal decision, ⌊oa(Pa∗
t ) = ⌊oRt(Pa∗
t ). The recursion (2.22)
is performed in the backward manner against the course given by the extending
experience, starting from
V(Pa∗
˚
t+1) ≡0.
(2.23)
The minimum reached has the value
min
{Rt: P∗
a∗
t
→a∗
t }∗
t∈t∗
E[Z(Pa∗
˚
t+1)] = E[V(Pa∗
1)].
Proof. It follows exactly the line of Proposition 2.8 with a modiﬁed deﬁnition
of the function V(·)
V(Pa∗
t ) ≡
min
{Rτ : P∗
a∗τ →a∗
τ }∗
τ≥t
E

τ≥t

z(∆(τ), a(τ))| at = Rt(Pa∗
t ), Pa∗
t

.
(2.24)
For reference purposes, we formulate the following agreement.
Agreement 2.9 (Bellman function; loss-to-go) The function V(·) occur-
ring in dynamic programming is called the Bellman function. The Bellman
function V(·) in (2.24) is also called the optimal loss-to-go.
2.4.2 Fully probabilistic design
A speciﬁc design that expresses losses fully in probabilistic terms is formulated
and solved here. It is systematically used in the body of the text. Moreover, it
is believed to form a bridge between optimal and practically optimal designs.
The notion of the Kullback–Leibler divergence [37] that measures well prox-
imity of a pair of pdfs is widely used.

2.4 Dynamic design
29
Agreement 2.10 (Kullback–Leibler divergence) Let f, g be a pair of
pdfs acting on a common set x∗. Then, the Kullback–Leibler divergence
D(f||g) is deﬁned by the formula
D(f||g) ≡

f(x) ln
f(x)
g(x)

dx.
(2.25)
For conciseness, the Kullback–Leibler divergence is referred to as the KL
divergence.
Proposition 2.10 (Basic properties of KL divergence)
Let f, g be a pair of pdfs acting on a same set. It holds
1. D(f||g) ≥0,
2. D(f||g) = 0 iﬀf = g (a.e.),
3. D(f||g) = ∞iﬀon a set of a positive dominating measure f > 0 and
g = 0,
4. D(f||g) ̸= D(g||f) and the KL divergence does not obey triangle inequality.
Proof. See, for instance, [74].
Now, the fully probabilistic design problem can be formulated and solved.
A simple version considering the data-driven design is presented here. In this
case, the joint pdf f(Q) ≡f(∆(˚t), a(˚t)) describing observable quantities of
interest can be factorized by a repetitive use of the chain rule
f(∆(˚t), a(˚t)) =
 
t∈t∗
f(∆t|at, Pa∗
t )f(at|Pa∗
t ).
(2.26)
The ﬁrst factors

f(∆t|at, Pa∗
t )

t∈t∗under the product sign describe possible
reactions of the system on the decision at under the experience Pa∗
t . These
pdfs form the outer model of the system; see Agreement 2.7. Similarly, the
pdfs

f(at|Pa∗
t )

t∈t∗represent an outer model of the randomized decision
strategy to be chosen; see Agreement 2.6. Looking at the joint pdf (2.26), it
seems to be natural to formulate the design as the selection of such a decision
strategy that make this pdf as close as possible to some “ideal” joint pdf.
Agreement 2.11 (Fully probabilistic design)
The fully probabilistic,
data-driven design, Pa∗
t ≡d(t −1) ≡(∆(t −1), a(t −1))), speciﬁes its loss
function through an ideal pdf
⌊If(Q) =
 
t∈t∗
⌊If(∆t|at, d(t −1)) ⌊If(at|d(t −1)).
The optimal admissible, possibly randomized, decision strategy is deﬁned as
a minimizer of the KL divergence (2.25) of f(d(˚t)) = f(∆(˚t), a(˚t)) and
⌊If(d(˚t)) = ⌊If(∆(˚t), a(˚t))
D

f
!!!
!!! ⌊If

≡

f(∆(˚t), a(˚t)) ln
 f(∆(˚t), a(˚t))
⌊If(∆(˚t), a(˚t))

d(∆(˚t), a(˚t)). (2.27)

30
2 Underlying theory
Proposition 2.11 (Solution of fully probabilistic design) The optimal
strategy minimizing the KL divergence (2.27) has the form
f(at|d(t −1)) = ⌊If(at|d(t −1))exp[−ωγ(at, d(t −1))]
γ(d(t −1))
,
(2.28)
γ(d(t −1)) ≡

⌊If(at|d(t −1)) exp[−ω(at, d(t −1))] dat, for t < ˚t,
γ(d(˚t)) = 1,
(2.29)
ωγ(at, d(t −1)) ≡

f(∆t|at, d(t −1)) ln

f(∆t|at, d(t −1))
γ(d(t)) ⌊If(∆t|at, d(t −1))

d ∆t.
The solution is performed against the time course, starting at t = ˚t.
Proof. With the chain rule, the KL divergence gets the form D

f|| ⌊If

= E
"
t∈t∗

f(at|d(t −1))
#
ln
 f(at|d(t −1))
⌊If(at|d(t −1))

+ ω(at, d(t −1))
$
dat
%
,
ω(at, d(t −1)) ≡

f(∆t|at, d(t −1)) ln
 f(∆t|at, d(t −1))
⌊If(∆t|at, d(t −1))

d∆t.
Let us denote
−ln(γ(d(t))) ≡
min
{f(aτ+1|d(τ))}˚
t
τ=t
E
⎧
⎨
⎩
˚t

τ=t+1

f(aτ|d(τ −1))
×
#
ln
 f(aτ|d(τ −1))
⌊If(aτ|d(τ −1))

+ ω(aτ, d(τ −1))
$
daτ
!!!! d(t)

.
Then, this deﬁnition implies that γ(d(˚t)) = 1 and −ln(γ(d(t)))
≡
min
f(at+1|d(t))

f(at+1|d(t))
#
ln
 f(at+1|d(t))
⌊If(at+1|d(t))

+ ωγ(at+1, d(t))
$
dat+1,
ωγ(at+1, d(t)) ≡

f(∆t+1|at+1, d(t)) ln

f(∆t+1|at+1, d(t))
γ(d(t + 1)) ⌊If(∆t+1|at+1, d(t))

d∆t+1.
It gives −ln(γ(d(t)))
≡
min
f(at+1|d(t))

f(at+1|d(t))
⎡
⎢⎣ln
⎛
⎜
⎝
f(at+1|d(t))
⌊If(at+1|d(t)) exp[−ωγ(at+1,d(t))]

⌊If(˜at+1|d(t)) exp[−ωγ(˜at+1,d(t))] d˜at+1
⎞
⎟
⎠dat+1
−ln

⌊If(at+1|d(t)) exp [−ωγ(at+1, d(t))] dat+1
$
.
The ﬁrst term in the above identity is the KL divergence that reaches its
smallest zero value for the claimed pdf. It also deﬁnes the form of the minima
reached.

2.4 Dynamic design
31
Remark(s) 2.7
1. For an alternative derivation with more details see [63, 78].
2. At a descriptive level, the stochastic dynamic programming consists of a
sequence of the evaluation pairs
(conditional expectation, minimization).
Except of a few numerically solvable cases, some approximation tech-
niques have to be employed. The complexity of the approximated optimum
prevents a systematic use of the standard approximation theory. Conse-
quently, various ad hoc schemes are adopted. The fully probabilistic design
ﬁnds minimizers explicitly and thus reduces the design to a sequence of
conceptually feasible multivariate integrations.
3. The found optimal strategy is randomized and obviously causal one. The
physical constraints are met trivially if the chosen ideal strategy respects
them, i.e., if supp
 ⌊If(at|Pa∗
t )

⊂a∗
t , cf. (2.28).
2.4.3 Asymptotic of the design
The asymptotic of the dynamic programming is analyzed for horizon ˚t →∞
within this section. The outlined analysis serves us only as a motivation for
approximate design; for instance, see Algorithm 4.2. Thus, all technicalities
are suppressed as much as possible.
The data-driven case with an additive loss function (2.21) is considered.
The general, data-dependent loss function can always be converted into the
additive form by deﬁning the partial loss
z(∆(t), a(t))) =

Z(∆(˚t), a(˚t)) if t = ˚t,
0
otherwise .
(2.30)
We deal, however, with a simpler but still useful case by assuming that
•
there is a ﬁnite-dimensional information state xt−1, i.e., Pa∗
t ≡xt−1 ≡an
observed ﬁnite-dimensional vector,
•
the partial loss depends on the information state xt and the action at only
z(∆(t), a(t)) ≡z(xt, at), i.e., the considered loss is
Z(∆(˚t), a(˚t)) =

t∈t∗
z(xt, at).
(2.31)
Agreement 2.12 (Stabilizing strategy) Let us consider sequence of de-
cision-making problems with the growing horizon ˚t →∞, i.e., with extending
sets ⌊˚tt∗≡{1, . . . ,˚t}. The inﬁnite sequence of decision rules
{Rt : P∗
a∗
t →a∗
t }t∈⌊∞t∗≡{1,2,...,}
is called the stabilizing strategy if there is a ﬁnite constant c such that
E[z(xt, at)|at, Pa∗
t ] ≤c < ∞, t ∈⌊∞t∗≡{1, 2, 3, . . .}.
(2.32)

32
2 Underlying theory
Intuitively, it is obvious that with growing decision horizon the expected
loss, as a sum of positive terms, grows to inﬁnity. Consequently, the inﬂuence
of individual rules on it decreases. The following proposition shows that in this
practically important case the optimal strategy can be chosen as stationary
one. The stationary strategy is formed by a repetitive use of the same rule
whose (approximate) evaluation is simpler than that of a general strategy
with time-varying rules.
Proposition 2.12 (Asymptotic design) Let a stabilizing strategy exist.
Then, for ˚t →∞, the optimal strategy can be chosen as stationary one. Deci-
sions generated by the rule deﬁning it are minimizing arguments in the formal
analogy of (2.22)
⌊∞V(xt−1) + ⌊∞C = min
at∈a∗
t
E
	
z(xt, at) + ⌊∞V(xt)
!!! at, xt−1

(2.33)
with a constant ⌊∞C ≤c and a time-invariant Bellman function ⌊∞V(x).
Proof. Let us take any ﬁnite horizon ˚t and, within this horizon, denote
⌊˚t˜V(Pa∗
t ) ≡⌊˚t˜V(xt−1) the optimal loss-to-go; see Agreement 2.9.
Let us deﬁne ⌊˚tC as the smallest value such that
⌊˚tV(xt) ≡⌊˚t˜V(xt) −(˚t −t) ⌊˚tC
is bounded from above for ˚t →∞and any ﬁxed t, xt. Obviously, the optimal
strategy cannot lead to a higher expected loss than any stabilizing strategy.
Thus, the optimal strategy has to also be a stabilizing strategy. Thus, ⌊˚tC ≤c
and lim˚t→∞
⌊˚tC = ⌊∞C exists.
The optimization is uninﬂuenced if we subtract the value
⌊˚tC from all
partial losses. For arbitrary ﬁxed t, xt, the corresponding modiﬁed Bellman
function ⌊˚tV(xt), is bounded from above and ⌊˚tV(xt) = ⌊˚t˜V(xt) −(˚t −t) ⌊˚tC is
the diﬀerence between a pair of monotonous sequences (indexed by ˚t). Thus,
a ﬁnite limit ⌊∞V(xt) = lim˚t→∞
⌊˚tV(xt) exists.
The modiﬁed Bellman function fulﬁlls the equation
⌊˚tV(xt−1) + ⌊˚tC = min
at∈a∗
t
E
	
z(xt, at) + ⌊˚tV(xt)
!!! at, xt−1

.
Existence and ﬁniteness of the involved limits imply that the asymptotic ver-
sion of the Bellman equation is fulﬁlled, too,
⌊∞V(xt−1) + lim˚t→∞
⌊˚tC = min
at∈a∗
t
E
	
z(xt, at) + ⌊∞V(xt)
!!! at, xt−1

.
Limits of ⌊˚tV(xt) exist and, thus, lim˚t→∞
⌊˚tC = lim˚t→∞
⌊˚tC = ⌊∞C.
The identical optimization is performed for each t < ∞. Thus, it provides
the same decision rule for each t: the optimal strategy is a stationary one.

2.5 Learning
33
Remark(s) 2.8
1. The same proof is directly applicable to the fully probabilistic design as it
can be seen as an instance of the additive loss function.
2. Solutions of the Bellman equation obtained for a growing ﬁnite horizon ˚t
can be interpreted as successive approximations for solving its stationary
counterpart (2.33).
3. So-called iterations in strategy space [79] are an alternative and eﬃcient
way of ﬁnding the asymptotic solution. Essentially, a stabilizing stationary
strategy {R} is selected and the linear equation
V(x) + C = E[z(˜x, R(x)) + V(˜x)|R(x), x]
is solved for the function V(·) and constant C. Then, a new approximating
strategy is found valuewise R(x) ∈Arg mina∈a∗E[z(˜x, a) + V(˜x)|a, x] with
such a V(·) (Arg min denotes a set of minimizing arguments). Under gen-
eral conditions, the newly found strategy is stabilizing and iterations may
be repeated until the guaranteed convergence. Details of this procedure are
beyond the scope of this work but it should be considered when searching
for eﬃcient numerical procedures.
2.5 Learning
Considered behavior Q∗contains generally internal quantities Θ(˚t), Agree-
ment 2.8, that are never observed directly. Despite this, we want to describe
or inﬂuence them. Still, the optimal decision-making needs the outer model
(2.19); see Proposition 2.8. If, moreover, the loss function depends on Θ(˚t),
the general dynamic programming needs the pdf f(Θ(˚t)|Pa∗
˚
t+1) for evaluation
of the initial condition (2.18).
Here we describe how to get both outer model and this estimate of in-
ternal quantities. The solved problem, known as nonlinear ﬁltering [46], is
of independent interest as its solution provides a consistent formal model of
learning.
2.5.1 Bayesian ﬁltration
The joint pdf f(Q) describing both observed and internal quantities is con-
structed from the following elements.
Requirement 2.5 (Models; natural conditions of decision making)
1. The innovations ∆t are related to experience Pa∗
t and decisions at through
the observation model
{f(∆t|at, Pa∗
t , Θt) ≡f(∆t|at, Pa∗
t , Θ(t))}t∈t∗
(2.34)
that is given up to unknown internal quantities Θt ∈Θ∗
t ⊂Fa∗
τ , ∀τ ∈t∗.

34
2 Underlying theory
2. The internal quantities Θ(˚t) ∈Θ∗(˚t) are described by a known collection
of pdfs called the time evolution model

f(Θt|at, Pa∗
t , Θt−1) ≡f(Θt|at, Pa∗
t , Θ(t −1))

t∈t∗.
(2.35)
3. The quantities Θ(˚t) are unknown to the strategies considered. The natural
conditions of decision making (a slight generalization of natural conditions
of control [69]) express it formally. They postulate independence of at and
Θt when conditioned on Pa∗
t
f(at|Pa∗
t , Θt) = f(at|Pa∗
t )
⇔

Proposition 2.4
f(Θt|at, Pa∗
t ) = f(Θt|Pa∗
t ).
(2.36)
4. The initial experience Pa∗
1 coincides with the prior information about the
initial internal quantity Θ0 so that the prior pdf f(Θ0) fulﬁlls
f(Θ0) ≡f(Θ0|Pa∗
1)
=

(2.36)
f(Θ0|a1, Pa∗
1).
(2.37)
Remark(s) 2.9
1. The conditional independence, required by (2.34) for observations and by
(2.35) for time evolution, is used to simplify notation. Generally, it is
unnecessary.
2. Often, the unknown quantities Θt together with the decision at are assumed
to describe the involved conditional pdfs fully. Then, Pa∗
t can be omitted
and Θt can be identiﬁed with the information state.
3. The natural conditions of decision making express the assumption that
Θt /∈Pa∗
τ ∀τ, ∀t ∈t∗. Thus, values of Θt cannot be used by the decision
rules forming the admissible strategy. Alternatively, we cannot gain infor-
mation about Θt from the decision at if the corresponding innovation ∆t
(the corresponding reaction of the system) is not available.
The natural conditions of decision making are “naturally” fulﬁlled by
strategies we are designing. They have to be checked when the data in-
ﬂuenced by an “externally chosen” strategy are processed.
Proposition 2.13 (Generalized Bayesian ﬁltering) Let Requirement 2.5
be met. Then, the outer model of the system (2.19) is given by the formula
f(∆t|at, Pa∗
t ) =

f(∆t|at, Pa∗
t , Θt)f(Θt|Pa∗
t ) dΘt.
(2.38)
The evolution of the pdf f(Θt|Pa∗
t ), called (generalized Bayesian) ﬁltration
of unknown quantities Θt, is described by the following recursion that starts
from the prior pdf f(Θ0).

2.5 Learning
35
•
Time updating
f(Θt+1|Pa∗
t+1) =

f(Θt+1|at+1, Pa∗
t+1, Θt)f(Θt|Pa∗
t+1) dΘt
(2.39)
that reﬂects the time evolution Θt →Θt+1.
•
Data updating
f(Θt|Pa∗
t+1) = f(∆t|at, Pa∗
t , Θt)f(Θt|Pa∗
t )
f(∆t|at, Pa∗
t )
∝f(∆t|at, Pa∗
t , Θt)f(Θt|Pa∗
t )
(2.40)
that incorporates the innovation ∆t and the decision at.
Proof. Sequential use of marginalization, the chain rule, Proposition 2.4, and
the natural conditions of decision making (2.36) imply (2.38)
f(∆t|at, Pa∗
t ) =

f(∆t, Θt|at, Pa∗
t ) dΘt
=

f(∆t|at, Pa∗
t , Θt)f(Θt|at, Pa∗
t ) dΘt
=

f(∆t|at, Pa∗
t , Θt)f(Θt|Pa∗
t ) dΘt.
Marginalization, the chain rule, and natural conditions of decision making
also imply the formula for time updating.
Data updating coincides with the Bayes rule in which the outer model of
the strategy cancels as it does not depend on Θt due to the natural conditions
of decision making (2.36).
Agreement 2.13 (Filtering; predictive pdf) The process of generating
ﬁltration is called (generalized Bayesian) ﬁltering. The outer model of the
system obtained by ﬁltering is called predictive pdf.
Remark(s) 2.10
1. The term generalized distinguishes a nonstandard use of the terms Bayesian
ﬁltering and predictions. Without this adjective, they are understood as
speciﬁc decision-making problems. The “generalization” means that the
conditional pdfs needed for these tasks are evaluated only. They serve for
solving a whole class of decision-making problems.
2. The term predictive pdf reﬂects how the outer model of the system has been
obtained. It uses the observed experience and extrapolates it into ignorance
assuming that the mechanism of generating Θt does not change.
This accumulation of experience and its extrapolation represent a good
formal model of learning.
3. It has to be stressed that the accumulation of experience can take place
only when the rules governing the behavior are not changed during it, i.e.,
when we can rely on the validity of the underlying models.

36
2 Underlying theory
4. The ﬁltering results are often of independent interest. The construction of
the predictive pdf and of the pdf needed in (2.18) are our key motivation
for ﬁltering. Under the adopted conditions stated in Requirement 2.5, the
latter pdf can be evaluated recursively as follows.
f(Θ(˚t)|Pa∗
˚
t+1) =
f(Θ(˚t), d˚t|Pa∗
˚
t )
f(d˚t|Pa∗
˚
t )
=
f(d˚t|Pa∗
˚
t , Θ(˚t))f(Θ˚t|Pa∗
˚
t , Θ(˚t −1))
f(d˚t|Pa∗
˚
t )
f(Θ(˚t −1)|Pa∗
˚
t )
=

(2.34),(2.35),(2.36)
=
f(∆˚t|a˚t, Pa∗
˚
t , Θt)f(Θ˚t|Pa∗
˚
t , Θ˚t−1)
f(∆˚t|a˚t, Pa∗
˚
t )
f(Θ(˚t −1)|Pa∗
˚
t ).
This recursion uses the observation model, the time-evolution model, and
the predictive pdf. It can be formally repeated up to reaching prior pdf as
starting point f(Θ(0)|Pa∗
1) ≡f(Θ0).
5. Under the natural conditions of decision making, ﬁltering relies on the
knowledge of decisions and not on the knowledge of rules R : P∗
a∗→a∗
generating them. It is important practically when we learn while decision
loop is closed, especially, by a human decision maker.
6. The time evolution model f(Θt|at, Pa∗
t , Θt−1) as well as the observation
model f(∆t|at, Pa∗
t , Θt) have to result from a theoretical modelling of the
system in question. Such modelling uses both ﬁeld knowledge, like laws
of conservation, and approximation capabilities of the selected family of
models involved. Often, deterministic relationships are modelled and then
the “deviations” from an “expected” trajectory are described.
7. The prior pdf f(Θ0) allows us to introduce information based on expert
knowledge or analogy to situations observed previously.
8. The observed data, the only bridge to reality, enter the evaluations in
the data-updating step only when the newest innovation-decision pair is
processed. This simple fact is important for approximation of the time
evolution model; see Section 3.1.
9. In summary, the described Bayesian ﬁltering combines prior informa-
tion in f(Θ0), theoretical knowledge of the speciﬁc ﬁelds described by
f(∆t|at, Pa∗
t , Θt), f(Θt|at, Pa∗
t , Θt−1) and data d(˚t) = (∆(˚t), a(˚t)) by us-
ing coherent deductive calculus with pdfs. This combination of informa-
tion sources is a powerful internally consistent framework describing the
essence of learning. Due to its deductive structure, an important assurance
is gained:
the incorrect modelling or non-informative data can only be
blamed for a failure of the speciﬁc learning process.
2.5.2 Bayesian estimation
This section deals with a special version of ﬁltering called estimation. It arises
when the internal quantities Θt are time invariant

2.5 Learning
37
Θt = Θ, ∀t ∈t∗.
(2.41)
The common value Θ is called a parameter. In this case, the time evolution
model is f(Θt|at, Pa∗
t , Θt−1) = δ(Θt −Θt−1). The employed Dirac delta func-
tion δ(·) is a formal pdf of the measure fully concentrated on zero.
Proposition 2.14 (Generalized Bayesian estimation) Let Requirement
2.5 be met with time invariant Θt = Θ ∈Θ∗⊂Fa∗
τ , ∀τ ∈t∗. Then, the outer
model of the system (2.19) is given by the formula
f(∆t|at, Pa∗
t ) =

f(∆t|at, Pa∗
t , Θ)f(Θ|Pa∗
t ) dΘ.
(2.42)
The evolution of the pdf f(Θ|Pa∗
t ), called (generalized Bayesian) parameter
estimation, generates the parameter estimate coinciding with the posterior pdf
of the unknown parameter. It is described by the recursion identical with the
data updating (2.40)
f(Θ|Pa∗
t+1) = f(∆t|at, Pa∗
t , Θ)f(Θ|Pa∗
t )
f(∆t|at, Pa∗
t )
∝f(∆t|at, Pa∗
t , Θ)f(Θ|Pa∗
t ).
(2.43)
It starts from the prior pdf f(Θ) ≡f(Θ|a1, Pa∗
1) = f(Θ|Pa∗
1).
The simplicity of the estimation formula allows us to write down its (non-
recursive) batch variant
f(Θ|Pa∗
t+1) =
/
τ≤t f(∆τ|aτ, Pa∗
τ , Θ)f(Θ)
 /
τ≤t f(∆τ|aτ, Pa∗
τ , Θ)f(Θ) dΘ ≡
L(Θ, Pa∗
t+1)f(Θ)
I(Pa∗
t+1)
. (2.44)
The introduced likelihood function
L(Θ, Pa∗
t+1) ≡
 
τ≤t
f(∆τ|aτ, Pa∗
τ , Θ)
(2.45)
evolves according to the recursion identical with that for the non-normalized
posterior pdf (2.43). It starts, however, from the L(Θ, Pa∗
1) identically equal
to 1. The normalization factor I(·) is deﬁned by the formula
I(Pa∗
t+1) =

L(Θ, Pa∗
t+1)f(Θ) dΘ ∝f(∆t|at, Pa∗
t ).
(2.46)
With it, the outer model of the system (2.19) can alternatively be expressed as
f(∆t|at, Pa∗
t ) =
I(Pa∗
t+1)
I(Pa∗
t ) .
(2.47)
Proof. It is again a simple exercise in calculus with pdfs, marginalization, the
chain rule, and the Bayes rule, Proposition 2.4, under the natural conditions
of decision making (2.36).

38
2 Underlying theory
Remark(s) 2.11
1. The observation model f(∆t|at, Pa∗
t , Θ) is called a parameterized model
whenever the estimation problem is considered. We respect this tradition.
2. Note that the recursive evolution of the pdf f(Θ|Pa∗
t ) allows us to interpret
the posterior pdf as the prior one before processing new observations.
3. The data inserted into the “objective” parameterized (observation) model
gradually correct the subjectively chosen prior pdf f(Θ). The posterior pdf
f(Θ|Pa∗
t ) always reﬂects both objective and subjective information pieces.
If the data are informative enough, the relative contribution of the single
subjective factor f(Θ) to the posterior pdf is decreasing with increasing t
as the likelihood function L(Θ, Pa∗
t+1) contains t “objective” factors (2.45).
4. Zero values are preserved by multiplication. Thus, the posterior pdf re-
distributes the probability mass only within the support of the prior pdf,
i.e., within the set supp [ f(Θ)] ≡{Θ ∈Θ∗: f(Θ) > 0}. This fact allows
us to introduce hard bounds on possible parameter values but does not
allow us to “learn” about parameters Θ out of the support supp [ f(Θ)].
5. Remarks 2.10, related to ﬁltering, apply mostly to estimation, too. The
parameter estimation is a task on its own; unknown parameters are always
in the ignorance of the decision to be chosen; under the natural conditions
of decision making (2.36), decisions values are only needed and the strategy

Rt : P∗
a∗
t →a∗
t

t∈t∗generating them need not to be known.
6. The parameters Θt are usually assumed to be ﬁnite-dimensional in order
to avoid technicalities related to measure theory. In exceptional cases, like
description of the so-called equivalence approach (see Section 3.4), we deal
with potentially inﬁnite-dimensional parameter. It means that the number
of unknown quantities is ﬁnite but increases without limitations. This case
is often called nonparametric estimation.
2.5.3 Asymptotic of estimation
The analysis outlined here serves us primarily for interpretation of estimation
results when none of the considered parameterized models describes reality
exactly. This interpretation can be directly used for constructions of approx-
imate estimation, for instance; see Section 6.4.8. Similarly as for design, all
technicalities are suppressed as much as possible.
The “objective” pdf f(Q) (see Section 2.3.1) describing the system be-
havior is denoted here ⌊of(Q). The corresponding outer model of the system
f(∆t|at, Pa∗
t ) is denoted ⌊of(∆t|at, Pa∗
t ). Its relationship to the predictive pdf
f(∆t|at, Pa∗
t ) — obtained through the parameter estimation; see Proposition
2.14 — is inspected here.
For the analysis, the notion of a (relative) entropy rate H∞
 ⌊of
!!!! Θ

is
needed; see the discrete-valued analogy in [80]. For a given realization of be-
havior, it measures the distance of a parameterized model to the objective pdf
and determines asymptotic behavior of Bayesian estimation.

2.5 Learning
39
For each Θ ∈Θ∗, the entropy rate is deﬁned by the formula
H∞

⌊of
!!!
!!! Θ

≡limt→∞Ht

⌊of
!!!
!!! Θ

(2.48)
≡limt→∞
1
t

τ≤t

⌊of(∆τ|aτ, Pa∗
τ ) ln
0
⌊of(∆τ|aτ, Pa∗
τ )
f(∆τ|aτ, Pa∗
τ , Θ)
1
d∆τ.
Proposition 2.15 (Asymptotic of estimation) Let the natural conditions
of decision-making (2.36) hold. For almost all Θ ∈Θ∗, let there exist positive
CΘ, CΘ uniformly bounded by a ﬁnite c, i.e., 0 < CΘ ≤CΘ ≤c < ∞, and a
ﬁnite time moment ¯tΘ ∈{1, 2, . . .}, such that ∀t > ¯tΘ, ∀Pa∗
t+1 ∈P∗
a∗
t+1
CΘf(∆t|at, Pa∗
t , Θ) ≤⌊of(∆t|at, Pa∗
t ) ≤CΘf(∆t|at, Pa∗
t , Θ).
(2.49)
Then, the posterior pdf f(Θ|Pa∗
t ) (2.43) converges almost surely to a pdf
f(Θ|Pa∗
∞). Its support coincides with the set of minimizing arguments in
supp

f(Θ|Pa∗
∞)

= Arg
min
Θ∈supp[ f(Θ)]∩Θ∗H∞

⌊of
!!!
!!! Θ

.
(2.50)
Proof. Under the natural conditions of decision making (2.36), the posterior
pdf (2.43) can be written in the form
f(Θ|Pa∗
t+1) ∝f(Θ) exp[−tH(Pa∗
t+1, Θ)],
(2.51)
H(Pa∗
t+1, Θ) = 1
t

τ≤t
ln[η(Pa∗
τ , Θ)],
η(Pa∗
τ+1, Θ) ≡
⌊of(∆τ|aτ, Pa∗
τ )
f(∆τ|aτ, Pa∗
τ , Θ). (2.52)
This form exploits the fact that the non-normalized posterior pdf can be
multiplied by any factor independent of Θ.
Let us ﬁx the argument Θ ∈Θ∗and deﬁne
eΘ;τ ≡ln(η(Pa∗
τ+1, Θ)) −⌊oE
	
ln(η(Pa∗
τ+1, Θ))
!!! aτ, Pa∗
τ

≡ln(η(Pa∗
τ+1, Θ)) −

⌊of(∆τ|aτ, Pa∗
τ ) ln(η(Pa∗
τ+1, Θ)) d∆τ.
A direct check reveals that the introduced deviations eΘ;τ of ln(η(Pa∗
τ+1, Θ))
from their conditional expectations
⌊oE[ln(η(Pa∗
τ+1, Θ))|aτ, Pa∗
τ ], given by
⌊of(∆τ|aτ, Pa∗
τ ), are zero mean and mutually uncorrelated. With them,
H(Pa∗
t+1, Θ) = Ht

⌊of
!!!
!!! Θ

+ 1
t

τ≤t
eΘ;τ.
The assumption (2.49) implies that the variance of eΘ;τ is bounded. Conse-
quently, the last term in the above expression converges to zero almost surely;

40
2 Underlying theory
see [81], page 417. The ﬁrst term on the right-hand side of the last equality
is nonnegative as it can be viewed as a sum of Kullback–Leibler divergences;
see Proposition 2.10. Due to (2.49), it is also ﬁnite. Thus, (2.52) converges
a.s. to the nonnegative value H∞
 ⌊of||Θ

. The posterior pdf remains un-
changed if we subtract t minΘ∈supp[ f(Θ)]∩Θ∗H∞
 ⌊of||Θ

from the exponent
of its non-normalized version (2.51). Then, the exponent contains (−t× an
asymptotically nonnegative factor). Thus, the posterior pdf f(Θ|Pa∗
∞) may
be asymptotically nonzero on minimizing arguments (2.50) only.
Remark(s) 2.12
1. The entropy rate can be seen as an extension of the Kullback–Leibler diver-
gence (2.25) that covers well asymptotic and controlled cases. It coincides
with the Kullback–Leibler divergence in a range of particular cases.
2. The assumption (2.49) can be weakened. It is, however, intuitively accept-
able. It excludes parameterized models, which assign no conﬁdence to data
generated by the system with a nonzero probability, and vice versa.
3. The Bayesian estimation chooses among candidates f(∆t|at, Pa∗
t , Θ), Θ ∈
Θ∗, the pdf that minimizes the asymptotic entropy rate from the objective
pdf ⌊of(∆t|at, Pa∗
t ). In other words, a best projection of the objective pdf to
the considered parameterized models is asymptotically found. The prior pdf
can be interpreted as a prior belief assigned to the individual parameters
Θ ∈Θ∗that the corresponding parameterized model is the best projection
of the objective pdf [82]: not knowing the reality we do not know the best
projection we ﬁnally arrive at.
4. The posterior pdf concentrates on a point if there is a unique minimizer
of the entropy rate. In this case, the model is called identiﬁable. The pos-
sibility to identify the model can be inﬂuenced by
•
the considered class of the parameterized models,
•
the decisions chosen, for instance, by the controller used: e.g., the con-
troller generating constant inputs prevents us from learning their dy-
namic inﬂuence on outputs.
5. If the objective pdf
⌊of(∆t|at, Pa∗
t ) coincides with f(∆t|at, Pa∗
t , Θ) for
some Θ = ⌊oΘ with f
 ⌊oΘ

> 0 then ⌊oΘ is in the support of the asymp-
totic posterior pdf f(Θ|Pa∗
∞). If, moreover, the model is identiﬁable, then
the objective pdf is asymptotically identiﬁed by the adopted Bayesian ap-
proach. This fact can be expressed in a more appealing form:
The Bayesian estimate is consistent whenever there is a consistent estimator.
6. Often, a similar analysis is performed by measuring the distance of param-
eterized models to the empirical pdf of data [83]. It gives similar answers if
the empirical pdf converges to the objective pdf. Moreover, it provides hints
of how to approximate the posterior pdf [84]; see also Section 3.4. On the
other hand, the known conditions of such convergence are more restrictive.
For instance, an analysis of the controlled case is much harder.

2.5 Learning
41
Problem 2.1 (How to unify statistics?) Asymptotic analysis and the ﬁ-
nite-data-oriented Bayesian approach are often perceived in an antagonistic
way. Their harmonized use still waits for its full exploitation.

3
Approximate and feasible learning
The operator support we deal with relies on the ability to describe diﬀerent
operating modes. The ﬁnite probabilistic mixture [49] is the black-box model
we use for this purpose. It is a convex combination of unimodal pdfs called
components; see Agreement 5.4. The set of mixtures among which a speciﬁc
model of a speciﬁc process is searched for is parameterized by an unknown
ﬁnite-dimensional parameter Θ. Formally, it can be estimated using Propo-
sition 2.13. In the considered high-dimensional, data-intensive applications,
the formal solution is useless as the exact likelihood function cannot be prac-
tically handled. The inevitable approximate mixture estimation (see Section
6.5) relies on our ability to solve estimation and prediction tasks for variety
of parameterized components. This preliminary task is addressed here with
the aim of preparing common tools used for the mixture estimation and con-
sequently for estimation of its normal, Markov-chain and uniform variants.
Speciﬁcally, estimation with forgetting allows us to track slow changes of
parameters and thus to make the advisory system adaptive; see Section 3.1.
The estimation within an exponential family (EF) of parameterized mod-
els is recalled in Section 3.2. It covers the majority of components whose
exact estimation is feasible. Its most important special instances — normal
parameterized models and Markov-chain parameterized models — are treated
in detail Chapters 8 and 10.
The the chain rule allows us to decompose any parameterized component
f(dt|d(t −1), Θ) =
˚
d
 
i=1
f(di;t|di+1;t, . . . , d˚
d;t, d(t −1), Θ).
(3.1)
The individual pdfs describing scalars di;t are called factors; see Agreement
5.4. Starting in Chapter 5, factor-based modelling will be systematically used
as it describes data records with mixed — discrete and continuous — entries.
Moreover, factors reveal a ﬁne structure of dependencies that spares parame-
ters and contributes signiﬁcantly to identiﬁability; cf. Remark 4, 2.12. Basic
principles of their structure estimation are outlined in Section 3.3.

44
3 Approximate and feasible learning
The descriptive power of a ﬁnite mixture depends strongly on the richness
of the set of parameterized factors we are able to handle eﬃciently. This
makes us to present in Section 3.4 so-called equivalence approach to parameter
estimation [84]. It provides a promising tool for handling nonlinear and/or
non-normal factors. At the same time, it points to an important but neglected
problem of approximate recursive Bayesian estimation.
3.1 Estimation with forgetting
The advisory system we are constructing relies on the validity of the model
learned. We have to grasp all signiﬁcant time-varying relationships. At the
same time, we cannot exclude slow changes caused, for instance, by aging
of the maintained system. Thus, it is reasonable to inspect the case of slowly
varying parameters as a widely met intermediate case bridging estimation and
ﬁltering. It admits time variations of Θt, but it assumes that Θt+1 ≈Θt as
the only information related to missing time evolution model. This incom-
pletely formulated ﬁltering problem is mostly addressed by various forgetting
techniques, e.g., [85, 86, 87].
We summarize here an approach called stabilized forgetting, [88]. It is based
on a ﬂexible problem formulation of this formally ill-posed problem.
Let f(Θt+1 = Θ|d(t)) be the pdf that assumes no parameter changes
happened after measuring dt and before processing dt+1, i.e., Θt+1 = Θt.
Let ⌊Af(Θt+1 = Θ|d(t)) be an alternative pdf that describes parameters after
expected changes within time interval (t, t + 1).
Let λ ∈[0, 1] be the probability that the “correct” unknown pdf f(Θt+1 =
Θ|d(t)) has the best projection equal to the former pdf and 1−λ the probabil-
ity that the latter one is relevant. We are searching for the best compromise
ˆf(Θt+1 = Θ|d(t)) minimizing its expected KL divergence to the unknown pdf
f(Θt+1 = Θ|d(t)). Solution of this decision-making task is described by the
following proposition.
Proposition 3.1 (Geometric representation of a pair of pdfs) Let an
unknown pdf f ∈f ∗≡{f1, f2} be equal to f1 with a probability λ ∈λ∗≡[0, 1]
and equal to f2 with the complementary probability 1 −λ. The pdfs f1, f2 are
supposed to have a common support x∗. Then, the pdf
ˆf(x) ∝[f1(x)]λ[f2(x)]1−λ, x ∈x∗
is the estimate of f(·) that
(3.2)
•
uses the experience P ˆ
f ∗≡{λ, f1, f2} and
•
minimizes the expected KL divergence (2.25), i.e., the functional
E
	
D

ˆf
!!!
!!! f

≡λD

ˆf
!!!
!!! f1

+ (1 −λ)D

ˆf
!!!
!!! f2

.
(3.3)

3.1 Estimation with forgetting
45
The reached minimum is
ω(λ) ≡E
	
D

ˆf
!!!
!!! f

= −ln

f λ
1 (x)f 1−λ
2
(x) dx.
(3.4)
If f1 ̸= f2, the function ω(λ) reaches its maximum on (0, 1).
Proof. The minimized functional (3.3) can be rewritten into the form
D
0
ˆf(x)
!!!!!
!!!!!
[f1(x)]λf2(x)]1−λ

f λ
1 (˜x)f 1−λ
2
(˜x) d˜x
1
−ln

f λ
1 (x)f 1−λ
2
(x) dx.
This form and properties of the KL divergence imply the form of the minimizer
(3.2) as well as the attained minimum value (3.4).
The last statement of the proposition is implied by the assumption f1 ̸= f2,
closeness of the set λ∗, and continuity of ω(λ) guaranteed by the common
support of f1, f2. Non-negativity of the KL divergence and obvious equalities
ω(0) = ω(1) = 0 imply that the extreme in (0,1) must be the maximum.
The direct application of Proposition 3.1 provides the best correction of
the posterior pdf to expected changes of parameters
ˆf(Θt+1 = Θt = Θ|d(t)) ∝[f(Θt+1 = Θ|d(t))]λ 	
⌊Af(Θt+1 = Θ|d(t))
1−λ
.
(3.5)
By using this formula, we approximate the time-updating step (2.39) in ﬁl-
tering without explicitly specifying the model of time evolution (2.35).
Algorithm 3.1 (Stabilized forgetting)
Initial (oﬄine) mode
•
Specify the prior pdf f(Θ1 = Θ) ≡f(Θ1 = Θ|d(0)) corresponding to the
treated parameterized model f(∆t|at, d(t −1), Θt).
•
Select the probability λ ∈[0, 1] that parameters do not change.
Sequential (online) mode, running for t ∈t∗,
1. Collect the newest data dt.
2. Perform data updating
f(Θt = Θ|d(t)) ∝f(∆t|at, d(t −1), Θ)f(Θt = Θ|d(t −1)).
3. Select or update the alternative pdf ⌊Af(Θt+1 = Θ|d(t)).
4. Approximate time updating (forget)
f(Θt+1 = Θ|d(t)) ∝[f(Θt+1 = Θt = Θ|d(t))]λ 	
⌊Af(Θt+1 = Θ|d(t))
1−λ
.

46
3 Approximate and feasible learning
Remark(s) 3.1
1. The pdf (3.5) after the time updating is a compromise between the pos-
terior pdf obtained under the hypothesis that Θt is time invariant and an
externally supplied alternative
⌊Af. The closer λ is to unity, the slower
changes are expected, i.e., the higher weight the posterior pdf corresponding
to the time invariant case gets.
2. The forgetting operation (3.5) preserves the basic property of time updat-
ing: the posterior pdf on parameters propagates without obtaining any new
measured information.
3. Let us assume that
⌊Af ∝1 and λ < 1. Then, f(Θt+1 = Θ|d(t)) ∝
[f(Θt+1 = Θt = Θ|d(t))]λ ≡[f(∆t|at, d(t −1))f(Θ|d(t −1))]λ, i.e., the
pdf after time updating is a ﬂattened version of the pdf obtained after
data updating. It is intuitively appealing as our uncertainty about param-
eters can hardly decrease without knowing a good time evolution model
(2.35) and with no new information processed.
4. It is instructive to inspect the inﬂuence of forgetting on old data built in
through the observation model. The older data are, the stronger ﬂattening
is applied to the values of the corresponding parameterized model. Con-
sequently, the older data inﬂuence the estimation results less than new
ones. Data are gradually “forgotten”. This explains why the probability λ
is called the forgetting factor.
5. The alternative pdf ⌊Af(·) expresses our belief where the parameters might
move within the time interval (t, t + 1) while we have no new observable
information. Often, the pessimistic uniform alternative pdf (∝1) has been
used. This special case of stabilized forgetting is called exponential forget-
ting. It allows us to follow relatively fast parameter changes but it forgets
the accumulated information with an often too high exponential rate. For
this reason, it is worth preserving what we feel as a guaranteed informa-
tion. The prior pdf f(Θt+1 = Θ) is a typical, reasonably conservative,
choice of the alternative pdf ⌊Af(Θt+1 = Θ|d(t)).
6. The nontrivial alternative pdf prevents us to forget the “guaranteed” in-
formation as it is always incorporated after ﬂattening (exponential for-
getting). This stabilizes whole learning and reﬂects very positively in its
numerical implementations. Without this, the posterior pdf may become
too ﬂat whenever the information brought by new data is poor. Note that
lack of information brought by new data is more rule than exception. It
is true especially in the so-called regulation problem [89]. In it, the con-
troller tries to make the closed control loop as quiet as possible; it tries to
suppress any new information brought by data.
7. The forgetting factor λ can be either taken as a tuning knob or estimated.
The predictive pdf parameterized by it, however, depends on it in a very
complex way so that a partitioned estimation has to be applied when its
posterior pdf is estimated on a prespeciﬁed grid [90].

3.2 Exponential family
47
Alternatively, the forgetting factor can be chosen in a pessimistic way as
the maximizer of the reached minima; see Proposition 3.2.
8. The practical importance of this particular case of estimating slowly vary-
ing parameters cannot be overstressed: the vast majority of adaptive sys-
tems rely on a version of forgetting.
3.2 Exponential family
A majority of the factors we deal with are taken from exponential family.
Agreement 3.1 (Exponential family) The ith parameterized factor in (3.1)
belongs to the dynamic exponential family iﬀit can be written in the form
f(di;t|di+1;t, . . . , d˚
d;t, d(t −1), Θ) ≡f(di;t|ψi;t, Θ)
(3.6)
≡A(Θ) exp[⟨B(Ψi;t), C(Θ)⟩+ D(Ψi;t)],
where
ψi;t is the ﬁnite-dimensional regression vector determined by di+1;t, . . . , d˚
d;t
and at, d(t −1),
Ψ ′
i;t ≡[di;t, ψ′
i;t] is a ﬁnite-dimensional data vector, whose values can be up-
dated recursively according to a known rule (Ψi;t−1, dt)∗→Ψ ∗
i;t, where
′ denotes transposition
⟨·, ·⟩is the functional, linear in the ﬁrst argument. Within this text it is deﬁned
⟨x, y⟩=
⎧
⎨
⎩
x′y
if x, y are vectors
tr[xy]
if x, y are matrices, tr is trace
2
i∈i∗xiyi if x, y are arrays with a multi-index i,
(3.7)
A(·) is a nonnegative scalar function deﬁned on Θ∗,
B(·), C(·) are either vector or matrix functions of compatible, ﬁnite and ﬁxed
dimensions; they are deﬁned on respective arguments in Ψ ∗
i;t and Θ∗,
D(·) is a nonnegative scalar function deﬁned on Ψ ∗
i .
Remark(s) 3.2
1. Our deﬁnition of the exponential family contains the nonstandard require-
ment on the recursive updating of the data vector Ψi;t. It is practically
important for dynamic cases we deal with.
2. Notice that equality is used in (3.6). The normalization of this pdf must
not spoil this form. It makes the allowed form rather restrictive. In the
dynamic case with a nonempty regression vector ψ, normal (Gaussian)
linear-in-parameters factors and Markov chains almost cover exponential
family.
3. The scalar function D entering (3.6) does not inﬂuence estimation. The
factor exp(D(Ψi;t)) enters prediction unchanged. We use this property only
in Section 8.1.6. Otherwise, D(Ψi;t) is omitted.

48
3 Approximate and feasible learning
4. In the rest of this chapter, we consider a factor related to a predicted data
entry di;t with a ﬁxed i and the index i is dropped.
The practical signiﬁcance of the exponential family becomes obvious when
we apply Proposition 2.14, which describes the corresponding estimation and
prediction.
Proposition 3.2 (Estimation and prediction in exponential family)
Let natural conditions of decision making, Requirement 2.5, be met with the
time-invariant parameter Θt = Θ ∈Θ∗. Let the parameterized model belong
to the exponential family (3.6). Then, the predictive pdf, the outer model of
the system, is given by the formula
f(∆t|at, d(t −1)) = I(Vt−1 + B(Ψt), νt−1 + 1)
I(Vt−1, νt−1)
exp[D(Ψt)],
(3.8)
Vt = Vt−1 + B(Ψt), V0 = 0;
νt = νt−1 + 1, ν0 = 0,
(3.9)
I(V, ν) =

Aν(Θ) exp[⟨V, C(Θ)⟩]f(Θ)χΘ∗(Θ) dΘ,
(3.10)
where f(Θ) is a prior pdf. Its support is restricted by the indicator χΘ∗(·)
of the set Θ∗.
The Bayesian parameter estimate (posterior pdf) is
f(Θ|d(t)) = Aνt(Θ) exp[⟨Vt, C(Θ)⟩]χΘ∗(Θ)f(Θ)
I(Vt, νt)
,
(3.11)
i.e., the likelihood function is
L(Θ, d(t)) ≡L(Θ, Vt, νt) = Aνt(Θ) exp[⟨Vt, C(Θ)⟩].
(3.12)
Let us consider the conjugate prior pdf
f(Θ) ∝Aν0(Θ) exp[⟨V0, C(Θ)⟩]χΘ∗(Θ),
(3.13)
determined by the “prior statistics” V0, ν0. Then, the prediction and estima-
tion formulas (3.8) and (3.11) are valid if
•
V0, ν0 replace the zero initial conditions in (3.9),
•
the indicator χΘ∗(·) is formally used as the prior pdf.
Let us allow slow parameter changes with the forgetting factor λ ∈[0, 1] and
the alternative pdf given in the conjugate form determined by the pair of suf-
ﬁcient statistics ⌊AVt, ⌊Aνt. Then, the prediction and estimation formulas re-
main unchanged with statistics evolving according to the recursion
Vt = λ(Vt−1 + B(Ψt)) + (1 −λ) ⌊AVt, V0 given,
νt = λ(νt−1 + 1) + (1 −λ) ⌊Aνt,
ν0 given.
(3.14)

3.3 Structure estimation in the nested exponential family
49
Remark(s) 3.3
1. Estimation and prediction within the exponential family is very simple,
especially with the conjugate prior pdf. The updating of functions (pdfs)
converts into the algebraic recursive updating of the ﬁnite-dimensional suf-
ﬁcient statistic consisting of Vt and the sample counter νt. Moreover, a
single type of the normalization integral I(V, ν) has to be evaluated. The
need to have the complete recursion explains the requirement for a possi-
bility to update Ψt recursively; see Agreement 3.1.
2. An inspection whether there is a wider set of parameterized models with ad-
vantageous properties of the exponential family opens just a narrow space
[91]. Essentially, the exponential family coincides with all parameterized
models that are suﬃciently smooth functions of Θ and with supports in-
dependent of Θ. Uniform distribution with unknown constant boundaries
represents one of a few feasible examples of pdfs out of the exponential
family.
3. The class of models that lead to a ﬁnite-dimensional characterization of
pdfs occurring in ﬁltering is even more restrictive. Its discussion can be
found in [92].
3.3 Structure estimation in the nested exponential
family
Often, speciﬁcation of the parameterized model can be done by selecting
discrete-valued pointers to a ﬁnite set of alternative parameterized mod-
els. These pointers deﬁne model structure; see [93] for a detailed discussion.
Formally, estimation of the best structure can be performed fully within a
Bayesian set-up by assigning the prior pf to competitive structures and com-
puting the posterior one. The problem becomes speciﬁc and diﬃcult due to
the usual extremely large cardinality of the set of possible structures. Then,
special measures have to be taken. Often, we use nested models with suﬃcient
statistics contained in a single one corresponding to the richest structure.
Proposition 3.3 (Nesting in the exponential family)
Let the parame-
terized model with the richest structure belong to the exponential family (3.6)
f(d|ψr, Θr) = Ar(Θr) exp[⟨Br(Ψr), Cr(Θr)⟩]. Let us consider another model
f(d|ψ, Θ) = A(Θ) exp[⟨B(Ψ), C(Θ)⟩] describing the same data d(˚t).
Let N be a time invariant linear nesting operator such that
B(Ψ(d(t))) ≡N[Br(Ψr(d(t)))].
Let us consider a pair of conjugate prior pdfs given by statistics Vr;0, νr;0 and
V0 ≡N[Vr;0], ν0. Then, the V statistics of the posterior pdfs of both models are

50
3 Approximate and feasible learning
related by the nesting mapping V˚t = N[Vr;˚t]. The predictive pdf of the nested
model is
f(d(˚t)) ∝I(V˚t, νt)
I(V0, ν0) = I

N[Vr;˚t], νt

I (N[Vr;0], ν0).
(3.15)
Proof. It is implied directly by Proposition 3.2 and linearity of N.
For structures s ∈s∗, that can be obtained by a nesting operator from
the richest structure, we are able to evaluate the pdf f(d(˚t)|s) for any speciﬁc
structure s. Let f(s) be prior pf on s∗, then the Bayes rule, Proposition 2.4,
gives us formally the posterior pf on structures, i.e., full information needed
for its point estimation.
If ψr is the richest regression vector then the number ˚s of possible com-
petitive structures nested in it is 2˚
ψr. This is mostly an excessive number
that prevents us from evaluating completely posterior probabilities of nested
structures. Instead, we are searching for the maximum a posteriori probabil-
ity (MAP) estimate. Of course, we can inform also about highly probable
structures met during the search for MAP estimate. The following conceptual
algorithm is used for it.
Algorithm 3.2 (MAP estimate of a factor structure)
Do while the prespeciﬁed number of restarts is not exceeded.
1. Select an initial guess of the structure.
2. Do while the value of the likelihood increases and a prespeciﬁed number of
searches is not exceeded.
a) Make a full search for the best structure within a “neighborhood” of
the current guess of the structure and ﬁnd the structure maximizing
the posterior likelihood f(d(˚t)|s)f(s) within it.
b) Take the maximizer as a new guess of the structure.
The algorithm is “parameterized” by the following:
•
The generator of the initial guesses: a speciﬁed number of random choices,
empty, richest and user-speciﬁed regression vectors are mostly used.
Speciﬁcation of the number of random draws has to balance computational
demands and probability that global maximum is found. A solution of this
problem exploiting the Bayesian sequential stopping rule was developed for
this purpose [94].
•
Deﬁnition of neighborhood: a good choice depends on the speciﬁc parame-
terized model considered. A detailed solution tailored to normal regression
models is described in [95].
3.4 Equivalence approach
The exponential family and special uniform distributions provide us with a
basic supply of factors. Sometimes, however, we are forced to go out of this

3.4 Equivalence approach
51
family. Under natural conditions of decision making (2.36), the generalized
Bayesian estimation, Proposition 2.14, updates the posterior pdfs according
to the Bayes rule (2.43)
f(Θ|d(t)) = f(∆t|at, d(t −1), Θ)f(Θ|d(t −1))
f(∆t|at, d(t −1))
, t ∈t∗.
The complexity of these pdfs increases quickly with an increasing number of
data, with increasing t. The exponential family (3.6) is essentially the only
exception from this rule. This section tries to cope with recursive estimation
applicable out of the exponential family. The equivalence approach presented
in this section allows us to ﬁnd a well-justiﬁed approximation even in these
cases.
3.4.1 Recursively feasible representation
The limited capabilities of computers call for a reduced representation of the
propagated posterior pdfs. It is a diﬃcult task as the posterior pdfs concen-
trate quickly on a very narrow support at a priori unknown position in Θ∗.
Thus, a representation on a suﬃciently ﬁne grid that does not miss the ﬁnal
position becomes soon computationally prohibitive. The way out has been
elaborated in a sequence of papers and summarized in [84]. Here, we just
outline the essence of this equivalence approach.
Proposition 3.4 (Equivalence-preserving mapping) Let f ∗(Θ|d(t −1))
be a set of posterior pdfs f(Θ|d(t −1)) with a common, time, data, and pa-
rameter invariant support. Let the mapping
Gt−1 : f ∗(Θ|d(t −1)) →g∗
t−1
(3.16)
assign to each pdf f(Θ|d(t −1)) from f ∗(Θ|d(t −1)) a ﬁnite-dimensional vec-
tor statistics gt−1 ≡g(d(t −1)) representing it. Then, the value of gt−1 can
be exactly recursively updated using only its previous value and the current
parameterized model f(∆t|at, d(t−1), Θ) iﬀGt is a time-invariant linear map-
ping Gt ≡G, t ∈t∗, acting on logarithms of the pdfs involved. The logarithmic
pdfs are treated as functions of Θ.
Gt has to map Θ-independent elements to zero.
Proof. To demonstrate necessity is rather diﬃcult, and the interested reader
is referred to [96, 97]. To show that the conditions on Gt ≡G, t ∈t∗, are
suﬃcient is simple and instructive. They become obvious if we apply G to the
logarithmic version of the Bayes rule (2.43) and use both time invariance and
linearity of G. The normalizing term ln(f(∆t|at, d(t −1)) is independent of Θ
and as such mapped to zero. The recursion for gt is then
gt = G [ln (f(∆t|at, d(t −1), Θ))] + gt−1,
with
(3.17)
g0 = G(ln(f(Θ))) ≡G(ln(prior pdf)).

52
3 Approximate and feasible learning
Note that (3.17) becomes the true recursion if we need not store complete
past observed data for evaluating f(∆t|at, d(t −1), Θ). Thus, similarly to
the case of the exponential family (see Agreement 3.1) we restrict ourselves
to such models. Together with their formal description we introduce other
notions useful in the subsequent discussion.
Agreement 3.2 (Finite memory; Riezs representation)
The parame-
terized model is said to have ﬁnite memory iﬀ
f(∆t|at, d(t −1), Θ) ≡M(Θ, Ψt),
(3.18)
where M(·, ·) is a known function of Θ and of a ﬁnite-dimensional data vector
Ψt that can be updated recursively
(Ψt−1, dt)∗→Ψ ∗
t .
Let {Ψτ}t
τ=1 be measured data vectors. Then,
ft(Ψ) ≡1
t
t

τ=1
δ(Ψ −Ψτ), Ψ ∈Ψ ∗≡
3
t∈t∗
Ψ ∗
t
(3.19)
is the formal empirical pdf of Ψ. The Dirac delta function δ(·) used is the
linear functional assigning to (reasonable) functions B(Ψ) their values at zero
argument. It has a Riezs integral representation, [98],

B(Ψ)δ(Ψ) dΨ = B(0),
(3.20)
where δ(Ψ)should be formally taken as a generalized function [99].
We assume that the same representation exists for the linear mapping
G introduced in Proposition 3.4, i.e., there is a, possibly generalized, vector
function G(Θ) such that
G(C) ≡

C(Θ)G(Θ) dΘ
(3.21)
for any considered function C : Θ∗→(−∞, ∞).
Assuming (3.18), using the empirical pdf (3.19) and Riezs representation of
G (3.21), we see that the representation gt of the posterior pdf f(Θ|d(t)) can
be written in the form
gt = t
 #
ln[M(Θ, Ψ)]G(Θ) dΘ
$
ft(Ψ) dΨ + g0.
(3.22)
The integral in brackets deﬁnes the vector function

3.4 Equivalence approach
53
h(Ψ) ≡

ln[M(Θ, Ψ)]G(Θ) dΘ.
(3.23)
With it, we get the equivalent form of (3.22)
gt = t

h(Ψ)ft(Ψ) dΨ + g0.
(3.24)
Recall that left-hand side of (3.24) is known as it can be updated recursively
according to (3.17), which has the equivalent Riezs representation
gt
=

(3.17),(3.18),(3.21)

ln[M(Θ, Ψt)]G(Θ) dΘ + gt−1
≡

(3.23)
h(Ψt) + gt−1
g0 = G(ln(f(Θ))).
(3.25)
Also, for the chosen parameterized model (3.18) and functions G(Θ) repre-
senting the admissible projections to g∗
t , the vector function h(Ψ) (3.23) is
known as well as its values in measured data vectors Ψt.
3.4.2 Approximation as a point estimation
The posterior pdf we are interested in can be expressed in terms of the em-
pirical pdf ft(Ψ) as follows, cf. the similar transformation in the proof of
Proposition 2.15,
f(Θ|d(t)) ≡f(Θ|ft(·)) ∝f(Θ) exp
#
t

ln[M(Θ, Ψ)]ft(Ψ) dΨ
$
.
(3.26)
The empirical pdf is unknown to us as we are not able to store it and map it
without information loss on a ﬁnite-dimensional statistic. Thus, this posterior
pdf is unknown, too. As we want to estimate it, we are facing the decision-
making problem.
The selection of a suitable estimate ˆf(Θ|gt)(≡a pdf acting on Θ∗) ﬁts our
general decision-making framework as follows.
•
Q ≡(Pa∗, a, Fa∗) ≡

gt, ˆf(Θ|gt), f(Θ|ft(·))

≡
(stored statistic, posterior-pdf estimate, posterior pdf given by the un-
known empirical pdf ft(Ψ), Ψ ∈Ψ ∗).
•
Admissible decision rules are of the form
Rt : g∗
t →ˆf ∗≡

ˆf(Θ) :

ˆf(Θ) dΘ = 1, ˆf(Θ) ≥0, ∀Θ ∈Θ∗

.
Note that g0 is a known ﬁxed representation of the known prior pdf f(Θ)
and as such neither of them is explicitly mentioned as a part of the domain
of Rt.
•
The loss function is selected as the KL divergence (2.25) D( ˆf(Θ)||f(Θ|ft)).

54
3 Approximate and feasible learning
Formally, the optimal point estimate of the posterior pdf is
ˆf(Θ|gt) ∈Arg min
ˆ
f∈ˆ
f ∗E
	
D

ˆf(Θ)
!!!
!!! f(Θ|ft)
!!! gt

(3.27)
= Arg min
ˆ
f∈ˆ
f ∗
#
D

ˆf(Θ)||f(Θ)

−t

Θ∗

Ψ ∗
ˆf(Θ) ln[M(Θ, Ψ)]E[ft(Ψ)|gt] dΨ dΘ
$
.
The conditional expectation E[·|gt] is taken with respect to the uncertain
empirical pdf ft(Ψ), Ψ ∈Ψ ∗.
The minimizing argument can be found explicitly as
ˆf(Θ|gt) ∝f(Θ) exp

t

ln[M(Θ, Ψ)]E[ft(Ψ)|gt] dΨ

.
(3.28)
3.4.3 Speciﬁcation of E[ft(Ψ)|gt]
The estimate (3.28) depends only on the conditional expectation
ˆft(Ψ) ≡E [ft(Ψ)| gt] , Ψ ∈Ψ ∗.
(3.29)
Its choice and the resulting estimation are described in this subsection.
First we notice that the empirical pdf ft(Ψ) obeys the identity (3.24) that
is linear in it. Consequently, its conditional expectation ˆft(Ψ) = E[ft(Ψ)|gt]
has to fulﬁll it, too (recall, g0 is known)
gt =

h(Ψ)E [ft(Ψ)| gt] dΨ + g0 ⇔

(3.29)
gt −g0 =

h(Ψ) ˆft(Ψ) dΨ.
(3.30)
Obviously, ˆft(Ψ) has to be pdf. The identity (3.30) is the only objective knowl-
edge we have about it. Thus, it is reasonable to select it as close as possible
to the pdf describing prior information about ft(Ψ) while respecting the con-
straint (3.30).
Marginalization and the chain rule, Proposition 2.4, together with the
assumption (3.18) imply that the prior distribution on Ψ is
f(Ψ) =

f(Ψ|Θ)f(Θ) dΘ = f(ψ)

M(Θ, Ψ)f(Θ) dΘ.
There the pdf f(ψ) describes our prior information on possible regression
vectors. It can be taken as a ﬂat pdf with its support on ψ∗. The pdf M(Θ, Ψ)
is the model in question and f(Θ) is the chosen prior pdf on its parameters.
As usual, we measure the distance of ˆft(Ψ) to f(Ψ) with the help of the KL
divergence. Taking into account the constraint (3.30), we minimize
min
ˆ
f(Ψ)

ˆf(Ψ)

ln
0 ˆf(Ψ)
f(Ψ)
1
−v′
th(Ψ)

dΨ
(3.31)
= min
ˆ
f(Ψ)
D
⎛
⎝ˆf(Ψ)
!!!!!!
!!!!!!
f(Ψ) exp (v′
th(Ψ))

f( ˜Ψ) exp

v′
th( ˜Ψ)

d ˜Ψ
⎞
⎠−ln

f(Ψ) exp (v′
th(Ψ)) dΨ

,

3.4 Equivalence approach
55
where the vector vt of Lagrangian multipliers is to be selected so that (3.30)
is met. This requirement, the second form of the minimized functional and
properties of the KL divergence give the optimal ˆf(Ψ)
ˆf(Ψ) =
f(Ψ) exp (v′
th(Ψ))

f(Ψ) exp (v′
th(Ψ)) dΨ ,
(3.32)
with the vector vt solving the equation
gt −g0 =

h(Ψ) ˆft(Ψ) dΨ =
∂
∂vt
ln

f(Ψ) exp (v′
th(Ψ)) dΨ

.
This option completes the overall algorithm.
Algorithm 3.3 (Recursive equivalence estimation)
Initial (oﬄine) mode
•
Select the parameterized model f(∆t|at, d(t −1), Θ) ≡M(Θ, Ψt).
•
Select the prior pdfs f(Θ) and f(ψ).
•
Evaluate the prior pdf f(Ψ) = f(ψ)

M(Θ, Ψ)f(Θ) dΘ on Ψ ∗.
•
Select the generalized vector function G(Θ) such that

G(Θ) dΘ = 0.
•
Prepare the evaluation of the function
h(Ψ) ≡

ln(M(Θ, Ψ))G(Θ) dΘ.
(3.33)
•
Set g0 = 0.
Sequential (online) mode, running for t ∈t∗,
1. Measure data vector Ψt.
2. Evaluate ht ≡h(Ψt) ≡

ln(M(Θ, Ψt))G(Θ) dΘ.
3. Update the weights gt = gt−1 + ht.
4. Find the vector vt solving the equation (gt is known ﬁxed vector)
gt =
∂
∂vt
ln

f(Ψ) exp (v′
th(Ψ)) dΨ

5. Exploit the obtained approximation of the posterior pdf
ˆf(Θ|gt) ∝f(Θ) exp
#
ln(M(Θ, Ψ))f(Ψ) exp (v′
th(Ψ)) dΨ

f(Ψ) exp (v′
th(Ψ)) dΨ
$
.
(3.34)
Remark(s) 3.4
1. Zero value of the initial weights g0 reﬂects that the weights are always
determined by the increment gt −g0; see (3.32).
2. The name “equivalence approach” stresses the fact that the set of posterior
pdfs is reduced to equivalence classes. The pdfs with the same representa-
tion g cannot be distinguished.

56
3 Approximate and feasible learning
3. The required commutative updating and projecting of the posterior pdfs
is crucial. The recursion for gs is exact and the approximation errors
caused by the use of ˆf(Θ|gt) instead of f(Θ|d(t)) ≡f(Θ|ft(·)) do not
accumulate! Use of a noncommutative projection Gt : f ∗(Θ|d(t)) →g∗
t
is always endangered by a divergence as the estimation described by the
Bayes rule can be viewed as a dynamic system evolving f(Θ|d(t)) at the
stability boundary.
4. The indicated integrations represent the computationally most demanding
part of the algorithm. They can be performed in oﬄine mode if their results
can be eﬃciently stored (the resulting functions interpolated). The solution
of the nonlinear equation for vt is also hard, but is a standard problem.
5. We would like to get the exact posterior pdf if the model belongs to the
exponential family (3.6). This dictates the choice of the mapping G that
should make h(Ψ) = [B′(Ψ), 1]′. It is suﬃcient, to introduce the prior
initial moments of the vector function ˜C(Θ) ≡[C′(Θ), ln(A(Θ))]′
¯C ≡

˜C(Θ)f(Θ) dΘ, C ≡cov
	
˜C

=

˜C(Θ) ˜C′(Θ)f(Θ) dΘ −¯C ¯C′
and deﬁne the weighting function
G(Θ) ≡[ ˜C(Θ) −¯C]′C−1f(Θ).
Problem 3.1 (How to choose the mapping G?) The generalized functions
G represent the key tuning knobs of the approach. Options leading to discrete
versions of the function and/or its derivatives, or M(Θ, Ψi) on a grid of Ψi
have been tried with a success, but a deeper insight is needed in order to arrive
at a cookbook.
A possible direction can be found by approximating M(Ψ, Θ) by a member
from the exponential family and by using the recommendation given in step 5
in Remarks 3.4.
Problem 3.2 (Application of equivalence approach to mixtures) This
section describes how a correct approximate recursive estimation should look
like. As it will be seen in Chapters 6, 8, 10 and 12, we found no practical way
how to apply it to mixtures. Any progress in this respect would be invaluable.

4
Approximate design
Formally, the fully probabilistic design adopted for the design of advising
strategies is described by Proposition 2.11. The corresponding functional equa-
tion is rarely solvable in the high-dimensional multimodal cases considered.
Thus, speciﬁc approximation techniques are needed to get feasible strategies.
This chapter prepares such techniques that are exploited in Chapters 7 and 9
for the design of advising strategies.
The dynamic design essentially predicts possible behavior of the system
interacting with the judged strategy and selects the most favorable one. The
design complexity is signiﬁcantly inﬂuenced by the richness of the inspected
space. Its reduction is behind the majority of available approximation schemes
including those discussed in this chapter.
First, we relate an approximate design with the notion of adaptive systems,
Section 4.1. It provides us a common perspective on established approximate
designs that look otherwise as a “bag of tricks”. Section 4.2 lists the most
common techniques used. It will serve us a reference point in the design body
of the text (Chapters 7, 9, 11). The reader is referred to classical references
[1, 68, 89, 100] for a detailed presentation of adaptive systems.
Adaptive control has a relatively long history within which substantial ex-
perience has been accumulated. It guides designers on how to split this com-
plex decision-making task into a sequence of meaningful and solvable subtasks.
This “prototype line” is generalized in Section 4.3.
4.1 Adaptive systems
The ideal solution of the decision-making under uncertainty is described by
the combination of Bayesian ﬁltering (see Proposition 2.13) and dynamic pro-
gramming; see Propositions 2.9 and 2.11. The functional equations describing
them are mostly computationally infeasible and are solved approximately.
The involved multivariate functions should be represented in a computer,
i.e., in the device that can operate on a high but ﬁnite number of values. Thus,

58
4 Approximate design
a sort of approximation is needed. The global approximation of functions of
many variables that we are dealing with is known to be computationally hard.
On the other hand, the application of the strategies resulting from the design
requires knowledge of the discussed solutions only for the recorded experience.
Thus, it is suﬃcient to know them locally around the actual experience. Such
a local approximation can be identiﬁed with an adaptive system [101]. The
mixture model we use as well as its quasi-Bayes estimation (see Chapter 6)
follow exactly this direction. In this way, we get practically feasible learning.
Below, the localization principles used in the design are discussed.
4.2 Suboptimal design
The design complexity is the key issue addressed repeatedly at various places
of this text. At the design stage, the complexity stems from
•
richness of the space of the ignorance part of the behavior that has to be
inspected for the optimal selection of decisions;
•
complexity of models describing relationships of the experience and op-
tional decisions to ignorance part of the behavior.
The suboptimal design tries to reduce the inﬂuence of one or both of these
sources of complexity. The selected techniques described below are suitable to
the design of the adaptive advisory system.
4.2.1 Strategies examining reduced space
Here, we outline common techniques oriented on simpliﬁcation of the space
searched for.
Receding horizon
The reduction of the design horizon is the most direct way to a simpliﬁed
(suboptimal) design. The reduction obtained by planning just one-step-ahead
has been popular for a long time [102]. Dynamic decision-making, however,
means that consequences of a decision are encountered far behind the time
moment of its application. Consequently, the decision that is optimal when
judged from a short-sighted perspective might be quite bad from the long-term
viewpoint [68].
This observation has stimulated the search for a compromise between the
ideal planning over the whole horizon of interest and short-sighted, locally
optimizing strategies.
A little-steps-ahead planning provides just an approximation of the opti-
mal design. Thus, it is reasonable to apply just the initial planned decisions
and redesign strategy whenever a new information about the system and its

4.2 Suboptimal design
59
state is processed. This is the essence of the design technique called receding-
horizon strategy. Let us describe its algorithm in the case of additive loss
function (2.31) with the ﬁnite-dimensional observed information state xt and
for a prespeciﬁed value T of the receding horizon T < ˚t. Note that the infor-
mation state is generally composed of the observed state of the system and
statistics describing results of learning [103, 104].
Algorithm 4.1 (Receding horizon strategy)
Repeat for t ∈t∗≡{1, . . . ,˚t},
1. Find the rules Rt, . . . , Rt+T approximately minimizing
E
t+T

τ=t
z(xτ, aτ)
!!!!! Pa∗
t

using the available experience Pa∗
t ≡xt−1 and the outer model of the
system, Agreement 2.7.
2. Apply at ≡Rt(Pa∗
t ) for the available Pa∗
t .
3. Extend the experience by the new data ∆t, at and use them in learning —
perform ﬁltration or estimation, Propositions 2.13 or 2.14 — so that an
improved outer model of the system is obtained.
Iterations spread in time
It is intuitively clear and practically veriﬁed that the receding horizon T guar-
anteeing good approximation of the optimal design can be too large if the
decision horizon ˚t is large. In the case of additive loss, the asymptotic analysis
of the design, Proposition 2.12, shows that for ˚t →∞the optimal decision is
the minimizer in
⌊∞V(xt−1) + ⌊∞C = min
at∈a∗
t
E
	
z(xt, at) + ⌊∞V(xt)
!!! at, xt−1

.
This stationary form can be interpreted as one-step-ahead design for the
partial loss z(xt, at) increased by the stationary Bellman function
⌊∞V(xt).
Knowing the function ⌊∞V(xt), the design with receding horizon T = 1 is the
optimal one. At the same time, dynamic programming has been interpreted as
an iterative search for the Bellman function ⌊∞V(xt), Proposition 2.12. Thus,
we can use the Bellman function resulting from an approximate design at time
moment t −1 as an estimate of ⌊∞V(xt) at time moment t. Then, we perform
the receding-horizon design that has this estimate as its terminal condition,
i.e., increases the terminal partial loss. This allows us to use a short design
horizon T . This reasoning leads to the following approximate strategy.
Algorithm 4.2 (Strategy with iterations spread in time)
Initial (oﬄine) phase
Select an initial guess of the stationary Bellman function V0(x).
Iterative (online) phase repeated for t ∈t∗≡{1, . . . ,˚t}

60
4 Approximate design
1. Find the rules Rt, . . . , Rt+T approximately minimizing
E
t+T

τ=t
z(xτ, aτ) + Vt−1(xt+T −1)
!!!!! xt−1

using the available experience Pa∗
t stored in information state xt−1 and
the outer model of the system, Agreement 2.7. Evaluate these rules and
achieved minima Vt(x) for all possible states x ∈x∗in the role of xt−1.
2. Take the ﬁnal Bellman function Vt(x) resulting from this design as an
updated approximation of the stationary Bellman function.
3. Apply at ≡Rt(xt−1) for the measured information state xt−1.
4. Extend the experience by the new data ∆t, at and use them in learning —
perform ﬁltration or estimation, Propositions 2.13 or 2.14 — so that an
improved outer model of the system is obtained.
Predictive strategies
There is a whole set of strategies that drastically reduce the space of inspected
behaviors by working only with point predictions of uncertain quantities to
be inﬂuenced. Sometimes, they deal with set predictions using credibility sets
of a very simpliﬁed form. Such strategies are usually labelled as predictive
strategies [89, 105, 106, 107].
Let us consider an additive loss function with receding-horizon T. It serves
us an example demonstrating essence of these strategies. For minimization
purposes, the predictive strategies use the approximation
E
t+T

τ=t
z (xτ, aτ)
!!!!! Pa∗
t

≈
t+T

τ=t
z

˜xτ|Pa∗
t , aτ

,
with ˜xτ|Pa∗
t obtained from the uncertain future information state xτ by
approximating
∆τ ≈E[∆τ|Pa∗
t ] ≡˜
∆τ|Pa∗
t .
Obviously, such an approximation may be quite rough when there is a non-
negligible uncertainty caused either by lack of knowledge or by noise inﬂuence.
On the other hand, the gained simpliﬁcation allows the user to concentrate
on respecting hard bounds on actions or other quantities. The practical sig-
niﬁcance of physical constraints justiﬁes this simpliﬁcation and explains the
popularity of predictive strategies and its permanent use. Papers [108, 109]
serve as samples of such applications.
4.2.2 Strategies simplifying models
Let us consider the receding-horizon strategy applied at time t. Then, a sub-
stantial degree of the design complexity is caused by the use of predictive pdfs

4.2 Suboptimal design
61

f(∆τ|aτ, Pa∗
τ )
t+T
τ=t obtained through the Bayesian estimation. They have the
form (see Proposition 2.14)
f(∆τ|aτ, Pa∗
τ ) =

f(∆τ|aτ, Pa∗
τ , Θ)f(Θ|Pa∗
τ ) dΘ.
(4.1)
For a relatively short planning horizon T, the predictors (4.1) can be approx-
imated by
f(∆τ|aτ, Pa∗
τ ) ≈

f(∆τ|aτ, Pa∗
τ , Θ) ˆfτ(Θ) dΘ, τ = t, . . . , t + T,
(4.2)
with a simpler pdf ˆfτ(Θ) ≈f(Θ|Pa∗
τ ). Below we outline widespread versions
of ˆfτ(Θ) used.
Supercautious strategy
If the posterior pdf f(Θ|Pa∗
t ) is reasonably concentrated then it makes sense
to exploit the approximate equality
f(Θ|Pa∗
τ ) ≈f(Θ|Pa∗
t ) ≡ˆft(Θ), τ = t, . . . , t + T.
(4.3)
The receding-horizon strategy combined with the approximation of (4.2) and
(4.3) is called supercautious as it is based on the assumption that we learn
nothing about unknown parameters until the receding horizon. The uncer-
tainty of the parameter estimates (4.3) projected into the predictors through
the formula (4.2) inhibits excessive decision values. It makes the strategy su-
percautious.
Cautious strategy
The assumption (4.3) is often too strong. Then, it is reasonable to assume
that
f(Θ|Pa∗
τ ) ≈F(τ, f(Θ|Pa∗
t )) ≡ˆfτ(Θ), τ = t, . . . , t + T, Θ ∈Θ∗.
(4.4)
The mapping F(τ, ·) modiﬁes the posterior pdf f(Θ|Pa∗
t ) to another, more
concentrated, pdf. The mapping F is chosen beforehand and does not use
data belonging to the ignorance Fa∗
t . Typically, the generated pdf ˆfτ(Θ) has
the same ﬁrst moment (expectation) as f(Θ|Pa∗
t ), but its covariance Cτ|t
decreases with increasing distance τ −t in a prespeciﬁed way. Often,
Cτ|t = b(τ −t) × Ct ≡b(τ −t) × covariance determined by f(Θ|Pa∗
t ).
The following nonnegative functions b(j) serve as representative examples.
b(j) =
1
j + 1 or b(j) =

1 if j = 0
0 otherwise .
(4.5)
Such a choice can be seen as sharpening of the pdf f(Θ|Pa∗
t ) by taking its
power f λ−1
τ (Θ|Pa∗
t ) using a prespeciﬁed sequence {λτ ∈(0, 1)}t+T
τ=t .

62
4 Approximate design
Certainty-equivalence strategy
This strategy is the most widespread one. It gets the approximate predictive
pdf by replacing an unknown parameter in the parameterized model by its
current point estimate ˆΘt
f(∆τ|aτ, Pa∗
τ ) ≈f(∆τ|aτ, Pa∗
τ , ˆΘt), τ = t, . . . , t + T.
(4.6)
It corresponds to the approximate generalized Bayesian parameter estimate
f(Θ|Pa∗
τ ) ≈ˆft(Θ) ≡δ(Θ −ˆΘt), τ = t, . . . , t + T, where
(4.7)
δ(·) is Dirac delta function, a formal pdf of the measure with its support equal
to {0}.
Active strategies
All outlined strategies are passive strategies in the sense that the planned
decisions do not care about learning. At the same time, it is known (see [75,
76]) that the optimal strategy is dual strategy. It cares both about immediate
decisions and learning process in a balanced way. This stimulates a search for
measures that support learning. The resulting strategies are known as active
strategies. Two basic suboptimal ways are used for their design.
•
An external stimulating signal is fed into the closed loop. It is added to
optional quantities like inputs or set points. It improves learning conditions
at the cost of deteriorating the achievable quality.
•
A term reﬂecting learning quality even under a passive-type design is added
to the original loss function [104]. It is usually numerically demanding and
sensitive to the relative weight of the added term.
Problem 4.1 (Development of active strategies) Practical experience in-
dicates that the active strategies improve the overall performance just a little
for normal linear models. It can be shown, however, that passivity may result
in completely bad performance in the case of controlled Markov-chain models
[110]. The latter fact indicates possible problems in the context of mixture es-
timation as well as in hidden Markov-chains area [47]. Systematic attempts
to solve this diﬃcult problem are rare; see reference in [111]. The problem is
less pronounced in signal-processing applications where the discussed models
have been predominantly used. Their foreseen wider use for feedback advising
and control [64, 112] calls for a change of this state.
4.3 Decomposition of decision-making
Splitting of the decision-making task in subtasks is the known way to get
an approximation of the practically optimal design but the splitting violates

4.3 Decomposition of decision-making
63
golden decision-making rule — try to solve the problem at hand in its entirety
— and drives the solution from its optimum. Thus, a compromise has to be
searched for.
Lack of the formal tools for the decomposition leaves us with empirical
rules in this area. This makes us summarize here the experience we have
collected in this respect in a long-term project DESIGNER [65, 113, 114, 115].
The project tries to decrease the burden on designers of adaptive controllers
by creating algorithmic support for their prior tuning. It has led to “natural”
decomposition of the design we list below while generalizing it to wider set of
decision-making tasks. Each item in the list has been found as a relatively self-
containing decision subproblem. The majority of them have a good solution
for adaptive control based on normal linear controlled regression models. The
majority of them are newly addressed in this book in order to cope with the
mixture-based advising.
4.3.1 Oﬄine phase
The design, as any human activity, is iterative. The iterations should be mostly
made in the oﬄine phase of the design in order to minimize expenses related
to the commission of the proposed strategy.
The following indicative list of subtasks is solved, often with internal iter-
ations, until the user is satisﬁed.
Formulate the addressed problem
The formulation speciﬁes
•
the technical decision-making aims,
•
the system,
•
the available data, decisions, and innovations,
•
the physical and complexity constraints,
•
the knowledge available.
Perform experimental design and collect data for oﬄine analysis
This important subtask [116] is still weakly supported [117].
Preprocess data
Data preprocessing is an extensive area [118] with a lot of signiﬁcant
results; see e.g., [118, 119] and Sections 6.2, 8.2, 10.2.
Select the used class of parameterized models
The choice is mostly dictated by our ability to handle them. This text
provides tools for normal mixtures (Chapters 8 and 9) and Markov chains
(Chapters 10 and 11). Chapter 13 opens a way to treatment of their mixed
versions.
Quantify prior knowledge on unknown parameters
This is still an underestimated area with particular results in [65, 120] and
Section 6.3.
Estimate model structure
There are a lot of signiﬁcant result in this respect, e.g., [26, 65, 95, 121],
but the problem is far from being completely solved; see Section 6.6.

64
4 Approximate design
Estimate the period with which the actions are applied
The choice of the period for adaptive control is discussed in [122, 123] but
a general solution for a general multivariate case is missing.
Perform generalized Bayesian estimation
It combines theory behind the adopted models, prior knowledge, and avail-
able data; cf. [69], Proposition 2.14, and the mixture-tailored versions in
Sections 6.5, 8.5, 10.5. The results are used as the prior and/or alternative
pdf in online phase.
Estimate forgetting factor
The maximum a posteriori probability estimate on a discrete grid is used;
for instance, see Algorithm 6.2.
Validate estimation results.
Commonly, the achieved modelling quality is compared with that obtained
when using a wider model set. The quality is also compared with learning
and validation data [124]. Implementation of these ideas has no generally
accepted methodology. Thus, a whole range of variants is to be used; see
Section 6.7.
Transform the decision aims into the loss function
The class of loss functions is mostly determined by our ability to handle
it. The approximate expression of the aims is then achieved by the tun-
ing of optional knobs determining the loss function. Typically, weights of
quadratic loss and, generally, the parameters determining the ideal pdf in
fully probabilistic design have to be chosen. The iterative choice runs as
follows.
1. Select the test values parameters of the tuned parameters and design
the corresponding strategy.
The optimization-based selection of the test values seems to be ade-
quate [125].
2. Predict closed loop behavior.
The closed loop is formed by the coupling system with the considered
strategy. The prediction consists formally of transformation of all un-
certain quantities into the user-deﬁned quality indicators. Its formal
solution provides Proposition 2.5 but practically a Monte Carlo eval-
uation has to be employed [126]. It becomes feasible using sequential
stopping rules [94, 127, 128].
3. Compare predictions with user’s speciﬁcations.
Stop if the user’s speciﬁcations are met. Otherwise, go to Step 1 while
there are observable changes of indicators; otherwise, demand changes
in the problem speciﬁcation.
Validate the design results
Again, no complete established formal methodology is available but a
range of particular tests can be made, Section 7.4, often based on extensive
simulations combined with Monte Carlo techniques.

4.3 Decomposition of decision-making
65
4.3.2 Online phase
The decision-making subtasks listed here are solved in real time for t ∈t∗.
Thus, there is almost no freedom for iterative trial-and-error solutions. Of
course, it is wise to store the data collected during the online phase and use
them for an improved oﬄine design. The processing proceeds as follows.
•
Collect and preprocess data.
•
Generate reference signals.
•
Estimate the parameters with stabilized forgetting; see [88] and Section
3.1.
•
Use receding-horizon or iterations-spread-in-time design, in an appropriate
version; Section 4.2;
•
Generate the action using the designed strategy and measured data.
•
Check possible discrepancies and make a ﬁner tuning of optional param-
eters of the design; this supervision can be based on the theory discussed
in this book.
Problem 4.2 (Completion of the design support) The presented outline
shows the complexity of the overall design chain. Some steps are weakly sup-
ported by theory and algorithms. Others are solved for linear normal models
only. Some of them are not supported at all. Our experience indicates that
the systematic solution of the design support pays back. The completion and
generalization of this support represent a research challenge with a signiﬁcant
potential impact on the resulting quality of decision-making.

5
Problem formulation
This chapter formulates the problem of the design of an advisory system and
outlines its conceptual solution. The interconnection of the managed system
with its operator is modelled by the ﬁnite mixture model. Its optional parts
are optimized so that the resulting mixture model is as close as possible to
management aims expressed by a user’s ideal pdf in a fully probabilistic sense,
cf. 2.4.2. The resulting mixture is oﬀered to the operator as the recommended
ideal pdf to be followed. Unlike the user’s ideal pdf, the state described by
the recommended ideal pdf can be practically achieved.
The application of this conceptually simple design requires formulation
and solution of a sequence of particular technical steps. Their description
forms the content of this chapter.
Design conditions and adopted design principles are clariﬁed in Section
5.1. Special attention is paid to relationships of data spaces accessible to the
operator and to the advisory system. Also, necessary reductions and exten-
sions of involved data spaces are proposed there. The learning conditions we
assume are speciﬁed in Section 5.2. Dynamic predictions, forming a bridge
between learning and advising parts, are discussed in Section 5.3. The design
of advices oﬀered to the operator is described in Section 5.4. Basic types of
advisory systems diﬀering in the extent of optional ingredients of the modiﬁed
model are classiﬁed there. The design of the presentation part of the advisory
system is in Section 5.5. Learning and design steps, which form the backbone
of detailed solutions presented in Chapters 6 and 7, are summarized in Section
5.6.2.
5.1 Design principle and design conditions
This section introduces notions needed for formalization and solution of the
addressed design problem.

68
5 Problem formulation
5.1.1 Systems and data spaces
We start with inspection of relationships of the managed system, its operator,
and the constructed advisory system. The following agreement introduces ﬁxes
notions.
Agreement 5.1 (Nomenclature of systems)
The system managed by
the operator is called the m-system. The closed loop formed by the m-system
and its operator (supervisor) is called the o-system. The advisory system
transforming the data measured on the o-system into advices to the opera-
tor is called the p-system; see Fig. 5.1.
If need be, the quantities related to m-, o-, and p-systems are distinguished
by preﬁxes m-, o-, and p- or by subscripts m, o, and p.
Out of this chapter, we deal mostly with the data handled by the p-system.
Then, their subscript p is dropped if there is no danger of misunderstanding.
Formulation and solution of the overall design need clariﬁcation of rela-
tionships among quantities dealt with by the o- and p-systems.
Agreement 5.2 (Data, observation, and action spaces) Values of the
quantities available to the operator form the data space of the operator d∗
o(˚t).
This space is the Cartesian product of the observation space of the operator
∆∗
o(˚t) — formed by the innovations ∆o(˚t) available to the operator; see Section
2.2 — and of the action space of the operator a∗
o(˚t), i.e., d∗
o(˚t) ≡(∆∗
o(˚t), a∗
o(˚t)).
Values of the quantities available to the advisory system form the data
space of the advisory system d∗
p(˚t). This space is the Cartesian product of the
observation space of the advisory system ∆∗
p(˚t) and of the action space of the
advisory system a∗
p(˚t), i.e., d∗
p(˚t) ≡(∆∗
p(˚t), a∗
p(˚t)).
Values of the quantities available to the operator but unavailable to the
advisory system form the surplus data space of the operator d∗
o+(˚t) ≡d∗
p(˚t) ∪
d∗
o(˚t) \ d∗
p(˚t).
Values of the quantities available to the advisory system but unavailable
to the operator form the surplus data space of the advisory system d∗
p+(˚t) ≡
d∗
p(˚t) ∪d∗
o(˚t) \ d∗
o(˚t); see Fig. 5.1.
Note that the possible nonemptiness of the surplus data spaces singles
out the addressed problem from the standard formulation of decision-making.
Obviously, the design of the advisory system is meaningful only when the p-
and o-data spaces overlap.
Requirement 5.1 (Overlap of data spaces) The data spaces available to
the operator d∗
o(˚t) and to the advisory system d∗
p(˚t) have a nonempty intersec-
tion d∗
op(˚t) ̸= ∅. Thus,
d∗
o(˚t) = d∗
op(˚t) ∪d∗
o+(˚t),
d∗
op(˚t) ∩d∗
o+(˚t) = ∅,
d∗
p(˚t) = d∗
op(˚t) ∪d∗
p+(˚t), d∗
op(˚t) ∩d∗
p+(˚t) = ∅,
where
(5.1)
d∗
o+(˚t) is the surplus data space of the operator and d∗
p+(˚t) is the surplus data
space of the advisory system.

5.1 Design principle and design conditions
69
CLOSED LOOP: o−SYSTEM
MANAGED: m−SYSTEM
OPERATOR
common o−& p−data
innovations
actions
op
aop
surplus p−data
innovations
p+
p−actions
advices ap
ADVISORY:
p−SYSTEM
surplus o−data
innovations actions
o+
ao+
common p−& o−data
d op
uo
recognizable actions uo
Fig. 5.1. Relationships of systems and data spaces: Agreements 5.1, 5.2, 5.7.
5.1.2 Basic scenario and design principle
The following basic scenario is considered within the time span determined
by a horizon ˚t ≤∞.
The operator handling the m-system deals with a sequence do(˚t) of the
o-data. A nonempty part of the data record do;t is formed by operator’s actions
ao;t ∈a∗
o. The rest consists of innovations ∆o;t, i.e.,
do;t = (∆o;t, ao;t) ≡(o-innovations, o-actions).
Formally, the operator implements the causal strategy

d∗
o(t −1) →a∗
o;t

t∈t∗.
The strategy of the operator is to be judged according to the expected value
E of a loss function
Z : d∗
o(˚t) →[0, ∞]
(5.2)
that reﬂects the management aims. The real operator’s strategy is usually
chosen informally, but the joint pdf f(do(˚t)) would be the adequate description
of the o-system needed for the formal evaluation of the operator’s strategy;
see Chapter 2.
The p-system works on a sequence of the p-data dp(˚t). Each record dp;t
contains data items dpi;t, i ∈i∗≡{1, . . . , ˚
dp} with either real or discrete
values. The record dp;t ≡(∆p;t, ap;t) includes p-innovations ∆p;t, observed by
the p-system on the o-system and actions, of the p-system ap;t, called advices.
The p-system implements its causal strategy

d∗
p(0), d∗
p(t −1) →a∗
p;t

t∈t∗,
where dp(0) denotes experience collected before using the p-system.
The p-system strategy is designed so that the o-system accepting advices
achieves the smallest expected loss (5.2).

70
5 Problem formulation
Agreement 5.3 (Guided and unguided o-system) The interconnection
of the o-system with the p-system creates a new guided o-system. We shall
use also the mirror term unguided o-system for the o-system working without
a p-system.
The adjectives guided and unguided are also used in connection with the
corresponding models, behaviors, situations, etc. For instance, unguided model
and guided model mean the model of the unguided and guided o-system,
respectively.
The complete outer description of the guided o-system is given by the
joint pdf f(dp(˚t), do+(˚t)) of all involved data (dp(˚t), do+(˚t)), cf. (5.1). The
structure of the discussed interconnection is predominantly determined by the
communication ways of the managed system, the operator and the advisory
system. The m-system
•
provides its o-innovations to the operator as responses to the o-actions,
•
oﬀers some data to the p-system that generally diﬀer from do;t,
•
is indirectly inﬂuenced by the p-system through the o-actions that are
stimulated by advices, i.e., by actions of the p-system.
We would like to design the p-system that guides the operator to make the
expectation of the loss function (5.2) as small as possible. The advisory system
cannot force the operator to follow its advices. The p-system can only present
a “target” to be reached. The advices will be useful if the operator is able
to respect them, i.e., if the advised target is reachable by the cooperating
operator. Both the design of the p-system and presentation of advices can be
done in a systematic way if we adopt the fully probabilistic design; see Section
2.4.2. It determines the way we intend to stimulate the operator.
The ideal pdf in the sense of the fully probabilistic design, Agreement 2.7,
is adopted as the optimized target oﬀered to the operator.
The corresponding conceptual algorithm implementing this design princi-
ple looks as follows.
Algorithm 5.1 (Design principle of the advisory system)
1. Express managing aims as the user’s ideal pdf ⌊Uf

dp(˚t), do+(˚t)

.
2. Estimate an outer multimodal model f(dp(˚t), do+(˚t)) describing relation-
ships among the considered data (dp(˚t), do+(˚t)).
3. Create the ideal pdf ⌊If

dp(˚t), do+(˚t)

that
•
is as close as possible to the user’s ideal pdf
⌊Uf

dp(˚t), do+(˚t)

; the
KL divergence is used as the proximity measure,
•
inherits those constituents of the pdf f

dp(˚t), do+(˚t)

describing an
unguided o-system that cannot be changed even by the fully cooperat-
ing operator that implements the randomized strategy recommended to
him.

5.1 Design principle and design conditions
71
The left superscript I marks the resulting ideal pdf and its optimized
constituents.
4. Present low-dimensional projections of the ideal pdf ⌊If

dp(˚t), do+(˚t)

as
the “target” to be followed by the operator.
Remark(s) 5.1
1. The applicability of Algorithm 5.1 depends on the possibility of creating
the involved elements practically. This nontrivial task is solved gradually
in subsequent sections.
2. The focus on a fully probabilistic design allows us to deal with a uniform
probabilistic description of learning, design, and advising.
3. The optimization with properly preserved elements of the m-system guar-
antees that a good past practice can be followed. The ideal pdf, constructed
in the outlined way,
•
is reachable,
•
relates all observed consequences to their observed causes unlike human
being can.
5.1.3 Reduction of surplus data of the operator
Algorithm 5.1 deals formally with all data occurring in the guided system, i.e.,
with the union of p- and o-data. This subsection shows that, in the design of
the p-system, we need not model the surplus o-data do+(˚t).
The p-system has no information on d∗
o+(˚t). Thus, it has to leave this part
of the o-behavior to its fate. In other words, the strategy of the p-system, de-
signed without considering the surplus o-data, implies that their distribution
has to be accepted as the ideal one. Formally, it restricts the constructed ideal
pdf ⌊If(·) by the requirement
⌊If

do+(˚t)|dp(˚t)

≡f

do+(˚t)|dp(˚t)

.
(5.3)
The objective pdf f(do+(˚t)|dp(˚t)) (see Chapter 2) describes the data do+(˚t)
unavailable to the p-system.
According to the concept of the fully probabilistic design, the distance of
the pdf describing the inspected behavior to its ideal pdf is measured through
the KL divergence (2.25). In this context, the requirement (5.3) implies a
simple but important consequence.
Proposition 5.1 (Ideal pdf oﬀered by the advisory system) Let the ideal
pdf
⌊If(dp(˚t), do+(˚t)) oﬀered by the advisory system meet the requirement
(5.3). Then,
D

f
!!!
!!! ⌊If

≡

f(dp(˚t), do+(˚t)) ln
 f(dp(˚t), do+(˚t))
⌊If(dp(˚t), do+(˚t))

d(dp(˚t), do+(˚t))

72
5 Problem formulation
=

f(dp(˚t)) ln
 f(dp(˚t))
⌊If(dp(˚t))

ddp(˚t) and
(5.4)
D

⌊If
!!!
!!! f

≡

⌊If(dp(˚t)) ln
 ⌊If(d0p(˚t))
f(dp(˚t))

ddp(˚t).
Thus, for our design purposes, the outer description of the o-system f(·) and
the optimized ideal pdf ⌊If(·) have to be speciﬁed on d∗
p(˚t) only.
Proof. Using the basic rules for pdfs — the chain rule and normalization; see
Proposition 2.4 — we can directly verify the following identities
D

f
!!!
!!! ⌊If

≡

f(dp(˚t), do+(˚t)) ln
 f(dp(˚t), do+(˚t))
⌊If(dp(˚t), do+(˚t))

d(dp(˚t), do+(˚t))
=

chain rule

f(do+(˚t)|dp(˚t))f(dp(˚t))
×
ln

f(do+(˚t)|dp(˚t))f(dp(˚t))
⌊If(do+(˚t)|dp(˚t)) ⌊If(dp(˚t))

d(dp(˚t), do+(˚t))
=

(5.3)

f(do+(˚t)|dp(˚t))f(dp(˚t)) ln
 f(dp(˚t))
⌊If(dp(˚t))

d(dp(˚t), do+(˚t))
=

normalization, Proposition 2.4

f(dp(˚t)) ln
 f(dp(˚t))
⌊If(dp(˚t))

ddp(˚t).
The equality for D
 ⌊If||f

can be proved in the same way.
Consequently, the accepted condition (5.3) allows us to leave the surplus
data space of the operator d∗
o+(˚t) completely out of our consideration. Thus,
under (5.3), the design results obtained for empty and nonempty d∗
o+(˚t) are the
same. Notation is, however, simpler if d∗
o+(˚t) = ∅. In this case, the deﬁnition
(5.1) implies
d∗
o(˚t) = d∗
op(˚t) ⇒d∗
o(˚t) ⊂d∗
p(˚t).
(5.5)
From now on, we adopt this formal simpliﬁcation that the surplus data space
of the operator d∗
o+(˚t) is empty and thus the data space of the operator d∗
o(˚t)
is a subset of the data space of the advisory system d∗
p(˚t).
5.1.4 Construction of a true user’s ideal pdf
The considered design of an optimal advisory system assumes that the aims of
management and advising can be expressed by the user’s ideal pdf describing
the desired behavior of the p-data dp(˚t).
The user expresses its aims in terms of quantitative indicators, called qual-
ity markers, that can be evaluated using the o-data only. The quality markers
m(˚t) ∈m∗(˚t) qualify behavior of the o-system through a known function

5.1 Design principle and design conditions
73
d∗
o(˚t) →m∗(˚t) ≡(partially) ordered space.
(5.6)
Desired properties of quality markers, expressing management aims, are as-
sumed to be “translated” into the true user’s ideal pdf ⌊Uf(do(˚t)) that charac-
terizes desired distribution of o-data available to the operator. The following
“translation” methods are at our disposal.
•
A simple, typically normal, pdf is chosen. Set point for do;t is deﬁned as
its mean. Covariance matrix is chosen so that the signiﬁcant probability
is allocated to the multivariate interval covering desirable ranges of
do-entries.
•
A simple, typically normal, model is estimated on historical records do(˚to)
and its mean is replaced by the desired set-point. The covariance is shrunk
so that a desirable improvement is enforced.
Remark(s) 5.2
1. A Monte Carlo-based translation, as elaborated in connection with
DESIGNER project [126], can be also used.
2. Within this book, the true user’s ideal pdf is taken as unimodal pdf. Re-
cently, it was found that the adopted fully probabilistic design can be prac-
tically applied even when the user’s ideal pdf is a ﬁnite mixture [129, 130].
This extends applicability of the fully probabilistic design on decision-
making problems with multiple criteria!
Problem 5.1 (Advising on internal quantities) Generally, the user cares
about inner, directly unobservable states, too. The operator has to guess them
using observed data and also optimize behavior of these estimates. Finally, the
observed-data dependent loss function is optimized. For simplicity, the advis-
ing is formulated directly as the data-driven design, cf. Agreement 2.8. The
relevant theory should, however, be extended explicitly to the case when the
operator deals with internal, considered but directly unobservable states, too.
5.1.5 Extension of a true user’s ideal pdf to
the surplus p-data
The adopted condition (5.5) implies that an implementation of conceptual
Algorithm 5.1 requires speciﬁcation of a user’s ideal pdf ⌊Uf(·) on the data
space of the advisory system d∗
p(˚t). The true user’s ideal pdf is, however,
deﬁned “naturally” on the data space of the operator d∗
o(˚t) ≡d∗
op(˚t); see (5.5)
and Section 5.1.4. At the same time, the fact that the advisory system deals
with a wider data set than the operator should be exploited for reaching a
better quality of advices. Thus, it is necessary to extend the user’s ideal pdf
from d∗
o(˚t) to d∗
p(˚t).
By deﬁnition, the operator is not aware and consequently interested in
the surplus data of the advisory system dp+(˚t). Thus, the operator has to

74
5 Problem formulation
leave this surplus data to the fate determined by the managed system and the
inﬂuence of the advisory system. It leads us to the choice
⌊Uf(dp(˚t))
=

chain rule
⌊Uf(dp;˚t|dp(˚t −1)) ⌊Uf(dp(˚t −1))
=

(5.1),(5.5)
= ⌊Uf(do;˚t|dp+;˚t, dp(˚t −1)) ⌊Uf(dp+;˚t|dp(˚t −1)) ⌊Uf(dp(˚t −1))
≡⌊Uf(do;˚t|dp+;˚t, dp(˚t −1)) ⌊If(dp+;˚t|dp(˚t −1)) ⌊Uf(dp(˚t −1))
≡⌊Uf(do;˚t|do(˚t −1)) ⌊If(dp+;˚t|dp(˚t −1)) ⌊Uf(dp(˚t −1))
=
 
t∈t∗
⌊Uf(do;t|do(t −1)) ⌊If(dp+;t|dp(t −1)).
(5.7)
The ﬁrst equivalence in the third row means that d∗
p+;˚t is left to its fate: the
operator leaves the p-system to identify this part of the user’s ideal pdf with
the option made by the p-system. The second equivalence in the third row says
that the user’s ideal pdf on d∗
o;˚t is constructed irrespective of the inaccessible
values in d∗
p+(˚t). The ﬁnal identity in (5.7) is adopted as a basic assumption.
Remark(s) 5.3
1. This subsection completes construction of the user’s ideal pdf on the union
of data spaces needed in the ﬁrst step of Algorithm 5.1. Step 2 is discussed
in Section 5.2 and elaborated in Chapters 6, 8, and 10. Steps 3 and 4 are
covered by Sections 5.4 and 5.5 and elaborated in Chapters 7, 9, and 11.
2. Operator may be aware of but uninterested in some entries of do;t. Then,
they can be formally thought as entries in the surplus data space of an
operator.
3. The designer may use the entries of p-data as tuning knobs in design.
This option is indeed exploited when we try to create a user-friendly ad-
visory system that controls the burden on the operator. For instance, the
frequency of changes in advising is kept low.
5.2 Learning conditions
The design of the advisory system relies on a good mixture model of the
o-system. This sections discusses necessary modelling and learning conditions
we suppose to be met.
Before progressing in a formal way, it is worth stressing the following facts.
The need for any advisory system arises when there are good and bad modes
in managing the considered m-system.
The chance to design a good advisory system exists if both good and bad
modes are reﬂected in its data space d∗
p. It implies that the pdf f(dp(˚t))
describing d∗
p(˚t) completely is expected to have multiple modes.

5.2 Learning conditions
75
The possibility to design an eﬃcient advisory system arises if the available de-
sign experience contains well-pronounced information about all signiﬁcant
operation modes that may occur while the operator handles the managed
system. In other words, the data providing this experience have to be rich
and informative.
The top position of the operator in the control hierarchy implies (see Chapter
1) that the experience of the advisory system is to be predominantly data-
based.
The rate of the operator’s actions is often (much) slower than the sampling
rate of the sensors and controllers within the m-system. Consequently, all
considered data can be and should be grouped or reduced to a sequence
generated with the rate of the operator’s actions. We suppose it done.
The experience of the p-system also includes surplus data of the advisory
system d∗
p+(˚t) ≡d∗
p(˚t) \ d∗
o(˚t). They are directly at the disposal of the
advisory system but not to the operator. These data may be invaluable in
discovering various operating modes. They have to be considered in the
design of any eﬃcient p-system. Consequently, we have to deal with all
data dp(˚t) and thus we can mostly drop the subscript p further on and
adopt the identity
d(˚t) ≡dp(˚t).
(5.8)
The general theory (see Chapter 2) and the above discussion imply that
a multiple-mode pdf f(d(˚t)|d(0)) is the description required for a design of
the considered advisory system. The condition d(0) ≡dp(0) stands for the
experience available to the p-system before its use. Further on, d(0) is ﬁxed and
formally included into d(˚t), Then, the notation can be simpliﬁed by “hiding”
d(0).
The pdf f(d(˚t)) can be factorized according to the chain rule f(d(˚t)) =
/
t∈t∗f(dt|d(t −1)). The assumed low action rate of the operator implies
that the faster dynamics of the system is diminished in the grouped or re-
duced data. Thus, slow transitions among quasi-steady-state working points
are modelled. This can be well described by a Markov model of a ﬁnite order.
Thus, we can assume that the unguided o-system is described by the joint pdf
f(d(˚t)) =
 
t∈t∗
f(dt|φt−1), where
φt ∈φ∗, t ∈t∗, are known ﬁnite-dimensional vectors called observable states.
The intended online use of the advisory system implies that we have to
deal with models containing φt that can be evaluated in a recursive manner,
i.e., φt = Φ(φt−1, dt) with a known function Φ.
The advisory system can be successful only if the relationships learned
from experience are valid almost permanently. Thus, we have to assume that
the outer model {f(dt|φt−1)}t∈t∗, Agreement 2.7, of the unguided o-system
built on the p-data dt ≡dp;t is time invariant.
It is known that the needed multiple-mode probabilistic models can
(almost) always be approximated by a ﬁnite mixture of unimodal models [49],

76
5 Problem formulation
called components. We estimate this model using — at least approximately
— the standard Bayesian methodology.
For reference purposes, we summarize learning conditions adopted in the
construction of the advisory system.
Requirement 5.2 (Learning conditions for the design)
1. The data space d∗(˚t) of the advisory system (the p-system) has a nonempty
intersection with the data space d∗
o(˚t) of the o-system.
2. The sampling rate is harmonized with the operating rate. The number ˚
d
of data items sent to the p-system at each time moment is ﬁxed.
3. No attempt is made to inﬂuence quantities lying in the data space of the
o-system and being out of the data space of the p-system.
4. The pdf on records d(˚t), available to the p-system, is modelled by the pdf
f(d(˚t)|Θ) ≡/
t∈t∗f(dt|φt−1, Θ), where the pdf f(dt|φt−1, Θ), determined
by the measurable state φt−1 and by the parameter Θ, is a time invariant
ﬁnite mixture; see (5.9) below.
5. The approximate Bayesian learning described in Section 6.5 provides the
pdf f(d(˚t)) ≡f(d(˚t)|d(0)) = /
t∈t∗f(dt|d(t −1)) needed for the design of
the p-system.
The ﬁnite mixture approximating distribution of data d(˚t) with multiple
modes is assumed to have the form
f(d(˚t)|Θ) ≡
 
t∈t∗
f(dt|φt−1, Θ) with ﬁnite mixtures as parameterized models
f(dt|φt−1, Θ) ≡

c∈c∗
αcf(dt|φc;t−1, Θc, c), c∗= {1, . . . ,˚c}, ˚c < ∞,
(5.9)
f(dt|φc;t−1, Θc, c)is called component given by parameters Θc and the state
φc;t = Φc(φc;t−1, dt), i.e., the state φc;t−1 can be recursively updated data dt,
αc ≡the probabilistic component weight
Θ ≡mixture parameter formed by component parameters and weights in
Θ∗≡
"
{Θc ∈Θ∗
c}c∈c∗, α ≡[α1, . . . , α˚c] ∈α∗≡
"
αc ≥0,

c∈c∗
αc = 1
%%
.
The mixture parameter Θ = [αc, Θc]c∈c∗may also include the number of
components ˚c.
The entries of dt can be permuted in each component and some permu-
tations may lead to parameterizations with fewer parameters. It makes us
include into the model description the permutations
d →dc with dic = djic,
(5.10)
where jic is ith entry of the permuted indexes [1, . . . , ˚
d].
The assignment (5.10) is applied component-wise and together with the
chain rule, Proposition 2.4, give

5.2 Learning conditions
77
f(dt|φc;t−1, Θc, c) =
 
i∈i∗
f(dic;t|d(i+1)···˚
dc;t, φc;t−1, Θic, c)
≡
 
i∈i∗
f(dic;t|ψic;t, Θic, c).
(5.11)
The additional subscript i of the parameter Θic indicates that only some
entries of Θc may occur in the ith pdf predicting the ith scalar entry of dic;t.
Similarly, the introduced regression vector ψic;t is generally a subvector of the
vector
[d(i+1)c;t, . . . , d˚
dc;t, φ′
c;t−1]′.
(5.12)
Now we can ﬁx nomenclature related to the mixture.
Agreement 5.4 (Nomenclature related to mixtures)
Pdfs: The pdf f(dt|φc;t−1, Θc, c) in (5.9) is called the parameterized compo-
nent of a mixture and αc is the weight of the cth parameterized compo-
nent.
The pdf f(dic;t|ψic;t, Θic, c) in (5.11) is called the parameterized factor.
A parameterized factor occurring in several components is the common
parameterized factor.
Factors are called the adjacent factors if d(i+1)c;t is in the regression vector
of the factor predicting dic;t or vice versa.
The predictive pdf f(dt|d(t −1), c) is called the component.
The predictive pdf f(dic;t|d(i+1)···˚
dc;t, d(t −1), c) is called the factor.
The pdf f(Θic|d(t)) is called the factor estimate.
The pdf f(Θc|d(t)) is called the component estimate.
The pdf f(α|d(t)) is called the component-weight estimate.
The pdf f(Θ|d(t)) is called the mixture estimate.
The estimate is called the prior estimate if t = 0.
The estimates are called posterior estimates if t ∈t∗. Often, the posterior
estimate is called the estimate only.
Data: The vector dt containing data measured at time t is called the data
record.
The predicted scalar quantity dic;t is called the output of the factor.
The entry di;t, i = 1, . . . , ˚
d, of the data record dt is also called the ith data
channel or simply the ith channel. These terms are used in the implemen-
tation context.
Data entries that never play the role of the output of a factor are called
nonmodelled data.
The vector φc;t−1, that can be updated recursively using the newest data
dt, is the observable state of the parameterized component.
The parameterized factor is determined by the regression vector ψic;t
formed by a subselection of entries from the vector [d(i+1)···˚
dc;t, φ′
c;t−1]′
(5.12).
The coupling Ψic;t ≡[dic;t, ψ′
ic;t]′ is called the data vector of the factor.

78
5 Problem formulation
The data vector Ψ is in the phase form if it consists of a selection of entries
from the data record dt and its several delayed values dt, . . . , dt−∂, ∂∈
∂∗≡{0, 1, . . . , ˚∂}, ˚∂< ∞. The corresponding state vector φt−1 is also
said to be in the phase form.
Structures: Model structure is deﬁned in a hierarchical way starting from the
simplest elements, i.e., factors.
The list of regressors, meaning the entries of the regression vector of a
parameterized factor, is called the structure of the parameterized factor.
The structure of the parameterized factor in the phase form is the list of
pairs (j, ∂j) stating that dj;t−∂j, ∂j ∈∂∗, belongs to the data vector Ψt.
The structure of the parameterized component is an ordered list of factors
creating it. The order characterizes the chosen permutation (5.10).
Structure of the parameterized mixture is the list of parameterized com-
ponents creating it.
Remark(s) 5.4
1. The introduced factors, predicting individual entries of the modelled data,
•
provide ﬂexibility of the parametric description,
•
allow us to jointly describe continuous and discrete valued quantities,
•
permit us to respect dependencies reﬂected in several components,
•
open a way for use of diﬀerent models for diﬀerent entries of dt.
2. The adopted dynamic mixture model is not suﬃciently general. The com-
ponent weights should also depend on the state vector. The choice is driven
by our inability to estimate this “natural” and more realistic model. This
important aspect is discussed more deeply in Section 5.3. The restrictive
assumption is partially relaxed in Chapter 13.
3. The modelled p-data may contain a part that is not in the data space of
the o-system. Some of them might just bring complementary information
and their evolution need not be modelled. They are used only as entries
in the state vectors φt. In this way, the introduced nonmodelled data may
arise. It is worth stressing that their use is limited more or less to one-
step-ahead predictions. Otherwise, such quantities have to be modelled as
their predictions are needed.
4. Redundancy and contradictions in speciﬁcation of structures have to be
checked when being deﬁned.
5. Let us assume that
dt ∼Ndt
#
θ
0
$
,
#
r1 r12
r12 r2
$
,
where the symbol ∼expresses that the two-dimensional vector dt is dis-
tributed according to the normal pdf Nd(µ, R) with the expectation µ and
covariance matrix R. The scalar parameter θ ̸= 0 determines µ.
It is straightforward to show that both possible factorized parameteriza-
tions diﬀer in the number of parameters whenever r12 ̸= 0. This provides

5.3 Mixtures as approximate models and predictors
79
the counterexample to the conjecture that the number of parameters to be
estimated does not depend on the order of factors. Thus, the notation of
the component structure as an ordered list of factors is meaningful.
6. Formally, the measured data, the mixture model and a suitably speciﬁed
prior pdf allow us to get the needed model of the unguided o-system f(d(˚t))
through the Bayesian estimation and prediction. Practically, the estima-
tion of mixture models on tens of thousands of records dt with tens of
entries is computationally very intensive. Thus, we are forced to use an
approximations developed in detail in Section 6.5.
5.3 Mixtures as approximate models and predictors
The considered mixture has dynamic components but constant weights. They
express that the cth component of the o-system is active for 100 × αc% of
the operating time. The adopted model (5.9) allows mutually independent
as well as past-state-independent changes of active components at any time
moment. For dynamic mixtures, this is an “unnatural” choice. The restriction
to constant component weights has a pragmatic motivation. The assumption
of constant α and a proposal as to how to weaken it are discussed here. A
more systematic attempt to avoid this restriction is given in Section 13.2.
Let us consider that the parameterized model is a projection of a more
complex model labelled by Θ and by an additional parameter M ∈M ∗≡
∪c∈c∗M ∗
c where the ﬁnite collection of sets {M ∗
c }c∈c∗covers M ∗, i.e.
M ∗
c ∩M ∗
˜c = ∅for c ̸= ˜c. Then,
f(dt|d(t −1), Θ) =

f(dt, M|d(t −1), Θ) dM
=

f(dt|d(t −1), Θ, M)f(M|d(t −1), Θ) dM
=

c∈c∗

M ∗
c
f(dt|d(t −1), Θ, M)f(M|d(t −1), Θ) dM. (5.13)
Let us assume that for each c ∈c∗there is an Mc ∈M ∗
c for which the
following approximation
f(dt|d(t −1), Θ, M) ≈f(dt|d(t −1), Θ, Mc) ≡f(dt|d(t −1), Θc, c)
is good for all M ∈M ∗
c and for all possible data sequences d(t), t ∈t∗. Using
this assumption, we arrive at the ﬁnite mixture with data-dependent weights
f(dt|d(t −1), Θ) ≈

c∈c∗
f(dt|d(t −1), Θc, c)˜αc(d(t −1), Θ),
(5.14)

80
5 Problem formulation
where
˜αc(d(t −1), Θ) =

M ∗
c
f(M|d(t −1), Θ) dM
= Probability(M ∈M ∗
c |d(t −1), Θ) ≡f(M ∗
c |d(t −1), Θ).
The approximating mixture on the right-hand side of (5.14) has to be pdf. The
individual components are pdfs; thus the right-hand side of (5.14) becomes
pdf iﬀwe assume 2
c∈c∗˜αc(d(t −1), Θ) = 1 for all d(t −1). In order to
make the consequences of this condition explicit, we write ˜αc(d(t−1), Θ) as a
normalized product of constant probabilistic weights αc and of a nonnegative
parameterized functions of data βc(d(t −1), Θ)
˜αc(d(t −1), Θ) =
αcβc(d(t −1), Θ)
2
˜c∈c∗α˜cβ˜c(d(t −1), Θ).
The mixtures with constant component weights are obtained if the functions
{βc(·)}c∈c∗are constant. If they really depend on data, we get the mixture
f(dt|d(t −1), Θ) =

c∈c∗
αc
f(dt|d(t −1), Θc, c)βc(d(t −1), Θ)
2
˜c∈c∗α˜cβ˜c(d(t −1), Θ)
.
(5.15)
For nontrivial βc(·), the components of the mixture (5.15) do not belong to
the exponential family so that their eﬃcient estimation on large data sets is
extremely diﬃcult. Consequently, no eﬃcient algorithm for estimation of the
overall mixture is known except a novel attempt in Section 13.2.
We show, however, that our restricted model (5.9) with constant weights
can be interpreted as a limit of the model (5.14).
Proposition 5.2 (Constant weights approximation (5.14))
Weights of the approximating pdf (5.14) converge almost surely to constant
values. Thus, the adopted model with constant weights can be viewed as an
asymptotic version of the “correct” approximating pdf (5.14).
Proof. For a ﬁxed c and Θ, it holds that
E[˜αc(d(t), Θ)|d(t −1), Θ] ≡

f(M ∗
c |d(t), Θ)f(dt|d(t −1), Θ) ddt
=

chain rule
 f(M ∗
c , dt|d(t −1), Θ)
f(dt|d(t −1), Θ)
f(dt|d(t −1), Θ) ddt
=

canceling

f(M ∗
c , dt|d(t −1), Θ) ddt
=

marginalization
f(M ∗
c |d(t −1), Θ) ≡˜αc(d(t −1), Θ).

5.3 Mixtures as approximate models and predictors
81
Thus, {˜αc(d(t), Θ), d(t)}t∈t∗is a martingale, which is moreover nonnegative
and bounded by 1 as ˜αc(d(t), Θ) is a probability. Thus, the martingale con-
vergence theorem [81] applies and ˜αc(d(t), Θ) converges almost surely to a
constant probability.
The mixture serves mainly as the predictor of the future behavior of the
o-system. The assumed invariance of weights may deteriorate its quality sub-
stantially. It can be seen on a simple mixture with a well-separated pair of
components of similar symmetric shapes and equal weights. For such a mix-
ture, the expected value, which is taken as a good point estimate of the future
values dt, sits in the improbable area between them. The following proposi-
tion shows how the problem can be resolved in a generic way that ﬁts into
the considered context.
Proposition 5.3 (Mixtures on grouped data) Let us decompose data se-
quence d(˚t) into adjacent nonoverlapping groups of a length n > 1. Thus, we
consider the following probabilistic description of the whole sequence (with a
negligible exception of initial and terminal groups of the length n)
f(d(˚t)|Θ) =
˚
t
n
 
τ=1
f(d[(τ−1)n+1]···τn|d((τ −1)n), Θ).
(5.16)
Let the individual parameterized pdfs have the mixture form with constant
component weights
f(d[(τ−1)n+1]···τn|d((τ −1)n), Θ) =

c∈c∗
αcf(d[(τ−1)n+1]···τn|d((τ −1)n), Θc, c).
(5.17)
Then, the predictor of dτn based on d(τn −1) (notice the braces!) has data-
dependent weights. Speciﬁcally,
f(dτn|d(τn −1), Θ) =

c∈c∗
˜αc(d(τn −1), Θ)f(dτn|d(τn −1), Θc, c)
˜αc(d(τn −1), Θ) =
αcf(d[(τ−1)n+1]···(τn−1)|d((τ −1)n), Θc, c)
2
˜c∈c∗α˜cf(d[(τ−1)n+1]···(τn−1)|d((τ −1)n), Θ˜c, ˜c). (5.18)
Proof. The derived formula is directly implied by the chain rule for pdfs.
Remark(s) 5.5
Note that we predict the data at the end of the grouping interval. It is suﬃcient
for the assumed low rate of operator interventions for which the predictions
serve. The other data records in the group can be predicted similarly, but the
very ﬁrst data record in the group is still predicted with constant weights.
Problem 5.2 (Mixtures at factor level) The mixture modelling of group-
ed data indicates that mixtures can be used at various levels of decomposition

82
5 Problem formulation
of the pdf f(d(˚t)). For instance, modelling of factors by mixtures could bring
additional freedom. For instance, non-normal factors can be approximated or
modes living at the factor level can be modelled.
Problem 5.3 (Shifted and repeatedly used predictors) Poorer predict-
ions of “earlier” entries in the group can be suppressed by dealing with n mu-
tually shifted predictors or by using the single one working on shifted data.
Experiments indicate that these techniques are worth elaborating.
Problem 5.4 (Rational approximations)
The discussed way of getting
data-dependent weights seems to be acceptable. In spite of this, a theoretical
and algorithmic solution admitting rational forms instead of ﬁnite mixtures
would be highly desirable. An attempt presented in Section 13.2 is based on the
technique given in [131]. Alternatively, the approximate estimation developed
in Section 6.5 could be extended by applying it both to the numerator and the
denominator of the “rational” approximation.
5.4 Design of advisory systems
Here, elements related to the optimization part of the basic design Algorithm
5.1 are presented.
5.4.1 Types of advisory systems
Under the adopted notations and assumptions, we are able to specify a formal
description of advisory systems and to distinguish their basic types.
Agreement 5.5 (Fixed and adaptive advisory systems) The advisory sys-
tem is a system that constructs the ideal pdf
⌊If(d(˚t)|P) and presents its
projections to the operator. The following types of advisory systems are dis-
tinguished according to the exploited experience P.
The ﬁxed advisory system constructs the ideal pdf in oﬄine mode using
the experience P ≡d(0), cf. Chapter 2, obtained before the use of the advisory
system in its online mode. Thus, its construction is formally described by the
mapping
⌊Uf(d(˚t)), f(Θ|d(0)) →

⌊If(d(˚t)|d(0))

.
The pdf ⌊Uf(d(˚t)) is the user’s ideal pdf obtained by extending the true user’s
ideal pdf, Section 5.1.4, in the way described in Section 5.1.5. The involved
parameter estimate f(Θ|d(0)) is based on the experience collected before online
usage of the advisory system. Thus, the ﬁxed advisory system exploits the
unguided model f(d(˚t)|d(0)) that results from the estimation based on the data
produced without the use of the p-system, cf. Agreement 5.3.
The adaptive advisory system extends its experience during its online use.
Thus, its construction is formally described by the sequence of mappings

5.4 Design of advisory systems
83

⌊Uf(dt+1, · · · , d˚t|d(t)), f(Θ|d(t)) →

⌊If(dt+1, · · · , d˚t|d(t))

t∈{0}∪t∗.
Thus, the adaptive advisory system exploits the guided model f(dt, · · · , d˚t|d(t))
that results from the estimation based also on the data produced with the use
of the p-system, cf. Agreement 5.3.
The use of the advisory system in the online mode consists of a sequen-
tial presentation of the optimized ideal pdf ⌊If(·). It is evaluated at measured
and (or) contemplated arguments do(t) as well as at the measured values
dp+(t), t ∈t∗.
As anticipated by conceptual Algorithm 5.1, only some optional parts of
the estimated model are optimized. Basic variants are discussed now.
Generally, the p-system may not be aware which quantities in d∗
o(˚t) are
operator actions. For instance, the operator can change both pressure and
temperature of a managed gas system. The advisory system measures changes
of both of them but may have no information on the command button pressed
by the operator. Note that such a situation is more frequent in medical or
societal applications.
This incomplete knowledge is another important diﬀerence that makes
the design of the advisory system a very speciﬁc decision-making problem.
The following agreement singles out the case when this information lack is
complete.
Agreement 5.6 (Academic advisory system) The advisory system de-
signed without knowing which entries of do;t belong to the action space of
the operator a∗
o(˚t) is called the academic advisory system. The corresponding
design is called the academic design.
Agreement 5.7 (Industrial and simultaneous advisory systems) The
advisory system designed with knowledge of a nonempty part of the action
space of the operator, say u∗
o(˚t) ⊂a∗
o(˚t), u∗
o(˚t) ̸= ∅, is called the industrial
advisory system.
The o-actions uo;t are called the recognizable actions; see Fig. 5.1.
The design of recognizable actions is called industrial design. The joint
academic and industrial design is called simultaneous design.
Remark(s) 5.6
Obviously, the industrial advisory system is to be optimized through the si-
multaneous design whenever possible. Sometimes, however, the weights have
physical meaning and cannot be inﬂuenced by operator’s strategy.
5.4.2 Advices as actions of the p-system
During development of the advisory system, basic types of its actions emerged.
Here we classify them (a wider discussion follows).

84
5 Problem formulation
Agreement 5.8 (Nomenclature of actions of the p-system) The actions
available to p-systems
ap;t ≡(ct, uo;t, zt, st) are interpreted as follows.
(5.19)
Recommended pointers {ct}t∈t∗are pointers to the components that are rec-
ommended to be kept active at respective time moments. Recommended
pointers are academic advices. Academic advices cannot be directly com-
municated to the operator and have to be reﬂected in the ideal pdf
⌊If(do;t|d(t −1)) oﬀered to him.
Recommended recognizable actions {uo;t}t∈t∗guide the operator in selecting
recognizable actions. These advices result from the industrial or simulta-
neous designs. The recommended recognizable actions can be interpreted
as ordinary inputs of the o-system with the operator serving as an im-
perfect actuator. Ideally, the recommended recognizable actions should be
directly fed into the o-system. This insures that the identical notation is
being used for the recommended recognizable actions and the recognizable
actions.
Priority actions {zt}t∈t∗select entries of {dt}t∈t∗whose ideal behavior is
shown to the operator. These advices result from optimized assigning pri-
orities. The priority action zt is ˚z vector (˚z ≤˚
do) of diﬀering indexes
zi;t ∈{1, . . . , ˚
do}, i ∈{1, . . . ,˚z}. The operator gets the marginal pdfs
 ⌊If(dzt;t|d(t −1)

t∈t∗of the ideal pdf resulting from the previous design.
Signaling actions {st ∈s∗≡{0, 1}}t∈t∗stimulate the operator to take some
measures when behavior of the o-system signiﬁcantly diﬀers from the de-
sired one. These advices result from optimized signaling. The operator gets
probabilistic information whether an intervention is needed or not. It is
coded, for instance, as traﬃc lights.
5.4.3 Unguided and guided models for respective designs
We assume that the learning part of the advisory system provides a good
model f(dt|d(t −1)) of the o-system uninﬂuenced by the p-system, i.e., the
model of the unguided o-system.
A systematic design of the p-system, as described in Algorithm 5.1, re-
quires a model relating its advices to responses of the o-system, i.e., the model
of the guided o-system.
The needed but speculative class of models is proposed gradually in subse-
quent sections. The term “speculative” underlines that the model is based on
hypothesis that the operator fully cooperates and is able to drive the o-system
to the desired state. Possible adverse consequences of this speculation can be
suppressed by using an adaptive advisory system with models having advices
as an explicit part of experience. Initially, and often permanently, we have
to rely on such speculative models as the basis of the systematic academic,
industrial and simultaneous design, respectively. Speculative guided models
are also used for assigning priorities and signalling.

5.4 Design of advisory systems
85
The consistent transition from the unguided model to the guided one has
the following common structure.
The considered data split
dt ≡dp;t = (∆p;t, ap;t) ≡(p-innovations, p-actions) ≡(p-innovations, advices).
The corresponding factorization of the unguided model by the chain rule reads
f(dt|d(t −1)) = f(∆p;t|ap;t, d(t −1))f(ap;t|d(t −1)).
Assuming (speculating) that the recommended actions and actions realized
by the o-system coincide, the ﬁrst factor on the right-hand side describes the
reaction of the o-system on advices. It is given by its physical nature and
cannot be changed. The second factor describes the rule of generating ap;t.
Exactly this rule should be changed by the optimized advising. This gives the
general form of the optimized guided model
⌊If(dt|d(t −1)) = f(∆p;t|ap;t, d(t −1)) ⌊If(ap;t|d(t −1))
=
f(dt|d(t −1))

f(dt|d(t −1)) d∆p;t
⌊If(ap;t|d(t −1)).
(5.20)
As discussed in Section 5.4.1, respective designs diﬀer in the available advices,
and consequently they lead to diﬀerent guided models.
Remark(s) 5.7
Note that conditioning used in (5.20) is potential source of computational diﬃ-
culties. We can say beforehand that for the academic and simultaneous designs
the obtained guided models are relatively simple, unlike for the industrial de-
sign and assigning priorities. The complexity of signalling related model is
somewhere in between these two cases.
5.4.4 Academic design
We have at disposal the multiple-mode model of the unguided o-system
f(d(˚t)). As discussed above; see Agreement 5.5, the advisory system maps
f(d(˚t)) on an ideal pdf ⌊If(d(˚t)), whose projections are presented to the op-
erator, preferably in a graphic form.
The joint pdf f(d(˚t)) describes the probability distribution of achievable
modes within the data space of the advisory system. Thus, the reachable ideal
pdf should be created from these modes. The selection of modes leading to a
higher management quality should be advised. The academic design selects the
recommended mode through the recommended pointer ct ∈c∗to a particular
component (mode) by deﬁning the ideal pdf
⌊If(d(˚t), c(˚t)) ≡
 
t∈t∗
⌊If(dt, ct|d(t−1)) ≡
 
t∈t∗
f(dt|d(t−1), ct) ⌊If(ct|d(t−1)).

86
5 Problem formulation
The pdfs f(dt|d(t−1), ct), ct ∈c∗are estimated components and the optional
probabilities ⌊If(ct|d(t −1)) describe the randomized causal strategy
{d∗(t −1) →ct ∈c∗}t∈t∗
to be designed.
(5.21)
Remark(s) 5.8
1. Usage of the notation ⌊If(d(˚t), c(˚t)) is a bit inconsistent as c(˚t) is a part
of d(˚t). It helps, however, to focus attention on the discussed advices.
Further on, both variants are used. Context should prevent possible mis-
understandings.
2. The optimized ideal pdf
⌊I(dt|d(t −1)) is projected on low-dimensional
pdfs on subsets of d∗
o;t. They describe entries of o-data and are also called
advisory mixtures. This agreement is used for all basic designs.
The recommended pointer ct ∈d∗
p+;t, thus, a projection on d∗
o has to be
presented to the operator. The corresponding marginal predictive pdf has the
form
⌊If(do;t|d(t −1)) =

ct∈c∗
⌊If(ct|d(t −1))f(do;t|d(t −1), Θct, ct).
(5.22)
The advising strategy
 ⌊If(ct|d(t −1))

t∈t∗is optimized in the sense of the
fully probabilistic design; see Section 2.4.2. For that, we have to specify a
user ideal pdf for the interconnection of the o- and p-systems ⌊Uf(d(˚t), c(˚t)) ≡
⌊If(dt|d(t −1)) ⌊Uf(ct|d(t −1)). The constructed ideal pdf
⌊If(d(˚t), c(˚t)) =
/
t∈t∗⌊If(dt|d(t −1)) ⌊Uf(ct|d(t −1)) should be as close as possible to the
user’s ideal pdf ⌊Uf(d(˚t), c(˚t)).
The recommended pointers ct belong to d∗
p+;t so that the general exten-
sion of the user’s ideal pdf could be used; see Section 5.1.5. Practical reasons
make us to take this part of the user’s ideal pdf as tuning knob of the design.
For instance, it is reasonable to inhibit fast changes of values of c(˚t) in order
to get relatively stable advices given to the operator. This can be achieved
by selecting such a user’s ideal pdf /
t∈t∗⌊Uf(ct|d(t −1)) that assigns high
probabilities to sequences c(˚t) with small diﬀerences ct −ct−1. Also, an of-
ﬂine analysis may discourage operating at some dangerous modes of f(d(˚t))
completely. For that, it is suﬃcient to restrict support of ⌊Uf(ct|d(t −1)) on
pointers to the nondangerous components. Such considerations determine the
discussed part of the user’s ideal pdf

⌊Uf(ct|d(t −1))

t∈t∗.
With it, the complete user’s ideal pdf gets the form
⌊Uf(d(˚t)) =
 
t∈t∗
⌊If(dp+;t|d(t −1)) ⌊Uf(do;t|do(t −1)) ⌊Uf(ct|d(t −1)).(5.23)

5.4 Design of advisory systems
87
It follows from the discussed extension of the true user’s ideal pdf ⌊Uf(do(˚t))
to ⌊Uf(d(˚t)) (see Section 5.1.5) from the chain rule and the fact, that the user
can deal with quantities which he is aware of.
This selection of the extended user’s ideal pdf completes the formulation of
the academic design that makes the general fully probabilistic design formally
applicable; see Proposition 2.11. The practical evaluation requires approxima-
tions that are discussed in Chapter 7.
As mentioned above, some components might be handled as “dangerous”.
We take a component as dangerous if a permanent operation on it leads to an
unacceptable behavior of the o-system.
Agreement 5.9 (Dangerous component) Let f(Ψ|c) be the steady-state
pdf of the data vector Ψ assigned to the permanent activity of the cth compo-
nent of the mixture
f(Ψ|c) =

f(Ψ| ˜Ψ, c)f( ˜Ψ|c) d ˜Ψ.
(5.24)
Here, f(Ψ| ˜Ψ, c) ≡f(Ψt = Ψ|Ψt−1 = ˜Ψ, c) is a formal, state-space version of
the cth component that describes the evolution of the data vector Ψt.
Let us consider average marker of the form
1
˚t

t∈t∗
m(Ψt)
(5.25)
given by a partial quality marker m(Ψt). Then, the component c is called dan-
gerous if the probability of a given set ¯m∗of non-acceptable values of m(Ψ)

χ ¯m∗(m(Ψ))f(Ψ|c) dΨ
(5.26)
is too high. The symbol χx∗(·) means indicator of the set x∗.
5.4.5 Industrial design
The industrial design optimizes recommended recognizable actions uo;t. Ide-
ally, these actions are directly fed into the o-system and their consequences
are predicted by the model of the unguided o-system. They are similar to
ordinary inputs of the o-system with the operator serving as an imperfect
actuator.
The constructed randomized strategy is described by the pdfs
 ⌊If(uo;t|d(t −1))

t∈t∗. These pdfs replace {f(uo;t|d(t −1))}t∈t∗forming a
part of the estimated unguided model f(dt|d(t −1)). Thus, the ideal pdf
generated by this design has the form
⌊If(dt|d(t −1)) = f(∆t|uo;t, d(t −1)) ⌊If(uo;t|d(t −1)) =
(5.27)
= ⌊If(uo;t|d(t −1))
2
ct∈c∗αctf(∆t|uo;t, d(t −1), ct)f(uo;t|d(t −1), ct)
2
ct∈c∗αctf(uo;t|d(t −1), ct)
.

88
5 Problem formulation
The strategy determining the optimal ⌊If(uo;t|d(t −1)) is obtained through
the fully probabilistic design, Proposition 2.11. The needed user’s ideal pdf
⌊Uf(d(˚t)) =
 
t∈t∗
⌊Uf(∆t|uo;t, d(t −1)) ⌊Uf(uo;t|d(t −1)),
that includes the target for the recognizable actions, is constructed exactly as
described in Section 5.1.5.
Remark(s) 5.9
1. Note that uo;t belongs to d∗
o;t, thus it is the only advice that can be directly
presented to the operator.
2. The estimated strategy, generating the recognizable actions of the unguided
o-system and described by the marginal pdfs f(uo;t|d(t−1), ct) of individual
components, inﬂuences the resulting ideal pdf; see (5.27). This eﬀect is
speciﬁc for nontrivial mixtures, in which the strategies used at various
components do not cancel in the inspected conditional pdf (5.27).
3. Properties of the components creating the ideal pdf are inﬂuenced by the
advising strategy { ⌊If(uo;t|d(t −1))}t∈t∗inﬂuencing the recognizable ac-
tions uo(˚t) applied. It may, for instance, convert the dangerous compo-
nents in nondangerous ones and vice versa.
5.4.6 Simultaneous academic and industrial design
The simultaneous design optimizes both recommended pointers to compo-
nents and recommended recognizable actions. It should lead to a better ad-
vising strategy than a sequential use of academic and industrial designs. The
simultaneous design is surprisingly simpler than the industrial one; see Chap-
ter 7.
The ideal pdf ⌊If(dt|d(t −1)), generated by the fully probabilistic design,
Proposition 2.11, minimizes the KL divergence to the user’s ideal pdf
⌊Uf(d(˚t)) =
 
t∈t∗
⌊Uf(∆o;t|uo;t, do(t −1)) ⌊If(∆p+;t|uo;t, d(t −1))
× ⌊Uf(uo;t|d(t −1)) ⌊Uf(ct|uo;t, d(t −1)),
which includes the user’s ideal pdf
⌊Uf(uo;t|do(t −1)) for the recognizable
actions uo;t as well as the target probability ⌊Uf(ct|uo;t, d(t −1)) for the rec-
ommended pointers. The latter element is discussed in connection with the
academic design, Section 5.4.4. In the simultaneous design, it may depend on
uo;t, too.
The result is similar to (5.27) with the component weights replaced by the
designed probabilities ⌊If(ct|uo;t, d(t −1)) of recommended actions. Speciﬁ-
cally, it holds that

5.5 Interactions with the operator
89
⌊If(dt|d(t −1)) = ⌊If(∆t|uo;t, d(t −1)) ⌊If(uo;t|d(t −1)) ≡⌊If(uo;t|d(t −1))
×
2
ct∈c∗⌊If(ct|uo;t, d(t −1))f(∆t|uo;t, d(t −1), ct)f(uo;t|d(t −1), ct)
2
ct∈c∗⌊If(ct|uo;t, d(t −1))f(uo;t|d(t −1), ct)
. (5.28)
Remark(s) 5.10
It is worth repeating that the elements in the formula (5.28) with the su-
perscript ⌊I are optimized. The elements without the superscript ⌊I are those
obtained through estimation of the unguided o-system. They reﬂect those parts
of operating practice that are not expected to be changed by the advising.
5.5 Interactions with the operator
The discussed advisory systems can be seen as speciﬁc versions of a high-level
control system. The ideal pdf ⌊If(d(˚t)) resulting from the designs discussed
above has to be, however, perceived by a human being. This implies a non-
standard task, namely, the optimization of the presentation of advices. Essen-
tially, low-dimensional projections of the high-dimensional ideal pdf have to
be shown to the operator. This calls for generating additional actions of the
p-system caring about interaction of the p-system with the operator. Speciﬁ-
cally, it has to be taken into account that
•
A few selected quantities can only be shown to the operator including
those which should be changed the most urgently in order to minimize
risk of malfunctioning or maximize beneﬁt. In other words, presentation
priorities have to be dynamically assigned to the o-data.
•
The information load on the operator has to be controlled by demanding
changes of the o-actions only when needed.
In other words, signaling that controls dynamically operator’s attention
has to be designed.
These problems are addressed in Sections 5.5.1 and 5.5.2 under typical
advising scenarios.
5.5.1 Assigning priorities
Presentation of quantities worth the operator interest is simple when priorities
of critical quantities to be shown are ﬁxed by technological prescriptions.
The situation is also simple if a full question and answer mode of the dialog
is adopted. In this case, the operator can ask the p-system:
What happens to a quantity di;t if I assign a value ¯dj;t to the quantity
dj;t?
In this case, the optimized (guided) predictive pdf
⌊If(di;t| ¯dj;t, d(t −1)) is
simply shown. This pdf obtained via marginalization and conditioning from
the optimized guided pdf ⌊If(dt|d(t −1)).

90
5 Problem formulation
A similar simple case arises when a few recognizable actions uo;t are to be
recommended only. Then, the marginal pdfs ⌊If(uio;t|d(t −1)), i = 1, . . . ,˚uo,
of the optimized pdf ⌊If(uo;t|d(t−1)) are evaluated and shown to the operator.
The situation becomes more complex when there is a need to show only
marginal pdfs of a few critical quantities contained in the extensive full data
record dt. It leads to the following speciﬁc decision problem.
The p-system is given task to generate a ˚z-vector of priority actions zt
with entries zi;t ∈{1, . . . , ˚
do}, i ∈i∗≡{1, . . . ,˚z}, ˚z < ˚
do. The value of
zi;t = j means that recommendations on jth entry of do;t should be shown to
the operator.
Note that the number of shown quantities ˚z has to be small, say 5, in order
to respect limited perceiving abilities of human beings.
The ideal pdf ⌊If(d(˚t)) resulting from academic, industrial or simultaneous
designs as well as the user’s ideal pdf ⌊Uf(d(˚t)) are assumed to be ﬁxed and
available when designing the presentation strategy
 ⌊If(zt|d(t −1))

t∈t∗.
Similarly as in the academic design, the target pdf for the adopted fully
probabilistic design ⌊Uf(d(˚t)) is extended by the factor /
t∈t∗⌊Uf(zt|d(t−1)).
This tuning knob allows us to respect technological preferences and (or) to
restrict rate of changes of the quantities selected for the presentation to the
operator.
Using the redundant notation d(˚t), z(˚t) instead of d(˚t) (cf. Remark 5.8)
the optimized model, describing the inﬂuence of presentation actions, gets
the form
⌊If(d(˚t), z(˚t)) =
 
t∈t∗
⌊If(dt|zt, d(t −1)) ⌊If(zt|d(t −1)),
(5.29)
where the pfs
 ⌊If(zt|d(t −1))

t∈t∗describe the randomized presentation
strategy to be designed.
Let us assume again that the operator cooperates fully when given the ideal
pdf for entries of dt with indexes zt. Then, the operator is expected to act so
that the behavior of the o-system has the distribution with the marginal pdf
⌊If(dzt;t|d(t −1)), while entries not shown follow the model of the unguided
o-system. Here, the pdf ⌊If(dt|d(t−1)) is the ideal pdf oﬀered by the advisory
system that results from the previous optimization.
Thus, the compromise ⌊If(dt|zt, d(t −1)) between
•
the unguided model of the o-system f(dt|d(t −1)), acting without the
p-system, and
•
the optimized guided model ⌊If(dt|d(t −1)), acting fully according to the
p-system that presents dzt;t
looks as follows (5.20):
⌊If(dt|zt, d(t −1)) = f(dt|d(t −1))
⌊If(dzt;t|d(t −1))
f(dzt;t|d(t −1)) .
(5.30)

5.5 Interactions with the operator
91
In this model, the marginal pdf f(dzt;t|d(t −1)) of the presented quantities
dzt;t — computed from the estimated mixture f(dt|d(t −1)) — is replaced
by the corresponding marginal pdf
⌊If(dzt;t|d(t −1)) gained from the pre-
viously designed ideal pdf
⌊If(dt|d(t −1)), which is generally also mixture.
Thus, the model (5.30) is rather complex ratios of mixtures. Consequently,
the fully probabilistic design must be approximated in order to get a feasible
presentation strategy; cf. Chapter 7.
Moreover, the number of variants to be compared
 ˚
do
˚z

during opti-
mization is mostly very large. It motivates us to select ˚z = 1 and to use
⌊If(zt = i|d(t −1)), i ∈{1, . . . , ˚
do} as a degree of the presentation priority
assigned to the ith entry of dt.
Problem 5.5 (Alternative design of presentation priorities) This part
of the design is, a bit surprisingly, the hardest one. It calls for an alternative
formulation. For instance, it would be possible to perform design predecessors
with alternative ﬁxed choices of presented quantities and then to compare the
predicted quality of the guided closed loop behavior. This formulation is worth
considering.
5.5.2 Stimulating the operator
Operator may actively call the p-system for advices. Typically, however, his
attention has to be attracted when the state of the managed system requires
it. The problem how to attract the operator’s attention is addressed here. In
modelling of signalling inﬂuence, we proceed similarly as in previous sections.
The p-system is given the task to generate actions {st}t∈t∗, st ∈{0, 1}.
The value st = 0 means that system is in a good state and no extra operator
activity is needed. The value of st = 1 urgently demands operator actions.
We search for an admissible signaling strategy described by the causal rules
{d∗(t −1) →s∗
t ≡{0, 1}}t∈t∗.
The user’s ideal pdf ⌊Uf(d(˚t)) as well as the ideal pdf ⌊If(d(˚t)), resulting from
academic or industrial or simultaneous design, are assumed to be ﬁxed here.
The user’s ideal pdf ⌊Uf(d(˚t)) is extended to signaling actions s(˚t) by the pf
⌊Uf(st|d(t −1)) reﬂecting the desired damping of the stimulation.
Stimulation, when respected by the operator,
•
results into the guided behavior of the o-system, i.e., f(dt|st = 1, d(t−1)) ≡
⌊If(dt|d(t −1)) if st = 1,
•
leaves the o-system unguided, i.e., f(dt|st = 0, d(t −1)) ≡f(dt|d(t −1)) if
st = 0
Thus, the resulting model of the optimized guided o-system has the form
⌊If(d(˚t), s(˚t)) =
 
t∈t∗
⌊If(dt|st, d(t −1)) ⌊If(st|d(t −1)),

92
5 Problem formulation
where the probabilities
 ⌊If(st|d(t −1))

t∈t∗describe the constructed signal-
ing strategy. The inﬂuence of the signalling action is described by the model
⌊If(dt|st, d(t −1)) = δst,0f(dt|d(t −1)) + (1 −δst,0) ⌊If(dt|d(t −1)).
As st ∈d∗
p+;t, it cannot be directly provided to the operator. Instead,
ˆst = E[δst,0|d(t −1)] = ⌊If(st = 0|d(t −1))
is shown, usually, as a colored traﬃc light. Here, Kronecker symbol is used
δs,˜s =

1 if s = ˜s
0 otherwise .
(5.31)
5.6 Design summary
For reference purposes, a review of the proposed models, expressing the ex-
pected inﬂuence of particular advises, is given, Subsection 5.6.1. The overall
design scenario in Subsection 5.6.2 anticipates the decision subtasks to be
solved on the way towards the constructed advisory system.
5.6.1 Inﬂuence of advices on the o-system
During the discussion of particular designs, the following overall model of the
interconnecting of the o-system and the p-system has arisen. Recall, the super-
script ⌊I indicates that the corresponding object results from the optimization
of advices ap;t = (ct, uo;t, zt, st). The overall model has the form
f(do;t|ap;t, d(t −1)) ≡δst,0f(do;t|d(t −1)) + (1 −δst,0) ⌊If(do;t|d(t −1))
st is 0 if operator does not use recommended actions, otherwise st is 1.
He reacts on signaling chosen according to ⌊If(st|d(t −1)).
The ﬁrst predictor above is obtained in learning of the unguided system
f(do;t|d(t −1)) ≡

c∈c∗
αcf(do;t|d(t −1), c) and
(5.32)
⌊If(do;t|d(t −1)) ≡f(do;t|d(t −1))
⌊If(dzt;t|d(t −1))
f(dzt;t|d(t −1)) , where
zt is the presentation action chosen according to ⌊If(zt|d(t −1))
⌊If(do;t|d(t −1)) ≡⌊If(uo;t|d(t −1)) ×
×
2
ct∈c∗⌊If(ct|uo;t, d(t −1))f(∆o;t|uo;t, d(t −1), ct)f(uo|d(t −1), ct)
2
ct∈c∗⌊If(ct|uo;t, d(t −1))f(uo|d(t −1), ct)
.
The probabilities
 ⌊If(st|d(t −1))

t∈t∗, st ∈s∗≡{0, 1}, describe signaling
strategy. They result from the corresponding, fully probabilistic, signaling
design. This design is the last in the sequence of respective designs.

5.6 Design summary
93
The probabilities
 ⌊If(zt|d(t −1))

t∈t∗,
zt ∈z∗≡

[z1, . . . , z˚z], zi ∈{1, . . . , ˚
do}

describe presentation strategy. They result from the presentation design
made after ﬁnishing some of the designs listed below.
The pdfs
 ⌊If(uo;t|d(t −1))

t∈t∗, uo;t ∈u∗
o, describe strategy generating
recommended recognizable actions. They result from industrial or simul-
taneous design. The industrial design relies on availability of the compo-
nent weights f(ct|uo;t, d(t −1)). They are obtained either from learning,
then f(ct|uo;t, d(t −1)) = αc, or from the previous academic design, then
f(ct|uo;t, d(t −1)) =
⌊If(ct|uo;t, d(t −1)). The simultaneous design —
when adopted — is the ﬁrst in the sequence of designs.
The probabilities
 ⌊If(ct|d(t −1))

t∈t∗, ct ∈c∗≡{1, . . . ,˚c}, describe strat-
egy generating academic advices. They result from the academic or simul-
taneous designs that start the overall sequence of designs.
Remark(s) 5.11
Recall that the adopted models relating advices to the behavior of the guided
o-system are of a speculative nature. They serve as the necessary departing
point, but the model should be corrected through the use of the p-system: we
should estimate model f(dt|ap;t, d(t −1), Θ) describing explicitly dependence
of data dt on the adopted advices ap;t. For it, the use of the adaptive version
of the p-system becomes highly desirable.
5.6.2 Overall scenario and design subtasks
The solution of the overall design problem includes a number of particular
steps anticipated in the algorithm below. The algorithm serves us as a design
guide. Its steps are discussed in Chapters 6 and 7 at the general level and
specialized to speciﬁc mixture elements in subsequent Chapters. For ﬁxed
advisory system, all steps, except steps 16c and 17, are made in oﬄine mode.
For adaptive advisory system, steps 7, 14, 15 have to be run in online mode,
too. Note that the recursively performed estimation step 7 is computationally
cheap and redesigns 14, 15 can be performed with much slower rate without
a signiﬁcant harm.
Algorithm 5.2 (Design of the advisory system)
1. Collect the learning data that have to reﬂect all modes of operating.
2. Select quality markers and express their desirable values as the true user’s
ideal pdf ⌊Uf(do(˚t)).
3. Collect prior physical information on the managed system, operating and
measuring conditions.
4. Preprocess the data available for learning by

94
5 Problem formulation
a) grouping data records according to the operator’s perceiving and acting
rates,
b) reducing dimensionality using expert knowledge that should exclude
surely irrelevant record entries,
c) removing outliers,
d) replacing missing data,
e) suppressing high-frequency noise.
5. Select the largest acceptable structure of the estimated mixture.
6. Select a prior pdf initializing estimation of the mixture describing the
o-system.
7. Estimate the mixture describing the o-system; if need be, go back to step
6 or even go to step 4.
8. Estimate structure of the mixture in its full hierarchy from factors to the
whole mixture and, if need be, go back to step 6.
9. Reduce dimensionality of the problem by removing data that do not inﬂu-
ence even indirectly quantities in
⌊Uf(do(˚t)) and, if need be, go back to
Steps 4 or 6.
10. Use physical prior information for individual factors and, if need be, go
back to Step 6.
11. Validate quality of the obtained model using expert opinion as well as
independent testing data. And, if the result is unsatisfactory, repeat whole
learning procedure, possibly from Step 3.
12. Analyze individual components and qualify recommendable and dangerous
ones.
13. Select basic advising scenario (academic, industrial or simultaneous).
14. Design the advising strategy.
15. Design presentation and signaling strategies.
16. Validate advising strategy by
a) comparing real actions of the operator with those generated by advising
system (without closing the advising loop),
b) judging proximity of good modes in data with the behavior stimulated
by a good operator,
c) using advising system at the full scale.
17. Use the p-system in the ﬁxed or adaptive mode by feeding the currently
measured data into the advising mixture as well as into presentation and
signaling strategies. Show the low-dimensional projection of the advising
mixture to the operator. The shown quantities are selected by the presenta-
tion strategy and the call for o-actions is driven by the signaling strategy.

6
Solution and principles of its approximation:
learning part
Chapter 5 speciﬁed all elements needed for the design of an advisory system
according to the theory recalled in Chapter 2. This formal solution of the
design of the advisory system helps us undoubtedly to clarify the structure
of evaluations that should be made. Their practical usefulness is, however,
restricted by the “curse of dimensionality”. Thus, this conceptual solution has
to be complemented by approximate but feasible evaluations. A discussion of
their principles for the learning part of the advisory system is presented here.
The oﬄine mode is predominantly addressed and data are mostly historical.
Speciﬁcally, the treated advisory system is based on the parameterized
model of the o-system. Its behavior observed by the p-system, grouped ac-
cording to the rate of operator actions, is described by the mixture (5.9)
f(dt|d(t −1), Θ) = f(dt|φ1···˚c;t−1, Θ) =

c∈c∗
αcf(dt|φc;t−1, Θc, c).
(6.1)
Each parameterized component f(dt|φc;t−1, Θc, c) is decomposed into the
product of parameterized factors (see Agreement 5.4)
f(dt|φc;t−1, Θc, c) =
 
i∈i∗
f(dic;t|ψic;t, Θic, c)



ith factor
, i∗≡

1, . . . , ˚
d

,
(6.2)
where the regression vectors ψic;t are made of [d′
(i+1)···˚
dc;t, φ′
c;t−1]′. The factors
f(dic;t|ψic;t, Θic, c) are parameterized by individual parameters Θic. Collection
of these parameters, together with the probabilistic weights of components
α ∈α∗(5.9), form the multivariate parameter Θ of the mixture.
Parameters, structures of factors and components, as well as the structure
of the mixture (see Agreement 5.4) have to be estimated. The estimation is
inspected, here.
Section 6.1 prepares common tools used throughout this chapter. First, the
considered class of Bayesian estimates is speciﬁed. Then, predictors serving
for comparison of alternative estimates are presented in Sections 6.1.1 and

96
6 Solution and principles of its approximation: learning part
6.1.2. The alternatives are generated through versions of branch-and-bound
techniques; see Section 6.1.3.
The formal Bayesian estimation is described by Proposition 2.14 with ex-
perience formed by the p-data. These data result from preprocessing the raw
data observed by the p-system; see discussion in Section 6.2.
Application of the Bayesian paradigm requires speciﬁcation of a prior pdf
f(Θ). Use of the prior knowledge to this purpose is treated in Section 6.3.
Even with such knowledge available, proper speciﬁcation of the prior pdf is
nontrivial. An extensive discussion of promising ways of its construction is
described in Section 6.4.
For a chosen f(Θ), the evaluations of the likelihood function L(Θ, Pa∗
t+1)
(2.45) and its integral I(Pa∗
t+1) (2.46) represent the main computational bur-
den. The diﬃculty of the mixture estimation stems from the fact that the
likelihood function is a product of sums of pdfs depending on data d(t) and
on the unknown parameter Θ. Thus, its formal analytical expression contains
a huge number of terms that cannot be handled exactly. For this reason, an
approximate treatment is necessary. It is discussed in Section 6.5.
The important structure estimation task is outlined in Section 6.6. Section
6.7 covers model validation. It forms a natural bridge to Chapter 7, which
discusses design of the advising and presentation strategies, cf. Section 5.4.
6.1 Common tools
Here, tools used throughout this chapter are prepared. Their description re-
quires speciﬁcation of learning conditions.
Agreement 6.1 (Considered forms of pdfs on Θ∗) The prior pdf f(Θ) ≡
f(Θ|d(0)) and posterior pdf f(Θ|d(t)) deﬁning generalized Bayesian estimates
of the mixture (Agreement 5.4) are considered in the common form
f(Θ|d(t)) = Diα(κt)
 
i∈i∗,c∈c∗
f(Θic|d(t)), t ∈{0} ∪t∗,
(6.3)
Diα(κt) ≡B−1(κt)
 
c∈c∗
ακc;t−1
c
χα∗(α) ≡Dirichlet pdf on
α∗≡
"
αc,

c∈c∗
αc = 1
%
B(κt) ≡
/
c∈c∗Γ(κc;t)
Γ
2
c∈c∗κc;t
 ≡multivariate beta function, where
(6.4)
κt ≡[κ1;t, . . . , κ˚c;t]′ ∈κ∗≡{κt : κc;t > 0}.
Verbally, parameters Θic, i ∈i∗≡{1, . . . , ˚
d}, c ∈c∗, of individual param-
eterized factors are mutually conditionally independent and independent of

6.1 Common tools
97
the component weights α. The component weights have Dirichlet distribution
Diα(κ) with its support on the probabilistic simplex α∗.
The Dirichlet distribution Diα(κt) is analyzed in Chapter 10 in detail. Here,
we only need to know that the expectation assigned to Diα(κt) is
E [αc|d(t)] = E[αc|κt] =
κc;t
2
˜c∈c∗κ˜c;t
≡ˆαc;t.
(6.5)
6.1.1 Prediction and model selection
The constructed p-system predicts consequences of the observed behavior and
operator actions on the future behavior of the o-system. Thus, its performance
depends heavily on the quality of the used predictive pdf. Under Agreement
6.1, the value of the predictive pdf of a component c at a possible data vector
Ψt+1 = [d′
t+1, φ′
t]′, Agreement 5.4, conditioned on measured data d(t) is
f(dt+1|d(t), c) ≡E
 
i∈i∗
f(dic;t+1|ψic;t+1, Θic, c)
!!!!! d(t), c

=
 
i∈i∗

f(dic;t+1|ψic;t+1, Θic, c)f(Θic|d(t)) dΘic
=
 
i∈i∗
f (dic;t+1|ψic;t+1, d(t), c) .
(6.6)
The overall predictive pdf of a mixture is
f(dt+1|d(t)) ≡E

c∈c∗
αc
 
i∈i∗
f(dic;t+1|ψic;t+1, Θic, c)
!!!!! d(t)

=

c∈c∗
κc;t
2
˜c∈c∗κ˜c;t
 
i∈i∗

f(dic;t+1|ψic;t+1, Θic, c)f(Θic|d(t)) dΘic
=

(6.5)

c∈c∗
ˆαc;t
 
i∈i∗
f(dic;t+1|ψic;t+1, d(t), c).
(6.7)
Similarly, we get a predictor for the ﬁxed advisory system. For reference pur-
poses, we summarize these predictors in the following proposition.
Proposition 6.1 (Mixture-based one-step-ahead predictor) Under
Agreement 6.1, the estimation within the adaptive advisory system provides
the value of the one-step-ahead predictor at a possible data vector Ψt+1 =
[d′
t+1, φ′
t]′ (Agreement 5.4) in the form
f(dt+1|d(t)) =

c∈c∗
ˆαc;t
 
i∈i∗
f(dic;t+1|ψic;t+1, d(t), c).
(6.8)

98
6 Solution and principles of its approximation: learning part
The adaptive predictor of a factor output dic;t+1
f(dic;t+1|ψic;t+1, d(t), c) ≡

f(dic;t+1|ψic;t+1, Θic, c)f(Θic|d(t)) dΘic
(6.9)
eliminates the unknown parameters of the parameterized factor by its integra-
tion weighted by the posterior pdf f(Θic|d(t)), by the posterior factor estimate,
Agreement 5.4.
The component weights are replaced by the expectation (6.5) determined
by the statistic κt.
In the ﬁxed advisory system, measured data do not enter the condition of
the distribution on parameters, i.e., f(Θ|d(t)) ≡f(Θ|d(0)) ≡f(Θ). Thus, the
one-step-ahead predictor becomes
f(dt+1|d(t)) ≡

c∈c∗
ˆαc;0
 
i∈i∗
f(dic;t+1|ψic;t+1, c).
(6.10)
The ﬁxed predictor of a factor output dic;t+1
f(dic;t+1|ψic;t+1, c) ≡

f(dic;t+1|ψic;t+1, Θic, c)f(Θic) dΘic
(6.11)
eliminates the unknown parameters of the parameterized factor by its integra-
tion weighted by the prior pdf f(Θic), by the prior factor estimate, Agreement
5.4 .
The component weights are replaced by the expectation (6.5) determined
by the prior statistic κ0.
6.1.2 Likelihood on variants
During the learning phase of the p-system construction, the predictors (6.8)
or (6.10) serve for selecting the best variant among those diﬀering in initial-
ization, forgetting, structure, etc. Let d(˚t) be learning data and let v ∈v∗
label a ﬁnite collection of such, a priori equally probable, variants. Then, the
Bayes rule provides their posterior probabilities
f(v|d(˚t)) ∝f(d(˚t)|v).
The variants v with high values of the predictive pdf f(d(˚t)|v) evaluated at
measured data d(˚t) are obviously preferable. For conciseness, we call the re-
peatedly evaluated values f(d(˚t)|v) v-likelihoods.
For the adaptive advisory system, the chain rule for pdfs implies that the
v-likelihood is obtained as the product of one-step-ahead predictors with dt+1
equal to the measured data item. This is not true for the ﬁxed advisory system

6.1 Common tools
99
as it holds that
f(d(˚t)|v) =
  
t∈t∗
f(dt|d(t −1), Θ, v) f(Θ|v) dΘ
̸=
 
t∈t∗

f(dt|d(t −1), Θ, v) f(Θ|v) dΘ.
The product of ﬁxed one-step-ahead predictors is just an approximation of
the v-likelihood corresponding to the ﬁxed advisory system. This approxima-
tion is reasonable if the ﬁxed prior estimate f(Θ|v) of the mixture parameters,
Agreement 5.4, has almost one-point support. Otherwise, the adopted approx-
imation may be misleading.
The branch-and-bound algorithm (Section 6.1.3) searches for the high-
est v-likelihood among a ﬁnite set of variants. They are, however, evaluated
approximately only. Thus, the maximum value can be blurred by the “ap-
proximation noise”. Thus, a tool is needed distinguishing whether compared
v-likelihood functions are practically equal or not. The following simple test
of a hypothesis may serve for this purpose.
Proposition 6.2 (Test on equality of log-likelihoods) Let us consider a
pair of random sequences l1(˚t), l2(˚t) of real scalars l1;t, l2;t. Let us formulate
the following hypotheses
H0 : l(˚t) ≡

l1(˚t) −l2(˚t)

∼N(0, rI˚t),
with an unknown variance r > 0,
H1 : l(˚t) ≡

l1(˚t) −l2(˚t)

∼N(m1˚t, rI˚t),
(6.12)
with an unknown mean m ∈(−∞, ∞) and r > 0,
where I˚t is (˚t,˚t)-unit matrix and 1˚t is ˚t-vector consisting of units.
Let both hypotheses be a priori equally probable and conjugate prior Gauss–
inverse–Wishart pdfs GiWr(ε, ε), GiWm,r(εI2, ε), ε > 0 are chosen; see Chap-
ter 8. Then, for ε →0,
f(H1|l(˚t)) =
⎡
⎣1 +
0
1 −l
2
l2
10.5˚t⎤
⎦
−1
,
l ≡1
˚t

t∈t∗
lt,
l2 ≡1
˚t

t∈t∗
l2
t .
(6.13)
Thus, for a given probability β ∈(0, 1), β ≈1, we take both variants as equiv-
alent iﬀ
1 −

β
1 −β
2/˚t
≥
¯l2
l2 .
(6.14)
Proof. This is a special case of Bayesian prediction and hypothesis testing
related to normal pdfs that are discussed in detail in Chapter 8. The general
suﬃcient statistics are just given a speciﬁc form.

100
6 Solution and principles of its approximation: learning part
Problem 6.1 (Alternative tests of equality)
Experiments indicate ex-
cessive sharpness of the test. Other ways have to be inspected. For instance,
assuming asymptotic normality of the sequence t−0.5 2t
τ=1 lτ, the test on the
zero mean of the limiting distribution applies. Alternatively, expected value in
H1 may be assumed as a ˚t-vector m, or recently proposed general stopping
rules [128] can be adopted.
6.1.3 Branch-and-bound techniques
In subsequent sections, we search for the highest v-likelihood in a relatively
complex setting. The search itself can be seen as a version of branch-and-bound
techniques. This methodology is widely used in optimization, e.g., [132, 133].
It generates sets of alternatives, evaluates values of the optimized functional
(function) and then bounds the set of the inspected alternatives.
More formally, let us search for maximum of the functional (function)
F : X∗→(−∞, ∞) over X∗. Then, the considered generic algorithm looks
as follows.
Algorithm 6.1 (Generic branch-and-bound algorithm)
Initial mode
•
Select the upper bound ˚n on the number n of iterations.
•
Set the iteration counter n = 1 and the initial guess of the maximum value
¯F = −∞.
•
Select the initial set of alternatives X∗
n ≡{Xιn ∈X∗, ι = 1, . . . ,˚ιn}, ˚ιn <
∞.
•
Select optional parameters of branching and bounding mappings.
Iterative mode
1. Evaluate the values F ∗
n ≡{F(Xιn), Xιn ∈X∗
n} of F on the set of alter-
natives X∗
n.
2. Find ¯Fn ≡max F ∗
n.
3. Take a maximizing argument ¯Xn of F on X∗
n as an approximation of the
maximizing argument searched for. Set ¯Fn = F( ¯Xn).
4. Take ¯Xn−1 as the maximizing argument of F on X∗and stop if ¯Fn ≤¯F.
Otherwise set ¯F = ¯Fn and go to the next step.
5. Branch the set of alternatives X∗
n by a branching mapping A
A : (X∗
n, F ∗
n) →X∗
n+1|n ≡{Xι(n+1|n) ∈X∗, ι = 1, . . . ,˚ιn+1|n}, ˚ιn+1|n ≥˚ιn.
(6.15)
6. Evaluate the values of F on the set X∗
n+1|n of alternatives
F ∗
n+1|n ≡

F(Xι(n+1|n)), Xι(n+1|n) ∈X∗
n+1|n

.

6.1 Common tools
101
7. Bound the set of alternatives X∗
n+1|n by a bounding mapping U
U : (X∗
n+1|n, F ∗
n+1|n) →X∗
n+1
(6.16)
≡{Xι(n+1) ∈X∗, ι = 1, . . . ,˚ιn+1}, ˚ιn+1 ≤˚ιn+1|n.
8. Increase the counter n = n + 1. Take ¯Xn as the maximizing argument of
F and stop if n > ˚n. Otherwise go to the beginning of Iterative mode.
Proposition 6.3 (Properties of branch-and-bound algorithm) Let us
select ¯Xn ∈Arg max F ∗
n and ¯Xn+1|n ∈Arg max F ∗
n+1|n. Let ¯Xn stay in X∗
n+1|n
and ¯Xn+1|n in X∗
n+1. Then, Algorithm 6.1 may stop at the local maximum only
in Step 4. The argument found during the premature break at Step 8 cannot
be worse then the initial guess.
Proof. The statement is implied directly by construction of Algorithm 6.1
and by the assumption that the best alternative is either preserved or even
improved during each complete step of the algorithm.
Remark(s) 6.1
1. The algorithm may not stop at Step 4.
2. Attaining the global maximum is guaranteed when the maximized F has
a single mode and the algorithm stops at Step 4, i.e., when it avoids the
enforced break in Step 8.
3. The speciﬁc algorithm is obtained by selecting
•
the initial set of alternatives X∗
1,
•
the branching A and bounding U mappings.
Eﬃciency of this algorithm depends on the adapted choice of these tuning
knobs. Section 6.4 speciﬁes the functional F we maximize and justiﬁes
options X∗
1, A, U we consider as promising.
4. Selection of the bounding mapping U is straightforward if we want to re-
spect conditions of Proposition 6.3. Entries X∗
n+1|n with low values of F
are simply omitted. Thus, the choice of the number of the preserved ar-
guments ˚ιn+1 is the only real option made in connection with bounding
mapping U. In our application, this number is restricted from above by
computational complexity. It is also restricted from below as X∗
n+1 has to
provide suﬃcient number of points for branching. Thus, the choice of the
initial set X∗
1 and of the problem-adapted branching mapping A decide on
the resulting eﬃciency.
Problem 6.2 (Critical review of branching mapping)
Choice of the
branching mapping is the hardest problem addressed. The options made be-
low could be and should be complemented by “stealing” the most promis-
ing ideas occurring in various ﬁelds of optimization, for instance, in genetic
algorithms [133].

102
6 Solution and principles of its approximation: learning part
6.2 Data preprocessing
The advisory system relies on its ability to model signiﬁcant relationships
observable on the o-system; see Agreement 5.1. An attempt to reﬂect all re-
lationships is usually hopeless as it leads to a hardly manageable model. For
this reason, it is necessary to separate rare events and suppress superﬂuous
details from modelling. Data have to be preprocessed. The preprocessing tasks
can be classiﬁed as follows.
•
Data transformation covers:
–
data scaling that suppresses numerical problems and simpliﬁes the
choice of optional learning and design parameters; for instance, it al-
lows us to standardize prior pdfs;
–
reduction of dimensionality that decreases the computational and nu-
merical load by taking into account usual measurement redundancy;
–
tailoring of the time-scale that harmonizes the modelling and operator-
actions rates.
•
Outlier removal excludes rarely occurring data that diﬀer signiﬁcantly
from the behavior of the rest of data. Note that the mixture estimation
separates frequently occurring outliers automatically as it assigns them
speciﬁc components. The outlier preprocessing can often be decomposed
into:
–
outlier detection when the outlying data items are marked as missing
ones;
–
data interpolation when missing data are substituted by their estimates.
•
Filtering removes parts of data unrelated to the underlying dynamic re-
lationships of interest. The removed parts reﬂect deﬁciencies of the mea-
surement process. The noise is suppressed by a variety of signal processing
techniques [118]. Typically, diﬀerences in frequency content are exploited.
The ﬁnal aim of the data processing has to be kept in mind while applying
it. Any data preprocessing adds a dynamic module into the closed loop to
be handled by the advisory system. This simple statement implies that some
classical signal-processing techniques, which add a substantial dynamic delay,
have to be avoided. For instance, outlier detection is often based on use of
nonlinear median or linear moving average ﬁlters [134, 135, 136]. In the given
context, they can be used only with a narrow windowing. In that respect, the
detection methods exploiting dynamically changing boundaries for outliers
detection may help [137].
The mixture estimation adds the following strict constraint:
Preprocessing of individual signals must not mix data from various components!
Techniques solving the discussed tasks partially overlap. The Table 6.1 guides
in this respect.

6.2 Data preprocessing
103
Table 6.1. Preprocessing tasks and methods
Tasks
Methods
Sec.
Data transformation
6.2.1
Data scaling
Physical range and sample moments
Reduction of dimensionality
Principal component analysis
Tailoring of time scale
Local ﬁltering
Outlier removal
6.2.2
Detection
Check of physical boundaries, model-
based tests,
Interpolation
Mixtures of normal and outlying data,
model-based interpolation, ﬁlter-based
interpolation, wavelet-based ﬁltering, lo-
cal ﬁltering
Filtering
6.2.3
Removal of well separable noise
Classical smoothing
Removal of poorly separable noise
and grouping
Local ﬁltering
Noise removal by noncausal
Wavelet-based ﬁltering
ﬁltering
6.2.1 Data transformation
Data scaling
For numerical reasons, it is necessary to scale the processed data to similar
numerical ranges. Data scaling and shifting should be done on the basis of
the usual ranges of considered quantities. The widespread scaling based on
sample moments may be sensitive to outlying data. Use of extreme values for
scaling is even less robust.
It is reasonable to deal with scaled data throughout learning and design of
the advisory system. Rescaling to the user units is needed just in presentation
of the design results to the operator during advising; see Section 9.1.4.
Dimensionality reduction
Principal component analysis (PCA) is one of the most important techniques
for dimensionality reduction of strongly correlated multidimensional data [17].
The standard PCA assumes implicitly or explicitly unimodal multivariate
normal distribution. The data clustering techniques assume that data are
generated by a mixture of (normal) distributions. So, a direct use of PCA is
slightly illogical. It would be better to ﬁt a mixture in the original data space
and then apply PCA to individual normal components. We need, however, to
reduce the dimensionality before clustering in order to improve it. A sort of

104
6 Solution and principles of its approximation: learning part
data presegmenting provides a compromise between these contradictory needs.
Sometimes, it is possible in the learning phase when the processed data can
be segmented into unimodal classes. PCA then can be applied separately to
each of them; cf. Section 6.7.1.
Alternatively, mixtures with components having low-rank expectations
could be and should be considered. The idea of functional approximation
[36, 38] that approximates Bayesian estimation by minimizing of the KL di-
vergence over a suitable set of approximating pdfs seems to be proper way for
doing this task.
Problem 6.3 (PCA on components) Feasibility and real inﬂuence of the
discussed ways of PCA application on components should be studied in a quan-
titative way.
Tailoring of the time scale
The discrete-time models are built for the sampling rate given by the highest
rate feasible by the human being. Data are mostly collected with higher rates.
Thus, a representative has to be searched for a group of measured data. This
can be done with help of a local ﬁlter [138, 139]. Its use allows us, moreover, to
suppress high-frequency noise and also partially suppress outliers. The skip-
ping of data, often recommended, falls into this category, but it is obvious
that it loses precious information.
6.2.2 Outlier removal
Outlier removal consists of interconnected detection of outliers and interpola-
tion of data they hide.
Outlier detection based on physical boundaries
Mostly, the inspected data dt have a speciﬁc physical meaning with well de-
ﬁned boundaries d, d on their usual values, d ≤dt ≤d.
The censored data that do not fall in this hypercube can be immediately
interpolated or marked as missing for a postponed interpolation. Often, the
ranges on signal-rate changes are also available. Then, a similar hypercube on
temporal changes of data can be deﬁned and exploited in the same way.
Model-based detection
Comparison of the current signal value with a value predicted by a suitable
model is the eﬃcient method for detection of an unexpected value. The de-
tection discussed in the previous paragraph is essentially of this type with
physically justiﬁed expected characteristics of the inspected signal.

6.2 Data preprocessing
105
Comparison of the output of a ﬁxed ﬁlter with the value in question rests
on the assumption that the normal signal passes the ﬁlter without distortion,
on the assumption that the ﬁlter models its course properly. Of course, the
model can be built explicitly and even recursively estimated.
The simplest, most widely used technique checks the inequality σi;th ≤
|di;t −µi;t|. In it, µi;t and σi;t are the sample mean or median and the stan-
dard deviation of measurements di;t−˚k, . . . , di;t+˚k, respectively. The size of the
window is 2˚k + 1 and h is an optional threshold. The outlier is detected if the
inequality is satisﬁed. This is the noncausal version of the detector. The me-
dian and standard deviation are calculated from di;t−˚k, . . . , di;t−1 in its causal
counterpart.
The two plots in Fig. 6.1 show the outlier removal for artiﬁcial three-
dimensional data. The discussed outlier removal technique was used. The data
di;t marked as outliers are interpolated by µi;t.
0
50
100
150
200
250
300
−30
−20
−10
0
10
20
30
40
50
60
0
50
100
150
200
250
300
−30
−20
−10
0
10
20
30
40
50
60
Fig. 6.1. Outlier removal based on checking deviations from a sample mean com-
puted on a moving window. Shown are raw and processed data.
Mixtures of normal and outlying data
Rare outliers can be processed at the level of an individual signal. Frequently
occurring outliers fed into a mixture estimation create naturally extra com-
ponent(s). The overall mixture estimation ﬁnds the component to which the
current signal value belongs. Thus, we can assume that the processed signal
comes from a single “global” component and to model it by a local simple,
typically two-component mixture. This model is recursively estimated using
quasi-Bayes estimation with forgetting; Section 6.5. Again, the estimation
detects the component to which the inspected value belongs. It detects es-
sentially whether the value is an outlier or not and uses it for correction of

106
6 Solution and principles of its approximation: learning part
the corresponding parameter estimates. Data interpolation is then straight-
forward. The outlier is replaced by the value predicted by the component cor-
responding to “normal” course of the treated signal. Thus, the model-based
interpolation is used.
Success of the speciﬁc application of this idea depends heavily on a good
decision of whether the signal belongs to a single global component. A careful
selection of forgetting factors used for estimation of the local mixture is even
more important. The component describing the “normal” course has to be
highly adapted in order to use eﬀectively a local model that modiﬁes the
normal signal as little as possible. The component describing the outliers
should be adapted very little; otherwise there is danger that the separation of
both modes will be lost.
Model-based interpolation
This method replaces a missing data item by the point prediction made by
a simple model ﬁtted to the outlier-free data. The replacement of the invalid
data item by the last measured value is its practically attractive variant. It
adds small ﬁltering dynamics. The assumption that the basic signal varies
slowly represents the model behind this variant.
Generally, model-based methods are strongly application-domain depen-
dent. For example, the paper [140] describes interesting, model-based tech-
nique for data interpolation of a degraded audio signal. Another method of
the model-based interpolation, as well as the dynamic-boundaries test, are
described in [137].
Filter-based interpolation
This type of interpolation generates approximation of an actual data item by
classical smoothing ﬁlters.
The three plots in Fig. 6.2 illustrate the interpolation of missing data. The
artiﬁcial data with outliers are processed. The raw data are in the ﬁrst plot.
The data out of the given physical boundaries are marked as missing. The
lower bound d = −10 is considered only. In the second plot, the data marked
as missing are set to be equal to the value of this boundary. At the third plot,
the data are interpolated by a ﬁlter-based smoothing.
6.2.3 Filtering
High-frequency measurement noise is a typical disturbing element that should
be removed. There are a lot of techniques available to this purpose. They are
excellent if the frequency content of the removed noise diﬀers substantially
from that of the recovered signal. Otherwise, they add often substantial dy-
namic delay that is harmful in the closed loop.

6.2 Data preprocessing
107
0
50
100
150
200
250
300
−50
−40
−30
−20
−10
0
10
20
30
40
50
(a)
0
50
100
150
200
250
300
−40
−30
−20
−10
0
10
20
30
40
50
60
(b)
0
50
100
150
200
250
300
−50
−40
−30
−20
−10
0
10
20
30
40
50
(c)
Fig. 6.2. Interpolation of missing data. Shown are (a) raw data, (b) data cut at a
given lower bound, and (c) smoothed data.
Local ﬁlters overcome this problem. They are applicable whenever group-
ing of data is desirable. In oﬄine mode even noncausal ﬁltering is acceptable.
Then, the wavelet ﬁlters are a powerful tool for removing selected, typically
high, frequencies.
Classical ﬁlters for smoothing
The classical smoothing ﬁlters remove the high-frequency noise. The mean and
median ﬁlters are justiﬁed whenever we can assume that the system behaves
for a long time period according to a single component. Forgetting or moving-
window versions can be employed. The mean ﬁlter calculated on a moving
window is deﬁned xi;t = 1
˚k
2˚k
k=1 di;t−k+1, where xi;t is the ﬁlter output, and
˚k is the window size. The median ﬁlter on the moving window is deﬁned
xi;t = median(di;t, di;t−1, . . . , di;t−˚k+1), where the function median(·) evaluates
the median of the argument. The mean ﬁlter with forgetting is generated

108
6 Solution and principles of its approximation: learning part
recursively xi;t = λixi;t−1 + (1 −λi)di;t and it is determined by the forgetting
factor λi ∈(0, 1). The initial ﬁltered value is set xi;1 = di;1. The ﬁltered value
is the weighted mean of all previous values of di;t−k+1
xi;t =
t−1

k=1
ρik;tdi;t−k+1.
The weights are ρik;t = (1 −λi)λk−1
i
, except for ρi1;t = λt−1
i
. Notice that
2t
k=1 ρik;t = 1.
Analogy to the mean ﬁlter with forgetting leads to the median ﬁlter with
forgetting deﬁned by xi;t = wmedian(di;t, di;t−1, . . . , di;t−˚k+1; ρi1;t, . . . , ρi˚k;t),
where wmedian denotes the median of data weighted by ρi1;t, . . . , ρi˚k;t, [141].
Local ﬁlters
Local ﬁlters are based on the assumption that the underlying signal does not
change too quickly and on the possibility to group several data [138]. Then,
the signal can be modelled by a simple function, say by a straight line, within
the timespan determined by a single period of operator actions. The redun-
dant data are used for estimating this function whose single value is oﬀered
as the grouped and ﬁltered value. Models of the corrupting noise (light-tailed
Gaussian, mixture of a pair of Gaussian pdfs diﬀering in noise variance, heavy-
tailed Cauchy, one-sided exponential, etc.), fed into the Bayesian estimation
and prediction, provide directly the required estimate. The piecewise appli-
cation of the ﬁlter guarantees that a small dynamic delay is introduced. It
is at most a single period at the operator rate. Irregularities in the original
sampling can be suppressed by choosing evenly distributed time moments at
which the ﬁltered samples are evaluated.
Problem 6.4 (Outlier cancelling ﬁlters) Local regression with heavy-tailed
noise seems to be the proper direction inspected. Obsolete ﬁlters of this type
[142] should be renewed using advanced techniques for online nonlinear ﬁlter-
ing; see Section 3.4.
Wavelet ﬁltering
Wavelet transformation converts original data into diﬀerent levels of resolution
with respect to their spectrum. By manipulating the gained spectra, high
frequencies can be suppressed without removing “edges” from the original
signal. This noncausal ﬁlter can be used in the learning phase only.
Fig. 6.3 shows an example, of wavelet de-noising applied to artiﬁcial data
containing signiﬁcant edges (steps). Data are processed for each channel di(˚t)
separately. The ﬁgure shows a single channel processed. The Haar wavelet is
employed. The original signal is analyzed into wavelet coeﬃcients, Fig. 6.4,

6.2 Data preprocessing
109
ci
0
100
200
300
−5
0
5
10
15
20
25
original signal
t
ci
^
0
100
200
300
−5
0
5
10
15
20
25
signal after wavelet denoising
t
Fig. 6.3. Wavelet de-noising of a piecewise smooth signal. Raw and de-noised data
are shown.
by the discrete wavelet transformation [143]. H0 denotes the low-pass ﬁlter
operator and H1 the high-pass ﬁlter operator and the symbol ↓2 denotes down
sampling at the rate of 2:1. Thereafter, the smallest coeﬃcients are suppressed
0
H
2
1
H
2
0
H
2
1
H
2
0
H
1
H
ic
Level 1 coefficients
Level 2 coefficients
Level 3
2
2
coefficients
Fig. 6.4. Multilevel Haar-wavelet decomposition of the signal by the ﬁlter bank.
The notation ↓2 denotes down-sampling and H0, H1 mark ﬁlter elements.
— using an appropriate threshold — and the signal is reconstructed by a
synthesis process, which is the inverse to that shown in Fig. 6.4.
Problem 6.5 (Comparison of quality of ﬁlters) Mostly, preprocessing re-
duces eﬀects observable on reality. It makes conceptually hard to compare qual-
ity of competitive ﬁlters. Models obtained on diﬀerently ﬁltered data surely
cannot be compared on them.
Probably, the performance on predictions of raw data conditioned on ﬁltered
data should be compared. It is reasonable when preprocessing is “mild”, but it
is not clear whether such a comparison is fair; for instance, when removing
outliers. Obviously, a solution of this problem is of a direct practical interest.

110
6 Solution and principles of its approximation: learning part
Remark(s) 6.2
Recently a novel ﬁltering technique based on a mixture whose components diﬀer
just in ﬁltering used has been proposed [144]. It seems to be an eﬃcient and
promising way to merge a bank of ﬁlters while decreasing sensitivity to the
choice of ﬁlter parameters.
6.2.4 Filters generating factors in an exponential family
The algorithms presented in this text served for creating an eﬃcient software
basis [66] that can be simply tailored to a speciﬁc application. The original
software version was predominantly oriented towards normal ARX factors
(auto-regressive models with external inputs) and Markov-chain factors. They
both belong to the dynamic exponential family, Section 3.2, Agreement 3.1,
that provides the practically feasible factors. A rich supply of other feasible
factors is obtained from them by data transformations d →˜d and ﬁltering,
possibly applied also to regressors forming the regression vector ψ. This Sec-
tion discusses and classiﬁes possible ways of generating them in order to allow
their systematic implementation.
The ith parameterized factor, predicting the factor output di;t and belong-
ing to the dynamic exponential family is described by the p(d)f
f(di;t|d(i+1)···˚
d;t, d(t −1), Θ) ≡f(di;t|ψi;t, Θ)
= A(Θ) exp [⟨B(Ψi;t), C(Θ)⟩+ D(Ψi;t)] .
Two ingredients determine it.
1. The ﬁlter F(·)
[Ψi;t, Ωt] = F

di···˚
d;t, Ψi;t−1, Ωt−1

(6.17)
updating recursively the ﬁltered data vector
Ψ ′
i;t ≡[ ˜di;t, ψ′
i;t] ≡[ﬁltered factor output,ﬁltered regression vector].
The symbol Ωt denotes a ﬁnite-dimensional ﬁlter state.
2. The elements in the functional form of the exponential family,
⟨·, ·⟩≡a functional, linear in the ﬁrst argument,
(6.18)
A(Θ) ≡a nonnegative scalar function deﬁned on Θ∗,
B(Ψ), C(Θ) ≡compatible array functions deﬁned on Ψ ∗, Θ∗, and
D(Ψ) ≡scalar function on Ψ ∗.
The intended use of the ﬁltered data vectors in prediction and design of
actions imposes constraints on the admissible ﬁlters.
Requirement 6.1 (Allowed ﬁlters) The ﬁlter (6.17)
1. determines the ﬁltered regression vector ψt independently of the value di;t;

6.2 Data preprocessing
111
2. allows us to reconstruct uniquely the original di;t when ˜di;t and ψi;t are
given;
3. allows us to reconstruct uniquely the original actions among di+1;t, . . . , d˚
d;t
when ψi;t is given.
A limited supply of the practically available ﬁlters (6.17) and elements
(6.18) permits us to label them by the data vector type ≡
†Ψ ∈
†Ψ ∗≡
{1, . . . , ˚
†Ψ} and by the functional form type ≡†F∈†F ∗≡{1, . . . , ˚
†F}.
The following allowed ﬁlters are simply available.
Allowed ﬁltering of data vectors
•
State φt in the phase form; see Agreement 5.4.
The time-invariant ﬁlter state Ωis the list determining the structure
of the data vector constructed from the state in the phase form.
•
State φt in the phase form transformed by a ﬁxed aﬃne mapping.
Scaling factor, additive term and structure of the data vectors form
the time-invariant ﬁlter state Ω.
•
Generalized ARX models [69] with a transformed factor output ob-
tained from a one-to-one, unknown-parameter-free transformation of
the factor output.
The ﬁlter state is in the phase form and the Jacobian of the discussed
transformation is independent of unknown parameters.
The log-normal factors, Section 8.1.6, with the state in the phase form
(see Agreement 5.4) serves as an important example of this type. Gen-
erally, this simple class increases the modelling power surprisingly.
•
ARMAX factors, an extension of ARX factor by a known moving av-
erage (MA) model of the noise, is converted to an ARX model by
time-varying prewhitening [145].
The ﬁlter state Ωt contains the time-invariant description of the noise
correlations, i.e., both structure and parameters. It also contains the
time-varying ﬁlter resulting from it; see [145].
The factor is equivalent to a special state-space model that leads to
a special Kalman ﬁltering [146], which can be combined with the pa-
rameter estimation without an approximation.
•
A mixture of ARMAX factors of the above type with a common ARX
part [144].
The ﬁlter state Ωt contains several diﬀerent Ωj;t, each of the type
described in the previous item.
•
A mixture of ARX factors with the common ARX part and compo-
nents diﬀering in ﬁlters applied to the original state in the phase form.
The ﬁlter state Ωt contains information on the structure and time-
invariant parameters of the underlying ﬁlters.
Available functional forms within the exponential family
•
Normal factors, Chapter 8.

112
6 Solution and principles of its approximation: learning part
•
Markov-chain factors, Chapter 10.
•
MT normal factors, Chapter 11.
•
Static factors in the exponential family.
Both these lists can surely be extended. For instance, speciﬁc incremental
versions of the state in the phase form may be found as a useful speciﬁc
instance. Nonlinear/non-Gaussian factors embedded in the exponential family
in the way described in Section 3.4 serve as another example.
6.2.5 Statistics for the exponential family
The Bayesian estimation in the exponential family is described by Proposition
3.2. We use conjugate prior pdfs. It has the form
f(Θ) ≡f(Θ|d(0)) ∝A(Θ)ν0 exp [⟨V0, C(Θ)⟩] .
The estimation is combined with stabilized forgetting, Algorithm 3.1. It is
speciﬁed by the forgetting factor λ ∈[0, 1] and alternative pdf ⌊Af(Θ|d(t)).
We select it as a conjugate pdf, too
⌊Af(Θ|d(t)) ≡⌊Af(Θ) ∝A(Θ)
⌊Aνt exp
	6
⌊AVt, C(Θ)
7
.
In the discussed context, it is mostly chosen as a time invariant pdf. So that,
without substantial restriction of generality, we can assume that the formal
structure of its updating coincides with that of the factor statistics in question.
With the options made, the posterior pdf then has conjugate form and its
statistics νt, Vt can be updated recursively. Approximate estimations, Section
6.5, modify these recursions, giving a weight wt ∈[0, 1] to increments of these
statistics. The compound recursions, also describing evolution of the data
vector, have the following form. The ﬁrst part reﬂects the data updating; cf.
Proposition 2.13:
Filtering: [Ψt, Ωt] = F(dt, Ψt−1, Ωt−1), Ψ0, Ω0 given
(6.19)
Weighted data updating: ˜Vt = Vt−1 + wtB(Ψt),
˜νt = νt−1 + wt
V0, ν0 are chosen as a description of the prior pdf,
Filtering of the alternative:
	
⌊AΨt, ⌊AΩt

= ⌊AF(dt, ⌊AΨt−1, ⌊AΩt−1)
⌊AΨ0, ⌊AΩ0 given
Alternative data updating: ⌊AVt = ⌊AVt−1 + ⌊Awt
⌊AB

⌊AΨt

⌊Aνt = ⌊Aνt−1 + ⌊Awt,
⌊AV0, ⌊Aν0 characterize a prior alternative.
The time updating closes the recursion by the stabilized forgetting formula,
Algorithm 3.1,
Vt = λ ˜Vt + (1 −λ) ⌊AVt,
νt = λ˜νt + (1 −λ) ⌊Aνt.
(6.20)

6.2 Data preprocessing
113
The externally supplied weights wt, ⌊Awt, the functions B(·), ⌊AB(·) and up-
dating of data vectors Ψt, ⌊AΨt may diﬀer. Both values B(·), ⌊AB(·) have to
be compatible with the commonly considered array function C(Θ). This can
be checked when preparing the time updating.
Thus, the complete description of respective factors can be composed of
the above elements. Let us make it formal.
Agreement 6.2 (Description of factors in the exponential family)
The factor in the exponential family is described by
 †Ψ, †F, Ωτ, Ψτ, Vτ, ντ

≡(ﬁlter type, functional type, ﬁlter state,
data vector, V -statistics,degrees of freedom) .
The initial values, τ = 0, are stored for application of the iterative learning,
Section 6.4.1, in addition to the current values with τ = t.
The used ﬁlter has to meet Requirement 6.1.
6.2.6 Prediction in EF with statistics gained by ﬁltering
The term D(Ψ) occurring in the deﬁnition of the exponential family does not
inﬂuence estimation. Also, the estimation need not refer to the original data
and can completely use the ﬁltered versions of data vectors. For prediction,
however, both these aspects are signiﬁcant.
Proposition 3.2 implies that the prediction of the ith ﬁltered factor output
has the form (3.8)
f( ˜di;t|d(i+1)···˚
d;t, d(t −1)) = I(Vi;t−1 + B(Ψi;t), νi;t−1 + 1)
I(Vi;t−1, νi;t−1)
exp[D(Ψi;t)], with
I(V, ν) ≡

A(Θ)ν exp [⟨V, C(Θ)⟩] dΘ.
(6.21)
Proposition 2.5 on transformation of random quantities gives
f(di;t|d(i+1)···˚
d;t, d(t −1)) = J(Ψi;t)I(Vi;t−1 + B(Ψi;t), νi;t−1 + 1)
I(Vi;t−1, νi;t−1)
exp[D(Ψi;t)]
J(Ψi;t) ≡
∂F(di···˚
d;t, Ψi;t−1, Ωi;t−1)
∂di;t
.
(6.22)
This prediction serves for presenting predictions to the operator as well as
for computing v-likelihood values (see Section 6.1.2) used for comparing of
various estimation variants. These v-likelihood values can be used even for
comparison of diﬀerent ﬁlters applied to the same signal. This hints how to
solve Problem 6.5.

114
6 Solution and principles of its approximation: learning part
6.3 Use of prior knowledge at the factor level
The design of the advisory system relies mostly on vast amount of informative
data, but a strong prior knowledge may improve the quality of the resulting
model. This opportunity should not be missed and its inspection forms the
core of this section.
We deal with prior knowledge at the factor level: a prior pdf for each factor
is considered as an entity on its own. This ﬁts well the product form of the
considered pdfs; see Agreement 6.1.
Computational constraints force us to use predeﬁned functional forms of
prior estimates of factors. Mostly, they are taken as conjugate prior pdfs (3.13).
In this case, values of statistics determining them serve for expressing the prior
knowledge.
Initially, the available knowledge pieces are translated into a common
basis of ﬁctitious data, i.e., the data observed or potentially observable by
the advisory system. Fictitious data are split into internally consistent data
blocks. Each of them is processed by the Bayes rule with forgetting; see Section
3.1. Then, the estimation results are merged. The merging task is nontrivial
due to the unknown, possibly not fully consistent, relationships of the pro-
cessed data blocks. The particular knowledge sources are below labelled by
Kk, k ∈k∗≡{1, . . . ,˚k}.
6.3.1 Internally consistent ﬁctitious data blocks
Some sources of knowledge provide knowledge directly in the form of data
blocks. These blocks include obsolete data, data from identiﬁcation experi-
ments diﬀering from usual working conditions — like measurement of step re-
sponses — and data gained from a realistic simulation. Section 6.3.2 discusses
other sources of knowledge that have to be “translated” into data blocks. The
common expression as data blocks allows us to deal with all of them in a
uniﬁed way.
We sort the knowledge sources into groups whose members provide inter-
nally consistent data blocks.
Agreement 6.3 (Internally consistent data blocks) The data block DK
reﬂecting the knowledge piece K is called internally consistent iﬀf(Θ|K) can
be expressed as the result of Bayesian estimation, possibly with appropriately
chosen forgetting; see Section 3.1. The estimation inserts data DK into the
considered parameterized model and starts from a ﬂat pre-prior pdf ¯f(Θ).
The adequate forgetting should always be used in order to counteract under-
modelling. This is of an extreme importance for simulators that may provide
a huge number of data and make overﬁtting of the posterior pdfs possible.

6.3 Use of prior knowledge at the factor level
115
Algorithm 6.2 (Processing of internally consistent data blocks)
Initial mode
•
Select the structure of the considered factor.
•
Specify, usually very ﬂat, pre-prior pdf ¯f(Θ).
•
Select the set of alternative forgetting factors λ ∈λ∗≡{λ1, . . . , λ˚λ}, λi ∈
(0, 1]. Typically,
λi = 1 −10−i, i = 1, 2, 3, 4, 5, 6.
(6.23)
The choice is implied by the knowledge that the eﬀective memory is (1−λi)−1
and by the wish to cover a wide time span with a few grid points.
Processing mode
1. Perform Bayesian estimation and prediction starting from ¯f(Θ) and using
the data block DK for all λ ∈λ∗, i.e., obtain f(Θ|K, λi) ≡f(Θ|DK, λi)
and v-likelihood f(d(˚t)|K, λi), i ∈{1, . . . ,˚λ} evaluated on real data d(˚t).
2. Choose f(Θ|K) ≡f(Θ|K, ¯λ), where ¯λ is a point estimate of the forgetting
factor within the set λ∗. The value ¯λ is mostly taken as the maximizing
argument of the obtained v-likelihood f(d(˚t)|K, λi).
Remark(s) 6.3
1. The construction is applicable if the data DK allow us to evaluate the
value of the parameterized model f(d|ψ, Θ) at least for a single data vector
Ψ = [d, ψ′]′.
2. Selection of the best forgetting factor can be completely avoided if we take
the pairs (K, λi), i ∈i∗, as diﬀerent knowledge items and merge them as
described in Section 6.3.3. The weighting used there distinguishes diﬀer-
ences in quality implied by diﬀerences in forgetting.
6.3.2 Translation of input-output characteristics into data
Often, guessed or designed input-output characteristics of the modelled system
are available. Static gain, a point on frequency response, and time-constants
serve as examples. The majority, if not all, have an experimental basis. They
describe the expected response of the system to a given stimulus. Such knowl-
edge item K gives characteristics of the predictor
f(d|ψ) ≡f(d|ψ, K) ≡

f(d|ψ, Θ)f(Θ|K) dΘ
(6.24)
for a scalar d (a factor is dealt with) and a ﬁxed regression vector ψ. Mostly,
some moments of the predictive pdf can be guessed. Formally, we assume the
knowledge piece in the form
h(ψ) =

H(d, ψ)f(d|ψ) dd,
(6.25)

116
6 Solution and principles of its approximation: learning part
where h(ψ) and H(Ψ) ≡H(d, ψ) are known vector functions. Typically, we
know
ˆd =

df(d|ψ) dd,
rd =

(d −ˆd)2f(d|ψ) dd.
(6.26)
The case (6.26) corresponds to the knowledge h(ψ) =
	
ˆd, rd

, H(d, ψ) ≡
H(Ψ) =
	
d, (d −ˆd)2
.
If no pdf f(Θ|K) fulﬁlling (6.25) exists then this information source cannot
be internally consistent (see Agreement 6.3), and has to be split into internally
consistent parts. However, as a rule, the knowledge item (6.24), (6.25) does
not determine the constructed pdf f(Θ|K) completely. It is reasonable to
construct a pdf f(Θ|K) that expresses just the considered information item.
Thus, it makes sense to choose such a f(Θ|K) that is the nearest one to the
ﬂat pre-prior pdf ¯f(Θ). The prior estimate f(Θ|K) is searched for among all
pdfs
f(Θ|K) ∈f ∗
K ≡{pdfs fulﬁlling (6.24), (6.25)}.
(6.27)
It motivates our option of f(Θ|K) respecting (6.24) and (6.25) as
f(Θ|K) ∈Arg min
f∈f ∗
K
D(f|| ¯f).
(6.28)
Proposition 6.4 (Knowledge of input-output characteristics) The min-
imizing argument f(Θ|K) of (6.28) respecting the constraint (6.25) has the
form
f(Θ|K) =
¯f(Θ) exp[µ′g(ψ, Θ)]
 ¯f(Θ) exp[µ′g(ψ, Θ)] dΘ,
where
(6.29)
g(ψ, Θ) ≡

H(d, ψ)f(d|ψ, Θ) dd
and µ solves
(6.30)
h(ψ) =

g(ψ, Θ) exp[µ′g(ψ, Θ) ¯f(Θ)] dΘ

exp[µ′g(ψ, Θ) ¯f(Θ)] dΘ
.
(6.31)
Proof. Inserting (6.24), determined by an arbitrary f(Θ) ≡f(Θ|K) ∈f ∗
K,
into the constraint (6.25), we get
h(ψ) =

H(d, ψ)
#
f(d|ψ, Θ)f(Θ) dΘ
$
dd =

g(ψ, Θ)f(Θ) dΘ.
(6.32)
The second equality is implied by the Fubini theorem on multiple integrations
and by the deﬁnition (6.30). The equality (6.32), normalization

f(Θ) dΘ = 1
and non-negativity f(Θ) ≥0 determine the convex set where the optimal
f(Θ|K) is searched for. Thus, we optimize the convex KL divergence on the
convex set. The relevant Lagrangian, given by the vector multiplier µ, is

6.3 Use of prior knowledge at the factor level
117

f(Θ)
#
ln
f(Θ)
¯f(Θ)

−µ′g(ψ, Θ)
$
dΘ
=

f(Θ)
#
ln

f(Θ)
¯f(Θ) exp[µ′g(ψ, Θ)]
$
dΘ
=

f(Θ)
⎡
⎢⎣ln
⎛
⎜
⎝
f(Θ)
¯
f(Θ) exp[µ′g(ψ,Θ)]
 ¯
f( ˜
Θ) exp[µ′g(ψ, ˜
Θ)] d ˜
Θ
⎞
⎟
⎠
⎤
⎥⎦dΘ
−ln

¯f(Θ) exp[µ′g(ψ, Θ)] dΘ

.
Properties of the KL divergence imply that the ﬁrst term is minimized by the
pdf (6.29). It is the overall minimizer as the second term is not inﬂuenced by
this choice at all. The multiplier µ has to be chosen so that the constraints
(6.25) are met.
Remark(s) 6.4
1. Solution of the algebraic equation (6.31) is often a diﬃcult task.
2. The obtained form diﬀers generally from the conjugate prior pdf. For
this reason, a speciﬁc optimization is needed when the conjugate prior
pdf (3.13) is required.
3. The majority of elaborated solutions are related to a single-input u single-
output y linear system with the state in the phase form
ψt = [ut, . . . , ut−∂u, yt−1, . . . , yt−∂y, 1].
Knowledge of the static gain g is the simplest example of expressing the
knowledge pieces in terms of (6.26). The following correspondence holds:
E[g] ≈ˆg = ˆd, cov[g] ≈rg = rd and
ψ′ ≡[ 1, . . . , 1
  
(∂u+1) times
, ˆg, . . . , ˆg
  
∂y times
, 1].
Dominant time constant, knowledge of a point on frequency response, mea-
sured step response, and smoothness of the step response are other exam-
ples elaborated for this model [115, 147, 148].
6.3.3 Merging of knowledge pieces
A combination of results in Sections 6.3.1 6.3.2, gives a collection of prior
estimates f(Θ|Kk), k ∈k∗≡{1, . . . ,˚k} obtained by the processing of indi-
vidual, internally consistent, data blocks and of individual knowledge items.
We have to use them for constructing a single estimate ˆf(Θ|d(˚t), K(˚k)) of the
posterior pdf f(Θ|d(˚t), K(˚k)) that reﬂects all of them as well as the measured

118
6 Solution and principles of its approximation: learning part
data d(˚t). This posterior pdf should be close to the unknown posterior pdf
f(Θ|d(˚t), K(˚k)) that arises from the application of the Bayes rule starting
from an unknown “objective” combination f(Θ|K(˚k)). For the construction
of the estimate ˆf(Θ|d(˚t), K(˚k)), we
•
can use available real data d(˚t) and pdfs f(Θ|Kk), k ∈k∗: they form our
experience P for the addressed estimation task,
•
do not know mutual relationships of the prior estimates f(Θ|Kk), k ∈k∗,
•
are aware that the quality of individual pdfs f(Θ|Kk), k ∈k∗may vary
substantially but in an unknown manner.
We face the problem of estimating the unknown pdf f(Θ|d(˚t), K(˚k)) ∈f ∗. The
estimation of this inﬁnite-dimensional object is hard. We solve it by adopting
the following approximation.
Agreement 6.4 (Approximation of the estimated pdf) Let f ∗
k
⊂f ∗
contain those posterior pdfs f(Θ|d(˚t), K(˚k)) for which f(Θ|d(˚t), Kk) is the
best approximating pdf among

f(Θ|d(˚t), Kk)

k∈k∗.
On f ∗
k, we approximate the unknown objective pdf f ≡f(Θ|d(˚t), K(˚k)),
combining prior knowledge K(˚k) and real data, by the pdf fk ≡f(Θ|d(˚t), Kk),
i.e.,
f ≡f(Θ|d(˚t), K(˚k)) ≈f(Θ|d(˚t), Kk) ≡fk, ∀f(Θ|d(˚t), K(˚k)) ∈f ∗
k.
(6.33)
Proposition 6.5 (Merging of knowledge pieces) Let the approximation
(6.33) be adopted, the natural conditions of decision making (2.36) met and
the sets f ∗
j be a priori equally probable. Then, the merger ˆf minimizing the
expected KL divergence E
	
D

ˆf||f

, exploiting the experience P consisting
of measured data d(˚t) and prior pdfs corresponding to individual internally
consistent knowledge pieces {f(Θ|Kk)}k∈k∗has the form
ˆf(Θ|d(˚t), K(˚k)) ∝L(Θ, d(˚t))
 
k∈k∗
[f(Θ|Kk)]βk|d(˚
t) .
(6.34)
In (6.34), L(Θ, d(˚t)) is the likelihood corresponding to the considered param-
eterized factor and measured data d(˚t). The posterior probabilities βk|d(˚t) of
sets f ∗
k are
βk|d(˚t) ∝

L(Θ, d(˚t))f(Θ|Kk) dΘ.
(6.35)
Thus, the probabilities βk|d(˚t) are equal to the normalized v-likelihood corre-
sponding to respective choices f(Θ|Kk) of the prior pdfs.
Proof. Under (6.33), the minimization of the approximate expected KL
divergence can be performed as follows.

6.3 Use of prior knowledge at the factor level
119
Arg min
ˆ
f
E
	
D

ˆf
!!!
!!! f

= Arg min
ˆ
f
E
" 
k∈k∗
χf ∗
k (f)E
	
D

ˆf
!!!
!!! f
!!! P
%
≈

(6.33)
Arg min
ˆ
f
E
" 
k∈k∗
E
	
χf ∗
k (f) D

ˆf
!!!
!!! fk
!!! P
%
=
(6.36)
=

Proposition 2.7
Arg min
ˆ
f

k∈k∗
E
	
χf ∗
k (f) D

ˆf
!!!
!!! fk
!!! P

=

βk|d(˚t) ≡E[χf ∗
k (f)|P]
deﬁnition of D
= Arg min
ˆ
f

ˆf(Θ|d(˚t), K(˚k)) ln

ˆf(Θ|d(˚t), K(˚k))
/
k∈k∗[f(Θ|d(˚t), Kk)]βk|d(˚
t)

dΘ.
Normalization of the denominator in the last fraction to a pdf and the use of
the second property of the KL divergence, Proposition 2.10, imply the form
(6.34) of the approximating pdf. To prove remaining statements, it is suﬃcient
to realize that the pdfs combined into the geometric mean have the common
factor equal to the likelihood function L(Θ, d(˚t)). The weight βk|d(˚t) is the
posterior probability that fk ≡f(Θ|Kk) is the closest pdf to f(Θ|K(˚k)), i.e.,
f(Θ|K(˚k)) ∈f ∗
k. Values of these posterior probabilities are simply obtained
by the Bayes rule applied to hypotheses f(Θ|K(˚k)) ∈f ∗
k, k ∈k∗, starting
from the assumed uniform prior on them. It proves the formula (6.35).
Algorithm 6.3 (Merging knowledge pieces)
1. Apply Algorithm 6.2 to get f(Θ|Kk), k ∈k∗on internally consistent data
blocks.
2. Quantify individual knowledge pieces as described by Proposition 6.4.
3. Evaluate the likelihood function L(Θ, d(˚t)) corresponding to the considered
parameterized model.
4. Evaluate the v-likelihood
f(d(˚t)|Kk) =

L(Θ, d(˚t))f(Θ|Kk) dΘ with prior pdfs f(Θ|Kk), k ∈k∗.
5. Evaluate weights
βk|d(˚t) =
f(d(˚t)|Kk)
2
˜k∈k∗f(d(˚t)|K˜k), k ∈k∗.
6. Determine the merger as the posterior pdf to be used
ˆf(Θ|d(˚t), K(˚k)) ∝L(Θ, d(˚t))
 
k∈k∗
[f(Θ|Kk)]βk|d(˚
t).
Note that the used “prior pdf” /
k∈k∗[f(Θ|Kk)]βk|d(˚
t) is seen in the last step
of the merging algorithm.

120
6 Solution and principles of its approximation: learning part
6.4 Construction of the prior estimate
It is known [49] that mixtures cannot be identiﬁed uniquely. This means that
the estimation results depend on the prior parameter estimates of the indi-
vidual factors and on the estimates of component weights as well as on the
overall structure used. The need to use an approximate estimation, Section
6.5, makes the situation even harder. Thus, the choice of the prior pdf signif-
icantly determines the quality of the results.
All clustering and mixture estimation techniques face a similar initializa-
tion problem. There is a lot of algorithms for approaching it, for instance,
[149]. We have, however, found no good solution suitable for estimation of
mixtures with high-dimensional dynamic components and a large estimation
horizon ˚t.
Our probably novel approach is gradually presented here. It applies tai-
lored branch-and-bound Algorithm 6.1 for inspection of alternative prior
pdfs. Subsection 6.4.1 interprets this approach as a feasible approximation
of Bayesian estimation of unknown prior pdf and demonstrates that the cor-
responding v-likelihood is the relevant functional to be maximized. Omission
of variants with smaller v-likelihoods is justiﬁed as common bounding map-
ping in Section 6.4.2. The major problem of selecting promising alternatives,
i.e., the design of branching mappings, forms the body of this important sec-
tion. The variants exploit guesses of posterior pdfs obtained from previous
guesses of prior pdfs. The posterior pdfs are too sharp to be combined di-
rectly into new variants of prior pdfs. Thus, they have to be ﬂattened in some
way. Flattening mappings are inspected in Subsection 6.4.3. Then, a group of
branching mappings is studied that preserves the structure of inspected mix-
ture variants, Sections 6.4.4, 6.4.5, 6.4.6, 6.4.7. They diﬀer in complexity and
applicability. They serve as building blocks of the most important technique,
proposed in Section 6.4.8, which inspects prior pdfs corresponding to diﬀering
structures of the estimated mixture.
A signiﬁcant part of the complexity of the initialization problem stems
from the dynamic nature of the estimated mixture. Restriction to static mix-
tures makes the problem simpler. The relationships of dynamic and static
mixtures are inspected in concluding Section 6.4.9, which sheds some light on
the applicability of static clustering techniques to dynamic data records.
6.4.1 Iterative construction of the prior pdf
The Bayes rule speciﬁes the posterior estimates f(Θ|d(˚t)) ∝f(d(˚t)|Θ)f(Θ) in
a noniterative fashion. At the same time, iterative data-based constructions
of f(Θ) are practically and successfully used. They face the following common
and often overlooked danger.
Let the pdf fn(Θ|d(˚t)) be the pdf obtained through the nth formal repe-
tition of the Bayes rule

6.4 Construction of the prior estimate
121
fn(Θ|d(˚t)) ∝f(d(˚t)|Θ)fn−1(Θ|d(˚t))
with f0(Θ|d(˚t)) ≡f(Θ). Then, fn(Θ|d(˚t)) ∝[f(d(˚t)|Θ)]nf(Θ). For f(Θ) > 0
on Θ∗, the pdf fn(Θ|d(˚t)) concentrates on Θ maximizing globally the likeli-
hood function f(d(˚t)|Θ). This seems to be a good property. The convergence
to a meaningful point is, however, likely to be spoiled when the involved likeli-
hood f(d(˚t)|Θ) is evaluated approximately only, as must be done for mixtures.
Moreover, the pdf obtained in this way completely loses information on pre-
cision of such an estimate.
The following re-interpretation and modiﬁcation of the iterative evalua-
tions resolves the outlined problem.
Iterations are used when we are uncertain about the adequate prior pdf.
Moreover, the likelihood function is evaluated approximately only and the
quality of the approximation depends on the prior pdf used. Thus, the like-
lihood function is uncertain, too. According to the adopted Bayesian philos-
ophy, any uncertainty should be treated as randomness. Thus, the joint pdf
f(d(˚t), Θ) of data d(˚t) and parameters Θ becomes an inﬁnite-dimensional un-
known (hyper)parameter. The mixture estimation of interest speciﬁes the set
f ∗(d(˚t), Θ) of the possible joint pdfs. The considered estimation task is then
characterized by the following agreement.
Agreement 6.5 (Estimation of the joint pdf of data and parameters)
An estimate ˆf(d(˚t), Θ) of the joint pdf of data and parameters f(d(˚t), Θ) is
searched for within the set
f ∗(·, ·) ≡

f(d(˚t), Θ) ≡L(Θ, d(˚t))f(Θ)

with the likelihood
L(Θ, d(˚t)) =
 
t∈t∗
f(dt|d(t −1), Θ) given by the parameterized model
f(dt|d(t −1), Θ) =

c∈c∗
αcf(dt|d(t −1), Θc, c).
(6.37)
Its components are products of factors
f(dt|d(t −1), Θc, c) =
 
i∈i∗
f(dic;t|ψic;t, Θic, c)
and the prior mixture estimate f(Θ) is a product of (conjugate) prior pdfs
f(Θ) = Diα(κ0)
 
i∈i∗
f(Θic); see Agreement 6.1.
The constructed estimator d∗(˚t) →f ∗is required to specify a point estimate
ˆf(·, ·) ∈f ∗(·, ·) of the joint pdf f(·, ·) of data and parameters. The evaluations
have to stop after a ﬁnite number of evaluation steps.
The application of the general decision-making theory needs a speciﬁcation
of the expected loss to be optimized. It calls for speciﬁcation of probabilistic
measure on the set f ∗(·, ·) of pdfs. It is diﬃcult both technically and practi-
cally. In order to avoid this diﬃculty, we interpret the maximum likelihood

122
6 Solution and principles of its approximation: learning part
estimate as a point Bayesian estimate corresponding to a special prior distri-
bution. This interpretation is correct under some technical conditions, e.g.,
[150]. We assume that these conditions are applicable in our case. Then, we
have to describe the corresponding (hyper)likelihood function ⌊hL(f(·, ·), d(˚t))
only. It means that we have to specify the functional dependence of the dis-
tribution of the observed data d(˚t) on the estimated inﬁnite-dimensional (hy-
per)parameter f(·, ·) ≡f(d(˚t), Θ). This likelihood equals to the marginal pdf
of data d(˚t) computed for each unknown hyperparameter formed by the un-
known joint pdf f(·, ·) of data and parameters. Thus,
⌊hL(f(·, ·), d(˚t)) ≡f

d(˚t)|f(·, ·)

=

f(d(˚t), Θ) dΘ.
(6.38)
The last equality is implied by the marginalization rule, Proposition 2.4.
These considerations lead us to the choice of the estimate ˆf(d(˚t), Θ) of the
joint pdf f(d(˚t), Θ) of data and parameters as
ˆf(d(˚t), Θ) ∈Arg
max
˜
f∈f ∗(·,·)

˜f(d(˚t), Θ) dΘ.
(6.39)
For any ˜f ∈f ∗(·, ·) (6.37), we are able to evaluate (approximately) the max-
imized functional (6.39). We face an “ordinary” optimization problem over
the inﬁnite-dimensional domain (6.37). We tackle it by the branch-and-bound
techniques prepared in Section 6.1.3. Moreover, we use the fact that for a
chosen guess of the prior pdf ˆf(Θ) the approximation of the likelihood L in
(6.37) is uniquely determined by the algorithm adopted for the approximate
estimation; see Section 6.5.
Note that forgetting can be used during the search. The ﬁnal estimates
have to be done without forgetting as we need a time-invariant description of
the o-system. We summarize the above thoughts.
Agreement 6.6 (Search for the joint pdf of data and parameters) We
search for a variant of ˆf(Θ) for which the joint pdf ˆf(d(˚t), Θ) in f ∗(·, ·) (6.37)
evaluated by an approximate algorithm, Section 6.5, with the unit forgetting
exhibits the highest v-likelihood ˆf(d(˚t)). The dimensionality of the problem
directs us towards the maximization by the branch-and-bound techniques; Sec-
tion 6.1.3.
6.4.2 Common bounding mapping
The bounding mapping U (6.16) adopted further on is simple and universal.
The arguments Xι(n+1|n) ≡fι(n+1|n)(·, ·) in (6.37) with smallest values of
v-likelihoods
F(Xι(n+1|n)) ≡f

d(˚t)|fι(n+1|n)(·, ·)

=

fι(n+1|n)(·, ·) dΘ ≡fι(n+1|n)(d(˚t))

6.4 Construction of the prior estimate
123
are omitted when forming the new set of candidates X∗
n+1 ⊂f ∗(·, ·); see
(6.37).
It is necessary to stress that for application it is useful to take into account
the following points.
•
Values F(Xι(n+1|n)) ≡fι(n+1|n)(d(˚t)) for omitted guesses of prior pdfs
have to be known and compared with the best value of the v-likelihood
¯Fn+1|n ≡¯fn+1|n found up to this moment. This trivial observation can be
and was overlooked in a complex optimization setting.
•
The number of preserved or omitted arguments is the only optional pa-
rameter of this mapping. It is mostly dictated by the adopted branching
mapping that usually needs several arguments in X∗
n ⊂f ∗(·, ·) for gener-
ating new promising candidates to form new candidates X∗
n+1|n ⊂f ∗(·, ·);
see (6.37).
6.4.3 Flattening mapping
Our discussion on the choice of the prior estimate started with an inspection
of the iterative application of the Bayes rule. Its basic idea — that posterior
pdf f(Θ|d(˚t)) probably gives a better clue about Θ than the prior pdf f(Θ)
— is elaborated here.
The posterior estimate of parameters cannot be directly used as a new
guess of the prior pdf as it is much more concentrated than a reasonable prior
pdf. It is dangerous in the discussed context, as the original prior has been
assumed to be unreliable, and thus the posterior pdf may be concentrated at a
false subset of Θ∗. In order to avoid this danger, we have to apply a ﬂattening
mapping G
G : f(Θ|d(˚t)) →ˆf(Θ)
(6.40)
to get a new guess of ˆf(Θ) of the prior pdf f(Θ). It has to be designed so that
a compromise between the following contradictory requirements is reached.
•
ˆf(Θ) should resemble f(Θ|d(t)),
•
ˆf(Θ) should be ﬂat enough.
According to the adopted development methodology, we design G by solving
a suitable decision-making task.
For the ﬁxed d(˚t), let us denote the posterior pdf ˜f ≡˜f(Θ) ≡f(Θ|d(˚t)).
Moreover, we select a prototype of a ﬂat pdf ¯f ≡¯f(Θ), called also pre-prior
pdf. A uniform pdf (even an improper one) suits often to this purpose.
The pdf ˆf ≡f(Θ) generated by the constructed ﬂattening mapping G
(6.40) is found as a minimizing argument of the functional
D

ˆf|| ˜f

+ qD

ˆf|| ¯f

speciﬁed by the optional q > 0.
(6.41)
The KL divergence (2.25) D

ˆf|| ˜f

reﬂects the ﬁrst requirement and D

ˆf|| ¯f

the second one. The positive weight q is the design parameter that controls

124
6 Solution and principles of its approximation: learning part
the compromise we are seeking for. It can be interpreted as the ratio of prob-
abilities assigned to hypotheses that the true pdf equals ˆf and ¯f, respectively.
Proposition 6.6 (Optimal ﬂattening mapping) Let ˜f and ¯f be a given
pair of pdfs deﬁned on Θ∗. Then, the pdf ˆf ∈f ∗≡{pdfs deﬁned on Θ∗}
minimizing the functional (6.41) has the form
ˆf ∝˜f Λ ¯f 1−Λ with Λ = 1/(1 + q) ∈(0, 1).
(6.42)
Proof. It holds ˆf ∈Arg minf∈f ∗D

f|| ˜f

+ qD

f|| ¯f

≡
≡

deﬁnition of D
Arg min
f∈f ∗

f
#
ln
f
˜f

+ q ln
f
¯f
$
dΘ
= Arg min
f∈f ∗(1 + q)

f ln

f
˜f 1/(1+q) ¯f q/(1+q) dΘ

≡

(6.42)
ˆf.
The last identity is implied by independence of the normalizing shift
ln

˜f 1/(1+q) ¯f q/(1+q) dΘ

of the optional pdf f, by the positivity of 1 + q, the deﬁnition of Λ (6.42), the
deﬁnition of ˆf (6.42) and Proposition 2.10.
The pdf ˆf found in Proposition 6.6 coincides formally with a geometric
mean of a pair of pdfs; see Proposition 3.1. The power Λ has, however, another
interpretation. It is controlled by the optional weight q > 0 ⇔Λ ∈(0, 1)
balancing the Bayes rule and the ﬂattening.
The adopted Agreement 6.1 implies that the estimate of mixture parame-
ters Θ is a product of the Dirichlet pdf describing component weights α and
the product of pdfs describing parameters Θic of individual factors. The KL
divergence of a pair of such products is simply sum of KL divergences between
the corresponding marginal pdfs creating the product. Consequently, Propo-
sition 6.6 can be applied to each of them with its speciﬁc weight and thus its
speciﬁc Λ.
Flattening was motivated by an iterative application of the Bayes rule.
The combination of the Bayes rule and ﬂattening is described by the operator
AΛ : f(Θ) →

L(Θ, d(˚t))f(Θ)
Λ [ ¯f(Θ)]1−Λ
 
L(Θ, d(˚t))f(Θ)
Λ [ ¯f(Θ)]1−Λ dΘ
.
(6.43)
Its use requires careful speciﬁcation of the ﬂattening rate Λ.

6.4 Construction of the prior estimate
125
Choice of ﬂattening rate in branching
Flattening is often applied as a part of branching. Then, it is eﬀectively used
just once and the asymptotic analysis in a subsequent section gives no hint
about how to choose the ﬂattening parameter Λ. We discuss an adequate
choice here.
For the Dirichlet pdf Diα(κ) (6.4) estimating component weights, the sum
2
c∈c∗κc is the eﬀective number of observed and ﬁctitious data; see Chapter
10. Thus, the prior and posterior values of this sum diﬀer by the eﬀective
number of processed data. This diﬀerence should be suppressed if the ﬂattened
pdf serves as the prior pdf. The ﬂattened version should be based on the
same number of (ﬁctitious) data as the prior pdf. This gives the following
recommendation.
Proposition 6.7 (Flattening of the Dirichlet pdf in branching) Let the
pre-prior pdf be Dirichlet Diα(¯κ), the prior one be Diα(κ0) and the posterior
one Diα(κ˚t). Then, the new prior Diα(ˆκ0), obtained by ﬂattening with
ˆκ0 = Λκ˚t + (1 −Λ)¯κ,
where Λ =
2
c∈c∗(κc;0 −¯κc)
2
c∈c∗(κc;˚t −¯κc) ,
(6.44)
guarantees equality

c∈c∗
ˆκc;0 =

c∈c∗
κc;0 ≡⌊κK0.
(6.45)
Proof. Omitted.
Remark(s) 6.5
1. Experiments indicate that ¯κ ≈0 and 2
c∈c∗κc;0 ≈0.1˚t are suitable op-
tions. Then, Λ ≈0.1.
2. A positive ﬂattening rate Λ is obtained iﬀ(see (6.45))
⌊κK0 > ⌊κ ¯K ≡

c∈c∗
¯κc.
(6.46)
For the discussed noniterative ﬂattening, it is suﬃcient and reasonable to
take the lowest value ¯κ = 0.
3. Meaningful Λ < 1 is obtained if
⌊κK˚t ≡2
c∈c∗κc;˚t >
⌊κK0. It is nat-
urally fulﬁlled when estimating without forgetting. This condition has to
be checked whenever exponential forgetting is employed. For the constant
forgetting factor with a ﬂat alternative pdf, this condition is equivalent to
the requirement, cf. (6.45), (6.46),
forgetting factor > 1 −
1
⌊κK0 −⌊κ ¯K .
(6.47)

126
6 Solution and principles of its approximation: learning part
Let us discuss now the choice of the ﬂattening rate related to parameters
Θic; cf. Agreement 6.1.
Mostly, we assume that all pdfs in /
i∈i∗
/
c∈c∗f(Θic) are conjugate
pdfs of the parameterized factors belonging to the exponential family; Sec-
tion 3.2. In this family, the eﬀective number of exploited, possibly ﬁctitious,
records is stored in counters νic for each in f(Θic). All considered approx-
imate estimations (see Section 6.5) add a fraction of the data mass to in-
dividual factors. Even without forgetting, we can guarantee at most that
2
ic νic;˚t = ˚
d˚t + 2
ic νic;0. Thus, even for single ﬂattening used in branch-
ing, we cannot ﬂatten factor-wise. We have to use a common ﬂattening rate
to all of them. Similarly as in the case of component weights, the common
ﬂattening rate is chosen so that 2
ic νic;˚t decreases to 2
ic νic;0. This implies
the following proposition.
Proposition 6.8 (Flattening of /
ic f(Θic|d(˚t)) in branching) Let us
consider factors in the exponential family and the product forms of
conjugate pre-prior pdf
 
i∈i∗,c∈c∗
A¯νic(Θic) exp
9 ¯Vic, C(Θ)
:
χΘ∗
ic(Θic)
conjugate prior pdf
 
i∈i∗,c∈c∗
Aνic;0(Θic) exp [⟨Vic;0, C(Θ)⟩] χΘ∗
ic(Θic)
posterior pdf
 
i∈i∗,c∈c∗
Aνic;˚
t(Θic) exp
9
Vic;˚t, C(Θ)
:
χΘ∗
ic(Θic).
(6.48)
Then, the prior pdf obtained by ﬂattening
 
i∈i∗,c∈c∗
Aˆνic;0(Θ) exp
	6
ˆVic;0, C(Θ)
7
χΘ∗
ic(Θic) with
ˆVic;0 = ΛVic;˚t + (1 −Λ) ¯Vic,
ˆνic;0 = Λνic;˚t + (1 −Λ)¯νic
(6.49)
∀i ∈i∗≡{1, . . . , ˚
d}, c ∈c∗, and Λ =
2
i∈i∗
2
c∈c∗(νic;0 −¯νic)
2
i∈i∗
2
c∈c∗(νic;˚t −¯νic)
guarantees that

i∈i∗

c∈c∗
ˆνic;0 =

i∈i∗

c∈c∗
νic;0 ≡⌊νK0.
(6.50)
Proof. Omitted.
Remark(s) 6.6
1. A positive ﬂattening rate Λ is obtained iﬀ
⌊νκ0 >

i∈i∗

c∈c∗
¯νic ≡⌊ν ¯K.
(6.51)
It is guaranteed when we select ¯νc = 0, c ∈c∗.

6.4 Construction of the prior estimate
127
2. Meaningful Λ < 1 is obtained if
⌊νK˚t ≡2
i∈i∗
2
c∈c∗νic;˚t >
⌊νK0. It
is naturally fulﬁlled when the estimation is performed without forgetting.
This condition has to be checked whenever the exponential forgetting is
employed. For the constant forgetting factor with a ﬂat alternative pdf,
this condition is equivalent to the requirement ( cf. (6.50), (6.51))
forgetting factor > 1 −
1
⌊νK0 −⌊ν ¯K .
(6.52)
3. Use of stabilized forgetting avoids the problem discussed in the previous
item. It can also be used for the Dirichlet part of the treated prior and
posterior pdfs. For the respective factors in the exponential family, it is
suﬃcient to select a positive degree νic;0 of the factor A(Θic) in the expo-
nential family cf. (3.6) serving as the alternative pdf. Then, the inspected
sums do not fall and no special actions are needed during ﬂattening.
Choice of ﬂattening rate in iterative learning
In order to give justiﬁed recommendations of the ﬂattening rates in iterations,
we inspect inﬂuence of ﬂattening rate Λ on results of the repetitive use of
AΛ. The analysis is made in the ideal case when the likelihood L(Θ, d(˚t)) ≡
f(d(˚t)|Θ) is evaluated exactly in each iteration.
Proposition 6.9 (Asymptotic of the repetitive use of AΛ) Let Λ(n) ∈
[0, 1−ε]n, ε ∈(0, 1), be a sequence of weights determining operators An ≡AΛn
(6.43) with a common likelihood L(Θ, d(˚t)) ≡f(d(˚t)|Θ). Let the common sup-
port of the prior pdf f(Θ) and the (ﬂat) pre-prior pdf ¯f(Θ) contain the support
of L(Θ, d(˚t)). Then, the pdfs fn ≡AnAn−1 · · · A1[f] have the following possi-
ble stationary value
f∞≡limn→∞fn ∝L
⌊ΛA ¯f
⌊ΛB,
where the exponents are
(6.53)
⌊ΛA ≡limn→∞
⌊ΛAn,
⌊ΛAn ≡
n

i=1
n
 
j=i
Λj ≡Λn

1 + ⌊ΛAn−1

⌊ΛA0 = 0
(6.54)
⌊ΛB ≡limn→∞
⌊ΛBn,
⌊ΛBn ≡
n

i=1
(1 −Λi)
n
 
j=i+1
Λj ≡(1 −Λn) + Λn
⌊ΛBn−1
⌊ΛB0 = 0.
(6.55)
The asymptotic pdf f∞equals to LΛ/(1−Λ) ¯f for a constant Λ. For Λ = 0.5,
the pdf f∞coincides with that resulting from the Bayes rule initiated by the
pre-prior pdf ¯f.
The weight Λ = 0.5 is the desirable asymptotic value of varying Λn. With
Λ = 0.5, we get ⌊ΛA = ⌊ΛB = 1, leading to f∞coinciding with the posterior
pdf for the prior pdf equal to ¯f.

128
6 Solution and principles of its approximation: learning part
Proof. The repetitive application of An gives fn = L
⌊ΛAnf
/n
˜n=1 Λ˜n ¯f
⌊ΛBn.
The nonnegative sequence
 ⌊ΛAn

n≥1 is given by the formula (6.54) and is
bounded from above by the sum of the geometric sequence with the ﬁrst term
and quotient equal to 1 −ε. Thus, the limn→∞⌊ΛAn exists and it is smaller
than 1/ε −1.
The power of the prior pdf f converges quickly to zero as all factors Λn ≤
1 −ε. The power ⌊ΛBn of the pre-prior pdf ¯f evolves according to (6.55) and
it is bounded by unity. Thus, its limn→∞is smaller than one. For a constant
Λ, ⌊ΛAn becomes the sum of a geometric sequence with value converging to
Λ/(1 −Λ) and ⌊ΛBn to unity.
Remark(s) 6.7
1. Uniform separation of Λn from unity by ε > 0 corresponds to a uniformly
positive penalty qn ≥q > 0 (6.41). This desirable constraint prevents
repetitive application of the plain Bayes rule and avoids the drawbacks
discussed in Section 6.4.1.
2. The chosen “informative” prior pdf does not inﬂuence the asymptotic so-
lution. Its preservation, however, may be of extreme importance at the
beginning of iterations as it may keep the approximately evaluated likeli-
hood close to the correct one.
A change of the pre-prior pdf used in the ﬂattening during iterative learn-
ing oﬀers a remedy of the problem mentioned in the above remark. The sim-
plest possibility is described by the following algorithm.
Algorithm 6.4 (Iterative learning with the preserved prior pdf)
Initial mode
•
Select the upper bound ˚n on the number n of iterations.
•
Set the iteration counter n = 1 and select the initial ﬂattening rate Λ1 ∈
(0, 1).
•
Select a ﬂat pre-prior pdf, typically, improper one ¯f ∝1.
•
Specify a proper prior pdf f0 = f.
•
Compute a new guess of the prior pdf f1 using the approximate estimation
and ﬂattening (cf. (6.43))
f1 ∝[L0f0]Λ0 ¯f 1−Λ1,
with L0 ≈L(Θ, d(˚t)).
•
Re-deﬁne the pre-prior pdf to f0.
Iterative mode
1. Stop if n ≥˚n.
2. Increase the iteration counter n = n + 1 and select the ﬂattening rate Λn.
3. Compute a new guess of the prior pdf fn using approximate estimation
and ﬂattening with f0 serving as the pre-prior pdf

6.4 Construction of the prior estimate
129
fn ∝[Ln−1fn−1]Λn f 1−Λn
0
.
4. Go to the beginning of Iterative mode.
Proposition 6.10 (Asymptotic of Algorithm 6.4) Let Λ(n) ∈[0, 1 −ε]n,
ε ∈(0, 1), be a sequence of weights determining operators An ≡AΛn (6.43)
with a common likelihood L(Θ, d(˚t)) ≡f(d(˚t)|Θ). Let the common support
of the prior pdf f0(Θ) ≡f(Θ) and the (ﬂat) pre-prior pdf ¯f(Θ) contain the
support of L(Θ, d(˚t)). Then, the pdfs fn generated by Algorithm 6.4 have the
following possible stationary value
f∞≡limn→∞fn ∝L
⌊ΛAf
⌊ΛB
0
,
where the exponents are
(6.56)
⌊ΛA ≡limn→∞
⌊ΛAn = limn→∞Λn(1 + ⌊ΛAn−1),
⌊ΛA1 = Λ1
⌊ΛB ≡limn→∞
⌊ΛBn = ⌊ΛBn ≡(1 −Λn) + Λn
⌊ΛBn−1,
⌊ΛB1 = Λ1.
The asymptotic pdf becomes f∞= LΛ/(1−Λ)f0, for a constant Λ = Λn, n > 1.
For Λ = 0.5, the pdf f∞coincides with that resulting from the Bayes rule
initiated by the prior pdf f0.
The value Λ = 0.5 is the desirable limit of varying Λn. For it, we get
⌊ΛA = ⌊ΛB = 1, leading to f∞coinciding with the posterior pdf determined
by the prior pdf f0.
Proof. Omitted, as it essentially copies the proof of Proposition 6.9.
In the realistic iterative mode when the likelihood is evaluated approxi-
mately, it is reasonable to use a varying ﬂattening rate Λn. We would like to
have
⌊ΛA˚n = 1 after the speciﬁed number of iterations ˚n > 1. For ˚n = 1,
the values of Λ are recommended in Propositions 6.7 and 6.8. We take them
respectively as initial conditions ⌊ΛA1 ≡Λ1 for the Dirichlet (6.4) and expo-
nential factors (6.48). If we specify, moreover, a function describing the desired
increase of ⌊ΛAn to ⌊ΛA˚n = 1 we get the rule as to how to compute respective
values of Λn. We do that for a simple linear function.
Proposition 6.11 (Flattening rate for linearly growing conﬁdence) Let
us repeat ﬂattening for ˚n > 1 steps and select
⌊ΛA1D ≡Λ1D =
2
c∈c∗(κc;0 −¯κc)
2
c∈c∗(κc;˚t −¯κc)
for the Dirichlet factor in (6.3)
⌊ΛA1 ≡Λ1 =
2
i∈i∗,c∈c∗(νic;0 −¯νic)
2
i∈i∗,c∈c∗(νic;˚t −¯νic)
for the factors (6.48) in (6.3).
Let us require ⌊ΛA˚n = 1 and ⌊ΛA˚nD = 1 after a linear growth. Then, for n > 1
⌊ΛAnD = ⌊ΛA(n−1)D + kD, kD ≡1 −⌊ΛA1D
˚n −1
,
ΛnD =
⌊ΛAnD
1 + ⌊ΛA(n−1)D
⌊ΛAn = ⌊ΛAn−1 + k, k ≡1 −⌊ΛA1
˚n −1
,
Λn =
⌊ΛAn
1 + ⌊ΛAn−1
.
(6.57)

130
6 Solution and principles of its approximation: learning part
Proof. The required linear growth and the ﬁxed initial condition implies
⌊ΛAn = ⌊ΛA1 + k(n −1). The requirement ⌊ΛA˚n = 1 gives k = 1−⌊ΛA1
˚n−1
and
(6.54) implies
Λn =
⌊ΛAn
1 + ⌊ΛAn−1
≡
⌊ΛA1 + k(n −1)
1 + ⌊ΛA1 + k(n −2).
Formulas are formally the same for the Dirichlet part that diﬀers in initial
conditions.
Asymptotic analysis of the ﬂattening is made for the common exactly eval-
uated likelihood L(Θ, d(˚t)). Flattening is, however, justiﬁed by a violation of
this assumption. Thus, it makes sense to model this violation and consequently
to modify variations of the ﬂattening rate. In this respect, we assume that in
the nth ﬂattening iteration
Ln(Θ, d(˚t)) =

L(Θ, d(˚t))
βn ,
(6.58)
where βn ∈(0, 1] is a known scalar. This model is motivated by experi-
ments with estimation employing forgetting; see Section 6.4.7. With forgetting
2
c∈c∗νc;˚t < 2
c∈c∗νc;0 + ˚
d˚t (cf. Remarks 6.6) and thus Ln(Θ, d(˚t)) cannot
be equal to the exact L(Θ, d(˚t)). The likelihood is simply more ﬂat than that
assumed up to now. The ratio
βn =
2
c∈c∗νnc;˚t
2
c∈c∗νnc;0 + 2˚t
t=1 λt , where λ is the used forgetting factor,(6.59)
indicates the degree of ﬂattening in the nth iterative step. Let us repeat the
asymptotic analysis of Algorithm 6.4 under the assumption (6.58).
Proposition 6.12 (Asymptotic of Algorithm 6.4 under (6.58))
Let Λ(n) ∈[0, 1 −ε]n, ε ∈(0, 1), be a sequence of weights determin-
ing operators An ≡AΛn (6.43) with the varying likelihood Ln(Θ, d(˚t)) =
[L(Θ, d(˚t))]βn ≡[f(d(˚t)|Θ)]βn. Let the common support of the prior pdf
f(Θ) = f0(Θ) and of the (ﬂat) pre-prior pdf ¯f(Θ) contain the support of
L(Θ, d(˚t)). Then, the pdfs fn generated by Algorithm 6.4 have the following
possible stationary value
f∞= limn→∞fn ∝L
⌊ΛAf
⌊ΛB
0
,
where
(6.60)
⌊ΛA = limn→∞
⌊ΛAn = limn→∞Λn(βn + ⌊ΛAn−1),
⌊ΛA1 = Λ1,
and
⌊ΛB = limn→∞
⌊ΛBn = ⌊ΛBn ≡(1 −Λn) + Λn
⌊ΛBn−1,
⌊ΛB1 = Λ1.
The desirable limit is A = B = 1 when f∞coincides with the posterior pdf
given by the prior pdf f0.
Proof. Let us assume that, for n > 1, fn−1 = L
⌊ΛAn−1f
⌊ΛBn−1
0
¯f
⌊ΛCn−1. The
estimation and ﬂattening steps, together with the last assumption and with
(6.58), imply

6.4 Construction of the prior estimate
131
fn = [Lnfn−1]Λnf 1−Λn
0
=
	
Lβn+ ⌊ΛAn−1f
⌊ΛBn−1
0
¯f
⌊ΛCn−1Λn
f 1−Λn
0
⇒
⌊ΛAn = Λn(βn + ⌊ΛAn−1),
⌊ΛBn −1 = Λn

⌊ΛBn−1 −1

,
⌊ΛCn = Λn
⌊ΛCn−1.
Thus, ⌊ΛBn →1 and ⌊ΛCn →0 whenever /˚n
n=1 Λn →0. For it, it is suﬃcient
to have Λn ∈[0, 1 −ε], 1 > ε > 0. Then, also the nonstationary diﬀerence
equation for ⌊ΛAn is stable and the requirement ⌊ΛAn →1 is the only serious
constraint on the sequence Λn.
The discussed modiﬁcation leads to the following modiﬁcation of Proposi-
tion 6.11.
Proposition 6.13 (Almost linearly growing conﬁdence in Ln (6.58))
Let us assume that βn, βnD are given and repeat ﬂattening for ˚n > 1 steps.
Let us select
⌊ΛA1D ≡β1DΛ1D, Λ1D =
2
c∈c∗(κc;0 −¯κc)
2
c∈c∗(κc;˚t −¯κc)
for ﬂattening of Dirichlet factor (6.4) in (6.3) and
⌊ΛA1 ≡β1Λ1, Λ1 =
2
i∈i∗,c∈c∗(νic;0 −¯νic)
2
i∈i∗,c∈c∗(νic;˚t −¯νic)
for the factors (6.48) in (6.3). Let us require ⌊ΛA˚n = 1 after a linear growth
under (6.58). Then, for n > 1,
⌊ΛAn = ⌊ΛAn−1 + kn, kn ≡min

βn, 1 −⌊ΛAn−1
˚n −n + 1

(6.61)
Λn =
⌊ΛAn
βn + ⌊ΛAn−1
⌊ΛAnD = ⌊ΛA(n−1)D + knD, knD ≡min
0
βnD, 1 −⌊ΛA(n−1)D
˚n −n + 1
1
ΛnD =
⌊ΛAnD
βn + ⌊ΛA(n−1)D
It may happen that either
⌊ΛA˚n < 1 or
⌊ΛA˚nD < 1. Then, ˚n must be in-
creased by 1. The necessary number of such extensions for reaching the value
max( ⌊ΛA˚n, ⌊ΛA˚nD) is always ﬁnite.
Proof. It is suﬃcient to inspect the exponential-family factor case as the
Dirichlet case is identical.
Let us consider a generic step n with
⌊ΛAn−1 and βn given. We would
like to have ⌊ΛA˚n = 1 after a linear growth. With ⌊ΛAn = ⌊ΛAn−1 + kn, we
require 1 = ⌊ΛAn−1 + 2˚n
˜n=n k˜n. Hoping for constant k˜n for ˜n ≥n, we get

132
6 Solution and principles of its approximation: learning part
kn = 1 −⌊ΛAn−1
˚n −n + 1
and
Λn = kn + ⌊ΛAn−1
βn + ⌊ΛAn−1
.
This is a legal step iﬀΛn ≤1 ⇔kn ≤βn. When this condition is met,
we apply the proposed Λn. We use Λn = 1 otherwise, which corresponds to
kn = βn. This will be slower than the intended linear growth but such a
Λn will increase βn+1 at most to 1. Thus, it can be expected that the linear
increase will be possible in the next iteration step.
It may well happen that, for the planned ˚n,
⌊ΛA˚n does not reach unity.
Then, it has to be increased. The need for this extension will end up in a
ﬁnite number of attempts as the increase of An in each step is positive and
the target value is ﬁnite.
The proposition speciﬁes a general ﬂattening algorithm applicable both in
iterative learning and in branching. It is presented for factors in the expo-
nential family f(di|ψic, Θic, ic) = A(Θic) exp [⟨B(Ψic), C(Θic)⟩] and estimates
f(Θic|d(˚t)) ∝Aνic;˚
t(Θic) exp
9
Vic;˚t, C(Θic)
:
corresponding to the conjugate
prior pdfs f(Θic) ∝Aνic;0(Θic) exp [⟨Vic;0, C(Θic)⟩] and the ﬂat conjugate al-
ternative ¯f(Θic) ∝A¯νic(Θic) exp
9 ¯Vic, C(Θic)
:
.
Dirichlet pdfs Diα(¯κ), Diα(κ0) are used as ﬂat pre-prior pdf and prior
pdf, respectively. The adopted approximate estimation preserves this form so
that the posterior pdf is also Diα(κ˚t).
Algorithm 6.5 (Universal ﬂattening with an almost linear rate)
Initial mode
•
Select upper bound ˚n on the number n of iterations and set n = 1.
•
Select the statistics ¯ν, ¯V , ¯κ determining the pre-prior pdf ¯f(Θ).
Iterative mode
1. Perform approximate mixture estimation; see Section 6.5.
2. Evaluate
T =
"˚t
if no forgetting is used
2˚t
t=1 λt ≈
1
1−λ
if forgetting with factor λ < 1 is used
βn =
2
i∈i∗,c∈c∗νic;˚t
˚
dT + 2
i∈i∗,c∈c∗νic;0
for the “factor” part of the posterior pdf
βnD =
2
c∈c∗κc;˚t
T + 2
c∈c∗κc;0
for the Dirichlet part of the posterior pdf.
3. Compute ﬂattening rates Λn, ΛnD and the powers of the likelihood ⌊ΛAn,
⌊ΛAnD for the factor as well as for Dirichlet parts.
For n = 1,
Λ1 ≡
2
i∈i∗,c∈c∗(νic;0 −¯νic)
2
i∈i∗,c∈c∗(νic;˚t −¯νic) and set ⌊ΛA1 ≡β1Λ1

6.4 Construction of the prior estimate
133
Λ1D ≡
2
c∈c∗(κc;0 −¯κc)
2
c∈c∗(κc;˚t −¯κc)
and set ⌊ΛA1D ≡β1DΛ1D.
For n > 1,
kn ≡min

βn, 1 −⌊ΛAn−1
˚n −n + 1

,
⌊ΛAn = ⌊ΛAn−1 + kn
Λn =
⌊ΛAn
βn + ⌊ΛAn−1
knD ≡min
0
βnD, 1 −⌊ΛA(n−1)D
˚n −n + 1
1
⌊ΛAnD = ⌊ΛA(n−1)D + knD
ΛnD =
⌊ΛAnD
βnD + ⌊ΛA(n−1)D
.
4. Apply ﬂattening as follows, i = 1, . . . , ˚
d, c ∈c∗.
For n = 1, Vic(n+1);0 = ΛnVicn;˚t + (1 −Λn) ¯Vic
νic(n+1);0 = Λnνicn;˚t + (1 −Λn)¯νic
κc(n+1);0 = ΛnDκcn;˚t + (1 −ΛnD)¯κc
For n > 1, Vic(n+1);0 = ΛnVicn;˚t + (1 −Λn)Vic;0
νic(n+1);0 = Λnνicn;˚t + (1 −Λn)νic;0
κc(n+1);0 = ΛnDκcn;˚t + (1 −ΛnD)κc;0.
5. Stop if ˚n = 1 and take the result as the newly generated prior pdf.
6. Increase n = n + 1.
7. Stop if n > ˚n > 1 and max
 ⌊ΛA˚n, ⌊ΛA˚nD

= 1 and take the result as the
newly generated prior pdf.
8. Go to the beginning of Iterative mode if n ≤˚n.
9. Increase ˚n = ˚n + 1 and go to the beginning of Iterative mode if n > ˚n and
max
 ⌊ΛA˚n, ⌊ΛA˚nD

< 1.
Remark(s) 6.8
1. It is possible to take the result of the ﬁrst estimation that started from a
ﬂat pre-prior pdf and was followed by ﬂattening as the prior pdf if there
is no justiﬁed alternative option.
2. The powers ⌊ΛA˚n, ⌊ΛA˚nD have to be simultaneously checked for reaching
unity. Generally, they reach unity after diﬀerent numbers of iterations.
We have selected conservative stopping leading to a ﬂatter ﬁnal pdf. It
corresponds to the experience that over-conﬁdence is more dangerous than
under-conﬁdence.
3. Use of this ﬂattening should allow us to use forgetting extensively as the
presented algorithm avoids the check on values of the forgetting factor
discussed in Remarks 6.6.

134
6 Solution and principles of its approximation: learning part
Problem 6.6 (Improvements of ﬂattening strategies) Experiments
indicate superiority of forgetting with linear growth. Seemingly more realistic
“almost linear growth” provides poorer results. It indicates that the under-
standing of the problem is still limited and there is a space for further im-
provements. Ideally, a sort of feedback during iterations could and should be
used.
6.4.4 Geometric mean as branching mapping
This subsection starts description of several branching mappings. They tailor
the general branch-and-bound technique (see, Section 6.1.3) to the initializa-
tion problem summarized in Agreement 6.6.
The inspected estimates of the prior pdf ˆf(Θ) and the adopted approx-
imate estimator, Section 6.5, determine the joint pdf of data and mixture
parameters X ≡ˆf(·, ·) ≡ˆf(d(˚t), Θ). This pdf is the argument of the maxi-
mized functional (6.38)
F(X) ≡⌊hL

ˆf(·, ·), d(˚t)

≡

ˆf(d(˚t), Θ) dΘ = ˆf(d(˚t)).
While searching for maximizing argument we always preserve the best ar-
gument found until the considered step; cf. Proposition 6.3. Thus, for a de-
scription of the branching mapping, it is necessary to describe only how novel
alternative guesses { ˆf(Θ)} of the best prior pdf are generated.
Here, we inspect the case when the set of candidates contains just a pair of
pdfs ˆf1(Θ), ˆf2(Θ) and a new singleton is generated. These guesses of the prior
pdf deﬁne the approximate posterior pdfs through an approximate estimation.
We want to ﬁnd the best point estimate of the posterior pdf. It is unknown
because of the lack of complete knowledge about the adequate prior pdf.
Formally, we are facing exactly the same situation as discussed in Section
6.3.3. Similarly to Agreement 6.4, we introduce the unknown probability β1
that the unknown prior pdf f(Θ) belongs to the set f ∗
1 containing pdfs that are
closer to the guess ˆf1(Θ) than to the guess ˆf2(Θ). Adopting the approximation
f(Θ) ≈ˆf1(Θ) on f ∗
1 and f(Θ) ≈ˆf2(Θ) on the complement of f ∗
1 , we get the
(approximate) minimizing argument ˆf(Θ|d(˚t)) of the expected KL divergence
E
	
D

f|| ˆf

. It is a hot candidate for the value of the branching operator.
This motivates the deﬁnition of the geometric branching mapping
A :

ˆf1(d(˚t)), ˆf2(d(˚t)), ˆf1(Θ|d(˚t)), ˆf2(Θ|d(˚t))

→ˆf(Θ|d(˚t)) ∝[ ˆf1

Θ|d(˚t)

]λ[ ˆf2

Θ|d(˚t)

]1−λ
λ ≡β1|d(˚t) =
ˆf1(d(˚t))
ˆf1(d(˚t)) + ˆf2(d(˚t))
.
(6.62)
The used values of v-likelihood ˆfi(d(˚t)) ≡
 ˆfi(d(˚t)|Θ) ˆfi(Θ) dΘ, i = 1, 2, are
obtained as by-products of the quasi-Bayes algorithm (see formula (6.7) in

6.4 Construction of the prior estimate
135
Section 6.1.1) or have to be approximated for a ﬁxed predictor as discussed
in Section 6.1.2.
Remark(s) 6.9
1. We may use the geometric branching (almost) universally in conjunction
with various initial guess of alternatives and various additional branching
mappings A. In this way, we get various versions of the general branch-
and-bound Algorithm 6.1.
2. It is straightforward to specify a geometric branching that combines more
than two variants into a single pdf. Simply,
ˆf(d(˚t), Θ) ∝
˚i 
i=1
[ ˆfi(d(˚t), Θ)]λi,
λi ∝

ˆfi(d(˚t), Θ) dΘ, i = 1, 2, . . . ,˚i.
It does not seem that it makes sense to deal with this extension in the
discussed context.
3. The structure of the estimated mixture does not change during iterations.
Thus, it has to be suﬃciently reﬂected even in the prior pdf f(Θ). Tech-
niques allowing changes of the structure are described in Section 6.4.8.
Problem 6.7 (Likelihood assigned to the geometric mean) It is not cer-
tain that the found geometric mean gives a better results. Generally, it must
be checked by repeating the estimation after ﬂattening. The change in the
corresponding v-likelihood can be predicted, however, without repeating the es-
timation. It is implied by the Bayes rule (2.8)
ˆfi(Θ|d(˚t)) =
L(Θ, d(˚t)) ˆfi(Θ)

L(Θ, d(˚t)) ˆfi(Θ) dΘ
= L(Θ, d(˚t))fi(Θ)
ˆfi(d(˚t))
, i = 1, 2,
⇒

(6.62)
ˆf3(Θ|d(˚t)) =
[ ˆf1(Θ|d(˚t))]λ[ ˆf2(Θ|d(˚t))]1−λ

[ ˆf1(Θ|d(˚t))]λ[ ˆf2(Θ|d(˚t))]1−λ dΘ
⇒

(2.8)
ˆf3(Θ|d(˚t)) =
L(Θ, d(˚t)) ˆf λ
1 (Θ) ˆf 1−λ
2
(Θ)
ˆf3(d(˚t))
 ˆf λ
1 (Θ) ˆf 1−λ
2
(Θ) dΘ
⇒
ˆf3(d(˚t)) = [ ˆf1(d(˚t))]λ[ ˆf2(d(˚t))]1−λ
 	
ˆf1(Θ|d(˚t))
λ 	
ˆf2(Θ|d(˚t))
1−λ
dΘ
 	
ˆf1(Θ)
λ 	
ˆf2(Θ)
1−λ
dΘ
.
The above formula is an approximate one as the approximately evaluated like-
lihood function depends on the chosen prior pdf. The derived relationship has
not been tested suﬃciently. Its analogy is, however, widely and successfully
exploited for merging components and factors; see Section 6.6.4. Thus, it
is worth trying it as it could substantially enhance the potential behind the
geometric-mean mapping.

136
6 Solution and principles of its approximation: learning part
6.4.5 Random branching of statistics
The deterministic optimization algorithms are prone to ﬁnd just a local op-
timum. It is known that the global optimization calls for a random search
[132]. Computational complexity prevents us to use the safe, completely ran-
dom search. Thus, we should use a combination of deterministic and random
searches. Here, we touch on possible random steps.
According to Agreement 6.1, all considered pdfs on unknown parameters
of the mixture have the form (6.3). In learning, we have to consider the cases
when the whole data history d(˚t) reduces to a ﬁnite-dimensional (almost)
suﬃcient statistics, say {Vic}. It means that estimates are searched in the
form ˆf(Θic|d(˚t)) = ˆf(Θic|Vic), i ∈{1, . . . , ˚
d}, c ∈c∗. The functional form of
the right-hand sides as well as the set V∗
ic of possible values of Vic are known.
Knowing this, we can generate random samples ˜Vic in V∗
ic. It gives a new
guess ˜f(Θic|d(˚t)) ≡ˆf(Θic|˜Vic). By ﬂattening (see Proposition 6.6), we get a
new guess of the prior pdf ˆfnew(Θic).
Remark(s) 6.10
1. The random generating should be applied to selected factors only. It de-
creases the computational load and, moreover, preserves those estimates
that are satisfactory. Typically, the candidate factors are those that pro-
vide predictors similar to predictors constructed from the prior pdf only.
2. The random sample ˜Vic may or may not be related to the given Vic. The
latter option allows us a less restricted search and increases our chance of
reaching the best possible result. Computationally it may be prohibitive.
3. Samples ˜Vic around Vic should be searched for, if worries of the previous
item apply. The Bayes rule implies that
f(Vic) = f(d(˚t)) = f(d(˚t)|Θicj)f(Θicj)
f(Θicj|d(˚t))
for any {Θicj}j∈j∗∈Θ∗. Thus, we know the functional form of f(Vic)
and we are able to evaluate this pdf for any values Vic. Thus, we can get a
clue this pdf looks like and use it potentially for generating highly probable
samples of the statistics.
6.4.6 Prior-posterior branching
The posterior pdf ﬂattened back to the space of potential prior pdfs provides
an alternative to the original prior pdf. Thus, AΛ (6.43) can be used as a
promising branching mapping. Flattening combined with geometric branching
(6.62) we call prior-posterior branching. It gives the following iterative learning
algorithm.

6.4 Construction of the prior estimate
137
Algorithm 6.6 (Prior-posterior branching)
Initial mode
•
Select an upper bound ˚n on the number n of iterations and set n = 1.
•
Select a suﬃciently rich structure of the mixture; see Agreement 5.4.
•
Select the pre-prior ¯f(Θ) = a ﬂat prior pdf used for ﬂattening.
•
Select the prior pdf ˆf1n(Θ) ≡f(Θ) (not necessarily equal to ¯f(Θ)).
•
Compute the approximate posterior pdf ˜f1n(Θ|d(˚t)) ∝f(d(˚t)|Θ) ˆf1n(Θ) us-
ing an approximate Bayesian estimation; see Section 6.5.
•
Evaluate the v-likelihood l1n resulting from the use of ˆf1n(Θ).
•
Apply the ﬂattening operation to ˜f1n(Θ|d(˚t)) according to Propositions 6.7
(on the Dirichlet marginal) and 6.8 (on pdfs describing factors). Denote
the resulting pdf ˆf2n(Θ).
•
Compute the approximate posterior pdf ˜f2n(Θ|d(˚t)) ∝f(d(˚t)|Θ) ˆf2n(Θ) us-
ing an approximate Bayesian estimation; see Section 6.5.
•
Evaluate the v-likelihood l2n resulting from the use of ˆf2n(Θ).
•
Set ¯ln = max(l1n, l2n).
Iterative mode
1. Apply geometric branching to the pair ˜f1n(Θ|d(˚t)), ˜f2n(Θ|d(˚t)) with the
v-likelihood l1n, l2n, respectively. For λ ≡
l1n
l1n+l2n , it gives
˜f3n(Θ|d(˚t)) ∝
	
˜f1n(Θ|d(˚t))
λ 	
˜f2n(Θ|d(˚t))
1−λ
.
2. Apply the ﬂattening operation on ˜f3n(Θ|d(˚t)) according to Propositions 6.7
(on the Dirichlet marginal) and 6.8 (on pdfs describing factors). Denote
the resulting pdf ˆf3n(Θ).
3. Compute the approximate posterior pdf ˜f3n(Θ|d(˚t)) resulting from the use
of ˆf3n(Θ) as the prior pdf. Evaluate the v-likelihood l3n related to the use
of ˆf3n(Θ) as the prior pdf.
4. Choose among ˜fin(Θ|d(˚t)), i ∈{1, 2, 3} the pair with the highest v-likeli-
hood lin. Call them ˜f1(n+1)(Θ|d(˚t)), ˜f2(n+1)(Θ|d(˚t)) with the v-likelihood
l1(n+1), l2(n+1).
5. Go to the beginning of Iterative mode with n = n + 1 if
¯ln+1 ≡max(l1(n+1), l2(n+1)) > ¯ln,
or if ¯ln+1, ¯ln are the same according to Proposition 6.2, and if n < ˚n.
6. Stop and select among ˆfin(Θ), i = 1, 2, the pdf leading to the higher value
of lin as the prior pdf constructed.
Remark(s) 6.11
1. No improvement can be expected when the values of λ stabilize around 0.5.
This observation may serve as an additional stopping rule.

138
6 Solution and principles of its approximation: learning part
2. The algorithm is applicable out of the considered context of the mixture
estimation.
3. The structure of the estimated mixture does not change during iterations.
Thus, it has to be suﬃciently reﬂected even in the prior pdf f(Θ). Tech-
niques allowing changes of the structure are described in Section 6.4.8.
Problem 6.8 (Controlled prior-posterior branching) Prediction of the
v-likelihood after making geometric mean (see Problem 6.7) can be used for
controlling the branching algorithm. The comparison of the predicted and eval-
uated v-likelihood values indicates how much the likelihood varies due to the
approximate estimation used.
6.4.7 Branching by forgetting
Each iteration of the Bayes rule described in the previous section is performed
over all data available d(˚t). It might be a waste of precious computational re-
sources. Moreover, it cannot be used in online mode. The technique described
here helps us to avoid these drawbacks. Essentially, the considered alterna-
tives are generated through parallel quasi-Bayes estimations, Algorithm 6.13,
diﬀering in forgetting factors used.
For a given ˆf(Θ|d(t)), two approximate estimations run in parallel, one
with the unit forgetting and the other one with a forgetting λ << 1. Their
predictive abilities are evaluated through their v-likelihood. Their geometric
mean coincides with one of the compared pdfs if the absolute diﬀerence of their
v-log-likelihood values is high enough. At this moment, the poorer variant
can be reset to the better alternative. This description is formalized in the
following algorithm.
Algorithm 6.7 (Online branching with forgetting)
Initial mode
•
Select a suﬃciently rich structure of the mixture.
•
Select a constant ρ ≈3-5 deﬁning the signiﬁcant diﬀerence of v-log-
likelihood values.
•
Set the record counter t = 0 and select the prior pdf ˆf(Θ|d(t)) ≡f(Θ).
•
Choose a ﬁxed, relatively small forgetting factor λ < 1.
•
Select a ﬁxed alternative pdf used in the stabilized forgetting; see Propo-
sition 3.1. The alternative is either ﬂat pre-prior pdf or the chosen prior
pdf.
Data processing mode
1. Set ˆf1(Θ|d(t)) = ˆfλ(Θ|d(t)) = ˆf(Θ|d(t)).
2. Initialize v-log-likelihood values assigned to considered alternatives l1;t =
0, lλ;t = 0 .
3. Collect new data dt+1.

6.4 Construction of the prior estimate
139
4. Update ˆf1(Θ|d(t)) to ˆf1(Θ|d(t+1)) using approximate estimation, Section
6.5, with the forgetting factor 1.
5. Recompute the v-log-likelihood l1;t to l1;t+1 by adding the logarithm of the
mixture-based prediction ln(f(d(t + 1)|d(t))) obtained for the “prior” pdf
ˆf1(Θ|d(t)).
6. Update ˆfλ(Θ|d(t)) to ˆfλ(Θ|d(t + 1)) using approximate estimation with
the forgetting factor λ and the chosen alternative pdf.
7. Recompute the v-log-likelihood lλ;t to lλ;t+1 by adding logarithm of the
mixture-based prediction ln(f(d(t + 1)|d(t))) obtained for the “prior” pdf
ˆfλ(Θ|d(t)).
8. Go to Step 3 with t = t + 1 if |l1;t+1 −lλ;t+1| < ρ.
9. Set ˆf(Θ|d(t + 1)) = ˆf1(Θ|d(t + 1)) if l1;t+1 > lλ;t, otherwise assign
ˆf(Θ|d(t + 1)) = ˆfλ(Θ|d(t + 1)).
10. Set t = t + 1 and go to the beginning of Data processing mode if t ≤˚t.
11. Take ˆf(Θ|d(˚t)) as the ﬁnal estimate of the posterior pdf.
Remark(s) 6.12
1. The decision on the appropriate model, based on the diﬀerence of the in-
volved v-likelihood, is more sensitive to the choice of ρ than expected. An
insuﬃcient reliability of the posterior pdfs seems to be the real reason for
this behavior. This hints at the appropriate remedy: decide on the model
quality after checking that the probability of the branch with no forgetting
stabilizes in the time course.
2. Speeding up of the learning is the main expectation connected with this
algorithm. The model with no forgetting is expected to be the winner in
long run. Thus, the estimation with forgetting can be switched oﬀwhen
the estimation without forgetting is better majority of the time. The rule
for switching oﬀthe estimation with forgetting might look like as follows.
Switch oﬀthe estimation with forgetting if the estimation without it is better
for a suﬃciently large portion of time.
3. There is a danger of a numerical breakdown when the update with forget-
ting wins for a longer time. This case indicates either a very poor start or
a signiﬁcantly wrong model structure. The use of a proper alternative in
forgetting removes this danger.
4. The estimation with no forgetting should always be included as we search
for a time invariant model of the o-system.
5. The technique can be directly combined with prior-posterior branching.
6. The choice of the ﬁxed forgetting factor λ is based on experience. At
present, the option λ ≈0.6 seems to be satisfactory.
7. The necessary condition needed for standard ﬂattening 2
i∈i∗,c∈c∗νic;˚t >
2
i∈i∗,c∈c∗νic;0 may be violated when forgetting λ < 1 wins too often and
noninformative alternative pdf is used. Use of the stabilized forgetting with
a simpliﬁed alternative which preserves the degrees of freedom is the rec-
ommended way to avoid the problem.

140
6 Solution and principles of its approximation: learning part
Problem 6.9 (Branching by forgetting at factor level) The algorithm is
presented at the mixture level: the whole mixture is a winner if its v-likelihood
is suﬃciently higher than its competitor. The strategy can be and should be
extended up to the factor level. This extension looks quite promising and worth
trying.
6.4.8 Branching by factor splitting
The design of the branching mapping (6.15) presented in this section is unique
as it suits the cases when there is no clue on mixture structure, i.e., structure
of factors, presence of common factors and the number of components.
The basic idea of the branching by factor splitting is simple. Let us assume
that the mixture structure, Agreement 5.4, and the estimate of the prior pdf
ˆfn(Θ) are selected in an nth iteration. The approximate estimation, Section
6.5, gives the posterior pdf ˜fn(Θ|d(˚t)) ∝f(d(˚t)|Θ) ˆfn(Θ).
During approximate estimation, Section 6.5, we can check whether a par-
ticular factor covers two modes of the pdf predicting dic;t. We split each factor
that covers two modes into a new pair that preserves some properties of the
original factor but has a chance to ﬁt the processed data better.
Structure of factors is estimated and possibly modiﬁed during splitting. We
get a new, substantially larger, number of components that are re-estimated
after ﬂattening. Then, similar components are merged or spurious ones can-
celled. Consequently a simpler mixture is obtained. The whole process is re-
peated while the v-likelihood increases.
For reference purposes, we list steps that have to be elaborated in detail.
Algorithm 6.8 (Key steps of branching by splitting)
1. Selection of the very initial mixture to be split.
2. Selection of factors for splitting.
3. Splitting of factors.
4. Estimation of the factor structure; see Section 6.6.1.
5. Construction of a new mixture.
6. Merging of components; see Section 6.6.4.
7. Cancelling of components; see Section 6.6.4.
The steps without reference are discussed in this section. The structure es-
timation has a wider use and its parts are discussed in the referred subsections
of Section 6.6.
Selection of the initial mixture: Step 1 in Algorithm 6.8
The very initial mixture, corresponding to the selection of the initial set of
the alternatives in branch-and-bound Algorithm 6.1, has to be selected ﬁrst.
It should

6.4 Construction of the prior estimate
141
•
give a chance to ﬁnd the objective model,
•
exclude part of the data space that contains (almost) no data.
The ﬁrst condition requires selection of suﬃciently rich structures of factors
involved. For reference purposes, we formulate it formally.
Requirement 6.2 (Over-parameterized factors) The regression vectors
ψic;t of parameterized factors
f(di;t|d(i+1)···˚
d;t, d(t −1), Θic, c) ≡f(di;t|ψic;t, Θic, c)
include regression vectors ⌊oψi;t of the objective pdf
⌊of(di;t|d(i+1)···˚
d;t, d(t −1)) ≡⌊of(di;t| ⌊oψi;t), cf. Section 2.3.1.
This requirement is relatively simply fulﬁlled due to the slow dynamics of
the inspected o-system; cf. Section 5.2. It must, however, be respected when
reducing the model structure; see Section 6.6.
To meet the second requirement on the very initial mixture, we used the
single-component mixture. It safely excludes the space out of the union of
support of the objective components. It cannot exclude emptiness of the inter-
component space. This often causes bad behavior during the search. Typically,
the attempts to improve the one-component mixture fail and the initialization
stops prematurely. Initial splitting performed without the check of the
v-
likelihood brings practical remedy of the problem. The depth ˚
m of this initial
splitting is usually restricted by the problem complexity so that its choice is
not diﬃcult. This uncontrolled splitting relies on our ability to merge similar
components; see Section 6.6.4.
Algorithm 6.9 (Selection of the very initial mixture)
Initial mode
•
Select quantities in dt to be modelled.
•
Select a structure of the richest regression vector.
•
Select an initial-splitting depth ˚
m > 1 and set the depth counter m = 0.
•
Select a (ﬂat) prior pdf f(Θ) on the single component mixture.
•
Select an initial value of the statistics κ0 describing the Dirichlet pdf (10.2).
It serves for ﬂattening according to Proposition 6.7.
Evaluation mode
1. Increase m = m + 1.
2. Perform (approximate) estimation of the mixture; see Section 6.5.
3. Split factors as described in subsequent sections.
4. Apply ﬂattening operation, Propositions 6.7, 6.8, so that a new initial
mixture estimate is obtained.
5. Go to the beginning of Evaluation mode if m < ˚
m. Otherwise take the
resulting mixture as the very initial one for further evaluations.

142
6 Solution and principles of its approximation: learning part
Remark(s) 6.13
Other choices, like random starts, are possible and should be considered in
speciﬁc cases. A random start, however, does not guarantee that we shall not
stay in a weakly populated part of the data space. Moreover, available genera-
tors of this type care mostly about initial positions only. They do not provide
a complete description of the prior pdf.
Hierarchical selection of split factors and their split: Steps 2 and 3
in Algorithm 6.8
The hierarchical splitting described here solves both referred steps. It relies
on our ability to estimate three factors instead of a single one.
During the approximate estimation, Section 6.5, the ith factor within the
cth component is assigned a weight wic;t ∈[0, 1] that expresses the expecta-
tion that the data item dic;t is generated by this factor. Then, the modiﬁed
parameterized factor
fw(dic;t|d(i+1)···˚
d;t, d(t −1)) ≡fw(dic;t|ψic;t, Θic) ∝[f(dic;t|ψic;t, Θic)]wic;t
is used in the “ordinary” Bayes rule for data updating of the posterior pdf
describing the estimate of factor parameters. Thus, for estimation purposes,
we can inspect this factor without taking into account others. It allows us to
simplify notation and temporarily drop the subscripts w, c.
We want to check whether the discussed factor explains data that should
be modelled by more factors while assuming that Requirement 6.2 is met. We
formulate hypothesis H0 that the objective pdf has two components
⌊of(dt|ψt) = βf(dt|ψt, Θ1) + (1 −β)f(dt|ψt, Θ2), β ∈(0, 1),
(6.63)
where Θ1, Θ2 have the same structure as the parameter Θ in the split factor.
The alternative hypothesis H1 assumes that
⌊of(dt|ψt) = f(dt|ψt, ⌊oΘ),
i.e., denies the need for splitting.
If we can aﬀord it, we estimate parameters of the mixture (6.63) together
with the factor in question in order to decide on the need to split. With
f(H0) = f(H1), modelling no prejudice, the Bayes rule gives
Probability(split is needed|d(˚t)) ≡f(H0|d(˚t)) =
f(d(˚t)|H0)
f(d(˚t)|H0) + f(d(˚t)|H1).
(6.64)
The v-likelihood values f(d(˚t)|H0), f(d(˚t)|H1) are obtained as a byproduct of
the approximate estimation applied to the simple mixture (6.63), Section 6.5.
The factor is split if the probability (6.64) is high enough. The estimated
factors of the mixture (6.63) are natural candidates for its replacement.
For reference purposes, let us write down the corresponding algorithm.

6.4 Construction of the prior estimate
143
Algorithm 6.10 (Hierarchical split of factors)
Initial mode
•
Construct the very initial estimate f(Θ) of the mixture, Algorithm 6.9.
•
Select signiﬁcance level ¯P ∈(0, 1), ¯P ≈1 controlling the need to split.
•
Assign to each factor ic, i = 1, . . . , ˚
d, c ∈c∗, a prior pdf f(βic, Θ1ic, Θ2ic)
on parameters of the mixture (6.63). Indices ic stress the “membership”
of this mixture to the factor ic.
•
Initialize v-likelihoods lic;0|H corresponding to respective hypotheses H ∈
{H0, H1} and factors i ∈i∗, c ∈c∗.
Sequential mode, running for t = 1, 2, . . .,
1. Acquire data dt and complement the data vectors Ψic;t = [dic;t, ψ′
ic;t]′, i =
1, . . . , ˚
d, c ∈c∗.
2. Perform a single step of an approximate estimation (see Section 6.5), i.e.,
update f(Θ|d(t −1)) →f(Θ|d(t)). The estimation generates weights wic;t
expressing the degree with which the data dt are assigned to the param-
eterized factor ic. Update at the same time the values of the v-likelihood
lic;t|H1.
3. Weight the current data by respective wic;t. In the exponential family (3.6),
it replaces unit power of A(Θic) by wic;t and B(Ψic;t) by wic;tB(Ψic;t) ≡
B(Ψwic;t). Update estimates of parameters of the models (6.63)
f(βic, Θ1ic, Θ2ic|d(t −1)) →f(βic, Θ1ic, Θ2ic|d(t)),
using Ψwic;t.
Update also values of the v-likelihood lic;t|H0 using the predictors
f(dwic;t|ψwic;t, d(t −1)), with Ψwic;t ≡[dwic;t, ψ′
wic;t]′ and
constructed from the estimated two-component mixture (6.63).
4. Go to the beginning of Sequential mode while t ≤˚t.
Selection mode running for i = 1, . . . , ˚
d, c ∈c∗
Split f(Θic|d(˚t)) →

f(Θ1ic|d(˚t)), f(Θ2ic|d(˚t))

if
lic;˚t|H0
lic;˚t|H0 + lic;˚t|H1
≥¯P.
Heuristic choice of split factors: an alternative for Step 2 in
Algorithm 6.8
The hierarchically-based splitting depends heavily on our ability to face the
computational demands caused by the need to estimate three factors instead
of each original factor. In this and subsequent paragraph, less demanding ways
are discussed.
Simpliﬁcation is reached by leaving out the full estimation of subfactors
hidden in the factor to be split. It is done by

144
6 Solution and principles of its approximation: learning part
•
a heuristic step, for instance, by inspecting only the most ﬂat factors or
factors in the most populated component,
•
a tailored hypothesis testing,
•
exploiting a reduced version of the hierarchical split; see Chapter 8.
Other variants were also considered. Generally, experience is rather mixed but
the last item seems to be the most preferable.
Optimization-based factor splitting: an alternative of Step 3 in
Algorithm 6.8
Simpliﬁed splitting of a selected factor is discussed here. The ﬁrst variant
takes new factors as ﬂattened or sharpened versions of the factor in question.
Proposition 6.14 (Flattened / sharpened factors)
Let pdfs f, ¯f have a
common support Θ∗. Let the pdf ˆf minimize the KL divergence D

ˆf||f

and
have the prespeciﬁed KL divergence
D

ˆf|| ¯f

= ωD

f|| ¯f

, ω ̸= 1. Then, it has the form ˆf ∝f λ ¯f 1−λ.
(6.65)
The scalar λ is chosen so that the constraint in (6.65) is met.
Proof. We minimize the convex functional and the minimizing argument of the
Lagrangian is searched for. It coincides, however, with the functional (6.41),
where q is now the Lagrangian multiplier. It gives a ﬂattened version if q >
0 ⇔λ < 1 and a sharpened version if q < 0 ⇔λ > 1.
The obtained factor has a limited use since it preserves the original-factor
mode. Moreover, the choice of the optional value ω is generally unsolved.
More promising is the version that enforces explicitly a shift of the original-
factor mode. The mode is characterized through the expected value of a func-
tion g(Θ) depending on the estimated parameter Θ.
Proposition 6.15 (Shifted factor)
Let pdfs ˆf, f have a common support
Θ∗and let g(Θ) be an array-valued function deﬁned on Θ∗. Let the pdf ˆf
minimize the KL divergence D

ˆf||f

and have the prescribed norm of the
shift in expectation of the function g(Θ)
ω =
;
g(Θ)( ˆf(Θ) −f(Θ)) dΘ,

g(Θ)( ˆf(Θ) −f(Θ)) dΘ
<
, ω > 0.
Then, it has the form ˆf(Θ) ∝f(Θ) exp[s ⟨µ, g(Θ)⟩], s ∈{−1, 1},
(6.66)
determined by the constant array µ. The array µ is compatible with the scalar
product ⟨·, ·⟩and the solution of the considered task is in the set of functions
(6.66) “indexed” by µ. The array µ has to fulﬁll the equality

6.4 Construction of the prior estimate
145
µ = ρ

g(Θ)
⎛
⎝
f(Θ) exp[−⟨µ, g(Θ)⟩]

f( ˜Θ) exp[−
6
µ, g( ˜Θ)
7
] d ˜Θ
−f(Θ)
⎞
⎠dΘ
(6.67)
with the scalar ρ determined by the identity ⟨µ, µ⟩= ρ2ω.
Proof. The Lagrangian of this optimization task is
J ≡D

ˆf||f

+ ν

ˆf(Θ) dΘ
+ρ
;
g(Θ)

ˆf(Θ) −f(Θ)

dΘ,

g(Θ)

ˆf(Θ) −f(Θ)

dΘ
<
.
It is determined by scalars ν, ρ that have to be chosen so that constraints,
normalization and the restriction on the shift norm, are met. Let us denote
µ ≡ρ

g(Θ)( ˆf(Θ) −f(Θ)) dΘ. Then, the Lagrangian can be written in the
form
J = constant
+

ˆf(Θ) ln
⎛
⎜
⎝
ˆf(Θ)
f(Θ) exp[−⟨µ,g(Θ)⟩]

f(Θ) exp[−⟨µ,g(Θ)⟩] dΘ
⎞
⎟
⎠dΘ −ln
#
f(Θ) exp[−⟨µ, g(Θ)⟩] dΘ
$
.
Basic properties of the KL divergence imply the claimed form of the minimizer.
The found form of the minimizer and deﬁnition of µ imply
µ = ρ

g(Θ)
⎛
⎝
f(Θ) exp[−⟨µ, g(Θ)⟩]

f( ˜Θ) exp[−
6
µ, g( ˜Θ)
7
] d ˜Θ
−f(Θ)
⎞
⎠dΘ.
The restriction on the norm of the shift determines the constraint on the
length of the vector µ.
The freedom in the choice of s is implied by the even nature of the con-
straint in (6.66).
Remark(s) 6.14
1. The proposed shifting may fail if the over-parameterized factor is split.
The shift tends to directions, where the split factor is less concentrated.
In the over-parameterized case, such a shift brings nothing positive. Thus,
it is necessary to perform structure estimation on the factor selected for
splitting and get rid of superﬂuous parameters.
2. Constraints in Propositions 6.14, 6.15 can be used simultaneously, giving
the candidate pdfs in the predictable form
ˆf(Θ) ∝f λ(Θ) ¯f 1−λ(Θ) exp [⟨µ, g(Θ)⟩]
(6.68)
parameterized by a scalar λ and an array µ. The optimum can be searched
for them only.

146
6 Solution and principles of its approximation: learning part
3. A proper choice of the function g(Θ) helps us to stay within a desirable
class of pdfs. Typically, we try to stay within the computationally advan-
tageous class of conjugate pdfs, (3.13).
4. A linear term in

g(Θ)( ˆf(Θ)−f(Θ)) dΘ can be included in the constraint
(6.66) without changing the form of the results. It adds a freedom that may
be used for obtaining a suitable form of ˆf.
5. The constraint ˆf ≥0 was not explicitly considered while optimizing. The
solution meets it automatically.
The initialization results based on Proposition 6.15 were found to be
too sensitive with respect to a speciﬁc choice of the optional parameters
⟨·, ·⟩, g(Θ), ω. For this reason, an alternative formulation was tried. The
following proposition reﬂects a step made in this direction. It gets rid of
the choice of the product ⟨·, ·⟩and supports intuitive reasons for selecting
g(Θ) = Θ.
Proposition 6.16 (Alternative shifted factor)
Let us consider pdfs ˆf, f
with a common support Θ∗and ﬁnite gradients on Θ∗. Moreover, let a function
g : Θ∗→Θ∗and scalars β, b ∈(0, 1) be chosen. We search for such a pdf ˆf
that
•
minimizes the KL divergence D

ˆf||f

,
•
has the prescribed shift in expectation of g(Θ)
f

g(Θ) ˆf(Θ) dΘ

= βf

g(Θ)f(Θ) dΘ

, β ∈(0, 1),
(6.69)
•
has the prescribed ratio of “peaks”
ˆf

g(Θ) ˆf(Θ) dΘ

= b−1f

g(Θ)f(Θ) dΘ

, b ∈(0, 1).
(6.70)
Then, it has the form
ˆf(Θ) ∝f(Θ) exp[µ′g(Θ)]
(6.71)
determined by a vector µ chosen so that the constraints (6.69), (6.70) are met.
Proof. The Lagrangian of this optimization task is
J ≡D( ˆf||f)+ν

ˆf(Θ) dΘ+ρf

g(Θ) ˆf(Θ) dΘ

+λ ˆf

g(Θ) ˆf(Θ) dΘ

.
It is determined by scalars ν, ρ and λ that have to be chosen so that constraints
— normalization, (6.69) and (6.70) — are met. Its variation δJ , which should
be equal to zero for the optimal ˆf, reads

6.4 Construction of the prior estimate
147
δJ =

ˆδ
	
ln( ˆf/f) + ν + 1 + g′(Θ)µ

dΘ, with µ = ρ∂f(Θ)
∂Θ
+ λ∂ˆf(Θ)
∂Θ
evaluated at the point

g(Θ) ˆf(Θ) dΘ.
This implies the claimed results.
Remark(s) 6.15
1. The requirement (6.69) has the following meaning. The positions of the
new factor ˆf(Θ), characterized by

g(Θ) ˆf(Θ) dΘ should be still suﬃ-
ciently probable when judged from the viewpoint of the split pdf f(Θ).
It should, however, diﬀer from the original position of f(Θ) characterized
by

g(Θ)f(Θ) dΘ. The selection β < 1 guarantees it.
2. As a rule, there are many pdfs ˆf that minimize the divergence D

ˆf||f

under the constraint (6.69). We can use this freedom for selecting a more
concentrated pdf than the split one so that the corresponding parameter un-
certainty projected into the data space is smaller. The requirement (6.70)
expresses this wish. The requirement ﬁxes ratio of “peaks” of the involved
pdfs. The pdf values at expectations determining respective positions are
taken as the compared peaks. The selection b < 1 guarantees that the new
pdf has a higher peak and thus is narrower than the split factor f.
3. Intuitively, for each pair (β, b) ∈(0, 1)×(0, 1) there are pdfs fulﬁlling both
conditions (6.69), (6.70). Nonemptiness of this set has to be, of course,
checked. Those pdfs ˆf that minimize the distance to the split pdf f while
meeting these conditions are taken as a result of splitting. Additional con-
ditions can be formulated if the formulated task has more solutions.
4. The speciﬁc choices β, b have to be studied in order to ﬁnd a compromise
between the contradictory requirements. We want to
•
make the shift as large as possible,
•
stay within the domain of attraction of the factor split,
•
make the resulting pdf reasonably narrow.
Intuition and experiments indicate that the choice g(Θ) = Θ is reasonable.
The results were, however, found sensitive to the optional parameters β, b.
This stimulated attempts to search for a more objective choice of constraints.
Proposition 2.15 provides a guide. According to it, the posterior pdf f(Θ|d(t))
concentrates on minimizing arguments of entropy rate (2.48). For motivating
thoughts, we assume that it converges to its expected value and that we deal
with the parameterized model from the exponential family, Section 3.2. Thus,
the posterior pdf f(Θ|d(t)), conjugated to this family, concentrates on
lim
˚t→∞supp

f(Θ|d(˚t))

= Arg min
¯
Θ∈Θ∗

−ln(A( ¯Θ)) −⌊oE
9
B([d, ψ′]′), C( ¯Θ)
:
≡Arg min
¯
Θ∈Θ∗H∞

⌊of|| ¯Θ

.
(6.72)

148
6 Solution and principles of its approximation: learning part
Here, ¯Θ is a nonrandom argument of the posterior pdf f(Θ = ¯Θ|d(t)) and
⌊oE[·] is the expectation assigned to the objective pdf ⌊of(d, ψ) ≡⌊of(Ψ).
The weighting used in connection with the approximate estimation, Sec-
tion 6.5, guarantees that we deal with data vectors Ψ = [d′, ψ′]′ in a relatively
narrow set. Thus, we can assume that the mixture character of the objective
pdf is reﬂected in the conditional pdf (6.63) only. It allows us to assume
⌊of(d, ψ) =
	
β ⌊of(d|ψ, Θ1) + (1 −β) ⌊of(d|ψ, Θ2)

⌊of(ψ),
(6.73)
where the pdf
⌊of(ψ) brings no information on β, Θ1, Θ2. In other words,
meeting of a sort of natural conditions of decision making (2.36) is expected.
Then, the identity (6.72) relates points in supp

f(Θ|d(˚t))

, to the param-
eters β, Θ1, Θ2 and speciﬁes a constraint on the split factors. This obser-
vation is elaborated in Chapter 8. Due to it, the split into a pair of pdfs
f(Θ1|d(˚t)), f(Θ2|d(˚t)) is made without a full estimation of the mixture (6.63).
It decreases signiﬁcantly the computational burden connected with the hier-
archical splitting.
Construction of a new mixture: Step 5 in Algorithm 6.8
Splitting of factors provides a potentially huge number of components made
of them. A prospective cth component is formed from new factors ic with
parameters described by pdfs ˆfji(Θic|d(˚t)), ji ∈{1, 2}. A deductive selection
of a reasonably small subset of such components seems to be impossible. For
this reason, a nondeductive rule has to be chosen. At present, we let each
component split at most into a pair of components by selecting respective
factors in a predeﬁned way. Random choice seems to be a better alternative
and tests conﬁrm it.
Remark(s) 6.16
The discussed construction of a new mixture belongs to a wide class of prob-
lems in which simple elements can be combined in a more complex object in
many ways. A systematic solution for a class of such integer-programming
tasks is proposed in [151]. This methodology was proposed in connection with
the so-called shadow cancelling problem; see Section 12.3.2. It is worth elabo-
rating for the problem of this paragraph, too.
6.4.9 Techniques applicable to static mixtures
The majority of available techniques are applicable to static mixtures that
have constant regression vectors. The following section demonstrates that
these techniques are approximately applicable to dynamic mixtures. Then,
promising techniques suitable for static mixtures are outlined.

6.4 Construction of the prior estimate
149
Static clustering of dynamic systems
Mixture estimation constructs models with multiple modes. It is perceived
as a branch of cluster analysis [149]. Cluster algorithms are often used for
an approximate dynamic clustering, e.g., [54, 152, 153, 154]. They simply
neglect mutual dependence of data vectors Ψ(˚t) and treat them as independent
records. Thus, it is reasonable to analyze properties of this approximation. We
rely on asymptotic analysis of the type presented in [82] and in Proposition
2.15. For presentation simplicity, we assume a restricted but important special
case of discrete-valued data and the state in the phase form, with an over-
estimated order ∂. Thus, our analysis is made under the following restrictions.
Requirement 6.3 (On static treatment of dynamic mixtures) We
assume that
•
data dt have discrete values,
•
data vectors Ψt are modelled by a static mixture
f(Ψt|Ψ(t −1), Θ) ≡f(Ψt|Θ);
(6.74)
•
the chosen prior pdf f(Θ) is positive on Θ∗,
•
data vectors are in the phase form Ψt = [d′
t, . . . , d′
t−∂, 1]′ ≡[d′
t, φ′
t−1]′ with
a ﬁnite order ∂,
•
the state of the objective pdf of data ⌊of(d(˚t)), cf. Chapter 2, is uniquely
determined by the model state φt−1, t ∈t∗,
⌊of(dt|d(t −1)) = ⌊of(dt|φt−1) ⇒⌊of(d(˚t)) =
 
t∈t∗
⌊of(dt|φt−1).
(6.75)
Proposition 6.17 (On independently clustered data vectors) Let Requi-
rement 6.3 be met. If a unique ⌊oΘ ∈Θ∗∩supp [ f(Θ)] exists such that
f(Ψt| ⌊oΘ) = ⌊of(Ψt), ∀Ψt ∈Ψ ∗
t ,
(6.76)
then the formal posterior pdf /
t∈t∗f(Ψt|Θ)f(Θ) concentrates on ⌊oΘ. Other-
wise, the posterior pdf /
t∈t∗f(Ψt|Θ)f(Θ) concentrates on minimizing argu-
ments of the (relative) entropy rate
Arg min
Θ∈Θ∗limt→∞
1
t
t

τ=1
ln
 ⌊of(Ψτ)
f(Ψτ|Θ)

.
The statement holds in spite of the neglected dependence of data vectors Ψ(˚t).
Proof. The formal approximate posterior pdf can be expressed as follows.
f(Θ|Ψ(t)) ∝f(Θ) exp
"
−t1
t
t

τ=1
ln
 ⌊of(dτ|φτ−1)
f(Ψτ|Θ)
%
.
(6.77)

150
6 Solution and principles of its approximation: learning part
Let ⌊oE denote the objective expectation corresponding to the objective pdf
⌊of(d(˚t). Then, for any ﬁxed Θ ∈Θ∗and it holds
⌊oE

t 
τ=1
f(Ψτ|Θ)
⌊of(dτ|φτ−1)

=
 
t 
τ=1
f(Ψτ|Θ)
⌊of(dτ|φτ−1)
⌊of(dτ|d(τ −1))

dd(t)
=

(6.75)
 
t 
τ=1
f(Ψτ|Θ)
⌊of(dτ|φτ−1)
⌊of(dτ|φτ−1)

dd(t)
=

canceling

t 
τ=1
f(Ψτ|Θ) dd(t)
=

chain rule

t 
τ=1
f(dτ|φτ−1, Θ)f(φτ−1|Θ) dd(t)
≤

discrete φt−1

t 
τ=1
f(dτ|φτ−1, Θ) dd(t)
=

normalisation
1.
(6.78)
In summary, for the discrete-valued φt−1, it holds that
0 < ⌊oE
 t 
τ
f(Ψτ|Θ)
⌊of(dτ|φτ−1)

≤1.
(6.79)
Similar manipulations with the conditional version of ⌊oE pdf reveals that
ζt ≡
t 
τ
f(Ψτ|Θ)
⌊of(dτ|φτ−1)
is nonnegative martingale with respect to d(t). Thus, [81], it converges almost
surely to a nonnegative quantity smaller than one. Consequently, the inversion
ζ−1
t
converges almost surely either to inﬁnity or to a ﬁnite value greater than
one. Consequently,
limt→∞
1
t
t

τ=1
ln
 ⌊of(dτ|φt−1)
f(Ψτ|Θ)

≥0
almost surely for t →∞. The form of (6.77), notice the factor −t, implies
that the formal posterior pdf concentrates on
Arg min
Θ∈Θ∗limt→∞
1
t
t

τ=1
ln
 ⌊of(dτ|φτ−1)
f(Ψτ|Θ)

= Arg min
Θ∈Θ∗limt→∞
1
t
t

τ=1
ln
 ⌊of(Ψτ)
f(Ψτ|Θ)

= Arg min
Θ∈Θ∗limt→∞Ht( ⌊of(·)||Θ).
The ﬁrst equality is implied by the chain rule ⌊of(Ψτ) = ⌊of(dτ|φτ−1) ⌊of(φτ−1)
and by the fact that the added term 1
t
2t
τ=1 ln( ⌊of(φτ−1)) does not inﬂuence
minimization. The last equality is just the deﬁnition of the entropy rate.

6.4 Construction of the prior estimate
151
If the unique ⌊oΘ ∈Θ∗exists such that ⌊of(Ψτ) = f

Ψτ| ⌊oΘ

, then it is
the unique minimizing argument.
Remark(s) 6.17
1. The result is not surprising: a dynamic model introduces a speciﬁc depen-
dence structure among data records {dt}. The use of data vectors Ψt in-
stead of dt oﬀers a similar but less structured freedom. Hence, the asymp-
totic coincidence is possible whenever Ψt, t ∈t∗, “overlap” the dependence
structure of the correct dynamic model.
2. The previous statement can be illustrated nicely on the special case of
normal components.
3. The performed analysis indicates that the clustering and estimation algo-
rithms designed for static mixtures are applicable in the dynamic case, at
least asymptotically.
4. The parameterized mixture can be interpreted as a superposition of two
random generators. First, a pointer ct ∈c∗is selected with probability αc.
Then, data are randomly generated from this component. In the considered
mixtures, the generated pointers {ct}t∈t∗are mutually independent. This
independence is illogical in the dynamic context. modelling of pointers by
Markov chains would be more adequate. With such an option, the estima-
tion becomes much harder. The pointers, however, can be approximately
treated as pairs ct, ct−1 with dependence on ct−1, ct−2 neglected. The dis-
cussed result makes this extension of the mixture model worth considering.
Problem 6.10 (Weakening of the conditions in Proposition 6.17) The
conditions of Proposition 6.17 can be almost surely made weaker. It would be
worthwhile to make inspection in this respect as there is a chance for a better
understanding of the result. Also, estimates of the convergence rate could be
and should be searched for.
Promising initializations of static mixtures
Here, potential directions in solution of the initialization problem restricted
to static mixtures are outlined without a detailed elaboration.
Splitting of data space
The idea of this technique is similar to that of branching by factor splitting. All
operations are, however, made in the data space. The technique is applicable
to static mixtures and can be extended to dynamic mixtures when data vectors
Ψ are treated as independent data records.

152
6 Solution and principles of its approximation: learning part
Gradual extension of low-dimensional mixtures
The approximate Bayesian mixture estimation for low-dimensional data records
is a computationally feasible task. Even the initial locations and widths can
be spaced equally within the region, where data and thus their static mean
values occur. Then, the approximate Bayesian estimation is expected to pro-
vide good results within a reasonable computational time. This speculation
has motivated the ﬁrst solution we have ever used. The solution is described
in terms of data records {dt}, but it is directly applicable to the data vectors
{Ψt}.
Algorithm 6.11 (Extension of low-variate static mixtures)
Initial mode
•
Select the upper bound ˚ci on the number ci of components on each scalar
axis i ∈{1, . . . , ˚
d}.
•
Specify prior pdfs f(Θi) related to single-dimensional mixtures assigned to
each entry of di.
•
Estimate the individual mixtures f(Θi|di(˚t)), i = 1, . . . , ˚
d, by some approx-
imate technique; see Section 6.5.
•
Select the most signiﬁcant components (coinciding with factors); see Sec-
tion 6.6.
•
Apply branching versions of the ﬂattening operation; Propositions 6.7, 6.8.
This gives good single-variate prior pdfs f(Θi), i = 1, . . . , ˚
d.
•
Set the dimension of the data space to be extended ˚
d = 1.
•
Denote f(Θ1···˚
d) = f(Θ1).
Extension mode
1. Set ˚
d = ˚
d + 1.
2. Assume the mixture deﬁned on data d1···˚
d in the product form
f

d1···˚
d
!!! Θ1···˚
d

≡f

d1···(˚
d−1)
!!! Θ1···(˚
d−1)

f

d˚
d
!!! Θ˚
d

.
3. Deﬁne the prior pdf on its parameters as f

Θ1···˚
d

= f

Θ1···(˚
d−1))f(Θ˚
d

.
4. Perform an approximate parameter estimation using data d1···˚
d(˚t) to get
f

Θ1···˚
d
!!! d1···˚
d(˚t)

.
5. Select the most signiﬁcant components; see Section 6.6.
6. Apply branching versions of the ﬂattening operation, Propositions 6.7, 6.8.
This gives a good higher-variate prior pdf f

Θ1···˚
d

.
7. Go to the beginning of Extension mode if ˚
d < ˚
d. Otherwise stop and take
the resulting prior pdf as the prior on the whole parameter space.

6.4 Construction of the prior estimate
153
Remark(s) 6.18
The experimental results obtained are reasonable. They exhibit a dependence
on the order in which the extension is performed. This may be compensated
by starting the procedure from the technologically most important quantities
or by a random permutation of the ordering used.
A direct extension of single variate components
The following variant of the extension provides another possibility to solve
the initialization problem.
Again, we perform estimation of single variate mixtures for all entries di
(or Ψi). Each entry di (Ψi) is individually described by a mixture
f(di|Θi) =

ci∈c∗
i
αcif(di|Θici, ci), i = 1, . . . , ˚
d.
(6.80)
Its components are identical with factors. This provides a set of factors for
building multivariate components. We take the single-variate components as
independent factors forming multivariate components. We have insuﬃcient
reasons for other choice at this stage of the construction; see also Proposition
12.4. The potential multivariate components have structures determined by
the one-to-one composition rule π
π : c∗→[c∗
1, . . . , c∗
˚
d] ⇔
(6.81)
π : the multivariate component c is the product of factors that coincide
with components π(c)1 ∈c∗
1, . . . , π(c)˚
d ∈c∗
˚
d in (6.80).
The number of such mappings π is very large. Thus, we cannot inspect them
fully and suitable candidates have to be guessed from the available single-
variate results. The selection of promising composition rules is called the
shadow cancelling problem. Essentially, we want to avoid the combinations
that contain little data and appear due to the nonuniqueness of reconstruct-
ing multivariate objects from their low-dimensional “shadows”. A solution is
proposed in Chapter 12.
Clustering of pointers
The troubles with the discussed shadow cancelling problem led to the idea
of recording weights of individual single-variate components generated in an
approximate estimation, Section 6.5, and clustering these pointers. This clus-
tering is of a similar complexity as the original one. We expect, however, a
better separation of the “weight” clusters. Moreover, a coupling with MT algo-
rithm [67], Chapter 12, suits it ideally as the static clustering is adequate and
the box width determining it can simply be chosen: the probabilistic weights
are known to be in the interval [0, 1].

154
6 Solution and principles of its approximation: learning part
Combination of solutions
Feasible solutions are mostly nondeductive and thus susceptible to failures or
to stopping at local optimum. Thus, a combination of techniques is the must.
Generally,
•
a random element in the adopted search increases the chance of reaching
the global optimum,
•
the quality of the results can hardly be a monotonous function of the
problem parameters; thus, both extensions of low-dimensional solutions as
well as reductions of high-dimensional ones have to be used,
•
the v-likelihood, Section 6.1.2, seems to be the only viable universal tool
for comparing quality of the alternative results.
Problem 6.11 (Extension of the model set) The exponential family con-
tains a wider set of pdfs than the dynamic exponential family. Thus, the static
treatment of dynamic components opens the possibility to extend the set of
feasible models. This possibility should be widely exploited.
Problem 6.12 (Elaborate the above ideas and bring in new ones) This
section outlines an incomplete but wide range of possible directions to be fol-
lowed. They should be complemented and elaborated. Even conclusions that
some of the sketched ideas are crazy would be invaluable.
6.5 Approximate parameter estimation
The estimation described by Proposition 2.14 is quite formal for the mixture
model (6.1) since the resulting posterior pdf consists of a product of sums of
functions of unknown parameters. The number of terms that should be stored
and handled blows up exponentially. An approximation is therefore required.
The existing algorithms do not support estimation of dynamic mixtures.
This has motivated our search for an adequate algorithm. A slight extension
of a known algorithm [49], labelled the quasi-Bayes estimation (QB), was
proposed in [155] and its properties illustrated on simulation examples. It is
discussed in Section 6.5.1.
The insight gained into the approximate learning has allowed us to extend
the classical expectation-maximization algorithm (EM) to the dynamic mix-
tures; see Section 6.5.2. It serves us as an auxiliary initialization tool and as
a golden standard suitable for comparisons. Note that Markov Chain Monte
Carlo (MCMC) techniques are also worth inspecting but the known applica-
tions [50] still deal with much lower dimensions than needed for advising.
The quasi-Bayes estimation has good properties, Bayesian motivation and
interpretation as well as predictable and tractable computational complexity.
It is of a recursive nature so that it may serve in the adaptive advisory system.
These reasons justify our preference for it. At the same time, its construction

6.5 Approximate parameter estimation
155
implies that its results depend on the order of the data processing. This draw-
back was found signiﬁcant in some applications dealing with static mixtures.
This made us design a hybrid of the quasi-Bayes and EM algorithms. This
algorithm, called batch quasi-Bayes estimation (BQB), is described in Section
6.5.3. It preserves the essence of the Bayesian paradigm needed in other tasks
such as in structure estimation; see Section 6.6. At the same time, its results
are independent of the processing order.
The quasi-EM algorithm is another hybrid proposed. It can be viewed as
a rather simple quasi-Bayes point estimation.
6.5.1 Quasi-Bayes estimation
For the design and description of the quasi-Bayes estimation, we introduce dis-
crete random pointers c(˚t) = (c1, . . . , c˚t), ct ∈c∗, to particular components.
They are assumed to be mutually independent with time-invariant probabili-
ties f(ct = c|d(t −1), Θ) = αc. With these pointers, the parameterized model
(6.1) can be interpreted as the marginal pdf f(dt|d(t −1), Θ) of the joint pdf
(cf. Agreement 5.1)
f(dt, ct|d(t −1), Θ) =
 
c∈c∗
[αcf(dt|φc;t−1, Θc, c)]δc,ct
(6.82)
=

(6.2)
 
c∈c∗

αc
 
i∈i∗
f(dic;t|ψic;t, Θic, c)
δc,ct
,
where δ is the Kronecker symbol deﬁned by the formula
δc,˜c ≡

1 if c = ˜c
0 otherwise .
Indeed, the marginal pdf f(dt|d(t−1), Θ) of the pdf f(dt, ct|d(t−1), Θ), which
is found by summing (6.82) over ct ∈c∗, has the form (6.1), (6.2).
Let the approximate pdf f(Θ|d(t −1)) be of the product form, cf. Agree-
ment 6.1,
f(Θ|d(t −1)) = Diα(κt−1)
 
c∈c∗
 
i∈i∗
f(Θic|d(t −1)) ∝
∝
 
c∈c∗
ακc;t−1−1
c
 
i∈i∗
f(Θic|d(t −1)).
(6.83)
The pdfs f(Θic|d(t −1)) describe parameters of factors and Diα(κt−1) is the
pdf describing component weights. It is determined by the vector κt−1 with
positive entries κc;t−1 > 0. They are known values of functions of d(t −1).
The proportionality in (6.83) is implied by the deﬁnition of the Dirichlet pdf
Diα(κ) ≡
/
c∈c∗ακc−1
c
B(κ)
, B(κ) ≡
/
c∈c∗Γ(κc)
Γ
2
c∈c∗κc
.

156
6 Solution and principles of its approximation: learning part
Its properties are discussed in detail in Chapter 10.
The assumption (6.83), the formula (6.82) and the Bayes rule (2.8) give
f(Θ, ct|d(t)) ∝
 
c∈c∗
α
κc;t−1+δc,ct−1
c
 
i∈i∗
[f(dic;t|ψic;t, Θic, c)]δc,ct f(Θic|d(t −1)).
(6.84)
In order to obtain an approximation of the desired pdf f(Θ|d(t)), we have
to eliminate ct from (6.84). The correct marginalization with respect to ct
destroys the feasible product form (6.83). It is preserved if δc,ct is replaced by
its point estimate. We approximate δc,ct by its conditional expectation
δc,ct ≈E[δc,ct|d(t)] = f(ct = c|d(t)).
(6.85)
By integrating (6.84) over the parameters Θ, cf. Proposition 10.1, we get this
probability in the form
wc;t ≡f(ct = c|d(t)) =
ˆαc;t−1
/
i∈i∗f(dic;t|ψic;t, d(t −1), c)
2
˜c∈c∗ˆα˜c;t−1
/
i∈i∗f(di˜c;t|ψi˜c;t, d(t −1), ˜c)
=
κc;t−1
/
i∈i∗f(dic;t|ψic;t, d(t −1), c)
2
˜c∈c∗κ˜c;t−1
/
i∈i∗f(di˜c;t|ψi˜c;t, d(t −1), ˜c).
(6.86)
Here,
f(dic;t|ψic;t, d(t −1), c) ≡

f(dic;t|ψic;t, Θic)f(Θic|d(t −1)) dΘic
ˆαc;t−1 =
κc;t−1
2
˜c∈c∗κ˜c;t−1
(6.87)
are the Bayesian prediction (2.38) for a single factor identiﬁed by indexes
ic. The values ˆαc;t−1 are the conditional expectations of αc; cf. (6.5) and
Chapter 10. The formula (6.86) can be interpreted as the Bayes rule applied
to the discrete unknown random variable ct ∈c∗with the prior probability
ˆαc;t−1 ∝κc;t−1.
By inserting the approximation (6.85), (6.86) into (6.84), the approxi-
mately updated posterior pdf has the same product form as in (6.83) with
κc;t = κc;t−1 + wc;t
(6.88)
f(Θic|d(t)) ∝[f(dic;t|ψic;t, Θic, c)]wc;t f(Θic|d(t −1)).
(6.89)
This step completes the design of the estimation algorithm.
Algorithm 6.12 (Quasi-Bayes estimation without common factors)
Initial (oﬄine) mode
•
Select the complete structure of the mixture.
•
Select the prior pdfs f(Θic) of the individual factors, ideally, in the conju-
gate form with respect to the parameterized factors f(dic;t|ψic;t, Θic, c).
•
Select initial values κc;0 > 0 of statistics describing prior pdf α. Intuitively
motivated values about 0.1˚t/˚c were found reasonable.

6.5 Approximate parameter estimation
157
•
Compute the initial estimates of the component weights ˆαc;0 =
κc;0
2
˜c∈c∗κ˜c;0 .
Sequential (online) mode, running for t = 1, 2, . . .,
1. Acquire the data record dt.
2. Compute the values of the predictive pdfs
f(dic;t|ψic;t, d(t −1), c) =

f(dic;t|ψic;t, Θic)f(Θic|d(t −1)) dΘic
=
I(d(t)|ic)
I(d(t −1)|ic),
see (2.47), for each individual factor, i ∈i∗= {1, . . . , ˚
d}, in all compo-
nents, c ∈c∗, and the measured data record dt. The adaptive, one-stage-
ahead predictor (see Section 6.1.2) is thus used.
3. Compute values of the predictive pdfs
f(dt|d(t −1), c) =
 
i∈i∗
f(dic;t|ψic;t, d(t −1), c)
for the measured data dt and each individual component c ∈c∗.
4. Compute the probabilistic weights wc;t using the formula (6.86).
5. Update the scalars κc;t = κc;t−1 + wc;t according to (6.88).
6. Update the Bayesian parameter estimates f(Θic|d(t −1)) of individual
factors according to the weighted Bayes rule(6.89)
f(Θic|d(t)) ∝[f(dic;t|ψic;t, Θic, c)]wc;t f(Θic|d(t −1)).
7. Evaluate the point estimates of the mixing weights
E[αc|d(t)] =
κc;t
2
˜c∈c∗κ˜c;t
≡ˆαc;t
and, if need be, characteristics of f(Θic|d(t)) describing parameters Θic.
8. Go to the beginning of Sequential mode while data are available.
Remark(s) 6.19
1. The algorithm is applicable whenever the Bayesian estimation and pre-
diction for each factor can be simply calculated. This singles out param-
eterized models admitting ﬁnite-dimensional statistics as the candidates
among which factors should be chosen. This class consists essentially of the
exponential family augmented by the uniform distribution with unknown
boundaries, Section 3.2. They have conjugate (self-reproducing) prior pdfs
for which only ﬁnite-dimensional statistics need to be stored and updated.
Normal regression models, Chapter 8, or Markov chains, Chapter 10, are
prominent examples of such dynamic factors. Other cases are more or less
restricted to static factors.

158
6 Solution and principles of its approximation: learning part
2. It is worth noticing that the predictions of individual factors without data
weighting is performed for evaluation of the weights wc;t+1. The param-
eter estimation algorithm performs almost the same algebraic operations
but with weighted data. This simple observation is exploited in implemen-
tation of the algorithm. Moreover, it is widely used in judging of estimation
quality; see Section 6.1.2.
Problem 6.13 (Alternative approximation of unknown δc,ct)
The proposed solution can be improved by searching for a speciﬁc product-
form-preserving approximation ˆf(Θ|d(t + 1)) (containing no ct+1), which is
the nearest one to (6.84) in terms of the KL divergence [37]. This task is fea-
sible. This type of solution is elaborated in [131] and indeed provides a better
solution. The quasi-Bayes estimation is there also shown to be reasonable ap-
proximation of this solution. The problem of accumulating of approximation
errors, cf. Section 3.4, remains to be open.
The described quasi-Bayes algorithm 6.12 does not take into account the
possibility that some factors are common to various components. The exten-
sion to this useful case is, however, straightforward.
Algorithm 6.13 (Quasi-Bayes estimation with common factors)
Initial (oﬄine) mode
•
Select the complete structure of the mixture.
•
Select prior pdfs f(Θic) of individual factors, ideally, in the conjugate form
(3.13) with respect to the parameterized factors f(dic;t+1|ψic;t+1, Θic, c).
•
Select initial values κc;0 > 0, say, about 0.1˚t/˚c, describing prior pdf of the
component weights α.
•
Compute the initial point estimates of the component weights ˆαc;0 =
κc;0
2
˜cc∗κ˜c;0 .
Sequential (online) mode, running for t = 1, 2, . . .,
1. Acquire the data record dt.
2. Compute values of the predictive pdfs
f(dic;t|ψic;t, d(t −1), c) =

f(dic;t|ψic;t, Θic)f(Θic|d(t −1)) dΘic
=
I(d(t)|ic)
I(d(t −1)|ic),
see (2.47), for diﬀerent factors, i ∈i∗= {1, . . . , ˚
d}, in all components,
c ∈c∗, and the measured data record dt.
The adaptive, one-stage-ahead predictor (see Section 6.1.2) is used.
3. Compute the values of predictive pdfs
f(dt|d(t −1), c) =
 
i∈i∗
f(dic;t|ψic;t, d(t −1), c)
for the measured data dt and each individual component c ∈c∗.

6.5 Approximate parameter estimation
159
4. Compute the probabilistic weights wc;t using the formula (6.86).
5. Update the scalars κc;t = κc;t−1 + wc;t according to (6.88).
6. Update the Bayesian parameter estimates of diﬀerent factors
f(Θic|d(t)) ∝[f(dic;t|ψic;t, Θic, c)]wic;t f(Θic|d(t −1)),
where
(6.90)
wic;t =

˜c∈c∗
i
w˜c;t.
The set c∗
i includes pointers c to components that contain ith factor.
Handling of diﬀerent factors only and this step distinguish the presented
algorithm from Algorithm 6.12.
7. Evaluate, the point estimate of the mixing weights
E[αc|d(t)] =
κc;t
2
˜c∈c∗κ˜c;t
≡ˆαc;t
and, if need be, characteristics of f(Θic|d(t)) describing parameters Θic.
8. Go to the beginning of Sequential mode while data are available.
6.5.2 EM estimation
The expectation-maximization (EM) algorithm is a classical and successful
way of the mixture estimation [49]. The EM algorithm provides a local max-
imum of the posterior pdf (2.44) over Θ∗.
Its convergence is known to be monotonic but slow. The generic multi-
modality of the posterior pdf calls for a repetitive search using various initial
conditions. AutoClass [42] is a typical and successful implementation of the
EM algorithm. It combats the multimodality by using random initial condi-
tions. It oﬀers a high chance of ﬁnding the global maximum but it is compu-
tationally expensive. Essence of the EM algorithm is described here.
We are given the joint pdf of the observed data d(˚t) and nonmeasured
pointers c(˚t) to individual components conditioned on unknown parameters
Θ ∈Θ∗. For ﬁxed measured data d(˚t) and chosen structure of parameterized
models, they specify the logarithmic likelihood function
L(Θ, d(˚t), c(˚t)) ≡ln(f(d(˚t), c(˚t)|Θ)) =

t∈t∗

c∈c∗
δc,ct ln (αcf(dt|φt−1, c, Θ)) .
(6.91)
Similarly as in the quasi-Bayes estimation, a reasonable approximation of
δc,ct is searched for. Unlike for the quasi-Bayes estimation, a point estimate
ˆΘ of Θ is searched for and batch processing is supported.
Algorithm 6.14 (EM algorithm for mixture estimation)
Initial mode
•
Select the complete structure of the mixture.
•
Select the upper bound ˚n on the number n of iterations and set n = 0.
•
Select the initial point estimate ˆΘn of Θ.

160
6 Solution and principles of its approximation: learning part
Iterative mode
1. Approximate in batch all δc,ct, t ∈t∗. Use all measured data d(˚t) when
taking
δc,ct ≈E
	
δc,ct|d(˚t), ˆΘn

≡f

ct = c|d(˚t), ˆΘn

, t ∈t∗.
(6.92)
This is called the E(xpectation) step.
2. Insert the approximations (6.92) into the log-likelihood function (6.91).
3. Find the new point estimate ˆΘn+1 of Θ as the maximizing argument of this
approximate likelihood function. This is called the M(aximization) step.
4. Evaluate the value of the approximate log-likelihood attained by the maxi-
mizing argument.
5. Stop if the value of the approximate log-likelihood has not increased or
n ≥˚n. Otherwise, set n = n + 1 and go to the beginning of Iterative mode.
To make the EM algorithm applicable we need to evaluate the estimate of the
Kronecker symbol.
Proposition 6.18 (Batch estimate of pointers to components) Let
f(dt, ct|d(t −1), c(t −1), Θ) ≡f(dt|φct;t−1, ct, Θct)αct, t ∈t∗,
and ˆΘ ≡(ˆα1, . . . , ˆα˚c, ˆΘ1, . . . , ˆΘ˚c) ∈Θ∗be a ﬁxed instance of
Θ ≡(α1, . . . , α˚c, Θ1, . . . , Θ˚c).
Then, the probability of the random pointer ct ∈c∗, conditioned on all data
d(˚t) and ˆΘ, is given by the formula
wct;t ≡f(ct|d(˚t), ˆΘ) =
ˆαctf(dt|φct;t−1, ct, ˆΘ)
2
c∈c∗ˆαcf(dt|φc;t−1, c, ˆΘ)
∝ˆαctf(dt|φct;t−1, ct, ˆΘ).
(6.93)
Proof. The the chain rule and assumed dependencies imply
f(d(˚t), c(˚t)| ˆΘ) =
 
t∈t∗
f(dt|φct;t−1, ct, ˆΘc)ˆαct.
The pdf f(d(˚t), ct| ˆΘ) is obtained by marginalization
f(d(˚t), ct| ˆΘ) =

{cτ ∈c∗}τ∈t∗\t
f(d(˚t), c(˚t)| ˆΘ)
= f

dt|φct;t−1, ct, ˆΘct

ˆαct × term independent of ct.
The desired conditional pdf is proportional to the above pdf with the propor-
tion factor implied by normalization. In it, the complex term independent of
ct cancels and we get the claimed form.

6.5 Approximate parameter estimation
161
Remark(s) 6.20
1. The guaranteed monotonic increase of the likelihood [49] to a local maxi-
mum is the key advantage of EM algorithm and justiﬁes the stopping rule
used.
2. As a rule, EM algorithm is described and used for static components. Here,
the needed dynamic version is described.
3. The adopted interpretation of the EM algorithm diﬀers from a standard
interpretation. It is close to the description of the quasi-Bayes algorithm.
It helped us to create a novel batch quasi-Bayes algorithm 6.16.
EM algorithm 6.14 is described at the component level. Its applicability is
extended when it is used at factor level, possibly with common factors.
Algorithm 6.15 (EM mixture estimation with common factors)
Initial mode
•
Select the complete structure of the mixture.
•
Select the upper bound ˚n on the number n of iterations and set n = 0.
•
Select initial point estimates ˆΘicn of parameters Θic characterizing ith
factor within cth component.
•
Select point estimates ˆαcn of the components weights αc, typically, as the
uniform pf.
Iterative mode
1. Set the ˚c-vector of auxiliary statistics κn;0 = 0 and use the current point
estimates ˆΘn in the following evaluations.
2. Set the approximate log-likelihood functions Ln(Θic, d(0)) to be accumu-
lated to zero. They correspond to log-likelihoods of individual factors within
individual components.
Sequential mode, running for t = 1, 2, . . .,
a) Construct the data vectors Ψic;t, i ∈{1, . . . , ˚
d}, c ∈c∗.
b) Compute the values of the predictive pdfs f(dic;t|ψic;t, ˆΘicn, c) for dif-
ferent factors, i ∈i∗= {1, . . . , ˚
d}, in all components, c ∈c∗, using
the parameter estimates ˆΘicn that are constant during the time cycle
within the nth iteration. Thus, the approximate, ﬁxed one-stage-ahead
predictor with certainty-equivalence approximation is used.
c) Compute the values of predictive pdfs
f(dt|φc;t−1, ˆΘcn, c) ≡
 
i∈i∗
f(dic;t|ψic;t, ˆΘicn, c)
for each individual component c ∈c∗.
d) Compute the weights wcn;t approximating the Kronecker symbol δc,ct
wcn;t =
ˆαcnf(dt|φc;t−1, ˆΘcn, c)
2
˜c∈c∗ˆα˜cnf(dt|φ˜c;t−1, ˆΘ˜cn, ˜c)
.

162
6 Solution and principles of its approximation: learning part
e) Update the statistics κcn;t = κcn;t−1 + wcn;t.
f) Update the log-likelihood functions describing diﬀerent factors
Ln(Θic, d(t)) = wicn;t ln [f(dic;t|ψic;t, Θic, c)] + Ln(Θic, d(t −1)),
with
wicn;t =

˜c∈c∗
i
w˜cn;t.
(6.94)
The set c∗
i includes pointers to components that contain the ith factor.
g) Go to the beginning of Sequential mode if t ≤˚t. Otherwise continue.
3. Find the new point estimates ˆΘn+1 of Θ as the maximizing arguments of
the approximate log-likelihood

c∈c∗

κcn;˚t ln(αc) +

i∈i∗
Ln(Θic, d(˚t))

.
4. Evaluate the value of the approximate log-likelihood attained at the maxi-
mizing argument.
5. Stop if the value of the approximate log-likelihood has not increased or
n ≥˚n. Otherwise, set n = n + 1 and go to the beginning of Iterative mode.
Remark(s) 6.21
1. The algorithm can be used for searching maximum a posteriori proba-
bility estimate (MAP) by selecting nontrivial initial likelihood function
L(Θ, d(0)) and positive κn;0.
2. Obviously, the EM algorithm is applicable iﬀthe considered log-likelihood
function can be represented on the computer. It essentially means that we
have to deal with factors belonging to the exponential family; see Section
3.2.
3. The algorithm is intentionally
written
in the style of the quasi-Bayes
algorithm; Algorithm 6.13. It indicates their similarity, which enriches
both of them. For instance, the maximizing argument can be searched and
immediately used within the time cycle. It leads to the adaptive quasi-EM
algorithm. It can be used in online learning and its convergence can be
faster. The loss of the monotonic convergence and of the processing-order
independence is the price paid for it.
6.5.3 Batch quasi-Bayes estimation
The construction of the quasi-Bayes estimation implies that its results depend
on the order in which data are processed. Experiments have shown that this
dependence may be signiﬁcant. The EM algorithm avoids this drawback but
its orientation to the point estimation prevents us to embed it into the ad-
vantageous Bayesian framework. For instance, the construction of the prior
pdf by splitting (see Section 6.4.8) cannot be exploited. The presented inter-
pretation of the EM algorithm allows us to create a novel batch quasi-Bayes

6.5 Approximate parameter estimation
163
estimation algorithm that is processing-order independent. Essentially, it es-
timates pointers to components within nth iteration by using approximation
of pdfs of the mixture parameters. This pdf is ﬁxed within the nth stage of
the iterative search.
Algorithm 6.16 (BQB mixture estimation with common factors)
Initial mode
•
Select the complete structure of the mixture.
•
Select the upper bound ˚n on the number n of iterations set n = 0.
•
Set maximum of the v-log-likelihood ¯l = −∞.
•
Select the (ﬂat) pre-prior pdfs ¯f(Θic) related to the individual factors
f(dic;t+1|ψic;t+1, Θic, c),
ideally, in the conjugate form.
•
Select the pre-prior values ¯κc > 0 used in ﬂattening.
•
Select the initial guess of the prior pdfs fn(Θic) related to the individual
factors f(dic;t+1|ψic;t+1, Θic, c), ideally, in the conjugate form.
•
Select initial values κcn > 0 determining the prior Dirichlet pdf on the
component weights.
Iterative mode
1. Make copies f(Θic|d(0)) = fn(Θic) and κc;0 = κcn.
2. Set the value of the v-log-likelihood ln;0 = 0.
3. Compute the point estimates of the component weights ˆαcn =
κcn
2
˜c∈c∗κ˜cn .
Sequential mode, running for t = 1, 2, . . .,
a) Construct the data vectors Ψic;t, i ∈i∗≡{1, . . . , ˚
d}, c ∈c∗.
b) Compute the values of the predictive pdfs
fn(dic;t|ψic;t, c) =

f(dic;t|ψic;t, Θic, c)fn(Θic) dΘic
for each individual factor i ∈i∗in all components c ∈c∗. The prior pdf
fn(Θ) is constant during the time cycle. The ﬁxed one-step-ahead pre-
dictor (see Section 6.1.2) is thus used.
c) Compute the values of the predictive pdfs
fn(dt|ψc;t, c) ≡
 
i∈i∗
fn(dic;t|ψic;t, c)
for each individual component c ∈c∗.
d) Update v-log-likelihood ln;t = ln;t−1 + ln
2
c∈c∗ˆαcnfn(dt|ψc;t, c)

.
e) Compute the weights wcn;t approximating the Kronecker symbol δc,ct
wcn;t =
ˆαcnfn(dt|ψc;t, c)
2
˜c∈c∗ˆα˜cnfn(dt|ψ˜c;t, ˜c).

164
6 Solution and principles of its approximation: learning part
f) Update copies of the statistic κc;t = κc;t−1 +wcn;t determining Dirich-
let pdf.
g) Update copies of the prior pdfs
f(Θic|d(t)) ∝[f(dic;t|ψic;t, Θic, c)]wicn;t f(Θic|d(t −1)), (6.95)
wicn;t =

˜c∈c∗
i
w˜cn;t.
The set c∗
i includes pointers to components that contain the ith factor.
h) Go to the beginning of Sequential mode if t ≤˚t. Otherwise continue.
4. Stop if ln;˚t < ¯l or the compared valued are taken as equal (see Proposition
6.2) or n ≥˚n. Otherwise set ¯l = ln;˚t, increase the iteration counter n =
n + 1 and apply the ﬂattening operation to
Diα(κc;˚t)
 
c∈c∗
 
i∈i∗
f(Θic|d(˚t)).
It provides the new estimate of the prior pdf (6.3) given by fn(Θic), κcn.
The ﬂattening rate corresponding to the iterative Bayesian learning, cf.
Proposition 6.9, has to be used.
5. Go to the beginning of Iterative mode.
Remark(s) 6.22
1. The BQB algorithm uses Bayesian predictors for estimating the Kronecker
symbol δc,ct. They, among other, respect uncertainty of the current esti-
mates of unknown parameters. Predictions become too cautious if this un-
certainty is too high. It may break down the algorithm completely. Knowing
it, the remedy is simple. Essentially, predictions used in the EM algorithm
that ignore these uncertainties have to be used in several initial iterative
steps of the algorithm.
2. The improvement anticipated in Problem 6.13 can surely be applied to
BQB estimation, too.
6.6 Structure estimation
The structure of the mixture is determined by the number and composition of
components. Structure of individual factors is included in it; see Agreement
5.4. We can list the set of potential candidates for such a selection and label
promising subselections by a “structural” pointer S ∈S∗. As its best value
is unknown, it becomes a part of the unknown mixture parameter Θ. Its
estimation essentially reduces to evaluation of the corresponding marginal
probability f(S|d(˚t)). For it, the predictive pdfs f(dt|d(t−1), S), are computed
in parallel for the competing structures S ∈S∗and used for computing the
posterior pf

6.6 Structure estimation
165
f(S|d(˚t)) ∝
 
t∈t∗
f(dt|d(t −1), S) f(S) = I(d(˚t)|S)
I(d(0)|S)f(S).
(6.96)
Recall that I(d(˚t)|S) is the normalization constant (2.46) with Pa∗
˚
t+1 = d(˚t),
computed within the Sth structure. The pf f(S) is the optional prior proba-
bility assigned S ∈S∗.
The complexity of the structure estimation increases with the number
of compared structures. This number blows up exponentially with the di-
mensionality of data space, lengths of regression vectors and the number of
components. Thus, we can compare only a small subselection of competitive
structures. The following feasible iterative procedure is used.
Algorithm 6.17 (Conceptual structure estimation)
1. The mixture is estimated with the richest acceptable structure, both with
respect to the number of components and complexity of the involved fac-
tors.
2. Structures of the individual factors are estimated; see Section 6.6.1.
3. Quantities having no (even indirect) inﬂuence on quality markers are ex-
cluded from the considered structures; cf. Section 5.1.4.
4. Structures of the individual components are estimated; see Section 6.6.3.
5. Similar components are merged; see Section 6.6.4.
6. Superﬂuous components are cancelled; see Section 6.6.4.
7. The resulting mixture is ﬂattened and the evaluation sequence is iterated
until convergence.
Problem 6.14 (Feasibility and reliability of structure estimation) Stru-
cture estimation is known to be a hard task even in the unimodal case. The
known problems are surely enhanced in the mixture estimation. Suﬃcient
amount of data seems to be the only advantage of the addressed problem.
On the other hand, it increases the computational load. Both experimental
design [117] and speciﬁc instances of Algorithm 6.17 decide on the feasibility
and reliability of structure estimation. Adequate and practically feasible ex-
perimental design is not available for the considered estimation of mixtures.
Also, the proposed way of structure estimation can be and should be improved.
6.6.1 Estimation of factor structure
In this case, structures of unimodal models with single outputs have to be
estimated. This is a classical, well-supported problem. For normal factors,
eﬃcient numerical procedures exist [93, 95]. For other factors (Markov, MT;
see Chapters 10 and 12), the adequate procedures have to be prepared but
the basic ideas can be “stolen” from the normal case.

166
6 Solution and principles of its approximation: learning part
6.6.2 Structure estimation in factor splitting
Structure estimation before splitting of factors, Section 6.4.8, was found in-
dispensable when splitting is made in the direction of largest uncertainty of
the posterior pdf f(Θ|d(˚t)). This happens in the case of optimization-based
splitting.
Originally, superﬂuous parameters were excluded when recognized. This
action is, however, dangerous when the estimates are still too far from the
correct positions. Requirement 6.2 on suﬃcient richness of the factor struc-
ture is then easily violated. The parameters labelled as superﬂuous for an
intermediate mixture estimate can be signiﬁcant in the ﬁnal best estimate.
The following combination of the structure estimation with splitting provides
the remedy.
Let us apply structure estimation. It splits Θ = (Θa, Θb) ≡temporarily
(superﬂuous, signiﬁcant) parameters. Using some technique of Section 6.4.8,
the marginal pdf f(Θb|d(˚t)) is split into a pair ˆfj(Θb|d(˚t)), j = 1, 2. The part,
that is temporarily taken as superﬂuous, remains unchanged. It deﬁnes the
pair of pdfs on the original parameter space
ˆfj(Θ|d(˚t)) = f(Θa|Θb, d(˚t)) ˆfj(Θb|d(˚t)), j = 1, 2.
(6.97)
These pdfs are used in further iterations so that the possibility to move tem-
porarily superﬂuous parameter entries among signiﬁcant ones and vice versa
is preserved.
6.6.3 Estimation of component structure
A component is a product of factors (see Agreement 5.4)
f(dt|φt−1, Θc, c) =
 
i∈i∗
f(dic;t|d1c;t, . . . , d(i−1)c;t, φt−1, Θic)
≡
 
i∈i∗
f(dic;t|, ψic;t, Θic).
(6.98)
The permutation πc (5.10) of dt to dc;t inﬂuences the overall description of
the parameterized component. Thus, it makes sense to search for the best
ordering, to search for the structure of the component. It can be done by the
following conceptual algorithm.
Algorithm 6.18 (MAP estimate of a component structure) Specify the
set of compared structures of the component, and for all its entries execute
the following actions.
•
Estimate structures of the involved factors according to Section 6.6.1.
•
Evaluate the likelihood value assigned to the inspected component structure
and the best structures of factors.

6.6 Structure estimation
167
Finally, compute the posterior probability of the component structures within
the considered set and select the MAP estimate.
The algorithm is parameterized by the set of compared component struc-
tures. This set is always somehow restricted. The following constraints are
common.
•
Discrete-valued entries have to be placed at the end of d-entries in order
to get Markov-chain factors.
•
Structures in which “privileged quantities” deﬁning quality markers, Sec-
tion 5.1.4, depend on the smallest number of quantities are preferred.
Problem 6.15 (Algorithmic estimation of component structure) In
spite of the discussed restrictions, the complete set is again too large to be
inspected fully. Thus, a similar strategy to the factor-structure estimation has
to be adopted. A full local search around the best current guess of the structure
is to be performed while an improvement is observable. An algorithmic solution
of this problem is, however, missing.
6.6.4 Merging and cancelling of components
The initialization by the factor splitting, Section 6.4.8, is almost always em-
ployed for determining the overall number of components. During splitting,
the number of components increases rather quickly, leading to mixtures with
too many components. It calls for algorithms reducing the number of compo-
nents. They are discussed here.
We deal with mixtures with diﬀerent number of components. In order to
distinguish them, we attach the left superscript that stresses the number of
components involved.
Two types of reductions of number of components are possible. The merg-
ing of components deals with mixtures
⌊˚cf(dt|d(t −1), Θ) =
˚c

c=1
αcf(dt|d(t −1), Θc, c)
that contain almost identical components. We merge them and estimate the
mixture with less components.
The cancelling of components deals with mixtures containing negligible
components. We drop them and estimate the mixture with less components.
For a proper treatment of both cases, subsequent paragraphs inspect
•
how to modify prior and posterior pdfs on parameters after reducing the
number of components,
•
how to ﬁnd the component to be modiﬁed,
•
when to stop reductions.

168
6 Solution and principles of its approximation: learning part
How to modify pdfs on parameters?
The mixture is invariant with respect to permutations of its components.
Thus, we can inspect merging of the components ˚c−1,˚c and cancelling of the
component ˚c.
The verbal description of the component merging implies that
⌊˚c−1f(α1, . . . , α˚c−1, Θ1, . . . , Θ˚c−1)
(6.99)
∝
⌊˚cf(α1, . . . , α˚c, Θ1, . . . , Θ˚c|α˚c−1 = α˚c, Θ˚c−1 = Θ˚c)
∝

(6.3)
˚c−2
 
c=1
	
α
⌊˚
cκc−1 ⌊˚cf(Θc)

α
⌊˚
cκ˚
c−1+ ⌊˚
cκ˚
c−2
˚c−1
⌊˚cf(Θ˚c−1) ⌊˚cf(Θ˚c = Θ˚c−1).
It gives the merged component in the form
⌊˚c−1f(Θ˚c−1) ∝⌊˚cf(Θ˚c−1) ⌊˚cf(Θ˚c = Θ˚c−1)
(6.100)
and its weight is characterized by the statistic
⌊˚c−1κ˚c−1 = ⌊˚cκ˚c−1 + ⌊˚cκ˚c −1
while pdfs describing the remaining components and weights are unchanged.
The verbal description of the component cancelling implies that
⌊˚c−1f(α1, . . . , α˚c−1, Θ1, . . . , Θ˚c−1)
= ⌊˚cf(α1, . . . , α˚c, Θ1, . . . , Θ˚c−1, Θ˚c|α˚c = 0, Θ˚c has no inﬂuence)
∝

(6.3)
˚c−1
 
c=1
α
⌊˚
cκc−1
c
⌊˚cf(Θc).
(6.101)
Thus, the spurious component is completely neglected and statistics of the
remaining pdfs are unchanged.
Remark(s) 6.23
1. The considered prior and posterior pdfs have the common form (6.3) so
that the inspected question is answered both for prior and posterior pdfs.
2. The merging leads to a proper pdf only if
⌊˚cκ˚c−1 + ⌊˚cκ˚c −1 > 0. This
condition may be critical for prior pdfs as the component is ready for
cancelling if this condition is violated for the posterior pdf.
3. The merging (6.99) increases expected weights of components with indexes
c = 1, . . . ,˚c −2 as
⌊˚c−1E[αc] =
⌊˚cκc
2˚c
˜c=1
⌊˚cκ˜c −1
≥
⌊˚cκc
2˚c
˜c=1
⌊˚cκ˜c
≡⌊˚cE[αc].
Also, a straightforward algebra reveals that
⌊˚c−1E[α˚c−1] ≥⌊˚cE[α˚c−1] + ⌊˚cE[α˚c].
Thus, values of likelihoods assigned to respective components decide whether
the merging improves the overall mixture likelihood.

6.6 Structure estimation
169
4. The cancelling (6.101) implies
⌊˚c−1E[αc] ≡
⌊˚cκc
2˚c−1
˜c=1
⌊˚cκ˜c
≥
⌊˚cκc
2˚c
˜c=1
⌊˚cκ˜c
≡⌊˚cE[αc], c = 1, . . . ,˚c −1.
It indicates that there is a chance for an increase of the v-likelihood by
omitting a nonnegative term in the parameterized mixture.
5. The v-likelihood need not be recomputed after component merging and can-
celling if the error of the approximate estimation can be neglected. This
fact, demonstrated below, signiﬁcantly decreases the computational burden.
What are candidates for merging of components
Generally, we select the merging candidate by evaluating a distance between
the posterior pdf
⌊˚cf(Θ|d(˚t)), describing the original mixture, and the pdf
⌊˚c−1f(Θ|d(˚t)) obtained by merging. We have to extend the merged pdf to the
original parameter space. Then, we can use the KL divergence as the evaluated
distance.
Let us start with the extension of the merger.
The prior and posterior pdfs assigned to the original and merged pdf have
the form (6.3). The merging does not change initial component and their
estimates, i.e.,
⌊˚c−1f(Θc|d(˚t)) = ⌊˚cf(Θc|d(˚t)),
⌊˚c−1κc;˚t = ⌊˚cκc;˚t, c = 1, . . . ,˚c −2.
The same identity holds for prior pdfs.
The posterior pdf corresponding to the component obtained by merging
(6.100) has the form
⌊˚c−1f(Θ˚c−1|d(˚t)) ∝⌊˚cf(Θ˚c−1|d(˚t)) ⌊˚cf(Θ˚c = Θ˚c−1|d(˚t))
⌊˚c−1κ˚c−1;˚t = ⌊˚cκ˚c−1;˚t + ⌊˚cκ˚c;˚t −1.
The pdf ⌊˚c−1f(Θ|d(˚t)) acts on the reduced space of parameters. For judging
the distance of ⌊˚c−1f and ⌊˚cf, we have to stay within the original parameter
space corresponding to ˚c components. For achieving it, we extend the merger
on the original space by using identical estimates ˜f(Θ˚c−1|d(˚t)),
˜f(Θ˚c|d(˚t))
of the last two components. Both these pdfs are determined by the identical
statistics that are selected so that the merger (6.100) is obtained after their
merging. Taking into account the form (6.3), we can formalize this requirement
at the factor level and set
˜f(Θi(˚c−1) = Θi|d(˚t)) ≡˜f(Θi˚c = Θi|d(˚t))
∝
=
⌊˚cf(Θi(˚c−1) = Θi|d(˚t)) ⌊˚cf(Θi˚c = Θi|d(˚t))
˜κ˚t ≡0.5

⌊˚cκ˚c−1;˚t + ⌊˚cκ˚c;˚t

.
(6.102)

170
6 Solution and principles of its approximation: learning part
This completes extension of the prospective merger to the original space. The
posterior pdf
⌊˚c˜f(Θ|d(˚t)) has the form (6.3) with factors describing compo-
nents c = 1, . . . ,˚c−2 identical with those describing original mixture. The last
two components have the posterior pdfs assigned to them in the form (6.102).
With this, we are ready to search for merging candidates. The components
˚c−1, ˚c are taken candidate for merging if the following KL divergence is small
D(˚c−1)˚c ≡D

⌊˚cf(·|d(˚t))
!!!
!!! ⌊˚c˜f(·|d(˚t))

(6.103)
=
˚
d

i=1
	
D

⌊˚cf(Θi(˚c−1)|d(˚t))
!!!
!!! ˜f(Θi(˚c−1)|d(˚t))

+ D

⌊˚cf(Θi˚c|d(˚t))
!!!
!!! ˜f(Θi˚c|d(˚t))

+ D

Diα˚
c−1,α˚
c

⌊˚cκ˚c−1;˚t, ⌊˚cκ˚c;˚t
!!!
!!! Diα˚
c−1,α˚
c (˜κ˚t, ˜κ˚t)

.
This allows us to order candidates for merging. We take also into account
that
•
a diﬀerence in the structure of components prevents their merging as they
are inﬁnitely far,
•
the distance matrix (6.103) is symmetric,
•
the numerical construction of the trial merger is necessary for ﬁnding com-
ponents whose merging makes the smallest change of the posterior pdf.
Algorithm 6.19 (Selection and merging of a pair of components)
Initial mode
•
Perform estimation of the mixture with a suﬃcient number of components
˚c so that the pdfs ⌊˚cf(Θic|d(t)) and statistics ⌊˚cκt, t ∈{0,˚t}, c ∈c∗, i =
1, . . . , ˚
d, are at disposal.
•
Set the minimum value of the KL divergence D = +∞and initialize the
indexes (c,˜c) = (0, 0) of the component pair to be merged.
Evaluation mode
1. Select the pair whose merging leads to the smallest KL divergence between
the original mixture and mixture with the merged components as follows.
For
c = 1, . . . ,˚c −1
For
˜c = c + 1, . . . ,˚c
Set the indicator of the common structure cs = 0.
For
i = 1, . . . , ˚
d
Set cs = −1 and break the cycle over i if the structures of
Θic and Θi˜c diﬀer.

6.6 Structure estimation
171
Create the pdf ˜f (6.102) needed in the distance measuring
with ˚c −1 ↔c, ˚c ↔˜c (↔means mutual correspondence)
end
of the cycle over i
Do if cs = 0
Complete deﬁnition of the pdf (6.102) used in
the KL divergence and set ˜κ˚t = 1
2

κc;˚t + κ˜c;˚t

.
Evaluate the KL divergence ˜D ≡D(˚c−1)˚c according to (6.103)
with ˚c −1 ↔c, ˚c ↔˜c
If ˜D < D
Set D = ˜D, (c,˜c) = (c, ˜c) and store the pdf ˜f, ˜κ.
end of the test on the value ˜D
end of the condition cs = 0
end
of the cycle over ˜c
end
of the cycle over c
2. Stop and announce that no merging is possible if (c,˜c) = (0, 0). It happens
if no pair of components has the identical structure of components.
3. Rename components so that (˚c −1,˚c) = (c,˜c).
4. Finish the merging of the best components found and apply also the same
operation to the prior pdf, i.e.,
⌊˚c−1κ˚c−1;˚t ≡2˜κ˚t −1 ≡⌊˚cκ˚c−1;˚t + ⌊˚cκ˚c;˚t −1
⌊˚c−1κ˚c−1;0 ≡⌊˚cκ˚c−1;0 + ⌊˚cκ˚c;0 −1 and
For i = 1, . . . , ˚
d
⌊˚c−1f(Θi(˚c−1)|d(˚t))
≡
⌊˚cf(Θi(˚c−1)|d(˚t)) ⌊˚cf(Θi˚c = Θi(˚c−1)|d(˚t))
 ⌊˚cf(Θi(˚c−1)|d(˚t)) ⌊˚cf(Θi˚c = Θi(˚c−1)|d(˚t)) dΘi(˚c−1)
∝
	
˜f(Θi(˚c−1)|d(˚t))
2
(6.104)
⌊˚c−1f(Θi(˚c−1)|d(0)) ≡
≡
⌊˚cf(Θi(˚c−1)|d(0)) ⌊˚cf(Θi˚c = Θi(˚c−1)|d(0))
 ⌊˚cf(Θi(˚c−1)|d(0)) ⌊˚cf(Θi˚c = Θi(˚c−1)|d(0)) dΘi(˚c−1)
.
end of the cycle over i.
5. Leave the remaining components and statistics unchanged by the consid-
ered merging. It completes the deﬁnition of the prior and posterior pdf on
the mixture with ˚c −1 components.

172
6 Solution and principles of its approximation: learning part
The necessary condition for obtaining the proper pdfs κ˚c−1;t+κ˚t;t > 1, t ∈
{0,˚t} should be checked. Such components should not be merged but they are
hot candidates for cancelling.
The complexity of the underlying evaluations is clearer to see on a practical
version of this algorithm written for parameterized factors in the exponential
family
f(dic;t|ψic;t, Θic) = A(Θic) exp [⟨B(Ψic;t), C(Θic)⟩+ D(Ψic;t)] ,
with scalar functions A(Θic) ≥0, D(Ψic;t), Ψic;t = [dic;t, ψ′
ic;t]′, and ⟨·, ·⟩
being a scalar product of array-valued functions B(·), C(·); see Section 3.2.
Its conjugate pdfs have the form, t ∈{0,˚t},
⌊˚cf

Θ| ⌊˚cVt, ⌊˚cνt, ⌊˚cκt

= B−1 
⌊˚cκt

˚c
 
c=1
α
⌊˚
cκc;t−1
c
×
˚
d
 
i=1
A(Θic)
⌊˚
cνic;t exp
9 ⌊˚cVic;t, Cic(Θic)
:

A(Θic)
⌊˚
cνic;t exp
	6
⌊˚cVic;t, Cic(Θic)
7
dΘic



I( ⌊˚
cVic;t, ⌊˚
cνic;t)
.
(6.105)
Algorithm 6.20 (Merging of a component pair in EF)
Initial mode
•
Perform estimation of a mixture with a suﬃcient number of components
˚c so that statistics describing them
⌊˚cκt,
⌊˚cνic;t,
⌊˚cVic;t, t ∈{0,˚t}, c ∈
c∗, i = 1, . . . , ˚
d, are at disposal.
•
Set the minimum value of the KL divergence D = +∞and initialize the
indexes (c,˜c) = (0, 0) of the component pair to be merged.
Evaluation mode
1. Select the pair whose merging leads to the smallest KL divergence between
the original mixture and mixture with the merged components as follows.
For
c = 1, . . . ,˚c −1
For
˜c = c + 1, . . . ,˚c
Set the indicator of the common structure cs = 0.
For
i = 1, . . . , ˚
d
Set cs = −1 and break the cycle over i if the structures of
Θic and Θi˜c diﬀer.
Create the statistics
˜νi;˚t = 0.5(νic;˚t + νi˜c;˚t),
˜Vi;˚t = 0.5(Vic;˚t + Vi˜c;˚t).
end
of the cycle over i

6.6 Structure estimation
173
Do if cs = 0
Complete creating the statistics for the KL divergence
measuring and set ˜κ˚t = 0.5(κc;˚t + κ˜c;˚t).
Evaluate the common part of the KL divergence
˜D = D

Diαc,α˜c(κc;˚t, κ˜c;˚t)||Diαc,α˜c(˜κ˚t, ˜κ˚t)

.
Complete the evaluation of the KL divergence
For
i = 1, . . . , ˚
d
˜D = ˜D + D

f(Θic|Vic;˚t, νic;˚t)
!!!! f(Θic| ˜Vi;˚t, ˜νi;˚t)

+D

f(Θi˜c|Vi˜c;˚t, νi˜c;˚t)
!!!! f(Θic| ˜Vi;˚t, ˜νi;˚t)

.
end
of the cycle over i
If ˜D < D
Set D = ˜D, (c,˜c) = (c, ˜c) and store values of
the trial statistics ˜κ˚t, ˜νi;˚t, ˜Vi;˚t, ∀i ∈i∗.
end of the test on the value ˜D.
end of the condition cs = 0
end
of the cycle over ˜c
end
of the cycle over c
2. Stop and announce that no merging is possible if (c,˜c) = (0, 0).
3. Rename components so that (˚c −1,˚c) = (c,˜c).
4. Finish the merging of the best components found and also apply the same
operation to the prior pdf
⌊˚c−1κ˚c−1;˚t ≡2˜κ˚t −1 ≡⌊˚cκ˚c−1;˚t + ⌊˚cκ˚c;˚t −1
(6.106)
⌊˚c−1κ˚c−1;0 ≡⌊˚cκ˚c−1;0 + ⌊˚cκ˚c;0 −1 and
For
i = 1, . . . , ˚
d
⌊˚c−1νi(˚c−1);˚t ≡2˜νi;˚t ≡⌊˚cνi(˚c−1);˚t + ⌊˚cνi˚c;˚t
⌊˚c−1Vi(˚c−1);˚t ≡2 ˜Vi;˚t ≡⌊˚cVi(˚c−1);˚t + ⌊˚cVi˚c;˚t
⌊˚c−1νi(˚c−1);0 ≡⌊˚cνi(˚c−1);0 + ⌊˚cνi˚c;0
⌊˚c−1Vi(˚c−1);0 ≡⌊˚cVi(˚c−1);0 + ⌊˚cVi˚c;0.
(6.107)
end
of the cycle over i
5. Leave the remaining statistics unchanged by the considered merging. It
completes the deﬁnition of the conjugate prior and posterior pdfs on the
mixture with ˚c −1 components.

174
6 Solution and principles of its approximation: learning part
Remark(s) 6.24
Merging can be performed at the factor level. It is done in an independent
paragraph. Factor merging can reveal common factors that reﬂect a common
physical nature of some modelled relationships.
Merging of a group of components
The previous discussion describes how to merge a component pair. The result-
ing estimate has to be ﬂattened and the estimation repeated. It provides both
corrected merger and the v-likelihood that indicates success or failure of this
merging. This way is extremely costly for the considered large data sets. Thus,
it makes sense to merge several pairs of components before re-estimation. It
calls for a rule determining how many components should be merged. In other
words, the estimation results obtained for ˚c components have to be used for
prediction of the value of the v-likelihood after group merging. This problem
is addressed here.
The merging provides both
⌊˚c−1f(Θ|d(˚t)) and
⌊˚c−1f(Θ). We also know
⌊˚cf(Θ|d(˚t)) and
⌊˚cf(Θ). Parameter estimates of both mixtures, labelled by
˜c ∈{˚c −1,˚c}, obey approximately the Bayes rule
known



⌊˜cf(Θ|d(˚t)) =
⌊˜cf(d(˚t)|Θ)
known
  
⌊˜cf(Θ)
⌊˜cf(d(˚t))
.
(6.108)
For the mixture with ˚c terms, we even know the v-likelihood ⌊˚cf(d(˚t)). Let us
consider the prior and posterior pdfs describing parameters of both mixtures
on the subset ⌊˚cΘ∗determined by the merging conditions
α˚c−1 = α˚c, Θi(˚c−1) = Θi˚c, i = 1, . . . , ˚
d.
(6.109)
On this subset ⌊˚cf(d(˚t)|Θ) = ⌊˚c−1f(d(˚t)|Θ) and this factor cancels in the ratio
of expressions (6.108)
⌊˚c−1f(Θ|d(˚t))
⌊˚cf(Θ|d(˚t))
(6.110)
=
B
 ⌊˚cκ˚t

B
 ⌊˚c−1κ˚t

˚
d
 
i=1
⌊˚c−1f(Θi(˚c−1)|d(˚t))
⌊˚cf(Θi(˚c−1)|d(˚t)) ⌊˚cf(Θi˚c = Θi(˚c−1)|d(˚t))
=

(6.104),(6.4),(6.109)
Γ
 ⌊˚cκ˚c−1;˚t

Γ
 ⌊˚cκ˚c;˚t

Γ


2˚c
c=1
⌊˚cκc;˚t

−1

Γ
 ⌊˚cκ˚c−1;˚t + ⌊˚cκ˚c;˚t −1

Γ

2˚c
c=1
⌊˚cκc;˚t

×
˚
d
 
i=1
 ⌊˚cf(Θi(˚c−1)|d(˚t)) dΘi(˚c−1)
 ⌊˚cf(Θi˚c|d(˚t)) dΘi˚c
 ⌊˚cf(Θi(˚c−1)|d(˚t)) ⌊˚cf(Θi˚c = Θi(˚c−1)|d(˚t)) dΘi(˚c−1)

6.6 Structure estimation
175
=

(6.108),(6.104),(6.109)
⌊˚cf(d(˚t))
⌊˚c−1f(d(˚t))
Γ
 ⌊˚cκ˚c−1;0

Γ
 ⌊˚cκ˚c;0

Γ


2˚c
c=1
⌊˚cκc;0

−1

Γ
 ⌊˚cκ˚c−1;0 + ⌊˚cκ˚c;0 −1

Γ

2˚c
c=1
⌊˚cκc;0

×
˚
d
 
i=1
 ⌊˚cf(Θi(˚c−1)|d(0)) dΘi(˚c−1)
 ⌊˚cf(Θi˚c|d(0)) dΘi˚c
 ⌊˚cf(Θi(˚c−1)|d(0)) ⌊˚cf(Θi˚c = Θi(˚c−1)|d(0)) dΘi(˚c−1)
.
The last equality in (6.110) gives the identity that allows us to evaluate the
v-likelihood
⌊˚c−1f(d(˚t)) without repeating the whole estimation. Using the
formula Γ(x + 1) = xΓ(x), [156], we get
⌊˚c−1f(d(˚t)) = ⌊˚cf(d(˚t))
Γ( ⌊˚
cκ˚
c−1;0)Γ( ⌊˚
cκ˚
c;0)
2˚
c
c=1
⌊˚
cκc;0

−1
Γ( ⌊˚
cκ˚
c−1;0+ ⌊˚
cκ˚
c;0−1)
Γ( ⌊˚
cκ˚
c−1;˚
t)Γ( ⌊˚
cκ˚
c;˚
t)
2˚
c
c=1
⌊˚
cκc;˚
t

−1
Γ( ⌊˚
cκ˚
c−1;˚
t+ ⌊˚
cκ˚
c;˚
t−1)
(6.111)
×
/˚
d
i=1

⌊˚
cf(Θi(˚
c−1)|d(0)) dΘi(˚
c−1)

⌊˚
cf(Θi˚
c|d(0)) dΘi˚
c

⌊˚
cf(Θi(˚
c−1)|d(0)) ⌊˚
cf(Θi˚
c=Θi(˚
c−1)|d(0)) dΘi(˚
c−1)
/˚
d
i=1

⌊˚
cf(Θi(˚
c−1)|d(˚t)) dΘi(˚
c−1)

⌊˚
cf(Θi˚
c|d(˚t)) dΘi˚
c

⌊˚
cf(Θi(˚
c−1)|d(˚t)) ⌊˚
cf(Θi˚
c=Θi(˚
c−1)|d(˚t)) dΘi(˚
c−1)
.
Thus, we can judge whether trial merging of a component pair increases the
v-likelihood. This gives us a chance to merge a group components without
costly re-estimation.
We write the resulting algorithm for the practically signiﬁcant case of
components in the exponential family. For this model, the formula (6.111)
gets a more speciﬁc form. It can be written in terms of the statistics of the
original mixture so that the superscript ˚c can be dropped.
⌊˚c−1f(d(˚t)) =
= ⌊˚cf(d(˚t))
Γ

κ˚c−1;˚t + κ˚c;˚t −1

Γ (κ˚c−1;0) Γ (κ˚c;0)


2˚c
c=1 κc;0

−1

Γ (κ˚c−1;0 + κ˚c;0 −1) Γ

κ˚c−1;˚t

Γ

κ˚c;˚t
 

2˚c
c=1 κc;˚t

−1

×
˚
d
 
i=1
I(Vi(˚c−1);˚t + Vi˚c;˚t, νi(˚c−1);˚t + νi˚c;˚t)
I(Vi(˚c−1);0 + Vi˚c;0, νi(˚c−1);0 + νi˚c;0)
I(Vi(˚c−1);0, νi(˚c−1);0)I(Vi˚c;0, νi˚c;0)
I(Vi(˚c−1);˚t, νi(˚c−1);˚t)I(Vi˚c;˚t, νi˚c;˚t) .
The last formula allows us to modify Algorithm 6.20 so that promising can-
didates are gradually merged up to the moment when the v-likelihood is pre-
dicted to drop.
Algorithm 6.21 (Merging of a group of components in EF)
Initial mode
•
Perform estimation of a mixture with components in the exponential family
and conjugate prior pdfs. Let us do that for an over-estimated number of
components ˚c ≥2. Thus, the statistics ⌊˚cκt,
⌊˚cνic;t, ⌊˚cVic;t, t ∈{0,˚t}, c =
1, . . . ,˚c, i = 1, . . . , ˚
d, are at our disposal.

176
6 Solution and principles of its approximation: learning part
•
Set pointers c = 1, ˜c = 2 to trial components to be merged.
Evaluation mode
Set the indicator of the common structure cs = 0.
For
i = 1, . . . , ˚
d
Set cs = −1 and break the cycle over i if the structures of
Θic and Θi˜c diﬀer.
end
of the cycle over i
Do if cs = 0
Evaluate the common part of the trial merger
˜κ˚t = κc;˚t + κ˜c;˚t −1, ˜κ0 = κc;0 + κ˜c;0 −1.
Evaluate and store the factor-related parts of the trial merger
For
i = 1, . . . , ˚
d
˜νi;˚t = νic;˚t + νi˜c;˚t,
˜Vi;˚t = Vic;˚t + Vi˜c;˚t.
end
of the cycle over i
Evaluate the change ˜l of log-v-likelihood expected after
the deﬁnite merging
˜l =
"
−ln

Γ(κc;˚t)

−ln

Γ(κ˜c;˚t)

+ ln (Γ(˜κ˚t)) −ln
00˚c−1

c=1
κc;˚t
1
−1
1%
−
"
−ln (Γ(κc;0)) −ln (Γ(κ˜c;0)) + ln (Γ(˜κ0)) −ln
00 ˚c

c=1
κc;0
1
−1
1%
.
For
i = 1, . . . , ˚
d
(factor parts)
˜l = ˜l +

ln(I( ˜Vi;˚t, ˜νi;˚t)) −ln(I(Vic;˚t, νic;˚t)) −ln(I(Vi˜c;˚t, νi˜c;˚t))

−

ln(I( ˜Vi;0, ˜νi;0)) −ln(I(Vic;0, νic;0)) −ln(I(Vi˜c;0, νi˜c;0))

.
end
of the cycle over i
end of the condition cs = 0
If ˜l ≤0 or cs < 0
Set ˜c = ˜c + 1.
Go to the beginning of Evaluation mode if ˜c ≤˚c. Otherwise continue.
Set c = c + 1 and ˜c = c + 1.
Go to the beginning of Evaluation mode if c < ˚c. Otherwise stop.
else replace statistics related to the component c by
˜κ˚t, ˜κ0,

˜Vi;˚t, ˜Vi;0, ˜νi;˚t, ˜νi;0
˚
d
i=1 .

6.6 Structure estimation
177
Swap the components ˚c and ˜c.
Decrease ˚c = ˚c −1, i.e., omit the component ˜c.
Set ˜c = c + 1 if ˜c > ˚c.
end of the test on improvement of v-likelihood and of cs < 0
Stop if ˚c = 1. Otherwise go to the beginning of Evaluation mode.
Factor-based merging
Here we merge superﬂuous factors by inspecting the presence of common
factors. It decreases the computational load, can reveal relationships of a
common nature and — if a component pair will consist of common factors
only — to reduce the number of components. We proceed similarly as with
the merging of component pairs.
Candidates for merging
The pdf on parameters has the form (6.3)
f(Θ|d(t)) ≡Diα(κt)
 
c∈c∗
˚
d
 
i=1
f(Θicd(t)), t ∈{0,˚t}.
For presentation simplicity, we assume that the order of items di;t in the data
record dt is common for all components.
The pdf
⌊ic˜cf(Θ|d(t)), t ∈{0,˚t}, describing the parameter estimate —
under the hypothesis that estimates of the ith factor in components c ̸= ˜c ∈c∗
are equal — has the form
⌊ic˜cf(Θ|d(˚t)) ≡f(Θ|d(˚t))
˜f(Θic|d(˚t)) ˜f(Θi˜c|d(˚t))
f(Θic|d(˚t))f(Θi˜c|d(˚t)),
(6.112)
where f(Θ|d(˚t)) is the original pdf whose factors should be merged and
f(Θic|d(˚t)), f(Θi˜c|d(˚t)) are its marginal pdfs. The pdf ˜f(Θic|d(˚t)) is the con-
structed common factor, i.e., ˜f(Θic|d(˚t)) ≡˜f(Θi˜c = Θic|d(˚t)) ∀Θic ∈Θ∗
ic.
Creation of a common factor makes sense only when the structures of Θic and
Θi˜c are the same.
The KL divergence of the mixture with the common factor (6.112) to the
original mixture is
⌊ic˜cD ≡D

˜f(Θic|d(˚t))
!!!
!!! f(Θic|d(˚t))

+ D

˜f(Θic = Θi˜c|d(˚t))
!!!
!!! f(Θi˜c|d(˚t))

.
(6.113)
It is minimized by the geometric mean of the inspected factor estimates
˜f(Θic|d(˚t)) ∝
=
f(Θic|d(˚t))f(Θi˜c = Θic|d(˚t)).
(6.114)

178
6 Solution and principles of its approximation: learning part
Note that this merger is proposed in (6.102) without invoking this minimizing
property.
Thus, for all i = 1, . . . , ˚
d, we can independently evaluate distances ⌊ic˜cD,
c ∈c∗, ˜c > c, for the merger (6.114). The restriction to the upper triangular
part only exploits the obvious symmetry of matrices ⌊i··D, i = 1, . . . , ˚
d. The
prospective common factors should be closest to those describing the original
parameter estimate. This guides us in selecting the prospective merger.
Algorithm 6.22 (Selection and merging of pairs of factors)
Initial mode
•
Estimate the mixture with a suﬃcient number of components ˚c so that the
pdfs ⌊˚cf(Θic|d(t)) and statistics ⌊˚cκt, t ∈{0,˚t}, c ∈c∗, i = 1, . . . , ˚
d, are
at our disposal.
Evaluation mode
For
i = 1, . . . , ˚
d
Set the smallest value of the KL divergence D = +∞
and initiate indexes of the component pair
(c,˜c) = (0, 0) in which the merged factors are listed.
For
c = 1, . . . ,˚c −1
For
˜c = c + 1, . . . ,˚c
Go to the end of the cycle over ˜c if the structures of
Θic and Θi˜c diﬀer.
Create the trial merger (6.114)
Evaluate the KL divergence ˜D ≡⌊ic˜cD according to (6.113).
If ˜D < D
Set D = ˜D, (c,˜c) = (c, ˜c) and store the trial merger.
end of the test on the value of the KL divergence
end
of the cycle over ˜c
end
of the cycle over c
Go to the end of cycle over i if (c,˜c) = (0, 0).
Create a merger of prior pdfs corresponding to factors
with indexes ic and i˜c.
Replace prior and posterior estimates of factors with indexes
ic, i˜c by the trial merger.
end
of the cycle over i

6.6 Structure estimation
179
Merging of a group of factors
The need to perform full estimation after ﬂattening the merged factors needed
for judging improvement of the v-likelihood disqualiﬁes the way described in
the previous paragraph. Prediction of the v-likelihood in the same way done
with the component provides the adequate remedy. The ability to merge two
components only when all factors in them are merged is the main change with
respect to the merging of a group of components.
The proposed merging provides both
⌊ic˜cf(Θ|d(˚t)) and ⌊ic˜cf(Θ) ≡⌊ic˜cf(Θ|d(0)).
We also know f(Θ|d(˚t)), f(Θ) ≡f(Θ|d(0)) and the original v-likelihood
f(d(˚t)). We know that for values Θic = Θi˜c the corresponding likelihood
functions coincide. Assuming the ratio f(Θ|d(˚t))/ ⌊ic˜cf(Θ|d(˚t)) at such points,
using the Bayes rule and exploiting the merger form, we get
f(Θ|d(˚t))
⌊ic˜cf(Θ|d(˚t)) ≡

f(Θic|d(˚t))f(Θi˜c = Θic|d(˚t)) dΘic

f(Θic|d(˚t)) dΘic

f(Θi˜c|d(˚t)) dΘi˜c
=
⌊ic˜cf(d(˚t))
f(d(˚t))

f(Θic)f(Θi˜c = Θic) dΘic

f(Θic) dΘic

f(Θi˜c) dΘi˜c
.
It gives the rule how to ﬁnd the v-likelihood ⌊ic˜cf(d(˚t)) after merging
⌊ic˜cf(d(˚t)) = f

d(˚t)

(6.115)
×

f(Θic|d(˚t)) dΘic

f(Θi˜c|d(˚t)) dΘi˜c

f(Θic|d(˚t))f(Θi˜c = Θic|d(˚t)) dΘic

f(Θic)f(Θi˜c = Θic) dΘic

f(Θic) dΘic

f(Θi˜c) dΘi˜c
.
The constructed estimate makes it possible to merge a group of factors while
the v-likelihood is improving. Then, it remains to merge components. Obvi-
ously, the components c, ˜c with all factors common can be taken as a single
one. It makes no sense to distinguish them and their weights. Thus, the statis-
tics of their weights are simply summed. This leads to the following algorithm.
Algorithm 6.23 (Merging of a group of factors)
Initial mode
•
Perform estimation of a mixture with a suﬃcient number of components.
•
Initialize the list of factors with rows ρ = (i, c, ˜c) ≡ith factor is common
for components c, ˜c.
Mostly, ρ is selected as the empty one.
Evaluation mode
For
i = 1, . . . , ˚
d
For
c = 1, . . . ,˚c −1

180
6 Solution and principles of its approximation: learning part
For
˜c = c + 1, . . . ,˚c
Go to the end of the cycle over ˜c if the structures of
Θic and Θi˜c diﬀer.
Create and store the trial merger (6.114) of posterior pdfs.
Create the trial merger (6.114) of prior pdfs.
Evaluate the factor-related change (6.115) of
the v-likelihood predicted after merging.
Go to the end of cycle over ˜c if no improvement is predicted.
Replace prior and posterior factor estimates with indexes
ic, i˜c by the trial merger.
Extend the list of common factors by ρ = [ρ; (i, c,˜c)] .
end
of the cycle over ˜c
end
of the cycle over c
end
of the cycle over i
For
c = 1, . . . ,˚c −1
For
˜c = c + 1, . . . ,˚c
Set κ˜c;˚t = κ˜c;˚t + κc;˚t −1 κ˜c;0 = κ˜c;0 + κc;0 −1 and cancel cth
component if the components consist of common factors only.
end
of the cycle over ˜c
end
of the cycle over c
Problem 6.16 (Inﬂuence of component weights) The Dirichlet factor
inﬂuences the ﬁnal v-likelihood whenever components are merged. This fact
is not taken into account in Algorithm 6.23. It would be necessary to evaluate
the change of the v-likelihoods for the possibility that the components will be
merged as well as for the case that merging will concern only a few of factors.
The modiﬁcation is worth inspecting.
The above algorithm is now written for factors in the exponential family. It
is enriched so that common factors in several components can be recognized.
Algorithm 6.24 (Systematic merging of factors in EF)
Initial mode
•
Perform estimation of a mixture with factors in the exponential family.
The inspected part of the mixture estimate is described by the collection of
statistics
{Vic;t, νic;t}c∈c∗,i=1,...,˚
d,t∈{0,˚t} .
The factors with the common i are supposed to describe the same entry of
di;t irrespective of the component number.

6.6 Structure estimation
181
•
Initialize the list with rows ρ = (i, c, ˜c) ≡ith factor, which is common for
components c, ˜c. Usually, ρ is initialized as the empty one.
•
Evaluate logarithms of the individual normalization factors ln(I(Vic;t, νic:t)),
∀c ∈c∗, i = 1, . . . , ˚
d, t ∈{0,˚t}.
Evaluation mode
For
i = 1, . . . , ˚
d
Set pointers c = 1, ˜c = 2 to trial components to be merged.
Test of the common structure
Set the indicator of the common structure to cs = 0.
Set cs = −1 if the structures of Θic and Θi˜c diﬀer.
Do if cs = 0
Create the trial merger
˜Vi;˚t = Vic;˚t + Vi˜c;˚t, ˜Vi;0 = Vic;0 + Vi˜c;0
˜νi;˚t = νic;˚t + νi˜c;˚t, ˜νi;0 = νic;0 + νi˜c;0.
Evaluate increment ˜l of the log-v-likelihood
˜l = +

ln(I( ˜Vi;˚t, ˜νi;˚t)) −ln(I(Vic;˚t, νic;˚t)) −ln(I(Vi˜c;˚t, νi˜c;˚t))

−

ln(I( ˜Vi;0, ˜νi;0)) −ln(I(Vic;0, νic;0)) −ln(I(Vi˜c;0, νi˜c;0))

.
end of the test on cs = 0
If ˜l ≤0 or cs < 0
Set ˜c = ˜c + 1.
Go to the Test of the common structure if ˜c ≤˚c.
Otherwise continue.
Set c = c + 1 and ˜c = c + 1.
Go to the beginning of Test of the common structure if c < ˚c.
Otherwise go to the end of cycle over i.
else
replace prior and posterior estimates of factors with indexes
ic and i˜c by the trial merger.
Extend the list of common factors by ρ = [ρ; (i, c, ˜c)].
end of the test on improvement of v-likelihood and of cs < 0
end
of the cycle over i
Merging of components
For
c = 1, . . . ,˚c −1
For
˜c = c + 1, . . . ,˚c
Set κ˜c;˚t = κ˜c;˚t + κc;˚t −1,
κ˜c;0 = κ˜c;0 + κc;0 −1 and cancel the

182
6 Solution and principles of its approximation: learning part
cth component if the components consist of common factors only.
end
of the cycle over ˜c
end
of the cycle over c
Remark(s) 6.25
Solution of Problem 6.23 would improve the above algorithm, too.
Component cancelling
The technique used in connection with the merging of components allows us
predict the inﬂuence of cancelling on the v-likelihood without re-estimation.
Consequently, all cancelling possibilities can be checked with a relatively small
computational load. The explicit solution is described here. It needs a bit of
care since for α˚c = 0 the prior and posterior pdfs are zero.
The the chain rule f(a|b) = f(a, b)/f(b), properties of the Dirichlet pdf,
and the formula for marginal pdf (10.4) in Proposition 10.1, however, imply
that for f( ⌊˚cα) = Di ⌊˚
cα
 ⌊˚cκ

the conditional pdf
⌊˚cf(α|α˚c = 0) = Di[α1,...,α˚
c−1]

	
⌊˚cκ1, . . . , ⌊˚cκ˚c−1

≡⌊˚c−1f(α) ≡Diα

⌊˚c−1κ

.
The posterior pdf on parameters before cancelling conditioned by α˚c = 0 and
the posterior pdf after cancelling have the form
⌊˚cf(Θ|d(˚t), α˚c = 0) = Diα( ⌊˚c−1κ˚t)
˚c
 
c=1
⌊˚cf(Θc|d(˚t))
⌊˚cIc(d(˚t))
(6.116)
=
⌊˚cf(d(˚t)|Θ, α˚c = 0)
⌊˚cf(d(˚t))
Diα( ⌊˚c−1κ0)
˚c
 
c=1
⌊˚cf(Θc|d(0))
⌊˚cIc(d(0))
⌊˚c−1f(Θ|d(˚t)) = Diα( ⌊˚c−1κ˚t)

⌊˚c−1κ˚t
˚c−1
 
c=1
⌊˚c−1f(Θc|d(˚t))
⌊˚c−1Ic(d(˚t))
=
⌊˚c−1f(d(˚t)|Θ)
⌊˚c−1f(d(˚t)) Diα

⌊˚c−1κ0
˚c−1
 
c=1
⌊˚cf(Θc|d(0))
⌊˚cIc(d(0)) .
Similarly as above, ⌊˚cIc(d(t)), t ∈{0,˚t} denote normalizing integrals of the
pdfs describing parameters Θc conditioned on d(t) for the mixture with ˚c
components.
The mixture form of the parameterized model implies that
⌊˚cf

dt
!!d(t −1), {Θc, αc}˚c−1
c=1, Θ˚c, α˚c = 0

does not depend on Θ˚c. Thus, the exact posterior pdf
⌊˚cf(Θ˚c|d(˚t), α˚c = 0)
coincides with its prior counterpart
⌊˚cf(Θ˚c|α˚c = 0). The evaluated approx-
imate posterior pdf does not meet this condition. This makes us combine

6.6 Structure estimation
183
the relationships (6.116) at a speciﬁc point ⌊˚cΘ for which even approximate
estimation provides an exact value likelihood.
We assume that there are parameter values ⌊˚cΘc, c = 1, . . . ,˚c such that
f

dt|d(t −1), ⌊˚cΘc, c

= g(d(t)) for c = 1, . . . ,˚c and a function g(d(t)).
(6.117)
Then, the likelihood values ⌊˚cf

d(˚t)| ⌊˚cΘ, ⌊˚cα˚c = 0

, ⌊˚c−1f

d(˚t)| ⌊˚cΘ

assigned
to both parameterized models coincide as the component weights sum to unity.
Taking the ratios of the posterior pdfs of both mixture models at such param-
eters, we get
⌊˚c−1f(d(˚t)) = ⌊˚cf(d(˚t))
⌊˚cf
 ⌊˚cΘ˚c
!! d(˚t)

⌊˚cf
 ⌊˚cΘ˚c
!! d(0)
 I˚c(d(0))
I˚c(d(˚t)) .
(6.118)
The value
⌊˚cΘ˚c is ﬁxed by the requirement (6.117); thus we can predict
whether the cancelling will result in a higher v-likelihood. It directly gives
the algorithm searched for. It is written for the exponential family.
Algorithm 6.25 (Systematic cancelling of components in EF)
Initial mode
•
Perform estimation of a mixture with factors in the exponential family.
The relevant part of the mixture estimate is described by the statistics
{Vic;t, νic;t}c∈c∗,i=1,...,˚
d,t∈{0,˚t} .
The factors with the common i are supposed to describe the same entry of
di;t irrespective of the component number.
•
Evaluate logarithms of the normalization factors ln(I(Vic;t, νic;t)), ∀c ∈
c∗, i = 1, . . . , ˚
d, t ∈{0,˚t}.
•
Select values
 ⌊˚cΘc

c∈c∗such that f (dt| d(t −1), ⌊˚cΘc, c

= g(d(t)), ∀c ∈
c∗, with a positive ﬁnite value g(d(t)) independent of c.
•
Set c = 1.
Evaluation mode
Do while c ≤˚c and ˚c > 1
Set l = ln

f

⌊˚cΘc
!!! d(˚t)

−ln

f

⌊˚cΘc
!!! d(0)

For
i = 1, . . . , ˚
d
l = l + ln (I(Vic;0, νic;0)) −ln

I(Vic;˚t, νic;˚t)

end
of the cycle over i
If l > 0
Swap c with ˚c and set ˚c = ˚c −1, i.e., cancel the component
else

184
6 Solution and principles of its approximation: learning part
Set c = c + 1
end of the test on v-log-likelihood increase
end of the while cycle over c
Remark(s) 6.26
1. Originally, components were cancelled using hypothesis testing with re-
estimation after each trial cancelling. It worked but it was computationally
expensive.
2. Intuitively, the components with very small estimates ˆαc;˚t are candidates
for cancelling. This check is made indirectly in the proposed algorithm as
the increase of the statistics κc determining them is the same as the in-
crease of statistics νic; see Section 6.5. The presented solution respects,
moreover, the values of pdfs deﬁning the individual components. Conse-
quently, the hard selection of the level deﬁning the small values is avoided.
3. An alternative solution of the cancelling problem was proposed and tested
in [157]. It estimates a background level by including a ﬁxed ﬂat pdf into
the estimated mixture. Then, all components that have weights well below
it are cancelled.
Problem 6.17 (Predicted v-likelihood in model validation) Both merg-
ing and cancelling exploits prediction of the v-likelihood. The quality of the
prediction is strongly correlated with the quality of the model. It leads to the
obvious idea: to exploit the discrepancy between predicted and evaluated v-
likelihood for the model validation; see Section 6.7. The discrepancy can be
potentially used in controlling the learning process, to be used as the main
input in sequential stopping rules [127].
Problem 6.18 (Removal of superﬂuous data items) The ﬁnal mixture
found may model quantities that have, even indirectly, no inﬂuence on data
determining quality markers of the problem, cf. Step 9 in Algorithm 5.2. Then,
they should be removed completely from consideration. The adequate analysis
of the graph describing nontrivial relationships among quantities is to be com-
plemented by the tool set described in this text.
6.7 Model validation
The complexity of the mixture estimation makes model validation a necessary
part of the overall design of the p-system. A full-scale use of the p-system is a
decisive validation test. However, a number of oﬄine tests is needed in order
to check the quality of its design while developing it. This aspect is the topic
of this section.
Generally, we test the hypothesis H ≡estimated model is good. Tests
diﬀer in the speciﬁcation of alternatives to this hypothesis. The validation art

6.7 Model validation
185
consists of a proper selection of alternatives that can compete with the tested
hypothesis and can be evaluated with the limited computer power available.
Section 6.7.1 discusses the exploitation of additional externally supplied
information on processed data for testing their homogeneity. The test serves
for deciding whether or not to segment the data in subgroups before estima-
tion. Learning results are inspected in Section 6.7.2. It reﬁnes the most usual
tests that evaluate model quality on the subset of data unused in estimation.
The subsequent subsections represent samples of various heuristic inspec-
tions tried. They indicate how underdeveloped this area is and how many
theoretical and algorithmic results are needed.
A nonstandard but quite eﬃcient test based on comparing models esti-
mated with diﬀerent forgetting rates is in Section 6.7.3. Evaluation by de-
signer is commented in Section 6.7.4 and links to the design part in Section
6.7.5.
6.7.1 Test of data homogeneity
Discussion on PCA in Section 6.2.1 indicates that learning is substantially
simpliﬁed if the learning data are segmented into homogenous groups before
processing. Such a segmentation is inspected in this subsection.
Often, raw data sets to be processed can be qualiﬁed by process experts.
For instance, the expert distinguishes diﬀerent classes of the input material
and expects diﬀerent behaviors of the o-system in their processing.
Here we consider an alternative situation when data segments are cat-
egorized as reﬂecting excellent, good, bad (possibly with a type of errors)
behaviors. The categorization provides an important additional data item,
say e ∈e∗≡{1, . . . ,˚e}, ˚e < ∞, that is worth being exploited.
Some of the discussed labels might be directly measured. Then, they are
simply discrete data. Even if they are nonmodelled, cf. Agreement 5.4, their
presence in condition directly segments data. Markov-type factors are at our
disposal when they are modelled and predicted. In both these cases, they do
not diﬀer from other data and require no special discussion.
Diﬀerent situation arises when the data are classiﬁed ex post. In this case,
a ﬁner modelling is desirable as a reasonably managed system provides a few
data sets with the label “bad” (errors are exceptional). They could get too
small weight or could be completely overlooked when they are treated without
taking into account their speciﬁc position. This danger is enhanced by the fact
that such labels are constant over whole data blocks.
For the ﬁner modelling of this case, we formulate adequate hypotheses. In
their formulation, we assume that the standard and labelled data form blocks
with their speciﬁc time counters.
H0 ≡The observed diﬀerence in quality is caused by inseparable inﬂuence of
external conditions and the way of operating. In technical terms, a single
mixture describes the standard d(˚ts) as well as the labelled d(˚te) data.
Thus, for d(˚t) ≡(d(˚ts), d(˚te)),

186
6 Solution and principles of its approximation: learning part
f(d(˚t)|H0) =

f(d(˚t)|Θ, H0)f(Θ|H0) dΘ.
(6.119)
The symbol H0 in the conditions stresses that both the structure of a
mixture and the prior pdf are chosen under this hypothesis.
H1 ≡The observed diﬀerence in quality is caused by diﬀerence in operating.
In technical terms, diﬀerent mixtures should be used for the standard
d(˚ts) and labelled d(˚te) data, respectively. Thus, for d(˚t) ≡(d(˚ts), d(˚te)),
f(d(˚t)|H1) =

f(d(˚ts)|Θs, H1)f(Θs, H1) dΘs

f(d(˚te)|Θe, H1)f(Θe|H1) dΘe.
(6.120)
The structure of the mixture and the prior parameter estimate for pro-
cessing of d(˚te) may diﬀer from those used on d(˚ts). This fact is stressed
by the indexes s, e.
With these elements and no prejudice, f(H0) = f(H1), the Bayes rule provides
the posterior pdf f(H0|d(˚t)). The common model — hypothesis H0 — can be
accepted if this probability is high enough.
The conceptual testing algorithm that may test any suspicion on hetero-
geneity of data looks as follows.
Algorithm 6.26 (Test of data homogeneity)
1. Run complete mixture estimations on the standard d(˚ts), labelled d(˚te) and
concatenated data d(˚t) ≡

d(˚ts), d(˚te)

.
2. Evaluate the corresponding v-likelihood
f(d(˚ts)|H1) =

f(d(˚ts)|Θs, H1)f(Θs|H1) dΘs
f(d(˚te)|H1) =

f(d(˚te)|Θe, H1)f(Θe|H1) dΘ
f(d(˚t)|H0) =

f(d(˚ts), d(˚te)|Θ, H0)f(Θ|H0) dΘ.
3. Determine probability of the hypothesis H0 that a single standard model
should be used
f(standard|d(˚t)) ≡f(H0|d(˚t)) =
f(d(˚t)|H0)
f(d(˚t)|H0) + f(d(˚ts)|H1)f(d(˚te)|H1).
(6.121)
4. Use the single model further on if f(H0|d(˚t)) is close to one. Inspect the
factors that were active on d(˚te) as potentially dangerous.
5. Use both mixtures independently if f(H0|d(˚t)) is close to zero. A danger
connected with the situations labelled by e should be signaled whenever the
model ﬁtted to d(˚te) makes better predictions than the model ﬁtted to the
standard data d(˚ts).

6.7 Model validation
187
Remark(s) 6.27
1. Obviously, the excellent or bad outcomes of the o-system may be caused by
conditions that are out of control of the operator. For instance, excellent
output quality of the rolling may be attributed to the operator or to the
excellent input quality of the rolled material. This dichotomy leads to the
important warning.
Quality labels are insuﬃcient to express the managing quality.
2. It is worth stressing that the available labelling may help us in marking
the factors active on bad data d(˚te) as potentially dangerous even if insep-
arability of external conditions and quality of operating (hypothesis H0) is
accepted.
3. The inspected situation is often classiﬁed as learning with an imperfect
teacher: the quality of the supplied labels is tested. This observation im-
plies that we can use the same test also on segmentation recommended by
an expert according to directly measured indicators. It will simply check
whether the distinction supposed by the process is signiﬁcant or not.
6.7.2 Learning results
During the learning, basic assumptions used in the design of the p-system
should be tested. The following questions have to be answered during the
model validation; see Chapter 5.
•
Can the o-system be described by a time invariant mixture model in prac-
tically all possible working conditions?
•
Do learning data cover suﬃciently all these working conditions?
Essentially, we are asking how good is the obtained model in extrapolation
of the past to the future. In the oﬄine mode, it can be tested by cutting the
available data d(˚t) into learning data d(˚tl) and validation data d(˚tv). To check
it, we assume that the test on labelled data, Algorithm 6.26, was performed.
Thus, we are dealing with homogeneous data describable by a single mixture.
For validation of learning results, we formulate hypotheses similar to those in
Section 6.7.1 but inspecting the following validation aspect.
H0 ≡All data — both learning and validation ones — d(˚t) ≡(d(˚tl), d(˚tv)) are
described by a single mixture model. The v-likelihood of this hypothesis is
obtained by running of the quasi-Bayes or batch quasi-Bayes algorithms
on all data
f(d(˚t)|H0) ≡

f(d(˚t)|Θl, H0)f(Θl|H0) dΘl.
(6.122)
In this case, both the structure of the model f(d(˚t)|Θl, H0) and the prior
pdf used in learning phase f(Θl|H0) are used also for the validation data
d(˚tv).

188
6 Solution and principles of its approximation: learning part
H1 ≡Learning data and validation data should be described by individual
models. The v-likelihood of this hypothesis is obtained by independent
runs of the quasi-Bayes or batch quasi-Bayes algorithms on both data
collections giving
f(d(˚t)|H1)
(6.123)
≡

f(d(˚tl)|Θl, H1)f(Θl|H1) dΘl ×

f(d(˚tv)|Θv, H1)f(Θv|H1) dΘv.
The structure of the used model f(d(˚tv)|Θv, H1) and the prior pdf f(Θv)
for the validation data d(˚tv) may diﬀer from those for learning data.
With these elements and no prejudice, f(H0) = f(H1), the Bayes rule provides
the posterior pdf f(H0|d(˚t)). The learned model can be accepted as a good one
if the posterior pf f(H0|d(˚t)) is high enough. Otherwise, we have to search for
reasons why the chosen model is not reliable enough. It gives the algorithmic
solution that is formally identical with Algorithm 6.26 but with the processed
data segmented in a diﬀerent way.
Algorithm 6.27 (Model validation on homogenous data)
1. Run complete mixture estimations on learning d(˚tl), validation d(˚tv) and
full d(˚t) ≡(d(˚tl), d(˚tv)) data.
2. Evaluate the corresponding v-likelihood values f

d(˚tl)|H1

, f

d(˚tv)|H1

,
f

d(˚t)|H0

.
3. Determine the probability of successful learning
f

success|d(˚t)

≡f

H0|d(˚t)

(6.124)
=
f

d(˚t)|H0

f

d(˚t)|H0

+ f

d(˚tl)|H1

f

d(˚tv)|H1
.
4. The test is successfully passed if f(H0|d(˚t)) is close to 1. Otherwise, mea-
sures for a better learning have to be taken.
Results of the test depend, often strongly, on the way how the available
data are cut into learning and validation parts. Surprisingly, this aspect is
rarely discussed for dynamic systems. The extensive available results are al-
most exclusively focused on static problems [124].
Here, we inspect the choice of the cutting moments tu in the dynamic case.
The cutting should be obviously restricted to suﬃciently long subsequences of
consecutive records. The proper length of these subsequences is, however, un-
known. Thus, it makes sense to validate learning for various cutting moments
tu ∈t∗
u ⊂t∗. The cutting moment controls the validation test as it identiﬁes
dl;t ≡dt for t ≤tu and dv;t = dt for t > tu.
We are making a pair of decisions ( ˆH, tu) based on the experience P ≡d(˚t).
We select tu ∈t∗
u and accept ( ˆH = H0) that the learned model is valid or

6.7 Model validation
189
reject it ( ˆH = H1). We assume for simplicity that the losses caused by a wrong
acceptance and rejection are identical, say z > 0.
We solve this static decision task and select the optimal decision ⌊o ˆH on
inspected hypotheses and optimal cutting time moment ⌊otu as a minimizer
of the expected loss
( ⌊o ˆH, ⌊otu) ∈Arg
min
ˆ
H∈{H0,H1},tu∈t∗
u
E
	
(1 −δ ˆ
H,H)z

.
(6.125)
Proposition 6.19 (Optimal cutting) Let 0,˚t ∈t∗
u. Then, the optimal de-
cision ⌊o ˆH about the inspected hypotheses H0, H1 and the optimal cutting ⌊otu,
that minimize the expected loss in (6.125) are given by the following rule
Compute ⌊0tu ∈Arg max
t∈t∗
u f(H0|d(˚t), tu)
⌊1tu ∈Arg min
t∈t∗
u
f(H0|d(˚t), tu)
(6.126)
Select ⌊o ˆH = H0, ⌊otu = ⌊0tu if
f(H0|d(˚t), ⌊0tu) ≥1 −f(H0|d(˚t), ⌊1tu)
⌊o ˆH = H1,
⌊otu = ⌊1tu if
f(H0|d(˚t), ⌊0tu) < 1 −f(H0|d(˚t), ⌊1tu).
Proof. Let us take the cutting moments ⌊0t∗
u ≡

τ ∈t∗
u : f(H0|d(˚t), tu) ≥0.5

.
This ﬁnite set is nonempty, as for tu = 0 f(H0|d(˚t), tu) = 0.5. For a ﬁxed tu ∈
⌊0t∗
u, the decision ˆH = H0 leads to a smaller loss than the decision ˆH = H1.
The achieved minimum is expectation over d(˚t) of 1 −f(H0|d(˚t), ⌊0tu). Thus,
it is smallest for ⌊0t maximizing f(H0|d(˚t), tu) on ⌊0t∗
u.
For any ﬁxed tu in the set ⌊1t∗
u ≡{tu ∈t∗
u : f(H0|d(˚t), tu) ≤0.5}, the deci-
sion ˆH = H1 leads to a smaller loss than the decision ˆH = H0. The achieved
minimum is expectation over d(˚t) of f(H0|d(˚t), tu). Thus, it is smallest for
⌊1tu minimizing f(H0|d(˚t), tu) on ⌊1τ ∗. The smaller of the discussed pairs of
minima determines the optimal decision pair.
Remark(s) 6.28
1. The choice of the prior pdf for estimation on the validation data is critical
for a good performance of the test. The use of the posterior pdf obtained
from the validation data and ﬂattened as in branching (see Section 6.4.3)
seems to be satisfactory.
2. A practical application of the above test depends strongly on the set t∗
u
of the allowed cutting moments. The ﬁnest possible choice t∗
u = t∗. An
exhaustive search is too demanding for the considered extensive data sets.
A search for the minimizer by a version of the golden-cut rule, by a random
choice or by systematic inspection on a proper subset on a small predeﬁned
grid can be applied. The predeﬁned grid seems to be the simplest variant
as minor changes in tu make no physical sense.

190
6 Solution and principles of its approximation: learning part
3. Learning and validation data have to overlap in dynamic case in order to
ﬁll the richest regression vector occurring in the mixture. This ﬁne point is
neglected in analysis as it has negligible inﬂuence on the test performance.
6.7.3 Forgetting-based validation
This subsection presents a relatively successful sample of many heuristic at-
tempts to ﬁnd eﬃcient validation tests.
Forgetting techniques are proposed to cope with slow variations of pa-
rameters caused either by real changes or by under-modelling. It oﬀers the
following “natural” test of validity of the ﬁxed estimated model.
The tested model is taken as an alternative in estimations with stabilized
forgetting, Section 3.1, run in parallel for several forgetting factors. If the
tested model is good then it can be expected that the additional adaptation
brings no new quality in the description of data. Thus, the approximate learn-
ing is expected to describe the observed data the better, the higher weight is
given to the valid tested model taken as an alternative in stabilized forgetting.
It immediately gives the following validation algorithm.
Algorithm 6.28 (Forgetting-based validation)
Initial mode
•
Estimate completely the mixture model, i.e., both parameters and structure
and denote the resulting pdf f(Θ|d(˚t)).
•
Apply ﬂattening to f(Θ|d(˚t)) in the branching version, Section 6.4.3, so
that a good prior pdf f(Θ) is obtained.
•
Select several forgetting factors 0 ≈λ1 < λ2 < · · · < λ˚i−1 < λ˚i = 1,
1 <˚i < ∞.
•
Set prior pdfs f(Θ|λi) = f(Θ).
Validation mode
1. Perform estimation with the stabilized forgetting, Section 3.1, for all λi,
using the tested prior pdf f(Θ|d(˚t)) as the alternative.
2. Evaluate values of the v-likelihood li;˚t = f(d(˚t)|λi) and compute MAP
estimate ˆλ of λ.
3. Take the model as a successful one if λ1 = ˆλ. Otherwise search for its
improvements.
Remark(s) 6.29
Often, three alternative forgetting factors are suﬃcient for a good testing.
Problem 6.19 (Analysis of forgetting-based validation) Algorithm 6.19
is intuitively appealing and practical experience with it is good. Appropriate
insight is, however, missing and a deeper analysis is highly desirable.

6.7 Model validation
191
6.7.4 Inspection by a human designer
Complete visual inspections are mostly excluded due to the excessive dimen-
sionality of data records. A partial visual inspection is possible and useful
especially when the inﬂuence of various low-dimensional factors on the result-
ing quality is inspected. This situation happens repeatedly when various tools
for designing the advisory system are being constructed or when these tools
are tailored to a speciﬁc managed system. Human beings are able to grasp
relationships that are hard to ﬁnd in an algorithmic way. At the same time,
this ability is restricted to 2 or 3 dimensional spaces. Proposition 7.2 shows
how to get such low-dimensional projections in a computationally cheap way.
6.7.5 Operating modes
A stable model does not guarantee that we get eﬃcient advisory system. As
discussed in Section 5.1.2, the p-system makes sense if there are good and bad
modes of operating that are reﬂected in the observation space of the p-system.
These conditions have to be tested, too.
The distance of the observable behavior of the o-system to the user’s ideal
pdf ⌊Uf is measured by the KL divergence. Recall that we extended the true
user’s ideal pdf on the full data space of the p-system (5.7). The KL divergence
has the form
D

f
!!!
!!! ⌊Uf

=

f(d(˚t)) ln
 f(d(˚t))
⌊Uf(d(˚t))

dd(˚t)
(6.127)
=

t∈t∗
E
#
f(dt|d(t −1)) ln
 f(dt|d(t −1))
⌊Uf(dt|d(t −1))

ddt
$
.
Let us assume, that f(dt|d(t −1)) = 2
c∈c∗αcf(dt|d(t −1), c) is a known, i.e.,
well estimated, mixture. Then, the Jensen inequality (2.14) and the inequality
between weighted arithmetic and geometric means imply
D

f
!!!
!!! ⌊Uf

(6.128)
≤

c∈c∗
αc

t∈t∗
E
#
f(dt|d(t −1), c) ln
 f(dt|d(t −1), c)
⌊Uf(dt|d(t −1))

ddt
$
D

f
!!!
!!! ⌊Uf

≥

c∈c∗

˜c∈c∗
αcα˜c

t∈t∗
E
#
f(dt|d(t −1), ˜c) ln
 f(dt|d(t −1), c)
⌊Uf(dt|d(t −1))

ddt
$
.
The inequalities (6.128) provide lower and upper bounds on the KL diver-
gence to be optimized. The upper bound is determined by the KL divergences
of individual components to the user’s ideal pdf ⌊Uf. For the weights α with
a dominant entry αc ≈1, the same distance dominates the lower bound. For

192
6 Solution and principles of its approximation: learning part
αc = 1, inequalities reduce to equalities. It supports an intuitive deﬁnition of
good (bad) modes as components having small (large) KL divergence to ⌊Uf.
Obviously, advising has a chance to be successful if there is a component, with
non-negligible weight, whose KL divergence to the user’s ideal pdf is (signiﬁ-
cantly) smaller than that of other components with non-negligible weights. It
makes the distribution of pairs (component weight, component KL divergence
to ⌊Uf) a signiﬁcant indicator of the potential design success.
Problem 6.20 (Systematic model validation) Above, various ideas on
the model validation are outlined. Experimental results as well as the diversity
of techniques proposed indicate that we are still dealing more with a bag of
tricks than with a systematic approach. This status should be improved.
We have at our disposal a wide supply of indicators when addressing the
problem.
In learning, for instance, structure estimates should be stable over vari-
ous data sets and no branching, merging or cancelling of components should
improve the value of the v-likelihood, etc.
In design, for instance, prediction of quality markers, Section 5.1.4, as
well as prediction of recognizable operator actions, Agreement 5.7, are good
partial tests.
Also, having in mind the warning that the o-system has to be judged as a
mapping of external conditions on the quality of results (see Section 6.7.1),
we can proceed as follows.
•
Split available data on those with good and bad management results.
•
Build independent mixture models on them.
•
Judge whether the operator has a tendency to improve or spoil the quality
of the overall behavior.
•
Take operating modes leading to improvement (deterioration) as good (bad)
ones.
•
Search for similarity of good (bad) modes obtained on both data ﬁles.
Remark(s) 6.30
Problem 6.20 is quite hard. Meanwhile, the collection of and stabilization of
intuitively acceptable indicators like
•
comparison of data moments predicted by the estimated model with their
sample counterparts
•
analysis of components as dynamic mappings (structure of eigenvalues)
•
comparison of theoretical and measured properties (whiteness of prediction
errors)
•
. . .
are invaluable.

7
Solution and principles of its approximation:
design part
Proposition 2.11 on fully probabilistic design, ﬁlled by elements described in
Chapter 5, provides a complete formal solution of the design of the advisory
system. It speciﬁes the evaluation structure but cannot be practically used.
The exact analytical solution is not available and the brute force numerical
approach is inhibited by the “curse of dimensionality”. Thus, the formal so-
lution has to be complemented by approximate feasible evaluations. For the
learning part of the advisory system, this is done in Chapter 6. The discussion
related to the design part is discussed here.
The design is based on the model of the o-system. The observed behavior,
tailored to the rate of operator actions, is described by the mixture (5.9)
f(dt|φt−1, Θ) =

c∈c∗
αcf(dt|φc;t−1, Θc, c).
Each component f(dt|φc;t−1, Θc, c) is decomposed into the product of factors
f(dic;t|ψic;t, Θic, c) (see Agreement 5.4)
f(dt|φc;t−1, Θc, c) =
 
i∈i∗
f(dic;t|ψic;t, Θic, c), i∗≡{1, . . . , ˚
d}.
The factors are parameterized by individual parameters Θic. The collection
of these parameters, together with probabilistic weights αc ∈α∗(5.9), form
the multivariate parameter Θ of the mixture. The structure of the mixture
as well as this parameter are assumed to be known throughout this chapter.
For the ﬁxed advisory system, their reliable point estimates are supposed to
be obtained during the oﬄine learning phase. For the adaptive advisory sys-
tem, the initial oﬄine estimates are permanently corrected. In both cases, the
certainty-equivalence strategy, Section 4.2.2, is adopted. Formally, parameters
are taken as known quantities and thus can be omitted in conditions.
As outlined in Chapter 5, the estimated model of the unguided o-system
provides the basic building blocks for creating the advising mixture that com-
bines them with optional elements. The optional advising elements are opti-
mized so that the resulting mixture is as close as possible to the user’s ideal

194
7 Solution and principles of its approximation: design part
pdf. The result is then oﬀered to the operator as the target to be followed.
The design is performed in the fully probabilistic sense (Section 2.4.2), i.e.;
proximity of the involved pdfs is judged via the KL divergence.
The chapter is organized as follows. Section 7.1 discusses common design
tools like evaluation of the stationary behavior of the o-system and projec-
tions of the mixture model to low-dimensional spaces as well as construction
of approximate predictors. The model, relating advices to responses of the
o-system, is reviewed in Section 7.1.3. This model is restricted to the case of
the fully cooperating operator. Then, the design part is prepared. Recursive
formulas for the optimized KL divergence and its upper bounds of a Jensen
type (2.14) are prepared in Sections 7.1.4 and 7.1.5. These feasible bounds
contain no logarithms of mixtures or their ratios and serve as the optimized
loss functions. The eﬀort spent on the approximation instead of a direct in-
vention of feasible loss functions pays back: signiﬁcant relationships between
various elements are “discovered”. This is most clear with the design of inter-
actions with the operator in the academic case. Directly chosen feasible loss
functions have failed to judge the presentation quality whenever components
of the estimated and ideal models are identical.
The design of advising strategies is addressed in Section 7.2. Academic,
industrial and simultaneous cases are distinguished; Agreements 5.6, 5.7. The
presentation of advices and evaluation of the overall state are addressed in
Section 7.3. Section 7.4 outlines validation of the design.
The basic evaluations performed in this chapter are simple. However, their
description is sometimes cumbersome due to the use of integral expressions
for expectations encountered. We prefer this way as it clearly distinguishes
quantities in conditions, quantities integrated out and those optimized.
7.1 Common tools
Here, the tools used throughout this chapter are prepared.
7.1.1 Model projections in design
Let φ be the richest state vector of the considered mixture. For its given initial
value, the time invariant mixture model deﬁnes a complete distribution of data
d(˚t). Marginal and conditional pdfs derived from it, called projections, are used
in analysis, design and exploitation of the p-system. They are discussed here.
Steady-state pdfs
Analysis of the steady-state behavior of individual, permanently active, com-
ponents serves both for the model validation, Section 6.7, and approximate
design, Section 7.2. In both cases, the steady-state moments of the quality

7.1 Common tools
195
marker are primarily judged. The choice of the marker depends on the spe-
ciﬁc application. The evaluation of the full steady state pdf described below
postpones the selection of a speciﬁc marker and thus preserves the freedom
in its choice.
Proposition 7.1 (Steady-state component)
Let a component be described by the pdf
f(dt|d(t −1)) = f(dt|dt−1, . . . , dt−∂) = f(dt|φt−1), 1 ≤∂< ∞,
(7.1)
i.e., it has the state φt−1 in the phase form φ′
t−1 = [d′
t−1, . . . , d′
t−∂, 1], Agree-
ment 5.4. Let the steady state pdf f∞(φ) ≡limt→∞f(φt = φ) exist on the
domain φ∗≡{[d′
t−1 = φ′
1, . . . , d′
t−∂= φ′
∂]′}, φk ∈d∗, k ∈{1, . . . , ∂}. Then, it
solves the equation
f∞(φ1, . . . , φ∂)
=

f

dt = φ1|φt−1 =
	
φ2, . . . , φ∂, ˜d

f∞

φ2, . . . , φ∂, ˜d

d ˜d. (7.2)
Proof. It is directly implied by the marginalization, the chain rule for pdfs,
Proposition 2.4, and by the phase form of the state.
Remark(s) 7.1
1. Proposition 7.1 provides the necessary but not suﬃcient condition for the
existence of the steady-state pdf. Thus, the solution of (7.2) has to be
checked whether it represents the steady-state pdf f∞. Also, uniqueness is
not guaranteed.
2. For static components, ∂= 0, the steady-state pdf f∞coincides with the
pdf describing the component. This makes the evaluation of individual
static components trivial. It also indicates their descriptive weakness.
Marginal and conditional pdfs
The important question is how to present the design results to the operator
in a comprehensible manner. The probabilistic description of data by condi-
tional pdfs oﬀers an eﬃcient presentation tool prepared here.
In the industrial case, Agreement 5.6, the advisory system directly pro-
vides the ideal randomized control strategy for the choice of the recognizable
actions uo;t; see Section 5.4.5. If the recognizable actions have a high dimen-
sion, marginal pdfs of the most important recognizable actions, conditioned
on the known past data, are presented to the operator. Then, it is neces-
sary to specify preference among them: either automatically, Section 7.3.1, or
manually.
Similarly, in high-dimensional cases, only selected entries of the o-innovat-
ions ∆o;t, predicted by the optimized ideal pdf, can be shown to the operator
in order to inﬂuence his actions.

196
7 Solution and principles of its approximation: design part
In both cases, predictions by the mixture model of the o-system or by
the ideal mixture model have to be done, and their relevant, low-dimensional,
marginal pdfs presented. This makes conditioning and marginalization the
universal operations needed for exploiting the mixture-based predictors.
Proposition 7.2 (Marginal and conditional pdfs of the mixture model)
Let the joint pdf of data d(˚t) be described by the known mixture model in the
factorized form
f(dt|d(t −1)) =

c∈c∗
αc
 
ι∈ι∗
f(dιc;t|d(ι+1)···˚ιc;t, φc;t−1, c)
≡

c∈c∗
αc
 
i∈i∗
f(dic;t|ψic;t, c),
where dic;t are permuted entries of dt; φc;t−1 are observable states of the in-
dividual components and ψic;t are regression vectors of respective factors.
Let dιc;t, ι ∈ι∗≡{ι1, . . . , ι˚ι} ⊂{1, . . . , ˚
d} ≡ι∗∪ι∗, ι∗∩ι∗= ∅be selected
entries of dc;t. Then, the predictor of these entries is the mixture
f(dι1···˚
ιc;t|d(t −1)) =

c∈c∗
αc
  
ι∈ι∗
f(dιc;t|d(ι+1)···˚ιc;t, φc;t−1, c) ddk∈ι∗c;t, (7.3)
where the integration is performed over the nonpredicted entries dι∗c;t ≡
{dkc;t : k ∈ι∗}.
All factors predicting dic;t with i ∈ι∗and i < min{ι ∈ι∗} integrate to
unity in (7.3). The remaining nonpredicted quantities have to be integrated
out explicitly.
Let ι∗= β∗∪γ∗, β∗∩γ∗= ∅. If β∗̸= ∅, γ∗̸= ∅, then, the predictor of
the data entries dβ∈β∗;t, conditioned on the past data d(t −1) and the data
entries dγ∈γ∗;t, is the ratio of mixtures
f(dβ1···˚
βc;t| dγ1···˚
γc;t, d(t −1))
(7.4)
=
2
c∈c∗αc
 /
ι∈ι∗f(dιc;t|d(ι+1)···˚ιc;t, φc;t−1, c) ddι∗c;t
2
c∈c∗αc
 /
ι∈ι∗f(dιc;t|d(ι+1)···˚ιc;t, φc;t−1, c) ddι∗∪β∗c;tc; t.
Proof. It is directly implied by the marginalization and the chain rules.
Remark(s) 7.2
1. Sometimes, the integrations in (7.3) or (7.4) can be approximated by in-
serting expectations of the appropriate quantities instead of the values to
be integrated out.
2. The rational form (7.4) shows clearly the need to use predictors of the
quantities with indexes in γ∗even if they are used in the condition only.

7.1 Common tools
197
3. The condition used for predicting the presented quantities contains mea-
sured values, the values proposed by the p-system and values contemplated
by the operator. The latter supports a question-and-answer mode of advis-
ing. The operator can inspect what happens if he chooses a speciﬁc value of
the selected quantity. He also can select an appropriate value of a suitable
quantity in order to move other quantities to a desired range.
7.1.2 Dynamic predictors in advising
Long-horizon predictors
Generalized Bayesian estimation, Proposition 2.13, evaluates the posterior
pdf f(Θ|d(˚t)) on unknown parameters Θ. For the ﬁxed advisory system
with the pdf f(Θ|d(0)) obtained on learning data d(0), the parameter es-
timate serves for constructing ﬁxed predictors f(dt|d(t −1)) =

f(dt|d(t −
1), Θ)f(Θ|d(0)) dΘ. They are used in the design of advices and applied to new
data dt measured in online mode. We assume that under-modelling is negligi-
ble and data are informative enough. Then, the predictors are approximated
f(dt|d(t −1)) ≈f(dt|d(t −1), ˆΘ), i.e., a point estimate ˆΘ of Θ is inserted into
the parameterized model f(dt|d(t −1), Θ).
During learning, we usually process normal operation records. Thus, in-
formation content of data may be poor. It does not harm the quality of short-
horizon predictors but may produce rather bad long-horizon predictors. It is
known that the ability to make long-term predictions signiﬁcantly inﬂuences
the quality of the design. The situation when the predictor behaves as an
unstable dynamic mapping is the worst and the most visible case of a bad
prediction, and has to be avoided. Recall that the predictor is unstable if it
has no steady-state pdf.
We have to face this problem that may occur even if all measures increasing
the information content of data and decreasing inevitable under-modelling are
exhausted. A Bayesian solution is outlined here.
Let Θ∗
s ⊂Θ∗be set of “reasonable” parameters. Typically, Θ∗
s describes
stable mappings. Prior information that parameters are expected to be “rea-
sonable” implies that support of the prior pdf f(Θ) should be reduced from
Θ∗to Θ∗
s. It does not inﬂuence evaluation of the likelihood and the “re-
stricted” posterior pdf becomes simply proportional to f(Θ|d(˚t))χΘ∗
s (Θ),
where χΘ∗
s (·) is an indicator of the set Θ∗
s. The corresponding expected value
ˆΘs ≡E

Θ|d(˚t)

is then inserted into the parameterized model. Thus, the ﬁxed
predictor gets the form f(dt|d(t−1), ˆΘs). Evaluation of ˆΘs is the only trouble
faced. Mostly, it must be done numerically. A straightforward use of Monte
Carlo is often suﬃcient (for an exception and its treatment see Section 9.1.2).
The following algorithm projects estimates on a “reasonable” set Θ∗
s.

198
7 Solution and principles of its approximation: design part
Algorithm 7.1 (Choice of dynamic predictors)
Initial (oﬄine) mode
•
Estimate the mixture model of the o-system; Chapter 6.
•
Specify the set Θ∗
s ⊂Θ∗determining meaningful dynamic predictors, for
instance, stable predictors or predictors having a given static gain.
•
Test whether the unrestricted point estimate ˆΘ of Θ belongs to Θ∗
s.
•
Set ˆΘs = ˆΘ if ˆΘ ∈Θ∗
s and stop. Otherwise, continue.
•
Select the upper bound ˚n on the number of iterations n and set n = 0.
•
Select the required number ˚
m of independent Monte Carlo samples to be
observed in Θ∗
s in order to get reliable estimate ˆΘs and set m = 0.
•
Set ˆΘs = 0; the zero matrix 0 has the same dimensions as parameter Θ.
Iterative mode
1. Do while n < ˚n & m < ˚
m.
2. Set n = n + 1.
3. Take an independent sample ˜Θ ∼f

Θ|d(˚t)

.
4. Go to Step 1 if ˜Θ /∈Θ∗
s.
5. Set ˜m = m + 1 and ˜Θs = ˆΘs + 1
˜m( ˆΘs −˜Θ).
6. Set ˆΘs = ˜Θs and m = ˜m if ˜Θs ∈Θ∗
s, continue.
7. Go to Step 1.
Accept the value ˆΘs as the ﬁnal estimate if m = ˚
m; otherwise take the evalu-
ation as unsuccessful.
Remark(s) 7.3
1. The stopping when ˆΘ ∈Θ∗
s is justiﬁed by the narrow support of the poste-
rior pdf that is expected after processing large number of data. This choice
should not be applied whenever there are doubts in this respect.
2. The algorithm relies on the ability to eﬃciently determine whether a sam-
ple ˜Θ belongs to Θ∗
s.
3. The exact Bayesian estimation is not inﬂuenced by the set Θ∗
s. The approx-
imate estimation (see Section 6.5) is generally inﬂuenced by it as the set
Θ∗
s inﬂuences one-step-ahead predictors used for weighting of the processed
data. We conjecture that this inﬂuence can be neglected if one-step-ahead
predictions are good. This conjecture is supported by experimental results.
4. The test whether the updated sample mean ˆΘs belongs to Θ∗
s is generally
necessary as Θ∗
s need not be a convex set.
5. The portion of Monte Carlo samples falling into Θ∗
s may be rather small.
Then, the way thay are generated has to be modiﬁed. In Section 9.1.2, an
instance of this situation is described.

7.1 Common tools
199
Approximation of dynamic predictors
Discussion in Section 5.3 has shown that dynamic mixtures with data-
dependent weights cannot be yet eﬃciently used. In the same section, a univer-
sal approach has been proposed that overcomes drawbacks of mixtures with
constant weights. This solution requires, however, at least n-times (grouping
rate n > 1; see Proposition 5.3) more evaluations than the standard estima-
tion. Here, a generally applicable approximation is proposed that covers cases
when a component is active for relatively long time intervals.
In Section 5.3, the data-dependent component weights ˜αc(d(t −1), Θ) are
interpreted through a projection and approximation of a more complex param-
eterized model. Alternatively, ˜αc(d(t −1), Θ) can be seen as the probability
that the data vector Ψt, Agreement 5.4, belongs to a set Ψ ∗
c on which the
cth component is the best approximation of the “objective” system descrip-
tion, cf.; Chapter 2. It is also the probability that the pointer ct = c. This
probability is evaluated during the approximate estimation and found to be
proportional to αcf(dt|d(t −1), c), cf.; Section 6.5. Thus, we know it after
observing Ψt.
For the discussed case, which properly models a rich class of applications,
we can and will assume that
Ψt ∈Ψ ∗
c with a high probability if Ψt−1 ∈Ψ ∗
c .
(7.5)
This assumption leads to the following approximate dynamic predictor
f(dt|d(t −1)) =

c∈c∗
wc(d(t −1))f(dt|d(t −1), c) with
(7.6)
wc(d(t −1)) ≡
αcf(dt−1|d(t −2), c)
2
˜c∈c∗α˜cf(dt−1|d(t −2), ˜c).
This is a simple and eﬃcient dynamic predictor that, however, can be suc-
cessful only when condition (7.5) is met.
7.1.3 Advices and their inﬂuence
We repeat the classiﬁcation of actions of the p-system with an extended pre-
sentation of the adopted models of their inﬂuence; see Chapter 5. Recall that
the superscript ⌊I distinguishes the optimized elements.
Agreement 7.1 (Advices and their inﬂuence) Advices, i.e., the actions
of the p-system, are
ap;t ≡(ct, uo;t, zt, st).
(7.7)
The individual entries have the following interpretation.

200
7 Solution and principles of its approximation: design part
•
Recommended pointers ct ∈c∗to active components are actions in the
academic design. With them, the optimized ideal pdf is
⌊If(dt, ct|d(t −1)) ≡f(dt|d(t −1), ct) ⌊If(ct|d(t −1)).
(7.8)
In (7.8), the pdfs

f(dt|d(t −1), ct) ≡f(dt|d(t −1), ˆΘct, ct)

t∈t∗
describe the ctth component of the estimated o-model. The point esti-
mate ˆΘ, based on oﬄine data, replaces the unknown component param-
eters Θc in the parameterized component model.The collection of pdfs
 ⌊If(ct|d(t −1))

t∈t∗describes the optimized academic strategy generat-
ing the recommended pointers {ct}t∈t∗. The ideal pdf communicated to the
operator has the form
⌊If(do;t|d(t −1)) =

ct∈c∗
⌊If(ct|d(t −1))f(do;t|d(t −1), ct), t ∈t∗. (7.9)
The pdf f(do;t|d(t −1), ct) is the marginal pdf of the joint f(dt|d(t −1), ct)
reduced on the o-data do;t.
•
Recommended recognizable actions uo;t ∈u∗
o guide the operator in select-
ing recognizable actions. The advising strategy
 ⌊If(uo;t|d(t −1))

t∈t∗in-
ﬂuences the constructed ideal diﬀerently for industrial and simultaneous
designs.
–
Industrial design assumes that the component weights f(ct|d(t−1)) are
ﬁxed either at learned values αct or at values ⌊If(ct|d(t −1)) resulting
in the preceding academic design. The optimized ideal pdf is
⌊If (dt|d(t −1))
≡⌊If(uo;t|d(t −1))f(∆t|uo;t, d(t −1)) = ⌊If(uo;t|d(t −1))(7.10)
×
2
ct∈c∗f(ct|d(t −1))f(∆t|uo;t, d(t −1), ct)f(uo;t|d(t −1), ct)
2
ct∈c∗f(ct|d(t −1))f(uo;t|d(t −1), ct)
.
The pdfs f(∆t|uo;t, d(t−1), c), f(uo;t|d(t−1), c) are marginal pdfs of the
estimated cth component. The ideal pdf communicated to the operator
is then the marginal pdf reduced on the o-data
⌊If(do;t|d(t −1)) = ⌊If(uo;t|d(t −1))
(7.11)
×
2
ct∈c∗f(ct|d(t −1))f(∆o;t|uo;t, d(t −1), ct)f(uo;t|d(t −1), ct)
2
ct∈c∗f(ct|d(t −1))f(uo;t|d(t −1), ct)
.
–
Simultaneous design selects the joint strategy
 ⌊If(ct, uo;t|d(t −1))

t∈t∗.
The joint optimization allows us to make the recommended recognizable
actions uo;t dependent on the recommended pointer ct. It simpliﬁes the
optimized model to

7.1 Common tools
201
⌊If(dt, ct|d(t−1)) = f(∆t|uo;t, d(t−1), ct) ⌊If(ct, uo;t|d(t−1)). (7.12)
The conditional pdf f(∆t|uo;t, d(t −1), ct) is derived from the cth esti-
mated component f(dt|d(t −1), ct). The corresponding ideal pdf com-
municated to the operator becomes
⌊If(do;t|d(t −1)) =

ct∈c∗
f(∆o;t|uo;t, d(t −1), ct) ⌊If(ct, uo;t|d(t −1)).
(7.13)
•
Priority actions zt ∈z∗consist of a ˚z−vector (˚z ≤˚
do) of diﬀerent indexes
zk;t ∈{1, . . . , ˚
do}, k ∈{1, . . .˚z}; zt selects entries of do;t to be shown
to the operator. Given the ideal pdf
⌊If(ct, uo;t|d(t −1)) describing the
recommended pointers ct and the recommended recognizable actions uo;t,
the vectors of priority actions zt are generated by the optimized strategy
 ⌊If(zt|d(t −1))

t∈t∗. The priority actions are supposed to deﬁne the op-
timized ideal pdf
⌊If(dt|zt, d(t −1)) = f(d¯zt;t|dzt;t, d(t −1)) ⌊If(dzt;t|d(t −1))
= f(dt|d(t −1))
⌊If(dzt;t|d(t −1))
f(dzt;t|d(t −1)) .
(7.14)
In (7.14), d¯zt;t denotes entries of dt not presented to the operator. The
pdf f(dt|d(t −1)) is the estimated mixture, the pdf f(dzt;t|d(t −1)) is its
marginal pdf on d∗
zt;t (also mixture!). The pdf
⌊If(dzt;t|d(t −1)) is the
marginal pdf of the ideal pdf designed in academic, industrial or simulta-
neous design. The ideal pdf presented to the operator is ⌊If(dˆzt;t|d(t −1)),
where the pointer ˆzt to the shown entries dˆzt;t is a sample from ⌊If(zt|d(t−
1)).
•
Signaling actions st ∈s∗≡{0, 1} stimulate the operator to take appropri-
ate measures when behavior of the o-system signiﬁcantly diﬀers from the
desired one. These actions, when respected by the operator, modify the be-
havior of the unguided o-system f(dt|st = 0, d(t−1)) ≡f(dt|d(t−1)) to the
behavior described by the ideal pdf f(dt|st = 1, d(t −1)) ≡⌊If(dt|d(t −1)).
The ideal pdf
⌊If(dt|d(t −1)) arises from the academic, industrial or si-
multaneous design of the p-system. The optimized ideal pdf has the form
⌊If(dt, st|d(t −1)) = ⌊If(dt|st, d(t −1)) ⌊If(st|d(t −1)),
(7.15)
where the probabilities
 ⌊If(st|d(t −1))

t∈t∗describe the signaling strat-
egy. These optimized probabilities are presented to the operator. Typically,
the probability
⌊If(st = 1|d(t −1)) is converted into a traﬃc-light color
that reﬂects the degree of the need for operator actions.
The above items determine the overall model of the connection of the o-system
and p-system.

202
7 Solution and principles of its approximation: design part
Remark(s) 7.4
The proposed model is used for designing the optimized advices and assumes
the fully cooperating operator. It would be desirable to model an imperfect co-
operation of a real operator. Yet, we have found no simple, suﬃciently univer-
sal, way to do that. The behavior of the guided system seems to be reasonably
robust to the degree of cooperation as extensive experiments indicate.
Problem 7.1 (Real operator) An active correction for a real operator that
modiﬁes the recommended strategy can be achieved by extending the adaptive
advisory system. Such an extended system has to relate explicitly response of
the guided o-system on advices. This is a feasible but nontrivial possibility.
At present, we can just passively check whether the operator cooperates: the
proposed guided model is expected to provide a higher v-likelihood than the
unguided model of the o-system. At least this test should be implemented in
the online use of the advisory system.
7.1.4 Fully probabilistic design in advising
The fully probabilistic design, Proposition 2.11, makes the conceptual frame-
work we follow. It requires an additional inspection of the KL divergence that
serves us as the loss function. It is done here.
Let us split the p-data into the p-innovations ∆t and the p-actions at
d(˚t) ≡dp(˚t) ≡(do(˚t), dp+(˚t)) = (∆o(˚t), a(˚t), ∆p+(˚t)).
Innovation entries ∆o belong to the o-data space and ∆p+ to the surplus data
space of the p-system.
A recursive expression of the KL divergence for a ﬁxed advising strategy
suits for initializations of the design and for checking its results. It is described
by the following proposition, which is a simpliﬁed version of Proposition 2.11.
Proposition 7.3 (Recursive evaluation of the KL divergence)
The
KL divergence of the pdfs ⌊If(d(˚t)) and ⌊Uf(d(˚t)) can be expressed as follows.
D

⌊If(d(˚t))
!!!
!!! ⌊Uf(d(˚t))

= E

t∈t∗
ω(d(t −1))

,
(7.16)
where the conditional KL divergence
ω(d(t −1)) ≡

⌊If(dt|d(t −1)) ln
 ⌊If(dt|d(t −1))
⌊Uf(dt|d(t −1))

ddt.
The value of the KL divergence D
 ⌊If(d(˚t))
!!!! ⌊Uf(d(˚t))

≡−ln(γ(d(0))) is
generated recursively for t = ˚t,˚t −1, . . . , 1, as follows.
−ln(γ(d(t −1)))
≡E [ωγ(d(t))|d(t −1)] ≡

⌊If(dt|d(t −1)) ln

⌊If(dt|d(t −1))
γ(d(t)) ⌊Uf(dt|d(t −1))

ddt,

7.1 Common tools
203
where the weighted conditional KL divergence is deﬁned by
ωγ(d(t −1)) ≡

⌊If(dt|d(t −1)) ln

⌊If(dt|d(t −1))
γ(d(t)) ⌊Uf(dt|d(t −1))

ddt.
The terminal value is γ(d(˚t)) ≡1.
Proof. It holds
D

⌊If(d(˚t))
!!!
!!! ⌊Uf(d(˚t))

≡

⌊If(d(˚t)) ln
 ⌊If(d(˚t))
⌊Uf(d(˚t))

dd(˚t)
=

chain rule

⌊If(d(˚t))

t∈t∗
ln
 ⌊If(dt|d(t −1))
⌊Uf(dt|d(t −1))

dd(˚t)
=

linearity, marginalization
chain rule, Fubini theorem
=

t∈t∗

⌊If(d(t −1))

⌊If(dt|d(t −1)) ln
 ⌊If(dt|d(t −1))
⌊Uf(dt|d(t −1))

ddt



ω(d(t−1))
dd(t −1)



E[ω(d(t−1))]
.
Deﬁning
−ln(γ(d(t −1))) ≡E
⎡
⎣
˚t

τ=t
ω(d(τ))
!!!!!!
d(t −1)
⎤
⎦
⇒

chain rule for E
−ln(γ(d(t −1))) ≡E [ω(d(t)) −ln(γ(d(t)))|d(t −1)]
≡

deﬁnition of ωγ
≡E [ωγ(d(t))|d(t −1)]
⇒

E[·]≡E[·|d(0)]
D

⌊If
!!!
!!! ⌊Uf

= −ln(γ(d(0))).
The ideal pdf ⌊If(d(˚t)) ≡⌊If(∆(˚t), a(˚t)) is constructed so that it reﬂects
managing objectives expressed by the true user’s ideal pdf ⌊Uf(do;t|do(t−1)),
extended on d∗
t by the pdf ⌊If(dp+;t|d(t −1)) as discussed in Section 5.1.5,
⌊Uf(d(˚t)) ≡

(5.7)
 
t∈t∗
⌊Uf(∆o;t|do(t −1)) ⌊If(∆p+;t|at, d(t −1)) ⌊Uf(at|d(t −1)).
(7.17)
This extension expresses
•
lack of information (interest) of the operator concerning data out of d∗
o;
•
the user’s wishes with respect to advices at. They are either given by
the true user’s ideal pdf if at = uo;t = recognizable actions or speciﬁed
by ⌊Uf(at|d(t −1)) employed as a tuning knob of the design. Stability of
advices is a typical implicit operator’s wish respected with the help of this
design knob.

204
7 Solution and principles of its approximation: design part
The special form (7.17) of the user’s ideal pdf
⌊Uf(d(˚t)) leads to a special
form of Proposition 2.11.
Proposition 7.4 (Fully probabilistic design with a special target)
Let the joint pdf
⌊If(d(˚t)) ≡⌊If(∆(˚t), a(˚t)) ≡
 
t∈t∗
f(∆t|at, d(t −1)) ⌊If(at|d(t −1))
be inﬂuenced by the optional strategy
 ⌊If(at|d(t −1))

t∈t∗.
Let the innovations ∆t = (∆o;t, ∆p+;t) be split into the part ∆o;t belonging
to the data space of the operator and the part ∆p+;t belonging to the surplus
data space of the advisory system. Then, the optimal strategy, minimizing the
KL divergence
D

⌊If
!!!
!!! ⌊Uf

≡

⌊If(∆(˚t), a(˚t)) ln

⌊If(∆(˚t), a(˚t))
⌊Uf(∆(˚t), a(˚t))

d(∆(˚t), a(˚t))
to the user’s ideal pdf ⌊Uf(d(˚t)) (7.17), has the form
⌊If(at|d(t −1)) = ⌊Uf(at|d(t −1))exp[−ωγ(at, d(t −1))]
γ(d(t −1))
,
where
(7.18)
γ(d(t −1)) ≡

⌊Uf(at|d(t −1)) exp[−ωγ(at, d(t −1))] dat
ωγ(at, d(t −1)) ≡

f(∆t|at, d(t −1)) ln

f(∆o;t|∆p+;t, at, d(t −1))
γ(d(t)) ⌊Uf(∆o;t|at, do(t −1))

d∆t
γ(d(˚t)) = 1.
The solution is performed against the time course, starting at t = ˚t.
Proof. Comparing to Proposition 2.11, the main change concerns the deﬁni-
tion of the function ωγ(at, d(t −1)). It is implied directly by the assumption
(7.17). Other changes are just typographical. The target pdf is distinguished
by the superscript
⌊U, the optimized one by
⌊I and experience is explicitly
expressed in terms of the observed p-data d(t −1).
7.1.5 Approximations of the KL divergence
Some predictors forming the optimized pdf ⌊If(d(˚t)) are mixtures. This makes
evaluation of the KL divergence D
 ⌊If
!!!! ⌊Uf

and consequently the applica-
tion of Proposition 7.4 hard. To avoid this trouble, we use Jensen-type in-
equalities (2.14) for ﬁnding an upper bound on this divergence. It gives us a
chance to optimize at least such an upper bound.

7.1 Common tools
205
Proposition 7.5 (The J divergence of a mixture f to ⌊Uf) Let us con-
sider the joint pdf on observed data d(˚t) ∈d∗(˚t)
f(d(˚t)) ≡
 
t∈t∗

c∈c∗
αc;tf(dt|d(t −1), c),
where the components f(dt|d(t −1), c) as well as their probabilistic weights
αc;t, possibly dependent on d(t −1), are known. Let ⌊Uf(d(˚t)) be another pdf
on the same data space d∗(˚t). Then, the following inequality holds
D

f
!!!
!!! ⌊Uf

≤J

f
!!!
!!! ⌊Uf

≡E
"
t∈t∗
ω(d(t −1))
%
ω(d(t −1)) ≡

c∈c∗
αc;tω(c, d(t −1))
(7.19)
ω(c, d(t −1)) ≡

f(dt|d(t −1), c) ln
 f(dt|d(t −1), c)
⌊Uf(dt|d(t −1))

ddt ≥0.
The Jensen divergence (J divergence) J

f
!!!! ⌊Uf

is
•
nonnegative,
•
equal to zero iﬀf(dt|d(t −1), c) = ⌊Uf(dt|d(t −1)) a.s. for all those t ∈t∗
and c ∈c∗for which αc;t ̸≡0,
•
inﬁnite iﬀfor some t ∈t∗and c ∈c∗the pdf ⌊Uf(dt|d(t −1)) = 0 and the
pdf f(dt|d(t−1), c) > 0 on a subset of d∗of a positive dominating measure
while αc;t ̸≡0 on this subset.
Proof. The the chain rule and deﬁnition of the KL divergence, Proposition
2.10, imply
D (f|| ⌊Uf

=

t∈t∗

f(d(t −1))
#
f(dt|d(t −1)) ln
 f(dt|d(t −1))
⌊Uf(dt|d(t −1))

ddt
$
dd(t −1).
For a given d(t −1), the inner integration over d∗
t concerns the function
f(dt|d(t −1)) ln
 f(dt|d(t −1))
⌊Uf(dt|d(t −1))

=

c∈c∗
αc;tf(dt|d(t −1), c) ln
0
c∈c∗
αc;tf(dt|d(t −1), c)
1
−

c∈c∗
αc;tf(dt|d(t −1), c) ln

⌊Uf(dt|d(t −1))

≤

(2.14)

c∈c∗
αc;tf(dt|d(t −1), c) ln(f(dt|d(t −1), c))

206
7 Solution and principles of its approximation: design part
−

c∈c∗
αc;tf(dt|d(t −1), c) ln

⌊Uf(dt|d(t −1))

=

c∈c∗
αc;tf(dt|d(t −1), c) ln
 f(dt|d(t −1), c)
⌊Uf(dt|d(t −1))

.
Integration of this inequality over d∗
t and the deﬁnitions of ω(d(t −1)) and
ω(c, d(t−1)) imply (7.19). The non-negativity of ω(d(t−1)) is obvious as, for
any ﬁxed d(t −1), it is a convex combination of the nonnegative conditional
KL divergences ω(c, d(t−1)). Remaining properties of the J divergence follow
from its form and properties of the KL divergence, Proposition 2.10.
The inequality (7.19) between the KL and J divergences is proved for the
mixture model. We have to deal with the ratio of mixture models, Proposition
7.4, whenever the surplus data space d∗
p+;t of the p-system is nonempty and
the special form of the user’s ideal pdf (7.17) is used. The inequality (7.19)
can be extended to this case, too.
Proposition 7.6 (J divergence of a pdf f to ⌊Uf (7.17)) Let us consi-
der the joint pdf on observed data d(˚t) ∈d∗(˚t), dt = (do;t, dp+;t) with a non-
trivial part dp+;t belonging to the surplus data space of the advisory system.
Let us assume that
f(d(˚t)) ≡
 
t∈t∗

c∈c∗
αc;tf(dt|d(t −1), c),
where the components f(dt|d(t −1), c) as well as their probabilistic weights
αc;t, possibly dependent on d(t −1), are known. Let
⌊Uf(d(˚t)) =
 
t∈t∗
⌊Uf(do;t|do(t −1))

c∈c∗
αc;tf(dp+;t|d(t −1), c)
be the pdf deﬁning the extended user’s ideal pdf (7.17). Let for some constant
K ≥1 and some pdf g(dp+;t|d(t −1)) hold
f(dp+;t|d(t −1), c) ≤Kg(dp+;t|d(t −1)), ∀c ∈c∗and almost all data involved.
(7.20)
Then, the following inequality holds
D

f
!!!
!!! ⌊Uf

≤J

f
!!!
!!! ⌊Uf

+ ln(K) with
J

f
!!!
!!! ⌊Uf

≡E
"
t∈t∗
ω(d(t −1))
%
(7.21)
ω(d(t −1)) ≡

c∈c∗
αc;tω(c, d(t −1))
ω(c, d(t −1)) ≡

f(dt|d(t −1), c) ln
f(do;t|dp+;t, d(t −1), c)
⌊Uf(do;t|do(t −1))

ddt ≥0.

7.1 Common tools
207
Proof. Use of the chain rule for expressing the KL divergence implies that we
have to inspect the diﬀerence

t∈t∗
E
"
c∈c∗
αc;t

f(dt|d(t −1), c)
×
#
ln

2
˜c∈c∗α˜c;tf(dt|d(t −1), ˜c)
2
˜c∈c∗α˜c;tf(dp+;t|d(t −1), ˜c) ⌊Uf(do;t|do(t −1))

−
ln

Kf(dt|d(t −1), c)
f(dp+;t|d(t −1), c) ⌊Uf(do;t|do(t −1))
$
ddt

≤

(2.14)

t∈t∗,c∈c∗
E

αc;t

f(dt|d(t −1), c)
×
ln

f(dp+;t|d(t −1), c)
K 2
˜c∈c∗α˜c;tf(dp+;t|d(t −1), ˜c)

ddt

≤

(7.20)

t∈t∗
E
"
c∈c∗
αc;t

f(dt|d(t −1), c) ln

g(dp+;t|d(t −1))
2
˜c∈c∗α˜c;tf(dp+;t|d(t −1), ˜c)

ddt
%
=
−

t∈t∗
E
"
c∈c∗
αc;t

f(dt|d(t −1), c)
×
ln
2
˜c∈c∗α˜c;tf(dp+;t|d(t −1), ˜c)
g(dp+;t|d(t −1))

ddt

=
−

t∈t∗
E
"
D
0
c∈c∗
αc;tf(dp+;t|d(t −1), c)||g(dp+;t|d(t −1))
1%
≤

−D(·)≤0
0.
In the industrial design and when designing presentation priorities, the
KL divergences of more general ratios of ﬁnite mixtures to a given pdf are in-
spected. The following proposition shows how to approximate such distances.
Proposition 7.7 (The J divergence of a mixture ratio ⌊If to ⌊Uf)
Let us consider the mixture
f(x, y) =

c∈c∗
αcf(x, y|c)
on quantities x, y given by known components f(x, y|c) and their probabilis-
tic weights αc, c ∈c∗. Its marginal pdf is f(y) = 2
c∈c∗αcf(y|c). Let
⌊Uf(x, y), ⌊If(y) be given pdfs. Then, for
⌊If(x, y) ≡f(x, y) ⌊If(y)
f(y)

208
7 Solution and principles of its approximation: design part
D

⌊If
!!!
!!! ⌊Uf

≡
 f(x, y) ⌊If(y)
f(y)
ln
 f(x, y) ⌊If(y)
f(y) ⌊Uf(x, y)

dxdy
≤

⌊If(y)
#
ln
 ⌊If(y)
⌊Uf(y)

+ ω(y)
$
dy
ω(y) ≡

c∈c∗
f(c|y)
#
ω(c, y) + ln
f(c|y)
αc
$
,
where
(7.22)
ω(c, y) ≡

f(x|y, c) ln
 f(x|y, c)
⌊Uf(x|y)

dx and f(c|y) ≡
αcf(y|c)
2
c∈c∗αcf(y|c).
Proof. It holds that
D

⌊If
!!!
!!! ⌊Uf

≡
 f(x, y) ⌊If(y)
f(y)
ln
 f(x, y) ⌊If(y)
f(y) ⌊Uf(x, y)

dxdy
≤

(2.14)

c∈c∗
αc
 f(x, y|c)
f(y)
⌊If(y) ln
f(x, y|c) ⌊If(y)
f(y) ⌊Uf(x, y)

dxdy
=

chain rule
marginalization
f(y) = 2
c∈c∗αcf(y|c)
=

⌊If(y) ln
 ⌊If(y)
⌊Uf(y)

dy +

c∈c∗

⌊If(y) αcf(y|c)
f(y)



f(c|y)
ln
αcf(y|c)
f(y)αc

dy
+

c∈c∗

⌊If(y)f(c|y)

f(x|y, c) ln
 f(x|y, c)
⌊Uf(x|y)

dx



ω(c,y)≥0
dy.
Problem 7.2 (Bounds on the KL divergence of mixture ratio) There
are surely variants of the derived upper bound. The problem should be inspected
further on in order to get tighter upper bounds while preserving the possibility
of evaluating them at least for normal and Markov mixtures.
The approximations discussed up to now counteract evaluation problems
caused by the form of the adopted models: the KL divergence is evaluated for
mixtures or their ratios. The found bounds overcome them. In the adopted
fully probabilistic design, Proposition 7.4, we have to evaluate two functions
γ(d(t)) and ωγ(d(t)); see (7.18). This brings additional problems and calls for
additional approximations. They are prepared here.
We search for an upper bound in order to guarantee that the strategy
minimizing it bounds the KL divergence of interest.
We bound ﬁrst the function γ(d(t)). The Bellman function of the solved
design is −ln(γ(t)); thus, if we ﬁnd the lower bound on γ(d(t)), we get the
desired upper bound on it. This result we call the γ-bound.

7.1 Common tools
209
Proposition 7.8 (The γ-bound) Let ⌊Uf(at+1|d(t)) be a given pdf on a∗
t+1
and ωγ(at+1, d(t)) ≥0 be such a function that
ωγ(d(t)) ≡

ωγ(at+1, d(t)) ⌊Uf(at+1|d(t)) dat+1 < ∞a.s. on d∗(t).
Then,
(7.23)
γ(d(t)) ≡

⌊Uf(at+1|d(t)) exp[−ωγ(at+1, d(t))] dat+1 ≥exp[−ωγ(d(t))] > 0.
Proof. For ﬁxed d(t), γ(d(t)) ≡E[exp(−ω(·, d(t)))|d(t)]. exp(−ω(·, d(t))) is
a convex function of the argument ω. Thus, The Jensen inequality (2.14) is
directly applicable. It gives the lower bound searched for. Its positivity is
implied by the assumed ﬁniteness of ωγ(d(t)).
The estimate (7.23) can be reﬁned if the considered actions have a ﬁ-
nite number of possible values. It is the case of advices restricted to a∗⊂
(c∗, z∗, s∗); cf. Agreement 7.1. Essentially, bounds on individual functions
ωγ(at+1, d(t)), at+1 ∈a∗are constructed. These bounds lead to the upper
bound on −ln(γ(d(t −1))). The corresponding bound is called the ω-bound.
Proposition 7.9 (The ω-bound) For ˚a < ∞and t = ˚t,˚t −1, . . . , 1, let us
consider sequence functions, cf. (7.18),
γ(d(t)) ≡

at+1∈a∗
⌊Uf(at+1|d(t)) exp[−ωγ(at+1, d(t))]
ωγ(at, d(t −1)) ≡
≡

f(∆t|at, d(t −1)) ln

f(∆o;t|∆p+;t, at, d(t −1))
γ(d(t)) ⌊Uf(∆o;t|at, do(t −1))

d∆t
≡

f(∆t|at, d(t −1)) ln
f(∆o;t|∆p+;t, at, d(t −1))
⌊Uf(∆o;t|at, do(t −1))

d∆t



ω(at,d(t−1))
−

f(∆t|at, d(t −1)) ln(γ(d(t))) d∆t



q(at,d(t−1))
.
The last decomposition separates the inﬂuence of γ(d(t)) on ωγ(at, d(t −1)).
The ﬁrst member of the sequence is ω(a˚t, d(˚t −1)) ≡ωγ≡1(a˚t, d(˚t −1)).
For ﬁxed t, d(t −1), at, let us select arbitrary at+1 ≡aat ∈a∗and let us
deﬁne
˜ωγ(at, d(t −1)) ≡ω(at, d(t −1))
+

f(∆t|at, d(t −1)) ln

⌊Uf(aat|d(t)) exp[−˜ωγ(aat, d(t))]

d∆t
with zero second term for t = ˚t. Then, ∀t ∈t∗,

210
7 Solution and principles of its approximation: design part
−ln[γ(d(t))] ≡−ln
⎡
⎣
at+1∈a∗
⌊Uf(at+1|d(t)) exp[−ωγ(at+1, d(t))]
⎤
⎦
≤−ln[˜γ(d(t))] ≡−ln
⎡
⎣
at+1∈a∗
⌊Uf(at+1|d(t)) exp[−˜ωγ(at+1, d(t))]
⎤
⎦.
(7.24)
Proof. Let us consider, for ﬁxed d(t −1), at, the second term q(at, d(t −1))
in the expression for ωγ(at, d(t −1)) that depends on γ(d(t)).
By deﬁnition, γ(d(t)) is a superposition of nonnegative terms. Omitting
all of them except one, we get the lower bound on q(at, d(t−1)). Thus, for an
arbitrary ﬁxed at+1 ≡aat ∈a∗,
ωγ(at, d(t −1)) ≡ω(at, d(t −1)) −q(at, d(t −1)) ≤ω(at, d(t −1))
−

f(∆t|at, d(t −1)) ln

⌊Uf(aat|d(t)) exp[−ωγ(aat, d(t))]

d∆t
≡˜ω(aat, d(t −1)).
Using the deﬁnition of γ(d(t −1)), we get
−ln(γ(d(t −1))) ≡−ln

at
⌊Uf(at|d(t −1)) exp[−ωγ(at, d(t −1)]

≤−ln
"
at
⌊Uf(at|d(t −1) exp [−˜ω(at, d(t −1))]
%
.
Thus, the use of the derived upper bound on a particular ωγ(at+1, d(t)) for
the deﬁnition of ωγ(at, d(t −1)) guarantees that we get the upper bound on
the Bellman function at time t −1. For t = ˚t, inequality is guaranteed by the
common starting condition γ(d(˚t)) = 1.
It remains to determine on a proper choice of aat to get the tight version
of the derived ω-bound. This decision is speciﬁc for the speciﬁc model and
design type.
7.2 Design of advising strategies
7.2.1 Academic design
The recommended pointers ct ∈c∗to mixture components form the actions of
the academic p-system. They are generated by a causal strategy d∗(t −1) →
ct ∈c∗described by pfs
 ⌊If(ct|d(t −1))

t∈t∗. The strategy determines the
optimized ideal pdfs
⌊If(dt, ct|d(t −1)) = f(dt|d(t −1), ct) ⌊If(ct|d(t −1)).

7.2 Design of advising strategies
211
The extended user’s ideal pdf, Section 5.1.5, has the form
⌊Uf(d(˚t), c(˚t)) =
 
t∈t∗
⌊Uf(do;t|do(t −1)) ⌊If(dp+;t|d(t −1), ct) ⌊Uf(ct|d(t −1)).
(7.25)
The user’s ideal pf ⌊Uf(ct|d(t −1)) is assumed to have support that excludes
dangerous components; see Agreement 5.9 and Section 7.1.1. If a single non-
dangerous component remains, the optimal design of the academic p-system
is solved by this exclusion. The optimal advising strategy has to be searched
for if several nondangerous components exist.
Proposition 7.10 (Academic fully probabilistic design) Let us consi-
der the design of the academic advisory system with actions ct ∈c∗restricted
to those indexes in c∗that point to the nondangerous components only. Let us
search for the optimal causal advising strategy d∗(t −1) →ct ∈c∗minimizing
the KL divergence of
⌊If(d(˚t), c(˚t)) to the user’s ideal pdf
⌊Uf(d(˚t), c(˚t)) as
given in (7.25). Then, this strategy is given by the following formulas, solved
for t = ˚t,˚t −1, . . . , 1,
⌊If(ct|d(t −1)) = ⌊Uf(ct|d(t −1))exp[−ωγ(ct, d(t −1))]
γ(d(t −1))
,
where
(7.26)
γ(d(t −1)) ≡

ct∈c∗
⌊Uf(ct|d(t −1)) exp[−ωγ(ct, d(t −1))]
ωγ(ct, d(t −1)) ≡

f(dt|d(t −1), ct) ln
 f(do;t|dp+;t, d(t −1), ct)
γ(d(t)) ⌊Uf(do;t|do(t −1))

ddt
γ(d(˚t)) = 1.
The needed pdf f(do;t|dp+;t, d(t −1), c) is the conditional pdf of the cth com-
ponent f(dt|d(t −1), c) obtained in learning the o-system.
Proof. The proposition coincides with Proposition 7.4, see (7.18), for dt ≡∆t
and the speciﬁc choice of actions of the p-system and their assumed inﬂuence
(7.8) on the resulting ideal pdf.
The above proposition, combined with the receding-horizon certainty-
equivalence strategy, justiﬁes the following algorithm written for the state
description with the state φ.
Algorithm 7.2 (Academic advising optimizing KL divergence)
Initial (oﬄine) mode
•
Estimate the mixture model of the o-system with the state φt; Chapter 6.
•
Evaluate the steady-state behaviors of individual components; Section 7.1.1.
•
Exclude dangerous components; Agreement 5.9.
•
Return to the learning phase if all components are dangerous.
•
Take the nondangerous component as the ideal pdf oﬀered to the operator
and stop if ˚c = 1.

212
7 Solution and principles of its approximation: design part
•
Specify the user’s ideal pdf
⌊Uf(do;t|do(t −1)) ≡
⌊Uf(do;t|φt−1) on the
response of the o-system.
•
Specify the user’s ideal pdf ⌊Uf(ct|d(t −1)) ≡⌊Uf(ct|φt−1) on the recom-
mended pointers ct to the nondangerous components.
•
Select the length of the receding horizon T ≥1.
Online (sequential) mode, running for t = 1, 2, . . .
1. Acquire the data record dt and determine the state vector φt.
2. Update the estimates of the model parameters if you deal with the adaptive
advisory system.
3. Initialize the iterative mode by setting τ = t + T and γ(φτ) = 1.
Iterative mode
a) Evaluate the functions
ωγ(cτ, φτ−1) ≡

f(dτ|φτ−1, cτ) ln
f(do;τ|dp+;τ, φτ−1, cτ)
γ(φτ) ⌊Uf(do;τ|φτ−1)

ddτ, cτ ∈c∗,
γ(φτ−1) ≡

cτ ∈c∗
⌊Uf(cτ|φτ−1) exp[−ωγ(cτ, φτ−1)].
(7.27)
b) Continue if τ = t + 1. Otherwise decrease τ = τ −1 and go to Step
3a.
4. Evaluate the advising strategy
⌊If(ct+1|φt) = ⌊Uf(ct+1|φt)exp[−ωγ(ct+1, φt)]
γ(φt)
;
cf. (7.26).
5. Present to the operator projections of the ideal pdf (advisory mixture)
⌊If(do;t+1|φt) =

ct+1∈c∗
f(do;t+1|φt, ct+1) ⌊If(ct+1|φt),
where the pdf f(do;t+1|φt, ct+1) is marginal pdf of the cth estimated com-
ponent f(dt+1|φt, ct+1).
6. Go to the beginning of Sequential mode.
Remark(s) 7.5
1. The quasi-Bayes or quasi-EM algorithms, Section 6.5, possibly with the
stabilized forgetting, Section 3.1, are suited for the online updating of the
mixture model.
2. Other approximate strategies than the certainty-equivalence one are pos-
sible; see Section 4.2. They are not elaborated in this text.
3. Presentation of the design results is discussed in Section 7.3.1.
Feasibility of Algorithm 7.2 depends on our ability to evaluate functions
ωγ(·) and γ(·). It is hard even for normal and Markov mixtures due to the
additive form (7.27) determining γ(·). In order to simplify the situation, we
can use the freedom in the choice of the user’s ideal pdf for advising actions
⌊Uf(ct+1|φt).

7.2 Design of advising strategies
213
Proposition 7.11 (Academic design and the most probable advices)
Let us consider the design of the academic advisory system with actions ct ∈c∗
restricted to those indexes in c∗that point to the nondangerous components
only. Let us search for the optimal causal advising strategy d∗(t −1) →
ct ∈c∗that minimizes the KL divergence of
⌊If(d(˚t), c(˚t)) to the user ideal
⌊Uf(d(˚t), c(˚t)) (7.25). The obtained minimum depends on the used ideal prob-
abilities
 ⌊Uf(ct|d(t −1))

t∈t∗. Let us select these probabilities so that the
minimum reached is the smallest one. Then, the optimal advising strategy is
the deterministic feedback recommending the component with the index
⌊Ict ∈Arg min
ct∈c∗ωγ(ct, d(t −1))
(7.28)
ωγ(ct, d(t −1)) ≡

f(dt|d(t −1), ct)
× ln

f(do;t|dp+;t, d(t −1), ct)
exp(−ωγ( ⌊Ict+1, d(t))) ⌊Uf(do;t|do(t −1))

ddt
ωγ

⌊Ic˚t+1, d(˚t)

= 0.
The pdf f(do;t|dp+;t, d(t −1), ct) is the conditional pdf of the cth component
f(dt|d(t −1), ct) obtained by learning the mixture model of the o-system.
The chosen action selects the most probable academic advises among those
given by Proposition 7.2.
Proof. The complexity of the academic design described by Proposition 7.2
stems from complexity of the Bellman function that equals to −ln(γ(d(t)))
with
γ(d(t)) ≡

ct+1∈c∗
⌊Uf(ct+1|d(t)) exp[−ωγ(ct+1, d(t))]
ωγ(ct, d(t −1)) ≡

f(dt|d(t −1), ct) ln
 f(do;t|dp+;t, d(t −1), ct)
γ(d(t)) ⌊Uf(do;t|do(t −1))

ddt.
The pf
⌊Uf(ct+1|d(t)) is the optional design knob. We select it so that the
Bellman function is minimized with respect to this pf. For that, we have to
concentrate
⌊Uf(ct+1|d(t)) on
⌊Ict+1 ∈Arg minct+1∈c∗ωγ(ct+1, d(t)). In this
way, we get γ(d(t)) = exp

−ωγ
 ⌊Ict+1, d(t)

and the optimal strategy is
deterministic
⌊If(ct+1|d(t)) = δct+1, ⌊Ict+1 ≡

1, if ct+1 = ⌊Ict+1
0, if ct+1 ̸= ⌊Ict+1 .
Moreover, this choice of ⌊Uf(ct+1|d(t)) maximizes the probability
⌊Uf(ct+1|d(t)) exp[−ωγ(ct+1, d(t))],
i.e., it selects the most probable academic advice among those given by Propo-
sition 7.2.

214
7 Solution and principles of its approximation: design part
The terminal value ωγ
 ⌊Ic˚t+1, d(˚t)

= 0 is implied by the general terminal
value γ(d(˚t)) = 1 valid for the fully probabilistic design.
The additional optimization replaces the random choice (7.26) of the rec-
ommended pointers ct. It takes the single component f

dt|d(t −1), ⌊Ict

of
the learned model as the constructed ideal pdf.
The proved proposition, combined with the receding-horizon certainty-
equivalence strategy, justiﬁes the following algorithm written for the practi-
cally used state description with the state φ.
Algorithm 7.3 (The most probable academic advising)
Initial (oﬄine) mode
•
Estimate the mixture model of the o-system with the state φt; Chapter 6.
•
Evaluate the steady state behaviors of individual components; Section 7.1.1.
•
Exclude dangerous components; Agreement 5.9.
•
Return to the learning phase if all components are dangerous.
•
Take the nondangerous component as the ideal pdf oﬀered to the operator
and stop if ˚c = 1.
•
Specify the user’s ideal pdf
⌊Uf(do;t|do(t −1)) ≡
⌊Uf(do;t|φt−1) on the
response of the o-system.
•
Select the length of the receding horizon T ≥1.
Sequential (online) mode, running for t = 1, 2, . . .,
1. Acquire the data record dt and determine the state vector φt.
2. Update the estimates of the model parameters if you deal with the adaptive
advisory system.
3. Initialize the iterative mode by setting τ = t + T and ωγ
 ⌊Icτ+1, φτ

= 0.
Iterative mode
a) Evaluate the functions, cτ ∈c∗, ωγ(cτ, φτ−1)
≡

f(dτ|φτ−1, cτ) ln
0
f(do;τ|dp+;τ, φτ−1, cτ)
exp

−ωγ
 ⌊Icτ+1, φτ
 ⌊Uf(do;τ|φτ−1)
1
ddτ
⌊Icτ(φτ−1) ∈Arg min
cτ ∈c∗ωγ(cτ, φτ−1).
b) Continue if τ = t + 1 otherwise decrease τ = τ −1 and go to Step 3a.
4. Present to the operator the ideal pdf ⌊If(do;t+1|φt) = f

do;t+1|φt, ⌊Ict+1

,
which is a marginal pdf of the estimated component f

dt+1|d(t), ⌊Ict+1

.
5. Go to the beginning of Sequential mode.
The feasibility of the design can be achieved also by minimizing an up-
per bound on the KL divergence. The following proposition provides such
a solution that suits both normal components, for which ωγ(ct+1, d(t)) are
quadratic forms in data (see Chapter 9) as well as Markov chains, for which
ωγ(ct+1, d(t)) are ﬁnite-dimensional arrays; see Chapter 11.

7.2 Design of advising strategies
215
Proposition 7.12 (Academic design with the γ-bound) Let us consider
the design of the academic advisory system with actions ct ∈c∗restricted to
those indexes in c∗that point to the nondangerous components only. Let us
search for the optimal causal advising strategy d∗(t −1) →ct ∈c∗that ap-
proximately minimizes the KL divergence of ⌊If(d(˚t), c(˚t)) to the user’s ideal
pdf
⌊Uf(d(˚t), c(˚t)); see (7.25). The strategy given by the following formulas,
evaluated for t = ˚t,˚t −1, . . . , 1,
⌊If(ct|d(t −1)) ∝⌊Uf(ct|d(t −1)) exp[−ωγ(ct, d(t −1))]
(7.29)
ωγ(ct, d(t −1)) ≡

f(dt|d(t −1), ct) ln
 f(do;t|dp+;t, d(t −1), ct)
γ(d(t)) ⌊Uf(do;t|do(t −1))

ddt
γ(d(t)) ≡exp
⎡
⎣−

ct+1∈c∗
⌊Uf(ct+1|d(t))ωγ(ct+1, d(t))
⎤
⎦
γ(d(˚t)) = 1
minimizes the γ-bound, Proposition 7.8, on the KL divergence.
The pdf f(do;t|dp+;t, d(t −1), ct) is the conditional version of the cth com-
ponent f(dt|d(t −1), ct) of the learned mixture model of the o-system.
Proof. We apply formula (7.18) in Proposition 7.4, for the speciﬁc choice of
actions of the p-system and their inﬂuence on the resulting ideal pdf. It gives
⌊If(ct|d(t −1)) ∝⌊Uf(ct|d(t −1)) exp[−ωγ(ct, d(t −1))],
where
ωγ(ct, d(t −1)) ≡

f(dt|d(t −1), ct) ln
 f(do;t|dp+;t, d(t −1), ct)
γ(d(t)) ⌊Uf(do;t|do(t −1))

ddt
γ(d(˚t)) = 1 and for t < ˚t
γ(d(t)) ≡

ct+1∈c∗
⌊Uf(ct+1|d(t)) exp[−ωγ(ct+1, d(t))].
The Bellman function of this optimization equals to −ln(γ(d(t))). Thus, any
replacement of γ(d(t)) by a lower value provides an upper bound on the op-
timized functional. We get it by using inequality between the weighted arith-
metic and geometric means. Thus,
γ(d(t)) ≥exp
⎡
⎣−

ct+1∈c∗
⌊Uf(ct+1|d(t))ωγ(ct+1, d(t))
⎤
⎦.
The use of the right-hand side of this inequality in the role of γ(d(t)) gives
the claimed result.
The proved proposition, combined with the receding-horizon certainty-
equivalence strategy, justiﬁes the following algorithm written for the practi-
cally used state description with the state φ.

216
7 Solution and principles of its approximation: design part
Algorithm 7.4 (Academic advising with the γ-bound)
Apply Algo-
rithm 7.2 with the formula (7.27) replaced by
γ(φτ−1) ≡exp

−

cτ ∈c∗
⌊Uf(cτ|φτ−1)ωγ(cτ, φτ−1)

.
For the desirable receding horizon T > 1, all proposed variants depend
heavily on our ability to evaluate the Bellman function −ln(γ(φ)). This calls
for use of the strategy of iterations spread in time (IST); Section 4.2.1. The
horizon T = 1 is expected to be suﬃcient in the majority of cases.
The common patch introducing IST strategy in all algorithms looks as
follows.
Algorithm 7.5 (The common IST patch)
Initial (oﬄine) mode
•
. . . , . . .
•
Parameterize properly γ(φ) = γ(ϑ, φ) by a ﬁnite-dimensional parameter ϑ.
•
Select the initial value ϑ0 so that the general initial condition of the fully
probabilistic design γ(ϑ0, φ) = 1 is fulﬁlled.
Sequential (online) mode, running for t = 1, 2, . . .
...
Omit resetting of γ(·) before Iterative mode.
Iterative mode
...
Approximate the minimum reached after the tth step of Iterative mode by
γ(ϑt, φ).
Problem 7.3 (Extension of a set of approximate designs) The list of
approximate designs given in this chapter should be gradually completed. For
instance, the following constraint on the target pdfs in advising
⌊Uf (at|d(t −1)) ∝⌊If(at|d(t −1)) exp

−0.5
!!!
!!!at −⌊Uat
!!!
!!!
2
⇔⌊If(at|d(t −1)) ∝⌊Uf(at|d(t −1)) exp

0.5
!!!
!!!at −⌊Uat
!!!
!!!
2
(7.30)
∀t ∈t∗, at ∈a∗
t , d(t −1) ∈d∗(t −1) and a user-speciﬁed ⌊Uat
was considered. It reduces the choice of ⌊Uf(at|d(t −1)) to the choice of the
appropriate weighted norm || · || and the speciﬁcation of the target value ⌊Uat
of the action at. The assumption (7.30) assigns low target probabilities to the
actions far from a given ⌊Uat.
It can be shown that with this restriction, a deterministic strategy arises
and a sort of quadratic programming has to be solved for normal mixtures.

7.2 Design of advising strategies
217
Problem 7.4 (Use of the ω-bound in approximate designs)
The ω-bound, Proposition 7.9, opens the way for construction of a wide set
of approximate designs that are expected to improve the elaborated use of the
γ-bound for discrete-valued advices.
7.2.2 Choice of user ideal on pointers
The pfs
 ⌊Uf(ct|d(t −1))

t∈t∗have an important role in academic and simul-
taneous designs. They are out of the direct user interest and should be left to
their fate; see Section 5.1.3. This leads to the choice ⌊Uf(ct|d(t −1)) = αct,
where α are estimated component weights. This choice has the following in-
terpretation in the γ-bounding of the Bellman function
−ln(γ(d(t)))
≡−ln
⎧
⎨
⎩

ct+1∈c∗
αct+1
(7.31)
× exp
#
−

f(dt+1|d(t), ct+1) ln

f(dt+1|d(t), ct+1)
γ(d(t + 1)) ⌊Uf(dt+1|d(t))

dt+1
$
≤

ct+1∈c∗

f(dt+1, ct+1|d(t)) ln

f(dt+1, ct+1|d(t))
γ(d(t + 1)) ⌊Uf(dt+1|d(t))αct+1

dt+1.
Thus, the bound describing the loss-to-go, Agreement 2.9, is derived from
the objectively estimated pdf f(dt+1, ct+1|d(t)) and it is expected to lead to
a realistic but conservative approximation. At the same time, recommended
pointers are hoped to improve the unguided situation. Thus, it makes sense
to deviate from the complete resignation on the desired ⌊Uf(ct|d(t −1)). For
instance, a constraint of the support of
⌊Uf(ct|d(t −1)) serves us for the
exclusion of dangerous components. An active choice of ⌊Uf(ct|d(t−1)) opens
other useful possibilities that are discussed here.
The low rate of operator actions calls for a low rate of changes of recom-
mended components. This requirement can be respected by the speciﬁcation
⌊Uf(cτ|d(τ −1)) = δcτ ,cnt+1 for τ = nt + 1, . . . , n(t + 1)
(7.32)
⌊Uf(cnt+1|d(nt)) ≡a given pf.
The integer number n ≥1 determines a grouping rate that should correspond
to the rate with which the advices oﬀered to the operator may change. Here,
t ∈t∗counts the groups.
The choice (7.32) allows the recommended pointer to be changed at most
each nth time moment. It leads to a special form of the academic design.
Proposition 7.13 (Academic design for ⌊Uf(ct|d(t −1)) (7.32)) Let us
consider the design of the academic advisory system with actions ct ∈c∗

218
7 Solution and principles of its approximation: design part
restricted to indexes in c∗that point to the nondangerous components only.
Let us also assume that the user’s ideal pf on recommended pointers is selected
according to (7.32). Let us search for the optimal causal advising strategy
d∗(t −1) →ct ∈c∗that minimizes the KL divergence of ⌊If(d(˚t), c(˚t)) to the
user’s ideal pdf ⌊Uf(d(˚t), c(˚t)) as given in (7.25). Then, this strategy has the
functional structure
⌊If(cτ|d(τ −1)) = δcτ ,cnt+1
for τ = nt + 1, . . . , n(t + 1), where
(7.33)
⌊If(cnt+1|d(nt)) is given by the following formulas, solved for t = ˚t−1, . . . , 1,
⌊If(cnt+1|d(nt)) = ⌊Uf(cnt+1|d(nt))exp[−ωγ(cnt+1, d(nt))]
γ(d(nt))
(7.34)
γ(d(nt)) ≡

cnt+1∈c∗
⌊Uf(cnt+1|d(nt)) exp[−ωγ(ctn+1, d(nt))]
ωγ(cnt+1, d(nt)) ≡−1
n ln(γ(cnt+1, d(nt))) with
γ(cnt+1, d(nt)) being the last term of the sequence γ(cnt+1, d(τ)) with
γ(cnt+1, d(n(t + 1))) = γ(d(n(t + 1))) for t < ˚t −1 and γ(d(n˚t)) = 1
−ln(γ(cnt+1, d(τ −1)))
=

f(dτ|d(τ −1), cnt+1) ln

f(do;τ|dp+;τ, d(τ −1), cnt+1)
γ(cnt+1, d(τ)) ⌊Uf(do;τ|do(τ −1), cnt+1)

ddτ.
The needed pdf f(do;τ|dp+;τ, d(τ −1), cτ) is the conditional pdf of the cth com-
ponent f(dτ|d(τ −1), cτ) obtained in learning of the o-system. The ideal pdf
presented to the operator at moments τ = nt + 1, . . . , n(t + 1) has the form
⌊If(dτ+1|d(τ)) =

ctn+1∈c∗
⌊If(cnt+1|d(nt))f(dτ+1|d(τ), cnt+1),
(7.35)
where the learned components f(dτ+1|d(τ), cτ+1) are used.
Proof. The optimized KL divergence is inﬁnite if the support of the optimized
pdf ⌊If(cτ|d(τ −1)) is not fully included in the support of the user’s ideal pf
⌊Uf(cτ|d(τ −1)). This determines the functional structure (7.33) of the optimal
pf ⌊If(cτ|d(τ −1)). For such a pf, the optimized KL divergence can be given
the form
D

⌊If
!!!
!!! ⌊Uf

≡E
⎧
⎨
⎩

t∈t∗

c(tn+1)···(t+1)n

⌊If(d(tn+1)···(t+1)n, c(tn+1)···(t+1)n|d(tn), c(tn))
× ln
0
⌊If(d(tn+1)···(t+1)n, c(tn+1)···(t+1)n|d(tn), c(tn))
⌊Uf(d(tn+1)···(t+1)n, c(tn+1)···(t+1)n|d(tn), c(tn))
1
dd(tn+1)···(t+1)n
%

7.2 Design of advising strategies
219
= E
⎧
⎨
⎩

t∈t∗

ctn+1
(t+1)n

τ=tn+1

f(dτ|d(τ −1), ctn+1) ⌊If(ctn+1|d(tn))
× ln
 f(dτ|d(τ −1), ctn+1) ⌊If(ctn+1|d(tn))
⌊Uf(dτ|d(τ −1), ctn+1) ⌊Uf(ctn+1|d(tn))

ddτ

= nE
⎧
⎨
⎩

t∈t∗

ctn+1
⌊If(ctn+1|d(tn))
#
ln
 ⌊If(ctn+1|d(tn))
⌊Uf(ctn+1|d(tn))

+ ω(ctn+1, d(tn))
$⎫
⎬
⎭
ω(ctn+1, d(tn)) = 1
nE
⎡
⎣
(t+1)n

τ=tn+1

f(dτ|d(τ −1), ctn+1) ln
f(do;τ|dp+;τ, d(τ −1), ctn+1)
⌊Uf(do;τ|do(τ −1), ctn+1)

dτ|d(tn)
$
.
The function ω(ctn+1, d(tn)) is the conditional KL divergence that can be eval-
uated recursively in the way mimic to Proposition 7.3, i.e., ω(ctn+1, d(tn)) ≡
−1/n ln(γ(ctn+1, d(tn))) with γ(c˚tn+1, d(˚tn)) = 1, γ(ctn+1, d((t + 1)n)) =
γ(d((t + 1)n)), and
−ln(γ(ctn+1, d(τ −1)))
=

f(dτ|d(τ −1), ctn+1) ln

f(do;τ|dp+;τ, d(τ −1), ctn+1)
γ(cnt+1, d(τ)) ⌊Uf(do;τ|do(τ −1), ctn+1)

ddτ
for τ = (t + 1)n, (t + 1)n −1, . . . , tn + 1. With the introduced function
ω(ctn+1, d(tn)), we have arrived to the standard expression for the KL di-
vergence: the standard dynamic programming gives the claimed result.
Let us present the algorithm corresponding to the proved proposition com-
bined with the receding-horizon certainty-equivalence strategy. As above, it is
written for the practically used state description with the state φ.
Algorithm 7.6 (Grouped academic advising)
Initial (oﬄine) mode
•
Estimate the mixture model of the o-system with the state φt; Chapter 6.
•
Evaluate the steady state behaviors of individual components; Section 7.1.1.
•
Exclude dangerous components; Agreement 5.9.
•
Return to the learning phase if all components are dangerous.
•
Take the nondangerous component as the ideal pdf oﬀered to the operator
and stop if ˚c = 1.
•
Specify the user’s ideal pdf
⌊Uf(do;t|do(t −1)) ≡
⌊Uf(do;t|φt−1) on the
response of the o-system.
•
Select the grouping rate n > 1 and specify the user’s ideal pdf
⌊Uf(cnt+1|d(nt)) ≡
⌊Uf(cnt+1|φnt) on the recommended pointers to the
nondangerous components.

220
7 Solution and principles of its approximation: design part
•
Select the length of the receding horizon T ≥1.
Sequential (online) mode, running for t = 1, 2, . . .,
1. Acquire the data record dt and determine the state vector φt.
2. Update the estimates of the model parameters if you deal with the adaptive
advisory system.
3. Initialize the iterative mode by setting τ = n(t + T) and γ(φn(t+T )) = 1.
Iterative mode
a) Evaluate the functions ωγ(cτ, φτ), cτ ∈c∗, as follows.
Set ˜τ = τ, γ(c, φ˜τ) = γ(φτ)
For ˜τ = τ, τ −1, . . . , τ −n + 1 evaluate
−ln(γ(c˜τ, φ˜τ−1)) =

f(d˜τ|φ˜τ−1, c˜τ) ln
f(do;˜τ|dp+;˜τ, φ˜τ−1, c˜τ)
γ(c˜τ, φ˜τ)f(do;˜τ|φ˜τ−1)

dd˜τ
end of the cycle over ˜τ
ωγ(c, φτn) ≡−1
n ln (γ(c, φτn))
γ(φτn) ≡

cτn+1∈c∗
⌊Uf(cτn+1|φτn) exp[−ωγ(cτn+1, φτn)].
(7.36)
b) Continue if τ = t otherwise decrease τ = τ −1 and go to Step 3a.
4. Evaluate the advising strategy
⌊If(cnt+1|φnt) = ⌊Uf(cnt+1|φtn)exp[−ωγ(cnt+1, φtn)]
γ(φnt)
.
5. Present to the operator projections of the ideal pdfs
⌊If(do;τ|φτ−1)
=

cnt+1∈c∗
f(do;τ|φτ−1, cnt+1) ⌊If(cnt+1|φnt), τ = nt + 1, . . . , n(t + 1).
The pdf f(do;τ|φτ−1, c) is derived from the cth estimated components .
6. Go to the beginning of Sequential mode.
The introduced grouping can be used for an alternative, problem-tailored
analysis of dangerous components. The nonweighted version of the conditional
KL divergence, which assumes a ﬁxed selection of the recommended pointers
for n steps, expresses the expected quality when a single component is used
for a long time. Thus, dangerous components are those for which
lim
n→∞ω(ctn+1 = c, φtn = φ) ≡ω∞(c, φ)
≡lim
n→∞
1
nE
⎡
⎣
(t+1)n

τ=tn+1

f(dτ|φτ−1, c) ln
f(do;τ|dp+;τ−1, φτ−1, c)
⌊Uf(do;τ|do(τ −1), c)

dτ
!!!!!!
φtn = φ
⎤
⎦

7.2 Design of advising strategies
221
is too large. Moreover, the values ω∞(c, φ) indicate preferences among com-
ponents and guide in selecting the user’s ideal pf ⌊Uf(ct|φt−1) even when no
grouping is applied. It is reasonable to choose
⌊Uf(ct|φt−1) ∈Arg
min
f(ct|φt−1)

D (f||˚c−1
+ qE(ω∞(ct, φt−1)

,
i.e., to select the user’s ideal pf close to the uniform f(c) ≡˚c−1 and having
a small expected value of ω∞(ct, φt−1. The positive optional weight q deﬁnes
compromise between these requirements. Such a pf has the form
⌊Uf(ct|φt−1) ∝exp[−qω∞(ct, φt−1)].
(7.37)
Proposition 7.12 optimizes a computationally attractive upper bound on
the KL divergence. Experiments, however, indicate that the resulting strategy
is not sensitive enough to diﬀerences in quality of individual components. This
sensitivity can be increased by applying the same approximation on grouped
advices discussed above. This motivates the following proposition.
Proposition 7.14 (Grouped academic design with the γ-bound)
Let
us consider the design of the academic advisory system with actions ct ∈c∗
restricted to indexes in c∗that point to the nondangerous components only.
Let us also assume that the user’s ideal pf on the recommended pointers is
selected according to (7.32). Let us search for the optimal causal advising
strategy d∗(t −1) →ct ∈c∗that minimizes the γ-bound, Proposition 7.8, on
the KL divergence of
⌊If(d(˚t), c(˚t)) to the user’s ideal pdf
⌊Uf(d(˚t), c(˚t)) as
given in (7.25). Then, such a strategy has the functional structure
⌊If(cτ|d(τ −1)) = δcτ ,cnt+1. for τ = nt + 1, . . . , n(t + 1).
The value cnt+1, generated by the pf ⌊If(cnt+1|d(nt)), is given by the following
formulas, solved for t = ˚t,˚t −1, . . . , 1,
⌊If(cnt+1|d(nt)) ∝⌊Uf(cnt+1|d(nt)) exp[−ωγ(cnt+1, d(nt))]
(7.38)
ωγ(cnt+1, d(nt)) ≡1
nE
⎡
⎣
n(t+1)

τ=nt+1

f(dτ|d(τ −1), cnt+1)
× ln

f(do;τ|dp+;τ, d(τ −1), cnt+1)
γ(d(n(t + 1))) ⌊Uf(do;τ|do(τ −1))

ddτ
!!!! d(tn)
$
γ(d(nt)) ≡exp
⎡
⎣−

cnt+1∈c∗
⌊Uf(cnt+1|d(nt))ωγ(ctn+1, d(nt))
⎤
⎦
γ(d(n˚t)) = 1.
The needed pdf f(do;τ|dp+;τ, d(τ −1), cτ) is the conditional pdf of the cth com-
ponent f(dτ|d(τ −1), cτ) obtained in learning of the o-system. The ideal pdf
communicated to the operator has the form

222
7 Solution and principles of its approximation: design part
⌊If(dτ+1|d(τ)) =

ctn∈c∗
⌊If(cnt+1|d(nt))f(dτ+1|d(τ), cnt+1),
τ = nt + 1, . . . , n(t + 1), the cth learned component f(dτ+1|d(τ), cτ+1) are
used.
Proof. The result is a straightforward extension of Proposition 7.13 when
approximating the Bellman function from above through inequality between
geometric and arithmetic means as it is done in the proof of Proposition 7.12
or in Proposition 7.8.
This proposition, combined with the receding-horizon certainty-equivalence
strategy, justiﬁes the following algorithm written for the practically used state
description with the state φ.
Algorithm 7.7 (Grouped academic advising with the γ-bound)
Apply Algorithm 7.6 with the formula (7.36) replaced by
γ(φτn) ≡exp
⎡
⎣−

cτn+1∈c∗
⌊Uf(cτn+1|φτn)ωγ(cτn+1, φτn)
⎤
⎦.
Problem 7.5 (Design and application of grouped advices) Estimati-
on in the adaptive version of the grouped design should run at the highest
data collection rate. The grouped design can be repeated either after n real-
time steps or repeated in every real time moment; cf. [158].
Both possibilities have their pros and cons that need a detailed study.
7.2.3 Industrial design
The industrial design that inﬂuences components but leaves their weights un-
changed deals with a rather complex and hardly manageable model. This leads
to the temptation to omit this design completely and to rely on the simul-
taneous design solved in the next section. There is, however, an important
class of problems in which component weights are objectively given. Thus,
the industrial design inspected here is a necessary part of the design toolkit.
Proposition 7.15 (Industrial design with the bound (7.22)) Let the op-
timized joint pdf
⌊If(∆(˚t), uo(˚t))
≡
 
t∈t∗
2
c∈c∗αcf(∆t|uo;t, d(t −1), c)f(uo;t|d(t −1), c)
2
c∈c∗αcf(uo;t|d(t −1), c)
⌊If(uo;t|d(t −1))
be determined by the optional industrial advising strategy described by pdfs
 ⌊If(uo;t|d(t −1))

t∈t∗. The involved mixture with components, c ∈c∗,

7.2 Design of advising strategies
223
{f(dt|uo;t, d(t −1), c) = f(∆t|uo;t, d(t −1), c)f(uo;t|d(t −1), c)}t∈t∗
and their weights αc are assumed to be known (well estimated).
Let us search for the strategy minimizing the upper bound of the type (7.22)
on the KL divergence D
 ⌊If
!!!! ⌊Uf

to the user’s ideal pdf
⌊Uf(d(˚t)) ≡
 
t∈t∗
⌊Uf(∆o;t|uo;t, do(t−1)) ⌊Uf(uo;t|do(t−1)) ⌊If(∆p+;t|d(t−1)).
Let us denote
f(c|uo;t, d(t −1)) ≡
αcf(uo;t|d(t −1), c)
2
c∈c∗αcf(uo;t|d(t −1), c).
(7.39)
Then, the strategy searched for is described by the following formulas, solved
for t = ˚t,˚t −1, . . . , 1,
⌊If(uo;t|d(t −1)) = ⌊Uf(uo;t|d(t −1))exp[−ωγ(uo;t, d(t −1))]
γ(d(t −1))
,
where
γ(d(t −1)) ≡

⌊Uf(uo;t|d(t −1)) exp[−ωγ(uo;t, d(t −1))] duo;t
ωγ(uo;t, d(t −1)) ≡

c∈c∗
f(c|uo;t, d(t −1))ωγ(c, uo;t, d(t −1))
(7.40)
ωγ(c, uo;t, d(t −1)) ≡ln
f(c|uo;t, d(t −1))
αc

+

f(∆t|uo;t, d(t −1), c) ln
 f(∆o;t|∆p+;t, uo;t, d(t −1), c)
γ(d(t)) ⌊Uf(∆o;t|uo;t, do(t −1))

d∆t
γ(d(˚t)) ≡1.
Proof. We set the correspondence with quantities used in Proposition 7.7:
d(t −1) is a ﬁxed condition, x ⇔∆t, y ⇔uo;t. Then, we can write the
optimized upper bound as the expected value of the loss function

t∈t∗

⌊If(uo;t|d(t −1))
#
ln
 ⌊If(uo;t|d(t −1))
⌊Uf(uo;t|d(t −1))

+ ω(uo;t, d(t −1))
$
duo;t
ωγ(uo;t, d(t −1)) ≡

c∈c∗
f(c|uo;t, d(t −1))ωγ(c, uo;t, d(t −1))
ωγ(c, uo;t, d(t −1)) ≡ln
f(c|uo;t, d(t −1))
αc

+

f(∆t|uo;t, d(t −1), c) ln
f(∆o;t|∆p+;t, uo;t, d(t −1), c)
⌊Uf(∆o;t|uo;t, do(t −1))

d∆t.
The standard backward induction for t = ˚t gives
⌊If(uo;˚t|d(˚t −1)) ∝⌊Uf(uo;˚t|d(˚t −1)) exp[−ω(uo;˚t, d(˚t −1))]

224
7 Solution and principles of its approximation: design part
and the minimum value −ln(γ(d(˚t −1))) transferred to the further step with
γ(d(˚t −1)) =

⌊Uf(uo;˚t|d(˚t −1)) exp[−ω(uo;˚t, d(˚t −1))] duo;˚t.
For a generic t, we redeﬁne
ωγ(c, uo;t, d(t −1))
≡

f(∆t|uo;t, d(t −1), c) ln
 f(∆o;t|∆p+;t, uo;t, d(t −1), c)
γ(d(t)) ⌊Uf(∆o;t|uo;t, do(t −1))

d∆t,
in the description of ω(uo;t, d(t −1)). It shows that the computation has the
same structure as for t = ˚t. The full conformity is reached when deﬁning
γ(d(˚t)) = 1.
The proved proposition, combined with the receding-horizon certainty-
equivalence strategy, justiﬁes the following algorithm written for the state
description with the state φ.
Algorithm 7.8 (Industrial advising with the bound (7.22))
Initial (oﬄine) mode
•
Estimate the mixture model of the o-system with the state φt; Chapter 6.
•
Specify the user’s ideal pdf on the response of the o-system
⌊Uf(∆o;t|uo;t, do(t −1)) ⌊Uf(uo;t|do(t −1)).
•
Select the length of the receding horizon T ≥1.
Sequential (online) mode, running for t = 1, 2, . . .,
1. Acquire the data record dt and determine the state vector φt.
2. Update the estimates of the model parameters if you deal with the adaptive
advisory system.
3. Initialize the iterative mode by setting τ = t + T and γ(φτ) = 1.
Iterative mode
a) Evaluate the functions
f(cτ|uo;τ, φτ−1) ≡
αcτ f(uo;τ|φτ−1, cτ)
2
cτ ∈c∗αcτ f(uo;τ|φτ−1, cτ)
ωγ(cτ, uo;τ, φτ−1) ≡ln
f(cτ|uo;τ, φτ−1)
αcτ

+

f(∆τ|uo;τ, φτ−1, cτ) ln
f(∆o;τ|∆p+;τ, uo;τ, φτ−1, cτ)
γ(φτ) ⌊Uf(∆o;τ|uo;τ, φτ−1)

d∆τ
ωγ(uo;τ, φτ−1) ≡

cτ ∈c∗
f(c|uo;τ, φτ−1)ωγ(cτ, uo;τ, φτ−1)
γ(φτ−1) ≡

⌊Uf(uo;τ|φτ−1) exp[−ωγ(uo;τ, φτ−1)] duo;τ

7.2 Design of advising strategies
225
b) Continue if τ = t + 1, otherwise decrease τ = τ −1 and go to Step 3a.
4. Evaluate the industrial strategy
⌊If(uo;t+1|φt) ∝⌊Uf(uo;t+1|φt) exp[−ωγ(uo;t+1, φt)].
5. Present to the operator projections of the ideal pdf (advisory mixture)
⌊If(do;t+1|φt) =
2
c∈c∗αcf(∆o;t|uo;t+1, φt, c)f(uo;t+1|φt, c)
2
c∈c∗αcf(uo;t+1|φt, c)
⌊If(uo;t+1|φt).
The pdfs f(∆o;t|uo;t+1, φt, c), f(uo;t+1|φt, c) are derived from cth learned
mixture component.
6. Go to the beginning of Sequential mode.
Remark(s) 7.6
1. Various bounds have been and can be derived. The bound (7.22) seems to
be the best one of those tried. Alternatives have to be considered in the
future.
2. Use of γ- or ω-bounds, Propositions 7.8 and 7.9 is probably unnecessary
as the used bound (7.22) includes them.
3. The maximum probable choice of the recognizable actions is possible.
7.2.4 Simultaneous academic and industrial design
The separation of academic and industrial designs is often motivated pedagog-
ically only. Whenever possible, the optimization of the recommended pointers
ct and recognizable actions uo;t should be performed simultaneously. It may
give much better results. The recognizable actions may completely change
the character of the analyzed components, for instance, to change danger-
ous components into nondangerous ones. Even less drastic changes reﬂected
in the improved quality are worth considering. Moreover, the simultaneous
design addressed here is simpler than the industrial one.
Proposition 7.16 (Simultaneous fully probabilistic design) Let the op-
timized joint pdf
⌊If(d(˚t), c(˚t)) ≡
 
t∈t∗
f(∆t|uo;t, d(t −1), ct) ⌊If(uo;t|d(t −1), ct) ⌊If(ct|d(t −1))
be determined by the optional simultaneous advising strategy described by pdfs

⌊If(ct, uo;t|d(t −1)) = ⌊If(uo;t|d(t −1), ct) ⌊If(ct|d(t −1))

t∈t∗.
The pdfs {f(∆t|uo;t, d(t−1), ct)}t∈t∗are determined by the components of the
known (well estimated) mixture. Let us search for the strategy minimizing the
KL divergence D
 ⌊If
!!!! ⌊Uf

to the user’s ideal pdf

226
7 Solution and principles of its approximation: design part
⌊Uf(d(˚t), c(˚t)) ≡
 
t∈t∗
⌊Uf(∆o;t|uo;t, do(t −1)) ⌊Uf(uo;t|do(t −1))
× ⌊If(∆p+;t|d(t −1)) ⌊Uf(ct|uo;t, d(t −1)).
Then, the optimal strategy is described by the following formulas, solved for
t = ˚t,˚t −1, . . . , 1,
⌊If(ct, uo;t|d(t −1)) = ⌊Uf(uo;t|do(t −1)) ⌊Uf(ct|uo;t, d(t −1))
×exp[−ωγ(ct, uo;t, d(t −1))]
γ(d(t −1))
γ(d(t −1)) ≡

ct∈c∗

⌊Uf(uo;t|do(t −1)) ⌊Uf(ct|uo;t, d(t −1))
× exp[−ωγ(ct, uo;t, d(t −1))] duo;t
ωγ(ct, uo;t, d(t −1))
≡

f(∆t|uo;t, d(t −1), ct) ln
#f(∆o;t|∆p+;t, uo;t, d(t −1), ct)
γ(d(t)) ⌊Uf(∆o;t|uo;t, d(t −1))
$
d∆t
γ(d(˚t)) ≡1.
(7.41)
Proof. Let us assume that the Bellman function in the addressed problem
has the form −ln(γ(d(t))). For t = ˚t, it holds with γ(d(˚t)) = 1. A generic
optimization step has to ﬁnd
−ln(γ(d(t −1)))
≡
min
{ ⌊If(ct,uo;t|d(t−1))}

ct∈c∗

f(∆t|uo;t, d(t −1), ct) ⌊If(ct, uo;t|d(t −1)) ln
f(∆o;t|∆p+;t, uo;t, d(t −1), ct) ⌊If(ct, uo;t|d(t −1))
γ(d(t)) ⌊Uf(∆o;t|uo;t, do(t −1)) ⌊Uf(uo;t|do(t −1)) ⌊Uf(ct|uo;t, d(t −1)) ddt
=

(7.41)

ct∈c∗

⌊If(ct, uo;t|d(t −1)) ×
×
#
ωγ(ct, uo;t, d(t −1)) + ln

⌊If(ct, uo;t|d(t −1))
⌊Uf(uo;t|do(t −1)) ⌊Uf(ct|uo;t, d(t −1))
$
duo;t.
The minimizing joint pdf of pointers and recognizable actions is
⌊If(ct, uo;t|d(t −1))
=
⌊Uf(uo;t|do(t −1)) ⌊Uf(ct|d(t −1)) exp[−ωγ(ct, uo;t, d(t −1))]
γ(d(t −1))
.
The achieved minimum that coincides with −ln(·) of the normalizing factor
deﬁnes the achieved form of γ(d(t −1)), namely,

7.2 Design of advising strategies
227
γ(d(t −1)) =

ct∈c∗

⌊Uf(ct|uo;t, d(t −1)) ⌊Uf(uo;t|do(t −1))
× exp[−ωγ(ct, uo;t, d(t −1))] duo;t.
The proved proposition, combined with the receding-horizon certainty-
equivalence strategy, justiﬁes the following algorithm written for the state
description with the state φ.
Algorithm 7.9 (Simultaneous advising with the KL divergence)
Initial (oﬄine) mode
•
Estimate the mixture model of the o-system with the state φt; Chapter 6.
•
Specify the user’s ideal pdf on the response of the o-system
⌊Uf (∆o;t|uo;t, do(t −1), ct) ⌊Uf(uo;t, ct|do(t −1))
≡⌊Uf(∆o;t|uo;t, φt−1) ⌊Uf(uo;t, ct|φt−1).
•
Select the length of the receding horizon T ≥1.
Sequential (online) mode, running for t = 1, 2, . . .,
1. Acquire the data record dt and determine the state vector φt.
2. Update the estimates of the model parameters if you deal with the adaptive
advisory system.
3. Initialize the iterative mode by setting τ = t + T and γ(φτ) = 1.
Iterative mode
a) Evaluate the functions ωγ(cτ, uo;τ, φτ−1) ≡
ωγ(cτ, uo;τ, φτ−1)
≡

f(∆τ|uo;τ, φτ−1, cτ) ln
f(∆o;τ|uo;τ, ∆p+;τ, φτ−1, cτ)
γ(φτ) ⌊Uf(∆o;τ|uo;τ, φτ−1)

d∆τ
γ(φτ−1) ≡

cτ ∈c∗

⌊Uf(uo;τ|φτ−1) ⌊Uf(cτ|uo;τ, φτ−1)
(7.42)
× exp[−ωγ(cτ, uo;τ, φτ−1)] duo;τ.
b) Continue if τ = t + 1, otherwise decrease τ = τ −1 and go to Step 3a.
4. Evaluate the optimal simultaneous strategy
⌊If(ct+1, uo;t+1|φt) ∝⌊Uf(ct+1|uo;t+1, φt) ⌊Uf(uo;t+1|φt)
× exp[−ωγ(ct+1, uo;t+1, φt)].
5. Present to the operator projections of the ideal pdf (advisory mixture)
⌊If(do;t+1|φt) =

ct+1∈c∗
f(∆o;t+1|uo;t+1, φt, ct+1) ⌊If(ct+1, uo;t+1|φt),
where the pdf f(∆o;t+1|uo;t+1, φt, ct+1) is derived from the ct+1th learned
mixture component.

228
7 Solution and principles of its approximation: design part
6. Go to the beginning of Sequential mode.
The additional minimization of the achieved minimum of the KL divergence
with respect to the optional ⌊Uf(ct|d(t −1)) does not simplify the evaluation.
For this reason, no counterpart of Proposition 7.3 is presented. However, the
replacement of γ(d(t)) in the deﬁnition of ωγ(·) by a lower bound on γ(d(t))
simpliﬁes the design substantially.
Proposition 7.17 (Simultaneous design with the γ-bound) Let the op-
timized joint pdf
⌊If(d(˚t), c(˚t)) ≡
 
t∈t∗
f(∆t|uo;t, d(t −1), ct) ⌊If(uo;t|d(t −1), ct) ⌊If(ct|d(t −1))
be determined by the optional simultaneous advising strategy described by pdfs

⌊If(ct, uo;t|d(t −1)) = ⌊If(uo;t|d(t −1), ct) ⌊If(ct|d(t −1))

t∈t∗.
The pdfs {f(∆t|uo;t, d(t −1), ct)}t∈t∗are derived from the components of the
known (well-estimated) mixture. Let us search for the strategy approximately
minimizing the KL divergence D
 ⌊If
!!!! ⌊Uf

to the user’s ideal pdf
⌊Uf(d(˚t), c(˚t)) ≡
 
t∈t∗
⌊Uf(∆o;t|uo;t, do(t −1)) ⌊Uf(uo;t|do(t −1))
× ⌊If(∆p+;t|d(t −1)) ⌊Uf(ct|uo;t, d(t −1)).
Then, the following strategy minimizes the γ-bound, Proposition 7.8, on the
KL divergence, t = ˚t,˚t −1, . . . , 1,
⌊If(ct, uo;t|d(t −1))
∝⌊Uf(uo;t|do(t −1)) ⌊Uf(ct|uo;t, d(t −1)) exp[−ωγ(ct, uo;t, d(t −1))]
ωγ(ct, uo;t, d(t −1)) ≡

f(∆t|uo;t, d(t −1), ct)
(7.43)
× ln
#f(∆o;t|∆p+;t, uo;t, d(t −1), ct)
γ(d(t)) ⌊Uf(∆o;t|uo;t, d(t −1))
$
d∆t
γ(d(t −1)) ≡

⌊Uf(uo;t|do(t −1))
× exp

−

ct∈c∗
⌊Uf(ct|uo;t, d(t −1))ωγ(ct, uo;t, d(t −1))

duo;t
γ(d(˚t)) ≡1.
Proof. The optimal strategy is determined by Proposition 7.16 and its Bell-
man function equals to −ln(γ(d(t))). Thus, it is suﬃcient to ﬁnd a lower
bound on γ(d(t)) in order to care about minimization of an upper bound

7.3 Interaction with an operator
229
on the KL divergence. The inequality between the weighted arithmetic and
geometric means is used here; similarly as in Proposition 7.12.
Notice that the γ-bound, Proposition 7.8, is applied to the marginal pf on
pointers c ∈c∗only.
The above proposition, combined with the receding-horizon certainty-
equivalence strategy, justiﬁes the following algorithm written for systems with
the state φ.
Algorithm 7.10 (Simultaneous advising with the γ-bound)
Apply
Algorithm 7.9 with the formula (7.42) replaced by
γ(φτ−1) ≡

⌊Uf(uo;τ|φτ−1)
× exp

−

cτ ∈c∗
⌊Uf(cτ|uo;τ, φτ−1)ωγ(cτ, uo;τ, φτ−1)

duo;τ.
Remark(s) 7.7
1. The grouped variant, similar to Algorithm 7.7, can be simply derived. Its
use seems to be desirable.
2. Other design variants with the γ-bound, like the maximum probable one,
are possible and worth inspecting.
Problem 7.6 (Industrial design as a restricted simultaneous one)
Industrial design can be interpreted as a simultaneous one restricted by the
requirement
⌊If(ct|uo;t, d(t −1)) = αct ≡estimated component weight. It
seems that the design tuning knob
⌊Uf(ct|uo;t, d(t −1)) could be chosen so
that the discussed constraint is met at least approximately. This promising
approximation is worth a deeper inspection.
7.3 Interaction with an operator
Priority zt and signaling st actions are the main tools for communication with
the operator. Their approximate fully probabilistic designs are addressed here.
7.3.1 Assigning priorities
Actions zt, called priorities, select the few, most important entries of do;t that
should be presented to the operator; see Agreement 7.1. Such a selection is
necessary in a generic case when the dimension of do;t does not allow us to
jointly show all entries.
When assigning priorities, we assume that the operator has been given a
full go for making recommended actions. It means that the signaling action

230
7 Solution and principles of its approximation: design part
st = 1; see Section 7.3.2. Then, the model relating the priorities zt to the
response of the o-system reduces to
⌊If(dt|zt, d(t −1)) ≡f(dt|d(t −1))
⌊If(dzt;t|d(t −1))
f(dzt;t|d(t −1)) ,
where
(7.44)
f(dt|d(t −1)) =

c∈c∗
αcf(dt|d(t −1), c) is the learned mixture and
⌊If(dt|d(t −1)) =

ct∈c∗
⌊If(ct|d(t −1)) ⌊If(dt|d(t −1), ct)
is the ideal pdf resulting from the academic, industrial or simultaneous design.
Data dp+;t are not inﬂuenced directly by priorities as we cannot show the
surplus p-data to the operator. Thus, the extension of the true user’s ideal
pdf
⌊Uf(dt|zt, d(t −1)) ≡⌊If(dp+;t|zt, d(t −1)) ⌊Uf(do;t|do(t −1))
= ⌊If(dp+;t|d(t −1)) ⌊Uf(do;t|do(t −1)) ≡⌊Uf(dt|d(t −1))
does not depend on the presentation actions zt. Similarly to academic design,
we introduce and use
⌊Uf(zt|d(t −1)) as a tuning knob of the presentation
design that ﬁxes the externally supplied priorities and damps the rate of zt-
changes.
The conditional KL divergence, the key quantity in the fully probabilistic
design, has the form
ωγ(zt, d(t −1)) ≡

⌊If(dt|zt, d(t −1)) ln
# ⌊If(dt|zt, d(t −1))
⌊Uf(dt|d(t −1))
$
ddt
=

(7.44)
=

f(dt|d(t −1))
⌊If(dzt;t|d(t −1))
f(dzt;t|d(t −1)) ln f(dt|d(t −1)) ⌊If(dzt;t|d(t −1))
f(dzt;t|d(t −1)) ⌊Uf(dt|do(t −1)) ddt.
The rational form (7.44) of the model ⌊If(dt|zt, d(t−1)) implies that an upper
bound on the conditional KL divergence has to be constructed in order to
get a loss function that can be eﬀectively minimized. Essentially, Proposition
7.7 is tailored and complemented by a single use of the Jensen inequality,
Proposition 7.6.
Proposition 7.18 (J bound on the KL divergence in presentation)
Let us consider that the academic, industrial or simultaneous design of the ad-
visory system has provided the strategy d∗(t −1) →(c∗
t , u∗
o;t) determining the
ideal pdf
⌊If(dt|d(t −1)) =

ct∈c∗
⌊If(dt|d(t −1), ct) ⌊If(ct|d(t −1)).
The presentation strategy {f(zt|d(t −1))}t∈t∗is inspected, assuming the in-
ﬂuence of the presentation advices zt through the model (7.44). Let us denote

7.3 Interaction with an operator
231
f(c|dzt;t, d(t −1)) =
αcf(dzt;t|d(t −1), c)
2
c∈c∗αcf(dzt;t|d(t −1)), ∀c ∈c∗.
(7.45)
Let us assume that the basic assumption (7.20) of Proposition 7.6 is met with
a constant K ≥1. Let ¯zt consist of indexes of the data record dt in {1, 2, . . . , ˚
d}
not included in zt and let us deﬁne
ω(c, dzt;t, d(t −1)) ≡ln
f(c|dzt;t, d(t −1))
αc

(7.46)
+

f(d¯zt;t|dzt;t, d(t −1), c) ln
 f(d¯zt;t|dzt;t, d(t −1), c)
⌊Uf(d¯zt;t|dzt;t, d(t −1))

dd¯zt;t
ω(zt, dzt;t, d(t −1)) ≡

c∈c∗
f(c|dzt;t, d(t −1))ω(c, dzt;t, d(t −1)).
Then,
ω(zt, d(t −1)) ≡

f(dt|d(t −1))
⌊If(dzt;t|d(t −1))
f(dzt;t|d(t −1))
(7.47)
× ln
# f(dt|d(t −1)) ⌊If(dzt;t|d(t −1))
⌊Uf(dt|d(t −1))f(dzt;t|d(t −1))
$
ddt ≤¯ω(zt, d(t −1))
¯ω(zt, d(t −1)) ≡

ct∈c∗
⌊If(ct|d(t −1))

⌊If(dzt;t|d(t −1), ct)
×
#
ln
 ⌊If(dzt;t|dp+;t, d(t −1), ct)
⌊Uf(dzt;t|do(t −1))

+

c∈c∗
f(c|dzt;t, d(t −1))ω(c, dzt;t, d(t −1))

ddzt;t.
Proof. For a ﬁxed zt, we use the following correspondence with quantities of
Proposition 7.7
d(t −1)
is a ﬁxed condition
x ⇔d¯zt;t
y ⇔dzt;t
f(x, y) ⇔f(dt|d(t −1))
f(y) ⇔f(dzt;t|d(t −1))
⌊If(y) ⇔⌊If(dzt;t|d(t −1))
⌊Uf(x, y) ⇔⌊Uf(dt|d(t −1)) ≡

(5.7)
⌊Uf(do;t|do(t −1)) ⌊If(dp+;t|d(t −1)).
It gives, cf. (7.22),
ω(zt, d(t −1)) ≡

f(dt|d(t −1))
⌊If(dzt;t|d(t −1))
f(dzt;t|d(t −1))

232
7 Solution and principles of its approximation: design part
× ln
 f(dt|d(t −1)) ⌊If(dzt;t|d(t −1))
⌊Uf(dt|d(t −1))f(dzt;t|d(t −1))

ddt
≤

⌊If(dzt;t|d(t −1))
#
ln
 ⌊If(dzt;t|d(t −1))
⌊Uf(dzt;t|d(t −1))

+ ω(dzt;t, d(t −1))
$
ddzt;t
ω(dzt;t, d(t −1)) ≡

c∈c∗
f(c|dzt;t, d(t −1))ω(c, dzt;t, d(t −1)).
ω(c, dzt;t, d(t −1)) ≡ln
f(c|dzt;t, d(t −1))
αc

+

f(d¯zt;t|dzt, d(t −1), c) ln
 f(d¯zt;t|dzt;t, d(t −1), c)
⌊Uf(d¯zt;t|dzt;t, d(t −1))

dd¯zt;t.
This upper bound still contains logarithms of the mixture ⌊If(dzt;t|d(t −1)).
The use of the Jensen inequality extended according to Proposition 7.6 implies

⌊If(dzt;t| d(t −1)) ln
 ⌊If(dzt;t|d(t −1))
⌊Uf(dzt;t|d(t −1))

ddzt,t
≤

ct∈c∗

⌊If(ct|d(t −1)) ⌊If(dzt;t|d(t −1), ct)
× ln
 ⌊If(dzt;t|dp+;t, d(t −1), ct)
⌊Uf(dzt;t|d(t −1))

ddzt,t.
Inserting this estimate into the upper bound on ω(zt, d(t −1)), using the
fact that 2
ct∈c∗⌊If(ct|d(t −1)) = 1 and the observation that the surplus
p-data dp+;t are not presented, we get the claimed result
ω(zt, d(t −1)) ≤

ct∈c∗
⌊If(ct|d(t −1))

⌊If(dzt;t|d(t −1), ct)
×
#
ln
 ⌊If(dzt;t|dp+;t, d(t −1), ct)
⌊Uf(dzt;t|do(t −1))

+

c∈c∗
f(c|dzt;t, d(t −1))ω(c, dzt;t, d(t −1))

ddzt;t.
Using the found upper bound as the loss function in the fully probabilistic
design, Proposition 7.4, we get the presentation strategy searched for.
Proposition 7.19 (Presentation design with the bound (7.47)) Let us
consider that the academic, industrial or simultaneous design of the advisory
system has provided the strategy d∗(t −1) →(c∗
t , u∗
o;t) determining the ideal
pdf
⌊If(dt|d(t −1)) =

ct∈c∗
⌊If(dt|d(t −1), ct) ⌊If(ct|d(t −1)).

7.3 Interaction with an operator
233
Let the signaling strategy make the operator fully alert, i.e., signaling actions
s(˚t) ≡1. Let also assume that there is constant K ≥1 and a pdf g(dp+;t|d(t−
1)) such that
⌊If(dp+;t|d(t −1), c) ≤Kg(dp+;t|d(t −1)), ∀c ∈c∗
(7.48)
and for almost all data in arguments; cf. Proposition 7.6.
Let us deﬁne for each zt ∈z∗
f(c|dzt;t, d(t −1)) =
αcf(dzt;t|d(t −1), c)
2
c∈c∗αcf(dzt;t|d(t −1)) ≤1, ∀c ∈c∗.
(7.49)
Let us specify the user’s ideal pf ⌊Uf(zt|d(t−1)) on the set of possible priority
actions z∗≡{[z1, . . . , z˚z]} with zj being a unique index in the set of indexes of
the data records do. Then, the presentation strategy that minimizes the upper
bound on the KL divergence, implied by the inequality given in Proposition
7.7, is described by the following algorithm, in which ¯zt mark indexes of dt in
{1, . . . , ˚
d} excluded from zt,
⌊If(zt|d(t −1)) ≡
⌊Uf(zt|d(t −1)) exp[−ωγ(zt, d(t −1))]
γ(d(t −1))
(7.50)
γ(d(t −1)) ≡

zt∈z∗
⌊Uf(zt|d(t −1)) exp[−ωγ(zt, d(t −1))]
ωγ(zt, d(t −1)) ≡

ct∈c∗
⌊If(ct|d(t −1))

⌊If(dzt;t|d(t −1), ct)
×
#
ln
 ⌊If(dzt;t|dp+;t, d(t −1), ct)
⌊Uf(dzt;t|do(t −1))

+

c∈c∗
f(c|dzt;t, d(t −1))ω(c, dzt;t, d(t −1))

ddzt;t
ω(c, dzt;t, d(t −1)) ≡ln
f(c|dzt;t, d(t −1))
αc

+

f(d¯zt;t|dzt;t, d(t −1), c) ln

f(d¯zt;t|dzt;t, d(t −1), c)
γ(d(t)) ⌊Uf(d¯zt;t|dzt;t, d(t −1))

dd¯zt;t
γ(d(˚t)) ≡1.
The solution is evaluated against the time course, starting at t = ˚t.
Proof. The conditional KL divergence is just replaced by the weighted KL
divergence arising in dynamic programming. It preserves the non-negativity
of the original deﬁnition that was used in deriving the used upper bound.
The above proposition, combined with the receding-horizon certainty-
equivalence strategy, justiﬁes the following algorithm written for the prac-
tically used state description with the state φ.

234
7 Solution and principles of its approximation: design part
Algorithm 7.11 (Presentation with the bound (7.47))
Initial (oﬄine) mode
•
Estimate the mixture model of the o-system with the state φt; Chapter 6.
•
Specify the user’s ideal pdf on ∆o;t, uo;t coinciding with the true user’s ideal
pdf and on ct, zt as the tuning knob of the presentation design.
•
Select the length of the receding horizon T ≥1.
Sequential (online) mode, running for t = 1, 2, . . .,
1. Acquire the data record dt and determine the state vector φt.
2. Update the estimates of the model parameters if you deal with the adaptive
advisory system.
3. Design an academic, industrial or simultaneous strategy generating the
optimal ct, uo;t and thus generating on d∗
t the ideal pdf
⌊If(dt|φt−1) =

ct∈c∗
⌊If(ct|φt−1) ⌊If(dt|φt−1, ct).
4. Initialize the iterative mode by setting τ = t + T and γ(φτ) = 1.
Iterative mode
a) Evaluate for each zτ ∈{1, . . . , ˚
do}˚z the functions
f(c|dzτ ;τ, φτ−1) ≡
αcf(dzτ ;τ|φτ−1, c)
2
c∈c∗αcf(dzτ ;τ|φτ−1, c)
γ(φτ−1) ≡

zτ ∈z∗
⌊Uf(zτ|φτ−1) exp[−ωγ(zτ, φτ−1)]
ωγ(zτ, φτ−1) ≡

cτ ∈c∗
⌊If(cτ|φτ−1)

⌊If(dzτ ;τ|φτ−1, cτ)
×
#
ln
 ⌊If(dzτ ;τ|dp+;τ, φτ−1, cτ)
⌊Uf(dzτ ;τ|φτ−1)

+

c∈c∗
f(c|dzτ ;τ, φτ−1)ω(c, dzτ ;τ, φt−1)

ddzτ ;τ
ω(c, dzτ ;τ, φτ−1) ≡ln
f(c|dzτ ;τ, φτ−1)
αc

+

⌊If(d¯zτ ;τ|dzτ ;τ, φτ−1, c) ln

⌊If(d¯zτ ;τ|dzτ ;τφτ−1, c)
γ(φτ) ⌊Uf(d¯zτ ;τ|dzτ ;τ, φτ−1)

dd¯zτ ;τ.
b) Continue if τ = t + 1, otherwise decrease τ = τ −1 and go to Step 4a.
5. Generate a sample ˆzt+1 ∈z∗from the pf ⌊If(zt+1|φt), for instance, max-
imizing argument,
⌊If(zt+1|φt) ∝⌊Uf(zt+1|φt) exp[−ωγ(zt+1, φt)].

7.3 Interaction with an operator
235
6. Present the projections
⌊If(dˆzt+1;t+1|φt) of the ideal pdf
⌊If(dt+1|φt) to
the operator.
7. Go to the beginning of Sequential mode.
In spite of many approximations made, even this algorithm may be
infeasible. This makes us to design the presentation strategy that mini-
mizes the γ-bound, Proposition 7.8. Moreover, the number of compared
presentation values is quickly growing with ˚z. It equals to
 ˚
do
˚z

. Thus,
it is almost necessary to select ˚z = 1 and to show the operator data entries
with the highest values of ⌊If(zt|d(t −1)). This variant is summarized in the
algorithm below that otherwise assumes the receding-horizon certainty-equi-
valence strategy and the state φ.
Algorithm 7.12 (Presentation with (7.47); changed order)
Initial (oﬄine) mode
•
Estimate the mixture model of the o-system with the state φt; Chapter 6.
•
Specify the user’s ideal pdf on ∆o;t, uo;t, ct, zt.
•
Select the length of the receding horizon T ≥1.
•
Specify the dimension ˚ˆz ≤˚
do of the vector ˆzt of do;t-indexes to be shown
to the operator. It is limited by just perceiving the abilities of the operator
and may be much higher than the dimension ˚zt = 1.
Sequential (online) mode, running for t = 1, 2, . . .,
1. Acquire the data record dt and determine the state vector φt.
2. Update the estimates of the model parameters if you deal with the adaptive
advisory system.
3. Design an academic, industrial or simultaneous strategy generating the
optimal ct, uo;t and thus determining on d∗
t the ideal pdf
⌊If(dt|φt−1) =

ct∈c∗
⌊If(ct|φt−1) ⌊If(dt|φt−1, ct).
4. Initialize the iterative mode by setting τ = t + T and γ(φτ) = 1.
Iterative mode
a) Evaluate, for each zτ ∈z∗≡{1, . . . , ˚
do} the functions
f(c|dzτ ;τ, φτ−1) ≡
αcf(dzτ ;τ|φτ−1, c)
2
c∈c∗αcf(dzτ ;τ|φτ−1, c)
γ(φτ−1) ≡exp

−

zτ ∈z∗
⌊Uf(zτ|φτ−1)ωγ(zτ, φτ−1)

ωγ(zτ, φτ−1) ≡

cτ ∈c∗
⌊If(cτ|φτ−1)

⌊If(dzτ ;τ|φτ−1, cτ)

236
7 Solution and principles of its approximation: design part
×
#
ln
 ⌊If(dzτ ;τ|dp+;τ, φτ−1, cτ)
⌊Uf(dzτ ;τ|φτ−1)

+

c∈c∗
f(c|dzτ ;τ, φτ−1)ω(c, dzτ ;τ, φt−1)

ddzτ ;τ
ω(c, dzτ ;τ, φτ−1) ≡ln
f(c|dzτ ;τ, φτ−1)
αc

+

⌊If(d¯zτ ;τ|dzτ ;τ, φτ−1, c) ln

⌊If(d¯zτ ;τ|dzτ ;τφτ−1, c)
γ(φτ) ⌊Uf(d¯zτ ;τ|dzτ ;τ, φτ−1)

dd¯zτ ;τ.
b) Continue if τ = t + 1, otherwise decrease τ = τ −1 and go to the
beginning of Iterative mode.
5. Order the values ⌊If(zt+1|φt) ∝⌊Uf(zt+1|φt) exp[−ωγ(zt+1, φt)].
6. Present projections of the ideal pdf ⌊If(dˆzt+1;t+1|φt) to the operator. The
vector ˆzt+1 of indexes has the entries with ˚ˆz highest values of ⌊If(zt+1|φt).
7. Go to the beginning of Sequential mode.
Problem 7.7 (Completion of the set of presentation strategies) Several
algorithms should be completed for presentation combining IST strategy, Sec-
tion 4.2.1, grouping mimic to (7.32), the maximum probable design, etc.
Problem 7.8 (An alternative design of presentation strategies)
Alternatively, it seems possible to reduce data do to a subselection given by
the presentation action z and perform “ordinary”, say simultaneous, design.
By doing it for several z’s, we can compare the achieved minima and present
those quantities corresponding to the smallest one. It avoids the cumbersome
upper bounds but needs several simultaneous designs to be performed in par-
allel. It is expected that a carefully proposed strategy of selecting the compared
presentation variants will lead to a feasible algorithm.
7.3.2 Stimulating the operator
When designing a signaling strategy, we assume that the academic, industrial
or simultaneous design of the ideal pdf ⌊If(d(˚t)) has been performed. Then,
the model relating the signaling action st to the response of the o-system
becomes
⌊If(dt, st|d(t −1)) ≡⌊If(dt|st, d(t −1)) ⌊If(st|d(t −1)), st ∈s∗≡{0, 1}
⌊If(dt|st = 0, d(t −1)) ≡f(dt|d(t −1))
≡learnt mixture describing the unguided o-system
⌊If(dt|st = 1, d(t −1)) ≡⌊If(dt|d(t −1))
=

ct∈c∗
⌊If(ct|d(t −1)) ⌊If(dt|d(t −1), ct)
⌊If(dt|d(t −1), ct) ≡f(dt = ∆t|d(t −1), ct) for the academic design

7.3 Interaction with an operator
237
⌊If(dt|d(t −1), ct) ≡f(∆t|uo;t, d(t −1), ct) ⌊If(uo;t|d(t −1))
for the industrial design
⌊If(dt|d(t −1), ct) ≡f(∆t|uo;t, d(t −1), ct) ⌊If(uo;t|d(t −1), ct)
for the simultaneous design
f(∆t|uo;t, d(t −1), ct) ≡the conditional pdf computed from
ctth estimated component
⌊If(uo;t|d(t −1)) ≡the conditional pdf from the industrial design
⌊If(uo;t|d(t −1), ct) ≡the conditional pdf from the simultaneous design
⌊If(ct|d(t −1)) ≡αct ≡component weight for the industrial design
⌊If(ct|d(t −1)) ≡the pf from the academic or simultaneous design.
The exact fully probabilistic design of the optimal signaling strategy is
hopeless at least because of the mixture form of the used models and the
rational form needed when d∗
p+ is nonempty. This makes us to design directly
an approximate strategy. Simplicity of the action space s∗= {0, 1} allows us
to use the tighter bound of the ω-type; Proposition 7.9.
Proposition 7.20 (Signaling design with the ω-bound)
Let us consi-
der that the academic, industrial or simultaneous design of the advisory system
has provided the strategy d∗(t −1) →(c∗
t , u∗
o;t) determining the ideal pdf
⌊If(dt|d(t −1)) =

ct∈c∗
⌊If(dt|d(t −1), ct) ⌊If(ct|d(t −1)).
Let us assume that the conditions of Proposition 7.4 are met. Then, the fol-
lowing signaling strategy minimizes the ω-type bound, Proposition 7.9, on the
KL divergence. The recursion run for t = ˚t,˚t −1, . . . , 1.
f(st|d(t −1)) ∝⌊Uf(st|d(t −1)) exp[−ωγ(st, d(t −1))],
(7.51)
ωγ(st = 0, d(t −1)) ≡

c∈c∗
αcωγ(c, d(t −1))
ωγ(c, d(t −1)) ≡

f(dt|d(t −1), c)
×
#
ln
f(do;t|dp+;t, d(t −1), c)
⌊Uf(do;t|do(t −1))

+ ωγ(d(t))
$
ddt
ωγ(st = 1, d(t −1)) ≡

c∈c∗
⌊If(ct|d(t −1)) ⌊Iωγ(c, d(t −1))
⌊Iω(c, d(t −1)) ≡

⌊If(dt|d(t −1), c)
×
#
ln
 ⌊If(do;t|dp+;t, d(t −1), c)
⌊Uf(do;t|do(t −1))

+ ωγ(d(t))
$
ddt
ωγ(d(t)) ≡⌊Uf(st+1 = 0|d(t))ωγ(st+1 = 0, d(t)) +

238
7 Solution and principles of its approximation: design part
+ ⌊Uf(st+1 = 1|d(t))ωγ(st+1 = 1, d(t))
ωγ(d(˚t)) = 0.
Proof. According to Proposition 7.4, the optimal strategy minimizing the KL
divergence
D

⌊If
!!!
!!! ⌊Uf

≡

⌊If(d(˚t), s(˚t)) ln

⌊If(d(˚t), s(˚t))
⌊Uf(d(˚t), s(˚t))

d(d(˚t)s(˚t))
to the user’s ideal pdf ⌊Uf(d(˚t), s(˚t)), fulﬁlling (7.17), has the form
⌊If(st|d(t −1)) = ⌊Uf(st|d(t −1))exp[−ωγ(st, d(t −1))]
γ(d(t −1))
,
where
γ(d(t −1)) ≡

st∈s∗
⌊Uf(st|d(t −1)) exp[−ωγ(st, d(t −1))]
ωγ(st = 0, d(t −1)) ≡

f(dt|d(t −1)) ln

f(do;t|dp+;t, d(t −1))
γ(d(t)) ⌊Uf(do;t|do(t −1))

ddt
ωγ(st = 1, d(t −1)) ≡

⌊If(dt|d(t −1)) ln

⌊If(do;t|dp+;t, d(t −1))
γ(d(t)) ⌊Uf(do;t|do(t −1))

ddt
γ(d(˚t)) = 1.
If we ﬁnd upper bounds on ωγ(d(t −1)) and insert them into deﬁnition of
γ(d(t)) we get a lower bound on it and consequently the upper bound on the
Bellman function −ln(γ(d(t))). Let us do that.
We use Proposition 7.6 and omit the term ln(K) that has no inﬂuence on
optimization. It implies
ωγ(st = 0, d(t −1))
≡

f(dt|d(t −1)) ln

f(do;t|dp+;t, d(t −1))
γ(d(t)) ⌊Uf(do;t|do(t −1))

ddt
≤

c∈c∗
αc

f(dt|d(t −1), c) ln
 f(do;t|dp+;t, d(t −1), c)
γ(d(t)) ⌊Uf(do;t|do(t −1))

ddt
≡

c∈c∗
αcωγ(c, d(t −1)) and
ωγ(st = 1, d(t −1)) ≡

⌊If(dt|d(t −1))
× ln

⌊If(do;t|dp+;t, d(t −1))
γ(d(t)) ⌊Uf(do;t|do(t −1))

ddt
≤

ct∈c∗
⌊If(ct|d(t −1))
×

⌊If(dt|d(t −1), ct) ln
 ⌊If(do;t|dp+;t, d(t −1), ct)
γ(d(t)) ⌊Uf(do;t|do(t −1))

ddt ≡

7.3 Interaction with an operator
239
≡

ct∈c∗
⌊If(ct|d(t −1)) ⌊Iωγ(ct, d(t −1)).
Substituting this upper bound into the deﬁnition of γ(d(t)) and using the
inequality between weighted arithmetic and geometric means for a further
bounding of γ(d(t)), we complete the last step giving the claimed result
ln(γ(d(t))) ≥

ct∈c∗
	
⌊Uf(st = 0|d(t −1))αctωγ(ct, d(t −1))
+
⌊Uf(st = 1|d(t −1)) ⌊If(ct|d(t −1)) ⌊Iωγ(ct, d(t −1))

.
The proved proposition, combined with the receding-horizon certainty-
equivalence strategy, justiﬁes the following algorithm written for the practi-
cally used state description with the state φ.
Algorithm 7.13 (Signaling with the ω-bound)
Initial (oﬄine) mode
•
Estimate the mixture model f(dt|d(t −1)) = 2
c∈c∗αcf(dt|φt−1, c) of the
o-system with the state φt; Chapter 6.
•
Specify the user’s ideal pf
⌊Uf(st|d(t −1)) =
⌊Uf(st|φt−1) on signaling
actions st ∈{0, 1}.
•
Specify the user’s ideal pdf on the recommended pointers ct, o-innovations
∆o;t and recognizable actions uo;t.
•
Select the length of the receding horizon T ≥1.
Sequential (online) mode, running for t = 1, 2, . . .,
1. Acquire the data record dt and determine the state vector φt.
2. Update the estimates of the model parameters if you deal with the adaptive
advisory system.
3. Perform the academic, industrial or simultaneous design generating the
ideal pdf
⌊If(dt|φt−1) =

ct∈c∗
⌊If(ct|φt−1) ⌊If(dt|φt−1, ct).
4. Initialize the iterative mode by setting τ = t + T and ωγ(φτ) = 0.
Iterative mode
a) Evaluate the functions
⌊If(cτ, uo;τ|d(τ −1)) = ⌊If(cτ, uo;τ|φτ−1)
using the academic, industrial or simultaneous design that gives
⌊If(dτ|φτ−1) =

cτ ∈c∗
⌊If(cτ|φτ−1) ⌊If(dτ|φτ−1, cτ)
⌊If(dτ|φτ−1, cτ) ≡f(∆τ|uo;τ, φτ, cτ) ⌊If(uo;τ|φτ, cτ).

240
7 Solution and principles of its approximation: design part
b) Determine the following functions, c ∈c∗,
ωγ(c, φτ−1)
≡

f(dτ|φτ−1, c)
#
ln
f(do;τ|dp+;τ, φτ−1, c)
⌊Uf(dτ|φτ−1)

+ ωγ(φτ)
$
ddτ
⌊Iωγ(cτ, φτ−1) ≡

⌊If(dτ|φτ−1, cτ)
×
#
ln
 ⌊If(do;τ|dp+;τ, φτ−1, cτ)
⌊Uf(cτ, do;τ|φτ−1)

+ ωγ(φτ)
$
ddτ
ωγ(φτ) ≡⌊Uf(sτ+1 = 0|φτ)ωγ(sτ+1 = 0, φτ)
+ ⌊Uf(sτ+1 = 1|φτ)ωγ(sτ+1 = 1, φτ),
where
ωγ(sτ+1 = 0, φτ) ≡

cτ+1∈c∗
αcτ+1ωγ(cτ+1, φτ)
ωγ(sτ+1 = 1, φτ) ≡

cτ+1∈c∗
⌊If(cτ+1|φτ
⌊Iωγ(cτ+1, φτ).
c) Continue if τ = t + 1. Otherwise decrease τ = τ −1 and go to the
beginning of Iterative mode.
5. Evaluate the optimal signaling strategy
⌊If(st+1|φt) ∝⌊Uf(st+1|φt) exp[−ωγ(st+1, φt).
6. Make the operator alert to perform recommended actions if
⌊If(st+1 = 0|φt) is close to zero. Otherwise let him proceed as usual.
7. Go to the beginning of Sequential mode.
Problem 7.9 (Order of presentation and signaling designs) The design
of the signaling strategy has to be done after ﬁnishing the academic, indus-
trial or simultaneous design. It is, however, unclear whether to perform it
after speciﬁcation of priorities or whether priorities should be decided after
the decision that the operator should make some actions.
The former version is more realistic as it measures possible improvements
limited by the restricted ability of human being to grasp information. The
latter case is less conservative and more sensitive to possible problems that
need not be manageable by the operator. The higher sensitivity and simplicity
of the design make us select the latter case. The alternative solution has to be
inspected in the future.
Problem 7.10 (Approximation of Bellman functions) Practically, the
evaluation of Bellman functions in all design variants has to be reduced to
algebraic manipulations. It seems that, in addition to minimization of upper
bounds of the KL divergence, it is possible to exploit upper bounds resulting
from insertion of nonoptimal actions during dynamic programming; cf. Propo-
sition 7.9. Some results of this type are also in Chapter 9. This promising
methodology should be, however, inspected systematically.

7.4 Design validation
241
7.4 Design validation
The fullscale use of the advisory system is the only decisive validation test.
Naturally, a collection of indicators is needed in the design phase for check-
ing the chance of the ﬁnal success and for early recognition of troubles. The
following, deﬁnitely incomplete, list of ideas has been collected and partially
elaborated up to now.
•
The model validation has to be successful; see Section 6.7.
•
The estimated model has to be reliable as a long horizon predictor; see Sec-
tion 7.1.2. If need be, the model estimate has to be stabilized as described
in Algorithm 7.1 and tested for the quality of predictions.
•
The KL divergence of the estimated model of the o-system to the user’s
ideal pdf should be close to a sample version of the KL divergence ob-
tained from the measured data. The construction of the sample version is
a generally nontrivial task for continuous valued data since logarithms of
Dirac delta functions should be dealt with. A plausible solution is, however,
available for the normal case that is of our primary interest; see Section
9.1.4. Note that the analysis of the sample version of the KL divergence
should be done for both components and the overall mixture; see item 8
of Remarks 9.8.
•
The advisory system should behave properly when an artiﬁcial closed loop
is created with the estimated model in the role of the o-system. This test
can be implemented only when recognizable actions are present, when the
industrial or simultaneous design is tested.
•
Open-loop advices, generated by the p-system even if fed into the o-system,
should be reasonably close to the good practice reﬂected in learning data.
It has an important psychological aspect with respect to users: they surely
will not be ready to change radically their current habits.
•
All tests above should be robust with respect to small changes of tuning
knobs used both in learning and design.
Problem 7.11 (Systematic design validation) Design validation is even
harder that the learning validation. Thus, it is not surprising that it still needs
a systematic solution. Even partial progress is highly desirable.

8
Learning with normal factors and components
Factors form basic building blocks of components. The feasibility of evalua-
tions outlined in Chapter 6 singles out normal factors, Markov-chain factors
(Chapter 10), and so-called mean tracking (MT) factors (Chapter 12) as suit-
able candidates. This chapter elaborates on the operations needed for normal
factors in detail. Operations outlined in Chapter 6 are specialized to nor-
mal factors and to Gauss-inverse-Wishart pdf (GiW), that is their conjugate
pdf. Numerically stable learning algorithms are developed based on L′DL or
LDL′ decompositions of the extended information matrix forming a decisive
part of the suﬃcient statistics describing normal factors. Aspects related to
the normal components consisting solely of normal factors are also discussed.
The normal parameterized factor that we deal with predicts a real-valued
quantity dt ≡di;t, i ∈{1, . . . , ˚
d} by the pdf
f(dt|d(i+1)···˚
d;t, d(t −1), Θ) = Ndt(θ′ψt, r), where
(8.1)
Θ ≡[θ, r] ≡[regression coeﬃcients, noise variance] ∈Θ∗
Θ∗⊂(˚
ψ-dimensional, nonnegative) real quantities, and
ψ is the regression vector,
Nd(θ′ψ, r) ≡(2πr)−0.5 exp

−(d −θ′ψ)2
2r

(8.2)
= (2πr)−0.5 exp

−1
2rtr (ΨΨ ′[−1, θ′]′[−1, θ′])

,
Ψ ≡[d, ψ′]′ ≡data vector, tr is the matrix trace, ′ denotes transposition.
The layout of Chapter 6 is more or less copied. Section 8.1 prepares common
tools used throughout the chapter. Preprocessing of raw data observed by the
p-system is described in Section 8.2. Speciﬁc elicitation of prior knowledge is
treated in Section 8.3. Even with such knowledge available, a proper speciﬁca-
tion of the prior pdf is nontrivial. An extensive discussion of its construction
is in Section 8.4. Then, specialization of the approximate estimation to the

244
8 Learning with normal factors and components
normal mixtures follows; Section 8.5. Structure estimation is elaborated in
Section 8.6. The concluding Section 8.6 covers model validation. It forms a
bridge to Chapter 9, which treats design of the advising strategies.
8.1 Common tools
This section collects common technical tools used for learning with mixtures
consisting solely of normal factors. For these factors, learning reduces to al-
gebraic recursions so that the tools concern mainly matrix operations.
8.1.1 Selected matrix operations
Proposition 8.1 (Some matrix formulas) Let the involved matrices A,
B, C have compatible dimensions and the used inversions exist. Then,
tr(ABC) = tr(CAB) = tr(BCA)
(8.3)
tr(A) = tr(A′), |A| = |A′|, |A−1| = |A|−1
(8.4)
(A + BCD)−1 = A−1 −A−1B(C−1 + DA−1B)−1DA−1
(8.5)
∂
∂Atr(AB) = B′,
∂
∂A ln(|A|) = A−1
(8.6)
Proof.
Eqn. (8.3):
tr(ABC) ≡

i∈i∗
(ABC)ii =

i∈i∗

k∈k∗
(AB)ikCki
=

k∈k∗
0
i∈i∗
Cki(AB)ik
1
=

k∈k∗
(CAB)kk ≡tr(CAB).
Eqn. (8.4): tr(A) ≡2
i∈i∗Aii = 2
i∈i∗(A′)ii ≡tr(A′).
Let λ be eigenvalue of A, i.e., there is a vector x ̸= 0 such that Ax = λx. It
implies that x′ solves the equation x′A′ = λx′. Thus, eigenvalues of A and A′
coincide and consequently |A| = |A′|. Similarly, for nonzero eigenvalues λ(A)
of the regular matrix A, we get λ(A−1) =
1
λ(A). Thus, |A−1| =
1
|A|.
Eqn. (8.5):
(A + BCD)

A−1 −A−1B(C−1 + DA−1B)−1DA−1
= I + BCDA−1 −B(C−1 + DA−1B)−1DA−1
−BCDA−1B(C−1 + DA−1B)−1DA−1
=

DA−1B=−C−1+C−1+DA−1B
= I + BCDA−1 −B(C−1 + DA−1B)−1DA−1
−BCDA−1 + B(C−1 + DA−1B)−1DA−1 = I.
Eqn. (8.6):
∂
∂A ijtr(AB) =
∂
∂A ij
	2
i∈i∗,j∈j∗AijBji

= Bji = (B′)ij.

8.1 Common tools
245
Let
⌊klA be the complement to the entry Akl, i.e., determinant of the
matrix obtained from A by cancelling the kth row and lth column multiplied
by (−1)k+l. Then, |A| = 2
kl Akl ⌊klA and
∂
∂Aij
ln |A| =
⌊ijA
|A| =

A−1
ij .
8.1.2 L′DL decomposition
A positive deﬁnite matrix V, called the extended information matrix, forms
the decisive part of the suﬃcient statistic in estimation of normal factors;
see Section 8.1.5. Often, it is poorly conditioned and the use of its L′DL
decomposition is the only safe way how to counteract the induced numerical
troubles. We collect the facts used explicitly in this text. For a broader view
see [159].
Agreement 8.1 (L′DL decomposition) Let V be a positive deﬁnite sym-
metric matrix with ˚Ψ rows. Let us suppose that V = L′DL, where L is a lower
triangular matrix with a unit diagonal, D is a diagonal matrix with positive
diagonal entries. This expression is called L′DL decomposition of V .
Proposition 8.2 (Existence and uniqueness of L′DL decomposition)
Let V be a positive deﬁnite symmetric matrix with ˚Ψ rows. Then, its L′DL
decomposition exists and it is unique. It is constructed as follows.
For
j = ˚Ψ, . . . , 1
Set Ljj = 1
For
i = ˚Ψ, . . . , j + 1
Set s = Vij
For
k = i + 1, . . . , ˚Ψ
Set s = s −LkiDkkLkj
end
of the cycle over k
Set Lij = s/Dii
end
of the cycle over i
Set s = Vjj
For
k = j + 1, . . . , ˚Ψ
Set s = s −L2
kjDkk
end
of the cycle over k
Set Djj = s
end
of the cycle over j

246
8 Learning with normal factors and components
Proof. The algorithm is directly implied by the desired identity V = L′DL
written entrywise. The algorithm fails if some Djj ≤0. Let us assume that
such Djj occurs and denote
⌊jL the part of the matrix L found up to this
moment. Let ⌊jx solve the triangular equation ⌊jx′ ⌊jL′ = [1, 0, . . . , 0



lenght j
]. Then,
the quadratic form x′V x is not positive for x =

0′, ⌊jx′′. This contradicts
the assumed deﬁniteness of V .
Remark(s) 8.1
It is worth stressing that the derived algorithm is useful for proving existence
and uniqueness. It may fail numerically in evaluating entries Dii when the
matrix is poorly conditioned. We do not use it practically.
Updating L′DL decomposition
The meaningful use of the L′DL decomposition depends on our ability to
convert the recursion V = λV + wΨΨ ′ into a direct, numerically robust,
recursion for matrices L and D; Proposition 8.2. This recursion, with Ψ equal
to the data vector and scalar positive weights λ, w, arises in estimation; cf.
Proposition 8.11. The direct updating is based on the algorithm dydr [146]
that makes it eﬃciently.
Proposition 8.3 (Algorithm dydr) The positive semi-deﬁnite matrix of
the rank 2 can be given the two equivalent forms deﬁning the same kernels
of a quadratic form
[a, b]
#
Da 0
0 Db
$
[a, b]′ = [c, d]
#
Dc 0
0 Dd
$
[c, d]′.
(8.7)
There, Da, Db, Dc, Dd are positive scalars and a, b, c, d are column vectors of
the same length ˚a ≥2.
Let the following entries of c, d be ﬁxed at values
cj ≡1, dj ≡0,
for a chosen j ∈{1, . . . ,˚a}.
(8.8)
Then, the right-hand side matrix in (8.7) is determined uniquely by the left-
hand side through the following algorithm.
Algorithm 8.1 (Dyadic reduction: dydr)
1. Set Dc = a2
jDa + b2
jDb.
2. Set x = ajDa
Dc , y = bjDb
Dc .
3. Set Dd = DaDb
Dc .
4. Evaluate the remaining entries of c, d as follows. ci = xai + ybi, di =
−bjai + ajbi for i = 1, . . . ,˚a. It gives cj = 1, dj = 0.
The Matlab script of dydr may look as follows.

8.1 Common tools
247
function [Dc,Dd,c,d]=dydr(Da,Db,a,b,j)
%
% dydr makes dyadic reduction of the positive definite
%
quadratic form [a,b]diag(Da,Db)[a,b]’ to the
%
quadratic form [c,d]diag(Dc,Dd)[c,d]’ so that
%
jth entry of c equals 1, jth entry of d is zero
aj=a(j,1); bj=b(j,1); Dc=ajˆ(2)*Da+bjˆ(2)*Db;
if Dc<machine_precision, ’not positive definite’, return, end
x =aj*Da/Dc; y=bj*Db/Dc; Dd=Da*Db/Dc;
c=x*a+y*b; d=bj*a+aj*b;
c(j,1)=1; d(j,1)=0;
Proof. Let us take for simplicity j = 1 and let T =
#
x −b1
y
a1
$
be a regular
matrix determined by free scalars x, y. It has its second column orthogonal
to the row vector [a1, b1]. Thus, [c, d] ≡[a, b]T has d1 = 0. The remaining
requirement in (8.8) is fulﬁlled if a1x+b1y = 1. It also makes the determinant
of T equal to 1. The inspected decomposed form of the positive semi-deﬁnite
matrix (8.7) is preserved after such a transformation of [a, b] iﬀ
#
Dc 0
0 Dd
$
= T −1
#
Da 0
0 Db
$
(T −1)′, T −1 =
#
a1 b1
−y x
$
.
The diagonal form is preserved iﬀ−ya1Da + xb1Db = 0. This together with
the former condition a1x+b1y = 1 determines uniquely y, x and consequently
all other elements
Dc = a2
1Da + b2
1Db, x = a1Da
Dc
, y = b1Db
Dc
, Dd = DaDb
Dc
c = xa + yb, d = −b1a + a1b.
With the algorithm dydr, the rank-one updating V = λV +wΨΨ ′ of L′DL
decomposition of the extended information matrix V is straightforward.
Algorithm 8.2 (Rank-one updating of L′DL = λL′DL + wΨΨ ′)
Set b = Ψ, Dd = w
For
j = ˚Ψ, . . . , 1
[Dj, Dd, jth column of L′, b] = dydr (λ ∗Dj, Dd, jth column of L′, b, j)
end
of the cycle over j
Conversion of L′DL to LDL′
Learning uses mostly the L′DL decomposition; Agreement 8.1. For some ready
structure estimation algorithms [93], it is useful to deal with the LDL′ de-
composition. It is given, again uniquely, by the lower triangular matrix L with

248
8 Learning with normal factors and components
unit diagonal and by the diagonal matrix D with positive diagonal entries.
The algorithm dydr serves well for the conversion L′DL →LDL′.
Algorithm 8.3 (Conversion of L′DL to LDL′)
For
j = ˚Ψ −1, . . . , 1
For
i = j + 1, . . . , ˚Ψ
[Dj, Di, ith column of L, jth column of L]
= dydr (Dj, Di, ith column of L, jth column of L, j)
end
of the cycle over i
end
of the cycle over j
Permutation of variables in quadratic forms
We permute entries of regression vectors ψ when evaluating marginal pdfs and
when estimating the structure of normal factors; see Section 8.6. This action
induces permutations of regression coeﬃcients θ. The decisive quadratic form
[−1, θ′]V [−1, θ′]′ determining GiW pdf, Subsection 8.1.3, remains unchanged
if the corresponding rows and columns of V are permuted, too. It spoils,
however, LDL′ or L′DL decompositions of V . The following propositions
describe simple algorithms that recover these decompositions after permuting
adjacent entries of ψ and thus of θ. More complex permutations are obtained
through a sequence of such elementary permutations.
Proposition 8.4 (Permutation of adjacent entries in LDL′) Let V =
LDL′ be the decomposition of the extended information matrix corresponding
to the data Ψ = [d, ψ′]′ and parameter [−1, θ′]′ vectors. Let
ψ = [h′, a, b, c′]′, ˜ψ = [h′,
b, a

permuted
, c′]′,
with scalar a, b,
(8.9)
θ = [θ′
h, θa, θb, θ′
c]′, ˜θ = [θ′
h, θb, θa
  
permuted
, θ′
c]′,
with scalar θa, θb.
Then, the LDL′ decomposition of the matrix ˜V
= ˜L ˜D˜L′ preserving the
quadratic form [−1, θ′]V [−1, θ′]′ = [−1, ˜θ′] ˜V [−1, ˜θ′]′ is obtained from the
decomposition V = LDL′ by the following algorithm.
1. Permute rows of L corresponding to regressors a and b up to the main
subdiagonal entry of the shorter one.
2. Store Dao = Da = entry of D corresponding to the regressor a.
3. Recompute Da = Db + ω2Da, where ω is the scalar on the subdiagonal of
the longer vector of the permuted rows.
4. Compute auxiliary quantities x = ωDao/Da, y = Db/Da.

8.1 Common tools
249
5. Recompute Db = DaoDb/Da = entry of D corresponding to the regressor
b.
6. Store ath column La of L into Lao starting from the entry below ω.
7. Recompute La = xLa + yLb, where Lb contains entries in the adjacent
entries of the column b.
8. Recompute Lb = Lao −ωLb.
9. Correct ω = x.
Proof. The permutation of entries a, b in the regression vector implies the
permutation of the corresponding pair of columns and rows in the symmetric
matrix V . In the equivalent LDL′ decomposition, it changes
D =
⎡
⎢⎢⎣
Dh
Da
Db
Dc
⎤
⎥⎥⎦, L =
⎡
⎢⎢⎣
Lh
0
0
0
Lha 1
0
0
Lhb ω
1
0
Lhc La Lb Lc
⎤
⎥⎥⎦,
with scalars Da, Db, ω,
to
D = D, L =
⎡
⎢⎢⎣
Lh
0
0
0
Lhb ω
1
0
Lha 1
0
0
Lhc La Lb Lc
⎤
⎥⎥⎦.
(8.10)
We search for ˜D, ˜L such that quadratic forms [−1, ˜θ′]˜L ˜D˜L′[−1, ˜θ′]′ and
[−1, θ′]′LDL′[−1, θ′]′ are equal. It is achieved when D and L coincide with
˜D and ˜Lh with exception of columns having indexes a, b. For them, it must
hold
⎡
⎣
ω
1
1
0
La Lb
⎤
⎦
#
Da
Db
$ ⎡
⎣
ω
1
1
0
La Lb
⎤
⎦
′
=
⎡
⎣
1
0
˜ω
1
˜La ˜Lb
⎤
⎦
# ˜Da
˜Db
$ ⎡
⎣
1
0
˜ω
1
˜La ˜Lb
⎤
⎦
′
.
(8.11)
We proceed similarly as in the derivation of dydr but we exploit the special
form of entries aj, bj. Let us consider the regular (2,2)-matrices T =
#
x
1
y −ω
$
parameterized by scalars x, y. Their second column is orthogonal to the vector
occurring in the ﬁrst row of the ﬁrst matrix in (8.11). It holds
⎡
⎣
ω
1
1
0
La Lb
⎤
⎦T =
⎡
⎣
xω + y
0
x
1
xLa + yLb La −ωLb
⎤
⎦.
The desired “tilde” form is obtained if
˜La = xLa + yLb, ˜Lb = La −ωLb
xω + y = 1, T −1diag[Da, Db]

T −1′ = diagonal matrix.
The operator diag[·] converts the vector argument into the diagonal matrix
with the vector placed on the diagonal and the matrix argument into the
vector containing its diagonal.

250
8 Learning with normal factors and components
The unspeciﬁed values x, y have to be chosen so that the last two con-
straints are fulﬁlled. It gives
˜Da = Db + ω2Da, x = ωDa
˜Da
, y = Db
˜Da
, ˜Db = DaDb
˜Da
.
We also need to recover L′DL decomposition after permuting adjacent
entries. For the sake of completeness, we summarize it.
Proposition 8.5 (Permutation of adjacent entries in L′DL) Let V =
L′DL be the L′DL decomposition of the information matrix V corresponding
to the data Ψ = [d, ψ′]′ and parameter [−1, θ′]′ vectors. Let
ψ = [h′, a, b, c′]′, ˜ψ = [h′, b, a, c′]′ and θ = [θ′
h, θa, θb, θ′
c]′, ˜θ = [θ′
h, θb, θa, θ′
c]′
(8.12)
with scalars a, b, θa, θb. Then, the L′DL decomposition of ˜V = ˜L′ ˜D˜L de-
scribing the same quadratic form [−1, θ′]V [−1, θ′]′ = [−1, ˜θ′] ˜V [−1, ˜θ′]′ can
be obtained from the decomposition V = L′DL by the following algorithm.
1. Permute a and b columns of L up to main subdiagonal entry of the shorter
one.
2. Store the Dao = Da = entry of D corresponding to the regressor a.
3. Recompute Da = Db + ω2Da; ω denotes the second nonzero entry in the
longer nonzero part of the permuted columns.
4. Compute auxiliary quantities x = ωDao/Da, y = Db/Da.
5. Recompute the Db = DaoDb/Da entry of D corresponding to the regressor
b.
6. Store ath row La of L into Lao until the entry before ω.
7. Recompute La = xLa + yLb, where Lb contains entries in the adjacent
entries of the row b.
8. Recompute Lb = Lao −ωLb.
9. Correct ω = x.
Proof. The idea is identical with the proof of Proposition 8.4. The roles of
rows and columns are just reversed in corrections.
Complete squares and minimization of quadratic forms
Often, we deal with quadratic forms [−1, θ′]V [−1, θ]′ in a ˚
ψ+1-vector formed
by −1 and regression coeﬃcients θ. The kernel of this form is the extended
information matrix V , which is by construction positive deﬁnite. We assume
that the L′DL decomposition of V is available, V = L′DL.
Let us split the matrix V and its L′DL decomposition as follows.

8.1 Common tools
251
V =
#
⌊dV
⌊dψV ′
⌊dψV
⌊ψV
$
,
⌊dV is scalar,
L =
#
1
0
⌊dψL ⌊ψL
$
,
D =
# ⌊dD
0
0
⌊ψD
$
,
⌊dD is scalar.
(8.13)
From here onwards, when working with quadratic forms, the upper left index
in V, D, L indicates blocks obtained by splitting of the matrix according to
the element ordering in the corresponding data vector.
Proposition 8.6 (Completion of squares) It holds
[−1, θ′]V [−1, θ′]′ ≡[−1, θ′]L′DL[−1 θ′]′ = (θ −ˆθ)′ ⌊ψL′ ⌊ψD ⌊ψL(θ −ˆθ) + ⌊dD
ˆθ ≡⌊ψL−1 ⌊dψL ≡least-squares (LS) estimate of θ,
(8.14)
⌊dD ≡least-square remainder.
This quadratic form is minimized by θ = ˆθ. ⌊dD is to the minimum reached.
Proof. The straightforward vector-matrix multiplication for the split L′DL
decomposition proofs equality (8.14). It is known as completion of squares.
Due to the positive deﬁniteness of V, the term dependent of θ is nonnegative
and becomes zero for θ = ˆθ.
8.1.3 GiW pdf as a conjugate prior
Normal factors belong to the exponential family (see Section 3.2) so that they
possess conjugate (self-reproducing) prior. The following correspondence to
the general form of the exponential family (3.6) holds
Nd(θ′ψ, r) = A(Θ) exp[⟨B(Ψ), C(Θ)⟩] with
(8.15)
A(Θ) ≡(2πr)−0.5, B(Ψ) ≡ΨΨ ′, D(Ψ) = 0.
C(Θ) = (2r)−1[−1, θ′]′[−1, θ′],
⟨B, C⟩≡tr [B′C] .
This correspondence determines the conjugate prior (3.13) in the form known
as Gauss-inverse-Wishart pdf (GiW),
GiWΘ(V, ν)
≡GiWθ,r(V, ν) ≡r−0.5(ν+˚
ψ+2)
I(V, ν)
exp

−1
2rtr (V [−1, θ′]′[−1, θ′])

. (8.16)
The value of the normalization integral I(V, ν) and constraints on statistics
V, ν that guarantee ﬁniteness of I(V, ν) are described below, together with
other properties of this important pdf.
The (˚Ψ, ˚Ψ)-dimensional extended information matrix V can be chosen
to be symmetric. Its potential antisymmetric constituents disappear in the

252
8 Learning with normal factors and components
quadratic form in which it occurs. Moreover, the extended information ma-
trix must be positive deﬁnite. Otherwise, there are unbounded combinations
of θ entries for which the inspected function (8.16) does not fall to zero and
thus is not integrable.
Basic properties of the GiW pdf exploit the L′DL decomposition of the
extended information matrix, Agreement 8.1, and splitting (8.13).
Proposition 8.7 (Basic properties and moments of the GiW pdf)
1. GiWΘ(V, ν) has the following alternative expressions
GiWΘ(V, ν) ≡GiWΘ(L, D, ν) = r−0.5(ν+˚
ψ+2)
I(L, D, ν)
(8.17)
× exp

−1
2r
#
⌊ψLθ −⌊dψL
′ ⌊ψD

⌊ψLθ −⌊dψL

+ ⌊dD
$
≡r−0.5(ν+˚
ψ+2)
I(L, D, ν)
exp

−1
2r
	
(θ −ˆθ)′C−1(θ −ˆθ) + ⌊dD

≡r−0.5(ν+˚
ψ+2)
I(L, D, ν)
exp

−1
2r
	
Q(θ) + ⌊dD

,
where
ˆθ ≡⌊ψL−1 ⌊dψL ≡least-squares (LS) estimate of θ
(8.18)
C ≡⌊ψL−1 ⌊ψD−1 
⌊ψL′−1
≡covariance of LS estimate
(8.19)
⌊dD ≡least-squares remainder
(8.20)
Q(θ) ≡

θ −ˆθ
′
C−1 
θ −ˆθ

(8.21)
≡

⌊ψLθ −⌊dψL
′ ⌊ψD

⌊ψLθ −⌊dψL

.
2. The normalization integral is
I(L, D, ν) = Γ(0.5ν) ⌊dD−0.5ν !!! ⌊ψD
!!!
−0.5
20.5ν(2π)0.5˚
ψ
(8.22)
Γ(x) ≡
 ∞
0
zx−1 exp(−z) dz < ∞
for x > 0.
Thus, it is ﬁnite iﬀν > 0 and V is positive deﬁnite ⇔D > 0 (entrywise).
3. The GiW pdf has the following marginal pdfs and moments
f(r|L, D, ν) = r−0.5(ν+2)
I
 ⌊dD, ν
 exp
#
−
⌊dD
2r
$
≡iWr

⌊dD, ν

≡inverse Wishart pdf
(8.23)
I

⌊dD, ν

≡
Γ(0.5ν)

0.5 ⌊dD
0.5ν ≡normalization of f(r|L, D, ν).
E[r|L, D, ν] =
⌊dD
ν −2 ≡ˆr,
var[r|L, D, ν] =
2ˆr2
ν −4

8.1 Common tools
253
E[r−1|L, D, ν] =
ν
⌊dD
E[ln(r)|L, D, ν] = ln

⌊dD

−ln(2) −∂ln (Γ(0.5ν))
∂(0.5ν)
f(θ|L, D, ν) = I−1(D, ν)
×
#
1 +

⌊dD
−1 
θ −ˆθ
′ ⌊ψL′ ⌊ψD ⌊ψL

θ −ˆθ
$−0.5(ν+˚
ψ)
I(D, ν) ≡
⌊dD0.5˚
ψ /˚
ψ
i=1 Γ(0.5(ν + ˚
ψ −i))
!! ⌊ψD
!!0.5
≡normalization integral of f(θ|L, D, ν)
E[θ|L, D, ν] = ⌊ψL−1 ⌊dψL ≡ˆθ
cov[θ|L, D, ν] =
⌊dD
ν −2
⌊ψL−1 ⌊ψD−1 
⌊ψL′−1
≡ˆrC.
Proof. The majority of evaluations can be found in [69]. Here we ﬁx the most
important steps and evaluate the nonstandard quantities E[ln(r)|L, D, ν] and
E

r−1|L, D, ν

needed in Proposition 8.9.
1. The alternative form of GiW pdf relies on the completion of squares as
described in Proposition 8.6.
2. Let us put substitutions used in compound brackets within the sequence
of evaluations. Then, the normalization integral is evaluated as follows.
I(L, D, ν) ≡

r−0.5(ν+˚
ψ+2)
× exp

−1
2r
#
⌊ψLθ −⌊dψL
′ ⌊ψD

⌊ψLθ −⌊dψL

+ ⌊dD
$
dθdr
=

x ≡r−0.5 ⌊ψD0.5 
⌊ψLθ −⌊dψL

, dx = r−0.5˚
ψ !!! ⌊ψD
!!!
0.5
dθ

= (2π)0.5˚
ψ !!! ⌊ψD
!!!
−0.5  ∞
0
r−0.5(ν+2) exp
	
−0.5r−1 ⌊dD

dr
=

x = 0.5r−1 ⌊dD, r = 0.5 ⌊dDx−1, dr = −0.5 ⌊dDx−2dx

= (2π)0.5˚
ψ !!! ⌊ψD
!!!
−0.5 
0.5 ⌊dD
−0.5ν  ∞
0
x0.5(ν−2) exp(−x) dx
=

deﬁnition of Γ (·)
Γ(0.5ν) ⌊dD−0.5ν !!! ⌊ψD
!!!
−0.5
20.5ν(2π)0.5˚
ψ.
3. Integrating out θ in the previous step, we ﬁnd the marginal pdf of r
proportional to r−0.5(ν+2) exp
	
−
⌊dD
2r

. The corresponding normalization
integral is obtained as follows.

254
8 Learning with normal factors and components
I

⌊dD, ν

≡
 ∞
0
r−0.5(ν+2) exp
	
−0.5r−1 ⌊dD

dr
=

x = 0.5r−1 ⌊dD, r = 0.5 ⌊dDx−1, dr = −0.5 ⌊dDx−2dx

=

0.5 ⌊dD
−0.5ν
Γ(0.5ν).
4. Using the deﬁnition
I

⌊dD, ν

≡
Γ(0.5ν)

0.5 ⌊dD
0.5ν
of the normalizing factor in the marginal pdf of r (see (8.23)), we get
a) E

ri
= I
 ⌊dD, ν −2i

/I
 ⌊dD, ν

, i = . . . , −1, 0, 1, . . . , 0.5ν −1,
For i = 1, it gives E[r] =
0.5 ⌊dD
0.5(ν −2) =
⌊dD
ν −2.
For i = 2, it gives E

r2
=

0.5 ⌊dD
2
0.52(ν −2)(ν −4) ⇒
var(r) = E[r2] −(E[r])2 =
ˆr2
ν −4[ν −2 −(ν −4)] =
2ˆr2
ν −4.
For i = −1, it gives E

r−1
=

0.5 ⌊dD
−1
(0.5ν) =
ν
⌊dD.
b)
E[ln(r)|L, D, ν] ≡
1
I
 ⌊dD, ν

 ∞
0
ln(r)r−0.5(ν+2) exp

−
⌊dD
2r

dr
=
−2
I
 ⌊dD, ν

 ∞
0
∂
∂ν r−0.5(ν+2) exp

−
⌊dD
2r

dr
=
−2
I
 ⌊dD, ν
 ∂
∂ν
 ∞
0
r−0.5(ν+2) exp

−
⌊dD
2r

dr
= −2 ∂
∂ν ln

I

⌊dD, ν

= ln

⌊dD

−ln(2) −∂ln (Γ(0.5ν))
∂(0.5ν)
.
5. Marginal pdf of θ and corresponding moments are obtained as follows.
f(θ) ∝

r−0.5(ν+˚
ψ+2)
× exp

−0.5r−1 ⌊dD[1 + (θ −ˆθ)′ ⌊dD−1 ⌊ψL′ ⌊ψD ⌊ψL(θ −ˆθ)]

dr
=

r = 0.5 ⌊dD
#
1 +

θ −ˆθ
′ ⌊dD−1 ⌊ψL′ ⌊ψD ⌊ψL

θ −ˆθ
$
/x

∝
#
1 +

θ −ˆθ
′ ⌊dD−1 ⌊ψL′ ⌊ψD ⌊ψL

θ −ˆθ
$−0.5(ν+˚
ψ)
.

8.1 Common tools
255
Symmetry with respect to ˆθ implies that E[θ] = ˆθ. Moreover, neither
normalization integral nor covariance depend on ˆθ, thus we can write
without loss of generality the further formulas for the special case ˆθ = 0.
Substitution with the unit Jacobian x = ⌊ψLθ implies that the normalizing
integral does not depend on ⌊ψL and
I(D, ν) =
 	
1 + x′ ⌊dD−1 ⌊ψDx
−0.5(ν+˚
ψ)−2
dx
=

y =
	
⌊dD−1 ⌊ψD
0.5
x

=
⌊dD0.5˚
ψ ⌊ψD−0.5

(1 + y′y)−0.5(ν+˚
ψ−2) dy
=

see [156]
⌊dD0.5˚
ψ ⌊ψD−0.5
˚
ψ
 
i=1
Γ(0.5(ν + ˚
ψ −i)).
Using the fact that E[θ|r] = E[θ], the identity cov[θ|r] = E[θθ′|r]−E[θ]E[θ]′
and the chain rule for expectations, Proposition 2.6, we have
cov[θ] = E[θθ′] −E[θ]E[θ]′ = E [E[θθ′ −E[θ]E[θ]′|r]] = E[cov[θ|r]]
= E
#
r

⌊ψL′ ⌊ψD ⌊ψL
−1$
=
⌊dD
ν −2

⌊ψL′ ⌊ψD ⌊ψL
−1
.
We need also to evaluate marginal and conditional pdfs of regression co-
eﬃcients described by GiW pdf.
Proposition 8.8 (Low-dimensional pdfs related to GiW pdf) Let the
L′DL decomposition of the extended information matrix determining the pdf
GiW[ ⌊aθ′, ⌊bθ′]
′,r(L, D, ν) be split in accordance with the splitting of regression
coeﬃcients θ =
 ⌊aθ′, ⌊bθ′′
L ≡
⎡
⎣
1
⌊daL
⌊aL
⌊dbL ⌊abL ⌊bL
⎤
⎦,
D ≡
⎡
⎣
⌊dD
⌊aD
⌊bD
⎤
⎦.
Then,
f

⌊aθ, r

= GiW ⌊aθ,r
#
1
⌊daL ⌊aL
$
,
# ⌊dD
⌊aD
$
, ν

(8.24)
f

⌊bθ
!!! ⌊aθ, r

= N ⌊bθ

⌊bL−1 	
⌊dbL −⌊abL ⌊aθ

, r

⌊bL′ ⌊bD ⌊bL
−1
.
Proof.
GiW[ ⌊aθ′, ⌊bθ′]
′,r(L, D, ν) ∝r−0.5(ν+˚
ψ+2) exp

−1
2r×

256
8 Learning with normal factors and components
×
⎡
⎣
−1
⌊aθ
⌊bθ
⎤
⎦
′ ⎡
⎣
1
⌊daL
⌊aL
⌊dbL ⌊abL ⌊bL
⎤
⎦
′ ⎡
⎣
⌊dD
⌊aD
⌊bD
⎤
⎦
⎡
⎣
1
⌊daL
⌊aL
⌊dbL ⌊abL ⌊bL
⎤
⎦
⎡
⎣
−1
⌊aθ
⌊bθ
⎤
⎦
⎫
⎬
⎭
= r−−ν+ ⌊a˚
ψ+2
2
exp
"
−1
2r
# −1
⌊aθ
$′ #
1
⌊daL ⌊aL
$′ # ⌊dD
⌊aD
$ #
1
⌊daL ⌊aL
$ # −1
⌊aθ
$%



A
× r−0.5 ⌊b˚
ψ exp
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
−1
2r
⎡
⎣
−1
⌊aθ
⌊bθ
⎤
⎦
′
 ⌊dbL ⌊abL ⌊bL
′ ⌊bD
 ⌊dbL ⌊abL ⌊bL

⎡
⎣
−1
⌊aθ
⌊bθ
⎤
⎦



Q
⎫
⎪
⎪
⎪
⎪
⎪
⎬
⎪
⎪
⎪
⎪
⎪
⎭



B
.
Integration over ⌊bθ, with the substitution
x = r−0.5  ⌊dbL ⌊abL ⌊bL

⎡
⎣
−1
⌊aθ
⌊bθ
⎤
⎦,
concerns only the factor B. The integration result is independent both of r
and ⌊aθ. Thus, the factor A, which has the GiW form, is the marginal pdf of
 ⌊aθ, r

searched for.
Consequently, the factor B has to be pdf f
 ⌊bθ| ⌊aθ, r

. It is normal pdf.
Its moments are easily found by completing squares in the quadratic form Q
in the exponent
Q =

⌊bθ −E
	
⌊bθ
!!! ⌊aθ, r
′ ⌊bL′ ⌊bD ⌊bL

⌊bθ −E
	
⌊bθ
!!! ⌊aθ, r

,
E
	
⌊bθ
!!! ⌊aθ, r

≡E
	
⌊bθ
!!! ⌊aθ

= ⌊bL−1 	
⌊dbL −⌊abL ⌊aθ

.
The covariance is cov
 ⌊bθ
!! ⌊aθ, r

= cov
 ⌊bθ
!! r

= r
 ⌊bL′ ⌊bD ⌊bL
−1 .
Note that the result of Proposition is simple due to the chosen variant of
L′DL decomposition. The alternative version LDL′ is more complex.
Repeatedly, we need to evaluate the KL divergence of a pair of GiW pdfs.
Proposition 8.9 (The KL divergence of GiW pdfs) Let
f(Θ) = GiWΘ(L, D, ν), ˜f(Θ) = GiWΘ

˜L, ˜D, ˜ν

be a pair of GiW pdfs of
parameters Θ ≡(θ, r) = (regression coeﬃcients, noise variance). Let Dii
stand for the diagonal element of the matrix D. Then, the KL divergence of
f and ˜f is given by the formula
D

f
!!!
!!! ˜f

= ln
Γ(0.5˜ν)
Γ(0.5ν)

−0.5 ln
⎛
⎝
˚
Ψ
 
i=2
˜Dii
Dii
⎞
⎠+ 0.5˜ν ln
 ⌊dD
⌊d˜D

(8.25)

8.1 Common tools
257
+ 0.5(ν −˜ν)
∂
∂(0.5ν) ln (Γ(0.5ν)) −0.5˚
ψ
+ 0.5tr
#
⌊ψL−1 ⌊ψD−1 
⌊ψL′−1 ⌊ψ˜L′ ⌊ψ ˜D ⌊ψ˜L
$
+ 0.5 ν
⌊dD
#
ˆθ −ˆ˜θ
′ ⌊ψ˜L′ ⌊ψ ˜D ⌊ψ˜L

ˆθ −ˆ˜θ

−⌊dD + ⌊d˜D
$
≡ln
Γ (0.5˜ν)
Γ (0.5ν)

−0.5 ln
!!!C ˜C−1!!! + 0.5˜ν ln
 ⌊dD
⌊d˜D

+ 0.5(ν −˜ν)
∂
∂(0.5ν) ln (Γ(0.5ν)) −0.5˚
ψ −0.5ν + 0.5tr
	
C ˜C−1
+ 0.5 ν
⌊dD
#
ˆθ −ˆ˜θ
′ ˜C−1 
ˆθ −ˆ˜θ

+ ⌊d˜D
$
.
Proof. A substantial part of evaluations is prepared by Proposition 8.7. The
deﬁnition of the KL divergence (2.25) reads
D ≡D

f
!!!
!!! ˜f

=

f(Θ|L, D, ν) ln
⎛
⎝f(Θ|L, D, ν)
˜f

Θ|˜L, ˜D, ˜ν

⎞
⎠dΘ.
We write down the GiW pdf in a bit simpliﬁed form, cf. (8.19), (8.21),
f(Θ|L, D, ν) ≡GiWΘ(L, D, ν) = r−0.5(ν+˚
ψ+2)
I(L, D, ν)
exp

−1
2r
	
Q(θ) + ⌊dD

,
Q(θ) ≡

⌊ψLθ −⌊dψL
′ ⌊ψD

⌊ψLθ −⌊dψL

=

θ −⌊ψL−1 ⌊dψL
′ ⌊ψL′ ⌊ψD ⌊ψL

θ −⌊ψL−1 ⌊dψL

=

θ −ˆθ
′
C−1 
θ −ˆθ

,
where ˆθ ≡⌊ψL−1 ⌊dψL and C−1 = ⌊ψL′ ⌊ψD ⌊ψL. The same notation is used
for ˜f

Θ|˜L, ˜D, ˜ν

. If we recall that Θ = [θ, r], we can write
D = ln
⎛
⎝
I

˜L, ˜D, ˜ν

I (L, D, ν)
⎞
⎠
+ E
#
−0.5(ν −˜ν) ln(r) −1
2r

Q(θ) + ⌊dD −˜Q(θ) −⌊d˜D
!!!! L, D, ν
$
= ln
⎛
⎝
I

˜L, ˜D, ˜ν

I(L, D, ν)
⎞
⎠−0.5(ν −˜ν)
#
ln

⌊dD

−ln(2) −∂ln (Γ(0.5ν))
∂(0.5ν)
$
−0.5 E

r−1 	
Q(θ) −˜Q(θ)
!!! L, D, ν




X
+ ν
⌊dD
	
−⌊dD + ⌊d˜D

.
(8.26)

258
8 Learning with normal factors and components
The the chain rule for expectations, Proposition 2.6, and the formula in (8.23)
for E

r−1
help us to evaluate the last term X.
X = ˚
ψ −tr
	
C ˜C−1
+
ν
⌊dD
#
−

ˆθ −ˆ˜θ
′ ˜C−1 
ˆθ −ˆ˜θ
$
.
We substitute this result and explicit formulas for I(L, D, ν) and I(˜L, ˜D, ˜ν)
into (8.26). Taking into account the form of I(V, ν) and I( ˜V , ˜ν), the result
reads
D = ln
Γ(0.5˜ν)
Γ(0.5ν)

−0.5 ln
⎛
⎝
!!! ⌊ψ ˜D
!!!
!! ⌊ψD
!!
⎞
⎠+ 0.5˜ν ln
 ⌊dD
⌊d˜D

+ 0.5(ν −˜ν)
∂
∂(0.5ν) ln (Γ(0.5ν)) −0.5˚
ψ + 0.5tr
	
C ˜C−1
+ 0.5 ν
⌊dD
#
ˆθ −ˆ˜θ
′ ˜C−1 
ˆθ −ˆ˜θ

−⌊dD + ⌊d˜D
$
.
This alternative relates the considered L′DL decomposition to the LS quan-
tities; see Proposition 8.7.
8.1.4 KL divergence of normal pdfs
The KL divergence serves us as a good measure when judging distance of pairs
of normal factors or components in the data space. It serves in the parameter
space too when dealing with so called MT normal factors; see Chapters 12
and 13. Its value can be computed as follows.
Proposition 8.10 (KL divergence of normal pdfs)
The KL divergence
(2.25) of the normal pdfs f(d) = Nd(M, R), ˜f(d) = Nd( ˜
M, ˜R) is given by the
formula
D

f
!!!
!!! ˜f

= 1
2
#
ln
!!! ˜RR−1!!! −˚
d + tr
	
R ˜R−1
+

M −˜
M
′ ˜R−1 
M −˜
M
$
.
(8.27)
Let us consider a pair of normal pdfs in factorized forms, i∗≡{1, . . . , ˚
d},
f(dt|d(t−1)) =
 
i∈i∗
Ndi(θ′
iψi;t, ri),
⌊Uf(dt|d(t−1)) =
 
i∈i∗
Ndi

⌊Uθ′
i
⌊Uψi;t, ⌊Uri

with known regression vectors ψi;t, ⌊Uψi;t, regression coeﬃcients θ′
i, ⌊Uθ′
i and
variance ri, ⌊Uri, i ∈i∗. Then, the KL divergence of ith factors, conditioned
on ψi;t, ⌊Uψi;t, is
D

f(di|ψi;t)
!!!
!!! ⌊Uf

di| ⌊Uψi;t
 !!! ψi;t, ⌊Uψi;t

(8.28)
= 1
2

ln
 ⌊Uri
ri

−1 +
ri
⌊Uri
+

θ′
iψi;t −⌊Uθ′
i
⌊Uψi;t
2
⌊Uri

.

8.1 Common tools
259
Proof. The deﬁnitions of the KL divergence, normal pdfs and the identity
E[x′Qx] = [E(x)]′QE[x] + tr[cov(x)Q] imply
2D

f
!!!
!!! ˜f

≡ln

!!! ˜RR−1!!!

+ 2

Nd(M, R)
#
−(d −M)′R−1(d −M) +

d −˜
M
′ ˜R−1 
d −˜
M
$
dd
= ln

!!! ˜RR−1!!!

−tr

RR−1
+

M −˜
M
′ ˜R−1 
M −˜
M

+ tr

R ˜R−1
.
The factor version is obtained by a direct substitution of moments.
8.1.5 Estimation and prediction with normal factors
The normal factors predicting a real-valued scalar d belong to the exponen-
tial family. Consequently, their estimation and the corresponding prediction
reduce to algebraic operations; see Proposition 3.2.
Proposition 8.11 (Estimation and prediction of the normal factor)
Let natural conditions of decision making, Requirement 2.5, hold. The treated
factor (8.1) is supposed to be normal. A conjugate prior pdf (3.13) GiWΘ(V0, ν0)
as well as conjugate alternative GiWΘ( ⌊AVt, ⌊Aνt) in the stabilized forgetting
are used; see Section 3.1. Then, the posterior pdf is GiWΘ(Vt, νt) and its
suﬃcient statistics evolve according to the recursions
Vt = λ(Vt−1 + ΨtΨ ′
t) + (1 −λ) ⌊AVt,
V0 given by the prior pdf
νt = λ(νt−1 + 1) + (1 −λ) ⌊Aνt,
ν0 > 0 given by the prior pdf. (8.29)
The used forgetting factor λ ∈[0, 1].
The predictive pdf is Student pdf. For any data vector Ψ = [d, ψ′]′, its
values can be found numerically as the ratio
f(d|ψ, V, ν) = I (V + ΨΨ ′, ν + 1)
√
2πI(V, ν)
,
or
(8.30)
f(d|ψ, L, D, ν) =
Γ(0.5(ν + 1))
 ⌊dD(1 + ζ)
−0.5
√πΓ(0.5ν)

1 +
ˆe2
⌊dD(1+ζ)
0.5(ν+1) ,
where
(8.31)
ˆe ≡d −ˆθ′ψ ≡prediction error
ˆθ = ⌊ψL−1 ⌊dψL, ζ ≡ψ′ ⌊ψL−1 ⌊ψD−1 
⌊ψL′−1
ψ
cf. Proposition 8.7.
Proof. The ﬁrst form is directly implied by Proposition 2.14. We use it while
•
exploiting the form of the normalizing factor I(L, D, ν), Proposition 8.7,
•
respecting relationships among various forms of statistics, and basic alge-
braic formulas; Proposition 8.1.

260
8 Learning with normal factors and components
It gives
f(d|ψ, L, D, ν) = Γ(0.5(ν + 1))
√πΓ(0.5ν)
×
!!C−1!!0.5ν !!C−1 + ψψ′!!−0.5ν 
⌊dD
−0.5
|V |0.5(ν+1)|V + ΨΨ ′|−0.5(ν+1)
= Γ(0.5(ν + 1))
√πΓ(0.5ν)
× |C|−0.5ν(1 + ζ)−0.5ν ⌊dD−0.5 
1 + Ψ ′L−1D−1 
L−1′ Ψ
−0.5(ν+1)
=
Γ(0.5(ν + 1))
√πΓ(0.5ν)
 ⌊dD(1 + ζ)
−0.5

1 +
ˆe2
⌊dD(1 + ζ)
−0.5(ν+1)
.
We also used the identity Ψ ′L−1D−1 
L−1′ Ψ = ˆe2/ ⌊dD + ζ. Note that the
majority of evaluations are in [69].
Remark(s) 8.2
1. The recursion (8.29) is practically replaced by updating the L′DL decom-
position of the extended information matrix according to Algorithm 8.2.
In order to cope with the stabilized forgetting,
a) the updated D is multiplied by λ,
b) the data vector Ψ is replaced by
√
λΨ,
c) the L′DL decomposition of ⌊AVt is taken as the sum of weighted dyads
formed by

kth row of ⌊ALt
′
(1 −λ) ⌊ADk;t

kth row of ⌊ALt

, k = 1, . . . , ˚Ψ.
2. The extensive use of the L′DL decomposition is vital for numerical stabil-
ity of computations. Experience conﬁrms that without it, safe processing
of real data records with target dimensions (˚Ψ around hundreds) is impos-
sible. Moreover, the evaluation of the determinants occurring in various
pdfs becomes simple with the L′DL decomposition.
3. The predictive pdf is the key element needed in approximate estimation,
Section 8.5, and for comparing variants through v-likelihood, Section 6.1.2.
It is thus worthwhile to check which of the versions (8.30), (8.31) is com-
putationally simpler. The latter one has the added advantage that the pre-
diction errors {ˆet}t∈t∗are suited for an intuitively plausible judgement of
the predictive properties of the inspected factor. The form (8.31) of the
Student pdf is suited for evaluating likelihood function when LS parameter
estimates ˆθ, ⌊dD are ﬁxed.
4. The performed evaluations are closely related to least squares and its re-
cursive version; see e.g., [69].

8.1 Common tools
261
8.1.6 Estimation and prediction with log-normal factors
The applicability of the studied model can be simply extended by modelling
and predicting unknown-parameter free, one-to-one, transformations of dt;
see Subsection 6.2.4 and [69]. Almost everything remains the same. Only mo-
ments of the original dt have to be derived. Log-normal parameterized factor
predicting ln(dt) represents the most practical instance of this generalization.
It allows us to deal with positive data having a relatively heavy-tailed pdf.
The log-normal parameterized factor models a positive scalar quantity d
by the pdf
f(d|ψ, Θ) = LN d(θ′ψ, r), where
(8.32)
Θ ≡[θ, r] ≡[regression coeﬃcients, noise variance]
∈Θ∗⊂(˚
ψ-dimensional, nonnegative) reals
ψ ≡regression vector,
Ψ = [ln(d), ψ′]′ ≡data vector
LN d(θ′ψ, r) ≡(2πr)−0.5d−1 exp
"
−(ln(d) −θ′ψ)2
2r
%
= (2πr)−0.5d−1 exp

−1
2rtr (ΨΨ ′[−1, θ′]′[−1, θ′])

.
Log-normal parameterized factors belong to the exponential family (see Sec-
tion 3.2) so that they possess conjugate (self-reproducing) prior. The following
correspondence to (3.6) holds
LN d(θ′ψ, r) = A(Θ) exp[⟨B(Ψ), C(Θ) + D(Ψ)⟩] with
A(Θ) ≡(2πr)−0.5, B(Ψ) ≡ΨΨ ′, C(Θ) ≡2r−1 [−1, θ′]′ [−1, θ′]
D(Ψ) ≡ln
1
d

,
⟨B, C⟩≡tr [B′C] .
(8.33)
The factor exp (D(Ψ)) ≡d−1 could be included into B(Ψ). It has, however,
no inﬂuence on estimation. For this reason, it is kept separately.
The correspondence determines the conjugate prior (3.13) in the form of
the Gauss-inverse-Wishart pdf (GiW); see (8.16). The estimation studied in
connection with normal models remains obviously unchanged. The prediction
is slightly inﬂuenced by the factor d−1 in (8.33).
Proposition 8.12 (Estimation and prediction of log-normal factors)
Let natural conditions of decision making, Requirement 2.5, hold. The treated
factor (8.32) is log-normal and a conjugate prior (3.13) GiWΘ(V0, ν0) as well
as a conjugate alternative GiWΘ( ⌊AVt, ⌊Aνt) in the stabilized forgetting are
used; see Section 3.1. Then, the posterior pdf is GiWΘ(Vt, νt) and its suﬃ-
cient statistics evolve according to the recursions
Vt = λ(Vt−1 + ΨtΨ ′
t) + (1 −λ) ⌊AVt, V0 given by the prior pdf
νt = λ(νt−1 + 1) + (1 −λ) ⌊Aνt,
ν0 given by the prior pdf .

262
8 Learning with normal factors and components
The predictive pdf is log-Student pdf. Its values can be numerically evaluated,
for any data vector Ψ = [ln(d), ψ′]′, as the ratio
f(d|ψ, V, ν) = I (V + ΨΨ ′, ν + 1)
√
2πd I(V, ν)
,
see Proposition 2.14, or
f(d|ψ, L, D, ν) =
Γ(0.5(ν + 1))
 ⌊dD(1 + ζ)
−0.5
d√πΓ(0.5ν)

1 +
ˆe2
⌊dD(1+ζ)
0.5(ν+1) ,
where (8.34)
ˆe ≡ln(d) −ˆθ′ψ ≡prediction error
ˆθ = ⌊ψL−1 ⌊dψL, ζ = ψ′ ⌊ψL−1 ⌊ψD−1 
⌊ψL′−1
ψ.
Proof. It just copies Proposition 8.11 with d−1 included into the parameter-
ized model and with ln(d) replacing d.
8.1.7 Relationships of a component to its factors
We deal with the factor-based description of components f(dt|φt−1, Θ); see
Agreement 5.4. They deﬁne the component through the chain rule
f(dt|φt−1, Θ) =
 
i∈i∗
f(di;t|ψi;t, Θi).
For speciﬁcation of simulation examples and for interpretation of estimation
results, it is useful to relate the normal component to its factors in a detail.
This task is addressed here.
It is known that conditional pdfs of a normal pdf are again normal. Thus,
it is suﬃcient to inspect ﬁrst and second moments.
Proposition 8.13 (Normal component and its factors)
I. Let us consider the matrix form of a normal component [160]
f

dt
!!!φt−1, ⌊Mθ, ⌊eR

= Ndt

⌊Mθ′φt−1, ⌊eL′ ⌊eD ⌊eL

,
where
(8.35)
⌊Mθ is (˚φ, ˚
d)-matrix of unknown regression coeﬃcients,
⌊eL, ⌊eD deﬁne the L′DL decomposition of the unknown noise-covariance
matrix ⌊eR.
Then, the ith parameterized factor is
f(di;t|ψi;t, Θi) = Ndi;t

θ′
iψi;t, ⌊eDi

,
where
(8.36)
ψi;t = [d′
(i+1)···˚i;t, φ′
t−1]′ = [di+1;t, ψ′
i+1;t]′, i < ˚
d, ψ˚
d;t ≡φt−1 and
θ′
i =
	 ⌊eL′−1 −I,
 ⌊eL′−1 ⌊Mθ′
i, where the operation [ ]i selects the ith
row of the matrix in its argument and omits leading zeros.

8.1 Common tools
263
II. Let the normal parameterized factors
f(di;t|ψi;t, Θi) = Ndi;t (θ′
iψi;t, ri)
(8.37)
be ordered so that ψi;t is a subvector of
	
d′
(i+1)···˚i;t, φ′
t−1
′
. Let us extend re-
gression coeﬃcients θi to ¯θi by inserting zeros at appropriate places so that
θ′
iψi;t = ¯θ′
i

d′
t, φ′
t−1
′. The vector ¯θ′
i has at least i leading zeros. Let us create

˚
d, ˚
d

-upper triangular matrix η1 having unit diagonal and −¯θij value on the
position 1 < i < j ≤˚
d,

˚
d, ˚φ

-matrix η2 with the value ¯θi(j+˚
d) on the position i ∈{1, . . . , ˚
d},
j ∈{1, . . . , ˚φ}.
Then, these factors form normal component (8.35) with the moments
⌊eL′ = η−1
1 ,
⌊Mθ′ = ⌊eL′η2 and
⌊eDi = ri.
(8.38)
Proof. By a direct comparison of moments.
The derived relationships suit whenever uncertainty of parameters can be
neglected. This is the case, for instance, when we specify simulation.
The situation is more complex when information on parameters Θ was
obtained through a parameter estimation. Then, the predictive pdfs describing
individual factors have Student pdf (8.31). It is known that this pdf resembles
the normal pdf with the same moments whenever ν is high enough. The values
above 20 make this approximation excellent. Thus, for a given factor, we get
the correspondence required; see (8.23) and (8.31),
ˆθ ↔θ and ˆr(1 + ζ) ↔r.
(8.39)
This observation gives the algorithm for creating an approximate normal com-
ponent from incompletely estimated factors.
Algorithm 8.4 (Approximate component from uncertain factors)
For all factors i ∈i∗let us have suﬃcient statistics Li, Di, νi determining the
corresponding GiW pdfs.
1. For i ∈i∗,
•
Compute vectors of parameter estimates θi ≡
⌊ψL−1
i
⌊dψLi and hi =
⌊ψL−1
i ψi;t.
•
Deﬁne ri ≡
⌊dDi
νi

1 + 2˚
d
j=1
h2
ij
⌊ψDij

, where hij, ⌊ψDij are jth entries
of hi and of ⌊ψDij diagonal.
2. Apply the transformation described in II. of Proposition 8.13.

264
8 Learning with normal factors and components
Remark(s) 8.3
1. The variance of the factor output (cf. Algorithm 8.4) is greater than the
estimate ˆr of the noise variance. The increase by the factor 1+ζi;t reﬂects
a projection of parameter uncertainties to the direction of the regression
vector ψi;t. The increase is obviously data dependent.
2. The needed inversion of the triangular matrix ⌊ψL is eﬃciently performed
by a backward elimination with two-column right-hand side of the set of
linear equations ⌊ψL
	
ˆθ, h

=
 ⌊dψL, ψ

.
Problem 8.1 (Exact relationships of factors to component) It is worth-
while to ﬁnd the studied relationships without the crude approximation adopted.
8.1.8 Prediction and model selection
This subsection provides predictors based on normal mixtures. They are re-
peatedly used for selection of a model among several available alternatives.
Proposition 8.11 leads immediately to a normal variant of Proposition 6.1.
Proposition 8.14 (Normal-mixture, one-step-ahead predictor) Let
the prior and posterior estimates of the normal mixture have the form (6.3)
f(Θ|d(t)) = Diα(κt)
 
c∈c∗
 
i∈i∗
f(Θic|d(t)), t ∈{0} ∪t∗.
The Dirichlet pdf Diα(κt) is the estimate of component weights α (Agreement
5.4) and has the expected value
ˆαc;t =
κc;t
2
˜c∈c∗κ˜c;t
.
Let the estimates of the individual normal factors be GiW pdfs (8.16)
f(Θic|d(t)) = GiWθic,ric(Lic;t, Dic;t, νic;t).
Then, the estimation within the adaptive advisory system provides the value
of the one-step-ahead predictor at a possible data point dt+1 in the form
f(dt+1|d(t)) =

c∈c∗
ˆαc;t
 
i∈i∗
f(dic;t+1|d(t), c)
with
(8.40)
f(dic;t+1|d(t), c) = I(Vic;t + Ψic;t+1Ψ ′
ic;t+1, νic;t + 1)
√
2πI(Vic;t, νic;t)
I(Vic;t, νic;t) ≡I (Lic;t, Dic;t, νic;t)
= Γ (0.5νic;t)

⌊dDic;t
−0.5νic;t !!! ⌊ψicDic;t
!!!
−0.5
20.5νic;t(2π)0.5˚
ψic
Vic;t ≡L′
ic;tDic;tLic;t
is the extended information matrix of the factor ic at time t
νic;t ≡the number of degrees of freedom of the factor ic at time t.

8.1 Common tools
265
The predictive pdf for a factor ic can be given the alternative form (8.31).
We show it explicitly in the following speciﬁcation of the predictor in the
ﬁxed advisory system, when the measured data do not enter the condition of
the pdf on parameters, f(Θ|d(t)) ≡f(Θ). The mixture predictor for the ﬁxed
advisory system is
f(dt+1|d(t)) ≡

c∈c∗
ˆαc;0
 
i∈i∗

f(dic;t+1|ψic;t+1, Θic, c)f(Θic) dΘic



f(dic;t+1|ψic;t+1,c)
, where
f(dic;t+1|ψic;t+1, c) =
Γ(0.5(νic;0 + 1))
 ⌊dDic;0(1 + ζic;t+1)
−0.5
√πΓ(0.5νic;0)

1 +
ˆe2
ic;t+1
⌊dDic;0(1+ζic;t+1)
0.5(νic;0+1)
ˆeic;t+1 = dic;t+1 −ˆθ′
ic;0ψic;t+1 ≡prediction error of the ﬁxed predictor
ζic;t+1 = ψ′
ic;t+1
⌊ψicL−1
ic;0
⌊ψicD−1
ic;0

⌊ψicL′
ic;0
−1
ψic;t+1.
(8.41)
In both types of advisory systems, D = diag
 ⌊dD, ⌊ψD

, L =
#
1
0
⌊dψL ⌊ψL
$
,
ˆθ = ⌊ψL−1 ⌊dψL.
Proof. Omitted.
8.1.9 Likelihood on variants
During the design phase of the p-system, predictors serve for selecting the best
initialization, forgetting, structure, etc. For the adaptive advisory system, the
v-likelihood is the product of one-step-ahead predictors. For the ﬁxed advisory
system, such a product is an approximate v-likelihood; see Section (6.1.2).
It is good news that in both cases one-step-ahead predictors of the mixture
do not reﬂect the way statistics were collected. Thus, their product serves well
as a v-likelihood even when comparing various estimation variants.
8.1.10 Branch-and-bound techniques
For normal parameterized factors with conjugate prior pdfs, various esti-
mates of factors GiWθ,r(V, ν) are alternative descriptions inspected and com-
pared. Thus, alternative sets of suﬃcient statistics V, ν, or their factorized and
shifted equivalents L, D, ν, are branched and bounded as outlined in Section
6.1.3. The maximized functional F then becomes the function, namely, the
v-likelihood f(d(˚t)|V, ν) of data d(˚t) conditioned on the variant of suﬃcient
statistics V, ν. These statistics determine the GiWθ,r(V, ν) pdf that is used for
eliminating unknown parameters
f(d(˚t)|V, ν) =

f(d(˚t)|θ, r)GiWθ,r(V, ν) dθ dr.

266
8 Learning with normal factors and components
Evaluation of these v-likelihood values for normal mixtures is implied by
Proposition 8.14. Speciﬁc versions of the branch-and-bound techniques are
described in Section 8.4.
8.2 Data preprocessing
Data preprocessing is universally discussed in Chapter 6. Here, just some
speciﬁc comments are made.
8.2.1 Use of physical boundaries
Normal pdfs are symmetric around the expected value and positive on the
whole real line. The tails of this pdf fall down rather quickly. This can be ex-
ploited when respecting known physical boundaries. Individual signals should
be scaled and shifted according to the physically expected range. For standard-
ization purposes, it is useful to scale them so that the middle of this range
is mapped to zero and 70% boundaries to unity. It simpliﬁes the universal
outlier detection.
8.2.2 Removal of high-frequency noise
Normal mixtures can be perceived as a collection of local normal regression
models. Their estimation is known to be sensitive to the presence of a high-
frequency measurement noise. It has to be removed before using these data
for the normal mixture estimation. The general local ﬁlters exploiting over-
sampling of data are expected to suit this task. Use of normal ARMAX factors
is worth being considered. Recall that the ARMAX model is an extension of
the normal regression model that allows colored noise modelled by the moving-
average process. At least the case with the known MA part, [145], is directly
applicable. A promising extension to the unknown MA part is in [144].
8.2.3 Suppression of outliers
Outliers strictly contradict the nature of the normal model that has very light
tails. Thus, their removal is crucial for obtaining reliable results. It corresponds
to a well-known observation that least squares, which form the algorithmic
core of estimation of normal mixtures, are sensitive to outlying data. Local
ﬁlters [142] and simple mixtures [161] may serve for the discussed removal.
8.3 Use of prior knowledge at the factor level
Knowledge elicitation at the factor level (Section 6.3) is specialized here to
the normal factors.

8.3 Use of prior knowledge at the factor level
267
8.3.1 Internally consistent ﬁctitious data blocks
Processing of internally consistent data blocks coincides with learning normal
factors; see Section 8.1.5. Thus, we have to quantify individual knowledge
items only and then specialize merging of the individual estimates f(Θ|Kk)
expressing knowledge items K(˚k).
8.3.2 Translation of input–output characteristics into data
The quantiﬁed knowledge is assumed in the form of the initial moments ˆd, rd
(6.26) of the predictive pdf f(d|ψ) given by a ﬁxed regression vector ψ
ˆd =

d f(d|ψ) dd, rd =
 
d −ˆd
2
f(d|ψ) dd.
(8.42)
It reﬂects the knowledge (6.25) with h(ψ) =
	
ˆd, rd

, H(Ψ) =
	
d, (d −ˆd)2
.
The function g(ψ, Θ) that serves the optimal quantiﬁcation of this knowledge
(see Proposition 6.4) has the form
g(ψ, Θ) =
	
θ′ψ, (θ′ψ −ˆd)2 + r

.
(8.43)
With this function, the pdf f(Θ|K) constructed according to Proposition 6.4
falls out of the GiW class even with the pre-prior pdf chosen within it. For this
reason, we perform the optimization described in the cited proposition under
the additional requirement: the optimum is searched for within the GiW class.
Proposition 8.15 (Knowledge of input–output characteristics) Let us
consider GiW pdfs determined by least-squares statistics ˆθ, ˆr, C, ν; see Propo-
sition 8.7. The GiW pdf that fulﬁlls constraints (8.42) and minimizes the KL
divergence to the ﬂat pre-prior GiW — given by zero parameters estimate,
noise variance ε > 0, covariance factor of LS estimate 1/ε2I and degrees of
freedom ν = ε < 1 — has the least-squares statistics
ˆθ =
ˆdψ
ψ′ψ ,
C−1 = ε2(I + xψψ′),
ˆr = rd
ε2(1 + xψ′ψ)
ε2(1 + xψ′ψ) + ψ′ψ ,
(8.44)
where x is the unique (largest) solution of the equation
x +
ε2(1 + xψ′ψ)
ε2(1 + xψ′ψ) + ψ′ψ =
ˆd2
ψ′ψ + 1/ε
rd
.
(8.45)
For a ≡(ψ′ψ)−1, b ≡r−1
d
	
ˆd2a + ε−1
, it has the form
x = 0.5
	
−(a + ε−2 + 1 −b) +
?
(a + ε−2 + 1 −b)2 + 4a(b + ba −1)

.
(8.46)
Degrees of freedom ν should be unchanged.

268
8 Learning with normal factors and components
Proof. The proof is straightforward but lengthy and error prone. For this
reason, we present it in detail.
1. We express the optimized KL divergence (8.25) in terms of least-squares
statistics. At the same time, we rearrange it, insert the considered speciﬁc
form of the pre-prior pdf ¯f and omit terms not inﬂuencing optimization.
It gives the minimized function in the form
F(ˆθ, ˆr, C, ν)
= −ln(Γ(0.5ν)) + 0.5(ν −ε)
∂
∂(0.5ν) ln (Γ(0.5ν)) + 0.5ε2 ln(ν) −0.5ν



˜
F (ν)
+ 0.5

−ln |C| + ε2tr[C]

+ 0.5ε2 ln (ˆr) + 0.51
ˆr
	
ε2ˆθ′ˆθ + ε

.
2. The constraints on moments of the predictor are
ˆd = ˆθ′ψ,
rd = ˆr (1 + ψ′Cψ) ≡ˆr(1 + ζ), ζ ≡ψ′Cψ.
3. The minimization of F(·) with respect to ˆθ gives directly ˆθ =
ˆdψ
ψ′ψ irre-
spective of other optimized quantities.
4. Inserting the found ˆθ into the optimized functional and using the second
constraint for expressing ˆr, we get the following function to be minimized
with respect to C.
F(C) = 0.5

−ln |C| + ε2tr[C]

−0.5ε2 ln(1 + ζ) + 0.5ζε2B
B ≡
ˆd2
ψ′ψ + ε−1
⌊dr
.
Taking its derivatives with respect to C, using ∂ln |C|
∂C
= C−1 (see (8.6)),
we get necessary condition for minimum
C−1 = ε2
#
I +

B −
1
1 + ζ

ψψ′
$
.
Denoting x = B −
1
1+ζ , we get the optimal form of C.
5. We solve the above implicit (ζ = ψ′Cψ) equation. Using the matrix in-
version lemma, formula (8.5), and the deﬁnition of ζ, we get
ζ = ε−2
ψ′ψ
1 + xψ′ψ .
Deﬁnition of x in the previous step and an algebraic rearrangement give
x + 1/(1 + ζ) = B ⇒x +
1
1 + ε−2
xψ′ψ
1+xψ′ψ
= B
⇒x +
ε2(1 + xψ′ψ)
ε2(1 + xψ′ψ) + xψ′ψ = B.

8.3 Use of prior knowledge at the factor level
269
This is the equation (8.45) to be proved. It can be converted into a
quadratic equation for x and solved, but this form shows clearly that it has
a solution. Its right-hand side is always positive. The left-hand side can be
made arbitrarily large for positive x and when x →−(ψ′ψ)−1 is negative.
Within the admissible range when x > −(ψ′ψ)−1, which makes the con-
structed C positive deﬁnite, the left-hand side is continuous. Consequently,
a real admissible solution exists. A direct inspection shows that just one
formal solution guarantees positive deﬁniteness of C, i.e., x > −1/(ψ′ψ).
Equation (8.46) gives the explicit form of the solution.
6. Expressing ˆr in term of x, we get
ˆr =
rd
1 + ζ =
rdε2(1 + xψ′ψ)
ε2(1 + xψ′ψ) + ψ′ψ .
7. It remains to ﬁnd the minimizing argument of the part ˜F(ν) that depends
on ν only. The necessary condition for the extreme reads
1 = 0.5(ν −ε)∂2 ln(Γ(0.5ν))
∂2(0.5ν)
+ ε
ν .
It is fulﬁlled for ν = ε. The explicit evaluation of the factor at ν −ε and
use of the Jensen inequality imply that the factor at ν = ε is positive.
Thus, the right-hand side of this equation is 1 for ν = ε only.
8.3.3 Merging of knowledge pieces
We have a collection of factor estimates f(Θ|Kk) = GiWθ,r(Vk, νk) k ∈k∗≡

1, . . . ,˚k

after processing individual, internally consistent, data blocks and
individual knowledge items. We have to use them for constructing of a single
posterior pdf ˆf(Θ|d(˚t), K(˚k)) = GiWθ,r(V˚t, ν˚t) that puts them together with
available real data d(˚t). For this, Proposition 6.5 is applied. It leads directly
to the GiW counterpart of Algorithm 6.3.
Algorithm 8.5 (Merging GiW information sources)
1. Construct the prior factor estimates GiWθ,r(Vk, νk) reﬂecting internally
consistent data blocks by applying ordinary Bayesian estimation or reﬂect-
ing individual knowledge pieces and constructed according to Proposition
8.15. The least-squares representation of the latter case has to be trans-
formed to the (V, ν)-description using the relationships (8.17).
2. Evaluate the likelihood function L(Θ, d(˚t)) = GiWθ,r(V0;˚t, ν0;˚t) by applying
Proposition 8.11 with zero initial conditions for V, ν.

270
8 Learning with normal factors and components
3. Evaluate the posterior pdfs f(Θ|d(t), Kk) = GiWθ,r(V0;˚t + Vk, ν0;˚t + νk)
and the v-likelihoods
f(d(˚t)|Kk) = I(V0;˚t + Vk, ν0;˚t + νk)
I(Vk, νk)
corresponding to the prior pdfs f(Θ|Kk) = GiWθ,r(Vk, νk), k ∈k∗. The
integral I(V, ν) is given by the formula (8.22) expressed in terms of prac-
tically used L′DL decomposition of information matrix V . The regular-
ization by a ﬂat pre-prior pdf GiWθ,r(εI, ε), given by small ε > 0 has to
be considered if some Vk is singular.
4. Evaluate the weights
βk|d(˚t) =
f(d(˚t)|Kk)
2
˜k∈k∗f(d(˚t)|K˜k) =
I(V0;˚
t+Vk,ν0;˚
t+νk)
I(Vk,νk)
2
˜k∈k∗
I(V0;˚
t+V˜k,ν0;˚
t+ν˜k)
I(V˜k,ν˜k)
, k ∈k∗.
5. Determine the merger as the posterior pdf to be used
ˆf(Θ|d(˚t), K(˚k)) = GiWθ,r
0
V0;˚t +

k∈k∗
βk|d(˚t)Vk, ν0;˚t +

k∈k∗
βk|d(˚t)νk
1
= GiWθ,r(V0;˚t, ν0;˚t)GiWθ,r
0 
k∈k∗
βk|d(˚t)Vk,

k∈k∗
βk|d(˚t)νk
1
.
Notice that the eﬀectively used “prior pdf” is seen in the above formula.
8.4 Construction of the prior estimate
Eﬃcient solution of the initialization problem is vital for a proper mixture
estimation. At the general level, it is discussed in Section 6.4. Here, its relevant
Gaussian counterpart is elaborated.
We apply the general branch-and-bound techniques (Section 6.1.3) for
solving the initialization problem. Here and in the subsequent sections ap-
propriate specializations are presented.
8.4.1 Common bounding mapping
As said in Section 6.4.2, the common bounding mapping just cancels the “least
ﬁt candidates”. For normal mixtures, the posterior pdfs are described by the
vector statistics κ, related to the component weights, and by the collection
of the extended information matrices Vic together with degrees of freedom
νic, i ∈i∗≡{1, . . . , ˚
d}, c ∈c∗. These are ﬁnite-dimensional objects. They
may contain, however, a huge number of entries. Taking, for instance, the
simplest static case without common factors, the single alternative represents

8.4 Construction of the prior estimate
271
˚c[1 + (˚
d + 1)(˚
d + 2)/2] numbers. For the target dimensions 30 −40, it gives
about 1000 numbers even for ˚c = 2. It indicates that we face two contradictory
requirements on the bounding mapping. We have to
•
preserve as much information as possible from previous iteration steps,
•
store and treat as few as possible alternatives.
We found no general guideline as to how to reach the adequate compromise.
At present, we prefer the second item and bound the number of alternatives
to two, at most to three.
8.4.2 Flattening mapping
Solution of the initialization problem is based on iterative processing of avail-
able learning data d(˚t). The danger of a plain repetitive use of the Bayes rule,
discussed at general level in Section 6.4.1, becomes even more obvious when
applied to normal factors. Within the class of conjugate GiW pdfs, the ˚nth
“naive” approximate evaluation of the posterior pdf gives
GiWθ,r
0 ˚n

n=1
Vn;˚t,
˚n

n=1
νn;˚t
1
.
Taking into account basic properties of the GiW pdf, Proposition 8.7, espe-
cially, second moments, it can be seen, that the point estimates of the un-
known Θ = (θ, r) are around nonweighted averages corresponding to the sum
of the individual extended information matrices. Their apparent uncertainty,
however, decreases proportionally to ˚n˚t, i.e., quite quickly. This observation
clariﬁes why the ﬂattening may help; see Section 6.4.3. It acts as forgetting
that prefers newer, hopefully better, values of Vn;˚t and prevents the cumulative
degrees of freedom ν = 2˚n
n=1 νn;˚t from growing too quickly.
Here, we specialize the ﬂattening operation to the involved GiW pdfs.
Proposition 8.16 (Optimal ﬂattening mapping for GiW pdfs) Let ˜f =
GiWθ,r

˜V , ˜ν

and ¯f = GiWθ,r
 ¯V , ¯ν

be a pair of GiW pdfs deﬁned on the
common support Θ∗= [θ, r]∗. Then, the pdf ˆf minimizing the functional
D

ˆf
!!!
!!! ˜f

+ qD

ˆf
!!!
!!! ¯f

, q > 0, is GiWθ,r( ˆV , ˆν) with
ˆV = Λ ˜V + (1 −Λ) ¯V , ˆν = Λ˜ν + (1 −Λ)¯ν and Λ ≡1/(1 + q) ∈(0, 1). (8.47)
Proof. Omitted.
The application of this result to whole mixtures is straightforward as the
posterior pdf of its parameters is a product of the posterior estimates of
weights α and of the individual factors; cf. Agreement 6.1.

272
8 Learning with normal factors and components
Proposition 8.17 (Optimal ﬂattening of normal-factor estimates) Let
parameters of a pair of normal mixtures be described by (6.3) with factor es-
timates ˜f(θic, ric) = GiWθic,ric

˜Vic, ˜νic

, ¯f(θic, ric) = GiWθic,ric
 ¯Vic, ¯νic

,
i ∈i∗, c ∈c∗. These factor estimates are assumed to have a common support
[θic, ric]∗, i.e., the common structure of θic.
The corresponding estimates of the component weights are assumed to be
described by ˜f(α) = Diα (˜κ) and ¯f(α) = Diα (¯κ) of a common structure.
Then, the pdf ˆf minimizing the functional
D

ˆf
!!!
!!! ˜f

+ qD

ˆf
!!!
!!! ¯f

, q > 0,
preserves the original form described in Agreement 6.1 with GiW factors. The
resulting pdf is determined by the statistics, i ∈i∗, c ∈c∗,
ˆVic = Λ ˜Vic + (1 −Λ) ¯Vic, ˆνic = Λ˜νic + (1 −Λ)¯νic
(8.48)
ˆκc = Λ˜κc + (1 −Λ)¯κc, with Λ ≡1/(1 + q) ∈(0, 1)
Proof. It is omitted. Just notice that the ﬂattening of the component-weight
estimates is universal. It preserves the Dirichlet form with statistics being a
convex combination of the individual statistics involved.
The choice of the ﬂattening rate is fully described by Propositions 6.7, 6.8
and 6.11. The GiW form brings nothing new in this respect.
8.4.3 Geometric mean as branching mapping
Geometric-mean branching mapping A (6.15) maps a pair of arguments ˆfn(Θ),
n = 1, 2, of the maximized functional (6.38)
⌊hL

fn(d(˚t)|Θ) ˆfn(Θ), d(˚t)

≡
ˆfn(d(˚t)) ≡

fn(d(˚t)|Θ) ˆfn(Θ) dΘ on a new, hopefully better, candidate
ˆfn+1(Θ). We apply it, assuming that Agreement 6.1 is met for all involved
pdfs and that GiW pdfs serve as the estimates of parameterized factors.
Proposition 8.18 (Geometric mean of a pair GiW pdfs) Let, for n =
1, 2, t ∈{0} ∪t∗, Agreement 6.1 be met
ˆfn(Θ|d(t)) ≡Diα(κn;t)
 
c∈c∗
 
i∈i∗
GiWθic,ric(Lnic;t, Dnic;t, νnic;t).
These pdfs are obtained from a pair of diﬀerent prior pdfs when estimating
approximately, Section 8.5, the normal mixture
f(dt|d(t −1), Θ) ≡

c∈c∗
αc
 
i∈i∗
Ndi;t (θ′
icψic;t, ric) .
Recall, Diα(κ) denotes Dirichlet pdf of α ∈α∗≡

αc ≥0 : 2
c∈c∗αc = 1

of
the form (6.3)

8.4 Construction of the prior estimate
273
Diα(κ) ≡
/
c∈c∗ακc−1
c
B(κ)
, B(κ) ≡
/
c∈c∗Γ(κc)
Γ(2
c∈c∗κc).
The corresponding expected values of the component weights αc, c ∈c∗, are
ˆαc;t =
κc;t
2
˜c∈c∗κ˜c;t
.
Then, the geometric means ˆf3(Θ|d(t)), t ∈t∗, constructed according to Section
6.4.4, preserve the functional form (6.3). Its factors have statistics
V3ic;t = λtV1ic;t + (1 −λt)V2ic;t
(8.49)
ν3ic;t = λtν1ic;t + (1 −λt)ν2ic;t
κ3c;t = λtκ1c;t + (1 −λt)κ2c;t,
where
λt =
⎡
⎣1 +
t 
τ=1
2
c∈c∗ˆα2c;τ−1
/
i∈i∗
I(L2ic;τ ,D2ic;τ ,ν2ic;τ )
I(L2ic;τ−1,D2ic;τ ,ν2ic;τ−1)
2
˜c∈c∗ˆα1˜c;τ−1
/
˜i∈i∗
I(L1˜i˜c;τ ,D1˜i˜c;τ ,ν1˜i˜c;τ )
I(L1˜i˜c;τ−1,D1˜i˜c;τ ,ν1˜i˜c;τ−1)
⎤
⎦
−1
.
The normalization integral I(L, D, ν) is given by the formula (8.22).
Proof. Geometric bounding is directly applied with the explicitly expressed
v-likelihood taken as the product of adaptive one-step-ahead predictors.
8.4.4 Random branching of statistics
Random branching is a known safe way to reach global optimum. Compu-
tational complexity related to it prevents us from using the safe, completely
random, repetitive search. Thus, we support a combined use of determinis-
tic and random searches. Here, we discuss this possibility in connection with
normal factors.
According to Agreement 6.1, we deal with the mixture estimate f(Θ|d(˚t))
that is the product of the estimate Di of component weights and the estimates
GiW of factor parameters. The number of factors may be relatively large as
it is mainly determined by the dimension ˚Ψ of data vectors. Thus, random
generating of variants should be and often can be reduced to their small
subselection.
The GiW estimate of a factor is determined by the ﬁnite-dimensional,
approximately suﬃcient, statistics L, D, ν. L ∈L∗≡set of lower triangular
matrices with unit diagonal, D ∈D∗≡set of a diagonal matrices with positive
diagonal entries and ν ∈ν∗≡set of positive real scalars.
Knowing this, we generate a random sample ˜L, ˜D, ˜ν in L∗, D∗, ν∗for se-
lected factors whose predictive ability is to be challenged. Even for a single
factor, the possible extent of the random choice is usually prohibitive. Thus,
it makes sense to exploit interpretation of parts of these statistics and change
them partially only. It seems to be wise, cf. Proposition 8.7:

274
8 Learning with normal factors and components
•
To estimate the factor structure before generating new statistics.
•
To preserve characteristics determining second moments, i.e., ˜C−1 ≡
C−1 ≡⌊ψL′ ⌊ψD ⌊ψL and ˜ν ≡ν.
•
To change a point estimate ˆθ of regression coeﬃcients
˜ˆθ = ˆθ + ρ
√
ˆrC0.5e, f(e) = Ne(0, I), ρ ∈ρ∗≡(1, 5), I ≡unit matrix ⇔
⌊dψ˜L = ⌊dψL + ρ√r ⌊ψD−0.5e.
(8.50)
•
To change a point estimate of noise covariance ˆr ≡
⌊dD/(ν −2), using
normal approximation for its estimate, possibly cut to values greater than
r specifying the smallest expected noise level. The level r is always strictly
positive as at least numerical noise is always present. Speciﬁcally, with
f(e) = Ne(0, 1),
⌊d˜D = max

⌊dD
0
1 +
ρ
√
2
√ν −4e
1
, (ν −2)r

, ρ ∈ρ∗≡(1, 5).
(8.51)
Statistics κ determining the Dirichlet pdf of component weights should be
changed so that components with ˆαc ≈0 are given a chance to be modiﬁed. We
use basic properties of the Dirichlet pdf, Proposition 10.1. For the considered
purpose, we approximate it by a normal pdf. It is also cut so that the smallest
κc does not decrease. It gives
˜κc = max

κc
0
1 +
ρ
?2
˜c∈c∗κ˜c
ec
1
, min
˜c∈c∗κ˜c

, ρ ∈(1, 5), f(ec) = Nec(0, 1).
(8.52)
Remark(s) 8.4
1. The obtained result has to be ﬂattened, Section 6.4.3.
2. Random generating of statistics can be used as a part of various compound
algorithms for constructing the prior pdf.
3. The optional value ρ is tuning knob of generators. Its recommended range
stems from standard properties of the normal pdf. Values of ρ in a more
narrow range ρ∗≡(1, 2) seem to be preferable.
4. The adopted normal approximations are very simpliﬁed and can surely be
improved. In the inspected context, it does not seem worth spending energy
on this problem.
5. A proper selection of the factor to be randomly branched decides on the
eﬃciency of the algorithm within which the branching is used. The prob-
lem is explicitly addressed in connection with branching by splitting; see
Sections 6.4.8 and 8.4.7.

8.4 Construction of the prior estimate
275
8.4.5 Prior-posterior branching
The prior-posterior branching (Section 6.4.6) starts at some prior pdf, per-
forms an approximate estimation (Section 8.5) and ﬂattens the resulting pos-
terior pdf so that it provides a new alternative to the prior pdf used. The
specialization of the general results on ﬂattening gives directly the following
iterative Bayesian learning of normal mixtures.
Algorithm 8.6 (Prior-posterior branching)
Initial mode
•
Select an upper bound ˚n on the number n of iterations and set n = 0.
•
Select a suﬃciently rich structure of the mixture, i.e., specify the number
of components ˚c and the ordered lists of factors allocated to considered
components. The factor structure for each ic is determined by the structure
of the corresponding data vector Ψic.
•
Select a ﬂat pre-prior pdf ¯f(Θ) in the form (6.3) with GiW pdfs describing
individual factors. It means, select the prior statistics ¯Vic, ¯νic, ¯κc determin-
ing GiW and Dirichlet pdfs with high uncertainties; cf. Propositions 8.7
and 10.1. The pre-prior pdf serves as an alternative in ﬂattening.
•
Select a prior pdf f(Θ) in the form (6.3) with GiW pdfs describing indi-
vidual factors. It means, select the prior statistics Vic, νic, κc determining
GiW and Dirichlet pdfs, cf. Propositions 8.7, 10.1. Note that generally
¯f(Θ) ̸= f(Θ).
•
Set the ﬁrst guess of the prior pdf in nth iteration ˆf1n(Θ) ≡f(Θ),
i.e., set V1icn;0 = Vic, ν1icn;0 = νic, κ1cn;0 = κc, with c ∈c∗mark-
ing component, and giving ˆf1n(θic, ric) = GiWθic,ric (V1icn;0, ν1icn;0) and
ˆf1n(α) = Diα(κ1n;0).
•
Compute the posterior pdf
˜f1n(Θ|d(˚t)) = Diα(κ1n;˚t)
 
i∈i∗c∈c∗
GiWθic,ric(V1icn;˚t, ν1icn;˚t)
using an approximate Bayesian estimation that starts at ˆf1n(Θ); see
Section 8.5.
•
Evaluate the v-likelihood l1n resulting from the use of ˆf1n(Θ).
•
Apply the ﬂattening operation to ˜f1n(Θ|d(˚t)) according to Propositions
6.7 (on Dirichlet marginal pdfs Diα(κ1n;˚t)) and 6.8 (on the GiW pdfs
GiWθi,ri(V1icn;˚t, νicn;˚t) describing factors). Denote the resulting pdf ˆf2n(Θ).
For
ΛD ≡
2
c∈c∗(κc −¯κc)
2
˜c∈c∗(κ1˜cn;˚t −¯κ˜c),
ΛG ≡
2
c∈c∗
2
i∈i∗(νic −¯νic)
2
˜c∈c∗(ν1i˜cn;˚t −¯νi˜c)
,
it preserves the form (6.3) with
κ2cn;0 = ΛDκ1cn;˚t + (1 −ΛD)¯κc,
V2icn;0 = ΛGV1icn;˚t + (1 −ΛG) ¯Vic
ν2icn;0 = ΛGν1icn;˚t + (1 −ΛG)¯νic.

276
8 Learning with normal factors and components
•
Compute the posterior pdf
˜f2n(Θ|d(˚t)) = Diα(κ2n;˚t)
 
i∈i∗
GiWθic,ric

V2icn;˚t, ν2icn;˚t

using an approximate Bayesian estimation that starts at ˆf2n(Θ); see Sec-
tion 8.5.
•
Evaluate the v-likelihood l2n resulting from the use of ˆf2n(Θ).
•
Set ¯ln = max(l1n, l2n).
Iterative mode
1. Apply geometric branching to the pair ˜f1n(Θ|d(˚t)), ˜f2n(Θ|d(˚t)) with the
v-likelihood l1n, l2n, respectively. For λ ≡
l1n
l1n+l2n , it gives ˜f3n(Θ|d(˚t)) of
the form (6.3) with the GiW description of factors. It is determined by
the statistics
κ3cn;˚t = λκ1cn;˚t + (1 −λ)κ2cn;˚t, κ3cn = λκ1cn;0 + (1 −λ)κ2cn;0
ν3icn;˚t = λν1icn;˚t + (1 −λ)ν2icn;˚t, ν3icn = λν1icn;0 + (1 −λ)ν2icn;0
V3icn;˚t = λV1icn;˚t + (1 −λ)V2icn;˚t.
2. Apply the ﬂattening operation to ˜f3n(Θ|d(˚t)) according to Propositions
6.7 (on the Dirichlet marginal pdfs Diα(κ3;˚t) and 6.8 (on the GiW
pdfs GiWθic,ric(V3icn;˚t, ν3icn;˚t) describing factors). Denote the resulting pdf
ˆf3n(Θ). For
ΛD ≡
2
c∈c∗(κ3cn −¯κc)
2
˜c∈c∗(κ3˜cn;˚t −¯κ˜c),
ΛG ≡
2
c∈c∗
2
i∈i∗(ν3ic −¯νic)
2
i∈i∗
2
˜c∈c∗(ν3i˜cn;˚t −¯νi˜c),
it preserves the GiW version of (6.3) with
κ3cn;0 = ΛDκ3cn;˚t + (1 −ΛD)¯κc
V3icn;0 = ΛGV3icn;˚t + (1 −ΛG) ¯Vic, ν3icn;0 = ΛGν3icn;˚t + (1 −ΛG)¯νic.
3. Evaluate the v-likelihood l3n resulting from the use of ˆf3n(Θ) as the prior
pdf in an approximate estimation; Section 8.5. The approximation pre-
pared for the ﬁxed advisory system may be used; see Section 6.1.2.
4. Choose among ˜fιn(Θ|d(˚t)), ι ∈{1, 2, 3} the pair with the highest v-li-
kelihood values and call them ˜f1(n+1)(Θ|d(˚t)), ˜f2(n+1)(Θ|d(˚t)) with the
v-likelihood values l1(n+1), l2(n+1).
5. Go to the beginning of Iterative mode with n = n + 1 if
¯ln+1 ≡max(l1(n+1), l2(n+1)) > ¯ln
or if ¯ln+1, ¯ln are the same according to Proposition 6.2 and n < ˚n.
6. Stop and select among ˆfιn(Θ), ι = 1, 2 that leading to the higher value of
lιn and take it as the prior pdf constructed.

8.4 Construction of the prior estimate
277
Remark(s) 8.5
1. Prediction of the v-likelihood related to the alternative gained by forgetting
can be made in the way used in connection with merging and cancelling
of components; cf. Section 6.3.3. It can spare one complete approximate
estimation.
2. Notice that the ﬂattening relevant to branching (Propositions 6.7 and 6.8)
is applied as the geometric branching applied at time ˚t generates a new
alternative to be tested.
3. No improvement can be expected when the value of λ, used for the geomet-
ric branching at the beginning of the iterative mode, is around 0.5. This
observation may serve as an additional stopping rule.
4. The structure of the estimated mixture does not change during iterations.
Thus, it has to be suﬃciently reﬂected even in the prior pdf f(Θ).
8.4.6 Branching by forgetting
Branching by forgetting (see Section 6.4.7) makes parallel recursive estima-
tions without forgetting and with a ﬁxed forgetting with the forgetting fac-
tor smaller than 1. The alternative pdfs are compared according to their
v-likelihood. At the moment, when one of them is a sure winner they are
bounded to a single pdf and the whole process is repeated. Here, the algo-
rithm is specialized to normal mixtures.
Algorithm 8.7 (Online branching with forgetting)
Initial mode
•
Select a suﬃciently rich structure of the mixture, i.e., specify the number
of components ˚c and the ordered lists of factors allocated to the considered
components. The factor structure for each ic is determined by the structure
of the corresponding data vector Ψic.
•
Set a constant ρ ≈3−5 deﬁning the signiﬁcant diﬀerence of v-log-likelihood
values.
•
Set the record counter t = 0 and select the statistics of the guessed prior
pdf
ˆf(θic, ric) ≡ˆf(θic, ric|d(0)) = GiWθic,ric(Vic;0, νic;0), i ∈i∗, c ∈c∗
for factors as well as the statistics κ0 determining the pdf ˆf(α) = Diα(κ0)
of the component weights α.
•
Choose a ﬁxed relatively low forgetting factor λ < 1, say λ = 0.6.
•
Select a ﬁxed pre-prior alternative pdf used in the stabilized forgetting; see
Proposition 3.1. The alternative is usually taken as a ﬂat pre-prior pdf in
the GiW version of (6.3). It is given by small ⌊Aκ, ⌊Aνic and ⌊AVic = εI.
Here, ε > 0, ε ≈0 and I is a unit matrix of an appropriate dimension.

278
8 Learning with normal factors and components
Data processing mode
1. Set ˆf1(Θ|d(t)) = ˆfλ(Θ|d(t)) = ˆf(Θ|d(t)), i.e.,
κ1c;0 = κλc;0 = κc, c ∈c∗
V1ic;0 = Vλic;0 = Vic;0, i ∈{1, . . . , ˚
d}, c ∈c∗,
ν1ic;0 = νλic;0 = νic;0, i ∈{1, . . . , ˚
d}, c ∈c∗.
2. Initialize the v-log-likelihood values assigned to the considered alternatives
l1;t = 0, lλ;t = 0.
3. Collect new data dt+1 and construct the data vector Ψt+1.
4. Update ˆf1(Θ|d(t)) to ˆf1(Θ|d(t+1)) using an approximate estimation, Sec-
tion 8.5, with the forgetting factor 1.
5. Recompute the v-log-likelihood l1;t to l1;t+1 by adding the logarithm of
the mixture prediction ln(f(d(t + 1)|d(t))) obtained for the “prior” pdf
ˆf1(Θ|d(t)).
6. Update ˆfλ(Θ|d(t)) to ˆfλ(Θ|d(t+1)) using approximate estimation with the
forgetting factor λ and the chosen alternative. Thus, after obtaining statis-
tics κλ1;t+1, Vicλ1;t+1, νicλ1;t+1 through updating of κλ;t, Vicλ;t, νicλ;t with
forgetting 1, forget
κλ;t+1 = λκλ1;t+1 + (1 −λ) ⌊Aκ,
Vicλ;t+1 = λVicλ1;t+1 + (1 −λ) ⌊AVic
νicλ;t+1 = λνicλ1;t+1 + (1 −λ) ⌊Aνic.
7. Add logarithm of the mixture prediction ln(f(d(t + 1)|d(t))), obtained for
the “prior” pdf ˆfλ(Θ|d(t)), to the v-log-likelihood lλ;t get lλ;t+1.
8. Go to Step 3 with t = t + 1 if |l1;t+1 −lλ;t+1| < ρ.
9. Set ˆf(Θ|d(t + 1)) = ˆf1(Θ|d(t + 1)) if l1;t+1 > lλ;t. Otherwise set
ˆf(Θ|d(t+1)) = ˆfλ(Θ|d(t+1)). It consists of the assignment of the appro-
priate suﬃcient statistics, i.e., for l1;t+1 > lλ;t, i ∈i∗, c ∈c∗,
κλc;t+1 = κ1c;t+1, Vλic;t+1 = V1ic;t+1, i ∈i∗, νλic;t+1 = ν1ic;t+1
and similarly in the opposite case.
10. Increase t = t + 1 and go to the beginning of Data processing mode if
t ≤˚t otherwise stop and take ˆf1(Θ|d(˚t)) given by κ1c;˚t, V1ic;˚t and ν1ic;˚t,
i ∈i∗, c ∈c∗, as the ﬁnal estimate.
Remark(s) 8.6
1. Speeding up of the learning is the main expectation connected with this
algorithm. The model with no forgetting is expected to be the winner in a
long run. Current experience indicates that the estimator with forgetting
wins only for initial several tens of data records. The estimation with
forgetting can be switched oﬀwhen the estimation without forgetting is
better for a majority of time.

8.4 Construction of the prior estimate
279
2. The technique can be directly combined with prior-posterior branching. Use
of the stabilized forgetting is vital in this case. Without it, ﬂattening rates
computed as recommended in Section 6.4.3 often go out of the admissible
range (0,1].
3. Use of the general version of stabilized forgetting in Algorithm 8.7 is com-
putationally expensive. The option that cares only about estimates of the
noise variance and component weights seems to be acceptable to the given
purpose. It has the form
⌊AVic =
# ⌊AdVic 0
0
0
$
,
⌊Aνic > 0, κc > 0, i ∈i∗, c ∈c∗.
The scalars ⌊AdVic, ⌊Aνic, κc are chosen so that the estimate of the noise
variance and component weight as well as their precision are ﬁxed at prior
values.
4. The experience with a choice of the ﬁxed forgetting factor λ indicates that
the option λ ≈0.6 is satisfactory.
5. It would be desirable to formulate the selection of the better model as se-
quential decision-making. It should prevent the situations when the deci-
sion is made using too uncertain probabilities of the compared hypotheses.
8.4.7 Branching by factor splitting
Branching by factor splitting splits factors suspicious for hiding more modes
and makes a new learning attempt. The general solution is described in Sec-
tion 6.4.8. It covers important cases when we have no clue on structure of
the mixture. Basic steps described by Algorithm 6.8 apply to the normal case
without change. Normality adds nothing new to the selection of the very ini-
tial mixture and to the construction of a new mixture. Structure estimation
aspects are specialized in Section 8.6. Thus, it remains to specialize the se-
lection of factors to be split and the splitting algorithms. These aspects are
discussed in this section.
Optimization-based splitting of factors
The preferable hierarchical selection of split factors, Section 6.4.8, is often too
costly to be directly used. Thus, we have to orient ourselves on optimization-
based splitting. Signiﬁcant symmetry of GiW pdfs in regression coeﬃcients θ
calls for an explicit shift of factors to be split, for the application of Proposition
6.15. It enforces a nonzero shift of the optional function g(Θ) that determines
the resulting functional form of the modiﬁed pdf as f(Θ) exp[−⟨µ, g(Θ)⟩],
(6.71). It is easy to see that the result remains within GiW class if
g′(Θ) ≡g′(θ, r) =
#
ln(r), 1
r , θ′
r
$
M,
(8.53)

280
8 Learning with normal factors and components
where M is an arbitrary ﬁxed matrix with (˚Ψ + 1) rows. The application of
Proposition 6.15 to this most general form does not provide a closed form
solution. The problem can be avoided as follows.
First, we observe that the shifted pdf has to have C−1 = ⌊ψL′ ⌊ψD ⌊ψL iden-
tical with its pattern as no shift of the quadratic term in θ is done. Second,
we recall that splitting is done with the hope to improve predictive abilities
of the factor. The combination of these facts implies that the noise variance
r of the shifted factors is expected to be smaller than it appears currently.
The variance of a convex mixture of a pair of normal pdfs is greater than a
convex combination of individual ones. We suppose that the estimated vari-
ance resulted from such a combination and we have no reasons to assume their
asymmetric role. Thus, we expect that for the shifted factors it will be smaller
than the original value. Assuming that the error caused by merged ﬁrst and
second moments are similar, we expect that the noise variance will fall to its
half after splitting. Use of this bound gives the rule how to replace ⌊dD with
⌊dˆD. We set
⌊dˆD = s ⌊dD with the optional s ∈(0, 5).
(8.54)
This determines shift in “noise-variance direction”. Thus, we can consider the
following simpliﬁed shift determining function g(Θ) = θ/r. This choice of
g(Θ) guarantees that the (6.71) stay within GiW class with no changes in ν,
⌊ψL and ⌊ψD; cf. Proposition 6.15. Thus, ⌊dψˆL is the only optional quantity.
In other words, we can deal with a simpler, explicitly solvable case, that cares
about shift of the regression coeﬃcients only.
Proposition 8.19 (Shifted GiW factor)
Let us consider a ﬁxed pdf
f
= GiWθ,r(V, ν) ≡GiWθ,r(L, D, ν) and the approximating pdfs
ˆf
=
GiWθ,r( ˆV , ν) ≡GiWθ,r(ˆL, ˆD, ν) with
V =
#
⌊dV
⌊dψV ′
⌊dψV
⌊ψV
$
,
ˆV =
#
⌊dV
⌊dψˆV ′
⌊dψˆV
⌊ψV
$
with scalar ⌊dV . The optional ⌊dψˆV column is restricted by the requirement
⌊dV −⌊dψˆV ′ ⌊ψV −1 ⌊dψˆV = s

⌊dV −⌊dψV ′ ⌊ψV −1 ⌊dψV

⇔⌊dˆD = s ⌊dD
(8.55)
with s ∈(0, 0.5) in (8.54) being tuning knob of this shifting. Then, the pdf ˆf
minimizing the KL divergence D

ˆf
!!!
!!! f

is determined by
ˆL ≡
#
1
0
⌊dψL + ρ ⌊ψLx Lψ
$
⇔ˆˆθ = ˆθ + ρx,
⌊ψ ˆD = ⌊ψD, ˆν = ν. (8.56)
The unit ˚
ψ-vector x is the eigenvector of the covariance matrix of parameters
⌊ψL−1 ⌊ψD−1  ⌊ψL′−1 corresponding to its largest eigenvalue η. The signed
norm ρ of the shift of regression-coeﬃcients estimate is given by the formula

8.4 Construction of the prior estimate
281
ρ = ±
=
(ˆθ′x)2 + (1 −s) ⌊dDη −ˆθ′x.
(8.57)
Proof. The part of the KL divergence D

ˆf
!!!
!!! f

that depends on the optimal
estimates of regression coeﬃcients is positively proportional to

ˆˆθ −ˆθ
′
C−1 
ˆˆθ −ˆθ

,
where ˆˆθ is the LS estimate of θ assigned to ˆf.
A nonzero shift is necessary in order to reach the prescribed decrease of the
least squares remainder ⌊dD to s ⌊dD.
Obviously, ˆθ−ˆθ = ±ρx is minimizing argument searched for, if x is the unit
eigenvector corresponding to the smallest eigenvalue η−1 of ⌊ψL′ ⌊ψD ⌊ψL. This
is the largest eigenvalue of its inversion. The signed norm of the eigenvector
ρ has to be chosen so that
⌊dV = s ⌊dD +

ˆθ + ρx
′ ⌊ψL′ ⌊ψD ⌊ψL

ˆθ + ρx

= ⌊dV + ˆθ′ ⌊ψL′ ⌊ψD ⌊ψLˆθ ⇒
0 = −(1 −s) ⌊dDη + 2ρx′ˆθ + ρ2
This has the pair of claimed solutions ρ = ±
=
(ˆθ′x)2 + (1 −s) ⌊dDη −ˆθ′x.
Remark(s) 8.7
1. In an over-parameterized case, the maximizing eigenvector points to “su-
perﬂuous” directions. Thus, structure estimation and corresponding reduc-
tion have to be performed before splitting the factor; cf. item 1 in Remarks
6.14.
2. The following simple iterative algorithm for determining the maximum
eigenvalue and corresponding eigenvector x is used
˜xn ≡Cxn−1, xn =
˜xn
√ηn
, ηn ≡˜z′
n˜xn, x0 ̸= 0.
(8.58)
Its properties can be seen in the space rotated so that C is a diagonal ma-
trix. In this space, xn concentrates its unit mass at the entry corresponding
to the largest eigenvalue and thus it selects the searched eigenvector in the
original space. The scalar ηn converges to the corresponding eigenvalue.
This simple case happens if the searched eigenvalue is strictly the largest
one. If there is more such eigenvalues then the algorithm concentrates xn
to the subspace of the corresponding eigenvectors. This is, however, exactly
what we need for the considered purpose.
3. The above iterations have to be performed at an appropriate numerical
level as the considered kernel C may be low due to the proportionality to
the number of data records ˚t−1.

282
8 Learning with normal factors and components
4. Experiments indicate sensitivity of splitting quality on the optional factor
s in (8.54). For normalized data, values s ≈0.2 seem to be reasonable but
sometimes much better results can be gained with other options. It calls
for experimenting with this tuning knob. Related computational demands
make this feature highly undesirable.
We have to carefully select the function g(Θ) in order to stay within the
GiW class after shifting. The following proposition oﬀers a variant that re-
quires the class preservation explicitly. It is based on the alternative formula-
tion of the splitting problem; cf. Proposition 6.16.
Proposition 8.20 (Shift of a GiW factor to a GiW factor) Let us con-
sider the set of GiW pdfs f ∗≡{f = GiWθ,r(L, D, ν)} and a ﬁxed pdf
f = GiWθ,r(L, D, ν) in it.
Let scalar β ∈(0, 1) be chosen and we search for ˆf ∈f ∗that
1. minimizes the KL divergence D

ˆf
!!!
!!! f

,
2. has the prescribed shift in expectations ˆθ, ˆr (for f) and ˆˆθ, ˆˆr (for ˆf) of
θ, r−1
f

ˆˆΘ

= βf

ˆΘ

with
ˆˆΘ =
	ˆˆθ, ˆˆr

≡

⌊ψˆL−1 ⌊dψˆL,
⌊dˆD
ˆν

ˆΘ =
	
ˆθ, ˆr

≡
#
⌊ψL−1 ⌊dψL,
⌊dD
ν
$
computed for ˆf(Θ) ≡GiWθ,r

ˆL, ˆD, ˆν

and f(Θ) ≡GiWθ,r(L, D, ν),
3. has the prescribed ratio of peaks
ˆf

ˆˆΘ

= β−1f

ˆΘ

,
(8.59)
4. has the largest Euclidean norm of the shift in ˆθ, both as a consequence of
the optimization and of the appropriate choice of the factor β.
Then, the statistics determining ˆf are given by the formulas
ˆL ≡
#
1
0
⌊dψL + sρ ⌊ψLx ⌊ψL
$
⇔ˆˆθ = ˆθ + sρx, s ∈{−1, 1},
(8.60)
x = unit-length eigenvector of C = ( ⌊ψL′ ⌊ψD ⌊ψL)−1
corresponding to the maximum eigenvalue η,
⌊ψ ˆD = ⌊ψD, ˆν = ν,
⌊dˆD = ˆˆrˆν with
ˆˆr = ˆr/z.
(8.61)
The scalars z > 1, ρ > 0 are determined by expressions

8.4 Construction of the prior estimate
283
z ≡β
−
2
˚
ψ+2
(8.62)
ρ2 = γ
⎧
⎨
⎩−1 +
1 −2/ν ln(β) +

1 +
˚
Ψ+2
ν

ln(z)
z
⎫
⎬
⎭,
where
γ ≡νηˆr and β = exp
0
−0.5
(˚Ψ + 2)2
2(˚Ψ + 2) + ν
1
.
Proof. The optimization is split in several steps using repeatedly the speciﬁc
form of the GiW pdf and Propositions 8.7, 8.1.
1. The ﬁrst constraint f

ˆˆΘ

= βf

ˆΘ

, enforcing an explicit shift of ˆˆΘ, has
for the pdf f(Θ) = GiW(ˆθ, C, ˆr, ν) the form
ˆr−0.5(ν+˚
Ψ+2) exp[−0.5ν]
= β−1ˆˆr
−0.5(ν+˚
Ψ+2) exp
⎡
⎢⎣−0.5ν

ˆˆθ −ˆθ
′
(νC)−1 
ˆˆθ −ˆθ

+ ˆr
ˆˆr
⎤
⎥⎦.
Let us introduce auxiliary variables
z ≡ˆr
ˆˆr
> 0,
ρx ≡ˆˆθ −ˆθ, x′x = 1,
ω ≡ρ2x′(ˆrνC)−1x > 0, δ ≡
˚Ψ + 2
ν
> 0,
q ≡1 −2
ν ln(β) > 1.
Then, the above constraint gets the form (1 + δ) ln(z) + q = z(ω + 1).
Note that this constraint speciﬁes a nonempty set of admissible solutions
as the pair z = 1 and ω = −2/ν ln(β) solves it.
2. The KL divergence expressed in terms of the introduced variables has the
form
D

ˆf
!!!
!!! f

= ln
Γ(0.5ν)
Γ(0.5ˆν)

−0.5 ln

!!! ˆCC−1!!!

−0.5ν ln(ν) −0.5ν ln(z)
+ 0.5ν ln(ˆν) + 0.5(ˆν −ν)
∂
∂(0.5ˆν) ln(Γ(0.5ˆν)) −0.5˚
ψ −0.5ˆν
+ 0.5tr
	
ˆCC−1
+ 0.5νz(ω + 1).
3. The part of the KL divergence optimized with respect to 0.5ˆν reads
−ln (Γ(0.5ˆν)) + 0.5ν ln(0.5ˆν) + 0.5(ˆν −ν)
∂
∂(0.5ˆν) ln(Γ(0.5ˆν)) −0.5ˆν.
Setting its derivative with respect to ˆν to zero, we get

284
8 Learning with normal factors and components
1 = ν/ˆν + 0.5(ˆν −ν)
∂2
∂(0.5ˆν)2 ln (Γ(0.5ˆν)) .
Using an asymptotic formula [156], page 250, for derivatives of ln(Γ(·)),
∂2
∂(0.5ˆν)2 ln (Γ(0.5ˆν)) ≈(0.5ˆν)−1 + 0.5(0.5ˆν)−2, we get, for y = ν/ˆν,
1 = y + (1 −y)(1 + y/ν) = 1 + (1 −y)y/ν ⇒y = 1 ⇒ˆν = ν.
4. Respecting the diﬀerence of normalizing factors, the second constraint
ˆf

ˆˆΘ

= β−1f( ˆΘ) becomes
| ˆC|−0.5ˆˆr
−0.5(˚
Ψ+2) = β−1|C|−0.5ˆr−0.5(˚
Ψ+2).
This condition provides
z =
	
β−2 !!! ˆCC−1!!!
(˚
Ψ+2)
−1
.
Note that
!!! ˆCC−1!!! ≥1 and β < 1 imply that z > 1.
5. By minimizing the KL divergence unconditionally with respect to ˆC, we
get ˆC = C, so that z is uniquely determined
z = β−
2
˚
Ψ+2 .
It will be optimum value if the remaining free parameters stay within the
admissible range.
6. Given z, the value of ω is uniquely determined. We require the largest
shift. Thus, x must be an eigenvector of C corresponding to the largest
eigenvalue η of C. Then, ω = ρ2/γ with γ = ηνˆr and the ﬁrst constraint
implies
ρ2 = γ
#
−1 + (1 + δ) ln(z) + q
z
$
.
7. It remains to maximize the right-hand side of the above equation and
check whether it is positive for the maximizing β ∈(0, 1). We can maxi-
mize the expression in question with respect to z as there is its one-to-one
mapping to β. The necessary condition for extreme and form of z give
1 −1 −2
ν ln(β)
1 + δ
= ln(z) = −
2
˚Ψ + 2
ln(β)
⇒β = exp
⎛
⎜
⎝−0.5

˚Ψ + 2
2
2

˚Ψ + 2

+ ν
⎞
⎟
⎠.

8.4 Construction of the prior estimate
285
8.4.8 Hierarchical and optimization-based splitting
As already stated, the preferable hierarchical selection of the split factors,
Section 6.4.8, is too costly to be directly used. Here, we use the speciﬁc form of
the split factor and combine the hierarchical and optimization-based splitting.
Hierarchical splitting exploits the fact that during approximate estimation
the ith factor within the cth component is assigned a weight wic;t ∈[0, 1]. It
expresses the degree to which the current data item dic;t can be thought of as
generated by this factor. The correspondingly modiﬁed parameterized factor
fw(dic;t|d(i+1)···˚
d;t, d(t −1)) ≡fw(dic;t|ψic;t, Θic) ∝[f(dic;t|ψic;t, Θic)]wic;t
is used in the “ordinary” Bayes rule for updating parameter estimates of this
factor. Thus, we can inspect parameter estimation of this factor without con-
sidering the others. Working with a ﬁxed factor allows us to drop temporarily
the subscripts w, i, c. We can formulate hypotheses H0, H1 that the objective
pdf is two and one component mixture, respectively,
⌊of(dt|ψt, Θ0, H0) = βNdt(θ′
1ψt, r1) + (1 −β)Ndt(θ′
2ψt, r2), β ∈(0, 1),
⌊of(dt|ψt, Θ, H1) = Ndt(θ′ψt, r).
(8.63)
H0 corresponds to the hypothesis that the factor should be split into the two-
component mixture characterized by the parameter Θ0 ≡(β, θ1, r1, θ2, r2). H1
takes the estimated factor with parameters Θ = (θ, r) as the correct one. We
assume that structures of all regression coeﬃcients coincide; cf. Requirement
6.2. Moreover, we assume that the pdf f(ψ) brings no information on parame-
ters and hypotheses involved, i.e., natural conditions of decision making (2.36)
apply
f(dt, ψ|Θ0, H0) = f(dt|ψ, Θ0, H0)f(ψ), f(dt, ψ|Θ, H1) = f(dt|ψ, Θ, H1)f(ψ).
According to Proposition 2.15, the posterior pdf f(Θ|d(t)) concentrates on
minimizers of the entropy rate (2.48). We assume that it converges to its
expected value. Thus, asymptotically, the evaluated posterior pdf f(Θ|d(t))
estimating the normal factor Nd(θ′ψ, r) concentrates on
lim
˚t→∞supp

f(Θ|d(˚t))

= Arg min
θ,r

0.5 ln(r) + 0.5 ⌊oE

(d −θ′ψ)2/r

≡Arg min
θ,r H∞

⌊of
!!!
!!! θ, r

.
(8.64)
The expectation ⌊oE is an expectation assigned to the objective pdf ⌊of(d, ψ).
Note that a constant term non-inﬂuencing the minimization is dropped.
Under the hypothesis H0 on the objective pdf (8.63), we have
⌊oE[·] =
E[·|Θ0, H0] we get, for H ≡2H∞
 ⌊of
!!!! Θ ≡[θ, r]

,
H = ln(r) + r−1E[(d −θ′ψ)2|H0, Θ0]
= ln(r) + βr−1E[(d −θ′ψ)2|θ1, r1] + (1 −β)r−1E[(d −θ′ψ)2|θ2, r2]
= ln(r) + β r1
r + (1 −β)r2
r + r−1E

β[(θ1 −θ)′ψ]2 + (1 −β)[(θ2 −θ)′ψ]2
.

286
8 Learning with normal factors and components
Let us denote C−1 = E[ψψ′]. Then, points r, θ in supp

f(Θ|d(˚t))

minimizing
2H are
θ = βθ1 + (1 −β)θ2
(8.65)
r = βr1 + (1 −β)r2 + β(1 −β)(θ1 −θ2)′C−1(θ1 −θ2).
Let us consider a point r, θ in supp

f(Θ|d(˚t))

and introduce the quantities
et = dt −θ′ψt = β(dt −θ′
1ψt) + (1 −β)(dt −θ′
2)ψt. They are generated by the
static mixture
f(et|d(t −1)) = βNet(0, r1) + (1 −β)Net(0, r2).
The best point estimate of the unknown et is the ﬁltering error
ˆet ≡E[et|d(t)] ≡dt −ˆθ′
tψt, ˆθt ≡E[θ|d(t)].
(8.66)
Asymptotically, it is expected to behave as et. Thus, we can model the ﬁltering
error ˆet by a similar static mixture as et. In order to cope with the adopted
approximations, we include constant oﬀsets µ1, µ2 into the two-component
static mixture describing the ﬁltering error
f(ˆet|d(t −1), r1, r2, µ1, µ2, β) = βNˆet(µ1, r1) + (1 −β)Nˆet(µ2, r2).
(8.67)
It is estimated jointly with the factor in question. The estimation of the model
(8.67) gives us the estimates ˆβ ≡E[β|d(˚t)], ˆr1 ≡E[r1|d(˚t)], ˆr2 ≡E[r2|d(˚t)] of
β, r1, r2 and v-likelihood f(ˆe(˚t)). The relationships (8.65) determine approx-
imately the same relationships for expectations
ˆθ = ˆβˆθ1 + (1 −ˆβ)ˆθ2
(8.68)
ˆr = ˆβˆr1 + (1 −ˆβ)ˆr2 + ˆβ(1 −ˆβ)(ˆθ1 −ˆθ2)′C−1(ˆθ1 −ˆθ2).
In it, the conditional independence of involved parameters, implied by the
product form of the approximately evaluated posterior pdfs (6.3) in the special
case of two-component mixture, is used. Moreover, the covariance of the term
β(1 −β) is neglected.
The second equality in (8.68) determines the value of the quadratic form
q′C−1q =
ˆr
ˆβ(1 −ˆβ)
−
ˆr1
1 −ˆβ
−ˆr2
ˆβ
≡ρ, q ≡ˆθ1 −ˆθ2.
(8.69)
Recalling that C−1 = E[ψψ′], we see, (8.19), that we have at disposal its
sampled version while estimating θ, r.
We make the splitting unique by selecting the most distant ˆθ1, ˆθ2, by
selecting q that fulﬁlls (8.69) with the largest norm q′q. The vector ˆq = √ζρq0,
where q0 is the unit eigenvector of C corresponding to the largest eigenvalue
ζ of C can be shown to be vector of this type. Having it, we can use the ﬁrst
equality in (8.68) and specify

8.4 Construction of the prior estimate
287
ˆθ1 = ˆθ + (1 −ˆβ)ˆq, ˆθ2 = ˆθ −ˆβˆq.
(8.70)
The data attributed originally to a single factor should be distributed between
newly created factors. It leads to the option
C1 = ˆβ−1C, C2 = (1 −ˆβ)−1C and ν1 = ˆβν,
ν2 = (1 −ˆβ)ν.
(8.71)
It concludes the speciﬁcation of the splitting step.
In order to judge whether splitting is necessary, it is suﬃcient to evaluate
the v-likelihood under the hypothesis H1, i.e., to estimate during estimation
also a one-component counterpart of model (8.63), i.e., Nˆet(µ, r). The test
is described by the following algorithm that also generates as a byproduct
quantities needed for performing the split. It is prepared for the normalized
data that lie predominantly in the range [−1, 1].
Algorithm 8.8 (Test on call for a factor split)
Initial mode
•
Select the decision level γ ∈(0, 1), γ →1.
•
Attach to each factor ic, i ∈i∗, c ∈c∗, the two-component, one-
dimensional, static mixture given by the suﬃcient LS statistics (8.17)
ˆθ1ic;0 = −ˆθ2ic;0 ∈(1, 5),
(signiﬁcant shifts from the expected value 0),
ˆr1ic;0 = ˆr2ic;0 ∈(10−6, 10−4)
(the noise level in the range (0.1,1)%) of the data range,
C1ic;0 = C2ic;0 = 1/ˆr1ic;0
(covariance of parameter estimates expected to be order ≈1),
ν1ic;0 = ν2ic;0 = 2(2 + 1/ε2), ε ∈(0.1, 1),

the ratio
√
var(r)
ˆr
expected in (10,100)%, cf. (8.23)

,
κ1ic;0 = κ2ic;0 = 0.05˚t, (the standard option).
•
Attach to each factor ic, i ∈i∗, c ∈c∗, the one-component static mix-
ture given by the suﬃcient LS statistics; cf. (8.17). It can be formally
chosen as the two-component mixture described above but with completely
overlapping components. Thus, all options of the real two-component mix-
ture are copied but point estimates of positions are selected to be identical
ˆθ1ic;0 = −ˆθ2ic;0 = 0.
•
Set the v-likelihood values assigned to one- and two-component mixtures
⌊1lic;0 = 0 and ⌊2lic;0 = 0.
Learning mode
For
t = 1, . . . ,˚t
Perform a step of the QB algorithm

288
8 Learning with normal factors and components
estimating parameters of the original mixture.
For
c = 1, . . . ,˚c
For
i = 1, . . . , ˚
d
Weight the data vectors [ˆeic;t, 1] ≡[ﬁltering error, 1] by
√wic;t =
?
weight of the factor in question assigned by QB.
Run in parallel the QB algorithm on the weighted data
fed in the one- and two-component mixtures.
Update the v-likelihood values
⌊1lic;t,
⌊2lic;t.
end
of the cycle over i
end
of the cycle over c
end
of the cycle over t
Decision mode
For
i = 1, . . . , ˚
d
For
c = 1, . . . ,˚c
Denote the factor ic as ready for splitting if
⌊2lic;˚t
⌊2lic;˚t + ⌊1lic;˚t
> γ
and store the terminal values of the LS statistics.
end
of the cycle over c
end
of the cycle over i
Estimation results obtained for two-component mixture on prediction er-
rors allow us to summarize the overall factor-splitting algorithm. The ﬁxed
indexes ic;˚t are dropped in it.
Algorithm 8.9 (Splitting of factors with LS statistics ˆθ, ˆr, C, ν)
1. Deﬁne LS statistics of newly created factors as follows.
•
ˆr1, ˆr2 ≡estimates of noise covariance of respective components of the
two-component mixture estimated on the weighted ﬁltering errors,
•
ν1 = ˆβν, ν2 = (1 −ˆβ)ν, where ˆβ is the weight corresponding of the
ﬁrst component in the two-component mixture on ﬁltering errors, cf.
(8.71),
•
C1 = ˆβ−1C, C2 = (1 −ˆβ)−1C, cf. (8.71).
2. Reduce temporarily factor structure to signiﬁcant one; see Algorithm 8.13.
3. Evaluate the unit eigenvector q0 corresponding to the maximum eigenvalue
ζ of the LS covariance factor of parameters C (8.23) using (8.58).
4. Compute the norm of the shift in point estimates of regression coeﬃcient
ρ =
@
A
A
Bνζ
0
ˆr
ˆβ(1 −ˆβ)
−
ˆr1
1 −ˆβ
−ˆr2
ˆβ
1
.

8.5 Approximate parameter estimation
289
The multiplying factor ν respects that inversion of the LS covariance fac-
tors is a non-normalized version of the sampling covariance of regression
vectors.
The inspected factor is to be denoted as not ready for splitting if the argu-
ment of the above square root is negative.
5. Complement the deﬁnition of the LS statistics by ˆθ1 = ˆθ + sρq0, ˆθ2 =
ˆθ −sρq0,
s ∈{−1, 1}. The sign s is selected randomly.
Problem 8.2 (On a systematic choice of the combined factors) The
random choice in the last step of the above algorithm can be replaced by the
choice attempting to maximize the resulting v-likelihood. Algorithm 12.5 used
in so called shadow cancelling problem may serve to this purpose.
8.4.9 Techniques applicable to static mixtures
Normality of the mixture brings nothing speciﬁc to this counterpart of Chapter
6. The following problem expresses the only conjecture worth mentioning.
Problem 8.3 (Learning of dynamic mixtures via static ones) We conjec-
ture that under rather weak conditions Proposition 6.17 is applicable to normal
mixtures even for the considered continuous-valued data. This should be proved
formally.
8.5 Approximate parameter estimation
The approximate estimation described in Section 6.5 is specialized here to
normal components. The most general variants are only described.
8.5.1 Quasi-Bayes estimation
A direct application of Algorithm 6.13 gives the specialized algorithm.
Algorithm 8.10 (Quasi-Bayes algorithm with common factors)
Initial (oﬄine) mode
•
Select the structure of the mixture, i.e., specify the number of components
˚c and the ordered lists of factors allocated to the considered components.
The factor structure for each ic is determined by the structure of the cor-
responding data vector Ψic.
•
Select the statistics Lic;0, Dic;0, νic;0 determining prior pdfs of the individ-
ual factors
GiWθic,ric(Vic;0, νic;0) ≡GiWθic,ric(Lic;0, Dic;0, νic;0).
•
Select the initial values κc;0 > 0 determining the Dirichlet pdf Diα(κ0) of
the component weights α, say, about 0.1˚t/˚c.

290
8 Learning with normal factors and components
•
Select forgetting factor λ ∈(0, 1] if you intend to use forgetting.
•
Specify the L′DL decomposition of statistics used in alternative GiW
pdf GiW
 ⌊AVic;t, ⌊Aνic;t

pdf if you intend to use forgetting. Typically,
⌊AVic;t = Vic;0, ⌊Aνic;t = νic;0, ∀t ∈t∗.
•
Specify the alternative to component weights
⌊Af(α) = Diα
 ⌊Aκc;t

.
Again, ⌊Aκc;t = ⌊Aκc;0 as a rule.
•
Compute initial estimates of the component weights ˆαc;0 =
κc;0
2
˜cc∗κ˜c;0 .
Sequential (online) mode, running for t = 1, 2, . . .,
1. Acquire the data record dt.
2. Perform, for each individual factor i ∈i∗= {1, . . . , ˚
d}, c ∈c∗, a trial up-
dating of Lic;t−1, Dic;t−1 by the data vector Ψic;t using Algorithm 8.2 with
the forgetting factor λ = 1. These operations give values of the predictive
pdfs
f(dic;t|d(t −1), c) =
I(d(t)|ic)
√
2πI(d(t −1)|ic), (2.47),
with
I(d(t)|ic) ≡I(Lic;t, Dic;t, νic;t)
= Γ(0.5νic;t) ⌊dD−0.5νic;t
ic;t
!!! ⌊ψDic;t
!!!
−0.5
20.5νic;t(2π)0.5˚
ψ.
3. Compute values of the predictive pdfs, for each component c ∈c∗,
f(dt|d(t −1), c) =
 
i∈i∗
f(dic;t|d(t −1), c).
4. Compute the probabilistic weights wc;t, using the formula
wc;t =
ˆαc;t−1f(dt|d(t −1), c)
2
˜c∈c∗ˆα˜c;t−1f(dt|d(t −1), ˜c), c ∈c∗.
5. Update the scalars
κc;t = λ(κc;t−1 + wc;t) + (1 −λ) ⌊Aκc;t, c ∈c∗;
cf. (6.88).
6. Update Bayesian parameter estimates of diﬀerent factors, i.e., update the
corresponding statistics
Lic;t−1, Dic;t−1, νic;t−1 →Lic;t, Dic;t, νic;t.
The updating is equivalent to the weighted version of (8.29)
Vic;t = λ(Vic;t−1 + wic;tΨic;tΨ ′
ic;t) + (1 −λ) ⌊AVic;t, Vic;0 given
νic;t = λ(νic;t−1 + wic;t) + (1 −λ) ⌊Aνic;t, νic;0 given
(8.72)
wic;t =

˜c∈c∗
i
w˜c;t
(8.73)

8.5 Approximate parameter estimation
291
with c∗
i being a set of pointers to components that contain an ith factor.
Numerically, Dic;t−1 are ﬁrst multiplied by λ = forgetting factor and
then real updating of Lic;t−1, Dic;t−1 by data vectors Ψic;t is performed
using Algorithm 8.2 with λ = (forgetting factor)×wic;t. The alternative
is added “dyad-wise” with weights (1−(forgetting factor)) ⌊ADic;t, where
⌊ADic;t is the corresponding diagonal of the L′DL decomposition of ⌊AVic;t.
7. Evaluate the point estimates of the mixing weights
E[αc|d(t)] =
κc;t
2
˜c∈c∗κ˜c;t
≡ˆαc;t
and, if need be, characteristics of the pdf f(Θic|d(t)) = GiWθic,ric(Vic;t, νic;t)
describing other parameters Θic.
8. Go to the beginning of Sequential mode while data are available, while
t ≤˚t.
Remark(s) 8.8
1. The predictive pdf can be computed in its Student form (8.31). It makes
sense especially when prediction errors are explicitly needed.
2. The stabilized forgetting could be applied to the statistics κc;t with its spe-
ciﬁc forgetting factor.
8.5.2 EM estimation
A direct application of EM algorithm 6.15 to normal factors looks as follows.
Algorithm 8.11 (EM mixture estimation with common factors)
Initial mode
•
Select the upper bound ˚n on the number n of iterations and set n = 0.
•
Select the structure of the mixture, i.e., specify the number of components
˚c and the ordered lists of factors allocated to the considered components.
The factor structure for each ic is determined by the structure of the cor-
responding data vector Ψic.
•
Select the point estimates ˆΘicn ≡
	
ˆθicn, ˆricn

of parameters Θic ≡[θic, ric]
characterizing the ith normal factor within the cth normal component.
•
Select κcn;0 = 1 that corresponds with the point estimates ˆαcn = 1/˚c of
components weights αc.
Iterative mode
1. Use the current point estimate ˆΘn in the following evaluations.
2. Fill L′DL decomposition of the extended information matrix related to the
ith factor within the cth component as follows.
Licn;0 =
#
1
ˆθicnε I
$
, Dicn;0 =
#
ˆricnε
0
εI
$
, ε > 0, ε →0.
(8.74)

292
8 Learning with normal factors and components
Initialize the corresponding νicn;0 = ε.
Sequential mode, running for t = 1, 2, . . .,
a) Construct the data vectors Ψic;t.
b) Compute for this Ψic;t values of predictive pdfs f

dic;t|ψic;t, ˆΘicn, c

≡
Ndic;t

ˆθ′
icnψic;t, ˆricn

for each individual factor i ∈i∗= {1, . . . , ˚
d} in
all components c ∈c∗using the parameter estimates ˆΘicn that are
constant during the time cycle of the sequential mode. Thus, the ap-
proximate, ﬁxed, one-step-ahead predictor with certainty-equivalence
approximation is used.
c) Compute the values of the predictive pdfs
f

dt|ψc;t, ˆΘcn, c

≡
 
i∈i∗
Ndic;t

ˆθ′
icnψic;t, ˆricn

for each component c ∈c∗.
d) Compute the probabilities wcn;t approximating δc,ct
wcn;t =
f

dt|ψc;t, ˆΘcn, c

ˆαcn
2
˜c∈c∗f

dt|ψ˜c;t, ˆΘcn, ˜c

ˆα˜cn
.
e) Update the statistics determining the log-likelihood functions describ-
ing diﬀerent factors
Vicn;t = Vicn;t−1 + wicn;tΨic;tΨ ′
ic;t, νicn;t = νicn;t−1 + wicn;t
wicn;t =

˜c∈c∗
i
w˜cn;t.
(8.75)
The set c∗
i includes pointers to components that contain an ith fac-
tor. The recursive step (8.75) is numerically performed by updating
L′DL decompositions of extended information matrices with data vec-
tors Ψic;t weighted by wicn;t (using Algorithm 8.2).
f) Update κc;t = κc;t−1 + wc;t, c ∈c∗.
g) Go to the beginning of Sequential mode if t ≤˚t. Otherwise continue.
3. Find the new point estimates ˆΘic(n+1) =
	
⌊ψL−1
icn;˚t
⌊dψLicn;˚t, ⌊dDicn;˚t/νicn;˚t

of Θic ≡[θic, ric] and ˆαc(n+1) ∝κcn;˚t.
These values are maximizing arguments of the nth approximate likelihood.
4. Stop if the log-likelihood value

c∈c∗
κcn;˚t

ln(ˆαcn;˚t) −0.5

i∈i∗
ln

⌊dDicn;˚t/νicn;˚t

(8.76)
is not increasing any more or n = ˚n. Otherwise set n = n + 1 and go to
the beginning of Iterative mode.

8.5 Approximate parameter estimation
293
8.5.3 Batch quasi-Bayes estimation
Here, Algorithm 6.16 is specialized to normal mixtures. In this way, processing-
order-independent, batch quasi-Bayes estimation of normal mixtures is gained.
Algorithm 8.12 (BQB mixture estimation with common factors)
Initial mode
•
Select the upper bound ˚n on the number n of iterations and set n = 0.
•
Select the structure of the mixture, i.e., specify the number of components
˚c and the ordered lists of factors allocated to the considered components.
The factor structure for each ic is determined by the structure of the cor-
responding data vector Ψic.
•
Set the maximum of the v-log-likelihood ¯l = −∞.
•
Select the statistics ¯Lic, ¯Dic, ¯νic determining (ﬂat) pre-prior pdfs of the
individual factors GiWθic,ric
 ¯Vic, ¯νic

≡GiWθic,ric
¯Lic, ¯Dic, ¯νic

.
•
Select the values ¯κc > 0 determining a ﬂat pre-prior Dirichlet pdf on com-
ponent weights. These values serve for ﬂattening.
•
Select the statistics Licn, Dicn, νicn determining prior pdfs of the individual
factors
GiWθic,ric(Vicn, νicn) ≡GiWθic,ric(Licn, Dicn, νicn).
•
Select the initial values κcn > 0 determining a prior Dirichlet pdf on com-
ponent weights.
•
Make copies Lic;0 = Licn, Dic;0 = Dicn, νic;0 = νicn and κc;0 = κcn.
Iterative mode
1. Use the current prior pdf
fn(Θ) = Diα(κn)
 
c∈c∗
 
i∈i∗
GiWθic,ric(Licn, Dicn, νicn)
in the following evaluations.
2. Set the value of v-log-likelihood ln;0 = 0.
3. Compute the point estimates of the components weights ˆαcn =
κcn
2
˜c∈c∗κ˜cn.
Sequential mode, running for t = 1, 2, . . . ,
a) Construct the data vectors Ψic;t.
b) Compute for these data vectors the values of the predictive pdfs
fn(dic;t|ψic;t, c) =

f(dic;t|ψic;t, Θic, c)fn(Θic) dΘic
=
Γ(0.5(νicn + 1))
 ⌊dDicn(1 + ζicn;t)
−0.5
√πΓ(0.5νicn)

1 +
ˆe2
icn;t
⌊dDicn(1+ζic;t)
0.5(νicn+1) ,
ˆeicn;t ≡dt −⌊dψL′
icn

⌊ψL′
icn
−1
ψic;t
ζicn;t = ψ′
ic;t
⌊ψL−1
icn
⌊ψD−1
icn

⌊ψL′
icn
−1
ψic;t

294
8 Learning with normal factors and components
for each factor i ∈i∗in all components c ∈c∗using the prior pdfs
GiWθic,ric(Licn, Dicn, νicn) that are constant during time cycle.
c) Compute the values of predictive pdfs
fn(dt|ψc;t, c) ≡
 
i∈i∗
fn(dic;t|ψic;t, c)
for each component c ∈c∗.
d) Update the v-log-likelihood ln;t = ln;t−1 + ln
2
c∈c∗ˆαcnfn(dt|ψc;t, c)

.
e) Compute the probabilistic weights wcn;t approximating δc,ct by
wcn;t =
ˆαcnfn(dt|ψc;t, c)
2
˜c∈c∗ˆα˜cnfn(dt|ψ˜c;t, ˜c).
f) Update the statistics determining the posterior pdfs evolving from
copies of the prior statistics Lic;0, Dic;0, νic;0 and κc;0. The factor-
ized equivalent of the update of the extended information matrix is
performed
Vicn;t = Vicn;t−1 + wicn;tΨic;tΨ ′
ic;t,
Vicn;t ≡L′
icn;tDicn;tLicn;t
κc;t = κc;t−1 + wcn;t
(8.77)
νicn;t = νicn;t−1 + wicn;t with wicn;t =

˜c∈c∗
i
w˜cn;t.
The set c∗
i includes the pointers to components that contain the ith
factor.
g) Go to the beginning of Sequential mode if t ≤˚t. Otherwise continue.
4. Stop if the v-likelihood of the mixture does not increase ln;˚t < ¯l, or the
compared values are perceived as the same in the vein of Proposition 6.2,
or n = ˚n. Otherwise set ¯l = ln;˚t, increase the iteration counter n = n + 1,
apply ﬂattening operation to f(Θic|d(˚t)) and Diα(κc;˚t)
Dicn = ΛnDic;˚t + (1 −Λn) ¯Dic,
νicn = Λnνic;˚t + (1 −Λn)¯νic
κcn = Λnκc;˚t + (1 −Λn)¯κc,
Λn →0.5 according to Proposition 6.11.
5. Go to the beginning of Iterative mode.
Remark(s) 8.9
1. As discussed in Remarks 6.22, the BQB algorithm uses Bayesian predic-
tors for estimating δc,ct. They respect uncertainty of the current estimates
of unknown parameters. Predictions become too cautious if this uncertainty
is initialized to high values. This may break down the algorithm completely.
In the context of normal pdfs, it happens if the factor ζ = ψ′Cψ becomes
too high. Then, the inﬂuence of prediction errors {ˆe} that predominantly
indicates membership of the data vector to the speciﬁc components is sup-
pressed too much. Knowing the danger, the remedy is simple. Essentially,

8.6 Structure estimation
295
predictions used in the EM algorithm that ignore these uncertainties have
to be used in several initial iterative steps of the algorithm, i.e., the value
ζ = 0 is enforced.
2. Quasi-EM algorithm can be simply specialized to normal mixtures. It can
be used whenever use of quasi-Bayes algorithm is time-critical.
8.6 Structure estimation
Eﬃciency of the advisory system depends strongly on the quality of the model
of the o-system. A good choice of the used structure of the mixture (see
Agreement 5.4) is quite important in this respect. It includes an appropriate
selection of
•
quantities among those measured on the o-system that should be used by
the p-system;
•
the structure of individual factors; it mostly means data entries and de-
layed data entries used in the state vector in the phase form;
•
the structure of components, i.e., the order of factors used;
•
the structure of the mixture determined by the number of components and
speciﬁcation of the common factors in them.
All these tasks can be formally solved as the Bayesian estimation of discrete-
valued pointers to alternative structures. The excessive number of possible
alternatives makes the problem nontrivial. Details needed for implementing
the strategy outlined in Section 6.6 are described here.
8.6.1 Estimation of factor structure
Here, we summarize facts that make a basis for the tailored choice of the
neighborhood for normal factors. Publications [93, 95, 162] serve as references
for details.
Agreement 8.2 (Nested normal factors) Let regression vectors ψ, ˜ψ of a
pair of normal factors predicting the same data item d fulﬁll
ψ′ =
	
˜ψ′, •

(8.78)
with • marking here and below arbitrary arrays of appropriate dimensions.
Let also the statistics V0, ˜V0,
⌊AV,
⌊A˜V of the conjugate prior pdfs f(Θ) =
GiWΘ(V0, ν0), f

˜Θ

= GiW ˜
Θ

˜V0, ˜ν0

and alternative pdfs, also in the GiW
form, ⌊Af(Θ) = GiWΘ
 ⌊AV, ⌊Aν

, ⌊Af( ˜Θ) = GiW ˜
Θ

⌊A˜V , ⌊A˜ν

(8.16) fulﬁll
V0 =
# ˜V0 •
• •
$
,
⌊AV =
# ⌊A˜V •
•
•
$
.
(8.79)
Then, we say that the factor f(d| ˜ψ, ˜Θ) is nested into the factor f(d|ψ, Θ).

296
8 Learning with normal factors and components
Proposition 8.21 (Estimation and prediction with nested factors)
Let natural conditions of decision making, Requirement 2.5, hold. The con-
sidered parameterized factor (8.1) is normal, given by the regression vector
ψ. Moreover, let a conjugate prior (3.13) and a conjugate alternative (see
Section 3.1) be used in the stabilized forgetting. Let another normal factor
f

d
!!! ˜ψ, ˜Θ

, determined by the regression vector ˜ψ, be nested into the factor
f(d|ψ, Θ). Then, the statistic Vt describing estimates of the factor f(d|ψ, Θ)
evolves according to the recursion
Vt = λ(Vt−1 + ΨΨ ′) + (1 −λ) ⌊AVt, V0 given.
It provides also updating of the statistics ˜Vt as
Vt =
# ˜Vt •
• •
$
, ∀t ∈t∗.
(8.80)
Let us decompose all symmetric positive deﬁnite V -matrices into LDL′ decom-
position (it diﬀers from the decomposition L′DL used otherwise in learning!)
V = LDL′, L is lower triangular matrix with unit diagonal
(8.81)
D is diagonal matrix with nonnegative entries
L =
#
1
0
⌊dψL ⌊ψL
$
,
D =
# ⌊dD
0
0
⌊ψD
$
,
⌊dD is scalar.
Then,
L =
# ˜L 0
• •
$
, D =
# ˜D 0
0 •
$
.
(8.82)
The normalization integral deﬁning the likelihood function of data for the given
structure is
I(V, ν) = Γ(0.5ν)

⌊dD
−0.5ν !!! ⌊ψD
!!!
−0.5
20.5(ν−2)(2π)0.5˚
ψ
(8.83)
Γ(x) =
 ∞
0
zx−1 exp(−z) dz < ∞for x > 0.
The v-likelihood corresponding to the considered structure is
f(d(˚t)) = I(V˚t, ν˚t)
I(V0, ν0).
(8.84)
Proof. Detailed evaluations can be found in [162]. Nesting of the extended
information matrix follows directly from assumptions on nesting of the initial
and alternative values together with the nesting of data vectors and the form
of updating. The deﬁnition of LDL′ (!) decomposition implies its nesting. The
form of the normalizing integral I(V, ν) given in Proposition 8.7 is preserved in
spite of the change of the decomposition type as it depends on the determinant
of matrices V and ⌊ψV that can be unambiguously computed from diagonals
D and
⌊ψD only. The formula (8.84) results from (2.47) and the chain rule
for pdfs, Proposition 2.4.

8.6 Structure estimation
297
Remark(s) 8.10
1. The version with L′DL decomposition is prepared, too. It is nested at the
tail position of ψ and L, D.
2. Note that the normal pdf belongs to the exponential family (3.6) with
B(Ψ) = ΨΨ ′. The nested normal model is obtained by cancelling entries
in the regression vector at its tail. This can obviously be interpreted as a
linear operator deﬁning a nesting mapping on B(Ψ); see Proposition 3.3.
Thus, Proposition 8.21 is mostly implied by Agreement 8.2. The cancella-
tion at tails only and the choice of the decomposition LDL′ make elements
of LDL′ nested, too.
3. The nesting property can be and is used for an eﬃcient evaluation of
f(d(˚t)|s) for a rich neighborhood of some structure s0. It contains
•
all regression vectors that can be gained by deleting one entry from that
determined by s0 or by adding one regressor from the richest regression
vector ψr;
•
all regression vectors that are nested into regression vectors speciﬁed
under the previous item.
By evaluating ˚
ψ diﬀerent LDL′ decompositions of V we get much higher
number of values of likelihood functions for nested structures. Moreover,
recomputation of these LDL′ decomposition that guarantee appropriate
nesting is computationally cheap. It can be performed by the repetitive
permutation of adjacent entries in the regression vector and corresponding
restoration of the LDL′ decomposition of the extended information matrix
V ; see Proposition 8.4.
4. Nesting of the prior statistics is guaranteed for weakly informative prior
pdfs. The nesting is violated when a nontrivial physical knowledge is used;
see Section 8.3. An eﬃcient algorithm coping with the induced problems
is described in [64].
8.6.2 Structure estimation in factor splitting
We address the problem that arises in connection with branching by factor
splitting; see Section 8.4.7. Essentially, we need to perform splitting in the
space of signiﬁcant parameters and to extend it to the original parameter
space. Particular steps and their solutions are given in the following algorithm.
Algorithm 8.13 (Factor splitting steps in a signiﬁcant subspace)
1. Estimation of the factor structure f(θ, r) = GiWθ,r(L, D, ν) by analysis
of the given L′DL decomposition of the extended information matrix.
Using Algorithm 8.3, we transform L′DL to ˜L ˜D˜L′ and apply the structure
estimation algorithm outlined in Section 8.6.1.
2. Analysis of the marginal f( ⌊aθ, r) = GiW ⌊aθ,r(·) pdf on signiﬁcant regres-
sion coeﬃcients ⌊aθ. The needed marginal pdf

298
8 Learning with normal factors and components
f

⌊aθ, r

= GiW ⌊aθ,r
#
1
⌊daL ⌊aL
$
,
# ⌊dD
⌊aD
$
, ν

is obtained directly from the original pdf whose statistics are split as fol-
lows. f(θ, r) = GiWθ,r(L, D, ν)
L ≡
⎡
⎣
1
⌊daL
⌊aL
⌊dbL ⌊abL ⌊bL
⎤
⎦,
D ≡
⎡
⎣
⌊dD
⌊aD
⌊bD
⎤
⎦.
This simple relationship holds if the regression coeﬃcients
⌊aθ are at a
leading position of all regression coeﬃcients; see Proposition 8.8. This con-
ﬁguration is achieved by their permutation with the corresponding restora-
tion of L′DL according to Proposition 8.5. The conditional pdf of insignif-
icant coeﬃcients f
 ⌊bθ| ⌊aθ, r

is obtained as a byproduct. The statistics
determining it are in the part of the permuted extended information ma-
trix that is unexploited in splitting. The mentioned analysis deals with the
least-squares version of the found marginal pdf. One-to-one relationships
(8.18), (8.19), (8.20) provide it.
3. Splitting of the factor reduced on ⌊aθ, r. The solution is presented in Sec-
tion 8.4.7 and modiﬁes the reduced decomposition of the extended infor-
mation matrix to the other one given by, say,
#
1
⌊daL ⌊aL
$
,
# ⌊dD
⌊aD
$
.
4. Extension of the modiﬁed pdf
f( ⌊aθ, r) = GiW ⌊aθ,r
#
1
⌊daL ⌊aL
$
,
# ⌊dD
⌊aD
$
, ν

to a new pdf on the original space of parameters. It is done according to
the chain rule
f(θ, r) ≡f

⌊bθ| ⌊aθ, r

f( ⌊aθ, r) = GiWθ,r(L, D, ν),
where
L ≡
⎡
⎣
1
⌊daL
⌊aL
⌊dbL ⌊abL ⌊bL
⎤
⎦,
D ≡
⎡
⎣
⌊dD
⌊aD
⌊bD
⎤
⎦.
In words, the original ⌊a-parts are simply replaced by the new ⌊a-parts.
8.6.3 Estimation of component structure
A practical universal search for the best order of factors forming the compo-
nent is unsolved even for the normal components. Their speciﬁc form allows
us to get a deeper insight, which will hopefully lead to practical algorithms.

8.6 Structure estimation
299
A normal component can be written in the matrix “equation form”
dt = ⌊Mθ′φt−1 + G′et,
(8.85)
where
⌊Mθ is a matrix of regression coeﬃcients complemented by zeros so
that we can use the state vector φt−1 that is common for all entries of dt.
G′ ≡⌊eL′ ⌊eD0.5 is the Choleski square root of the noise covariance and et is
normal white zero-mean noise with uncorrelated entries and unit variance.
The chosen triangular form of G uniquely deﬁnes the decomposition of
this component into factors as well as their parameterizations; see Proposi-
tion 8.13. If we permute two entries of dt, we have to permute corresponding
columns of ⌊Mθ and G. In this way, the triangular form of G is spoiled and
has to be recovered by using invariance of the noise covariance to an orthog-
onal transformation applied directly to G′. Such a recovered G has generally
diﬀerent number of zero elements. Its inversion combines columns of ⌊Mθ in
a diﬀerent way, too. Thus, the number of zero entries in parameters of new
factors diﬀers from the former one.
The result depends in a complex way on linear dependencies of modiﬁed
rows of ⌊Mθ, rows of G and G−1. Up to now, we have found no operational
way how to describe them and thus, we have no guideline how to search for the
“permutation” candidates. The brute-force solution considering permutations
of all factors is of course formally possible.
8.6.4 Merging and cancelling of components
The normality of components brings a speciﬁc form of statistics and the nor-
malizing integral I(V, ν). It allows us to present directly the ﬁnal algorithms
of merging and cancelling.
Merging of a group of normal components
Here, the normal counterpart of Algorithm 6.21 is given.
Algorithm 8.14 (Merging of a group of normal components)
Initial mode
•
Estimate the mixture with a suﬃcient number of components ˚c so that
statistics ⌊˚cκt,
⌊˚cνic;t, ⌊˚cLic;t,
⌊˚cDic;t t ∈{0,˚t}, c ∈c∗, i ∈i∗≡{1, . . . , ˚
d}
are at disposal.
•
Set pointers c = 1, ˜c = 2 to trial components to be merged.
Evaluation mode
Set the indicator of the common structure cs = 0.
For
i = 1, . . . , ˚
d

300
8 Learning with normal factors and components
Set cs = −1 & break the cycle over i if the structures of θic, θi˜c diﬀer.
end
of the cycle over i
Do if cs = 0
Evaluate the common part of the trial merger
˜κ˚t = κc;˚t + κ˜c;˚t −1, ˜κ0 = κc;0 + κ˜c;0 −1.
Evaluate and store the factor-related parts of the trial merger
For
i = 1, . . . , ˚
d
˜νi;˚t = νic;˚t + νi˜c;˚t
˜L′
i;˚t ˜Di;˚t ˜Li;˚t = L′
ic;˚tDic;˚tLic;˚t + L′
i˜c;˚tDi˜c;˚tL′
i˜c;˚t.
end
of the cycle over i
Evaluate the change ˜l of log-v-likelihood expected after the merging
˜l = +
"
−ln

Γ(κc;˚t)

−ln

Γ(κ˜c;˚t)

+ ln (Γ(˜κ˚t)) −ln
00˚c−1

c=1
κc;˚t
1
−1
1%
−
"
−ln (Γ(κc;0)) −ln (Γ(κ˜c;0)) + ln (Γ(˜κ0)) −ln
00 ˚c

c=1
κc;0
1
−1
1%
.
For
i = 1, . . . , ˚
d
(factor parts)
˜l = ˜l
+

ln(I(˜Li;˚t, ˜Di;˚t, ˜νi;˚t)) −ln(I(Lic;˚t, Dic;˚t, νic;˚t)) −ln(I(Li˜c;˚t, Di˜c;˚t, νi˜c;˚t))

−

ln(I(˜Li;0, ˜Di;0, ˜νi;0)) −ln(I(Lic;0, Dic;0, νic;0)) −ln(I(Li˜c;0, Di˜c;0, νi˜c;0))

.
end
of the cycle over i
end of the condition cs = 0
Do if ˜l ≤0 or cs < 0
Set ˜c = ˜c + 1.
Go to the beginning of Evaluation mode if ˜c ≤˚c. Otherwise continue.
Set c = c + 1 and ˜c = c + 1.
Go to the beginning of Evaluation mode if c < ˚c. Otherwise stop.
else replace statistics related to the component c by
˜κ˚t, ˜κ0,

˜Li;˚t, ˜Di;˚t, ˜Li;0, ˜Di;0, ˜νi;˚t, ˜νi;0
˚
d
i=1 .
Swap the components ˚c and ˜c.
Decrease ˚c = ˚c −1, i.e., omit the component ˜c.
Set ˜c = c + 1 if ˜c > ˚c.
end of the test on improvement of v-likelihood and of cs < 0
Stop if ˚c = 1. Otherwise go to the beginning of Evaluation mode.

8.6 Structure estimation
301
Normal factor-based merging
The ﬁnal, most promising Algorithm 6.24 is specialized only.
Algorithm 8.15 (Systematic merging of normal factors)
Initial mode
•
Estimate a mixture with normal factors. The mixture estimate is described
by the collection of statistics
{Lic;t, Dic;t, νic;t}c∈c∗,i=1,...,˚
d,t∈{0,˚t} .
The factors with the common i are supposed to describe the same entry of
di;t irrespective of the component number.
•
Initializing the list with rows ρ = (i, c, ˜c) with meaning that the ith factor is
common for components c, ˜c. Usually, the list ρ is initialized as the empty
one.
•
Evaluate the individual normalization factors, ∀c ∈c∗, i = 1, . . . , ˚
d, t ∈
{0,˚t},
I(Lic;t, Dic;tνic:t) = Γ(0.5νic;t) ⌊dD−0.5νic;t
ic;t
!!! ⌊ψDic;t
!!!
−0.5
20.5νic;t(2π)0.5˚
ψ.
Evaluation mode
For
i = 1, . . . , ˚
d
Set pointers c = 1, ˜c = 2 to trial components.
Test of the common structure
Set the indicator of the common structure cs = 0.
Set cs = −1 if the structures of θic and θi˜c diﬀer.
Do if cs = 0
Create L′DL decomposition of the trial merger
˜L′
i;˚t ˜Di;˚t ˜Li;˚t = L′
ic;˚tDic;˚tLic;˚t + L′
i˜c;˚tDi˜c;˚tLi˜c;˚t
˜L′
i;0 ˜Di;0 ˜Li;0 = L′
ic;0Dic;0Lic;0 + L′
i˜c;0Di˜c;0Li˜c;0
using Algorithm 8.2 on columns of the added matrices.
Set ˜νi;˚t = νic;˚t + νi˜c;˚t, ˜νi;0 = νic;0 + νi˜c;0.
Evaluate increment ˜l of the log-v-likelihood
using prepared values of normalization integrals and (8.22)
˜l = ln(I(˜Li;˚t, ˜Di;˚t, ˜νi;˚t)) −
−ln(I(Lic;˚t, Dic;˚t, νic;˚t)) −ln(I(Li˜c;˚t, Di˜c;˚t, νi˜c;˚t)) −
−ln(I(˜Li;0, ˜Di;0, ˜νi;0))
+ ln(I(Lic;0, Dic;0, νic;0)) + ln(I(Li˜c;0, Di˜c;0, νi˜c;0)).

302
8 Learning with normal factors and components
end of the test on cs = 0
Do if ˜l ≤0 or cs < 0
Set ˜c = ˜c + 1.
Go to the Test of the common structure if ˜c ≤˚c.
Otherwise continue.
Set c = c + 1 and ˜c = c + 1.
Go to the beginning of Test of the common structure if c < ˚c.
Otherwise go to the end of cycle over i.
else replace prior and posterior factors with indexes ic and i˜c
by the trial merger.
Extend the list of common factors by ρ = [ρ; (i, c, ˜c)].
end of the test on improvement of v-likelihood and of cs < 0
end
of the cycle over i
Merging of components
For
c = 1, . . . ,˚c −1
For
˜c = c + 1, . . . ,˚c
Set κ˜c;˚t = κ˜c;˚t + κc;˚t,
κ˜c;0 = κ˜c;0 + κc;0 and cancel the component c
if the components c, ˜c consist of common factors only.
end
of the cycle over ˜c
end
of the cycle over c
Component cancelling
Cancelling is based on the specialized version of Algorithm 6.25. For it, it is
necessary to ﬁnd parameter values fulﬁlling (6.117). It is straightforward in
the normal case. The choice θic = 0, ric = 1, c ∈c∗, i = 1, . . . , ˚
d, guarantees
that all parameterized factors in all components coincide.
The following value is the speciﬁc item needed in the cancelling algorithm
ln
0
⌊˚cf
 ⌊˚cΘ˚c|d(˚t)

⌊˚cf
 ⌊˚cΘ˚c|d(0)

1
= 0.5
˚
d

i=1

⌊dVi˚c;0 −⌊dVi˚c;˚t

The identity ⌊dV = ⌊dD + ⌊dψL′ ⌊ψD ⌊dψL is used within the algorithm, .
Algorithm 8.16 (Systematic cancelling of normal components)
Initial mode
•
Estimate of the mixture with normal factors. The mixture estimate is de-
scribed by the collection of statistics {Lic;t, Dic;t, νic;t}c∈c∗,i=1,...,˚
d,t∈{0,˚t} .

8.7 Model validation
303
The factors with the common i are supposed to describe the same entry of
di;t irrespective of the component number.
•
Evaluate the individual normalization factors I(Lic;t, Dic;t, νic:t), ∀c ∈
c∗, i = 1, . . . , ˚
d, t ∈{0,˚t}, using formula (8.22).
•
Set c = 1.
Evaluation mode
Do while c ≤˚c and ˚c > 1
Set l = 0
For
i = 1, . . . , ˚
d
l = l + 0.5

⌊dDic;0 −⌊dDic;˚t
+ ⌊dψL′
ic;0
⌊ψDic;0
⌊dψLic;0 −⌊dψL′
ic;˚t
⌊ψDic;˚t
⌊dψLic;˚t

+ ln (I(Lic;0, Dic;0, νic;0)) −ln

I(Lic;˚t, Dic;˚t, νic;˚t)

end
of the cycle over i
If l > 0
Swap c with ˚c and set ˚c = ˚c −1, i.e., cancel the component
Stop if ˚c = 1
else
Set c = c + 1
end of the test on v-log-likelihood increase
end of the while cycle over c
8.7 Model validation
Section applies the general model validation given in Section 6.7 to normal
components.
8.7.1 Test of data homogeneity
This part specializes Section 6.7.1.
Construction of the advisory system is simpliﬁed if learning data are
qualiﬁed by experts. It provides an important additional data item, say
e ∈e∗≡{1, . . . ,˚e}, ˚e < ∞. If the discussed labels are directly measured,
then they can be treated as other discrete data, i.e., modelled by Markov-
chain factors and require no special discussion.
A diﬀerent situation arises with labels that classify data ex post. In this
case, a ﬁner modelling is desirable at least because of the inherently unbal-
anced scenario of the considered learning. It stems from the fact that any rea-
sonably managed process leads to a few types of outcomes. Deviations from

304
8 Learning with normal factors and components
a good state are exceptional. As such, they can get too small weight or be
completely overlooked when treated without taking into account their speciﬁc
role. Quasi-Bayes estimation increases this danger. These labels are constant
over whole data blocks and thus approximate processing-order-dependent es-
timation may provide quite misleading results.
In Section 6.7.1, the following hypotheses are formulated.
H0 ≡The diﬀerence in observed consequences is due to the inseparable in-
ﬂuence of external conditions and management way. A single mixture
describes the standard d(˚ts) as well as another block of the labelled d(˚te)
data, i.e., for d(˚t) ≡(d(˚ts), d(˚te))
f(d(˚t)|H0) =

f(d(˚t)|Θ, H0)f(Θ|H0) dΘ.
(8.86)
H1 ≡The diﬀerence in observed consequences is caused by diﬀerent ways of
management. Thus, diﬀerent mixtures should be used for the standard
d(˚ts) and the labelled d(˚te) data, i.e., for d(˚t) ≡(d(˚ts), d(˚te))
f(d(˚t)|H1) =

f(d(˚ts)|Θs, H1)f(Θs|H1) dΘs

f(d(˚te)|Θe, H1)f(Θe|H1) dΘe.
(8.87)
The structures of both mixtures in (8.87) may diﬀer.
Assuming no prejudice, f(H0) = f(H1), the Bayes rule provides the posterior
pf f(H0|d(˚t)). The common model is accepted as a good one if this probability
is high enough. Then, the labelling just helps in recognition of the factors
active on d(˚te) as potentially dangerous.
If f(H0|d(˚t)) is small, H1 is accepted and both models should be used
separately. The factors of the predictor obtained from f(d(˚ts)|Θ, H0) near
to the predictive factors obtained from f(d(˚te)|Θe, H1) should be treated as
potentially dangerous.
The corresponding algorithm is as follows.
Algorithm 8.17 (Test of normal data homogeneity)
1. Run the complete model estimation on standard d(˚ts), labelled d(˚te) and
concatenated d(˚t) ≡(d(˚ts), d(˚te)) data. This provides the posterior pdfs
f(Θ|d(˚tι)) = Diα(κ˚tι)
 
c∈c∗
 
i∈i∗
GiWθic,ric(Lic;˚tι, Dic;˚tινic;˚tι), ι ∈ι∗≡{s, e, ∅}.
2. The corresponding v-likelihood values indexed by ι ∈ι∗are obtained as a
byproduct of approximate estimations. They have the form (8.40)
f(d(˚tι)|ι) =
 
t∈t∗ι

c∈c∗
 
i∈i∗
I(Lic;t, Dic;t, νic;t)
I(Lic;t−1, Dic;t−1, νic;t−1)
κc;t−1
2
˜c∈c∗κ˜c;t−1
I(Lic;t, Dic;t, νic;t) = Γ(0.5νic;t) ⌊dD−0.5νic;t
ic;t
!!! ⌊ψicDic;t
!!!
−0.5
20.5νic;t(2π)0.5˚
ψic.

8.7 Model validation
305
3. Determine the probability that a single standard model should be used
f(standard|d(˚t)) ≡f(H0|d(˚t)) =
f(d(˚t))
f(d(˚t)) + f(d(˚ts)|s)f(d(˚te)|e). (8.88)
4. Use the single model further on if f(standard|d(˚t)) is close to 1. The
factors that were active on f(d(˚te)) are potentially dangerous.
5. Use both mixtures independently if f(standard|d(˚t)) is close to 0. The
danger of provoking the situation labelled by e should be signaled whenever
the model ﬁtted to d(˚te) makes better predictions than the model ﬁtted to
the standard data.
8.7.2 Learning results
Let us cut the data available in oﬄine mode d(˚t) into the learning d(˚tl) =
d(tu) and validation data d(˚tv) ≡d(tu −∂, . . . , t) for a cutting moment tu ∈
t∗
u ⊂{0} ∪t∗and the highest model order ∂. We want to test whether the
model ﬁtted on the learning data is suited the validation set, too. We test the
hypotheses
H0 ≡All recorded data d(˚t) ≡(d(˚tl), d(˚tv)) are described by a single mixture
model.
H1 ≡The learning data d(˚tl) set and the validation data set d(˚tv) should be
described by individual models.
At the same time, we select the best cutting moment minimizing the expected
loss E[δ ˆ
H,H]; see Proposition 6.19. The following algorithm elaborates this
solution for normal mixtures using the ﬂattened results gained on d(˚tl) as the
prior pdf for the learning on d(˚tv).
Algorithm 8.18 (Model validation on homogenous data)
Initial phase
•
Select the structure of the mixture. Specify the collection of prior statistics
M0 ≡{Vic;0, νic;0 κc;0}i=1,...,˚
d, c∈c∗.
•
Select a grid of cutting moments t∗
u ≡{0 = tu;1 < tu;2 < · · · < tu;˚tu ≡˚t}.
Collection of statistics for t ∈t∗
u
•
Estimate the mixture using data d(tu) starting from the collection M0
This provides a collection of learned statistics ⌊lMtu and their v-likelihood
⌊lLtu.
•
Flatten the collection of statistics
⌊lMtu using Propositions 6.7 and 6.8.
Denote the result ⌊vM0.

306
8 Learning with normal factors and components
•
Estimate the mixture of the same structure using data d(tu −∂, . . . ,˚t)
and starting from the prior statistics
⌊vM0. Evaluate the corresponding
v-likelihood ⌊vLtu.
Evaluation of the probabilities of hypotheses for tu ∈t∗
u
f(H0|d(˚t), tu) =

1 +
⌊lLtu
⌊vLtu
⌊lL˚tu
−1
Decision-making on model validity
Accept the model learned on d(˚t)(!) if
1 −max
t∈t∗
u
f(H0|d(˚t), tu) < min
t∈t∗
u
f(H0|d(˚t), tu).
Otherwise reject it and search for a better model.
8.7.3 Forgetting-based validation
Application of forgetting-based validation to normal mixtures is straight-
forward. We present it here for completeness only.
Algorithm 8.19 (Forgetting-based validation)
Initial mode
•
Estimate both parameters and structure of the normal mixture model.
•
Apply ﬂattening in the branching version so that a good prior pdf
f(Θ) = Diα(κ0)
 
c∈c∗
 
i∈i∗
GiWθic,ric(Lic;0, Di;0, νic;0),
is obtained.
•
Select several forgetting factors
0 ≈λ1 < λ2 < · · · λ˚i−1 < λ˚i = 1, 1 <˚i < ∞.
•
Set f(Θ|λi) = f(Θ).
Validation mode
1. Perform estimation with the stabilized forgetting, Section 3.1 for all λi,
using f(Θ|d(˚t)) as the alternative.
2. Evaluate values of v-likelihood li;˚t = f(d(˚t)|λi) as the product of the one-
step-ahead adaptive predictors (8.40). Compute MAP estimate ˆλ of λ .
3. Take the model as successful one if λ1 = ˆλ. Otherwise search for its im-
provements.

8.7 Model validation
307
8.7.4 Inspection by a human designer
Low-dimensional projections of the estimated pdfs are computed using Propo-
sition 8.8. Evaluation of the low-dimensional projections of normal predictors
is described by Propositions 9.2, 9.3. Using these projections, it is possible
to exploit human ability to grasp features hardly accessible in an algorithmic
way.
8.7.5 Operating modes
This validation, described generally in Section 6.7.5, judges the KL diver-
gence of suﬃciently probable components to the user’s ideal pdf
⌊Uf(d(˚t)).
The (worst) best of them should coincide with those operation modes that
according to the expert judgement are taken as the (worst) best ones.
We assume that the estimated mixture is precise enough, i.e. it passed
successfully validations described above, when making this test. Then, we
can assume that components are normal with known parameters and specify
the user’s ideal pdf as a normal pdf, too. Then, we can measure distance of
components to the user’s ideal using Proposition 8.10.
Moreover, the data record d can be split into
dm quantities determining directly markers that consist of the decisive out-
puts of the o-system and recognizable actions uo of the operator,
de external and/or informative quantities that cannot or can be inﬂuenced
by the operator but whose speciﬁc values do not inﬂuence the user’s ideal
pdf.
In other words, the user ideal is expressed in terms of the nonvoid part dm of
d.
The above discussion allows us allows us to specify the following validation
algorithm.
Algorithm 8.20 (Analysis of normal operating modes)
1. Split data records d into marker-deﬁning dm and remaining external quan-
tities de.
2. Determine the user’s ideal pdf / ˚
dm
i=1 Ndi
 ⌊Uθ′
i
⌊Uψi, ⌊Uri

on dm.
3. Take the estimated normal mixture that passed successfully learning tests.
4. Select a lower bound α ∈[0, 1) on non-negligible component weights.
5. Take gradually all components with weights αc ≥α.
6. Evaluate marginal pdfs f(dm|d(t−1)) from the inspected component using
Proposition 7.2 and if need be use the results of Section 9.1.1.
7. Evaluate the KL divergence of the resulting normal components to the
user’s ideal pdf using Proposition 8.10.
8. Check whether the KL divergences are decreasing the functions of quality
assigned by an expert to operating modes around the respective components.
9. The model passes this test successfully if no visible discrepancy is recog-
nized in the previous step. Otherwise, the model has to be improved.

308
8 Learning with normal factors and components
Remark(s) 8.11
1. The algorithm can be easily extended to markers that are a one-to-one
known image of dm. The corresponding substitution in the integral deﬁning
the KL divergence does not change its value.
2. The conditional version of divergence is evaluated. It gives a local view on
the achieved quality. If we make the user’s ideal pdf of external quantities
de equal to the pdf f(de|dm, d(t −1)), if let them to their fate (cf. Section
5.1.5) then the overall divergence of a component to the user’s ideal pdf
reads
D

f
!!!
!!! ⌊Uf

= E

t∈t∗

f(dm|d(t −1)) ln
 f(dm|d(t −1))
⌊Uf(dm|d(t −1))

ddm

.
Its sample version can be evaluated using the result of Section 9.1.4, giving
the formula of the (9.23) type.
3. This validation part can be substantially extended by using results of the
design; see Chapter 9. Other tests, like comparison of the optimal recom-
mendations and real actions, can be and should be added.

9
Design with normal mixtures
Normal models with known parameters and the state in the phase form, in con-
junction with unrestricted optimization of quadratic or exponential-quadratic
loss function, lead to feasible Bellman functions; Agreement 2.9. For them,
the optimal design reduces to the numerically tractable manipulations with
quadratic forms. Here, we inspect how this property can be extended to mix-
tures made of the normal components
f(dt|d(t −1), Θc, c) = Ndt(θ′
cφc;t−1, rc),
(9.1)
with parameters Θc = [θc, rc]′ consisting of matrix regression coeﬃcients θc
and covariance matrix rc. The state vector φc;t−1 has the phase form φc;t−1 =
[d′
(t−1)···(t−∂c), 1]′, ∂c ≥0. When recognizable actions uo;t are at our disposal,
the innovations ∆t available to the p-system are modelled by the components
f(∆t|uo;t, d(t −1), Θc, c) = N∆t

⌊∆θ′
cψt, ⌊∆rc

,
(9.2)
⌊∆Θc =
 ⌊∆θc, ⌊∆rc

,
⌊∆θc contains matrix regression coeﬃcients and
⌊∆rc
is the noise covariance. The regression vector ψ′
c;t ≡
	
u′
o;t, d′
(t−1)···(t−∂c), 1

≡

u′
o;t, φ′
c;t−1

, ∂c ≥0. The generating of recognizable actions is modelled by
f

uo;t|d(t −1), ⌊uΘc, c

= Nuo;t

⌊uθ′
cφc;t−1, ⌊urc

.
(9.3)
⌊uΘc =
 ⌊uθc, ⌊urc

,
⌊uθc contains matrix regression coeﬃcients and
⌊urc is
the corresponding covariance matrix. The coeﬃcient θc ≡
 ⌊∆θc, ⌊uθc

and
covariance matrices ⌊∆rc, ⌊urc are obtained from the factorized version of the
normal mixture as described in Section 8.1.7. The design description is sim-
pliﬁed when adopting various organizational agreements; the common state
vector φt−1 ≡φc;t−1 is used. For reference, let us ﬁx them.
Agreement 9.1 (Design conditions)
The system is modelled by a mix-
ture with normal components (9.1) having known parameters Θ and the state

310
9 Design with normal mixtures
φt in the phase form. The regression coeﬃcients are complemented by zeros so
that all factors within a single component have a common state vector. In the
academic design, the data record dt = ∆t ≡innovations. Regression vectors
of individual factors are nested as follows, i = 1, . . . , ˚
d −1,
ψi;t ≡[d′
(i+1)···˚
d;t, φ′
t−1]′ ≡[di+1;t; ψ′
i+1;t]′
(9.4)
ψ˚
d;t ≡φt−1 ≡[d′
(t−1)···(t−∂), 1]′, ∂≥0,
ψ0;t ≡Ψt ≡[d′
t···(t−∂), 1]′.
In the industrial or simultaneous design, the data record
dt = (∆′, u′
o;t)′ ≡(innovations, recognizable actions)
and regression vectors are nested in the following way
ψi;t ≡[∆′
(i+1)··· ˚
∆;t, u′
o;t, φ′
t−1]′ ≡[∆i+1;t, ψ′
i+1;t]′ = Ψi+1;t, i < ˚
∆
(9.5)
ψ ˚
∆;t ≡[u′
o;t, φ′
t−1]′ ≡[u′
o;t, d′
(t−1)···(t−∂), 1]′, ∂≥0,
ψ0;t ≡Ψt ≡[d′
t···(t−∂), 1]′.
Graphical expression of this nesting looks as follows.
Ψt ≡ψ0;t
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
φt−1 ≡ψ˚
d;t ≡
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
dt
−−−
dt−1
−−−
. . .
−−−
dt−∂
−−−
1
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
≡
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
d1;t
d2;t
. . .
d˚
d;t
−−−
d1;t−1
d2;t−1
. . .
d˚
d;t−1
−−−
. . .
−−−
d1;t−∂
d2;t−∂
. . .
d˚
d;t−∂
−−−
1
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
≡
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
∆1;t
∆2;t
. . .
∆˚
∆;t
uo1;t
uo2;t
. . .
uo˚uo;t
−−−
∆1;t−1
∆2;t−1
. . .
∆˚
∆;t−1
uo1;t−1
uo2;t−1
. . .
uo˚uo;t−1
−−−
. . .
−−−
∆1;t−∂
∆2;t−∂
. . .
∆˚
∆;t−∂
uo1;t−∂
uo2;t−∂
. . .
uo˚uo;t−∂
−−−
1
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
⎫
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎬
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎭
ψ ˚
∆;t.

9.1 Common tools
311
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
d1;t
. . .
di;t
di+1;t
. . .
d˚
d;t
−−−
d1;t−1
d2;t−1
. . .
d˚
d;t−1
−−−
. . .
−−−
d1;t−∂
d2;t−∂
. . .
d˚
d;t−∂
−−−
1
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
⎫
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎬
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎭
≡ψi;t ≡
⎡
⎣
di+1;t
−−−
ψi+1;t
⎤
⎦≡
⎡
⎢⎢⎢⎢⎣
di+1;t
. . .
d˚
d;t
−−−
φt−1
⎤
⎥⎥⎥⎥⎦
.
This chapter starts with common tools, Section 9.1, that cover model pro-
jections, discussion of practical presentation aspects, evaluations of feasible
upper bounds of a Jensen type on the KL divergence and evaluation of ex-
pected quadratic forms. Then, academic, industrial and simultaneous designs
of the advisory system are elaborated in detail; Section 9.2. Designs of pre-
sentation and signaling strategies conclude the chapter; Section 9.3.
9.1 Common tools
9.1.1 Model projections in design
Steady-state pdfs
Steady-state pdfs of the observed data are needed for recognizing dangerous
components; Agreement 5.9. The large number of data available justiﬁes the
assumption that the uncertainty of parameters is negligible after estimation.
It implies that we can evaluate the steady-state pdf of data assuming that
the parameters Θ = [θ, r], characterizing the normal component (9.1) with
matrix regression coeﬃcients
θ′ ≡[˜θ′, µ] ≡[A1, . . . , A∂, µ], Ai are square matrices,
(9.6)
and noise covariance
r ≡L′
eDeLe, Le, De are lower triangular and diagonal matrices

312
9 Design with normal mixtures
are known. The column ˚
d-vector µ in θ describes the data oﬀset. The modelled
o-system is supposed to be stable without a signiﬁcant loss of generality. Thus,
a good model has to have A’s describing a stable auto-regression.
The steady-state pdf of the state φ is normal since the relationships among
the observed data are linear and the driving white noise is normal. Thus, it is
suﬃcient to evaluate the steady-state expected value φ∞≡µ∞⊗1∂and the
steady-state covariance matrix C∞= L′
∞D∞L∞. Recall that ⊗denotes the
Kronecker product and 1∂is the ∂-vector of units.
The value µ∞can be computed recursively as the limiting value of the
sequence {µn}∞
n=1−∂. The sequence starts from zero initial conditions µn = 0,
for n ≤0, and its other members are generated as follows.
µn =
∂

i=1
Aiµn−i + µ.
(9.7)
This evaluation is preferable against an explicit solution. The convergence of
(9.7) tests the stability of the estimated auto-regressive model; it tests whether
the component is dangerous.
The L′DL decomposition of the steady-state covariance C∞of φ without
constant entry 1 can be found also recursively
L′
n+1Dn+1Ln+1 =

Ln˜θ ˜Ln
′ Dn

Ln˜θ ˜Ln

+ [Le 0]′De[Le 0],
(9.8)
where L1 = D1 = I = unit matrix, ˜θ denotes θ with the omitted oﬀset µ and
˜Ln coincides with initial ˚
d(∂−1) columns of Ln. The full algorithm looks as
follows.
Algorithm 9.1 (Moments of the steady-state normal pdf)
Initial mode
•
Select the upper bound ˚n on the number n of recursive steps and set n = 0.
•
Select a small ε > 0 used for stopping.
•
Set [µ−1, . . . , µ−∂] = 0.
•
Set Ln = Dn = I = (˚
d∂, ˚
d∂)-unit matrix.
Iterative mode (expectation)
1. Update µn = 2∂
i=1 Aiµn−i + µ.
2. Stop completely and announce the instability of the model and label the
component as a potentially dangerous one if ||µn|| > 1/ε for some norm
|| · ||.
3. Set n = 0 and go to the beginning of Iterative mode (covariance) if n > ˚n
or ||µn −µn−1|| < ε.
4. Increase the counter n = n + 1 and go to the beginning of Iterative mode
(expectation).

9.1 Common tools
313
Iterative mode (covariance)
1. Make the updating (9.8) using a variant of Algorithm 8.2.
2. Stop if n > ˚n or ||Dn −Dn−1|| < ε and take µn and L′
nDnLn as steady-
state moments.
3. Increase the counter n = n + 1 and go to the beginning of Iterative mode
(covariance).
The unstable components are obvious candidates to be labelled dangerous,
but those with stationary moments far from the target area may be classiﬁed
as dangerous, too; Agreement 5.9.
Remark(s) 9.1
The presence of unstable components does not automatically mean that the
mixture with such components is unstable. The following simple example indi-
cates it. Let the scalar dt be generated by the normal two-component mixture
f(dt|d(t −1)) = αNdt(θ1dt−1, 1) + (1 −α)Ndt(θ2dt−1, 1).
Then, ρt ≡E[d2
t] ≥0 evolves according to the recursion
ρt = [αθ2
1 + (1 −α)θ2
2]



⌊mθ2
ρt−1 + 1
and has the ﬁnite solution if ⌊mθ2 < 1. This condition is met even for com-
binations of stable and unstable components, for instance, α = 0.8, θ1 = 1.1
(!) and θ2 = 0.3 giving
⌊mθ2 = 0.986 < 1. With it, the second noncentral
and consequently ﬁrst moments are ﬁnite even for t →∞. The conclusion
can be expressed in the appealing form: the presence of, even rarely active,
stable component has stabilizing eﬀect on the mixture.
Marginal and conditional pdfs
Low-dimensional marginal and conditional pdfs provide the main technical
tool for presenting the results of the design of the p-system. The algorith-
mic description of their evaluation is given here for a known (well-estimated)
normal mixture.
In the industrial design with quadratic loss function and in simultaneous
design, the pdf of the optimal recognizable actions is also normal. Thus, the
results of this section serve for all versions of advisory systems. Essentially,
Proposition 7.2 is specialized here. The specialization is split in Proposition
9.2, dealing with marginal pdfs, and Proposition 9.3, addressing the condi-
tioning. Both of them rely on a speciﬁc structure of components; Agreement
5.4. Thus, we need a tool for changing it.

314
9 Design with normal mixtures
Proposition 9.1 (Marginal pdf of adjacent normal factors) Let us
consider a pair of adjacent normal factors (see, Agreement 5.4) with known
parameters
f(∆1, ∆2|ψ1, ψ2) = N∆1 ([β, θ′
1][∆2, ψ′
1]′, r1) N∆2 (θ′
2ψ′
2, r2) .
(9.9)
Then,
f(∆1, ∆2|ψ1, ψ2) = N∆2

[˜β, ˜θ′
2][∆1, ψ′]′, ˜r2

N∆1

˜θ′
1ψ, ˜r1

,
where ψ contains union of entries in ψ1, ψ2. The entry, which is at least in
one of them, is put on the corresponding position in ψ.
The obtained normal factor for ∆1 in the second version coincides with the
marginal pdf of ∆1. The quantities marked by ˜ are generated by the following
algorithm.
•
Extend vectors θi by zeros to the vectors ¯θi of a common length so that
[β, θ′
1][∆2, ψ′
1]′ = [β, ¯θ′
1][∆2, ψ′]′ and θ′
2ψ2 = ¯θ′
2ψ.
•
Permute the entries ∆1, ∆2 in the quadratic form Q
Q ≡[∆1, ∆2, ψ′]
#
−1 β ¯θ1
0 −1 ¯θ2
$′
diag[r−1
1 , r−1
2 ]
#
−1 β ¯θ1
0 −1 ¯θ2
$
[∆1, ∆2, ψ′]′
= [∆2, ∆1, ψ′]
#
0 −1 ¯θ2
−1 β ¯θ1
$′
diag[r−1
1 , r−1
2 ]
#
0 −1 ¯θ2
−1 β ¯θ1
$
[∆2, ∆1, ψ′]′
and recover L′DL decomposition with −1(!) on the diagonal of L of its
kernel using Proposition 8.4
Q = [∆2, ∆1, ψ′]
#
−1 ˜β ˜θ2
0 −1 ˜θ1
$′
diag[˜r−1
2 , ˜r−1
1 ]
#
−1 ˜β ˜θ2
0 −1 ˜θ1
$
[∆2, ∆1, ψ′]′.
Proof. Omitted.
Any desired change of the component structure can be achieved by a se-
quence of pairwise permutations on adjacent factors.
If the component consists of normal factors only, then it can be written in
the matrix form (9.1) and the discussed permutation can be made on it.
Proposition 9.2 (Marginal predictors for normal mixtures) Under
Agreement 9.1, let us consider the known normal mixture model in the factor-
ized form
f(∆t|uo;t, d(t −1)) =

c∈c∗
αc
 
i∈i∗
N∆ic;t(θ′
icψic;t, ric),
where
ψic;t = [∆′
(i+1)··· ˚
∆c;t, u′
o;t, φ′
c;t−1]′ ≡[∆′
(i+1)··· ˚
∆c;t, ψ′
˚
∆c;t]′ are regression vec-
tors, i ∈i∗≡{1, . . . , ˚
∆−1}, c ∈c∗,
ψ′
˚
∆c;t is the common part of regression vectors forming the component c,
∆ic;t are entries of innovations ∆c;t and uo;t are recognizable o-actions,

9.1 Common tools
315
θic are regression coeﬃcients, with entries ordered accordingly to the corre-
sponding regression vector ψic, i.e., θic =
	
θ1ic, . . . , θ( ˚
∆−i)ic, ⌊ψθ′
ic
′
, where
θjic, j = 1, . . . , ˚
∆−i, are scalars and
⌊ψ˚θic ≡˚
ψ ˚
∆c;t; zeros are inserted
into the coeﬃcients θic in order to get the common regression vectors
ψ ˚
∆c;t = ψ ˚
∆;t,
ric is the noise variance of the corresponding factor.
The considered normal component is determined by the matrices Gc, Hc and
Fc, Proposition 8.13,
Fc ≡diag
	
r−1
1c , . . . , r−1
˚
∆c

(9.10)
[Gc, Hc] ≡
⎡
⎢⎢⎢⎢⎢⎢⎣
−1 θ11c θ21c . . .
θ( ˚
∆−1)1c
⌊ψθ′
1c
0
−1 θ12c . . .
θ( ˚
∆−2)2c
⌊ψθ′
2c
...
...
0
0
. . . −1
θ1( ˚
∆−1)c
⌊ψθ′
( ˚
∆−1)c
0
0
. . .
0
−1
⌊ψθ′
˚
∆c
⎤
⎥⎥⎥⎥⎥⎥⎦
, Gc is square matrix.



Gc



Hc
Let the marginal pdf be computed for the selected entries of ∆t, say, ∆ι;t, ι ∈
ι∗≡{k1, . . . , k˚ι} ⊂i∗≡ι∗∪ι∗, ι∗∩ι∗= ∅, i.e., the marginal pdf of entries
∆ι∗;t ≡[∆k1;t, . . . , ∆k˚
ι;t]′ is computed. Let the permutation matrix T ′
c permute
∆c;t so that the entries ∆ι∗;t are placed at the end of the permuted vector of
innovations, i.e. T ′
c ∆c;t =

•, ∆′
ι∗;t
′.
Let us transform matrices Fc and [GcTc, Hc] to ˜Fc and [ ˜Gc, ˜Hc] so that ˜Fc
is diagonal matrix, ˜Gc has the same form as Gc and the following quadratic
form is preserved
[GcTc, Hc]′Fc[GcTc, Hc] = [ ˜Gc, ˜Hc]′ ˜Fc[ ˜Gc, ˜Hc].
(9.11)
Then, the predictor of the quantities of interest is the mixture
f(∆ι∗;t|uo;t, d(t −1)) ≡f(∆k1;t, . . . , ∆k˚
ι;t|uo;t, d(t −1))
=

c∈c∗
αc
˚ι 
ι=1
N∆kι;t(θ′
kιcψkιc;t, rkιc),
where the regression coeﬃcients θ′
kιc are in the last ˚ι rows of [ ˜Gc, ˜Hc] (with
−1 omitted) and variance inversions r−1
kιc are at corresponding positions in ˜Fc.
Proof. Let us take a ﬁxed component c. Then, for ∆c;t = [∆1c;t, . . . , ∆˚
∆c;t]′,
its pdf is

316
9 Design with normal mixtures
f(∆c;t|uo;t, d(t −1), c) =
 
i∈i∗
N∆ic;t (θ′
icψic;t, ric) ∝exp
−X′
2
⎡
⎢⎢⎢⎣
r−1
1c
r−1
2c
...
r−1
˚
∆c
⎤
⎥⎥⎥⎦



Fc
⎡
⎢⎢⎢⎢⎢⎢⎣
−1 θ11c θ21c . . . θ( ˚
∆−1)1c
⌊ψθ′
1c
0
−1 θ12c . . . θ( ˚
∆−2)2c
⌊ψθ′
2c
...
...
0
0
. . . −1 θ1( ˚
∆−1)c
⌊ψθ′
( ˚
∆−1)c
0
0
. . .
0
−1
⌊ψθ′
˚
∆c
⎤
⎥⎥⎥⎥⎥⎥⎦
# ∆c;t
ψ ˚
∆;t
$



X
≡exp

−0.5[∆′
c;t, ψ′
˚
∆;t]
#
G′
c
H′
c
$
Fc[Gc Hc]
# ∆c;t
ψ ˚
∆;t
$
≡exp{−0.5Q},
where Fc is diagonal (˚
d, ˚
d)-matrix, Gc is upper triangular matrix with −1 on
its diagonal. The rectangular ( ˚
∆, ˚
ψ ˚
∆c) matrix Hc contains regression coeﬃ-
cients corresponding to the common part ψ ˚
∆;t of regression vectors.
Let J′ be a permutation matrix, which places entries ∆ι∗;t whose marginal
pdfs should be computed to the end of the transformed vector of innovations
∆t. Taking another matrix Tc that performs the permutation Tc∆t = ∆c;t ⇔
∆t = T ′
c∆c;t, the following equality is obtained
[•, ∆′
ι∗;t]′ ≡J′∆t = J′T ′
c∆c;t ≡T ′
c ∆c;t.
Orthogonality of permutation matrices implies that the quadratic form Q in
the exponent of the normal component can be expressed as
Q =
	
[•, ∆′
ι∗;t], ψ′
˚
∆c;t

[GcTc, Hc]′Fc[GcTc, Hc]
	
[•, ∆′
ι∗;t], ψ′
˚
∆c;t
′
.
Using nonuniqueness of the kernel decomposition, we ﬁnd diagonal ˜Fc, up-
per triangular ˜Gc and rectangular ˜Hc matrices, which satisfy the equality
[GcTc, Hc]′Fc[GcTc, Hc] = [ ˜Gc, ˜Hc]′ ˜Fc[ ˜Gc, ˜Hc]. In algorithmic terms, LDL′
decomposition, with −1 on diagonal L, is re-created. With it, the integration
of superﬂuous quantities reduces to the omission of leading rows and columns
of the matrices ˜Fc, ˜Gc together with leading rows of ˜Hc.
Proposition 9.3 (Conditional pdfs of the normal mixture model)
Under Agreement 9.1, let us consider the known normal mixture model in the
factorized form
f(∆t|uo;t, d(t −1)) =

c∈c∗
αc
 
i∈i∗
N∆ic;t(θ′
icψic;t, ric),
where
ψic;t = [∆′
(i+1)··· ˚
∆c;t, u′
o;t, φ′
c;t−1]′ ≡[∆(i+1)c;t, ψ′
(i+1)c;t]′ are regression vec-
tors, i ∈{1, . . . , ˚
∆−1}, c ∈c∗, with the common part ψ ˚
∆;t ≡[u′
o;t, φ′
t−1]′,
∆ic;t are entries of innovations ∆c;t, uo;t are recognizable o-actions and
φt−1 ≡φc;t−1 is the common observable state of individual components,

9.1 Common tools
317
θic =
	
θ1ic, . . . , θ( ˚
∆−i)ic, ⌊ψθ′
ic
′
,
⌊ψ˚θic ≡˚
ψ ˚
∆c;t, are regression coeﬃcients
split in accordance with the corresponding regression vector; if need be,
zeros are inserted to get the common part ψ′
˚
∆;t,
ric is the noise variance of the factor ic.
For simplicity, let the order of factors for all components be common. In other
words, a common structure of components, Agreement 5.4, implying ∆c;t = ∆t
is considered. Suppose that indexes ι ∈ι∗≡{ι, . . . ,˚i}, ι ≤˚i, point to selected
entries of ∆t. Their marginal pdfs are already computed (see Proposition 9.2)
while index k ∈(ι,˚i) determines the splitting of ∆ι∗;t into two parts. Then, the
predictor of ∆ι···(k−1);t conditioned on uo;t, d(t −1) and the remaining ∆k···˚i;t
is the ratio of normal mixtures
f

∆ι···(k−1);t|∆k···˚i;t, uo;t, d(t −1)

=
2
c∈c∗αc
/˚i
ι=ι N∆ι;t(θ′
ιcψι;c, rιc)
2
c∈c∗αc
/˚i
ι=k N∆ι;t(θ′ιcψι;c, rιc)
.
(9.12)
When all values in the condition are ﬁxed, the resulting predictor is the normal
mixture
f(∆ι···(k−1);t |∆k···˚i;t, uo;t, d(t −1))
=

c∈c∗
˜αc(∆k···˚i;t, uo;t, d(t −1))
k−1
 
ι=ι
N∆ι;t(θ′
ιcψι;c, rιc), with
˜αc

∆k···˚i;t, uo;t, d(t −1)

∝αc
˚i 
ι=k
N∆ι;t(θ′
ιcψι;c, rιc).
(9.13)
Proof. It is implied by Proposition 9.2 and by the formula
f(β|γ) = f(β,γ)
f(γ) =
f(β,γ)

f(β,γ) dβ .
Remark(s) 9.2
1. The dependence of weights (9.13) on data indicates that the model obtained
through the estimation of the full predictor followed by marginalization is
richer than the directly estimated, low-dimensional predictor. This very
practical observation is easily overlooked.
2. Permutations of adjacent factors according to Proposition 9.1 have to be
made if the considered entries are not at the assumed positions. This need
also implies that the assumption of the c-invariant ordering of ∆c;t = ∆t
is not restrictive: we have to reach this situation anyway, at least for the
innovation entries of interest.

318
9 Design with normal mixtures
9.1.2 Dynamic predictors in advising
Here, the general results of Section 7.1.2 are specialized to normal mixtures.
For these mixtures, individual components are multivariate auto-regression
models (AR). Their stability is the key property we need for good long-horizon
predictors.
Stable auto-regression
Normal multivariate AR models serve well as short-horizon predictors in a
range of applications including those covered by this text. They are often
unsuitable for long-term predictions as the dynamic system represented by the
estimated coeﬃcients is too close to the stability boundary or even unstable.
The remedy should be searched in data preprocessing (Chapter 6), use of
continuous-time model [138, 163] or model with moving average part ARMAX
factors [26]. None of them, however, can guarantee the full success. Then, the
reduction of the support of the prior pdf on the set, cf. (9.6),
Θ∗
s ≡
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
([A1, . . . , A∂, µ], r) , A =
⎡
⎢⎢⎢⎣
A1 . . . A∂−1 A∂
I . . .
0
0
...
...
...
...
0
0
I
0
⎤
⎥⎥⎥⎦
has spectral
radius < 1
⎫
⎪
⎪
⎪
⎬
⎪
⎪
⎪
⎭
(9.14)
as discussed in Section 7.1.2, is the only possibility. Technically, Monte Carlo
evaluation of the expectation over the set of stable AR models is applied.
The samples of Θ are generated from the estimated factorized version of the
posterior pdf
f(Θ|d(˚t)) ∝
˚
d
 
i=1
GiWθi,ri

Li;˚t, Di;˚t, νi;˚t

χΘ∗
s (Θ).
(9.15)
The involved statistics are updated irrespective of the constraint used. For the
approximate mixture estimation, Section 6.5, weights of individual data vec-
tors should be modiﬁed compared to the unrestricted case. They are formed,
however, by one-step-ahead predictors that are weakly inﬂuenced by the in-
formation about stability. Thus, this dependence can be and will be neglected.
Consequently, the evaluation of the posterior likelihood function is uninﬂu-
enced by the stability restriction even for mixtures. Having the posterior pdf,
we need to evaluate a point estimate ˆΘ of the parameter Θ. The expected
value
ˆΘ ≡E

Θ|d(˚t)

=

ΘχΘ∗
s (Θ) /˚
d
i=1 GiWθi,ri

Li;˚t, Di;˚t, νi;˚t

dΘ

χΘ∗
s (Θ) /˚
d
i=1 GiWθi,ri

Li;˚t, Di;˚t, νi;˚t

dΘ
(9.16)

9.1 Common tools
319
is taken as the required estimate. Its analytical evaluation is impossible. A
Monte Carlo evaluation is to be used. It has to take into account the non-
convex shape of the integration domain. The evaluations are performed by the
following algorithm that specializes Algorithm 7.1 to a normal component. For
a mixture, it is applied componentwise.
Algorithm 9.2 (Point estimation of the stable AR component)
Initial mode
•
Perform the standard estimation (Chapter 8) that gives the collection of
statistics Li;˚t, Di;˚t, νi;˚t, i = 1, . . . , ˚
d.
•
Convert the collected statistics into their least-squares (LS) counterparts
ˆθi;˚t ≡⌊ψL−1
i;˚t
⌊dψLi;˚t ≡LS estimate of regression coeﬃcients
ˆri;˚t ≡
⌊dDi;˚t
νi;˚t −2 ≡LS estimate of noise variance
Ci;˚t ≡⌊ψL−1
i;˚t
⌊ψD−1
i;˚t

⌊ψL′
i;˚t
−1
≡LS covariance factor.
•
Stop and take the unrestricted LS point estimates as the approximation of
(9.16) if they deﬁne a stable AR model, i.e., if they belong to Θ∗
s (9.14).
•
Select the upper bound ˚n, say on the order of 104 −106, on the number n
of samples and set n = 0.
•
Select the bound ˚
m, say on the order of 100 −−1000, on the necessary
number m of stable samples and set m = 0.
•
Initialize the generated stable point estimates ˆθis = 0, ˆris = 0, i = 1, . . . , ˚
d.
Iterative mode
1. Do while n < ˚n & m < ˚
m.
2. Set n = n + 1.
3. Generate, for i = 1, . . . , ˚
d, random samples
θin, rin ∼GiWθi,ri

ˆθi;˚t, ˆri;˚t, Ci;˚t, νi;˚t

as follows.
rin = ˆri;˚t(1 + er), er ∼Ner
0
0,
C
2
νi;˚t −4
1
; cf.(8.23),
rin = ˆri;˚t if the sample rin ≤0
θin = ˆθi;˚t +
?
˜ri
⌊ψL−1
i;˚t
⌊ψD−0.5
i;˚t
e,
e ∼Ne(0, I˚
θi).
Above, the normal, moments-preserving, approximation of the marginal
pdf f(ri|d(˚t)) is adopted.
4. Go to the beginning of Iterative mode, if Θn /∈Θ∗
s, i.e., if the multivariate
AR model given by θin, i = 1, . . . , ˚
d, is unstable.

320
9 Design with normal mixtures
5. Set ˜m ≡m + 1 and ˜θis ≡ˆθis + 1
˜m

ˆθis −θin

,
˜ris = ˆris + 1
˜m (ˆris −rin),
i = 1, . . . , ˚
d.
6. Set m = ˜m and ˆΘs = ˜Θs if ˜Θs ∈Θ∗
s, i.e., if ˜θis, i = 1, . . . , ˚
d, deﬁne a
stable AR model.
7. Go to the beginning of Iterative mode.
Accept ˆΘs as the ﬁnal estimate if m = ˚
m. Otherwise, take the search as
unsuccessful.
Remark(s) 9.3
1. Better stopping rules can be created using simple estimates of covariance
matrices of the constructed expected value and inequality of the Chebyshev
type [164]. Also, Bayesian stopping rules [94, 128] are at our disposal.
2. It is useful to remember that Θ∗
s may be restricted by another prior knowl-
edge, for instance, by an expected range of static gains.
The restricted set Θ∗
s is often much smaller than Θ∗. Then, the number of
discarded samples is prohibitive. This makes us design an alternative sampling
strategy. Essentially, samples are taken from Θ∗
s and the expected value is
computed as their weighted mean value. The weights express the degree of
how much the given sample can be attributed to the posterior pdf f(Θ|d(˚t)).
The need to preserve the structure of individual factors is the key obstacle
faced.
The following steps have to be discussed to design such an improved sam-
pling strategy. They use more or less textbook results. Their presentation
complexity stems from the eﬀort to stay with decisive evaluations at the fac-
tor level.
Let us inspect the eigenvalues of the state matrix
A ≡
⎡
⎢⎢⎢⎢⎢⎣
A1 A2 . . . A∂−1 A∂
I
0 . . .
0
0
0
I . . .
0
0
...
0
0 . . .
I
0
⎤
⎥⎥⎥⎥⎥⎦
(9.17)
corresponding to the multivariate AR model without oﬀset µ. Let ρ be an
eigenvalue of A assigned to an eigenvector φ, i.e., Aφ = ρφ. Let us split φ into
∂˚
d-blocks φ′ = [φ′
1, . . . , φ′
∂] corresponding to the size ˚
d of the data record dt,
i.e., to the size of the multivariate regression coeﬃcients Ai. The blocks φi are
related by the recursion φiρ = φi−1 valid for i > 1. This recursion and the
identity for the block φ1 give, for ρ ̸= 0 of interest,
φi = ρ−i+1φ1, i = 2, . . . , ∂,
and ρφ1 =
∂

i=1
Aiφi =
∂

i=1
Aiρ−i+1φ1

9.1 Common tools
321
⇒0 =
0
I −
∂

i=1
Aiρ−i
1
φ1 ⇒ρ is root of
!!!!!I −
∂

i=1
Aiρ−i
!!!!! = 0.
(9.18)
Let us consider the modiﬁed multivariate AR model with matrix coeﬃcients
˜Ai = xiAi, i = 1, . . . , ∂, where x is an optional positive scalar. Obviously, if ρ
is an eigenvalue corresponding to the coeﬃcients {Ai}∂
i=1 then xρ is eigenvalue
corresponding to the coeﬃcients { ˜Ai}∂
i=1.
Thus, if ρ is an eigenvalue with the largest module |ρ| greater than one,
then the AR model modiﬁed by the factor x = g/|ρ| is stable for an arbitrary
g ∈(0, 1),.
Let us inspect individual components. Using widely available algorithms
for evaluation of matrix eigenvalues, the component is tested whether or not
the expected value of its regression coeﬃcients deﬁne a stable state matrix. It
is taken as the point estimate searched for, if the answer is positive. Otherwise,
we select g ∈(0, 1), and transform expected values ˆθi, of regression coeﬃcients
θi of the ith factor, i = 1, . . . , ˚
d, as follows.
˜θi =
⎡
⎢⎢⎢⎢⎢⎣
I˚
d−i
g
|ρ|I˚
d
... 
g
|ρ|
∂
I˚
d
⎤
⎥⎥⎥⎥⎥⎦
θi ≡Tiˆθi.
(9.19)
Let us consider the pdf GiWθi,ri

˜θi, ˜Ci, ˜ri, ˜νi

. By construction, the expected
value of the component described by such factors has spectral radius equal to
g < 1.
We select the optional statistics ˜Ci, ˜ri, ˜νi so that the product of factors
is as close as possible to the posterior pdf /˚
d
i=1 GiWθi,ri

ˆθi, Ci, ˆri, νi

. The
following simple proposition holds.
Proposition 9.4 (The nearest shifted GiW pdf) Let us consider some
set of GiW pdfs

˜f(θ, r) = GiWθ,r(˜θ, ˜C, ˜r, ˜ν), ˜θ is ﬁxed

, and a given pdf
f(θ, r) = GiWθ,r(ˆθ, C, ˆr, ν). Then,
GiWθ,r
⎛
⎜
⎝˜θ, C +
ν

˜θ −ˆθ
 
˜θ −ˆθ
′
(ν −2)ˆr
, ˆr, ν
⎞
⎟
⎠= arg
min
˜
C>0,˜r>0,˜ν>0
D(f|| ˜f). (9.20)
Proof. Using the explicit form of the KL divergence of a pair GiW pdfs, (8.25),
it is straightforward to ﬁnd the minimizing values ˜r = ˆr and ˜ν = ν. The part
depending on the remaining optional ˜C has the form
−0.5 ln
!!!C ˜C−1!!! + 0.5tr
	
C ˜C−1
+ 0.5
ν
(ν −2)ˆr

ˆθ −˜θ
′ ˜C−1 
ˆθ −˜θ

.

322
9 Design with normal mixtures
Taking the derivative with respect to ˜C−1 and using the formulas (8.3), (8.6),
we get the claimed form of ˜C.
Using a direct inspection or formalism of the Radon–Nikod´ym derivative,
[72], we ﬁnd that the expected value ˆθi of the pdf GiWθi,ri(ˆθi, Ci, ˆri, νi) can be
expressed in terms of the expectation ˜E[·] assigned to GiWθi,ri

˜θi, ˜Ci, ˆri, νi

with ˜θi, ˜Ci given by formulas (9.19), (9.20). It has the following form.
ˆθi = E[χθ∗
s (θi)θi] =
˜E[χθ∗
s (θi)θiq(θi)]
˜E[χθ∗
s (θi)q(θ)]
with
(9.21)
q(θi) ≡GiWθi,ri(ˆθi, C, ˆri, νi)
GiWθi,ri(˜θi, ˜Ci, ˆri, νi)
.
Thus, we can draw samples from the GiW pdf having a stable AR model as
the expected value and apply Monte Carlo evaluations to both expectations
involved. For each i ∈i∗, we take samples Θik ∼GiWΘi

˜θi, ˜Ci, ˆri, νi

and
compute
ˆθis ≈
2
k χθ∗
s (θik)θikq(Θik)
2
k χΘ∗
s (θik)q(Θik) .
(9.22)
This leads to the following modiﬁcation of Algorithm 9.2.
Algorithm 9.3 (Point estimation of a stable AR component)
Initial mode
•
Perform the standard estimation, Chapter 8, giving the collection of statis-
tics Li;˚t, Di;˚t, νi;˚t, i = 1, . . . , ˚
d.
•
Convert the collected statistics into their least-squares (LS) counterparts
ˆθi;˚t ≡⌊ψL−1
i;˚t
⌊dψLi;˚t ≡LS estimate of the regression coeﬃcients
ˆri;˚t ≡
⌊dDi;˚t
νi;˚t −2 ≡LS estimate of the noise variance
Ci;˚t ≡⌊ψL−1
i;˚t
⌊ψD−1
i;˚t

⌊ψL′
i;˚t
−1
≡LS covariance factor.
•
Evaluate the absolute value ρ of the maximum eigenvalue of the state ma-
trix (9.17) made of expected regression coeﬃcients of all factors involved.
•
Stop and take the unrestricted LS point estimates as the approximation of
(9.16) if ρ < 1 as they deﬁne a stable AR model or equivalently belong to
Θ∗
s (9.14).
•
Select a number g1 ∈(0, 1), say g1 = 0.99, used for stabilization and set
g = g1/ρ.

9.1 Common tools
323
•
Deﬁne, for i = 1, . . . , ˚
d, matrices Ti (9.19) and transform the statistics
˜θi = Tiˆθi;˚t, ˜Ci = Ci;˚t +
νi;˚t

˜θi −ˆθi;˚t
 
˜θi −ˆθi;˚t
′
(νi;˚t −2)ˆri;˚t
.
Note that the standard rank-one updating can be used for evaluation of the
L′DL decomposition of the matrix ˜Ci.
•
Select the upper bound ˚n, say on the order of 102 −104, on the number n
of generated samples and set n = 0.
•
Select the bound ˚
m, say on the order of 100−−1000, on the needed number
m of stable samples and set m = 0.
•
Initialize the vectors that will contain the generated stable point estimates
ˆθis = 0, ˆris = 0, and denominators mi = 0, for i = 1, . . . , ˚
d.
Iterative mode
1. Do while n < ˚n & m < ˚
m.
2. Set n = n + 1.
3. Generate samples θin, rin ∼GiWθi,ri

˜θi, ˆri;˚t, ˜Ci, νi;˚t

, i = 1, . . . , ˚
d,
rin = ˆri;˚t(1 + er),
er ∼Ner
0
0,
C
2
νi;˚t −4
1
, cf.(8.23),
rin = ˆri;˚t if the sample rin ≤0,
θin = ˜θi +
?
ˆri ˜C0.5
i
e,
e ∼Ne(0, I˚
θi).
The normal, moment-preserving, approximation of the marginal pdf
f(ri|d(˚t)) is adopted above.
4. Test the component stability, i.e., inspect the maximum absolute values of
eigenvalues of the state matrix (9.17) made of generated samples. Go to
the beginning of Iterative mode if Θn /∈Θ∗
s, if the generated multivariate
AR model is unstable.
5. Set, for i = 1, . . . , ˚
d,
˜mi = mi + q (Θin) ,
˜θis = ˆθis + q (Θin)
˜mi

θin −ˆθis

˜ris = ˆris + q (Θin)
˜mi
(rin −ˆris) , q(·) is given by (9.21).
6. Set m = m+1, ˆΘis = ˜Θis and mi = ˜mi, if ˜θs−made of ˜θi−is a stable AR
model.
7. Go to the beginning of Iterative mode.
Accept ˆΘs as the ﬁnal estimate if m = ˚
m. Otherwise take the construction as
unsuccessful.

324
9 Design with normal mixtures
9.1.3 Advices and their inﬂuence
The specialization of the model presented in Section 7.1.3, is implied by
Agreement 9.1. Among other things, it implies that recognizable actions enter
linearly regression vectors. Otherwise, the specialization to normal mixtures
brings nothing new and it is elaborated in connection with the respective
designs.
9.1.4 Practical presentation aspects
Multi-step-ahead predictors
Ideally, the estimated mixture should describe well both deterministic and
stochastic relationships between observed history and future behavior. It is es-
pecially important for the discussed design part. The quality of the estimated
mixture can be well judged according to its performance as a multi-step-ahead
predictor. Its exact practical construction is diﬃcult for the same reasons that
make diﬃcult the mixture estimation. Thus, an approximation is needed. The
following approximation is based on our ability to evaluate the one-step-ahead
predictor. Essentially, this predictor is used as a random generator of a next
data item, which is inserted into the condition of the next predictor, etc.
This relatively short-horizon simulation is expected to reveal a signiﬁcant
information about the simulated model due to a large number of such simula-
tion periods that coincides with the number of processed data records ˚t. The
algorithm is rather simple but surprisingly error prone. This has motivated
the following detailed presentation of the algorithm. The simulated values are
marked by the symbol ˜.
Algorithm 9.4 (Simulation-based multi-step predictor)
Initial mode
•
Specify the analyzed normal mixture, typically, estimate it as described in
Chapter 8.
•
Select the prediction horizon T ≥1.
Sequential mode, running for t = 1, 2, . . . ,
1. Complement the state vector φt by dt.
2. Specify recognizable actions u0;t+1 and complement the regression vectors
ψ ˚
∆c;t+1, c ∈c∗.
3. Generate ct+1 ∼[α1, . . . , α˚c].
Make copies ˜φc;t = φc;t, c ∈c∗and set ˜ψ ˚
∆ct+1;t+1 ≡φct+1;t
For
i = ˚
∆, ˚
∆−1, . . . , 1
Sample
˜di;t+1 ∼Ndi;t+1

θ′
ict+1 ˜ψict+1;t+1, rict+1

.
Complement
˜ψ(i−1)ct+1;t+1 by the sample ˜di;t+1.

9.1 Common tools
325
end
of the cycle over i
Take ˜dt+1 from ˚
d initial entries of ˜Ψct+1;t+1 ≡˜ψ0ct+1;t+1.
For
c = 1, . . . ,˚c
Create
˜ψ˚
dc;t+1 ≡˜φc;t.
end
of the cycle over c
For
τ = t + 1, . . . , t + T
Generate cτ ∼[α1, . . . , α˚c].
For
i = ˚
d, ˚
d −1, . . . , 1
Sample
˜di;τ ∼Ndi;τ

θ′
icτ ˜ψicτ ;τ, ricτ

.
Complement
˜ψ(i−1)cτ ;τ by the sample ˜di;τ.
end
of the cycle over i
Take the simulated ˜dτ from ˚
d initial entries of ˜Ψcτ ;τ ≡˜ψ0cτ ;τ.
For
c = 1, . . . ,˚c
Create
˜ψ˚
dc;τ+1 = ˜φc;τ.
end
of the cycle over c
end
of the cycle over τ
4. Use the one-step-ahead predictor, Proposition 8.14, given by the state vec-
tors ˜φc;t+T −1. For instance, evaluate moments of dt+T .
Remark(s) 9.4
1. Except for the initial prediction time, when the recognizable actions are
determined externally, the whole data record dt should be simulated to get
the real test of the overall model.
2. Component probabilities used for selecting the active mixture are either
those estimated or their dynamic approximation; Section 7.1.2. The ap-
proximation can be restricted to the ﬁrst step only or applied over the
whole prediction horizon. The second variant is conjectured as the better
one.
3. A sort of ergodic hypothesis is behind the construction of the algorithm:
predictive relevance of samples is supposed. This aspect should be inspected
more closely.
Support of visible part of normal mixture
A graphic representation of the mixture predicting several data entries, say
y, is shown to the operator. It requires evaluation of a multivariate interval

326
9 Design with normal mixtures
[y, y] on which the values of the pdf
f(y|P) =

c∈c∗
αcNy(µc, rc)
are high enough. We derive simple but useful algorithm for determining the
interval [y, y].
The component weights αc, the vector-valued expected values µc and co-
variance matrices rc = L′
cDcLc are ﬁxed in this task by the experience P
in the condition. Normality implies that the highest value (2π)−0.5˚y ¯β of the
involved weighted component is
(2π)−0.5˚y ¯β ≡
max
c∈c∗,y∈(−∞,∞)˚
y αcf(y|P, c) = (2π)−0.5˚y max
c∈c∗βc
βc ≡
αc
?
|rc|
=
αc
=/˚y
i=1 Dic
.
Let us deﬁne the visibility level K ∈(0, 1), say K = 0.01. Then, the weighted
pdf describing the weighted cth component is to be displayed on the appro-
priate interval [y, y] on which f(y|P, c) ≥K(2π)−0.5˚y ¯β. The extreme values
yic ≡µic −x, yic = µic +x for the cth component on the ith axis, i = 1, . . . ,˚y,
are determined by the positive solution of the equation
max
xι∈(−∞,∞), ι̸=iexp{−0.5 [x1, . . . , xi−1, x, xi+1, . . . , x˚y] r−1
c
× [x1, . . . , xi−1, x, xi+1, . . . , x˚y]′}
= exp

−0.5 x2
Dic

= K
¯β
βc
⇔x =
?
Dicζ ≡
C
Dic2 ln
 βc
K ¯β

.
The positive solution exists iﬀ
βc
K ¯β > 1. The interval that is searched for has
to cover the union of intervals [yic, yic] for all components c ∈c∗and all axes
i ∈{1, . . . ,˚y}. These considerations lead to the overall algorithm.
Algorithm 9.5 (Practical support of a normal mixture)
Initial mode
•
Evaluate moments µc, rc ≡L′
cDcLc and weights αc of the normal mixture
of the interest.
•
Specify the visibility level K ∈(0, 1), typically, K = 0.01.
•
Deﬁne the initial values of the constructed interval yi = +∞, yi = −∞,
i = 1, . . . ,˚y.
•
Set ¯β = −∞.

9.1 Common tools
327
Construction mode
For
c = 1, . . . ,˚c
βc =
αc
=/˚y
i=1 Dic
,
¯β = max(¯β, βc).
end
of the cycle over c
For
c = 1, . . . ,˚c
βc ≡βc
¯β ,
ζc = 2 ln
βc
K

.
Do if ζc > 0, ζc =
?
ζc
For
i = 1, . . . ,˚y
xic =
?
Dicζc,
yi = min(yi, µic −xic),
yi = max(yi, µic + xic)
end
of the cycle over i
end of the condition ζc > 0
end
of the cycle over c
Rescaling
Both learning and design work on scaled data. Scaling is necessary both for
numeric reasons and uniﬁcation of various default values. The ﬁnal presenta-
tion has to be done in the original user’s units. It concerns predicted values
only as we can always normalize data fed into the conditions, including those
just contemplated. Thus, rescaling reduces to a simple, often aﬃne, transfor-
mation of pdfs, cf. Proposition 2.5.
Projections to be presented
Operator can see low-dimensional pdfs only. Thus, a practical question arises
— which of many possible projections is adequate?
The projected pdf is the ideal joint pdf resulting from the design. The
optimized inﬂuence of the presentation action is based on the fact that the
operator can willingly inﬂuence only the distribution of the shown quantities
having indexes zt. Thus, he can modify
f(dt|d(t −1)) →
f(dt|d(t −1))
f(dzt;t|d(t −1))
⌊If(dzt;t|d(t −1)) ≡⌊If(dt|zt, d(t −1)).
This relation models the inﬂuence of presentation actions zt; Section 9.1.3.
The strategy generating the actions zt is optimized to get the modiﬁed pdf
⌊If(dt|zt, d(t −1)) as close as possible to the user’s ideal pdf. It leads to the
clear conclusion: the marginal ⌊If(dzt;t|d(t−1)) has to be presented, otherwise
the optimal nature of the constructed advices is lost.

328
9 Design with normal mixtures
Point advice
Generally, advices to the operator are presented as marginal pdfs of a mix-
ture resulting from an optimization with the common instruction seek for a
high-probability area. Sometimes, a point advice is required. If the mixture is
unimodal (if it contains single component), the maximizing argument is such
an advice. It is harmonized with the above instruction. The question arises
whether the same argument should be used in the multimodal case. The an-
swer is positive. Such a choice can be interpreted as the maximum probable
advice. It minimizes the distance of the ideal pdf to the user’s ideal pdf while
selecting the user’s ideal pdf on advices as the optimized design knob; cf.
Proposition 7.11.
On experimental evaluation of the KL divergence
During experimental veriﬁcations of the designed advisory system, the natu-
ral question arose how to evaluate experimentally the KL divergence of the
objective pdf
⌊of of data (see Chapter 2) to the user’s ideal pdf
⌊Uf. The
most straightforward approximation of the unknown ⌊of by a formal sample
pdf fails. The sample pdf equals the average of the Dirac delta functions sit-
ting on measured data and cannot be used in expressions of the type • ln(•).
When approximating Dirac functions smoothly by Gaussian pdfs centered on
measured data and having variance R →0, we also get inﬁnite values. This
makes us use the normal approximation but selecting R as the minimizer of
the inspected KL divergence instead of considering R →0. It seems to be a
proper solution of the problem. Let us describe it in detail.
Let ⌊of(d(˚t)) = /
t∈t∗⌊of(dt|φt−1), where the state vectors φt include both
the state vector describing the objective dependence and the state vector in the
user’s ideal pdf ⌊Uf(d(˚t)) = /
t∈t∗⌊Uf(dt|φt−1). The normalized asymptotic
KL divergence can be written as follows.
lim˚t→∞
1
˚t D

⌊of
!!!
!!! ⌊Uf

= lim˚t→∞E
#
⌊of(dt|φt−1) ln
 ⌊of(dt|φt−1)
⌊Uf(dt|φt−1)

ddt
$



ω(φt−1)
.
If we manage to evaluate at least approximately a ﬁnite sample version of
ω(φt−1), we can use ordinary approximation
E[ω(φt−1)] ≈1
˚t
˚t

t=1
ω(˜φt−1),
hoping in ergodic behavior. The measured values are marked by the symbol ˜
in this paragraph.
As planned above, we approximate the objective pdf ⌊of(dt|φt−1) at the
measured point ˜dt, ˜φt−1 by the normal pdf ⌊of(dt|˜φt−1) ≈Ndt( ˜dt, R) with the
optional covariance matrix R.

9.1 Common tools
329
For the normal user’s ideal pdf
⌊Uf(dt|˜φt−1) = Ndt

⌊UM(˜φt−1), ⌊UR

,
Proposition 8.10 implies
ω(˜φt−1) = 0.5

ln
!!! ⌊URR−1!!! −˚
d + tr
	
R ⌊UR−1
+

˜dt −⌊UM(˜φt−1)
′ ⌊UR−1 
˜dt −⌊UM(˜φt−1)

.
It is minimized by R = ⌊UR. This result and the sample-mean replacement of
the expectation give the practical plausible indicator of the design quality
1
2˚t
˚t

t=1

˜dt −⌊UM(˜φt−1)
′ ⌊UR−1 
˜dt −⌊UM(˜φt−1)

.
(9.23)
9.1.5 Quadratic forms in a fully probabilistic design
Section 7.1.4 expresses the KL divergence of the constructed ideal pdf on the
p-data d(˚t) to the user’s ideal pdf ⌊Uf(d(˚t)). It consists of the true user’s ideal
pdf /
t∈t∗⌊Uf(do;t|do(t −1)) and of the factor on the surplus data dp+(˚t) of
the p-system. According to the assumption (5.7), it coincides with the pdf
/
t∈t∗⌊If(dp+;t|d(t −1)) derived from the constructed ideal pdf
⌊If(d(˚t)).
The fully probabilistic design, Proposition 2.11, with this special target is de-
scribed by Proposition 7.4. Its normal counterpart brings nothing new. The
speciﬁc nature of the normal case can be exploited after expressing upper
bounds on the KL divergence. Before progressing in this respect, the neces-
sary manipulations with expected quadratic forms and the conditional KL
divergence of normal pdfs are prepared. The formulas are expressed in the
way suitable for an eﬃcient evaluation that relies on the factorized form of
normal components.
It is worthwhile stressing, that LDL′ decomposition is used further on as
it ﬁts to the operations needed in the discussed design part of construction of
the p-system.
Proposition 9.5 (Expected quadratic form)
Under Agreement 9.1, let
us consider a normal parameterized component described by
f(∆t|uo;t, φt−1, Θ) ≡
 
i∈i∗
N∆i;t(θ′
iψi;t, ri) with
(9.24)
Θ ≡(Θ1, . . . , Θ ˚
∆),
Θi ≡[θi, ri]
ψ′
i;t ≡[∆′
(i+1)··· ˚
∆;t, u′
o;t, φ′
t−1] ≡[∆i+1;t, ψ′
i+1;t]
i = 0, 1, . . . , ˚
∆−1, recall ψ0;t ≡Ψt,
ψ′
˚
∆;t ≡[u′
o;t, φ′
t−1].
Let us consider a quadratic form in ψ0;t ≡Ψt with the given kernel L0D0L′
0.

330
9 Design with normal mixtures
Then, the expected quadratic form, lifted by a constant k0, reads
E[k0 + Ψ ′
tL0D0L′
0Ψt|uo;t, φt−1] ≡E[k0 + ψ′
0;tL0D0L′
0ψ0;t|ψ ˚
∆;t]
(9.25)
= k ˚
∆+ ψ′
˚
∆;tL ˚
∆D ˚
∆L′
˚
∆ψ ˚
∆;t,
where
Li+1Di+1L′
i+1 = ⌊ψLi
⌊ψDi
⌊ψL′
i +

θi+1 + ⌊∆ψLi

⌊∆Di

θi+1 + ⌊∆ψLi
′
ki+1 = ki + ⌊∆Diri+1,
for i = 0, . . . , ˚
∆−1,
with
Li ≡
#
1
0
⌊∆ψLi ⌊ψLi
$
, Di ≡diag
	
⌊∆Di, ⌊ψDi

,
where ⌊∆Di is scalar and ˚
Di+1 = ˚
Di −1.
The updating the LDL′ decomposition can be made using Algorithm 8.2.
Proof. The expectation is taken over entries of ∆t since the remaining part of
the data vector Ψt is ﬁxed by the condition ψ ˚
∆;t ≡[u′
o;t, φ′
t−1]′. The the chain
rule for expectations, Proposition 2.6, implies that we can evaluate conditional
expectations of individual entries in the vector ∆t one-by-one, starting from
the ﬁrst one. Taking a generic step and using the identity
E

∆2
i+1|ψi+1

= ri+1 + {E[∆i+1|ψi+1]}2 ,
we have
E

ki + ψ′
i;tLiDiL′
iψi;t|ψi+1;t

= ki + ⌊∆Diri+1



ki+1
+ ψ′
i+1;t
# θ′
i+1
I˚
ψi+1
$′
LiDiL′
i
# θ′
i+1
I˚
ψi+1
$
ψi+1;t = ki+1
+ ψ′
i+1;t
#
⌊ψLi
⌊ψDi
⌊ψL′
i +

θi+1 + ⌊∆ψLi

⌊∆Di

θi+1 + ⌊∆ψLi
′$



Li+1Di+1L′
i+1
ψi+1;t.
The treated quadratic forms do not contain linear term due to the in-
clusion of unit into regression vector. It can be numerically dangerous as it
corresponds to the system description with a state at stability boundary. Con-
sequently, the numerical noise causes divergence in dynamic programming.
Moreover, when using this inclusion, the constant lift of the quadratic form is
split into two parts and design algorithms need their sum. In software imple-
mentation, it is simply avoided by treating the linear term of quadratic form
independently using the following proposition.
Proposition 9.6 (Expected linear form of factorized component)
Under Agreement 9.1, let us consider a normal parameterized component de-
scribed by (9.24) and a linear form l′
0ψ0;t in ψ0;t ≡Ψt given by a vector l0.

9.1 Common tools
331
The expected linear form is evaluated recursively for i = 0, . . . , ˚
∆−1
E[l′
0Ψt|uo;t, φt−1] ≡E[l′
0ψ0;t|ψ ˚
∆;t] = l′
˚
∆ψ ˚
∆;t
(9.26)
l′
i+1 = ⌊∆liθ′
i+1 + ⌊ψl′
i with li ≡
 ⌊∆li ⌊ψl′
i
′ ,
⌊∆li is scalar, ˚li+1 =˚li −1.
Proof. The expectation is taken over entries of ∆t as the rest of the data
vector Ψt is ﬁxed by the condition ψ ˚
∆;t ≡[u′
o;t, φ′
t−1]′. The the chain rule
for expectations, Proposition 2.6, implies that we can evaluate conditional
expectations of individual entries in ∆t one-by-one, starting from the ﬁrst
one
E [l′
iψi;t|ψi+1;t] = l′
i
# θ′
i+1
I˚
ψi+1
$
ψi+1;t =
	
⌊∆liθ′
i+1 + ⌊ψl′
i




l′
i+1
ψi+1;t.
A combination of Propositions 9.5, 9.6 gives a numerically safe evaluation
of the expected value of the lifted quadratic form. The algorithm is based on
a separate processing of the linear term in the treated quadratic form.
Algorithm 9.6 (Safe evaluation of the expected quadratic form)
Initial mode
•
Specify parameters
¯θ′
i, ri

≡([θ′
i, µi] , ri) of a component in the factorized
form with the scalar oﬀset µi at the last position.
•
Specify the lift ¯k0 ≡k0 and the kernel ¯L0 ¯D¯L′
0 of the lifted quadratic form
in k0 + ψ′
0;t ¯L0 ¯D¯L′
0ψ0;t whose expectation conditioned by ψ ˚
∆;t is evaluated.
The matrices ¯Li, ¯Di, i = 0, . . . , ˚
∆−1, are split
¯Li =
#
Li 0
l′
i 1
$
, ¯Di =
#
Di
0
$
.
Recursive mode
For
i = 1, . . . , ˚
∆
Li+1Di+1L′
i+1 = ⌊ψLi
⌊ψDi
⌊ψL′
i +

θi+1 + ⌊∆ψLi

⌊∆Di

θi+1 + ⌊∆ψLi
′
.
Updating of the LDL′ decomposition is made using Algorithm 8.2.
ki+1 = ki + ⌊∆Diri+1,
with
Li ≡
#
1
0
⌊∆ψLi ⌊ψLi
$
, Di ≡diag
	
⌊∆Di, ⌊ψDi

,
where ⌊∆Di is scalar and
˚
Di+1 = ˚
Di −1
l′
i+1 = ⌊∆li¯θ′
i+1 + ⌊ψl′
i with,
li ≡
 ⌊∆li ⌊ψl′
i
′ ,
where ⌊∆li is scalar, ˚li+1 =˚li −1.
The operations ki+1 ≡ki + 2l˚
ψi+1(i+1),
l˚
ψi+1(i+1) = 0

332
9 Design with normal mixtures
shift a constant from the linear term to the lift.
end
of the cycle over i
The following auxiliary proposition is repeatedly used in approximate, fully
probabilistic designs.
Proposition 9.7 (The conditional KL divergence) Under Agreement 9.1,
let ∆t = (∆o;t, ∆p+;t), f(∆t|uo;t, d(t −1)) = / ˚
∆
i=1 N∆i;t(θ′
iψi;t, ri) and
⌊Uf(∆o;t|uo;t, d(t −1)) =
˚
∆o
 
i=1
N∆i;t

⌊Uθ′
iψi;t, ⌊Uri

.
The regression coeﬃcients
⌊Uθi of the user’s ideal pdf
⌊Uf(·) are comple-
mented by zeros so that the regression vectors ψi;t for the ith factor and
the corresponding factor of the user’s ideal pdf are common. Recall that, for
i ∈{0, . . . , ˚
∆−1},
ψi;t = [∆′
(i+1)··· ˚
∆;t, u′
o;t, φ′
t−1]′ ≡[∆′
(i+1)··· ˚
∆;t, ψ′
˚
∆;t]′ ≡[∆(i+1);t, ψ′
i+1;t]′
ψ ˚
∆;t = [u′
o;t, φ′
t−1]′.
Then,
ω(uo;t, φt−1) ≡ω(ψ ˚
∆;t)
(9.27)
≡2

f(∆t|uo;t, φt−1) ln
f(∆o;t|∆p+;t, uo;t, φt−1)
⌊Uf(∆o;t|uo;t, φt−1)

d∆t
= k ˚
∆+ ψ′
˚
∆;tL ˚
∆D ˚
∆L′
˚
∆ψ ˚
∆;t.
The lift k ˚
∆and kernel L ˚
∆D ˚
∆L′
˚
∆of the conditional KL divergence are found
recursively
For
i = 1, . . . , ˚
∆
LiDiL′
i = ⌊ψLi−1
⌊ψDi−1
⌊ψL′
i−1
+

θi + ⌊∆ψLi−1)

⌊∆Di−1

θi + ⌊∆ψLi−1
′
+χ

i ≤˚
∆o
 
θi −⌊Uθi

⌊Ur−1
i

θi −⌊Uθi
′
ki = ki−1 + ⌊∆Di−1ri + χ

i ≤˚
∆o
 #
ln
 ⌊Uri
ri

+
ri
⌊Uri
$
,
k0 = −˚
∆o, D0 = 0˚
ψ,˚
ψ, L0 = I˚
ψ
Li ≡
#
1
0
⌊∆ψLi ⌊ψLi
$
, Di ≡diag
	
⌊∆Di, ⌊ψDi

,
where
⌊∆Di is scalar and ˚
Di+1 = ˚
Di −1.
end
of the cycle over i

9.1 Common tools
333
The updating of the LDL′ (!) decomposition can be done by a double, if the
set indicator χ(·) = 1, or single, if χ(·) = 0, use of Algorithm 8.2.
Proof. Let the innovations be split ∆= (∆o, ∆p+). Then,
ω(uo;t, φt−1)
2

f(∆t|uo;t, φt−1) ln

f(∆t|uo;t, d(t −1))
f(∆p+;t|uo;t, d(t −1)) ⌊Uf(∆o;t|uo;t, d(t −1))

d∆t
=
˚
∆o

i=1
ln
 ⌊Uri
ri

+
˚
∆o

i=1

f(∆t|uo;t, φt−1)
×

−(∆i;t −θ′
iψi;t)2
ri
+

∆i;t −⌊Uθ′
iψi;t
2
⌊Uri

d∆t
=

Proposition 2.6
E[•2] = E2[•] + cov[•]
=
˚
∆o

i=1
ln
 ⌊Uri
ri

−˚
∆o +
˚
∆o

i=1

f(∆t|uo;t, φt−1)(∆i;t −⌊Uθ′
iψi;t)2
⌊Uri
d∆t
=

Proposition 2.6
−˚
∆o +
˚
∆o

i=1
#
ln
 ⌊Uri
ri

+
ri
⌊Uri
$
+
˚
∆o

i=1
E
#
ψ′
i;t

θi −⌊Uθi

⌊Ur−1
i

θi −⌊Uθi
′
ψi;t
!!!! ψ ˚
∆;t
$
.
Let us deﬁne the kernel Li−1Di−1L′
i−1 of the lifted quadratic form ki−1 +
ψ′
i−1;tLi−1Di−1L′
i−1ψi−1;t for which we evaluate
E[ki−1 + ψ′
i−1;tLi−1Di−1L′
i−1ψi−1;t|ψ ˚
∆;t].
Then, according to the equation (9.26) in the proof of Proposition 9.5, an
intermediate lifted quadratic form arises ˜ki + ψ′
i;t ˜Li ˜Di ˜L′
iψi;t with
˜Li ˜Di ˜L′
i = ⌊ψLi−1
⌊ψDi−1
⌊ψL′
i−1 +

θi + ⌊∆ψLi−1

⌊∆Di−1

θi + ⌊∆ψLi−1
′
˜ki = ki−1 + ⌊∆Di−1ri.
While i ≤˚
∆o, the expression
ln
 ⌊Uri
ri

+
ri
⌊Uri
+ ψ′
i;t

θi −⌊Uθi

⌊Ur−1
i

θi −⌊Uθi
′
ψi;t
has to be added to it.

334
9 Design with normal mixtures
LiDiL′
i = ⌊ψLi−1
⌊ψDi−1
⌊ψL′
i−1 +

θi + ⌊∆ψLi−1

⌊∆Di−1

θi + ⌊∆ψLi−1
′
+ χ

i ≤˚
∆o
 
θi −⌊Uθi
 
θi −⌊Uθi
′
⌊Uri
ki = ki−1 + ⌊∆Di−1ri + χ

i ≤˚
∆o
 #
ln
 ⌊Uri
ri

+
ri
⌊Uri
$
.
The updating can be made by a double or single use of Algorithm 8.2. The
initial values are k0 = −˚
∆o and D0 = 0; L0 = I = unit matrix.
While performing the approximate fully probabilistic design, we work with
a weighted version of the conditional KL divergence. The following slight
extension of Proposition 9.7 supports the cases for which the function −ln(γ)
determining the Bellman function is approximated by a lifted quadratic form.
Proposition 9.8 (The weighted conditional KL divergence) Under
Agreement 9.1, let
∆t = (∆o;t, ∆p+;t) = (o-innovations, innovations in the surplus p-space),
f(∆t|uo;t, d(t −1)) =
˚
∆
 
i=1
N∆i;t(θ′
iψi;t, ri),
⌊Uf(∆o;t|uo;t, d(t −1)) =
˚
∆o
 
i=1
N∆i;t

⌊Uθ′
iψi;t, ⌊Uri

.
The regression coeﬃcients ⌊Uθi of the user’s ideal pdf ⌊Uf(·) are complemented
by zeros so that regression vectors ψi;t of the corresponding factors coincide.
Recall, that ψ ˚
∆;t = [u′
o;t, φ′
t−1]′ and for i ∈{0, . . . , ˚
∆−1}
ψi;t = [∆′
(i+1)··· ˚
∆;t, u′
o;t, φ′
t−1]′ ≡[∆′
(i+1)··· ˚
∆;t, ψ′
˚
∆;t]′ ≡[∆(i+1);t, ψ′
i+1;t]′.
Let, moreover,
γ(φt) ≡exp

−0.5(kγ + φ′
tLγDγL′
γφt)

,
where
(9.28)
φt ≡[d′
t···(t−∂+1), 1]′ ⇒ψ0;t ≡Ψt ≡[∆′
t, u′
o;t, φ′
t−1]′,
Lγ ≡a lower triangular matrix with unit diagonal
Dγ ≡a diagonal matrix with nonnegative diagonal entries.
Then,
ωγ(uo;t, φt−1) ≡
(9.29)
≡2

f(∆t|uo;t, φt−1) ln
 f(∆o;t|∆p+;t, uo;t, φt−1)
γ(φt) ⌊Uf(∆o;t|uo;t, φt−1)

d∆t
= k ˚
∆+ ψ′
˚
∆;tL ˚
∆D ˚
∆L′
˚
∆ψ ˚
∆;t.

9.1 Common tools
335
Lift k ˚
∆and kernel L ˚
∆D ˚
∆L′
˚
∆of the KL divergence are found recursively
For
i = 1, . . . , ˚
∆
LiDiL′
i = ⌊ψLi−1
⌊ψDi−1
⌊ψL′
i−1
+

θi + ⌊∆ψLi−1

⌊∆Di−1

θi + ⌊∆ψLi−1
′
+χ

i ≤˚
∆o
 
θi −⌊Uθi
 
θi −⌊Uθi
′
⌊Uri
ki = ki−1 + ⌊∆Di−1ri + χ

i ≤˚
∆o
 #
ln
 ⌊Uri
ri

+
ri
⌊Uri
$
end
of the cycle over i
k0 = −˚
∆o + kγ, L0D0L′
0 = KLγDγL′
γK′
K′ ≡
#I˚
d(∂−1)
0
0
0
01,˚
d 1
$
(9.30)
Li ≡
#
1
0
⌊∆ψLi ⌊ψLi
$
, Di ≡diag
	
⌊∆Di, ⌊ψDi

,
where ⌊∆Di is scalar and ˚
Di+1 = ˚
Di −1.
The updating of the LDL′ (!) decomposition can be made by a double, if the
set indicator χ(·) = 1, or single, if χ(·) = 0, use of Algorithm 8.2.
Proof. The function γ(φt) just adds nontrivial initial conditions. The matrix K
extends the quadratic form in φt to the quadratic form in Ψt ≡ψ0;t. Otherwise,
the proof of Proposition 9.7 can be copied.
The role of the matrix K (9.30) that expresses the vector φt as a function
of Ψt ≡ψ0;t is more visible if we distinguish the entries corresponding to the
position of the unit in the phase form of the state vector; Agreement 9.1.
Let Lγ ≡
# ⌊φ0Lγ 0
⌊φ1L′
γ 1
$
, Dγ = diag
	
⌊φ0Dγ, ⌊1Dγ

,
⌊1Dγ is scalar.
(9.31)
Then, L′
γK′ =
# ⌊φ0L′
γ 0
⌊φ1Lγ
0
01,˚
d
1
$
and
KLγDγL′
γK′ =
⎡
⎣
⌊φ0Lγ ⌊φ0Dγ ⌊φ0′Lγ 0
⌊φ0Dγ ⌊φ1Lγ
0
0˚
d,˚
d
0˚
d,1
⌊φ1L′
γ
⌊φ0Lγ
01,˚
d
⌊φ1L′
γ
⌊φ0Dγ ⌊φ1Lγ + ⌊1Dγ
⎤
⎦.
It is straightforward to verify that the following algorithm provides LDL′
decomposition of this kernel.
Algorithm 9.7 (Extension of kernel φ′
tLγDγL′
γφt →ψ′
0;tL0D0L′
0ψ0;t)
D0 = diag
	
diag
 ⌊φ0Dγ

, 01,˚
d, ⌊1Dγ

, L0 =
⎡
⎣
⌊φ0Lγ 0 0
0
I˚
d 0
⌊φ1L′
γ 0 1
⎤
⎦,
⌊1Dγ is scalar.

336
9 Design with normal mixtures
The following auxiliary proposition is useful in the industrial and simulta-
neous designs operating at the factor level.
Proposition 9.9 (Normal expectation of exp(quadratic form)) Let
ψ′
˚
∆= [u′, φ′] and f(u|φ) = /˚
d
i= ˚
∆+1 Nui−˚
∆(θ′
iψi, ri) ≡/˚
d
i= ˚
∆+1 N∆i(θ′
iψi, ri)
with known parameters and ψ′
i = [u′
i+1−˚
∆, ψ′
i+1], ˚
∆≤i < ˚
d, ψ˚
d = φ. Let us
consider the lifted quadratic positive semi-deﬁnite form k ˚
∆+ψ′
˚
∆L ˚
∆D ˚
∆L′
˚
∆ψ ˚
∆.
The lift k ˚
∆is nonnegative, L ˚
∆is a lower triangular matrix with unit diagonal
and D ˚
∆is a diagonal matrix with nonnegative diagonal entries. Then,
E

exp

−0.5

k ˚
∆+ ψ′
˚
∆L ˚
∆D ˚
∆L′
˚
∆ψ ˚
∆

|φ

≡

f(u|φ) exp

−0.5(k ˚
∆+ ψ′
˚
∆L ˚
∆D ˚
∆L′
˚
∆ψ ˚
∆)

du
= exp
	
−0.5(k˚
d + φ′L˚
dD˚
dL′
˚
dφ)

.
The lift and kernel are found recursively
For
i = ˚
∆+ 1, . . . , ˚
d
˜Li ˜Di ˜L′
i = Li−1Di−1L′
i−1 + [−1, θ′
i]′r−1
i
[−1, θ′
i],
(9.32)
˜Li =
#
1
0
⌊1ψ˜Li Li
$
, ˜Di = diag
	
⌊1˜Di, Di

,
⌊1˜Di is scalar,
ki = ki−1 + ln

ri
⌊1˜Di

, ˚
Di = ˚
Di−1 −1.
end
of the cycle over i
The updating of the LDL′ (!) decomposition can be done by Algorithm 8.2.
Proof. The the chain rule for expectation, Proposition 2.6, implies the need
to evaluate, for i = ˚
∆+ 1, . . . , ˚
d,

(2πri)−0.5
× exp
"
−ki−1 + [u, ψ′
i]

[−1, θ′
i]′r−1
i
[−1, θ′
i] + Li−1Di−1L′
i−1

[u, ψ′
i]′
2
%
du
≡

(2πri)−0.5 exp

−0.5

ki−1 + [u, ψ′
i]˜Li ˜Di ˜L′
i[u, ψ′
i]′
du
= exp
	
−0.5

ki−1 + ln

ri
⌊1˜Di

+ ψ′
iLiDiL′
iψi

.
It remains to recall that ψ˚
d ≡φ.
Within the considered framework, the evaluation of the KL divergences
reduces to manipulations with expected quadratic forms. In the computation-
ally advantageous factorized version, the correct way of computing the second
moment for mixture models can easily be overlooked. This observation and

9.1 Common tools
337
applicability in special design versions makes us evaluate this moment on the
component basis.
Proposition 9.10 (Expected quadratic form: matrix components) Let
L be a lower triangular matrix with unit diagonal and D be a diagonal ma-
trix with nonnegative entries. Let the normal mixture with matrix components
describe the evolution of the state vector in the phase form. Then, it holds
E[φ′
tLDL′φt|ψt, Θ] =

c∈c∗
	
ψ′
tA′
cLDL′Acψt + αctr

⌊∆L ⌊∆D ⌊∆L′rc

Ac ≡√αc
#
θ′
c
Λ
$
,
Λ ≡
# I˚
ψ−˚
∆−1 0˚
ψ−˚
∆−1, ˚
∆+1 0
01,˚
ψ−˚
∆−1
01, ˚
∆+1
1
$
,
where
(9.33)
L =
#
⌊∆L
0
⌊∆ψL ⌊ψL
$
, D =
# ⌊∆D
0
0
⌊ψD
$
,
⌊∆L,
⌊∆D are ( ˚
∆, ˚
∆)-matrices.
Proof. It exploits the phase form of the state, known moments of components
and identities: E[xx′] = E[x]E[x′] + cov(x), E[x′Qx] = tr[Qcov(x)] valid for
any vector and any symmetric (˚x,˚x)-kernel Q.
Now we are ready to focus on the fact that the individual predictors form-
ing the optimized pdf ⌊If(d(˚t)) are ﬁnite mixtures. This makes evaluation of
the KL divergence D
 ⌊If|| ⌊Uf

and consequently the application of Propo-
sition 2.11 impossible. For this reason, we follow the direction outlined in
Chapter 7 and use the Jensen inequality (2.14) for ﬁnding an upper bound on
the KL divergence. It gives us a chance to optimize at least this upper bound.
Its structure is demonstrated on the matrix form of the involved normal pdfs.
Proposition 9.11 (J divergence of a mixture to ⌊Uf) Let us consider
the joint pdf on observed data d(˚t) ∈d∗(˚t)
f(d(˚t)) ≡
 
t∈t∗

c∈c∗
αc;tNdt(θ′
cφt−1, rc),
where the matrix parameters θc, rc of normal components as well as their pos-
sibly past-data-dependent probabilistic weights αc;t are known. Let ⌊Uf(d(˚t)) =
/
t∈t∗Ndt
 ⌊Uθ′φt−1, ⌊Ur

be another known normal pdf. If need be, the matrix
regression coeﬃcients θc in all components as well as in ⌊Uθ are complemented
by zeros so that the state vector φt−1 is common to all of them. Then, the fol-
lowing inequality holds
D

f
!!!
!!! ⌊Uf

≤J

f
!!!
!!! ⌊Uf

≡0.5E
"
t∈t∗
α′
tω(φt−1)
%
with
ω(φt−1) ≡[ω (1, φt−1) , . . . , ω (˚c, φt−1)]′
ω(c, φt−1) ≡2

f(dt|d(t −1), c) ln
 f(dt|d(t −1), c)
⌊Uf(dt|d(t −1))

ddt

338
9 Design with normal mixtures
= kc + φ′
t−1LcDcL′
cφt−1, where
kc ≡ln
!!! ⌊Urr−1
c
!!! −˚
d + tr
	
rc
⌊Ur−1
LcDcL′
c ≡

θc −⌊Uθ

⌊Ur−1 
θc −⌊Uθ
′
.
(9.34)
The J divergence J

f
!!!! ⌊Uf

is nonnegative and equal to zero iﬀrc = ⌊Ur
and θ′
cφt−1 = ⌊Uθ′φt−1 ∀t ∈t∗and c ∈c∗for which αc;t > 0.
Proof. It is implied by a direct combination of Propositions 7.5, 8.10.
9.2 Design of the advising strategy
Here, design variants of the academic, industrial and simultaneous advisory
systems are discussed in the special case of normal components and the normal
user’s ideal pdf.
9.2.1 Academic design
The recommended pointers to components ct are the actions of the aca-
demic p-system. They are described by the optimized academic strategy
 ⌊If(ct|d(t −1))

t∈t∗. The strategy determines, together with the estimated
model of the o-system, the ideal pdfs
⌊If(dt, ct|d(t −1)) ≡
˚
d
 
i=1
Ndict;t

θ′
ictψict;t, rict
 ⌊If(ct|d(t −1)) with dt ≡∆t.
(9.35)
For the adopted fully probabilistic design, we have to specify the user’s ideal
pdf. We assume its normality on the o-data d∗
o;t. This true user’s ideal pdf is
extended on d∗
t in the way discussed in Section 5.1.5. It is extended further
on c∗
t by specifying the target pf
⌊Uf(ct|d(t −1)) for the academic advices,
i.e., for the recommended pointers ct.
Initially, we always evaluate dangerous components (see Agreement 5.9 and
Section 9.1.1), and reduce the support of ⌊Uf(ct|d(t−1)) to the nondangerous
components. The optimal design of the academic p-system is solved by this
choice if the reduced set contains just a single component. This component
is oﬀered to the operator as the designed ideal pdf. Otherwise, the normal
version of the optimal academic advising strategy described by Proposition
7.10 has to be searched for.
Proposition 9.12 (Academic design with the γ-bound) Let us consider
the academic design for the o-system described by the mixture with normal
components (9.1) having the state φ in the phase form; Agreement 9.1. Lack

9.2 Design of the advising strategy
339
of recognizable actions implies that the innovation ∆t and the data record dt
coincide.
Let dt = (do;t, dp+;t) = (o-data, surplus p-data) and the user’s ideal pdf
⌊Uf(d(˚t)) on d∗(˚t) be deﬁned by
⌊Uf(dt|d(t −1)) ≡
 
io∈i∗
o
Ndi;t

⌊Uθ′
iψi;t, ⌊Uri

⌊If(dp+;t|d(t −1))
i∗
o ≡{1, . . . , ˚
do} ⊂i∗≡{1, . . . , ˚
d}.
(9.36)
The parameters Θic = [θic, ric], i ∈i∗, c ∈c∗, of the mixture model as well
those determining the normal user’s ideal pdf
⌊UΘ ≡
 ⌊Uθi, ⌊Uri

i∈i∗are
assumed to be known. Regression coeﬃcients θic,
⌊Uθi are complemented by
zeros so that the corresponding factors of the user’s ideal pdf and the mix-
ture model have the common regression vectors ψi;t ≡

di+1;t, ψ′
i+1;t
′ =
	
d′
(i+1)···˚
d;t, φ′
t−1
′
, i < ˚
d, ψ˚
d;t ≡φt−1.
The recommended pointers ct are allowed to have nonzero values at most
for indexes in c∗that point to nondangerous components; Agreement 5.9.
Let us search for the causal advising strategy {d∗(t −1) →ct ∈c∗}t∈t∗,
that, at least approximately, minimizes the KL divergence of ⌊If(d(˚t), c(˚t)) to
the user’s ideal pdf
⌊Uf(d(˚t), c(˚t)) =
 
t∈t∗
⌊Uf(dt|d(t −1)) ⌊Uf(ct|d(t −1)).
In this description, the deﬁnition (9.36) is used and the user’s ideal pf on ct+1
is considered in the form
⌊Uf(ct+1|d(t)) ∝⌊Uf(ct+1) exp
	
−0.5 ⌊Uω(ct+1, φt)

(9.37)
⌊Uf(ct+1) is a probabilistic vector
⌊Uω(ct+1, φt) ≡⌊Ukct+1;t + φ′
t
⌊ULct+1;t
⌊UDct+1;t
⌊UL′
ct+1;tφt.
(9.38)
The ﬁxed, data independent, part ⌊Uf(ct+1) serves for the speciﬁcation of sup-
port on nondangerous components. The lifts ⌊Ukc;t ≥0 and kernels
⌊ULct+1;t
⌊UDct+1;t
⌊UL′
ct+1;t,
determined by the lower triangular matrices with unit diagonal ⌊ULct+1;t and
the diagonal matrices ⌊UDct+1;t, are assumed to be data independent. Mostly,
they are even time-invariant. The lifted quadratic form determines a preferable
user strategy of selecting recommended pointers ct+1 ∈c∗.
The LDL′ decomposition of kernels used below are split
L ≡
#
1
0
⌊dψL ⌊ψL
$
,
D ≡diag
	
⌊dD, ⌊ψD

,
where ⌊dD is scalar.

340
9 Design with normal mixtures
Let us consider the following strategy, c ∈c∗,
⌊If(ct|φt−1) ∝⌊Uf(ct) exp[−0.5ωγ(ct, φt−1)],
where
(9.39)
ωγ(ct, φt−1) ≡kct;t−1 + φ′
t−1Lct;t−1Dct;t−1L′
ct;t−1φt−1.
The lifts kct;t−1 and kernels Lct;t−1Dct;t−1L′
ct;t−1, c ∈c∗, are evaluated
against the time course t = ˚t,˚t −1, . . . , 1, with the initial values kc;˚t = 0,
Lc;˚t = I˚
φ = unit matrix, Dc;˚t = 0˚
φ,˚
φ.
For
t = ˚t, . . . , 1
For
c = 1, . . . ,˚c
Create the common initial conditions of recursions over factors
k0c ≡−˚
do ≡average lift.
L0c = I˚
Ψ, D0c = 0˚
Ψ,˚
Ψ ≡average kernel.
For
˜c = 1, . . . ,˚c
β˜c ∝⌊Uf(˜c) exp(−0.5k˜c;t),
(9.40)
L0cD0cL′
0c ≡L0cD0cL′
0c + β˜c, ˜L˜c;t ˜D˜c;t ˜L′
˜c;t.
The kernel decomposition ˜L˜c;t, ˜D˜c;t is speciﬁed using the split
L˜c;t ≡
# ⌊ψ0L˜c;t 0
⌊ψ1L′
˜c;t 1
$
,
D˜c;t = diag
	
diag
	
⌊ψ0D˜c;t

, ⌊1D˜c;t

,
⌊1D˜c;t is scalar.
˜L˜c;t ≡
⎡
⎣
⌊ψ0L˜c;t 0 0
0
I˚
d 0
⌊ψ1L′
˜c;t 0 1
⎤
⎦,
˜D˜c;t = diag
	
diag
	
⌊ψ0D˜c;t

, 01,˚
d, ⌊1D˜c;t

.
end
of the cycle over ˜c
For
i = 1, . . . , ˚
d
LicDicL′
ic = ⌊ψL(i−1)c
⌊ψD(i−1)c
⌊ψL′
(i−1)c
+

θic + ⌊dψL(i−1)c

⌊dD(i−1)c

θic + ⌊dψL(i−1)c
′
+χ

i ≤˚
do
 
θic −⌊Uθi

⌊Ur−1
i

θic −⌊Uθi
′
,
kic = k(i−1)c + ⌊dD(i−1)cric + χ

i ≤˚
do
 #
ln
 ⌊Uri
ric

+ ric
⌊Uri
$
.
end
of the cycle over i
Lc;t−1Dc;t−1L′
c;t−1 ≡L˚
dcD˚
dcL′
˚
dc + ⌊ULc;t−1
⌊UDc;t−1
⌊UL′
c;t−1
kc;t−1 ≡k˚
dc + ⌊Ukc;t−1
end
of the cycle over c
end
of the cycle over t

9.2 Design of the advising strategy
341
Then, this strategy minimizes the KL divergence loss for the design horizon
equal to one. For longer horizons, it minimizes the upper bound of the γ-type
on the KL divergence (see Proposition 7.8) as it replaces the Bellman function
−ln
⎧
⎨
⎩

ct+1∈c∗
⌊Uf(ct+1) exp[−0.5ωγ(ct+1, φt)]
⎫
⎬
⎭by the larger value
(9.41)
1
2

ct+1∈c∗
βct+1φ′
tLct+1;tDct+1;tL′
ct+1;tφt + data and strategy independent term.
Proof. Let us assume that the Bellman function is −ln(γ(φt)), with
γ(φt) = exp
⎡
⎣−0.5

ct+1∈c∗
βct+1φ′
tLct+1;tDct+1;tL′
ct+1;tφt
⎤
⎦, where
βct+1 ∝⌊Uf(ct+1) exp[−0.5kct+1;t].
The kernels Lct+1;tDct+1;tL′
ct+1;t and the lifts kct+1;t are conjectured to be
independent of data.
This conjecture is true for t = ˚t with kc˚
t+1;˚t = 0, Lc˚
t+1;˚t = I˚
φ, Dc˚
t+1;˚t =
0˚
φ,˚
φ. We prove that this form is preserved during the backward induction for
t < ˚t, if the approximation (9.41) is used. It gives us also the algorithmic
solution of the inspected problem.
First, we rewrite the assumed form of γ(φt) into the quadratic form in
Ψt ≡ψ0;t, taking into account the phase form of the state φt = K′Ψt; see
(9.30). This implies
γ(φt) = exp

−0.5ψ′
0;tL0D0L′
0ψ0;t

with
L0D0L′
0 ≡

ct+1∈c∗
βct+1KLct+1;tDct+1;tL′
ct+1;tK′ average kernel.
Algorithm 9.7 implies the explicit expression of the kernel
L0D0L′
0 ≡

ct+1∈c∗
βct+1 ˜Lct+1;t ˜Dct+1;t ˜L′
ct+1;t,
˜Lc;t ≡
⎡
⎣
⌊ψ0Lc;t 0 0
0
I˚
d 0
⌊ψ1L′
c;t 0 1
⎤
⎦,
˜Dc;t = diag
	
diag
	
⌊ψ0Dc;t

, 01,˚
d, ⌊1Dc;t

.
The tth step of dynamic programming, with ˚
∆≡˚
d, becomes

342
9 Design with normal mixtures
min
{ ⌊If(ct|d(t−1))}
2
ct∈c∗
⌊If(ct|d(t −1))
×
⎡
⎢⎣0.5
⎛
⎜
⎝˜ωγ(ct, φt−1) + ⌊Uω(ct, φt−1)



(9.38)
⎞
⎟
⎠+ ln
 ⌊If(ct|d(t −1))
⌊Uf(ct)

⎤
⎥⎦
˜ωγ(ct, φt−1)
≡
2

f(dt|φt−1, ct) ln
f(do;t|dp+;t, φt−1, ct)
γ(φt) ⌊Uf(do;t|φt−1)

ddt.
The deﬁnition ωγ(ct, φt−1) ≡˜ωγ(ct, φt−1) + ⌊Uω(ct, φt−1) and use of the
Proposition 9.8 imply
ωγ(ct, φt−1) = k˚
dct;t−1 + ⌊Ukct;t−1 + φ′
t−1Lct;t−1Dct;t−1L′
ct;t−1φt−1,
Lc;t−1Dc;t−1L′
c;t−1 ≡L˚
dcD˚
dcL′
˚
dc + ⌊ULc;t−1
⌊UDc;t−1
⌊UL′
c;t−1,
LicDicL′
ic = ⌊ψL(i−1)c
⌊ψD(i−1)c
⌊ψL′
(i−1)c
+

θic + ⌊dψL(i−1)c

⌊dD(i−1)c

θic + ⌊dψL(i−1)c
′
+ χ

i ≤˚
do
 
θic −⌊Uθi

⌊Ur−1
i

θic −⌊Uθi
′
,
kic = k(i−1)c + ⌊dD(i−1)cric + χ

i ≤˚
do
 #
ln
 ⌊Uri
ric

+ ric
⌊Uri
$
i = 1, . . . , ˚
d, with the common initial conditions
L0c = L0, D0c = D0,
k0c = −˚
do + k0.
The minimizing argument is
f(ct|φt−1) = ⌊Uf(ct) exp[−0.5ωγ(ct, φt−1)]/˜γ(φt−1),
where ˜γ(φt−1) is normalizing factor, i.e.,
˜γ(φt−1) = q

ct∈c∗
βct exp

−0.5φt−1Lct;t−1Dct;t−1L′
ct;t−1φt−1

with
q ≡

ct∈c∗
⌊Uf(ct) exp[−0.5kct;t−1].
The form of the reached minimum −ln(˜γ(φt−1)) diﬀers from that assumed
and cannot be practically used further on. The inequality between weighted
arithmetic and geometric means implies that
˜γ(φt−1) ≥q exp

−0.5

ct∈c∗
βctφ′
t−1Lc;t−1Dc;t−1L′
c;t−1φt−1

≡γ(φt−1),
where the right-hand side has the same form as that assumed for γ(φt). The
Bellman function −ln(˜γ(φ)) is decreasing function of the values ˜γ(φt). Con-
sequently, the adopted approximation (9.41), that replaces the function ˜γ(φt)

9.2 Design of the advising strategy
343
by the function γ(φt), bounds the minimized functional from above while
preserving the advantageous analytical form.
The proved proposition combined with the certainty-equivalence strategy
gives the following algorithm.
Algorithm 9.8 (Fixed academic advising with the γ-bound)
Initial (oﬄine) mode
•
Estimate the normal mixture model of the o-system with the state φt, Chap-
ter 8, and use the point estimates of parameters in the deﬁnition of the
individual components /˚
d
i=1 Ndic (θ′
icψic, ric), c ∈c∗.
•
Evaluate the steady-state behaviors of individual components; Section 9.1.1.
•
Exclude dangerous components (Agreement 5.9) or stabilize them using
Algorithm 9.3.
•
Return to the learning phase if all components are dangerous.
•
Take the nondangerous component as the ideal pdf oﬀered to the operator
and go to Sequential mode if ˚c = 1.
•
Specify the true user’s ideal pdf on the response of the o-system
⌊Uf(do;t|do(t −1)) ≡⌊Uf(do;t|φt−1) =
˚
do
 
i=1
Ndi;t

⌊Uθ′
iψi;t, ⌊Uri

.
•
Specify data and time invariant part ⌊Uf(ct) of the user’s ideal pf on the
recommended pointers. It is zero on dangerous components.
•
Choose data and time invariant lifts ⌊Ukct and kernels of the user-speciﬁed
KL divergence ⌊ULct,
⌊UDct. It completes the deﬁnition of the user’s ideal
pf ⌊Uf(ct|d(t −1)); see (9.37).
•
Select the length of the design horizon ˚t ≥1.
•
Initialize the iterative mode by setting Lc;˚t = I˚
φ, Dc;˚t = 0˚
φ,˚
φ, kc;˚t = 0,
c ∈c∗.
Iterative (oﬄine) mode
•
Correct the quadratic forms, for t = ˚t,˚t−1, . . . , 1, according to the formulas
(9.40).
•
Take the terminal characteristics as those describing the approximate
optimal steady-state strategy; Chapter 3,
kc ≡kc;1, Lc ≡Lc;1, Dc ≡Dc;1, c ∈c∗.
Sequential (online) mode, running for t = 1, 2, . . . ,
1. Acquire the data record dt and determine the state vector φt.
2. Evaluate the values of the pf describing the optimal academic advising
strategy
⌊If(ct+1|φt) ∝⌊Uf(ct+1) exp
	
−0.5

kct+1 + φ′
tLct+1Dct+1L′
ct+1φt

.

344
9 Design with normal mixtures
3. Present to the operator projections of the ideal pdf
⌊If(dt+1|φt) =

ct+1∈c∗
⌊If(ct+1|φt)
˚
d
 
i=1
Ndict+1;t+1

θ′
ict+1ψict+1;t, rict+1

.
4. Go to the beginning of Sequential mode.
Remark(s) 9.5
1. The solution is prepared for the factorized implementation, which is
numerically safe.
2. The chosen form ⌊Uf(ct|d(t −1)), that coincides with that of the optimal
advising strategy, allows us to stay within the computationally advanta-
geous class while being able to
•
exclude a priori bad (dangerous) components; Agreement 5.9,
•
respect the “natural” requirement that advices should not be changed
too quickly,
•
employ the IST strategy, Algorithm 7.5, in an adaptive implementation
of the above strategy.
3. The redundant speciﬁcation of probabilities
⌊Uf(c) and lifts kc simpli-
ﬁes interpretation. The pf
⌊Uf(c) cares about the support of the de-
sired recommended pointers. The lifts kc distinguish data-invariant abso-
lute values of individual probabilities. The user-speciﬁed KL kernel, given
by
⌊ULc,
⌊UDc, prescribes data-dependent preferences among the recom-
mended pointers.
4. All data-invariant parts in the conditional KL divergences have to be con-
centrated into the lift, including that occurring in the quadratic form writ-
ten in terms of the state vectors with 1 as its entry. Ideally, the updating
variant described by Algorithm 9.6 should be used.
5. The grouped variant of advising, Proposition 7.13, can be designed and
used. Essentially, the initial conditions k0c, L0c, D0c are constructed as
described above only each nth step. In the intermediate recursions, k0c =
kc;t+1, L0c = Lc;t+1, D0c = Dc;t+1.
6. The last two remarks apply for all advising algorithms discussed in this
chapter.
The online use of the ﬁxed advisory system is extremely simple. It re-
quires just evaluation of values of the normal-mixture predictor. Naturally,
the quality of its advices heavily depends on the quality of the used mixture
model. This makes us write down an adaptive version of the above algorithm.
The increased complexity can be well counteracted by using the IST patch,
Algorithm 7.5. The lifts kc;t and the kernels Lc;tDc;tL′
c;t of quadratic forms
obtained at time t seem to be “natural” parameter ϑ needed: they are used
as initial conditions for the design made at time t + 1. For the IST strategy,
the receding horizon T = 1 is expected to be mostly suﬃcient.

9.2 Design of the advising strategy
345
Let us write down the adaptive algorithm with receding-horizon, certainty-
equivalence strategy complemented by the IST patch.
Algorithm 9.9 (Adaptive academic advising with the γ-bound)
Initial (oﬄine) mode
•
Estimate the normal mixture model of the o-system with the state φt;
Chapter 8.
•
Evaluate the steady-state behaviors of individual components, Section 9.1.1.
•
Exclude dangerous components, Agreement 5.9, or stabilize them using
Algorithm 9.3.
•
Return to the learning phase if all components are dangerous.
•
Take the nondangerous component as the ideal pdf oﬀered to the operator.
Skip Iterative mode if ˚c = 1.
•
Specify the true user’s ideal pdf on the response of the o-system
⌊Uf(do;t|do(t −1)) ≡⌊Uf(do;t|φt−1) =
˚
do
 
i=1
Ndi;t

⌊Uθ′
iψi;t, ⌊Uri

.
•
Specify the data and time invariant part ⌊Uf(ct) of the user’s ideal pf on
the recommended pointers. It is zero on dangerous components.
•
Specify data invariant lifts
⌊Ukct;t−1 and kernels of the user-speciﬁed KL
divergence ⌊ULct;t−1,
⌊UDct;t−1. It completes deﬁnition of the user’s ideal
pf (see 9.37)
⌊Uf(ct|d(t−1))∝⌊Uf(ct) exp

−0.5

kct;t−1+ φ′
t−1Lct;t−1Dct;t−1L′
ct;t−1φt−1

,
•
Select the length of the receding horizon T ≥1.
Sequential (online) mode, running for t=1,2,. . . ,
1. Acquire the data record dt and determine the state vector φt.
2. Update estimates of the model parameters; Section 8.5.
3. Initialize the iterative mode by setting τ = t + T and Lc;τ = I˚
φ, Dc;τ =
0˚
φ,˚
φ, kc;τ = 0. The initialization of L, D, k is skipped for t > 1 if the IST
strategy is used.
Iterative mode
Correct the following quadratic forms using the current point estimates of
the factor parameters
For
τ = t + T, . . . , t + 1
For
c = 1, . . . ,˚c
Create the common initial conditions of recursions over factors
k0c ≡−˚
do ≡average lift,
L0c = I˚
Ψ, D0c = 0˚
Ψ,˚
Ψ ≡average kernel.

346
9 Design with normal mixtures
For
˜c = 1, . . . ,˚c
β˜c ∝⌊Uf(˜c) exp(−0.5k˜c;τ),
L0cD0cL′
0c ≡L0cD0cL′
0c + β˜c ˜L˜c;τ ˜D˜c;τ ˜L′
˜c;τ.
Terms ˜L˜c;τ, ˜D˜c;τ are speciﬁed using the split
L˜c;τ ≡
# ⌊ψ0L˜c;τ 0
⌊ψ1L′
˜c;τ 1
$
,
D˜c;τ = diag
	
diag
	
⌊ψ0D˜c;τ

, ⌊1D˜c;τ

,
⌊1D˜c;τ is scalar.
˜L˜c;τ ≡
⎡
⎣
⌊ψ0L˜c;τ 0 0
0
I˚
d 0
⌊ψ1L′
˜c;τ 0 1
⎤
⎦,
˜D˜c;τ = diag
	
diag
	
⌊ψ0D˜c;τ

, 01,˚
d, ⌊1D˜c;τ

.
end
of the cycle over ˜c
For
i = 1, . . . , ˚
d
LicDicL′
ic = ⌊ψL(i−1)c
⌊ψD(i−1)c
⌊ψL′
(i−1)c
+

θic + ⌊dψL(i−1)c

⌊dD(i−1)c

θic + ⌊dψL(i−1)c
′
+χ

i ≤˚
do
 
θic −⌊Uθi

⌊Ur−1
i

θic −⌊Uθi
′
kic = k(i−1)c + ⌊dD(i−1)cric + χ

i ≤˚
do
 #
ln
 ⌊Uri
ric

+ ric
⌊Uri
$
.
end
of the cycle over i
Lc;τ−1Dc;τ−1L′
c;τ−1 ≡L˚
dcD˚
dcL′
˚
dc + ⌊ULc;τ−1
⌊UDc;τ−1
⌊UL′
c;τ−1
kc;τ−1 ≡k˚
dc + ⌊Ukc;τ−1.
end
of the cycle over c
end
of the cycle over τ
4. Evaluate the pf describing the optimal academic advising strategy
⌊If(ct+1|φt) ∝⌊Uf(ct+1) exp
	
−0.5(kct+1;t + φ′
tLct+1;tDct+1;tL′
ct+1;tφt)

.
5. Present to the operator projections of the ideal pdf
⌊If(dt+1|φt) =

ct+1∈c∗
⌊If(ct+1|φt)
 
i∈i∗
Ndict+1;t+1

θ′
ict+1ψict+1;t, rict+1

.
6. Go to the beginning of Sequential mode.
For completeness, let us write down a version of this algorithm that selects
the most probable recommended pointer. Within the iterative evaluations, the

9.2 Design of the advising strategy
347
maximizer
⌊Icτ+1 of
⌊If(cτ+1|φτ) is selected under simplifying assumption
that φτ = φt. This assumption allows us to preserve computational feasibility.
It brings no additional approximation when using the IST strategy with the
horizon T = 1.
Algorithm 9.10 (Adaptive, most probable, academic advising)
Initial (oﬄine) mode
•
Estimate the normal mixture model of the o-system with the state φt;
Chapter 8.
•
Evaluate the steady-state behaviors of individual components; Section 9.1.1.
•
Exclude dangerous components, Agreement 5.9, or stabilize them using
Algorithm 9.3.
•
Return to the learning phase if all components are dangerous.
•
Take the nondangerous component as the ideal pdf oﬀered to the operator.
Skip Iterative mode if ˚c = 1.
•
Specify the true user’s ideal pdf on the response of the o-system
⌊Uf(do;t|do(t −1)) ≡⌊Uf(do;t|φt−1) =
˚
do
 
i=1
Ndi;t

⌊Uθ′
iψi;t, ⌊Uri

.
•
Select the length of the receding horizon T ≥1.
•
Select randomly the pointer ⌊IcT +1 ∈c∗.
Sequential (online) mode, running for t = 1, 2, . . . ,
1. Acquire the data record dt and determine the state vector φt.
2. Update estimates of model parameters; Section 8.5.
3. Initialize the iterative mode by setting τ = t + T and Lc;τ = I˚
φ, Dc;τ =
0˚
φ,˚
φ, kc;τ = 0. The initialization of L, D, k is skipped for t > 1 if the IST
strategy is used.
Iterative mode
Correct the following quadratic forms using the current point estimates of
the factor parameters.
For
τ = t + T, . . . , t + 1
For
c = 1, . . . ,˚c
Create the common initial conditions of recursions over factors
L0cD0cL′
0c ≡˜L ⌊Icτ+1;τ ˜D ⌊Icτ ;τ ˜L′
⌊Icτ+1;τ,
k0c ≡−˚
do + k ⌊Icτ+1;τ,
where
˜L ⌊Icτ+1;τ, ˜D ⌊Icτ+1;τ are speciﬁed using the split
L ⌊Icτ+1;τ ≡

⌊ψ0L ⌊Icτ+1;τ 0
⌊ψ1L′
⌊Icτ+1;τ 1

,

348
9 Design with normal mixtures
D ⌊Icτ+1;τ = diag
	
diag
	
⌊ψ0D ⌊Icτ+1;τ

, ⌊1D ⌊Icτ+1;τ

,
⌊1D ⌊Icτ+1;τ is scalar.
˜L ⌊Icτ+1;τ ≡
⎡
⎣
⌊ψ0L ⌊Icτ+1;τ 0 0
0
I˚
d 0
⌊ψ1L′
⌊Icτ+1;τ 0 1
⎤
⎦,
˜D ⌊Icτ+1;τ = diag
	
diag
	
⌊ψ0D ⌊Icτ+1;τ

, 01,˚
d, ⌊1D ⌊Icτ+1;τ

.
For
i = 1, . . . , ˚
d
LicDicL′
ic = ⌊ψL(i−1)c
⌊ψD(i−1)c
⌊ψL′
(i−1)c
+

θic + ⌊dψL(i−1)c

⌊dD(i−1)c

θic + ⌊dψL(i−1)c
′
+χ

i ≤˚
do
 
θic −⌊Uθi

⌊Ur−1
i

θic −⌊Uθi
′
,
kic = k(i−1)c + ⌊dD(i−1)cric + χ

i ≤˚
do
 #
ln
 ⌊Uri
ric

+ ric
⌊Uri
$
.
end
of the cycle over i
Lc;τ−1Dc;τ−1L′
c;τ−1 ≡L˚
dcD˚
dcL′
˚
dc + ⌊ULc;τ−1
⌊UDc;τ−1
⌊UL′
c;τ−1
kc;τ−1 ≡k˚
dc + ⌊Ukc;τ−1.
end
of the cycle over c
Select ⌊Icτ ≡Arg min
c∈c∗

kc;τ + φ′
tLc;τDc;τL′
c;τφt

using the simplifying assumption φτ = φt.
end
of the cycle over τ
4. Present to the operator projections of the ideal pdf
⌊If(dt+1|φt) =
˚
d
 
i=1
Ndi ⌊Ict+1;t+1

θ′
i ⌊Ict+1ψi ⌊Ict+1;t+1, ri ⌊Ict+1

.
5. Go to the beginning of Sequential mode.
Remark(s) 9.6
1. In a former formulation tried, the probabilities α, determining component
weights, Agreement 5.4, were taken as academic actions. The correspond-
ing design was much more complex. Experiments indicated, however, rea-
sonable properties of such a strategy. Thus, it might be useful to inspect
this direction in future.
2. It is worth stressing that the selected strategy tries to minimize not only
the Jensen upper bound on the KL divergence as it was needed for the
previous variant, but also its γ-bound.
3. The choice of the user-speciﬁed KL divergence determining
⌊Uf(ct+1|φt)
inﬂuences substantially properties of the designed strategy. Mostly, we rely

9.2 Design of the advising strategy
349
on the discussion presented in Section 7.2.2. Speciﬁcally, grouped versions
of algorithms are implemented; see Proposition 7.13 and Remark 5.
9.2.2 Industrial design
The industrial design has to be used whenever component weights have objec-
tive meaning and cannot be inﬂuenced by the operator. We address it using
ideas of Proposition 7.15 proved in Section 7.2.3. It should be stressed that the
more eﬀective and simpler simultaneous design should be used (see Section
9.2.3) whenever the component weights are under the operator control.
The normal components with explicitly marked recognizable actions
"
f(∆t|uo;t, d(t −1), c) f(uo;t|d(t −1), c) ≡
(9.42)
˚
∆
 
i=1
N∆i;t (θ′
icψic;t, ric) ×
˚
d
 
i= ˚
∆+1
Nuo(i−˚
∆);t (θ′
icψic;t, ric)
%
t∈t∗,c∈c∗
and their weights {αc}c∈c∗are assumed to be known (well-estimated). Here,
we use the convention that the data record is ordered as in previous sections
dt = (∆o;t, ∆p+;t, uo;t).
The following extension (see Section 5.1.5) of the true user’s ideal pdf is
considered ⌊Uf(d(˚t)) ≡
⌊Uf(d(˚t)) ≡
 
t∈t∗
⌊Uf(∆o;t|uo;t, do(t −1)) ⌊If(∆p+;t|uo;t, d(t −1)) ⌊Uf(uo;t|do(t −1))
⌊Uf(∆o;t|uo;t, do(t −1)) ≡
˚
∆o
 
i=1
N∆i;t

⌊Uθ′
iψi;t, ⌊Uri

, ∆io;t = ∆i;t for i ≤˚
∆o,
⌊Uf(uo;t|do(t −1)) ≡
˚
d
 
i= ˚
∆+1
Nuo(i−˚
∆);t

⌊Uθ′
iψi;t, ⌊Uri

.
(9.43)
The upper bound on the KL divergence, serving as the loss whose expectation
is optimized, reads
Z(d(˚t)) ≡

t∈t∗

⌊If(uo;t|d(t −1))
×
#
ln
 ⌊If(uo;t|d(t −1))
⌊Uf(uo;t|d(t −1))

+ ω(uo;t, d(t −1))
$
duo;t
ω(uo;t, d(t −1)) ≡

c∈c∗
f(c|uo;t, d(t −1))ω(c, uo;t, d(t −1))

350
9 Design with normal mixtures
ω(c, uo;t, d(t −1)) ≡ln
f(c|uo;t, d(t −1))
αc

(9.44)
+

f(∆t|uo;t, d(t −1), c) ln
f(∆o;t|∆p+;t, uo;t, d(t −1), c)
⌊Uf(∆o;t|uo;t, do(t −1))

d∆t.
Its optimization calls for the evaluation of the weights
f(c|uo;t, d(t −1)) ≡
αcf(uo;t|d(t −1), c)
2
c∈c∗αcf(uo;t|d(t −1), c).
(9.45)
For the considered normal mixture, they have to be approximated. It seems
to be reasonable to approximate them by αc within the design horizon and to
use the values (9.45) in the ﬁnal step only. The following proposition applies
Proposition 7.15 in conjunction with this approximation.
Proposition 9.13 (Industrial design with the bound (7.22)) Let
the joint pdf
⌊If(∆(˚t), uo(˚t))
≡
 
t∈t∗
2
c∈c∗αcf(∆t|uo;t, d(t −1), c)f(uo;t|d(t −1), c)
2
c∈c∗αcf(uo;t|d(t −1), c)
⌊If(uo;t|d(t −1)),
with components (9.43), be determined by the optional industrial advising
strategy described by pdfs
 ⌊If(uo;t|d(t −1))

t∈t∗.
Let us search for the strategy approximately minimizing the expected value
of the loss Z(d(˚t)) (9.44). It is the upper bound on the KL divergence
D
 ⌊If|| ⌊Uf

to the user’s ideal pdf (9.43). Moreover, let us assume that
f(c|uo;t, d(t −1)) ≈αc, cf. (9.45), for t > 1.
In description of the strategy, we use the deﬁnition (9.30)
K′ ≡
#I˚
d(∂−1)
0
0
0
01,˚
d 1
$
,
Lt =
# ⌊φ0Lt 0
⌊φ1Lt 1
$
, Dt = diag
	
⌊φ0Dt, ⌊1Dt

.
⌊1Dt is scalar. We also use the following split of matrices deﬁning LDL′
decompositions of involved kernels
Lic ≡
#
1
0
⌊∆ψLic ⌊ψLic
$
, Dic ≡diag
	
⌊∆Dic, ⌊ψDic

,
where
⌊∆Dic is scalar and ˚
D(i+1)c = ˚
Dic −1.
Then, with the introduced notation, the specialization of the approximately
optimal strategy described in Proposition 7.15 becomes
⌊If(uo;t|d(t −1)) =
˚
d
 
i= ˚
∆+1
Nuo(i−˚
∆);t

⌊Iθ′
i;t−1ψi;t, ⌊Iri;t−1

.
(9.46)

9.2 Design of the advising strategy
351
The regression coeﬃcients ⌊Iθi;t−1 and variance ⌊Iri;t−1 are generated by the
following algorithm.
Set L˚t = I˚
φ, D˚t = 0˚
φ,˚
φ.
(9.47)
For
t = ˚t, . . . , 1
L ˚
∆= I˚
ψ, D ˚
∆= 0˚
ψ,˚
ψ
For
c = 1, . . . ,˚c
L0c ≡
⎡
⎣
⌊φ0Lt 0 0
0
I˚
d 0
⌊φ1L′
t 0 1
⎤
⎦
D0c ≡diag
	
diag
	
⌊φ0Dt

, 01,˚
d, ⌊1Dt

,
⌊1Dt is scalar.
For
i = 1, . . . , ˚
∆
LicDicL′
ic = ⌊ψL(i−1)c
⌊ψD(i−1)c
⌊ψL′
(i−1)c
+

θic + ⌊∆ψL(i−1)c

⌊∆D(i−1)c

θic + ⌊∆ψL(i−1)c
′
+χ

i ≤˚
∆o
 
θic −⌊Uθi

⌊Ur−1
i

θic −⌊Uθi
′
.
end
of the cycle over i
L ˚
∆D ˚
∆L′
˚
∆= L ˚
∆D ˚
∆L′
˚
∆+ αcL ˚
∆cD ˚
∆cL′
˚
∆c
end
of the cycle over c
For
i = ˚
∆+ 1, . . . , ˚
d
˜Li ˜Di ˜L′
i = Li−1Di−1L′
i−1 +
	
−1, ⌊Uθ′
i
′ ⌊Ur−1
i
	
−1, ⌊Uθ′
i

˜Li ≡
#
1
0
−⌊Iθi;t−1 Li
$
˜Di ≡diag
	
⌊Ir−1
i;t−1, diag[Di]

,
⌊Iri;t−1 is scalar.
end
of the cycle over i
Lt−1 ≡L˚
d, Dt−1 ≡D˚
d.
end
of the cycle over t
The ideal pdf shown to the operator is
⌊If(do;t|d(t −1)) ≡
˚
d
 
i= ˚
∆+1
Nu(i−˚
∆)o;t

⌊Iθ′
ic;t−1ψi;t; ⌊Iric;t−1

×

c∈c∗
f(c|uo;t, d(t −1))
˚
∆o
 
i=1
N∆i;t(θ′
icψi;t; ric) with

352
9 Design with normal mixtures
f(c|uo;t, d(t −1)) ∝αc
˚
d
 
i= ˚
∆+1
Nuo(i−˚
∆);t (θ′
icψi;t, ric) .
(9.48)
Proof. The proof is based on Proposition 9.13. Let us assume that the Bellman
function has the form −ln(γ(d(t))) = 0.5φ′
tLtDtL′
tφt with data independent
kernel LtDtL′
t. It is true for t = ˚t for the claimed terminal conditions.
Specialization of (7.40) should conﬁrm this assumption and provide the
corresponding algorithm.
We assume that f(c|uo;t, d(t −1)) ≈αc so that the ﬁrst term in the deﬁ-
nition (7.40) of ω(c, uo;t, d(t −1)) is zero and
2ωγ(uo;t, d(t −1))
≡

c∈c∗
αc

f(∆t|uo;t, d(t −1), c) × ln
 f(∆o;t|∆p+;t, uo;t, d(t −1), c)
γ(d(t)) ⌊Uf(∆o;t|uo;t, do(t −1))

d∆t
=

c∈c∗
αc
	
k ˚
∆c + ψ′
˚
∆;tL ˚
∆cD ˚
∆cL′
˚
∆cψ ˚
∆;t

≡k ˚
∆+ ψ′
˚
∆;tL ˚
∆D ˚
∆L′
˚
∆ψ ˚
∆;t.
The individual lifts k ˚
∆c and kernels L ˚
∆c, D ˚
∆c in the above sum are evaluated
using Proposition 9.8 that provides the values of the weighted conditional
KL divergence. The respective recursions start from the common initial con-
dition k0c = kγ = 0, L0cD0cL′
0c = KLtDtL′
tK′. Results are summed into a
single shifted quadratic form. The resulting strategy is proportional to the
product ⌊Uf(uo;t|d(t −1)) exp[−0.5ω(uo;t, φt−1)] Thus, the quadratic form is
increased by the quadratic form in the exponent of the normal user’s ideal
pdf on recognizable actions. The integration over uo;t can be performed re-
cursively according to Proposition 9.9. It shows that γ(d(t −1)) preserves the
assumed form. The average lift cancels in normalization and can be ﬁxed at
zero. Consequently, individual lifts need not be evaluated at all. It completes
the full design step. The algorithm (9.47) puts these evaluations together.
This proposition, combined with the receding-horizon certainty-equivalence
strategy, justiﬁes the following algorithm that adds just the learning part to
the algorithm described.
Algorithm 9.11 (Industrial advising: (7.22), f(c|uo;t, d(t −1)) ≈αc)
Initial (oﬄine) mode
•
Estimate the mixture model of the o-system with the state φt, Chapter 8.
•
Specify the true user’s ideal pdf (9.43) on the response of the o-system.
•
Select the length of the receding horizon T ≥1.
Sequential (online) mode, running for t = 1, 2, . . . ,
1. Acquire the data record dt and determine the state vector φt.
2. Update estimates of the model parameters, Section 8.5, if you deal with
the adaptive advisory system.

9.2 Design of the advising strategy
353
3. Initialize the iterative mode by setting τ = t + T and Lτ = I, Dτ = 0.
Omit the initialization of Lτ, Dτ if t > 0 and the IST strategy is used.
Iterative mode
•
Apply the algorithm given in Proposition 9.13 while replacing t by τ
and stopping at τ = t + 1.
4. Present to the operator projections of the ideal pdf (9.48) with pdfs
f(∆o;t|uo;t+1, φt, c), f(uo;t+1|φt, c)
derived from the cth learned mixture component.
5. Go to the beginning of Sequential mode.
Remark(s) 9.7
A grouped version of the industrial design is implemented; see Proposition
7.13 and Remark 5.
Problem 9.1 (Improvements of industrial design) The speciﬁc normal
form of the adopted models could and should be used for constructing im-
proved approximations both of the upper bound on the KL divergence and on
f(c|uo;t, d(t −1)). Preliminary inspections have conﬁrmed that this research
direction is a promising one.
An application of the simultaneous design with ⌊Uf(ct|d(t−1)) manipulated
so that ⌊If(ct|d(t −1)) = αct is worth considering as well.
At the end of this section, we attach a version of industrial design with a
quadratic criterion. It has a tight connection with the multiple-model direc-
tion studied currently in control theory [112]. As such, it is of independent
interest. This makes us to present it. The optimization is made via dynamic
programming written for a quadratic additive loss, Proposition 2.9.
Proposition 9.14 (Quadratic design) Let us consider the data-driven de-
sign, Agreement 2.8, and search for the optimal admissible strategy

d∗(t −1) →u∗
o;t

t∈t∗
acting on an extending experience formed by d(t). Let the system be described
by a known normal mixture. Then, the optimal strategy minimizing expected
value of the quadratic loss

t∈t∗

φ′
t
⌊φL ⌊φD ⌊φL′φt + u′
o;t
⌊uL ⌊uD ⌊uL′uo;t

,
(9.49)
determined by the constant decomposed penalization kernels ⌊φL ⌊φD ⌊φL′ and
⌊uL ⌊uD ⌊uL′, is generated by the following algorithm.

354
9 Design with normal mixtures
Algorithm 9.12 (Linear quadratic advising for mixture models)
Initial mode
•
Construct the matrices Ac, c ∈c∗according to (9.33).
•
Choose penalization kernels ⌊φL ⌊φD ⌊φL′ and ⌊uL ⌊uD ⌊uL′.
•
Set L = I˚
φ, D = 0˚
φ,˚
φ.
Iterative mode
1. Transform D, L to ¯D, ¯L of the same type so that
¯L ¯D¯L′ = LDL′ + ⌊φL ⌊φD ⌊φL′.
(9.50)
2. Compute ¯Ac = ¯LAc, c ∈c∗, while exploiting the special form of the shift-
ing matrix Λ; see (9.33).
3. Transform ¯Ac, c ∈c∗, and ¯D, to ˜L, ˜D so that the following equality holds

c∈c∗
¯A′
c ¯D ¯Ac +
	
⌊uL′, 0
′ ⌊uD
	
⌊uL′, 0

= ˜L ˜D˜L′.
(9.51)
4. Split ˜L, ˜D
˜L ≡
# ⌊u˜L
0
⌊uφ˜L ⌊φ˜L
$
, ˜D = diag
	
⌊u˜D, ⌊φ˜D

,
where
(9.52)
⌊u˜L, ⌊u˜D are of (˚u,˚u)-type.
5. Set L = ⌊φ˜L and D = ⌊φ˜D.
6. Go to the beginning of Iterative mode until convergence is observed.
Sequential (online) mode, running for t = 1, 2, . . . ,
Generate the optimal recognizable actions by the linear feedback
uo;t = −

⌊u˜L′−1 ⌊uφ˜L′φt−1.
(9.53)
Proof. For the considered ﬁnite horizon ˚t and additive loss, the optimal strat-
egy can be constructed valuewise. The optimal recognizable inputs are mini-
mizing arguments in the functional Bellman equation (2.22)
V(d(t −1))
= min
uo;t∈u∗
o;t
E
	
φ′
t
⌊φL ⌊φD ⌊φL′φt + u′
o;t
⌊uL ⌊uD ⌊uL′uo;t + V(d(t))|uo;t, d(t −1)

,
for t = ˚t,˚t −1, . . . , 1, starting with V(d(˚t)) = 0. In the considered case of the
normal mixture with the common state in the phase form, the Bellman func-
tion depends on the state only. It is conjectured to be of the lifted quadratic
form
V(d(t)) = V(φt) = kt + φ′
tLtDtL′
tφt
(9.54)

9.2 Design of the advising strategy
355
with the nonnegative scalar lift kt and the decomposed kernel LtDtL′
t inde-
pendent of data.
For˚t, the conjecture is valid with L˚t = I˚
φ, D˚t = 0˚
φ,˚
φ and k˚t = 0. According
to the inductive assumption for a generic t, the right-hand side of the Bellman
equation is
min
uo;t E
	
φ′
t

⌊φL ⌊φD ⌊φL′ + LtDtL′
t

φt + u′
o;t
⌊uL ⌊uD ⌊uL′uo;t
!!! ψt

+ kt
=

(9.50)
min
uo;t E
	
φ′
t
⌊φ¯L ⌊φ¯D ⌊φ¯L′φt + u′
o;t
⌊uL ⌊uD ⌊uL′uo;t
!!! ψt

+ kt
(9.55)
=

(9.33)
min
uo;t ψ′
t
0
c∈c∗
A′
c
⌊φ¯L ⌊φ¯D ⌊φ¯L′Ac
1
ψt + u′
o;t
⌊uL ⌊uD ⌊uL′uo;t
+
tr

[I ˚
∆, 0]¯L ¯D¯L′[I ˚
∆, 0]′ 
c∈c∗
αcrc

+ kt



kt−1
=

(9.51)
min
uo;t ψ′
t ˜L ˜D˜L′ψt + kt−1
=

(9.52)
φ′
t−1
⌊φ˜L ⌊φ˜D ⌊φ˜L′φt−1 + kt−1
with the minimizing argument u′
o;t = −φ′
t−1
⌊uφ˜L ⌊u˜L−1.
These evaluations prove both the claimed form and provide the algorithm
giving the optimal feedback.
Remark(s) 9.8
1. The algorithm is described directly in the way suitable for a numerically
eﬃcient, factorized solution based on Algorithm dydr 8.3.
2. For simplicity, the regulation problem is considered. An extension to the
combined regulation and tracking is straightforward and standard one.
3. The optimization is made for the known model. As usual inlinear-quadratic
design problems, the normality assumption serves us for learning. In the
design, the knowledge of the second moment (9.33) is only needed.
4. The key message is that the state matrix corresponding to the mixture
is not the weighted mean of state matrices of individual components. The
combination has to be done in the mean square sense as reﬂected in Algo-
rithm 9.12.
5. Knowledge on linear-quadratic control theory can be simply exploited. For
instance, if there is a controller that makes the expected loss — divided
by ˚t — ﬁnite for ˚t →∞, the designed strategy makes this loss ﬁnite, too.
Also, a suﬃcient rank of penalizing matrices and existence of a stabilizing
controller imply that the designed one is stabilizing, etc.
6. The optimization is equivalent to a solution of the discrete-time Riccati
equation [2, 79]. Thus, the presented evaluations can be viewed as its ex-
tension to mixture models.

356
9 Design with normal mixtures
7. The IST strategy, Section 4.2.1, should be used in the adaptive context.
8. Reducing the derived algorithm to the case with empty uo;t, we get the
second noncentral moment assigned to the whole mixture. This evaluation
can serve us for practical test of the stability of the mixture as a whole.
Problem 9.2 (Extension of linear-quadratic optimization art)
It is
obvious that the well developed linear-quadratic optimization art [2] can be
extended to mixture models. It is worth to do it in detail.
9.2.3 Simultaneous academic and industrial design
Whenever applicable, the simultaneous academic and industrial design pro-
vides the best problem formulation and solution. The considered actions of
the academic part of the simultaneous p-system ct ∈c∗≡{1, . . . ,˚c} are to
be generated by a causal strategy d∗(t −1) →c∗. The industrial part gen-
erates the recommended recognizable actions d∗(t −1) →u∗
o;t. The strategy
determines the potential ideal pdfs, among which the best one is searched for,
⌊If(dt, ct|d(t −1)) = f(∆o;t|∆p+;t, uo;t, d(t −1), ct)
(9.56)
× f(∆p+;t|uo;t, d(t −1), ct) ⌊If(ct|uo;t, d(t −1)) ⌊If(uo;t|d(t −1)).
The normal user’s ideal pdf is used
⌊Uf(dt, ct|d(t −1)) = ⌊Uf(∆o;t|uo;t, do(t −1))
× f(∆p+;t|uo;t, d(t −1), ct) ⌊Uf(uo;t|do(t −1)) ⌊Uf(ct|uo;t, d(t −1))
∝
˚
∆o
 
i=1
N∆i;t

⌊Uθ′
iψi;t, ⌊Uri

˚
∆
 
i= ˚
∆o+1
N∆i;t

θ′
ictψict;t, rict

×
˚
d
 
i= ˚
∆+1
Nuo(i−˚
∆);t

⌊Uθ′
iψi;t, ⌊Uri

× ⌊Uf(ct) exp
	
−0.5

⌊Ukct;t−1 + ψ′
t
⌊ULct;t−1
⌊UDct;t−1
⌊UL′
ct;t−1ψt

.
The following elements are involved.
f(∆o;t|∆p+;t, uo;t, d(t −1), ct) ≡/ ˚
∆o
i=1 N∆ict;t

θ′
ictψict;t, rict

is the pdf de-
rived from the ct-th learned component describing the o-innovations;
f(∆p+;t|uo;t, d(t −1), ct) ≡/ ˚
∆
i= ˚
∆o+1 N∆i;t

θ′
ictψict;t, rict

is the pdf derived
from the ct-th learned component describing the surplus innovations of
the p-system;
 ⌊If(ct, uo;t|d(t −1)) ≡⌊If(ct|uo;t, d(t −1)) ⌊If(uo;t|d(t −1))

t∈t∗is the op-
timized simultaneous strategy;
⌊Uf(∆o;t|uo;t, do(t −1)) = / ˚
∆o
i=1 N∆i;t
 ⌊Uθ′
iψi;t, ⌊Uri

is the true user’s ideal
pdf on the o-innovations; see Section 5.1.5;

9.2 Design of the advising strategy
357
⌊Uf(uo;t|do(t −1)) = /˚
d
i= ˚
∆+1 Nuo(i−˚
∆);t
 ⌊Uθ′
iψi;t, ⌊Uri

is the true user’s
ideal pdf on the recognizable actions uo;t; see Section 5.1.5;
⌊Uf(ct|uo;t, d(t −1)) ∝
∝⌊Uf(ct) exp
	
−0.5

⌊Ukct;t−1 + ψ′
t
⌊ULct;t−1
⌊UDct−1;t
⌊UL′
ct;t−1ψt

is the pf representing the optional knob of the p-system that can respect
special requirements like stability of advices. It is determined by the time
invariant pf
⌊Uf(ct) and by the lifted and decomposed quadratic forms
in the exponent. Notice that the quadratic forms in the regression vector
ψt are considered, i.e., the desirable ct can be made dependent on uo;t.
The function
⌊Uω(ct, ψt) ≡
⌊Ukct;t−1 + ψ′
t
⌊ULct;t−1 ⌊UDct;t−1 ⌊UL′
ct;t−1ψt
can be interpreted as a version of the user-speciﬁed KL divergence.
Proposition 9.15 (Simultaneous fully probabilistic design)
Let us
consider the simultaneous academic and industrial design for the o-system
described by the normal mixture with the state φ in the phase form. The data
record dt contains both innovations ∆t = (∆o;t, ∆p+;t) =(innovations in d∗
o,
innovations in d∗
p+) and the unrestricted recognizable actions uo;t. The o-data
do;t consist of (∆o;t, uo;t) = (o-innovations, recognizable actions). The data
record is ordered d = (∆o, ∆p+, uo).
The assumed inﬂuence of advices and the user’s ideal pdf are described
by (9.56). The parameters Θic = [θic, ric] of the mixture model, as well those
determining the true user’s ideal pdf,
⌊UΘi ≡
	
⌊Uθi, ⌊Uri

, i ∈i∗≡

1, . . . , ˚
∆o

∪

˚
∆+ 1, . . . , ˚
d

are known and ﬁxed. The regression coeﬃcients are complemented by zeros so
that, for each index i in the set i∗, the corresponding factors in the user’s
ideal pdf and mixture model have the common regression vectors ψi;t ≡
[di+1;t, ψ′
i+1;t]′ = [d′
(i+1)···˚
d;t, φ′
t−1]′, i < ˚
d, ψ˚
d;t ≡φt−1.
Let us search for the advising strategy
 ⌊If(ct, uo;t|d(t −1))

t∈t∗selecting
both the recommended pointers ct and the recognizable actions uo;t that, at
least approximately, minimize the KL divergence of
⌊If(d(˚t), c(˚t)) =
 
t∈t∗
f(dt, ct|d(t −1)) to the user’s ideal pdf
⌊Uf(d(˚t), c(˚t)) =
 
t∈t∗
⌊Uf(dt, ct|d(t −1)) with its factors given by (9.56).
The deﬁnition of the KL divergence, the chain rule and marginalization imply
that the minimized KL divergence can be interpreted as the expected value of
the loss function,

358
9 Design with normal mixtures

t∈t∗,ct∈c∗

f(∆t|uo;t, d(t −1), ct) ⌊If(ct|uo;t, d(t −1)) ⌊If(uo;t|d(t −1))
(9.57)
× ln
f(∆o;t|∆p+;t, uo;t, d(t −1), ct) ⌊If(ct|uo;t, d(t −1)) ⌊If(uo;t|d(t −1))
⌊Uf(∆o;t|uo;t, do(t −1)) ⌊Uf(ct|uo;t, do(t −1)) ⌊Uf(uo;t|do(t −1))

ddt.
Let us consider the following strategy
⌊If(ct, uo;t|φt−1) ∝⌊Uf(ct) exp [−0.5ωγ(ct, φt−1)] ⌊If(uo;t|φt−1, ct)
ωγ(ct, φt−1) ≡kct;t−1 + φ′
t−1Lct;t−1Dct;t−1L′
ct;t−1φt−1
(9.58)
⌊If(uo;t|φt−1, ct) ≡
˚
d
 
i= ˚
∆+1
Nuo(i−˚
∆);t

⌊Iθ′
ict;t−1ψi;t, ⌊Irict;t−1

.
The lifts kct;t−1 and kernels Lct;t−1Dct;t−1L′
ct;t−1, deﬁning ωγ(ct, φt−1), and
parameters
⌊IΘict;t−1 ≡
 ⌊Iθ′
ict;t−1, ⌊Irict;t−1

, deﬁning pdfs
⌊If(uo;t|φt−1, ct),
are generated recursively. In the description of recursions, the following split
of LDL′ kernels is used
L ≡
#
1
0
⌊dψL ⌊ψL
$
,
D ≡diag
	
⌊dD, ⌊ψD

,
where ⌊dD is scalar.
An average quadratic form φ′
t−1Lγ;t−1Dγ;t−1L′
γ;t−1φt−1 is used in the speciﬁ-
cation of the initial conditions of recursions deﬁning the strategy. Its following
split is used
Lγ;t ≡
# ⌊φ0Lγ;t 0
⌊φ1L′
γ;t 1
$
, Dγ;t = diag
	
diag
	
⌊φ0Dγ;t

, ⌊1Dγ;t

,
⌊1Dγ;t is scalar.
The recursions are described by the following formulas.
Set Lγ;˚t = I˚
φ = ˚φ-unit matrix, Dγ;˚t = 0˚
φ,˚
φ ≡(˚φ, ˚φ)-zero matrix.
For
t = ˚t, . . . , 1
q = 0
For
c = 1, . . . ,˚c
L0c ≡
⎡
⎣
⌊φ0Lγ;t 0 0
0
I˚
d 0
⌊φ1L′
γ;t 0 1
⎤
⎦, D0c = diag
	
diag
	
⌊φ0Dγ;t

, 01,˚
d, ⌊1Dγ;t

k0c ≡−˚
do
For
i = 1, . . . , ˚
∆
LicDicL′
ic = ⌊ψL(i−1)c
⌊ψD(i−1)c
⌊ψL′
(i−1)c
+

θic + ⌊dψL(i−1)c

⌊dD(i−1)c

θic + ⌊dψL(i−1)c
′
+χ

i ≤˚
∆o
 
θic −⌊Uθi

⌊Ur−1
i

θic −⌊Uθi
′
,

9.2 Design of the advising strategy
359
kic ≡k(i−1)c + ⌊dD(i−1)cric + χ

i ≤˚
∆o
 #
ln
 ⌊Uri
ric

+ ric
⌊Uri
$
˚
Dic = ˚
D(i−1)c −1
end
of the cycle over i
L ˚
∆cD ˚
∆cL′
˚
∆c ≡L ˚
∆cD ˚
∆cL′
˚
∆c + ⌊ULc;t−1
⌊UDc;t−1
⌊UL′
c;t−1
k ˚
∆c ≡k ˚
∆c + ⌊Ukc;t−1
end
of the cycle over c
Lγ;t−1 = I˚
φ, Dγ;t−1 = 0˚
φ,˚
φ
For
c = 1, . . . ,˚c
For
i = ˚
∆+ 1, . . . , ˚
d
˜Lic ˜Dic ˜L′
ic = L(i−1)cD(i−1)cL′
(i−1)c +
	
−1, ⌊Uθ′
i
′ ⌊Ur−1
i
	
−1, ⌊Uθ′
i

˜Lic =
#
1
0
−⌊Iθic;t−1 Lic
$
˜Dic = diag
	
⌊Ir−1
ic;t−1, Dic

,
⌊Iric;t−1 is scalar,
kic = k(i−1)c + ln

⌊Uri
⌊Ir−1
ic;t−1

end
of the cycle over i
Lc;t−1 ≡L˚
dc, Dc;t−1 ≡D˚
dc, kc;t−1 ≡k˚
dc
βc ≡⌊Uf(c) exp(−0.5k˚
dc)
q = q + βc
end
of the cycle over c
For
c = 1, . . . ,˚c
βc = βc
q
Lγ;t−1Dγ;t−1L′
γ;t−1 = Lγ;t−1Dγ;t−1L′
γ;t−1 + βcLc;t−1Dc;t−1L′
c;t−1.
end
of the cycle over c
end
of the cycle over t
The updating of the LDL′ (!) decomposition can be done by Algorithm 8.2.
Then, this strategy minimizes the KL divergence for the horizon equal one.
For other horizons, it minimizes the upper bound on the expected loss as it
replaces the correct Bellman function, cf. (9.58),
−ln
" 
ct∈c∗
⌊Uf(ct) exp[−0.5ωγ(ct, φt−1)]
%
by the larger value
0.5φ′
t−1
0 
ct∈c∗
βctLct;t−1Dcc;t−1L′
ct;t−1
1
φt−1.
(9.59)

360
9 Design with normal mixtures
Proof. Let us assume that the Bellman function is −ln(γ(φt)), with
γ(φt) = exp
⎡
⎣−0.5

ct+1∈c∗
βct+1ωγ(ct+1, φt)
⎤
⎦≡exp [−0.5ωγ(φt)]
βct+1 ∝⌊Uf(ct+1) exp[−0.5kct+1;t]
ωγ(ct+1, φt) ≡φ′
tLct+1;tDct+1;tL′
ct+1;tφt, i.e. ωγ(φt) = φ′
tLγ;tDγ;tL′
γ;tφt with
Lγ;tDγ;tL′
γ;t ≡

ct+1∈c∗
βct+1Lct+1;tDct+1;tL′
ct+1;t.
The kernels Lct+1;tDct+1;tL′
ct+1;t and the scalar lifts kct+1;t are conjectured to
be independent of data. This conjecture is correct for t = ˚t with kc˚
t+1;˚t =
0, Lc˚
t+1;˚t = I˚
φ, Dc˚
t+1;˚t = 0˚
φ,˚
φ. We prove that this form is preserved during
the backward induction for t < ˚t if the approximation (9.59) is used. It gives
us also the algorithmic solution of the inspected problem.
Under the inductive assumption, the weighted conditional KL divergence is
2˜ωγ(ct, ψt) ≡2

f(∆t|ψt, ct) ln
#f(∆o;t|∆p+;t, ψt, ct)
γ(φt) ⌊Uf(∆o;t|ψt)
$
d∆t
= k ˚
∆ct + ψ′
tL ˚
∆ctD ˚
∆ctL′
˚
∆ctψt,
where, according to Proposition 9.8, the lifts and the kernels are found recur-
sively for i = 1, . . . , ˚
∆
LicDicL′
ic = ⌊ψL(i−1)c
⌊ψD(i−1)c
⌊ψL′
(i−1)c
+

θic + ⌊∆ψL(i−1)c

⌊∆D(i−1)c

θic + ⌊∆ψL(i−1)c
′
+ χ

i ≤˚
∆o
 
θic −⌊Uθi

⌊Ur−1
i

θic −⌊Uθi
′
kic = k(i−1)c + ⌊∆D(i−1)cric + χ

i ≤˚
∆o
 #
ln
 ⌊Uri
ric

+ ric
⌊Uri
$
.
The initial conditions, implied by the general condition γ(d(˚t)) = 1, are
k0c = −˚
∆o,
L0cD0cL′
0c = KLγ;tDγ;tL′
γ;tK′
K′ ≡
#I˚
d(∂−1)
0
0
0
01,˚
d 1
$
Lic ≡
#
1
0
⌊∆ψLic ⌊ψLic
$
, Dic ≡diag
	
⌊∆Dic, ⌊ψDic

,
where
⌊∆Dic is scalar and ˚
D(i+1)c = ˚
Dic −1.

9.2 Design of the advising strategy
361
The optimal pdf ⌊If(ct, uo;t|d(t −1)) is the minimizer of

ct∈c∗

⌊If(ct, uo;t|d(t −1))
×
#
ωγ(ct, ψt) + ln

⌊If(ct, uo;t|d(t −1))
⌊Uf(ct|uo;t, do(t −1)) ⌊Uf(uo;t|φt−1)
$
duo;t, where
ωγ(ct, ψt) ≡˜ωγ(ct, ψt) + ⌊Uω(ct, ψt).
Thus, ωγ is deﬁned by the kernel L ˚
∆cD ˚
∆cL′
˚
∆c of ˜ωγ increased by
⌊ULc;t−1 ⌊UDc;t−1 ⌊UL′
c;t−1. Also, the lift ⌊Ukc;t−1 is added to k ˚
∆c.
The minimizer is
⌊If(ct, uo;t|φt−1) =
⌊Uf(ct) ⌊Uf(uo;t|φt−1) exp[−0.5ωγ(ct, ψt)]
˜γ(φt−1)
˜γ(φt−1) ≡

ct∈c∗
⌊Uf(ct)

⌊Uf(uo;t|φt−1) exp[−0.5ωγ(ct, ψt)] duo;t.
We modify this expression so that the marginal pf ⌊If(ct|φt−1) become visible.
For it, we use the explicit form of the user’s ideal pdf on the recognizable
actions when expressing the product
⌊Uf(uo;t|φt−1) exp[−0.5ωγ(ct, ψt)]
=
˚
d
 
i= ˚
∆+1

2π ⌊Uri
−0.5
exp

−1
2

k ˚
∆ct + ψ′
tL ˚
∆ctD ˚
∆ctL′
˚
∆ctψt

× exp
⎧
⎨
⎩−1
2
⎛
⎝
˚
d

i= ˚
∆+1
[uo(i−˚
∆);t, ψ′
i;t]

−1, ⌊Uθ′
i
′ 
−1, ⌊Uθ′
i

⌊Uri
[uo(i−˚
∆);t, ψ′
i;t]′
⎞
⎠
⎫
⎬
⎭.
Completion of the squares in individual entries of uo(i−˚
∆);t deﬁnes sequence
of kernels for i = ˚
∆+ 1, . . . , ˚
d, c ∈c∗,
˜Lic ˜Dic ˜L′
ic ≡L(i−1)cD(i−1)cL′
(i−1)c +

−1, ⌊Uθ′
i
′ 
−1, ⌊Uθ′
i

⌊Uri
˜Lic =
#
1
0
−⌊Iθic;t−1 Lic
$
, ˜Dic ≡diag
	
⌊Ir−1
ic;t−1, diag[Dic]

,
⌊Ir−1
ic;t−1 is scalar.
Thus,
⌊If(ct, uo;t|φt−1) =
⌊Uf(ct)
˜γ(φt−1)
× exp

−0.5

kct;t−1 + φ′
t−1Lct;t−1Dct;t−1L′
ct;t−1φt−1

×
˚
d
 
i= ˚
∆+1
Nuo(i−˚
∆);t

⌊Iθ′
ic;t−1ψi;t, ⌊Iric;t−1

.

362
9 Design with normal mixtures
The integration over uoi, performed while normalizing, increases lifts to
kct;t−1 ≡k ˚
∆ct +
˚
d

i= ˚
∆+1
ln

⌊Uri
⌊Iric;t−1

and Lct;t−1 ≡L˚
dct,
Dct;t−1 ≡D˚
dct.
˜γ(φt−1) ≡

ct∈c∗
⌊Uf(ct) exp

−1
2

kct;t−1 + φ′
t−1Lct;t−1Dct;t−1L′
ct;t−1φt−1

= q

ct∈c∗
βct exp

−0.5φ′
t−1Lct;t−1Dct;t−1L′
ct;t−1φt−1

= q

ct∈c∗
βct exp [−0.5ω(ct; φt−1)]
with
βct =
⌊Uf(ct) exp [−0.5kct;t−1]
q
,
q ≡

ct∈c∗
⌊Uf(ct) exp [−0.5kct;t−1] .
The obtained minimum −ln(˜γ(φt−1)) is approximated from above by replac-
ing weighted arithmetic mean by weighted geometric mean. It reproduces
γ(φt−1) = exp

−0.5φ′
t−1Lγ;t−1Dγ;t−1L′
γ;t−1φt−1

with
Lγ;t−1Dγ;t−1L′
γ;t−1 ≡

ct∈c∗
βctLct;t−1Dct;t−1L′
ct;t−1.
The proposition, combined with the certainty-equivalence strategy, justi-
ﬁes the algorithm designing the ﬁxed simultaneous advisory system.
Algorithm 9.13 (Fixed simultaneous advising with the γ-bound)
Initial (oﬄine) mode
•
Estimate normal mixture model of the o-system with the state φt in the
phase form; Chapter 8.
•
Specify the true user’s ideal pdf on the response of the o-system
⌊Uf(do;t|do(t −1)) ≡⌊Uf(do;t|φt−1)
=
˚
∆o
 
i=1
N∆i;t

⌊Uθ′
iψi;t, ⌊Uri

˚
d
 
i= ˚
∆+1
Nuo(i−˚
∆);t

⌊Uθ′
iψi;t, ⌊Uri

.
•
Specify the data and time invariant part ⌊Uf(ct) of the user’s ideal pf on
the recommended pointers. It is zero on dangerous components.
•
Specify data and time invariant lifts
⌊Ukct and data and time invariant
kernels of the user-speciﬁed KL divergence ⌊ULct,
⌊UDct. It completes the
deﬁnition of the user’s ideal pf f(ct|d(t −1)); see (9.56). Notice that the
quadratic form in the regression vector (not only in the state φ) is to be
considered.

9.2 Design of the advising strategy
363
•
Select the length of the design horizon ˚t ≥1.
•
Initialize the iterative mode by setting Lγ;˚t = I˚
φ, Dγ;˚t = 0˚
φ,˚
φ.
Iterative (oﬄine) mode
1. Correct the conditional KL divergences, for t = ˚t, . . . , 1, as given in (9.58).
2. Denote the ﬁnal characteristics of the approximate optimal steady-state
strategy, cf. Chapter 3, i = ˚
∆+ 1, . . . , ˚
d, c ∈c∗,
kc ≡kc;1, Lc ≡Lc;1, Dc ≡Dc;1, θic ≡⌊Iθic;1, ric ≡⌊Iric;1.
Sequential (online) mode, running for t = 1, 2, . . . ,
1. Acquire the data record dt and determine the state vector φt.
2. Evaluate the ideal pf on pointers
⌊If(ct+1|φt) ∝⌊Uf(ct+1) exp
	
−0.5

kct+1 + φ′
t−1Lct+1Dct+1L′
ct+1φt−1

.
3. Present to the operator selected projections of the ideal pdf
⌊If(dt+1|φt) =

ct+1∈c∗
⌊If(ct+1|φt)
˚
d
 
i=1
Ndict+1;t+1(θ′
ict+1ψict+1;t, rict+1).
4. Go to the beginning of Sequential mode.
Proposition 9.15, combined with the receding-horizon, certainty-equivalence
strategy, justiﬁes the following adaptive design algorithm.
Algorithm 9.14 (Adaptive simultaneous advising with γ-bound)
Initial (oﬄine) mode
•
Estimate normal mixture model of the o-system with the state φt in the
phase form; Chapter 8.
•
Specify the true user’s ideal pdf on the response of the o-system
⌊Uf(do;t|do(t −1)) ≡⌊Uf(do;t|φt−1)
=
˚
∆o
 
i=1
N∆i;t

⌊Uθ′
iψi;t, ⌊Uri

˚
d
 
i= ˚
∆+1
Nui−˚
∆;t

⌊Uθ′
iψi;t, ⌊Uri

.
•
Specify data invariant part ⌊Uf(ct) of the user ideal on the recommended
pointers.
•
Specify data invariant lifts ⌊Ukc;t and the kernels ⌊ULc;t,
⌊UDc;t that deﬁne
the user’s ideal pf on recommended pointers
f(ct|uo;t, d(t −1))
∝⌊Uf(ct) exp
	
−0.5

⌊Ukct;t−1 + ψ′
t
⌊ULct;t−1
⌊UDct;t−1
⌊UL′
ct;t−1ψt

.

364
9 Design with normal mixtures
•
Select the length of the receding horizon T ≥1.
Sequential (online) mode, running for t = 1, 2, . . . ,
1. Acquire the data record dt and determine the state vector φt.
2. Update estimates of the model parameters; Section 8.5.
3. Initialize the iterative mode by setting τ = t + T, Lγ;τ = I˚
φ, Dγ;τ = 0˚
φ,˚
φ.
Lγ;τ ≡
# ⌊φ0Lγ;τ 0
⌊φ1L′
γ;τ 1
$
, Dγ;τ ≡
	
diag
	
⌊φ0Dγ;τ

, ⌊1Dγ;τ

,
⌊1Dγ;τ is scalar.
Omit the initialization of Lγ;τ, Dγ;τ if t > 1 and the IST strategy is
adopted.
Iterative mode
Correct the lifted quadratic forms deﬁning the KL divergences using the
current point estimates of parameters.
Set Lγ;t+T = I˚
φ = ˚φ-unit matrix, Dγ;t+T = 0˚
φ,˚
φ ≡(˚φ, ˚φ)-zero.
For
τ = t + T, . . . , t + 1
q = 0
For
c = 1, . . . ,˚c
L0c ≡
⎡
⎣
⌊φ0Lγ;τ 0 0
0
I˚
d 0
⌊φ1L′
γ;τ 0 1
⎤
⎦
D0c = diag
	
diag
	
⌊φ0Dγ;τ

, 01,˚
d, ⌊1Dγ;τ

,
k0c ≡−˚
do
For
i = 1, . . . , ˚
∆
LicDicL′
ic = ⌊ψL(i−1)c
⌊ψD(i−1)c
⌊ψL′
(i−1)c
+

θic + ⌊dψL(i−1)c

⌊dD(i−1)c

θic + ⌊dψL(i−1)c
′
+χ

i ≤˚
∆o
 
θic −⌊Uθi

⌊Ur−1
i

θic −⌊Uθi
′
,
kic ≡k(i−1)c + ⌊dD(i−1)cric + χ

i ≤˚
∆o
 #
ln
 ⌊Uri
ric

+ ric
⌊Uri
$
˚
Dic = ˚
D(i−1)c −1
end
of the cycle over i
L ˚
∆cD ˚
∆cL′
˚
∆c ≡L ˚
∆cD ˚
∆cL′
˚
∆c + ⌊ULc;t−1
⌊UDc;τ−1
⌊UL′
c;τ−1
k ˚
∆c ≡k ˚
∆c + ⌊Ukc;τ−1
end
of the cycle over c
Lγ;τ−1 = I˚
φ, Dγ;τ−1 = 0˚
φ,˚
φ
For
c = 1, . . . ,˚c

9.2 Design of the advising strategy
365
For
i = ˚
∆+ 1, . . . , ˚
d
˜Lic ˜Dic ˜L′
ic = L(i−1)cD(i−1)cL′
(i−1)c +
	
−1, ⌊Uθ′
i
′ ⌊Ur−1
i
	
−1, ⌊Uθ′
i

˜Lic =
#
1
0
−⌊Iθic;τ−1 Lic
$
˜Dic = diag
	
⌊Ir−1
ic;τ−1, diag[Dic]

,
⌊Iric;τ−1 is scalar,
kic = k(i−1)c + ln

⌊Uri
⌊Ir−1
ic;τ−1

end
of the cycle over i
Lc;τ−1 ≡L˚
dc, Dc;τ−1 ≡D˚
dc, kc;τ−1 ≡k˚
dc
βc ≡⌊Uf(c) exp(−0.5k˚
dc)
q = q + βc
end
of the cycle over c
For
c = 1, . . . ,˚c
βc = βc
q
Lγ;τ−1Dγ;τ−1L′
γ;τ−1 = Lγ;τ−1Dγ;τ−1L′
γ;τ−1 + βcLc;τ−1Dc;τ−1L′
c;τ−1.
end
of the cycle over c
end
of the cycle over τ
The updating of the LDL′ (!) decomposition can be done by Algorithm
8.2.
4. Evaluate the ideal pf on pointers
⌊If(ct+1|φt) ∝⌊Uf(ct+1) exp[−0.5(kct+1;t + φ′
tLct+1;tDct+1;tL′
ct+1;tφt)].
5. Present to the operator projections of the ideal pdf
⌊If(dt+1|φt) =

ct+1∈c∗
⌊If(ct+1|φt)
˚
∆
 
i=1
Ndict+1;t+1(θ′
ict+1ψict+1;t, rict+1)
×
˚
d
 
i= ˚
∆+1
Nuo(i−˚
∆)ct+1;t+1

⌊Iθ′
ict+1;tψict+1;t, ⌊Irict+1;t

.
6. Go to the beginning of Sequential mode.
Remark(s) 9.9
1. It is worth stressing that the user’s ideal pf on ct is conditioned on ψt.
Thus, it can modify dependence of ct and uo;t. In algorithmic terms, the
constructed coeﬃcients ⌊Iθic;t are inﬂuenced by the optional ⌊ULc, which
is the (˚
ψ, ˚
ψ)-dimensional matrix.

366
9 Design with normal mixtures
2. Other design variants, like selection of the most probable advices or the
grouped version, can be constructed directly according to Chapter 7, using
the above evaluations.
9.3 Interaction with an operator
Here, we elaborate the design of strategies generating presentation and signal-
ing actions, using the model presented in Section 7.1.3, in the case of normal
mixtures and normal user’s ideal pdfs.
9.3.1 Assigning priorities
We present a normal version of the choice of presentation priorities, i.e., the
choice of the quantities that should be shown to the operator most urgently. It
is based on Proposition 7.19, on the restriction to ˚zt = 1 and on the simplifying
assumption that the probabilities of pointers c ∈c∗to components used in
the design are close to the estimated weights αc
f(c|dzt;t, d(t −1)) ≈αc.
(9.60)
We also assume that the optimized component weights are approximated by
data and time invariant values
⌊If(c|d(t −1)) ≈⌊Iαc.
(9.61)
Proposition 9.16 (Presentation design; the bound (7.47), ˚zt = 1)
Let us consider that the academic, industrial or simultaneous design has pro-
vided the optimal advising mixture
⌊If(dt|d(t −1)) =

ct∈c∗
⌊If(dt|d(t −1), ct) ⌊If(ct|d(t −1)).
Let the signaling strategy make the operator fully alert, i.e., signaling actions
s(˚t) ≡1. Let us assume that ˚zt = 1 and (9.60), (9.61) hold in addition to the
assumptions of Proposition 7.19. Let us specify the user data invariant ideal
pf ⌊Uf(zt) on the set of possible presentation actions z∗≡{1, . . . , ˚
do}.
Let us deﬁne a presentation strategy that assigns the higher priority to the
entries of dzt;t the higher are the values of the following pf
f(zt|φt−1) ∝⌊Uf(zt) exp

−0.5

kzt + φ′
t−1Lzt;tDzt;tL′
zt;tφ′
t−1

.
(9.62)
The involved lifts and kernels are generated by the following algorithm.

9.3 Interaction with an operator
367
Set L˚t = I˚
φ, D˚t = 0˚
φ,˚
φ.
(9.63)
For
t = ˚t, . . . , 1
q = 0
For
zt = 1, . . . , ˚
do
Permute entry dzt;t at the tail position in the used ideal pdf
⌊Uf(dt|d(t −1))
→

Proposition 9.1
 
i∈i∗
Ndi;t

⌊Uθ′
iztψi;t, ⌊Urizt

.
Reﬂect this permutation into kernel of the quadratic form Lt, Dt
Lt, Dt
→

Proposition 8.4
Lzt;t, Dzt;t
Set Lzt = I˚
φ+1, Dzt = 0˚
φ+1,˚
φ+1, kzt = 0
For
c = 1, . . . ,˚c
Permute entry dzt;t to the tail position in estimated and ideal pdfs
⌊If(dt|d(t −1), c)
→

Proposition 9.1
 
i∈i∗
Ndi;t

⌊Iθ′
icztψi;t, ⌊Iriczt

,
f(dt|d(t −1), c)
→

Proposition 9.1
 
i∈i∗
Ndi;t

θ′
icztψi;t, riczt

.
Assign k0czt ≡0, L0czt ≡
⎡
⎣
⌊φ0Lzt;t 0 0
0
I˚
d 0
⌊φ1L′
zt;t 0 1
⎤
⎦,
D0czt ≡diag
	
diag
	
⌊φ0Dzt;t

, 01,˚
d, ⌊1Dzt;t

, scalar ⌊1Dzt;t.
For
i = 1, . . . , ˚
d −1
LicztDicztL′
iczt = ⌊ψL(i−1)czt
⌊ψD(i−1)czt
⌊ψL′
(i−1)czt
+

θiczt + ⌊dψL(i−1)czt

⌊dD(i−1)czt

θiczt + ⌊dψL(i−1)czt
′
kiczt = k(i−1)czt + ⌊dD(i−1)cztriczt, where
L(i−1)czt =
#
1
0
⌊dψL(i−1)czt
⌊ψL(i−1)czt
$
D(i−1)czt = diag
	
⌊dD(i−1)czt, diag
	
⌊ψD(i−1)czt

⌊dD(i−1)czt is scalar.
end
of the cycle over i
LztDztL′
zt = LztDztL′
zt + αcL(˚
d−1)cztD(˚
d−1)cztL′
(˚
d−1)czt,
kzt = kzt + αck(˚
d−1)czt.
end
of the cycle over c
lzt = ⌊dψLzt, δzt = ⌊dDzt, Lzt = ⌊ψLzt, Dzt = ⌊ψDzt.

368
9 Design with normal mixtures
For
c = 1, . . . ,˚c
LztDztL′
zt = LztDztL′
zt
+ ⌊Iαc

⌊Iθ˚
dczt + lzt

δzt

⌊Iθ˚
dczt + lzt
′
+

⌊Iθ˚
dczt −⌊Uθ˚
dzt

⌊Ur−1
˚
dzt

⌊Iθ˚
dczt −⌊Uθ˚
dzt
′
,
kzt = kzt + ⌊Iαc
"
⌊dDczt
⌊Ir˚
dczt + ln
0 ⌊Ur˚
dzt
⌊Ir˚
dczt
1
+
⌊Ir˚
dczt
⌊Ur˚
dzt
%
.
end
of the cycle over c
βzt = ⌊Uf(zt) exp(−0.5kzt), q = q + βzt
end
of the cycle over zt
Lt−1 = I˚
φ, Dt−1 = 0˚
φ,˚
φ
For
zt = 1, . . . , ˚
do
βzt = βzt
q
Lt−1Dt−1L′
t−1 = Lt−1Dt−1L′
t−1 + βztLztDztL′
zt.
end
of the cycle over zt
end
of the cycle over t
Then, this presentation strategy minimizes the upper bound on the KL diver-
gence, implied by the inequality described in Proposition 7.7 for horizon equal
1 and the γ-bound (see Proposition 7.8) on it when ˚t > 1.
Proof. Let us assume that
−ln(γ(d(t)) = 0.5
˚
do

z=1
βzφ′
tLz;tDz;tL′
z;tφt = 0.5φ′
tLtDtL′
tφt.
It is true for t = ˚t with L˚t = I˚
φ, D˚t = 0˚
φ,˚
φ. As usual, the backward in-
duction serves us for verifying this assumption and constructing the resulting
algorithms.
For a generic t, the inductive assumption and the assumption (9.60) imply
that the function, cf. (7.50),
ω(c, dzt;t, d(t −1)) =

f(d¯zt;t|dzt;t, d(t −1), c)
× ln

f(d¯zt;t|dzt;t, d(t −1), c)
γ(d(t)) ⌊Uf(d¯zt;t|dzt;t, d(t −1))

dd¯zt;t
has to be evaluated. Note that the ﬁrst term in its deﬁnition is zero due to
the assumption (9.60). Proposition 9.8 describes evaluation of the weighted

9.3 Interaction with an operator
369
conditional KL divergence. In order to make it applicable, we permute the
considered entry dzt;t on the last position in dt. It is achieved by a sequential
use of Proposition 9.1. At the same time, the corresponding permutations
of the kernel determining γ(d(t)) have to be applied; see Proposition 8.4.
These permutation have to be also made both for the normal components
⌊If(dt|d(t −1), c) resulting from a previous design and for the user’s ideal pdf
⌊Uf(dt|d(t −1)).
After all these permutations, the application of Proposition 9.8 gives re-
cursions, applied for the dimension ˚
d −1 for computing ω(c, dzt;t, d(t −1)) =
kc,zt + [dzt;t, φ′
t−1]Lczt;t−1Dczt;t−1L′
czt;t−1[dzt;t, φ′
t−1]′.
The assumption (9.60) also implies that the second term in the deﬁnition
of ω(zt, d(t −1)) (7.50) becomes
⌊IE
"
c∈c∗
αc

kc,zt + [dzt;t, φ′
t−1]Lczt;t−1Dczt;t−1L′
czt;t−1[dzt;t, φ′
t−1]′
!!!!! zt, φt−1, ct
%
≡kct,zt;t−1 + φ′
t−1Lctzt;t−1Dctzt;t−1L′
ctzt;t−1φt−1,
where ⌊IE{·} stresses that the expectation is taken with respect to the optimal
mixture ⌊If(dzt;t|d(t −1), ct) obtained in the previous design of the advisory
system.
The result is obtained in two steps. First, the computationally demanding
mixing of factorized lifts kczt and kernels Lczt;t−1Dczt;t−1L′
czt;t−1 is made.
Then, the integration over dzt;t is made according to Proposition 9.5. In the
same cycle over c ∈c∗, the conditional KL divergence is evaluated

⌊If(dzt;t|d(t −1), ct) ln
 ⌊If(dzt;t|dp+;t, d(t −1), ct)
⌊Uf(dzt;t|d(t −1), ct)

ddzt;t
= ⌊Ikctzt;t−1 + φ′
t−1
⌊ILctzt;t−1
⌊IDctzt;t−1
⌊IL′
ctzt;t−1φt−1
using Proposition 9.7. Adopting the assumption (9.61), we mix intermediate
results, see (7.50), and get
ωγ(zt, d(t −1)) =

ct∈c∗
⌊Iαct
	
⌊Ikctzt;t−1 + kctzt;t−1
+ φ′
t−1

Lctzt;t−1Dctzt;t−1L′
ctzt;t−1 + ⌊ILctzt;t−1
⌊IDctzt;t−1
⌊IL′
ctzt;t−1

φt−1

≡⌊Ikzt;t−1 + φ′
t−1
⌊ILzt;t−1
⌊IDzt;t−1
⌊IL′
zt;t−1φt−1.
It deﬁnes the pf on the presentation priorities. Its normalizing factor used
in the next optimization steps is approximated by replacing the weighted
arithmetic mean by its smaller geometric counterpart. It guarantees that an
upper bound is minimized and the assumed form of γ is reproduced with
ω(d(t −1)) = φ′
t−1
 
zt∈z∗
βzt
⌊ILzt;t−1
⌊IDzt;t−1
⌊IL′
zt;t−1

φt−1
with βzt ∝⌊Uf(zt) exp

−0.5 ⌊Ikzt;t−1

.

370
9 Design with normal mixtures
Algorithm 9.15 (Presentation with the bound (7.47) and˚zt = 1)
Initial (oﬄine) mode
•
Estimate the normal mixture model of the o-system with the state φt in
the phase form; Chapter 8.
•
Specify the user’s ideal pdf on dt, ct in the form
⌊Uf(dt, ct|d(t −1)) = ⌊Uf(∆o;t|uo;t, do(t −1))
× f(∆p+;t|uo;t, d(t −1), ct) ⌊Uf(ct|uo;t, d(t −1)) ⌊Uf(uo;t|do(t −1))
∝
˚
∆o
 
i=1
N∆i;t

⌊Uθ′
iψi;t, ⌊Uri

˚
∆
 
i= ˚
∆o+1
N∆i;t (θ′
iψi;t, ri)
×
˚
d
 
i= ˚
∆+1
Nuo(i−˚
∆);t

⌊Uθ′
iψi;t, ⌊Uri

× ⌊Uf(ct) exp
	
−0.5

⌊Ukct + ψ′
t
⌊ULct
⌊UDct
⌊UL′
ctψt

.
•
Select the user’s ideal pf
⌊Uf(zt|d(t −1)) on the scalar priority actions
zt ∈z∗≡{1, . . . , ˚
do}.
•
Select the number ˚ˆz of quantities to be presented to the operator. Typically,
˚ˆz < 10.
•
Select the length of the receding horizon T ≥1.
Sequential (online) mode, running for t = 1, 2, . . .,
1. Acquire the data record dt and determine the state vector φt.
2. Update estimates of the model parameters, Section 8.5, if you deal with
the adaptive advisory system.
3. Design the academic, industrial or simultaneous strategy generating the
ideal pdf
⌊If(dt|φt−1) =

ct∈c∗
⌊If(ct|φt−1) ⌊If(dt|φt−1, ct) =

ct∈c∗
˚
∆
 
i=1
Ndi;t(θ′
icψi;t, ric)
˚
d
 
i= ˚
∆+1
Nuo(i−˚
∆);t

⌊Iθ′
ic;t−1ψi;t, ⌊Iric;t−1

⌊If(ct|φt−1),
⌊If(ct+1|φt) ∝⌊Uf(ct+1) exp
	
−0.5

kct+1 + φ′
t−1Lct+1Dct+1L′
ct+1φt−1

.
4. Initialize the iterative mode by setting τ = t+T and Lτ = I˚
φ, Dτ = 0˚
φ,˚
φ.
The initialization of Lτ, Dτ is skipped if t > 1 and the IST strategy is
used.

9.3 Interaction with an operator
371
5. Apply the iterative part of the algorithm described in Proposition 9.16 on
the range [t + 1, t + T]. It gives the pf f(zt+1|d(t)).
6. Order the values ⌊If(zt+1|φt) ∝⌊Uf(zt+1|φt) exp[−ωγ(zt+1, φt)].
7. Present projections of the ideal pdf ⌊If(dˆzt+1;t+1|φt) to the operator. The
entries of ˚ˆz-vector ˆzt+1 are indexes zt ∈{1, . . . , ˚
do} chosen so that they
have the highest values of ⌊If(zt+1|φt).
8. Go to the beginning of Sequential mode.
Problem 9.3 (Improvements of presentation strategies) The presented
solution is far from being satisfactory. In spite of signiﬁcant approximations
made, the result is cumbersome and highly computationally demanding. Prob-
ably, a direct use of these approximations before estimating the KL divergence
could simplify the solution.
Alternatively, the academic, industrial or simultaneous designs with do;t =
dz;t with several diﬀerent zth in {1, . . . , ˚
do} could be performed and those
options resulting to the smallest KL divergences presented. The logic behind
this is obvious: the operator can optimize only those quantities of which he is
aware. This justiﬁes the reduction of his observable data space to the presented
data space.
Of course, other directions have to be thought of, too.
9.3.2 Stimulating the operator
The signaling strategy makes the operator alert. It asks him to follow the
advised actions, when the ideal pdf, resulting from the academic, industrial
or simultaneous design, gives a signiﬁcantly smaller KL divergence to the
user’s ideal pdf than the KL divergence of the estimated model to this user’s
ideal pdf.
The model relating the signaling action st to the response of the optimized
guided o-system is
⌊If(dt, st|d(t −1)) ≡⌊If(dt|st, d(t −1)) ⌊If(st|d(t −1)), st ∈s∗≡{0, 1}
⌊If(dt|st = 0, d(t −1)) ≡f(dt|d(t −1)) ≡

c∈c∗
αc
˚
d
 
i=1
Ndi;t (θ′
icψi;t, ric)



learned mixture
⌊If(dt|st = 1, d(t −1)) ≡⌊If(dt|d(t −1))
(9.64)
≡

ct∈c∗
⌊If(ct|φt−1)
˚
d
 
i=1
Ndi;t

⌊Iθ′
icψi;t, ⌊Iric




designed mixture
⌊If(ct|φt−1) ∝⌊Uf(ct) exp

−0.5

kct;t−1 + φ′
t−1Lct;t−1Dct;t−1L′
ct;t−1φt−1

.
Note that ⌊Iθic = θic,
⌊Iric = ric for i ≤˚
∆as the ideal pdfs use the estimated
factors predicting innovations without any change.

372
9 Design with normal mixtures
The model (9.64) is a special version of the model (9.35) used in the
academic design. Thus, the design of the signaling strategy reduces to it. It is
reasonable to assume that periods of operator activity or nonactivity have to
be relatively long. Thus, the grouped version of the design (Proposition 7.13)
is to be used.
Proposition 9.17 (Grouped signaling design with the γ-bound) Let
us consider that the academic, industrial or simultaneous design of the ad-
visory system has provided the ideal pdf
⌊If(dt|φt−1) that is built into the
used model (9.64). Then, the following signaling strategy minimizes the γ-
type bound on the KL divergence under the grouping constraint f(sτ|d(tn)) =
f(stn+1|d(tn)) for τ ∈{tn + 1, . . . , t(n + 1)}.
f(snt+1|φnt) ∝⌊Uf(snt+1|φnt)
× exp
	
−0.5

ksnt+1;nt+1 + φ′
ntLsnt+1;nt+1Dsnt+1;nt+1L′
snt+1;nt+1φnt

.
It is deﬁned for snt+1 ∈{0, 1} recursively starting with the average kernel
Lγ;˚t = I˚
φ, Dγ;˚t = 0˚
φ,˚
φ.
For
t = ˚t, . . . ,˚t −i × n + 1, . . . , 1
q = 0
For
s = 0, . . . , 1
Ls;t−n = I˚
φ, Ds;t−n = 0˚
φ,˚
φ, ks = 0
For
c = 1, . . . ,˚c
L0sc ≡Lγ;t, D0sc ≡Dγ;t, k0sc = 0.
For
˜n = 1, . . . , n
L0˜nsc =
⎡
⎢⎣
⌊φ0L˚
d(˜n−1)sc 0 0
0
I˚
d 0
⌊φ1L′
˚
d(˜n−1)sc 0 1
⎤
⎥⎦
D00sc = diag
	
diag
	
⌊φ0D˚
d(˜n−1)sc

, 01,˚
d, ⌊1D˚
d(˜n−1)sc

.
k0˜nsc = k˚
d(˜n−1)sc.
It uses the split
L0(˜n−1)sc ≡
 ⌊φ0L˚
d(˜n−1)sc 0
⌊φ1L′
˚
d(˜n−1)sc 1

D0(˜n−1)sc ≡diag
	
diag
	
⌊φ0D˚
d(˜n−1)sc

, ⌊1D˚
d(˜n−1)sc

⌊1D˚
d(˜n−1)sc is scalar.
For
i = 1, . . . , ˚
d
L(i−1)˜nsc ≡
#
1
0
⌊∆ψL(i−1)˜nsc ⌊ψL(i−1)˜nsc
$
D(i−1)˜nsc ≡diag
	
⌊∆D(i−1)˜nsc, diag
	
⌊ψD(i−1)˜nsc


9.3 Interaction with an operator
373
⌊∆D(i−1)˜nsc is scalar.
Li˜nscDi˜nscL′
i˜nsc = ⌊ψL(i−1)˜nsc
⌊ψD(i−1)˜nsc
⌊ψL′
(i−1)˜nsc
+χ

i ≤˚
∆o

×
#
θic + ⌊∆ψL(i−1)˜nsc

⌊∆D(i−1)˜nsc

θic + ⌊∆ψL(i−1)˜nsc
′
+

θic −⌊Uθic

⌊Ur−1
i

θic −⌊Uθic
′$
+ χ

˚
∆o < i ≤˚
∆

×

θisc + ⌊∆ψL(i−1)˜nsc

⌊∆D(i−1)sc

θisc + ⌊∆ψL(i−1)˜nsc
′
+χ

˚
∆< i

×
#
θisc + ⌊∆ψL(i−1)˜nsc

⌊∆D(i−1)sc

θisc + ⌊∆ψL(i−1)˜nsc
′
+

θisc −⌊Uθic

⌊Ur−1
i

θisc −⌊Uθic
′$
ki˜nsc = ki˜nsc + χ

i ≤˚
∆o

×

k(i−1)˜nsc + ⌊∆D(i−1)˜nscric ln
 ⌊Uri
ric

+ ric
⌊Uri

+χ

˚
∆o < i ≤˚
∆

⌊∆D(i−1)˜nscrisc
+χ

˚
∆< i
 
⌊∆D(i−1)˜nscrisc + ln
 ⌊Uri
risc

+ risc
⌊Uri

end
of the cycle over i
end
of the cycle over ˜n
end
of the cycle over c
For
c = 1, . . . ,˚c
Ls;t−nDs;t−nL′
s;t−n = Ls;t−nDs;t−nL′
s;t−n
+χ(s = 0)
αc
n L˚
dnscD˚
dnscL′
˚
dnsc

+χ(s = 1)

⌊Uf(c)
 1
nL˚
dnscD˚
dnscL′
˚
dnsc + ⌊ILc
⌊IDc
⌊IL′
c

ks;t−n = ks;t−n + χ(s = 0)αc
n k˚
dnsc
+χ(s = 1)

⌊Uf(c)
 1
nk˚
dn1c + ⌊Ikc

end
of the cycle over c
βs ≡⌊Uf(s) exp (−0.5ks;t−n) , q = q + βs
end
of the cycle over s

374
9 Design with normal mixtures
Lγ;t−nDγ;t−nL′
γ;t−n ≡β0
q L0;t−nD0;t−nL′
0;t−n + β1
q L1;t−nD1;t−nL′
1;t−n.
end
of the cycle over t
Proof. Let us assume that −2 ln(γ(d(n(t + 1))))
=

sn(t+1)∈s∗
βsn(t+1);tφ′
n(t+1)Lsn(t+1);n(t+1)Dsn(t+1);n(t+1)L′
sn(t+1);n(t+1)φn(t+1)
≡φ′
n(t+1)Lγ;n(t+1)Dγ;n(t+1)L′
γ;n(t+1)φn(t+1),
βsn(t+1);n(t+1) ∝⌊Uf(sn(t+1)) exp[−0.5ksn(t+1);n(t+1)].
The lifts kst;t as well as the kernels are assumed to be independent data.
It is true for n(t + 1) = ˚t with ks˚
t;˚t = 0, Lγ;˚t = I˚
φ, Dγ;˚t = 0˚
φ,˚
φ. We use
the backward induction to verify this assumption and to derive the design
algorithm.
Let us adopt the inductive assumption, approximate the KL divergence
from above using Jensen inequality (2.14) and evaluate, cf. Proposition 7.13,
ωγ(snt+1 = s, c, φnt) ≡E
⎡
⎣1
n
n(t+1)

τ=nt+1

f(dτ|d(τ −1), snt+1, c)
× ln
f(do;τ|dp+;τ, φτ−1, snt+1, c)
γ(φn(t+1)) ⌊Uf(do;τ|φτ−1)

ddτ|φnt
$
=

Proposition 9.7
kn˚
dsc + φ′
ntLn˚
dscDn˚
dscL′
n˚
dscφ′
nt
With kernels and lifts found recursively starting from
L0sc ≡Lγ;nt, D0sc ≡Dγ;nt, k0sc = 0.
For
˜n = 1, . . . , n
L0˜nsc =
⎡
⎢⎣
⌊φ0L˚
d(˜n−1)sc 0 0
0
I˚
d 0
⌊φ1L′
˚
d(˜n−1)sc 0 1
⎤
⎥⎦
D00sc = diag
	
diag
	
⌊φ0D˚
d(˜n−1)sc

, 01,˚
d, ⌊1D˚
d(˜n−1)sc

k0˜nsc = k˚
d(˜n−1)sc
For
i = 1, . . . , ˚
d
Li˜nscDi˜nscL′
i˜nsc = ⌊ψL(i−1)˜nsc
⌊ψD(i−1)˜nsc
⌊ψL′
(i−1)˜nsc + χ

i ≤˚
∆o

×
#
θic + ⌊∆ψL(i−1)˜nsc

⌊∆D(i−1)˜nsc

θic + ⌊∆ψL(i−1)˜nsc
′
+

θic −⌊Uθic

⌊Ur−1
i

θic −⌊Uθic
′$
+ χ

˚
∆o < i ≤˚
∆


9.3 Interaction with an operator
375
×

θisc + ⌊∆ψL(i−1)˜nsc

⌊∆D(i−1)sc

θisc + ⌊∆ψL(i−1)˜nsc
′
+χ

˚
∆< i
 #
θisc + ⌊∆ψL(i−1)˜nsc

⌊∆D(i−1)sc

θisc + ⌊∆ψL(i−1)˜nsc
′
+

θisc −⌊Uθic

⌊Ur−1
i

θisc −⌊Uθic
′$
,
ki˜nsc = ki˜nsc
+χ

i ≤˚
∆o
 
k(i−1)˜nsc + ⌊∆D(i−1)˜nscric ln
 ⌊Uri
ric

+ ric
⌊Uri

+χ

˚
∆o < i ≤˚
∆

⌊∆D(i−1)˜nscrisc
+χ

˚
∆< i
 
⌊∆D(i−1)˜nscrisc + ln
 ⌊Uri
risc

+ risc
⌊Uri

end
of the cycle over i
end
of the cycle over ˜n
Note that the splitting to subsets respects both the distinction of the o- and
p-data and the fact that parameters of factors predicting innovations are in-
dependent of the signaling action st. For speciﬁcation of the optimal strategy,
it remains to mix contributions of distances of individual components. We
take into account the form of the component weights for the estimated and
designed models. For it we set, L0 = L1 = I˚
φ, D0 = D1 = 0˚
φ,˚
φ, k0 = k1 = 0.
For
c = 1, . . . ,˚c
L0D0L′
0 = L0D0L′
0 + αc
n L˚
dn0cD˚
dn0cL′
˚
dn0c, k0 = k0 + αc
n k˚
dn0c
L1D1L′
1 = L1D1L′
1 + ⌊Uf(c)
 1
nL˚
dn1cD˚
dn1cL′
˚
dn1c + ⌊ILc
⌊IDc
⌊IL′
c

k1 = k1 + ⌊Uf(c)
 1
nk˚
dn1c + ⌊Ikc

.
end
of the cycle over c
The standard minimization implies that the optimal strategy is
⌊If(snt+1|d(nt)) ∝⌊Uf(st) exp
	
−0.5

ksnt+1 + φ′
ntLsnt+1Dsnt+1L′
snt+1φ′
nt

.
Its normalizing factor γ(φnt) deﬁnes the exact Bellman function to be trans-
ferred to the next optimization step. Use of the inequality between the arith-
metic and geometric means preserves the assumed form of −ln(γ(d(nt)) while
guaranteeing that the upper bound is minimized.
Remark(s) 9.10
1. The probability ⌊If(stn+1 = 0|φtn) is to be mapped on traﬃc lights. Psy-
chologically, it seems to be reasonable to use a nonlinear mapping given
by a pair of thresholds 0 < w < W < 1

376
9 Design with normal mixtures
Call for action if
⌊If(stn+1 = 0|φtn) ≤w.
(9.65)
Allow nonaction if ⌊If(stn+1 = 0|φtn) ≥W > w.
Otherwise, do not change current signalling action.
2. The common factors of both models can be exploited when the grouping
rate n = 1. Otherwise, this property brings no advantage.
3. Attempts to use the ω-bound were done but with no signiﬁcant inﬂuence
on the algorithm. It is worth checking possible alternatives.
The result is rather complex. Thus, a ﬁxed version of signaling will be probably
used. Let us write down the corresponding ﬁxed signaling algorithm.
Algorithm 9.16 (Fixed signaling based on Proposition 9.17)
Initial (oﬄine) mode
•
Estimate normal mixture model of the o-system with the state φt; see Chap-
ter 8.
•
Specify the true user’s ideal pdf on do;t, ct.
•
Specify the user “alarm probability” pf ⌊Uf(st = 0) .
•
Perform a ﬁxed academic, industrial or simultaneous design.
•
Compute steady-state lifts ks and kernels Ls, Ds, s ∈{0, 1} according to
Proposition 9.17.
•
Specify thresholds w, W determining the mapping (9.65).
Sequential (online) mode, running for t = 1, 2, . . .,
1. Acquire dt and evaluate the state φt.
2. Evaluate signaling probabilities
f(st+1|φt) ∝⌊Uf(st+1) exp
	
−0.5

kst+1 + φ′
tLst+1Dst+1L′
st+1φt

.
3. Convert the value f(st+1 = 0|φt) into color using the nonlinearity (9.65).
The call action is the stronger the closer is f(st+1 = 0|φt) to zero.
4. Go to the beginning of Sequential mode.
Problem 9.4 (Completion and development of advising design) The
described algorithms cover all formulated tasks. The overall state is, however,
far from being satisfactory. The following problems have to be at least ad-
dressed
•
completion and comparison of all variants,
•
design of new variants,
•
simpliﬁcation,
•
creation of a guide on choosing of tuning knobs,
•
inclusion of stopping rules,
•
analysis of theoretical properties known from control area (like controlla-
bility),
•
robustness analysis, . . .

10
Learning with Markov-chain factors
and components
Markov-chain factors allow us to incorporate logical quantities and to work
with mixed real and discrete components. Mixtures consisting solely of Markov-
chain components form a Markov chain. In spite of this, the use of mixtures
makes sense as they have the potential to provide parsimonious parameteri-
zation. A detailed description of all learning aspects related to Markov-chain
factors, components and their mixtures forms the content of this chapter.
We deal with Markov-chain factors predicting scalar discrete-valued dt ∈
d∗≡{1, . . . , ˚
d}. The factor is described by the pf
f(dt|d(t −1), Θ) ≡f(dt|ψt, Θ) =
 
d∈d∗
 
ψ∈ψ∗
	
⌊d|ψΘ
δ[d,ψ′]′,Ψt , where (10.1)
ψt ∈ψ∗≡{1, . . . , ˚
ψ < ∞} is a ﬁnite-dimensional regression vector with a
ﬁnite number of diﬀerent values that can be constructed in a recursive
way from the observed data;
Ψt ≡[dt, ψ′
t]′ is a ﬁnite-dimensional, ﬁnite-valued data vector;
Θ ∈Θ∗≡
 ⌊d|ψΘ ≥0, 2
d∈d∗⌊d|ψΘ = 1, ∀ψ ∈ψ∗
are unknown transition
probabilities;
δ·,· is the Kronecker symbol that equals 1 for identical arguments and it is
zero otherwise.
This chapter layout copies that of the general Chapter 6. Common tools
in Section 10.1 concern mainly properties of the Dirichlet pdf that is the con-
jugate one to the Markov-chain model. Data preprocessing, Section 10.2, adds
to common operations those speciﬁc to Markov chains, namely, quantization
of continuous-valued signals and coding of discrete regression vectors. After
discussion of prior-knowledge elicitation, Section 10.3, the key construction of
the prior pdf is specialized to Markov chains in Section 10.4. Adequate ver-
sions of approximate estimation, Section 10.5, structure estimation, Section
10.6, and model validation, Section 10.7, form the rest of this chapter.
It is fair to forewarn that the presented algorithms are elaborated much
less than their normal counterpart. Applicability of the general approaches of

378
10 Learning with Markov-chain factors and components
Chapter 6 and presentation of a wide range of open research problems form
the main messages of this chapter.
10.1 Common tools
10.1.1 Dirichlet pdf as a conjugate prior
Markov-chain factors belong to the exponential family (see Section 3.2) so
that they possess a conjugate prior. The following correspondence to (3.6)
holds
f(dt|d(t −1), Θ) = exp
⎡
⎣

[d,ψ′]′=Ψ∈Ψ ∗
δ[d,ψ′]′,Ψt ln

⌊d|ψΘ

⎤
⎦
≡A(Θ) exp [⟨B(Ψt), C(Θ)⟩+ D(Ψ)]
A(Θ) ≡1,
B ˜Ψ(Ψ) ≡δ ˜Ψ,Ψ, C(Θ ˜Ψ) = ln

⌊˜d| ˜
ψΘ

, with ˜Ψ ≡
	
˜d, ˜ψ′′
∈Ψ ∗,
D(Ψ) = 0,
⟨B, C⟩≡

˜Ψ∈Ψ ∗
B ˜Ψ(Ψ)C ˜Ψ(Θ).
This correspondence determines the conjugate prior (3.13) in the form known
as the Dirichlet pdf
DiΘ(V ) ≡f(Θ|V ) =
/
Ψ=[d,ψ′]′∈Ψ ∗
 ⌊d|ψΘ
 ⌊d|ψV −1 χΘ∗(Θ)
I(V )
,
(10.2)
where χΘ∗(Θ) is indicator of Θ∗.
The value of the normalizing integral I(V ) and constraint on the statistic
V = [ ⌊d|ψV ]d∈d∗,ψ∈ψ∗that guarantees ﬁniteness of I(V ) are described below
together with other properties of this important pdf.
Within this chapter the indexes at Θ (similarly as for statistic V ) corre-
sponding to the treated data vector Ψ = [d′, ψ′]′ are placed as the left upper
index ⌊d|ψ. It makes iterative formulas with a lot of other indexes a bit more
readable.
Proposition 10.1 (Basic properties and moments of Di pdf) The nor-
malization integral of the Dirichlet pdf DiΘ(V ) is
I(V ) =
 
ψ∈ψ∗
B

⌊·|ψV

≡
 
ψ∈ψ∗
/
d∈d∗Γ
 ⌊d|ψV

Γ
2
d∈d∗⌊d|ψV

(10.3)
Γ(x) ≡
 ∞
0
zx−1 exp(−z) dz < ∞for x > 0.
Thus, the normalization factor is ﬁnite iﬀ
⌊d|ψV > 0, ∀Ψ ≡[d, ψ′]′ ∈Ψ ∗.
This condition is met for all posterior statistics ⌊d|ψVt if ⌊d|ψV0 > 0.

10.1 Common tools
379
The Dirichlet pdf has the following marginal pdfs and moments Di ⌊d|ψΘ(V )
≡f

⌊d|ψΘ|V

=
 ⌊d|ψΘ
 ⌊d|ψV −1 
1 −⌊d|ψΘ
 ⌊ψν−⌊d|ψV −1 χ[0,1]
 ⌊d|ψΘ

I
 ⌊d|ψV

⌊ψν ≡

d∈d∗
⌊d|ψV,
I

⌊d|ψV

≡Γ
 ⌊d|ψV

Γ
 ⌊ψν −⌊d|ψV

Γ
 ⌊ψν

(10.4)
E
	
⌊d|ψΘ
!!! V, Ψ

=
⌊d|ψV
⌊ψν
E
	
⌊d|ψΘ ⌊˜d| ˜
ψΘ
!!! V, Ψ, ˜Ψ

= (1 −δΨ, ˜Ψ)E
	
⌊d|ψΘ
!!! V, Ψ

E
	
⌊˜d| ˜
ψΘ
!!! V, ˜Ψ

+δΨ, ˜Ψ

E
	
⌊d|ψΘ
!!! V, Ψ
2 1 + ⌊d|ψV −1
1 + ⌊ψν−1
cov
	
⌊d|ψΘ, ⌊˜d| ˜
ψΘ
!!! V, Ψ, ˜Ψ

= δΨ, ˜Ψ

E
	
⌊d|ψΘ
!!! V, Ψ
2 ⌊d|ψV −1 −⌊ψν−1
1 + ⌊ψν−1
E
	
ln

⌊d|ψΘ
!!! V, Ψ

=
∂
∂⌊d|ψV ln

Γ

⌊d|ψV

−
∂
∂⌊ψν ln

Γ

⌊ψν

. (10.5)
The predictive pdf is f(d|ψ, V ) =
⌊d|ψV
⌊ψν
≡E
	
⌊d|ψΘ
!!! V, Ψ

.
(10.6)
Proof. Evaluation of the normalization integral is the basic step. It can be
done inductively starting with ˚
d = 2, using the deﬁnition of the Euler beta
function, coinciding with B for ˚
d = 2 and its relationship to the gamma
function Γ(·) deﬁned by (10.3). The rest relies mostly on the known recursion
Γ(x + 1) = xΓ(x), [156].
The evaluation E

ln
 ⌊d|ψΘ
!! V, Ψ

is the only involved step. To demon-
strate it, let us assume that Θ ∼DiΘ(m, n) = B−1(m, n)Θm−1(1 −Θ)n−1.
Then,
E[ln(Θ)] = B−1(m, n)
 1
0
ln(Θ)Θm−1(1 −Θ)n−1 dΘ
= B−1(m, n)
 1
0
∂
∂mΘm−1(1 −Θ)n−1 dΘ
= B−1(m, n) ∂
∂mB(m, n) =
∂
∂m ln(B(m, n)
=
∂
∂m ln(Γ(m)) −
∂
∂(m + n) ln(Γ(m + n)).
Substitution m = ⌊d|ψV and m + n = ⌊ψν gives the result (10.5).
We need to know the KL divergence of a pair of Dirichlet pdfs. Parameters
corresponding to diﬀerent regression vectors are independent. Consequently,
we can consider a ﬁxed, and for notation simplicity, empty regression vector.

380
10 Learning with Markov-chain factors and components
Proposition 10.2 (KL divergence of Di pdfs) Let f(Θ) = DiΘ(V ), ˜f(Θ)
= DiΘ

˜V

be a pair of Dirichlet pdfs describing parameters
Θ ≡

⌊1Θ, . . . , ⌊˚
dΘ

∈Θ∗=
"
⌊dΘ > 0,

d∈d∗
⌊dΘ = 1
%
, d∗≡

1, . . . , ˚
d

.
Then, their KL divergence is given by the formula
D(f|| ˜f) =
˚
d

d=1
⎡
⎣

⌊dV −⌊d˜V

∂
∂⌊dV ln

Γ

⌊dV

+ ln
⎛
⎝
Γ

⌊d˜V

Γ
 ⌊dV

⎞
⎠
⎤
⎦
−(ν −˜ν) ∂
∂ν ln(Γ(ν)) + ln
Γ(ν)
Γ(˜ν)

ν ≡
˚
d

d=1
⌊dV,
˜ν ≡
˚
d

d=1
⌊d˜V .
(10.7)
Proof. The majority of evaluations is prepared by Proposition 10.1. For the
considered pdfs, the KL divergence (2.25) gets the form (use (10.3), (10.4))
D = E
⎡
⎣
˚
d

d=1

⌊dV −⌊d˜V

ln

⌊dΘ

|V
⎤
⎦−ln
B(V )
B( ˜V )

=
˚
d

d=1

⌊dV −⌊d˜V

E
	
ln

⌊dΘ

| ⌊dV

−ln
B(V )
B( ˜V )

=

(10.5)
˚
d

d=1
#
⌊dV −⌊d˜V
 
∂
∂⌊dV ln

Γ

⌊dV

−∂
∂ν ln(Γ(ν))
$
−ln
⎛
⎝B(V )
B

˜V

⎞
⎠
=
˚
d

d=1

⌊dV −⌊d˜V

∂
∂⌊dV ln

Γ

⌊dV

−(ν −˜ν) ∂
∂ν ln(Γ(ν))−ln
B(V )
B( ˜V )

=
˚
d

d=1
⎡
⎣

⌊dV −⌊d˜V

∂
∂⌊dV ln

Γ

⌊dV

+ ln
⎛
⎝
Γ

⌊d˜V

Γ
 ⌊dV

⎞
⎠
⎤
⎦
−(ν −˜ν) ∂
∂ν ln(Γ(ν)) + ln
Γ(ν)
Γ(˜ν)

.
There, we have used linearity of expectation, the deﬁnitions of the beta func-
tion B and of the statistic ν ≡2
d∈d∗⌊dV , ˜ν ≡2
d∈d∗⌊d˜V .

10.1 Common tools
381
10.1.2 Estimation and prediction with Markov-chain factors
The Markov-chain factors predicting discrete-valued dt belong to the exponen-
tial family. Thus, their estimation with the conjugate prior pdf and subsequent
prediction reduce to algebraic operations; see Proposition 3.2.
Proposition 10.3 (Estimation and prediction with Markov chains)
Let us consider a ﬁxed discrete value ψ of the regression vector. Let nat-
ural conditions of decision making, Requirement 2.5, hold, the treated fac-
tor (10.1) is Markov-chain and a Dirichlet conjugate prior DiΘ(V0) (3.13),
V0 ≡
	
⌊1|ψV0, . . . , ⌊˚
d|ψV0

as well as conjugate alternatives DiΘ( ⌊AVt), ⌊AVt ≡
	
⌊1|ψ AVt, . . . , ⌊˚
d|ψ AVt

with the forgetting factor λ ∈[0, 1], are used in stabi-
lized forgetting; see Section 3.1. Then, the posterior pdf is also the Dirichlet
pdf DiΘ(Vt) with
Vt ≡
	
⌊1|ψVt, . . . , ⌊˚
d|ψVt

.
The suﬃcient statistic Vt evolves according to the recursion
⌊d|ψVt = λ

⌊d|ψVt−1 + δΨ,Ψt

+ (1 −λ) ⌊d|ψ AVt
⌊d|ψV0 given, [d, ψ′]′ ≡Ψ ∈Ψ ∗.
(10.8)
The predictive pdf is
f(d|ψ, Vt) =
⌊d|ψVt
2
˜d∈d∗⌊˜d|ψVt
.
(10.9)
Proof. It is a direct consequence of the Bayes rule applied to the member of
the exponential family.
Remark(s) 10.1
1. The array V =
 ⌊d|ψV

d∈d∗,ψ∈ψ∗is also known as the occurrence table.
2. The obtained prediction corresponds with understanding of the probability
as a relative frequency of events. Here, the data are just split in subsets
corresponding to diﬀerent values of regression vectors ψ. Numerically, the
Bayesian set up adds nontrivial initial conditions to the occurrence table.
3. The predictive pdf is the key element needed for approximate estimation;
see Section 10.5.
Problem 10.1 (Reduction of dimensionality) The dimensionality of the
occurrence table might be easily excessive, mostly because of the high cardinal-
ity ˚
ψ. Then, a reduced parameterization is necessary. Promising techniques
exploiting a sparse nature of this table are described in [157, 165]. They could
be a reasonable start for solving this practically important problem.
Problem 10.2 (Relation to nonparametric Bayesian estimation) Mar-
kov chains have a tight connection to nonparametric Bayesian estimation,
[166]. Inspection whether this connection can be used in our context is worth
considering. It could extend applicability of the achieved results signiﬁcantly.

382
10 Learning with Markov-chain factors and components
10.1.3 Likelihood on variants
Predictors based on Markov chains serve for comparing competitive descrip-
tions of the same discrete valued data. Proposition 10.1 provides immediately
a Markov-chain variant of Proposition 6.1.
Proposition 10.4 (Markov-chain mixture one-step-ahead predictor)
Use of online estimation of a Markov-chain mixture within the framework of
the adaptive advisory system provides a one-step-ahead predictor in the form
f(dt+1|d(t)) =

c∈c∗
κc;t
2
˜c∈c∗κ˜c;t
 
i∈i∗
f(dic;t+1|d(t), c)
(10.10)
≡

c∈c∗
κc;t
2
˜c∈c∗κ˜c;t
 
i∈i∗
I(d(t + 1)|ic)
I(d(t)|ic)
≡

c∈c∗
ˆαc;t
 
i∈i∗
f(dic;t+1|ψic;t+1, d(t), c),
ˆαc;t ≡
κc;t
2
˜c∈c∗κ˜c;t
.
I(d(t)|ic) ≡I(Vic;t) = B(Vic;t) ≡
/
dic∈d∗
ic Γ
 ⌊dic|ψicVic;t

Γ

2
dic∈d∗
ic
⌊dic|ψicVic;t
,
Γ(x) =
 ∞
0
zx−1 exp(−z) dz < ∞for x > 0, where
⌊dic|ψicVic;t = the occurrence table of the factor ic collected up to time t.
For the ﬁxed advisory system, the predictor is given by the last equality in
(10.10) with f(dic;t+1|ψic;t+1, d(t), c), ˆαc;t replaced by f(dic;t+1|ψic;t+1, d(0), c),
ˆαc;0. The used factor predictors can be expressed as follows.
f(dic;t+1|ψic;t+1, d(t), c) =
⌊dic;t+1|ψic;t+1Vic;t
2
dic∈d∗
ic
⌊dic|ψic;t+1Vic;t
, for an adaptive advising,
f(dic;t+1|ψic;t+1, d(0), c) =
⌊dic;t+1|ψic;t+1Vic;0
2
dic∈d∗
ic
⌊dic|ψic;t+1Vic;0
, for a ﬁxed advising.
Proof. Omitted.
10.1.4 Branch-and-bound techniques
For Markov-chain parameterized factors with conjugate prior pdfs, various
DiΘ(V ) pdfs are alternative descriptions inspected and compared. Thus, al-
ternative sets of suﬃcient statistics V are branched and bounded as outlined
in Section 6.1.3. The maximized functional F then becomes the function,
namely, the v-likelihood f(d(˚t)|V ) of data d(˚t) conditioned on the suﬃcient

10.2 Data preprocessing
383
statistics V determining the DiΘ(V ) pdf that are used for eliminating un-
known parameters
f(d(˚t)|V ) =

f(d(˚t)|Θ)DiΘ(V ) dΘ
=

(10.10)
 
t∈t∗
f(dt|d(t −1)).
Evaluation of approximate v-likelihood values for Markov-chain mixtures is
implied by Proposition 10.4. Conceptually, general procedures for function
maximization can be used. Generic high dimensions of occurrence matrices
V make us stay within the considered framework of the branch-and-bound
techniques. Speciﬁc versions are described in Section 10.4.
10.2 Data preprocessing
Except for the handling of missing data, no general preprocessing is expected
when the modelled data are “naturally” discrete-valued. Often, however, the
discrete-valued data arise by quantizing underlying continuous-valued signals.
Then, the complete preprocessing arsenal described in Chapter 6 is needed.
Here, the aspects speciﬁc to the intended quantization are brieﬂy discussed.
10.2.1 Use of physical boundaries
The ability to respect hard physical bounds is a key advantage of Markov-
chain models applied to continuous-valued signals. The uneven occurrence of
the underlying scalar signal values within the inspected range is more the
rule than the exception. This calls for an uneven speciﬁcation of quantization
levels. It allows us either “aggregate” signals so that diﬀerences between the
signal distribution and target are well characterized or to exploit a full range
of the inspected information channel. The following simple proposition gives
guidelines for the latter case.
Proposition 10.5 (Signal quantization)
Let f(x) > 0 be pdf of a scalar
continuous-valued quantity x ∈x∗≡[x, x] with known ﬁnite boundaries x, x.
Let us consider a grid xι, ι = 0, . . . ,˚ι,
x = x0 < x1 < · · · < x˚ι−1 < x˚ι = x
with a given ﬁnite number of grid points ˚ι + 1.
Let ˆf ∈ˆf ∗≡

pdfs on x∗with constant values ˆfι on (xι−1, xι)

. The best
approximation ˆf(x) of the pdf f(x) taken from ˆf ∗such that
D

f
!!!
!!! ˆf

→
min
{ ˆ
fι}ι∈ι∗
and D

ˆf
!!!
!!! uniform pdf

→
min
{xι}ι∈ι∗, is
ˆf(x) = xι −xι−1
˚ι
χ[xι−1,xι](x)

384
10 Learning with Markov-chain factors and components
on the grid speciﬁed by the requirement
¯x −x
˚ι
=
 xι
xι−1
f(x) dx.
(10.11)
Proof. First a ﬁxed grid is considered, then the part of D

f
!!!
!!! ˆf

inﬂuenced
by values ˆfι has the form
˚ι

ι=1
 xι
xι−1
f(x) ln
 1
ˆfι

dx =
˚ι

ι=1
0 xι
xι−1
f(x) dx
1
ln
 1
ˆfι

=
˚ι

ι=1
0 xι
xι−1
f(x) dx
1
ln
0 xι
xι−1 f(x) dx
ˆfι
1
−
˚ι

ι=1
0 xι
xι−1
f(x) dx
1
ln
0 xι
xι−1
f(x) dx
1
.
In this expression, the last term is independent of the optimized values and
the previous term is the KL divergence minimized by ˆfι =
 xι
xι−1 f(x) dx.
The second KL divergence measures uncertainty of the resulting approxi-
mation and it reaches the smallest zero value for uniform pdf ˆf.
This simple Proposition hints how to quantize scalar signal d(˚t).
Algorithm 10.1 (Signal quantization)
1. Select the number ˚ι of quantization levels.
2. Fit a rich normal static mixture to the learning data d(˚t).
3. Evaluate the corresponding distribution function as the integral of the pdf
estimated in the previous step.
4. Split the range [0,1] of values of the distribution function into ˚i-intervals
of the same length.
5. Project these values on the axis of arguments of the distribution function.
It gives the grid searched for.
Remark(s) 10.2
1. The recommended simple quantization rule touches on an extensive ﬁeld
reviewed well in the paper [167].
2. The choice of the grid so that the quantized version is as close as possible
to a uniform pdf tries to avoid the situation that the subsequently learned
models have to deal with rare events.
3. Any mixture can be ﬁtted to experimental data for the discussed purpose.
Even an ordinary histogram can be used. Mixture estimation serves here
as a smoothed version of a histogram.

10.2 Data preprocessing
385
4. Dependencies are neglected in the construction. Essentially, a sort of er-
godic behavior is implicitly assumed and the estimated pdf is the limiting
distribution. This approach seems to be suﬃcient for the considered quan-
tization purpose.
5. Proposition 10.5 can be and should be applied to increments of the sig-
nal, too. For smooth signals, that are expected in the physical world, the
probability that the signal change is greater than some level is practically
zero. This fact is revealed by the described algorithm that “discovers” a
band of nonzero transition probabilities. It helps to decrease signiﬁcantly
the number of estimated parameters and makes treatment of such signals
practicable.
Problem 10.3 (Algorithmic solution of quantization) The basic ideas
presented above have to be converted into a complete set of algorithms.
10.2.2 Removal of high-frequency noise
Quantization of signal values suppresses small (within the quantization step)
changes in signal values. High-frequency noise usually has relatively small
amplitudes. Consequently, quantization suppresses “naturally” high-frequency
noise. This brief argument describes more of a tendency than a general rule.
Thus, a high-frequency-noise removal should generally be considered before
quantization.
10.2.3 Suppression of outliers
In the discussed context, outliers are dangerous as they extend the range of the
signal to be quantized. They increase the number of levels to be considered for
achieving the target precision. Proposition 10.5 helps in this respect, too. By
deﬁnition, outliers occur rarely so that their, even wide, range can be labelled
by a few discrete values only.
10.2.4 Coding of regression vectors
Both predicted data item d and regression vector ˜ψ are discrete valued. The
suﬃcient statistics V describing individual factors are arrays indexed by data
vectors Ψ =
	
d, ˜ψ′′
. For an easy software manipulation, it is reasonable to
keep d as an independent index and to map the regression vector ˜ψ to a
scalar quantity ψ. The chosen mapping, called coding, inﬂuences the formal
structure of the statistics V =
	
⌊d| ˜
ψV

=
 ⌊d|ψV

, d ∈d∗≡{1, . . . , ˚
d},
ψ ∈ψ∗≡{1, . . . , ˚
ψ}. Treatment of the potentially sparse matrix [Vd|ψ] is
simpler if its nontrivial entries are clustered in a few contiguous areas. Coding
may either enhance or destroy this property.

386
10 Learning with Markov-chain factors and components
It seems that delayed items of a single quantity, say ˜dt, . . . , ˜dt−∂, each with
˚
d possible values, should be coded to scalar dt by the “thermometer” code
dt ≡
∂

i=0
˚
d∂−i ˜dt−i = ˚
d∂˜dt + ˚
d−1 
dt−1 −˜dt−∂−1

.
(10.12)
This coding reﬂects presumption that the older values have a smaller inﬂu-
ence on the predicted value. Universality of this option and combinations of
regressors of a diﬀerent nature are questionable and the problem should be
studied in detail. Vast amount of experience available in signal processing can
deﬁnitely be exploited.
Description of graph-type dependencies is another aspect of the same prob-
lem. Experience from the ﬁeld known as Bayesian networks [168, 169] can
help.
10.2.5 Coding of signal values
The mixture consisting exclusively of Markov-chain components is again a
Markov chain. It stimulates the natural question of whether it makes sense to
use them at all. The aﬃrmative answer follows from the possibility to spare
estimated parameters. The coding of signal values discussed here serves as an
example of this property.
Let us have a continuous-valued signal xt whose evolution is described
by the pdf f(xt|x(t −1)) ≡f(xt|xt−1) with a ﬁnite support covered say
by [0, 1]2. Binary expansion of xt ≈2˚
d
i=1 di;t2−i makes xt (approximately)
equivalent to discrete-valued multivariate data record dt with entries di;t ∈
{0, 1}. The data dt forms the Markov chain that can be approximated by a
speciﬁc mixture. For describing it, it is suﬃcient to consider ˚
d = 2. Then, the
following approximation
f(dt|dt−1) = f(d1;t|d2;t, d1;t−1, d2;t−1)f(d2;t|d1;t−1, d2;t−1)
≈f(d1;t|d1;t−1) [αf(d2;t|d2;t−1, d1;t−1 = 0)
+ (1 −α)f(d2;t|d2;t−1, d1;t−1 = 1)]
≡f(d1;t|d1;t−1) [αf(d2;t|d2;t−1, c = 1) + (1 −α)f(d2;t|d2;t−1, c = 2)]
can be justiﬁed by an expected dominant inﬂuence of d1;t−1 on d1;t and by in-
troducing the “averaged” inﬂuence of d1;t−1 on the evolution of d2;t−1 →d2;t.
The original Markov chain on the left-hand side has 12 free parameters, the
approximate right-hand side has 7 free parameters, including the probability
α quantifying the average inﬂuence of d1;t−1. This number increases to 9 if we
do not assume that f(d1;t|d1;t−1) is a common factor. The diﬀerence is much
more signiﬁcant for higher ˚
ds and longer memory of the approximated model.

10.3 Use of prior knowledge at the factor level
387
10.3 Use of prior knowledge at the factor level
Here, general ideas of quantiﬁcation of prior knowledge at the factor level,
Section 6.3, are specialized to Markov-chain factors.
10.3.1 Internally consistent ﬁctitious data blocks
Processing of internally consistent data blocks coincides with learning Markov-
chain factors; see Section 10.1.2. Thus, we have to quantify individual knowl-
edge items Kk, k = 1, . . . ,˚k and then to specialize merging of individual pdfs
f(Θ|Kk) expressing them.
10.3.2 Translation of input-output characteristics into data
Quantiﬁcation of the knowledge of the initial moments (6.26) of the predictive
pdf f(d|ψ) given by a ﬁxed regression vector ψ is assumed
ˆd =

d∈d∗
df(d|ψ), ˆr =

d∈d∗

d −ˆd
2
f(d|ψ).
(10.13)
The general Proposition 6.4 gives the constructed prior out of the conjugate
class Dirichlet pdfs. We need to stay within it. It makes us derive the following
specialized proposition.
Proposition 10.6 (Knowledge of input-output characteristics)
Let us
ﬁx a regression vector ψ. Consider Dirichlet pdfs Diθ(V ) of the unknown
parameter θ with entries θd ≡⌊d|ψΘ and determined by the vector statistics
V with entries
⌊dV ≡
⌊d|ψV , d ∈d∗. The symbol
⌊d|ψV denotes entry of a
positive occurrence array; see Section 10.1.1.
We search for the Diθ(V ) pdf that fulﬁlls constraints (10.13) and mini-
mizes the KL divergence to the ﬂat pre-prior Diθ(ε1) given by ε > 0, ε →0
that multiplies vector of units 1 = [1, . . . , 1]′ of the appropriate length.
Such a pdf is determined by the statistics
⌊dV =
1
ad2 + bd + c, d ∈d∗= {1, . . . , ˚
d}
(10.14)
with constants a, b, c solving equations
ˆd =
2
d∈d∗
d
ad2+bd+c
2
d∈d∗
1
ad2+bd+c
, ˆr =
2
d∈d∗
(d−ˆd)
2
ad2+bd+c
2
d∈d∗
1
ad2+bd+c
,
(10.15)
while minimizing the resulting distance.

388
10 Learning with Markov-chain factors and components
Proof. For ν ≡2
d∈d∗⌊dV and ¯ν ≡ε˚
d, the optimized functional D

f|| ¯f

is
the function of statistics V , ¯V = ε1 (see Proposition 10.2)
D

f|| ¯f

=
˚
d

d=1

⌊dV −⌊d¯V

∂
∂⌊dV ln

Γ

⌊dV

+ ln
0
Γ
 ⌊d¯V

Γ
 ⌊dV

1
−(ν −¯ν) ∂
∂ν ln(Γ(ν)) + ln
Γ(ν)
Γ(¯ν)

.
Its derivative with respect to ⌊dV is
∂D

f|| ¯f

∂⌊dV
= ∂ln

Γ
 ⌊dV

∂⌊dV
+

⌊dV −⌊d¯V
 ∂2 ln

Γ
 ⌊dV

∂⌊dV 2
−∂ln

Γ
 ⌊dV

∂⌊dV
−∂ln(Γ(ν))
∂ν
+ ∂ln(Γ(ν))
∂ν
−(ν −¯ν)∂2 ln(Γ(ν))
∂ν2
=

⌊dV −⌊d¯V
 ∂2 ln

Γ
 ⌊dV

∂⌊dV 2
−(ν −¯ν)∂2 ln(Γ(ν))
∂ν2
.
Similarly,
∂ˆd
∂⌊dV = ν−1(d −ˆd),
∂ˆr
∂⌊dV = ν−1
#
d −ˆd
2
−ˆr
$
.
This gives derivatives of the Lagrangian function that, for ε →0, can be
rewritten into the form
0 = ⌊dV ∂2 ln

Γ
 ⌊dV

∂V 2
d
+ 0.5ad2 + 0.5bd + 0.5(c −1),
where the constants a, b, c are made of Lagrangian multipliers and terms in-
dependent of d. Using expansion of ln

Γ
 ⌊dV

[156], the involved second
derivative can be approximated by
∂2 ln

Γ
 ⌊dV

∂⌊dV 2
≈0.5 ⌊dV −1 
1 −⌊dV −1
.
Putting this approximation into the condition for extreme, we get the linear
equation for ⌊dV that determines its dependence on d. The optional constants
a, b, c are selected so that constraints are fulﬁlled. The selection is made unique
by selecting c so that the resulting distance is the smallest one.
Remark(s) 10.3
1. For a given a, b, the value c determines the sum ν = 2
d∈d∗(ad2+bd+c)−1.
The minimized functional is its increasing function while ν > ¯ν. It hints at
the choice of c as the solution of the equation ¯ν = 2
d∈d∗(ad2 + bd + c)−1.
This statement is not included into Proposition, as it is not proved that
such a triple (a, b, c) exist while guaranteeing that ⌊dV > 0. A nontrivial
solution can be expected iﬀmeaningful options ˆd ∈

1, ˚
d

and ˆr <

0.5˚
d
2
are made.
2. Other constraints can be and should be considered, respecting the discrete
nature of data.

10.4 Construction of the prior estimate
389
10.3.3 Merging of knowledge pieces
We have got a collection of pdfs f(Θ|Kk) = DiΘ(Vk) k ∈k∗≡{1, . . . ,˚k}
after processing individual internally consistent data blocks and individual
knowledge items. We use them for construction of a single posterior pdf
ˆf(Θ|d(˚t), K(˚k)) = DiΘ(V˚t) that merges them all together with available real
data d(˚t). For this, the general Proposition 6.5 applies. It leads directly to the
DiΘ counterpart of Algorithm 6.3.
Algorithm 10.2 (Merging Dirichlet knowledge sources)
1. Construct prior DiΘ(Vk) pdfs reﬂecting internally consistent data blocks
by applying ordinary Bayesian estimation and (or) reﬂecting individual
knowledge pieces according to Proposition 10.6.
2. Evaluate the likelihood function L(Θ, d(˚t)) = DiΘ(V0;˚t) by applying Propo-
sition 10.3 with zero initial conditions for recursive evaluation of the oc-
currence matrix V .
3. Evaluate posterior pdfs f(Θ|d(t), Kk) = DiΘ(V0;˚t + Vk) and v-likelihood
f(d(˚t)|Kk) = I(V0;˚t + Vk)
I(Vk)
corresponding to prior pdfs f(Θ|Kk) = DiΘ(Vk) k ∈k∗. The normaliza-
tion integral I(V ) is given by the formula (10.3).
Regularization by a ﬂat pre-prior pdf DiΘ(ε1), given by small ε > 0 has
to be considered if some Vk contains zero values.
4. Evaluate the weights expressing the posterior conﬁdence to individual
knowledge items
βk|d(˚t) =
f(d(˚t)|Kk)
2
˜k∈k∗f(d(˚t)|K˜k) =
I(V0;˚
t+Vk)
I(Vk)
2
˜k∈k∗
I(V0;˚
t+V˜k)
I(V˜k)
, k ∈k∗.
5. Determine the merger as the posterior pdf to be used
ˆf(Θ|d(˚t), K(˚k)) = DiΘ
0
V0;˚t +

k∈k∗
βk|d(˚t)Vk
1
= DiΘ(V0;˚t)DiΘ
0 
k∈k∗
βk|d(˚t)Vk
1
.
Notice that the used “prior” pdf is seen in the last formula.
10.4 Construction of the prior estimate
Here, Markov-chain counterparts of Section 6.4 are presented.

390
10 Learning with Markov-chain factors and components
10.4.1 Iterative construction of prior pdf
The danger of a plain repetitive use of the Bayes rule, discussed at the general
level in Section 6.4.1, gets the following form within the conjugate class of
Dirichlet pdfs. After ˚nth repetitive application of the (approximate) Bayes
rule we get the posterior pdf
DiΘ
0 ˚n

n=1
Vn;˚t
1
, where Vn is the suﬃcient statistic evaluated at nth step.
Taking into account the basic properties of the Dirichlet pdf, Proposition
10.1, it can be seen that point estimates ˆΘ of unknown Θ would be around
the point estimate equal to nonweighted average of point estimates obtained
in respective iterations. It can be a reasonable value. Its apparent uncertainty
would be, however, too small as it is inversely proportional to ˚n˚t. This ob-
servation clariﬁes why the ﬂattening may help; see Section 6.4.3. It acts as
forgetting that prefers newer, hopefully better, values of Vn;˚t and prevents the
unrealistically fast growth of the estimated precision.
10.4.2 Common bounding mapping
The common bounding mapping (see Section 6.4.2) just cancels the “least
ﬁt candidates”. For Markov-chain mixtures, the posterior pdfs are given by
the vector statistic κ, describing component weights, and by the collection
of the occurrence matrices Vic. These are ﬁnite-dimensional objects. They
may contain, however, a large number of entries. This fact makes us search
for a compromise between two contradictory requirements on the bounding
mapping
•
preserve as much information as possible from previous iteration steps,
•
store as little as possible alternatives.
As said in Chapters 6, 8, we have no general guideline how to reach the
adequate compromise. At present, we stress the second item and bound the
number of alternatives to two, at most to three.
10.4.3 Flattening mapping
We specialize the ﬂattening operation to Markov-chain mixtures.
Proposition 10.7 (Optimal ﬂattening mapping for Di factors) Let ˜f =
DiΘ

˜V

and ¯f = DiΘ
 ¯V

be a pair of Di pdfs deﬁned on the common
support Θ∗. Then, the pdf ˆf deﬁned on Θ∗and minimizing the functional
D

ˆf|| ˜f

+ qD

ˆf|| ¯f

, q > 0 is DiΘ

ˆV

with
ˆV = Λ ˜V + (1 −Λ) ¯V , where Λ ≡1/(1 + q) ∈(0, 1).
(10.16)

10.4 Construction of the prior estimate
391
Proof. Omitted.
The application of this result to whole mixtures is straightforward as the
posterior pdf of its parameters is a product of the posterior pdfs of Dirichlet
form related to both weights α and parameters of individual factors.
Proposition 10.8 (Optimal ﬂattening for Markov-chain mixtures) Let
parameters of a pair of Markov-chain mixtures be described by factors ˜fic(Θic)
= DiΘic

˜Vic

, weights ˜f(α) = Diα(˜κ), and similarly ¯fic(Θic) = DiΘic
 ¯Vic

,
¯f(α) = Diα(¯κ), i ∈i∗, c ∈c∗. The factors with the same indexes ic are deﬁned
on the common support Θ∗
ic. Then, the pdf ˆf minimizing the functional
D

ˆf|| ˜f

+ qD

ˆf|| ¯f

, q > 0
preserves the Dirichlet functional form. The resulting pdfs are given by the
statistics, i ∈{1, . . . , ˚
d}, c ∈c∗,
ˆVic = Λ ˜Vic+(1−Λ) ¯Vic, ˆκc = Λ˜κc+(1−Λ)¯κc, Λ ≡1/(1+q) ∈(0, 1). (10.17)
Proof. Omitted.
Flattening of the component-weights estimates is universal. It preserves
the Dirichlet form with statistics being a convex combination of statistics of
estimates among which the compromise is searched for. The same applies to
estimates of Markov-chain factors that are of Dirichlet type, too. The choice
of the ﬂattening rate is fully described by Propositions 6.7, 6.8, 6.11 and 6.13.
10.4.4 Geometric mean as branching mapping
Geometric-mean branching mapping A (6.15) maps a pair of arguments ˆfn(Θ),
n = 1, 2, of the maximized functional (6.38)
⌊hL

fn(d(˚t)|Θ) ˆfn(Θ), d(˚t)

≡
ˆfn(d(˚t)) ≡

fn(d(˚t)|Θ) ˆfn(Θ) dΘ on a new, hopefully better, candidate ˆfn(Θ).
Recall that fn(d(˚t)|Θ) ˆfn(Θ) ∝DiΘ(Vn;˚t) is an approximate posterior
likelihood computed by approximate estimation when conjugate ˆfn(Θ) =
DiΘ(Vn;0), n = 1, 2, are used as prior pdfs.
The new candidate is deﬁned
ˆf3(Θ|d(˚t)) ∝ˆf λ
1 (Θ|d(˚t)) ˆf 1−λ
2
(Θ|d(˚t))
≡DiΘ(V3;˚t) ≡DiΘ

λV1;˚t + (1 −λ)V2;˚t

(10.18)
λ =
ˆf1(d(˚t))
ˆf1(d(˚t)) + ˆf2(d(˚t))
, ˆfn(d(˚t)) =

ˆfn(d(˚t)|Θ) ˆfn(Θ) dΘ,
n = 1, 2.
(10.19)
Use of (10.18), (10.19) and Proposition 10.4 describes the new candidate
for the better estimate.

392
10 Learning with Markov-chain factors and components
Proposition 10.9 (Geometric-mean branching of Dirichlet pdfs)
Let
ˆfn(Θ) ≡Diα(κn;0)
 
c∈c∗
 
i∈i∗
DiΘic(Vicn;0),
n = 1, 2, be prior pdfs employed in approximate estimation (see Section 10.5)
of the Markov-chain mixture
f(dt|d(t −1), Θ) ≡

c∈c∗
αc
 
i∈i∗
⌊dic;t|ψic;tΘic.
The posterior pdfs preserve the functional forms of the prior pdfs and they are
described by statistics Vicn;˚t and κcn;˚t.
Their geometric mean f3(Θ|V3;˚t) keeps this form and its statistics are
V3ic;˚t = λ1;˚tVic1;˚t + (1 −λ1;˚t)Vic2;˚t
(10.20)
κ3ic;˚t = λ1;˚tκic1;˚t + (1 −λ1;˚t)κic2;˚t
λ1;˚t =
⎡
⎢⎣1 +
 
t∈t∗
2
c∈c∗
/
i∈i∗
I(Vic2;t)
I(Vic2;t−1)
κc2;t−1
2
˜c∈c∗κ˜c2;t−1
2
c∈c∗
/
i∈i∗
I(Vic1;t)
I(Vic1;t−1)
κc1;t−1
2
˜c∈c∗κ˜c1;t−1
⎤
⎥⎦
−1
.
The normalization integral I(V ) is given by the formula (10.3).
Proof. Omitted.
10.4.5 Random branching of statistics
The deterministic search algorithms are often stuck at a local optimum. This
makes us complement the deterministic search by a random one. Here, we
discuss this possibility in connection with Markov-chain factors.
Approximate estimation, Section 10.5, provides the posterior pdf f(Θ|d(˚t))
as a product of the posterior DiΘ pdfs corresponding to the individual,
Markov-chain parameterized, factors and to the posterior Dirichlet pdf on
component weights. Thus, the following considerations and computations may
deal with individual factors only and the random search step may be applied
to their subselection.
The DiΘ(V ) factor is determined by the ﬁnite-dimensional (almost) suf-
ﬁcient statistics V ∈V ∗≡{ collection of occurrence tables V > 0 with
dimensions compatible with estimated Θ }. Knowing this, we generate a ran-
dom sample ˜V in V ∗describing the modiﬁed factor. It gives us a new guess
˜f(Θ|d(˚t)) ≡DiΘ( ˜V ). By ﬂattening it towards a ﬂat pdf ¯f = DiΘ( ¯V ), given
by a small positive ¯V (see Proposition 6.6), we get a new guess of the prior
pdf ˆfnew(Θ) = DiΘ(Λ ˜V + (1 −Λ) ¯V ). Even for a single factor, the computa-
tional burden induced by the random choice is usually prohibitive. Thus, it
is reasonable to exploit interpretation of parts of statistics and change them
partially only. At present, it seems wise

10.4 Construction of the prior estimate
393
•
to estimate the factor structure before generating new statistics;
•
to change the point estimate of parameters using normal approximation,
based on coincidence of moments, cf. Proposition 10.1, of Dirichlet pdf
⌊d|ψ˜ˆΘ = max
⎡
⎣⌊d|ψ¯ˆΘ, ⌊d|ψ ˆΘ
⎛
⎝1 + eρ
C
⌊d|ψ ˆΘ−1 −1
⌊ψν + 1
⎞
⎠
⎤
⎦
(10.21)
e ∼Ne(0, 1),
where
⌊d|ψ¯ˆΘ > 0
is a preselected lower bound
ρ ∈ρ∗≡(1, 5) scales the generating noise
⌊d|ψ˜ˆΘ ≡⌊d|ψ˜ˆΘ
ν
ν −⌊d|ψ ˆΘ + ⌊d|ψ˜ˆΘ
˜ν ≡ν

1 −⌊d|ψ ˆΘ + ⌊d|ψ˜ˆΘ

and deﬁne the new occurrence table
⌊d|ψV ≡˜ν ⌊d|ψ˜ˆΘ.
Statistics κ determining the Dirichlet pdf of component weights are modiﬁed
in the same ways as in (8.52). It gives a chance to be modiﬁed even to the
components with ˆαc ≈0. The normal pdf cut so that the smallest κc does not
decrease is approximately used. It gives equivalent of (8.52)
˜κc = max

κc
0
1 +
ρ
?2
˜c∈c∗κ˜c
ec
1
, min
˜c∈c∗κ˜c

, ρ ∈(1, 5), f(ec) = Nec(0, 1).
Remark(s) 10.4
1. The chosen scaling of new point estimates to the occurrence table pre-
serves the value of ⌊ψν = 2
d∈d∗⌊d|ψV that determines uncertainty of the
inspected Dirichlet pdf.
2. Random generating of statistics can be used as a part of various compound
algorithms constructing the prior pdf.
3. The optional value ρ is a tuning knob of generators. Its recommended
range stems from standard properties of the normal pdf used instead of
the correct Dirichlet pdf. At present, values of ρ in a more narrow range
ρ∗≡(1, 2) seem to be preferable.
10.4.6 Prior-posterior branching
The prior-posterior branching (see Section 6.4.6) starts at some prior pdf,
performs an approximate estimation, usually quasi-Bayes estimation (see Al-
gorithm 6.13), and ﬂattens the resulting posterior pdf so that it provides a
new alternative to the prior pdf used. The specialization of the general re-
sults on ﬂattening gives directly the following iterative Bayesian learning of
Markov-chain mixtures.

394
10 Learning with Markov-chain factors and components
Algorithm 10.3 (Prior-posterior branching with geometric mean)
Initial mode
•
Select the upper bound ˚n on the number of iterations n and set n = 1.
•
Select a suﬃciently rich structure of the mixture, i.e., specify the number
of components ˚c and the ordered lists of factors allocated to considered
components. The factor structure for each ic is determined by the structure
of the corresponding data vector Ψic.
•
Select a ﬂat pre-prior pdf ¯f(Θ) in the form (6.3) with Dirichlet pdfs de-
scribing individual factors. It means, select pre-prior statistics ¯Vic, ¯κc de-
termining Dirichlet pdfs on the transition probabilities ⌊d|ψΘ and on com-
ponent weights α with a high variance; cf. Proposition 10.1. Typically,
¯Vic = ε (entrywise) and ¯κc = ε > 0, ε small. They serve as alternatives in
ﬂattening.
•
Select a prior pdf f(Θ) in the form (6.3) with Dirichlet pdfs describing
individual factors. It means, select prior statistics Vic, κc determining the
involved Dirichlet pdfs; cf. Proposition 10.1. Generally, ¯f(Θ) ̸= f(Θ).
•
Set ˆf1n(Θ) ≡f(Θ), i.e., set Vic1n;0 = Vic, κc1n;0 = κc giving ˆf1n(Θic) =
/
Ψ∈Ψ ∗Di ⌊d|ψΘic
 ⌊d|ψVic1n;0

and ˆf1n(α) = Diα(κ1n;0).
•
Compute the posterior pdf
˜f1n(Θ|d(˚t)) = Diα(κ1n;˚t)
 
i∈i∗,Ψ∈Ψ ∗
Di ⌊d|ψΘic

⌊d|ψVic1n;˚t

using an approximate Bayesian estimation that starts at ˆf1n(Θ); see Sec-
tion 10.5.
•
Evaluate v-likelihood l1n resulting from the use of ˆf1n(Θ).
•
Apply ﬂattening operation to ˜f1n(Θ|d(˚t)) according to Proposition 6.7. Call
the resulting pdf ˆf2n(Θ). For the component weights α, the ﬂattening rate
is
ΛD ≡
2
c∈c∗(κc −¯κc)
2
˜c∈c∗(κ˜c1n;˚t −¯κ˜c).
For Dirichlet estimates of Markov-chain factors, the ﬂattening is deter-
mined by
Λic|ψ ≡
2
d∈d∗
 ⌊d|ψVic −⌊d|ψ¯Vic

2
˜d∈d∗

⌊˜d|ψVic1n;˚t −⌊˜d|ψ¯Vic
.
It provides a new guess of the prior pdf of the form (6.3) given by
κc2n;0 = ΛDκc1n;˚t + (1 −ΛD)¯κc
⌊d|ψVic2n;0 = Λic|ψ
⌊d|ψVic1n;˚t + (1 −Λic|ψ) ⌊d|ψ¯Vic.
•
Compute the posterior pdf
˜f2n(Θ|d(˚t)) = Diα(κ2n;˚t)
 
i∈i∗,c∈c∗,d∈d∗,ψ∈ψ∗
Di ⌊d|ψΘic

⌊d|ψVicn;˚t


10.4 Construction of the prior estimate
395
using an approximate Bayesian estimation that starts at ˆf2n(Θ); see Sec-
tion 10.5.
•
Evaluate v-likelihood l2n resulting from the use of ˆf2n(Θ).
•
Set ¯ln = max(l1n, l2n).
Iterative mode
1. Apply the geometric branching to the pair ˜f1n(Θ|d(˚t)), ˜f2n(Θ|d(˚t)) with
v-likelihood l1n, l2n, respectively. For λ ≡
l1n
l1n+l2n , it gives ˜f3n(Θ|d(˚t)) of
the form (6.3) with Dirichlet descriptions of factors. It is determined by
the statistics
κc3n;˚t = λκc1n;˚t + (1 −λ)κc2n;˚t, Vic3n;˚t = λVic1n;˚t + (1 −λ)Vic2n;˚t.
2. Apply the ﬂattening operation to ˜f3n(Θ|d(˚t)) according to Proposition 6.7.
Call the resulting pdf ˆf3n(Θ). It preserves the form (6.3). The ﬂattening
rates are
ΛD ≡
2
c∈c∗(κc3n −¯κc)
2
˜c∈c∗(κ˜c3n;˚t −¯κ˜c),
Λic|ψ ≡
2
d∈d∗
 ⌊d|ψVic3n −⌊d|ψ¯Vic

2
˜d∈d∗

⌊˜d|ψVic3n;˚t −⌊˜d|ψ¯Vic
.
They provide the new statistics
κc3n;0 = ΛDκc3n;˚t + (1 −ΛD)¯κc
⌊d|ψVic3n;0 = Λic|ψ
⌊d|ψVic3n;˚t + (1 −Λic|ψ) ⌊d|ψ¯Vic.
3. Evaluate v-likelihood l3n resulting from the use of ˆf3n(Θ) for determining
of ˜f3n(Θ|d(˚t)). The approximation prepared for the ﬁxed advisory system
has to be used; see Section 6.1.2.
4. Choose among the triple ˜fin(Θ|d(˚t)), i ∈{1, 2, 3}, the pair with the highest
v-likelihood values and call these pdfs ˜f1(n+1)(Θ|d(˚t)), ˜f2(n+1)(Θ|d(˚t)) with
v-likelihood l1(n+1), l2(n+1).
5. Go to the beginning of Iterative mode with n = n + 1 if
¯ln+1 ≡max(l1(n+1), l2(n+1)) > ¯ln
or if ¯ln+1, ¯ln are the same according to Proposition 6.2 and n < ˚n.
6. Stop and select among ˆfin(Θ), i = 1, 2 that leading to the higher value of
lin and take it as the prior pdf constructed.
Remark(s) 10.5
1. The structure of the estimated mixture does not change during iterations.
Thus, it has to be suﬃciently reﬂected in the prior pdf f(Θ).
2. Prediction of the v-likelihood of connected with the prior pdf obtained ﬂat-
tened geometric mean is possible; see Section 10.6.3.

396
10 Learning with Markov-chain factors and components
10.4.7 Branching by forgetting
Branching by forgetting (see Section 6.4.7) makes parallel recursive estimation
without forgetting and with a ﬁxed forgetting with forgetting factor smaller
than one. The alternative pdfs are compared according to their v-likelihood
values. At the time moment, when one of them is a sure winner they are
bounded into a single pdf and whole process is repeated. Here, the algorithm
is specialized to Markov-chain mixtures.
Algorithm 10.4 (Online branching with forgetting)
Initial mode
•
Select a suﬃciently rich structure of the mixture, i.e., specify the number
of components ˚c and the ordered lists of factors allocated to the considered
components. The factor structure for each ic is determined by the structure
of the corresponding data vector Ψic.
•
Select a constant ρ ≈3 −5 deﬁning the signiﬁcant diﬀerence of v-log-
likelihood values.
•
Set the record counter t = 0 and select the statistics Vic;0 determining the
prior pdf
ˆf(Θic) =
 
Ψ∈Ψ ∗
Di ⌊d|ψΘic

⌊d|ψVic;0

, i ∈i∗, c ∈c∗, Ψ = [d, ψ′]′,
for factors as well as for the component weights ˆf(α) = Diα(κ0).
•
Choose a ﬁxed relatively small forgetting factor λ < 1.
•
Select a ﬁxed pre-prior alternative pdf used in the stabilized forgetting; see
Proposition 3.1. The alternative is usually taken as a ﬂat pre-prior pdf of
the Dirichlet version of (6.3) given by small
⌊Aκ =
⌊Ad|ψVic = ε > 0, ε
small.
•
Set ˆf1(Θ|d(t)) = ˆfλ(Θ|d(t)) = ˆf(Θ|d(t)).
•
Initialize v-log-likelihood l1;t = 0, lλ;t = 0 assigned to the respective forget-
ting alternatives.
Data processing mode, running for t = 1, 2, . . .,
1. Collect new data dt and construct the data vector Ψt.
2. Update ˆf1(Θ|d(t−1)) to ˆf1(Θ|d(t)) using approximate estimation, Section
10.5, with the forgetting factor 1.
3. Re-compute the v-log-likelihood l1;t−1 to l1;t by adding the logarithm of
the mixture prediction ln(f(d(t)|d(t −1))) obtained for the “prior” pdf
ˆf1(Θ|d(t −1)).
4. Update ˆfλ(Θ|d(t −1)) to ˆfλ(Θ|d(t)) using approximate estimation with
the forgetting factor λ and the chosen alternative. Thus, after obtaining
statistics κλ1;t, Vicλ1;t through updating of κλ;t−1, Vicλ;t−1, with forgetting
1, forget κλ;t = λκλ1;t + (1 −λ) ⌊Aκ,
Vicλ;t = λVicλ1;t + (1 −λ) ⌊AVic.

10.4 Construction of the prior estimate
397
5. Recompute the v-log-likelihood lλ;t−1 to lλ;t by adding the logarithm of
the mixture prediction ln(f(d(t)|d(t −1))) obtained for the “prior” pdf
ˆfλ(Θ|d(t −1)).
6. Go to Step 1 with t = t + 1 if |l1;t −lλ;t−1| < ρ.
7. Set
ˆf(Θ|d(t)) =
ˆf1(Θ|d(t)) if l1;t > lλ;t otherwise set
ˆf(Θ|d(t)) =
ˆfλ(Θ|d(t)).
This setting means assignment of the appropriate suﬃcient statistics.
8. Go to the beginning of Data processing mode if t ≤˚t. Otherwise stop and
take ˆf1(Θ|d(˚t)) as the ﬁnal estimate.
Remark(s) 10.6
1. Speeding up of the learning is the main expectation connected with this
algorithm. The model with no forgetting is expected to be long-run winner.
The estimation with forgetting is to be switched oﬀwhen the estimation
without forgetting is better the majority of the time.
2. The technique can be directly combined with the prior-posterior branching.
3. It will be necessary to get experience with the choice of the ﬁxed forgetting
factor λ in the case of Markov chains. The option λ ≈0.6 seems to be
satisfactory for normal mixtures. A similar value represents a reasonable
start for a closer inspection in the Markov-chain case.
10.4.8 Branching by factor splitting
This section specializes the algorithm described in Section 6.4.8. It covers im-
portant cases when we have no clue about the structure of the mixture. The
algorithm simply splits factors suspicious for hiding more modes and makes
a new learning attempt. Selection of the structure of the mixture and its
constituents is harder than in the case of normal mixtures as the most parsi-
monious structure is not unique. However, it causes no harm: the predictive
properties are decisive in the advising mode.
New factors should remain in the class of Dirichlet pdfs. The ﬂattened and
sharpened factors found according to Proposition 6.14 have this property.
Proposition 10.10 (Flattened/sharpened Markov-chain factors)
Let us consider pdfs f = DiΘ(V ), ¯f = DiΘ
 ¯V

. The pdf minimizing the KL
divergence D

ˆf
!!!
!!! f

, and having the KL divergence
D

ˆf
!!!
!!! ¯f

= ωD

f
!!!! ¯f

, ω ̸= 1 has the form
(10.22)
ˆf = DiΘ(λV + (1 −λ) ¯V )
with the scalar λ chosen so that condition (10.22) is met.
Proof. Proposition 6.14 implies the form of ˆf and condition (10.22) determines
the values of λ.

398
10 Learning with Markov-chain factors and components
Problem 10.4 (Shifted Di factor) The explicit shift in expected value of
some function g(Θ) of parameters Θ is intuitively preferable. The choice
g(Θ) = [ln(Θ1), . . . , ln(Θ˚
d)]′ guarantees that the factor found according to
Proposition 6.15 stays within the desirable Dirichlet class. The statistics of
the resulting pdf solve complex algebraic equations resulting from necessary
conditions of the extreme. This is not elaborated further but is worth consid-
ering.
10.4.9 Hierarchical selection of split factors
The hierarchical splitting described here relies on our ability to estimate three
factors instead of a single one.
During approximate estimation, Section 10.5, the ith factor within the
cth component is assigned a weight wic;t ∈[0, 1] that expresses the expecta-
tion that the data item dic;t is generated by this factor. Then, the modiﬁed
parameterized factor
fw(dic;t|d(i+1)···˚
d;t, d(t −1)) ≡fw(dic;t|ψic;t, Θic) ∝[f(dic;t|ψic;t, Θic)]wic;t
is used in the “ordinary” Bayes rule when updating the parameter estimates
of this factor. Thus, for estimation purposes, we can inspect this factor inde-
pendently of others and drop (temporarily) the subscripts w, c.
We want to check whether the discussed factor explains data that should
be modelled by more factors while assuming that Requirement 6.2 is met, i.e.,
the split factor is conditioned by a regression vector that includes the true
one. We formulate hypothesis H0, that the objective pdf has two components
⌊of(dt|ψt) = β ⌊dt|ψtΘ1 + (1 −β) ⌊dt|ψtΘ2, β ∈(0, 1),
(10.23)
where Θ1, Θ2 have structures diﬀering from that of Θ in the split factor as
they contain more zero entries.
The alternative hypothesis H1 assumes that
⌊of(dt|ψt) =
⌊dt|ψtΘ, i.e.,
denies the need for splitting.
We estimate parameters of the mixture (6.63) together with the factor
in question in order to decide on the need to split. With f(H0) = f(H1),
modelling no prejudice, the Bayes rule gives
Probability

split is needed|d(˚t)

≡f(H0|d(˚t)) =
f(d(˚t)|H0)
f(d(˚t)|H0) + f(d(˚t)|H1).
(10.24)
The v-likelihood values f(d(˚t)|H0), f(d(˚t)|H1) are obtained as a byproduct of
the approximate estimation; see Section 10.5.
The factor is split if the probability (10.24) is high enough. The estimated
factors of the mixture (10.23) are natural candidates for its replacement. We
have to deﬁne initial estimates of the “small mixture” (10.23). Its components

10.4 Construction of the prior estimate
399
should be dissimilar and their mixture should be close to the mixture split.
We shall reach this property by splitting (possibly in a random way)
Ψ ∗= Ψ ∗
1 ∪Ψ ∗
2 , Ψ ∗
1 ∩Ψ ∗
2 = ∅
(10.25)
so that cardinalities of both sets are approximately equal. For the given occur-
rence matrix ⌊d|ψV0 deﬁning the prior pdf on the considered factor, we specify
initial occurrence matrices, ∀ψ ∈ψ∗and ε ∈

0, mind∈d∗,ψ∈ψ∗⌊d|ψV0

,
⌊d|ψV1;0 =
 ⌊d|ψV0 −ε, ∀Ψ ∈Ψ ∗
1
ε,
∀Ψ ∈Ψ ∗
2
,
⌊d|ψV2;0 =
 ⌊d|ψV0 −ε, ∀Ψ ∈Ψ ∗
2
ε,
∀d ∈Ψ ∗
1
.
(10.26)
We also set the initial statistics κ1;0 = κ2;0 = κ0, where κ0 is the initial
statistics determining estimates of component weights α. With these options,
we can describe the Markov-chain version of Algorithm 6.10
Algorithm 10.5 (Hierarchical split of Markov-chain factors)
Initial mode
•
Construct the initial estimate of the mixture parameters; see Algorithm
6.8,
f(Θ) ∝Diα(κ0)
 
c∈c∗
˚
d
 
d=1
 
ψ∈ψ∗
	
⌊d|ψΘ
 ⌊d|ψV0−1
.
•
Select signiﬁcance level ¯P ∈(0, 1), ¯P ≈1 controlling the need to split.
•
Select ε ∈

0, mind∈d∗,ψ∈ψ∗⌊d|ψV0

.
•
Deﬁne sets Ψ ∗
1 , Ψ ∗
2 according to (10.25).
•
Assign to each factor i = 1, . . . , ˚
d, c ∈c∗, a prior pdf
f(βic) = Diβic (0.5κc;0 [1, 1]) ,
and, for j = 1, 2, cf. (10.26),
f(Θjic|d(0)) =
 
ψ∈ψ∗
Di{ ⌊d|ψΘjic}d∈d∗

⌊d|ψVjic;0, d ∈d∗
on parameters of the “small” mixture (10.23). Indices ic stress “member-
ship” of this mixture with the factor ic.
•
Initialize likelihood lic;0|H0, lic;0|H1, i ∈i∗, c ∈c∗.
Sequential mode, running for t = 1, 2, . . .,
1. Acquire data dt and complement data vectors Ψi;t = [di;t, ψ′
it]′.
2. Perform a single step of an approximate estimation, i.e., update
f(Θ|d(t −1)) →f(Θ|d(t)),
Section 10.5. It generates weights wic;t measuring the degree with which
data are assigned to respective factors.

400
10 Learning with Markov-chain factors and components
Update at the same time respective values of the v-likelihood lic;t|H1 ≡
f(dic;t|ψic;t, d(t−1))lic;t−1|H1. Here, d(t−1) in condition stresses that the
predictors for all possible discrete values dic;t|ψic;t are computed using the
observed data d(t −1).
3. Weight new data by respective wic;t and update estimates of parameters of
“small” mixtures (10.23)
f(βic, Θ1ic, Θ2ic|d(t −1)) →f(βic, Θ1ic, Θ2ic|d(t)).
Update also values of the v-likelihood lic;t|H0 = f(dic;t|ψic;t, d(t−1))lic;t−1|H0
using predictors f(dic;t|ψic;t, d(t −1)) constructed from the estimated two-
component mixtures.
4. Go to the beginning of Sequential mode while t ≤˚t.
Selection mode
1. For i = 1, . . . , ˚
d, c ∈c∗.
2. Compare Pic ≡
lic;˚
t|H0
lic;˚
t|H0+lic;˚
t|H1 with ¯P.
3. Split f(Θic|d(˚t)) →

f(Θ1ic|d(˚t)), f(Θ2ic|d(˚t))

if Pic ≥¯P.
10.4.10 Techniques applicable to static mixtures
The speciﬁc Markov-chain form of the considered model brings nothing spe-
ciﬁc to this counterpart of Chapter 6. The validity of the assumptions of
Proposition 6.17 is worth mentioning only.
10.5 Approximate parameter estimation
10.5.1 Quasi-Bayes estimation
A direct application of Algorithm 6.13 gives the specialized algorithm.
Algorithm 10.6 (Quasi-Bayes algorithm with common factors)
Initial (oﬄine) mode
1. Select statistics Vic;0 determining prior distributions of the individual fac-
tors DiΘic(Vic;0).
2. Select initial values κc;0 > 0 determining Dirichlet distribution Diα(κ0)
of weights α, say, 2
c∈c∗κc;0 ≈10% of the length ˚t of the processed data.
3. Select forgetting factor λ and alternative statistics ⌊AV needed for stabi-
lized forgetting; see (10.8).
Sequential (online) mode, running for t = 1, 2, . . .,
1. Acquire the data record dt.

10.5 Approximate parameter estimation
401
2. Evaluate values of the predictive pdfs (2.47) for respective factors
f(dic;t|ψic;t, d(t −1), c) =
I(d(t)|ic)
I(d(t −1)|ic) =
⌊dic;t|ψic;tVt−1
2˚
di
˜dic=1
⌊˜dic|ψic;tVt−1
.
3. Compute the values of predictive pdfs for respective components
f(dt|d(t −1), c) =
 
i∈i∗
f(dic;t|ψic;t, d(t −1), c), c ∈c∗.
4. Compute the probabilities wc;t, using the formula (6.86)
wc;t ≡f(ct = c|d(t)) =
κc;t−1
2
¯c∈c∗κ¯c;t−1 f(dt|d(t −1), c)
2
˜c∈c∗
κ˜c;t−1
2
¯c∈c∗κ¯c;t−1 f(dt|d(t −1), ˜c)
=
κc;t−1f(dt|d(t −1), c)
κ˜c;t−1
2
˜c∈c∗f(dt|d(t −1), ˜c).
5. Update scalars κc;t = κc;t−1 + wc;t; cf. (6.88).
6. Update Bayesian parameter estimates of diﬀerent factors, i.e., update the
corresponding statistics
⌊d|ψVic;t−1 →
⌊dψVic;t equivalent to the weighted
version of (10.8)
⌊d|ψVic;t = λ

⌊d|ψVic;t−1 + wic;tδΨic;t,Ψ

+ (1 −λ) ⌊Ad|ψVic
wic;t =

˜c∈c∗
i
w˜c;t.
(10.27)
The set c∗
i consists of pointers to components that contain the ith factor.
7. Evaluate, if need be, characteristics of the Bayesian estimate of the com-
ponent weights and factor parameters.
8. Go to the beginning of Sequential mode while data are available.
10.5.2 EM estimation
A direct application of EM Algorithm 6.15 to Markov-chain factors gives the
adequate specialization.
Algorithm 10.7 (EM mixture estimation with common factors)
Initial mode
•
Select the upper bound ˚n on the number n of iterations and set n = 0.
•
Select point estimates ˆΘicn ≡
	
⌊d|ψ ˆΘicn

of parameters
 ⌊d|ψΘic

≡proba-
bilities of dic = d when conditioned by the regression vector ψic = ψ within
the cth component.
•
Select point estimates ˆαcn = 1/˚c of components weights αc.

402
10 Learning with Markov-chain factors and components
Iterative mode
1. Fill the occurrence matrices Vic;0 = ε (entrywise) and the statistic κc;0 =
ε, where ε > 0, ε ≈0.
Sequential mode, running for t = 1, 2, . . .,
a) Acquire data record dt and construct the data vectors Ψic;t.
b) Compute values of the predictive pdfs
f

dic;t|ψic;t, ˆΘicn, c

≡⌊dic;t|ψic;t ˆΘicn
for each individual factor i ∈i∗=

1, . . . , ˚
d

in all components c ∈c∗
using the parameter estimates ˆΘicn that are constant during time cycle
of the sequential mode.
c) Compute the values of the predictive pdfs
f(dt|φc;t−1, ˆΘcn, c) ≡
 
i∈i∗
⌊dic;t|ψic;t ˆΘicn
for each individual component c ∈c∗.
d) Compute the probabilities wc;t approximating δc,ct
wc;t =
f

dt|φc;t−1, ˆΘcn, c

ˆαcn
2
˜c∈c∗f(dt|φ˜c;t−1, ˆΘ˜cn, ˜c)ˆα˜cn
.
e) Update the statistics κc;t = κc;t−1 + wc;t, c ∈c∗.
f) Update the statistics determining log-likelihood values describing dif-
ferent factors
⌊d|ψVic;t = ⌊d|ψVic;t−1 + wic;tδΨic;t,Ψ, where
wic;t =

˜c∈c∗
i
w˜c;t.
(10.28)
The set c∗
i ≡consists of pointers to components that contain the ith
factor.
g) Go to the beginning of Sequential mode if t ≤˚t. Otherwise continue.
2. Find the new point estimates
⌊di|ψ ˆΘic(n+1) =
⌊di|ψVic;˚t
2
di∈d∗
i
⌊di|ψVic;˚t
and
ˆαc(n+1) =
κc;˚t
2
˜c∈c∗κ˜c;˚t
.
These values maximize the nth approximate likelihood.
3. Stop if the attained likelihood values

c∈c∗
κc;˚t
⎡
⎣ln(ˆαc(n+1)) +

i∈i∗,Ψ∈Ψ ∗
⌊d|ψVic;˚t ln

⌊d|ψ ˆΘic(n+1)

⎤
⎦
(10.29)
do not increase further. Otherwise set n = n + 1 and go to the beginning
of Iterative mode.

10.5 Approximate parameter estimation
403
10.5.3 Batch quasi-Bayes estimation
Here, Algorithm 6.16 is specialized to Markov chains. In this way, processing-
order-independent, batch quasi-Bayes estimation of Markov chains is gained.
Algorithm 10.8 (BQB estimation with common factors)
Initial mode
•
Select the upper bound ˚n on the number n of iterations and set n = 0.
•
Select the statistics ¯Vic, ¯κc determining the alternative pdf used in ﬂat-
tening operation.
•
Select the statistics Vic determining prior pdfs of individual Markov-chain
factors DiΘic(Vic).
•
Select initial values κc > 0 describing estimates of component weights.
Iterative mode
1. Make copies Vic;0 = Vic and κc;0 = κc and set v-log-likelihood l0 of the
mixture to zero.
Sequential mode, running for t = 1, 2, . . .,
a) Acquire the data record dt and construct the data vectors Ψic;t.
b) Compute values of the predictive pdfs
f(dic;t|ψic;t, c) =

f(dic;t|ψic;t, Θic, c)f(Θic|V, κ) dΘic
=
⌊dic;t|ψic;tVic
2
˜d∈˜d∗
ic
⌊˜d|ψic;tVic
.
for each individual factor i ∈i∗= {1, . . . , ˚
d} in all components c ∈c∗
using the statistics V that are constant during the time cycle.
c) Compute the values of predictive pdfs
f(dt|φc;t−1, c) ≡
 
i∈i∗
fn(dic;t|ψic;t, c)
for each individual component c ∈c∗.
d) Compute the probabilities wc;t approximating δc,ct
wc;t ∝f(dt|φc;t−1, c)κc
using statistics κc that are constant during the time cycle.
e) Update statistics determining posterior pdfs evolving from copies of
prior statistics Vic;0 and κc;0.
⌊d|ψVic;t = ⌊d|ψVic;t−1 + wic;tδΨic;t,Ψic
(10.30)
κc;t = κc;t−1 + wc;t, where
wic;t =

˜c∈c∗
i
w˜c;t.
The set c∗
i consists of pointers to components that contain ith factor.

404
10 Learning with Markov-chain factors and components
f) Update the v-log-likelihood of the mixture
lt = lt−1 + ln

c∈c∗
κc;t
2
˜c∈c∗κ˜c;t
f(dt|ψc;t, c)

.
g) Go to the beginning of Sequential mode if t ≤˚t. Otherwise continue.
2. Stop if the v-likelihood l˚t of the mixture does not increase among iterations.
Otherwise apply ﬂattening operation to f(Θic|d(˚t)) and Diα(κc;˚t)
Vic = ΛnVic|˚t + (1 −Λn) ¯Vic, κic = Λnκic;˚t + Λn¯κc, Λn →0.5.
3. Increase the counter to n = n + 1.
4. Stop if n > ˚n; otherwise go to the beginning of Iterative mode.
10.6 Structure estimation
10.6.1 Estimation of factor structure
Estimation of a factor structure can be and will be based on Bayesian struc-
ture estimation using the fact that the Markov chain belongs to the nested
exponential family. The technique is applicable to a Markov chain with a
low-dimensional regression vector ψr corresponding to the richest structure.
Proposition 10.11 (Structure estimation of nested Markov chains)
Let us consider Markov chain f(d|ψr, Θr) = ⌊d|ψrΘr with the richest regres-
sion vector ψr and another model f(d|ψs, Θ) =
⌊d|ψsΘ describing the same
data d(˚t).
Let ψs = Nψr, where N is time invariant matrix selecting entries of ψs
from ψr. Let us consider Dirichlet pdfs /
ψS∈ψ∗
S Di ⌊·|ψS ,SΘ
 ⌊·|ψS,SV0

as con-
jugate prior pdfs for both models S ∈{s, r}.
Let the initial V -statistics be related by the nesting mapping
⌊d|ψs,sVt =

ψr∈{ψs=Nψr}
⌊d|ψr,rVt,
for t = 0.
(10.31)
Then, the same property holds for all t ∈t∗if we use Bayes estimation or
quasi-Bayes estimation with common data weights for both models.
The v-likelihood for the regression vector having structure S ∈{s, r} is
f(d(˚t)|S) =
 
ψS∈ψ∗
S
B( ⌊·|ψS,SV˚t)
B( ⌊·|ψS,SV0).
(10.32)
The multivariate beta function

10.6 Structure estimation
405
B(v) =
/˚v
i=1 Γ(vi)
Γ

2˚v
i=1 vi

is well deﬁned for vectors v with positive entries vi for which Euler gamma
function Γ is deﬁned.
Let f(s) and f(r) be prior probabilities of s, r. Then,
f(s|d(˚t)) =

1 + f(d(˚t)|r)f(r)
f(d(˚t)|s)f(s)
−1
.
(10.33)
Proof. It is a specialized version of Proposition 3.3 and extended by the use
of the Bayes rule on competitive structures S ∈{s, r}.
The following algorithm uses this proposition for computing posterior
probabilities of all nested structures within a given richest one.
Algorithm 10.9 (Estimate of Markov-chain factor structure)
Initial mode
•
Select the structure of a richest regression vector.
•
Specify the ﬂat prior statistics ⌊d|ψr,rV0 > 0, ⌊d|ψr,rV0 ≈0.
•
Collect the posterior statistics ⌊d|ψr,rV˚t using Bayes, batch quasi-Bayes or
quasi-Bayes estimation.
•
Specify prior probabilities f(s) of competitive structures, typically a uni-
form one on a priori possible structures.
•
Deﬁne the initial values of v-log-likelihood of competitive a priori possible
structures ls = ln(f(s)).
Structure estimation
1. Do for all ψr ∈ψ∗
r.
a) Select the structure s determining ψs nested in ψr and having
f(s) > 0; ψr has to be included among selections made.
b) Evaluate for d ∈d∗and t ∈{0,˚t}
⌊d|ψsVs;t =

ψr∈{ψs=Nψr}
⌊d|ψr,rVt.
c) Compute increments of the v-log-likelihood
lψs =

d∈d∗
ln
0
Γ
 ⌊d|ψs,sV˚t

Γ
 ⌊d|ψs,sV0

1
−ln
⎡
⎣
Γ

2
˜d∈d∗⌊˜d|ψs,sV˚t

Γ

2
˜d∈d∗⌊˜d|ψs,sV0

⎤
⎦.
d) Update v-log-likelihood ls = ls + lψs.
2. Shift the v-log-likelihood ls = ls −max{s:f(s)>0} ls
3. Compute posterior probabilities of individual structures f(s|d(˚t)) ∝exp(ls).
4. Select an estimate of a structure, typically, the MAP estimate.

406
10 Learning with Markov-chain factors and components
Remark(s) 10.7
1. The prior probabilities are an eﬃcient tool for reducing the space in which
the best structure is searched for. For instance, it can reﬂect additional in-
formation that arises from smoothness of the originally continuous-valued
regression vector; cf. [170].
2. Flat prior pdf is chosen in order to violate the assumption on nested prior
pdfs only slightly. This condition can be met by a more careful choice
of V0. Generally, this problem should be studied but negligible practical
consequences are expected.
3. The assumption that updating of various structures is performed with a
common weight is the most serious approximation we use. It is enforced
by the wish to reduce the need for updating of statistics for all structures
that can be generated from ψr.
4. The initial and terminal values of statistics are suﬃcient for structure
estimation when no forgetting is used. Otherwise, the overall predictor is
a product of one-stage-ahead predictors that do not cancel in the product.
This simple observation is often overlooked.
Problem 10.5 (Connection with Bayesian networks) Prior information
resulting from the underlying dependence knowledge as studied in Bayesian-
networks techniques can be used here [168, 169]. Its use is, however, infre-
quent for the assumed applications in which a detailed inspection is a priori
prevented by the problem complexity. It may be important in speciﬁc cases.
10.6.2 Estimation of component structure
Similar to the normal case, this task is still unsolved in an eﬃcient algorithmic
way. Bayesian-networks technology [168, 169] seems to be the proper direction
to be inspected. In the mixed discrete-continuous case of the primary interest,
the simple rule “place the Markov factors at the tail of the component” seems
to be suﬃcient.
10.6.3 Merging and cancelling of components
Initiation by factor splitting is almost always employed for determining the
number of components. The resulting, usually excessive, number of compo-
nents has to be reduced. Thus, algorithms reducing the number of components
form an important part of mixture estimation. A reduced and tailored set of
general algorithms given in Section 6.6.4 is described here. General discus-
sion is skipped and algorithms predicting the values of the v-log-likelihood
are considered only. Factor-based merging of components and cancelling of
components are described.
The formula (6.115) predicts v-likelihood after merging. Algorithm 6.24
uses it for a systematic merging of factors. It is specialized here.

10.6 Structure estimation
407
Algorithm 10.10 (Systematic merging of Markov-chain factors)
Initial mode
•
Estimate a mixture with Markov-chain factors and conjugate Dirichlet
prior pdf. The estimate is described by the collection of occurrence ma-
trices
{Vic;t}c∈c∗,i=1,...,˚
d,t∈{0,˚t} .
The factors with the common i are supposed to describe the same entry of
di;t irrespective of the component number.
•
Initialize the list with rows ρ = (i, c, ˜c) ≡ith factor is common for compo-
nents c, ˜c. Usually, ρ is initialized as the empty one.
•
Evaluate the individual normalization factors (see Proposition 10.1)
ln(I(Vic;t)), ∀c ∈c∗, i = 1, . . . , ˚
d, t ∈{0,˚t}.
Evaluation mode
For
i = 1, . . . , ˚
d
Set pointers c = 1, ˜c = 2 to trial components to be merged.
Test of the common structure
Set the indicator of the common structure cs = 0.
Set cs = −1 if the structures of Θic and Θi˜c diﬀer.
Do if cs = 0
Create the trial merger
˜Vi;˚t = Vic;˚t + Vi˜c;˚t, ˜Vi;0 = Vic;0 + Vi˜c;0.
Evaluate increment ˜l of the log-v-likelihood
˜l = +

ln(I( ˜Vi;˚t)) −ln(I(Vic;˚t)) −ln(I(Vi˜c;˚t))

−

ln(I( ˜Vi;0)) −ln(I(Vic;0)) −ln(I(Vi˜c;0))

end of the test on cs = 0
Do if ˜l ≤0 or cs < 0
Set ˜c = ˜c + 1.
Go to the Test of the common structure if ˜c ≤˚c.
Otherwise continue.
Set c = c + 1 and ˜c = c + 1.
Go to the beginning of Test of the common structure if c < ˚c.
Otherwise go to the end of cycle over i.
else replace prior and posterior estimates of factors with indexes
ic and i˜c by the trial merger.
Extend the list of common factors by ρ = [ρ; (i, c, ˜c)].

408
10 Learning with Markov-chain factors and components
end of the test on improvement of v-likelihood and of cs < 0
end
of the cycle over i
Merging of components
For
c = 1, . . . ,˚c −1
For
˜c = c + 1, . . . ,˚c
Set κ˜c;˚t = κ˜c;˚t + κc;˚t,
κ˜c;0 = κ˜c;0 + κc;0 and cancel the component c
if the components consist of common factors only.
end
of the cycle over ˜c
end
of the cycle over c
Component cancelling
Cancelling of spurious components is also based on predicting induced change
of the v-likelihood. The general approach of Chapters 6 and 8 is just specialized
here. Selection of parameter values for which f(dt|d(t −1), Θc, c) = g(d(t))
makes this case speciﬁc. Obviously, it is suﬃcient to take ⌊d|ψΘ = 1
˚
d.
Algorithm 10.11 (Systematic cancelling of Markov components)
Initial mode
•
Estimate a Markov-chain mixture described by the collection of occurrence
matrices
{Vic;t}c∈c∗,i=1,...,˚
d,t∈{0,˚t} .
The factors with the common i are supposed to describe the same entry of
di;t irrespective of the component number.
•
Evaluate the individual normalization factors ln(I(Vic;t)), ∀c ∈c∗, i =
1, . . . , ˚
d, t ∈{0,˚t}; see Proposition 10.1.
•
Set c = 1 and K = ln(˚
d).
Evaluation mode
Do while c ≤˚c and ˚c > 1
Set l = 0.
For
i = 1, . . . , ˚
d
l = l −(Vic:˚t −Vic;0)K + ln (I(Vic;0)) −ln

I(Vic;˚t)

.
end
of the cycle over i
If l > 0
Swap c with ˚c and set ˚c = ˚c −1, i.e., cancel the component
Stop if ˚c = 1
else

10.7 Model validation with Markov-chain components
409
Set c = c + 1
end of the test on v-log-likelihood increase
10.7 Model validation with Markov-chain components
This part applies the general model validation given in Section 6.7 to Markov-
chain components. The presentation is appropriately reduced.
10.7.1 Test of data homogeneity
This part is a reduced counterpart of Section 6.7.1. We deal with the situa-
tion when quality of observed behavior is classiﬁed ex post and the following
hypotheses are formulated:
H0 ≡The diﬀerence in observed consequences is due to the inseparable in-
ﬂuence of external conditions and management. Under this hypothesis, a
single mixture describes the standard d(˚ts) as well as the labelled d(˚te)
data, i.e., for d(˚t) ≡(d(˚ts), d(˚te))
f(d(˚t)|H0) =

f(d(˚t)|Θ, H0)f(Θ|H0) dΘ.
(10.34)
H1 ≡The diﬀerence in observed consequences is caused by diﬀerences in man-
agement. Diﬀerent mixtures should be used for the standard d(˚ts) and the
labelled d(˚te) data, i.e., for d(˚t) ≡(d(˚ts), d(˚te))
f(d(˚t)|H1) =

f(d(˚ts)|Θs, H1)f(Θs|H1) dΘs

f(d(˚te)|Θe, H1)f(Θe|H1) dΘe
(10.35)
with possibly diﬀerent structures of both mixtures.
With these elements and no prejudice, f(H0) = f(H1), the Bayes rule provides
the posterior pdf f(H0|d(˚t)). The common model can be accepted as a good
one if this probability is high enough. The test of these hypotheses is described
by the following algorithm.
Algorithm 10.12 (Test of Markov-chain data homogeneity)
1. Run the complete model estimations on the standard d(˚ts), labelled d(˚te)
and concatenated d(˚t) ≡(d(˚ts), d(˚te)) data. This provides
f(Θ|d(˚tι)) = Diα(κ˚tι)
 
c∈c∗
 
d∈d∗,ψ∈ψ∗
Di ⌊d|ψΘc

⌊d|ψVc;˚tι

, ι ∈ι∗≡{s, e, ∅}.
2. The corresponding v-likelihood values indexed by ι ∈ι∗are obtained as by
product of approximate estimations; see (10.10).

410
10 Learning with Markov-chain factors and components
3. Determine the probability that a single standard model should be used
f(standard|d(˚t)) ≡f(H0|d(˚t)) =
f(d(˚t)|H0)
f(d(˚t)|H0) + f(d(˚ts)|H1)f(d(˚te)|H1).
(10.36)
4. Use the single model further on if f(standard|d(˚t)) is close to 1. The
factors that were active on f(d(˚te)) are potentially dangerous.
5. Use both mixtures independently if f(standard|d(˚t)) is close to 0. The
danger of causing the situation labelled by e should be signaled whenever
the model ﬁtted to d(˚te) makes better predictions than the model ﬁtted to
the standard data.
10.7.2 Learning results and forgetting-based validation
The test on homogeneous data (see Algorithm 10.12) can be directly used for
model validation if we take d(˚ts) as learning data and d(˚tv) as validation data
unused in learning. Of course, the results of the test have to be re-interpreted
appropriately. We expect that the Markov-chain counterpart of Algorithm
8.18 with varying cutting moments and forgetting-based validation, Section
6.7.3, will be mostly used.
10.7.3 Other indicators of model validity
Other techniques mentioned in Chapter 6 such as human inspection of low-
dimensional projections, Section 6.7.4, or checking of operating modes, Section
6.7.5, have to be used for model validation. It cannot be over-stressed that
the list of validation tests is still very much open.
Problem 10.6 (Completion of the Markov-chain suite) In the studied
context, much less experience is available with Markov chains than with nor-
mal mixtures. This chapter indicates clearly that algorithms proposed in Chap-
ter 6 are applicable to the Markov-chain case. It also shows that a lot of aspects
still have to be elaborated in order to get a complete suite of algorithms cov-
ering this important class of models.

11
Design with Markov-chain mixtures
Markov-chain factors allow us to incorporate logical quantities and to work
with mixed real- and discrete- valued data. The description of design aspects
related to mixtures consisting completely of Markov chains forms the content
of the chapter. The mixed case is addressed in this Chapter 13.
Formally, the majority of approximations used in connection with the nor-
mal case are unnecessary in the case of Markov-chain mixtures as we operate
algebraically on ﬁnite-dimensional tables. The design is complex due the di-
mensionality of these tables.
Similarly, as in normal case, Chapter 9, we restrict the presentation to
the case with the state in the phase form; see Agreement 5.4. This ﬁts the
considered applications and decreases the computational load caused by di-
mensionality. The restriction to the phase form allows us to exploit, without
repetitive references, the relevant notation and relationships introduced in
Agreement 9.1.
The chapter starts with a brief summary of common tools, Section 11.1.
Then, academic, industrial and simultaneous designs are described in Section
11.2. The concluding Section 11.3 provides strategies supporting interactions
with an operator.
11.1 Common tools
11.1.1 Model projections in design
Steady-state distribution
Evaluation of the steady-state distribution of the observed data helps us to
recognize good and bad factors and components. The large number of data
available justiﬁes the assumption that the uncertainty of parameters is neg-
ligible after estimation. It implies that we can evaluate the steady-state dis-
tribution of the state vector assuming that parameters Θ are given. For the

412
11 Design with Markov-chain mixtures
adopted phase form, the stationary pf f(φt) ≡f([d′
t, . . . , d′
t−∂+1]′) has to fulﬁll
the identity
f(dt, . . . , dt−∂+1) =

dt−∂
Θdt|φt−1f(dt−1, . . . , dt−∂)
(11.1)
=

dt−∂
˚
d
 
i=1
Θdi;t|ψi;tf(dt−1, . . . , dt−∂).
Note that the indexes of Θ related to data vector are written again right lower
subscript and that the inclusion of unit in φt is superﬂuous in the Markov-
chain case.
The full solution of (11.1) is feasible in low-dimensional cases only. Often,
it is, however, suﬃcient to get some stationary characteristics, typically, mo-
ments. Then, it is reasonable to simulate this Markov chain and to estimate
the steady-state moments from the observed realization. We rely on ergodic
behavior and, ideally, apply an adapted recursive estimation of steady-state
moments with a sequential stopping rule [94].
Problem 11.1 (Analysis of the Markov chain) Classiﬁcation of states of
the classical Markov chain is well elaborated and gives a well-understood pic-
ture of the behavior of such dynamic system; see e.g., [79, 171]. A similar
picture for higher-order Markov chains with the state in the phase form would
be useful. It does not belong to the standard textbook content and should be
collected.
Marginal and conditional distributions
Low-dimensional marginal and conditional pfs provide the main technical tool
for presenting results of the design of the p-system. The algorithmic descrip-
tion of their evaluation is given here for a known (well-estimated) Markov-
chain mixture.
Essentially, Proposition 7.2 is specialized here. The specialization is split
in Proposition 11.2 dealing with marginal pfs and Proposition 11.3 addressing
the conditioning. Both rely on a speciﬁc structure of components, Agreement
5.4. Thus, we need a tool for changing it.
Proposition 11.1 (Permutation of an adjacent pair of factors) Let
us consider a pair of adjacent Markov-chain factors with known parameters
f(∆1, ∆2|ψ1, ψ2) = Θ∆1|∆2,ψ1Θ∆2|ψ2 = ˜Θ∆1|ψ ˜Θ∆2|∆1,ψ,
where
(11.2)
Θ are known transition probabilities,
˜Θ are transition probabilities after permutation,
ψ contains the union of entries in ψ1, ψ2; the entry, which is at least in one
of them, is put on the corresponding position of ψ.

11.1 Common tools
413
Then, the parameters ˜Θ, describing the permuted ∆1, ∆2, are generated by the
following algorithm.
For ψ ∈ψ∗
1 ∪ψ∗
2
(11.3)
For ∆1 ∈∆∗
1
Set ˜Θ∆1|ψ = 0
For
∆2 ∈∆∗
2
Evaluate the joint probability Θ∆1,∆2|ψ ≡Θ∆1|∆2,ψΘ∆2|ψ
Θ∆1|∆2,ψ = Θ∆1|∆2,ψ1 for ψ1 included in ψ and
Θ∆2|ψ = Θ∆2|ψ2 for ψ2 in ψ.
Add ˜Θ∆1|ψ = ˜Θ∆1|ψ + Θ∆1,∆2|ψ.
end of the cycle over ∆2
For
∆2 ∈∆∗
2
Set ˜Θ∆2|∆1,ψ = Θ∆1,∆2|ψ
˜Θ∆1|ψ
end of the cycle over ∆2
end of the cycle over ∆1
end of the cycle over ψ
Proof. The result is implied by the alternative expressions for the joint prob-
ability f(x, y) = f(x|y)f(y) = f(y|x)f(x) and by marginalization.
Any desired change of the component structure can be performed by such
pairwise permutations.
Proposition 11.2 (Marginal predictors for known mixtures) Let us con-
sider the known Markov-chain mixture in the factorized form
f(∆t|uo;t, d(t −1)) =

c∈c∗
αc
 
i∈i∗
Θ∆i;t|ψic;t,c,
where
ψic;t =
	
∆′
(i+1)··· ˚
∆c;t, u′
o;t, φ′
c;t−1
′
≡
	
∆′
(i+1)··· ˚
∆c;t, ψ′
˚
∆c;t
′
are regression vec-
tors, i ∈i∗≡{1, . . . , ˚
∆−1}, c ∈c∗,
ψ′
˚
∆c;t is the common part of regression vectors forming the component c,
∆i;t are entries of innovations ∆t and uo;t are recognizable o-actions,
Θ∆i;t|ψic;t,c = are known transition probabilities of the cth component.
Then, the marginal pf of ∆i··· ˚
∆, i ∈{1, . . . , ˚
∆}, conditioned on the common
part of the regression vector ψ ˚
∆=

u′
o;t, φ′
t−1
′ is obtained by omitting leading
factors in the above product, i.e.,
f(∆i··· ˚
∆;t|uo;t, d(t −1)) =

c∈c∗
αc
˚
∆
 
i=i
Θ∆i;t|ψic;t,c.

414
11 Design with Markov-chain mixtures
Proof. Omitted.
For reference purposes, evaluation of conditional pfs is described.
Proposition 11.3 (Conditional pfs of Markov-chain mixture) Let us
consider the known Markov-chain mixture in the factorized form
f(∆t|uo;t, d(t −1)) =

c∈c∗
αc
 
i∈i∗
Θ∆i;t|ψic;t,c,
where
ψic;t =
	
∆′
(i+1)··· ˚
∆c;t, u′
o;t, φ′
c;t−1
′
≡
	
∆(i+1)c;t, ψ′
(i+1)c;t
′
are regression vec-
tors, i ∈{0, 1, . . . , ˚
∆−1}, with the common part ψ ˚
∆c;t ≡

u′
oc;t, φ′
c;t−1
′,
∆ic;t are entries of innovations ∆c;t, uoc;t are recognizable o-actions and
φc;t−1 are observable states of individual components,
Θ∆i;t|ψi;t,ct are known transition probabilities of the cth component.
For simplicity, let the order of factors for all components be common, i.e.,
∆c;t = ∆t. Let j ∈j∗≡{j, . . . ,˚i}, j ≤˚i point to selected entries of ∆t. Let
k ∈(j,˚i) point to a subset of the selected entries in ∆t. Then, the predictor of
∆j···k−1;t conditioned on uo;t, d(t−1) and ∆k···˚i;t is the ratio of Markov-chain
mixtures
f(∆j···k−1;t|∆k···˚i;t, uo;t, d(t −1)) =
2
c∈c∗αc
/˚i
j=j Θ∆j;t|ψj;t,c
2
˜c∈c∗α˜c
/˚i
˜j=k Θ∆˜j;t|ψ˜j;t,˜c
. (11.4)
For a given regression vector, the resulting predictor can be interpreted as the
Markov-chain mixture
f(∆j···k−1;t|∆k···˚i;t, uo;t, d(t −1))
=

c∈c∗
Ac(∆k···˚i;t, uo;t, d(t −1))
k−1
 
j=j
Θ∆j;t|ψj;t,c
Ac(∆k···˚i;t, uo;t, d(t −1)) =
αc
/˚i
j=k Θ∆j;t|ψj;t,c
2
˜c∈c∗α˜c
/˚i
j=k Θ∆j;t|ψj;t,˜c
.
(11.5)
Proof. Conditioning f(β|γ) = f(β,γ)
f(γ) =
f(β,γ)

f(β,γ) dβ implies the result.
Remark(s) 11.1
1. The formula (11.5) shows that the model obtained through the estimation
of the full predictor followed by marginalization is richer than the directly
estimated low-dimensional predictor: the mixture obtained by conditioning
has data-dependent component weights.

11.1 Common tools
415
2. Permutations of factors according to Proposition 11.1 have to be made if
the considered entries are not at the assumed positions.
Problem 11.2 (Graphical presentation of advices) The general advice
“try to reach data conﬁgurations having a high probability” applies in the
Markov-chain case, too. The adequate and informative graphical representa-
tion has to be chosen or developed for the presentation of the optimized ideal
low-dimensional pfs.
11.1.2 Basic operations for fully probabilistic design
This section prepares basic evaluations needed in connection with the fully
probabilistic design.
Proposition 11.4 (Expected loss for a factorized Markov chain) Let us
consider a Markov-chain component described by
f(∆t|uo;t, φt−1, Θ) =
 
i∈i∗
Θ∆i;t|ψi;t
with
(11.6)
Θ ≡

Θ∆i|ψi ≥0

∆i∈∆i,ψi∈ψ∗
i ,i=1,..., ˚
∆
with ﬁnite sets of all involved indexes
ψ′
i;t ≡
	
∆′
(i+1)··· ˚
∆;t, u′
o;t, φ′
t−1

≡

∆i+1;t, ψ′
i+1;t

i = 0, 1, . . . , ˚
∆−1,
ψ′
˚
∆;t ≡

u′
o;t, φ′
t−1

.
Let ω0(Ψt) be a nonnegative array indexed by Ψt = ψ0;t. Then, the expected
value
E[ω0(Ψt)|uo;t, φt−1] ≡ω ˚
∆(ψ ˚
∆;t),
where ω ˚
∆(ψ ˚
∆;t) is obtained recursively
ωi(ψi;t) =

∆i;t∈∆∗
i
ωi−1([∆i;t, ψi;t])Θ∆i;t|ψi;t starting from ω0(ψ0;t).
(11.7)
Proof. The expectation is taken over entries of ∆t as the remaining part of
the data vector Ψt is ﬁxed by the condition ψ ˚
∆;t ≡

u′
o;t, φ′
t−1
′ . The the chain
rule for expectations, Proposition 2.6, implies that we can evaluate conditional
expectations over individual entries in ∆t one-by-one starting from the ﬁrst
one.
When performing fully probabilistic designs, we use the following auxiliary
proposition.

416
11 Design with Markov-chain mixtures
Proposition 11.5 (The conditional KL divergence) Let innovations ∆t
= (∆o;t, ∆p+;t) and
f(∆t|uo;t, d(t −1)) =
˚
∆
 
i=1
Θ∆i;t| ⌊lψi;t
⌊Uf(∆o;t|uo;t, d(t −1)) =
˚
∆o
 
i=1
⌊UΘ∆i;t| ⌊Uψi;t.
The transition probabilities Θ∆i;t| ⌊lψi;t and user’s ideal pf ⌊UΘ∆i;t| ⌊Uψi;t are ex-
tended as follows. Θ∆i;t| ⌊lψi;t = Θ∆i;t|ψi;t, ⌊UΘ∆i;t| ⌊Uψi;t = ⌊UΘ∆i;t|ψi;t, where
ψi;t contains the union of entries from respective regression vectors
⌊lψi;t,
⌊Uψi;t. In other words, the regression vectors ψi;t for the ith learned factor
and the corresponding factor of the user’s ideal pf are common. Recall that
ψ ˚
∆;t =

u′
o;t, φ′
t−1
′ and
ψi;t =
	
∆′
(i+1)··· ˚
∆;t, u′
o;t, φ′
t−1
′
≡

∆(i+1);t, ψ′
i+1;t
′ for i ∈{0, . . . , ˚
∆−1}.
Then, ω(uo;t, φt−1) ≡

∆t∈∆∗
f(∆t|uo;t, φt−1) ln
f(∆o;t|∆p+;t, uo;t, φt−1)
⌊Uf(∆o;t|uo;t, φt−1)

= ω ˚
∆(ψ ˚
∆;t).
(11.8)
The conditional KL divergence ω ˚
∆(ψ ˚
∆;t) is found recursively
ωi(ψi;t) = ⌊ψωi−1(ψi;t)
+

∆i;t∈∆∗
i
Θ∆i;t|ψi;t
#
⌊∆Ψωi−1([∆i;t, ψi;t]) + χ

i ≤˚
∆o

ln
 Θ∆i;t|ψi;t
⌊UΘ∆i;t|ψi;t
$
In the recursion, running for i = 1, . . . , ˚
∆, we set ω0(ψ0;t) = 0,
⌊ψωi−1(ψi;t) = the part of ωi−1(ψi−1;t) independent of entries ∆i;t,
⌊∆Ψωi−1([∆i;t, ψi;t]) = the part of ωi−1(ψi−1;t) that depends also on ∆i;t.
Proof. Let the innovations be split ∆= (∆o, ∆p+). Then, ω(uo;t, φt−1)
≡

∆t∈∆∗
f(∆t|uo;t, φt−1) ln

f(∆t|uo;t, d(t −1))
f(∆p+;t|uo;t, d(t −1)) ⌊Uf(∆o;t|uo;t, d(t −1))

=

∆t∈∆∗
Θ∆t|uo;t,φt ln
⎛
⎝
˚
∆o
 
i=1
Θ∆i;t|ψi;t
⌊UΘ∆i;t|ψi;t
⎞
⎠
=

Proposition 2.6

∆˚
∆;t∈∆∗
˚
∆;t
Θ∆˚
∆;t|ψ ˚
∆;t
"
χ( ˚
∆≤˚
∆o) ln
0
Θ∆˚
∆;t|ψ ˚
∆;t
⌊UΘ∆˚
∆;t|ψ ˚
∆;t
1

11.1 Common tools
417
+ · · · +

∆2;t∈∆∗
2;t
Θ∆2;t|ψ2;tχ(2 ≤˚
∆o) ln
 Θ∆2;t|ψ2;t
⌊UΘ∆2;t|ψ2;t

+ ω1(ψ1;t)
⎫
⎬
⎭.



ω2(ψ2;t)
ω1(ψ1;t) ≡

∆1;t∈∆∗
1;t
Θ∆1;t|ψ1;tχ(1 ≤˚
∆o) ln
 Θ∆1;t|ψ1;t
⌊UΘ∆1;t|ψ1;t

The part of ωi−1(ψi−1;t) independent of ∆i;t, called
⌊ψωi(ψi;t), simply adds
to the part whose expectation is taken. It consists of the sum part called
⌊∆Ψωi(ψi−1;t) and of the “penalization” term χ(i ≤˚
∆o) ln

Θ∆i;t|ψi;t
⌊UΘ∆i;t|ψi;t

.
While performing the fully probabilistic design, we work with a shifted
version of the conditional KL divergence. The following slight extension of
Proposition 11.5 supports the cases for which the Bellman function is given
by a table ωγ(φt).
Proposition 11.6 (The shifted conditional KL divergence) Let inno-
vations ∆t = (∆o;t, ∆p+;t) and
f(∆t|uo;t, d(t −1)) =
˚
∆
 
i=1
Θ∆i;t|ψi;t,
⌊Uf(∆o;t|uo;t, d(t −1)) =
˚
∆o
 
i=1
⌊UΘ∆i;t|ψi;t.
The transition probabilities Θ∆i;t|ψi;t and the pf
⌊UΘ∆i;t|ψi;t describing the
user’s ideal pf are extended (see the formulation of Proposition 11.5) so that
the regression vectors ψi;t for the ith factor and the corresponding factor of
the user’s ideal pf are common. Recall that ψ ˚
∆;t =

u′
o;t, φ′
t−1
′ and
ψi;t =
	
∆′
(i+1)··· ˚
∆;t, u′
o;t, φ′
t−1
′
≡

∆(i+1);t, ψ′
i+1;t
′ for i ∈{0, . . . , ˚
∆−1}.
Let, moreover, the Bellman function be the table ωγ(φt) with
φt ≡
	
d′
t···(t−∂+1)
′
⇒ψ0;t ≡Ψt ≡

∆′
t, u′
o;t, φ′
t−1
′ .
Then, the lifted KL divergence
ωγ(uo;t, φt−1) ≡

∆t∈∆∗
Θ∆t|uo;t,φt−1
#
ln
Θ∆o;t|∆p+;t,uo;t,φt−1
⌊UΘ∆o;t|uo;t,φt−1

+ ωγ(φt)
$
equals ω ˚
∆(ψ ˚
∆;t). The value ω ˚
∆(ψ ˚
∆;t) is found recursively
ωi(ψi;t) = ⌊ψωi−1(ψi;t)
+

∆i;t∈∆∗
i
Θ∆i;t|ψi;t

⌊∆Ψωi−1([∆i;t, ψi;t]) + χ

i ≤˚
∆o

ln
 Θ∆i;t|ψi;t
⌊UΘ∆i;t|ψi;t

.
In the recursion, running for i = 1, . . . , ˚
∆, we denoted

418
11 Design with Markov-chain mixtures
⌊ψωi−1(ψi;t) = the part of ωi−1(ψi−1;t) independent of ∆i;t
⌊∆Ψωi−1([∆i;t, ψi;t]) = the part of ωi−1(ψi−1;t) that depends also on ∆i;t.
The recursions start from the following initial condition
ω0(ψ0;t) = ωγ(φt) for any dt−∂extending φt →ψ0;t = Ψt.
Notice that during the evaluations the array ωi “loses” entries with indexes
∆i, [∆i, ψi]. On the other hand, ω0 extends ωγ so that the dimensionality loss
is compensated.
Proof. The table ω(φt) just adds nontrivial initial conditions to the recursion
described in Proposition 11.5. It arises by extending ω(φt) so that it can be
taken as the function Ψt.
11.1.3 Dangerous components
The discrete and ﬁnite nature of the data space modelled by Markov chains
implies that there is no such universally dangerous component like the unsta-
ble one for the normal components. Thus, we have to deﬁne as dangerous those
components that, when permanently active, lead to a much higher distance
to the user’s ideal pf than the other components; cf. Section 7.2.2.
For a quantitative expression of this statement, we write down the Markov-
chain version of Proposition 7.3. It evaluates recursively the KL divergence
of a pair of multivariate Markov chains
⌊If(d(˚t)), ⌊Uf(d(˚t)). The transition
matrices ⌊IΘd|ψ, ⌊UΘd|ψ generating them
⌊If(d(˚t)) =
 
t∈t∗
˚
d
 
i=1
⌊IΘdi;t|ψi;t,
⌊Uf(d(˚t)) =
 
t∈t∗
˚
d
 
i=1
⌊UΘdi;t|ψi;t,
(11.9)
describe a ﬁxed component and the user’s ideal pf, respectively. We assume
that for surplus data of the p-system it holds that
⌊UΘ∆i;t|ψi;t = ⌊IΘ∆i;t|ψi;t for i = ˚
∆o + 1, . . . , ˚
∆.
(11.10)
The transition probabilities ⌊IΘ∆i;t|ψi;t may result from optimization, for in-
stance, of the recognizable actions. For the considered purpose, we need not
distinguish innovations and recognizable actions explicitly. Thus, we can as-
sume that ∆t = dt.
Proposition 11.7 (Recursive evaluation of the KL divergence) Let ∆t =
(∆o;t, ∆p+;t) = dt. Let pfs
⌊If(d(˚t)),
⌊Uf(d(˚t)) be generated according to
(11.9) and fulﬁll (11.10). Then, the KL divergence of ⌊If(d(˚t)) and ⌊Uf(d(˚t))
D

⌊If(d(˚t))
!!!
!!! ⌊Uf(d(˚t))

≡ωγ(φ0) is obtained recursively for
(11.11)
t = ˚t,˚t −1, . . . , 1,
starting at ωγ(φ˚t) = 0

11.2 Design of the advising strategy
419
ωγ(φt−1) ≡

∆t∈∆∗
˚
∆
 
i=1
⌊IΘ∆i;t|ψi;t
⎡
⎣ln
⎛
⎝
˚
∆
 
j=1
⌊IΘ∆j;t|ψj;t
⌊UΘ∆j;t|ψj;t
⎞
⎠+ ωγ(φt)
⎤
⎦.
The table ω ˚
∆(ψ ˚
∆;t) ≡ωγ(φt−1) is found recursively
ωi(ψi;t) = ⌊ψωi−1(ψi;t)
(11.12)
+

∆i;t∈∆∗
i
Θ∆i;t|ψi;t

⌊∆Ψωi−1([∆i;t, ψi;t]) + χ

i ≤˚
∆o

ln
 Θ∆i;t|ψi;t
⌊UΘ∆i;t|ψi;t

.
In the recursion, running for i = 1, . . . , ˚
∆, we denoted
⌊ψωi−1(ψi;t) = the part of ωi−1(ψi−1;t) independent of ∆i;t,
⌊∆Ψωi−1([∆i;t, ψi;t]) = the part of ωi−1(ψi−1;t) that depends also on ∆i;t.
The recursions start from the following initial condition
ω0(ψ0;t) = ωγ(φt) for any dt−∂extending φt →ψ0;t = Ψt.
Proof. It combines directly Propositions 7.3 and 11.6.
Remark(s) 11.2
1. The index γ is used in order to keep continuity with the notation used in
Chapters 7 and 9.
2. The recursion (11.12) is linear with respect to the array ωγ(·).
3. It makes sense to consider the stationary version of (11.12), i.e., the case
with ˚t →∞. It is closely related to the average KL divergence per step, i.e.
lim˚t→∞
1
˚t D
 ⌊If(d(˚t))|| ⌊Uf(d(˚t))

. The full art the Markov-chain decision
processes can be used for its analysis [79, 171]. Even numerical techniques
elaborated in this area, e.g., [172], should be used for its evaluation and
optimization.
11.2 Design of the advising strategy
Particular design versions are based on a straightforward application of the
fully probabilistic design with the special target resulting from the diﬀerence
between sets d∗
o and d∗
p; see Proposition 7.4. Inﬂuence of advices on the in-
terconnection of the p- and o-systems is modelled as presented in Section
7.1.3.
11.2.1 Academic design
The recommended pointers ct to components are the only actions of the
academic p-system. They are generated by the optimized academic strategy
 ⌊If(ct|d(t −1))

t∈t∗. It determines, together with the estimated Markov-
chain mixture of the o-system, the ideal pfs to be presented to the operator

420
11 Design with Markov-chain mixtures
⌊If(dt, ct|d(t −1)) ≡
˚
d
 
i=1
Θdi;t|ψict;t,ct
⌊If(ct|d(t −1)) with dt ≡∆t, ˚
d = ˚
∆.
(11.13)
The user’s ideal pf needed for the fully probabilistic design is selected as a
Markov chain on the o-data d∗
o;t. This true user’s ideal pf is extended on d∗
t in
the way discussed in Section 5.1.5. It is extended further on c∗
t by specifying
the target pf ⌊UΘct|φt−1 for the academic advices. Altogether,
⌊Uf(dt, ct|d(t −1)) =
˚
do
 
i=1
⌊UΘdi;t|ψi;t
⌊If(dp+;t|ct, d(t −1)) ⌊UΘct|φt−1.
In evaluations, we use the freedom of choice of the ideal pf
⌊UΘct|φt−1 for
the actions ct of the constructed academic p-system. We always evaluate ini-
tially dangerous components (see Section 11.1.3) and reduce the support of
⌊UΘct|φt−1 to nondangerous ones. If the reduced set contains just a single com-
ponent, the optimal design of the academic p-system is solved by this choice
and the component is presented to the operator as the designed ideal pf. Oth-
erwise, the Markov-chain version of the optimal academic advising strategy
described by Proposition 7.10 has to be searched for.
Proposition 11.8 (Optimal fully probabilistic academic design) Let us
consider the design of the academic advisory system for the o-system described
by the mixture with Markov-chain components having the state φt in the phase
form. The innovation ∆t and data record dt coincide since no recognizable ac-
tions are available. Let dt = (do;t, dp+;t) =(o-data, surplus p-data) and the
user’s ideal pf ⌊Uf(d(˚t)) on d∗(˚t) be generated by
⌊Uf(dt, ct|d(t −1)) ≡
 
io∈i∗
o
⌊UΘdi;t|ψi;t
⌊If(dp+;t|d(t −1)) ⌊UΘct|φt−1(11.14)
i∗
o ≡

1, . . . , ˚
do

⊂i∗≡

1, . . . , ˚
d

.
The parameters Θdi;t|ψi;t,c ≥0, 2
di∈d∗
i Θdi|ψic = 1 of the Markov-chain mix-
ture as well those determining the Markov-chain user’s ideal pf are assumed to
be known. The probabilities Θdi;t|ψi;t,c,
⌊UΘdi;t|ψi;t are extended (cf. Proposi-
tion 11.5) so that the corresponding factors of the user ideal and the Markov-
chain mixture have common regression vectors ψi;t ≡

di+1;t, ψ′
i+1;t
′ =
	
d′
(i+1)···˚
d;t, φ′
t−1
′
, i < ˚
d, ψ˚
d;t ≡φt−1.
The recommended pointers ct are allowed to have nonzero values at most
for those indexes in c∗that point to nondangerous components; Section 11.1.3.
Then, the optimal causal academic advisory strategy, minimizing the KL di-
vergence of ⌊If(d(˚t), c(˚t)) to the user ideal
⌊Uf(d(˚t), c(˚t)) =
 
t∈t∗
⌊Uf(dt, ct|φt−1),

11.2 Design of the advising strategy
421
is described by the following formulas initialized by ωγ(φ˚t) = 0,
∀φ˚t ∈φ∗.
For
t = ˚t, . . . , 1
For φt−1 ∈φ∗
Set ωγ(φt−1) = 0.
For
ct = 1, . . . ,˚c
For
dt = 1, . . . , ˚
d
Set Ψt ≡ψ0;t = [d′
t, φ′
t−1]′ ≡[φ′
t, d′
t−∂]′
(11.15)
ω0(ct, ψ0;t) ≡ω0(ψ0;t) = ωγ(φt) for any dt−∂
extending φt →ψ0;t = Ψt.
end
of the cycle over dt
For
i = 1, . . . , ˚
d
ωi(ct, ψi;t) = ⌊ψωi−1(ct, ψi;t)
For
di;t = 1, . . . , ˚
di
ωi(ct, ψi;t) = ωi(ct, ψi;t) + Θ∆i;t|ψi;t,ct
×
#
⌊dΨωi−1(ct, [di;t, ψi;t]) + χ

i ≤˚
do

ln
 Θdi;t|ψi;t,ct
⌊UΘdi;t|ψi;t
$
.
end
of the cycle over di;t
In the above recursion, we use
⌊ψωi−1(ct, ψi;t) = the part of ωi−1(ct, ψi−1;t) independent of di;t,
⌊dΨωi−1(ct, [di;t, ψi;t]) = the part of ωi−1(ct, ψi−1;t)
that depends also on di;t.
end
of the cycle over i
Set
⌊If(ct|φt−1) = ⌊UΘct|φt−1 exp[−ω˚
d(ct, φt−1)],
ωγ(φt−1) = ωγ(φt−1) + ⌊If(ct|φt−1).
end
of the cycle over ct
For
ct = 1, . . . ,˚c
⌊If(ct|φt−1) =
⌊If(ct|φt−1)
ωγ(φt−1)
,
ωγ(φt−1) = −ln(ωγ(φt−1))
end
of the cycle over ct
end of the cycle over φt−1
end
of the cycle over t
Proof. We show that the Bellman function is the table ωγ(φt). For t = ˚t, it
holds with ω(φ˚t) = 0. Backward induction implies that for a generic t
ωγ(φt−1) =

ct∈c∗
⌊If(ct|φt−1)
#
ln
 ⌊If(ct|φt−1)
⌊Uf(ct|φt−1)

+ ωγ(ct, φt−1)
$
,
with

422
11 Design with Markov-chain mixtures
ωγ(ct, φt−1) ≡

dt∈d∗
f(dt|φt−1, ct)
#
ln
f(dt|φt−1, ct)
⌊Uf(dt|φt−1)

+ ωγ(φt)
$
.
It implies the form of the minimizing strategy with the achieved minimum
being the table
ωγ(φt−1) = −ln
 
ct∈c∗
⌊Uf(ct|φt−1) exp[−ωγ(ct, φt−1)]

.
Proposition 11.6 provides evaluations of the shifted KL divergence.
The proved proposition combined with the certainty-equivalence strategy
gives the following algorithm.
Algorithm 11.1 (Optimal ﬁxed academic advising)
Initial (oﬄine) mode
•
Estimate the Markov-chain mixture describing the o-system with the state
φt in the phase form; Chapter 10.
•
Exclude dangerous components; Sections 11.1.3, 11.1.1.
•
Return to the learning phase if all components are dangerous.
•
Take the nondangerous component as the ideal pf oﬀered to the operator
and stop if ˚c = 1.
•
Specify the true user’s ideal pf on the response of the o-system
⌊Uf(do;t|do(t −1)) ≡⌊Uf(do;t|φt−1) =
˚
do
 
i=1
⌊UΘdi;t|ψi;t.
•
Specify time invariant user’s ideal pf
⌊Uf(ct|φt−1) =
⌊UΘct|φt−1 on the
recommended pointers. It is zero on dangerous components.
•
Select the length of the design horizon ˚t ≥1.
•
Initialize the iterative mode by setting ωγ(φ˚t) = 0.
Iterative (oﬄine) mode
•
Correct the arrays, for t = ˚t, . . . , 1, as given in (11.15).
•
Store the terminal characteristics ωγ(c, φ), c ∈c∗, φ ∈φ∗, determining
the optimal steady-state strategy; Chapter 3.
Sequential (online) mode, running for t = 1, 2, . . .,
1. Acquire the data record dt and determine the state vector φt.
2. Evaluate the values of the pf describing the optimal academic advising
strategy
⌊IΘct+1|φt ∝⌊UΘct+1|φt exp[−ωγ(ct+1, φt)].

11.2 Design of the advising strategy
423
3. Present to the operator projections of the ideal pf
⌊IΘdt+1|φt =

ct+1∈c∗
⌊IΘct+1|φt
˚
d
 
i=1
Θdict+1;t+1|ψi;t+1.
4. Go to the beginning of Sequential mode.
The adaptive version of the academic design with certainty-equivalence strat-
egy and IST patch is described by the following algorithm.
Algorithm 11.2 (Optimal adaptive academic advising)
Initial (oﬄine) mode
•
Estimate the Markov-chain mixture describing the o-system with the state
φt in the phase form; Chapter 10.
•
Specify the true user’s ideal pf on the response of the o-system
⌊Uf(do;t|do(t −1)) ≡⌊Uf(do;t|φt−1) =
˚
do
 
i=1
⌊UΘdi;t|ψi;t.
•
Specify a time invariant user’s ideal pf ⌊Uf(ct|φt−1) = ⌊UΘct|φt−1 on the
recommended pointers.
•
Select the length of the design horizon T ≥1.
Sequential (online) mode, running for t = 1, 2, . . .,
1. Complement the state vector φt by newly acquired data dt and construct
the data vector Ψt = [d′
t, φ′
t−1]′.
2. Update the estimates of the Markov mixture using quasi-Bayes estimation,
Algorithm 6.13.
3. Initialize the iterative mode by setting ωγ(φ˚t) = 0. Skip this step if t > 1
and IST patch is used.
4. Correct iteratively the arrays ωγ as given in (11.15) with τ in the role of
t, τ = t + T, . . . , t + 1.
5. Evaluate the values of the pf describing the optimal academic advising
strategy
⌊IΘct+1|φt ∝⌊UΘct+1|φt exp[−ωγ(ct+1, φt)].
6. Present to the operator projections of the ideal pf
⌊IΘdt+1|φt =

ct+1∈c∗
⌊IΘct+1|φt
˚
d
 
i=1
Θdict+1;t+1|ψi;t+1.
7. Go to the beginning of Sequential mode.

424
11 Design with Markov-chain mixtures
Remark(s) 11.3
1. The strategy with maximum probable advices can simply be derived by
copying general considerations of Chapter 7.
2. The strategy with grouped advices can also be simply derived by copying
results given in Chapter 7.
3. Design and application of the academic advising is simple. Manipulations
with high-dimensional arrays are the most complex and restrictive opera-
tions. Current technology allows, however, handle rather extensive memo-
ries. It is important, especially in online mode, when read-only operations
dominate.
11.2.2 Industrial design
The industrial design is used whenever component weights have objective
meaning and the operator has no inﬂuence on them. It is addressed here.
Similarly, as in previous chapters, the following order of entries in the
data record dt is supposed dt = (∆o;t, ∆p+;t, uo;t) ≡(o-innovations, surplus
p-innovations, recognizable actions). For t ∈t∗, c ∈c∗, the Markov-chain com-
ponents, with explicitly marked recognizable actions,
f(∆t|uo;t, d(t −1), c)f(uo;t|d(t −1), c) ≡
˚
∆
 
i=1
Θ∆i;t|ψic;t
˚
d
 
i= ˚
∆+1
Θuo(i−˚
∆);t|ψic;t
(11.16)
and their weights {αc}c∈c∗are assumed to be known (well estimated).
The considered extension (see Section 5.1.5) of the true user’s ideal pf is
⌊Uf(d(˚t)) ≡
 
t∈t∗
˚
∆o
 
i=1
⌊UΘ∆i;t|ψi;t
˚
∆
 
i= ˚
∆o+1
⌊If(∆i;t|ψi;t)
˚
d
 
i= ˚
∆+1
⌊UΘuo(i−˚
∆);t|ψi;t.
(11.17)
Unlike in normal case, Chapter 9, the KL divergence can be exactly optimized.
Proposition 11.9 (Optimal fully probabilistic industrial design) Let
the joint pf
⌊If(∆(˚t), uo(˚t))
≡
 
t∈t∗
2
c∈c∗αcf(∆t|uo;t, d(t −1), c)f(uo;t|d(t −1), c)
2
c∈c∗αcf(uo;t|d(t −1), c)
⌊If(uo;t|d(t −1))
with components (11.16) be determined by the optional industrial advising
strategy described by pfs
 ⌊If(uo;t|d(t −1))

t∈t∗. Then, the optimal strategy,
minimizing the KL divergence D
 ⌊If
!!!! ⌊Uf

to the user’s ideal pf (11.17), is
generated by the following algorithm, initialized by ωγ(φ˚t) = 0,
∀φ˚t ∈φ∗.

11.2 Design of the advising strategy
425
For
t = ˚t, . . . , 1
For
φt−1 = 1, . . . , ˚φ
Set ψ˚
d;t = φt−1,
ωγ(φt−1) = 0.
(11.18)
For
i = ˚
d, . . . , 1
For
di;t = 1, . . . , ˚
di
Set ψi−1;t ≡[di;t, ψ′
i;t],
Θdi···˚
d;t|ψi;t = 0.
For
ct = 1, . . . ,˚c
Set Θdi···˚
d|ψi;t,ct = 1.
For
j = i, . . . , ˚
d
Θdi···˚
d;t|ψi;t,ct = Θdi···˚
d|ψi;t,ctΘdj;t|ψj;t,ct
end
of the cycle over j
Θdi···˚
d;t|ψi;t = Θdi···˚
d;t|ψi;t + αctΘdi···˚
d;t|ψi;t,ct.
end
of the cycle over ct
end
of the cycle over di;t
end
of the cycle over i
For
uo;t = 1, . . . ,˚uo
For
∆t = 1, . . . , ˚
∆
Set ω0(ψ0;t) ≡ωγ(φt) for any dt−∂extending φt →ψ0;t = Ψt.
end
of the cycle over ∆t
For
i = 1, . . . , ˚
∆
ωi(ψi;t) = ⌊ψωi−1(ψi;t)
For
∆i;t = 1, . . . , ˚
∆i
ωi(ψi;t) = ωi(ψi;t) +
Θdi···˚
d;t|ψi;t
Θd(i+1)···˚
d;t|ψi;t
×

⌊∆Ψωi−1([∆i;t, ψi;t]) + χ

i ≤˚
∆o

ln
0
Θdi···˚
d;t|ψi;t
Θd(i+1)···˚
d;t|ψi;t
⌊UΘdi;t|ψi;t
1
.
end
of the cycle over ∆i;t
In the above recursion, we use
⌊ψωi−1(ψi;t) = the part of ωi−1(ψi−1;t)
independent of entries ∆i;t
⌊∆Ψωi−1([∆i;t, ψi;t]) = the part of ωi−1(ct, ψi−1;t)
that depends also on ∆i;t
end
of the cycle over i
Set
⌊If(uo;t|φt−1) = ⌊UΘuo;t|φt−1 exp[−ω ˚
∆(ψ ˚
∆)],

426
11 Design with Markov-chain mixtures
ωγ(φt−1) = ωγ(φt−1) + ⌊If(uo;t|φt−1).
end
of the cycle over uo;t
For
uo;t = 1, . . . ,˚uo
⌊If(uo;t|φt−1) =
⌊If(uo;t|φt−1)
ωγ(φt−1)
,
end
of the cycle over uo;t
ωγ(φt−1) = −ln(ωγ(φt−1)).
end
of the cycle over φt−1
end
of the cycle over t
Proof. We apply Proposition 7.4 with the Bellman function in the form of the
table ωγ(φt). Its initial value is zero. The optimal strategy has the form
⌊If(uo;t|φt−1) = ⌊UΘut|φt−1
exp[−ωγ(uo;t, φt−1)]
γ(φt−1)
with
γ(φt−1) ≡

uo;t∈u∗
o
⌊UΘut|φt−1 exp[−ωγ(uo;t, φt−1)],
ωγ(φt−1) = −ln(γ(φt−1)).
The decisive shifted conditional KL divergence has the form
ωγ(uo;t, φt−1) =

∆t∈∆∗
2
ct∈c∗αc
/˚
d
i=1 Θdi;t|ψi;t,ct
2
˜ct∈c∗α˜c
/˚
d
i= ˚
∆+1 Θuo(i−˚
∆);t|ψi;t,˜ct
×
⎡
⎣ln
⎛
⎝
2
ct∈c∗αc
/˚
d
i=1 Θdi;t|ψi;t,ct
2
˜ct∈c∗
	
α˜c
/˚
d
i= ˚
∆o+1 Θdi;t|ψi;t,˜ct
 / ˚
∆o
i=1
⌊UΘ∆i;t|ψi;t
⎞
⎠+ ωγ(φt)
⎤
⎦.
Similarly as in Proposition 11.6, its evaluation is done recursively using the
chain rule for expectations, Proposition 2.6. Conditional and marginal pfs are
evaluated according to Propositions 11.2 and 11.3. For i = 1, . . . , ˚
∆, it holds
that
ωi(ct, ψi;t) = ⌊ψωi−1(ct, ψi;t) +

∆i;t∈∆∗
i
2
ct∈c∗αc
/˚
d
j=i Θdj;t|ψj;t,ct
2
˜ct∈c∗α˜c
/˚
d
j=i+1 Θdj;t|ψj;t,˜ct
×
	
⌊∆Ψω(ct, [∆i;t, ψi;t])
+ χ

i ≤˚
∆o

ln
⎛
⎝
2
ct∈c∗αc
/˚
d
j=i Θdj;t|ψj;t,ct
2
˜ct∈c∗α˜c
/˚
d
j=i+1 Θdj;t|ψj;t,˜ct
⌊UΘdi;t|ψi;t
⎞
⎠
⎤
⎦.

11.2 Design of the advising strategy
427
Initial value of this recursion is obtained by extending ωγ(φt) to ω0(ψ0;t) by
taking them as equal whenever φt is a part of ψ0;t.
The proved proposition, combined with the receding-horizon certainty-
equivalence strategy, justiﬁes the following algorithm that adds the estimation
environment to the design algorithm.
Algorithm 11.3 (Optimal industrial advising)
Initial (oﬄine) mode
•
Estimate the Markov-chain mixture describing the o-system with the state
φt in the phase form; see Chapter 10.
•
Specify the true user’s ideal pf (11.17) on the response of the o-system.
•
Select the length of the receding horizon T ≥1.
Sequential (online) mode, running for t = 1, 2, . . .,
1. Acquire the data record dt and determine the state vector φt.
2. Update estimates of the model parameters, Section 10.5, if you deal with
the adaptive advisory system.
3. Initialize the iterative mode by setting τ = t + T and ωγ(φτ) = 0. Omit
the zeroing of ωγ if t > 1 and the IST strategy is used.
Iterative mode
•
Apply algorithm given in Proposition 11.9 while replacing t by τ and
stopping at τ = t + 1.
4. Evaluate the pf ⌊If(uo;t+1|φt) resulting from this industrial design.
5. Present to the operator projections of the ideal pf
⌊If(dt+1|φt) =
2
ct+1∈c∗αct+1
/˚
d
i=1 Θdi;t+1|ψi;t+1,ct+1
2
ct+1∈c∗αct+1
/˚
d
i= ˚
∆+1 Θdi;t+1|ψi;t+1,ct+1
⌊If(uo;t+1|φt).
6. Go to the beginning of Sequential mode.
Remark(s) 11.4
The grouped version of the industrial design is to be implemented; see Propo-
sition 7.13 and Remark 5.
11.2.3 Simultaneous academic and industrial design
The simultaneous academic and industrial design provides the best problem
formulation and solution. The academic actions of the simultaneous p-system
ct ∈c∗≡{1, . . . ,˚c} are generated by a causal strategy d∗(t −1) →c∗. The
industrial part generates the recommended recognizable actions d∗(t −1) →
u∗
o;t. The potential ideal pfs are

428
11 Design with Markov-chain mixtures
⌊If(dt, ct|d(t −1)) = f(∆o;t|∆p+;t, uo;t, d(t −1), ct)
(11.19)
× f(∆p+;t|uo;t, d(t −1), ct) ⌊If(ct|uo;t, d(t −1)) ⌊If(uo;t|d(t −1)).
The user’s ideal pf is
⌊Uf(dt, ct|d(t −1)) = ⌊Uf(∆o;t|uo;t, do(t −1))
× f(∆p+;t|uo;t, d(t −1), ct) ⌊Uf(ct|uo;t, d(t −1)) ⌊Uf(uo;t|do(t −1))
∝
˚
∆o
 
i=1
	
⌊UΘ∆i;t|ψi;t

f(∆p+;t|uo;t, d(t −1), ct)
˚
d
 
i= ˚
∆+1
	
⌊UΘuo(i−˚
∆);t|ψi;t

⌊UΘct|ψt
f(∆o;t|∆p+;t, uo;t, d(t −1), ct) ≡/ ˚
∆o
i=1 Θ∆ict;t|ψict;t is the pf derived from the
ctth learned component describing the o-innovations;
f(∆p+;t|uo;t, d(t −1), ct) ≡/ ˚
∆
i= ˚
∆o+1 Θ∆i;t|ψict;t is the pf also derived from
the ctth learned component and describing the surplus p-innovations;
 ⌊If(ct, uo;t|d(t −1)) ≡⌊If(ct|uo;t, d(t −1)) ⌊If(uo;t|d(t −1))

t∈t∗is the op-
timized simultaneous strategy;
⌊Uf(∆o;t|uo;t, do(t −1)) = / ˚
∆o
i=1
⌊UΘ∆i;t|ψi;t is the true user’s ideal pf on the
o-innovations; see Section 5.1.5;
⌊Uf(uo;t|do(t −1)) = /˚
d
i= ˚
∆+1
⌊UΘuo(i−˚
∆);t|ψi;t is the true user’s ideal pf on
the recognizable actions uo;t; see Section 5.1.5;
⌊Uf(ct|uo;t, d(t −1)) = ⌊UΘct|ψt is the pf representing the optional knob of
the p-system that can respect special requirements like stability of advices.
Notice that the desirable ct may depend on uo;t.
Proposition 11.10 (Optimal simultaneous fully probabilistic design)
Let us
consider the simultaneous
academic and industrial design for the
o-system described by the Markov-chain mixture with the state φ in the phase
form. The data record dt contains both innovations ∆t = (∆o;t, ∆p+;t) =
(innovations in d∗
o, innovations in d∗
p+) and recognizable actions uo;t. The o-
data are do;t = (∆o;t, uo;t) = (o-innovations, recognizable actions). The data
record dt is ordered as follows dt = (∆o;t, ∆p+;t, uo;t).
The assumed inﬂuence of advices and the user’s ideal pf are described by
(11.19). The parameters Θdi;t|ψic;t;c of the Markov-chain mixture as well those
determining the true user’s ideal pf ⌊UΘdi;t|ψic;t,c are known and ﬁxed. They
are extended as in Proposition 11.5 so that the corresponding factors of the
learned mixture and of the user’s ideal pf have the common regression vectors
ψi;t ≡

di+1;t, ψ′
i+1;t
′ =
	
d′
(i+1)···˚
d;t, φ′
t−1
′
, i < ˚
d, ψ˚
d;t ≡φt−1.
Let us search for the advising strategy
 ⌊If(ct, uo;t|d(t −1))

t∈t∗, select-
ing both the recommended pointers ct and the recognizable actions uo;t, that
minimizes the KL divergence of
⌊If(d(˚t), c(˚t)) =
 
t∈t∗
⌊If(dt, ct|d(t −1)) to the user’s ideal pf

11.2 Design of the advising strategy
429
⌊Uf(d(˚t), c(˚t)) =
 
t∈t∗
⌊Uf(dt, ct|d(t −1)) with factors given by (11.19).
Then, the optimal simultaneous advising strategy is described by pfs
⌊If(ct, uo;t|φt−1) ∝⌊UΘct|ψt
⌊UΘut|φt−1 exp [−ωγ(ct, ψt)] ,
where the array ωγ(ct, ψt) is generated by the following formulas initialized by
ωγ(φ˚t) = 0,
∀φ˚t ∈φ∗.
For
t = ˚t, . . . , 1
For
φt−1 = 1, . . . , ˚φ
Set ωγ(φt−1) = 0.
(11.20)
For
(ct, uo;t) = (1, 1), . . . , (˚c,˚uo)
For
∆t = 1, . . . , ˚
∆
Set Ψt ≡ψ0;t =

d′
t, φ′
t−1
′ ≡

φ′
t, d′
t−∂
′
ω0(ct, ψ0;t) ≡ω0(ψ0;t) = ωγ(φt)
for any dt−∂
extending φt →ψ0;t = Ψt.
end
of the cycle over ∆t
For
i = 1, . . . , ˚
∆
ωi(ct, ψi;t) = ⌊ψωi−1(ct, ψi;t)
For
∆i;t = 1, . . . , ˚
∆i
ωi(ct, ψi;t) = ωi(ct, ψi;t) + Θ∆i;t|ψi;t,ct
×
#
⌊∆Ψωi−1(ct, [∆i;t, ψi;t]) + χ

i ≤˚
∆o

ln
 Θ∆i;t|ψi;t,ct
⌊UΘ∆i;t|ψi;t
$
.
end
of the cycle over ∆i;t
In the above recursion, we use
⌊ψωi−1(ct, ψi;t) = the part of ωi−1(ct, ψi−1;t)
independent of entries ∆i;t,
⌊∆Ψωi−1(ct, [∆i;t, ψi;t]) = the part of ωi−1(ct, ψi−1;t)
that depends also on ∆i;t.
end
of the cycle over i
Set
⌊If(ct, uo;t|φt−1) = ⌊UΘct|ψt
⌊UΘuo;t|φt−1 exp[−ω ˚
∆(ct, φt−1)],
ωγ(φt−1) = ωγ(φt−1) + ⌊If(ct, uo;t|φt−1),
end
of the cycle over (ct, uo;t)
For
(ct, uo;t) = (1, 1), . . . , (˚c,˚uo)
⌊If(ct, uo;t|φt−1) =
⌊If(ct, uo;t|φt−1)
ωγ(φt−1)
,

430
11 Design with Markov-chain mixtures
end
of the cycle over (ct, uo;t)
ωγ(φt−1) = −ln(ωγ(φt−1)).
end
of the cycle over φt−1
end
of the cycle over t
Proof. Discrete nature of the recognizable actions implies that formally they
play the same role as recommended pointers to components. Thus, the cur-
rent proposition copies the results of Proposition 11.8 just with appropriate
changes in notation.
The proposition, combined with the certainty-equivalence strategy, justi-
ﬁes the following algorithm for the design of the ﬁxed simultaneous advisory
system.
Algorithm 11.4 (Optimal ﬁxed simultaneous advising)
Initial (oﬄine) mode
•
Estimate the Markov-chain mixture describing the o-system with the state
φt in the phase form; see Chapter 10.
•
Specify the true user’s ideal pf on the response of the o-system
⌊Uf(do;t|do(t−1)) ≡⌊Uf(do;t|φt−1) =
˚
∆o
 
i=1
⌊UΘ∆i;t|ψi;t
˚
d
 
i= ˚
∆+1
⌊UΘuo(i−˚
∆);t|ψi;t.
•
Specify time invariant user’s ideal pf on the recommended pointers ⌊UΘct|ψt.
•
Select the length of the design horizon ˚t ≥1.
•
Initialize the iterative mode by setting ωγ(φ˚t) = 0.
Iterative (oﬄine) mode
•
Correct the arrays ωγ(ct, ψt), for t = ˚t, . . . , 1, as given in (11.20).
•
Take the ﬁnal ωγ as the array deﬁning the optimal steady-state strategy,
cf. Chapter 3.
Sequential (online) mode, running for t = 1, 2, . . .,
1. Acquire the data record dt and determine the state vector φt.
2. Evaluate the ideal pf
⌊If(ct+1, uo;t+1|φt) ∝⌊UΘct+1|ψt+1
⌊UΘuo;t+1|φt exp [−ω(ct+1, ψt+1)] .
3. Present to the operator projections of the ideal pf
⌊If(dt+1|φt) =

ct+1∈c∗
⌊IΘct+1,uo;t+1|φt
˚
∆
 
i=1
Θ∆i;t+1|ψt+1,ct+1.

11.2 Design of the advising strategy
431
4. Go to the beginning of Sequential mode.
Proposition 11.10, combined with the receding-horizon, certainty-
equivalence strategy, justiﬁes the following adaptive design algorithm.
Algorithm 11.5 (Optimal adaptive simultaneous advising)
Initial (oﬄine) mode
•
Estimate the Markov-chain mixture describing the o-system with the state
φt in the phase form; see Chapter 10.
•
Specify the true user’s ideal pf on the response of the o-system
⌊Uf(do;t|do(t−1)) ≡⌊Uf(do;t|φt−1) =
˚
∆o
 
i=1
⌊UΘ∆i;t|ψi;t
˚
d
 
i= ˚
∆+1
⌊UΘuo(i−˚
∆);t|ψi;t.
•
Specify the user’s ideal pf ⌊UΘct|ψt on the recommended pointers.
•
Select the length of the receding horizon T ≥1.
Sequential (online) mode, running for t = 1, 2, . . .,
1. Acquire the data record dt and determine the state vector φt as well as the
data vector Ψt =

d′
t, φ′
t−1
′.
2. Update estimates of the model parameters; Section 10.5.
3. Initialize the iterative mode by setting τ = t + T and ωγ(φτ) = 0. Omit
the initialization of ωγ if t > 1 and the IST strategy is adopted.
Iterative mode
•
Correct the arrays ωγ(cτ, ψτ) deﬁning the optimal strategy using Propo-
sition 11.10 with the horizon T and τ in the role of t.
4. Evaluate the ideal pf on recommended pointers ct+1 and recognizable
actions uo;t
⌊IΘct+1,uo;t+1|φt ∝⌊UΘct+1|ψt+1
⌊UΘuo;t+1|φt exp [−ωγ(ct+1, ψt+1)] .
5. Present to the operator projections of the ideal pf
⌊If(dt+1|φt) =

ct+1∈c∗
⌊IΘct+1,uo;t|φt
˚
∆
 
i=1
Θ∆ict+1;t+1|ψict+1.
6. Go to the beginning of Sequential mode.
Remark(s) 11.5
1. It is worth stressing that the user’s ideal pf on ct is conditioned on ψt.
Thus, it can modify dependence of ct and uo;t.
2. Other design variants, like selection of the most probable advices or
grouped version, can be constructed directly according to Chapter 7, us-
ing the above evaluations.

432
11 Design with Markov-chain mixtures
11.3 Interaction with an operator
Here, we outline designs of strategies generating the presentation and signaling
actions using the model of Section 7.1.3 in the case of Markov-chain mixtures.
11.3.1 Assigning priorities
Again, Markov-chain mixtures make this task formally much easier than in the
normal case. Dimensionality is the main obstacle. Thus, similarly to Chapter
9, we restricts ourselves to the simplest case with ˚zt = 1. We also assume
that there are no surplus p-innovations in order to simplify presentation of
the results.
First we ﬁnd explicitly the algorithm describing how to compute the inﬂu-
ence of the zt ∈{1, . . . , ˚
do}. It requires evaluation of marginal pfs Θdzt;t|φt−1,
⌊IΘdzt;t|φt−1. It is reasonable to evaluate them jointly in order to decrease the
computational load.
Algorithm 11.6 (Marginal pfs for ﬁxed zt, dzt;t, t, φt−1)
Set Θdzt;t|φt−1 = 0,
⌊IΘdzt;t|φt−1 = 0
For ct ∈c∗
Set Θdzt;t|φt−1,ct = 0,
⌊IΘdzt;t|φt−1,ct = 0
For d1···(zt−1);t ∈d∗
1···(zt−1)
Create ψzt;t = [d1···(zt−1);t, φ′
t−1]′
Set Θd1···zt;t|φt−1,ct = 1,
⌊IΘd1···zt;t|φt−1,ct = 1
For i = 1, · · · , zt
Θd1···zt;t|φt−1,ct = Θd1···zt;t|φt−1,ctΘdi;t|ψi;t,ct
⌊IΘd1···zt;t|φt−1,ct = ⌊IΘd1···zt;t|φt−1,ct
⌊IΘdi;t|ψi;t,ct
end of the cycle over i
Θdzt;t|φt−1,ct = Θdzt;t|φt−1,ct + Θd1···(zt−1);t|φt−1,ct
⌊IΘdzt;t|φt−1,ct = ⌊IΘdzt;t|φt−1,ct + ⌊IΘd1···(zt−1);t|φt−1,ct
end of the cycle over d1···(zt−1);t
Θdzt;t|φt−1 = Θdzt;t|φt−1 + αctΘdzt;t|φt−1,ct
⌊IΘdzt;t|φt−1 = ⌊IΘdzt;t|φt−1 + ⌊IΘct|φt−1
⌊IΘdzt;t|φt−1,ct
end of the cycles over ct
The outputs of this algorithm provides the model relating presentation action
to the data record
f(dt|φt−1, zt) =

ct∈c∗
αct
˚
d
 
i=1
Θdi;t|ψi;t,ct
⌊IΘdzt|φt−1
Θdzt|φt−1
.
(11.21)

11.3 Interaction with an operator
433
Proposition 11.11 (Optimal fully probabilistic presentation)
Let us
consider that the academic, industrial or simultaneous design has provided for
the optimum model
⌊If(dt|d(t −1)) =

ct∈c∗
⌊IΘct|φt−1
˚
d
 
i=1
⌊IΘdi;t|ψi;t,ct.
Let the signaling strategy make the operator fully alert, i.e., signaling actions
s(˚t) ≡1. Let us assume that ˚zt = 1. Let us specify the user data invariant
ideal pf ⌊Uf(zt) on the set of possible presentation actions z∗≡{1, . . . , ˚
do}.
The optimal presentation strategy assigns the higher priority to the entries
of dzt;t, the higher are values of the following pf
f(zt|φt−1) ∝⌊Uf(zt) exp [−ωγ(zt, φt−1)] .
(11.22)
The table ωγ(zt, φt−1) is generated by the following algorithm initialized by
ωγ(φ˚t) = 0, ∀φ˚t ∈φ∗,
For
t = ˚t, . . . , 1
For
φt−1 = 1, . . . , ˚φ
Set ωγ(φt−1) = 0.
(11.23)
For
i = ˚
d, . . . , 1
For
di;t = 1, . . . , ˚
di
Set ψi−1;t ≡

di;t, ψ′
i;t

,
Θdi···˚
d;t|ψi;t = 0.
For
ct = 1, . . . ,˚c
Set Θdi···˚
d|ψi;t,ct = 1.
For
j = i, . . . , ˚
d
Θdi···˚
d;t|ψi;t,ct = Θdi···˚
d|ψi;t,ctΘdj;t|ψj;t,ct.
end
of the cycle over j
Θdi···˚
d;t|ψi;t = Θdi···˚
d;t|ψi;t + αctΘdi···˚
d;t|ψi;t,ct.
end
of the cycle over ct
end
of the cycle over di;t
end
of the cycle over i
For
dt ≡(d1;t, . . . , d˚
d;t) = 1˚
d, . . . , [˚
d, . . . , ˚
d]
Set ω0(ψ0;t) ≡ωγ(φt) for any dt−∂
extending φt = [d′
t, φ′
t−1]′ →ψ0;t = Ψt.
end
of the cycle over dt ≡(d1;t, . . . , d˚
d;t)
For
zt = 1, . . . , ˚
do
Evaluate Θdzt,t|φt−1,
⌊IΘdzt,t|φt−1 using Algorithm 11.6.

434
11 Design with Markov-chain mixtures
For
i = 1, . . . , ˚
d
ωi(zt, ψi;t) ≡⌊ψωi−1(zt, ψi;t)
ωi(zt, ψi;t) = ωi(zt, ψi;t) + Θdi···˚
d;t|ψi;t
⌊IΘdzt;t|φt−1
Θdzt;t|φt−1
×

⌊∆Ψωi−1(zt, [∆i;t, ψi;t]) + χ

i ≤˚
∆o

ln
0
Θdi···˚
d;t|ψi;t
⌊IΘdzt;t|φt−1
Θdzt;t|φt−1
⌊UΘdi;t|ψi;t
1
.
end
of the cycle over i
In the above recursion, we use
⌊ψωi−1(zt, ψi;t) = the part of ωi−1(zt, ψi−1;t) independent of entries di;t,
⌊∆Ψωi−1(zt, [di;t, ψi;t]) = the part of ωi−1(zt, ψi−1;t) that depends on di;t.
Set
⌊If(zt|φt−1) = ⌊UΘzt|φt−1 exp[−ω˚
d(zt, ψ˚
d;t)]
ωγ(φt−1) = ωγ(φt−1) + ⌊If(zt|φt−1)
end
of the cycle over zt
For
zt = 1, . . . , ˚
d
⌊If(zt|φt−1) =
⌊If(zt|φt−1)
ωγ(φt−1)
,
end
of the cycle over zt
ωγ(φt−1) = −ln(ωγ(φt−1)).
end
of the cycle over φt−1
end
of the cycle over t
Proof. With the prepared model a version of industrial design has arisen.
Consequently, the corresponding algorithm can be copied with an appropriate
change of notation.
11.3.2 Stimulating the operator
The signaling strategy makes the operator alert. It asks him to follow the
advised actions when the ideal pf resulting from an academic, industrial or
simultaneous design gives signiﬁcantly smaller KL divergence to the user’s
ideal pf than the KL divergence of the estimated model to it.
The model relating the signaling action st ∈s∗≡{0, 1} to the response of
the optimized guided o-system is
⌊If(dt, st|d(t −1)) ≡⌊If(dt|st, d(t −1)) ⌊If(st|d(t −1))
(11.24)
⌊If(dt|st = 0, d(t −1)) ≡f(dt|d(t −1)) ≡

c∈c∗
αc
˚
d
 
i=1
Θdi;t|ψi;t,c



learned mixture

11.3 Interaction with an operator
435
⌊If(dt|st = 1, d(t −1)) ≡⌊If(dt|d(t −1)) ≡
≡

ct∈c∗
⌊If(ct|φt−1)
˚
d
 
i=1
⌊IΘdi;t|ψi;t,ct



designed mixture
⌊If(ct|φt−1) ∝⌊Uf(ct|φt−1) exp[−ωγ(ct, φt−1)].
The model (11.24) is a special version of the model (11.13) used in the aca-
demic design. Thus, the signalling design reduces completely to it.
Problem 11.3 (Completion of the Markov-chain design suite)
This
chapter covers all basic steps of the design, taking advantage of the formal
simplicity of the Markov-chain case. It is fair to underline that the described
algorithms are applicable in low-dimensional cases only. All available art and
possibly additional results will be needed in order to cope with high-dimensional
arrays. Sure steps to be taken are
•
exploitation of the sparse nature of the underlying transition matrices,
•
use of the well-developed art of graphs describing relationships among non-
trivially occurring state transitions,
•
orientation on searches for approximate stationary solutions.

12
Sandwich BMTB for mixture initiation
The research described in this work has been stimulated by successes and
limitations of the mean tracking (MT) clustering algorithm [67]. We have de-
signed factors of a speciﬁc type, called MT factors when unifying the overall
approach to the learning and design. These factors have allowed us to inter-
pret the MT clustering algorithm in a Bayesian way. It has opened up the
possibility of using the tool set available within the Bayesian paradigm for
these factors and to strengthen the original algorithm as well as its exploita-
tion. It was found that built-in independence of entries of dt prevents the full
use of such factors for advising. This makes us use some excellent features
of the MT algorithm only for supporting the decisive learning step, i.e., the
learning initiation.
The considered MT uniform factor makes the static prediction of a real-
valued data entry dt ∈[−1, 1]. The factor is described by the pdf
f(dt|at, d(t −1), Θ) = f(dt|µ) ≡Mdt(µ) ≡
 1−ε
2b
if |dt −µ| ≤b
ε
2(1−b) otherwise
, (12.1)
where the unknown parameter Θ ≡µ ∈[−1 + b, 1 −b]. The width 0 < b < 1
and 0 < ε < 1, ε ≈0 are ﬁxed optional parameters of this pdf.
The sandwich initiation, described here, uses Bayesian methodology for
estimating the key ﬁxed parameter, namely, the box width b. Then, it exploits
the simplicity with which the MT algorithm searches for the box position
at local stationary points in the data space. The local maxima found among
them then serve as initial positions for the ﬁnal Bayesian step described in
detail in Chapter 8.
The MT algorithm moves windows through the data space without chang-
ing the width of the “inspecting” window. This important property can be
exploited more generally by introducing MT normal factors. They are sim-
ply normal pdfs with a ﬁxed noise variance. They allow us to make dynamic
clustering in the vein of uniform MT factors. The normal MT factor is
f(dt|at, d(t −1), Θ) = Ndt(θ′ψt, r),

438
12 Sandwich BMTB for mixture initiation
where Θ ≡θ ≡regression coeﬃcients in θ∗≡˚
ψ-dimensional real space,
ψ is the regression vector and r is a known positive noise variance. These
factors serve the same purpose as MT factors. They are more computationally
demanding but — unlike MT factors — they suit the modelling of dynamic
systems. Their use in the BMTB sandwich is straightforward and therefore is
skipped here. They are discussed in Chapter 13 as they serve for modelling
the dependence of discrete-valued variables on continuous ones.
An important but restricted role of MT factors dictates that the layout of
this chapter diﬀers from that of Chapters 8 and 10. It focuses on facts related
to the selection of the prior pdf f(Θ) for normal mixture estimation.
After preparing common tools, Section 12.1.1, the conceptual BMTB al-
gorithm is described, Section 12.2. Then, the steps creating it, distinguished
by preﬁxes B-, MT and -B, are in Sections 12.3, 12.4 and 12.5, respectively.
12.1 Common tools
12.1.1 Properties of the MT factor
The uniform MT factor is a nonstandard pdf. Thus, it makes sense to evaluate
its moments.
Proposition 12.1 (Moments of the uniform MT factor) Let f(d|µ) =
Md(µ); see (12.1). Then, for i = 0, 1, . . .
E

di|µ

=
ε
2(i + 1)(1 −b)

1 −(−1)i+1 + (µ −b)i+1 −(µ + b)i+1
+
1 −ε
2(i + 1)b

(µ + b)i+1 −(µ −b)i+1
(12.2)
E[d|µ] = µ
#
1 −
bε
1 −b −ε
$
→µ,
cov[d|µ] = b2
3 both for ε →0.
Proof. It follows from the identity
mi ≡E

di|µ

≡

dif(d|µ) dd =
ε
2(1 −b)
 µ−b
−1
di dd +
 1
b+µ
di dd

+ 1 −ε
2b
 µ+b
µ−b
di dd
ε
2(i + 1)(1 −b)

1 −(−1)i+1 + (µ −b)i+1 −(µ + b)i+1
+
1 −ε
2(i + 1)b

(µ + b)i+1 −(µ −b)i+1
.
For i = 1, E[d|µ] = µ
	
1 −
bε
1−b −ε

. The variance is found in a similar way
using the identity cov[d|µ] = E

d2|µ

−E2[d|µ].

12.1 Common tools
439
12.1.2 KL divergence of MT factors
For judging the proximity of a pair of MT factors, we use their KL divergence.
Proposition 12.2 (KL divergence of parameterized MT factors)
Let
dt be a scalar quantity in [−1, 1] and f(d(t)) = /
t∈t∗Mdt(µ),
˜f(d(t)) =
/
t∈t∗Mdt(˜µ); see (12.1). The parameters µ, ˜µ are assumed to be known.
Their KL divergence is given by the formula
D(f|| ˜f) = ˚tKabs(µ −˜µ) with
(12.3)
K ≡1 −ε
2b
ln
(1 −ε)(1 −b)
bε

+
ε
2(1 −b) ln

bε
(1 −b)(1 −ε)

.
Proof.
D(f|| ˜f) ≡

f(d(t)|µ) ln
f(d(t)|µ)
f(d(t)|˜µ)

dd(t) =

t∈t∗

Mdt(µ) ln
Mdt(µ)
Mdt(˜µ)

ddt
=

t∈t∗
 µ+b
µ−b
1 −ε
2b
ln

1 −ε
2bMdt(˜µ)

ddt
+
 µ−b
−1
ε
2(1 −b) ln

ε
2(1 −b)Mdt(˜µ)

ddt
+
 1
µ+b
ε
2(1 −b) ln

ε
2(1 −b)Mdt(˜µ)

ddt
$
.
Let us evaluate a generic term assuming that ˜µ ≤µ
 µ+b
µ−b
1 −ε
2b
ln

1 −ε
2bMdt(˜µ)

ddt +
 µ−b
−1
ε
2(1 −b) ln

ε
2(1 −b)Mdt(˜µ)

ddt
+
 1
µ+b
ε
2(1 −b) ln

ε
2(1 −b)Mdt(˜µ)

ddt
=
 µ+b
˜µ+b
1 −ε
2b
ln
(1 −ε)2(1 −b)
2bε

ddt
+
 µ−b
˜µ−b
ε
2(1 −b) ln

2bε
2(1 −b)(1 −ε)

ddt
= (µ −˜µ)
#1 −ε
2b
ln
(1 −ε)(1 −b)
bε

+
ε
2(1 −b) ln

bε
(1 −b)(1 −ε)
$



K
.
For ˜µ > µ, the role of these variables just exchanges.

440
12 Sandwich BMTB for mixture initiation
12.1.3 Estimation and prediction with MT factors
MT factors do not belong to the exponential family but their estimation is
still relatively simple. They are similar to the uniform pdf with an unknown
center µ and a ﬁxed length 2b. The ﬁxed nonzero value 0.5ε/(1−b) considered
out of the interval [µ −b, µ+ b] prevents the learning from breaking down due
to outlying data.
Proposition 12.3 (Estimation and prediction of the MT factor) Let
natural conditions of decision making, Requirement 2.5, hold, and the MT
factor (12.1) be estimated. Let the uniform prior pdf on [−1 + b, 1 −b] be used
for µ. Then, the posterior pdf of µ has the form
f(µ|d(˚t)) ∝
#1 −ε
2b
$ν(µ,˚t) #
ε
2(1 −b)
$˚t−ν(µ,˚t)
≡Mµ(ν(µ,˚t)), where
(12.4)
ν(µ,˚t) denotes the number of data points among d(˚t) fulﬁlling |dt −µ| ≤b.
The MAP point estimate ˆµ(d(˚t)) of µ maximizes ν(µ,˚t), i.e., ν

ˆµ(d(˚t)),˚t

≥
ν(µ,˚t), ∀µ ∈µ∗≡[−1 + b, 1 −b].
For a given MAP estimate of parameters the Bayesian prediction can be
approximated by the “certainty-equivalence” predictor
f(d|d(t)) ≈Md(ˆµ(d(˚t))).
(12.5)
Proof. By a direct evaluation. The prediction relies on the sharpness of the
posterior pdf f(µ|d(˚t)) around its modes.
The fact that the MT algorithm [67] provides eﬃciently the MAP estimate
ˆµ(d(˚t)) of µ is the main reason for discussing this special factor. Let us recall
the essence of the original MT algorithm [67].
Algorithm 12.1 (Basic MT algorithm)
Initial mode
•
Remove outliers from the raw data.
•
Normalize data d(˚t) so that they belong to [−1, 1].
•
Select the parameter 0 < b < 1.
•
Select the initial guess ˆµ0 in µ∗≡[b −1, 1 −b].
•
Select the upper bound ˚n on the number n of iterations.
Iterative mode
For
n = 1, . . . ,˚n
Set ˆµn ≡sample mean of data belonging to [ˆµn−1 −b, ˆµn−1 + b] .
Break if |ˆµn −ˆµn−1| < ε.
end
of the cycle over n

12.2 Conceptual BMTB algorithm
441
Remark(s) 12.1
1. The algorithm is described for a scalar dt. It is applicable in high dimen-
sions without a change and with a very low additional computational cost.
2. The estimation stops at the local maximum of the empirical pdf of data.
This ﬁts in well with our wish to ﬁnd all signiﬁcant modes since the local
extremes are of direct interest.
3. The adequate choice for the ﬁxed parameters of the MT factor decides
upon the achieved quality. Their tuning is described below. It is based on
practical similarity of uniform and normal factors. Essentially, a normal
static mixture is ﬁtted to the considered scalar normalized data and its
(averaged) standard deviation is taken as b. The found mean value of
the normal pdf may serve as an initial guess of the unknown µ (B-step).
This connection is used in the opposite direction, too. The MT factors
estimated in the MT step provide initial positions of factors in the ﬁnal
normal mixture (-B step).
4. The considered normalization is quite sensitive to outlying data. Their
presence shrinks data points too much; consequently, some modes are eas-
ily “over-looked” during clustering.
5. Estimation of the mixture consisting of MT components is extremely sim-
ple and fast. It serves well as a good starting point for the estimation of
normal mixtures that are able to describe correlation between entries of the
multivariate record d. It is important in order to grasp dynamic properties
of the modelled system: MT factors make static clustering of dynamic data;
see Section 6.4.9.
6. MT factors are tightly related to histograms with a ﬁxed box length dis-
tributed on a variable orthogonal grid.
7. Many windows describing MT factors can be shifted in parallel.
8. The original MT algorithm lacks
•
systematic but feasible initiation of the MT algorithm for large data
sets, for large ˚t,
•
recognition of whether the reached stationary point is a local minimum
or maximum,
•
systematic merging and cancelling of components,
•
structure estimation whenever MT algorithm is applied to dynamic
data as reﬂected in Proposition 6.17.
These aspects are also addressed here.
12.2 Conceptual BMTB algorithm
As said above, this chapter describes an attempt to use simplicity of the MT
algorithm and its ability to ﬁnd eﬃciently local stationary points in the data
space. The initial univariate Bayesian estimation, B-step on respective data
axes, serves well for the choice of critical parameters of the MT algorithm.

442
12 Sandwich BMTB for mixture initiation
Then, the MT algorithm is applied. The obtained restricted results are ex-
tended to the initial mixture. This initial mixture resulting from BMT part of
the discussed “sandwich” initializes the complete Bayesian estimation, which
forms the ﬁnal -B step.
Particular steps of the following conceptual BMTB algorithm are elab-
orated on subsequent sections. The presentation is predominantly made for
multivariate static components, i.e., in terms of data records dt. It is worth
stressing that the dynamic case is addressed simply by treating data vectors
Ψt instead of the data records.
Algorithm 12.2 (Conceptual BMTB algorithm)
B-step, run for i = 1, . . . , ˚
d,
Initial mode
•
Remove outliers.
•
Normalize the data so that the majority of them have entries in the range
[−1, 1].
•
Specify the initial, univariate normal mixture covering safely and uniformly
the whole range [−1, 1].
Learning mode
•
Use an approximate Bayesian estimation on axes di(˚t) (Section 8.5) for
learning this normal mixture.
•
Specify box widths bi speciﬁc to the considered entry di(˚t).
MT step
Initial mode
•
Select the structure of the data vectors Ψ to be described by the static
normal mixture as justiﬁed by Proposition 6.17.
•
Specify optional parameters of the MT step using estimation results ob-
tained in the B-step.
Learning mode
•
Apply the MT algorithm to get initial guesses of cluster positions in the
space of data vectors Ψ ∗.
•
Use the BMT results for deﬁning an initial guess of the mixture estimated
in the -B step.
-B step
Initial mode
•
Specify optional parameters of the Bayesian initialization and subsequent
estimation using the BMT results.
Learning mode
•
Apply an initiation algorithm for normal mixtures (see Section 8.4) using
the initial mixture obtained in the BMT steps.

12.3 B-step: preparation of MT parameters
443
•
Apply iterative learning to the mixture obtained; see Section 8.5.
•
Validate the model; see Section 8.7. Stop if validation is successful; other-
wise go to MT step.
12.3 B-step: preparation of MT parameters
One-dimensional static mixtures are estimated in this step. For the consid-
ered purpose, it is suﬃcient to initialize the mixture estimation by selecting
a suﬃciently high number of components ˚c, typically a few tens. The initial
positions of component estimates are equidistantly distributed over the dom-
inant range of scaled data, i.e., over the interval [-1,1]. Components can be
just shifted copies of a normal pdf. Their common noise variance should make
them distinguishable but overlapping, so that distance of centers should be
about 4 to 6 standard deviations of noise and the parameter variance should
be of the order of the noise variance. These values should be suﬃciently ﬁxed,
so that the standard recommended value of degrees of freedom νi;0 ≈0.1˚t
is applicable; see Remark 6.5. Universally, equal component weights respect-
ing the recommendation κc;0 ≈0.1˚t/˚c can be and should be chosen. Let us
summarize formally the B-step.
Algorithm 12.3 (Initialization of B-step: apply entrywise!)
1. Perform data preprocessing with outlier removal.
2. Scale the data to have zero mean and unit variance.
3. Select the number ˚c ≈20 of univariate components.
4. Deﬁne νi;0 ≈0.1˚t, i = 1, . . . , ˚
d, κc;0 ≈0.1˚t/˚c, c = 1, . . . ,˚c.
5. Deﬁne the distance between component centers s = 2
˚c.
6. Complement the deﬁnition of the prior pdf by selecting L′DL decomposi-
tion of respective extended information matrices as follows
Lc;0 =
#
1
0
−1 +

c −1
2

s 1
$
,
Dc;0 ≡D0 =

(ν0−2)s2
16
1

,
c ∈c∗.
The learning mode consists of a direct application of the normal mixture
estimation, presented in Section 8.5, to this static univariate mixture. Thus,
it remains to use its results for selection of box widths and possibly of initial
positions of boxes entering the MT algorithm. The discussion is formalized
with the help of the following simple proposition.
Proposition 12.4 (Extension of single variate pdfs)
Let f(x), f(y) be
a pair of pdfs and let us search for the joint pdf f(x, y) that
1. has f(x), f(y) as its marginal pdfs, i.e., f(x) =

f(x, y) dy, f(y) =

f(x, y) dx,

444
12 Sandwich BMTB for mixture initiation
2. is the most uncertain among such pdfs (in order to respect just the con-
sidered constraints); the KL divergence to a uniform, possibly improper,
pdf is taken as the measure of uncertainty.
Then, f(x, y) = f(x)f(y).
Proof. We minimize a convex functional on a convex set so the we can formu-
late the problem in terms of the Lagrangian functional

f(x, y) [ln (f(x, y)) + λ(x) + λ(y)] dxdy
=

f(x, y) ln
⎛
⎜
⎜
⎝
f(x, y)

exp[−λ(x)−λ(y)]

exp[−λ(˜x)−λ(˜y)] d˜xd˜y

⎞
⎟
⎟
⎠dxdy
−ln

exp[−λ(˜x) −λ(˜y)] d˜xd˜y

= D

f(x, y)
!!!!
!!!!
exp(−λ(x))

exp[−λ(˜x)] d˜x
exp(−λ(y))

exp[−λ(˜y)] d˜y

−ln

exp[−λ(˜x)] d˜x

−−ln

exp[−λ(˜y)] d˜y

.
The Lagrangian multipliers λ(x), λ(y) have to be chosen so that the ﬁrst
requirement is met. The KL distance forming the ﬁrst term in the last identity
is minimized by the pdf in product form. The choice λ(x) = −ln(f(x)) λ(y) =
−ln(f(y)) meets the ﬁrst constraint. The uniqueness of the minima implies
that we have found the optimum.
We would like to extend the mixtures on individual data entries to mix-
tures on the overall data space. The above proposition shows why it is not
possible exactly for the target dimensions ˚
d on the order of several tens. The
number of multivariate components that have the speciﬁed marginal pdfs is
extremely large and the majority of them are spurious. The spurious compo-
nents are simply shadows of the true components. Their exclusion is called
the shadow cancelling problem. The general solution of the above problem is
computationally hard. A promising version is outlined in [173] and elaborated
on in Section 12.3.2. Before it, a simpler version ﬁtting the studied sandwich
algorithm is proposed.
12.3.1 Simple choice of box width
The simple solution given here neglects information on the component centers
and, for each individual data axis di;t, it speciﬁes a single box width used
further on.
The scalar normal mixture estimated for a given data record axis says
that with probability αc the noise variance is rc. The posterior pdf of α is

12.3 B-step: preparation of MT parameters
445
the Dirichlet pdf Diα(κ˚t). It is determined by the statistic κ˚t; see Proposition
10.1. The adopted approximate Bayesian estimation, Section 8.5 implies that
the joint posterior pdf of rc, c ∈c∗, is the product of the inverse Wishart
pdfs (8.23) f(rc|d(˚t)) ≡iWrc
 ⌊dDc;˚t, νc;˚t

∝r
−0.5(νc;˚
t+2)
c
exp
#
−
⌊dDc;˚
t
2rc
$
. They
are determined by the LS remainders
⌊dDc;˚t and the numbers of degrees of
freedom νc;˚t; see Proposition 8.7. We search for a single representative of these
pdfs.
Proposition 12.5 (Representative of a group of iWrc pdfs)
The pdf
f(r|d(˚t)) ≡iWr
2
c∈c∗ˆαc;˚t
⌊dDc;˚t, 2
c∈c∗ˆαc;˚tνc;˚t

with ˆαc;˚t =
κc;˚
t
2
c∈c∗κc;˚
t min-
imizes the expected KL divergence
E

c∈c∗
αc

f(r|d(˚t)) ln

f(r|d(˚t))
f(r = rc|d(˚t))

dr

.
Proof. Proposition 2.7 implies that we have to minimize the conditional ex-
pectation E[·|d(˚t)] of the loss. It reads

c∈c∗
ˆαc;˚t

f(r|d(˚t)) ln

f(r|d(˚t))
f(rc = r|d(˚t))

dr
=

f(r|d(˚t)) ln
0
f(r|d(˚t))
/˚c
c=1

f(rc = r|d(˚t))
ˆαc;˚
t
1
dr
= D
0
f(r|d(˚t))
!!!!!
!!!!!
/
c∈c∗

f(r = rc|d(˚t))
ˆαc;˚
t
 /
c∈c∗

f(r = rc|d(˚t))
ˆαc;˚
t dr
1
−ln
0
 
c∈c∗

f(r = rc|d(˚t))
ˆαc;˚
t dr
1
.
Properties of the KL divergence imply that the minimizing pdf is the weighted
geometric mean of pdfs corresponding to particular components. The weighted
geometric mean of iW pdfs is iW pdf with the statistics being weighted arith-
metic means of the combined statistics.
The expected variance ˆr corresponding to the found representative is
ˆr =
2
c∈c∗ˆαc;˚t
⌊dDc;˚t
2
c∈c∗ˆαc;˚t ⌊dνc;˚t −2.
This common estimate of the noise variance ˆr is converted into the box width
b by using probabilistic interpretation (12.1) of MT factors. For a negligible ε,
they are simply uniform pdfs with half-width equal to b. The overall algorithm
for determining the box width b we get by equating its variance b2/3 with the
adequate point estimate of r, which is the expected value of the pdf obtained
in Proposition 12.5.

446
12 Sandwich BMTB for mixture initiation
Algorithm 12.4 (Choice of box widths for respective data axes)
Initial phase
•
Initiate univariate normal mixture estimation using Algorithm 12.3.
•
Estimate approximately the parameters of the normal mixture.
Evaluation phase
Deﬁne box width
b =
C
3
2
c∈c∗ˆαc;˚t ⌊dDc;˚t
2
c∈c∗ˆαc;˚t ⌊dνc;˚t −2.
(12.6)
12.3.2 Centers and box widths via shadow cancelling
The solution presented above neglects the information on positions of one-
dimensional projections of cluster centers. Moreover, it works with an average
variance estimate. The latter item was found to be critical when both very
narrow and wide clusters are needed. This situation is often met, for instance,
in the application on rolling mill; see Section 14.1. This makes us consider the
shadow cancelling problem (see Chapter 6) and to apply the solution proposed
in the paper [151] while relying on an algorithm described in [173].
The solution is built stepwise.
1. The prior and posterior pdfs on a multivariate component are constructed
by using a ﬁxed selection of marginal components as a building material.
The selection is coded by an index vector. The corresponding component
weight is also assigned to prior and posterior pdfs. Propositions 12.4 and
6.5 motivate the combination selected.
2. The v-likelihood corresponding to the inspected index vector is predicted
using ideas developed in connection with the merging of components; see
Section 6.6.4.
3. The optimization algorithm, proposed in [173], and selecting a given num-
ber of index vectors leading to the highest v-likelihood, is applied. The
algorithm enables us to ﬁnd a relatively large number of potential multi-
variate components that, after appropriate ﬂattening, serve as initial po-
sitions and box widths for the MT step or can be directly used as initial
estimates of the normal mixture.
Step 1 We assume that the modelled system is described by the normal static
mixture written in the matrix form
f(dt|Θ) =

c∈c∗
αcNdt(θc, Rc)
with the ˚
d-vector expected values θc and diagonal covariance matrices Rc.
The marginal pdf on the ith axis is the mixture
f(di;t|Θ) =

c∈c∗
αcNdi;t(θic, ric),

12.3 B-step: preparation of MT parameters
447
where the probabilistic weights αc coincide with that of the multivariate
mixture, θic is the ith entry of θc and ric the ith diagonal entry of Rc. The
posterior pdfs obtained through the estimation of “marginal” mixtures on
respective axes are
f(θi1···˚ci, ri1···˚ci, α|di(τ)) =
˚ci
 
ci=1
GiWθici,rici(Vici;τ, νici;τ)Diα(κi1···˚c;τ),
where τ = ˚t. The result is valid if the conjugate prior of the same form
but with τ = 0 is used. For notation and derivation; see Chapter 8. The
constructed approximate multivariate components are indexed by m ∈
m∗≡{1, . . . , ˚
m}. The mth approximate component is identiﬁed by the
index vector
⌊mc ≡
 ⌊mc1, . . . , ⌊mc˚
d
′. It is chosen so that it points to a
single marginal component ⌊mci on each axis i = 1, . . . , ˚
d. It selects ⌊mcith
univariate components
f(θi ⌊mci, ri ⌊mci|di(τ)) = GiWθi ⌊mci,ri ⌊mci(Vi ⌊mci;τ, νi ⌊mci;τ).
(12.7)
We interpret the pdfs (12.7) as marginal pdfs of the constructed estimate
of the multivariate parameters of the normal, static, parameterized com-
ponent Nd (θ ⌊mc, R ⌊mc). Using Proposition 12.4, the extension of these
marginal pdfs to ˚
d-dimensional space, corresponding to the index vector
⌊mc, reads
f(θ ⌊mc, R ⌊mc|d(τ)) =
˚
d
 
i=1
GiWθi ⌊mci,ri ⌊mci(Vi ⌊mci;τ, νi ⌊mci;τ), τ = 0,˚t.
For the used univariate static mixtures, we deal with (2,2)-dimensional
extended information matrices Vi ⌊mci;τ. Their L′DL decompositions are
Li ⌊mci;τ =
#
1
0
ˆθi ⌊mci;τ 1
$
, Di ⌊mci;τ = diag
	
⌊dDi ⌊mci;τ, ⌊ψDi ⌊mci;τ

,
where ˆθi ⌊mci;τ is the least-squares (LS) estimate of the oﬀset, ⌊dDi ⌊mci;τ
is the LS remainder and
⌊ψDi ⌊mci;τ coincides with the LS-estimates co-
variance factor, respectively.
Furthermore, using Proposition 10.1, we get the marginal pdfs of weights
of univariate mixtures, i = 1, . . . , ˚
d, τ ∈{0,˚t},
fi ≡f(α ⌊mci|di(τ)) = Diα ⌊mci
0
κi ⌊mci;τ,
˚c

c=1
κic;τ −κi ⌊mci;τ
1
.
(12.8)
They provide the only available experience P for constructing the estimate
f ≡f(α ⌊mc|P) of the objective pdf ⌊of ≡⌊of(α ⌊mc|d(τ)). The estimate is

448
12 Sandwich BMTB for mixture initiation
chosen as the minimizer of the expected KL divergence. Proposition 2.7
implies that it minimizes
E
	
D

f
!!!
!!! ⌊of
!!! P

.
The conditional expectation E[·|P] over the unknown pdf ⌊of is assumed
to assign equal probabilities of the sets
 ⌊of ≡⌊of(α|d(τ)) :
⌊of ≈fi

.
Under this assumption, the optimal estimate f of
⌊of is the geometric
mean of the pdfs forming P; cf. Proposition 6.5. Thus, for a chosen ⌊mc,
the Bayesian estimate of the weight α ⌊mc assigned to the multivariate
component in question, becomes
f(α ⌊mc|d(τ))
(12.9)
≡Diα ⌊mc
⎡
⎣1
˚
d
˚
d

i=1
κi ⌊mci;τ, 1
˚
d
˚
d

i=1
⎛
⎝

c∈{1,...,˚c}
κic;τ −κi ⌊mci;τ
⎞
⎠
⎤
⎦.



κ ⌊mc;τ



ρτ −κ ⌊mc;τ
The found estimates f(α ⌊mc|d(τ)), m = 1, . . . , ˚
m, are marginal pdfs of
the joint pdf f(α|d(τ)) describing the collection α =
 ⌊1α, · · · , ⌊˚
mα

of
the probabilistic weights of the multivariate mixture. Properties of the
Dirichlet pdf (Proposition 10.1) imply that the pdf
f(α|d(˚t)) = Diα(κ1;τ, . . . , κ˚
m;τ) ≡Diα(κτ)
(12.10)
has the marginal pdfs (12.9). This motivates us to take the pdf (12.10),
with the κ statistics having the entries κ ⌊mc;τ deﬁned in (12.9), as the
estimate of mixture-components weights.
Step 2 For the chosen index vector ⌊mc, Step 1 provides the prior and pos-
terior pdfs on parameters of the component
⌊mc for τ = 0 and τ = ˚t
respectively. The Bayes rule (2.8), applied to data belonging to the ⌊mcth
component, implies that
f

θ ⌊mc, R ⌊mc|d(˚t), ⌊mc

= L

θ ⌊mc, R ⌊mc, d(˚t)

f

θ ⌊mc, R ⌊mc|d(0), ⌊mc

f

d(˚t)| ⌊mc

.
This identity holds for arbitrary parameters and the likelihood function
L

θ ⌊mc, R ⌊mc, d(˚t

evaluated for θ ⌊mc = 0 and R ⌊mcI˚
d is independent of
⌊mc. It provides the following estimate of the v-likelihood related to the
respective index vectors
f

d(˚t)| ⌊mc

= L

θ ⌊mc = 0, R ⌊mc = I˚
d, d(˚t)

f

θ ⌊mc = 0, R ⌊mc = I˚
d|d(0), ⌊mc

f

θ ⌊mc = 0, R ⌊mc = I˚
d|d(˚t), ⌊mc

.

12.3 B-step: preparation of MT parameters
449
This expression can be made more speciﬁc by omitting ⌊mc-independent
factors; cf. formulas (8.22) and (10.3). Moreover, the identity, Proposition
8.7, is used
⌊dVi ⌊mci;τ = ⌊dDi ⌊mci;τ + ˆθ2
i ⌊mci;τ
⌊ψD ⌊mci;τ,
τ ∈{0,˚t}.
It results in the ﬁnal expression
f

d(˚t)
!!! ⌊mc

∝exp

−0.5tr
 ⌊dV ⌊mc;0

I(V ⌊mc;0, ν ⌊mc;0)
I(V ⌊mc;˚t, ν ⌊mc;˚t)
exp

−0.5tr
 ⌊dV ⌊mc;˚t
 ∝exp
⎡
⎣1
2
˚
d

i=1

⌊dD ⌊mci;˚t −⌊dD ⌊mci;0 + ˆθ2
⌊mci;˚t
⌊ψD ⌊mci;˚t −ˆθ2
⌊mci;0
⌊ψD ⌊mci;0

⎤
⎦
×
˚
d
 
i=1
Γ(0.5ν ⌊mci;˚t) ⌊dD
0.5ν ⌊mci;0
⌊mci;0
⌊ψD0.5
⌊mci;0
Γ(0.5ν ⌊mci;0) ⌊dD
0.5ν ⌊mci;˚
t
⌊mci;˚t
⌊ψD0.5
⌊mci;˚t
.
(12.11)
Step 3 For any choice of the index vector ⌊mc, formula (12.11) provides the
corresponding v-likelihood. Thus, we can search for the ˚
m best extensions.
The number of the index vectors is, however, extremely large so that
an adequate search algorithm is needed. An algorithm solving a speciﬁc
index-based maximization task is suitable. First, the task is speciﬁed and
its solution is described. Then, it is connected with the addressed problem.
Let us consider a set (x∗, >) linearly ordered according to values of the
function l(x). We also consider its ˚
d-fold Cartesian product ordered ac-
cording to the values of a scalar function L

x1(˚c1), . . . , x˚
d(˚c˚
d)

deﬁned on
a priori given, nonempty ﬁnite sequences xi(˚ci) ≡(xi1, xi2, . . . , xi˚ci) , i =
1, . . . , ˚
d, xic ∈x∗. The lengths of respective sequences ˚ci ∈(0, ∞) may
diﬀer and the function L(·) is assumed to be isotonic, i.e.,
l(xic) > l(˜xic) ⇒L(xi1, . . . , xic, . . . , xi˚c) > L(xi1, . . . , ˜xic, . . . , xi˚c).
(12.12)
We inspect values of
L

⌊mc

≡L

⌊mx1 ⌊mc1, ⌊mx2 ⌊mc2, . . . , ⌊mx˚
d ⌊mc˚
d

(12.13)
while taking just one item ⌊mxi ⌊mci from each sequence xi(˚ci), i = 1, . . . , ˚
d.
We search for indexes forming index vectors
⌊mc ≡
	
⌊mc1, ⌊mc2, . . . , ⌊mc˚
d

(12.14)
giving ˚
m largest values of L(·) with arguments of the form (12.13).
The set containing all potential index vectors (12.14) has the form
⌊•c∗=

⌊•c ≡[c1, c2, . . . , c˚
d] | 1 ≤ci ≤˚ci, ∀i = 1, 2, . . . , ˚
d

.

450
12 Sandwich BMTB for mixture initiation
The addressed index-based maximization task is formalized as follows.
Find diﬀerent index vectors ⌊mc ∈⌊•c∗, m = 1, . . . , ˚
m ≤⌊•˚c
min
⌊•c∈{ ⌊1c, ⌊2c,..., ⌊˚
mc} L

⌊•c

≥max
⌊•c∈⌊•c∗\{ ⌊1c, ⌊2c,..., ⌊˚
mc}L

⌊•c

.
Verbally, the worst index vector from the constructed set is better than the
best index vector from its complement. Algorithm 12.5 given below solves
the formulated task. The paper [173] proves it. The following symbols are
used.
C denotes a sequence of index vectors. It contains the optimal index vec-
tors when the algorithm stops.
⌊aC is an auxiliary sequence containing the candidates for the optimal
index vectors.
S is the sequence of sons of the last index vector in C. A son of the index
vector ⌊•c has the form ⌊•c + ei, where ei is ˚
d-vector having the only
nonzero value equal 1 on ith position.
ΣA is the sequence of the values L(·) assigned to members of the sequence
A of index vectors.
Algorithm 12.5 (Algorithm solving the index maximization)
Initial mode
•
Order the input sequences in the nonincreasing manner
l(xi1) ≥l(xi2) ≥· · · ≥l(xi˚ci), i = 1, . . . , ˚
d.
•
Set C = 1˚
d ≡[1, 1, . . . , 1]



˚
d−times
, ⌊aC = ∅and 2 ⌊aC = ∅.
Iterative mode
1. Return C and stop if length(C) = ˚
m.
2. Set S = ∅and ΣS = ∅.
3. For i = 1, 2, . . . , ˚
d If Cilength(C) < ˚ci put Clength(C) + ei as the last
member of S and L(Clength(C) + ei) as the last member of ΣS.
4. Sort the sequence ΣS in a nondecreasing order and sort the sequence
S using the same rule.
5. Merge the sequences Σ ⌊aC and ΣS while placing the equal items from
Σ ⌊aC ﬁrst and merge the sequences ⌊aC and S using the same rule.
6. Erase duplicates from the sequence
⌊aC as well as the corresponding
members from Σ ⌊aC.
7. Preserve the initial min {˚
m−length(C), length( ⌊aC)} members of both
Σ ⌊aC and ⌊aC, erase all others.
8. Delete the ﬁrst member from Σ ⌊aC while deleting the ﬁrst member
from ⌊aC and placing it as the last member of C.
9. Go to the beginning of Iterative mode.

12.3 B-step: preparation of MT parameters
451
Now we apply this algorithm in order to ﬁnd index vectors ⌊•c that combine
properly selected components on individual axes so that the each constructed
multivariate component has a high v-likelihood.
The linearly ordered set x∗consists of statistics
xic ≡

νic;˚t, νic;0, ˆθic;˚t, ˆθic;0, ⌊dDic;˚t, ⌊dDic;0, ⌊ψDic;˚t, ⌊ψDic;0

.
The individual statistics are ordered according to the value of the v-log like-
lihood xic > x˜i˜c ⇔l(xic) > l(x˜i˜c), where
l(xic) ≡0.5

⌊dDic;˚t −⌊dDic;0 + ˆθ2
ic;˚t
⌊ψDic;˚t −ˆθ2
ic;t
⌊ψDic;0

+ ln
⎛
⎝Γ(0.5νic;˚t) ⌊dD0.5νic;0
ic;0
⌊ψD0.5
ic;0
Γ(0.5νic;0) ⌊dD
0.5νic;˚
t
ic;˚t
⌊ψD0.5
ic;˚t
⎞
⎠.
The sum of the marginal v-log likelihoods deﬁnes the function L(·) assigned
to each index vector. Summing meets obviously the monotonicity property
(12.12). It conﬁrms the possibility to use Algorithm 12.5 to our problem.
This option ﬁnishes extension of the marginal posterior pdfs to the overall
description of the multivariate mixture as the choice of index vectors deter-
mines also the estimate of component weights; see the discussion of the ﬁrst
step.
In order to avoid falsely low uncertainty, it is necessary to ﬂatten the
constructed estimate; see Section 6.4.3. It is wise to select separate ﬂattening
rates λD ∈(0, 1), λ ∈(0, 1) so that the resulting sums of counters κ and of
degrees of freedom ν are equal to the sums of prior values, respectively.
Let us describe the overall algorithm.
Algorithm 12.6 (Index-vector-based initiation of MT algorithm)
Initial mode
• Remove outliers and normalize the data so that the majority of them has
entries in the range [−1, 1].
• Specify the prior and posterior pdfs on univariate components
For
i = 1, . . . , ˚
d
Specify the number of components ˚ci and shift in positions si = 2
˚ci
For
c = 1, . . . ,˚ci
Select statistics κic;0 ≈0.1˚t/˚c, νic;0 ≈1, ˆθic;0 = −1 + (c −0.5)si
⌊dDic;0 = (νic;0 −2)s2
i
16
,
⌊ψDic;0 = 1
end
of the cycle over c
end
of the cycle over i

452
12 Sandwich BMTB for mixture initiation
For
i = 1, . . . , ˚
d
Estimate univariate mixture using data di(˚t).
For
c = 1, . . . ,˚ci
Form the statistics describing both prior and posterior pdf
xic ≡

νic;˚t, νic;0, ˆθic;˚t, ˆθic;0, ⌊dDic;˚t, ⌊dDic;0, ⌊ψDic;˚t, ⌊ψDic;0

Evaluate the individual v-log-likelihood
lic = 0.5

⌊dDic;˚t −⌊dDic;0 + ˆθ2
ic;˚t
⌊ψDic;˚t −ˆθ2
ic;0
⌊ψDic;0

+ ln
⎛
⎝Γ(0.5νic;˚t) ⌊dD0.5νic;0
ic;0
⌊ψD0.5
ic;0
Γ(0.5νic;0) ⌊dD
0.5νic;˚
t
ic;˚t
⌊ψD0.5
ic;˚t
⎞
⎠
end
of the cycle over c
Order xi = [xi1, . . . , xi˚ci] so that li1 ≥li2 ≥· · · ≥li˚ci
end
of the cycle over i
•
Select the number ˚
m of constructed multivariate components.
•
Apply Algorithm 12.5 on the constructed sequences xi = [xi1, . . . , xi˚ci] to
get index sequences ⌊mc =
 ⌊mc1, . . . , ⌊mc˚
d

, m = 1, . . . , ˚
m.
Evaluation mode
For
m = 1, . . . , ˚
m
Specify the posterior pdf on parameters of multivariate components
f

θ ⌊mc, R ⌊mc
!!!d(˚t), ⌊mc

=
˚
d
 
i=1
GiWθi ⌊mci,ri ⌊mci(Vi ⌊mci;˚t, νi ⌊mci;˚t)
≡
˚
d
 
i=1
GiWθi ⌊mci,ri ⌊mci

ˆθi ⌊mci;˚t, ⌊dDi ⌊mci;˚t, ⌊ψDi ⌊mci;˚tνi ⌊mci;˚t

.
Specify the statistics of the pdf on component weights
κ ⌊mc;τ = 1
˚
d
˚
d

i=1
κi ⌊mci;τ, τ ∈{0,˚t}.
One-shot ﬂattening, Section 6.4.3, gives the constructed prior pdf f(Θ| ⌊mc).
Use the centers ˆθ ⌊mc as initial positions for the MT algorithm and recompute
the corresponding marginal variances of data to the box widths
b ⌊mci =
C
3
⌊dDi ⌊mci
νi ⌊mci −2
	
1 + ⌊ψD−1
i ⌊mci

,
cf. (8.31).
end
of the cycle over m

12.4 MT step: make the MT algorithm feasible
453
12.4 MT step: make the MT algorithm feasible
The original MT algorithm proved to be unsuitable for the target extent of
data sets ˚t ≈105. This stimulated a search for improvements. Algorithm 12.6
provides a rather promising solution. Here, alternative and complementary
improvements are discussed.
12.4.1 Initialization
The original MT algorithm selects gradually each data record dt, t ∈t∗as
the initial center of the box for searching of stationary positions. This safest
way is, however, too expensive for data ﬁles containing more than several tens
of thousand records. Then, an incomplete search is necessary.
Random starts provide an alternative to an exhaustive search. It can be
speeded up signiﬁcantly by exploiting the deterministic nature of the MT
algorithm. Essentially, the visited data records that would lead to the same
trajectory are excluded from a further search. We want to preserve simplicity
of the algorithm. For this reason, we want to recognize such points treated in
connection with the box in question.
Considering a ﬁxed axis, we can analyze univariate case. Let ˆd be a center
of the inspected box. Let us deﬁne
D ≡min{dt : dt > ˆd + b}t∈t∗
the smallest data record right to the box
D ≡max{dt : dt < ˆd −b}t∈t∗
the largest data record left to the box
d ≡max{dt : dt ≤ˆd + b}t∈t∗
the largest data record within the box
d ≡min{dt : dt ≥ˆd −b}t∈t∗
the smallest data record within the box.
(12.15)
These bounds specify ranges of data safely outside (D, D) and safely inside
(d, d) the inspected box trajectory.
We arrive at the same intermediate and ﬁnal box center if we replace ˆd by
any ˜dt (in this box) such that the box centered in this data record contains
the same data records. Formally:
˜dt ≤d + b, ˜dt < D −b
˜dt ≥d −b, ˜dt > D + b.
Thus, all such data points can be excluded from the set of potential starting
points. Evaluation of D, D, d, d can be done simultaneously when searching
for the points belonging to the inspected box. The comparisons needed for
determination of points ˜d can again be made cheaply on the data belonging
to the box. It is suﬃcient to store them temporarily.

454
12 Sandwich BMTB for mixture initiation
12.4.2 Merging and cancelling of centers
Merging and cancelling of boxes are now performed in the MT step using ad
hoc rules for their closeness or (almost) emptiness. Within the “sandwich”
context, it is possible to postpone this action to the beginning of the -B step;
see Section 12.5. It is suﬃcient to apply cancelling and merging of Gaussian
components (see Section 8.6.4) that arise from the MT factors in the -B step.
If need be, we can use ﬁniteness of the KL divergence of a pair of MT
factors (see Proposition 12.2) in order to decrease the number of components
before entering the -B step; Section 12.5. For this, let us consider the set f ∗of
the MT components having the common box width and individual pdfs f, ˜f
deﬁned by centers µ, ˜µ. Then,
ρ(µ, ˜µ) ≡
D

f
!!!
!!! ˜f

supf∈f ∗, ˜
f∈f ∗D(f|| ˜f)
=
˚
d

i=1
|µi −˜µi|
2
.
(12.16)
Thus, we can take µ, ˜µ as identical if ρ(µ, ˜µ) is a small number, say of the
order 10−3.
12.4.3 Recognition of a false local maximum
Updating a box center ˆµ ends when it does not shift any more. It may, how-
ever, happen that the window sits between data clusters. We counteract this
situation by formulating and testing the following hypothesis.
H0 : the data dk, k ∈k∗≡{1, . . . ,˚k} within the box [ˆµ −b, ˆµ + b] have the
uniform pdf Ud (ˆµ −b, ˆµ + b),
H1 : the data dk, k ∈{1, . . . ,˚k1} fulﬁlling the inequality dk ≤ˆµ have the
uniform pdf Ud (ˆµ −b, ˆµ −b1) and the data dk, k ∈{˚k1+1, . . . ,˚k} fulﬁlling
the inequality dk > ˆµ have the uniform pdf Ud (ˆµ + b2, ˆµ + b).
The corresponding models relating observations to respective hypotheses are
given by the following formulas.
f(dk|H0) = Udk (ˆµ −b, ˆµ + b) = 1
2b
⇒

static case
f(d(˚k)|H0) = (2b)−˚k
f(dk|b1, b2, H1) = χ[ˆµ−b,ˆµ−b1](dk)
2(b −b1)
+ χ(ˆµ+b2,ˆµ+b](dk)
2(b −b2)
⇒

static case
f(d(˚k)|b1, b2, H1) = χ[ˆµ−b,ˆµ−b1]( ¯d1) × χ(ˆµ+b2,ˆµ+b](d2)
2˚k(b −b1)˚k1(b −b2)˚k−˚k1
,
where ˚k is the number of data points within the inspected box. ˚k1 denotes
the number of data points among them fulﬁlling the inequality dk ≤ˆµ and

12.4 MT step: make the MT algorithm feasible
455
¯d1 their maximum. The minimum of the data dk being within the box and
fulﬁlling dk > ˆµ is denoted d2.
Taking uniform prior pdfs f(bi) = Ubi(0, b), i = 1, 2, we get
f(d(˚k)|H1) =
1
2˚kb2
 ˆµ−d1
0
(b −b1)−˚k1 db1
 d2−ˆµ
0
(b −b2)−˚k+˚k1 db2
=
1
2˚kb2
(b −ˆµ + d1)−˚k1+1 −b−˚k1+1
(˚k1 −1)
(b + ˆµ −d2)−˚k+˚k1+1 −b−˚k+˚k1+1
˚k −˚k1 −1
.
Using the Bayes rule without prejudice, we get
f(H0|d(˚k)) =
f(d(˚k)|H0)
f(d(˚k)|H0) + f(d(˚k)|H1)
.
(12.17)
When dealing with the multivariate data records, the entry-related quantities
are conditionally independent and, for ι ∈{0, 1}, f(d(˚k)|Hι) = /˚
d
i=1 f(di(˚k)|Hiι),
where Hiι refers to the hypothesis ι on the ith axis.
With these probabilities, it is straightforward to cancel those centers for
which the posterior probability f(H0|d(˚k)) is too small.
12.4.4 Improved MT algorithm
The above ideas lead to the following improved version of the MT algorithm.
Algorithm 12.7 (Improved MT algorithm )
Initial mode
•
Remove outliers from data sample d(˚t); see Section 6.2.2.
•
Normalize resulting data to the range [−1, 1]˚
d.
•
Attach to each data record dt of the resulting data the ﬂag gt = 1 ≡
ready to serve as starting point.
•
Select widths of box bi, i = 1, . . . , ˚
d, for individual data channels di;t, using
the B-step; see Section 12.3.
•
Select the upper bound ˚n on the number n of iterations.
•
Select the signiﬁcance level ε ∈

10−3, 10−5
, used for cancelling of local
minima and “merging” level, i.e., deﬁne small values of (12.16).
•
Initialize the list C of found centers, C =empty list, and the numbers κ =
of points in them, κ =empty list.
Iterative mode
For
n = 1, . . . ,˚n
Select a starting center ˆd = a data record with ﬂag gt = 1.
Set d = D = +∞× 1˚
d, d = D = −∞× 1˚
d.
Set e = +∞.

456
12 Sandwich BMTB for mixture initiation
REPEAT while the data center move, while e > ε.
Initialize list Υ of data in the box, Υ = empty list and
the number ˚k of points within the inspected box, ˚k = 0.
For
t = 1, . . . ,˚t
Set the flag in = 1(point is in box) and ﬁnd all data in
the current box and evaluate the bounds Di, di, Di, di; see (12.15),
For
i = 1, . . . , ˚
d
IF di;t > ˆdi + bi
Di = min

di;t, Di

,
flag in = 0.
ELSE
If di;t < ˆdi −bi
Di = max (di;t, Di) ,
flag in = 0
end of the ELSE
end
of the cycle over i
If flag in = 1
For i = 1, . . . , ˚
d
di = min (di;t, di) ,
di = max

di;t, di

end of the cycle over i.
Set Υ = [Υ, (dt, t)], ˚k = ˚k + 1,
end of the If
end
of the cycle over t
Mark the data suitable for initialization and compute a new box center.
Set s = 0
For
k = 1, . . . ,˚k
Set the ﬂag gt = 0 for (dt, t) on the kth position of Υ. Set s = s + dt.
For
i = 1, . . . , ˚
d
If di;t > di + b or di;t ≥Di −b or di;t ≤Di + b or di;t < di −b
Set the ﬂag gt = 1.
end of the If
end
of the cycle over i
end
of the cycle over k
Set e = ρ

ˆd, s
˚k

, see (12.16), and set ˆd = s
˚k
.
end of the cycle REPEAT
Extend the list of centers and numbers of points in them
C = [C, ˆd], κ = [κ,˚k].

12.4 MT step: make the MT algorithm feasible
457
Cancel the local minima as follows.
For
i = 1, . . . , ˚
d
Set ˚ki1 = 0, di1 = −∞, di2 = +∞
end
of the cycle over i
For
k = 1, . . . ,˚k
For (dt, t) on the kth position of Υ
For
i = 1, . . . , ˚
d
If di;t < ˆdi
Set ˚ki1 = ˚ki1 + 1 and di1 = max(di1, di;t)
Else
Set di2 = min(di2, di;t).
end Else
end
of the cycle over i
end
of the cycle over k
Evaluate the probability (12.17), in the multivariate version,
using ˚k and vectors ˚k1, d1, d2 found.
Cancel the center found from the list C and
the corresponding counter from κ if this probability is small.
end
of the cycle over n
Merge centers from the list C with mutual distance (12.16) smaller than ε.
Remark(s) 12.2
1. The conditions for the identity of the ﬁnal boxes can be relaxed by setting
for the ﬂag gt = 0 even if the conditions for gt = 0 are violated slightly
only.
2. The choice of initial points is not ﬁxed here. Either a random choice from
the data list with ﬂag gt = 1 can be made, or Algorithm 12.5 is employed.
3. The information on repetitive visiting of the same local extreme can be
exploited for predicting the overall number of maxima and thus used for
an eﬃcient and reliable stopping [174].
4. The use of a shadow-cancelling-based choice of initial boxes avoids the
need for labelling of suitable starting points.
5. The algorithm can be substantially accelerated by temporary sorting of
each data channel and storing the sorted indexes. Then, much fewer data
records have to be inspected when searching for the points belonging to the
given box and evaluating D, D.

458
12 Sandwich BMTB for mixture initiation
12.5 -B step: MT results as initial mixture
Important but partial information obtained from the MT step has to be ex-
tended into the statistics determining the prior GiW pdf of the ﬁnal normal
mixture. The extension is discussed here.
12.5.1 Position and noise covariance
The center of a multivariate box on the data-vector space Ψ ∗is a “natural”
prior LS point estimate ˆθ0 of the oﬀset in the static model modelling Ψt.
Similarly, the diagonal LS estimate of the matrix noise covariance is obtained
by equating respective scalar variances to the square of the corresponding box
width divided by 3; cf. Algorithm 12.4.
12.5.2 Remaining statistics
For the static model, ﬁxed component c and factor i, the covariance factor Cic
of the LS estimate is scalar. It is just a shifted version of the corresponding
νic = νc, ∀i. The scalar νc equals the corresponding κc, again potentially up
to some shift. Having no reasons for selecting diﬀerent shifts, we set Cic;0 =
νic;0 = κc;0. The reasonable value κc;0 is proportional to the number ˚kc;˚t
of data vectors captured within the inspected box. The proportion factor is
chosen so that the general recommendation for initial values of 2
c∈c∗κc;0 ≈
γ˚t, γ ≈0.1, is met. It gives
Cic;0 = νic;0 = κc;0 = ˚kc;˚t
γ˚t
2
˜c∈˚c˚k˜c;˚t
.
(12.18)
This complements the deﬁnition of the prior GiW pdf for the normal mixture.
12.5.3 Conversion of static components to dynamic factors
The MT algorithm provides a static model that is extended to the dynamic
case by applying it to the data vector Ψt, which has unity as its last entry.
The extension is justiﬁed by Proposition 6.17. In this way, we get statistics
νc;0, Vc;0 of the static matrix components c ∈c∗. We need to convert them
into statistics of related dynamic factors. This is done here using a special
structure of the extended information matrix Vc ≡Vc;0.
The matrix Vc contains some nontrivial entries resulting from the MT
algorithm. The remaining ones, expressing unobserved correlations, are set to
zero using the standard argument of insuﬃcient reasons. The wish to preserve
sample moments, while respecting relationships between uniform to normal
pdfs, leads to the following form of the extended information matrix for the
ith factor

12.5 -B step: MT results as initial mixture
459
Vic = kc
⎡
⎢⎢⎢⎢⎢⎢⎣
b2
ic
3 + ˆµ2
ic
ˆµic
b2
(i+1)c
3
+ ˆµ2
(i+1)c
ˆµ(i+1)c
...
...
ˆµ˚
Ψc
ˆµic
ˆµ(i+1)c
. . . ˆµ˚
Ψc
˚Ψ
⎤
⎥⎥⎥⎥⎥⎥⎦
,
(12.19)
where kc is the number of data in the cth ﬁnal box found by MT algorithm.
The symbol bic is used for the box width on the ith axis and ˆµic is the
corresponding entry of the cth box center.
We have to verify that Vic is well deﬁned, to verify its positive deﬁniteness.
The submatrices Aic arising by omission of the last row and column are
diagonal with positive diagonal entries, and thus they are positive deﬁnite.
Thus, it remains to show that |Vic| > 0. This property is implied by the
identity
|Vic| = |Aic|(˚Ψ −[ˆµic, ˆµ(i+1)c, . . . , ˆµ˚
Ψc]A−1
ic [ˆµic, ˆµ(i+1)c, . . . , ˆµ˚
Ψc]′
= |Aic|
⎛
⎝˚Ψ −
˚
Ψ

j=i
ˆµ2
jc
b2
jc + ˆµ2
jc
⎞
⎠> |Aic|

˚Ψ −(˚Ψ −i)

> 0.
We need LDL′ decompositions of these information matrices. The simple
form of the matrices (12.19) allows us to generate them relatively cheaply by
a special version of the algorithm presented in Proposition 8.2. The follow-
ing proposition describes this version. In it, the ﬁxed component subscript is
suppressed.
Proposition 12.6 (L′DL form of MT-based Vi, i = ˚Ψ, . . . , 1) For i = ˚Ψ,
set L˚
Ψ = 1, D˚
Ψ = ˚Ψ; see (12.19).
Let us have the L′DL decomposition of Vi+1 = Li+1Di+1L′
i+1 and write
the deﬁnition (12.19) recursively
Vi =

gi
[0, . . . , 0, ˆµi]
[0, . . . , 0, ˆµi]′ L′
i+1Di+1Li+1

.
Then, the decomposition Vi = L′
iDiLi is obtained as follows
Li =
 1
0
βi Li+1

Di =
 ai
0
0 Di+1

,
where
βi = (L′
i+1Di+1)−1 [0, . . . , 0, ˆµi]′



b′
i
,
ai = gi −β′
iDi+1βi.
Proof. Multiplication of the matrices forming the L′DL decompositions imply
Vi =
#
ai + β′
iDi+1βi
β′
iDi+1Li+1
L′
i+1Di+1βi
L′
i+1Di+1Li+1
$
≡
#
gi
b′
i
bi Vi+1
$
.

460
12 Sandwich BMTB for mixture initiation
The comparison of respective entries implies the proved formulas.
In this way, the transition from MT statistics, gained for the static com-
ponents, to normal dynamic factors is completed. The following algorithm
summarizes this transition.
Algorithm 12.8 (Static component →dynamic factors)
Initial mode
•
Perform initialization by the MT algorithm so that you will get ˚c of ˚Ψ-
dimensional boxes characterized by the number of data ˚kc captured within
the box, and ˚Ψ-vectors of the box center ˆµc and widths bc.
•
Set L˚
Ψ+1,c;0 = 1, D˚
Ψ+1,c;0 = ˚Ψ, c ∈c∗.
•
Select the ratio γ ≈0.1 and evaluate s = 2
c∈c∗˚kc.
Recursive mode
For
c = 1, . . . ,˚c
Set κc;0 = ˚kc
ρ
s
For
i = ˚Ψ, . . . , 2
νic;0 = κc;0
Solve equation for β with upper triangular matrix L′
ic;0Dic;0
L′
ic;0Dic;0β = [0, . . . , 0, kcˆµic]′
Set a = kc
b2
ic
3 + ˆµ2
ic

−β′Dic;0β
Deﬁne
L(i−1)c;0 ≡
#
1
0
β Lic;0
$
, D(i−1)c;0 ≡diag [a, diag (Dic;0)]
end
of the cycle over i
end
of the cycle over c
Problem 12.1 (BMTB algorithm with normal MT factors) MT normal
factors can be used instead of MT uniform factors to create an alternative ini-
tialization.
It makes no sense to replace MT factors by a normal ones in a one-to-
one fashion since it would just increase the computational complexity without
bringing any obvious advantage. On the other hand, it is possible to use an ap-
proximate mixture estimation on a multivariate mixture made of MT-normal
factors. The centers, diagonal covariances and component weights, found when
solving the shadow cancelling problem, may serve as the needed start.
Moreover, the possibility of using the dynamic nature of MT normal com-
ponents is worth inspection.

12.5 -B step: MT results as initial mixture
461
Obviously, there are a lot of aspects related to normal mixtures that can
be exploited while preserving the mean-tracking ability of MT normal factors.
This direction is worth elaborating.

13
Mixed mixtures
Learning described at the general level in Chapter 6 deals with the factorized
version of the probabilistic component description. It allows us to use diﬀerent
models for describing diﬀerent entries of data records and to model jointly
continuous and discrete data, to deal with mixed mixtures. Speciﬁc aspects
related to mixtures of this type form the content of the current chapter.
Continuous-valued quantities are modelled by normal factors (see Chapter
8) and discrete-valued ones by Markov-chain factors; see Chapter 10. While
the former one can be made easily dependent on later ones, the opposite
case has not been supported. This major and substantial restriction on the
presented treatment is weakened here by exploiting a special version of normal
factors suitable to this purpose. These MT normal factors provide a practical
bridge between the world of discrete and continuous quantities. They are
simply normal factors with a small ﬁxed variance. Consequently, their learning
just tracks positions of the modelled quantities, similarly as the original MT
factors. Their mixture approximates the pf of a discrete-valued quantity. In
this way, the diﬃcult area of logistic regression, e.g., [175], is avoided.
Learning of the mixed mixtures is addressed in Section 13.1. Section 13.2
presents a promising attempt to estimate the ratio of mixtures. It allows us to
model dependence of discrete quantities on continuous ones. More generally
and more importantly it allows the use of data-dependent component weights.
The design part is omitted as it has not been elaborated in detail. The
learning part and Chapters 9 and 11 imply, however, that it will lead to a
feasible blend of manipulations with quadratic forms and tables. Moreover, the
mild — and often inevitable — restriction on modelling of discrete quantities
by the MT normal factors makes the design part identical with that of Chapter
9. It is obvious as the referred design uses constant point estimates of all
parameters.

464
13 Mixed mixtures
13.1 Learning with factors on mixed-type quantities
The joint presence of discrete and continuous valued quantities in respective
factors is the key problem of the mixed mixtures. Both possible variants, i.e.,
the dependencies of the continuous factor output on discrete and continuous
quantities and the discrete factor output on continuous and discrete quantities,
are discussed in this section.
13.1.1 Factors in EF with a discrete regressor
We consider the case that the ith regression vector contains one or more
discrete entries (regressors). To simplify notation, we map them on a scalar
discrete regressor, say ιt ∈ι∗≡{1, . . . ,˚ι}. Then, it holds.
Proposition 13.1 (Estimation in EF with a discrete regressor)
Let us consider the ith factor in the exponential family in the form
f(di;t|d(i+1)···˚
d;t, d(t −1), Θi) =
˚ι 
ι=1
[A(Θιi) exp [⟨Bι(Θιi), Cι(Ψιi;t)⟩]]διιt
where Θi ≡{Θιi}˚ι
ι=1. Kronecker symbol δ (5.31) and the functions A(·), B(·),
C(·) occurring in the exponential family, Agreement 3.1, are employed. The
individual factors in this product called parameterized subfactors. Then, the
conjugate prior pdf f(Θi|d(0)) has the form
f(Θi|d(0)) =
˚ι 
ι=1
Aνιi;0(Θιi) exp [⟨Vιi;0, Cι(Θιi)⟩] .
The corresponding posterior pdfs f(Θi|d(t)) preserve this functional form and
their suﬃcient statistics evolve as follows.
Vιi;t = Vιi;t−1 + διt,ιBι(Ψιi;t), νιi;t = νιi;t−1 + διt,ι, ι = 1, . . . ,˚ι, t ∈t∗.
Proof. It is implied directly by the Bayes rule.
The proposition says that the observed discrete-valued entry ιt serves as a
known pointer to the single pair of statistics Vιti;t−1, νιti;t−1 updated at the
time t.
The individual subfactors with indexes ιi are only updated on the subselec-
tion of data for which the observed discrete pointers ιt, t ∈t∗, have the value
ι. Thus, the observed discrete regressor ιt eﬀectively segments the processed
data into ˚ι parts. Let us formalize this conclusion.
Proposition 13.2 (Processing of factors with discrete regressor)
Let us consider learning of a mixed mixture with some factors, say {i1, . . . , i˚k},
each depending on a discrete-valued observable quantity ιik;t, k ∈k∗≡

13.1 Learning with factors on mixed-type quantities
465
{1, . . . ,˚k}. Then, at time t, the parameter estimates of subfactors with in-
dexes ιik;t, k ∈k∗, are updated by the current data and possibly forgotten.
They serve for computing component weights used in the approximate mixture
estimation, Section 6.5. Other subfactors are untouched and unused.
Proof. Omitted.
Remark(s) 13.1
Often, the discrete-valued quantity in the condition keeps its ﬁxed value for a
long period. Then, it is potentially possible to presegment the data accordingly
and process these segments independently. Before doing it, it is reasonable to
consider explicitly such a quantity in the condition of the parameterized model
because it may well happen that its diﬀerent values lead to identical system
responses. Then, the presegmentation can be done with respect to aggregated
values of this quantity. Consequently, a smaller amount of segments have to
be learned and overall learning eﬃciency is improved. This situation may also
have signiﬁcant interpretation consequences.
13.1.2 MT normal factors
The opposite case, when the discrete-valued factor output di;t depends on
continuous-valued, and possibly discrete, quantities is much more diﬃcult. It
is implied by the fact that in a nontrivial dynamic case a model out of the
exponential family is needed. Essentially, Markov-chains are the only dynamic
models of discrete outputs staying within EF.
Let us indicate how to arrive at this conclusion. For this, let it us assume
that the scalar discrete-valued innovation ∆t has a model in the dynamic EF
with vector-valued functions B(Ψt), C(Θ), i.e.,
f(∆t|ψt, Θ) = A(Θ) exp ⟨B(∆t, ψt), C(Θ)⟩≡exp ⟨βt, γ∆t(Θ)⟩≡f(∆t|βt, Θ)
β′(ψt) ≡
	
B′(1, ψt), . . . , B′( ˚
∆, ψt), 1

γ′
∆t(Θ) ≡
	
01,(∆t−1)˚
C, C′(Θ), 0, . . . , 0, ln(A(Θ))

This identity holds on support of the pf f(∆t|ψt, Θ) ≤1. For a ﬁxed Θ,
we can always select γ∆t ≥0. For a nontrivial dynamic EF, some entries
γi∆t > 0 and f(∆t|βt, Θ) depends nontrivially on βt. Taking the derivative
of the normalizing condition 1 = 2 ˚
∆
∆t=1 f(∆t|βt, Θ) with respect to the ith
entry of bt, we get the contradiction
0 =
˚
∆

∆t=1
γi∆t(Θ)f(∆t|βt, Θ) > 0.
Thus, no such model exists within EF and we either have to employ approxi-
mate techniques developed in the logistic regression, e.g., [176], or ﬁnd another

466
13 Mixed mixtures
way out. The ﬁxed box widths of the MT uniform factors, Chapter 12, inspire
us to approximate the desired parameterized factor by a mixture of parame-
terized MT normal factors, introduced in Chapter 12, which model well the
diﬀerences in data positions.
Thus, even if we know that the output di;t of the ith factor is a discrete-
valued one, we model it by the normal (scalar) component
f(di;t|d(i+1)···˚
d;t, d(t −1), Θic, c) = Ndi;t(θ′
icψic;t, ric),
(13.1)
around the positions θ′
icψic;t. Here, Θic ≡θi ≡regression coeﬃcients in θ∗
ic ≡
˚
ψic-dimensional real space. ψic;t is the regression vector. The noise variance ric
is a known and small positive number. Behavior around other positions has
to be modelled by other MT factors and thus the mixture model is needed.
Let us assume that the predicted factor output di;t ∈{1, 2, . . .}. To distin-
guish sharply these values by normal pdf it is suﬃcient to take its standard
deviation smaller than 0.05. It motivates the recommendation to ﬁx the vari-
ance ric at the order 10−3 and smaller.
Using the results of Chapter 8, it is straightforward to describe the esti-
mation and prediction of the MT normal factors. The notation of Chapter 8
is adopted and the subscript ic is temporarily suppressed. Recall also that the
information matrices are split as follows.
V =
#
⌊dV
⌊dψV ′
⌊dψV
⌊ψV
$
,
⌊dV is scalar. The L′DL decomposition is employed:
V = L′DL, L is a lower triangular matrix with unit diagonal and
D is diagonal matrix with nonnegative entries while
L =
#
1
0
⌊dψL ⌊ψL
$
,
D =
# ⌊dD
0
0
⌊ψD
$
,
⌊dD is scalar.
Proposition 13.3 (Estimation and prediction of the MT normal fac-
tors) Let natural conditions of decision making, Requirement 2.5, hold. The
MT normal factor (13.1) is treated, and a conjugate prior (3.13) as well as
the conjugate alternative (see Section 3.1) in stabilized forgetting are used.
Then, the prior, posterior and alternative pdfs are normal
f(θ|V ) = Nθ

ˆθ, r ⌊ψV −1
with ˆθ ≡E[θ|L, D, ν] = ⌊ψL−1 ⌊dψL and
r ≡⌊dD = ⌊dV −⌊dψV ′ˆθ = a priori ﬁxed value.
The predictive pdf is also normal (see Proposition 3.2)
f(d|ψ, V ) = Nd

ˆθ′ψ, r

1 + ψ′ ⌊ψV −1ψ

or alternatively
f(d|ψ, V ) =
exp

−
h2
d
2r(1+ζ)

?
2πr(1 + ζ)
, with
(13.2)
h = (L′)−1Ψ, h′ = [hd, h′
ψ], hd is scalar, ζ ≡
˚
Ψ

i=2
h2
i /Dii.
(13.3)

13.1 Learning with factors on mixed-type quantities
467
Note that hd coincides with the prediction error ˆe (8.31). The involved suﬃ-
cient statistic evolves according to the recursion with resetting of the entry ⌊dVt
Vt = λ(Vt−1 + ΨtΨ ′
t) + (1 −λ) ⌊AVt,
initial and alternative V0, ⌊AVt given
⌊dVt = r + ⌊dψV ′
t ˆθt ⇔
⌊dDt = r.
The normalization is ﬁnite for all time moments iﬀ⌊ψD0 > 0, and r > 0.
Proof. The majority of evaluations can be found in [69] or can be derived as
a special case of the general normal factor with the known r; Chapter 8.
Remark(s) 13.2
The algorithm for updating these factors is identical to that for normal factors;
see Chapter 8. We just have to change the value of the least-squares remainder
⌊dD (8.14) after each data updating. The main diﬀerence is in evaluation of
predictive pdfs; cf. (8.31) and (13.2).
The derived estimation is an important but particular step in the whole
learning. Here, we review the remaining steps by referring to relevant sections,
where their solutions are presented. We also point to the problems that remain
to be solved.
•
Data preprocessing is mostly oriented on individual signals in question.
Generally, it is addressed in Section 6.2. Section 8.2 specializes in nor-
mal factors and thus also in MT normal factors. Markov chain oriented
preprocessing is discussed in Section 10.2.
Problem 13.1 (Mixed counterpart of PCA) Reduction of dimension-
ality is the only considered preprocessing step dealing jointly with several
signals. It is based on continuous-signal oriented PCA. Thus, a speciﬁc
solution is needed for the mixed case. Surely, strongly unequal variances of
respective data entries have to be taken into account.
•
Incorporation of physical knowledge is strictly signal-oriented within this
text. Under this restriction, no additional problems are induced by the
mixed case. General, normal, and thus MT normal, and Markov cases are
addressed in Section 6.3, 8.3 and 10.3, respectively.
•
Construction of the prior pdf is solved predominantly factorwise. Thus,
adequate solutions are ready; see Sections 6.4, 8.4 and 10.4.
•
Structure estimation is again solved factorwise. For particular solutions;
see Sections 6.6, 8.6, 10.6.
Problem 13.2 (Unsolved structure estimation problems) The ma-
jority of the unsolved problems is not induced by the mixed case. It is,
however, worthwhile to list them.
–
Structure estimation of MT normal factors is not described here in
detail but its solution is a special and simpliﬁed case of the normal
factors; Section 8.6.1 and references [93, 95, 162].

468
13 Mixed mixtures
–
Structure estimation of Markov chains is not practically solved. The
solution given in Proposition 10.11 has to be elaborated further on,
for instance, in the direction outlined in [170] and deﬁnitely in the
directions related to Bayesian networks.
–
Eﬃcient estimation of the component structure is the open problem for
all types factors and an adequate solution has to be searched for.
–
The estimation of the mixture structure is conceptually solved through
the branching by factor splitting, factor merging and component can-
celling. All problems mentioned in relevant Sections of Chapters 6, 8
and 10 persist for the mixed case, too. It brings, however, no new prob-
lems.
•
Model validation, presented in previous chapters, is applicable to the mixed
case mostly without change. Algorithm 8.18, forgetting based validation,
Section 6.7.3, and judging of models as multi-step predictors, Section 7.1.2
seem to be the most promising common techniques.
Problem 13.3 (Completion of the mixed-mixtures suite) Learning as
well as design algorithm is feasible for the mixed mixtures. This is especially
true when normal MT factors are employed for modelling of discrete data. In
this case, the learning is obtained through simpliﬁcation of the learning of nor-
mal mixtures. The design is completely unchanged as the ﬁxed point estimates
of parameters are used.
13.2 An approximate estimation of mixture ratios
The normal MT factors help us to cope with the modelling of dependence of
discrete quantities on continuous ones. The solution is based on interpreting
discrete quantities as continuous ones with a very narrow variation range. In
this way, the normalization does not spoil the mixture character of the model.
Estimation of a ratio of mixtures is another way how to approach the problem.
A promising attempt in this respect is outlined in this section. It extends
the descriptive power of all mixtures as it allows us to deal with dynamic
mixtures having data-dependent component weights. The signiﬁcance of this
extension cannot be exaggerated. At the same time, it is fair to forewarn that
the proposed solution is far from being the ﬁnal one.
13.2.1 Mixture modelling of stationary pdf
We start with a reparameterization of the joint pdf of the observed data.
The the chain rule applied to the joint pdf f(d(˚t)) of the data sequence
d(˚t) gives f(d(˚t)) = /
t∈t∗f(dt|d(t −1)). Finite memory of the majority of
real systems justiﬁes the assumption that there is a ﬁnite ﬁxed-dimensional
state φt−1 = φ(d(t −1)) such that f(dt|d(t −1)) = f(dt|φt−1). We assume

13.2 An approximate estimation of mixture ratios
469
moreover that the conditional pdf f(dt|φt−1) is a time invariant function of
the data vector (cf. Agreement 9.1)
Ψt = [d′
t, φ′
t−1]′ ≡[Ψ1;t, . . . , Ψ˚
Ψ;t]′, Ψi;t are scalars.
(13.4)
The considered modelling speciﬁes a parametric class of stationary pdfs on Ψt
that deﬁnes indirectly the parameterized model used in estimation. Speciﬁ-
cally, we assume that the stationary pdf f(Ψt|Θ) of the data vector Ψt, pa-
rameterized by an unknown parameter Θ, is at disposal. It deﬁnes the param-
eterized model of the system in question
f(dt|d(t −1), Θ) = f(dt|φt−1, Θ) =
f(Ψt|Θ)
f(φt−1|Θ),
(13.5)
where f(φt−1|Θ) =

f(Ψt|Θ) ddt.
The possibility to parameterize time and data invariant function of Ψt is
the main advantage of the indirect construction (13.5). Under rather general
conditions, ﬁnite mixtures have a “universal approximation property” [39],
i.e., almost any time-invariant pdf f(Ψt) can be approximated by a ﬁnite
mixture
f(Ψt|Θ) =

c∈c∗
αcf(Ψt|Θc, c),
(13.6)
Θ ∈Θ∗=
"
Θc, c ∈c∗, α ∈
"
αc ≥0,

c∈c∗
αc = 1
%%
.
The mixture form (13.6), the conditioning (13.5) and the chain rule give the
parameterized model needed for the Bayesian parameter estimation
f(dt|φt−1, Θ) =
2
c∈c∗αcf(Ψt|Θc, c)
2
˜c∈c∗α˜cf(φt−1|Θ˜c, ˜c)
(13.7)
=

c∈c∗
αcf(φt−1|Θc, c)
2
˜c∈c∗α˜cf(φt−1|Θ˜c, ˜c)



αc(φt−1)
f(dt|φt−1, Θc, c).
The resulting dynamic mixture (13.7) has time-invariant but state-dependent
component weights {αc(φt−1)}c∈c∗.
We use factorized versions of the permuted components f(Ψc;t|Θc, c) in
the mixture (13.6). It means that we factorize them using the chain rule
f(Ψc;t|Θc, c) =
˚
Ψ
 
i=1
f(Ψic;t|ψic;t, Θic, c).
(13.8)
The data record dt is the obligatory part of all component-speciﬁc data vectors
Ψc;t. The subsequent evaluations are simpliﬁed by keeping the data record dt
at leading positions of all data vectors Ψc;t.

470
13 Mixed mixtures
The factor f(Ψic;t|ψic;t, Θic, c) predicts the ith entry of cth data vector
Ψc;t, i.e., it predicts the factor output Ψic;t, using the regression vector ψic;t,
formed by an appropriate subselection of entries (Ψ(i+1)c;t, . . . , Ψ˚
Ψc;t). It is
parameterized by an unknown parameter Θic formed by a subselection of Θc.
Using (13.8), the conditional pdf (13.7) gets the form
f(dt|φt−1, Θ) =
2
c∈c∗αc
/˚
Ψ
i=1 f(Ψic;t|ψic;t, Θic, c)
2
c∈c∗αc
/˚
Ψ
i=˚
d+1 f(Ψic;t|ψic;t, Θic, c)
,
i.e., the marginal pdfs in the denominator are obtained by omitting the initial
factors in the products deﬁning the components. This property stems from the
assumed leading position of the predicted data record dt in Ψc;t ≡[d′
t, φ′
c;t−1]′.
13.2.2 Extended quasi-Bayes estimation
The mixture estimation is a well-established art, [48, 49]. A speciﬁc estimation
of the rational model (13.7) is, however, missing. A promising solution is
outlined here.
The quasi-Bayes estimation, Section 6.5.1, takes the mixture as the marginal
pdf of the pdf
f(Ψt, ct|Θ) = αctf(Ψct;t|Θct, ct) =
 
c∈c∗
[αcf(Ψc;t|Θc, c)]δc,ct .
(13.9)
The quantity ct is interpreted as an unobserved random pointer to the active
component. The Kronecker symbol δc,ct ≡1 if c = ct and δc,ct ≡0 otherwise.
Recall that assuming the prior pdf in the form, cf. Agreement 6.1,
f(Θ|d(t −1)) ∝
 
c∈c∗
ακc;t−1−1
c
˚
d
 
i=1
f(Θic|d(t −1)),
(13.10)
the quasi-Bayes estimation uses the weight wc;t ≡f(ct = c|d(t)) as an ap-
proximation of the unknown δc,ct. This choice used in the data updating
f(Θ|d(t−1)) →f(Θ|d(t)) preserves the product form (13.10) of the parameter
estimate.
In the inspected case, the dynamic model is the ratio of two ﬁnite mixtures
with constant weights. The numerator is the mixture describing the data
vector Ψt and the denominator is the mixture describing the state φt−1. Thus,
it seems to be reasonable to
•
assume that the prior pdf is also in the form (13.10), but with ˚Ψ factors,
•
approximate the inverse of the denominator by a ﬁnite mixture,
•
compute the weights wct;t for the product version of the numerator and
the weights ˜w˜ct;t related to the product version of the approximated
denominator,

13.2 An approximate estimation of mixture ratios
471
•
update the prior pdf by the product of these product forms with the un-
known Kronecker symbols replaced by respective weights wct;t, ˜w˜ct;t.
Let us develop this plan starting from a simple motivating proposition.
Proposition 13.4 (One-sided approximation of pdfs) Let f(Θ|d(t))
be a posterior pdf and ˆf(Θ|d(t)) its approximation such that the following
implication hold ˆf(Θ|d(t)) = 0 ⇒f(Θ|d(t)) = 0 for all t ∈t∗and any
Θ ∈Θ∗. Let the asymptotic support of the pdf ˆf(Θ|d(t)) consist of a single-
point set
 ⌊oΘ

⊂Θ∗. Then, the asymptotic support of f(Θ|d(t)) consists of
the same point.
Proof. The assumption implies that supp [ f(Θ|d(t))] ⊂supp
	
ˆf(Θ|d(t))

for
all t ∈t∗. Thus, the inclusion holds asymptotically and the nonempty subset
of the single-point set
 ⌊oΘ

⊂Θ∗coincides with this set.
Proposition 2.15, that describes asymptotic properties of the Bayesian esti-
mation, shows that the support of the pdf f(Θ|d(t)) concentrates almost surely
on parameters that point to parameterized models closest to the objective
model of reality. Consequently, Proposition 13.4 says that the pdf ˆf(Θ|d(t))
approximating f(Θ|d(t)) from above will provide the correct estimate if it
concentrates on a single point.
The following proposition provides a speciﬁc upper bound ˆf(Θ|d(t)) that
can be constructed recursively.
Recall that Diα(κ) is Dirichlet pdf determined by the vector statistics κ
and describing the component weights α.
Proposition 13.5 (One sided approximation: ratio of mixtures)
Let us consider the model parameterized by Θ ≡

{Θic}
˚
Ψ
i=1 , αc

c∈c∗
f(dt|d(t −1), Θ) ≡
2
c∈c∗αc
/˚
Ψ
i=1 f(Ψic;t|ψic;t, Θic)
2
˜c∈c∗α˜c
/˚
Ψ
i=˚
d+1 f(Ψic;t|ψic;t, Θi˜c)
and the prior upper bound
ˆf(Θ|d(t −1)) = Diα(ˆκt−1)
 
c∈c∗
˚
Ψ
 
i=1
ˆf(Θic|d(t −1))
on the prior pdf f(Θ|d(t −1)), i.e., fulﬁlling the inequality f(Θ|d(t −1)) ≤
C(d(t−1)) ˆf(Θ|d(t−1)) with a ﬁnite C(d(t−1)). This guarantees the inclusion
of their supports supp [ f(Θ|d(t −1))] ⊂supp
	
ˆf(Θ|d(t −1))

.
After observing the new data vector Ψt, the following pdf forms the upper
bound on the posterior pdf f(Θ|d(t)).

472
13 Mixed mixtures
ˆf(Θ|d(t))∝ˆf(Θ|d(t −1))
(13.11)
×
⎧
⎪
⎨
⎪
⎩
1
2
¯c∈˜c∗α¯c
2
2
c∈c∗αc
2
˜c∈˜c∗α˜c
/˚
Ψ
i=1 f(Ψic;t|ψic;t,Θic)
/˚
Ψ
˜i=˚
d+1 f(Ψ˜i˜c;t|ψ˜i˜c;t,Θ˜i˜c) if ˜c∗̸= ∅
2
c∈c∗
/˚
d
i=1 f(Ψic;t|ψic;t, Θic)
if ˜c∗= ∅.
The set ˜c∗≡˜c∗(Ψt) contains pointers ˜c ∈c∗to such components for which

ˆf(Θi˜c|d(t −1))
f(Ψi˜c;t|ψi˜c;t, Θi˜c) dΘi˜c < ∞for all i = ˚
d + 1, . . . , ˚Ψ.
(13.12)
Proof. The Bayes rule implies that supp [ f(Θ|d(t))] is contained in the sup-
port of the pdf proportional to
2
c∈c∗αc
/˚
Ψ
i=1 f(Ψic;t|ψic;t, Θic)
2
˜c∈c∗α˜c
/˚
Ψ
˜i=˚
d+1 f(Ψ˜i˜c;t|ψ˜i˜c;t, Θ˜i˜c)
ˆf(Θ|d(t −1)).
(13.13)
Let us consider the case ˜c∗̸= ∅. By omitting all components in denominator
out of ˜c∗, we get an upper bound on the expression (13.13). It has the same
form as (13.13) but summation in the denominator is taken over ˜c∗only. The
Jensen inequality implies the following bound on the new denominator
1
2
˜c∈˜c∗α˜c
/˚
Ψ
i=˚
d+1 f(Ψi˜c;t|ψi˜c;t, Θi˜c)
=
1
2
¯c∈˜c∗α¯c
 2
˜c∈˜c∗
α˜c
2
¯c∈˜c∗α¯c
/˚
Ψ
i=˚
d+1 f(Ψi˜c;t|ψi˜c;t, Θi˜c)
≤

(2.14)
1
2
¯c∈˜c∗α¯c
2

˜c∈˜c∗
α˜c
/˚
Ψ
i=˚
d+1 f(Ψi˜c;t|ψi˜c;t, Θi˜c)
.
It proves the ﬁrst part of the claim.
Let us consider the case with ˜c∗= ∅. In each cth term of the sum over
c ∈c∗occurring in (13.13), we simply omit all terms in denominator except
the cth one. It leads to cancelling both αc and parameterized factors with
indexes i = ˚
d + 1, . . . , ˚Ψ and proves this degenerate case.
Problem 13.4 (Reﬁnement of bounds to factor structure) The com-
ponent is shifted to c∗\ ˜c∗even if just its single factor makes the integral
(13.12) inﬁnite. This condition can be probably reﬁned. It should done at least
for normal mixtures.
For the case ˜c∗̸= ∅, ˜c∗̸= c∗the factor
2
¯c∈˜c∗α¯c
−2 “spoils” the resem-
blance of the upper bound to a mixture. The following simple proposition
helps us to get rid of it.

13.2 An approximate estimation of mixture ratios
473
Proposition 13.6 (One-sided approximation: ratio of weights) Let
˜c∗be nonempty set and the statistic ˆκt−1 determining the Dirichlet pdf has
entries ˆκ˜c;t−1 > 2
˚˜c for all ˜c ∈˜c∗. Then,
/
c∈c∗αˆκc;t−1−1
c
2
˜c∈˜c∗α˜c
2
≤
 
c∈c∗\˜c∗
αˆκc;t−1−1
c
 
˜c∈˜c∗
αˆκ˜c;t−1−η−1
˜c
,
η ≡2
˚˜c
.
(13.14)
The ﬁrst product in (13.14) is set to 1 if c∗= ˜c∗.
Proof. Diving the inequality to be proved by its positive right-hand side, we
get the equivalent to be proved
/
˜c∈˜c∗αη
˜c
2
˜c∈˜c∗α˜c
2 ≤1,
for α˜c ≥0 and

˜c∈˜c∗
α˜c ≤1.
It can be simply shown that its maximum is reached for identical entries
α˜c = A ≥0, A ≤1, ˜c ∈˜c∗. For them, we get the value Aη˚˜c−2
˚˜c
2
. It is clear that
Aη˚˜c−2 ≤1 for η ≥2
˚˜c. Thus, the claim holds as ˚c ≥1.
Remark(s) 13.3 The approximation is not needed for the case ˜c∗= c∗. We
can eﬀectively deal with both cases at once by setting η = 0 for ˜c∗= c∗.
The combination of Propositions 13.5, 13.6 updates the upper bound in
the form of the mixture. Thus, the heuristic leading to quasi-Bayes estimation;
see Section 6.5.1, can almost be copied. To make it, the upper bound is viewed
formally as the marginal pdf of the following pdf (the sign ˆ is dropped)
For ˜c∗̸= ∅
(13.15)
f(Θ, ct, ˜ct|d(t)) ∝
 
c∈c∗
⎡
⎣αc
˚
Ψ
 
i=1
f(Ψic;t|ψic;t, Θic)
⎤
⎦
δc,ct
×
 
˜c∈˜c∗
⎡
⎣α1−η
˜c
˚
Ψ
 
˜i=˚
d+1
1
f(Ψ˜i˜c;t|ψ˜i˜c;t, Θ˜i˜c)
⎤
⎦
δ˜c,˜ct
Diα(κt−1)
˚
Ψ,˚c
 
˜i=1,¯c=1
f(Θ˜i¯c|d(t −1)).
For ˜c∗= ∅
f(Θ, ct|d(t)) ∝
 
c∈c∗
⎡
⎣
˚
d
 
i=1
f(Ψic;t|ψic;t, Θic)
⎤
⎦
δc,ct
× Diα(κt−1)
˚
Ψ,˚c
 
˜i=1,¯c=1
f(Θ˜i¯c|d(t −1)).
Comparing to the quasi-Bayes estimation, the recognition whether the com-
ponent belongs to ˜c∗is an additional logical operation needed. Moreover, the

474
13 Mixed mixtures
expectations E[αcα1−η
˜c
|d(t−1)] have to be evaluated. It seems to be suﬃcient
to use the crudest approximation
E[αc α1−η
˜c
|d(t −1)] =
(13.16)
= E[αc|d(t −1)] [E[α˜c|d(t −1)]]1−η ∝
κc;t−1
2
c∈c∗κc;t−1
#
κ˜c;t−1
2
˜c∈˜c∗κ˜c;t−1
$1−η
.
The overall extended quasi-Bayes estimation algorithm we put together for
mixtures with parameterized factors in exponential family; see Section 3.2,
f(Ψic;t|ψic;t, Θic) = A(Θic) exp
9
B([Ψic;t, ψ′
ic;t]′), C(Θic)
:
and the corresponding conjugate (upper bounds on) prior pdfs
f(Θic|d(t −1)) = Aνic;t−1(Θic) exp ⟨Vic;t−1, C(Θic)⟩
I(Vic;t−1, νic;t−1)
.
Here, Vic;t−1 and νic;t−1 form the (approximate) suﬃcient statistic and
I(Vic;t−1, νic;t−1) denotes the corresponding normalizing integral.
The evaluation of the posterior pf f(ct, ˜ct|d(t)) — decisive in the design
of the learning algorithm — is straightforward for the degenerated case with
˜c∗= ∅. Integration of the joint pdf (13.15) over Θ∗implies that
For ˜c∗= ∅
(13.17)
f(ct = c|d(t)) ∝
˚
d
 
i=1
I

Vic;t−1 + B

[Ψic;t, ψ′
ic;t]′
, νic;t−1 + 1

I(Vic;t−1, νic;t−1)
.
The normalization of the pf f(ct|d(t)) provide the weights
wc;t =
f(ct = c|d(t))
2
ct∈c∗f(ct|d(t)) ≈δct,c.
(13.18)
Use of this approximation in the formula (13.15) provides the updating rule
of the statistics determining the approximate posterior pdf in the degenerate
case ˜c∗= ∅.
The case ˜c∗̸= ∅is treated separately for ct = ˜ct = c and ct = c ̸= ˜c = ˜ct.
The expression (13.15) reads
For ˜c∗̸= ∅, and ct = ˜ct = c
(13.19)
f(Θ, ct = c, ˜ct = c|d(t)) ∝Diα(κt−1)
×α2−η
c
˚
d
 
i=1
A(Θic)νic;t−1+1 exp ⟨Vic;t−1 + B ([Ψic;t, ψic;t]) , C(Θic)⟩.
Thus, with the approximation (13.16), it holds

13.2 An approximate estimation of mixture ratios
475
For ˜c∗̸= ∅,
and ct = ˜ct = c
(13.20)
f(ct = c, ˜ct = c|d(t))
∝κ2−η
c;t−1
˚
d
 
i=1
I (Vic;t−1 + B ([Ψic;t, ψic;t] , νic;t−1 + 1))
I (Vic;t−1, νic;t−1)
.
The remaining case ct = c ̸= ˜c = ˜ct specializes the expression (13.15) to
For ˜c∗̸= ∅, and c ̸= ˜c, f(Θ, ct = c, ˜ct = ˜c|d(t)) ∝Diα(κt−1)
(13.21)
× αcα1−η
˜c
˚
Ψ
 
i=1
A(Θic)νic;t−1+1 exp ⟨Vic;t−1 + B ([Ψic;t, ψic;t]) , C(Θic)⟩
×
˚
Ψ
 
˜i=˚
d+1
A(Θ˜i˜c)ν˜i˜c;t−1−1 exp
6
V˜i˜c;t−1 −B

	
Ψ˜i˜c;t, ψ˜i˜c;t

, C(Θ˜i˜c)
7
.
Thus, with the approximation (13.16), it holds
For ˜c∗̸= ∅,
and c ̸= ˜c,
f(ct = c, ˜ct = ˜c|d(t))
(13.22)
∝κc;t−1κ1−η
˜c;t−1
˚
Ψ
 
i=1
I (Vic;t−1 + B ([Ψic;t, ψic;t]) , νic;t−1 + 1)
I (Vic;t−1, νic;t−1)
×
˚
Ψ
 
˜i=˚
d+1
I

V˜i˜c;t−1 −B

	
Ψ˜i˜c;t, ψ˜i˜c;t

, ν˜i˜c;t−1 −1

I

V˜i˜c;t−1, ν˜i˜c;t−1

.
The marginalization and normalization of the pf f(ct, ˜ct|d(t)) provide the
weights
wc;t =
2
˜ct∈˜c∗f(ct = c, ˜ct|d(t))
2
˜ct∈˜c∗
2
ct∈c∗f(ct, ˜ct|d(t)) ≈δct,c
(13.23)
˜w˜c;t =
2
ct∈c∗f(ct, ˜ct = ˜c|d(t))
2
˜ct∈˜c∗
2
ct∈c∗f(ct, ˜ct|d(t)) ≈δ˜ct,˜c.
To simplify the notation, let us deﬁne ˜wc ≡0, for c ∈c∗\ ˜c∗. This is the
last preparatory step in completing the updating rule for all statistics involved.
The resulting extended quasi-Bayes estimation preserves the functional form
(6.3) with Dirichlet pdf Diα(κt) assigned to the component weights and with
conjugate pdfs f(Θic|d(t)) ∝Aνic;t(Θic) exp ⟨Vic;t, C(Θic)⟩for the parameter-
ized factors from the exponential family.
For ˜c∗̸= ∅, the updating Diα(κt) ∝/
c∈c∗αwc
c
/
˜c∈˜c∗α(1−η) ˜
w˜c
˜c
Diα(κt−1)
is performed. It gives κc;t ≡κc;t−1 + wc + (1 −η) ˜wc.
The diﬀerent updating is obtained for the factor outputs and for individual
predicted entries of the state vector. Speciﬁcally, for each c ∈c∗,

476
13 Mixed mixtures
For i = 1, . . . , ˚
d, f(Θic|d(t)) ∝[f(Ψic;t|ψic;t, Θic)]wc f(Θic|d(t −1)) giving
Vic;t = Vic;t−1 + wc;tB


Ψic;t, ψ′
ic;t
′
, νic;t = νic;t−1 + wc;t.
For i = ˚
d, . . . , ˚Ψ, f(Θic|d(t)) ∝[f(Ψic;t|ψic;t, Θic)]wc−˜
wc f(Θic|d(t −1)) giving
Vic;t = Vic;t−1 + (wc;t −˜wc;t)B


Ψic;t, ψ′
ic;t
′
νic;t = νic;t−1 + wc;t −˜wc;t.
For ˜c∗= ∅, no updating is performed on component weights Diα(κt) =
Diα(κt−1). It gives κc;t ≡κc;t−1.
The updating of the factors diﬀers for the factor outputs and for individual
predicted entries of the state vector. Speciﬁcally, for each c ∈c∗
For i = 1, . . . , ˚
d, f(Θic|d(t)) ∝[f(Ψic;t|ψic;t, Θic)]wc f(Θic|d(t)) giving
Vic;t = Vic;t−1 + wc;tB


Ψic;t, ψ′
ic;t
′
, νic;t = νic;t−1 + wc;t.
For i = ˚
d, . . . , ˚Ψ, f(Θic|d(t)) = f(Θic|d(t −1)) giving
Vic;t = Vic;t−1, νic;t = νic;t−1.
Let us summarize these results into a complete algorithm.
Algorithm 13.1 (Extended Quasi-Bayes estimation in EF)
Initial (oﬄine) mode
•
Select the complete structure of the mixture and set time t = 0.
•
Select prior pdfs f(Θic) of the individual factors in the conjugate form
(3.13) with respect to the parameterized factors f(Ψic;t|ψic;t, Θic, c).
In other words, specify the statistics Vic;t, νic;t, c ∈c∗, i = 1, . . . , ˚Ψ!
•
Select initial values κc;0 > 2, say, about 0.1˚t/˚c, describing the prior pdf of
the component weights α.
Sequential (online) mode,
For
t = 1, . . . , . . .
Acquire the data dt and create the data vector Ψt
Determine the set ˜c∗, i.e., set ˜c∗= c∗, ˚˜c = ˚c and
For
c = 1, . . . ,˚c
For
i = ˚
d + 1, . . . , ˚Ψ
Evaluate I−ic ≡
I

Vic;t−1 −B


Ψic;t, ψ′
ic;t
′
, νic;t−1 −1

I (Vic;t−1, νic;t−1)
Set ˜c∗= ˜c∗\ {c}, ˚˜c =˚˜c −1, and break i-cycle if I−ic = ∞
end
of the cycle over i
For
i = 1, . . . , ˚Ψ

13.2 An approximate estimation of mixture ratios
477
Evaluate I+ic ≡
I

Vic;t−1 + B


Ψic;t, ψ′
ic;t
′
, νic;t−1 + 1

I (Vic;t−1, νic;t−1)
end
of the cycle over i
end
of the cycle over c
Treat the degenerate case if ˜c∗= ∅, i.e., set s = 0 and
For
c = 1, . . . ,˚c
fc;t ≡
˚
d
 
i=1
I+ic
s = s + fc;t
end
of the cycle over c
Update the statistics in the degenerate case, i.e.,
For
c = 1, . . . ,˚c
Set wc;t ≡fc;t
s
For
i = 1, . . . , ˚
d
Update Vic;t = Vic;t−1 + wc;tB


Ψic;t, ψ′
ic;t
′
νic;t = νic;t−1 + wc;t
end
of the cycle over i
For
i = ˚
d + 1, . . . , ˚Ψ
Vic;t = Vic;t−1
νic;t = νic;t−1
end
of the cycle over i
κc;t = κc;t−1
end
of the cycle over c
End the degenerate branch, i.e., go to the end of the cycle over time t.
Treat the nondegenerate case, ˜c∗̸= ∅, i.e.
Set s = 0 and η =
 0 if ˜c∗= c∗
2
˚˜c otherwise
For
c = 1, . . . ,˚c
For
˜c = 1, . . . ,˚˜c
if ˜c = c,
fcc = κ2−η
c;t−1
˚
d
 
i=1
I+ic

478
13 Mixed mixtures
else,
fc˜c = κc;t−1κ1−η
˜c;t−1
˚
Ψ
 
i=1
I+ic
˚
Ψ
 
i=˚
d+1
I−i˜c
end if-else,
s = s + fc˜c
end
of the cycle over ˜c
end
of the cycle over c
For
c = 1, . . . ,˚c
wc =

˜c∈˜c∗
fc˜c
s
if c ∈˜c∗
˜wc =

˜c∈c∗
f˜cc
s
else ˜wc = 0
end
of the cycle over c
Update statistics in the non-degenerate case, i.e.,
For
c = 1, . . . ,˚c
For
i = 1, . . . , ˚
d
Vic;t = Vic;t−1 + wcB


Ψic;t, ψ′
ic;t
′
,
νic;t = νic;t−1 + wc
end
of the cycle over i
For
i = ˚
d + 1, . . . , ˚Ψ
Vic;t = Vic;t−1 + (wc −˜wc) B


Ψic;t, ψ′
ic;t
′
,
νic;t = νic;t−1 + wc −˜wc
end
of the cycle over i
κc;t = κc;t−1 + wc + (1 −η) ˜wc
end
of the cycle over c
Evaluate the estimates of Θ using f(Θ|Vt, νt, κt).
end
of the cycle over t
Remark(s) 13.4
1. The derived algorithm allows negative weights to new data. In this way,
it is closer to the reinforcement learning and as such it is expected to
have better transient properties than the quasi-Bayes estimation applied
to f(Ψ|Θ).

13.2 An approximate estimation of mixture ratios
479
2. The algorithm may fail when some κc;t−1 falls below 2/˚˜c. Then, this com-
ponent has to be shifted to ˜c∗, too.
3. Using Jensen inequality (2.14), it can be shown that the approximation
of the unknown δc,ct by its expectation provides a lower bound on the ap-
proximating function. Thus, the approximated upper bound on the correct
pdf is not guaranteed to be upper bound anymore. This made us to take
Proposition 13.4 as motivating one only.
4. Normalization of a dynamic factor predicting discrete quantity makes the
treated pdf rational: thus the proposed solution can be directly used to this
case vital for mixed mixtures.
Problem 13.5 (Complete extension of approximate estimation)
Preliminary limited experience with the extended quasi-Bayes estimation is
mixed: the expected signiﬁcant improvement with respect to a plain application
of the Bayes rule to data vectors has not been achieved. At the same time,
the illogical frozen updating of factors in complement of ˜c∗indicates that the
proposed algorithm can be improved. We expect that the same methodology can
be followed but the optimized upper bound has to be reﬁned.
Moreover, the extension of the quasi-Bayes estimation concerns only ma-
nipulation of weights of data. Thus, it is obvious that similar extensions are
possible for all remaining versions of approximate estimation, Section 6.5.

14
Applications of the advisory system
The applications described here conﬁrm usefulness of the developed theory
and algorithms. At the same time, the applications proved to be signiﬁcant for
developing both the theory and algorithms. They helped us to discover errors,
inconsistencies, drawbacks and bugs. They stimulated solutions of many sub-
problems that arose in attempts to implement the theoretical results. The
process is still unﬁnished but the discussed interaction can be unanimously
claimed to be useful.
Three rather diﬀerent applications are outlined here. Advising at cold
rolling mill is described in Section 14.1. Nuclear medicine application related
to treatment of thyroid gland cancer is reﬂected in Section 14.2. Prediction
problems related to urban traﬃc control are in Section 14.3. Practical conclu-
sions are made in Section 14.4; see also [177].
The presented experience with applications we are working with reﬂects
the research stage that corresponds with the last arrow in the veriﬁcation
chain
theory →software →oﬄine experiments →implementation.
14.1 Operation of a rolling mill
Support of rolling mill operators in their decisions how to adjust key operating
parameters of the machine was the main application output of the project that
stimulated the results presented in this text. In this application, the ﬁxed
advisory system with periodically refreshed advisory mixture is used.
14.1.1 Problem description
Nowadays rolling mills are usually equipped with a control system enabling
high quality production for properly adjusted manual settings. It is, however,
diﬃcult to ﬁnd optimal settings for all possible working conditions and every
type of the material being processed.

482
14 Applications of the advisory system
The rolling mill
A cold rolling mill is a complex machine used for reduction of metal strip
thickness. The thickness is reduced between working rolls of the mill. It is af-
fected by the rolling force in conjunction with input and output strip tensions
being applied. For reversing mills, the strip is moved forward and backward
in several passes until the desired thickness is achieved.
Two types of cold rolling mills were selected for full-scale experiments.
They diﬀer in the arrangement of rolls. The 4-high rolls arrangement consists
of two working rolls each being supported by a single back-up roll. Data from
two mills of this type were used for oﬄine experiments.
A ﬁne reversing cold rolling mill with 20-high arrangement of rolls,
Fig. 14.1, was employed for both oﬄine test and ﬁnal online advisory system
implementation. About 12 material types — alloys of iron, copper, nickel,
zinc, etc. — are processed on the machine. Contact meters on both sides of
the rolling mill provide measurements of strip thickness with ±1 µm accu-
racy. For illustration, rolling forces are of order of 106 N, electric currents of
drives about 102 A, strip tensions about 104 N and rolling speed in orders of
0.1–1 ms−1.
The machine has been already equipped with the two-level control and in-
formation system including the adaptive thickness controller [178]. For prop-
erly adjusted settings, the controller is capable to keep deviations of the output
strip thickness on the level of the measurement accuracy.




A
A
AA




h1, H1
h2, H2
x
x
-
Rolling direction
dei
m
ei
i
m
m
m
de
e
i
ii
m
m
m
m
Fig. 14.1. Schematic diagram of the 20-high reversing rolling mill. For the selected
rolling direction, H1 and h1 denote the input strip thickness and deviation from its
nominal value, respectively; similarly, H2 and h2 for the output thickness.
Data collection
The modern distributed control system of rolling mills enables to archive every
sample of process data. The collection is triggered by the strip movement.

14.1 Operation of a rolling mill
483
Several tens of signals are collected on each particular mill. Thus, for each
pass, (˚
d,˚t) data matrix is produced where ˚
d is the number of channels speciﬁc
for a particular mill and the number of samples ˚t varies from 3 000 to 30 000
depending on a particular pass. Data samples are recorded each 4 cm of the
strip, i.e., sampling period varies according to the strip speed. For instance, for
the speed 1 m/s, the sampling period is 40 ms. The rolling mill experts selected
˚
d = 10 most important data channels as adequate for advising purposes. The
speciﬁc selection depends on a particular rolling mill as described below.
14.1.2 Problem and its solution
The advisory system is to help adjust the main process quantities in order
to maintain the best possible product quality. Moreover, for the 20-high mill,
the goal is a better utilization of the rolling speed range in order to increase
production potential without a loss of the high product quality. The practical
implementation aspects described here relate to this problem.
Oﬄine phase
The oﬄine phase of the solution consists of data preprocessing, Section 6.2,
estimation of the prior mixture information, Section 6.4, structure and param-
eter estimation, Sections 6.6 and 6.5, and the design of the advisory system;
see Chapters 7 and 9.
Data
Data from two 4-high rolling mills were utilized for oﬄine experiments.
58 quantities are recorded. The number of considered quantities was reduced
to 10.
Most important selected data channels for mill 1 (rolling copper and its
alloys) and mill 2 (rolling iron and its alloys) diﬀer. The diﬀerence is caused by
diﬀerences of control systems at respective mills. In contrast with the 20-high
rolling mill, they contain explicitly rolling forces and hydraulic pressures on
rolling cylinders.
Additional oﬄine tests and a ﬁnal online implementation concern the 20-
high rolling mill. The available 44 data channels were also reduced to 10 rel-
evant ones shown in Table 14.1.
For reversing rolling mill input/output pairs of signals refer to right/left
sides of the mill, or vice versa according to the rolling direction. The front/rear
pairs of signals refer to operator/drive sides of a rolling mill.
Particular sets of important data channels for the given rolling mills were
selected by combining experience, correlation analysis, availability and relia-
bility of particular data channels. The quantities measured with insuﬃcient
precision, heavily correlated or irrelevant for the addressed problem were omit-
ted. Formally, they were treated as surplus data do+ of the o-system.

484
14 Applications of the advisory system
Table 14.1. Oﬄine and online processed quantities for the 20-high rolling mill
Typical
# Symbol
Description
range
Unit Type
Filter
1
T1
Input strip tension
⟨0; 50⟩
kN
uo
Outliers 3
2
T2
Output strip tension
⟨0; 50⟩
kN
uo
Outliers 3
3
vR
Ratio of input and output strip speeds ⟨0.5; 0.99⟩
uo
Outliers 5
4
v1
Input strip speed
1st pass:
uo
Outliers 5
⟨0.1; 0.3⟩m/s
another:
⟨0.5; 0.7⟩m/s
5
v2
output strip speed
1st pass:
uo
Outliers 5
⟨0.1; 0.3⟩m/s
another:
⟨0.5; 0.7⟩m/s
6
I1
Electric current of the input coiler
⟨50; 200⟩
A
∆p+
Smooth
7
I2
Electric current of the output coiler
⟨50; 200⟩
A
∆p+
Smooth
8
I
Electric current of the mill main drive
⟨20; 180⟩
A
∆p+
Smooth
9
h1
Deviation of input thickness
⟨−50; 50⟩µm
∆p+
—
from nominal value
10
h2
Deviation of output thickness
⟨−10; 10⟩µm
∆o
Limits
from nominal value
⟨−10; 10⟩
Quality markers
The concept of quality markers is introduced in Section 5.1.4. The deviation
of the output strip thickness from its nominal value is the key quality marker,
which must be kept as low as possible, practically in units of µm. To eval-
uate the output quality, three statistical performance indicators (capability
coeﬃcients), usual in statistical process control [179], are taken as quality
markers:
1. Statistical coeﬃcient Cp deﬁned
Cp = tol+
h2 + |tol−
h2|
6 σH2
,
(14.1)
where H2 denotes output thickness, h2 is its deviation from the nominal
value H2nom, tol+
h2, tol−
h2 are boundaries of tolerance range of h2 and
¯H2, σH2 are mean and standard deviation of the output thickness H2,
respectively. The coeﬃcient Cp describes variability of output thickness
H2 despite its magnitude, e.g., bias.
2. Statistical coeﬃcient Cpk deﬁned
Cpk = min(¯h2 −tol−
h2, tol+
h2 −¯h2)
3 σH2
,
(14.2)

14.1 Operation of a rolling mill
485
where ¯h2 denotes the mean of h2. The coeﬃcient Cpk describes the rela-
tive diﬀerence of the output thickness deviation h2 from the mean of the
tolerance range related to the variability of H2.
3. The coeﬃcient Cper representing the percentage of h2 being within the
tolerance range ⟨tol−
h2, tol+
h2⟩.
The aim of the quality control is to keep values of the coeﬃcients Cp, Cpk and
Cper as high as possible.
These markers were used according to the customer’s wish to compare the
product quality before and after implementation of the advisory system.
Preprocessing of data ﬁles
Data ﬁles corresponding to particular passes were grouped according to the
material type. Within each group, three subgroups were created for the ﬁrst,
and next even and odd passes through the mill. The corresponding data ﬁles
within a subgroup were merged into a ﬁle having 5 × 105 samples on average.
The subsequent mixture estimation provided acceptable results but it was
time consuming. Therefore only representative shorter parts from particular
data ﬁles were merged, preserving mutual ratios of data lengths.
Consequently, a typical data ﬁle within each subgroup contains roughly
30,000 samples of 10 selected data channels. As a result, n ﬁles have been
available for each rolling mill, where n = 3 × nmat and nmat is the number of
material types processed on the given rolling mill. The selection and merging
procedures were automated to allow repetition for new sets of process data.
The selected quantities and the way of their ﬁltering for the 20-high rolling
mill are in Table 14.1. There, the number given for outliers removal means
a multiple of standard deviation as a half-width of an acceptance interval
around the estimated mean; see 6.2.2 and 6.2.3.
Before further analysis, data in each channel were scaled to zero mean and
unit variance.
Static mixture estimation
The static mixtures can be considered as a smooth approximation of multidi-
mensional histograms representing the number of occurrences of data points in
the 10-dimensional (10-D) space. As an input, the data gained during the op-
eration of an experienced operator, yielding a high-quality product, are used.
The adjustment of the actual working point into a location where data points
occurred most often during the good rolling should lead to a high-quality
product.
Preprocessed data ﬁles were used for an iterative estimation in the oﬄine
mode using the Mixtools function mixinit [180] that provides initialization
by hierarchical factor splitting and implements the normal version of Algo-
rithm 6.8. Typically, ten iterations per data ﬁle were used. The runtime of
estimation for a single ﬁle with 30,000 records on a 1 GHz machine was about

486
14 Applications of the advisory system
10 minutes for default options, 160 minutes when batch quasi-Bayes estima-
tion was applied. On average, nine components were estimated.
Comparison of the estimated mixture with the empirical pdf constructed
from multidimensional histograms served as the main indicator of the estima-
tion success. The estimated mixture seems to be quite fair for some selected
2-D projections, while for another projection with crumbled data clusters it
is problematic. Improvements have been achieved by utilizing nondefault op-
tions for the identiﬁcation procedure. Essentially, the changes have to reﬂect
high diﬀerences of noise-level in processed data-record entries. At the end, an
15
20
25
30
80
90
100
110
120
130
140
150
160
170
OutStripTension [kN]
MillDriveCurrent [A]
Mixture contour
15
20
25
30
80
90
100
110
120
130
140
150
160
170
OutStripTension [kN]
MillDriveCurrent [A]
Mixture composition
Fig. 14.2. Left plot: 2-D marginal projection of a static mixture for two selected
data channels. Right plot: composition of the mixture from particular components.
acceptable compromise was achieved considering diﬀerent importance of data
channels from the application point of view. A two-dimensional projection of
a typical static mixture is shown in the Fig. 14.2. For the 20-high rolling mill,
estimated static mixtures are used as inputs for online operation according to
the type of material and pass number.
Dynamic mixture estimation
Despite its clear interpretation, the static approach does not respect depen-
dence of a current state of the system on its recent history, i.e., does not model
the system evolution. The ﬁrst-order auto-regression was found suﬃcient to
describe estimated dynamic components. The order of the model was chosen
with respect to sampling rate, human reaction times and closed-loop behav-
ior. The estimates were periodically corrected (after each pass) and used in
the ﬁxed advisory system. The fully adaptive advisory system was not used
yet.
Zero- and second-order models were also tried The quality of these al-
ternatives was compared according to values of logarithmic v-likelihood and

14.1 Operation of a rolling mill
487
by inspecting prediction errors. Based on these tests, the ﬁrst-order model
was chosen as optimal. The same comparison was used for a ﬁner tuning of
optional parameters of the estimation procedure.
Typical processing time of the dynamic estimation on the same machine
as above is approximately 5 minutes for default options and 120 minutes for
the batch quasi-Bayes option with three detected components in average.
As an alternative to a dual static/dynamic estimation, a pseudo-dynamic
approach has been investigated; cf. Section 6.4.9. The static mixture describ-
ing data vector, containing also one delayed data record was estimated. The
processing combines intuitively appealing histogram interpretation while re-
specting the dynamic nature of dependencies among data records. Dynamic
models are obtained by appropriate conditioning; see Proposition 7.2.
Simultaneous design
The simultaneous design, Section 5.4.6, was applied for advising at the 20-high
rolling mill.
The user’s ideal pdf
⌊Uf for the 20-high rolling mill was constructed as
a static normal pdf that respects the treated regulated problem and aims of
the control.
Speciﬁcally, the following correspondence to general notions applies
uo = (T1, T2, vR, v1, v2) recognizable actions
∆o = (h2) o-innovations
∆p+ = (I1, I2, I, h1) surplus p-data.
The user’s ideal pdf is expressed as (see Section 5.4.6)
⌊Uf(d(˚t)) =
˚t 
t=1
⌊Uf(dt|d(t −1))
=
˚t 
t=1
⌊Uf(∆o;t) ⌊Uf(uo;t) ⌊Uf(ct) ⌊If(∆p+;t|d(t −1)). (14.3)
The user’s ideal pf ⌊Uf(ct) served only for exclusion of dangerous components.
It was set as uniform one on nondangerous components as the user cannot
make any statement about them.
The term ⌊If(∆p+;t|d(t−1)) concerns quantities that cannot be inﬂuenced
by the operator and therefore they are “left to their fate”, i.e., no requirements
are put on them.
The term ⌊Uf(∆o;t) is the key factor in the true user’s ideal. It expresses
the main management aim. As the innovation h2 is continuous, ⌊Uf(∆o;t) has
a form of normal pdf Nh2(0, σh2). The zero expectation expresses the wish to
get zero deviations of the output thickness from the technologically prescribed
value. The value of σh2 expresses acceptable spread of these deviations. It is

488
14 Applications of the advisory system
related to the desired coeﬃcient Cp (14.1). For instance, if Cp is required to be
4/3, then σh2 ≡σH2 must be 8-times contained in the interval ⟨tol−
h2, tol+
h2⟩.
Then σh2 = (tol+
h2 + |tol−
h2|)/8.
The pdf ⌊Uf(uo;t) concerning recognizable actions was chosen as a product
of one-dimensional normal pdfs. Their means and variances express the tech-
nologically desirable ranges of these quantities; see Table 14.1. Their choice
was made similarly as for the output thickness.
The parameters of time-invariant pdfs
⌊Uf(ct),
⌊Uf(∆o;t) and
⌊Uf(uo;t)
together with a list of corresponding data channels are passed to the design
procedures that generate the optimized ideal mixture ⌊If(dt|d(t −1)).
The advisory mixture is obtained by projection of ⌊If to the space (uo, ∆o),
i.e., the advisory mixture is
⌊If(uo;t, ∆o;t|∆p+;t, d(t −1)).
(14.4)
The overall procedure of simultaneous design is described in Algorithm 7.9.
Online phase
The online phase was fully implemented for the 20-high rolling mill.
Generating advices
Based on oﬄine results of mixture estimations, the advisory part of the system
uses the newest available data for generating recommendations to operators.
The shapes and weights of advisory mixture components are recalculated for
each new data record and assign the probability of the best possible location of
the working point. Marginal pdfs of the advisory mixture (14.4) are evaluated
for all o-data channels di;t, i = 1, . . . , ˚
do. The recommended values correspond
with the modes of these one-dimensional projections.
The limited extent of the o-data allowed us to avoid a presentation prob-
lem.
A heuristic solution of signaling problem is temporarily implemented.
A simple distance between the actual working point and its best recommended
location is evaluated permanently and set up as an “alarm” when it is found
that the setting should be changed.
Mixture updating and adaptivity
The adaptive advisory system updates online the mixture estimate, repeats
the design with each new data record and uses the updated advisory mix-
ture. Historical (slower machines) and practical (separation of advising and
updating) reasons make us use a ﬁxed advisory system. To allow learning, the
estimated mixtures are updated and redesigned online by a parallel process
during each pass, for each material and each pass subgroup (ﬁrst, odd and
even; see paragraph concerning data preprocessing). For the new pass of the
given subgroup, the updated advisory mixtures are used.

14.1 Operation of a rolling mill
489
14.1.3 Implementation
The advisory system has been implemented into the distributed control sys-
tem by Compureg Plzeˇn, s.r.o. The implementation was realized in the form
of a dedicated server and a visualization node equipped with a special graph-
ical user interface (GUI). A speciﬁc eﬀort was made to enable the bulk of
computation to be executed either under MS Windows or Linux operating
systems.
The server
The server executes the following two main applications.
Adviser loads a proper mixture ﬁle at the beginning of the pass and then,
when appropriate, uses new data record for evaluating the advisory mix-
ture and its marginal projections to be displayed for operators;
Updater uses data samples corresponding to a good rolling for updating the
mixture. Thus, the system can reﬁne the estimates and learn new possible
locations of “good” working points.
Both applications use a multithreading technique that allows us to opti-
mize the system performance. Programs are coded in ANSI C, and the Tcl
language/interpreter is used for interface to a human supervisor. This together
with the appropriate version of the Mixtools library [180] makes porting to
another computer platform easy.
Graphical user interface
A visualization node was introduced for the control system on which the ded-
icated GUI for operators is executed. The application can be used in a one-
dimensional (1-D; Fig. 14.3) and two-dimensional (2-D; Fig. 14.4) modes,
which project selected quantities of (14.4), and compares them with their ac-
tual values. Values of the projected pdfs are transformed into a color scale and
actual working points are marked by a black line. Its basic properties and ap-
pearance can be easily modiﬁed through a conﬁguration ﬁle. Whatever mode
is selected, the GUI displays the overall status of the system in the form of
traﬃc lights where “green” status means “no recommendations”. The quan-
tity to be changed primarily is emphasized, together with its recommended
value. For 2-D mode, the operator can select data channels whose marginal
mixture projection should be plotted. OpenGL functions are used for smooth
online animations.
14.1.4 Results
Oﬄine processing of data from two 4-high rolling mills was made mainly to
conﬁrm functionality of developed algorithms and to verify generality of the

490
14 Applications of the advisory system
Fig. 14.3. Screenshot of the Graphical User Interface for 1-D mode.
approach. Qualitatively, the results were satisfactory. As the advisory loop
was not closed, no overall quantitative evaluation was made.
The case of the 20-high rolling mill was brought to online use enabling us
to compare statistically the production before and after the implementation.
The tolerance range was set to tol+
h2 = 10 µm, tol−
h2 = −10 µm for all
cases. Data collected within 20 months prior to implementation were taken as
the basis for comparisons. More than two months of the new system operation
were taken into account for the ﬁnal evaluation. Comparisons were made for
several sorts of materials, which were processed in both the periods.
Numbers for comparisons were obtained by SQL queries to production
databases. The following values were evaluated:
•
Averages of the rolling speed,
•
Averages of coeﬃcients Cp, Cpk and Cper.
Quality markers for results evaluation are represented by relative diﬀer-
ences of these values (in percent) between the production before and after
installation of the advisory system. For example, ∆¯Cp is deﬁned as
∆¯Cp = ( ¯Cp)after −( ¯Cp)before
( ¯Cp)before
· 100%.
The values ∆¯Cpk, ∆¯Cper and ∆¯v2 are deﬁned similarly.
Six common material types, marked by capital letters, were tested in both
periods. Percentage improvements of monitored values are summarized in Ta-
ble 14.2. First pass and further passes are distinguished in comparisons since

14.1 Operation of a rolling mill
491
Fig. 14.4. Screenshot of the Graphical User Interface for 2-D mode.
conditions for both cases diﬀer. The Cper coeﬃcient was evaluated for last
passes only.
Table 14.2. Percentage improvements of quality markers for the 20-high mill.
Material
A
B
C
D
E
F
Weighted
Quality Marker
mean
∆¯Cp
0.98
0.50
-0.69
-0.14
0.66
0.72
0.45
Pass 1
∆¯Cpk
43.36 15.45 28.57 16.13 39.39
0.00
4.84
∆¯v2
13.33 29.41 58.33 17.65 47.37 10.53
17.08
∆¯Cp
31.87 24.68 83.33 -2.94 89.29 -1.08
9.51
Pass 2+
∆¯Cpk
25.30
6.25 105.41
5.00 85.45
1.43
12.36
∆¯v2
16.67 42.86 62.96 16.67 26.83 29.41
33.41
Last pass ∆¯Cper 42.76 16.22 33.33 25.81 45.95
0.68
5.50
14.1.5 Conclusions
The system turned out to stabilize the highest product quality and delimit
secure machine settings for the whole variety of working conditions. Obtained
results, Table 14.2, validate prior expectations that the rolling speed can be

492
14 Applications of the advisory system
increased by up to 40% (depending on the pass number and material type)
while preserving the highest product quality.
The results are encouraging in spite of the fact that the improvements
are limited by the amount of information contained in the available data —
relatively small and ﬁne mill and low rolling speed. At the same time, we are
aware that utilization for high-speed steel mills will undoubtedly need more
computing power and probably a further development as well.
14.2 Treatment of thyroid gland cancer
Treatment of thyroid gland tumor using 131I is another important application
area tried.
The task is to help physicians to decide on administration of an individual
amount of radioactive 131I for a speciﬁc patient using information hidden
in retrospective data. The decisions in this application were supported by
a ﬁxed advisory system. Its advisory mixture can be modiﬁed periodically
after collecting enough new patient data records.
14.2.1 Problem description
Treatment of thyroid gland carcinoma is a complex process involving en-
docrinology, histology, surgery, radiology and other branches of medicine. The
current section pertains to support of the radiological treatment [181].
Thyroid gland and iodine
The thyroid gland accumulates anorganic iodine from blood and incorporates
it into thyroid hormones. A stable isotope of iodine is 127
53I, simply denoted
as 127I. Radioactive isotope is chemically identical to the stable one but it
has a diﬀerent number of neutrons in the nucleus. Such a nucleus is unstable,
i.e., it can spontaneously change and emit one or more ionizing particles. The
nucleus of 131I produces ionizing particles of β- and γ-radiation due to nuclear
decays. Thyroid accumulating 131I becomes a source of ionizing radiation. The
thyroid tissue is almost unaﬀected by γ-particles (high-energy photons). The
majority of them are not absorbed in the tissue and they can be detected
outside the body. Almost all β-particles (electrons) are absorbed in the tissue
and their energy is passed to the tissue. The half-life ⌊pT of 131I — the time
in which one half of the radioactive nuclei takes a change — is approximately
8 days.
Radiotherapy of thyroid cancer
A thyroid tumor is usually removed by surgery. What remains or reappears
is destroyed by radiotherapy. The radiotherapy has a diagnostic and a thera-
peutic stage.

14.2 Treatment of thyroid gland cancer
493
In the diagnostic stage, 131I in the form of sodium or potassium iodide
of a low diagnostic (tracer) activity is administered orally to a patient. This
activity is about 70 MBq = 70×106 changes per second in mean. Then, several
measurements are performed, detecting γ-radiation from the accumulating
tissues, and some quantities describing the kinetics of 131I are evaluated. This
information is used for the decision about the next therapeutic stage.
In the therapeutic stage, the patient is administered the solution with 131I
of a high activity in the range 3–10 GBq. The therapeutic dose, representing
the absorbed energy of β-radiation caused by 131I accumulated in the thyroid,
destroys the thyroid tissue.
About 3–6 months later, the diagnostic stage is repeated to examine the
therapy result.
Notations, terms and quantities
The notation adopted in this section follows the conventions introduced in this
book. Hence, it diﬀers from a notation usual in other thyroid-related papers.
Continuous time will be denoted as ρ, discrete time index as t. Discrete
(indexed) time is denoted as ρt. A value of a quantity X in a time instant t is
denoted as Xt ≡Xρt. A quantity X as a function of time ρ is denoted as Xρ.
After the administration, 131I is distributed over the body and accumu-
lated in thyroid gland and, possibly, other tissues, called lesions, and partially
over a patient’s whole body. Lesions are usually metastases of the primary tu-
mor. Here, we include thyroid gland among them.
The thyroid activity rapidly increases, reaches its maximum within hours
and then slowly decreases within days or weeks. The activity of lesions and
the whole body can be evaluated and sequences {At, ρt} of activity At sam-
pled in time ρt. However, activity is not directly measurable and just a few,
rather noisy, indirect measurements are available. A nontrivial, theoretical
and Bayesian algorithmic solution of its estimation is summarized in [182].
Administered activity A0 is activity of 131I salt solution drunk by the pa-
tient. The diagnostic administration is denoted as ⌊dA0 and the therapeutic
one as ⌊tA0.
Dosimetric data are sequences of activity in time {(At, ρt)} concerning the
given lesion or the whole body.
The eﬀective half-life
⌊efT is a parameter of a mono-exponential model
describing decrease of activity of a lesion in time. The mono-exponential model
uses the maximum A1 of the activity course in the time ρ1 and predicts the
activity Aρ in time ρ as follows
Aρ = A1 exp

−ρ −ρ1
⌊efT
ln 2

.
(14.5)
The model describes the activity course only for ρ > ρ1. Eﬀective half-life
⌊efT combines physical and biological mechanisms of activity decrease and
quantiﬁes its rate.

494
14 Applications of the advisory system
Residence time τ is a time for which all the administered activity hypo-
thetically “resided” in a selected tissue to cause the same irradiation eﬀect,
i.e.,
τ = 1
A0
+∞

0
Aρ dρ.
(14.6)
The residence time is proportional to radiation dose — energy per mass unit
— absorbed in the tissue. Values concerning the diagnostic or therapeutic
administration are denoted ⌊dτ or ⌊tτ, respectively.
Relative activity (uptake) ⌊rA is a percentage of the absolute lesion activity
A from the administered activity corrected to the physical decay, i.e.,
⌊rA =
A
A0 exp

−
ρ
⌊pT ln 2
 100 %.
(14.7)
Time ρ is set to zero at the administration moment. Uptake informs about the
ability of the lesion to accumulate 131I. Usual values of the maximum thyroid
uptake are up to 5 %.
Excretion of the activity ⌊rE is a relative activity diluted from the body
within some time interval. Typically, the intervals used for its description
are 0–24 hours, ⌊rE2, and 24–48 hours, ⌊rE3, after the administration. These
values are estimated from measurements of the whole-body activity and carry
additional information about 131I kinetics in the organism. They are evaluated
after the diagnostic administration only.
14.2.2 Problem and its solution
The aim is to recommend such a value of administered activity ⌊tA0 for ther-
apy so that 3–6 months later the maximum uptake ⌊rmnA is less than 0.18 %.
The value ⌊tA0 should be chosen as low as possible.
The solution consists of oﬄine estimation of a static mixture on the his-
torical patient data and online generation of a recommendation on ⌊tA0.
Therapeutic activity ⌊tA0 is a key quantity inﬂuencing the treatment suc-
cess, because the dose absorbed in the thyroid tissue is proportional to it.
A decision on the optimal value of
⌊tA0 is the responsibility of the physi-
cian. The value of
⌊tA0 must be high enough so that the aﬀected tissue is
destroyed. This is quantiﬁed by the negligible accumulation ability after the
therapy. However, the administered activity must be low enough to meet pre-
scribed irradiation limits and to minimize secondary radiation risks.
Oﬄine phase
Data
The data used for the mixture analysis were collected from 1992 on more than
6500 patients. After reorganizing and preprocessing, the ﬁnal data ﬁle contains

14.2 Treatment of thyroid gland cancer
495
about 1200 complete records of 12 biophysical quantities directly measured or
estimated using Bayesian methodology [183, 184].
The quantities chosen for each record are described in the Table 14.3.
Table 14.3. Quantities used in the advisory system for nuclear medicine
Typical
# Symbol
Description
range
Unit Type
1
g
Patient’s gender: 0=female, 1=male
{0, 1}
∆p+
2
a
Patient’s age
⟨7; 85⟩
year ∆p+
3
⌊dA0
Diagnostic administered activity
⟨10; 130⟩
MBq ∆p+
before therapy
4
⌊ln
Number of lesions
⟨1; 5⟩
∆p+
5
⌊efdT
Diagnostic thyroidal eﬀective half-life
⟨0.1; 8⟩
day
∆p+
6
⌊dτ
Diagnostic thyroidal residence time
⟨0.000 4; 1⟩
day
∆p+
7
⌊rmdA Maximum diagnostic thyroid uptake
⟨0.01; 25⟩
%
∆p+
before therapy
8
⌊rE2
Excretions 0–24 hours
⟨15; 88⟩
%
∆p+
9
⌊rE3
Excretions 24–48 hours
⟨0.8; 34⟩
%
∆p+
10
⌊tn
Number of previous therapies
⟨0; 5⟩
∆p+
11
⌊tA0
Therapeutic administered activity
⟨1 700; 8 300⟩MBq
uo
12
⌊rmnA Maximum diagnostic thyroid uptake
⟨0.01; 1.22⟩
%
∆o
after therapy
One data record contains information about one patient concerning his
single therapeutic and two diagnostic administrations: 2–3 days before and 3–
6 months after the therapy. Data records of diﬀerent patients are undoubtedly
mutually independent. One patient can have more records if more therapies
have been absolved. Although an individual patient’s history is causal, time
interval between two therapies is in the order of months to years. This allows
us to assume weak mutual dependence of records even for one patient. There-
fore a static model of the whole patient population provides “natural” data
description. With the “delayed” diagnostic uptake after therapy in the record,
the model is pseudo-dynamic.
Quality marker
The less thyroid tissue remained after therapy, the less activity it accumulates.
The therapy is taken as successful if the accumulation activity is negligible.
The marker of the therapy success is a maximum relative activity ⌊rmnA
(uptake) reached by the thyroid gland in the diagnostic administration of 131I

496
14 Applications of the advisory system
after the therapy. Ideally, after a successful therapy, ⌊rmnA = 0. Practically,
⌊rmnA < 0.18 % of the administered activity represents a successful therapy.
Preprocessing of the data ﬁles
Records with missing data were excluded. For the complete preserved records,
the data were tested for physically and medically meaningful ranges to avoid
cases with mistyped values or outliers of another origin. Due to this operation,
other records of the original number were lost.
Because of numerical reasons, each quantity was scaled to zero mean and
unit variance. All the estimations and computations were performed with the
scaled data. The results are presented in their original scales.
Static mixture estimation
The addressed problem and its technical conditions lead to the following cor-
respondence of data entries to the general notions presented in Chapter 5
uo = ⌊tA0 recognizable action
(14.8)
∆o = ⌊rmnA o-innovation
∆p+ = (g, a, ⌊dA0, ⌊ln, ⌊efdT, ⌊dτ, ⌊rmdA, ⌊rE2, ⌊rE3, ⌊tn) surplus p-data.
The meaning of respective quantities is summarized in Table 14.3.
The 12-dimensional data space ( ⌊tA0, ⌊rmnA, ∆p+) was examined for the
occurrence of clusters. The parameters and structure of the normal static mix-
ture f( ⌊tA0, ⌊rmnA, ∆p+|Θ) (see 5.9) were estimated. Three processing ways
were tried.
BMTB algorithm: An older, less elaborated variant of the sandwich algorithm
providing Bayesian extension of the mean-tracking algorithm [154] was
tried; see Chapter 12. It is computationally very cheap, but, unfortunately,
it failed in the sparsely populated data space available.
AutoClass software: This freely available software [42] detects clusters using
the EM algorithm (see Chapter 8) with random starts. Repetitive searches
increase the probability of ﬁnding a better description of clusters but the
computational cost increases, too. Over 700 000 random starts have been
tried to get stable results. Low dimensions of the data set have allowed it.
The best result was used as partial prior information for processing cor-
responding fully to the theory and algorithm described in Chapter 8.
Hierarchical splitting, quasi-Bayes algorithm and AutoClass: An older version
of initialization [44] and quasi-Bayes algorithm as implemented in Mix-
tools [180] were used. The results were enhanced by exploiting partially
results obtained by AutoClass.

14.2 Treatment of thyroid gland cancer
497
Simultaneous design
The simultaneous design, described in Section 5.4.6 and elaborated in Proposi-
tion 9.15, was applied. It means that the component weights were interpreted
more as elements of the mixture approximating the objective distribution
of data records than objective values reﬂecting characteristics of the patient
population.
As the parameters Θ are assumed to be known in the design, they will be
omitted in the notation below. Using the notation introduced in (14.8), the
user ideal pdf ⌊Uf(d(˚t)) was deﬁned in the same way like in (14.3). Uniform pf
⌊Uf(ct) was chosen. The true user’s ideal for the recognizable action ⌊Uf(uo;t)
was set to N ⌊tA0(3 500, 800). This pdf has practical support within the usual
range of administered activities. The true user ideal pdf of ∆o;t was chosen
conditioned by the value of uo;t in the following way:
⌊Uf(∆o;t|uo;t) = N ⌊rmnA(g( ⌊tA0), 0.03),
where g( ⌊tA0) = a ⌊tA0 + b, a < 0. The values of a and b were chosen so that
the range of ⌊tA0 shown in the Table 14.3 is linearly mapped to the required
range of ⌊rmnA ∈(0; 0.18) with a negative slope. Using this formulation, the
intention to minimize therapeutic administered activity ⌊tA0 was expressed.
After the design made by Algorithm 7.9, the constructed ideal pdf was
projected into d∗
o ≡⌊rmnA, ⌊tA0∗giving the advisory mixture ⌊If(uo, ∆o|∆p+).
Online phase
The statistics of the ideal pdf ⌊If( ⌊rmnA, ⌊tA0|∆p+) conditioned by the actual
patient’s data ∆p+ were evaluated. The maximum of the pdf indicates the
recommended value of ⌊tA0 with predicted value of corresponding ⌊rmnA. The
example with a two-dimensional pdf map and one-dimensional marginal pdfs
of both quantities is shown in the Figure 14.5.
14.2.3 Implementation
The initial versions of advisory modules were programmed in C++. An original
API capable of transferring Matlab mex-functions into stand-alone applica-
tions was used to take advantage of ready-made Mixtools algorithms. The
application accepting data ∆p+ and computing a grid of the corresponding
⌊If( ⌊rmnA, ⌊tA0|∆p+) was integrated into the system Iodine III [185]. This sys-
tem, written in MS Visual FoxPro, cares about data management and evalu-
ation of a range of Bayesian estimates of various biophysical quantities. The
presented GUI is a part of this system.
Graphical presentations of advices are shown in Figure 14.5. The inter-
active color pdf map allows physicians to try, for the given patient, various

498
14 Applications of the advisory system
planned administrations by clicking on the map and examining the conse-
quences, i.e., to predict values of ⌊rmnA. The GUI allows to classify the ad-
vices for testing purposes, save the data, restore data of previously processed
patients and adjust GUI.
Fig. 14.5. Screenshot of Iodine III with interactive probability density map
on the left and bars with marginal pdfs at the bottom and on the right
14.2.4 Results
With the cooperation of physicians from the Clinic of Nuclear Medicine and
Endocrinology, Motol Hospital, Prague, the advices were tested for 101 pa-
tients. The recommended values of ⌊tA0 were compared to those decided by
the physicians.
It was observed that the best coincidence was reached in the cases when
a patient ﬁrst visited the clinic for a radio-destruction of thyroid remnants
after thyroid removal during surgery. These patients usually suﬀer from a pri-
mary tumor, i.e., only the thyroid is aﬀected and no metastases are usually
developed.
In these cases, the treatment procedure usually does not depend on other
quantities like histology of the tumor, biochemical analyzes, etc. The diﬀer-
ences between the recommended and decided value of ⌊tA0 in these cases are
below 15 %. These cases represent 46 % of the tested patients. A diﬀerence
below 10 % was observed in 31 % of the tested patients.

14.3 Prediction of traﬃc quantities
499
In cases of therapy repetition due to the tumor reappearance, the coin-
cidence was much lower. A diﬀerence above 50 % was observed in 15 % of
patients. Generally, the advisory system recommends lower values than the
physicians. Decision in this category depends also on other examinations than
the used dosimetric ones. Unfortunately, these vital data have not been avail-
able in the clinic in a form suitable for automatic processing.
14.2.5 Conclusions
The described advisory system is an original application of the mixture the-
ory in this ﬁeld. However, the task is speciﬁc to a small amount of the data
available; therefore the results of the learning stage depend heavily on prior
information. The AutoClass initialization has improved performance of the
tested version of the Mixtools. Even with the prior obtained on the basis of
700 000 random starts, the model designed for the advising has acceptable
physical interpretation only in about one-half of the cases. The advices are
sensitive to mixture estimation. The key assumption, that the requested in-
formation is contained in the available data set, seems to be violated by using
only a subset of data that is only accessible in a systematic way. The GIGO
principle (garbage in, garbage out) is manifested here.
Anyway, the subset of cases relevant to the data set and the way of its pro-
cessing, 46 % in this application, exhibits satisfactory results. Moreover, the
quantitatively demonstrated conclusion that dosimetric data are insuﬃcient
for controlling the therapy has initiated the reorganization of data acquisition.
Consequently, the advising based also on additional informative data will be
possible in the near future. The nature of the considered data implies that
the use of mixed data mixtures, Chapter 13, will be inevitable.
14.3 Prediction of traﬃc quantities
With an increasing number of cars, various signiﬁcant transportation problems
emerge, especially those concerning urban traﬃc, [186], [187]. Feedback control
via existing traﬃc lights is a viable way to decrease them.
14.3.1 Problem description
The control design for complex traﬃc systems has to be build by solving
partial, mutually harmonized, subtasks. Among them, the prediction of the
traﬃc state is of primary importance. Here, we demonstrate appropriateness
of predicting traﬃc quantities based on a mixture model.

500
14 Applications of the advisory system
Prediction of urban traﬃc state
Solution of urban transportation problems via reconstruction of the street
network is expensive and very limited as it has to respect the existing urban
conditions. Thus, the capacity of the network has to be eﬃciently exploited.
This makes feedback traﬃc control utilizing the available traﬃc lights ex-
tremely important. Its design has to be able to predict a future traﬃc state
for a given regime of traﬃc lights. Only with such a model, the regime can be
varied to increase the permeability of city crossroads network. For it, mixture
modelling seems to be suitable. Changes of daily and seasonal traﬃc indicate
it clearly.
Notations, terms and quantities
Controlled networks are split into microregions. They are logically self-
contained transportation areas of several cross-roads with their adjoining
roads. Their modelling and feedback control exploit data measured by de-
tectors based on inductive electric coils placed under the road surface. The
presence of a huge metallic object above the coil changes its magnetic prop-
erties and thus individual cars are detected. Each detector signals a presence
or absence of a car above it. From this signal, basic transportation quantities
are evaluated:
•
Occupancy o, which is deﬁned as the portion (in %) of the time when the
inspected place is occupied by cars.
•
Intensity q expressing the number of cars per hour.
•
Density ρ, which is deﬁned as the number of cars per kilometer of the
traﬃc ﬂow. Specifying an average length of cars, it is computed as a ratio
of occupancy and average car length.
Intensity and density describe the traﬃc state at the detector position.
14.3.2 Problem and its solution
Crossroads in cities are controlled by setting a proper green proportion and
cycle length of the signal lights. Mostly, these signals are set according to
a working plan whose changes during the day are given by a ﬁxed schedule.
Automatic feedback in selection of these plans can improve quality of the
traﬃc signiﬁcantly.
For the control, knowledge of traﬃc ﬂow state incoming into the micro-
region in the near future is necessary. Reliable and possibly multistep predic-
tion of the traﬃc ﬂow can decide about practical success of such a feedback
control.

14.3 Prediction of traﬃc quantities
501
Oﬄine phase
Data
For experiments, 20-dimensional data records measured along two traﬃc lanes
of the Strahov tunnel in Prague were used. The length of the tunnel is 2 km
with two lanes in each direction. The detectors are placed after 500 m un-
der each lane. Traﬃc in the tunnel is relatively ﬂuent and almost no traﬃc
congestions are observed.
Time course of the measured quantities on detectors reﬂects natural trans-
portation periodicity. It is clearly seen on the Fig. 14.6, showing a typical time
course of intensity and density of traﬃc ﬂow for about 4 weeks.
Time course of density ρ
Time course of intensity q
Fig. 14.6. Traﬃc quantities from the middle of the tunnel
The daily periodicity is visible there. At night, the traﬃc intensity is very
low. In the morning, the demands rapidly rise due to the cars of commuters
and increased commercial transport. The intensity of the traﬃc reaches soon
its maximum and a slight fall is observed around noon. Then, it rises again
and the saturation lasts until the evening when the intensity starts to fall
gradually to zero. The weekly periodicity connected with alternating work
days and weekends is also strongly reﬂected in the data.
The available detectors provide 5-minutes samples of the traﬃc intensity
and density. Data from 10 detectors are recorded giving 20-dimensional data
record each 5 minutes, 288 vectors per day.
About 8 500 data records reﬂecting approximately 4 weeks period were
used for learning and 300 data records corresponding to 1 day served for
testing.
Quality marker
Quality of models used as predictors is judged using the relative standard
deviation Ri of the prediction error ˆei;t ≡di;t −ˆdi;t of the ith data entry di;t,

502
14 Applications of the advisory system
ith channel,
Ri ≡
C
2
t∈t∗ˆe2
i;t
2
t∈t∗(di;t −¯di)2 , i = 1, . . . , ˚
d = 20, ¯di ≡sample mean of di;t t ∈t∗.
(14.9)
In (14.9), the point prediction ˆdi;t is an approximate conditional expectation
of di;t.
Preprocessing of data
Experience shows that detectors are fault-prone and their reparation is far
from being easy. Therefore the ﬁltration of their data is necessary. Here, outlier
ﬁltration and normalization to zero mean and unit standard deviation were
applied on the raw data.
Model for prediction
The traﬃc system switches among several very diﬀerent states. A mixture
model has been chosen as a proper tool for modelling of this eﬀect.
The model is built in the learning oﬄine phase and is used for prediction
with another part of the data. During the learning, the joint pdf of the mod-
elled data record is estimated. Then, the pdf predicting selected channel(s)
conditioned on other measured data is created. It is used for point or interval
predictions of the channels of interest.
Estimation of mixture models
Both static and dynamic normal mixture models were used.
Experiments with the static case inspected the contribution of multivariate
modelling and of the switching among various components.
Auto-regressions of the ﬁrst-order used in the dynamic case were found
adequate for modelling and predicting 20-dimensional data records. Mixtures
with components having higher order brought no improvements.
The initialization based on hierarchical factor splitting and implementing
the normal version of Algorithm 6.8, [44], was used. It determined a ﬁner struc-
ture of components and their number. Up to six components were found. In
all cases, at least three of these components had non-negligible weights. Some
components had almost zero weights but it is interesting that their omission
decreased the prediction quality visibly. The rarely populated components de-
scribed outlying data and consequently improved parameter estimates of the
remaining components.
Online phase
The traﬃc application has not reached the implementation phase yet mainly
because of economical reasons. Thus, testing of predictive capabilities of the

14.3 Prediction of traﬃc quantities
503
learnt models on validation data was used as a substitution of their online
use. It imitates well application of the models as ﬁxed predictors.
The test were performed in the experimental and development environ-
ment provided by the Mixtools toolbox [180].
14.3.3 Experiments
The experiments veriﬁed the ability of the estimated mixture model to predict
well the state of the traﬃc ﬂow at the northern exit of the tunnel using the
data along the whole tunnel.
Prediction quality of the inspected mixture model (MIX) was compared
with the one-component mixture, i.e., with the auto-regression (AR) model.
The comparison of results is used both for the static and dynamic case.
The choice of the best model variant was based on the corresponding v-
likelihood. The function of the obtained predictors was quantiﬁed by the per-
formance index Ri (14.9). Its dependence on the number of modelled channels
˚
d and the number of prediction steps, are presented in Tables 14.4 and 14.5.
Static mixture estimation
Static normal components predict the future data by their oﬀsets only. The
prediction made with them shows the need for dynamic modelling and supe-
riority of the mixture model in comparison to the corresponding AR model.
This superiority stems from the data-dependent switching between compo-
nents, i.e., between diﬀerent oﬀsets.
The two-dimensional model of intensity and density at the tunnel exit, 1st
and 2nd channel, ˚
d = 2, was estimated only.
Table 14.4 shows prediction quality expressed by the marker Ri, i = 1, 2
(14.9) for two modelled channels and the prediction horizon ranging from 1 to
18 steps, which corresponds to the range from 5 to 90 minutes.
Table 14.4. Multistep ahead predictions with static two-dimensional model. Ri is
the marker (14.9) for channels i = 1, 2 (˚
d = 2). Results related to the mixture and
auto-regression models are marked “MIX” and “AR”, respectively.
R1
R2
Steps ahead
MIX
AR
MIX
AR
1
(5 min)
0.418
1.021
0.422
1.020
6 (30 min)
0.512
1.025
0.516
1.024
12 (60 min)
0.634
1.031
0.638
1.030
18 (90 min)
0.756
1.028
0.760
1.037
Figure 14.7 shows typical behavior of the compared autoregression “AR”
and static mixture “MIX” models on one-step and 18-step ahead predictions.

504
14 Applications of the advisory system
0
5
10
15
20
25
−1.5
−1
−0.5
0
0.5
1
1.5
2
0
5
10
15
20
25
−1.5
−1
−0.5
0
0.5
1
1.5
2
0
5
10
15
20
25
−1.5
−1
−0.5
0
0.5
1
1.5
2
1-step-ahead “AR”
1-step-ahead “MIX”
18-step-ahead “MIX”
Fig. 14.7. Prediction with auto-regression “AR” and static mixture “MIX” models.
Dots denote measured data, × predictions. Data are normalized to zero mean and
unit variance.
Dynamic mixture estimation
First-order normal components have been used. Mixtures with ˚
d = 2 and
˚
d = 20 were estimated, the latter was projected into the space of the channels
1 and 2.
Table 14.5 shows a comparison of the marker Ri, (14.9), for diﬀerent num-
ber of modelled channels used for multiple-step predictor. The length of pre-
dictions covers the range from 5 to 90 minutes (one step means 5 minutes).
Table 14.5. Multistep predictions with dynamic models. ˚
d — the number of mod-
elled channels, Ri the prediction marker (14.9) for channels i = 1, 2. The results are
related to the automatically initialized mixture model with four components found.
R1
R2
Steps ahead
1
6
12
18
1
6
12
18
˚
d = 2
0.34
0.45
0.56
0.68
0.48
1.05
1.09
1.12
˚
d = 20
0.32
0.41
0.54
0.67
0.86
0.91
0.93
0.96
14.3.4 Results
Comparison of auto-regression and mixture models
It can be seen, that the mixture models predict better, even though the signal
lights are preset into the mode preventing congestions inside the Strahov
tunnel and thus limiting other traﬃc modes. The mixture model also utilize
better the information from the additional entries of data records.

14.4 Conclusions on the applications
505
Static models
The good property of mixtures is clearly seen on Fig. 14.7. The static AR
model is able to predict only the mean value of the whole data sample. The
projected mixture, due to the data-dependent weights of individual compo-
nents, is able to follow even the ascending and descending trends of the data;
see Section 7.1.2. With the increasing length of prediction the ability to follow
data declines but the switching among components is clearly visible.
Dynamic models
They describe and thus predict data of this kind much better. For short-
term predictions, projected high dimensional model does not dominate over
the low-dimensional one. For longer-term predictions, advantage of the high-
dimensional model is clearly visible as it includes more information about the
traﬃc state.
14.3.5 Conclusions
In summary, mixtures are worth being considered for modelling and predic-
tion of high-dimensional transportation data. Their ability to make reason-
able multistep ahead predictions indicates their ability to grasp a signiﬁcant
portion of physical properties of the modelled systems. This is a necessary
precondition for applicability of a model in a control design.
14.4 Conclusions on the applications
14.4.1 Lessons learned
The applicability of the advisory system based on mixture models has been
tested on three real processes: rolling of metal strips, treatment of thyroid
gland tumor and prediction of transportation data. All of them have a multi-
modal nature that makes the use of ordinary linear models ineﬃcient.
The rolling mill application conﬁrmed that the adopted methodological
basis is sound and that the resulting algorithms can be applied with a mea-
surable increase of eﬃciency of the managed system. At the same time, it has
provided invaluable feedback to the reported research and clariﬁed priorities
for continuing research.
A speciﬁc trait seen on a nuclear medicine application is insuﬃciency of
data given by the technical conditions of the treatment and data measure-
ment. It makes the most visible the key application problem: the amount of
information on the system carried by the data has to be suﬃcient. According
to the GIGO principle (garbage in, garbage out), the quality of advices de-
pends on how much information in the data represents the system behavior

506
14 Applications of the advisory system
in its entirety. It is clear that lack of information in the data is crucial for
successful estimation and advising.
This application has also conﬁrmed the real need for a full coverage of
mixed-mixtures modelling.
All cases, and especially the experiments with traﬃc data, conﬁrmed that
mixture models, in spite of necessary approximations in their estimation, are
an excellent tool for description of multimodal systems.
14.4.2 Other application areas
The described applications are just samples from an extreme application do-
main of the described theory and algorithms. During the development of the
advisory system we met, for instance, the following tasks that can use eﬃ-
ciently the research outcomes
•
prediction of nonlinear phenomena like load in energy networks (electricity,
gas, heat),
•
modelling, prediction and evaluation of life-saving signals of prematurely
born children,
•
use of mixtures for speculative short-term monetary operations,
•
support of operators of large furnaces for producing glass or metal,
•
call for creating operation model to be used for training of operators of
complex processes,
•
attempt to use mixture models for fault detection and isolation [188],
•
eﬀort to use mixture models in complex social phenomena studied, for
instance, in connection with research in electronic democracy [129],

15
Concluding remarks
This work has its roots in decades of research within the Department of Adap-
tive Systems where the authors are working. The preliminary version of this
text arisen during solution of project IST-1999-12058 supported by European
Commission as a theoretical and algorithmic basis of the project solution. It
was substantially modiﬁed, improved, completed and reﬁned in subsequent
projects running within the department.
The IST project itself has been quite ambitious both with respect to its
content, planned short period between elaboration of the theoretical solu-
tions and the full scale use. The result is necessarily marked by the fact that
we needed to collect or design theoretical solutions that can be converted in
implementable algorithms. As such, it is unbalanced in its level, it is counter-
pedagogical, contains many repetitions and surely some inconsistencies, vari-
ous solutions have an ad hoc character, etc.
These problems may hide achievements we are proud of. First of all, our
formulation of the design of the advisory systems is novel and represents
an extension of the classical decision-making theory for a dynamic uncertain
system. Consequently, it has the generic nature and an extreme applicability
width. The following list underlines some points within this framework we feel
as crucial achievements.
1. Academic, industrial and simultaneous advising were formulated and
solved using approximate probabilistic optimization of advising.
2. Dynamic mixture modelling and prediction provide a novel and powerful
decision-supporting tool.
3. Problem of the mixture estimation with mixed dynamic components has
not been solved before to the extent presented here.
4. The designed estimation algorithms admit adaptive online clustering with
an extreme potential for a permanent improvements of managing.
5. The basic initialization of the mixture estimation seems to be a novel tool
applicable in high-dimensional data spaces.

508
15 Concluding remarks
It also solves – to a substantial extent – the structure estimation problem
that is known to be crucial in the mixture estimation.
6. Both estimation and design for the basic normal factors, use eﬃcient,
numerically robust, factorized algorithms.
7. Claims above are supported by the diversity of the successful applications
we have managed to implement within the project span; see Chapter 14.
We are aware that a lot of things are unﬁnished and some of them are missing.
The crucial steps that should be done are as follows.
1. Oﬄine prediction of closed loop performance of the advisory system should
be done, in the vein of the project DESIGNER [115, 148, 189].
2. Filtering counterpart of the learning should be made. This would allow
us to exploit process knowledge more deeply and to express management
aims more directly.
3. The set of employed dynamic factors can be and should be signiﬁcantly
extended.
4. The models of the “rational” form – ratios of a mixture pair – should be
addressed in depth in order to cope with the dynamic case more rigorously.
5. The number of ad hoc solutions should be decreased.
6. Improvements of various aspects of the proposed solutions should be con-
sidered.
7. Experience with real applications should be accumulated further on and
reﬂected in the tool set we described here.
The above points can be summarized into the optimistic statement: there
are many interesting problems and an extensive unexploited application potential
on the deﬁnitely promising way described in this text.
On the margin of the proposed advisory system, it is worth stressing:
•
The advisory system is coming in a proper time as users are gradually
willing to work with sophisticated multivariate data processing.
•
The described concept of the advisory system has no viable competitor
that would be able to give optimized advices using dynamic, black-box,
high-dimensional models. Its generic nature makes the resulting product
adaptable to a surprisingly wide range of problems.
•
The advisory system is expected to serve as a “clever” node in a more com-
plex hierarchical support operator or their group. It cannot cover all tasks
taken traditionally as operator support. It has to rely on an information
system available as well as on the signals generated by other specialized
modules.
•
The advisory system has a speciﬁc niche on the “market” by providing
relatively quickly an advanced addition to existing information systems. It
will beneﬁt by the expected speed of its implementation and its adaptive
abilities.

15 Concluding remarks
509
•
Abilities of the advisory system to reduce information overﬂow and fo-
cus operator attention on signiﬁcant quantities are more important than
originally expected.
•
The theoretical and algorithmic outcomes of the research may well com-
plement tool set for building specialized modules like fault-detectors [188].

References
1. M. Krsti´c, I. Kannellakopoulos, and P. Kokotovi´c,
Nonlinear and Adaptive
Control Design, Wiley-Interscience, New York, 1995.
2. B.D.O. Anderson and J.B. Moore, Optimal Control : Linear Quadratic Meth-
ods, Prentice-Hall, Englewood Cliﬀs, New Jersey, 1989.
3. D.P. Bertsekas, Dynamic Programming and Optimal Control, Athena Scientiﬁc,
Nashua, US, 2001, 2nd edition.
4. B. Tamer (ed.), Control Theory, IEEE Press, New York, 2001.
5. T.H.Lee, C.C.Hang, and K.K.Tan,
“Special issue in intelligent control for
industrial application”,
Journal of Adaptive Control and Signal Processing,
vol. 15, no. 8, 2001.
6. J.O. Berger,
Statistical Decision Theory and Bayesian Analysis,
Springer-
Verlag, New York, 1985.
7. G.F. Luger and W.A. Stubbleﬁeld, Artiﬁcial Intelligence and the Design of
Expert Systems, chapter 8, pp. 296–297, Benjamin/Cummings, 1989.
8. B. S. Everitt and D. J. Hand, Applied Multivariate Data Analysis, Edward
Arnold, London, 1991.
9. J. Girst, “The practical application of rule and knowledge-based system tech-
niques to industrial process”, in Rule-Based Systems for Real-Time Planning
and Control, IEE Colloquium, October 1991.
10. S.R. Schmidt and R.G. Launsby, Understanding Industrial Designed Experi-
ments, Air Academy Press, Colorado, 1992.
11. J.T.Kim, K.C. Kwon, I.K. Hwang, D.Y. Lee, W.M. Park, J.S. Kim, and S. Lee,
“Development of advanced I & C in nuclear power plants: ADIOS and ASICS”,
Nuc. Eng. Des., vol. 207, no. 1, pp. 105–119, 2001.
12. M. Setnes and R. Babuˇska, “Fuzzy decision support for the control of detere-
gent production”, Int. J. of Adaptive Control and Signal Processing, vol. 15,
no. 8, pp. 769–785, 2001.
13. C. Lindheim and K.M. Lien,
“Operator support systems for new kinds of
process operation work”, Comput. Chem. Eng., vol. 21, pp. S113–S118, 1997.
14. I. Ivanov, “Multivariate techniques for process monitoring and optimization
at Tembec”, Pulp Pap. — Can., vol. 102, no. 7, pp. 23–25, 2001.
15. A. Mjaavatten and B.A. Foss, “A modular system for estimation and diagno-
sis”, Comput. Chem. Eng., vol. 21, no. 11, pp. 1203–1218, 1997.

512
References
16. Y.D. Pan, S.W. Sung, and J.H. Lee, “Data-based construction of feedback-
corrected nonlinear prediction model using feedback neural networks”, Control
Engineering Practice, vol. 9, no. 8, pp. 859–867, 2001.
17. I.T. Jolliﬀe, Principal Component Analysis, Springer-Verlag, New York, 1986.
18. A. Alessandri, T. Parisini, and R. Zoppoli, “Sliding-window neural state esti-
mation in a power plant heater line”, International Journal of Adaptive Control
and Signal Processing, vol. 15, no. 8, pp. 815–836, 2001.
19. M. Malek, M.P. Toitgans J.L. Wybo, and M. Vincent,
“An operator sup-
port system based on case-based reasoning for the plastic moulding injection
process”,
in Lecture Note in Artiﬁcial Intelligence, vol. 1488, pp. 402–413.
Springer-Verlag, New York, 2001.
20. A. Bonastre, R. Ors, and M. Peris, “Distributed expert systems as a new tool
in analytical chemistry”, Trac–Trends Anal. Chem., vol. 20, no. 5, pp. 263–271,
2001.
21. G.A. Sundstrom, “Designing support contexts: Helping operators to generate
and use knowledge”, Control Eng. Practice, vol. 5, no. 3, pp. 375–381, 1997.
22. M.B. Perry, J.K. Spoerre, and T. Velasco, “Control chart pattern recognition
using back propagation artiﬁcial neural networks”, Int. J. Prod. Res., vol. 39,
no. 15, pp. 3399–3418, 2001.
23. C.W. Lu and M.R. Reynolds, “Cusum charts for monitoring an autocorrelated
process”, J. Qual. Technol., vol. 33, no. 3, pp. 316–334, 2001.
24. F. Doymaz, J. Chen, J.A. Romagnoli, and A. Palazoglu, “A robust strategy for
real-time process monitoring”, J. Process Control, vol. 11, no. 4, pp. 343–359,
2001.
25. T. Bohlin, Interactive System Identiﬁcation: Prospects and Pitfalls, Springer-
Verlag, New York, 1991.
26. L. Ljung, System Identiﬁcation: Theory for the User, Prentice-Hall, London,
1987.
27. A. Fink, O. Nelles, M. Fisher, and R. Iserman, “Nonlinear adaptive control
of a heater exchanger”, International Journal of Adaptive Control and Signal
Processing, vol. 15, no. 8, pp. 883–906, 2001.
28. B. Kuijpers and K. Dockx, “An intelligent man-machine dialogue system based
on AI planning”, J. Appl. Intell., vol. 8, no. 3, pp. 235–245, 1998.
29. T.W. Anderson, An Introduction to Multivariate Statistical Analysis, John
Wiley, 1958.
30. K.A. Hoo, K.J. Tvarlapati, M.J. Piovoso, and R. Hajare, “A method of robust
multivariate outlier replacement”, Comput. Chem. Eng., vol. 26, no. 1, pp.
17–39, 2002.
31. J.H. Chen and J.L. Liu, “Derivation of function space analysis based PCA
control charts for batch process”, Chemical Engineering Science, vol. 56, no.
10, pp. 3289–3304, May 2001.
32. M. Kano, S. Hasebe, I Hashimoto, and H. Ohno, “A new multivariate pro-
cess monitoring method using principal component analysis”, Computers and
Chemical Engineering, vol. 25, no. 7-8, pp. 1103–1113, August 2001.
33. C. Rosen and J.A. Lennox, “Multivariate and multiscale monitoring of wastew-
ater treatment operation”, Water Res., vol. 35, no. 14, pp. 3402–3410, 2001.
34. J.H. Chen and K.C. Liu, “Online batch process monitoring using dynamic
PCA and dynamic PLS models”, Chem. Eng. Sci., vol. 57, no. 1, pp. 63–75,
2002.

References
513
35. S.J. Qin, S. Valle, and M.J. Piovoso, “On unifying multiblock analysis with
application to decentralized process monitoring”, J. Cheometrics, vol. 15, no.
9, pp. 715–742, 2001.
36. M.E. Tipping and C.M. Bishop, “Probabilistic principal component analysis”,
Journal of the Royal Society Series B — Statistical Methodology, vol. 61, pp.
611–622, 1999.
37. S. Kullback and R. Leibler,
“On information and suﬃciency”,
Annals of
Mathematical Statistics, vol. 22, pp. 79–87, 1951.
38. M.E. Tipping and C.M. Bishop, “Mixtures of probabilistic principal component
analyzers”, Neural Computation, vol. 11, no. 2, pp. 443–482, 1999.
39. S. Haykin, ”Neural Networks: A Comprehensive Foundation, Macmillan, New
York, 1994.
40. B. Lennox, G.A. Montague, A.M. Frith, C. Gent, and V. Bevan, “Industrial
application of neural networks – an investigation”, J. of Process Control, vol.
11, no. 5, pp. 497–507, 2001.
41. P.V. Varde, S. Sankar, and A.K. Verma,
“An operator support system for
research reactor operations and fault diagnosis through a framework of PSA
knowledge based systems”, Reliabl. Eng. Syst. Safety, vol. 60, no. 1, pp. 53–69,
1998.
42. J. Stutz and P. Cheeseman, “AutoClass - a Bayesian approach to classiﬁca-
tion”, in Maximum Entropy and Bayesian Methods, J. Skilling and S. Sibisi,
Eds. Kluwer, Dordrecht, 1995.
43. P. Pacl´ık, J. Novoviˇcov´a, P. Pudil, and P. Somol, “Road sign classiﬁcation using
Laplace kernel classiﬁer”, Pattern Recognition Letters, vol. 21, no. 13/14, pp.
1165–1174, 2000.
44. M. K´arn´y, P. Nedoma, I. Nagy, and M. Valeˇckov´a, “Initial description of multi-
modal dynamic models”, in Artiﬁcial Neural Nets and Genetic Algorithms.
Proceedings, V. K˚urkov´a, R. Neruda, M. K´arn´y, and N. C. Steele, Eds., Vienna,
April 2001, pp. 398–401, Springer-Verlag.
45. S. Gourvenec, D.L. Massart, and D.N. Rutledge, “Determination of the number
of components during mixture analysis using the Durbin-Watson criterion in
the orthogonal projection approach and in the simple-to-use interactive self-
modelling mixture analysis approach”, Chemometr Intell. Lab. Syst., vol. 61,
no. 1–2, pp. 51–61, 2002.
46. A.M. Jazwinski, Stochastic Processes and Filtering Theory, Academic Press,
New York, 1970.
47. R.H. Elliot, L. Assoun, and J.B. Moore, Hidden Markov Models, Springer-
Verlag, New York, 1995.
48. B.S. Everitt and D.J. Hand, Finite Mixture Distributions, Chapman and Hall,
1981.
49. D.M. Titterington, A.F.M. Smith, and U.E. Makov,
Statistical Analysis of
Finite Mixtures, John Wiley, New York, 1985.
50. S. Richardson and P.J. Green,
“On Bayesian analysis of mixtures with an
unknown number of components, with discussion”, Journal of the Royal Sta-
tistical Society, Series B, vol. 59, no. 4, pp. 731–792, 1997.
51. D.W. Scott, Multivariate Density Estimation, John Wiley, New York, 1992.
52. B.W. Silverman, Density Estimation, Chapman and Hall, 1991.
53. J. Coste, A. Spira, P. Ducimetiere, and J.B. Paolaggi, “Clinical and psycho-
logical diversity of non speciﬁc low-back pain. a new approach towards the

514
References
classiﬁcation of clinical subgroups”, Journal of Clinical Epidemiol, vol. 44, pp.
1233–1245, 1991.
54. R. Huth, I. Nemesova, and N. Klimperova, “Weather categorization based on
the average linkage clustering technique: An application to European midlati-
tudes”, International Journal of Climatology, vol. 13, 1993.
55. N. Jardine and R. Sibson, “The construction of hierarchic and nonhierarchic
classiﬁcation”, Computer Journal, vol. 11, pp. 177–184, 1968.
56. D.W. Ginsberg and W.J. White,
“Expert system developement using
ellipsoidal-based clustering”, Minerals Engineering, vol. 6, no. 1, pp. 31–40,
1993.
57. E.L. Sutanto, “Use of cluster analysis for the study of machine processes”,
in Colloquium on Intelligent Manufacturing Systems, London, December 1995,
pp. 9/1–9/5.
58. E.L. Sutanto, “Intelligent reasoning for complex processes using multivariate
cluster analysis”, in Proceedings of Computer Intensive Methods in Control
and Data Processing CMP98, Prague, September 1998, pp. 69–76.
59. R. Kulhav´y and P.I. Ivanova, “Memory-based prediction in control and opti-
mization”, in Proceedings of IFAC World Congress, pp. 469–485. Pergamon,
Oxford, 1999.
60. G. Bontempi, M. Birattari, and H. Bersini, “Lazy learning for local modelling
and control design”,
International Journal of Control, vol. 72, no. 7-8, pp.
643–658, 1999.
61. M.H. DeGroot, Optimal Statistical Decisions, McGraw-Hill, New York, 1970.
62. J.M. Bernardo and A.F.M. Smith, Bayesian Theory, John Wiley, Chichester,
1997, 2nd ed.
63. M. K´arn´y, “Towards fully probabilistic control design”, Automatica, vol. 32,
no. 12, pp. 1719–1722, 1996.
64. M. K´arn´y, J. B¨ohm, T.V. Guy, and P. Nedoma,
“Mixture-based adaptive
probabilistic control”, International Journal of Adaptive Control and Signal
Processing, vol. 17, no. 2, pp. 119–132, 2003.
65. M. K´arn´y, P. Nedoma, N. Khailova, and L. Pavelkov´a, “Prior information in
structure estimation”, IEE Proceedings — Control Theory and Applications,
vol. 150, no. 6, pp. 643–653, 2003.
66. P. Nedoma, M. K´arn´y, T.V. Guy, I. Nagy, and J. B¨ohm, Mixtools (Program),
´UTIA AV ˇCR, Prague, 2003.
67. E.L. Sutanto,
Mean-tracking algorithm for multivariable cluster analysis in
manufacturing processes,
PhD thesis, University of Reading, Reading, UK,
1996.
68. M. K´arn´y, A. Halouskov´a, J. B¨ohm, R. Kulhav´y, and P. Nedoma, “Design of
linear quadratic adaptive control: Theory and algorithms for practice”, Kyber-
netika, vol. 21, 1985, Supplement to Nos. 3, 4 ,5, 6.
69. V. Peterka, “Bayesian system identiﬁcation”, in Trends and Progress in System
Identiﬁcation, P. Eykhoﬀ, Ed., pp. 239–304. Pergamon Press, Oxford, 1981.
70. M. K´arn´y, I. Nagy, and J. Novoviˇcov´a, “Mixed-data multimodelling for fault
detection and isolation”, Adaptive control and signal processing, , no. 1, pp.
61–83, 2002.
71. R.L. Keeny and H. Raiﬀa, Decisions with Multiple Objectives: Preferences and
Value Tradeoﬀs, J. Wiley, New York, 1978.
72. M.M. Rao, Measure Theory and Integration, John Wiley, New York, 1987.

References
515
73. V. Jarn´ık, Integral Calculus II, Academia, Prague, 1984, (in Czech).
74. I. Vajda, Information Theory and Statistical Decision Making, Alfa, Bratislava,
1982, (in Slovak).
75. A.A. Feldbaum, “Theory of dual control”, Autom. Remote Control, vol. 21,
no. 9, 1960.
76. A.A. Feldbaum, “Theory of dual control”, Autom. Remote Control, vol. 22,
no. 2, 1961.
77. R. Bellman, Introduction to the Mathematical Theory of Control Processes,
Academic Press, New York, 1967.
78. J. ˇSindel´aˇr and M. K´arn´y, “Dynamic decision making under uncertainty allows
explicit solution”, Tech. Rep. 1916, ´UTIA AVˇCR, POB 18, 18208 Prague 8,
CR, 1997.
79. H. Kushner, Introduction to Stochastic Control, Holt, Rinehart and Winston,
New York, 1971.
80. I. Csisz´ar and J. K¨orner, Information Theory: Coding Theorems for Discrete
Memoryless Systems, Akad´emiai Kiad´o, Budapest, 1986.
81. M. Loeve, Probability Theory, van Nostrand, Princeton, New Jersey, 1962,
Russian translation, Moscow 1962.
82. L. Berec and M. K´arn´y,
“Identiﬁcation of reality in Bayesian context”,
in Computer-Intensive Methods in Control and Signal Processing: Curse of
Dimensionality, K. Warwick and M. K´arn´y, Eds., pp. 181–193. Birkh¨auser,
Boston, 1997.
83. I.N. Sanov,
“On probability of large deviations of random variables”,
Matematiˇceskij Sbornik, vol. 42, pp. 11–44, 1957,
(in Russian), translation
in Selected Translations Mathematical Statistics and Probability, I, 1961, 213–
244.
84. R. Kulhav´y,
Recursive Nonlinear Estimation: A Geometric Approach, vol.
216 of Lecture Notes in Control and Information Sciences, Springer-Verlag,
London, 1996.
85. R. Kulhav´y and M. K´arn´y, “Tracking of slowly varying parameters by direc-
tional forgetting”, in Preprints of the 9th IFAC World Congress, vol. X, pp.
178–183. IFAC, Budapest, 1984.
86. J.J. Milek and F.J. Kraus, “Time-varying stabilized forgetting for recursive
least squares identiﬁcation”, in IFAC Symposium ACASP’95, Cs. B´any´asz,
Ed., pp. 539–544. IFAC, Budapest, 1995.
87. L.Y. Cao and H. Schwartz, “A directional forgetting algorithm based on the
decomposition of the information matrix”, Automatica, vol. 36, no. 11, pp.
1725–1731, November 2000.
88. R. Kulhav´y and M.B. Zarrop, “On the general concept of forgetting”, Inter-
national Journal of Control, vol. 58, no. 4, pp. 905–924, 1993.
89. E. Mosca, Optimal, Predictive, and Adaptive Control, Prentice Hall, 1994.
90. R.K. Mehra and D.G. Lainiotis (Eds.), System Identiﬁcation – Advances and
Case Studies, Pergamon Press, New York, 1976.
91. R. Koopman, “On distributions admitting a suﬃcient statistic”, Transactions
of American Mathematical Society, vol. 39, pp. 399, 1936.
92. E.F. Daum, “New exact nonlinear ﬁlters”, in Bayesian Analysis of Time Series
and Dynamic Models, J.C. Spall, Ed. Marcel Dekker, New York, 1988.
93. L. Berec, Model Structure Identiﬁcation: Global and Local Views. Bayesian
Solution, Ph.D. Thesis, Czech Technical University, Faculty of Nuclear Sciences
and Physical Engineering, Prague, 1998.

516
References
94. J. Roj´ıˇcek and M. K´arn´y,
“A sequential stopping rule for extensive simu-
lations”,
in Preprints of the 3rd European IEEE Workshop on Computer-
Intensive Methods in Control and Data Processing, J. Roj´ıˇcek, M. Valeˇckov´a,
M. K´arn´y, and K. Warwick, Eds., Praha, September 1998, pp. 145–150, ´UTIA
AV ˇCR.
95. M. K´arn´y and R. Kulhav´y, “Structure determination of regression-type models
for adaptive prediction and control”, in Bayesian Analysis of Time Series and
Dynamic Models, J.C. Spall, Ed. Marcel Dekker, New York, 1988, Chapter 12.
96. R. Kulhav´y, “A Bayes-closed approximation of recursive nonlinear estimation”,
International Journal Adaptive Control and Signal Processing, vol. 4, pp. 271–
285, 1990.
97. R. Kulhav´y, “Recursive Bayesian estimation under memory limitations”, Ky-
bernetika, vol. 26, pp. 1–20, 1990.
98. R. Taylor,
Introduction to Functional Analysis,
Academia, Prague, 1973,
(Czech translation).
99. V.S. Vladimirov, Generalized Functions in Mathematical Physics, Mir Pub-
lishers, Moscow, 1979.
100. K.J. Astrom and B. Wittenmark, Adaptive Control, Addison-Wesley, Reading,
Massachusetts, 1989.
101. M. K´arn´y,
“Adaptive systems: Local approximators?”,
in Preprints of the
IFAC Workshop on Adaptive Systems in Control and Signal Processing, Glas-
gow, August 1998, pp. 129–134, IFAC.
102. V. Peterka, “Adaptive digital regulation of noisy systems”, in Preprints of the
2nd IFAC Symposium on Identiﬁcation and Process Parameter Estimation.
´UTIA ˇCSAV, Prague, 1970, paper 6.2.
103. K.J Astrom, Introduction to Stochastic Control, Academic Press, New York,
1970.
104. O.L.R. Jacobs and J.W. Patchell, “Caution and probing in stochastic control”,
International Journal of Control, vol. 16, pp. 189–199, 1972.
105. V. Peterka, “Predictor-based self-tuning control”, Automatica, vol. 20, no. 1,
pp. 39–50, 1984, reprinted in: Adaptive Methods for Control System Design,
M.M. Gupta, Ed., IEEE Press, New York, 1986.
106. D.W. Clarke, C. Mohtadi, and P.S. Tuﬀs, “Generalized predictive control”,
Automatica, vol. 23, no. 2, pp. 137–160, 1987.
107. D.W. Clarke, Advances in Model-Based Predictive Control, Oxford University
Press, Oxford, 1994.
108. M. Cannon, B. Kouvaritakis, A. Brooms, and Y. Lee,
“Eﬃcient nonlinear
model predictive control”,
in Proceedings of American Control Conference,
June 28-30, Chicago, 2000.
109. Y. Sheng, M. Tomizuka, and M. Ozaki, “Dynamic modelling and adaptive pre-
dictive control of drilling of composite materials”, in Proceedings of American
Control Conference, June 28-30, Chicago, 2000.
110. P.R. Kumar, “A survey on some results in stochastic adaptive control”, SIAM
J. Control and Applications, vol. 23, pp. 399–409, 1985.
111. N.M. Filatov and H.B. Unbehauen (Ed.), Adaptive Dual Control - Theory and
Applications, Springer, Berlin, 2004.
112. R. Murray-Smith and T.A. Johansen, Multiple Model Approaches to Modelling
and Control, Taylor & Francis, London, 1997.

References
517
113. M. K´arn´y and A. Halouskov´a, “Preliminary tuning of self-tuners”, in Lecture
Notes: Advanced Methods in Adaptive Control for Industrial Application (Joint
UK-CS seminar), K. Warwick, M. K´arn´y, and A. Halouskov´a, Eds., vol. 158.
Springer-Verlag, 1991, held in May 1990, Prague.
114. M. K´arn´y and A. Halouskov´a, “Pretuning of self-tuners”, in Advances in Model-
Based Predictive Control, D. Clarke, Ed., pp. 333–343. Oxford University Press,
Oxford, 1994.
115. J. B˚ucha, M. K´arn´y, P. Nedoma, J. B¨ohm, and J. Roj´ıˇcek, “Designer 2000
project”, in International Conference on Control ’98, London, September 1998,
pp. 1450–1455, IEE.
116. G. Belforte and P. Gay, “Optimal experiment design for regression polynomial
models identiﬁcation”, International Journal of Control, vol. 75, no. 15, pp.
1178–1189, 2002.
117. M. Zarrop,
Experiment Design for Dynamic System Identiﬁcation. Lecture
Notes in Control and Information Sciences 21, Springer, New York, 1979.
118. A.V. Oppenheim and A.S. Wilsky, Signals and systems, Englewood Clifts,
Jersye, 1983.
119. R. Kruse and C. Borgelt, “Data mining with graphical models”, Lecture Notes
In Computer Science, vol. 2534, pp. 2–11, 2002.
120. M. K´arn´y, N. Khailova, P. Nedoma, and J. B¨ohm, “Quantiﬁcation of prior
information revised”,
International Journal of Adaptive Control and Signal
Processing, vol. 15, no. 1, pp. 65–84, 2001.
121. M. Ishikawa and T. Moriyama,
“Prediction of time series by a structural
learning of neural networks”, Fuzzy Sets and Systems, vol. 82, no. 2, pp. 167–
176, September 1996.
122. M. K´arn´y, “Estimation of control period for selftuners”, Automatica, vol. 27,
no. 2, pp. 339–348, 1991, extended version of the paper presented at 11th IFAC
World Congress, Tallinn.
123. L. Berec and J. Roj´ıˇcek, “Control Period Selection: Veriﬁcation on Coupled
Tanks”, in Preprints of European Control Conference ECC’97 (on CD-ROM),
G. Bastin and M. Gevers, Eds. ECC, Brussels, 1997.
124. M.E.P. Plutowski,
“Survey: Cross-validation in theory and practice”,
Re-
search report, Department of Computational Science Research, David Sarnoﬀ
Research Center, Princeton, New Jersey, 1996.
125. M. Nov´ak and J. B¨ohm, “Adaptive LQG controller tuning”, in Proceedings of
the 22nd IASTED International Conference on Modelling, Identiﬁcation and
Control, M. H. Hamza, Ed., Calgary, February 2003, Acta Press.
126. M. Nov´ak, J. B¨ohm, P. Nedoma, and L. Tesaˇr,
“Adaptive LQG controller
tuning”, IEE Proceedings — Control Theory and Applications, vol. 150, no. 6,
pp. 655–665, 2003.
127. A. Wald, Statistical Decision Functions, John Wiley, New York, London, 1950.
128. M. K´arn´y, J. Krac´ık, I. Nagy, and P. Nedoma, “When has estimation reached a
steady state? The Bayesian sequential test”, International Journal of Adaptive
Control and Signal Processing, vol. 19, no. 1, pp. 41–60, 2005.
129. M. K´arn´y and J. Krac´ık, “A normative probabilistic design of a fair govern-
mental decision strategy”, Journal of Multi-Criteria Decision Analysis, vol.
12, no. 2-3, pp. 1–15, 2004.
130. T.V. Guy, J. B¨ohm, and M. K´arn´y,
“Probabilistic mixture control with
multimodal target”,
in Multiple Participant Decision Making, J. Andr´ysek,

518
References
M. K´arn´y, and J. Krac´ık, Eds., Adelaide, May 2004, pp. 89–98, Advanced
Knowledge International.
131. J. Andr´ysek, “Approximate recursive Bayesian estimation of dynamic prob-
abilistic mixtures”,
in Multiple Participant Decision Making, J. Andr´ysek,
M. K´arn´y, and J. Krac´ık, Eds., pp. 39–54. Advanced Knowledge International,
Adelaide, 2004.
132. R. Horst and H. Tuy, Global Optimization, Springer, 1996, 727 pp.
133. Z. Michalewicz, Genetic Algorithms + Data Structures = Evolution Programs,
Springer, 1996.
134. Tao Chen, Kai-Kuang Ma, and Li-Hui Chen, “Tristate median ﬁlter for image
denoising”, IEEE Transactions on Image Processing, vol. 8, no. 12, pp. 1834–
1838, December 1999.
135. T. Cipra, “Dynamic credibility with outliers”, Applications of Mathematics,
vol. 41, no. 2, pp. 149–159, 1996.
136. M. Tanaka and T. Katayama, “A robust identiﬁcation of a linear system with
missing observations and outliers by the EM algorithm”, Transactions of the
Institute of Systems, Control and Information Engineering, vol. 1, no. 4, pp.
117–129, September 1988.
137. L. Tesaˇr and A. Quinn, “Detection and removal of outliers from multidimen-
sional ar processes”, in Proceedings of The Irish Signal and Systems Confer-
ence, Maynooth, Ireland, August 2001, pp. 117–122, National University of
Ireland, Maynooth College.
138. I. Nagy and M. K´arn´y, “A view on ﬁltering of continuous data signals”, Ky-
bernetika, vol. 28, no. 6, pp. 494–505, 1992.
139. T.V. Guy and M. K´arn´y, “On structure of local models for hybrid controllers”,
in Artiﬁcial Neural Nets and Genetic Algorithms. Proceedings, V. K˚urkov´a,
R. Neruda, M. K´arn´y, and N. C. Steele, Eds., Vienna, April 2001, pp. 340–
344, Springer-Verlag.
140. S.J. Godsill, The Restoration of Degraded Audio Signals, PhD thesis, Univer-
sity of Cambridge, Department of Engineering, December 1993.
141. L. Tesaˇr and A. Quinn, “Method for artefact detection and supression using
alpha-stable distributions”, in Proceedings of ICANNGA Conference, Prague,
March 2001.
142. K´arn´y M., “Local ﬁlter robust with respect to outlying data”, Tech. Rep.
1644, ´UTIA ˇCSAV, Prague, 1990.
143. R.M. Rao and A.S. Bopardikar, Wavelet Transforms: Introduction to Theory
and Applications, Addison,Wesley,Longman, July 1998.
144. L. He and M. K´arn´y, “Estimation and prediction with ARMMAX model: a
mixture of ARMAX models with common ARX part”, International Journal
of Adaptive Control and Signal Processing, vol. 17, no. 4, pp. 265–283, 2003.
145. V. Peterka,
“Real-time parameter estimation and output prediction for
ARMA-type system models”, Kybernetika, vol. 17, pp. 526–533, 1981.
146. V. Peterka, “Control of uncertain processes: applied theory and algorithms”,
Kybernetika, vol. 22, 1986, Supplement to No. 3, 4 ,5, 6.
147. M. K´arn´y, “Quantiﬁcation of prior knowledge about global characteristics of
linear normal model”, Kybernetika, vol. 20, no. 5, pp. 376–385, 1984.
148. N. Khaylova,
Exploitation of Prior Knowledge in Adaptive Control Design,
PhD thesis, University of West Bohemia, Pilsen, Czech Republic, 2001.
149. B.D. Ripley, Pattern Recognition and Neural Networks, Cambridge University
Press, London, 1997.

References
519
150. B. Harris and G. Heinel, “The relation between statistical decision theory and
approximation theory”, in Optimizing Methods in Statistics, J.G. Rustagi, Ed.,
pp. 263–272. Academic Press, New York, 1979.
151. J. ˇSindel´aˇr, P. Nedoma, and M. K´arn´y,
“Algorithm for selecting the best
variants in the shadow cancelling problem”, Kybernetika, 2004, submitted.
152. E.L. Sutanto and K. Warwick,
“Cluster analysis: An intelligent system for
the process industries”, in Cybernetics and Systems ’94, Robert Trappl, Ed.,
Vienna, 1994, vol. 1, pp. 327–344, World Scientiﬁc.
153. E.L. Sutanto and K. Warwick,
“Cluster analysis for multivariable process
control”, in Proceedings of the American Control Conference 1995, Seattle,
June 1995, vol. 1, pp. 749–750.
154. E.L. Sutanto, J.D. Mason, and K. Warwick,
“Mean-tracking clustering al-
gorithm for radial basis function centre selection”,
International journal of
Control, vol. 67, no. 6, pp. 961–977, August 1997.
155. M. K´arn´y, J. Kadlec, and E. L. Sutanto,
“Quasi-Bayes estimation applied
to normal mixture”,
in Preprints of the 3rd European IEEE Workshop
on Computer-Intensive Methods in Control and Data Processing, J. Roj´ıˇcek,
M. Valeˇckov´a, M. K´arn´y, and K. Warwick, Eds., Prague, September 1998, pp.
77–82, ´UTIA AV ˇCR.
156. M. Abramowitz and I.A. Stegun, Handbook of Mathematical Functions, Dover
Publications, New York, 1972.
157. M. Valeˇckov´a, M. K´arn´y, and E. L. Sutanto, “Bayesian M-T clustering for re-
duced parametrisation of Markov chains used for nonlinear adaptive elements”,
in Preprints of the IFAC Workshop on Adaptive Systems in Control and Signal
Processing, Glasgow, August 1998, pp. 381–386, IFAC.
158. V. Peterka, “Adaptation for LQG control design to engineering needs”, in Lec-
ture Notes: Advanced Methods in Adaptive Control for Industrial Application;
Joint UK-CS seminar, K. Warwick, M. K´arn´y, and A. Halouskov´a, Eds., vol.
158. Springer-Verlag, New York, 1991, held in May 1990, Prague.
159. G.J. Bierman, Factorization Methods for Discrete Sequential Estimation, Aca-
demic Press, New York, 1977.
160. M. K´arn´y,
“Parametrization of multi-output multi-input autoregressive-
regressive models for self-tuning control”,
Kybernetika, vol. 28, no. 5, pp.
402–412, 1992.
161. V. ˇSm´ıdl, A. Quinn, M. K´arn´y, and T.V. Guy,
“Robust estimation of au-
toregressive processes using a mixture based ﬁlter bank”, System & Control
Letters, , no. 4, pp. 315–324, 2005.
162. M. K´arn´y, “Algorithms for determining the model structure of a controlled
system”, Kybernetika, vol. 19, no. 2, pp. 164–178, 1983.
163. T.V. Guy, M. K´arn´y, and J. B¨ohm,
“Linear adaptive controller based on
smoothing noisy data algorithm”, in European Control Conference. ECC ’99.
(CD-ROM), Karlsruhe, August 1999, VDI/VDE GMA.
164. A. Renyi, Probability theory, Academia, Prague, 1972, in Czech.
165. M. Valeˇckov´a and M. K´arn´y,
“Estimation of Markov chains with re-
duced parametrisation”, in Preprints of the 2nd European IEEE Workshop
on Computer-Intensive Methods in Control and Signal Processing, CMP’96,
L. Berec, J. Roj´ıˇcek, M. K´arn´y, and K. Warwick, Eds., pp. 135–140. ´UTIA AV
ˇCR, Prague, 1996.
166. T.S. Fergusson, “A Bayesian analysis of some nonparametric problems”, The
Annals of Statistics, vol. 1, pp. 209–230, 1973.

520
References
167. R.M. Gray and D.I. Neuhoﬀ, “Quantization”, IEEE Transaction On Informa-
tion Theory, vol. 44, no. 6, pp. 2325–2383, 1998.
168. R. Jirouˇsek, “Introduction into Bayesian network theory”, Tech. Rep. LISp-
94-04, LISp, Department of Information and Knowledge Engineering, Prague
University of Economics, 1994, in Czech.
169. F.V. Jensen, Bayesian Networks and Decision Graphs, Springer-Verlag, New
York, 2001.
170. M. Valeˇckov´a, M. K´arn´y, and E.L. Sutanto,
“Bayesian M-T clustering for
reduced parameterisation of Markov chains used for nonlinear adaptive ele-
ments”, Automatica, vol. 37, no. 6, pp. 1071–1078, 2001.
171. H. Mine and S. Osaki, Markovian Decision Processes, Elsevier, New York,
1970.
172. M. Hendrikx, J. van Nunen, and J. Wessels,
“On iterative optimization of
structured Markov decision processes with discounted rewards”, Math. Op-
erationsforsch. und Statistics, ser. Optimization, vol. 15, no. 3, pp. 439–459,
1984.
173. J. ˇSindel´aˇr, M. K´arn´y, and P. Nedoma,
“Algorithms selecting several best
“diagonal” variants”, Tech. Rep., ´UTIA AV ˇCR, 1998.
174. L. Tesaˇr, M. K´arn´y, and J. ˇSindel´aˇr,
“Bayesian stopping rule for a global
maxima search in discrete parameter space”, Kybernetika, 2004, submitted.
175. S. Rabe-Hesketh and A. Skrondal, “Parameterization of multivariate eﬀects
models for categorical data”, Biometrics, vol. 57, no. 4, pp. 1256–1263, 2001.
176. T. Hastie, R. Tibshirani, and J. Friedman, The Elements of Statistical Learn-
ing: Data Mining, Inference and Prediction,
Springer Series in Statistics.
Springer, New York, 2001.
177. A. Quinn, P. Ettler, L. Jirsa, I. Nagy, and P. Nedoma, “Probabilistic advisory
systems for data-intensive applications”,
International Journal of Adaptive
Control and Signal Processing, vol. 17, no. 2, pp. 133–148, 2003.
178. P. Ettler and F. Jirkovsk´y, “Digital controllers for ˇskoda rolling mills”, in Lec-
ture Notes: Advanced Methods in Adaptive Control for Industrial Application
(Joint UK-CS seminar), K. Warwick, M. K´arn´y, and A. Halouskov´a, Eds., vol.
158, pp. 31–35. Springer Verlag, 1991.
179. Samuel Kotz and Norman L. Johnson, Process Capability Indices, Chapman
& Hall, London, 1993.
180. P. Nedoma, M. K´arn´y, I. Nagy, and M. Valeˇckov´a, “Mixtools. MATLAB Tool-
box for Mixtures”, Tech. Rep. 1995, ´UTIA AV ˇCR, Prague, 2000.
181. J. Harbert, W. Eckelman, and R. Neumann, Nuclear Medicine. Diagnosis and
Therapy, Thieme, New York, 1996.
182. L. Jirsa, Advanced Bayesian Processing of Clinical Data in Nuclear Medicine,
FJFI ˇCVUT, Prague, 1999, 95 pages, Ph.D. Thesis.
183. J. Heˇrmansk´a, K. Voˇsmikov´a, L. Jirsa, M. K´arn´y, and M. ˇS´amal, “Biophysical
inputs into the software MIRDose”, Sborn´ık l´ekaˇrsk´y, vol. 99, no. 4, pp. 521–
527, 1998.
184. J. Heˇrmansk´a, M. K´arn´y, J. Zim´ak, L. Jirsa, and M. ˇS´amal, “Improved predic-
tion of therapeutic absorbed doses of radioiodine in the treatment of thyroid
carcinoma”, The Journal of Nuclear Medicine, vol. 42, no. 7, pp. 1084–1090,
2001.
185. J. Zim´ak, J. Heˇrmansk´a, N. Medi´c, L. Jirsa, M. K´arn´y, M. ˇS´amal, and L. K´arn´a,
“Guide to Iodine III ”, Tech. Rep., Clinic of Nuclear Medicine, Motol Hospital,
Prague, 2001, 28 pp.

References
521
186. D. Helbing,
“Traﬃc data and their implications for consistent traﬃc ﬂow
modelling”, in Transportation Systems. 1997, pp. 809–814, Chania.
187. F. McLeod, N. Hounsell, and Saeed Ishtia, “Traﬃc data and their implications
for consistent traﬃc ﬂow modelling”,
in Transportation Systems. 1997, pp.
911–916, Chania.
188. A. Rakar, T.V. Guy, P. Nedoma, M K´arn´y, and D. Juriˇci´c, “Advisory system
prodactool: Case study on gas conditioning unit”, Journal of Adaptive Control
and Signal Processing, 2004, submitted.
189. M. K´arn´y, “Tools for computer-aided design of adaptive controllers”, IEE
Proceedings — Control Theory and Applications, vol. 150, no. 6, pp. 642, 2003.

Index
γ-bound, 208, 215, 221, 229, 235, 368
ω-bound, 209, 210
\ is the set subtraction, 12
a.e., 20
academic advices, 84, 93
academic advisory system, 83
academic design, 83
action space of the advisory system, 68
action space of the operator, 68
actions ≡decisions, 11
active strategies, 62
adaptive advisory system, 82, 97, 264,
382
adaptive predictor, 98
adaptive system, 47, 58
additive loss function, 28, 31
adjacent factors, 77
adjacent normal factors, 314
adjectives guided and unguided, 70
administered activity, 493
admissible decision rule, 24
admissible strategy, 15
advices, 69, 70
advices and their inﬂuence, 199
advisory mixture, 86, 212, 225, 227,
488, 489
advisory system, 68
algebraic recursive updating, 49
algorithm dydr, 246
almost everywhere, 20, 22
alternative pdf, 44, 46
applications, 481
AR, 318
ARMAX factors, 111, 266, 318
Arg min, 33
array of expectations, 24
assigning priorities, 84
auto-regression, 318
average kernel, 340, 341, 345
average lift, 340, 345
average marker, 87
average quadratic form, 358
-B step, 442
B-step, 441
basic decision-making lemma, 24
batch quasi-Bayes estimation, 155, 162,
293, 403
batch variant, 37
Bayes rule, 22, 51
Bayesian decision making, 11
Bayesian learning, 11
Bayesian networks, 386, 468
Bayesian parameter estimate, 48
behavior, 14
Bellman function, 28, 32
best projection, 40
black-box modelling, 7
BMT part, 442
bounding mapping, 101
box width, 437
BQB, 155, 164, 293, 403
branch-and-bound techniques, 96, 100
branching mapping, 100, 136
bridge to reality, 36
cancelling of components, 167, 406

524
Index
censored data, 104
certainty-equivalence strategy, 193
chain rule, 22
channel, 77, 108, 455, 483, 485, 502, 503
choice of the prior pdf, 120
Choleski square root, 299
closed loop, 3
cluster analysis, 149
clusters, 3
coding, 385
combination of information sources, 36
common factor, 177
common parameterized factor, 77
commutative updating and projecting,
56
comparing quality, 154
completion of squares, 251
complexity of the decision-making, 16
component, 43, 76, 77
component estimate, 77
component weight, 76
component-weight estimate, 77
conditional covariance, 23
conditional expectation, 21
conditional KL divergence, 202, 332,
416
conditional pdf, 21
conditionally independent, 22
conditioned on, 21
conditioning symbol, 21
conjugate prior, 48, 114, 251, 261, 378
consistent estimator, 40
consistent ﬁctitious data blocks, 114
control hierarchy, 75
controller, 15
cooperating operator, 202
covariance of LS estimate, 252
cutting moment, 188, 305, 410
dangerous component, 211, 220, 338,
418, 420
data channel, 77, 483, 489
data driven, 27
data interpolation, 102
data mining, 3
data record, 77
data scaling, 102
data space of the advisory system, 68,
72, 85
data space of the operator, 68
data updating, 35
data vector, 47, 52, 77, 385, 469
data vector type ≡†Ψ, 111
decision ≡Action, 14
decision maker, 13
deductive calculus, 36
density, 500
design, 15
design horizon, 58
design of optimal strategies, 7
design principle, 11, 70
DESIGNER, 63, 73
designer, 15
determinant, 23
diag[·], 249
diagonal matrix, 245
dimensionality reduction, 103
Dirac delta function, 37, 62
Dirichlet pdf, 155, 272, 378, 381, 471
discrete time, 12
discrete wavelet transformation, 109
discrete-valued factor output, 465
dominated rules, 18
dosimetric data, 493
down sampling, 109
dual strategy, 62
dyadic reduction, 246
dynamic clustering, 437
dynamic components, 120
dynamic design, 15, 17, 25
dynamic exponential family, 110
dynamic mixture, 148, 469
dynamic programming, 25
dynamic properties, 7
EF, 43
eﬀective half-life, 493
emphasized, 11
empirical pdf, 40, 52, 53
entropy rate, 38, 40, 147, 149, 150, 285
equivalence approach, 44, 51
equivalence-preserving mapping, 51
estimation, 36
estimator, 15
exactly recursively updated, 51
excretion, 494
exhibits multimodal behavior, 3
expectation, 17

Index
525
expectation-maximization algorithm
(EM), 154
expected KL divergence, 44
expected loss, 17
experience, 14
expert knowledge, 36
exponential family, 43, 47, 126, 157,
162, 183, 251, 261, 378
exponential forgetting, 46
extended information matrix, 243, 245,
248, 251
extended quasi-Bayes estimation, 474,
475
extending experience, 25, 26, 28, 353
extension of the mixture model, 151
factor, 43, 77
factor estimate, 77
factor output, 110, 111, 470
factor splitting, 140
ﬁctitious data, 114
ﬁlter state, 110
ﬁltered factor output, 110
ﬁltering, 35
ﬁltering error, 286
ﬁltration of unknown quantities, 34
ﬁnite memory, 52
ﬁnite mixture, 75, 76
ﬁxed advisory system, 82, 98, 99, 265,
481
ﬁxed predictor, 98
ﬁxed variance, 463
ﬂattened version, 46
ﬂattening mapping, 123
ﬂattening rate, 124, 127, 272, 391, 394
forget, 45
forgetting, 114
forgetting factor, 46, 115
formal model of learning, 33
fully cooperating operator, 70, 194
fully probabilistic design, 29, 64, 419
functional form type ≡†F, 111
Gauss-inverse-Wishart pdf (GiW), 251,
261
generalized Bayesian estimation, 51
geometric branching mapping, 134
GIGO principle, 499, 505
golden decision-making rule, 63
grouped variant of advising, 344
grouping rate, 217
GUI, 489, 497
guided model, 70, 83
guided o-system, 70, 84, 93, 202
Haar wavelet, 108
hard bounds, 38
hierarchical splitting, 142, 398
high-pass ﬁlter, 109
highly probable structures, 50
horizon, 12, 31, 69, 341, 359
ideal pdf, 29, 64, 70, 82, 85
ideal pdf for the interconnection of the
o- and p-systems, 86
identiﬁable, 40
ignorance, 14
incomplete knowledge and randomness,
15
incomplete ordering of strategies, 16
independent data records, 151
index vector, 446, 447, 449
index-based maximization, 449, 450
indicator of a set, 20
industrial advisory system, 83
industrial design, 83, 87
inﬁnite-dimensional unknown (hy-
per)parameter, 121
information state, 31, 34, 59
initialization problem, 120, 134
innovation, 27, 68
input, 14
intensity, 500
internal quantities, 27, 33
internally consistent data blocks, 114,
115
inverse Wishart pdf, 252
isotonic, 18
iterations in strategy space, 33
iterations spread in time, 59, 216
iterative construction of the prior pdf,
120
J divergence, 205, 338
Jensen divergence, 205
Jensen inequality, 24, 337
Jensen-type inequalities, 204
joint pdf, 21
joint probability (density) function, 20

526
Index
kernel, 332
KL divergence, 29, 44, 307
KL divergence of GiW pdfs, 256
KL divergence of normal pdfs, 258
KL divergence of Di pdfs, 380
KL divergence of parameterized MT
factors, 439
knowledge of input-output characteris-
tics, 116
knowledge sources, 114
knowledge of input–output characteris-
tics, 267
knowledge of input-output characteris-
tics, 387
Kronecker product, 312
Kronecker symbol, 92, 155, 377
Kullback–Leibler divergence, 28, 40
L′DL decomposition, 245, 246, 260, 466
L′DL to LDL′, 248
LDL′ decomposition, 247, 296
learning condition, 76
learning data, 187
learning part of the advisory system, 95
least-square remainder, 251
least-squares (LS) estimate, 251, 252
least-squares statistics, 267
lesion, 493
lift, 332
likelihood function, 37, 43, 48
likelihood function is uncertain, 121
linear nesting operator, 49
linear term of quadratic form, 330
linear-in-parameters, 47
local approximation, 58
local ﬁlter, 104
log-normal parameterized factor, 261
log-Student pdf, 262
loss function, 15
low action rate, 75
low-pass ﬁlter, 109
lower dimensional joint pdf, 22
lower triangular matrix, 245
LS parameter estimates, 260
m-system, 68, 74
main barrier of the applicability, 16
maintenance, 2
managed system, 2, 67, 68, 70, 74
management, 2
MAP, 50, 162, 190, 306, 405
MAP estimate of a factor structure, 50
MAP estimate of a component structure,
166
marginal pdf, 21, 22
marginalization, 22
marked as missing, 104
marker, 307
Markov Chain Monte Carlo, 154
Markov chains, 47
Markov model of a ﬁnite order, 75
Markov-chain factor, 243, 377, 381
Markov-chain parameterized model, 43
martingale, 81
mathematical expectation, 20
maximum a posteriori probability, 50
MCMC, 154
mean ﬁlter, 107
mean tracking (MT), 243, 437
mean tracking (MT), 9
mechanism of generating Θt does not
change, 35
median ﬁlter, 107
merging, 267, 387
merging of components, 167
merging of knowledge pieces, 118
mixed mixtures, 463
mixture estimate, 77
model of learning, 35
model of the system, 27
model structure, 49
model validation, 96, 184, 244
most probable advice, 213
MT factor, 437
MT normal factor, 112, 437, 463
MT uniform factor, 437
multi-step-ahead, 324
multiple-mode pdf, 75
multivariate beta function, 96
natural conditions of control, 34
natural conditions of decision making,
34
nested factor, 296
nested models, 49
neural networks, 4
NN, 4
noise-covariance matrix, 262

Index
527
nomenclature of actions of the p-system,
84
nomenclature related to mixtures, 77
nonmodelled data, 77, 78
nonparametric Bayesian estimation, 381
nonparametric estimation, 38
normal ARX factor, 110
normal components, 243, 309
normal factor, 243, 259
normal mixtures, 5
normal parameterized factor, 243
normal parameterized model, 43
normalization, 22
normalization factor, 37
number of components, 167, 406
o-actions, 69
o-innovations, 69
o-system, 68
objective expectation, 20
objective pdf, 21, 40, 71, 141
“objective” pdf, 38
observable states, 75
observation model, 33
observation space of the advisory
system, 68
observation space of the operator, 68
occupancy, 500
occurrence table, 381
oﬀset, 286, 312, 331, 447, 458
one-step-ahead design, 59
one-step-ahead predictor, 97, 264, 382
online use, 75
operating modes, 191
operator, 2, 68
optimal admissible decision rule, 24
optimal admissible strategy, 25
optimal advisory system, 72
optimal decision rule, 17
optimal design, 16
optimal loss-to-go, 28
optimized probabilistic advising, VII, 1
ordered list of factors, 79
outer model, 75
outer model of the decision rule, 25
outer model of the decision strategy, 25
outer model of the system, 27
outlier detection, 102
output, 14
output of the factor, 77
p(d)f, 20
p-system, 68
parameter, 37
parameter estimation, 37
parameterized component, 77
parameterized factor, 77
parameterized model, 38, 45
partial loss, 28, 31, 59
passive strategies, 62
PCA, 4
pdf, 21
permutations on adjacent factors, 314
permuting adjacent entries, 248, 250
pf, 21
phase form, 78, 117, 149, 295, 309, 411
physical boundaries, 104
physical constraint, 15, 31
point estimate, 159
positive deﬁnite symmetric matrix, 245
posterior estimates, 77
posterior pdf, 37, 38, 48
potentially dangerous, 187, 304
potentially inﬁnite-dimensional
parameter, 38
practically admissible strategy, 16
practically optimal design, 16
pre-prior pdf, 114, 115, 123
prediction error, 259, 262, 265, 467
predictive pdf, 35, 48, 97
predictive strategies, 60
presentation of advices, 89
presentation strategy, 90, 93, 230, 233,
368
principal component analysis, 103
prior belief, 40
prior estimate, 77
prior knowledge, 114
prior pdf, 34
prior statistics, 48
prior-posterior branching, 136
probabilistic clustering, 7
probabilistic simplex, 97
probability density function, 21
probability function, 21
projections, 194
properties of expectation, 23
proportion sign, ∝, 22

528
Index
QB, 154
QB algorithm, 287
quadratic loss, 353
quality marker, 72, 192, 194
quantitative indicators, 72
quantity, 13
quasi-Bayes algorithm with common
factors, 289, 400
quasi-Bayes estimation, 154, 155, 162,
393, 404, 470, 473
quasi-Bayes estimation with common
factors, 158
quasi-Bayes estimation without common
factors, 156
quasi-EM algorithm, 155, 162
question and answer mode, 89
question-and-answer mode, 197
random variable, 12
randomized causal strategy, 25
randomized decision rule, 25
randomized strategy, 25
rank-one updating of L′DL =
λL′DL + wΨΨ ′, 247
rate of the operator’s actions, 75
ratio of Markov-chain mixtures, 414
ratio of mixtures, 196, 468
ratio of normal mixtures, 317
realization, 13, 14
receding horizon, 59
receding-horizon strategy, 59
recognizable action, 83, 90, 195, 307
recommended pointers, 419
recommended recognizable action, 93
recursive equivalence estimation, 55
recursive estimation applicable out of
the exponential family, 51
reduction of dimensionality, 102
regression vector, 47, 77, 243, 261, 385,
438, 466
regressors, 78
regulation, 46
relative activity (uptake), 494
residence time, 493
richest regression vector, 50, 297
richest structure, 49, 404
Riezs integral representation, 52
risk indiﬀerent, 20
rule for switching oﬀ, 139
sample counter, 49
sandwich initiation, 437
scaling, 103
seek for a high-probability area, 328
self-reproducing, 251, 261
set of alternatives, 100
set of minimizing arguments, 33
set-point, 27
shadow cancelling problem, 153, 289,
444
sharpening, 61
shifted conditional KL divergence, 417
signaling, 84
signaling strategy, 91, 92, 237, 372
simultaneous design, 83, 88, 487, 497
slowly varying parameters, 44
speculative class of models, 84
stability of the mixture, 356
stabilized forgetting, 44, 127
stabilizing strategy, 31
state matrix, 320, 321, 355
state of the parameterized component,
77
state vector, 194
state-dependent component weights,
469
static design, 15, 17
static factors, 112
static mixtures, 148
stationary strategy, 32
statistical process control (SPC), 3
steady state pdf, 195
steady-state pdf, 87
steady-state strategy, 343, 363, 422, 430
strategy, 15
strictly dominated, 18
strictly isotonic expectation, 18
structure estimation, 145
structure of the mixture, 295
structure of the parameterized
component, 78
structure of the parameterized factor,
78
structure of the parameterized factor in
the phase form, 78
structure of the parameterized mixture,
78
Student pdf, 259

Index
529
subfactor, 464
suboptimal design, 16, 58
suboptimal strategy, 16
successive approximations, 33
suﬃcient statistic, 49
supercautious, 61
superscript I marks the resulting ideal,
71
supervision, 2
support, 12, 38, 51, 97
supp [ f(x)], 12
surplus data space of the advisory
system, 68, 204, 206
surplus data space of the operator, 68,
72
symbol ∼, 78
tailoring of the time-scale, 102
test loss functions, 19
test of data homogeneity, 185, 303, 409
the chain rule for expectations, 25
theoretical modelling, 36
time evolution model, 34, 44
time updating, 35
time-invariant linear mapping, 51
trace, 47
transposition, 23, 47, 243
trial updating, 290
triangle inequality, 29
true user’s ideal pdf, 73, 203
true user’s ideal pf, 420
uncertain behavior, 15
uncertainty Υ, 15
unconditional expectation, 21
unequivocally bad rules, 18
unguided model, 70, 82, 90
unguided o-system, 70, 79, 84, 193
uniform distribution, 49
uninterested in some entries, 74
unit matrix, 99
unknown parameter, 37
unstable, 197, 313, 418
updating recursively the ﬁltered data
vector, 110
upper left index in V, D, L, 251
use of the advisory system, 82
user’s ideal pdf, 70, 307
user-speciﬁed KL divergence, 343
user-speciﬁed KL kernel, 344
users, 15
utility function, 20
v-likelihood, 98, 115
validation data, 187
valuewise, 28
vector of units, 387
visibility level, 326
we, 15
we designers, 15
weight of the cth parameterized
component, 77
weighted conditional KL divergence,
203, 334

