Nature Machine Intelligence | Volume 5 | April 2023 | 457â€“467
457
nature machine intelligence
https://doi.org/10.1038/s42256-023-00642-4
Article
Machine learning-enabled globally 
guaranteed evolutionary computation
Bin Liâ€‰
â€Šâ€‰1,2,6â€‰
, Ziping Wei1,6, Jingjing Wu1, Shuai Yu3, Tian Zhang3, Chunli Zhu2, 
Dezhi Zheng2, Weisi Guo4,5, Chenglin Zhao1 & Jun Zhangâ€‰
â€Šâ€‰2â€‰
Evolutionary computation, for example, particle swarm optimization, 
has impressive achievements in solving complex problems in science and 
industry; however, an important open problem in evolutionary computation 
is that there is no theoretical guarantee of reaching the global optimum 
and general reliability; this is due to the lack of a unified representation of 
diverse problem structures and a generic mechanism by which to avoid 
local optima. This unresolved challenge impairs trust in the applicability 
of evolutionary computation to a variety of problems. Here we report an 
evolutionary computation framework aided by machine learning, named 
EVOLER, which enables the theoretically guaranteed global optimization of 
a range of complex non-convex problems. This is achieved by: (1) learning 
a low-rank representation of a problem with limited samples, which helps 
to identify an attention subspace; and (2) exploring this small attention 
subspace via the evolutionary computation method, which helps to reliably 
avoid local optima. As validated on 20 challenging benchmarks, this method 
finds the global optimum with a probability approaching 1. We use EVOLER 
to tackle two important problems: power grid dispatch and the inverse 
design of nanophotonics devices. The method consistently reached optimal 
results that were challenging to achieve with previous state-of-the-art 
methods. EVOLER takes a leap forwards in globally guaranteed evolutionary 
computation, overcoming the uncertainty of data-driven black-box methods, 
and offering broad prospects for tackling complex real-world problems.
Evolutionary computation is essential to complex real-world prob-
lems that cannot be solved by classical gradient-based methods, for  
example, molecular docking or dynamics simulation1â€“3, nanophotoÂ­
nics4â€“7, ultra-fast lasers8,9, medical diagnosis10, nuclear physics11, power 
grid dispatch12â€“14, aerodynamics15,16 and so on. Particle swarm opti-
mization (PSO), a well-known evolutionary computation method,  
is a powerful tool for such challenging problems17â€“20. By reconciling  
two conflicting aspectsâ€”exploitation and exploration19â€”PSO learns 
from the best experience of the particle itself and the best experience  
of the whole population17,21; it has therefore attracted great attention 
due to its high efficiency and flexibility22,23. Various new mechanisms 
have recently been designed to avoid vanishing diversity or achieve 
fast convergence21, including: multiple populations24â€“26, learning 
strategies27,28, velocity update29, parameter settings30, population 
topology31,32 and so on. Furthermore, existing theoretical works have 
analysed the trajectory of the simplified particle33,34, the second-order 
and Lyapunov stabilities35â€“37, and the effect of parameters on stability 
and convergence35,38â€“40. But there are still two long-standing pitfalls in 
Received: 11 October 2022
Accepted: 8 March 2023
Published online: 10 April 2023
 Check for updates
1School of Information and Communication Engineering, Beijing University of Posts and Telecommunications (BUPT), Beijing, China. 2School of Information 
and Electronics, Beijing Institute of Technology, Beijing, China. 3State Key Laboratory of Information Photonics and Optical Communications, Beijing 
University of Posts and Telecommunications, Beijing, China. 4Centre for Autonomous and Cyberphysical Systems, Cranfield University, Bedford, UK.  
5The Alan Turing Institute, London, UK. 6These authors contributed equally: Bin Li, Ziping Wei. 
â€‰e-mail: Binli@bupt.edu.cn; buaazhangjun@vip.sina.com

Nature Machine Intelligence | Volume 5 | April 2023 | 457â€“467
458
Article
https://doi.org/10.1038/s42256-023-00642-4
overcoming the inherent uncertainty of black-box methods and offer-
ing broad prospects for solving challenging real-world problems.
Evolutionary computation with machine learning
We are interested in applying evolutionary computation to solve a 
prevalent problem, that is, finding the global optimum of a complex 
non-analytic function f âˆ¶â„d â†¦â„1. Our new method consists of two 
stages: (1) learning the low-rank representation, and (2) performing 
the evolutionary computation (Fig. 1 and Supplementary Fig. 2). First 
we reconstruct a low-rank representation of unknown problem space 
from limited samples (Fig. 1a). This learned global representation helps 
to identify one small attention subspace, which potentially contains 
the global optimum. Second, we use the optimization methods to 
explore this small subspace (Fig. 1b) by reliably rejecting the local 
optima. As the learned low-rank representation has the analytical 
expression and the bounded error, the theoretical probability of find-
ing the global optimum can be derived, thus overcoming the uncer-
tainty of black-box evolutionary computation.
Learning low-rank representation
Classical machine learning methods can be applied in the first stage. 
For example, one may directly use J samples {xj, f(xj)}
J
j=1 to train one 
neural network, thus modelling the complex unknown function 
Ì‚f âˆ¶â„d â†¦â„1 by 
Ì‚f(x) = g(Wx + b)  (a single layer neural network is  
considered here for simplicity), where W âˆˆâ„1Ã—d is the learned  
network weight, g(â‹…) is the nonlinear activation function and b âˆˆâ„  
is the bias. However, there are two limitations to this classical  
method in low-rank representation learning. First, it requires huge 
samples to explore the whole problem space, each of which {xj,â€‰f(xj)} 
corresponds to one time function evaluation. Second, it acquires  
unexplainable weights (that is, W), which hinders further theoretical 
analysis. To this end, we design a low-rank representation learning 
method to reconstruct a problem space from limited samples  
(Fig. 1aii). Our method is inspired by the ubiquitous low-rank structures 
of real-world problems (see Supplementary Fig. 1 for diverse benchmark 
problems, Fig. 5b for the power-dispatch problem and Fig. 6b for  
the nanophotonics inverse-design problem).
For simplicity, we start with the two-dimensional problems. We 
first explore the discrete problem space F = f(X) âˆˆâ„MÃ—N by randomly 
sampling s rows/columns (M and N denote the grid sizes of a  
solution space X âˆˆâ„MÃ—N). The sampled function values {f(xj)}
s(M+N)âˆ’s2
j=1
 
are structured into two sub-matrices C âˆˆâ„MÃ—s and R âˆˆâ„sÃ—N  
(where s â‰ªmin(M, N)); see Fig. 1ai for the sampling result of a non- 
convex Schwefel function (Supplementary Table 1); sâ€‰=â€‰3,â€‰Mâ€‰=â€‰Nâ€‰=â€‰100. 
Targeting a sample-efficient reconstruction of F, we turn to  
learning another mapping function h âˆ¶â„(MÃ—s)Ã—(sÃ—N) â†¦â„MÃ—N, so that 
Ì‚F = h(C, R) =
Ì‚f(X) (Fig. 1aii). This formulated model may be intractable 
as it is usually underdetermined. Fortunately, for the low-rank problems 
classical PSO methods that seriously undermine trust in their applica-
tion to real-world problems emerging in science and industry.
There being no theoretical guarantee of attaining the global opti-
mum of evolutionary computation methods21 has been an important 
open problem for more than 50 years41. Due to the lack of a unified 
description of diverse problem structures and a generic mechanism 
to avoid local optima, globally guaranteed evolutionary computa-
tion remains a challenging task, especially for complex non-convex 
problems. This leads to the so-called uncertainty problem; that is, after 
a limited computation time, one can hardly know whether or not the 
returned solution is globally optimal. For another, according to the cel-
ebrated no free lunch (NFL) theorem42, almost all such heuristic meth-
ods are problem-dependent. That is to say, every refined mechanism 
is only suitable to specific geometric structures (for example, convex 
envelope, smoothness and so on), yet ineffective or even problematic 
to the other problems of different structures. Consequently, there is 
no universal best method for general problems21,43,44. This presents 
another critical difficulty, especially when handling complex real-world 
problems with unexplored properties.
In this article we report a new evolutionary computation frame-
work aided by machine learning, named EVOLER, which enables the 
theoretically guaranteed global optimization of complex non-convex 
problems. By leveraging the common low-rank structure of real-world 
problemsâ€”which is barely considered in evolutionary computationâ€”our 
new method involves two stages (Fig. 1). First, with a small portion of 
structured samples (Fig. 1ai), a low-rank representation of the problem 
is learned (Fig. 1aii), which helps to identify one small attention subspace 
(Fig. 1aiii). Second, this identified subspace is explored via evolutionary 
computation methods (Fig. 1b), which offers a generic mechanism to reli-
ably avoid local optima. As shown by empirical and theoretical results, 
EVOLER finds the global optimum with a probability approaching 1 for 
rank-restricted problems (Figs. 2c and 3u,v). Moreover, it substantially 
extends the applicability of evolutionary computation in diverse prob-
lems with ubiquitous low-rank structures, and exhibits the best perfor-
mance in 20 challenging benchmarks30,45 (see Fig. 3). Furthermore, the 
convergence can be accelerated by orders of magnitude (Figs. 2f and 3).
We demonstrate our new optimizer in two important real-world 
problems: power grid dispatch and the inverse design of nanopho-
tonics devices. For the first problem, EVOLER almost surely finds the 
optimal economic cost that was not reported, making global optimiza-
tion possible subject to equality/inequality constraints. For the second 
problem, it consistently gains the optimal nanophotonic structures and 
attains the most favourable transmittance responses. Past evolution-
ary computation methods, however, find only local optima or acquire 
bad performance. Meanwhile, the number of function evaluations 
(or samples) is reduced by ~5â€“10-fold with EVOLER, thus enabling 
many rapid-prototyping applications. By a marriage of low-rank rep-
resentation and evolutionary computation, our method makes a sub-
stantial stride towards theoretically guaranteed global optimization, 
1,400
1,200
1,000
800
600
400
200
0
1,400
1,600
1,200
1,000
800
600
400
200
1,400
1,200
1,000
800
600
400
200
Ë†F
x
0
k âˆˆA
(C, R) = sampling (F), F = f (X)
Ë†
A = attention (F)
Problem
Non-analytic
f(x)
xiâˆˆ[ai,bi]
Solution
x* = argmin f(x) 
xiâˆˆ[ai,bi]
(i) Structured random 
sampling
(ii) Low-rank space 
reconstruction
Evolutionary computation
Solution initialization
t
f
Learn a low-rank approximation h
Ë†
Ë†
Ë†
rank(F) â‰¤ r,
||F â€“ F||2
F  is minimal.
s.t. F = h(C,R),
Ë†F = h(C,R)
C,R
Low-rank representation learning 
Evolutionary computation
A
(iii) Identifying attention subspace
a
b
x
t+1 = update  x0:t ,f (x0:t)
k
k
k
Fig. 1 | Schematic flow of EVOLER. a, Learning a low-rank representation of 
unknown problem space: (i) randomly sampling s columns/rows of unknown 
space F âˆˆâ„MÃ—N (dâ€‰=â€‰2,â€‰sâ€‰=â€‰3; taking a 2D Schwefel function for example); (ii) 
reconstructing the low-rank representation space Ì‚F âˆˆâ„MÃ—N (s.t., subject to); (iii) 
identifying an attention subspace. b, Exploring the small attention subspace via 
evolutionary computation and finding the global optimum.

Nature Machine Intelligence | Volume 5 | April 2023 | 457â€“467
459
Article
https://doi.org/10.1038/s42256-023-00642-4
(that is, rank (F) â‰ƒr â‰ªmin(M, N)), we are able to apply randomized 
matrix approximation techniques46â€“49 and hence approximate h via 
one special form: Ì‚F = h(C, R) â‰œCWR (Fig. 2a). Here, W âˆˆâ„sÃ—s is one 
weighting matrix that can be directly obtained (see Methods for more 
details and the extension to d-dimensional problems).
Taking a 2D Schwefel function, for example, the learned low-rank 
representation is shown in Fig. 1aiii; the residual error between real 
function values f(x) and reconstructed ones Ì‚f(x) is given in Fig. 2b. Our 
new method would have two key advantages compared with classical 
neural networks. First, it demonstrates a promising extrapolation 
capacity and thus attains very high sample efficiency. To be specific, 
we can reconstruct the unknown problem space of MN samples by  
only using [s(Mâ€‰+â€‰N)â€‰âˆ’â€‰s2] samples, where s â‰ˆğ’ªğ’ª(r log r) â‰ªmin(M, N). 
Second, it permits an analytical expression for the reconstructed  
space Ì‚F, as well as the bounded residual error46,47. As such, it further 
enables a theoretical analysis on the probability of finding the global 
optimum (see Supplementary Section 2 for details).
Evolutionary computation
Relying on the low-rank representation learned from the first stage, 
we identify one attention subspace ğ’œğ’œ. As its name suggests, this small 
subspace ğ’œğ’œ probably contains the global solution and hence claims 
the attention of the next evolutionary computation. The initial popu-
lation x0
k (k = 1, 2, â‹¯, K) is thus placed around ğ’œğ’œ, and then canonic or 
local-version PSO18,19,21 can be used to exploit this small subspace (see 
Methods for more details). Note that other evolutionary computation 
methods50 such as genetic algorithm and differential evolution can be 
combined with our method. Similarly, classical optimization methods 
such as the downhill simplex algorithm51 will be also applicable.
After the total T generations, the final solution xT is obtained. 
As noted, the identification of attention subspace offers a generic 
mechanism to reliably avoid the local optima (Supplementary 
Theorem 3). Incorporating the evolutionary computation or 
other methods, EVOLER converges to the global solution x* with a  
probability approaching 1, as demonstrated in widespread rank- 
restricted problems (see approximately low-rank problems in  
Supplementary Fig. 1bâ€“f and Fig. 6b, and strictly low-rank problems 
in Supplementary Figs. 1a,g,j and Fig. 5b). More importantly, EVOLER 
establishes the first theoretical result on the global optimum of the 
non-convex problems with common low-rank structures; that is, 
regardless of diverse geometry properties of problems, the lower 
bound probability of finding the global optimum is given by
Pr {xT â†’xâˆ—} > (1 âˆ’Ïµ) Ã— 2
Ï€ arctan (
Î”f
Î”E(s)) .
Here Ïµ is a small constant (see Supplementary Section 2). This 
lower bound probability relates to two important properties of the 
objective function. First, Î”fâ€‰â‰œâ€‰âˆ£â€‰f(x*)â€‰âˆ’â€‰f(xlocal)âˆ£ reflects the local differ-
ence (Fig. 2c), that is, the distance between the global optimum f(x*) 
and the next local optimum f(xlocal). Second, Î”E(s) âˆ[
1
MN âˆ‘
min(M,N)
j=s+1
Ïƒ2
j ]
1/2
 
is the error bound of âˆ¥F âˆ’Ì‚Fâˆ¥2
F and reflects the global coherence, that 
is, the extent of the accuracy of representing the other values with  
few samples. Here, Ïƒj denotes the jth singular value of F. We consider 
again the non-convex Schwefel function to illustrate our theoretical 
result. After obtaining the low-rank representation Ì‚F (Fig. 1aiii), we 
estimate Î” Ì‚f > 100 and Î” Ì‚E(s) â‰ƒ10âˆ’12 (sâ€‰=â€‰3,â€‰Mâ€‰=â€‰Nâ€‰=â€‰100). In line with the 
estimated lower bound in Fig. 2c, EVOLER finds the global optimum 
almost surely, with probability approaching 1 (Fig. 2e). By contrast, 
classical optimization methods almost inevitably fall into the local 
optimums in this case (Fig. 2d,g).
Results
Representative benchmark problems
We examine EVOLER in 20 benchmark problems that are commonly used 
in evolutionary computation30,45, including: unimodal, banana-valley, 
non-continuous, non-differentiable and multimodal functions, the 
2
1
0.8
0.6
0.4
0.2
0
EVOLER
Multi-start
PSO
GA
Surrogate
PS
SQP
SA
4
6
8
10
12
14
0.985
0.99
0.995
Theoretical result
Emperical data
1
5
10
15
20
25
Convergence generations
2
4
6
8
10
12 14
16
18 20
Generations
500
0
50
100
150
200
250
300
350
400
450
Generations
0
50
100
50
100
150
200
250
300
350
400
450
500
0
10
20
30
Globally guaranteed
Sampling length
Fitness function f(x)
xlocal
xopt
âˆ†f
Probability of global
optimum
Lower bound Pr{xTâ†’x*}
Histogram
Histogram
â€“1.5
â€“1
â€“0.5
0.5
1
1.5
0
2.5
1.5
1
0.5
0
2
3
Probability density
function Ã— 1011
10
2
10
0
10
â€“2
10
â€“4
Fitness
102
100
10â€“2
10â€“4
Fitness
Ã—
Ã—
R âˆˆ R
s Ã— N
C âˆˆ R
M Ã— s
W âˆˆ R
s Ã— s
â‰ˆ
F âˆˆ RM Ã— N
b
a
Averaged
g
f
e
d
c
Averaged
PSO
EVOLER
Pr{xT â†’ x*} > (1 â€“ Îµ) Ã—
arctan
2Ï€
âˆ†f
âˆ†E(s)
Residual error {F â€“ F} Ã— 10â€“11
Ë„
Fig. 2 | EVOLER enables globally guaranteed evolutionary computation.  
a, Reconstructing a low-rank representation Ì‚F âˆˆâ„MÃ—N from two sampling matrices 
C âˆˆâ„MÃ—s and R âˆˆâ„sÃ—N, as well as one weighting matrix WâˆˆRsÃ—s. b, Probability 
density of the residual error of a representation space. We still consider a 2D 
Schwefel function in this example. c, Lower bound probability of finding the global 
solution (see Supplementary Section 2); Î”f is distance between the global optimum 
and the next local optimum, whereas Î”E(s) is the upper-bound residual error related 
to a sampling length s. d, Convergence of classical evolutionary computation for a 
standard PSO with 50 particles. e, Convergence of EVOLER. f, EVOLER reduces the 
sample complexity by more than tenfold. g, EVOLER gains the global solution with 
probability 1 (500 random trials). By contrast, classical deterministic/heuristic 
global optimization methods all fail to do so (see ref. 50 for details on such 
methods). GA, genetic algorithm; PS, pattern search; SA, simulated annealing; SQP, 
sequential quadratic programming; multi-start, SQP with multiple starts.

Nature Machine Intelligence | Volume 5 | April 2023 | 457â€“467
460
Article
https://doi.org/10.1038/s42256-023-00642-4
rotated versions, the shifted versions and the hybrid composite func-
tions (see Supplementary Table 1 for details on these benchmark func-
tions). Classical methods of various new mechanisms were evaluated, 
including: multiple populations, for example, MPCPSO26, MCPSO25 
and CPSO-H/S24; improved learning strategies, for example, CLPSO28 
and NPSO27; refined position update, for example, DPSO29; parameter 
settings, for example, DNSPSO30; and population topology, for exam-
ple, GCPSO31 (see Methods for the parameter settings of EVOLER and  
Supplementary Table 2 for the parameter settings of classical meth-
ods). In the experiments, each method was evaluated for Ntâ€‰=â€‰500 
u
1
0.75
0.50
0.25
1
0.75
0.50
0.25
v
a
b
c
d
e
f
g
h
i
j
k
l
m
n
o
p
q
r
s
t
Local-PSO
EVOLERd
MPCPSO
DNSPSO
CPSO-S
CLPSO
PSO
MCPSO
CPSO-H 
DPSO
GCPSO
NPSO
EVOLERl
EVOLER
EVOLERd
EVOLERl
100
10â€“5
Fitness
Number of function
evaluations Ã— 10
4
10â€“15
0.5
1
1.5
2
2.5
0
10â€“10
100
10â€“5
Fitness
10â€“15
0.5
1
1.5
2
2.5
0
10â€“10
100
10â€“5
Fitness
10â€“15
10â€“10
100
10â€“5
Fitness
10â€“15
10â€“10
100
10â€“5
Fitness
Number of function
evaluations Ã— 10
4
10â€“15
10â€“20
0.5
1
1.5
2
2.5
0
10â€“10
100
10â€“5
Fitness
Number of function
evaluations Ã— 10
4
10â€“15
10â€“20
0.5
1
1.5
2
2.5
0
10â€“10
100
Fitness
Number of function
evaluations Ã— 10
4
Number of function
evaluations Ã— 10
4
10â€“30
10â€“40
10â€“20
0.5
1
1.5
2
2.5
0
10â€“10
Number of function
evaluations Ã— 10
4
0.5
1
1.5
2
2.5
0
f1
f1
f2
f3
f4
f5
f6
f7
f8
f9
f10
f11
f12
f13
f14
f15
f16
f17
f18
f19
f20
f2
f3
f4
f5
f6
f7
f8
f9
f10
f11
f12
f13
f14
f15
f16
f17
f18
f19
f20
f1
f2
f3
f4
f5
f6
f7
f8
f9
f10
f11
f12
f13
f14
f15
f16
f17
f18
f19
f20
Number of function
evaluations Ã— 10
4
0.5
1
1.5
2
2.5
Number of function
evaluations Ã— 10
4
2,000
Theoretical low-bound
Emperical results
6,000
10,000
14,000
0
100
10â€“5
Fitness
Number of function
evaluations Ã— 10
4
10â€“15
10â€“20
0.5
1
1.5
2
2.5
0
Number of function
evaluations Ã— 10
4
0.5
1
1.5
2
2.5
0
10â€“10
100
10â€“5
Fitness
Probability of convergence
to global optimum
10â€“15
10â€“20
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0
0.2
0.1
10â€“10
100
10â€“5
Fitness
10â€“15
10â€“10
100
10â€“5
Fitness
Number of function
evaluations Ã— 10
4
10â€“15
10â€“20
0.5
1
1.5
2
2.5
0
10â€“10
100
Fitness
Number of function
evaluations Ã— 10
4
10â€“30
10â€“20
0.5
1
1.5
2
2.5
0
10â€“10
100
10â€“5
Fitness
10â€“15
10â€“20
10â€“10
100
10â€“5
Fitness
10â€“15
10â€“20
10â€“10
102
100
Fitness
Number of function
evaluations Ã— 10
4
10â€“4
0.5
1
1.5
2
2.5
0
Number of function
evaluations Ã— 10
4
0.5
1
1.5
2
2.5
0
Number of function
evaluations Ã— 10
4
0.5
1
1.5
2
2.5
0
Number of function
evaluations Ã— 10
4
0.5
1
1.5
2
2.5
0
10â€“2
100
Fitness
10â€“100
10â€“50
100
10â€“10
Fitness
Number of function
evaluations Ã— 10
4
10â€“30
0.5
1
1.5
2
2.5
0
10â€“20
100
10â€“10
Fitness
Number of function
evaluations Ã— 10
4
10â€“30
0.5
1
1.5
2
2.5
0
10â€“20
100
10â€“5
Fitness
Number of function
evaluations Ã— 10
4
10â€“10
0.5
1
1.5
2
2.5
0
10â€“20
10â€“15
100
10â€“5
Fitness
Number of function
evaluations Ã— 10
4
10â€“10
0.5
1
1.5
2
2.5
0
10â€“20
10â€“15
EVOLER
Local PSO
DNSPSO
MPCPSO
GCPPSO
NPSO
MCPSO
CLPSO
CPSO-H
CPSO-S
DPSO
PSO
Fig. 3 | Finding the global optimum almost surely. aâ€“v, Averaged convergence 
curves are derived via 500 independent trials with random initializations. In 
EVOLER, canonic PSO is used in the second stage, whereas the local PSO and 
downhill methods are used in EVOLERl and EVOLERd, respectively. a, Ackley 
function (f1). b, Rosenbrock function (f2). c, Griewank function (f3). d, Levy 
function (f4). e, Non-continuous Rastrigin function (f5). f, Rastrigin function 
(f6). g, Schwefel function (f7). h, Sphere function (f8). i, Weierstrass function (f9). 
j, Rotated Ackley function (f10). k, Rotated Griewank function (f11). l, Rotated 
non-continuous Rastrigin function (f12). m, Rotated Rastrigin function (f13). 
n, Rotated Weierstrass function (f14). o, Shifted Levy function (f15). p, Shifted 
Rastrigin function (f16). q, Shifted Sphere function (f17). r, Shifted Weierstrass 
function (f18). s, Hybrid Composite function 2 (f19). t, Hybrid composite function 
3 (f20). u, Empirical probabilities of different methods in finding the global 
optimum (maximum generationâ€‰=â€‰500). v, Theoretical low-bound probability of 
convergence to the global optimum versus the empirical results.

Nature Machine Intelligence | Volume 5 | April 2023 | 457â€“467
461
Article
https://doi.org/10.1038/s42256-023-00642-4
independent trials with random restarts, so that 1â€‰âˆ’â€‰1/Ntâ€‰â‰¥â€‰Pr{xTâ€‰â†’â€‰x*}. 
The averaged convergence curves are thus derived (see Supplementary 
Table 3 for the statistical results); the empirical probability of finding 
the global optimum was also obtained. As the number of function evalu-
ations in each generation may be different for various methods, we 
focus on the convergence performance with regards to the number of 
function evaluations. For dâ€‰=â€‰2, we assume Kâ€‰=â€‰50 and the experimental 
results are shown in Fig. 3; for dâ€‰=â€‰30, Kâ€‰=â€‰100 and the results are shown in  
Fig. 4 and Supplementary Fig. 5.
As mentioned, one critical challenge of classical evolutionary 
computation methods is the uncertainty problem; that is, we can never 
know whether or not the returned solution is globally optimal. Apart 
from this, they are especially vulnerable to varying problem struc-
tures. Although some methods may find the global optimum in special 
cases (for example, MPCPSO in the Griewank function with the convex 
envelope), none of them can gain the good performance in all such 
benchmarks (Fig. 3a,t). By contrast, our method potentially overcomes 
the two pitfalls inherent to evolutionary computation.
From Fig. 3, EVOLER finds the global optimum with probability 1, 
regardless of the different benchmark problems of diverse geometry 
properties. This further validates our theoretical result. As the benchmark 
problems generally have low-rank structures (see Supplementary Fig. 1), 
when s â‰ˆğ’ªğ’ª{r log(r/Ïµ)}, we have Pr{xTâ€‰â†’â€‰x*}â€‰â†’â€‰1. See Fig. 2c for the theoreti-
cal lower bound probability of the Schwefel function, and Fig. 3v  
for the theoretical lower bound probability of the convergence to the 
global optimum of the other benchmark functions, as well as the empiri-
cal results. As such, even for the challenging non-convex problems, 
EVOLER would gain the global optimum almost surely, whereas classical 
deterministic or heuristic methods fail to do so (Figs. 2g and 3u).
We also observe that EVOLER attains the best performance in 
all cases. In contrast to classical PSO methods explicitly or implic-
itly assuming specific geometry properties, in EVOLER a discrete  
problem space needs only to be rank-restricted. Note that this low- 
rank structure is easy to evaluate in practice (see the online rank  
estimation in Supplementary Section 1a and Supplementary Fig. 3)  
and, moreover, is ubiquitous in application. As a result, EVOLER 
substantially extends the applicability of evolutionary computation 
in diverse problems with common low-rank structures, providing  
great promise to real-world problems with unexplored properties. 
Moreover, with the sample-efficient reconstruction of the attention 
subspace, the sample/time complexity is substantially reduced.  
For example, the required samples of EVOLER are reduced by more  
than 30-fold compared with CLPSO in the case of Schwefel function 
(Fig. 3g). To even things up, we also take samples of the first stage  
into account.
Our method could be scalable to the more challenging 
30-dimensional problems. Taking the shifted Levy function, for exam-
ple, EVOLER almost surely converges to the near-global optimum within 
1.45â€‰s; by contrast, classical PSO methods fail to do so with equal time 
budgets (see the averaged convergence curves in Fig. 4a, and the statis-
tical distribution of the achieved fitness of various methods in Fig. 4b). 
Similar results are obtained in the other 30-dimensional benchmark 
problems (see Supplementary Fig. 5 for the averaged convergence 
curves and Fig. 4d for the probability of convergence to the global 
optimum; 500 independent trials with random restarts). Provided the 
maximum generation of 900, the averaged running time of various 
methods is also obtained (Fig. 4c); 30-dimensional composite function, 
20 trails, CPUâ€‰=â€‰4â€‰GHz, RAMâ€‰=â€‰32â€‰GB.
11.6383
Â±0.0124
10.3474
Â±0.1210
12.3054
Â±0.0606
22.6337
Â±0.4131
24.2702
Â±0.3812
25.6481
Â±0.4411
25.9356
Â±0.4037
26.0529
Â±0.3838
27.5162
Â±0.4579
29.3115
Â±0.5304
31.8311
Â±0.4997
52.8459
Â±0.9642
54.0676
Â±0.9536
84.0128
Â±1.1768
EVOLERd
EVOLER
EVOLERl
NPSO
CLPSO
MCPSO
PSO
DPSO
Local-PSO
GCPSO
MPCPSO
CPSO-S
CPSO-H
DNSPSO
c
d
1
0.75
0.50
0.25
1
0.75
0.50
0.25
Local-PSO
EVOLERd
MPCPSO
DNSPSO
CPSO-S
CLPSO
PSO
MCPSO
CPSO-H 
DPSO
GCPSO
NPSO
EVOLERl
EVOLER
90
80
70
60
50
Time (s)
Time (s)
40
30
20
f15
f14
f13
f12
f11
f10
f9
f8
f7
f6
f5
f4
f3
f2
f1
f15
f14
f13
f12
f11
f10
f9
f8
f7
f6
f5
f4
f3
f2
f1
10
0
10
0
10
â€“5
10
â€“10
10
â€“15
Fitness
PDF Ã—10
16
0
1
0.5
0
PDF Ã—10
18
0.1
0.2
0.3
0.4
0.5
0
PDF
0.1
0.2
0.3
0.4
0.5
0
PDF
50
100
150
0
PDF
0.1
0.2
0.3
0
PDF
0.1
0.2
0.3
0
PDF
500
1,000
1,500
2,000
0
PDF
500
1,000
1,500
2,000
0
1
0.5
0.5
1.5
Fitness Ã—10
â€“16
Fitness Ã—10
â€“18
1
1
2
3
4
5
Fitness
0
10
20
Fitness
2
8
4
6
Fitness
0
30
10
20
Fitness Ã—10â€“3
0
0.5
1
1.5
2
Fitness Ã—10â€“3
1
1.5
2.5
2
2
0
0.005
0.015
Fitness
0.001
0.02
1.4
Local-PSO
EVOLERd
MPCPSO
DNSPSO
CPSO-S
CLPSO
PSO
MCPSO
CPSO-H 
DPSO
GCPSO
NPSO
EVOLERl
EVOLER
EVOLER
EVOLERl
MCPSO
CLPSO
Local-PSO
CPSO-H
DNSPSO
PSO
a
b
Fig. 4 | Performance in 30-dimensional benchmark problems. a, Averaged 
convergence performance of various evolutionary computation method 
(30-dimensional shifted Levy function, 100 independent trials). b, Probability 
density function (PDF) of the achieved fitness with equal time budgets (CPU 
time 1.45â€‰s). c, CPU running time of various methods. The data are presented 
as mean valuesâ€‰Â±â€‰s.e.m. (sample size 20) (30-dimensional hybrid composition 
function 1, maximum generationâ€‰=â€‰900). d, Probability of convergence to the 
global optimum of various methods (500 independent trials with random 
initializations, maximum generationâ€‰=â€‰900; see the averaged convergence curves 
in Supplementary Fig. 5). f1, hybrid composite function 1; f2, hybrid composite 
function 2; f3, Levy function; f4, Rastrigin function; f5, Rastrigin function with 
noise; f6, rotated Griewank function; f7, rotated Rastrigin function; f8, Schwefel 
function; f9, shifted composite function; f10, shifted Levy function; f11, shifted 
Rastrigin function; f12, shifted sphere function; f13, shifted Weierstrass function; 
f14, sphere function; f15, Weierstrass function.

Nature Machine Intelligence | Volume 5 | April 2023 | 457â€“467
462
Article
https://doi.org/10.1038/s42256-023-00642-4
Dispatch of power grid
Economic dispatch of a power grid is a classical yet still challenging 
real-world problem, characterized by the intrinsic difficulties in global 
optimization, that is, non-smooth fitness with many local optima12â€“14,52. 
Despite the applications of evolutionary computation14,52â€“54, this impor-
tant problem still remains unsolved. On the one hand, it is not known 
whether the global solution could be found; on the other hand, the 
probability of finding it was rarely considered. Assume the power grid 
consists of d units; each of them has the maximum power Pmax
j
 and the 
minimal power Pmin
j
 so that the output power satisfies Pmin
j
â‰¤Pj â‰¤Pmax
j
 
(see Fig. 5a). MeanÂ­while, the accumulated power of d units must be a  
consÂ­tant, that is, âˆ‘
d
j=1 Pj = Ptotal. Each unit has a non-smooth cost funcÂ­
tion fj(Pj) = aj + bjPj + cjP2
j + |dj sin[ej(Pmin
j
âˆ’Pj)]|;[ aj, bj, cj, dj, ej, Pmin
j
, 
Pmax
j
] is the parameters set of unit j, which are available in ref. 55. The 
goal is to optimize the output powers of d units, that is, {Pj}
d
j=1, so as to 
minimize the accumulated economic cost f = âˆ‘
d
j=1 fj(Pj), subject to 
the above inequality and equality constraints.
We first study the power dispatch with dâ€‰=â€‰3 by applying evolution-
ary computation methods. As we are interested in the trusted global 
optimization, each method was evaluated independently for 50 trials 
and the averaged fitness was obtained (Fig. 5c). From the singular values 
of 3D fitness, this real-world problem is strictly low ranked (Fig. 5b). We 
thus expect EVOLER would reliably find the global optimum. As seen, 
EVOLER indeed converges to a cheaper optimal cost than that of classi-
cal methods, after a few number of function evaluations. The minimal 
expected cost of classical methods is $USD 8,234.51 per 860â€‰MWh (that 
is, DSNPSO), whereas that of EVOLER is $USD 8,233.66.
We then evaluate the best solutions of different methods and the 
probabilities of finding them. For classical methods, we estimate an 
upper-bound probability of successful results, that is, the sub-optimal 
results falling to [f best
j
, (1 + Îº)f best
j
] are treated as successful ones, where 
f best
j
 is the best result achieved by method j and Îºâ€‰=â€‰10âˆ’3. From Fig. 5d, 
EVOLER finds the optimum solution with probability 1. The best cost 
of EVOLER is $USD 8,233.66 per 860â€‰MWh. Among classical methods, 
the minimal cost was achieved by GCPSO, that is, $USD 8,233.66, yet 
102
10
3
101
10
2
103
Best cost (USD Ã—104)
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
10
2
103
Number of function evaluations
1.53
1.535
1.54
1.545
1.55
1.555
1.56
1.565
1.57
1.575
EVOLER
d
EVOLER
l
EVOLER
Local PSO
DNSPSO
MPCPSO
NPSO
MCPSO
CLPSO
CPSO-H
CPSO-S
DPSO
PSO
GCPSO
102
103
Number of function evaluations
8,250
8,300
8,350
8,400
Fitness
Fitness Ã—104
Probablity of global solution
Probablity of global solution
Generations
Generations
Singular value
8,450
EVOLERd
EVOLERl
EVOLER
Local PSO
DNSPSO
MPCPSO
NPSO
MCPSO
CLPSO
CPSO-H
CPSO-S
DPSO
PSO
GCPSO
1.53035
1.5304
1.53045
1.5305
1.53055
1.5306
1.53065
CPSO-s
PSO
DNSPSO
DPSO
EVOLERl
EVOLERd
GCPSO
CPSO-h
MCPSO
CLPSO
MPCPSO
NPSO
Local PSO
EVOLER
CPSO-s
PSO
DNSPSO
DPSO
EVOLERl
EVOLERd
GCPSO
CPSO-h
MCPSO
NPSO
MCPSO
CLPSO
Local PSO
EVOLER
8,233.7
8,233.8
8,233.9
8,234
8,234.1
Best cost ($USD)
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
P2
DPSO
1
2
3
4
5
6
7
8
9
Index
10
â€“10
10
â€“5
10
0
10
5
1st dimension
2nd dimension
3rd dimension
Accumulated Energy
>95% 
GCPSO
Unit 3
Unit 2
Unit 1
P1
P1max
P2max
P3max
f1(P1)
f2(P2)
f3(P3)
a
g
f
EVOLER
CPSO-S
CPSO-H
MCPSO
PSO
DPSO
GCPSO
EVOLER
CPSO-H
CPSO-S
NPSO
b
d
c
e
h
DNSPSO
DNSPSO
MPCPSO
P3
CLPSO
NPSO
Local PSO
EVOLERl
EVOLERd
CLPSO
Local PSO
MPCPSO
PSO
MCPSO
EVOLERl
EVOLERd
Maximum 
Outlier
Median
75%
25%
Minimum 
Whisker
Fig. 5 | Optimal dispatch of power grid. a, Illustration of power dispatch with 
dâ€‰=â€‰3. b, Singular values of d-dimensional fitness (dâ€‰=â€‰3). c, Averaged results of 
various evolutionary computation methods (dâ€‰=â€‰3, Kâ€‰=â€‰20, 50 independent  
trials). d, Achievable minimal costs of different methods and the probabilities  
of finding them. e, Required generations for convergence (sample size 50).  
f, Averaged results of various evolutionary computation methods (dâ€‰=â€‰6, Kâ€‰=â€‰20, 
50 independent trials). g, Achievable minimal costs of different methods and  
the probabilities of finding them. h, Required generations for convergence 
(sample size 50).

Nature Machine Intelligence | Volume 5 | April 2023 | 457â€“467
463
Article
https://doi.org/10.1038/s42256-023-00642-4
with a small probability of 0.34. Combining the theoretical result on 
the low-rank problems, it is convinced that EVOLER would gain the 
global optimum almost surely. Furthermore, EVOLER accelerates the 
evolutionary computation by more than 15-fold compared with CLPSO 
(Fig. 5e).
We further demonstrate the advantage of EVOLER for dâ€‰=â€‰6 (see 
Supplementary Fig. 6 for the case of dâ€‰=â€‰13). From Fig. 5f, it converges 
stably to the minimal cost, that is, $USD 15,303.872 per 1,260â€‰MWh, 
whereas classical methods can only achieve $USD 15,352.396 in expecta-
tion. By rough calculation, the economic cost will be reduced by 1.1â€‰Ã—â€‰109 
dollars per year, provided that the power consumption of the whole 
world in 2021 was about 28.32â€‰Ã—â€‰1012â€‰KWh. From Fig. 5g, EVOLER again 
finds the global solution with probability 1. By contrast, classical meth-
ods more likely end up with local solutions. Although classical methods 
have an intrinsic defect of problem dependency (for example, GCPSO 
for dâ€‰=â€‰3, DNSPSO for dâ€‰=â€‰6, CLPSO for dâ€‰=â€‰13), our method consistently 
gains the best performance (see Fig. 5d,g and Supplmentary Fig. 6).
Inverse design of nanophotonics devices
Inverse design of nanostructures is essential to nanophotonics5,6, 
which has begun to reshape the landscape of structures available 
to nanophotonics4, and has been applied in many fields7,56,57 such as 
optical physics, biosensors, optical communications and so on. This 
computational task is very challenging, with elusive nanophotonics 
mechanisms and non-unique local solutions. At the present, there are 
two common strategies to handle it4,8: machine learning and evolution-
ary computation. The former adopts neural networks to model the 
complex relationship between nanophotonics structures and spec-
trum responses58â€“60, yet lacking the critical interpretability. The latter 
directly optimizes nanophotonic devices7,56,61, but inevitably acquires 
non-unique local solutions. Most importantly, both of them fail to  
gain the optimal structure, severely limiting the functionality of  
various wavelength-sensitive nanophotonics devices such as  
biosensors5,56,62, optical switches63 and so on. Despite the great impor-
tance, the optimal inverse design of nanophotonics devices remains 
an open problem.
Here we consider one representative inverse-design problem, mul-
tilayer thin-film structures4â€“6,56,59, which aims to optimize the thickness 
of L dielectric layers (SiO2 and Si3N4), subject to the target transmittance 
response. Note that our method can be generalized to similar problems, 
such as jointly optimizing the materials type or the number of periods6. 
In the experiment, dâ€‰=â€‰5 thickness parameters of Lâ€‰=â€‰18 dielectric layers 
need to be adjusted for two desirable responses (Fig. 6a). In the first 
case, the desirable response involves two bell-shaped transmittance 
bands (Fig. 6e; 3â€‰dB bandwidthâ€‰=â€‰85â€‰nm, the two centre wavelengths 
are located at 535â€‰nm and 760â€‰nm). In the second case, the response 
contains one sharp transmittance band (Fig. 6g; bandwidthâ€‰=â€‰200â€‰nm, 
the centre wavelength is located at 750â€‰nm). As noted, this real-world 
problem is inherently rank-restricted; see the singular values (Fig. 6b) 
and 2D slice of d-dimensional fitness (Fig. 6c; a2 versus a3; a1â€‰=â€‰120â€‰nm, 
a4â€‰=â€‰80â€‰nm, a5â€‰=â€‰80â€‰nm; two bell-shaped bands).
Given the thickness parameters a âˆˆâ„d, the designed  
response was obtained by finite difference time domain (FDTD)  
methods64. The fitness is defined as mean square error between the 
targeted response rt(Î»; a) and a designed response rd(Î»; a); that is, 
f(a) = âˆ‘
Iâˆ’1
i=0 |rt(Î»i; a) âˆ’rd(Î»i; a)|2; I = 201, Î»i is the discrete wavelength 
of interest. Note that each run is time consuming, for example, ~10â€“20â€‰h 
for one trial (maximum generationâ€‰=â€‰200, Kâ€‰=â€‰50; CPUâ€‰=â€‰4â€‰GHz, 
RAMâ€‰=â€‰32â€‰GB).
To demonstrate the global optimality of EVOLER, we first con-
sider one special case with an achievable optimal response, whereby 
it reliably gains the global solution (Supplementary Fig. 7). Various 
PSO methods were then evaluated in two designed cases, and the 
convergence curves were derived via five independent trials (Fig. 6d,f). 
In the first case, EVOLER consistently converges to the best result, 
acquiring a minimal mean square error of 24.7 with a probability of 
1. By contrast, the best expected fitness of classical methods is only 
26.95, that is, local PSO (see Supplementary Fig. 8 for their designed 
responses). Similar results are obtained in the second case (Fig. 6f 
and Supplementary Fig. 9). When it comes to realistic applications, 
for example, the wavelength-sensitive optical communications6,7, the 
transmission efficiency and reliability are substantially enhanced, as 
Running time (h)
20
25
30
35
40
45
50
55
EVOLERd
EVOLERl
EVOLER
Local PSO
DNSPSO
MPCPSO
GCPSO
NPSO
MCPSO
CLPSO
CPSO-H
CPSO-S
DPSO
PSO
Minimum
Running time (h)
25
30
35
40
45
50
EVOLERd
EVOLERl
EVOLER
Local PSO
DNSPSO
MPCPSO
GCPSO
NPSO
MCPSO
CLPSO
CPSO-H
CPSO-S
DPSO
PSO
Minimum
Wavelength (nm)
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1.1
Wavelength (nm)
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1.1
0
5
10
15
20
0
5
10
15
20
400
500
600
700
800
900
1,000
400
500
600
700
800
900
1,000
1
2
3
4
5
6
7
8
9
10
Index
100
1,000
10,000
50,000
110
100
90
80
70
60
50
75
60
45
30
15
75
60
45
30
15
100
95
90
85
80
75
70
65
60
1st dimension
2st dimension
3rd dimension
4th dimension
5th dimension
a1
Target
Designed
c
b
a
g
f
e
d
Output 
spectrum
Input
spectrum
Target
Designed
Accumulated energy 
>95% 
a2 a3 a4 a5 a4 a3 a2 a1 a1 a2 a3 a4 a5 a4 a3 a2 a1
Fitness
Fitness
a2 (nm)
a3 (nm)
Fitness
Transmission
Transmission
Singular value
Fig. 6 | Inverse design of nanostructures. a, Illustration of multilayer thin-
film structures. In the experiment, the thickness of Lâ€‰=â€‰18 dielectric layers 
needs to be designed, subject to the targeted transmittance response. SiO2, 
green; Si3N4, purple. b, Singular values of the problem space (dâ€‰=â€‰5). c, One 
2D slice of d-dimensional fitness. d, Averaged optimization curves of various 
evolutionary computation methods; double bell-shaped transmittance bands; 
five independent trials. e, Designed optimal transmittance response versus 
the targeted response. f, Averaged optimization curves of various evolutionary 
computation methods; single transmittance band; five independent trials. g, 
Designed optimal transmittance response vs the targeted response.

Nature Machine Intelligence | Volume 5 | April 2023 | 457â€“467
464
Article
https://doi.org/10.1038/s42256-023-00642-4
the in-band desirable signal is maximized while the out-band interfer-
ence signal is minimized.
Another important advantage of EVOLER is that it permits 
the highly efficient computation, which is very promising to the 
time-consuming inverse-design tasks. Recall that each sample was 
independently evaluated in the first stage, which can be implemented 
in parallel, thus remarkably reducing the time complexity. From Fig. 
6d,f, the computational time is reduced by around tenfold compared 
with classical PSO; two computers are used in the first stage. That is 
to say, with a dramatically reduced complexity, EVOLER attains the 
global optimum with a theoretical guarantee. As such, it provides great 
potentials to the inverse design of nanophotonics structures, as well 
as the other complex real-world problems.
Discussion
Many important problems emerging in science and industry call 
for judicious data-driven and derivative-free optimization. Despite  
broad application prospects, current evolutionary computation  
methods depend on specific problem structures and fail to acquire 
globally guaranteed solutions, severely undermining the trust in  
their applications. Here we report a new framework of evolution-
ary computation aided by machine learning, EVOLER, which makes  
it possible to attain the theoretically guaranteed global optimization 
of complex non-convex problems. As demonstrated on 20 challeng-
ing benchmark problems, and two real-world problems with diverse 
properties yet common low-rank structures, it finds the global opti-
mum almost surely, thus substantially extending applicability. Mean-
while, the number of samples can be remarkably reduced. As such, our  
method takes a leap forwards in theoretically guaranteed evolutionary 
computation, overcoming the uncertainty in data-driven black-box 
methods, and paving the way for solving complex real-world problems. 
Note that EVOLER also embodies two important biological charac-
teristics that rarely emerge in classical evolutionary computation65: 
(1) neutrality or weak selection at an early stage to preserve the  
diversity; and (2) major transitions to suddenly discover the promising 
region of solutions.
According to the theoretical result, EVOLER would be generally 
applicable to d-dimensional problems with low-rank structures. The 
complexity of our method is ğ’ª(drdâˆ’1N + TK) (see Methods and Sup-
plementary Section 3). Our method would be less attractive for prob-
lems with high d (for example, dâ€‰>â€‰100) or without a low-rank structure. 
There are two remedies for the potential limitations when tackling 
high-dimensional problems. First, various dimension reduction tech-
niques are readily applicable. Taking the challenging aerodynamic 
design problem (for example, ref. 16), a set of orthogonal basis func-
tions was first identified; the high-dimensional problem of dâ€‰>â€‰20 was 
then transformed to optimize the coefficients of the dâ€‰â‰¤â€‰10 principle 
orthogonal basis. Second, as a future direction, the incorporation of 
the hierarchy concept (for example, the hierarchy reconstruction of 
d-dimensional space; see Supplementary Fig. 4) could substantially 
reduce the complexity. For example, assume the number of blocks to 
be L â‰¤âŒŠâˆšdâŒ‹, the complexity of our method will be ğ’ª{dr(d/Lâˆ’1)N + TK}. 
Thus, the complexity in solving high-dimensional problems could be 
effectively reduced (see Supplementary Fig. 5 for the challenging 
benchmark problems of dâ€‰=â€‰30, and Supplementary Fig. 6 for the 
power-dispatch problem of dâ€‰=â€‰13). Although the wide applicability of 
EVOLER has been demonstrated, another open question is whether it 
is possible to further relax the requirements for unknown problems, 
which may deserve further study.
Methods
Evolutionary computation with PSO
Particle swarm optimization is inspired by collective intelligence in 
nature, for example, birds flocking or fish schooling17â€“19. In canonical 
PSO14,18,21, K particles (or agents) cooperatively search the d-dimensional 
problem space and update their positions (or solutions) xt+1
k
âˆˆâ„d,  
that is,
vt+1
k
= wvt
k + c1u1 âˆ˜(gt
pbest,k âˆ’xt
k) + c2u2 âˆ˜(gt
gbest âˆ’xt
k) ,
xt+1
k
= vt
k + xt
k.
(1)
As seen, updating the particle velocity vt
k involves three parts. The first 
part is the inertia termâ€”the dependence of the particleâ€™s velocity on 
time t, that is, vt
k(k = 0, 1, 2, â‹¯, K âˆ’1); the inertia weight is w âˆˆâ„+. The 
second part is the cognition itemâ€”the influence from the particleâ€™s own 
experience so far; gt
pbest,k = arg min
t
f(xt
k) âˆˆâ„d is the optimal position of 
the kth particle and f(x) âˆ¶â„d â†¦â„ is the fitness function, c1 âˆˆâ„+ is a 
cognition learning factor, u1 âˆˆâ„d is a Gaussian variable and âˆ˜ is the 
Hadamard (element-wise) product. The third term is the social  
partâ€”the influence from the experience of the whole population; 
gt
gbest = arg min
k,t f(xt
k) âˆˆâ„d  is the optimal position of K particles;  
c2 âˆˆâ„+ is the social learning factor and u2 âˆˆâ„d is a Gaussian variable.
The above canonic PSO is referred to as the global version PSO, as 
the particles will track the global best gt
gbest of the whole population. 
There also exists another local-version PSO, whereby the particles only 
track the best position of its local neighbourhood, which is denoted as 
gt
lbest. The particle positions (or solutions) will then be updated via:
vt+1
k
= wvt
k + c1u1 âˆ˜(gt
pbest,k âˆ’xt
k) + c2u2 âˆ˜(gt
lbest âˆ’xt
k) ,
xt+1
k
= vt
k + xt
k.
Exploring a global problem space
Taking dâ€‰=â€‰2 for example, the original problem spaceâ€”which is  
composed of the fitness values on a discrete grid X âˆˆâ„MÃ—N of  
continuous variables x âˆˆâ„2â€”is structured to one matrix Fâ€‰=â€‰{f(Xm,n)}, 
where mâ€‰=â€‰1,â€‰2,â€‰â€¦â€‰,â€‰M, and nâ€‰=â€‰1,â€‰2,â€‰â€¦â€‰,â€‰N;â€‰M and N denote the grid  
sizes. To explore this unknown problem space F, we randomly sample 
s columns and rows, thus obtaining two sub-matrices:
C = F(âˆ¶, ğ’ğ’) âˆˆâ„MÃ—s,
ğ’ğ’ğ’{1, 2, â‹¯, N};
R = F(â„›, âˆ¶) âˆˆâ„sÃ—N,
â„›âŠ‚{1, 2, â‹¯, M}.
Here, ğ’ğ’ and â„› are two indexing sets, with the cardinality of |ğ’ğ’ğ’= ğ’â„›ğ’
= s â‰ªmin{M, N} (see Supplementary Section 1 for the probability densi-
ties of random sampling).
Reconstructing a low-rank representation
Based on the sub-matrices C and R, a low-rank representation space is 
reconstructed (see Fig. 2a).
Ì‚F = CWR âˆˆâ„MÃ—N,
(2)
W = arg min
Wâˆˆâ„sÃ—s ||F âˆ’CWR||2
F â‰ƒ[F(â„›, ğ’ğ’)]
â€ .
(3)
Here, a small weighting matrix W âˆˆâ„sÃ—s is directly computed by mini-
mizing the residual error46â€“48,66; Yâ€  is the Mooreâ€“Penrose pseudo-inverse 
of Y. When the original space F âˆˆâ„MÃ—N is rank-restricted, that is, 
rank (F) = r â‰ªmin(M, N), and the sampling length satisfies s â‰ˆğ’ªğ’ª{r log(r/Ïµ)}, 
then the residual error is upper bounded with probability 1â€‰âˆ’â€‰Ïµ  
(refs. 46,47), that is,
âˆ¥F âˆ’Ì‚Fâˆ¥2
F â‰¤(1 + Î·)
min(M,N)
âˆ‘
j=s+1
Ïƒ2
j ,
where âˆ¥Xâˆ¥2
F is the Frobenius norm of X, Ïƒj is the jth singular value  
of F and Î· is a constant related to s. For convenience, we define the 

Nature Machine Intelligence | Volume 5 | April 2023 | 457â€“467
465
Article
https://doi.org/10.1038/s42256-023-00642-4
upper bound of the averaged residual error of each element in Ì‚F as 
Î”E(s) â‰œ[
1
MN Ã— (1 + Î·) âˆ‘
min(M,N)
j=s+1
Ïƒ2
j ]
1/2
 so that we have 
1
MN âˆ¥F âˆ’Ì‚Fâˆ¥2
F â‰¤Î”E2(s).
Identifying an attention subspace
Provided a low-rank representation space Ì‚F âˆˆâ„MÃ—N, an initial solution 
Ì‚xopt âˆˆX is then identified:
Ì‚xopt = arg min
xâˆˆX
Ì‚f(x).
(4)
We define an attention subspace as ğ’œğ’œâ‰œ{x âˆˆX; |x âˆ’Ì‚xopt| < Î´|}, where  
ğ›¿ is the subspace radius. As discussed, the learned low-rank represenÂ­
tation Ì‚F is highly accurate and thus the attention subspace ğ’œğ’œ  
probably contains the global optimum xopt = arg minxâˆˆX f(x) of a  
discrete space F (Supplementary Section 2). When N and M are  
sufficiently large, X has a very high grid resolution and hence  
subspace ğ’œğ’œ would contain the global solution xâˆ—= arg minxâˆˆâ„2 f(x)  
(Fig. 1aiii). We thus initialize K particles via one Gaussian distribution:
x0
k âˆ¼ğ’©ğ’©( Ì‚xopt, Î´) âˆˆğ’œğ’œğ’œÎ´ = ğ’ªğ’ª{max(Î´1, Î´2)},
(5)
where Î´1 = (xmax
1
âˆ’xmin
1
)/M  and Î´2 = (xmax
2
âˆ’xmin
2
)/N  denote the grid 
resolution.
Reconstructing low-rank representation for dâ€‰>â€‰2
Similar to the case in which dâ€‰=â€‰2, the high-dimensional (dâ€‰>â€‰2) space 
can be reconstructed via few structured samples. For clarity, a 
high-dimensional problem space is denoted by the tensor â„±âˆˆâ„NÃ—NÃ—â‹¯Ã—N, 
and we assume each dimensionality of the tensor â„± is equal to N.
Taking the three-dimensional representation space reconstruc-
tion as an example, we first apply a structured random sampling and 
abstract three small tensors67â€“69 ğ’ğ’1 âˆˆâ„NÃ—s2Ã—s3, ğ’ğ’2 âˆˆâ„s1Ã—NÃ—s3, ğ’ğ’3 âˆˆâ„s1Ã—s2Ã—N 
and one intersection tensor â„›âˆˆâ„s1Ã—s2Ã—s3 (s1,â€‰s2,â€‰s3â€‰â‰ªâ€‰N) (Supplementary 
Fig. 14). A representation tensor is then reconstructed via:
Ì‚â„±â‰ƒâ„›Ã—1(C1Uâ€ 
1 )Ã—2(C2Uâ€ 
2)Ã—3(C3Uâ€ 
3),
(6)
where C1 âˆˆâ„NÃ—(s2s3) was obtained by expanding the tensor ğ’ğ’1 to one 2D 
matrix along the first dimension; U1 âˆˆâ„s1Ã—(s2s3) was obtained by expand-
ing a tensor â„› to 2D matrix along the first dimension, Uâ€ 
1 denotes the 
pseudo-inverse of U1 and â„›Ã—1(C1Uâ€ 
1 ) âˆˆâ„NÃ—s2Ã—s3 denotes the one-mode 
product70.
When it comes to the arbitrary d-dimensional tensor, the above 
sampling and reconstruction procedure can be directly applicable. In 
this case, the required samples for a structured exploration is 
ğ’ªğ’ª{dsdâˆ’1N} , s = âŒŠÌ‚r Ã— log( Ì‚r)âŒ‹; r  is the rank of the tensor. To reduce the sam-
ples, we may apply a multiscale exploration, that is, we first reconstruct 
one down-sampling (
N
2 Ã—
N
2 Ã— â€¦ Ã—
N
2 ) tensor and then interpolate it  
to form the other (Nâ€‰Ã—â€‰Nâ€‰Ã—â€‰â€¦â€‰Ã—â€‰N) tensor (also see Supplementary  
Figs. 5, 6 and 15 for practical methods to further reduce the samples).
Parameter settings
EVOLER. The hyperparameters in EVOLER can be classified into two 
subsets. In the first stage, there are two parameters: the discrete length 
N (for simplicity, we assume N1â€‰=â€‰N2â€‰=â€‰â€¦â€‰=â€‰Ndâ€‰=â€‰N) and the sampling 
length s. In practice, the discrete length N is directly set to ~20â€“120. The 
rank of a discrete problem space is then estimated (see Supplementary 
Section 1a for more details), which is denoted as Ì‚r. On this basis, the 
sampling length is configured to be s = âŒŠÌ‚r Ã— log( Ì‚r)âŒ‹ (in practice, we find 
s = Ì‚r is also applicable). In the second stage, there are three parameters 
in the PSO method: the inertia weight w, the cognition learning factor 
c1 and the social learning factor c2. In the tth generation (0â€‰â‰¤â€‰tâ€‰â‰¤â€‰T), we 
have wâ€‰=â€‰0.3,â€‰c1â€‰=â€‰2â€‰âˆ’â€‰1.5â€‰Ã—â€‰t/T and c2â€‰=â€‰1.5â€‰+â€‰0.5â€‰Ã—â€‰t/T; whereby the maxi-
mum generation is T. In each independent trial, K particles are 
randomly initialized, and the sampling indexes are also randomly 
determined. For the high-dimensional problems (for example, dâ€‰=â€‰30), 
the hierarchy exploration is applied (see Supplementary Fig. 15). In  
this case, the discrete length N is ~3â€“6, and the iterative hierarchy 
exploration was terminated when the change on solutions was smaller 
than 10âˆ’3.
Classical methods. In the experiments, the parameter settings of 
classical PSO methods remain exactly the same as the related refer-
ences. For these comparative methods, their parameter settings are 
summarized in Supplementary Table 2.
Data availability
The representative benchmarks for testing evolutionary computa-
tion methods are partly available at http://www.sfu.ca/~ssurjano/
optimization.html, and partly presented in refs. 30,45. The power- 
dispatch dataset, that is, the Economic Load Dispatch Test Systems 
Repository55, is available at https://al-roomi.org/economic-dispatch. 
The dataset of inverse design of multilayer thin-film structures is avail-
able at Gitbub (https://github.com/BinLi-BUPT/EVOLER.git)71, which 
was generated by the FDTD method. Source Data are provided with 
this paper.
Code availability
Matlab code of EVOLER is available at https://github.com/BinLi-BUPT/
EVOLER.git (ref. 71).
References
1.	
Weiel, M. et al. Dynamic particle swarm optimization of 
biomolecular simulation parameters with flexible objective 
functions. Nat. Mach. Intell. 3, 727â€“734 (2021).
2.	
Morris, G. M. et al. Automated docking using a Lamarckian 
genetic algorithm and an empirical binding free energy function. 
J. Comput. Chem. 19, 1639â€“1662 (1998).
3.	
Quignot, C. et al. Interevdock2: an expanded server for protein 
docking using evolutionary and biological information from 
homology models and multimeric inputs. Nucleic Acids Res. 46, 
W408â€“W416 (2018).
4.	
Molesky, S. et al. Inverse design in nanophotonics. Nat. Photon. 12, 
659â€“670 (2018).
5.	
Sreekanth, K. V. et al. Biosensing with the singular phase of an 
ultrathin metal-dielectric nanophotonic cavity. Nat. Commun. 9, 
1â€“8 (2018).
6.	
Qiu, C. et al. Simultaneous inverse design continuous and discrete 
parameters of nanophotonic structures via back-propagation 
inverse neural network. Optics Commun. 483, 126641 (2021).
7.	
Fischer, B. et al. Autonomous on-chip interferometry for 
reconfigurable optical waveform generation. Optica 8, 1268â€“1276 
(2021).
8.	
Genty, G. et al. Machine learning and applications in ultrafast 
photonics. Nat. Photon. 15, 91â€“101 (2021).
9.	
Andral, U. et al. Fiber laser mode locked through an evolutionary 
algorithm. Optica 2, 275â€“278 (2015).
10.	 Inbarani, H. H., Azar, A. T. & Jothi, G. Supervised hybrid feature 
selection based on PSO and rough sets for medical diagnosis. 
Comput. Methods Prog. Biomed. 113, 175â€“185 (2014).
11.	
Wild, S. M., Sarich, J. & and Schunck, N. Derivative-free 
optimization for parameter estimation in computational nuclear 
physics. J. Phys. G 42, 034031 (2015).
12.	 Park, J.-B., Lee, K.-S., Shin, J.-R. & Lee, K. Y. A particle swarm 
optimization for economic dispatch with nonsmooth cost 
functions. IEEE Trans. Power Syst. 20, 34â€“42 (2005).
13.	 Park, J. B., Jeong, Y. W., Shin, J. R. & Lee, K. Y. An improved particle 
swarm optimization for nonconvex economic dispatch problems. 
IEEE Trans. Power Syst. 25, 156â€“166 (2010).

Nature Machine Intelligence | Volume 5 | April 2023 | 457â€“467
466
Article
https://doi.org/10.1038/s42256-023-00642-4
14.	 Del Valle, Y., Venayagamoorthy, G. K., Mohagheghi, S.,  
Hernandez, J.-C. & Harley, R. G. Particle swarm optimization: basic 
concepts, variants and applications in power systems. IEEE Trans. 
Evolut. Comput. 12, 171â€“195 (2008).
15.	 Skinner, S. N. & Zare-Behtash, H. State-of-the-art in aerodynamic 
shape optimisation methods. Appl. Soft Comput. 62, 933â€“962 
(2018).
16.	 Yasong, Q., Junqiang, B., Nan, L. & Chen, W. Global aerodynamic 
design optimization based on data dimensionality reduction. 
Chinese J. Aeronaut. 31, 643â€“659 (2018).
17.	 Kennedy, J. & Eberhart, R. Particle swarm optimization. In Proc. 
International Conference on Neural Networks (ICNNâ€™95) Vol. 4, 
1942â€“1948 (IEEE, 1995).
18.	 Shi, Y. & Eberhart, R. C. A modified particle swarm optimizer. In 
Proc. IEEE ICEC Conference (IEEE, 1998).
19.	 Shi, Y. & Eberhart, R. C. Empirical study of particle swarm 
optimization. In Proc. 1999 Congress on Evolutionary Computation 
(CECâ€™99) Vol. 3, 1945â€“1950 (IEEE, 1999).
20.	 Mendes, R., Kennedy, J. & Neves, J. The fully informed particle 
swarm: simpler, maybe better. IEEE Trans. Evolut. Comput. 8, 
204â€“210 (2004).
21.	 Wang, D., Tan, D. & Liu, L. Particle swarm optimization algorithm: 
an overview. Soft Comput. 22, 387â€“408 (2018).
22.	 Shi, Y. et al. Particle swarm optimization: developments, 
applications and resources. In Proc. 2001 Congress on 
Evolutionary Computation (CEC) Vol. 1, 81â€“86 (IEEE, 2001).
23.	 Poli, R., Kennedy, J. & Blackwell, T. Particle swarm optimization. 
Swarm Intell. 1, 33â€“57 (2007).
24.	 Van den Bergh, F. & Engelbrecht, A. P. A cooperative approach 
to particle swarm optimization. IEEE Trans. Evolut. Comput. 8, 
225â€“239 (2004).
25.	 Niu, B., Zhu, Y., He, X. & Wu, H. MCPSO: A multi-swarm 
cooperative particle swarm optimizer. Appl. Mathematics 
Comput. 185, 1050â€“1062 (2007).
26.	 Li, W., Meng, X., Huang, Y. & Fu, Z.-H. Multipopulation cooperative 
particle swarm optimization with a mixed mutation strategy. Inf. 
Sci. 529, 179â€“196 (2020).
27.	 Yang, C. & Simon, D. A new particle swarm optimization 
technique. In 18th International Conference on Systems 
Engineering (ICSEngâ€™05) 164â€“169 (IEEE, 2005).
28.	 Liang, J. J., Qin, A. K., Suganthan, P. N. & Baskar, S. Comprehensive 
learning particle swarm optimizer for global optimization of 
multimodal functions. IEEE Trans. Evolut. Comput. 10, 281â€“295 
(2006).
29.	 Xie, X.-F., Zhang, W.-J. & Yang, Z.-L. Dissipative particle 
swarm optimization. In Proc. 2002 Congress on Evolutionary 
Computation (CECâ€™02) Vol. 2, 1456â€“1461 (IEEE, 2002).
30.	 Zeng, N. et al. A dynamic neighborhood-based switching particle 
swarm optimization algorithm. IEEE Trans. Cybernetics 52, 
9290â€“9301 (2022).
31.	 Peer, E. S., van den Bergh, F. & Engelbrecht, A. P. Using 
neighbourhoods with the guaranteed convergence PSO. In Proc. 
2003 IEEE Swarm Intelligence Symposium (SISâ€™03) 235â€“242 (IEEE, 
2003).
32.	 Blackwell, T. & Kennedy, J. Impact of communication topology 
in particle swarm optimization. IEEE Trans. Evolut. Comput. 23, 
689â€“702 (2018).
33.	 Kennedy, J. The behavior of particles. In International Conference 
on Evolutionary Programming 579â€“589 (Springer, 1998).
34.	 Ozcan, E. & Mohan, C. K. Analysis of a simple particle swarm 
optimization system. Intell. Eng. Syst. Artificial Neural Netw. 8, 
253â€“258 (1998).
35.	 Clerc, M. & Kennedy, J. The particle swarm-explosion, stability, 
and convergence in a multidimensional complex space. IEEE 
Trans. Evolut. Comput. 6, 58â€“73 (2002).
36.	 Van Den Bergh, F. et al. An analysis of particle swarm optimizers. 
PhD thesis, Univ. Pretoria (2007).
37.	 Kadirkamanathan, V., Selvarajah, K. & Fleming, P. J. Stability 
analysis of the particle dynamics in particle swarm optimizer. IEEE 
Trans. Evolut. Comput. 10, 245â€“255 (2006).
38.	 Van den Bergh, F. & Engelbrecht, A. P. A study of particle swarm 
optimization particle trajectories. Inf. Sci. 176, 937â€“971 (2006).
39.	 Fernandez-Martinez, J. L. & Garcia-Gonzalo, E. Stochastic stability 
analysis of the linear continuous and discrete PSO models. IEEE 
Trans. Evolut. Comput. 15, 405â€“423 (2010).
40.	 Van den Bergh, F. & Engelbrecht, A. P. A convergence proof for 
the particle swarm optimiser. Fundam. Inform. 105, 341â€“374 
(2010).
41.	 Holland, J. H. Genetic algorithms and the optimal allocation of 
trials. SIAM J. Comput. 2, 88â€“105 (1973).
42.	 Wolpert, D. H. & Macready, W. G. No free lunch theorems for 
optimization. IEEE Trans. Evolut. Compu. 1, 67â€“82 (1997).
43.	 Garcia-Martinez, C., Rodriguez, F. J. & Lozano, M. Arbitrary 
function optimisation with metaheuristics. Soft Comput. 16, 
2115â€“2133 (2012).
44.	 Adam, S. P., Alexandropoulos, S.-A. N., Pardalos, P. M. & Vrahatis, 
M. N. in Approximation and Optimization 57â€“82 (Springer 2019).
45.	 Suganthan, P. N. et al. Problem definitions and evaluation criteria 
for the CEC2005 special session on real-parameter optimization. 
In Proc. IEEE Congr. Evol. Comput. (CEC) 1â€“5 (2005).
46.	 Drineas, P., Mahoney, M. W. & Muthukrishnan, S. Relative-error 
CUR matrix decompositions. SIAM J. Matrix Anal. Appl. 30, 
07070471X (2008).
47.	 Wang, S. & Zhang, Z. Improving CUR matrix decomposition 
and the NystrÃ¶m approximation via adaptive sampling. J. Mach. 
Learning Res. 14, 2729â€“2769 (2013).
48.	 Li, B. et al. Random sketch learning for deep neural networks in 
edge computing. Nat. Comput. Sci. 1, 221â€“228 (2021).
49.	 Liu, H., Wei, Z., Zhang, H., Li, B. & Zhao, C. Tiny machine learning 
(TINY-ML) for efficient channel estimation and signal detection. 
IEEE Trans. Vehicular Technol. 71, 6795â€“6800 (2022).
50.	 Younis, A. & Dong, Z. Trends, features, and tests of common 
and recently introduced global optimization methods. Eng. 
Optimization 42, 691â€“718 (2010).
51.	 Nelder, J. A. & Mead, R. A simplex method for function 
minimization. Comput. J. 7, 308â€“313 (1965).
52.	 Yang, H.-T., Yang, P.-C. & Huang, C.-L. Evolutionary programming 
based economic dispatch for units with non-smooth fuel cost 
functions. IEEE Trans. Power Syst. 11, 112â€“118 (1996).
53.	 Singh, R. P., Mukherjee, V. & Ghoshal, S. Optimal reactive power 
dispatch by particle swarm optimization with an aging leader and 
challengers. Appl. Soft Comput. 29, 298â€“309 (2015).
54.	 Xu, S., Xiong, G., Mohamed, A. W. & Bouchekara, H. R. Forgetting 
velocity based improved comprehensive learning particle swarm 
optimization for non-convex economic dispatch problems with 
valve-point effects and multi-fuel options. Energy 256, 124511 
(2022).
55.	 Al-Roomi, A. R. Economic Load Dispatch Test Systems Repository. 
Electric Power Systems Analysis & Nature-Inspired Optimization 
Algorithms https://www.al-roomi.org/economic-dispatch (2016).
56.	 Rodrigo, D. et al. Mid-infrared plasmonic biosensing with 
graphene. Science 349, 165â€“168 (2015).
57.	 Lin, Z., Liang, X., Loncar, M., Johnson, S. G. & Rodriguez, 
A. W. Cavity-enhanced second-harmonic generation via 
nonlinear-overlap optimization. Optica 3, 233 (2016).
58.	 Liu, Z., Zhu, D., Raju, L. & Cai, W. Tackling photonic inverse design 
with machine learning. Adv. Sci. 8, 2002923 (2021).
59.	 Sheverdin, A., Monticone, F. & Valagiannopoulos, C. Photonic 
inverse design with neural networks: the case of invisibility in the 
visible. Phys. Rev. Appl. 14, 024054 (2020).

Nature Machine Intelligence | Volume 5 | April 2023 | 457â€“467
467
Article
https://doi.org/10.1038/s42256-023-00642-4
60.	 Zhang, T. et al. Machine learning and evolutionary algorithm  
studies of graphene metamaterials for optimized plasmon- 
induced transparency. Opt. Express 28, 18899â€“18916 (2020).
61.	 Yu, Z., Cui, H. & Sun, X. Genetically optimized on-chip wideband 
ultracompact reflectors and Fabryâ€“Perot cavities. Photon. Res. 5, 
B15â€“B19 (2017).
62.	 Zhang, T. et al. Plasmon induced absorption in a graphene-based 
nanoribbon waveguide system and its applications in logic gate 
and sensor. J. Phys. D 51, 055103 (2018).
63.	 Miller, K. J., Hallman, K. A., Haglund, R. F. & Weiss, S. M. Silicon 
waveguide optical switch with embedded phase change material. 
Opt. Express 25, 26527â€“26536 (2017).
64.	 Lumerical, F. FDTD Solutions 6.5 (Ansys, 2023); http://www.
lumerical.com/tcad-products/fdtd
65.	 Miikkulainen, R. & Forrest, S. A biological perspective on 
evolutionary computation. Nat. Mach. Intell. 3, 9â€“15 (2021).
66.	 Li, B., Wang, S., Zhang, J., Cao, X. & Zhao, C. Ultra-fast accurate 
AoA estimation via automotive massive-MIMO radar. IEEE Trans. 
Vehicular Technol. 71, 1172â€“1186 (2021).
67.	 Mahoney, M. W., Maggioni, M. & Drineas, P. Tensor-CUR 
decompositions for tensor-based data. SIAM J. Matrix Anal. Appl. 
30, 957â€“987 (2008).
68.	 Cai, H., Hamm, K., Huang, L. & Needell, D. Mode-wise tensor 
decompositions: multi-dimensional generalizations of CUR 
decompositions. JMLR 22, 8321â€“8356 (2021).
69.	 Song, Z., Woodruff, D. P. & Zhong, P. Relative error tensor low rank 
approximation. In Proc. 30th Annual ACM-SIAM Symposium on 
Discrete Algorithms 2772â€“2789 (SIAM, 2019).
70.	 Kolda, T. G. & Bader, B. W. Tensor decompositions and 
applications. SIAM Rev. 51, 455â€“500 (2009).
71.	 Li, B., Wei, Z. & Wu, J. Machine Learning-enabled Globally 
Guaranteed Evolutionary Computation [Source Code] (Zenodo, 
2023); https://doi.org/10.5281/zenodo.7688653
Acknowledgements
This work was supported by National Natural Science Foundation of 
China under grant nos. U1805262, 62088101, 61971050 and 62171055.
Author contributions
J.Z. supervised the study. B.L. conceived the idea. B.L. and Z.P.W. 
designed and implemented source code. B.L., T.Z., S.Y. and Z.P.W. 
performed the experiments on inverse design of nanophotonics 
structures. All of the authors interpreted the findings and wrote the 
paper.
Competing interests
The authors declare no competing interests.
Additional information
Supplementary information The online version  
contains supplementary material available at  
https://doi.org/10.1038/s42256-023-00642-4.
Correspondence and requests for materials should be addressed to 
Bin Li or Jun Zhang.
Peer review information Nature Machine Intelligence thanks Jing Liang 
and the other, anonymous, reviewer(s) for their contribution to the 
peer review of this work.
Reprints and permissions information is available at  
www.nature.com/reprints.
Publisherâ€™s note Springer Nature remains neutral with regard  
to jurisdictional claims in published maps and institutional  
affiliations.
Open Access This article is licensed under a Creative Commons 
Attribution 4.0 International License, which permits use, sharing, 
adaptation, distribution and reproduction in any medium or format, 
as long as you give appropriate credit to the original author(s) and the 
source, provide a link to the Creative Commons license, and indicate 
if changes were made. The images or other third party material in this 
article are included in the articleâ€™s Creative Commons license, unless 
indicated otherwise in a credit line to the material. If material is not 
included in the articleâ€™s Creative Commons license and your intended 
use is not permitted by statutory regulation or exceeds the permitted 
use, you will need to obtain permission directly from the copyright 
holder. To view a copy of this license, visit http://creativecommons.
org/licenses/by/4.0/.
Â© The Author(s) 2023

