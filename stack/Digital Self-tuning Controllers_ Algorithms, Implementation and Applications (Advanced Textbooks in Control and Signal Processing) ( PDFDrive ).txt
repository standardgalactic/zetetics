
Advanced Textbooks in Control and Signal Processing

Series Editors
Professor Michael J. Grimble, Professor of Industrial Systems and Director
Professor Emeritus Michael A. Johnson, Professor of Control Systems and Deputy Director
Industrial Control Centre, Department of Electronic and Electrical Engineering,
University of Strathclyde, Graham Hills Building, 50 George Street, Glasgow G1 1QE, U.K.
Other titles published in this series:
Genetic Algorithms
K.F. Man, K.S. Tang and S. Kwong
Neural Networks for Modelling and Control of Dynamic Systems
M. Nørgaard, O. Ravn, L.K. Hansen and N.K. Poulsen
Modelling and Control of Robot Manipulators (2nd Edition)
L. Sciavicco and B. Siciliano
Fault Detection and Diagnosis in Industrial Systems
L.H. Chiang, E.L. Russell and R.D. Braatz
Soft Computing
L. Fortuna, G. Rizzotto, M. Lavorgna, G. Nunnari, M.G. Xibilia and R. Caponetto
Statistical Signal Processing
T. Chonavel
Discrete-time Stochastic Processes (2nd Edition)
T. Söderström
Parallel Computing for Real-time Signal Processing and Control
M.O. Tokhi, M.A. Hossain and M.H. Shaheed
Multivariable Control Systems
P. Albertos and A. Sala
Control Systems with Input and Output Constraints
A.H. Glattfelder and W. Schaufelberger
Analysis and Control of Non-linear Process Systems
K. Hangos, J. Bokor and G. Szederkényi
Model Predictive Control (2nd Edition)
E.F. Camacho and C. Bordons
Principles of Adaptive Filters and Self-learning Systems
A. Zaknich
Control of Robot Manipulators in Joint Space
R. Kelly, V. Santibáñez and A. Loría
Publication due July 2005
Robust Control Design with MATLAB®
D.-W. Gu, P.Hr. Petkov and M.M. Konstantinov
Publication due July 2005
Active Noise and Vibration Control
M.O. Tokhi
Publication due November 2005

V. Bob´al, J. Böhm, J. Fessl and J. Mach´aˇcek
Digital
Self-tuning
Controllers
Algorithms, Implementation and Applications
With 187 Figures
123

Vladimír Bob´al, Prof. Ing. CSc.
Tomas Bata University in Zlín, Faculty of Technology,
762 72 Zlín, Czech Republic
Josef Böhm, Ing. CSc.
Academy of Sciences of the Czech Republic,
Institute of Information and Automation, 182 08 Praha 8, Czech Republic
Jaromír Fessl, Ing. CSc.
Consultant in Control Engineering, Hornomˇecholupsk´a 76, 102 00 Praha 10,
Czech Republic
Jiˇrí Mach´aˇcek, Doc. Ing. CSc.
University of Pardubice, Faculty of Chemical Technology,
532 10 Pardubice, Czech Republic
British Library Cataloguing in Publication Data
Digital self-tuning controllers : algorithmus,
implementation and applications. - (Advanced textbooks in control and
signal processing)
1. Self-tuning controllers
I. Bob´al, V.
629.8’36
ISBN-10: 1852339802
Library of Congress Control Number: 2005923880
Apart from any fair dealing for the purposes of research or private study, or criticism or review, as
permitted under the Copyright, Designs and Patents Act 1988, this publication may only be reproduced,
stored or transmitted, in any form or by any means, with the prior permission in writing of the
publishers, or in the case of reprographic reproduction in accordance with the terms of licences issued
by the Copyright Licensing Agency. Enquiries concerning reproduction outside those terms should be
sent to the publishers.
Advanced Textbooks in Control and Signal Processing series ISSN 1439-2232
ISBN-10 1-85233-980-2
ISBN-13 978-1-85233-980-7
Springer Science+Business Media
springeronline.com
© Springer-Verlag London Limited 2005
MATLAB® and SIMULINK® are the registered trademarks of The MathWorks, Inc., 3 Apple Hill Drive,
Natick, MA 01760-2098, U.S.A. http://www.mathworks.com
The use of registered names, trademarks, etc. in this publication does not imply, even in the absence of
a speciﬁc statement, that such names are exempt from the relevant laws and regulations and therefore
free for general use.
The publisher makes no representation, express or implied, with regard to the accuracy of the infor-
mation contained in this book and cannot accept any legal responsibility or liability for any errors or
omissions that may be made.
Typesetting: Camera ready by authors
Production and Cover Design: LE-TEX Jelonek, Schmidt & Vöckler GbR, Leipzig, Germany
Printed in Germany
69/3830-543210 Printed on acid-free paper SPIN 11330257

To our wives Jana, Marta, Marie and Marie.

Series Editors’ Foreword 
The topics of control engineering and signal processing continue to flourish and 
develop. In common with general scientific investigation, new ideas, concepts and 
interpretations emerge quite spontaneously and these are then discussed, used, 
discarded or subsumed into the prevailing subject paradigm. Sometimes these 
innovative concepts coalesce into a new sub-discipline within the broad subject 
tapestry of control and signal processing. This preliminary battle between old and 
new usually takes place at conferences, through the Internet and in the journals of 
the discipline. After a little more maturity has been acquired by the new concepts 
then archival publication as a scientific or engineering monograph may occur. 
A new concept in control and signal processing is known to have arrived when 
sufficient material has evolved for the topic to be taught as a specialised tutorial 
workshop or as a course to undergraduate, graduate or industrial engineers. 
Advanced Textbooks in Control and Signal Processing are designed as a vehicle 
for the systematic presentation of course material for both popular and innovative 
topics in the discipline. It is hoped that prospective authors will welcome the 
opportunity to publish a structured and systematic presentation of some of the 
newer emerging control and signal processing technologies in the textbook series.
Methods adopted for use in industrial and process control systems are 
invariably straightforward in structure and easily implemented. The success of 
industrial PID controllers is often claimed to be due to these factors. The self-
tuning controller is a technology, which has all the benefits of structural simplicity 
and is not very difficult to implement but has not been widely applied in industrial 
application. One possible reason is the recent extensive development of the robust 
controller paradigm where the “one size fits all” fixed controller philosophy reigns 
supreme. Of course, a conservative controller may come with a performance cost 
degradation so it is always useful to have several tools available for each controller 
task. And as Professor Bobál and his colleagues Professors Böhm, Fessl and 
Macháþek show in this advanced course textbook the self-tuning controller can be 
very effective in preserving controller performance in the presence of slowly 
varying processes, and unknown process disturbances. 
Advances on the industrial PID controller will not make the transfer to 
industrial practice unless there are lucid and direct textbooks available to aid 

viii 
Series Editors’ Foreword 
engineers in understanding the potential of these techniques. In this textbook, 
Professor Bobál and his colleagues have captured their experiences in designing 
and applying the self-tuning controller method. The book gives a staged 
presentation that should enable the industrial engineer to develop new industrial 
applications of this adaptive control technique. 
The context of self-tuning controllers is established in the opening three 
chapters of the book. In these chapters can be found a classification of adaptive 
control methods establishing the general position of the self-tuning controller 
method. Chapter 3 serves as an introduction to process model nomenclature and to 
the techniques of process identification to be used in the text. 
Three thorough chapters then follow on different types of control design 
methods to be used in the self-tuning controller framework. These chapters 
examine closely the self-tuning PID controller (Chapter 4), the algebraic methods 
for self-tuning controller design like deadbeat, and pole-placement (Chapter 5) and 
finally, a self-tuning LQ controller (Chapter 6). Each chapter contains invaluable 
simulation examples and tips for tuning and implementing the various controller 
types.
The final two chapters deal with SIMULINK® simulation tools for gaining 
experience using the self-tuning controllers devised and recount the author team’s 
experiences with some practical process applications. The highlight here is the 
application of an adaptive LQ controller to a heat-exchanger process. 
Since the 1960s, the academic control community has devised many innovative 
controller methodologies but too few of them have made the transition to regular 
or widespread industrial practice. This new course textbook on the self-tuning 
controller method should enable industrial control engineers to gain an insight into 
the applications potential of this very transparent control technique. The material 
of the text also gives a good summary of both the theoretical and applications 
status of the method, which could prove valuable for graduate classes and for re-
igniting the method as a research theme. 
M.J. Grimble and M.A. Johnson 
Industrial Control Centre 
Glasgow, Scotland, U.K. 
January 2005 

Preface
The ﬁeld of adaptive control has undergone signiﬁcant development in recent
years. The aim of this approach is to solve the problem of controller design,
for instance where the characteristics of the process to be controlled are not
suﬃciently known or change over time. Several approaches to solving this
problem have arisen. One showing great potential and success is the so-called
self-tuning controller (STC).
The basic philosophy behind STCs is the recursive identiﬁcation of the best
model for the controlled process and the subsequent synthesis of the controller.
A number of academics from universities and other institutes have worked in-
tensively on this approach to adaptive control; K. J.˚Astr¨om (Department of
Automatic Control, Lund Institute of Technology), D. W. Clarke (Department
of Engineering Science, University of Oxford), P. A. Wellstead (Institute of Sci-
ence and Technology, University of Manchester), R. Isermann (Department of
Control Engineering, Technical University of Darmstadt), I. D. Landau (Insti-
tut National Polytechnique de Grenoble), H. Unbehauen (Control Engineering
Laboratory, Ruhr University Bochum) and also V. Peterka (Institute of Infor-
mation Theory and Automation, Academy of Sciences of the Czech Republic,
Prague) can be considered as pioneers in this ﬁeld.
Although during research much eﬀort has been devoted to meeting speciﬁc
practical requirements it cannot be said that the above approach has been
widely applied. On the other hand, many projects have been successfully put
into practice. The characteristic common to all these projects was that there
was a suﬃciently qualiﬁed operator available who was both well acquainted
with the technology in the ﬁeld and able to take on board the scientiﬁc aspects
of the work.
At this current stage of development in adaptive controllers there is a
slight growth of interest in both the simpler and more sophisticated types
of controller, particularly among universities and companies that deal with
control design. It can be seen, however, that the lack of suitable literature in
this ﬁeld imposes a barrier to those who might otherwise be interested. We
are referring especially to literature which can be read by the widest possible

x
Preface
audience, where the theoretical aspects of the problem are relegated to the
background and the main text is devoted to practical issues and helping to
solve real problems. In comparison with the most recent publications on this
subject, this book leans towards practical aspects, aiming to exploit the wide
and unique experience of the authors. An important part of this publication
is the detailed documentary and experimental material used to underline the
elements in the design approach using characteristics in the ﬁeld of time or
frequency, dealing with typical problems and principles which guide the intro-
duction of individual methods into practice. We should like to note that all
the suggested control algorithms have been tested under laboratory conditions
in controlling real processes in real time and some have also been used under
semi-industrial conditions.
The book is organized in the following way. Chapter 1 gives a brief view
of the historical evolution of adaptive control systems. The reader is intro-
duced to problems of adaptive control and is acquainted with a classiﬁcation
of adaptive control systems in Chapter 2. Modelling and process identiﬁca-
tion for use in self-tuning controllers is the content of Chapter 3. Chapter 4
discusses self-tuning PID (Proportional-Integral-Derivative) controllers. Al-
gebraic methods used for adaptive controller design are described in Chap-
ter 5. Chapter 6 is dedicated to controller synthesis based on the minimiza-
tion of the linear quadratic (LQ) criterion. Toolboxes have been created for
the Matlab R
⃝/Simulink R
⃝programming system. They serve to demonstrate
designed controller properties and help in applications of controllers in user-
speciﬁc cases. They are described in Chapter 7. Chapter 8 is devoted to prac-
tical and application problems. This chapter is based on the rich practical
experience of the authors with implementation of self-tuning controllers in
real-time conditions.
Although this book is the product of four workplaces (two universities,
academia and industry), the authors have tried to take a uniﬁed approach. Of
course, this has not always been possible. The original work is followed by a
list of literature treating the problem under discussion. We assume the reader
knows mathematics to technical university level.
This book was created by a team of authors. Chapter 2 was written by
V. Bob´al, Chapter 3 by V. Bob´al together with J. B¨ohm. V. Bob´al and J. Fessl
created Chapter 4 as follows: Sections 4.1 and 4.2 they wrote together, Sec-
tions 4.3, 4.4, and 4.5 are by J. Fessl, and Sections 4.6, 4.7, 4.8, and 4.9 are by
V. Bob´al. J. Mach´aˇcek and V. Bob´al wrote Chapter 5. Chapter 6 was written
by J. B¨ohm and Chapter 7 by V. Bob´al and J. B¨ohm. Finally Chapter 8 is a
corporate work by all authors.
This book appears with the support of the Grant Agency of the Czech
Republic, which provided the funding for projects numbered 102/99/1292 and
102/02/0204 and by the Ministry of Education of the Czech Republic under
grant No. MSM 281100001.
We would like to thank our colleagues and students in the Institute of
Process Control and Applied Informatics, Faculty of Technology at the Tomas

Preface
xi
Bata University in Zl´ın for their assistance in the preparation of toolboxes and
the camera-ready manuscript, namely Dr Petr Chalupa, Dr Frantiˇsek Gazdoˇs,
Dr Marek Kubalˇc´ık, Alena Koˇsˇt´alov´a and Jakub Nov´ak.
We would ﬁnally like to thank the Series Editors Professor M. J. Grimble
and Professor M. A. Johnson for their support during the publication of this
book.
Zl´ın, Praha, Pardubice
Vladim´ır Bob´al
December 2004
Josef B¨ohm
Jarom´ır Fessl
Jiˇr´ı Mach´aˇcek

Contents
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
2
Adaptive Control Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
2.1
Formulation of Adaptive Control Problem . . . . . . . . . . . . . . . . . .
5
2.2
Classiﬁcation of Adaptive Control Systems. . . . . . . . . . . . . . . . . .
9
2.2.1
Adaptive Controllers Based on a Heuristic Approach . . .
9
2.2.2
Model Reference Adaptive Systems . . . . . . . . . . . . . . . . . . 11
2.2.3
Self-tuning Controllers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
2.3
Summary of chapter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
3
Process Modelling and Identiﬁcation for Use in
Self-tuning Controllers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
3.1
Stochastic Process Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
3.2
Process Identiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
3.2.1
Typical Identiﬁcation Problems in Adaptive Control . . . 27
3.2.2
Identiﬁcation Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
3.2.3
Principle of the Least Squares Method . . . . . . . . . . . . . . . 30
3.2.4
Recursive Identiﬁcation Using the Least Squares Method 32
3.3
Summary of chapter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
4
Self-tuning PID Controllers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
4.1
PID Type Digital Controllers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
4.2
Modifying Digital PID Controllers . . . . . . . . . . . . . . . . . . . . . . . . . 61
4.2.1
Filtering the Derivative Component. . . . . . . . . . . . . . . . . . 62
4.2.2
Supression of Large Changes in the Controller Output . 63
4.3
Nonlinear PID Controllers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
4.4
Choice of Sampling Period . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
4.5
PID Controllers for Operational Use . . . . . . . . . . . . . . . . . . . . . . . 73
4.5.1
Initial Conditions and Controller Bumpless Connection. 74

xiv
Contents
4.5.2
Limiting the Integral Term and Wind-up of Controller . 77
4.5.3
Limited Precision in Calculation . . . . . . . . . . . . . . . . . . . . 87
4.5.4
Filtering the Measured Variables . . . . . . . . . . . . . . . . . . . . 87
4.5.5
Industrial PID Controllers . . . . . . . . . . . . . . . . . . . . . . . . . . 89
4.6
Survey of Self-tuning PID Controllers . . . . . . . . . . . . . . . . . . . . . . 90
4.7
Selected Algorithms for Self-tuning PID Controllers . . . . . . . . . . 93
4.7.1
Dahlin PID Controller . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
4.7.2
B´any´asz and Keviczky PID Controller . . . . . . . . . . . . . . . 94
4.7.3
Digital PID Controllers Based on the Pole Assignment
Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
4.7.4
Digital PID Controllers Based on the Modiﬁed
Ziegler–Nichols Criterion . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
4.8
Simulation Examples in the Simulink R
⃝Environment . . . . . . . . 128
4.8.1
Simulation Control of Fourth-order Model . . . . . . . . . . . . 129
4.8.2
Simulation Control of Third-order Nonminimum
Phase Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
4.9
Summary of chapter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
5
Algebraic Methods for Self-tuning Controller Design . . . . . . 139
5.1
Basic Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
5.2
Dead-beat Method. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
5.2.1
Strong Version of the Dead-beat Method . . . . . . . . . . . . . 143
5.2.2
Weak Version of the Dead-beat Method . . . . . . . . . . . . . . 148
5.3
Pole Assignment Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
5.3.1
Eﬀects of Pole Assignment on the Control Process . . . . . 150
5.3.2
Algorithm Derivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152
5.4
Linear Quadratic Control Methods . . . . . . . . . . . . . . . . . . . . . . . . 157
5.5
Simulation Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
5.5.1
Dead-beat Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
5.5.2
Pole Assignment Methods . . . . . . . . . . . . . . . . . . . . . . . . . . 162
5.5.3
Linear Quadratic Control Methods . . . . . . . . . . . . . . . . . . 163
5.6
Summary of chapter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164
6
Self-tuning Linear Quadratic Controllers . . . . . . . . . . . . . . . . . . . 165
6.1
The Principles of Linear Quadratic Controller Design . . . . . . . . 166
6.1.1
The Criterion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
6.1.2
The Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
6.1.3
The Optimization Approach . . . . . . . . . . . . . . . . . . . . . . . . 168
6.2
Using Linear Quadratic Controllers; Examples and Simulation 172
6.2.1
Stochastic Disturbance Compensation . . . . . . . . . . . . . . . . 175
6.2.2
Set point Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177
6.3
Adaptive Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180

Contents
xv
6.3.1
The Stochastic Approach to Linear Quadratic
Controller Design. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183
6.3.2
The Synthesis of Quadratic Control in Real Time. . . . . . 184
6.4
The Properties of a Control Loop Containing an Linear
Quadratic Controller . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185
6.4.1
Stability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186
6.4.2
The Characteristics of Linear Quadratic Control in
the Time Domain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190
6.4.3
The Characteristics of Linear Quadratic Control in
the Frequency Domain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213
6.5
Tuning an Linear Quadratic Controller . . . . . . . . . . . . . . . . . . . . . 226
6.5.1
Tuning a Controller. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226
6.5.2
Implementing Linear Quadratic Controllers . . . . . . . . . . . 233
6.6
Multivariable Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 236
6.7
Minimization of the Quadratic Criterion . . . . . . . . . . . . . . . . . . . . 237
6.7.1
Standard Minimization of the Quadratic Criterion . . . . . 237
6.7.2
Minimization of the Quadratic Criterion in Square
Root Form . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241
6.7.3
The Minimization Algorithm. . . . . . . . . . . . . . . . . . . . . . . . 242
6.8
Summary of chapter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244
7
Computer-aided Design for Self-tuning Controllers . . . . . . . . 247
7.1
Self-tuning Controllers Simulink R
⃝Library . . . . . . . . . . . . . . . . . 247
7.1.1
Overview of Library Controllers . . . . . . . . . . . . . . . . . . . . . 248
7.1.2
Controller Parameters. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252
7.1.3
Internal Controller Structure . . . . . . . . . . . . . . . . . . . . . . . . 256
7.1.4
Reference Guide and Help . . . . . . . . . . . . . . . . . . . . . . . . . . 258
7.1.5
Creating Applications with Real-Time Workshop . . . . . . 258
7.2
Linear-Quadratic Toolbox . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260
7.2.1
Fixed Linear-Quadratic Controllers . . . . . . . . . . . . . . . . . . 260
7.2.2
Adaptive Controllers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261
7.3
Summary of chapter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 265
8
Application of Self-tuning Controllers. . . . . . . . . . . . . . . . . . . . . . 267
8.1
Decentralized Control Using Self-tuning Controllers . . . . . . . . . . 267
8.1.1
Supervisory System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 268
8.1.2
Critera Used for Ending Adaptation of a Particular
Subsystem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269
8.1.3
Logical Supervisor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272
8.1.4
Control of Air Heating System Model . . . . . . . . . . . . . . . . 275
8.1.5
Control of Coupled Motors CE 108 . . . . . . . . . . . . . . . . . . 278
8.1.6
Control of Twin Rotor MIMO System – Helicopter . . . . 280
8.2
Application of the Adaptive Linear Quadratic Controller to a
Heat Exchanger Station . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282

xvi
Contents
8.2.1
The Technology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282
8.2.2
Linear Quadratic Controller . . . . . . . . . . . . . . . . . . . . . . . . 283
8.2.3
Programming Aspects. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283
8.2.4
Experimental Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285
8.2.5
Conclusions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289
8.3
Boiler Control With Multivariable Linear Quadratic Controllers291
8.3.1
The Technology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291
8.3.2
Programming Aspects. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 292
8.3.3
Connection of the Adaptive Controller into the
Existing Control Loop . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293
8.3.4
Control Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 294
8.4
Adaptive Linear Quadratic Controller in Cascade Control . . . . 297
8.4.1
The Technology and Controlled Loops . . . . . . . . . . . . . . . 297
8.4.2
Programming Aspects. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298
8.4.3
Control Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299
8.5
Steam Pressure Control of Drum Boiler in Power Plant. . . . . . . 303
8.5.1
The Technology and Controlled Loops . . . . . . . . . . . . . . . 304
8.5.2
Programming Aspects. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304
8.5.3
Control Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 315

1
Introduction
For over forty years the ﬁeld of adaptive control and adaptive systems has been
an attractive and developing area for theorists, researchers, and engineers.
Over 6 000 publications have appeared during the history of adaptive systems
and this number is certainly not deﬁnitive. However, the number of industry
applications is still low because many manufacturers distrust nontraditional
and sometimes rather complicated methods of control. The classic methods of
control and regulation have often been preferred. These have been worked out
in detail, tested, and in many cases reached the desired reliability and quality.
On the other hand, it is necessary to realize that the vast majority of processes
to be controlled are, in fact, neither linear nor stationary systems and change
their characteristics over time or when the set point changes. Such changes
aﬀect diﬀerent processes in various ways and are not always signiﬁcant. In
other systems and processes, however, the changes may be signiﬁcant enough
to make the use of controllers with ﬁxed parameters, particularly of a PID
type, unacceptable or eventually impossible.
The ﬁrst attempts to develop a new and higher quality type of controller,
capable of adapting and modifying its behaviour as conditions change (due to
stochastic disturbances), were made in the 1950s. This was in the construction
of autopilot systems, in aeronautics, in the air force, and in the military. The
concept of adaptation that in living organisms is characterized as a process
of adaptation and learning was thus transferred to control, technical, and
cybernetic systems.
From the beginning the development of adaptive systems was extremely
heterogeneous and fruitful. The results were dependent on the level of the the-
ory used and the technical and computing equipment available. During the
ﬁrst attempts simple analogue techniques (known as MIT algorithms) were
applied. Later algorithms became more complicated and the theory, more
demanding. Many approaches were not suitable for real-time applications be-
cause of the performance of the available computers or were simply too sophis-
ticated for analogue computers. That period brought results of a theoretical

2
1 Introduction
research value only. Reference [1] from 1961 shows the wealth of methods and
approaches dating from this pioneering age.
During the 1960s two main areas emerged from this diversity of approaches
to dominate the ﬁeld of adaptive systems for many years. The ﬁrst were Model
Reference Adaptive Systems (MRAS) in which the parameters of the con-
troller modify themselves so that the feedback system has the required be-
haviour. The second were self-tuning controllers (STC), which due to use of
the matrix inversion lemma were able to use measured data to identify the
model (the controlled process) on-line. The linear feedback controller param-
eters adapt according to the values of the identiﬁed parameters of the process
model. Naturally both directions had their own supporters and developments
were outlined in [2]. The next decade was characterized by growing attempts
to use adaptive systems in real-world applications, increased use of modern
computers, and by applying the latest information and methods available in
the theory of control. Examples include:
•
the use of algebraic approach in control design,
•
the parameterization of controllers,
•
the use of rational fraction functions,
•
the digitalization of signals and models.
A survey of developments during this period is given in [3]. The 1980s saw fur-
ther breakthroughs. As microprocessor technology became ever faster, cheaper
and more compact, and analogue equipment began to fall into disuse, the level
of digitalization increased and became attractive for real-time use. Adaptation
was also relevant to other areas such as ﬁltration, signal prediction, image
recognition, and others (see [4]). Methods known as auto-tuning started to
appear,in which adaptation only occurs in the ﬁrst stage of control (in order
to identify the right controller type, which then remains ﬁxed). Conferences
dealing speciﬁcally with adaptive systems were held and the number of mono-
graphs and special publications increased. The developments that took place
during this period is documented in [5]. In the early 1990s new discoveries were
applied to adaptive methods, such as artiﬁcial intelligence, neuron networks
and fuzzy techniques.
However, in the second half of the 1990s adaptive systems still showed great
unused potential in mass applications even though many well-known compa-
nies deployed adaptive principles for auto-tuning and occasionally even for
on-line control. There were still opportunities for improvements, for stream-
lining in the areas of theory and application, and for increasing reliability
and robustness. It has been accepted that there are processes that can only
be controlled with automatic adaptive controllers but that are still controlled
manually. In many real-world processes this high quality control must be en-
sured and as the process alters, this leads back to adaptation. It is reasonable
to assume that even where a nonadaptive controller is suﬃcient, an adaptive
controller can achieve improvements in the quality of control. An example

1 Introduction
3
of this is given in [6] where the use of an adaptive controller decreased fuel
consumption signiﬁcantly.
This publication is devoted to adaptive controllers of the STC type. On-
line process identiﬁcation is followed by a controller design. Various design
techniques can be used. PID, algebraic methods and the LQ approach to
controller design are considered. Speciﬁc examples of solutions are provided
including their simulation environment. This discussion is suitable for students
of engineering and those working on theses in the ﬁeld of technical cybernetics
and automation at universities of technology.

2
Adaptive Control Systems
The majority of processes met in industrial practice have stochastic charac-
ter. Traditional controllers with ﬁxed parameters are often unsuited to such
processes because their parameters change. Parameter changes are caused
by changes in the manufacturing process, in the nature of the input materi-
als, fuel, machinery use (wear) etc. Fixed controllers cannot deal with this.
One possible alternative for improving the quality of control for such pro-
cesses is the use of adaptive control systems, which has been made possi-
ble by the development of modern digital automation based on microproces-
sor technology. Naturally this must be taken together with the development
and improvement of adaptive control algorithms, and the exploration of their
potential, advantages and limitations.
This chapter is divided into two main sections followed by a summary
in Section 2.3. Formulation of the adaptive control problem is introduced
in Section 2.1, and classiﬁcation of adaptive control systems from the point
of view of basic approach in Section 2.2.
2.1 Formulation of Adaptive Control Problem
Originally, adaptation was displayed only by plants and animals, where it is
seen in its most varied forms. It is a characteristic of living organisms that
they adapt their behaviour to their environment even where this is harsh.
Each adaptation involves a certain loss for the organism, whether it is ma-
terial, energy or information. After repeated adaptations to the same changes,
plants and animals manage to keep such losses to a minimum. Repeated adap-
tation is, in fact, an accumulation of experiences that the organism can eval-
uate to minimize the losses involved in adaptation. We call this learning.
Alongside such systems found in nature there are also technical systems
capable of adaptation. These vary greatly in nature, and a wide range of math-
ematical tools are used to describe them. It is therefore impossible to ﬁnd a sin-
gle mathematical process to deﬁne all adaptive systems. For the purposes of

6
2 Adaptive Control Systems
our deﬁnition of adaptive systems we will limit ourselves to cybernetic systems
which meet the following assumptions:
•
their state or structure may change;
•
we may inﬂuence the state or output of the system.
One possible generalized deﬁnition of an adaptive system is as follows:
The adaptive system has three inputs and one output (Figure 2.1). The en-
vironment acting on the adaptive system is composed of two elements:
the reference variable w and disturbance v. The reference variable is created
by the user but, as a rule, the disturbance cannot be measured. The sys-
tem receives information on the required behaviour Ω, the system output is
the behaviour of the system (decided rule)
y = f(w, v, Θ)
(2.1)
which assigns the single output y to each behaviour occurring in environ-
ments w and v. A change in behaviour, i.e. a change in this functionality, is
eﬀected by changing parameters Θ. For each combination (w, v, Θ) we select
in place of Θ parameter Θ∗so as to minimize loss function g (for unit time
or for a given time period)
g(Ω, w, v, Θ∗) = min g(Ω, w, v, Θ)
(2.2)
Decision rule
y = f(w,v,
)

Loops for
exchange 
Minimization
of loss function
g( ,w,v, )


v
w
y

Figure 2.1. Inner structure of an adaptive system

2.1 Formulation of Adaptive Control Problem
7
In this case adaptation is the process used to search for Θ∗and contin-
ues until this parameter is found. A characteristic property of an adaptive
system is the fact that the process of adaptation always occurs when there
is a change in the environment w or v or a change in the required behaviour
Ω. If a change occurs after each time interval T0 adaptation will take place
repeatedly at the start of each interval. If the adaptation then lasts for time τ
(after which loss g decreases) then the mean loss will be lower with a smaller
ratio τ/T0. The inverse value of the mean loss is known as the adaptation
eﬀect.
We mention here the so-called learning system. The learning system can
be seen as a system that remembers the optimal value of parameter Θ∗
on ﬁnishing the adaptation for the given m triplet (wm, vm, Ωm) of sequence
{(wm, vm, Ωm)}, for k = 1, 2, . . ., m, . . . , ∞, and uses it to create in its mem-
ory the following function
Θ∗= f(w, v, Ω)
(2.3)
On completing the learning process the decided rule for every behaviour
in environments w and v can be chosen directly by selecting the appropriate
value for parameter Θ∗from memory without adaptation.
We can conclude, therefore, that an adaptive system constantly repeats
the adaptation process, even when the environment behaviour remains un-
changed, and needs constant information on the required behaviour. A learn-
ing system evaluates repeated adaptations so as to remember any state previ-
ously encountered during adaptation and when this reoccurs in the environ-
ment, does not use Equation (2.2) to ﬁnd the optimum but uses information
already in its memory.
Adaptive and learning systems can be used to solve the following tasks:
•
recursive identiﬁcation – i.e. the creation of a mathematical description of
the controlled process using self-adjusting models;
•
the control of systems about which we know too little before starting up
to predeﬁne the structure and parameters of the control algorithm, and
also systems whose transfer characteristics change during control;
•
recognition of subjects or situations (scenes) and their classiﬁcation. Adap-
tive and learning systems are then components of so-called classiﬁers;
•
manipulation of subjects – i.e. change of their spatial position. Adaptive
and learning systems are then components of robots.
Further we will focus only on problems of adaptive control. Figure 2.2
shows a general block diagram of an adaptive system. According to this dia-
gram we can formulate the following deﬁnition:
An adaptive system measures particular features of the adjustable system
behaviour using its inputs, states and outputs. By virtue of comparison of
these measured features and sets of required features it modiﬁes parameters
and the structure of an adjustable loop or generates an auxiliary input so that
the measured features track as closely as possible the required features.

8
2 Adaptive Control Systems
This deﬁnition is fairly general and allows inclusion of most of the adap-
tive problems of technical cybernetics. Features of the behaviour can take
diﬀerent forms in these problems. If the adaptive system is used for control,
the behaviour feature could be, for example,
•
pole and zeros assignment of a closed loop system;
•
the required overshoot of the step response of a closed loop system to ref-
erence and input disturbances;
•
the settling time;
•
the minimum value of various integral or summing criteria;
•
the amplitude and natural frequency of oscillations in nonlinear loops;
•
the frequency spectrum of a closed loop control system;
•
the required value of gain and phase margins etc.
Adjustable system
Adaptation
mechanism
Comparison unit
Measured indicators
of behaviour
Outputs
Inputs
Required
indicators
State
Nonmeasurable
Measurable
Disturbances
Figure 2.2. General block diagram of adaptive control system
For the purposes of automatic control we can simplify the deﬁnition
of an adaptive system still further:
Adaptive control systems adapt the parameters or structure of one part
of the system (the controller) to changes in the parameters or structure in an-
other part of the system (the controlled system) in such a way that the entire
system maintains optimal behaviour according to the given criteria, indepen-
dent of any changes that might have occurred.
Adaptation to changes in the parameters or structure of the system can
basically be performed in three ways:

2.2 Classiﬁcation of Adaptive Control Systems
9
•
by making a suitable alteration to the adjustable parameters of the con-
troller;
•
by altering the structure of the controller;
•
by generating a suitable auxiliary input signal (an adaptation by the input
signal).
2.2 Classiﬁcation of Adaptive Control Systems
The diﬀerence between classic feedback controllers and adaptive controllers is
that the classic controller uses the principle of feedback to compensate for un-
known disturbances and states in the process. Feedback is ﬁxed and ampliﬁes
or otherwise modiﬁes the error e = w −y (w is the reference value of process
output y), which in turn determines the value of the input signal u (controller
output) for the system. The way in which the error is processed is the same
in all situations. The basis of the adaptive system is that it alters the way
in which the error is processed, i.e. adapts the control law to unknown con-
ditions and extends the area of real situations in which high quality control
can be achieved. Adaptation can be understood as feedback at a higher level
where the controller parameters change according to the quality of the control
process.
In recent years the theory of adaptive control has made signiﬁcant devel-
opments. Obviously, as in any other new scientiﬁc discipline, the theory of
adaptive control has no uniﬁed approach to classifying the systems operating
on this principle. Here it suﬃces to use the classiﬁcation set out in Figure 2.3;
learning systems are not included. For detailed adaptive control systems clas-
siﬁcation according to diﬀerent approaches see [7].
Adaptive systems based on the heuristic approach, self-tuning controllers
(STC) and model adaptive reference systems (MRAS) are currently the three
basic approaches to the problem of adaptive control. Adaptive systems which
have a variable structure will purposely alter their structure following the set
procedure. Since such a system alters its structure on the basis of experience
gained previously in its working life, it may be regarded as a self-organizing
system.
2.2.1 Adaptive Controllers Based on a Heuristic Approach
Methods using this approach provide adaptability directly either by evaluating
the process output (or its error) or selected quality criteria for the control
process. In these cases the algorithm for a PID digital controller is often used
and we usually select the level of oscillation in the process output, or its error,
as the criterion. These methods do not require identiﬁcation of the controlled
system. In some cases it is not even necessary to monitor the output error
or introduce special test signals. A block illustration of these methods is given
in Figure 2.4. Process output y, or error e, are evaluated according to the

10
2 Adaptive Control Systems
ADAPTIVE CONTROL
SYSTEMS
Adaptive
controllers -
heuristic approach
Self-tuning
controllers (STC)
Model reference
adaptive systems
(MRAS)
Adaptive systems
with
variable structure
STC based on
direct
identification
STC based on
indirect
identification
MRAS using
parametric setting
MRAS using
signal setting
Figure 2.3. Classiﬁcation of adaptive control systems
supplied criterion and subsequently preset the parameters of a PID controller.
w
Criterion evaluation
Controller parameters
computation
Process
Controller
u
y
n
q
e
Figure 2.4. Diagram of the heuristic approach to adaptive control
When synthesizing this kind of controller we try to optimize the criterion
that quantiﬁes the quality of the control process. Although this approach
satisﬁes practical applications while also being robust, it comes up against
a number of calculation problems and has only been successfully applied in
the simplest cases.

2.2 Classiﬁcation of Adaptive Control Systems
11
One of these successful applications is the approach designed by Marˇs´ık [8];
the method involves setting the gain of the PID controller and selecting the os-
cillation range as the directly measurable criterion. We know that the con-
trol process oscillates more as it approaches the limits of stability, while too
damped a process ceases to oscillate at all. There are several modiﬁcations
to this type of controller, some of which are so simple that they can even be
realized by a few dozen ﬁxed point operations.
˚Astr¨om and H¨agglund added the term self-tuning alongside the expres-
sion auto-tuning [9]. Although auto-tuning cannot be regarded as the same
as self-tuning we will describe some of the principles of these controllers in
this section. One example of this type of controller which has been fairly
widely applied in practice is the auto-tuning controller designed by ˚Astr¨om
and H¨agglund [10, 11], where alongside the PID controller a relay type of non-
linearity is inserted in parallel into the feedback. During the adjustment phase
the relay is introduced into the feedback causing the control loop to oscillate
at a critical frequency. Since controller output u acquires only two values ±R
and is therefore a rectangular process, the process output y has an approxi-
mately sine wave pattern, the shape of which depends on how the system ﬁl-
ters harmonics out of the controller output. A simple Fourier series expansion
of the relay output shows that the ﬁrst harmonic component has amplitude
4R/π. The ultimate (critical) gain KPu is then given as the ratio of the am-
plitude of the ﬁrst harmonic component and the error amplitude emax
KPu =
4R
πemax
(2.4)
The ultimate (critical) period Tu is measured from the cycling.
The controller can also be automatically adjusted by evaluating tran-
sient processes. Kraus and Myron [12] describe the so-called “EXACT Con-
troller” (Expert Adaptive Controller Tuning) from the company Foxboro. This
auto-tuning controller uses the pattern recognition approach, i.e. knowledge
of the error process during transition. To make adjustments the controller
uses three peaks from the error process to calculate overshoot and undershoot,
which in turn is used together with the oscillation period to set the parameters
for the PID controller. Some authors (such as Nishikawa et al. [13]) suggested
adjusting PID controllers by measuring system response of the reference sig-
nal or process output in an open or closed loop. The parameters of the PID
controller are optimized by calculating the integral linear or quadratic crite-
rion for control process quality. In recent years much has been published on
auto-tuning controllers, especially of the PID type (see [14, 15] and others).
2.2.2 Model Reference Adaptive Systems
The problem of model reference adaptive systems design is theoretically well
elaborated and widely discussed in the scientiﬁc literature [16, 17]. The basic
block diagram of the model reference adaptive system is shown in Figure 2.5.

12
2 Adaptive Control Systems
The reference model gives requested response ym or requested state vector xm
to reference input signal ur.
This approach is based on observation of the diﬀerence between the output
of the adjustable system ys and the output of the reference model ym.
The aim of the adaptation is convergence of the static and dynamic char-
acteristics of the adjustable system, i.e. the closed loop, to the characteris-
tics of the reference model. This, in fact, is an adaptive system with forced
behaviour where the comparison between this forced behaviour and the be-
haviour (response) of the adjustable system (control loop) ys, provides the
error ε. The task of the appropriate control mechanism is to reduce error ε
or errors in the state vector x between the reference model and the adjustable
system to a minimum for the given criteria. This is done either by adjusting
the parameters of the adjustable system or by generating a suitable input
signal, as can be seen in Figure 2.5.
Reference model
Adjustable system
Adaptation
mechanism
ur
ym
Disturbances
Disturbances
ys

Adaptation using
parametric setting
Adaptation using
signal setting
Figure 2.5. Basic block diagram of a model reference adaptive system
The dual character of this adaptive system is important since it can be
used both for control and to identify the parameters of the model process
or to estimate the state of the system. These systems are, to a certain extent,
limited by the fact that they are only suited to deterministic control, however
prospects for their wider use are good.

2.2 Classiﬁcation of Adaptive Control Systems
13
2.2.3 Self-tuning Controllers
For the two approaches previously outlined the design of an adaptive controller
did not require detailed knowledge of the dynamic behaviour of the controlled
system. Another approach to adaptive control is based on the recursive es-
timation of the characteristics of the system and disturbances and updating
the estimates, so monitoring possible changes. Using this knowledge, appro-
priate methods can be employed to design the optimal controller. This kind
of controller, which identiﬁes unknown processes and then synthesizes control
(adaptive control with recursive identiﬁcation) is referred to in the literature
as a self-tuning controller – STC. The most useful results in practical terms
have been achieved mainly in one-dimensional systems for which a number
of numerically stable algorithms of varying complexity have been designed.
These algorithms can then be applied via a control computer equipped with
a unit to interface with the technological environment. Expanding this to mul-
tivariable systems in many cases does not cause fundamental problems.
Controlled process
Computer - adaptive
controller
y(k)
u(k)
w(k)
n(k)
v(k)
Figure 2.6. Basic block diagram of digital adaptive control loop
We assume a controlled technological process with a single process in-
put u(k) and a single process output y(k). In addition, measurable distur-
bance v(k) and nonmeasurable disturbance n(k) – random noise – may aﬀect
the controlled process. A computer working as the digital adaptive controller
is connected in feedback to the controlled process and, among other things,
processes the required value of the process output. The block diagram of this
basic feedback loop is given in Figure 2.6.
An adaptive digital controller works with a ﬁxed sampling period T0.
A controller with this period generates a sequence of numerical values for
the controller output {u(k); k = 1, 2, . . .} (assuming T0 = 1). The discrete
controller output u(k) operates via an digital–to–analogue (D/A) converter

14
2 Adaptive Control Systems
and actuator in the closed loop. The controller output value is constant during
the sampling interval. The actuator, including D/A converter, is included in
the dynamics of the controlled process. The output of the controlled process
is a physical (usually continuous-time) variable, which is also sampled over
period T0. Therefore, as far as the controller is concerned, the process out-
put is a sequence of numerical values {y(k); k = 1, 2, . . .} and this is the only
information the controller has regarding the continuous-time output. It can
sometimes be useful to ﬁlter the continuous-time system output before sam-
pling. The sensor, A/D converter and any ﬁlter being used are also regarded
as part of the controlled process.
The basic feedback loop can be extended by a forward loop from the ex-
ternally measured disturbance v(k), if such measurements are available. Its
behaviour is also sampled over period T0 and transferred to the controller
as a sequence of numerical values {v(k); k = 1, 2, . . .}, and at the same time
the reference variable value is digitally expressed as a sequence of numerical
values {w(k); k = 1, 2, . . .}. The existence of random nonmeasurable distur-
bance v(k) and any change in the reference variable value w(k) is the reason
for introducing automatic control. The aim of control is to compensate these
disturbances as well as to track the reference variable values. Further, we as-
sume that the parameters of the controlled process are either constant but un-
known or variable, in which case changes in these parameters are signiﬁcantly
slower than the speed of the adaptation process. Depending on
the nature
of the controlled process we can see how the following aims can be achieved
using adaptive control with recursive identiﬁcation:
•
automatic tuning of the digital controller;
•
improved control where nonstationary disturbances are present;
•
the detection of changes in the parameters of the controlled system aris-
ing from various technological causes, for example changing the operating
mode of the equipment;
•
improvement in the control procedure of a given process by making a suit-
able change to the parameters of the digital controller.
Algorithmic Structure of Self-tuning Controllers
It is clear that to reach these goals the identiﬁcation of the static and dy-
namic characteristics of a given process plays an important role together with
the optimal control strategy itself. From parameter estimation theory we know
that the determination of parameters is always burdened by a degree of uncer-
tainty – error. This uncertainty not only depends on the number of identiﬁed
steps (i.e. on the amount of sampled data) and on the choice of structure
for the mathematical model of the controlled process, but is also dependent
on the behaviour of the controller output, the sampling period and the choice
of ﬁlter for the controller and process outputs. This means that every realized
change in a controller output except the required control eﬀect, also excites

2.2 Classiﬁcation of Adaptive Control Systems
15
Process
Adaptive predictor
Calculation
of parameters
for control law L
w
y
Control law L
y
n
v
u

Identification part
Control part
Self-tuning
controller
Figure 2.7. Internal algorithmic structure of a self-tuning controller
the controlled system and thus creates the conditions for its identiﬁcation; in
other words, for the best identiﬁcation of the controlled process, it is necessary
to impose certain conditions on the course of controller outputs.
The general task of optimal adaptive control with recursive identiﬁcation
is, therefore, extremely complicated because we have to seek within it a se-
quence of such controller outputs which can ensure that the mean process
output value is as close as possible to the target value and at the same time
enable the most accurate identiﬁcation of the given process. Feldbaum [18]
has presented a design for optimal control which, to a certain extent, ﬁts
the given assumptions. Because this design for optimal control has two eﬀects
it is called dual optimal control. Unfortunately, due to the complexity of the
calculations it involves, dual optimal control is too demanding to be of use
in most situations. Although exceptional eﬀorts have been devoted to dual
optimal control, not even the use of various simpliﬁed approximations has
managed to reduce it to a stage where it can be applied practically.
It has, therefore, been necessary to simplify the solution to this problem
using experimental experience and intuition. This solution is called forced

16
2 Adaptive Control Systems
separation of identiﬁcation and control – the Certainty Equivalence Principle.
The principle of this simpliﬁcation is outlined in the following procedure:
1. The vector of process model parameters Θ are regarded as being known
for each control step and this equals its point estimate, which is available
at any given moment, i.e. Θ = ˆΘ(k −1).
2. The design of the control strategy to aﬀect the desired control quality
criteria is based on this assumption and the required controller output
u(k) is calculated.
3. Having acquired a new sample of process output y(k) (or external mea-
sured disturbance v(k)) and known controller output u(k) a further
step in identiﬁcation is performed using a recursive identiﬁcation algo-
rithm. This means that the new information on the process deduced from
the three data items {u(k), y(k), v(k)} is used to update estimate ˆΘ(k−1)
and the entire procedure is repeated to make a new estimate ˆΘ(k).
From experience gained during experimentation we can see that the ma-
jority of practical tasks of adaptive control with recursive identiﬁcation are
suited to the given simpliﬁed approach.
The approach described above implies the inner algorithmic structure
of the self-tuning controller schematically shown in Figure 2.7. The forced
separation of identiﬁcation and control splits the inner controller structure
into parts for identiﬁcation and control, which are only connected through
the transfer of point parameter estimates ˆΘ(k). Recursive estimation of the
process model parameters is carried out in the identiﬁcation part and used
to predict value ˆy(k) of process output y(k). The control part contains a block
to calculate the control parameters (control law L) using the process model
parameter estimates ˆΘ(k). The control parameters then serve to calculate
the value of controller output u(k) for each sampling period.
As can be seen from the structure above, reliable and quickly convergent
identiﬁcation is absolutely vital if the controller is to function well. Even
though certain speciﬁc conditions are applied to the synthesis of adaptive
control we can state that, where identiﬁcation works well, synthesis can be
carried out using known algorithms such as those for pole assignment de-
sign, dead-beat control, minimum variance control, generalized minimum vari-
ance control, linear quadratic control, and digital synthesis methods for PID
controllers. The STC algorithms mentioned in this monograph diﬀer only in
the control path; for identiﬁcation we will be using the recursive least squares
method.
In some STCs the identiﬁcation process does not serve to determine es-
timates of the process model parameters ˆΘ(k), rather, appropriate repara-
metrization of the control loop can be used recursively to estimate the con-
troller parameters directly. This means it is necessary to ﬁnd the relationship
between the process input and
output and deﬁne it directly from the con-
troller parameters without recalculating them using the estimates of the pro-
cess model parameters. These controllers are referred to as being implicit,

2.2 Classiﬁcation of Adaptive Control Systems
17
w
Recursive
identification of
process parameters
Controller parameters
computation
Process
Controller
e
y
n
q
Q S
Q i

v
u
Figure 2.8. Block diagram of an explicit STC (with direct identiﬁcation)
whereas controllers using a synthesis from estimates of the process model
parameters are called explicit. If we illustrate an explicit STC using a dia-
gram like the one in Figure 2.8, which is analogous to Figure 2.7, where Qi
is the identiﬁcation criterion, Qs the controller synthesis criterion and q are
the controller parameters, we may draw a diagram of an implicit STC as in
Figure 2.9.
w
Recursive
identification of
controller parameters
Process
Controller
e
y
n
q
Q i
v
u
Figure 2.9. Block diagram of an implicit STC (with indirect identiﬁcation)
The STC principle can also be used for one-shot controller tuning (auto-
tuning). If the algorithm illustrated in Figure 2.7 is used for controller auto-
tuning then the blocks representing recursive identiﬁcation and controller pa-

18
2 Adaptive Control Systems
rameter calculation are only connected at the moment when the controller is
being set up, i.e. during the adjustment phase. Once the controller has been
adjusted they are disconnected. The system is then controlled by ﬁxed pa-
rameters. Clearly, this method of control is useful for deterministic processes
where identiﬁcation is switched oﬀonce the controller has been adjusted. The
underlying principle of this type of controller is shown in Figure 2.10.
w
One-off process
identification
Controller parameters
computation
Process
Controller
e
y
n
q
v
u
Figure 2.10. Block diagram of an auto-tuning controller using a one-oﬀidentiﬁca-
tion process
Development of Self-tuning Controllers
Here we give a brief history of the development of explicit STCs. The ap-
proach used in STCs was ﬁrst mentioned in the work of Kalman [19] in 1958.
He designed a single-purpose computer to identify the parameters of a lin-
ear model process and subsequently calculate the control law using minimum
quadratic criteria. This problem was revived in the early 1970s by the work
of Peterka [20] and ˚Astr¨om and Wittenmark [21] and others. The approach
has been developed signiﬁcantly since then. The ﬁrst STCs were designed so
as to minimize system output variance where some disadvantages were re-
moved by the general minimization of output dispersion method developed
by Clarke and Gawthrop [22, 23]. These are known as single-step methods
because only one sample of the process output is considered in the quadratic
criterion. One great disadvantage is that they are unable to control the so-
called nonminimum phase systems, which are processes where the polynomial
B(z) (the polynomial which is included in the controlled system transfer func-
tion numerator) has its poles outside the unit circle of the complex z-plane,
i.e. in an unstable area.

2.2 Classiﬁcation of Adaptive Control Systems
19
This problem can be solved by using multi-step criteria (to limit an inﬁ-
nite number of steps) which is a solution to the general quadratic problem.
Peterka analyzed the probability rate of the Bayessian approach to adaptive
control based on linear quadratic synthesis [24]. In general this control synthe-
sis involves rather complex iteration calculations [25]. It has been shown that
analytic methods may be used to ﬁnd relatively simple explicit relationships
to determine the optimal controller for one-dimensional models that are no
higher than second order (see B¨ohm et al., [26]).
In the late 1970s, early 1980s the ﬁrst work was done on STCs based
on pole assignment [27, 28]. During the 1980s much attention was also paid
to single- and multi-step prediction adaptive methods [29, 30]. Hybrid STCs
using a δ operator have similarly been analyzed [31]. Alongside these devel-
opments there has been exploration into synthesis methods for digital PID
controllers which might be able to use parameter estimates gained through
recursive identiﬁcation to calculate controller intervention. These parameters
are then used to calculate the PID controller elements, that is gain KP , and
integral and derivative time constants TI and TD [32, 33].
Problems for Further Research of Self-tuning Control Design
The principles of adaptive controllers bring also some drawbacks, mainly in
the area of reliability, a property that is very important for any application.
The problem is caused mainly by the identiﬁcation part. Conditions for unbi-
ased estimation cannot always be satisﬁed. Most of the present adaptive con-
trollers consider only model parameter adaptation. Thus adaptive controllers
are suitable only for slowly varying processes. In cases when parameter changes
are abrupt, e.g. in the case of nonlinearities, fault states or rapid changes of
process working conditions, parameter adaptivity cannot react properly.
To improve the identiﬁcation part, developments in the following areas
may be promising:
•
use of diﬀerent, usually more complex, identiﬁcation methods which have
less strict conditions for correct estimation;
•
use a set of ﬁxed models describing the given plant instead of on-line
identiﬁcation;
•
use of a supervisor, monitoring controller behaviour and correcting its
behaviour.
The idea of a supervisor deserves further attention. A supervisor can be
implemented simply and some forms of it are now frequently used. Any prac-
tical application is completed by a process-speciﬁc supervisor that switches
the adaptive controller over to an available standard controller in the case of
unexpected controller behaviour.
A data-dependent forgetting factor in identiﬁcation is now standard [34].
Data-dependent controller synthesis is used in Chapter 6 and Chapter 8.

20
2 Adaptive Control Systems
More complex supervisors can be developed based on artiﬁcial inteligence
approaches. Methods such as fuzzy logic, evolutionary algorithms [35, 36],
or their combination show themselves to be promising methods from the
artiﬁcial intelligence ﬁeld [37, 38]. An intelligent supervisor based on these
methods can be used. Its task generally is parameter adjusting and/or choice
of an appropriate controller. If a fuzzy supervisor is used, then it can be
regarded as a set of static nonlinear I/O functions. Its task is controller pa-
rameter adjustment if needed, and/or the choice of an appropriate controller
from classes of controllers. Adjustment of the fuzzy controller must be done
for error-free function. Today, there are three common methods for this. In
the ﬁrst, an expert adjusts all fuzzy logic properties according to his experi-
ence; in the second, some sophisticated method is used [39]; and ﬁnally in the
third, a fuzzy supervisor is adjusted on-line by means of modern evolution-
ary algorithms [35]. If the evolutionary algorithm is used like an evolutionary
supervisor, i.e. independently of other methods, then its entire task can be
regarded as a nonlinear constrained multi-objective optimization problem. An
advantage of such a supervisor is its simplicity, universality, and of course, its
independence from a human operator. Nowadays, similar methods are applied
in intelligent sensors for the class of so-called fault-detection tasks.
2.3 Summary of chapter
This chapter gives a formulation of the adaptive control problem, and de-
ﬁnes those problems that can be solved using adaptive systems. A simpliﬁed
deﬁnition of the adaptive system suitable for the design of adaptive control
loops is also given. Adaptive control systems can be classiﬁed as adaptive
controllers based on heuristic approach, model reference adaptive systems,
and self-tuning controllers.
The principles of the self-tuning controller are described including its al-
gorithmic structure. The diﬀerences between implicit and explicit versions
of the self-tuning controller are also explained. The chapter concludes with a
summary of the historical development of self-tuning controllers and describes
further developments in this area of adaptive control.
Problems
2.1. Clarify the general term “adaptivity” and utilization of the principle for
process control.
2.2. Describe a class of technological processes suitable for the implementation
of adaptive controllers.
2.3. Design a block diagram of an MRAS for adaptive system identiﬁcation.
2.4. What are the diﬀerences between explicit and implicit versions of STC?

3
Process Modelling and Identiﬁcation for Use in
Self-tuning Controllers
Controller designs rely on knowledge of the controlled plant. Since complete
knowledge is illusory we refer to knowledge of the plant model or controlled
process model. Introducing the term model explicitly expresses the potential
diﬀerence between the reality of the controlled process and the abstract math-
ematical model (in speciﬁc ﬁelds, other types of models may also be used).
The aim of the model is to give a faithful representation of the process
behaviour. However, the term “faithful” can be interpreted in many diﬀerent
ways according to the purpose for which the model is being used. Here the
model is used to design a controller, so by the word “faithful” we mean that
the controller designed for the model under consideration will also operate
with a real plant. Because we will be dealing with several design methods it
is also necessary to take the speciﬁc faithfulness of each method into account.
Traditionally it is stated that a model can be derived from mathematical
analysis of the physical and chemical processes in the plant or from an analysis
of measured data. Adaptive control models are mainly represented by the
second approach, although, as we will point out in the section dealing with
identiﬁcation, the ﬁrst approach cannot be completely omitted.
As was shown in Section 2.2.3, an algorithm for recursive identiﬁcation of
the parameters of the process model is an indispensable part of every self-
tuning controller. Consequently, it is obvious that a model obtained by one-
oﬀprocessing of system data is not suﬃcient. Therefore, when selecting a
model for adaptive control purposes, it is necessary to consider the following
assumptions:
1. The controlled object must be identiﬁable, which means that it is possible
to model it by analysis of measurable values of input and output variables.
2. The model must be selected from the class of so-called parametric models.
These are models that can be described as a function of independent
variables (in the discrete-time version using samples of the last values
of input and output variables) and from a ﬁnite number of parameters.
Determination of these parameters is the subject of identiﬁcation.

22
3 Process Modelling and Identiﬁcation for Use in Self-tuning Controllers
3. A criterion for comparing the diﬀerences between various types of models
from the given class must be chosen. It has to be deﬁned by a relation
allowing one to compare measured data with model data. For the criterion,
it is necessary to fulﬁl the following conditions:
•
it must be a suitable measure for detecting the diﬀerences between
model and object behaviour;
•
it must be sensitive to random eﬀects and errors;
•
it must be easily computable.
The aim of this chapter is to introduce the reader to the problems of
recursive identiﬁcation of processes with regards to practical aspects of self-
tuning controllers design. Selection of the stochastic process model in ARX
and ARMAX structures is discussed brieﬂy. For practical purposes the ARX
model is chosen, and to obtain parameter estimates of the one-oﬀmodel the
least squares method is introduced. A recursive algorithm for this method
is also derived. In order to ensure numeric stability of the computation, the
square root ﬁlter is employed. Applying the equations given at the end of this
chapter, the reader can use this technique extended by directional (adaptive)
forgetting. Application of this method is illustrated by several examples.
This chapter is divided into the following sections. Section 3.1 presents
stochastic process models suitable for self-tuning controller design. The recur-
sive least squares method is discussed in detail in Section 3.2, together with
an algorithm for the advanced forgetting technique.
3.1 Stochastic Process Models
In order to create a model we seek a function f which describes the plant
output behaviour y(t) as a function of input variables, typically the controller
output u(t), and other measured variables which may aﬀect the output, such
as the disturbance variable v(t). Hence we assume
y(t) = f [u(t), v(t), t]
(3.1)
However, the output of an actual plant is rarely a deterministic function of
the measurable input variables. Disturbance appears in the plant output, rep-
resenting nonmeasurable inﬂuences on the process, variations in the operating
point, in the raw materials composition, and so on. These inﬂuences, which are
often very diﬃcult to describe accurately, are included as random – stochastic
– inﬂuences. The most generalized form of the model can then be characterized
by the relation
y(t) = f [u(t), v(t), t] + n(t)
(3.2)
where n(t) is the term describing stochastic inﬂuences.

3.1 Stochastic Process Models
23
Discrete Model
While it is necessary to work with derivatives of
measured signals when
describing a continuous-time dynamic plant, it is considerably simpler to
construct discrete models, which rely on signal values taken only at regu-
lar sampling periods T0. The digital process computer, which is used as the
control unit of the control loop, operates only in discrete time sequences
tk = kT0(k = 0, 1, 2, ...). In the case of controlling a continuous-time tech-
nological process we consider a continuous-time control object and a discrete
controller. For this control loop, in order to work properly, an interface be-
tween these diﬀerently operating dynamic systems is essential. Sample and
hold units are used as the interface. The sample part samples the continuous-
time signal in k-multiples of sampling periods T0 to produce an output signal
as an impulse sequence. The height of the impulses is equal to the value of the
input signal at the sampling instant. For control of technological processes,
zero-order hold is used almost exclusively to hold the impulse constant over
the entire sampling period. Therefore, it is necessary to use a suitable math-
ematical description to express the dynamic behaviour of components of the
control loop discretized in this way. One such description is an expression
employing the Z-transform. If G(s) is the transfer function of a continuous-
time dynamic system, then the following expression for the discrete transfer
function with zero-order holder is valid
G(z) = (1 −z−1)Z

L−1 G(s)
s

T0
(3.3)
This step transfer function (3.3) is a rational polynomial function in the com-
plex variable z. Note that the complex variable z has the meaning of the
forward time-shift operator and z−1, the backward time-shift operator, so
zy(k) = y(k + 1)
z−1y(k) = y(k −1)
The simple model structure, identiﬁcation from measured data, suitability
for the synthesis of the discrete control loop and for the description and expres-
sion of diﬀerent types of stochastic processes including disturbance modelling
are advantages of the discrete-time transfer function (3.3).
Predictor
It is possible to express a generalized discrete description of a dynamic system
as a function of the values of previously measured variables, i.e.
y(k) = f[y(k −1), y (k −2) , . . . , y (k −na) , u (k −1) , u (k −2) , . . . ,
u (k −nb) , v(k −1), v (k −2) , . . . , v (k −nd) , k] + n(k)
(3.4)
where y(k) is the value of the output variable at the k-sample interval, i.e.
at time t = kT0 (T0 is the sampling period which in Equation (3.4) is taken

24
3 Process Modelling and Identiﬁcation for Use in Self-tuning Controllers
to be one). The problem is how to specify the stochastic term more precisely.
Disturbance n(k) can be modelled as a signal originating as a noise signal with
known characteristics passing via a given ﬁlter. In the same way as the plant,
the ﬁlter can be described in relation to delayed input and output variables.
Thus we obtain
y(k) = f[y(k −1), y(k −2), . . . , y(k −na), u(k −1), u(k −2), . . . , u(k −nb),
v(k −1), . . . , v(k −nd), es(k), es(k −1), es(k −2), . . . , es(k −nc), k]
(3.5)
where es(k) is the random nonmeasurable component. If we limit ourselves to
a linear function f, it is possible to obtain the familiar ARMAX model
y(k) = −
na

i=1
aiy (k −i) +
nb

i=1
biu (k −i) +
nd

i=1
div (k −i)
+ es(k) +
nc

i=1
cies(k −i)
(3.6)
or in the probably better known form using the backward time-shift operator
z−1
A

z−1
y(k) = B

z−1
u(k) + D

z−1
v(k) + C

z−1
es(k)
(3.7)
where the individual polynomials of equation (3.7) take the form
A

z−1
= 1 + a1z−1 + a2z−2 + . . . + anaz−na
B

z−1
= b1z−1 + b2z−2 + . . . + bnbz−nb
C

z−1
= 1 + c1z−1 + c2z−2 + . . . + cncz−nc
D

z−1
= d1z−1 + d2z−2 + . . . + dndz−nd
(3.8)
However, the ARMAX model is not entirely suitable for adaptive control.
If its parameters (coeﬃcients of polynomials A, B, C, D) are the subject of
identiﬁcation using measured data we encounter the problem of identifying
coeﬃcients of the polynomial C(z−1) because the ﬁctitious noise es(k) can-
not be measured. Although there are identiﬁcation procedures (the extended
least squares method, for example) enabling C(z−1) to be identiﬁed, their
convergence is not guaranteed generally and usually is too slow. Therefore
most adaptive controller designs are based on the regression (ARX) model,
which describes the plant output according to the relation
y(k) = −
na

i=1
aiy (k −i) +
nb

i=1
biu (k −i) +
nd

i=1
div (k −i) + es(k)
(3.9)
or

3.1 Stochastic Process Models
25
D(
)
z
-1
A(
)
z
-1
1
A(
)
z
-1
B(
)
A(
)
z
z
-1
-1
v
eS
y
u
n
Figure 3.1. Block diagram of the regression model
A

z−1
y(k) = B

z−1
u(k) + D

z−1
v(k) + es(k)
(3.10)
The block diagram of this model is given in Figure 3.1.
The ARX regression model is often written in the compact vector form
y(k) = ΘT (k)φ(k −1) + es(k)
(3.11)
where
ΘT (k) = [a1, a2, . . . , ana, b1, b2, . . . , bnb, d1, d2, . . . , dnd]
(3.12)
is the vector of parameters of the model under examination and
φT (k −1) = [−y(k −1), −y(k −2), . . . , −y (k −na) ,
u(k −1), u (k −2) , . . . , u (k −nb) ,
v(k −1), v (k −2) , . . . , v (k −nd)]
(3.13)
is the data vector, so-called regressor.
Note:
The quality of the model largely depends on the sampling period and order of
the regression model. In modelling and simulation, it is necessary to fulﬁl the
rule that a discrete open-loop must maintain at least one time-delay interval
even if the delay is not included in the continuous-time transfer functions.
Otherwise algebraic loops occur when the loop is closed, which is unrealistic.
In the literature it is possible to ﬁnd cases where the polynomial B(z−1) is
considered either with the term b0 or without even for plants with no time

26
3 Process Modelling and Identiﬁcation for Use in Self-tuning Controllers
delay. If b0 ̸= 0 is considered, then controller output u(k) aﬀects y(k). If this
holds, then the controller may not use y(k) to generate u(k). On the other
hand, if a controller is used such that u(k) = f [y(k)] for plants which have
no time delay, then b0 = 0 should be fulﬁlled. It is diﬃcult to choose between
these two possibilities but it is always necessary to decide which convention
is to be used in each case. It may happen that an extra time delay occurs in
the loop. Relations (3.6)–(3.9) are used in Chapters 4 and 5, which discuss
self-tuning PID controllers and controllers derived from the algebraic theory
of control. In Chapter 6 where we discuss STCs based on the minimization
of the LQ (Linear Quadratic) criteria, the parameter vector is expanded to
include the oeﬃcient b0 and consequently, the data vector includes the variable
u(k). As a result, the variable u(k) appears in functions (3.4) and (3.5), and
also in equations (3.9) and (3.13).
The quality of the regression model used is primarily judged by the pre-
diction error, i.e. the deviation
ˆe(k) = y(k) −ˆy(k)
(3.14)
where ˆy(k) is calculated according to (3.9) with es(k) = 0. The prediction
error plays a key role in identifying the parameters for a regression model
derived from measured data. It is also important for selecting the structure
(order) of the regression model and a suitable sampling period. It must be
emphasized that for a good model, the prediction error must not only be
small but must also represent white (uncorrelated) noise with a zero mean
value.
The quality of the model is also judged by the purpose for which it is
used. The crucial model characteristics are those used for controller design.
For example, in the Ziegler–Nichols PID design method, the dominant char-
acteristic is the ultimate gain of the plant. When using the pole assignment
design method, we require the model to mirror the placement of zeros and
poles faithfully. For the LQ approach, the stochastic term is also required to
represent the disturbance under consideration.
3.2 Process Identiﬁcation
In adaptive control the task of identiﬁcation is just as important as the role
of control synthesis. Identiﬁcation for adaptive control has, of course, its own
speciﬁcation, which for most cases involves estimation of parameters for the
ARX regression model using the least squares method. Here, we can explore
reasons for this. When identifying a given plant, we should follow this proce-
dure:
1. Preparation of the identiﬁcation experiment. A choice of the most suitable
input (exciting) signal, a trade-oﬀbetween the theoretical optimal excite-
ment and that applied, with respect to the technology used. The process

3.2 Process Identiﬁcation
27
of identiﬁcation can be observed, interrupted, and the input signal can be
altered.
2. The data gathered during the experiment can be stored and subsequently
processed using various methods with diﬀerent models, ﬁltered, etc.
3. The model parameters obtained can be tested using other sampled data.
4. The identiﬁcation experiment can be repeated, possibly with the knowl-
edge gained from previous experiments.
5. Conditions for the lack of bias of the estimates can be tested or veriﬁed.
However, when performing identiﬁcation for adaptive control, it is neces-
sary to meet the following conditions:
•
The data (inputs) are generated by a feedback controller.
•
The aim of the controller is to compensate for disturbances and to stabilize
the process. These circumstances make it more diﬃcult to identify process
parameters.
•
The identiﬁcation process for adaptive control takes an inﬁnitely long time.
It is, therefore, not possible to assume constant parameter estimates. Meth-
ods to estimate time-varying parameters are essential.
•
The identiﬁcation must be functional with various operating conditions of
the plant (at relative steady-state, with disturbances, and during transi-
tions between diﬀerent states).
•
The structure of the identiﬁed model (order) cannot usually be changed
while running.
•
The identiﬁcation algorithm must be numerically reliable and suﬃciently
fast.
We see from this that the conditions governing adaptive control are not
always ideal for identiﬁcation. The conditions for obtaining unbiased estimates
cannot usually be tested, they can only be assumed in these cases. If the
assumptions are not met, adaptive control can get into diﬃculties.
3.2.1 Typical Identiﬁcation Problems in Adaptive Control
In this section we demonstrate several speciﬁc problems in identiﬁcation for
controller design.
a priori information.
When using the certainty equivalence principle, the model parameters must
approach the true values right from the start of control. This means that as the
adaptive algorithm begins to operate, identiﬁcation must be run from suitable
start-up conditions – the result of the best possible a priori information.
Their role in identiﬁcation is often underestimated. In a typical identiﬁcation
experiment their role is not, in fact, so signiﬁcant since we are only interested
in the results of identiﬁcation at the end of the experiment when suﬃcient
data have been analysed. In adaptive control, it is important to include every

28
3 Process Modelling and Identiﬁcation for Use in Self-tuning Controllers
possible piece of information in the start-up conditions for identiﬁcation, in
particular for the following reasons:
•
the parameter estimates must represent the plant right from the start of
the identiﬁcation process to prevent the designed controller from perform-
ing inadequately;
•
data obtained as the controller is operating are not always suﬃciently
informative and in this case a priori information provides the minimum
safe information.
The start-up conditions for the most commonly used identiﬁcation meth-
ods are represented by initial parameter estimates and their covariance matrix.
Although most users understand the importance of the initial parameter esti-
mates and with a certain amount of eﬀort are usually able to assign realistic
values using their technical expertise, the importance of the covariance matrix
is often neglected and it is diﬃcult to estimate. The ﬁctitious data method
[40] has proved to be a viable and relatively simple way to obtain the start-up
conditions for identiﬁcation, including more or less all a priori information.
It works by means of a model (which can be very simple) representing the
characteristic under analysis to generate the data.
For example, if we know that the plant gain equals “g”, then the corre-
sponding output value to any u(t) input value will be y(t) = gu(t). If we know
one point of the frequency characteristic, then it is possible to obtain more
data so that the input will be a sine wave with a given frequency and the
output will be a shifted sine wave with the amplitude corresponding to the
absolute value of the frequency characteristic of the plant at that point and
the shift corresponding to the phase.
Similarly, data can be generated for some other requested information. In
less complex examples data can be contrived, for more complicated cases data
can be obtained using simulation.
By processing this data in the same way as if they were real, it is possible
to obtain the start-up estimates and the covariance matrix. The problem is
that this data cannot be processed using the common approaches (for exam-
ple the least squares method). We have to take into account that individual
components of the a priori information may be partially conﬂicting, but in
any case, this information can only be considered to have a certain probabil-
ity. It may happen that the use of a great deal of data on speciﬁc information
(for example gain) leads to the information becoming so ﬁxed in the estimates
that even a large amount of real data cannot change it.
In practice, it turns out that even a very small amount of a priori infor-
mation can have a positive eﬀect on the start-up of adaptive control if it is
correctly introduced. a priori information is also important for determining
the model structure when preparing adaptive control (see Section 6.5).

3.2 Process Identiﬁcation
29
Monitoring time-variable parameters.
As was noted earlier, the assumption of constant parameters is unacceptable
when considering adaptive controllers, mainly for the following reasons:
•
the long period of operation of the controller;
•
change in the parameters of a linearized model together with alteration of
the plant’s operating point.
The issue of estimating time-variable parameters is detailed and tested in
[34] and [41]. When there is no information on the character of changes in
the parameters, the problem can be solved using a forgetting technique. The
best known is the exponential forgetting factor method where the inﬂuence
of old data on the parameter estimates and their covariance matrix decreases
exponentially. A serious drawback of this technique in an adaptive mode is
the loss of information when the process is stabilized so that the data cannot
provide enough information on it. This situation can be resolved by switching
oﬀthe identiﬁcation process, using the variable forgetting factor or other
forms of forgetting (directional, regularized) which have the ability to alter
the amount of information forgotten according to the character of the data.
3.2.2 Identiﬁcation Algorithms
It is not necessary to diﬀerentiate between coeﬃcients ai and bi in order to
identify the parameters of a regressive model; it is possible to work with the
vector of unknown parameters Θ(k) (3.12) and the regression vector φ(k −1)
(3.13).
For control purposes using a self-tuning controller we are interested only in
those methods of experimental identiﬁcation which can be performed in real
time. Recursive procedures are the most suitable for parameter estimation in
real time when the estimate in the discrete-time step k is obtained using new
data to correct an earlier estimate ˆΘ(k −1) in time k −1. The most common
recursive procedures [42, 43] to estimate the parameters of an ARX model are
the following:
•
the recursive least squares method;
•
the recursive instrumental variable method;
•
the stochastic approximation;
and to estimate the parameters of an ARMAX model:
•
the extended recursive least squares method;
•
the recursive maximum likelihood method.
The least squares method described by Ljung and S¨oderstr¨om [44] and
Strejc [45] has given the best results in estimation of the ARX model param-
eters and it will be used in the identiﬁcation procedure of all the self-tuning
controllers presented in this monograph.

30
3 Process Modelling and Identiﬁcation for Use in Self-tuning Controllers
3.2.3 Principle of the Least Squares Method
The least squares method is one of the methods of regression analysis suitable
for examining static and dynamic relations between variables of the plant
under consideration. Consider a single-input/single-output (SISO) stochastic
process described by the ARX model (3.11) and for the parameter vector
(3.12) and regression vector (3.13) assume that na = nb = n, nd = 0, i.e.
their dimension is nz = 2n
ΘT (k) = [a1, a2, . . . , an, b1, b2, . . . , bn]
(3.15)
φT (k−1) = [−y(k−1), −y(k−2), . . ., −y(k−n), u(k−1), u(k−2), . . ., u(k−n)]
(3.16)
Then the generation of output signal y(k) at individual time-moments can be
expressed using a matrix equation
y = FΘ + e
(3.17)
where the matrix F of dimension (N −n, 2n) and vectors y, e of dimension
(N −n) take the form
yT = [y (n + 1) , y (n + 2) , . . . , y (N)]
(3.18)
eT = [es (n + 1) , es (n + 2) , . . . , es (N)]
(3.19)
F =
⎡
⎢⎢⎢⎢⎢⎢⎣
−y(n)
−y(n −1) . . .
−y(1)
u(n)
. . .
u(1)
−y(n + 1)
−y(n)
. . .
−y(2)
u(n + 1) . . .
u(2)
...
...
−y(N −1) −y(N −2) . . . −y(N −n) u(N −1) . . . u(N −n)
⎤
⎥⎥⎥⎥⎥⎥⎦
(3.20)
N is the number of samples of measured input and output data. From Equa-
tion (3.17) an error can be determined as
e = y −FΘ
(3.21)
then, the following criterion is deﬁned
J = eT e = (y −FΘ)T (y −FΘ)
(3.22)
the minimum of which can be obtained by diﬀerentiating (3.22) with respect
to Θ and setting this equal to zero, i.e.
∂J
∂Θ

Θ= ˆ
Θ
= 0
(3.23)
By solving Equation (3.23) it is possible to obtain a basic matrix relation
to estimate model parameters using the least squares method

3.2 Process Identiﬁcation
31
ˆΘ=

FT F
−1
FT y
(3.24)
Equation (3.24) serves for a one-oﬀcalculation of the parameter estimates
of the process model using N samples of measured data. This calculation
places fairly high demands on the computer memory which must be large
enough to store all the measured data.
Example 3.1. Assume a plant with transfer function G(z) =
0.1997z−1
1−0.8669z−1 . As-
sume the input to the plant to be a random signal u(k) with Gaussian dis-
tribution, zero expected value and a unity variance. The response y(k) of the
system was recorded in the form of Table 3.1 and Figure 3.2. Measurement
noise was simulated by a random signal with standard deviation 0.001 af-
fecting the output from the plant. For identiﬁcation, assume a discrete ARX
model in the form y(k) = −a1y(k −1) + b1u(k −1) + es(k) and compute the
vector of process model parameter estimates ˆΘT =

ˆa1,ˆb1

and error vector e
using the least squares method. Compare the calculated vector of parameter
estimates ˆΘ at time k = 8 for sample period T0 = 1 s with the parameters
a1, b1 of the discrete transfer function G(z) =
0.1997z−1
1−0.8669z−1 .
Table 3.1. Record of input and output variables of the example system
k
1
2
3
4
5
6
7
8
u(k) -0.6918 0.8580 1.2540 -1.5937 -1.4410 0.5711 -0.3999 0.6900
y(k) 0.0071 -0.1252 0.0583 0.3070 0.0744 -0.3420 -0.1839 -0.2539
0
2
4
6
8
−2
−1
0
1
2
y, u
Time [s]
u − input
y − output
Figure 3.2. Example 3.1: record of input and output variables
The number of measured pairs of input and output values is N = 8, model
order n = 1. Data matrix F of dimension (7, 2) and data vector y of dimension
(7, 1) are in the form (see (3.18) and (3.20))

32
3 Process Modelling and Identiﬁcation for Use in Self-tuning Controllers
F =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
−0.0071 −0.6918
0.1252
0.8580
−0.0583 1.2540
−0.3070 −1.5937
0.0744 −1.4410
0.3420
0.5711
0.1839 −0.3999
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
yT = [−0.1252, 0.0583, 0.3070, −0.0744, −0.3420, −0.1839, −0.2539]
By substitution into Equation (3.24) the parameter estimates vector is
given by ˆΘT = [−0.8593, 0.2023] and using Equation (3.21) it is possible to
obtain the error vector.
eT = [0.0087, −0.0077, 0.0032, −0.0158, 0.0135, −0.0055, −0.0150]
3.2.4 Recursive Identiﬁcation Using the Least Squares Method
Equation (3.24) cannot be used to calculate the parameter estimates of the
process model for self-tuning controllers; it is necessary to use its recursive
version, which can perform the identiﬁcation in real time. Here, newly mea-
sured values are only used to correct the original estimates. This reduces the
complexity of the calculation and thus the demands placed on the computer
technology used. Recursive algorithms allow one to monitor changes in the
characteristics (parameters) of the process in real time and therefore form the
basis for self-tuning controllers.
Let a linear SISO stochastic model be described by the ARX model ex-
pressed in the form (3.11). Further, the nonmeasurable random component
es(k) is a sequence of mutually uncorrelated random signals uncorrelated also
with the process input and output. Assume furthermore that the random
variable has an expected value equal to zero and constant variance.
Now the task is to estimate recursively the unknown parameters Θ of
model (3.11) on the basis of inputs and outputs at time k, {u(i), y(i), i =
k, k−1, k−2, . . ., 0}. Therefore, the unknown vector parameter Θ of dimension
nz = 2n can be found when minimizing the criterion
Jk(Θ) =
k

i=0
e2
s(i)
(3.25)
where
es(i) = y(i) −ΘT φ(i) =

1 −ΘT 
⎡
⎣y(i)
φ(i)
⎤
⎦
(3.26)

3.2 Process Identiﬁcation
33
If we require the algorithm to be able to monitor slow changes in the pa-
rameters of the identiﬁed process, this can be achieved using the technique of
exponential forgetting. Then, it is necessary to minimize the modiﬁed criterion
Jk(Θ) =
k

i=0
ϕ2(k−i)e2
s(i)
(3.27)
where 0 < ϕ2 ≤1 is the exponential forgetting factor. Substitution of Equa-
tion (3.26) into criterion (3.27) yields
Jk(Θ) =

1 −ΘT 
V(k)
⎡
⎣1
−Θ
⎤
⎦
(3.28)
The symmetrical square matrix V(k) of type (nz + 1, nz + 1), which is
assumed to be positively deﬁnite, is given as
V(k) =
k

i=k0
ϕ2(k−i)d(i)dT (i);
d(i) = [y(i)φ(i)]T
(3.29)
and can be calculated recursively
V(k) = ϕ2V (k −1) + d(k)dT (k)
(3.30)
Now, it is clear that minimization of criterion (3.27) leads to the minimiza-
tion of quadratic form (3.28) from the point of view of the parameter vector
Θ. Minimization of (3.28) leads to equations containing V−1.
Positive semi-deﬁniteness is a necessary characteristic of the matrix V−1(k)
because it ensures the non-negativity of the minimized function, and conse-
quently, the existence of a ﬁnite minimizing argument ˆΘ(k).
In numerically adverse conditions (matrix V−1(k) is almost singular),
which is common during operation of self-tuning controllers, it is necessary to
use the version of the least squares method where the theoretically assumed
positive semi-deﬁniteness of V(k) holds also numerically. Otherwise the iden-
tiﬁcation may collapse numerically. These numerical diﬃculties motivated the
development of ﬁlters to prevent the numeric collapse of the algorithm. Re-
cently, the so-called square root ﬁlter REFIL derived by Peterka [46] was
successfully used. The basic idea of this digital ﬁltration technique is to re-
place recursive relations for the calculation of the symmetric matrix (which
must be positively semi-deﬁnite) like Equation (3.30) with a recursive calcu-
lation of the square root of this matrix. The so-called Cholesky square root
inversion matrix V(k) has been shown to work well.
G(k) =

V−1(k)
 1
2
(3.31)

34
3 Process Modelling and Identiﬁcation for Use in Self-tuning Controllers
The Cholesky square root positively semi-deﬁnite matrix V−1(k) is deﬁned
as the lower triangular matrix (3.30) which has non-negative elements on the
main diagonal and fulﬁls relation
V−1(k) = G(k)GT (k)
(3.32)
whereas the transposition of the Cholesky square root GT (k) is the upper
triangular matrix. The numerical advantage of square root ﬁltration lies in
the fact that if we recursively calculate square root V−1(k) instead of ma-
trix G(k), then whatever real matrix G(k) is, the product (3.32) is always a
positive semi-deﬁnite matrix.
Here, an alternative ﬁlter LDFIL will be used which retains the necessary
numeric characteristics of the REFIL ﬁlter but does not require the square
roots of diagonal elements to be determined and also saves on the number of
multiplications [47, 48].
Let us consider the factorization of matrix V(k) in the form
V−1(k) = L(k)D(k)LT (k)
(3.33)
where D(k) is a diagonal matrix (with positive elements) and L(k) a lower
triangular matrix with a unit diagonal (both matrices are square with dimen-
sion nz +1). This kind of factorization certainly exists for a positively deﬁnite
(regular and semi-deﬁnite) matrix. If the matrices D and L are separated into
blocks (for now the discrete time k is left out for the sake of clarity)
D =
⎡
⎣Dy 0
0 Dz
⎤
⎦
L =
⎡
⎣1
0
Lzy Lz
⎤
⎦
(3.34)
then, it is possible to rewrite criterion (3.28) as
Jk(Θ) =
⎡
⎣1
−Θ
⎤
⎦
T
(L−1)T D−1L−1
⎡
⎣1
−Θ
⎤
⎦
(3.35)
Since
L−1 =
⎡
⎣
1
0
−L−1
z Lzy L−1
z
⎤
⎦
(3.36)
is valid for the inversion of triangular matrix L, the criterion (3.35) can be
rewritten as
Jk(Θ) =
⎡
⎣1
−Θ
⎤
⎦
T ⎡
⎣1 −L−1
z Lzy
0
L−1
z
⎤
⎦
⎡
⎣D−1
y
0
0
D−1
z
⎤
⎦
⎡
⎣
1
0
−L−1
z Lzy L−1
z
⎤
⎦
⎡
⎣1
−Θ
⎤
⎦
= D−1
y
+

−Θ −Lzy
T 
L−1
z
T D−1
z L−1
z

−Θ −Lzy

(3.37)

3.2 Process Identiﬁcation
35
It is clear from the form of criteria (3.37) that only the second non-negative
addend depends on model parameters Θ on the right-hand side. The absolute
minimum is therefore obtained for
ˆΘ(k) = −Lzy(k)
(3.38)
and the value of this minimum is
Jk( ˆΘ) = D−1
y (k)
(3.39)
The solution to this problem is thus contained in the factorization of (3.33),
which can be illustrated as
L(k) =
⎡
⎣
1
0
−ˆΘ(k) Lz(k)
⎤
⎦;
D(k) =
⎡
⎣[min Jk( ˆΘ)]−1
0
0
Dz(k)
⎤
⎦
(3.40)
In conclusion to this section the algorithm of the recursive least squares
method is given, regardless of the numerical aspects mentioned above, ex-
tended to include the technique of directional (adaptive) forgetting [49, 50].
The vector of parameter estimates is updated according to the recursive
relation
ˆΘ(k) = ˆΘ(k −1) + C(k)φ(k −1)
1 + ξ(k)
ˆe(k)
(3.41)
where
ξ(k) = φT (k −1)C(k)φ(k −1)
(3.42)
is an auxiliary scalar and
ˆe(k) = y(k) −ˆΘ
T (k −1)φ(k −1)
(3.43)
is the prediction error. If ξ(k) > 0, the square covariance matrix with dimen-
sion nz is updated by relation
C(k) = C(k −1) −C(k −1)φ(k −1)φT (k −1)C(k −1)
ε−1(k) + ξ(k)
(3.44)
where
ε(k) = ϕ(k) −1 −ϕ(k)
ξ(k −1)
(3.45)
If ξ(k) = 0, then
C(k) = C(k −1)
(3.46)
The value of adaptive directional forgetting ϕ(k) is then calculated for
each sampling period as
[ϕ(k)]−1 = 1 + (1 + ρ)[ln(1 + ξ(k))]
+
 (υ(k) + 1)η(k)
1 + ξ(k) + η(k) −1

ξ(k)
1 + ξ(k)
(3.47)

36
3 Process Modelling and Identiﬁcation for Use in Self-tuning Controllers
Listing 3.1. Recursive least squares method with directional forgetting for a second-
order model – identdf.m
% Recursive least squares method with directional forgetting
% fi
- directional forgetting factor
% theta - vector of the parameter estimates
% d
- regression vector
% c
- covariance matrix
% la
- parameter lambda
% ny
- parameter eta
% ep
- prediction error
% ks
- auxiliary scalar ksi
% eps
- auxiliary parameter
% te
- parameter theta
% up
- previous controller output
% y
- current process output
% ro
- parameter ro
function
[fi,theta,d,c,la,ny,ep,te,ks,pp]=idendf(fi,theta,d,c,la,ny,up,y,ro)
% Cyclic date substitution in regression vector (1)
d(4)=d(3);
d(3)=up;
% Update of parameter estimates
ep=y-theta’*d;
%prediction error
ks=d’*c*d;
pp=(c*d/(1+ks))*ep;
theta=theta+pp;
% Update of identification variables
if ks>0
eps=fi-(1-fi)/ks;
c=c-c*d*d’*c/(inv(eps)+ks);
end
la=fi*(la+ep*ep/(1+ks));
ny=fi*(ny+1);
te=ep*ep/la;
fi=1/(1+(1+ro)*(log(1+ks-ks/(1+ks)+ks*(ny+1)*
te/(1+ks+te)/(1+ks))));
% Cyclic date substitution in regression vector (2)
d(2)=d(1);
d(1)=-y;
where
η(k) = ˆe2(k)
λ(k)
υ(k) = ϕ(k) [(υ(k −1) + 1]

3.2 Process Identiﬁcation
37
λ(k) = ϕ(k)

λ(k −1) +
ˆe2(k)
1 + ξ(k)

(3.48)
are auxiliary variables. Although the question of a priori information in the
selection of start-up conditions has been discussed in Section 3.2.1, it proved
better to choose the following conditions for the start of the algorithm: ele-
ments of the main diagonal of the covariance matrix Cii(0) = 103, start value
for the directional forgetting factor ϕ(0) = 1, λ(0) = 0.001, υ(0) = 10−6,
ρ = 0.99. The initial estimates for the vector ˆΘ(0) are chosen according to a
priori information and this selection has caused no problems in the majority
of simulation and laboratory tests on self-tuning controllers.
The relations given above can directly be programmed as an M-function
in the Matlab R
⃝system without taking the numeric aspects into account,
i.e. without the use of numeric ﬁlters.
The algorithm in Listing 3.1 is the implementation of the recursive least
squares method with directional forgetting factor for a second-order model
and in Listing 3.2 is an example for the initial procedure.
Listing 3.2. Initialization of identiﬁcation for a second-order model – inide.m
% Initialization of identification
function [d,theta,c,ro,fi,la,ny,u]=inide
d=zeros(4,1);
% regression vector
theta=[0.1; 0.2; 0.1; 0.2];
% parameter estimates
c=1000*eye(4);
% covariance matrix
% Initialization of auxiliary parameters
ro=0.99; fi=1; la=0.001; ny=0.000001; u=0;
0
2
4
6
8
−1
−0.5
0
Parameter estimates
 Prediction error
Time [s]
a1 estimate
b1 estimate
e
Figure 3.3. Example 3.2. Parameter estimates and prediction error
Example 3.2. Use the data listed in Table 3.1 of Example 3.1 for recursive
identiﬁcation of the process employing the least squares method with the

38
3 Process Modelling and Identiﬁcation for Use in Self-tuning Controllers
ﬁrst-order regression model y(k) = −a1y(k −1) + b1u(k −1) + es(k). For pa-
rameter estimates, choose the forgetting factor ϕ(k) = 1. Plot a graph showing
evolution of the parameter estimates and prediction error ˆe(k). Compare the
results with those obtained in Example 3.1.
It is clear that according to (3.10)–(3.12) it is possible to describe the
regression model in the vector form:
y(k) = ΘT (k)φ(k −1) + es(k) = [a1 b1]
⎡
⎣−y(k −1)
u(k −1)
⎤
⎦+ es(k)
Equations (3.41)–(3.48) were used for recursive computation of the parameter
estimates with forgetting factorϕ(k) = 1. The procedure identbasic.m (see
Matlab R
⃝Listing 3.3) was used for solving this example.
Figure 3.3 shows the process model parameter estimates and the prediction
error. The converged vector of parameter estimates at step k = 8 is ˆΘT (8) =
[−0.8556, 0.2020]. The results obtained match those from Example 3.1.
Example 3.3. Assume the block scheme of an ARX model as shown in Fig-
ure 3.1 neglecting the measurable error variable, i.e. v(t) = 0. The process is
modelled by the continuous-time transfer function
G(s) = Y (s)
U(s) = B(s)
A(s) =
2.5(0.8s + 1)
(4.2s + 1)(0.5s + 1)
Identify this system by a recursive least squares method and determine dis-
crete model parameter estimates for the sampling period T0 = 0.25 s. For
excitation of the model by signal u(t) use a random signal generator with
variance limits deﬁned from 0 to 1. Generate the noise es(t) by Matlab R
⃝
function rand with variance 10e−5. Display the evolution of model parameter
estimates and prediction error for the time interval ⟨0; 5⟩s.
0
1
2
3
4
5
−2
−1
0
1
Parameter estimates
Time[s]
a1 estimate
a2 estimate
b1 estimate
b2 estimate
Figure 3.4. Example 3.3. Evolution of parameter estimates

3.2 Process Identiﬁcation
39
Listing 3.3. Basic recursive least squares algorithm – identbasic.m
% Basic recursive least squares method
% N - number of identification steps
% c - covariance matrix
% d - regression vector
% theta - vector of the parameter estimates
% ep(k)- prediction error
% eps - auxiliary parameter
% y(k)
- process output
% u(k)
- controller output
% input variables
u=[-0.6918 0.858 1.254 -1.5937 -1.441 0.5711 -0.3999 0.69];
% output variables
y=[0.0071 -0.1252 0.0583 0.307 -0.0744 -0.342 -0.1839 -0.2539];
N=8;
theta= [0 0]’;
% initial vector of parameter estimates
c = 1000*eye(2);
% initial covariance matrix
for k=2:1:N
d = [ -y(k-1)
u(k-1) ]’; % new data vector
ep(k)= y(k)-theta’*d;
eps = d’*c*d;
theta = theta + (c*d*ep(k)) / (1+eps);
% theta update
c = c-(c*d*d’*c)/(1+eps); % new covariance matrix
a1(k)=theta(1);
b1(k)=theta(2);
end
figure;
plot(a1,’k’);
hold on;
plot(b1,’b’);
plot(ep,’r’);
xlabel(’time steps’)
ylabel(’theta, e’)
The parameter estimates evolution is shown in Figure 3.4 and the pre-
diction error in Figure 3.5. The parameter estimates at time 5 s have the
following values:
ˆa1(5) = −1.5557;
ˆa2(5) = 0.5781;
ˆb1(5) = 0.2074;
ˆb2(5) = −0.1547.
It is possible to compare the results obtained by recursive identiﬁcation
with the discrete transfer function of the plant for the sampling period T0 =
0.25 s, which is given as
G(z) =
0.2125z−1 −0.1557z−2
1 −1.5487z−1 + 0.5715z−2

40
3 Process Modelling and Identiﬁcation for Use in Self-tuning Controllers
Listing 3.4. Function for identiﬁcation of an n-order model – identnorder.m
% Recursive least squares method for an n-order model
% theta - vector of the parameter estimates
% d
- regression vector
% c
- covariance matrix
% ep
- prediction error
% y
- new process output
% u
- new controller output
% na
- order of the denominator
% nb
- order of the numerator
function [theta,d,c,ep]=identnorder(na,nb,theta,d,c,u,y)
d = [ y d(1:na-1) u
d(na+1:na+nb-1) ]’; % new data vector
ep= y-theta’*d;
eps = d’*c*d;
theta = theta + (c*d*ep) / (1+eps);
% theta update
c = c-(c*d*d’*c)/(1+eps); % new covariance matrix
end;
0
1
2
3
4
5
−1
−0.5
0
0.5
1
Prediction error
Time[s]
Figure 3.5. Example 3.3. Evolution of prediction error
Example 3.4. Assume the block scheme of the ARX model as shown in Fig-
ure 3.1, with the following diﬀerence: set the measurable error variable to
v(t) = sin t and the polynomial D(s) = 0.6s + 2. Choose the same conditions
for the experiment as in Example 3.3 but implement the identiﬁcation in the
following way:
1. In the ﬁrst case, use the discrete regression model structure (3.8) for the
identiﬁcation. Neglect the measurable error variable v(t), so the parameter
estimates d1, d2 need not be computed (but you still have to consider that
the input of the model is aﬀected by errors).
2. In the second case, use the discrete regression model structure (3.8) for
the identiﬁcation and consider the measurable error variable v(t), so the
parameter estimates d1, d2 have to be computed.
Plot graphs of model parameter estimates and the prediction error for the time
interval ⟨0; 10⟩s. Compare the prediction error in both experiments according

3.2 Process Identiﬁcation
41
to the quadratic criterion in the form
Se = 1
N
N

k=1
[ˆe(k)]2
where N is the number of identiﬁcation steps.
Solution (a). The parameter estimates evolution and the prediction error
are shown in Figure 3.6. The estimated transfer function of the process is
G(z) =
0.2147z−1−0.2344z−2
1−1.9330z−1+0.9428z−2 .
0
2
4
6
8
10
−2
−1
0
1
2
Parameter estimates
Time[s]
a1 estimate
a2 estimate
b1 estimate
b2 estimate
0
2
4
6
8
10
−1
−0.5
0
0.5
1
Prediction error
Time[s]
Figure 3.6. Example 3.4. Evolution of parameter estimates and prediction error –
solution (a)
Criterion: Sea = 1
N
N

k=1
[ˆe(k)]2 = 0.0015
Solution (b). The parameter estimates evolution and the prediction error
are shown in Figure 3.7. The estimated transfer function of the process is
G(z) =
0.2129z−1−0.1546z−2
1−1.5439z−1+0.5670z−2 .
Criterion: Seb = 1
N
N

k=1
[ˆe(k)]2 = 0.0015
In both cases, the prediction error converges to zero and values of the cri-
teria are the same, however, in solution (b) the estimated parameters converge
to the correct values of the process. In solution (a) the sine wave is identiﬁed
as part of the plant and the estimated transfer function is close to the stabil-

42
3 Process Modelling and Identiﬁcation for Use in Self-tuning Controllers
0
2
4
6
8
10
−2
−1
0
1
Parameter estimates
Time[s]
a1 estimate
a2 estimate
b1 estimate
b2 estimate
0
2
4
6
8
10
−0.2
0
0.2
0.4
Parameter estimates
 Prediction error
Time[s]
d1 estimate
d2 estimate
e
Figure 3.7. Example 3.4. Evolution of parameter estimates and prediction error –
solution (b)
ity bound. Therefore, it is obvious that inclusion of parameters d1, d2 into the
ARX model results in better accuracy of the identiﬁcation experiment.
Example 3.5. Figure 3.8 shows a scheme for the laboratory model CE 108 –
coupled drives apparatus (made by TecQuipment Ltd., Nottingham, United
Kingdom). This model can be used for design and laboratory testing of control
algorithms in real-time conditions. With this model, it is possible to design
Drive
motor 1
Drive
motor 2
Continuous
flexible belt
Simulated
workstation
Jockey pulley
Jockey arm for
tension measurement
Figure 3.8. Example 3.5. Schematic diagram of the laboratory model CE 108

3.2 Process Identiﬁcation
43
controllers for regulating the required speed and tension of the material on
machines equipped with spools or cylinders. Examples of such devices are
machines used for the production of ﬁbres, paper, plastic foil, pipes, cables
etc. In these technologies, the material passes a workstation which measures
its speed and tension (the output variables of the process). These two variables
are dependent on each other and can be controlled by changing the speed of
motors placed in front and beyond the workstation (input variables of the
process). On the laboratory model, the measurement of these variables is
done by leading a ﬂexible belt through three pulleys. The angular velocities
of the two lower pulleys correspond to the rotation speeds of the motors. The
third pulley is placed on a moving arm (“jockey arm”) and plays the role of a
workstation, measuring the speed and tension of the belt. Two drive motors’
control the speed and tension of the rubber belt. The drive motors rotation
speed range is 0–3000 revolutions/minute, which corresponds to the input
power voltage 0–10 V. The tape tension measurement is done indirectly by
the change of angle of the jockey arm ±10◦, which corresponds to the output
voltage of ±10 V. The ampliﬁers of the drive motors are bi-directional and
allow control of the motor rotation in both directions.
G11
G12
G22
u2
G21
u1
y1
y2
Figure 3.9. Example 3.5. Block diagram of the TITO system
From the description above it is clear that we are dealing with a two-
input/two-output (TITO) system which can be described by the schema
shown in Figure 3.9. The transfer matrix of the TITO system, which describes
the input/output relations, can be written in the form:
G(z) = Y(z)
U(z) =
⎡
⎣G11(z) G12(z)
G21(z) G22(z)
⎤
⎦
where U(z) is the vector of input variables (voltage inputs to the motors) and
Y(z) is the vector of controlled variables (tension and the tape speed).

44
3 Process Modelling and Identiﬁcation for Use in Self-tuning Controllers
The laboratory model shows quite nonlinear behaviour with strong in-
teractions between the individual variables. The static characteristics of the
model were measured to determine the system linearity ranges. All the char-
acteristics show nonlinear behaviour, namely the belt tension characteristic is
nonlinear over the whole range due to belt oscillations. The static character-
istics are shown in Figure 3.10. The variable y1 denotes speed and variable y2
the tension of the belt. The variables u1 and u2 are the voltage inputs of the
left and right drive motors.
0
2
4
6
8
10
0 
2
4
6
8 
10
0
0.2
0.4
0.6
0.8
1
u1 / V
u2 / V
y1
0
2
4
6
8
10
0 
2
4
6
8
10
0
0.2
0.4
0.6
0.8
1
u1 / V
u2 / V
y2
Figure 3.10. Example 3.5. Static characteristics of the laboratory model CE 108
Because the scope of this book is limited to single-input/single-output
adaptive control systems, we show an example of experimental recursive iden-
tiﬁcation of submodel G11, which represents the relation y1 = f(u1), i.e. the
belt speed y1 as a function of the left drive motor rotation speed u1. Measure-
ments were implemented in the following way: the voltage of the right drive
motor u2 was kept constant and a random signal with Gaussian distribution
was superposed on the working points of the input voltage u1 in the following
ranges (see Figure 3.11):
u11(k) = 0.2 + es(k);
for k ∈⟨0; 40⟩s

3.2 Process Identiﬁcation
45
0
20
40
60
80
100
120
−0.5
0
0.5
1
u1,y1
Time[s]
u1 
y1 
Figure 3.11. Example 3.5. Input and output signal of the identiﬁed object
u12(k) = 0.4 + es(k);
for k ∈⟨41; 80⟩s
u13(k) = 0.6 + es(k);
for k ∈⟨81; 120⟩s
The initial vector of the parameter estimates was chosen ad hoc in the form
ˆΘT (0) = [0.1; 0.2; 0.3; 0.4], the sampling period T0 = 0.2 s and the structure
of a second-order model was chosen as a discrete transfer function
G(z) =
b1z−1 + b2z−2
1 + a1z−1 + a2z−2
The parameter estimates evolution over individual intervals are shown in Fig-
ure 3.12.
Experiment results. In the ﬁrst interval, t ∈⟨0; 40⟩, the discrete transfer
function with parameter estimates in step t = 40 s has the form
G(z) =
−0.0472z−1 + 0.2000z−2
1 −0.4661z−1 + 0.1415z−2
Figure 3.13 shows the calculated step response for the ﬁrst interval.
In the second interval, t ∈⟨41; 80⟩, the discrete transfer function with
parameter estimates in step t = 80 s has the form
G(z) =
−0.0225z−1 + 0.1825z−2
1 −0.6150z−1 + 0.0763z−2
and the calculated step response is presented in Figure 3.14.
In the third interval, t ∈⟨81; 120⟩, the discrete transfer function with
parameter estimates in step t = 120 s has the form

46
3 Process Modelling and Identiﬁcation for Use in Self-tuning Controllers
0
10
20
30
40
−2
−1
0
1
Time [s]
Parameter estimates
a1 estimate
a2 estimate
b1 estimate
b2 estimate
40
50
60
70
80
−2
−1
0
1
Time [s]
Parameter estimates
a1 estimate
a2 estimate
b1 estimate
b2 estimate
80
90
100
110
120
−2
−1
0
1
Time [s]
Parameter estimates
a1 estimate
a2 estimate
b1 estimate
b2 estimate
Figure 3.12. Example 3.5. Evolution of parameter estimates
G(z) =
0.002z−1 + 0.1190z−2
1 −0.6757z−1 −0.0261z−2
and the calculated step response is shown in Figure 3.15.
From Figure 3.12 it is clear, that in the second interval the parameter
estimates ˆa1, ˆa2 are changing slowly, therefore, it is possible to suppose that
a controller with ﬁxed parameters will not guarantee satisfactory control over
the whole range needed by the laboratory model. From the individual discrete
transfer functions and step responses in Figures 3.13–3.15 it is obvious that

3.2 Process Identiﬁcation
47
0
0.5
1
1.5
2
2.5
3
0
0.1
0.2
0.3
0.4
0.5
Step response
Time[s]
Figure 3.13. Example 3.5. Step response in the ﬁrst interval
the process has nonminimum phase behaviour. Therefore the use of a suit-
able adaptive controller is one possibility for ensuring the control quality of
the laboratory model. The design and veriﬁcation of the TITO digital self-
tuning controller for this laboratory model is presented in [51] and a delta
modiﬁcation of this controller in [52].
Example 3.6. Consider a continuous stirred tank reactor (CSTR) with ﬁrst-
order consecutive exothermic reactions according to the scheme A
k1
→B
k2
→C
and with a perfectly mixed cooling jacket (see Figure 3.16).
Using the usual simpliﬁcations, the model of the CSTR can be described
by four nonlinear diﬀerential equations (see [53]).
dcA
dt = −
Qr
Vr
+ k1

cA + Qr
Vr
cAf
dcB
dt = −
Qr
Vr
+ k2

cB + k1cA + Qr
Vr
cBf
dTr
dt =
hr
(ρcp)r
+ Qr
Vr
(Trf −Tr) +
AhU
Vr(ρcp)r
(Tc −Tr)
dTc
dt = Qc
Vc
(Tcf −Tc) +
AhU
Vc(ρcp)c
(Tr −Tc)
0
0.5
1
1.5
2
2.5
3
0
0.1
0.2
0.3
0.4
0.5
Step response
Time[s]
Figure 3.14. Example 3.5. Step response in the second interval

48
3 Process Modelling and Identiﬁcation for Use in Self-tuning Controllers
0
0.5
1
1.5
2
2.5
3
0
0.1
0.2
0.3
0.4
0.5
Step response
Time[s]
Figure 3.15. Example 3.5. Step response in the third interval
Qr , cA ,
cB , Tr
Qr , cAv , Trv
Qc , Tc
Qc , Tcv
Vc , Tc
Ah
U
Vr , cA ,
cB , Tr
 
 
 
Figure 3.16. Example 3.6. Continuous stirred tank reactor
with initial conditions cA(0) = cs
A, cB(0) = cs
B, Tr(0) = T s
r , and Tc(0) = T s
c .
Here, t is the time, c denote concentrations, T are temperatures, V stands for
volumes, ρ are densities, cp denote speciﬁc heat capacities, Q are volumetric
ﬂow rates, Ah stands for the heat exchange surface area and U is the heat
transfer coeﬃcient. The subscripts are (.)r for the reactant mixture, (.)c for
the coolant, (.)f for feed (inlet) values and the superscript (.)s for steady-state
values.
The reaction rates and the reaction heat are expressed as
kj = k0j exp
−Ej
RTr

,
for j = 1, 2
hr = h1k1cA + h2k2cB
where k0 are pre-exponential factors, E denote activation energies and h
stands for reaction enthalpies. The values of all parameters, feed values and
steady-state values are given in Table 3.2.
For the identiﬁcation purposes, the process output and input are deﬁned as

3.2 Process Identiﬁcation
49
Table 3.2. Parameters, inlet values and initial conditions
Vr = 1.2 m3
Qr = 0.08 m3 min−1
Vc = 0.64 m3
Qs
c = 0.03 m3 min−1
ρr = 985 kg m−3
cpr = 4.05 kJ kg−1K−1
ρc = 998 kg m−3
cpc = 4.18 kJ kg−1K−1
A = 5.5 m2
U = 43.5 kJ m−2 min−1 K−1
k10 = 5.616 × 1016 min−1 E1/R = 13477 K
k20 = 1.128 × 1018 min−1 E2/R = 15290 K
h1 = 4.8 × 104 kJ kmol−1 h2 = 2.2.104 kJ kmol−1
cAf = 2.85 kmol m−3
cBf = 0 kmol m−3
Tf = 323K
Tcf = 293 K
cs
A = 0.1649 kmol m−3
cs
B = 0.9435 kmol m−3
T s
r = 350.19 K
T s
c = 330.55 K
y(t) = Tr(t) −T s
r ;
u(t) = 10Qc(t) −Qs
c
Qsc
These expressions enable one to obtain variables of approximately the same
magnitude.
Solve the system of nonlinear diﬀerential equations in the Simulink R
⃝
environment. Generate step changes +20%, +100% and -30% around the basic
steady-state value of the volumetric ﬂow rate Qs
c = 0.03 m3 min−1 with
additive discrete noise. For RLSM use a second-order discrete model
G(z) =
b1z−1 + b2z−2
1 + a1z−1 + a2z−2
with a sampling period T0 = 2.5 minutes. Plot graphs of the evolution of
model parameter estimates and prediction error for the volumetric ﬂow rate
step change +20% in time interval ⟨0; 120⟩min.
1. Step change +20% – Qs
c = 1.2 × 0.03 = 0.036 m3 min−1.
The z-transfer function: G(z) =
−0.0348z−1−0.0211z−2
1−1.6020z−1+0.6351z−2
2. Step change +100% – Qs
c = 2 × 0.03 = 0.06 m3 min−1.
The z-transfer function: G(z) =
−0.0345z−1−0.0179z−2
1−1.5546z−1+0.5859z−2
3. Step change −30% – Qs
c = 0.7 × 0.03 = 0.021 m3 min−1.
The z-transfer function: G(z) =
−0.0391z−1−0.0239z−2
1−1.5889z−1+0.6252z−2
The evolution of parameter estimates and prediction error for the volumetric
ﬂow rate +20% in time interval ⟨0; 120⟩min are shown in Figure 3.17

50
3 Process Modelling and Identiﬁcation for Use in Self-tuning Controllers
0
20
40
60
80
100
120
−2
−1
0
1
Parameter estimates
a1 estimate
a2 estimate
b1 estimate
b2 estimate
Time[min] 
0
20
40
60
80
100
120
−1
−0.5
0
0.5
1
Prediction error
Time[min] 
Figure 3.17. Example 3.6. Evolution of parameter estimates and prediction error
– step change +20%
3.3 Summary of chapter
A recursive identiﬁcation algorithm is an indispensable part of the algorith-
mic structure of a self-tuning controllers. The objective of this chapter was
not the exact analysis of recursive identiﬁcation methods but only an intro-
duction to this area from the viewpoint of utilization of these methods in
adaptive controllers. Therefore attention was paid only to the identiﬁcation
method most widely used in practical applications – least squares method for
estimation of parameters of a simple stochastic (regressive ARX) model. For
better comprehension of recursive identiﬁcation methods, the theoretical dis-
cussion was complemented with several examples. One example is solved using
data obtained by measurements on laboratory nonlinear TITO model CE 108
– coupled drive apparatus. For further practice in this area, an example of a
analytic nonlinear model of the continuous stirred tank reactor is presented.
For this analytic model, an adaptive continuous-time controller was designed
and veriﬁed by simulation (see [53]).
Problems
3.1. Consider the discrete system

3.3 Summary of chapter
51
y(k) = −a1y(k −1) −a2y(k −2) + b1y(k −1) + b2y(k −2) + es(k)
where b1 = 0.2, b2 = 0.15, a2 = −0.7 and a1 = 1.5 for 0 < k < 100; a1 = 0.75
for k ≥100.
Make graphs of the evolution of parameter estimates and prediction error
for time interval ⟨0; 200⟩.
3.2. Consider a second-order continuous-time system
y′′(t) + a1y′(t) + a0y(t) = b1u′(t) + b0(t)u(t)
with a1 = 1.5, a0 = 0.5, b1 = 0.8 and b0(t) = sin t. Use Matlab R
⃝/Simulink R
⃝
for simulation of this time-varying system and plot graphs of the evolu-
tion of discrete parameter estimates and prediction error for sampling period
T0 = 0.4 s.
3.3. Consider a second-order continuous-time system
y′′(t) + a1(t)y′(t) + a0y(t) = b0u(t)
where a1(t) = cos t, a0 = 1.2, and b0 = 0.5. Use Matlab R
⃝/Simulink R
⃝for
simulation of this time-varying system and make graphs of the evolution of
parameter estimates and prediction error for sampling period T0 = 0.4 s.
3.4. Consider “interacting tanks in series process” (see Figure 3.18). The
model of the process is described by two diﬀerential equations
F1
dh1
dt = q0 −q1
F2
dh2
dt = q1 −q2
The inlet q1 depends on the diﬀerence between the liquid heights and
outlet ﬂow rate q2 depends on the liquid height in the second tank as
q1 = k1

h1 −h2
q2 = k2

h2
The values of all parameters, feed values and steady-state values are given
in Table 3.3.
Solve the system of diﬀerential equations in the Simulink R
⃝environment.
Identify the system by the recursive least squares method. Change the set
point from the steady-state to the values q0 = 0.02 m3 min−1; q0 = 0.04 m3
min−1; q0 = 0.08 m3 min−1. For generation of the input signal u(t), add a
suitable discrete generator of random noise. Use a second-order discrete model
structure for recursive identiﬁcation.

52
3 Process Modelling and Identiﬁcation for Use in Self-tuning Controllers
q0
h1
q1
q2
h2
Figure 3.18. Problem 3.4 Interacting tanks in series process
where
t
time [min]
h1, h2 heights of liquids in the ﬁrst and second tanks [m]
q0
inlet volumetric ﬂow rate to the ﬁrst tank [m3 min−1]
q1
inlet volumetric ﬂow rate to the second tank [m3 min−1]
q2
outlet volumetric ﬂow rate from the second tank [m3 min−1]
F1, F2 cross-section area of the tanks [m2]
Table 3.3. Parameters, inlet values and initial conditions
F1 = 0.0177 m2
qs
0 = 0.03 m3 min−1
F2 = 0.0314 m2
hs
1 = 0.36 m
hs
2 = 0.25 m
k1 = 0.0905 m5/2 min−1
k2 = 0.06 m5/2 min−1

4
Self-tuning PID Controllers
This chapter is devoted to PID digital controllers and how they may be made
self-tuning.
Experience in implementing adaptive control systems indicates that users
in industrial practice are mistrustful of adaptive digital controllers based on
the optimal theory of automatic control, mainly because understanding the
algorithms involved requires in-depth knowledge of the theory of automatic
control. The common factor to all successful applications of this kind of adap-
tive controller has been the availability of a suﬃciently qualiﬁed person in
industrial practice both capable of absorbing the results of scientiﬁc research
and well acquainted with the technology in use. It is for this reason that we
have been able to see a trend over recent years towards research into simple
adaptive controllers which can be implemented not only by theoreticians in
the ﬁeld of adaptive control but also by users in industrial applications.
It is clear that the vast majority of controllers (around 90%) currently
used in industry are PID type controllers because, provided these are well ad-
justed, they show very good control results. They are also user-friendly in that
they are simple, generally well known and easy to implement. Provided the
parameters have been well chosen they are capable of controlling a signiﬁcant
portion of continuous-time technological processes.
The use of continuous-time PID controllers has a tradition going back
many years. A number of adjustment approaches and methods of optimization
have been developed in which users and manufacturers of control technology
have wide practical experience. Understandably they wish to put this knowl-
edge to work along with their experience with analogue techniques and apply
this also to digital control systems.
The aim of this chapter is to acquaint the reader with problems of dis-
cretization of continuous-time PID type controllers. A survey of particular
digital PID type algorithms which are suitable for design of their self-tuning
versions is also proposed. Especially emphasized are the additional versions of
PID type controllers which have a number of advantages from the point of view
of their practical implementation. The proposed algorithms are partly taken

54
4 Self-tuning PID Controllers
from literature and partly originally designed by the authors. The chapter is
accompanied by suitable examples of the design of some controllers and some
simulation examples are also included to demonstrate the dynamic properties
of controllers using suitable control models.
This chapter is divided into the following sections. In Section 4.1 meth-
ods of discretizing continuous-time PID controllers are described, while in
Section 4.2 some modiﬁcations are discussed to improve the dynamic charac-
teristics of controllers. Nonlinear PID controllers are the subject of Section 4.3.
Section 4.4 gives a brief discussion of the issue of selecting the sampling period,
and 4.5 deals with the industrial applications of PID controllers. Section 4.6
provides a survey of self-tuning controllers; 4.7 gives a detailed analysis of cer-
tain algorithms used in self-tuning PID controllers, with simulation examples
of some types of controllers. Finally, in Section 4.8 simulations are performed
in Matlab R
⃝environment using Simulink R
⃝oriented toolbox.
4.1 PID Type Digital Controllers
The ideal, textbook version of a continuous-time PID controller is usually
given in the form
u(t) = KP
⎡
⎣e(t) + 1
TI
t

0
e(τ)dτ + TD
de(t)
dt
⎤
⎦
(4.1)
or in the form
u(t) = r0e(t) + r−1
t

0
e(τ)dτ + r1
de(t)
dt
(4.2)
where e(t) = w(t) −y(t) and the conversion between (4.1) and (4.2) is
KP = r0
TI = KP
r−1
TD = r1
KP
(4.3)
where u(t) is the controller output, i.e. manipulated variable y(t) denotes
the process output, i.e. controlled variable e(t) stands for the tracking error
and w(t) is the reference signal, i.e. set point. The parameters of the PID
controller (4.1) are as follows: proportional gain KP , integral time constant
TI, and derivative time constant TD.
The parameters for controller (4.2) are
gain r0, integral constant r−1, and derivative constant r1. Since (4.1) is the
most widely used in practice, and the rules for tuning the PID controller have
been deﬁned for parameters KP , TI and TD, this is the form we prefer to deal
with.
Using the Laplace transform it is possible to convert Equation (4.1) into
the form

4.1 PID Type Digital Controllers
55
U(s) = KP

1 +
1
TIs + TDs

E(s)
(4.4)
where s represents the Laplace transform operator. From Equation (4.4) we
can determine the transfer function of the PID controller
GR(s) = U(s)
E(s) = KP

1 +
1
TIs + TDs

(4.5)
To obtain a digital version of a continuous-time PID controller we must
discretize the integral and derivative components of Equation (4.1), see [54].
When the sampling period T0 is small and noise from the process output signal
is eﬀectively ﬁltered out, the simplest algorithm is obtained by replacing the
derivative with a diﬀerence of the ﬁrst-order (two-point, backward diﬀerence)
de
dt ≈e(k) −e(k −1)
T0
= ∆e(k)
T0
(4.6)
where e(k) is the error value at the k-th moment of sampling, i.e. at time
t = kT0. The easiest way of approximating the integral is by simple summing
so that we approximate the continuous-time function by sampling periods T0
of the constant function (step function, rectangle). Using the so-called forward
rectangular method (FRM) yields
t

0
e(τ)dτ ≈T0
k

i=1
e(i −1)
(4.7)
so that the equation for a discrete PID controller has the form
u(k) = KP

e(k) + T0
TI
k

i=1
e(i −1) + TD
T0
[e(k) −e(k −1)]

(4.8)
If the continuous-time signal is discretized recursively using the step func-
tion with the help of the so-called backward rectangular method (BRM),
instead of relation (4.7) we obtain relation
t

0
e(τ)dτ ≈T0
k

i=1
e(i)
(4.9)
and Equation (4.8) changes to form (4.10) which is most often used in the
formal description of a digital PID controller
u(k) = KP

e(k) + T0
TI
k

i=1
e(i) + TD
T0
[e(k) −e(k −1)]

(4.10)

56
4 Self-tuning PID Controllers
If, instead of rectangular methods (4.7), (4.9), we use the more accurate
trapezoidal method (TRAP) to calculate the integral, where we replace the
continuous-time signal with straight line sections, i.e.
t

0
e(τ)dτ ≈T0
k

i=1
e(i) + e(i −1)
2
(4.11)
then the equation for the digital PID controller will take the form
u(k) = KP

e(k) + T0
TI

e(0) + e(k)
2
+
k−1

i=1
e(i)

+ TD
T0
[e(k) −e(k −1)]

(4.12)
The individual methods of discretizing the integral of continuous-time error
e(t) at points e(kT0), where k = 0, 1, 2, . . . are illustrated in Figure 4.1.
t
e t( )
t
e t( )
t
e t( )
e( )
1
e( )
3
e( )
2
T0
3T0
2T0
0
e( )
1
e( )
3
e( )
2
T0
3T0
2T0
0
e( )
1
e( )
3
e( )
2
T0
3T0
2T0
0
4T0
e( )
4
4T0
4T0
e( )
4
e( )
4
BRM
FRM
TRAP
Figure 4.1. Methods of discretizing the integral component
As far as changes in error are concerned, where sampling is suﬃciently
fast, there is no signiﬁcant diﬀerence between integral approximations and
consequently between relations (4.8), (4.10) and (4.12), therefore (4.10) is the
one most often used. Because the whole value of controller output u(k) is
calculated, usually in terms of the drive position, these algorithms are also
known as absolute or position algorithms for a PID controller. Equations (4.8),
(4.10) and (4.12) are called nonrecurrent algorithms, where all previous error
values e(k −i), i = 1, 2, . . . , k have to be known, to calculate the integral and

4.1 PID Type Digital Controllers
57
with it the controller action. In real industrial applications this is impractical
largely because it would be necessary to keep all previous error values in the
memory of the control computer. In the form they are given, Equations (4.8),
(4.10) and (4.12) are also unsuitable with regards to changes in the controller
parameters – a change in TI or KP leads to an instant change of the entire
value of the integral component resulting in an overload of the whole calcula-
tion of the error, which is not acceptable. Recurrent algorithms are, therefore,
more suitable for practical use. It is either necessary to calculate recurrently
integral (4.9) – see algorithms (4.27) and (4.28) below – or controller output
value u(k) from a previously recorded value u(k −1) plus correction incre-
ment ∆u(k). Alternatively, for a PID controller with digital output, just the
increment (change) ∆u(k) may be calculated. Algorithms which calculate in-
crement (change) ∆u(k) are referred to as incremental or velocity algorithms.
By subtracting Equation (4.10), which we obtained from the backward rect-
angular method, for steps k and k −1, we obtain the recurrent relation
u(k) = ∆u(k) + u(k −1)
(4.13a)
∆u(k) = KP

e(k) −e(k −1) + T0
TI
e(k)
+ TD
T0
[e(k) −2e(k −1) + e(k −2)]

(4.13b)
and in general form
u(k) = q0e(k) + q1e(k −1) + q2e(k −2) + u(k −1)
(4.14)
Controller parameters q0, q1 and q2 in Equation (4.14) are given in Table 4.1.
Using (4.14) it is possible to calculate the step response of PI and PID type
digital controllers (Figures 4.2 and 4.3). For the step response of a digital PID
controller to approach that of a continuous-time PID controller the following
must be valid (for positive controller gain q0 > 0):
•
the second sample of controller output u(1) < u(0);
•
constant positive growth of the step response (from k = 2);
•
straight line linear growth must intersect positively with ordinate axis u(k)
(for a continuous-time PID controller this value is KP = r0).
This corresponds to limits on values q0, q1 and q2
q0 > 0
q1 < −q2
−(q0 + q1) < q2 < q0
(4.15)
Value q0 determines the size of ﬁrst action u(0) for the step-change of the
reference signal w and the initial zero steady-state.
Recurrent relation (4.14) obtained from (4.10) (BRM) can also be written
in the form
u(k) = KP

e(k) −e(k −1) + T0
TI
e(k)
+ TD
T0
[e(k) −2e(k −1) + e(k −2)]

+ u(k −1)
(4.16)

58
4 Self-tuning PID Controllers
 
u(k)
q0
q0+q1
k
0
Figure 4.2. Step response of a digital PI controller
 
u(k)
k
q0+q1+q2
(q0-q2)
q0
(2q0+q1)
0
Figure 4.3. Step response of a digital PID controller
which is essentially form (4.13a). The advantage of form (4.14) is the simple
structure of the algorithm but it has the disadvantage of having a less trans-
parent link between the individual components. Comparing (4.14) and (4.16)
yields
KP = q0 −q2
TD
T0
= q2
KP
T0
TI
= q0 + q1 + q2
KP
(4.17)
To continue, we give the incremental algorithm deduced from Equation
(4.8) (FRM)
u(k) = KP

e(k) −e(k −1) + T0
TI
e(k −1)
+ TD
T0
[e(k) −2e(k −1) + e(k −2)]

+ u(k −1)
(4.18)
The incremental algorithm derived from Equation (4.12) (TRAP) has the
form
u(k) = KP

e(k) −e(k −1) + T0
2TI
[e(k) + e(k −1)]
+ TD
T0
[e(k) −2e(k −1) + e(k −2)]

+ u(k −1)
(4.19)

4.1 PID Type Digital Controllers
59
and the individual equation parameters for form (4.14) are once again shown
in Table 4.1.
Table 4.1. Parameters of a digital incremental PID controller
Controller
Parameters
FRM
BRM
TRAP
q0
KP

1 + TD
T0

KP

1 + T0
TI + TD
T0

KP

1 +
T0
2TI + TD
T0

q1
−KP

1 −T0
TI + 2TD
T0

−KP

1 + 2TD
T0

−KP

1 −
T0
2TI + 2TD
T0

q2
KP
TD
T0
KP
TD
T0
KP
TD
T0
From Table 4.1 it follows that incremental controller parameters q0, q1 and
q2 expressed in the form of Equation (4.14) are functions of proportional gain
KP , time constant integral TI and derivative TD, sampling period T0 and the
method of discretization, i.e. the functional relations
qi = f(KP, TI, TD, T0);
for i = 0, 1, 2
(4.20)
are valid.
Some equations for digital PID controllers can also be derived using trans-
formation formulas which allow us to transfer continuous-time description
from the Laplace transform to discrete transfer functions. These transforma-
tion formulas take the form
s = 1 −z−1
z−1T0
s = 1 −z−1
T0
s = 2
T0
1 −z−1
1 + z−1
(4.21)
where z−1 is the backward time-shift operator, i.e. x(k −1) = z−1x(k). Using
the second formula in (4.21) it is possible to obtain controller (4.16) from
transfer function (4.5). The use of the third formula of (4.21) to obtain further
modiﬁcations of a digital PID controller is explained in Section 4.2.1.
Niederlinski [55] has discussed the properties of positional (absolute) and
incremental controllers with regard to their practical implementation, but the
conclusions reached apply mainly to the automation and computer technology
available at the time of writing.
The approximation of the derivation term can also be performed by re-
placing the derivation by a four-point mean diﬀerence using the relation
∆e(k) = 1
6[e(k) + 3e(k −1) −3e(k −2) −e(k −3)]
(4.22)
The position algorithm obtained using the BRM to discretize the integral
component then has the form

60
4 Self-tuning PID Controllers
u(k) = KP

e(k) + T0
TI
k
i=1
e(i)
+ TD
6T0
[e(k) + 3e(k −1) −3e(k −2) −e(k −3)]

(4.23)
and the incremental algorithm takes either form
u(k) = KP

e(k) −e(k −1) + T0
TI
e(k)
+ TD
6T0
[e(k) + 2e(k −1) −6e(k −2) + 2e(k −3) + e(k −4)]

+u(k −1)
(4.24)
or
u(k) = q0e(k)+q1e(k−1)+q2e(k−2)+q3e(k−3)+q4e(k−4)+u(k−1) (4.25)
where
q0 = KP

1 + T0
TI
+ TD
6T0

q1 = −KP

1 −TD
3T0

q2 = −KP
TD
T0
q3 = KP
TD
3T0
q4 = KP
TD
6T0
(4.26)
Instead of position algorithm (4.10) it is possible to use a component form
of the control algorithm, where the controller output is determined by the sum
of the individual components and only the last value of the integral component
is retained in the memory. In this case the algorithm takes the form
u(k) = uP (k) + uI(k) + uD(k)
(4.27)
where
uP (k) = KP e(k)
uI(k) = KP
T0
TI
k

i=1
e(i) = uI(k −1) + KP
T0
TI
e(k)
uD(k) = KP
TD
T0
[e(k) −e(k −1)]
(4.28)
are the controller’s proportional, integral and derivative components.
The advantage of the component form is its transparency when setting the
gain of the individual controller components. However, it is necessary to limit
integral component uI in the algorithm – see Section 4.5.2.
The deﬁnition of initial values uI(0) for (4.28) and u(0) for algorithms
(4.16), (4.18), (4.19) and (4.27) and the diﬀerences in the behaviour between
these formally congruent algorithms are treated in Sections 4.5.1 and 4.5.2.
Also compared are various PID algorithms from the point of view of the
impact on controller output u(k) if parameters KP, TI and TD change.

4.2 Modifying Digital PID Controllers
61
From the point of view of nearly the same dynamics, the approximation of
a continuous-time PID controller is only suitable where the sampling period
T0 is short compared with system dynamics. For a greater value of T0, the
simple transfer of parameters KP , TI and TD from a continuous-time to a
digital controller, even in conjunction with period T0, is unacceptable and
all parameters must be set for the given sampling period T0. If we take into
account that for the same sampling period T0 roughly the same energy  u
is put into the system in order to regulate it, we can permit a signiﬁcantly
larger control output at higher levels of sampling, and therefore greater gain
KP , than we can for low levels of sampling. Generally, it is possible to state
that with an increase in sampling period T0, gain KP nonlinearly falls, term
KP T0/TI slightly increases, while term KP TD/T0 grows smaller.
4.2 Modifying Digital PID Controllers
While Equation (4.1) represents an idealization of a real PID-like controller
behaviour, computation of the control law for digital PID-like controllers pro-
ceeds according to a corresponding diﬀerence equation. This fact causes some
problems with practical implementation of these controllers, since in contradis-
tinction to continuous-time controllers, here natural suppression of large and
rapid changes of control errors and controllers outputs (manipulated) vari-
ables is not enabled. In a particular realization of the continuous-time PID-
like function a delay appears, which is omissible owing to the dynamics of the
controlled process and it is not necessary to take it into account. But this delay
operates both like a natural noise ﬁlter (namely its higher frequency elements)
and delaying factor during step changes of reference signals. Ideal step changes
of signals for continuous-time are unrealizable anyway. That is why the risk of
rapid changes of manipulated variables connected with dynamical straining of
an actuator is not so high in continuous-time control loops as in discrete con-
trol loops where discrete controllers get and accept step changes of reference
signals as changes of variable in a program. The variable acquires a new value
of the controller output according to Equation (4.14). Large changes of the
manipulated variable in a discrete controller follow large changes of control
error. Then the contribution of the proportional and derivative parts to the
general function of a PID-like controller is signiﬁcant. Since the controlled
variable is inﬂuenced by noise, samples of the controlled variable are aﬀected
by random faults. The changes of control error cause not only changes of con-
troller output variable but also changes given by the faulty process output
variable.
The negative eﬀect of the large and rapid changes of control error can be
suppressed by incorporation of speciﬁc technical or software precautions ahead
of the algorithm for computation of the discrete PID function (preprocessing of
e(k)). Another possibility is modiﬁcation of the default discrete PID algorithm

62
4 Self-tuning PID Controllers
so that some of the ﬁltering or delaying precautions are incorporated directly
in the algorithm.
4.2.1 Filtering the Derivative Component
There is often interference in the measured value of the process output y(t)
from relatively high frequency noise. If a derivative component is used in
the controller, the derivation of the signal aﬀected by noise, which has, in
addition, been approximated by a simple diﬀerential of the ﬁrst-order, may
cause inappropriate and unsuitably large changes in the controller output. The
derivative component is limited, therefore, either by using a limiter or, more
often, a ﬁrst or second-order ﬁlter which decrease gain at higher frequencies.
When using a ﬁrst-order ﬁlter (single capacity ﬁlter) with time constant
Tf the derivative component takes the form
D(s) = KP
TDs
Tfs + 1E(s)
Tf = TD
α ;
α ∈⟨3; 20⟩
(4.29)
Usually α = 10 is selected which means that the D-component ﬁlter has a
time constant ten times smaller than the derivative time constant. Discretiza-
tion (4.29) using backward rectangular integration (the second transformation
formula of (4.21)) gives the relation
d(k) = TDd(k −1) + KP TDα[e(k) −e(k −1)]
TD + αT0
(4.30)
Using the Tustin transformation (the third transformation formula of
(4.21)) yields
d(k) = (2TD −αT0)d(k −1) + 2KPTDα[e(k) −e(k −1)]
2TD + αT0
(4.31)
Both approximations (4.30) and (4.31) have the form
d(k) = ad(k −1) + b[e(k) −e(k −1)]
(4.32)
but with diﬀering a, b coeﬃcients. Approximations (4.30) and (4.31) are stable
for all TD > 0 situations. However in (4.31) the coeﬃcient is a < 0 when TD <
αT0/2 which can cause unwanted oscillation during calculation especially if
TD ≪T0. Only (4.30) provides good results for all values of TD.
It is possible to use relation (4.30) or (4.31) in previous formulas (for ex-
ample in (4.27)) in which the existing expression for the derivative is replaced.
Another complex method of obtaining a digital PID controller with D-
component ﬁltration will be presented. The transfer function of the continuous-
time version of this type of PID controller has the form
GR(s) = U(s)
E(s) = KP

1 +
1
TIs +
TDs
Tfs + 1

(4.33a)

4.2 Modifying Digital PID Controllers
63
where Tf is the time constant of the derivative component ﬁlter. We use
the third transformation formula of (4.21) (the Tustin approximation) to dis-
cretize (4.33a). The discrete form of controller transfer function (4.33a) is
given by
GR(z) = U(z)
E(z) = Q(z−1)
P(z−1)
(4.33b)
where
Q(z−1) = q0 + q1z−1 + q2z−2
P(z−1) = 1 + p1z−1 + p2z−2
(4.34)
The equation for the controller with ﬁltration of the D-component then
takes the form
u(k) = p1u(k −1) + p2u(k −2) + q0e(k) + q1e(k −1) + q2e(k −2)
(4.35)
where the parameters of controller (4.35) are given by
p1 =
−4Tf
T0
2Tf
T0 + 1
p2 =
2Tf
T0 −1
2Tf
T0 + 1
q0 =
KP + 2KP
Tf+TD
T0
+ KP T0
2TI ( 2Tf
T0 + 1)
2Tf
T0 + 1
q1 =
KP T0
2TI
−4KP
Tf +TD
T0
2Tf
T0 + 1
q2 =
Tf
T0 (2KP −KP T0
TI
) + 2 KP TD
T0
+ KP T0
2TI
−KP
2Tf
T0 + 1
(4.36)
4.2.2 Supression of Large Changes in the Controller Output
Instead of using error e(k) in the derivative component, we can use process
output y(k) to decrease the larger changes in the controller output resulting
from set point changes. In this case algorithm (4.16) (and similarly (4.18) and
(4.19)) has the form
u(k) = KP

e(k) −e(k −1) + T0
TI
e(k)
+TD
T0
[2y(k −1) −y(k) −y(k −2)]

+ u(k −1)
(4.37)
In this way we can achieve a signiﬁcant decrease in the controller output at
the moment of a set point change and then a decrease in the limitation on the
controller output and the movements of the ﬁnal control element into an area

64
4 Self-tuning PID Controllers
of nonlinearity. Usually, the rise time of the process output is slowed down and
overshoot is signiﬁcantly decreased while the settling time remains roughly the
same. The adjustment of the parameters for controller (4.37) to changes in
control and disturbance diﬀers little from the adjustment of a controller using
error in the derivation.
Changes in controller output amplitude decrease further if the reference
signal w(k) is substantial only in the integral component.
u(k) = KP

−y(k) + y(k −1) + T0
TI
[w(k) −y(k)]
+TD
T0
[2y(k −1) −y(k) −y(k −2)]

+ u(k −1)
(4.38)
which is the well-known relation given by Takahashi [56].
Changing the process output to the reference signal is then mainly reg-
ulated by the integral component. This can, however, be a fairly slow pro-
cess. To decrease larger changes in the controller output (as a result of the
reference change) it is therefore useful to modify values w(k) with a single-
capacity ﬁlter, or a change limiter, or to employ term βw(k) −y(k) instead of
term w(k) −y(k), in the proportional component, where weighting factor β
is determined by the dynamics of the system and is chosen from the interval
0 < β < 1. In [57] and [58] it was proved that a good characteristic of the
process dynamics is the so-called normalized gain κ, which is deﬁned as the
product of the gain of the controlled process KS and critical proportional gain
KPu, where the control loop is on the point of stability
κ = KSKPu
(4.39)
Then it is possible to change PID controller parameters KP , TI and TD
in relation to the size of normalized gain κ. In order to reduce the maximum
overshoot of the process output, the reference signal w in the proportional
component (4.39) can be weighted using the factor β so that a change of the
normalized gain κ is achieved. The proportional part of controller (4.27) then
takes the form
uP (k) = KP [βw(k) −y(k)]
(4.40)
As a result, the following continuous-time controller algorithm was devel-
oped which, as well as using weighting factor β, also makes use of single-
capacity ﬁlter (4.29) to ﬁlter the derivative component.
u(t) = KP
⎡
⎣βw(t) −y(t) + 1
TI
t

0
e(τ)dτ −TD
dyf
dt
⎤
⎦
(4.41)
where yf(t) is the process output ﬁltered by ﬁrst-order transfer function
Yf(s)
Y (s) =
1
1 + s TD
α
(4.42)

4.3 Nonlinear PID Controllers
65
where the ﬁlter constant α is selected from the interval according to (4.29).
The equation for a digital incremental PID controller, taken from equations
(4.41) and (4.42) after replacing the derivation of the ﬁrst diﬀerential and the
approximation of the integral with the trapezoidal method, has the form given
(see [59])
u(k) = uPI(k) + uD(k)
(4.43)
where
uPI(k) = KP[y(k −1) −y(k)] + KPT0
2TI
[e(k) + e(k −1)]
+βKP[w(k) −w(k −1)] + uPI(k −1)
(4.44)
uD(k) = KP
TDα
TD + T0α[y(k −1) −y(k)] +
TD
TD + T0αuD(k −1) (4.45)
4.3 Nonlinear PID Controllers
Real control loops often contain various nonlinearities in the ﬁnal control el-
ements as well as in the controlled system. Further nonlinear elements are
sometimes added to improve the dynamic behaviour and/or decrease the in-
ﬂuence of current nonlinear elements. Therefore, we will give some reasons
for introducing nonlinear PID controllers and nonlinearities into the control
loops:
•
The nonlinearity of the controlled system (gain and/or time constants –
a controller with nonlinear gain is useful for controlling the level of liquid
in a spherical tank, for example, where the set point is not constant but
subject to large changes; the same changes of ﬂow cause diﬀerent changes
in level depending on the current level).
•
The nonlinear characteristics of the ﬁnal control element, usually a valve
(for example ﬂow or pressure depends on the valve position) – the nonlinear
transformation of the controller output is used (inverse nonlinearity to the
nonlinearity of the valve).
•
Measurement noise in the controlled variable.
•
Nonlinearities in the actuator, mainly dead zone, hysteresis and saturation.
•
Attempts to improve the dynamic behaviour of the control loop aﬀected
by great and small disturbances.
The eﬀect of nonlinear elements depends also on their position in the con-
trol loop. Static nonlinear elements like saturation or insensitivity in feedback
have in fact an “inverse” characteristic then in the direct path. Hysteresis
(dead band) worsens control responses and results in oscillating responses
with amplitude dependent on hysteresis band. Controlled variables (process
outputs) usually have higher overshoots after set point changes compared with

66
4 Self-tuning PID Controllers
u
y
Figure 4.4. Dead zone with limitations
u
y
Figure 4.5. Static nonlinearity
the linear case. The eﬀect of process output noise can be diminished by in-
troducing insensitivity, i.e. a nonlinear element, dead zone, into the controller
output or into the controller input (see Figure 4.4). Dead zone as well as insen-
sitivity caused by signal quantization decrease the eﬀect of small-amplitude
noise and can damp down control responses. Similarly, the nonlinearity illus-
trated in Figure 4.5 gives a range of controller output over which the actuator
is unable to react and may signiﬁcantly damp the actuator. However such in-
sensitivity can lead to (permanent) nonzero control error and also to (perma-
nent) oscillations if a PI controller is used – the integral component varies up
to band level and then control action is applied. The limitation of controller
output included in a controller algorithm or limitation of the control error
cause slower control responses in general, but not always (see Figure 4.14 in
Section 4.5.2). Limitation outside of a controller and not considered in the con-
troller algorithm (existing in the actuator, ﬁnal control element etc.) results
in complicated control problems – increase of the integral term (“wind-up”
eﬀect), overshoots of process output etc.
The use of a nonlinear controller with variable gain has a similar eﬀect to
introducing insensitivity into the controller output and, for the sake of clarity,
we give it here in its continuous-time version
u(t) = KPf(e)
⎡
⎣e(t) + 1
TI
t

0
e(τ)dτ + TD
de(t)
dt
⎤
⎦
(4.46)
where

4.3 Nonlinear PID Controllers
67
Nonlinear controller 
disturbance 
disturbance 
Linear controller 
Figure 4.6. Linear and nonlinear PID controller with variable gain according to
Equation (4.46)
f(e) = K0 + (1 −K0)|e(t)|
(4.47)
where K0 is selected at interval ⟨0; 1⟩. When K0 = 1 the controller is lin-
ear; when K0 approaches zero the proportional term will be proportional to
the square of the error and the controller will be insensitive to small errors.
This may cause oﬀset of control error. The controller shown may be useful
in systems where gain changes in indirect proportion to amplitude, or where
the controlled variable is aﬀected by noise which causes problems in using
the derivative term. In comparison with linear controllers, the nonlinear con-
troller improves the response of controlled variable y(t) to set point changes
(Figure 4.6), but makes the response y(t) worse when signiﬁcantly aﬀected
by disturbance. This is because the eﬀects of the disturbance result in slow
drift of the controlled variable away from the set point, where a nonlinear
controller has a smaller gain than a linear one.
e
f(e)
e
f(e)
e
f(e)
Figure 4.7. Various forms of nonlinear gain f(e)
Function f(e) can also be deﬁned by sections as shown in Figure 4.7. A
common variation on the nonlinear controller is the controller with variable
gain, deﬁned by function f(e) as follows:

68
4 Self-tuning PID Controllers
f(e) = 1
for e > eu
f(e) = 1
for e < el
f(e) = K0
for e ∈⟨el; eu⟩, K0 ≥0
(4.48)
The output value for K0 = 0 at points el, eu will not change and this may
signiﬁcantly damp the actuator.
Another more generalized variant – see Figure 4.8 – is a controller with
gain which changes linearly according to signal v(t) outside ﬁxed limits vl, vu;
inside these limits gain is constant and equal to one. The total controller gain
is Kp = Kf(v). Then the relation for gain can be written in the form
f(v) = 1 + (K1 −1)(vl −v)/10
for v < vl,
(4.49a)
f(v) = 1 + (K2 −1)(v −vu)/10
for v > vu,
(4.49b)
f(v) = 1
for v ∈⟨vl; vu⟩
(4.49c)
where K1 and K2 are the values of f(v) at points 10% from the appropriate
limit vl (from the left) or vu (from the right). Value v(t) lies in the range
⟨0; 100⟩[%], and the total controller gain for v ∈⟨vl; vu⟩is Kp = K.
 
 
                                                 
1 
0            vd-10  vd      vh    vh+10    100 
f(v) 
K1 
K2 
v 
Figure 4.8. Gain characteristic f(v) – (4.49)
The following can be considered as signal v(t):
•
input into the system;
•
process output (controlled variable);
•
control error;
•
controller output;
•
external variables;

4.4 Choice of Sampling Period
69
•
in some cases, a logic signal.
In a similar way it is possible to introduce a nonlinear change into the
integral constant.
The dynamic systems with variable system gain deﬁned by any function of
f(v) are often controlled by nonlinear PID controllers with “gain scheduling”;
the controller gain approximating inverse function f −1(v) is deﬁned by several
segments.
Note
The controllers with variable gain outlined here are often, but inaccurately,
referred to as controllers with adaptive gain in some alternative publications.
Every gain change (switch) in general results in a step in the controller
output u(k). The size of the step strictly depends on the applied version of PID
algorithm – compare the proportional term in the incremental algorithm (4.16)
based on diﬀerence of e(k), e(k −1) and in the component-form algorithm
(4.27) and (4.28) where only value e(k) is used.
It is occasionally problematic to set the parameters of gain functions
(4.47)–(4.49 for the nonlinear controllers given here when they are used to
control almost linear systems. Note that the introduction of nonlinear param-
eters leads to controllers with variable structure. Such controllers were popular
and in use in previous years. From this point of view the controllers with gain
functions (4.47)–(4.49) etc. are only a poor approximation of controllers with
variable structure. ˇSindel´aˇr [60, 61], for example, has performed an analysis
on this as well as the conditions for switching over on the basis of control error
and its derivation.
The control responses may be improved if not function f(e) but a function
of the weighted sum of control error and its derivation is used in (4.48).
4.4 Choice of Sampling Period
The calculation time for digital controllers is usually between a hundredth of a
second and one second. Although the sampling period is one of the controller
parameters, the shortest period is often used so that, eﬀectively, these digital
PID controllers may be considered to be continuous-time (more precisely:
when control is applied to a system for which the controller period is T0 ≪Ta,
where Ta, denotes the dominant time constant of the system). Nevertheless it
is wise to be aware of the inﬂuence the choice of period T0 has on control and
of the diﬀerence compared to a continuous-time controller.
In general, shortening sampling period T0 improves the quality of control,
the ability to react to disturbances and causes a discrete digital controller to
resemble a continuous-time one. However, it also increases the demands on
the actuator (step changes in controller output are generated with period T0)
and there is usually an increase in the system’s energy consumption, judged

70
4 Self-tuning PID Controllers
according to the quadratic criteria
Ju =

u2(t)dt
(4.50)
Lengthening sampling period T0 often slows the control process slightly but
decreases change in the manipulated variable and the value of criteria (4.50)
signiﬁcantly. In particular, lengthening sampling period T0 should lower gain
value KP – see reference in Section 4.1. However, shortening the sampling pe-
riod can cause deterioration of control to the point of instability even for small
controller gain. This is due to the fact that discretization of the controlled sys-
tem causes a shift from a so-called minimal phase system to a nonminimum
phase system which has unstable zeros (that is the roots of the discrete trans-
fer function numerator of the controlled system are outside the unit circle in
the z complex plane). This fact is demonstrated by, for example, Roberts [62]
who optimized the parameters of a digital PID controller using ITAE criteria
J =
∞

0
t|e(t)|dt
(4.51)
for a system approximated by the transfer
G(s) =
KS
T1s + 1e−τds
(4.52)
The dependence of the gain K = KSKP (KS is the system gain) and of
the value of criterion J on the sampling period (ratio T0/T1 ) and on the size
of the time delay (ratio τd/T1) is illustrated in Figure 4.9 (from Roberts [62]).
Only the PID controller gain KP for integral time constant TI = 5T0 and
derivative time constant TD = 0.8T0 for step changes of the reference signal
are optimized. When choosing the sampling period it is recommended to use:
ωuT0 < π/4 where ωu is the critical frequency at which an open-loop fre-
quency characteristic ﬁrst crosses a negative semi-axis. Figure 4.9 shows that
the controller is very sensitive, especially at high sampling rate, i.e. when the
ratio T0/T1 is low and the time delay small (ratio τd/T1 < 0.5). It is neces-
sary to remember to include “artiﬁcial” time delay caused by the controller
calculation time in the overall time delay.
The choice of the sampling period is mainly aﬀected by:
1. The required standard of control, which is given by the demands on the
controlled variable response, the control error band, and the response and
changes in the manipulated variable.
2. The dynamics of the controlled system, characterized, for example, by the
value of the approximating time constant and time delay according to
(4.52).

4.4 Choice of Sampling Period
71
3. The disturbance frequency spectrum. It follows from the behaviour of the
control dynamic factor S(ω) (Figure 4.10), deﬁned as the ratio between
the amplitudes of closed and open-loop frequency transfer functions (that
is the ratio between a controlled and an uncontrolled loop) that the eﬀect
of low-frequency disturbance on control is suppressed, high-frequency dis-
turbance passes through almost without control and medium frequency
is magniﬁed (see Figure 4.10). If control is to suppress disturbances up
to the frequency level ωmax, then the Shannon–Kotelnik theorem must be
used to select the sampling period T0
T0 ≤
π
ωmax
(4.53)
4. The calculation time demands and by the capabilities of the computer
employed, the number of control loops, etc.
5. Demands on operator intervention, thus limiting the maximum sampling
period T0.
6. The properties of the actuator – in drives this means dead zone, response
time and permitted number of switches per hour (limits the minimum
sampling period T0); similarly for contactors, circuit breakers, relays, etc.
A summary of the rules for choosing the sampling period has been taken
from Isermann [54] and is shown in Table 4.2.
Table 4.2. Summary of the rules for choosing the sampling period
Criteria to determine the sam-
pling period T0
Determining relation
Notes
T0 =  1
8 ÷
1
16
 1
f
T0 =  1
4 ÷ 1
8

τd
Systems with dominant
time delay (transport lag)
Takes 15% longer settling time
than a continuous-time control
circuit with PID controller
T0 = (0.35 ÷ 1.2)Tu
0.1 ≤Tu/T0 ≤1.0
Compensation of disturbances up
to ωmax as in continuous-time
control circuit
T0 =
π
ωmax
|GP (jωmax)| = 0.01 ÷ 0.1
Simulation results
T0 =  1
6 ÷
1
15

T95
Comments:
f – natural frequency of the closed loop [Hz],
τd – time delay,
Tu – apparent dead time,
T95 – 95% of the step-response settling time,
GP – system transfer function

72
4 Self-tuning PID Controllers
 
Figure 4.9. Dependence of optimum gain K = KSKP and minimum criteria ITAE
(4.51) on the sampling period of a digital PID controller (from Roberts [62])
Considering the speed of presentday microprocessors, the most signiﬁcant
limit placed on T0 is, in fact, point 6, but again we should remember that from
the point of view of “dulciﬁcation” a controlled and manipulated variable,
longer sampling may be better than shorter sampling.
The choice of sampling period is also aﬀected by the precision of the A/D
and D/A converters used, the length of the computer words (see Section 4.5.3);
and the size of controller time constants TI and TD also play an important
role. If the ratio TD/T0 is too large, the controller will react more to noise
causing pulsing (steps in the controller output), and thus oscillation in the
process output. Shinskey [63] recommends the ratio

4.5 PID Controllers for Operational Use
73
S()
2
max
LF bound
HF bound
Figure 4.10. Behaviour of the control dynamic factor
TD/T0 = 0.17ωn/T0 ∈⟨10; 20⟩
which leads to T0 ∈⟨0.008ωn; 0.017ωn⟩where ωn is the natural frequency of
the system. If T0/TI is too small, a permanent control error will occur as a
result of the limited precision of the converter, computer and rounding errors
(see Section 4.5.3).
4.5 PID Controllers for Operational Use
The continuous-time PID controllers given in the available reference works
are almost exclusively in form (4.1), (4.2), or (4.4) and, after discretization,
in form (4.8), (4.10), (4.12) or in form (4.16), (4.18), (4.19) and (4.27). These
relations are often mechanically programmed which usually results in the con-
troller not operating well in practice. The reasons behind the malfunction are
the unproved but tacit assumption (though unsatisﬁed) of the linearity of the
control system, limitless controller output, zero initial steady state, zero initial
set point, error-free calculation, etc.
The real simple control loop shown in Figure 4.11 includes actuator SS,
with nonlinearities such as limits on position and speed, dead zone etc., actu-
ator controller RS (ﬁnal ampliﬁer – P controller), and own controlled system
SH (with nonlinearity of the control device) controlled by PID controller RH.
The RH controller output, that is the calculated manipulated variable u(k),
is the set point for the inner control loop (servo-loop), i.e.
wS = uH = u
(4.54)
The measured manipulated variable um of controller RH is the input for
SH, which is simultaneously the output of the inner loop, i.e.
um = umH = yS
(4.55)

74
4 Self-tuning PID Controllers
RS
RH
SS
SH
y
H
w
H
w =u
S
H
y =u
S
mH
manual control
v
Figure 4.11. Simple real control loop
4.5.1 Initial Conditions and Controller Bumpless Connection
The digital PID controller described in component form, Equation (4.27), can
be written with a separate integral component uI in the form
uI(k) = uI(k −1) + r−1e(k)
(4.56)
u(k) = r0e(k) + uI(k) + r1[e(k) −e(k −1)]
(4.57)
where
r0 = KP
r−1 = KP T0
TI
r1 = KP TD
T0
(4.58)
or, for incremental controller (4.16), in the form
∆uI(k) = r−1e(k)
(4.59)
∆u(k) = r0[e(k) −e(k −1)] + ∆uI(k)
+r1[e(k) −2e(k −1) + e(k −2)]
(4.60)
Then, the controller output is calculated using relation
u(k) = u(k −1) + ∆u(k)
(4.61)
Here, for the sake of simplicity, the form with parameters r0, r−1 and r1 is
used.
The initial values which are missing in (4.1) and therefore also in (4.56)–
(4.61) are
e(−1) = e(0)
y(−1) = y(0)
w(−1) = w(0)
u(0)
(4.62)

4.5 PID Controllers for Operational Use
75
and particularly
uI(0) = r−1
0
−∞
e(τ)dτ = u(0) −r0e(0) −r1[e(0) −e(−1)]
u(0) ≈um(0)
(4.63)
where u(0) indicates the initial (steady-state) value of the controller output
(equal to the measured value um) which corresponds to the initial steady-state
value of the process output y(0) (time k = 1 is regarded as the ﬁrst step in
the controller calculation). Value u(0) can be considered to be the reference
value related to the output of controller (4.57) or (4.61).
If the controller does not contain the integral component (i.e. parameter
r−1 = 0 and it is a P, PD or D type controller), then Equation (4.57) must
contain either the term which, for uniformity of notation, will be referred to
as uI, that is
uI(k) = uI(0) = u(0) −r0e(0) = const
(4.64)
or term (4.63) which also includes the derivative component.
Term (4.64) acts as a bias and is usually nonzero, i.e. in static systems the
steady-state value of the controlled variable corresponds to the steady-state
nonzero value of the controller output. Term (4.64) is often referred to as
“bias” or “manual reset”, whereas the integral term, which changes automat-
ically according to the control error, is known as “reset” or “automatic reset”.
The commonly assumed zero value in (4.62) and the absent or zero-value term
(4.63) or (4.64) leads to the incorrect calculation of u(k) and step u(1).
To ensure bumpless transition when switching from manual to automatic
control, controller output RH – see Figure 4.11 – should track the value xk,
otherwise deﬁned as
x(k) =

wS(k)
... slave loop set point (manual control signal)
um(k)
... measured manipulated variable
(4.65)
Note
Set point wS for manual control is often given directly from the controller
under manual control; controller output is then u = wS. In the loop shown in
Figure 4.11, variable um equals the output from the ﬁnal control element or
actuator position yS.
Incremental controller (4.59), (4.60) with output ∆u(k) is bumpless be-
cause it only uses the diﬀerence ∆u(k) from the current status. This is partic-
ularly useful when controlling the actuator directly from the digital controller
outputs.
For incremental controller (4.59)–(4.61) with output u(k)
u(k −1) = x(k)
(4.66)

76
4 Self-tuning PID Controllers
Output from position controller (4.56), (4.57) is set according to (4.65).
Unlike incremental controller (4.59)–(4.61), the initial value of integral term
uI(k −1) must still be deﬁned for (4.56) and bias (4.64) for any controller
without integral term
uI(k −1) = x(k) −r0e(k −1)
(4.67)
which means that, on connection, u(k) changes mostly by the derivative term
(for nonzero value r1).
Provided the control error is nonzero and roughly constant when switching
from manual to automatic control, position controller (4.57) with its integral
term will alter the output using primarily the integral term (so as to achieve
zero control error), which means sometimes quite a slow process (due to the
size of parameter r−1 and control error). In this case a controller without an
integral term (P, PD) leaves the output (nearly) unchanged.
If we introduce integral term (4.56) with regard to the controller output,
as was often done in analogue controllers, i.e.
uI(k −1) = u(k −1) = x(k)
(4.68)
then, at the moment controller (4.57) is connected, there will be a step in
output u(k) corresponding to the size of control error e(k) at that instant (in
such a case it follows that it is advisable to connect the controller at a point
where the control error is more or less zero).
We have tacitly assumed that set point w, ﬁxed before the controller is
connected, does not change at the instant of connection, that is that w(k) =
w(k −1).
The shortcoming of method (4.67) is that the control error is removed
slowly after connection, whereas the disadvantage of (4.68) is that it results
in step u(k). Sometimes set point tracking is used in bumpless controller
connection, where w(j) = y(j) and therefore e(j) = 0, for j = k −1, k. The
connection is bumpless for both (4.67) and (4.68), but has the disadvantage
that, after connection, you must enter the real set point for the controlled
variable. One possible solution is to switch between set points at the instant
of connection, which can be implemented using a set point switch with two
contacts. The controlled variable is connected to the ﬁrst contact (for set point
tracking) whereas the pre-ﬁxed set point is connected to the second contact
through a ﬁrst-order lag or rate limiter. When the controller is switched from
manual to automatic control, the switch instantaneously moves from the ﬁrst
to the second contact (i.e. e(k−1) = 0, but e(k) is, already, generally nonzero).
Controller (4.57) then behaves in the same way on connection as it does in
operation and a change in the set point will occur.
Comparing position controller (4.56)–(4.57) with incremental controller
(4.59)–(4.61) it follows that:
•
The initial value for the integral term or bias uI does not have to be
calculated for an incremental controller. The change in controller output

4.5 PID Controllers for Operational Use
77
at the instant of connection is mainly determined by the diﬀerence between
e(k) and e(k −1). As a result, the control error is compensated slowly just
as in the case of a position controller which includes uI according to (4.67).
The solution is to switch set points at the instant of connection.
•
Both controllers are equal in value if the following relation still holds:
uI(k) = u(k −1) −r0e(k −1) + r−1e(k) −r1[e(k −1) −e(k −2)] (4.69)
Generally uI(k) ̸= u(k −1). Equation (4.69) is valid only for the linear
range of the controller, i.e. if the value of controller output u(k) is not
limited by upper or lower boundaries.
•
The value of integral component uI may only be limited at upper or lower
boundaries for a position controller.
Note
If a measured value is to be used as the tracking signal it should ﬁrst be
ﬁltered.
4.5.2 Limiting the Integral Term and Wind-up of Controller
Let the cascade control loop in Figure 4.12 be PID controlled with a slave
(auxiliary) and master (main) controller (RP , RH). The plant SP and SH is
contaminated by disturbances vP and vH causing bias of variables yS = umH
and yP = umH. Therefore the actuator yS may be at a stop (yS = yS
minoryS =
yS
max) and yP can still remain within the set (technological) band.
RS
RH
SS
SP
w
S
v
P
RH
SH
y
H
w
H
v
H
y
P
y
S
Figure 4.12. Cascade control loop
Assume that while the systems SS and SH have positive gain, system SP
has negative gain, as a result, the growth in yS causes a drop in yP and yH.

78
4 Self-tuning PID Controllers
Therefore, controller RP has negative gain and controllers RS and RH positive
gain.
If the actuator (drive, end element) comes to a stop and control error
e(k) is nonzero, then integral term uI(k) in the PID position controller starts
to grow (theoretically) – see Equation (4.56); the increase of integral term
uI(k) is stopped only after a change in polarity of e(k). This results in com-
putation of nonfeasible values for control output u(k), causing the actuator
to remain longer at a stop (the return to the control band depends on the
relationship of the P, I and D terms). This delayed return of the actuator
to the control band and consequent waste of energy supplied to the system
can cause large overshoots in the process output, mainly in cascade control
loops. This “over-excitation” of the controller is known as “wind-up” (“reset
wind-up”) or “integral saturation”. It is caused by the failure to limit the
integral term suﬃciently after limiting the controller output in the actuator
and/or in the ﬁnal control element. The wind-up eﬀect is demonstrated here
in Figure 4.13, which shows the responses of a simple controlled system com-
posed of a linear dynamic system and PI controller to set point changes. The
manipulated variable is the controller output. The ﬁrst step point change is
a linear case without limitation of manipulated variable u(k); in the second
step point change the manipulated variable is limited but the integral term
increases without limit. Compare the responses of u(k), y(k).
0
5
10
15
20
25
30
35
40
0
1
2
3
4
5
6
7
time
y,w,u
y(t)
u(t)
w(t)
Figure 4.13. Wind-up eﬀect
Some safeguards against the wind-up eﬀect (anti wind-up algorithms)
which must be based on the subsequent modiﬁcation of the integral term
are described below. These are eﬀective for a controller in a simple control

4.5 PID Controllers for Operational Use
79
loop, but in a cascade control loop they are usually only useful for slave con-
troller RP , the limited output uP of which corresponds to the limited value
of actuator yS. For the master controller, it is impossible to preset a constant
output boundary which permanently corresponds to the stop in the control el-
ement (actuator). When dealing with the wind-up eﬀect it is assumed that the
master controller receives a signal (information) that the slave controller or ac-
tuator has reached a stop. Only Shinskey [63] and Fessl and Jarkovsk´y [64, 65]
(for PID as well as for LQ controllers) give solutions to cascade control in the
references cited here. The other references do not treat this problem at all.
˚Astr¨om and H¨agglund [9] recommend solving this problem by switching the
master controller to manual control.
Glattfelder and Schauﬀelberger [66] and Rundquist [67, 68], among others,
analyse wind-up from the point of view of nonlinear theory. ˚Astr¨om and Wit-
tenmark [69] suggested one solution to the wind-up eﬀect involving a state
controller with observer. Rundquist [67, 68] examines several approaches and
demonstrates that the diﬀerent solutions can be regarded as variations on the
state controller with observer.
It must be stated that the eﬀectiveness of anti wind-up algorithms depends
on whether the control device (actuator) has been limited as the result of
disturbance or set point change, and also on the nature of the disturbance and
the point at which it aﬀects the system, as well as on the system dynamics
(static or astatic, the ratio between time delay and the system’s dominant
time constant and the order of the system). It is therefore diﬃcult to compare
various anti wind-up algorithms and they all have diﬀerent eﬀects.
The controller output is limited to the control band
u ∈⟨umin; umax⟩
(4.70)
Which means that position controller Equation (4.56)–(4.57) and incremental
controller Equation (4.59)–(4.61) must be supplemented by limitation (4.70).
Due to varying modiﬁcations of the integral term, the output from incremental
controller (4.59)–(4.61) and position controller (4.56)–(4.57) may diﬀer after
control element limiting. Incremental controller (4.59)–(4.60) with only output
∆u(k) implicitly includes a limited output because the calculated value is not
put into eﬀect if the control element or slave controller lies outside the control
band. Since only the changes in the integral term and controller output ∆u(k)
are calculated the wind-up eﬀect does not occur.
Slave controller RP is limited by the operating band of the ﬁnal control
element and thus the equation
uP
min ≈yS
min
uP
max ≈yS
max
(4.71)
is valid.
A common solution to the wind-up eﬀect was the use of tracking signal x
for the integral term while limiting the controller output, where x denotes the
controller’s limited output. For the position controller described by (4.57),

80
4 Self-tuning PID Controllers
or more exactly by (4.56)–(4.58) and (4.70), a relation similar to (4.68) is
employed, i.e. for slave controller RP
uP
I (k) =

uP
min
for yS = yS
minor u(k) = uP
min
uP
max
for yS = yS
maxor u(k) = uP
max
(4.72)
Here the value of integral term uP
I in fact jumps when it reaches stop yS
min
or yS
max. Controller RP and the actuator return back within the control band
when control error eP changes polarity.
A static limit on the integral term uI on constant boundary
uI ∈⟨uI min; uI max⟩
(4.73)
is analogous to Equation (4.72), where
uP
I min ≈yS
min ≈uP
min
uP
I max ≈yS
max ≈uP
max
(4.74)
is generally used for controller RP .
Controller RP and the actuator return back within the control band when
control error eP changes polarity as in the previous case.
The eﬀect of the static limit on the integral term uI by (4.73) is shown
on Figure 4.14 which shows responses of the same simple control loop as for
Figure 4.13. The ﬁrst step point change is linear without limitation of the
manipulated variable u(k); in the second step point change the manipulated
variable is limited and the integral term is limited statically to a constant value
as in (4.73). Compare the responses of u(k), y(k) with those of Figure 4.13.
Note
In some commercially available controllers the boundary of integral term uI
can be deﬁned within a narrower band than that of the controller output.
When the boundary between the integral term and the output has been
reached, controller RP and the actuator unit return to within band as soon
as the control error eP starts to fall.
The boundaries of uI (4.73) cannot be introduced directly for incremental
controller (4.59)–(4.61) and (4.70), where only the output limit (4.70) can be
used. This is where the hitherto equivalent controllers (4.57) and (4.61) begin
to diﬀer. For an incremental controller, limit u(k) in fact causes a step in the
integral component of usat(k)−u(k), where usat(k) denotes the value limited
in the band ⟨umin; umax⟩and u(k) stands for the calculated unlimited value.
This leads to a subsequent recalculation of integral term uI for position con-
troller (4.57) to the value required to achieve limited values on the controller
output (see ˚Astr¨om and Wittenmark [69], Clarke [70])
uI(k) = uI(k) + usat(k) −u(k)
(4.75)
where

4.5 PID Controllers for Operational Use
81
0
50
100
150
200
250
300
350
400
0
1
2
3
4
5
6
7
time
y w u
output
input
setpoint
Figure 4.14. Static limit on the integral term uI by (4.73)
usat(k) =
u(k)
for u(k) ∈⟨umin; umax⟩
umin
for u(k) < umin
umax
for u(k) > umax
(4.76)
Controller RP and the actuator return to the control band as soon as control
error eP drops. However this may cause the drive to oscillate greatly between
stop and the control band and slow down the process of regulating disturbance
and achieving zero control error (especially for the case of a larger drift in the
measured values of the controlled variable).
˚Astr¨om and Wittenmark [69] designed a solution to the wind-up eﬀect for
a state controller with observer as well as for a PID controller transformed into
the state form. The solution is given below. First, the controller is transformed
into the state form
x(k + 1) = Fx(k) + Gy(k)
(4.77)
u(k) = Cx(k) + Dy(k)
(4.78)
where x denotes the controller state, y the input (i.e. the control error) and
u the controller output which is subject to a nonlinear type of limitation
(i.e. by the drive) with output ur. For the case where y and the limit of u
have nonzero values, state x, and therefore the calculated value of output u,
will grow – unless the state value is made to correspond to the actual value
of output ur (estimate ur or measured value um). Then, an explicit state
observer is introduced so that, after multiplication by K, Equation (4.78)
can be added to Equation (4.77) and, instead of calculated value u(k), the
observed output value ur(k) is used.

82
4 Self-tuning PID Controllers
This gives us
x(k + 1) = Fx(k) + Gy(k) + K[ur(k) −Cx(k) −Dy(k)]
= [F −KC]x(k) + [G −KD]y(k) + Kur(k)
= F0x(k) + G0y(k) + Kur(k)
(4.79)
If system (4.77) and (4.78) is observable, then matrix K can be chosen so
that matrix F0 = F −KC always has its eigenvalues inside the unit circle.
The controller with observer then takes the form
x(k + 1) = F0x(k) + G0y(k) + Kur(k)
u(k) = Cx(k) + Dy(k)
ur(k) = sat[u(k)] = sat[Cx(k) + Dy(k)]
(4.80)
where sat denotes the limiter with boundaries umin, umax.
For a position controller, integral component uI is the state x, i.e. x = uI
– see Equation (4.56) and (4.57). For K = 1/T
uI(k) = uI(k −1) + r−1e(k)
u(k) = r0e(k) + uI(k) + r1[e(k) −e(k −1)]
ur(k) = sat[u(k)]
uI(k) = uI(k −1) + r−1e(k) +
1
Tr [ur(k) −u(k)]
(4.81)
where the ﬁnal equation deﬁnes the re-calculation of the state-integral term.
The relation (4.75) can be obtained for K = 1 (the so-called dead-beat ob-
server).
Figure 4.15 shows a diagram (illustrating a continuous-time PID controller
for the sake of clarity) where gain Tr (the observer constant) is introduced
as feedback correction to the integrator state. The choice of value Tr can be
used to inﬂuence the dynamics of the controller and its sensitivity to the noise
resulting from measurements. The recommended value of Tr is proportional
to TI. The signal which is equal to (ur −u)/Tr can also be interpreted as the
tracking signal from the integrator.
Hanus et al. [71] suggest a recalculation of set point wH to a value which
leads to a limit on the control element. Another solution suggests a recalcula-
tion of set point wH to a value which leads to a limit on the control element.
This approach can be regarded as a variant on the controller with observer
(see Rundquist [67, 68]). Like the previous (4.72)–(4.80), this solution can only
be used directly for the subordinate controller RP , since a boundary (4.70) or
(4.73) for uH = wP , which permanently corresponds to drive boundary yS,
cannot usually be preset in the main controller RH. The eﬀects of disturbance

4.5 PID Controllers for Operational Use
83
vP can change the level of yP so that wP is within the boundaries, but yS is
limited.
In incremental controller (4.60), (4.61) it is possible to use the measured
controller output u(k −1) instead of um(k), but, generally speaking, this is
incorrect. Although wind-up disappears from both RP and RH controllers,
it often leads to worse control within the control band. This is caused by
neglected dynamic delay between um(k) and u(k −1) which may even lead to
instability in the loop (see Fessl and Jarkovsk´y [64, 65]). Measurement noise
and disturbance acting on um interfere with the functioning of the controller.
It is, however, possible to use measured controller output um as the track-
ing signal for main controller RH in a cascade control loop (if a stop of the
actuator or slave controller has been reached), which means that
uH
I (k) = yP (k) = um(k)
(4.82)
where the measured control output um is simultaneously the process out-
1
s
w
KP
TI
KP
e
u
y
u
r
K T s
P
D
sat
1
Tr
Figure 4.15. Block diagram of a PID controller where the wind-up eﬀect is solved
using Equation (4.81)
put yP of the slave controller RP , for which the set point is uH = wP . This
solution, which removes or signiﬁcantly suppresses wind-up in the main con-
troller, is only described by Shinskey [65] and is generally little known among
designers and control engineers. In incremental controller (4.60), (4.61) the
corresponding value of u(k −1) is calculated according to (4.69).
The dynamic limitation of the integral term can be used for both RP
and RH. At the moment of limiting the control element, the integral term
is “frozen”, i.e. it is limited to a previously unknown dynamically variable
boundary

84
4 Self-tuning PID Controllers
∗uI = uI(k) = uI(k −1)
(4.83)
or, for incremental controller (4.60), during the “freeze” period
∆uI(k) = 0
(4.84)
The drive returns to the control band when terms P and D start to drop
(this is slower than recalculation (4.75) when it is used for slave controller RP ,
but usually better because the actuator does not oscillate so much around the
stop).
Both (4.82) and (4.83) are the only methods given so far to remove or
signiﬁcantly diminish the wind-up eﬀect in the main controller RH in a cascade
control loop. Figure 4.16 presents responses of the cascade control loop, shown
in Figure 4.12, with disturbances and constant set point; the integral term
is limited: (a) statically to a constant value as in (4.73), which is not too
successful in cascade control; (b) dynamically according to (4.83). Compare
the responses of main controller output wP = uH and the impact on controlled
variable yH after limitation of the actuator.
 
 
 
a) 
b) 
Figure 4.16. Limiting the integral term: (a) statically as in (4.73), (b) dynamically
as in (4.83) in cascade control
The “frozen” value ∗uI (4.83) can also be taken as the tracking signal for
the integration channel. The disadvantage of (4.82) and (4.83) is that the size
of uH
I (k), ∗uI and the behaviour of yP depend on the disturbance behaviour
causing the actuator to reach the limit. Therefore, in some situations Equation
(4.83), in others (4.82) results in smaller overshoot of the controlled variable,

4.5 PID Controllers for Operational Use
85
depending on the previously unknown disturbance behaviour. This shortcom-
ing can be removed if the tracking signal is determined by a logical selector,
which selects between the two alternative tracking signals to give the lowest
process output overshoot.
Correcting the calculated manipulated variable.
The calculated controller output (manipulated variable) u(k) can be dynam-
ically limited using a so-called manipulated variable corrector (Fessl and
Jarkovsk´y [64, 65]), which respects the true values of measured controller out-
put um. The corrector, originally developed for an adaptive controller with
recursive identiﬁcation, can also be used for PID and similar controllers. In
incremental controller (4.60), (4.61) the last calculated value of u(k −1) is
replaced by corrected value uK(k). Denoting v the diﬀerence between the
computed and measured value of u
v = u(k −1) −um(k)
then, it yields
u(k −1) = uK(k) = sate max(v) + um(k)
(4.85)
where e max > 0 is the maximum permitted control error (over several sam-
pling periods) in the relevant control loop, and sat denotes the limiter in
boundaries −e max and +e max. The value of e max must also be chosen
with regard to possible changes in controlled variable y(k) and manipulated
variable u(k) when disturbance is great or there are large changes in the set
point. Equation uK(k) = u(k −1), i.e. standard incremental controller (4.61),
remains valid when |v| < e max. For the unsuitable limit e max = 0, the
controller changes to one using the constantly measured manipulated vari-
able um. In contrast to the dynamic limitation on integral term (4.83), the
eﬀect of the ﬁnal control element’s static nonlinearity is now compensated as
well. The value of uI can subsequently be recalculated for position controller
(4.56)–(4.57) as
uI(k −1) = uI(k −1) + uk(k) −u(k −1)
(4.86)
The application of Equation (4.85) is often reasonable combined with an-
other condition (especially the actuator position yS near the real stop, i.e.
apply corrector for yS < 3% or yS > 97%, for example). Unlike constant
boundary usat (4.76) used for recalculating value uI(k) employing (4.75), the
“boundary” given by uK is variable and obtained from the true measured
value of um. Corrector (4.85) is particularly useful for main controller RH
and is an alternative solution to the use of tracking signal (4.82) and dynamic
limitation on the integral term (4.83).
Rundquist [67, 68] compares several anti wind-up algorithms for a simple
control loop, and ˇSulc [72] describes real hydraulic and pneumatic controllers
and suitable solutions.

86
4 Self-tuning PID Controllers
Apart from using (algorithmic) controller output limitation (4.70), output
changes are often limited by
∆u(k) ∈⟨∆umin; ∆umax⟩
(4.87)
and also the values of controller output u(k) in relation to another variable
z(k)
u(k) = satz[u(k) −z(k)] + z(k)
(4.88)
The integral term is changed indirectly by limiting the controller output,
whereas in incremental controller (4.61) we in fact alter the increment of the
integral term ∆uI(k), and consequently integral term uI(k). It follows that
boundary uH
min, uH
max can be changed directly rather than altering the value
of integral component uI(k) in the main controller of a cascade control loop.
When the slave controller reaches the output boundary, the boundary of the
main controller can be deﬁned to equal the current value of its output uH, and
consequently its integral term will be corrected. For example, the following
algorithm can be used (assuming the same range of values for uH and uP , e.g.
0, 100% and the same polarity for the controllers)
uH
max = uH + uP
max −uP
uH
min = uH + uP
min −uP
(4.89)
The wind-up eﬀect can also result from the use of selection circuit (for
example a circuit to select a minimum or maximum) to switch over signals
(“override control”). Consider the structure of a control loop in which the
control signal for the slave controller or control element is selected from the
outputs of two or more main controllers. Then, if the “unselected” PID con-
trollers remain active their integral terms will change even if the output is
not put into eﬀect. One answer to this problem is to set the output from
unselected controllers to the value of the output from the selected controller.
Alternatively, we can constantly change the boundaries of these controllers.
Note
Except for corrector (4.85), all algorithms for limitation of the integral com-
ponent are based on the assumption that the stop of the ﬁnal control element
(actuator) and the boundary of the relevant controller correspond. If, due to
bad (mechanical) tuning, the actuator reaches the stop before the controller
does, the controller will continue the integration process, resulting in wind-up,
i.e. greater integration of the controller and consequently greater overshoot
in the process output. Unfortunately even the use of digital output to signal
the actuator boundary is not entirely reliable.
“The control paradox”: sometimes a seemingly inexplicable phenomenon
occurs. Even though there may be a large control error, the control element
starts to move in the wrong direction at the stop, closes up rather than open-
ing, for example, or perhaps oscillates near the stop. This is caused by an
unsuitable anti wind-up algorithm, drift in the process output, and possibly
also by an unsuitably large integral time constant.

4.5 PID Controllers for Operational Use
87
4.5.3 Limited Precision in Calculation
The precision of the A/D and D/A converters used (quantization level), com-
puter word length together with related errors in rounding oﬀand the use
of ﬁxed or ﬂoating point arithmetic, all aﬀect the performance of a digital
controller. For details see Isermann [54] and ˚Astr¨om and Wittenmark [69].
All the conditions above also have an eﬀect on the choice of sampling period
and controller parameters KP , TI and TD (see Section 4.4).
An appropriate normalization of variables (for example subtracting the
reference values from the controlled and manipulated variable) increases the
number of valid places for the calculated values and therefore improves the
precision of the calculation. Limited precision causes bias – a permanent con-
trol error or limiting cycles. This will be illustrated by an example. The change
in the integral component is
∆uI(k) = KP T0
TI
e(k)
(4.90)
If we use a 12 bit converter with quantization 1/4096, and KP T0 = 1 and
TI = 3600, error not exceeding 88% of the converter band does not cause
the change in ∆uI to be greater than the level of quantization. No change
occurs when the common 8 bit converter with a level of 1/256 is used. The
answer is to double the length of the word to calculate the integral component
or round up all calculations, or add to the random component (noise on the
level of quantization) together with suitable normalization of the variables –
Bristol [73]. Similarly, the derivative term is either invalid, or else is valid with
steps
∆uD(k) = [e(k) −e(k −1)]KP TD
T0
(4.91)
It is clear from the above that there is a diﬀerence in behaviour between in-
cremental controller (4.59), (4.60), which only calculates the variously rounded
oﬀvalues of ∆uI, and position controller (4.56), (4.57). Another diﬀerence
(apart from the eﬀect of limited controller output – see Section 4.5.2) is in
the behaviour towards changes in the parameters and in set point w.
4.5.4 Filtering the Measured Variables
Sampling using a period T0 and frequency ω0 = 2π/T0 creates a low frequency
signal with diﬀerential frequency ω2 = |ω0 −ω1| and unchanged amplitude
from signal x(t) with higher frequency ω1, when ω1 ≥ω0/2 and period T1 <
2T0. This is illustrated in Figure 4.17.
This “aliasing eﬀect” would result in an unsuitable calculation of the con-
troller output. These higher frequencies must, therefore, be ﬁltered through
a low frequency ﬁlter before being used in a controller. A ﬁlter also limits
the eﬀects of the acting measurement noise, etc. The most commonly used

88
4 Self-tuning PID Controllers
 
Figure 4.17. Signal x(t) with higher frequency ω1 sampled with frequency ω0 ≪ω1
are analogue ﬁlters (ﬁrst or higher order lag) or specialized ﬁlters (the But-
terworth, Bessel or Chebyshev ﬁlter). Isermann [54] and others deal with the
problems of ﬁlters in more detail. Analogue ﬁlters are more diﬃcult to apply
to larger sampling periods and are therefore replaced by digital ﬁlters. An
analogue signal can be sampled with digital ﬁlter period Tf = T0/m < T0,
where the ﬁlter output is used with period T0. Eﬀective ﬁlters for multiple
sampling based on the on-line identiﬁcation approach have been designed,
which ﬁlter the signal better than, for example, the commonly used method
of simply taking an average of the latest values. However, ﬁltration not only
suppresses noise but the useful signal as well. For this reason it was suggested
use be made of a digital correction term with inverse transfer function F −1
to the transfer function of an analogue ﬁrst-order ﬁlter F
F(z) = (1 −a)z
z −a
a = exp(−T0/Tf)
(4.92)
The input into the analogue ﬁlter is a signal aﬀected by noise yn(k), the
useful component y(k) of which is calculated with period T0. Using (4.92) it
follows that
y(k) = yf(k) −ayf(k −1)
1 −a
(4.93)
where yf(k) denotes the output from the analogue ﬁlter.
Special ﬁlters are used for signals aﬀected by abnormal noise distribution.
Clarke [70] describes a ﬁlter which reliably removes noise having short-term
rectangular pulses (“peaks”). This algorithm, where parameter gapmin is the
minimal value of variable gap(k), x(k) and y(k) denotes ﬁlter input and out-
put, resp., follows:
d(k)= x(k) - y(k-1)
if
abs(d(k)) < gap(k-1)
then y(k) = x(k)
gap(k)= max (gap(k-1)*0.5, gapmin)
else y(k) = y(k-1) + gap(k)*sign(d(k))
gap(k)= gap(k-1)*2

4.5 PID Controllers for Operational Use
89
end
4.5.5 Industrial PID Controllers
The development of electronics and particularly computer technology (micro-
processors) has meant that practically all commercial electronic controllers are
digital and no longer contain analogue elements as they did before. PID con-
trollers exist as one or multi-control loop controllers or as program (function)
blocks in PLCs or control systems.
It should be noted that the output from PID-type controllers either takes
the form of analogue output (AO) or digital output (DO) – one digital output
is usually used (for switching on and oﬀ) or two digital outputs (for switching
on and oﬀor to control the actuator in the “increasing” and “decreasing” di-
rection, etc.). Apart from these main outputs there may be other auxiliary dig-
ital outputs for various indications etc. Furthermore, controllers are commonly
connected to the communication interface RS422/485 or other company chan-
nels. An analogue output with period T0 generates an amplitude-modulated
impulse signal, whereas a digital output produces a pulse width-modulated
signal, i.e. a signal with a width proportional to a calculated value u(k). This
makes a digital PID controller with digital outputs rather similar to the clas-
sic two or three-position controller. For a controller with digital outputs, it is
wise to use an incremental controller with output ∆u(k) – Equation (4.13b)
or (4.59)–(4.60); the size (and polarity) of the change ∆u(k) is introduced
directly into the relevant digital output. In the case of a controller with an
analogue output, it is possible to use either algorithm (4.16) or (4.59)–(4.61),
alternatively the component form (4.27)–(4.28) or (4.56)–(4.57).
In addition to its own parameters (KP , TI, and TD, plus the Tf parameter
for the D-term ﬁlter), a PID controller block also has upper and lower out-
put boundaries (minimum and maximum values) umin, umax and sampling
period T0 (which can be deﬁned as the period of the whole control pro-
gram). It is sometimes also possible to include the greatest permitted change
+∆umax, −∆umax.
The polarity of the controller is set according to the polarity of the gain of
the controlled system – terms indirect or reverse action controller and direct
controller are used. These names are taken from the direction in which the
manipulated variable operates in relation to the direction of changes in the
controlled variable. If the controlled system has negative gain then an increase
in the controlled variable results in a direct increase of the P term causing a
direct increase in the manipulated variable.
The controller block often includes feed-forward signals and possibilities to
use proportional or cascade control. Functions for switching between manual
and automatic control and manual setting of the value for controller output
are standard. Many industrial controllers can be programmed: the set point is
generated by a program (for programmable control). In the case of so-called

90
4 Self-tuning PID Controllers
multi-function controllers, the user can even program the structure of the
control loop from a library of function blocks. Most companies manufacturing
controllers now supply them with an auto-tuning function which is (a one-
shot) function to tune the controller parameters automatically. Some compa-
nies developing algorithms for auto-tuning oﬀer fuzzy logic algorithms. Auto-
tuning algorithms are quite often based on evaluation of the step-response in
both open and closed loops. It is tacitly assumed that only the manipulated
variable acts on the controlled system, which is a single-variable one. This
means that the algorithms fail to consider the eﬀects of various measured and
unmeasured disturbances and nonlinearities. Therefore these algorithms (and
the controllers which use them to tune their parameters) tend to work better
for set point transitions and worse for a disturbance-contaminated loop.
4.6 Survey of Self-tuning PID Controllers
The structure of these controllers must be designed so that the numerator of
the discrete transfer function is always in the form of a second-order polyno-
mial. The form that is most frequently used is given below:
GR(z) = U(z)
E(z) = q0 + q1z−1 + q2z−2
1 −z−1
(4.94)
The structure of discrete transfer function (4.94) leads to the incremen-
tal equation of digital PID controller (4.14), where parameters q0, q1 and q2
depend on the type of discretization of the integral component.
A suitable version of the discrete transfer function of a digital PID con-
troller to apply the pole assignment method is the structure
GR(z) = q0 + q1z−1 + q2z−2
(1 −z−1)(1 + γz−1)
(4.95)
By choosing one of the above or similar structures we ensure that the
parameters of the digital PID controller correspond to the P, I, and D com-
ponents of its continuous-time version. The algorithm of this controller is
composed of the parameter estimates of process model ˆΘ(k). These are then
used to calculate the optimal parameters of the digital PID controller and
consequently controller output u(k) at each sampling period.
In this section we will give a clear picture of some work taken from texts
dealing with the design of self-tuning PID controllers, i.e. adaptive PID con-
trollers with recursive identiﬁcation.
Corripio and Tomkins [74] designed an algorithm based on estimation of
the parameters of a second-order model using recursive identiﬁcation applied
by the instrumental variable method. The parameter estimates ˆa1,ˆb1 and ˆa2
(assuming ˆb2 = 0) are used to calculate the controller parameters and included
in those relations obtained by Dahlin [75, 76].

4.6 Survey of Self-tuning PID Controllers
91
Wittenmark [77] analyzed digital PID controllers designed using the pole
assignment method together with the recursive least squares method to esti-
mate the process model parameters. Six diﬀerent digital PID controller struc-
tures are discussed in relation to a more generalized control algorithm and
there is a particular comparison between the suggested algorithm and the
common version based on the pole assignment method. The advantages and
disadvantages of each individual controller are demonstrated in simulated ex-
amples.
A survey and discussion of several self-tuning PID controller types is given
by Ortega and Kelly [78]. They treat two types of explicit controllers and one
implicit, all based on recursive identiﬁcation and the pole assignment method.
They also include a controller which minimizes the explicit criterion.
Kim and Choi [79, 80] modiﬁed the algorithm of the implicit controller
given in [78], limiting large oscillations of the controlled output due to set
point changes.
Kofahl and Isermann [81] developed a tuning procedure based on the al-
gebraic calculation of critical gain and critical periods of oscillation, followed
by application of the Ziegler–Nichols method.
Radke and Isermann [82] showed a self-tuning PID controller built on
the estimation of process model parameters using the recursive least squares
method and numeric optimization of parameters based on quadratic criteria.
If qT = [q0, q1, q2] is the vector of the parameters of the controller (4.94),
then the most generalized method of determining their optimal values is to
minimize quadratic criteria
J =
N

k=0
[e2(k) + rK2
S∆u2(k)]
(4.96)
where e(k) is the tracking error, ∆u(k) = u(k) −u(k −1) is the controller
output error, KS is the process gain, and r is the weighting factor of the
controller output. The optimal controller parameters are obtained by solving
equation
∂J
∂qi
= 0;
for i = 1, 2, 3
(4.97)
The parameter optimization above can only be performed analytically for
lower order controllers or systems. In general, optimization must be carried
out numerically. Two ways are given to solve criterion (4.97) in reference [82];
either in the time ﬁeld by solving the diﬀerential equation of a closed control
loop with suitable external excitement, or in the z domain using the Parseval
integral. Optimization of parameters according to relation (4.97) is carried
out numerically.
Tzafestas and Kapsiotis [83] designed a combined self-tuning controller
based on the pole assignment method followed by the optimization of the
vector of the controller parameters using criterion (4.96).

92
4 Self-tuning PID Controllers
Gawthrop [84] used a hybrid self-tuning controller to tune an external
PID controller. The implementation of this kind of control system, however,
presumes very high integration of the hybrid controller using special loops,
and produces a controller which is part digital and part pseudo-analogue.
Neuman [85] designed a self-tuning predictive PI controller (PIR) derived
from the algorithm of the classic incremental PI controller. The predicted
output value can be used either in the integral or proportional component,
or even in both. This controller permits the use of both one-step and higher
order predictors. The recursive parameter estimate of the linear predictor is
performed using the recursive least squares method. This is, then, a controller
with ﬁxed parameters, adaptive in that it uses the predicted output value to
determine the control output.
Alex´ık [86] describes analytical PID algorithm which has adaptive self-
tuning performance. Its synthesis is performed in the continuous-time domain.
This means that identiﬁcation is followed by recalculation into the continuous-
time domain and the ﬁnal gain of the algorithm is compensated due to the
sampling period. B´any´asz et al. [87, 88] suggested several modiﬁcations of the
self-tuning PID controller. Again, the least squares method is used to estimate
parameters of the process model and very simple relations have been deduced
to design the controller. The algorithms are also suitable for the control of
processes which are already known or have unknown time delay.
Some modiﬁcations of PID type controllers have been developed by B¨ohm
et al. [89]. Each modiﬁcation diﬀers from the others in the choice of model
structure; controller design is solved on the basis of minimizing the quadratic
criterion using the polynomial method.
Ziegler–Nichols’ method is very often used as the ﬁrst method for tuning a
control loop in practice. It has some advantages and some disadvantages. Its
simplicity and universality are advantages and the low accuracy is the basic
disadvantage. Controlled circuits tuned by this method gave relatively high
values of overshoot (10–60%). The dynamic inversion method (see V´ıteˇckov´a
et al. [90, 91]) retains the simplicity of the Ziegler–Nichols method but it is
more accurate and universal. However, the method described thereinafter is
suitable only for some types of controlled systems which are controlled by some
types of PID controllers. The transfer functions of the controlled systems are
given in the s complex plane there, however, they can be easily transformed
into the z complex plane and in the STC algorithm are used as discrete ones.
However, there are several methods of reducing the order of the controlled
system or it can be estimated directly into a suitable one using recursive
identiﬁcation, i.e. RLSM (recursive least squares method).
A self-tuning PID controller algorithm based on this approach has been
derived by Bob´al et al. [92]. The process was identiﬁed using the regression
(ARX) continuous-time model, the RLSM with directional forgetting was ap-
plied. The recursive parameter estimates of the continuous-time model (dif-
ferential equation) have been used for synthesis of the PID controller.

4.7 Selected Algorithms for Self-tuning PID Controllers
93
Algorithms for self-tuning PID controllers based on the use of the Ziegler–
Nichols criterion, modiﬁed for digital loops, have been designed by Bob´al [93].
Synthesis of the controller is based on determination of critical proportional
gain and critical period of oscillation when the closed loop is at the stability
boundary. The critical parameters are calculated from the recursive parameter
estimates of the process model without the necessity of using some test signal
to make the control loop oscillate at the stability boundary. The recursive
least squares method with directional forgetting is used in the identiﬁcation
procedure [49, 50]. A control algorithm has been derived for second-order
models [94] together with a controller for third-order systems [33, 95], as well
as for general n-th order systems [59, 96]. The approach given can easily be
modiﬁed to enable the derivation of algorithms to control systems with time
delay [97, 98].
4.7 Selected Algorithms for Self-tuning PID Controllers
In this chapter certain explicit self-tuning controllers will be presented which
have been algorithmically modiﬁed in the form of mathematical relations or
as ﬂow diagrams so as to make them easy to program and apply. All the
algorithms given below are included in the Matlab R
⃝Toolbox. Some are
original algorithms based on a modiﬁed Ziegler–Nichols criterion, others have
been culled from publications and adapted to make them more accessible to
the user.
4.7.1 Dahlin PID Controller
The algorithm of this controller, which is given in [74], calculates the controller
output using an incremental form of relation discretized by the forward rect-
angular method (4.16)
u(k) = KP

e(k) −e(k −1) + T0
TI
e(k)
+ TD
T0
[e(k) −2e(k −1) + e(k −2)]

+ u(k −1)
(4.98)
This controller uses parameter estimation vector (3.14) in the form
ˆΘT (k) = [ˆa1, ˆa2,ˆb1]
(4.99)
and since ˆb2 = 0, regression vector (3.15) is
ΘT (k −1) = [−y(k −1), −y(k −2), u(k −1)]
(4.100)
The following relations were obtained for individual controller parameters:

94
4 Self-tuning PID Controllers
KP = −(a1 + 2a2)Q
b1
TI = −
T0
1
a1+2a2 + 1 + TD
T0
TD = T0a2Q
KPb1
(4.101)
Variable Q in Equation (4.101) is deﬁned by the relation
Q = 1 −e−T0
B
(4.102)
where B is known as the adjustment factor which characterizes the dominant
time constant of the transfer function according to changes made to the pro-
cess output of a closed control loop. The smaller the value of B, the faster the
response of the closed control loop.
To avoid oscillation in the process output variable it is advisable to choose
the initial control parameter estimates using the following relations. These are
basically the inverse expression of Equation (4.101).
C = 1 + T0
TI
+ TD
T0
a1 = −
1 + 2 TD
T0
C
a2 = TD
T0C
b1 =
Q
KP C
(4.103)
Before devising our own algorithm we must take its numerical stability
into account. It follows from Equation (4.101) that if b1 = 0 division by zero
may occur. Therefore when we start the algorithm we must avoid choosing
zero for parameter b1 and manipulate the algorithm bearing this danger in
mind.
4.7.2 B´any´asz and Keviczky PID Controller
This controller has been derived from and analysed in references [87, 99, 100,
88]. The PID controller discrete transfer function is considered in its standard
form
GR(z) = Q(z−1)
P(z−1) = q0 + q1z−1 + q2z−2
1 −z−1
(4.104)
Digital ﬁlter GF is serially connected to the controller. The controlled
process is described by the discrete transfer function
GP (z) = B(z−1)
A(z−1) =
b0 + b1z−1
1 + a1z−1 + a2z−2 z−d
=
b0(1 + γz−1)
1 + a1z−1 + a2z−2 z−d
(4.105)
where b0 ̸= 0 and d > 0 is the number of time delay steps. Figure 4.18 shows a
block diagram of the closed loop. The controller polynomial Q(z−1) is chosen
so as to validate
Q(z−1) = q0(1+q′
1z−1+q′
2z−2) = q0(1+a1z−1+a2z−2) = q0A(z−1) (4.106)

4.7 Selected Algorithms for Self-tuning PID Controllers
95
b (1
z )z
1 a z
a z
0
1
2
+
+
+

-1
-d
-1
-2
Q(z )
-1
P(z )
-1
G (z)
F
e(k)
u(k)
y(k)
w(k)
Figure 4.18. Block diagram of the control loop for a B´any´asz and Keviczky con-
troller
which means that
q′
1 = q1
q0
q′
2 = q2
q0
(4.107)
This idea allows us to simplify the control loop of Figure 4.18 to that of
Figure 4.19 where the integrator and pure time delay are directly connected
in series when relation (4.108) for integrator gain is valid.
kI = q0b0
(4.108)
e(k)
w(k)
k (1
z )
1 - z
I
+
-1
-1
z
-d
y(k)
G (z)
F
u(k)
Figure 4.19. Simpliﬁed block diagram of a control loop
The correction ﬁlter can be used to compensate for unwanted interference
caused by the expression 1 + γz−1 as well as for other purposes during con-
troller synthesis. This controller assumes knowledge of the number of time
delay steps. Parameter estimates vector (3.15) has the form
ˆΘT (k) = [ˆa1, ˆa2,ˆb0,ˆb1]
(4.109)
and regression vector (3.16) is
φT (k −1) = [−y(k −1), −y(k −2), u(k −d), u(k −d −1)]
(4.110)
The model parameter estimates are then used to calculate the controller
parameters according to the simple relation (3.15)
γ = b1
b0
q0 = kI
b0
q1 = q0a1 = kI
b0
a1
q2 = q0a2 = kI
b0
a2
(4.111)
where

96
4 Self-tuning PID Controllers
kI =
1
2d −1
for γ = 0
(4.112a)
kI =
1
2d(1 + γ)(1 −γ)
for γ > 0
(4.112b)
If γ < 1, Equation (4.112a) is used together with a serially connected
digital ﬁlter
GF (z) =
1
1 + γz−1
(4.113)
Relations (4.111) and (4.112) are then inserted into the equation to calcu-
late the controller output
u(k) = q0e(k) + q1e(k −1) + q2e(k −2) + u(k −1)
(4.114)
If b0 = 0 division by zero may occur.
4.7.3 Digital PID Controllers Based on the Pole Assignment
Method
A controller based on the assignment of poles in a closed feedback control loop
is designed to stabilize the closed loop while the characteristic polynomial
should have previously determined poles. Apart from the stability require-
ment, good poles conﬁguration can make it relatively easy to obtain desired
closed loop response (e.g., the maximum overshoot, damping, etc.). The gen-
eral approach to this method on the basis of algebraic theory is examined in
detail in Chapter 5.
A PID controller design which ensures the required control loop dynamic
behaviour by choosing the characteristic polynomial is given in references in
connection with various loop block structures [77, 78].
Structure of the PID–A Control Loop
This controller design comes from the general closed loop block diagram shown
in Figure 4.20, where
GP (z) = Y (z)
U(z) = B(z−1)
A(z−1)
(4.115)
is the discrete transfer function of the controlled plant with polynomials
A(z−1) = 1 + a1z−1 + a2z−2
B(z−1) = b1z−1 + b2z−2
(4.116)
GR(z) = U(z)
E(z) = Q(z−1)
P(z−1)
(4.117)
is the transfer function of a controller with polynomials

4.7 Selected Algorithms for Self-tuning PID Controllers
97
y(k)
B(z )
-1
A(z )
-1
u(k)
e(k)
w(k)
Q(z )
-1
P(z )
-1
Figure 4.20. Block diagram of control loop for a PID–A controller
P(z−1) = (1 −z−1)(1 + γz−1)
Q(z−1) = q0 + q1z−1 + q2z−2
(4.118)
From Equation (4.117) it is possible to determine the controller equation
in the form
U(z) = Q(z−1)
P(z−1)E(z)
(4.119)
and by inserting polynomials (4.118) into Equation (4.119), the relation to
calculate the controller output becomes
u(k) = q0e(k) + q1e(k −1) + q2e(k −2) + (1 −γ)u(k −1) + γu(k −2) (4.120)
Further, the following relation can be obtained for the control transfer
function of the closed loop shown in Figure 4.20
GW (z) = Y (z)
W(z) =
B(z−1)Q(z−1)
A(z−1)P(z−1) + B(z−1)Q(z−1)
(4.121)
where the characteristic polynomial is to be found in the denominator of
(4.121). By choosing the characteristic polynomial
D(z−1) = 1 +
nd

i=1
diz−i,
nd ≤4
(4.122)
in the polynomial equation
A(z−1)P(z−1) + B(z−1)Q(z−1) = D(z−1)
(4.123)
we ﬁx the desired pole placement for the transfer function (4.121). This is
achieved by selecting the correct parameters for controller polynomials (4.119)
which are the solution to polynomial Equation (4.123). The characteristic
polynomial (4.123) can be deﬁned by various methods. Most frequently used
are those which meet the following requirements:
•
the response of a continuous-time second-order plant;
•
the response of a discrete second-order plant;
•
dead-beat control;
•
quadratic optimal control;
•
desired response according to the user.

98
4 Self-tuning PID Controllers
PID–A1 Controller
This type of a controller was derived using method 1 where the required
control response of a closed loop can be achieved by selecting natural frequency
ωn and damping factor ξ in the characteristic equation for a continuous-time
second-order plant
s2 + 2ξωns + ω2
n = 0
(4.124)
If the polynomial D(z−1) is chosen in the form
D(z−1) = 1 + d1z−1 + d2z−2
(4.125)
then the following relations to calculate the coeﬃcients for a sampling period
T0 can be derived:
d1 = −2 exp(−ξωnT0) cos(ωnT0

1 −ξ2);
for ξ ≤1
d1 = −2 exp(−ξωnT0) cosh(ωnT0

1 −ξ2);
for ξ > 1
d2 = exp(−2ξωnT0)
(4.126)
For polynomial (4.124) to have stable poles ξ > 0, ωn > 0 must be valid.
The damping factor ξ is chosen according to the requirement of an oscillating
or non-oscillating control response. Wittenmark and ˚Astr¨om [101] recommend
choosing a value for natural frequency which makes the inequality 0.45 ≤
ωnT0 ≤0.90 valid.
If polynomial (4.125) is inserted into the right side of Equation (4.123),
a series of four algebraical linear equations for four unknown parameters is
obtained which can be written in the matrix form
⎡
⎢⎢⎢⎢⎢⎢⎣
b1 0 0
1
b2 b1 0 a1 −1
0 b2 b1 a2 −a1
0 0 b2
−a2
⎤
⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎣
q0
q1
q2
γ
⎤
⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
x1
x2
x3
x4
⎤
⎥⎥⎥⎥⎥⎥⎦
(4.127)
The ﬁrst matrix on the left side of (4.127) depends only on the parameters
of the controlled system, the next vector contains the unknown parameters of
the controller, being the solution to the system of equations (4.127), and the
vector on the right depends on the number of poles nd and their position in
the z complex plane. In this case the elements in the vector are given by the
relations
x1 = d1 + 1 −a1
x2 = d2 + a1 −a2
x3 = a2
x4 = 0
(4.128)
The solution of the equation system, i.e. the relations to calculate the
controller parameters, are is given in Table 4.3.

4.7 Selected Algorithms for Self-tuning PID Controllers
99
PID–A2 Controller
When controlling technological processes, in many cases there is a requirement
for a control response without or only with limited overshoot. Then it is a good
idea to choose the characteristic polynomial in the form [93, 102]
D(z) = (z −α)2[z −(α + jω)][z −(α −jω)]
(4.129)
Re
Im
1
-1
z1
z2
-j
j


z3, 4
Figure 4.21. Pole assignment in polynomial D(z)
Table 4.3. Relations to calculate PID–A controller parameters
Controller
parameters
PID–A1
PID–A2
q0
1
b1 (d1 + 1 −a1 −γ)
r2 −r3
r1
q1
a2
b2 −q2(b1
b2 −a1
a2 + 1) −r4 + r5
r1
q2
−s1
r1
x4 + γa2
b2
γ
q2 b2
a2
r6
r1
Characteristic polynomial (4.129) has a pair of complex conjugated poles
z1,2 = α ± jω placed inside the unit circle at interval 0 ≤α < 1 and double
real pole z3,4 = α, where α2 + ω2 < 1 (see Figure 4.21). The parameter α
can be used to change the speed of the control response and the size of the
changes in the controller output at the same time. It is also possible to change
parameter ω to select diﬀerent overshoots. The left side of the equation system

100
4 Self-tuning PID Controllers
in this controller is similar to that of system (4.127), the vector elements on
the right side are given by relations
x1 = c + 1 −a1
x2 = d + a1 −a2
x3 = f + a2
x4 = g
(4.130)
where
c = −4α
d = 6α2 + ω2
f = −2α(2α2 + ω2)
g = α2(α2 + ω2)
(4.131)
The relations for calculating the controller parameters are again given in
Table 4.3, while the relations to calculate the auxiliary variables needed to
determine the controller parameters take the form
s1 = a2[(b1 + b2)(a1b2 −a2b1) + b2(b1d2 −b2d1 −b2)]
r1 = (b1 + b2)(a1b1b2 + a2b2
1 + b2
2)
r2 = x1(b1 + b2)(a1b2 −a2b1)
r3 = b2
1x4 −b2[b1x3 −b2(x1 + x2)]
r4 = a1[b2
1x4 + b2
2x1 −b1b2(x2 + x3)]
r5 = (b1 + b2)[a2(b1x2 −b2x1) −b1x4 + b2x3]
r6 = b1(b2
1x4 −b1b2x3 + b2
2x2) −b3
2x1
(4.132)
Example 4.1. Consider three controlled processes described by the following
continuous-time transfer functions:
(a) Stable GA(s) =
1
(5s+1)(10s+1)
(b) With nonminimum phase GB(s) =
1−4s
(4s+1)(10s+1)
(c) Unstable GC(s) =
s+1
(2s−1)(4s+1)
Let us now discretize them with a sampling period T0 = 2 s
GA(z) =
0.0329z−1 + 0.0269z−2
1 −1.4891z−1 + 0.5488z−2
GB(z) =
−0.1017z−1 + 0.1730z−2
1 −1.4253z−1 + 0.4966z−2
GC(z) =
−0.6624z−1 + 0.0137z−2
1 −3.3248z−1 + 1.6487z−2
Depict step responses for the particular transfer functions and design ap-
propriate PID–A1 type controllers. Verify dynamic behaviour of the closed
loop systems by simulation for step changes of the reference signal w(k) with
ξ = 1 and ωn = 0.45.
(a) The model GA(z):
The step response of the model GA(z) is shown in Figure 4.22. Using
Table 4.3 and Equation (4.120) we can derive the controller equation
u(k) = 32.97e(k)−39.14e(k−1)+12.06e(k−2)+0.409u(k−1)+0.591u(k−2)

4.7 Selected Algorithms for Self-tuning PID Controllers
101
0
20
40
60
80
100
0
0.2
0.4
0.6
0.8
1
1.2
1.4
Step response
Time [s] 
Figure 4.22. Step response of the model GA(z) – Example 4.1
0
50
100
150
0
0.2
0.4
0.6
0.8
1
y,w
0
50
100
150
−2
0
2
4
6
u
Time[s] 
Time[s] 
Figure 4.23. Example 4.1 – simulation results: control of the model GA(z)
Simulated control responses of the model GA(z) are shown in Figure 4.23.
(b) The model GB(z):
The step response of the model GB(z) is shown in Figure 4.24. The con-
troller output becomes
u(k) = 37.85e(k)−48.58e(k−1)+15.68e(k−2)−4.461u(k−1)+5.461u(k−2)
Simulated control responses of the model GB(z) are shown in Figure 4.25.
(c) The model GC(z):
The step response of the model GC(z) is shown in Figure 4.26. The con-
troller output is given by the equation
u(k) = 5.27e(k)−7.233e(k−1)+2.484e(k−2)+0.979u(k−1)+0.021u(k−2)

102
4 Self-tuning PID Controllers
0
20
40
60
80
100
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Step response
Time [s] 
Figure 4.24. Example 4.1 – step response of the model GB(z)
0
50
100
150
−1
−0.5
0
0.5
1
1.5
y,w
Time[s]
0
50
100
150
−2
0
2
4
6
u
Time[s]
Figure 4.25. Example 4.1 – simulation results: control of the model GB(z)
Simulated control responses of the model GC(z) are shown in Figure 4.27.
Example 4.2. Simulate control of the models used in the Example 4.1 using the
PID–A1 type controller with recursive identiﬁcation (self-tuning controller).
The sampling period is set to T0 = 2 s for all cases. Choose the initial pa-
rameter estimates as ˆΘT (0) = [0.1, 0.2, 0.1, 0.2] and the initial value of the
directional forgetting factor as ϕ(0) = 1. Depict the evolution of the param-
eter estimates vector ˆΘT (k), the directional forgetting factor ϕ(k) and the
prediction error ˆe(k). Simulate control of these models when using the con-
vergent initial parameter estimates ˆΘT (k) in k = 80.
Make a simulation program with use of the Listings 3.1, 3.2 and Table 4.3.
For computation of the controllers’ parameters using the Matlab R
⃝environ-
ment it is possible to apply the matrix Equation (4.127) and the expressions
(4.126),(4.128). Control responses, together with the parameter estimates and

4.7 Selected Algorithms for Self-tuning PID Controllers
103
0
2
4
6
8
10
0
20
40
60
80
Step response
Time [s] 
Figure 4.26. Example 4.1 – step response of the model GC(z)
0
50
100
150
0
0.2
0.4
0.6
0.8
1
y,w
Time[s]
0
50
100
150
−1.5
−1
−0.5
0
0.5
1
u
Time[s]
Figure 4.27. Example 4.1 – simulation results: control of the model GC(z)
the evolution of the directional forgetting factor with the prediction error are
shown in Figures 4.28–4.30.
Comparing these graphs we can clearly see the excellent eﬀect of a priori
information (the control process when using convergent estimates).
Structure of the PID–B Control Loop
The structure of this control loop with the block diagram illustrated in Fig-
ure 4.31 was designed by Ortega and Kelly [78]. Here, the controller equation
takes the form
U(z) = [βE(z) −Q′(z−1)Y (z)]
1
P(z−1)
(4.133)
and while the polynomial P(z−1) has the same form as polynomial (4.118)
for controller (4.119), the second polynomial Q′(z−1) takes the form

104
4 Self-tuning PID Controllers
0
50
100
150
0
0.5
1
1.5
2
y,w
Time[s]
0
50
100
150
−10
−5
0
5
10
u
Time[s]
Figure 4.28. (a) Example 4.2 – control variables without a priori information:
model GA(z)
0
50
100
150
−1.5
−1
−0.5
0
0.5
1
Time[s]
Parameter estimates
0
50
100
150
−0.5
0
0.5
1
Time[s]
Prediction error, fi
a2 
b1 
b2 
a1 
e 
fi 
Figure 4.28. (b) Example 4.2 – parameter estimates, directional forgetting factor
and prediction error: model GA(z)
Q′(z−1) = (1 −z−1)(q′
0 −q′
2z−1)
(4.134)
Substitution of polynomials (4.118) and (4.134) into Equation (4.133)
yields the following relation for the controller output
u(k) = −[(q′
0 + β)y(k) −(q′
0 + q′
2)y(k −1) + q′
2y(k −2)] −(γ −1)u(k −1)
+γu(k −2) + βw(k)
(4.135)
For the transfer function of the closed loop according to Figure 4.31 it is
possible to obtain the relation

4.7 Selected Algorithms for Self-tuning PID Controllers
105
0
50
100
150
0
0.5
1
1.5
y,w
Time[s]
0
50
100
150
−2
0
2
4
6
u
Time[s]
Figure 4.28. (c) Example 4.2 – control variables when using convergent estimates:
model GA(z), initial parameter estimates ˆΘT (80) = [−1.4953, 0.5571, 0.0338, 0.0281]
0
50
100
150
−2
−1
0
1
2
y,w
Time[s]
0
50
100
150
−20
−10
0
10
20
u
Time[s]
Figure 4.29. (a) Example 4.2 – control variables without a priori information:
model GB(z)
GW (z) = Y (z)
W(z) =
βB(z−1)
A(z−1)P(z−1) + B(z−1)[Q′(z−1) + β]
(4.136)
so the polynomial equation takes the form
A(z−1)P(z−1) + B(z−1)[Q′(z−1) + β] = D(z−1)
(4.137)
In the case of controlled system polynomials in the form (4.116), polyno-
mial Equation (4.137) deﬁnes a system of four linear algebraic equations with
four unknown controller parameters q′
0, q′
2, β and γ:

106
4 Self-tuning PID Controllers
0
50
100
150
−1.5
−1
−0.5
0
0.5
1
Time[s]
Parameter estimates
0
50
100
150
−0.5
0
0.5
1
Time[s]
Prediction error, fi
a2 
a1 
b2 
b1 
fi 
e 
Figure 4.29. (b) Example 4.2 – Parameter estimates, directional forgetting factor
and prediction error: model GB(z)
0
50
100
150
−1
−0.5
0
0.5
1
1.5
y,w
Time[s]
0
50
100
150
−2
0
2
4
6
u
Time[s]
Figure
4.29.
(c)
Example
4.2
–
control
variables
when
using
con-
vergent
estimates:
model
GB(z)
Initial
parameter
estimates
ˆΘT (80)
=
[−1.4283, 0.4996, −0.1018, 0.1732]
⎡
⎢⎢⎢⎢⎢⎢⎣
b1
0
b1
1
b2 −b1
−b1
b2 a1 −1
b2
b2 −b1 0 a1 −a2
0
b2
0
−a2
⎤
⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎣
q′
0
q′
2
β
γ
⎤
⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
x1
x2
x3
x4
⎤
⎥⎥⎥⎥⎥⎥⎦
(4.138)

4.7 Selected Algorithms for Self-tuning PID Controllers
107
0
50
100
150
−10
−5
0
5
y,w
Time[s]
0
50
100
150
−40
−20
0
20
40
u
Time[s]
Figure 4.30. (a) Example 4.2 – control variables without a priori information:
model GC(z)
0
50
100
150
−4
−2
0
2
Time[s]
Parameter estimates
0
50
100
150
−5
−2
0
2
5
Time[s]
Prediction error, fi
a2 
a1 
b1 
b2 
e 
fi 
Figure 4.30. (b) Example 4.2 – parameter estimates, directional forgetting factor
and prediction error: model GC(z)
PID–B1 Controller
This type of controller is obtained when the polynomial D(z−1) in polyno-
mial Equation (4.137) is substituted by the relation (4.125) and the vector
components on the right side of system Equation (4.138) are
x1 = d1 + 1 −a1
x2 = d2 + a1 −a2
x3 = −a2
x4 = 0
(4.139)
By solving Equation system (4.138) we obtain the relations to calculate
the controller parameters (see Table 4.4); variables d1 and d2 are calculated
using relations (4.126).

108
4 Self-tuning PID Controllers
0
50
100
150
0
0.2
0.4
0.6
0.8
1
y,w
Time[s]
0
50
100
150
−1
−0.5
0
0.5
1
1.5
u
Time[s]
Figure
4.30.
(c)
Example
4.2
–
control
variables
when
using
con-
vergent
estimates:
model
GC(z),
initial
parameter
estimates
ˆΘT (80)
=
[−3.3246, 1.6481, −0.6628, −0.0138]
y(k)
B(z )
-1
A(z )
-1
1
P(z )
-1
u(k)
e(k)
w(k)

Q'(z )
-1
Figure 4.31. Block diagram of the control loop for a PID–B controller
Table 4.4. Relations to calculate PID–B controller parameters
Controller parameters
PID–B1
PID–B2
q′
0
q′
2( b1
b2 −a1
a2 ) −a2
b2
−r2−r3+r4
r1
q′
2
s1
r1
r6+r7
r1
γ
q′
2
b2
a2
r5
r1
β
1
b1 (d1 + 1 −a1 −γ −b1q′
0) x1+x2−x3+x4
b1+b2
PID–B2 Controller
The parameters for this type of a controller are obtained by inserting ap-
propriately modiﬁed relation (4.129) as polynomial D(z−1) into polynomial
Equation (4.137), where the vector components on the right side of Equation

4.7 Selected Algorithms for Self-tuning PID Controllers
109
system (4.138) is given by
x1 = c + 1 −a1
x2 = d + a1 −a2
x3 = −f −a2
x4 = g
(4.140)
and relations (4.131) are valid. In this case, by solving Equation system
(4.138), we also obtain the equations for calculating the controller param-
eters given in Table 4.4 where the formulas to compute the auxiliary variables
needed to determine the controller parameters take the form
s1 = a2{b2[a1(b1 + b2) + b1(d2 −a2) −b2(d1 + 1)] −a2b2
1}
r1 = (b1 + b2)(a1b1b2 −a2b2
1 −b2
2)
r2 = a1b2[b1(x2 −x3 + x4) −b2x1]
r3 = a2b1[b2x1 −b1(x2 −x3 + x4)]
r4 = (b1 + b2)[b1x4 + b2(x3 −x4)]
r5 = b1(b2
1x4 + b1b2x3 + b2
2x2) −b3
2x1
r6 = b2
1(a2x3 + a1x4 −a2x4)
r7 = b2[b1(a1x4 + a2x2 −x4) −b2(a2x1 + x4)]
(4.141)
4.7.4 Digital PID Controllers Based on the Modiﬁed
Ziegler–Nichols Criterion
The experimental tuning of parameters for a continuous-time PID controller
designed by Ziegler and Nichols [103] more than half a century ago is still used
today in industrial practice. In this well-known and popular approach the PID
controller parameters are calculated from the critical (ultimate) proportional
gain KPu and the critical (ultimate) period of oscillations Tu of a closed
loop. These critical parameters are obtained by gradually increasing the gain
of the proportional controller until the output of the closed loop oscillates
at constant amplitude, i.e. the control loop is at the stability boundary. In
this case the poles of the closed loop are placed on the imaginary axis of
a complex s-plane. Then both, the proportional critical gain KPu and the
critical period of oscillations Tu are recorded. The parameters of the PID
controller are determined by the relations
KP = 0.6KPu
TI = 0.5Tu
TD = 0.125Tu
(4.142)
The following relations are recommended to calculate the parameters for
PID controller (3.38) [56]
KP = 0.6KPu

1 −T0
Tu

TI = KP Tu
1.2KPu
TD = 3KPuTu
40KP
(4.143)
The disadvantage of experimentally determining the critical parameters
is that the system can be brought to a state of instability, and the ﬁnding

110
4 Self-tuning PID Controllers
stability boundary in systems with large time constants can be very time-
consuming. The modiﬁed method given below for tuning a digital PID con-
troller avoids this problem.
When discretizing a control loop, the continuous-time controller output is
modiﬁed to the form of a step function using a sample and hold unit. Then
the step function can approximate the original continuous-time signal delayed
by half of a sampling period T0. More simply, we can assume that the system’s
discrete model diﬀers from the continuous-time model in that it includes an
extra time delay of T0/2. The time delay does not change amplitude but
linearly increases the phase shift as the frequency grows.
ϕ = −T0ω
2
(4.144)
At critical frequency ωu the system has phase shift ϕ = −π and gain Au,
validating
AuKPu = −1
(4.145)
In discrete control the eﬀects of phase shift ϕ caused by discretization
changes the critical frequency and, since the system has diﬀerent gain at
diﬀerent frequencies, critical gain will also change. The critical values depend
on the sampling period chosen and this will be referred to as function T0, i.e.
KPu(T0) and Tu(T0).
Calculating the Critical Parameters for an n-th order Model
Assume the discrete transfer function of the controlled process taking the form
GP (z) = Y (z)
U(z) = z−dB(z−1)
A(z−1)
(4.146)
with polynomials
A(z−1) = 1 +
n

i=1
aiz−i = 1 + a1z−1 + a2z−2 + . . . + anz−n
(4.147)
B(z−1) =
n

i=1
biz−i = b1z−1 + b2z−2 + . . . + bnz−n
(4.148)
where d is the number of time delay intervals. Next, consider the discrete
transfer function of a proportional controller
GR(z) = U(z)
E(z) = KP
(4.149)
The transfer function of the closed loop, illustrated as a block diagram in
Figure 4.20, then takes the form

4.7 Selected Algorithms for Self-tuning PID Controllers
111
Gw(z) = Y (z)
W(z) =
GP (z)GR(z)
1 + GP (z)GR(z) =
z−dKpB(z−1)
A(z−1) + z−dKpB(z−1)
(4.150)
The denominator of transfer function (4.150) is the characteristic polyno-
mial
D(z−1) = A(z−1) + z−dKpB(z−1)
(4.151)
the poles of which determine the dynamic behaviour of the closed loop. It is
clear that the closed loop will be at the stability boundary if at least one of the
poles of the characteristic polynomial (4.151) is placed on the unit circle and
the others are inside it. This meets condition KP = KPu(T0). There are two
possible positions for pole assignment of the characteristic polynomial on the
unit circle (Figure 4.32) may occur so that the control loop is on the stability
boundary.
•
The characteristic polynomial (4.151) has a pair of complex conjugate
poles z1,2 = α ± jβ, for which α2 + β2 = 1. Thus, the appropriate part of
the characteristic polynomial can be expressed as a product of root factors
D1(z) = (z −z1)(z −z2) = z2 −2αz + 1
(4.152)
•
The characteristic polynomial (4.151) has one or more real poles zj = αj =
−1; (βj = 0) so that the appropriate part of the characteristic polynomial
can be expressed in the form
D2(z) = (z + 1)j
(4.153)
Re
Im
1
-1
z1
z2
-j
j


T0K
Figure 4.32. Placement of critical poles on the unit circle
In the ﬁrst case, characteristic polynomial (4.151) must be divisible by
polynomial (4.152), which leads to the solution of the polynomial equation
zn+d 
A(z−1) + z−dKPu(T0)B(z−1)

= (z2 −2αz +1)zn+d−2E(z−1) (4.154)

112
4 Self-tuning PID Controllers
where
E(z−1) = 1 +
n+d−2

i=1
eiz−i
(4.155)
and KPu(T0), α and ei are the unknown parameters of polynomial Equation
(4.154).
The following polynomial equation can be obtained for the second case
zn+d 
A(z−1) + z−dKPu(T0)B(z−1)

= (z + 1)jzn+d−jF(z−1)
(4.156)
where
F(z−1) = 1 +
n+d−j

i=1
fiz−i
(4.157)
and KPu(T0), fi are the unknown parameters of polynomial Equation (4.156).
In both cases the solution with KPu(T0) > 0 is chosen, which does not contain
unstable poles.
Rather than solve Equation (4.146) it is possible to calculate critical gain
KPu(T0) in a more simple way. For the pole α = −1 the oscillating compo-
nent is created by the term (−1)k, which corresponds to the continuous-time
function cos π
T0
t. Here, the critical frequency is given by the relation
ωu = π
T0
(4.158)
If we insert critical frequency ωu (according to Equation (4.158)) into the
deﬁning relation of the z-transform
z = ejωT0 = cos ωT0 + j sin ωT0
(4.159)
then the solution to Equation (4.159) is z = −1. As a result, critical gain is
calculated using equation
KPu(T0) = −
1
GP (z−1) = −
1
GP (−1)
(4.160)
Solving equations (4.154) and (4.156) using the method of uncertain coef-
ﬁcients for n + d > 3 involves fairly complicated calculations so it is advisable
to use a numeric method to solve the polynomial equation.
Again, calculation of the critical period of oscillations depends on place-
ment of the poles on the unit circle in the complex z-plane. It is clear from
Figure 4.32 that the critical period of oscillations can be computed from the
relations
cos(T0ωu) = α
ωu = 1
T0
arccosα
Tu(T0) = 2π
ωu
(4.161)
Obviously, for real critical poles zj = −1, the following formulas for the
critical period of oscillations are valid

4.7 Selected Algorithms for Self-tuning PID Controllers
113
cos(T0ωu) = −1
ωu = π
T0
Tu(T0) = 2T0
(4.162)
Using the uniﬁed approach given above it is also possible to derive algorithms
for control systems with time delay. This of course holds only for lower-order
systems with few time delay steps, since with each increase in the order of the
system or number of time delay steps there is an increase in the degree of the
characteristic polynomial (4.151).
Now, let us derive the relations to calculate the critical proportional gain
for the ﬁrst- to third-order models. It will be shown that for second-order mod-
els it is possible to compute the critical parameters using other approaches.
Calculating Critical Gain for First-order Models
Let the process be described by a ﬁrst-order model (n = 1, d = 0 in Equations
(4.146)–(4.148)). Characteristic polynomial (4.151) then takes the form
D(z) = z + a1 + KP b1
(4.163)
When using a ﬁrst-order model only one critical real pole can exist and so
polynomial Equation (4.156) becomes
z + a1 + KPu(T0)b1 = z + 1
(4.164)
where the critical gain is given by the relation
KPu(T0) = 1 −a1
b1
(4.165)
Calculating Critical Gain for Second-order Models
There are several methods for deriving the relations to calculate the critical
gain.
Uniﬁed Approach
Let the process be described by a second-order model (n = 2, d = 0 in Equa-
tions (4.146)–(4.148)). Characteristic polynomial (4.151) then takes the form
D(z) = z2 + (a1 + b1KP)z + (a2 + b2KP )
(4.166)
In the ﬁrst case, i.e. when considering polynomial Equation (4.154), this
equation, as applied to a second-order model, will take the form
z2  
1 + a1z−1 + a2z−2 + KPu(T0)[b1z−1 + b2z−2]
!
= z2 −2αz + 1 (4.167)
By comparing the coeﬃcients of the same power of z, it is possible to
obtain the two equations

114
4 Self-tuning PID Controllers
a1 + KPu(T0)b1 = −2α
a2 + KPu(T0)b2 = 1
(4.168)
Then, the relations to calculate critical gain and real parts of the complex
conjugate pole are obtained from the equations above and have the form
KPu(T0) = 1 −a2
b2
α = a2b1 −a1b2 −b1
2b2
(4.169)
In the second case, i.e. when considering polynomial Equation (4.156), the
equation for a second-order model takes the form
z2{1+a1z−1+a2z−2+KPu(T0)[b1z−1+b2z−2]} = (z+1)z(1+f1z−1) (4.170)
In the same way as in the previous example we obtain two equations
a1 + KPu(T0)b1 = 1 + f1
a2 + KPu(T0)b2 = f1
(4.171)
deﬁning the critical gain
KPu(T0) = a1 −a2 −1
b2 −b1
(4.172)
The relation can also be derived from Equation (4.160).
The critical gain is calculated either from Equation (4.169) or (4.172)
depending on the condition
b2 −4c < 0
(4.173)
where expression (4.173) is the discriminant of the characteristic equation
z2 + (a1 + b1KP )z + (a2 + b2KP ) = 0
(4.174)
with notation
b = a1 + b1KP
c = a2 + b2KP
(4.175)
A ﬂow diagram for calculation of the controller parameters for a second-
order system is illustrated in Figure 4.33. The Matlab R
⃝code of this algo-
rithm is given in Listing 4.1.
Complex Analysis of the Placement of Critical Poles in the z-Plane
If we denote characteristic polynomial
D(z) = z2 + bz + c
(4.176)
with coeﬃcients as in (4.175), there are four possibilities for pole assignment
of the second-order characteristic polynomial so that the closed loop is on the
stability boundary (Figure 4.34):

4.7 Selected Algorithms for Self-tuning PID Controllers
115
0
d <
1
P
Pu
K
K
=
0
d =
0
1
2T
T
K
K
u
P
Pu
=
=
0
2
2T
T
K
K
u
P
Pu
=
=
YES
 YES 
 NO 
   NO
u
u
u
P
P
P
P
T
T
b
-
c
b
d
a
K
b
c
a
K
b
b
b
b
a
a
K
b
a
K
ω
π
2
α
arccos
1
ω
2
α
4
1
1
0
2
2
1
2
1
1
1
1
2
2
1
2
2
2
1
=
=
=
−
=
+
=
+
=
−
−
−
=
−
=
START
END
Figure 4.33. Flow diagram for the calculation of critical parameters for a second-
order system
(a) The characteristic polynomial (4.176) has a pair of complex conjugate
poles z1,2 = α ± jβ (Figure 4.34a)) where the formula α2 + β2 = 1 holds.
Then, the characteristic polynomial (4.176) can be expressed as a product
of root factors
D(z) = (z −z1)(z −z2)
(4.177)
Substitution of z1,2 = α±jβ and α2 +β2 = 1 into Equation (4.177) yields

116
4 Self-tuning PID Controllers
Listing 4.1. Calculation of critical parameters for a second-order system
%Calculation of critical parameters for a 2nd-order system
Kp1=(1-a2)/b2; Kp2=(a1-a2-1)/(b2-b1);
bb=b1*Kp1+a1; cc=b2*Kp1+a2;
dd=bb*bb-4*cc; alfa=-bb/2;
if alfa>1
omegau=(1/T0)*acos(.99);
%critical frequency
elseif alfa<-1
omegau=(1/T0)*acos(-1);
else
omegau=(1/T0)*acos(alfa);
end
Tu=(2*pi)/omegau; %critical period of oscillations
if dd<0
Kpu=Kp1; %critical gain
elseif dd==0
Kpu=Kp1; Tu=2*T0;
else
Kpu=Kp2;
Tu=2*T0;
end
D(z) = (z−α−jβ)(z−α+jβ) = z2−2αz+α2+β2 = z2−2αz+1 (4.178)
Comparing Equations (4.176) and (4.178) it follows that b = −2α (there-
fore α = −b/2) and c = 1. Assuming KP = KPu(T0) and replacing the
variable c from Equation (4.175) with
a2 + b2KPu(T0) = 1
(4.179)
it is possible to obtain a relation to calculate critical gain and a formula
for the real part of complex conjugate pole (4.169).
(b) The characteristic polynomial (4.176) has a double real pole z3,4 = α
(imaginary part β = 0) – Figure 4.34b. The control loop is on the stability
boundary only in the case when α = −1, because the positive real pole α =
1 will not cause the control loop to oscillate. As a result, the characteristic
polynomial (4.176), expressed as a product of root factors, now takes the
form
D(z) = (z + 1)2 = z2 + 2z + 1
(4.180)
Since c = 1, therefore relation (4.169) can again be used for computing
critical gain KPu(T0).
(c) The characteristic polynomial (4.176) has only imaginary poles z5,6 = ±j
(real component α = 0 – Figure 4.34c) so the characteristic polynomial
(4.176) takes the form
D(z) = (z + j)(z −j) = z2 + 1
(4.181)

4.7 Selected Algorithms for Self-tuning PID Controllers
117
It is clear from Equation (4.181) that b = 0 and c = 1, therefore the ﬁrst
relation for the calculation of KPu (4.169) is also valid.
(d) Characteristic polynomial (4.176) has one pole z7 = −1 and a second real
pole |z8| < 1 (a stable pole inside the unit circle – Figure 4.34d). The
characteristic polynomial (4.176) can again be expressed as a product of
root factors
D(z) = (z + 1)(z −z8)
(4.182)
It follows from Equations (4.176) and (4.182) that the characteristic poly-
nomial (4.176) should be divisible by the factor z + 1 without any remain-
der. Since the following relation
z2 + bz + c
z + 1
= z + b −1 + 1 −b + c
z + 1
(4.183)
holds, the condition of zero remainder is fulﬁlled in the case
1 −b + c = 0
(4.184)
Upon substituting from Equation (4.175) for the variables b and c and
KP = KPu(T0) into Equation (4.184), it yields
1 −a1 −KPu(T0)b1 + a2 + KPu(T0)b2 = 0
(4.185)
and after some manipulations, relation (4.172) is obtained. The pole z8 =
1 −b lies inside the unit circle.
The critical gain KPu(T0) is then computed either from the ﬁrst relation
of Equations (4.169) or from Equation (4.172) according to fulﬁlment of the
condition (4.173). It is obvious that when satisfying the condition (4.173),
the characteristic polynomial (4.176) has its poles situated according to (a),
(b) or (c). Therefore, for the computation of KPu(T0) the ﬁrst relation of
equations (4.169) is used. If condition (4.173) is not fulﬁlled, the characteristic
polynomial (4.176) has its poles situated according to (d) and KPu(T0) is
computed according to relation (4.172).
Derivation Using Bilinear Transformation
It is possible to achieve the same relations using bilinear transformation
z = w + 1
w −1
(w = α + jβ)
(4.186)
where the unit circle in the z-plane transforms into the imaginary axis of the
w-plane so that point (−1; 0) in the z-plane corresponds to point (0; 0) of
the w-plane. The introduction of transformation (4.186) into characteristic
Equation (4.174) yields quadratic equation
w2(1 + b + c) + w(2 −2c) + 1 −b + c = 0
(4.187)

118
4 Self-tuning PID Controllers
Re
Im
-j
j
1
z3, 4= -1
Re
Im
1
-1
z
j
5=
z
-j
6=
Re
(a)
1
-1
z1
z2
-j
j


Re
Im
-j
j
1
z7= -1
z8
(b)
(c)
(d)
Figure 4.34. Placement of critical poles for a second-order model
With regard to stability, Equation (4.187) can be solved using a well-
known method from the theory of continuous-time systems. A continuous-time
control loop is at the stability boundary if roots of characteristic Equation
(4.187) lie on the imaginary axis of the w complex plane, i.e. when α = 0.
Then Equation (4.187) takes a form
−β2(1 + b + c) + jβ(2 −2c) + 1 −b + c = 0
(4.188)
and can be separated into real and imaginary parts
−β2(1 + b + c) + 1 −b + c = 0
(4.189a)
β (1 −c) = 0
(4.189b)
Equation (4.189) has two solutions:
•
1 −c = 0, from which it follows that c = 1 and by inserting this into
the second Equation of (4.175) it is possible to obtain the ﬁrst relation of
Equation (4.169) to calculate the critical gain;
•
β = 0, which can be put into Equation (4.189a) to obtain formula (4.184)
so that the relation to calculate the critical gain (4.172) holds.
A demonstration of the algorithm for this kind of a self-tuning controller is
presented here. The ARX model in the form (3.10) is used in the identiﬁcation

4.7 Selected Algorithms for Self-tuning PID Controllers
119
part of the control algorithm, where
ˆΘT (k) =

ˆa1, ˆa2,ˆb1,ˆb2

(4.190)
is the parameter estimates vector and
φT (k −1) = [−y(k −1), −y(k −2), u(k −1), u(k −2)]
(4.191)
is the regression vector.
As an example, the Takahashi controller (4.38) is
used, which can be modiﬁed to the form below
u(k) = KR[y(k −1) −y(k)] + KI[w(k) −y(k)]
+KD[2y(k −1) −y(k −2) −y(k)] + u(k −1)
(4.192)
where
KR = 0.6KPu −KI
2
KI = 1.2KPuT0
Tu
KD = 3KPuTu
40T0
(4.193)
are the adjustable components of a digital PID controller taken from [56]. If
we introduce the following notation for the individual elements of regression
vector (4.191)
d1 = y(k −1),
d2 = y(k −2),
d3 = u(k −1),
d4 = u(k −2)
then Equation (4.192) can be rewritten into the form
u(k) = KR[d1 −y(k)] + KI[w(k) −y(k)] + KD[2d1 −d2 −y(k)] + d3 (4.194)
It is clear from the ﬁrst relation of Equations (4.169) that division by zero
will occur when ˆb2 = 0 and this will also happen in relation (4.172) for ˆb1 = ˆb2.
It is also necessary to take into account the fact that the second relation of
Equation (4.161) must meet condition
α =
−b
2
 ≤1
(4.195)
The algorithm of this controller now consists of the following steps per-
formed at each sampling period:
Step 1. Parameter estimates of the process model (4.190).
Step 2. If parameter estimate ˆb2 is less than machine zero or if ˆb1 = ˆb2, use
the previous parameter estimate ˆb2.
Step 3. Calculation of critical gain KPu(T0) and critical period Tu(T0) (see
the ﬂow diagram, Figure 4.30). If α < −1 set α = −1; if α > 1, set α = 1 (see
relation (4.195).
Step 4. Calculation of digital PID controller parameters according to relations
(4.193).

120
4 Self-tuning PID Controllers
Step 5. Calculation of controller output according to relation (4.194).
Step 6. Limiting controller output u(k) with respect to the actuator con-
straints and technological conditions.
Step 7. Cyclic exchange of the data in regression vector (4.191)
d4 = d3,
d2 = d1,
d3 = u(k),
d1 = −y(k)
Example 4.3. For the models used in the Example 4.1 design controllers based
on the modiﬁed Ziegler–Nichols method. Verify by simulation the dynamic
behaviour of the closed loops using the Takahashi controller (4.192), (4.193)
for step changes of the reference signal w(k).
Using the diagram in Figure 4.33 or the Listing 4.1 it is possible to calculate
appropriate critical parameters KP 1(2) and KP 2(2). Consequently we can
calculate the critical gain Ku(2) and the critical period of oscillation Tu(2).
(a) The model GA(z):
The critical parameters are: KP 1(2) = 16.7732; KP 2(2) = 506.3172;
Ku(2) = 16.7732; Tu(2) = 11.6027. The controller output is given by
the equation
u(k) = 8.3292[y(k −1) −y(k)] + 3.4695[w(k) −y(k)]
+7.2980[2y(k −1) −y(k −2) −y(k)] + u(k −1)
Simulation results of the control of the model GA(z) are shown in Fig-
ure 4.35.
0
50
100
150
0
0.5
1
1.5
y,w
Time[s]
0
50
100
150
−2
0
2
4
6
u
Time[s]
Figure 4.35. Example 4.3 – simulation results: control of the model GA(z)
(b) The model GB(z):
The critical parameters are: KP 1(2) = 2.2098; KP 2(2) = −10.6367;
Ku(2) = 2.9098; Tu(2) = 23.5184. The controller output is given by

4.7 Selected Algorithms for Self-tuning PID Controllers
121
u(k) = 1.5974[y(k −1) −y(k)] + 0.2969[w(k) −y(k)]
+2.5663[2y(k −1) −y(k −2) −y(k)] + u(k −1)
Simulation results for the model GB(z) are shown in Figure 4.36.
0
50
100
150
−0.5
0
0.5
1
1.5
y,w
Time[s]
0
50
100
150
0
0.5
1
1.5
u
Time[s]
Figure 4.36. Example 4.3 – simulation results: control of the model GB(z)
(c) The model GC(z):
Control of the model GC(z) is unstable.
Example 4.4. Simulate control of the models GA(z) and GB(z) used in the
Example 4.1 employing a self-tuning controller based on the modiﬁed Ziegler–
Nichols method. Verify by simulation the dynamic behaviour of the closed
loops using the Takahashi controller (4.192), (4.193). The sampling period for
both cases is T0 = 2 s. Choose the initial estimates of model parameters as
ˆΘT (0) = [0.1, 0.2, 0.1, 0.2] and the initial value of the directional forgetting
factor as ϕ(0) = 1. Simulate also control of these models when using the
convergent initial parameter estimates ˆΘT (k) in k = 80. Design a simulation
program using the Listings 3.1, 3.2 and 4.1. Simulation results for models
GA(z) and GB(z) are shown in Figures 4.37 and 4.38.
The Matlab R
⃝program for control of the model GA(z) is given in List-
ing 4.2.
Calculating Critical Gain for Third-order Models
The relations needed to calculate critical gain in a process described by a
third-order model (n = 3, d = 0 in Equations (4.146)–(4.148)) can be derived
similarly to those in previous sections. Here, only the uniﬁed approach is

122
4 Self-tuning PID Controllers
Listing 4.2. Self-tuning Takahashi controller for a second-order model
%Simulation verification of self-tuning Takahashi controller
%G(s)=1/(5s+1)(10s+1)
%Controlled continuous-time model
T0=2;
%Sampling period
A1=-1.4891; A2=0.5488;
B1=0.0329; B2=0.0269;
[d,theta,c,ro,fi,la,ny,u]=inidedf;
%Initialization
D=zeros(4,1);
%[y(k-1), y(k-2), u(k-1), u(k-2)]
w=1;
% Choice of reference signal
for k=1:80
if k==25
w=0.5;
elseif k==50
w=1;
end
steps(k)=k;
y(k)=-A1*D(1)-A2*D(2)+B1*D(3)+B2*D(4);
%Simulation
% Recursive identification
[fi,theta,d,c,la,ny,ep,te,ks,pp]
=identdf(fi,theta,d,c,la,ny,D(3),y(k),ro);
% Parameter estimates
a1=theta(1); a2=theta(2); b1=theta(3); b2=theta(4);
Kp1=(1-a2)/b2;
Kp2=(a1-a2-1)/(b2-b1);
%critical param. computation
bb=b1*Kp1+a1;
cc=b2*Kp1+a2;
dd=bb*bb-4*cc;
alfa=-bb/2;
if alfa>1
omegau=(1/T0)*acos(.99);
elseif alfa<-1
omegau=(1/T0)*acos(-1);
else
omegau=(1/T0)*acos(alfa);
end
Tu=(2*pi)/omegau;
if dd<0
Kpu=Kp1; %critical gain
elseif dd==0
Kpu=Kp1;
Tu=2*T0;
else
Kpu=Kp2;
Tu=2*T0;
end
kp=0.6*Kpu*(1-T0/Tu);
%controller
ki=1.2*Kpu*T0/Tu;
kd=3*Kpu*Tu/(40*T0);
u(k)=kp*(D(1)-y(k))+ki*(w-y(k))+kd*(2*D(1)-D(2)-y(k))+D(3);
% Cyclic date substitution in process model
D(2)=D(1);
D(1)=y(k);
D(4)=D(3);
D(3)=u(k);
ww(k)=w;
%save control loop variables
aa1(k)=a1; aa2(k)=a2; bb1(k)=b1; bb2(k)=b2;
ff(k)=fi; eep(k)=ep;
end;
plot(steps,y,’m’, steps,u,’r’, steps,ww,’g’);
figure;
plot(steps,aa1,’m’,steps,aa2,’r’,steps,bb1,’g’,steps,bb2,’b’);

4.7 Selected Algorithms for Self-tuning PID Controllers
123
0
50
100
150
−0.5
0
0.5
1
1.5
y,w
Time[s]
0
50
100
150
−1
0
1
2
3
4
u
Time[s]
Figure 4.37. (a) Example 4.4 – control variables without a priori information:
model GA(z)
0
50
100
150
−0.5
0
0.5
1
1.5
y,w
Time[s]
0
50
100
150
0
0.5
1
1.5
u
Time[s]
Figure 4.37. (b) Example 4.4 – control variables when using convergent estimates:
model GA(z), initial parameter estimates ˆΘT (80) = [−1.5060, 0.5673, 0.0307, 0.0307]
employed, although in this case it is also possible to use bilinear transformation
methods. Characteristic polynomial (4.151) has the form
D(z) = z3 + (a1 + b1KP)z2 + (a2 + b2KP )z + a3 + b3KP
(4.196)
In the ﬁrst case, i.e. when considering polynomial Equation (4.154), the
equation for KP = KPu(T0), when applied to a third-order model, takes the
form
z3{1 + a1z−1 + a2z−2 + a3z−3 + KPu(T0)[b1z−1 + b2z−2 + b3z−3]}
= (z2 −2αz + 1)z(1 + e1z−1)
(4.197)

124
4 Self-tuning PID Controllers
0
50
100
150
−0.5
0
0.5
1
1.5
y,w
Time[s]
0
50
100
150
−1
0
1
2
3
4
u
Time[s]
Figure 4.38. (a) Example 4.4 – control variables without a priori information:
model GB(z)
0
50
100
150
−0.5
0
0.5
1
1.5
y,w
Time[s]
0
50
100
150
0
0.5
1
1.5
u
Time[s]
Figure
4.38.
(b)
Example
4.4
–
Control
variables
when
using
con-
vergent
estimates:
model
GB(z),
initial
parameter
estimates
ˆΘT (80)
=
[−1.4345, 0.5118, −0.1043, 0.1817]
By comparing coeﬃcients at the same power of z, it is possible to obtain
three equations with three unknowns KPu(T0), α and e1
a1 + b1KPu(T0) = −2α + e1
a2 + b2KPu(T0) = 1 −2αe1
a3 + b3KPu(T0) = e1
(4.198)
Equation (4.198) has the following solution
KP 1,2(T0) = −r1 ±
√
d
2r2
α = a3 −a1 + KPu(T0)[b3 −b1]
2
(4.199)

4.7 Selected Algorithms for Self-tuning PID Controllers
125
(
)
(
)
(
)
2
0
2
1
1
3
3
2
1
3
2
1
3
3
1
2
1
3
3
0
4
2
1
r
r
r
d
b
-
b
b
r
b
a
-
b
a
a
b
r
a
a
a
a
r
−
=
=
+
−
=
−
+
−
=
START
0
d <
2
3
3
12
1
3
3
11
3
2
1
3
2
1
3
2
1
2
1
1
2
P
P
P
,
P
K
b
a
e
K
b
a
e
b
b
b
a
a
a
K
r
d
r
K
+
=
+
=
+
−
−
+
−
=
±
−
=
1
1
0
11
1
<
∧
>
e
KP
1
0
12
2
<
∧
>
e
KP
2
P
Pu
K
K
=
0
3
2T
T
K
K
u
P
Pu
=
=
0
d=
(
)
u
u
u
Pu
T
T
b
b
K
a
a
ω
π
2
α
arccos
1
ω
2
α
0
1
3
1
3
=
=
−
+
−
=
END
    
YES
YES
NO
NO
NO
YES
1
1
P
Pu
K
K
=
Figure 4.39. Flow diagram of the calculation of critical parameters for a third-order
model
where
r0 = a3(a3 −a1) + a2 −1
r1 = b3(2a3 −a1) + b2 −a3b1;
r2 = b3(b3 −b1)
d = r2
1 −4r0r2
(4.200)
and the last relation of Equation (4.198) is used to calculate e1. Then, the
solution which satisﬁes following inequalities
KPu(T0) > 0
|e1| < 1
(4.201)
is taken. If conditions (4.201) are not met either for KP 1(T0) or KP 2(T0),
Equation (4.156) must be used to calculate the critical gain. For a third-order
model this takes the form
z3{1 + a1z−1 + a2z−2 + a3z−3 + KPu(T0)[b1z−1 + b2z−2 + b3z−3]}
= (z + 1)z2(1 + f1z−1 + f2z−2)
(4.202)
Comparing coeﬃcients at the same power of z yields the following three
equations

126
4 Self-tuning PID Controllers
a1 + b1KPu(T0) = 1 + f1
a2 + b2KPu(T0) = f1 + f2
a3 + b3KPu(T0) = f2
(4.203)
and by solving these, a relation for critical gain is obtained as follows
KPu(T0) = 1 −a1 + a2 −a3
b1 −b2 + b3
(4.204)
The relation (4.204) can also be obtained by solving Equation (4.160). A
ﬂow diagram showing the calculation of controller parameters is given in Fig-
ure 4.39, and Matlab R
⃝code is given in Listing 4.3.
The algorithm of this self-tuning controller has a similar structure to that
of a second-order model. Again, the ARX model in form (3.10) is used in the
identiﬁcation part, where the vector of parameter estimates for the process
model has the form
ˆΘT (k) =

ˆa1, ˆa2, ˆa3,ˆb1,ˆb2,ˆb3

(4.205)
and
φT (k −1) = [−y(k −1), −y(k −2), −y(k −3), u(k −1), u(k −2), u(k −3)]
(4.206)
is the regressor.
Example 4.5. Consider a continuous-time transfer function as a model of a
controlled process
GD(s) =
1
(0.5s + 1)(s + 1)(2s + 1)
Then its discrete version for the sampling period T0 = 1 s has the form
GD(z) =
0.0706z−1 + 0.1416z−2 + 0.0136z−3
1 −1.2747z−1 + 0.5361z−2 + 0.0302z−3
Design a controller based on the modiﬁed Ziegler–Nichols method. Verify
by simulation dynamic behaviour of the closed loop using Takahashi con-
troller (4.192), (4.193) for step changes of the reference signal w(k). Using
the ﬂow diagram in Figure 4.37 or the Listing 4.3 we can calculate appro-
priate critical parameters KP 1(1), KP 2(1) and KP 3(1). Consequently, we can
compute the critical gain Ku(1) and the critical period of oscillations Tu(1).
Then, the critical parameters have these values: KP 1(1) = 3.1782; KP 2(1) =
203.5381; KP 3(1) = −49.4948; Ku(1) = 3.1783; Tu(1) = 11.6027 and the con-
troller output is computed from equation

4.7 Selected Algorithms for Self-tuning PID Controllers
127
Listing 4.3. Calculation of critical parameters for a third-order system
%Calculation of critical gain Kpu
r2=b3*(b3-b1); r1=b3*(2*a3-a1)+b2-a3*b1; r0=a3*(a3-a1)+a2-1;
dd=r1*r1-4*r0*r2;
if dd<0
dd=0;
end
Kp1=(-r1+sqrt(dd))/(2*r2);
Kp2=(-r1-sqrt(dd))/(2*r2);
Kp3=(a1+a3-a2-1)/(b2-b1-b3);
Kpu=Kp1;
aa=b1*Kpu+a1;
bb=b2*Kpu+a2; cc=b3*Kpu+a3;
pp=bb-aa*aa/3; qq=(2*aa*aa*aa/27)-(aa*bb/3)+cc;
qq1=(qq/2)*(qq/2); pp1=(pp/3)*(pp/3)*(pp/3);
DD=qq1+pp1;
if DD<=0
Kpu=Kp2;
aa=b1*Kpu+a1; bb=b2*Kpu+a2; cc=b3*Kpu+a3;
pp=bb-aa*aa/3; qq=2*aa*aa*aa/27-aa*bb/3+cc;
qq1=(qq/2)*(qq/2); pp1=(pp/3)*(pp/3)*(pp/3);
DD=qq1+pp1;
end
if DD<=0
Kpu=Kp3;
aa=b1*Kpu+a1; bb=b2*Kpu+a2; cc=b3*Kpu+a3;
pp=bb-aa*aa/3; qq=2*aa*aa*aa/27-(aa*bb/3)+cc;
qq1=(qq/2)*(qq/2); pp1=(pp/3)*(pp/3)*(pp/3);
DD=qq1+pp1;
end
qq2=sqrt(DD);
%Calculation of critical period of oscillation Tu
mm1=-qq/2+qq2; mm2=-qq/2-qq2;
nn1=mm1; nn2=mm2;
if nn1<0
nn1=abs(nn1);
end
if nn2<0
nn2=abs(nn2);
end
uu1=(nn1)^(1/3); vv1=(nn2)^(1/3);
if mm1<0
uu1=-uu1;
end
if mm2<0
vv1=-vv1;
end
zz1=uu1+vv1; beta=-((uu1+vv1)/2)-aa/3;
if beta>1
beta=.9999;
elseif beta<-1
beta=-1;
end
omegau=acos(beta)/T0; Tu=2*3.14/omegau;
if beta==0
Tu=4*T0;
elseif beta==-1 & zz1==-1
Tu=2*T0;
end

128
4 Self-tuning PID Controllers
0
50
100
150
0
0.5
1
1.5
y,w
Time[s]
0
50
100
150
0.4
0.6
0.8
1
1.2
1.4
u
Time[s]
Figure 4.40. Example 4.5 – simulation results: control of model GD(z)
u(k) = 1.6002[y(k −1) −y(k)] + 0.6135[w(k) −y(k)]
+1.4818[2y(k −1) −y(k −2) −y(k)] + u(k −1)
Simulation results for the model GD(z) are shown in Figure 4.40.
Example 4.6. Simulate control of the third-order model from Example 4.5 us-
ing the Takahashi controller (4.192), (4.193) with recursive identiﬁcation (self-
tuning controller). Choose the sampling period T0 = 1 s, the initial parameter
estimates as ˆΘT (0) = [0.1, 0.2, 0.3, 0.1, 0.2, 0.3] and the initial value of the
directional forgetting factor set to ϕ(0) = 1.
Design a simulation program using the diagram in Figure 4.39 and List-
ing 4.3. Simulation results are shown in Figure 4.41.
It is clear from the recorded control responses in Figure 4.41 that in this
case of a third-order self-tuning controller, the control quality is very good
(without a priori information about controlled system parameters).
4.8 Simulation Examples in the Simulink
R
⃝Environment
Simulation is a useful tool for the synthesis of control systems, allowing one
not only to create mathematical models of a process but also to design virtual
controllers in a computer. The mathematical models provided are suﬃciently
close to a real object that simulation can be used to verify the dynamic char-
acteristics of control loops when the structure or parameters of the controller
change. The models of the processes may also be excited by various random
noise generators which can simulate the stochastic characteristics of process
noise signals with similar properties to disturbance signals measured in the
machinery. Simulation results are valuable for implementation of a chosen con-
troller (control algorithm) under laboratory and industrial conditions. It must

4.8 Simulation Examples in the Simulink
R
⃝Environment
129
0
50
100
150
0
0.5
1
1.5
y,w
Time[s]
0
50
100
150
0.4
0.6
0.8
1
1.2
1.4
u
Time[s]
Figure 4.41. Example 4.6 – simulation results: self-tuning control of the third-order
model GD(z)
be borne in mind, however, that the practical application of a controller ver-
iﬁed by simulation cannot be taken as a routine event. Obviously simulation
and laboratory conditions can be quite diﬀerent from those in real plants, and
therefore one must verify its practicability with regard to process dynamics
and the required standard of control quality (for example maximum allowable
overshoot, accuracy, settling time, etc.).
While in Section 4.7 discrete models of the processes were used and the
particular algorithms were programmed as M–Functions of the Matlab R
⃝
programming language, in this section simulations were performed using the
Self-tuning Controllers Simulink Library [104] – see Section 7.1.
Only higher-order systems which have been approximated by second- or
third-order models in the identiﬁcation procedure have been chosen for sim-
ulation veriﬁcation. Simulation veriﬁcation has been limited to digital PID
controllers based on the Ziegler–Nichols and the pole assignment methods,
which have proved to be the best in practical applications. A scheme of the
control circuit used for simulation in the Matlab R
⃝/Simulink R
⃝environment
is shown in Figure 4.42.
Note
The names of the particular controllers in the following examples and symbolic
representations are given in Table 7.1, Section 7.1.1.
4.8.1 Simulation Control of Fourth-order Model
As an example of veriﬁcation by computer simulation a fourth-order system
with the transfer function
G(s) =
1
(s + 1)4
(4.207)

130
4 Self-tuning PID Controllers
 
u_in(k) 
y(k) 
w(k) 
u(k) 
ID params 
Adaptive controller 
Step 
Reference signal 
Output 
ID parameters 
Controlled process 
G(s) 
Figure 4.42. Control circuit used for simulation
was used. Simulation veriﬁcation was realized using four types of controller
included in the Self-tuning Controllers Simulink R
⃝Library [104] (see Sec-
tion 7.1). In time interval t = 150–200 s a constant disturbance v(k) = 0.5
was injected onto the system output. The controller output value u(k) was
limited within the range ⟨0; 2⟩. The initial value of the directional forget-
ting factor was chosen as ϕ(0) = 1. The initial values of the model param-
eter estimates are ˆΘT (0) = [0.1, 0.2, 0.3, 0.4] for a second-order model, and
ˆΘT (0) = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6] for a third-order model.
Example 4.7. Consider a continuous-time controlled process with transfer
function (4.207). Simulate the control loop using a PID Takahashi controller
(zn2tak), choose sampling period T0 = 1 s. Figure 4.43 illustrates the simu-
lation control performance using Takahashi controller (4.38), (4.143). Critical
parameters KPu(T0) and Tu(T0) were calculated recursively using the equa-
tions delivered in Section 4.7.4 for the identiﬁcation of a second-order model.
Example 4.8. Consider a continuous-time controlled process with transfer
function (4.207). Simulate the control loop using a PID Takahashi controller
(zn3tak), choose sampling period T0 = 1.5 s. Figure 4.44 illustrates the simu-
lation control performance using Takahashi controller (4.38), (4.143). Critical
parameters KPu(T0) and Tu(T0) were recursively calculated using the equa-
tions derived in Section 4.7.4 for the identiﬁcation of a third-order model.
Example 4.9. Consider a continuous-time controlled process with transfer
function (4.207). Simulate the control loop using a pole assignment controller
PID–A1 (pp2a 1). Choose sampling period T0 = 2.5 s, damping factor ξ = 1
and natural frequency ωn = 0.3. Figure 4.45 illustrates the simulation control
performance using controller (4.120), (4.126), (4.127).

4.8 Simulation Examples in the Simulink
R
⃝Environment
131
0
50
100
150
200
0
0.5
1
1.5
2
y,w
Time[s]
0
50
100
150
200
0
0.5
1
1.5
2
u
Time[s]
Figure 4.43. Example 4.7 – simulation control performance using a PID Takahashi
controller (zn2tak)
0
50
100
150
200
0
0.5
1
1.5
y,w
Time[s]
0
50
100
150
200
0
0.5
1
1.5
u
Time[s]
Figure 4.44. Example 4.8 – simulation control performance using a PID Takahashi
controller (zn3tak)

132
4 Self-tuning PID Controllers
0
50
100
150
200
0
0.5
1
1.5
2
y,w
Time[s]
0
50
100
150
200
0
0.5
1
1.5
u
Time[s]
Figure 4.45. Example 4.9 – simulation control performance using a pole assignment
controller PID–A1 (pp2a 1)
Example 4.10. Consider a continuous-time controlled process with transfer
function (4.207). Simulate the control loop using a pole assignment controller
PID–B1 (pp2b 1). Choose sampling period T0 = 2.5 s, damping factor ξ = 1
and natural frequency ωn = 0.11. Figure 4.46 illustrates simulation control
performance using controller (4.126), (4.133), (4.138), (4.139).
4.8.2 Simulation Control of Third-order Nonminimum Phase
Model
As an example of veriﬁcation by computer simulation a fourth-order system
with the transfer function
G(s) = 1 −2s
(s + 1)3
(4.208)
was used. Simulation veriﬁcation was realized using the same four types of
controller as in Section 4.8.1. Simulation conditions (v(k), ˆΘT (0) and limiting
of u(k)) were also chosen to be the same.
Example 4.11. Consider the continuous-time transfer function (4.208) as a
model of a controlled process. Simulate the control loop using a PID Takahashi
controller (zn2tak), choose sampling period T0 = 1 s. Figure 4.47 illustrates
the simulation control performance using Takahashi controller (4.38), (4.143).

4.8 Simulation Examples in the Simulink
R
⃝Environment
133
Critical parameters KPu(T0) and Tu(T0) were calculated recursively using
the equations derived in Section 4.7.4 for the identiﬁcation of a second-order
model.
Example 4.12. Consider a continuous-time controlled process with transfer
function (4.208). Simulate the control loop using a PID Takahashi controller
(zn3tak), choose sampling period T0 = 0.35 s. Figure 4.48 illustrates the simu-
lation control performance using Takahashi controller (4.38), (4.143). Critical
parameters KPu(T0) and Tu(T0) were calculated recursively using the equa-
tions derived in Section 4.7.4 for the identiﬁcation of a third-order model.
Example 4.13. Consider a continuous-time controlled process with transfer
function (4.208). Simulate the control loop using a pole assignment controller
PID–A1 (pp2a 1). Choose sampling period T0 = 2.5 s, damping factor ξ = 1
and natural frequency ωn = 0.11. Figure 4.49 illustrates the simulation control
performance using controller (4.120), (4.126), (4.127).
Example 4.14. Consider a continuous-time controlled process with transfer
function (4.208). Simulate the control loop using a pole assignment controller
PID–B1 (pp2b 1). Choose sampling period T0 = 2.5 s, damping factor ξ = 1
and natural frequency ωn = 0.11. Figure 4.50 illustrates the simulation control
performance using controller (4.126), (4.133), (4.138), (4.139).
0
50
100
150
200
0
1
2
3
y,w
Time[s]
0
50
100
150
200
0
0.5
1
1.5
2
u
Time[s]
Figure 4.46. Example 4.10 – simulation control performance using a pole assign-
ment controller PID–B1 (pp2b 1)

134
4 Self-tuning PID Controllers
0
100
200
300
400
−1
0
1
2
y,w
Time[s]
0
100
200
300
400
0
0.5
1
1.5
2
u
Time[s]
Figure 4.47. Example 4.11 – simulation control performance using a PID Takahashi
controller (zn2tak)
0
100
200
300
400
−1
0
1
2
y,w
Time[s]
0
100
200
300
400
0
0.5
1
1.5
u
Time[s]
Figure 4.48. Example 4.12 – simulation control performance using a PID Takahashi
controller (zn3tak)

4.9 Summary of chapter
135
The purpose of the examples above was not to ﬁnd optimal values of the
particular variables in the control loops; this task must be solved by a user
according to his control demands. The analysis and discussion of simulation
results with regard to the chosen initial conditions and input parameters can
be left to the reader as a problem to solve.
4.9 Summary of chapter
PID controllers are still the most widely used controllers in the industry and
thus corresponding attention is paid to them in this chapter. The purpose of
this part is not only to give an overview of digital PID controllers suitable
for self-tuning modiﬁcations but attention is also focused on the implemen-
tation of controllers in industrial application. The chapter is supplemented
by examples of the design of digital PID controllers and listings of their pro-
grams. Self-tuning versions of these controllers can then be programmed by
incorporating recursive identiﬁcation, and used for both simulation purposes
and implementations in real time. The dynamic behaviour of these types of
controllers is determined by a number of simulation veriﬁcations.
0
100
200
300
400
−1
0
1
2
y,w
Time[s]
0
100
200
300
400
0
0.5
1
1.5
u
Time[s]
Figure 4.49. Example 4.13 – simulation control performance using a pole assign-
ment controller PID–A1 (pp2a 1)

136
4 Self-tuning PID Controllers
0
100
200
300
400
−1
0
1
2
y,w
Time[s]
0
100
200
300
400
0
0.5
1
1.5
u
Time[s]
Figure 4.50. Example 4.14 – simulation control performance using a pole assign-
ment controller PID–B1 (pp2b 1)
Problems
4.1. Design PID–B1 type controllers suitable for the control of processes de-
scribed by the models used in Example 4.1 Choose a suitable pole assignment,
simulate the control, and compare the simulation results achieved with the re-
sults in the above mentioned Example 4.1.
4.2. Design PID–A2 type controllers for control of processes described by the
models used in Example 4.1. Simulate the control and compare the simulation
results achieved with the results in Example 4.1.
4.3. Modify the PID–B1 type controllers designed in Problem 4.1 as self-
tuning controllers.
4.4. Verify by experiment the inﬂuence of the damping factor ξ and natural
frequency ωn on control by self-tuning PID type controllers based on the pole
assignment method.
4.5. Verify by experiment the inﬂuence of the sampling period T0 on control
by self-tuning PID type controllers based on the pole assignment method.
4.6. Verify by experiment the inﬂuence of the sampling period T0 on control
by self-tuning PID type controllers based on the modiﬁed Ziegler–Nichols
method.

4.9 Summary of chapter
137
4.7. Verify by experiment the inﬂuence of random disturbances on the be-
haviour of closed loop systems with self-tuning PID type controllers based on
the modiﬁed Ziegler–Nichols method.

5
Algebraic Methods for Self-tuning Controller
Design
Diﬀerent forms of self-tuning controllers may be suggested according to
the type of plant model chosen (and consequently, the chosen identiﬁcation
method), according to quality criteria, or according to the mathematical pro-
cedure used during the derivation of controller equations. Diﬀerent algebraic
control theory-based algorithms are introduced in this chapter. These algo-
rithms use various criteria for the process control – i.e. the dead-beat method,
the pole assignment method, and the linear quadratic (LQ) control method.
This chapter is further divided into ﬁve sections: Section 5.1 summarizes
the basic starting assumptions for controller tuning using algebraic methods;
Section 5.2 considers a description of the dead-beat method – in both its strong
and weak versions; Section 5.3 is concerned with the pole assignment method;
Section 5.4 solves the problems associated with LQ criterion minimization;
and Section 5.5 contains illustrative examples and concludes this chapter.
5.1 Basic Terms
Let us consider validation of the following assumptions:
•
The controller equations are expressed in discrete form.
•
The plant has, for a zero disturbance signal v, the ARMAX model
A(z−1)y(k) = z−dB(z−1)u(k) + C(z−1)es(k)
(5.1)
where
A(z−1) = 1 + a1z−1 + . . . + anaz−na
B(z−1) = b1z−1 + . . . + bnbz−nb
C(z−1) = 1 + c1z−1 + . . . + cncz−nc
d is a time delay expressed as an integer multiple of sampling period T0,
es(k) is a sequence of non-correlative noise with zero mean value.

140
5 Algebraic Methods for Self-tuning Controller Design
This plant model is the result of recursive identiﬁcation in the self-tuning
controller algorithm. It is possible to obtain simpler forms of the model
(5.1) for C(z−1) = 1 (ARX model), for d = 0 (zero time delay) and for
na = nb = n (equal degree of polynomials).
•
Process input and output are in an incremental form.
•
The plant has zero initial conditions.
The controller design will be based on the general block scheme of a closed
loop controller with two degrees of freedom (see Figure 5.1). The inﬂuence of
changes in the reference value w and the inﬂuence of disturbances v placed
on the input of a plant can be observed.
1
K(z )
-1
w(k)
Q(z )
-1
P(z )
-1
R(z )
-1
P(z )
-1
C(z )
-1
A(z )
-1
B(z )
-1
A(z )
-1 z
-d
v(k)
u(k)
y(k)
e(k)
s
Controller
Process
Figure 5.1. Block scheme of a control process with a controller with two degrees
of freedom
Given that v(k) = 0, and es(k) = 0, the following controller equation can
be extrapolated:
P(z−1)K(z−1)u(k) = R(z−1)w(k) −Q(z−1)y(k)
(5.2)
This equation could be simpliﬁed for K(z−1) = 1. A special case is a
controller with only one degree of freedom (Figure 5.2), which is valid for
R(z−1) = Q(z−1), and which works with a tracking error e(k) = w(k) −y(k).
It can be proved that such a controller is only sub-optimal for tasks with
reference value tracking.
A similar procedure could be used to determine a controller for a nonzero
disturbance v(k) and with zero reference value w(k):
P(z−1)K(z−1)u(k) = P(z−1)K(z−1)v(k) −Q(z−1)y(k)
(5.3)

5.1 Basic Terms
141
w(k)
Q(z )
-1
P(z )
-1
e(k)
1
K(z )
-1
C(z )
-1
A(z )
-1
B(z )
-1
A(z )
-1 z
-d
v(k)
u(k)
y(k)
e(k)
s
Controller
Process
Figure 5.2. Block scheme of a control process with a controller with one degree of
freedom
From Equations (5.1) and (5.2), it is possible to determine the transfer func-
tion of a closed loop, thus:
Gw(z) = Y (z)
W(z) =
B(z−1)R(z−1)
A(z−1)K(z−1)P(z−1) + B(z−1)Q(z−1)
(5.4)
and from Equations (5.1) and (5.3) the transfer function from v to y, thus:
Gv(z) = Y (z)
V (z) =
B(z−1)K(z−1)P(z−1)
A(z−1)K(z−1)P(z−1) + B(z−1)Q(z−1)
(5.5)
The most important inﬂuence on a control process (mainly on its stability)
is the denominator of the transfer function. The transfer function of a closed
loop is suitably adjusted by choosing a controller transfer function to ﬁt the
desired criterion.
Above all, the controller must be designed to achieve closed loop stability.
One can deﬁne the stability condition as the requirement for the existence of
only stable pole, which means
|zi| < 1,
i = 1, 2, . . .n
(5.6)
The controlled system (plant) itself could be unstable (it has unstable
polynomial A(z−1)), or nonminimum phase (unstable polynomial B(z−1)).
Some controllers can successfully control these systems, while some produce
instability, and thus cannot be used. The problem is that unstable plant poly-
nomials may be cancelled by controller polynomials. Formally, it is possible to
eliminate these polynomials, but the instability of the closed loop remains the

142
5 Algebraic Methods for Self-tuning Controller Design
same. The instability can lead to stabilization of the controlled variable, while
the controller output oscillates. The problem of a polynomial cancelling un-
stable polynomials is that the plant model can never describe the behaviour of
a plant perfectly – and the controller, designed according to the plant model,
cannot fully compensate the sources of instability in a real plant. For instance,
in order to cancel ﬁrst-degree unstable polynomials (|a1| > 1), which is diﬀer-
ent for arbitrary small ∆a1, the result is not close to 1, but rather, the inﬁnite
divergent sequence
(1 + a1z−1) :

1 + (a1 + ∆a1)z−1
=
1 −∆a1z−1 + a1∆a1z−2 −a2
1∆a1z−3 + a3
1∆a1z−4 + . . .
after omitting the products ∆a1∆a1. To avoid these cancelling problems, fac-
torization of polynomials is sometimes performed for some methods, which
divides the polynomials into a stable part (denoted with the index +) and an
unstable part (-), for example
A(z−1) = A+(z−1)A−(z−1)
(5.7)
which cancels only the stable parts of polynomials. Another way is by spectral
factorization of polynomials, which leaves the stable parts unchanged and
changes unstable parts into reciprocal ones, and by this operation making
them stable.
Algebraic Control Theory is based on the methods of linear algebra
[105, 106, 107]. The basic tool for the description of transfer functions is
the application of polynomials, expressed as a ﬁnite sequence of numbers –
i.e. the coeﬃcients of a polynomial. Thus, signals are expressed as an inﬁnite
sequence of numbers. Controller synthesis consists in solving linear polynomial
(Diophantine) equations of the general form [108]
AX + BY = C
(5.8)
The equation can be solved if the common divisor of polynomials A and
B also divides the polynomial C. The Equation (5.8) has an inﬁnite number
of solutions. If a particular solution is X0, Y0, then the general solution has
the form
X = X0 + BT
Y = Y0 −AT
(5.9)
where T is an arbitrary polynomial. Hence, the choice of polynomial T could
fulﬁl additional requirements on the solution of the equation. Diophantine
equations can be solved using the uncertain coeﬃcients method – which is
based on comparing coeﬃcients of the same power. The Diophantine equation
is then transformed into a system of linear algebraic equations. It is also
possible to solve Diophantine equations using the function axbyc from the
Matlab R
⃝Polynomial Toolbox [109] during simulations.

5.2 Dead-beat Method
143
5.2 Dead-beat Method
There exist both strong and a weak versions of this method – if a process
output and a reference output are the same for an arbitrary time point, or
if this equality is valid only for the time points of the sampling period. This
causes a diﬀerence in a controller output progression, which does achieve (after
a change) the steady state (in the strong version), or where it only converges
towards the steady state (weak version).
5.2.1 Strong Version of the Dead-beat Method
An algorithm can be derived [110, 111] for a control loop according to Fig-
ure 5.1 with the following simpliﬁcations: there is no noise signal nor dis-
turbance, the system does not consist of a time-delay and the polynomial
K(z−1) = 1. The Equations (5.1) and (5.2), which describe a controlled sys-
tem and a controller, have, after their transformation, the form
Y (z−1) = B(z−1)
A(z−1) U(z−1)
(5.10)
U(z−1) = R(z−1)
P(z−1)W(z−1) −Q(z−1)
P(z−1)Y (z−1)
(5.11)
If U(z−1) from (5.11) is substituted into (5.10), then after adjustment
Y (z−1) =
B(z−1)R(z−1)
A(z−1)P(z−1) + B(z−1)Q(z−1)W(z−1)
(5.12)
Using the opposite operation, if Y (z−1) is omitted from (5.11), one can
obtain the expression for an input signal
U(z−1) =
A(z−1)R(z−1)
A(z−1)P(z−1) + B(z−1)Q(z−1)W(z−1)
(5.13)
The polynomial for the tracking error is, after substituting from (5.12) for
the
E(z−1) = W(z−1) −Y (z−1)
=

1 −
B(z−1)R(z−1)
A(z−1)P(z−1) + B(z−1)Q(z−1)

W(z−1)
(5.14)
If the requirement is the achievement of zero level tracking error after a
change to the controller output in a ﬁnite number of control steps (dead-beat),
the polynomial E(z−1) must be as simple as possible. This condition is valid
only if this polynomial is not in the form of a fraction, which means if
A(z−1)P(z−1) + B(z−1)Q(z−1) = 1
(5.15)

144
5 Algebraic Methods for Self-tuning Controller Design
is valid. Equation (5.15) has a minimal solution if the following equations
∂P(z−1) = ∂B(z−1) −1
∂Q(z−1) = ∂A(z−1) −1
(5.16)
are valid for the degrees of polynomials P(z−1) and Q(z−1), and if the polyno-
mials A(z−1) and B(z−1) are coprime. The expression (5.15) is consequently
the condition of closed loop stability. Equation (5.14) is, after application of
the condition (5.15), reduced to
E(z−1) =

1 −B(z−1)R(z−1)

W(z−1)
(5.17)
The sequence W(z−1), which describes the time progression of reference
value w(k), could be expressed as the ratio of polynomials, as follows:
W(z−1) = Nw(z−1)
Dw(z−1)
(5.18)
Consequent simpliﬁcation of the polynomial E(z−1) is possible if the poly-
nomial Dw(z−1) divides the expression 1 −B(z−1)R(z−1). This ratio will be
denoted as polynomial S(z−1), thus
S(z−1) = 1 −B(z−1)R(z−1)
Dw(z−1)
(5.19)
and Equation (5.19) is adjusted to the form
Dw(z−1)S(z−1) + B(z−1)R(z−1) = 1
(5.20)
Similar to the solution of Equation (5.15), this equation has a minimal
solution if the following condition for degrees of polynomials is valid:
∂R(z−1) = ∂Dw(z−1) −1
∂S(z−1) = ∂B(z−1) −1
(5.21)
Polynomial S(z−1) serves as a by-product and there is no need to compute
it in the course of tuning the controller. It could be used for computing a
tracking error
E(z−1) = S(z−1)Nw(z−1)
(5.22)
as in the results from Equations (5.17) to (5.19).
Polynomial Equations (5.15) and (5.20) are usually solved using the un-
certain coeﬃcient method (the comparison of elements with the same power
of z). The above-mentioned algorithm is used for reference signal tracking,
whose progression must be known in order to tune a controller. Step changes

5.2 Dead-beat Method
145
of the reference signal are usually used in practice. The step function with
size w1 can be expressed as
W(z−1) = Nw(z−1)
Dw(z−1) =
w1
1 −z−1
(5.23)
Because it is simpler, let us consider unitary change of the reference (w1 =
1); Equation (5.20) is then simpliﬁed to a form where
(1 −z−1)S(z−1) + B(z−1)R(z−1) = 1
(5.24)
With respect to Equation (5.21), the polynomial R(z−1) has zero degree
and the solution of Equation (5.24) is the relationship
R(z−1) = r0 =
1
b1 + b2 + . . . + bn
(5.25)
Hence, the controller design is simpliﬁed to computation of the coeﬃcients
of the polynomials P(z−1) and Q(z−1) from Equation (5.15) and the coeﬃ-
cient r0 from Equation (5.25). The tracking error polynomial for step changes
of a reference signal is
E(z−1) = S(z−1) =

1 −B(z−1)r0

1
1 −z−1
(5.26)
and it has n nonzero coeﬃcients. The sequence of values of the process output
is described by the equation
Y (z−1) = W(z−1) −E(z−1) = B(z−1)r0
1
1 −z−1
(5.27)
which could be, after dividing the polynomials, written as
Y (z−1) = r0

b1z−1 + (b1 + b2)z−2 + . . . + (b1 + b2 + . . . + bn)z−n
+(b1 + b2 + . . . + bn)z−(n+1) + . . .

(5.28)
Beginning with the n-th step, the coeﬃcients of the sequence are equal to
1, which means: y(k) = w(k). The controller output U(z−1) is, according to
Equations (5.10) and (5.27) equal to
U(z−1) = A(z−1)
B(z−1)Y (z−1) = A(z−1)r0
1
1 −z−1
(5.29)
and after extension
U(z−1) = r0

1 + (1 + a1)z−1 + . . . + (1 + a1 + a2 + . . . + an)z−n
+(1 + a1 + a2 + . . . + an)z−(n+1) + . . .

(5.30)

146
5 Algebraic Methods for Self-tuning Controller Design
Controller output values are constant from the n-th step, and they are
equal to the reciprocal value of system gain. The transfer function of a closed
loop for step changes of a reference signal can be derived from Equations
(5.23) and (5.27)
Gw(z) = Y (z)
W(z) = B(z−1)r0
(5.31)
After transformation of the transfer function to a variable of z, the de-
nominator is equal to zn and the characteristic equation has n multiple zero
roots. Zero poles ensure the fastest stabilization of a control process.
If a system contains a time delay d, the degree of the polynomial B(z−1)
is increased to n + d
B(z−1) = b1z−(1+d) + b2z−(2+d) + . . . + bnz−(n+d)
The procedure for controller design remains the same – tracking of the
reference signal is performed for n + d sampling periods. The characteristic
equation of a closed loop transfer function has a pole with (n + d)-th power.
Note
It is possible to obtain the simplest tracking error polynomial for the known
progression of a reference signal if the condition equations are in the form
A(z−1)P(z−1) + B(z−1)Q(z−1) = Nw(z−1)
Dw(z−1)S(z−1) + B(z−1)R(z−1) = Nw(z−1)
Such a controller meets the requirement for a ﬁnite number of steps only
for zero initial conditions, but the controller from Equations (5.15) and (5.20)
is more general and works with arbitrary initial conditions on the process
output, controller output and reference signal.
The algorithm for the dead-beat method was designed for reference track-
ing, and it does not consist of an integral (or summing in a discrete form)
action. Thus, it is not convenient for disturbance elimination or for a con-
troller with one degree of freedom because it causes steady-state errors. In-
tegral behaviour of a controller can be achieved if it consists of the element
K(z−1) = 1−z−1. From the transfer function of closed loop (5.4), the modiﬁed
conditional Equation (5.15) can be derived in the form
A(z−1)K(z−1)P(z−1) + B(z−1)Q(z−1) = 1
(5.32)
where the degree of the polynomial Q(z−1) is increased by 1
∂Q(z−1) = ∂A(z−1) + ∂K(z−1) −1 = ∂A(z−1).
(5.33)
The condition (5.20) for computing the polynomial R(z−1) does not change
and the element K(z−1) does not have any inﬂuence on tracking the reference
signal.

5.2 Dead-beat Method
147
The design of controller parameters for a controller with two degrees of
freedom and with the element K(z−1) will be demonstrated in the example
on control of a second-order system with a transfer function
GP (z) = B(z−1)
A(z−1) =
b1z−1 + b2z−2
1 + a1z−1 + a2z−2
The degree of the polynomial P(z−1) is, according to (5.16) ∂P(z−1) = 1
and the degree of the polynomial Q(z−1) with respect to (5.33), ∂Q(z−1) = 2.
Equation (5.32) is then expressed in the form
(1 + a1z−1 + a2z−2)(1 −z−1)(p0 + p1z−1)
+(b1z−1 + b2z−2)(q0 + q1z−1 + q2z−2) = 1
The uncertain coeﬃcients method leads to a system of nonlinear equations
(p0 = 1)
⎡
⎢⎢⎢⎢⎢⎢⎣
b1 0 0
1
b2 b1 0 a1 −1
0 b2 b1 a2 −a1
0 0 b2
−a2
⎤
⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎣
q0
q1
q2
p1
⎤
⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
1 −a1
a1 −a2
a2
0
⎤
⎥⎥⎥⎥⎥⎥⎦
and their solution is as follows
q2 =
b1a2
2 −b2a2

a1 −a2 + b2
b1 (a1 −1)

(a2 −a1)b1b2 + b2
2(1 −a2 + b2
b1 ) + a2b2
1
q1 = a1 −a2
b1
+ b2
b2
1
(a1 −1) + b2q2
a2b1
(1 −a1 + b2
b1
)
q0 = a2(1 −a1) −b2q2
a2b1
p1 = b2q2
a2
Polynomial R(z−1) has, according to Equation (5.25), only one parameter
if only step changes of the reference signal are performed
r0 =
1
b1 + b2
Computed parameters are then substituted into the controller equation,
as derived from Equation (5.3)
u(k) = r0w(k)−q0y(k)−q1y(k−1)−q2y(k−2)+(1−p1)u(k−1)+p1u(k−2)

148
5 Algebraic Methods for Self-tuning Controller Design
Examples of control processes with this type of controller (denoted DB1)
are given in Section 5.5.
The controller with one degree of freedom, where R(z−1) = Q(z−1), con-
tains an input tracking error e(k), but the polynomial parameters do not
change
u(k) = q0e(k) + q1e(k −1) + q2e(k −2) + (1 −p1)u(k −1) + p1u(k −2)
This type of controller does not ensure tracking of the reference signal with
zero error. It results from Equation (5.17) for the tracking error sequence,
which need not be ﬁnite.
The common disadvantage of the dead-beat method is that for fast stabi-
lization of the process output, it is necessary to produce large peaks at the
controller output – especially in the ﬁrst step. During decreases in the sam-
pling period, the controller output must increase to ensure stabilization of the
process output in a shorter time. Practically realized actuators have a ﬁxed
range and in the ﬁrst steps, the process input may be saturated, which causes
degradation in the quality of control (an increase in the number of steps to
stabilization of the process output). The simplest way to decrease controller
output peaks is to increase the sampling period, or to ﬁlter the step changes
of the reference.
5.2.2 Weak Version of the Dead-beat Method
A controller for the weak version of the dead-beat method may be derived
from the condition that the process output tracks changes of the reference
signal with a delay of one sampling period y(k) = w(k−1). Thus, the transfer
function of the closed loop is equal to Gw(z) = z−1 . Using Equation (5.10),
it can be computed as follows
y(k) = B(z−1)u(k) −

A(z−1) −1

y(k)
(5.34)
and, after simplifying, y(k) = w(k −1), and after a shift of a single sampling
period, it is possible to obtain the following equation for the controller
u(k) = 1
b1
 n

i=1
aiy(k −i + 1) + w(k) −
n

i=2
biu(k −i + 1)

(5.35)
It is evident from the form of this equation that the controller has two de-
grees of freedom, and the polynomial K(z−1) = 1. For a second-order system,
the controller (5.35) has the form
u(k) = 1
b1
w(k) + a1
b1
y(k) + a2
b1
y(k −1) −b2
b1
u(k −1)
and this will be denoted DB2.

5.3 Pole Assignment Method
149
It is possible, by comparing the general form of controller according to
(5.2), to write Equation (5.35) using polynomials, as follows
P(z−1) = zB(z−1) = b1 + b2z−1 + . . . + bnz−(n−1)
Q(z−1) = z

1 −A(z−1)

= −a1 −a2z−1 −. . . −anz−(n−1)
R(z−1) = 1
K(z−1) = 1
And after substituting the polynomials into the transfer function of the closed
loop (5.4), as
Gw(z) = Y (z)
W(z) =
B(z−1)
A(z−1)zB(z−1) + B(z−1)z [1 −A(z−1)] = B(z−1)
zB(z−1)
(5.36)
This transfer function can be simpliﬁed to the original form z−1 only under
the assumption that the polynomial B(z−1) is stable. Thus, the method is not
suitable for the control of nonminimum phase systems, because the cancelling
of an unstable polynomial B(z−1) leads to an unstable control process.
Equal polynomials could be derived from the conditional equation
A(z−1)P(z−1) + B(z−1)Q(z−1) = zB(z−1)
(5.37)
The stability of nonminimum phase systems is ensured by factorization of
polynomial B(z−1) according to Equation (5.7). The only stable part of this
polynomial is located on the right side of Equation (5.37)
A(z−1)P(z−1) + B(z−1)Q(z−1) = zB+(z−1)
(5.38)
and only these stable parts are cancelled. This results in the closed loop trans-
fer function Gw(z) = z−1B−(z−1).
As was mentioned at the beginning of this chapter, there is equality be-
tween the reference and the process output only during the sampling period.
The course of the controller output is given by the ratio of the coprime poly-
nomials, so the controller output does not achieve steady state. The process
output oscillates with a period equal to two sampling periods around the
reference value, as will be demonstrated in the example given in Section 5.5.
5.3 Pole Assignment Method
A controller based on the pole assignment (placement) of a closed control
loop is designed to achieving the pre-set poles of the characteristic polyno-
mial [69]. Besides the requirement for stability, it is possible, using suitable
pole assignment, to obtain the required characteristic of the output variable
of the closed loop – for instance maximal overshoot, damping, etc. The chosen
types of controllers based on pole assignment methods have already been cited
in Section 4.7.3. In this section, they will be generalized and completed.

150
5 Algebraic Methods for Self-tuning Controller Design
5.3.1 Eﬀects of Pole Assignment on the Control Process
The relationship between the position of the poles and the course of a control
process will be demonstrated with the 2-nd order transfer function of the form
Gw(s) =
ω2
n
s2 + 2ξωns + ω2n
(5.39)
where ξ is the damping factor, and ωn is the natural frequency of oscillation.
The real damping of the system is equal to ξωn (damping factor), and the real
(damped) oscillating frequency of the system is ωn

1 −ξ2. The characteristic
equation of the transfer function (5.39) is
s2 + 2ξωns + ω2
n = 0
which has poles (roots)
s1,2 = −ξωn ± ωn

ξ2 −1
(5.40)
To achieve stability of the control process, the poles have to lie in the
left half-plane of the plane s, and the conditions ξ > 0 and ωn > 0 must be
valid. An oscillating damped control process will be obtained, if the roots are
complex-conjugate – i.e., if the damping factor is in the range 0 < ξ < 1. In
this case, the response of the system to a unit step has the form [112]
y(t) = 1 −e−ξωnt

1 −ξ2

ξ sin

ωn

1 −ξ2t

+

1 −ξ2 cos

ωn

1 −ξ2t)

(5.41)
From Equation (5.41), the oscillation frequency is ωn

1 −ξ2 and accord-
ingly the oscillation period is given by
Tk =
2π
ωn

1 −ξ2
(5.42)
The ﬁrst (maximal) overshoot of the process output will be observed in a
time equal to half the period Tk. The size of the process output at this time
point is computed by setting t = Tk/2 in Equation (5.41)
ymax = y(Tk
2 ) = 1 + e
−
ξπ
√
1−ξ2
(5.43)
Thus, the maximum percentage overshoot of ∆y is given by
∆y = 100e
−
ξπ
√
1−ξ2
The real roots (ξ ≥1) represent reciprocal values of the time constants of the
transfer function and lead to an aperiodical control process.
It is possible using the above analysis to choose the parameters ξ and ωn
so that the course of the control process ﬁts the required properties.

5.3 Pole Assignment Method
151
Example 5.1. Compute the oscillation period and overshoot of the process
output of transfer function (5.39) (the damping factor ξ = 0.4 and the natural
frequency ωn = 0.3 s−1) and compare with the course of the step response of
this system given on Figure 5.3.
From Equation (5.42), the oscillation period is Tk = 22.9 s. The ﬁrst over-
shoot will be observed in a time 11.45 s and its size, according to Equation
(5.43) is ymax = 1.25. The computed values correspond to the values in Fig-
ure 5.3.
0
10
20
30
40
0
0.5
1
1.5
Time [s]
Step response
Figure 5.3. Step response of an underdamped second-order process (solid line –
process output y, dash/dot line – reference value w)
After conversion of the transfer function (5.39) into a discrete form, the
denominator of the transfer function contains the second-degree polynomial
D(z−1) in the form
D(z−1) = 1 + d1z−1 + d2z−2.
(5.44)
The roots of the continuous-time transfer function are converted into dis-
crete form according to the relationship zi = exp(siT0), i = 1, 2; and the
coeﬃcients of the polynomial D(z−1) then have the form
d1 = −2 exp(−ξωnT0) cos

ωnT0

1 −ξ2

;
for ξ ≤1
d1 = −2 exp(−ξωnT0) cosh

ωnT0

ξ2 −1

;
for ξ > 1
d2 = exp(−2ξωnT0)
(5.45)
The pole assignment of the discrete transfer function depends on the cho-
sen sampling period T0.

152
5 Algebraic Methods for Self-tuning Controller Design
Below are some options for pole assignment of the closed loop discrete
transfer function:
•
for a control process with overshoot, the pair of complex-conjugate poles
with positive real parts is chosen;
•
for an aperiodical control process, the real poles are placed on the positive
axis;
•
for a dead-beat control process, the poles are placed at the zeros (see
Section 5.2);
•
the poles are derived from the transfer function of the controlled system; for
example by using spectral factorization of the numerator and denominator
(see Section 5.4).
The above-mentioned approaches can be mutually combined.
It is necessary to realize that it is not possible “to force” the controlled
system to track the required behaviour with pole assignment. For example, a
controller cannot eliminate time delay in the system, or the undershoot of a
nonminimum phase system.
5.3.2 Algorithm Derivation
The derivation of equations for computing controller parameters is similar to
the procedure with the dead-beat method. In the conditional Equation (5.15),
the one on the right side of the equation – which places the poles to zero, is
replaced by the polynomial D(z−1) with chosen poles, thus
A(z−1)P(z−1) + B(z−1)Q(z−1) = D(z−1)
(5.46)
Likewise, Equation (5.32) is changed using the polynomial K(z−1), as
follows
A(z−1)K(z−1)P(z−1) + B(z−1)Q(z−1) = D(z−1)
(5.47)
If the following equation is valid
∂D(z−1) ≤∂A(z−1) + ∂B(z−1) + ∂K(z−1) −1
(5.48)
then the relationships for determining the minimal degree of polynomials
P(z−1) and Q(z−1) are equal those ones used according to the criterion of the
dead-beat method – see Equations (5.16) and (5.33). If the condition (5.48) is
not valid, the degrees of polynomials P(z−1) and Q(z−1) cannot be uniquely
determined. For instance, for Equation (5.46), the number of determined pa-
rameters is equal to ∂P(z−1) + ∂Q(z−1) + 2, because a polynomial of n-th
degree has n + 1 parameters. The number of equations, which are obtained
by comparing elements of the same power, is either ∂A(z−1) + ∂P(z−1) + 1
or ∂B(z−1) + ∂Q(z−1) + 1 – where the greater value has to be chosen. Either
the equation
∂P(z−1) + ∂Q(z−1) + 2 = ∂A(z−1) + ∂P(z−1) + 1
(5.49)

5.3 Pole Assignment Method
153
or the equation
∂P(z−1) + ∂Q(z−1) + 2 = ∂B(z−1) + ∂Q(z−1) + 1
(5.50)
is valid.
The solution of the ﬁrst variant: from Equation (5.49) we have
∂Q(z−1) = ∂A(z−1) −1
(5.51)
and, on the condition that the ﬁrst element on the left side of Equation (5.46)
has a higher degree than the second one, the degree of polynomial P(z−1) is
determined as
∂P(z−1) = ∂D(z−1) −∂A(z−1)
(5.52)
In the opposite case, i.e. from Equation (5.50), the polynomial P(z−1) has
the degree
∂P(z−1) = ∂B(z−1) −1
(5.53)
and from Equation (5.46), the degree of polynomial Q(z−1) is
∂Q(z−1) = ∂D(z−1) −∂B(z−1)
(5.54)
For example, where the polynomials A(z−1) and B(z−1) for the second-
order system are of 2-nd degree and the polynomial D(z−1) are of 3-rd degree,
the condition (5.48) is fulﬁlled. The degrees of polynomials P(z−1) and Q(z−1)
are, according to Equation (5.16) and the pair (5.52), (5.54), equal to one.
By increasing the degree of polynomial D(z−1) to 4-th degree, the degree of
polynomials will then be, according to Equations (5.51)–(5.54), ∂P(z−1) = 2
and ∂Q(z−1) = 1, or ∂P(z−1) = 1 and ∂Q(z−1) = 2. The controller equation
has one of the following forms
u(k) = R(z−1)w(k) −q0y(k) −q1y(k −1) −p1u(k −1) −p2u(k −2) (5.55)
u(k) = R(z−1)w(k) −q0y(k) −q1y(k −1) −q2y(k −2) −p1u(k −1) (5.56)
The courses of the control processes are equal for both types of controller.
The design of controllers with polynomial K(z−1) have only one solution
according to Equations (5.53) and (5.54).
The parameters of the polynomials P(z−1) a Q(z−1) are equal for con-
trollers with one and two degrees of freedom. The relationship for computing
the coeﬃcients of polynomial R(z−1) for a controller with two degrees of free-
dom will now be derived. The ratio of polynomials according to (5.18) will be
applied to the equation for tracking error (5.14) and the denominator of the
transfer function will be replaced by D(z−1) according to Equation (5.46) or
(5.47)
E(z−1) = W(z−1) −Y (z−1) =
D(z−1) −B(z−1)R(z−1)
D(z−1)
 Nw(z−1)
Dw(z−1) (5.57)

154
5 Algebraic Methods for Self-tuning Controller Design
The expression may be simpliﬁed if the polynomial Dw(z−1) divides the
expression in the numerator. Denoting this ratio as polynomial S(z−1), it is
possible to obtain the second conditional equation in the form
Dw(z−1)S(z−1) + B(z−1)R(z−1) = D(z−1)
(5.58)
For a step-changing value when Dw(z−1) = 1 −z−1, it is possible to solve
Equation (5.58) by substituting z = 1
r0 = D(1)
B(1) = 1 + d1 + . . . + dm
b1 + . . . + bn
(5.59)
If a controller contains the polynomial K(z−1), the coeﬃcient r0 can also
be computed, thus
r0 = Q(1) = q0 + q1 + q2
(5.60)
Note
The course of a control process is aﬀected not only by the chosen poles, but
also zeros in the numerator of the closed loop transfer function. Stable poles
ensure the stability of a control process, but cannot always guarantee the
required response properties – for instance, the size of overshoot or the time
taken to settle. If a continuous-time transfer function of second order has only
a constant in the numerator according to (5.39), then the numerator of the
corresponding discrete transfer function contains a polynomial of the second-
degree. The transfer function according to (5.4) has, for a controller with two
degrees of freedom, the form
Gw(z) = Y (z)
W(z) = B(z−1)r0
D(z−1)
since for a controller with one degree of freedom, it has the form
Gw(z) = Y (z)
W(z) = B(z−1)Q(z−1)
D(z−1)
It is obvious that the numerator of the ﬁrst transfer function is closer to
the required form than the numerator of the second one, although both forms
are approximations. Major diﬀerences could lead to completely diﬀerent ﬂow
of a control process.
A controller to control a second-order system without time delay with the
transfer function
GP (z) = B(z−1)
A(z−1) =
b1z−1 + b2z−2
1 + a1z−1 + a2z−2
will be derived from Equation (5.47), which for four chosen poles has the form

5.3 Pole Assignment Method
155
(1 + a1z−1 + a2z−2)(1 −z−1)(p0 + p1z−1)+
(b1z−1 + b2z−2)(q0 + q1z−1 + q2z−2) = 1 + d1z−1 + d2z−2 + d3z−3 + d4z−4
A system of linear equations can be obtained using the uncertain coeﬃ-
cients method (p0 = 1)
⎡
⎢⎢⎢⎢⎢⎢⎣
b1 0 0
1
b2 b1 0 a1 −1
0 b2 b1 a2 −a1
0 0 b2
−a2
⎤
⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎣
q0
q1
q2
p1
⎤
⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
d1 + 1 −a1
d2 + a1 −a2
d3 + a2
d4
⎤
⎥⎥⎥⎥⎥⎥⎦
with its solution
p1 = r6
r1
q0 = r2 −r3
r1
q1 = −r4 + r5
r1
q2 = d4 + p1a2
b2
and with auxiliary variables
x1 = d1 + 1 −a1
x2 = d2 + a1 −a2
x3 = d3 + a2
x4 = d4
r1 = (b1 + b2)(a1b1b2 −a2b2
1 −b2
2)
r2 = x1(b1 + b2)(a1b2 −a2b1)
r3 = b2
1x4 −b2[b1x3 −b2(x1 + x2)]
r4 = a1

b2
1x4 + b2
2x1 −b1b2(x2 + x3)

r5 = (b1+b2)[a2(b1x2−b2x1)−b1x4+b2x3] r6 = b1(b2
1x4−b1b2x3+b2
2x2)−b3
2x1
Similar to the dead-beat method, the computed parameters are substituted
into the equation of a controller with one degree of freedom
u(k) = q0e(k) + q1e(k −1) + q2e(k −2) + (1 −p1)u(k −1) + p1u(k −2)
As mentioned above, the required control process is met by a controller
with two degrees of freedom (denoted PP1) in the form
u(k) = r0w(k)−q0y(k)−q1y(k−1)−q2y(k−2)+(1−p1)u(k−1)+p1u(k−2)
where the parameter r0 is computed from the relationship
r0 = 1 + d1 + d2 + d3 + d4
b1 + b2
If a smaller degree polynomial D(z−1) is chosen (e.g. second order), it is
suﬃcient to set coeﬃcients d3 and d4 to zero. In the case of zero values for
all coeﬃcients d, the poles are placed at zero and the algorithm PP1 is the
same as algorithm DB1.
The algorithm PP1, applied to a control process with one degree of free-
dom according to Figure 5.2, is the same as algorithms PID–A1 and PID–A2

156
5 Algebraic Methods for Self-tuning Controller Design
from Section 4.7.3, if the polynomial P(z−1) according to Equation (4.118) is
written as
P(z−1) = (1 −z−1)(1 + γz−1) = K(z−1)(1 + p1z−1)
(5.61)
Also the algorithms PID–B1 and PID–B2, which use the structure de-
signed by Ortega and Kelly [78] as shown in Figure 4.31, could, after formal
adjustment of the deﬁning polynomial, be replaced with the algorithm PP1 in
the following way: the transfer function of a closed loop described by Equation
(4.136) is
GW (z) = Y (z)
W(z) =
βB(z−1)
A(z−1)P(z−1) + B(z−1) [Q′(z−1) + β]
(5.62)
Polynomial P(z−1) can be rewritten in the form (5.61) and polynomial
Q′(z−1) + β can be deﬁned as
Q′(z−1)+β = (1−z−1)(q′
0−q′
2z−1)+β = q′
0+β−(q′
0+q′
2)z−1+q′
2z−2 (5.63)
and can be replaced by the polynomial Q(z−1) with coeﬃcients q0 = q′
0 +
β, q1 = −(q′
0 + q′
2) and q2 = q′
2. Consequently, β = r0. The advantage of the
original method is that only four parameters are computed.
A diﬀerent approach to controller design using pole assignment was sug-
gested in [28]. The polynomial in the numerator of the transfer function
B(z−1) is factorized to
B(z−1) = z−1B+(z−1)B−(z−1)
(5.64)
and the controller polynomial P(z−1) is chosen to be divisible by the stable
part of the polynomial B(z−1), thus
P(z−1) = P1(z−1)B+(z−1)
(5.65)
Both denominator and numerator of the transfer function of closed loop
(5.4) are then divided by the stable part of polynomial B(z−1)
Gw(z) =
B(z−1)R(z−1)
A(z−1)K(z−1)P(z−1) + B(z−1)Q(z−1)
=
z−1B−(z−1)R(z−1)
A(z−1)K(z−1)P1(z−1) + z−1B−(z−1)Q(z−1)
(5.66)
The conditional Equation (5.47) is then changed into the form
A(z−1)K(z−1)P1(z−1) + z−1B−(z−1)Q(z−1) = D(z−1)
(5.67)
For computation of the controller parameters, the algorithm PP1 can be
used when the polynomial B(z−1) is replaced with its unstable part.

5.4 Linear Quadratic Control Methods
157
5.4 Linear Quadratic Control Methods
Linear quadratic control (LQ) methods try to minimize the quadratic criterion
by penalizing the controller output
J =
∞

k=0
 
[w(k) −y(k)]2 + qu[u(k)]2!
(5.68)
where qu is the so-called penalization constant, which gives weight of the con-
troller output on the value of the criterion (where the constant at the ﬁrst
element of the criterion is considered equal to one). The standard procedure
for minimization of criterion (5.68) is based on the state description of the
system and leads to solution of the Riccati equation. In this section, criterion
minimization is realized through spectral factorization for the input/output
description of the system. LQ control methods, based on state variables, cre-
ated by shifted inputs and outputs, are described in detail in Chapter 6.
If the sequences of the values of both tracking error and input signal are
considered as polynomials, it is possible to rewrite criterion (5.68), using no-
tation ⟨x⟩= x(0)
J =
"
E(z)E(z−1) + quU(z)U(z−1)
#
(5.69)
where E(z) and U(z) are the conjugated polynomials to the polynomials
E(z−1) and U(z−1), which means their negative powers are replaced by pos-
itive ones.
The tracking error polynomial
E(z−1) = W(z−1) −Y (z−1)
=

1 −
B(z−1)R(z−1)
A(z−1)K(z−1)P(z−1) + B(z−1)Q(z−1)

W(z−1)
(5.70)
and the input signal polynomial
U(z−1) =
A(z−1)R(z−1)
A(z−1)K(z−1)P(z−1) + B(z−1)Q(z−1)W(z−1)
(5.71)
are substituted into criterion (5.69) and the condition for criterion minimiza-
tion is found. It can be veriﬁed [113] that the criterion is minimum if the
equation
A(z−1)K(z−1)P(z−1) + B(z−1)Q(z−1) = D(z−1)
(5.72)
is valid. The polynomial D(z−1) is the result of spectral factorization accord-
ing to the equation
A(z−1)quA(z) + B(z−1)B(z) = D(z−1)δD(z)
(5.73)
where δ is a constant chosen so that d0 = 1. The spectral factorization of a
polynomial leaves its stable part unchanged, while the unstable parts change

158
5 Algebraic Methods for Self-tuning Controller Design
to reciprocal ones (stable). Spectral factorization of polynomials of the ﬁrst
and the second degree can be computed simply; the procedure for higher
degrees must be performed iteratively.
While performing the spectral factorization of a polynomial of the second
degree M(z−1), the following equation is solved
M(z−1)M(z) = D(z−1)δD(z)
(5.74)
The products of the polynomials can be extended as
m0 + m1(z + z−1) + m2(z2 + z−2) = δ(1 + d2
1 + d2
2) + δd1(1 + d2)(z + z−1)
+δd2(z2 + z−2)
(5.75)
where the constants of the factorized polynomial on the left side of the equa-
tion are combined into the coeﬃcients m0, m1 and m2. Comparing the left
and right side of Equation (5.75), one obtains
m0 = δ(1 + d2
1 + d2
2)
(5.76)
m1 = δd1(1 + d2)
(5.77)
m2 = δd2
(5.78)
The conditions for stability of the polynomial D(z−1) result from the
Routh–Schur criterion
1 −d2
2 > 0
(5.79)
(1 + d2)2 −d2
1 > 0
(5.80)
Solving Equations (5.76)–(5.80), the following expressions are derived
δ = λ +

λ2 −4m2
2
2
(5.81)
where
λ = m0
2 −m2 +
$m0
2 + m2
2
−m2
1
(5.82)
d1 =
m1
δ + m2
(5.83)
d2 = m2
δ
(5.84)
As identical expression can be used for spectral factorization of polynomials
of the ﬁrst degree for m2 = 0.
Solving the spectral factorization of Equation (5.73), an identical expres-
sion can be used, but it is necessary to convert the left side of this equation
to the form used in Equation (5.74), thus

5.5 Simulation Experiments
159
m0 = qu(1 + a2
1 + a2
2) + b2
1 + b2
2
(5.85)
m1 = qu(a1 + a1a2) + b1b2
(5.86)
m2 = qua2
(5.87)
The control algorithm based on the LQ control method (denoted LQ1),
contains the following steps.
Step 1: The parameters of the polynomial M(z−1) are computed according
to Equations (5.85)–(5.87)
m0 = qu(1 + a2
1 + a2
2) + b2
1 + b2
2
m1 = qu(a1 + a1a2) + b1b2
m2 = qua2
Step 2: The parameters of the polynomial D(z−1) are computed according
to Equations (5.81)–(5.87):
λ = m0
2 −m2 +
$m0
2 + m2
2
−m2
1
δ = λ +

λ2 −4m2
2
2
d1 =
m1
δ + m2
d2 = m2
δ
Step 3: The controller parameters are computed using the PP1 algorithm.
Penalization of the controller output is performed by setting qu ≥0. With
increasing size of penalization constant, the amplitude of the controller output
decreases and thereby, the ﬂow of the process output is smoothed and any
possible oscillations or instability are damped. For qu = 0, the polynomial
D(z−1) = B(z−1), and the method changes to the weak version of the dead-
beat method. Thus, with variation of the penalization constant, it is possible
to change the characteristics of the control loop, which will be demonstrated
in the simulation examples in Section 5.5.
5.5 Simulation Experiments
Simulation of control with controllers, described in detail in previous chapters,
has been realized with three systems of second order:
A - stable;
B - with nonminimum phase;
C - unstable.
The continuous-time transfer functions of the systems (see also Exam-
ple 4.1 in Chapter 4) are
GA(s) =
1
(5s + 1)(10s + 1)
GB(s) =
1 −4s
(4s + 1)(10s + 1)
GC(s) =
s + 1
(2s −1)(4s + 1)
The discrete forms of the transfer functions for sampling period T0 = 2 s are

160
5 Algebraic Methods for Self-tuning Controller Design
GA(z) =
0.03286z−1 + 0.0269z−2
1 −1.48905z−1 + 0.54881z−2
GB(z) =
−0.10166z−1 + 0.17299z−2
1 −1.42526z−1 + 0.49659z−2
GC(z) =
0.6624z−1 + 0.01369z−2
1 −3.3248z−1 + 1.64872z−2
The simulations were performed in the Matlab R
⃝and Simulink R
⃝environ-
ments.
Because the main purpose of these simulations was to show the properties
of the methods investigated, these algorithms are not adaptive. The speed of
obtaining parameters during recursive identiﬁcation is dependent on the initial
state of the system, and it is assumed that the estimated parameters are at
their nominal values because the systems do not contain disturbances. From
the results of the Example 4.2, it follows that stabilization of the parameters
is completed after approximately ﬁve sampling periods.
5.5.1 Dead-beat Methods
Example 5.2. Compute the sequences of the values of the process output and
the DB1 controller output for step changes of the reference for all three
systems.
The output and input system variables have the following calculated values
(see also Figure 5.5):
Stable system A:
y(0) = 0;
y(1) = 0.5498;
y(2) = 1;
y(3) = 1;
. . .
u(0) = 16.7333;
u(1) = −8.1834;
u(2) = 1;
u(3) = 1;
. . .
Nonminimum phase system B:
y(0) = 0;
y(1) = −1.4252;
y(2) = 1;
y(3) = 1;
. . .
u(0) = 14.0193;
u(1) = −5.9619;
u(2) = 1;
u(3) = 1;
. . .
Unstable system C:
y(0) = 0;
y(1) = 0.9798;
y(2) = 1;
y(3) = 1;
. . .
u(0) = −1.4791;
u(1) = 3.4386;
u(2) = 1;
u(3) = 1;
. . .
The DB1 method ensures tracking of the step change of the reference from
the second sampling period for all three systems, as follows from the theory.
Example 5.3. Compute the tracking of a reference signal in the form of a linear
increasing function.
The transfer function of this reference signal can be written as the ratio
of polynomials, thus

5.5 Simulation Experiments
161
W(z−1) = Nw(z−1)
Dw(z−1) =
z−1
1 −2z−1 + z−2
(5.88)
The controller parameters, in comparison with Example 5.2, must be
changed only in the polynomial R(z−1) according to Equation (5.20)
r0 = 2 + r1b2
b1
r1 = −b1 −2b2
(b1 + b2)2
(5.89)
The control process for system A is shown in Figure 5.4, where it is com-
pared with the control process from Example 5.2, in which only step changes
are expected. While in the ﬁrst case, exact tracking of the reference can be
observed from the third sampling period, the second controller leaves a perma-
nent tracking error. Better tracking of the reference is achieved with greater
values of the controller output (see right side of Figure 5.4). The control pro-
cesses for the B and C systems have similar properties.
0
5
10
15
0
5
10
15
Time[s]
y,w
0
5
10
15
0
20
40
60
80
Time[s]
u
Figure 5.4. Control process for a linear increasing reference value (ramp) w – DB1
method (solid line – controller with parameters according to (5.89); dashed line –
controller designed for step changes in w; circles – discrete values of the reference
w)
In conformity with the theory, the controller DB1, containing K(z−1)
ensures zero tracking error after the eﬀects of the disturbance to the input
of the system (denendent on the type of the system, maximally after four
sampling periods).
Example 5.4. Repeat Example 5.2 for a controller with one degree of freedom,
i.e. with only polynomials P(z−1) and Q(z−1).
This algorithm ensures that step changes are tracked from the fourth sam-
pling period and results in a large overshoot (System A)

162
5 Algebraic Methods for Self-tuning Controller Design
y(0) = 0;
y(1) = 1.7720;
y(2) = 1.5195;
y(3) = 0.6060;
y(4) = 1;
. . .
Example 5.5. Compute the tracking of step changes in the reference for the
weak version of the dead-beat method (DB2) for System A and compare with
the DB1 method.
Calculation results are demonstrated in Figure 5.5. Using the DB2 method
the tracking error is zero at the sampling times from the ﬁrst sampling period,
but between sampling times the process output oscillates. Compared to the
DB1 method, the control process is much worse.
0
10
20
30
0
0.5
1
1.5
Time[s]
w,y
0
10
20
30
−40
−20
0
20
40
Time[s]
u
Figure 5.5. The control process for step change of the reference for System A
(solid line – method DB2; dashed line – method DB1; circles – discrete values of
the reference w)
The process control for System C is without oscillation, and stabilizes after
three sampling periods. The DB2 method leads, for the nonminimum phase
System B, to an unstable control process. Because it is not possible to elimi-
nate the creation of nonminimum phase models during recursive identiﬁcation,
the DB2 method is not convenient for self-tuning controllers.
5.5.2 Pole Assignment Methods
Example 5.6. Design a PP1 controller to ensure the same poles in the closed
loop as the process in Example 5.1 in Section 5.3.
The denominator of continuous system (5.39) may be converted into dis-
crete form using (5.45). The coeﬃcients of the polynomial D(z−1) are then
d1 = −1.3413 and d2 = 0.6188. Process control with controller PP1 is al-
most identical for Systems A and C with the required response according to
Figure 5.3. For the nonminimum phase System B, the output variable does

5.6 Summary of chapter
163
not track the chosen reference signal, but process control is acceptable (see
Figure 5.6).
0
5
10
15
20
25
30
−2
−1
0
1
2
Time[s]
w,y
Figure 5.6. Process control for System B (dashed line – required response; solid line
– control with controller PP1; dotted line – controller with one degree of freedom,
dash and dot line – reference value w))
If a controller with one degree of freedom is used, the numerator of the
closed loop transfer function contains the product of polynomials B(z−1) and
Q(z−1), which causes an acceleration of the response but also increases over-
shoot and undershoot – see dotted line in Figure 5.6.
5.5.3 Linear Quadratic Control Methods
Example 5.7. Compute the response of control processes with the LQ1 algo-
rithm and diﬀering sizes of penalization constant for System B.
The results are demonstrated in Figure 5.7. With increasing penalization
constant, the response of the control process decelerates and undershoots de-
crease. Consequently, the values of controller output are reduced.
5.6 Summary of chapter
The most commonly used methods – dead-beat, pole assignment and LQ con-
trol, based on algebraic control theory, are presented in this chapter. For each
method a general algorithm for controller design is derived, together with
its concrete form for a second-order system. Properties of each method are
shown by simulation examples. Close relations between methods are also men-
tioned. The methods described are given in basic form and their adaption into

164
5 Algebraic Methods for Self-tuning Controller Design
0
10
20
30
−0.5
0
0.5
1
Time[s]
y
0
10
20
30
0
2
4
6
Time[s]
u
Figure 5.7. Control processes for the LQ1 controller for System B and diﬀerent
penalization constants (dashed line qu = 0; solid line qu = 0.03; and dotted line
qu = 0.2)
self-tuning controllers involves repeated calculation of controller parameters
according to the recursive identiﬁcation model at every step.
Problems
5.1. Design a strong version of the DB controller for a ﬁrst-order system with
a time delay of two sampling periods. Compute the sequences of values of
the process output and controller output for step and ramp changes of the
reference signal.
5.2. Compute the sequence of values of the process output for a step distur-
bance present on the system input for the strong version of a DB controller
with one degree of freedom, with and without polynomial K(z−1).
5.3. Compare the sequences of the process output for controllers designed in
line with Equations (5.37) and (5.38) during the control of nonminimum phase
systems, given the transfer function GB(z).
5.4. Design the polynomial D(z−1) for a PP1 method which ensures a ﬁrst
overshoot of process output of about 30% in the time 10 s.
5.5. Compute the spectral factorization of the polynomial M(z−1) = 1 +
2.5z−1 + z−2. Observe the changes to its unstable part.

6
Self-tuning Linear Quadratic Controllers
In this chapter we will discuss the design of controllers using minimization of
the quadratic criterion where the linear model of the system is known (the
LQ method). In theory, the ﬁeld of LQ control has seen detailed development.
This chapter, however, concentrates mainly on the results of theoretical work
and how they aﬀect control behaviour in practice. This will be done by testing
the results in simulations using the well-known Matlab R
⃝
Simulink R
⃝en-
vironment, which allows the user to experiment interactively. For the beneﬁt
of those who do not have access to Matlab R
⃝, the Simulink R
⃝illustrations
serve as block diagrams and the simulation results must be taken on trust.
The chapter is composed of several sections which may be of interest to a
variety of readers.Section 6.1 and Section 6.2 provide a survey of the standard
results of LQ control. There is a selection of examples to demonstrate the
typical behaviour of LQ controlled loops and the eﬀect of the basic “tuning”
parameters representing the penalty of the control output in the quadratic
criterion. This is used to achieve the desired control behaviour. In these ex-
amples we consider the match between the model and the system. Section
6.3 is devoted to the problems involved in using LQ designs in adaptive con-
trollers. Section 6.4 gives an in-depth description of the characteristics of the
LQ approach from various aspects and contains information that is readily
available from textbooks, together with results from more hidden sources and
from the work of the authors themselves. These are given here because our un-
derstanding of the individual aspects and properties of LQ control forms the
basis for establishing a methodology to tune LQ controllers. This methodology
is dealt with in Section 6.5. Section 6.6 brieﬂy discusses extending the appli-
cation of these methods to multivariable control loops. Section 6.7 deals with
the algorithmic aspects of LQ synthesis and details the square root method of
minimization of the quadratic criteria on which all versions of LQ controllers
used here are based. There is also a reference to the related m-ﬁles for the
Matlab R
⃝environment.

166
6 Self-tuning Linear Quadratic Controllers
u
System
Controller
n
v
y
q
w
Figure 6.1. Diagram of a control loop
6.1 The Principles of Linear Quadratic Controller Design
We will take the basic control scheme pictured in Figure 6.1 as our starting
point. This is a simpliﬁed and idealized version of reality. System is the pro-
cess under consideration. This could, for example, be an electric oven. The
temperature inside the oven at a given spot is the variable we wish to control,
i.e. the output y(t). The temperature depends on the energy supplied, which
we usually vary by altering the electrical current, and on the temperature in
surrounding area. The electrical current, therefore, is simultaneously system
input variable u(t) and the controller output. The eﬀects of the other variables
are represented by disturbance n(t). In this example, disturbance is both the
change in the voltage supply, which also inﬂuences power input, and changes
in the surrounding temperature. Sometimes the eﬀect of disturbance can be
speciﬁed more precisely. The inﬂuence of the voltage supply can be deﬁned
with relative precision and, if we know how it behaves, it can be eﬀectively
compensated. We call this type of disturbance “measurable” and it is repre-
sented by signal v(t) in the diagram. Output y(t), which we measure for use in
the control process, does not always correspond to the true physical variable.
This diﬀerence is represented by signal q(t). We will not take this signal into
account but assume that we have a suﬃciently precise measuring system. In
the section dealing with the properties of LQ controllers we will show how its
eﬀects might be felt. The remaining variable w(t) in the diagram represents
the set point. In controller design it is necessary to know (select) the criterion
and process of the model and to use a suitable optimization procedure. We
will concern ourselves with the discrete approach where the signal is known
at the instants of sampling only. The choice of sampling period is, therefore,
an important factor in the design of an LQ controller for a continuous-time
process. We will discuss the inﬂuence of the sampling period in Section 6.4,
but for now we will assume that it was chosen in such a way as to provide a
discrete model which describes the behaviour of the system well.

6.1 The Principles of Linear Quadratic Controller Design
167
6.1.1 The Criterion
The aim of control is to generate the kind of input signal u(k) which results
in a system output close to the set point, i.e. so that
[w(k) −y(k)] →min
for all the k values under observation. This means that the criterion used to
evaluate the quality of control must be a non-negative function of all variables
(w(k)−y(k)) at those values of k we wish to use in the design. These conditions
are satisﬁed by the quadratic criterion
J =
k+T

i=k+1
[qy(w(i) −y(i))2]
(6.1)
When evaluating the quality of control achieved we must also consider the cost
of a larger input signal to improve quality. This is reﬂected in the criterion by
a further term
J =
k+T

i=k+1
[qy(w(i) −y(i))2 + quu(i)2]
(6.2)
where qy, qu, T are the basic criterion parameters. We try to choose these in
such a way as to make the criterion represent the user’s deﬁnition of optimal
control behaviour. Later we will discuss a further extension of the quadratic
criterion to include a reference signal for the controller output. This criterion
will have the form
J =
k+T

i=k+1
[qy(w(i) −y(i))2 + qu(u(i) −u0(i))2]
(6.3)
This makes the control output dependent on yet another purposely chosen
signal, and we will show how this can be used to advantage in maintaining
the useful properties of the controller..
6.1.2 The Model
The principle of LQ design is that it starts from current time k0, and tries
to generate values of u(k0 + 1), u(k0 + 2), . . . , u(k0 + T ), to keep the future
error to a minimum. In order to be able to put the LQ method into practice,
models must be available which allow one to determine the future values of
all signals (variables) occurring in the criterion. In the simplest case this is a
system model used to calculate the future values of output y(k), and a model
which determines the behaviour of the set point in the future. As far as the
set point is concerned, it may be that its future numerical values are known
rather than having to refer to the model.

168
6 Self-tuning Linear Quadratic Controllers
One linear model which satisﬁes minimization of the quadratic criterion is
the linear regression model given in Chapter 3. Because the model is a good
one from the point of view of parameter identiﬁcation and can be used in
synthesis, it is the most frequently used in adaptive controllers. A regression
model with measurable external disturbance (transformed into the system
output) will be considered, i.e. regression model
y(k) = −
n

i=1
aiy(k −i) +
n

i=0
biu(k −i) + ek +
n

i=1
div(k −i) + K
(6.4)
Note
We must bear in mind that a single diﬀerence equation (regression model) can
represent several transfer functions. This is true in this example where model
(6.4) represents the transfer functions shown in Figure 3.1.
Similarly the structure of a controller is represented by more transfer func-
tions. Minimization of the criterion leads to a diﬀerence equation for optimal
u(k) in the form
u(k) =
n

i=1
Siy(k−i)+
n

i=1
Riu(k−i)+
n

i=1
Cldiv(k−i)+
N

i=1
Clwiw(k+i) (6.5)
This corresponds to the diagram given in Figure 6.2.
We can see that the control law obtained simultaneously represents the
feedback from the system output and the feedforward from the individually
measurable variables. It follows that the controller here does not operate with
a control error but independently with each individual signal. If we wish to
compare the properties of the loop with a situation where control error is
ﬁrst introduced as controller input, the loop has to be transformed into the
structure given in Figure 6.3.
The structure of the controller is closely bound to that of the model. All
the transfer functions produced by the model are employed in the controller.
If, for example, only the feedback part is used, a signiﬁcant deterioration in
the behaviour can be expected.
6.1.3 The Optimization Approach
The standard method of minimizing the quadratic criterion for LQ control
is derived from the state description of the system. The state space formula-
tion permits the elegant use of dynamic programming so that the minimizing
process is performed from the end of the interval back to the beginning. In a
linear state space model, step-by-step minimization results in the evolution of
a matrix of quadratic form. This can be expressed in the form of an equation
known as the (discrete) Riccati equation.

6.1 The Principles of Linear Quadratic Controller Design
169
−1
y
q
w
1
A(z  )
A(z  )
B(z  )
S(z  )
R(z  )
Cld(z  )
Clw(z  )
Clu0(z  )
D(z  )
A(z  )
−1
−1
−1
−1
−1
−1
−1
−1
−1
−1
−1
R(z  )
R(z  )
−1
R(z  )
u0
v
n
e
u
Figure 6.2. Diagram of a controller
−1
y
u
n
v
q
w
B(z  )
A(z  )
S(z  )
R(z  )
Clw(z  )
−1
−1
−1
−1
−1
R(z  )
Figure 6.3. Diagram of the error approach
A Survey of Standard Results
In most texts linear quadratic control is presented in the following form. The
system is deﬁned by the discrete state space model
x(k) = Fx(k −1) + Gu(k −1)
y(k) = Cx(k) + Du(k)
(6.6)
where vectors x(k), y(k), u(k) represent state, output and input vectors, and
have dimensions n, r, m. Matrices F, G, C, D are the state, input, output

170
6 Self-tuning Linear Quadratic Controllers
and feedforward matrices, and their dimensions correspond to those of the
relevant vector.
The aim is to ﬁnd the sequence of control laws Li which minimize criterion
J =
T

k=1
x(k)T Qx x(k) + u(k)T Qu u(k)
(6.7)
i.e. optimize the transfer function of given state x(0) to zero state. Qx and
Qu are penalty matrices for state and input, and we assume that Qx ≥0
and Qu > 0 is valid. The discrete
Riccati equation which represents the
minimization takes the form
Si = FT Si−1F −FT Si−1G(Qu + GT Si−1G)−1GT Si−1F + Qx
(6.8)
where index i should be taken to be iteration i ∈[1, T ], S0 = 0. The sequence
of the matrices Si deﬁnes the sequence of control laws
Li = (Qu + GT Si−1G)−1GT Si−1F
(6.9)
These control laws are applied in reverse order of iteration, i.e.,
LT , LT −1, .. , L2, L1
and optimal control is calculated from relation
u(k + i) = LT −i+1x(k + i −1),
i = 1, 2, ..., T
The whole value of the criterion at the interval under consideration [1, T ] is
given by the expression
J∗= x(0)T ST x(0)
Using relation (6.9), the Riccati equation (6.8) can alternatively be written as
Si = FT Si−1(F −GLi) + Qx
(6.10)
Si = (F −GLi)T Si−1(F −GLi) + Qx + LT
i QuLi
(6.11)
The value of T →∞has a special signiﬁcance in control theory. In fact when
we talk about the LQ problem we are almost always referring to this particular
situation. Its importance lies in that the minimization of this criterion with
an inﬁnite horizon results in stationary control law L∞, which is, therefore,
time invariable. It has a stabilizing eﬀect under standard conditions. These
conditions aﬀect the controllability (ability to stabilize) of pair (F, G) and
the observability (detectability) of pair (F, Q1/2
x ). This control law is obtained
from the solution of the algebraic Riccati equation. If it has several solutions
we must choose the highest rank positively semideﬁnite solution.
This stationary solution has a number of other interesting properties which
will be treated in another section. The most signiﬁcant of these is the stabi-
lizing eﬀect, not only on the system it was designed for, but also on systems

6.1 The Principles of Linear Quadratic Controller Design
171
where the amplitude and phase frequency characteristics lie at a certain dis-
tance from the nominal. This kind of control is described as being robust in
terms of stability. The diﬃculty is that the state must be accessible for the
purposes of control. Access to state is rare in technological processes, so LQ
optimum control will be formulated on the assumption that we only have
access to the system output. The properties of the two types of control can
diﬀer greatly because another dynamic enters into the loop, either as a trans-
fer function of a dynamic controller if it is relying on the system transfer
function, or as the dynamics of an observer used to reconstruct an unmea-
surable state. The guarantee of robustness and other qualities is lost if the
state cannot be accessed. In our solution we use a state composed of delayed
input and output. Although this state is made up of measurable signals, it is
not itself measurable (to obtain these variables at time k, the previous mea-
sured values must be preserved, in shift registers perhaps, thus creating an
observer). Therefore
x(k−1) = [u(k−1), u(k−2), . . ., u(k−n), y(k−1), y(k−2), . . ., y(k−n)] (6.12)
Here, the regressor of the model used is composed of the true input and the
state vector
z(k) = [u(k), x(k −1)]
The state matrix of this type of state model is now made up of the parameters
of the regression model; zeros and ones. The state used is not minimal. It can,
however, be shown that the complexity of calculation involved here, especially
in the square root form, is comparable to the complexity of the algorithm used
to solve the minimal state problem.
Section 6.7 gives a detailed derivation of the minimization, including the
square root algorithm. With regards to the state used, the calculated steady
state control law contains the coeﬃcients of polynomials R, S, and Clw Cld
of the transfer function of controller (6.5).
Note
Must we really use the state formulation in the LQ problem if we are starting
from the formulation of input/output and ﬁnally return to it? It is not entirely
necessary but does carry certain advantages:
•
The alternative, the polynomial approach, provides a solution only for the
inﬁnite horizon. However, in the adaptive approach, it is useful to imagine
a steady solution as the limits of the ﬁnite horizon when the calculation
method cannot ﬁnd the steady solution.
•
The state formulation allows us to formulate a cautious strategy and put
it into practice – see the section on adaptive controllers.
•
The nonminimum state approach permits the formulation of a strategy
using a data-dependent penalty variable – see the section on adaptive
controllers.
It is also possible to neglect the formulation of the state. An algorithm has
been developed for the step-by-step minimization of the quadratic criterion

172
6 Self-tuning Linear Quadratic Controllers
which does not require the introduction of the state and state description.
Unlike the classic approach, where the state is used to express the cost to
go loss of the criterion using quadratic form xT (k)Skx(k), the new approach
exploits a list of those variables contributing to the loss. This list is updated
by individual steps of minimization. This update, however, can be far more
generalized than merely relating to the state alone. This approach can be used
on models where the structure changes along the criterion horizon, as well
as to evaluate non-synchronous sampling for several variables [114, 115].The
pseudo-state algorithms described here can be regarded as practicable due to
their relative simplicity, transparency and reliability.
6.2 Using Linear Quadratic Controllers; Examples and
Simulation
In the previous section we introduced the basic characteristics of controllers
designed using the minimization of the quadratic criterion method. We are
aware that we must select a criterion and a penalty for those variables included
in the quadratic criterion, and determine the model which describes the be-
haviour of the controlled process. This is the system transfer function, the
disturbance transfer function, and any other transfer functions from measur-
able variables. Having performed these two tasks, we use a computer program
to generate the appropriate control law which can then represent also several
transfer functions. It now remains to put the design into practice and discover
what kind of control behaviour we have achieved. To make a good control law
which meets our requirements, we must not only have a good process model,
but we must also know how to select the penalty in the criterion which will
lead to good control behaviour. The aim of this section is to acquaint the
reader with the typical behaviour of an LQ controller working under diﬀer-
ent regimes and with various systems. The advantage of an LQ controller is
that, mathematically speaking, the control behaviour is optimal with regard
to the chosen criterion, at least when system and model match and are both
linear. But not even these “ideal” conditions necessarily mean that behaviour
is “user optimum”. Better control behaviour almost always requires an input
signal which consumes more energy, has a greater amplitude and a higher fre-
quency. The user may be unable to permit such a signal. The user expresses
the compromise between quality and the limitations on the input signal using
penalty values on input Qu (or more exactly the ratio Qu/Qy). This variable
therefore becomes the basic tuning element. Shortly we will see that this tun-
ing “button” is insuﬃcient to adjust the control behaviour so that it meets
the desired performance. In practice, other methods of modifying the control
behaviour are required, such as dynamic penalties, modiﬁcation of the trans-
fer function of an open-loop or ﬁltering. We will deal with these alternatives
in a later section. We will familiarize ourselves with the typical characteristics

6.2 Using Linear Quadratic Controllers; Examples and Simulation
173
of LQ controllers using examples from the Matlab R
⃝and Simulink R
⃝envi-
ronments and the functions and simulations in the LQ toolbox. This part will
simultaneously introduce us to working with this toolbox and the possibilities
it oﬀers. The toolbox functions are fully listed and described in Section 7.2.
The control layout used for our simulation example features a system,
controller, loops aﬀected by disturbance, a set point generator and other aux-
iliary blocks. Each block must be deﬁned before simulation starts; various
procedures and programs are available in the toolbox to do this. The basic
simulation procedure is represented in ﬁle schema1.mdl and is illustrated in
Figure 6.4. This is similar to the scheme given in Figure 6.2.
Note
The diagram shows a system created by the System block using discrete trans-
fer function and random disturbance generated by the Discrete Noise and
Disturbance block. The Saturation block, which represents the limit on the
controller output, is placed before the system. The controller is created by
blocks Filter–Filter 3.Filter and Filter 1 deal with feedback, Filter 2 with the
inﬂuence of the set point, and Filter 3 with the eﬀect of auxiliary signal u0,
though this is not used in the standard approach and therefore disconnected
from the diagram. The set point is generated by the Simulink R
⃝block Signal
Generator. Other blocks are used to illustrate the input and output variables
and calculate the sum of squares of the output error.
The modely.m ﬁle contains a number of pre-deﬁned systems which can
be selected interactively. The ﬁle also sets the corresponding sampling period
T0 and several other parameters in the Simulink R
⃝diagram, as well as the
option of the controller calculation.
uout
To Workspace1
yout
To Workspace
Sum2
Sum1
Sum
Signal
Generator
Scope1
Scope
Saturation
Mux
Mux
−K−
Gain
Clu0 
1 
Filter3
Clw 
1 
Filter2
1 
R 
Filter1
S 
1 
Filter
u[1]^2
Fcn
kn(z)
Af(z)
Disturbance
0
Display
0.1
z−1
Discrete−Time
Integrator
0
Constant3
Band−Limited
White Noise
B(z)
A(z)
    system
Figure 6.4. The basic simulation diagram

174
6 Self-tuning Linear Quadratic Controllers
The quality of control behaviour depends to a large degree on the proper-
ties of the system. It is known that the so-called nonminimum phase system is
among those in which the quality of control behaviour is sometimes severely
limited. These are systems in which the transfer function has an unstable
zero. While continuous-time nonminimum phase systems are not common,
they occur more often with a discrete description. In this case the property
of nonminimum phase does not only depend on the physical properties of the
system but also on the sampling period.
Several simple systems have been chosen as examples. Nevertheless, they
are well suited to demonstrating the chosen properties.
S1 A simple second-order system described by continuous-time transfer func-
tion
G(s) =
1
(s + 1)2
(6.13)
In the main the discrete version is used, obtained by sampling at period
T0 = 0.1 s, which has discrete transfer function
G(z−1) =
0.00468 + 0.00438z−1
1 −1.81z−1 + 0.8187z−2
(6.14)
This is a simple process for achieving good quality control behaviour, it is
minimum phase, and will be used to demonstrate standard behaviour.
S3 is one of the three discrete transfer functions representing one mechanical
system introduced in [116] as a benchmark. The system transfer function,
which has signiﬁcantly elevated resonance, takes the form
G(z−1) =
0.2826z−3 + 0.50666z−4
1 −1.9919z−1 + 2.2026z−2 −1.8408z−3 + 0.8941z−4
(6.15)
S5 is a simple discrete model of a Pelton turbine with long feed pipes, where
the transfer function is nonminimum phase and has the form
G(z−1) = −2.0 + 2.05z−1
1 −0.95z−1
(6.16)
The next four systems are constructed artiﬁcially. Discrete transfer func-
tion S1 was modiﬁed so that:
S6 the system has two time delay periods and so assumes the form
G

z−1
= 0.00468z−2 + 0.00438z−3
1 −1.81z−1 + 0.8187z−2
(6.17)
S7 the system numerator contains one unstable root
G

z−1
= 0.1 −0.16z−1 + 0.028z−2
1 −1.81z−1 + 0.8187z−2
(6.18)

6.2 Using Linear Quadratic Controllers; Examples and Simulation
175
S8 , the system numerator contains two unstable roots
G

z−1
= 1 −2.15z−1 + 1.155z−2
1 −1.81z−1 + 0.8187z−2
(6.19)
S9 , the system is unstable and has the numerator from system S1
G

z−1
=
0.00468 + 0.00438z−1
1 −2.104z−1 + 1.1067z−2
(6.20)
•
Helicopter model. The Simulink R
⃝scheme of a simple helicopter model
has been created. It represents the dynamics in elevation angle. This con-
tinu˜ous-time nonlinear model serves to demonstrate the features of an
adaptive LQ controller used with a nonlinear system.
The basic optimization procedure lqex1.m from the toolbox is used in
the optimal control calculation. The examples are divided into disturbance
compensation and set point control to demonstrate the properties of a step
response. The systems best suited to demonstrating these properties were
selected from those above and used in the following simulations.
6.2.1 Stochastic Disturbance Compensation
The optimal control law will be composed purely of feedback component S
R.
The compensation behaviour and the controller output for “well-behaved”
system S1 and for two penalty values Qu is captured in Figure 6.5. The graphs
show the time behaviour of the output and disturbance without compensation
(Sx-y, v) and controller output (Sx-u).
The next four graphs (Figure 6.6) show the error of disturbance compen-
sation for oscillating system (S3), time delay system (S6), nonminimum phase
system (S7), and unstable system (S9), when the penalty is relatively small
Qu = 0.001.
Note
1. The disturbance behaviour of systems S1, S6, S7, and S9 are the same
because they were created by the same ﬁlter. In order to obtain a stable
signal, the roots of the ﬁlter for unstable system S9 are reciprocal to its
unstable roots. Its auto-correlation function, however, also corresponds to
the denominator of the original unstable system.
2. If we want to experiment with the control of system S1 by changing the
penalties, introducing an eﬀective limitation on the controller output in
the saturation block, or by using just a short horizon in the optimization
criterion, most of the results will be obtained when the disturbance is more
or less compensated for. At the same time, penalty Qu greatly aﬀects the
quality of the disturbance compensation.

176
6 Self-tuning Linear Quadratic Controllers
0
100
200
300
−1
−0.5
0
0.5
1
1.5
S1 −y,v Qu=.001
0
100
200
300
−1
−0.5
0
0.5
1
1.5
S1 −y,v Qu=.1
0
100
200
300
−10
−5
0
5
10
S1 − u  Qu=.001
0
100
200
300
−10
−5
0
5
10
S1 − u  Qu=.1
Figure 6.5. Disturbance compensation for system S1 with various penalties
0
200
400
600
-6
-4
-2
0
2
4
6
S3 -y,v Q u=.001
0
100
200
300
-1
-0.5
0
0.5
1
1.5
S6 -y,v Q u=.001
0
100
200
300
-1
-0.5
0
0.5
1
1.5
S7 -y,v Q u=.001
0
100
200
300
-1
-0.5
0
0.5
1
1.5
S9 -y,v Q u=.001
d
a
b
c
Figure 6.6. Disturbance compensation for diﬀerent systems and with penalty Qu =
0.001
3. Nothing like this, of course, applies to the other systems, which are either
unstable, nonminimum phase or have time delay. For unstable system S9
the limitation of the input signal is critical. In the simulation shown in
Figure 6.6d the controller output remains mostly within the boundary
|u(k)| < 5. Nevertheless, applying this limitation results in a noticeable

6.2 Using Linear Quadratic Controllers; Examples and Simulation
177
deterioration in compensation, yet limitation |u(k)| < 4 leads to instabil-
ity. It helps to increase penalty Qu so that the limitation cannot come into
eﬀect. The length of the criterion horizon used in this case makes little
diﬀerence to the quality of compensation.
4. The disturbance compensation for the nonminimum phase system S7 Fig-
ure 6.6c is poor. Further experiments show that it is almost independent
of penalty Qu. The amplitude of the controller output is small and its
limitation by the saturation block results in a further deterioration in dis-
turbance compensation, but in such a way as to approach disturbance
without control. Here, the length of the horizon in the criterion used is
signiﬁcant. If a short horizon is used (hor = 3), the control behaviour is
worse than if there were no control at all. Unless we consider the use of an
extra penalty on the ﬁnite state, behaviour will be unstable (see Section
6.4.1 – Stability).
5. Systems S6 and S1 diﬀer in that S6 has two time delay intervals. Compen-
sation is similar to that in S1 and is illustrated in Figure 6.6b. Even when
the horizon used in this system is short there is a penalty which can be
applied to produce good disturbance compensation.
6. Figure 6.7 shows two types of disturbance compensation for system S5.
The upper series shows the behaviour resulting from a single step strat-
egy (hor = 1). A noticeable disturbance compensation can be seen but
there is an unstable input signal. This is a typical feature in the control
of a nonminimum phase system where satisfactory short-term control be-
haviour can be achieved with an unstable input signal. Optimal, stable
behaviour can be seen in the lower pair of illustrations. The noise com-
pensation is minor but requires just a very small input signal.
The compensation of disturbance represented by a regression model is
truly optimal. In a minimum phase system, disturbance can be compensated
to its source, white noise, which will remain in the compensation process.
Compensation in nonminimum phase systems is limited. The advantage of an
optimal controller here is that only a small controller output is required.
6.2.2 Set point Control
First a step set point change is considered. Figure 6.8 shows the step responses
for system S1 and controller outputs using two diﬀerent penalties. A similar
situation is pictured in Figure 6.9, this time for nonminimum phase system
S7.
Figure 6.10 illustrates the control behaviour of system S3 and unstable
system S9. Figure 6.11 shows the control behaviour of systems S3 and S1
with a limited control output. Although S3 shows a poor result, limitation u
has a positive eﬀect on system S1. Experimenting with these systems under
various conditions yields the following conclusions:

178
6 Self-tuning Linear Quadratic Controllers
0
100
200
300
−1
−0.5
0
0.5
1
1.5
S5 − y,v  Qu=.001 , hor=1
0
100
200
300
−5
0
5
10
15
S5 − u  Qu=.001 , hor=1
0
100
200
300
−1
−0.5
0
0.5
1
1.5
S5 − y,v  Qu=.001 , hor=200
0
100
200
300
−0.2
−0.1
0
0.1
0.2
0.3
S5 − u  Qu=.001 , hor=200
Figure 6.7. The disturbance compensation behaviour of system S5 for various
criterion horizons
0
100
200
300
−50
0
50
S1 − u  Qu=.001
0
100
200
300
−50
0
50
S1 − u  Qu=.3
0
100
200
300
−4
−2
0
2
4
S1 − y,w  Qu=.001
0
100
200
300
−4
−2
0
2
4
S1 − y,w  Qu=.3
Figure 6.8. The step response and controller output for system S1 using various
penalties

6.2 Using Linear Quadratic Controllers; Examples and Simulation
179
0
100
200
300
−20
−10
0
10
20
S7 − u Qu=.001
0
100
200
300
−3
−2
−1
0
1
2
3
S7 − y Qu=.3
0
100
200
300
−20
−10
0
10
20
S7 − u Qu=.3
0
100
200
300
−4
−2
0
2
4
S7 − y Qu=.001
Figure 6.9. The step response and controller output for system S7 using various
penalties
1. Standard optimization of the criterion results in a steady state control
error. The size of this depends on the controller output penalty, and system
gain. This is why penalty Qu = 0.001 is not noticeable. An integrator
term must be included in the open-loop or signal u0 must be employed to
eliminate this error.
2. There are systems, S3 for example, where overshoot in the step response
cannot be eliminated by any type of penalty (see Figure 6.10a).
3. As with disturbance compensation, limitation of the controller output is
acceptable for a minimum phase system. However, it can cause instability
in an unstable system and have a very negative eﬀect in a nonminimum
phase system.
4. It can be seen that the conditions for good control behaviour under set
point changes are the same as for disturbance compensation.
5. The steady state control error may increase ramp-like, if the set point
change is also ramp-like (Figure 6.12).
In the examples so far, the simulation of the systems has been discrete. It
remains to test if the controller under consideration behaves in the same way in
a continuous-time system. To do this we use simulation diagram schema2.mdl,
where the system is simulated in continuous-time form. Figure 6.13 illustrates
combined control for step response and disturbance compensation for systems
S1 and S1 with time delay (in a discrete representation of S6). Since a suitable
sampling period was used, all have the same type of behaviour.
In this section we have shown the typical behaviour of LQ controllers on
selected examples. All behaviour was optimal, but we did not always obtain

180
6 Self-tuning Linear Quadratic Controllers
0
200
400
600
-6
-4
-2
0
2
4
6
S3 -y,v Q u=.001
0
100
200
300
-1
-0.5
0
0.5
1
1.5
S6 -y,v Q u=.001
0
100
200
300
-1
-0.5
0
0.5
1
1.5
S7 -y,v Q u=.001
0
100
200
300
-1
-0.5
0
0.5
1
1.5
S9 -y,v Q u=.001
d
a
b
c
0
100
200
300
-3
-2
-1
0
1
2
3
S9 -y Q u=.001
0
100
200
300
-50
0
50
S9 -u Q u=.001
0
200
400
600
-3
-2
-1
0
1
2
3
S3 -y Q u=.001
0
200
400
600
-30
-20
-10
0
10
20
30
S3 -u Q u=.001
b
c
d
a
Figure 6.10. The step response and controller output for systems S3 and S9 for
Qu = 0.001
the type of behaviour required by the user. The main shortcomings were
identiﬁed as being:
•
a steady state control error
•
oscillation in the transfer function process
•
unstable behaviour when the criterion horizon is short
•
instability when the system input signal is limited.
The next section gives a more detailed analysis of the solution to these
problems, the questions raised by the sampling period, the issue of robustness,
and general control properties where the controller was originally developed
for a diﬀerent system.
6.3 Adaptive Control
Sections 6.1 and 6.2 devoted to an introduction to the typical behaviour of LQ
controllers. In all cases the system was known. In many situations the system
is not known, is known only partially, or the plant is so complex that even if
it is known the model used in the controller design can only be an approxi-
mation of the actual plant. In all these cases the ﬁrst step in controller design
is construction of a model. The structure of the model and its parameters are
determined from information about the system (prior information) and from
measured data on the process. It is obvious, however, that such a model is not

6.3 Adaptive Control
181
0
200
400
600
−3
−2
−1
0
1
2
3
S3 − y,w  Qu=.001, omez u 
0
200
400
600
−5
0
5
S3 − u  Qu=.001, omez u 
0
100
200
300
−3
−2
−1
0
1
2
3
S1 − y,w  Qu=.001, omez u 
0
100
200
300
−5
0
5
S1 − u  Qu=.001, omez u 
Figure 6.11. The step response and controller output for systems S1 and S3 when
the controller output is limited
0
100
200
300
−2
−1
0
1
2
3
S6 −y,w  Qu=.001 
0
100
200
300
−20
−10
0
10
20
30
40
S6 −u  Qu=.001 
0
100
200
300
−20
−10
0
10
20
30
40
S6 −u  Qu=.3 
0
100
200
300
−2
−1
0
1
2
3
S6 −y,w  Qu=.3 
Figure 6.12. Ramp set point change response of S6

182
6 Self-tuning Linear Quadratic Controllers
0
500
1000
−3
−2
−1
0
1
2
3
S1 − y,w,v  Qu=.001
0
500
1000
−50
0
50
S1 − u  Qu=.001
0
500
1000
−3
−2
−1
0
1
2
3
S6 − y,w,v  Qu=.001
0
500
1000
−50
0
50
S6 − u   Qu=.001
Figure 6.13. The response behaviour of continuous-time systems S1 and S6 to a
step set point change and noise compensation
equivalent to reality. The behaviour of a controller designed to the model but
used with an actual plant depends not only on the criterion and model used
but also how the model represents the plant. In such situations adaptation
and robustness start to become important. The aim of adaptivity is to tune
the model in such a way that it tries to be, in some respect, close to real-
ity. Robustness implies trying to guarantee that some control properties are
maintained to be kept for all systems from supposed set. These two branches
of control theory are often considered in isolation but in practice they are
both needed simultaneously. Any modelling of a control process is limited to
restricted-complexity models. The information about its parameters is also
limited. The more the model is able to adapt to reality the less robustness is
necessary, and vice versa.
It is clear that when adaptation takes precedence we achieve better control
behaviour, so this section will be devoted to this topic. Identiﬁcation plays a
dominant role in adaptation. This is the process by which we learn about the
properties of the system from measured data. The data can, for the time being,
be regarded as random processes. We will ﬁrst try to formulate the task of LQ
control as a stochastic example. We will demonstrate how the identiﬁcation
process and control synthesis ﬁt into the adaptive approach and the resulting
speciﬁcation for these processes. In conclusion we will again show the typical
behaviour of an LQ controller using the LQ toolbox.

6.3 Adaptive Control
183
6.3.1 The Stochastic Approach to Linear Quadratic Controller
Design
So far we have examined the characteristics of LQ design with regard to deter-
ministic signals. LQ synthesis, however, lends itself to working with random
signals. We need only recall the Wiener synthesis, which made it possible to
design optimal control that minimized quadratic loss for a familiar stochastic
disturbance.
If the system has random output or contains a random component, crite-
rion (6.2) cannot be directly minimized. Instead we must use a deterministic
function of random variables. Experience shows that the mean value of a ran-
dom variable or process is an acceptable function. The criterion appears as
follows
J = E
 k+T

i=k+1

qy (w (i) −y (i))2 + quu (i)2
(6.21)
The introduction of mean value E does not involve any great complications.
To minimize the criterion a model which deﬁnes the required mean value will
be needed. This is regression model (6.4), which has already been introduced,
where the deterministic part of the signal
ˆy (k) = −
n

i=1
aiy(k −i) +
n

i=0
biu(k −i) +
n

i=1
div(t −i) + K
(6.22)
is simultaneously the mean value of output y(k). This can be written as
ˆy(k) = E {y (k) |x (k −1) , u (k)}
(6.23)
where x(k −1) contains the previous inputs and outputs, and signal y(k) is
modelled as
y(k) = ˆy(k) + es(k)
(6.24)
Since es(k) is white noise with zero mean value, E {es(k)} = 0, the terms
with es(k) do not appear in the criterion. However, because E
 
e2
s(k)
!
= σ2
es,
the value of the criterion will increase with each new mean value of σes. This
increment does not depend on u(k) and cannot be inﬂuenced in any way. It
can therefore be ignored when the criterion is minimized.
All this leads to the “Certainty Equivalence Principle”, which states that
when we do not know the true parameters we use the mean value of their
estimates. These mean values are not necessarily acceptable as parameters.
The start of adaptation is a typical situation where the parameter estimates
are wildly oﬀthe correct values.
When this principle is used, synthesis is not based on information on the
state (precision) of the estimated parameters contained in the covariance ma-
trix. Attempts have been made to modify the synthesis so as to give a role
to the quality of identiﬁcation. Because the resulting control algorithm takes

184
6 Self-tuning Linear Quadratic Controllers
account of the identiﬁcation state, this control strategy is referred to as be-
ing “cautious”. Reference [117] is an example of this. Similar results can be
obtained from generalizing the regression model so that the dispersion vari-
ance of the error prediction is a function of the covariance matrix of the
parameters. This model has been given the name linear stochastic transform
[118]. Whereas Equation (6.24) yields σ2
y = σ2
es for the regression model, the
stochastic linear transform uses
σ2
y = σ2
es(1 + ξ)
(6.25)
where ξ = zT (k)C(k)z(k), and z(k) is the data used in prediction y(k). Here
it is seen that noise dispersion is dependent on the value of u(k), which is a
part of z(k).
This model forms the basis for the so-called cautious strategy [118, 25],
Despite partial success in practical applications, it is not often used in adaptive
control due to two serious failings:
•
The start-up covariance matrix C must be chosen very carefully if the
strategy is to yield good results.
•
The strategy very often chooses u(k) to minimize ξ, and not its own cri-
terion. The sequence of u(k) is particularly ill-suited to the identiﬁcation
of parameters, with the result that the covariance matrix does not grow
smaller. This means that the entire process cannot avoid bad control.
6.3.2 The Synthesis of Quadratic Control in Real Time
The use of LQ synthesis in adaptive controllers is governed by the fact that
synthesis of the controller must be constantly repeated as the parameters
alter. Generally speaking therefore, parameter estimation and synthesis are
updated at each sampling period. The restriction placed on the ﬁnal permis-
sible calculation time is also important. On the one hand this is dependent
on the sampling period and speed of the calculation technology, and on the
other it depends on the complexity of the calculation. A calculation method
which requires a constant and, if possible, short calculation time is best suited
to adaptive control. Since this is an iterative process the in which calculation
time depends on a number of factors, there is no guarantee that optimal con-
trol corresponding to the inﬁnite horizon can be calculated in one control
period. There are two alternatives:
(a)In each sampling period a ﬁnite horizon criterion will be minimized. The
length of the horizon must allow enough space for the iterations to complete
the Riccati equation in the time available. A test on convergence of the control
law may be added to this approach and the calculation aborted if there is little
change. Where the iterations are few in number, the start-up conditions for
solving the Riccati equation play a vital role in stability and quality (the
roots of a closed loop) – see Section 6.4.1. This is the matrix S0 which acts
as the tuning “button”. This approach, in which the horizon is shifted further

6.4 The Properties of a Control Loop Containing an LQ Controller
185
and further away during the control process, is known as the receding horizon
strategy or moving horizon strategy MH.
(b) If we require control with an inﬁnite horizon we must spread the it-
erations of the Riccati equation in time. This means that a ﬁxed number of
iterations is performed in each control period, based on the previously at-
tained state, and not on the start-up conditions. The eﬀect of doing this is
that the criterion horizon increases by the chosen number at each control pe-
riod (NSTEP). After a certain time the control law will approach a steady
state solution. This assumes, of course, that we use the same model parame-
ters for the calculation in each control period. This is not necessarily true in
adaptive control. It is impossible to tell what the control law will be when the
parameters are apt to change. Experience shows that this strategy, known as
iteration spread in time (IST), yields good results even when just one iteration
is used during the control period, this being the shortest possible calculation
time.
The IST strategy has another positive eﬀect. It is both a one-step and a
stabilizing strategy. When a strategy has just one step, the future input and
output values are easy to determine and compare with the restriction require-
ment, so, for example, penalty Qu can be directly modiﬁed to maintain the
restriction. This algorithm is known as the MIST (modiﬁed iteration spread
in time), and is described in [119] and [120] and later in Section 6.5.1.
6.4 The Properties of a Control Loop Containing an
Linear Quadratic Controller
Before exploiting the possibilities oﬀered by controllers based on the optimiza-
tion of the quadratic criterion we must be more familiar with their properties.
These can be considered from several angles. We can start with stability.
The issue of stability in the control loop using a given controller is vital: if
behaviour becomes unstable none of the other properties are relevant. The sta-
bility requirement is met by the classic PID type controller and is often used
as the basis for design. A main factor here is the gain of the open-loop (see
Ziegler–Nichols), and, on further analysis, also the gain at various frequencies,
i.e. the frequency characteristic. The diﬃculties in maintaining stability when
using an LQ controller, however, are very diﬀerent.
We will then consider the properties of a control loop using an LQ con-
troller in the time domain. This is vital in LQ control because its design is
based on minimization of the criterion, which itself evaluates the time be-
haviour of the signals.
In the time domain the behaviour of the loop in the two usual cases,
disturbance compensation and set point change, will be observed.
Although in a linear system there is an unambiguous relationship between
the frequency and time domain characteristic, there are a number of properties
which are better observed from the aspect of frequency. Robustness is a major

186
6 Self-tuning Linear Quadratic Controllers
example of these, since by this we mean observing the stability and quality
of the control behaviour in cases where the model featured in the controller
design diﬀers from the true system.
6.4.1 Stability
Stability is probably the most important requirement of a control loop. The
advantage of LQ design is that the stability requirement is, to a certain extent,
automatically built into the controller design. This statement must include
the qualiﬁer “to a certain extent”, because stability can only be theoretically
guaranteed if the model used is a precise match to reality. In practice, the
problem of stability is more complicated. Stability must be ensured even when
reality diﬀers from the mathematical model. This issue will be dealt with in
the section on robustness of design.
The theoretical problems with stability have been published in several ar-
ticles and there is a summary of conclusions in, for example, reference [121],
the basic results of which we will give here. The minimization of quadratic cri-
terion (6.2) results in the solution of the Riccati equation (6.8), the properties
of which can then be used to manipulate stability. Stability is only naturally
guaranteed for inﬁnite horizon T →∞, where the solution is given by the
so-called algebraic Riccati equation (ARE)
S = FT SF −FT SG(GT SG + Qu)−1GT SF + Qx
(6.26)
Theorem 1. We will consider (6.26) corresponding to minimization (6.2)
for T →∞where
•
[F, G] is stabilizable
•
[F, Q1/2
x
] has no observeable mode on the unit circle
•
Qx ≥0, Qu > 0
then
•
there is a single, maximum rank, non-negative deﬁnite, symmetric solution
¯S
•
¯S is the only stabilizing solution, and the matrix of closed loop F −
G(GT ¯SG + Qu)−1GT ¯SF has eigenvalues inside the unit circle.
The matrix relation type A > B can be seen as the deﬁniteness of the
matrix. Therefore matrix A is greater than B (A > B), provided that
A −B > 0, so A −B is a positively deﬁnite matrix.
Stability where the horizon is ﬁnite can easily be solved by transferring
it to an inﬁnite horizon using the following trick. Let the solution to the
Riccati equation corresponding to the horizon of criterion (6.2) T be ST . This
simultaneously relates to ARE solution (6.26) for other state penalties ¯
Qx.
ST = FT ST F −FT SG(GT ST G + Qu)−1GT ST F + ¯Qx
(6.27)

6.4 The Properties of a Control Loop Containing an LQ Controller
187
where ¯Qx = Qx −(ST +1 −ST ). Equation (6.27) is called the fake algebraic
Riccati equation (FARE).
Stability when minimization of the criterion is used is then solved by the
following theorem:
Theorem 2. We will consider Equation (6.27) which deﬁnes ¯Qx. If ¯Qx ≥
0, Qu > 0 , [F, G] is stabilizable, and [F, Qx1/2] is detectable, then ST is
stabilizing, and F −G(GT ST G + Qu)−1GT ST F has eigenvalues inside the
unit circle.
It is clear from the deﬁnition of ¯Qx that, if the sequence of ST decreases,
the stability requirement will automatically be satisﬁed since ST +1 −ST will
be negatively semi-deﬁnite. There is a very strong relationship between mono-
tonicity and stability in the Riccati equation. This can be used as the basis
for formulating conditions which guarantee that the solution to the Riccati
equation will have a stabilizing eﬀect from a given iteration k < T. k = 1, i.e.
the very start, is a special situation.
The theoretical basis creates a theorem on the monotonicity of the solution
to the Riccati equation and the relationship between monotonicity and sta-
bility [122]. The following theorem evaluates the monotonicity of the Riccati
equation:
Theorem on monotonicity: If the Riccati equation has a non-negative
solution in iterations i, i + 1, Si,
Si+1 and if Si > Si+1, is true, then
Sk+i > Sk+i+1, is valid for all k > 0.
Theorem on stability (a): We consider diﬀerence the Riccati Equation
(6.8). If
•
[F, G] is stabilizable
•
[F, Q1/2
x
] is detectable
•
Si+1 ≤Si, for some i
then the closed loop deﬁned by (F −G(Qu + GT SkG)−1GT SkF) is stable
for all k ≥i.
Similarly:
Theorem on stability (b): We consider the diﬀerence Riccati Equation (6.8).
If
•
[F, G] is stabilizable
•
[F, Q1/2
x
] is detectable
•
Si+2 −2Si+1 + Si ≤0, for some i
then the closed loop deﬁned by (F −G(Qu + GT SkG)−1GT SkF) is stable
for all k ≥i.
Before discussing the practical signiﬁcance of these theorems, we should
recall the physical eﬀect of the individual iterations of the Riccati equation in
the development of losses. These properties are most obvious when the aim of
control is to transfer the system from initial conditions x0 to zero (x∞= 0).
Here the Riccati matrix (the R.E. solution) represents the development of a
matrix of quadratic form determining the loss (the value of the criterion). If we

188
6 Self-tuning Linear Quadratic Controllers
have constant Qu, Qy, the loss will grow from the initial value of S0 to value
ST . If at the time k0 + T , the value y(k0 + T ) is very small and consequently
u(k0 + T ) is also small, there will not be a great diﬀerence between ST and
S∞.
If we take the iterations from the initial condition S0 = 0, corresponding
to the formulation of criterion (6.2), the quadratic form must increase and so
we never have the situation where Si > Si+1.
If we want to ensure stability we must ﬁnd S0, Qy, Qu such that S0 > S1,
or Si+2 −2Si+1 +Si ≤0. This is not possible with basic criterion (6.2) where
S0 = 0 is supposed. S must increase in some way as it results from the principle
of cumulative loss which S represents.
When stability is to be ensured using the quadratic criterion with a ﬁnite
horizon, the criterion must be changed to include a penalty on the ﬁnal state
represented by matrix S0. The new criterion takes the form
J =
k+T

i=k+1

qy (w (i) −y (i))2 + quu (i)2
+ xT (T )S0x(T )
(6.28)
S0 > S∞must be true if the sequence of Si is to decrease monotonically.
The penalty on the ﬁnal state S0 must be greater than the entire cumulative
loss of the whole compensation process of the initial state. Then cumulative
loss may decrease, since the loss of each individual step in the minimization
process is compensated for by a decrease in the value of the ﬁnal state, and
therefore a decrease in its contribution to the overall loss. The following ex-
ample explains how it is possible for the cumulative loss to decrease. If we
consider 0-step control, loss is J0 = xT
0 S0x0. In one-step control, the overall
loss can be written as J1 = xT
1 S0x1 + xT
0 Qxx0 (the ﬁnite state is now x1),
and this value may be less than J0 because value x1 is already smaller than
x0 due to control. This process may be continued.
As stated in reference [121] and as can be seen in the example, not even the
choice S0 > S∞can guarantee that S0 > S1. This also applies to the simple
choice S0 = αI, where α is a real positive number with a high value. No high
value of α can ensure stability in feedback from the very beginning of the
solution of the Riccati equation. One way of ﬁnding S0 to satisfy S0 > S1 is
given in reference [123]. However, this involves inversion of the system matrix
F−1. This cannot be applied to our example because the state matrix we use
is always singular.
Initial value S0 ̸= 0 means an extra penalty on the ﬁnite state. If T is
large, it will have only a small eﬀect on the quality of control. However, if the
horizon is small, the choice of S0 ̸= 0 can signiﬁcantly alter control behaviour.
These remarks lead to the conclusion that it is relatively diﬃcult to guar-
antee stability in a closed loop for a ﬁnite horizon T . Still, the situation is not
entirely hopeless.

6.4 The Properties of a Control Loop Containing an LQ Controller
189
1. The stability requirements described above are suﬃcient, but not necessary;
the examples given here will show these conditions are very strict.
2. Stability need not be guaranteed right from the very ﬁrst iteration. An
analysis of selected examples will guide us in our choice of horizon length.
3. We will look at cases where we can exploit knowledge previously obtained
on stabilizing control or a priori knowledge of S gained from the minimization
of a similar criterion (perhaps for a diﬀerent value of Qu or T , etc).
In order to ensure the stability of an LQ controller it is wise to:
•
select a suﬃciently long horizon for an oﬀ-line calculation and then check
that some of the suﬃcient stability conditions are met;
•
use the IST strategy in an adaptive environment as this will help us achieve
an asymptotic inﬁnite horizon.
The Examples
The evolution of the Riccati equation iteration understandably diﬀers from
system to system, and from penalty to penalty. We will use our chosen exam-
ples to demonstrate at least a few typical situations. The following illustrations
show the position of the roots of a closed loop which would be obtained using
a controller derived from the ith iteration of the Riccati equation. They will
also illustrate the ﬁrst and second diﬀerences of this equation (or more pre-
cisely, the eigenvalues of the matrix of the ﬁrst and second diﬀerence of the
Riccati equation for individual iterations i = 1, 2, 3, ..., T.
We can inﬂuence the number of iterations of the Riccati equation required
to achieve stability using penalty Qu and the penalty on the ﬁnite state S0.
We will take S0 = αI. This will be demonstrated on stable minimum phase
system S1, unstable system S6 and nonminimum phase system S8.
Figures 6.14 and 6.15 show examples of a stable minimum phase system.
Here we can see that stabilizing control can be achieved regardless of the size
of the penalty or the initial penalty on state S0. We should note from the
illustrations of the behaviour of the ﬁrst and second diﬀerences of the Riccati
equation how conservative the suﬃciency condition of negative deﬁniteness is
for both diﬀerences. For example, in Figure 6.15b there is no stability at all
according to the ﬁrst diﬀerence, stability is achieved from the tenth iteration
according to the second diﬀerence. And yet the root locus in Figure 6.15a
indicates that control remains in the area of stability for all iterations.
Evidently the convergence of the Riccati equation for penalty Qu = 1 is
somewhat slower than for Qu = 0.001. This is because the roots of the closed
loop are considerably closer to the unit circle.
The next series of illustrations (Figures 6.16 and 6.17) gives similar ex-
amples for an unstable system. We should note that the start from S0 = 0
took place in the area of instability and, where higher penalty Qu = 1 is used,
more steps are required to attain stabilizing control. As before, the penalty
on the ﬁnite state S0 = 1000 speeded up convergence. In addition to this, the
iterations took place in the stable area right from the start.

190
6 Self-tuning Linear Quadratic Controllers
The last series of illustrations (Figures 6.18–6.21) shows the same examples
performed on nonminimum phase system S8. The larger penalty Qu = 1
used in this system produces more satisfactory iteration behaviour, where
all the iterations lead to stabilizing control. The root locus corresponding to
each iteration was dramatically changed by adding an initial penalty. The
behaviour illustrated in Figure 6.21 is especially noteworthy. It can be seen
from the root locus that iteration started in the area of stability, soon left it,
and then ﬁnally returned after step 36. The behaviour of the eigevalues of the
second diﬀerence of the Riccati equation is also interesting. In Figure 6.21b it
appears to be an indeﬁnite matrix as far as step 36. In this case, the suﬃcient
conditions of stability give the correct region for stability.
6.4.2 The Characteristics of Linear Quadratic Control in the Time
Domain
The previous section dealt with stability as the most vital property of control.
Users, however, are more interested in the behaviour of closed loop responses.
The system output not only depends on input but is also aﬀected by various
disturbances. In this section we show in greater depth how to inﬂuence dis-
turbance compensation, and how an adaptive controller reacts to a situation
where the type of disturbance acting does not correspond to the regression
model’s deﬁnition of disturbance. Later, we will discuss compensation for mea-
surable disturbance where we can make use of a feedforward process. Finally,
we will concentrate in more detail on the problems of set point control and
observe the transitions to set point changes. The resulting behaviour of the
closed loop is then the superposition of cases previously mentioned.
Compensation of Disturbance
There are many types of disturbance which act on the output of the controlled
process. It may be a random process or perhaps the response of some ﬁlter to
a step. If we cannot measure the source of the disturbance, the disturbance
must be modelled. In Chapter 3 we showed that the regression model models
both system and disturbance, and its characteristics are modelled by ﬁlter
1
A(z−1). Here we consider stochastic disturbance. The characteristics of control
behaviour in compensating deterministic disturbance are similar to those of
set point control, which is dealt with in the concluding part of this section.
Quadratic criterion synthesis of the controller can only ensure optimal
compensation for disturbance modelled by the regression model. It is there-
fore important that the model represents the characteristics of both system
and disturbance. First we look at a situation where the disturbance is char-
acterized by the regression model. We described typical behaviour in Section
6.2, together with the inﬂuence of basic parameter Qu.
In this part we concentrate on two issues:

6.4 The Properties of a Control Loop Containing an LQ Controller
191
−1
−0.5
0
0.5
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
real(roots)
imag(roots)
 System S1, Qu=.001, S0=0; closed loop poles for N=1,...100
Figure 6.14a. Closed loop pole placement
0
2
4
6
8
10
12
14
16
18
20
−2
0
2
4
6
8
iterations
roots
System S1; Qu=.001, S0= 0; eig(dS) for N=[1 ...100]
0
2
4
6
8
10
12
14
16
18
20
−4
−2
0
2
4
iterations
roots
System S1; Qu=.001, S0= 0; eig(d2S) for N=[1 ...100]
Figure 6.14b The ﬁrst and second diﬀerences of the Riccati matrix
Figure 6.14. System S1: Qu = 0.001, S0 = 0, horizon T = [1, ..., 100]
•
how does the sampling period aﬀect the quality of compensation?
•
what will the control behaviour be when the system is aﬀected by distur-
bance which diﬀers from that modelled by the regression model?
In our evaluation of the eﬀect of the sampling period we use a continuous-
time system with transfer function G(s) =
B(s)
A(s) and random disturbance
obtained as white noise passes through a ﬁlter with transfer function F(s) =
1/A(s). If the noise dispersion is σ2
es, the mean value for the ﬁlter output will
also be zero and dispersion will be given by

192
6 Self-tuning Linear Quadratic Controllers
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1.1
1.2
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
real(roots)
imag(roots)
 System S1, Qu=1, S0=0; closed loop poles for N=1,...100
Figure 6.15a. Closed loop pole placement
0
2
4
6
8
10
12
14
16
18
20
−10
0
10
20
30
iterations
roots
 System S1, Qu=1, S0=0; eig(dS) for N=1,...20
0
2
4
6
8
10
12
14
16
18
20
−2
0
2
4
6
iterations
roots
 System S1, Qu=1, S0=0; eig(d2S) for N=1,...20
Figure 6.15b The ﬁrst and second diﬀerences of the Riccati matrix
Figure 6.15. System S1: Qu = 1, SO = 0, horizon T = [1, ..., 100]
σ2
y = σ2
s
1
πi
%
1
A(s)A(−s)ds
(6.29)
If we consider a discrete controller using a discrete process model in a
continuous-time process, then a single continuous-time process is character-
ized by a set of discrete models, depending on the sampling period chosen.
Disturbance dispersion does not change with sampling. However, dispersion
of the generating white noise does. This enables one to obtain a relation for
the dispersion of actuating noise in the form

6.4 The Properties of a Control Loop Containing an LQ Controller
193
−1
−0.5
0
0.5
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
real(roots)
imag(roots)
 System S6, Qu=.001, S0=0; closed loop poles for N=1,...100
Figure 6.16a. Closed loop pole placement
0
2
4
6
8
10
12
14
16
18
20
−5
0
5
10
15
iterations
roots
 System S6, Qu=.001, S0=0; eig(dS) for N=1,...20
0
2
4
6
8
10
12
14
16
18
20
−10
−5
0
5
10
iterations
roots
 System S6, Qu=.001, S0=0; eig(d2S) for N=1,...20
Figure 6.16b The ﬁrst and second diﬀerences of the Riccati matrix
Figure 6.16. System S6: Qu = 0.001, SO = 0, horizon T = [1, ..., 100]
σ2
es,d = πi
σ2
y
&
1
A(z)A(z−1) dz
z
(6.30)
It can be shown how its size is aﬀected by the sampling period. We take
as an example, system (ﬁlter) F(s) = 1/(s + 1)2. Table 6.1 gives the discrete
transfer functions of the ﬁlter which correspond to the value of the integral,
and resulting dispersion σ2
es for T0 = 0.1 s, 0.2 s, 0.5 s and 1 s.
Result 1
Dispersion σ2
esd of the generating white noise will fall as the frequency of

194
6 Self-tuning Linear Quadratic Controllers
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1.1
1.2
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
real(roots)
imag(roots)
 System S6, Qu=1, S0=0; closed loop poles for N=1,...100
Figure 6.17a. Closed loop pole placement
0
5
10
15
20
25
30
35
40
−200
0
200
400
600
800
iterations
roots
 System S6, Qu=1, S0=0; eig(dS) for N=1,...40
0
5
10
15
20
25
30
35
40
−100
−50
0
50
100
iterations
roots
 System S6, Qu=1, S0=0; eig(d2S) for N=1,...40
Figure 6.17b The ﬁrst and second diﬀerences of the Riccati matrix
Figure 6.17. System S6: Qu = 1, SO = 0, horizon T = [1, ..., 100]
Table 6.1. Values for white noise dispersion in relation to the sampling period
T0[s] Filter transfer function Integral value Noise dispersion
0.1
1
z−2 −1.81z−1+ 0.819
305.3
0.0033
0.2
1
z−2−1.63z−1+ 0.67
46.614
0.0215
0.5
1
z−2−1.21z−1+ 0.368
5.4156
0.1847
1
1
z−2−0.736z−1+ 0.135
1.7562
0.5694

6.4 The Properties of a Control Loop Containing an LQ Controller
195
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1.1
1.2
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
 System S8, Qu=.001, S0=0; closed loop poles for N=1,...200
Figure 6.18a. Closed loop pole placement
0
10
20
30
40
50
60
70
80
90
100
−20
0
20
40
60
80
iterations
roots
 System S8, Qu=.001, S0=0; eig(dS) for N=1,...200
0
10
20
30
40
50
60
70
80
90
100
−20
−10
0
10
20
iterations
roots
 System S8, Qu=.001, S0=0; eig(d2S) for N=1,...200
Figure 6.18b The ﬁrst and second diﬀerences of the Riccati matrix
Figure 6.18. System S8: Qu = 0.001, SO = 0, horizon T = [1, ..., 100]
sampling increases (T0 gets shorter) if continuous-time random disturbance is
represented by a discrete model for various sampling periods.
Result 2
Since σ2
esd is the lower boundary of attainable values for the control criteria,
better disturbance compensation can be achieved by increasing the sampling
period.
These results will be tested in simulation according to the diagram given
in Figure 6.22.
The two continuous-time systems seen here are modelled by the usual
method involving integrators and feedback. The aim of Transfer function 1 is

196
6 Self-tuning Linear Quadratic Controllers
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1.1
1.2
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
 System S8, Qu=1, S0=0; closed loop poles for N=1,...200
Figure 6.19a. Closed loop pole placement
0
10
20
30
40
50
60
70
80
90
100
−50
0
50
100
150
iterations
roots
 System S8, Qu=1, S0=0; eig(dS) for N=1,...160
0
10
20
30
40
50
60
70
80
90
100
−10
0
10
20
30
40
iterations
roots
 System S8, Qu=1, S0=0; eig(d2S) for N=1,...160
Figure 6.19b The ﬁrst and second diﬀerences of the Riccati matrix
Figure 6.19. System S8: Qu = 1, SO = 0, horizon T = [1, ..., 100]
to generate disturbance. Suitable random disturbance is obtained by feeding
a random signal into the system input.
We have used a limited spectrum random signal which is, in eﬀect, a re-
alization of discrete white noise. We can attain the kind of behaviour which
imitates reality by manipulating the bandwidth of random noise, the scale,
and the length of the graph records. This signal is added to the system output,
where it simultaneously represents uncontrolled output. Transfer function rep-
resents the controlled process itself, which is, again, continuous-time – as it is
in reality.

6.4 The Properties of a Control Loop Containing an LQ Controller
197
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1.1
1.2
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
real(roots)
imag(roots)
 System S8, Qu=1, S0=1000; closed loop poles for N=1,...200
Figure 6.20a. Closed loop pole placement
0
10
20
30
40
50
60
70
80
90
100
−100
−50
0
50
100
iterations
roots
 System S8, Qu=1, S0=1000; eig(dS) for N=1,...160
0
10
20
30
40
50
60
70
80
90
100
−100
−50
0
50
100
iterations
roots
 System S8, Qu=1, S0=1000; eig(d2S) for N=1,...160
Figure 6.20b The ﬁrst and second diﬀerences of the Riccati matrix
Figure 6.20. System S8: Qu = 1, SO = 1000, horizon T = [1, ..., 100]
Since we are using an LQ controller based on a regression model of the
process, the ﬁlter and system must be set so as to meet the conditions for
representing the process as a regression model. This is why both Transfer
function and Transfer function1 have the same denominator.
A further condition, which is that the ﬁlter numerator should equal 1,
cannot be met in all sampling periods. In fact, it is diﬃcult to derive its dis-
crete transfer function because the input and output are generally sampled at
diﬀerent periods. It helps if we obtain the discrete (regression) model directly
from the identiﬁcation data, rather than transforming from the Laplace to the
Z-image. This is how it would normally be done in practice.

198
6 Self-tuning Linear Quadratic Controllers
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1.1
1.2
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
real(roots)
imag(roots)
 System S8, Qu=.001, S0=1000; closed loop poles for N=1,...200
Figure 6.21a. Closed loop pole placement
0
10
20
30
40
50
60
70
80
90
100
−100
−50
0
50
100
iterations
roots
 System S8, Qu=.001, S0=1000; eig(dS) for N=1,...160
0
10
20
30
40
50
60
70
80
90
100
−10
−5
0
5
10
iterations
roots
 System S8, Qu=.001, S0=1000; eig(d2S) for N=1,...160
Figure 6.21b The ﬁrst and second diﬀerences of the Riccati matrix
Figure 6.21. System S8: Qu = 0.001, SO = 1000, horizon T = [1, ..., 100]
The discrete blocks representing the controller (i.e. identiﬁcation), LQ
synthesis, and the controller itself, will all have an optional sampling period.
Each image also illustrates the dispersion of model’s prediction error and
this represents the minimum possible value of the dispersion of disturbance
compensation.
Conclusions
1. It is clear from the behaviour seen in Figures 6.24–6.26 that the quality of
disturbance compensation depends on the sampling period. A small penalty on
u, Qu = 0.001 was used throughout the examples. The relationship between
the quality of compensation and the sampling period is especially obvious

6.4 The Properties of a Control Loop Containing an LQ Controller
199
Zero−Order
Hold5
Zero−Order
Hold3
Zero−Order
Hold2
Zero−Order
Hold1
z
1
Unit Delay
1
s  +2s+1
2
Transfer Fcn1
1
s  +2s+1
2
Transfer Fcn
uout
To Workspace3
yout
To Workspace2
Sum2
Signal
generator
Scope1
Scope
Saturation
Ts
Rate Transition
Mux
Mux1
Mux
Mux
−K−
Gain4
u[1]^2
Fcn
0
Display
z−1
num(z)
Discrete−Time
Integrator
LQ 
 Adaptive 
  Controller 
Controller
Band−Limited
White Noise
Figure 6.22. Diagram of the simulation of noise compensation
when a small value is chosen.
2. The size of the controller output is independent of the sampling period.
More frequent sampling gives better compensation without increasing the
amplitude of the input. Naturally, however, the input frequency spectrum
is higher.
Let us turn now to the problem of compensation of disturbance where the
properties are not characterized by the regression model. Two possibilities
must be taken into account:
•
a ﬁxed LQ controller
•
an adaptive controller.
The case of a ﬁxed LQ controller is relatively easy to deal with. Simply,
it will not provide optimal compensation of a disturbance. The method of
compensation is governed by the properties of the closed loop created by the
system and controller. The stability is not aﬀected.
Adaptive LQ control case is more complicated. The mismatch between
the characteristics of the disturbance and those represented by a ﬁlter forces
the identiﬁcation process to ﬁnd coeﬃcients ¯ai of
1
¯
A(z−1) so that it predicts
the disturbance as eﬃciently as possible. This, of course, also modiﬁes the
transfer function of the system model. The behaviour of a controller based on
such parameters cannot be determined; it can only be estimated through an
analysis of the robustness of the controller.
We can now demonstrate this kind of situation on some simple examples.
Disturbance will be generated by a ﬁlter which has a transfer function other
than
1
A(z).

200
6 Self-tuning Linear Quadratic Controllers
We have chosen two extreme cases for system S1 to demonstrate its be-
haviour.
1. Factor 1 −z−1 has been added to the dynamic of the noise ﬁlter.
2. Factor 1 −0.98z−1 has been added to the ﬁlter numerator.
In the series illustrated by Figure 6.26 we can see an example of standard
noise compensation, in which the conditions for the regression model are sat-
isﬁed. This is followed by three examples where noise is generated according
to point 1. Clearly this noise is “slower”. In Figure 6.27b it is compensated by
an adaptive controller using a second-order model. The estimated parameters
diﬀer signiﬁcantly from those of the system itself. Figure 6.27c features com-
pensation performed by a third-order controller, where the structure of the
model permits the inclusion of the entire dynamic of the ﬁlter. Compensation
is perfect. In the ﬁnal ﬁgure, a ﬁxed controller designed using the system pa-
rameters is used for compensation. Compensation here is rather worse than
for the adaptive controller using the same structure. These results are given
in numeric form in Table 6.2.
Table 6.2. Results of simulation testing
Figure Identiﬁed parameters B
A
Loss
6.26b
0.0047z−2 0.0044z−1
z−2−1.816z−1+ 0.804z−2
0.049
6.26c
0.0047z−3−0.0003z−2−0.0044z−1
z−3−2.815z−2+ 2.6373z−1−0.82 0.0366
6.26d
ﬁxed parameters
0.0519
The second situation is documented in the series of illustrations in Fig-
ures 6.27. Figures 6.27a and 6.27c show disturbance and system output. Dis-
turbance here is clearly “fast” and the system is unable to compensate it
adequately. The failure of the regression model to meet the assumption of
noise results in estimated parameters which diﬀer from those of the system.
A controller designed using these parameters is still better than one designed
using the system parameters. The character of compensation is roughly the
same, but the controller which uses estimated parameters has a noticeably
smaller controller output (Figure 6.28b) compared to the one which was de-
signed using the system parameters (Figure 6.28d). The simulation results are
given in Table 6.3.
Shifting the parameters alters the system model, with the potential danger
that instability will arise due to the diﬀerence between the model used in the
design and the true system. We will discuss this point in the section dealing
with robustness. So as to avoid potential loss of stability we must:
•
use a model structure which permits more complex disturbances to be
modelled (a higher-order model);

6.4 The Properties of a Control Loop Containing an LQ Controller
201
0
5
10
15
20
25
30
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
time(seconds)
Figure 6.23a. Output (solid line) and disturbance (dotted line)
0
5
10
15
20
25
30
−200
−150
−100
−50
0
50
100
150
200
time(seconds)
Figure 6.23b Input
Figure 6.23. System S1:T0 = 0.5s, Euler, ˆσes = 0.6454
Table 6.3. Results of simulation testing
Figure Identiﬁed parameters B
A
Loss 
u2
6.27a
0.0055z−2+ 0.0069z−1+ 0.0034
z−2−1.026z−10.145
1.67 3.83e3
6.27c
ﬁxed parameters
1.58 35 900

202
6 Self-tuning Linear Quadratic Controllers
0
5
10
15
20
25
30
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
time(seconds)
Figure 6.24a. Output (solid line) and disturbance (dotted line)
0
5
10
15
20
25
30
−200
−150
−100
−50
0
50
100
150
200
time(seconds)
Figure 6.24b Input
Figure 6.24. System S1: T0 = 0.1 s, Euler, ˆσes = 0.0983
•
ﬁlter the data. This, of course, assumes a knowledge of the character of
the disturbance, in order to determine the ﬁlter.
A combination of both approaches can be employed.
Figure 6.28 illustrates a Simulink R
⃝diagram in which the signals are
ﬁltered for identiﬁcation. The use of the ﬁlters ensures that the identiﬁed
parameters represent only some of the characteristics of the process. For ex-
ample: an integration factor is often added to the open-loop to ensure zero
steady state error. This factor will appear in the estimated parameters. This

6.4 The Properties of a Control Loop Containing an LQ Controller
203
0
5
10
15
20
25
30
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
time(seconds)
Figure 6.25a. Output (solid line) and disturbance (dotted line)
0
5
10
15
20
25
30
−200
−150
−100
−50
0
50
100
150
200
time(seconds)
Figure 6.25b Input
Figure 6.25. System S1: T0 = 0.01 s, Euler, ˆσes = 0.0185
means the disturbance ﬁlter will contain the factor as well. This dramatically
changes the noise properties. For a better solution see Section 6.5.1.
The External Measurable Variable
If we can measure the source of disturbance v(k) , which generates the dis-
turbance at the output (Figure 3.1) ,
yv = D(z−1)
A(z−1)

204
6 Self-tuning Linear Quadratic Controllers
50
100
150
200
−0.5
0
0.5
1
time
y,v
integrated noise, fixed controller
50
100
150
200
−0.5
0
0.5
1
time
y,v
integrated noise, 3rd order contr.
50
100
150
200
−0.5
0
0.5
1
time
y,v
integrated noise, 2rd order contr.
50
100
150
200
−0.5
0
0.5
1
time
y,v
stand.  noise, 2rd order contr.
Figure 6.26. Compensation of a disturbance where the ﬁlter denominator is ex-
panded by 1 −z−1
Sum2
Subsystem
Signal
generator
Mux
Mux1
Mux
Mux
Graph1
Graph
1
Gain4
1−z −1
1 
Discrete Filter1
1−z −1
1 
Discrete Filter
.01
z  −1.81z+.819
2
Discrete
Transfer Fcn2
num(z)
z  −1.81z+.819
2
Discrete
Transfer Fcn
LQ
 Adaptive 
 Incremental
 Controller
Controller
0
Constant1
Figure 6.27. Compensation of disturbance where the ﬁlter numerator has been
expanded by 1 −0.98z−1
it is a good idea to use this knowledge in compensation. In practice, distur-
bance can commonly be measured, since it need not be true disturbance. We
can use any signal connected in some way with the system output if its inﬂu-
ence can be described by ﬁlter D(z−1)
A(z−1) . The source of the disturbance in this
case need not be white noise but any signal generated by ﬁlter
Fv =
1
Av(z−1)

6.4 The Properties of a Control Loop Containing an LQ Controller
205
Sum2
Subsystem
Signal
generator
Mux
Mux1
Mux
Mux
Graph1
Graph
1
Gain4
1−z −1
1 
Discrete Filter1
1−z −1
1 
Discrete Filter
.01
z  −1.81z+.819
2
Discrete
Transfer Fcn2
num(z)
z  −1.81z+.819
2
Discrete
Transfer Fcn
LQ
 adaptive 
 incremental
 controller
Controller
0
Constant1
Figure 6.28. Simulink
R
⃝diagram using ﬁlters for identiﬁcation
D(z)
A(z)
meas. dist 
1
Av(z)
autoregr
uout
To Workspace1
yout
To Workspace
Sum2
Sum1
Sum
Signal
Generator
Scope1
Scope
Saturation
Mux
Mux
−K−
Gain
Clw 
1 
Filter4
Clu0 
1 
Filter3
Clw 
1 
Filter2
1 
R 
Filter1
S 
1 
Filter
u[1]^2
Fcn
kn(z)
Af(z)
Disturbance
0
Display
0.1
z−1
Discrete−Time
Integrator
0
Constant3
Band−Limited
White Noise1
Band−Limited
White Noise
B(z)
A(z)
    system
Figure 6.29. Simulink
R
⃝diagram of the compensation for measurable disturbance
Coeﬃcients avi of this ﬁlter now represent the dynamic of the measurable
disturbance. We either know these, or can identify them in the same way as
we identify the system parameters.
The Simulink R
⃝diagram in Figure 6.29 will be used to demonstrate the
compensation of measurable disturbance. In this diagram the measurable dis-
turbance is generated randomly by ﬁlter Fv, shown above. The value is mea-
sured and used in the next feedforward component of the controller with
transfer function Cld(z−1)
R(z−1) . The output disturbance is governed by the regres-
sion model as it passes through ﬁlter D(z−1)
A(z−1) .

206
6 Self-tuning Linear Quadratic Controllers
Nonmeasurable disturbance is suppressed in the ﬁrst three responses
shown in Figure 6.30 so as to highlight the compensation of measurable
disturbance. Figure 6.30a shows a process in which disturbance is not be-
ing measured; Figure 6.30b one where the disturbance is measured but we
are unfamiliar with its properties (with the model which generates it); Fig-
ure 6.30c shows the situation where the disturbance is fully understood, and
Figure 6.30d shows the overall behaviour with measured and unmeasured dis-
turbance and set point transition.
0
50
100
150
200
−3
−2
−1
0
1
2
3
a  loss=.431                  time
yd,y
disturbance not measured
0
50
100
150
200
−3
−2
−1
0
1
2
3
b  loss=.113                  time
yd,y
dist. measured, av not used
0
50
100
150
200
−3
−2
−1
0
1
2
3
c  loss=.0072                  time
yd,y
dist. measured, av  used
0
50
100
150
200
−3
−2
−1
0
1
2
3
d                           time
yd,y
measured dist. + noise + set point
Figure 6.30. Diﬀerent forms of compensation for external disturbance, (- -) un-
compensated disturbance
Set point Tracking
Set point tracking is one of the most important functions of the control loop.
The quality of control is often judged on the form of response to the typical
changes of the set point (steps – the step response). When we are design-
ing a controller to track the set point we ﬁnd the following diﬀerences with
disturbance compensation:
•
The transfer function from disturbance to output diﬀers from the transfer
function from set point to output.
•
A further signal must be taken into account in the minimization criterion
and, in addition, we must know its future values.
Unlike most of the other signals in the loop, a knowledge of the future
behaviour of the set point is, in practice, very common and natural. Moreover

6.4 The Properties of a Control Loop Containing an LQ Controller
207
it can almost always be applied simply by delaying the true change in the set
point over several (tens of) sampling periods.
The standard approach to optimization, in which the unknown values of
the signals in the criterion are predicted using a model, can always be used.
This approach can also be applied to set point control. The model used to
predict the future constant set point is
w(k) = w(k −1)
(6.31)
Let us discuss in greater depth the situation where the future desired out-
put values are known. If we look at the diagram of the controller (Figure 6.2),
we can see that optimization generates both the feedback and feedforward
parts of the controller. It is important to remember that, in an adaptive con-
troller, the feedforward component is an integral part of the control transfer
function, and any discrepancy between model and reality may be reﬂected in
an error in set point tracking. The ﬁlter transfer function in the feedforward
component is
u
w =
F(z)
R(z−1)
(6.32)
when F (z) = f0 + f1z + f2z2 + . . . + fnwznw
Transfer function (6.32) is noncausal, as expected. The coeﬃcients of the
transfer function are obtained using the optimization process (see Section 6.7).
If the control signal is constant, the transfer function can be simpliﬁed
togive
u
w =
nw
i=1 fi
R(z−1) .
Term nw
i=0 fi is obtained using the optimization process, by accumulating
all future set points into one column of matrix S. It is simpler to use ﬁlter
(6.32) immediately if other types of future behaviour are known, even though
it is possible to obtain speciﬁc results for each given signal. We will try to
demonstrate this using a ramp example. When the ramp has initial value w0
and increment δw the ﬁlter output can be written as
uw =
nw
i=1 fi
R(z−1) w0 +
nw
i=1 ifi
R(z−1) δw
In the optimization procedure this is done by giving the Riccati matrix an
extra column which corresponds to the increment on the ramp.
Figure 6.31 shows the simulation plan for experiments on set point transi-
tions, including pre-programming. Since Simulink R
⃝is unable to generate a
vector of future values, it must work with delayed real values and compare the
system output with the delayed set point. The delay is eﬀected in the oldval
block. The product nw
i=1 fiwt+i is performed in the block trail1. The remain-
ing blocks are standard. The controller parameters with pre-programming are

208
6 Self-tuning Linear Quadratic Controllers
calculated by the lqex3.m procedure which consists of calculating steady op-
timal control, and subsequently the pre-programming component. Otherwise
the form of the pre-programming ﬁlter would be aﬀected by the initial condi-
tions for the Riccati equation. Adaptive controllers with a pre-programming
property are contained in the Simulink R
⃝scheme adlqsw or those containing
“w” in its name. Let us now look at the typical behaviour of a simple S1
system.
Figure 6.32 shows the step response. The corresponding reaction of the
controller output can be seen in Figure 6.33. The coeﬃcients of the pre-
programming ﬁlter are plotted in Figure 6.34, where we see that fi = 0 for
i > 16. Therefore, if the pre-programming length is made 10 (see Figure 6.35),
the steady state value will be greater than the set point because we neglected
the negative coeﬃcients for i > 10. Similarly, when the pre-programming
length is 5 (Figure 6.36), the output does not reach the required value. In the
remaining ﬁgures 6.37–6.39 we illustrate output, input and coeﬃcients fi for
a controller using a diﬀerent penalty on the input. Figures 6.40–6.42) show
control of nonminimum phase systems.
uout
To Workspace1
yout
To Workspace
Sum2
Sum1
Sum
Signal
Generator
Scope1
Scope
Saturation
Mux
Mux
−K−
Gain
Clu0 
1 
Filter3
Clw 
1 
Filter2
1 
R 
Filter1
S 
1 
Filter
trial1
Fcn2
oldval
Fcn1
u[1]^2
Fcn
kn(z)
Af(z)
Disturbance
0
Display
0.1
z−1
Discrete−Time
Integrator
0
Constant3
Band−Limited
White Noise
B(z)
A(z)
    system
Figure 6.31. Simulation with pre-programming
Conclusions
Pre-programming uses information on future control and so achieves optimal
response both from the point of view of output quality and demands placed
on the input.
Zero Steady State Error
A typical drawback of LQ design using minimization criterion (6.2) is the
nonzero steady state error in the step response when the system contains no
integrator term. This oﬀset is particularly obvious when, for whatever reason,

6.4 The Properties of a Control Loop Containing an LQ Controller
209
0
10
20
30
40
50
60
−0.5
0
0.5
1
Soustava No 1 ; Qu= 0.001 ; nstep= 20
Cas
Y, W
Figure 6.32. S1 output, 20 steps ahead strategy
0
10
20
30
40
50
60
70
−2
−1
0
1
2
3
4
5
6
7
8
Soustava No 1 ; Qu= 0.001 ; nstep= 20
Cas
U
Figure 6.33. S1 input, 20 steps ahead strategy
a higher penalty Qu must be used. We have already met with this feature in
Section 6.2
The standard solution to this problem is to add an integrator to the open-
loop. However this changes the transfer function of the disturbance ﬁlter as
well and, by doing so, also changes its assumed character. Though the response
to the transition improves, the disturbance compensation may deteriorate. We
must use an ARMAX model and assume that C = z −1 so that the addition
of an integrator does not change the compensation of disturbance.

210
6 Self-tuning Linear Quadratic Controllers
0
2
4
6
8
10
12
14
16
18
20
−6
−5
−4
−3
−2
−1
0
1
Soustava No 1 ; Qu= 0.001 ; nstep= 20
Cas
Figure 6.34. S1: coeﬃcients fi 20 steps ahead strategy
0
5
10
15
20
25
30
−0.5
0
0.5
1
Soustava No 1 ; Qu= 0.001 ; nstep= 10
Cas
Y, W
Figure 6.35. S1: output, 10 steps ahead strategy
The steady state error (oﬀset) can be eliminated by penalizing the incre-
ment on u, i.e. penalizing △u itself. This penalty does not limit the size of
the controller output, only changes in it.
Another solution can be derived from criterion (6.3) where we take account
of another signal: the reference input. In reality it is more natural not to
penalize the entire controller output, only the part remaining after subtraction

6.4 The Properties of a Control Loop Containing an LQ Controller
211
0
5
10
15
20
25
30
−0.5
0
0.5
1
Soustava No 1 ; Qu= 0.001 ; nstep= 5
Cas
Y, W
Figure 6.36. S1: output, 5 steps ahead strategy
0
10
20
30
40
50
60
70
−0.5
0
0.5
1
Soustava No 1 ; Qu= 0.01 ; nstep= 30
Cas
Y, W
Figure 6.37. S1: output, 30 steps ahead strategy
of the value of u needed to achieve the required output level. The required
size of u0 can be obtained in two ways:
•
u0 can be taken as another variable to be used in the minimization criterion
(see [124]).
•
u0 is a signal which is proportional to the set point and must be added to
u(k) to compensate for the oﬀset.

212
6 Self-tuning Linear Quadratic Controllers
0
10
20
30
40
50
60
70
80
−0.5
0
0.5
1
1.5
2
2.5
3
3.5
Soustava No 1 ; Qu= 0.01 ; nstep= 30
Cas
U
Figure 6.38. S1: input, 30 steps ahead strategy
0
5
10
15
20
25
30
−1.4
−1.2
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
Soustava No 1 ; Qu= 0.01 ; nstep= 30
Cas
Figure 6.39. S1: coeﬃcients fi 30 steps ahead strategy
The second method is easier to interpret and is used, e.g. in Simulink R
⃝
diagram schema1p.m, illustrated in Figure 6.43. Signal u0 will be used for
other purposes in the following section.

6.4 The Properties of a Control Loop Containing an LQ Controller
213
0
10
20
30
40
50
60
70
−0.5
0
0.5
1
Soustava No 5 ; Qu= 0.01 ; nstep= 30
Cas
Y, W
Figure 6.40. Nonminimum phase system S6: output
0
10
20
30
40
50
60
70
80
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Soustava No 5 ; Qu= 0.01 ; nstep= 30
Cas
U
Figure 6.41. Nonminimum phase system S6: input
6.4.3 The Characteristics of Linear Quadratic Control in the
Frequency Domain
We know that in a linear system the properties of a control loop with re-
gards to time (transfer function characteristic) and frequency are two sides
of the same coin. Until now we have concentrated on the time aspect. The
regression model describes the system over time, the minimization criterion
was performed in the time domain, and we have demonstrated the typical
characteristics of compensation of disturbance and set point tracking. These

214
6 Self-tuning Linear Quadratic Controllers
0
5
10
15
20
25
30
−1.4
−1.2
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
Soustava No 5 ; Qu= 0.01 ; nstep= 30
Cas
Figure 6.42. Nonminimum phase system S6: coeﬃcients fi
uout
To Workspace1
yout
To Workspace
Sum2
Sum1
Sum
Signal
Generator
Scope1
Scope
Saturation
Mux
Mux
−K−
Gain
Clu0 
1 
Filter3
Clw 
1 
Filter2
1 
R 
Filter1
S 
1 
Filter
u[1]^2
Fcn
kn(z)
Af(z)
Disturbance
0
Display
0.1
z−1
Discrete−Time
Integrator
Band−Limited
White Noise
B(z)
A(z)
    system
Figure 6.43. Compensation of an oﬀset by signal u0
are of primary importance in adaptive control. We will now deal with the
other side of the question, which is LQ control with regard to frequency. It
is particularly important to observe these properties so as to be able to eval-
uate the stability of the loop and the robustness of the design. This involves
an analysis of the behaviour of a system which is diﬀerent from the model
used in the control design. With reference to frequency, it will also be sim-
pler to demonstrate the eﬀect of the sampling period on stability and the
quality of control behaviour. When illustrating the frequency characteristic of
discrete systems obtained from sampling a continuous-time system, attention

6.4 The Properties of a Control Loop Containing an LQ Controller
215
must be paid to the correct transformation of frequency. The discrete transfer
function only represents the continuous frequency over half the sampling fre-
quency. This means that sampling period T0 =
1
f0 can reﬂect the maximum
angular frequency
ωm = 2π f0
2 = πf0 = π
T0
(6.33)
This frequency is transformed by sampling to discrete angular frequency
ωd,m = π. Therefore, if we are dealing with a control loop in which the dis-
crete transfer function was obtained through sampling, we cannot avoid the
relation between the discrete and continuous frequencies arising out of (6.33)
ωd = ωsT0
Sometimes the discrete frequency is expressed as a ratio to the Nyquist fre-
quency, which is half the sampling frequency fr =
ωd
ωd,m . In this case the high-
est frequency has a value of 1. The continuous frequency is obtained using
fs = frf0/2, and the discrete angular frequency using ωd = frπ.
The frequency characteristics of LQ controller loops display several typical
properties:
•
the frequency characteristic of an LQ controller has a tendency to amplify
signals at higher frequencies,
•
the frequency characteristic of an open-loop in the complex plane (the
Nyquist diagram) displays typical behaviour around points (-1, 0) of the
complex plane,
•
the LQ controller attempts to maintain the frequency characteristic of a
closed loop transfer function between output and set point in the logarith-
mic coordinates ﬂat to the highest frequency.
The Frequency Characteristics in Logarithmic Coordinate
The frequency characteristics in logarithmic coordinates are useful for demon-
strating the eﬀects of the sampling period and penalization. We can show the
typical behaviour of a controller on an example of control of a continuous-time
system with transfer function
G(p) =
1
(p + 1)3 .
When the sampling periods are T0 = 0.1, 0.2, 0.5 and 1s, the discrete transfer
functions are marked as S10, S12, S15 and S20 in the modely.m ﬁle. Fig-
ure 6.44 illustrates the frequency characteristics of those continuous-time and
discrete transfer functions corresponding to each individual sampling period.
We have purposely emphasized the maximum frequency where the discrete
model still represents the continuous-time system at diﬀerent sampling peri-
ods. We achieve a match with the continuous frequency characteristic up to

216
6 Self-tuning Linear Quadratic Controllers
10
−2
10
−1
10
0
10
1
10
2
10
−6
10
−5
10
−4
10
−3
10
−2
10
−1
10
0
frequency
gain
bode plot for 1/(p+1)^3 and discretized for .1 .2 .5 1 sampling period
Figure 6.44. The frequency characteristic of a discretely modelled continuous-time
system at various sampling periods
frequency
π
T0 ; at higher frequencies the value of the characteristic periodically
repeats itself. Due to the logarithmic coordinates used and the paucity of
points at high frequency, the periodicity, and particularly symmetry, of the
solution are distorted.
10
−1
10
0
10
1
10
2
10
−2
10
−1
10
0
10
1
frequency
gain
closed loop Y/W for 1/(p+1)^3 with LQ, To=.1; Qu=.0001,.01,.1
Qu=.0001
Qu=.01
Qu=.1
Figure 6.45. The frequency characteristic of a closed loop with various penalties

6.4 The Properties of a Control Loop Containing an LQ Controller
217
10
−2
10
−1
10
0
10
1
10
−1
10
0
10
1
frequency
gain
Sensit. function for system S15 with LQ controller. Qu=.0001,.01,.1
Qu=.1
Qu=.01
Qu=.0001
Figure 6.46. The sensitivity function for various penalties
10
−2
10
−1
10
0
10
1
10
2
10
−2
10
−1
10
0
10
1
10
2
frequency
gain
open loop gain for 1/(p+1)^3 with LQ, To=.1; Qu=.0001,.01,.1
Qu=.0001
Qu=.01
Qu=.1
system b/a
Figure 6.47. Open-loop gain for various penalties
Figure 6.45 shows the system’s set point closed loop transfer function
frequency characteristic for diﬀerent penalties and sampling period T0 = 0.1 s.
Figure 6.46 illustrates the sensitivity function (disturbance transfer func-
tion) of the same system, with sampling period T0 = 0.1 s. Penalty Qu shifts
the controller frequency characteristic vertically and so signiﬁcantly alters the
total gain of the open-loop (see Figure 6.47).
In other types of system, for example nonminimum phase, the shift in the
controller frequency characteristic is markedly smaller.

218
6 Self-tuning Linear Quadratic Controllers
10
−2
10
−1
10
0
10
1
10
2
10
−2
10
−1
10
0
10
1
frequency
gain
Sensit. fun. 1/(p+1)^3 with LQ contr., Qu=.0001, sampling To=.1,.2,.5
To=.2
To=.5
To=.1
Figure 6.48. The sensitivity function for various sampling periods
Figure 6.48 illustrates the changing character of the sensitivity function
where the system uses an LQ controller obtained byoptimization of the same
criterion, but diﬀerent sampling periods.
The Frequency Characteristic in the Complex Plane
The frequency characteristics of an open-loop transfer function with an LQ
controller show typical behaviour by surrounding the point (−1, 0) in the
complex plane.
The form of the frequency characteristic can be deduced from the fre-
quency interpretation of the Riccati equation and, as a matter of interest, we
give this procedure in detail in [121].
Our starting point is the standard form of the algebraic (steady state)
Riccati Equation (6.8). Frequency interpretations almost always apply to the
steady state. Omitting index i, we use relation (6.9) to obtain
S = FT SF + Qx −LT (Qu + GT SG)L
(6.34)
We then move the term FT SF to the left side of the equation and simultane-
ously add and subtract terms zIFT S and z−1IFS on this side. The left side
can then be manipulated as follows:
(z−1I −FT )S(zI −F) + (z−1I −FT )SF + FT S(zI −F)
The equation is then multiplied from the left by (z−1I −FT )−1, and from the
right by (zI −F)−1, to obtain
S + SF(zI −F)−1 + (z−1I −FT )−1FT S =

6.4 The Properties of a Control Loop Containing an LQ Controller
219
(z−1I −FT )−1Qx(zI −F)−1 −z−1I −FT )−1LT (Qu + GT SG)L(zI −F)−1
The ﬁnal term of the right-hand side is moved to the left, both sides are
multiplied by GT from the left and G from the right, and Qu is added to both
sides. We use relation (Qu + GT SG)L = GT SF to obtain successively
Qu + GT (z−1I −FT )−1Qy(zI −F)−1G =
Qu + GT SG −(Qu + GT SG)L(zI −F)−1 −(z−1I −FT )−1LT
(Qu + GT SG) + GT (z−1I −FT )−1LT (Qu + GT SG)L(zI −F)−1G
= (Qu + GT SG) −(Qu + GT SG)L(zI −F)−1 −(z−1I −FT )−1LT
(Qu + GT SG) + GT (z−1I −FT )−1LT (Qu + GT SG)L(zI −F)−1G
= [I −L(z−1I −FT )−1G]T (Qu + GT SG)[I −L(z−1I −FT )−1G]
(6.35)
For a single-input single-output case this can be written as
Qu
GT SG + Qu
+ |(zI −F)−1G|2
GT SG + Qu
= |I −L(z−1I −FT )−1G|2
(6.36)
Therefore
Qu
GT SG + Qu
< |I −L(z−1I −FT )−1G|2
(6.37)
Inequality (6.37) can be interpreted simply: the distance of the frequency
characteristic from point (−1, 0) in the complex plane is always greater than
the constant which appears on the left side of the inequality.
These relations required relatively complicated manipulation of the Riccati
equation. Similar relations which also include the case of a dynamic output
controller can be obtained far more easily from the system transfer function
and the polynomial synthesis of an LQ controller [106]. We will demonstrate
this on a simpliﬁed example in which synthesis is performed in two stages:
1. First the polynomial of the closed loop φ is calculate from the factorization
equation
Qy ¯BB + Qu ¯AA = φ2
0 ¯φφ
(6.38)
2. The polynomial equation is solved
AR + BS = φ
¯B, ¯A in the equation denote the conjugated polynomial for numerator B and
denominator A of the system transfer function, and φ0 is the normalization
coeﬃcient which yields φ = 1 + p1z−1 + . . . + pnz−n. If we divide (6.38) by
terms ¯AA, ¯RR and φ2
0, where R is the denominator of the controller transfer
function, we obtain equation
Qu
φ2
0 ¯RR + Qy
¯BB
φ2
0 ¯AA ¯RR =
¯φφ
¯AA ¯RR
(6.39)
or

220
6 Self-tuning Linear Quadratic Controllers
Qu
φ2
0 ¯RR + Qy
¯BB
φ2
0 ¯AA ¯RR = |1 + G|2
The inverse of the module of the sensitivity function is on the right side. On
the left side we are principally interested in the ﬁrst expression. It follows
from the algorithm of the solution to the Riccati equation (Section 6.7) that
φ2
0 = Qu + PT
u SPu
and that this value equals the Huu element of minimized matrix Hn (see Sec-
tion 6.7). Unlike the state space example (6.36), where the minimum distance
of the frequency characteristic from point (−1, 0) in the complex plane is lim-
ited by the ﬁrst term on the left side of Equation (6.30), in Equation (6.39)
the minimum distance is also a function of
1
¯
RR. We cannot therefore claim a
guaranteed minimum distance.
Robustness in LQ Controllers
Robustness has gained popularity in recent years but, more importantly, it
is a vital attribute of all controllers for practical applications. The reason for
this is simple. The perfect match between model and true system, assumed
in controller design, cannot be guaranteed in practice. We do have methods
to design a so-called robust controller, but these usually result in a controller
set to maintain a certain quality of control for a whole class of systems which
diﬀer from the model in a deﬁned way. Quality, however, is often only average.
Here we overcome the problems of insuﬃcient knowledge of the real system
using an adaptive approach. Notwithstanding, the properties which determine
robustness must be taken into account because adaptation relying on the
identiﬁcation of model parameters can never ensure a perfect match. We use
results taken from our analysis of frequency response to observe robustness.
When treating robustness properties, we will mainly consider the stability
of the system closed loop for which the controller was not originally designed.
The size of changes in the system which can occur without destabilizing
the loop is easily determined from the shortest distance between the open-loop
frequency characteristic and point (−1, 0). This is illustrated in Figure 6.49,
which shows
the open-loop frequency characteristic. Point P of the frequency charac-
teristic is the closest to point K (−1, 0). The following vector relation applies
in the complex plane
KP = K0 + 0P
(6.40)
or
P(jω) = I + G(jω) = AR + BS
AR
Since the ﬁnal expression is the inverse of the sensitivity function, the inverse
of |P(jω)| yields the modulus of the sensitivity function. In the previous sec-
tion we showed how the minimum distance between the open-loop frequency

6.4 The Properties of a Control Loop Containing an LQ Controller
221
0
-1
P
Re
Im
F(p)
K
Figure 6.49. Evaluating robustness from the frequency characteristic
characteristic and critical point (−1, 0) on the complex plane can be found
through optimization. Therefore the result of optimization can guarantee a
certain level of robustness.
Note:
In other words: the frequency characteristic does not intersect with the circle
centred on point (-1, 0) of the complex plane and radius
Qu
(GT SG+Qu)1/2|Rm|,
where |Rm| is the maximum value of the frequency characteristic modulus
of the controller transfer function denominator.
Unlike similar results for continuous-time systems, the term omitted from
Equation (6.36) can have a very positive eﬀect on the radius of the cir-
cle since, depending on the chosen sampling period, the modulus of the
frequency characteristic may be suﬃciently large at point ω = π.
The tolerance of a steady state LQ controller to a change in gain in the
range (1/2 −∞) and to a change in phase of 60o is well known. This,
however, does not apply to discrete systems where the state controller
is derived from (6.36). In our example, which is characterized by feedback
from the system output and not from the state, the robust stability is
characterized by Equation (6.39). This equation aﬀects robustness using
penalty Qu both directly and via controller denominator R. The form of
the frequency characteristic is also inﬂuenced by the sampling period. We
can demonstrate the typical eﬀect of these variables by analyzing a simple
example.
Figure 6.50 illustrates the open-loop frequency characteristic of system
G(s) =
1
(s+1)3 , sampled at period T0 = 0.1 s (system S10), with LQ controller
for Qu = 0.0001.

222
6 Self-tuning Linear Quadratic Controllers
−2
−1.5
−1
−0.5
0
0.5
1
−2
−1.5
−1
−0.5
0
0.5
1
1/(p+1)^3 with LQ contr. To= .1; Qu=.0001
real G(z)
imag G(z)
w=4
w=10
w=20
w=6
Figure 6.50. The open-loop frequency characteristic, T0 = 0.1 s, Qu = 0.0001
−2
−1.5
−1
−0.5
0
0.5
1
−2
−1.5
−1
−0.5
0
0.5
1
1/(p+1)^3 with LQ contr. To= .5; Qu=.0001
real G(z)
imag G(z)
w=4
w=6
w=2
Figure 6.51. The open-loop frequency characteristic , T0 = 0.5 s, Qu = 0.0001

6.4 The Properties of a Control Loop Containing an LQ Controller
223
The dotted line marks the circle which the frequency characteristic cannot
intersect. Figure 6.51 illustrates a similar example where the sampling period
has been changed to 0.5 s.
We will now look at a case where we use an identiﬁed model and models
of lower order than the actual system in the design of the controller. We again
take system G(s) =
1
(s+1)3 . The identiﬁcation experiments are used to obtain
third-, second- and ﬁrst-order models, the parameters of which are given in
the table below.
Table 6.4. Discrete model parameters
Order Numerator
Denominator
Ideal
0.0001547 + 0.000574z−1 + 0.0001331z−2
1. −2.7145z−1 + 2.4562z−2 −0.74080z−3
3
0.00037136 + 0.00015823z−1 + 0.00006041z−2 + 0.00013480z−3
1. −2.7926z−1 + 2.6130z−2 −0.81810z−3
2
−0.0000536 + 0.0001094z−1 + 0.0006688z−2
1. −1.987z−1 + .99540z−2
1
0.000869 + 0.000799z−1
1. −0.99630z−1
Figure 6.52 illustrates the amplitude and phase characteristics of these
transfer functions. Figure 6.53 shows the open-loop frequency characteristics
of a third-order system using a controller designed on the basis of identiﬁed
ﬁrst-, second- and third-order models for penalty Qu = 0.0001 s. It is clear
that a second-order model can still result in a stable loop, but a ﬁrst-order
model already shows signs of instability. If we increase the penalty in this case
the loop will stabilize.
In the section on noise compensation we saw that, where the ﬁlter-
generating disturbance contained C(z−1) = 1−0.98z−1 in the numerator, the
parameter estimates diﬀered radically from the true parameters of the system.
Looking at this with regards to frequency, it will be shown what eﬀect this
has on stability.
Figure 6.54 illustrates the frequency characteristics of a system with ideal-
ized and identiﬁed parameters. Although the two characteristics diﬀer, those
of the open-loop are almost identical, especially at high frequencies. This is
illustrated in Figure 6.55.
To a large extent, the stability and quality of control behaviour when the
model diﬀers from reality depend upon how close the frequency characteristics

224
6 Self-tuning Linear Quadratic Controllers
10
−2
10
−1
10
0
10
1
10
2
−400
−200
0
200
frequency
phase
S10, phase(B(z)/A(z)) ideal, 3rd, 2nd and 1st order estimates
10
−2
10
−1
10
0
10
1
10
2
10
−4
10
−2
10
0
frequency
gain
S10, |(B(z)/A(z)| ideal, 3rd, 2nd and 1st order estimates
Figure 6.52. The frequency characteristic of an idealized system and third-, second-
and ﬁrst-order models
−5
−4
−3
−2
−1
0
1
−5
−4
−3
−2
−1
0
1
real G(z)
imag G(z)
 open loop of 1/(p+1)^3 with LQ based on 1,2,3rd order estimates
1st o., Qu=.1
1st o., Qu=.0001
2nd o.
3rd o.
ideal
Figure 6.53. The open-loop frequency characteristic using various controllers

6.4 The Properties of a Control Loop Containing an LQ Controller
225
10
−2
10
−1
10
0
10
1
10
−5
10
−4
10
−3
10
−2
10
−1
10
0
10
1
frequency
gain
module od tr.funct. of ideal and estimated system for noise with C(z)= z−.098
ideal
estimated
Figure 6.54. The frequency characteristic of an idealized and identiﬁed system
−5
−4
−3
−2
−1
0
1
−5
−4
−3
−2
−1
0
1
real G(z)
imag G(z)
 open loop of 1/(p+1)^2 with LQ , different noise 
C(z)=1
C(z)=z −.98
Figure 6.55. The open-loop frequency characteristic in an idealized and identiﬁed
system

226
6 Self-tuning Linear Quadratic Controllers
are at higher frequencies. In the ﬁrst instance we saw that a ﬁrst-order model
corresponds quite closely to the idealized system at lower frequencies but
diﬀers merkedly at higher frequencies, resulting in instability. Contrary to
this, in the second instance the diﬀerences between system and model were
greatest at low frequencies.
Monograph [69] gives a relation which may modify the frequency charac-
teristic so that the process remains stable. In the introduction to this section
we showed the conditions which apply to possible changes in the open-loop
transfer function. These are given by the inequality
|G (z) −G0 (z)| < |1 −G (z)|
where G(z), G0(z) are the open-loop frequency characteristics of a true and
idealized system. Since
|G(z) −G0(z)| = | S
R||B
A −B0
A0 |,
is valid we can write
|B
A −B0
A0 | < |AR + BS
AR
R
S |
and, after cancelling R, we obtain
|B
A −B0
A0 | < |AR + BS
AS
|
If we modify this expression in the way described in [69], where, in our
example Hm =
BClw
AR+BS , Hff = Clw
R , H = B
A, Hfb = S
R we obtain
|B
A −B0
A0 | < | H(z)Clw
Hm(z)S(z)|.
6.5 Tuning an Linear Quadratic Controller
In the previous sections we became acquainted with the relevant properties
of a control loop using an LQ controller. This section deals with the issue of
adjusting an LQ controller to meet the demands the user makes on control
behaviour as fully as possible. In the following passages we will recall useful
rules for adjusting and starting up an adaptive controller in a real system.
6.5.1 Tuning a Controller
At ﬁrst glance it might seem rather curious to tune an LQ optimal con-
troller when the optimization process itself should generate the best control

6.5 Tuning an Linear Quadratic Controller
227
behaviour. Quite simply, although the optimization process really does guar-
antee optimal control behaviour, provided certain conditions are satisﬁed, this
does not necessarily mean that it is optimal from the user’s viewpoint. The
behaviour obtained from an optimization criterion with a large penalty will
probably not satisfy the user in terms of speed of response and steady state
error. The principal on which the tuning of an LQ controller is based consists
primarily in choosing the criterion (penalty) which results in the type of con-
trol the user wants. We have seen that there are other inﬂuences acting on the
control loop, particularly the sampling period. The next section is devoted to
ways of modifying the criterion.
Adjustable Criterion Parameters
In our previous discussion of LQ controllers we have referred to one of the
tuning elements – penalty Qu, or Q△u. It has been shown, however, that, by
itself, it is insuﬃcient to ensure full adjustment of behaviour. This can be
shown on an example. The root locus of the closed loop roots of system S3,
with reference to the size of penalty Qu, is illustrated in Figure 6.56. It can
be seen that, regardless of the penalty, the dominant roots are formed by a
complex conjugated pair. Simulation shows that there is always an overshoot
in the step response . Penalty Qu cannot, therefore, be used to achieve the
required response without overshoot. Figure 6.57 illustrates the geometric root
locus of the roots of the same system, but a further penalty on the output
diﬀerence (y(k) −y(k −1))T Qdy(y(k) −y(k −1)) was added to the criterion.
−1
−0.5
0
0.5
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Figure 6.56. The closed loop roots for 0 < Qu/Qy < ∞

228
6 Self-tuning Linear Quadratic Controllers
−1
−0.5
0
0.5
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Figure 6.57. The closed loop roots for 0 < Qu/Qy < ∞and Qdy = 0; 1; 10
If penalty Qdy has been well chosen we can achieve a nonoscilatory tran-
sient to a closed loop change. This example indicates the necessity of expand-
ing the set of adjustable criterion parameters. Here we should note that the
classic state space formulation of LQ control permits the closed loop poles
to be placed in a suﬃciently large region, providing the controllability con-
ditions have been satisﬁed. Superﬁcially it may appear that we have got rid
of this possibility when using the input/output formulation of LQ control.
When we use input/output penalties, the closed loop roots lie on a speciﬁc
single parametric curve, the parameters of which are Qu/Qy. We know that
choosing the roots from this set does not necessarily represent the behaviour
required of the loop. However, this is simple to correct both principally and
algorithmically.
Generalized Penalization
The pseudo-state solution to the minimization of the quadratic criteria (see
Sections 6.1 and 6.7) allows the problem-free expansion of the penalty to
include a general penalization on the pseudo- state. Until now we have used
penalty matrix
Q =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
Qu ... 0 ... 0 0
0 ... 0 ... 0 0
0 ... Qy ... 0 0
0 ... 0
0 0
0 ... 0 ... 0 0
0 ... 0 ... 0 0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
to penalize input and output; we can use a general Q matrix in its place.

6.5 Tuning an Linear Quadratic Controller
229
It is fairly diﬃcult to ﬁnd a generalized matrix which would result in the
required modiﬁcation to the control behaviour. It is easier to regard such a
matrix as the sum of several penalties, each with a simpler matrix. It is a good
idea to express each square symmetric matrix as the sum of rank 1 matrices,
which are the product of the vector and its transpose. Each component of the
penalty then has the form
αif T
i f i
where α is the weighting of the penalty and f i is the numeric vector. Each
term of the criterion will have the form
Qi = z(k)T f T
i αf iz(k)
Vectors f i can be selected such that they have nonzero elements in the
positions corresponding to either inputs or outputs in the z(k) . If we introduce
˜y(k) = f iz(k) or ˜u(k) = f iz(k), this type of penalty can be regarded as
a penalization on ﬁltered variables where the ﬁlter has an FIR character.
The criterion can contain more than one type of ﬁlter, in fact any linear
combination of these ﬁlters can be used without diﬃculty. If ˜z(k) represents
our pseudo-state made up of delayed inputs and outputs, we can use criterion
J =
t0+T

t0+1
˜zT (k)Q1˜z(k) + ˜zT (k)Q2˜z(k) + . . . ˜zT (k)Qn˜z(k)
(6.41)
Designing and choosing individual ﬁlters seems simpler than selecting an
entire matrix so, in our example, we have chosen to penalize the output dif-
ference because this is where the oscillation of the response is most apparent.
The ﬁlter used was the simple f(z) = [1 −z−1], the vector of which was
f 1 = [0 . . . 0 1 −1 . . . 0], resulting in criterion matrix
Q =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
Qu ...
0
...
0 0
0 ...
0
...
0 0
0 ... Qy + Qdy −Qdy... 0 0
0 ...
−Qdy
Qdy
0 0
0 ...
0
...
0 0
0 ...
0
...
0 0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
Qu, Qy, Qdy are the parameters used to modify the criterion. The LQ
toolbox contains the procedure which is used to apply these modiﬁcations, as
well as to penalize the increments on input u(k) −u(k −1). The structure of
this procedure can serve as a model for developing other types of penalization.
Modifying the Open-Loop Transfer function
The dynamic penalization creates a greater space for tuning control behaviour

230
6 Self-tuning Linear Quadratic Controllers
to suit the user but does not guarantee that all conditions are satisﬁed. A
typical example is the requirement for zero steady state error in the step
response. We have demonstrated that one approach is to add an integrator
factor into the open-loop transfer function. This can be generalized in that
it is possible to introduce any transfer function into the loop. Synthesis for a
new system must then be performed, consisting of a serial combination of the
original systems plus the new transfer functions. The algorithmic solution is
straightforward. If we wish to include an integrator we proceed as follows:
1. Before starting the optimization process we create a new denominator for
the system
¯a = (1 −z−1)A(z−1)
By doing this we state that there will be an integrator in the loop.
2. Once optimisation has been completed we expand controller polynomial R
in a similar fashion. This action actually adds the integrator to the loop.
identif.
e
y
w
u
u
p −filtr
s−filtr
     LQ
LQ
B(z  )
A(z  )
1
A(z  )
synthesis
controller
Figure 6.58. A ﬂow diagram of an adaptive LQ controller with parallel and serial
ﬁlters
If a general transfer function is added to the system, the system’s numer-
ator and denominator must be modiﬁed in the same way. R and S in the
controller must also be altered after optimization.
This approach can be combined with LQ or any of the classic designs
for correction terms. If the ﬁlter design results in control behaviour which
approaches optimal, the synthesis will suggest an LQ controller which only
corrects the loop slightly. We can take this to extremes. If we design a ﬁlter
to be LQ optimal, the controller transfer function will equal one.

6.5 Tuning an Linear Quadratic Controller
231
We have given an example of adjusting an LQ controller in series with a
correcting ﬁlter. A similar approach can be taken towards designing an LQ
controller working in parallel with a ﬁlter. Here the controller must be designed
for a system which already has another controller R1 in the feedback path.
The design here is not based on the original system, but on a system with
transfer function
Sn =
S
1 + SR1
This is a common method which is often unwittingly used in controlling
processes containing internal feedback. It is a standard approach to unsta-
ble processes where the stabilizing feedback is found ﬁrst, allowing a further
controller to implement the required loop characteristics.
The advantage of this connection is that, when Qu is used as a tuning
device, the closed loop transfer function is changed from the primary controller
to the optimal LQ loop. In addition to this, parallel connection creates a
natural back up. The disadvantage is a more complicated recalculation of the
system during the LQ design process. This drawback is overcome when an
adaptive form of controller is used, since the consideration of diﬀerent signals
for input during identiﬁcation can be used in identifying either the system
itself or a closed loop connection of the system with a primary controller.
Generally, two LQ controllers can be connected in parallel and it has been
found that adaptive versions work reliably.
Cross-product Term in the Criterion
Until now we have considered penalizations of u and x strictly separated.
However, the criterion (6.41) makes it possible to set a cross-product term
(uT Quxx) . In the literature the cross-term is usually not considered or it is
shown that it can be eliminated by substitution [125]
˜u = u + Q−1
u Quxx
(6.42)
Here we will use the cross-term product penalization Qux to tune an LQ con-
troller to give interesting and useful properties. Let us consider penalization
matrix
QA = α
⎡
⎣1
LA
LT
A LT
ALA
⎤
⎦
(6.43)
then the minimization of the criterion
J =
t0+T

t0+1
˜z(t)αQA˜z(t)
(6.44)
leads to a control law u∗(t) = LAx(t −1). LA is any ﬁxed linear controller
including any PID type. Using the criterion
J =
t0+T

t0+1
˜z(t)(Q + αQA)˜z(t)
(6.45)

232
6 Self-tuning Linear Quadratic Controllers
where Q is any other penalization matrix constructed according to (6.41)
giving reasonably tuned LQ controller. Then by varying value α from ∞to 0
we can tune the LQ controller from any ﬁxed controller with the control law
LA to a standard LQ controller.
Note.
When using criterion (6.45) and the control law LA is not stabilizing, the
resulting control law from the optimization will be stabilizing even for large
but ﬁnite values of α. When LA is stabilizing, then for large α the controller
resulting from the optimisation will be close to LA .
The use of reference signal u0
The input reference signal u0 can be used in controller settings in various
ways.
1. Naturally, it has the meaning of the input value characterizing the operat-
ing point of the plant.
2. It can be considered as another variable to be optimized during the opti-
mization process. Typically, its value can be determined so that the steady
state step response has no oﬀset [124].
3. It need not be a constant value, it can be variable over time, u0(t). Let it
be a function (linear) of the output and delayed inputs and output. We can
write
u0(t) = LAx(t −1)
(6.46)
so u0(t) is generated by some controller. As the LQ controller output consists
of several parts (6.5) the resulting controller is a weighted parallel connection
of a controller LA with an LQ controller. The weight is Qu . For Qu →0
the inﬂuence of LA is negligible, for Qu →∞the LQ controller follows the
signal u0. In this way, by changing Qu, diﬀerent LQ controller properties can
be generated. Typically, this property can be used for cooperation of existing
standard controllers.
Note. As the LQ optimisation does not know how u0 is generated the stability
of such a connection cannot be guaranteed.
Variable Penalizations.
Adaptive environment enables the use of varying penalization; time, data or
environment dependent. The optimization is solved in each sampling period
because parameters of the plant model can change. But there is a reason to
assume that the criterion can change as well. The change of criterion can
be inﬂuenced by the user. Such a possibility was outline above. Two other
possibilities are treated here, examples of data-dependent penalizations.
Penalization of input depending on input saturation
In one step strategy (horizon T = 1) or in the last step of a multi-step strategy
it is easy to design an additional input penalization so that the input at that
time is just on the boundary of the allowed interval.
Qu(ut, usat)
⎧
⎨
⎩
Qu = ut−usat
Huu
, ut > usat
Qu = qu, ut ≤usat
(6.47)

6.5 Tuning an Linear Quadratic Controller
233
Qu is the new penalization, Huu is part of the Riccati matrix (see Section 6.7).
Penalization of output depending on the amplitude of the disturbance.
Similarly, it is possible to create a controller that compensates only distur-
bances that exceed a given boundary. Then the variable penalization is Qy
and when the disturbance is below the speciﬁed boundary, it is set to zero. So
Qy(yt, y0, ε) =
⎧
⎨
⎩
Qy, if(abs(yt) > y0)
0, otherwise
(6.48)
Qy can also depend on the amplitude of the disturbance, hence
Qy(yt, y0, ε) =
⎧
⎨
⎩
αQy(abs(yt) −y0), if(abs(yt) > y0)
0, otherwise
(6.49)
6.5.2 Implementing Linear Quadratic Controllers
There is a whole range of problems to be solved before applying LQ adaptive
controllers to a chosen system, certainly more and of greater complexity than
for the classic types of controller. The result may be (signiﬁcantly) improved
control quality and an ability to meet speciﬁc technological requirements, fast
step response with small (or even without) overshoot, for example.
It therefore makes sense to try to apply an LQ controller in those cases
where a classic controller, however well adjusted, cannot provide the required
quality of control, even though we suspect there is room for improvement. No
controller can increase the step response speed if the system input is saturated
even for PI controller. We can hardly expect recursive identiﬁcation to provide
a good model for the synthesis of optimal control if the measured variables
are heavily aﬀected by noise, contain signiﬁcant drift or systematic error.
Once we decide to apply an LQ controller, the following preparations must
be made:
1. We must decide which model to use (structure, order). This involves de-
termining input and output, and perhaps additional measured variables,
and the number of delayed terms to be considered in the model regressor
(order).
2. The size of the forgetting factor must be selected according to the nature
of the changes in the parameters.
3. We must check that the parameter estimates of the regression model result
in unbiased estimates.
4. We must decide whether to use an incremental model (include the inte-
grator component in the control loop).
5. Generate the start-up conditions for recursive identiﬁcation using a priori
knowledge.

234
6 Self-tuning Linear Quadratic Controllers
The process of connecting up and tuning the controller can be speeded up
by using a computer program to detect problems and provide the means to
solve them before the controller is actually activated. The ABET programming
system for Matlab R
⃝[126, 127], is one such program and can perform the
following operations:
1. Collect and ﬁlter measured data on the process.
2. Determine the structure on the basis of the data measured, together with
the ability to include a priori knowledge of the process in various forms.
3. Identify parameters from the measured data. There is a choice of several
forms and levels of forgetting. We can evaluate the authenticity of the
parameters obtained, and therefore the entire model, from the resulting
covariance matrix of the parameters.
4. Design a controller for the model we have obtained and test it by simula-
tion. Provided the model is suﬃciently precise, this module can be used to
adjust and test the controller so that transfer to a real plant is as smooth
as possible. If a model obtained from identiﬁcation and used for synthesis
is also used in simulation, the testing can only be limited because the
complexity and nonlinearity of the system will not be represented.
Introducing the Controller into the Control Loop
The synthesis process is reliable and represents the deterministic transforma-
tion of model to controller parameters. This transformation is modiﬁed by the
criterion. The one uncertain variable is the length of the horizon, which must
be selected so to obtain stabilizing control.
There are three reasons why an adaptive controller might fail:
1. The system model was ill-chosen
2. The identiﬁcation lead to parameters which do not accurately reﬂect the
controlled process, causing insuﬃcient robustness and unacceptable be-
haviour.
3. The horizon of the criterion is small
The Start
Usually an adaptive controller is activated so that the process is controlled
by another controller (or manually) and the adaptive controller is switched
on at a given moment. Bumpless conditions must be ensured at the moment
of switching so that the data register in the adaptive controller receives the
true values of signals measured previously. This can be done by allowing the
controller to act as an observer over a certain period of time. It can thus
measure individual variables, perform identiﬁcation and synthesis, but is not
allowed to apply the results. At a suitable moment, when the process is at its
quietest, the system input is switched to the adaptive controller output. The
result can be broken down into three categories:

6.5 Tuning an Linear Quadratic Controller
235
1. Behaviour is good or acceptable. In this case all is well and ﬁne tuning can
be carried out by changing the penalty, provided the application permits
this.
2. After the switch is made the system reacts with a large, unwanted exci-
tation, but the process settls down again in time and control behaviour
is then good. This is a typical reaction to badly chosen initial estimates
for the model parameters and can be avoided by improving the estimates.
This can be done by increasing the length of the identiﬁcation period, us-
ing additional data for identiﬁcation, and by supplying whatever a priori
knowledge is available. The fact that the process returns to normal and the
controller functions satisfactorily shows that the structure of the process
model is adequate and that identiﬁcation provides parameter estimates
which give a good representation of the system.
3. The worst case is where control is so poor that the adaptive controller
must be disconnected. This may be caused by:
(a) bad model structure (order too low) unable to represent the real pro-
cess;
(b) the identiﬁcation process giving biased parameter estimates, perhaps
due to the violation of conditions of an unbiased estimate by the dis-
turbance;
(c) the criterion chosen could not produce a controller with suﬃcient ro-
bustness;
(d) the process is markedly nonlinear and cannot be represented by linear
model.
0
20
40
60
80
100
120
140
160
180
200
0
1
2
3
4
5
6
pocet vzorku
vstup u, u0
Figure 6.59. The successive transfer of control from PID to LQ controller (u full,
u0 dashed

236
6 Self-tuning Linear Quadratic Controllers
When this occurs we can try to increase the order of the model, thus creat-
ing more freedom for identiﬁcation to respect the properties of the disturbance
and the system. We can also modify the criterion to result in a more robust
controller. In the previous section we saw that increasing penalty Qu and
lengthening the sampling period improve robustness, though this is accompa-
nied by a deterioration in the quality which can be achieved. Nonlinearity in
the process is usually such that it is impossible to obtain a more precise linear
model. Neither raising the order nor more thorough identiﬁcation will lead to
any improvement. The only thing that can be done is to try to improve the
robustness of the controller. The tuning process is not a one-shot event and
often the whole procedure must be repeated several times.
We have already shown how to use input reference signal u0 in combining
an LQ adaptive controller with another type. As can be seen from Figure 6.59,
the selection of just one parameter suﬃces to move from a reliable standard
controller to a fully operational adaptive controller. This ﬁgure illustrates the
input of a controlled system, which was a heat exchanger to make hot service
water [128]. The output of a standard PID controller was used as signal u0.
In the initial stage of adaptation, where the adaptive controller is apt to
give inappropriate controller output, a high value was assigned to penalty Qu
This resulted in the adaptive controller, in eﬀect, following signal u0 so that
the process was, to all intents and purposes, controlled in the standard way.
Gradually, penalty Qu was decreased to levels suitable for LQ control. The
penalty was chosen on the basis of earlier experimentation. The LQ control
algorithm progressively gained in eﬀectiveness as the penalty was lowered.
6.6 Multivariable Control
The multivariable version of LQ control, that is where there are several system
inputs and outputs, creates no complications either theoretically or algorith-
mically. Individual variable vectors will appear in regression model (6.4) and
criterion (6.2). LQ control is solved in the state space, where the vectors and
matrices are also used for systems with one input and output. Equally, there
are few algorithmic diﬃculties to be solved for multivariable examples, other
than the extra dimensions of the vectors and matrices and the consequent
growth in the number of operations and increased calculation time.
There is, however, a complication in the analysis of the behaviour of mul-
tivariable controller and how it is tuned. In our one-dimensional example
penalty Qy = 1 was suﬃcient, but in a multivariable process we must deal
with the Qy matrix and, at the same time, it is diﬃcult to give precise in-
structions. An indication of the procedure is given in [25]. On the other hand,
multivariable controllers have been applied in practical experiments [129] and
some applications are described in Section 8.3.
Unless the nature of the process requires a truly multivariable approach,
it is more sensible to approximate this need using a series of one-dimensional

6.7 Minimization of the Quadratic Criterion
237
controllers with external disturbance created by the components left over from
the output. A fundamental diﬀerence is that each output is directly deter-
mined by one input. Yet the controller output is also determined by the other
outputs. This modiﬁcation has one advantage: the sampling period for the
controller used in diferent loops can diﬀer. Closer analysis and programming
support falls outside the scope of this chapter.
6.7 Minimization of the Quadratic Criterion
In this section we will be dealing with a detailed approach to minimizing
the quadratic criterion using the principle of dynamic programming, both in
standard form and in a square root form, which will form the basis for our
own calculation algorithm.
6.7.1 Standard Minimization of the Quadratic Criterion
We will take the form of quadratic criterion
J =
k+T

i=k+1

qy (w (i) −y (i))2 + qu (u (i) −u0 (i))2
+ xT (T )S0x(T )
(6.50)
which is the most generalized form appearing in this chapter. When minimiz-
ing criterion (6.2) or (6.50), it is formally appropriate to use the state form
to describe the system. This need not be a state space model in the classic
sense of the term, the state space form alone is suﬃcient. The condition is
that the vector on the left side of the equation in time k is a function of the
same vector in time k −1. If the form of regression vector (6.12) is taken the
following notation is obtained:
x (k) = Pxx (k −1) + Puu (k) + Pv¯v (k −1) = Pz (k −1)
(6.51)
where
xT (k) = [u (k) , u (k −1) , . . . , u (k −nb) , y (k) , y (k −1) , . . . , y (k −na + 1)]
zT (k) = [u (k) , x (k −1) , ¯v (k −1)]
¯v (k −1) = [v (k −1) , v (k −2) , . . . , v (k −nd)]
It is assumed that disturbance v(k) is generated by ﬁlter 1/Av(z−1). The
individual matrices are obtained from the deﬁnitions of the vectors

238
6 Self-tuning Linear Quadratic Controllers
Px =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
1
0
0 · · · 0
0
0 · · · 0 · · · 0
0
b1 · · · bnb a1 · · · ana
0 · · · 0
1
0
· · ·
0 · · · 0 · · · 0
0
0 · · · 0 · · · 0
0
0 · · · 0 · · · 0
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
; Pu =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
1
0
b0
0
...
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
Pv =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
0
0
0
0
0
0
0
d1 · · · dnd k
0
0
0
0
0
0
0
0
av1 · · · avnd 0
1
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
State matrix Px also respects any autoregression model of the development of
measurable noise. Matrix P = [Pu, Px, Pv] is composed of a row containing
the parameters of the regression model, the parameters for the models of the
development of external disturbance (avi) and the appropriate number of 1s.
Vector ˜z (k) is now used, which also contains other variables upon which the
value of the criterion depends. So quadratic criterion (6.2) can be written
J =
k0+T

i=k0+1
˜zT (k) Q˜z (k)
(6.52)
where ˜zT (k) = [x(k), w(k), u0(k)], and the standard penalty is drawn from
Q =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
Qu . . .
0
. . .
0
−Qu
0
...
0
...
0
0
0
...
Qy
... −Qy
0
0
...
0
...
0
0
0
... −Qy ...
Qy
0
−Qu ...
0
...
0
Qu
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
Generally, Q can be any symmetrical positive semi-deﬁnite matrix.

6.7 Minimization of the Quadratic Criterion
239
The minimization process (6.52) now proceeds from the end of the horizon
T as follows: u (k0 + T)can only aﬀect the ﬁnal term of (6.52). If we express
y (k0 + T) in vector x (k0 + T) as a function of the preceding y(k) and u(k0 +
T ) we can then ﬁnd u(k0 + T ) to minimize y(k0 + T ). Matrix P from (6.51)
is used in the new calculation.
Since the vector ˜z (k) contains further elements which do not change we
can write
˜z (k0 + T) =
⎡
⎢⎢⎢⎣
P 0 0
0 1 0
0 0 1
⎤
⎥⎥⎥⎦˜z (k0 + T −1) = Ω˜z (k0 + T −1)
The size of the losses we wish to minimize using u (k0 + T) is, therefore
J (k0 + T) = ˜zT (k0 + T −1) ΩT QΩ˜z (k0 + T −1)
= ˜zT (k0 + T −1) H˜z (k0 + T −1)
(6.53)
The minimum of this quadratic form is obtained in the standard way
(derivation by u (k0 + T), with the condition that the derivation equals zero).
We obtain
J∗(k0 + T) = min [J (k0 + T)]
(6.54)
= ¯zT (k0 + T −1)

Hxx −HT
xxH−1
uuHux

¯z (k0 + T −1)
where ¯z (k0 + T −1) is ˜z (k0 + T −1) without element u (k0 + T), and H..
are the corresponding submatrices of matrix H. Because H represents loss in
time k0 + T , we coordinate it with this index.
Loss was minimized in the ﬁnal step so we can now turn to minimizing the
penultimate step. This component of the criterion depends on u (k0 + T −1)
and is
J∗(k0 + T ) = min [J(k0 + T )]
= ¯zT (k0 + T −1)H∗
xx¯z(k0 + T −1) +
˜zT (k0 + T −1)Q˜z(k0 + T −1)
(6.55)
where matrix H∗
xx = (Hxx −HT
uxH−1
uuHux) remains from the previous step.
Vectors ˜z(k0 + T −1) and ¯z(k0 + T −1) diﬀer in that vector ˜z(k0 + T −1)
contains set point w (k0 + T −1). We can now create a combined vector
˜z (k0 + T −1), which contains both ﬁnal set points w (k0 + T) and also
w (k0 + T −1). We must also expand H∗and Q by a column of zeros at
the appropriate position. We can now continue formally as in the preceding
step. We express y (k0 + T + 1)] in vector x (k0 + T −1)as a function of the
previous y(k) and u (k0 + T −1). Matrix Ωwill now be given

240
6 Self-tuning Linear Quadratic Controllers
Ω=
⎡
⎢⎢⎢⎢⎢⎢⎣
P 0 0 0
0 1 0 0
0 0 1 0
0 0 0 1
⎤
⎥⎥⎥⎥⎥⎥⎦
We can see that matrix Ωhas acquired an extra column which corresponds
to variable w (k0 + T −1), which will continue to appear until the end of
minimization. The loss in the penultimate step will be
J (k0 + T −1) = ˜zT (k0 + T −1) ΩT (H∗(k0 + T) + Q) ˜z (k0 + T −1)
= ˜zT (k0 + T −1) H (k0 + T −1) ˜z (k0 + T −1)
(6.56)
The result of minimization is similar to the previous step.
J∗(k0 + T −1) =
min
u0+T −1 [J (k0 + T −1)]
(6.57)
= ¯zT (k0 + T −2)

Hxx −HT
xxH−1
uuHux
 ¯z (k0 + T −2)
This procedure is continued until all the terms of the criterion have been
processed.
Commentary
We have shown that the control law can be split into several parts according
to which variable is used to multiply their elements. The basic component is
Hux, which is multiplied by variables u and y. This component deﬁnes the
feedback properties and represents controller transfer function u(z)
y(z) = S(z−1)
R(z−1).
The relationship between polynomials S and R and vector Hux is given by
the relation
R = [1
Hux (1 : nb)] ;
S = [0
Hux (nb + 1 : nb + na)]
The Huv part represents the feedforward (ﬁlter) of external disturbance. There
may be several of these components, depending on how many external dis-
turbances have been modelled. Part Huw represents the inﬂuence of the set
point. We have seen how each value for w(k) is given by single element Huw.
If the criterion contains many terms (a long horizon), the dimension of Huw
will be large. It is, however, possible to accumulate these values in one col-
umn. If we assume that the set point does not change along the horizon, then
all the elements of vector Huw can simply be added and the result used as
the numerator of the controller transfer function from set point Fuw = Huw
R .
Since variable w(k) can be regarded as the product w(k) ∗1 values can be
included in matrix Ω. Vector ˜z(k) will then contain 1s for w(k). Any set point
change can then be accumulated in one column using this layout. Similarly,
Huu0 represents the inﬂuence of the reference input variables and the same
rules apply as for Huw.

6.7 Minimization of the Quadratic Criterion
241
6.7.2 Minimization of the Quadratic Criterion in Square Root
Form
The procedure given above is unsuitable for practical calculations. The diﬀer-
ence which appears in relation (6.54) can cause the matrix of the quadratic
form Hxx to cease to be positive deﬁnite (semi- deﬁnite). This means that
the calculated value no longer makes any sense. The so-called square root
approach, where we work with the square root (factor) of the symmetrical
matrix, is a useful tool for avoiding this. All the algorithms in this part are
based on this principle.
The square root of a matrix is deﬁned as follows. Matrix F is the square
root of symmetrical, positive deﬁnite matrix A, when
A = FT F
is valid. FT is the matrix transposed to F. There is an inﬁnite number of
matrices which satisfy the condition above. However, there exists an unam-
biguous factorization on a triangular matrix. Therefore
A = ∆T ∆= ∇T ∇
yet ∆T ̸= ∇, whie ∆and ∇mark the lower and upper triangular matrix
respectively.
The guiding principle of the square root is to replace the symmetrical
matrix by its square root (factor of the matrix) for the purposes of calculation.
In the minimization of criterion (6.52) we used matrix multiplication, addition
of matrices, and the relation for minimizing quadratic form (6.54). In the same
way, when we take the square root approach, we will require speciﬁc operations
to manipulate the square root matrix.
Matrix multiplication remains, but we will need to deﬁne the operations
which correspond to the addition of the matrices and minimization of the
quadratic criterion. It soon becomes clear that the factor of the matrix addi-
tion corresponds to the expansion of the matrix of one factor by another. If
A = FT F, B = GT G, and C = HT H, then it follows from the deﬁnition of
the multiplication of the composed matrices that
C = A + B = HT H = [FG] [FG]T
therefore
H =
⎡
⎣F
G
⎤
⎦
Minimization of the quadratic form: according to relation (6.54), minimization
of the quadratic form is used to ﬁnd the u(k) which minimizes
[u (k) , x (k −1)] S [u (k) , x (k −1)]T
(6.58)

242
6 Self-tuning Linear Quadratic Controllers
If we use factor F instead of S, (6.58) can be written as
***F [u (k) , x (k −1)]T ***
2
If F is the upper triangle, u(k) can only inﬂuence the value of the ﬁrst element
of the vector under consideration. We obtain minimization by selecting
Fuuu (k) + Fuxx (k −1) = 0
where Fuu and Fux are submatrices of F corresponding to the multiplication
by u(k) or x(k −1). The minimum achieved is given by the relation
∥Fxxx (k −1)∥2
In the square root approach a further operation must be added to those
above. Both the multiplication operation and the expansion of the matrix
disturb the triangular shape of the square root of the quadratic form. Yet we
still need the triangular shape both for its inambiguity and in order to ﬁnd the
optimal u(k). The operation we require is orthogonal transformation, which
can restore the triangular form. Orthogonal transformation is represented by
regular square matrix T, where T−1 = TT , i.e. TT T = I. In reality, the
multiplication of the matrix square root using the orthogonal matrix from the
left does not change the value of the quadratic form.
xT Sx = xT FT Fx = xT FT TT TFx = xT ∆T ∆x
Algorithms for the T transformation, which transforms F into ∆, are
known under the names Householder transformation, Givenson transforma-
tion, or elementary rotation.
6.7.3 The Minimization Algorithm
The minimization algorithm comprises the above relations with the proviso
that:
•
Instead of using the square root matrix, it operates with factorization of
the symmetrical matrix on S = UT DU where U is the triangular matrix
with a unit diagonal, and D is the diagonal matrix.
•
The orthogonal transformation is realized by the Matlab R
⃝qr function
or employs the method of elementary rotations coded in special function
RTREDUC.
The algorithm can be described as follows:
1. Create matrix S with dimension (nx, nz) with diagonal S0. S0 = 1000 is
standard. The algorithm is not sensitive to this value. Set i = horizon
2. Calculate mean value H = SP;
3. Augment H with all penalizations

6.8 Summary of chapter
243
˜H =
⎡
⎢⎢⎢⎢⎢⎢⎣
H
α1f 1
. . .
α2f 2
⎤
⎥⎥⎥⎥⎥⎥⎦
4. Perform orthogonal transformation of ˜H into triangle matrix H∆.
5. Split matrix H∆into submatrices as follows
⎡
⎣Huu Hux
0
Hxx
⎤
⎦
6. Do:i = i −1; if(i > 0), S = Hxx; goto step2
7. Control law is
cl = −H−1
uuHux
Graphically the process can be represented by Figure 6.60
*
S
P
H
  
S
t
l
q
l
l
cl
t−1
q1
1
q2
2
3
3
triu(qr())
Θ
qy
Figure 6.60. Representation of one step of LQ optimization
The operations described are performed at each step of the minimization
of the quadratic criterion (one iteration of the Riccati equation).
The form of vectors li representing the quare root of the most widely used
penalizations are presented in the Table 6.5.
6.8 Summary of chapter
LQ adaptive control can oﬀer nice closed loop behaviour for uncertain plant
when
•
correct model can be identiﬁed;

244
6 Self-tuning Linear Quadratic Controllers
Table 6.5. Basic penalizations
Penalizations of Weight u(k) u(k −1) . . . y(k)
y(k −1) y0 u0
input
αu
1
0
0
0
0
0
-1
output
αy
b0
b1
. . . a1
a2
-1
0
input
increment
α∆u
1
-1
0
0
0
n 0 0
output
increment
α∆y
b0
b1
. . . a1 −1 a2 −1
0
0
•
the system is suﬃciently linear.
Unfortunately, these conditions can be checked only ex post, when some trial
is done. That is why operators are very cautious when using something that
might not work properly. In addition, the choice of penalties to obtain sat-
isfactory behaviour is not simple. To change the situation the following was
done: properties of an LQ controller in disturbance compensation, set point
tracking and the frequency domain were documented Tuning was simpliﬁed
by factorization of the penalty matrix to a sum of rank one matrices having
speciﬁc physical meaning. LQ controller tuning was enriched by the possibil-
ity to emulate any standard controller and by the change of one parameter
(penalization ) smoothly changing the controller behaviour from the standard
controller to an LQ one, and vice versa if necessary. Reliability is ensured
by using square root approaches to both system on-line identiﬁcation and
controller synthesis.
Problems
6.1. Compensation of stochastic disturbance.
(a) Simulate a continuous-time plant with stochastic disturbance and discrete
adaptive controller. Use a disturbance which is correctly modelled by the
identiﬁed regression model. Observe how the quality of controldepends on the
penalization Qu and how the input amplitude depends on Qu.
(b) On the same scheme with Qu ﬁxed, change the sampling period of the
controller (and identiﬁcation as well) and observe disturbance compensation
and input signal amplitude.
(c) Filter the disturbance so that disturbance dynamics do not correspond to
plant dynamics. Observe the identiﬁed parameters. What could help (ﬁltering
of signals for identiﬁcation, increasing the order of the model)?
6.2. Set point control and oﬀset removal.
(a) Observe how the oﬀset value depends on input penalization Qu or in-

6.8 Summary of chapter
245
crement of input penalization Q∆u. Use instead an adaptive controller with
integrator. (b) Demonstrate how the oﬀset is removed when using a reference
input signal with u0 = 1/g y0 (g= plant static gain).
(c) Compare the step response when future values of the set point can or
cannot be used. Observe the role of the horizon in the criterion.
6.3. Startup of the adaptive algorithm.
(a) Observe the role of prior information for startup of the adaptive algo-
rithm. Demonstrate that even correct prior parameter estimates are not suf-
ﬁcient without reasonable choice of parameter covariance matrix and initial
data (initial inputs and outputs).
(b) Create a Simulink R
⃝scheme in which the adaptive controller ﬁrst collects
data, several sample times later starts the identiﬁcation, and after some fur-
ther tine switches to the adaptive LQ controller. During the ﬁrst two phases
use a simple ﬁxed controller.
(c) Connect the output of the selected ﬁxed controller tothe u0 port of
the adaptive LQ controller. Observe the smooth transition between LQ be-
haviour and simple controller behaviour when changing Qu. Design appropri-
ate changes of Qu to obtain bumpless startup.
6.4. Generalized penalizations.
(a) Verify on an example (e.g. model no. 3. or the helicopter) that for systems
with slightly damped poles, nonzero penalization of Q∆y is necessary to ob-
tain a step response without overshoot.
(b) Design a penalization which will make the LQ controller imitate the be-
haviour of an I (PI, PID, any ﬁxed linear controller described by a transfer
function) controller. Observe that the resulting control law is the one that you
want to imitate;it is stabilizing.
(c) Observe, that if the choice of alternative controller leads to an unstable
closed loop, optimization will not result in such a control law.
6.5. Forgetting in identiﬁcation.
Using the helicopter nonlinear model verify the role ofthe forgetting factor.

7
Computer-aided Design for Self-tuning
Controllers
In the education process of Automatic Control Theory, the veriﬁcation through
simulation, and the practical implementation of the designed controller algo-
rithms in real-time conditions, are very important for training control engi-
neers. In Chapter 7 therefore, two Matlab R
⃝toolboxes are presented which
contain digital self-tuning controllers that have been described in the previous
chapters of this monograph. Section 7.1 describes the Self-tuning Controllers
Simulink R
⃝Library (STCSL), where digital PID controllers (see Chapter 4)
and controllers based on the algebraic approach (see Chapter 5) are included.
The LQ toolbox, containing self-tuning controllers based on general regression
model identiﬁcation and LQ criterion optimization, and presented in Chap-
ter 6, is described in Section 7.2.
7.1 Self-tuning Controllers Simulink
R
⃝Library
Based on Chapter 4 and Chapter 5, a library of self-tuning controllers was
created in the Matlab R
⃝/Simulink R
⃝environment [130], the purpose being
to create an environment suitable for the creation and testing of self-tuning
controllers. This library is available free of charge from the Tomas Bata Uni-
versity in Zl´ın Internet site www.utb.cz/stctool [104]. The library was created
using Matlab R
⃝version 6.0 (Release 12), but it can be ported, with some
changes, to both lower and higher Matlab R
⃝versions. Controllers are im-
plemented in the library as standalone Simulink R
⃝blocks, which allow easy
incorporation into existing simulation schemes and simple creation of new
simulation circuits. Only standard techniques of the Simulink R
⃝environment
were used when creating the controller blocks and so only a basic knowledge
of this environment is required to be able to begin working with the library.
Controllers can be implemented into simulation schemes just by copying or
using the drag & drop function, and their parameters are set using dialogue
windows. Another advantage of the approach used is its relatively easy im-

248
7 Computer-aided Design for Self-tuning Controllers
plementation of user-deﬁned controllers by the modiﬁcation of some suitable
controller in the library.
Nowadays, the library contains over 30 simple single-input/single-output,
digital, self-tuning controllers, which use discrete second- and third-order
models for recursive process identiﬁcation. All of these controllers use dis-
crete control laws, in which controller parameters are computed by various
methods. The ﬁrst part covers self-tuning algorithms using the traditional
PID structure; the second part describes controllers based on the algebraic
approach. The library package not only contains the controllers, but also in-
cludes a reference manual with simple descriptions of the algorithm and the
internal structure of each controller. The controllers included in the library
use the discrete ARX model for the recursive identiﬁcation of process model
parameters. The library user can select one of three recursive identiﬁcation
methods oﬀered for the computation of parameter estimates vector ˆΘ(k):
the basic least squares method or one of its modiﬁcations, the least squares
method with exponential forgetting and the least squares method with adap-
tive directional forgetting (see Chapter 3).
The typical wiring of any library controller is shown in Figure 7.1. Each
self-tuning controller from the library uses three input signals and provides
two outputs. The inputs are the reference signal (w) and the actual output
of the controlled process (y). The last controller input is the current input
of the controlled process – the control signal (u in). The value of this signal
does not have to be the same as the controller output, e.g. due to controller
output saturation. The main controller output is, of course, the input sig-
nal of the controlled process. The second controller output consists of the
current parameter estimates of the controlled process model. The number of
parameters this output consists of depends on the model used by on-line iden-
tiﬁcation: controllers using the second-order model provide four values, i.e.
(a1, a2, b1, b2); and controllers using the third-order model provide six values,
i.e. (a1, a2, a3, b1, b2, b3).
A scheme analogous to the scheme in Figure 7.1 can also be used to sim-
ulate the control processes of both discrete and continuous-time controlled
processes with much more complicated structures. It is also possible to imple-
ment processes with time variable parameters, processes described by nonlin-
ear diﬀerential equations, etc.
7.1.1 Overview of Library Controllers
The Self-tuning Controllers Simulink R
⃝Library is started by opening the
following Simulink R
⃝ﬁle: stcsl std.mdl, which contains block schemes of all
controllers.
The name of the controller always corresponds to the name of the ﬁle
that processes the calculation of the controller parameters and always has
the following structure: xxNyyyy. The ﬁrst two characters (xx), indicate

7.1 Self-tuning Controllers Simulink
R
⃝Library
249
 
 
                                                 
u_in(k) 
y(k) 
w(k) 
u(k) 
ID params 
adaptive pp2b_2 
Saturation 
Reference signal 
Output 
0.2 
5s  +10s+1 
2 
Noise filtration 
ID parameters 
5 
5s  +10s+1 
2 
Controlled process 
Band-Limited 
White Noise 
Figure 7.1. Control circuit in the Simulink
R
⃝environment
the controller type – zn indicates a controller synthesis based on the Ziegler–
Nichols method; pp represents controllers with a pole assignment synthesis;
mv denotes the minimum variance controller, etc. The third character (N)
in a controller name is the digit 2 or 3 – corresponding to the order of the
model used by the on-line identiﬁcation part of the controller. The following
characters (yyyy), serve to cover more detailed controller details. A survey
of all the library controllers is set out in Table 7.1.
Table 7.1. Survey of individual controllers
Contr.
Controller algorithm
Input
name
param.
(1)
u(k) = q0e(k) + q1e(k −1) + q2e(k −2) + u(k −1)
KP u
zn2fr
q0 = KP (1 + TD
T0 );
q1 = −KP (1 −T0
TI + 2 TD
T0 )
Tu
zn3fr
q2 = KP
TD
T0
T0
(2)
u(k) = q0e(k) + q1e(k −1) + q2e(k −2) + u(k −1)
KP u
zn2br
q0 = KP (1 + TD
T0 + T0
TI );
q1 = −KP (1 + 2 TD
T0 )
Tu
zn3fr
q2 = KP
TD
T0
T0
(3)
u(k) = q0e(k) + q1e(k −1) + q2e(k −2) + u(k −1)
KP u
zn2br
q0 = KP (1 + TD
T0 +
T0
2TI );
q1 = −KP (1 −
T0
2TI + 2TD
T0 )
Tu
zn3fr
q2 = KP
TD
T0
T0
(4)
u(k) = KP
 
w(k) −y(k) + TD
T0 [y(k −1) −y(k)]!
KP u
zn2pd
KP = 0.4KP u;
TD = TU
20
Tu; T0

250
7 Computer-aided Design for Self-tuning Controllers
(5)
u(k) = q0e(k) + q1e(k −1) + u(k −1)
KP u
zn2pi
q0 = KP

1 +
T0
2TI

;
q1 = −KP

1 −
T0
2TI

Tu; T0
(6)
u(k) = p1u(k −1) + p2u(k −2) + q0e(k)
KP u
+q1e(k −1) + q2e(k −2)
Tf = TD
α ;
α ∈⟨3; 20⟩
zn2fd
p1 =
−4
Tf
T0
2Tf
T0 +1;
p2 =
2Tf
T0 −1
2Tf
T0 +1
Tu
zn3fd
q0 =
KP +2KP
Tf +TD
T0
+ KP T0
2TI
(
2Tf
T0 +1)
2Tf
T0 +1
T0
q1 =
KP T0
2TI
−4KP
Tf +TD
T0
2Tf
T0 +1
q2 =
Tf
T0 (2KP −KP T0
TI
)+2 KP TD
T0
+ KP T0
2TI
−KP
2Tf
T0 +1
(7)
u(k) = KR[y(k −1) −y(k)] + KI[w(k) −y(k)]
KP u
zn2tak
+KD[2y(k −1) −y(k −2) −y(k)] + u(k −1)
Tu
zn3tak
KR = 0.6KP u −KI
2 ;
KI = 1.2KP uT0
Tu
T0
KD = 3KP uTu
40T0
(8)
u(k) = uP I(k) + uD(k)
KP u
α ∈⟨3; 20⟩;
β ∈⟨0; 1⟩
zn2ast
uP I(k) = KP [y(k −1) −y(k)] + KP T0
2TI [e(k) + e(k −1)]
Tu
zn3ast
+βKP [w(k) −w(k −1)] + uP I(k −1)
T0
uD(k) = KP
TDα
TD+T0α[y(k −1) −y(k)] +
TD
TD+T0αuD(k −1)
(9)
u(k) = KP
 
e(k) −e(k −1) + T0
TI e(k)
KP u
zn2fpd
+ TD
6T0 [e(k) + 2e(k −1) −6e(k −2) + 2e(k −3) + e(k −4)]!
Tu
zn3fpd
+u(k −1)
T0
(10)
u(k) = q0e(k) + q1e(k −1) + q2e(k −2) + u(k −1)
d
ba2
γ = b1
b0
kI =
1
2d−1;
for γ = 0;
kI =
1
2d(1+γ)(1−γ) ;
for γ > 0
q0 = kI
b0 ;
q1 = q0a1 = kI
b0 a1;
q2 = q0a2 = kI
b0 a2
(11)
u(k) = KP
 
e(k) −e(k −1) + T0
TI e(k)
+ TD
T0 [e(k) −2e(k −1) + e(k −2)]!
+ u(k −1)
B
da2
Q = 1 −e−T0
B ;
KP = −(a1+2a2)Q
b1
T0
TD = T0a2Q
KP b1 ;
TI = −
T0
1
a1+2a2 +1+ TD
T0
(12)
u(k) = q0e(k) + q1e(k −1) + q2e(k −2) + (1 −γ)u(k −1)
ωn
+γu(k −2)
pp2a 1
s1 = a2 [(b1 + b2)(a1b2 −a2b1) + b2(b1d2 −b2d1 −b2)]

7.1 Self-tuning Controllers Simulink
R
⃝Library
251
r1 = (b1 + b2)(a1b1b2 + a2b2
1 + b2
2
γ = q2
b2
a2 ;
q0 =
1
b1 (d1 + 1 −a1 −γ)
q1 = a2
b2 −q2( b1
b2 −a1
a2 + 1);
q2 = −s1
r1
ξ
(13)
u(k) = q0e(k) + q1e(k −1) + q2e(k −2) + (1 −γ)u(k −1)
+γu(k −2)
α
pp2a 2
r1 = (b1 + b2)(a1b1b2 + a2b2
1 + b2
2)
r2 = x1(b1 + b2)(a1b2 −a2b1)
ω
r3 = b2
1x4 −b2[b1x3 −b2(x1 + x2)]
r4 = a1[b2
1x4 + b2
2x1 −b1b2(x2 + x3)]
r5 = (b1 + b2)[a2(b1x2 −b2x1) −b1x4 + b2x3]
r6 = b1(b2
1x4 −b1b2x3 + b2
2x2) −b3
2x1
γ = r6
r1 ;
q0 = r2−r3
r1
;
q1 = −r4+r5
r1
;
q2 = x4+γa2
b2
(14)
u(k) = −[(q′
0 + β)y(k) −(q′
0 + q′
2)y(k −1) + q′
2y(k −2)]
−(γ −1)u(k −1) + γu(k −2) + βw(k)
ωn
pp2b 1
s1 = a2
 
b2[a1(b1 + b2) + b1(d2 −a2) −b2(d1 + 1)] −a2b2
1
!
ξ
r1 = (b1 + b2)(a1b1b2 −a2b2
1 −b2
2)
q′
0 = q′
2( b1
b2 −a1
a2 ) −a2
b2 ;
q′
2 = s1
r1 ;
γ = q′
2
b2
a2
β =
1
b1 (d1 + 1 −a1 −γ −b1q′
0)
(15)
u(k) = −[(q′
0 + β)y(k) −(q′
0 + q′
2)y(k −1) + q′
2y(k −2)]
−(γ −1)u(k −1) + γu(k −2) + βw(k)
α
r1 = (b1 + b2)(a1b1b2 −a2b2
1 −b2
2)
pp2b 2
r2 = a1b2[b1(x2 + x3 + x4) −b2x1]
ω
r3 = a2b1[b2x1 −b1(x2 −x3 + x4)]
r4 = (b1 + b2)[b1x4 + b2(−x3 −x4)]
r5 = b1(b2
1x4 −b1b2x3 + b2
2x2) −b3
2x1
r6 = b2
1(−a2x3 + a1x4 −a2x4)
r7 = b2[b1(a1x4 + a2x2 −x4) −b2(a2x1 + x4)]
q′
0 = −r2−r3+r4
r1
;
q′
2 = r6+r7
r1
γ = r5
r1 ;
β = x1+x2−x3+x4
b1+b2
(16)
u(k) = r0w(k) −q0y(k) −q1y(k −1)
db2w
−q2y(k −2) −p1u(k −1) −p2u(k −2)
db3w
(17)
u(k) = r0w(k) −q0y(k) −q1y(k −1)
db2s
−q2y(k −2) −p1u(k −1) −p2u(k −2)
db3s

252
7 Computer-aided Design for Self-tuning Controllers
(18)
u(k) = 1
q [a1y(k −1) + a2y(k −2) −b1u(k −1)
−b2u(k −2) + w(k)] + u(k −1)
q
mv2
(19)
u(k) = r0w(k) + r1w(k −1) + r2w(k −2) −q0y(k)
−q1y(k −1) −q2y(k −2) −p1u(k −1) −p2u(k −2)
D
pp2chp
A(z−1)P(z−1) + B(z−1)Q(z−1) = D(z−1)
T0
pp3chp
B(z−1)R(z−1) + Dw(z−1)S(z−1) = D(z−1)
(20)
u(k) = r0w(k) + r1w(k −1) + r2w(k −2)
−q0y(k) −q1y(k −1) −q2y(k −2) −p1u(k −1) −p2u(k −2)
qu
pp2lq
A(z−1)P(z−1) + B(z−1)Q(z−1) = D(z−1)
B(z−1)R(z−1) + Dw(z−1)S(z−1) = D(z−1)
T0
D(z−1) = 1 + d1z−1 + d2z−2
m0 = qu(1 + a2
1 + a2
2) + b2
1 + b2
2
m2 = qua2;
m1 = qu(a1 + a1a2) + b1b2
d1 =
m1
δ+m2 ;
d2 = m2
δ ;
δ =
λ+√
λ2−4m2
2
2
λ = m0
2 −m2 +
+ m0
2 + m2
2 −m2
1
Notes
The undermentioned relations are used for computiation of the individual
controller parameters.
Controller numbers: 1–4, 6, 8 and 9:
KP = 0.6KPu
TI = 0.5Tu
TD = 0.125Tu
Controller numbers 12 and 14:
d1 = −2 exp(−ξωnT0) cos(ωnT0

1 −ξ2)
for ξ ≤1
d1 = −2 exp(−ξωnT0) cosh(ωnT0

1 −ξ2)
for ξ > 1
Controller numbers 13 and 15:
x1 = c + 1 −a1
x2 = d + a1 −a2
x3 = f + a2;
x4 = g
c = −4α
d = 6α2 + ω2
f = −2α(2α2 + ω2)
g = α2(α2 + ω2)
7.1.2 Controller Parameters
The dynamic behaviour of a controller can be inﬂuenced by changing the pa-
rameters available for a given controller. Controller parameters can be divided
into two groups:

7.1 Self-tuning Controllers Simulink
R
⃝Library
253
•
parameters common to all controllers;
•
controller speciﬁc parameters.
All controller parameters are set or changed by standard approaches in the
Simulink R
⃝environment, that is, by changing items in the dialogue window
– invoked for example, by double-clicking with the mouse on the controller
object. This dialogue window also contains a short description of the corre-
sponding controller; and the “Help” button is used to invoke the corresponding
part of the hypertext reference guide. The parameter setting dialogue window
of the pp2a 1 controller is shown in Figure 7.2.
 
Figure 7.2. Dialogue for pp2a 1 controller setting parameters
The group of common controller parameters consists of the sampling pe-
riod and parameters aﬀecting the on-line identiﬁcation process. The list of
these parameters is set out here.

254
7 Computer-aided Design for Self-tuning Controllers
Sample time T0. It deﬁnes sampling period T0. This value is used for
process identiﬁcation as well as for calculation of the controller output.
Identiﬁcation type. It is possible to select from the following on-line iden-
tiﬁcation methods:
•
Least squares method (LSM) – the simplest method, in which all process
input/output pairs aﬀect identiﬁed parameters with the same weight.
•
LSM with exponential forgetting – the latest process input/output pairs
aﬀect identiﬁed parameters more than older pairs. This method can be
used for systems with time-varying parameters.
•
LSM with adaptive directional forgetting – the most sophisticated method,
the weight of the current process input/output pair is determined with
respect to changes of input and output signal. This method is useful for
systems with time-varying parameters.
ID Initial parameter estimations. The initial process parameter estimates
used by on-line identiﬁcation. This is a column vector of parameters in the
form [a1, a2, b1, b2] for most second-order controllers; [a1, a2, b1] for Dahlin
controller; and [a1, a2, a3, b1, b2, b3] for third-order systems.
ID Initial covariance matrix C. Initial value of the covariance matrix used
in the on-line identiﬁcation process. This must be a square positive deﬁnite
matrix with dimensions the same as the number of identiﬁed parameters.
Usually, a diagonal matrix is used in the form: G∗I, where I is the unit matrix
and G is gain. The gain then determines the inﬂuence of initial parameter
estimates on the identiﬁcation process: the greater the gain, the smaller the
inﬂuence of the initial estimates.
ID Initial phi (forgetting coeﬃcient). The initial value of the forgetting
factor ϕ used in the on-line identiﬁcation of the controller process. This pa-
rameter is used only if the Identiﬁcation type is LSM with exponential forget-
ting or LSM with adaptive directional forgetting and should be in the range:
0 < ϕ ≤1. When LSM with exponential forgetting is used, this parameter
determines the forgetting rate of the older process input/output pairs: the
smaller ϕ, the smaller the inﬂuence of the older pairs to the current param-
eter estimates. When LSM with adaptive directional forgetting is used, ϕ
changes during the identiﬁcation process, according to the process of input u
and output y values.
ID Initial lambda. The initial value of parameter λ used in the on-line
identiﬁcation of the controlled process. This parameter is used only if the
Identiﬁcation type is LSM with adaptive directional forgetting.
ID Initial rho. The initial value of parameter ρ used in the on-line identi-
ﬁcation of the controlled process. This parameter is used only if the Identiﬁ-
cation type is LSM with adaptive directional forgetting.
ID Initial nu. The initial value of parameter ν used in the on-line identiﬁca-
tion of the controlled process. This parameter is used only if the Identiﬁcation
type is LSM with adaptive directional forgetting.

7.1 Self-tuning Controllers Simulink
R
⃝Library
255
Some controllers allow adjustment by parameters speciﬁc to the particular
controller – these controller-speciﬁc parameters are listed in Table 7.2. For
example, pp2a 1 controller-speciﬁc parameters are xi – damping factor and
omega – natural frequency, as shown in Figure 7.2.
Table 7.2. Controller-speciﬁc parameters
Type
Parameter
Description
ba2
ID dead time
The dead time d of the controlled process dur-
ing sampling periods. The value of this parameter
must be a non-negative integer.
da2
B – adjustment
factor
The adjustment factor B speciﬁes the dominant
time constant of the closed loop: the smaller B,
the quicker the closed loop step response.
pp2a 1
pp2b 1
xi
–
damping
factor
The damping factor ξ specifying the dynamic
behaviour of the closed loop. The dynamic be-
haviour of the closed loop is similar to that
of second-order continuous-time systems with a
characteristic polynomial D(s) = s2+2ξωns+ω2
n.
omega – natural
frequency
The natural frequency ωn specifying the dynamic
behaviour of the closed loop. The dynamic be-
haviour of the closed loop is similar to second-
order continuous-time systems with characteristic
polynomial D(s) = s2 + 2ξωns + ω2
n.
pp2a 2
pp2b 2
omega – imagi-
nary component
of the pole
The imaginary component ω of the poles of the
closed loop. The dynamic behaviour of the closed
loop is deﬁned by its poles: z1,2 = α±jω; z3,4 = α.
alfa – real com-
ponent
of
the
pole
The real component α of the poles of the closed
loop. The dynamic behaviour of the closed loop
is deﬁned by its poles: z1,2 = α ± jω;
z3,4 = α.
zn2fd
zn3fd
alfa – ﬁltration
coeﬃcient
The ﬁltration coeﬃcient α used to ﬁlter the pro-
cess output signal. The time constant of the ﬁlter
is Tf = TD/α, usually α ∈⟨3; 20⟩.
mv2
q – penalisation
factor
The penalisation factor q is used for the compu-
tation of control law parameters. This parameter
speciﬁes the measure of change of the current con-
troller output with respect to the previous con-
troller output: the smaller the penalisation, the
greater the possible change of controller output.

256
7 Computer-aided Design for Self-tuning Controllers
zn2ast
zn3ast
alfa – ﬁlter con-
stant
The ﬁltration coeﬃcient α is used to ﬁlter the
process output signal. The time constant of the
ﬁlter is, Tf = TD/α, usually α ∈⟨3; 20⟩.
beta
–
weight
factor
The weight β of the reference signal in the propor-
tional component of the controller. This weight
factor should fulﬁl the condition: 0 < β ≤1.
pp2chp
pp3chp
Reference signal
type
The controller is capable of working with three
types of controlled signal: steps, ramps and sine
waves.
Frequency
The frequency of sine waves of the reference sig-
nal. This parameter is used only if reference signal
type is sine waves.
Coeﬃcients
of
characteristic
polynomial
The vector of coeﬃcients of the closed loop char-
acteristic polynomial D(z−1) = d0 + d1z−1 +
d2z−2+. . .. The vector is formed as [d0, d1, d2, . . .].
pp2lq
Reference signal
type
The controller is capable of working with three
types of controlled signal: steps, ramps and sine
waves.
Frequency
The frequency of sine waves of the reference sig-
nal. This parameter is used only if reference signal
type is sine waves.
ﬁ– penalization
of
controller
output
The penalization of controller output in the LQ
criterion. The higher the value of qu, the greater
the weight of controller output in the LQ crite-
rion.
7.1.3 Internal Controller Structure
Each library controller is constructed as a mask of a subsystem, which consists
of Simulink R
⃝blocks and has inputs, outputs and parameters. As stated in the
previous chapters, each controller uses three input signals (i.e. the reference
signal w, the controlled signal y, and the control signal u in), and provides
two outputs (i.e. the control output u, and the current model parameter
estimates).
The internal controller structure consists of Simulink R
⃝blocks which pro-
vide, among other things, for the possibility of simple creation of a new con-
troller by the modiﬁcation of an appropriate library controller. The structure
of the controller pp2a 1 is presented in Figure 7.3 as an example. Each library
controller consists of three basic parts:
•
on-line identiﬁcation block;

7.1 Self-tuning Controllers Simulink
R
⃝Library
257
•
block for computing controller parameters;
•
block for computing controller output.
 
2 
ID param. 
1 
u(k) 
xi 
xi 
MATLAB 
Function 
pp2a_1 
omega 
omega 
sid 
Identification 
1 
Adaptation 
1/z 
Unit Delay 
T0 
Sampling 
period 
scqp
Q(z) / P(z) 
3 
w(k) 
2 
y(k) 
1 
u_in(k) 
Figure 7.3. Block scheme of the pp2a 1 controller
From a programmer point of view, each block corresponds to a stand-
alone program ﬁle, which is, after the simulation starts, interpreted by the
Matlab R
⃝environment. The blocks are implemented as a Matlab R
⃝Fcn and
an S-Function. The Matlab R
⃝Fcn block performs the call of a Matlab R
⃝
function, which converts the input data vector to the output data vector. The
S-Function block is more universal, and the corresponding function can in
addition use both discrete and continuous-time states.
The on-line identiﬁcation algorithm is implemented using the s-function
sid, which calculates parameter estimations of the controlled process model
on the basis of the current process output, the previous process input, the
identiﬁcation parameters, and the states of the on-line identiﬁcation.
The computation of controller parameters is provided by the m-function,
which does not use the states, and only converts the input vector to the output
vector. The input vector consists of the current parameter model estimates,
and eventually, other parameters depending on controller type. The output
vector contains the controller parameters used when calculating the controller
output. The name of this function is the same as the name of the whole
controller.
The computation of controller output is implemented as an s-function
computing the controller output on the basis of the controller parameters, the
control error, and the previous input of controlled output. The reference value
and the current process output are used instead of control error in feedback
feedforward controllers. The previous value of the controller output is not
taken as a state – because it can be changed before reaching the controlled
process input, e.g. due to saturation. The scqp function is used to calculate
controller output in most of the feedback controllers, i.e. controllers that use
control error. Controllers containing a feedforward part, use the scrqp func-
tion. Controllers using four-point diﬀerence (zn2fpd and zn3fpd) and ˚Astr¨om

258
7 Computer-aided Design for Self-tuning Controllers
Controllers (zn2ast and zn3ast) use their own functions to compute controller
output – scfpd and scast.
The basic version of the library uses the Matlab R
⃝programming language
to implement all of the above-mentioned functions. The advantage of this
approach is the simple implementation of matrix and vector operations.
7.1.4 Reference Guide and Help
Besides the ﬁles implementing the functionality of all library controllers, the
library package also includes a reference guide with a short description of all
the controller algorithms, operating with the controllers, and a description of
the internal structure of the controllers. The guide is currently available in
two versions:
•
pdf format – suitable for printing;
•
html format – used for context help.
Moreover, the help for each function included in the library can be invoked by
entering the following: help function name in the Matlab R
⃝command line.
Then a short description of the function, its inputs, and outputs is displayed
in the Matlab R
⃝command window.
7.1.5 Creating Applications with Real-Time Workshop
The Matlab R
⃝/Simulink R
⃝environment can also be used to generate code
to be used in controllers in industrial practice. Real-Time Workshop, one of
the toolboxes shipped with Matlab R
⃝, allows the generation of source code
and programs to be used outside the Matlab R
⃝environment. The process
of generating the source code is controlled by special compiler ﬁles that are
interpreted by Target Language Compiler. These ﬁles are identiﬁed by the .tlc
(target language compiler) extension and describe how to convert Simulink R
⃝
schemes into the target language. Thereby, source code is generated and after
compiling and linking, the resulting application is created. Applications for
various microprocessors and operating systems can be created by selecting the
corresponding .tlc ﬁles.
The Target Language Compiler can create applications to be used under
the Windows environment, which perform control algorithms and save the
results in a binary ﬁle with a structure acceptable to the Matlab R
⃝system.
An analysis of the control process can then be performed using the advantages
of the Matlab R
⃝functions and commands. Selecting another .tlc ﬁle, leads to
the creation of an MS-DOS application, or an application to be used on PC-
based industrial computers without the requirement for an operating system.
Many manufacturers of industrial computers and controllers have created
their own target language compiler ﬁles used to create applications for the
equipment they produce. Real-Time Workshop provides a relatively open en-
vironment for the conversion of block schemes to various platforms, where any

7.1 Self-tuning Controllers Simulink
R
⃝Library
259
users can create their own .tlc ﬁles for conversion of the block scheme to a
source code and hence, achieve compatibility with any hardware.
Application creation only requires selection of the appropriate .tlc ﬁle, or
eventually, setting the compiler parameters and then initiation of the compi-
lation process.
Compatibility of Simulink R
⃝Schemes
The Target language compiler ﬁles provided in a standard installation of Real-
Time Workshop unfortunately do not support all Simulink R
⃝blocks. The set
of unsupported blocks depends on the .tlc ﬁle used, but when working with the
Self-tuning Controllers Simulink R
⃝Library, the user may encounter problems
especially with two blocks: the Matlab R
⃝Fcn and S-Function. The .tlc ﬁles do
not support the Matlab R
⃝Fcn block, and the S-Function block is supported
only in cases where the function is written in the C language without calls in
Matlab R
⃝.
The standard library version stcsl std has been revised, and the stcsl rtw
version created so as to achieve full compatibility of the library and Real-Time
Workshop. The functionality and internal structure of all controllers is the
same in both versions, the only diﬀerence is in the resources used to program
the individual parts of the controllers. The Matlab R
⃝Fcn blocks are used
in the standard version to compute controller parameters. These blocks have
been superseded by C language s-functions, which only compute their outputs
(controller parameters) on the basis of their inputs (parameter estimates of the
controlled process model and eventually, other controller-speciﬁc parameters)
– these functions do not use any states. The on-line identiﬁcation block and
the blocks computing controller output are implemented as s-functions that
have had to be rewritten into C language. The ﬁle names in both library
versions are the same – the diﬀerence is in the extension: functions written in
Matlab R
⃝language use an .m extension, and functions written in C language
use a .c extension.
Library Versions
As mentioned in the previous chapter, the Self-tuning Controllers Simulink R
⃝
Library is available in two versions: the standard version and the Real-Time
Workshop version. The functionality, number of controllers, and internal con-
troller structure is the same in both versions – the diﬀerence being in the
internal program implementation of the program code
The standard version uses Matlab R
⃝programming language, with a sim-
ple code structure, where no variable declarations are required – the program
interpreter assigns the type to the variable according to its usage. Another
advantage of this language is the very simple implementation of matrix and
vector operations. The on-line identiﬁcation block especially uses matrix mul-
tiplications and transpositions and the computation of dead-beat controller
parameters requires matrix inversion. The code written in this language is

260
7 Computer-aided Design for Self-tuning Controllers
easy to read, to study, and to understand – and thus suitable when studying
the details of controller implementation. This code is also suitable for writing
user-deﬁned controllers.
The Real-Time Workshop version of the library was constructed using the
C programming language. The main advantage of this version is its portability,
because only functions written in C language are supported when converting
block schemes to applications through the Target Language Compiler. The
disadvantage resides in larger source ﬁles and thus worse readability of the
code.
The Self-tuning Controllers Simulink R
⃝Library is used in the univer-
sity course Adaptive Control Systems. Its architecture enables easy user ori-
entation in Simulink R
⃝block schemes and generates source code for con-
troller functions. The controllers provided are suitable for modiﬁcation and
thereby implementation of user-deﬁned controllers. Compatibility with Real-
Time Workshop not only ensures the possibility of laboratory testing using
real-time models, but also the possibility of creating applications for industrial
controllers.
7.2 Linear-Quadratic Toolbox
The toolbox given here has arisen out of the need to demonstrate the charac-
teristics and application of
•
LQ controllers, which require knowledge of the discrete transfer function
of the controlled system.
•
Adaptive LQ controllers.
The current toolbox for Matlab R
⃝and Simulink R
⃝provides:
•
Simulink R
⃝schemes for:
–
a ﬁxed controller (various schemes to demonstrate various characteris-
tics).
–
an adaptive controller (a standard regression model, or a model with
integrator factor).
•
Simulink R
⃝blocks representing ﬁxed and adaptive controllers.
•
m-ﬁles for LQ optimization and identiﬁcation and a few auxiliary m-ﬁles.
7.2.1 Fixed Linear-Quadratic Controllers
This part of the LQ toolbox was created to provide the material presented in
Chapter 6 demonstrating the properties of this LQ approach. There are two
basic schemes. Schema1.mdl is depicted in Figure 6.4, and serves for discrete
time applications. The Schema2.mdl demonstrates the application of a ﬁxed
controller to a continuous-time plant.

7.2 Linear-Quadratic Toolbox
261
1
s  +2s+1
2
Transfer Fcn1
2
s  +2s+1
2
Transfer Fcn
uout
To Workspace1
yout
To Workspace
Sum2
Sum1
Sum
Signal
Generator
Scope1
Scope
Saturation
Mux
Mux
1/s
Integrator
−K−
Gain1
Clu0 
1 
Filter3
Clw 
1 
Filter2
1 
R 
Filter1
1 
num(z)
Filter
u[1]^2
Fcn
0
Display
0
Constant1
Band−Limited
White Noise
Figure 7.4. Schema2.mdl; discrete LQ controller with continuous-time plant
This scheme is similar to that of the general controller scheme Figure 6.2.
The input signals are system output y(t); set point w(t); and reference input
u0(t). The parameters of such a controller can be calculated using of the
function
function [R,S,kon,Clw,Clu0,sric]=lqexb(b,a,k,nstep,qur,dqy,dqu,s0)
where the outputs of the function are the parameters of corresponding blocks,
and additionally, the square root of the Riccati matrix (sric); input parameters
are as follows:
b - System numerator in the operator z−1 with arbitrary length, i.e leading
zeros can be used to represent time delay.
a - System denominator of arbitrary order.
k - Value of the oﬀset in a regression model (6.4).
nstep - Horizon of the criterion.
qur - Penalization of system input.
dqy - Penalization of system output increments.
dqu - Penalization of system input increments.
s0 - Diagonal element of the initial Riccati matrix
The code of this function is quite simple.
The auxiliary function: abk2pr.m creates a pseudostate matrix of the sys-
tem; makesm1.m creates the initial Riccati matrix. The function znob.m con-
tains the call of lqexb.m. This function is useful for tuning the controller. After
changes to any penalization, a new control law is obtained by calling znob.m.
7.2.2 Adaptive Controllers
Adaptive controllers are represented by eight Simulink R
⃝schemes with six
diﬀerent adaptive controllers for the positional LQ adaptive controller (stan-
dard regression model) and an incremental one (with added integrator factor)
for cases with external measurable disturbance and set point preprogramming.

262
7 Computer-aided Design for Self-tuning Controllers
Listing 7.1. The code of the LQ optimization function lqexb
function [rr,ss,kon,clw,clu0,s]=lqexb(b,a,k,nstep,qur,dqy,dqu,s0)
na=max(size(a))-1;
nb=max(size(b));
m=nb+na + 3;
[pr,str]=abk2pr(b,a,k);
s = makesm1(str,s0,1);
qur=sqrt(qur); dqu=sqrt(dqu); dqy=sqrt(dqy);
th=pr(nb,:);
qu=zeros(size(th)); qdy=th; qdu=qu; qu(1)=1; qu(m)=-1;
qdy(nb+2)=qdy(nb+2)-1;qdu(1)=1;qdu(2)=-1;
h=s*pr;
[mm,nn]= size(h);
hn= zeros(mm+1,nn); dn=eye(mm+1);
for i=1:nstep
h= s*pr;
xx=th;xx(m-1)=-1;
hn=triu(qr([h;xx;qur*qu;dqy*qdy;dqu*qdu]));
s=hn(2:m,2:m);
end
cl=hn(1,:)/hn(1,1);
rr=cl(1,1:nb); ss=cl(1,nb:na +nb); kon=cl(1,m-2); ss(1)=0;
clw=cl(1,m-1); clu0=cl(1,m);
All controllers that do not consider pre-programming use the same basic
blocs for identiﬁcation (jbslidex.m), controller synthesis (lqjbse.m) and for con-
Table 7.3. Adaptive LQ controller Simulink
R
⃝blocks
Name
Function
adlqs
basic scheme for positional controller
adlqsd
scheme for measurable disturbance and positional controller
adlqsw
scheme for set point pre-programming positional controller
adlqswd scheme for set point pre-programming
measurable disturbance with positional controller
adlqi
basic scheme for incremental controller
adlqid
scheme for measurable disturbance and incremental controller
adlqiw
scheme for set point pre-programming incremental controller
adlqiwd scheme for set point pre-programming
measurable disturbance with incremental controller

7.2 Linear-Quadratic Toolbox
263
troller (ctrlx.m)but diﬀers by the use of other blocks and additional signals.
Controllers for pre-programming use slightely modiﬁer functions ctrlxw and
lqjbsebw.m. The Simulink R
⃝block for identiﬁcation can be substituted by the
identiﬁcation block lsident2.mdl realizing square root identiﬁcation function
lssqrt.m having the following code:
Listing 7.2. The code of the square root identiﬁcation function lssqrt.m
function [sys, x0,str,ts]= lssqrt(t,x,u,flag,stru,F0,Ts,fi)
m=stru(2)*stru(1)+stru(4)*stru(3)+stru(6)*stru(5)+1;
mm=stru(3)*m;
ny=stru(3);
nu=stru(1);
mp=m-1;if (stru(7)==1),mp=m;end
if abs(flag) == 0
sys = [0 mm+m+(m+ny)*(m+ny)+ny mm+ny
ny+nu 0 0 1];
x0 = zeros(m+mm+(m+ny)*(m+ny)+ny,1);
x0(m+1:m+(m+ny)*(m+ny))= F0(:,:);
if (stru(7)==1),
x0(m)=1; end
ts =[Ts 0];
elseif flag == 2
yy= x(m-ny:m-1);
uu=u(1:stru(1));
vv=[ ]; if(stru(5)~=0),vv= u(stru(1)+stru(3)+1:end);end
xx=x(1:m);
xx= fun_shif(xx,stru,yy,uu,vv);
P=zeros(m+ny);
P(:)= x(m+1:m+(m+ny)*(m+ny));
z=[xx; u(stru(1)+1:stru(1)+stru(3))];
P=triu(qr([P;z’]));
Eth=inv(P(1:mp,1:mp))*P(1:mp,m+1:m+ny);
Eth=[Eth ;zeros(1-stru(7),stru(3))];
P = P(1:m+ny,1:m+ny)*fi;
ep =
u(stru(1) +1:stru(3)+stru(1)) -
Eth’*xx ;
xx(m-ny:m-1)=u(stru(1) +1:stru(3)+stru(1));
pom=Eth’;
sys=[xx;P(:);pom(:);ep];
elseif flag == 3
sys =x(m+(m+ny)*(m+ny) +1:end);
else
sys=[ ];
end
The scheme below shows the application of the controller with measurable
disturbance and pre-programming in a typical environment.
Controller output is a manipulated variable, the controller block inputs are
the system input u(t) (it can be diﬀerent from the controller output); system
output y(t); set point w(t); reference input u0(t); measurable disturbance d(t);

264
7 Computer-aided Design for Self-tuning Controllers
uout
To Workspace3
yout
To Workspace2
Sum2
Sum1
Scope1
Scope
Saturation
oldval
S−Function
Pulse
Generator
Mux
Mux1
Mux
Mux
0
Gain4
u[1]^2
Fcn
0
Display
0.1
z−1
Discrete−Time
Integrator
.1
z−.9
Discrete
Transfer Fcn4
num(z)
z  −1.81z+.819
2
Discrete
Transfer Fcn
.3z+.1
z  −1.81z+.819
2
DTF2
z  +2z+1
2
z  −1.81z+.819
2
DTF1
LQ
 adaptive 
 controller
Controller
−1
Constant2
0
Constant1
Band−Limited
White Noise1
Band−Limited
White Noise
Figure 7.5. adlqswd.mdl; adaptive LQ controller with external disturbance and
pre-programming
and the pair [uf(t), yf(t)] for identiﬁcation. These values can be directly:
[u(t),y(t)], but frequently they are ﬁltered input and output.
Adaptive controllers are masked blocks. The meaning of its parameters is
given in Table 7.4
Table 7.4. Adaptive controller parameters
name meaning
details
strav measurable disturbance order of the denominator of the disturbance
structure
autoregression model
stru
model structure
[numerator order, denominator order
order of the measurable disturbance
qur
input penalization
value of Qu
dqu
input increment
value of Q∆u
penalization
dqy
output increment
value of Q∆y
penalization
nstep horizon of the
criterion
ﬁ
forgetting factor
To
sampling period

7.3 Summary of chapter
265
The schemes serve as:
•
Demo ﬁle.
•
A typical simulation environment to test adaptive LQ ControllersIN which
the user can change the system or controller setting.
•
Sources for the “LQ Adaptive Controller” block for other simulation
schemes created by the user. The adaptive controller is provided with a
group of S-functions for identiﬁcation, optimization, and controller output
generation.
The blocks of the adaptive controller with exteral disturbance and pre-
programming are shown in Figure 7.6. There are two identiﬁcation blocks
providing the parameters of the plant model and of the disturbance model.
1
out_1
LQ−syn
synthesis
parid
To Workspace2
parid1
To Workspace1
cl
To Workspace
CTRLe 
 adaptive
S−function2
jbslidex
S−function1
jbslidex
S−function
Mux
Mux4
Mux
Mux3
Mux
Mux1
6
in_5
5
in_6
4
in_4
3
in_3
2
in_2
1
in_1
Figure 7.6. Adaptive controller subsystem with external disturbance and pre-
programming
The incremental controller is represented by the scheme Figure 7.7.
The parameters of adaptive controllers are set in the mask in Figure 7.8.
7.3 Summary of chapter
Two Matlab R
⃝toolboxes are introduced in this chapter: the Self-tuning Con-
trollers Simulink R
⃝Library and the LQ Toolbox. The ﬁrst contains over 30
simple, discrete, single-input/single-output adaptive controllers which identify
a controlled process model using second or third-order models. The controller
parameters and algorithms are discussed and summarized in overviews in
several tables. Incorporation of the controllers into Simulink R
⃝schemes, sim-
ulation veriﬁcations and real-time examples are also presented. To simplify

266
7 Computer-aided Design for Self-tuning Controllers
1
out_1
LQ−syn
synthesis
parid
To Workspace2
cl
To Workspace
CTRLe 
 adaptive
S−function2
jbslidex
S−function
INTEGR1
S−Function1
INTEGR2
S−Function
Mux
Mux4
Mux
Mux3
5
in_5
4
in_4
3
in_3
2
in_2
1
in_1
Figure 7.7. Adaptive LQ incremental controller subsystem
Figure 7.8. Adaptive LQ controller parameters setting table
use of the controllers in real-time environments, the connection to Real-Time
Workshop is mentioned. The LQ toolbox contains two groups of discrete con-
trollers based on minimization of the LQ criterion: ﬁxed controllers and adap-
tive controllers with on-line identiﬁcation of the controlled process using the
ARX model. The control laws of these types of controllers are based on solving
the Riccati equation, and this process is presented by listing the program in
connection with the corresponding simulation schemes.

8
Application of Self-tuning Controllers
Several self-tuning controllers described in this monograph have been veriﬁed
by real-time control of laboratory plants. Section 8.1 gives results of the real-
time control of several laboratory models by controllers included in the Self-
tuning Controllers Simulink Library [131]. Also described are applications of
the adaptive LQ controller to a heat exchanger station (Section 8.2), to boiler
control with multivariable LQ controllers (Section 8.3), to an adaptive LQ
controller in cascade control (Section 8.4) and to steam pressure control in a
drum boiler in a power plant (Section 8.5).
8.1 Decentralized Control Using Self-tuning Controllers
The selected SISO controllers included in the library were veriﬁed by real-
time control of educational laboratory models. This section gives results of
the control of the following models: air heating system, laboratory model of
coupled motors CE 108, and twin rotor MIMO system (helicopter model). All
these models are two-input/two-output (TITO) systems and the decentralized
approach with logical supervisor was applied for their control.
The classical approach to the control of MIMO systems is based on the
design of a matrix controller to control all system outputs at one time. Com-
putation of the matrix controller is realized by one central computer. The
basic advantage of this approach is the possibility of achieving optimal con-
trol performance because the controller can use all information known about
the controlled system. The disadvantage of using a central matrix controller
is its demand on computer resources because the number of operations and
required memory depend on the square of the number of controlled signals.
Nowadays this problem is reduced thanks to great progress in the develop-
ment of computer hardware; this, however, increases the price of the control
system. Another disadvantage is the inﬂuence central controller faults on the
controlled system. If the central controller fails, all the controlled signals are

268
8 Application of Self-tuning Controllers
aﬀected; thus the reliability of the controller is fundamental. Ensuring the re-
quired reliability can be unbearable from the ﬁnancial point of view, especially
in critical applications.
An alternative solution to the control of MIMO systems is a decentralized
approach. In this case, the system is considered as a set of interconnected
subsystems and the output of each subsystem is inﬂuenced not only by the
input to this subsystem but also by the input to the other subsystems. Each
subsystem is controlled by a stand-alone controller. Thus, decentralized con-
trol is based on decomposition of the MIMO system to subsystems, and the
design of a controller for each subsystem [104]. Another advantage of the de-
centralized approach is that it is a lot easier to set controller parameters (e.g.
choice of poles of the characteristic polynomial) for SISO control loops than
for MIMO control loops. On the other hand, the control performance of a
decentralized control system is suboptimal because controllers do not use in-
formation from the other subsystems. A further disadvantage is the limited
applicability of the decentralized control to symmetric systems (systems with
an equal number of inputs and outputs).
Each output of a multivariable controlled system can be aﬀected by each
system input. The strength of the eﬀect is determined not only by internal
transfers of the MIMO system but also by the evolution of the system input
signals. When the decentralized approach is used to control such a system
then, from the point of view of a controller of a particular subsystem, the
transfer function varies in time even if the MIMO system is linear and stable.
The presence of subsystem interconnections is the main reason for us-
ing self-tuning controllers in a decentralized approach to ensure the required
course of controlled variables. Identiﬁcation algorithms suitable for use in de-
centralized control must include weighting of identiﬁcation data such that new
data aﬀect model parameters estimation more than older data. This require-
ment is a consequence of the time-varying inﬂuences of other subsystems on
the identiﬁed subsystem. The inﬂuence of control variable (ui) on the corre-
sponding controlled variable (yi) decreases with increasing gain of subsystem
interconnections. This could lead to an unstable process of recursive param-
eter estimates. The stability of recursive identiﬁcation can be increased by
ensuring that just one of the controllers connected to the multivariable sys-
tems works in an adaptive regime at a particular time. Recursive identiﬁcation
parts of other controllers are suspended and parameter model estimates are
constant for that time.
8.1.1 Supervisory System
The process of switching on and oﬀrecursive identiﬁcation is controlled by
a new part of the control circuit – the supervisory system. Switching the
identiﬁcation on and oﬀcan be described as a process of transferring tokens
among subsystems where only the controller, which currently has a token, can

8.1 Decentralized Control Using Self-tuning Controllers
269
perform recursive identiﬁcation. The token is moved to an other subsystem
when a selected criterion is used.
The supervisory system represents a second level of control and thus a
control circuit with supervisory system has a hierarchical control structure.
An example of a control circuit scheme with supervisory system is shown in
Figure 8.1. The ﬁrst (lowest) level of hierarchy contains individual self-tuning
controllers (STC 1, STC 2 and STC 3 in Figure 8.1) and the second level
(superior) is represented by a supervisory system, which controls individual
self-tuning controllers. The supervisory system analyses particular values from
the control circuit and on the basis of these analyses moves the identiﬁcation
token among subsystems. In the case shown in Figure 8.1, the analysis is
performed on the basis of reference values and controlled values (dotted lines)
and the process of transferring token is represented by dashed lines.
 
w1 
 
 
 
 
Controlled 
system 
 
y3 
y1 
STC 1 
STC 3 
w3 
u1 
u3 
STC 2 
w2 
u2 
y2 
Supervisory  
system 
 
Figure 8.1. Decentralized control circuit with supervisory system
The inclusion of a supervisory system into the control circuit brings the
problem of deﬁning a strategy for switching the identiﬁcation of individual
subsystems on and oﬀ, i.e. moving the token between subsystems.
8.1.2 Critera Used for Ending Adaptation of a Particular
Subsystem
Three basic approaches can be used in deciding when to suspend identiﬁcation
of a particular subsystem and move the token to an other one [132]:
•
on the basis of elapsed time;
•
on the basis of values from the currently identiﬁed subsystem;
•
on the basis of values from other subsystems.
It is also possible to combine these approaches.
Switching on the Basis of Time
This is the simplest switching algorithm, in which the supervisory system

270
8 Application of Self-tuning Controllers
contains almost no mathematical relations. Switching is realized after a pre-
set period that a controller has been in adaptive mode has elapsed. Thus,
the controller works in adaptive mode, and after a speciﬁc time elapses the
parameter estimates are “frozen” and controller continues in a mode with
constant parameters and another controllers starts its adaptive mode.
The advantage of this approach is ﬁrst its simplicity because no values have
to be the supervisory system and the programming of switching algorithms
is simple. The main disadvantage lies in the fact that the adaptive mode is
ended even if the system has not yet been well identiﬁed. This could lead to
nonstability of the identiﬁcation process especially if the preset time is short.
Switching on the Basis of Parameters of the Current Subsystem
Particular values from the currently identiﬁed subsystem are analysed and
when these values fulﬁl a criterion, the identiﬁcation is considered accurate
enough and the corresponding self-tuning controller is switched from adaptive
mode to constant parameters mode. Analysed values can be current estima-
tions of model parameters, the control error, or the controlled value.
If a control variable is observed, the criterion for ending identiﬁcation is
a steady measured level of this variable. The standard deviation computed
on the basis of a preset number of previous variable samples can serve as the
measure of a steady level. The adaptation mode is ended when the following
criterion is fulﬁlled
Ji < eps
Ji = 1
m
,
-
-
.
m−1

j=0
[yi(k −j) −¯yi]2
¯yi = 1
m
m−1

j=0
yi(k −j)
(8.1)
where eps is a threshold decision whether the observed output variable yi is
steady or not, m is the preset number of previous values to be used when
computing the standard deviation, and k is the current identiﬁcation step.
The use of the Equations (8.1) is restricted to cases where the reference
signal is constant or sequentially constant, i.e. it contains only step changes.
If the reference signal does not fulﬁl this restriction and thus the controlled
signal is not required to trace the sequentially constant signal, the control
error can be used instead of the controlled variable
Ji < eps
Ji = 1
m
,
-
-
.
m−1

j=0
[ei(k −j) −¯ei]2
¯ei = 1
m
m−1

j=0
ei(k −j)
(8.2)
An advantage of using control error lies in the fact that identiﬁcation
can be considered accurate even in cases where the control error is constant
but nonzero. This can occur when the controller is designed for a diﬀerent
reference signal then the one actually used. For example if a pole assignment
controller is designed to cover step changes of the reference signal and the
reference signal contains a ramp, the control error is constant but nonzero.

8.1 Decentralized Control Using Self-tuning Controllers
271
Another criterion can be reaching a reference variable, or to be exact, a
preset zone width about the reference signal. In this case, the adaptive mode
is ended when the control error is less than a predeﬁned level for a predeﬁned
number of samples
Ji < eps
Ji = max |ei(k −j)|
for j = 0, 1, . . ., m
(8.3)
where eps is a threshold for the decision whether to end the adaptive mode or
not, ei is the control error of the observed subsystem, m is the preset number
of previous values to be used when evaluating the criterion and k is the current
identiﬁcation step.
Another approach is based on analysing the ongoing values of model pa-
rameter estimates. In this case, the adaptation mode is ended when parameter
estimates become steady. The criterion can again be based on the standard
deviation of each parameter. Because the system model has more then one
parameter, the criterion must cover the ongoing values of all parameters. The
maximum standard deviations can be used
Ji < eps
Ji = max
r
1
m
,
-
-
.
m−1

j=0
[Θir(k −j) −¯Θir]2
¯Θir = 1
m
m−1

j=0
Θir(k −j)
(8.4)
where eps is a threshold for the decision when to end the adaptive mode, m is
the preset number of previous values to be used when evaluating the criterion,
k is the current identiﬁcation step and Θir(k −j) represents the value of the
r-th model parameter of the currently identiﬁed subsystem (i-th subsystem).
The advantage of observing parameter estimates, system output or control
error is good use of time and thus quicker attainment of correct parameter
estimates for all subsystems. There is no waste of identiﬁcation time by identi-
fying a subsystem which has already been well identiﬁed. From the time point
of view, observing parameter estimates instead of controlled system output
or control error is better because parameter estimates become steady earlier
than the system output and movement of the identiﬁcation token to another
subsystem is performed as soon as the parameter estimates become steady.
The main disadvantage of this approach lies in higher memory and computer
time demands.
Switching on the Basis of Parameters of the Other Subsystems
Ending the adaptive mode of a controller on the basis of parameters of the
other subsystems is an opposite approach to the one based on values of the
currently identiﬁed subsystem. The adaptation is ended if some other subsys-
tem needs a criterion. A simple criterion often used is the absolute value or
square of the control error
J > eps
J = max
r
|er(k)|;
r ̸= i
(8.5)

272
8 Application of Self-tuning Controllers
where eps is a threshold for the decision whether control of the r-th is accurate
enough or not, er is the control error of the r-th subsystem and k is the current
identiﬁcation step. The criterion is evaluated for each subsystem except the
currently identiﬁed one. The index corresponding to the currently identiﬁed
subsystem is i. Exceeding the criterion could be a sign that the controller is
not properly tuned and identiﬁcation of the corresponding subsystem should
be performed.
Indicators that are more complex can be used for the criterion instead of
the control error, e.g. an integral criterion of the quality of the control process.
Observing the outputs or control errors of other subsystems corresponds
better to the requirement of industrial applications of decentralized control.
It is usually not necessary to reach the exact reference signal value but it is
required, that all outputs reach predeﬁned tolerances. The disadvantage of
this approach is that it does not contain any eﬀort to avoid problem states –
adaptation is not ended as long as no outputs exceed preset limits.
Choice of Next Controller for Adaptive Mode
After adaptation of a particular subsystem is ended, the supervisory system
has to solve the task of selecting the next subsystem to switch to adaptive
mode i.e. to move the identiﬁcation token to. Often a preset sequential sub-
system order is set: after adaptation of the ﬁrst subsystem is ended, the token
is moved to the second subsystem, then to the third subsystem and so on.
After ending adaptation of the last subsystem, the token is moved back to the
ﬁrst subsystem.
Better results can be achieved if the next subsystem to be switched to
adaptive mode is determined dynamically during the control process. A typical
case when this approach is used is the case of ending adaptation on the basis
of the parameters of other subsystems. In this case, the token is naturally
moved to the subsystem which caused the ending of adaptation.
8.1.3 Logical Supervisor
A logical supervisor has been proposed to utilize and simplify the design of a
supervisory system. This approach is suitable for use in real-time industrial
applications. The idea of a logical supervisor is based on the following two
principles:
•
assigning priorities to individual subsystems;
•
on-line evaluation of criteria for each subsystem.
The situation that reaching the reference value is more important for some
subsystems than for others is very common, especially in industrial applica-
tions. It is thus possible to assign a unique priority to each subsystem. The
priority corresponds to the importance of the subsystem’s output. The num-
bering of subsystems is just a formal problem and thus the subsystems can be

8.1 Decentralized Control Using Self-tuning Controllers
273
numbered according to priorities. The ﬁrst subsystem has the highest priority;
the second subsystem has the second highest priority and so on.
 
w1 
 
 
 
 
Controlled 
system 
 
y3 
y1 
STC 1 
STC 3 
w3 
u1 
u3 
STC 2 
w2 
u2 
y2 
Logical 
supervisor 
Real signals 
Key: 
Adaptation enabled 
Adaptation required 
Boolean signals 
Figure 8.2. Decentralized control circuit with logical supervisor
Further, for each subsystem, a criterion which determines whether the
subsystem requires switching to adaptive mode or not, is calculated. The cri-
terion can be designed with respect to particular properties of the subsystem.
The block responsible for computing the criterion can be encapsulated with
the self-tuning controllers and the output, which is sent to the logical super-
visor, is a Boolean value determining whether or not the subsystem requires
adaptation.
The last part of the logical supervisor approach is a superior logic deter-
mining which of subsystems requiring adaptation will be switched to adaptive
mode. The decision-making is based on priorities assigned to individual sub-
systems. If the ﬁrst subsystem requires switching to adaptive mode it is always
satisﬁed; if the second subsystem requires switching to adaptive mode, it is
satisﬁed only if the ﬁrst subsystem does not require switching to adaptive
mode, etc. The control circuit schema with logical supervisor approach and
a controlled system of three inputs and three outputs is shown in Figure 8.2
when only one of the dashed signals, “Adaptation enabled”, is switched on at
a time.
The logical supervisor uses only the logical values on its input and provides
logical values on its output. In addition, the relations between inputs and
outputs are simple logical functions. The transfer function between the input

274
8 Application of Self-tuning Controllers
and output signals of the logical supervisor can be arranged as a table of
logical values. This situation is shown in Table 8.1 for the MIMO system of
three inputs and three outputs.
Table 8.1. Relations between inputs and outputs of a logical supervisor
Required adaptation (inputs)
Enabled adaptation (outputs)
R1
R2
R3
E1
E2
E3
0
0
0
0
0
0
0
0
1
0
0
1
0
1
0
0
1
0
0
1
1
0
1
0
1
0
0
1
0
0
1
0
1
1
0
0
1
1
0
1
0
0
1
1
1
1
0
0
It is also possible to rewrite relations between inputs (Rk) and outputs
(Ek) using logical operators:
E1 = R1
E2 = ¯
R1 AND R2
E3 = ¯
R1 AND ¯
R2 AND R3
(8.6)
where the bar denotes negation of a variable and function AND represents
logic product. When determining signal “Adaptation enabled” for a general
controlled MIMO system, the following relation is valid:
Ek =
k−1
/
i=1
¯Ri AND Rk
(8.7)
where 0 stands for logic product.
The logical supervisor represents a reliable approach to the design of a
supervisory system for decentralized control. The advantage of this approach

8.1 Decentralized Control Using Self-tuning Controllers
275
 
  
y2   
y1   
u_in(k)   
y(k)   
w(k)   
id_cntrl   
u(k)   
R2 
  
Adaptive 
Controller 2   
u_in(k)   
y(k)   
w(k)   
id_cntrl   
u(k)   
  
Adaptive 
controller 1     
Reference 
  
signal 1   
R1 
R2 
E1 
E2 
Logical supervisor   
u1   
u2   
y1   
y2   
Controlled   
process 
  
  
Reference 
  
signal 2   
R1 
Figure 8.3. Simulink control circuit with TITO controlled system
is its simplicity of implementation and the small number of signals that are
transferred from subsystems to supervisory system and back.
The logical supervisor was tested in connection with controllers from
the STCSL. The properties of controllers were tested in the Matlab R
⃝or
Simulink R
⃝environment using the control scheme shown in Figure 8.3. The
model contains a continuous-time TITO system controlled by two self-tuning
controllers and a logical supervisor which provides identiﬁcation switching
between input/output pairs.
The quality of the control process is aﬀected by many parameters; e.g.
sampling period, control law algorithm, logical supervisor algorithm, satu-
ration, initial parameter estimates. The recursive identiﬁcation uses a least
squares method with adaptive directional forgetting.
8.1.4 Control of Air Heating System Model
The air heating system model is shown in Figure 8.4. This system has two in-
puts (rotations of ventilator and power of resistance heating) and two outputs
(the ﬂow of air, measured by the rotations of an airscrew; and temperature
inside the tunnel, measured by a resistance thermometer). The system was
divided into two input/output pairs, the ﬁrst pair consisting of ventilator ro-
tations as input u1 and ﬂow of air as output y1. The second pair consist of
resistance heating power as input u2 and temperature as output y2. The aim
is to control a TITO system using two standalone single-input/single-output
controllers; i.e. a decentralized approach was applied.
The connection of the laboratory model and the Simulink R
⃝environment
has been realized through control and measurement PC card Advantech PCI-
1711. Blocks for reading analogue inputs and for writing to the analogue

276
8 Application of Self-tuning Controllers
                                                                                                                             
1   
2  
3  
4
5
6  
7
1 – ventilator  
 
4 – resistance thermometer 
2 – resistance heating  
5 – shutter 
3 – pressure sensor 
 
6 – shield 
7 – air flow measurement 
Figure 8.4. Laboratory air heating model
outputs on the PC card were used to communicate with the model. These
blocks are implemented as s-functions written in C language, which allows
low-level access to the ports of the PC computer. This mechanism allows
the connection of Simulink R
⃝and any PC compatible equipment designed to
collect external data.
The control performances using pole assignment controllers pp2b 1 (4.135)
given by
u(k) = −[(q′
0 + β)y(k) −(q′
0 + q′
2)y(k −1) + q′
2y(k −2)]
−(γ −1)u(k −1) + γu(k −2) + βw(k)
(8.8)
0
200
400
600
800
0
2
4
6
8
y1,w1
Time[s]
0
200
400
600
800
0
2
4
6
u1
Time[s]
0
200
400
600
800
0
2
4
6
8
y2,w2
Time[s]
0
200
400
600
800
0
2
4
6
8
u2
Time[s]
Figure 8.5. Control performance using pole assignment controllers (pp2b 1) – lab-
oratory heating model

8.1 Decentralized Control Using Self-tuning Controllers
277
are shown in Figure 8.5. The controller output variables are the air ﬂow source
(speed of the ventilator – u1) and the heat source (resistance heating – u2).
The process output variables are the speed value of the air indicator – y1 and
the air temperature – y2. The following controller parameters were chosen:
First controller: sampling period T0 = 1 s, damping factor ξ = 3, natural
frequency ωn = 1.
Second controller: sampling period T0 = 1 s, damping factor ξ = 10,
natural frequency ωn = 1.
0
200
400
600
800
−2
−1
0
1
Parameter estimates
Time[s]
a2 
a1 
b1 
b2 
0
200
400
600
800
−2
−1
0
1
2
Parameter estimates
Time[s]
b1 
a1 
b2 
a2 
Figure 8.6. Evolution of parameter estimates using pp2b 1 controllers – laboratory
heating model: upper graph – control of air-ﬂow, lower graph – control of tempera-
ture
The time constant of the pair ventilator–ﬂow is relatively small compared
with time constant of the heating–temperature pair and thus the output of
the ﬁrst pair becomes steady earlier. Results demonstrate that the change of
resistance heating power does not aﬀect the ﬂow of air, but the inﬂuence of
ventilator rotation on the temperature is substantial. The parameters of the
heating–temperature controlled system thus change over time and the on-line
identiﬁcation method used should assign greater weight to newer data than to
older data. The evolution of parameter estimates are presented in Figure 8.6.
It is obvious from Figure 8.6 that changes of parameter estimates are greater
in the ﬁrst phase, caused by inaccurate initial parameter estimates. Further
changes of parameter estimates correspond to changes of reference signal,
indicating the presence of a nonlinearity in the system.

278
8 Application of Self-tuning Controllers
The control performance was diﬀerent when a controller of another type
was used, as shown in Figure 8.7. The evolution of the reference signal is the
same as in the previous case, but zn2br controllers (4.16) given by
u(k) = KP

e(k) −e(k −1) + T0
TI
e(k)
+TD
T0
[e(k) −2e(k −1) + e(k −2)]

+ u(k −1)
(8.9)
were used. The zn2br controller uses the Ziegler–Nichols algorithm to com-
pute the value of controller output using a backward rectangular method of
discretization integration component with sampling period T0 = 1 s.
In this case process output oscillations are signiﬁcantly greater and the
quality of control is lower compared with the pole assignment controllers.
0
200
400
600
800
0
2
4
6
8
y1,w1
Time[s]
0
200
400
600
800
0
2
4
6
u1
Time[s]
0
200
400
600
800
0
2
4
6
8
y2,w2
Time[s]
0
200
400
600
800
0
2
4
6
8
u2
Time[s]
Figure 8.7. Control performance using Ziegler–Nichols based controllers (zn2br) –
laboratory heating model
In all cases the initial vector of parameter estimates was chosen without
a priori information ˆΘT (0) = [0.1, 0.2, 0.3, 0.4] and controllers outputs were
limited within the range ⟨0; 5⟩.
8.1.5 Control of Coupled Motors CE 108
Another practical veriﬁcation of decentralized control using STCSL in connec-
tion with the Real-Time Workshop was carried out with coupled servomotors
CE 108 (producer TecQuipment Ltd., Nottingham, UK). The schema of this
model is shown in Figure 3.8 (see Section 3.2.4).
This system has two inputs (rotations of the left, u1, and the right, u2,
servomotors) and two outputs: the speed, y1, of the belt measured by pulley
rotation and the tension, y2, of the belt measured by deviation of the jib.
Considering the mechanical point of view, the system was divided into two

8.1 Decentralized Control Using Self-tuning Controllers
279
input/output pairs, the ﬁrst pair consisting of the rotations of the left ser-
vomotor, input u1, and the tension of the belt, output y2. The second pair
consists of the rotations of the right servomotor, input u2, and the speed of the
belt, output y1. This system is strongly nonlinear with great interactions be-
tween individual loops. The static characteristics of this equipment are shown
in Figure 3.10.
A sample of the control performance using Ziegler–Nichols based con-
trollers zn2fr with sampling period T0 = 0.25 s given by Equation (4.18)
u(k) = KP

e(k) −e(k −1) + T0
TI
e(k −1)
+TD
T0
[e(k) −2e(k −1) + e(k −2)]

+ u(k −1)
(8.10)
is shown in Figure 8.8. The ﬁrst part of the control sequence (approximately
0–40 s) is used to adapt controllers to the system because the initial model
parameter estimates are set without a priori information about the controlled
system.
0
50
100
150
200
0
2
4
6
y1,w1
Time[s]
0
50
100
150
200
−2
0
2
4
6
u1
Time[s]
0
50
100
150
200
−2
−1
0
1
2
3
y2,w2
Time[s]
0
50
100
150
200
−2
0
2
4
6
u2
Time[s]
Figure 8.8. Control performance using Ziegler–Nichols based controllers (zn2fr) –
coupled motors CE 108
Another control performance is shown in Figure 8.9. The pole assignment
controllers pp2a1 given by equation (4.120)
u(k) = q0e(k) + q1e(k −1) + q2e(k −2) + (1 −γ)u(k −1) + γu(k −2) (8.11)
were used in this case. The poles were set so that the closed loop behaves like
a second-order continuous-time system with controller parameters in both
circuits T0 = 0.1 s, ξ = 1 and ωn = 2.
In all cases the initial vector of parameter estimates was chosen without
a priori information ˆΘT (0) = [0.1, 0.2, 0.3, 0.4] and controller outputs were
limited within the range ⟨0; 5⟩.

280
8 Application of Self-tuning Controllers
0
50
100
150
200
−2
0
2
4
6
y1,w1
Time[s]
0
50
100
150
200
−2
0
2
4
6
u1
Time[s]
0
50
100
150
200
−2
−1
0
1
2
y2,w2
Time[s]
0
50
100
150
200
−2
0
2
4
6
u2
Time[s]
Figure 8.9. Control performance using pole assignment controllers (pp2a1) – cou-
pled motors CE 108
8.1.6 Control of Twin Rotor MIMO System – Helicopter
The ﬁnal laboratory model used to verify the decentralized approach to the
control of multivariable systems, is the Twin Rotor MIMO System (Feedback
Instruments, Ltd, UK). This model, which is shown in Figure 8.10, provides a
high-order, nonlinear system with signiﬁcant cross-coupling. The main parts
of the system are the pedestal, the jib connected to the pedestal and two
propellers at the ends of the jib. The system jib can freely rotate around
the vertical axis by about 330 degrees (process output y1(t)) and the hori-
zontal axis by about 100 degrees (process output y2(t)). The system inputs
u1(t), u2(t) are the voltages used to drive the propeller motors, and outputs
are angular rotations with respect to horizontal and vertical axes.
 
1 
2 
4 
5 
1 – small airscrew 
2 – jib 
3 – measurement of 
rotation angles 
4 – pedestal 
5 – big airscrew 
3 
Figure 8.10. Twin rotor MIMO model (helicopter)

8.1 Decentralized Control Using Self-tuning Controllers
281
Despite the strong interactions in the system, decomposition to subsystems
is straightforward:
•
the ﬁrst subsystem consists of the small propeller which drives the angular
rotation around the vertical axis;
•
the second subsystem consists of the big propeller driving the angular
rotation around the horizontal axis.
Before the control circuit was connected as a closed loop, experiments to
obtain the static characteristics of the systems were performed. The inﬂuence
of the ﬁrst system input on the second system output is small but the evolution
of the second output is a sign of nonlinearity of the system. Another control
problem using this system is the large hysteresis which is present in the system.
The static characteristics of the ﬁrst subsystem, measured for increasing and
decreasing input signals, are shown in Figure 8.11. The great inﬂuence of
changes of the second system input on the ﬁrst output was conﬁrmed by this
measurement.
−0.25
−0.15
0
0.15
0.25
−200
−100
0
100
200
300
u1 − small propeller
y1 − vertical axis 
u2 = −0.25
u2 = 0.05
Figure 8.11. Static characteristics of the ﬁrst subsystem showing hysteresis – twin
rotor MIMO model
The control performance of the twin rotor MIMO system using pp2b 1
controllers (8.8) is presented in Figure 8.12. The following controller parame-
ters were chosen:
First controller: sampling period T0 = 0.5 s, damping factor ξ = 10, natu-
ral frequency ωn = 1.
Second controller: sampling period T0 = 1 s, damping factor ξ = 10, nat-
ural frequency ωn = 1.
In both cases the initial vector of parameter estimates was chosen without
a priori information ˆΘT (0) = [0.1, 0.2, 0.3, 0.4]. Figure 8.12 demonstrates that
this strongly nonlinear, unstable and high-order system can be stabilized, and

282
8 Application of Self-tuning Controllers
0
50
100
150
200
250
300
−100
0
100
200
300
y1,w1
Time[s]
0
50
100
150
200
250
300
−2
−1
0
1
2
u1
Time[s]
0
50
100
150
200
250
300
0
100
200
300
400
500
y2,w2
Time[s]
0
50
100
150
200
250
300
−2
−1
0
1
2
u2
Time[s]
Figure 8.12. Control performance using pole assignment controllers (pp2b 1) – twin
rotor MIMO model
also that quite good asymptotic tracking can be achieved by using adaptive
control without a priori information about the process model.
8.2 Application of the Adaptive Linear Quadratic
Controller to a Heat Exchanger Station
A team from the Faculty of Mechanical Engineering of the Slovak University of
Technology in Bratislava prepared the experimentation on the heat exchang-
ing station at the university. A PC computer was connected to the existing
control system. Automatic switching mechanism was build up to switch on the
standard controller in case the experiment leads to the undesirable behaviour.
In this way the problems with the technology as well as operators of the plant
were safely prevented. The Matlab R
⃝Simulink R
⃝environment was used for
the communication with the technology. Various predictive controllers were
tested in the plant and are reported in [133]. Here an experiment with a LQ
adaptive controller is described.
8.2.1 The Technology
Trials were carried out on a standard industrial heat exchange station at the
university campus. The station supplies heat and hot water to all university
buildings and facilities. It is equipped with a two-stage tubular concentric
counterﬂow exchanger having 20m2 of heat-exchanging surface. The temper-
ature of the outlet is controlled by varying the ﬂow of the primary hot water
by means of a servovalve. The dynamics of the exchanger can be roughly ap-
proximated by a ﬁrst-order system with time delay about 30 s and rise time
about 120 s. In the existing setup, the plant is controlled by a PID controller
running at a sampling period of 0.5 s and with an outlet temperature set point
of 55oC. The PID constants are as follows: P = 2, I = 0.003, D = 0.

8.2 Application of the Adaptive LQ Controller to a Heat Exchanger Station
283
8.2.2 Linear Quadratic Controller
The adaptive LQ controller used in the experiment was described in Chapter 6,
and the LQ toolbox in Section 7.2. Its setup is as follows:
1. The bsic model of the process was assumed to be in the form of second-order
regression model
y(k) = −
n

i=1
aiy(k −i) +
n

i=0
biu(k −i) + ek +
n

i=1
div(k −i) + K
(8.12)
but other structures were tested as well, typically ﬁrst- and third-order and
less time delay.
2. The control quality was evaluated by the criterion
Ψ =
k+T

i=k+1
[fy(w(i) −y(i))2 + fu(u(i) −u0(i))2].
(8.13)
This penalizes the control error between the actual and desired output and
the diﬀerence between the actual input and some reference u0. The introduc-
tion of this reference is a novelty and was discussed in Chapter 6; fy and fu
denote for the data-dependent penalty. This form of criterion widens substan-
tially the possibilities of controller tuning and reﬂects the practical situation
when quite often a function of the input or output is required to fulﬁl a given
speciﬁcation.
3. The minimization of criterion (8.13) based on model (8.12) is based on dy-
namic programming in state space. The nonminimum dimension state space
is used here, using delayed measured data as elements of the state space. This
choice increases only moderately the computational burden of the square root
minimization algorithm, simplifying the interpretation of results considerably.
4. A reliable square root algorithm for minimization of the criterion (see Sec-
tion 6.7) allows simple implementation of the various types of penalization
considered in the criterion.
5. The IST (iteration spread in time) (see Section 6.3.2) strategy ensures the
adaptive version of the approach is suﬃciently fast.
6. To be able to cope with typical signal constraints the controller algorithm
enables automatic penalization adjustment based on constraints of the input
signal and its moves [119].
7. The introduction of input reference signal u0 is used to smooth the transi-
tion from the existing PID controller to the adaptive LQ controller.
8. A standard on-line LS algorithm with exponential forgetting was used for
system parameter identiﬁcation.
8.2.3 Programming Aspects
All the features listed above have been implemented into Matlab R
⃝and
Simulink R
⃝functions. Basic Simulink R
⃝schemes used for the direct con-

284
8 Application of Self-tuning Controllers
trol of the plant are shown in Figure 8.1 and Figure 8.2. The ﬁrst one realizes
the positional control, the second one adds an integrator to the loop.
LQ−syn
synthesis
yout
To Workspace2
uout
To Workspace1
cl
To Workspace
u.mat
To File2
y.mat
To File1
par.mat
To File
Switch
Sum3
Sum2
Subsystem
Saturation
CTRLe 
 adaptive
S−function2
ident.
S−function
PCL812 PG
signal u0 from
PI controller
Mux
Mux4_
Mux
Mux4
Mux
Mux3
Mux
Mux1
Mux
Mux
Graph1
Graph
−K−
Gain4
z  +2z+1
2
z  −1.81z+.819
2
Discrete
Transfer Fcn2
ss(z)
rr(z)
Discrete
Transfer Fcn1
D/A − A/D converter
To and ftom the plant
5.5
Constant2
sw
Constant
Figure 8.13. Control of the plant with incremental LQ adaptive controller
Two types of controller with special properties and automatic adjustment
of the criterion were prepared and tested. First, was a controller which oper-
ates only in cases when the disturbance exceeds a given level. Such a controller
can be called “cheap” as it does very little, more precisely, it keeps the input
at a level u0. A scheme representing a “cheap” controller in which penalization
of the output depends on the predicted control error is schown in Figure 8.14.
The output of the block is system input u(t), the input points in 1
to in 6
are places where the following signals enter
in 1
– system input u(t),
in 2
– system output y(t),
in 3
– set point w(t),
in 4
– output level where the output starts to be penalized,
in 5
– minimum penalization (when no additional penalization is used),
in 6
– the pair of [u(t), y(t)] for parameter estimation.
Another example of a controller with data-dependent penalizations, in
which the input penalization depends on the level of the input itself and in
such a way that it suppress large input values, was prepared. Figure 8.15 shows
the block diagram of the arrangement for data-dependent input penalization
adjustment. Here the inputs points of the block are:
in 1
– system input u(t),
in 2
– system output y(t),
in 3
– setpoint w(t),
in 4
– reference input u0(t),
in 5
– minimum penalization (when no additional penalization is used)
in 6
– the pair of [u(t), y(t)] for parameter estimation.

8.2 Application of the Adaptive LQ Controller to a Heat Exchanger Station
285
2
out_2
1
out_1
LQ−syn
synthesis1
cl
To Workspace1
par.mat
To File4
Sum7
Sum6
CTRLe 
 adaptive
S−function3
ident.
S−function1
INTEGR1
S−Function3
INTEGR2
S−Function2
>=
Relational
Operator1
Product1
Mux
Mux6
Mux
Mux5
Mux
Mux4_1
Graph
−K−
Gain6
1
Gain5
Demux
Demux3
Demux
Demux2
.02
Constant6
|u|
Abs1
6
in_6
5
in_5
4
in_4
3
in_3
2
in_2
1
in_1
Figure 8.14. Adaptive LQ controller with output penalization depending on the
output prediction – “cheap” controller
1
out_1
LQ−syn
synthesis1
Sum7
Sum6
Saturation1
CTRLe 
 adaptive
S−function3
ident.
S−function1
Product1
Mux
Mux6
Mux
Mux5
Mux
Mux4_1
Graph3
.8 
1−.2z −1
Filter1
Demux
Demux2
|u|
Abs2
6
in_6
5
in_5
4
in_4
3
in_3
2
in_2
1
in_1
Figure 8.15. Adaptive LQ controller with input penalization depending on con-
straints
As the setting of penalizations are in both cases totally independent they
can be simply implemented together.
Figure 8.16 shows the way of using the reference input signal. The signal
can be either set to some value, or it can be linked to the output of the original
controller.
8.2.4 Experimental Results
Experiments were carried out in three periods of the year representing diﬀerent
operating conditions of the technology.
The aim was to test:
•
behaviour of the LQ controller, i.e.

286
8 Application of Self-tuning Controllers
uout
To Workspace1
yout
To Workspace
Switch
Sum3
Sum2
Signal
generator
Scope1
Scope
Mux
Mux1
Mux
Mux
.2
Gain4
S(z)
R(z)
Discrete Filter
.02
z  −1.81z+.819
2
Discrete
Transfer Fcn2
num(z)
z  −1.81z+.819
2
Discrete
Transfer Fcn
LQ 
  Adaptive 
  Controller
Controller
1
Constant
Band−Limited
White Noise
Figure 8.16. The use of adaptive and ﬁxed default controllers together
–
how the input penalization inﬂuences the behaviour
–
the inﬂuence of the structure of the model (controller)
–
the possibilities of more sophisticated penalizations;
•
adaptation process;
•
startup of the adaptation;
•
ways to ensure smoothness of the transition from standard control to LQ
and back.
The ﬁrst experiments were carried out in the summer period. The primary
water temperature was low (70oC) and hot water consumption was rare. To
see the controller action artiﬁcial disturbances were created by opening a hot
water tap for approximately one minute. Several experiments were run on the
heat exchanger: diﬀerent models, sampling and penalization were tested in
these cases. Using prior information about the plant a second-order regression
model with two time delay steps for the sampling period T0 = 10 s was used
initially. A few experiments showed that this model was satisfactory, and that
a reasonable penalization was within the interval Qu = (0.1 −1). In all the
following ﬁgures the dotted lines indicate reference values, i.e. the set point for
the output and the reference input for the input. In most cases this reference
input is an output of the standard controller.
Figure 8.17 shows the situation when the adaptive controller starts in a
smooth way from the standard PID controller of the plant. The dropouts in
the input variable were caused by stopping the simulation to change penaliza-
tion Qu. Then the simulation started with zero initial conditions. The output
variations were caused by a disturbance. This can be deduced from the fact
that both the PID and adaptive controllers tend to change input value at

8.2 Application of the Adaptive LQ Controller to a Heat Exchanger Station
287
time                        [ No of samples]
temperature      [x10 °C]
0
50
100
150
200
250
300
350
400
450
4.9
5
5.1
5.2
5.3
5.4
5.5
5.6
5.7
5.8
time                        [ No of samples]
input     [x10 %]
0
50
100
150
200
250
300
350
400
450
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
8.17a. Output and setpoint
8.17b. Input
Figure 8.17. Experiment No 1
the same direction. When dropouts occurred the PID controller moved in the
opposite direction.
time                        [ No of samples]
temperature      [x10 °C]
0
50
100
150
200
250
300
350
5.1
5.2
5.3
5.4
5.5
5.6
5.7
5.8
5.9
6
time                        [ No of samples]
input     [x10 %]
0
50
100
150
200
250
300
350
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
8.18a. Output and setpoint
8.18b. Input
Figure 8.18. Experiment No 8
Figure 8.18 documents again the nice startup given by smooth tuning from
the standard PID controller to the full LQ controller.
Table 8.2 shows the identiﬁed roots of the numerator and denominator in
various experiments. The second part of the table contains the results from
the second period ( only one part of a complex pair is shown).
More interesting results were obtained from the third, winter, period. Ex-
periment No 13 used a shorter sampling period. The standard structure was

288
8 Application of Self-tuning Controllers
Table 8.2. Roots αi of denominator and βi of numerator of identiﬁed model
Exp. No α1
α2
β1
β2
β3
β4
1
0.9953 0.3163 0.60-0.53i
0.60-0.53i
2
1.1004
1.17
0.12+0.79i -0.64
4
0.9960 0.4809 -6.25
1.40
0.57+1.10i
7
0.9968 0.2723 -8.58
1.11
-0.57+0.38i
8
0.9854 0.7607 1.17+0.52i 0.57+0.75i 0.41+0.80i -0.46
9
1.0226 0.7924 1.81
1.40
37+1.04i
-0.45+0.69i
10
0.9821 0.7651 1.94+0.49i -0.11+0.36i
used but with sampling T0 = 5 s. The input and output are shown in Fig-
ure 8.19, and the identiﬁed roots of the numerator and denominator in Fig-
ure 8.20.
time                        [ No of samples]
temperature      [x10 °C]
50
100
150
200
250
5
5.1
5.2
5.3
5.4
5.5
5.6
5.7
5.8
5.9
6
time                        [ No of samples]
input     [x10 %]
50
100
150
200
250
0
0.5
1
1.5
2
2.5
3
3.5
4
8.19a. Output and setpoint
8.19b. Input
Figure 8.19. Experiment No 13
Experiment No 14 lasted more than 2 hours and contained the lunch time
rush hour. The temperature control is very good (Figure 8.21).
Figure 8.22 documents a very quiet startup from zero initial conditions.
Experiment No 18 was carried out with the scheme shown in Figure 8.14.
The details of the input and corresponding data-dependent penalization are
shown in Figure 8.24.

8.2 Application of the Adaptive LQ Controller to a Heat Exchanger Station
289
time                        [ No of samples]
abs(roots(B(z)))
0
50
100
150
200
250
0
1
2
3
4
5
6
7
8
9
0
50
100
150
200
250
0
0.2
0.4
0.6
0.8
1
1.2
1.4
8.20a. Roots of the numerator
8.20b. Roots of the denominator
Figure 8.20. Experiment No 13.
time                        [ No of samples]
temperature      [x10 °C]
200
400
600
800
1000
1200
1400
5
5.1
5.2
5.3
5.4
5.5
5.6
5.7
5.8
5.9
6
time                        [ No of samples]
input     [x10 %]
0
500
1000
1500
0
1
2
3
4
5
6
7
8.21a. Output and setpoint
8.21b. Input
Figure 8.21. Experiment No 14
8.2.5 Conclusions
Experiments with LQ controllers in the temperature loop of a heat exchanger
were performed in three periods with diﬀerent loads and disturbances. In all
cases the adaptive LQ control was successful and the input penalization Qu
was suﬃcient to tune the behaviour of the controller from “smooth”, when
the quality is similar to a PID controller, to “restless”, however, achieving
better quality. The identiﬁcation results conﬁrmed the second-order model
structure with time delay. The choice of time delay was not crucial. The
examples with rare disturbances show how the parameters tend to a ﬁrst-
order structure and disturbance moves them back to second-order. A diﬀerence
in denominator of the model transfer function obtained in diﬀerent periods
can be seen. In all cases the resulting model was nonminimum phase, which

290
8 Application of Self-tuning Controllers
time                        [ No of samples]
input     [x10 %]
5
10
15
20
25
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
time                        [ No of samples]
prediction error        [10°C]
200
400
600
800
1000
1200
1400
−0.1
−0.08
−0.06
−0.04
−0.02
0
0.02
0.04
0.06
0.08
0.1
8.22a. Input at the startup
8.22b. Prediction error
Figure 8.22. Experiment No 14
time                        [ No of samples]
abs(roots(B(z)))
200
400
600
800
1000
1200
1400
0
0.5
1
1.5
2
2.5
3
time                        [ No of samples]
abs(root(A(z)))
0
500
1000
1500
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
8.23a. Roots of the numerator
8.23b. Roots of the denominator
Figure 8.23. Experiment No 14
explains the discrepancy between prediction errors of the model shown and
the resulting controller behaviour. The experiments have shown that for a
given purpose a simple PID (in fact, practically, only P) controller is fully
satisfactory for the desired quality. On the other hand, these experiments
veriﬁed that the application of an adaptive controller could also be simple
and safe. The quality of control obtained was not much better due to existing
delays and nonminimum phase behaviour, but it could be expected that if the
disturbances could be measured, the control performance could be improved.

8.3 Boiler Control With Multivariable Linear Quadratic Controllers
291
time                        [ No of samples]
temperature      [x10 °C]
100
200
300
400
500
600
700
5
5.1
5.2
5.3
5.4
5.5
5.6
5.7
5.8
5.9
6
time                        [ No of samples]
input     [x10 %]
100
200
300
400
500
600
700
0
1
2
3
4
5
6
8.24a. Output and setpoint
8.24b. Input
Figure 8.24. Experiment No 18
time                        [ No of samples]
input     [x10 %]
300
310
320
330
340
350
360
370
380
390
400
0
1
2
3
4
5
6
time                        [ No of samples]
output penalty
300
310
320
330
340
350
360
370
380
390
400
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
8.25a. Input detail
8.25b. Corresponding penalization of output
Figure 8.25. Experiment No 18
8.3 Boiler Control With Multivariable Linear Quadratic
Controllers
Control loops of the outlet steam pressure and outlet superheated steam tem-
perature are usually the most important loops in steam boilers. Their dynam-
ics vary with steam ﬂow (load) and working conditions and depend also on
acting disturbances. Adaptive LQ controllers were applied to control simulta-
neously outlet steam pressure and two outlet superheated steam temperatures.
8.3.1 The Technology
In the power plant of a metallurgical factory, two fossil-fuel-ﬁred drum boilers
(with the same parameters: 120 ton/h, 9.5 MPa = 95 bar, 540oC) deliver steam

292
8 Application of Self-tuning Controllers
into a common collector. The steam is conducted into a 25 MW back-pressure
turbine and to various metallurgical shops to be used for production purposes.
The steam boiler has two branches of superheaters. The steam temperatures
behind the last superheaters of both branches are controlled by injected wa-
ter ﬂow through spray valves before the superheaters. The steam temperature
is inﬂuenced by steam pressure, variable load, and fuel changes and by the
injected water in the valves. This suggests strong interaction between both
branches. Changing the speed of powdered coal feeders controls steam pres-
sure. According to the load, the number of coal feeders used varies from 4 to
8. The powdered coal intake is measured only indirectly by the positions of
actuators on the speed changing units and depends also on the state of the
coal bunkers. The quality of coal and its caloriﬁc value varies too. Therefore
the dependence of coal intake on feeder speed is time variable. The combus-
tion air intake is controlled by turning the control rims of two fans. Adaptive
control of the combustion airﬂow is desirable because the coal intake and
quality varies for the same load (steam ﬂow). The common steam collector
means that control of the steam pressure in one boiler is strictly inﬂuenced
by conditions in the other boiler, by the momentary condition of the combus-
tion process, and by changes of load. The normal load of each boiler is about
100–110 ton/h.
An adaptive LQ controller (LQ Self-tuning Controller, LQ STC) was ex-
perimentally applied as a multi-variable (MIMO, multi-input, multi-output )
STC to control simultaneously the following loops of the drum boiler plant
[129]:
(A) outlet steam temperature on the left branch of the ﬁnal superheater;
(B) outlet steam temperature on the right branch of the ﬁnal superheater;
(C) outlet steam pressure with an additional adaptive control loop for the
combustion air (a special algorithm was designed for combustion air control).
8.3.2 Programming Aspects
The LQ STC was programmed as a module composed of several subroutines
called by up to four independent programs. Therefore it was possible to use
simultaneously up to four LQ STC in a MIMO version. Such a solution enabled
the use of one or more LQ STC programs to check proper model structure,
control synthesis etc. and others directly for control. A multivariable regression
model of N th-order with n process inputs u(k) and n process outputs yc(k) and
with r measured external disturbances v(k) was programmed; these external
disturbances were part of an (n+r)-dimensional extended vector output y(k).
All measured values were related to reference values. Constant values (equal
set point) were used as reference values for process outputs. Constant values
or the preceding measured values could be taken as reference values for inputs,
that is “incremental” inputs were considered as increments of measured values.
Zero initial parameter values were used except the value of parameter B0.

8.3 Boiler Control With Multivariable Linear Quadratic Controllers
293
Exponential forgetting was applied for identiﬁcation. The sum of squares of
the prediction error was calculated and used in model comparison.
Controller algorithm
Estimated parameters Θ(k) or also their covariance matrix C(k), i.e. un-
certainty of parameters (in so-called cautious control) were used for control
synthesis. The use of uncertainty of parameters C(k) leads to an additional
control penalisation varying according to C(k).
A mMoving horizon strat-
egy MH was used with only ﬁnal state penalisation, as well as an iteration
spread in time strategy IST; see Section 6.3.2. The horizon (number of Riccati
equation iterations) was chosen according to convergence of the control law
|Cl(i + 1) −Cl(i)| < eps ∗|Cl(i + 1) + Cl(i)|
where eps is a chosen constant. Additionally, maximum number of iterations
(steps) M was allowed.
Calculated controller output u(k) was limited; the upper and lower limits
varied (with an exponential rate, from initial values equal to the reference
value at start time) up to their maximum values. In this way an initial bump
at the start of STC was eﬃciently excluded.
8.3.3 Connection of the Adaptive Controller into the Existing
Control Loop
The adaptive controller calculated the manipulated variables u(k) as the de-
sired value (set point) for the inner loops of the actuators. These actuators
were controlled in a servo-loop by digital P regulators using pulse width mod-
ulation in the case of computer control. The sampling periods of both inner
and outer loops were the same, 20 s. The vector of inputs u(k) to the system
(i.e. manipulated variables) consists of:
•
the temperature behind the spray valve for steam temperature control;
•
the position of one coal feeder actuator for steam pressure control.
The remaining feeders were set to the same desired value. The desired
values for both air fans were calculated according to the desired value of coal
feeders with the adaptively varying relation between air and coal (this relation
was based on the estimated parameters of the steam pressure model applied
by LQ STC).
Note: Input Deﬁnition and Connection
As the input is usually provided by an actuator in the inner loop, it is possible
to choose the system model input u(k) as
(A)the desired value of manipulated variables calculated by LQ STC (set
point for the inner loop with the actuator), where the inner loop dynamic
including actuator becomes part of the whole identiﬁed system; or

294
8 Application of Self-tuning Controllers
(B)the measured value of manipulated variables (controlled variable of the
inner loop), where only ‘own system’ is identiﬁed on the basis of the true
acting manipulated variable, and the inner loop dynamic is not considered
part of the identiﬁed system.
In this application only case (B) was used. The pros and cons of the two
variants are discussed in [64].
8.3.4 Control Results
The existing analogue control of the control loops did not work well under
changing process conditions and therefore these loops were usually controlled
manually on both boilers. The failures of coal intake, the interaction of both
boilers and rapid changes in outlet steam ﬂow generallyled to load changes on
the boiler of about 20 ton/h, but changes up to 50 ton/h also occurred.
As there was no previous knowledge of the controlled system and no pre-
vious identiﬁcation results then all “structural parameters” of the LQ STC
(model order N, the choice of external measured disturbances, control strat-
egy, the type of variable – increments or not, exponential forgetting value,
etc.) had to be determined directly on the plant. The predicted error per-
formance was used as the criterion for model structure comparisons and the
control error quadratic criterion for the control strategy. Models with various
structural parameters were identiﬁed at the same time and compared under
the conditions of running LQ STC. No artiﬁcial signals were used, only the
real control action of LQ STC. (Four LQ STC programs could be used si-
multaneously.) Results of such tests led to the use of adaptive controllers LQ
STC always realized with measured disturbance v(k) and with moving horizon
strategy only.
The steam temperatures of both branches were controlled alternatively by
•
two independent single-input single-output (SISO) controllers with mea-
surable external disturbance included in the extended output y(k),
•
one multi-input multi-output (MIMO) controller with two-dimensional in-
put and controlled output yc(k) and with two measurable external distur-
bances included in the extended output.
Steam pressure or steam ﬂow and air fan position were used as measurable
external disturbances. The control results with the MIMO temperature con-
troller were better than with the two SISO controllers. The temperature be-
hind the superheaters was controlled over a smaller range with less control
eﬀort. The MIMO controller with regression model of order N = 3 and two
measurable external disturbances led to the estimation of 80 parameters. In-
puts u(k) use constant reference values. A moving horizon strategy was used
and the uncertainty of parameters incorporated. A cautious control strategy
led to better results than the strategy based on certainty equivalence (smaller
range of control errors and overshoots). Therefore the temperature set points
were increased.

8.3 Boiler Control With Multivariable Linear Quadratic Controllers
295
The steam pressure was controlled by a SISO controller together with
combustion air intake. The model order was N = 3 with two measured dis-
turbances (steam ﬂow and air fan position): 39 parameters were estimated.
Again the moving horizon strategy was used. The use of a model with incre-
mental inputs improved steam pressure control performance. The STC had
higher and faster adaptability to various nonlinear and nonstationary process
changes including fast load changes and a jump change in the number of feed-
ers in operation. The signiﬁcantly lower range of control errors and smaller
overshoots in the case of larger process and load changes enabled the steam
pressure set point to be increased from the usual 93 bars to 95 bars. Improved
boiler control, including improved combustion control, favourably aﬀected the
operation of both boilers and the turbine power. This led plant operators to
use adaptive controllers as standard controllers.
The convergence of the Riccati matrix was fast. The number of steps M =
5 for steam pressure control or M = 3 for MIMO temperature control provided
suﬃcient horizon for the criterion. The sampling period T0 = 20 s was used in
all control loops.
Figure 8.26. Drum boiler control with LQ STC and manual operations. (A) Two-
variable control of steam temperature loops with MIMO LQ STC. (B) steam pressure
control including combustion optimization with SIMO LQ STC. (C) Failure in the
measurement of steam ﬂow, i.e. boiler output (external variable of LQ STC)
Typical control responses with and without a LQ STC to control all three
loops by two LQ STCs are documented by plant plotter records shown in Fig-
ures 8.26 and 8.27. The boiler steam ﬂow (load) and the steam temperatures

296
8 Application of Self-tuning Controllers
Figure 8.27. Drum boiler control: LQ STC and manual operations
are recorded, together with variables measured on the turbine: the amount
of steam led into the plant (labelled steam extraction), the turbine power
and admission steam pressure. The second boiler delivers steam into the same
common collector and therefore admission steam pressure shows pressure of
steam blended from both boilers. Start of LQ STC from zero initial parame-
ter values (except parameter B0) was bumpless (see Figure 8.28); no troubles
occurred at the start due to applied variable output limits and relatively large
forgetting of data (value frg = 0.97 to 0.98) enabling fast identiﬁcation of
model parameters from their initial zero values. LQ STC also started directly
from last parameter values, mainly when turned on by plant operators.
Figure 8.28. Start of LQ STC. Start from zero initial parameter values except
parameter B0

8.4 Adaptive Linear Quadratic Controller in Cascade Control
297
A failure in the measurement of one of the measured disturbances (boiler
steam ﬂow), which occurred several times, produced no signiﬁcant deteri-
oration of steam pressure control. Covariance wind-up did not take place,
probably due to the nonstationarity of process model parameters, the ap-
plied multistep control criterion, and permanent process changes. Later the
applied regression models were compared with ARMAX models on an exter-
nal computer. Identiﬁcation from data ﬁles obtained under a standard control
strategy led to almost the same values of performance criterion for both types
of model.
This application was one of the ﬁrst MIMO STC applications and helped
with other later applications.
8.4 Adaptive Linear Quadratic Controller in Cascade
Control
Control of superheated steam temperature in a cascade control loop using an
adaptive LQ controller in the power plant was described in [134].
8.4.1 The Technology and Controlled Loops
Long-term experiments were done on a fossil-fuel-ﬁred once-through boiler of
200 MW (660 t/h, 540oC) power plant to control superheated steam temper-
atures. This boiler has superheated system divided into two branches (A and
B), each branch consisting of three superheaters (PI, PII and PIII). Outlet
superheated steam temperatures from both ﬁnal superheaters PIII (labelled
T20A and T20B) are mixed and fed into a turbine. The steam temperature be-
hind each superheater is controlled in a cascade control loop. The superheater
is a system directly inﬂuenced by changes of inlet steam ﬂow and tempera-
ture, sprayed water and heat ﬂow. The approximate time constant of such
a system varies signiﬁcantly with load. Therefore conventional PI controllers
are not always suitable to control steam temperature under varying conditions
and in the presence of large process changes and failures which result in large
temperature overshoots. The adaptive control was veriﬁed on the right branch
“B” only. This branch “B” had worse dynamics than branch “A”. The left
branch “A” remained controlled via standard PID analogue control to com-
pare control results [134]. Two diﬀerent control concepts were applied. In the
ﬁrst, the main analogue PI controller of the cascade control loop was replaced
by the LQ STC. In the second concept the LQ STC was connected and added
into the control of the two ﬁnal superheaters and calculated a set point for
the main analogue PI controller. The following applications of the LQ STC
were proved:
(A)The control of steam temperature behind the superheater PII
Superheated steam temperature behind the superheater is controlled in the

298
8 Application of Self-tuning Controllers
following manner (Figure 8.29). The main (master) analogue PI controller
R1 of the cascade control loop calculates set point T16A, T16B, of the
steam temperature behind the spray valve (i.e. the steam temperature
before the superheater T16AZ, T16BZ) for the small (slave) loop with
analogue PI controller (R2). The controller R2 sets a signal for the servo
loop of the actuator which operates the spray valve. The main controller R1
in the cascade control loop of the second superheater (PII) was replaced
by the LQ STC. The small loop and servo loop remained controlled by
analogue controllers. The set point of the main controller R1 (T18AZ,
T18BZ) is constant as usual.
Figure 8.29. Diagram of superheated steam temperature control behind the su-
perheater PII
(B)The control of steam temperature of the ﬁnal two superheaters
The STC was connected into the control loop of two ﬁnal superheaters
(PII and PIII). The LQ STC calculated the set point T18BZ for the second
superheater PII on the basis of the control error of the ﬁnal superheater
(PIII). The whole analogue cascade control for PII and PIII remained in
operation (Figure 8.30). However, now the superheater PII was controlled
to the variable set point T18BZ to keep the controlled variable, i.e. the
steam temperature T20B behind the PIII.
8.4.2 Programming Aspects
LQ STC was programmed as a MIMO controller with measured external
disturbances similarly to the previous application. The controller algorithm
incorporated new theoretical results. Not only ﬁnal state penalization but
direct input penalization or input diﬀerences (increments) penalization were
used. Conditional interruption of identiﬁcation was applied in the case of small
or very large prediction errors ep(k). If

8.4 Adaptive Linear Quadratic Controller in Cascade Control
299
Figure 8.30. Diagram of adaptive control of steam temperature of the ﬁnal two
superheaters
ep(k)2 < K1R(k) or ep(k)2 > K2R(k)
where K1 ∼0.25, K2 ∼2.0 and R(k) denotes the estimate of the covariance
matrix, then calculations of the estimates of parameters θ(k) or θ(k) and R(k)
were skipped.
8.4.3 Control Results
No identiﬁcations were made before the experiment and reasonable structural
parameters had been chosen directly during tests – similarly to a previous
application; the prediction error performance and parameter variances (i.e.
uncertainty of parameters) and the quadratic criterion of control errors were
compared.
(A) Control of steam temperature behind superheater PII.
The manipulated variable was in this case steam temperature behind the spray
valve controlled by R2 – see Figure 8.29. The control experiments started with
a SISO controller with model order N = 3. External measured variables were
not used here – no suﬃciently important permanent relations were found.
(The inﬂuence of external variables on model prediction depends also on the
sampling period, usually decreasing with increased period; a rather long pe-
riod was used in this application.) The IST strategy with cautious variant and
penalization of input diﬀerences was used for most experiments. The horizon
M = 3 was used even with the IST strategy to respect possible changes in
parameters. Exponential forgetting with conditional interruption of identiﬁ-
cation was used. Sampling period T0 was set to eliminate the dynamics of

300
8 Application of Self-tuning Controllers
the small analogue control loop and was taken in the range of 25 s to 50 s,
without signiﬁcant diﬀerences in control performance. The penalization of in-
put diﬀerences was suitable for changing operation conditions. The LQ STC
calculated the set point for the analogue slave control loop controlling the
steam temperature behind the spray valve. Both types of model input u(k)
deﬁnition were tested, i.e. desired or measured value of manipulated variables
were deﬁned like u(k) (see Note: Input deﬁnition in Section 8.3, case (A) and
(B)). The control results were comparable. As the use of the measured manip-
ulated variable seemed better from the point of view of prediction error and
also avoided potential wind up in the case when the actuator’s position is lim-
ited, the measured manipulated variable was mainly used as the input u(k).
Tests with an incremental model led to prediction and control error increases
and therefore a such model was not applied. Typical control responses with
and without LQ STC are documented as plant plotter records and shown in
Figure 8.31 and Figure 8.32.
Figure 8.31. Steam temperature control of superheater PII. Branch B (temperature
T18B) is controlled with analog control or LQ STC: model order N = 3, number of
steps M = 3, T0 = 50 s
Controlled steam temperatures behind the superheater T18B, and steam
temperature behind the spray T16B, (i.e. manipulated variable for main con-

8.4 Adaptive Linear Quadratic Controller in Cascade Control
301
Figure 8.32. Steam temperature control of superheater PII. Failure of coal supply.
Branch B (temperature T18B) is controlled using analogue control or LQ STC. LQ
STC : model order N = 3, number of steps M = 3, change of sampling period T0
from 40 to 50 s
troller) are shown, together with temperatures of branch “A” controlled only
with standard analogue PID controllers. In Figure 8.32 the sampling period
of LQ STC was switched from 40 to 50 s ; then a failure of the coal supply (of
coal mill) caused oscillations, however, control errors were in a similar range
for the usually better controlled branch A and for branch B controlled by LQ
STC – in spite of the very long sampling period T0 = 50 s of LQ STC.

302
8 Application of Self-tuning Controllers
A comparison of analogue and LQ STC control gives the following results:
The application of LQ STC led to a signiﬁcant decrease of changes in the
manipulated variable (steam temperature behind the spray valve) with lower
overshoots in the controlled variable and a decrease of the controlled and ma-
nipulated variable frequencies, resulting in an important heat stress decrease.
The frequency of changes of the manipulated variable and their magnitude
were decreased by approximately three times. At the same time, the range of
control error remained approximately the same as for analogue control.
(B) Control of steam temperature of ﬁnal two superheaters.
The manipulated variable was, in this case, steam temperature behind PII.
The same structure of SISO LQ STC was used with sampling period 60 s. The
input u(k) was deﬁned as the desired value of manipulated variable, i.e. the
set point of the steam temperature behind PII. In this case the model used
included the dynamics of the system PIII and PII with all inner analogue
control loops. Application of the adaptive controller (Figure 8.31) resulted
in a decrease of the overshoots in the temperature behind the PIII during
the usual operating failures and in smoothing the spray valve control. From
the comparison between steam temperature control on PIII of both branches
(see T20B and T20A in Figure 8.33) it can be seen that with analogue con-
trol, overshoots of the right branch “B” are substantially larger than those
on branch “A” in the case of sudden failures. The LQ STC on branch “B”
signiﬁcantly reduced the control deviation and overshoots, even in comparison
with the usually better branch “A”.
Figure 8.33 (from plant plotter records) shows responses of controlled
steam temperatures behind the superheater PIII (T20A, T20B), temperature
behind the evaporator TVYP, steam ﬂow M4 and electric power NEL.
Conclusions
LQ STC improved control compared with the existing controllers. The second
application in which another controller (here the LQ STC) was connected into
the control loops of two superheators was unusual and not previously tested.
One adaptive controller plus 2*3 =6 analogue control loops with their dynam-
ics and nonlinearities were involved. LQ STC was applied without any previ-
ous identiﬁcation. Only about 3 hours were required to choose a proper LQ
STC model structure and Qu penalisation for both applications. The burst-
ing eﬀect (covariance wind up) does not take place, mainly due to excitation
of the system by disturbances and also due to above mentioned conditional
interruption of identiﬁcation. About 20 to 30 % of data were not taken into
the identiﬁcation after the test on the small prediction error (for K1 = 0.25).
Satisfactory and eﬃcient control was achieved with LQ STC also in the case
of fast process changes and failures – in spite of longer sampling times (up to
50 or 60 s). Such long sampling times, impossible with digital PID controllers,

8.5 Steam Pressure Control of Drum Boiler in Power Plant
303
Figure 8.33. Steam temperature adaptive control of the ﬁnal two superheaters PII
and PIII. Branch B (temperature T20B) is controlled using analogue control or LQ
STC: model order N = 4, number of steps M = 3, T0 = 60 s
were surprising to plant control engineers. This application pointed out also
potential problems caused by the danger of wind-up eﬀect in cascade control
loops. Possible solutions are described in [64] and [65].
8.5 Steam Pressure Control of Drum Boiler in Power
Plant
This application was similar to the application described in Section 8.3 but
here analogue controllers ran, however, not fully successfully under large
changes and process failures, this bring the reason why LQ STC was applied.

304
8 Application of Self-tuning Controllers
8.5.1 The Technology and Controlled Loops
The LQ STC was applied for steam pressure control with additional adap-
tive control of the combustion air on a coal-fuel-ﬁred drum boiler 220 t/h,
delivering steam with three other similar boilers into a common collector in
a power plant. On the boiler there are 11 coal feeders; the number of coal
feeders used varies from 5 up to 11, according to load. The combustion air
intake is controlled by turning the control rims of two fans. The powdered
coal intake is measured only indirectly by the positions of actuators on the
speed changing units and depends also on the state of the coal bunkers and
the quality of milled coal, the caloriﬁc value of which varies. Therefore the
dependence of coal intake on feeder speed is time variable. The quality of the
combustion process depends not only on the number of feeders used but also
on their choice.
8.5.2 Programming Aspects
LQ STC was programmed as a MIMO controller with measured external
disturbances similarly to both previous applications. Penalization of input or
input increments could be used. Not only a constant value of penalization Qu
but also a variable value was applied. This value changed if the input (i.e.
manipulated variable) reached its limits [119] and also according to the input
variance (to automate tuning under conditions of output variance) – see [135].
Additional adaptive control of the combustion air, which was always used
with LQ STC of steam pressure, was based on the estimated parameters of
the process model created by this LQ STC.
8.5.3 Control Results
A SISO controller with two measurable disturbances and with IST strategy
and penalization of input increments was used. The multi-step criterion with
M = 3 was used as standard. However to demonstrate the diﬀerence between
multi-step and single-step criterion, the following experiment was made. See
Figure 8.34, where the inﬂuence of diﬀerent values Qu and applied control
strategies are recorded; in Figure 8.34 variable y denotes controlled steam
pressure, u manipulated variable (speed of coal feeders limited in the range
umin, umax) and v steam ﬂow used as the measured disturbance. The multi-
step IST strategy was signiﬁcantly better; the simple single-step criterion was
unsatisfactory (manipulated variable was often limited and remained on its
stops, controlled variable oscillated wildly, system was not correctly excited
and parameter estimates and prediction error performance were wrong).
The variable input penalization used here improved control behaviour,
avoided wind-up when the actuator was limited and removed tuning of Qu.
To eliminate the wind-up eﬀect the corrector described in Section 4.5.2, Equa-
tion (4.86) and in [64, 65], was applied – together with variable penalization

8.5 Steam Pressure Control of Drum Boiler in Power Plant
305
Figure 8.34. Steam pressure control of drum boiler 220 t/h. Comparison of single
step v. multistep cost function. Change of penalization: a/ Qu = 0.0008, b/ Qu =
0.008, c/ Qu = 0.004, d/ T0 : 40 s →30s, y denotes controlled steam pressure, u
speed of coal feeders (manipulated variable), and v steam ﬂow used as measured
disturbance
increase if the actuator limited – see [119]. Again, the application of LQ STC
improved control especially under large and fast changes and process failures
(of coal mill etc.), which the use of PID controllers was not able to cope with.

References
1. R. Bellman, Adaptive Control - A Guided Tour. Princeton University Press,
1961.
2. Y. Z. Tsypkin, Adaptation and Learning in Automatic Systems. New York:
Academic Press, 1971.
3. K. J. ˚Astr¨om, “Theory and applications of adaptive control,” Automatica,
vol. 19, no. 5, pp. 471–486, 1983.
4. G. C. Goodwin and K. S. Sinn, Adaptive Filtering, Prediction and Control.
Englewood Cliﬀs, New Jersey: Prentice Hall, 1984.
5. K. J. ˚Astr¨om and B. Wittenmark, Adaptive Control. Reading, Massachusetts:
Addison-Wesley Publishing Company, 1989.
6. P. Wellstead and M. Zarrop, Self-tuning Systems. Chichester: John Wiley &
Sons, 1991.
7. N. M. Filatov and H. Unbehauen, Adaptive Dual Control: Theory and Appli-
cations. Berlin Heidelberg New York: Springer-Verlag, 2004.
8. J. Marˇs´ık and V. Strejc, “Application of identiﬁcation-free algorithms for adap-
tive control,” Automatica, vol. 25, pp. 225–228, 1989.
9. K. J. ˚Astr¨om and T. H¨agglund, Automatic Tuning of PID Controllers. Re-
search Triangle Park, North Carolina: Instrument Society of America, 1988.
10. K. J. ˚Astr¨om and T. H¨agglund, “Automatic tuning of simple regulators with
speciﬁcations on phase and amplitude margins,” Automatica, vol. 20, pp. 645–
651, 1984.
11. K. J. ˚Astr¨om and T. H¨agglund, PID Controllers: Theory, Design and Tuning.
Research Triangle Park, North Carolina: Instrument Society of America, 1995.
2nd Edition.
12. T. W. Kraus and T. J. Myron, “Self-tuning PID controller uses pattern recog-
nition approach,” Control Engineering, vol. June, pp. 106–111, 1984.
13. Y. Nishikawa, N. Sannomia, T. Ohta, and H. Tanaka, “A method for auto-
tuning of PID control parameters,” Automatica, vol. 20, pp. 321–332, 1984.
14. K. J. ˚Astr¨om, C. C. Hang, P. Persson, and W. K. Ho, “Towards intelligent PID
control,” Automatica, vol. 28, pp. 1–9, 1992.
15. W. K. Ho, C. C. Hang, and L. S. Cao, “Tuning of PID contollers based on gain
and phase margin speciﬁcations,” Automatica, vol. 31, pp. 497–502, 1995.
16. I. D. Landau, Adaptive Control – the Model Reference Approach. New York:
Marcel Dekker, 1979.

308
References
17. P. A. Ioannou, Robust Adaptive Control. Englewood Cliﬀs, New Jersey: Pren-
tice Hall, 1996.
18. A. Feldbaum, “Theory of dual control,” Autom. Remote Control, vol. 21, no. 9,
1960.
19. R. E. Kalman, “Design of a self optimizing control system,” Trans. ASME,
vol. 80, pp. 481–492, 1958.
20. V. Peterka, “Adaptive digital regulation of noisy systems,” in Preprints of the
2nd IFAC Symposium on Identiﬁcation and Process Parameter Estimation,
p. 6.2, Prague: ´UTIA ˇCSAV, 1970.
21. K. J. ˚Astr¨om and B. Wittenmark, “On self-tuning regulators,” Automatica,
vol. 9, pp. 185–199, 1973.
22. D. W. Clarke and P. J. Gawthrop, “Self-tuning controller,” Proc. IEE, vol. 122,
pp. 929–934, 1975.
23. D. W. Clarke and P. J. Gawthrop, “Self-tuning control,” Proc. IEE, vol. 126,
pp. 633–640, 1979.
24. V. Peterka, “Predictor-based self-tuning control,” Automatica, vol. 20, no. 1,
pp. 39–50, 1984. Reprinted in : Adaptive Methods for Control System Design,
Editor M.M. Gupta, IEEE Press, 1986.
25. M. K´arn´y, A. Halouskov´a, J. B¨ohm, R. Kulhav´y, and P. Nedoma, “Design of
linear quadratic adaptive control: Theory and algorithms for practice,” Kyber-
netika, vol. 21, 1985. Supplement to No. 3, 4 ,5, 6.
26. J. B¨ohm, A. Halouskov´a, M. K´arn´y, and V. Peterka, “Simple LQ self-tuning
controllers,” in Preprints of 9th IFAC World Congress, vol. 8, pp. 171–176,
1984.
27. P. E. Wellstead, J. M. Edmunds, D. I. Prager, and P. M. Zanker, “Pole zero as-
sigment self-tuning regulator,” International Journal of Control, vol. 30, pp. 1–
26, 1979.
28. K. J. ˚Astr¨om and B. Wittenmark, “Self-tuning controller based on pole-zero
placement,” IEE-Procedings D, vol. 127, pp. 120–130, 1980.
29. D. W. Clarke, C. Mohtadi, and P. S. Tuﬀs, “Generalized predictive control –
part i. the basic algorithm,” Automatica, vol. 23, pp. 137–148, 1987.
30. D. Clarke, C. Mohtadi, and P. Tuﬀs, “Generalized predictive control,” Auto-
matica, vol. 23, no. 2, pp. 137–160, 1987.
31. P. J. Gawthrop, “Hybrid self-tuning control,” IEE-Procedings D, vol. 127,
pp. 229–236, 1980.
32. C. B´any´asz and L. Keviczky, “Direct methods for self-tuning PID regulators,”
in Proc. 6th IFAC Symposium on Identiﬁcation and System Parameter Esti-
mation, pp. 1249–1254, 1982.
33. V. Bob´al, J. B¨ohm, and R. Prokop, “Practical aspects of self-tuning con-
trollers,” International Journal of Adaptive Control and Signal Processing,
vol. 13, pp. 671–690, 1999.
34. R. Kulhav´y and F. J. Kraus, “On duality of regularized exponential and linear
forgetting,” Automatica, vol. 32, pp. 1403–1415, 1996.
35. J.Lampinen and I. Zelinka, New Ideas in Optimization - Mechanical Engineer-
ing Design Optimization by Diﬀerential Evolution, vol. 1. McGraw-Hill, 1999.
36. I. Zelinka, “Evolutionary identiﬁcation of predictive models,” in ISF’ 2000, The
20th International Symposium on Forecasting, Lisbon, Portugal: International
Institute of Forecasters, 2000.
37. C. Kar, Practical Applications of Computational Intelligence for Adaptive Con-
trol. CRC Press, 1999.

References
309
38. R. Ballini and F. Zuben, Application of Neural Networks to Adaptive Control
of Nonlinear Systems. Research Studies Press Ltd, 1997.
39. H. Hellendoorn and D. Driankov, Fuzzy Model Identiﬁcation. Springer Verlag,
1997.
40. J. B¨ohm and M. K´arn´y, “Merging of user’s knowledge into self-tuning con-
trollers,” in Preprints of 4th IFAC Symposium Adaptive Control and Signal
Processing ACASP’92 (I. Landau, L. Dugard, and M. M’Saad, eds), vol. 2,
pp. 427–432, Grenoble: Academic Press, 1992.
41. R. Kulhav´y and M. B. Zarrop, “On general concept of forgetting,” International
Journal of Control, vol. 58, no. 4, pp. 905–924, 1993.
42. L. Ljung, System Identiﬁcation: Theory for the User. London: Prentice-Hall,
1987.
43. T. S¨oderstr¨om and P. Stoica, System Identiﬁcation. Englewood Cliﬀs, New
Jersey: Prentice-Hall, 1989.
44. L. Ljung and T. S¨oderstr¨om, Theory and Practice of Recursive Identiﬁcation.
Cambridge, Massachusetts: MIT Press, 1983.
45. V. Strejc, “Least squares parameter estimation,” Automatica, vol. 16, pp. 535–
550, 1980.
46. V. Peterka, “A square-root ﬁlter for real-time multivariable regression,” Ky-
bernetika, vol. 11, pp. 53–67, 1975.
47. G. Bierman, Factorization Methods for Discrete Sequential Estimation. New
York: Academic Press, 1977.
48. V. Peterka, “Real-time parameter estimation and output prediction for ARMA-
type system models,” Kybernetika, vol. 17, pp. 526–533, 1981.
49. R. Kulhav´y, “Directional tracking of regression-type model parameters,” in
Preprints of the 2nd IFAC Workshop on Adaptive Systems in Control and
Signal Processing (Lund, Sweden), pp. 97–102, 1986.
50. R. Kulhav´y, “Restricted exponential forgetting in real-time identiﬁcation,” Au-
tomatica, vol. 23, no. 5, pp. 589–600, 1987.
51. M. Kubalˇc´ık and V. Bob´al, “Adaptive control of coupled drives apparatus
based on polynomial approach,” in Proceedings of the IEEE International Con-
ference on Control Applications 2002, pp. 594–599, 2002.
52. V. Bob´al, P. Navr´atil, P. Dost´al, and M. Sysel, “Delta self-tuning control MIMO
systems: comparison 1dof and 2dof conﬁgurations,” in Proc. of IASTED In-
ternational Conference Circuits, Signals and Systems, pp. 5–10, 2003.
53. P. Dost´al, V. Bob´al, and M. Blaha, “One approach to adaptive control of non-
linear processes,” in Preprints of IFAC Workshop on Adaptation and Learning
in Control and Signal Processing ALCOSP (Cernobbio-Como, Italy), pp. 407–
412, 2001.
54. R. Isermann, Digital Control Systems. Berlin, Heidelberg, New York: Springer-
Verlag, 1991. 2nd Edition.
55. A. Niederli´nsky, Digital Systems for Control of Technological Processes: Hard-
ware and Software. Praha: SNTL, 1984 (in Czech).
56. Y. Takahashi, C. Chan, and D. Auslander, “Parametereinstellung bei linearen
DDC-algorithmen,” Regelunstechnik und Prozessdatenverarbeitung, vol. 19,
pp. 237–284, 1971.
57. C. C. Hang, K. J. ˚Astr¨om, and W. K. Ho, “Reﬁnements of the Ziegler–Nichols
tuning formula,” IEE Procedings-D, vol. 138, pp. 111–118, 1991.
58. K. J. ˚Astr¨om, C. C. Hang, P. Persson, and W. K. Ho, “Towards intelligent PID
control,” Automatica, vol. 28, pp. 1–9, 1992.

310
References
59. V. Bob´al, J. Mach´aˇcek, and R. Prokop, “Tuning of digital PID controllers
based on Ziegler-Nichols method,” in Proc. of the 2nd IFAC Workshop on
New Trends in Design of Control Systems (Smolenice, Slovakia), pp. 133–138,
1997.
60. J. ˇSindel´aˇr, “Adaptation of control system structure to the course of control-
ling error,” in Proc. of the 2nd IFAC Symposium on System Sensitivity and
Adaptivity (Dubrovn´ık), 1978.
61. J. ˇSindel´aˇr, Control Systems with Discontinuously Variable Structure. Praha:
Academia, 1973 (in Czech).
62. P. D. Roberts, “Simple tuning of discrete PI and PID controllers,” Measure-
ment and Control, vol. 9, pp. 227–234, 1975.
63. F. B. Shinskey, Process Control Systems. New York: Mc Graw Hill, 1979.
64. J. Fessl and J. Jarkovsk´y, “Cascade control using adaptive controllers with on-
line identiﬁcation: Some problems and solutions,” in Proc. of the 10th IFAC
World Congress, Vol. 10 (Munich), pp. 59–64, 1987.
65. J. Fessl and J. Jarkovsk´y, “Cascade control of superheated steam tempera-
ture with lq self-tuning controllerss,” in Proc. of the 8th IFAC Symposium on
Identiﬁcation and System Parameter Estimation (Beijing), 1988.
66. A. H. Glattfelder and W. Schaufelberger, “Stability analysis of single loop
control systems with saturation and anti-reset wind-up circuits,” IEEE Trans.
Automatic Control, vol. 28, pp. 1074–1081, 1983.
67. L.
Rundquist,
Anti-reset
Windup
for
PID
Controllers.
Report
LUTFD2/(TRFT-1033)/
1-143.
Lund, Sweden: Lund
Inst. of
Tech.,
1991.
68. L. Rundquist, “Anti-reset windup for PID controllers,” in Proc. of the 11th
IFAC World Congress, Vol. 8, (Tallinn), pp. 146–151, 1991.
69. K. J. ˚Astr¨om and B. Wittenmark, Computer-Controlled Systems: Theory and
Design. New Jersey: Englewood Cliﬀs Prentice Hall, 1984.
70. D. W. Clarke, “PID algorithms and their computer implementation,” Trans-
actions of the Institute of Measurement and Control, vol. 6, pp. 305–316, 1984.
71. R. M. Hanus, M. Kinneart, and J. Henrotte, “Conditioning technique on gen-
eral anti-windup and bumpless transfer method,” Automatica, vol. 23, pp. 729–
739, 1987.
72. B. ˇSulc, “Integral wind-up in control and system simulation,” Control En-
gineering Solutions. A Practical Approach. IEE Control Engineering Series,
vol. 54, pp. 61–76, 1997.
73. B. H. Bristol, “Designing and programming control algorithms for DDC sys-
tems,” Control Engineering, vol. 1, pp. 24–26, 1977.
74. A. B. Corripio and P. M. Tomkins, “Industrial application of self-tuning feed-
back control algorithhm,” ISA Transactions, vol. 20, pp. 3–10, 1981.
75. D. B. Dahlin, “Designing and tuning digital controllers,” Inst. Control Systems,
vol. 42, pp. 77–83, 1968.
76. K. C. Chiu, A. B. Corripio, and C. L. Smith, “Digital control algorithms, part
1, Dahlin algorithm,” Inst. Control Systems, vol. 47, pp. 57–59, 1973.
77. B. Wittenmark, Self-tuning PID-controllers based on pole placement. Report
LUTFD2/(TRFT-7179)/ 1-037.
Lund, Sweden: Lund Inst. of Technology,
1979.
78. R. Ortega and R. Kelly, “PID self-tuners: Some theoretical and practical as-
pects,” IEEE Trans. Ind. Electron., vol. 31, pp. 332–338, 1984.

References
311
79. J. H. Kim and K. K. Choi, “Self-tuning discrete PID controller,” IEEE Trans.
Automatic Control, vol. 34, pp. 298–300, 1987.
80. J. H. Kim and K. K. Choi, “Design of direct pole placement PID self-tuners,”
IEEE Trans. Automatic Control, vol. 34, pp. 351–356, 1987.
81. R. Kofahl and R. Isermann, “A simple method for automatic tuning of PID-
controllers based on process parameter estimation,” in Proc. American Control
Conference (Boston), pp. 1143–1148, 1985.
82. F. Radke and R. Isermann, “A parameter-adaptive PID controller with step-
wise parameter optimization,” Automatica, vol. 23, pp. 449–457, 1987.
83. S. Tzaseftas and G. Kapsiotis, “PID self-tuning control combining pole-
placement and parameter optimization features,” in Proc. IMACS/IFAC Sec-
ond International Symposium on Mathematical and Intelligent Models in Sys-
tem Simulation, Vol. II (Brussels), pp. 30–40, 1993.
84. P. J. Gawthrop, Using the self-tuning controller to tune PID regulators. Report
No. CE/T/2. Brighton: School of Appl. Sci., Univ. Sussex, 1982.
85. P. Neuman, “Industrial adaptive regulator with discontinuously structure,” in
Proc. of IFAC Workshop Evaluation of Adaptive Control Strategies in Indus-
trial Applications (Tbilisi), pp. 281–288, 1989.
86. M. Alex´ık, “Adaptive self-tuning algorithm based on continuous synthesis,” in
Proc. of the 2nd IFAC Workshop on New Trends in Design of Control Systems,
(Smolenice, Slovakia), pp. 481–486, 1997.
87. C. B´any´asz and L. Keviczky, “Direct methods for self-tuning PID controllers,”
in Proc. of the 6th IFAC Symposium on Identiﬁcation and System Parameter
Estimation, (Washington), pp. 1249–1254, 1982.
88. C. B´any´asz and L. Keviczky, “Design of adaptive PID regulators based on
recursive estimation of the process parameters,” Journal of Process Control,
vol. 3, pp. 53–59, 1993.
89. J. B¨ohm, A. Halouskov´a, M. K´arn´y, and V. Peterka, “Simple lq self-tuning
controllers,” in Proc. of the 9th Triennial World Congress of IFAC (Budapest),
pp. 961–966, 1984.
90. M. V´ıteˇckov´a, A. V´ıteˇcek, and L. Smutn´y, “Simple PI and PID controllers
tuning for monotone self-regulating plants,” in Proc. of the IFAC Workshop
Digital Control: Past, Present and Future of PID Control (Terrassa, Spain),
pp. 259–264, 2000.
91. M. V´ıteˇckov´a, A. V´ıteˇcek, and L. Smutn´y, “Controller tuning for controlled
plants with time delay,” in Proc. of the IFAC Workshop Digital Control: Past,
Present and Future of PID Control, (Terrassa, Spain), pp. 253–258, 2000.
92. V. Bob´al, P. Dost´al, J. Mach´aˇcek, and M. V´ıteˇckov´a, “Self-tuning PID con-
trollers based on dynamics inversion method,” in Proc. of the IFAC Workshop
Digital Control: Past, Present and Future of PID Control, (Terrassa, Spain),
pp. 167–172, 2000.
93. V. Bob´al, Auto-Tuning of Digital PID Controllers Using Recursive Identiﬁ-
cation. Report ESR 9409. Bochum: Faculty of Electrical Engineering, Ruhr-
University, 1994.
94. V. Bob´al, “Self-tuning Ziegler-Nichols PID controller,” International Journal
of Adaptive Control and Signal Processing, vol. 9, pp. 213–226, 1995.
95. V. Bob´al, “Robust self-tuning PID controller,” in Proc: 1st IFAC Workshop on
New Trends in Design of Control Systems (Smolenice, Slovakia), pp. 312–317,
1994.

312
References
96. V. Bob´al, J. Mach´aˇcek, and R. Prokop, “Practical tuning of industrial PID con-
trollers,” in Proc. of the IFAC-IFIP-IMACS Conference Control of Industrial
Systems (University of Belfort), pp. 37–42, 1997.
97. J. Mach´aˇcek and V. Bob´al, “Adaptive PID controller with time delay,” in Proc.
of the European Control Conference ECC99 (Karlsruhe), pp. paper BA – 12 –
5, 1999.
98. J. Mach´aˇcek and V. Bob´al, “Adaptive PID controller with on-line identiﬁca-
tion,” Journal of Electrical Engineering, vol. 53, pp. 233–240, 2002.
99. C. B´any´asz, J. Hetthessy, and L. Keviczky, “An adaptive PID regulator ded-
icated for microprocessor based compact controllers,” in Proc. of the 7th
IFAC Symposium on Identiﬁcation and System Parameter Estimation, (York),
pp. 1299–1304, 1985.
100. L. Keviczky and C. B´any´asz, “A completely adaptive PID regulator,” in Proc.
of the 8th IFAC Symposium on Identiﬁcation and System Parameter Estima-
tion (Beijing), pp. 91–97, 1988.
101. K. J. ˚Astr¨om and B. Wittenmark, “Simple self-tuning controllers,” in Proc.
Symposium on Methods and Applications in Adaptive Control (Bochum),
pp. 21–30, 1980.
102. V. Bob´al, M. Kubalˇc´ık, and M. ´Ulehla, “Auto-tuning of digital PID controllers
using recursive identiﬁcation,” in Proc. of the 5th IFAC Symposium on Adaptive
Systems in Control and Signal Processing (Budapest), pp. 384–389, 1995.
103. J. G. Ziegler and N. B. Nichols, “Optimum settings for automatic controllers,”
Trans. ASME, vol. 64, pp. 759–768, 1942.
104. H. Cui and E. W. Jacobsen, “Performance limitations in decentralized control,”
Journal of Process Control, vol. 12, pp. 485–494, 2002.
105. V. Kuˇcera, Discrete Linear Control: The Polynomial Equation Approach.
Chichester: John Wiley, 1979.
106. V. Kuˇcera, Analysis and Design of Discrete Linear Control Systems. London:
Prentice Hall, 1991.
107. M. Vidyasagar, Control System Synthesis: A Factorization Approach. Cam-
bridge MA, MIT Press, 1985.
108. V. Kuˇcera, “Equations in control
a survey,” Automatica, vol. 29, pp. 1361–
1375, 1993.
109. M. ˇSebek, The Polynomial Toolbox 2 Manual. Prague: Polyx, 1999.
110. V. Kuˇcera, “A dead-beat servo problem,” Int. J. Control, vol. 32, pp. 107–113,
1980.
111. M. ˇSebek, “Multivariable dead-beat servo problem,” Kybernetika, vol. 16,
pp. 442–453, 1980.
112. S. M. Shinners, Advanced Modern Control System
Theory and Design. New
York: John Wiley, 1998.
113. M. ˇSebek and V. Kuˇcera, “Polynomial approach to quadratic tracking in dis-
crete linear systems,” IEEE Trans. Automatic Control, vol. AC-27, pp. 1248–
1250, 1982.
114. J. B¨ohm, M. K´arn´y, and A. Halouskov´a, “LQ optimization with irregular input-
output sampling: Algorithmic and complexity aspects,” in Preprints of the
European IEEE Workshop CMP’94 (L. Kulhav´a, M. K´arn´y, and K. Warwick,
eds), pp. 265–268, Prague: ´UTIA AVˇCR, 1994.
115. J. B¨ohm, “On algorithmic problems related to multivariate adaptive LQG con-
trollers,” in Symposium on Control, Optimization and Supervision, CESA’96,
pp. 310–314, 1996.

References
313
116. I. D. Landau, D. Rey, A. Karimi, A. Voda, and A. Franco, “A ﬂexible trans-
mition system as a benchmark for robust digital control,” European Journal of
Control, vol. 1, pp. 77–96, 1995.
117. B. Wittenmark, “An active suboptimal dual controller for systems with
stochastic parameters,” Automatic Control Theory and Application, vol. 3,
no. 1, pp. 13–19, 1975.
118. V. Peterka, “Digital control of processes with random disturbances and uncer-
tain characteristics,” Technical Report, ´UTIA AVˇCR, POB 18, 18208 Prague
8, CR, 1975 in Czech.
119. J. B¨ohm, “LQ self-tuners with signal level constraints,” in Preprints of the 7th
IFAC/IFIP Symposium on Identiﬁcation and System Parameter Estimation,
vol. 1, pp. 131–137, 1985.
120. J. B¨ohm and M. K´arn´y, “Self-tuning regulators with restricted inputs,” Ky-
bernetika, vol. 18, no. 6, pp. 529–544, 1982.
121. R. Bitmead, M. Gevers, and V. Wertz, Adaptive Optimal Control. The Thinking
Man’s GPC. Prentice Hall, 1990.
122. C. E. de Souza, “Monotonicity and stabilizability results for the solutions of
the Riccati diﬀerence equation,” in Preprints of the Workshop on the Riccati
Equation in Control, Systems and Signals, pp. 38–41, 1989.
123. W. H. Kwon and A. E. Pearson, “On feedback stabilization of time-varying
discrete linear systems,” IEEETransactions on Automatic Control, vol. AC-23,
pp. 479–481, 1978.
124. J. B¨ohm, “The set point control and oﬀset compensation in the discrete LQ
adaptive control,” Problems of Control and Information Theory, vol. 17, no. 3,
pp. 33–46, 1988.
125. B. D. O. Anderson and J. Moore, Optimal Control. Linear Quadratic Method.
London: Prentice-Hall, 1989.
126. P. Nedoma, and M. K´arn´y and J. B¨ohm, “Designer : Preliminary tuning of
adaptive controllers,” in Proceeding of the 2nd scientiﬁc–technical Conference
PROCESS CONTROL, Horn´ı Beˇcva, 1996 (J. Krejˇc´ı, ed.), pp. 225–228, 1996.
127. P. Nedoma, and M. K´arn´y and J. B¨ohm, ABET: Adaptive Bayesian Estimation
Toolbox for MATLAB. Prague, Czech Republic: ´UTIA AV ˇCR, 1996.
128. J. B¨ohm, “Experiments with LQ adaptive controller in the heat exchanger
station at STU Bratislava,” Technical Report 1919, ´UTIA AVˇCR, P.O.Box 18,
182 08 Prague, Czech Republic, 1998.
129. J. Fessl, “An application of multivariable self-tuning regulators to drum boiler
control,” Automatika, vol. 22, pp. 581–585, 1986.
130. V. Bob´al, J. B¨ohm, and P. Chalupa, “Matlab-toolbox for CAD of simple self-
tuning controllers,” in Proc. of the 7th IFAC Workshop on Adaptation and
Learning in Control and Signal Processing (Cernobbio-Como, Italy), pp. 273–
278, 2001.
131. V. Bob´al and P. Chalupa, Self-tuning Controllers Simulink Library.
Zl´ın:
Tomas
Bata
University
in
Zl´ın,
Faculty
of
Technology,
2002.
http:
//www.utb.cz/stctool/.
132. P. Chalupa, Discrete Decentralized Control Systems. Ph.D. Thesis. Zl´ın: Tomas
Bata University in Zl´ın, Faculty of Technology, 2003.
133. P. Zelinka, B. Rohal’-Ilkiv, and A. Kuznetsov, “Experimental veriﬁcation of
stabilizing predictive control,” Control Engineering Practice, vol. 7, pp. 601–
610, 1999.

314
References
134. J. Fessl and J. Jarkovsk´y, “Steam superheater control via self-tuning regula-
tor,” in Preprints of IFAC Symposium on Digital Computer Applications to
Process Control, Vienna: Academic Press, 1985.
135. J. Fessl, “LQ self-tuning controllers with varying cost function weight,” in
Preprints of Proc. of IFAC Symposium ITAC 91 on Intelligent Tuning and
Adaptive Control, Singapore: Academic Press, 1991.

Index
actuator, 65, 73, 77
adaptation, 5, 7, 9
adaptive
control system, 5, 8, 11
heuristic approach, 9
MRAS, 2, 11
LQ controller, 199, 285
algebraic design method, 139
dead-beat, 143
strong version, 143
weak version, 148, 162
linear quadratic control, 157, 163
one degree of freedom, 140
pole assignment, 149, 162
damping factor, 150, 151
natural frequency, 150
two degrees of freedom, 140
algorithm
controller, 93, 118, 126, 129, 249, 258,
295
identiﬁcation, 29, 257, 270
least squares, 26, 30, 32, 36, 38, 40
directional forgetting, 36, 102
square root, 263
linear quadratic
square root, 242
auto-tuning, 2, 17
characteristic polynomial, 97
constant, 54
derivative, 54, 59, 62
integral, 54, 59
time, 65, 69, 79, 94
control
law, 9, 16, 61, 170
manual, 75, 89
multivariable, 236, 269, 295
optimal, 175
control theory
algebraic, 139, 142
controller
adaptive LQ, 199, 285
continuous-time PID, 53, 54, 62, 69,
82, 109
digital PID, 55
absolute, 57
bumpless connection, 74
cascade control, 77
derivative component ﬁltering, 62
incremental, 57, 59, 74, 75, 83, 87
industrial, 73, 89
limited precision, 87
modiﬁcations, 61
normalized gain, 64
position, 57
sampling period, 69
set point weighting, 63
Takahashi, 63, 119, 126
velocity, 57
wind up, 65, 77
LQ tuning, 172, 227
main, 83, 85
nonlinear PID, 65
parameters, 54, 63, 93, 99, 248, 255,
264
PID STC
B´any´asz and Keviczky, 94

316
Index
critical gain, 64, 93, 109, 113, 120
critical period of oscillations, 64,
113
Dahlin, 93
pole assignment, 96
sampling period, 93
Ziegler–Nichols criterion, 109
state, 79
structure, 168
covariance matrix, 28, 35, 184
criterion
least squares, 32
LQ, 157, 167
data ﬁltering, 87, 203
data vector (regressor), 25, 31, 38, 93,
95, 119, 120
discretization
backward rectangular method, 55
forward rectangular method, 55
trapezoidal method, 56
two-point diference, 54
disturbance
compensation, 192
measurable, 166, 205
stochastic, 192
dynamic programming, 168, 237
equation
diﬀerential, 47
polynomial (Diophantine), 97, 142
uncertain coeﬃcients, 142, 144, 147,
155
Riccati, 170
ﬁlter LDFIL, 34
forgetting
directional, 35
exponential, 33
regularized, 29
frequency
characteristic, 215, 222
discrete, 215
domain, 213
Nyquist, 215
sampling, 215
gain
nonlinear, 65
proportional, 54
identiﬁcation
direct, 16
indirect, 16
initialization, 37
process, 26
recursive, 7, 13, 14, 29
least squares method, 30, 32
initial estimates, 102, 121, 130, 235
input reference, 232, 286
input saturation, 233
integrator, 208, 230
LQ STC application
in a boiler control, 294
in cascade control, 300
in heat exchanger station, 285
power plant, 300
mean value, 182
model, 21
ARMAX, 24, 139, 209
ARX, 22, 24, 29, 92, 119, 126, 140,
248
continuous-time, 23
discrete, 23, 110
laboratory, 269
regression, 24, 140, 168
state space, 169
stochastic process, 22
structure, 23
nonminimum phase, 132, 163, 174, 177,
189
oﬀset, 208
optimization
LQ, 237
square root, 241, 261
parameter
estimates, 13, 29
estimation, 26
penalization
constant, 157
cross-term, 231
generalized, 229
variable, 233, 286
prediction error, 26, 35, 38

Index
317
predictor, 23
real-time control, 258
Riccati equation, 170
algebraic, 170, 186, 219
fake, 186
monotonicity, 187
Riccati matrix, 187
robustness, 220
sampling period, 87, 93, 98, 111, 114,
193
self-tuning controller, 16
algebraic structure, 14
application, 269, 285
CAD, 112, 247
LQ, 234
certainty equivalence principle, 15,
183
decentralized control, 269
dual control, 15
explicit, 16
implicit, 16
supervisory system, 270
logical supervisor, 274
sensitivity function, 216, 220
set point
pre-programming, 207
tracking, 54, 140, 207
simulation, 128, 132, 159
spectral factorization, 142, 157
stability, 141, 144, 149, 150, 158, 188
step response, 45, 57, 177
strategy
cautious, 183, 295
ﬁnite horizon, 184
inﬁnite horizon, 184
IST, 184
moving horizon, 184, 295
receding horizon, 184
switching criterion, 272
system
adjustable, 7
continuous-time, 23, 194, 198
MIMO, 269, 276, 277, 282
nonlinear, 175, 282
SISO, 30, 32, 270
stable, 117
TITO, 43, 269, 277
unstable, 112, 175, 176, 189, 282
toolbox
LQ, 261
STCSL, 247
vector of parameters, 25

