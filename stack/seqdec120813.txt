Ergodicity, Decisions, and Partial Information
Ramon van Handel
Abstract In the simplest sequential decision problem for an ergodic stochastic pro-
cess X, at each time n a decision un is made as a function of past observations
X0,...,Xn−1, and a loss l(un,Xn) is incurred. In this setting, it is known that one
may choose (under a mild integrability assumption) a decision strategy whose path-
wise time-average loss is asymptotically smaller than that of any other strategy. The
corresponding problem in the case of partial information proves to be much more
delicate, however: if the process X is not observable, but decisions must be based on
the observation of a different process Y, the existence of pathwise optimal strategies
is not guaranteed. The aim of this paper is to exhibit connections between pathwise
optimal strategies and notions from ergodic theory. The sequential decision problem
is developed in the general setting of an ergodic dynamical system (Ω,B,P,T) with
partial information Y ⊆B. The existence of pathwise optimal strategies grounded in
two basic properties: the conditional ergodic theory of the dynamical system, and the
complexity of the loss function. When the loss function is not too complex, a gen-
eral sufﬁcient condition for the existence of pathwise optimal strategies is that the
dynamical system is a conditional K-automorphism relative to the past observations
￿
n≥0 T nY. If the conditional ergodicity assumption is strengthened, the complexity
assumption can be weakened. Several examples demonstrate the interplay between
complexity and ergodicity, which does not arise in the case of full information. Our
results also yield a decision-theoretic characterization of weak mixing in ergodic
theory, and establish pathwise optimality of ergodic nonlinear ﬁlters.
1 Introduction
Let X = (Xk)k∈Z be a stationary and ergodic stochastic process. A decision maker
must select at the beginning of each day k a decision uk depending on the past
observations X0,...,Xk−1. At the end of the day, a loss l(uk,Xk) is incurred. The
decision maker would like to minimize her time-average loss
LT(u) = 1
T
T
∑
k=1
l(uk,Xk).
How should she go about selecting a decision strategy u = (uk)k≥1?
Ramon van Handel
Sherrerd Hall 227, Princeton University, Princeton, NJ 08544, USA. e-mail: rvan@princeton.edu
1

2
Ramon van Handel
There is a rather trivial answer to this question. Taking the expectation of the
time-average loss, we obtain for any strategy u using the tower property
E[LT(u)] = E
￿
1
T
T
∑
k=1
E[l(uk,Xk)|X0,...,Xk−1]
￿
≥E
￿
1
T
T
∑
k=1
min
u E[l(u,Xk)|X0,...,Xk−1]
￿
= E[LT(˜u)],
where ˜u = ( ˜uk)k≥1 is deﬁned as ˜uk = argminu E[l(u,Xk)|X0,...,Xk−1] (we disregard
for the moment integrability and measurability issues, existence of minima, and the
like; such issues will be properly addressed in our results). Therefore, the strategy ˜u
minimizes the mean time-average loss E[LT(u)].
However, there are conceptual reasons to be dissatisﬁed with this obvious so-
lution. In many decision problems, one only observes a single sample path of the
process X. For example, if Xk is the return of a ﬁnancial market in day k and LT(u)
is the loss of an investment strategy u, only one sample path of the model is ever
realized: we do not have the luxury of averaging our investment loss over multiple
“alternative histories”. The choice of a strategy for which the mean loss is small
does not guarantee, a priori, that it will perform well on the one and only realiza-
tion that happens to be chosen by nature. Similarly, if Xk models the state of the
atmosphere and LT(u) is the error of a weather prediction strategy, we face a sim-
ilar conundrum. In such situations, the use of stochastic models could be justiﬁed
by some sort of ergodic theorem, which states that the mean behavior of the model
with respect to different realizations captures its time-average behavior over a sin-
gle sample path. Such an ergodic theorem for sequential decisions was obtained by
Algoet [1, Theorem 2] under a mild integrability assumption.
Theorem 1.1 (Algoet [1]). Suppose that |l(u,x)| ≤Λ(x) with Λ ∈LlogL. Then
liminf
T→∞{LT(u)−LT(˜u)} ≥0
a.s.
for every strategy u: that is, the mean-optimal strategy ˜u is pathwise optimal.
The proof of this result follows from a simple martingale argument. What is
remarkable is that the details of the model do not enter the picture at all: nothing
is assumed on the properties of X or l beyond some integrability (ergodicity is not
needed, and a similar result holds even in the absence of stationarity, cf. [1, Theorem
3]). This provides a universal justiﬁcation for optimizing the mean loss: the much
stronger pathwise optimality property is obtained “for free.”
In the proof of Theorem 1.1, it is essential that the decision maker has full infor-
mation on the history X0,...,Xk−1 of the process X. However, the derivation of the
mean-optimal strategy can be done in precisely the same manner in the more gen-
eral setting where only partial or noisy information is available. To formalize this
idea, let Y = (Yk)k∈Z be the stochastic process observable by the decision maker,
and suppose that the pair (X,Y) is stationary and ergodic. The loss incurred at

Ergodicity, Decisions, and Partial Information
3
time k is still l(uk,Xk), but now uk may depend on the observed data Y0,...,Yk−1
only. It is easily seen that in this setting, the mean-optimal strategy ˜u is given by
˜uk = argminu E[l(u,Xk)|Y0,...,Yk−1], and it is tempting to assume that ˜u is also
pathwise optimal. Surprisingly, this is very far from being the case.
Example 1.2 (Weissman and Merhav [32]). Let X0 ∼Bernoulli(1/2) and let Xk =
1−Xk−1 and Yk = 0 for all k. Then (X,Y) is stationary and ergodic: Yk = 0 indicates
that we are in the setting of no information (that is, we must make blind decisions).
Consider the loss l(u,x) = (u −x)2. Then the mean-optimal strategy ˜uk = 1/2 sat-
isﬁes LT(˜u) = 1/4 for all T. However, the strategy uk = kmod2 satisﬁes LT(u) = 0
for all T with probability 1/2. Therefore, ˜u is not pathwise optimal. In fact, it is
easily seen that no pathwise optimal strategy exists.
Example 1.2 illustrates precisely the type of conundrum that was so fortuitously
ruled out in the full information setting by Theorem 1.1. Indeed, it would be hard to
argue that either u or ˜u in Example 1.2 is superior: a gambler placing blind bets uk
on a sequence of games with loss l(uk,Xk) may prefer either strategy depending on
his demeanor. The example may seem somewhat artiﬁcial, however, as the hidden
process X has inﬁnitely long memory; the gambler can therefore beat the mean-
optimal strategy by simply guessing the outcome of the ﬁrst game. But precisely the
same phenomenon can appear when (X,Y) is nearly memoryless.
Example 1.3. Let (ξk)k∈Z be i.i.d. Bernoulli(1/2), and let Xk = (ξk−1,ξk) and Yk =
|ξk −ξk−1| for all k. Then (X,Y) is a stationary 1-dependent sequence: (Xk,Yk)k≤n
and (Xk,Yk)k≥n+2 are independent for every k. We consider the loss l(u,x) = (u −
x1)2. It is easily seen that Xk is independent of Y1,...,Yk−1, so that the mean-optimal
strategy ˜uk = 1/2 satisﬁes LT(˜u) = 1/4 for all T. On the other hand, note that ξk−1 =
(ξ0 +Y1 +···+Yk−1)mod2. It follows that the strategy uk = (Y1 +···+Yk−1)mod2
satisﬁes LT(u) = 0 for all T with probability 1/2.
Evidently, pathwise optimality cannot be taken for granted in the partial infor-
mation setting even in the simplest of examples: in contrast to the full information
setting, the existence of pathwise optimal strategies depends both on speciﬁc ergod-
icity properties of the model (X,Y) and (as will be seen later) on the complexity
on the loss l. What mechanism is responsible for pathwise optimality under partial
information is not very well understood. Weissman and Merhav [32], who initiated
the study of this problem, give a strong sufﬁcient condition in the binary setting.
Little is known beyond their result, beside one particularly special case of quadratic
loss and additive noise considered by Nobel [24].1
1 It should be noted that the papers [1, 32, 24], in addition to studying the pathwise optimality
problem, also aim to obtain universal decision schemes that achieve the optimal asymptotic loss
without any knowledge of the law of X (note that to compute the mean-optimal strategy ˜u one must
know the joint law of (X,Y)). Such strategies “learn” the law of X on the ﬂy from the observed
data. In the setting of partial information, such universal schemes cannot exist without very speciﬁc
assumptions on the information structure: for example, in the blind setting (cf. Example 1.2), there
is no information and thus universal strategies cannot exist. What conditions are required for the
existence of universal strategies is an interesting question that is beyond the scope of this paper.

4
Ramon van Handel
The aim of this paper is twofold. On the one hand, we will give general conditions
for pathwise optimality under partial information, and explore some tradeoffs inher-
ent in this setting. On the other hand, we aim to exhibit some connections between
the pathwise optimality problem and certain notions and problems in ergodic the-
ory, such as conditional mixing and individual ergodic theorems for subsequences.
To make such connections in their most natural setting, we begin by rephrasing the
decision problem in the general setting of ergodic dynamical systems.
1.1 The dynamical system setting
Let T be an invertible measure-preserving transformation of a probability space
(Ω,B,P). T deﬁnes the time evolution of the dynamical system (Ω,B,P,T): if the
system is initially in state ω ∈Ω, then at time k the system is in the state T kω.
The state of the system is not directly observable, however. To model the available
information, we ﬁx a σ-ﬁeld Y ⊆B of events that can be observed at a single time.
Therefore, if we have observed the system in the time interval [m,n], the information
contained in the observations is given by the σ-ﬁeld Ym,n = ￿
k∈[m,n] T −kY.
In this general setting, the decision problem is deﬁned as follows. Let ￿:
U × Ω→R be a given loss function, where U is the set of possible decisions.
At each time k, a decision uk is made and a loss ￿k(uk) := ￿(uk,T kω) is incurred.
The decision can only depend on the observations: that is, a strategy u = (uk)k≥1 is
admissible if uk is Y0,k-measurable for every k. The time-average loss is given by
LT(u) := 1
T
T
∑
k=1
￿k(uk).
The basic question we aim to answer is whether there exists a pathwise optimal
strategy, that is, a strategy u￿such that for every admissible strategy u
liminf
T→∞{LT(u)−LT(u￿)} ≥0
a.s.
The stochastic process setting discussed above can be recovered as a special case.
Example 1.4. Let (X,Y) be a stationary and ergodic stochastic process, where Xk
takes values in the measurable space (E,E) and Yk takes values in the measurable
space (F,F). We can realize (X,Y) as the coordinate process on the canonical path
space (Ω,B,P) where Ω= EZ ×FZ, B = EZ ⊗FZ, and P is the law of (X,Y). Let
T : Ω→Ωbe the canonical shift (T(x,y))n = (xn+1,yn+1). Then (Ω,B,P,T) is an
ergodic dynamical system. If we choose the observation σ-ﬁeld Y = σ{Y0} and the
loss ￿(u,ω) = l(u,X1(ω)), we recover the decision problem with partial information
for the stochastic process (X,Y) as it was introduced above. More generally, we
could let the loss depend arbitrarily on future or past values of (X,Y).

Ergodicity, Decisions, and Partial Information
5
Let us brieﬂy discuss the connection between pathwise optimal strategies and
classical ergodic theorems. The key observation in the derivation of the mean-
optimal strategy ˜uk = argminu E[￿k(u)|Y0,k] is that by the tower property
E
￿
1
T
T
∑
k=1
￿k(uk)
￿
= E
￿
1
T
T
∑
k=1
E[￿k(uk)|Y0,k]
￿
.
As the summands on the right-hand side depend only on the observed information,
we can minimize inside the sum to obtain the mean-optimal strategy ˜u. Precisely
the same considerations would show that ˜u is pathwise optimal if we could prove
the ergodic counterpart of the tower property of conditional expectations
1
T
T
∑
k=1
{￿k(uk)−E[￿k(uk)|Y0,k]} T→∞
−−−→0
a.s.
?
The validity of such a statement is far from obvious, however.
In the special case of blind decisions (that is, Y is the trivial σ-ﬁeld) the “ergodic
tower property” reduces to the question of whether, given fk(ω) := ￿(uk,ω),
1
T
T
∑
k=1
{ fk −E[fk]}◦T k T→∞
−−−→0
a.s.
?
If the functions fk do not depend on k, this is precisely the individual ergodic theo-
rem. However, an individual ergodic theorem need not hold for arbitrary sequences
fk. Special cases of this problem have long been investigated in ergodic theory. For
example, if fk = ak f for some ﬁxed function f and bounded sequence (ak) ⊂R,
the problem reduces to a weighted individual ergodic theorem, see [2] and the ref-
erences therein. If ak ∈{0,1} for all k, the problem reduces further to an individual
ergodic theorem along a subsequence (at least if the sequence has positive density),
cf. [6, 2] and the references therein. A general characterization of such ergodic prop-
erties does not appear to exist, which suggests that it is probably very difﬁcult to
obtain necessary and sufﬁcient conditions for pathwise optimality. The situation is
better for mean (rather than individual) ergodic theorems, cf. [3] and the references
therein, and we will also obtain more complete results in a weaker setting.
The more interesting case where the information Y is nontrivial provides addi-
tional complications. In this situation, the “ergodic tower property” could be viewed
as a type of conditional ergodic theorem, in between the individual ergodic theorem
and Algoet’s result [1]. Our proofs are based on an elaboration of this idea.
1.2 Some representative results
The essence of our results is that, when the loss ￿is not too complex, pathwise op-
timal strategies exist under suitable conditional mixing assumptions on the ergodic

6
Ramon van Handel
dynamical system (Ω,B,P,T). To this end, we introduce conditional variants of
two standard notions in ergodic theory: weak mixing and K-automorphisms.
Deﬁnition 1.5. An invertible dynamical system (Ω,B,P,T) is said to be condition-
ally weak mixing relative to a σ-ﬁeld Z if for every A,B ∈B
1
T
T
∑
k=1
|P[A∩T kB|Z]−P[A|Z]P[T kB|Z]| T→∞
−−−→0
in L1.
Deﬁnition 1.6. An invertible dynamical system (Ω,B,P,T) is called a conditional
K-automorphism relative to a σ-ﬁeld Z ⊂B if there is a σ-ﬁeld X ⊂B such that
1. X ⊂T −1X.
2. ￿∞
k=1 T −kX = B
mod P.
3. ￿∞
k=1(Z∨T kX) = Z
mod P.
When the σ-ﬁeld Z is trivial, these deﬁnitions reduce2 to the usual notions of
weak mixing and K-automorphism, cf. [31]. Similar conditional mixing conditions
also appear in the ergodic theory literature, see [26] and the references therein.
An easily stated consequence of our main results, for example, is the following.
Theorem 1.7. Suppose that (Ω,B,P,T) is a conditional K-automorphism relative
to Y−∞,0. Then the mean-optimal strategy ˜u is pathwise optimal for every loss func-
tion ￿: U ×Ω→R such that U is ﬁnite and |￿(u,ω)| ≤Λ(ω) with Λ ∈L1.
This result gives a general sufﬁcient condition for pathwise optimality when the
decision space U is ﬁnite. In the stochastic process setting (Example 1.4), the con-
ditional K-property would follow from the validity of the σ-ﬁeld identity
∞
￿
k=1
(Y−∞,0 ∨X−∞,−k) = Y−∞,0
modP,
where X−∞,k = σ{Xi : i ≤k} (choose X := X−∞,0 ∨Y−∞,0 in Deﬁnition 1.6). In
the Markovian setting, this is a familiar identity in ﬁltering theory: it is precisely the
necessary and sufﬁcient condition for the optimal ﬁlter to be ergodic, see section 3.3
below. Our results therefore lead to a new pathwise optimality property of nonlinear
ﬁlters. Conversely, results from ﬁltering theory yield a broad class of (even non-
Markovian) models for which the conditional K-property can be veriﬁed [14, 27].
It is interesting to note that despite the apparent similarity between the conditions
for ﬁlter ergodicity and pathwise optimality, there appears to be no direct connec-
tion between these phenomena, and their proofs are entirely distinct. Let us also
note that, in the full information setting (Yk = Xk) the conditional K-property holds
trivially, which explains the deceptive simplicity of Algoet’s result.
2 To be precise, our deﬁnitions are time-reversed with respect to the textbook deﬁnitions; however,
T is a K-automorphism if and only if T −1 is a K-automorphism [31, p. 110], and the corresponding
statement for weak mixing is trivial. Therefore, our deﬁnitions are equivalent to those in [31].

Ergodicity, Decisions, and Partial Information
7
While the conditional ergodicity assumption of Theorem 1.7 is quite general,
the requirement that the decision space U is ﬁnite is a severe restriction on the
complexity of the loss function ￿. We have stated Theorem 1.7 here in order to
highlight the basic ingredients for the existence of a pathwise optimal strategy. The
assumption that U is ﬁnite will be replaced by various complexity assumptions on
the loss ￿; such extensions will be developed in the sequel. While some complexity
assumption on the loss is needed in the partial information setting, there is a tradeoff
between the complexity and ergodicity: if the notion of conditional ergodicity is
strengthened, then the complexity assumption on the loss can be weakened.
All our pathwise optimality results are corollaries of a general master theorem,
Theorem 2.6 below, that ensures the existence of a pathwise optimal strategy under
a certain uniform version of the K-automorphism property. However, in the absence
of further assumptions, this theorem does not ensure that the mean-optimal strat-
egy ˜u is in fact pathwise optimal: the pathwise optimal strategy constructed in the
proof may be difﬁcult to compute. We do not know, in general, whether it is possi-
ble that a pathwise optimal strategy exists, while the mean-optimal strategy fails to
be pathwise optimal. In order to gain further insight into such questions, we intro-
duce another notion of optimality that is intermediate between pathwise and mean
optimality. A strategy u￿is said to be weakly pathwise optimal if
P[LT(u)−LT(u￿) ≥−ε] T→∞
−−−→1
for every ε > 0.
It is not difﬁcult to show that if a weakly pathwise optimal strategy exists, then
the mean-optimal strategy ˜u must also be weakly pathwise optimal. However, the
notion of weak pathwise optimality is distinctly weaker than pathwise optimality.
For example, we will prove the following counterpart to Theorem 1.7.
Theorem 1.8. Suppose that (Ω,B,P,T) is conditionally weak mixing relative to
Y−∞,0. Then the mean-optimal strategy ˜u is weakly pathwise optimal for every loss
function ￿: U ×Ω→R such that U is ﬁnite and |￿(u,ω)| ≤Λ(ω) with Λ ∈L1.
There is a genuine gap between Theorems 1.8 and 1.7: in fact, a result of Conze
[6] on individual ergodic theorems for subsequences shows that there is a loss func-
tion ￿such that for a generic (in the weak topology) weak mixing system, a mean-
optimal blind strategy ˜u fails to be pathwise optimal.
While weak pathwise optimality may not be as conceptually appealing as path-
wise optimality, the weak pathwise optimality property is easier to characterize. In
particular, we will show that the conditional weak mixing assumption in Theorem
1.8 is not only sufﬁcient, but also necessary, in the special case that Y is an invari-
ant σ-ﬁeld (that is, Y = T −1Y). Invariance of Y is somewhat unnatural in decision
problems, as it implies that no additional information is gained over time as more
observations are accumulated. On the other hand, invariance of Z in Deﬁnitions 1.5
and 1.6 is precisely the situation of interest in applications of conditional mixing in
ergodic theory (e.g., [26]). The interest of this result is therefore that it provides a
decision-theoretic characterization of the (conditional) weak mixing property.

8
Ramon van Handel
1.3 Organization of this paper
The remainder of the paper is organized as follows. In section 2, we state and dis-
cuss the main results of this paper. We also give a number of examples that illustrate
various aspects of our results. Our main results require two types of assumptions:
conditional mixing assumptions on the dynamical system, and complexity assump-
tions on the loss. In section 3 we discuss various methods to verify these assump-
tions, as well as further examples and consequences (such as pathwise optimality of
nonlinear ﬁlters). Finally, the proofs of our main results are given in section 4.
2 Main results
2.1 Basic setup and notation
Throughout this paper, we will consider the following setting:
• (Ω,B,P) is a probability space.
• Y ⊆B is a sub-σ-ﬁeld.
• T : Ω→Ωis an invertible measure-preserving ergodic transformation.
• (U,U) is a measurable space.
As explained in the introduction, we aim to make sequential decisions in the ergodic
dynamical system (Ω,B,P,T). The decisions take values in the decision space U,
and the σ-ﬁeld Y represents the observable part of the system. We deﬁne
Ym,n =
n￿
k=m
T −kY
for −∞≤m ≤n ≤∞,
that is, Ym,n is the σ-ﬁeld generated by the observations in the time interval [m,n].
An admissible decision strategy must depend causally on the observed data.
Deﬁnition 2.1. A strategy u = (uk)k≥1 is called admissible if it is Y0,k-adapted, that
is, uk : Ω→U is Y0,k-measurable for every k ≥1.
It will be convenient to introduce the following notation. For every m ≤n, deﬁne
Um,n = {u : Ω→U : u is Ym,n-measurable},
Un =
￿
−∞<m≤n
Um,n.
Thus a strategy u is admissible whenever uk ∈U0,k for all k. Note that Un ￿U−∞,n:
this distinction will be essential for the validity of our results.
To describe the loss of a decision strategy, we introduce a loss function ￿.
• ￿: U ×Ω→R is a measurable function and |￿(u,ω)| ≤Λ(ω) with Λ ∈L1.

Ergodicity, Decisions, and Partial Information
9
If |￿(u,ω)| ≤Λ(ω) with Λ ∈Lp, the loss is said to be dominated in Lp. As indicated
above, we will always assume3 that our loss functions are dominated in L1.
The loss function ￿(u,ω) represents the cost incurred by the decision u when the
system is in state ω. In particular, the cost of the decision uk at time k is given by
￿(uk,T kω) = ￿k(uk), where we deﬁne for notational simplicity
￿n(u) : Ω→R,
￿n(u)(ω) = ￿(u,T nω).
Our aim is to select an admissible strategy u that minimizes the time-average loss
LT(u) = 1
T
T
∑
k=1
￿k(uk)
in a suitable sense.
Deﬁnition 2.2. An admissible strategy u￿is pathwise optimal if
liminf
T→∞{LT(u)−LT(u￿)} ≥0
a.s.
for every admissible strategy u.
Deﬁnition 2.3. An admissible strategy u￿is weakly pathwise optimal if
P[LT(u)−LT(u￿) ≥−ε] T→∞
−−−→1
for every ε > 0
for every admissible strategy u.
Deﬁnition 2.4. An admissible strategy u￿is mean optimal if
liminf
T→∞{E[LT(u)]−E[LT(u￿)]} ≥0
for every admissible strategy u.
These notions of optimality are progressively weaker: a pathwise optimal strat-
egy is clearly weakly pathwise optimal, and a weakly pathwise optimal strategy is
mean optimal (as the loss function is assumed to be dominated in L1).
In the introduction, it was stated that ˜uk = argminu∈U E[￿k(u)|Y0,k] deﬁnes a
mean-optimal strategy. This disregards some technical issues, as the argmin may
not exist or be measurable. It sufﬁces, however, to consider a slight reformulation.
Lemma 2.5. There exists an admissible strategy ˜u such that
E[￿k( ˜uk)|Y0,k] ≤essinf
u∈U0,k
E[￿k(u)|Y0,k]+k−1
a.s.
for every k ≥1. In particular, ˜u is mean-optimal.
3 Non-dominated loss functions may also be of signiﬁcant interest, see [24] for example. We will
restrict attention to dominated loss functions, however, which sufﬁce in many cases of interest.

10
Ramon van Handel
Proof. It follows from the construction of the essential supremum [25, p. 49] that
there exists a countable family (Un)n∈N ⊆U0,k such that
essinf
u∈U0,k
E[￿k(u)|Y0,k] = inf
n∈NE[￿k(Un)|Y0,k].
Deﬁne the random variable
τ = inf
￿
n : E[￿k(Un)|Y0,k] ≤essinf
u∈U0,k
E[￿k(u)|Y0,k]+k−1￿
.
Note that τ < ∞a.s. as essinfu∈U0,k E[￿k(u)|Y0,k] ≥−E[Λ ◦T k|Y0,k] > −∞a.s. We
therefore deﬁne ˜uk = Uτ. To show that ˜u is mean optimal, it sufﬁces to note that
E[LT(u)]−E[LT(˜u)] = 1
T
T
∑
k=1
E
￿
E[￿k(uk)|Y0,k]−E[￿k( ˜uk)|Y0,k]
￿
≥−1
T
T
∑
k=1
k−1
for any admissible strategy u and T ≥1.
￿￿
In particular, we emphasize that a mean-optimal strategy ˜u always exists. In the
remainder of this paper, we will ﬁx a mean-optimal strategy ˜u as in Lemma 2.5.
2.2 Pathwise optimality
Our results on the existence of pathwise optimal strategies are all consequences of
one general result, Theorem 2.6, that will be stated presently. The essential assump-
tion of this general result is that the properties of the conditional K-automorphism
(Deﬁnition 1.6) hold uniformly with respect to the loss function ￿. Note that, in prin-
ciple, the assumptions of this result do not imply that (Ω,B,P,T) is a conditional
K-automorphism, though this will frequently be the case.
Theorem 2.6 (Pathwise optimality). Suppose that for some σ-ﬁeld X ⊂B
1. X ⊂T −1X.
2. The following martingales converge uniformly:
esssup
u∈U0
￿￿E[￿0(u)|Y−∞,0 ∨T −nX]−￿0(u)
￿￿n→∞
−−−→0
in L1,
esssup
u∈U0
￿￿E[￿0(u)|Y−∞,0 ∨T nX]−E[￿0(u)|￿∞
k=1(Y−∞,0 ∨T kX)]
￿￿n→∞
−−−→0
in L1.
3. The remote past does not affect the asymptotic loss:
L￿:= E
￿
essinf
u∈U0
E[￿0(u)|Y−∞,0]
￿
= E
￿
essinf
u∈U0
E[￿0(u)|￿∞
k=1(Y−∞,0 ∨T kX)]
￿
.
Then there exists an admissible strategy u￿such that for every admissible strategy u

Ergodicity, Decisions, and Partial Information
11
liminf
T→∞{LT(u)−LT(u￿)} ≥0
a.s.,
lim
T→∞LT(u￿) = L￿
a.s.,
that is, u￿is pathwise optimal and L￿is the optimal long time-average loss.
The proof of this result will be given in section 4.1 below.
Before going further, let us discuss the conceptual nature of the assumptions of
Theorem 2.6. The assumptions encode two separate requirements:
1. Assumption 3 of Theorem 2.6 should be viewed as a mixing assumption on
the dynamical system (Ω,B,P,T) that is tailored to the decision problem. In-
deed, Y−∞,0 represents the information contained in the observations, while
￿∞
k=1(Y−∞,0 ∨T kX) includes in addition the remote past of the generating σ-ﬁeld
X. The assumption states that knowledge of the remote past of the unobserved
part of the model cannot be used to improve our present decisions.
2. Assumption 2 of Theorem 2.6 should be viewed as a complexity assumption on
the loss function ￿. Indeed, in the absence of the essential suprema, these state-
ments hold automatically by the martingale convergence theorem. The assump-
tion requires that the convergence is in fact uniform in u ∈U0. This will be the
case when the loss function is not too complex.
The assumptions of Theorem 2.6 can be veriﬁed in many cases of interest. In sec-
tion 3 below, we will discuss various methods that can be used to verify both the
conditional mixing and the complexity assumptions of Theorem 2.6.
In general, neither the conditional mixing nor the complexity assumption can be
dispensed with in the presence of partial information.
Example 2.7 (Assumption 3 is essential). We have seen in Examples 1.2 and 1.3 in
the introduction that no pathwise optimal strategy exists. In both these examples
Assumption 2 is satisﬁed, that is, the loss function is not too complex (this will
follow from general complexity results, cf. Example 3.6 in section 3 below). On the
other hand, it is easily seen that the conditional mixing Assumption 3 is violated.
Example 2.8 (Assumption 2 is essential). Let X = (Xk)k∈Z be the stationary Markov
chain in [0,1] deﬁned by Xk+1 = (Xk + εk+1)/2 for all k, where (εk)k∈Z is an i.i.d.
sequence of Bernoulli(1/2) random variables. We consider the setting of blind de-
cisions with the loss function ￿k(u) = ￿2uXk￿mod2, u ∈U = N. Note that
Xk =
∞
∑
i=0
2−i−1εk−i,
￿k(u) = εk−u+1.
We claim that no pathwise optimal strategy can exist. Indeed, consider for ﬁxed
r ≥0 the strategy ur such that ur
k = k +r. Then ￿k(ur
k) = ε1−r for all k. Therefore,
ε1−r −limsup
T→∞
LT(u￿) = liminf
T→∞{LT(ur)−LT(u￿)} ≥0
a.s.
for all r ≥0
for every pathwise optimal strategy u￿. In particular,

12
Ramon van Handel
0 = inf
r≥0ε1−r ≥limsup
T→∞
LT(u￿) ≥liminf
T→∞LT(u￿) ≥0
a.s.
As |LT(u￿)| ≤1 for all T, it follows by dominated convergence that a pathwise
optimal strategy u￿must satisfy E[LT(u￿)] →0 as T →∞. But clearly E[LT(u)] =
1/2 for every T and strategy u, which entails a contradiction.
Nonetheless, in this example the dynamical system is a K-automorphism (even a
Bernoulli shift), so that that Assumption 3 is easily satisﬁed. As no pathwise optimal
strategy exists, this must be caused by the failure of Assumption 2. For example, for
the natural choice X = σ{Xk : k ≤0}, Assumption 3 holds as ￿
k T kX is trivial by
the Kolmogorov zero-one law, but it is easily seen that the second equation of As-
sumption 2 fails. Note that the function l(u,x) = ￿2ux￿mod2 becomes increasingly
oscillatory as u →∞; this is precisely the type of behavior that obstructs uniform
convergence in Assumption 2 (akin to “overﬁtting” in statistics).
Example 2.9 (Assumption 2 is essential, continued). In the previous example, path-
wise optimality fails due to failure of the second equation of Assumption 2. We now
give a variant of this example where the ﬁrst equation of Assumption 2 fails.
Let X = (Xk)k∈Z be an i.i.d. sequence of Bernoulli(1/2) random variables. We
consider the setting of blind decisions with the loss function ￿k(u) = Xk+u, u ∈U =
N. We claim that no pathwise optimal strategy can exist. Indeed, consider for r = 0,1
the strategy ur deﬁned by uk = 2r+n+1 −k for 2n ≤k < 2n+1, n ≥0. Then
L2n−1(ur) =
1
2n −1
n−1
∑
m=0
2m+1−1
∑
k=2m
Xk+uk =
2n
2n −1
n−1
∑
m=0
2−(n−m)X2r+m+1.
Suppose that u￿is pathwise optimal. Then
liminf
T→∞E[LT(u0)∧LT(u1)−LT(u￿)] ≥E
￿
liminf
T→∞{LT(u0)∧LT(u1)−LT(u￿)}
￿
≥0.
But a simple computation shows that E[L2n−1(u0)∧L2n−1(u1)] converges as n →∞
to a quantity strictly less than 1/2 = E[LT(u￿)], so that we have a contradiction.
Nonetheless, in this example Assumption 3 and the second line of Assumption 2
are easily satisﬁed, e.g., for the natural choice X = σ{Xk : k ≤0}. However, the ﬁrst
line of Assumption 2 fails, and indeed no pathwise optimal strategy exists.
It is evident from the previous examples that an assumption on both conditional
mixing and on complexity of the loss function is needed, in general, to ensure exis-
tence of a pathwise optimal strategy. In this light, the complete absence of any such
assumptions in the full information case is surprising. The explanation is simple,
however: all assumptions of Theorem 2.6 are automatically satisﬁed in this case.
Example 2.10 (Full information). Let X = (Xk)k∈Z be any stationary ergodic pro-
cess, and consider the case of full information: that is, we choose the obser-
vation σ-ﬁeld Y = σ{X0} and the loss ￿(u,ω) = l(u,X1(ω)). Then all assump-
tions of Theorem 2.6 are satisﬁed: indeed, if we choose X = σ{Xk : k ≤0}, then

Ergodicity, Decisions, and Partial Information
13
Y−∞,0 = Y−∞,0 ∨T kX for all k ≥0, so that Assumption 3 and the second line of
Assumption 2 hold trivially. Moreover, ￿0(u) is T −kX-measurable for every u ∈U0
and k ≥1, and thus the ﬁrst line of Assumption 2 holds trivially. It follows that in
the full information setting, a pathwise optimal strategy always exists.
In a sense, Theorem 2.6 provides additional insight even in the full information
setting: it provides an explanation as to why the case of full information is so much
simpler than the partial information setting. Moreover, Theorem 2.6 provides an
explicit expression for the optimal asymptotic loss L￿, which is not given in [1].4
However, it should be emphasized that Theorem 2.6 does not state that the mean-
optimal strategy ˜u is pathwise optimal; it only guarantees the existence of some
pathwise optimal strategy u￿. In contrast, in the full information setting, Theorem
1.1 ensures pathwise optimality of the mean-optimal strategy. This is of practical
importance, as the mean-optimal strategy can in many cases be computed explicitly
or by efﬁcient numerical methods, while the pathwise optimal strategy constructed
in the proof of Theorem 2.6 may be difﬁcult to compute. We do not know whether
it is possible in the general setting of Theorem 2.6 that a pathwise optimal strategy
exists, but that the mean-optimal strategy ˜u is not pathwise optimal. Pathwise op-
timality of the mean-optimal strategy ˜u can be shown, however, under somewhat
stronger assumptions. The following corollary is proved in section 4.2 below.
Corollary 2.11. Suppose that for some σ-ﬁeld X ⊂B
1. X ⊂T −1X.
2. The following martingales converge uniformly:
esssup
u∈U0
￿￿E[￿0(u)|Y−∞,0 ∨T −nX]−￿0(u)
￿￿n→∞
−−−→0
in L1,
esssup
u∈U0
￿￿E[￿0(u)|Y−∞,0 ∨T nX]−E[￿0(u)|￿∞
k=1(Y−∞,0 ∨T kX)]
￿￿n→∞
−−−→0
in L1,
esssup
u∈U−n,0
￿￿E[￿0(u)|Y−n,0]−E[￿0(u)|Y−∞,0]
￿￿n→∞
−−−→0
a.s.
3. The remote past does not affect the present:
E[￿0(u)|Y−∞,0] = E[￿0(u)|￿∞
k=1(Y−∞,0 ∨T kX)]
for all u ∈U0.
Then the mean-optimal strategy ˜u (Lemma 2.5) satisﬁes LT(˜u) →L￿a.s. as T →∞.
In particular, it follows from Theorem 2.6 that ˜u is pathwise optimal.
4 In [1, Appendix II.B] it is shown that under a continuity assumption on the loss function l, the
optimal asymptotic loss in the full information setting is given by E[infu E[l(u,X1)|X0,X−1,...]].
However, a counterexample is given of a discontinuous loss function for which this expression
does not yield the optimal asymptotic loss. The key difference with the expression for L￿given in
Theorem 2.6 is that in the latter the essential inﬁmum runs over u ∈U0, while it is implicit in [1] that
the inﬁmum in the above expression is an essential inﬁmum over u ∈U−∞,0. As the counterexample
in [1] shows, these quantities need not coincide in the absence of continuity assumptions.

14
Ramon van Handel
The assumptions of Corollary 2.11 are stronger than those of Theorem 2.6 in two
respects. First, Assumption 3 is slightly strengthened; however, this is a very mild
requirement. More importantly, a third martingale is assumed to converge uniformly
(pathwise!) in Assumption 2. The latter is not an innocuous requirement: while the
assumption holds in many cases of interest, substantial regularity of the loss function
is needed (see section 3.1 for further discussion). In particular, this requirement is
not automatically satisﬁed in the case of full information, and Theorem 1.1 therefore
does not follow in its entirety from our results. It remains an open question whether
it is possible to establish pathwise optimality of the mean-optimal strategy ˜u under
a substantial weakening of the assumptions of Corollary 2.11.
A particularly simple regularity assumption on the loss is that the decision space
U is ﬁnite. In this case uniform convergence is immediate, so that the assumptions
of Corollary 2.11 reduce essentially to the Y−∞,0-conditional K-property. Therefore,
evidently Corollary 2.11 implies Theorem 1.7. More general conditions that ensure
the validity of the requisite assumptions will be discussed in section 3.
2.3 Weak pathwise optimality
In the previous section, we have seen that a pathwise optimal strategy u￿exists
under general assumptions. However, unlike in the full information case, it is not
clear whether in general (without a nontrivial complexity assumption) the mean-
optimal strategy ˜u is pathwise optimal. In the present section, we will aim to obtain
some additional insight into this issue by considering the notion of weak pathwise
optimality (Deﬁnition 2.3) that is intermediate between pathwise optimality and
mean optimality. This notion is more regularly behaved than pathwise optimality;
in particular, it is straightforward to prove the following simple result.
Lemma 2.12. Suppose that a weakly pathwise optimal strategy u￿exists. Then the
mean-optimal strategy ˜u is also weakly pathwise optimal.
Proof. Let ΛT = 1
T ∑T
k=1Λ ◦T k. As |LT(u)| ≤ΛT for any strategy u, we have
E[(LT(˜u)−LT(u￿))−] ≤ε P[LT(˜u)−LT(u￿) ≥−ε]+E[2ΛT 1LT (˜u)−LT (u￿)<−ε]
for any ε > 0. Note that the sequence (ΛT)T≥1 is uniformly integrable as ΛT →E[Λ]
in L1 by the ergodic theorem. Therefore, using weak pathwise optimality of u￿, it
follows that E[(LT(˜u)−LT(u￿))−] →0 as T →∞. We therefore have
limsup
T→∞
E[|LT(˜u)−LT(u￿)|] = −liminf
T→∞{E[LT(u￿)]−E[LT(˜u)]} ≤0
by mean-optimality of ˜u. It follows easily that ˜u is also pathwise optimal.
￿￿
While Theorem 2.6 does not ensure that the mean-optimal strategy ˜u is pathwise
optimal, the previous lemma guarantees that ˜u is at least weakly pathwise optimal.

Ergodicity, Decisions, and Partial Information
15
However, we will presently show that the latter conclusion may follow under con-
siderably weaker assumptions than those of of Theorem 2.6. Indeed, just as path-
wise optimality was established for conditional K-automorphisms, we will establish
weak optimality for conditionally weakly mixing automorphisms.
Let us begin by developing a general result on weak pathwise optimality, Theo-
rem 2.13 below, that plays the role of Theorem 2.6 in the present setting. The essen-
tial assumption of this general result is that the conditional weak mixing property
(Deﬁnition 1.5) holds uniformly with respect to the loss function ￿. For simplicity
of notation, let us deﬁne as in Theorem 2.6 the optimal asymptotic loss
L￿:= E
￿
essinf
u∈U0
E[￿0(u)|Y−∞,0]
￿
(let us emphasize, however, the Assumption 3 of Theorem 2.6 need not hold in the
present setting!) In addition, let us deﬁne the modiﬁed loss functions
¯￿0(u) := ￿0(u)−E[￿0(u)|Y−∞,0],
¯￿M
0 (u) := ￿0(u)1Λ≤M −E[￿0(u)1Λ≤M|Y−∞,0].
The proof of the following theorem will be given in section 4.3.
Theorem 2.13. Suppose that the uniform conditional mixing assumption
lim
M→∞limsup
T→∞
￿￿￿￿
1
T
T
∑
k=1
esssup
u,u￿∈U0
|E[{ ¯￿M
0 (u)◦T −k} ¯￿M
0 (u￿)|Y−∞,0]|
￿￿￿￿
1
= 0
holds. Then the mean-optimal strategy ˜u is weakly pathwise optimal, and the optimal
long time-average loss satisﬁes the ergodic theorem LT(˜u) →L￿in L1.
Remark 2.14. We have assumed throughout that the loss function ￿is dominated in
L1. If the loss is in fact dominated in L2, that is, |￿(u,ω)| ≤Λ(ω) with Λ ∈L2, then
the assumption of Theorem 2.13 is evidently implied by the natural assumption
1
T
T
∑
k=1
esssup
u,u￿∈U0
|E[{ ¯￿0(u)◦T −k} ¯￿0(u￿)|Y−∞,0]| T→∞
−−−→0
in L1,
and in this case LT(˜u) →L￿in L2 (by dominated convergence). The additional trun-
cation in Theorem 2.13 is included only to obtain a result that holds in L1.
Conceptually, as in Theorem 2.6, the assumption of Theorem 2.13 combines a
conditional mixing assumption and a complexity assumption. Indeed, the condi-
tional weak mixing property relative to Y−∞,0 (Deﬁnition 1.5) implies that
1
T
T
∑
k=1
|E[{f ◦T −k} g|Y−∞,0]−E[f ◦T −k|Y−∞,0]E[g|Y−∞,0]| T→∞
−−−→0
in L1
for every f,g ∈L2 (indeed, for simple functions f,g this follows directly from the
deﬁnition, and the claim for general f,g follows by approximation in L2). Therefore,

16
Ramon van Handel
in the absence of the essential supremum, the assumption of Theorem 2.13 reduces
essentially to the assumption that the dynamical system (Ω,B,P,T) is conditionally
weak mixing relative to Y−∞,0. However, Theorem 2.13 requires in addition that
the convergence in the deﬁnition of the conditional weak mixing property holds
uniformly with respect to the possible decisions u ∈U0. This will be the case when
the loss function ￿is not too complex (cf. section 3). For example, in the extreme
case where the decision space U is ﬁnite, uniformity is automatic, and thus Theorem
1.8 in the introduction follows immediately from Theorem 2.13.
Recall that a pathwise optimal strategy is necessarily weakly pathwise optimal.
This is reﬂected, for example, in Theorems 1.7 and 1.8: indeed, note that
￿P[A∩T kB|Z]−P[A|Z]P[T kB|Z]￿1
= ￿E[{1A −P[A|Z]}1T kB|Z]￿1
≤￿E[{1A −P[A|Z]}P[T kB|T k−nX]|Z]￿1 +￿1T kB −P[T kB|T k−nX]￿1
≤￿P[A|Z∨T k−nX]−P[A|Z]￿1 +￿1B −P[B|T −nX]￿1
for any n,k, so that the conditional K-property implies the conditional weak mix-
ing property (relative to any σ-ﬁeld Z) by letting k →∞, then n →∞. Along the
same lines, one can show that a slight variation of the assumptions of Theorem 2.6
imply the assumption of Theorem 2.13 (modulo minor issues of truncation, which
could have been absorbed in Theorem 2.6 also at the expense of heavier notation).
It is not entirely obvious, at ﬁrst sight, how far apart the conclusions of our main
results really are. For example, in the setting of full information, cf. Example 2.10,
the assumption of Theorem 2.13 holds automatically (as then ¯￿M
0 (u)◦T −k is Y−∞,0-
measurable for every u ∈U0 and k ≥1). Moreover, the reader can easily verify that
in all the examples we have given where no pathwise optimal strategy exists (Ex-
amples 1.2, 1.3, 2.8, 2.9), even the existence of a weakly pathwise optimal strategy
fails. It is therefore tempting to assume that in a typical situation where a weakly
pathwise optimal strategy exists, there will likely also be a pathwise optimal strat-
egy. The following example, which is a manifestation of a rather surprising result in
ergodic theory due to Conze [6], provides some evidence to the contrary.
Example 2.15 (Generic transformations). In this example, we ﬁx the probability
space (Ω,B,P), where Ω= [0,1] with its Borel σ-ﬁeld B and the Lebesgue mea-
sure P. We will consider the decision space U = {0,1} and loss function ￿deﬁned
as
￿(u,ω) = −u(1[0,1/2](ω)−1/2)
for (u,ω) ∈U ×Ω.
Moreover, we will consider the setting of blind decisions, that is, Y is trivial.
We have not yet deﬁned a transformation T. Our aim is to prove the following: for
a generic invertible measure-preserving transformation T, there is a mean-optimal
strategy ˜u that is weakly pathwise optimal but not pathwise optimal. This shows not
only that there can be a substantial gap between Theorems 1.7 and 1.8, but that this
is in fact the typical situation (at least in the sense of weak topology).

Ergodicity, Decisions, and Partial Information
17
Let us recall some basic notions. Denote by T the set of all invertible measure-
preserving transformations of (Ω,B,P). The weak topology on T is the topology
generated by the basic neighborhoods B(T0,B,ε) = {T ∈T : P[TB￿T0B] < ε} for
all T0 ∈T , B ∈B, ε > 0. A property is said to hold for a generic transformation if
it holds for every transformation T in a dense Gδ subset of T . A well-known result
of Halmos [13] states that a generic transformation is weak mixing. Therefore, for
a generic transformation, any mean-optimal strategy ˜u is weakly pathwise optimal
by Theorem 1.8. This proves the ﬁrst part of our statement.
Of course, in the present setting, E[￿k(u)|Y0,k] = E[￿k(u)] = 0 for every decision
u ∈U. Therefore, every admissible strategy u is mean-optimal, and the optimal
mean loss is given by L￿= 0, regardless of the choice of transformation T ∈T . It
is natural to choose a stationary strategy ˜u (for example, ˜uk = 1 for all k) so that
limT→∞LT(˜u) = L￿a.s. We will show that for a generic transformation, the strategy
˜u is not pathwise optimal. To this end, it evidently sufﬁces to ﬁnd another strategy
u such that liminfT→∞LT(u) < L￿with positive probability.
To this end, we use the following result of Conze that can be read off from the
proof of [6, Theorem 5]: there exists a sequence nk ↑∞with k/nk →1/2 such that
for every 0 < α < 1 and 1/2 < λ < 1, a generic transformation T satisﬁes
P
￿
limsup
N→∞
1
N
N
∑
k=1
1[0,1/2] ◦T nk ≥λ
￿
≥1−α.
Deﬁne the strategy u such that un = 1 if n = nk for some k, and un = 0 otherwise.
Then, for a generic transformation T, we have with probability at least 1−α
liminf
T→∞LnT (u) = −limsup
T→∞
1
nT
T
∑
k=1
(1[0,1/2] ◦T nk −1/2) ≤−2λ −1
4
.
In words, we have shown that for a generic transformation T, the time-average loss
of the mean-optimal strategy ˜u exceeds that of the strategy u inﬁnitely often by
almost 1/4 with almost unit probability. Thus the mean-optimal strategy ˜u fails to
be pathwise optimal in a very strong sense, and our claim is established.
Example 2.15 only shows that there is a mean-optimal strategy ˜u that is weakly
pathwise optimal but not pathwise optimal. It does not make any statement about
whether or not a pathwise optimal strategy u￿actually exists. However, we do not
know of any mechanism that might lead to pathwise optimality in such a setting. We
therefore conjecture that for a generic transformation a pathwise optimal strategy
in fact fails to exist at all, so that (unlike in the full information setting) pathwise
optimality and weak pathwise optimality are really distinct notions.
The result of Conze used in Example 2.15 originates from a deep problem in
ergodic theory that aims to understand the validity of individual ergodic theorems
for subsequences, cf. [6, 2] and the references therein. A general characterization of
such ergodic properties does not appear to exist, which suggests that the pathwise
optimality property may be difﬁcult to characterize beyond general sufﬁcient con-
ditions such as Theorem 2.6. In contrast, the weak pathwise optimality property is

18
Ramon van Handel
much more regularly behaved. The following theorem, which will be proved in sec-
tion 4.4 below, provides a complete characterization of weak pathwise optimality in
the special case that the observation ﬁeld Y is invariant.
Theorem 2.16. Let (Ω,B,P,T) be an ergodic dynamical system, and suppose that
(Ω,B,P) is a standard probability space and that Y ⊆B is an invariant σ-ﬁeld
(that is, Y = T −1Y). Then the following are equivalent:
1. (Ω,B,P,T) conditionally weak mixing relative to Y.
2. For every bounded loss function ￿: U × Ω→R with ﬁnite decision space
cardU < ∞, there exists a weakly pathwise optimal strategy.
The invariance of Y is automatic in the setting of blind decisions (as Y is trivial),
in which case Theorem 2.16 yields a decision-theoretic characterization of the weak
mixing property. In more general observation models, invariance of Y may be an un-
natural requirement from the point of view of decisions under partial information,
as it implies that there is no information gain over time. On the other hand, appli-
cations of the notion of conditional weak mixing relative to a σ-ﬁeld Z in ergodic
theory almost always assume that Z is invariant (e.g., [26]). Theorem 2.16 yields a
decision-theoretic interpretation of this property by choosing Y = Z.
3 Complexity and conditional ergodicity
3.1 Universal complexity assumptions
The goal of this section is to develop complexity assumptions on the loss function
￿that ensure that the uniform convergence assumptions in our main results hold
regardless of any properties of the transformation T or observations Y. While such
universal complexity assumptions are not always necessary (for example, in the full
information setting uniform convergence holds regardless of the loss function), they
frequently hold in practice and provide easily veriﬁable conditions that ensure that
our results hold in a broad class of decision problems with partial information.
The simplest assumption is Grothendieck’s notion of equimeasurability [12].
Deﬁnition 3.1. The loss function ￿: U ×Ω→R on the probability space (Ω,B,P)
is said to be equimeasurable if for every ε > 0, there exists Ωε ∈B with P[Ωε] ≥
1−ε such that the class of functions {￿0(u)1Ωε : u ∈U} is totally bounded in L∞(P).
The beauty of this simple notion is that it ensures uniform convergence of almost
anything. In particular, we obtain the following results.
Lemma 3.2. Suppose that the loss function ￿is equimeasurable. Then Assumption
2 of Corollary 2.11 holds, and thus Assumption 2 of Theorem 2.6 holds as well,
provided that X is a generating σ-ﬁeld (that is, ￿
n T −nX = B).

Ergodicity, Decisions, and Partial Information
19
Proof. Let us establish the ﬁrst line of Assumption 2. Fix ε > 0 and Ωε as in Def-
inition 3.1. Then there exist N < ∞measurable functions l1,...,lN : Ω→R such
that for every u ∈U, there exists k(u) ∈{1,...,N} such that
￿￿0(u)1Ωε −lk(u)1Ωε￿∞≤ε
(and u ￿→k(u) can clearly be chosen to be measurable). It follows that
esssup
u∈U0
￿￿E[￿0(u)|Y−∞,0 ∨T −nX]−￿0(u)
￿￿≤max
1≤k≤N
￿￿E[lk1Ωε|Y−∞,0 ∨T −nX]−lk1Ωε
￿￿
+2ε +E[Λ1Ωcε |Y−∞,0 ∨T −nX]+Λ1Ωcε .
As X is generating, the martingale convergence theorem gives
limsup
n→∞
￿￿￿￿esssup
u∈U0
￿￿E[￿0(u)|Y−∞,0 ∨T −nX]−￿0(u)
￿￿
￿￿￿￿
1
≤2ε +E[2Λ1Ωcε ].
Letting ε ↓0 yields the ﬁrst line of Assumption 2. The remaining statements of
Assumption 2 follow by an essentially identical argument.
￿￿
Lemma 3.3. Suppose that the following conditional mixing assumption holds:
lim
M→∞limsup
T→∞
￿￿￿￿
1
T
T
∑
k=1
|E[{ ¯￿M
0 (u)◦T −k} ¯￿M
0 (u￿)|Y−∞,0]|
￿￿￿￿
1
= 0
for every u,u￿∈U.
If the loss function ￿is equimeasurable, then the assumption of Theorem 2.13 holds.
Proof. The proof is very similar to that of Lemma 3.2 and is therefore omitted.
￿￿
As an immediate consequence of these lemmas, we have:
Corollary 3.4. The conclusions of Theorems 1.7 and 1.8 remain in force if the as-
sumption that U is ﬁnite is replaced by the assumption that ￿is equimeasurable.
We now give a simple condition for equimeasurability that sufﬁces in many cases.
It is closely related to a result of Mokobodzki (cf. [9, Theorem IX.19]).
Lemma 3.5. Suppose that U is a compact metric space and that u ￿→￿(u,ω) is
continuous for a.e. ω ∈Ω. Then ￿is equimeasurable.
Proof. As U is a compact metric space (with metric d), it is certainly separable. Let
U0 ⊆U be a countable dense set, and deﬁne the functions
bn =
sup
u,u￿∈U0:d(u,u￿)≤n−1 |￿0(u)−￿0(u￿)|.
bn is measurable, as it is the supremum of countably many random variables. More-
over, for almost every ω, the function u ￿→￿(u,ω) is uniformly continuous (being
continuous on a compact metric space). Therefore, bn ↓0 a.s. as n →∞.

20
Ramon van Handel
By Egorov’s theorem, there exists for every ε > 0 a set Ωε with P[Ωε] ≥1 −ε
such that ￿bn1Ωε￿∞↓0. We claim that {￿0(u)1Ωε : u ∈U} is compact in L∞. Indeed,
for any sequence (un)n≥1 ⊆U we may choose a subsequence (unk)k≥1 that converges
to u∞∈U. Then for every r, we have |￿0(unk) −￿0(u∞)| ≤br for all k sufﬁciently
large, and therefore ￿￿0(unk)1Ωε −￿0(u∞)1Ωε￿∞→0.
￿￿
Let us give two standard examples of decision problems (cf. [1, 24]).
Example 3.6 (￿p-prediction). Consider the stochastic process setting (X,Y), and let
f be a bounded function. The aim is, at each time k, to choose a predictor uk of
f(Xk+1) on the basis of the observation history Y0,...,Yk. We aim to minimize the
pathwise time-average ￿p-prediction loss 1
T ∑T
k=1 |uk −f(Xk+1)|p (p ≥1). This is
a particular decision problem with partial information, where the loss function is
given by ￿0(u) = |u−f(X1)|p and the decision space is U = [infx f(x),supx f(x)]. It
is immediate that ￿is equimeasurable by Lemma 3.5.
Example 3.7 (Log-optimal portfolios). Consider a market with d securities (e.g., d −
1 stocks and one bond) whose returns in day k are given by the random variable Xk
with values in Rd
+. The decision space U = {p ∈Rd
+ : ∑d
i=1 pi = 1} is the simplex:
ui
k represents the fraction of wealth invested in the ith security in day k. The total
wealth at time T is therefore given by ∏T
k=1￿uk,Xk￿. We only have access to partial
information Yk in day k, e.g., from news reports. We aim to choose an investment
strategy on the basis of the available information that maximizes the wealth, or,
equivalently, its growth 1
T ∑T
k=1 log￿uk,Xk￿. This corresponds to a decision problem
with partial information for the loss function ￿0(u) = −log￿u,X0￿.
In order for the loss to be dominated in L1, we impose the mild assumption
E[Λ] < ∞with Λ = ∑d
i=1 |logXi
0|. We claim that the loss ￿is then also equimeasur-
able. Indeed, as E[Λ] < ∞, the returns must satisfy Xi
0 > 0 a.s. for every i. Therefore,
equimeasurability follows directly from Lemma 3.5.
As we have seen above, equimeasurability follows easily when the loss function
possesses some mild pointwise continuity properties. However, there are situations
when this may not be the case. In particular, suppose that ￿(u,ω) only takes the
values 0 and 1, that is, our decisions are sets (as may be the case, for example, in
predicting the shape of an oil spill or in sequential classiﬁcation problems). In such a
case, equimeasurability will rarely hold, and it is of interest to investigate alternative
complexity assumptions. As we will presently explain, equimeasurability is almost
necessary to obtain a universal complexity assumption for Corollary 2.11; however,
in the setting of Theorem 2.6, the assumption can be weakened considerably.
The simplicity of the equimeasurability assumption hides the fact that there are
two distinct uniformity assumptions in Corollary 2.11: we require uniform conver-
gence of both martingales and reverse martingales, which are quite distinct phenom-
ena (cf. [18, 17]). The uniform convergence of martingales can be restrictive.
Example 3.8 (Uniform martingale convergence). Let (Gn)n≥1 be a ﬁltration such
that each Gn = σ{πn} is generated by a ﬁnite measurable partition πn of the prob-
ability space (Ω,B,P). Let L : N ×Ω→R a bounded function such that L(u,·) is

Ergodicity, Decisions, and Partial Information
21
G∞-measurable for every u ∈N. Then E[L(u,·)|Gn] →L(u,·) a.s. for every u. We
claim that if this martingale convergence is in fact uniform, that is,
sup
u∈N
|E[L(u,·)|Gn]−L(u,·)| n→∞
−−−→0
in L1,
then L must necessarily be equimeasurable. To see this, let us ﬁrst extract a subse-
quence nk ↑∞along which the uniform martingale convergence holds a.s. Fix ε > 0.
By Egorov’s theorem, there exists a set Ωε with P[Ωε] ≥1−ε such that
sup
u∈N
￿E[L(u,·)|Gnk]1Ωε −L(u,·)1Ωε￿∞
k→∞
−−−→0.
Therefore, for every α > 0, there exists k such that
sup
u∈N
￿α￿α−1E[L(u,·)|Gnk]1Ωε￿−L(u,·)1Ωε￿∞≤2α.
But as Gn is ﬁnitely generated, we can write
E[L(u,·)|Gn]1Ωε = ∑
P∈πn
Ln,u,P1P∩Ωε,
with |Ln,u,P| ≤￿L￿∞for all n,u,P. In particular, {α￿α−1E[L(u,·)|Gn]1Ωε￿: u ∈N}
is a ﬁnite family of random variables for every n. We have therefore established that
the family {L(u,·)1Ωε : u ∈N} is totally bounded in L∞.
In the context of Corollary 2.11, the previous example can be interpreted as fol-
lows. Suppose that the observations are ﬁnite-valued, that is, Y is a ﬁnitely generated
σ-ﬁeld. Let us suppose, for simplicity, that the decision space U is countable (the
same conclusion holds for general U modulo some measurability issues). Then, if
the third line of Assumption 2 in Corollary 2.11 holds, then the conditioned loss
E[￿0(u)|Y−∞,0] is necessarily equimeasurable. While it is possible that the condi-
tioned loss is equimeasurable even when the loss ￿is not (e.g., in the case of blind
decisions), this is somewhat unlikely to be the case given a nontrivial observation
structure. Therefore, it appears that equimeasurability is almost necessary to obtain
universal complexity assumptions in the setting of Corollary 2.11.
The situation is much better in the setting of Theorem 2.6, however. While the
ﬁrst line of Assumption 2 in Theorem 2.6 is still a uniform martingale convergence
property, the σ-ﬁeld X cannot be ﬁnitely generated except in trivial cases. In fact, in
many cases the loss ￿will be T −nX-measurable for some n < ∞, in which case the
ﬁrst line of Assumption 2 is automatically satisﬁed (in particular, in the stochastic
process setting, this will be the case for ﬁnitary loss ￿0(u) = l(u,Xn1,...,Xnk) if we
choose X = σ{Xk,Yk : k ≤0}). The remainder of Assumption 2 is a uniform reverse
martingale convergence property, which holds under much weaker assumptions.
Deﬁnition 3.9. The loss ￿: U ×Ω→R on (Ω,B) is said to be universally bracket-
ing if for every probability measure P and ε,M > 0, the family {￿0(u)1Λ≤M : u ∈U}
can be covered by ﬁnitely many brackets { f : g ≤f ≤h} with ￿g−h￿L1(P) ≤ε.

22
Ramon van Handel
Lemma 3.10. Let (Ω,B) be a standard space, and let X,Y be countably generated.
Suppose the loss ￿is universally bracketing and ﬁnitary (that is, for some n ∈Z,
￿0(u) is T −nX-measurable for all u ∈U). Then Assumption 2 of Theorem 2.6 holds.
Proof. The ﬁnitary assumption trivially implies the ﬁrst line of Assumption 2. The
second line follows along the lines of the proof of [17, Corollary 1.4(2⇒7)].5
￿￿
To show that universal bracketing can be much weaker than equimeasurability,
we give a simple example in the context of set estimation.
Example 3.11 (Conﬁdence intervals). Consider the stochastic process setting (X,Y)
where X takes values in the set [−1,1], and ﬁx ε > 0. We would like to pin down the
value of Xk up to precision ε; that is, we want to choose uk ∈[−1,1] as a function
of the observations Y0,...,Yk such that uk ≤Xk < uk +ε as often as possible. This is
a partial information decision problem with loss function ￿0(u) = 1R\[u,u+ε[(X0).
The proof of the universal bracketing property of ￿is standard. Given P and
ε > 0, we choose −1 = a0 < a1 < ··· < an = 1 (for some ﬁnite n) in such a way
that P[ai < X0 < ai+1] ≤ε for all i (note that every atom of X0 with probability
greater than ε is one of the values ai). Put each function ￿0(u) such that u = ai
or u + ε = ai for some i in its own bracket, and consider the additional brackets
{ f : 1R\]ai−1,a j+1[ ≤f ≤1R\[ai,aj]} for all 1 ≤i ≤j < n. Then evidently each of the
brackets has diameter not exceeding 2ε, and for every u ∈U the function ￿0(u) is
included in one of the brackets thus constructed.
On the other hand, whenever the law of X0 is not purely atomic, the loss ￿cannot
be equimeasurable. Indeed, as ￿￿0(u)1Ωε −￿0(u￿)1Ωε￿∞= 1 whenever ￿0(u)1Ωε ￿=
￿0(u￿)1Ωε, it is impossible for {￿0(u)1Ωε : u ∈U} to be totally bounded in L∞for
any inﬁnite set Ωε (and therefore for any set of sufﬁciently large measure).
In [17] a detailed characterization is given of the universal bracketing property.
In particular, it is shown that a uniformly bounded, separable loss ￿on a standard
measurable space is universally bracketing if and only if {￿0(u) : u ∈U} is a uni-
versal Glivenko-Cantelli class, that is, a class of functions for which the law of
large numbers always holds uniformly. Many useful methods have been developed
in empirical process theory to verify this property, cf. [10, 29]. In particular, for a
separable {0,1}-valued loss, a very useful sufﬁcient condition is that {￿0(u) : u ∈U}
is a Vapnik-Chervonenkis class. We refer to [17, 10, 29] for further details.
3.2 Conditional absolute regularity
In the previous section, we have developed universal complexity assumptions that
are applicable regardless of other details of the model. In the present section, we
5 The pointwise separability assumption in [17, Corollary 1.4(2⇒7)] is not needed here, as the
essential supremum can be reduced to a countable supremum as in the proof of Lemma 2.5.

Ergodicity, Decisions, and Partial Information
23
will in some sense take the opposite approach: we will develop a sufﬁcient condi-
tion for a stronger version of the conditional K-property (in the stochastic process
setting) under which no complexity assumptions are needed. This shows that there
is a tradeoff between mixing and complexity; if the mixing assumption is strength-
ened, then the complexity assumption can be weakened. An additional advantage of
the sufﬁcient condition to be presented is that it is in practice one of the most easily
veriﬁable conditions that ensures the conditional K-property.
In the remainder of this section, we will work in the stochastic process setting.
Let (X,Y) be a stationary ergodic process taking values in the Polish space E × F.
We deﬁne Yn,m = σ{Yk : n ≤k ≤m} and Xn,m = σ{Xk : n ≤k ≤m} for n ≤m, and
we consider the observation and generating ﬁelds Y = σ{Y0}, X = X−∞,0 ∨Y−∞,0.
In this setting, the conditional K-property relative to Y−∞,0 reduces to
∞
￿
k=1
(Y−∞,0 ∨X−∞,−k) = Y−∞,0
modP.
If Y is trivial (that is, the observations Y are noninformative), this reduces to the
statement that X has a trivial past tail σ-ﬁeld, that is, X is regular (or purely nonde-
terministic) in the sense of Kolmogorov. This property is often fairly easy to check:
for example, any Markov chain whose law converges weakly to a unique invari-
ant measure is regular (cf. [28, Prop. 3]). When Y is nontrivial, the conditional
K-property is generally not so easy to check, however. We therefore give a con-
dition, arising from ﬁltering theory [27], that allows to deduce conditional mixing
properties from their more easily veriﬁable unconditional counterparts.
We will require two assumptions. The ﬁrst assumption states that the pair (X,Y)
is absolutely regular in the sense of Volkonski˘ı and Rozanov [30] (this property is
also known as β-mixing). Absolute regularity is a strengthening of the regularity
property; assuming regularity of (X,Y) is not sufﬁcient for what follows [16]. Many
techniques have been developed to verify the absolute regularity property; for ex-
ample, any Harris recurrent and aperiodic Markov chain is absolutely regular [22].
Deﬁnition 3.12. The process (X,Y) is said to be absolutely regular if
￿￿P[(Xk,Yk)k≥n ∈·|X−∞,0 ∨Y−∞,0]−P[(Xk,Yk)k≥n ∈·]
￿￿
TV
n→∞
−−−→0
in L1.
By itself, however, absolute regularity of (X,Y) is not sufﬁcient for the con-
ditional K-property, as can be seen in Example 1.3. In this example, the relation
between the processes X and Y is very singular, so that things go wrong when we
condition. The following nondegeneracy assumption rules out this possibility.
Deﬁnition 3.13. The process (X,Y) is said to be nondegenerate if
P[Y1,...,Ym ∈·|Z−∞,0 ∨Zm+1,∞] ∼P[Y1,...,Ym ∈·|Y−∞,0 ∨Ym+1,∞]
a.s.
for every 1 ≤m < ∞, where Zn,m := Xn,m ∨Yn,m.

24
Ramon van Handel
The nondegeneracy assumption ensures that the null sets of the law of the obser-
vations Y do not depend too much on the unobserved process X. The assumption is
often easily veriﬁed. For example, if Yk = f(Xk)+ηk where ηk is an i.i.d. sequence
of random variables with strictly positive density, then the conditional distributions
in Deﬁnition 3.13 have strictly positive densities and are therefore equivalent a.s.
Theorem 3.14 ([27]). If (X,Y) is absolutely regular and nondegenerate, then
∞
￿
k=1
(Y−∞,0 ∨X−∞,−k) = Y−∞,0
modP.
Theorem 3.14 provides a practical method to check the conditional K-property.
However, the proof of Theorem 3.14 actually yields a much stronger statement. It is
shown in [27, Theorem 3.5] that if (X,Y) is absolutely regular and nondegenerate,
then X is conditionally absolutely regular relative to Y−∞,∞in the sense that
￿￿P[(Xk)k≥n ∈·|X−∞,0 ∨Y−∞,∞]−P[(Xk)k≥n ∈·|Y−∞,∞]
￿￿
TV
n→∞
−−−→0
in L1.
Moreover, it is shown6 that under the same assumptions [27, Proposition 3.9]
P[(Xk)k≤0 ∈·|Y−∞,0] ∼P[(Xk)k≤0 ∈·|Y−∞,∞]
a.s.
From these properties, we can deduce the following result.
Theorem 3.15. In the setting of the present section, suppose that (X,Y) is absolutely
regular and nondegenerate, and consider a loss function of the form ￿0(u) = l(u,X0).
Then the conclusions of Theorem 2.6 hold.
The key point about Theorem 3.15 is that no complexity assumption is imposed:
the loss function l(u,x) may be an arbitrary measurable function (as long as it is
dominated in L1 in accordance with our standing assumption). The explanation for
this is that the conditional absolute regularity property is so strong that the reg-
ular conditional probabilities P[X0 ∈·|Y−∞,∞∨X−∞,−n] converge in total variation.
Therefore, the corresponding reverse martingales converge uniformly over any dom-
inated family of measurable functions. The strength of the conditional mixing prop-
erty therefore eliminates the need for any additional complexity assumptions. In
contrast, we may certainly have pathwise optimal strategies when absolute regular-
ity fails, but then a complexity assumption is essential (cf. Example 2.8).
The proof of Theorem 3.15 will be given in section 4.5. The proof is a straightfor-
ward adaptation of Theorem 2.6; unfortunately, the fact that the conditional absolute
regularity property is relative to Y−∞,∞rather than Y−∞,0 complicates a direct veri-
ﬁcation of the assumptions of Theorem 2.6 (while this should be possible along the
lines of [27], we will follow the simpler route here). The results of [27] could also
6 Some of the statements in [27] are time-reversed as compared to their counterparts stated here.
However, as both the absolute regularity and the nondegeneracy assumptions are invariant under
time reversal (cf. [30] for the former; the latter is trivial), the present statements follow immediately.

Ergodicity, Decisions, and Partial Information
25
be used to obtain the conclusion of Corollary 2.11 in the setting of Theorem 3.15
under somewhat stronger nondegeneracy assumptions.
3.3 Hidden Markov models and nonlinear ﬁlters
The goal of the present section is to explore some implications of our results to
ﬁltering theory. For simplicity of exposition, we will restrict attention to the classical
setting of (general state space) hidden Markov models (see, e.g., [4]).
We adopt the stochastic process setting and notations of the previous section. In
addition, we assume that (X,Y) is a hidden Markov model, that is, a Markov chain
whose transition kernel can be factored as ˜P(x,y,dx￿,dy￿) = P(x,dx￿)Φ(x￿,dy￿).
This implies that the process X is a Markov chain in its own right, and that the
observations Y are conditionally independent given X. In the following, we will as-
sume that the observation kernel Φ has a density, that is, Φ(x,dy) = g(x,y)ϕ(dy)
for some measurable function g and reference measure ϕ.
A fundamental object in this theory is the nonlinear ﬁlter Πk, deﬁned as
Πk := P[Xk ∈·|Y0,...,Yk].
The measure-valued process Π = (Πk)k≥0 is itself a (nonstationary) Markov chain
[16] with transition kernel P. To study the stationary behavior of the ﬁlter, which
is of substantial interest in applications (see, for example, [15] and the references
therein), one must understand the relationship between the ergodic properties of X
and Π. The following result, proved in [16], is essentially due to Kunita [20].
Theorem 3.16. Suppose that the transition kernel P possesses a unique invariant
measure (that is, X is uniquely ergodic). Then the ﬁlter transition kernel P pos-
sesses a unique invariant measure (that is, Π is uniquely ergodic) if and only if
∞
￿
k=1
(Y−∞,0 ∨X−∞,−k) = Y−∞,0
modP.
Evidently, ergodicity of the ﬁlter is closely related to the conditional K-property.
We will exploit this fact to prove a new optimality property of nonlinear ﬁlters.
The usual interpretation of the ﬁlter Πk is that one aims to track to current loca-
tion Xk of the unobserved process on the basis of the observation history Y0,...,Yk.
By the elementary property of conditional expectations, Πk(f) provides, for any
bounded test function f, an optimal mean-square error estimate of f(Xk):
E
￿
{f(Xk)−Πk(f)}2￿
≤E
￿
{ f(Xk)−ˆfk(Y0,...,Yk)}2￿
for any measurable ˆfk.
This interpretation may not be satisfying, however, if only one sample path of the
observations is available (recall Examples 1.2 and 1.3): one would rather show that

26
Ramon van Handel
liminf
T→∞
￿
1
T
T
∑
k=1
{f(Xk)−ˆfk(Y0,...,Yk)}2 −1
T
T
∑
k=1
{f(Xk)−Πk(f)}2
￿
≥0
a.s.
for any alternative sequence of estimators ( ˆfk)k≥0. If this property holds for any
bounded test function f, the ﬁlter will be said to be pathwise optimal.
Corollary 3.17. Suppose that the ﬁltering process Π is uniquely ergodic. Then the
ﬁlter is both mean-square optimal and pathwise optimal.
Proof. Note that the ﬁlter Πk(f) is the mean-optimal policy for the partial informa-
tion decision problem with loss ￿0(u) = {f(X0)−u}2. As the latter is equimeasur-
able, the result follows directly from Theorem 3.16 and Corollary 2.11.
￿￿
The interaction between our main results and the ergodic theory of nonlinear
ﬁlters is therefore twofold. On the one hand, our main results imply that ergodic
nonlinear ﬁlters are always pathwise optimal. Conversely, Theorem 3.16 shows that
ergodicity of the ﬁlter is a sufﬁcient condition for our main results to hold in the
context of hidden Markov models with equimeasurable loss. This provides another
route to establishing the conditional K-property: the ﬁltering literature provides a
variety of methods to verify ergodicity of the ﬁlter [14, 5, 7, 27]. It should be noted,
however, that ergodicity of the ﬁlter is not necessary for the conditional K-property
to hold, even in the setting of hidden Markov models.
Example 3.18. Consider the hidden Markov model (X,Y) where X is the station-
ary Markov chain such that X0 ∼Uniform([0,1]) and Xk+1 = 2Xk mod1, Yk = 0
for all k ∈Z (that is, we have noninformative observations). Clearly the tail σ-
ﬁeld ￿
n X−∞,n is nontrivial, and thus the ﬁlter fails to be ergodic by Theorem 3.16.
Nonetheless, we claim that the conditional K-property holds, so that our main results
apply for any equimeasurable loss; in particular, the ﬁlter is pathwise optimal.
The key point is that, even in the hidden Markov model setting, one need not
choose the “canonical” generating σ-ﬁeld X = X−∞,0 in Deﬁnition 1.6. In the
present example, we choose instead X = σ{1Xk>1/2 : k ≤0}. To verify the condi-
tional K-property, note that (1Xk>1/2)k∈Z are i.i.d. Bernoulli(1/2) random variables
and
Xk =
∞
∑
￿=0
2−￿−11Xk+￿>1/2
a.s.
for all k ∈Z.
Thus X ⊂T −1X by construction, ￿
k T −kX = σ{Xn : n ∈Z} is a generating σ-ﬁeld,
and ￿
k T kX is trivial by the Kolmogorov zero-one law.
Let us now consider the decision problem in the setting of a hidden Markov
model with equimeasurable loss function ￿0(u) = l(u,X0). If the ﬁlter is ergodic,
then Corollary 3.4 ensures that the mean-optimal strategy ˜u is pathwise optimal. In
this setting, the mean-optimal strategy can be expressed in terms of the ﬁlter:
˜uk = argmin
u∈U
E[l(u,Xk)|Y0,...,Yk] = argmin
u∈U
￿
l(u,x)Πk(dx).

Ergodicity, Decisions, and Partial Information
27
When Xk takes values in a ﬁnite set E = {1,...,d}, the ﬁlter can be recursively
computed in a straightforward manner [4]. In this case, the mean-optimal strategy
˜u can be implemented directly. On the other hand, when E is a continuous space,
the conditional measure Πk is an inﬁnite-dimensional object which cannot be com-
puted exactly except in special cases. However, Πk can often be approximated very
efﬁciently by recursive Monte Carlo approximations Π N
k = 1
N ∑N
i=1 δZN
k (i), known
as particle ﬁlters [4], that converge to the true ﬁlter Πk as the number of particles
increases N →∞. This suggests to approximate the mean-optimal strategy ˜u by
˜uk ≈˜uN
k := argmin
u∈U
￿
l(u,x)Π N
k (dx) = argmin
u∈U
1
N
N
∑
i=1
l(u,ZN
k (i)).
The strategy ˜uN is a type of sequential stochastic programming algorithm to approx-
imate the mean-optimal strategy. In this setting, it is of interest to establish whether
the strategy ˜uN is in fact approximately pathwise optimal, at least in the weak sense.
To this end, we prove the following approximation lemma.
Lemma 3.19. In the hidden Markov model setting with equimeasurable loss ￿0(u) =
l(u,X0), suppose that the ﬁlter is ergodic, and let Π N
k be an approximation of Πk. If
lim
N→∞limsup
T→∞
E
￿
1
T
T
∑
k=1
esssup
u∈U0,k
|Π N
k (l(u,·))−Πk(l(u,·))|
￿
= 0,
then the strategy ˜uN is approximately weakly pathwise optimal in the sense that
lim
N→∞liminf
T→∞P[LT(u)−LT(˜uN) ≥−ε] = 1
for every ε > 0
holds for every admissible strategy u.
Proof. We begin by noting that
P[LT(u)−LT(˜uN) < −ε] ≤P[LT(u)−LT(˜u) < −ε/2]+P[LT(˜uN)−LT(˜u) > ε/2].
Under the present assumptions, the mean-optimal strategy ˜u is (weakly) pathwise
optimal. It follows7 as in the proof of Lemma 2.12 that E[(LT(˜uN)−LT(˜u))−] →0
as T →∞, and we obtain for any admissible strategy u and ε > 0
limsup
T→∞
P[LT(u)−LT(˜uN) < −ε] ≤2
ε limsup
T→∞
E[LT(˜uN)−LT(˜u)].
To proceed, we estimate
7 As particle ﬁlters employ a random sampling mechanism, the strategy ˜uN is technically speaking
not admissible in the sense of this paper: Π N
k (and therefore ˜uN
k ) depends also on auxiliary sam-
pling variables ξ0,...,ξk that are independent of Y0,...,Yk. However, it is easily seen that all our
results still hold when such randomized strategies are considered. Indeed, it sufﬁces to condition
on (ξk)k≥0, so that all our results apply immediately under the conditional distribution.

28
Ramon van Handel
E[LT(˜uN)−LT(˜u)] = E
￿
1
T
T
∑
k=1
￿
{l( ˜uN
k ,x)−l( ˜uk,x)}Πk(dx)
￿
≤E
￿
1
T
T
∑
k=1
￿
{l( ˜uN
k ,x)−l( ˜uk,x)}Π N
k (dx)
￿
+2E
￿
1
T
T
∑
k=1
esssup
u∈U0,k
|Π N
k (l(u,·))−Πk(l(u,·))|
￿
.
But note that by the deﬁnition of ˜uN
￿
{l( ˜uN
k ,x)−l( ˜uk,x)}Π N
k (dx) = inf
u∈U
￿
l(u,x)Π N
k (dx)−
￿
l( ˜uk,x)Π N
k (dx) ≤0.
The proof is therefore easily completed by applying the assumption.
￿￿
Evidently, the key difﬁculty in this problem is to control the time-average error
of the ﬁlter approximation (in a norm determined by the loss function l) uniformly
over the time horizon. This problem is intimately related with the ergodic theory
of nonlinear ﬁlters. The requisite property follows from the results in [15] under
reasonable ergodicity assumptions but under very stringent complexity assumptions
on the loss (essentially that {l(u,·) : u ∈U} is uniformly Lipschitz). Alternatively,
one can apply the results in [8], which require exceedingly strong ergodicity as-
sumptions but weaker complexity assumptions. Let us note that one could similarly
obtain a pathwise version of Lemma 3.19, but the requisite pathwise approximation
property of particle ﬁlters has not been investigated in the literature.
3.4 The conditions of Algoet, Weissman, Merhav, and Nobel
The aim of this section is to brieﬂy discuss the assumptions imposed in previous
work on the pathwise optimality property due to Algoet [1], Weissman and Mer-
hav [32], and Nobel [24]. Let us emphasize that, while our results cover a much
broader range of decision problems, none of these previous results follow in their
entirety from our general results. This highlights once more that our results are, un-
fortunately, nowhere close to a complete characterization of the pathwise optimality
property.
3.4.1 Algoet
Algoet’s results [1], which cover the full information setting only, were already
discussed at length in the introduction and in section 2.2. The existence of a pathwise
optimal strategy can be obtained in this setting under no additional assumptions
from Theorem 2.6, which even goes beyond Algoet’s result in that it gives an explicit

Ergodicity, Decisions, and Partial Information
29
expression for the optimal asymptotic loss. However, Algoet establishes that in fact
the mean-optimal strategy ˜u is pathwise optimal in this setting, while our general
Corollary 2.11 can only establish this under an additional complexity assumption.
We do not know whether this complexity assumption can be weakened in general.
3.4.2 Weissman and Merhav
Weissman and Merhav [32] consider the stochastic process setting (X,Y), where
Xk takes values in {0,1} and Yk takes values in R for all k ∈Z, and where the loss
function takes the form ￿0(u) = l(u,X1) and is assumed to be uniformly bounded.
As X is binary-valued, it is immediate that any loss function l is equimeasurable.
Therefore, our results show that the mean-optimal strategy ˜u is pathwise optimal
whenever the model is a conditional K-automorphism relative to Y−∞,0.
The assumption imposed by Weissman and Merhav in [32] is as follows:
∞
∑
k=1
sup
r≥1
E[|P[Xr+k = a|Xr = a,Y0,r+k−1]−P[Xr+k = a|Y0,r+k−1]|] < ∞for a = 0,1.
Using stationarity, this condition is equivalent to
∞
∑
k=0
sup
r≥1
E[|P[X1 = a|X−k = a,Y−r−k,0]−P[X1 = a|Y−r−k,0]|] < ∞for a = 0,1,
which readily implies
∞
∑
k=0
E[|P[X1 = a|σ{X−k}∨Y−∞,0]−P[X1 = a|Y−∞,0]|] < ∞.
If the σ-ﬁeld σ{X−k}∨Y−∞,0 could be replaced by the larger σ-ﬁeld X−∞,−k∨Y−∞,0
in this expression, then Assumption 3 of Corollary 2.11 would follow immediately.
However, the smaller σ-ﬁeld appears to yield a slightly better variant of the assump-
tion imposed in [32]. This is possible because the result is restricted to the special
choice of loss ￿0(u) = l(u,X1) that depends on X1 only. On the other hand, it is to
be expected that in most cases the assumption of [32] is much more stringent than
that of Corollary 2.11. Note that Assumption 3 of Corollary 2.11 is purely qual-
itative in nature: it states, roughly speaking, that two σ-ﬁelds coincide. This is a
structural property of the model. On the other hand, the assumption of [32] is in-
herently quantitative in nature: it requires that a certain mixing property holds at
a sufﬁciently fast rate (the mixing coefﬁcients must be summable). A quantitative
bound on the mixing rate is both much more restrictive and much harder to verify,
in general, as compared to a purely structural property.
In a sense, the approach of Weissman and Merhav is much closer in spirit to the
weak pathwise optimality results in this paper than it is to the pathwise optimality
results. Indeed, if we replace the weak pathwise optimality property

30
Ramon van Handel
P[LT(u)−LT(u￿) < −ε] T→∞
−−−→0
for every ε > 0
by its quantitative counterpart
∞
∑
T=1
P[LT(u)−LT(u￿) < −ε] < ∞
for every ε > 0,
then pathwise optimality will automatically follow from the Borel-Cantelli lemma.
In the same spirit, if in Theorem 2.13 we replace the uniform conditional mixing
assumption by the corresponding quantitative counterpart
T
∑
k=1
E
￿
esssup
u,u￿∈U0
|E[{ ¯￿M
0 (u)◦T −k} ¯￿M
0 (u￿)|Y−∞,0]|
￿
= O(T α)
for some α < 1 (that may depend on M), then we easily obtain a pathwise version of
Lemma 4.7 below (using Etemadi’s well-known device [11]), and consequently the
conclusion of Theorem 2.13 is replaced by that of Theorem 2.6. It is unclear whether
such quantitative mixing conditions provide a distinct mechanism for pathwise op-
timality as compared to qualitative structural conditions as in our main results.
3.4.3 Nobel
Nobel [24] considers the stochastic process setting (X,Y) with observations of the
additive form Yk = Xk + Nk, where N = (Nk)k∈Z is an L2-martingale difference se-
quence independent of X. The loss function considered is the mean-square loss
￿0(u) = (u−X1)2. This very special scenario is essential for the result given in [24];
on the other hand, it is not assumed that (X,Y) is even stationary or that the decision
space U is a compact set (when U = R, the quadratic loss is not dominated). In
order to compare with our general results, we will additionally assume that (X,Y) is
stationary and ergodic and that Xk are uniformly bounded random variables (so that
we may choose U = [−￿X1￿∞,￿X1￿∞] without loss of generality).
While this is certainly a decision problem with partial information, the key obser-
vation is that this special problem is in fact a decision problem with full information
in disguise. Indeed, note that we can write for any strategy u
LT(u) = 1
T
T
∑
k=1
(uk −Yk+1)2 + 1
T
T
∑
k=1
{X2
k+1 −Y 2
k+1}+ 1
T
T
∑
k=1
2ukNk+1.
The last term of this expression converges to zero a.s. as T →∞for any admis-
sible strategy u by the martingale law of large numbers, as (ukNk+1)k∈Z is an L2-
martingale difference sequence. On the other hand, the second to last term of this
expression does not depend on the strategy u at all. Therefore,

Ergodicity, Decisions, and Partial Information
31
liminf
T→∞{LT(u)−LT(˜u)} = liminf
T→∞
￿
1
T
T
∑
k=1
(uk −Yk+1)2 −1
T
T
∑
k=1
( ˜uk −Yk+1)2
￿
a.s.,
which corresponds to the decision problem with the full information loss ￿0(u) =
(u −Y1)2. Thus pathwise optimality of the mean-optimal strategy ˜u follows from
Algoet’s result. (The main difﬁculty in [24] is to introduce suitable truncations to
deal with the lack of boundedness, which we avoided here.)
Of course, we could deduce the result from our general theory in the same man-
ner: reduce ﬁrst to a full information decision problem as above, and then invoke
Corollary 2.11 in the full information setting. However, a more relevant test of our
general theory might be to ask whether one can deduce the result directly from
Corollary 2.11, without ﬁrst reducing to the full information setting. Unfortunately,
it is not clear whether it is possible, in general, to ﬁnd a generating σ-ﬁeld X such
that Assumption 3 of Corollary 2.11 holds.
One might interpret the additive noise model as a type of “informative” observa-
tions: while X cannot be reconstructed from the observations Y, the law of X can
certainly be reconstructed from the law of Y even if the former were not known a
priori (this idea is exploited in [32, 24] to devise universal prediction strategies that
do not require prior knowledge of the law of X). In the hidden Markov model setting,
there is in fact a connection between “informative” observations and the conditional
K-property. In particular, if (X,Y) is a hidden Markov model where Xk takes a ﬁnite
number of values, and Yk = Xk + ξk where ξk are i.i.d. and independent of X, then
the conditional K-property holds, and we therefore have pathwise optimal strategies
for any dominated loss. This follows from observability conditions in the Markov
setting, cf. [5, section 6.2] and the references therein. However, the ideas that lead
to this result do not appear to extend to more general situations.
4 Proofs
4.1 Proof of Theorem 2.6
Throughout the proof, we ﬁx a generating σ-ﬁeld X that satisﬁes the conditions of
Theorem 2.6. In the following, we deﬁne the σ-ﬁelds
Gn
k = Y−∞,k ∨T n−kX,
G∞
k =
￿
n
Gn
k.
Note that Gn
k is decreasing in n and increasing in k.
We begin by establishing the following lemma.
Lemma 4.1. For any admissible strategy u and any m,n ∈Z
1
T
T
∑
k=1
{E[￿k(uk)|Gm
k ]−E[￿k(uk)|Gn
k]} T→∞
−−−→0
a.s.

32
Ramon van Handel
Proof. Assume m < n without loss of generality. Fix r < ∞, and deﬁne
∆j
k = E[￿k(uk)1Λ◦T k≤r|G j
k]−E[￿k(uk)1Λ◦T k≤r|G j+1
k
]
for m ≤j < n. Then it is easily seen that we have the inequality
￿￿￿￿
1
T
T
∑
k=1
{E[￿k(uk)|Gm
k ]−E[￿k(uk)|Gn
k]}
￿￿￿￿≤
n−1
∑
j=m
￿￿￿￿
1
T
T
∑
k=1
∆j
k
￿￿￿￿+
1
T
T
∑
k=1
{E[Λ1Λ>r|Gm
0 ]+E[Λ1Λ>r|Gn
0]}◦T k.
By the ergodic theorem, the second term on the right converges to κ(r) := E[2Λ1Λ>r]
a.s. as T →∞. It remains to consider the ﬁrst term.
To this end, note the inclusions G j+1
k
⊆G j
k ⊆G j+1
k+1. It follows that
∆j
k is G j+1
k+1-measurable,
E[∆j
k|G j+1
k
] = 0,
and |∆j
k| ≤2r
for 0 ≤j < n. Thus (∆j
k)k≥1 is a uniformly bounded martingale difference sequence
with respect to the ﬁltration (G j+1
k+1)k≥1, and we consequently have
1
T
T
∑
k=1
∆j
k
T→∞
−−−→0
a.s.
by the simplest form of the martingale law of large numbers (indeed, it is easily seen
that Mn = ∑n
k=1 ∆j
k/k is an L2-bounded martingale, so that the result follows from
the martingale convergence theorem and Kronecker’s lemma).
Putting together these results, we obtain
limsup
T→∞
￿￿￿￿
1
T
T
∑
k=1
{E[￿k(uk)|Gm
k ]−E[￿k(uk)|Gn
k]}
￿￿￿￿≤κ(r)
a.s.
for arbitrary r < ∞. Letting r →∞completes the proof.
￿￿
We can now establish a lower bound on the loss of any strategy.
Corollary 4.2. Under the assumptions of Theorem 2.6, we have
1
T
T
∑
k=1
{￿k(uk)−E[￿k(uk)|G∞
k ]} T→∞
−−−→0
a.s.
for any admissible strategy u. In particular,
liminf
T→∞LT(u) ≥E
￿
essinf
u∈U0
E[￿0(u)|G∞
0 ]
￿
= L￿
a.s.
Proof. We begin by noting that

Ergodicity, Decisions, and Partial Information
33
￿￿￿￿
1
T
T
∑
k=1
{E[￿k(uk)|Gn
k]−E[￿k(uk)|G∞
k ]}
￿￿￿￿≤1
T
T
∑
k=1
esssup
u∈Uk
|E[￿k(u)|Gn
k]−E[￿k(u)|G∞
k ]|
T→∞
−−−→E
￿
esssup
u∈U0
|E[￿0(u)|Gn
0]−E[￿0(u)|G∞
0 ]|
￿
a.s.
by the ergodic theorem. Similarly,
￿￿￿￿
1
T
T
∑
k=1
{E[￿k(uk)|Gm
k ]−￿k(uk)}
￿￿￿￿≤1
T
T
∑
k=1
esssup
u∈Uk
|E[￿k(u)|Gm
k ]−￿k(u)|
T→∞
−−−→E
￿
esssup
u∈U0
|E[￿0(u)|Gm
0 ]−￿0(u)|
￿
a.s.
Therefore, using Lemma 4.1 and Assumption 2 of Theorem 2.6, the ﬁrst statement
of the Corollary follows by letting n →∞and m →−∞.
For the second statement, it sufﬁces to note that
1
T
T
∑
k=1
E[￿k(uk)|G∞
k ] ≥1
T
T
∑
k=1
essinf
u∈Uk
E[￿k(u)|G∞
k ] T→∞
−−−→L￿
a.s.
by the ergodic theorem and Assumption 3 of Theorem 2.6.
￿￿
As was explained in the introduction, a pathwise optimal strategy could easily be
obtained of one can prove “ergodic tower property” of the form
1
T
T
∑
k=1
{￿k(uk)−E[￿k(uk)|Y0,k]} T→∞
−−−→0
a.s.
?
Corollary 4.2 establishes just such a property, but where the σ-ﬁeld Y0,k is replaced
by the larger σ-ﬁeld G∞
k . This yields a lower bound on the asymptotic loss, but it is
far from clear that one can choose a Y0,k-adapted strategy that attains this bound.
Therefore, what remains is to show that there exists an admissible strategy u￿that
attains the lower bound in Corollary 4.2. A promising candidate is the mean-optimal
strategy ˜u. Unfortunately, we are not able to prove pathwise optimality of the mean-
optimal strategy in the general setting of Theorem 2.6. However, we will obtain a
pathwise optimal strategy u￿by a judicious modiﬁcation of the mean-optimal strat-
egy ˜u. The key idea is the following “uniform” version of the martingale conver-
gence theorem, which we prove following Neveu [23, Lemma V-2-9].
Lemma 4.3. The following holds:
essinf
u∈U−k,0
E[￿0(u)|Y−k,0] k→∞
−−−→essinf
u∈U0
E[￿0(u)|Y−∞,0]
a.s. and in L1.
Proof. Using the construction of the essential supremum as in the proof of Lemma
2.5, we can choose for each 0 ≤k < ∞a countable family Uc
−k,0 ⊂U−k,0 such that

34
Ramon van Handel
essinf
u∈U−k,0
E[￿0(u)|Y−k,0] =
inf
u∈Uc
−k,0
E[￿0(u)|Y−k,0]
a.s.,
and a countable family Uc
0 ⊂U0 such that
essinf
u∈U0
E[￿0(u)|Y−∞,0] = inf
u∈Uc
0
E[￿0(u)|Y−∞,0]
a.s.
For every 0 ≤k < ∞, choose an arbitrary ordering (Un
k )n∈N of the elements of the
countable set Uc
−k,0 ∪(Uc
0 ∩U−k,0). Then we clearly have
Mk := essinf
u∈U−k,0
E[￿0(u)|Y−k,0] = min
0≤l≤k inf
n∈NE[￿0(Un
l )|Y−k,0]
a.s.
and
M := essinf
u∈U0
E[￿0(u)|Y−∞,0] =
inf
0≤l<∞inf
n∈NE[￿0(Un
l )|Y−∞,0]
a.s.
Our aim is to prove that Mk →M a.s. and in L1 as k →∞.
We begin by noting that |Mk| ≤E[Λ|Y−k,0]. Therefore, the sequence (Mk)k≥0 is
uniformly integrable. Moreover, (Mk)k≥0 is a supermartingale with respect to the
ﬁltration (Y−k,0)k≥0: indeed, we can easily compute
E[Mk+1|Y−k,0] ≤E
￿
min
0≤l≤k inf
n∈NE[￿0(Un
l )|Y−k−1,0]
￿￿￿Y−k,0
￿
≤Mk.
Thus Mk →M∞a.s. and in L1 by the martingale convergence theorem for some
random variable M∞. We must now show that M∞= M a.s. Note that
M∞= lim
k→∞Mk ≤lim
k→∞E[￿0(Un
l )|Y−k,0] = E[￿0(Un
l )|Y−∞,0]
a.s.
for every n ∈N and 0 ≤l < ∞, so M∞≤M a.s. To complete the proof, it therefore
sufﬁces to show that E[M∞] = E[M].
To this end, deﬁne for N ∈N and 0 ≤k ≤∞
MN
k = min
l≤N∧kmin
n≤N E[￿0(Un
l )|Y−k,0].
As (MN
k )k≥0 is again a supermartingale, clearly E[MN
k ] is doubly nonincreasing in k
and N. The exchange of limits is therefore permitted, so that
E[M∞] = lim
k→∞lim
N→∞E[MN
k ] = lim
N→∞lim
k→∞E[MN
k ] = E[M].
This completes the proof.
￿￿
Corollary 4.4. Suppose that Assumption 3 of Theorem 2.6 holds. Then
E[￿k( ˜uk)|G∞
k ]◦T −k k→∞
−−−→essinf
u∈U0
E[￿0(u)|G∞
0 ]
in L1.

Ergodicity, Decisions, and Partial Information
35
Proof. Deﬁne ˆuk = ˜uk ◦T −k ∈U−k,0, so that
E[￿k( ˜uk)|G∞
k ]◦T −k = E[￿0( ˆuk)|G∞
0 ].
By stationarity and the deﬁnition of ˜u, we have
E[E[￿0( ˆuk)|G∞
0 ]] = E[E[￿0( ˆuk)|Y−k,0]]
≤E
￿
essinf
u∈U−k,0
E[￿0(u)|Y−k,0]
￿
+k−1.
Therefore, by Lemma 4.3, we have
limsup
k→∞
E[E[￿0( ˆuk)|G∞
0 ]] ≤E
￿
essinf
u∈U0
E[￿0(u)|Y−∞,0]
￿
= L￿.
On the other hand, note that
E[￿0( ˆuk)|G∞
0 ] ≥essinf
u∈U0
E[￿0(u)|G∞
0 ]
a.s.
Using Assumption 3, we therefore have
limsup
k→∞
￿￿￿E[￿0( ˆuk)|G∞
0 ]−essinf
u∈U0
E[￿0(u)|G∞
0 ]
￿￿￿
1 ≤0.
This completes the proof.
￿￿
We are now in the position to construct the pathwise optimal strategy u￿. By
Corollary 4.4, we can choose a (nonrandom) sequence kn ↑∞such that
E[￿kn( ˜ukn)|G∞
kn]◦T −kn n→∞
−−−→essinf
u∈U0
E[￿0(u)|G∞
0 ]
a.s.
Let us deﬁne
u￿
k = ˜ukn ◦T k−kn
for kn ≤k < kn+1, n ∈N.
Then clearly u￿= (u￿
k)k≥1 is an admissible strategy.
Lemma 4.5. Suppose that the assumptions of Theorem 2.6 hold. Then
lim
T→∞LT(u￿) = L￿
a.s.
Proof. By construction,
E[￿k(u￿
k)|G∞
k ]◦T −k k→∞
−−−→essinf
u∈U0
E[￿0(u)|G∞
0 ]
a.s.
Moreover,
sup
k≥1
￿￿E[￿k(u￿
k)|G∞
k ]◦T −k￿￿≤E[Λ|G∞
0 ] ∈L1.
Therefore, by Maker’s generalized ergodic theorem [19, Corollary 10.8]

36
Ramon van Handel
1
T
T
∑
k=1
E[￿k(u￿
k)|G∞
k ] T→∞
−−−→E
￿
essinf
u∈U0
E[￿0(u)|G∞
0 ]
￿
= L￿
a.s.
Thus LT(u￿) →L￿a.s. as T →∞by Corollary 4.2.
￿￿
The proof of Theorem 2.6 is now complete. Indeed, if u is admissible, then
liminf
T→∞{LT(u)−LT(u￿)} = liminf
T→∞LT(u)−L￿≥0
a.s.
by Lemma 4.5 and Corollary 4.2, so u￿is pathwise optimal.
4.2 Proof of Corollary 2.11
The prove pathwise optimality, it sufﬁces to show LT(˜u) →L￿a.s.
Lemma 4.6. Under the assumptions of Corollary 2.11, the mean-optimal strategy ˜u
(Lemma 2.5) satisﬁes LT(˜u) →L￿a.s. as T →∞.
Proof. By the deﬁnition of ˜u and Lemma 4.3,
E[￿k( ˜uk)|Y0,k]◦T −k k→∞
−−−→essinf
u∈U0
E[￿0(u)|Y−∞,0]
a.s.
Therefore, the third part of Assumption 2 of Corollary 2.11 implies that
E[￿k( ˜uk)|Y−∞,k]◦T −k k→∞
−−−→essinf
u∈U0
E[￿0(u)|Y−∞,0]
a.s.
But by Assumption 3 of Corollary 2.11 and stationarity, we obtain
E[￿k( ˜uk)|G∞
k ]◦T −k k→∞
−−−→essinf
u∈U0
E[￿0(u)|Y−∞,0]
a.s.
Moreover, we have
sup
k≥1
￿￿E[￿k( ˜uk)|G∞
k ]◦T −k￿￿≤E[Λ|G∞
0 ] ∈L1.
Maker’s generalized ergodic theorem [19, Corollary 10.8] therefore yields
1
T
T
∑
k=1
E[￿k( ˜uk)|G∞
k ] T→∞
−−−→E
￿
essinf
u∈U0
E[￿0(u)|Y−∞,0]
￿
= L￿
a.s.
As the assumptions of Corollary 2.11 imply those of Theorem 2.6, the result as well
as pathwise optimality of ˜u now follow from Corollary 4.2.
￿￿

Ergodicity, Decisions, and Partial Information
37
4.3 Proof of Theorem 2.13
The proof of the Theorem is once again based on a variant of the “ergodic tower
property” described in the introduction. In the present setting, the result follows
rather easily from the conditional weak mixing assumption.
Lemma 4.7. Suppose that the assumption of Theorem 2.13 holds. Then
1
T
T
∑
k=1
{￿k(uk)−E[￿k(uk)|Y−∞,k]} T→∞
−−−→0
in L1
for every admissible strategy u.
Proof. Deﬁne ¯￿M
k (u) = ¯￿M
0 (u)◦T k for u ∈U. We begin by noting that
E
￿￿1
T
T
∑
k=1
¯￿M
k (uk)
￿2￿
= 1
T 2
T
∑
n,m=1
E[ ¯￿M
n (un) ¯￿M
m (um)].
Suppose that m ≤n. Then by stationarity and as u is admissible
E[ ¯￿M
n (un) ¯￿M
m (um)] = E[ ¯￿M
0 (un ◦T −n) { ¯￿M
0 (um ◦T −m)◦T −(n−m)}]
≤E
￿
esssup
u,u￿∈U0
|E[ ¯￿M
0 (u￿) { ¯￿M
0 (u)◦T −(n−m)}|Y−∞,0]|
￿
.
We can therefore estimate
E
￿￿1
T
T
∑
k=1
¯￿M
k (uk)
￿2￿
≤2
T 2
T
∑
n=1
n−1
∑
k=0
E
￿
esssup
u,u￿∈U0
|E[ ¯￿M
0 (u￿) { ¯￿M
0 (u)◦T −k}|Y−∞,0]|
￿
= 2
T 2
T−1
∑
k=0
(T −k)E
￿
esssup
u,u￿∈U0
|E[ ¯￿M
0 (u￿) { ¯￿M
0 (u)◦T −k}|Y−∞,0]|
￿
≤2
T
T−1
∑
k=0
E
￿
esssup
u,u￿∈U0
|E[ ¯￿M
0 (u￿) { ¯￿M
0 (u)◦T −k}|Y−∞,0]|
￿
.
By the uniform conditional mixing assumption, it follows that
lim
M→∞limsup
T→∞
￿￿￿￿
1
T
T
∑
k=1
¯￿M
k (uk)
￿￿￿￿
2
= 0.
On the other hand, note that
sup
T≥1
￿￿￿￿
1
T
T
∑
k=1
{￿k(uk)−E[￿k(uk)|Y−∞,k]}−1
T
T
∑
k=1
¯￿M
k (uk)
￿￿￿￿
1
≤E[2Λ1Λ>M] M→∞
−−−→0.
The result now follows by applying the triangle inequality.
￿￿

38
Ramon van Handel
Corollary 4.8. Under the assumption of Theorem 2.13, we have
P
￿
LT(u)−L￿≤−ε
￿T→∞
−−−→0
for every ε > 0
for every admissible strategy u.
Proof. Let u be any admissible strategy. Then by Lemma 4.7
LT(u)−1
T
T
∑
k=1
E[￿k(uk)|Y−∞,k] T→∞
−−−→0
in L1.
On the other hand, note that
1
T
T
∑
k=1
E[￿k(uk)|Y−∞,k] ≥1
T
T
∑
k=1
essinf
u∈Uk
E[￿k(u)|Y−∞,k] T→∞
−−−→L￿
in L1
by the ergodic theorem. The result follows directly.
￿￿
In view of Corollary 4.8, in order to establish weak pathwise optimality of ˜u it
evidently sufﬁces to prove that ˜u satisﬁes the ergodic theorem LT(˜u) →L￿in L1.
However, most of the work was already done in the proof of Theorem 2.6.
Lemma 4.9. Under the assumption of Theorem 2.13, LT(˜u) →L￿in L1.
Proof. By the deﬁnition of ˜u, we have
E[￿k( ˜uk)|Y0,k]◦T −k ≤essinf
u∈U−k,0
E[￿0(u)|Y−k,0]+k−1
a.s.
Therefore, by Lemma 4.3, we obtain
limsup
k→∞
E[E[￿k( ˜uk)|Y−∞,k]◦T −k] ≤E
￿
essinf
u∈U0
E[￿0(u)|Y−∞,0]
￿
= L￿.
On the other hand,
E[￿k( ˜uk)|Y−∞,k]◦T −k ≥essinf
u∈U0
E[￿0(u)|Y−∞,0]
a.s.
for all k ∈N. It follows that
limsup
k→∞
￿￿￿￿E[￿k( ˜uk)|Y−∞,k]◦T −k −essinf
u∈U0
E[￿0(u)|Y−∞,0]
￿￿￿￿
1
=
limsup
k→∞
E[E[￿k( ˜uk)|Y−∞,k]◦T −k]−E
￿
essinf
u∈U0
E[￿0(u)|Y−∞,0]
￿
≤0.
Therefore, by Maker’s generalized ergodic theorem [19, Corollary 10.8]
1
T
T
∑
k=1
E[￿k( ˜uk)|Y−∞,k] T→∞
−−−→L￿
in L1.

Ergodicity, Decisions, and Partial Information
39
The result now follows using Lemma 4.7.
￿￿
Combining Corollary 4.8 and Lemma 4.9 completes the proof of Theorem 2.13.
4.4 Proof of Theorem 2.16
The implication 1 ⇒2 of Theorem 2.16 follows immediately from Theorem 1.8.
In the following, we will prove the converse implication 2 ⇒1: that is, we will
show that if (Ω,B,P,T) is not conditionally weak mixing relative to Y, then we
can construct a bounded loss function ￿with some ﬁnite decision space U for which
there exists no weakly pathwise optimal strategy.
We begin by providing a “diagonal” characterization of conditional weak mixing.
Lemma 4.10. (Ω,B,P,T) is conditionally weak mixing relative to Z if and only if
1
T
T
∑
k=1
|E[{h◦T −k} h|Z]−E[h◦T −k|Z]E[h|Z]| T→∞
−−−→0
in L1
for every h ∈L2, provided that Z ⊆T −1Z.
Proof. It sufﬁces to show that if the equation display in the lemma holds, then
(Ω,B,P,T) is conditionally weak mixing relative to Z. To this end, let us ﬁx h ∈L2
and denote by A the class of all functions g ∈L2 such that
1
T
T
∑
k=1
|E[{g◦T −k} h|Z]−E[g◦T −k|Z]E[h|Z]| T→∞
−−−→0
in L1.
Clearly A is closed linear subspace of L2. Note that A certainly contains every
random variable of the form h1B ◦T m or 1B ◦T m for m ∈Z and B ∈Z. Therefore,
the closed linear span K of all such random variables is included in A . On the other
hand, suppose that g ∈K⊥. Then for every k ∈Z, we have
E[E[{g◦T −k} h|Z]1B] = E[g {h1B ◦T k}] = 0
for all B ∈Z. It follows that E[{g ◦T −k} h|Z] = 0 a.s. for all k ∈N. Similarly, we
ﬁnd that E[g◦T −k|Z] = 0 a.s. for all k ∈N. Thus evidently K⊥⊆A also. Therefore,
A contains K ⊕K⊥= L2, and the proof is complete.
￿￿
In the remainder of this section, we suppose that (Ω,B,P,T) is not conditionally
weakly mixing relative to Y. By Lemma 4.10, there is a function h ∈L2 such that
limsup
T→∞
E
￿
1
T
T
∑
k=1
|E[{H ◦T −k} H|Y]|
￿
≥ε > 0

40
Ramon van Handel
where H := h −E[h|Y]. By approximation in L2, we may clearly assume without
loss of generality that h takes values in [0,1], so that H takes values in [−1,1]. We
will ﬁx such a function in the sequel, and consider the loss function
￿(u,ω) = uH(ω)
where we initially choose decisions u ∈[−1,1] (the decision space will be dis-
cretized at the end of the proof as required by Theorem 2.16). We claim that for
the loss function ￿there exists no weakly pathwise optimal strategy. This will be
proved by a randomization procedure that will be explained presently.
In the following ([0,1],I) denotes the unit interval with its Borel σ-ﬁeld.
Lemma 4.11. Suppose that (Ω,B,P) is a standard probability space. Then there
exists a (Y⊗I)-measurable map ι : Ω×[0,1] →Ωsuch that
E[X|Y](ω) =
￿1
0 X(ι(ω,λ))dλ
P-a.e. ω ∈Ω.
for any bounded (B-)measurable function X : Ω→R.
Proof. As (Ω,B,P) is a standard probability space, this is [19, Lemma 3.22] to-
gether with the existence of regular conditional probabilities [19, Theorem 6.3].
￿￿
Consider the quantity
Aλ
T(ω) = 1
T
T
∑
k=1
H(T kι(ω,λ))H(T kω).
Then we can compute
￿1
0 (Aλ
T)2 dλ = 1
T 2
T
∑
m,n=1
H(T mω)H(T nω)
￿1
0 H(T mι(ω,λ))H(T nι(ω,λ))dλ
= 1
T 2
T
∑
m,n=1
H(T mω)H(T nω)E[{H ◦T m}{H ◦T n}|Y](ω).
In particular, using the invariance of Y, we have
￿￿1
0 E[(Aλ
T)2]dλ
￿1/2
= E
￿
1
T 2
T
∑
m,n=1
E[{H ◦T m}{H ◦T n}|Y]2
￿1/2
≥E
￿
1
T 2
T
∑
m,n=1
|E[{H ◦T m}{H ◦T n}|Y]|
￿
≥E
￿
1
T 2
T
∑
n=1
n
∑
m=1
|E[{H ◦T m−n}H|Y]|
￿

Ergodicity, Decisions, and Partial Information
41
= E
￿
1
T 2
T−1
∑
k=0
(T −k)|E[{H ◦T −k}H|Y]|
￿
≥E
￿
1
2T
￿T/2￿
∑
k=0
|E[{H ◦T −k}H|Y]|
￿
.
By our choice of H, it follows that
limsup
T→∞
E[(Aλ
T)2] ≥ε2
16
for some λ = λ0 ∈[0,1]. Deﬁne
uk(ω) = H(T kι(ω,λ0)).
Then uk is Y-measurable for all k (and is therefore admissible if we choose, for the
time being, the continuous decision space U = [−1,1]), and LT(u) = Aλ0
T . Moreover,
ε2
16 ≤limsup
T→∞
E[(LT(u))2] ≤ε2
64 +limsup
T→∞
P
￿
LT(u) > ε
8
￿
+limsup
T→∞
P
￿
LT(u) < −ε
8
￿
implies that we may assume without loss of generality that
limsup
T→∞
P
￿
LT(u) < −ε
8
￿
> 0
(if this is not the case, simply substitute −u for u in the following). But note that
the strategy ˜u deﬁned by ˜uk = 0 for all k is mean-optimal (indeed, E[￿k(u)|Y] =
uE[H|Y]◦T k = 0 for all u by construction). Thus evidently
limsup
T→∞
P
￿
LT(u)−LT(˜u) < −ε
8
￿
> 0,
so ˜u is not weakly pathwise optimal. It follows from Lemma 2.12 that no weakly
pathwise optimal strategy can exist if we choose the decision space U = [−1,1].
To complete the proof of Theorem 2.16, it remains to show that this conclusion
remains valid if we replace U = [−1,1] by some ﬁnite set. This is easily attained by
discretization, however. Indeed, let U = {kε/16 : k = −￿16/ε￿,...,￿16/ε￿}, and
construct a new strategy u￿such that u￿
k equals the value of uk (which takes values
in [−1,1]) rounded to the nearest element of U. Clearly ˜u and u￿both take values in
the ﬁnite set U, and we have |LT(u)−LT(u￿)| ≤ε/16. Therefore,
limsup
T→∞
P
￿
LT(u￿)−LT(˜u) < −ε
16
￿
> 0,
and it follows again by Lemma 2.12 that no weakly pathwise optimal strategy exists.

42
Ramon van Handel
4.5 Proof of Theorem 3.15
By stationarity, we can rewrite the conditional absolute regularity property as
￿￿P[(Xk)k≥0 ∈·|X−∞,−n ∨Y−∞,∞]−P[(Xk)k≥0 ∈·|Y−∞,∞]
￿￿
TV
n→∞
−−−→0
in L1.
Using a simple truncation argument (as the loss is dominated in L1), this implies
esssup
u∈U0
￿￿E[l(u,X0)|X−∞,−n ∨Y−∞,∞]−E[l(u,X0)|Y−∞,∞]
￿￿n→∞
−−−→0
in L1.
If only we could replace Y−∞,∞by Y−∞,0 in this expression, all the assumptions of
Theorem 2.6 would follow immediately. Unfortunately, it is not immediately obvi-
ous whether this replacement is possible without additional assumptions.
Remark 4.12. In general, it is not clear whether a conditional K-automorphism rel-
ative to Y−∞,∞is necessarily a conditional K-automorphism relative to Y−∞,0. In
this context, it is interesting to note that the corresponding property does hold for
conditional weak mixing. We brieﬂy sketch the proof. Suppose that (Ω,B,P,T) is
conditionally weakly mixing relative to Y−∞,∞. We claim that then also
1
T
T
∑
k=1
|E[{f ◦T −k} g|Y−∞,0]−E[f ◦T −k|Y−∞,0]E[g|Y−∞,0]| T→∞
−−−→0
in L1
for every f,g ∈L2. Indeed, the conclusion is clearly true whenever f is Y−∞,n-
measurable for some n ∈Z. By approximation in L2, the conclusion holds whenever
f is Y−∞,∞-measurable, and it therefore sufﬁces to consider f ∈L2(Y−∞,∞)⊥. But in
this case we have E[f ◦T −k|Y−∞,∞] = E[f ◦T −k|Y−∞,0] = 0 for all k, and
￿￿￿￿
1
T
T
∑
k=1
|E[{ f ◦T −k} g|Y−∞,0]|
￿￿￿￿
1
≤
￿￿￿￿
1
T
T
∑
k=1
|E[{ f ◦T −k} g|Y−∞,∞]|
￿￿￿￿
1
T→∞
−−−→0
in L1
by Jensen’s inequality and the conditional weak mixing property relative to Y−∞,∞.
As we cannot directly replace Y−∞,∞by Y−∞,0, we take an alternative approach.
We begin by noting that, using the conditional absolute regularity property as de-
scribed above, we obtain the following trivial adaptation of Corollary 4.2.
Lemma 4.13. Under the assumptions of Theorem 3.15, we have
1
T
T
∑
k=1
{l(uk,Xk)−E[l(uk,Xk)|Y−∞,∞]} T→∞
−−−→0
a.s.
for any admissible strategy u.
We will now proceed to replace Y−∞,∞by Y−∞,k in Lemma 4.13. To this end, we
use the additional property established in [27, Proposition 3.9]:

Ergodicity, Decisions, and Partial Information
43
P[(Xk)k≤0 ∈·|Y−∞,0] ∼P[(Xk)k≤0 ∈·|Y−∞,∞]
a.s.
Theorem 3.14 implies that the past tail σ-ﬁeld ￿
n X−∞,n is P[·|Y−∞,0]-trivial a.s.
(cf. [33]). Thus a standard argument [21, Theorem III.14.10] yields
￿￿P[(Xk)k≤n ∈·|Y−∞,0]−P[(Xk)k≤n ∈·|Y−∞,∞]
￿￿
TV
n→−∞
−−−−→0
in L1.
Therefore, by stationarity and a simple truncation argument, we have
esssup
u∈U0
￿￿E[l(u,X0)|Y−∞,n]−E[l(u,X0)|Y−∞,∞]
￿￿n→∞
−−−→0
in L1.
This yields the following consequence.
Corollary 4.14. Under the assumptions of Theorem 3.15, we have
1
T
T
∑
k=1
{l(uk,Xk)−E[l(uk,Xk)|Y−∞,k]} T→∞
−−−→0
a.s.
for any admissible strategy u. In particular,
liminf
T→∞LT(u) ≥E
￿
essinf
u∈U0
E[￿0(u)|Y−∞,0]
￿
= L￿
a.s.
Proof (Sketch). Following almost verbatim the proof of Lemma 4.1, one can prove
1
T
T
∑
k=1
{E[l(uk,Xk)|Y−∞,k]−E[l(uk,Xk)|Y−∞,k+r]} T→∞
−−−→0
a.s.
for any r ∈N. On the other hand, we have
limsup
T→∞
￿￿￿￿
1
T
T
∑
k=1
{E[l(uk,Xk)|Y−∞,k+r]−E[l(uk,Xk)|Y−∞,∞]}
￿￿￿￿
≤lim
T→∞
1
T
T
∑
k=1
esssup
u∈Uk
￿￿E[l(u,Xk)|Y−∞,k+r]−E[l(u,Xk)|Y−∞,∞]
￿￿
= E
￿
esssup
u∈U0
￿￿E[l(u,X0)|Y−∞,r]−E[l(u,X0)|Y−∞,∞]
￿￿
￿
a.s.
by the ergodic theorem. It was shown above that the latter quantity converges to zero
as r →∞, and the result now follows using Lemma 4.13.
￿￿
The remainder of the proof of Theorem 3.15 is identical to that of Theorem 2.6
modulo trivial modiﬁcations, and is therefore omitted.

44
Ramon van Handel
Acknowledgment
This work was partially supported by NSF grant DMS-1005575.
References
1. Algoet, P.H.: The strong law of large numbers for sequential decisions under uncertainty. IEEE
Trans. Inform. Theory 40(3), 609–633 (1994)
2. Bellow, A., Losert, V.: The weighted pointwise ergodic theorem and the individual ergodic
theorem along subsequences. Trans. Amer. Math. Soc. 288(1), 307–345 (1985)
3. Berend, D., Bergelson, V.: Mixing sequences in Hilbert spaces. Proc. Amer. Math. Soc. 98(2),
239–246 (1986)
4. Capp´e, O., Moulines, E., Ryd´en, T.: Inference in hidden Markov models. Springer, New York
(2005)
5. Chigansky, P., van Handel, R.: A complete solution to Blackwell’s unique ergodicity problem
for hidden Markov chains. Ann. Appl. Probab. 20(6), 2318–2345 (2010)
6. Conze, J.P.: Convergence des moyennes ergodiques pour des sous-suites. In: Contributions au
calcul des probabilit´es, pp. 7–15. Bull. Soc. Math. France, M´em. No. 35. Soc. Math. France,
Paris (1973)
7. Crisan, D., Rozovski˘ı, B. (eds.): The Oxford handbook of nonlinear ﬁltering. Oxford Univer-
sity Press, Oxford (2011)
8. Del Moral, P., Ledoux, M.: Convergence of empirical processes for interacting particle sys-
tems with applications to nonlinear ﬁltering. J. Theoret. Probab. 13(1), 225–257 (2000)
9. Dellacherie, C., Meyer, P.A.: Probabilities and potential. C.
North-Holland, Amsterdam
(1988)
10. Dudley, R.M.: Uniform central limit theorems.
Cambridge University Press, Cambridge
(1999)
11. Etemadi, N.: An elementary proof of the strong law of large numbers. Z. Wahrsch. Verw.
Gebiete 55(1), 119–122 (1981)
12. Grothendieck, A.: Produits tensoriels topologiques et espaces nucl´eaires. Mem. Amer. Math.
Soc. 1955(16), 140 (1955)
13. Halmos, P.R.: In general a measure preserving transformation is mixing. Ann. of Math. (2)
45, 786–792 (1944)
14. van Handel, R.: The stability of conditional Markov processes and Markov chains in random
environments. Ann. Probab. 37(5), 1876–1925 (2009)
15. van Handel, R.: Uniform time average consistency of Monte Carlo particle ﬁlters. Stochastic
Process. Appl. 119(11), 3835–3861 (2009)
16. van Handel, R.: On the exchange of intersection and supremum of σ-ﬁelds in ﬁltering theory.
Israel J. Math. (2012). To appear
17. van Handel, R.: The universal Glivenko-Cantelli property. Probab. Th. Rel. Fields (2012). To
appear
18. Hoffmann-Jørgensen, J.: Uniform convergence of martingales.
In: Probability in Banach
spaces, 7 (Oberwolfach, 1988), Progr. Probab., vol. 21, pp. 127–137. Birkh¨auser Boston,
Boston, MA (1990)
19. Kallenberg, O.: Foundations of modern probability, second edn. Springer-Verlag, New York
(2002)
20. Kunita, H.: Asymptotic behavior of the nonlinear ﬁltering errors of Markov processes. J.
Multivariate Anal. 1, 365–393 (1971)
21. Lindvall, T.: Lectures on the coupling method. Dover Publications Inc., Mineola, NY (2002).
Corrected reprint of the 1992 original

Ergodicity, Decisions, and Partial Information
45
22. Meyn, S., Tweedie, R.L.: Markov chains and stochastic stability, second edn. Cambridge
University Press, Cambridge (2009)
23. Neveu, J.: Discrete-parameter martingales. North-Holland, Amsterdam (1975)
24. Nobel, A.B.: On optimal sequential prediction for general processes. IEEE Trans. Inform.
Theory 49(1), 83–98 (2003)
25. Pollard, D.: A user’s guide to measure theoretic probability. Cambridge University Press,
Cambridge (2002)
26. Rudolph, D.J.: Pointwise and L1 mixing relative to a sub-sigma algebra. Illinois J. Math.
48(2), 505–517 (2004)
27. Tong, X.T., van Handel, R.: Conditional ergodicity in inﬁnite dimension (2012). Preprint
28. Totoki, H.: On a class of special ﬂows. Z. Wahrscheinlichkeitstheorie und Verw. Gebiete 15,
157–167 (1970)
29. van der Vaart, A.W., Wellner, J.A.: Weak convergence and empirical processes. Springer-
Verlag, New York (1996)
30. Volkonski˘ı, V.A., Rozanov, Y.A.: Some limit theorems for random functions. I. Theor. Proba-
bility Appl. 4, 178–197 (1959)
31. Walters, P.: An introduction to ergodic theory. Springer-Verlag, New York (1982)
32. Weissman, T., Merhav, N.: Universal prediction of random binary sequences in a noisy envi-
ronment. Ann. Appl. Probab. 14(1), 54–89 (2004)
33. von Weizs¨acker, H.: Exchanging the order of taking suprema and countable intersections of
σ-algebras. Ann. Inst. H. Poincar´e Sect. B (N.S.) 19(1), 91–100 (1983)

